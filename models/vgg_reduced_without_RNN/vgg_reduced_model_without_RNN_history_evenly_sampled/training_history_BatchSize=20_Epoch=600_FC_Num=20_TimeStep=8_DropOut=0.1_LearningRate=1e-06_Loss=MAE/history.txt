Epoch: 1| Step: 0
Training loss: 4.342678070068359
Validation loss: 4.4030072714692805

Epoch: 5| Step: 1
Training loss: 4.207711219787598
Validation loss: 4.402277372216665

Epoch: 5| Step: 2
Training loss: 3.6577327251434326
Validation loss: 4.398914050030452

Epoch: 5| Step: 3
Training loss: 3.9798636436462402
Validation loss: 4.395382599164081

Epoch: 5| Step: 4
Training loss: 3.9158782958984375
Validation loss: 4.393417235343687

Epoch: 5| Step: 5
Training loss: 4.8470282554626465
Validation loss: 4.390735241674608

Epoch: 5| Step: 6
Training loss: 4.499570846557617
Validation loss: 4.387800996021558

Epoch: 5| Step: 7
Training loss: 4.287532806396484
Validation loss: 4.38524995311614

Epoch: 5| Step: 8
Training loss: 3.889957904815674
Validation loss: 4.382175758320798

Epoch: 5| Step: 9
Training loss: 3.6734671592712402
Validation loss: 4.381866096168436

Epoch: 5| Step: 10
Training loss: 5.082354545593262
Validation loss: 4.376168194637503

Epoch: 2| Step: 0
Training loss: 3.5015740394592285
Validation loss: 4.37709705803984

Epoch: 5| Step: 1
Training loss: 4.784136772155762
Validation loss: 4.371472758631552

Epoch: 5| Step: 2
Training loss: 3.9074459075927734
Validation loss: 4.371513561535907

Epoch: 5| Step: 3
Training loss: 4.723620891571045
Validation loss: 4.368857655473935

Epoch: 5| Step: 4
Training loss: 3.6724610328674316
Validation loss: 4.366133607843871

Epoch: 5| Step: 5
Training loss: 5.176007270812988
Validation loss: 4.364288724878783

Epoch: 5| Step: 6
Training loss: 3.920680522918701
Validation loss: 4.360043787187146

Epoch: 5| Step: 7
Training loss: 4.379283905029297
Validation loss: 4.35619201455065

Epoch: 5| Step: 8
Training loss: 4.218630790710449
Validation loss: 4.3574881502377085

Epoch: 5| Step: 9
Training loss: 3.571866512298584
Validation loss: 4.35419366692984

Epoch: 5| Step: 10
Training loss: 4.138051509857178
Validation loss: 4.351920527796591

Epoch: 3| Step: 0
Training loss: 3.601390838623047
Validation loss: 4.349332696648054

Epoch: 5| Step: 1
Training loss: 5.678708076477051
Validation loss: 4.345169292983188

Epoch: 5| Step: 2
Training loss: 3.5635344982147217
Validation loss: 4.342802534821213

Epoch: 5| Step: 3
Training loss: 4.702174186706543
Validation loss: 4.342693169911702

Epoch: 5| Step: 4
Training loss: 3.916822910308838
Validation loss: 4.336840127104072

Epoch: 5| Step: 5
Training loss: 4.116334915161133
Validation loss: 4.337524649917438

Epoch: 5| Step: 6
Training loss: 4.63986873626709
Validation loss: 4.332813893595049

Epoch: 5| Step: 7
Training loss: 4.299201011657715
Validation loss: 4.330796436596942

Epoch: 5| Step: 8
Training loss: 2.9013679027557373
Validation loss: 4.3284256355736845

Epoch: 5| Step: 9
Training loss: 5.0302276611328125
Validation loss: 4.326759697288595

Epoch: 5| Step: 10
Training loss: 3.0911359786987305
Validation loss: 4.324456417432395

Epoch: 4| Step: 0
Training loss: 4.866891384124756
Validation loss: 4.322883021446966

Epoch: 5| Step: 1
Training loss: 3.5394959449768066
Validation loss: 4.318670780427994

Epoch: 5| Step: 2
Training loss: 3.9385695457458496
Validation loss: 4.316275606873215

Epoch: 5| Step: 3
Training loss: 3.1071105003356934
Validation loss: 4.3154760329954085

Epoch: 5| Step: 4
Training loss: 4.99098539352417
Validation loss: 4.311268078383579

Epoch: 5| Step: 5
Training loss: 5.718232154846191
Validation loss: 4.309935938927435

Epoch: 5| Step: 6
Training loss: 4.0372819900512695
Validation loss: 4.305653277263846

Epoch: 5| Step: 7
Training loss: 3.7853050231933594
Validation loss: 4.302783817373296

Epoch: 5| Step: 8
Training loss: 3.8836886882781982
Validation loss: 4.3010014923669955

Epoch: 5| Step: 9
Training loss: 3.8984436988830566
Validation loss: 4.299063287755494

Epoch: 5| Step: 10
Training loss: 3.541283130645752
Validation loss: 4.295924878889514

Epoch: 5| Step: 0
Training loss: 3.690960645675659
Validation loss: 4.293157369859757

Epoch: 5| Step: 1
Training loss: 4.0615715980529785
Validation loss: 4.290890078390798

Epoch: 5| Step: 2
Training loss: 2.829237461090088
Validation loss: 4.287574598866124

Epoch: 5| Step: 3
Training loss: 5.073831081390381
Validation loss: 4.286313303055302

Epoch: 5| Step: 4
Training loss: 4.422822952270508
Validation loss: 4.283109923844696

Epoch: 5| Step: 5
Training loss: 4.589131832122803
Validation loss: 4.2806997324830744

Epoch: 5| Step: 6
Training loss: 4.281013488769531
Validation loss: 4.279393380688083

Epoch: 5| Step: 7
Training loss: 4.530920505523682
Validation loss: 4.2772574168379585

Epoch: 5| Step: 8
Training loss: 2.797860622406006
Validation loss: 4.272981171966881

Epoch: 5| Step: 9
Training loss: 5.0226240158081055
Validation loss: 4.27365772185787

Epoch: 5| Step: 10
Training loss: 3.7285702228546143
Validation loss: 4.269290401089576

Epoch: 6| Step: 0
Training loss: 4.247073173522949
Validation loss: 4.263612670283163

Epoch: 5| Step: 1
Training loss: 3.796225070953369
Validation loss: 4.262565658938501

Epoch: 5| Step: 2
Training loss: 4.5078630447387695
Validation loss: 4.2590947305002524

Epoch: 5| Step: 3
Training loss: 4.658425331115723
Validation loss: 4.254956547931958

Epoch: 5| Step: 4
Training loss: 3.6115143299102783
Validation loss: 4.253351575584822

Epoch: 5| Step: 5
Training loss: 4.071854591369629
Validation loss: 4.24982189875777

Epoch: 5| Step: 6
Training loss: 4.103742599487305
Validation loss: 4.247638415264827

Epoch: 5| Step: 7
Training loss: 4.692659378051758
Validation loss: 4.246209703465944

Epoch: 5| Step: 8
Training loss: 3.2121264934539795
Validation loss: 4.242618560791016

Epoch: 5| Step: 9
Training loss: 3.1095616817474365
Validation loss: 4.234919183997698

Epoch: 5| Step: 10
Training loss: 4.889939785003662
Validation loss: 4.235648155212402

Epoch: 7| Step: 0
Training loss: 3.6718223094940186
Validation loss: 4.2324661644556185

Epoch: 5| Step: 1
Training loss: 4.322760581970215
Validation loss: 4.227798431150375

Epoch: 5| Step: 2
Training loss: 4.951263904571533
Validation loss: 4.22714033690832

Epoch: 5| Step: 3
Training loss: 4.419955253601074
Validation loss: 4.225019008882584

Epoch: 5| Step: 4
Training loss: 3.6802074909210205
Validation loss: 4.221072068778417

Epoch: 5| Step: 5
Training loss: 3.9879562854766846
Validation loss: 4.218508238433509

Epoch: 5| Step: 6
Training loss: 3.9483859539031982
Validation loss: 4.216036196677916

Epoch: 5| Step: 7
Training loss: 3.2489097118377686
Validation loss: 4.211517318602531

Epoch: 5| Step: 8
Training loss: 4.254700660705566
Validation loss: 4.2085132752695396

Epoch: 5| Step: 9
Training loss: 3.9072418212890625
Validation loss: 4.20517470247002

Epoch: 5| Step: 10
Training loss: 4.021690845489502
Validation loss: 4.200757598364225

Epoch: 8| Step: 0
Training loss: 4.079610347747803
Validation loss: 4.194541661970077

Epoch: 5| Step: 1
Training loss: 4.3464765548706055
Validation loss: 4.1926144938315115

Epoch: 5| Step: 2
Training loss: 3.273153781890869
Validation loss: 4.1893861063065065

Epoch: 5| Step: 3
Training loss: 3.957256317138672
Validation loss: 4.189986475052372

Epoch: 5| Step: 4
Training loss: 4.056661128997803
Validation loss: 4.183673030586653

Epoch: 5| Step: 5
Training loss: 4.016711711883545
Validation loss: 4.1816768851331485

Epoch: 5| Step: 6
Training loss: 4.658824920654297
Validation loss: 4.1742584782262

Epoch: 5| Step: 7
Training loss: 4.082073211669922
Validation loss: 4.1732967592054795

Epoch: 5| Step: 8
Training loss: 4.007180213928223
Validation loss: 4.16627287608321

Epoch: 5| Step: 9
Training loss: 4.239752769470215
Validation loss: 4.165443784447127

Epoch: 5| Step: 10
Training loss: 3.2342607975006104
Validation loss: 4.160300772677186

Epoch: 9| Step: 0
Training loss: 4.595440864562988
Validation loss: 4.154460022526402

Epoch: 5| Step: 1
Training loss: 4.623071670532227
Validation loss: 4.153281437453403

Epoch: 5| Step: 2
Training loss: 4.255423069000244
Validation loss: 4.1499283647024505

Epoch: 5| Step: 3
Training loss: 2.7898736000061035
Validation loss: 4.14263710411646

Epoch: 5| Step: 4
Training loss: 4.005274772644043
Validation loss: 4.14127472395538

Epoch: 5| Step: 5
Training loss: 5.166192054748535
Validation loss: 4.136172033125354

Epoch: 5| Step: 6
Training loss: 2.5568089485168457
Validation loss: 4.130235005450505

Epoch: 5| Step: 7
Training loss: 4.3349223136901855
Validation loss: 4.126970860265916

Epoch: 5| Step: 8
Training loss: 3.6650147438049316
Validation loss: 4.120743172143095

Epoch: 5| Step: 9
Training loss: 3.811190128326416
Validation loss: 4.11684847903508

Epoch: 5| Step: 10
Training loss: 3.7884180545806885
Validation loss: 4.116868775377991

Epoch: 10| Step: 0
Training loss: 3.9321601390838623
Validation loss: 4.109045028686523

Epoch: 5| Step: 1
Training loss: 3.6688945293426514
Validation loss: 4.108322138427406

Epoch: 5| Step: 2
Training loss: 3.854823589324951
Validation loss: 4.100531531918433

Epoch: 5| Step: 3
Training loss: 3.651020050048828
Validation loss: 4.097523094505392

Epoch: 5| Step: 4
Training loss: 4.693231105804443
Validation loss: 4.09199402152851

Epoch: 5| Step: 5
Training loss: 4.204485893249512
Validation loss: 4.085596951105261

Epoch: 5| Step: 6
Training loss: 3.294419765472412
Validation loss: 4.081416022393011

Epoch: 5| Step: 7
Training loss: 2.8752849102020264
Validation loss: 4.0770655165436445

Epoch: 5| Step: 8
Training loss: 4.3037824630737305
Validation loss: 4.073477160546087

Epoch: 5| Step: 9
Training loss: 4.58772087097168
Validation loss: 4.066633398814868

Epoch: 5| Step: 10
Training loss: 4.070990562438965
Validation loss: 4.061699810848441

Epoch: 11| Step: 0
Training loss: 4.501765251159668
Validation loss: 4.054971802619196

Epoch: 5| Step: 1
Training loss: 5.272910118103027
Validation loss: 4.051961119456958

Epoch: 5| Step: 2
Training loss: 3.950471878051758
Validation loss: 4.045625704590992

Epoch: 5| Step: 3
Training loss: 4.262110233306885
Validation loss: 4.039228588022212

Epoch: 5| Step: 4
Training loss: 4.819777011871338
Validation loss: 4.032393014559182

Epoch: 5| Step: 5
Training loss: 3.2589144706726074
Validation loss: 4.02905604147142

Epoch: 5| Step: 6
Training loss: 4.1367058753967285
Validation loss: 4.022615127666022

Epoch: 5| Step: 7
Training loss: 3.2002463340759277
Validation loss: 4.019245829633487

Epoch: 5| Step: 8
Training loss: 3.444314956665039
Validation loss: 4.0105916684673675

Epoch: 5| Step: 9
Training loss: 3.3970134258270264
Validation loss: 4.007447560628255

Epoch: 5| Step: 10
Training loss: 2.1213502883911133
Validation loss: 3.9971972947479575

Epoch: 12| Step: 0
Training loss: 4.014817714691162
Validation loss: 3.9921439181091967

Epoch: 5| Step: 1
Training loss: 4.323995113372803
Validation loss: 3.9883882717419694

Epoch: 5| Step: 2
Training loss: 4.269574165344238
Validation loss: 3.9807585823920464

Epoch: 5| Step: 3
Training loss: 3.5890839099884033
Validation loss: 3.972791420516147

Epoch: 5| Step: 4
Training loss: 3.7230217456817627
Validation loss: 3.9682937078578497

Epoch: 5| Step: 5
Training loss: 2.670609712600708
Validation loss: 3.9645295399491505

Epoch: 5| Step: 6
Training loss: 3.677037477493286
Validation loss: 3.953249885189918

Epoch: 5| Step: 7
Training loss: 3.7641196250915527
Validation loss: 3.9533270097547963

Epoch: 5| Step: 8
Training loss: 3.8079981803894043
Validation loss: 3.941783438446701

Epoch: 5| Step: 9
Training loss: 4.2922210693359375
Validation loss: 3.939923963239116

Epoch: 5| Step: 10
Training loss: 3.8636341094970703
Validation loss: 3.9308772804916545

Epoch: 13| Step: 0
Training loss: 4.234437942504883
Validation loss: 3.9200210622561875

Epoch: 5| Step: 1
Training loss: 4.204123020172119
Validation loss: 3.916067108031242

Epoch: 5| Step: 2
Training loss: 4.867761611938477
Validation loss: 3.906279343430714

Epoch: 5| Step: 3
Training loss: 2.767191171646118
Validation loss: 3.8969728562139694

Epoch: 5| Step: 4
Training loss: 2.6083545684814453
Validation loss: 3.8986504001002156

Epoch: 5| Step: 5
Training loss: 4.060445308685303
Validation loss: 3.8845095583187637

Epoch: 5| Step: 6
Training loss: 3.931708812713623
Validation loss: 3.8777145929234003

Epoch: 5| Step: 7
Training loss: 3.6117451190948486
Validation loss: 3.87191960119432

Epoch: 5| Step: 8
Training loss: 3.469250440597534
Validation loss: 3.8641084009601223

Epoch: 5| Step: 9
Training loss: 4.269883155822754
Validation loss: 3.8515221175327095

Epoch: 5| Step: 10
Training loss: 3.1698689460754395
Validation loss: 3.842265708472139

Epoch: 14| Step: 0
Training loss: 4.387718677520752
Validation loss: 3.840955303561303

Epoch: 5| Step: 1
Training loss: 2.4548001289367676
Validation loss: 3.8306002027244976

Epoch: 5| Step: 2
Training loss: 3.7308382987976074
Validation loss: 3.818613093386414

Epoch: 5| Step: 3
Training loss: 3.578063488006592
Validation loss: 3.814244649743521

Epoch: 5| Step: 4
Training loss: 3.7564361095428467
Validation loss: 3.8047092447998705

Epoch: 5| Step: 5
Training loss: 4.275083541870117
Validation loss: 3.793519550754178

Epoch: 5| Step: 6
Training loss: 4.473249912261963
Validation loss: 3.7896654990411576

Epoch: 5| Step: 7
Training loss: 3.133739948272705
Validation loss: 3.7853406654891146

Epoch: 5| Step: 8
Training loss: 2.6213815212249756
Validation loss: 3.7752334892108874

Epoch: 5| Step: 9
Training loss: 4.852912425994873
Validation loss: 3.760645056283602

Epoch: 5| Step: 10
Training loss: 3.0921578407287598
Validation loss: 3.750120629546463

Epoch: 15| Step: 0
Training loss: 3.3667328357696533
Validation loss: 3.745914310537359

Epoch: 5| Step: 1
Training loss: 3.5775275230407715
Validation loss: 3.7437886115043395

Epoch: 5| Step: 2
Training loss: 3.8579418659210205
Validation loss: 3.7339098325339695

Epoch: 5| Step: 3
Training loss: 3.270720958709717
Validation loss: 3.720283762101204

Epoch: 5| Step: 4
Training loss: 3.9313995838165283
Validation loss: 3.7139221006824124

Epoch: 5| Step: 5
Training loss: 3.7158408164978027
Validation loss: 3.6995902958736626

Epoch: 5| Step: 6
Training loss: 4.296422958374023
Validation loss: 3.6929225101265857

Epoch: 5| Step: 7
Training loss: 2.8415842056274414
Validation loss: 3.679555659653038

Epoch: 5| Step: 8
Training loss: 2.6371641159057617
Validation loss: 3.6765235213823217

Epoch: 5| Step: 9
Training loss: 4.019835948944092
Validation loss: 3.6696614860206522

Epoch: 5| Step: 10
Training loss: 4.05992317199707
Validation loss: 3.655505400831981

Epoch: 16| Step: 0
Training loss: 3.9924445152282715
Validation loss: 3.642520796868109

Epoch: 5| Step: 1
Training loss: 3.7356719970703125
Validation loss: 3.636341805099159

Epoch: 5| Step: 2
Training loss: 4.056262493133545
Validation loss: 3.6237983242157967

Epoch: 5| Step: 3
Training loss: 4.369276523590088
Validation loss: 3.614168679842385

Epoch: 5| Step: 4
Training loss: 3.0488619804382324
Validation loss: 3.6007668177286782

Epoch: 5| Step: 5
Training loss: 3.3035988807678223
Validation loss: 3.591128969705233

Epoch: 5| Step: 6
Training loss: 2.277299165725708
Validation loss: 3.5814931572124524

Epoch: 5| Step: 7
Training loss: 2.789762258529663
Validation loss: 3.5695535162443757

Epoch: 5| Step: 8
Training loss: 3.528212308883667
Validation loss: 3.5591141408489597

Epoch: 5| Step: 9
Training loss: 3.4248931407928467
Validation loss: 3.5438248418992564

Epoch: 5| Step: 10
Training loss: 4.014193534851074
Validation loss: 3.5294155510522986

Epoch: 17| Step: 0
Training loss: 4.161801338195801
Validation loss: 3.523803534046296

Epoch: 5| Step: 1
Training loss: 3.65937876701355
Validation loss: 3.5132016315255115

Epoch: 5| Step: 2
Training loss: 3.6608898639678955
Validation loss: 3.502317443970711

Epoch: 5| Step: 3
Training loss: 3.645455837249756
Validation loss: 3.4863590091787358

Epoch: 5| Step: 4
Training loss: 3.3186874389648438
Validation loss: 3.4688164803289596

Epoch: 5| Step: 5
Training loss: 3.094238758087158
Validation loss: 3.4586053176592757

Epoch: 5| Step: 6
Training loss: 2.3738296031951904
Validation loss: 3.448930489119663

Epoch: 5| Step: 7
Training loss: 3.531323194503784
Validation loss: 3.4312499928218063

Epoch: 5| Step: 8
Training loss: 3.36796498298645
Validation loss: 3.423484153645013

Epoch: 5| Step: 9
Training loss: 3.282519578933716
Validation loss: 3.4121952646522113

Epoch: 5| Step: 10
Training loss: 3.1284866333007812
Validation loss: 3.385830907411473

Epoch: 18| Step: 0
Training loss: 3.783998966217041
Validation loss: 3.372598930071759

Epoch: 5| Step: 1
Training loss: 2.4957492351531982
Validation loss: 3.3508645590915473

Epoch: 5| Step: 2
Training loss: 3.8573012351989746
Validation loss: 3.3518760614497687

Epoch: 5| Step: 3
Training loss: 2.2197511196136475
Validation loss: 3.329173195746637

Epoch: 5| Step: 4
Training loss: 3.333949565887451
Validation loss: 3.3142505614988265

Epoch: 5| Step: 5
Training loss: 2.390113353729248
Validation loss: 3.313274665545392

Epoch: 5| Step: 6
Training loss: 3.972240447998047
Validation loss: 3.287228820144489

Epoch: 5| Step: 7
Training loss: 3.635572910308838
Validation loss: 3.2694411662317093

Epoch: 5| Step: 8
Training loss: 3.626070499420166
Validation loss: 3.263306256263487

Epoch: 5| Step: 9
Training loss: 3.026214122772217
Validation loss: 3.2407047184564735

Epoch: 5| Step: 10
Training loss: 3.538766860961914
Validation loss: 3.226389044074602

Epoch: 19| Step: 0
Training loss: 2.85689377784729
Validation loss: 3.2032655618524037

Epoch: 5| Step: 1
Training loss: 3.1140103340148926
Validation loss: 3.1820951559210338

Epoch: 5| Step: 2
Training loss: 2.1888229846954346
Validation loss: 3.18105322827575

Epoch: 5| Step: 3
Training loss: 3.264921188354492
Validation loss: 3.153664719673895

Epoch: 5| Step: 4
Training loss: 3.4397010803222656
Validation loss: 3.1450610519737325

Epoch: 5| Step: 5
Training loss: 3.8957858085632324
Validation loss: 3.1116761238344255

Epoch: 5| Step: 6
Training loss: 3.434617519378662
Validation loss: 3.103871868502709

Epoch: 5| Step: 7
Training loss: 3.1346471309661865
Validation loss: 3.0973640744404127

Epoch: 5| Step: 8
Training loss: 3.192173957824707
Validation loss: 3.0707938568566435

Epoch: 5| Step: 9
Training loss: 2.861053466796875
Validation loss: 3.0667797083495767

Epoch: 5| Step: 10
Training loss: 2.916139602661133
Validation loss: 3.054275046112717

Epoch: 20| Step: 0
Training loss: 3.131667375564575
Validation loss: 3.0129973273123465

Epoch: 5| Step: 1
Training loss: 3.4947166442871094
Validation loss: 3.0074920090295936

Epoch: 5| Step: 2
Training loss: 2.668306827545166
Validation loss: 2.9763014649832122

Epoch: 5| Step: 3
Training loss: 2.512899875640869
Validation loss: 2.9711217111156834

Epoch: 5| Step: 4
Training loss: 3.0737051963806152
Validation loss: 2.954199088517056

Epoch: 5| Step: 5
Training loss: 2.5437002182006836
Validation loss: 2.948243510338568

Epoch: 5| Step: 6
Training loss: 3.1259946823120117
Validation loss: 2.9162655440709924

Epoch: 5| Step: 7
Training loss: 2.7974891662597656
Validation loss: 2.907491394268569

Epoch: 5| Step: 8
Training loss: 3.1131415367126465
Validation loss: 2.883504565044116

Epoch: 5| Step: 9
Training loss: 2.9068737030029297
Validation loss: 2.8699131114508516

Epoch: 5| Step: 10
Training loss: 3.442063093185425
Validation loss: 2.874730815169632

Epoch: 21| Step: 0
Training loss: 2.7680790424346924
Validation loss: 2.836611447795745

Epoch: 5| Step: 1
Training loss: 2.3719799518585205
Validation loss: 2.8236373675766813

Epoch: 5| Step: 2
Training loss: 3.129387378692627
Validation loss: 2.806395241009292

Epoch: 5| Step: 3
Training loss: 2.6046414375305176
Validation loss: 2.7921245790296987

Epoch: 5| Step: 4
Training loss: 3.0588583946228027
Validation loss: 2.7721110261896604

Epoch: 5| Step: 5
Training loss: 3.279759168624878
Validation loss: 2.7726042321933213

Epoch: 5| Step: 6
Training loss: 2.3048956394195557
Validation loss: 2.714196438430458

Epoch: 5| Step: 7
Training loss: 3.9331493377685547
Validation loss: 2.7203797986430507

Epoch: 5| Step: 8
Training loss: 2.1932082176208496
Validation loss: 2.721210974518971

Epoch: 5| Step: 9
Training loss: 3.145355701446533
Validation loss: 2.6919017914802796

Epoch: 5| Step: 10
Training loss: 2.7428386211395264
Validation loss: 2.666669063670661

Epoch: 22| Step: 0
Training loss: 2.6079366207122803
Validation loss: 2.669130845736432

Epoch: 5| Step: 1
Training loss: 2.6760876178741455
Validation loss: 2.645931310551141

Epoch: 5| Step: 2
Training loss: 2.6763641834259033
Validation loss: 2.6149745679670766

Epoch: 5| Step: 3
Training loss: 2.84183406829834
Validation loss: 2.583564535264046

Epoch: 5| Step: 4
Training loss: 2.5950074195861816
Validation loss: 2.5991554414072344

Epoch: 5| Step: 5
Training loss: 2.6123037338256836
Validation loss: 2.6115884498883317

Epoch: 5| Step: 6
Training loss: 3.094770908355713
Validation loss: 2.561151853171728

Epoch: 5| Step: 7
Training loss: 2.429267168045044
Validation loss: 2.5458277194730696

Epoch: 5| Step: 8
Training loss: 2.8077335357666016
Validation loss: 2.5362725744965258

Epoch: 5| Step: 9
Training loss: 2.8871231079101562
Validation loss: 2.52597019749303

Epoch: 5| Step: 10
Training loss: 3.318119764328003
Validation loss: 2.493937466734199

Epoch: 23| Step: 0
Training loss: 2.6399776935577393
Validation loss: 2.480593378825854

Epoch: 5| Step: 1
Training loss: 2.276261329650879
Validation loss: 2.4471233942175425

Epoch: 5| Step: 2
Training loss: 2.6196329593658447
Validation loss: 2.4391939716954387

Epoch: 5| Step: 3
Training loss: 2.6722099781036377
Validation loss: 2.438271366139894

Epoch: 5| Step: 4
Training loss: 2.4554896354675293
Validation loss: 2.424453245696201

Epoch: 5| Step: 5
Training loss: 2.854508399963379
Validation loss: 2.409773529216807

Epoch: 5| Step: 6
Training loss: 2.3864803314208984
Validation loss: 2.387281505010461

Epoch: 5| Step: 7
Training loss: 3.077765703201294
Validation loss: 2.4092755343324397

Epoch: 5| Step: 8
Training loss: 2.974457263946533
Validation loss: 2.3765952151308776

Epoch: 5| Step: 9
Training loss: 2.7240712642669678
Validation loss: 2.356454946661508

Epoch: 5| Step: 10
Training loss: 2.4704575538635254
Validation loss: 2.3574747962336384

Epoch: 24| Step: 0
Training loss: 2.7492260932922363
Validation loss: 2.3235208911280476

Epoch: 5| Step: 1
Training loss: 2.4070305824279785
Validation loss: 2.32668625667531

Epoch: 5| Step: 2
Training loss: 2.0978024005889893
Validation loss: 2.307619310194446

Epoch: 5| Step: 3
Training loss: 2.827126979827881
Validation loss: 2.31357043532915

Epoch: 5| Step: 4
Training loss: 3.558525800704956
Validation loss: 2.303106560502001

Epoch: 5| Step: 5
Training loss: 2.052877187728882
Validation loss: 2.278050373959285

Epoch: 5| Step: 6
Training loss: 2.7247211933135986
Validation loss: 2.2913617241767144

Epoch: 5| Step: 7
Training loss: 1.886183500289917
Validation loss: 2.2787024897913777

Epoch: 5| Step: 8
Training loss: 2.577362060546875
Validation loss: 2.243536255692923

Epoch: 5| Step: 9
Training loss: 2.5307300090789795
Validation loss: 2.2592135911346762

Epoch: 5| Step: 10
Training loss: 2.7684404850006104
Validation loss: 2.275099928661059

Epoch: 25| Step: 0
Training loss: 1.955124855041504
Validation loss: 2.238421706743138

Epoch: 5| Step: 1
Training loss: 3.1295669078826904
Validation loss: 2.2252121740771877

Epoch: 5| Step: 2
Training loss: 2.4819724559783936
Validation loss: 2.2457099550513813

Epoch: 5| Step: 3
Training loss: 2.8506855964660645
Validation loss: 2.202747283443328

Epoch: 5| Step: 4
Training loss: 3.026484727859497
Validation loss: 2.2027892681860153

Epoch: 5| Step: 5
Training loss: 1.9475539922714233
Validation loss: 2.2064369263187533

Epoch: 5| Step: 6
Training loss: 2.8150181770324707
Validation loss: 2.19324254861442

Epoch: 5| Step: 7
Training loss: 2.2852654457092285
Validation loss: 2.1938085376575427

Epoch: 5| Step: 8
Training loss: 2.033316135406494
Validation loss: 2.1936108732736237

Epoch: 5| Step: 9
Training loss: 2.7747888565063477
Validation loss: 2.203722680768659

Epoch: 5| Step: 10
Training loss: 2.3958723545074463
Validation loss: 2.155168197488272

Epoch: 26| Step: 0
Training loss: 2.838338851928711
Validation loss: 2.1579754839661303

Epoch: 5| Step: 1
Training loss: 2.7205300331115723
Validation loss: 2.1555423762208674

Epoch: 5| Step: 2
Training loss: 2.2942466735839844
Validation loss: 2.1916388337330153

Epoch: 5| Step: 3
Training loss: 2.539724588394165
Validation loss: 2.170511899455901

Epoch: 5| Step: 4
Training loss: 2.3330812454223633
Validation loss: 2.145251143363214

Epoch: 5| Step: 5
Training loss: 2.2393250465393066
Validation loss: 2.13286881549384

Epoch: 5| Step: 6
Training loss: 2.837470293045044
Validation loss: 2.153200739173479

Epoch: 5| Step: 7
Training loss: 2.171142101287842
Validation loss: 2.1434689337207424

Epoch: 5| Step: 8
Training loss: 1.9826393127441406
Validation loss: 2.15744032654711

Epoch: 5| Step: 9
Training loss: 3.1166141033172607
Validation loss: 2.132139636624244

Epoch: 5| Step: 10
Training loss: 2.328291177749634
Validation loss: 2.1209471251374934

Epoch: 27| Step: 0
Training loss: 2.962172746658325
Validation loss: 2.112764189320226

Epoch: 5| Step: 1
Training loss: 1.9104589223861694
Validation loss: 2.131609527013635

Epoch: 5| Step: 2
Training loss: 2.6401703357696533
Validation loss: 2.1591114818408923

Epoch: 5| Step: 3
Training loss: 3.2067275047302246
Validation loss: 2.1430010129046697

Epoch: 5| Step: 4
Training loss: 2.4810376167297363
Validation loss: 2.1336248382445304

Epoch: 5| Step: 5
Training loss: 2.225006580352783
Validation loss: 2.089428917054207

Epoch: 5| Step: 6
Training loss: 2.0428199768066406
Validation loss: 2.142251281328099

Epoch: 5| Step: 7
Training loss: 2.0425760746002197
Validation loss: 2.1545855781083465

Epoch: 5| Step: 8
Training loss: 2.9490153789520264
Validation loss: 2.1236126807428177

Epoch: 5| Step: 9
Training loss: 1.9799009561538696
Validation loss: 2.129955486584735

Epoch: 5| Step: 10
Training loss: 2.6863133907318115
Validation loss: 2.109022528894486

Epoch: 28| Step: 0
Training loss: 2.392862558364868
Validation loss: 2.1198722675282466

Epoch: 5| Step: 1
Training loss: 2.771169662475586
Validation loss: 2.0914288182412424

Epoch: 5| Step: 2
Training loss: 2.255272388458252
Validation loss: 2.10095989319586

Epoch: 5| Step: 3
Training loss: 2.0383598804473877
Validation loss: 2.0777229442391345

Epoch: 5| Step: 4
Training loss: 2.051663875579834
Validation loss: 2.0921286177891556

Epoch: 5| Step: 5
Training loss: 2.3496768474578857
Validation loss: 2.1031418295316797

Epoch: 5| Step: 6
Training loss: 2.9221439361572266
Validation loss: 2.1107802775598343

Epoch: 5| Step: 7
Training loss: 2.8120484352111816
Validation loss: 2.1169175999138945

Epoch: 5| Step: 8
Training loss: 2.6278862953186035
Validation loss: 2.0978970912195023

Epoch: 5| Step: 9
Training loss: 2.417384386062622
Validation loss: 2.1064820161429783

Epoch: 5| Step: 10
Training loss: 2.663041830062866
Validation loss: 2.082464307867071

Epoch: 29| Step: 0
Training loss: 2.813063383102417
Validation loss: 2.110105247907741

Epoch: 5| Step: 1
Training loss: 2.089280843734741
Validation loss: 2.062553995399065

Epoch: 5| Step: 2
Training loss: 2.162125825881958
Validation loss: 2.0633906638750465

Epoch: 5| Step: 3
Training loss: 2.7069873809814453
Validation loss: 2.097180986917147

Epoch: 5| Step: 4
Training loss: 2.653110980987549
Validation loss: 2.0811141062808294

Epoch: 5| Step: 5
Training loss: 2.8086485862731934
Validation loss: 2.088846755284135

Epoch: 5| Step: 6
Training loss: 2.435608386993408
Validation loss: 2.095128902824976

Epoch: 5| Step: 7
Training loss: 2.345768451690674
Validation loss: 2.0903675376728015

Epoch: 5| Step: 8
Training loss: 2.5689468383789062
Validation loss: 2.0903613131533385

Epoch: 5| Step: 9
Training loss: 2.709188938140869
Validation loss: 2.086335748754522

Epoch: 5| Step: 10
Training loss: 1.9621063470840454
Validation loss: 2.0942685091367332

Epoch: 30| Step: 0
Training loss: 2.31048321723938
Validation loss: 2.116026347683322

Epoch: 5| Step: 1
Training loss: 2.656926155090332
Validation loss: 2.089489757373769

Epoch: 5| Step: 2
Training loss: 2.117933750152588
Validation loss: 2.0953091062525266

Epoch: 5| Step: 3
Training loss: 2.814744472503662
Validation loss: 2.1069686681993547

Epoch: 5| Step: 4
Training loss: 2.747098207473755
Validation loss: 2.0892420455973637

Epoch: 5| Step: 5
Training loss: 2.5893967151641846
Validation loss: 2.1221133047534573

Epoch: 5| Step: 6
Training loss: 2.3719863891601562
Validation loss: 2.0795382094639603

Epoch: 5| Step: 7
Training loss: 1.9985653162002563
Validation loss: 2.094857700409428

Epoch: 5| Step: 8
Training loss: 2.4505486488342285
Validation loss: 2.0770214526884017

Epoch: 5| Step: 9
Training loss: 2.5548923015594482
Validation loss: 2.091101852796411

Epoch: 5| Step: 10
Training loss: 2.464824914932251
Validation loss: 2.104293643787343

Epoch: 31| Step: 0
Training loss: 2.717226505279541
Validation loss: 2.1098071054745744

Epoch: 5| Step: 1
Training loss: 2.367936849594116
Validation loss: 2.0768616378948255

Epoch: 5| Step: 2
Training loss: 1.8707778453826904
Validation loss: 2.098045159411687

Epoch: 5| Step: 3
Training loss: 2.737166404724121
Validation loss: 2.1313450797911613

Epoch: 5| Step: 4
Training loss: 2.528404951095581
Validation loss: 2.0883945239487516

Epoch: 5| Step: 5
Training loss: 2.4069509506225586
Validation loss: 2.1041914468170493

Epoch: 5| Step: 6
Training loss: 2.2396817207336426
Validation loss: 2.0883709012821154

Epoch: 5| Step: 7
Training loss: 2.4575393199920654
Validation loss: 2.0832261770002303

Epoch: 5| Step: 8
Training loss: 2.7653679847717285
Validation loss: 2.075860061953145

Epoch: 5| Step: 9
Training loss: 2.5165348052978516
Validation loss: 2.0666058806962866

Epoch: 5| Step: 10
Training loss: 2.3092548847198486
Validation loss: 2.0983195279234197

Epoch: 32| Step: 0
Training loss: 2.080378770828247
Validation loss: 2.1062040457161526

Epoch: 5| Step: 1
Training loss: 2.133457660675049
Validation loss: 2.0649841882849254

Epoch: 5| Step: 2
Training loss: 2.3626656532287598
Validation loss: 2.101053768588651

Epoch: 5| Step: 3
Training loss: 2.2865474224090576
Validation loss: 2.083366750389017

Epoch: 5| Step: 4
Training loss: 2.3709919452667236
Validation loss: 2.070859811639273

Epoch: 5| Step: 5
Training loss: 2.2773849964141846
Validation loss: 2.0807735766133955

Epoch: 5| Step: 6
Training loss: 2.8966400623321533
Validation loss: 2.1197078176724014

Epoch: 5| Step: 7
Training loss: 2.7244856357574463
Validation loss: 2.110633454015178

Epoch: 5| Step: 8
Training loss: 2.808523416519165
Validation loss: 2.065678963097193

Epoch: 5| Step: 9
Training loss: 2.4843814373016357
Validation loss: 2.120905758232199

Epoch: 5| Step: 10
Training loss: 2.6966943740844727
Validation loss: 2.0604805856622677

Epoch: 33| Step: 0
Training loss: 2.622742176055908
Validation loss: 2.1034072394012124

Epoch: 5| Step: 1
Training loss: 2.046424388885498
Validation loss: 2.0890053318392847

Epoch: 5| Step: 2
Training loss: 2.7983436584472656
Validation loss: 2.068758555637893

Epoch: 5| Step: 3
Training loss: 2.123669147491455
Validation loss: 2.092678766096792

Epoch: 5| Step: 4
Training loss: 2.1985056400299072
Validation loss: 2.0643747455330304

Epoch: 5| Step: 5
Training loss: 2.1640267372131348
Validation loss: 2.0952103650698097

Epoch: 5| Step: 6
Training loss: 2.04937481880188
Validation loss: 2.0779143251398557

Epoch: 5| Step: 7
Training loss: 3.028137683868408
Validation loss: 2.08485605127068

Epoch: 5| Step: 8
Training loss: 2.725888729095459
Validation loss: 2.1104755734884613

Epoch: 5| Step: 9
Training loss: 2.8092849254608154
Validation loss: 2.095133291777744

Epoch: 5| Step: 10
Training loss: 2.2957403659820557
Validation loss: 2.086304595393519

Epoch: 34| Step: 0
Training loss: 2.37393856048584
Validation loss: 2.10180902224715

Epoch: 5| Step: 1
Training loss: 2.72196888923645
Validation loss: 2.096006506232805

Epoch: 5| Step: 2
Training loss: 2.1255133152008057
Validation loss: 2.058218066410352

Epoch: 5| Step: 3
Training loss: 2.930551052093506
Validation loss: 2.0661889788925007

Epoch: 5| Step: 4
Training loss: 2.0495662689208984
Validation loss: 2.1115804128749396

Epoch: 5| Step: 5
Training loss: 2.3473143577575684
Validation loss: 2.101145484114206

Epoch: 5| Step: 6
Training loss: 2.5088741779327393
Validation loss: 2.0904167326547767

Epoch: 5| Step: 7
Training loss: 2.0601751804351807
Validation loss: 2.087783266139287

Epoch: 5| Step: 8
Training loss: 2.441607713699341
Validation loss: 2.088997710135675

Epoch: 5| Step: 9
Training loss: 2.384439468383789
Validation loss: 2.0804629338684903

Epoch: 5| Step: 10
Training loss: 2.7873432636260986
Validation loss: 2.086906019077506

Epoch: 35| Step: 0
Training loss: 2.9974875450134277
Validation loss: 2.0659487350012666

Epoch: 5| Step: 1
Training loss: 1.796075463294983
Validation loss: 2.1293074905231433

Epoch: 5| Step: 2
Training loss: 2.2806687355041504
Validation loss: 2.0859534637902373

Epoch: 5| Step: 3
Training loss: 2.5256173610687256
Validation loss: 2.0735931665666643

Epoch: 5| Step: 4
Training loss: 2.3888680934906006
Validation loss: 2.092614931444968

Epoch: 5| Step: 5
Training loss: 2.27860689163208
Validation loss: 2.0820655117752733

Epoch: 5| Step: 6
Training loss: 2.484433650970459
Validation loss: 2.0850057499383086

Epoch: 5| Step: 7
Training loss: 2.321767807006836
Validation loss: 2.1007290783748833

Epoch: 5| Step: 8
Training loss: 2.8260891437530518
Validation loss: 2.0912372783948014

Epoch: 5| Step: 9
Training loss: 2.4055895805358887
Validation loss: 2.083461025709747

Epoch: 5| Step: 10
Training loss: 2.730901002883911
Validation loss: 2.0581152977481967

Epoch: 36| Step: 0
Training loss: 2.1770710945129395
Validation loss: 2.067629527020198

Epoch: 5| Step: 1
Training loss: 2.1499204635620117
Validation loss: 2.1099940499951764

Epoch: 5| Step: 2
Training loss: 2.804439067840576
Validation loss: 2.066146453221639

Epoch: 5| Step: 3
Training loss: 1.867600440979004
Validation loss: 2.0911281595947924

Epoch: 5| Step: 4
Training loss: 2.7258753776550293
Validation loss: 2.093660572523712

Epoch: 5| Step: 5
Training loss: 2.191544771194458
Validation loss: 2.0664249209947485

Epoch: 5| Step: 6
Training loss: 2.536175489425659
Validation loss: 2.0928194702312513

Epoch: 5| Step: 7
Training loss: 2.844597816467285
Validation loss: 2.127573549106557

Epoch: 5| Step: 8
Training loss: 2.1287879943847656
Validation loss: 2.085910217736357

Epoch: 5| Step: 9
Training loss: 2.5580894947052
Validation loss: 2.081272672581416

Epoch: 5| Step: 10
Training loss: 2.7234325408935547
Validation loss: 2.093022536205989

Epoch: 37| Step: 0
Training loss: 2.965064525604248
Validation loss: 2.0968524563697075

Epoch: 5| Step: 1
Training loss: 2.369108200073242
Validation loss: 2.105186294483882

Epoch: 5| Step: 2
Training loss: 3.660640001296997
Validation loss: 2.1107012482099634

Epoch: 5| Step: 3
Training loss: 1.4802430868148804
Validation loss: 2.0944722288398334

Epoch: 5| Step: 4
Training loss: 1.9525591135025024
Validation loss: 2.0844664830033497

Epoch: 5| Step: 5
Training loss: 2.484510898590088
Validation loss: 2.087305489406791

Epoch: 5| Step: 6
Training loss: 2.67252779006958
Validation loss: 2.098863934957853

Epoch: 5| Step: 7
Training loss: 2.1101772785186768
Validation loss: 2.089208584959789

Epoch: 5| Step: 8
Training loss: 2.2891719341278076
Validation loss: 2.1210147770502235

Epoch: 5| Step: 9
Training loss: 2.8344595432281494
Validation loss: 2.0971217770730295

Epoch: 5| Step: 10
Training loss: 1.7157560586929321
Validation loss: 2.0685138010209605

Epoch: 38| Step: 0
Training loss: 2.0909276008605957
Validation loss: 2.08723194624788

Epoch: 5| Step: 1
Training loss: 2.2202837467193604
Validation loss: 2.079891476579892

Epoch: 5| Step: 2
Training loss: 2.2839865684509277
Validation loss: 2.0728558648017144

Epoch: 5| Step: 3
Training loss: 2.4825408458709717
Validation loss: 2.08286359489605

Epoch: 5| Step: 4
Training loss: 2.1075797080993652
Validation loss: 2.071790627253953

Epoch: 5| Step: 5
Training loss: 2.183067560195923
Validation loss: 2.0751552325423046

Epoch: 5| Step: 6
Training loss: 2.514631509780884
Validation loss: 2.059126538615073

Epoch: 5| Step: 7
Training loss: 3.103985071182251
Validation loss: 2.0724535693404493

Epoch: 5| Step: 8
Training loss: 2.562668561935425
Validation loss: 2.078298648198446

Epoch: 5| Step: 9
Training loss: 2.3968403339385986
Validation loss: 2.0965011017296904

Epoch: 5| Step: 10
Training loss: 2.628725051879883
Validation loss: 2.0513957059511574

Epoch: 39| Step: 0
Training loss: 2.4025802612304688
Validation loss: 2.08540012503183

Epoch: 5| Step: 1
Training loss: 2.8619110584259033
Validation loss: 2.080072458072375

Epoch: 5| Step: 2
Training loss: 2.334463357925415
Validation loss: 2.0697716769351753

Epoch: 5| Step: 3
Training loss: 2.2538654804229736
Validation loss: 2.0503126767373856

Epoch: 5| Step: 4
Training loss: 2.4722766876220703
Validation loss: 2.057244323915051

Epoch: 5| Step: 5
Training loss: 2.778085708618164
Validation loss: 2.0791859934406896

Epoch: 5| Step: 6
Training loss: 2.58341383934021
Validation loss: 2.077871855869088

Epoch: 5| Step: 7
Training loss: 2.069885015487671
Validation loss: 2.0715345362181306

Epoch: 5| Step: 8
Training loss: 2.4822540283203125
Validation loss: 2.06160238481337

Epoch: 5| Step: 9
Training loss: 2.4064037799835205
Validation loss: 2.0464829244921283

Epoch: 5| Step: 10
Training loss: 1.939977765083313
Validation loss: 2.0825373229160102

Epoch: 40| Step: 0
Training loss: 2.523484468460083
Validation loss: 2.0598182703859065

Epoch: 5| Step: 1
Training loss: 2.6311068534851074
Validation loss: 2.016996446476188

Epoch: 5| Step: 2
Training loss: 2.2935593128204346
Validation loss: 2.072369953637482

Epoch: 5| Step: 3
Training loss: 2.6016266345977783
Validation loss: 2.067068488367142

Epoch: 5| Step: 4
Training loss: 2.141510486602783
Validation loss: 2.0410728685317503

Epoch: 5| Step: 5
Training loss: 2.083651065826416
Validation loss: 2.092209251978064

Epoch: 5| Step: 6
Training loss: 2.591937780380249
Validation loss: 2.0733289334081833

Epoch: 5| Step: 7
Training loss: 2.51811146736145
Validation loss: 2.0573713189812115

Epoch: 5| Step: 8
Training loss: 2.1792569160461426
Validation loss: 2.0762068174218618

Epoch: 5| Step: 9
Training loss: 2.514604330062866
Validation loss: 2.0487639134930027

Epoch: 5| Step: 10
Training loss: 2.2341270446777344
Validation loss: 2.0510838493224113

Epoch: 41| Step: 0
Training loss: 2.3920657634735107
Validation loss: 2.060270913185612

Epoch: 5| Step: 1
Training loss: 2.396350383758545
Validation loss: 2.0812850459929435

Epoch: 5| Step: 2
Training loss: 2.648451328277588
Validation loss: 2.0690022822349303

Epoch: 5| Step: 3
Training loss: 2.9472479820251465
Validation loss: 2.068107472952976

Epoch: 5| Step: 4
Training loss: 1.943246603012085
Validation loss: 2.045607087432697

Epoch: 5| Step: 5
Training loss: 2.7851767539978027
Validation loss: 2.05381973584493

Epoch: 5| Step: 6
Training loss: 2.557079553604126
Validation loss: 2.0652977997256863

Epoch: 5| Step: 7
Training loss: 1.65277099609375
Validation loss: 2.047220480057501

Epoch: 5| Step: 8
Training loss: 2.489070177078247
Validation loss: 2.087366578399494

Epoch: 5| Step: 9
Training loss: 2.269911289215088
Validation loss: 2.073326059567031

Epoch: 5| Step: 10
Training loss: 2.704047918319702
Validation loss: 2.0551806367853636

Epoch: 42| Step: 0
Training loss: 2.7930774688720703
Validation loss: 2.068106430833058

Epoch: 5| Step: 1
Training loss: 3.046238899230957
Validation loss: 2.0679155703513854

Epoch: 5| Step: 2
Training loss: 2.5163540840148926
Validation loss: 2.0655220580357376

Epoch: 5| Step: 3
Training loss: 1.931016206741333
Validation loss: 2.0790816404486216

Epoch: 5| Step: 4
Training loss: 1.7597312927246094
Validation loss: 2.068097094053863

Epoch: 5| Step: 5
Training loss: 2.207653760910034
Validation loss: 2.0232417621920185

Epoch: 5| Step: 6
Training loss: 2.2615199089050293
Validation loss: 2.074326543397801

Epoch: 5| Step: 7
Training loss: 2.779144763946533
Validation loss: 2.0566052083046205

Epoch: 5| Step: 8
Training loss: 2.1375174522399902
Validation loss: 2.099450627321838

Epoch: 5| Step: 9
Training loss: 2.6559624671936035
Validation loss: 2.072006602441111

Epoch: 5| Step: 10
Training loss: 2.4378550052642822
Validation loss: 2.075561108127717

Epoch: 43| Step: 0
Training loss: 2.1405322551727295
Validation loss: 2.066622431560229

Epoch: 5| Step: 1
Training loss: 2.8398773670196533
Validation loss: 2.056820491308807

Epoch: 5| Step: 2
Training loss: 2.4111557006835938
Validation loss: 2.077805511413082

Epoch: 5| Step: 3
Training loss: 2.4741246700286865
Validation loss: 2.056908030663767

Epoch: 5| Step: 4
Training loss: 2.8934593200683594
Validation loss: 2.0860483582301805

Epoch: 5| Step: 5
Training loss: 2.0317115783691406
Validation loss: 2.088356856376894

Epoch: 5| Step: 6
Training loss: 2.5013415813446045
Validation loss: 2.085340440914195

Epoch: 5| Step: 7
Training loss: 1.8554954528808594
Validation loss: 2.059581087481591

Epoch: 5| Step: 8
Training loss: 3.337270736694336
Validation loss: 2.065580598769649

Epoch: 5| Step: 9
Training loss: 2.2624545097351074
Validation loss: 2.0421610057994886

Epoch: 5| Step: 10
Training loss: 1.6637468338012695
Validation loss: 2.072792263441188

Epoch: 44| Step: 0
Training loss: 2.6638240814208984
Validation loss: 2.058183054770193

Epoch: 5| Step: 1
Training loss: 2.1375985145568848
Validation loss: 2.055331378854731

Epoch: 5| Step: 2
Training loss: 2.3206324577331543
Validation loss: 2.0715032521114556

Epoch: 5| Step: 3
Training loss: 2.523341417312622
Validation loss: 2.0630444762527302

Epoch: 5| Step: 4
Training loss: 2.701012372970581
Validation loss: 2.0794165301066574

Epoch: 5| Step: 5
Training loss: 2.219208240509033
Validation loss: 2.0325300103874615

Epoch: 5| Step: 6
Training loss: 2.906928777694702
Validation loss: 2.028452270774431

Epoch: 5| Step: 7
Training loss: 1.970160722732544
Validation loss: 2.062926866674936

Epoch: 5| Step: 8
Training loss: 2.5221285820007324
Validation loss: 2.078852488148597

Epoch: 5| Step: 9
Training loss: 2.818941593170166
Validation loss: 2.077771458574521

Epoch: 5| Step: 10
Training loss: 1.779600977897644
Validation loss: 2.0478583651204265

Epoch: 45| Step: 0
Training loss: 2.2205333709716797
Validation loss: 2.046268082434131

Epoch: 5| Step: 1
Training loss: 2.1068077087402344
Validation loss: 2.067076595880652

Epoch: 5| Step: 2
Training loss: 2.2448997497558594
Validation loss: 2.0604921630633775

Epoch: 5| Step: 3
Training loss: 2.52736234664917
Validation loss: 2.0684473232556413

Epoch: 5| Step: 4
Training loss: 3.050179958343506
Validation loss: 2.062298197900095

Epoch: 5| Step: 5
Training loss: 2.4437859058380127
Validation loss: 2.0626823017674107

Epoch: 5| Step: 6
Training loss: 2.52974009513855
Validation loss: 2.0624481734409126

Epoch: 5| Step: 7
Training loss: 2.4360103607177734
Validation loss: 2.0819667231652046

Epoch: 5| Step: 8
Training loss: 1.9663854837417603
Validation loss: 2.0389699295002925

Epoch: 5| Step: 9
Training loss: 2.321542501449585
Validation loss: 2.0562798823079755

Epoch: 5| Step: 10
Training loss: 2.3345558643341064
Validation loss: 2.0676550378081617

Epoch: 46| Step: 0
Training loss: 2.52335786819458
Validation loss: 2.0557026863098145

Epoch: 5| Step: 1
Training loss: 1.6817550659179688
Validation loss: 2.0534131193673737

Epoch: 5| Step: 2
Training loss: 2.796870470046997
Validation loss: 2.0544004863308323

Epoch: 5| Step: 3
Training loss: 1.8734718561172485
Validation loss: 2.047997569525114

Epoch: 5| Step: 4
Training loss: 2.487339496612549
Validation loss: 2.0315105812523955

Epoch: 5| Step: 5
Training loss: 2.772902727127075
Validation loss: 2.043606096698392

Epoch: 5| Step: 6
Training loss: 2.32267165184021
Validation loss: 2.0301339344311784

Epoch: 5| Step: 7
Training loss: 2.386061429977417
Validation loss: 2.0524172116351385

Epoch: 5| Step: 8
Training loss: 2.33975887298584
Validation loss: 2.0626351551343034

Epoch: 5| Step: 9
Training loss: 2.8329789638519287
Validation loss: 2.054723144859396

Epoch: 5| Step: 10
Training loss: 2.385148525238037
Validation loss: 2.0919893813389603

Epoch: 47| Step: 0
Training loss: 2.841001272201538
Validation loss: 2.0569671905168923

Epoch: 5| Step: 1
Training loss: 2.2862401008605957
Validation loss: 2.079863254741956

Epoch: 5| Step: 2
Training loss: 2.0206334590911865
Validation loss: 2.049283665995444

Epoch: 5| Step: 3
Training loss: 2.5700860023498535
Validation loss: 2.03356695431535

Epoch: 5| Step: 4
Training loss: 1.3908450603485107
Validation loss: 2.070482341192102

Epoch: 5| Step: 5
Training loss: 3.1594793796539307
Validation loss: 2.0755238789384083

Epoch: 5| Step: 6
Training loss: 2.92057728767395
Validation loss: 2.034648271017177

Epoch: 5| Step: 7
Training loss: 2.1357195377349854
Validation loss: 2.0927807002939205

Epoch: 5| Step: 8
Training loss: 2.450162410736084
Validation loss: 2.0750304627162155

Epoch: 5| Step: 9
Training loss: 2.4170355796813965
Validation loss: 2.0586123812583184

Epoch: 5| Step: 10
Training loss: 2.3670172691345215
Validation loss: 2.0637643862796087

Epoch: 48| Step: 0
Training loss: 2.5002799034118652
Validation loss: 2.1085156676589802

Epoch: 5| Step: 1
Training loss: 2.3202762603759766
Validation loss: 2.0622658703916814

Epoch: 5| Step: 2
Training loss: 2.251512050628662
Validation loss: 2.070044586735387

Epoch: 5| Step: 3
Training loss: 1.8927392959594727
Validation loss: 2.0431700996173325

Epoch: 5| Step: 4
Training loss: 2.517054796218872
Validation loss: 2.0619304474963935

Epoch: 5| Step: 5
Training loss: 2.7783992290496826
Validation loss: 2.0813077008852394

Epoch: 5| Step: 6
Training loss: 2.475174903869629
Validation loss: 2.086846859224381

Epoch: 5| Step: 7
Training loss: 2.279102325439453
Validation loss: 2.0683890388857935

Epoch: 5| Step: 8
Training loss: 1.8867450952529907
Validation loss: 2.0992537365164807

Epoch: 5| Step: 9
Training loss: 2.7731497287750244
Validation loss: 2.052446480720274

Epoch: 5| Step: 10
Training loss: 2.707108736038208
Validation loss: 2.0696516062623713

Epoch: 49| Step: 0
Training loss: 2.3194804191589355
Validation loss: 2.0648116527065152

Epoch: 5| Step: 1
Training loss: 2.8428359031677246
Validation loss: 2.0958080214838826

Epoch: 5| Step: 2
Training loss: 1.8037971258163452
Validation loss: 2.0802596192206106

Epoch: 5| Step: 3
Training loss: 2.283249616622925
Validation loss: 2.0355016826301493

Epoch: 5| Step: 4
Training loss: 2.791658639907837
Validation loss: 2.0444289945786998

Epoch: 5| Step: 5
Training loss: 1.9394686222076416
Validation loss: 2.0389031146162298

Epoch: 5| Step: 6
Training loss: 2.748354911804199
Validation loss: 2.044843981342931

Epoch: 5| Step: 7
Training loss: 2.1047770977020264
Validation loss: 2.038988741495276

Epoch: 5| Step: 8
Training loss: 2.937783718109131
Validation loss: 2.0672672986984253

Epoch: 5| Step: 9
Training loss: 2.0688538551330566
Validation loss: 2.0558661748004217

Epoch: 5| Step: 10
Training loss: 2.2306206226348877
Validation loss: 2.0384724319622083

Epoch: 50| Step: 0
Training loss: 3.003121852874756
Validation loss: 2.0534672019302205

Epoch: 5| Step: 1
Training loss: 1.810156226158142
Validation loss: 2.0519142753334454

Epoch: 5| Step: 2
Training loss: 2.2094597816467285
Validation loss: 2.011330807080833

Epoch: 5| Step: 3
Training loss: 2.8094542026519775
Validation loss: 2.060868887491124

Epoch: 5| Step: 4
Training loss: 2.3684897422790527
Validation loss: 2.036556182369109

Epoch: 5| Step: 5
Training loss: 2.5305843353271484
Validation loss: 2.053153899408156

Epoch: 5| Step: 6
Training loss: 2.748548984527588
Validation loss: 2.0381565927177347

Epoch: 5| Step: 7
Training loss: 2.0651466846466064
Validation loss: 2.035446474629064

Epoch: 5| Step: 8
Training loss: 1.8886139392852783
Validation loss: 2.0630305685022825

Epoch: 5| Step: 9
Training loss: 2.558871030807495
Validation loss: 2.0255914170254945

Epoch: 5| Step: 10
Training loss: 1.8566861152648926
Validation loss: 2.0745678306907736

Epoch: 51| Step: 0
Training loss: 2.2658185958862305
Validation loss: 2.0459212590289373

Epoch: 5| Step: 1
Training loss: 1.945959448814392
Validation loss: 2.0590687003186954

Epoch: 5| Step: 2
Training loss: 2.369861364364624
Validation loss: 2.0142090948679114

Epoch: 5| Step: 3
Training loss: 2.6303741931915283
Validation loss: 2.026675283267934

Epoch: 5| Step: 4
Training loss: 2.5850136280059814
Validation loss: 2.0396286287615375

Epoch: 5| Step: 5
Training loss: 2.765908718109131
Validation loss: 2.044379557332685

Epoch: 5| Step: 6
Training loss: 2.441697359085083
Validation loss: 2.0877467355420514

Epoch: 5| Step: 7
Training loss: 2.5527617931365967
Validation loss: 2.043289448625298

Epoch: 5| Step: 8
Training loss: 2.4749531745910645
Validation loss: 2.0364314791976765

Epoch: 5| Step: 9
Training loss: 2.0438742637634277
Validation loss: 2.0275334619706675

Epoch: 5| Step: 10
Training loss: 2.135986089706421
Validation loss: 2.0193770418884935

Epoch: 52| Step: 0
Training loss: 2.6114768981933594
Validation loss: 2.025916184148481

Epoch: 5| Step: 1
Training loss: 2.419462203979492
Validation loss: 2.039351719681935

Epoch: 5| Step: 2
Training loss: 2.1647181510925293
Validation loss: 2.027640076093776

Epoch: 5| Step: 3
Training loss: 2.169673204421997
Validation loss: 2.0595573943148375

Epoch: 5| Step: 4
Training loss: 2.5556411743164062
Validation loss: 2.049013364699579

Epoch: 5| Step: 5
Training loss: 2.148746967315674
Validation loss: 2.0062410472541727

Epoch: 5| Step: 6
Training loss: 2.50054669380188
Validation loss: 2.0719138473592777

Epoch: 5| Step: 7
Training loss: 1.7836984395980835
Validation loss: 2.0452967343791837

Epoch: 5| Step: 8
Training loss: 2.373865842819214
Validation loss: 2.0518043348866124

Epoch: 5| Step: 9
Training loss: 3.0444841384887695
Validation loss: 2.0445033452844106

Epoch: 5| Step: 10
Training loss: 2.43428897857666
Validation loss: 2.0166113453526653

Epoch: 53| Step: 0
Training loss: 1.9299399852752686
Validation loss: 2.029200102693291

Epoch: 5| Step: 1
Training loss: 2.466789484024048
Validation loss: 2.007491224555559

Epoch: 5| Step: 2
Training loss: 2.4413440227508545
Validation loss: 2.0264968333705777

Epoch: 5| Step: 3
Training loss: 1.6713035106658936
Validation loss: 2.0419650872548423

Epoch: 5| Step: 4
Training loss: 2.4143590927124023
Validation loss: 2.0414514131443475

Epoch: 5| Step: 5
Training loss: 2.8035812377929688
Validation loss: 2.0034507513046265

Epoch: 5| Step: 6
Training loss: 2.4416961669921875
Validation loss: 2.0111673044902023

Epoch: 5| Step: 7
Training loss: 2.7217907905578613
Validation loss: 2.026991603195026

Epoch: 5| Step: 8
Training loss: 2.8607687950134277
Validation loss: 2.0287402137633292

Epoch: 5| Step: 9
Training loss: 2.8984923362731934
Validation loss: 2.0360825574526222

Epoch: 5| Step: 10
Training loss: 1.2963783740997314
Validation loss: 2.0053466750729467

Epoch: 54| Step: 0
Training loss: 2.5630812644958496
Validation loss: 2.0225507572133052

Epoch: 5| Step: 1
Training loss: 2.4940104484558105
Validation loss: 2.021878792393592

Epoch: 5| Step: 2
Training loss: 1.8588345050811768
Validation loss: 2.0485434711620374

Epoch: 5| Step: 3
Training loss: 2.434126377105713
Validation loss: 2.022730178730462

Epoch: 5| Step: 4
Training loss: 2.1011147499084473
Validation loss: 2.0746202802145355

Epoch: 5| Step: 5
Training loss: 2.6443586349487305
Validation loss: 2.0337827872204524

Epoch: 5| Step: 6
Training loss: 2.9324893951416016
Validation loss: 2.0147023380443616

Epoch: 5| Step: 7
Training loss: 2.2928519248962402
Validation loss: 2.076374605137815

Epoch: 5| Step: 8
Training loss: 2.228598117828369
Validation loss: 2.0925797929045973

Epoch: 5| Step: 9
Training loss: 2.09723162651062
Validation loss: 2.051642951144967

Epoch: 5| Step: 10
Training loss: 2.719322919845581
Validation loss: 2.048513627821399

Epoch: 55| Step: 0
Training loss: 2.5919127464294434
Validation loss: 2.0819746781420965

Epoch: 5| Step: 1
Training loss: 2.7405941486358643
Validation loss: 2.0314192592456775

Epoch: 5| Step: 2
Training loss: 2.423649787902832
Validation loss: 2.018602583997993

Epoch: 5| Step: 3
Training loss: 2.19305419921875
Validation loss: 2.0374214367199968

Epoch: 5| Step: 4
Training loss: 2.321916103363037
Validation loss: 2.041694207858014

Epoch: 5| Step: 5
Training loss: 2.9599575996398926
Validation loss: 2.032198864926574

Epoch: 5| Step: 6
Training loss: 1.6402606964111328
Validation loss: 2.0166961916031374

Epoch: 5| Step: 7
Training loss: 1.8423926830291748
Validation loss: 2.06490917359629

Epoch: 5| Step: 8
Training loss: 2.3225948810577393
Validation loss: 2.049683900289638

Epoch: 5| Step: 9
Training loss: 2.0701334476470947
Validation loss: 2.0617066006506644

Epoch: 5| Step: 10
Training loss: 2.9286863803863525
Validation loss: 2.013134329549728

Epoch: 56| Step: 0
Training loss: 2.500269889831543
Validation loss: 2.055872504429151

Epoch: 5| Step: 1
Training loss: 2.4083142280578613
Validation loss: 2.0531664151017384

Epoch: 5| Step: 2
Training loss: 2.15634822845459
Validation loss: 2.0530093139217747

Epoch: 5| Step: 3
Training loss: 1.919054388999939
Validation loss: 1.994070840138261

Epoch: 5| Step: 4
Training loss: 2.5426878929138184
Validation loss: 2.0193726016629125

Epoch: 5| Step: 5
Training loss: 2.0584843158721924
Validation loss: 2.049693706215069

Epoch: 5| Step: 6
Training loss: 1.9917793273925781
Validation loss: 2.021272127346326

Epoch: 5| Step: 7
Training loss: 2.7515363693237305
Validation loss: 2.0343916428986417

Epoch: 5| Step: 8
Training loss: 2.972621202468872
Validation loss: 2.0071891687249623

Epoch: 5| Step: 9
Training loss: 2.4781723022460938
Validation loss: 2.027365835764075

Epoch: 5| Step: 10
Training loss: 2.3812716007232666
Validation loss: 2.059990954655473

Epoch: 57| Step: 0
Training loss: 2.6870570182800293
Validation loss: 2.035215746971869

Epoch: 5| Step: 1
Training loss: 2.5593624114990234
Validation loss: 2.0047962768103487

Epoch: 5| Step: 2
Training loss: 1.8771721124649048
Validation loss: 2.0050685072457917

Epoch: 5| Step: 3
Training loss: 2.5962045192718506
Validation loss: 2.0091579652601674

Epoch: 5| Step: 4
Training loss: 2.421173572540283
Validation loss: 2.0458016908296974

Epoch: 5| Step: 5
Training loss: 2.9441351890563965
Validation loss: 2.054858002611386

Epoch: 5| Step: 6
Training loss: 2.9773478507995605
Validation loss: 2.05328784706772

Epoch: 5| Step: 7
Training loss: 2.058149814605713
Validation loss: 2.047498272311303

Epoch: 5| Step: 8
Training loss: 1.6833245754241943
Validation loss: 2.0237857436621063

Epoch: 5| Step: 9
Training loss: 2.0288517475128174
Validation loss: 2.04609316138811

Epoch: 5| Step: 10
Training loss: 1.9523605108261108
Validation loss: 2.000650171310671

Epoch: 58| Step: 0
Training loss: 2.3151237964630127
Validation loss: 2.047366754983061

Epoch: 5| Step: 1
Training loss: 1.6261348724365234
Validation loss: 2.035565468572801

Epoch: 5| Step: 2
Training loss: 1.7265625
Validation loss: 2.006333219107761

Epoch: 5| Step: 3
Training loss: 2.3750269412994385
Validation loss: 2.0270983813911356

Epoch: 5| Step: 4
Training loss: 2.992753744125366
Validation loss: 2.0160684598389493

Epoch: 5| Step: 5
Training loss: 2.4817841053009033
Validation loss: 2.01773101540022

Epoch: 5| Step: 6
Training loss: 2.357109546661377
Validation loss: 2.04154537570092

Epoch: 5| Step: 7
Training loss: 2.875100612640381
Validation loss: 2.027919077104138

Epoch: 5| Step: 8
Training loss: 2.1140408515930176
Validation loss: 2.018675455483057

Epoch: 5| Step: 9
Training loss: 2.423168897628784
Validation loss: 1.9911620834822297

Epoch: 5| Step: 10
Training loss: 2.7975893020629883
Validation loss: 2.016891038545998

Epoch: 59| Step: 0
Training loss: 1.8825180530548096
Validation loss: 2.0000753941074496

Epoch: 5| Step: 1
Training loss: 3.158783435821533
Validation loss: 2.0292584075722644

Epoch: 5| Step: 2
Training loss: 1.9532709121704102
Validation loss: 2.0429796147090133

Epoch: 5| Step: 3
Training loss: 1.8985315561294556
Validation loss: 2.0166941778634184

Epoch: 5| Step: 4
Training loss: 2.497678756713867
Validation loss: 2.0200467135316584

Epoch: 5| Step: 5
Training loss: 2.4020512104034424
Validation loss: 2.016683578491211

Epoch: 5| Step: 6
Training loss: 2.095010280609131
Validation loss: 2.036544492167811

Epoch: 5| Step: 7
Training loss: 2.6548943519592285
Validation loss: 2.0220598751498806

Epoch: 5| Step: 8
Training loss: 2.2072651386260986
Validation loss: 2.0299220162053264

Epoch: 5| Step: 9
Training loss: 1.867915153503418
Validation loss: 2.043442239043533

Epoch: 5| Step: 10
Training loss: 3.444791316986084
Validation loss: 1.9893480808504167

Epoch: 60| Step: 0
Training loss: 1.8999141454696655
Validation loss: 2.034886767787318

Epoch: 5| Step: 1
Training loss: 2.8492164611816406
Validation loss: 1.9964546260013376

Epoch: 5| Step: 2
Training loss: 1.9328107833862305
Validation loss: 2.027065918009768

Epoch: 5| Step: 3
Training loss: 2.3775923252105713
Validation loss: 1.9893061627623856

Epoch: 5| Step: 4
Training loss: 2.770158290863037
Validation loss: 2.0321864748513825

Epoch: 5| Step: 5
Training loss: 2.075326681137085
Validation loss: 2.016955719199232

Epoch: 5| Step: 6
Training loss: 2.502744436264038
Validation loss: 1.9967810133452057

Epoch: 5| Step: 7
Training loss: 2.8166542053222656
Validation loss: 2.0315949609202724

Epoch: 5| Step: 8
Training loss: 2.1144325733184814
Validation loss: 2.0160027857749694

Epoch: 5| Step: 9
Training loss: 2.572561740875244
Validation loss: 2.0381751983396468

Epoch: 5| Step: 10
Training loss: 1.9750691652297974
Validation loss: 2.0183273182120374

Epoch: 61| Step: 0
Training loss: 1.9283151626586914
Validation loss: 2.0332642101472422

Epoch: 5| Step: 1
Training loss: 2.664092540740967
Validation loss: 2.036919596374676

Epoch: 5| Step: 2
Training loss: 2.499053955078125
Validation loss: 2.0340814923727386

Epoch: 5| Step: 3
Training loss: 2.6835720539093018
Validation loss: 2.0388970618606894

Epoch: 5| Step: 4
Training loss: 2.230253219604492
Validation loss: 2.0415789747750885

Epoch: 5| Step: 5
Training loss: 2.5503041744232178
Validation loss: 2.074385173859135

Epoch: 5| Step: 6
Training loss: 2.62249755859375
Validation loss: 2.0330713589986167

Epoch: 5| Step: 7
Training loss: 2.213879346847534
Validation loss: 2.0435457973070044

Epoch: 5| Step: 8
Training loss: 2.333289384841919
Validation loss: 2.0233234346553846

Epoch: 5| Step: 9
Training loss: 1.7439113855361938
Validation loss: 2.032215690100065

Epoch: 5| Step: 10
Training loss: 2.176912784576416
Validation loss: 2.030854759677764

Epoch: 62| Step: 0
Training loss: 1.8084949254989624
Validation loss: 2.0321979548341487

Epoch: 5| Step: 1
Training loss: 2.585003137588501
Validation loss: 2.031852670895156

Epoch: 5| Step: 2
Training loss: 2.339249849319458
Validation loss: 2.0386817250200497

Epoch: 5| Step: 3
Training loss: 2.3959927558898926
Validation loss: 2.016040286710185

Epoch: 5| Step: 4
Training loss: 2.436957597732544
Validation loss: 2.004595310457291

Epoch: 5| Step: 5
Training loss: 2.130202054977417
Validation loss: 2.0182961058873

Epoch: 5| Step: 6
Training loss: 1.957481026649475
Validation loss: 2.03819901199751

Epoch: 5| Step: 7
Training loss: 2.5851800441741943
Validation loss: 2.0204839629511677

Epoch: 5| Step: 8
Training loss: 2.518005847930908
Validation loss: 2.048367625923567

Epoch: 5| Step: 9
Training loss: 2.309959888458252
Validation loss: 2.028348292073896

Epoch: 5| Step: 10
Training loss: 2.722959518432617
Validation loss: 2.023001750310262

Epoch: 63| Step: 0
Training loss: 2.348426103591919
Validation loss: 1.9916146262999503

Epoch: 5| Step: 1
Training loss: 2.2572178840637207
Validation loss: 2.0387130450176936

Epoch: 5| Step: 2
Training loss: 1.9047794342041016
Validation loss: 2.0180770665086727

Epoch: 5| Step: 3
Training loss: 2.716431140899658
Validation loss: 2.043058644058884

Epoch: 5| Step: 4
Training loss: 2.2549471855163574
Validation loss: 2.0281070701537596

Epoch: 5| Step: 5
Training loss: 2.1406455039978027
Validation loss: 2.0302770522332962

Epoch: 5| Step: 6
Training loss: 2.0839362144470215
Validation loss: 2.050324316947691

Epoch: 5| Step: 7
Training loss: 2.854851484298706
Validation loss: 2.030718203513853

Epoch: 5| Step: 8
Training loss: 2.0157546997070312
Validation loss: 2.0355118410561674

Epoch: 5| Step: 9
Training loss: 2.942553758621216
Validation loss: 2.050277128014513

Epoch: 5| Step: 10
Training loss: 2.48150634765625
Validation loss: 2.030613722339753

Epoch: 64| Step: 0
Training loss: 2.715616464614868
Validation loss: 2.0532033545996553

Epoch: 5| Step: 1
Training loss: 2.777648448944092
Validation loss: 2.018908494262285

Epoch: 5| Step: 2
Training loss: 1.8589061498641968
Validation loss: 2.0120851032195555

Epoch: 5| Step: 3
Training loss: 2.3574116230010986
Validation loss: 2.0251556878448813

Epoch: 5| Step: 4
Training loss: 2.7452750205993652
Validation loss: 2.0248069737547185

Epoch: 5| Step: 5
Training loss: 1.6930115222930908
Validation loss: 1.999000318588749

Epoch: 5| Step: 6
Training loss: 2.117166519165039
Validation loss: 2.035751332518875

Epoch: 5| Step: 7
Training loss: 2.103447675704956
Validation loss: 2.023622473080953

Epoch: 5| Step: 8
Training loss: 1.7904131412506104
Validation loss: 2.0119450323043333

Epoch: 5| Step: 9
Training loss: 2.558213472366333
Validation loss: 2.0335923228212582

Epoch: 5| Step: 10
Training loss: 2.8241608142852783
Validation loss: 2.0090563245998916

Epoch: 65| Step: 0
Training loss: 2.4363138675689697
Validation loss: 2.0192702213923135

Epoch: 5| Step: 1
Training loss: 2.1179089546203613
Validation loss: 2.025478718101337

Epoch: 5| Step: 2
Training loss: 2.1186861991882324
Validation loss: 2.0583333161569413

Epoch: 5| Step: 3
Training loss: 1.7143722772598267
Validation loss: 2.005035194017554

Epoch: 5| Step: 4
Training loss: 2.364262104034424
Validation loss: 2.0100915329430693

Epoch: 5| Step: 5
Training loss: 2.1462242603302
Validation loss: 1.9834486515291276

Epoch: 5| Step: 6
Training loss: 2.4165360927581787
Validation loss: 2.0165324172665997

Epoch: 5| Step: 7
Training loss: 2.2809832096099854
Validation loss: 1.9998339453051168

Epoch: 5| Step: 8
Training loss: 2.7187111377716064
Validation loss: 2.029365634405485

Epoch: 5| Step: 9
Training loss: 2.5656371116638184
Validation loss: 2.0008378413415726

Epoch: 5| Step: 10
Training loss: 2.624455451965332
Validation loss: 1.9806364223521242

Epoch: 66| Step: 0
Training loss: 2.6146671772003174
Validation loss: 1.989980710450039

Epoch: 5| Step: 1
Training loss: 2.1337156295776367
Validation loss: 2.0236293987561296

Epoch: 5| Step: 2
Training loss: 1.7186365127563477
Validation loss: 2.0048130404564644

Epoch: 5| Step: 3
Training loss: 2.2226274013519287
Validation loss: 2.0259725098968833

Epoch: 5| Step: 4
Training loss: 1.7764371633529663
Validation loss: 2.0001857498640656

Epoch: 5| Step: 5
Training loss: 2.537191867828369
Validation loss: 2.026841850690944

Epoch: 5| Step: 6
Training loss: 2.449625015258789
Validation loss: 2.0033513320389615

Epoch: 5| Step: 7
Training loss: 2.4709439277648926
Validation loss: 2.0352659584373556

Epoch: 5| Step: 8
Training loss: 2.2985033988952637
Validation loss: 1.988882658302143

Epoch: 5| Step: 9
Training loss: 2.8125159740448
Validation loss: 1.9990643634591052

Epoch: 5| Step: 10
Training loss: 2.5096497535705566
Validation loss: 1.9903621186492264

Epoch: 67| Step: 0
Training loss: 2.6406543254852295
Validation loss: 1.9897227556474748

Epoch: 5| Step: 1
Training loss: 1.8753273487091064
Validation loss: 1.9954285531915643

Epoch: 5| Step: 2
Training loss: 2.2967629432678223
Validation loss: 1.974082782704343

Epoch: 5| Step: 3
Training loss: 2.4698030948638916
Validation loss: 1.9816981195121683

Epoch: 5| Step: 4
Training loss: 2.6060619354248047
Validation loss: 2.021963038752156

Epoch: 5| Step: 5
Training loss: 1.9486579895019531
Validation loss: 2.0078124179634997

Epoch: 5| Step: 6
Training loss: 2.850555419921875
Validation loss: 1.9855819081747403

Epoch: 5| Step: 7
Training loss: 2.1953964233398438
Validation loss: 2.006371082798127

Epoch: 5| Step: 8
Training loss: 1.9866176843643188
Validation loss: 2.0147293229256906

Epoch: 5| Step: 9
Training loss: 2.405855655670166
Validation loss: 2.0113974514827935

Epoch: 5| Step: 10
Training loss: 2.4564313888549805
Validation loss: 1.999243228666244

Epoch: 68| Step: 0
Training loss: 1.8820682764053345
Validation loss: 1.9803537335447086

Epoch: 5| Step: 1
Training loss: 2.6776046752929688
Validation loss: 2.0437754559260544

Epoch: 5| Step: 2
Training loss: 2.575087308883667
Validation loss: 2.0057395530003372

Epoch: 5| Step: 3
Training loss: 2.350745677947998
Validation loss: 2.0166015727545625

Epoch: 5| Step: 4
Training loss: 2.308321237564087
Validation loss: 2.0451988225342124

Epoch: 5| Step: 5
Training loss: 1.901715636253357
Validation loss: 2.020456765287666

Epoch: 5| Step: 6
Training loss: 2.0932230949401855
Validation loss: 1.9957090090679865

Epoch: 5| Step: 7
Training loss: 2.626373767852783
Validation loss: 2.017014048432791

Epoch: 5| Step: 8
Training loss: 2.5037455558776855
Validation loss: 2.0065283442056305

Epoch: 5| Step: 9
Training loss: 2.0507571697235107
Validation loss: 2.01611513732582

Epoch: 5| Step: 10
Training loss: 2.444284200668335
Validation loss: 2.0123740755101687

Epoch: 69| Step: 0
Training loss: 2.27583384513855
Validation loss: 2.03192542188911

Epoch: 5| Step: 1
Training loss: 2.032410144805908
Validation loss: 2.0560919610402917

Epoch: 5| Step: 2
Training loss: 2.389683723449707
Validation loss: 2.0224277691174577

Epoch: 5| Step: 3
Training loss: 2.4451115131378174
Validation loss: 2.0080241977527575

Epoch: 5| Step: 4
Training loss: 2.117418050765991
Validation loss: 2.021296183268229

Epoch: 5| Step: 5
Training loss: 2.3249611854553223
Validation loss: 2.0243302058148127

Epoch: 5| Step: 6
Training loss: 2.3353981971740723
Validation loss: 1.9821035951696417

Epoch: 5| Step: 7
Training loss: 2.438494920730591
Validation loss: 2.0332639037921862

Epoch: 5| Step: 8
Training loss: 2.1118502616882324
Validation loss: 2.011428725334906

Epoch: 5| Step: 9
Training loss: 2.1611385345458984
Validation loss: 2.0546515577582904

Epoch: 5| Step: 10
Training loss: 2.7680413722991943
Validation loss: 2.025849767910537

Epoch: 70| Step: 0
Training loss: 2.3411943912506104
Validation loss: 2.034260662653113

Epoch: 5| Step: 1
Training loss: 2.5205721855163574
Validation loss: 2.0078800288579797

Epoch: 5| Step: 2
Training loss: 1.9232118129730225
Validation loss: 2.0248543729064283

Epoch: 5| Step: 3
Training loss: 2.5939488410949707
Validation loss: 2.0216506681134625

Epoch: 5| Step: 4
Training loss: 2.469468116760254
Validation loss: 2.0186412078078075

Epoch: 5| Step: 5
Training loss: 2.059528350830078
Validation loss: 2.024252562112706

Epoch: 5| Step: 6
Training loss: 1.7286369800567627
Validation loss: 2.0058681682873796

Epoch: 5| Step: 7
Training loss: 2.494650363922119
Validation loss: 2.041828683627549

Epoch: 5| Step: 8
Training loss: 2.5978102684020996
Validation loss: 2.0644525097262476

Epoch: 5| Step: 9
Training loss: 2.0409727096557617
Validation loss: 2.009318282527308

Epoch: 5| Step: 10
Training loss: 2.4594857692718506
Validation loss: 2.045421172213811

Epoch: 71| Step: 0
Training loss: 2.4002773761749268
Validation loss: 2.000545818318603

Epoch: 5| Step: 1
Training loss: 2.4100234508514404
Validation loss: 2.0423454238522436

Epoch: 5| Step: 2
Training loss: 2.405034065246582
Validation loss: 2.041528131372185

Epoch: 5| Step: 3
Training loss: 2.389619827270508
Validation loss: 1.9995063953502203

Epoch: 5| Step: 4
Training loss: 2.570547342300415
Validation loss: 2.024864190368242

Epoch: 5| Step: 5
Training loss: 2.179600954055786
Validation loss: 2.0042575764399704

Epoch: 5| Step: 6
Training loss: 2.3586649894714355
Validation loss: 2.0427846588114256

Epoch: 5| Step: 7
Training loss: 1.961321473121643
Validation loss: 2.003356122201489

Epoch: 5| Step: 8
Training loss: 2.2463667392730713
Validation loss: 2.029820106362784

Epoch: 5| Step: 9
Training loss: 2.642962694168091
Validation loss: 2.042441639848935

Epoch: 5| Step: 10
Training loss: 1.9205408096313477
Validation loss: 2.008792931033719

Epoch: 72| Step: 0
Training loss: 2.6077027320861816
Validation loss: 2.054430138680243

Epoch: 5| Step: 1
Training loss: 2.5302720069885254
Validation loss: 2.0196631505925167

Epoch: 5| Step: 2
Training loss: 2.249992609024048
Validation loss: 1.984304408873281

Epoch: 5| Step: 3
Training loss: 2.4717063903808594
Validation loss: 2.0351013727085565

Epoch: 5| Step: 4
Training loss: 2.3236336708068848
Validation loss: 2.0254354284655665

Epoch: 5| Step: 5
Training loss: 1.7907215356826782
Validation loss: 2.0223922832037813

Epoch: 5| Step: 6
Training loss: 2.7118289470672607
Validation loss: 1.9973581772978588

Epoch: 5| Step: 7
Training loss: 2.198239803314209
Validation loss: 1.9980338914420015

Epoch: 5| Step: 8
Training loss: 2.1505637168884277
Validation loss: 2.0307115252299974

Epoch: 5| Step: 9
Training loss: 2.2193140983581543
Validation loss: 2.005989065734289

Epoch: 5| Step: 10
Training loss: 1.9479855298995972
Validation loss: 2.020383224692396

Epoch: 73| Step: 0
Training loss: 2.3175125122070312
Validation loss: 1.980593535207933

Epoch: 5| Step: 1
Training loss: 2.151008129119873
Validation loss: 2.012878415405109

Epoch: 5| Step: 2
Training loss: 2.454465389251709
Validation loss: 2.0012504003381215

Epoch: 5| Step: 3
Training loss: 2.281775951385498
Validation loss: 2.0164748263615433

Epoch: 5| Step: 4
Training loss: 2.66755747795105
Validation loss: 2.0055162419555006

Epoch: 5| Step: 5
Training loss: 2.0945334434509277
Validation loss: 2.0000363524242113

Epoch: 5| Step: 6
Training loss: 2.9201502799987793
Validation loss: 2.0148634179945915

Epoch: 5| Step: 7
Training loss: 2.2787697315216064
Validation loss: 2.035911008875857

Epoch: 5| Step: 8
Training loss: 1.9314302206039429
Validation loss: 2.014194578252813

Epoch: 5| Step: 9
Training loss: 2.2698981761932373
Validation loss: 2.002012680935603

Epoch: 5| Step: 10
Training loss: 2.357870578765869
Validation loss: 2.0162141630726476

Epoch: 74| Step: 0
Training loss: 1.7309672832489014
Validation loss: 2.0501641560626287

Epoch: 5| Step: 1
Training loss: 2.339083194732666
Validation loss: 2.0163156511963054

Epoch: 5| Step: 2
Training loss: 2.728078842163086
Validation loss: 1.9941303935102237

Epoch: 5| Step: 3
Training loss: 2.9451401233673096
Validation loss: 1.994992152337105

Epoch: 5| Step: 4
Training loss: 2.1039743423461914
Validation loss: 1.9927154664070375

Epoch: 5| Step: 5
Training loss: 2.074321746826172
Validation loss: 2.0149753298810733

Epoch: 5| Step: 6
Training loss: 2.3049588203430176
Validation loss: 2.004934985150573

Epoch: 5| Step: 7
Training loss: 2.71710205078125
Validation loss: 2.0453273352756294

Epoch: 5| Step: 8
Training loss: 2.1688435077667236
Validation loss: 2.0452236885665567

Epoch: 5| Step: 9
Training loss: 2.2480292320251465
Validation loss: 2.0366880252797115

Epoch: 5| Step: 10
Training loss: 1.723503828048706
Validation loss: 2.0226736184089416

Epoch: 75| Step: 0
Training loss: 2.200540542602539
Validation loss: 2.019312463780885

Epoch: 5| Step: 1
Training loss: 2.5682625770568848
Validation loss: 1.998312255387665

Epoch: 5| Step: 2
Training loss: 1.8463293313980103
Validation loss: 2.0177144247998475

Epoch: 5| Step: 3
Training loss: 1.9583101272583008
Validation loss: 2.0398862464453584

Epoch: 5| Step: 4
Training loss: 1.6668739318847656
Validation loss: 1.9980006320502168

Epoch: 5| Step: 5
Training loss: 2.4517428874969482
Validation loss: 2.0070231614574308

Epoch: 5| Step: 6
Training loss: 3.082465410232544
Validation loss: 2.007502143101026

Epoch: 5| Step: 7
Training loss: 2.3198537826538086
Validation loss: 1.9865556327245568

Epoch: 5| Step: 8
Training loss: 2.3484933376312256
Validation loss: 2.0272913953309417

Epoch: 5| Step: 9
Training loss: 2.6776185035705566
Validation loss: 1.986069797187723

Epoch: 5| Step: 10
Training loss: 2.101500988006592
Validation loss: 2.0223172787697083

Epoch: 76| Step: 0
Training loss: 2.816174268722534
Validation loss: 2.015991381419602

Epoch: 5| Step: 1
Training loss: 1.9512945413589478
Validation loss: 2.0191440031092656

Epoch: 5| Step: 2
Training loss: 2.5505270957946777
Validation loss: 2.0050363181739725

Epoch: 5| Step: 3
Training loss: 1.7590229511260986
Validation loss: 2.040254992823447

Epoch: 5| Step: 4
Training loss: 2.5815067291259766
Validation loss: 1.9987947094825007

Epoch: 5| Step: 5
Training loss: 2.4078426361083984
Validation loss: 2.0113743402624644

Epoch: 5| Step: 6
Training loss: 2.6794331073760986
Validation loss: 2.004672619604295

Epoch: 5| Step: 7
Training loss: 2.4246678352355957
Validation loss: 2.005408684412638

Epoch: 5| Step: 8
Training loss: 2.2619714736938477
Validation loss: 2.0218388367724676

Epoch: 5| Step: 9
Training loss: 2.327674388885498
Validation loss: 1.9996881164530271

Epoch: 5| Step: 10
Training loss: 1.7765603065490723
Validation loss: 2.001220764652375

Epoch: 77| Step: 0
Training loss: 2.804276704788208
Validation loss: 2.018664183155183

Epoch: 5| Step: 1
Training loss: 2.8180909156799316
Validation loss: 2.0244193179633028

Epoch: 5| Step: 2
Training loss: 2.3968589305877686
Validation loss: 2.015399935424969

Epoch: 5| Step: 3
Training loss: 2.004209041595459
Validation loss: 1.9993770609619796

Epoch: 5| Step: 4
Training loss: 1.6885284185409546
Validation loss: 1.9829415159840738

Epoch: 5| Step: 5
Training loss: 2.4419350624084473
Validation loss: 1.994152295973993

Epoch: 5| Step: 6
Training loss: 2.541886568069458
Validation loss: 1.9901086181722663

Epoch: 5| Step: 7
Training loss: 2.3991780281066895
Validation loss: 2.070398597307103

Epoch: 5| Step: 8
Training loss: 2.3579962253570557
Validation loss: 1.9916026617891045

Epoch: 5| Step: 9
Training loss: 2.2293541431427
Validation loss: 2.0407619130226875

Epoch: 5| Step: 10
Training loss: 1.3170781135559082
Validation loss: 2.0310944690499255

Epoch: 78| Step: 0
Training loss: 2.0642447471618652
Validation loss: 2.021858251223

Epoch: 5| Step: 1
Training loss: 2.6623847484588623
Validation loss: 2.0140633365159393

Epoch: 5| Step: 2
Training loss: 2.2024829387664795
Validation loss: 2.0080275420219666

Epoch: 5| Step: 3
Training loss: 1.8805758953094482
Validation loss: 2.006341649639991

Epoch: 5| Step: 4
Training loss: 3.100625991821289
Validation loss: 2.016248068501872

Epoch: 5| Step: 5
Training loss: 1.8508679866790771
Validation loss: 2.017674696060919

Epoch: 5| Step: 6
Training loss: 2.28140926361084
Validation loss: 1.9939528575507544

Epoch: 5| Step: 7
Training loss: 1.944112777709961
Validation loss: 2.0229559662521526

Epoch: 5| Step: 8
Training loss: 2.096198797225952
Validation loss: 2.001223582093434

Epoch: 5| Step: 9
Training loss: 2.478283405303955
Validation loss: 2.0197488441262195

Epoch: 5| Step: 10
Training loss: 2.8245108127593994
Validation loss: 2.034770469511709

Epoch: 79| Step: 0
Training loss: 2.1512858867645264
Validation loss: 1.9817107441604778

Epoch: 5| Step: 1
Training loss: 2.2562708854675293
Validation loss: 2.0484479576028805

Epoch: 5| Step: 2
Training loss: 2.0708630084991455
Validation loss: 1.988630243526992

Epoch: 5| Step: 3
Training loss: 2.472907781600952
Validation loss: 2.0272040572217715

Epoch: 5| Step: 4
Training loss: 1.9403737783432007
Validation loss: 2.011258594451412

Epoch: 5| Step: 5
Training loss: 1.917562484741211
Validation loss: 2.000609582470309

Epoch: 5| Step: 6
Training loss: 2.717097759246826
Validation loss: 1.9904544225303076

Epoch: 5| Step: 7
Training loss: 2.3748674392700195
Validation loss: 2.035962161197457

Epoch: 5| Step: 8
Training loss: 2.725522041320801
Validation loss: 2.019023859372703

Epoch: 5| Step: 9
Training loss: 2.3106584548950195
Validation loss: 2.03024132661922

Epoch: 5| Step: 10
Training loss: 2.368726968765259
Validation loss: 1.9978361950125745

Epoch: 80| Step: 0
Training loss: 2.1746604442596436
Validation loss: 2.026472489039103

Epoch: 5| Step: 1
Training loss: 2.0738837718963623
Validation loss: 2.0263211137504986

Epoch: 5| Step: 2
Training loss: 2.0493381023406982
Validation loss: 2.0341244718079925

Epoch: 5| Step: 3
Training loss: 2.9010257720947266
Validation loss: 2.04247470055857

Epoch: 5| Step: 4
Training loss: 1.942509651184082
Validation loss: 2.017441908518473

Epoch: 5| Step: 5
Training loss: 1.47688889503479
Validation loss: 2.029825897626979

Epoch: 5| Step: 6
Training loss: 2.805205821990967
Validation loss: 1.9655454620238273

Epoch: 5| Step: 7
Training loss: 3.363945722579956
Validation loss: 2.0033064132095664

Epoch: 5| Step: 8
Training loss: 2.2761502265930176
Validation loss: 2.032327377667991

Epoch: 5| Step: 9
Training loss: 1.744126558303833
Validation loss: 2.0178388677617556

Epoch: 5| Step: 10
Training loss: 2.25957989692688
Validation loss: 2.008662321234262

Epoch: 81| Step: 0
Training loss: 2.4454963207244873
Validation loss: 2.025602830353604

Epoch: 5| Step: 1
Training loss: 2.789637565612793
Validation loss: 1.9662716439975205

Epoch: 5| Step: 2
Training loss: 2.579859972000122
Validation loss: 1.9984931715073124

Epoch: 5| Step: 3
Training loss: 1.7538505792617798
Validation loss: 1.9858908537895448

Epoch: 5| Step: 4
Training loss: 2.217526912689209
Validation loss: 1.9826501159257786

Epoch: 5| Step: 5
Training loss: 2.3212130069732666
Validation loss: 1.9805514094650105

Epoch: 5| Step: 6
Training loss: 1.8219194412231445
Validation loss: 1.9753014541441394

Epoch: 5| Step: 7
Training loss: 1.9850437641143799
Validation loss: 2.0229549818141486

Epoch: 5| Step: 8
Training loss: 2.100025177001953
Validation loss: 1.9749201523360385

Epoch: 5| Step: 9
Training loss: 2.75540828704834
Validation loss: 1.996389086528491

Epoch: 5| Step: 10
Training loss: 2.5534920692443848
Validation loss: 2.016918341318766

Epoch: 82| Step: 0
Training loss: 2.1792495250701904
Validation loss: 2.046550509750202

Epoch: 5| Step: 1
Training loss: 1.5730979442596436
Validation loss: 2.0129135821455266

Epoch: 5| Step: 2
Training loss: 2.7638041973114014
Validation loss: 2.0001450789872037

Epoch: 5| Step: 3
Training loss: 3.3364005088806152
Validation loss: 2.018311539003926

Epoch: 5| Step: 4
Training loss: 1.8423312902450562
Validation loss: 2.023129447813957

Epoch: 5| Step: 5
Training loss: 1.8966903686523438
Validation loss: 2.035217696620572

Epoch: 5| Step: 6
Training loss: 2.4195444583892822
Validation loss: 1.976816955433097

Epoch: 5| Step: 7
Training loss: 1.9197603464126587
Validation loss: 2.049104421369491

Epoch: 5| Step: 8
Training loss: 2.183577537536621
Validation loss: 2.001029916988906

Epoch: 5| Step: 9
Training loss: 2.555363178253174
Validation loss: 2.0345320393962245

Epoch: 5| Step: 10
Training loss: 2.432764768600464
Validation loss: 2.0716199695423083

Epoch: 83| Step: 0
Training loss: 2.4792752265930176
Validation loss: 2.0425226303838913

Epoch: 5| Step: 1
Training loss: 1.6229894161224365
Validation loss: 2.0136445337726223

Epoch: 5| Step: 2
Training loss: 2.3997397422790527
Validation loss: 2.0425218279643724

Epoch: 5| Step: 3
Training loss: 2.361772060394287
Validation loss: 2.0213840623055734

Epoch: 5| Step: 4
Training loss: 2.2894577980041504
Validation loss: 2.0391780945562545

Epoch: 5| Step: 5
Training loss: 1.8790779113769531
Validation loss: 2.0460708077235887

Epoch: 5| Step: 6
Training loss: 2.318516254425049
Validation loss: 2.0423966543648833

Epoch: 5| Step: 7
Training loss: 2.3296167850494385
Validation loss: 2.040173171668924

Epoch: 5| Step: 8
Training loss: 2.4914469718933105
Validation loss: 2.0266333946617703

Epoch: 5| Step: 9
Training loss: 2.3502695560455322
Validation loss: 2.0523456476067983

Epoch: 5| Step: 10
Training loss: 2.5653343200683594
Validation loss: 2.054260065478663

Epoch: 84| Step: 0
Training loss: 2.0091919898986816
Validation loss: 2.040722265038439

Epoch: 5| Step: 1
Training loss: 3.0059351921081543
Validation loss: 2.025222352755967

Epoch: 5| Step: 2
Training loss: 2.377978563308716
Validation loss: 2.037027871736916

Epoch: 5| Step: 3
Training loss: 1.7600606679916382
Validation loss: 2.016988415871897

Epoch: 5| Step: 4
Training loss: 2.05876088142395
Validation loss: 2.0361737589682303

Epoch: 5| Step: 5
Training loss: 2.4109528064727783
Validation loss: 2.0133569432843115

Epoch: 5| Step: 6
Training loss: 2.2029685974121094
Validation loss: 2.0419884548392346

Epoch: 5| Step: 7
Training loss: 2.2276358604431152
Validation loss: 2.010784888780245

Epoch: 5| Step: 8
Training loss: 2.241070032119751
Validation loss: 2.0060088224308465

Epoch: 5| Step: 9
Training loss: 2.0022623538970947
Validation loss: 2.0160776184451197

Epoch: 5| Step: 10
Training loss: 2.750734567642212
Validation loss: 1.9802354497294272

Epoch: 85| Step: 0
Training loss: 2.5009121894836426
Validation loss: 2.040007862993466

Epoch: 5| Step: 1
Training loss: 2.3454349040985107
Validation loss: 2.0316074150864796

Epoch: 5| Step: 2
Training loss: 1.997380256652832
Validation loss: 1.986402016814037

Epoch: 5| Step: 3
Training loss: 2.1840662956237793
Validation loss: 2.034950262756758

Epoch: 5| Step: 4
Training loss: 2.4947707653045654
Validation loss: 2.0188649033987396

Epoch: 5| Step: 5
Training loss: 1.7957252264022827
Validation loss: 2.015535790433166

Epoch: 5| Step: 6
Training loss: 2.535357713699341
Validation loss: 2.04207593394864

Epoch: 5| Step: 7
Training loss: 2.5648298263549805
Validation loss: 1.986486747700681

Epoch: 5| Step: 8
Training loss: 2.237295389175415
Validation loss: 2.025778311555104

Epoch: 5| Step: 9
Training loss: 2.3600335121154785
Validation loss: 1.996283515807121

Epoch: 5| Step: 10
Training loss: 2.1143765449523926
Validation loss: 1.9902974379959928

Epoch: 86| Step: 0
Training loss: 2.223372220993042
Validation loss: 2.020844505679223

Epoch: 5| Step: 1
Training loss: 2.532503604888916
Validation loss: 1.999507745107015

Epoch: 5| Step: 2
Training loss: 2.6087446212768555
Validation loss: 2.0081968820223244

Epoch: 5| Step: 3
Training loss: 2.389859437942505
Validation loss: 2.037180851864558

Epoch: 5| Step: 4
Training loss: 2.427241802215576
Validation loss: 1.9897060419923516

Epoch: 5| Step: 5
Training loss: 2.006014108657837
Validation loss: 1.9954323627615487

Epoch: 5| Step: 6
Training loss: 2.4105682373046875
Validation loss: 2.015705777752784

Epoch: 5| Step: 7
Training loss: 1.5712767839431763
Validation loss: 2.01550708534897

Epoch: 5| Step: 8
Training loss: 2.0146408081054688
Validation loss: 2.024093258765436

Epoch: 5| Step: 9
Training loss: 2.7489187717437744
Validation loss: 1.9780797958374023

Epoch: 5| Step: 10
Training loss: 1.9616864919662476
Validation loss: 1.967837772061748

Epoch: 87| Step: 0
Training loss: 1.660265564918518
Validation loss: 2.0502943300431773

Epoch: 5| Step: 1
Training loss: 1.8933318853378296
Validation loss: 2.0339211315237065

Epoch: 5| Step: 2
Training loss: 2.4136593341827393
Validation loss: 2.0122548944206646

Epoch: 5| Step: 3
Training loss: 2.7585461139678955
Validation loss: 2.0151040771956086

Epoch: 5| Step: 4
Training loss: 2.090684413909912
Validation loss: 2.0140034639707176

Epoch: 5| Step: 5
Training loss: 1.8885600566864014
Validation loss: 1.9807040870830577

Epoch: 5| Step: 6
Training loss: 2.8288052082061768
Validation loss: 1.9879404037229476

Epoch: 5| Step: 7
Training loss: 3.508984088897705
Validation loss: 2.0107706644201793

Epoch: 5| Step: 8
Training loss: 1.928084135055542
Validation loss: 2.013046333866735

Epoch: 5| Step: 9
Training loss: 1.9571574926376343
Validation loss: 2.005641573218889

Epoch: 5| Step: 10
Training loss: 2.3744254112243652
Validation loss: 2.025982238913095

Epoch: 88| Step: 0
Training loss: 2.2915215492248535
Validation loss: 1.9982065616115448

Epoch: 5| Step: 1
Training loss: 2.138482093811035
Validation loss: 2.0335033478275424

Epoch: 5| Step: 2
Training loss: 2.2247729301452637
Validation loss: 2.003736206280288

Epoch: 5| Step: 3
Training loss: 2.2053980827331543
Validation loss: 2.000663334323514

Epoch: 5| Step: 4
Training loss: 2.3384909629821777
Validation loss: 1.9945874342354395

Epoch: 5| Step: 5
Training loss: 2.6504805088043213
Validation loss: 1.9851625298941007

Epoch: 5| Step: 6
Training loss: 2.0109763145446777
Validation loss: 2.009249448776245

Epoch: 5| Step: 7
Training loss: 2.019286632537842
Validation loss: 1.9862771854605725

Epoch: 5| Step: 8
Training loss: 2.7314677238464355
Validation loss: 1.9936802617965206

Epoch: 5| Step: 9
Training loss: 2.223879337310791
Validation loss: 1.9738410313924153

Epoch: 5| Step: 10
Training loss: 1.8830844163894653
Validation loss: 1.9885109778373473

Epoch: 89| Step: 0
Training loss: 1.8903954029083252
Validation loss: 2.0631875530365975

Epoch: 5| Step: 1
Training loss: 2.0972983837127686
Validation loss: 2.018259125371133

Epoch: 5| Step: 2
Training loss: 3.083550214767456
Validation loss: 1.997092878946694

Epoch: 5| Step: 3
Training loss: 2.3348357677459717
Validation loss: 2.0067473098795903

Epoch: 5| Step: 4
Training loss: 2.314307451248169
Validation loss: 2.0199986965425554

Epoch: 5| Step: 5
Training loss: 2.5842490196228027
Validation loss: 2.0742827359066216

Epoch: 5| Step: 6
Training loss: 1.9445722103118896
Validation loss: 2.0340595155633907

Epoch: 5| Step: 7
Training loss: 2.6482677459716797
Validation loss: 2.0286384192846154

Epoch: 5| Step: 8
Training loss: 1.646247148513794
Validation loss: 2.0319386618111723

Epoch: 5| Step: 9
Training loss: 1.9480273723602295
Validation loss: 2.0545982160875873

Epoch: 5| Step: 10
Training loss: 2.641923666000366
Validation loss: 2.0697674674372517

Epoch: 90| Step: 0
Training loss: 2.2579948902130127
Validation loss: 2.032189578138372

Epoch: 5| Step: 1
Training loss: 2.02632474899292
Validation loss: 2.0592514994323894

Epoch: 5| Step: 2
Training loss: 1.8254448175430298
Validation loss: 2.0277830810957056

Epoch: 5| Step: 3
Training loss: 2.919041156768799
Validation loss: 2.0372194872107556

Epoch: 5| Step: 4
Training loss: 1.884259581565857
Validation loss: 2.031318191559084

Epoch: 5| Step: 5
Training loss: 2.8106155395507812
Validation loss: 2.020716567193308

Epoch: 5| Step: 6
Training loss: 2.241626262664795
Validation loss: 2.016485962816464

Epoch: 5| Step: 7
Training loss: 2.0610287189483643
Validation loss: 2.0245406012381277

Epoch: 5| Step: 8
Training loss: 2.9583191871643066
Validation loss: 2.0335814158121743

Epoch: 5| Step: 9
Training loss: 1.6372045278549194
Validation loss: 2.000596779648976

Epoch: 5| Step: 10
Training loss: 2.3175814151763916
Validation loss: 2.0024042616608324

Epoch: 91| Step: 0
Training loss: 2.49162220954895
Validation loss: 2.032384431490334

Epoch: 5| Step: 1
Training loss: 2.256248950958252
Validation loss: 2.041587063061294

Epoch: 5| Step: 2
Training loss: 1.9906314611434937
Validation loss: 2.048986751546142

Epoch: 5| Step: 3
Training loss: 2.3062400817871094
Validation loss: 2.071905502709009

Epoch: 5| Step: 4
Training loss: 2.118638515472412
Validation loss: 2.046586880119898

Epoch: 5| Step: 5
Training loss: 2.155689239501953
Validation loss: 2.069173175801513

Epoch: 5| Step: 6
Training loss: 2.0671029090881348
Validation loss: 2.025458871677358

Epoch: 5| Step: 7
Training loss: 3.147265911102295
Validation loss: 2.010028063610036

Epoch: 5| Step: 8
Training loss: 2.5897438526153564
Validation loss: 2.0180024639252694

Epoch: 5| Step: 9
Training loss: 1.5945137739181519
Validation loss: 2.0357383656245407

Epoch: 5| Step: 10
Training loss: 2.222843647003174
Validation loss: 2.0377902356527184

Epoch: 92| Step: 0
Training loss: 1.8467261791229248
Validation loss: 2.009077823290261

Epoch: 5| Step: 1
Training loss: 2.1202340126037598
Validation loss: 1.9838820503604027

Epoch: 5| Step: 2
Training loss: 1.6316906213760376
Validation loss: 1.988354088157736

Epoch: 5| Step: 3
Training loss: 1.7793967723846436
Validation loss: 1.996567729980715

Epoch: 5| Step: 4
Training loss: 2.0293447971343994
Validation loss: 1.9880312732470933

Epoch: 5| Step: 5
Training loss: 2.2337253093719482
Validation loss: 2.007076426218915

Epoch: 5| Step: 6
Training loss: 2.9394073486328125
Validation loss: 2.009673398028138

Epoch: 5| Step: 7
Training loss: 2.1399710178375244
Validation loss: 1.9775244702575028

Epoch: 5| Step: 8
Training loss: 2.4384071826934814
Validation loss: 2.03416193685224

Epoch: 5| Step: 9
Training loss: 2.509756326675415
Validation loss: 1.9735318588954147

Epoch: 5| Step: 10
Training loss: 3.487703323364258
Validation loss: 1.9975742627215642

Epoch: 93| Step: 0
Training loss: 2.2200052738189697
Validation loss: 1.991788762871937

Epoch: 5| Step: 1
Training loss: 2.1989426612854004
Validation loss: 2.03795535590059

Epoch: 5| Step: 2
Training loss: 1.9126167297363281
Validation loss: 1.9910338822231497

Epoch: 5| Step: 3
Training loss: 2.7281668186187744
Validation loss: 1.9962855282650198

Epoch: 5| Step: 4
Training loss: 2.4183645248413086
Validation loss: 1.9946517662335468

Epoch: 5| Step: 5
Training loss: 1.9433317184448242
Validation loss: 1.9921439129819152

Epoch: 5| Step: 6
Training loss: 2.249878168106079
Validation loss: 1.969269637138613

Epoch: 5| Step: 7
Training loss: 2.642982006072998
Validation loss: 1.9911508278180194

Epoch: 5| Step: 8
Training loss: 2.526029109954834
Validation loss: 1.989634020354158

Epoch: 5| Step: 9
Training loss: 2.0415382385253906
Validation loss: 2.0006596708810456

Epoch: 5| Step: 10
Training loss: 1.756098985671997
Validation loss: 2.010241203410651

Epoch: 94| Step: 0
Training loss: 2.4072139263153076
Validation loss: 1.9886683238449918

Epoch: 5| Step: 1
Training loss: 2.007465362548828
Validation loss: 2.0108428603859356

Epoch: 5| Step: 2
Training loss: 2.413640022277832
Validation loss: 1.9851360167226484

Epoch: 5| Step: 3
Training loss: 3.2543323040008545
Validation loss: 2.021312024003716

Epoch: 5| Step: 4
Training loss: 2.5004618167877197
Validation loss: 1.993332084789071

Epoch: 5| Step: 5
Training loss: 1.9585357904434204
Validation loss: 1.9897600271368538

Epoch: 5| Step: 6
Training loss: 2.4323668479919434
Validation loss: 2.0439203067492415

Epoch: 5| Step: 7
Training loss: 2.110020875930786
Validation loss: 2.015285502197922

Epoch: 5| Step: 8
Training loss: 2.4110312461853027
Validation loss: 2.0094541580446306

Epoch: 5| Step: 9
Training loss: 1.9885272979736328
Validation loss: 2.056819377406951

Epoch: 5| Step: 10
Training loss: 1.660339593887329
Validation loss: 2.0296225829791

Epoch: 95| Step: 0
Training loss: 2.6695468425750732
Validation loss: 2.022033417096702

Epoch: 5| Step: 1
Training loss: 2.1043410301208496
Validation loss: 2.054199375132079

Epoch: 5| Step: 2
Training loss: 2.713860511779785
Validation loss: 2.057060403208579

Epoch: 5| Step: 3
Training loss: 2.113403797149658
Validation loss: 2.037929759230665

Epoch: 5| Step: 4
Training loss: 2.6517136096954346
Validation loss: 2.0282248655954995

Epoch: 5| Step: 5
Training loss: 2.3280014991760254
Validation loss: 2.052659808948476

Epoch: 5| Step: 6
Training loss: 2.260817050933838
Validation loss: 2.0561574556494273

Epoch: 5| Step: 7
Training loss: 1.8766593933105469
Validation loss: 2.0131761181739067

Epoch: 5| Step: 8
Training loss: 1.9760990142822266
Validation loss: 2.0076815479545185

Epoch: 5| Step: 9
Training loss: 2.464210033416748
Validation loss: 2.0182269683448215

Epoch: 5| Step: 10
Training loss: 1.6725468635559082
Validation loss: 2.0152911498982418

Epoch: 96| Step: 0
Training loss: 2.3408737182617188
Validation loss: 1.979761690221807

Epoch: 5| Step: 1
Training loss: 2.5599138736724854
Validation loss: 2.02870838744666

Epoch: 5| Step: 2
Training loss: 2.431398868560791
Validation loss: 2.0095648483563493

Epoch: 5| Step: 3
Training loss: 2.4534668922424316
Validation loss: 2.0359947732699815

Epoch: 5| Step: 4
Training loss: 2.321582078933716
Validation loss: 2.0335889503520024

Epoch: 5| Step: 5
Training loss: 1.8730939626693726
Validation loss: 2.0244924188942037

Epoch: 5| Step: 6
Training loss: 2.076725482940674
Validation loss: 2.0063706931247505

Epoch: 5| Step: 7
Training loss: 1.3128769397735596
Validation loss: 2.0189178143778155

Epoch: 5| Step: 8
Training loss: 2.7007198333740234
Validation loss: 2.0362192469258464

Epoch: 5| Step: 9
Training loss: 2.001739978790283
Validation loss: 2.031153448166386

Epoch: 5| Step: 10
Training loss: 2.6430623531341553
Validation loss: 2.0403217064437045

Epoch: 97| Step: 0
Training loss: 2.441694736480713
Validation loss: 1.9956416763285154

Epoch: 5| Step: 1
Training loss: 2.5067434310913086
Validation loss: 2.028376810012325

Epoch: 5| Step: 2
Training loss: 2.5742454528808594
Validation loss: 2.0210000622657036

Epoch: 5| Step: 3
Training loss: 1.7552505731582642
Validation loss: 1.9736863336255472

Epoch: 5| Step: 4
Training loss: 1.6626074314117432
Validation loss: 2.0219790294606197

Epoch: 5| Step: 5
Training loss: 2.55356502532959
Validation loss: 2.0297971079426427

Epoch: 5| Step: 6
Training loss: 2.1752288341522217
Validation loss: 2.036413792640932

Epoch: 5| Step: 7
Training loss: 1.9626106023788452
Validation loss: 1.9999523649933517

Epoch: 5| Step: 8
Training loss: 2.197589874267578
Validation loss: 2.0517983846766974

Epoch: 5| Step: 9
Training loss: 2.1371378898620605
Validation loss: 2.035334248696604

Epoch: 5| Step: 10
Training loss: 2.8196802139282227
Validation loss: 1.9889694490740377

Epoch: 98| Step: 0
Training loss: 2.6429760456085205
Validation loss: 2.020506182024556

Epoch: 5| Step: 1
Training loss: 2.5082013607025146
Validation loss: 2.0180255802728797

Epoch: 5| Step: 2
Training loss: 2.2975497245788574
Validation loss: 2.011717491252448

Epoch: 5| Step: 3
Training loss: 2.286579132080078
Validation loss: 1.9885452319216985

Epoch: 5| Step: 4
Training loss: 1.9374046325683594
Validation loss: 2.007632641382115

Epoch: 5| Step: 5
Training loss: 1.941765546798706
Validation loss: 2.050096059358248

Epoch: 5| Step: 6
Training loss: 2.1734261512756348
Validation loss: 2.040337793288692

Epoch: 5| Step: 7
Training loss: 1.7767289876937866
Validation loss: 1.9948578137223438

Epoch: 5| Step: 8
Training loss: 2.037299394607544
Validation loss: 2.0018060694458666

Epoch: 5| Step: 9
Training loss: 2.037644147872925
Validation loss: 1.9834126221236361

Epoch: 5| Step: 10
Training loss: 3.047349452972412
Validation loss: 2.019666306434139

Epoch: 99| Step: 0
Training loss: 2.110591411590576
Validation loss: 1.9865629198730632

Epoch: 5| Step: 1
Training loss: 2.5483219623565674
Validation loss: 2.01555819665232

Epoch: 5| Step: 2
Training loss: 1.6017719507217407
Validation loss: 2.012387453868825

Epoch: 5| Step: 3
Training loss: 2.3382294178009033
Validation loss: 2.0033960906408166

Epoch: 5| Step: 4
Training loss: 2.6829628944396973
Validation loss: 1.9712513544226204

Epoch: 5| Step: 5
Training loss: 2.0367190837860107
Validation loss: 1.9741852142477547

Epoch: 5| Step: 6
Training loss: 2.3277432918548584
Validation loss: 1.9846338059312554

Epoch: 5| Step: 7
Training loss: 2.3076279163360596
Validation loss: 1.9490505649197487

Epoch: 5| Step: 8
Training loss: 2.0582168102264404
Validation loss: 2.0089098433012604

Epoch: 5| Step: 9
Training loss: 1.7540607452392578
Validation loss: 2.0028393755676928

Epoch: 5| Step: 10
Training loss: 2.7636024951934814
Validation loss: 2.0079205818073724

Epoch: 100| Step: 0
Training loss: 1.9113706350326538
Validation loss: 2.0032783733901156

Epoch: 5| Step: 1
Training loss: 2.1928353309631348
Validation loss: 2.019759355052825

Epoch: 5| Step: 2
Training loss: 2.1878745555877686
Validation loss: 2.0281227993708786

Epoch: 5| Step: 3
Training loss: 2.2727174758911133
Validation loss: 2.020298086186891

Epoch: 5| Step: 4
Training loss: 2.871464967727661
Validation loss: 2.0360302399563532

Epoch: 5| Step: 5
Training loss: 2.132084369659424
Validation loss: 1.9997905685055641

Epoch: 5| Step: 6
Training loss: 2.5279927253723145
Validation loss: 2.0221393364731983

Epoch: 5| Step: 7
Training loss: 2.722163200378418
Validation loss: 2.0106910697875486

Epoch: 5| Step: 8
Training loss: 2.3134400844573975
Validation loss: 2.0403963032589165

Epoch: 5| Step: 9
Training loss: 1.9830703735351562
Validation loss: 2.007769582092121

Epoch: 5| Step: 10
Training loss: 1.5187405347824097
Validation loss: 2.038659823838101

Epoch: 101| Step: 0
Training loss: 1.5522267818450928
Validation loss: 2.048522468536131

Epoch: 5| Step: 1
Training loss: 2.6440560817718506
Validation loss: 2.035617168231677

Epoch: 5| Step: 2
Training loss: 2.127030849456787
Validation loss: 2.0180886073779036

Epoch: 5| Step: 3
Training loss: 1.9994361400604248
Validation loss: 2.014266057681012

Epoch: 5| Step: 4
Training loss: 2.3002560138702393
Validation loss: 2.0273661895464827

Epoch: 5| Step: 5
Training loss: 1.8038253784179688
Validation loss: 2.0103352480037238

Epoch: 5| Step: 6
Training loss: 2.4728212356567383
Validation loss: 1.973174802718624

Epoch: 5| Step: 7
Training loss: 2.4362006187438965
Validation loss: 2.020713979198087

Epoch: 5| Step: 8
Training loss: 2.3407840728759766
Validation loss: 2.022392708768127

Epoch: 5| Step: 9
Training loss: 2.460799217224121
Validation loss: 2.0184833875266452

Epoch: 5| Step: 10
Training loss: 2.4791133403778076
Validation loss: 2.03781113829664

Epoch: 102| Step: 0
Training loss: 2.0032784938812256
Validation loss: 2.0082887526481383

Epoch: 5| Step: 1
Training loss: 2.5414960384368896
Validation loss: 2.0294500268915647

Epoch: 5| Step: 2
Training loss: 2.5418410301208496
Validation loss: 1.980460084894652

Epoch: 5| Step: 3
Training loss: 1.355392575263977
Validation loss: 2.03078043589028

Epoch: 5| Step: 4
Training loss: 2.6052472591400146
Validation loss: 1.9960555979000625

Epoch: 5| Step: 5
Training loss: 2.221940040588379
Validation loss: 2.0369381007327827

Epoch: 5| Step: 6
Training loss: 1.9219402074813843
Validation loss: 2.012838899448354

Epoch: 5| Step: 7
Training loss: 1.8696072101593018
Validation loss: 2.0415100923148533

Epoch: 5| Step: 8
Training loss: 2.1127307415008545
Validation loss: 2.0297435945080173

Epoch: 5| Step: 9
Training loss: 2.3465676307678223
Validation loss: 2.037686804289459

Epoch: 5| Step: 10
Training loss: 3.2306997776031494
Validation loss: 2.0288708979083645

Epoch: 103| Step: 0
Training loss: 1.84799063205719
Validation loss: 2.050982459898918

Epoch: 5| Step: 1
Training loss: 2.3343801498413086
Validation loss: 2.020876972906051

Epoch: 5| Step: 2
Training loss: 1.494538426399231
Validation loss: 2.040043220725111

Epoch: 5| Step: 3
Training loss: 1.9986768960952759
Validation loss: 2.023830326654578

Epoch: 5| Step: 4
Training loss: 2.141758680343628
Validation loss: 2.0134930790111585

Epoch: 5| Step: 5
Training loss: 2.540499210357666
Validation loss: 2.0663493115414857

Epoch: 5| Step: 6
Training loss: 2.002901554107666
Validation loss: 2.0058205819899038

Epoch: 5| Step: 7
Training loss: 2.3118221759796143
Validation loss: 2.0605393378965315

Epoch: 5| Step: 8
Training loss: 2.312838554382324
Validation loss: 2.0414287223610827

Epoch: 5| Step: 9
Training loss: 3.1671462059020996
Validation loss: 2.043783433975712

Epoch: 5| Step: 10
Training loss: 2.2957308292388916
Validation loss: 2.0679141142035045

Epoch: 104| Step: 0
Training loss: 2.6918816566467285
Validation loss: 2.0353334680680306

Epoch: 5| Step: 1
Training loss: 2.1074438095092773
Validation loss: 2.044051031912527

Epoch: 5| Step: 2
Training loss: 2.2770912647247314
Validation loss: 2.0305598820409467

Epoch: 5| Step: 3
Training loss: 2.0733485221862793
Validation loss: 2.04259781940009

Epoch: 5| Step: 4
Training loss: 2.197610378265381
Validation loss: 2.01499927941189

Epoch: 5| Step: 5
Training loss: 2.5860836505889893
Validation loss: 2.027578205190679

Epoch: 5| Step: 6
Training loss: 2.06939697265625
Validation loss: 2.0449262254981586

Epoch: 5| Step: 7
Training loss: 2.431196689605713
Validation loss: 2.0357956091562905

Epoch: 5| Step: 8
Training loss: 2.238783597946167
Validation loss: 2.048318645005585

Epoch: 5| Step: 9
Training loss: 2.0271174907684326
Validation loss: 2.046573564570437

Epoch: 5| Step: 10
Training loss: 1.5995005369186401
Validation loss: 1.9958059134021882

Epoch: 105| Step: 0
Training loss: 3.027940273284912
Validation loss: 2.0439900275199645

Epoch: 5| Step: 1
Training loss: 1.7577354907989502
Validation loss: 2.0066326484885266

Epoch: 5| Step: 2
Training loss: 2.1710636615753174
Validation loss: 2.0274951893796205

Epoch: 5| Step: 3
Training loss: 1.824496865272522
Validation loss: 2.044588235116774

Epoch: 5| Step: 4
Training loss: 2.6702373027801514
Validation loss: 2.0227865147334274

Epoch: 5| Step: 5
Training loss: 2.8338615894317627
Validation loss: 2.008728433680791

Epoch: 5| Step: 6
Training loss: 2.227578639984131
Validation loss: 2.0310661562027468

Epoch: 5| Step: 7
Training loss: 2.332949161529541
Validation loss: 2.0262519262170278

Epoch: 5| Step: 8
Training loss: 1.6120630502700806
Validation loss: 2.0649773843826784

Epoch: 5| Step: 9
Training loss: 1.7697970867156982
Validation loss: 2.0441640602645053

Epoch: 5| Step: 10
Training loss: 2.1131937503814697
Validation loss: 2.037024381340191

Epoch: 106| Step: 0
Training loss: 2.1452722549438477
Validation loss: 2.0126372088668165

Epoch: 5| Step: 1
Training loss: 3.2140345573425293
Validation loss: 1.9993732975375267

Epoch: 5| Step: 2
Training loss: 2.7725391387939453
Validation loss: 2.034199689024238

Epoch: 5| Step: 3
Training loss: 1.9343178272247314
Validation loss: 2.0111725561080442

Epoch: 5| Step: 4
Training loss: 2.2041068077087402
Validation loss: 2.044651469876689

Epoch: 5| Step: 5
Training loss: 2.1328182220458984
Validation loss: 1.9916009672226445

Epoch: 5| Step: 6
Training loss: 1.8594223260879517
Validation loss: 2.0321186050291984

Epoch: 5| Step: 7
Training loss: 1.8679107427597046
Validation loss: 2.03291061616713

Epoch: 5| Step: 8
Training loss: 2.0035836696624756
Validation loss: 1.99698317691844

Epoch: 5| Step: 9
Training loss: 2.2437098026275635
Validation loss: 2.0248230580360658

Epoch: 5| Step: 10
Training loss: 2.591275453567505
Validation loss: 2.0018534455248105

Epoch: 107| Step: 0
Training loss: 3.0495214462280273
Validation loss: 2.030254797268939

Epoch: 5| Step: 1
Training loss: 1.959981918334961
Validation loss: 2.03259475000443

Epoch: 5| Step: 2
Training loss: 1.8141186237335205
Validation loss: 2.0119935363851567

Epoch: 5| Step: 3
Training loss: 2.1134073734283447
Validation loss: 1.9997792474685177

Epoch: 5| Step: 4
Training loss: 1.8958261013031006
Validation loss: 2.0300365455688967

Epoch: 5| Step: 5
Training loss: 2.4939637184143066
Validation loss: 2.0069037381038872

Epoch: 5| Step: 6
Training loss: 1.9007076025009155
Validation loss: 2.012904138975246

Epoch: 5| Step: 7
Training loss: 2.363502264022827
Validation loss: 2.031266805946186

Epoch: 5| Step: 8
Training loss: 2.4706387519836426
Validation loss: 2.0313697168903966

Epoch: 5| Step: 9
Training loss: 1.7806860208511353
Validation loss: 1.970198186494971

Epoch: 5| Step: 10
Training loss: 2.6500813961029053
Validation loss: 2.029695772355603

Epoch: 108| Step: 0
Training loss: 1.687514066696167
Validation loss: 2.0490261008662563

Epoch: 5| Step: 1
Training loss: 2.378046989440918
Validation loss: 2.0110723485228834

Epoch: 5| Step: 2
Training loss: 2.440016269683838
Validation loss: 2.024181999186034

Epoch: 5| Step: 3
Training loss: 2.5974605083465576
Validation loss: 2.0189973128739225

Epoch: 5| Step: 4
Training loss: 1.6369785070419312
Validation loss: 2.0673240025838218

Epoch: 5| Step: 5
Training loss: 1.9289382696151733
Validation loss: 2.008498876325546

Epoch: 5| Step: 6
Training loss: 2.010889768600464
Validation loss: 2.051647665680096

Epoch: 5| Step: 7
Training loss: 2.896331548690796
Validation loss: 2.0714559093598397

Epoch: 5| Step: 8
Training loss: 2.5756797790527344
Validation loss: 2.059279554633684

Epoch: 5| Step: 9
Training loss: 1.5173969268798828
Validation loss: 2.0526644427289247

Epoch: 5| Step: 10
Training loss: 2.889951467514038
Validation loss: 2.020946935940814

Epoch: 109| Step: 0
Training loss: 2.4584403038024902
Validation loss: 2.075900916130312

Epoch: 5| Step: 1
Training loss: 2.440952777862549
Validation loss: 2.014895790366716

Epoch: 5| Step: 2
Training loss: 2.2381770610809326
Validation loss: 2.0489402714596

Epoch: 5| Step: 3
Training loss: 1.7232639789581299
Validation loss: 2.0448529899761243

Epoch: 5| Step: 4
Training loss: 2.2226204872131348
Validation loss: 2.0712660999708277

Epoch: 5| Step: 5
Training loss: 2.015752077102661
Validation loss: 2.066276414420015

Epoch: 5| Step: 6
Training loss: 2.6744747161865234
Validation loss: 2.0327293244741296

Epoch: 5| Step: 7
Training loss: 2.130760908126831
Validation loss: 2.0350764823216263

Epoch: 5| Step: 8
Training loss: 2.635547637939453
Validation loss: 2.0479895132844166

Epoch: 5| Step: 9
Training loss: 2.1793878078460693
Validation loss: 2.069331856184108

Epoch: 5| Step: 10
Training loss: 1.8474457263946533
Validation loss: 2.065874590668627

Epoch: 110| Step: 0
Training loss: 2.2655105590820312
Validation loss: 2.0081866428416264

Epoch: 5| Step: 1
Training loss: 1.8665755987167358
Validation loss: 2.036202211533823

Epoch: 5| Step: 2
Training loss: 2.524568557739258
Validation loss: 2.0378762150323517

Epoch: 5| Step: 3
Training loss: 2.390688180923462
Validation loss: 2.0492073284682406

Epoch: 5| Step: 4
Training loss: 2.902737617492676
Validation loss: 2.0357797786753666

Epoch: 5| Step: 5
Training loss: 1.638964056968689
Validation loss: 2.047672253783031

Epoch: 5| Step: 6
Training loss: 2.1690666675567627
Validation loss: 2.0015287860747306

Epoch: 5| Step: 7
Training loss: 2.0824897289276123
Validation loss: 2.0328778246397614

Epoch: 5| Step: 8
Training loss: 1.3234732151031494
Validation loss: 2.016086188695764

Epoch: 5| Step: 9
Training loss: 2.449558973312378
Validation loss: 2.0755489462165424

Epoch: 5| Step: 10
Training loss: 2.7858870029449463
Validation loss: 2.015737138768678

Epoch: 111| Step: 0
Training loss: 1.8816816806793213
Validation loss: 2.0167673031489053

Epoch: 5| Step: 1
Training loss: 2.642421007156372
Validation loss: 2.0072951265560683

Epoch: 5| Step: 2
Training loss: 1.6979182958602905
Validation loss: 2.0039321863523094

Epoch: 5| Step: 3
Training loss: 2.402137041091919
Validation loss: 2.0216046405094925

Epoch: 5| Step: 4
Training loss: 3.1123390197753906
Validation loss: 2.03680996741018

Epoch: 5| Step: 5
Training loss: 2.1499505043029785
Validation loss: 2.00783271174277

Epoch: 5| Step: 6
Training loss: 2.2473464012145996
Validation loss: 2.0295173827038018

Epoch: 5| Step: 7
Training loss: 1.891956090927124
Validation loss: 2.0093822197247575

Epoch: 5| Step: 8
Training loss: 1.9824947118759155
Validation loss: 2.0671341752493255

Epoch: 5| Step: 9
Training loss: 2.221935272216797
Validation loss: 1.9911511841640677

Epoch: 5| Step: 10
Training loss: 2.421724557876587
Validation loss: 1.9986254066549323

Epoch: 112| Step: 0
Training loss: 2.559356212615967
Validation loss: 2.0496480721299366

Epoch: 5| Step: 1
Training loss: 2.1962831020355225
Validation loss: 1.9983754311838458

Epoch: 5| Step: 2
Training loss: 2.239849805831909
Validation loss: 2.039150611046822

Epoch: 5| Step: 3
Training loss: 1.8880714178085327
Validation loss: 2.0289780145050376

Epoch: 5| Step: 4
Training loss: 1.9969089031219482
Validation loss: 2.013512211461221

Epoch: 5| Step: 5
Training loss: 2.2348437309265137
Validation loss: 2.016704992581439

Epoch: 5| Step: 6
Training loss: 2.364287853240967
Validation loss: 2.002369862730785

Epoch: 5| Step: 7
Training loss: 2.0027174949645996
Validation loss: 2.054018046266289

Epoch: 5| Step: 8
Training loss: 2.5069198608398438
Validation loss: 1.9824999763119606

Epoch: 5| Step: 9
Training loss: 2.605682373046875
Validation loss: 2.0366964186391523

Epoch: 5| Step: 10
Training loss: 1.9640932083129883
Validation loss: 2.0240523353699715

Epoch: 113| Step: 0
Training loss: 1.9010175466537476
Validation loss: 2.025393439877418

Epoch: 5| Step: 1
Training loss: 2.163320541381836
Validation loss: 2.035758936277

Epoch: 5| Step: 2
Training loss: 1.8700006008148193
Validation loss: 2.019144319718884

Epoch: 5| Step: 3
Training loss: 1.7919366359710693
Validation loss: 2.0511978159668627

Epoch: 5| Step: 4
Training loss: 2.782878875732422
Validation loss: 2.0601995657849055

Epoch: 5| Step: 5
Training loss: 2.0555710792541504
Validation loss: 2.0361704364899667

Epoch: 5| Step: 6
Training loss: 2.5603041648864746
Validation loss: 2.0347687659725064

Epoch: 5| Step: 7
Training loss: 2.4422554969787598
Validation loss: 2.0075163854065763

Epoch: 5| Step: 8
Training loss: 2.6574795246124268
Validation loss: 2.0554621399089856

Epoch: 5| Step: 9
Training loss: 2.4501991271972656
Validation loss: 2.0326358836184264

Epoch: 5| Step: 10
Training loss: 1.8410755395889282
Validation loss: 1.99798858293923

Epoch: 114| Step: 0
Training loss: 2.2424044609069824
Validation loss: 2.035284790941464

Epoch: 5| Step: 1
Training loss: 2.4444756507873535
Validation loss: 1.996744824993995

Epoch: 5| Step: 2
Training loss: 2.084524631500244
Validation loss: 2.0330022381198023

Epoch: 5| Step: 3
Training loss: 2.1762235164642334
Validation loss: 2.014319094278479

Epoch: 5| Step: 4
Training loss: 2.0430197715759277
Validation loss: 2.063449932682899

Epoch: 5| Step: 5
Training loss: 2.2698872089385986
Validation loss: 2.0410245387784895

Epoch: 5| Step: 6
Training loss: 2.16117000579834
Validation loss: 2.073681567304878

Epoch: 5| Step: 7
Training loss: 2.394852638244629
Validation loss: 2.0806878420614425

Epoch: 5| Step: 8
Training loss: 2.3923354148864746
Validation loss: 2.021846289275795

Epoch: 5| Step: 9
Training loss: 2.4074249267578125
Validation loss: 2.0540921085624286

Epoch: 5| Step: 10
Training loss: 1.7117316722869873
Validation loss: 2.028486640222611

Epoch: 115| Step: 0
Training loss: 2.2201294898986816
Validation loss: 2.0659769888847106

Epoch: 5| Step: 1
Training loss: 1.903611183166504
Validation loss: 2.0498825427024596

Epoch: 5| Step: 2
Training loss: 2.3443987369537354
Validation loss: 2.0174554189046225

Epoch: 5| Step: 3
Training loss: 1.945186972618103
Validation loss: 2.024731973166107

Epoch: 5| Step: 4
Training loss: 2.7412257194519043
Validation loss: 2.043922426880047

Epoch: 5| Step: 5
Training loss: 2.387007236480713
Validation loss: 2.023837210029684

Epoch: 5| Step: 6
Training loss: 2.424699306488037
Validation loss: 2.03897996358974

Epoch: 5| Step: 7
Training loss: 1.832040786743164
Validation loss: 2.0483948940871866

Epoch: 5| Step: 8
Training loss: 1.9838695526123047
Validation loss: 2.046590285916482

Epoch: 5| Step: 9
Training loss: 2.090318202972412
Validation loss: 2.037353633552469

Epoch: 5| Step: 10
Training loss: 2.5590124130249023
Validation loss: 2.0104710132844987

Epoch: 116| Step: 0
Training loss: 1.783715009689331
Validation loss: 2.0620284823961157

Epoch: 5| Step: 1
Training loss: 2.668001890182495
Validation loss: 2.027668435086486

Epoch: 5| Step: 2
Training loss: 1.987874984741211
Validation loss: 2.016031539568337

Epoch: 5| Step: 3
Training loss: 2.4479167461395264
Validation loss: 2.022490078403104

Epoch: 5| Step: 4
Training loss: 2.202427864074707
Validation loss: 2.003134504441292

Epoch: 5| Step: 5
Training loss: 2.0153815746307373
Validation loss: 2.041471374932156

Epoch: 5| Step: 6
Training loss: 2.5707972049713135
Validation loss: 2.038274990615024

Epoch: 5| Step: 7
Training loss: 2.9445979595184326
Validation loss: 2.050542864748227

Epoch: 5| Step: 8
Training loss: 1.8588861227035522
Validation loss: 2.0555242133396927

Epoch: 5| Step: 9
Training loss: 2.2061188220977783
Validation loss: 2.0558310221600276

Epoch: 5| Step: 10
Training loss: 1.7618005275726318
Validation loss: 2.0241131231349003

Epoch: 117| Step: 0
Training loss: 1.8268638849258423
Validation loss: 2.0281574495377077

Epoch: 5| Step: 1
Training loss: 1.913648009300232
Validation loss: 2.0048543983890164

Epoch: 5| Step: 2
Training loss: 2.1124987602233887
Validation loss: 2.0338184884799424

Epoch: 5| Step: 3
Training loss: 2.4918835163116455
Validation loss: 2.0225571445239487

Epoch: 5| Step: 4
Training loss: 3.071274995803833
Validation loss: 2.046110822308448

Epoch: 5| Step: 5
Training loss: 2.8522720336914062
Validation loss: 2.0244249477181384

Epoch: 5| Step: 6
Training loss: 1.8731473684310913
Validation loss: 2.0419811599998066

Epoch: 5| Step: 7
Training loss: 1.6268304586410522
Validation loss: 2.0233570350113737

Epoch: 5| Step: 8
Training loss: 2.254514694213867
Validation loss: 2.0087413326386483

Epoch: 5| Step: 9
Training loss: 2.064713954925537
Validation loss: 2.0443740608871623

Epoch: 5| Step: 10
Training loss: 2.20371413230896
Validation loss: 2.062353548183236

Epoch: 118| Step: 0
Training loss: 2.237356662750244
Validation loss: 1.9956882974152923

Epoch: 5| Step: 1
Training loss: 2.222571849822998
Validation loss: 2.0321733182476414

Epoch: 5| Step: 2
Training loss: 1.8805286884307861
Validation loss: 2.0241533684474167

Epoch: 5| Step: 3
Training loss: 2.499293804168701
Validation loss: 2.0016976223197034

Epoch: 5| Step: 4
Training loss: 1.6843929290771484
Validation loss: 1.9949660813936623

Epoch: 5| Step: 5
Training loss: 2.5525877475738525
Validation loss: 2.013398248662231

Epoch: 5| Step: 6
Training loss: 2.4972567558288574
Validation loss: 2.00730751791308

Epoch: 5| Step: 7
Training loss: 2.696174383163452
Validation loss: 2.0350990859411096

Epoch: 5| Step: 8
Training loss: 2.2449615001678467
Validation loss: 2.0446746374971125

Epoch: 5| Step: 9
Training loss: 1.9269521236419678
Validation loss: 2.0473365501690934

Epoch: 5| Step: 10
Training loss: 1.8628687858581543
Validation loss: 2.0227903883944274

Epoch: 119| Step: 0
Training loss: 2.556605815887451
Validation loss: 2.0425295368317635

Epoch: 5| Step: 1
Training loss: 1.5790420770645142
Validation loss: 1.9987110450703611

Epoch: 5| Step: 2
Training loss: 2.109265089035034
Validation loss: 2.020800325178331

Epoch: 5| Step: 3
Training loss: 2.4948272705078125
Validation loss: 2.0173244425045547

Epoch: 5| Step: 4
Training loss: 2.026459217071533
Validation loss: 2.0124150373602427

Epoch: 5| Step: 5
Training loss: 2.535609006881714
Validation loss: 2.058542823278776

Epoch: 5| Step: 6
Training loss: 2.235988140106201
Validation loss: 2.033338754407821

Epoch: 5| Step: 7
Training loss: 1.9658558368682861
Validation loss: 2.0520434405214045

Epoch: 5| Step: 8
Training loss: 1.908725380897522
Validation loss: 2.0471332124484483

Epoch: 5| Step: 9
Training loss: 2.6629574298858643
Validation loss: 2.0508029922362296

Epoch: 5| Step: 10
Training loss: 2.1567468643188477
Validation loss: 2.0222409540607083

Epoch: 120| Step: 0
Training loss: 2.3284077644348145
Validation loss: 2.0445034247572704

Epoch: 5| Step: 1
Training loss: 2.278597354888916
Validation loss: 2.02845811587508

Epoch: 5| Step: 2
Training loss: 2.254171848297119
Validation loss: 2.0278744095115253

Epoch: 5| Step: 3
Training loss: 1.8963439464569092
Validation loss: 1.9815253262878747

Epoch: 5| Step: 4
Training loss: 2.336221218109131
Validation loss: 1.9775360322767688

Epoch: 5| Step: 5
Training loss: 2.614790678024292
Validation loss: 2.0116719071583082

Epoch: 5| Step: 6
Training loss: 2.2702877521514893
Validation loss: 2.035260708101334

Epoch: 5| Step: 7
Training loss: 1.8761640787124634
Validation loss: 2.0119056893933203

Epoch: 5| Step: 8
Training loss: 2.254952907562256
Validation loss: 1.9682329482929681

Epoch: 5| Step: 9
Training loss: 1.879157304763794
Validation loss: 1.9788864915088942

Epoch: 5| Step: 10
Training loss: 2.099985122680664
Validation loss: 2.0166376649692492

Epoch: 121| Step: 0
Training loss: 2.327646255493164
Validation loss: 2.0487686357190533

Epoch: 5| Step: 1
Training loss: 1.7899057865142822
Validation loss: 1.9992704904207619

Epoch: 5| Step: 2
Training loss: 1.9303877353668213
Validation loss: 2.017363650824434

Epoch: 5| Step: 3
Training loss: 2.4028677940368652
Validation loss: 2.021575863643359

Epoch: 5| Step: 4
Training loss: 2.100581645965576
Validation loss: 2.0527921568962837

Epoch: 5| Step: 5
Training loss: 2.5484097003936768
Validation loss: 2.0194605319730696

Epoch: 5| Step: 6
Training loss: 2.7387704849243164
Validation loss: 2.0431760664909118

Epoch: 5| Step: 7
Training loss: 1.6110255718231201
Validation loss: 2.0308725936438448

Epoch: 5| Step: 8
Training loss: 2.4180703163146973
Validation loss: 2.015320534347206

Epoch: 5| Step: 9
Training loss: 2.3450779914855957
Validation loss: 2.068770134320823

Epoch: 5| Step: 10
Training loss: 2.0449018478393555
Validation loss: 2.023668376348352

Epoch: 122| Step: 0
Training loss: 2.021421432495117
Validation loss: 2.0823782823419057

Epoch: 5| Step: 1
Training loss: 2.1035971641540527
Validation loss: 2.0467609064553374

Epoch: 5| Step: 2
Training loss: 2.5576577186584473
Validation loss: 2.0144566284712924

Epoch: 5| Step: 3
Training loss: 1.7878615856170654
Validation loss: 2.068342790808729

Epoch: 5| Step: 4
Training loss: 2.7942211627960205
Validation loss: 2.0542683447560957

Epoch: 5| Step: 5
Training loss: 2.5624685287475586
Validation loss: 2.0267845687045845

Epoch: 5| Step: 6
Training loss: 1.8093315362930298
Validation loss: 2.022916711786742

Epoch: 5| Step: 7
Training loss: 2.145277261734009
Validation loss: 2.065392945402412

Epoch: 5| Step: 8
Training loss: 2.557279109954834
Validation loss: 2.083731525687761

Epoch: 5| Step: 9
Training loss: 1.9489710330963135
Validation loss: 2.0192231516684256

Epoch: 5| Step: 10
Training loss: 1.965942621231079
Validation loss: 2.039413108620592

Epoch: 123| Step: 0
Training loss: 1.9782168865203857
Validation loss: 2.075342050162695

Epoch: 5| Step: 1
Training loss: 2.5739855766296387
Validation loss: 2.022402455729823

Epoch: 5| Step: 2
Training loss: 2.0629172325134277
Validation loss: 2.033694790255639

Epoch: 5| Step: 3
Training loss: 2.169562578201294
Validation loss: 2.0315451980918966

Epoch: 5| Step: 4
Training loss: 2.3370792865753174
Validation loss: 2.0491916441148326

Epoch: 5| Step: 5
Training loss: 2.4690909385681152
Validation loss: 2.017381655272617

Epoch: 5| Step: 6
Training loss: 2.1293816566467285
Validation loss: 2.0150012662333827

Epoch: 5| Step: 7
Training loss: 2.4795680046081543
Validation loss: 2.014031033362112

Epoch: 5| Step: 8
Training loss: 1.4149169921875
Validation loss: 2.024430254454254

Epoch: 5| Step: 9
Training loss: 3.2829437255859375
Validation loss: 1.992540354369789

Epoch: 5| Step: 10
Training loss: 1.4971054792404175
Validation loss: 2.012966586697486

Epoch: 124| Step: 0
Training loss: 1.7645742893218994
Validation loss: 2.021318727923978

Epoch: 5| Step: 1
Training loss: 2.3010480403900146
Validation loss: 1.9973332907563897

Epoch: 5| Step: 2
Training loss: 1.8427674770355225
Validation loss: 2.0162754956112114

Epoch: 5| Step: 3
Training loss: 1.3878594636917114
Validation loss: 1.9902042765771188

Epoch: 5| Step: 4
Training loss: 2.443704843521118
Validation loss: 2.052449685271068

Epoch: 5| Step: 5
Training loss: 2.684809923171997
Validation loss: 2.0177107472573557

Epoch: 5| Step: 6
Training loss: 2.7009685039520264
Validation loss: 2.0234315164627565

Epoch: 5| Step: 7
Training loss: 1.9368995428085327
Validation loss: 2.0160706107334425

Epoch: 5| Step: 8
Training loss: 2.1660497188568115
Validation loss: 2.011298633390857

Epoch: 5| Step: 9
Training loss: 2.2760729789733887
Validation loss: 2.048233696209487

Epoch: 5| Step: 10
Training loss: 2.820178270339966
Validation loss: 2.0074025738623833

Epoch: 125| Step: 0
Training loss: 1.9818038940429688
Validation loss: 2.0496227587423017

Epoch: 5| Step: 1
Training loss: 1.7374293804168701
Validation loss: 2.015566938666887

Epoch: 5| Step: 2
Training loss: 2.273918867111206
Validation loss: 2.025718012163716

Epoch: 5| Step: 3
Training loss: 2.764698028564453
Validation loss: 2.0177777762054117

Epoch: 5| Step: 4
Training loss: 2.620993137359619
Validation loss: 2.038953040235786

Epoch: 5| Step: 5
Training loss: 1.5498566627502441
Validation loss: 2.0407380775738786

Epoch: 5| Step: 6
Training loss: 2.111475706100464
Validation loss: 2.046716418317569

Epoch: 5| Step: 7
Training loss: 1.7737281322479248
Validation loss: 2.0198667767227336

Epoch: 5| Step: 8
Training loss: 2.5115432739257812
Validation loss: 2.065262025402438

Epoch: 5| Step: 9
Training loss: 2.2072901725769043
Validation loss: 2.0457642270672705

Epoch: 5| Step: 10
Training loss: 2.828204870223999
Validation loss: 2.0534739622505764

Epoch: 126| Step: 0
Training loss: 2.436771869659424
Validation loss: 2.033983738191666

Epoch: 5| Step: 1
Training loss: 1.8229334354400635
Validation loss: 2.0503228159360987

Epoch: 5| Step: 2
Training loss: 2.064631938934326
Validation loss: 2.0348789063833093

Epoch: 5| Step: 3
Training loss: 2.1265196800231934
Validation loss: 2.0240423910079466

Epoch: 5| Step: 4
Training loss: 2.2233381271362305
Validation loss: 2.0232063544693815

Epoch: 5| Step: 5
Training loss: 2.7979698181152344
Validation loss: 2.0472617713353967

Epoch: 5| Step: 6
Training loss: 2.3456146717071533
Validation loss: 1.9901714953043128

Epoch: 5| Step: 7
Training loss: 2.467303514480591
Validation loss: 2.0065821383589055

Epoch: 5| Step: 8
Training loss: 1.9171510934829712
Validation loss: 2.015652684755223

Epoch: 5| Step: 9
Training loss: 2.159769296646118
Validation loss: 2.0098995008776264

Epoch: 5| Step: 10
Training loss: 1.8372876644134521
Validation loss: 1.9926942279261928

Epoch: 127| Step: 0
Training loss: 2.0431201457977295
Validation loss: 2.007077274783965

Epoch: 5| Step: 1
Training loss: 2.2614574432373047
Validation loss: 2.025515426871597

Epoch: 5| Step: 2
Training loss: 2.3472824096679688
Validation loss: 2.0299800813839

Epoch: 5| Step: 3
Training loss: 2.1152539253234863
Validation loss: 2.0412808451601254

Epoch: 5| Step: 4
Training loss: 1.5451929569244385
Validation loss: 2.03829691743338

Epoch: 5| Step: 5
Training loss: 2.8504638671875
Validation loss: 1.9904579654816659

Epoch: 5| Step: 6
Training loss: 2.540809154510498
Validation loss: 2.00066686830213

Epoch: 5| Step: 7
Training loss: 2.6160826683044434
Validation loss: 2.032294688686248

Epoch: 5| Step: 8
Training loss: 2.004772663116455
Validation loss: 2.0305725207892795

Epoch: 5| Step: 9
Training loss: 2.0703024864196777
Validation loss: 2.0503398218462543

Epoch: 5| Step: 10
Training loss: 1.7434440851211548
Validation loss: 2.000685752079051

Epoch: 128| Step: 0
Training loss: 1.8649938106536865
Validation loss: 2.019537268146392

Epoch: 5| Step: 1
Training loss: 2.68076753616333
Validation loss: 2.007089429004218

Epoch: 5| Step: 2
Training loss: 2.5758872032165527
Validation loss: 2.0470328587357716

Epoch: 5| Step: 3
Training loss: 1.9960689544677734
Validation loss: 2.030026202560753

Epoch: 5| Step: 4
Training loss: 1.9041802883148193
Validation loss: 2.0348334837985296

Epoch: 5| Step: 5
Training loss: 2.0179998874664307
Validation loss: 2.0235365539468746

Epoch: 5| Step: 6
Training loss: 1.9838192462921143
Validation loss: 1.9922514333519885

Epoch: 5| Step: 7
Training loss: 2.3308303356170654
Validation loss: 2.026938033360307

Epoch: 5| Step: 8
Training loss: 2.535181760787964
Validation loss: 1.9979707656368133

Epoch: 5| Step: 9
Training loss: 2.074033260345459
Validation loss: 2.0468023643698743

Epoch: 5| Step: 10
Training loss: 1.942090630531311
Validation loss: 2.023343495143357

Epoch: 129| Step: 0
Training loss: 2.0798866748809814
Validation loss: 2.038088858768504

Epoch: 5| Step: 1
Training loss: 1.741786003112793
Validation loss: 2.0459673020147506

Epoch: 5| Step: 2
Training loss: 2.717287063598633
Validation loss: 2.026971341461264

Epoch: 5| Step: 3
Training loss: 2.190859794616699
Validation loss: 2.004951023286389

Epoch: 5| Step: 4
Training loss: 2.128775119781494
Validation loss: 2.014336560362129

Epoch: 5| Step: 5
Training loss: 2.191152572631836
Validation loss: 2.0194331151182934

Epoch: 5| Step: 6
Training loss: 2.0350000858306885
Validation loss: 2.0180784220336587

Epoch: 5| Step: 7
Training loss: 2.3043434619903564
Validation loss: 2.0315224932086084

Epoch: 5| Step: 8
Training loss: 2.496338367462158
Validation loss: 2.040043415561799

Epoch: 5| Step: 9
Training loss: 2.1232051849365234
Validation loss: 2.0237708437827324

Epoch: 5| Step: 10
Training loss: 2.3347439765930176
Validation loss: 2.0405060783509286

Epoch: 130| Step: 0
Training loss: 1.99677312374115
Validation loss: 2.0371858304546726

Epoch: 5| Step: 1
Training loss: 2.309805393218994
Validation loss: 2.0266491469516548

Epoch: 5| Step: 2
Training loss: 3.1084818840026855
Validation loss: 2.016412522203179

Epoch: 5| Step: 3
Training loss: 2.424243927001953
Validation loss: 2.0188673978210776

Epoch: 5| Step: 4
Training loss: 1.95188307762146
Validation loss: 2.0096644816860074

Epoch: 5| Step: 5
Training loss: 2.0562360286712646
Validation loss: 2.058250909210533

Epoch: 5| Step: 6
Training loss: 2.0649354457855225
Validation loss: 2.04357805303348

Epoch: 5| Step: 7
Training loss: 2.0618700981140137
Validation loss: 1.976791540781657

Epoch: 5| Step: 8
Training loss: 1.9398952722549438
Validation loss: 2.0472648451405187

Epoch: 5| Step: 9
Training loss: 1.7631458044052124
Validation loss: 2.049278305422875

Epoch: 5| Step: 10
Training loss: 2.3137667179107666
Validation loss: 2.0286691368267102

Epoch: 131| Step: 0
Training loss: 2.575373411178589
Validation loss: 2.0485689729772587

Epoch: 5| Step: 1
Training loss: 1.4701343774795532
Validation loss: 2.006015472514655

Epoch: 5| Step: 2
Training loss: 1.4852172136306763
Validation loss: 2.0451218646059752

Epoch: 5| Step: 3
Training loss: 2.390951156616211
Validation loss: 2.0259718612958024

Epoch: 5| Step: 4
Training loss: 2.8460354804992676
Validation loss: 2.040185946290211

Epoch: 5| Step: 5
Training loss: 2.7638654708862305
Validation loss: 2.052187305624767

Epoch: 5| Step: 6
Training loss: 1.8970768451690674
Validation loss: 2.011040110741892

Epoch: 5| Step: 7
Training loss: 2.3334338665008545
Validation loss: 2.0661611557006836

Epoch: 5| Step: 8
Training loss: 2.4710566997528076
Validation loss: 2.015704547205279

Epoch: 5| Step: 9
Training loss: 1.8728997707366943
Validation loss: 2.040248452976186

Epoch: 5| Step: 10
Training loss: 1.815566062927246
Validation loss: 2.016346111092516

Epoch: 132| Step: 0
Training loss: 2.1639773845672607
Validation loss: 2.018295875159643

Epoch: 5| Step: 1
Training loss: 2.3801109790802
Validation loss: 2.0293934601609425

Epoch: 5| Step: 2
Training loss: 2.546614170074463
Validation loss: 2.028013453688673

Epoch: 5| Step: 3
Training loss: 2.088688373565674
Validation loss: 2.006325311558221

Epoch: 5| Step: 4
Training loss: 2.320916175842285
Validation loss: 2.047921972890054

Epoch: 5| Step: 5
Training loss: 2.4631338119506836
Validation loss: 1.9702162896433184

Epoch: 5| Step: 6
Training loss: 1.7829498052597046
Validation loss: 1.9979924155819802

Epoch: 5| Step: 7
Training loss: 1.8634636402130127
Validation loss: 2.009094297244985

Epoch: 5| Step: 8
Training loss: 2.1768927574157715
Validation loss: 2.0185766463638632

Epoch: 5| Step: 9
Training loss: 2.231492757797241
Validation loss: 2.017662581577096

Epoch: 5| Step: 10
Training loss: 2.2179574966430664
Validation loss: 1.999950078225905

Epoch: 133| Step: 0
Training loss: 2.3954648971557617
Validation loss: 1.9965503907972766

Epoch: 5| Step: 1
Training loss: 2.2324271202087402
Validation loss: 2.027118600824828

Epoch: 5| Step: 2
Training loss: 1.7648305892944336
Validation loss: 2.054724060079103

Epoch: 5| Step: 3
Training loss: 2.4555351734161377
Validation loss: 1.9749313759547409

Epoch: 5| Step: 4
Training loss: 1.819785714149475
Validation loss: 2.0427696986864974

Epoch: 5| Step: 5
Training loss: 2.146557331085205
Validation loss: 2.032223804022676

Epoch: 5| Step: 6
Training loss: 2.3637585639953613
Validation loss: 2.021132233322308

Epoch: 5| Step: 7
Training loss: 2.2790870666503906
Validation loss: 2.0441088150906306

Epoch: 5| Step: 8
Training loss: 2.596841812133789
Validation loss: 2.0514609788053777

Epoch: 5| Step: 9
Training loss: 2.0787220001220703
Validation loss: 2.0609340795906643

Epoch: 5| Step: 10
Training loss: 2.250030755996704
Validation loss: 2.043596777864682

Epoch: 134| Step: 0
Training loss: 2.6043033599853516
Validation loss: 2.0108456432178454

Epoch: 5| Step: 1
Training loss: 1.8967342376708984
Validation loss: 2.030937397351829

Epoch: 5| Step: 2
Training loss: 1.9902324676513672
Validation loss: 2.072030372517083

Epoch: 5| Step: 3
Training loss: 2.4352383613586426
Validation loss: 1.993122749431159

Epoch: 5| Step: 4
Training loss: 1.8963216543197632
Validation loss: 2.0060898514204126

Epoch: 5| Step: 5
Training loss: 2.5031421184539795
Validation loss: 2.0448799543483283

Epoch: 5| Step: 6
Training loss: 1.6201632022857666
Validation loss: 2.039251004495928

Epoch: 5| Step: 7
Training loss: 2.320338726043701
Validation loss: 2.0400653731438423

Epoch: 5| Step: 8
Training loss: 2.107807159423828
Validation loss: 2.02316265977839

Epoch: 5| Step: 9
Training loss: 2.168412685394287
Validation loss: 2.0297501984462945

Epoch: 5| Step: 10
Training loss: 2.5812642574310303
Validation loss: 2.0085446552563737

Epoch: 135| Step: 0
Training loss: 2.1702582836151123
Validation loss: 2.014224562593686

Epoch: 5| Step: 1
Training loss: 2.568751811981201
Validation loss: 2.030048038369866

Epoch: 5| Step: 2
Training loss: 2.0777747631073
Validation loss: 2.0269490595786803

Epoch: 5| Step: 3
Training loss: 2.126225709915161
Validation loss: 2.0295551528212843

Epoch: 5| Step: 4
Training loss: 2.3371596336364746
Validation loss: 2.0660012140068957

Epoch: 5| Step: 5
Training loss: 1.4557616710662842
Validation loss: 2.029843053510112

Epoch: 5| Step: 6
Training loss: 2.12534499168396
Validation loss: 2.033216708449907

Epoch: 5| Step: 7
Training loss: 2.450038433074951
Validation loss: 2.0562609549491637

Epoch: 5| Step: 8
Training loss: 2.092085838317871
Validation loss: 2.0300298262667913

Epoch: 5| Step: 9
Training loss: 2.3208351135253906
Validation loss: 2.0541018952605543

Epoch: 5| Step: 10
Training loss: 2.4499423503875732
Validation loss: 2.0453158822110904

Epoch: 136| Step: 0
Training loss: 2.4517784118652344
Validation loss: 2.084962237265802

Epoch: 5| Step: 1
Training loss: 1.7634786367416382
Validation loss: 2.053535633189704

Epoch: 5| Step: 2
Training loss: 2.025827407836914
Validation loss: 2.0276873521907355

Epoch: 5| Step: 3
Training loss: 1.9204734563827515
Validation loss: 2.044525659212502

Epoch: 5| Step: 4
Training loss: 2.3849539756774902
Validation loss: 2.075389728751234

Epoch: 5| Step: 5
Training loss: 2.1529059410095215
Validation loss: 2.0379170858731834

Epoch: 5| Step: 6
Training loss: 2.211252450942993
Validation loss: 2.0434840699677825

Epoch: 5| Step: 7
Training loss: 2.3987534046173096
Validation loss: 2.0274523650446246

Epoch: 5| Step: 8
Training loss: 2.4208836555480957
Validation loss: 2.006285536673761

Epoch: 5| Step: 9
Training loss: 1.9630584716796875
Validation loss: 2.0293338811525734

Epoch: 5| Step: 10
Training loss: 2.354316473007202
Validation loss: 2.0233970572871547

Epoch: 137| Step: 0
Training loss: 2.073631763458252
Validation loss: 2.0431816488183956

Epoch: 5| Step: 1
Training loss: 2.2033839225769043
Validation loss: 2.0537603362914054

Epoch: 5| Step: 2
Training loss: 2.163611650466919
Validation loss: 2.020565584141721

Epoch: 5| Step: 3
Training loss: 2.1278388500213623
Validation loss: 2.042136758886358

Epoch: 5| Step: 4
Training loss: 2.458646774291992
Validation loss: 2.025679721627184

Epoch: 5| Step: 5
Training loss: 2.3102803230285645
Validation loss: 1.994673107260017

Epoch: 5| Step: 6
Training loss: 2.262303352355957
Validation loss: 2.024886954215265

Epoch: 5| Step: 7
Training loss: 2.2748303413391113
Validation loss: 2.070294451969926

Epoch: 5| Step: 8
Training loss: 2.065758466720581
Validation loss: 2.036813474470569

Epoch: 5| Step: 9
Training loss: 1.6690441370010376
Validation loss: 2.029491909088627

Epoch: 5| Step: 10
Training loss: 2.467827320098877
Validation loss: 2.002903894711566

Epoch: 138| Step: 0
Training loss: 2.0744364261627197
Validation loss: 2.0352836590941235

Epoch: 5| Step: 1
Training loss: 2.1170153617858887
Validation loss: 2.053177318265361

Epoch: 5| Step: 2
Training loss: 2.501642942428589
Validation loss: 2.053837171164892

Epoch: 5| Step: 3
Training loss: 2.2194936275482178
Validation loss: 2.0539062920437066

Epoch: 5| Step: 4
Training loss: 3.0942115783691406
Validation loss: 2.014109469229175

Epoch: 5| Step: 5
Training loss: 2.1450817584991455
Validation loss: 1.9785231736398512

Epoch: 5| Step: 6
Training loss: 2.5115890502929688
Validation loss: 1.9773145055258146

Epoch: 5| Step: 7
Training loss: 2.077420473098755
Validation loss: 2.0187561383811374

Epoch: 5| Step: 8
Training loss: 1.2937819957733154
Validation loss: 1.9860513594842726

Epoch: 5| Step: 9
Training loss: 2.215150833129883
Validation loss: 2.020007352675161

Epoch: 5| Step: 10
Training loss: 1.70106041431427
Validation loss: 2.054987358790572

Epoch: 139| Step: 0
Training loss: 2.5801098346710205
Validation loss: 1.9645839750125844

Epoch: 5| Step: 1
Training loss: 2.257495403289795
Validation loss: 2.0175321871234524

Epoch: 5| Step: 2
Training loss: 2.2087223529815674
Validation loss: 2.027275913505144

Epoch: 5| Step: 3
Training loss: 1.8354942798614502
Validation loss: 2.03545138143724

Epoch: 5| Step: 4
Training loss: 1.947382926940918
Validation loss: 2.012663866883965

Epoch: 5| Step: 5
Training loss: 1.9213787317276
Validation loss: 2.0359894357701784

Epoch: 5| Step: 6
Training loss: 1.7428748607635498
Validation loss: 2.0444264027380172

Epoch: 5| Step: 7
Training loss: 2.7320380210876465
Validation loss: 2.0205872853597007

Epoch: 5| Step: 8
Training loss: 2.125274181365967
Validation loss: 2.048359740164972

Epoch: 5| Step: 9
Training loss: 2.521879196166992
Validation loss: 2.0118290673020067

Epoch: 5| Step: 10
Training loss: 2.2068724632263184
Validation loss: 2.003324495848789

Epoch: 140| Step: 0
Training loss: 2.0224759578704834
Validation loss: 2.035184121900989

Epoch: 5| Step: 1
Training loss: 2.5090126991271973
Validation loss: 2.05594697049869

Epoch: 5| Step: 2
Training loss: 2.3297131061553955
Validation loss: 2.0244898052625757

Epoch: 5| Step: 3
Training loss: 2.201612710952759
Validation loss: 2.0535372944288355

Epoch: 5| Step: 4
Training loss: 1.8902431726455688
Validation loss: 2.0523591092837754

Epoch: 5| Step: 5
Training loss: 1.7987334728240967
Validation loss: 2.040813534490524

Epoch: 5| Step: 6
Training loss: 2.694955825805664
Validation loss: 2.068679682670101

Epoch: 5| Step: 7
Training loss: 1.8247902393341064
Validation loss: 2.0432542575302945

Epoch: 5| Step: 8
Training loss: 1.9300343990325928
Validation loss: 2.044307420330663

Epoch: 5| Step: 9
Training loss: 2.155973196029663
Validation loss: 2.0671936747848347

Epoch: 5| Step: 10
Training loss: 2.565993309020996
Validation loss: 2.0585296718023156

Epoch: 141| Step: 0
Training loss: 1.882261872291565
Validation loss: 2.0619410930141324

Epoch: 5| Step: 1
Training loss: 1.554613709449768
Validation loss: 2.040422301138601

Epoch: 5| Step: 2
Training loss: 2.8352339267730713
Validation loss: 2.036349577288474

Epoch: 5| Step: 3
Training loss: 2.121232509613037
Validation loss: 2.057086472870201

Epoch: 5| Step: 4
Training loss: 2.491259813308716
Validation loss: 2.038148853086656

Epoch: 5| Step: 5
Training loss: 2.5830533504486084
Validation loss: 2.0211734515364452

Epoch: 5| Step: 6
Training loss: 1.757761001586914
Validation loss: 2.0585446460272676

Epoch: 5| Step: 7
Training loss: 2.304487705230713
Validation loss: 2.0299470437470304

Epoch: 5| Step: 8
Training loss: 1.7590019702911377
Validation loss: 2.042636017645559

Epoch: 5| Step: 9
Training loss: 2.554971694946289
Validation loss: 2.1140851538668395

Epoch: 5| Step: 10
Training loss: 2.2245984077453613
Validation loss: 2.0421314726593676

Epoch: 142| Step: 0
Training loss: 2.498135805130005
Validation loss: 2.053865376339164

Epoch: 5| Step: 1
Training loss: 2.4529333114624023
Validation loss: 2.026187409636795

Epoch: 5| Step: 2
Training loss: 1.9302070140838623
Validation loss: 2.0353419447457917

Epoch: 5| Step: 3
Training loss: 1.9870163202285767
Validation loss: 2.0554561538081013

Epoch: 5| Step: 4
Training loss: 2.801359176635742
Validation loss: 2.0316080277965916

Epoch: 5| Step: 5
Training loss: 1.464358925819397
Validation loss: 2.044858371057818

Epoch: 5| Step: 6
Training loss: 1.9537101984024048
Validation loss: 2.0874279699017926

Epoch: 5| Step: 7
Training loss: 1.8172729015350342
Validation loss: 2.0281201767665085

Epoch: 5| Step: 8
Training loss: 2.7316648960113525
Validation loss: 2.0443157483172674

Epoch: 5| Step: 9
Training loss: 2.1491599082946777
Validation loss: 2.044519914093838

Epoch: 5| Step: 10
Training loss: 2.2454254627227783
Validation loss: 2.032290022860291

Epoch: 143| Step: 0
Training loss: 1.4572725296020508
Validation loss: 2.034337716717874

Epoch: 5| Step: 1
Training loss: 1.6068971157073975
Validation loss: 2.018103366257042

Epoch: 5| Step: 2
Training loss: 1.810614824295044
Validation loss: 2.0068478866290023

Epoch: 5| Step: 3
Training loss: 2.471027374267578
Validation loss: 2.0294111095448977

Epoch: 5| Step: 4
Training loss: 2.374863862991333
Validation loss: 2.0297995716012935

Epoch: 5| Step: 5
Training loss: 2.0309791564941406
Validation loss: 2.0292376087557886

Epoch: 5| Step: 6
Training loss: 2.497141122817993
Validation loss: 2.035146647884

Epoch: 5| Step: 7
Training loss: 3.129528284072876
Validation loss: 2.020718397632722

Epoch: 5| Step: 8
Training loss: 2.4354195594787598
Validation loss: 1.9828920325925272

Epoch: 5| Step: 9
Training loss: 1.6783714294433594
Validation loss: 2.0587624221719723

Epoch: 5| Step: 10
Training loss: 2.3876748085021973
Validation loss: 2.0450206507918653

Epoch: 144| Step: 0
Training loss: 2.0528054237365723
Validation loss: 2.0281911319301975

Epoch: 5| Step: 1
Training loss: 1.9344650506973267
Validation loss: 2.0421237561010543

Epoch: 5| Step: 2
Training loss: 2.5259416103363037
Validation loss: 2.017711849622829

Epoch: 5| Step: 3
Training loss: 1.7048728466033936
Validation loss: 2.037554174341181

Epoch: 5| Step: 4
Training loss: 2.578610897064209
Validation loss: 2.0155105155001403

Epoch: 5| Step: 5
Training loss: 2.4252853393554688
Validation loss: 2.014361504585512

Epoch: 5| Step: 6
Training loss: 2.735619306564331
Validation loss: 2.0519858714072936

Epoch: 5| Step: 7
Training loss: 1.832956075668335
Validation loss: 2.030058183977681

Epoch: 5| Step: 8
Training loss: 2.176344394683838
Validation loss: 2.0450090003269974

Epoch: 5| Step: 9
Training loss: 1.8217065334320068
Validation loss: 2.0216859540631695

Epoch: 5| Step: 10
Training loss: 2.2192869186401367
Validation loss: 2.0383891136415544

Epoch: 145| Step: 0
Training loss: 2.1413464546203613
Validation loss: 2.056850294913015

Epoch: 5| Step: 1
Training loss: 2.062910795211792
Validation loss: 2.0178029485928115

Epoch: 5| Step: 2
Training loss: 2.3284683227539062
Validation loss: 2.0830339257435133

Epoch: 5| Step: 3
Training loss: 2.4268908500671387
Validation loss: 2.037194146904894

Epoch: 5| Step: 4
Training loss: 2.0813345909118652
Validation loss: 2.0035187864816315

Epoch: 5| Step: 5
Training loss: 2.1008095741271973
Validation loss: 2.0330457866832776

Epoch: 5| Step: 6
Training loss: 2.946263551712036
Validation loss: 2.021379263170304

Epoch: 5| Step: 7
Training loss: 2.067573308944702
Validation loss: 2.0512303447210662

Epoch: 5| Step: 8
Training loss: 1.965519666671753
Validation loss: 2.0454910801303003

Epoch: 5| Step: 9
Training loss: 1.5456995964050293
Validation loss: 2.066132301925331

Epoch: 5| Step: 10
Training loss: 2.012194871902466
Validation loss: 2.0708698072741107

Epoch: 146| Step: 0
Training loss: 1.731971025466919
Validation loss: 2.0119413150254117

Epoch: 5| Step: 1
Training loss: 1.926107406616211
Validation loss: 2.033005443952417

Epoch: 5| Step: 2
Training loss: 2.4749834537506104
Validation loss: 2.018295777741299

Epoch: 5| Step: 3
Training loss: 1.671130895614624
Validation loss: 2.0240185491500364

Epoch: 5| Step: 4
Training loss: 2.3136391639709473
Validation loss: 2.0570422680147233

Epoch: 5| Step: 5
Training loss: 2.282951831817627
Validation loss: 2.0145442357627292

Epoch: 5| Step: 6
Training loss: 2.269993543624878
Validation loss: 2.0184887352810112

Epoch: 5| Step: 7
Training loss: 2.791170358657837
Validation loss: 2.0291151205698648

Epoch: 5| Step: 8
Training loss: 2.0150442123413086
Validation loss: 2.015111982181508

Epoch: 5| Step: 9
Training loss: 2.0932974815368652
Validation loss: 2.0263765550428823

Epoch: 5| Step: 10
Training loss: 2.037562608718872
Validation loss: 2.041841447994273

Epoch: 147| Step: 0
Training loss: 2.2572758197784424
Validation loss: 2.0347291141427974

Epoch: 5| Step: 1
Training loss: 2.8768529891967773
Validation loss: 2.0337342177667925

Epoch: 5| Step: 2
Training loss: 2.354367733001709
Validation loss: 2.037672410729111

Epoch: 5| Step: 3
Training loss: 2.6550838947296143
Validation loss: 2.028874425477879

Epoch: 5| Step: 4
Training loss: 2.181291103363037
Validation loss: 2.0266416867574057

Epoch: 5| Step: 5
Training loss: 2.1172597408294678
Validation loss: 2.0307893022414176

Epoch: 5| Step: 6
Training loss: 1.5794425010681152
Validation loss: 2.029823668541447

Epoch: 5| Step: 7
Training loss: 2.305595636367798
Validation loss: 1.9991668373025873

Epoch: 5| Step: 8
Training loss: 1.920122504234314
Validation loss: 2.042287060009536

Epoch: 5| Step: 9
Training loss: 1.657983422279358
Validation loss: 2.014626015899002

Epoch: 5| Step: 10
Training loss: 2.0081288814544678
Validation loss: 1.9958840672687819

Epoch: 148| Step: 0
Training loss: 2.1585941314697266
Validation loss: 2.0336650097241966

Epoch: 5| Step: 1
Training loss: 2.334346055984497
Validation loss: 2.012855681039954

Epoch: 5| Step: 2
Training loss: 2.5332813262939453
Validation loss: 2.0316512712868313

Epoch: 5| Step: 3
Training loss: 2.704226493835449
Validation loss: 1.9973835816947363

Epoch: 5| Step: 4
Training loss: 2.176124095916748
Validation loss: 2.005325284055484

Epoch: 5| Step: 5
Training loss: 1.8883459568023682
Validation loss: 2.0092531942552134

Epoch: 5| Step: 6
Training loss: 1.5825024843215942
Validation loss: 1.996142768090771

Epoch: 5| Step: 7
Training loss: 2.3079469203948975
Validation loss: 2.0341938323872064

Epoch: 5| Step: 8
Training loss: 1.3287639617919922
Validation loss: 2.038008406598081

Epoch: 5| Step: 9
Training loss: 2.451655864715576
Validation loss: 2.0610831424754155

Epoch: 5| Step: 10
Training loss: 2.6231307983398438
Validation loss: 2.0094013137202107

Epoch: 149| Step: 0
Training loss: 1.5280336141586304
Validation loss: 2.0114443468791183

Epoch: 5| Step: 1
Training loss: 2.081963062286377
Validation loss: 1.9968980589220602

Epoch: 5| Step: 2
Training loss: 2.3423526287078857
Validation loss: 2.0347184775978007

Epoch: 5| Step: 3
Training loss: 1.8772857189178467
Validation loss: 2.050283544807024

Epoch: 5| Step: 4
Training loss: 2.0871987342834473
Validation loss: 1.9883248088180379

Epoch: 5| Step: 5
Training loss: 2.097391128540039
Validation loss: 2.0225227545666438

Epoch: 5| Step: 6
Training loss: 2.3882696628570557
Validation loss: 2.0096435239238124

Epoch: 5| Step: 7
Training loss: 2.5519301891326904
Validation loss: 2.0355932815100557

Epoch: 5| Step: 8
Training loss: 1.8741390705108643
Validation loss: 2.026306565089892

Epoch: 5| Step: 9
Training loss: 2.868147373199463
Validation loss: 2.05099682910468

Epoch: 5| Step: 10
Training loss: 2.0042755603790283
Validation loss: 2.0504500468571982

Epoch: 150| Step: 0
Training loss: 2.103893756866455
Validation loss: 2.0144593267030615

Epoch: 5| Step: 1
Training loss: 1.968906044960022
Validation loss: 2.05300937544915

Epoch: 5| Step: 2
Training loss: 2.4551422595977783
Validation loss: 2.0365391969680786

Epoch: 5| Step: 3
Training loss: 2.0961685180664062
Validation loss: 2.0259668109237507

Epoch: 5| Step: 4
Training loss: 2.173541784286499
Validation loss: 2.0200985977726598

Epoch: 5| Step: 5
Training loss: 2.00356125831604
Validation loss: 2.0786888650668565

Epoch: 5| Step: 6
Training loss: 1.990579605102539
Validation loss: 2.0324383115255706

Epoch: 5| Step: 7
Training loss: 2.0746426582336426
Validation loss: 2.069442815678094

Epoch: 5| Step: 8
Training loss: 2.882615327835083
Validation loss: 2.040338288071335

Epoch: 5| Step: 9
Training loss: 2.142824172973633
Validation loss: 2.039462189520559

Epoch: 5| Step: 10
Training loss: 2.1176929473876953
Validation loss: 2.0666901398730535

Epoch: 151| Step: 0
Training loss: 1.618766188621521
Validation loss: 2.0957182632979525

Epoch: 5| Step: 1
Training loss: 2.192859649658203
Validation loss: 2.0508057917318037

Epoch: 5| Step: 2
Training loss: 2.2187187671661377
Validation loss: 2.0727511323908323

Epoch: 5| Step: 3
Training loss: 2.417814254760742
Validation loss: 2.0473882254733833

Epoch: 5| Step: 4
Training loss: 2.213593006134033
Validation loss: 2.051931850371822

Epoch: 5| Step: 5
Training loss: 2.2035679817199707
Validation loss: 2.021537559006804

Epoch: 5| Step: 6
Training loss: 2.625718593597412
Validation loss: 2.056909006129029

Epoch: 5| Step: 7
Training loss: 2.299299478530884
Validation loss: 2.0012973559800016

Epoch: 5| Step: 8
Training loss: 2.102107524871826
Validation loss: 2.047910051961099

Epoch: 5| Step: 9
Training loss: 1.9387710094451904
Validation loss: 2.0360816268510717

Epoch: 5| Step: 10
Training loss: 1.8312244415283203
Validation loss: 2.0366532161671627

Epoch: 152| Step: 0
Training loss: 2.2923130989074707
Validation loss: 2.075326547827772

Epoch: 5| Step: 1
Training loss: 2.1911063194274902
Validation loss: 2.0258311046067106

Epoch: 5| Step: 2
Training loss: 1.8672149181365967
Validation loss: 2.0403829441275647

Epoch: 5| Step: 3
Training loss: 2.437744617462158
Validation loss: 2.0592535618812806

Epoch: 5| Step: 4
Training loss: 2.1768720149993896
Validation loss: 2.0494678507569017

Epoch: 5| Step: 5
Training loss: 2.306972026824951
Validation loss: 2.052234322794022

Epoch: 5| Step: 6
Training loss: 1.7045894861221313
Validation loss: 2.1017441352208457

Epoch: 5| Step: 7
Training loss: 2.619173526763916
Validation loss: 2.055240801585618

Epoch: 5| Step: 8
Training loss: 2.1986310482025146
Validation loss: 2.028801102792063

Epoch: 5| Step: 9
Training loss: 2.0607340335845947
Validation loss: 2.0296434587047947

Epoch: 5| Step: 10
Training loss: 1.971400260925293
Validation loss: 2.039525144843645

Epoch: 153| Step: 0
Training loss: 2.6780903339385986
Validation loss: 2.048882892054896

Epoch: 5| Step: 1
Training loss: 2.249431848526001
Validation loss: 2.0393452759711974

Epoch: 5| Step: 2
Training loss: 1.986607313156128
Validation loss: 2.0412224390173472

Epoch: 5| Step: 3
Training loss: 2.238793134689331
Validation loss: 2.073175555916243

Epoch: 5| Step: 4
Training loss: 2.742373466491699
Validation loss: 2.0733698747491323

Epoch: 5| Step: 5
Training loss: 1.6919113397598267
Validation loss: 2.068977778957736

Epoch: 5| Step: 6
Training loss: 2.4005966186523438
Validation loss: 2.028941954335859

Epoch: 5| Step: 7
Training loss: 1.4517178535461426
Validation loss: 2.0402766786595827

Epoch: 5| Step: 8
Training loss: 1.9430491924285889
Validation loss: 2.039246054105861

Epoch: 5| Step: 9
Training loss: 2.3857808113098145
Validation loss: 2.0370307289144045

Epoch: 5| Step: 10
Training loss: 1.9360367059707642
Validation loss: 2.0276394223654144

Epoch: 154| Step: 0
Training loss: 1.7118864059448242
Validation loss: 2.040672291991531

Epoch: 5| Step: 1
Training loss: 2.62773060798645
Validation loss: 2.0084089758575603

Epoch: 5| Step: 2
Training loss: 1.6098461151123047
Validation loss: 2.0355360302873837

Epoch: 5| Step: 3
Training loss: 1.6572767496109009
Validation loss: 2.0547806934643815

Epoch: 5| Step: 4
Training loss: 2.8343043327331543
Validation loss: 2.062876009172009

Epoch: 5| Step: 5
Training loss: 2.3622817993164062
Validation loss: 2.0483260129087713

Epoch: 5| Step: 6
Training loss: 2.915526866912842
Validation loss: 2.088838597779633

Epoch: 5| Step: 7
Training loss: 1.3776237964630127
Validation loss: 2.0335532311470277

Epoch: 5| Step: 8
Training loss: 2.3118882179260254
Validation loss: 2.0474692967630204

Epoch: 5| Step: 9
Training loss: 1.9967858791351318
Validation loss: 2.0706220826795025

Epoch: 5| Step: 10
Training loss: 2.4659368991851807
Validation loss: 2.0426855010371052

Epoch: 155| Step: 0
Training loss: 2.435852527618408
Validation loss: 2.0570024367301696

Epoch: 5| Step: 1
Training loss: 1.9950100183486938
Validation loss: 2.089904122455146

Epoch: 5| Step: 2
Training loss: 1.8619334697723389
Validation loss: 2.041875123977661

Epoch: 5| Step: 3
Training loss: 1.9737169742584229
Validation loss: 2.081700955667803

Epoch: 5| Step: 4
Training loss: 2.58937406539917
Validation loss: 2.0507637685345066

Epoch: 5| Step: 5
Training loss: 1.9710819721221924
Validation loss: 2.070539338614351

Epoch: 5| Step: 6
Training loss: 2.6590657234191895
Validation loss: 2.103696280910123

Epoch: 5| Step: 7
Training loss: 1.853416085243225
Validation loss: 2.0529920503657353

Epoch: 5| Step: 8
Training loss: 2.412045478820801
Validation loss: 2.0426892362615114

Epoch: 5| Step: 9
Training loss: 1.6524381637573242
Validation loss: 2.0952175714636363

Epoch: 5| Step: 10
Training loss: 2.636003255844116
Validation loss: 2.0658797102589763

Epoch: 156| Step: 0
Training loss: 2.2861201763153076
Validation loss: 2.0916366936058126

Epoch: 5| Step: 1
Training loss: 2.4677023887634277
Validation loss: 2.0655284594464045

Epoch: 5| Step: 2
Training loss: 2.1771841049194336
Validation loss: 2.0450628752349527

Epoch: 5| Step: 3
Training loss: 2.058427333831787
Validation loss: 2.0369197553203953

Epoch: 5| Step: 4
Training loss: 1.7389167547225952
Validation loss: 2.015500137882848

Epoch: 5| Step: 5
Training loss: 1.713477373123169
Validation loss: 2.0286253600992183

Epoch: 5| Step: 6
Training loss: 2.422145366668701
Validation loss: 2.053003482921149

Epoch: 5| Step: 7
Training loss: 1.7643253803253174
Validation loss: 2.0205799302747174

Epoch: 5| Step: 8
Training loss: 2.583641529083252
Validation loss: 1.992431503470226

Epoch: 5| Step: 9
Training loss: 2.4742188453674316
Validation loss: 2.0245394732362483

Epoch: 5| Step: 10
Training loss: 2.0788989067077637
Validation loss: 2.054247825376449

Epoch: 157| Step: 0
Training loss: 2.151029109954834
Validation loss: 2.0349448919296265

Epoch: 5| Step: 1
Training loss: 1.5805898904800415
Validation loss: 2.042395571226715

Epoch: 5| Step: 2
Training loss: 2.1034717559814453
Validation loss: 2.0293906119561966

Epoch: 5| Step: 3
Training loss: 2.6042122840881348
Validation loss: 2.0366393212349183

Epoch: 5| Step: 4
Training loss: 1.6542352437973022
Validation loss: 2.021012547195599

Epoch: 5| Step: 5
Training loss: 2.8388009071350098
Validation loss: 2.0249174089841944

Epoch: 5| Step: 6
Training loss: 2.14738392829895
Validation loss: 2.015371968669276

Epoch: 5| Step: 7
Training loss: 2.527238368988037
Validation loss: 2.0262610707231747

Epoch: 5| Step: 8
Training loss: 2.5416252613067627
Validation loss: 2.0318420138410342

Epoch: 5| Step: 9
Training loss: 1.9394162893295288
Validation loss: 2.0391954939852477

Epoch: 5| Step: 10
Training loss: 1.7020940780639648
Validation loss: 2.0362833853690856

Epoch: 158| Step: 0
Training loss: 1.9165242910385132
Validation loss: 2.0174116421771306

Epoch: 5| Step: 1
Training loss: 2.1705825328826904
Validation loss: 2.072732094795473

Epoch: 5| Step: 2
Training loss: 1.4103187322616577
Validation loss: 2.0587531084655435

Epoch: 5| Step: 3
Training loss: 2.4102654457092285
Validation loss: 2.0070344824944772

Epoch: 5| Step: 4
Training loss: 1.9569495916366577
Validation loss: 2.0658805062693935

Epoch: 5| Step: 5
Training loss: 2.142171859741211
Validation loss: 2.0611603785586614

Epoch: 5| Step: 6
Training loss: 2.893767833709717
Validation loss: 2.0398383166200373

Epoch: 5| Step: 7
Training loss: 1.9501479864120483
Validation loss: 2.0501356188968947

Epoch: 5| Step: 8
Training loss: 2.070082187652588
Validation loss: 1.9995653078120241

Epoch: 5| Step: 9
Training loss: 2.4707045555114746
Validation loss: 2.085715501539169

Epoch: 5| Step: 10
Training loss: 2.241206169128418
Validation loss: 2.0536131115369898

Epoch: 159| Step: 0
Training loss: 2.463690996170044
Validation loss: 2.0457732882550967

Epoch: 5| Step: 1
Training loss: 1.7759777307510376
Validation loss: 2.0225921574459282

Epoch: 5| Step: 2
Training loss: 2.0951738357543945
Validation loss: 2.0658503399100354

Epoch: 5| Step: 3
Training loss: 1.908421516418457
Validation loss: 2.062861145183604

Epoch: 5| Step: 4
Training loss: 2.3305857181549072
Validation loss: 2.0643372407523533

Epoch: 5| Step: 5
Training loss: 1.8809309005737305
Validation loss: 2.073796646569365

Epoch: 5| Step: 6
Training loss: 2.6078341007232666
Validation loss: 2.0700189644290554

Epoch: 5| Step: 7
Training loss: 2.072432279586792
Validation loss: 2.0633947336545555

Epoch: 5| Step: 8
Training loss: 1.782904863357544
Validation loss: 2.0908811605104836

Epoch: 5| Step: 9
Training loss: 2.6746678352355957
Validation loss: 2.079104995214811

Epoch: 5| Step: 10
Training loss: 2.141880989074707
Validation loss: 2.0754255915200837

Epoch: 160| Step: 0
Training loss: 1.7527320384979248
Validation loss: 2.0361421646610385

Epoch: 5| Step: 1
Training loss: 1.9637031555175781
Validation loss: 2.032176145943262

Epoch: 5| Step: 2
Training loss: 2.3125052452087402
Validation loss: 2.05752214565072

Epoch: 5| Step: 3
Training loss: 2.28021502494812
Validation loss: 2.056759556134542

Epoch: 5| Step: 4
Training loss: 2.192335367202759
Validation loss: 2.0809363062663744

Epoch: 5| Step: 5
Training loss: 1.8309648036956787
Validation loss: 2.0613836062851774

Epoch: 5| Step: 6
Training loss: 2.427121639251709
Validation loss: 2.03017528851827

Epoch: 5| Step: 7
Training loss: 2.3782436847686768
Validation loss: 2.0844073052047403

Epoch: 5| Step: 8
Training loss: 2.554591417312622
Validation loss: 2.0911104448380007

Epoch: 5| Step: 9
Training loss: 1.4467769861221313
Validation loss: 2.0298572509519515

Epoch: 5| Step: 10
Training loss: 2.761320114135742
Validation loss: 2.0461603826092136

Epoch: 161| Step: 0
Training loss: 2.287978172302246
Validation loss: 2.036191475006842

Epoch: 5| Step: 1
Training loss: 2.453032970428467
Validation loss: 2.0539602874427714

Epoch: 5| Step: 2
Training loss: 2.470411777496338
Validation loss: 2.0352359740964827

Epoch: 5| Step: 3
Training loss: 2.1929385662078857
Validation loss: 2.0265839228066067

Epoch: 5| Step: 4
Training loss: 2.41441011428833
Validation loss: 2.034204808614587

Epoch: 5| Step: 5
Training loss: 1.992876648902893
Validation loss: 2.051002025604248

Epoch: 5| Step: 6
Training loss: 2.3826191425323486
Validation loss: 2.062247310915301

Epoch: 5| Step: 7
Training loss: 2.1160833835601807
Validation loss: 2.033925232066903

Epoch: 5| Step: 8
Training loss: 2.074483871459961
Validation loss: 2.017028224083685

Epoch: 5| Step: 9
Training loss: 1.9662885665893555
Validation loss: 2.0648995522529847

Epoch: 5| Step: 10
Training loss: 1.5217986106872559
Validation loss: 2.0434356684325845

Epoch: 162| Step: 0
Training loss: 1.767635703086853
Validation loss: 2.0585352105479084

Epoch: 5| Step: 1
Training loss: 1.8217474222183228
Validation loss: 2.0337888604851178

Epoch: 5| Step: 2
Training loss: 1.9324076175689697
Validation loss: 2.0242946609374015

Epoch: 5| Step: 3
Training loss: 2.3994596004486084
Validation loss: 2.003171475984717

Epoch: 5| Step: 4
Training loss: 2.338383197784424
Validation loss: 2.0154246989116875

Epoch: 5| Step: 5
Training loss: 2.09450101852417
Validation loss: 1.9852110826840965

Epoch: 5| Step: 6
Training loss: 2.9008705615997314
Validation loss: 2.0259473810913744

Epoch: 5| Step: 7
Training loss: 2.633432149887085
Validation loss: 2.0301463706519014

Epoch: 5| Step: 8
Training loss: 1.7021936178207397
Validation loss: 2.0281768742428032

Epoch: 5| Step: 9
Training loss: 1.7238664627075195
Validation loss: 2.0474427746188257

Epoch: 5| Step: 10
Training loss: 2.4386098384857178
Validation loss: 2.0282636688601587

Epoch: 163| Step: 0
Training loss: 2.5111277103424072
Validation loss: 1.9868454856257285

Epoch: 5| Step: 1
Training loss: 2.3301265239715576
Validation loss: 2.0485345496926257

Epoch: 5| Step: 2
Training loss: 1.6007217168807983
Validation loss: 2.021575694443077

Epoch: 5| Step: 3
Training loss: 2.0367462635040283
Validation loss: 2.0256124722060336

Epoch: 5| Step: 4
Training loss: 2.0047073364257812
Validation loss: 2.0410595145276798

Epoch: 5| Step: 5
Training loss: 1.8395893573760986
Validation loss: 1.9979389816202142

Epoch: 5| Step: 6
Training loss: 1.6843891143798828
Validation loss: 2.0236904621124268

Epoch: 5| Step: 7
Training loss: 2.542994976043701
Validation loss: 2.0152614014123076

Epoch: 5| Step: 8
Training loss: 2.4018032550811768
Validation loss: 2.0564326714443903

Epoch: 5| Step: 9
Training loss: 2.1596789360046387
Validation loss: 2.0179061274374686

Epoch: 5| Step: 10
Training loss: 2.66229510307312
Validation loss: 2.0146874074013

Epoch: 164| Step: 0
Training loss: 1.8587478399276733
Validation loss: 2.0062825372142177

Epoch: 5| Step: 1
Training loss: 2.4175782203674316
Validation loss: 2.033812584415559

Epoch: 5| Step: 2
Training loss: 1.7500295639038086
Validation loss: 2.015462657456757

Epoch: 5| Step: 3
Training loss: 2.338409662246704
Validation loss: 2.0522394795571604

Epoch: 5| Step: 4
Training loss: 2.0166783332824707
Validation loss: 1.9957051251524238

Epoch: 5| Step: 5
Training loss: 2.2511725425720215
Validation loss: 2.0228472409709806

Epoch: 5| Step: 6
Training loss: 2.136776924133301
Validation loss: 2.0264175784203315

Epoch: 5| Step: 7
Training loss: 2.3111751079559326
Validation loss: 1.9965468914278093

Epoch: 5| Step: 8
Training loss: 2.29425311088562
Validation loss: 2.0405017791255826

Epoch: 5| Step: 9
Training loss: 2.4203524589538574
Validation loss: 2.0363391368619856

Epoch: 5| Step: 10
Training loss: 1.8188228607177734
Validation loss: 2.055317565958987

Epoch: 165| Step: 0
Training loss: 1.4980931282043457
Validation loss: 2.021850191136842

Epoch: 5| Step: 1
Training loss: 2.0896201133728027
Validation loss: 2.0233358247305757

Epoch: 5| Step: 2
Training loss: 1.930350661277771
Validation loss: 2.068111051795303

Epoch: 5| Step: 3
Training loss: 2.5713839530944824
Validation loss: 2.0238282834329913

Epoch: 5| Step: 4
Training loss: 2.0188839435577393
Validation loss: 2.090015234485749

Epoch: 5| Step: 5
Training loss: 2.1163976192474365
Validation loss: 2.0341991019505326

Epoch: 5| Step: 6
Training loss: 2.5733978748321533
Validation loss: 2.0753395147221063

Epoch: 5| Step: 7
Training loss: 2.013758897781372
Validation loss: 2.0256121325236496

Epoch: 5| Step: 8
Training loss: 2.510305404663086
Validation loss: 2.077995895057596

Epoch: 5| Step: 9
Training loss: 2.250458002090454
Validation loss: 2.0355305146145564

Epoch: 5| Step: 10
Training loss: 2.2086868286132812
Validation loss: 2.022260360820319

Epoch: 166| Step: 0
Training loss: 2.268198251724243
Validation loss: 2.0448204394309752

Epoch: 5| Step: 1
Training loss: 2.203709602355957
Validation loss: 2.0336384850163616

Epoch: 5| Step: 2
Training loss: 1.6243642568588257
Validation loss: 2.053781267135374

Epoch: 5| Step: 3
Training loss: 2.5707263946533203
Validation loss: 2.0100838702212096

Epoch: 5| Step: 4
Training loss: 1.7903289794921875
Validation loss: 2.042278466686126

Epoch: 5| Step: 5
Training loss: 2.1844091415405273
Validation loss: 2.0397220170626076

Epoch: 5| Step: 6
Training loss: 2.8260273933410645
Validation loss: 2.046845233568581

Epoch: 5| Step: 7
Training loss: 1.9281734228134155
Validation loss: 2.0227529823139148

Epoch: 5| Step: 8
Training loss: 2.1339714527130127
Validation loss: 2.065757715573875

Epoch: 5| Step: 9
Training loss: 2.5112173557281494
Validation loss: 2.0490519795366513

Epoch: 5| Step: 10
Training loss: 1.803334355354309
Validation loss: 2.0709342084905153

Epoch: 167| Step: 0
Training loss: 2.1116995811462402
Validation loss: 2.0344171985503166

Epoch: 5| Step: 1
Training loss: 1.5952939987182617
Validation loss: 2.0168108760669665

Epoch: 5| Step: 2
Training loss: 1.8442096710205078
Validation loss: 2.000184057861246

Epoch: 5| Step: 3
Training loss: 1.897534966468811
Validation loss: 2.0366809098951277

Epoch: 5| Step: 4
Training loss: 1.8569610118865967
Validation loss: 2.021130459282988

Epoch: 5| Step: 5
Training loss: 2.0578086376190186
Validation loss: 2.05963074263706

Epoch: 5| Step: 6
Training loss: 3.386730194091797
Validation loss: 1.9964323146368868

Epoch: 5| Step: 7
Training loss: 2.379190444946289
Validation loss: 2.0162814842757357

Epoch: 5| Step: 8
Training loss: 1.8304970264434814
Validation loss: 2.023911281298566

Epoch: 5| Step: 9
Training loss: 2.192981719970703
Validation loss: 2.0502583749832644

Epoch: 5| Step: 10
Training loss: 2.3371827602386475
Validation loss: 2.038222474436606

Epoch: 168| Step: 0
Training loss: 2.2809395790100098
Validation loss: 2.0197422337788407

Epoch: 5| Step: 1
Training loss: 2.144270420074463
Validation loss: 2.033576624367827

Epoch: 5| Step: 2
Training loss: 2.1122162342071533
Validation loss: 2.0347551581680134

Epoch: 5| Step: 3
Training loss: 2.4225053787231445
Validation loss: 2.071406341368152

Epoch: 5| Step: 4
Training loss: 2.0753965377807617
Validation loss: 2.078253630668886

Epoch: 5| Step: 5
Training loss: 2.3303580284118652
Validation loss: 2.0343187829499603

Epoch: 5| Step: 6
Training loss: 2.3760616779327393
Validation loss: 2.0502656121407785

Epoch: 5| Step: 7
Training loss: 1.8287467956542969
Validation loss: 2.024251366174349

Epoch: 5| Step: 8
Training loss: 2.1202473640441895
Validation loss: 2.0144735715722524

Epoch: 5| Step: 9
Training loss: 1.5424606800079346
Validation loss: 2.039792578707459

Epoch: 5| Step: 10
Training loss: 2.2912850379943848
Validation loss: 2.038371188666231

Epoch: 169| Step: 0
Training loss: 1.72415030002594
Validation loss: 2.004078390777752

Epoch: 5| Step: 1
Training loss: 2.193207263946533
Validation loss: 2.036330758884389

Epoch: 5| Step: 2
Training loss: 1.8843435049057007
Validation loss: 2.029865144401468

Epoch: 5| Step: 3
Training loss: 2.5445494651794434
Validation loss: 2.041848712070014

Epoch: 5| Step: 4
Training loss: 2.2964024543762207
Validation loss: 2.0370712754546956

Epoch: 5| Step: 5
Training loss: 1.6548969745635986
Validation loss: 2.0788306420849216

Epoch: 5| Step: 6
Training loss: 2.248321056365967
Validation loss: 2.0667753424695743

Epoch: 5| Step: 7
Training loss: 2.311768054962158
Validation loss: 2.0447936109317246

Epoch: 5| Step: 8
Training loss: 1.414821982383728
Validation loss: 2.021376940511888

Epoch: 5| Step: 9
Training loss: 2.6160964965820312
Validation loss: 2.0464286945199452

Epoch: 5| Step: 10
Training loss: 2.651304006576538
Validation loss: 2.0590704641034527

Epoch: 170| Step: 0
Training loss: 2.245044231414795
Validation loss: 2.04751157247892

Epoch: 5| Step: 1
Training loss: 1.4188485145568848
Validation loss: 2.026401742812126

Epoch: 5| Step: 2
Training loss: 2.092449903488159
Validation loss: 2.0480900733701644

Epoch: 5| Step: 3
Training loss: 1.9913440942764282
Validation loss: 2.0283499353675434

Epoch: 5| Step: 4
Training loss: 2.463459014892578
Validation loss: 2.0345195647208922

Epoch: 5| Step: 5
Training loss: 2.3477797508239746
Validation loss: 1.9968328193951679

Epoch: 5| Step: 6
Training loss: 2.090775728225708
Validation loss: 2.063064008630732

Epoch: 5| Step: 7
Training loss: 2.8057737350463867
Validation loss: 2.010991201605848

Epoch: 5| Step: 8
Training loss: 1.6284507513046265
Validation loss: 2.0558171618369316

Epoch: 5| Step: 9
Training loss: 2.403061866760254
Validation loss: 2.04881529654226

Epoch: 5| Step: 10
Training loss: 2.074049949645996
Validation loss: 2.043685015811715

Epoch: 171| Step: 0
Training loss: 1.9930626153945923
Validation loss: 2.0201137565797374

Epoch: 5| Step: 1
Training loss: 1.9511101245880127
Validation loss: 2.0559999583869852

Epoch: 5| Step: 2
Training loss: 1.9131739139556885
Validation loss: 2.0539095350491103

Epoch: 5| Step: 3
Training loss: 2.681527853012085
Validation loss: 2.0681619541619414

Epoch: 5| Step: 4
Training loss: 1.790819764137268
Validation loss: 2.0706189294015207

Epoch: 5| Step: 5
Training loss: 2.114915132522583
Validation loss: 2.021113029090307

Epoch: 5| Step: 6
Training loss: 2.1370034217834473
Validation loss: 2.0271156077743857

Epoch: 5| Step: 7
Training loss: 2.1956593990325928
Validation loss: 2.0811526724087295

Epoch: 5| Step: 8
Training loss: 2.5537467002868652
Validation loss: 2.0469629841466106

Epoch: 5| Step: 9
Training loss: 1.7428001165390015
Validation loss: 2.048473758082236

Epoch: 5| Step: 10
Training loss: 2.5164241790771484
Validation loss: 2.0279961375780005

Epoch: 172| Step: 0
Training loss: 2.3456931114196777
Validation loss: 1.9769917380425237

Epoch: 5| Step: 1
Training loss: 2.5003936290740967
Validation loss: 2.0662616196499077

Epoch: 5| Step: 2
Training loss: 1.932069182395935
Validation loss: 2.0302528386474936

Epoch: 5| Step: 3
Training loss: 1.6817328929901123
Validation loss: 2.0504103168364494

Epoch: 5| Step: 4
Training loss: 1.69003427028656
Validation loss: 2.0751206439028502

Epoch: 5| Step: 5
Training loss: 2.439786195755005
Validation loss: 2.0528108509637977

Epoch: 5| Step: 6
Training loss: 1.9146744012832642
Validation loss: 2.0455872397268973

Epoch: 5| Step: 7
Training loss: 2.177314281463623
Validation loss: 2.0768449050123974

Epoch: 5| Step: 8
Training loss: 2.25943922996521
Validation loss: 2.0301161389197073

Epoch: 5| Step: 9
Training loss: 2.326350212097168
Validation loss: 2.0368568128155125

Epoch: 5| Step: 10
Training loss: 2.493314504623413
Validation loss: 2.01998915467211

Epoch: 173| Step: 0
Training loss: 2.2221598625183105
Validation loss: 2.0088569002766765

Epoch: 5| Step: 1
Training loss: 1.5375940799713135
Validation loss: 2.0707259255070842

Epoch: 5| Step: 2
Training loss: 2.3999392986297607
Validation loss: 2.0415075876379527

Epoch: 5| Step: 3
Training loss: 2.394479274749756
Validation loss: 2.0318583442318823

Epoch: 5| Step: 4
Training loss: 2.1961452960968018
Validation loss: 2.0400709208621772

Epoch: 5| Step: 5
Training loss: 2.114197254180908
Validation loss: 2.043530470581465

Epoch: 5| Step: 6
Training loss: 1.925210952758789
Validation loss: 2.0287538138769006

Epoch: 5| Step: 7
Training loss: 2.089050769805908
Validation loss: 2.069986097274288

Epoch: 5| Step: 8
Training loss: 2.2414660453796387
Validation loss: 2.041638679401849

Epoch: 5| Step: 9
Training loss: 2.0586254596710205
Validation loss: 2.0352104094720658

Epoch: 5| Step: 10
Training loss: 2.379362106323242
Validation loss: 2.013053683824437

Epoch: 174| Step: 0
Training loss: 2.3559012413024902
Validation loss: 2.046377856244323

Epoch: 5| Step: 1
Training loss: 1.5564290285110474
Validation loss: 2.061461824242787

Epoch: 5| Step: 2
Training loss: 2.016181468963623
Validation loss: 2.011882419227272

Epoch: 5| Step: 3
Training loss: 2.5914833545684814
Validation loss: 2.0524745551488732

Epoch: 5| Step: 4
Training loss: 1.8826160430908203
Validation loss: 2.0339569455833844

Epoch: 5| Step: 5
Training loss: 2.233823299407959
Validation loss: 2.033538426122358

Epoch: 5| Step: 6
Training loss: 2.441293954849243
Validation loss: 2.012928629434237

Epoch: 5| Step: 7
Training loss: 2.0940756797790527
Validation loss: 2.0154379055064213

Epoch: 5| Step: 8
Training loss: 2.147467613220215
Validation loss: 2.0254143886668707

Epoch: 5| Step: 9
Training loss: 1.7973778247833252
Validation loss: 2.0157020476556595

Epoch: 5| Step: 10
Training loss: 2.228980541229248
Validation loss: 2.036675947968678

Epoch: 175| Step: 0
Training loss: 2.468205213546753
Validation loss: 2.0305795874646915

Epoch: 5| Step: 1
Training loss: 1.7484022378921509
Validation loss: 2.022992467367521

Epoch: 5| Step: 2
Training loss: 1.524100422859192
Validation loss: 2.0353386709767003

Epoch: 5| Step: 3
Training loss: 1.7944161891937256
Validation loss: 2.091777358003842

Epoch: 5| Step: 4
Training loss: 2.212702751159668
Validation loss: 2.051938118473176

Epoch: 5| Step: 5
Training loss: 2.2108757495880127
Validation loss: 2.0155445862841863

Epoch: 5| Step: 6
Training loss: 2.147047519683838
Validation loss: 2.0380560198137836

Epoch: 5| Step: 7
Training loss: 2.6695914268493652
Validation loss: 2.0343756291174118

Epoch: 5| Step: 8
Training loss: 2.187507152557373
Validation loss: 2.0636010349437757

Epoch: 5| Step: 9
Training loss: 2.736380100250244
Validation loss: 2.052317734687559

Epoch: 5| Step: 10
Training loss: 1.5859174728393555
Validation loss: 2.058683074930663

Epoch: 176| Step: 0
Training loss: 1.5739103555679321
Validation loss: 2.0435045611473823

Epoch: 5| Step: 1
Training loss: 2.0642361640930176
Validation loss: 2.035664872456622

Epoch: 5| Step: 2
Training loss: 2.091113328933716
Validation loss: 2.0492072310498965

Epoch: 5| Step: 3
Training loss: 2.1498148441314697
Validation loss: 2.040444653521302

Epoch: 5| Step: 4
Training loss: 2.588453769683838
Validation loss: 2.040674683868244

Epoch: 5| Step: 5
Training loss: 1.9187361001968384
Validation loss: 2.0309181649197816

Epoch: 5| Step: 6
Training loss: 1.9285688400268555
Validation loss: 2.012924632718486

Epoch: 5| Step: 7
Training loss: 2.565908908843994
Validation loss: 2.0302550613239245

Epoch: 5| Step: 8
Training loss: 2.2418713569641113
Validation loss: 2.049322989679152

Epoch: 5| Step: 9
Training loss: 2.4812748432159424
Validation loss: 2.0453138889804965

Epoch: 5| Step: 10
Training loss: 1.8011058568954468
Validation loss: 2.000873081145748

Epoch: 177| Step: 0
Training loss: 2.230271100997925
Validation loss: 2.058889706929525

Epoch: 5| Step: 1
Training loss: 2.236438035964966
Validation loss: 2.0432232605513705

Epoch: 5| Step: 2
Training loss: 2.1490390300750732
Validation loss: 2.0631619204757032

Epoch: 5| Step: 3
Training loss: 2.275578022003174
Validation loss: 2.05956700540358

Epoch: 5| Step: 4
Training loss: 1.666858434677124
Validation loss: 2.0900412554381997

Epoch: 5| Step: 5
Training loss: 1.820916771888733
Validation loss: 2.05670036936319

Epoch: 5| Step: 6
Training loss: 2.3310561180114746
Validation loss: 2.039517451358098

Epoch: 5| Step: 7
Training loss: 2.4766998291015625
Validation loss: 2.0635692637453795

Epoch: 5| Step: 8
Training loss: 1.5012199878692627
Validation loss: 2.082395053678943

Epoch: 5| Step: 9
Training loss: 1.9106025695800781
Validation loss: 2.0498888761766496

Epoch: 5| Step: 10
Training loss: 2.8765597343444824
Validation loss: 2.005977879288376

Epoch: 178| Step: 0
Training loss: 1.848341703414917
Validation loss: 2.0578501865427983

Epoch: 5| Step: 1
Training loss: 2.356335163116455
Validation loss: 2.031706162678298

Epoch: 5| Step: 2
Training loss: 2.048182487487793
Validation loss: 2.0201697157275293

Epoch: 5| Step: 3
Training loss: 2.5298221111297607
Validation loss: 2.048296643841651

Epoch: 5| Step: 4
Training loss: 2.261619806289673
Validation loss: 2.041570650633945

Epoch: 5| Step: 5
Training loss: 2.6205193996429443
Validation loss: 2.015152382594283

Epoch: 5| Step: 6
Training loss: 2.285074472427368
Validation loss: 2.059448298587594

Epoch: 5| Step: 7
Training loss: 1.788530945777893
Validation loss: 2.008103015602276

Epoch: 5| Step: 8
Training loss: 2.158863067626953
Validation loss: 2.0344539021932952

Epoch: 5| Step: 9
Training loss: 1.2290637493133545
Validation loss: 2.0596816142400107

Epoch: 5| Step: 10
Training loss: 2.606818675994873
Validation loss: 2.07549927824287

Epoch: 179| Step: 0
Training loss: 2.483450412750244
Validation loss: 2.0210884668493785

Epoch: 5| Step: 1
Training loss: 2.501049518585205
Validation loss: 2.0385961378774335

Epoch: 5| Step: 2
Training loss: 1.7023261785507202
Validation loss: 2.0400621339838994

Epoch: 5| Step: 3
Training loss: 2.0441532135009766
Validation loss: 2.063301896536222

Epoch: 5| Step: 4
Training loss: 1.6297376155853271
Validation loss: 2.063273725971099

Epoch: 5| Step: 5
Training loss: 2.5517067909240723
Validation loss: 2.0520475436282415

Epoch: 5| Step: 6
Training loss: 1.5675909519195557
Validation loss: 2.088357735705632

Epoch: 5| Step: 7
Training loss: 2.186516046524048
Validation loss: 2.0719397478206183

Epoch: 5| Step: 8
Training loss: 2.2022128105163574
Validation loss: 2.0678539199213826

Epoch: 5| Step: 9
Training loss: 2.774179697036743
Validation loss: 2.069796516049293

Epoch: 5| Step: 10
Training loss: 1.8161267042160034
Validation loss: 2.06836042352902

Epoch: 180| Step: 0
Training loss: 2.3244616985321045
Validation loss: 2.035358923737721

Epoch: 5| Step: 1
Training loss: 3.0364081859588623
Validation loss: 2.050085234385665

Epoch: 5| Step: 2
Training loss: 2.279940128326416
Validation loss: 2.024352418479099

Epoch: 5| Step: 3
Training loss: 1.878870964050293
Validation loss: 2.0556862123550905

Epoch: 5| Step: 4
Training loss: 2.069720506668091
Validation loss: 2.0256929269400974

Epoch: 5| Step: 5
Training loss: 1.8577098846435547
Validation loss: 2.0650444953672347

Epoch: 5| Step: 6
Training loss: 2.0316567420959473
Validation loss: 2.035845087420556

Epoch: 5| Step: 7
Training loss: 2.041841983795166
Validation loss: 2.0197908621962353

Epoch: 5| Step: 8
Training loss: 2.4664745330810547
Validation loss: 2.0459503332773843

Epoch: 5| Step: 9
Training loss: 1.6080223321914673
Validation loss: 2.0499897951720865

Epoch: 5| Step: 10
Training loss: 1.8662954568862915
Validation loss: 2.0351491666609243

Epoch: 181| Step: 0
Training loss: 2.1151626110076904
Validation loss: 2.0205113836514053

Epoch: 5| Step: 1
Training loss: 2.1705117225646973
Validation loss: 2.0332419180100962

Epoch: 5| Step: 2
Training loss: 1.5854697227478027
Validation loss: 2.01291976692856

Epoch: 5| Step: 3
Training loss: 2.0954837799072266
Validation loss: 2.026015002240417

Epoch: 5| Step: 4
Training loss: 1.9949159622192383
Validation loss: 2.0070547788373885

Epoch: 5| Step: 5
Training loss: 2.762425184249878
Validation loss: 2.044128969151487

Epoch: 5| Step: 6
Training loss: 2.2563562393188477
Validation loss: 2.0531216898272113

Epoch: 5| Step: 7
Training loss: 1.7180376052856445
Validation loss: 2.048132518286346

Epoch: 5| Step: 8
Training loss: 2.0477285385131836
Validation loss: 2.0451606922252203

Epoch: 5| Step: 9
Training loss: 1.9985790252685547
Validation loss: 2.0640215450717556

Epoch: 5| Step: 10
Training loss: 2.4867045879364014
Validation loss: 2.0274758595292286

Epoch: 182| Step: 0
Training loss: 2.2746312618255615
Validation loss: 2.0623723845328055

Epoch: 5| Step: 1
Training loss: 2.1311581134796143
Validation loss: 2.0503629907484977

Epoch: 5| Step: 2
Training loss: 2.126551389694214
Validation loss: 2.0795446518928773

Epoch: 5| Step: 3
Training loss: 2.3545923233032227
Validation loss: 2.0627687618296635

Epoch: 5| Step: 4
Training loss: 1.1625258922576904
Validation loss: 2.0847992627851424

Epoch: 5| Step: 5
Training loss: 2.4033823013305664
Validation loss: 2.064683573220366

Epoch: 5| Step: 6
Training loss: 2.301971912384033
Validation loss: 2.0397336175364833

Epoch: 5| Step: 7
Training loss: 2.678746461868286
Validation loss: 2.0595227377389067

Epoch: 5| Step: 8
Training loss: 2.1695055961608887
Validation loss: 2.06815497080485

Epoch: 5| Step: 9
Training loss: 2.222726821899414
Validation loss: 2.0522387989105715

Epoch: 5| Step: 10
Training loss: 1.6688191890716553
Validation loss: 2.056082123069353

Epoch: 183| Step: 0
Training loss: 2.0977001190185547
Validation loss: 2.0690707468217417

Epoch: 5| Step: 1
Training loss: 1.9567642211914062
Validation loss: 2.052014443182176

Epoch: 5| Step: 2
Training loss: 2.0871455669403076
Validation loss: 2.0338934506139448

Epoch: 5| Step: 3
Training loss: 2.0898125171661377
Validation loss: 2.032272627276759

Epoch: 5| Step: 4
Training loss: 1.9099452495574951
Validation loss: 2.071486424374324

Epoch: 5| Step: 5
Training loss: 2.173917770385742
Validation loss: 2.015707814565269

Epoch: 5| Step: 6
Training loss: 2.5668859481811523
Validation loss: 2.072772982299969

Epoch: 5| Step: 7
Training loss: 2.18491792678833
Validation loss: 2.069392224793793

Epoch: 5| Step: 8
Training loss: 2.094611644744873
Validation loss: 2.0585568156293643

Epoch: 5| Step: 9
Training loss: 2.286206007003784
Validation loss: 2.043967321354856

Epoch: 5| Step: 10
Training loss: 1.7877724170684814
Validation loss: 2.0275796818476852

Epoch: 184| Step: 0
Training loss: 2.2526965141296387
Validation loss: 2.0247297363896526

Epoch: 5| Step: 1
Training loss: 2.3918139934539795
Validation loss: 2.042249587274367

Epoch: 5| Step: 2
Training loss: 1.5959954261779785
Validation loss: 1.997927087609486

Epoch: 5| Step: 3
Training loss: 1.9630634784698486
Validation loss: 2.0480238109506588

Epoch: 5| Step: 4
Training loss: 2.0624988079071045
Validation loss: 2.046133473355283

Epoch: 5| Step: 5
Training loss: 1.884194016456604
Validation loss: 2.0265623895070886

Epoch: 5| Step: 6
Training loss: 2.6212315559387207
Validation loss: 2.0224269243978683

Epoch: 5| Step: 7
Training loss: 1.670456886291504
Validation loss: 2.0342429991691344

Epoch: 5| Step: 8
Training loss: 1.8597596883773804
Validation loss: 2.0207543744835803

Epoch: 5| Step: 9
Training loss: 2.826751947402954
Validation loss: 2.059026869394446

Epoch: 5| Step: 10
Training loss: 2.2749109268188477
Validation loss: 2.0398425261179605

Epoch: 185| Step: 0
Training loss: 2.0634257793426514
Validation loss: 2.048278275356498

Epoch: 5| Step: 1
Training loss: 2.484758138656616
Validation loss: 2.0006175220653577

Epoch: 5| Step: 2
Training loss: 1.5747891664505005
Validation loss: 2.0755329234625703

Epoch: 5| Step: 3
Training loss: 2.2098066806793213
Validation loss: 2.061277263907976

Epoch: 5| Step: 4
Training loss: 1.9939861297607422
Validation loss: 2.1082007013341433

Epoch: 5| Step: 5
Training loss: 1.9619255065917969
Validation loss: 2.0757557704884517

Epoch: 5| Step: 6
Training loss: 2.3488714694976807
Validation loss: 2.0949169602445377

Epoch: 5| Step: 7
Training loss: 2.6920559406280518
Validation loss: 2.10929839329053

Epoch: 5| Step: 8
Training loss: 1.5524342060089111
Validation loss: 2.068972033839072

Epoch: 5| Step: 9
Training loss: 1.9969896078109741
Validation loss: 2.067955505463385

Epoch: 5| Step: 10
Training loss: 2.2551229000091553
Validation loss: 2.0281133920915666

Epoch: 186| Step: 0
Training loss: 1.825272798538208
Validation loss: 2.0578598822316816

Epoch: 5| Step: 1
Training loss: 2.5145468711853027
Validation loss: 2.0745029270008044

Epoch: 5| Step: 2
Training loss: 1.394822120666504
Validation loss: 2.101334318037956

Epoch: 5| Step: 3
Training loss: 2.0995993614196777
Validation loss: 2.0923892323688795

Epoch: 5| Step: 4
Training loss: 2.209808349609375
Validation loss: 2.040263952747468

Epoch: 5| Step: 5
Training loss: 2.609652519226074
Validation loss: 2.0726725696235575

Epoch: 5| Step: 6
Training loss: 2.0449821949005127
Validation loss: 2.0385586292512956

Epoch: 5| Step: 7
Training loss: 2.1129720211029053
Validation loss: 2.025786999733217

Epoch: 5| Step: 8
Training loss: 2.6470694541931152
Validation loss: 2.0256523880907285

Epoch: 5| Step: 9
Training loss: 2.056595802307129
Validation loss: 2.0109510037206833

Epoch: 5| Step: 10
Training loss: 1.9373245239257812
Validation loss: 2.0458665740105415

Epoch: 187| Step: 0
Training loss: 2.3182878494262695
Validation loss: 2.034164208237843

Epoch: 5| Step: 1
Training loss: 2.84879732131958
Validation loss: 2.0109212090892177

Epoch: 5| Step: 2
Training loss: 1.8305213451385498
Validation loss: 2.051545559719045

Epoch: 5| Step: 3
Training loss: 1.889690637588501
Validation loss: 2.0323870951129543

Epoch: 5| Step: 4
Training loss: 2.2207560539245605
Validation loss: 2.0330047607421875

Epoch: 5| Step: 5
Training loss: 2.5543949604034424
Validation loss: 2.0855240283473844

Epoch: 5| Step: 6
Training loss: 1.72722589969635
Validation loss: 2.024894227263748

Epoch: 5| Step: 7
Training loss: 2.012810230255127
Validation loss: 2.0388361228409635

Epoch: 5| Step: 8
Training loss: 2.1111950874328613
Validation loss: 2.0462308365811586

Epoch: 5| Step: 9
Training loss: 2.078061580657959
Validation loss: 2.051630655924479

Epoch: 5| Step: 10
Training loss: 1.6221232414245605
Validation loss: 2.0008549177518455

Epoch: 188| Step: 0
Training loss: 2.3884551525115967
Validation loss: 2.031062315869075

Epoch: 5| Step: 1
Training loss: 2.54935884475708
Validation loss: 2.06191603086328

Epoch: 5| Step: 2
Training loss: 2.615198850631714
Validation loss: 2.0042569727026005

Epoch: 5| Step: 3
Training loss: 2.952118158340454
Validation loss: 2.0161034189244753

Epoch: 5| Step: 4
Training loss: 2.0728919506073
Validation loss: 2.032984966872841

Epoch: 5| Step: 5
Training loss: 1.500014066696167
Validation loss: 2.0682334451265234

Epoch: 5| Step: 6
Training loss: 1.2865427732467651
Validation loss: 2.0296552822154057

Epoch: 5| Step: 7
Training loss: 1.4554345607757568
Validation loss: 2.042244884275621

Epoch: 5| Step: 8
Training loss: 2.114105701446533
Validation loss: 2.051953759244693

Epoch: 5| Step: 9
Training loss: 2.072566270828247
Validation loss: 2.0298465733887046

Epoch: 5| Step: 10
Training loss: 2.5335521697998047
Validation loss: 2.0677719218756563

Epoch: 189| Step: 0
Training loss: 2.4019367694854736
Validation loss: 2.029148324843376

Epoch: 5| Step: 1
Training loss: 2.1308155059814453
Validation loss: 2.0920264387643464

Epoch: 5| Step: 2
Training loss: 1.6805274486541748
Validation loss: 2.06589275534435

Epoch: 5| Step: 3
Training loss: 2.5306878089904785
Validation loss: 2.04203878166855

Epoch: 5| Step: 4
Training loss: 2.1283063888549805
Validation loss: 2.0758936764091573

Epoch: 5| Step: 5
Training loss: 1.6242339611053467
Validation loss: 2.068387585301553

Epoch: 5| Step: 6
Training loss: 2.2857842445373535
Validation loss: 2.0887639458461473

Epoch: 5| Step: 7
Training loss: 2.0509822368621826
Validation loss: 2.037704239609421

Epoch: 5| Step: 8
Training loss: 1.5629165172576904
Validation loss: 2.0570378470164474

Epoch: 5| Step: 9
Training loss: 2.614722728729248
Validation loss: 2.0321795427671043

Epoch: 5| Step: 10
Training loss: 2.1746644973754883
Validation loss: 2.0680264503725114

Epoch: 190| Step: 0
Training loss: 2.4541263580322266
Validation loss: 2.0692277493015414

Epoch: 5| Step: 1
Training loss: 2.1571946144104004
Validation loss: 2.0321970511508245

Epoch: 5| Step: 2
Training loss: 2.4573447704315186
Validation loss: 2.059490506367017

Epoch: 5| Step: 3
Training loss: 2.0115857124328613
Validation loss: 2.0622115545375372

Epoch: 5| Step: 4
Training loss: 2.0524208545684814
Validation loss: 2.0588800561043525

Epoch: 5| Step: 5
Training loss: 1.3530538082122803
Validation loss: 2.0849206755238194

Epoch: 5| Step: 6
Training loss: 1.8399431705474854
Validation loss: 2.0838234655318724

Epoch: 5| Step: 7
Training loss: 2.2540738582611084
Validation loss: 2.0715492284426125

Epoch: 5| Step: 8
Training loss: 2.0254790782928467
Validation loss: 2.0256666855145524

Epoch: 5| Step: 9
Training loss: 2.2951903343200684
Validation loss: 2.0692728642494447

Epoch: 5| Step: 10
Training loss: 2.1982321739196777
Validation loss: 2.099701864745027

Epoch: 191| Step: 0
Training loss: 1.890511155128479
Validation loss: 2.0696953291534097

Epoch: 5| Step: 1
Training loss: 2.2787952423095703
Validation loss: 2.063014216320489

Epoch: 5| Step: 2
Training loss: 1.8638637065887451
Validation loss: 2.1034794622851956

Epoch: 5| Step: 3
Training loss: 1.5583693981170654
Validation loss: 2.0747662974942114

Epoch: 5| Step: 4
Training loss: 1.836843729019165
Validation loss: 2.0469526488293885

Epoch: 5| Step: 5
Training loss: 1.9825599193572998
Validation loss: 2.0597474369951474

Epoch: 5| Step: 6
Training loss: 2.448403835296631
Validation loss: 2.0328930988106677

Epoch: 5| Step: 7
Training loss: 2.2558469772338867
Validation loss: 2.041444447732741

Epoch: 5| Step: 8
Training loss: 2.202139139175415
Validation loss: 2.028129305890811

Epoch: 5| Step: 9
Training loss: 2.318898916244507
Validation loss: 2.0237633079610844

Epoch: 5| Step: 10
Training loss: 2.4282619953155518
Validation loss: 2.030727296747187

Epoch: 192| Step: 0
Training loss: 1.6870126724243164
Validation loss: 1.9597981078650362

Epoch: 5| Step: 1
Training loss: 1.5588102340698242
Validation loss: 2.007982968002237

Epoch: 5| Step: 2
Training loss: 2.3691487312316895
Validation loss: 2.068904640854046

Epoch: 5| Step: 3
Training loss: 2.277301788330078
Validation loss: 2.0730140363016436

Epoch: 5| Step: 4
Training loss: 2.483428716659546
Validation loss: 2.01462451488741

Epoch: 5| Step: 5
Training loss: 2.0000903606414795
Validation loss: 2.0718935151253977

Epoch: 5| Step: 6
Training loss: 2.084986448287964
Validation loss: 2.0404805060355895

Epoch: 5| Step: 7
Training loss: 2.429023027420044
Validation loss: 2.0182045787893315

Epoch: 5| Step: 8
Training loss: 2.6507458686828613
Validation loss: 2.045539655993062

Epoch: 5| Step: 9
Training loss: 1.4918668270111084
Validation loss: 2.035867932022259

Epoch: 5| Step: 10
Training loss: 2.365347146987915
Validation loss: 2.03754432483386

Epoch: 193| Step: 0
Training loss: 2.4781978130340576
Validation loss: 2.0732508346598637

Epoch: 5| Step: 1
Training loss: 1.6405826807022095
Validation loss: 2.0163480081865863

Epoch: 5| Step: 2
Training loss: 1.4127476215362549
Validation loss: 2.1016241427390807

Epoch: 5| Step: 3
Training loss: 2.104910373687744
Validation loss: 2.0489173884032876

Epoch: 5| Step: 4
Training loss: 1.684665322303772
Validation loss: 2.0718015791267477

Epoch: 5| Step: 5
Training loss: 2.170379161834717
Validation loss: 2.089667856052358

Epoch: 5| Step: 6
Training loss: 2.6523804664611816
Validation loss: 2.0622218270455637

Epoch: 5| Step: 7
Training loss: 2.2977170944213867
Validation loss: 2.0568821763479583

Epoch: 5| Step: 8
Training loss: 2.1378471851348877
Validation loss: 2.082402370309317

Epoch: 5| Step: 9
Training loss: 1.7021089792251587
Validation loss: 2.071203657375869

Epoch: 5| Step: 10
Training loss: 2.648879289627075
Validation loss: 2.0550162740933

Epoch: 194| Step: 0
Training loss: 2.1750295162200928
Validation loss: 2.0643999832932667

Epoch: 5| Step: 1
Training loss: 1.8833658695220947
Validation loss: 2.0586808009814193

Epoch: 5| Step: 2
Training loss: 2.0826163291931152
Validation loss: 2.030863364537557

Epoch: 5| Step: 3
Training loss: 2.423372507095337
Validation loss: 2.021614246470954

Epoch: 5| Step: 4
Training loss: 1.7982323169708252
Validation loss: 2.016092070969202

Epoch: 5| Step: 5
Training loss: 2.3248374462127686
Validation loss: 2.0414834663432133

Epoch: 5| Step: 6
Training loss: 2.113208770751953
Validation loss: 2.068908244050959

Epoch: 5| Step: 7
Training loss: 1.8796024322509766
Validation loss: 2.007158317873555

Epoch: 5| Step: 8
Training loss: 2.0152535438537598
Validation loss: 2.0512681943114086

Epoch: 5| Step: 9
Training loss: 1.8182299137115479
Validation loss: 2.068049051428354

Epoch: 5| Step: 10
Training loss: 2.992515802383423
Validation loss: 2.0402095343476985

Epoch: 195| Step: 0
Training loss: 2.5278375148773193
Validation loss: 2.083315841613277

Epoch: 5| Step: 1
Training loss: 1.9131256341934204
Validation loss: 2.041023163385289

Epoch: 5| Step: 2
Training loss: 1.649776816368103
Validation loss: 2.0882679313741703

Epoch: 5| Step: 3
Training loss: 3.104154109954834
Validation loss: 2.073981942669038

Epoch: 5| Step: 4
Training loss: 2.323702335357666
Validation loss: 2.059132211951799

Epoch: 5| Step: 5
Training loss: 1.775573968887329
Validation loss: 2.075478410208097

Epoch: 5| Step: 6
Training loss: 1.984108567237854
Validation loss: 2.0836745821019655

Epoch: 5| Step: 7
Training loss: 2.5622920989990234
Validation loss: 2.0790862242380777

Epoch: 5| Step: 8
Training loss: 1.729079008102417
Validation loss: 2.0564938719554613

Epoch: 5| Step: 9
Training loss: 1.4941784143447876
Validation loss: 2.0985966087669454

Epoch: 5| Step: 10
Training loss: 2.079758644104004
Validation loss: 2.071513796365389

Epoch: 196| Step: 0
Training loss: 2.1924777030944824
Validation loss: 2.0366237830090266

Epoch: 5| Step: 1
Training loss: 2.58029842376709
Validation loss: 2.085603743471125

Epoch: 5| Step: 2
Training loss: 2.3118462562561035
Validation loss: 2.0695467764331448

Epoch: 5| Step: 3
Training loss: 2.172524929046631
Validation loss: 2.0436704517692648

Epoch: 5| Step: 4
Training loss: 1.6226638555526733
Validation loss: 2.0580343533587713

Epoch: 5| Step: 5
Training loss: 1.7841829061508179
Validation loss: 2.0623237599608717

Epoch: 5| Step: 6
Training loss: 2.2715296745300293
Validation loss: 2.0453350415793796

Epoch: 5| Step: 7
Training loss: 2.343214750289917
Validation loss: 2.079719599857125

Epoch: 5| Step: 8
Training loss: 1.72623610496521
Validation loss: 2.0706430045507287

Epoch: 5| Step: 9
Training loss: 2.0120511054992676
Validation loss: 2.0381561607442875

Epoch: 5| Step: 10
Training loss: 1.6681225299835205
Validation loss: 2.045862541403822

Epoch: 197| Step: 0
Training loss: 2.6833436489105225
Validation loss: 2.0259484398749565

Epoch: 5| Step: 1
Training loss: 1.8174936771392822
Validation loss: 2.060937621260202

Epoch: 5| Step: 2
Training loss: 2.065634250640869
Validation loss: 2.03342031791646

Epoch: 5| Step: 3
Training loss: 2.5584237575531006
Validation loss: 2.0720853561996133

Epoch: 5| Step: 4
Training loss: 1.9186270236968994
Validation loss: 2.044867927028287

Epoch: 5| Step: 5
Training loss: 2.0524532794952393
Validation loss: 2.0292635630535822

Epoch: 5| Step: 6
Training loss: 1.9630037546157837
Validation loss: 2.0488103435885523

Epoch: 5| Step: 7
Training loss: 2.0884323120117188
Validation loss: 2.06105516546516

Epoch: 5| Step: 8
Training loss: 1.9406474828720093
Validation loss: 2.054072738975607

Epoch: 5| Step: 9
Training loss: 2.4006295204162598
Validation loss: 2.014643794746809

Epoch: 5| Step: 10
Training loss: 1.3257156610488892
Validation loss: 2.032413326283937

Epoch: 198| Step: 0
Training loss: 2.389787197113037
Validation loss: 2.020498243711328

Epoch: 5| Step: 1
Training loss: 2.3523359298706055
Validation loss: 2.039985922075087

Epoch: 5| Step: 2
Training loss: 1.6366138458251953
Validation loss: 2.0147586650745843

Epoch: 5| Step: 3
Training loss: 2.1826205253601074
Validation loss: 2.056185740296559

Epoch: 5| Step: 4
Training loss: 2.7351489067077637
Validation loss: 2.063782371500487

Epoch: 5| Step: 5
Training loss: 1.7078139781951904
Validation loss: 2.036259598629449

Epoch: 5| Step: 6
Training loss: 1.840650200843811
Validation loss: 2.021387346329228

Epoch: 5| Step: 7
Training loss: 2.8143863677978516
Validation loss: 2.019092978969697

Epoch: 5| Step: 8
Training loss: 1.5379866361618042
Validation loss: 2.0671998236768987

Epoch: 5| Step: 9
Training loss: 1.790558099746704
Validation loss: 2.0314441880872174

Epoch: 5| Step: 10
Training loss: 2.0017712116241455
Validation loss: 2.050110052990657

Epoch: 199| Step: 0
Training loss: 2.0844874382019043
Validation loss: 2.0560538666222685

Epoch: 5| Step: 1
Training loss: 2.2304794788360596
Validation loss: 2.066088471361386

Epoch: 5| Step: 2
Training loss: 1.939714789390564
Validation loss: 2.0398364092714045

Epoch: 5| Step: 3
Training loss: 2.3092453479766846
Validation loss: 2.0391227506822154

Epoch: 5| Step: 4
Training loss: 2.2905216217041016
Validation loss: 2.057992043033723

Epoch: 5| Step: 5
Training loss: 1.6829936504364014
Validation loss: 2.027827952497749

Epoch: 5| Step: 6
Training loss: 2.4582648277282715
Validation loss: 2.0816434762811147

Epoch: 5| Step: 7
Training loss: 1.8995736837387085
Validation loss: 2.0704123050935808

Epoch: 5| Step: 8
Training loss: 2.173583984375
Validation loss: 2.0494765876441874

Epoch: 5| Step: 9
Training loss: 1.7975841760635376
Validation loss: 2.051599379508726

Epoch: 5| Step: 10
Training loss: 2.3195300102233887
Validation loss: 2.0960495241226687

Epoch: 200| Step: 0
Training loss: 2.063244581222534
Validation loss: 2.0940793329669583

Epoch: 5| Step: 1
Training loss: 2.8043830394744873
Validation loss: 2.068403054309148

Epoch: 5| Step: 2
Training loss: 1.2713587284088135
Validation loss: 2.0455395867747646

Epoch: 5| Step: 3
Training loss: 2.431121349334717
Validation loss: 2.0949482533239547

Epoch: 5| Step: 4
Training loss: 2.284485340118408
Validation loss: 2.0741400769961778

Epoch: 5| Step: 5
Training loss: 1.6279455423355103
Validation loss: 2.0497241225293887

Epoch: 5| Step: 6
Training loss: 2.6054751873016357
Validation loss: 2.0686321591818206

Epoch: 5| Step: 7
Training loss: 1.8605949878692627
Validation loss: 2.0574225982030234

Epoch: 5| Step: 8
Training loss: 2.5166850090026855
Validation loss: 2.04976156193723

Epoch: 5| Step: 9
Training loss: 1.6000964641571045
Validation loss: 2.0612192769204416

Epoch: 5| Step: 10
Training loss: 1.9968762397766113
Validation loss: 2.0837294376024635

Epoch: 201| Step: 0
Training loss: 1.8382564783096313
Validation loss: 2.0968822433102514

Epoch: 5| Step: 1
Training loss: 2.2972636222839355
Validation loss: 2.0634162323449248

Epoch: 5| Step: 2
Training loss: 2.118417263031006
Validation loss: 2.0739398874262327

Epoch: 5| Step: 3
Training loss: 2.347682476043701
Validation loss: 2.068304584872338

Epoch: 5| Step: 4
Training loss: 1.6711876392364502
Validation loss: 2.083890050970098

Epoch: 5| Step: 5
Training loss: 2.1722474098205566
Validation loss: 2.068588523454564

Epoch: 5| Step: 6
Training loss: 2.1253368854522705
Validation loss: 2.0654943912259993

Epoch: 5| Step: 7
Training loss: 2.1769332885742188
Validation loss: 2.0743404152572795

Epoch: 5| Step: 8
Training loss: 1.9024314880371094
Validation loss: 2.084745068703928

Epoch: 5| Step: 9
Training loss: 2.07085919380188
Validation loss: 2.0509999849463023

Epoch: 5| Step: 10
Training loss: 2.3074748516082764
Validation loss: 2.0503427174783524

Epoch: 202| Step: 0
Training loss: 1.4718618392944336
Validation loss: 2.064793816176794

Epoch: 5| Step: 1
Training loss: 2.4065279960632324
Validation loss: 2.061468629426854

Epoch: 5| Step: 2
Training loss: 1.8259426355361938
Validation loss: 2.0765038356986096

Epoch: 5| Step: 3
Training loss: 2.4219095706939697
Validation loss: 2.061152429990871

Epoch: 5| Step: 4
Training loss: 1.6948363780975342
Validation loss: 2.063512635487382

Epoch: 5| Step: 5
Training loss: 1.9940459728240967
Validation loss: 2.070239177314184

Epoch: 5| Step: 6
Training loss: 2.9238319396972656
Validation loss: 2.074731542218116

Epoch: 5| Step: 7
Training loss: 1.666788101196289
Validation loss: 2.067639463691301

Epoch: 5| Step: 8
Training loss: 2.6982598304748535
Validation loss: 2.10877816395093

Epoch: 5| Step: 9
Training loss: 1.461883783340454
Validation loss: 2.055266450810176

Epoch: 5| Step: 10
Training loss: 2.461787223815918
Validation loss: 2.0741748502177577

Epoch: 203| Step: 0
Training loss: 1.7007195949554443
Validation loss: 2.078292133987591

Epoch: 5| Step: 1
Training loss: 2.383148431777954
Validation loss: 2.070211789941275

Epoch: 5| Step: 2
Training loss: 2.3564624786376953
Validation loss: 2.0853150429264193

Epoch: 5| Step: 3
Training loss: 2.424353837966919
Validation loss: 2.057699486773501

Epoch: 5| Step: 4
Training loss: 2.0725131034851074
Validation loss: 2.074868115045691

Epoch: 5| Step: 5
Training loss: 2.3109402656555176
Validation loss: 2.072691794364683

Epoch: 5| Step: 6
Training loss: 1.866089105606079
Validation loss: 2.0778017300431446

Epoch: 5| Step: 7
Training loss: 1.6396009922027588
Validation loss: 2.0679315290143414

Epoch: 5| Step: 8
Training loss: 2.00291109085083
Validation loss: 2.0759848138337493

Epoch: 5| Step: 9
Training loss: 2.1273491382598877
Validation loss: 2.082254162398718

Epoch: 5| Step: 10
Training loss: 2.27728009223938
Validation loss: 2.048321088155111

Epoch: 204| Step: 0
Training loss: 2.261014699935913
Validation loss: 2.0770695773504113

Epoch: 5| Step: 1
Training loss: 2.2126107215881348
Validation loss: 2.0669798043466385

Epoch: 5| Step: 2
Training loss: 2.346210479736328
Validation loss: 2.057870649522351

Epoch: 5| Step: 3
Training loss: 2.4335873126983643
Validation loss: 2.0750923284920315

Epoch: 5| Step: 4
Training loss: 2.2590415477752686
Validation loss: 2.0949446488452215

Epoch: 5| Step: 5
Training loss: 1.7290527820587158
Validation loss: 2.016754345227313

Epoch: 5| Step: 6
Training loss: 1.7892417907714844
Validation loss: 2.011602081278319

Epoch: 5| Step: 7
Training loss: 1.965692162513733
Validation loss: 2.065937570346299

Epoch: 5| Step: 8
Training loss: 2.0895237922668457
Validation loss: 2.0298140484799623

Epoch: 5| Step: 9
Training loss: 2.0173773765563965
Validation loss: 2.0810513880945023

Epoch: 5| Step: 10
Training loss: 1.595036506652832
Validation loss: 2.0329868460214264

Epoch: 205| Step: 0
Training loss: 2.3030993938446045
Validation loss: 2.0451431325686875

Epoch: 5| Step: 1
Training loss: 1.939444899559021
Validation loss: 2.042870872764177

Epoch: 5| Step: 2
Training loss: 2.904996156692505
Validation loss: 2.058149673605478

Epoch: 5| Step: 3
Training loss: 1.4360510110855103
Validation loss: 2.0331015971399125

Epoch: 5| Step: 4
Training loss: 2.159698724746704
Validation loss: 2.0511074322526173

Epoch: 5| Step: 5
Training loss: 2.2448954582214355
Validation loss: 2.0266474344397105

Epoch: 5| Step: 6
Training loss: 1.803790807723999
Validation loss: 2.033570820285428

Epoch: 5| Step: 7
Training loss: 1.8543821573257446
Validation loss: 2.0421010653177896

Epoch: 5| Step: 8
Training loss: 2.1965222358703613
Validation loss: 2.053812469205549

Epoch: 5| Step: 9
Training loss: 2.1600728034973145
Validation loss: 2.0156003429043676

Epoch: 5| Step: 10
Training loss: 1.794895887374878
Validation loss: 2.0715364204939974

Epoch: 206| Step: 0
Training loss: 2.079796075820923
Validation loss: 2.0460458788820493

Epoch: 5| Step: 1
Training loss: 2.952472686767578
Validation loss: 2.032456223682691

Epoch: 5| Step: 2
Training loss: 1.3608665466308594
Validation loss: 2.0542288505902855

Epoch: 5| Step: 3
Training loss: 2.3497843742370605
Validation loss: 2.0692539343269925

Epoch: 5| Step: 4
Training loss: 1.941354513168335
Validation loss: 2.008107116145472

Epoch: 5| Step: 5
Training loss: 2.171513319015503
Validation loss: 2.0464333436822377

Epoch: 5| Step: 6
Training loss: 1.817115068435669
Validation loss: 2.0525981392911685

Epoch: 5| Step: 7
Training loss: 1.999762773513794
Validation loss: 2.020343852299516

Epoch: 5| Step: 8
Training loss: 1.8706413507461548
Validation loss: 2.019615186158047

Epoch: 5| Step: 9
Training loss: 2.41485333442688
Validation loss: 2.062390791472568

Epoch: 5| Step: 10
Training loss: 1.7157962322235107
Validation loss: 2.054615948789863

Epoch: 207| Step: 0
Training loss: 1.7749364376068115
Validation loss: 2.0915349978272633

Epoch: 5| Step: 1
Training loss: 2.0243923664093018
Validation loss: 2.097426040198213

Epoch: 5| Step: 2
Training loss: 1.6125694513320923
Validation loss: 2.0663794343189528

Epoch: 5| Step: 3
Training loss: 1.9747543334960938
Validation loss: 2.0884790407714022

Epoch: 5| Step: 4
Training loss: 2.164407968521118
Validation loss: 2.083600903070101

Epoch: 5| Step: 5
Training loss: 2.163987636566162
Validation loss: 2.059847713798605

Epoch: 5| Step: 6
Training loss: 1.9625940322875977
Validation loss: 2.137039928026097

Epoch: 5| Step: 7
Training loss: 2.3022873401641846
Validation loss: 2.113814623125138

Epoch: 5| Step: 8
Training loss: 2.1613969802856445
Validation loss: 2.1057907663365847

Epoch: 5| Step: 9
Training loss: 2.5858306884765625
Validation loss: 2.0928862607607277

Epoch: 5| Step: 10
Training loss: 2.463364601135254
Validation loss: 2.051245036945548

Epoch: 208| Step: 0
Training loss: 2.5413708686828613
Validation loss: 2.07180300066548

Epoch: 5| Step: 1
Training loss: 1.893153190612793
Validation loss: 2.0987625891162502

Epoch: 5| Step: 2
Training loss: 2.513619899749756
Validation loss: 2.074546088454544

Epoch: 5| Step: 3
Training loss: 2.533385753631592
Validation loss: 2.067836946056735

Epoch: 5| Step: 4
Training loss: 1.7740436792373657
Validation loss: 2.063200307148759

Epoch: 5| Step: 5
Training loss: 2.006110668182373
Validation loss: 2.1001715070457867

Epoch: 5| Step: 6
Training loss: 2.435338258743286
Validation loss: 2.059688514278781

Epoch: 5| Step: 7
Training loss: 2.117039918899536
Validation loss: 2.0529685892084593

Epoch: 5| Step: 8
Training loss: 1.7338405847549438
Validation loss: 2.079803894924861

Epoch: 5| Step: 9
Training loss: 1.6169017553329468
Validation loss: 2.085997158481229

Epoch: 5| Step: 10
Training loss: 1.7445305585861206
Validation loss: 2.08537858275957

Epoch: 209| Step: 0
Training loss: 2.3828606605529785
Validation loss: 2.0440276976554625

Epoch: 5| Step: 1
Training loss: 1.8899612426757812
Validation loss: 2.068068288987683

Epoch: 5| Step: 2
Training loss: 3.0846705436706543
Validation loss: 2.0801489327543523

Epoch: 5| Step: 3
Training loss: 1.8314340114593506
Validation loss: 2.1134034664400163

Epoch: 5| Step: 4
Training loss: 2.2905969619750977
Validation loss: 2.040076709562732

Epoch: 5| Step: 5
Training loss: 2.054300308227539
Validation loss: 2.0664761207437

Epoch: 5| Step: 6
Training loss: 1.6159003973007202
Validation loss: 2.0639485800138084

Epoch: 5| Step: 7
Training loss: 2.256434202194214
Validation loss: 2.0253821598586215

Epoch: 5| Step: 8
Training loss: 1.9735599756240845
Validation loss: 2.0668067650128434

Epoch: 5| Step: 9
Training loss: 1.769508957862854
Validation loss: 2.0015484671438895

Epoch: 5| Step: 10
Training loss: 1.8417401313781738
Validation loss: 2.051955739657084

Epoch: 210| Step: 0
Training loss: 1.9118324518203735
Validation loss: 2.056883781186996

Epoch: 5| Step: 1
Training loss: 2.0388901233673096
Validation loss: 2.097094803728083

Epoch: 5| Step: 2
Training loss: 1.898768424987793
Validation loss: 2.050335281638689

Epoch: 5| Step: 3
Training loss: 1.6520297527313232
Validation loss: 2.0586285257852204

Epoch: 5| Step: 4
Training loss: 2.4309492111206055
Validation loss: 2.0415513925654913

Epoch: 5| Step: 5
Training loss: 2.570122003555298
Validation loss: 2.0118128086930964

Epoch: 5| Step: 6
Training loss: 1.7998768091201782
Validation loss: 2.024376457737338

Epoch: 5| Step: 7
Training loss: 1.5294569730758667
Validation loss: 2.0651912073935232

Epoch: 5| Step: 8
Training loss: 2.280264377593994
Validation loss: 2.0654857876480266

Epoch: 5| Step: 9
Training loss: 2.1931862831115723
Validation loss: 2.0194127944207962

Epoch: 5| Step: 10
Training loss: 2.648550033569336
Validation loss: 2.076922457705262

Epoch: 211| Step: 0
Training loss: 1.9494727849960327
Validation loss: 2.0709239103460826

Epoch: 5| Step: 1
Training loss: 2.445620536804199
Validation loss: 2.0707948566764913

Epoch: 5| Step: 2
Training loss: 1.7535228729248047
Validation loss: 2.0668937339577624

Epoch: 5| Step: 3
Training loss: 1.9939619302749634
Validation loss: 2.071896396657472

Epoch: 5| Step: 4
Training loss: 1.7197043895721436
Validation loss: 2.0881542441665486

Epoch: 5| Step: 5
Training loss: 1.76238214969635
Validation loss: 2.0812397362083517

Epoch: 5| Step: 6
Training loss: 3.3384900093078613
Validation loss: 2.1031770629267537

Epoch: 5| Step: 7
Training loss: 1.7293201684951782
Validation loss: 2.0873442234531527

Epoch: 5| Step: 8
Training loss: 2.044405698776245
Validation loss: 2.099818047656808

Epoch: 5| Step: 9
Training loss: 2.1245343685150146
Validation loss: 2.083060715788154

Epoch: 5| Step: 10
Training loss: 2.08579158782959
Validation loss: 2.065513454457765

Epoch: 212| Step: 0
Training loss: 2.446160078048706
Validation loss: 2.0258837207671134

Epoch: 5| Step: 1
Training loss: 2.1743171215057373
Validation loss: 2.0444679285890315

Epoch: 5| Step: 2
Training loss: 2.2853081226348877
Validation loss: 2.0517306404729045

Epoch: 5| Step: 3
Training loss: 1.9539642333984375
Validation loss: 2.0361345403937885

Epoch: 5| Step: 4
Training loss: 1.5321165323257446
Validation loss: 2.0886745516971876

Epoch: 5| Step: 5
Training loss: 1.591280221939087
Validation loss: 2.1221070315248225

Epoch: 5| Step: 6
Training loss: 2.0018131732940674
Validation loss: 2.0674278620750672

Epoch: 5| Step: 7
Training loss: 2.646944046020508
Validation loss: 2.089069648455548

Epoch: 5| Step: 8
Training loss: 2.1374716758728027
Validation loss: 2.062226603108068

Epoch: 5| Step: 9
Training loss: 2.579974412918091
Validation loss: 2.073762191239224

Epoch: 5| Step: 10
Training loss: 1.6407930850982666
Validation loss: 2.1130742001277145

Epoch: 213| Step: 0
Training loss: 1.7974516153335571
Validation loss: 2.0866393940423125

Epoch: 5| Step: 1
Training loss: 2.286816358566284
Validation loss: 2.07810910542806

Epoch: 5| Step: 2
Training loss: 2.425295829772949
Validation loss: 2.062899607484059

Epoch: 5| Step: 3
Training loss: 2.4788620471954346
Validation loss: 2.0880450792210077

Epoch: 5| Step: 4
Training loss: 2.1909356117248535
Validation loss: 2.086100398853261

Epoch: 5| Step: 5
Training loss: 1.9182226657867432
Validation loss: 2.069417579199678

Epoch: 5| Step: 6
Training loss: 2.1305766105651855
Validation loss: 2.03816476175862

Epoch: 5| Step: 7
Training loss: 1.6376628875732422
Validation loss: 2.068252750622329

Epoch: 5| Step: 8
Training loss: 2.106266498565674
Validation loss: 2.036363649111922

Epoch: 5| Step: 9
Training loss: 1.946112871170044
Validation loss: 2.063150170028851

Epoch: 5| Step: 10
Training loss: 2.0087833404541016
Validation loss: 2.0463103684045936

Epoch: 214| Step: 0
Training loss: 2.002779006958008
Validation loss: 2.0833515505636893

Epoch: 5| Step: 1
Training loss: 1.6430842876434326
Validation loss: 2.0546327316632835

Epoch: 5| Step: 2
Training loss: 2.047287940979004
Validation loss: 2.0382081116399458

Epoch: 5| Step: 3
Training loss: 1.8147722482681274
Validation loss: 2.024365455873551

Epoch: 5| Step: 4
Training loss: 1.9432075023651123
Validation loss: 2.0758165338987946

Epoch: 5| Step: 5
Training loss: 2.2058215141296387
Validation loss: 2.0301982638656453

Epoch: 5| Step: 6
Training loss: 2.7358851432800293
Validation loss: 2.049018052316481

Epoch: 5| Step: 7
Training loss: 2.2808735370635986
Validation loss: 2.050277525378812

Epoch: 5| Step: 8
Training loss: 2.1908645629882812
Validation loss: 2.033642042067743

Epoch: 5| Step: 9
Training loss: 2.206822156906128
Validation loss: 2.0210319988189207

Epoch: 5| Step: 10
Training loss: 1.8079413175582886
Validation loss: 2.0136478395872217

Epoch: 215| Step: 0
Training loss: 2.1044864654541016
Validation loss: 2.0418534458324475

Epoch: 5| Step: 1
Training loss: 1.877995252609253
Validation loss: 2.0267584887883996

Epoch: 5| Step: 2
Training loss: 1.9375003576278687
Validation loss: 2.0582097986693024

Epoch: 5| Step: 3
Training loss: 2.1316070556640625
Validation loss: 2.0487183319625033

Epoch: 5| Step: 4
Training loss: 1.8932571411132812
Validation loss: 2.0320534398478847

Epoch: 5| Step: 5
Training loss: 2.382969379425049
Validation loss: 2.024923406621461

Epoch: 5| Step: 6
Training loss: 2.1043732166290283
Validation loss: 2.024515906969706

Epoch: 5| Step: 7
Training loss: 1.4325298070907593
Validation loss: 2.0525742410331644

Epoch: 5| Step: 8
Training loss: 1.9119243621826172
Validation loss: 2.07194455464681

Epoch: 5| Step: 9
Training loss: 2.3895413875579834
Validation loss: 2.0797750898586806

Epoch: 5| Step: 10
Training loss: 2.563504695892334
Validation loss: 2.0723420317455004

Epoch: 216| Step: 0
Training loss: 1.7143669128417969
Validation loss: 2.0766612432336293

Epoch: 5| Step: 1
Training loss: 1.9517781734466553
Validation loss: 2.0412855686679965

Epoch: 5| Step: 2
Training loss: 2.339776039123535
Validation loss: 1.987148424630524

Epoch: 5| Step: 3
Training loss: 1.5209029912948608
Validation loss: 2.0582933079811836

Epoch: 5| Step: 4
Training loss: 2.354752540588379
Validation loss: 1.998052902119134

Epoch: 5| Step: 5
Training loss: 2.0194833278656006
Validation loss: 2.0870050563607165

Epoch: 5| Step: 6
Training loss: 1.8634105920791626
Validation loss: 2.0757876826870825

Epoch: 5| Step: 7
Training loss: 2.3001720905303955
Validation loss: 2.0420421272195797

Epoch: 5| Step: 8
Training loss: 1.8676645755767822
Validation loss: 2.025645968734577

Epoch: 5| Step: 9
Training loss: 2.406914472579956
Validation loss: 2.1001193087588073

Epoch: 5| Step: 10
Training loss: 2.3596935272216797
Validation loss: 2.029401320283131

Epoch: 217| Step: 0
Training loss: 2.1224310398101807
Validation loss: 2.074604871452496

Epoch: 5| Step: 1
Training loss: 2.2314395904541016
Validation loss: 2.0161517640595794

Epoch: 5| Step: 2
Training loss: 2.170292615890503
Validation loss: 2.0335756591571275

Epoch: 5| Step: 3
Training loss: 1.9755260944366455
Validation loss: 2.0654262676033923

Epoch: 5| Step: 4
Training loss: 1.651792287826538
Validation loss: 2.0705227569867204

Epoch: 5| Step: 5
Training loss: 2.205742359161377
Validation loss: 2.0521273382248415

Epoch: 5| Step: 6
Training loss: 2.0798189640045166
Validation loss: 2.0429300082627164

Epoch: 5| Step: 7
Training loss: 2.119810104370117
Validation loss: 2.043456600558373

Epoch: 5| Step: 8
Training loss: 2.6558806896209717
Validation loss: 2.075863212667486

Epoch: 5| Step: 9
Training loss: 1.778759241104126
Validation loss: 2.0109909529327066

Epoch: 5| Step: 10
Training loss: 1.866764783859253
Validation loss: 2.070808736226892

Epoch: 218| Step: 0
Training loss: 1.7467210292816162
Validation loss: 2.0280276729214575

Epoch: 5| Step: 1
Training loss: 1.9584671258926392
Validation loss: 2.0561108025171424

Epoch: 5| Step: 2
Training loss: 2.308903694152832
Validation loss: 2.050205925459503

Epoch: 5| Step: 3
Training loss: 2.0294508934020996
Validation loss: 2.0353491883124075

Epoch: 5| Step: 4
Training loss: 1.9260727167129517
Validation loss: 2.025675812075215

Epoch: 5| Step: 5
Training loss: 1.9282748699188232
Validation loss: 2.0247239438436364

Epoch: 5| Step: 6
Training loss: 2.09478497505188
Validation loss: 2.0357853776665142

Epoch: 5| Step: 7
Training loss: 2.0490355491638184
Validation loss: 1.9841945722538938

Epoch: 5| Step: 8
Training loss: 2.518872022628784
Validation loss: 2.0571261285453715

Epoch: 5| Step: 9
Training loss: 2.455383777618408
Validation loss: 2.0501914331989903

Epoch: 5| Step: 10
Training loss: 1.742374062538147
Validation loss: 2.0347325878758586

Epoch: 219| Step: 0
Training loss: 1.9939556121826172
Validation loss: 2.038596832624046

Epoch: 5| Step: 1
Training loss: 2.3822572231292725
Validation loss: 2.0576752680604176

Epoch: 5| Step: 2
Training loss: 2.2815160751342773
Validation loss: 2.041542701823737

Epoch: 5| Step: 3
Training loss: 2.2677512168884277
Validation loss: 2.051117589396815

Epoch: 5| Step: 4
Training loss: 2.080577850341797
Validation loss: 2.062891580725229

Epoch: 5| Step: 5
Training loss: 1.786489486694336
Validation loss: 2.0975469619997087

Epoch: 5| Step: 6
Training loss: 2.7047550678253174
Validation loss: 2.071295779238465

Epoch: 5| Step: 7
Training loss: 2.1048600673675537
Validation loss: 2.0646533696882186

Epoch: 5| Step: 8
Training loss: 1.2943941354751587
Validation loss: 2.046121790844907

Epoch: 5| Step: 9
Training loss: 1.8493906259536743
Validation loss: 2.0757654866864605

Epoch: 5| Step: 10
Training loss: 1.6971217393875122
Validation loss: 2.077804196265436

Epoch: 220| Step: 0
Training loss: 2.1876392364501953
Validation loss: 2.0990606379765335

Epoch: 5| Step: 1
Training loss: 1.824493646621704
Validation loss: 2.0493438628412064

Epoch: 5| Step: 2
Training loss: 2.370169162750244
Validation loss: 2.07740008190114

Epoch: 5| Step: 3
Training loss: 2.133577823638916
Validation loss: 2.045867307211763

Epoch: 5| Step: 4
Training loss: 1.8857752084732056
Validation loss: 2.047678578284479

Epoch: 5| Step: 5
Training loss: 2.668114185333252
Validation loss: 2.091724803370814

Epoch: 5| Step: 6
Training loss: 2.1949729919433594
Validation loss: 2.0787076719345583

Epoch: 5| Step: 7
Training loss: 1.5236408710479736
Validation loss: 2.0945859980839554

Epoch: 5| Step: 8
Training loss: 2.146963119506836
Validation loss: 2.0703581020396244

Epoch: 5| Step: 9
Training loss: 2.0378921031951904
Validation loss: 2.090316880133844

Epoch: 5| Step: 10
Training loss: 1.4074534177780151
Validation loss: 2.1198262091605895

Epoch: 221| Step: 0
Training loss: 1.519931435585022
Validation loss: 2.1141725765761508

Epoch: 5| Step: 1
Training loss: 1.4829108715057373
Validation loss: 2.0855233643644597

Epoch: 5| Step: 2
Training loss: 1.8354421854019165
Validation loss: 2.0576780419195853

Epoch: 5| Step: 3
Training loss: 2.0930466651916504
Validation loss: 2.090816649057532

Epoch: 5| Step: 4
Training loss: 2.2354931831359863
Validation loss: 2.108332316080729

Epoch: 5| Step: 5
Training loss: 2.2057406902313232
Validation loss: 2.095271933463312

Epoch: 5| Step: 6
Training loss: 1.9085077047348022
Validation loss: 2.0775156098027385

Epoch: 5| Step: 7
Training loss: 1.9902400970458984
Validation loss: 2.0585241574113087

Epoch: 5| Step: 8
Training loss: 3.124912738800049
Validation loss: 2.066385066637429

Epoch: 5| Step: 9
Training loss: 1.9891506433486938
Validation loss: 2.068221874134515

Epoch: 5| Step: 10
Training loss: 2.5357258319854736
Validation loss: 2.0949472150494977

Epoch: 222| Step: 0
Training loss: 2.2585949897766113
Validation loss: 2.0366154780951877

Epoch: 5| Step: 1
Training loss: 1.9962202310562134
Validation loss: 2.0697701323416924

Epoch: 5| Step: 2
Training loss: 1.6322176456451416
Validation loss: 2.0811941623687744

Epoch: 5| Step: 3
Training loss: 2.3991878032684326
Validation loss: 2.0768870243462185

Epoch: 5| Step: 4
Training loss: 1.8445247411727905
Validation loss: 2.068527683135002

Epoch: 5| Step: 5
Training loss: 1.7837145328521729
Validation loss: 2.054629930885889

Epoch: 5| Step: 6
Training loss: 1.7063376903533936
Validation loss: 2.0313543594011696

Epoch: 5| Step: 7
Training loss: 2.348245859146118
Validation loss: 2.036259074364939

Epoch: 5| Step: 8
Training loss: 1.653928518295288
Validation loss: 2.0351033287663616

Epoch: 5| Step: 9
Training loss: 2.595322847366333
Validation loss: 2.068231882587556

Epoch: 5| Step: 10
Training loss: 2.3195345401763916
Validation loss: 2.0463049257955244

Epoch: 223| Step: 0
Training loss: 1.601007103919983
Validation loss: 2.033853097628522

Epoch: 5| Step: 1
Training loss: 2.1618285179138184
Validation loss: 2.081262534664523

Epoch: 5| Step: 2
Training loss: 1.515615701675415
Validation loss: 2.027976187326575

Epoch: 5| Step: 3
Training loss: 1.6420570611953735
Validation loss: 2.029271751321772

Epoch: 5| Step: 4
Training loss: 2.610666275024414
Validation loss: 2.0922435637443297

Epoch: 5| Step: 5
Training loss: 1.980129599571228
Validation loss: 2.081226525768157

Epoch: 5| Step: 6
Training loss: 2.8857693672180176
Validation loss: 2.084545732826315

Epoch: 5| Step: 7
Training loss: 2.187572956085205
Validation loss: 2.0305989506424114

Epoch: 5| Step: 8
Training loss: 1.9748361110687256
Validation loss: 2.036434619657455

Epoch: 5| Step: 9
Training loss: 1.8065906763076782
Validation loss: 2.0870579750307146

Epoch: 5| Step: 10
Training loss: 2.115224599838257
Validation loss: 2.0743744655322005

Epoch: 224| Step: 0
Training loss: 3.0265302658081055
Validation loss: 2.043821116929413

Epoch: 5| Step: 1
Training loss: 1.6730926036834717
Validation loss: 2.062489237836612

Epoch: 5| Step: 2
Training loss: 1.7975540161132812
Validation loss: 2.083868608679823

Epoch: 5| Step: 3
Training loss: 1.77535080909729
Validation loss: 2.077384520602483

Epoch: 5| Step: 4
Training loss: 2.1823971271514893
Validation loss: 2.1014805186179375

Epoch: 5| Step: 5
Training loss: 2.0959115028381348
Validation loss: 2.0787993169599965

Epoch: 5| Step: 6
Training loss: 1.7584068775177002
Validation loss: 2.067621463088579

Epoch: 5| Step: 7
Training loss: 2.1834867000579834
Validation loss: 2.0437146245792346

Epoch: 5| Step: 8
Training loss: 2.3438448905944824
Validation loss: 2.077313377011207

Epoch: 5| Step: 9
Training loss: 1.9394928216934204
Validation loss: 2.1189734397395963

Epoch: 5| Step: 10
Training loss: 1.7872527837753296
Validation loss: 2.080055752108174

Epoch: 225| Step: 0
Training loss: 2.587860584259033
Validation loss: 2.057165220219602

Epoch: 5| Step: 1
Training loss: 1.6945120096206665
Validation loss: 2.0908100399919736

Epoch: 5| Step: 2
Training loss: 1.9117876291275024
Validation loss: 2.0512541917062577

Epoch: 5| Step: 3
Training loss: 1.7208023071289062
Validation loss: 2.096367102797313

Epoch: 5| Step: 4
Training loss: 2.520404815673828
Validation loss: 2.090893463421893

Epoch: 5| Step: 5
Training loss: 1.9616708755493164
Validation loss: 2.0561013798559866

Epoch: 5| Step: 6
Training loss: 2.4084060192108154
Validation loss: 2.069673658699118

Epoch: 5| Step: 7
Training loss: 2.198202610015869
Validation loss: 2.037483487077939

Epoch: 5| Step: 8
Training loss: 1.7750126123428345
Validation loss: 2.0763893242805236

Epoch: 5| Step: 9
Training loss: 2.1007065773010254
Validation loss: 2.046052517429475

Epoch: 5| Step: 10
Training loss: 1.3971391916275024
Validation loss: 2.049599224521268

Epoch: 226| Step: 0
Training loss: 1.949690580368042
Validation loss: 2.069902371334773

Epoch: 5| Step: 1
Training loss: 2.002870559692383
Validation loss: 2.0293289589625534

Epoch: 5| Step: 2
Training loss: 2.1186866760253906
Validation loss: 2.0683992601210073

Epoch: 5| Step: 3
Training loss: 2.257890462875366
Validation loss: 2.0558408973037556

Epoch: 5| Step: 4
Training loss: 1.9151639938354492
Validation loss: 2.057959533506824

Epoch: 5| Step: 5
Training loss: 2.4460415840148926
Validation loss: 1.996459972473883

Epoch: 5| Step: 6
Training loss: 1.5582658052444458
Validation loss: 2.0758643201602403

Epoch: 5| Step: 7
Training loss: 1.8081486225128174
Validation loss: 2.041948463327141

Epoch: 5| Step: 8
Training loss: 2.3569788932800293
Validation loss: 2.0712403661461285

Epoch: 5| Step: 9
Training loss: 1.9535640478134155
Validation loss: 2.072561985702925

Epoch: 5| Step: 10
Training loss: 1.8914247751235962
Validation loss: 2.062906598532072

Epoch: 227| Step: 0
Training loss: 2.1239514350891113
Validation loss: 2.069341025044841

Epoch: 5| Step: 1
Training loss: 1.944833755493164
Validation loss: 2.0392405909876667

Epoch: 5| Step: 2
Training loss: 2.065103769302368
Validation loss: 2.051121311803018

Epoch: 5| Step: 3
Training loss: 1.6020103693008423
Validation loss: 2.0650269139197563

Epoch: 5| Step: 4
Training loss: 1.4851850271224976
Validation loss: 2.0176252203602947

Epoch: 5| Step: 5
Training loss: 1.753847360610962
Validation loss: 2.025762100373545

Epoch: 5| Step: 6
Training loss: 2.3328537940979004
Validation loss: 2.039521227600754

Epoch: 5| Step: 7
Training loss: 2.2670977115631104
Validation loss: 2.048173696764054

Epoch: 5| Step: 8
Training loss: 2.4176135063171387
Validation loss: 2.0649348382026917

Epoch: 5| Step: 9
Training loss: 2.32576322555542
Validation loss: 2.072541723969162

Epoch: 5| Step: 10
Training loss: 2.0049891471862793
Validation loss: 2.081730846435793

Epoch: 228| Step: 0
Training loss: 2.1176908016204834
Validation loss: 2.0644596827927457

Epoch: 5| Step: 1
Training loss: 2.2524561882019043
Validation loss: 2.068176718168361

Epoch: 5| Step: 2
Training loss: 2.5626072883605957
Validation loss: 2.081016153417608

Epoch: 5| Step: 3
Training loss: 2.153799057006836
Validation loss: 2.0595354572419198

Epoch: 5| Step: 4
Training loss: 1.5566610097885132
Validation loss: 2.048259114706388

Epoch: 5| Step: 5
Training loss: 1.590714454650879
Validation loss: 2.1137933705442693

Epoch: 5| Step: 6
Training loss: 2.5748047828674316
Validation loss: 2.000047855479743

Epoch: 5| Step: 7
Training loss: 1.9666532278060913
Validation loss: 2.0550915810369674

Epoch: 5| Step: 8
Training loss: 1.7854163646697998
Validation loss: 2.0554240057545323

Epoch: 5| Step: 9
Training loss: 2.1870853900909424
Validation loss: 2.052560785765289

Epoch: 5| Step: 10
Training loss: 1.5521230697631836
Validation loss: 2.0092968633097987

Epoch: 229| Step: 0
Training loss: 1.6709716320037842
Validation loss: 2.0520382286399923

Epoch: 5| Step: 1
Training loss: 2.227720260620117
Validation loss: 2.021741792719851

Epoch: 5| Step: 2
Training loss: 1.8728183507919312
Validation loss: 2.096687214348906

Epoch: 5| Step: 3
Training loss: 1.8130910396575928
Validation loss: 2.066159174006472

Epoch: 5| Step: 4
Training loss: 1.8368308544158936
Validation loss: 2.067324956258138

Epoch: 5| Step: 5
Training loss: 2.0026469230651855
Validation loss: 2.0719964940060853

Epoch: 5| Step: 6
Training loss: 2.0563881397247314
Validation loss: 2.0673109600620885

Epoch: 5| Step: 7
Training loss: 2.0433011054992676
Validation loss: 2.052247634498022

Epoch: 5| Step: 8
Training loss: 2.2417616844177246
Validation loss: 2.043373877002347

Epoch: 5| Step: 9
Training loss: 2.174191951751709
Validation loss: 2.062980362164077

Epoch: 5| Step: 10
Training loss: 2.3266971111297607
Validation loss: 2.0865584996438797

Epoch: 230| Step: 0
Training loss: 1.9581512212753296
Validation loss: 2.091146679334743

Epoch: 5| Step: 1
Training loss: 2.261875629425049
Validation loss: 1.9929628423465195

Epoch: 5| Step: 2
Training loss: 1.4288570880889893
Validation loss: 2.0901672904209425

Epoch: 5| Step: 3
Training loss: 2.4598565101623535
Validation loss: 2.0381655872509046

Epoch: 5| Step: 4
Training loss: 2.066664218902588
Validation loss: 2.070282038821969

Epoch: 5| Step: 5
Training loss: 2.2401435375213623
Validation loss: 2.0363392932440645

Epoch: 5| Step: 6
Training loss: 1.8096015453338623
Validation loss: 2.0534602993278095

Epoch: 5| Step: 7
Training loss: 2.09318470954895
Validation loss: 2.0742720250160462

Epoch: 5| Step: 8
Training loss: 1.93557870388031
Validation loss: 2.064216088223201

Epoch: 5| Step: 9
Training loss: 1.930588722229004
Validation loss: 2.0611579187454714

Epoch: 5| Step: 10
Training loss: 2.4106671810150146
Validation loss: 2.0975259324555755

Epoch: 231| Step: 0
Training loss: 2.0930399894714355
Validation loss: 2.101562523072766

Epoch: 5| Step: 1
Training loss: 2.2982864379882812
Validation loss: 2.0723382965210946

Epoch: 5| Step: 2
Training loss: 1.5670074224472046
Validation loss: 2.062848287243997

Epoch: 5| Step: 3
Training loss: 2.150768995285034
Validation loss: 2.0970305601755777

Epoch: 5| Step: 4
Training loss: 2.0062434673309326
Validation loss: 2.1035413229337303

Epoch: 5| Step: 5
Training loss: 2.337944746017456
Validation loss: 2.118849951733825

Epoch: 5| Step: 6
Training loss: 2.1405441761016846
Validation loss: 2.086617103186987

Epoch: 5| Step: 7
Training loss: 1.844419240951538
Validation loss: 2.1284307305530836

Epoch: 5| Step: 8
Training loss: 2.348250150680542
Validation loss: 2.100904098121069

Epoch: 5| Step: 9
Training loss: 1.671680212020874
Validation loss: 2.076925854529104

Epoch: 5| Step: 10
Training loss: 1.948400855064392
Validation loss: 2.0745209186307845

Epoch: 232| Step: 0
Training loss: 1.6405887603759766
Validation loss: 2.0961312529861287

Epoch: 5| Step: 1
Training loss: 2.764003038406372
Validation loss: 2.0958036299674743

Epoch: 5| Step: 2
Training loss: 1.4700806140899658
Validation loss: 2.1056777072209183

Epoch: 5| Step: 3
Training loss: 2.1387808322906494
Validation loss: 2.080605230023784

Epoch: 5| Step: 4
Training loss: 2.0523600578308105
Validation loss: 2.1230323340303157

Epoch: 5| Step: 5
Training loss: 2.0098533630371094
Validation loss: 2.0669217878772366

Epoch: 5| Step: 6
Training loss: 2.7765018939971924
Validation loss: 2.080747860734181

Epoch: 5| Step: 7
Training loss: 2.2587637901306152
Validation loss: 2.04563820233909

Epoch: 5| Step: 8
Training loss: 1.7597099542617798
Validation loss: 2.0844623747692315

Epoch: 5| Step: 9
Training loss: 1.662888765335083
Validation loss: 2.1018083403187413

Epoch: 5| Step: 10
Training loss: 1.8582426309585571
Validation loss: 2.1195247891128703

Epoch: 233| Step: 0
Training loss: 1.9430828094482422
Validation loss: 2.0545731565003753

Epoch: 5| Step: 1
Training loss: 1.5979416370391846
Validation loss: 2.0994843770098943

Epoch: 5| Step: 2
Training loss: 2.091496467590332
Validation loss: 2.07119555370782

Epoch: 5| Step: 3
Training loss: 2.6653428077697754
Validation loss: 2.085826881470219

Epoch: 5| Step: 4
Training loss: 1.9002964496612549
Validation loss: 2.065420775003331

Epoch: 5| Step: 5
Training loss: 2.3394312858581543
Validation loss: 2.109815339888296

Epoch: 5| Step: 6
Training loss: 2.420518159866333
Validation loss: 2.0892446848653976

Epoch: 5| Step: 7
Training loss: 1.8674981594085693
Validation loss: 2.074502529636506

Epoch: 5| Step: 8
Training loss: 2.5639986991882324
Validation loss: 2.090187285536079

Epoch: 5| Step: 9
Training loss: 1.458197832107544
Validation loss: 2.0944917586541947

Epoch: 5| Step: 10
Training loss: 1.4021095037460327
Validation loss: 2.079308085544135

Epoch: 234| Step: 0
Training loss: 2.108736515045166
Validation loss: 2.064092892472462

Epoch: 5| Step: 1
Training loss: 2.2006101608276367
Validation loss: 2.0661605763179

Epoch: 5| Step: 2
Training loss: 2.514003038406372
Validation loss: 2.0701068421845794

Epoch: 5| Step: 3
Training loss: 1.7070236206054688
Validation loss: 2.084671422999392

Epoch: 5| Step: 4
Training loss: 1.845982551574707
Validation loss: 2.0936781770439556

Epoch: 5| Step: 5
Training loss: 1.6658790111541748
Validation loss: 2.0893727169241956

Epoch: 5| Step: 6
Training loss: 1.8282406330108643
Validation loss: 2.04330769149206

Epoch: 5| Step: 7
Training loss: 1.9892122745513916
Validation loss: 2.0402711886231617

Epoch: 5| Step: 8
Training loss: 1.855625867843628
Validation loss: 2.088844414680235

Epoch: 5| Step: 9
Training loss: 2.4589972496032715
Validation loss: 2.0661788858393186

Epoch: 5| Step: 10
Training loss: 1.9926732778549194
Validation loss: 2.0852430943519837

Epoch: 235| Step: 0
Training loss: 2.0159599781036377
Validation loss: 2.0581522500643166

Epoch: 5| Step: 1
Training loss: 1.6061092615127563
Validation loss: 2.0385034315047728

Epoch: 5| Step: 2
Training loss: 2.2982373237609863
Validation loss: 2.073971756042973

Epoch: 5| Step: 3
Training loss: 1.7267920970916748
Validation loss: 2.0321524027855165

Epoch: 5| Step: 4
Training loss: 1.9663242101669312
Validation loss: 2.063286704401816

Epoch: 5| Step: 5
Training loss: 2.764901876449585
Validation loss: 2.063300005851253

Epoch: 5| Step: 6
Training loss: 2.6012635231018066
Validation loss: 2.030885327246881

Epoch: 5| Step: 7
Training loss: 1.5924620628356934
Validation loss: 2.0258056771370674

Epoch: 5| Step: 8
Training loss: 1.7473294734954834
Validation loss: 2.0416362452250656

Epoch: 5| Step: 9
Training loss: 2.3011410236358643
Validation loss: 2.031030329324866

Epoch: 5| Step: 10
Training loss: 1.6815897226333618
Validation loss: 2.0041539515218427

Epoch: 236| Step: 0
Training loss: 2.156275987625122
Validation loss: 2.0527530793220765

Epoch: 5| Step: 1
Training loss: 2.196305274963379
Validation loss: 2.0666453761439167

Epoch: 5| Step: 2
Training loss: 2.0688979625701904
Validation loss: 2.066204365863595

Epoch: 5| Step: 3
Training loss: 1.1432406902313232
Validation loss: 2.0966260510106243

Epoch: 5| Step: 4
Training loss: 1.981873869895935
Validation loss: 2.090194785466758

Epoch: 5| Step: 5
Training loss: 1.833127737045288
Validation loss: 2.058020120025963

Epoch: 5| Step: 6
Training loss: 2.336326837539673
Validation loss: 2.0651876195784538

Epoch: 5| Step: 7
Training loss: 1.856614112854004
Validation loss: 2.052714519603278

Epoch: 5| Step: 8
Training loss: 2.33670973777771
Validation loss: 2.050418560222913

Epoch: 5| Step: 9
Training loss: 1.9554996490478516
Validation loss: 2.07649948007317

Epoch: 5| Step: 10
Training loss: 2.370523691177368
Validation loss: 2.094895415408637

Epoch: 237| Step: 0
Training loss: 2.320328950881958
Validation loss: 2.1337912595400246

Epoch: 5| Step: 1
Training loss: 1.979101538658142
Validation loss: 2.0676135452844764

Epoch: 5| Step: 2
Training loss: 1.241328239440918
Validation loss: 2.116108450838315

Epoch: 5| Step: 3
Training loss: 2.165247678756714
Validation loss: 2.105239901491391

Epoch: 5| Step: 4
Training loss: 2.9263482093811035
Validation loss: 2.078407718289283

Epoch: 5| Step: 5
Training loss: 2.138352632522583
Validation loss: 2.105384342132076

Epoch: 5| Step: 6
Training loss: 2.08626127243042
Validation loss: 2.107245461915129

Epoch: 5| Step: 7
Training loss: 2.6195669174194336
Validation loss: 2.0621300115380237

Epoch: 5| Step: 8
Training loss: 1.5646837949752808
Validation loss: 2.1050704589454075

Epoch: 5| Step: 9
Training loss: 1.7918593883514404
Validation loss: 2.0969376256389003

Epoch: 5| Step: 10
Training loss: 1.2681894302368164
Validation loss: 2.063222928713727

Epoch: 238| Step: 0
Training loss: 1.5094683170318604
Validation loss: 2.0924693717751452

Epoch: 5| Step: 1
Training loss: 1.9925353527069092
Validation loss: 2.1292138612398537

Epoch: 5| Step: 2
Training loss: 1.4528611898422241
Validation loss: 2.0782933799169396

Epoch: 5| Step: 3
Training loss: 2.5693793296813965
Validation loss: 2.100788571501291

Epoch: 5| Step: 4
Training loss: 1.5798076391220093
Validation loss: 2.074417096312328

Epoch: 5| Step: 5
Training loss: 2.1684296131134033
Validation loss: 2.0873025155836538

Epoch: 5| Step: 6
Training loss: 2.3939290046691895
Validation loss: 2.081137554619902

Epoch: 5| Step: 7
Training loss: 2.371210813522339
Validation loss: 2.1220858327804075

Epoch: 5| Step: 8
Training loss: 1.804973840713501
Validation loss: 2.075400992106366

Epoch: 5| Step: 9
Training loss: 2.6119964122772217
Validation loss: 2.0810685747413227

Epoch: 5| Step: 10
Training loss: 1.9271186590194702
Validation loss: 2.0736722177074802

Epoch: 239| Step: 0
Training loss: 1.7676975727081299
Validation loss: 2.042468335038872

Epoch: 5| Step: 1
Training loss: 1.236562967300415
Validation loss: 2.083799668537673

Epoch: 5| Step: 2
Training loss: 2.3431715965270996
Validation loss: 2.0279356330953617

Epoch: 5| Step: 3
Training loss: 2.47456693649292
Validation loss: 2.0138558700520504

Epoch: 5| Step: 4
Training loss: 1.6960175037384033
Validation loss: 2.0570843553030365

Epoch: 5| Step: 5
Training loss: 1.9093424081802368
Validation loss: 2.056816657384237

Epoch: 5| Step: 6
Training loss: 1.650984525680542
Validation loss: 2.036751147239439

Epoch: 5| Step: 7
Training loss: 3.0620675086975098
Validation loss: 2.0565204799816175

Epoch: 5| Step: 8
Training loss: 1.978907823562622
Validation loss: 2.032642424747508

Epoch: 5| Step: 9
Training loss: 1.9771655797958374
Validation loss: 2.062200697519446

Epoch: 5| Step: 10
Training loss: 1.8902407884597778
Validation loss: 2.073953761849352

Epoch: 240| Step: 0
Training loss: 1.6531833410263062
Validation loss: 2.1138659779743483

Epoch: 5| Step: 1
Training loss: 2.203479290008545
Validation loss: 2.069922229295136

Epoch: 5| Step: 2
Training loss: 1.6056091785430908
Validation loss: 2.0331489501460904

Epoch: 5| Step: 3
Training loss: 1.7335363626480103
Validation loss: 2.0622466597505795

Epoch: 5| Step: 4
Training loss: 2.237722396850586
Validation loss: 2.041748995422035

Epoch: 5| Step: 5
Training loss: 1.7772905826568604
Validation loss: 2.0654470843653523

Epoch: 5| Step: 6
Training loss: 2.3486099243164062
Validation loss: 2.048954681683612

Epoch: 5| Step: 7
Training loss: 2.136199951171875
Validation loss: 2.0497551951357114

Epoch: 5| Step: 8
Training loss: 2.1912741661071777
Validation loss: 2.058188433288246

Epoch: 5| Step: 9
Training loss: 2.1614737510681152
Validation loss: 2.055774119592482

Epoch: 5| Step: 10
Training loss: 2.103792667388916
Validation loss: 2.068065215182561

Epoch: 241| Step: 0
Training loss: 2.0424540042877197
Validation loss: 2.095087376973962

Epoch: 5| Step: 1
Training loss: 2.238039970397949
Validation loss: 2.0789991078838224

Epoch: 5| Step: 2
Training loss: 1.9650852680206299
Validation loss: 2.0748251099740305

Epoch: 5| Step: 3
Training loss: 1.377166509628296
Validation loss: 2.0846302816944737

Epoch: 5| Step: 4
Training loss: 1.716855764389038
Validation loss: 2.0696399160610732

Epoch: 5| Step: 5
Training loss: 2.0833323001861572
Validation loss: 2.1032798726071595

Epoch: 5| Step: 6
Training loss: 2.3354430198669434
Validation loss: 2.0852679347479217

Epoch: 5| Step: 7
Training loss: 1.773908257484436
Validation loss: 2.090352613438842

Epoch: 5| Step: 8
Training loss: 2.201587677001953
Validation loss: 2.0924316144758657

Epoch: 5| Step: 9
Training loss: 2.0277280807495117
Validation loss: 2.077878446989162

Epoch: 5| Step: 10
Training loss: 2.6234278678894043
Validation loss: 2.067989662129392

Epoch: 242| Step: 0
Training loss: 2.0632219314575195
Validation loss: 2.063888648504852

Epoch: 5| Step: 1
Training loss: 2.150235652923584
Validation loss: 2.072569768915894

Epoch: 5| Step: 2
Training loss: 1.8281996250152588
Validation loss: 2.0864472248220958

Epoch: 5| Step: 3
Training loss: 2.274564743041992
Validation loss: 2.0822362720325427

Epoch: 5| Step: 4
Training loss: 2.2477874755859375
Validation loss: 2.0958332169440483

Epoch: 5| Step: 5
Training loss: 1.8845770359039307
Validation loss: 2.091362199475688

Epoch: 5| Step: 6
Training loss: 1.7824299335479736
Validation loss: 2.0753968095266693

Epoch: 5| Step: 7
Training loss: 1.8536866903305054
Validation loss: 2.034544910154035

Epoch: 5| Step: 8
Training loss: 1.5232053995132446
Validation loss: 2.116457344383322

Epoch: 5| Step: 9
Training loss: 1.7898690700531006
Validation loss: 2.082983632241526

Epoch: 5| Step: 10
Training loss: 2.677337646484375
Validation loss: 2.0701825567471084

Epoch: 243| Step: 0
Training loss: 1.8671010732650757
Validation loss: 2.100624494655158

Epoch: 5| Step: 1
Training loss: 1.8493608236312866
Validation loss: 2.1072813926204557

Epoch: 5| Step: 2
Training loss: 2.011240005493164
Validation loss: 2.0748039727569907

Epoch: 5| Step: 3
Training loss: 1.920885443687439
Validation loss: 2.1151576926631313

Epoch: 5| Step: 4
Training loss: 1.9144141674041748
Validation loss: 2.080367616427842

Epoch: 5| Step: 5
Training loss: 2.0184733867645264
Validation loss: 2.087697082950223

Epoch: 5| Step: 6
Training loss: 2.66109299659729
Validation loss: 2.0782933555623537

Epoch: 5| Step: 7
Training loss: 2.2056405544281006
Validation loss: 2.0637609945830477

Epoch: 5| Step: 8
Training loss: 1.5496355295181274
Validation loss: 2.0661537852338565

Epoch: 5| Step: 9
Training loss: 1.6083694696426392
Validation loss: 2.062399971869684

Epoch: 5| Step: 10
Training loss: 2.603591203689575
Validation loss: 2.029255167130501

Epoch: 244| Step: 0
Training loss: 2.0498433113098145
Validation loss: 2.071602903386598

Epoch: 5| Step: 1
Training loss: 1.7957324981689453
Validation loss: 2.0991742149476083

Epoch: 5| Step: 2
Training loss: 1.8387559652328491
Validation loss: 2.03718239004894

Epoch: 5| Step: 3
Training loss: 2.0551400184631348
Validation loss: 2.074671180017533

Epoch: 5| Step: 4
Training loss: 1.5398495197296143
Validation loss: 2.038236356550647

Epoch: 5| Step: 5
Training loss: 2.6049633026123047
Validation loss: 2.009427851246249

Epoch: 5| Step: 6
Training loss: 1.8937562704086304
Validation loss: 2.0352211318990236

Epoch: 5| Step: 7
Training loss: 1.8241803646087646
Validation loss: 2.0495073231317664

Epoch: 5| Step: 8
Training loss: 2.408639430999756
Validation loss: 2.1011136501066145

Epoch: 5| Step: 9
Training loss: 2.0084736347198486
Validation loss: 2.027691864198254

Epoch: 5| Step: 10
Training loss: 2.0084099769592285
Validation loss: 2.0132470028374785

Epoch: 245| Step: 0
Training loss: 1.8821468353271484
Validation loss: 2.059842819808632

Epoch: 5| Step: 1
Training loss: 1.9068753719329834
Validation loss: 2.033998502198086

Epoch: 5| Step: 2
Training loss: 1.9642994403839111
Validation loss: 2.03759572070132

Epoch: 5| Step: 3
Training loss: 2.110273838043213
Validation loss: 2.0847147126351633

Epoch: 5| Step: 4
Training loss: 1.9010260105133057
Validation loss: 2.0983562366936797

Epoch: 5| Step: 5
Training loss: 2.449153423309326
Validation loss: 2.09578901080675

Epoch: 5| Step: 6
Training loss: 1.3074162006378174
Validation loss: 2.0436981480608702

Epoch: 5| Step: 7
Training loss: 1.742553472518921
Validation loss: 2.1098360451318885

Epoch: 5| Step: 8
Training loss: 2.26041316986084
Validation loss: 2.0468815526654645

Epoch: 5| Step: 9
Training loss: 2.3143229484558105
Validation loss: 2.115811429997926

Epoch: 5| Step: 10
Training loss: 2.0593624114990234
Validation loss: 2.03861968107121

Epoch: 246| Step: 0
Training loss: 2.0939457416534424
Validation loss: 2.0909984534786594

Epoch: 5| Step: 1
Training loss: 2.971137046813965
Validation loss: 2.1034722892186974

Epoch: 5| Step: 2
Training loss: 2.0245585441589355
Validation loss: 2.0807440434732745

Epoch: 5| Step: 3
Training loss: 2.345048189163208
Validation loss: 2.076302118198846

Epoch: 5| Step: 4
Training loss: 2.068024158477783
Validation loss: 2.0654178575802873

Epoch: 5| Step: 5
Training loss: 2.242496967315674
Validation loss: 2.092160568442396

Epoch: 5| Step: 6
Training loss: 1.6223472356796265
Validation loss: 2.102623877986785

Epoch: 5| Step: 7
Training loss: 1.4290450811386108
Validation loss: 2.051929594368063

Epoch: 5| Step: 8
Training loss: 1.5344305038452148
Validation loss: 2.0903759476959065

Epoch: 5| Step: 9
Training loss: 1.6878092288970947
Validation loss: 2.0593199781192246

Epoch: 5| Step: 10
Training loss: 2.2434163093566895
Validation loss: 2.0798429186626146

Epoch: 247| Step: 0
Training loss: 1.960630178451538
Validation loss: 2.1052570137926327

Epoch: 5| Step: 1
Training loss: 2.3892877101898193
Validation loss: 2.0907563291570193

Epoch: 5| Step: 2
Training loss: 1.8629019260406494
Validation loss: 2.0596008634054535

Epoch: 5| Step: 3
Training loss: 2.2559590339660645
Validation loss: 2.043860443176762

Epoch: 5| Step: 4
Training loss: 2.166571855545044
Validation loss: 2.1095107857899

Epoch: 5| Step: 5
Training loss: 1.9577572345733643
Validation loss: 2.10549440691548

Epoch: 5| Step: 6
Training loss: 2.1086416244506836
Validation loss: 2.087498018818517

Epoch: 5| Step: 7
Training loss: 2.3316943645477295
Validation loss: 2.0810742660235335

Epoch: 5| Step: 8
Training loss: 1.8994381427764893
Validation loss: 2.062894554548366

Epoch: 5| Step: 9
Training loss: 1.3233363628387451
Validation loss: 2.075396971036029

Epoch: 5| Step: 10
Training loss: 1.7311080694198608
Validation loss: 2.084293629533501

Epoch: 248| Step: 0
Training loss: 2.0801713466644287
Validation loss: 2.0613834473394577

Epoch: 5| Step: 1
Training loss: 1.5522255897521973
Validation loss: 2.066039441734232

Epoch: 5| Step: 2
Training loss: 1.7518033981323242
Validation loss: 2.0433045100140315

Epoch: 5| Step: 3
Training loss: 1.9743916988372803
Validation loss: 2.001148521259267

Epoch: 5| Step: 4
Training loss: 2.7585537433624268
Validation loss: 2.079786923623854

Epoch: 5| Step: 5
Training loss: 2.493218183517456
Validation loss: 2.027257009219098

Epoch: 5| Step: 6
Training loss: 2.403395891189575
Validation loss: 2.114536422555165

Epoch: 5| Step: 7
Training loss: 2.0804810523986816
Validation loss: 2.0469474651480235

Epoch: 5| Step: 8
Training loss: 1.6136353015899658
Validation loss: 2.0866612054968394

Epoch: 5| Step: 9
Training loss: 1.8534183502197266
Validation loss: 2.076087713241577

Epoch: 5| Step: 10
Training loss: 1.3710070848464966
Validation loss: 2.070988944781724

Epoch: 249| Step: 0
Training loss: 2.2379581928253174
Validation loss: 2.0440001180095058

Epoch: 5| Step: 1
Training loss: 1.8845361471176147
Validation loss: 2.1173007616432766

Epoch: 5| Step: 2
Training loss: 1.9037954807281494
Validation loss: 2.077587418658759

Epoch: 5| Step: 3
Training loss: 1.6582622528076172
Validation loss: 2.063663590338922

Epoch: 5| Step: 4
Training loss: 2.149425983428955
Validation loss: 2.033531670929283

Epoch: 5| Step: 5
Training loss: 2.1132330894470215
Validation loss: 2.046377110224898

Epoch: 5| Step: 6
Training loss: 2.3000073432922363
Validation loss: 2.0335962926187823

Epoch: 5| Step: 7
Training loss: 1.8635952472686768
Validation loss: 2.0570172648276053

Epoch: 5| Step: 8
Training loss: 2.5590243339538574
Validation loss: 2.035898439345821

Epoch: 5| Step: 9
Training loss: 1.8154337406158447
Validation loss: 2.020950440437563

Epoch: 5| Step: 10
Training loss: 1.7925026416778564
Validation loss: 2.070077321862662

Epoch: 250| Step: 0
Training loss: 1.595692753791809
Validation loss: 2.080222882250304

Epoch: 5| Step: 1
Training loss: 2.119065523147583
Validation loss: 2.0668738965065248

Epoch: 5| Step: 2
Training loss: 2.395275592803955
Validation loss: 2.028994027004447

Epoch: 5| Step: 3
Training loss: 2.1465001106262207
Validation loss: 2.082281261362055

Epoch: 5| Step: 4
Training loss: 2.5260350704193115
Validation loss: 2.0392140893525976

Epoch: 5| Step: 5
Training loss: 1.4996721744537354
Validation loss: 2.1170118931801087

Epoch: 5| Step: 6
Training loss: 1.8008877038955688
Validation loss: 2.091976099116828

Epoch: 5| Step: 7
Training loss: 1.8726266622543335
Validation loss: 2.044652810660742

Epoch: 5| Step: 8
Training loss: 1.8341553211212158
Validation loss: 2.080032802397205

Epoch: 5| Step: 9
Training loss: 1.8913357257843018
Validation loss: 2.0900133912281325

Epoch: 5| Step: 10
Training loss: 2.163651704788208
Validation loss: 2.0532578473450034

Epoch: 251| Step: 0
Training loss: 2.5726211071014404
Validation loss: 2.072582439709735

Epoch: 5| Step: 1
Training loss: 1.6589820384979248
Validation loss: 2.025598604192016

Epoch: 5| Step: 2
Training loss: 1.8607828617095947
Validation loss: 2.0876804218497327

Epoch: 5| Step: 3
Training loss: 2.121612787246704
Validation loss: 2.077676284697748

Epoch: 5| Step: 4
Training loss: 2.0046963691711426
Validation loss: 2.093712745174285

Epoch: 5| Step: 5
Training loss: 1.7840839624404907
Validation loss: 2.110477852564986

Epoch: 5| Step: 6
Training loss: 1.8639129400253296
Validation loss: 2.0763316846662954

Epoch: 5| Step: 7
Training loss: 1.8052504062652588
Validation loss: 2.011247624633133

Epoch: 5| Step: 8
Training loss: 1.8119077682495117
Validation loss: 2.064859154403851

Epoch: 5| Step: 9
Training loss: 1.8603242635726929
Validation loss: 2.105579239065929

Epoch: 5| Step: 10
Training loss: 2.6227452754974365
Validation loss: 2.0502122217609036

Epoch: 252| Step: 0
Training loss: 2.687671184539795
Validation loss: 2.1050539837088635

Epoch: 5| Step: 1
Training loss: 1.4685018062591553
Validation loss: 2.0759547346381733

Epoch: 5| Step: 2
Training loss: 1.7032678127288818
Validation loss: 2.085598953308598

Epoch: 5| Step: 3
Training loss: 2.08046293258667
Validation loss: 2.1076093348123695

Epoch: 5| Step: 4
Training loss: 1.8623533248901367
Validation loss: 2.117485838551675

Epoch: 5| Step: 5
Training loss: 1.6222509145736694
Validation loss: 2.0653659348846762

Epoch: 5| Step: 6
Training loss: 1.6729371547698975
Validation loss: 2.0395299234697895

Epoch: 5| Step: 7
Training loss: 2.6655631065368652
Validation loss: 2.04139212126373

Epoch: 5| Step: 8
Training loss: 1.8422508239746094
Validation loss: 2.1155920464505433

Epoch: 5| Step: 9
Training loss: 1.8274104595184326
Validation loss: 2.07577347242704

Epoch: 5| Step: 10
Training loss: 2.3307788372039795
Validation loss: 2.0832760231469267

Epoch: 253| Step: 0
Training loss: 1.9185199737548828
Validation loss: 2.0569255839111986

Epoch: 5| Step: 1
Training loss: 2.6771762371063232
Validation loss: 2.0538154058558966

Epoch: 5| Step: 2
Training loss: 2.1659586429595947
Validation loss: 2.0548617814176824

Epoch: 5| Step: 3
Training loss: 1.8152164220809937
Validation loss: 2.043950580781506

Epoch: 5| Step: 4
Training loss: 2.0795845985412598
Validation loss: 2.063299294440977

Epoch: 5| Step: 5
Training loss: 1.4160901308059692
Validation loss: 2.017469950901565

Epoch: 5| Step: 6
Training loss: 1.7301762104034424
Validation loss: 2.072730295119747

Epoch: 5| Step: 7
Training loss: 1.6443355083465576
Validation loss: 2.0498148446441977

Epoch: 5| Step: 8
Training loss: 1.8737596273422241
Validation loss: 2.0541114781492498

Epoch: 5| Step: 9
Training loss: 1.8659851551055908
Validation loss: 2.0382794487860894

Epoch: 5| Step: 10
Training loss: 2.6255531311035156
Validation loss: 2.0388121246009745

Epoch: 254| Step: 0
Training loss: 1.8748239278793335
Validation loss: 2.0648876287603892

Epoch: 5| Step: 1
Training loss: 2.511910915374756
Validation loss: 2.0601761033458095

Epoch: 5| Step: 2
Training loss: 1.7967151403427124
Validation loss: 2.136397951392717

Epoch: 5| Step: 3
Training loss: 2.192255735397339
Validation loss: 2.0816589017068186

Epoch: 5| Step: 4
Training loss: 1.571933388710022
Validation loss: 2.0992645999436736

Epoch: 5| Step: 5
Training loss: 1.7312043905258179
Validation loss: 2.081177217985994

Epoch: 5| Step: 6
Training loss: 1.5759146213531494
Validation loss: 2.1027342081069946

Epoch: 5| Step: 7
Training loss: 1.6510288715362549
Validation loss: 2.041472593943278

Epoch: 5| Step: 8
Training loss: 2.5792136192321777
Validation loss: 2.068106597469699

Epoch: 5| Step: 9
Training loss: 2.1250784397125244
Validation loss: 2.100659916477819

Epoch: 5| Step: 10
Training loss: 2.1887502670288086
Validation loss: 2.1394299563541206

Epoch: 255| Step: 0
Training loss: 2.1888389587402344
Validation loss: 2.114495685023646

Epoch: 5| Step: 1
Training loss: 2.291187047958374
Validation loss: 2.1131425698598227

Epoch: 5| Step: 2
Training loss: 2.6031851768493652
Validation loss: 2.116657431407641

Epoch: 5| Step: 3
Training loss: 1.9480602741241455
Validation loss: 2.0884779755787184

Epoch: 5| Step: 4
Training loss: 2.158188581466675
Validation loss: 2.0678695222382903

Epoch: 5| Step: 5
Training loss: 0.987652599811554
Validation loss: 2.0726135879434566

Epoch: 5| Step: 6
Training loss: 1.864659070968628
Validation loss: 2.121803806674096

Epoch: 5| Step: 7
Training loss: 2.021228313446045
Validation loss: 2.075948835701071

Epoch: 5| Step: 8
Training loss: 1.7881450653076172
Validation loss: 2.1019529655415523

Epoch: 5| Step: 9
Training loss: 1.6680021286010742
Validation loss: 2.0708130956977926

Epoch: 5| Step: 10
Training loss: 2.225651979446411
Validation loss: 2.033451295668079

Epoch: 256| Step: 0
Training loss: 2.0385069847106934
Validation loss: 2.0805753225921304

Epoch: 5| Step: 1
Training loss: 1.8698358535766602
Validation loss: 2.060260990614532

Epoch: 5| Step: 2
Training loss: 1.6618305444717407
Validation loss: 2.092274917069302

Epoch: 5| Step: 3
Training loss: 2.0779383182525635
Validation loss: 2.085583561210222

Epoch: 5| Step: 4
Training loss: 1.850368857383728
Validation loss: 2.0356805298918035

Epoch: 5| Step: 5
Training loss: 2.123025417327881
Validation loss: 2.0415736962390203

Epoch: 5| Step: 6
Training loss: 2.0325825214385986
Validation loss: 2.0730489069415676

Epoch: 5| Step: 7
Training loss: 2.239562511444092
Validation loss: 2.0493793833640312

Epoch: 5| Step: 8
Training loss: 1.5722417831420898
Validation loss: 2.055754715396512

Epoch: 5| Step: 9
Training loss: 1.68008553981781
Validation loss: 2.0553323171472035

Epoch: 5| Step: 10
Training loss: 2.787796974182129
Validation loss: 2.044798651049214

Epoch: 257| Step: 0
Training loss: 1.6942020654678345
Validation loss: 2.0273676174943165

Epoch: 5| Step: 1
Training loss: 1.9567142724990845
Validation loss: 2.089567356212165

Epoch: 5| Step: 2
Training loss: 2.2736992835998535
Validation loss: 2.084177291521462

Epoch: 5| Step: 3
Training loss: 1.984164834022522
Validation loss: 2.04788641519444

Epoch: 5| Step: 4
Training loss: 1.9443126916885376
Validation loss: 2.031030167815506

Epoch: 5| Step: 5
Training loss: 2.4171998500823975
Validation loss: 2.064739775914018

Epoch: 5| Step: 6
Training loss: 2.018247127532959
Validation loss: 2.075646956761678

Epoch: 5| Step: 7
Training loss: 1.9744716882705688
Validation loss: 2.093272918014116

Epoch: 5| Step: 8
Training loss: 1.671552062034607
Validation loss: 2.0905806326097056

Epoch: 5| Step: 9
Training loss: 1.5681673288345337
Validation loss: 2.0822973494888632

Epoch: 5| Step: 10
Training loss: 2.223050594329834
Validation loss: 2.0773232278003486

Epoch: 258| Step: 0
Training loss: 1.674173355102539
Validation loss: 2.0562269790198213

Epoch: 5| Step: 1
Training loss: 1.890751600265503
Validation loss: 2.1091947760633243

Epoch: 5| Step: 2
Training loss: 2.3518905639648438
Validation loss: 2.077037867679391

Epoch: 5| Step: 3
Training loss: 1.7939817905426025
Validation loss: 2.0459231074138353

Epoch: 5| Step: 4
Training loss: 1.8267509937286377
Validation loss: 2.0853823756658905

Epoch: 5| Step: 5
Training loss: 1.4881410598754883
Validation loss: 2.0947657964562856

Epoch: 5| Step: 6
Training loss: 1.9971586465835571
Validation loss: 2.077019191557361

Epoch: 5| Step: 7
Training loss: 1.9358803033828735
Validation loss: 2.0508043907021962

Epoch: 5| Step: 8
Training loss: 2.3265528678894043
Validation loss: 2.0951426285569386

Epoch: 5| Step: 9
Training loss: 2.269083261489868
Validation loss: 2.0813312120335077

Epoch: 5| Step: 10
Training loss: 2.324789524078369
Validation loss: 2.084439951886413

Epoch: 259| Step: 0
Training loss: 1.7294018268585205
Validation loss: 2.07240201580909

Epoch: 5| Step: 1
Training loss: 2.0409646034240723
Validation loss: 2.0888616628544305

Epoch: 5| Step: 2
Training loss: 1.554441213607788
Validation loss: 2.0870782944463913

Epoch: 5| Step: 3
Training loss: 1.9803104400634766
Validation loss: 2.0935760492919595

Epoch: 5| Step: 4
Training loss: 1.1288478374481201
Validation loss: 2.095458433192263

Epoch: 5| Step: 5
Training loss: 2.328340768814087
Validation loss: 2.060840159334162

Epoch: 5| Step: 6
Training loss: 2.2924745082855225
Validation loss: 2.104118921423471

Epoch: 5| Step: 7
Training loss: 2.140899181365967
Validation loss: 2.1071152276890253

Epoch: 5| Step: 8
Training loss: 2.454989194869995
Validation loss: 2.098959656171901

Epoch: 5| Step: 9
Training loss: 1.379223108291626
Validation loss: 2.077287020221833

Epoch: 5| Step: 10
Training loss: 2.6972451210021973
Validation loss: 2.084792249946184

Epoch: 260| Step: 0
Training loss: 1.8293167352676392
Validation loss: 2.073810692756407

Epoch: 5| Step: 1
Training loss: 1.2636659145355225
Validation loss: 2.0499126129252936

Epoch: 5| Step: 2
Training loss: 2.0285515785217285
Validation loss: 2.0815428046769995

Epoch: 5| Step: 3
Training loss: 2.054169178009033
Validation loss: 2.07296996988276

Epoch: 5| Step: 4
Training loss: 1.4563753604888916
Validation loss: 2.0641186955154582

Epoch: 5| Step: 5
Training loss: 1.8671619892120361
Validation loss: 2.0450519720713296

Epoch: 5| Step: 6
Training loss: 2.084796667098999
Validation loss: 2.09706473735071

Epoch: 5| Step: 7
Training loss: 2.3840363025665283
Validation loss: 2.0714660370221702

Epoch: 5| Step: 8
Training loss: 2.3625593185424805
Validation loss: 2.046693126360575

Epoch: 5| Step: 9
Training loss: 2.0837056636810303
Validation loss: 2.071661385156775

Epoch: 5| Step: 10
Training loss: 2.5067152976989746
Validation loss: 2.059820612271627

Epoch: 261| Step: 0
Training loss: 1.6638683080673218
Validation loss: 2.1039353493721253

Epoch: 5| Step: 1
Training loss: 1.948012351989746
Validation loss: 2.0904278293732674

Epoch: 5| Step: 2
Training loss: 2.2532589435577393
Validation loss: 2.074829437399423

Epoch: 5| Step: 3
Training loss: 1.939192533493042
Validation loss: 2.0559827948129303

Epoch: 5| Step: 4
Training loss: 1.8654558658599854
Validation loss: 2.0307534176816224

Epoch: 5| Step: 5
Training loss: 2.3934166431427
Validation loss: 2.0380417992991786

Epoch: 5| Step: 6
Training loss: 1.5720555782318115
Validation loss: 2.0740876531088226

Epoch: 5| Step: 7
Training loss: 1.9551366567611694
Validation loss: 2.0577753961727185

Epoch: 5| Step: 8
Training loss: 1.5550501346588135
Validation loss: 2.026244423722708

Epoch: 5| Step: 9
Training loss: 1.9360628128051758
Validation loss: 2.053877830505371

Epoch: 5| Step: 10
Training loss: 2.7404134273529053
Validation loss: 2.0728006670551915

Epoch: 262| Step: 0
Training loss: 1.7351024150848389
Validation loss: 2.080132638254473

Epoch: 5| Step: 1
Training loss: 2.48078989982605
Validation loss: 2.080706560483543

Epoch: 5| Step: 2
Training loss: 1.8899967670440674
Validation loss: 2.0448941171810193

Epoch: 5| Step: 3
Training loss: 1.808005928993225
Validation loss: 2.0824938576708556

Epoch: 5| Step: 4
Training loss: 2.3055195808410645
Validation loss: 2.066125149367958

Epoch: 5| Step: 5
Training loss: 1.9193286895751953
Validation loss: 2.0830492486235914

Epoch: 5| Step: 6
Training loss: 2.0103914737701416
Validation loss: 2.0591173633452384

Epoch: 5| Step: 7
Training loss: 1.7176933288574219
Validation loss: 2.085186109747938

Epoch: 5| Step: 8
Training loss: 2.1517462730407715
Validation loss: 2.089726330131613

Epoch: 5| Step: 9
Training loss: 2.0424888134002686
Validation loss: 2.0470921224163425

Epoch: 5| Step: 10
Training loss: 1.826479196548462
Validation loss: 2.034033852238809

Epoch: 263| Step: 0
Training loss: 1.6954606771469116
Validation loss: 2.0630967437580066

Epoch: 5| Step: 1
Training loss: 1.8105266094207764
Validation loss: 2.0893398741240143

Epoch: 5| Step: 2
Training loss: 1.6527202129364014
Validation loss: 2.0750454215593237

Epoch: 5| Step: 3
Training loss: 2.2687251567840576
Validation loss: 2.098250091716807

Epoch: 5| Step: 4
Training loss: 2.343662738800049
Validation loss: 2.0796386349585747

Epoch: 5| Step: 5
Training loss: 1.9098259210586548
Validation loss: 2.0759912049898537

Epoch: 5| Step: 6
Training loss: 2.0770838260650635
Validation loss: 2.0745560917803036

Epoch: 5| Step: 7
Training loss: 1.4903912544250488
Validation loss: 2.0936504294795375

Epoch: 5| Step: 8
Training loss: 1.9468759298324585
Validation loss: 2.0824194364650275

Epoch: 5| Step: 9
Training loss: 2.1272928714752197
Validation loss: 2.0934998309740456

Epoch: 5| Step: 10
Training loss: 2.3909435272216797
Validation loss: 2.1054332845954487

Epoch: 264| Step: 0
Training loss: 2.3256239891052246
Validation loss: 2.073620750058082

Epoch: 5| Step: 1
Training loss: 1.8925487995147705
Validation loss: 2.047357468194859

Epoch: 5| Step: 2
Training loss: 1.6054242849349976
Validation loss: 2.061701222132611

Epoch: 5| Step: 3
Training loss: 1.8543660640716553
Validation loss: 2.065791840194374

Epoch: 5| Step: 4
Training loss: 1.8193025588989258
Validation loss: 2.0728111036362185

Epoch: 5| Step: 5
Training loss: 1.850033164024353
Validation loss: 2.042688451787477

Epoch: 5| Step: 6
Training loss: 2.2366957664489746
Validation loss: 2.057670017724396

Epoch: 5| Step: 7
Training loss: 1.7296180725097656
Validation loss: 2.103217068538871

Epoch: 5| Step: 8
Training loss: 2.0472848415374756
Validation loss: 2.0867327618342575

Epoch: 5| Step: 9
Training loss: 1.561597228050232
Validation loss: 2.07246091417087

Epoch: 5| Step: 10
Training loss: 2.5653083324432373
Validation loss: 2.1254505649689706

Epoch: 265| Step: 0
Training loss: 2.12042498588562
Validation loss: 2.062869328324513

Epoch: 5| Step: 1
Training loss: 1.6136505603790283
Validation loss: 2.126034749451504

Epoch: 5| Step: 2
Training loss: 1.6531994342803955
Validation loss: 2.080545376705867

Epoch: 5| Step: 3
Training loss: 2.3799102306365967
Validation loss: 2.0305469036102295

Epoch: 5| Step: 4
Training loss: 1.477654218673706
Validation loss: 2.094373696593828

Epoch: 5| Step: 5
Training loss: 1.8643436431884766
Validation loss: 2.0714682943077496

Epoch: 5| Step: 6
Training loss: 2.240805149078369
Validation loss: 2.0758235928832844

Epoch: 5| Step: 7
Training loss: 2.1623191833496094
Validation loss: 2.0665325131467593

Epoch: 5| Step: 8
Training loss: 1.9506094455718994
Validation loss: 2.0363018448634813

Epoch: 5| Step: 9
Training loss: 2.327939510345459
Validation loss: 2.0896462163617535

Epoch: 5| Step: 10
Training loss: 1.537644863128662
Validation loss: 2.050375476960213

Epoch: 266| Step: 0
Training loss: 2.5089006423950195
Validation loss: 2.088759596629809

Epoch: 5| Step: 1
Training loss: 2.0018439292907715
Validation loss: 2.0582574926396853

Epoch: 5| Step: 2
Training loss: 1.6062042713165283
Validation loss: 2.090371104978746

Epoch: 5| Step: 3
Training loss: 2.28751802444458
Validation loss: 2.0583511603775846

Epoch: 5| Step: 4
Training loss: 2.3415844440460205
Validation loss: 2.0643559117471018

Epoch: 5| Step: 5
Training loss: 1.9640285968780518
Validation loss: 2.015673739935762

Epoch: 5| Step: 6
Training loss: 1.8225551843643188
Validation loss: 2.0879724358999603

Epoch: 5| Step: 7
Training loss: 1.9436581134796143
Validation loss: 2.0468319616010113

Epoch: 5| Step: 8
Training loss: 1.4750168323516846
Validation loss: 2.1038395525306783

Epoch: 5| Step: 9
Training loss: 1.9843690395355225
Validation loss: 2.095580554777576

Epoch: 5| Step: 10
Training loss: 2.005129098892212
Validation loss: 2.0828434600624988

Epoch: 267| Step: 0
Training loss: 1.9020354747772217
Validation loss: 2.0598497262565036

Epoch: 5| Step: 1
Training loss: 1.614720106124878
Validation loss: 2.0591143536311325

Epoch: 5| Step: 2
Training loss: 2.3976402282714844
Validation loss: 2.0979728621821248

Epoch: 5| Step: 3
Training loss: 1.4402819871902466
Validation loss: 2.0307435886834257

Epoch: 5| Step: 4
Training loss: 1.452608346939087
Validation loss: 2.091705483774985

Epoch: 5| Step: 5
Training loss: 2.3438055515289307
Validation loss: 2.0775670774521364

Epoch: 5| Step: 6
Training loss: 1.9490619897842407
Validation loss: 2.1125604388534382

Epoch: 5| Step: 7
Training loss: 1.5724375247955322
Validation loss: 2.1004582656327115

Epoch: 5| Step: 8
Training loss: 2.1923611164093018
Validation loss: 2.0516834310306016

Epoch: 5| Step: 9
Training loss: 2.6005101203918457
Validation loss: 2.100449251872237

Epoch: 5| Step: 10
Training loss: 1.7220910787582397
Validation loss: 2.06488884392605

Epoch: 268| Step: 0
Training loss: 1.6977951526641846
Validation loss: 2.0818088259748233

Epoch: 5| Step: 1
Training loss: 1.553094506263733
Validation loss: 2.0929894960054787

Epoch: 5| Step: 2
Training loss: 2.1609745025634766
Validation loss: 2.124265819467524

Epoch: 5| Step: 3
Training loss: 1.6777855157852173
Validation loss: 2.1303471647283083

Epoch: 5| Step: 4
Training loss: 2.424609661102295
Validation loss: 2.0925925559895013

Epoch: 5| Step: 5
Training loss: 1.9942359924316406
Validation loss: 2.0849772601999264

Epoch: 5| Step: 6
Training loss: 1.6604721546173096
Validation loss: 2.0926463514245968

Epoch: 5| Step: 7
Training loss: 1.736322045326233
Validation loss: 2.0723660017854426

Epoch: 5| Step: 8
Training loss: 2.273993968963623
Validation loss: 2.055094026750134

Epoch: 5| Step: 9
Training loss: 2.396681070327759
Validation loss: 2.080812556769258

Epoch: 5| Step: 10
Training loss: 2.02659273147583
Validation loss: 2.081647978034071

Epoch: 269| Step: 0
Training loss: 2.76469087600708
Validation loss: 2.061390338405486

Epoch: 5| Step: 1
Training loss: 2.2990238666534424
Validation loss: 2.047808667664887

Epoch: 5| Step: 2
Training loss: 2.177037477493286
Validation loss: 2.0688109808070685

Epoch: 5| Step: 3
Training loss: 2.121703863143921
Validation loss: 2.068723855480071

Epoch: 5| Step: 4
Training loss: 1.9115931987762451
Validation loss: 2.109880419187648

Epoch: 5| Step: 5
Training loss: 1.654828667640686
Validation loss: 2.100742447760797

Epoch: 5| Step: 6
Training loss: 1.9355504512786865
Validation loss: 2.0647937892585673

Epoch: 5| Step: 7
Training loss: 1.6803805828094482
Validation loss: 2.079360459440498

Epoch: 5| Step: 8
Training loss: 2.0077338218688965
Validation loss: 2.061472023687055

Epoch: 5| Step: 9
Training loss: 1.5644906759262085
Validation loss: 2.056724376575921

Epoch: 5| Step: 10
Training loss: 1.4138298034667969
Validation loss: 2.0793310134641585

Epoch: 270| Step: 0
Training loss: 1.6466137170791626
Validation loss: 2.0656757713646017

Epoch: 5| Step: 1
Training loss: 2.0177876949310303
Validation loss: 2.0465569444881972

Epoch: 5| Step: 2
Training loss: 2.059908628463745
Validation loss: 2.077901699209726

Epoch: 5| Step: 3
Training loss: 2.2250285148620605
Validation loss: 2.0735261824823197

Epoch: 5| Step: 4
Training loss: 1.679796576499939
Validation loss: 2.0825679981580345

Epoch: 5| Step: 5
Training loss: 1.740221619606018
Validation loss: 2.088401814942719

Epoch: 5| Step: 6
Training loss: 2.040224552154541
Validation loss: 2.1251870765480945

Epoch: 5| Step: 7
Training loss: 1.8178246021270752
Validation loss: 2.0491054237529798

Epoch: 5| Step: 8
Training loss: 1.8983262777328491
Validation loss: 2.06474837692835

Epoch: 5| Step: 9
Training loss: 2.2718207836151123
Validation loss: 2.0811618015330327

Epoch: 5| Step: 10
Training loss: 1.784648060798645
Validation loss: 2.0761525425859677

Epoch: 271| Step: 0
Training loss: 1.897037148475647
Validation loss: 2.091773958616359

Epoch: 5| Step: 1
Training loss: 2.0288872718811035
Validation loss: 2.087733571247388

Epoch: 5| Step: 2
Training loss: 1.519307255744934
Validation loss: 2.0481717509608113

Epoch: 5| Step: 3
Training loss: 1.8646987676620483
Validation loss: 2.044958370988087

Epoch: 5| Step: 4
Training loss: 2.1344590187072754
Validation loss: 2.08146841808032

Epoch: 5| Step: 5
Training loss: 1.766400694847107
Validation loss: 2.0661151947513705

Epoch: 5| Step: 6
Training loss: 1.8953406810760498
Validation loss: 2.032940562053393

Epoch: 5| Step: 7
Training loss: 2.4630119800567627
Validation loss: 2.02529126597989

Epoch: 5| Step: 8
Training loss: 2.0490903854370117
Validation loss: 2.077591320519806

Epoch: 5| Step: 9
Training loss: 1.5868074893951416
Validation loss: 2.075874267085906

Epoch: 5| Step: 10
Training loss: 1.9203540086746216
Validation loss: 2.0613200792702298

Epoch: 272| Step: 0
Training loss: 1.7910600900650024
Validation loss: 2.048116071249849

Epoch: 5| Step: 1
Training loss: 1.588599443435669
Validation loss: 2.0626492769487443

Epoch: 5| Step: 2
Training loss: 2.1698126792907715
Validation loss: 2.020002572767196

Epoch: 5| Step: 3
Training loss: 2.250127077102661
Validation loss: 2.071819669456892

Epoch: 5| Step: 4
Training loss: 2.1971492767333984
Validation loss: 2.0749283247096564

Epoch: 5| Step: 5
Training loss: 1.8155171871185303
Validation loss: 2.0185555411923315

Epoch: 5| Step: 6
Training loss: 1.545095443725586
Validation loss: 2.0799433339026665

Epoch: 5| Step: 7
Training loss: 2.377838611602783
Validation loss: 2.0952772478903494

Epoch: 5| Step: 8
Training loss: 1.748387098312378
Validation loss: 2.068768116735643

Epoch: 5| Step: 9
Training loss: 1.9285857677459717
Validation loss: 2.1003438375329457

Epoch: 5| Step: 10
Training loss: 2.0016262531280518
Validation loss: 2.1484921465637865

Epoch: 273| Step: 0
Training loss: 1.9205925464630127
Validation loss: 2.0560600232052546

Epoch: 5| Step: 1
Training loss: 2.0136313438415527
Validation loss: 2.068316326346449

Epoch: 5| Step: 2
Training loss: 1.8717613220214844
Validation loss: 2.075237686916064

Epoch: 5| Step: 3
Training loss: 1.8758056163787842
Validation loss: 2.1091690037840154

Epoch: 5| Step: 4
Training loss: 2.047833204269409
Validation loss: 2.104670547669934

Epoch: 5| Step: 5
Training loss: 1.7963825464248657
Validation loss: 2.0476438178811023

Epoch: 5| Step: 6
Training loss: 1.7338266372680664
Validation loss: 2.081258463603194

Epoch: 5| Step: 7
Training loss: 2.3598453998565674
Validation loss: 2.066467114674148

Epoch: 5| Step: 8
Training loss: 1.9730228185653687
Validation loss: 2.102979798470774

Epoch: 5| Step: 9
Training loss: 2.1245405673980713
Validation loss: 2.0771518163783576

Epoch: 5| Step: 10
Training loss: 1.367732048034668
Validation loss: 2.068594972292582

Epoch: 274| Step: 0
Training loss: 2.004800796508789
Validation loss: 2.1041409559147333

Epoch: 5| Step: 1
Training loss: 1.697967290878296
Validation loss: 2.0831088430138043

Epoch: 5| Step: 2
Training loss: 2.004512310028076
Validation loss: 2.096233937048143

Epoch: 5| Step: 3
Training loss: 2.0563716888427734
Validation loss: 2.07953320651926

Epoch: 5| Step: 4
Training loss: 1.5198419094085693
Validation loss: 2.0677351490143807

Epoch: 5| Step: 5
Training loss: 1.8492786884307861
Validation loss: 2.0737685157406713

Epoch: 5| Step: 6
Training loss: 1.6889864206314087
Validation loss: 2.059179870031213

Epoch: 5| Step: 7
Training loss: 1.9276189804077148
Validation loss: 2.0660724229710077

Epoch: 5| Step: 8
Training loss: 1.4628269672393799
Validation loss: 2.068712131951445

Epoch: 5| Step: 9
Training loss: 2.112687587738037
Validation loss: 2.043356043036266

Epoch: 5| Step: 10
Training loss: 3.021575689315796
Validation loss: 2.0879477454769995

Epoch: 275| Step: 0
Training loss: 2.457568645477295
Validation loss: 2.0571342540043656

Epoch: 5| Step: 1
Training loss: 1.818647027015686
Validation loss: 2.0074882404778593

Epoch: 5| Step: 2
Training loss: 2.0919649600982666
Validation loss: 2.093074690911078

Epoch: 5| Step: 3
Training loss: 1.8492991924285889
Validation loss: 2.045226667516975

Epoch: 5| Step: 4
Training loss: 1.9181921482086182
Validation loss: 2.07840036576794

Epoch: 5| Step: 5
Training loss: 1.6578782796859741
Validation loss: 2.050954923834852

Epoch: 5| Step: 6
Training loss: 1.4822511672973633
Validation loss: 2.065077212549025

Epoch: 5| Step: 7
Training loss: 1.9948673248291016
Validation loss: 2.070648806069487

Epoch: 5| Step: 8
Training loss: 1.9178699254989624
Validation loss: 2.027744403449438

Epoch: 5| Step: 9
Training loss: 2.222904682159424
Validation loss: 2.0476393725282405

Epoch: 5| Step: 10
Training loss: 1.8112058639526367
Validation loss: 2.0512420041586763

Epoch: 276| Step: 0
Training loss: 2.3662075996398926
Validation loss: 2.0883337836111746

Epoch: 5| Step: 1
Training loss: 1.4648243188858032
Validation loss: 2.0514264978388304

Epoch: 5| Step: 2
Training loss: 1.5554853677749634
Validation loss: 2.0719068896385933

Epoch: 5| Step: 3
Training loss: 1.3330339193344116
Validation loss: 2.043859028047131

Epoch: 5| Step: 4
Training loss: 2.2831616401672363
Validation loss: 2.046467291411533

Epoch: 5| Step: 5
Training loss: 2.292215347290039
Validation loss: 2.092404753931107

Epoch: 5| Step: 6
Training loss: 2.258554220199585
Validation loss: 2.0898277375005905

Epoch: 5| Step: 7
Training loss: 2.143660068511963
Validation loss: 2.0196527563115603

Epoch: 5| Step: 8
Training loss: 2.1094236373901367
Validation loss: 2.0467740028135237

Epoch: 5| Step: 9
Training loss: 1.2178928852081299
Validation loss: 2.087632249760371

Epoch: 5| Step: 10
Training loss: 2.579082489013672
Validation loss: 2.087434543076382

Epoch: 277| Step: 0
Training loss: 2.0141043663024902
Validation loss: 2.055870945735644

Epoch: 5| Step: 1
Training loss: 1.4643760919570923
Validation loss: 2.070146676032774

Epoch: 5| Step: 2
Training loss: 1.4564772844314575
Validation loss: 2.085432328203673

Epoch: 5| Step: 3
Training loss: 3.1672747135162354
Validation loss: 2.1212494424594346

Epoch: 5| Step: 4
Training loss: 1.3330527544021606
Validation loss: 2.055987613175505

Epoch: 5| Step: 5
Training loss: 2.748812198638916
Validation loss: 2.095967656822615

Epoch: 5| Step: 6
Training loss: 1.9135392904281616
Validation loss: 2.0697056747251943

Epoch: 5| Step: 7
Training loss: 1.9901607036590576
Validation loss: 2.059412253800259

Epoch: 5| Step: 8
Training loss: 2.2778983116149902
Validation loss: 2.0626311520094514

Epoch: 5| Step: 9
Training loss: 1.4946686029434204
Validation loss: 2.105025822116483

Epoch: 5| Step: 10
Training loss: 1.4552973508834839
Validation loss: 2.0783713453559467

Epoch: 278| Step: 0
Training loss: 2.544583559036255
Validation loss: 2.079104620923278

Epoch: 5| Step: 1
Training loss: 1.6528527736663818
Validation loss: 2.0362212196473153

Epoch: 5| Step: 2
Training loss: 2.3697638511657715
Validation loss: 2.0466554126431866

Epoch: 5| Step: 3
Training loss: 1.858402967453003
Validation loss: 2.089199322526173

Epoch: 5| Step: 4
Training loss: 1.7105385065078735
Validation loss: 2.0511506783064974

Epoch: 5| Step: 5
Training loss: 1.7760238647460938
Validation loss: 2.0912561980626916

Epoch: 5| Step: 6
Training loss: 1.5996853113174438
Validation loss: 2.0443468991146294

Epoch: 5| Step: 7
Training loss: 2.1841931343078613
Validation loss: 2.063978067008398

Epoch: 5| Step: 8
Training loss: 2.1890175342559814
Validation loss: 2.070967935746716

Epoch: 5| Step: 9
Training loss: 1.5322191715240479
Validation loss: 2.041498073967554

Epoch: 5| Step: 10
Training loss: 1.6450730562210083
Validation loss: 2.0926434788652646

Epoch: 279| Step: 0
Training loss: 1.635436773300171
Validation loss: 2.077682679699313

Epoch: 5| Step: 1
Training loss: 1.5617244243621826
Validation loss: 2.0170275844553465

Epoch: 5| Step: 2
Training loss: 2.366166591644287
Validation loss: 2.0632943043144802

Epoch: 5| Step: 3
Training loss: 2.4851651191711426
Validation loss: 2.096166060816857

Epoch: 5| Step: 4
Training loss: 1.8744739294052124
Validation loss: 2.0880345016397457

Epoch: 5| Step: 5
Training loss: 1.9513518810272217
Validation loss: 2.0669486420128935

Epoch: 5| Step: 6
Training loss: 2.147387981414795
Validation loss: 2.055290011949437

Epoch: 5| Step: 7
Training loss: 1.6303246021270752
Validation loss: 2.069806214301817

Epoch: 5| Step: 8
Training loss: 1.8634002208709717
Validation loss: 2.0822164140721804

Epoch: 5| Step: 9
Training loss: 1.519015908241272
Validation loss: 2.0824862205854027

Epoch: 5| Step: 10
Training loss: 2.0807156562805176
Validation loss: 2.0598065160935923

Epoch: 280| Step: 0
Training loss: 2.1321792602539062
Validation loss: 2.0897482659227107

Epoch: 5| Step: 1
Training loss: 1.2764941453933716
Validation loss: 2.0791168187254216

Epoch: 5| Step: 2
Training loss: 2.1057372093200684
Validation loss: 2.0933017141075543

Epoch: 5| Step: 3
Training loss: 2.2262802124023438
Validation loss: 2.0302463923731158

Epoch: 5| Step: 4
Training loss: 1.5236095190048218
Validation loss: 2.06910046967127

Epoch: 5| Step: 5
Training loss: 2.3404338359832764
Validation loss: 2.118306995719992

Epoch: 5| Step: 6
Training loss: 2.0106303691864014
Validation loss: 2.0962082955145065

Epoch: 5| Step: 7
Training loss: 1.9546079635620117
Validation loss: 2.0752289525924192

Epoch: 5| Step: 8
Training loss: 2.1558194160461426
Validation loss: 2.107005206487512

Epoch: 5| Step: 9
Training loss: 1.5977661609649658
Validation loss: 2.0421367896500455

Epoch: 5| Step: 10
Training loss: 1.937878131866455
Validation loss: 2.065207194256526

Epoch: 281| Step: 0
Training loss: 1.8020038604736328
Validation loss: 2.1048052272488995

Epoch: 5| Step: 1
Training loss: 2.091689109802246
Validation loss: 2.091205035486529

Epoch: 5| Step: 2
Training loss: 2.049863338470459
Validation loss: 2.067169940599831

Epoch: 5| Step: 3
Training loss: 1.5963151454925537
Validation loss: 2.09810866848115

Epoch: 5| Step: 4
Training loss: 2.0213818550109863
Validation loss: 2.1277261677608696

Epoch: 5| Step: 5
Training loss: 2.0087203979492188
Validation loss: 2.103788924473588

Epoch: 5| Step: 6
Training loss: 1.8575958013534546
Validation loss: 2.0839828598883843

Epoch: 5| Step: 7
Training loss: 1.9195457696914673
Validation loss: 2.0909927506600656

Epoch: 5| Step: 8
Training loss: 1.9125518798828125
Validation loss: 2.122165587640578

Epoch: 5| Step: 9
Training loss: 2.176060676574707
Validation loss: 2.094580537529402

Epoch: 5| Step: 10
Training loss: 1.6753038167953491
Validation loss: 2.135700994922269

Epoch: 282| Step: 0
Training loss: 2.2221426963806152
Validation loss: 2.094299900916315

Epoch: 5| Step: 1
Training loss: 1.6616052389144897
Validation loss: 2.0996245902071715

Epoch: 5| Step: 2
Training loss: 1.9286807775497437
Validation loss: 2.0683597275005874

Epoch: 5| Step: 3
Training loss: 1.8928951025009155
Validation loss: 2.107610792242071

Epoch: 5| Step: 4
Training loss: 2.781125545501709
Validation loss: 2.097623812255039

Epoch: 5| Step: 5
Training loss: 1.7044109106063843
Validation loss: 2.0262216406483806

Epoch: 5| Step: 6
Training loss: 1.8807775974273682
Validation loss: 2.0716962570785196

Epoch: 5| Step: 7
Training loss: 1.5709549188613892
Validation loss: 2.0992244110312512

Epoch: 5| Step: 8
Training loss: 2.124403476715088
Validation loss: 2.124987881670716

Epoch: 5| Step: 9
Training loss: 1.8206487894058228
Validation loss: 2.10013847966348

Epoch: 5| Step: 10
Training loss: 1.5440855026245117
Validation loss: 2.0939250351280294

Epoch: 283| Step: 0
Training loss: 1.776322603225708
Validation loss: 2.1140219139796432

Epoch: 5| Step: 1
Training loss: 1.585435152053833
Validation loss: 2.0601923132455475

Epoch: 5| Step: 2
Training loss: 1.8571380376815796
Validation loss: 2.0482969668603714

Epoch: 5| Step: 3
Training loss: 2.060450553894043
Validation loss: 2.082119531528924

Epoch: 5| Step: 4
Training loss: 1.5148231983184814
Validation loss: 2.142317415565573

Epoch: 5| Step: 5
Training loss: 1.6844799518585205
Validation loss: 2.091776365874916

Epoch: 5| Step: 6
Training loss: 1.4978830814361572
Validation loss: 2.0492386510295253

Epoch: 5| Step: 7
Training loss: 2.20806884765625
Validation loss: 2.0884988166952647

Epoch: 5| Step: 8
Training loss: 2.2086734771728516
Validation loss: 2.0791217998791764

Epoch: 5| Step: 9
Training loss: 2.0034468173980713
Validation loss: 2.0929878424572688

Epoch: 5| Step: 10
Training loss: 2.879617691040039
Validation loss: 2.0813948531304636

Epoch: 284| Step: 0
Training loss: 1.9349066019058228
Validation loss: 2.0699102596570085

Epoch: 5| Step: 1
Training loss: 1.4769971370697021
Validation loss: 2.0742043167032223

Epoch: 5| Step: 2
Training loss: 1.9875097274780273
Validation loss: 2.0705678334800144

Epoch: 5| Step: 3
Training loss: 1.6056129932403564
Validation loss: 2.091122736213028

Epoch: 5| Step: 4
Training loss: 2.580064296722412
Validation loss: 2.1273340230347006

Epoch: 5| Step: 5
Training loss: 1.980944275856018
Validation loss: 2.049649264222832

Epoch: 5| Step: 6
Training loss: 1.5436232089996338
Validation loss: 2.045191898140856

Epoch: 5| Step: 7
Training loss: 2.4810283184051514
Validation loss: 2.044026949072397

Epoch: 5| Step: 8
Training loss: 1.7495158910751343
Validation loss: 2.0616083196414414

Epoch: 5| Step: 9
Training loss: 2.1117284297943115
Validation loss: 2.0879455945825063

Epoch: 5| Step: 10
Training loss: 1.5574519634246826
Validation loss: 2.0548483671680575

Epoch: 285| Step: 0
Training loss: 1.503394603729248
Validation loss: 2.056526335336829

Epoch: 5| Step: 1
Training loss: 2.3393406867980957
Validation loss: 2.047648581125403

Epoch: 5| Step: 2
Training loss: 1.7852649688720703
Validation loss: 2.100331978131366

Epoch: 5| Step: 3
Training loss: 2.3871545791625977
Validation loss: 2.0758543757982153

Epoch: 5| Step: 4
Training loss: 2.222520351409912
Validation loss: 2.120103105421989

Epoch: 5| Step: 5
Training loss: 2.0701849460601807
Validation loss: 2.0820069056685253

Epoch: 5| Step: 6
Training loss: 1.93939208984375
Validation loss: 2.0925124486287436

Epoch: 5| Step: 7
Training loss: 1.876434326171875
Validation loss: 2.1366383362841863

Epoch: 5| Step: 8
Training loss: 1.7744224071502686
Validation loss: 2.092926266372845

Epoch: 5| Step: 9
Training loss: 1.6118062734603882
Validation loss: 2.1190925695562877

Epoch: 5| Step: 10
Training loss: 1.7804715633392334
Validation loss: 2.076982299486796

Epoch: 286| Step: 0
Training loss: 1.240185022354126
Validation loss: 2.1019036898048977

Epoch: 5| Step: 1
Training loss: 1.6229305267333984
Validation loss: 2.149183973189323

Epoch: 5| Step: 2
Training loss: 2.6303048133850098
Validation loss: 2.053960059278755

Epoch: 5| Step: 3
Training loss: 2.291532278060913
Validation loss: 2.0708211442475677

Epoch: 5| Step: 4
Training loss: 1.6721616983413696
Validation loss: 2.0591498895358016

Epoch: 5| Step: 5
Training loss: 2.0620646476745605
Validation loss: 2.036780103560417

Epoch: 5| Step: 6
Training loss: 1.9575278759002686
Validation loss: 2.0707749423160347

Epoch: 5| Step: 7
Training loss: 1.923998475074768
Validation loss: 2.0809741327839513

Epoch: 5| Step: 8
Training loss: 1.468575358390808
Validation loss: 2.0519430150267897

Epoch: 5| Step: 9
Training loss: 1.9243967533111572
Validation loss: 2.0505604897775958

Epoch: 5| Step: 10
Training loss: 2.3013455867767334
Validation loss: 2.0512140322757024

Epoch: 287| Step: 0
Training loss: 1.7615768909454346
Validation loss: 2.0828545119172786

Epoch: 5| Step: 1
Training loss: 2.166412353515625
Validation loss: 2.0907407858038463

Epoch: 5| Step: 2
Training loss: 2.0410101413726807
Validation loss: 2.0891115947436263

Epoch: 5| Step: 3
Training loss: 2.0281925201416016
Validation loss: 2.095635458987246

Epoch: 5| Step: 4
Training loss: 1.9452645778656006
Validation loss: 2.0676787925022904

Epoch: 5| Step: 5
Training loss: 1.408115029335022
Validation loss: 2.0324133698658278

Epoch: 5| Step: 6
Training loss: 1.5423263311386108
Validation loss: 2.0832516865063737

Epoch: 5| Step: 7
Training loss: 2.2785823345184326
Validation loss: 2.1050684041874383

Epoch: 5| Step: 8
Training loss: 1.8216606378555298
Validation loss: 2.071327801673643

Epoch: 5| Step: 9
Training loss: 2.221491575241089
Validation loss: 2.1002982842024935

Epoch: 5| Step: 10
Training loss: 1.5585240125656128
Validation loss: 2.104001058045254

Epoch: 288| Step: 0
Training loss: 1.5039516687393188
Validation loss: 2.0890801747639975

Epoch: 5| Step: 1
Training loss: 1.3131917715072632
Validation loss: 2.1144332449923278

Epoch: 5| Step: 2
Training loss: 2.085402727127075
Validation loss: 2.1187642274364347

Epoch: 5| Step: 3
Training loss: 1.8770244121551514
Validation loss: 2.14340893683895

Epoch: 5| Step: 4
Training loss: 2.019263744354248
Validation loss: 2.0939230713793027

Epoch: 5| Step: 5
Training loss: 2.39750337600708
Validation loss: 2.098671490146268

Epoch: 5| Step: 6
Training loss: 1.5329644680023193
Validation loss: 2.1583797136942544

Epoch: 5| Step: 7
Training loss: 2.0185725688934326
Validation loss: 2.135023650302682

Epoch: 5| Step: 8
Training loss: 1.9917314052581787
Validation loss: 2.10720883646319

Epoch: 5| Step: 9
Training loss: 2.0219273567199707
Validation loss: 2.133668509862756

Epoch: 5| Step: 10
Training loss: 2.443772554397583
Validation loss: 2.1175234215233916

Epoch: 289| Step: 0
Training loss: 2.214337110519409
Validation loss: 2.0784369591743714

Epoch: 5| Step: 1
Training loss: 1.918530821800232
Validation loss: 2.0739348447451027

Epoch: 5| Step: 2
Training loss: 1.9871032238006592
Validation loss: 2.1036882759422384

Epoch: 5| Step: 3
Training loss: 1.5183080434799194
Validation loss: 2.064636253541516

Epoch: 5| Step: 4
Training loss: 2.5653207302093506
Validation loss: 2.1116111227261123

Epoch: 5| Step: 5
Training loss: 1.6073585748672485
Validation loss: 2.0904347563302643

Epoch: 5| Step: 6
Training loss: 1.583003282546997
Validation loss: 2.077580553229137

Epoch: 5| Step: 7
Training loss: 1.585646390914917
Validation loss: 2.074377388082525

Epoch: 5| Step: 8
Training loss: 1.9295079708099365
Validation loss: 2.0829814634015484

Epoch: 5| Step: 9
Training loss: 2.195709705352783
Validation loss: 2.0583904225339174

Epoch: 5| Step: 10
Training loss: 1.9247761964797974
Validation loss: 2.095015961636779

Epoch: 290| Step: 0
Training loss: 2.141921043395996
Validation loss: 2.08779154798036

Epoch: 5| Step: 1
Training loss: 1.8008582592010498
Validation loss: 2.06296859505356

Epoch: 5| Step: 2
Training loss: 2.0003445148468018
Validation loss: 2.061974988188795

Epoch: 5| Step: 3
Training loss: 1.859083890914917
Validation loss: 2.0525900112685336

Epoch: 5| Step: 4
Training loss: 2.268118381500244
Validation loss: 2.0653664809401318

Epoch: 5| Step: 5
Training loss: 2.2365756034851074
Validation loss: 2.0337932750742924

Epoch: 5| Step: 6
Training loss: 1.839208960533142
Validation loss: 2.085494743880405

Epoch: 5| Step: 7
Training loss: 1.7085330486297607
Validation loss: 2.09883383012587

Epoch: 5| Step: 8
Training loss: 2.249753475189209
Validation loss: 2.0664038529960056

Epoch: 5| Step: 9
Training loss: 1.7693274021148682
Validation loss: 2.082965084301528

Epoch: 5| Step: 10
Training loss: 1.274733066558838
Validation loss: 2.0487535486939135

Epoch: 291| Step: 0
Training loss: 2.120063066482544
Validation loss: 2.057314345913549

Epoch: 5| Step: 1
Training loss: 1.9985225200653076
Validation loss: 2.0519428355719453

Epoch: 5| Step: 2
Training loss: 1.8114593029022217
Validation loss: 2.060603867294968

Epoch: 5| Step: 3
Training loss: 1.8992319107055664
Validation loss: 2.08814957193149

Epoch: 5| Step: 4
Training loss: 2.428812026977539
Validation loss: 2.035630569663099

Epoch: 5| Step: 5
Training loss: 1.8074041604995728
Validation loss: 2.0822155552525676

Epoch: 5| Step: 6
Training loss: 1.9754343032836914
Validation loss: 2.0778263948296987

Epoch: 5| Step: 7
Training loss: 1.811201810836792
Validation loss: 2.0586650499733548

Epoch: 5| Step: 8
Training loss: 1.5850584506988525
Validation loss: 2.0844590279363815

Epoch: 5| Step: 9
Training loss: 1.9581432342529297
Validation loss: 2.143055107003899

Epoch: 5| Step: 10
Training loss: 1.6276410818099976
Validation loss: 2.1001158504075903

Epoch: 292| Step: 0
Training loss: 2.096450090408325
Validation loss: 2.0776262244870587

Epoch: 5| Step: 1
Training loss: 1.591263771057129
Validation loss: 2.02845101587234

Epoch: 5| Step: 2
Training loss: 1.757267951965332
Validation loss: 2.0580208429726223

Epoch: 5| Step: 3
Training loss: 2.305464267730713
Validation loss: 2.10001120772413

Epoch: 5| Step: 4
Training loss: 1.6498241424560547
Validation loss: 2.1164192743198846

Epoch: 5| Step: 5
Training loss: 1.742110013961792
Validation loss: 2.0456003476214666

Epoch: 5| Step: 6
Training loss: 2.309032678604126
Validation loss: 2.082237979417206

Epoch: 5| Step: 7
Training loss: 1.729383111000061
Validation loss: 2.07911039680563

Epoch: 5| Step: 8
Training loss: 1.7451778650283813
Validation loss: 2.0517624693532146

Epoch: 5| Step: 9
Training loss: 2.145841121673584
Validation loss: 2.067929901102538

Epoch: 5| Step: 10
Training loss: 1.5265655517578125
Validation loss: 2.0934322790433

Epoch: 293| Step: 0
Training loss: 1.6317344903945923
Validation loss: 2.0994634859023558

Epoch: 5| Step: 1
Training loss: 1.4033501148223877
Validation loss: 2.1009298191275647

Epoch: 5| Step: 2
Training loss: 2.468496322631836
Validation loss: 2.0852416561495875

Epoch: 5| Step: 3
Training loss: 2.409945487976074
Validation loss: 2.0864058873986684

Epoch: 5| Step: 4
Training loss: 1.3604971170425415
Validation loss: 2.1372378577468214

Epoch: 5| Step: 5
Training loss: 2.07130765914917
Validation loss: 2.108214503975325

Epoch: 5| Step: 6
Training loss: 1.8534390926361084
Validation loss: 2.1349150570490028

Epoch: 5| Step: 7
Training loss: 1.8872970342636108
Validation loss: 2.0871829294389292

Epoch: 5| Step: 8
Training loss: 1.3864474296569824
Validation loss: 2.0826643308003745

Epoch: 5| Step: 9
Training loss: 2.2500176429748535
Validation loss: 2.0764911302956204

Epoch: 5| Step: 10
Training loss: 2.1612582206726074
Validation loss: 2.09000168308135

Epoch: 294| Step: 0
Training loss: 1.7205150127410889
Validation loss: 2.0966054598490396

Epoch: 5| Step: 1
Training loss: 1.8611860275268555
Validation loss: 2.116362969080607

Epoch: 5| Step: 2
Training loss: 2.1407358646392822
Validation loss: 2.1318786426257064

Epoch: 5| Step: 3
Training loss: 2.0073556900024414
Validation loss: 2.074424248869701

Epoch: 5| Step: 4
Training loss: 1.497794270515442
Validation loss: 2.0415188112566547

Epoch: 5| Step: 5
Training loss: 1.713742971420288
Validation loss: 2.1080986043458343

Epoch: 5| Step: 6
Training loss: 2.107694149017334
Validation loss: 2.067871480859736

Epoch: 5| Step: 7
Training loss: 1.8169186115264893
Validation loss: 2.059046686336558

Epoch: 5| Step: 8
Training loss: 1.671320915222168
Validation loss: 2.1110455425836707

Epoch: 5| Step: 9
Training loss: 2.0137057304382324
Validation loss: 2.1155479313224874

Epoch: 5| Step: 10
Training loss: 1.9845702648162842
Validation loss: 2.1332710891641598

Epoch: 295| Step: 0
Training loss: 2.440671682357788
Validation loss: 2.073280798491611

Epoch: 5| Step: 1
Training loss: 2.010681629180908
Validation loss: 2.0900723011262956

Epoch: 5| Step: 2
Training loss: 1.7240158319473267
Validation loss: 2.101689430975145

Epoch: 5| Step: 3
Training loss: 1.6521599292755127
Validation loss: 2.03124987950889

Epoch: 5| Step: 4
Training loss: 1.8516921997070312
Validation loss: 2.0555727994570168

Epoch: 5| Step: 5
Training loss: 1.6669337749481201
Validation loss: 2.0390985499146166

Epoch: 5| Step: 6
Training loss: 2.162921905517578
Validation loss: 2.054035209840344

Epoch: 5| Step: 7
Training loss: 1.8747574090957642
Validation loss: 2.06497125728156

Epoch: 5| Step: 8
Training loss: 1.6347805261611938
Validation loss: 2.074336508268951

Epoch: 5| Step: 9
Training loss: 1.4990308284759521
Validation loss: 2.0967787209377495

Epoch: 5| Step: 10
Training loss: 2.1676316261291504
Validation loss: 2.081756255959952

Epoch: 296| Step: 0
Training loss: 2.217689037322998
Validation loss: 2.089965292202529

Epoch: 5| Step: 1
Training loss: 1.6323875188827515
Validation loss: 2.0768454177405244

Epoch: 5| Step: 2
Training loss: 1.4188443422317505
Validation loss: 2.0911043203005226

Epoch: 5| Step: 3
Training loss: 2.218675136566162
Validation loss: 2.084998802472186

Epoch: 5| Step: 4
Training loss: 1.486213207244873
Validation loss: 2.0914530728452947

Epoch: 5| Step: 5
Training loss: 1.9515568017959595
Validation loss: 2.0390662249698432

Epoch: 5| Step: 6
Training loss: 2.0971293449401855
Validation loss: 2.0750750469905075

Epoch: 5| Step: 7
Training loss: 1.7530286312103271
Validation loss: 2.0414887448792816

Epoch: 5| Step: 8
Training loss: 2.2880635261535645
Validation loss: 2.0830186028634348

Epoch: 5| Step: 9
Training loss: 2.2659592628479004
Validation loss: 2.127329521281745

Epoch: 5| Step: 10
Training loss: 2.0107460021972656
Validation loss: 2.096305621567593

Epoch: 297| Step: 0
Training loss: 2.2660865783691406
Validation loss: 2.081586014839911

Epoch: 5| Step: 1
Training loss: 1.9029289484024048
Validation loss: 2.131718474049722

Epoch: 5| Step: 2
Training loss: 2.233720541000366
Validation loss: 2.0629834949329333

Epoch: 5| Step: 3
Training loss: 1.6881424188613892
Validation loss: 2.0680321557547456

Epoch: 5| Step: 4
Training loss: 1.5976200103759766
Validation loss: 2.050004002868488

Epoch: 5| Step: 5
Training loss: 1.8308894634246826
Validation loss: 2.062157893693575

Epoch: 5| Step: 6
Training loss: 1.9267091751098633
Validation loss: 2.064078620685044

Epoch: 5| Step: 7
Training loss: 1.8639650344848633
Validation loss: 2.116364364982933

Epoch: 5| Step: 8
Training loss: 1.6113908290863037
Validation loss: 2.085686993855302

Epoch: 5| Step: 9
Training loss: 2.731224775314331
Validation loss: 2.106422153852319

Epoch: 5| Step: 10
Training loss: 0.9066764712333679
Validation loss: 2.065222168481478

Epoch: 298| Step: 0
Training loss: 2.261003017425537
Validation loss: 2.1395152794417513

Epoch: 5| Step: 1
Training loss: 1.5326894521713257
Validation loss: 2.069865733064631

Epoch: 5| Step: 2
Training loss: 1.6277706623077393
Validation loss: 2.064428734522994

Epoch: 5| Step: 3
Training loss: 2.515651226043701
Validation loss: 2.0968764264096498

Epoch: 5| Step: 4
Training loss: 2.173199415206909
Validation loss: 2.067632431625038

Epoch: 5| Step: 5
Training loss: 1.9616730213165283
Validation loss: 2.098418956161827

Epoch: 5| Step: 6
Training loss: 1.493513822555542
Validation loss: 2.100625866202898

Epoch: 5| Step: 7
Training loss: 2.1703150272369385
Validation loss: 2.1267973197403776

Epoch: 5| Step: 8
Training loss: 1.632412314414978
Validation loss: 2.0906889823175248

Epoch: 5| Step: 9
Training loss: 1.7298381328582764
Validation loss: 2.135815724249809

Epoch: 5| Step: 10
Training loss: 1.5305813550949097
Validation loss: 2.097192368199748

Epoch: 299| Step: 0
Training loss: 2.1366212368011475
Validation loss: 2.09741461148826

Epoch: 5| Step: 1
Training loss: 1.747868299484253
Validation loss: 2.102295220539134

Epoch: 5| Step: 2
Training loss: 1.6713154315948486
Validation loss: 2.1283335788275606

Epoch: 5| Step: 3
Training loss: 2.060516357421875
Validation loss: 2.0797141341752905

Epoch: 5| Step: 4
Training loss: 1.3845362663269043
Validation loss: 2.0867541515698997

Epoch: 5| Step: 5
Training loss: 1.4257839918136597
Validation loss: 2.07550040880839

Epoch: 5| Step: 6
Training loss: 1.574856162071228
Validation loss: 2.0484209035032537

Epoch: 5| Step: 7
Training loss: 2.406080484390259
Validation loss: 2.018362775925667

Epoch: 5| Step: 8
Training loss: 1.5015347003936768
Validation loss: 2.090777116437112

Epoch: 5| Step: 9
Training loss: 2.3163859844207764
Validation loss: 2.0584590229936826

Epoch: 5| Step: 10
Training loss: 2.195254325866699
Validation loss: 2.071391431234216

Epoch: 300| Step: 0
Training loss: 2.21030855178833
Validation loss: 2.0601327855099916

Epoch: 5| Step: 1
Training loss: 1.964754343032837
Validation loss: 2.107538425794212

Epoch: 5| Step: 2
Training loss: 2.143126964569092
Validation loss: 2.0888337550624723

Epoch: 5| Step: 3
Training loss: 1.8256855010986328
Validation loss: 2.06972994342927

Epoch: 5| Step: 4
Training loss: 2.429314374923706
Validation loss: 2.08557475766828

Epoch: 5| Step: 5
Training loss: 1.7515310049057007
Validation loss: 2.0535863932742866

Epoch: 5| Step: 6
Training loss: 1.3826634883880615
Validation loss: 2.0352748363248763

Epoch: 5| Step: 7
Training loss: 1.9139835834503174
Validation loss: 2.129620446953722

Epoch: 5| Step: 8
Training loss: 2.027374505996704
Validation loss: 2.059130185393877

Epoch: 5| Step: 9
Training loss: 1.4207420349121094
Validation loss: 2.0926137303793304

Epoch: 5| Step: 10
Training loss: 1.5841988325119019
Validation loss: 2.0754545375864994

Epoch: 301| Step: 0
Training loss: 1.6898565292358398
Validation loss: 2.0529330981675016

Epoch: 5| Step: 1
Training loss: 1.5645383596420288
Validation loss: 2.114043028123917

Epoch: 5| Step: 2
Training loss: 1.9645335674285889
Validation loss: 2.083886120909004

Epoch: 5| Step: 3
Training loss: 1.9337055683135986
Validation loss: 2.0927846816278275

Epoch: 5| Step: 4
Training loss: 3.106248140335083
Validation loss: 2.0840909455412175

Epoch: 5| Step: 5
Training loss: 1.5952082872390747
Validation loss: 2.100905854214904

Epoch: 5| Step: 6
Training loss: 1.8139607906341553
Validation loss: 2.0847335361665293

Epoch: 5| Step: 7
Training loss: 1.7051912546157837
Validation loss: 2.0471821049208283

Epoch: 5| Step: 8
Training loss: 1.9632879495620728
Validation loss: 2.0384599726687194

Epoch: 5| Step: 9
Training loss: 1.3588974475860596
Validation loss: 2.0793616874243623

Epoch: 5| Step: 10
Training loss: 2.055852174758911
Validation loss: 2.0845473966290875

Epoch: 302| Step: 0
Training loss: 2.1013576984405518
Validation loss: 2.1264515974188365

Epoch: 5| Step: 1
Training loss: 1.4130929708480835
Validation loss: 2.0869825014504055

Epoch: 5| Step: 2
Training loss: 2.4617602825164795
Validation loss: 2.0384430141859156

Epoch: 5| Step: 3
Training loss: 1.390978455543518
Validation loss: 2.067657173320811

Epoch: 5| Step: 4
Training loss: 1.5547784566879272
Validation loss: 2.107661311344434

Epoch: 5| Step: 5
Training loss: 2.065171718597412
Validation loss: 2.078320445552949

Epoch: 5| Step: 6
Training loss: 1.4272518157958984
Validation loss: 2.096988906142532

Epoch: 5| Step: 7
Training loss: 2.653830051422119
Validation loss: 2.1017066842766217

Epoch: 5| Step: 8
Training loss: 2.193416118621826
Validation loss: 2.0614900486443632

Epoch: 5| Step: 9
Training loss: 1.8727824687957764
Validation loss: 2.0646216125898462

Epoch: 5| Step: 10
Training loss: 1.570199728012085
Validation loss: 2.070958052912066

Epoch: 303| Step: 0
Training loss: 1.6748062372207642
Validation loss: 2.120772107954948

Epoch: 5| Step: 1
Training loss: 1.9506957530975342
Validation loss: 2.098052497833006

Epoch: 5| Step: 2
Training loss: 1.535851240158081
Validation loss: 2.0813085161229616

Epoch: 5| Step: 3
Training loss: 1.3229706287384033
Validation loss: 2.066614995720566

Epoch: 5| Step: 4
Training loss: 1.9483531713485718
Validation loss: 2.1303926257676977

Epoch: 5| Step: 5
Training loss: 1.6560195684432983
Validation loss: 2.1039095668382544

Epoch: 5| Step: 6
Training loss: 1.4167166948318481
Validation loss: 2.075405474632017

Epoch: 5| Step: 7
Training loss: 2.4967117309570312
Validation loss: 2.091700359057355

Epoch: 5| Step: 8
Training loss: 1.942206621170044
Validation loss: 2.0500855599680254

Epoch: 5| Step: 9
Training loss: 2.145193338394165
Validation loss: 2.047975370960851

Epoch: 5| Step: 10
Training loss: 2.4086079597473145
Validation loss: 2.077655230799029

Epoch: 304| Step: 0
Training loss: 2.0172057151794434
Validation loss: 2.0971032727149224

Epoch: 5| Step: 1
Training loss: 1.736779808998108
Validation loss: 2.091810727632174

Epoch: 5| Step: 2
Training loss: 1.672273874282837
Validation loss: 2.0863384649317753

Epoch: 5| Step: 3
Training loss: 1.685733437538147
Validation loss: 2.0838700186821724

Epoch: 5| Step: 4
Training loss: 2.1791205406188965
Validation loss: 2.1008609366673294

Epoch: 5| Step: 5
Training loss: 1.6344358921051025
Validation loss: 2.056742973225091

Epoch: 5| Step: 6
Training loss: 1.4976890087127686
Validation loss: 2.0960177477969917

Epoch: 5| Step: 7
Training loss: 1.9137229919433594
Validation loss: 2.0765066992851997

Epoch: 5| Step: 8
Training loss: 1.632467269897461
Validation loss: 2.074715025963322

Epoch: 5| Step: 9
Training loss: 2.6909899711608887
Validation loss: 2.094940618802142

Epoch: 5| Step: 10
Training loss: 1.633828043937683
Validation loss: 2.1032900118058726

Epoch: 305| Step: 0
Training loss: 2.7804527282714844
Validation loss: 2.09136490924384

Epoch: 5| Step: 1
Training loss: 1.3139594793319702
Validation loss: 2.1250934754648516

Epoch: 5| Step: 2
Training loss: 2.293333053588867
Validation loss: 2.0824256686754126

Epoch: 5| Step: 3
Training loss: 1.9511409997940063
Validation loss: 2.117513395124866

Epoch: 5| Step: 4
Training loss: 1.7449290752410889
Validation loss: 2.145811015559781

Epoch: 5| Step: 5
Training loss: 1.8053648471832275
Validation loss: 2.161306047952303

Epoch: 5| Step: 6
Training loss: 1.3838108777999878
Validation loss: 2.0574231429766585

Epoch: 5| Step: 7
Training loss: 1.8819005489349365
Validation loss: 2.06710918231677

Epoch: 5| Step: 8
Training loss: 1.4254200458526611
Validation loss: 2.079329772662091

Epoch: 5| Step: 9
Training loss: 1.1581392288208008
Validation loss: 2.0669805567751647

Epoch: 5| Step: 10
Training loss: 2.3247270584106445
Validation loss: 2.108156805397362

Epoch: 306| Step: 0
Training loss: 2.4048213958740234
Validation loss: 2.075799431852115

Epoch: 5| Step: 1
Training loss: 1.910199761390686
Validation loss: 2.086502559723393

Epoch: 5| Step: 2
Training loss: 2.1264195442199707
Validation loss: 2.082647822236502

Epoch: 5| Step: 3
Training loss: 1.9897321462631226
Validation loss: 2.044598671697801

Epoch: 5| Step: 4
Training loss: 1.5328861474990845
Validation loss: 2.066595782515823

Epoch: 5| Step: 5
Training loss: 1.6974166631698608
Validation loss: 2.0714030470899356

Epoch: 5| Step: 6
Training loss: 1.1512081623077393
Validation loss: 2.0885880326712005

Epoch: 5| Step: 7
Training loss: 1.3356759548187256
Validation loss: 2.064286551167888

Epoch: 5| Step: 8
Training loss: 2.2565395832061768
Validation loss: 2.0431505185301586

Epoch: 5| Step: 9
Training loss: 2.272597551345825
Validation loss: 2.052532885664253

Epoch: 5| Step: 10
Training loss: 1.7543344497680664
Validation loss: 2.0734728690116637

Epoch: 307| Step: 0
Training loss: 1.555760145187378
Validation loss: 2.0676299923209736

Epoch: 5| Step: 1
Training loss: 1.7494022846221924
Validation loss: 2.1048075973346667

Epoch: 5| Step: 2
Training loss: 1.9580638408660889
Validation loss: 2.111131966754954

Epoch: 5| Step: 3
Training loss: 1.3902837038040161
Validation loss: 2.1042097255747807

Epoch: 5| Step: 4
Training loss: 1.5468394756317139
Validation loss: 2.0992393814107424

Epoch: 5| Step: 5
Training loss: 2.0363497734069824
Validation loss: 2.055869015314246

Epoch: 5| Step: 6
Training loss: 1.9717155694961548
Validation loss: 2.073429435812017

Epoch: 5| Step: 7
Training loss: 1.6068884134292603
Validation loss: 2.051957236823215

Epoch: 5| Step: 8
Training loss: 2.2905819416046143
Validation loss: 2.0728151541884228

Epoch: 5| Step: 9
Training loss: 2.3800036907196045
Validation loss: 2.089325322899767

Epoch: 5| Step: 10
Training loss: 2.029503345489502
Validation loss: 2.063818198378368

Epoch: 308| Step: 0
Training loss: 1.8453680276870728
Validation loss: 2.066738910572503

Epoch: 5| Step: 1
Training loss: 2.1469874382019043
Validation loss: 2.020239189106931

Epoch: 5| Step: 2
Training loss: 1.7700798511505127
Validation loss: 2.0845310021472234

Epoch: 5| Step: 3
Training loss: 1.8508579730987549
Validation loss: 2.0909874926331224

Epoch: 5| Step: 4
Training loss: 2.2689309120178223
Validation loss: 2.074951699984971

Epoch: 5| Step: 5
Training loss: 1.5967124700546265
Validation loss: 2.0856168321383897

Epoch: 5| Step: 6
Training loss: 1.3903393745422363
Validation loss: 2.084942025523032

Epoch: 5| Step: 7
Training loss: 2.203662157058716
Validation loss: 2.080667593145883

Epoch: 5| Step: 8
Training loss: 1.2837642431259155
Validation loss: 2.1257536257466962

Epoch: 5| Step: 9
Training loss: 1.9870086908340454
Validation loss: 2.1213768618081206

Epoch: 5| Step: 10
Training loss: 1.6460793018341064
Validation loss: 2.093673413799655

Epoch: 309| Step: 0
Training loss: 2.321772813796997
Validation loss: 2.0934711169171076

Epoch: 5| Step: 1
Training loss: 2.002664566040039
Validation loss: 2.1075070186327864

Epoch: 5| Step: 2
Training loss: 1.5075738430023193
Validation loss: 2.075496309547014

Epoch: 5| Step: 3
Training loss: 1.7715349197387695
Validation loss: 2.1390914968265

Epoch: 5| Step: 4
Training loss: 1.455161452293396
Validation loss: 2.1530691308359944

Epoch: 5| Step: 5
Training loss: 1.6825538873672485
Validation loss: 2.062493566543825

Epoch: 5| Step: 6
Training loss: 1.919679880142212
Validation loss: 2.0838581797897175

Epoch: 5| Step: 7
Training loss: 2.081937313079834
Validation loss: 2.1080402174303607

Epoch: 5| Step: 8
Training loss: 1.9812748432159424
Validation loss: 2.0645751286578435

Epoch: 5| Step: 9
Training loss: 2.1408088207244873
Validation loss: 2.069244574475032

Epoch: 5| Step: 10
Training loss: 1.6876516342163086
Validation loss: 2.0974374817263697

Epoch: 310| Step: 0
Training loss: 1.7227312326431274
Validation loss: 2.0588520201303626

Epoch: 5| Step: 1
Training loss: 1.7356910705566406
Validation loss: 2.075823927438387

Epoch: 5| Step: 2
Training loss: 1.4088008403778076
Validation loss: 2.0786147950797953

Epoch: 5| Step: 3
Training loss: 2.279900074005127
Validation loss: 2.0851120589881815

Epoch: 5| Step: 4
Training loss: 1.4014818668365479
Validation loss: 2.118477418858518

Epoch: 5| Step: 5
Training loss: 1.9992282390594482
Validation loss: 2.066563558834855

Epoch: 5| Step: 6
Training loss: 1.9571449756622314
Validation loss: 2.068822355680568

Epoch: 5| Step: 7
Training loss: 2.00431752204895
Validation loss: 2.128161455995293

Epoch: 5| Step: 8
Training loss: 1.6384694576263428
Validation loss: 2.017413621307701

Epoch: 5| Step: 9
Training loss: 1.7370109558105469
Validation loss: 2.089919513271701

Epoch: 5| Step: 10
Training loss: 2.3426358699798584
Validation loss: 2.067612199373143

Epoch: 311| Step: 0
Training loss: 1.8856580257415771
Validation loss: 2.1150048035447315

Epoch: 5| Step: 1
Training loss: 1.7520630359649658
Validation loss: 2.0592820221377957

Epoch: 5| Step: 2
Training loss: 1.9954169988632202
Validation loss: 2.06435219446818

Epoch: 5| Step: 3
Training loss: 1.6347697973251343
Validation loss: 2.1095457615390902

Epoch: 5| Step: 4
Training loss: 2.903106689453125
Validation loss: 2.105500453261919

Epoch: 5| Step: 5
Training loss: 1.547692060470581
Validation loss: 2.087360530771235

Epoch: 5| Step: 6
Training loss: 1.32542884349823
Validation loss: 2.0885219022791874

Epoch: 5| Step: 7
Training loss: 2.3281543254852295
Validation loss: 2.10343361157243

Epoch: 5| Step: 8
Training loss: 1.5659763813018799
Validation loss: 2.1246235050180906

Epoch: 5| Step: 9
Training loss: 1.5356374979019165
Validation loss: 2.034581054923355

Epoch: 5| Step: 10
Training loss: 1.3538026809692383
Validation loss: 2.074648759698355

Epoch: 312| Step: 0
Training loss: 2.220198392868042
Validation loss: 2.0584783336167694

Epoch: 5| Step: 1
Training loss: 2.725468873977661
Validation loss: 2.0762701162727932

Epoch: 5| Step: 2
Training loss: 2.008330821990967
Validation loss: 2.0923938879402737

Epoch: 5| Step: 3
Training loss: 1.577494740486145
Validation loss: 2.0671596988554923

Epoch: 5| Step: 4
Training loss: 1.7149215936660767
Validation loss: 2.0891985970158733

Epoch: 5| Step: 5
Training loss: 1.877098798751831
Validation loss: 2.1340268068416144

Epoch: 5| Step: 6
Training loss: 1.5411181449890137
Validation loss: 2.0841442064572404

Epoch: 5| Step: 7
Training loss: 1.5917551517486572
Validation loss: 2.0659481863821707

Epoch: 5| Step: 8
Training loss: 1.8732547760009766
Validation loss: 2.103890229296941

Epoch: 5| Step: 9
Training loss: 1.6027895212173462
Validation loss: 2.1007016935656146

Epoch: 5| Step: 10
Training loss: 1.4778715372085571
Validation loss: 2.0950774351755777

Epoch: 313| Step: 0
Training loss: 1.7983543872833252
Validation loss: 2.0746331535359865

Epoch: 5| Step: 1
Training loss: 1.7918570041656494
Validation loss: 2.0840859143964705

Epoch: 5| Step: 2
Training loss: 1.7526336908340454
Validation loss: 2.0980210868261193

Epoch: 5| Step: 3
Training loss: 1.3369643688201904
Validation loss: 2.1112411765642065

Epoch: 5| Step: 4
Training loss: 2.1373214721679688
Validation loss: 2.0958401772283737

Epoch: 5| Step: 5
Training loss: 1.8009783029556274
Validation loss: 2.1304122991459344

Epoch: 5| Step: 6
Training loss: 2.0862319469451904
Validation loss: 2.1118834582708215

Epoch: 5| Step: 7
Training loss: 1.8389809131622314
Validation loss: 2.1168816768994896

Epoch: 5| Step: 8
Training loss: 2.087245464324951
Validation loss: 2.053440709267893

Epoch: 5| Step: 9
Training loss: 1.6064701080322266
Validation loss: 2.0474783976872764

Epoch: 5| Step: 10
Training loss: 2.011627197265625
Validation loss: 2.116517751447616

Epoch: 314| Step: 0
Training loss: 1.7355865240097046
Validation loss: 2.075532426116287

Epoch: 5| Step: 1
Training loss: 1.3784162998199463
Validation loss: 2.0960091262735348

Epoch: 5| Step: 2
Training loss: 2.0253007411956787
Validation loss: 2.082004600955594

Epoch: 5| Step: 3
Training loss: 1.581484079360962
Validation loss: 2.096467112982145

Epoch: 5| Step: 4
Training loss: 1.9273351430892944
Validation loss: 2.1227127890433035

Epoch: 5| Step: 5
Training loss: 2.11687970161438
Validation loss: 2.07823210377847

Epoch: 5| Step: 6
Training loss: 1.8035094738006592
Validation loss: 2.0935194671794934

Epoch: 5| Step: 7
Training loss: 2.051223039627075
Validation loss: 2.0450474357092254

Epoch: 5| Step: 8
Training loss: 2.053359270095825
Validation loss: 2.075967486186694

Epoch: 5| Step: 9
Training loss: 1.8991539478302002
Validation loss: 2.0784836943431566

Epoch: 5| Step: 10
Training loss: 1.637005090713501
Validation loss: 2.107056179354268

Epoch: 315| Step: 0
Training loss: 1.8648868799209595
Validation loss: 2.0736859921486146

Epoch: 5| Step: 1
Training loss: 1.9422823190689087
Validation loss: 2.0894517155103784

Epoch: 5| Step: 2
Training loss: 2.1421828269958496
Validation loss: 2.092726472885378

Epoch: 5| Step: 3
Training loss: 1.739357590675354
Validation loss: 2.1114974509003344

Epoch: 5| Step: 4
Training loss: 2.600191831588745
Validation loss: 2.0634174372560237

Epoch: 5| Step: 5
Training loss: 2.188044786453247
Validation loss: 2.091462086605769

Epoch: 5| Step: 6
Training loss: 1.966705560684204
Validation loss: 2.0794233147815993

Epoch: 5| Step: 7
Training loss: 1.555008888244629
Validation loss: 2.0918943061623523

Epoch: 5| Step: 8
Training loss: 1.2461856603622437
Validation loss: 2.105361319357349

Epoch: 5| Step: 9
Training loss: 1.862980604171753
Validation loss: 2.0766978327945997

Epoch: 5| Step: 10
Training loss: 1.4106910228729248
Validation loss: 2.147204036353737

Epoch: 316| Step: 0
Training loss: 1.8349597454071045
Validation loss: 2.1149240463010726

Epoch: 5| Step: 1
Training loss: 2.278838634490967
Validation loss: 2.0616607025105465

Epoch: 5| Step: 2
Training loss: 1.3396888971328735
Validation loss: 2.1095814192166893

Epoch: 5| Step: 3
Training loss: 2.0580363273620605
Validation loss: 2.139170974813482

Epoch: 5| Step: 4
Training loss: 1.9595922231674194
Validation loss: 2.117315915323073

Epoch: 5| Step: 5
Training loss: 2.321528196334839
Validation loss: 2.1010966377873577

Epoch: 5| Step: 6
Training loss: 1.9759019613265991
Validation loss: 2.0932307832984516

Epoch: 5| Step: 7
Training loss: 1.925790786743164
Validation loss: 2.1362281102006153

Epoch: 5| Step: 8
Training loss: 1.3026964664459229
Validation loss: 2.115868224892565

Epoch: 5| Step: 9
Training loss: 1.7024357318878174
Validation loss: 2.071878671646118

Epoch: 5| Step: 10
Training loss: 1.5622001886367798
Validation loss: 2.0635745550996516

Epoch: 317| Step: 0
Training loss: 2.0217483043670654
Validation loss: 2.098080324870284

Epoch: 5| Step: 1
Training loss: 1.9532381296157837
Validation loss: 2.0808050632476807

Epoch: 5| Step: 2
Training loss: 1.7945106029510498
Validation loss: 2.145361238910306

Epoch: 5| Step: 3
Training loss: 1.5232707262039185
Validation loss: 2.132245317582161

Epoch: 5| Step: 4
Training loss: 1.9346596002578735
Validation loss: 2.0977105376540974

Epoch: 5| Step: 5
Training loss: 1.6279102563858032
Validation loss: 2.053797960281372

Epoch: 5| Step: 6
Training loss: 1.787255883216858
Validation loss: 2.1137058593893565

Epoch: 5| Step: 7
Training loss: 2.1460587978363037
Validation loss: 2.085978215740573

Epoch: 5| Step: 8
Training loss: 1.4561902284622192
Validation loss: 2.087987023015176

Epoch: 5| Step: 9
Training loss: 2.137831687927246
Validation loss: 2.154785986869566

Epoch: 5| Step: 10
Training loss: 1.5249077081680298
Validation loss: 2.1150614651300574

Epoch: 318| Step: 0
Training loss: 1.7079318761825562
Validation loss: 2.08907070467549

Epoch: 5| Step: 1
Training loss: 1.387313723564148
Validation loss: 2.068647280816109

Epoch: 5| Step: 2
Training loss: 1.382080316543579
Validation loss: 2.064709940264302

Epoch: 5| Step: 3
Training loss: 2.0375778675079346
Validation loss: 2.100821401483269

Epoch: 5| Step: 4
Training loss: 1.8284095525741577
Validation loss: 2.121023001209382

Epoch: 5| Step: 5
Training loss: 1.8549573421478271
Validation loss: 2.0890678385252595

Epoch: 5| Step: 6
Training loss: 1.9447100162506104
Validation loss: 2.0799600219213836

Epoch: 5| Step: 7
Training loss: 1.7334706783294678
Validation loss: 2.091733842767695

Epoch: 5| Step: 8
Training loss: 2.0086288452148438
Validation loss: 2.094744260593127

Epoch: 5| Step: 9
Training loss: 2.42136287689209
Validation loss: 2.071684898868684

Epoch: 5| Step: 10
Training loss: 1.5659061670303345
Validation loss: 2.137233608512468

Epoch: 319| Step: 0
Training loss: 1.4162633419036865
Validation loss: 2.100948146594468

Epoch: 5| Step: 1
Training loss: 1.6930269002914429
Validation loss: 2.0870524350033013

Epoch: 5| Step: 2
Training loss: 1.6991294622421265
Validation loss: 2.1081929053029707

Epoch: 5| Step: 3
Training loss: 1.7536468505859375
Validation loss: 2.121712839731606

Epoch: 5| Step: 4
Training loss: 1.4099701642990112
Validation loss: 2.0878668831240748

Epoch: 5| Step: 5
Training loss: 1.4581893682479858
Validation loss: 2.1226046162266887

Epoch: 5| Step: 6
Training loss: 2.634261131286621
Validation loss: 2.113428554227275

Epoch: 5| Step: 7
Training loss: 2.1727473735809326
Validation loss: 2.1072037758365756

Epoch: 5| Step: 8
Training loss: 2.3431878089904785
Validation loss: 2.092204898916265

Epoch: 5| Step: 9
Training loss: 1.5339305400848389
Validation loss: 2.116291707561862

Epoch: 5| Step: 10
Training loss: 1.9830124378204346
Validation loss: 2.0922500830824657

Epoch: 320| Step: 0
Training loss: 1.7339019775390625
Validation loss: 2.067999178363431

Epoch: 5| Step: 1
Training loss: 1.7833884954452515
Validation loss: 2.1268401325389905

Epoch: 5| Step: 2
Training loss: 1.9206510782241821
Validation loss: 2.109701500144056

Epoch: 5| Step: 3
Training loss: 1.864161491394043
Validation loss: 2.079012786188433

Epoch: 5| Step: 4
Training loss: 1.6913940906524658
Validation loss: 2.08784919400369

Epoch: 5| Step: 5
Training loss: 1.8937880992889404
Validation loss: 2.0888166401975896

Epoch: 5| Step: 6
Training loss: 1.628906011581421
Validation loss: 2.1387396089492308

Epoch: 5| Step: 7
Training loss: 1.7449491024017334
Validation loss: 2.0789465519689743

Epoch: 5| Step: 8
Training loss: 2.226768970489502
Validation loss: 2.1215559538974555

Epoch: 5| Step: 9
Training loss: 1.672645926475525
Validation loss: 2.1059299540776077

Epoch: 5| Step: 10
Training loss: 1.8593642711639404
Validation loss: 2.0957626681174

Epoch: 321| Step: 0
Training loss: 1.8638064861297607
Validation loss: 2.0871309516250447

Epoch: 5| Step: 1
Training loss: 1.6778717041015625
Validation loss: 2.0710494467007217

Epoch: 5| Step: 2
Training loss: 1.3644742965698242
Validation loss: 2.0924424663666756

Epoch: 5| Step: 3
Training loss: 2.5712673664093018
Validation loss: 2.094438504147273

Epoch: 5| Step: 4
Training loss: 1.5305335521697998
Validation loss: 2.0498492666470107

Epoch: 5| Step: 5
Training loss: 2.3021202087402344
Validation loss: 2.0825382150629514

Epoch: 5| Step: 6
Training loss: 1.1316235065460205
Validation loss: 2.103942040474184

Epoch: 5| Step: 7
Training loss: 1.9636504650115967
Validation loss: 2.110793455954521

Epoch: 5| Step: 8
Training loss: 1.6119067668914795
Validation loss: 2.098715370701205

Epoch: 5| Step: 9
Training loss: 2.371307849884033
Validation loss: 2.1098460535849295

Epoch: 5| Step: 10
Training loss: 1.7705004215240479
Validation loss: 2.0787848323904057

Epoch: 322| Step: 0
Training loss: 1.9225490093231201
Validation loss: 2.0726233707961215

Epoch: 5| Step: 1
Training loss: 1.462186574935913
Validation loss: 2.098303541060417

Epoch: 5| Step: 2
Training loss: 1.5081955194473267
Validation loss: 2.0907501302739626

Epoch: 5| Step: 3
Training loss: 1.348902940750122
Validation loss: 2.1219456375286145

Epoch: 5| Step: 4
Training loss: 2.099546432495117
Validation loss: 2.141930087920158

Epoch: 5| Step: 5
Training loss: 1.9750308990478516
Validation loss: 2.137945362316665

Epoch: 5| Step: 6
Training loss: 1.9426968097686768
Validation loss: 2.090449615191388

Epoch: 5| Step: 7
Training loss: 1.7879936695098877
Validation loss: 2.1110928571352394

Epoch: 5| Step: 8
Training loss: 1.4749138355255127
Validation loss: 2.100932791668882

Epoch: 5| Step: 9
Training loss: 2.06809663772583
Validation loss: 2.0786774812206144

Epoch: 5| Step: 10
Training loss: 2.457926034927368
Validation loss: 2.0734468403682915

Epoch: 323| Step: 0
Training loss: 1.8015005588531494
Validation loss: 2.0594306069035686

Epoch: 5| Step: 1
Training loss: 2.2486984729766846
Validation loss: 2.0948332355868433

Epoch: 5| Step: 2
Training loss: 1.5092204809188843
Validation loss: 2.068437753185149

Epoch: 5| Step: 3
Training loss: 2.069495916366577
Validation loss: 2.162061324683569

Epoch: 5| Step: 4
Training loss: 1.858337640762329
Validation loss: 2.098584141782535

Epoch: 5| Step: 5
Training loss: 2.0151615142822266
Validation loss: 2.1308428087542133

Epoch: 5| Step: 6
Training loss: 1.7477439641952515
Validation loss: 2.1290448968128493

Epoch: 5| Step: 7
Training loss: 1.8828485012054443
Validation loss: 2.1063600394033615

Epoch: 5| Step: 8
Training loss: 1.9035606384277344
Validation loss: 2.053127711819064

Epoch: 5| Step: 9
Training loss: 1.4526264667510986
Validation loss: 2.103809960426823

Epoch: 5| Step: 10
Training loss: 1.127153754234314
Validation loss: 2.0966669218514555

Epoch: 324| Step: 0
Training loss: 2.195857524871826
Validation loss: 2.1410432118241505

Epoch: 5| Step: 1
Training loss: 1.623631238937378
Validation loss: 2.069138889671654

Epoch: 5| Step: 2
Training loss: 1.9058253765106201
Validation loss: 2.103964287747619

Epoch: 5| Step: 3
Training loss: 1.371495246887207
Validation loss: 2.1374338237188195

Epoch: 5| Step: 4
Training loss: 1.8075382709503174
Validation loss: 2.075449074468305

Epoch: 5| Step: 5
Training loss: 1.6814658641815186
Validation loss: 2.107327707352177

Epoch: 5| Step: 6
Training loss: 2.2671799659729004
Validation loss: 2.101284726973503

Epoch: 5| Step: 7
Training loss: 1.7700449228286743
Validation loss: 2.0746344161289993

Epoch: 5| Step: 8
Training loss: 2.1881072521209717
Validation loss: 2.0747461434333556

Epoch: 5| Step: 9
Training loss: 1.5975420475006104
Validation loss: 2.1034090954770326

Epoch: 5| Step: 10
Training loss: 1.7568578720092773
Validation loss: 2.1051631204543577

Epoch: 325| Step: 0
Training loss: 1.754461646080017
Validation loss: 2.1176623580276326

Epoch: 5| Step: 1
Training loss: 1.4384677410125732
Validation loss: 2.1176538467407227

Epoch: 5| Step: 2
Training loss: 2.3534767627716064
Validation loss: 2.073571333321192

Epoch: 5| Step: 3
Training loss: 1.3276481628417969
Validation loss: 2.046450825147731

Epoch: 5| Step: 4
Training loss: 1.733489751815796
Validation loss: 2.1061235986730105

Epoch: 5| Step: 5
Training loss: 1.3389503955841064
Validation loss: 2.1072515467161774

Epoch: 5| Step: 6
Training loss: 2.310572862625122
Validation loss: 2.113376550776984

Epoch: 5| Step: 7
Training loss: 2.37935209274292
Validation loss: 2.135989039174972

Epoch: 5| Step: 8
Training loss: 1.788353681564331
Validation loss: 2.120224383569533

Epoch: 5| Step: 9
Training loss: 1.3875583410263062
Validation loss: 2.157012067815309

Epoch: 5| Step: 10
Training loss: 2.311846971511841
Validation loss: 2.122637471845073

Epoch: 326| Step: 0
Training loss: 1.7872718572616577
Validation loss: 2.1244337097291024

Epoch: 5| Step: 1
Training loss: 2.3169422149658203
Validation loss: 2.119891546105826

Epoch: 5| Step: 2
Training loss: 2.2167961597442627
Validation loss: 2.0807439960459226

Epoch: 5| Step: 3
Training loss: 1.8320884704589844
Validation loss: 2.126143511905465

Epoch: 5| Step: 4
Training loss: 1.906237006187439
Validation loss: 2.085351470978029

Epoch: 5| Step: 5
Training loss: 1.233686089515686
Validation loss: 2.140607190388505

Epoch: 5| Step: 6
Training loss: 1.785747766494751
Validation loss: 2.077790767915787

Epoch: 5| Step: 7
Training loss: 1.7253650426864624
Validation loss: 2.087881129275086

Epoch: 5| Step: 8
Training loss: 1.8814958333969116
Validation loss: 2.1119173854909916

Epoch: 5| Step: 9
Training loss: 2.053671360015869
Validation loss: 2.1469763658379994

Epoch: 5| Step: 10
Training loss: 0.9411473870277405
Validation loss: 2.1244554981108634

Epoch: 327| Step: 0
Training loss: 1.738030195236206
Validation loss: 2.1529703447895665

Epoch: 5| Step: 1
Training loss: 2.2934556007385254
Validation loss: 2.095566067644345

Epoch: 5| Step: 2
Training loss: 1.9094820022583008
Validation loss: 2.0378195995925577

Epoch: 5| Step: 3
Training loss: 1.9986379146575928
Validation loss: 2.1171425952706286

Epoch: 5| Step: 4
Training loss: 1.6230465173721313
Validation loss: 2.1243401932460007

Epoch: 5| Step: 5
Training loss: 1.9780439138412476
Validation loss: 2.0850154110180434

Epoch: 5| Step: 6
Training loss: 1.5102864503860474
Validation loss: 2.0762624086872226

Epoch: 5| Step: 7
Training loss: 2.157047986984253
Validation loss: 2.0837344687472106

Epoch: 5| Step: 8
Training loss: 1.555068016052246
Validation loss: 2.100592699102176

Epoch: 5| Step: 9
Training loss: 1.6360561847686768
Validation loss: 2.144049479115394

Epoch: 5| Step: 10
Training loss: 1.0333447456359863
Validation loss: 2.158683858891969

Epoch: 328| Step: 0
Training loss: 1.6919305324554443
Validation loss: 2.0710646824170182

Epoch: 5| Step: 1
Training loss: 1.8220382928848267
Validation loss: 2.0989030227866223

Epoch: 5| Step: 2
Training loss: 2.412940502166748
Validation loss: 2.1137887918820946

Epoch: 5| Step: 3
Training loss: 1.7686868906021118
Validation loss: 2.0969491107489473

Epoch: 5| Step: 4
Training loss: 1.7036701440811157
Validation loss: 2.090397242576845

Epoch: 5| Step: 5
Training loss: 1.7460798025131226
Validation loss: 2.084524239263227

Epoch: 5| Step: 6
Training loss: 1.7432785034179688
Validation loss: 2.1132480149628012

Epoch: 5| Step: 7
Training loss: 1.854609727859497
Validation loss: 2.115767441770082

Epoch: 5| Step: 8
Training loss: 1.6467405557632446
Validation loss: 2.137761559537662

Epoch: 5| Step: 9
Training loss: 1.4944877624511719
Validation loss: 2.092350311176751

Epoch: 5| Step: 10
Training loss: 1.5745295286178589
Validation loss: 2.0556775062314925

Epoch: 329| Step: 0
Training loss: 1.507637619972229
Validation loss: 2.107711204918482

Epoch: 5| Step: 1
Training loss: 1.5065747499465942
Validation loss: 2.076029928781653

Epoch: 5| Step: 2
Training loss: 2.0517826080322266
Validation loss: 2.1328997099271385

Epoch: 5| Step: 3
Training loss: 1.5416412353515625
Validation loss: 2.102097313891175

Epoch: 5| Step: 4
Training loss: 1.6373097896575928
Validation loss: 2.0733451099805933

Epoch: 5| Step: 5
Training loss: 2.2132484912872314
Validation loss: 2.0377319525646906

Epoch: 5| Step: 6
Training loss: 1.780014991760254
Validation loss: 2.156567976038943

Epoch: 5| Step: 7
Training loss: 1.9163429737091064
Validation loss: 2.1246832673267653

Epoch: 5| Step: 8
Training loss: 1.1204599142074585
Validation loss: 2.1209702261032595

Epoch: 5| Step: 9
Training loss: 2.0855040550231934
Validation loss: 2.085184984309699

Epoch: 5| Step: 10
Training loss: 2.570512294769287
Validation loss: 2.1338513871674896

Epoch: 330| Step: 0
Training loss: 1.6424229145050049
Validation loss: 2.08135155195831

Epoch: 5| Step: 1
Training loss: 2.0975887775421143
Validation loss: 2.095174812501477

Epoch: 5| Step: 2
Training loss: 1.7274935245513916
Validation loss: 2.110822487902898

Epoch: 5| Step: 3
Training loss: 1.8250480890274048
Validation loss: 2.0948881359510523

Epoch: 5| Step: 4
Training loss: 1.8480427265167236
Validation loss: 2.099669800009779

Epoch: 5| Step: 5
Training loss: 1.799380898475647
Validation loss: 2.142678322330598

Epoch: 5| Step: 6
Training loss: 1.3051903247833252
Validation loss: 2.1163875954125517

Epoch: 5| Step: 7
Training loss: 1.956982970237732
Validation loss: 2.066816000528233

Epoch: 5| Step: 8
Training loss: 2.0736796855926514
Validation loss: 2.0831209844158542

Epoch: 5| Step: 9
Training loss: 1.7371184825897217
Validation loss: 2.0620941167236655

Epoch: 5| Step: 10
Training loss: 1.725517749786377
Validation loss: 2.078496297200521

Epoch: 331| Step: 0
Training loss: 1.208438515663147
Validation loss: 2.091803635320356

Epoch: 5| Step: 1
Training loss: 2.0453662872314453
Validation loss: 2.08557677653528

Epoch: 5| Step: 2
Training loss: 2.7913806438446045
Validation loss: 2.099503478696269

Epoch: 5| Step: 3
Training loss: 1.366137146949768
Validation loss: 2.1327414986907796

Epoch: 5| Step: 4
Training loss: 1.9293997287750244
Validation loss: 2.0659113263571136

Epoch: 5| Step: 5
Training loss: 1.9804627895355225
Validation loss: 2.101003295631819

Epoch: 5| Step: 6
Training loss: 2.0884690284729004
Validation loss: 2.072347988364517

Epoch: 5| Step: 7
Training loss: 1.4335981607437134
Validation loss: 2.0955664624450026

Epoch: 5| Step: 8
Training loss: 1.2980482578277588
Validation loss: 2.1373488108317056

Epoch: 5| Step: 9
Training loss: 1.7674057483673096
Validation loss: 2.0514135642718245

Epoch: 5| Step: 10
Training loss: 1.9041839838027954
Validation loss: 2.0724371556312806

Epoch: 332| Step: 0
Training loss: 2.3260271549224854
Validation loss: 2.1337048494687645

Epoch: 5| Step: 1
Training loss: 1.6608858108520508
Validation loss: 2.0891108871788107

Epoch: 5| Step: 2
Training loss: 1.9293897151947021
Validation loss: 2.1346964784847793

Epoch: 5| Step: 3
Training loss: 1.2365617752075195
Validation loss: 2.058084487915039

Epoch: 5| Step: 4
Training loss: 1.5275781154632568
Validation loss: 2.128628125754736

Epoch: 5| Step: 5
Training loss: 2.6209278106689453
Validation loss: 2.079316754494944

Epoch: 5| Step: 6
Training loss: 1.5873271226882935
Validation loss: 2.08443324412069

Epoch: 5| Step: 7
Training loss: 1.8829071521759033
Validation loss: 2.0903198783115675

Epoch: 5| Step: 8
Training loss: 1.4127956628799438
Validation loss: 2.0616827036744807

Epoch: 5| Step: 9
Training loss: 1.7998998165130615
Validation loss: 2.0991345977270477

Epoch: 5| Step: 10
Training loss: 1.1612486839294434
Validation loss: 2.094151653269286

Epoch: 333| Step: 0
Training loss: 1.6259212493896484
Validation loss: 2.1088798712658625

Epoch: 5| Step: 1
Training loss: 2.0509698390960693
Validation loss: 2.065666987049964

Epoch: 5| Step: 2
Training loss: 1.7121222019195557
Validation loss: 2.0839707095135926

Epoch: 5| Step: 3
Training loss: 2.04659104347229
Validation loss: 2.092426594867501

Epoch: 5| Step: 4
Training loss: 1.025848627090454
Validation loss: 2.1185836663810154

Epoch: 5| Step: 5
Training loss: 1.7883775234222412
Validation loss: 2.103082767096899

Epoch: 5| Step: 6
Training loss: 2.2470390796661377
Validation loss: 2.0992119414832002

Epoch: 5| Step: 7
Training loss: 1.6197803020477295
Validation loss: 2.1247926271089943

Epoch: 5| Step: 8
Training loss: 1.5181127786636353
Validation loss: 2.140799557009051

Epoch: 5| Step: 9
Training loss: 2.192927837371826
Validation loss: 2.1550668965103807

Epoch: 5| Step: 10
Training loss: 1.6904473304748535
Validation loss: 2.107402358003842

Epoch: 334| Step: 0
Training loss: 1.438791275024414
Validation loss: 2.108868331037542

Epoch: 5| Step: 1
Training loss: 1.313428521156311
Validation loss: 2.09356826607899

Epoch: 5| Step: 2
Training loss: 1.9975875616073608
Validation loss: 2.085021344564294

Epoch: 5| Step: 3
Training loss: 1.2322176694869995
Validation loss: 2.1202731363234983

Epoch: 5| Step: 4
Training loss: 1.8929216861724854
Validation loss: 2.0821874167329524

Epoch: 5| Step: 5
Training loss: 2.024447441101074
Validation loss: 2.1314401857314573

Epoch: 5| Step: 6
Training loss: 1.817139983177185
Validation loss: 2.118211853888727

Epoch: 5| Step: 7
Training loss: 2.001905918121338
Validation loss: 2.1190366783449726

Epoch: 5| Step: 8
Training loss: 2.0297539234161377
Validation loss: 2.0860793385454404

Epoch: 5| Step: 9
Training loss: 1.9876340627670288
Validation loss: 2.164691722521218

Epoch: 5| Step: 10
Training loss: 2.576925039291382
Validation loss: 2.066026436385288

Epoch: 335| Step: 0
Training loss: 2.2291903495788574
Validation loss: 2.048239665646707

Epoch: 5| Step: 1
Training loss: 2.121180772781372
Validation loss: 2.1627437850480438

Epoch: 5| Step: 2
Training loss: 1.7413361072540283
Validation loss: 2.0744891294869046

Epoch: 5| Step: 3
Training loss: 1.5661119222640991
Validation loss: 2.0923835808230984

Epoch: 5| Step: 4
Training loss: 1.5059298276901245
Validation loss: 2.04945312007781

Epoch: 5| Step: 5
Training loss: 1.905615210533142
Validation loss: 2.0724456182090183

Epoch: 5| Step: 6
Training loss: 1.602698564529419
Validation loss: 2.1037377875338317

Epoch: 5| Step: 7
Training loss: 1.1457302570343018
Validation loss: 2.1137110392252603

Epoch: 5| Step: 8
Training loss: 2.260005474090576
Validation loss: 2.0984201674820273

Epoch: 5| Step: 9
Training loss: 1.6812305450439453
Validation loss: 2.103912244560898

Epoch: 5| Step: 10
Training loss: 1.5937654972076416
Validation loss: 2.101767506650699

Epoch: 336| Step: 0
Training loss: 1.3711724281311035
Validation loss: 2.1028961263677126

Epoch: 5| Step: 1
Training loss: 1.8682082891464233
Validation loss: 2.0901986604095786

Epoch: 5| Step: 2
Training loss: 1.7244848012924194
Validation loss: 2.0528148476795485

Epoch: 5| Step: 3
Training loss: 1.885532021522522
Validation loss: 2.1057861133288314

Epoch: 5| Step: 4
Training loss: 2.0035910606384277
Validation loss: 2.1015923587224816

Epoch: 5| Step: 5
Training loss: 2.2573275566101074
Validation loss: 2.078727706786125

Epoch: 5| Step: 6
Training loss: 1.992582082748413
Validation loss: 2.145919453713202

Epoch: 5| Step: 7
Training loss: 2.0865297317504883
Validation loss: 2.099886278952322

Epoch: 5| Step: 8
Training loss: 1.8065646886825562
Validation loss: 2.1219632702489055

Epoch: 5| Step: 9
Training loss: 1.8200771808624268
Validation loss: 2.079130777748682

Epoch: 5| Step: 10
Training loss: 1.2064013481140137
Validation loss: 2.102051927197364

Epoch: 337| Step: 0
Training loss: 1.1928834915161133
Validation loss: 2.1006273108143962

Epoch: 5| Step: 1
Training loss: 2.4693450927734375
Validation loss: 2.0646304392045542

Epoch: 5| Step: 2
Training loss: 1.492310643196106
Validation loss: 2.1218498983690814

Epoch: 5| Step: 3
Training loss: 2.0722415447235107
Validation loss: 2.0914084116617837

Epoch: 5| Step: 4
Training loss: 1.3669683933258057
Validation loss: 2.1286387776815765

Epoch: 5| Step: 5
Training loss: 2.0033040046691895
Validation loss: 2.118898818569799

Epoch: 5| Step: 6
Training loss: 1.2931411266326904
Validation loss: 2.1146118820354505

Epoch: 5| Step: 7
Training loss: 2.0281248092651367
Validation loss: 2.0623258442007084

Epoch: 5| Step: 8
Training loss: 1.4301358461380005
Validation loss: 2.0859671074856996

Epoch: 5| Step: 9
Training loss: 2.0486462116241455
Validation loss: 2.0951444000326176

Epoch: 5| Step: 10
Training loss: 2.125487804412842
Validation loss: 2.0713073950941845

Epoch: 338| Step: 0
Training loss: 2.273702383041382
Validation loss: 2.0999644443552983

Epoch: 5| Step: 1
Training loss: 1.9622833728790283
Validation loss: 2.1172595113836308

Epoch: 5| Step: 2
Training loss: 1.266742467880249
Validation loss: 2.1477862045329106

Epoch: 5| Step: 3
Training loss: 1.333009958267212
Validation loss: 2.0934769209995063

Epoch: 5| Step: 4
Training loss: 1.8761472702026367
Validation loss: 2.148069641923392

Epoch: 5| Step: 5
Training loss: 1.5323619842529297
Validation loss: 2.096792010850804

Epoch: 5| Step: 6
Training loss: 1.4667551517486572
Validation loss: 2.1047909516160206

Epoch: 5| Step: 7
Training loss: 2.4682161808013916
Validation loss: 2.0740369019969815

Epoch: 5| Step: 8
Training loss: 1.6888765096664429
Validation loss: 2.1394739791911137

Epoch: 5| Step: 9
Training loss: 2.2312145233154297
Validation loss: 2.0824450049349057

Epoch: 5| Step: 10
Training loss: 1.5409159660339355
Validation loss: 2.139433035286524

Epoch: 339| Step: 0
Training loss: 1.7846887111663818
Validation loss: 2.0565820124841507

Epoch: 5| Step: 1
Training loss: 1.6787567138671875
Validation loss: 2.0911118445857877

Epoch: 5| Step: 2
Training loss: 1.6330913305282593
Validation loss: 2.0715727280544978

Epoch: 5| Step: 3
Training loss: 1.6278880834579468
Validation loss: 2.0691297156836397

Epoch: 5| Step: 4
Training loss: 2.4929986000061035
Validation loss: 2.096863591542808

Epoch: 5| Step: 5
Training loss: 1.5778323411941528
Validation loss: 2.112668014341785

Epoch: 5| Step: 6
Training loss: 1.7974741458892822
Validation loss: 2.1321916785291446

Epoch: 5| Step: 7
Training loss: 1.4064489603042603
Validation loss: 2.0649844651581137

Epoch: 5| Step: 8
Training loss: 1.6886628866195679
Validation loss: 2.1117703401914207

Epoch: 5| Step: 9
Training loss: 1.9465324878692627
Validation loss: 2.0879309433762745

Epoch: 5| Step: 10
Training loss: 1.9918659925460815
Validation loss: 2.108061280301822

Epoch: 340| Step: 0
Training loss: 2.094736337661743
Validation loss: 2.0587785436261083

Epoch: 5| Step: 1
Training loss: 1.7523667812347412
Validation loss: 2.0982362237027896

Epoch: 5| Step: 2
Training loss: 1.7222535610198975
Validation loss: 2.1394451638703704

Epoch: 5| Step: 3
Training loss: 1.8307750225067139
Validation loss: 2.0830705345317884

Epoch: 5| Step: 4
Training loss: 1.8317286968231201
Validation loss: 2.0806609994621685

Epoch: 5| Step: 5
Training loss: 2.183814287185669
Validation loss: 2.1252994768081175

Epoch: 5| Step: 6
Training loss: 1.4936960935592651
Validation loss: 2.0840745997685257

Epoch: 5| Step: 7
Training loss: 1.07992684841156
Validation loss: 2.0996252670082995

Epoch: 5| Step: 8
Training loss: 1.3040227890014648
Validation loss: 2.090530567271735

Epoch: 5| Step: 9
Training loss: 2.0855636596679688
Validation loss: 2.112358675208143

Epoch: 5| Step: 10
Training loss: 1.7880053520202637
Validation loss: 2.128105322519938

Epoch: 341| Step: 0
Training loss: 1.8512729406356812
Validation loss: 2.145468806707731

Epoch: 5| Step: 1
Training loss: 1.303196907043457
Validation loss: 2.1317726283945064

Epoch: 5| Step: 2
Training loss: 1.9078190326690674
Validation loss: 2.1224135391173826

Epoch: 5| Step: 3
Training loss: 1.1862719058990479
Validation loss: 2.1003207468217417

Epoch: 5| Step: 4
Training loss: 2.1694226264953613
Validation loss: 2.1629236898114605

Epoch: 5| Step: 5
Training loss: 0.9937607049942017
Validation loss: 2.1374788822666293

Epoch: 5| Step: 6
Training loss: 2.4272208213806152
Validation loss: 2.100389663891126

Epoch: 5| Step: 7
Training loss: 1.9703108072280884
Validation loss: 2.136796353965677

Epoch: 5| Step: 8
Training loss: 2.1472067832946777
Validation loss: 2.1313116063353834

Epoch: 5| Step: 9
Training loss: 1.292553186416626
Validation loss: 2.1499968882529967

Epoch: 5| Step: 10
Training loss: 1.9923126697540283
Validation loss: 2.1045955150358138

Epoch: 342| Step: 0
Training loss: 2.1447229385375977
Validation loss: 2.086206325920679

Epoch: 5| Step: 1
Training loss: 1.648289442062378
Validation loss: 2.1287483066640873

Epoch: 5| Step: 2
Training loss: 1.2811825275421143
Validation loss: 2.072875666361983

Epoch: 5| Step: 3
Training loss: 1.9746692180633545
Validation loss: 2.076252793753019

Epoch: 5| Step: 4
Training loss: 1.5487390756607056
Validation loss: 2.130162740266451

Epoch: 5| Step: 5
Training loss: 1.6714725494384766
Validation loss: 2.058455022432471

Epoch: 5| Step: 6
Training loss: 1.881996512413025
Validation loss: 2.1338538149351716

Epoch: 5| Step: 7
Training loss: 1.8967052698135376
Validation loss: 2.132142052855543

Epoch: 5| Step: 8
Training loss: 2.288095474243164
Validation loss: 2.115509958677394

Epoch: 5| Step: 9
Training loss: 1.6270349025726318
Validation loss: 2.088320768007668

Epoch: 5| Step: 10
Training loss: 1.5346009731292725
Validation loss: 2.0737873354265766

Epoch: 343| Step: 0
Training loss: 1.9657312631607056
Validation loss: 2.0714178034054336

Epoch: 5| Step: 1
Training loss: 2.068897247314453
Validation loss: 2.121247304383145

Epoch: 5| Step: 2
Training loss: 1.6426379680633545
Validation loss: 2.0953145642434396

Epoch: 5| Step: 3
Training loss: 1.5895111560821533
Validation loss: 2.082273434567195

Epoch: 5| Step: 4
Training loss: 1.7278168201446533
Validation loss: 2.094700790220691

Epoch: 5| Step: 5
Training loss: 1.4611483812332153
Validation loss: 2.1471798855771302

Epoch: 5| Step: 6
Training loss: 1.962972640991211
Validation loss: 2.0927044345486547

Epoch: 5| Step: 7
Training loss: 1.5269620418548584
Validation loss: 2.0891187447373585

Epoch: 5| Step: 8
Training loss: 1.8601226806640625
Validation loss: 2.1446162013597387

Epoch: 5| Step: 9
Training loss: 1.7189280986785889
Validation loss: 2.096501960549303

Epoch: 5| Step: 10
Training loss: 1.8356356620788574
Validation loss: 2.1050645369355396

Epoch: 344| Step: 0
Training loss: 2.123173475265503
Validation loss: 2.111622841127457

Epoch: 5| Step: 1
Training loss: 1.517096996307373
Validation loss: 2.1059154823262203

Epoch: 5| Step: 2
Training loss: 1.5533807277679443
Validation loss: 2.1104810135338896

Epoch: 5| Step: 3
Training loss: 3.1210594177246094
Validation loss: 2.1189914800787486

Epoch: 5| Step: 4
Training loss: 1.8205616474151611
Validation loss: 2.0933395252432874

Epoch: 5| Step: 5
Training loss: 1.6176058053970337
Validation loss: 2.1374297013846775

Epoch: 5| Step: 6
Training loss: 1.221550464630127
Validation loss: 2.1240903805660944

Epoch: 5| Step: 7
Training loss: 1.571467638015747
Validation loss: 2.0962857571981286

Epoch: 5| Step: 8
Training loss: 1.4606398344039917
Validation loss: 2.083155475636964

Epoch: 5| Step: 9
Training loss: 1.3887978792190552
Validation loss: 2.1037235208736953

Epoch: 5| Step: 10
Training loss: 1.6881839036941528
Validation loss: 2.087675343277634

Epoch: 345| Step: 0
Training loss: 1.1697137355804443
Validation loss: 2.109743332350126

Epoch: 5| Step: 1
Training loss: 1.6781737804412842
Validation loss: 2.052400694098524

Epoch: 5| Step: 2
Training loss: 1.6765302419662476
Validation loss: 2.095904375917168

Epoch: 5| Step: 3
Training loss: 1.5659042596817017
Validation loss: 2.112661461676321

Epoch: 5| Step: 4
Training loss: 1.851243257522583
Validation loss: 2.1891414350078953

Epoch: 5| Step: 5
Training loss: 1.5478851795196533
Validation loss: 2.1303632144005067

Epoch: 5| Step: 6
Training loss: 1.7549018859863281
Validation loss: 2.073119944141757

Epoch: 5| Step: 7
Training loss: 1.3219772577285767
Validation loss: 2.0754052951771724

Epoch: 5| Step: 8
Training loss: 2.3485474586486816
Validation loss: 2.122515837351481

Epoch: 5| Step: 9
Training loss: 1.8529081344604492
Validation loss: 2.1100843055273897

Epoch: 5| Step: 10
Training loss: 2.385376214981079
Validation loss: 2.1099277798847487

Epoch: 346| Step: 0
Training loss: 2.0019514560699463
Validation loss: 2.1833966560261224

Epoch: 5| Step: 1
Training loss: 1.827632188796997
Validation loss: 2.0620206145830053

Epoch: 5| Step: 2
Training loss: 1.3661442995071411
Validation loss: 2.0887711548036143

Epoch: 5| Step: 3
Training loss: 2.0996956825256348
Validation loss: 2.0659825186575613

Epoch: 5| Step: 4
Training loss: 1.4556140899658203
Validation loss: 2.1263521409803823

Epoch: 5| Step: 5
Training loss: 1.7809593677520752
Validation loss: 2.0576934135088356

Epoch: 5| Step: 6
Training loss: 1.9660791158676147
Validation loss: 2.1125257066501084

Epoch: 5| Step: 7
Training loss: 1.7846797704696655
Validation loss: 2.1541454304930983

Epoch: 5| Step: 8
Training loss: 1.5286626815795898
Validation loss: 2.087362484265399

Epoch: 5| Step: 9
Training loss: 1.5025758743286133
Validation loss: 2.1201803197142897

Epoch: 5| Step: 10
Training loss: 1.7373614311218262
Validation loss: 2.170847749197355

Epoch: 347| Step: 0
Training loss: 1.4295305013656616
Validation loss: 2.1019584158415436

Epoch: 5| Step: 1
Training loss: 2.2172019481658936
Validation loss: 2.0979531618856613

Epoch: 5| Step: 2
Training loss: 1.762921929359436
Validation loss: 2.097069369849338

Epoch: 5| Step: 3
Training loss: 1.8218055963516235
Validation loss: 2.132177032450194

Epoch: 5| Step: 4
Training loss: 1.5607523918151855
Validation loss: 2.200794844217198

Epoch: 5| Step: 5
Training loss: 2.29110050201416
Validation loss: 2.1652819456592685

Epoch: 5| Step: 6
Training loss: 1.6444495916366577
Validation loss: 2.1382369097842964

Epoch: 5| Step: 7
Training loss: 2.045316219329834
Validation loss: 2.1136522139272382

Epoch: 5| Step: 8
Training loss: 1.3149235248565674
Validation loss: 2.1951422845163653

Epoch: 5| Step: 9
Training loss: 1.7093636989593506
Validation loss: 2.130013078771612

Epoch: 5| Step: 10
Training loss: 1.318995475769043
Validation loss: 2.176357241087062

Epoch: 348| Step: 0
Training loss: 1.5992000102996826
Validation loss: 2.1311117474750807

Epoch: 5| Step: 1
Training loss: 1.3890459537506104
Validation loss: 2.1701091976575952

Epoch: 5| Step: 2
Training loss: 1.823926568031311
Validation loss: 2.1080477468429075

Epoch: 5| Step: 3
Training loss: 1.608795166015625
Validation loss: 2.129892497934321

Epoch: 5| Step: 4
Training loss: 2.0184946060180664
Validation loss: 2.1206889357618106

Epoch: 5| Step: 5
Training loss: 1.8521080017089844
Validation loss: 2.11089886260289

Epoch: 5| Step: 6
Training loss: 1.7805187702178955
Validation loss: 2.1407103384694746

Epoch: 5| Step: 7
Training loss: 2.0251388549804688
Validation loss: 2.055631237645303

Epoch: 5| Step: 8
Training loss: 1.3496534824371338
Validation loss: 2.1136619096161215

Epoch: 5| Step: 9
Training loss: 1.6742289066314697
Validation loss: 2.0839737487095658

Epoch: 5| Step: 10
Training loss: 1.657943844795227
Validation loss: 2.0714887213963333

Epoch: 349| Step: 0
Training loss: 1.3373241424560547
Validation loss: 2.0740877453998854

Epoch: 5| Step: 1
Training loss: 1.5466890335083008
Validation loss: 2.049010674158732

Epoch: 5| Step: 2
Training loss: 1.2566391229629517
Validation loss: 2.1158241302736345

Epoch: 5| Step: 3
Training loss: 1.8839280605316162
Validation loss: 2.0792553860654115

Epoch: 5| Step: 4
Training loss: 1.669569969177246
Validation loss: 2.0839918146851244

Epoch: 5| Step: 5
Training loss: 1.9806801080703735
Validation loss: 2.0812244184555544

Epoch: 5| Step: 6
Training loss: 1.7249904870986938
Validation loss: 2.1024704030765

Epoch: 5| Step: 7
Training loss: 1.8408511877059937
Validation loss: 2.111093662118399

Epoch: 5| Step: 8
Training loss: 2.4570488929748535
Validation loss: 2.088867574609736

Epoch: 5| Step: 9
Training loss: 1.7246160507202148
Validation loss: 2.12334983195028

Epoch: 5| Step: 10
Training loss: 1.6361068487167358
Validation loss: 2.068029675432431

Epoch: 350| Step: 0
Training loss: 1.5452970266342163
Validation loss: 2.117476855554888

Epoch: 5| Step: 1
Training loss: 0.9462922811508179
Validation loss: 2.1285956675006497

Epoch: 5| Step: 2
Training loss: 2.4182181358337402
Validation loss: 2.064289628818471

Epoch: 5| Step: 3
Training loss: 1.6018174886703491
Validation loss: 2.143365240866138

Epoch: 5| Step: 4
Training loss: 2.104976177215576
Validation loss: 2.0874948027313396

Epoch: 5| Step: 5
Training loss: 1.7012813091278076
Validation loss: 2.103361224615446

Epoch: 5| Step: 6
Training loss: 1.1954559087753296
Validation loss: 2.087025301430815

Epoch: 5| Step: 7
Training loss: 1.469353199005127
Validation loss: 2.096029822544385

Epoch: 5| Step: 8
Training loss: 2.1668059825897217
Validation loss: 2.1520159475265013

Epoch: 5| Step: 9
Training loss: 2.1461548805236816
Validation loss: 2.0819613907926824

Epoch: 5| Step: 10
Training loss: 1.7319846153259277
Validation loss: 2.102129664472354

Epoch: 351| Step: 0
Training loss: 1.8334506750106812
Validation loss: 2.1232861780351207

Epoch: 5| Step: 1
Training loss: 1.7999883890151978
Validation loss: 2.135494347541563

Epoch: 5| Step: 2
Training loss: 1.7370399236679077
Validation loss: 2.0660858154296875

Epoch: 5| Step: 3
Training loss: 2.026479482650757
Validation loss: 2.15876284850541

Epoch: 5| Step: 4
Training loss: 1.5033897161483765
Validation loss: 2.1394555440513034

Epoch: 5| Step: 5
Training loss: 2.1436610221862793
Validation loss: 2.149440070634247

Epoch: 5| Step: 6
Training loss: 1.2309097051620483
Validation loss: 2.138225440056093

Epoch: 5| Step: 7
Training loss: 1.536675214767456
Validation loss: 2.157037966994829

Epoch: 5| Step: 8
Training loss: 1.7300447225570679
Validation loss: 2.183599797628259

Epoch: 5| Step: 9
Training loss: 1.768796682357788
Validation loss: 2.1876815711298296

Epoch: 5| Step: 10
Training loss: 1.642024040222168
Validation loss: 2.100538002547397

Epoch: 352| Step: 0
Training loss: 1.445878028869629
Validation loss: 2.0941260758266655

Epoch: 5| Step: 1
Training loss: 1.6704448461532593
Validation loss: 2.1739874475745746

Epoch: 5| Step: 2
Training loss: 1.622625708580017
Validation loss: 2.1294460168448825

Epoch: 5| Step: 3
Training loss: 1.788661241531372
Validation loss: 2.1541684212223178

Epoch: 5| Step: 4
Training loss: 1.9895579814910889
Validation loss: 2.121345184182608

Epoch: 5| Step: 5
Training loss: 2.060769557952881
Validation loss: 2.134153832671463

Epoch: 5| Step: 6
Training loss: 1.889120101928711
Validation loss: 2.1136350811168714

Epoch: 5| Step: 7
Training loss: 1.9698234796524048
Validation loss: 2.138231264647617

Epoch: 5| Step: 8
Training loss: 1.5578486919403076
Validation loss: 2.1252122950810257

Epoch: 5| Step: 9
Training loss: 1.0607564449310303
Validation loss: 2.0931682996852423

Epoch: 5| Step: 10
Training loss: 1.5877538919448853
Validation loss: 2.125509790194932

Epoch: 353| Step: 0
Training loss: 1.6769134998321533
Validation loss: 2.103613266380884

Epoch: 5| Step: 1
Training loss: 1.8459676504135132
Validation loss: 2.0636237052179154

Epoch: 5| Step: 2
Training loss: 1.595578908920288
Validation loss: 2.1345933278401694

Epoch: 5| Step: 3
Training loss: 1.669323205947876
Validation loss: 2.095294926756172

Epoch: 5| Step: 4
Training loss: 1.1686242818832397
Validation loss: 2.1435910040332424

Epoch: 5| Step: 5
Training loss: 1.5194803476333618
Validation loss: 2.050943846343666

Epoch: 5| Step: 6
Training loss: 1.7596619129180908
Validation loss: 2.091754473665709

Epoch: 5| Step: 7
Training loss: 2.042001724243164
Validation loss: 2.1631080706914267

Epoch: 5| Step: 8
Training loss: 2.3075268268585205
Validation loss: 2.0987379666297667

Epoch: 5| Step: 9
Training loss: 1.8119760751724243
Validation loss: 2.106348072328875

Epoch: 5| Step: 10
Training loss: 1.6842631101608276
Validation loss: 2.062451167773175

Epoch: 354| Step: 0
Training loss: 2.1520886421203613
Validation loss: 2.1285365076475244

Epoch: 5| Step: 1
Training loss: 1.6214348077774048
Validation loss: 2.0614839702524166

Epoch: 5| Step: 2
Training loss: 1.449034333229065
Validation loss: 2.0727119702164845

Epoch: 5| Step: 3
Training loss: 1.5531530380249023
Validation loss: 2.125930029858825

Epoch: 5| Step: 4
Training loss: 2.214383363723755
Validation loss: 2.0783996979395547

Epoch: 5| Step: 5
Training loss: 2.029111385345459
Validation loss: 2.0743065136735157

Epoch: 5| Step: 6
Training loss: 1.6163384914398193
Validation loss: 2.129226307715139

Epoch: 5| Step: 7
Training loss: 1.6359144449234009
Validation loss: 2.1085999934904036

Epoch: 5| Step: 8
Training loss: 1.705495834350586
Validation loss: 2.062381580311765

Epoch: 5| Step: 9
Training loss: 1.5435664653778076
Validation loss: 2.1045863038750103

Epoch: 5| Step: 10
Training loss: 1.748011589050293
Validation loss: 2.120254229473811

Epoch: 355| Step: 0
Training loss: 1.908439040184021
Validation loss: 2.110598148838166

Epoch: 5| Step: 1
Training loss: 1.6273338794708252
Validation loss: 2.088035750132735

Epoch: 5| Step: 2
Training loss: 1.8641685247421265
Validation loss: 2.1073234696542062

Epoch: 5| Step: 3
Training loss: 1.1873750686645508
Validation loss: 2.141670237305344

Epoch: 5| Step: 4
Training loss: 2.173250675201416
Validation loss: 2.0915926169323664

Epoch: 5| Step: 5
Training loss: 1.494035005569458
Validation loss: 2.1270404938728578

Epoch: 5| Step: 6
Training loss: 1.3665871620178223
Validation loss: 2.1100518472733034

Epoch: 5| Step: 7
Training loss: 1.585990071296692
Validation loss: 2.0914135748340237

Epoch: 5| Step: 8
Training loss: 1.9781707525253296
Validation loss: 2.0888087800754014

Epoch: 5| Step: 9
Training loss: 2.145648241043091
Validation loss: 2.108966581283077

Epoch: 5| Step: 10
Training loss: 1.491468906402588
Validation loss: 2.0984770277495026

Epoch: 356| Step: 0
Training loss: 1.4153802394866943
Validation loss: 2.1073370082404024

Epoch: 5| Step: 1
Training loss: 1.1695762872695923
Validation loss: 2.1434226933346

Epoch: 5| Step: 2
Training loss: 1.2751919031143188
Validation loss: 2.1328427919777493

Epoch: 5| Step: 3
Training loss: 1.8469641208648682
Validation loss: 2.1076018361635107

Epoch: 5| Step: 4
Training loss: 1.4933964014053345
Validation loss: 2.1009408889278287

Epoch: 5| Step: 5
Training loss: 1.74251389503479
Validation loss: 2.135995634140507

Epoch: 5| Step: 6
Training loss: 1.7772252559661865
Validation loss: 2.1142997369971326

Epoch: 5| Step: 7
Training loss: 2.4104690551757812
Validation loss: 2.122207985129408

Epoch: 5| Step: 8
Training loss: 1.8774287700653076
Validation loss: 2.1507927281882173

Epoch: 5| Step: 9
Training loss: 1.7803131341934204
Validation loss: 2.117129615558091

Epoch: 5| Step: 10
Training loss: 1.8764729499816895
Validation loss: 2.112168655600599

Epoch: 357| Step: 0
Training loss: 1.6812950372695923
Validation loss: 2.123086493502381

Epoch: 5| Step: 1
Training loss: 1.6585906744003296
Validation loss: 2.12407938895687

Epoch: 5| Step: 2
Training loss: 1.4651962518692017
Validation loss: 2.101072116564679

Epoch: 5| Step: 3
Training loss: 1.9363572597503662
Validation loss: 2.0867519750390002

Epoch: 5| Step: 4
Training loss: 2.0080785751342773
Validation loss: 2.142667229457568

Epoch: 5| Step: 5
Training loss: 0.9051505923271179
Validation loss: 2.126262600703906

Epoch: 5| Step: 6
Training loss: 1.7854328155517578
Validation loss: 2.1763518343689623

Epoch: 5| Step: 7
Training loss: 2.4448955059051514
Validation loss: 2.099948324182982

Epoch: 5| Step: 8
Training loss: 1.7386207580566406
Validation loss: 2.0780648134088002

Epoch: 5| Step: 9
Training loss: 1.147946834564209
Validation loss: 2.109340121669154

Epoch: 5| Step: 10
Training loss: 1.8614529371261597
Validation loss: 2.132839233644547

Epoch: 358| Step: 0
Training loss: 1.391916036605835
Validation loss: 2.0838751305815992

Epoch: 5| Step: 1
Training loss: 2.006603240966797
Validation loss: 2.103730727267522

Epoch: 5| Step: 2
Training loss: 1.6362234354019165
Validation loss: 2.080652542011712

Epoch: 5| Step: 3
Training loss: 1.6025915145874023
Validation loss: 2.100844080730151

Epoch: 5| Step: 4
Training loss: 1.577854037284851
Validation loss: 2.1424250474540134

Epoch: 5| Step: 5
Training loss: 1.5192888975143433
Validation loss: 2.1300250279006137

Epoch: 5| Step: 6
Training loss: 1.1591870784759521
Validation loss: 2.1459514710210983

Epoch: 5| Step: 7
Training loss: 2.2066893577575684
Validation loss: 2.0979822143431632

Epoch: 5| Step: 8
Training loss: 1.5574947595596313
Validation loss: 2.1435494986913537

Epoch: 5| Step: 9
Training loss: 1.5620496273040771
Validation loss: 2.097061396926962

Epoch: 5| Step: 10
Training loss: 2.3826427459716797
Validation loss: 2.102513726039599

Epoch: 359| Step: 0
Training loss: 2.1688029766082764
Validation loss: 2.1361921192497335

Epoch: 5| Step: 1
Training loss: 1.892554521560669
Validation loss: 2.1445094231636292

Epoch: 5| Step: 2
Training loss: 1.2723709344863892
Validation loss: 2.121661106745402

Epoch: 5| Step: 3
Training loss: 1.8380353450775146
Validation loss: 2.1189966150509414

Epoch: 5| Step: 4
Training loss: 1.2512779235839844
Validation loss: 2.137563782353555

Epoch: 5| Step: 5
Training loss: 1.5383386611938477
Validation loss: 2.1216876455532607

Epoch: 5| Step: 6
Training loss: 1.7129024267196655
Validation loss: 2.154035904074228

Epoch: 5| Step: 7
Training loss: 1.3369840383529663
Validation loss: 2.0769962187736266

Epoch: 5| Step: 8
Training loss: 2.0709338188171387
Validation loss: 2.1396347322771625

Epoch: 5| Step: 9
Training loss: 2.26755952835083
Validation loss: 2.0709397920998196

Epoch: 5| Step: 10
Training loss: 1.4725598096847534
Validation loss: 2.1157017805243052

Epoch: 360| Step: 0
Training loss: 1.8859660625457764
Validation loss: 2.1083251891597623

Epoch: 5| Step: 1
Training loss: 1.4653456211090088
Validation loss: 2.1141639063435216

Epoch: 5| Step: 2
Training loss: 1.5913034677505493
Validation loss: 2.1016784124476935

Epoch: 5| Step: 3
Training loss: 2.0279440879821777
Validation loss: 2.1327499830594627

Epoch: 5| Step: 4
Training loss: 1.2860217094421387
Validation loss: 2.1702616599298294

Epoch: 5| Step: 5
Training loss: 1.7496888637542725
Validation loss: 2.121399353909236

Epoch: 5| Step: 6
Training loss: 1.8215768337249756
Validation loss: 2.1248878535404

Epoch: 5| Step: 7
Training loss: 1.5885684490203857
Validation loss: 2.0689479638171453

Epoch: 5| Step: 8
Training loss: 2.0410125255584717
Validation loss: 2.1534865005041963

Epoch: 5| Step: 9
Training loss: 1.6021314859390259
Validation loss: 2.1077572273951706

Epoch: 5| Step: 10
Training loss: 1.3976467847824097
Validation loss: 2.100512958342029

Epoch: 361| Step: 0
Training loss: 1.544774055480957
Validation loss: 2.080453888062508

Epoch: 5| Step: 1
Training loss: 1.8057752847671509
Validation loss: 2.0785612188359743

Epoch: 5| Step: 2
Training loss: 1.6945130825042725
Validation loss: 2.0946146518953386

Epoch: 5| Step: 3
Training loss: 1.5484397411346436
Validation loss: 2.0750160858195317

Epoch: 5| Step: 4
Training loss: 1.9764759540557861
Validation loss: 2.156456391016642

Epoch: 5| Step: 5
Training loss: 1.5106254816055298
Validation loss: 2.0514800574189875

Epoch: 5| Step: 6
Training loss: 1.4363386631011963
Validation loss: 2.0936620068806473

Epoch: 5| Step: 7
Training loss: 1.8229681253433228
Validation loss: 2.059890680415656

Epoch: 5| Step: 8
Training loss: 1.75030517578125
Validation loss: 2.08624525736737

Epoch: 5| Step: 9
Training loss: 1.4027917385101318
Validation loss: 2.150899533302553

Epoch: 5| Step: 10
Training loss: 2.1634104251861572
Validation loss: 2.0932389087574457

Epoch: 362| Step: 0
Training loss: 1.696468710899353
Validation loss: 2.0955103546060543

Epoch: 5| Step: 1
Training loss: 1.226144552230835
Validation loss: 2.1560026458514634

Epoch: 5| Step: 2
Training loss: 1.9088186025619507
Validation loss: 2.104595086907828

Epoch: 5| Step: 3
Training loss: 1.6591218709945679
Validation loss: 2.1535585080423663

Epoch: 5| Step: 4
Training loss: 1.2519233226776123
Validation loss: 2.100552481989707

Epoch: 5| Step: 5
Training loss: 2.2345709800720215
Validation loss: 2.1042160910944783

Epoch: 5| Step: 6
Training loss: 1.3661514520645142
Validation loss: 2.080583210914366

Epoch: 5| Step: 7
Training loss: 1.5113651752471924
Validation loss: 2.103932631913052

Epoch: 5| Step: 8
Training loss: 1.9528274536132812
Validation loss: 2.0802181779697375

Epoch: 5| Step: 9
Training loss: 1.64056396484375
Validation loss: 2.161758468997094

Epoch: 5| Step: 10
Training loss: 2.1810054779052734
Validation loss: 2.1268418758146224

Epoch: 363| Step: 0
Training loss: 1.869235634803772
Validation loss: 2.1083947202210784

Epoch: 5| Step: 1
Training loss: 1.5843766927719116
Validation loss: 2.1390273853014876

Epoch: 5| Step: 2
Training loss: 1.4011390209197998
Validation loss: 2.1162866571898102

Epoch: 5| Step: 3
Training loss: 1.8186464309692383
Validation loss: 2.1206023000901744

Epoch: 5| Step: 4
Training loss: 2.117762804031372
Validation loss: 2.146315161899854

Epoch: 5| Step: 5
Training loss: 1.4153335094451904
Validation loss: 2.092853561524422

Epoch: 5| Step: 6
Training loss: 1.673831582069397
Validation loss: 2.136749544451314

Epoch: 5| Step: 7
Training loss: 2.2124409675598145
Validation loss: 2.1236179080060733

Epoch: 5| Step: 8
Training loss: 0.9937102198600769
Validation loss: 2.133785779758166

Epoch: 5| Step: 9
Training loss: 1.6106551885604858
Validation loss: 2.170513863204628

Epoch: 5| Step: 10
Training loss: 1.9805326461791992
Validation loss: 2.1010564437476535

Epoch: 364| Step: 0
Training loss: 2.4389591217041016
Validation loss: 2.102432780368354

Epoch: 5| Step: 1
Training loss: 1.851355791091919
Validation loss: 2.0965764368734052

Epoch: 5| Step: 2
Training loss: 1.0418848991394043
Validation loss: 2.1078338135955152

Epoch: 5| Step: 3
Training loss: 1.3088451623916626
Validation loss: 2.1400940290061374

Epoch: 5| Step: 4
Training loss: 1.9516242742538452
Validation loss: 2.130014532355852

Epoch: 5| Step: 5
Training loss: 1.7639620304107666
Validation loss: 2.129865933490056

Epoch: 5| Step: 6
Training loss: 1.8520433902740479
Validation loss: 2.0897190442649265

Epoch: 5| Step: 7
Training loss: 1.9494645595550537
Validation loss: 2.1555349852449153

Epoch: 5| Step: 8
Training loss: 1.7552404403686523
Validation loss: 2.1207709466257403

Epoch: 5| Step: 9
Training loss: 1.4871492385864258
Validation loss: 2.107516363102903

Epoch: 5| Step: 10
Training loss: 1.0218164920806885
Validation loss: 2.0942232044794227

Epoch: 365| Step: 0
Training loss: 2.2081751823425293
Validation loss: 2.139270938852782

Epoch: 5| Step: 1
Training loss: 1.6871135234832764
Validation loss: 2.145225865866548

Epoch: 5| Step: 2
Training loss: 1.4907560348510742
Validation loss: 2.141141947879586

Epoch: 5| Step: 3
Training loss: 1.1666079759597778
Validation loss: 2.1212400595347085

Epoch: 5| Step: 4
Training loss: 1.538963794708252
Validation loss: 2.063859160228442

Epoch: 5| Step: 5
Training loss: 1.4511260986328125
Validation loss: 2.126084359743262

Epoch: 5| Step: 6
Training loss: 1.7495677471160889
Validation loss: 2.170314238917443

Epoch: 5| Step: 7
Training loss: 1.9367907047271729
Validation loss: 2.1261165500969015

Epoch: 5| Step: 8
Training loss: 1.549329161643982
Validation loss: 2.1492718650448706

Epoch: 5| Step: 9
Training loss: 1.6288446187973022
Validation loss: 2.0932617674591723

Epoch: 5| Step: 10
Training loss: 2.4876883029937744
Validation loss: 2.099466580216603

Epoch: 366| Step: 0
Training loss: 1.3973640203475952
Validation loss: 2.1019712007173927

Epoch: 5| Step: 1
Training loss: 0.9268043637275696
Validation loss: 2.1364804083301174

Epoch: 5| Step: 2
Training loss: 1.7802560329437256
Validation loss: 2.180868391067751

Epoch: 5| Step: 3
Training loss: 2.1812806129455566
Validation loss: 2.137600101450438

Epoch: 5| Step: 4
Training loss: 1.7798656225204468
Validation loss: 2.0695362706338205

Epoch: 5| Step: 5
Training loss: 0.8360345959663391
Validation loss: 2.144413562231166

Epoch: 5| Step: 6
Training loss: 2.094910144805908
Validation loss: 2.1186067006921254

Epoch: 5| Step: 7
Training loss: 1.1836384534835815
Validation loss: 2.094211729623938

Epoch: 5| Step: 8
Training loss: 2.1624741554260254
Validation loss: 2.1489902568119827

Epoch: 5| Step: 9
Training loss: 1.6115427017211914
Validation loss: 2.132194501097484

Epoch: 5| Step: 10
Training loss: 2.4228734970092773
Validation loss: 2.107955148143153

Epoch: 367| Step: 0
Training loss: 1.98284113407135
Validation loss: 2.1243121316356044

Epoch: 5| Step: 1
Training loss: 1.8428558111190796
Validation loss: 2.1047211667542816

Epoch: 5| Step: 2
Training loss: 1.74265456199646
Validation loss: 2.1148507031061317

Epoch: 5| Step: 3
Training loss: 1.7815214395523071
Validation loss: 2.1258494187426824

Epoch: 5| Step: 4
Training loss: 1.5075738430023193
Validation loss: 2.1504647706144597

Epoch: 5| Step: 5
Training loss: 1.6945505142211914
Validation loss: 2.131571941478278

Epoch: 5| Step: 6
Training loss: 1.567002773284912
Validation loss: 2.146359719255919

Epoch: 5| Step: 7
Training loss: 1.4770740270614624
Validation loss: 2.1479836715165006

Epoch: 5| Step: 8
Training loss: 1.8245432376861572
Validation loss: 2.1234049386875604

Epoch: 5| Step: 9
Training loss: 1.791884183883667
Validation loss: 2.139126254666236

Epoch: 5| Step: 10
Training loss: 1.2786396741867065
Validation loss: 2.1327388440409014

Epoch: 368| Step: 0
Training loss: 1.5010591745376587
Validation loss: 2.1356885561379055

Epoch: 5| Step: 1
Training loss: 1.3447949886322021
Validation loss: 2.0916882843099613

Epoch: 5| Step: 2
Training loss: 1.2041215896606445
Validation loss: 2.140884981360487

Epoch: 5| Step: 3
Training loss: 1.9369045495986938
Validation loss: 2.1364754015399563

Epoch: 5| Step: 4
Training loss: 1.9683917760849
Validation loss: 2.1113382821441977

Epoch: 5| Step: 5
Training loss: 1.4768730401992798
Validation loss: 2.159095756469234

Epoch: 5| Step: 6
Training loss: 1.4086297750473022
Validation loss: 2.103367418371221

Epoch: 5| Step: 7
Training loss: 2.067389965057373
Validation loss: 2.0838526564259685

Epoch: 5| Step: 8
Training loss: 1.4311740398406982
Validation loss: 2.1048495000408542

Epoch: 5| Step: 9
Training loss: 2.1903393268585205
Validation loss: 2.0897198056661956

Epoch: 5| Step: 10
Training loss: 1.9347246885299683
Validation loss: 2.108984778004308

Epoch: 369| Step: 0
Training loss: 2.018427610397339
Validation loss: 2.115777051577004

Epoch: 5| Step: 1
Training loss: 1.4839988946914673
Validation loss: 2.1808906165502404

Epoch: 5| Step: 2
Training loss: 1.6474605798721313
Validation loss: 2.1110044948516355

Epoch: 5| Step: 3
Training loss: 1.7138770818710327
Validation loss: 2.129803378094909

Epoch: 5| Step: 4
Training loss: 1.955867052078247
Validation loss: 2.059447088549214

Epoch: 5| Step: 5
Training loss: 1.8528025150299072
Validation loss: 2.135391048205796

Epoch: 5| Step: 6
Training loss: 1.7040119171142578
Validation loss: 2.060431424007621

Epoch: 5| Step: 7
Training loss: 1.2680580615997314
Validation loss: 2.138790774089034

Epoch: 5| Step: 8
Training loss: 1.8261473178863525
Validation loss: 2.077053782760456

Epoch: 5| Step: 9
Training loss: 1.618138074874878
Validation loss: 2.1113790158302552

Epoch: 5| Step: 10
Training loss: 1.062514066696167
Validation loss: 2.109179369864925

Epoch: 370| Step: 0
Training loss: 1.6245657205581665
Validation loss: 2.135001177428871

Epoch: 5| Step: 1
Training loss: 1.5165257453918457
Validation loss: 2.125465505866594

Epoch: 5| Step: 2
Training loss: 1.9337148666381836
Validation loss: 2.1139452329245945

Epoch: 5| Step: 3
Training loss: 1.5535856485366821
Validation loss: 2.1419702396597913

Epoch: 5| Step: 4
Training loss: 1.190800428390503
Validation loss: 2.136627653593658

Epoch: 5| Step: 5
Training loss: 1.5831682682037354
Validation loss: 2.1196293933417207

Epoch: 5| Step: 6
Training loss: 1.6761633157730103
Validation loss: 2.0809392582985664

Epoch: 5| Step: 7
Training loss: 1.7387326955795288
Validation loss: 2.099207962712934

Epoch: 5| Step: 8
Training loss: 1.663294792175293
Validation loss: 2.1669243458778626

Epoch: 5| Step: 9
Training loss: 1.8875980377197266
Validation loss: 2.1408709582462104

Epoch: 5| Step: 10
Training loss: 1.9266135692596436
Validation loss: 2.0820791644434773

Epoch: 371| Step: 0
Training loss: 1.3171186447143555
Validation loss: 2.1236222892679195

Epoch: 5| Step: 1
Training loss: 1.3505241870880127
Validation loss: 2.104104075380551

Epoch: 5| Step: 2
Training loss: 1.6938483715057373
Validation loss: 2.1345262655647854

Epoch: 5| Step: 3
Training loss: 1.590368628501892
Validation loss: 2.1099394367587183

Epoch: 5| Step: 4
Training loss: 1.493969202041626
Validation loss: 2.1494925663035405

Epoch: 5| Step: 5
Training loss: 1.6608350276947021
Validation loss: 2.124756428503221

Epoch: 5| Step: 6
Training loss: 1.6063690185546875
Validation loss: 2.108140551915733

Epoch: 5| Step: 7
Training loss: 1.5759947299957275
Validation loss: 2.1622921907773582

Epoch: 5| Step: 8
Training loss: 1.7980268001556396
Validation loss: 2.1363622014240553

Epoch: 5| Step: 9
Training loss: 2.443080425262451
Validation loss: 2.1723336609460975

Epoch: 5| Step: 10
Training loss: 1.737635850906372
Validation loss: 2.0983894153307845

Epoch: 372| Step: 0
Training loss: 1.8548133373260498
Validation loss: 2.146745090843529

Epoch: 5| Step: 1
Training loss: 1.8322646617889404
Validation loss: 2.095093252838299

Epoch: 5| Step: 2
Training loss: 1.802651047706604
Validation loss: 2.129810215324484

Epoch: 5| Step: 3
Training loss: 1.8876632452011108
Validation loss: 2.127047105502057

Epoch: 5| Step: 4
Training loss: 1.7887623310089111
Validation loss: 2.110542138417562

Epoch: 5| Step: 5
Training loss: 1.622550368309021
Validation loss: 2.1392941808187835

Epoch: 5| Step: 6
Training loss: 1.8119491338729858
Validation loss: 2.126840446584968

Epoch: 5| Step: 7
Training loss: 1.5391476154327393
Validation loss: 2.098385049450782

Epoch: 5| Step: 8
Training loss: 1.3468079566955566
Validation loss: 2.1861999111790813

Epoch: 5| Step: 9
Training loss: 1.3143819570541382
Validation loss: 2.161440581403753

Epoch: 5| Step: 10
Training loss: 1.3393856287002563
Validation loss: 2.149788369414627

Epoch: 373| Step: 0
Training loss: 1.3824005126953125
Validation loss: 2.1609899613165084

Epoch: 5| Step: 1
Training loss: 1.6803754568099976
Validation loss: 2.17109271787828

Epoch: 5| Step: 2
Training loss: 1.727770209312439
Validation loss: 2.1299317395815285

Epoch: 5| Step: 3
Training loss: 1.1908515691757202
Validation loss: 2.1712752183278403

Epoch: 5| Step: 4
Training loss: 1.518013596534729
Validation loss: 2.10484282688428

Epoch: 5| Step: 5
Training loss: 1.031208872795105
Validation loss: 2.117019054710224

Epoch: 5| Step: 6
Training loss: 2.1572556495666504
Validation loss: 2.095416791977421

Epoch: 5| Step: 7
Training loss: 1.6472152471542358
Validation loss: 2.090827388148154

Epoch: 5| Step: 8
Training loss: 2.008945941925049
Validation loss: 2.106956126869366

Epoch: 5| Step: 9
Training loss: 1.7424465417861938
Validation loss: 2.1342225510586976

Epoch: 5| Step: 10
Training loss: 2.3402416706085205
Validation loss: 2.089201783621183

Epoch: 374| Step: 0
Training loss: 1.4452749490737915
Validation loss: 2.153061138686313

Epoch: 5| Step: 1
Training loss: 1.8747930526733398
Validation loss: 2.1173690942025956

Epoch: 5| Step: 2
Training loss: 1.3363358974456787
Validation loss: 2.099700576515608

Epoch: 5| Step: 3
Training loss: 1.084993600845337
Validation loss: 2.121674253094581

Epoch: 5| Step: 4
Training loss: 1.823150873184204
Validation loss: 2.07929571982353

Epoch: 5| Step: 5
Training loss: 1.5140364170074463
Validation loss: 2.103758778623355

Epoch: 5| Step: 6
Training loss: 2.3145060539245605
Validation loss: 2.1342876957308863

Epoch: 5| Step: 7
Training loss: 1.2760448455810547
Validation loss: 2.123722726298917

Epoch: 5| Step: 8
Training loss: 1.607078194618225
Validation loss: 2.1154065952506116

Epoch: 5| Step: 9
Training loss: 1.8542951345443726
Validation loss: 2.1501894279192855

Epoch: 5| Step: 10
Training loss: 1.7572802305221558
Validation loss: 2.094697549778928

Epoch: 375| Step: 0
Training loss: 1.559881329536438
Validation loss: 2.227907939623761

Epoch: 5| Step: 1
Training loss: 1.5633280277252197
Validation loss: 2.1411240126497004

Epoch: 5| Step: 2
Training loss: 1.733472466468811
Validation loss: 2.1331160273603214

Epoch: 5| Step: 3
Training loss: 1.9580011367797852
Validation loss: 2.1096057686754452

Epoch: 5| Step: 4
Training loss: 1.4636144638061523
Validation loss: 2.1611301796410674

Epoch: 5| Step: 5
Training loss: 1.3876286745071411
Validation loss: 2.1893341618199504

Epoch: 5| Step: 6
Training loss: 1.4275164604187012
Validation loss: 2.128517513634056

Epoch: 5| Step: 7
Training loss: 2.1298282146453857
Validation loss: 2.1582955134812223

Epoch: 5| Step: 8
Training loss: 1.7076301574707031
Validation loss: 2.1318750330196914

Epoch: 5| Step: 9
Training loss: 1.7479314804077148
Validation loss: 2.1792197945297405

Epoch: 5| Step: 10
Training loss: 1.4002827405929565
Validation loss: 2.084273802336826

Epoch: 376| Step: 0
Training loss: 1.6529934406280518
Validation loss: 2.157176325398107

Epoch: 5| Step: 1
Training loss: 1.547927737236023
Validation loss: 2.152092925963863

Epoch: 5| Step: 2
Training loss: 2.1372132301330566
Validation loss: 2.1437580623934345

Epoch: 5| Step: 3
Training loss: 1.7015234231948853
Validation loss: 2.1253393016835695

Epoch: 5| Step: 4
Training loss: 0.9100973010063171
Validation loss: 2.127415523734144

Epoch: 5| Step: 5
Training loss: 1.7712751626968384
Validation loss: 2.1120156690638554

Epoch: 5| Step: 6
Training loss: 1.921478509902954
Validation loss: 2.126789898000738

Epoch: 5| Step: 7
Training loss: 1.6357927322387695
Validation loss: 2.1249770374708277

Epoch: 5| Step: 8
Training loss: 1.2520420551300049
Validation loss: 2.154444068990728

Epoch: 5| Step: 9
Training loss: 2.1430490016937256
Validation loss: 2.139376255773729

Epoch: 5| Step: 10
Training loss: 1.4855592250823975
Validation loss: 2.1235135960322555

Epoch: 377| Step: 0
Training loss: 1.116361379623413
Validation loss: 2.1543789332912815

Epoch: 5| Step: 1
Training loss: 1.3399829864501953
Validation loss: 2.0849348191292054

Epoch: 5| Step: 2
Training loss: 1.1126130819320679
Validation loss: 2.141899452414564

Epoch: 5| Step: 3
Training loss: 2.1357903480529785
Validation loss: 2.1137632528940835

Epoch: 5| Step: 4
Training loss: 1.8337732553482056
Validation loss: 2.107266151776878

Epoch: 5| Step: 5
Training loss: 1.3036043643951416
Validation loss: 2.1214007036660307

Epoch: 5| Step: 6
Training loss: 1.9470064640045166
Validation loss: 2.075732377267653

Epoch: 5| Step: 7
Training loss: 1.3003747463226318
Validation loss: 2.115069007360807

Epoch: 5| Step: 8
Training loss: 1.882542371749878
Validation loss: 2.074849236396051

Epoch: 5| Step: 9
Training loss: 2.1015191078186035
Validation loss: 2.1123293035773822

Epoch: 5| Step: 10
Training loss: 1.676357626914978
Validation loss: 2.145615831498177

Epoch: 378| Step: 0
Training loss: 1.4051811695098877
Validation loss: 2.122527887744288

Epoch: 5| Step: 1
Training loss: 1.631082534790039
Validation loss: 2.1333354724350797

Epoch: 5| Step: 2
Training loss: 1.2472723722457886
Validation loss: 2.158156669268044

Epoch: 5| Step: 3
Training loss: 1.3302068710327148
Validation loss: 2.0879560311635337

Epoch: 5| Step: 4
Training loss: 1.7769569158554077
Validation loss: 2.132696379897415

Epoch: 5| Step: 5
Training loss: 2.632615566253662
Validation loss: 2.124660098424522

Epoch: 5| Step: 6
Training loss: 1.4979150295257568
Validation loss: 2.112117322542334

Epoch: 5| Step: 7
Training loss: 1.0697338581085205
Validation loss: 2.1841004125533567

Epoch: 5| Step: 8
Training loss: 1.4837614297866821
Validation loss: 2.113323651334291

Epoch: 5| Step: 9
Training loss: 2.311173439025879
Validation loss: 2.1223154837085354

Epoch: 5| Step: 10
Training loss: 1.9038310050964355
Validation loss: 2.157578806723318

Epoch: 379| Step: 0
Training loss: 1.6516835689544678
Validation loss: 2.151755784147529

Epoch: 5| Step: 1
Training loss: 1.778725028038025
Validation loss: 2.118340325611894

Epoch: 5| Step: 2
Training loss: 1.5435583591461182
Validation loss: 2.074597848358975

Epoch: 5| Step: 3
Training loss: 1.352738380432129
Validation loss: 2.0953888970036663

Epoch: 5| Step: 4
Training loss: 1.9477195739746094
Validation loss: 2.159326327744351

Epoch: 5| Step: 5
Training loss: 1.1446573734283447
Validation loss: 2.102875747988301

Epoch: 5| Step: 6
Training loss: 1.7811752557754517
Validation loss: 2.1181954158249723

Epoch: 5| Step: 7
Training loss: 1.9661674499511719
Validation loss: 2.128877725652469

Epoch: 5| Step: 8
Training loss: 1.8950401544570923
Validation loss: 2.1319840915741457

Epoch: 5| Step: 9
Training loss: 1.6539589166641235
Validation loss: 2.1637370868395736

Epoch: 5| Step: 10
Training loss: 1.314406156539917
Validation loss: 2.1782199028999574

Epoch: 380| Step: 0
Training loss: 2.4223151206970215
Validation loss: 2.1251221933672504

Epoch: 5| Step: 1
Training loss: 1.3512392044067383
Validation loss: 2.1201820245353122

Epoch: 5| Step: 2
Training loss: 1.4867329597473145
Validation loss: 2.0921151407303347

Epoch: 5| Step: 3
Training loss: 2.0784671306610107
Validation loss: 2.109977227385326

Epoch: 5| Step: 4
Training loss: 1.9300053119659424
Validation loss: 2.100417289682614

Epoch: 5| Step: 5
Training loss: 1.5725889205932617
Validation loss: 2.1497357429996615

Epoch: 5| Step: 6
Training loss: 2.055649995803833
Validation loss: 2.096353884666197

Epoch: 5| Step: 7
Training loss: 1.4546387195587158
Validation loss: 2.1212650627218266

Epoch: 5| Step: 8
Training loss: 1.1949479579925537
Validation loss: 2.1187607524215535

Epoch: 5| Step: 9
Training loss: 1.25541353225708
Validation loss: 2.0961411204389346

Epoch: 5| Step: 10
Training loss: 1.3663344383239746
Validation loss: 2.170525577760512

Epoch: 381| Step: 0
Training loss: 1.5277683734893799
Validation loss: 2.1382961209102342

Epoch: 5| Step: 1
Training loss: 1.0197663307189941
Validation loss: 2.1729717357184297

Epoch: 5| Step: 2
Training loss: 1.2872661352157593
Validation loss: 2.1332737271503737

Epoch: 5| Step: 3
Training loss: 1.9060370922088623
Validation loss: 2.1121500410059446

Epoch: 5| Step: 4
Training loss: 2.0346763134002686
Validation loss: 2.1125929688894622

Epoch: 5| Step: 5
Training loss: 1.5731174945831299
Validation loss: 2.155685724750642

Epoch: 5| Step: 6
Training loss: 1.8073997497558594
Validation loss: 2.1318611252692437

Epoch: 5| Step: 7
Training loss: 1.6601788997650146
Validation loss: 2.128997718134234

Epoch: 5| Step: 8
Training loss: 1.7040103673934937
Validation loss: 2.1142153316928494

Epoch: 5| Step: 9
Training loss: 2.2730915546417236
Validation loss: 2.152788390395462

Epoch: 5| Step: 10
Training loss: 0.943997323513031
Validation loss: 2.1034125384464057

Epoch: 382| Step: 0
Training loss: 1.7973148822784424
Validation loss: 2.1547746068687847

Epoch: 5| Step: 1
Training loss: 1.4547245502471924
Validation loss: 2.136441033373597

Epoch: 5| Step: 2
Training loss: 1.3583043813705444
Validation loss: 2.1425572954198366

Epoch: 5| Step: 3
Training loss: 1.5604665279388428
Validation loss: 2.171808365852602

Epoch: 5| Step: 4
Training loss: 1.5028352737426758
Validation loss: 2.0799787070161555

Epoch: 5| Step: 5
Training loss: 1.6210441589355469
Validation loss: 2.200671237002137

Epoch: 5| Step: 6
Training loss: 1.5883997678756714
Validation loss: 2.1146250899120043

Epoch: 5| Step: 7
Training loss: 1.5443109273910522
Validation loss: 2.1280920313250635

Epoch: 5| Step: 8
Training loss: 1.948021650314331
Validation loss: 2.15391287496013

Epoch: 5| Step: 9
Training loss: 1.645106554031372
Validation loss: 2.097676291260668

Epoch: 5| Step: 10
Training loss: 1.6477159261703491
Validation loss: 2.076437762988511

Epoch: 383| Step: 0
Training loss: 2.0508878231048584
Validation loss: 2.1048791921266945

Epoch: 5| Step: 1
Training loss: 1.8327468633651733
Validation loss: 2.14379902937079

Epoch: 5| Step: 2
Training loss: 1.3535560369491577
Validation loss: 2.1148541460755053

Epoch: 5| Step: 3
Training loss: 1.7325299978256226
Validation loss: 2.1128856494862545

Epoch: 5| Step: 4
Training loss: 1.094464898109436
Validation loss: 2.110223226649787

Epoch: 5| Step: 5
Training loss: 1.4713232517242432
Validation loss: 2.0722954580860753

Epoch: 5| Step: 6
Training loss: 2.072218656539917
Validation loss: 2.1016262128788936

Epoch: 5| Step: 7
Training loss: 1.3040364980697632
Validation loss: 2.1224536972661174

Epoch: 5| Step: 8
Training loss: 1.849822759628296
Validation loss: 2.129488855279902

Epoch: 5| Step: 9
Training loss: 1.683589220046997
Validation loss: 2.1050759361636255

Epoch: 5| Step: 10
Training loss: 1.8492871522903442
Validation loss: 2.183304945627848

Epoch: 384| Step: 0
Training loss: 1.271589994430542
Validation loss: 2.1028712385444233

Epoch: 5| Step: 1
Training loss: 1.817357063293457
Validation loss: 2.1440200382663357

Epoch: 5| Step: 2
Training loss: 1.911928415298462
Validation loss: 2.128436170598512

Epoch: 5| Step: 3
Training loss: 1.4787003993988037
Validation loss: 2.1709388199672905

Epoch: 5| Step: 4
Training loss: 1.7083690166473389
Validation loss: 2.1300054570680023

Epoch: 5| Step: 5
Training loss: 1.473502278327942
Validation loss: 2.184067080097814

Epoch: 5| Step: 6
Training loss: 1.6226465702056885
Validation loss: 2.173874144913048

Epoch: 5| Step: 7
Training loss: 1.2039662599563599
Validation loss: 2.1126600516739713

Epoch: 5| Step: 8
Training loss: 1.7379980087280273
Validation loss: 2.1512123961602487

Epoch: 5| Step: 9
Training loss: 1.784630537033081
Validation loss: 2.091849147632558

Epoch: 5| Step: 10
Training loss: 1.943821907043457
Validation loss: 2.105586759505733

Epoch: 385| Step: 0
Training loss: 2.1259171962738037
Validation loss: 2.1696647597897436

Epoch: 5| Step: 1
Training loss: 2.0544629096984863
Validation loss: 2.16746049927127

Epoch: 5| Step: 2
Training loss: 1.3602726459503174
Validation loss: 2.1272525556625856

Epoch: 5| Step: 3
Training loss: 0.9795359373092651
Validation loss: 2.1647696546328965

Epoch: 5| Step: 4
Training loss: 1.390503168106079
Validation loss: 2.1104017560200026

Epoch: 5| Step: 5
Training loss: 1.8395801782608032
Validation loss: 2.1476851868373092

Epoch: 5| Step: 6
Training loss: 1.5389978885650635
Validation loss: 2.131472369675995

Epoch: 5| Step: 7
Training loss: 1.3180787563323975
Validation loss: 2.1400483116026847

Epoch: 5| Step: 8
Training loss: 1.7994152307510376
Validation loss: 2.1472523289342083

Epoch: 5| Step: 9
Training loss: 2.169978618621826
Validation loss: 2.110312872035529

Epoch: 5| Step: 10
Training loss: 1.3669387102127075
Validation loss: 2.1970125552146667

Epoch: 386| Step: 0
Training loss: 1.918652892112732
Validation loss: 2.182971146798903

Epoch: 5| Step: 1
Training loss: 1.7539304494857788
Validation loss: 2.1314063738751154

Epoch: 5| Step: 2
Training loss: 1.7950422763824463
Validation loss: 2.0506006158808225

Epoch: 5| Step: 3
Training loss: 1.1713125705718994
Validation loss: 2.141055184025918

Epoch: 5| Step: 4
Training loss: 1.4221330881118774
Validation loss: 2.1017712380296443

Epoch: 5| Step: 5
Training loss: 1.4777004718780518
Validation loss: 2.1230704322937997

Epoch: 5| Step: 6
Training loss: 1.5301116704940796
Validation loss: 2.126847118459722

Epoch: 5| Step: 7
Training loss: 1.8721139430999756
Validation loss: 2.1348276663851995

Epoch: 5| Step: 8
Training loss: 2.2905051708221436
Validation loss: 2.1557778043131672

Epoch: 5| Step: 9
Training loss: 1.3734225034713745
Validation loss: 2.114319950021723

Epoch: 5| Step: 10
Training loss: 1.2203081846237183
Validation loss: 2.136646309206563

Epoch: 387| Step: 0
Training loss: 1.7714061737060547
Validation loss: 2.1198500317911946

Epoch: 5| Step: 1
Training loss: 1.2911583185195923
Validation loss: 2.1490079972051803

Epoch: 5| Step: 2
Training loss: 1.4209423065185547
Validation loss: 2.1391844826359905

Epoch: 5| Step: 3
Training loss: 2.086629629135132
Validation loss: 2.1340746315576697

Epoch: 5| Step: 4
Training loss: 1.6062755584716797
Validation loss: 2.129454271767729

Epoch: 5| Step: 5
Training loss: 2.0507142543792725
Validation loss: 2.1238326475184452

Epoch: 5| Step: 6
Training loss: 1.3169828653335571
Validation loss: 2.1495396450001705

Epoch: 5| Step: 7
Training loss: 1.9755618572235107
Validation loss: 2.1382275717232817

Epoch: 5| Step: 8
Training loss: 1.2011789083480835
Validation loss: 2.16376813509131

Epoch: 5| Step: 9
Training loss: 1.5544865131378174
Validation loss: 2.137945064934351

Epoch: 5| Step: 10
Training loss: 1.42071533203125
Validation loss: 2.1757095013895342

Epoch: 388| Step: 0
Training loss: 2.0492541790008545
Validation loss: 2.1639790893882833

Epoch: 5| Step: 1
Training loss: 1.6778663396835327
Validation loss: 2.1581958814333846

Epoch: 5| Step: 2
Training loss: 1.9307241439819336
Validation loss: 2.099935495725242

Epoch: 5| Step: 3
Training loss: 1.3779019117355347
Validation loss: 2.1407983867071008

Epoch: 5| Step: 4
Training loss: 1.76651132106781
Validation loss: 2.156320269389819

Epoch: 5| Step: 5
Training loss: 1.4893447160720825
Validation loss: 2.152409904746599

Epoch: 5| Step: 6
Training loss: 1.2693067789077759
Validation loss: 2.1659042681417158

Epoch: 5| Step: 7
Training loss: 1.5124280452728271
Validation loss: 2.146077290658028

Epoch: 5| Step: 8
Training loss: 1.639204740524292
Validation loss: 2.1525603032881215

Epoch: 5| Step: 9
Training loss: 1.747664213180542
Validation loss: 2.0761248809035107

Epoch: 5| Step: 10
Training loss: 1.3571363687515259
Validation loss: 2.148852382936785

Epoch: 389| Step: 0
Training loss: 1.0180375576019287
Validation loss: 2.175103928453179

Epoch: 5| Step: 1
Training loss: 1.6591520309448242
Validation loss: 2.137595720188592

Epoch: 5| Step: 2
Training loss: 1.6467288732528687
Validation loss: 2.124888784141951

Epoch: 5| Step: 3
Training loss: 1.5409752130508423
Validation loss: 2.100666647316307

Epoch: 5| Step: 4
Training loss: 1.5631051063537598
Validation loss: 2.1363669108319026

Epoch: 5| Step: 5
Training loss: 1.3727902173995972
Validation loss: 2.140947940529034

Epoch: 5| Step: 6
Training loss: 2.0874924659729004
Validation loss: 2.162877849353257

Epoch: 5| Step: 7
Training loss: 1.5982240438461304
Validation loss: 2.1487984836742444

Epoch: 5| Step: 8
Training loss: 1.7371774911880493
Validation loss: 2.149606979021462

Epoch: 5| Step: 9
Training loss: 2.0927093029022217
Validation loss: 2.129707633808095

Epoch: 5| Step: 10
Training loss: 1.4013508558273315
Validation loss: 2.1641400244928177

Epoch: 390| Step: 0
Training loss: 2.0511393547058105
Validation loss: 2.1660930520744732

Epoch: 5| Step: 1
Training loss: 1.7416865825653076
Validation loss: 2.139437101220572

Epoch: 5| Step: 2
Training loss: 1.3230140209197998
Validation loss: 2.133332110220386

Epoch: 5| Step: 3
Training loss: 1.819261908531189
Validation loss: 2.1542198670807706

Epoch: 5| Step: 4
Training loss: 1.5364025831222534
Validation loss: 2.2047026439379622

Epoch: 5| Step: 5
Training loss: 1.5939258337020874
Validation loss: 2.1766608556111655

Epoch: 5| Step: 6
Training loss: 1.4613783359527588
Validation loss: 2.122342800581327

Epoch: 5| Step: 7
Training loss: 1.5494239330291748
Validation loss: 2.1194058707965318

Epoch: 5| Step: 8
Training loss: 1.8137686252593994
Validation loss: 2.111253358984506

Epoch: 5| Step: 9
Training loss: 1.5499074459075928
Validation loss: 2.080236740009759

Epoch: 5| Step: 10
Training loss: 1.1340327262878418
Validation loss: 2.145761497559086

Epoch: 391| Step: 0
Training loss: 2.012631893157959
Validation loss: 2.121256213034353

Epoch: 5| Step: 1
Training loss: 1.5482829809188843
Validation loss: 2.1201925534074024

Epoch: 5| Step: 2
Training loss: 2.217186450958252
Validation loss: 2.132499453841999

Epoch: 5| Step: 3
Training loss: 2.207770586013794
Validation loss: 2.140317360560099

Epoch: 5| Step: 4
Training loss: 1.3640546798706055
Validation loss: 2.1513790122924314

Epoch: 5| Step: 5
Training loss: 1.8006547689437866
Validation loss: 2.1916775293247674

Epoch: 5| Step: 6
Training loss: 1.2528756856918335
Validation loss: 2.1851046726267827

Epoch: 5| Step: 7
Training loss: 1.4132124185562134
Validation loss: 2.128350352728239

Epoch: 5| Step: 8
Training loss: 1.262373924255371
Validation loss: 2.1777144606395433

Epoch: 5| Step: 9
Training loss: 1.2781999111175537
Validation loss: 2.0703803518767

Epoch: 5| Step: 10
Training loss: 1.1058722734451294
Validation loss: 2.093605051758469

Epoch: 392| Step: 0
Training loss: 1.6535990238189697
Validation loss: 2.123779721157525

Epoch: 5| Step: 1
Training loss: 1.6427758932113647
Validation loss: 2.19557427078165

Epoch: 5| Step: 2
Training loss: 1.1599314212799072
Validation loss: 2.096034052551434

Epoch: 5| Step: 3
Training loss: 2.046811580657959
Validation loss: 2.177891799198684

Epoch: 5| Step: 4
Training loss: 1.8445892333984375
Validation loss: 2.1752430251849595

Epoch: 5| Step: 5
Training loss: 1.730773687362671
Validation loss: 2.156220172041206

Epoch: 5| Step: 6
Training loss: 1.2860257625579834
Validation loss: 2.117539455813746

Epoch: 5| Step: 7
Training loss: 1.0835838317871094
Validation loss: 2.138302779966785

Epoch: 5| Step: 8
Training loss: 2.3311376571655273
Validation loss: 2.1627098206550843

Epoch: 5| Step: 9
Training loss: 1.3506253957748413
Validation loss: 2.13879636538926

Epoch: 5| Step: 10
Training loss: 1.5319358110427856
Validation loss: 2.144471388991161

Epoch: 393| Step: 0
Training loss: 1.167822241783142
Validation loss: 2.148122828493836

Epoch: 5| Step: 1
Training loss: 0.7008787989616394
Validation loss: 2.15599839661711

Epoch: 5| Step: 2
Training loss: 2.4930636882781982
Validation loss: 2.1670476044377973

Epoch: 5| Step: 3
Training loss: 2.0201938152313232
Validation loss: 2.1241639942251225

Epoch: 5| Step: 4
Training loss: 2.078197717666626
Validation loss: 2.122001394148796

Epoch: 5| Step: 5
Training loss: 1.0972620248794556
Validation loss: 2.145195661052581

Epoch: 5| Step: 6
Training loss: 1.7089869976043701
Validation loss: 2.1364925740867533

Epoch: 5| Step: 7
Training loss: 1.8051153421401978
Validation loss: 2.1212458559261855

Epoch: 5| Step: 8
Training loss: 1.468130350112915
Validation loss: 2.1477627549120175

Epoch: 5| Step: 9
Training loss: 1.3448959589004517
Validation loss: 2.1540033240472116

Epoch: 5| Step: 10
Training loss: 1.9797062873840332
Validation loss: 2.1652110879139235

Epoch: 394| Step: 0
Training loss: 1.555879831314087
Validation loss: 2.1384969167811896

Epoch: 5| Step: 1
Training loss: 2.141282558441162
Validation loss: 2.1834263109391734

Epoch: 5| Step: 2
Training loss: 1.340935468673706
Validation loss: 2.1222508697099585

Epoch: 5| Step: 3
Training loss: 1.155653476715088
Validation loss: 2.0931693097596527

Epoch: 5| Step: 4
Training loss: 1.0664153099060059
Validation loss: 2.165071855309189

Epoch: 5| Step: 5
Training loss: 1.8816591501235962
Validation loss: 2.093996246655782

Epoch: 5| Step: 6
Training loss: 1.5565906763076782
Validation loss: 2.1198794713584324

Epoch: 5| Step: 7
Training loss: 2.09718656539917
Validation loss: 2.109976424965807

Epoch: 5| Step: 8
Training loss: 1.9104454517364502
Validation loss: 2.1221790570084766

Epoch: 5| Step: 9
Training loss: 1.7473363876342773
Validation loss: 2.1467478916209233

Epoch: 5| Step: 10
Training loss: 1.3108108043670654
Validation loss: 2.125276547606273

Epoch: 395| Step: 0
Training loss: 0.9506862759590149
Validation loss: 2.130235295141897

Epoch: 5| Step: 1
Training loss: 1.1599993705749512
Validation loss: 2.1768152957321494

Epoch: 5| Step: 2
Training loss: 1.9332656860351562
Validation loss: 2.124383400845271

Epoch: 5| Step: 3
Training loss: 1.4507007598876953
Validation loss: 2.129657563342843

Epoch: 5| Step: 4
Training loss: 1.7036826610565186
Validation loss: 2.063360519306634

Epoch: 5| Step: 5
Training loss: 1.1937024593353271
Validation loss: 2.167569265570692

Epoch: 5| Step: 6
Training loss: 2.258679151535034
Validation loss: 2.1842732275685957

Epoch: 5| Step: 7
Training loss: 1.7837278842926025
Validation loss: 2.1539246036160375

Epoch: 5| Step: 8
Training loss: 1.8548656702041626
Validation loss: 2.115982106936875

Epoch: 5| Step: 9
Training loss: 1.3744200468063354
Validation loss: 2.151475215470919

Epoch: 5| Step: 10
Training loss: 1.6951805353164673
Validation loss: 2.154513780788709

Epoch: 396| Step: 0
Training loss: 2.1678383350372314
Validation loss: 2.1171487838991228

Epoch: 5| Step: 1
Training loss: 2.176861047744751
Validation loss: 2.1583935470991236

Epoch: 5| Step: 2
Training loss: 1.218379020690918
Validation loss: 2.162635258449021

Epoch: 5| Step: 3
Training loss: 1.8399425745010376
Validation loss: 2.139526938879362

Epoch: 5| Step: 4
Training loss: 1.2956888675689697
Validation loss: 2.118168397616315

Epoch: 5| Step: 5
Training loss: 1.5757296085357666
Validation loss: 2.072372249377671

Epoch: 5| Step: 6
Training loss: 1.4771839380264282
Validation loss: 2.0780974613722933

Epoch: 5| Step: 7
Training loss: 1.6739065647125244
Validation loss: 2.1671076154196136

Epoch: 5| Step: 8
Training loss: 1.5309025049209595
Validation loss: 2.1550690820140224

Epoch: 5| Step: 9
Training loss: 1.3041341304779053
Validation loss: 2.1409417031913676

Epoch: 5| Step: 10
Training loss: 1.1107937097549438
Validation loss: 2.1732321862251527

Epoch: 397| Step: 0
Training loss: 1.8228555917739868
Validation loss: 2.1353554418010097

Epoch: 5| Step: 1
Training loss: 1.7202138900756836
Validation loss: 2.1121658535413843

Epoch: 5| Step: 2
Training loss: 1.470021367073059
Validation loss: 2.099340984898229

Epoch: 5| Step: 3
Training loss: 1.2724668979644775
Validation loss: 2.116151196982271

Epoch: 5| Step: 4
Training loss: 1.3681538105010986
Validation loss: 2.1546426075761036

Epoch: 5| Step: 5
Training loss: 1.7763862609863281
Validation loss: 2.164651639999882

Epoch: 5| Step: 6
Training loss: 2.4523117542266846
Validation loss: 2.1205507068223852

Epoch: 5| Step: 7
Training loss: 1.0661094188690186
Validation loss: 2.14541155933052

Epoch: 5| Step: 8
Training loss: 1.1849380731582642
Validation loss: 2.0948897741174184

Epoch: 5| Step: 9
Training loss: 1.9745317697525024
Validation loss: 2.0897741599749495

Epoch: 5| Step: 10
Training loss: 1.3765177726745605
Validation loss: 2.140712470136663

Epoch: 398| Step: 0
Training loss: 1.5604897737503052
Validation loss: 2.1476819322955225

Epoch: 5| Step: 1
Training loss: 1.881582260131836
Validation loss: 2.1301878293355307

Epoch: 5| Step: 2
Training loss: 1.9470895528793335
Validation loss: 2.1239442799680974

Epoch: 5| Step: 3
Training loss: 1.110856294631958
Validation loss: 2.111953509751187

Epoch: 5| Step: 4
Training loss: 1.958923578262329
Validation loss: 2.1291036336652693

Epoch: 5| Step: 5
Training loss: 1.5811814069747925
Validation loss: 2.110100879464098

Epoch: 5| Step: 6
Training loss: 1.7732408046722412
Validation loss: 2.1228832929365096

Epoch: 5| Step: 7
Training loss: 1.6514068841934204
Validation loss: 2.160261374647899

Epoch: 5| Step: 8
Training loss: 1.136736512184143
Validation loss: 2.1540340915802987

Epoch: 5| Step: 9
Training loss: 1.6340305805206299
Validation loss: 2.1233541298938055

Epoch: 5| Step: 10
Training loss: 1.2694497108459473
Validation loss: 2.124852888045772

Epoch: 399| Step: 0
Training loss: 2.077929735183716
Validation loss: 2.1399352845325263

Epoch: 5| Step: 1
Training loss: 1.7347335815429688
Validation loss: 2.1442698765826482

Epoch: 5| Step: 2
Training loss: 1.680072546005249
Validation loss: 2.1625194588015155

Epoch: 5| Step: 3
Training loss: 1.8091537952423096
Validation loss: 2.1608087349963445

Epoch: 5| Step: 4
Training loss: 0.8245642781257629
Validation loss: 2.186548889324229

Epoch: 5| Step: 5
Training loss: 1.7254995107650757
Validation loss: 2.135236391457178

Epoch: 5| Step: 6
Training loss: 1.5152608156204224
Validation loss: 2.1633332621666694

Epoch: 5| Step: 7
Training loss: 1.5704072713851929
Validation loss: 2.1306485322213944

Epoch: 5| Step: 8
Training loss: 1.9339416027069092
Validation loss: 2.125871437852101

Epoch: 5| Step: 9
Training loss: 1.5208797454833984
Validation loss: 2.110477502628039

Epoch: 5| Step: 10
Training loss: 1.2767879962921143
Validation loss: 2.1709908105993785

Epoch: 400| Step: 0
Training loss: 1.2534208297729492
Validation loss: 2.1219420561226467

Epoch: 5| Step: 1
Training loss: 1.8416602611541748
Validation loss: 2.130645890389719

Epoch: 5| Step: 2
Training loss: 1.6852308511734009
Validation loss: 2.1594700992748304

Epoch: 5| Step: 3
Training loss: 1.2593135833740234
Validation loss: 2.1605451132661555

Epoch: 5| Step: 4
Training loss: 1.5915868282318115
Validation loss: 2.1118768004960913

Epoch: 5| Step: 5
Training loss: 1.7693891525268555
Validation loss: 2.1415908772458314

Epoch: 5| Step: 6
Training loss: 1.22915780544281
Validation loss: 2.169947608824699

Epoch: 5| Step: 7
Training loss: 1.4405170679092407
Validation loss: 2.1662090170768

Epoch: 5| Step: 8
Training loss: 1.7741310596466064
Validation loss: 2.174703682622602

Epoch: 5| Step: 9
Training loss: 1.7362064123153687
Validation loss: 2.12846109174913

Epoch: 5| Step: 10
Training loss: 2.0567800998687744
Validation loss: 2.190424237200009

Epoch: 401| Step: 0
Training loss: 1.2310256958007812
Validation loss: 2.1590455180855206

Epoch: 5| Step: 1
Training loss: 1.3505439758300781
Validation loss: 2.1128536872966315

Epoch: 5| Step: 2
Training loss: 1.4610216617584229
Validation loss: 2.0759998572769987

Epoch: 5| Step: 3
Training loss: 1.4924900531768799
Validation loss: 2.134487795573409

Epoch: 5| Step: 4
Training loss: 2.0265135765075684
Validation loss: 2.055006952695949

Epoch: 5| Step: 5
Training loss: 1.2864649295806885
Validation loss: 2.0653964191354732

Epoch: 5| Step: 6
Training loss: 1.4111515283584595
Validation loss: 2.0735306765443537

Epoch: 5| Step: 7
Training loss: 1.1483981609344482
Validation loss: 2.1254623000339796

Epoch: 5| Step: 8
Training loss: 1.8974246978759766
Validation loss: 2.139261944319612

Epoch: 5| Step: 9
Training loss: 1.6434335708618164
Validation loss: 2.1552591657125824

Epoch: 5| Step: 10
Training loss: 2.5248663425445557
Validation loss: 2.1432161754177463

Epoch: 402| Step: 0
Training loss: 1.3215909004211426
Validation loss: 2.1563735892695766

Epoch: 5| Step: 1
Training loss: 1.7620093822479248
Validation loss: 2.1854378049091627

Epoch: 5| Step: 2
Training loss: 1.4235632419586182
Validation loss: 2.1673131373620804

Epoch: 5| Step: 3
Training loss: 1.3471745252609253
Validation loss: 2.157514992580619

Epoch: 5| Step: 4
Training loss: 1.336667537689209
Validation loss: 2.172896562084075

Epoch: 5| Step: 5
Training loss: 1.2917733192443848
Validation loss: 2.1789342023993052

Epoch: 5| Step: 6
Training loss: 1.7523329257965088
Validation loss: 2.1512576854357155

Epoch: 5| Step: 7
Training loss: 1.7302722930908203
Validation loss: 2.1646065455611034

Epoch: 5| Step: 8
Training loss: 1.742433786392212
Validation loss: 2.1915378903829925

Epoch: 5| Step: 9
Training loss: 1.7136421203613281
Validation loss: 2.1540047276404595

Epoch: 5| Step: 10
Training loss: 1.9877372980117798
Validation loss: 2.1326557590115454

Epoch: 403| Step: 0
Training loss: 1.757696509361267
Validation loss: 2.183933896403159

Epoch: 5| Step: 1
Training loss: 1.8290599584579468
Validation loss: 2.1468851438132663

Epoch: 5| Step: 2
Training loss: 1.1904224157333374
Validation loss: 2.086753335050357

Epoch: 5| Step: 3
Training loss: 1.9549556970596313
Validation loss: 2.110712706401784

Epoch: 5| Step: 4
Training loss: 1.4587388038635254
Validation loss: 2.143662861598435

Epoch: 5| Step: 5
Training loss: 1.8756717443466187
Validation loss: 2.1481564480771302

Epoch: 5| Step: 6
Training loss: 0.947613537311554
Validation loss: 2.1364803544936644

Epoch: 5| Step: 7
Training loss: 1.1481984853744507
Validation loss: 2.133685137635918

Epoch: 5| Step: 8
Training loss: 1.4422576427459717
Validation loss: 2.1218234621068484

Epoch: 5| Step: 9
Training loss: 1.7848224639892578
Validation loss: 2.107414427623954

Epoch: 5| Step: 10
Training loss: 1.6703940629959106
Validation loss: 2.096846156222846

Epoch: 404| Step: 0
Training loss: 1.511277198791504
Validation loss: 2.067008859367781

Epoch: 5| Step: 1
Training loss: 2.1038575172424316
Validation loss: 2.128274756093179

Epoch: 5| Step: 2
Training loss: 1.3539761304855347
Validation loss: 2.1057927223943893

Epoch: 5| Step: 3
Training loss: 1.4604195356369019
Validation loss: 2.12335701398952

Epoch: 5| Step: 4
Training loss: 2.0082874298095703
Validation loss: 2.118072212383311

Epoch: 5| Step: 5
Training loss: 1.7940759658813477
Validation loss: 2.1767602659040883

Epoch: 5| Step: 6
Training loss: 1.560401201248169
Validation loss: 2.150344316677381

Epoch: 5| Step: 7
Training loss: 1.3982772827148438
Validation loss: 2.1928010320150726

Epoch: 5| Step: 8
Training loss: 1.4444389343261719
Validation loss: 2.1361390467612975

Epoch: 5| Step: 9
Training loss: 2.1506762504577637
Validation loss: 2.182538451686982

Epoch: 5| Step: 10
Training loss: 1.0098406076431274
Validation loss: 2.133712987745962

Epoch: 405| Step: 0
Training loss: 1.3566596508026123
Validation loss: 2.1337605625070553

Epoch: 5| Step: 1
Training loss: 1.4581598043441772
Validation loss: 2.1681678654045187

Epoch: 5| Step: 2
Training loss: 1.4732211828231812
Validation loss: 2.149079289487613

Epoch: 5| Step: 3
Training loss: 1.476363182067871
Validation loss: 2.1191250419103973

Epoch: 5| Step: 4
Training loss: 1.9531053304672241
Validation loss: 2.1160362689725813

Epoch: 5| Step: 5
Training loss: 1.473616123199463
Validation loss: 2.166294185064172

Epoch: 5| Step: 6
Training loss: 1.6353915929794312
Validation loss: 2.139743648549562

Epoch: 5| Step: 7
Training loss: 1.614882469177246
Validation loss: 2.1931448341697775

Epoch: 5| Step: 8
Training loss: 1.3741964101791382
Validation loss: 2.1154054428941462

Epoch: 5| Step: 9
Training loss: 1.2716271877288818
Validation loss: 2.1435612440109253

Epoch: 5| Step: 10
Training loss: 2.299241065979004
Validation loss: 2.1403036937918714

Epoch: 406| Step: 0
Training loss: 1.8045543432235718
Validation loss: 2.1962212208778626

Epoch: 5| Step: 1
Training loss: 1.5588324069976807
Validation loss: 2.2327128815394577

Epoch: 5| Step: 2
Training loss: 2.154531955718994
Validation loss: 2.1527176723685315

Epoch: 5| Step: 3
Training loss: 1.3446868658065796
Validation loss: 2.1278498506033294

Epoch: 5| Step: 4
Training loss: 2.2189502716064453
Validation loss: 2.1188590590671827

Epoch: 5| Step: 5
Training loss: 1.1842982769012451
Validation loss: 2.1768074086917344

Epoch: 5| Step: 6
Training loss: 1.7404451370239258
Validation loss: 2.182343763689841

Epoch: 5| Step: 7
Training loss: 1.2090518474578857
Validation loss: 2.113957925509381

Epoch: 5| Step: 8
Training loss: 1.088809847831726
Validation loss: 2.1193773208125943

Epoch: 5| Step: 9
Training loss: 1.509303092956543
Validation loss: 2.1886545355601976

Epoch: 5| Step: 10
Training loss: 1.3851854801177979
Validation loss: 2.1704447859077045

Epoch: 407| Step: 0
Training loss: 1.5611165761947632
Validation loss: 2.178422899656398

Epoch: 5| Step: 1
Training loss: 1.5773576498031616
Validation loss: 2.1530310133452057

Epoch: 5| Step: 2
Training loss: 1.7813106775283813
Validation loss: 2.197636218481166

Epoch: 5| Step: 3
Training loss: 1.7908573150634766
Validation loss: 2.0827685389467465

Epoch: 5| Step: 4
Training loss: 0.983569324016571
Validation loss: 2.1523440371277514

Epoch: 5| Step: 5
Training loss: 2.1135001182556152
Validation loss: 2.1843208010478685

Epoch: 5| Step: 6
Training loss: 1.5143169164657593
Validation loss: 2.0709657438339724

Epoch: 5| Step: 7
Training loss: 1.2618420124053955
Validation loss: 2.142331615571053

Epoch: 5| Step: 8
Training loss: 1.710040807723999
Validation loss: 2.1162275601458806

Epoch: 5| Step: 9
Training loss: 1.7540394067764282
Validation loss: 2.104251689808343

Epoch: 5| Step: 10
Training loss: 1.2384835481643677
Validation loss: 2.1295015760647353

Epoch: 408| Step: 0
Training loss: 1.8405996561050415
Validation loss: 2.1581467223423783

Epoch: 5| Step: 1
Training loss: 0.9194285273551941
Validation loss: 2.1200133331360353

Epoch: 5| Step: 2
Training loss: 1.6460082530975342
Validation loss: 2.0928932582178423

Epoch: 5| Step: 3
Training loss: 1.8765958547592163
Validation loss: 2.079644524922935

Epoch: 5| Step: 4
Training loss: 1.239763617515564
Validation loss: 2.173353211854094

Epoch: 5| Step: 5
Training loss: 1.4625539779663086
Validation loss: 2.108435320597823

Epoch: 5| Step: 6
Training loss: 2.732714891433716
Validation loss: 2.168725239333286

Epoch: 5| Step: 7
Training loss: 1.1524887084960938
Validation loss: 2.1614026651587537

Epoch: 5| Step: 8
Training loss: 1.3429162502288818
Validation loss: 2.143439790253998

Epoch: 5| Step: 9
Training loss: 1.8918901681900024
Validation loss: 2.1420703203447404

Epoch: 5| Step: 10
Training loss: 1.2575470209121704
Validation loss: 2.1539197416715723

Epoch: 409| Step: 0
Training loss: 1.3834787607192993
Validation loss: 2.0881962442910798

Epoch: 5| Step: 1
Training loss: 1.1687811613082886
Validation loss: 2.1609825370132283

Epoch: 5| Step: 2
Training loss: 1.240295648574829
Validation loss: 2.1323872176549767

Epoch: 5| Step: 3
Training loss: 1.8360744714736938
Validation loss: 2.092802495084783

Epoch: 5| Step: 4
Training loss: 1.7689735889434814
Validation loss: 2.1562522175491496

Epoch: 5| Step: 5
Training loss: 1.5128501653671265
Validation loss: 2.1404948260194514

Epoch: 5| Step: 6
Training loss: 1.5514261722564697
Validation loss: 2.103576753729133

Epoch: 5| Step: 7
Training loss: 1.4135740995407104
Validation loss: 2.088768307880689

Epoch: 5| Step: 8
Training loss: 1.3686918020248413
Validation loss: 2.1231002922981017

Epoch: 5| Step: 9
Training loss: 2.25978422164917
Validation loss: 2.076919094208748

Epoch: 5| Step: 10
Training loss: 1.6150808334350586
Validation loss: 2.1380035082499185

Epoch: 410| Step: 0
Training loss: 1.0299509763717651
Validation loss: 2.131537711748513

Epoch: 5| Step: 1
Training loss: 1.4516254663467407
Validation loss: 2.133641930036647

Epoch: 5| Step: 2
Training loss: 1.170424222946167
Validation loss: 2.1161823836706017

Epoch: 5| Step: 3
Training loss: 2.008312463760376
Validation loss: 2.1619388134248796

Epoch: 5| Step: 4
Training loss: 1.6781721115112305
Validation loss: 2.1369925378471293

Epoch: 5| Step: 5
Training loss: 1.4252071380615234
Validation loss: 2.1589503570269515

Epoch: 5| Step: 6
Training loss: 1.6871492862701416
Validation loss: 2.140912817370507

Epoch: 5| Step: 7
Training loss: 1.123889684677124
Validation loss: 2.1639685092433805

Epoch: 5| Step: 8
Training loss: 2.097687244415283
Validation loss: 2.0940361125494844

Epoch: 5| Step: 9
Training loss: 1.8991286754608154
Validation loss: 2.129415919703822

Epoch: 5| Step: 10
Training loss: 1.966539740562439
Validation loss: 2.1672002500103367

Epoch: 411| Step: 0
Training loss: 1.576067566871643
Validation loss: 2.1294878810964604

Epoch: 5| Step: 1
Training loss: 1.8252290487289429
Validation loss: 2.125082867119902

Epoch: 5| Step: 2
Training loss: 1.8937276601791382
Validation loss: 2.1653145949045816

Epoch: 5| Step: 3
Training loss: 1.3320708274841309
Validation loss: 2.087071176498167

Epoch: 5| Step: 4
Training loss: 1.2330505847930908
Validation loss: 2.1296093822807394

Epoch: 5| Step: 5
Training loss: 1.3105779886245728
Validation loss: 2.114922683726075

Epoch: 5| Step: 6
Training loss: 1.9041181802749634
Validation loss: 2.137362628854731

Epoch: 5| Step: 7
Training loss: 1.6194190979003906
Validation loss: 2.098137653002175

Epoch: 5| Step: 8
Training loss: 2.043717861175537
Validation loss: 2.1131505761095273

Epoch: 5| Step: 9
Training loss: 1.00533127784729
Validation loss: 2.085252764404461

Epoch: 5| Step: 10
Training loss: 1.5381004810333252
Validation loss: 2.1541303550043414

Epoch: 412| Step: 0
Training loss: 1.6485445499420166
Validation loss: 2.1845963539615756

Epoch: 5| Step: 1
Training loss: 1.6702690124511719
Validation loss: 2.1588733555168234

Epoch: 5| Step: 2
Training loss: 1.188927173614502
Validation loss: 2.187995431243732

Epoch: 5| Step: 3
Training loss: 1.6198718547821045
Validation loss: 2.090203348026481

Epoch: 5| Step: 4
Training loss: 1.634637475013733
Validation loss: 2.159330798733619

Epoch: 5| Step: 5
Training loss: 1.841892957687378
Validation loss: 2.15102393011893

Epoch: 5| Step: 6
Training loss: 2.300025463104248
Validation loss: 2.153256716266755

Epoch: 5| Step: 7
Training loss: 1.396181344985962
Validation loss: 2.1418846948172456

Epoch: 5| Step: 8
Training loss: 1.8111006021499634
Validation loss: 2.121584910218434

Epoch: 5| Step: 9
Training loss: 1.0690789222717285
Validation loss: 2.146182652442686

Epoch: 5| Step: 10
Training loss: 1.3678631782531738
Validation loss: 2.175381455370175

Epoch: 413| Step: 0
Training loss: 1.1537307500839233
Validation loss: 2.164889099777386

Epoch: 5| Step: 1
Training loss: 1.323771595954895
Validation loss: 2.1946911068372827

Epoch: 5| Step: 2
Training loss: 1.341654658317566
Validation loss: 2.1364024377638295

Epoch: 5| Step: 3
Training loss: 1.9711902141571045
Validation loss: 2.0834222993543072

Epoch: 5| Step: 4
Training loss: 1.9174057245254517
Validation loss: 2.1634358462466987

Epoch: 5| Step: 5
Training loss: 1.5876152515411377
Validation loss: 2.1923054610529253

Epoch: 5| Step: 6
Training loss: 1.567699670791626
Validation loss: 2.1387967832626833

Epoch: 5| Step: 7
Training loss: 1.5418148040771484
Validation loss: 2.0930924338679158

Epoch: 5| Step: 8
Training loss: 1.4330295324325562
Validation loss: 2.1223656708194363

Epoch: 5| Step: 9
Training loss: 1.7893521785736084
Validation loss: 2.105570544478714

Epoch: 5| Step: 10
Training loss: 1.5542532205581665
Validation loss: 2.106944684059389

Epoch: 414| Step: 0
Training loss: 1.6902282238006592
Validation loss: 2.129780693720746

Epoch: 5| Step: 1
Training loss: 1.1521764993667603
Validation loss: 2.14873480924996

Epoch: 5| Step: 2
Training loss: 1.843714952468872
Validation loss: 2.1166430673291607

Epoch: 5| Step: 3
Training loss: 1.6726125478744507
Validation loss: 2.1365247003493772

Epoch: 5| Step: 4
Training loss: 1.7332872152328491
Validation loss: 2.109763527429232

Epoch: 5| Step: 5
Training loss: 1.352224349975586
Validation loss: 2.140991349374094

Epoch: 5| Step: 6
Training loss: 1.4960739612579346
Validation loss: 2.1697682078166673

Epoch: 5| Step: 7
Training loss: 1.4873046875
Validation loss: 2.090801723541752

Epoch: 5| Step: 8
Training loss: 1.3106056451797485
Validation loss: 2.1436936611770303

Epoch: 5| Step: 9
Training loss: 1.735350251197815
Validation loss: 2.1225675921286307

Epoch: 5| Step: 10
Training loss: 1.59148371219635
Validation loss: 2.1479094195109543

Epoch: 415| Step: 0
Training loss: 1.8247839212417603
Validation loss: 2.19703092369982

Epoch: 5| Step: 1
Training loss: 1.5139071941375732
Validation loss: 2.164629879818168

Epoch: 5| Step: 2
Training loss: 1.3475338220596313
Validation loss: 2.172547722375521

Epoch: 5| Step: 3
Training loss: 1.0285685062408447
Validation loss: 2.09013545128607

Epoch: 5| Step: 4
Training loss: 1.8703243732452393
Validation loss: 2.1624490778933287

Epoch: 5| Step: 5
Training loss: 1.698742151260376
Validation loss: 2.1486933385172198

Epoch: 5| Step: 6
Training loss: 1.8629268407821655
Validation loss: 2.1481061084296114

Epoch: 5| Step: 7
Training loss: 1.6645686626434326
Validation loss: 2.1389973804514897

Epoch: 5| Step: 8
Training loss: 1.4325640201568604
Validation loss: 2.116121369023477

Epoch: 5| Step: 9
Training loss: 1.3810925483703613
Validation loss: 2.1265767902456303

Epoch: 5| Step: 10
Training loss: 1.5627228021621704
Validation loss: 2.2070794079893377

Epoch: 416| Step: 0
Training loss: 0.7929331660270691
Validation loss: 2.147422993054954

Epoch: 5| Step: 1
Training loss: 1.9200372695922852
Validation loss: 2.13621856833017

Epoch: 5| Step: 2
Training loss: 1.6844040155410767
Validation loss: 2.1155373306684595

Epoch: 5| Step: 3
Training loss: 1.1784675121307373
Validation loss: 2.1530191283072195

Epoch: 5| Step: 4
Training loss: 2.374314785003662
Validation loss: 2.121620681978041

Epoch: 5| Step: 5
Training loss: 2.2103161811828613
Validation loss: 2.151015104786042

Epoch: 5| Step: 6
Training loss: 1.6623471975326538
Validation loss: 2.1192357565767024

Epoch: 5| Step: 7
Training loss: 1.0932590961456299
Validation loss: 2.162991290451378

Epoch: 5| Step: 8
Training loss: 1.5687310695648193
Validation loss: 2.136129876618744

Epoch: 5| Step: 9
Training loss: 1.2943518161773682
Validation loss: 2.1080593780804704

Epoch: 5| Step: 10
Training loss: 1.4248113632202148
Validation loss: 2.1265816201445875

Epoch: 417| Step: 0
Training loss: 1.5161802768707275
Validation loss: 2.108073344794653

Epoch: 5| Step: 1
Training loss: 2.145129680633545
Validation loss: 2.069520914426414

Epoch: 5| Step: 2
Training loss: 1.2274795770645142
Validation loss: 2.1198228854005055

Epoch: 5| Step: 3
Training loss: 1.8952457904815674
Validation loss: 2.132996725779708

Epoch: 5| Step: 4
Training loss: 1.4762872457504272
Validation loss: 2.179153475710141

Epoch: 5| Step: 5
Training loss: 1.994885802268982
Validation loss: 2.088006595129608

Epoch: 5| Step: 6
Training loss: 1.5637953281402588
Validation loss: 2.1588310759554625

Epoch: 5| Step: 7
Training loss: 1.2981846332550049
Validation loss: 2.1461130495994323

Epoch: 5| Step: 8
Training loss: 1.3484137058258057
Validation loss: 2.1275030284799556

Epoch: 5| Step: 9
Training loss: 1.106481909751892
Validation loss: 2.1565842192660094

Epoch: 5| Step: 10
Training loss: 1.50763738155365
Validation loss: 2.137254532947335

Epoch: 418| Step: 0
Training loss: 1.2362327575683594
Validation loss: 2.2084721467828237

Epoch: 5| Step: 1
Training loss: 1.5660978555679321
Validation loss: 2.1407192445570424

Epoch: 5| Step: 2
Training loss: 2.038069486618042
Validation loss: 2.1540709259689494

Epoch: 5| Step: 3
Training loss: 1.1206438541412354
Validation loss: 2.1215840052532893

Epoch: 5| Step: 4
Training loss: 1.4720678329467773
Validation loss: 2.1609000877667497

Epoch: 5| Step: 5
Training loss: 1.4778257608413696
Validation loss: 2.1260369952007006

Epoch: 5| Step: 6
Training loss: 1.753758192062378
Validation loss: 2.1140718383173787

Epoch: 5| Step: 7
Training loss: 1.1145750284194946
Validation loss: 2.13080624611147

Epoch: 5| Step: 8
Training loss: 1.3623192310333252
Validation loss: 2.1505416541971187

Epoch: 5| Step: 9
Training loss: 2.055649757385254
Validation loss: 2.147938541186753

Epoch: 5| Step: 10
Training loss: 1.781459093093872
Validation loss: 2.09763535376518

Epoch: 419| Step: 0
Training loss: 1.4626678228378296
Validation loss: 2.148286978403727

Epoch: 5| Step: 1
Training loss: 1.403871774673462
Validation loss: 2.1248199785909345

Epoch: 5| Step: 2
Training loss: 1.2965590953826904
Validation loss: 2.1061402187552503

Epoch: 5| Step: 3
Training loss: 1.739092469215393
Validation loss: 2.156372547149658

Epoch: 5| Step: 4
Training loss: 1.7517890930175781
Validation loss: 2.110247172335143

Epoch: 5| Step: 5
Training loss: 1.1018073558807373
Validation loss: 2.1046958918212564

Epoch: 5| Step: 6
Training loss: 1.749548316001892
Validation loss: 2.088661962939847

Epoch: 5| Step: 7
Training loss: 1.5293058156967163
Validation loss: 2.116187059751121

Epoch: 5| Step: 8
Training loss: 1.6475452184677124
Validation loss: 2.1742405045417046

Epoch: 5| Step: 9
Training loss: 1.866369605064392
Validation loss: 2.1894149895637267

Epoch: 5| Step: 10
Training loss: 1.2895689010620117
Validation loss: 2.149170224384595

Epoch: 420| Step: 0
Training loss: 1.7572931051254272
Validation loss: 2.165730143106112

Epoch: 5| Step: 1
Training loss: 2.1417336463928223
Validation loss: 2.1681044204260713

Epoch: 5| Step: 2
Training loss: 1.1594572067260742
Validation loss: 2.1708692735241306

Epoch: 5| Step: 3
Training loss: 1.0512466430664062
Validation loss: 2.110701222573557

Epoch: 5| Step: 4
Training loss: 1.4790712594985962
Validation loss: 2.087501759170204

Epoch: 5| Step: 5
Training loss: 1.1605619192123413
Validation loss: 2.1638770411091466

Epoch: 5| Step: 6
Training loss: 1.1744921207427979
Validation loss: 2.134792422735563

Epoch: 5| Step: 7
Training loss: 1.6605027914047241
Validation loss: 2.1077739166957077

Epoch: 5| Step: 8
Training loss: 1.1539323329925537
Validation loss: 2.0929870733650784

Epoch: 5| Step: 9
Training loss: 2.262026786804199
Validation loss: 2.140618165334066

Epoch: 5| Step: 10
Training loss: 1.6046916246414185
Validation loss: 2.147610572076613

Epoch: 421| Step: 0
Training loss: 1.189836025238037
Validation loss: 2.1024946038440993

Epoch: 5| Step: 1
Training loss: 1.8727340698242188
Validation loss: 2.146384382760653

Epoch: 5| Step: 2
Training loss: 1.748239278793335
Validation loss: 2.1729759029162827

Epoch: 5| Step: 3
Training loss: 1.2350480556488037
Validation loss: 2.146757894946683

Epoch: 5| Step: 4
Training loss: 1.372485637664795
Validation loss: 2.055685107425977

Epoch: 5| Step: 5
Training loss: 1.7370551824569702
Validation loss: 2.1230690069096063

Epoch: 5| Step: 6
Training loss: 1.8598957061767578
Validation loss: 2.097880939001678

Epoch: 5| Step: 7
Training loss: 1.0927650928497314
Validation loss: 2.1123733135961715

Epoch: 5| Step: 8
Training loss: 1.6480382680892944
Validation loss: 2.1412134324350665

Epoch: 5| Step: 9
Training loss: 1.83652663230896
Validation loss: 2.1274112450179232

Epoch: 5| Step: 10
Training loss: 1.308333396911621
Validation loss: 2.1509253645455964

Epoch: 422| Step: 0
Training loss: 1.0045191049575806
Validation loss: 2.122293039034772

Epoch: 5| Step: 1
Training loss: 0.8500934839248657
Validation loss: 2.1624735657886793

Epoch: 5| Step: 2
Training loss: 2.201807737350464
Validation loss: 2.124723801048853

Epoch: 5| Step: 3
Training loss: 1.4117952585220337
Validation loss: 2.096990693000055

Epoch: 5| Step: 4
Training loss: 1.1833994388580322
Validation loss: 2.1132648503908547

Epoch: 5| Step: 5
Training loss: 1.6940606832504272
Validation loss: 2.1368844534761164

Epoch: 5| Step: 6
Training loss: 1.7263673543930054
Validation loss: 2.0660355962732786

Epoch: 5| Step: 7
Training loss: 1.1290642023086548
Validation loss: 2.10925708534897

Epoch: 5| Step: 8
Training loss: 2.2002625465393066
Validation loss: 2.1298735359663605

Epoch: 5| Step: 9
Training loss: 1.2755106687545776
Validation loss: 2.119027063410769

Epoch: 5| Step: 10
Training loss: 1.9711158275604248
Validation loss: 2.0803305256751274

Epoch: 423| Step: 0
Training loss: 0.9821340441703796
Validation loss: 2.1609629918170232

Epoch: 5| Step: 1
Training loss: 1.3613463640213013
Validation loss: 2.1742521691065964

Epoch: 5| Step: 2
Training loss: 1.6209022998809814
Validation loss: 2.1384561369496007

Epoch: 5| Step: 3
Training loss: 1.6523911952972412
Validation loss: 2.155869863366568

Epoch: 5| Step: 4
Training loss: 1.0354864597320557
Validation loss: 2.1318768737136677

Epoch: 5| Step: 5
Training loss: 1.8117469549179077
Validation loss: 2.1645644813455562

Epoch: 5| Step: 6
Training loss: 1.336212158203125
Validation loss: 2.139580347204721

Epoch: 5| Step: 7
Training loss: 2.239269971847534
Validation loss: 2.1143029479570288

Epoch: 5| Step: 8
Training loss: 1.419274091720581
Validation loss: 2.1334123970359884

Epoch: 5| Step: 9
Training loss: 1.4426500797271729
Validation loss: 2.094817066705355

Epoch: 5| Step: 10
Training loss: 2.1000211238861084
Validation loss: 2.1111292685231855

Epoch: 424| Step: 0
Training loss: 1.4055719375610352
Validation loss: 2.130122776954405

Epoch: 5| Step: 1
Training loss: 1.3428319692611694
Validation loss: 2.1638262964064077

Epoch: 5| Step: 2
Training loss: 2.0819828510284424
Validation loss: 2.1326730020584597

Epoch: 5| Step: 3
Training loss: 1.372962236404419
Validation loss: 2.1069458582068004

Epoch: 5| Step: 4
Training loss: 1.951730728149414
Validation loss: 2.1098057992996706

Epoch: 5| Step: 5
Training loss: 1.6266906261444092
Validation loss: 2.0806429245138682

Epoch: 5| Step: 6
Training loss: 1.4506512880325317
Validation loss: 2.1899472052051174

Epoch: 5| Step: 7
Training loss: 1.2211594581604004
Validation loss: 2.1338029535867835

Epoch: 5| Step: 8
Training loss: 1.4224121570587158
Validation loss: 2.1455953198094524

Epoch: 5| Step: 9
Training loss: 1.4093196392059326
Validation loss: 2.148102193750361

Epoch: 5| Step: 10
Training loss: 1.735698938369751
Validation loss: 2.102634611950126

Epoch: 425| Step: 0
Training loss: 1.1562204360961914
Validation loss: 2.1030936215513494

Epoch: 5| Step: 1
Training loss: 1.3431625366210938
Validation loss: 2.1460001622476885

Epoch: 5| Step: 2
Training loss: 1.653699278831482
Validation loss: 2.1691992693049933

Epoch: 5| Step: 3
Training loss: 1.0915979146957397
Validation loss: 2.1271360279411398

Epoch: 5| Step: 4
Training loss: 2.2823309898376465
Validation loss: 2.144836641127063

Epoch: 5| Step: 5
Training loss: 1.2483338117599487
Validation loss: 2.193031035443788

Epoch: 5| Step: 6
Training loss: 1.6760133504867554
Validation loss: 2.1189745690232966

Epoch: 5| Step: 7
Training loss: 1.3674070835113525
Validation loss: 2.1722216631776545

Epoch: 5| Step: 8
Training loss: 1.3977713584899902
Validation loss: 2.164096907902789

Epoch: 5| Step: 9
Training loss: 1.5295010805130005
Validation loss: 2.182090172203638

Epoch: 5| Step: 10
Training loss: 1.8606573343276978
Validation loss: 2.1441627471677718

Epoch: 426| Step: 0
Training loss: 1.5799392461776733
Validation loss: 2.1472806507541287

Epoch: 5| Step: 1
Training loss: 1.609196424484253
Validation loss: 2.1451935729672833

Epoch: 5| Step: 2
Training loss: 1.6164909601211548
Validation loss: 2.134968473065284

Epoch: 5| Step: 3
Training loss: 0.965328574180603
Validation loss: 2.1890249765047463

Epoch: 5| Step: 4
Training loss: 1.5204819440841675
Validation loss: 2.1421193845810427

Epoch: 5| Step: 5
Training loss: 1.2504574060440063
Validation loss: 2.13401936715649

Epoch: 5| Step: 6
Training loss: 1.422441840171814
Validation loss: 2.120450635110178

Epoch: 5| Step: 7
Training loss: 1.5877480506896973
Validation loss: 2.162994477056688

Epoch: 5| Step: 8
Training loss: 1.5917341709136963
Validation loss: 2.125884431664662

Epoch: 5| Step: 9
Training loss: 1.3920462131500244
Validation loss: 2.1217446737391974

Epoch: 5| Step: 10
Training loss: 1.9892427921295166
Validation loss: 2.1209603971050632

Epoch: 427| Step: 0
Training loss: 1.7748444080352783
Validation loss: 2.0983436863909484

Epoch: 5| Step: 1
Training loss: 1.005059838294983
Validation loss: 2.1324377188118557

Epoch: 5| Step: 2
Training loss: 1.5759357213974
Validation loss: 2.1390377731733423

Epoch: 5| Step: 3
Training loss: 1.804882287979126
Validation loss: 2.121299046342091

Epoch: 5| Step: 4
Training loss: 1.0931994915008545
Validation loss: 2.183648065854144

Epoch: 5| Step: 5
Training loss: 1.2940146923065186
Validation loss: 2.141531564856088

Epoch: 5| Step: 6
Training loss: 1.6210248470306396
Validation loss: 2.1701454680453063

Epoch: 5| Step: 7
Training loss: 1.6101131439208984
Validation loss: 2.134627478097075

Epoch: 5| Step: 8
Training loss: 1.501842737197876
Validation loss: 2.1046884495724916

Epoch: 5| Step: 9
Training loss: 1.9205906391143799
Validation loss: 2.1459062048183974

Epoch: 5| Step: 10
Training loss: 1.3456754684448242
Validation loss: 2.1541155333160074

Epoch: 428| Step: 0
Training loss: 1.2419579029083252
Validation loss: 2.1433463070982244

Epoch: 5| Step: 1
Training loss: 1.5755317211151123
Validation loss: 2.1312669297700286

Epoch: 5| Step: 2
Training loss: 1.2806459665298462
Validation loss: 2.1528808198949343

Epoch: 5| Step: 3
Training loss: 1.7587740421295166
Validation loss: 2.118730015652154

Epoch: 5| Step: 4
Training loss: 1.3670181035995483
Validation loss: 2.1359111955088954

Epoch: 5| Step: 5
Training loss: 1.2651989459991455
Validation loss: 2.183968783706747

Epoch: 5| Step: 6
Training loss: 1.9107745885849
Validation loss: 2.090303700457337

Epoch: 5| Step: 7
Training loss: 2.1247572898864746
Validation loss: 2.120298900911885

Epoch: 5| Step: 8
Training loss: 1.1319166421890259
Validation loss: 2.1271582880327777

Epoch: 5| Step: 9
Training loss: 1.9352247714996338
Validation loss: 2.113776332588606

Epoch: 5| Step: 10
Training loss: 1.3933566808700562
Validation loss: 2.111583322607061

Epoch: 429| Step: 0
Training loss: 2.494603157043457
Validation loss: 2.126184002045662

Epoch: 5| Step: 1
Training loss: 1.3059266805648804
Validation loss: 2.1112233592617895

Epoch: 5| Step: 2
Training loss: 1.3630950450897217
Validation loss: 2.144423550175082

Epoch: 5| Step: 3
Training loss: 2.033827543258667
Validation loss: 2.1652341991342525

Epoch: 5| Step: 4
Training loss: 1.4517138004302979
Validation loss: 2.137631262502363

Epoch: 5| Step: 5
Training loss: 1.2686474323272705
Validation loss: 2.12119702113572

Epoch: 5| Step: 6
Training loss: 1.899675726890564
Validation loss: 2.181276459847727

Epoch: 5| Step: 7
Training loss: 1.129692554473877
Validation loss: 2.1621308301084783

Epoch: 5| Step: 8
Training loss: 1.0448906421661377
Validation loss: 2.161477627292756

Epoch: 5| Step: 9
Training loss: 1.1200745105743408
Validation loss: 2.1190540636739423

Epoch: 5| Step: 10
Training loss: 1.5181821584701538
Validation loss: 2.082993079257268

Epoch: 430| Step: 0
Training loss: 1.629193902015686
Validation loss: 2.1293114769843315

Epoch: 5| Step: 1
Training loss: 1.5946934223175049
Validation loss: 2.1037210059422318

Epoch: 5| Step: 2
Training loss: 1.959558129310608
Validation loss: 2.159867972455999

Epoch: 5| Step: 3
Training loss: 1.3951722383499146
Validation loss: 2.099415527876987

Epoch: 5| Step: 4
Training loss: 0.8928940892219543
Validation loss: 2.122407792716898

Epoch: 5| Step: 5
Training loss: 1.8864437341690063
Validation loss: 2.128316802363242

Epoch: 5| Step: 6
Training loss: 1.0413486957550049
Validation loss: 2.1192583935235136

Epoch: 5| Step: 7
Training loss: 1.8204530477523804
Validation loss: 2.169684383176988

Epoch: 5| Step: 8
Training loss: 1.5075819492340088
Validation loss: 2.1468320354338615

Epoch: 5| Step: 9
Training loss: 1.6012117862701416
Validation loss: 2.1123513662686912

Epoch: 5| Step: 10
Training loss: 1.2151495218276978
Validation loss: 2.1349436698421353

Epoch: 431| Step: 0
Training loss: 1.707964539527893
Validation loss: 2.1190447499675136

Epoch: 5| Step: 1
Training loss: 1.777484655380249
Validation loss: 2.1247481569167106

Epoch: 5| Step: 2
Training loss: 1.397573709487915
Validation loss: 2.1643325090408325

Epoch: 5| Step: 3
Training loss: 1.8440086841583252
Validation loss: 2.1190085129071305

Epoch: 5| Step: 4
Training loss: 1.3625246286392212
Validation loss: 2.1164886233627156

Epoch: 5| Step: 5
Training loss: 1.3107291460037231
Validation loss: 2.111159901465139

Epoch: 5| Step: 6
Training loss: 1.5190470218658447
Validation loss: 2.1917265230609524

Epoch: 5| Step: 7
Training loss: 1.2078694105148315
Validation loss: 2.155492531355991

Epoch: 5| Step: 8
Training loss: 1.3529057502746582
Validation loss: 2.176179101390223

Epoch: 5| Step: 9
Training loss: 1.5938841104507446
Validation loss: 2.1762181546098445

Epoch: 5| Step: 10
Training loss: 1.3599653244018555
Validation loss: 2.121617547927364

Epoch: 432| Step: 0
Training loss: 1.3809736967086792
Validation loss: 2.1374259046328965

Epoch: 5| Step: 1
Training loss: 1.3429219722747803
Validation loss: 2.097741083432269

Epoch: 5| Step: 2
Training loss: 1.3763213157653809
Validation loss: 2.070051016346101

Epoch: 5| Step: 3
Training loss: 2.097386360168457
Validation loss: 2.1282744548654042

Epoch: 5| Step: 4
Training loss: 1.3807942867279053
Validation loss: 2.1385314541478313

Epoch: 5| Step: 5
Training loss: 1.7531073093414307
Validation loss: 2.0926178988590034

Epoch: 5| Step: 6
Training loss: 1.783399224281311
Validation loss: 2.0881344759336082

Epoch: 5| Step: 7
Training loss: 1.1127026081085205
Validation loss: 2.1653624529479654

Epoch: 5| Step: 8
Training loss: 1.737919569015503
Validation loss: 2.1705269736628376

Epoch: 5| Step: 9
Training loss: 1.011420488357544
Validation loss: 2.137740819684921

Epoch: 5| Step: 10
Training loss: 1.6731417179107666
Validation loss: 2.170694979288245

Epoch: 433| Step: 0
Training loss: 1.5659457445144653
Validation loss: 2.128230417928388

Epoch: 5| Step: 1
Training loss: 1.5224816799163818
Validation loss: 2.105234726782768

Epoch: 5| Step: 2
Training loss: 1.361033320426941
Validation loss: 2.1155704054781186

Epoch: 5| Step: 3
Training loss: 1.4095216989517212
Validation loss: 2.1588118960780482

Epoch: 5| Step: 4
Training loss: 1.0644909143447876
Validation loss: 2.149542291959127

Epoch: 5| Step: 5
Training loss: 1.9159990549087524
Validation loss: 2.1299642990994196

Epoch: 5| Step: 6
Training loss: 2.1266698837280273
Validation loss: 2.1676594441936863

Epoch: 5| Step: 7
Training loss: 1.3169097900390625
Validation loss: 2.1339043237829722

Epoch: 5| Step: 8
Training loss: 1.5385485887527466
Validation loss: 2.1348312157456593

Epoch: 5| Step: 9
Training loss: 1.2096532583236694
Validation loss: 2.173889042228781

Epoch: 5| Step: 10
Training loss: 1.6109724044799805
Validation loss: 2.1415110967492543

Epoch: 434| Step: 0
Training loss: 1.2617435455322266
Validation loss: 2.091051842576714

Epoch: 5| Step: 1
Training loss: 1.5212680101394653
Validation loss: 2.145985021386095

Epoch: 5| Step: 2
Training loss: 1.993825912475586
Validation loss: 2.127969721312164

Epoch: 5| Step: 3
Training loss: 1.7722126245498657
Validation loss: 2.1574210569422734

Epoch: 5| Step: 4
Training loss: 1.2980787754058838
Validation loss: 2.1620444161917574

Epoch: 5| Step: 5
Training loss: 1.3533622026443481
Validation loss: 2.1115083925185667

Epoch: 5| Step: 6
Training loss: 1.6990153789520264
Validation loss: 2.1496436185734247

Epoch: 5| Step: 7
Training loss: 1.680556297302246
Validation loss: 2.1560544557468866

Epoch: 5| Step: 8
Training loss: 1.873924970626831
Validation loss: 2.202113328441497

Epoch: 5| Step: 9
Training loss: 0.9615063667297363
Validation loss: 2.1166553138404764

Epoch: 5| Step: 10
Training loss: 1.0102875232696533
Validation loss: 2.1207935297360985

Epoch: 435| Step: 0
Training loss: 1.9446346759796143
Validation loss: 2.129753485802681

Epoch: 5| Step: 1
Training loss: 1.0115469694137573
Validation loss: 2.116658144099738

Epoch: 5| Step: 2
Training loss: 1.1060854196548462
Validation loss: 2.1416294164555048

Epoch: 5| Step: 3
Training loss: 1.1142574548721313
Validation loss: 2.160753902568612

Epoch: 5| Step: 4
Training loss: 2.1025102138519287
Validation loss: 2.129396620617118

Epoch: 5| Step: 5
Training loss: 1.2156215906143188
Validation loss: 2.1742435655286236

Epoch: 5| Step: 6
Training loss: 1.1935311555862427
Validation loss: 2.1148949528253205

Epoch: 5| Step: 7
Training loss: 2.224524974822998
Validation loss: 2.142595480847102

Epoch: 5| Step: 8
Training loss: 1.2616344690322876
Validation loss: 2.1960314499434603

Epoch: 5| Step: 9
Training loss: 1.7808961868286133
Validation loss: 2.1292512109202724

Epoch: 5| Step: 10
Training loss: 1.7243107557296753
Validation loss: 2.1500965908009517

Epoch: 436| Step: 0
Training loss: 0.9939498901367188
Validation loss: 2.1410354991112985

Epoch: 5| Step: 1
Training loss: 1.8656562566757202
Validation loss: 2.1500457294525637

Epoch: 5| Step: 2
Training loss: 1.2889541387557983
Validation loss: 2.140719288138933

Epoch: 5| Step: 3
Training loss: 1.4871470928192139
Validation loss: 2.1548485012464624

Epoch: 5| Step: 4
Training loss: 1.575457215309143
Validation loss: 2.0987828239317863

Epoch: 5| Step: 5
Training loss: 1.882473349571228
Validation loss: 2.0738774435494536

Epoch: 5| Step: 6
Training loss: 1.0032540559768677
Validation loss: 2.095910886282562

Epoch: 5| Step: 7
Training loss: 1.5076334476470947
Validation loss: 2.132010353508816

Epoch: 5| Step: 8
Training loss: 1.8662307262420654
Validation loss: 2.091579738483634

Epoch: 5| Step: 9
Training loss: 1.8191581964492798
Validation loss: 2.1257137713893766

Epoch: 5| Step: 10
Training loss: 1.1576123237609863
Validation loss: 2.149799580215126

Epoch: 437| Step: 0
Training loss: 1.3278403282165527
Validation loss: 2.144278568606223

Epoch: 5| Step: 1
Training loss: 1.5554951429367065
Validation loss: 2.1672237432131203

Epoch: 5| Step: 2
Training loss: 1.3196293115615845
Validation loss: 2.1532905870868313

Epoch: 5| Step: 3
Training loss: 2.1299777030944824
Validation loss: 2.167425917040917

Epoch: 5| Step: 4
Training loss: 1.974876046180725
Validation loss: 2.13358122815368

Epoch: 5| Step: 5
Training loss: 1.1869096755981445
Validation loss: 2.1496138675238496

Epoch: 5| Step: 6
Training loss: 1.3406071662902832
Validation loss: 2.1548497112848426

Epoch: 5| Step: 7
Training loss: 1.4714040756225586
Validation loss: 2.1241319820445073

Epoch: 5| Step: 8
Training loss: 1.3712081909179688
Validation loss: 2.1222568173562326

Epoch: 5| Step: 9
Training loss: 1.1943854093551636
Validation loss: 2.1489778500731274

Epoch: 5| Step: 10
Training loss: 1.8178606033325195
Validation loss: 2.166614629889047

Epoch: 438| Step: 0
Training loss: 1.383500099182129
Validation loss: 2.1671113326985347

Epoch: 5| Step: 1
Training loss: 1.8570878505706787
Validation loss: 2.131976271188387

Epoch: 5| Step: 2
Training loss: 1.6990587711334229
Validation loss: 2.157750045099566

Epoch: 5| Step: 3
Training loss: 1.7001873254776
Validation loss: 2.1003615907443467

Epoch: 5| Step: 4
Training loss: 1.6101150512695312
Validation loss: 2.171238383939189

Epoch: 5| Step: 5
Training loss: 1.105799913406372
Validation loss: 2.1158737213380876

Epoch: 5| Step: 6
Training loss: 1.281002402305603
Validation loss: 2.1585532490925123

Epoch: 5| Step: 7
Training loss: 1.1956884860992432
Validation loss: 2.1138765760647353

Epoch: 5| Step: 8
Training loss: 1.4392187595367432
Validation loss: 2.134743041889642

Epoch: 5| Step: 9
Training loss: 1.919255018234253
Validation loss: 2.2089791515822053

Epoch: 5| Step: 10
Training loss: 0.9650133848190308
Validation loss: 2.1330848329810688

Epoch: 439| Step: 0
Training loss: 2.310823917388916
Validation loss: 2.122610330581665

Epoch: 5| Step: 1
Training loss: 1.5897186994552612
Validation loss: 2.1550756218612834

Epoch: 5| Step: 2
Training loss: 1.0322229862213135
Validation loss: 2.132179223081117

Epoch: 5| Step: 3
Training loss: 1.6787538528442383
Validation loss: 2.1310316952325965

Epoch: 5| Step: 4
Training loss: 2.080040454864502
Validation loss: 2.091726674828478

Epoch: 5| Step: 5
Training loss: 0.8477856516838074
Validation loss: 2.1310993702180925

Epoch: 5| Step: 6
Training loss: 1.39593505859375
Validation loss: 2.1459042077423423

Epoch: 5| Step: 7
Training loss: 1.0751787424087524
Validation loss: 2.1029302586791334

Epoch: 5| Step: 8
Training loss: 1.4060719013214111
Validation loss: 2.1129449618759977

Epoch: 5| Step: 9
Training loss: 1.4718542098999023
Validation loss: 2.088791649828675

Epoch: 5| Step: 10
Training loss: 1.7065892219543457
Validation loss: 2.087484500741446

Epoch: 440| Step: 0
Training loss: 1.014007806777954
Validation loss: 2.1290780933954383

Epoch: 5| Step: 1
Training loss: 1.476477026939392
Validation loss: 2.139726323466147

Epoch: 5| Step: 2
Training loss: 2.2552807331085205
Validation loss: 2.1073314553947857

Epoch: 5| Step: 3
Training loss: 1.4300355911254883
Validation loss: 2.1277136623218493

Epoch: 5| Step: 4
Training loss: 1.3060764074325562
Validation loss: 2.1668961548036143

Epoch: 5| Step: 5
Training loss: 1.3571418523788452
Validation loss: 2.164751491238994

Epoch: 5| Step: 6
Training loss: 1.5293033123016357
Validation loss: 2.1088842268913024

Epoch: 5| Step: 7
Training loss: 1.1697375774383545
Validation loss: 2.160059331565775

Epoch: 5| Step: 8
Training loss: 1.1022248268127441
Validation loss: 2.204103244248257

Epoch: 5| Step: 9
Training loss: 1.8032348155975342
Validation loss: 2.1957623984224055

Epoch: 5| Step: 10
Training loss: 1.7204327583312988
Validation loss: 2.2002682532033613

Epoch: 441| Step: 0
Training loss: 1.8111547231674194
Validation loss: 2.1269821889938845

Epoch: 5| Step: 1
Training loss: 1.7276904582977295
Validation loss: 2.135940199257225

Epoch: 5| Step: 2
Training loss: 1.2342733144760132
Validation loss: 2.1520390651559316

Epoch: 5| Step: 3
Training loss: 1.980503797531128
Validation loss: 2.176994877476846

Epoch: 5| Step: 4
Training loss: 1.5197824239730835
Validation loss: 2.1822102992765364

Epoch: 5| Step: 5
Training loss: 1.6864259243011475
Validation loss: 2.1567518300907587

Epoch: 5| Step: 6
Training loss: 1.1359660625457764
Validation loss: 2.1606607821679886

Epoch: 5| Step: 7
Training loss: 1.0926488637924194
Validation loss: 2.138218492589971

Epoch: 5| Step: 8
Training loss: 1.6077892780303955
Validation loss: 2.143624608234693

Epoch: 5| Step: 9
Training loss: 1.5750706195831299
Validation loss: 2.131448766236664

Epoch: 5| Step: 10
Training loss: 1.0427840948104858
Validation loss: 2.1622418383116364

Epoch: 442| Step: 0
Training loss: 1.408819556236267
Validation loss: 2.128280319193358

Epoch: 5| Step: 1
Training loss: 1.2448769807815552
Validation loss: 2.1207719361910256

Epoch: 5| Step: 2
Training loss: 1.3214976787567139
Validation loss: 2.1533544550659838

Epoch: 5| Step: 3
Training loss: 2.2164461612701416
Validation loss: 2.128261873798986

Epoch: 5| Step: 4
Training loss: 1.1655158996582031
Validation loss: 2.0780958475605136

Epoch: 5| Step: 5
Training loss: 1.6359796524047852
Validation loss: 2.2023632603306926

Epoch: 5| Step: 6
Training loss: 1.0527204275131226
Validation loss: 2.087384106010519

Epoch: 5| Step: 7
Training loss: 1.7829859256744385
Validation loss: 2.1393291693861767

Epoch: 5| Step: 8
Training loss: 1.826789140701294
Validation loss: 2.1241723081117034

Epoch: 5| Step: 9
Training loss: 1.3486297130584717
Validation loss: 2.122631908744894

Epoch: 5| Step: 10
Training loss: 1.0829588174819946
Validation loss: 2.175672725964618

Epoch: 443| Step: 0
Training loss: 1.487554669380188
Validation loss: 2.115175267701508

Epoch: 5| Step: 1
Training loss: 1.2364054918289185
Validation loss: 2.121576122058335

Epoch: 5| Step: 2
Training loss: 1.2885971069335938
Validation loss: 2.119967637523528

Epoch: 5| Step: 3
Training loss: 1.5750185251235962
Validation loss: 2.150439346990278

Epoch: 5| Step: 4
Training loss: 1.596006155014038
Validation loss: 2.115962695049983

Epoch: 5| Step: 5
Training loss: 1.1917307376861572
Validation loss: 2.161911415797408

Epoch: 5| Step: 6
Training loss: 1.9161955118179321
Validation loss: 2.0785446795084144

Epoch: 5| Step: 7
Training loss: 1.1528139114379883
Validation loss: 2.1582958057362545

Epoch: 5| Step: 8
Training loss: 1.3853018283843994
Validation loss: 2.121810987431516

Epoch: 5| Step: 9
Training loss: 1.772253394126892
Validation loss: 2.1227578578456754

Epoch: 5| Step: 10
Training loss: 1.713976502418518
Validation loss: 2.0881158767207975

Epoch: 444| Step: 0
Training loss: 1.8476455211639404
Validation loss: 2.140740966284147

Epoch: 5| Step: 1
Training loss: 1.7312930822372437
Validation loss: 2.1372799745170017

Epoch: 5| Step: 2
Training loss: 1.5347163677215576
Validation loss: 2.110114392413888

Epoch: 5| Step: 3
Training loss: 1.1630834341049194
Validation loss: 2.173182237532831

Epoch: 5| Step: 4
Training loss: 1.731783151626587
Validation loss: 2.149158772601876

Epoch: 5| Step: 5
Training loss: 1.612443208694458
Validation loss: 2.083553837191674

Epoch: 5| Step: 6
Training loss: 1.8965513706207275
Validation loss: 2.0863260992111696

Epoch: 5| Step: 7
Training loss: 1.133215308189392
Validation loss: 2.1765810828055105

Epoch: 5| Step: 8
Training loss: 1.3382552862167358
Validation loss: 2.1070120590989307

Epoch: 5| Step: 9
Training loss: 1.6141059398651123
Validation loss: 2.1223236078857095

Epoch: 5| Step: 10
Training loss: 0.9503828883171082
Validation loss: 2.0805683366713987

Epoch: 445| Step: 0
Training loss: 1.7953670024871826
Validation loss: 2.124670964415355

Epoch: 5| Step: 1
Training loss: 1.6647493839263916
Validation loss: 2.1543877483696066

Epoch: 5| Step: 2
Training loss: 1.4544494152069092
Validation loss: 2.1003226567340154

Epoch: 5| Step: 3
Training loss: 1.2283543348312378
Validation loss: 2.15314995345249

Epoch: 5| Step: 4
Training loss: 1.9070647954940796
Validation loss: 2.166568661248812

Epoch: 5| Step: 5
Training loss: 1.6207339763641357
Validation loss: 2.1147032322422152

Epoch: 5| Step: 6
Training loss: 1.3128445148468018
Validation loss: 2.1491336053417576

Epoch: 5| Step: 7
Training loss: 1.3183603286743164
Validation loss: 2.1078126917603197

Epoch: 5| Step: 8
Training loss: 1.3420040607452393
Validation loss: 2.0753658971478863

Epoch: 5| Step: 9
Training loss: 1.040818214416504
Validation loss: 2.1574634839129705

Epoch: 5| Step: 10
Training loss: 1.831067681312561
Validation loss: 2.114895671926519

Epoch: 446| Step: 0
Training loss: 1.6745588779449463
Validation loss: 2.1405491931464082

Epoch: 5| Step: 1
Training loss: 1.468004584312439
Validation loss: 2.167596055615333

Epoch: 5| Step: 2
Training loss: 1.1440742015838623
Validation loss: 2.1411755110627864

Epoch: 5| Step: 3
Training loss: 1.875207543373108
Validation loss: 2.1128309311405307

Epoch: 5| Step: 4
Training loss: 1.0649659633636475
Validation loss: 2.124655439007667

Epoch: 5| Step: 5
Training loss: 2.0406670570373535
Validation loss: 2.098770841475456

Epoch: 5| Step: 6
Training loss: 1.3121082782745361
Validation loss: 2.134855601095384

Epoch: 5| Step: 7
Training loss: 1.1533597707748413
Validation loss: 2.120050416197828

Epoch: 5| Step: 8
Training loss: 1.6587718725204468
Validation loss: 2.1415628181990756

Epoch: 5| Step: 9
Training loss: 1.2443201541900635
Validation loss: 2.1638589546244633

Epoch: 5| Step: 10
Training loss: 1.5809355974197388
Validation loss: 2.1415165393583235

Epoch: 447| Step: 0
Training loss: 1.1300818920135498
Validation loss: 2.076712764719481

Epoch: 5| Step: 1
Training loss: 1.4776275157928467
Validation loss: 2.1563726112406743

Epoch: 5| Step: 2
Training loss: 0.9866467714309692
Validation loss: 2.1508583330339

Epoch: 5| Step: 3
Training loss: 1.2351315021514893
Validation loss: 2.1294338151972783

Epoch: 5| Step: 4
Training loss: 1.7790616750717163
Validation loss: 2.116467652782317

Epoch: 5| Step: 5
Training loss: 1.323377251625061
Validation loss: 2.174471370635494

Epoch: 5| Step: 6
Training loss: 2.1293067932128906
Validation loss: 2.138219893619578

Epoch: 5| Step: 7
Training loss: 1.6616729497909546
Validation loss: 2.1691187350980696

Epoch: 5| Step: 8
Training loss: 1.1662405729293823
Validation loss: 2.183721083466725

Epoch: 5| Step: 9
Training loss: 1.4257968664169312
Validation loss: 2.178700372736941

Epoch: 5| Step: 10
Training loss: 2.2492542266845703
Validation loss: 2.1578395981942453

Epoch: 448| Step: 0
Training loss: 1.2164617776870728
Validation loss: 2.143408380528932

Epoch: 5| Step: 1
Training loss: 1.565314531326294
Validation loss: 2.112189298034996

Epoch: 5| Step: 2
Training loss: 2.103820323944092
Validation loss: 2.1571999185828754

Epoch: 5| Step: 3
Training loss: 0.7872607111930847
Validation loss: 2.139598059397872

Epoch: 5| Step: 4
Training loss: 1.797236680984497
Validation loss: 2.146006426503581

Epoch: 5| Step: 5
Training loss: 2.111018657684326
Validation loss: 2.1582584701558596

Epoch: 5| Step: 6
Training loss: 1.417175531387329
Validation loss: 2.1128464283481723

Epoch: 5| Step: 7
Training loss: 1.6481930017471313
Validation loss: 2.1363142485259683

Epoch: 5| Step: 8
Training loss: 1.2784587144851685
Validation loss: 2.098137337674377

Epoch: 5| Step: 9
Training loss: 1.0588710308074951
Validation loss: 2.1286038224415114

Epoch: 5| Step: 10
Training loss: 1.4718378782272339
Validation loss: 2.1155623338555776

Epoch: 449| Step: 0
Training loss: 1.1761258840560913
Validation loss: 2.1140154382233978

Epoch: 5| Step: 1
Training loss: 1.482682466506958
Validation loss: 2.130711352953347

Epoch: 5| Step: 2
Training loss: 1.7117799520492554
Validation loss: 2.135569196875377

Epoch: 5| Step: 3
Training loss: 1.6303380727767944
Validation loss: 2.1094316897853727

Epoch: 5| Step: 4
Training loss: 1.1461703777313232
Validation loss: 2.029088540743756

Epoch: 5| Step: 5
Training loss: 1.5773875713348389
Validation loss: 2.1611302232229583

Epoch: 5| Step: 6
Training loss: 1.4486157894134521
Validation loss: 2.106048325056671

Epoch: 5| Step: 7
Training loss: 1.2926645278930664
Validation loss: 2.130620630838538

Epoch: 5| Step: 8
Training loss: 1.7755438089370728
Validation loss: 2.1118859757659254

Epoch: 5| Step: 9
Training loss: 1.585626482963562
Validation loss: 2.1220649365455873

Epoch: 5| Step: 10
Training loss: 1.2681740522384644
Validation loss: 2.090437376370994

Epoch: 450| Step: 0
Training loss: 1.3592493534088135
Validation loss: 2.165718311904579

Epoch: 5| Step: 1
Training loss: 1.376522183418274
Validation loss: 2.131501668242998

Epoch: 5| Step: 2
Training loss: 1.606000304222107
Validation loss: 2.101870062530682

Epoch: 5| Step: 3
Training loss: 1.3383417129516602
Validation loss: 2.1216458594927223

Epoch: 5| Step: 4
Training loss: 1.5185883045196533
Validation loss: 2.0862153435266144

Epoch: 5| Step: 5
Training loss: 1.248985767364502
Validation loss: 2.123705369169994

Epoch: 5| Step: 6
Training loss: 1.7517204284667969
Validation loss: 2.1745566962867655

Epoch: 5| Step: 7
Training loss: 1.894046425819397
Validation loss: 2.172304432879212

Epoch: 5| Step: 8
Training loss: 1.6541328430175781
Validation loss: 2.072909673055013

Epoch: 5| Step: 9
Training loss: 1.372635006904602
Validation loss: 2.100950943526401

Epoch: 5| Step: 10
Training loss: 1.3687607049942017
Validation loss: 2.1159079741406184

Epoch: 451| Step: 0
Training loss: 0.9560244679450989
Validation loss: 2.080418175266635

Epoch: 5| Step: 1
Training loss: 1.740319848060608
Validation loss: 2.0309599138075307

Epoch: 5| Step: 2
Training loss: 1.8536245822906494
Validation loss: 2.0695017794127106

Epoch: 5| Step: 3
Training loss: 1.6056478023529053
Validation loss: 2.140873675705284

Epoch: 5| Step: 4
Training loss: 1.6278871297836304
Validation loss: 2.1031731956748554

Epoch: 5| Step: 5
Training loss: 1.1996127367019653
Validation loss: 2.18023193523448

Epoch: 5| Step: 6
Training loss: 1.0035946369171143
Validation loss: 2.1410083847661174

Epoch: 5| Step: 7
Training loss: 1.5279872417449951
Validation loss: 2.174341937547089

Epoch: 5| Step: 8
Training loss: 1.625885248184204
Validation loss: 2.127306365197705

Epoch: 5| Step: 9
Training loss: 1.6372630596160889
Validation loss: 2.1373554916792017

Epoch: 5| Step: 10
Training loss: 1.6990158557891846
Validation loss: 2.1453990115914294

Epoch: 452| Step: 0
Training loss: 1.0435994863510132
Validation loss: 2.1278356608524116

Epoch: 5| Step: 1
Training loss: 1.6152172088623047
Validation loss: 2.1193944126047115

Epoch: 5| Step: 2
Training loss: 1.1690528392791748
Validation loss: 2.1868728745368218

Epoch: 5| Step: 3
Training loss: 1.2536636590957642
Validation loss: 2.1299160142098703

Epoch: 5| Step: 4
Training loss: 1.9627254009246826
Validation loss: 2.1388399075436335

Epoch: 5| Step: 5
Training loss: 1.4904839992523193
Validation loss: 2.135164257018797

Epoch: 5| Step: 6
Training loss: 1.0183817148208618
Validation loss: 2.14154173738213

Epoch: 5| Step: 7
Training loss: 2.0984280109405518
Validation loss: 2.129368548752159

Epoch: 5| Step: 8
Training loss: 1.769122838973999
Validation loss: 2.184125707995507

Epoch: 5| Step: 9
Training loss: 1.1659307479858398
Validation loss: 2.1606418958274265

Epoch: 5| Step: 10
Training loss: 1.2974047660827637
Validation loss: 2.12640219606379

Epoch: 453| Step: 0
Training loss: 1.507785439491272
Validation loss: 2.0937008114271265

Epoch: 5| Step: 1
Training loss: 1.6202274560928345
Validation loss: 2.096929011806365

Epoch: 5| Step: 2
Training loss: 1.1797434091567993
Validation loss: 2.1283642322786394

Epoch: 5| Step: 3
Training loss: 1.6713275909423828
Validation loss: 2.1198475822325675

Epoch: 5| Step: 4
Training loss: 1.507555603981018
Validation loss: 2.126259619189847

Epoch: 5| Step: 5
Training loss: 0.8455488085746765
Validation loss: 2.0943084865488033

Epoch: 5| Step: 6
Training loss: 1.5155194997787476
Validation loss: 2.158108725342699

Epoch: 5| Step: 7
Training loss: 1.499276876449585
Validation loss: 2.1278249807255243

Epoch: 5| Step: 8
Training loss: 1.333823561668396
Validation loss: 2.105728316050704

Epoch: 5| Step: 9
Training loss: 1.8991057872772217
Validation loss: 2.1594027549989763

Epoch: 5| Step: 10
Training loss: 1.6219302415847778
Validation loss: 2.133807643767326

Epoch: 454| Step: 0
Training loss: 1.4735966920852661
Validation loss: 2.1466579821801957

Epoch: 5| Step: 1
Training loss: 1.5591984987258911
Validation loss: 2.1090992330223

Epoch: 5| Step: 2
Training loss: 1.1219050884246826
Validation loss: 2.1282221245509323

Epoch: 5| Step: 3
Training loss: 1.269709825515747
Validation loss: 2.1407554611083

Epoch: 5| Step: 4
Training loss: 1.7217060327529907
Validation loss: 2.100187927164057

Epoch: 5| Step: 5
Training loss: 1.1251071691513062
Validation loss: 2.1573383321044264

Epoch: 5| Step: 6
Training loss: 1.4357972145080566
Validation loss: 2.0844645346364667

Epoch: 5| Step: 7
Training loss: 1.3861745595932007
Validation loss: 2.152449405321511

Epoch: 5| Step: 8
Training loss: 1.6331024169921875
Validation loss: 2.1444484290256294

Epoch: 5| Step: 9
Training loss: 1.4667197465896606
Validation loss: 2.144295761662145

Epoch: 5| Step: 10
Training loss: 2.0632781982421875
Validation loss: 2.1588288558426725

Epoch: 455| Step: 0
Training loss: 1.9403820037841797
Validation loss: 2.156175910785634

Epoch: 5| Step: 1
Training loss: 1.2507892847061157
Validation loss: 2.1166738156349427

Epoch: 5| Step: 2
Training loss: 1.8292261362075806
Validation loss: 2.1432897506221646

Epoch: 5| Step: 3
Training loss: 1.8767286539077759
Validation loss: 2.1241693983795824

Epoch: 5| Step: 4
Training loss: 1.659996747970581
Validation loss: 2.1085014368898127

Epoch: 5| Step: 5
Training loss: 1.4677345752716064
Validation loss: 2.1711831951654084

Epoch: 5| Step: 6
Training loss: 1.2439979314804077
Validation loss: 2.0812997407810663

Epoch: 5| Step: 7
Training loss: 1.2313706874847412
Validation loss: 2.1391691418104273

Epoch: 5| Step: 8
Training loss: 1.4056644439697266
Validation loss: 2.104730208714803

Epoch: 5| Step: 9
Training loss: 1.2831751108169556
Validation loss: 2.203581517742526

Epoch: 5| Step: 10
Training loss: 1.2991676330566406
Validation loss: 2.170126538122854

Epoch: 456| Step: 0
Training loss: 1.0485694408416748
Validation loss: 2.1213629604667745

Epoch: 5| Step: 1
Training loss: 1.8288724422454834
Validation loss: 2.1621311377453547

Epoch: 5| Step: 2
Training loss: 1.5407100915908813
Validation loss: 2.1203655888957362

Epoch: 5| Step: 3
Training loss: 0.9549939036369324
Validation loss: 2.1808977152711604

Epoch: 5| Step: 4
Training loss: 1.604382872581482
Validation loss: 2.187892367762904

Epoch: 5| Step: 5
Training loss: 1.6705926656723022
Validation loss: 2.1090378684382283

Epoch: 5| Step: 6
Training loss: 1.6065070629119873
Validation loss: 2.1178257208998486

Epoch: 5| Step: 7
Training loss: 1.4291998147964478
Validation loss: 2.1263836199237454

Epoch: 5| Step: 8
Training loss: 1.4507107734680176
Validation loss: 2.144789486803034

Epoch: 5| Step: 9
Training loss: 1.3086340427398682
Validation loss: 2.1022299797304216

Epoch: 5| Step: 10
Training loss: 1.6424829959869385
Validation loss: 2.1597178597604074

Epoch: 457| Step: 0
Training loss: 1.7157611846923828
Validation loss: 2.112205082370389

Epoch: 5| Step: 1
Training loss: 0.9531474113464355
Validation loss: 2.1549944890442716

Epoch: 5| Step: 2
Training loss: 2.1161563396453857
Validation loss: 2.1678878889288953

Epoch: 5| Step: 3
Training loss: 1.1637485027313232
Validation loss: 2.1314701726359706

Epoch: 5| Step: 4
Training loss: 1.4824097156524658
Validation loss: 2.155739379185502

Epoch: 5| Step: 5
Training loss: 1.3054053783416748
Validation loss: 2.108050566847606

Epoch: 5| Step: 6
Training loss: 1.1432411670684814
Validation loss: 2.163385634781212

Epoch: 5| Step: 7
Training loss: 1.1265344619750977
Validation loss: 2.1905189150123188

Epoch: 5| Step: 8
Training loss: 1.96426522731781
Validation loss: 2.135630538386683

Epoch: 5| Step: 9
Training loss: 1.644296407699585
Validation loss: 2.0818156196225073

Epoch: 5| Step: 10
Training loss: 1.4262542724609375
Validation loss: 2.172763573226108

Epoch: 458| Step: 0
Training loss: 1.2353451251983643
Validation loss: 2.137208100288145

Epoch: 5| Step: 1
Training loss: 1.5993738174438477
Validation loss: 2.1119049185065815

Epoch: 5| Step: 2
Training loss: 1.1795088052749634
Validation loss: 2.1781485080718994

Epoch: 5| Step: 3
Training loss: 1.2006781101226807
Validation loss: 2.1641753617153374

Epoch: 5| Step: 4
Training loss: 1.3375420570373535
Validation loss: 2.1313191024206017

Epoch: 5| Step: 5
Training loss: 1.741188406944275
Validation loss: 2.133455966108589

Epoch: 5| Step: 6
Training loss: 1.7058321237564087
Validation loss: 2.1627590169188795

Epoch: 5| Step: 7
Training loss: 1.6090691089630127
Validation loss: 2.1487206387263473

Epoch: 5| Step: 8
Training loss: 1.929729700088501
Validation loss: 2.1431186199188232

Epoch: 5| Step: 9
Training loss: 1.2748502492904663
Validation loss: 2.1215260515930834

Epoch: 5| Step: 10
Training loss: 1.3330916166305542
Validation loss: 2.1690183378035024

Epoch: 459| Step: 0
Training loss: 1.4140591621398926
Validation loss: 2.1673807482565604

Epoch: 5| Step: 1
Training loss: 2.0367846488952637
Validation loss: 2.1084279373127925

Epoch: 5| Step: 2
Training loss: 0.9955037832260132
Validation loss: 2.1266181635600265

Epoch: 5| Step: 3
Training loss: 1.4198265075683594
Validation loss: 2.1195127348746023

Epoch: 5| Step: 4
Training loss: 1.485749363899231
Validation loss: 2.1322173995356404

Epoch: 5| Step: 5
Training loss: 1.360589623451233
Validation loss: 2.1368495507906844

Epoch: 5| Step: 6
Training loss: 1.6590888500213623
Validation loss: 2.1706097074734267

Epoch: 5| Step: 7
Training loss: 1.6629445552825928
Validation loss: 2.1248613954872213

Epoch: 5| Step: 8
Training loss: 1.5007469654083252
Validation loss: 2.1157665047594296

Epoch: 5| Step: 9
Training loss: 1.2967936992645264
Validation loss: 2.082198973624937

Epoch: 5| Step: 10
Training loss: 1.3891891241073608
Validation loss: 2.1749843346175326

Epoch: 460| Step: 0
Training loss: 1.2338297367095947
Validation loss: 2.0913043509247484

Epoch: 5| Step: 1
Training loss: 1.3150262832641602
Validation loss: 2.0901907438872964

Epoch: 5| Step: 2
Training loss: 1.5002524852752686
Validation loss: 2.0866748620105047

Epoch: 5| Step: 3
Training loss: 1.4633649587631226
Validation loss: 2.159905798973576

Epoch: 5| Step: 4
Training loss: 1.6334669589996338
Validation loss: 2.116470803496658

Epoch: 5| Step: 5
Training loss: 1.9162323474884033
Validation loss: 2.146707288680538

Epoch: 5| Step: 6
Training loss: 1.4900153875350952
Validation loss: 2.166441745655511

Epoch: 5| Step: 7
Training loss: 1.6055660247802734
Validation loss: 2.1116379012343702

Epoch: 5| Step: 8
Training loss: 1.990343451499939
Validation loss: 2.134427556427576

Epoch: 5| Step: 9
Training loss: 0.9906743764877319
Validation loss: 2.1454484937011555

Epoch: 5| Step: 10
Training loss: 0.8275418281555176
Validation loss: 2.0910459667123775

Epoch: 461| Step: 0
Training loss: 1.6376914978027344
Validation loss: 2.1231708424065703

Epoch: 5| Step: 1
Training loss: 1.8514341115951538
Validation loss: 2.1164473513121247

Epoch: 5| Step: 2
Training loss: 1.3649452924728394
Validation loss: 2.085201653101111

Epoch: 5| Step: 3
Training loss: 1.0322860479354858
Validation loss: 2.1133285081514748

Epoch: 5| Step: 4
Training loss: 1.0244414806365967
Validation loss: 2.1183977896167385

Epoch: 5| Step: 5
Training loss: 1.7007207870483398
Validation loss: 2.1358485478226856

Epoch: 5| Step: 6
Training loss: 1.1556438207626343
Validation loss: 2.110308390791698

Epoch: 5| Step: 7
Training loss: 1.4130833148956299
Validation loss: 2.0907608283463346

Epoch: 5| Step: 8
Training loss: 1.558348298072815
Validation loss: 2.0842486953222625

Epoch: 5| Step: 9
Training loss: 1.1935142278671265
Validation loss: 2.142129244342927

Epoch: 5| Step: 10
Training loss: 2.0336475372314453
Validation loss: 2.13167376928432

Epoch: 462| Step: 0
Training loss: 1.1514999866485596
Validation loss: 2.1361448739164617

Epoch: 5| Step: 1
Training loss: 1.5742439031600952
Validation loss: 2.124840441570487

Epoch: 5| Step: 2
Training loss: 1.8506813049316406
Validation loss: 2.1326804596890687

Epoch: 5| Step: 3
Training loss: 1.4265886545181274
Validation loss: 2.149980873189947

Epoch: 5| Step: 4
Training loss: 1.2863906621932983
Validation loss: 2.1257428840924333

Epoch: 5| Step: 5
Training loss: 1.6052634716033936
Validation loss: 2.154127267099196

Epoch: 5| Step: 6
Training loss: 1.2106635570526123
Validation loss: 2.1320952600048435

Epoch: 5| Step: 7
Training loss: 1.3372600078582764
Validation loss: 2.1820686773587297

Epoch: 5| Step: 8
Training loss: 1.2708020210266113
Validation loss: 2.162853435803485

Epoch: 5| Step: 9
Training loss: 1.3406355381011963
Validation loss: 2.145760246502456

Epoch: 5| Step: 10
Training loss: 2.146500825881958
Validation loss: 2.151855727677704

Epoch: 463| Step: 0
Training loss: 1.6289345026016235
Validation loss: 2.087354629270492

Epoch: 5| Step: 1
Training loss: 1.9683597087860107
Validation loss: 2.1572058777655325

Epoch: 5| Step: 2
Training loss: 1.3311302661895752
Validation loss: 2.1347602772456344

Epoch: 5| Step: 3
Training loss: 1.2477048635482788
Validation loss: 2.1459321847525974

Epoch: 5| Step: 4
Training loss: 1.6856178045272827
Validation loss: 2.1050453045034923

Epoch: 5| Step: 5
Training loss: 1.3475700616836548
Validation loss: 2.118166205703571

Epoch: 5| Step: 6
Training loss: 1.783196210861206
Validation loss: 2.1207007182541715

Epoch: 5| Step: 7
Training loss: 1.244341492652893
Validation loss: 2.0688517978114467

Epoch: 5| Step: 8
Training loss: 1.5342282056808472
Validation loss: 2.1270681940099245

Epoch: 5| Step: 9
Training loss: 1.1182684898376465
Validation loss: 2.107998312160533

Epoch: 5| Step: 10
Training loss: 0.8446440696716309
Validation loss: 2.153809093659924

Epoch: 464| Step: 0
Training loss: 1.6958892345428467
Validation loss: 2.1099179572956537

Epoch: 5| Step: 1
Training loss: 1.4318318367004395
Validation loss: 2.119613716679235

Epoch: 5| Step: 2
Training loss: 1.9979372024536133
Validation loss: 2.127654214059153

Epoch: 5| Step: 3
Training loss: 1.3049733638763428
Validation loss: 2.130261182785034

Epoch: 5| Step: 4
Training loss: 1.4857794046401978
Validation loss: 2.1877198808936664

Epoch: 5| Step: 5
Training loss: 1.6883522272109985
Validation loss: 2.087102308068224

Epoch: 5| Step: 6
Training loss: 1.5244932174682617
Validation loss: 2.109394304213985

Epoch: 5| Step: 7
Training loss: 0.9947344660758972
Validation loss: 2.147663072873187

Epoch: 5| Step: 8
Training loss: 1.6629520654678345
Validation loss: 2.1529116810009046

Epoch: 5| Step: 9
Training loss: 0.9079324007034302
Validation loss: 2.0969891907066427

Epoch: 5| Step: 10
Training loss: 1.5426455736160278
Validation loss: 2.0820490583296745

Epoch: 465| Step: 0
Training loss: 1.5062168836593628
Validation loss: 2.1157534173739854

Epoch: 5| Step: 1
Training loss: 0.7623997926712036
Validation loss: 2.1545904464619134

Epoch: 5| Step: 2
Training loss: 1.4049772024154663
Validation loss: 2.0892052714542677

Epoch: 5| Step: 3
Training loss: 1.9556804895401
Validation loss: 2.13725447141996

Epoch: 5| Step: 4
Training loss: 1.8436965942382812
Validation loss: 2.1137091805857997

Epoch: 5| Step: 5
Training loss: 1.6299225091934204
Validation loss: 2.120158032704425

Epoch: 5| Step: 6
Training loss: 0.9167047739028931
Validation loss: 2.143467841609832

Epoch: 5| Step: 7
Training loss: 1.3914530277252197
Validation loss: 2.132684374368319

Epoch: 5| Step: 8
Training loss: 1.529762625694275
Validation loss: 2.1217120949940016

Epoch: 5| Step: 9
Training loss: 1.011076807975769
Validation loss: 2.1146907716669063

Epoch: 5| Step: 10
Training loss: 1.6787989139556885
Validation loss: 2.1251593917928715

Epoch: 466| Step: 0
Training loss: 0.9726759195327759
Validation loss: 2.1419636767397643

Epoch: 5| Step: 1
Training loss: 1.5780874490737915
Validation loss: 2.096655550823417

Epoch: 5| Step: 2
Training loss: 1.8012866973876953
Validation loss: 2.168651726938063

Epoch: 5| Step: 3
Training loss: 1.8125464916229248
Validation loss: 2.1252699026497464

Epoch: 5| Step: 4
Training loss: 1.1828933954238892
Validation loss: 2.210719846910046

Epoch: 5| Step: 5
Training loss: 1.438053846359253
Validation loss: 2.181631980403777

Epoch: 5| Step: 6
Training loss: 1.3822728395462036
Validation loss: 2.142124065788843

Epoch: 5| Step: 7
Training loss: 2.3001811504364014
Validation loss: 2.079254218327102

Epoch: 5| Step: 8
Training loss: 1.0732343196868896
Validation loss: 2.1502284875480075

Epoch: 5| Step: 9
Training loss: 1.0143954753875732
Validation loss: 2.168520886410949

Epoch: 5| Step: 10
Training loss: 1.271649718284607
Validation loss: 2.0957474888011975

Epoch: 467| Step: 0
Training loss: 1.4925962686538696
Validation loss: 2.1185532410939536

Epoch: 5| Step: 1
Training loss: 1.2589991092681885
Validation loss: 2.094843608076854

Epoch: 5| Step: 2
Training loss: 1.4174442291259766
Validation loss: 2.1607433595964984

Epoch: 5| Step: 3
Training loss: 1.211632490158081
Validation loss: 2.118532180786133

Epoch: 5| Step: 4
Training loss: 1.2214398384094238
Validation loss: 2.1305103276365545

Epoch: 5| Step: 5
Training loss: 2.285205125808716
Validation loss: 2.1789382016786965

Epoch: 5| Step: 6
Training loss: 1.729203462600708
Validation loss: 2.1264911877211703

Epoch: 5| Step: 7
Training loss: 1.501678228378296
Validation loss: 2.132733839814381

Epoch: 5| Step: 8
Training loss: 1.287409782409668
Validation loss: 2.1931745775284304

Epoch: 5| Step: 9
Training loss: 0.8759371638298035
Validation loss: 2.110708834022604

Epoch: 5| Step: 10
Training loss: 1.4730159044265747
Validation loss: 2.131011087407348

Epoch: 468| Step: 0
Training loss: 1.7101606130599976
Validation loss: 2.131896080509309

Epoch: 5| Step: 1
Training loss: 1.5304391384124756
Validation loss: 2.112500424026161

Epoch: 5| Step: 2
Training loss: 0.5894672274589539
Validation loss: 2.105880750122891

Epoch: 5| Step: 3
Training loss: 1.254023551940918
Validation loss: 2.158780159488801

Epoch: 5| Step: 4
Training loss: 1.6640422344207764
Validation loss: 2.1199776331583657

Epoch: 5| Step: 5
Training loss: 1.282684087753296
Validation loss: 2.0843206631240023

Epoch: 5| Step: 6
Training loss: 1.5788145065307617
Validation loss: 2.1859458159374934

Epoch: 5| Step: 7
Training loss: 1.4486255645751953
Validation loss: 2.123483027181318

Epoch: 5| Step: 8
Training loss: 1.8009674549102783
Validation loss: 2.122502471811028

Epoch: 5| Step: 9
Training loss: 1.4574646949768066
Validation loss: 2.183913169368621

Epoch: 5| Step: 10
Training loss: 1.3644394874572754
Validation loss: 2.0969381845125588

Epoch: 469| Step: 0
Training loss: 1.2280045747756958
Validation loss: 2.1478999404497046

Epoch: 5| Step: 1
Training loss: 0.9509273767471313
Validation loss: 2.1623023402306343

Epoch: 5| Step: 2
Training loss: 1.8871500492095947
Validation loss: 2.1485035265645673

Epoch: 5| Step: 3
Training loss: 1.310571312904358
Validation loss: 2.145589095289989

Epoch: 5| Step: 4
Training loss: 2.2503409385681152
Validation loss: 2.171899982677993

Epoch: 5| Step: 5
Training loss: 1.5115187168121338
Validation loss: 2.127095180173074

Epoch: 5| Step: 6
Training loss: 0.9123818278312683
Validation loss: 2.1540763198688464

Epoch: 5| Step: 7
Training loss: 1.413625955581665
Validation loss: 2.127979579792228

Epoch: 5| Step: 8
Training loss: 1.2853758335113525
Validation loss: 2.17783341100139

Epoch: 5| Step: 9
Training loss: 1.5091627836227417
Validation loss: 2.131965906389298

Epoch: 5| Step: 10
Training loss: 1.3244706392288208
Validation loss: 2.143994151905019

Epoch: 470| Step: 0
Training loss: 1.1379408836364746
Validation loss: 2.1590978471181725

Epoch: 5| Step: 1
Training loss: 1.2967278957366943
Validation loss: 2.09311007940641

Epoch: 5| Step: 2
Training loss: 1.3680071830749512
Validation loss: 2.1487716269749466

Epoch: 5| Step: 3
Training loss: 1.8329236507415771
Validation loss: 2.128290758338026

Epoch: 5| Step: 4
Training loss: 1.4481513500213623
Validation loss: 2.1396363858253724

Epoch: 5| Step: 5
Training loss: 1.0232540369033813
Validation loss: 2.1481779390765774

Epoch: 5| Step: 6
Training loss: 1.6397864818572998
Validation loss: 2.1719904791924263

Epoch: 5| Step: 7
Training loss: 1.5235462188720703
Validation loss: 2.1725352105273994

Epoch: 5| Step: 8
Training loss: 1.1648238897323608
Validation loss: 2.106079291271907

Epoch: 5| Step: 9
Training loss: 1.6614272594451904
Validation loss: 2.114740658831853

Epoch: 5| Step: 10
Training loss: 1.7046887874603271
Validation loss: 2.1078159680930515

Epoch: 471| Step: 0
Training loss: 1.465489387512207
Validation loss: 2.1624065009496545

Epoch: 5| Step: 1
Training loss: 1.4695464372634888
Validation loss: 2.1357248918984526

Epoch: 5| Step: 2
Training loss: 1.7904914617538452
Validation loss: 2.1674280320444415

Epoch: 5| Step: 3
Training loss: 1.838545799255371
Validation loss: 2.1639364611717964

Epoch: 5| Step: 4
Training loss: 1.1311848163604736
Validation loss: 2.129232027197397

Epoch: 5| Step: 5
Training loss: 1.4096434116363525
Validation loss: 2.122799881042973

Epoch: 5| Step: 6
Training loss: 1.1948182582855225
Validation loss: 2.1751910140437465

Epoch: 5| Step: 7
Training loss: 0.9948962926864624
Validation loss: 2.1577125954371628

Epoch: 5| Step: 8
Training loss: 0.9348265528678894
Validation loss: 2.17933157438873

Epoch: 5| Step: 9
Training loss: 1.3727521896362305
Validation loss: 2.1320279926382084

Epoch: 5| Step: 10
Training loss: 1.839600920677185
Validation loss: 2.154260737921602

Epoch: 472| Step: 0
Training loss: 2.224055767059326
Validation loss: 2.1081842119975756

Epoch: 5| Step: 1
Training loss: 1.331968069076538
Validation loss: 2.121422376683963

Epoch: 5| Step: 2
Training loss: 1.2527028322219849
Validation loss: 2.1273618205901115

Epoch: 5| Step: 3
Training loss: 1.468398094177246
Validation loss: 2.0844367627174623

Epoch: 5| Step: 4
Training loss: 1.27996027469635
Validation loss: 2.1863763614367415

Epoch: 5| Step: 5
Training loss: 1.839740514755249
Validation loss: 2.117176716045667

Epoch: 5| Step: 6
Training loss: 1.2042551040649414
Validation loss: 2.1183541513258413

Epoch: 5| Step: 7
Training loss: 1.261422872543335
Validation loss: 2.119494676589966

Epoch: 5| Step: 8
Training loss: 1.2587534189224243
Validation loss: 2.1670899186083066

Epoch: 5| Step: 9
Training loss: 1.2026100158691406
Validation loss: 2.1413130042373494

Epoch: 5| Step: 10
Training loss: 1.3041892051696777
Validation loss: 2.0765020206410396

Epoch: 473| Step: 0
Training loss: 1.6374404430389404
Validation loss: 2.0716895377764137

Epoch: 5| Step: 1
Training loss: 0.7178600430488586
Validation loss: 2.1358060477882304

Epoch: 5| Step: 2
Training loss: 1.6787774562835693
Validation loss: 2.139804019722887

Epoch: 5| Step: 3
Training loss: 0.9481908082962036
Validation loss: 2.0943053409617436

Epoch: 5| Step: 4
Training loss: 1.7095251083374023
Validation loss: 2.1284204670177993

Epoch: 5| Step: 5
Training loss: 1.417258858680725
Validation loss: 2.140936541300948

Epoch: 5| Step: 6
Training loss: 1.939124345779419
Validation loss: 2.1799014229928293

Epoch: 5| Step: 7
Training loss: 1.1024583578109741
Validation loss: 2.131109509416806

Epoch: 5| Step: 8
Training loss: 1.5821739435195923
Validation loss: 2.142767637006698

Epoch: 5| Step: 9
Training loss: 1.4217827320098877
Validation loss: 2.152712106704712

Epoch: 5| Step: 10
Training loss: 1.4744081497192383
Validation loss: 2.1447424901429044

Epoch: 474| Step: 0
Training loss: 0.9044051170349121
Validation loss: 2.144708369367866

Epoch: 5| Step: 1
Training loss: 1.829702377319336
Validation loss: 2.1010651844804005

Epoch: 5| Step: 2
Training loss: 1.5335347652435303
Validation loss: 2.1406621830437773

Epoch: 5| Step: 3
Training loss: 1.450089931488037
Validation loss: 2.1340529841761433

Epoch: 5| Step: 4
Training loss: 1.853198766708374
Validation loss: 2.1236905949090117

Epoch: 5| Step: 5
Training loss: 1.0005686283111572
Validation loss: 2.091299687662432

Epoch: 5| Step: 6
Training loss: 1.3313148021697998
Validation loss: 2.196911141436587

Epoch: 5| Step: 7
Training loss: 1.8367030620574951
Validation loss: 2.1333595040023967

Epoch: 5| Step: 8
Training loss: 1.252953290939331
Validation loss: 2.099390258071243

Epoch: 5| Step: 9
Training loss: 1.6662395000457764
Validation loss: 2.1221065495603826

Epoch: 5| Step: 10
Training loss: 1.2408002614974976
Validation loss: 2.1562584010503625

Epoch: 475| Step: 0
Training loss: 1.2063963413238525
Validation loss: 2.1558638593201995

Epoch: 5| Step: 1
Training loss: 1.0318561792373657
Validation loss: 2.1125751887598345

Epoch: 5| Step: 2
Training loss: 1.232132911682129
Validation loss: 2.171425037486579

Epoch: 5| Step: 3
Training loss: 1.6674978733062744
Validation loss: 2.135368375368016

Epoch: 5| Step: 4
Training loss: 1.6931263208389282
Validation loss: 2.129463694428885

Epoch: 5| Step: 5
Training loss: 1.5445992946624756
Validation loss: 2.1208397649949595

Epoch: 5| Step: 6
Training loss: 1.225385308265686
Validation loss: 2.133422028633856

Epoch: 5| Step: 7
Training loss: 1.1877081394195557
Validation loss: 2.200077501676416

Epoch: 5| Step: 8
Training loss: 1.2757930755615234
Validation loss: 2.0616257959796536

Epoch: 5| Step: 9
Training loss: 1.7009273767471313
Validation loss: 2.095442723202449

Epoch: 5| Step: 10
Training loss: 1.6206485033035278
Validation loss: 2.118848216149115

Epoch: 476| Step: 0
Training loss: 1.3521651029586792
Validation loss: 2.1300528280196653

Epoch: 5| Step: 1
Training loss: 1.6712220907211304
Validation loss: 2.1182307761202575

Epoch: 5| Step: 2
Training loss: 1.6250492334365845
Validation loss: 2.1532125293567614

Epoch: 5| Step: 3
Training loss: 1.2642056941986084
Validation loss: 2.1783141551479215

Epoch: 5| Step: 4
Training loss: 1.7903541326522827
Validation loss: 2.124722989656592

Epoch: 5| Step: 5
Training loss: 1.4216938018798828
Validation loss: 2.0734812726256666

Epoch: 5| Step: 6
Training loss: 1.2056981325149536
Validation loss: 2.1356019973754883

Epoch: 5| Step: 7
Training loss: 1.2622300386428833
Validation loss: 2.1122606710721086

Epoch: 5| Step: 8
Training loss: 1.2439939975738525
Validation loss: 2.115663295151085

Epoch: 5| Step: 9
Training loss: 1.3180636167526245
Validation loss: 2.1373272993231334

Epoch: 5| Step: 10
Training loss: 1.7523194551467896
Validation loss: 2.110050127070437

Epoch: 477| Step: 0
Training loss: 1.1349719762802124
Validation loss: 2.09246745417195

Epoch: 5| Step: 1
Training loss: 1.1764962673187256
Validation loss: 2.1118494592687136

Epoch: 5| Step: 2
Training loss: 1.7310129404067993
Validation loss: 2.1468101022064046

Epoch: 5| Step: 3
Training loss: 1.1301480531692505
Validation loss: 2.1648093231262697

Epoch: 5| Step: 4
Training loss: 1.8583492040634155
Validation loss: 2.149869308676771

Epoch: 5| Step: 5
Training loss: 1.5335584878921509
Validation loss: 2.200701305943151

Epoch: 5| Step: 6
Training loss: 1.5214917659759521
Validation loss: 2.1066073499700075

Epoch: 5| Step: 7
Training loss: 1.4365589618682861
Validation loss: 2.1900087146348852

Epoch: 5| Step: 8
Training loss: 2.0205886363983154
Validation loss: 2.2130702105901574

Epoch: 5| Step: 9
Training loss: 1.213267207145691
Validation loss: 2.148766358693441

Epoch: 5| Step: 10
Training loss: 0.59952712059021
Validation loss: 2.0834889873381583

Epoch: 478| Step: 0
Training loss: 1.3777101039886475
Validation loss: 2.1118185981627433

Epoch: 5| Step: 1
Training loss: 1.421309232711792
Validation loss: 2.1436708627208585

Epoch: 5| Step: 2
Training loss: 1.2282497882843018
Validation loss: 2.1520298168223393

Epoch: 5| Step: 3
Training loss: 1.6658189296722412
Validation loss: 2.18901555256177

Epoch: 5| Step: 4
Training loss: 1.4131633043289185
Validation loss: 2.1168044126161965

Epoch: 5| Step: 5
Training loss: 1.3590285778045654
Validation loss: 2.1009489438867055

Epoch: 5| Step: 6
Training loss: 1.2654389142990112
Validation loss: 2.1559348414021153

Epoch: 5| Step: 7
Training loss: 1.5114195346832275
Validation loss: 2.1402063203114334

Epoch: 5| Step: 8
Training loss: 0.7933725714683533
Validation loss: 2.1067919500412478

Epoch: 5| Step: 9
Training loss: 1.580931544303894
Validation loss: 2.084327393962491

Epoch: 5| Step: 10
Training loss: 1.9039090871810913
Validation loss: 2.1076929851244857

Epoch: 479| Step: 0
Training loss: 1.8070513010025024
Validation loss: 2.1992914625393447

Epoch: 5| Step: 1
Training loss: 1.1902137994766235
Validation loss: 2.127246008124403

Epoch: 5| Step: 2
Training loss: 1.0118050575256348
Validation loss: 2.108090776269154

Epoch: 5| Step: 3
Training loss: 1.021303415298462
Validation loss: 2.1057988546227895

Epoch: 5| Step: 4
Training loss: 1.331223487854004
Validation loss: 2.1081668971687235

Epoch: 5| Step: 5
Training loss: 0.8952533602714539
Validation loss: 2.1592978713332966

Epoch: 5| Step: 6
Training loss: 1.7248294353485107
Validation loss: 2.0970528523127236

Epoch: 5| Step: 7
Training loss: 1.4279875755310059
Validation loss: 2.0744025681608464

Epoch: 5| Step: 8
Training loss: 2.134098529815674
Validation loss: 2.0893907495724258

Epoch: 5| Step: 9
Training loss: 1.3343863487243652
Validation loss: 2.1116195224946543

Epoch: 5| Step: 10
Training loss: 1.9015545845031738
Validation loss: 2.136854035879976

Epoch: 480| Step: 0
Training loss: 1.6692615747451782
Validation loss: 2.123934822697793

Epoch: 5| Step: 1
Training loss: 1.5619546175003052
Validation loss: 2.1069682926260014

Epoch: 5| Step: 2
Training loss: 1.3305310010910034
Validation loss: 2.1238067585934877

Epoch: 5| Step: 3
Training loss: 1.482374906539917
Validation loss: 2.0519726917307866

Epoch: 5| Step: 4
Training loss: 1.4729082584381104
Validation loss: 2.1564424666025306

Epoch: 5| Step: 5
Training loss: 1.1094114780426025
Validation loss: 2.152920646052207

Epoch: 5| Step: 6
Training loss: 1.21925687789917
Validation loss: 2.1767051989032375

Epoch: 5| Step: 7
Training loss: 0.8855632543563843
Validation loss: 2.151048647460117

Epoch: 5| Step: 8
Training loss: 1.719773292541504
Validation loss: 2.1578087217064312

Epoch: 5| Step: 9
Training loss: 1.2945080995559692
Validation loss: 2.2139787238131285

Epoch: 5| Step: 10
Training loss: 1.9281880855560303
Validation loss: 2.1436451045415734

Epoch: 481| Step: 0
Training loss: 1.8497190475463867
Validation loss: 2.121252562410088

Epoch: 5| Step: 1
Training loss: 1.4556833505630493
Validation loss: 2.1424643634467997

Epoch: 5| Step: 2
Training loss: 1.244038462638855
Validation loss: 2.1179322965683474

Epoch: 5| Step: 3
Training loss: 1.212659239768982
Validation loss: 2.1373825265515234

Epoch: 5| Step: 4
Training loss: 1.5337949991226196
Validation loss: 2.1203042973754225

Epoch: 5| Step: 5
Training loss: 1.5126796960830688
Validation loss: 2.150886421562523

Epoch: 5| Step: 6
Training loss: 1.6429405212402344
Validation loss: 2.139442243883687

Epoch: 5| Step: 7
Training loss: 1.1322195529937744
Validation loss: 2.0543739949503252

Epoch: 5| Step: 8
Training loss: 1.632707953453064
Validation loss: 2.11327778139422

Epoch: 5| Step: 9
Training loss: 1.1070553064346313
Validation loss: 2.1702107460268083

Epoch: 5| Step: 10
Training loss: 1.3879384994506836
Validation loss: 2.148776282546341

Epoch: 482| Step: 0
Training loss: 1.214838981628418
Validation loss: 2.1216056475075344

Epoch: 5| Step: 1
Training loss: 1.1287177801132202
Validation loss: 2.1365219662266393

Epoch: 5| Step: 2
Training loss: 1.1167943477630615
Validation loss: 2.155526876449585

Epoch: 5| Step: 3
Training loss: 1.3680003881454468
Validation loss: 2.1292377543705765

Epoch: 5| Step: 4
Training loss: 1.4835264682769775
Validation loss: 2.1604057768339753

Epoch: 5| Step: 5
Training loss: 1.0245907306671143
Validation loss: 2.1156184852764173

Epoch: 5| Step: 6
Training loss: 1.9918339252471924
Validation loss: 2.1548983281658542

Epoch: 5| Step: 7
Training loss: 1.2631480693817139
Validation loss: 2.171690494783463

Epoch: 5| Step: 8
Training loss: 1.737842321395874
Validation loss: 2.1324590918838338

Epoch: 5| Step: 9
Training loss: 1.3538062572479248
Validation loss: 2.136009634182017

Epoch: 5| Step: 10
Training loss: 1.4367589950561523
Validation loss: 2.1622403103818177

Epoch: 483| Step: 0
Training loss: 1.4449361562728882
Validation loss: 2.1444982046722085

Epoch: 5| Step: 1
Training loss: 1.4627470970153809
Validation loss: 2.104517170177993

Epoch: 5| Step: 2
Training loss: 1.8341143131256104
Validation loss: 2.1063809843473535

Epoch: 5| Step: 3
Training loss: 0.9668819308280945
Validation loss: 2.1542599483202864

Epoch: 5| Step: 4
Training loss: 1.8356082439422607
Validation loss: 2.149168768236714

Epoch: 5| Step: 5
Training loss: 1.638332724571228
Validation loss: 2.16927574270515

Epoch: 5| Step: 6
Training loss: 1.150510549545288
Validation loss: 2.1264183213633876

Epoch: 5| Step: 7
Training loss: 1.1914989948272705
Validation loss: 2.1397735149629655

Epoch: 5| Step: 8
Training loss: 1.3023852109909058
Validation loss: 2.0942206741661153

Epoch: 5| Step: 9
Training loss: 0.9624469876289368
Validation loss: 2.1573501427968345

Epoch: 5| Step: 10
Training loss: 1.571678876876831
Validation loss: 2.163629501096664

Epoch: 484| Step: 0
Training loss: 1.1945403814315796
Validation loss: 2.13123688133814

Epoch: 5| Step: 1
Training loss: 1.1240240335464478
Validation loss: 2.1097584668026177

Epoch: 5| Step: 2
Training loss: 1.6039249897003174
Validation loss: 2.108961905202558

Epoch: 5| Step: 3
Training loss: 1.0729756355285645
Validation loss: 2.103568958979781

Epoch: 5| Step: 4
Training loss: 1.4228122234344482
Validation loss: 2.1067768168705765

Epoch: 5| Step: 5
Training loss: 1.4782280921936035
Validation loss: 2.141106886248435

Epoch: 5| Step: 6
Training loss: 1.367484211921692
Validation loss: 2.1141555591296126

Epoch: 5| Step: 7
Training loss: 1.3245147466659546
Validation loss: 2.1028987092356526

Epoch: 5| Step: 8
Training loss: 1.3442600965499878
Validation loss: 2.16221175911606

Epoch: 5| Step: 9
Training loss: 1.9167406558990479
Validation loss: 2.1280410815310735

Epoch: 5| Step: 10
Training loss: 1.4603062868118286
Validation loss: 2.160857815896311

Epoch: 485| Step: 0
Training loss: 1.0090506076812744
Validation loss: 2.111226325394005

Epoch: 5| Step: 1
Training loss: 1.0652275085449219
Validation loss: 2.0912778198078112

Epoch: 5| Step: 2
Training loss: 1.4696863889694214
Validation loss: 2.1303911568016134

Epoch: 5| Step: 3
Training loss: 1.1866410970687866
Validation loss: 2.1138143795792774

Epoch: 5| Step: 4
Training loss: 1.7830145359039307
Validation loss: 2.160845568103175

Epoch: 5| Step: 5
Training loss: 1.2695021629333496
Validation loss: 2.0716856102789603

Epoch: 5| Step: 6
Training loss: 1.4279675483703613
Validation loss: 2.1224945027341127

Epoch: 5| Step: 7
Training loss: 1.171332836151123
Validation loss: 2.2154287420293337

Epoch: 5| Step: 8
Training loss: 1.6393096446990967
Validation loss: 2.169070537372302

Epoch: 5| Step: 9
Training loss: 0.6022999882698059
Validation loss: 2.1320808190171436

Epoch: 5| Step: 10
Training loss: 2.5055947303771973
Validation loss: 2.1850420198132916

Epoch: 486| Step: 0
Training loss: 1.2746542692184448
Validation loss: 2.1890293898121005

Epoch: 5| Step: 1
Training loss: 1.3915661573410034
Validation loss: 2.180073297151955

Epoch: 5| Step: 2
Training loss: 1.5819042921066284
Validation loss: 2.1767533517652944

Epoch: 5| Step: 3
Training loss: 1.0971360206604004
Validation loss: 2.145727660066338

Epoch: 5| Step: 4
Training loss: 1.6896148920059204
Validation loss: 2.168323923182744

Epoch: 5| Step: 5
Training loss: 0.8116075396537781
Validation loss: 2.1368175091282016

Epoch: 5| Step: 6
Training loss: 1.3088937997817993
Validation loss: 2.099473919919742

Epoch: 5| Step: 7
Training loss: 1.4010308980941772
Validation loss: 2.1225120867452314

Epoch: 5| Step: 8
Training loss: 1.6677865982055664
Validation loss: 2.149735866054412

Epoch: 5| Step: 9
Training loss: 1.6845319271087646
Validation loss: 2.1238460617680706

Epoch: 5| Step: 10
Training loss: 1.4430747032165527
Validation loss: 2.1237726352548085

Epoch: 487| Step: 0
Training loss: 1.875889778137207
Validation loss: 2.2308511567372147

Epoch: 5| Step: 1
Training loss: 1.5101419687271118
Validation loss: 2.1460116063394854

Epoch: 5| Step: 2
Training loss: 1.3676990270614624
Validation loss: 2.1678917049079813

Epoch: 5| Step: 3
Training loss: 1.2596410512924194
Validation loss: 2.1985268080106346

Epoch: 5| Step: 4
Training loss: 1.2835466861724854
Validation loss: 2.154177250400666

Epoch: 5| Step: 5
Training loss: 1.4828662872314453
Validation loss: 2.1208868629188946

Epoch: 5| Step: 6
Training loss: 1.3179535865783691
Validation loss: 2.1883273829695997

Epoch: 5| Step: 7
Training loss: 1.4003225564956665
Validation loss: 2.0853650557097567

Epoch: 5| Step: 8
Training loss: 1.3512616157531738
Validation loss: 2.150187761552872

Epoch: 5| Step: 9
Training loss: 1.429447889328003
Validation loss: 2.144464833762056

Epoch: 5| Step: 10
Training loss: 1.3928943872451782
Validation loss: 2.099675945056382

Epoch: 488| Step: 0
Training loss: 1.2899956703186035
Validation loss: 2.104181940837573

Epoch: 5| Step: 1
Training loss: 1.4178571701049805
Validation loss: 2.122616949901786

Epoch: 5| Step: 2
Training loss: 1.724843978881836
Validation loss: 2.1499870874548472

Epoch: 5| Step: 3
Training loss: 1.4423844814300537
Validation loss: 2.108277964335616

Epoch: 5| Step: 4
Training loss: 1.147996425628662
Validation loss: 2.162495215733846

Epoch: 5| Step: 5
Training loss: 1.4296495914459229
Validation loss: 2.0772464070268857

Epoch: 5| Step: 6
Training loss: 1.5691863298416138
Validation loss: 2.1468203324143604

Epoch: 5| Step: 7
Training loss: 1.8723407983779907
Validation loss: 2.1317418493250364

Epoch: 5| Step: 8
Training loss: 0.8366278409957886
Validation loss: 2.145148492628528

Epoch: 5| Step: 9
Training loss: 1.4446098804473877
Validation loss: 2.1553019374929447

Epoch: 5| Step: 10
Training loss: 1.3424601554870605
Validation loss: 2.182014270495343

Epoch: 489| Step: 0
Training loss: 1.304459810256958
Validation loss: 2.108337753562517

Epoch: 5| Step: 1
Training loss: 1.7355797290802002
Validation loss: 2.1240568622466056

Epoch: 5| Step: 2
Training loss: 1.7427791357040405
Validation loss: 2.12746686063787

Epoch: 5| Step: 3
Training loss: 1.4689441919326782
Validation loss: 2.169154214602645

Epoch: 5| Step: 4
Training loss: 1.8744503259658813
Validation loss: 2.1745251660705893

Epoch: 5| Step: 5
Training loss: 0.8166741132736206
Validation loss: 2.2083862584124327

Epoch: 5| Step: 6
Training loss: 1.3284313678741455
Validation loss: 2.1457816657199653

Epoch: 5| Step: 7
Training loss: 1.6796433925628662
Validation loss: 2.1816206055302776

Epoch: 5| Step: 8
Training loss: 1.5422008037567139
Validation loss: 2.159598083906276

Epoch: 5| Step: 9
Training loss: 1.0882017612457275
Validation loss: 2.185825397891383

Epoch: 5| Step: 10
Training loss: 0.9193949699401855
Validation loss: 2.117223257659584

Epoch: 490| Step: 0
Training loss: 1.2391633987426758
Validation loss: 2.166736372055546

Epoch: 5| Step: 1
Training loss: 1.3251047134399414
Validation loss: 2.162846146091338

Epoch: 5| Step: 2
Training loss: 1.2956862449645996
Validation loss: 2.107278453406467

Epoch: 5| Step: 3
Training loss: 1.1791532039642334
Validation loss: 2.1222802439043598

Epoch: 5| Step: 4
Training loss: 1.5034695863723755
Validation loss: 2.1009155575947096

Epoch: 5| Step: 5
Training loss: 0.9519004821777344
Validation loss: 2.1763719512570288

Epoch: 5| Step: 6
Training loss: 1.7956234216690063
Validation loss: 2.181253151227069

Epoch: 5| Step: 7
Training loss: 1.4381721019744873
Validation loss: 2.202734811331636

Epoch: 5| Step: 8
Training loss: 1.1614857912063599
Validation loss: 2.143055551795549

Epoch: 5| Step: 9
Training loss: 1.6245975494384766
Validation loss: 2.160030566236024

Epoch: 5| Step: 10
Training loss: 1.7162272930145264
Validation loss: 2.118503186010545

Epoch: 491| Step: 0
Training loss: 1.6178598403930664
Validation loss: 2.1562808662332515

Epoch: 5| Step: 1
Training loss: 0.895481288433075
Validation loss: 2.156720293465481

Epoch: 5| Step: 2
Training loss: 1.2703481912612915
Validation loss: 2.194051629753523

Epoch: 5| Step: 3
Training loss: 1.266167402267456
Validation loss: 2.123752676030641

Epoch: 5| Step: 4
Training loss: 1.2340524196624756
Validation loss: 2.0984467998627694

Epoch: 5| Step: 5
Training loss: 1.3966357707977295
Validation loss: 2.1151660001406105

Epoch: 5| Step: 6
Training loss: 1.739768624305725
Validation loss: 2.1465996132102063

Epoch: 5| Step: 7
Training loss: 1.776248574256897
Validation loss: 2.1624508057871172

Epoch: 5| Step: 8
Training loss: 0.9150785207748413
Validation loss: 2.1735142571951753

Epoch: 5| Step: 9
Training loss: 2.1070923805236816
Validation loss: 2.1465890407562256

Epoch: 5| Step: 10
Training loss: 1.0777802467346191
Validation loss: 2.1415164509127216

Epoch: 492| Step: 0
Training loss: 1.6187922954559326
Validation loss: 2.122418906099053

Epoch: 5| Step: 1
Training loss: 1.5284199714660645
Validation loss: 2.11549646623673

Epoch: 5| Step: 2
Training loss: 1.5701920986175537
Validation loss: 2.1202453028771187

Epoch: 5| Step: 3
Training loss: 1.6422874927520752
Validation loss: 2.1014934996122956

Epoch: 5| Step: 4
Training loss: 1.7224757671356201
Validation loss: 2.1315799144006546

Epoch: 5| Step: 5
Training loss: 1.2630342245101929
Validation loss: 2.073289291833037

Epoch: 5| Step: 6
Training loss: 1.2335429191589355
Validation loss: 2.159027430319017

Epoch: 5| Step: 7
Training loss: 1.3473384380340576
Validation loss: 2.1169116086857294

Epoch: 5| Step: 8
Training loss: 1.1822601556777954
Validation loss: 2.161218673952164

Epoch: 5| Step: 9
Training loss: 1.1663172245025635
Validation loss: 2.16122458698929

Epoch: 5| Step: 10
Training loss: 1.1351374387741089
Validation loss: 2.1048651869579027

Epoch: 493| Step: 0
Training loss: 1.6462886333465576
Validation loss: 2.147079780537595

Epoch: 5| Step: 1
Training loss: 1.4948182106018066
Validation loss: 2.09352203594741

Epoch: 5| Step: 2
Training loss: 1.4432814121246338
Validation loss: 2.1398828247542023

Epoch: 5| Step: 3
Training loss: 1.2294235229492188
Validation loss: 2.066570198664101

Epoch: 5| Step: 4
Training loss: 1.0410610437393188
Validation loss: 2.1183288738291752

Epoch: 5| Step: 5
Training loss: 1.1485347747802734
Validation loss: 2.1499542600365094

Epoch: 5| Step: 6
Training loss: 1.4322378635406494
Validation loss: 2.120482446045004

Epoch: 5| Step: 7
Training loss: 1.7477384805679321
Validation loss: 2.180340181114853

Epoch: 5| Step: 8
Training loss: 1.7430036067962646
Validation loss: 2.149055988557877

Epoch: 5| Step: 9
Training loss: 0.9403015971183777
Validation loss: 2.1281993542948077

Epoch: 5| Step: 10
Training loss: 1.2927658557891846
Validation loss: 2.115120244282548

Epoch: 494| Step: 0
Training loss: 1.5878850221633911
Validation loss: 2.0747202032355854

Epoch: 5| Step: 1
Training loss: 1.291517972946167
Validation loss: 2.139071959321217

Epoch: 5| Step: 2
Training loss: 1.6056559085845947
Validation loss: 2.0839241653360348

Epoch: 5| Step: 3
Training loss: 1.227831244468689
Validation loss: 2.166371883884553

Epoch: 5| Step: 4
Training loss: 1.54734468460083
Validation loss: 2.1014085097979476

Epoch: 5| Step: 5
Training loss: 1.1592061519622803
Validation loss: 2.0729476636455906

Epoch: 5| Step: 6
Training loss: 1.3246036767959595
Validation loss: 2.132634083429972

Epoch: 5| Step: 7
Training loss: 1.3582007884979248
Validation loss: 2.0775542131034275

Epoch: 5| Step: 8
Training loss: 1.3502622842788696
Validation loss: 2.0980665606837117

Epoch: 5| Step: 9
Training loss: 1.4803595542907715
Validation loss: 2.1014963324351976

Epoch: 5| Step: 10
Training loss: 1.1776113510131836
Validation loss: 2.1787434777905865

Epoch: 495| Step: 0
Training loss: 0.8043825030326843
Validation loss: 2.1413189339381393

Epoch: 5| Step: 1
Training loss: 1.3346879482269287
Validation loss: 2.1411464547598236

Epoch: 5| Step: 2
Training loss: 1.1322619915008545
Validation loss: 2.074525640856835

Epoch: 5| Step: 3
Training loss: 1.0058220624923706
Validation loss: 2.167058167919036

Epoch: 5| Step: 4
Training loss: 1.335790991783142
Validation loss: 2.143820551133925

Epoch: 5| Step: 5
Training loss: 2.0879597663879395
Validation loss: 2.1199290778047297

Epoch: 5| Step: 6
Training loss: 1.307680606842041
Validation loss: 2.077911053934405

Epoch: 5| Step: 7
Training loss: 1.665716528892517
Validation loss: 2.1252919089409614

Epoch: 5| Step: 8
Training loss: 1.5126484632492065
Validation loss: 2.1040124816279255

Epoch: 5| Step: 9
Training loss: 1.8324073553085327
Validation loss: 2.124389217745873

Epoch: 5| Step: 10
Training loss: 1.1413594484329224
Validation loss: 2.092319537234563

Epoch: 496| Step: 0
Training loss: 1.3880283832550049
Validation loss: 2.1396318276723227

Epoch: 5| Step: 1
Training loss: 1.355921983718872
Validation loss: 2.1415944227608303

Epoch: 5| Step: 2
Training loss: 1.5855138301849365
Validation loss: 2.0837687971771404

Epoch: 5| Step: 3
Training loss: 1.3024600744247437
Validation loss: 2.1225798065944383

Epoch: 5| Step: 4
Training loss: 1.668752670288086
Validation loss: 2.0990828032134683

Epoch: 5| Step: 5
Training loss: 1.2252944707870483
Validation loss: 2.1296617971953524

Epoch: 5| Step: 6
Training loss: 0.9663063883781433
Validation loss: 2.1607559086174093

Epoch: 5| Step: 7
Training loss: 0.9777353405952454
Validation loss: 2.1189992581644366

Epoch: 5| Step: 8
Training loss: 0.9420817494392395
Validation loss: 2.111612609637681

Epoch: 5| Step: 9
Training loss: 1.9680122137069702
Validation loss: 2.1149349007555234

Epoch: 5| Step: 10
Training loss: 1.5420939922332764
Validation loss: 2.1052904596892734

Epoch: 497| Step: 0
Training loss: 1.2240991592407227
Validation loss: 2.1644444260545956

Epoch: 5| Step: 1
Training loss: 1.8594825267791748
Validation loss: 2.121564708730226

Epoch: 5| Step: 2
Training loss: 1.2784011363983154
Validation loss: 2.1289244492848716

Epoch: 5| Step: 3
Training loss: 1.3256003856658936
Validation loss: 2.146842997561219

Epoch: 5| Step: 4
Training loss: 1.44037663936615
Validation loss: 2.0821969598852177

Epoch: 5| Step: 5
Training loss: 1.1302390098571777
Validation loss: 2.109440921455301

Epoch: 5| Step: 6
Training loss: 1.1794967651367188
Validation loss: 2.1356101958982405

Epoch: 5| Step: 7
Training loss: 1.529250144958496
Validation loss: 2.0747080079970823

Epoch: 5| Step: 8
Training loss: 1.354567050933838
Validation loss: 2.133728068362

Epoch: 5| Step: 9
Training loss: 1.5302472114562988
Validation loss: 2.127890812453403

Epoch: 5| Step: 10
Training loss: 1.142883062362671
Validation loss: 2.131157262350923

Epoch: 498| Step: 0
Training loss: 1.8318586349487305
Validation loss: 2.1421934609772055

Epoch: 5| Step: 1
Training loss: 0.947978675365448
Validation loss: 2.1203083017820954

Epoch: 5| Step: 2
Training loss: 1.8857065439224243
Validation loss: 2.15793707806577

Epoch: 5| Step: 3
Training loss: 1.781076431274414
Validation loss: 2.0706460655376477

Epoch: 5| Step: 4
Training loss: 1.4653384685516357
Validation loss: 2.127976937960553

Epoch: 5| Step: 5
Training loss: 0.8663734197616577
Validation loss: 2.1299957921428065

Epoch: 5| Step: 6
Training loss: 1.2152153253555298
Validation loss: 2.1408798079336844

Epoch: 5| Step: 7
Training loss: 1.1139466762542725
Validation loss: 2.159353406198563

Epoch: 5| Step: 8
Training loss: 1.2789905071258545
Validation loss: 2.130989864308347

Epoch: 5| Step: 9
Training loss: 1.3409638404846191
Validation loss: 2.099224336685673

Epoch: 5| Step: 10
Training loss: 1.1688522100448608
Validation loss: 2.0998880735007663

Epoch: 499| Step: 0
Training loss: 1.7271934747695923
Validation loss: 2.0944288392220773

Epoch: 5| Step: 1
Training loss: 1.2132397890090942
Validation loss: 2.1710380508053686

Epoch: 5| Step: 2
Training loss: 1.5232832431793213
Validation loss: 2.1568928431439143

Epoch: 5| Step: 3
Training loss: 0.9235233068466187
Validation loss: 2.193304051635086

Epoch: 5| Step: 4
Training loss: 0.6862114667892456
Validation loss: 2.1288765681687223

Epoch: 5| Step: 5
Training loss: 1.369728446006775
Validation loss: 2.1561739162732194

Epoch: 5| Step: 6
Training loss: 1.2415237426757812
Validation loss: 2.1406573992903515

Epoch: 5| Step: 7
Training loss: 1.2197368144989014
Validation loss: 2.078164041683238

Epoch: 5| Step: 8
Training loss: 1.3069530725479126
Validation loss: 2.120872474485828

Epoch: 5| Step: 9
Training loss: 1.9004828929901123
Validation loss: 2.115214219657324

Epoch: 5| Step: 10
Training loss: 1.8299033641815186
Validation loss: 2.159608241050474

Epoch: 500| Step: 0
Training loss: 0.8930416107177734
Validation loss: 2.117595123988326

Epoch: 5| Step: 1
Training loss: 1.4235765933990479
Validation loss: 2.1959853121029433

Epoch: 5| Step: 2
Training loss: 1.5464928150177002
Validation loss: 2.1043536240054714

Epoch: 5| Step: 3
Training loss: 1.4542173147201538
Validation loss: 2.131146313041769

Epoch: 5| Step: 4
Training loss: 1.4747064113616943
Validation loss: 2.1382453569801907

Epoch: 5| Step: 5
Training loss: 2.042494058609009
Validation loss: 2.113256582649805

Epoch: 5| Step: 6
Training loss: 1.3214001655578613
Validation loss: 2.0959248581240253

Epoch: 5| Step: 7
Training loss: 1.4372260570526123
Validation loss: 2.124587507658107

Epoch: 5| Step: 8
Training loss: 1.3442869186401367
Validation loss: 2.091433148230276

Epoch: 5| Step: 9
Training loss: 1.2947139739990234
Validation loss: 2.050046479830178

Epoch: 5| Step: 10
Training loss: 1.2619961500167847
Validation loss: 2.0565152322092364

Epoch: 501| Step: 0
Training loss: 1.159915566444397
Validation loss: 2.089137085022465

Epoch: 5| Step: 1
Training loss: 1.1095958948135376
Validation loss: 2.1443615190444456

Epoch: 5| Step: 2
Training loss: 1.480940580368042
Validation loss: 2.1850887062729045

Epoch: 5| Step: 3
Training loss: 1.4799658060073853
Validation loss: 2.1695823720706406

Epoch: 5| Step: 4
Training loss: 1.729442834854126
Validation loss: 2.075739704152589

Epoch: 5| Step: 5
Training loss: 1.8275954723358154
Validation loss: 2.1638373174974994

Epoch: 5| Step: 6
Training loss: 1.6520004272460938
Validation loss: 2.212596320336865

Epoch: 5| Step: 7
Training loss: 1.0813270807266235
Validation loss: 2.2215411675873624

Epoch: 5| Step: 8
Training loss: 1.1936466693878174
Validation loss: 2.1567353215268863

Epoch: 5| Step: 9
Training loss: 1.8238502740859985
Validation loss: 2.1908862642062608

Epoch: 5| Step: 10
Training loss: 1.0362764596939087
Validation loss: 2.2021253813979444

Epoch: 502| Step: 0
Training loss: 1.5368274450302124
Validation loss: 2.168997037795282

Epoch: 5| Step: 1
Training loss: 1.3868759870529175
Validation loss: 2.1965060234069824

Epoch: 5| Step: 2
Training loss: 1.146692156791687
Validation loss: 2.2007604363144084

Epoch: 5| Step: 3
Training loss: 1.5357625484466553
Validation loss: 2.1681943067940335

Epoch: 5| Step: 4
Training loss: 1.6985492706298828
Validation loss: 2.2112336492025726

Epoch: 5| Step: 5
Training loss: 1.4938188791275024
Validation loss: 2.16613709029331

Epoch: 5| Step: 6
Training loss: 0.8248926401138306
Validation loss: 2.1992252744654173

Epoch: 5| Step: 7
Training loss: 1.4808704853057861
Validation loss: 2.1926987119900283

Epoch: 5| Step: 8
Training loss: 1.6051486730575562
Validation loss: 2.1275771612762124

Epoch: 5| Step: 9
Training loss: 1.1953226327896118
Validation loss: 2.0888299275470037

Epoch: 5| Step: 10
Training loss: 1.0638506412506104
Validation loss: 2.132041818352156

Epoch: 503| Step: 0
Training loss: 0.8911842107772827
Validation loss: 2.104753384026148

Epoch: 5| Step: 1
Training loss: 1.305739164352417
Validation loss: 2.096832629173033

Epoch: 5| Step: 2
Training loss: 2.1758460998535156
Validation loss: 2.1200405397722797

Epoch: 5| Step: 3
Training loss: 0.9800857305526733
Validation loss: 2.121218655699043

Epoch: 5| Step: 4
Training loss: 1.7459386587142944
Validation loss: 2.1288486821677095

Epoch: 5| Step: 5
Training loss: 0.9831945300102234
Validation loss: 2.1008133901062833

Epoch: 5| Step: 6
Training loss: 1.5774948596954346
Validation loss: 2.147357395900193

Epoch: 5| Step: 7
Training loss: 1.7045156955718994
Validation loss: 2.0752838183474798

Epoch: 5| Step: 8
Training loss: 0.9846574664115906
Validation loss: 2.144695479382751

Epoch: 5| Step: 9
Training loss: 1.693027138710022
Validation loss: 2.1472361933800483

Epoch: 5| Step: 10
Training loss: 1.1411194801330566
Validation loss: 2.119539855628885

Epoch: 504| Step: 0
Training loss: 1.2199379205703735
Validation loss: 2.11452111505693

Epoch: 5| Step: 1
Training loss: 1.383487343788147
Validation loss: 2.071477684923398

Epoch: 5| Step: 2
Training loss: 0.8498940467834473
Validation loss: 2.1415117863685853

Epoch: 5| Step: 3
Training loss: 1.5733355283737183
Validation loss: 2.1671571577748945

Epoch: 5| Step: 4
Training loss: 1.6108213663101196
Validation loss: 2.1609041767735637

Epoch: 5| Step: 5
Training loss: 1.0811398029327393
Validation loss: 2.2086034538925334

Epoch: 5| Step: 6
Training loss: 1.9262787103652954
Validation loss: 2.1199960195890037

Epoch: 5| Step: 7
Training loss: 1.6239345073699951
Validation loss: 2.15211066379342

Epoch: 5| Step: 8
Training loss: 1.3673756122589111
Validation loss: 2.1179688540838097

Epoch: 5| Step: 9
Training loss: 1.3358988761901855
Validation loss: 2.1681862851624847

Epoch: 5| Step: 10
Training loss: 1.5679031610488892
Validation loss: 2.1160905514993975

Epoch: 505| Step: 0
Training loss: 1.7770885229110718
Validation loss: 2.10539755000863

Epoch: 5| Step: 1
Training loss: 1.4146490097045898
Validation loss: 2.140103486276442

Epoch: 5| Step: 2
Training loss: 1.057594656944275
Validation loss: 2.117939879817347

Epoch: 5| Step: 3
Training loss: 1.4953575134277344
Validation loss: 2.168404954735951

Epoch: 5| Step: 4
Training loss: 1.5906848907470703
Validation loss: 2.117433750501243

Epoch: 5| Step: 5
Training loss: 1.4610224962234497
Validation loss: 2.141090444339219

Epoch: 5| Step: 6
Training loss: 1.3904683589935303
Validation loss: 2.1322494296617407

Epoch: 5| Step: 7
Training loss: 0.6409820318222046
Validation loss: 2.088235665393132

Epoch: 5| Step: 8
Training loss: 1.5916383266448975
Validation loss: 2.1258381899966987

Epoch: 5| Step: 9
Training loss: 1.2432500123977661
Validation loss: 2.1364761398684595

Epoch: 5| Step: 10
Training loss: 1.0501614809036255
Validation loss: 2.1671230152089107

Epoch: 506| Step: 0
Training loss: 1.5497127771377563
Validation loss: 2.100112602274905

Epoch: 5| Step: 1
Training loss: 1.352446436882019
Validation loss: 2.1075221825671453

Epoch: 5| Step: 2
Training loss: 1.017633080482483
Validation loss: 2.1665993326453754

Epoch: 5| Step: 3
Training loss: 1.4276649951934814
Validation loss: 2.116144895553589

Epoch: 5| Step: 4
Training loss: 1.3139086961746216
Validation loss: 2.187888886338921

Epoch: 5| Step: 5
Training loss: 0.9149118661880493
Validation loss: 2.198256256759808

Epoch: 5| Step: 6
Training loss: 2.053825855255127
Validation loss: 2.153910247228479

Epoch: 5| Step: 7
Training loss: 1.2277324199676514
Validation loss: 2.157277194402551

Epoch: 5| Step: 8
Training loss: 1.7016160488128662
Validation loss: 2.141224866272301

Epoch: 5| Step: 9
Training loss: 1.5466827154159546
Validation loss: 2.1036659004867717

Epoch: 5| Step: 10
Training loss: 1.0564758777618408
Validation loss: 2.2076102956648795

Epoch: 507| Step: 0
Training loss: 1.3769842386245728
Validation loss: 2.120972143706455

Epoch: 5| Step: 1
Training loss: 1.362485408782959
Validation loss: 2.0851921625034784

Epoch: 5| Step: 2
Training loss: 1.7644507884979248
Validation loss: 2.1374914287238993

Epoch: 5| Step: 3
Training loss: 1.3138998746871948
Validation loss: 2.146470305740192

Epoch: 5| Step: 4
Training loss: 0.8378372192382812
Validation loss: 2.1244509681578605

Epoch: 5| Step: 5
Training loss: 1.064260482788086
Validation loss: 2.156187824023667

Epoch: 5| Step: 6
Training loss: 1.6485847234725952
Validation loss: 2.1609004030945482

Epoch: 5| Step: 7
Training loss: 1.407658576965332
Validation loss: 2.120468537012736

Epoch: 5| Step: 8
Training loss: 1.2434929609298706
Validation loss: 2.1768011226448962

Epoch: 5| Step: 9
Training loss: 1.3086477518081665
Validation loss: 2.1077258791974796

Epoch: 5| Step: 10
Training loss: 1.5653339624404907
Validation loss: 2.11090148392544

Epoch: 508| Step: 0
Training loss: 1.258180856704712
Validation loss: 2.1143818773249143

Epoch: 5| Step: 1
Training loss: 1.5359535217285156
Validation loss: 2.064807591899749

Epoch: 5| Step: 2
Training loss: 1.9415979385375977
Validation loss: 2.1333615677331084

Epoch: 5| Step: 3
Training loss: 1.095852255821228
Validation loss: 2.045111447252253

Epoch: 5| Step: 4
Training loss: 1.2802492380142212
Validation loss: 2.1166035500905847

Epoch: 5| Step: 5
Training loss: 1.1593122482299805
Validation loss: 2.1301496990265383

Epoch: 5| Step: 6
Training loss: 1.338576078414917
Validation loss: 2.0871729825132634

Epoch: 5| Step: 7
Training loss: 1.7954431772232056
Validation loss: 2.1203275777960338

Epoch: 5| Step: 8
Training loss: 1.8863792419433594
Validation loss: 2.138665947862851

Epoch: 5| Step: 9
Training loss: 1.296759843826294
Validation loss: 2.118474050234723

Epoch: 5| Step: 10
Training loss: 0.7976328730583191
Validation loss: 2.0875296400439356

Epoch: 509| Step: 0
Training loss: 1.4747998714447021
Validation loss: 2.0868745593614477

Epoch: 5| Step: 1
Training loss: 1.5123507976531982
Validation loss: 2.1353309103237685

Epoch: 5| Step: 2
Training loss: 1.530225157737732
Validation loss: 2.1502516372229463

Epoch: 5| Step: 3
Training loss: 1.1349657773971558
Validation loss: 2.1536064096676406

Epoch: 5| Step: 4
Training loss: 1.4492145776748657
Validation loss: 2.0971376267812585

Epoch: 5| Step: 5
Training loss: 1.4305444955825806
Validation loss: 2.098950773157099

Epoch: 5| Step: 6
Training loss: 1.0757863521575928
Validation loss: 2.173791229083974

Epoch: 5| Step: 7
Training loss: 1.0172101259231567
Validation loss: 2.1520773800470496

Epoch: 5| Step: 8
Training loss: 1.6776479482650757
Validation loss: 2.1451744981991347

Epoch: 5| Step: 9
Training loss: 1.7006752490997314
Validation loss: 2.1356040239334106

Epoch: 5| Step: 10
Training loss: 0.9060166478157043
Validation loss: 2.141956744655486

Epoch: 510| Step: 0
Training loss: 0.8961025476455688
Validation loss: 2.1205473266622072

Epoch: 5| Step: 1
Training loss: 1.6563800573349
Validation loss: 2.128417666240405

Epoch: 5| Step: 2
Training loss: 1.6501432657241821
Validation loss: 2.0984641992917625

Epoch: 5| Step: 3
Training loss: 1.501436471939087
Validation loss: 2.123187844471265

Epoch: 5| Step: 4
Training loss: 1.142722725868225
Validation loss: 2.145803657911157

Epoch: 5| Step: 5
Training loss: 1.1343014240264893
Validation loss: 2.128806011651152

Epoch: 5| Step: 6
Training loss: 1.4552643299102783
Validation loss: 2.1459834691016906

Epoch: 5| Step: 7
Training loss: 1.4106194972991943
Validation loss: 2.133138282324678

Epoch: 5| Step: 8
Training loss: 1.4984915256500244
Validation loss: 2.1180853638597714

Epoch: 5| Step: 9
Training loss: 1.188636064529419
Validation loss: 2.108233380061324

Epoch: 5| Step: 10
Training loss: 1.260439395904541
Validation loss: 2.0974417694153322

Epoch: 511| Step: 0
Training loss: 1.9636281728744507
Validation loss: 2.110891085799022

Epoch: 5| Step: 1
Training loss: 0.7333330512046814
Validation loss: 2.109338152793146

Epoch: 5| Step: 2
Training loss: 1.6175968647003174
Validation loss: 2.109513990340694

Epoch: 5| Step: 3
Training loss: 1.38277268409729
Validation loss: 2.085607518431961

Epoch: 5| Step: 4
Training loss: 1.447036862373352
Validation loss: 2.075132264885851

Epoch: 5| Step: 5
Training loss: 1.0307481288909912
Validation loss: 2.1101414888135848

Epoch: 5| Step: 6
Training loss: 1.4679330587387085
Validation loss: 2.092147281092982

Epoch: 5| Step: 7
Training loss: 1.324523687362671
Validation loss: 2.1396478504262944

Epoch: 5| Step: 8
Training loss: 1.5040665864944458
Validation loss: 2.126211121518125

Epoch: 5| Step: 9
Training loss: 1.010769009590149
Validation loss: 2.097191079970329

Epoch: 5| Step: 10
Training loss: 1.7076835632324219
Validation loss: 2.1479621253987795

Epoch: 512| Step: 0
Training loss: 0.7830678224563599
Validation loss: 2.124204276710428

Epoch: 5| Step: 1
Training loss: 1.5343244075775146
Validation loss: 2.075046177833311

Epoch: 5| Step: 2
Training loss: 1.6828657388687134
Validation loss: 2.135325595896731

Epoch: 5| Step: 3
Training loss: 1.5415756702423096
Validation loss: 2.1407513490287204

Epoch: 5| Step: 4
Training loss: 1.4230800867080688
Validation loss: 2.1021002620779057

Epoch: 5| Step: 5
Training loss: 1.2776563167572021
Validation loss: 2.1195063578185214

Epoch: 5| Step: 6
Training loss: 1.1270869970321655
Validation loss: 2.1277078120939192

Epoch: 5| Step: 7
Training loss: 1.4044955968856812
Validation loss: 2.1407551726987286

Epoch: 5| Step: 8
Training loss: 1.17767333984375
Validation loss: 2.081400804622199

Epoch: 5| Step: 9
Training loss: 1.6070048809051514
Validation loss: 2.1024434028133268

Epoch: 5| Step: 10
Training loss: 1.1317611932754517
Validation loss: 2.1503387240953344

Epoch: 513| Step: 0
Training loss: 1.416884183883667
Validation loss: 2.123294658558343

Epoch: 5| Step: 1
Training loss: 1.2853244543075562
Validation loss: 2.160748653514411

Epoch: 5| Step: 2
Training loss: 1.3861539363861084
Validation loss: 2.1578279079929477

Epoch: 5| Step: 3
Training loss: 1.478205919265747
Validation loss: 2.1557512014142928

Epoch: 5| Step: 4
Training loss: 1.1458356380462646
Validation loss: 2.106447782567752

Epoch: 5| Step: 5
Training loss: 1.417205810546875
Validation loss: 2.1649967547385924

Epoch: 5| Step: 6
Training loss: 1.2442971467971802
Validation loss: 2.1518894703157487

Epoch: 5| Step: 7
Training loss: 1.5153142213821411
Validation loss: 2.163769970658005

Epoch: 5| Step: 8
Training loss: 1.540452003479004
Validation loss: 2.0796771510954826

Epoch: 5| Step: 9
Training loss: 1.2273987531661987
Validation loss: 2.1401928009525424

Epoch: 5| Step: 10
Training loss: 1.3821998834609985
Validation loss: 2.0868710856283865

Epoch: 514| Step: 0
Training loss: 1.500840425491333
Validation loss: 2.1575459164957844

Epoch: 5| Step: 1
Training loss: 1.7888195514678955
Validation loss: 2.1018750283025924

Epoch: 5| Step: 2
Training loss: 1.1062146425247192
Validation loss: 2.087146738524078

Epoch: 5| Step: 3
Training loss: 1.322801113128662
Validation loss: 2.074491165017569

Epoch: 5| Step: 4
Training loss: 1.3853819370269775
Validation loss: 2.0844422424993208

Epoch: 5| Step: 5
Training loss: 1.063865065574646
Validation loss: 2.102085708290018

Epoch: 5| Step: 6
Training loss: 1.2583255767822266
Validation loss: 2.1540035252930014

Epoch: 5| Step: 7
Training loss: 1.1697548627853394
Validation loss: 2.0771959738064836

Epoch: 5| Step: 8
Training loss: 1.8089277744293213
Validation loss: 2.1615376036654235

Epoch: 5| Step: 9
Training loss: 0.8738687634468079
Validation loss: 2.1443407202279694

Epoch: 5| Step: 10
Training loss: 1.5742305517196655
Validation loss: 2.116984518625403

Epoch: 515| Step: 0
Training loss: 1.5140928030014038
Validation loss: 2.1030378956948557

Epoch: 5| Step: 1
Training loss: 1.623974084854126
Validation loss: 2.0852523132037093

Epoch: 5| Step: 2
Training loss: 1.714362382888794
Validation loss: 2.1173790885556127

Epoch: 5| Step: 3
Training loss: 0.7243759036064148
Validation loss: 2.1499973407355686

Epoch: 5| Step: 4
Training loss: 1.0779378414154053
Validation loss: 2.1321183148250786

Epoch: 5| Step: 5
Training loss: 1.3717831373214722
Validation loss: 2.1587216777186238

Epoch: 5| Step: 6
Training loss: 1.0996570587158203
Validation loss: 2.0972490951579106

Epoch: 5| Step: 7
Training loss: 1.2784087657928467
Validation loss: 2.0787362667822067

Epoch: 5| Step: 8
Training loss: 1.2273855209350586
Validation loss: 2.1115340930159374

Epoch: 5| Step: 9
Training loss: 1.502175211906433
Validation loss: 2.1314806938171387

Epoch: 5| Step: 10
Training loss: 1.5974540710449219
Validation loss: 2.129837574497346

Epoch: 516| Step: 0
Training loss: 1.9248396158218384
Validation loss: 2.1608839573398715

Epoch: 5| Step: 1
Training loss: 1.0457351207733154
Validation loss: 2.1181688770171134

Epoch: 5| Step: 2
Training loss: 1.546117901802063
Validation loss: 2.107362237027896

Epoch: 5| Step: 3
Training loss: 1.246891736984253
Validation loss: 2.1132797182247205

Epoch: 5| Step: 4
Training loss: 1.3903870582580566
Validation loss: 2.1466819560655983

Epoch: 5| Step: 5
Training loss: 1.2387017011642456
Validation loss: 2.1017071970047487

Epoch: 5| Step: 6
Training loss: 1.4204819202423096
Validation loss: 2.109701951344808

Epoch: 5| Step: 7
Training loss: 1.5294873714447021
Validation loss: 2.0874742128515757

Epoch: 5| Step: 8
Training loss: 0.8682315945625305
Validation loss: 2.1430436975212506

Epoch: 5| Step: 9
Training loss: 1.6468994617462158
Validation loss: 2.133627341639611

Epoch: 5| Step: 10
Training loss: 1.0009219646453857
Validation loss: 2.1715132767154324

Epoch: 517| Step: 0
Training loss: 1.3175972700119019
Validation loss: 2.0898373652529973

Epoch: 5| Step: 1
Training loss: 1.631262183189392
Validation loss: 2.127708526067836

Epoch: 5| Step: 2
Training loss: 1.1389809846878052
Validation loss: 2.095417170114415

Epoch: 5| Step: 3
Training loss: 1.757014274597168
Validation loss: 2.082966084121376

Epoch: 5| Step: 4
Training loss: 1.2270444631576538
Validation loss: 2.1394853233009257

Epoch: 5| Step: 5
Training loss: 1.6632328033447266
Validation loss: 2.149157824054841

Epoch: 5| Step: 6
Training loss: 1.5092525482177734
Validation loss: 2.035019290062689

Epoch: 5| Step: 7
Training loss: 1.3697055578231812
Validation loss: 2.11686324432332

Epoch: 5| Step: 8
Training loss: 0.9201553463935852
Validation loss: 2.0685797045307774

Epoch: 5| Step: 9
Training loss: 1.2665876150131226
Validation loss: 2.0978423664646764

Epoch: 5| Step: 10
Training loss: 0.9496287107467651
Validation loss: 2.1627065853406022

Epoch: 518| Step: 0
Training loss: 1.1239039897918701
Validation loss: 2.1676501022872103

Epoch: 5| Step: 1
Training loss: 1.21688711643219
Validation loss: 2.1203534833846556

Epoch: 5| Step: 2
Training loss: 1.3282744884490967
Validation loss: 2.0932948256051667

Epoch: 5| Step: 3
Training loss: 0.904937744140625
Validation loss: 2.1171817125812655

Epoch: 5| Step: 4
Training loss: 1.6941673755645752
Validation loss: 2.148971737072032

Epoch: 5| Step: 5
Training loss: 1.076616644859314
Validation loss: 2.1227217566582466

Epoch: 5| Step: 6
Training loss: 2.0108397006988525
Validation loss: 2.1522980531056723

Epoch: 5| Step: 7
Training loss: 1.3880653381347656
Validation loss: 2.1138437191645303

Epoch: 5| Step: 8
Training loss: 1.518484354019165
Validation loss: 2.1016952914576374

Epoch: 5| Step: 9
Training loss: 1.1009691953659058
Validation loss: 2.1271399067294214

Epoch: 5| Step: 10
Training loss: 1.5984010696411133
Validation loss: 2.132999579111735

Epoch: 519| Step: 0
Training loss: 0.8351259231567383
Validation loss: 2.0961113334983907

Epoch: 5| Step: 1
Training loss: 1.4679269790649414
Validation loss: 2.1686246164383425

Epoch: 5| Step: 2
Training loss: 1.2020940780639648
Validation loss: 2.1343088842207387

Epoch: 5| Step: 3
Training loss: 1.5599017143249512
Validation loss: 2.1284193633705057

Epoch: 5| Step: 4
Training loss: 1.5875370502471924
Validation loss: 2.164240308987197

Epoch: 5| Step: 5
Training loss: 1.090928077697754
Validation loss: 2.101333220799764

Epoch: 5| Step: 6
Training loss: 1.423546314239502
Validation loss: 2.1220948426954207

Epoch: 5| Step: 7
Training loss: 1.5076615810394287
Validation loss: 2.102743641022713

Epoch: 5| Step: 8
Training loss: 1.3504985570907593
Validation loss: 2.140114640676847

Epoch: 5| Step: 9
Training loss: 1.2135179042816162
Validation loss: 2.1060898547531455

Epoch: 5| Step: 10
Training loss: 1.2391366958618164
Validation loss: 2.1211589715814076

Epoch: 520| Step: 0
Training loss: 1.5664494037628174
Validation loss: 2.1284236318321637

Epoch: 5| Step: 1
Training loss: 1.026793122291565
Validation loss: 2.104920735923193

Epoch: 5| Step: 2
Training loss: 1.3700501918792725
Validation loss: 2.086825050333495

Epoch: 5| Step: 3
Training loss: 0.8006988763809204
Validation loss: 2.1189443706184306

Epoch: 5| Step: 4
Training loss: 1.4668395519256592
Validation loss: 2.103209269944058

Epoch: 5| Step: 5
Training loss: 1.0626798868179321
Validation loss: 2.0745670603167627

Epoch: 5| Step: 6
Training loss: 1.006264090538025
Validation loss: 2.1065371523621264

Epoch: 5| Step: 7
Training loss: 1.9424679279327393
Validation loss: 2.151969502049108

Epoch: 5| Step: 8
Training loss: 1.5517512559890747
Validation loss: 2.1258918623770438

Epoch: 5| Step: 9
Training loss: 1.5575569868087769
Validation loss: 2.151575273083102

Epoch: 5| Step: 10
Training loss: 1.3564233779907227
Validation loss: 2.1396510883044173

Epoch: 521| Step: 0
Training loss: 1.2420936822891235
Validation loss: 2.0421983849617744

Epoch: 5| Step: 1
Training loss: 1.7782570123672485
Validation loss: 2.1831290119437763

Epoch: 5| Step: 2
Training loss: 1.206425428390503
Validation loss: 2.152406415631694

Epoch: 5| Step: 3
Training loss: 0.9111860394477844
Validation loss: 2.1013026378488027

Epoch: 5| Step: 4
Training loss: 1.9641860723495483
Validation loss: 2.149651804277974

Epoch: 5| Step: 5
Training loss: 1.0502262115478516
Validation loss: 2.1365878556364324

Epoch: 5| Step: 6
Training loss: 1.5245468616485596
Validation loss: 2.1611886588476037

Epoch: 5| Step: 7
Training loss: 1.152045488357544
Validation loss: 2.190377079030519

Epoch: 5| Step: 8
Training loss: 1.2048518657684326
Validation loss: 2.18523306744073

Epoch: 5| Step: 9
Training loss: 1.1732571125030518
Validation loss: 2.119450230752268

Epoch: 5| Step: 10
Training loss: 1.5345001220703125
Validation loss: 2.1051066511420795

Epoch: 522| Step: 0
Training loss: 1.6667382717132568
Validation loss: 2.094268814209969

Epoch: 5| Step: 1
Training loss: 1.6345866918563843
Validation loss: 2.1130904100274526

Epoch: 5| Step: 2
Training loss: 1.0661197900772095
Validation loss: 2.097816110939108

Epoch: 5| Step: 3
Training loss: 1.2995003461837769
Validation loss: 2.13459022327136

Epoch: 5| Step: 4
Training loss: 0.9812908172607422
Validation loss: 2.1011347604054276

Epoch: 5| Step: 5
Training loss: 1.4670960903167725
Validation loss: 2.0988231961445143

Epoch: 5| Step: 6
Training loss: 1.364648461341858
Validation loss: 2.1761996848608858

Epoch: 5| Step: 7
Training loss: 1.2143528461456299
Validation loss: 2.117960370996947

Epoch: 5| Step: 8
Training loss: 1.370500087738037
Validation loss: 2.065742423457484

Epoch: 5| Step: 9
Training loss: 1.5594041347503662
Validation loss: 2.088963818806474

Epoch: 5| Step: 10
Training loss: 0.9022814035415649
Validation loss: 2.089823558766355

Epoch: 523| Step: 0
Training loss: 1.4549356698989868
Validation loss: 2.098446221761806

Epoch: 5| Step: 1
Training loss: 1.230326771736145
Validation loss: 2.115302265331309

Epoch: 5| Step: 2
Training loss: 1.394963026046753
Validation loss: 2.1280744306502806

Epoch: 5| Step: 3
Training loss: 1.3625168800354004
Validation loss: 2.1879596069294918

Epoch: 5| Step: 4
Training loss: 1.0628573894500732
Validation loss: 2.1524546248938448

Epoch: 5| Step: 5
Training loss: 1.0410096645355225
Validation loss: 2.152875324731232

Epoch: 5| Step: 6
Training loss: 1.0628491640090942
Validation loss: 2.1327298456622708

Epoch: 5| Step: 7
Training loss: 1.92929208278656
Validation loss: 2.1439530195728427

Epoch: 5| Step: 8
Training loss: 1.9704653024673462
Validation loss: 2.1555609267245055

Epoch: 5| Step: 9
Training loss: 1.1452094316482544
Validation loss: 2.085038637602201

Epoch: 5| Step: 10
Training loss: 1.3212759494781494
Validation loss: 2.1215301354726157

Epoch: 524| Step: 0
Training loss: 1.2217400074005127
Validation loss: 2.115244245016447

Epoch: 5| Step: 1
Training loss: 1.0845515727996826
Validation loss: 2.1042216695765013

Epoch: 5| Step: 2
Training loss: 1.3010060787200928
Validation loss: 2.078259201459987

Epoch: 5| Step: 3
Training loss: 1.3703306913375854
Validation loss: 2.127115471388704

Epoch: 5| Step: 4
Training loss: 1.0744930505752563
Validation loss: 2.1465266494340796

Epoch: 5| Step: 5
Training loss: 1.7809299230575562
Validation loss: 2.1147401819946947

Epoch: 5| Step: 6
Training loss: 0.9150105714797974
Validation loss: 2.090673638928321

Epoch: 5| Step: 7
Training loss: 1.8394367694854736
Validation loss: 2.101362298893672

Epoch: 5| Step: 8
Training loss: 1.3222415447235107
Validation loss: 2.1128100874603435

Epoch: 5| Step: 9
Training loss: 1.3114451169967651
Validation loss: 2.1076409432195846

Epoch: 5| Step: 10
Training loss: 1.4216089248657227
Validation loss: 2.092334629386984

Epoch: 525| Step: 0
Training loss: 1.1724016666412354
Validation loss: 2.1076331882066626

Epoch: 5| Step: 1
Training loss: 1.2609513998031616
Validation loss: 2.109073528679468

Epoch: 5| Step: 2
Training loss: 1.3489104509353638
Validation loss: 2.0854870350130144

Epoch: 5| Step: 3
Training loss: 1.5736300945281982
Validation loss: 2.0830525249563236

Epoch: 5| Step: 4
Training loss: 1.155932068824768
Validation loss: 2.1155075232187905

Epoch: 5| Step: 5
Training loss: 1.7335315942764282
Validation loss: 2.0711201493458082

Epoch: 5| Step: 6
Training loss: 1.3134435415267944
Validation loss: 2.0601889061671432

Epoch: 5| Step: 7
Training loss: 1.474982500076294
Validation loss: 2.1058831445632444

Epoch: 5| Step: 8
Training loss: 1.5567411184310913
Validation loss: 2.142903616351466

Epoch: 5| Step: 9
Training loss: 1.146402359008789
Validation loss: 2.1210202068410893

Epoch: 5| Step: 10
Training loss: 1.0388901233673096
Validation loss: 2.1064284001627276

Epoch: 526| Step: 0
Training loss: 1.380406141281128
Validation loss: 2.1365076905937603

Epoch: 5| Step: 1
Training loss: 1.7743803262710571
Validation loss: 2.0978913396917362

Epoch: 5| Step: 2
Training loss: 0.7147910594940186
Validation loss: 2.1476933033235612

Epoch: 5| Step: 3
Training loss: 1.6370031833648682
Validation loss: 2.0855628469938874

Epoch: 5| Step: 4
Training loss: 1.0220134258270264
Validation loss: 2.1115933336237425

Epoch: 5| Step: 5
Training loss: 1.4003140926361084
Validation loss: 2.1315959294637046

Epoch: 5| Step: 6
Training loss: 1.4209474325180054
Validation loss: 2.1257675001698155

Epoch: 5| Step: 7
Training loss: 1.4606177806854248
Validation loss: 2.1088583495027278

Epoch: 5| Step: 8
Training loss: 1.3119916915893555
Validation loss: 2.139068954734392

Epoch: 5| Step: 9
Training loss: 1.540584921836853
Validation loss: 2.151297523129371

Epoch: 5| Step: 10
Training loss: 1.2453584671020508
Validation loss: 2.094816246340352

Epoch: 527| Step: 0
Training loss: 1.2103686332702637
Validation loss: 2.069006020022977

Epoch: 5| Step: 1
Training loss: 0.8322817087173462
Validation loss: 2.116890826532918

Epoch: 5| Step: 2
Training loss: 1.4713999032974243
Validation loss: 2.1386359686492593

Epoch: 5| Step: 3
Training loss: 1.2049105167388916
Validation loss: 2.1073135509285876

Epoch: 5| Step: 4
Training loss: 1.7626720666885376
Validation loss: 2.133234457303119

Epoch: 5| Step: 5
Training loss: 0.9558085203170776
Validation loss: 2.1059768635739564

Epoch: 5| Step: 6
Training loss: 1.2693712711334229
Validation loss: 2.1244305308147142

Epoch: 5| Step: 7
Training loss: 1.0926958322525024
Validation loss: 2.0899766619487474

Epoch: 5| Step: 8
Training loss: 1.5835434198379517
Validation loss: 2.155778528541647

Epoch: 5| Step: 9
Training loss: 1.6433391571044922
Validation loss: 2.1243372886411604

Epoch: 5| Step: 10
Training loss: 1.7808411121368408
Validation loss: 2.16741354491121

Epoch: 528| Step: 0
Training loss: 1.3804420232772827
Validation loss: 2.1324483092113207

Epoch: 5| Step: 1
Training loss: 1.8066375255584717
Validation loss: 2.1493121398392545

Epoch: 5| Step: 2
Training loss: 1.3199158906936646
Validation loss: 2.1791938940684

Epoch: 5| Step: 3
Training loss: 1.2558948993682861
Validation loss: 2.2003062386666574

Epoch: 5| Step: 4
Training loss: 1.2766834497451782
Validation loss: 2.143061269995987

Epoch: 5| Step: 5
Training loss: 1.13211989402771
Validation loss: 2.1284917734002553

Epoch: 5| Step: 6
Training loss: 1.1460546255111694
Validation loss: 2.155662754530548

Epoch: 5| Step: 7
Training loss: 2.003826856613159
Validation loss: 2.126701337034984

Epoch: 5| Step: 8
Training loss: 1.3380687236785889
Validation loss: 2.152424071424751

Epoch: 5| Step: 9
Training loss: 0.9561694264411926
Validation loss: 2.1800085959895963

Epoch: 5| Step: 10
Training loss: 1.0543603897094727
Validation loss: 2.1315922429484706

Epoch: 529| Step: 0
Training loss: 1.9827388525009155
Validation loss: 2.140788132144559

Epoch: 5| Step: 1
Training loss: 1.4402778148651123
Validation loss: 2.1662937210452173

Epoch: 5| Step: 2
Training loss: 1.559280514717102
Validation loss: 2.1516309310031194

Epoch: 5| Step: 3
Training loss: 1.2915233373641968
Validation loss: 2.1629053597809165

Epoch: 5| Step: 4
Training loss: 0.895123302936554
Validation loss: 2.124562653162146

Epoch: 5| Step: 5
Training loss: 1.5015003681182861
Validation loss: 2.1031827131907144

Epoch: 5| Step: 6
Training loss: 1.275162935256958
Validation loss: 2.075896737396076

Epoch: 5| Step: 7
Training loss: 1.3991665840148926
Validation loss: 2.1356216361445766

Epoch: 5| Step: 8
Training loss: 1.0115361213684082
Validation loss: 2.1181123948866323

Epoch: 5| Step: 9
Training loss: 1.301790475845337
Validation loss: 2.074981206206865

Epoch: 5| Step: 10
Training loss: 0.9187241792678833
Validation loss: 2.0820699994282057

Epoch: 530| Step: 0
Training loss: 1.4151545763015747
Validation loss: 2.0787930193767754

Epoch: 5| Step: 1
Training loss: 1.5177557468414307
Validation loss: 2.1085484540590675

Epoch: 5| Step: 2
Training loss: 1.2998502254486084
Validation loss: 2.123004226274388

Epoch: 5| Step: 3
Training loss: 1.005112648010254
Validation loss: 2.080514515599897

Epoch: 5| Step: 4
Training loss: 1.1011945009231567
Validation loss: 2.1530242709703344

Epoch: 5| Step: 5
Training loss: 1.1854642629623413
Validation loss: 2.078349409564849

Epoch: 5| Step: 6
Training loss: 1.1903451681137085
Validation loss: 2.070488202956415

Epoch: 5| Step: 7
Training loss: 1.4473985433578491
Validation loss: 2.099335862744239

Epoch: 5| Step: 8
Training loss: 1.590028166770935
Validation loss: 2.0855391845908215

Epoch: 5| Step: 9
Training loss: 1.169950246810913
Validation loss: 2.070579013516826

Epoch: 5| Step: 10
Training loss: 1.4160139560699463
Validation loss: 2.1367154723854473

Epoch: 531| Step: 0
Training loss: 1.420612096786499
Validation loss: 2.1449750097849036

Epoch: 5| Step: 1
Training loss: 1.6032397747039795
Validation loss: 2.138724603960591

Epoch: 5| Step: 2
Training loss: 0.9256521463394165
Validation loss: 2.0382107765443864

Epoch: 5| Step: 3
Training loss: 1.3383605480194092
Validation loss: 2.0851217892862137

Epoch: 5| Step: 4
Training loss: 1.1293365955352783
Validation loss: 2.1003968510576474

Epoch: 5| Step: 5
Training loss: 1.1474403142929077
Validation loss: 2.1081716219584146

Epoch: 5| Step: 6
Training loss: 1.0270607471466064
Validation loss: 2.122683007230041

Epoch: 5| Step: 7
Training loss: 1.812961220741272
Validation loss: 2.1107600273624545

Epoch: 5| Step: 8
Training loss: 1.5514627695083618
Validation loss: 2.1226290554128666

Epoch: 5| Step: 9
Training loss: 1.1764084100723267
Validation loss: 2.1260400484966975

Epoch: 5| Step: 10
Training loss: 1.378178358078003
Validation loss: 2.1363778011773222

Epoch: 532| Step: 0
Training loss: 1.6227829456329346
Validation loss: 2.138915264478294

Epoch: 5| Step: 1
Training loss: 0.5611740350723267
Validation loss: 2.0875721823784614

Epoch: 5| Step: 2
Training loss: 1.8747546672821045
Validation loss: 2.181209662909149

Epoch: 5| Step: 3
Training loss: 1.229628324508667
Validation loss: 2.122675085580477

Epoch: 5| Step: 4
Training loss: 1.0782452821731567
Validation loss: 2.137671788533529

Epoch: 5| Step: 5
Training loss: 1.5774856805801392
Validation loss: 2.1411611880025556

Epoch: 5| Step: 6
Training loss: 1.5460538864135742
Validation loss: 2.1172855272088

Epoch: 5| Step: 7
Training loss: 1.3263647556304932
Validation loss: 2.1464644093667307

Epoch: 5| Step: 8
Training loss: 1.3786698579788208
Validation loss: 2.163028806768438

Epoch: 5| Step: 9
Training loss: 1.3085743188858032
Validation loss: 2.1425399344454528

Epoch: 5| Step: 10
Training loss: 1.0366624593734741
Validation loss: 2.190822027062857

Epoch: 533| Step: 0
Training loss: 0.9770660400390625
Validation loss: 2.156447711811271

Epoch: 5| Step: 1
Training loss: 1.362218976020813
Validation loss: 2.101613190866286

Epoch: 5| Step: 2
Training loss: 1.4912437200546265
Validation loss: 2.1264178804171983

Epoch: 5| Step: 3
Training loss: 1.1733907461166382
Validation loss: 2.1117218309833157

Epoch: 5| Step: 4
Training loss: 1.3239209651947021
Validation loss: 2.096818116403395

Epoch: 5| Step: 5
Training loss: 1.4840577840805054
Validation loss: 2.0966404599528157

Epoch: 5| Step: 6
Training loss: 1.3792626857757568
Validation loss: 2.0276613517474105

Epoch: 5| Step: 7
Training loss: 1.5446231365203857
Validation loss: 2.0715652986239363

Epoch: 5| Step: 8
Training loss: 1.5340290069580078
Validation loss: 2.1034783932470504

Epoch: 5| Step: 9
Training loss: 1.1030116081237793
Validation loss: 2.112495573618079

Epoch: 5| Step: 10
Training loss: 1.2652459144592285
Validation loss: 2.1694135781257384

Epoch: 534| Step: 0
Training loss: 1.2034350633621216
Validation loss: 2.1243544650334183

Epoch: 5| Step: 1
Training loss: 1.2025032043457031
Validation loss: 2.1230287103242773

Epoch: 5| Step: 2
Training loss: 1.8209335803985596
Validation loss: 2.0976756990596814

Epoch: 5| Step: 3
Training loss: 0.9409483075141907
Validation loss: 2.142618369030696

Epoch: 5| Step: 4
Training loss: 0.7342050671577454
Validation loss: 2.1290806160178235

Epoch: 5| Step: 5
Training loss: 1.1736706495285034
Validation loss: 2.0400555620911303

Epoch: 5| Step: 6
Training loss: 1.5118200778961182
Validation loss: 2.1010042018787836

Epoch: 5| Step: 7
Training loss: 1.70758855342865
Validation loss: 2.09619402885437

Epoch: 5| Step: 8
Training loss: 0.8675861358642578
Validation loss: 2.080766539419851

Epoch: 5| Step: 9
Training loss: 1.5250976085662842
Validation loss: 2.122507628574166

Epoch: 5| Step: 10
Training loss: 1.3920973539352417
Validation loss: 2.1109210111761607

Epoch: 535| Step: 0
Training loss: 1.582796335220337
Validation loss: 2.1752254450193016

Epoch: 5| Step: 1
Training loss: 1.0249379873275757
Validation loss: 2.0822489902537358

Epoch: 5| Step: 2
Training loss: 0.7623469233512878
Validation loss: 2.1601960274481002

Epoch: 5| Step: 3
Training loss: 1.8678327798843384
Validation loss: 2.096124869520946

Epoch: 5| Step: 4
Training loss: 1.8629920482635498
Validation loss: 2.131230118454144

Epoch: 5| Step: 5
Training loss: 0.7726262211799622
Validation loss: 2.158387396925239

Epoch: 5| Step: 6
Training loss: 1.4442857503890991
Validation loss: 2.118694369510938

Epoch: 5| Step: 7
Training loss: 0.9522902369499207
Validation loss: 2.0838232809497463

Epoch: 5| Step: 8
Training loss: 1.2223438024520874
Validation loss: 2.119450285870542

Epoch: 5| Step: 9
Training loss: 1.7836185693740845
Validation loss: 2.0490744703559467

Epoch: 5| Step: 10
Training loss: 1.1827805042266846
Validation loss: 2.0989031458413727

Epoch: 536| Step: 0
Training loss: 1.0620726346969604
Validation loss: 2.1677875557253437

Epoch: 5| Step: 1
Training loss: 1.628308653831482
Validation loss: 2.1286376368614937

Epoch: 5| Step: 2
Training loss: 1.1929670572280884
Validation loss: 2.1322100290688137

Epoch: 5| Step: 3
Training loss: 1.15375816822052
Validation loss: 2.162947981588302

Epoch: 5| Step: 4
Training loss: 1.2121860980987549
Validation loss: 2.0920764682113484

Epoch: 5| Step: 5
Training loss: 1.098261833190918
Validation loss: 2.1175374395103863

Epoch: 5| Step: 6
Training loss: 1.2393018007278442
Validation loss: 2.112080781690536

Epoch: 5| Step: 7
Training loss: 1.4903472661972046
Validation loss: 2.1306729598711898

Epoch: 5| Step: 8
Training loss: 1.518998384475708
Validation loss: 2.1461025489273893

Epoch: 5| Step: 9
Training loss: 1.4134154319763184
Validation loss: 2.144291603437034

Epoch: 5| Step: 10
Training loss: 1.5366500616073608
Validation loss: 2.0746831727284256

Epoch: 537| Step: 0
Training loss: 1.1512908935546875
Validation loss: 2.140972509179064

Epoch: 5| Step: 1
Training loss: 1.6831880807876587
Validation loss: 2.061137665984451

Epoch: 5| Step: 2
Training loss: 1.489600658416748
Validation loss: 2.159641860633768

Epoch: 5| Step: 3
Training loss: 1.3683154582977295
Validation loss: 2.112680405698797

Epoch: 5| Step: 4
Training loss: 1.335222840309143
Validation loss: 2.1590994827208982

Epoch: 5| Step: 5
Training loss: 1.4751484394073486
Validation loss: 2.0862181186676025

Epoch: 5| Step: 6
Training loss: 1.5651895999908447
Validation loss: 2.138748022817796

Epoch: 5| Step: 7
Training loss: 0.9729336500167847
Validation loss: 2.1195054784897835

Epoch: 5| Step: 8
Training loss: 1.3285634517669678
Validation loss: 2.0662254953897126

Epoch: 5| Step: 9
Training loss: 0.9559146165847778
Validation loss: 2.0825807253519693

Epoch: 5| Step: 10
Training loss: 1.17900812625885
Validation loss: 2.0842412210279897

Epoch: 538| Step: 0
Training loss: 1.2437198162078857
Validation loss: 2.1447278556003364

Epoch: 5| Step: 1
Training loss: 1.0067611932754517
Validation loss: 2.101189769724364

Epoch: 5| Step: 2
Training loss: 1.5964775085449219
Validation loss: 2.080529661588771

Epoch: 5| Step: 3
Training loss: 1.3373150825500488
Validation loss: 2.0802496030766475

Epoch: 5| Step: 4
Training loss: 1.5988315343856812
Validation loss: 2.072568414031818

Epoch: 5| Step: 5
Training loss: 1.4042993783950806
Validation loss: 2.0722482409528507

Epoch: 5| Step: 6
Training loss: 1.213553786277771
Validation loss: 2.0791722984724146

Epoch: 5| Step: 7
Training loss: 1.6876423358917236
Validation loss: 2.1196710550656883

Epoch: 5| Step: 8
Training loss: 1.30437433719635
Validation loss: 2.119984995934271

Epoch: 5| Step: 9
Training loss: 0.9197301864624023
Validation loss: 2.1508101301808513

Epoch: 5| Step: 10
Training loss: 1.2293808460235596
Validation loss: 2.1240030539933072

Epoch: 539| Step: 0
Training loss: 1.4324910640716553
Validation loss: 2.0895203980066444

Epoch: 5| Step: 1
Training loss: 1.411950945854187
Validation loss: 2.0849910705320296

Epoch: 5| Step: 2
Training loss: 1.3530099391937256
Validation loss: 2.092165639323573

Epoch: 5| Step: 3
Training loss: 1.6113624572753906
Validation loss: 2.1228647078237226

Epoch: 5| Step: 4
Training loss: 1.089207410812378
Validation loss: 2.1166296620522775

Epoch: 5| Step: 5
Training loss: 1.6599069833755493
Validation loss: 2.1143897195016184

Epoch: 5| Step: 6
Training loss: 1.147708773612976
Validation loss: 2.1367219186598256

Epoch: 5| Step: 7
Training loss: 1.1990312337875366
Validation loss: 2.1608282545561432

Epoch: 5| Step: 8
Training loss: 0.8272863626480103
Validation loss: 2.1157908824182328

Epoch: 5| Step: 9
Training loss: 1.2543447017669678
Validation loss: 2.081215573895362

Epoch: 5| Step: 10
Training loss: 1.2334260940551758
Validation loss: 2.0749886958829817

Epoch: 540| Step: 0
Training loss: 1.5434061288833618
Validation loss: 2.1138536225083056

Epoch: 5| Step: 1
Training loss: 1.4416756629943848
Validation loss: 2.103941349573033

Epoch: 5| Step: 2
Training loss: 0.9875724911689758
Validation loss: 2.1530671094053533

Epoch: 5| Step: 3
Training loss: 0.9917014837265015
Validation loss: 2.0720154085466937

Epoch: 5| Step: 4
Training loss: 0.8916481137275696
Validation loss: 2.109317528304233

Epoch: 5| Step: 5
Training loss: 1.0892490148544312
Validation loss: 2.1162251477600424

Epoch: 5| Step: 6
Training loss: 1.5325368642807007
Validation loss: 2.088152157363071

Epoch: 5| Step: 7
Training loss: 1.7057392597198486
Validation loss: 2.096318385934317

Epoch: 5| Step: 8
Training loss: 1.0221474170684814
Validation loss: 2.0828919846524476

Epoch: 5| Step: 9
Training loss: 1.6996383666992188
Validation loss: 2.1414678404408116

Epoch: 5| Step: 10
Training loss: 1.0964138507843018
Validation loss: 2.1404238003556446

Epoch: 541| Step: 0
Training loss: 1.8677542209625244
Validation loss: 2.1280307949230237

Epoch: 5| Step: 1
Training loss: 1.2201951742172241
Validation loss: 2.1627530872180896

Epoch: 5| Step: 2
Training loss: 1.2342294454574585
Validation loss: 2.120578988905876

Epoch: 5| Step: 3
Training loss: 1.1875275373458862
Validation loss: 2.112348428336523

Epoch: 5| Step: 4
Training loss: 0.8514738082885742
Validation loss: 2.1389498261995215

Epoch: 5| Step: 5
Training loss: 1.0072367191314697
Validation loss: 2.113133430480957

Epoch: 5| Step: 6
Training loss: 1.3177262544631958
Validation loss: 2.135465624511883

Epoch: 5| Step: 7
Training loss: 1.4752700328826904
Validation loss: 2.0767027742119244

Epoch: 5| Step: 8
Training loss: 1.389847755432129
Validation loss: 2.087415060689372

Epoch: 5| Step: 9
Training loss: 1.398382544517517
Validation loss: 2.110860199056646

Epoch: 5| Step: 10
Training loss: 1.3305960893630981
Validation loss: 2.111343183825093

Epoch: 542| Step: 0
Training loss: 1.532496690750122
Validation loss: 2.105290300102644

Epoch: 5| Step: 1
Training loss: 1.0655993223190308
Validation loss: 2.13946533203125

Epoch: 5| Step: 2
Training loss: 1.3542187213897705
Validation loss: 2.1470200566835302

Epoch: 5| Step: 3
Training loss: 1.3462305068969727
Validation loss: 2.1010497257273686

Epoch: 5| Step: 4
Training loss: 1.743251085281372
Validation loss: 2.132158890847237

Epoch: 5| Step: 5
Training loss: 1.0312778949737549
Validation loss: 2.114433488538188

Epoch: 5| Step: 6
Training loss: 1.1836886405944824
Validation loss: 2.082631290599864

Epoch: 5| Step: 7
Training loss: 1.5445544719696045
Validation loss: 2.1146724493272844

Epoch: 5| Step: 8
Training loss: 0.9644410014152527
Validation loss: 2.1487553606751146

Epoch: 5| Step: 9
Training loss: 1.4707729816436768
Validation loss: 2.1517616984664754

Epoch: 5| Step: 10
Training loss: 1.2241288423538208
Validation loss: 2.141475313453264

Epoch: 543| Step: 0
Training loss: 1.4309583902359009
Validation loss: 2.117367967482536

Epoch: 5| Step: 1
Training loss: 1.6203502416610718
Validation loss: 2.1883267792322303

Epoch: 5| Step: 2
Training loss: 1.3723742961883545
Validation loss: 2.119032867493168

Epoch: 5| Step: 3
Training loss: 1.3805357217788696
Validation loss: 2.1023306538981776

Epoch: 5| Step: 4
Training loss: 1.2089061737060547
Validation loss: 2.131451875932755

Epoch: 5| Step: 5
Training loss: 1.1693891286849976
Validation loss: 2.1504431668148247

Epoch: 5| Step: 6
Training loss: 1.2036879062652588
Validation loss: 2.0959627987236105

Epoch: 5| Step: 7
Training loss: 1.4904948472976685
Validation loss: 2.0628203756065777

Epoch: 5| Step: 8
Training loss: 1.0491105318069458
Validation loss: 2.094540379380667

Epoch: 5| Step: 9
Training loss: 1.1714000701904297
Validation loss: 2.0760664068242556

Epoch: 5| Step: 10
Training loss: 1.2658424377441406
Validation loss: 2.0267775289473997

Epoch: 544| Step: 0
Training loss: 1.219411849975586
Validation loss: 2.1150282300928587

Epoch: 5| Step: 1
Training loss: 1.205567717552185
Validation loss: 2.1062990401380803

Epoch: 5| Step: 2
Training loss: 1.4908151626586914
Validation loss: 2.1484007181659823

Epoch: 5| Step: 3
Training loss: 1.7609403133392334
Validation loss: 2.1071274921458256

Epoch: 5| Step: 4
Training loss: 1.0030269622802734
Validation loss: 2.1044892239314255

Epoch: 5| Step: 5
Training loss: 1.579658031463623
Validation loss: 2.0844788307784707

Epoch: 5| Step: 6
Training loss: 0.9298307299613953
Validation loss: 2.1122845193391204

Epoch: 5| Step: 7
Training loss: 1.505691409111023
Validation loss: 2.139833838708939

Epoch: 5| Step: 8
Training loss: 1.2343482971191406
Validation loss: 2.112551631466035

Epoch: 5| Step: 9
Training loss: 1.0731866359710693
Validation loss: 2.141398481143418

Epoch: 5| Step: 10
Training loss: 1.1180170774459839
Validation loss: 2.161385807939755

Epoch: 545| Step: 0
Training loss: 1.2764527797698975
Validation loss: 2.1547487833166636

Epoch: 5| Step: 1
Training loss: 0.5586005449295044
Validation loss: 2.118829281099381

Epoch: 5| Step: 2
Training loss: 2.3078396320343018
Validation loss: 2.1176677198820215

Epoch: 5| Step: 3
Training loss: 0.8771206140518188
Validation loss: 2.061082440037881

Epoch: 5| Step: 4
Training loss: 1.5539042949676514
Validation loss: 2.090298321939284

Epoch: 5| Step: 5
Training loss: 1.725322961807251
Validation loss: 2.113231341044108

Epoch: 5| Step: 6
Training loss: 1.231628179550171
Validation loss: 2.135768655807741

Epoch: 5| Step: 7
Training loss: 1.320854902267456
Validation loss: 2.1038838945409304

Epoch: 5| Step: 8
Training loss: 0.9558412432670593
Validation loss: 2.1209840146444177

Epoch: 5| Step: 9
Training loss: 1.4874672889709473
Validation loss: 2.1036196780461136

Epoch: 5| Step: 10
Training loss: 1.2546857595443726
Validation loss: 2.1343272398876887

Epoch: 546| Step: 0
Training loss: 0.9907641410827637
Validation loss: 2.0887546872579925

Epoch: 5| Step: 1
Training loss: 1.6507313251495361
Validation loss: 2.133581648590744

Epoch: 5| Step: 2
Training loss: 1.2176482677459717
Validation loss: 2.1648338494762296

Epoch: 5| Step: 3
Training loss: 1.0452860593795776
Validation loss: 2.066934190770631

Epoch: 5| Step: 4
Training loss: 0.9912474751472473
Validation loss: 2.0993652856478127

Epoch: 5| Step: 5
Training loss: 1.6595367193222046
Validation loss: 2.0483453978774366

Epoch: 5| Step: 6
Training loss: 0.9949876070022583
Validation loss: 2.1148104052389822

Epoch: 5| Step: 7
Training loss: 1.5433073043823242
Validation loss: 2.111632224052183

Epoch: 5| Step: 8
Training loss: 1.2776750326156616
Validation loss: 2.1135629864149195

Epoch: 5| Step: 9
Training loss: 1.0482029914855957
Validation loss: 2.1322453996186614

Epoch: 5| Step: 10
Training loss: 1.7160381078720093
Validation loss: 2.1250243186950684

Epoch: 547| Step: 0
Training loss: 0.9250547289848328
Validation loss: 2.139442161847186

Epoch: 5| Step: 1
Training loss: 1.1062816381454468
Validation loss: 2.1699152684980825

Epoch: 5| Step: 2
Training loss: 1.2891981601715088
Validation loss: 2.163364565500649

Epoch: 5| Step: 3
Training loss: 0.8308219909667969
Validation loss: 2.186741077771751

Epoch: 5| Step: 4
Training loss: 1.3637746572494507
Validation loss: 2.114409515934606

Epoch: 5| Step: 5
Training loss: 1.3295581340789795
Validation loss: 2.113843551246069

Epoch: 5| Step: 6
Training loss: 1.6714109182357788
Validation loss: 2.1039279507052515

Epoch: 5| Step: 7
Training loss: 1.3777649402618408
Validation loss: 2.1262320369802494

Epoch: 5| Step: 8
Training loss: 1.8487260341644287
Validation loss: 2.094123355803951

Epoch: 5| Step: 9
Training loss: 1.1440739631652832
Validation loss: 2.073300733361193

Epoch: 5| Step: 10
Training loss: 1.117133378982544
Validation loss: 2.0987995568142144

Epoch: 548| Step: 0
Training loss: 1.293699860572815
Validation loss: 2.0994735097372406

Epoch: 5| Step: 1
Training loss: 1.1929954290390015
Validation loss: 2.069852247033068

Epoch: 5| Step: 2
Training loss: 1.2977135181427002
Validation loss: 2.1856620568101124

Epoch: 5| Step: 3
Training loss: 1.4716436862945557
Validation loss: 2.076205943220405

Epoch: 5| Step: 4
Training loss: 1.518376111984253
Validation loss: 2.1253288407479562

Epoch: 5| Step: 5
Training loss: 1.5156198740005493
Validation loss: 2.138131667208928

Epoch: 5| Step: 6
Training loss: 1.3193528652191162
Validation loss: 2.1409034959731565

Epoch: 5| Step: 7
Training loss: 1.0723917484283447
Validation loss: 2.174578917923794

Epoch: 5| Step: 8
Training loss: 1.5564720630645752
Validation loss: 2.1798309485117593

Epoch: 5| Step: 9
Training loss: 1.1270440816879272
Validation loss: 2.0755487667616976

Epoch: 5| Step: 10
Training loss: 1.029598593711853
Validation loss: 2.1134003452075425

Epoch: 549| Step: 0
Training loss: 0.926740825176239
Validation loss: 2.135215191430943

Epoch: 5| Step: 1
Training loss: 1.2677181959152222
Validation loss: 2.125882843489288

Epoch: 5| Step: 2
Training loss: 1.2938358783721924
Validation loss: 2.1057462794806368

Epoch: 5| Step: 3
Training loss: 1.3490877151489258
Validation loss: 2.103785963468654

Epoch: 5| Step: 4
Training loss: 1.3062784671783447
Validation loss: 2.123802584986533

Epoch: 5| Step: 5
Training loss: 1.0435490608215332
Validation loss: 2.1162812761081162

Epoch: 5| Step: 6
Training loss: 1.0199005603790283
Validation loss: 2.16225363105856

Epoch: 5| Step: 7
Training loss: 1.3743093013763428
Validation loss: 2.136182000560145

Epoch: 5| Step: 8
Training loss: 1.6662002801895142
Validation loss: 2.0896267121837986

Epoch: 5| Step: 9
Training loss: 1.5924111604690552
Validation loss: 2.106670191211085

Epoch: 5| Step: 10
Training loss: 1.2955552339553833
Validation loss: 2.1325673262278237

Epoch: 550| Step: 0
Training loss: 1.2111806869506836
Validation loss: 2.0942327130225395

Epoch: 5| Step: 1
Training loss: 0.8731540441513062
Validation loss: 2.110607429217267

Epoch: 5| Step: 2
Training loss: 1.3390389680862427
Validation loss: 2.157844130710889

Epoch: 5| Step: 3
Training loss: 1.0563195943832397
Validation loss: 2.17201671549069

Epoch: 5| Step: 4
Training loss: 1.2820813655853271
Validation loss: 2.1625072981721614

Epoch: 5| Step: 5
Training loss: 1.460807204246521
Validation loss: 2.1060226245593

Epoch: 5| Step: 6
Training loss: 1.4959032535552979
Validation loss: 2.1379478336662374

Epoch: 5| Step: 7
Training loss: 1.3528423309326172
Validation loss: 2.05188722379746

Epoch: 5| Step: 8
Training loss: 1.0108063220977783
Validation loss: 2.1206701814487414

Epoch: 5| Step: 9
Training loss: 1.3958319425582886
Validation loss: 2.110574476180538

Epoch: 5| Step: 10
Training loss: 1.4448987245559692
Validation loss: 2.12332155371225

Epoch: 551| Step: 0
Training loss: 1.5027406215667725
Validation loss: 2.1814871193260275

Epoch: 5| Step: 1
Training loss: 0.9770272374153137
Validation loss: 2.1093674859692975

Epoch: 5| Step: 2
Training loss: 1.3660023212432861
Validation loss: 2.054024911695911

Epoch: 5| Step: 3
Training loss: 1.2565672397613525
Validation loss: 2.155940532684326

Epoch: 5| Step: 4
Training loss: 1.150863766670227
Validation loss: 2.1205212313641786

Epoch: 5| Step: 5
Training loss: 1.167851209640503
Validation loss: 2.0871313541166243

Epoch: 5| Step: 6
Training loss: 1.5568596124649048
Validation loss: 2.1284994104857087

Epoch: 5| Step: 7
Training loss: 0.7146701812744141
Validation loss: 2.1059020873039

Epoch: 5| Step: 8
Training loss: 1.5762746334075928
Validation loss: 2.09180425828503

Epoch: 5| Step: 9
Training loss: 1.348630428314209
Validation loss: 2.104118465095438

Epoch: 5| Step: 10
Training loss: 1.5612618923187256
Validation loss: 2.0551533750308457

Epoch: 552| Step: 0
Training loss: 1.3156906366348267
Validation loss: 2.1474264103879213

Epoch: 5| Step: 1
Training loss: 1.0026819705963135
Validation loss: 2.088911610264932

Epoch: 5| Step: 2
Training loss: 1.2106692790985107
Validation loss: 2.1371161988986436

Epoch: 5| Step: 3
Training loss: 0.7546970248222351
Validation loss: 2.0774891248313327

Epoch: 5| Step: 4
Training loss: 1.2427425384521484
Validation loss: 2.177510183344605

Epoch: 5| Step: 5
Training loss: 1.1974012851715088
Validation loss: 2.1123912283169326

Epoch: 5| Step: 6
Training loss: 1.2066830396652222
Validation loss: 2.173976461092631

Epoch: 5| Step: 7
Training loss: 1.447593092918396
Validation loss: 2.1300434271494546

Epoch: 5| Step: 8
Training loss: 1.428650140762329
Validation loss: 2.121925705222673

Epoch: 5| Step: 9
Training loss: 1.0179855823516846
Validation loss: 2.1168430492442143

Epoch: 5| Step: 10
Training loss: 2.426015853881836
Validation loss: 2.0899654447391467

Epoch: 553| Step: 0
Training loss: 1.2358262538909912
Validation loss: 2.1021183665080736

Epoch: 5| Step: 1
Training loss: 0.7718988656997681
Validation loss: 2.152469640137047

Epoch: 5| Step: 2
Training loss: 1.401655912399292
Validation loss: 2.103768569166942

Epoch: 5| Step: 3
Training loss: 1.2910029888153076
Validation loss: 2.1265178790656467

Epoch: 5| Step: 4
Training loss: 1.4263551235198975
Validation loss: 2.158453497835385

Epoch: 5| Step: 5
Training loss: 1.459566354751587
Validation loss: 2.1223808539811

Epoch: 5| Step: 6
Training loss: 0.6805864572525024
Validation loss: 2.0897787642735306

Epoch: 5| Step: 7
Training loss: 1.5724281072616577
Validation loss: 2.127513336878951

Epoch: 5| Step: 8
Training loss: 1.4411258697509766
Validation loss: 2.131334307373211

Epoch: 5| Step: 9
Training loss: 1.7351999282836914
Validation loss: 2.0609346128279165

Epoch: 5| Step: 10
Training loss: 1.2260687351226807
Validation loss: 2.131138483683268

Epoch: 554| Step: 0
Training loss: 1.082710862159729
Validation loss: 2.116327888222151

Epoch: 5| Step: 1
Training loss: 1.3377540111541748
Validation loss: 2.093860664675313

Epoch: 5| Step: 2
Training loss: 1.1258286237716675
Validation loss: 2.115568589138728

Epoch: 5| Step: 3
Training loss: 1.2944631576538086
Validation loss: 2.1090799557265414

Epoch: 5| Step: 4
Training loss: 1.5123533010482788
Validation loss: 2.0786113110921716

Epoch: 5| Step: 5
Training loss: 0.9259331822395325
Validation loss: 2.112115962530977

Epoch: 5| Step: 6
Training loss: 1.3846471309661865
Validation loss: 2.114264254928917

Epoch: 5| Step: 7
Training loss: 0.9631559252738953
Validation loss: 2.1407839611012447

Epoch: 5| Step: 8
Training loss: 1.1430776119232178
Validation loss: 2.129536977378271

Epoch: 5| Step: 9
Training loss: 1.0998996496200562
Validation loss: 2.149782988332933

Epoch: 5| Step: 10
Training loss: 2.1508846282958984
Validation loss: 2.0837064737914712

Epoch: 555| Step: 0
Training loss: 1.246325135231018
Validation loss: 2.125985368605583

Epoch: 5| Step: 1
Training loss: 1.7339023351669312
Validation loss: 2.1066771271408244

Epoch: 5| Step: 2
Training loss: 1.419265866279602
Validation loss: 2.1143418717127975

Epoch: 5| Step: 3
Training loss: 1.111338496208191
Validation loss: 2.0614294634070447

Epoch: 5| Step: 4
Training loss: 1.1152591705322266
Validation loss: 2.07503822670188

Epoch: 5| Step: 5
Training loss: 1.167219877243042
Validation loss: 2.048889629302486

Epoch: 5| Step: 6
Training loss: 1.3870794773101807
Validation loss: 2.1099161986381776

Epoch: 5| Step: 7
Training loss: 0.9720842242240906
Validation loss: 2.102626092972294

Epoch: 5| Step: 8
Training loss: 1.2984367609024048
Validation loss: 2.0743467974406418

Epoch: 5| Step: 9
Training loss: 1.3582494258880615
Validation loss: 2.096755599462858

Epoch: 5| Step: 10
Training loss: 1.4484014511108398
Validation loss: 2.112553988733599

Epoch: 556| Step: 0
Training loss: 1.2404074668884277
Validation loss: 2.083409675987818

Epoch: 5| Step: 1
Training loss: 1.002507209777832
Validation loss: 2.125575630895553

Epoch: 5| Step: 2
Training loss: 1.7946193218231201
Validation loss: 2.054697000852195

Epoch: 5| Step: 3
Training loss: 1.2132502794265747
Validation loss: 2.126013002087993

Epoch: 5| Step: 4
Training loss: 1.1323593854904175
Validation loss: 2.117581000892065

Epoch: 5| Step: 5
Training loss: 1.0105878114700317
Validation loss: 2.0626390121316396

Epoch: 5| Step: 6
Training loss: 1.0292983055114746
Validation loss: 2.0994539696683168

Epoch: 5| Step: 7
Training loss: 1.4645709991455078
Validation loss: 2.1201056511171403

Epoch: 5| Step: 8
Training loss: 1.64552903175354
Validation loss: 2.1371767597813762

Epoch: 5| Step: 9
Training loss: 0.9247609972953796
Validation loss: 2.143147986422303

Epoch: 5| Step: 10
Training loss: 1.8386964797973633
Validation loss: 2.1282827059427896

Epoch: 557| Step: 0
Training loss: 0.6439353227615356
Validation loss: 2.136379372689032

Epoch: 5| Step: 1
Training loss: 1.5274819135665894
Validation loss: 2.142356462376092

Epoch: 5| Step: 2
Training loss: 0.7564653754234314
Validation loss: 2.0994232649444253

Epoch: 5| Step: 3
Training loss: 1.0113672018051147
Validation loss: 2.1028689543406167

Epoch: 5| Step: 4
Training loss: 2.1253068447113037
Validation loss: 2.1198316504878383

Epoch: 5| Step: 5
Training loss: 1.5086265802383423
Validation loss: 2.117176345599595

Epoch: 5| Step: 6
Training loss: 1.446336030960083
Validation loss: 2.1614725769207044

Epoch: 5| Step: 7
Training loss: 1.2427163124084473
Validation loss: 2.112588959355508

Epoch: 5| Step: 8
Training loss: 1.1200568675994873
Validation loss: 2.1389732437749065

Epoch: 5| Step: 9
Training loss: 1.4355710744857788
Validation loss: 2.0949370886689875

Epoch: 5| Step: 10
Training loss: 1.320582389831543
Validation loss: 2.1109306812286377

Epoch: 558| Step: 0
Training loss: 1.2628459930419922
Validation loss: 2.0376263203159457

Epoch: 5| Step: 1
Training loss: 0.926024317741394
Validation loss: 2.1101936435186737

Epoch: 5| Step: 2
Training loss: 1.5699748992919922
Validation loss: 2.1352222555427143

Epoch: 5| Step: 3
Training loss: 1.1794986724853516
Validation loss: 2.093381681749898

Epoch: 5| Step: 4
Training loss: 1.1672570705413818
Validation loss: 2.0957447790330455

Epoch: 5| Step: 5
Training loss: 1.302902102470398
Validation loss: 2.1136932373046875

Epoch: 5| Step: 6
Training loss: 1.3155510425567627
Validation loss: 2.0824678072365383

Epoch: 5| Step: 7
Training loss: 1.756209373474121
Validation loss: 2.0549664074374783

Epoch: 5| Step: 8
Training loss: 1.0991020202636719
Validation loss: 2.0723973371649302

Epoch: 5| Step: 9
Training loss: 1.489945650100708
Validation loss: 2.1199751541178715

Epoch: 5| Step: 10
Training loss: 1.2313095331192017
Validation loss: 2.1230589753837994

Epoch: 559| Step: 0
Training loss: 1.38846755027771
Validation loss: 2.1131200867314495

Epoch: 5| Step: 1
Training loss: 1.014725923538208
Validation loss: 2.137630817710712

Epoch: 5| Step: 2
Training loss: 0.9883627891540527
Validation loss: 2.1153056672824326

Epoch: 5| Step: 3
Training loss: 1.4155406951904297
Validation loss: 2.0737448430830434

Epoch: 5| Step: 4
Training loss: 1.6655166149139404
Validation loss: 2.1066512843613983

Epoch: 5| Step: 5
Training loss: 0.6123660802841187
Validation loss: 2.1403757141482447

Epoch: 5| Step: 6
Training loss: 1.2958259582519531
Validation loss: 2.132115379456551

Epoch: 5| Step: 7
Training loss: 1.2195950746536255
Validation loss: 2.133544550147108

Epoch: 5| Step: 8
Training loss: 1.500876545906067
Validation loss: 2.1272164698570006

Epoch: 5| Step: 9
Training loss: 1.458324670791626
Validation loss: 2.1194870907773256

Epoch: 5| Step: 10
Training loss: 1.449424147605896
Validation loss: 2.0787298115350867

Epoch: 560| Step: 0
Training loss: 1.4736437797546387
Validation loss: 2.122814847577003

Epoch: 5| Step: 1
Training loss: 1.023972988128662
Validation loss: 2.121283038969963

Epoch: 5| Step: 2
Training loss: 1.3581244945526123
Validation loss: 2.130314391146424

Epoch: 5| Step: 3
Training loss: 1.3335883617401123
Validation loss: 2.101485021652714

Epoch: 5| Step: 4
Training loss: 1.0055718421936035
Validation loss: 2.1312047473845945

Epoch: 5| Step: 5
Training loss: 1.3632457256317139
Validation loss: 2.137439389382639

Epoch: 5| Step: 6
Training loss: 1.7696781158447266
Validation loss: 2.1704744856844664

Epoch: 5| Step: 7
Training loss: 1.013566017150879
Validation loss: 2.1248645590197657

Epoch: 5| Step: 8
Training loss: 1.264065146446228
Validation loss: 2.0920316455184773

Epoch: 5| Step: 9
Training loss: 1.1794836521148682
Validation loss: 2.1085013035804994

Epoch: 5| Step: 10
Training loss: 1.068445086479187
Validation loss: 2.077612825619277

Epoch: 561| Step: 0
Training loss: 1.728046178817749
Validation loss: 2.128295983037641

Epoch: 5| Step: 1
Training loss: 1.6996257305145264
Validation loss: 2.1294956873821955

Epoch: 5| Step: 2
Training loss: 1.0950672626495361
Validation loss: 2.087152527224633

Epoch: 5| Step: 3
Training loss: 1.0584272146224976
Validation loss: 2.1409377180119997

Epoch: 5| Step: 4
Training loss: 1.315251111984253
Validation loss: 2.0863341028972338

Epoch: 5| Step: 5
Training loss: 0.9271564483642578
Validation loss: 2.08156644657094

Epoch: 5| Step: 6
Training loss: 1.3305584192276
Validation loss: 2.1183903717225596

Epoch: 5| Step: 7
Training loss: 0.9238387942314148
Validation loss: 2.1015406988000356

Epoch: 5| Step: 8
Training loss: 1.4018375873565674
Validation loss: 2.058526590306272

Epoch: 5| Step: 9
Training loss: 1.4688389301300049
Validation loss: 2.076075448784777

Epoch: 5| Step: 10
Training loss: 1.0037611722946167
Validation loss: 2.1306942239884408

Epoch: 562| Step: 0
Training loss: 1.3684380054473877
Validation loss: 2.1389203225412676

Epoch: 5| Step: 1
Training loss: 0.9513633847236633
Validation loss: 2.1225777544001097

Epoch: 5| Step: 2
Training loss: 1.452006459236145
Validation loss: 2.113911371077261

Epoch: 5| Step: 3
Training loss: 1.4085558652877808
Validation loss: 2.0883666802478094

Epoch: 5| Step: 4
Training loss: 1.2093441486358643
Validation loss: 2.096711459980216

Epoch: 5| Step: 5
Training loss: 1.3892070055007935
Validation loss: 2.1215482117027364

Epoch: 5| Step: 6
Training loss: 1.008274793624878
Validation loss: 2.1229111763738815

Epoch: 5| Step: 7
Training loss: 0.9281150698661804
Validation loss: 2.096678308261338

Epoch: 5| Step: 8
Training loss: 1.4660972356796265
Validation loss: 2.1151559865602882

Epoch: 5| Step: 9
Training loss: 1.4237024784088135
Validation loss: 2.131746079332085

Epoch: 5| Step: 10
Training loss: 1.3393796682357788
Validation loss: 2.1497804170013755

Epoch: 563| Step: 0
Training loss: 1.0112022161483765
Validation loss: 2.108551827810144

Epoch: 5| Step: 1
Training loss: 1.6400301456451416
Validation loss: 2.1184123510955484

Epoch: 5| Step: 2
Training loss: 1.4401023387908936
Validation loss: 2.136949926294306

Epoch: 5| Step: 3
Training loss: 1.2373555898666382
Validation loss: 2.092461501398394

Epoch: 5| Step: 4
Training loss: 1.2998619079589844
Validation loss: 2.202148414427234

Epoch: 5| Step: 5
Training loss: 1.5472612380981445
Validation loss: 2.101864855776551

Epoch: 5| Step: 6
Training loss: 0.8076192736625671
Validation loss: 2.111575908558343

Epoch: 5| Step: 7
Training loss: 0.9176256060600281
Validation loss: 2.1682152158470562

Epoch: 5| Step: 8
Training loss: 1.4039613008499146
Validation loss: 2.1341408298861597

Epoch: 5| Step: 9
Training loss: 1.317858338356018
Validation loss: 2.0864727663737472

Epoch: 5| Step: 10
Training loss: 1.5245836973190308
Validation loss: 2.1072115718677478

Epoch: 564| Step: 0
Training loss: 0.9945163726806641
Validation loss: 2.109625013925696

Epoch: 5| Step: 1
Training loss: 1.2174046039581299
Validation loss: 2.1392215644159625

Epoch: 5| Step: 2
Training loss: 1.3565884828567505
Validation loss: 2.1352219376512753

Epoch: 5| Step: 3
Training loss: 1.333424687385559
Validation loss: 2.1772788788682673

Epoch: 5| Step: 4
Training loss: 0.9138206243515015
Validation loss: 2.113656625952772

Epoch: 5| Step: 5
Training loss: 1.5237772464752197
Validation loss: 2.1287061296483523

Epoch: 5| Step: 6
Training loss: 1.6865752935409546
Validation loss: 2.12271358120826

Epoch: 5| Step: 7
Training loss: 1.2035290002822876
Validation loss: 2.1166852071721065

Epoch: 5| Step: 8
Training loss: 1.602603554725647
Validation loss: 2.127727749527142

Epoch: 5| Step: 9
Training loss: 1.217565894126892
Validation loss: 2.1091102900043612

Epoch: 5| Step: 10
Training loss: 0.8936443328857422
Validation loss: 2.1390976393094627

Epoch: 565| Step: 0
Training loss: 1.6253173351287842
Validation loss: 2.103326061720489

Epoch: 5| Step: 1
Training loss: 1.5644831657409668
Validation loss: 2.1163886772689

Epoch: 5| Step: 2
Training loss: 1.2832363843917847
Validation loss: 2.1098979967896656

Epoch: 5| Step: 3
Training loss: 1.0801899433135986
Validation loss: 2.089979064080023

Epoch: 5| Step: 4
Training loss: 1.166190266609192
Validation loss: 2.1321822789407547

Epoch: 5| Step: 5
Training loss: 1.2055996656417847
Validation loss: 2.098597868796318

Epoch: 5| Step: 6
Training loss: 1.0732529163360596
Validation loss: 2.1154245868805917

Epoch: 5| Step: 7
Training loss: 0.8425184488296509
Validation loss: 2.130775467042

Epoch: 5| Step: 8
Training loss: 1.365856409072876
Validation loss: 2.139419932519236

Epoch: 5| Step: 9
Training loss: 1.0221092700958252
Validation loss: 2.0667188270117647

Epoch: 5| Step: 10
Training loss: 1.9374094009399414
Validation loss: 2.117658189547959

Epoch: 566| Step: 0
Training loss: 1.7208410501480103
Validation loss: 2.0658972365881807

Epoch: 5| Step: 1
Training loss: 1.0847941637039185
Validation loss: 2.109356992988176

Epoch: 5| Step: 2
Training loss: 1.12394118309021
Validation loss: 2.082560198281401

Epoch: 5| Step: 3
Training loss: 1.683323621749878
Validation loss: 2.1268905093592982

Epoch: 5| Step: 4
Training loss: 1.2729880809783936
Validation loss: 2.1564261810753935

Epoch: 5| Step: 5
Training loss: 0.4516812264919281
Validation loss: 2.1225310243586057

Epoch: 5| Step: 6
Training loss: 1.641087532043457
Validation loss: 2.0424280435808244

Epoch: 5| Step: 7
Training loss: 1.0210295915603638
Validation loss: 2.1216417974041355

Epoch: 5| Step: 8
Training loss: 1.3258730173110962
Validation loss: 2.1516795414750294

Epoch: 5| Step: 9
Training loss: 1.0635206699371338
Validation loss: 2.097201165332589

Epoch: 5| Step: 10
Training loss: 1.830713152885437
Validation loss: 2.118599704516831

Epoch: 567| Step: 0
Training loss: 0.7128854990005493
Validation loss: 2.149446218244491

Epoch: 5| Step: 1
Training loss: 1.8427770137786865
Validation loss: 2.106496035411794

Epoch: 5| Step: 2
Training loss: 1.616445779800415
Validation loss: 2.136075419764365

Epoch: 5| Step: 3
Training loss: 1.0507761240005493
Validation loss: 2.15461798637144

Epoch: 5| Step: 4
Training loss: 1.292663335800171
Validation loss: 2.12882322906166

Epoch: 5| Step: 5
Training loss: 0.8271371126174927
Validation loss: 2.153893073399862

Epoch: 5| Step: 6
Training loss: 1.2709534168243408
Validation loss: 2.1260409765346076

Epoch: 5| Step: 7
Training loss: 1.2886300086975098
Validation loss: 2.1218171094053533

Epoch: 5| Step: 8
Training loss: 1.3983080387115479
Validation loss: 2.124065122296733

Epoch: 5| Step: 9
Training loss: 1.300922155380249
Validation loss: 2.107733093282228

Epoch: 5| Step: 10
Training loss: 1.0147912502288818
Validation loss: 2.187228000292214

Epoch: 568| Step: 0
Training loss: 0.9216408729553223
Validation loss: 2.1087713779941684

Epoch: 5| Step: 1
Training loss: 1.5212452411651611
Validation loss: 2.142354470427318

Epoch: 5| Step: 2
Training loss: 1.6165539026260376
Validation loss: 2.1190299885247343

Epoch: 5| Step: 3
Training loss: 1.406583309173584
Validation loss: 2.068375220862768

Epoch: 5| Step: 4
Training loss: 0.6864493489265442
Validation loss: 2.1245599203212286

Epoch: 5| Step: 5
Training loss: 1.229588270187378
Validation loss: 2.1246667933720413

Epoch: 5| Step: 6
Training loss: 1.8417327404022217
Validation loss: 2.1055690870490125

Epoch: 5| Step: 7
Training loss: 0.9595955014228821
Validation loss: 2.0426639703012284

Epoch: 5| Step: 8
Training loss: 1.324855089187622
Validation loss: 2.1184399127960205

Epoch: 5| Step: 9
Training loss: 1.1885439157485962
Validation loss: 2.110940876827445

Epoch: 5| Step: 10
Training loss: 1.1049787998199463
Validation loss: 2.0996058346122823

Epoch: 569| Step: 0
Training loss: 1.3689926862716675
Validation loss: 2.104125717634796

Epoch: 5| Step: 1
Training loss: 1.2283234596252441
Validation loss: 2.129893787445561

Epoch: 5| Step: 2
Training loss: 1.1707757711410522
Validation loss: 2.1316871566157185

Epoch: 5| Step: 3
Training loss: 0.8493374586105347
Validation loss: 2.1597906543362524

Epoch: 5| Step: 4
Training loss: 1.191694974899292
Validation loss: 2.1248078205252208

Epoch: 5| Step: 5
Training loss: 1.1657949686050415
Validation loss: 2.1653113416446153

Epoch: 5| Step: 6
Training loss: 1.4562432765960693
Validation loss: 2.142394196602606

Epoch: 5| Step: 7
Training loss: 0.9888374209403992
Validation loss: 2.1361253787112493

Epoch: 5| Step: 8
Training loss: 1.4678001403808594
Validation loss: 2.140550764658118

Epoch: 5| Step: 9
Training loss: 1.5965449810028076
Validation loss: 2.1223042100988407

Epoch: 5| Step: 10
Training loss: 1.001215934753418
Validation loss: 2.1066577460176203

Epoch: 570| Step: 0
Training loss: 0.9717291593551636
Validation loss: 2.1016220892629316

Epoch: 5| Step: 1
Training loss: 1.2965906858444214
Validation loss: 2.150733709335327

Epoch: 5| Step: 2
Training loss: 0.8436981439590454
Validation loss: 2.1208489300102316

Epoch: 5| Step: 3
Training loss: 1.4627662897109985
Validation loss: 2.099431486539943

Epoch: 5| Step: 4
Training loss: 1.3924280405044556
Validation loss: 2.1451435640294063

Epoch: 5| Step: 5
Training loss: 1.2312886714935303
Validation loss: 2.1288717639061714

Epoch: 5| Step: 6
Training loss: 1.1538937091827393
Validation loss: 2.0686131267137426

Epoch: 5| Step: 7
Training loss: 1.2800575494766235
Validation loss: 2.1223858133439095

Epoch: 5| Step: 8
Training loss: 1.7170730829238892
Validation loss: 2.117955223206551

Epoch: 5| Step: 9
Training loss: 1.378103256225586
Validation loss: 2.166656777422915

Epoch: 5| Step: 10
Training loss: 1.1742802858352661
Validation loss: 2.17903224883541

Epoch: 571| Step: 0
Training loss: 1.167353630065918
Validation loss: 2.113001546552104

Epoch: 5| Step: 1
Training loss: 1.106505274772644
Validation loss: 2.1482870963311966

Epoch: 5| Step: 2
Training loss: 1.0478118658065796
Validation loss: 2.142526857314571

Epoch: 5| Step: 3
Training loss: 1.2202248573303223
Validation loss: 2.1084342079777874

Epoch: 5| Step: 4
Training loss: 2.0533664226531982
Validation loss: 2.099131517512824

Epoch: 5| Step: 5
Training loss: 0.9698632955551147
Validation loss: 2.095564079541032

Epoch: 5| Step: 6
Training loss: 1.1956959962844849
Validation loss: 2.0941142164250857

Epoch: 5| Step: 7
Training loss: 1.1261281967163086
Validation loss: 2.112289100564936

Epoch: 5| Step: 8
Training loss: 1.254363775253296
Validation loss: 2.1591735168169905

Epoch: 5| Step: 9
Training loss: 0.8624473810195923
Validation loss: 2.1758549533864504

Epoch: 5| Step: 10
Training loss: 1.6792113780975342
Validation loss: 2.1241917328167985

Epoch: 572| Step: 0
Training loss: 1.2397540807724
Validation loss: 2.1715186462607434

Epoch: 5| Step: 1
Training loss: 1.6923446655273438
Validation loss: 2.110211431339223

Epoch: 5| Step: 2
Training loss: 1.509417176246643
Validation loss: 2.0784543022032707

Epoch: 5| Step: 3
Training loss: 0.7671101689338684
Validation loss: 2.08504363670144

Epoch: 5| Step: 4
Training loss: 1.2274749279022217
Validation loss: 2.1294237798260105

Epoch: 5| Step: 5
Training loss: 0.8995975255966187
Validation loss: 2.0781554842507965

Epoch: 5| Step: 6
Training loss: 1.608116865158081
Validation loss: 2.0981653082755303

Epoch: 5| Step: 7
Training loss: 1.3870418071746826
Validation loss: 2.1254970130100044

Epoch: 5| Step: 8
Training loss: 1.2525639533996582
Validation loss: 2.1318646092568674

Epoch: 5| Step: 9
Training loss: 1.3279633522033691
Validation loss: 2.1239802017006824

Epoch: 5| Step: 10
Training loss: 1.1385287046432495
Validation loss: 2.1581534518990466

Epoch: 573| Step: 0
Training loss: 1.597654104232788
Validation loss: 2.150018758671258

Epoch: 5| Step: 1
Training loss: 1.0750325918197632
Validation loss: 2.088819531984227

Epoch: 5| Step: 2
Training loss: 1.0371381044387817
Validation loss: 2.064636202268703

Epoch: 5| Step: 3
Training loss: 1.3339481353759766
Validation loss: 2.027664223024922

Epoch: 5| Step: 4
Training loss: 0.7646760940551758
Validation loss: 2.0872921687300487

Epoch: 5| Step: 5
Training loss: 0.9117554426193237
Validation loss: 2.1069810928836947

Epoch: 5| Step: 6
Training loss: 0.9810791015625
Validation loss: 2.068030857270764

Epoch: 5| Step: 7
Training loss: 1.6220213174819946
Validation loss: 2.189690218176893

Epoch: 5| Step: 8
Training loss: 1.4007861614227295
Validation loss: 2.0606524995578233

Epoch: 5| Step: 9
Training loss: 1.6075769662857056
Validation loss: 2.15196959177653

Epoch: 5| Step: 10
Training loss: 1.0818698406219482
Validation loss: 2.130294338349373

Epoch: 574| Step: 0
Training loss: 1.2200062274932861
Validation loss: 2.0619547995187903

Epoch: 5| Step: 1
Training loss: 1.0572404861450195
Validation loss: 2.1518844019982124

Epoch: 5| Step: 2
Training loss: 1.077892541885376
Validation loss: 2.1673177647334274

Epoch: 5| Step: 3
Training loss: 1.8221662044525146
Validation loss: 2.0915797346381733

Epoch: 5| Step: 4
Training loss: 1.3764755725860596
Validation loss: 2.107986092567444

Epoch: 5| Step: 5
Training loss: 0.5389219522476196
Validation loss: 2.1424754640107513

Epoch: 5| Step: 6
Training loss: 1.2731969356536865
Validation loss: 2.123105356770177

Epoch: 5| Step: 7
Training loss: 2.1003708839416504
Validation loss: 2.0499620373531053

Epoch: 5| Step: 8
Training loss: 1.0327297449111938
Validation loss: 2.143788588944302

Epoch: 5| Step: 9
Training loss: 0.9840161204338074
Validation loss: 2.1587143341700235

Epoch: 5| Step: 10
Training loss: 1.625302791595459
Validation loss: 2.1349030874108754

Epoch: 575| Step: 0
Training loss: 1.0904195308685303
Validation loss: 2.131990719867009

Epoch: 5| Step: 1
Training loss: 0.9717809557914734
Validation loss: 2.1417732700224845

Epoch: 5| Step: 2
Training loss: 1.2473804950714111
Validation loss: 2.1508596699724913

Epoch: 5| Step: 3
Training loss: 1.4567207098007202
Validation loss: 2.1436787600158365

Epoch: 5| Step: 4
Training loss: 1.003610372543335
Validation loss: 2.184538584883495

Epoch: 5| Step: 5
Training loss: 1.1615920066833496
Validation loss: 2.158208353545076

Epoch: 5| Step: 6
Training loss: 1.3203763961791992
Validation loss: 2.1195511305204002

Epoch: 5| Step: 7
Training loss: 1.531314730644226
Validation loss: 2.1551675309417067

Epoch: 5| Step: 8
Training loss: 1.4222805500030518
Validation loss: 2.068545074873073

Epoch: 5| Step: 9
Training loss: 1.0155023336410522
Validation loss: 2.0835734362243326

Epoch: 5| Step: 10
Training loss: 1.565348505973816
Validation loss: 2.0712588294859855

Epoch: 576| Step: 0
Training loss: 1.1656885147094727
Validation loss: 2.10582455255652

Epoch: 5| Step: 1
Training loss: 1.2758228778839111
Validation loss: 2.1106248953009166

Epoch: 5| Step: 2
Training loss: 1.4417095184326172
Validation loss: 2.121872909607426

Epoch: 5| Step: 3
Training loss: 1.1224285364151
Validation loss: 2.0994348282455118

Epoch: 5| Step: 4
Training loss: 1.2606953382492065
Validation loss: 2.0505667130152383

Epoch: 5| Step: 5
Training loss: 1.3295643329620361
Validation loss: 2.0707670270755725

Epoch: 5| Step: 6
Training loss: 1.1633121967315674
Validation loss: 2.0376736169220298

Epoch: 5| Step: 7
Training loss: 1.3636748790740967
Validation loss: 2.0438391290685183

Epoch: 5| Step: 8
Training loss: 1.2870599031448364
Validation loss: 2.1483987390354113

Epoch: 5| Step: 9
Training loss: 1.0935180187225342
Validation loss: 2.106256363212421

Epoch: 5| Step: 10
Training loss: 1.5379042625427246
Validation loss: 2.1235600492005706

Epoch: 577| Step: 0
Training loss: 0.9736803770065308
Validation loss: 2.1108183553141933

Epoch: 5| Step: 1
Training loss: 1.2868818044662476
Validation loss: 2.120366891225179

Epoch: 5| Step: 2
Training loss: 0.8031454086303711
Validation loss: 2.127977560925227

Epoch: 5| Step: 3
Training loss: 0.9113661050796509
Validation loss: 2.1651809446273313

Epoch: 5| Step: 4
Training loss: 1.255481243133545
Validation loss: 2.1682045895566224

Epoch: 5| Step: 5
Training loss: 2.0537495613098145
Validation loss: 2.1367863211580502

Epoch: 5| Step: 6
Training loss: 1.169974684715271
Validation loss: 2.120414512131804

Epoch: 5| Step: 7
Training loss: 1.7239573001861572
Validation loss: 2.1149717248896116

Epoch: 5| Step: 8
Training loss: 1.175594449043274
Validation loss: 2.1239554625685497

Epoch: 5| Step: 9
Training loss: 1.382206916809082
Validation loss: 2.208515559473345

Epoch: 5| Step: 10
Training loss: 0.8351355791091919
Validation loss: 2.1254494395307315

Epoch: 578| Step: 0
Training loss: 1.2645816802978516
Validation loss: 2.098525495939357

Epoch: 5| Step: 1
Training loss: 1.0663172006607056
Validation loss: 2.1870853106180825

Epoch: 5| Step: 2
Training loss: 0.7673124670982361
Validation loss: 2.146565245043847

Epoch: 5| Step: 3
Training loss: 1.0468324422836304
Validation loss: 2.170430455156552

Epoch: 5| Step: 4
Training loss: 1.5786430835723877
Validation loss: 2.114065001087804

Epoch: 5| Step: 5
Training loss: 1.5072128772735596
Validation loss: 2.1728573281277894

Epoch: 5| Step: 6
Training loss: 1.086006760597229
Validation loss: 2.0999340254773378

Epoch: 5| Step: 7
Training loss: 1.3548963069915771
Validation loss: 2.120803952217102

Epoch: 5| Step: 8
Training loss: 1.526111125946045
Validation loss: 2.075322913867171

Epoch: 5| Step: 9
Training loss: 1.636292815208435
Validation loss: 2.0821787080457135

Epoch: 5| Step: 10
Training loss: 1.0413395166397095
Validation loss: 2.106233207128381

Epoch: 579| Step: 0
Training loss: 1.1483958959579468
Validation loss: 2.14836948533212

Epoch: 5| Step: 1
Training loss: 1.2816683053970337
Validation loss: 2.088875627004972

Epoch: 5| Step: 2
Training loss: 1.1604007482528687
Validation loss: 2.0425832194666707

Epoch: 5| Step: 3
Training loss: 1.218329668045044
Validation loss: 2.126943222938045

Epoch: 5| Step: 4
Training loss: 0.834174633026123
Validation loss: 2.098328157137799

Epoch: 5| Step: 5
Training loss: 1.7736222743988037
Validation loss: 2.137527124856108

Epoch: 5| Step: 6
Training loss: 1.0082966089248657
Validation loss: 2.105487759395312

Epoch: 5| Step: 7
Training loss: 1.345502257347107
Validation loss: 2.098950683429677

Epoch: 5| Step: 8
Training loss: 1.3726392984390259
Validation loss: 2.1264283298164286

Epoch: 5| Step: 9
Training loss: 1.2822983264923096
Validation loss: 2.1302700555452736

Epoch: 5| Step: 10
Training loss: 0.8917840123176575
Validation loss: 2.11824438136111

Epoch: 580| Step: 0
Training loss: 1.5092836618423462
Validation loss: 2.1151527256094

Epoch: 5| Step: 1
Training loss: 1.0134259462356567
Validation loss: 2.159001850312756

Epoch: 5| Step: 2
Training loss: 1.1482642889022827
Validation loss: 2.1364641420302855

Epoch: 5| Step: 3
Training loss: 0.8846125602722168
Validation loss: 2.162628601956111

Epoch: 5| Step: 4
Training loss: 1.1387348175048828
Validation loss: 2.1280344660564134

Epoch: 5| Step: 5
Training loss: 0.9110231399536133
Validation loss: 2.1805203640332786

Epoch: 5| Step: 6
Training loss: 0.9353578686714172
Validation loss: 2.1553881834912043

Epoch: 5| Step: 7
Training loss: 1.4906688928604126
Validation loss: 2.1273343332352175

Epoch: 5| Step: 8
Training loss: 1.77519953250885
Validation loss: 2.082230870441724

Epoch: 5| Step: 9
Training loss: 1.5595371723175049
Validation loss: 2.0810382955817768

Epoch: 5| Step: 10
Training loss: 1.4813690185546875
Validation loss: 2.1222398819461947

Epoch: 581| Step: 0
Training loss: 1.670928955078125
Validation loss: 2.158327039851937

Epoch: 5| Step: 1
Training loss: 1.2238285541534424
Validation loss: 2.125786030164329

Epoch: 5| Step: 2
Training loss: 0.9247065782546997
Validation loss: 2.087145628467683

Epoch: 5| Step: 3
Training loss: 1.1200977563858032
Validation loss: 2.112790289745536

Epoch: 5| Step: 4
Training loss: 1.496169090270996
Validation loss: 2.0869072637250348

Epoch: 5| Step: 5
Training loss: 1.8309383392333984
Validation loss: 2.111001310809966

Epoch: 5| Step: 6
Training loss: 1.2175095081329346
Validation loss: 2.1547357318221882

Epoch: 5| Step: 7
Training loss: 0.9236569404602051
Validation loss: 2.1289615220921014

Epoch: 5| Step: 8
Training loss: 1.0318152904510498
Validation loss: 2.1115860810843845

Epoch: 5| Step: 9
Training loss: 1.1345863342285156
Validation loss: 2.044952183641413

Epoch: 5| Step: 10
Training loss: 1.0866155624389648
Validation loss: 2.0986569978857554

Epoch: 582| Step: 0
Training loss: 1.1833261251449585
Validation loss: 2.1082995860807356

Epoch: 5| Step: 1
Training loss: 1.6950714588165283
Validation loss: 2.127355978053103

Epoch: 5| Step: 2
Training loss: 0.8001030087471008
Validation loss: 2.0843466430582027

Epoch: 5| Step: 3
Training loss: 1.347895860671997
Validation loss: 2.0323723823793474

Epoch: 5| Step: 4
Training loss: 1.0775706768035889
Validation loss: 2.0760610847062964

Epoch: 5| Step: 5
Training loss: 1.195326805114746
Validation loss: 2.125902270758024

Epoch: 5| Step: 6
Training loss: 1.2464768886566162
Validation loss: 2.1186579171047417

Epoch: 5| Step: 7
Training loss: 1.1842817068099976
Validation loss: 2.120304026911336

Epoch: 5| Step: 8
Training loss: 1.168723464012146
Validation loss: 2.156231954533567

Epoch: 5| Step: 9
Training loss: 1.5449824333190918
Validation loss: 2.115801827881926

Epoch: 5| Step: 10
Training loss: 0.8167731165885925
Validation loss: 2.141944936526719

Epoch: 583| Step: 0
Training loss: 1.906550407409668
Validation loss: 2.144848938911192

Epoch: 5| Step: 1
Training loss: 1.0289453268051147
Validation loss: 2.1492668415910456

Epoch: 5| Step: 2
Training loss: 1.636777639389038
Validation loss: 2.1320215707184165

Epoch: 5| Step: 3
Training loss: 0.8098552823066711
Validation loss: 2.1796472252056165

Epoch: 5| Step: 4
Training loss: 1.1203961372375488
Validation loss: 2.108113004315284

Epoch: 5| Step: 5
Training loss: 0.9996734857559204
Validation loss: 2.110704201523976

Epoch: 5| Step: 6
Training loss: 1.2679250240325928
Validation loss: 2.139265114261258

Epoch: 5| Step: 7
Training loss: 0.9834626913070679
Validation loss: 2.175879504090996

Epoch: 5| Step: 8
Training loss: 1.344617247581482
Validation loss: 2.0598468088334605

Epoch: 5| Step: 9
Training loss: 1.4042013883590698
Validation loss: 2.0963966256828717

Epoch: 5| Step: 10
Training loss: 1.1423567533493042
Validation loss: 2.1155948587643203

Epoch: 584| Step: 0
Training loss: 0.9731441736221313
Validation loss: 2.161121370971844

Epoch: 5| Step: 1
Training loss: 1.7061342000961304
Validation loss: 2.1083495834822297

Epoch: 5| Step: 2
Training loss: 0.8636323809623718
Validation loss: 2.125941429086911

Epoch: 5| Step: 3
Training loss: 1.3004125356674194
Validation loss: 2.0858129224469586

Epoch: 5| Step: 4
Training loss: 1.3339773416519165
Validation loss: 2.0841173433488414

Epoch: 5| Step: 5
Training loss: 1.434602975845337
Validation loss: 2.1253355587682417

Epoch: 5| Step: 6
Training loss: 1.3125660419464111
Validation loss: 2.143075619974444

Epoch: 5| Step: 7
Training loss: 0.9497184753417969
Validation loss: 2.1561360090009627

Epoch: 5| Step: 8
Training loss: 1.0950078964233398
Validation loss: 2.1405101642813733

Epoch: 5| Step: 9
Training loss: 1.1763174533843994
Validation loss: 2.1094722709348126

Epoch: 5| Step: 10
Training loss: 1.1927251815795898
Validation loss: 2.1089905692685034

Epoch: 585| Step: 0
Training loss: 0.5194534063339233
Validation loss: 2.1251232675326768

Epoch: 5| Step: 1
Training loss: 1.46523118019104
Validation loss: 2.0994311532666607

Epoch: 5| Step: 2
Training loss: 1.700872778892517
Validation loss: 2.145754844911637

Epoch: 5| Step: 3
Training loss: 0.8789736032485962
Validation loss: 2.1106767295509257

Epoch: 5| Step: 4
Training loss: 1.7461936473846436
Validation loss: 2.0939974490032403

Epoch: 5| Step: 5
Training loss: 1.2167692184448242
Validation loss: 2.062565685600363

Epoch: 5| Step: 6
Training loss: 1.4374032020568848
Validation loss: 2.147285129434319

Epoch: 5| Step: 7
Training loss: 1.4501653909683228
Validation loss: 2.1054510096068024

Epoch: 5| Step: 8
Training loss: 0.8562021255493164
Validation loss: 2.1715808350552797

Epoch: 5| Step: 9
Training loss: 1.0051788091659546
Validation loss: 2.05771856282347

Epoch: 5| Step: 10
Training loss: 1.4635815620422363
Validation loss: 2.1137413235120874

Epoch: 586| Step: 0
Training loss: 1.2936376333236694
Validation loss: 2.1230369370470763

Epoch: 5| Step: 1
Training loss: 1.246801733970642
Validation loss: 2.1611284209835913

Epoch: 5| Step: 2
Training loss: 0.7021660804748535
Validation loss: 2.113877178520285

Epoch: 5| Step: 3
Training loss: 1.673588752746582
Validation loss: 2.0821657757605276

Epoch: 5| Step: 4
Training loss: 1.2888935804367065
Validation loss: 2.106390381372103

Epoch: 5| Step: 5
Training loss: 1.2690660953521729
Validation loss: 2.102775317366405

Epoch: 5| Step: 6
Training loss: 1.0022391080856323
Validation loss: 2.1285700464761383

Epoch: 5| Step: 7
Training loss: 0.8392341732978821
Validation loss: 2.129965457864987

Epoch: 5| Step: 8
Training loss: 1.7186462879180908
Validation loss: 2.1373992350793656

Epoch: 5| Step: 9
Training loss: 1.2057631015777588
Validation loss: 2.155344952819168

Epoch: 5| Step: 10
Training loss: 1.201714277267456
Validation loss: 2.1048138833815053

Epoch: 587| Step: 0
Training loss: 0.8407743573188782
Validation loss: 2.1167931864338536

Epoch: 5| Step: 1
Training loss: 1.4662197828292847
Validation loss: 2.1201555139275006

Epoch: 5| Step: 2
Training loss: 1.2801520824432373
Validation loss: 2.1067204642039474

Epoch: 5| Step: 3
Training loss: 0.9040695428848267
Validation loss: 2.091681852135607

Epoch: 5| Step: 4
Training loss: 1.4048974514007568
Validation loss: 2.100975082766625

Epoch: 5| Step: 5
Training loss: 0.9351600408554077
Validation loss: 2.0627235276724702

Epoch: 5| Step: 6
Training loss: 1.8307344913482666
Validation loss: 2.11693089367241

Epoch: 5| Step: 7
Training loss: 1.393726110458374
Validation loss: 2.1145462041260092

Epoch: 5| Step: 8
Training loss: 0.9762816429138184
Validation loss: 2.0534532967434136

Epoch: 5| Step: 9
Training loss: 1.1213926076889038
Validation loss: 2.0804723655023882

Epoch: 5| Step: 10
Training loss: 1.230831265449524
Validation loss: 2.140472332636515

Epoch: 588| Step: 0
Training loss: 1.4246625900268555
Validation loss: 2.0985045407408025

Epoch: 5| Step: 1
Training loss: 1.1417245864868164
Validation loss: 2.1255362802936184

Epoch: 5| Step: 2
Training loss: 1.1289963722229004
Validation loss: 2.103752923268144

Epoch: 5| Step: 3
Training loss: 1.2339355945587158
Validation loss: 2.050030367348784

Epoch: 5| Step: 4
Training loss: 1.6558879613876343
Validation loss: 2.1207759969977924

Epoch: 5| Step: 5
Training loss: 1.5298535823822021
Validation loss: 2.1359361269140757

Epoch: 5| Step: 6
Training loss: 1.5839660167694092
Validation loss: 2.0936674815352245

Epoch: 5| Step: 7
Training loss: 0.8054996728897095
Validation loss: 2.1201807350240727

Epoch: 5| Step: 8
Training loss: 1.0824295282363892
Validation loss: 2.094556987926524

Epoch: 5| Step: 9
Training loss: 1.0273008346557617
Validation loss: 2.114999177635357

Epoch: 5| Step: 10
Training loss: 0.9032227993011475
Validation loss: 2.128404043054068

Epoch: 589| Step: 0
Training loss: 1.1673110723495483
Validation loss: 2.115357860442131

Epoch: 5| Step: 1
Training loss: 1.517516851425171
Validation loss: 2.1235418268429336

Epoch: 5| Step: 2
Training loss: 1.1830953359603882
Validation loss: 2.1129808938631447

Epoch: 5| Step: 3
Training loss: 0.9184473156929016
Validation loss: 2.089393396531382

Epoch: 5| Step: 4
Training loss: 0.9563636779785156
Validation loss: 2.179486854102022

Epoch: 5| Step: 5
Training loss: 2.586188793182373
Validation loss: 2.140603370563958

Epoch: 5| Step: 6
Training loss: 1.775557518005371
Validation loss: 2.1022335137090375

Epoch: 5| Step: 7
Training loss: 1.0224500894546509
Validation loss: 2.1046288346731536

Epoch: 5| Step: 8
Training loss: 1.1401722431182861
Validation loss: 2.15992223575551

Epoch: 5| Step: 9
Training loss: 0.6875649690628052
Validation loss: 2.155813806800432

Epoch: 5| Step: 10
Training loss: 0.5506507754325867
Validation loss: 2.0639483108315417

Epoch: 590| Step: 0
Training loss: 0.8841878771781921
Validation loss: 2.1851841788138113

Epoch: 5| Step: 1
Training loss: 1.2189347743988037
Validation loss: 2.1415694131646106

Epoch: 5| Step: 2
Training loss: 1.3102481365203857
Validation loss: 2.19501248739099

Epoch: 5| Step: 3
Training loss: 1.5526937246322632
Validation loss: 2.0770755685785764

Epoch: 5| Step: 4
Training loss: 1.3087562322616577
Validation loss: 2.115643001371814

Epoch: 5| Step: 5
Training loss: 0.9763754606246948
Validation loss: 2.0984910598365207

Epoch: 5| Step: 6
Training loss: 1.1657555103302002
Validation loss: 2.0880715462469284

Epoch: 5| Step: 7
Training loss: 0.761954128742218
Validation loss: 2.080740826104277

Epoch: 5| Step: 8
Training loss: 1.7279274463653564
Validation loss: 2.0842470302376697

Epoch: 5| Step: 9
Training loss: 1.3258731365203857
Validation loss: 2.0890002558308263

Epoch: 5| Step: 10
Training loss: 0.945397675037384
Validation loss: 2.0728134544946815

Epoch: 591| Step: 0
Training loss: 1.033692479133606
Validation loss: 2.117602490609692

Epoch: 5| Step: 1
Training loss: 1.099578857421875
Validation loss: 2.057051347148034

Epoch: 5| Step: 2
Training loss: 1.1774637699127197
Validation loss: 2.1141473734250633

Epoch: 5| Step: 3
Training loss: 1.4834340810775757
Validation loss: 2.1184095362181306

Epoch: 5| Step: 4
Training loss: 1.5709965229034424
Validation loss: 2.1321508858793523

Epoch: 5| Step: 5
Training loss: 1.2625253200531006
Validation loss: 2.0840798142135784

Epoch: 5| Step: 6
Training loss: 1.2673519849777222
Validation loss: 2.128703994135703

Epoch: 5| Step: 7
Training loss: 1.2828776836395264
Validation loss: 2.148452066606091

Epoch: 5| Step: 8
Training loss: 1.213937759399414
Validation loss: 2.08943748217757

Epoch: 5| Step: 9
Training loss: 1.0211350917816162
Validation loss: 2.128963537113641

Epoch: 5| Step: 10
Training loss: 1.1321229934692383
Validation loss: 2.16304846220119

Epoch: 592| Step: 0
Training loss: 0.9375144839286804
Validation loss: 2.1135151822079896

Epoch: 5| Step: 1
Training loss: 1.1226222515106201
Validation loss: 2.2022645037661315

Epoch: 5| Step: 2
Training loss: 1.2518258094787598
Validation loss: 2.0767397188371226

Epoch: 5| Step: 3
Training loss: 1.1767761707305908
Validation loss: 2.1095174602282944

Epoch: 5| Step: 4
Training loss: 1.0434610843658447
Validation loss: 2.1761548596043743

Epoch: 5| Step: 5
Training loss: 1.0644017457962036
Validation loss: 2.1153560274390766

Epoch: 5| Step: 6
Training loss: 1.2248164415359497
Validation loss: 2.118078142084101

Epoch: 5| Step: 7
Training loss: 1.687139868736267
Validation loss: 2.0984279981223484

Epoch: 5| Step: 8
Training loss: 1.4772124290466309
Validation loss: 2.1348534527645318

Epoch: 5| Step: 9
Training loss: 1.4081100225448608
Validation loss: 2.1809835741596837

Epoch: 5| Step: 10
Training loss: 1.2269952297210693
Validation loss: 2.10432162848852

Epoch: 593| Step: 0
Training loss: 0.9709102511405945
Validation loss: 2.112572198273033

Epoch: 5| Step: 1
Training loss: 1.1769691705703735
Validation loss: 2.0897324110872004

Epoch: 5| Step: 2
Training loss: 0.9304431080818176
Validation loss: 2.117220991401262

Epoch: 5| Step: 3
Training loss: 1.1747868061065674
Validation loss: 2.1460950195148425

Epoch: 5| Step: 4
Training loss: 1.14399254322052
Validation loss: 2.1808417227960404

Epoch: 5| Step: 5
Training loss: 1.2726666927337646
Validation loss: 2.159386768135973

Epoch: 5| Step: 6
Training loss: 1.238574743270874
Validation loss: 2.089797483977451

Epoch: 5| Step: 7
Training loss: 1.2318345308303833
Validation loss: 2.1599517176228185

Epoch: 5| Step: 8
Training loss: 1.259496808052063
Validation loss: 2.1201422650326966

Epoch: 5| Step: 9
Training loss: 1.4219026565551758
Validation loss: 2.140053270965494

Epoch: 5| Step: 10
Training loss: 1.4200565814971924
Validation loss: 2.1169420185909478

Epoch: 594| Step: 0
Training loss: 1.0018609762191772
Validation loss: 2.109640226569227

Epoch: 5| Step: 1
Training loss: 1.873152732849121
Validation loss: 2.086682214531847

Epoch: 5| Step: 2
Training loss: 1.2026703357696533
Validation loss: 2.14249179696524

Epoch: 5| Step: 3
Training loss: 1.5664684772491455
Validation loss: 2.150942128191712

Epoch: 5| Step: 4
Training loss: 1.0022850036621094
Validation loss: 2.1020327665472545

Epoch: 5| Step: 5
Training loss: 1.033499002456665
Validation loss: 2.1464605639057774

Epoch: 5| Step: 6
Training loss: 1.670253038406372
Validation loss: 2.1672630797150316

Epoch: 5| Step: 7
Training loss: 1.1218223571777344
Validation loss: 2.1132584233437814

Epoch: 5| Step: 8
Training loss: 0.7673999071121216
Validation loss: 2.1321642116833757

Epoch: 5| Step: 9
Training loss: 0.9039206504821777
Validation loss: 2.1190756777281403

Epoch: 5| Step: 10
Training loss: 1.4428930282592773
Validation loss: 2.0914287182592575

Epoch: 595| Step: 0
Training loss: 1.9044071435928345
Validation loss: 2.106213500422816

Epoch: 5| Step: 1
Training loss: 1.3821516036987305
Validation loss: 2.1105074959416545

Epoch: 5| Step: 2
Training loss: 1.3452186584472656
Validation loss: 2.105740024197486

Epoch: 5| Step: 3
Training loss: 1.207018494606018
Validation loss: 2.1110059317722114

Epoch: 5| Step: 4
Training loss: 1.0450204610824585
Validation loss: 2.1336326163302184

Epoch: 5| Step: 5
Training loss: 1.2240018844604492
Validation loss: 2.0938973939546974

Epoch: 5| Step: 6
Training loss: 1.490820288658142
Validation loss: 2.106118973865304

Epoch: 5| Step: 7
Training loss: 1.1885310411453247
Validation loss: 2.084069134086691

Epoch: 5| Step: 8
Training loss: 1.274537444114685
Validation loss: 2.1162642817343436

Epoch: 5| Step: 9
Training loss: 0.7054802179336548
Validation loss: 2.0969780773244877

Epoch: 5| Step: 10
Training loss: 0.472898930311203
Validation loss: 2.174096932975195

Epoch: 596| Step: 0
Training loss: 1.0283676385879517
Validation loss: 2.114198733401555

Epoch: 5| Step: 1
Training loss: 0.7217265963554382
Validation loss: 2.0355086903418265

Epoch: 5| Step: 2
Training loss: 1.1081949472427368
Validation loss: 2.146809524105441

Epoch: 5| Step: 3
Training loss: 1.4438340663909912
Validation loss: 2.0806951868918633

Epoch: 5| Step: 4
Training loss: 1.239192008972168
Validation loss: 2.115476486503437

Epoch: 5| Step: 5
Training loss: 1.478527545928955
Validation loss: 2.0971271145728325

Epoch: 5| Step: 6
Training loss: 1.539930820465088
Validation loss: 2.1293299633969545

Epoch: 5| Step: 7
Training loss: 1.2889721393585205
Validation loss: 2.079827712428185

Epoch: 5| Step: 8
Training loss: 1.0949517488479614
Validation loss: 2.035107740791895

Epoch: 5| Step: 9
Training loss: 1.609460473060608
Validation loss: 2.0900064924711823

Epoch: 5| Step: 10
Training loss: 0.8523628115653992
Validation loss: 2.1239226659139

Epoch: 597| Step: 0
Training loss: 1.3708076477050781
Validation loss: 2.121272317824825

Epoch: 5| Step: 1
Training loss: 1.4701894521713257
Validation loss: 2.1192034034318823

Epoch: 5| Step: 2
Training loss: 1.085020899772644
Validation loss: 2.094219729464541

Epoch: 5| Step: 3
Training loss: 0.9904614686965942
Validation loss: 2.155293796652107

Epoch: 5| Step: 4
Training loss: 0.8669347763061523
Validation loss: 2.134829023832916

Epoch: 5| Step: 5
Training loss: 1.698131799697876
Validation loss: 2.124861263459729

Epoch: 5| Step: 6
Training loss: 1.2992626428604126
Validation loss: 2.1407275558799825

Epoch: 5| Step: 7
Training loss: 1.250140905380249
Validation loss: 2.145890756319928

Epoch: 5| Step: 8
Training loss: 1.492846965789795
Validation loss: 2.146778873218003

Epoch: 5| Step: 9
Training loss: 0.5367945432662964
Validation loss: 2.131885943874236

Epoch: 5| Step: 10
Training loss: 1.3531874418258667
Validation loss: 2.1450755339796825

Epoch: 598| Step: 0
Training loss: 1.3594087362289429
Validation loss: 2.1307885544274443

Epoch: 5| Step: 1
Training loss: 1.4746592044830322
Validation loss: 2.098773885798711

Epoch: 5| Step: 2
Training loss: 0.6521228551864624
Validation loss: 2.099016720248807

Epoch: 5| Step: 3
Training loss: 1.4563068151474
Validation loss: 2.0848397247252928

Epoch: 5| Step: 4
Training loss: 0.9166498184204102
Validation loss: 2.150225285560854

Epoch: 5| Step: 5
Training loss: 1.6909801959991455
Validation loss: 2.131276628022553

Epoch: 5| Step: 6
Training loss: 1.4872348308563232
Validation loss: 2.1573590847753708

Epoch: 5| Step: 7
Training loss: 1.1045300960540771
Validation loss: 2.0785106279516734

Epoch: 5| Step: 8
Training loss: 0.8562644720077515
Validation loss: 2.0592050347276913

Epoch: 5| Step: 9
Training loss: 1.0356802940368652
Validation loss: 2.095944699420724

Epoch: 5| Step: 10
Training loss: 1.2614943981170654
Validation loss: 2.13246186061572

Epoch: 599| Step: 0
Training loss: 1.2880891561508179
Validation loss: 2.1221348418984363

Epoch: 5| Step: 1
Training loss: 0.9763439893722534
Validation loss: 2.1153399841759795

Epoch: 5| Step: 2
Training loss: 1.2953627109527588
Validation loss: 2.07987222748418

Epoch: 5| Step: 3
Training loss: 1.9617294073104858
Validation loss: 2.067658273122644

Epoch: 5| Step: 4
Training loss: 1.3476570844650269
Validation loss: 2.108252509947746

Epoch: 5| Step: 5
Training loss: 0.9972208142280579
Validation loss: 2.0914340813954673

Epoch: 5| Step: 6
Training loss: 1.3062419891357422
Validation loss: 2.116096829855314

Epoch: 5| Step: 7
Training loss: 0.7267480492591858
Validation loss: 2.141776555327959

Epoch: 5| Step: 8
Training loss: 0.8044204711914062
Validation loss: 2.1159708692181494

Epoch: 5| Step: 9
Training loss: 1.294207215309143
Validation loss: 2.1323062860837547

Epoch: 5| Step: 10
Training loss: 1.4712637662887573
Validation loss: 2.1292842383025796

Epoch: 600| Step: 0
Training loss: 1.0926973819732666
Validation loss: 2.0976731854100383

Epoch: 5| Step: 1
Training loss: 0.7725621461868286
Validation loss: 2.11391479738297

Epoch: 5| Step: 2
Training loss: 1.076899766921997
Validation loss: 2.1197381045228694

Epoch: 5| Step: 3
Training loss: 1.6574541330337524
Validation loss: 2.077069515823036

Epoch: 5| Step: 4
Training loss: 1.035659670829773
Validation loss: 2.058774173900645

Epoch: 5| Step: 5
Training loss: 1.0336490869522095
Validation loss: 2.1158393634262906

Epoch: 5| Step: 6
Training loss: 1.2016875743865967
Validation loss: 2.119019018706455

Epoch: 5| Step: 7
Training loss: 1.033282995223999
Validation loss: 2.123105223460864

Epoch: 5| Step: 8
Training loss: 1.126444697380066
Validation loss: 2.103573368441674

Epoch: 5| Step: 9
Training loss: 1.6046310663223267
Validation loss: 2.1229626465869207

Epoch: 5| Step: 10
Training loss: 1.5529680252075195
Validation loss: 2.138219630846413

Testing loss: 2.0450919601652355
