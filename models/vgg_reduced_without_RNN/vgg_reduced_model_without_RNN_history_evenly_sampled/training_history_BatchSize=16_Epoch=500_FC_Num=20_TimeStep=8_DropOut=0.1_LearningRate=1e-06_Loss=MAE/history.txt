Epoch: 1| Step: 0
Training loss: 8.385234832763672
Validation loss: 9.163994020031344

Epoch: 6| Step: 1
Training loss: 9.35540771484375
Validation loss: 9.16362903964135

Epoch: 6| Step: 2
Training loss: 9.62233829498291
Validation loss: 9.159583122499528

Epoch: 6| Step: 3
Training loss: 9.131397247314453
Validation loss: 9.156221235952069

Epoch: 6| Step: 4
Training loss: 10.748235702514648
Validation loss: 9.156280958524315

Epoch: 6| Step: 5
Training loss: 7.996043682098389
Validation loss: 9.154201015349358

Epoch: 6| Step: 6
Training loss: 8.419353485107422
Validation loss: 9.14990338971538

Epoch: 6| Step: 7
Training loss: 8.47192096710205
Validation loss: 9.145466496867519

Epoch: 6| Step: 8
Training loss: 8.169123649597168
Validation loss: 9.145825509102114

Epoch: 6| Step: 9
Training loss: 7.812370777130127
Validation loss: 9.143525174869005

Epoch: 6| Step: 10
Training loss: 9.18851089477539
Validation loss: 9.140817293556788

Epoch: 6| Step: 11
Training loss: 10.040016174316406
Validation loss: 9.137730162630799

Epoch: 6| Step: 12
Training loss: 8.411699295043945
Validation loss: 9.136645286313948

Epoch: 6| Step: 13
Training loss: 9.898075103759766
Validation loss: 9.133566692311277

Epoch: 2| Step: 0
Training loss: 8.25178337097168
Validation loss: 9.132859045459378

Epoch: 6| Step: 1
Training loss: 8.561565399169922
Validation loss: 9.12824934272356

Epoch: 6| Step: 2
Training loss: 9.68708610534668
Validation loss: 9.127509640109155

Epoch: 6| Step: 3
Training loss: 9.117063522338867
Validation loss: 9.122296384585802

Epoch: 6| Step: 4
Training loss: 8.98105525970459
Validation loss: 9.123133136380103

Epoch: 6| Step: 5
Training loss: 8.731376647949219
Validation loss: 9.119154202040805

Epoch: 6| Step: 6
Training loss: 9.005718231201172
Validation loss: 9.116406379207488

Epoch: 6| Step: 7
Training loss: 7.784625053405762
Validation loss: 9.114996069221087

Epoch: 6| Step: 8
Training loss: 9.27033805847168
Validation loss: 9.112207443483415

Epoch: 6| Step: 9
Training loss: 8.911737442016602
Validation loss: 9.107666528353127

Epoch: 6| Step: 10
Training loss: 8.840570449829102
Validation loss: 9.107029135509205

Epoch: 6| Step: 11
Training loss: 9.628058433532715
Validation loss: 9.104309369159001

Epoch: 6| Step: 12
Training loss: 8.893136978149414
Validation loss: 9.099993572440198

Epoch: 6| Step: 13
Training loss: 9.17556381225586
Validation loss: 9.097146982787757

Epoch: 3| Step: 0
Training loss: 9.805889129638672
Validation loss: 9.093604979976531

Epoch: 6| Step: 1
Training loss: 8.470584869384766
Validation loss: 9.091758153771842

Epoch: 6| Step: 2
Training loss: 8.493437767028809
Validation loss: 9.088636008642053

Epoch: 6| Step: 3
Training loss: 9.172364234924316
Validation loss: 9.085019501306677

Epoch: 6| Step: 4
Training loss: 9.136033058166504
Validation loss: 9.083009166102256

Epoch: 6| Step: 5
Training loss: 8.744439125061035
Validation loss: 9.07970630481679

Epoch: 6| Step: 6
Training loss: 7.217243671417236
Validation loss: 9.077473086695518

Epoch: 6| Step: 7
Training loss: 9.973669052124023
Validation loss: 9.074658414368988

Epoch: 6| Step: 8
Training loss: 9.346136093139648
Validation loss: 9.07127990517565

Epoch: 6| Step: 9
Training loss: 8.167837142944336
Validation loss: 9.06646833112163

Epoch: 6| Step: 10
Training loss: 8.515825271606445
Validation loss: 9.064332244216756

Epoch: 6| Step: 11
Training loss: 9.36865234375
Validation loss: 9.06273260424214

Epoch: 6| Step: 12
Training loss: 9.45258903503418
Validation loss: 9.057506407460858

Epoch: 6| Step: 13
Training loss: 7.765604019165039
Validation loss: 9.052395215598485

Epoch: 4| Step: 0
Training loss: 8.769569396972656
Validation loss: 9.049963233291463

Epoch: 6| Step: 1
Training loss: 8.54326343536377
Validation loss: 9.048990126579039

Epoch: 6| Step: 2
Training loss: 8.947236061096191
Validation loss: 9.04481355605587

Epoch: 6| Step: 3
Training loss: 9.23550796508789
Validation loss: 9.039870846656061

Epoch: 6| Step: 4
Training loss: 7.575557708740234
Validation loss: 9.03697141011556

Epoch: 6| Step: 5
Training loss: 8.789741516113281
Validation loss: 9.033294103478873

Epoch: 6| Step: 6
Training loss: 8.301590919494629
Validation loss: 9.028399590523012

Epoch: 6| Step: 7
Training loss: 9.274163246154785
Validation loss: 9.025526077516618

Epoch: 6| Step: 8
Training loss: 9.997058868408203
Validation loss: 9.021594355183263

Epoch: 6| Step: 9
Training loss: 9.670926094055176
Validation loss: 9.01867788581438

Epoch: 6| Step: 10
Training loss: 7.6389923095703125
Validation loss: 9.012368786719538

Epoch: 6| Step: 11
Training loss: 9.049108505249023
Validation loss: 9.00920953032791

Epoch: 6| Step: 12
Training loss: 9.338769912719727
Validation loss: 9.006019879412907

Epoch: 6| Step: 13
Training loss: 7.857882976531982
Validation loss: 8.998713226728542

Epoch: 5| Step: 0
Training loss: 8.747784614562988
Validation loss: 8.997041599724882

Epoch: 6| Step: 1
Training loss: 8.255786895751953
Validation loss: 8.99004163024246

Epoch: 6| Step: 2
Training loss: 9.416686058044434
Validation loss: 8.987844672254337

Epoch: 6| Step: 3
Training loss: 7.064092636108398
Validation loss: 8.983736766281949

Epoch: 6| Step: 4
Training loss: 9.706159591674805
Validation loss: 8.978132606834494

Epoch: 6| Step: 5
Training loss: 9.60113525390625
Validation loss: 8.97293839403378

Epoch: 6| Step: 6
Training loss: 7.5428948402404785
Validation loss: 8.970237608878843

Epoch: 6| Step: 7
Training loss: 10.358969688415527
Validation loss: 8.96569029490153

Epoch: 6| Step: 8
Training loss: 9.45196533203125
Validation loss: 8.959372622992403

Epoch: 6| Step: 9
Training loss: 8.239823341369629
Validation loss: 8.957812196464948

Epoch: 6| Step: 10
Training loss: 7.937811851501465
Validation loss: 8.95310797742618

Epoch: 6| Step: 11
Training loss: 8.786283493041992
Validation loss: 8.947711770252514

Epoch: 6| Step: 12
Training loss: 8.536600112915039
Validation loss: 8.94333964522167

Epoch: 6| Step: 13
Training loss: 9.05797290802002
Validation loss: 8.9399478666244

Epoch: 6| Step: 0
Training loss: 9.117738723754883
Validation loss: 8.931436231059413

Epoch: 6| Step: 1
Training loss: 9.412137985229492
Validation loss: 8.92675684857112

Epoch: 6| Step: 2
Training loss: 7.571792125701904
Validation loss: 8.923367428523237

Epoch: 6| Step: 3
Training loss: 8.150232315063477
Validation loss: 8.918258543937437

Epoch: 6| Step: 4
Training loss: 8.85454273223877
Validation loss: 8.912697674125754

Epoch: 6| Step: 5
Training loss: 9.039746284484863
Validation loss: 8.90952222065259

Epoch: 6| Step: 6
Training loss: 9.798877716064453
Validation loss: 8.90501973962271

Epoch: 6| Step: 7
Training loss: 8.868429183959961
Validation loss: 8.898236941265804

Epoch: 6| Step: 8
Training loss: 9.190788269042969
Validation loss: 8.895829036671628

Epoch: 6| Step: 9
Training loss: 8.82464599609375
Validation loss: 8.888756085467595

Epoch: 6| Step: 10
Training loss: 7.970839977264404
Validation loss: 8.884118736431162

Epoch: 6| Step: 11
Training loss: 6.889553070068359
Validation loss: 8.880587864947575

Epoch: 6| Step: 12
Training loss: 9.225098609924316
Validation loss: 8.87070490724297

Epoch: 6| Step: 13
Training loss: 8.741954803466797
Validation loss: 8.868640653548702

Epoch: 7| Step: 0
Training loss: 9.106478691101074
Validation loss: 8.862510106896842

Epoch: 6| Step: 1
Training loss: 8.803156852722168
Validation loss: 8.859615725855674

Epoch: 6| Step: 2
Training loss: 8.39306926727295
Validation loss: 8.852332381791966

Epoch: 6| Step: 3
Training loss: 6.990629196166992
Validation loss: 8.8457703334029

Epoch: 6| Step: 4
Training loss: 8.700567245483398
Validation loss: 8.84036563545145

Epoch: 6| Step: 5
Training loss: 8.5780029296875
Validation loss: 8.834014379849998

Epoch: 6| Step: 6
Training loss: 9.291845321655273
Validation loss: 8.82712278058452

Epoch: 6| Step: 7
Training loss: 9.764238357543945
Validation loss: 8.824088270946216

Epoch: 6| Step: 8
Training loss: 8.858060836791992
Validation loss: 8.819919032435264

Epoch: 6| Step: 9
Training loss: 9.165750503540039
Validation loss: 8.812920129427345

Epoch: 6| Step: 10
Training loss: 7.115508079528809
Validation loss: 8.806462062302456

Epoch: 6| Step: 11
Training loss: 9.713315963745117
Validation loss: 8.799871803611838

Epoch: 6| Step: 12
Training loss: 8.466330528259277
Validation loss: 8.791533285571683

Epoch: 6| Step: 13
Training loss: 6.816468238830566
Validation loss: 8.788703805656843

Epoch: 8| Step: 0
Training loss: 7.395411968231201
Validation loss: 8.782302538553873

Epoch: 6| Step: 1
Training loss: 7.5987548828125
Validation loss: 8.776722220964329

Epoch: 6| Step: 2
Training loss: 9.093920707702637
Validation loss: 8.767429803007392

Epoch: 6| Step: 3
Training loss: 9.139209747314453
Validation loss: 8.765665310685353

Epoch: 6| Step: 4
Training loss: 8.978707313537598
Validation loss: 8.758246544868715

Epoch: 6| Step: 5
Training loss: 8.116098403930664
Validation loss: 8.75115607887186

Epoch: 6| Step: 6
Training loss: 7.863375663757324
Validation loss: 8.744465879214708

Epoch: 6| Step: 7
Training loss: 8.376609802246094
Validation loss: 8.73995610719086

Epoch: 6| Step: 8
Training loss: 8.621070861816406
Validation loss: 8.731272948685513

Epoch: 6| Step: 9
Training loss: 9.837770462036133
Validation loss: 8.726914682695943

Epoch: 6| Step: 10
Training loss: 8.82241439819336
Validation loss: 8.718784588639455

Epoch: 6| Step: 11
Training loss: 7.585322856903076
Validation loss: 8.710623310458276

Epoch: 6| Step: 12
Training loss: 8.727157592773438
Validation loss: 8.705703376441873

Epoch: 6| Step: 13
Training loss: 9.592467308044434
Validation loss: 8.699222923606955

Epoch: 9| Step: 0
Training loss: 9.470044136047363
Validation loss: 8.693904281944357

Epoch: 6| Step: 1
Training loss: 8.733896255493164
Validation loss: 8.680905116501675

Epoch: 6| Step: 2
Training loss: 8.486001968383789
Validation loss: 8.671499477919712

Epoch: 6| Step: 3
Training loss: 8.660935401916504
Validation loss: 8.66461363146382

Epoch: 6| Step: 4
Training loss: 7.392590522766113
Validation loss: 8.662369297396753

Epoch: 6| Step: 5
Training loss: 9.274081230163574
Validation loss: 8.653905786493773

Epoch: 6| Step: 6
Training loss: 8.221647262573242
Validation loss: 8.645774051707278

Epoch: 6| Step: 7
Training loss: 8.381282806396484
Validation loss: 8.637395653673398

Epoch: 6| Step: 8
Training loss: 8.368511199951172
Validation loss: 8.628867046807402

Epoch: 6| Step: 9
Training loss: 7.488926887512207
Validation loss: 8.62688866481986

Epoch: 6| Step: 10
Training loss: 9.063104629516602
Validation loss: 8.613843138499927

Epoch: 6| Step: 11
Training loss: 7.708637237548828
Validation loss: 8.605700944059638

Epoch: 6| Step: 12
Training loss: 8.852838516235352
Validation loss: 8.596485619903893

Epoch: 6| Step: 13
Training loss: 7.246297836303711
Validation loss: 8.58985161524947

Epoch: 10| Step: 0
Training loss: 8.324875831604004
Validation loss: 8.57979416590865

Epoch: 6| Step: 1
Training loss: 7.944342136383057
Validation loss: 8.573644350933773

Epoch: 6| Step: 2
Training loss: 7.444504261016846
Validation loss: 8.562810169753208

Epoch: 6| Step: 3
Training loss: 7.2100419998168945
Validation loss: 8.557749132956229

Epoch: 6| Step: 4
Training loss: 9.058990478515625
Validation loss: 8.542812849885674

Epoch: 6| Step: 5
Training loss: 8.196175575256348
Validation loss: 8.537396610424082

Epoch: 6| Step: 6
Training loss: 8.527223587036133
Validation loss: 8.528462163863644

Epoch: 6| Step: 7
Training loss: 8.930237770080566
Validation loss: 8.520656636966173

Epoch: 6| Step: 8
Training loss: 8.975142478942871
Validation loss: 8.507649555001208

Epoch: 6| Step: 9
Training loss: 9.171253204345703
Validation loss: 8.498035359126265

Epoch: 6| Step: 10
Training loss: 7.95638370513916
Validation loss: 8.487760954005743

Epoch: 6| Step: 11
Training loss: 7.818795680999756
Validation loss: 8.478988632079094

Epoch: 6| Step: 12
Training loss: 7.703588485717773
Validation loss: 8.469686672251711

Epoch: 6| Step: 13
Training loss: 9.448954582214355
Validation loss: 8.457837566252678

Epoch: 11| Step: 0
Training loss: 8.320959091186523
Validation loss: 8.45205161904776

Epoch: 6| Step: 1
Training loss: 8.801957130432129
Validation loss: 8.439143898666545

Epoch: 6| Step: 2
Training loss: 9.741092681884766
Validation loss: 8.434449359934817

Epoch: 6| Step: 3
Training loss: 7.34751033782959
Validation loss: 8.420716788179131

Epoch: 6| Step: 4
Training loss: 8.816472053527832
Validation loss: 8.40752201695596

Epoch: 6| Step: 5
Training loss: 7.8488006591796875
Validation loss: 8.399386887909264

Epoch: 6| Step: 6
Training loss: 7.011363506317139
Validation loss: 8.387296738163117

Epoch: 6| Step: 7
Training loss: 8.45145034790039
Validation loss: 8.379314843044487

Epoch: 6| Step: 8
Training loss: 8.675168991088867
Validation loss: 8.36041017757949

Epoch: 6| Step: 9
Training loss: 8.518346786499023
Validation loss: 8.348227623970278

Epoch: 6| Step: 10
Training loss: 7.886841297149658
Validation loss: 8.341298154605333

Epoch: 6| Step: 11
Training loss: 8.492076873779297
Validation loss: 8.33155713030087

Epoch: 6| Step: 12
Training loss: 6.451031684875488
Validation loss: 8.316279124188167

Epoch: 6| Step: 13
Training loss: 7.493611812591553
Validation loss: 8.300531136092319

Epoch: 12| Step: 0
Training loss: 7.531660079956055
Validation loss: 8.289944751288301

Epoch: 6| Step: 1
Training loss: 7.215502738952637
Validation loss: 8.282817420139107

Epoch: 6| Step: 2
Training loss: 7.984447479248047
Validation loss: 8.26992735298731

Epoch: 6| Step: 3
Training loss: 8.030184745788574
Validation loss: 8.260101359377625

Epoch: 6| Step: 4
Training loss: 6.662188529968262
Validation loss: 8.241469455021685

Epoch: 6| Step: 5
Training loss: 8.201997756958008
Validation loss: 8.230801054226454

Epoch: 6| Step: 6
Training loss: 8.883804321289062
Validation loss: 8.218984973046087

Epoch: 6| Step: 7
Training loss: 9.025086402893066
Validation loss: 8.21051359689364

Epoch: 6| Step: 8
Training loss: 7.52496862411499
Validation loss: 8.192414252988753

Epoch: 6| Step: 9
Training loss: 8.243671417236328
Validation loss: 8.181373073208716

Epoch: 6| Step: 10
Training loss: 7.935042381286621
Validation loss: 8.165911879590762

Epoch: 6| Step: 11
Training loss: 7.50325870513916
Validation loss: 8.15086543175482

Epoch: 6| Step: 12
Training loss: 8.142630577087402
Validation loss: 8.14430998730403

Epoch: 6| Step: 13
Training loss: 9.406669616699219
Validation loss: 8.125530022446828

Epoch: 13| Step: 0
Training loss: 7.888835906982422
Validation loss: 8.108510576268678

Epoch: 6| Step: 1
Training loss: 8.572953224182129
Validation loss: 8.099791275557651

Epoch: 6| Step: 2
Training loss: 7.48029088973999
Validation loss: 8.088011434001308

Epoch: 6| Step: 3
Training loss: 7.8897857666015625
Validation loss: 8.060935092228716

Epoch: 6| Step: 4
Training loss: 6.922813415527344
Validation loss: 8.05290021178543

Epoch: 6| Step: 5
Training loss: 8.106902122497559
Validation loss: 8.037375193770213

Epoch: 6| Step: 6
Training loss: 7.287456035614014
Validation loss: 8.028792883760186

Epoch: 6| Step: 7
Training loss: 7.2479329109191895
Validation loss: 8.004256535601872

Epoch: 6| Step: 8
Training loss: 7.303430080413818
Validation loss: 7.989624905329879

Epoch: 6| Step: 9
Training loss: 7.804980278015137
Validation loss: 7.976206476970385

Epoch: 6| Step: 10
Training loss: 6.8321332931518555
Validation loss: 7.960594618192283

Epoch: 6| Step: 11
Training loss: 7.89188814163208
Validation loss: 7.951403207676385

Epoch: 6| Step: 12
Training loss: 9.656853675842285
Validation loss: 7.926414828146657

Epoch: 6| Step: 13
Training loss: 8.147035598754883
Validation loss: 7.924076336686329

Epoch: 14| Step: 0
Training loss: 7.7732391357421875
Validation loss: 7.901919226492605

Epoch: 6| Step: 1
Training loss: 8.366886138916016
Validation loss: 7.882224206001528

Epoch: 6| Step: 2
Training loss: 6.191252708435059
Validation loss: 7.865540212200534

Epoch: 6| Step: 3
Training loss: 8.388707160949707
Validation loss: 7.843337607640092

Epoch: 6| Step: 4
Training loss: 6.597689151763916
Validation loss: 7.8308308150178645

Epoch: 6| Step: 5
Training loss: 8.853425979614258
Validation loss: 7.816817278503089

Epoch: 6| Step: 6
Training loss: 8.5177001953125
Validation loss: 7.796653296357842

Epoch: 6| Step: 7
Training loss: 7.072735786437988
Validation loss: 7.780125356489612

Epoch: 6| Step: 8
Training loss: 5.675718307495117
Validation loss: 7.767195265780213

Epoch: 6| Step: 9
Training loss: 7.275577545166016
Validation loss: 7.752745710393434

Epoch: 6| Step: 10
Training loss: 8.334470748901367
Validation loss: 7.728727950844713

Epoch: 6| Step: 11
Training loss: 7.2635626792907715
Validation loss: 7.722796886197982

Epoch: 6| Step: 12
Training loss: 7.209336280822754
Validation loss: 7.695978708164667

Epoch: 6| Step: 13
Training loss: 8.664830207824707
Validation loss: 7.683034768668554

Epoch: 15| Step: 0
Training loss: 7.987290382385254
Validation loss: 7.664533440784742

Epoch: 6| Step: 1
Training loss: 7.271792888641357
Validation loss: 7.64146282852337

Epoch: 6| Step: 2
Training loss: 8.328289031982422
Validation loss: 7.619615882955571

Epoch: 6| Step: 3
Training loss: 7.562671184539795
Validation loss: 7.602939092984763

Epoch: 6| Step: 4
Training loss: 6.514948844909668
Validation loss: 7.5807173585379

Epoch: 6| Step: 5
Training loss: 5.945799827575684
Validation loss: 7.564944462109637

Epoch: 6| Step: 6
Training loss: 7.633715629577637
Validation loss: 7.551247186558221

Epoch: 6| Step: 7
Training loss: 7.200313091278076
Validation loss: 7.529570887165685

Epoch: 6| Step: 8
Training loss: 7.473875999450684
Validation loss: 7.509840637124995

Epoch: 6| Step: 9
Training loss: 7.590646743774414
Validation loss: 7.490280838422878

Epoch: 6| Step: 10
Training loss: 6.924520969390869
Validation loss: 7.4628255546733895

Epoch: 6| Step: 11
Training loss: 6.89854097366333
Validation loss: 7.444420486368159

Epoch: 6| Step: 12
Training loss: 8.037677764892578
Validation loss: 7.431007241690031

Epoch: 6| Step: 13
Training loss: 6.159246921539307
Validation loss: 7.399271729171917

Epoch: 16| Step: 0
Training loss: 6.47550106048584
Validation loss: 7.3779581387837725

Epoch: 6| Step: 1
Training loss: 6.9487199783325195
Validation loss: 7.371380662405363

Epoch: 6| Step: 2
Training loss: 7.423537254333496
Validation loss: 7.347603664603285

Epoch: 6| Step: 3
Training loss: 6.702643394470215
Validation loss: 7.329639373287078

Epoch: 6| Step: 4
Training loss: 5.670865058898926
Validation loss: 7.29740430462745

Epoch: 6| Step: 5
Training loss: 7.246456146240234
Validation loss: 7.280010346443422

Epoch: 6| Step: 6
Training loss: 7.594721794128418
Validation loss: 7.2533844209486436

Epoch: 6| Step: 7
Training loss: 7.3626708984375
Validation loss: 7.237536758504888

Epoch: 6| Step: 8
Training loss: 7.117074966430664
Validation loss: 7.210297061551001

Epoch: 6| Step: 9
Training loss: 7.833973407745361
Validation loss: 7.189357070512669

Epoch: 6| Step: 10
Training loss: 8.083619117736816
Validation loss: 7.1669077565593104

Epoch: 6| Step: 11
Training loss: 6.7990617752075195
Validation loss: 7.143282623701198

Epoch: 6| Step: 12
Training loss: 6.392130374908447
Validation loss: 7.11736229414581

Epoch: 6| Step: 13
Training loss: 5.534393787384033
Validation loss: 7.0982124010721845

Epoch: 17| Step: 0
Training loss: 7.712418079376221
Validation loss: 7.068452435155069

Epoch: 6| Step: 1
Training loss: 5.734915733337402
Validation loss: 7.0436083834658385

Epoch: 6| Step: 2
Training loss: 7.890053749084473
Validation loss: 7.014790770828083

Epoch: 6| Step: 3
Training loss: 6.312711715698242
Validation loss: 6.99306535208097

Epoch: 6| Step: 4
Training loss: 6.3305206298828125
Validation loss: 6.973190969036471

Epoch: 6| Step: 5
Training loss: 6.849431037902832
Validation loss: 6.930325108189737

Epoch: 6| Step: 6
Training loss: 5.785635948181152
Validation loss: 6.90455961227417

Epoch: 6| Step: 7
Training loss: 7.06286096572876
Validation loss: 6.8903526285643215

Epoch: 6| Step: 8
Training loss: 6.845281600952148
Validation loss: 6.85991302100561

Epoch: 6| Step: 9
Training loss: 6.326962471008301
Validation loss: 6.842232396525722

Epoch: 6| Step: 10
Training loss: 7.019144058227539
Validation loss: 6.811864724723241

Epoch: 6| Step: 11
Training loss: 6.770861625671387
Validation loss: 6.784148416211528

Epoch: 6| Step: 12
Training loss: 5.881305694580078
Validation loss: 6.7546039191625455

Epoch: 6| Step: 13
Training loss: 6.68555212020874
Validation loss: 6.728233480966219

Epoch: 18| Step: 0
Training loss: 5.430881500244141
Validation loss: 6.678883157750612

Epoch: 6| Step: 1
Training loss: 5.521688461303711
Validation loss: 6.676617535211706

Epoch: 6| Step: 2
Training loss: 7.621494770050049
Validation loss: 6.649331564544349

Epoch: 6| Step: 3
Training loss: 6.067024230957031
Validation loss: 6.615348923590876

Epoch: 6| Step: 4
Training loss: 6.135024547576904
Validation loss: 6.574527427714358

Epoch: 6| Step: 5
Training loss: 6.2676801681518555
Validation loss: 6.553462766831921

Epoch: 6| Step: 6
Training loss: 7.595783710479736
Validation loss: 6.518901568587109

Epoch: 6| Step: 7
Training loss: 5.59527587890625
Validation loss: 6.4953806118298605

Epoch: 6| Step: 8
Training loss: 7.116974353790283
Validation loss: 6.464366564186671

Epoch: 6| Step: 9
Training loss: 5.867271423339844
Validation loss: 6.416122831324095

Epoch: 6| Step: 10
Training loss: 6.704512596130371
Validation loss: 6.38592888206564

Epoch: 6| Step: 11
Training loss: 5.28247594833374
Validation loss: 6.360940415372131

Epoch: 6| Step: 12
Training loss: 5.435601711273193
Validation loss: 6.329104259449949

Epoch: 6| Step: 13
Training loss: 6.504214763641357
Validation loss: 6.300971554171655

Epoch: 19| Step: 0
Training loss: 5.788066864013672
Validation loss: 6.246734531976843

Epoch: 6| Step: 1
Training loss: 7.0197834968566895
Validation loss: 6.219902289811001

Epoch: 6| Step: 2
Training loss: 5.943333625793457
Validation loss: 6.199858204010995

Epoch: 6| Step: 3
Training loss: 7.096770763397217
Validation loss: 6.134521479247718

Epoch: 6| Step: 4
Training loss: 4.798834800720215
Validation loss: 6.111284245726883

Epoch: 6| Step: 5
Training loss: 5.7940168380737305
Validation loss: 6.076118064183061

Epoch: 6| Step: 6
Training loss: 5.628228187561035
Validation loss: 6.025368777654505

Epoch: 6| Step: 7
Training loss: 5.117189407348633
Validation loss: 5.997549579989526

Epoch: 6| Step: 8
Training loss: 4.820680141448975
Validation loss: 5.9556101265773975

Epoch: 6| Step: 9
Training loss: 6.226372718811035
Validation loss: 5.91904697110576

Epoch: 6| Step: 10
Training loss: 5.188475608825684
Validation loss: 5.872366710375714

Epoch: 6| Step: 11
Training loss: 5.9303789138793945
Validation loss: 5.83573196780297

Epoch: 6| Step: 12
Training loss: 5.035949230194092
Validation loss: 5.77754351913288

Epoch: 6| Step: 13
Training loss: 5.739649772644043
Validation loss: 5.747637810245637

Epoch: 20| Step: 0
Training loss: 4.471798419952393
Validation loss: 5.692585914365707

Epoch: 6| Step: 1
Training loss: 6.368340492248535
Validation loss: 5.643036688527753

Epoch: 6| Step: 2
Training loss: 5.036859035491943
Validation loss: 5.6329792750779015

Epoch: 6| Step: 3
Training loss: 4.765423774719238
Validation loss: 5.537606193173316

Epoch: 6| Step: 4
Training loss: 5.084509372711182
Validation loss: 5.542951419789304

Epoch: 6| Step: 5
Training loss: 6.561532974243164
Validation loss: 5.468603672519807

Epoch: 6| Step: 6
Training loss: 6.098915100097656
Validation loss: 5.44177790611021

Epoch: 6| Step: 7
Training loss: 4.747987270355225
Validation loss: 5.38643709305794

Epoch: 6| Step: 8
Training loss: 5.388703346252441
Validation loss: 5.335948113472231

Epoch: 6| Step: 9
Training loss: 4.619855880737305
Validation loss: 5.277182399585683

Epoch: 6| Step: 10
Training loss: 5.258195400238037
Validation loss: 5.213985550788141

Epoch: 6| Step: 11
Training loss: 3.4965591430664062
Validation loss: 5.157764957797143

Epoch: 6| Step: 12
Training loss: 4.583932399749756
Validation loss: 5.136556717657274

Epoch: 6| Step: 13
Training loss: 4.974802017211914
Validation loss: 5.067749597693003

Epoch: 21| Step: 0
Training loss: 5.813940048217773
Validation loss: 5.027624812177432

Epoch: 6| Step: 1
Training loss: 5.192986488342285
Validation loss: 4.975559583274267

Epoch: 6| Step: 2
Training loss: 5.690343379974365
Validation loss: 4.915534926998999

Epoch: 6| Step: 3
Training loss: 4.194219589233398
Validation loss: 4.846020529347081

Epoch: 6| Step: 4
Training loss: 4.074729919433594
Validation loss: 4.800741995534589

Epoch: 6| Step: 5
Training loss: 4.005764007568359
Validation loss: 4.743263972702847

Epoch: 6| Step: 6
Training loss: 5.42279052734375
Validation loss: 4.691396062092115

Epoch: 6| Step: 7
Training loss: 3.5203428268432617
Validation loss: 4.64524971541538

Epoch: 6| Step: 8
Training loss: 3.9276657104492188
Validation loss: 4.605392938019127

Epoch: 6| Step: 9
Training loss: 3.693830728530884
Validation loss: 4.535583193584155

Epoch: 6| Step: 10
Training loss: 3.2219345569610596
Validation loss: 4.492255769750123

Epoch: 6| Step: 11
Training loss: 4.670928001403809
Validation loss: 4.437920037136283

Epoch: 6| Step: 12
Training loss: 4.025083541870117
Validation loss: 4.3849464437013035

Epoch: 6| Step: 13
Training loss: 4.005708694458008
Validation loss: 4.324754284274194

Epoch: 22| Step: 0
Training loss: 3.0505080223083496
Validation loss: 4.276167997749903

Epoch: 6| Step: 1
Training loss: 2.5384416580200195
Validation loss: 4.218204103490358

Epoch: 6| Step: 2
Training loss: 2.7886085510253906
Validation loss: 4.168616320497247

Epoch: 6| Step: 3
Training loss: 5.621392250061035
Validation loss: 4.104768514633179

Epoch: 6| Step: 4
Training loss: 4.209978103637695
Validation loss: 4.041379687606647

Epoch: 6| Step: 5
Training loss: 3.4274978637695312
Validation loss: 4.013267296616749

Epoch: 6| Step: 6
Training loss: 4.170887470245361
Validation loss: 3.8992865521420716

Epoch: 6| Step: 7
Training loss: 4.230889797210693
Validation loss: 3.892153129782728

Epoch: 6| Step: 8
Training loss: 3.0824098587036133
Validation loss: 3.838572912318732

Epoch: 6| Step: 9
Training loss: 4.129679203033447
Validation loss: 3.83055716688915

Epoch: 6| Step: 10
Training loss: 4.833312034606934
Validation loss: 3.751782473697457

Epoch: 6| Step: 11
Training loss: 3.2196099758148193
Validation loss: 3.6912991641670145

Epoch: 6| Step: 12
Training loss: 4.2553815841674805
Validation loss: 3.6510917114955124

Epoch: 6| Step: 13
Training loss: 2.41916561126709
Validation loss: 3.5847047093094035

Epoch: 23| Step: 0
Training loss: 3.1638402938842773
Validation loss: 3.5620861643104145

Epoch: 6| Step: 1
Training loss: 3.9286255836486816
Validation loss: 3.5049641157991145

Epoch: 6| Step: 2
Training loss: 2.850876808166504
Validation loss: 3.4818695232432377

Epoch: 6| Step: 3
Training loss: 2.262289524078369
Validation loss: 3.3944639749424432

Epoch: 6| Step: 4
Training loss: 3.9580881595611572
Validation loss: 3.3871261996607624

Epoch: 6| Step: 5
Training loss: 3.148890972137451
Validation loss: 3.35349271118

Epoch: 6| Step: 6
Training loss: 3.510157823562622
Validation loss: 3.292305523349393

Epoch: 6| Step: 7
Training loss: 2.8699493408203125
Validation loss: 3.266621833206505

Epoch: 6| Step: 8
Training loss: 3.5263538360595703
Validation loss: 3.2503822388187533

Epoch: 6| Step: 9
Training loss: 2.7816216945648193
Validation loss: 3.1837635655556955

Epoch: 6| Step: 10
Training loss: 3.838674783706665
Validation loss: 3.143229753740372

Epoch: 6| Step: 11
Training loss: 3.6876349449157715
Validation loss: 3.0932410096609466

Epoch: 6| Step: 12
Training loss: 2.619837760925293
Validation loss: 3.1156336517744165

Epoch: 6| Step: 13
Training loss: 3.456122875213623
Validation loss: 3.0483022838510494

Epoch: 24| Step: 0
Training loss: 3.3869261741638184
Validation loss: 3.036962652719149

Epoch: 6| Step: 1
Training loss: 2.260655164718628
Validation loss: 2.9977183470162014

Epoch: 6| Step: 2
Training loss: 2.7332520484924316
Validation loss: 3.001622430739864

Epoch: 6| Step: 3
Training loss: 3.792875051498413
Validation loss: 2.9521711641742336

Epoch: 6| Step: 4
Training loss: 3.4483752250671387
Validation loss: 2.922914553714055

Epoch: 6| Step: 5
Training loss: 2.786367893218994
Validation loss: 2.8915469159362135

Epoch: 6| Step: 6
Training loss: 2.905399799346924
Validation loss: 2.879576575371527

Epoch: 6| Step: 7
Training loss: 3.3167471885681152
Validation loss: 2.85061474000254

Epoch: 6| Step: 8
Training loss: 3.3185935020446777
Validation loss: 2.838261683781942

Epoch: 6| Step: 9
Training loss: 2.3691861629486084
Validation loss: 2.7951881911164973

Epoch: 6| Step: 10
Training loss: 2.6047439575195312
Validation loss: 2.7444440754511024

Epoch: 6| Step: 11
Training loss: 2.8602118492126465
Validation loss: 2.7200075734046196

Epoch: 6| Step: 12
Training loss: 2.325288772583008
Validation loss: 2.710528314754527

Epoch: 6| Step: 13
Training loss: 2.9450507164001465
Validation loss: 2.7460107726435505

Epoch: 25| Step: 0
Training loss: 2.4015445709228516
Validation loss: 2.721355030613561

Epoch: 6| Step: 1
Training loss: 3.1751198768615723
Validation loss: 2.7098142254737114

Epoch: 6| Step: 2
Training loss: 3.867607831954956
Validation loss: 2.714244488746889

Epoch: 6| Step: 3
Training loss: 1.5965938568115234
Validation loss: 2.6504069323180826

Epoch: 6| Step: 4
Training loss: 2.863924503326416
Validation loss: 2.648068307548441

Epoch: 6| Step: 5
Training loss: 2.76269793510437
Validation loss: 2.6800610685861237

Epoch: 6| Step: 6
Training loss: 3.939499855041504
Validation loss: 2.652653696716473

Epoch: 6| Step: 7
Training loss: 2.190361976623535
Validation loss: 2.6204944990014516

Epoch: 6| Step: 8
Training loss: 2.168341636657715
Validation loss: 2.618223915817917

Epoch: 6| Step: 9
Training loss: 2.605916976928711
Validation loss: 2.6091214328683834

Epoch: 6| Step: 10
Training loss: 2.609314441680908
Validation loss: 2.6188656463417956

Epoch: 6| Step: 11
Training loss: 2.3496081829071045
Validation loss: 2.6114391075667513

Epoch: 6| Step: 12
Training loss: 3.1954593658447266
Validation loss: 2.6082195543473765

Epoch: 6| Step: 13
Training loss: 2.7595415115356445
Validation loss: 2.561498208712506

Epoch: 26| Step: 0
Training loss: 2.553053379058838
Validation loss: 2.569056687816497

Epoch: 6| Step: 1
Training loss: 3.368396282196045
Validation loss: 2.5846154715425227

Epoch: 6| Step: 2
Training loss: 2.379298686981201
Validation loss: 2.567187650229341

Epoch: 6| Step: 3
Training loss: 2.6132121086120605
Validation loss: 2.501415406503985

Epoch: 6| Step: 4
Training loss: 2.312875747680664
Validation loss: 2.510150865841937

Epoch: 6| Step: 5
Training loss: 2.3721718788146973
Validation loss: 2.551955114128769

Epoch: 6| Step: 6
Training loss: 2.1568336486816406
Validation loss: 2.4839300622222242

Epoch: 6| Step: 7
Training loss: 2.3998005390167236
Validation loss: 2.5238930871409755

Epoch: 6| Step: 8
Training loss: 2.36564302444458
Validation loss: 2.5448477268218994

Epoch: 6| Step: 9
Training loss: 2.604248285293579
Validation loss: 2.491619740763018

Epoch: 6| Step: 10
Training loss: 2.902254581451416
Validation loss: 2.552064049628473

Epoch: 6| Step: 11
Training loss: 2.944359302520752
Validation loss: 2.5294749403512604

Epoch: 6| Step: 12
Training loss: 3.6773104667663574
Validation loss: 2.528728151834139

Epoch: 6| Step: 13
Training loss: 3.2242114543914795
Validation loss: 2.4888985823559504

Epoch: 27| Step: 0
Training loss: 1.8486806154251099
Validation loss: 2.487667191413141

Epoch: 6| Step: 1
Training loss: 3.454723834991455
Validation loss: 2.509513306361373

Epoch: 6| Step: 2
Training loss: 2.001241683959961
Validation loss: 2.5236346849831204

Epoch: 6| Step: 3
Training loss: 3.091794967651367
Validation loss: 2.459205701786985

Epoch: 6| Step: 4
Training loss: 2.691889762878418
Validation loss: 2.509796911670316

Epoch: 6| Step: 5
Training loss: 2.5477466583251953
Validation loss: 2.5023202485935663

Epoch: 6| Step: 6
Training loss: 2.2034988403320312
Validation loss: 2.5304734527423816

Epoch: 6| Step: 7
Training loss: 2.4106664657592773
Validation loss: 2.517342077788486

Epoch: 6| Step: 8
Training loss: 3.2934114933013916
Validation loss: 2.489733167873916

Epoch: 6| Step: 9
Training loss: 2.3732824325561523
Validation loss: 2.431443791235647

Epoch: 6| Step: 10
Training loss: 3.7174575328826904
Validation loss: 2.5046984098290883

Epoch: 6| Step: 11
Training loss: 2.259268045425415
Validation loss: 2.523909112458588

Epoch: 6| Step: 12
Training loss: 2.929898738861084
Validation loss: 2.5158466677511893

Epoch: 6| Step: 13
Training loss: 2.8130900859832764
Validation loss: 2.514661358248803

Epoch: 28| Step: 0
Training loss: 3.411510467529297
Validation loss: 2.462628943945772

Epoch: 6| Step: 1
Training loss: 3.4057703018188477
Validation loss: 2.50540469795145

Epoch: 6| Step: 2
Training loss: 2.9552905559539795
Validation loss: 2.4711463169385026

Epoch: 6| Step: 3
Training loss: 2.6273488998413086
Validation loss: 2.4968697614567255

Epoch: 6| Step: 4
Training loss: 1.5639498233795166
Validation loss: 2.4796819186979726

Epoch: 6| Step: 5
Training loss: 3.065433979034424
Validation loss: 2.4683633491557133

Epoch: 6| Step: 6
Training loss: 3.035776138305664
Validation loss: 2.45954305125821

Epoch: 6| Step: 7
Training loss: 2.0850114822387695
Validation loss: 2.4806478843894055

Epoch: 6| Step: 8
Training loss: 2.348015069961548
Validation loss: 2.4731410164986887

Epoch: 6| Step: 9
Training loss: 2.8383967876434326
Validation loss: 2.4739282156831477

Epoch: 6| Step: 10
Training loss: 2.761685848236084
Validation loss: 2.401026277131932

Epoch: 6| Step: 11
Training loss: 2.213423252105713
Validation loss: 2.457467217599192

Epoch: 6| Step: 12
Training loss: 2.245203733444214
Validation loss: 2.48408995392502

Epoch: 6| Step: 13
Training loss: 2.6069843769073486
Validation loss: 2.4542232508300454

Epoch: 29| Step: 0
Training loss: 2.133344888687134
Validation loss: 2.442244229778167

Epoch: 6| Step: 1
Training loss: 3.9611423015594482
Validation loss: 2.4867626338876705

Epoch: 6| Step: 2
Training loss: 3.2104592323303223
Validation loss: 2.479616172852055

Epoch: 6| Step: 3
Training loss: 2.5725655555725098
Validation loss: 2.4269935700201217

Epoch: 6| Step: 4
Training loss: 2.59397292137146
Validation loss: 2.4470381070208806

Epoch: 6| Step: 5
Training loss: 2.6255457401275635
Validation loss: 2.432948230415262

Epoch: 6| Step: 6
Training loss: 2.4541687965393066
Validation loss: 2.442545816462527

Epoch: 6| Step: 7
Training loss: 2.4261157512664795
Validation loss: 2.4514941374460855

Epoch: 6| Step: 8
Training loss: 2.8135554790496826
Validation loss: 2.44043364063386

Epoch: 6| Step: 9
Training loss: 1.8805519342422485
Validation loss: 2.4690370969874884

Epoch: 6| Step: 10
Training loss: 3.362342119216919
Validation loss: 2.439059301089215

Epoch: 6| Step: 11
Training loss: 2.375462293624878
Validation loss: 2.417310683957992

Epoch: 6| Step: 12
Training loss: 1.8172210454940796
Validation loss: 2.4356766439253286

Epoch: 6| Step: 13
Training loss: 2.3507630825042725
Validation loss: 2.394815460328133

Epoch: 30| Step: 0
Training loss: 2.883174180984497
Validation loss: 2.4715502287751887

Epoch: 6| Step: 1
Training loss: 2.5216314792633057
Validation loss: 2.4165737257208875

Epoch: 6| Step: 2
Training loss: 2.4292736053466797
Validation loss: 2.445118499058549

Epoch: 6| Step: 3
Training loss: 3.2552695274353027
Validation loss: 2.3989788229747484

Epoch: 6| Step: 4
Training loss: 1.9276865720748901
Validation loss: 2.430324698007235

Epoch: 6| Step: 5
Training loss: 3.157742977142334
Validation loss: 2.4528810644662506

Epoch: 6| Step: 6
Training loss: 2.865757703781128
Validation loss: 2.4807086734361548

Epoch: 6| Step: 7
Training loss: 2.595444679260254
Validation loss: 2.4185013040419547

Epoch: 6| Step: 8
Training loss: 1.8277673721313477
Validation loss: 2.4666991849099436

Epoch: 6| Step: 9
Training loss: 2.382800579071045
Validation loss: 2.4393590419523177

Epoch: 6| Step: 10
Training loss: 2.8247814178466797
Validation loss: 2.404293385885095

Epoch: 6| Step: 11
Training loss: 2.7986133098602295
Validation loss: 2.464981399556642

Epoch: 6| Step: 12
Training loss: 2.99983549118042
Validation loss: 2.4719374410567747

Epoch: 6| Step: 13
Training loss: 2.180102825164795
Validation loss: 2.422457887280372

Epoch: 31| Step: 0
Training loss: 2.0830352306365967
Validation loss: 2.4237782878260457

Epoch: 6| Step: 1
Training loss: 2.1310009956359863
Validation loss: 2.457252105077108

Epoch: 6| Step: 2
Training loss: 2.554960012435913
Validation loss: 2.426329687077512

Epoch: 6| Step: 3
Training loss: 2.9672493934631348
Validation loss: 2.412212907627065

Epoch: 6| Step: 4
Training loss: 3.0209648609161377
Validation loss: 2.4250191232209564

Epoch: 6| Step: 5
Training loss: 3.4032130241394043
Validation loss: 2.419163316808721

Epoch: 6| Step: 6
Training loss: 3.1166818141937256
Validation loss: 2.402850727881155

Epoch: 6| Step: 7
Training loss: 3.012389659881592
Validation loss: 2.3801872038072154

Epoch: 6| Step: 8
Training loss: 2.231112003326416
Validation loss: 2.4115996694052093

Epoch: 6| Step: 9
Training loss: 1.5119283199310303
Validation loss: 2.419644353210285

Epoch: 6| Step: 10
Training loss: 2.255032777786255
Validation loss: 2.3853466356954267

Epoch: 6| Step: 11
Training loss: 1.8482493162155151
Validation loss: 2.376003647363314

Epoch: 6| Step: 12
Training loss: 3.030473232269287
Validation loss: 2.4135431948528496

Epoch: 6| Step: 13
Training loss: 3.42195200920105
Validation loss: 2.37713820703568

Epoch: 32| Step: 0
Training loss: 2.6130409240722656
Validation loss: 2.3924775315869238

Epoch: 6| Step: 1
Training loss: 2.058377981185913
Validation loss: 2.356831842853177

Epoch: 6| Step: 2
Training loss: 2.974604606628418
Validation loss: 2.3751381366483626

Epoch: 6| Step: 3
Training loss: 2.2227635383605957
Validation loss: 2.414864622136598

Epoch: 6| Step: 4
Training loss: 2.883014678955078
Validation loss: 2.429729487306328

Epoch: 6| Step: 5
Training loss: 2.1036479473114014
Validation loss: 2.395235320573212

Epoch: 6| Step: 6
Training loss: 2.0512938499450684
Validation loss: 2.40168333566317

Epoch: 6| Step: 7
Training loss: 2.231106758117676
Validation loss: 2.3816175845361527

Epoch: 6| Step: 8
Training loss: 3.199937343597412
Validation loss: 2.384687780052103

Epoch: 6| Step: 9
Training loss: 3.2813124656677246
Validation loss: 2.3753807185798563

Epoch: 6| Step: 10
Training loss: 2.7114415168762207
Validation loss: 2.3929407955497823

Epoch: 6| Step: 11
Training loss: 2.779287815093994
Validation loss: 2.42209804186257

Epoch: 6| Step: 12
Training loss: 2.6625466346740723
Validation loss: 2.3981106819645053

Epoch: 6| Step: 13
Training loss: 2.2556519508361816
Validation loss: 2.380796975986932

Epoch: 33| Step: 0
Training loss: 2.4765405654907227
Validation loss: 2.3670091808483167

Epoch: 6| Step: 1
Training loss: 2.5505762100219727
Validation loss: 2.3664259500400995

Epoch: 6| Step: 2
Training loss: 2.2787344455718994
Validation loss: 2.3761263432041293

Epoch: 6| Step: 3
Training loss: 2.0495638847351074
Validation loss: 2.3942456681241273

Epoch: 6| Step: 4
Training loss: 2.681631088256836
Validation loss: 2.404038690751599

Epoch: 6| Step: 5
Training loss: 2.361034393310547
Validation loss: 2.3826892824583155

Epoch: 6| Step: 6
Training loss: 3.592660903930664
Validation loss: 2.376458206484395

Epoch: 6| Step: 7
Training loss: 2.5067801475524902
Validation loss: 2.4497466010432087

Epoch: 6| Step: 8
Training loss: 2.8538057804107666
Validation loss: 2.4450900016292447

Epoch: 6| Step: 9
Training loss: 2.3130338191986084
Validation loss: 2.3962969549240603

Epoch: 6| Step: 10
Training loss: 2.029231071472168
Validation loss: 2.4045696950727895

Epoch: 6| Step: 11
Training loss: 2.2151923179626465
Validation loss: 2.4134166779056674

Epoch: 6| Step: 12
Training loss: 3.6647939682006836
Validation loss: 2.375948670089886

Epoch: 6| Step: 13
Training loss: 3.1216201782226562
Validation loss: 2.385089441012311

Epoch: 34| Step: 0
Training loss: 3.080080509185791
Validation loss: 2.4133021805876043

Epoch: 6| Step: 1
Training loss: 2.608950614929199
Validation loss: 2.4127035397355274

Epoch: 6| Step: 2
Training loss: 2.6437642574310303
Validation loss: 2.3772197564442954

Epoch: 6| Step: 3
Training loss: 1.6971492767333984
Validation loss: 2.3662909512878745

Epoch: 6| Step: 4
Training loss: 2.367570400238037
Validation loss: 2.3859571615854898

Epoch: 6| Step: 5
Training loss: 1.8741118907928467
Validation loss: 2.4093118124110724

Epoch: 6| Step: 6
Training loss: 3.1496453285217285
Validation loss: 2.3948074233147407

Epoch: 6| Step: 7
Training loss: 2.197953224182129
Validation loss: 2.361211810060727

Epoch: 6| Step: 8
Training loss: 2.4565694332122803
Validation loss: 2.3914108148185154

Epoch: 6| Step: 9
Training loss: 2.4014534950256348
Validation loss: 2.3223159159383466

Epoch: 6| Step: 10
Training loss: 2.2643399238586426
Validation loss: 2.3278670285337713

Epoch: 6| Step: 11
Training loss: 2.624238967895508
Validation loss: 2.405011858991397

Epoch: 6| Step: 12
Training loss: 3.1289124488830566
Validation loss: 2.3701514197934057

Epoch: 6| Step: 13
Training loss: 3.70059871673584
Validation loss: 2.3500012069620113

Epoch: 35| Step: 0
Training loss: 2.9170942306518555
Validation loss: 2.3255706961436937

Epoch: 6| Step: 1
Training loss: 2.8539445400238037
Validation loss: 2.3246972150700067

Epoch: 6| Step: 2
Training loss: 3.0725555419921875
Validation loss: 2.3665743181782384

Epoch: 6| Step: 3
Training loss: 2.315965175628662
Validation loss: 2.4079892584072646

Epoch: 6| Step: 4
Training loss: 2.084587574005127
Validation loss: 2.358067527894051

Epoch: 6| Step: 5
Training loss: 2.03427791595459
Validation loss: 2.352222358026812

Epoch: 6| Step: 6
Training loss: 2.69246768951416
Validation loss: 2.338235596174835

Epoch: 6| Step: 7
Training loss: 2.7962727546691895
Validation loss: 2.3223180540146364

Epoch: 6| Step: 8
Training loss: 2.9280335903167725
Validation loss: 2.3302924197207213

Epoch: 6| Step: 9
Training loss: 2.769918918609619
Validation loss: 2.3319344828205724

Epoch: 6| Step: 10
Training loss: 1.984320878982544
Validation loss: 2.3833154273289505

Epoch: 6| Step: 11
Training loss: 1.67732572555542
Validation loss: 2.4208236919936312

Epoch: 6| Step: 12
Training loss: 2.731607437133789
Validation loss: 2.3643257553859423

Epoch: 6| Step: 13
Training loss: 2.9860775470733643
Validation loss: 2.3362996988399054

Epoch: 36| Step: 0
Training loss: 2.5966081619262695
Validation loss: 2.3180247968243015

Epoch: 6| Step: 1
Training loss: 2.358283758163452
Validation loss: 2.347062045528043

Epoch: 6| Step: 2
Training loss: 2.4406681060791016
Validation loss: 2.3423837654052244

Epoch: 6| Step: 3
Training loss: 2.3358757495880127
Validation loss: 2.310557755090857

Epoch: 6| Step: 4
Training loss: 2.934081554412842
Validation loss: 2.341609386987584

Epoch: 6| Step: 5
Training loss: 2.495239734649658
Validation loss: 2.327118271140642

Epoch: 6| Step: 6
Training loss: 3.4836201667785645
Validation loss: 2.3785588613120456

Epoch: 6| Step: 7
Training loss: 2.57466197013855
Validation loss: 2.3292576420691704

Epoch: 6| Step: 8
Training loss: 1.902540683746338
Validation loss: 2.343113963321973

Epoch: 6| Step: 9
Training loss: 2.4136650562286377
Validation loss: 2.3624458210442656

Epoch: 6| Step: 10
Training loss: 3.5255541801452637
Validation loss: 2.3559298310228574

Epoch: 6| Step: 11
Training loss: 2.256500482559204
Validation loss: 2.3559266726175943

Epoch: 6| Step: 12
Training loss: 1.7640897035598755
Validation loss: 2.289316677278088

Epoch: 6| Step: 13
Training loss: 1.716113567352295
Validation loss: 2.327089589129212

Epoch: 37| Step: 0
Training loss: 2.517937183380127
Validation loss: 2.3575729811063377

Epoch: 6| Step: 1
Training loss: 2.9988207817077637
Validation loss: 2.3634896304017756

Epoch: 6| Step: 2
Training loss: 2.0464887619018555
Validation loss: 2.282226639409219

Epoch: 6| Step: 3
Training loss: 2.75535249710083
Validation loss: 2.316720275468724

Epoch: 6| Step: 4
Training loss: 2.3811135292053223
Validation loss: 2.310821525512203

Epoch: 6| Step: 5
Training loss: 2.5330004692077637
Validation loss: 2.3039534143222276

Epoch: 6| Step: 6
Training loss: 2.7909841537475586
Validation loss: 2.31000114769064

Epoch: 6| Step: 7
Training loss: 1.9220741987228394
Validation loss: 2.316622830206348

Epoch: 6| Step: 8
Training loss: 2.453436851501465
Validation loss: 2.285294639166965

Epoch: 6| Step: 9
Training loss: 2.712317943572998
Validation loss: 2.3039973115408294

Epoch: 6| Step: 10
Training loss: 2.1249752044677734
Validation loss: 2.30677225641025

Epoch: 6| Step: 11
Training loss: 3.0758373737335205
Validation loss: 2.3670440437973186

Epoch: 6| Step: 12
Training loss: 2.2113542556762695
Validation loss: 2.316890105124443

Epoch: 6| Step: 13
Training loss: 2.674414873123169
Validation loss: 2.304111667858657

Epoch: 38| Step: 0
Training loss: 3.3050150871276855
Validation loss: 2.32481066642269

Epoch: 6| Step: 1
Training loss: 2.362642765045166
Validation loss: 2.3110404065860215

Epoch: 6| Step: 2
Training loss: 3.352958917617798
Validation loss: 2.351614003540367

Epoch: 6| Step: 3
Training loss: 3.0226712226867676
Validation loss: 2.317944235699151

Epoch: 6| Step: 4
Training loss: 1.3691517114639282
Validation loss: 2.3079618151469896

Epoch: 6| Step: 5
Training loss: 1.7671279907226562
Validation loss: 2.298439803943839

Epoch: 6| Step: 6
Training loss: 2.582005500793457
Validation loss: 2.345961655339887

Epoch: 6| Step: 7
Training loss: 2.4582438468933105
Validation loss: 2.3594825498519407

Epoch: 6| Step: 8
Training loss: 2.590670585632324
Validation loss: 2.3414124647776284

Epoch: 6| Step: 9
Training loss: 2.1594667434692383
Validation loss: 2.2945806569950555

Epoch: 6| Step: 10
Training loss: 2.351728916168213
Validation loss: 2.295885375750962

Epoch: 6| Step: 11
Training loss: 2.4421000480651855
Validation loss: 2.3096726184250205

Epoch: 6| Step: 12
Training loss: 2.6105332374572754
Validation loss: 2.3291159496512464

Epoch: 6| Step: 13
Training loss: 2.8800888061523438
Validation loss: 2.266515060137677

Epoch: 39| Step: 0
Training loss: 1.9330990314483643
Validation loss: 2.3285689969216623

Epoch: 6| Step: 1
Training loss: 3.2837703227996826
Validation loss: 2.2983807799636677

Epoch: 6| Step: 2
Training loss: 3.2227413654327393
Validation loss: 2.3063149913664787

Epoch: 6| Step: 3
Training loss: 2.681525707244873
Validation loss: 2.350849407975392

Epoch: 6| Step: 4
Training loss: 2.116516590118408
Validation loss: 2.328530498730239

Epoch: 6| Step: 5
Training loss: 2.02586030960083
Validation loss: 2.2862278646038425

Epoch: 6| Step: 6
Training loss: 2.8257079124450684
Validation loss: 2.34238858889508

Epoch: 6| Step: 7
Training loss: 2.7088851928710938
Validation loss: 2.3521981957138225

Epoch: 6| Step: 8
Training loss: 2.84114933013916
Validation loss: 2.3784365025899743

Epoch: 6| Step: 9
Training loss: 3.164785861968994
Validation loss: 2.329630487708635

Epoch: 6| Step: 10
Training loss: 2.219122886657715
Validation loss: 2.36011980554109

Epoch: 6| Step: 11
Training loss: 2.1353249549865723
Validation loss: 2.3155600178626274

Epoch: 6| Step: 12
Training loss: 2.3822054862976074
Validation loss: 2.320764426262148

Epoch: 6| Step: 13
Training loss: 1.051283359527588
Validation loss: 2.328058535052884

Epoch: 40| Step: 0
Training loss: 2.563251256942749
Validation loss: 2.347135343859273

Epoch: 6| Step: 1
Training loss: 2.2119827270507812
Validation loss: 2.3549231790727183

Epoch: 6| Step: 2
Training loss: 2.503121852874756
Validation loss: 2.33598506066107

Epoch: 6| Step: 3
Training loss: 2.504267692565918
Validation loss: 2.3081696674387944

Epoch: 6| Step: 4
Training loss: 2.926677703857422
Validation loss: 2.310932497824392

Epoch: 6| Step: 5
Training loss: 3.0283827781677246
Validation loss: 2.351525309265301

Epoch: 6| Step: 6
Training loss: 2.5870859622955322
Validation loss: 2.2747605359682472

Epoch: 6| Step: 7
Training loss: 2.0293397903442383
Validation loss: 2.346590716351745

Epoch: 6| Step: 8
Training loss: 2.61326265335083
Validation loss: 2.363724454756706

Epoch: 6| Step: 9
Training loss: 2.3320095539093018
Validation loss: 2.342280526315012

Epoch: 6| Step: 10
Training loss: 2.5489649772644043
Validation loss: 2.3072580265742477

Epoch: 6| Step: 11
Training loss: 2.078824758529663
Validation loss: 2.3037325938542685

Epoch: 6| Step: 12
Training loss: 1.980103611946106
Validation loss: 2.3190654631583922

Epoch: 6| Step: 13
Training loss: 2.40132737159729
Validation loss: 2.3374104653635333

Epoch: 41| Step: 0
Training loss: 2.970496416091919
Validation loss: 2.312727864070605

Epoch: 6| Step: 1
Training loss: 2.6526081562042236
Validation loss: 2.3418457302995908

Epoch: 6| Step: 2
Training loss: 2.2022597789764404
Validation loss: 2.2709410395673526

Epoch: 6| Step: 3
Training loss: 3.4325380325317383
Validation loss: 2.2963598774325464

Epoch: 6| Step: 4
Training loss: 2.310915946960449
Validation loss: 2.3435675174959245

Epoch: 6| Step: 5
Training loss: 2.6448171138763428
Validation loss: 2.28385288869181

Epoch: 6| Step: 6
Training loss: 2.5204007625579834
Validation loss: 2.334555536188105

Epoch: 6| Step: 7
Training loss: 2.0618045330047607
Validation loss: 2.3009485031968806

Epoch: 6| Step: 8
Training loss: 2.157412052154541
Validation loss: 2.270666627473729

Epoch: 6| Step: 9
Training loss: 1.9903533458709717
Validation loss: 2.234553039714854

Epoch: 6| Step: 10
Training loss: 2.747812509536743
Validation loss: 2.3068365127809587

Epoch: 6| Step: 11
Training loss: 2.27940034866333
Validation loss: 2.2398396281785864

Epoch: 6| Step: 12
Training loss: 2.4231367111206055
Validation loss: 2.2828818957010903

Epoch: 6| Step: 13
Training loss: 2.212148904800415
Validation loss: 2.326984146589874

Epoch: 42| Step: 0
Training loss: 2.9925684928894043
Validation loss: 2.3370904127756753

Epoch: 6| Step: 1
Training loss: 2.3041629791259766
Validation loss: 2.259319051619499

Epoch: 6| Step: 2
Training loss: 2.6560144424438477
Validation loss: 2.3274272231645483

Epoch: 6| Step: 3
Training loss: 2.101170063018799
Validation loss: 2.3827962285728863

Epoch: 6| Step: 4
Training loss: 2.7956581115722656
Validation loss: 2.2982961208589616

Epoch: 6| Step: 5
Training loss: 2.4210638999938965
Validation loss: 2.3247428812006468

Epoch: 6| Step: 6
Training loss: 2.1408958435058594
Validation loss: 2.3087149845656527

Epoch: 6| Step: 7
Training loss: 2.8375110626220703
Validation loss: 2.295466963962842

Epoch: 6| Step: 8
Training loss: 2.3558168411254883
Validation loss: 2.2242352731766237

Epoch: 6| Step: 9
Training loss: 2.7880349159240723
Validation loss: 2.3007121445030294

Epoch: 6| Step: 10
Training loss: 2.3760571479797363
Validation loss: 2.2783567264515865

Epoch: 6| Step: 11
Training loss: 1.6749588251113892
Validation loss: 2.2741099775478406

Epoch: 6| Step: 12
Training loss: 2.639310359954834
Validation loss: 2.302542249361674

Epoch: 6| Step: 13
Training loss: 2.091606616973877
Validation loss: 2.211918336088939

Epoch: 43| Step: 0
Training loss: 1.6587653160095215
Validation loss: 2.249025901158651

Epoch: 6| Step: 1
Training loss: 3.1649060249328613
Validation loss: 2.274734304797265

Epoch: 6| Step: 2
Training loss: 2.4759936332702637
Validation loss: 2.2680057915308143

Epoch: 6| Step: 3
Training loss: 4.165095329284668
Validation loss: 2.27300755182902

Epoch: 6| Step: 4
Training loss: 2.959300994873047
Validation loss: 2.311167199124572

Epoch: 6| Step: 5
Training loss: 2.2697176933288574
Validation loss: 2.249858328091201

Epoch: 6| Step: 6
Training loss: 2.373727798461914
Validation loss: 2.2465033326097714

Epoch: 6| Step: 7
Training loss: 2.4624438285827637
Validation loss: 2.294809579849243

Epoch: 6| Step: 8
Training loss: 2.7355799674987793
Validation loss: 2.259348128431587

Epoch: 6| Step: 9
Training loss: 1.9985206127166748
Validation loss: 2.2664700220989924

Epoch: 6| Step: 10
Training loss: 1.249997615814209
Validation loss: 2.2805377873041297

Epoch: 6| Step: 11
Training loss: 2.4905495643615723
Validation loss: 2.249503829145944

Epoch: 6| Step: 12
Training loss: 2.237246036529541
Validation loss: 2.3312876865427983

Epoch: 6| Step: 13
Training loss: 2.627241611480713
Validation loss: 2.208515949146722

Epoch: 44| Step: 0
Training loss: 2.350409507751465
Validation loss: 2.289518728051134

Epoch: 6| Step: 1
Training loss: 2.5979740619659424
Validation loss: 2.2549642080901773

Epoch: 6| Step: 2
Training loss: 2.078084945678711
Validation loss: 2.3427874734324794

Epoch: 6| Step: 3
Training loss: 2.2717816829681396
Validation loss: 2.3002880568145425

Epoch: 6| Step: 4
Training loss: 2.2425899505615234
Validation loss: 2.2071188265277493

Epoch: 6| Step: 5
Training loss: 3.010472297668457
Validation loss: 2.2900933347722536

Epoch: 6| Step: 6
Training loss: 2.453324794769287
Validation loss: 2.3029100548836494

Epoch: 6| Step: 7
Training loss: 2.366987705230713
Validation loss: 2.311522432552871

Epoch: 6| Step: 8
Training loss: 2.350543975830078
Validation loss: 2.275414095130018

Epoch: 6| Step: 9
Training loss: 3.2574515342712402
Validation loss: 2.329281505718026

Epoch: 6| Step: 10
Training loss: 2.3826751708984375
Validation loss: 2.264246532993932

Epoch: 6| Step: 11
Training loss: 2.3794236183166504
Validation loss: 2.3208212519204743

Epoch: 6| Step: 12
Training loss: 1.9853243827819824
Validation loss: 2.287063826796829

Epoch: 6| Step: 13
Training loss: 2.3754544258117676
Validation loss: 2.2857735464649815

Epoch: 45| Step: 0
Training loss: 2.953512191772461
Validation loss: 2.2878794516286542

Epoch: 6| Step: 1
Training loss: 1.6978800296783447
Validation loss: 2.306100609481976

Epoch: 6| Step: 2
Training loss: 2.082947254180908
Validation loss: 2.3046573028769544

Epoch: 6| Step: 3
Training loss: 3.1070971488952637
Validation loss: 2.277366051109888

Epoch: 6| Step: 4
Training loss: 2.9320425987243652
Validation loss: 2.2918421555590887

Epoch: 6| Step: 5
Training loss: 2.1302225589752197
Validation loss: 2.304147429363702

Epoch: 6| Step: 6
Training loss: 3.3158249855041504
Validation loss: 2.291806282535676

Epoch: 6| Step: 7
Training loss: 2.438066005706787
Validation loss: 2.2674695214917584

Epoch: 6| Step: 8
Training loss: 2.4165635108947754
Validation loss: 2.2666255991945983

Epoch: 6| Step: 9
Training loss: 2.1450212001800537
Validation loss: 2.2814530031655424

Epoch: 6| Step: 10
Training loss: 1.553313970565796
Validation loss: 2.3302302078534196

Epoch: 6| Step: 11
Training loss: 2.1737558841705322
Validation loss: 2.2025682080176567

Epoch: 6| Step: 12
Training loss: 2.65251088142395
Validation loss: 2.291442989021219

Epoch: 6| Step: 13
Training loss: 3.1283063888549805
Validation loss: 2.228251334159605

Epoch: 46| Step: 0
Training loss: 2.355508327484131
Validation loss: 2.2372815147522958

Epoch: 6| Step: 1
Training loss: 2.1815743446350098
Validation loss: 2.304255203534198

Epoch: 6| Step: 2
Training loss: 2.2893567085266113
Validation loss: 2.38031034059422

Epoch: 6| Step: 3
Training loss: 2.713320732116699
Validation loss: 2.2780871775842484

Epoch: 6| Step: 4
Training loss: 2.73409366607666
Validation loss: 2.313836100280926

Epoch: 6| Step: 5
Training loss: 1.5074472427368164
Validation loss: 2.279482323636291

Epoch: 6| Step: 6
Training loss: 2.1242377758026123
Validation loss: 2.3563109931125434

Epoch: 6| Step: 7
Training loss: 2.9451582431793213
Validation loss: 2.2616830589950725

Epoch: 6| Step: 8
Training loss: 2.4155564308166504
Validation loss: 2.2277727562894105

Epoch: 6| Step: 9
Training loss: 2.932706356048584
Validation loss: 2.315353426882016

Epoch: 6| Step: 10
Training loss: 2.8029263019561768
Validation loss: 2.2553518702906947

Epoch: 6| Step: 11
Training loss: 1.935698390007019
Validation loss: 2.2618482369248585

Epoch: 6| Step: 12
Training loss: 2.970078468322754
Validation loss: 2.2795950622968775

Epoch: 6| Step: 13
Training loss: 1.9087278842926025
Validation loss: 2.3091349396654355

Epoch: 47| Step: 0
Training loss: 2.201294422149658
Validation loss: 2.245497788152387

Epoch: 6| Step: 1
Training loss: 2.580723524093628
Validation loss: 2.344776434283103

Epoch: 6| Step: 2
Training loss: 2.1815948486328125
Validation loss: 2.322547090950833

Epoch: 6| Step: 3
Training loss: 2.435690402984619
Validation loss: 2.258296751206921

Epoch: 6| Step: 4
Training loss: 2.46152925491333
Validation loss: 2.266774833843272

Epoch: 6| Step: 5
Training loss: 2.376199245452881
Validation loss: 2.2936720822447088

Epoch: 6| Step: 6
Training loss: 2.4154365062713623
Validation loss: 2.262793005153697

Epoch: 6| Step: 7
Training loss: 2.7542924880981445
Validation loss: 2.2237045739286687

Epoch: 6| Step: 8
Training loss: 2.789142608642578
Validation loss: 2.308100527332675

Epoch: 6| Step: 9
Training loss: 3.4979147911071777
Validation loss: 2.282721678415934

Epoch: 6| Step: 10
Training loss: 1.3911304473876953
Validation loss: 2.3259104631280385

Epoch: 6| Step: 11
Training loss: 2.374229907989502
Validation loss: 2.339978523151849

Epoch: 6| Step: 12
Training loss: 2.536008834838867
Validation loss: 2.2362517387636247

Epoch: 6| Step: 13
Training loss: 1.4681661128997803
Validation loss: 2.309673466990071

Epoch: 48| Step: 0
Training loss: 1.7567777633666992
Validation loss: 2.296917628216487

Epoch: 6| Step: 1
Training loss: 2.308115243911743
Validation loss: 2.298614909571986

Epoch: 6| Step: 2
Training loss: 2.3044910430908203
Validation loss: 2.3372183358797463

Epoch: 6| Step: 3
Training loss: 2.168879985809326
Validation loss: 2.2567456255676928

Epoch: 6| Step: 4
Training loss: 2.681954860687256
Validation loss: 2.269707058065681

Epoch: 6| Step: 5
Training loss: 2.4468235969543457
Validation loss: 2.185305744089106

Epoch: 6| Step: 6
Training loss: 2.7320897579193115
Validation loss: 2.2788499811644196

Epoch: 6| Step: 7
Training loss: 3.2574381828308105
Validation loss: 2.3042293928002797

Epoch: 6| Step: 8
Training loss: 2.570039749145508
Validation loss: 2.2784340227803876

Epoch: 6| Step: 9
Training loss: 1.8528623580932617
Validation loss: 2.312255379974201

Epoch: 6| Step: 10
Training loss: 2.373469829559326
Validation loss: 2.2493138415839082

Epoch: 6| Step: 11
Training loss: 2.1578774452209473
Validation loss: 2.2812520227124615

Epoch: 6| Step: 12
Training loss: 2.6676883697509766
Validation loss: 2.2710151339089997

Epoch: 6| Step: 13
Training loss: 2.3958234786987305
Validation loss: 2.2667885993116643

Epoch: 49| Step: 0
Training loss: 2.146655559539795
Validation loss: 2.2445797381862516

Epoch: 6| Step: 1
Training loss: 3.042722702026367
Validation loss: 2.3212857400217364

Epoch: 6| Step: 2
Training loss: 2.6367874145507812
Validation loss: 2.2299637179220877

Epoch: 6| Step: 3
Training loss: 2.3326973915100098
Validation loss: 2.2408244686741985

Epoch: 6| Step: 4
Training loss: 2.103658437728882
Validation loss: 2.283094416382492

Epoch: 6| Step: 5
Training loss: 2.5389747619628906
Validation loss: 2.2946703818536576

Epoch: 6| Step: 6
Training loss: 2.4511756896972656
Validation loss: 2.196631057288057

Epoch: 6| Step: 7
Training loss: 1.675845980644226
Validation loss: 2.2965632984715123

Epoch: 6| Step: 8
Training loss: 2.690934181213379
Validation loss: 2.289697398421585

Epoch: 6| Step: 9
Training loss: 2.584965229034424
Validation loss: 2.2106992378029773

Epoch: 6| Step: 10
Training loss: 2.681577205657959
Validation loss: 2.26495861494413

Epoch: 6| Step: 11
Training loss: 2.3519415855407715
Validation loss: 2.2638398472980787

Epoch: 6| Step: 12
Training loss: 2.4281654357910156
Validation loss: 2.252742841679563

Epoch: 6| Step: 13
Training loss: 1.8671011924743652
Validation loss: 2.2271920301580943

Epoch: 50| Step: 0
Training loss: 2.597670793533325
Validation loss: 2.166288962928198

Epoch: 6| Step: 1
Training loss: 1.9552799463272095
Validation loss: 2.2167403390330653

Epoch: 6| Step: 2
Training loss: 2.1537158489227295
Validation loss: 2.153941833844749

Epoch: 6| Step: 3
Training loss: 2.087468147277832
Validation loss: 2.240604817226369

Epoch: 6| Step: 4
Training loss: 3.160308837890625
Validation loss: 2.306366479525002

Epoch: 6| Step: 5
Training loss: 2.6079039573669434
Validation loss: 2.2516285962955926

Epoch: 6| Step: 6
Training loss: 2.144496440887451
Validation loss: 2.2137023556616997

Epoch: 6| Step: 7
Training loss: 2.168353319168091
Validation loss: 2.2601130021515714

Epoch: 6| Step: 8
Training loss: 1.926232933998108
Validation loss: 2.2890123680073726

Epoch: 6| Step: 9
Training loss: 2.338003635406494
Validation loss: 2.276847647082421

Epoch: 6| Step: 10
Training loss: 2.1288065910339355
Validation loss: 2.33550767232013

Epoch: 6| Step: 11
Training loss: 2.9172987937927246
Validation loss: 2.2732344878617154

Epoch: 6| Step: 12
Training loss: 2.3310909271240234
Validation loss: 2.3046751406884964

Epoch: 6| Step: 13
Training loss: 3.1598961353302
Validation loss: 2.3448723541793

Epoch: 51| Step: 0
Training loss: 3.068859338760376
Validation loss: 2.3901943481096657

Epoch: 6| Step: 1
Training loss: 2.9853744506835938
Validation loss: 2.2788587949609243

Epoch: 6| Step: 2
Training loss: 2.0687949657440186
Validation loss: 2.3268712105289584

Epoch: 6| Step: 3
Training loss: 1.8005667924880981
Validation loss: 2.2704934330396753

Epoch: 6| Step: 4
Training loss: 2.330554485321045
Validation loss: 2.2212297275502193

Epoch: 6| Step: 5
Training loss: 2.849088191986084
Validation loss: 2.303663266602383

Epoch: 6| Step: 6
Training loss: 2.413538932800293
Validation loss: 2.3335973652460242

Epoch: 6| Step: 7
Training loss: 2.109586715698242
Validation loss: 2.287275937295729

Epoch: 6| Step: 8
Training loss: 2.143139600753784
Validation loss: 2.2810897891239454

Epoch: 6| Step: 9
Training loss: 2.1112027168273926
Validation loss: 2.292882832147742

Epoch: 6| Step: 10
Training loss: 2.354417324066162
Validation loss: 2.210579784967566

Epoch: 6| Step: 11
Training loss: 2.809570550918579
Validation loss: 2.2757043633409726

Epoch: 6| Step: 12
Training loss: 2.1289854049682617
Validation loss: 2.2529625841366347

Epoch: 6| Step: 13
Training loss: 2.6174051761627197
Validation loss: 2.271092986547819

Epoch: 52| Step: 0
Training loss: 2.8670992851257324
Validation loss: 2.319624126598399

Epoch: 6| Step: 1
Training loss: 2.3277926445007324
Validation loss: 2.2885095842422976

Epoch: 6| Step: 2
Training loss: 2.86439847946167
Validation loss: 2.3195597048728698

Epoch: 6| Step: 3
Training loss: 1.6891391277313232
Validation loss: 2.2152856626818256

Epoch: 6| Step: 4
Training loss: 3.3372812271118164
Validation loss: 2.3221110733606483

Epoch: 6| Step: 5
Training loss: 2.0977420806884766
Validation loss: 2.2547087002825994

Epoch: 6| Step: 6
Training loss: 2.0437722206115723
Validation loss: 2.249812149232434

Epoch: 6| Step: 7
Training loss: 2.41088604927063
Validation loss: 2.213258147239685

Epoch: 6| Step: 8
Training loss: 2.050556182861328
Validation loss: 2.184370179330149

Epoch: 6| Step: 9
Training loss: 2.405289888381958
Validation loss: 2.1757007568113265

Epoch: 6| Step: 10
Training loss: 2.292135000228882
Validation loss: 2.241776256151097

Epoch: 6| Step: 11
Training loss: 2.283008098602295
Validation loss: 2.3245293017356627

Epoch: 6| Step: 12
Training loss: 2.238647937774658
Validation loss: 2.2528116818397277

Epoch: 6| Step: 13
Training loss: 2.031491994857788
Validation loss: 2.229820348883188

Epoch: 53| Step: 0
Training loss: 1.9403541088104248
Validation loss: 2.2103081416058283

Epoch: 6| Step: 1
Training loss: 3.091459274291992
Validation loss: 2.187950950796886

Epoch: 6| Step: 2
Training loss: 2.592857837677002
Validation loss: 2.1909029637613604

Epoch: 6| Step: 3
Training loss: 2.2638821601867676
Validation loss: 2.177677713414674

Epoch: 6| Step: 4
Training loss: 2.6293747425079346
Validation loss: 2.3069445881792294

Epoch: 6| Step: 5
Training loss: 1.9835243225097656
Validation loss: 2.2230325924452914

Epoch: 6| Step: 6
Training loss: 2.1525990962982178
Validation loss: 2.2215517336322415

Epoch: 6| Step: 7
Training loss: 2.4456913471221924
Validation loss: 2.2773403095942673

Epoch: 6| Step: 8
Training loss: 1.7506650686264038
Validation loss: 2.1879239646337365

Epoch: 6| Step: 9
Training loss: 2.680124044418335
Validation loss: 2.223157585308116

Epoch: 6| Step: 10
Training loss: 2.260387420654297
Validation loss: 2.2659441732591197

Epoch: 6| Step: 11
Training loss: 1.9626164436340332
Validation loss: 2.235722945582482

Epoch: 6| Step: 12
Training loss: 2.6793599128723145
Validation loss: 2.253278601554132

Epoch: 6| Step: 13
Training loss: 3.2992029190063477
Validation loss: 2.3082120034002487

Epoch: 54| Step: 0
Training loss: 2.0932185649871826
Validation loss: 2.2982808877063055

Epoch: 6| Step: 1
Training loss: 2.406508445739746
Validation loss: 2.2008613130097747

Epoch: 6| Step: 2
Training loss: 2.5820021629333496
Validation loss: 2.335572288882348

Epoch: 6| Step: 3
Training loss: 2.7683732509613037
Validation loss: 2.256365645316339

Epoch: 6| Step: 4
Training loss: 1.9657585620880127
Validation loss: 2.216805124795565

Epoch: 6| Step: 5
Training loss: 3.0808897018432617
Validation loss: 2.2591245558954056

Epoch: 6| Step: 6
Training loss: 1.931508183479309
Validation loss: 2.3295486024630967

Epoch: 6| Step: 7
Training loss: 1.8383725881576538
Validation loss: 2.271146789673836

Epoch: 6| Step: 8
Training loss: 2.7695367336273193
Validation loss: 2.3187861750202794

Epoch: 6| Step: 9
Training loss: 3.1627464294433594
Validation loss: 2.2394517083321848

Epoch: 6| Step: 10
Training loss: 1.958616018295288
Validation loss: 2.3009546931071947

Epoch: 6| Step: 11
Training loss: 1.8566021919250488
Validation loss: 2.3095325526370796

Epoch: 6| Step: 12
Training loss: 2.066875457763672
Validation loss: 2.316228844786203

Epoch: 6| Step: 13
Training loss: 2.5824472904205322
Validation loss: 2.273014030148906

Epoch: 55| Step: 0
Training loss: 2.458059549331665
Validation loss: 2.228855115111156

Epoch: 6| Step: 1
Training loss: 2.1192283630371094
Validation loss: 2.280427068792364

Epoch: 6| Step: 2
Training loss: 2.851865291595459
Validation loss: 2.2564806681807323

Epoch: 6| Step: 3
Training loss: 2.0323805809020996
Validation loss: 2.2088513835783927

Epoch: 6| Step: 4
Training loss: 1.9620401859283447
Validation loss: 2.165875550239317

Epoch: 6| Step: 5
Training loss: 2.9507551193237305
Validation loss: 2.2490255550671647

Epoch: 6| Step: 6
Training loss: 1.7842737436294556
Validation loss: 2.211380430447158

Epoch: 6| Step: 7
Training loss: 2.5867934226989746
Validation loss: 2.255017162651144

Epoch: 6| Step: 8
Training loss: 1.6804430484771729
Validation loss: 2.2295384278861423

Epoch: 6| Step: 9
Training loss: 2.497832775115967
Validation loss: 2.2476592858632407

Epoch: 6| Step: 10
Training loss: 2.6367578506469727
Validation loss: 2.164451742684969

Epoch: 6| Step: 11
Training loss: 2.849766731262207
Validation loss: 2.2173191321793424

Epoch: 6| Step: 12
Training loss: 2.6718757152557373
Validation loss: 2.2634493227927917

Epoch: 6| Step: 13
Training loss: 1.9171605110168457
Validation loss: 2.204820473988851

Epoch: 56| Step: 0
Training loss: 2.541862964630127
Validation loss: 2.2751616662548435

Epoch: 6| Step: 1
Training loss: 2.145010232925415
Validation loss: 2.156159100993987

Epoch: 6| Step: 2
Training loss: 2.4624223709106445
Validation loss: 2.1905048021706204

Epoch: 6| Step: 3
Training loss: 2.7359848022460938
Validation loss: 2.2143203135459655

Epoch: 6| Step: 4
Training loss: 2.3887240886688232
Validation loss: 2.1616019330998903

Epoch: 6| Step: 5
Training loss: 2.7977075576782227
Validation loss: 2.2935695135465233

Epoch: 6| Step: 6
Training loss: 2.7285070419311523
Validation loss: 2.212135548232704

Epoch: 6| Step: 7
Training loss: 1.3638232946395874
Validation loss: 2.230074518470354

Epoch: 6| Step: 8
Training loss: 2.0657260417938232
Validation loss: 2.171354011822772

Epoch: 6| Step: 9
Training loss: 1.908319354057312
Validation loss: 2.1986333118971957

Epoch: 6| Step: 10
Training loss: 2.766408681869507
Validation loss: 2.2465784062621412

Epoch: 6| Step: 11
Training loss: 2.058492422103882
Validation loss: 2.2770507874027377

Epoch: 6| Step: 12
Training loss: 2.8723807334899902
Validation loss: 2.2264670479682183

Epoch: 6| Step: 13
Training loss: 2.813932180404663
Validation loss: 2.23662559704114

Epoch: 57| Step: 0
Training loss: 2.321631669998169
Validation loss: 2.2241324634962183

Epoch: 6| Step: 1
Training loss: 2.638798475265503
Validation loss: 2.256699300581409

Epoch: 6| Step: 2
Training loss: 2.7769057750701904
Validation loss: 2.230101272624026

Epoch: 6| Step: 3
Training loss: 2.357851505279541
Validation loss: 2.214265182454099

Epoch: 6| Step: 4
Training loss: 2.480522632598877
Validation loss: 2.2455982700470956

Epoch: 6| Step: 5
Training loss: 2.792742967605591
Validation loss: 2.2078175724193616

Epoch: 6| Step: 6
Training loss: 2.0503482818603516
Validation loss: 2.2614716996428785

Epoch: 6| Step: 7
Training loss: 2.429877996444702
Validation loss: 2.2754459893831642

Epoch: 6| Step: 8
Training loss: 2.3534905910491943
Validation loss: 2.2502242390827467

Epoch: 6| Step: 9
Training loss: 2.346252202987671
Validation loss: 2.253476183901551

Epoch: 6| Step: 10
Training loss: 2.0826902389526367
Validation loss: 2.259764330361479

Epoch: 6| Step: 11
Training loss: 2.1360087394714355
Validation loss: 2.2539070716468235

Epoch: 6| Step: 12
Training loss: 2.4442086219787598
Validation loss: 2.2204697285929034

Epoch: 6| Step: 13
Training loss: 2.085984468460083
Validation loss: 2.225150610810967

Epoch: 58| Step: 0
Training loss: 2.8696587085723877
Validation loss: 2.3244651722651657

Epoch: 6| Step: 1
Training loss: 2.5886921882629395
Validation loss: 2.345817594118016

Epoch: 6| Step: 2
Training loss: 2.5009424686431885
Validation loss: 2.288557170539774

Epoch: 6| Step: 3
Training loss: 2.1481313705444336
Validation loss: 2.302206644447901

Epoch: 6| Step: 4
Training loss: 1.5597784519195557
Validation loss: 2.238348960876465

Epoch: 6| Step: 5
Training loss: 2.868502140045166
Validation loss: 2.2596374532227874

Epoch: 6| Step: 6
Training loss: 1.97127103805542
Validation loss: 2.207798219496204

Epoch: 6| Step: 7
Training loss: 2.5345678329467773
Validation loss: 2.3099427171932754

Epoch: 6| Step: 8
Training loss: 1.8221213817596436
Validation loss: 2.2455932991479033

Epoch: 6| Step: 9
Training loss: 2.5051350593566895
Validation loss: 2.217952125815935

Epoch: 6| Step: 10
Training loss: 2.914956569671631
Validation loss: 2.209117425385342

Epoch: 6| Step: 11
Training loss: 3.499544620513916
Validation loss: 2.2118830142482633

Epoch: 6| Step: 12
Training loss: 1.5794025659561157
Validation loss: 2.2176495905845397

Epoch: 6| Step: 13
Training loss: 2.206655740737915
Validation loss: 2.2023376931426344

Epoch: 59| Step: 0
Training loss: 2.1582164764404297
Validation loss: 2.233013250494516

Epoch: 6| Step: 1
Training loss: 2.113936424255371
Validation loss: 2.2169765426266577

Epoch: 6| Step: 2
Training loss: 2.233691692352295
Validation loss: 2.2209543156367477

Epoch: 6| Step: 3
Training loss: 3.314990997314453
Validation loss: 2.1744468827401437

Epoch: 6| Step: 4
Training loss: 1.8929839134216309
Validation loss: 2.282045461798227

Epoch: 6| Step: 5
Training loss: 2.634410858154297
Validation loss: 2.3071688682802263

Epoch: 6| Step: 6
Training loss: 2.8592453002929688
Validation loss: 2.233055160891625

Epoch: 6| Step: 7
Training loss: 2.1583008766174316
Validation loss: 2.2912182577194704

Epoch: 6| Step: 8
Training loss: 2.1506383419036865
Validation loss: 2.31259092720606

Epoch: 6| Step: 9
Training loss: 2.199669122695923
Validation loss: 2.200452184164396

Epoch: 6| Step: 10
Training loss: 2.287867784500122
Validation loss: 2.2307484252478487

Epoch: 6| Step: 11
Training loss: 1.9383981227874756
Validation loss: 2.273165597710558

Epoch: 6| Step: 12
Training loss: 2.469608783721924
Validation loss: 2.3043214685173443

Epoch: 6| Step: 13
Training loss: 3.15462589263916
Validation loss: 2.2199853607403335

Epoch: 60| Step: 0
Training loss: 1.9826123714447021
Validation loss: 2.269254422956897

Epoch: 6| Step: 1
Training loss: 2.1760735511779785
Validation loss: 2.261695546488608

Epoch: 6| Step: 2
Training loss: 2.5365443229675293
Validation loss: 2.2558548296651533

Epoch: 6| Step: 3
Training loss: 2.8310859203338623
Validation loss: 2.2438294797815304

Epoch: 6| Step: 4
Training loss: 3.0302937030792236
Validation loss: 2.2884445216066096

Epoch: 6| Step: 5
Training loss: 2.2074410915374756
Validation loss: 2.2639282800818004

Epoch: 6| Step: 6
Training loss: 2.863415002822876
Validation loss: 2.219638278407435

Epoch: 6| Step: 7
Training loss: 2.080732822418213
Validation loss: 2.2145005579917663

Epoch: 6| Step: 8
Training loss: 1.918257236480713
Validation loss: 2.1865165413066907

Epoch: 6| Step: 9
Training loss: 1.9752277135849
Validation loss: 2.2170448892860004

Epoch: 6| Step: 10
Training loss: 2.2708699703216553
Validation loss: 2.2013435902134066

Epoch: 6| Step: 11
Training loss: 2.913055419921875
Validation loss: 2.1891983606482066

Epoch: 6| Step: 12
Training loss: 2.013380765914917
Validation loss: 2.258321903085196

Epoch: 6| Step: 13
Training loss: 2.4372406005859375
Validation loss: 2.2025001407951437

Epoch: 61| Step: 0
Training loss: 2.001315116882324
Validation loss: 2.184565644110403

Epoch: 6| Step: 1
Training loss: 1.7835794687271118
Validation loss: 2.2079962248443277

Epoch: 6| Step: 2
Training loss: 2.105956792831421
Validation loss: 2.2547384308230494

Epoch: 6| Step: 3
Training loss: 2.9567832946777344
Validation loss: 2.3216872574180685

Epoch: 6| Step: 4
Training loss: 1.9270966053009033
Validation loss: 2.2607703516560216

Epoch: 6| Step: 5
Training loss: 2.3106303215026855
Validation loss: 2.2575437022793676

Epoch: 6| Step: 6
Training loss: 2.4746828079223633
Validation loss: 2.2858044357709986

Epoch: 6| Step: 7
Training loss: 2.4857301712036133
Validation loss: 2.3032265658019693

Epoch: 6| Step: 8
Training loss: 2.737791061401367
Validation loss: 2.2690656544059835

Epoch: 6| Step: 9
Training loss: 2.286332130432129
Validation loss: 2.25349606749832

Epoch: 6| Step: 10
Training loss: 2.298666000366211
Validation loss: 2.1827802452989804

Epoch: 6| Step: 11
Training loss: 1.834838628768921
Validation loss: 2.226044962483068

Epoch: 6| Step: 12
Training loss: 2.663804054260254
Validation loss: 2.299216115346519

Epoch: 6| Step: 13
Training loss: 2.927229881286621
Validation loss: 2.2889179978319394

Epoch: 62| Step: 0
Training loss: 1.993820071220398
Validation loss: 2.2168865370494064

Epoch: 6| Step: 1
Training loss: 2.545729875564575
Validation loss: 2.221130673603345

Epoch: 6| Step: 2
Training loss: 2.418142795562744
Validation loss: 2.2040263119564263

Epoch: 6| Step: 3
Training loss: 2.3983943462371826
Validation loss: 2.2530502145008375

Epoch: 6| Step: 4
Training loss: 1.9442355632781982
Validation loss: 2.2750570466441493

Epoch: 6| Step: 5
Training loss: 2.139284610748291
Validation loss: 2.2842295259557743

Epoch: 6| Step: 6
Training loss: 1.7725309133529663
Validation loss: 2.276528384095879

Epoch: 6| Step: 7
Training loss: 2.8560290336608887
Validation loss: 2.238334704470891

Epoch: 6| Step: 8
Training loss: 2.050048828125
Validation loss: 2.2585256689338276

Epoch: 6| Step: 9
Training loss: 2.42916202545166
Validation loss: 2.2483181389429236

Epoch: 6| Step: 10
Training loss: 3.675560712814331
Validation loss: 2.208149549781635

Epoch: 6| Step: 11
Training loss: 2.2171061038970947
Validation loss: 2.1852650104030484

Epoch: 6| Step: 12
Training loss: 1.9994500875473022
Validation loss: 2.305483636035714

Epoch: 6| Step: 13
Training loss: 1.993173599243164
Validation loss: 2.18508816278109

Epoch: 63| Step: 0
Training loss: 1.9038989543914795
Validation loss: 2.2874714200214674

Epoch: 6| Step: 1
Training loss: 2.5659255981445312
Validation loss: 2.2257585371694257

Epoch: 6| Step: 2
Training loss: 2.2874951362609863
Validation loss: 2.2721592457063737

Epoch: 6| Step: 3
Training loss: 1.9072693586349487
Validation loss: 2.2332060465248684

Epoch: 6| Step: 4
Training loss: 2.122255325317383
Validation loss: 2.2136481667077668

Epoch: 6| Step: 5
Training loss: 2.040621757507324
Validation loss: 2.2682989156374367

Epoch: 6| Step: 6
Training loss: 3.1065690517425537
Validation loss: 2.1690333735558296

Epoch: 6| Step: 7
Training loss: 2.9075472354888916
Validation loss: 2.226959423352313

Epoch: 6| Step: 8
Training loss: 3.1718034744262695
Validation loss: 2.187839161965155

Epoch: 6| Step: 9
Training loss: 1.7000194787979126
Validation loss: 2.2442996527559016

Epoch: 6| Step: 10
Training loss: 2.1474547386169434
Validation loss: 2.296818492233112

Epoch: 6| Step: 11
Training loss: 2.3079957962036133
Validation loss: 2.32581470089574

Epoch: 6| Step: 12
Training loss: 2.3931448459625244
Validation loss: 2.2768039011186167

Epoch: 6| Step: 13
Training loss: 2.13124942779541
Validation loss: 2.278751778346236

Epoch: 64| Step: 0
Training loss: 2.0501251220703125
Validation loss: 2.207183123916708

Epoch: 6| Step: 1
Training loss: 2.7701363563537598
Validation loss: 2.226429893124488

Epoch: 6| Step: 2
Training loss: 2.357757091522217
Validation loss: 2.1834169228871665

Epoch: 6| Step: 3
Training loss: 3.034503698348999
Validation loss: 2.259497086207072

Epoch: 6| Step: 4
Training loss: 2.2715108394622803
Validation loss: 2.2237988313039145

Epoch: 6| Step: 5
Training loss: 2.4274559020996094
Validation loss: 2.2609844669218986

Epoch: 6| Step: 6
Training loss: 2.850594997406006
Validation loss: 2.3232218911570888

Epoch: 6| Step: 7
Training loss: 2.0845208168029785
Validation loss: 2.187155310825635

Epoch: 6| Step: 8
Training loss: 2.3126673698425293
Validation loss: 2.303602203246086

Epoch: 6| Step: 9
Training loss: 2.351759910583496
Validation loss: 2.2835117437506236

Epoch: 6| Step: 10
Training loss: 2.047353744506836
Validation loss: 2.2534406056968113

Epoch: 6| Step: 11
Training loss: 2.913954257965088
Validation loss: 2.2492700289654475

Epoch: 6| Step: 12
Training loss: 1.301011323928833
Validation loss: 2.2135677414555706

Epoch: 6| Step: 13
Training loss: 2.0736587047576904
Validation loss: 2.268740238681916

Epoch: 65| Step: 0
Training loss: 2.4208807945251465
Validation loss: 2.2772423169946157

Epoch: 6| Step: 1
Training loss: 2.538264751434326
Validation loss: 2.2372134988025953

Epoch: 6| Step: 2
Training loss: 1.8717225790023804
Validation loss: 2.2108822509806645

Epoch: 6| Step: 3
Training loss: 2.566255569458008
Validation loss: 2.2519258863182476

Epoch: 6| Step: 4
Training loss: 2.5643579959869385
Validation loss: 2.2268543704863517

Epoch: 6| Step: 5
Training loss: 2.8425674438476562
Validation loss: 2.310429570495441

Epoch: 6| Step: 6
Training loss: 1.9144221544265747
Validation loss: 2.1949149177920435

Epoch: 6| Step: 7
Training loss: 1.689969778060913
Validation loss: 2.284779812700005

Epoch: 6| Step: 8
Training loss: 3.0918216705322266
Validation loss: 2.2909640804413827

Epoch: 6| Step: 9
Training loss: 2.454272747039795
Validation loss: 2.3092833129308556

Epoch: 6| Step: 10
Training loss: 2.0455093383789062
Validation loss: 2.304822988407586

Epoch: 6| Step: 11
Training loss: 2.3131263256073
Validation loss: 2.1939371567900463

Epoch: 6| Step: 12
Training loss: 2.711137533187866
Validation loss: 2.209960388880904

Epoch: 6| Step: 13
Training loss: 1.6318752765655518
Validation loss: 2.286650275671354

Epoch: 66| Step: 0
Training loss: 1.3845875263214111
Validation loss: 2.18965902379764

Epoch: 6| Step: 1
Training loss: 2.7561349868774414
Validation loss: 2.279137260170393

Epoch: 6| Step: 2
Training loss: 2.184689521789551
Validation loss: 2.267952783133394

Epoch: 6| Step: 3
Training loss: 1.8265113830566406
Validation loss: 2.2615989690185874

Epoch: 6| Step: 4
Training loss: 2.145512580871582
Validation loss: 2.3137960485232774

Epoch: 6| Step: 5
Training loss: 2.560905933380127
Validation loss: 2.20094572600498

Epoch: 6| Step: 6
Training loss: 3.3159475326538086
Validation loss: 2.212107176421791

Epoch: 6| Step: 7
Training loss: 2.1396617889404297
Validation loss: 2.2184423823510446

Epoch: 6| Step: 8
Training loss: 2.331153154373169
Validation loss: 2.2788796194138063

Epoch: 6| Step: 9
Training loss: 2.511200428009033
Validation loss: 2.211252691925213

Epoch: 6| Step: 10
Training loss: 2.922379732131958
Validation loss: 2.214560998383389

Epoch: 6| Step: 11
Training loss: 2.406982898712158
Validation loss: 2.2662371845655542

Epoch: 6| Step: 12
Training loss: 2.0160045623779297
Validation loss: 2.2529809705672728

Epoch: 6| Step: 13
Training loss: 1.506668210029602
Validation loss: 2.240699263029201

Epoch: 67| Step: 0
Training loss: 3.0140600204467773
Validation loss: 2.2892076917873916

Epoch: 6| Step: 1
Training loss: 1.6528297662734985
Validation loss: 2.284028099429223

Epoch: 6| Step: 2
Training loss: 2.7991538047790527
Validation loss: 2.2589723717781807

Epoch: 6| Step: 3
Training loss: 2.834768772125244
Validation loss: 2.2776832849748674

Epoch: 6| Step: 4
Training loss: 2.670135736465454
Validation loss: 2.290050406609812

Epoch: 6| Step: 5
Training loss: 1.7622871398925781
Validation loss: 2.249109752716557

Epoch: 6| Step: 6
Training loss: 2.9141311645507812
Validation loss: 2.2474106665580504

Epoch: 6| Step: 7
Training loss: 1.6659282445907593
Validation loss: 2.2548955819940053

Epoch: 6| Step: 8
Training loss: 1.9453277587890625
Validation loss: 2.246597082384171

Epoch: 6| Step: 9
Training loss: 1.8100969791412354
Validation loss: 2.2484400682551886

Epoch: 6| Step: 10
Training loss: 1.9802632331848145
Validation loss: 2.274880825832326

Epoch: 6| Step: 11
Training loss: 2.834528923034668
Validation loss: 2.2063969424975816

Epoch: 6| Step: 12
Training loss: 2.578906536102295
Validation loss: 2.2384598357703096

Epoch: 6| Step: 13
Training loss: 2.3913557529449463
Validation loss: 2.165365731844338

Epoch: 68| Step: 0
Training loss: 1.7216072082519531
Validation loss: 2.2064361008264686

Epoch: 6| Step: 1
Training loss: 2.5406041145324707
Validation loss: 2.199344068445185

Epoch: 6| Step: 2
Training loss: 1.9725050926208496
Validation loss: 2.272666804252132

Epoch: 6| Step: 3
Training loss: 3.2066664695739746
Validation loss: 2.1780414594117032

Epoch: 6| Step: 4
Training loss: 2.520418405532837
Validation loss: 2.125856143172069

Epoch: 6| Step: 5
Training loss: 2.4175362586975098
Validation loss: 2.231855414247

Epoch: 6| Step: 6
Training loss: 2.1066861152648926
Validation loss: 2.1548220470387447

Epoch: 6| Step: 7
Training loss: 1.987415075302124
Validation loss: 2.15136932429447

Epoch: 6| Step: 8
Training loss: 2.305654287338257
Validation loss: 2.1750303570942213

Epoch: 6| Step: 9
Training loss: 2.0216550827026367
Validation loss: 2.1912815468285674

Epoch: 6| Step: 10
Training loss: 2.416475772857666
Validation loss: 2.202322727890425

Epoch: 6| Step: 11
Training loss: 2.319509983062744
Validation loss: 2.2000815714559248

Epoch: 6| Step: 12
Training loss: 3.011096477508545
Validation loss: 2.203286019704675

Epoch: 6| Step: 13
Training loss: 2.706833839416504
Validation loss: 2.192030132457774

Epoch: 69| Step: 0
Training loss: 1.857835292816162
Validation loss: 2.26129590054994

Epoch: 6| Step: 1
Training loss: 2.936344623565674
Validation loss: 2.3410645607979066

Epoch: 6| Step: 2
Training loss: 1.558777093887329
Validation loss: 2.2956371025372575

Epoch: 6| Step: 3
Training loss: 3.291579008102417
Validation loss: 2.1918848791430072

Epoch: 6| Step: 4
Training loss: 2.378915786743164
Validation loss: 2.263632466716151

Epoch: 6| Step: 5
Training loss: 1.2938623428344727
Validation loss: 2.2991773031091176

Epoch: 6| Step: 6
Training loss: 2.4992120265960693
Validation loss: 2.3829576148781726

Epoch: 6| Step: 7
Training loss: 1.7648162841796875
Validation loss: 2.249198821283156

Epoch: 6| Step: 8
Training loss: 2.258707046508789
Validation loss: 2.3406757744409705

Epoch: 6| Step: 9
Training loss: 2.983246326446533
Validation loss: 2.310801362478605

Epoch: 6| Step: 10
Training loss: 2.5655980110168457
Validation loss: 2.373917541196269

Epoch: 6| Step: 11
Training loss: 2.5837082862854004
Validation loss: 2.3284706915578535

Epoch: 6| Step: 12
Training loss: 2.2649223804473877
Validation loss: 2.401391618995256

Epoch: 6| Step: 13
Training loss: 2.7242014408111572
Validation loss: 2.3126789446799987

Epoch: 70| Step: 0
Training loss: 2.904937744140625
Validation loss: 2.3695849039221324

Epoch: 6| Step: 1
Training loss: 2.2669358253479004
Validation loss: 2.4259880204354562

Epoch: 6| Step: 2
Training loss: 1.8943233489990234
Validation loss: 2.2909891195194696

Epoch: 6| Step: 3
Training loss: 2.7596030235290527
Validation loss: 2.2686177453687115

Epoch: 6| Step: 4
Training loss: 2.709599018096924
Validation loss: 2.3363302420544367

Epoch: 6| Step: 5
Training loss: 2.637028217315674
Validation loss: 2.3350854304529007

Epoch: 6| Step: 6
Training loss: 2.2261552810668945
Validation loss: 2.3638114031924995

Epoch: 6| Step: 7
Training loss: 1.700966238975525
Validation loss: 2.2936466868205736

Epoch: 6| Step: 8
Training loss: 2.281108856201172
Validation loss: 2.342237034151631

Epoch: 6| Step: 9
Training loss: 2.100329875946045
Validation loss: 2.2937214246360202

Epoch: 6| Step: 10
Training loss: 2.2415595054626465
Validation loss: 2.275486469268799

Epoch: 6| Step: 11
Training loss: 2.487475872039795
Validation loss: 2.310210866312827

Epoch: 6| Step: 12
Training loss: 1.9898350238800049
Validation loss: 2.205147979080036

Epoch: 6| Step: 13
Training loss: 1.5194236040115356
Validation loss: 2.201603005009313

Epoch: 71| Step: 0
Training loss: 2.3790459632873535
Validation loss: 2.26743588396298

Epoch: 6| Step: 1
Training loss: 1.9148625135421753
Validation loss: 2.1955164555580384

Epoch: 6| Step: 2
Training loss: 2.636559247970581
Validation loss: 2.2350593946313344

Epoch: 6| Step: 3
Training loss: 1.9742374420166016
Validation loss: 2.2213116153593986

Epoch: 6| Step: 4
Training loss: 1.7974953651428223
Validation loss: 2.1958745500092864

Epoch: 6| Step: 5
Training loss: 2.4513301849365234
Validation loss: 2.1778105894724527

Epoch: 6| Step: 6
Training loss: 2.1710386276245117
Validation loss: 2.1933538593271726

Epoch: 6| Step: 7
Training loss: 2.5599708557128906
Validation loss: 2.19049854945111

Epoch: 6| Step: 8
Training loss: 2.8249902725219727
Validation loss: 2.293958648558586

Epoch: 6| Step: 9
Training loss: 2.5017685890197754
Validation loss: 2.2089884191431026

Epoch: 6| Step: 10
Training loss: 1.7134199142456055
Validation loss: 2.1635327339172363

Epoch: 6| Step: 11
Training loss: 2.6177570819854736
Validation loss: 2.257764653492999

Epoch: 6| Step: 12
Training loss: 2.919741630554199
Validation loss: 2.240356268421296

Epoch: 6| Step: 13
Training loss: 2.532227039337158
Validation loss: 2.2437451936865367

Epoch: 72| Step: 0
Training loss: 2.927639961242676
Validation loss: 2.1998954280730216

Epoch: 6| Step: 1
Training loss: 2.3494873046875
Validation loss: 2.25847372188363

Epoch: 6| Step: 2
Training loss: 2.047806739807129
Validation loss: 2.206339946357153

Epoch: 6| Step: 3
Training loss: 2.1142587661743164
Validation loss: 2.1584786240772535

Epoch: 6| Step: 4
Training loss: 2.558218479156494
Validation loss: 2.256058869823333

Epoch: 6| Step: 5
Training loss: 2.3865973949432373
Validation loss: 2.1622875634060112

Epoch: 6| Step: 6
Training loss: 2.487260341644287
Validation loss: 2.1633902800980436

Epoch: 6| Step: 7
Training loss: 1.7734320163726807
Validation loss: 2.1987370342336674

Epoch: 6| Step: 8
Training loss: 2.0707879066467285
Validation loss: 2.2060003844640588

Epoch: 6| Step: 9
Training loss: 2.5648932456970215
Validation loss: 2.2347754663036716

Epoch: 6| Step: 10
Training loss: 2.3957228660583496
Validation loss: 2.28250410479884

Epoch: 6| Step: 11
Training loss: 2.743152618408203
Validation loss: 2.2250196241563365

Epoch: 6| Step: 12
Training loss: 2.7204339504241943
Validation loss: 2.216870520704536

Epoch: 6| Step: 13
Training loss: 1.642058253288269
Validation loss: 2.2265149995844853

Epoch: 73| Step: 0
Training loss: 2.2331972122192383
Validation loss: 2.186990548205632

Epoch: 6| Step: 1
Training loss: 2.4838547706604004
Validation loss: 2.1993721172373784

Epoch: 6| Step: 2
Training loss: 2.415226697921753
Validation loss: 2.204552483815019

Epoch: 6| Step: 3
Training loss: 2.4066665172576904
Validation loss: 2.270593015096521

Epoch: 6| Step: 4
Training loss: 1.4064505100250244
Validation loss: 2.220398308128439

Epoch: 6| Step: 5
Training loss: 2.287071704864502
Validation loss: 2.2051353864772345

Epoch: 6| Step: 6
Training loss: 2.248265266418457
Validation loss: 2.203939366084273

Epoch: 6| Step: 7
Training loss: 2.529205083847046
Validation loss: 2.165669834741982

Epoch: 6| Step: 8
Training loss: 2.5194406509399414
Validation loss: 2.248469909032186

Epoch: 6| Step: 9
Training loss: 1.9272161722183228
Validation loss: 2.2364511694959415

Epoch: 6| Step: 10
Training loss: 2.8866002559661865
Validation loss: 2.2917818741131852

Epoch: 6| Step: 11
Training loss: 2.48553204536438
Validation loss: 2.263428959795224

Epoch: 6| Step: 12
Training loss: 2.167360544204712
Validation loss: 2.1872289949847805

Epoch: 6| Step: 13
Training loss: 2.8087124824523926
Validation loss: 2.230759148956627

Epoch: 74| Step: 0
Training loss: 2.91904354095459
Validation loss: 2.2507919547378377

Epoch: 6| Step: 1
Training loss: 2.251023292541504
Validation loss: 2.177047675655734

Epoch: 6| Step: 2
Training loss: 1.815758228302002
Validation loss: 2.2316232650510726

Epoch: 6| Step: 3
Training loss: 2.192570686340332
Validation loss: 2.2241150563763035

Epoch: 6| Step: 4
Training loss: 2.117619037628174
Validation loss: 2.2896094270931777

Epoch: 6| Step: 5
Training loss: 1.9836028814315796
Validation loss: 2.2179921006643646

Epoch: 6| Step: 6
Training loss: 2.9219980239868164
Validation loss: 2.273371616999308

Epoch: 6| Step: 7
Training loss: 2.1176555156707764
Validation loss: 2.15614031335359

Epoch: 6| Step: 8
Training loss: 2.738276958465576
Validation loss: 2.14731236427061

Epoch: 6| Step: 9
Training loss: 1.694922685623169
Validation loss: 2.2635117128331173

Epoch: 6| Step: 10
Training loss: 2.4432034492492676
Validation loss: 2.2226778217541274

Epoch: 6| Step: 11
Training loss: 1.5503365993499756
Validation loss: 2.209213815709596

Epoch: 6| Step: 12
Training loss: 2.875434398651123
Validation loss: 2.2512037087512273

Epoch: 6| Step: 13
Training loss: 2.19775128364563
Validation loss: 2.1896553911188597

Epoch: 75| Step: 0
Training loss: 2.213041067123413
Validation loss: 2.236256271280268

Epoch: 6| Step: 1
Training loss: 1.6665364503860474
Validation loss: 2.2073540097923687

Epoch: 6| Step: 2
Training loss: 2.2871227264404297
Validation loss: 2.2477536380931897

Epoch: 6| Step: 3
Training loss: 2.5972111225128174
Validation loss: 2.24403969446818

Epoch: 6| Step: 4
Training loss: 2.2255349159240723
Validation loss: 2.233002378094581

Epoch: 6| Step: 5
Training loss: 2.2821426391601562
Validation loss: 2.221278590540732

Epoch: 6| Step: 6
Training loss: 2.2710320949554443
Validation loss: 2.207863005258704

Epoch: 6| Step: 7
Training loss: 2.3607044219970703
Validation loss: 2.2943695027341127

Epoch: 6| Step: 8
Training loss: 2.3251450061798096
Validation loss: 2.2938806626104538

Epoch: 6| Step: 9
Training loss: 2.3538661003112793
Validation loss: 2.251174114083731

Epoch: 6| Step: 10
Training loss: 2.3176276683807373
Validation loss: 2.2758419000974266

Epoch: 6| Step: 11
Training loss: 2.5028443336486816
Validation loss: 2.265630381081694

Epoch: 6| Step: 12
Training loss: 2.6171183586120605
Validation loss: 2.276021037050473

Epoch: 6| Step: 13
Training loss: 2.197012424468994
Validation loss: 2.220522124280212

Epoch: 76| Step: 0
Training loss: 2.338675022125244
Validation loss: 2.249935875656784

Epoch: 6| Step: 1
Training loss: 2.5180540084838867
Validation loss: 2.210346991016019

Epoch: 6| Step: 2
Training loss: 2.046937942504883
Validation loss: 2.2553840016806

Epoch: 6| Step: 3
Training loss: 2.4638752937316895
Validation loss: 2.226926957407305

Epoch: 6| Step: 4
Training loss: 2.350890874862671
Validation loss: 2.2928202780344153

Epoch: 6| Step: 5
Training loss: 2.900557041168213
Validation loss: 2.1706354361708446

Epoch: 6| Step: 6
Training loss: 2.0815954208374023
Validation loss: 2.2615278074818272

Epoch: 6| Step: 7
Training loss: 2.136741876602173
Validation loss: 2.139085408179991

Epoch: 6| Step: 8
Training loss: 2.4951562881469727
Validation loss: 2.2258164703205066

Epoch: 6| Step: 9
Training loss: 2.491407871246338
Validation loss: 2.2860817114512124

Epoch: 6| Step: 10
Training loss: 1.7497153282165527
Validation loss: 2.2490476844131306

Epoch: 6| Step: 11
Training loss: 2.4757561683654785
Validation loss: 2.234106509916244

Epoch: 6| Step: 12
Training loss: 1.2913014888763428
Validation loss: 2.196073609013711

Epoch: 6| Step: 13
Training loss: 3.7439465522766113
Validation loss: 2.17379391706118

Epoch: 77| Step: 0
Training loss: 2.1296281814575195
Validation loss: 2.2556147037013883

Epoch: 6| Step: 1
Training loss: 2.4704456329345703
Validation loss: 2.210228445709393

Epoch: 6| Step: 2
Training loss: 2.9037022590637207
Validation loss: 2.1521411531714985

Epoch: 6| Step: 3
Training loss: 1.9552710056304932
Validation loss: 2.2333710475634505

Epoch: 6| Step: 4
Training loss: 4.130465507507324
Validation loss: 2.2053872923697195

Epoch: 6| Step: 5
Training loss: 1.766797423362732
Validation loss: 2.2044694449311946

Epoch: 6| Step: 6
Training loss: 2.3214879035949707
Validation loss: 2.1818245226337063

Epoch: 6| Step: 7
Training loss: 2.3438949584960938
Validation loss: 2.2602325434325845

Epoch: 6| Step: 8
Training loss: 1.9109218120574951
Validation loss: 2.170444337270593

Epoch: 6| Step: 9
Training loss: 1.501420259475708
Validation loss: 2.2687810108225834

Epoch: 6| Step: 10
Training loss: 2.331751585006714
Validation loss: 2.200923668440952

Epoch: 6| Step: 11
Training loss: 2.186850070953369
Validation loss: 2.22778534120129

Epoch: 6| Step: 12
Training loss: 1.6875293254852295
Validation loss: 2.159682155937277

Epoch: 6| Step: 13
Training loss: 2.6560487747192383
Validation loss: 2.153469080566078

Epoch: 78| Step: 0
Training loss: 2.8085997104644775
Validation loss: 2.226546556718888

Epoch: 6| Step: 1
Training loss: 1.7885661125183105
Validation loss: 2.188631611485635

Epoch: 6| Step: 2
Training loss: 1.9460402727127075
Validation loss: 2.2904922423824186

Epoch: 6| Step: 3
Training loss: 2.354095935821533
Validation loss: 2.2594319748622116

Epoch: 6| Step: 4
Training loss: 2.129751682281494
Validation loss: 2.1882848944715274

Epoch: 6| Step: 5
Training loss: 1.1646158695220947
Validation loss: 2.27251906676959

Epoch: 6| Step: 6
Training loss: 3.3321006298065186
Validation loss: 2.2206969748261156

Epoch: 6| Step: 7
Training loss: 3.0078697204589844
Validation loss: 2.2251554586554088

Epoch: 6| Step: 8
Training loss: 2.3938822746276855
Validation loss: 2.2143669051508748

Epoch: 6| Step: 9
Training loss: 2.0049586296081543
Validation loss: 2.231559697017875

Epoch: 6| Step: 10
Training loss: 2.321291923522949
Validation loss: 2.1721239641148555

Epoch: 6| Step: 11
Training loss: 2.411196708679199
Validation loss: 2.252296722063454

Epoch: 6| Step: 12
Training loss: 1.7108067274093628
Validation loss: 2.213668377168717

Epoch: 6| Step: 13
Training loss: 2.1983330249786377
Validation loss: 2.249141036823232

Epoch: 79| Step: 0
Training loss: 2.196953296661377
Validation loss: 2.2640865823274017

Epoch: 6| Step: 1
Training loss: 2.361069679260254
Validation loss: 2.187660037830312

Epoch: 6| Step: 2
Training loss: 2.1463589668273926
Validation loss: 2.261247665651383

Epoch: 6| Step: 3
Training loss: 2.8728322982788086
Validation loss: 2.243176137247393

Epoch: 6| Step: 4
Training loss: 2.127728223800659
Validation loss: 2.318736460901076

Epoch: 6| Step: 5
Training loss: 2.151566982269287
Validation loss: 2.2427372214614705

Epoch: 6| Step: 6
Training loss: 1.6512482166290283
Validation loss: 2.153903729172163

Epoch: 6| Step: 7
Training loss: 2.4526619911193848
Validation loss: 2.2310902457083426

Epoch: 6| Step: 8
Training loss: 2.164670944213867
Validation loss: 2.21784988270011

Epoch: 6| Step: 9
Training loss: 2.1499743461608887
Validation loss: 2.197975048454859

Epoch: 6| Step: 10
Training loss: 1.9884626865386963
Validation loss: 2.207052964036183

Epoch: 6| Step: 11
Training loss: 2.0586681365966797
Validation loss: 2.173588470746112

Epoch: 6| Step: 12
Training loss: 3.169548273086548
Validation loss: 2.1830541087735083

Epoch: 6| Step: 13
Training loss: 1.9686906337738037
Validation loss: 2.2803775546371297

Epoch: 80| Step: 0
Training loss: 1.4242010116577148
Validation loss: 2.2036112047010854

Epoch: 6| Step: 1
Training loss: 2.3654704093933105
Validation loss: 2.2122539948391657

Epoch: 6| Step: 2
Training loss: 2.0257437229156494
Validation loss: 2.2071443783339633

Epoch: 6| Step: 3
Training loss: 1.8816590309143066
Validation loss: 2.242491982316458

Epoch: 6| Step: 4
Training loss: 2.1640658378601074
Validation loss: 2.087424906351233

Epoch: 6| Step: 5
Training loss: 2.643294334411621
Validation loss: 2.1897235737052014

Epoch: 6| Step: 6
Training loss: 2.85180926322937
Validation loss: 2.146832699416786

Epoch: 6| Step: 7
Training loss: 1.783299207687378
Validation loss: 2.2332732216004403

Epoch: 6| Step: 8
Training loss: 2.3235859870910645
Validation loss: 2.2878948309088267

Epoch: 6| Step: 9
Training loss: 2.3538012504577637
Validation loss: 2.1637527340201923

Epoch: 6| Step: 10
Training loss: 3.5244719982147217
Validation loss: 2.141603728776337

Epoch: 6| Step: 11
Training loss: 1.389582872390747
Validation loss: 2.1801551285610405

Epoch: 6| Step: 12
Training loss: 2.6033878326416016
Validation loss: 2.210010013272685

Epoch: 6| Step: 13
Training loss: 2.5287070274353027
Validation loss: 2.2620867580495854

Epoch: 81| Step: 0
Training loss: 2.746673107147217
Validation loss: 2.2611192964738414

Epoch: 6| Step: 1
Training loss: 1.7028125524520874
Validation loss: 2.240030114368726

Epoch: 6| Step: 2
Training loss: 2.3798108100891113
Validation loss: 2.3241194037980932

Epoch: 6| Step: 3
Training loss: 1.7362726926803589
Validation loss: 2.2170009997583207

Epoch: 6| Step: 4
Training loss: 2.905919075012207
Validation loss: 2.118462444633566

Epoch: 6| Step: 5
Training loss: 2.2140655517578125
Validation loss: 2.226400512520985

Epoch: 6| Step: 6
Training loss: 2.87406063079834
Validation loss: 2.205609511303645

Epoch: 6| Step: 7
Training loss: 3.4352450370788574
Validation loss: 2.3148713368241505

Epoch: 6| Step: 8
Training loss: 1.9059325456619263
Validation loss: 2.135194465678225

Epoch: 6| Step: 9
Training loss: 1.9024320840835571
Validation loss: 2.221912551951665

Epoch: 6| Step: 10
Training loss: 1.878456950187683
Validation loss: 2.2564704392545964

Epoch: 6| Step: 11
Training loss: 2.5854291915893555
Validation loss: 2.271211039635443

Epoch: 6| Step: 12
Training loss: 1.9474446773529053
Validation loss: 2.2269971268151396

Epoch: 6| Step: 13
Training loss: 2.2320172786712646
Validation loss: 2.170213827522852

Epoch: 82| Step: 0
Training loss: 2.1121058464050293
Validation loss: 2.2278096932236866

Epoch: 6| Step: 1
Training loss: 2.2942895889282227
Validation loss: 2.2890983294415217

Epoch: 6| Step: 2
Training loss: 1.8842062950134277
Validation loss: 2.223393412046535

Epoch: 6| Step: 3
Training loss: 2.1802611351013184
Validation loss: 2.207534264492732

Epoch: 6| Step: 4
Training loss: 2.6493446826934814
Validation loss: 2.170227434045525

Epoch: 6| Step: 5
Training loss: 2.569302558898926
Validation loss: 2.3039825270252843

Epoch: 6| Step: 6
Training loss: 2.2160534858703613
Validation loss: 2.211438942981023

Epoch: 6| Step: 7
Training loss: 2.3049755096435547
Validation loss: 2.1628252562656196

Epoch: 6| Step: 8
Training loss: 2.4729013442993164
Validation loss: 2.1507423026587373

Epoch: 6| Step: 9
Training loss: 2.6830344200134277
Validation loss: 2.187309726592033

Epoch: 6| Step: 10
Training loss: 1.6462123394012451
Validation loss: 2.1832613534824823

Epoch: 6| Step: 11
Training loss: 1.7988367080688477
Validation loss: 2.22228067921054

Epoch: 6| Step: 12
Training loss: 2.579409599304199
Validation loss: 2.169674050423407

Epoch: 6| Step: 13
Training loss: 2.294036388397217
Validation loss: 2.1206377834402104

Epoch: 83| Step: 0
Training loss: 2.152216672897339
Validation loss: 2.28289460110408

Epoch: 6| Step: 1
Training loss: 2.215876579284668
Validation loss: 2.2066544307175504

Epoch: 6| Step: 2
Training loss: 2.7753257751464844
Validation loss: 2.239533470522973

Epoch: 6| Step: 3
Training loss: 2.8621201515197754
Validation loss: 2.224914848163564

Epoch: 6| Step: 4
Training loss: 2.602583408355713
Validation loss: 2.262978115389424

Epoch: 6| Step: 5
Training loss: 2.13616943359375
Validation loss: 2.25950292874408

Epoch: 6| Step: 6
Training loss: 2.0054681301116943
Validation loss: 2.218360234332341

Epoch: 6| Step: 7
Training loss: 2.8049025535583496
Validation loss: 2.175783457294587

Epoch: 6| Step: 8
Training loss: 1.4040647745132446
Validation loss: 2.2757807623955513

Epoch: 6| Step: 9
Training loss: 1.60088312625885
Validation loss: 2.2738746763557516

Epoch: 6| Step: 10
Training loss: 2.4636871814727783
Validation loss: 2.2741160905489357

Epoch: 6| Step: 11
Training loss: 2.4932918548583984
Validation loss: 2.2260112403541483

Epoch: 6| Step: 12
Training loss: 2.1647610664367676
Validation loss: 2.2476399867765364

Epoch: 6| Step: 13
Training loss: 2.5127689838409424
Validation loss: 2.2534106111013763

Epoch: 84| Step: 0
Training loss: 2.4253218173980713
Validation loss: 2.214353189673475

Epoch: 6| Step: 1
Training loss: 1.8103128671646118
Validation loss: 2.2139665683110556

Epoch: 6| Step: 2
Training loss: 2.35774564743042
Validation loss: 2.22986941183767

Epoch: 6| Step: 3
Training loss: 1.4791297912597656
Validation loss: 2.19930987845185

Epoch: 6| Step: 4
Training loss: 3.6458871364593506
Validation loss: 2.1809768638303204

Epoch: 6| Step: 5
Training loss: 2.891390800476074
Validation loss: 2.231123320518001

Epoch: 6| Step: 6
Training loss: 1.8038578033447266
Validation loss: 2.1848316397718204

Epoch: 6| Step: 7
Training loss: 2.575744390487671
Validation loss: 2.2153619412452943

Epoch: 6| Step: 8
Training loss: 2.60347318649292
Validation loss: 2.2981344807532524

Epoch: 6| Step: 9
Training loss: 1.8465170860290527
Validation loss: 2.168823226805656

Epoch: 6| Step: 10
Training loss: 1.9891142845153809
Validation loss: 2.2409557142565326

Epoch: 6| Step: 11
Training loss: 2.600896120071411
Validation loss: 2.205791373406687

Epoch: 6| Step: 12
Training loss: 1.6980514526367188
Validation loss: 2.1484792796514367

Epoch: 6| Step: 13
Training loss: 1.4913169145584106
Validation loss: 2.2114609210721907

Epoch: 85| Step: 0
Training loss: 2.001181125640869
Validation loss: 2.2425708052932576

Epoch: 6| Step: 1
Training loss: 2.54394268989563
Validation loss: 2.1584811697724047

Epoch: 6| Step: 2
Training loss: 1.7628082036972046
Validation loss: 2.250437787784043

Epoch: 6| Step: 3
Training loss: 2.7656261920928955
Validation loss: 2.2090351761028333

Epoch: 6| Step: 4
Training loss: 2.5366458892822266
Validation loss: 2.154244602367442

Epoch: 6| Step: 5
Training loss: 1.9119176864624023
Validation loss: 2.2311307281576176

Epoch: 6| Step: 6
Training loss: 1.8672924041748047
Validation loss: 2.235530695607585

Epoch: 6| Step: 7
Training loss: 1.7152456045150757
Validation loss: 2.2366840275385047

Epoch: 6| Step: 8
Training loss: 2.4330782890319824
Validation loss: 2.303931213194324

Epoch: 6| Step: 9
Training loss: 1.8509349822998047
Validation loss: 2.1724010975130144

Epoch: 6| Step: 10
Training loss: 3.563260793685913
Validation loss: 2.1898799045111543

Epoch: 6| Step: 11
Training loss: 2.447598934173584
Validation loss: 2.1916239492354856

Epoch: 6| Step: 12
Training loss: 2.7241361141204834
Validation loss: 2.2136913089342016

Epoch: 6| Step: 13
Training loss: 2.228943109512329
Validation loss: 2.1988266591102845

Epoch: 86| Step: 0
Training loss: 1.73321533203125
Validation loss: 2.1923150554780038

Epoch: 6| Step: 1
Training loss: 2.588121175765991
Validation loss: 2.215788556683448

Epoch: 6| Step: 2
Training loss: 1.824953556060791
Validation loss: 2.2238830058805403

Epoch: 6| Step: 3
Training loss: 1.8650915622711182
Validation loss: 2.2426035404205322

Epoch: 6| Step: 4
Training loss: 2.0225601196289062
Validation loss: 2.2398397179060083

Epoch: 6| Step: 5
Training loss: 2.7665793895721436
Validation loss: 2.194378723380386

Epoch: 6| Step: 6
Training loss: 2.1448006629943848
Validation loss: 2.1845940274576985

Epoch: 6| Step: 7
Training loss: 2.161796808242798
Validation loss: 2.2107785568442395

Epoch: 6| Step: 8
Training loss: 2.9602255821228027
Validation loss: 2.2146827584953717

Epoch: 6| Step: 9
Training loss: 2.8098363876342773
Validation loss: 2.1804932214880504

Epoch: 6| Step: 10
Training loss: 2.576655864715576
Validation loss: 2.2554006281719414

Epoch: 6| Step: 11
Training loss: 2.320950508117676
Validation loss: 2.282989542971375

Epoch: 6| Step: 12
Training loss: 1.9165053367614746
Validation loss: 2.1775206532529605

Epoch: 6| Step: 13
Training loss: 1.94363534450531
Validation loss: 2.2245555616194204

Epoch: 87| Step: 0
Training loss: 2.338165760040283
Validation loss: 2.240261234262938

Epoch: 6| Step: 1
Training loss: 2.192321300506592
Validation loss: 2.1893718499009327

Epoch: 6| Step: 2
Training loss: 2.7021751403808594
Validation loss: 2.2413408756256104

Epoch: 6| Step: 3
Training loss: 1.8002434968948364
Validation loss: 2.2226635333030456

Epoch: 6| Step: 4
Training loss: 2.8539514541625977
Validation loss: 2.3061974894615913

Epoch: 6| Step: 5
Training loss: 1.8753747940063477
Validation loss: 2.1698576186292913

Epoch: 6| Step: 6
Training loss: 3.607956886291504
Validation loss: 2.2074866807588966

Epoch: 6| Step: 7
Training loss: 1.7793176174163818
Validation loss: 2.2252294632696334

Epoch: 6| Step: 8
Training loss: 1.8470772504806519
Validation loss: 2.207152602493122

Epoch: 6| Step: 9
Training loss: 2.9939393997192383
Validation loss: 2.326076474241031

Epoch: 6| Step: 10
Training loss: 2.1572587490081787
Validation loss: 2.161507942343271

Epoch: 6| Step: 11
Training loss: 1.5214108228683472
Validation loss: 2.2682416208328737

Epoch: 6| Step: 12
Training loss: 1.721806287765503
Validation loss: 2.2460229268638034

Epoch: 6| Step: 13
Training loss: 1.8607258796691895
Validation loss: 2.250023682912191

Epoch: 88| Step: 0
Training loss: 1.9862020015716553
Validation loss: 2.1767975079116

Epoch: 6| Step: 1
Training loss: 2.650662660598755
Validation loss: 2.213350381902469

Epoch: 6| Step: 2
Training loss: 2.1403517723083496
Validation loss: 2.2494375423718522

Epoch: 6| Step: 3
Training loss: 1.4760125875473022
Validation loss: 2.206594938872963

Epoch: 6| Step: 4
Training loss: 2.423701763153076
Validation loss: 2.224230904732981

Epoch: 6| Step: 5
Training loss: 2.3671133518218994
Validation loss: 2.1596746393429336

Epoch: 6| Step: 6
Training loss: 3.168043613433838
Validation loss: 2.247589244637438

Epoch: 6| Step: 7
Training loss: 2.295408010482788
Validation loss: 2.161412121147238

Epoch: 6| Step: 8
Training loss: 3.2786507606506348
Validation loss: 2.1921924160372828

Epoch: 6| Step: 9
Training loss: 2.266446113586426
Validation loss: 2.2327670089660154

Epoch: 6| Step: 10
Training loss: 2.240009069442749
Validation loss: 2.224368877308343

Epoch: 6| Step: 11
Training loss: 1.7565126419067383
Validation loss: 2.1759597511701685

Epoch: 6| Step: 12
Training loss: 1.7783334255218506
Validation loss: 2.218063223746515

Epoch: 6| Step: 13
Training loss: 2.10718035697937
Validation loss: 2.262783517119705

Epoch: 89| Step: 0
Training loss: 2.27026104927063
Validation loss: 2.278559365580159

Epoch: 6| Step: 1
Training loss: 2.189742088317871
Validation loss: 2.2886564680325088

Epoch: 6| Step: 2
Training loss: 1.5785622596740723
Validation loss: 2.2542818182258197

Epoch: 6| Step: 3
Training loss: 1.9905288219451904
Validation loss: 2.2181215260618474

Epoch: 6| Step: 4
Training loss: 2.561875820159912
Validation loss: 2.195611510225522

Epoch: 6| Step: 5
Training loss: 2.8407013416290283
Validation loss: 2.2376848869426276

Epoch: 6| Step: 6
Training loss: 3.112168073654175
Validation loss: 2.211930218563285

Epoch: 6| Step: 7
Training loss: 1.7133748531341553
Validation loss: 2.235811548848306

Epoch: 6| Step: 8
Training loss: 2.12027645111084
Validation loss: 2.245902834400054

Epoch: 6| Step: 9
Training loss: 1.6372854709625244
Validation loss: 2.248274923652731

Epoch: 6| Step: 10
Training loss: 2.3777809143066406
Validation loss: 2.2124535191443657

Epoch: 6| Step: 11
Training loss: 1.7824755907058716
Validation loss: 2.2551499412905787

Epoch: 6| Step: 12
Training loss: 2.0177316665649414
Validation loss: 2.2465102082939556

Epoch: 6| Step: 13
Training loss: 3.073408365249634
Validation loss: 2.2317768040523736

Epoch: 90| Step: 0
Training loss: 1.79166841506958
Validation loss: 2.1353803193697365

Epoch: 6| Step: 1
Training loss: 2.112299919128418
Validation loss: 2.186965363000029

Epoch: 6| Step: 2
Training loss: 2.3717565536499023
Validation loss: 2.1937466359907583

Epoch: 6| Step: 3
Training loss: 2.2231554985046387
Validation loss: 2.152455476022536

Epoch: 6| Step: 4
Training loss: 2.485647201538086
Validation loss: 2.1914872123349096

Epoch: 6| Step: 5
Training loss: 2.462068557739258
Validation loss: 2.150688161132156

Epoch: 6| Step: 6
Training loss: 1.7635692358016968
Validation loss: 2.151678272472915

Epoch: 6| Step: 7
Training loss: 1.9992234706878662
Validation loss: 2.1800274156755015

Epoch: 6| Step: 8
Training loss: 2.3419651985168457
Validation loss: 2.246468731152114

Epoch: 6| Step: 9
Training loss: 2.3641250133514404
Validation loss: 2.1693569844768894

Epoch: 6| Step: 10
Training loss: 1.9236148595809937
Validation loss: 2.272671430341659

Epoch: 6| Step: 11
Training loss: 2.9190526008605957
Validation loss: 2.1945658268467074

Epoch: 6| Step: 12
Training loss: 2.7234911918640137
Validation loss: 2.23390023426343

Epoch: 6| Step: 13
Training loss: 2.5148754119873047
Validation loss: 2.170680606237022

Epoch: 91| Step: 0
Training loss: 2.310506582260132
Validation loss: 2.172637924071281

Epoch: 6| Step: 1
Training loss: 2.8900721073150635
Validation loss: 2.211938960577852

Epoch: 6| Step: 2
Training loss: 2.258535861968994
Validation loss: 2.1818115172847623

Epoch: 6| Step: 3
Training loss: 2.2449305057525635
Validation loss: 2.1956758370963474

Epoch: 6| Step: 4
Training loss: 2.247713565826416
Validation loss: 2.2411769641342985

Epoch: 6| Step: 5
Training loss: 1.7954028844833374
Validation loss: 2.175754157445764

Epoch: 6| Step: 6
Training loss: 2.0027220249176025
Validation loss: 2.178692163959626

Epoch: 6| Step: 7
Training loss: 2.5895042419433594
Validation loss: 2.2296771387900076

Epoch: 6| Step: 8
Training loss: 1.896580457687378
Validation loss: 2.1581202001981836

Epoch: 6| Step: 9
Training loss: 2.7449262142181396
Validation loss: 2.279556776887627

Epoch: 6| Step: 10
Training loss: 1.5052331686019897
Validation loss: 2.295959157328452

Epoch: 6| Step: 11
Training loss: 2.017916679382324
Validation loss: 2.2475633672488633

Epoch: 6| Step: 12
Training loss: 2.430406093597412
Validation loss: 2.243605891863505

Epoch: 6| Step: 13
Training loss: 2.834977149963379
Validation loss: 2.245755801918686

Epoch: 92| Step: 0
Training loss: 2.3762543201446533
Validation loss: 2.172739701886331

Epoch: 6| Step: 1
Training loss: 2.4989442825317383
Validation loss: 2.176988394029679

Epoch: 6| Step: 2
Training loss: 2.080808162689209
Validation loss: 2.2052021975158365

Epoch: 6| Step: 3
Training loss: 2.0012407302856445
Validation loss: 2.2109178163672007

Epoch: 6| Step: 4
Training loss: 1.8172848224639893
Validation loss: 2.2135599710608043

Epoch: 6| Step: 5
Training loss: 2.9613265991210938
Validation loss: 2.1618486758201354

Epoch: 6| Step: 6
Training loss: 2.5168914794921875
Validation loss: 2.2267394950312953

Epoch: 6| Step: 7
Training loss: 2.7453556060791016
Validation loss: 2.2376145085980816

Epoch: 6| Step: 8
Training loss: 1.217456340789795
Validation loss: 2.288540760676066

Epoch: 6| Step: 9
Training loss: 2.2907955646514893
Validation loss: 2.185250528397099

Epoch: 6| Step: 10
Training loss: 2.775911331176758
Validation loss: 2.24349094078105

Epoch: 6| Step: 11
Training loss: 2.807114601135254
Validation loss: 2.19579904566529

Epoch: 6| Step: 12
Training loss: 2.170954704284668
Validation loss: 2.1868800604215233

Epoch: 6| Step: 13
Training loss: 1.7053228616714478
Validation loss: 2.178721011325877

Epoch: 93| Step: 0
Training loss: 2.3252594470977783
Validation loss: 2.1675768154923634

Epoch: 6| Step: 1
Training loss: 3.096935510635376
Validation loss: 2.150928117895639

Epoch: 6| Step: 2
Training loss: 2.4902687072753906
Validation loss: 2.26594848914813

Epoch: 6| Step: 3
Training loss: 2.384718894958496
Validation loss: 2.2358070368407876

Epoch: 6| Step: 4
Training loss: 2.015214204788208
Validation loss: 2.129212810147193

Epoch: 6| Step: 5
Training loss: 2.465149402618408
Validation loss: 2.21363264770918

Epoch: 6| Step: 6
Training loss: 2.2384283542633057
Validation loss: 2.1895670454989196

Epoch: 6| Step: 7
Training loss: 2.0881826877593994
Validation loss: 2.226781340055568

Epoch: 6| Step: 8
Training loss: 2.3683714866638184
Validation loss: 2.2332748520758843

Epoch: 6| Step: 9
Training loss: 0.7264705300331116
Validation loss: 2.1632809972250335

Epoch: 6| Step: 10
Training loss: 2.4853854179382324
Validation loss: 2.1955247899537444

Epoch: 6| Step: 11
Training loss: 2.2076637744903564
Validation loss: 2.2590165535608926

Epoch: 6| Step: 12
Training loss: 2.8340401649475098
Validation loss: 2.203714538646001

Epoch: 6| Step: 13
Training loss: 2.407710075378418
Validation loss: 2.1661335588783346

Epoch: 94| Step: 0
Training loss: 3.0259947776794434
Validation loss: 2.2679108599180817

Epoch: 6| Step: 1
Training loss: 2.2125110626220703
Validation loss: 2.194053972921064

Epoch: 6| Step: 2
Training loss: 2.1292481422424316
Validation loss: 2.1839438471742856

Epoch: 6| Step: 3
Training loss: 1.9170336723327637
Validation loss: 2.1960386819736932

Epoch: 6| Step: 4
Training loss: 2.8214378356933594
Validation loss: 2.137435459321545

Epoch: 6| Step: 5
Training loss: 2.842733860015869
Validation loss: 2.2240956085984425

Epoch: 6| Step: 6
Training loss: 1.427598476409912
Validation loss: 2.2082698755366827

Epoch: 6| Step: 7
Training loss: 2.216346025466919
Validation loss: 2.217072779132474

Epoch: 6| Step: 8
Training loss: 2.4371747970581055
Validation loss: 2.155405100955758

Epoch: 6| Step: 9
Training loss: 1.9023281335830688
Validation loss: 2.2190152316965084

Epoch: 6| Step: 10
Training loss: 1.4994604587554932
Validation loss: 2.24750421636848

Epoch: 6| Step: 11
Training loss: 2.8291049003601074
Validation loss: 2.12716241293056

Epoch: 6| Step: 12
Training loss: 1.4885146617889404
Validation loss: 2.2000760109193864

Epoch: 6| Step: 13
Training loss: 2.9726569652557373
Validation loss: 2.162863714720613

Epoch: 95| Step: 0
Training loss: 2.0931262969970703
Validation loss: 2.2050106345966296

Epoch: 6| Step: 1
Training loss: 2.1417105197906494
Validation loss: 2.1723018025839202

Epoch: 6| Step: 2
Training loss: 2.3679118156433105
Validation loss: 2.2314262543955157

Epoch: 6| Step: 3
Training loss: 2.2750349044799805
Validation loss: 2.180567431193526

Epoch: 6| Step: 4
Training loss: 2.0980963706970215
Validation loss: 2.2129716283531597

Epoch: 6| Step: 5
Training loss: 2.0067198276519775
Validation loss: 2.239595749044931

Epoch: 6| Step: 6
Training loss: 2.7483654022216797
Validation loss: 2.2082419754356466

Epoch: 6| Step: 7
Training loss: 2.340778350830078
Validation loss: 2.278171189369694

Epoch: 6| Step: 8
Training loss: 2.1357808113098145
Validation loss: 2.227490266164144

Epoch: 6| Step: 9
Training loss: 2.1447508335113525
Validation loss: 2.236532759922807

Epoch: 6| Step: 10
Training loss: 1.7212276458740234
Validation loss: 2.2551285759095223

Epoch: 6| Step: 11
Training loss: 2.0039124488830566
Validation loss: 2.231259443426645

Epoch: 6| Step: 12
Training loss: 2.67225980758667
Validation loss: 2.2929589774018977

Epoch: 6| Step: 13
Training loss: 2.297362804412842
Validation loss: 2.127467986076109

Epoch: 96| Step: 0
Training loss: 2.1802141666412354
Validation loss: 2.224065056411169

Epoch: 6| Step: 1
Training loss: 2.306276321411133
Validation loss: 2.246911584690053

Epoch: 6| Step: 2
Training loss: 2.601571559906006
Validation loss: 2.2618202445327595

Epoch: 6| Step: 3
Training loss: 2.1986277103424072
Validation loss: 2.2264845601973997

Epoch: 6| Step: 4
Training loss: 2.804926872253418
Validation loss: 2.192829306407641

Epoch: 6| Step: 5
Training loss: 2.4923582077026367
Validation loss: 2.228512728086082

Epoch: 6| Step: 6
Training loss: 1.7665600776672363
Validation loss: 2.222667960710423

Epoch: 6| Step: 7
Training loss: 2.5273194313049316
Validation loss: 2.2181006041906213

Epoch: 6| Step: 8
Training loss: 2.1943373680114746
Validation loss: 2.2673426879349576

Epoch: 6| Step: 9
Training loss: 2.1862008571624756
Validation loss: 2.2158580133991856

Epoch: 6| Step: 10
Training loss: 1.8134520053863525
Validation loss: 2.255085692610792

Epoch: 6| Step: 11
Training loss: 1.8432374000549316
Validation loss: 2.2690769331429594

Epoch: 6| Step: 12
Training loss: 2.4204533100128174
Validation loss: 2.134496581169867

Epoch: 6| Step: 13
Training loss: 2.5917246341705322
Validation loss: 2.248367530043407

Epoch: 97| Step: 0
Training loss: 2.3426406383514404
Validation loss: 2.2591433653267483

Epoch: 6| Step: 1
Training loss: 1.9359183311462402
Validation loss: 2.197645056632257

Epoch: 6| Step: 2
Training loss: 2.3400022983551025
Validation loss: 2.167342270574262

Epoch: 6| Step: 3
Training loss: 2.2762835025787354
Validation loss: 2.199183302540933

Epoch: 6| Step: 4
Training loss: 1.7078723907470703
Validation loss: 2.1105472246805825

Epoch: 6| Step: 5
Training loss: 2.320880174636841
Validation loss: 2.2319329169488724

Epoch: 6| Step: 6
Training loss: 2.492347478866577
Validation loss: 2.1841704383973153

Epoch: 6| Step: 7
Training loss: 2.3962979316711426
Validation loss: 2.176917611911733

Epoch: 6| Step: 8
Training loss: 2.3626859188079834
Validation loss: 2.173878644102363

Epoch: 6| Step: 9
Training loss: 2.563817024230957
Validation loss: 2.2474302617452477

Epoch: 6| Step: 10
Training loss: 2.2545623779296875
Validation loss: 2.1586588480139293

Epoch: 6| Step: 11
Training loss: 2.2387008666992188
Validation loss: 2.225571224766393

Epoch: 6| Step: 12
Training loss: 1.8359633684158325
Validation loss: 2.16315685677272

Epoch: 6| Step: 13
Training loss: 1.752970814704895
Validation loss: 2.161578296333231

Epoch: 98| Step: 0
Training loss: 1.0680468082427979
Validation loss: 2.1754954553419545

Epoch: 6| Step: 1
Training loss: 2.835090160369873
Validation loss: 2.1998102844402356

Epoch: 6| Step: 2
Training loss: 1.8975145816802979
Validation loss: 2.24815825621287

Epoch: 6| Step: 3
Training loss: 1.782605767250061
Validation loss: 2.1260426326464583

Epoch: 6| Step: 4
Training loss: 2.0939133167266846
Validation loss: 2.2186561220435688

Epoch: 6| Step: 5
Training loss: 3.0220320224761963
Validation loss: 2.233520987213299

Epoch: 6| Step: 6
Training loss: 1.8772690296173096
Validation loss: 2.1961050469388246

Epoch: 6| Step: 7
Training loss: 2.8824386596679688
Validation loss: 2.207008654071439

Epoch: 6| Step: 8
Training loss: 2.477961540222168
Validation loss: 2.2063973052527315

Epoch: 6| Step: 9
Training loss: 2.0842275619506836
Validation loss: 2.2910411537334485

Epoch: 6| Step: 10
Training loss: 2.681499481201172
Validation loss: 2.2322166940217376

Epoch: 6| Step: 11
Training loss: 1.7646255493164062
Validation loss: 2.1931468145821684

Epoch: 6| Step: 12
Training loss: 2.9677734375
Validation loss: 2.2123202585404917

Epoch: 6| Step: 13
Training loss: 2.3886477947235107
Validation loss: 2.2004360921921267

Epoch: 99| Step: 0
Training loss: 1.881334662437439
Validation loss: 2.2685857844609085

Epoch: 6| Step: 1
Training loss: 2.9907679557800293
Validation loss: 2.173620863627362

Epoch: 6| Step: 2
Training loss: 2.224255084991455
Validation loss: 2.1767024378622732

Epoch: 6| Step: 3
Training loss: 1.918837547302246
Validation loss: 2.1664711198499127

Epoch: 6| Step: 4
Training loss: 3.192561626434326
Validation loss: 2.1439249438624226

Epoch: 6| Step: 5
Training loss: 2.1565823554992676
Validation loss: 2.272677990698045

Epoch: 6| Step: 6
Training loss: 1.8622887134552002
Validation loss: 2.1809629753071773

Epoch: 6| Step: 7
Training loss: 2.6918065547943115
Validation loss: 2.172583190343713

Epoch: 6| Step: 8
Training loss: 1.6504908800125122
Validation loss: 2.214871436037043

Epoch: 6| Step: 9
Training loss: 2.227626085281372
Validation loss: 2.291734116051787

Epoch: 6| Step: 10
Training loss: 2.3295531272888184
Validation loss: 2.145751009705246

Epoch: 6| Step: 11
Training loss: 2.280778408050537
Validation loss: 2.2268425328757173

Epoch: 6| Step: 12
Training loss: 2.473125696182251
Validation loss: 2.21541658524544

Epoch: 6| Step: 13
Training loss: 1.79859459400177
Validation loss: 2.241321115083592

Epoch: 100| Step: 0
Training loss: 2.4589500427246094
Validation loss: 2.2034267174300326

Epoch: 6| Step: 1
Training loss: 2.0266432762145996
Validation loss: 2.202152144524359

Epoch: 6| Step: 2
Training loss: 2.4917213916778564
Validation loss: 2.184549664938322

Epoch: 6| Step: 3
Training loss: 2.1286091804504395
Validation loss: 2.2018701261089695

Epoch: 6| Step: 4
Training loss: 2.4485321044921875
Validation loss: 2.231878034530147

Epoch: 6| Step: 5
Training loss: 2.393197774887085
Validation loss: 2.189525370956749

Epoch: 6| Step: 6
Training loss: 2.2732791900634766
Validation loss: 2.190886716688833

Epoch: 6| Step: 7
Training loss: 2.655332326889038
Validation loss: 2.208465335189655

Epoch: 6| Step: 8
Training loss: 1.881844401359558
Validation loss: 2.1424681576349403

Epoch: 6| Step: 9
Training loss: 2.143747329711914
Validation loss: 2.1928695094200874

Epoch: 6| Step: 10
Training loss: 1.6749927997589111
Validation loss: 2.1982823046304847

Epoch: 6| Step: 11
Training loss: 1.7151379585266113
Validation loss: 2.186213457456199

Epoch: 6| Step: 12
Training loss: 2.2050652503967285
Validation loss: 2.222628919027185

Epoch: 6| Step: 13
Training loss: 2.8139734268188477
Validation loss: 2.1721857978451635

Epoch: 101| Step: 0
Training loss: 2.68959379196167
Validation loss: 2.211962661435527

Epoch: 6| Step: 1
Training loss: 2.1601078510284424
Validation loss: 2.1626933620822046

Epoch: 6| Step: 2
Training loss: 2.039114475250244
Validation loss: 2.137811969685298

Epoch: 6| Step: 3
Training loss: 2.3418352603912354
Validation loss: 2.2360937531276415

Epoch: 6| Step: 4
Training loss: 1.7425320148468018
Validation loss: 2.236131324562975

Epoch: 6| Step: 5
Training loss: 2.3167076110839844
Validation loss: 2.2343105244380173

Epoch: 6| Step: 6
Training loss: 1.9652124643325806
Validation loss: 2.2281215370342298

Epoch: 6| Step: 7
Training loss: 2.53212833404541
Validation loss: 2.173377299821505

Epoch: 6| Step: 8
Training loss: 2.6647486686706543
Validation loss: 2.1928883931970082

Epoch: 6| Step: 9
Training loss: 2.301201820373535
Validation loss: 2.249184298258956

Epoch: 6| Step: 10
Training loss: 2.8089067935943604
Validation loss: 2.2912530335046912

Epoch: 6| Step: 11
Training loss: 1.6649785041809082
Validation loss: 2.1852721219421714

Epoch: 6| Step: 12
Training loss: 1.4264583587646484
Validation loss: 2.213360935129145

Epoch: 6| Step: 13
Training loss: 2.8626325130462646
Validation loss: 2.2265179285439114

Epoch: 102| Step: 0
Training loss: 2.6203932762145996
Validation loss: 2.215925206420242

Epoch: 6| Step: 1
Training loss: 2.062880516052246
Validation loss: 2.2089451141254877

Epoch: 6| Step: 2
Training loss: 2.215712070465088
Validation loss: 2.2272969394601803

Epoch: 6| Step: 3
Training loss: 1.894273281097412
Validation loss: 2.2425992719588743

Epoch: 6| Step: 4
Training loss: 2.1653947830200195
Validation loss: 2.259255160567581

Epoch: 6| Step: 5
Training loss: 2.312183141708374
Validation loss: 2.17438647823949

Epoch: 6| Step: 6
Training loss: 2.3823037147521973
Validation loss: 2.1934796635822584

Epoch: 6| Step: 7
Training loss: 2.4708333015441895
Validation loss: 2.162019742432461

Epoch: 6| Step: 8
Training loss: 2.020580768585205
Validation loss: 2.2200534125810027

Epoch: 6| Step: 9
Training loss: 1.7756922245025635
Validation loss: 2.2148833300477717

Epoch: 6| Step: 10
Training loss: 2.022829532623291
Validation loss: 2.280849079931936

Epoch: 6| Step: 11
Training loss: 1.585410475730896
Validation loss: 2.1983055478783062

Epoch: 6| Step: 12
Training loss: 3.2482261657714844
Validation loss: 2.1985839592513217

Epoch: 6| Step: 13
Training loss: 2.5906803607940674
Validation loss: 2.231838805701143

Epoch: 103| Step: 0
Training loss: 1.999694585800171
Validation loss: 2.1684059712194625

Epoch: 6| Step: 1
Training loss: 2.5048904418945312
Validation loss: 2.140019678300427

Epoch: 6| Step: 2
Training loss: 1.5765621662139893
Validation loss: 2.1654647447729625

Epoch: 6| Step: 3
Training loss: 2.4815123081207275
Validation loss: 2.1755305080003637

Epoch: 6| Step: 4
Training loss: 1.705085277557373
Validation loss: 2.2306362582791235

Epoch: 6| Step: 5
Training loss: 2.190997362136841
Validation loss: 2.143756810054984

Epoch: 6| Step: 6
Training loss: 1.8388681411743164
Validation loss: 2.155044227518061

Epoch: 6| Step: 7
Training loss: 2.3794105052948
Validation loss: 2.2353584586933093

Epoch: 6| Step: 8
Training loss: 2.9181196689605713
Validation loss: 2.18649572326291

Epoch: 6| Step: 9
Training loss: 2.1615068912506104
Validation loss: 2.185715712526793

Epoch: 6| Step: 10
Training loss: 2.8372018337249756
Validation loss: 2.2498142539813952

Epoch: 6| Step: 11
Training loss: 1.9208747148513794
Validation loss: 2.163004062509024

Epoch: 6| Step: 12
Training loss: 2.4909486770629883
Validation loss: 2.1976312411728727

Epoch: 6| Step: 13
Training loss: 2.362545967102051
Validation loss: 2.137474859914472

Epoch: 104| Step: 0
Training loss: 2.386226177215576
Validation loss: 2.1311265755725164

Epoch: 6| Step: 1
Training loss: 2.2219414710998535
Validation loss: 2.1843548461955082

Epoch: 6| Step: 2
Training loss: 2.339355945587158
Validation loss: 2.2266710906900387

Epoch: 6| Step: 3
Training loss: 1.5256969928741455
Validation loss: 2.2325550689492175

Epoch: 6| Step: 4
Training loss: 2.977527141571045
Validation loss: 2.1486055915073683

Epoch: 6| Step: 5
Training loss: 1.7034276723861694
Validation loss: 2.2496353939015377

Epoch: 6| Step: 6
Training loss: 2.3343379497528076
Validation loss: 2.2128302871540027

Epoch: 6| Step: 7
Training loss: 2.5892505645751953
Validation loss: 2.2065134663735666

Epoch: 6| Step: 8
Training loss: 1.7414419651031494
Validation loss: 2.1888257906001103

Epoch: 6| Step: 9
Training loss: 2.1688692569732666
Validation loss: 2.206654812700005

Epoch: 6| Step: 10
Training loss: 2.4949827194213867
Validation loss: 2.1940742513184905

Epoch: 6| Step: 11
Training loss: 2.3474886417388916
Validation loss: 2.2016740024730725

Epoch: 6| Step: 12
Training loss: 2.814751625061035
Validation loss: 2.153723329626104

Epoch: 6| Step: 13
Training loss: 2.441756248474121
Validation loss: 2.1868798604575534

Epoch: 105| Step: 0
Training loss: 1.7793116569519043
Validation loss: 2.138920569932589

Epoch: 6| Step: 1
Training loss: 2.059011459350586
Validation loss: 2.2472115383353284

Epoch: 6| Step: 2
Training loss: 2.2250263690948486
Validation loss: 2.2138836512001614

Epoch: 6| Step: 3
Training loss: 2.548569440841675
Validation loss: 2.1891055376298967

Epoch: 6| Step: 4
Training loss: 2.372786521911621
Validation loss: 2.18701518735578

Epoch: 6| Step: 5
Training loss: 2.2359020709991455
Validation loss: 2.1806818746751353

Epoch: 6| Step: 6
Training loss: 3.3654332160949707
Validation loss: 2.1860460414681384

Epoch: 6| Step: 7
Training loss: 1.9031776189804077
Validation loss: 2.1368243873760266

Epoch: 6| Step: 8
Training loss: 1.7793152332305908
Validation loss: 2.1493378159820393

Epoch: 6| Step: 9
Training loss: 1.8842179775238037
Validation loss: 2.136789298826648

Epoch: 6| Step: 10
Training loss: 2.456895589828491
Validation loss: 2.2626050569677867

Epoch: 6| Step: 11
Training loss: 2.156832695007324
Validation loss: 2.2098349576355307

Epoch: 6| Step: 12
Training loss: 2.3653006553649902
Validation loss: 2.2017521550578456

Epoch: 6| Step: 13
Training loss: 1.5238827466964722
Validation loss: 2.16980682393556

Epoch: 106| Step: 0
Training loss: 2.763577699661255
Validation loss: 2.2129981171700264

Epoch: 6| Step: 1
Training loss: 2.6194562911987305
Validation loss: 2.216136165844497

Epoch: 6| Step: 2
Training loss: 1.7576570510864258
Validation loss: 2.1968207154222714

Epoch: 6| Step: 3
Training loss: 2.6281018257141113
Validation loss: 2.198626579776887

Epoch: 6| Step: 4
Training loss: 1.7313153743743896
Validation loss: 2.211990840973393

Epoch: 6| Step: 5
Training loss: 2.0827536582946777
Validation loss: 2.279486063987978

Epoch: 6| Step: 6
Training loss: 2.4723358154296875
Validation loss: 2.275904909256966

Epoch: 6| Step: 7
Training loss: 2.2747368812561035
Validation loss: 2.281290723431495

Epoch: 6| Step: 8
Training loss: 1.5667293071746826
Validation loss: 2.372741929946407

Epoch: 6| Step: 9
Training loss: 3.056051731109619
Validation loss: 2.3148145624386367

Epoch: 6| Step: 10
Training loss: 1.5723631381988525
Validation loss: 2.1973443749130412

Epoch: 6| Step: 11
Training loss: 1.9420368671417236
Validation loss: 2.3279976306423062

Epoch: 6| Step: 12
Training loss: 1.9716829061508179
Validation loss: 2.238381096111831

Epoch: 6| Step: 13
Training loss: 1.7049674987792969
Validation loss: 2.2982456709748957

Epoch: 107| Step: 0
Training loss: 1.7936899662017822
Validation loss: 2.282084736772763

Epoch: 6| Step: 1
Training loss: 2.656036615371704
Validation loss: 2.275213785068963

Epoch: 6| Step: 2
Training loss: 2.418168783187866
Validation loss: 2.2523458414180304

Epoch: 6| Step: 3
Training loss: 1.7922219038009644
Validation loss: 2.1850969560684694

Epoch: 6| Step: 4
Training loss: 1.9888367652893066
Validation loss: 2.184625373091749

Epoch: 6| Step: 5
Training loss: 1.7720450162887573
Validation loss: 2.1068108235636065

Epoch: 6| Step: 6
Training loss: 2.753793239593506
Validation loss: 2.2124575517510854

Epoch: 6| Step: 7
Training loss: 2.717709541320801
Validation loss: 2.2315414169783234

Epoch: 6| Step: 8
Training loss: 2.5750961303710938
Validation loss: 2.1294071110345985

Epoch: 6| Step: 9
Training loss: 2.2310805320739746
Validation loss: 2.11275984907663

Epoch: 6| Step: 10
Training loss: 2.8095169067382812
Validation loss: 2.1250097238889305

Epoch: 6| Step: 11
Training loss: 2.1834068298339844
Validation loss: 2.149524365701983

Epoch: 6| Step: 12
Training loss: 1.6198506355285645
Validation loss: 2.1454829938950075

Epoch: 6| Step: 13
Training loss: 1.6548442840576172
Validation loss: 2.16034693871775

Epoch: 108| Step: 0
Training loss: 2.5783002376556396
Validation loss: 2.16158305188661

Epoch: 6| Step: 1
Training loss: 2.262202024459839
Validation loss: 2.1969710652546217

Epoch: 6| Step: 2
Training loss: 2.0839548110961914
Validation loss: 2.2189443034510457

Epoch: 6| Step: 3
Training loss: 2.3264501094818115
Validation loss: 2.2035526716580955

Epoch: 6| Step: 4
Training loss: 2.1763603687286377
Validation loss: 2.2401103499115154

Epoch: 6| Step: 5
Training loss: 3.5049219131469727
Validation loss: 2.1300049366489535

Epoch: 6| Step: 6
Training loss: 1.7799980640411377
Validation loss: 2.175251430080783

Epoch: 6| Step: 7
Training loss: 1.5672149658203125
Validation loss: 2.1808481857340825

Epoch: 6| Step: 8
Training loss: 1.2430765628814697
Validation loss: 2.1188274762963735

Epoch: 6| Step: 9
Training loss: 1.6682522296905518
Validation loss: 2.210465867032287

Epoch: 6| Step: 10
Training loss: 2.208852529525757
Validation loss: 2.158958040257936

Epoch: 6| Step: 11
Training loss: 2.7072720527648926
Validation loss: 2.1094098193671114

Epoch: 6| Step: 12
Training loss: 2.115276336669922
Validation loss: 2.2104667681519703

Epoch: 6| Step: 13
Training loss: 2.720879316329956
Validation loss: 2.1698526490119194

Epoch: 109| Step: 0
Training loss: 3.5542829036712646
Validation loss: 2.1282369218846804

Epoch: 6| Step: 1
Training loss: 1.369774580001831
Validation loss: 2.199844842316002

Epoch: 6| Step: 2
Training loss: 1.9789659976959229
Validation loss: 2.183550306545791

Epoch: 6| Step: 3
Training loss: 2.35160231590271
Validation loss: 2.1860084302963747

Epoch: 6| Step: 4
Training loss: 2.2867860794067383
Validation loss: 2.1942006054744927

Epoch: 6| Step: 5
Training loss: 2.396329164505005
Validation loss: 2.2241904774019794

Epoch: 6| Step: 6
Training loss: 1.7621395587921143
Validation loss: 2.1887489185538342

Epoch: 6| Step: 7
Training loss: 2.677541732788086
Validation loss: 2.233383696566346

Epoch: 6| Step: 8
Training loss: 2.4304089546203613
Validation loss: 2.184039822188757

Epoch: 6| Step: 9
Training loss: 2.3024096488952637
Validation loss: 2.2173775447312223

Epoch: 6| Step: 10
Training loss: 1.5765390396118164
Validation loss: 2.251952417435185

Epoch: 6| Step: 11
Training loss: 2.2330665588378906
Validation loss: 2.1994518644066265

Epoch: 6| Step: 12
Training loss: 2.1953110694885254
Validation loss: 2.349831164524119

Epoch: 6| Step: 13
Training loss: 2.0847177505493164
Validation loss: 2.2955260635704122

Epoch: 110| Step: 0
Training loss: 1.7952054738998413
Validation loss: 2.3121307229483

Epoch: 6| Step: 1
Training loss: 2.0656626224517822
Validation loss: 2.2550530408018377

Epoch: 6| Step: 2
Training loss: 2.530158281326294
Validation loss: 2.257644348247077

Epoch: 6| Step: 3
Training loss: 2.4377336502075195
Validation loss: 2.325473226526732

Epoch: 6| Step: 4
Training loss: 2.4858009815216064
Validation loss: 2.3028426452349593

Epoch: 6| Step: 5
Training loss: 2.3331165313720703
Validation loss: 2.374770668245131

Epoch: 6| Step: 6
Training loss: 2.475567579269409
Validation loss: 2.337171713511149

Epoch: 6| Step: 7
Training loss: 2.1620538234710693
Validation loss: 2.362569416722944

Epoch: 6| Step: 8
Training loss: 1.726767659187317
Validation loss: 2.207848705271239

Epoch: 6| Step: 9
Training loss: 2.4496586322784424
Validation loss: 2.2923199925371396

Epoch: 6| Step: 10
Training loss: 2.061530113220215
Validation loss: 2.2834900732963317

Epoch: 6| Step: 11
Training loss: 1.7559597492218018
Validation loss: 2.1988870482290945

Epoch: 6| Step: 12
Training loss: 2.6512036323547363
Validation loss: 2.261901299158732

Epoch: 6| Step: 13
Training loss: 2.0693812370300293
Validation loss: 2.2198041562111146

Epoch: 111| Step: 0
Training loss: 2.4439432621002197
Validation loss: 2.2039164663642965

Epoch: 6| Step: 1
Training loss: 2.0381546020507812
Validation loss: 2.172090889305197

Epoch: 6| Step: 2
Training loss: 1.6868478059768677
Validation loss: 2.1849673499343214

Epoch: 6| Step: 3
Training loss: 2.458517074584961
Validation loss: 2.2146666203775713

Epoch: 6| Step: 4
Training loss: 1.355302333831787
Validation loss: 2.170291334070185

Epoch: 6| Step: 5
Training loss: 2.9800806045532227
Validation loss: 2.2324550459461827

Epoch: 6| Step: 6
Training loss: 2.2850749492645264
Validation loss: 2.119220463178491

Epoch: 6| Step: 7
Training loss: 1.8159469366073608
Validation loss: 2.125137795684158

Epoch: 6| Step: 8
Training loss: 2.9486143589019775
Validation loss: 2.1506031174813547

Epoch: 6| Step: 9
Training loss: 2.1105735301971436
Validation loss: 2.2153819991696264

Epoch: 6| Step: 10
Training loss: 2.7485737800598145
Validation loss: 2.0707960026238554

Epoch: 6| Step: 11
Training loss: 2.071580648422241
Validation loss: 2.1350166284909813

Epoch: 6| Step: 12
Training loss: 2.2543869018554688
Validation loss: 2.177889508585776

Epoch: 6| Step: 13
Training loss: 1.333872675895691
Validation loss: 2.20287404265455

Epoch: 112| Step: 0
Training loss: 2.339904546737671
Validation loss: 2.2644970801568802

Epoch: 6| Step: 1
Training loss: 2.4365580081939697
Validation loss: 2.138126047708655

Epoch: 6| Step: 2
Training loss: 3.1364212036132812
Validation loss: 2.1543154742128108

Epoch: 6| Step: 3
Training loss: 2.498645544052124
Validation loss: 2.1952045181746125

Epoch: 6| Step: 4
Training loss: 2.056607246398926
Validation loss: 2.252791427796887

Epoch: 6| Step: 5
Training loss: 2.141422748565674
Validation loss: 2.2482934510836037

Epoch: 6| Step: 6
Training loss: 1.5708526372909546
Validation loss: 2.141604200486214

Epoch: 6| Step: 7
Training loss: 2.182206630706787
Validation loss: 2.2070864580010854

Epoch: 6| Step: 8
Training loss: 2.59647798538208
Validation loss: 2.1467093754840154

Epoch: 6| Step: 9
Training loss: 2.6029059886932373
Validation loss: 2.281333186293161

Epoch: 6| Step: 10
Training loss: 1.7303669452667236
Validation loss: 2.2559828681330525

Epoch: 6| Step: 11
Training loss: 2.383333206176758
Validation loss: 2.24821138381958

Epoch: 6| Step: 12
Training loss: 2.216092824935913
Validation loss: 2.2406771093286495

Epoch: 6| Step: 13
Training loss: 1.08989679813385
Validation loss: 2.2737793794242283

Epoch: 113| Step: 0
Training loss: 1.737336277961731
Validation loss: 2.2547167078141244

Epoch: 6| Step: 1
Training loss: 1.939241647720337
Validation loss: 2.250751574834188

Epoch: 6| Step: 2
Training loss: 2.2577171325683594
Validation loss: 2.175005505161901

Epoch: 6| Step: 3
Training loss: 2.2776896953582764
Validation loss: 2.31295374901064

Epoch: 6| Step: 4
Training loss: 2.66050124168396
Validation loss: 2.2377620461166545

Epoch: 6| Step: 5
Training loss: 1.8279914855957031
Validation loss: 2.2048198664060203

Epoch: 6| Step: 6
Training loss: 1.4836146831512451
Validation loss: 2.2709412984950568

Epoch: 6| Step: 7
Training loss: 2.2863402366638184
Validation loss: 2.2234592181380077

Epoch: 6| Step: 8
Training loss: 1.9023222923278809
Validation loss: 2.19316029548645

Epoch: 6| Step: 9
Training loss: 2.079681634902954
Validation loss: 2.2252771777491414

Epoch: 6| Step: 10
Training loss: 2.7982900142669678
Validation loss: 2.187686627910983

Epoch: 6| Step: 11
Training loss: 2.405283212661743
Validation loss: 2.219380153122769

Epoch: 6| Step: 12
Training loss: 2.5899248123168945
Validation loss: 2.1996065775553384

Epoch: 6| Step: 13
Training loss: 2.5719220638275146
Validation loss: 2.2113135886448685

Epoch: 114| Step: 0
Training loss: 2.531162738800049
Validation loss: 2.194657543654083

Epoch: 6| Step: 1
Training loss: 2.925901412963867
Validation loss: 2.0794404117009972

Epoch: 6| Step: 2
Training loss: 1.6968493461608887
Validation loss: 2.1602037619518977

Epoch: 6| Step: 3
Training loss: 1.5103574991226196
Validation loss: 2.1560008628394014

Epoch: 6| Step: 4
Training loss: 2.579988956451416
Validation loss: 2.1955925469757407

Epoch: 6| Step: 5
Training loss: 2.230863094329834
Validation loss: 2.2108746638862034

Epoch: 6| Step: 6
Training loss: 1.4742848873138428
Validation loss: 2.193819858694589

Epoch: 6| Step: 7
Training loss: 2.399907112121582
Validation loss: 2.214156189272481

Epoch: 6| Step: 8
Training loss: 1.6791939735412598
Validation loss: 2.1539403277058757

Epoch: 6| Step: 9
Training loss: 2.265861988067627
Validation loss: 2.1987549156271

Epoch: 6| Step: 10
Training loss: 2.438174247741699
Validation loss: 2.2615217008898334

Epoch: 6| Step: 11
Training loss: 2.7217016220092773
Validation loss: 2.1412940691876154

Epoch: 6| Step: 12
Training loss: 2.328972816467285
Validation loss: 2.1393393829304683

Epoch: 6| Step: 13
Training loss: 2.9232215881347656
Validation loss: 2.1129007083113476

Epoch: 115| Step: 0
Training loss: 1.9624491930007935
Validation loss: 2.1234339411540697

Epoch: 6| Step: 1
Training loss: 2.5391910076141357
Validation loss: 2.2114585791864703

Epoch: 6| Step: 2
Training loss: 2.25949764251709
Validation loss: 2.1673016458429317

Epoch: 6| Step: 3
Training loss: 3.153590440750122
Validation loss: 2.200937327518258

Epoch: 6| Step: 4
Training loss: 2.6636886596679688
Validation loss: 2.1834529151198683

Epoch: 6| Step: 5
Training loss: 2.3369336128234863
Validation loss: 2.1591180857791694

Epoch: 6| Step: 6
Training loss: 2.71840238571167
Validation loss: 2.2891578110315467

Epoch: 6| Step: 7
Training loss: 1.6077537536621094
Validation loss: 2.1823932663086922

Epoch: 6| Step: 8
Training loss: 1.8392333984375
Validation loss: 2.1397318352935133

Epoch: 6| Step: 9
Training loss: 2.0659000873565674
Validation loss: 2.1997573132156045

Epoch: 6| Step: 10
Training loss: 1.899601936340332
Validation loss: 2.248684626753612

Epoch: 6| Step: 11
Training loss: 1.5843777656555176
Validation loss: 2.3130708086875176

Epoch: 6| Step: 12
Training loss: 1.6738193035125732
Validation loss: 2.197449546988292

Epoch: 6| Step: 13
Training loss: 2.988619327545166
Validation loss: 2.1479295428081224

Epoch: 116| Step: 0
Training loss: 2.0776727199554443
Validation loss: 2.191289319786974

Epoch: 6| Step: 1
Training loss: 1.1774091720581055
Validation loss: 2.1427586796463176

Epoch: 6| Step: 2
Training loss: 2.402869939804077
Validation loss: 2.197039258095526

Epoch: 6| Step: 3
Training loss: 2.3860483169555664
Validation loss: 2.2010462078996884

Epoch: 6| Step: 4
Training loss: 2.2248716354370117
Validation loss: 2.2390742019940446

Epoch: 6| Step: 5
Training loss: 2.1220057010650635
Validation loss: 2.1556875705718994

Epoch: 6| Step: 6
Training loss: 2.429034948348999
Validation loss: 2.183808490794192

Epoch: 6| Step: 7
Training loss: 1.524023413658142
Validation loss: 2.1540327687417307

Epoch: 6| Step: 8
Training loss: 2.20609712600708
Validation loss: 2.2429037222298245

Epoch: 6| Step: 9
Training loss: 2.289964199066162
Validation loss: 2.253249469623771

Epoch: 6| Step: 10
Training loss: 2.564627170562744
Validation loss: 2.238291653253699

Epoch: 6| Step: 11
Training loss: 1.9642763137817383
Validation loss: 2.346064257365401

Epoch: 6| Step: 12
Training loss: 2.357290744781494
Validation loss: 2.232048560214299

Epoch: 6| Step: 13
Training loss: 2.7471365928649902
Validation loss: 2.230754908695016

Epoch: 117| Step: 0
Training loss: 2.0963358879089355
Validation loss: 2.305604132272864

Epoch: 6| Step: 1
Training loss: 2.880361318588257
Validation loss: 2.155506859543503

Epoch: 6| Step: 2
Training loss: 1.461578130722046
Validation loss: 2.1411699415535055

Epoch: 6| Step: 3
Training loss: 2.3426413536071777
Validation loss: 2.152869716767342

Epoch: 6| Step: 4
Training loss: 2.1435627937316895
Validation loss: 2.239457050959269

Epoch: 6| Step: 5
Training loss: 2.2642464637756348
Validation loss: 2.233790187425511

Epoch: 6| Step: 6
Training loss: 2.253152847290039
Validation loss: 2.1471522905493297

Epoch: 6| Step: 7
Training loss: 1.996478796005249
Validation loss: 2.134652224920129

Epoch: 6| Step: 8
Training loss: 1.8140569925308228
Validation loss: 2.235914909711448

Epoch: 6| Step: 9
Training loss: 1.8316800594329834
Validation loss: 2.1618328171391643

Epoch: 6| Step: 10
Training loss: 2.2904837131500244
Validation loss: 2.200676623211112

Epoch: 6| Step: 11
Training loss: 3.148028612136841
Validation loss: 2.19558193350351

Epoch: 6| Step: 12
Training loss: 2.2052950859069824
Validation loss: 2.242429612785257

Epoch: 6| Step: 13
Training loss: 2.551826000213623
Validation loss: 2.1717175335012455

Epoch: 118| Step: 0
Training loss: 1.3767225742340088
Validation loss: 2.2492311590461322

Epoch: 6| Step: 1
Training loss: 2.519709587097168
Validation loss: 2.2339903910954795

Epoch: 6| Step: 2
Training loss: 2.1179447174072266
Validation loss: 2.2537532211631857

Epoch: 6| Step: 3
Training loss: 1.8913726806640625
Validation loss: 2.196686342198362

Epoch: 6| Step: 4
Training loss: 2.8696751594543457
Validation loss: 2.1975205995703257

Epoch: 6| Step: 5
Training loss: 3.0030879974365234
Validation loss: 2.199080095496229

Epoch: 6| Step: 6
Training loss: 1.7733616828918457
Validation loss: 2.2353262106577554

Epoch: 6| Step: 7
Training loss: 2.2117908000946045
Validation loss: 2.181861919741477

Epoch: 6| Step: 8
Training loss: 1.8585689067840576
Validation loss: 2.1590202046978857

Epoch: 6| Step: 9
Training loss: 2.1839606761932373
Validation loss: 2.1942891715675272

Epoch: 6| Step: 10
Training loss: 2.351726531982422
Validation loss: 2.172288202470349

Epoch: 6| Step: 11
Training loss: 2.0242388248443604
Validation loss: 2.1915582174895913

Epoch: 6| Step: 12
Training loss: 1.3318076133728027
Validation loss: 2.1421813657206874

Epoch: 6| Step: 13
Training loss: 2.8241958618164062
Validation loss: 2.1530069176868727

Epoch: 119| Step: 0
Training loss: 2.8644070625305176
Validation loss: 2.222498596355479

Epoch: 6| Step: 1
Training loss: 1.9900436401367188
Validation loss: 2.274455711405764

Epoch: 6| Step: 2
Training loss: 2.1070103645324707
Validation loss: 2.1682034705274846

Epoch: 6| Step: 3
Training loss: 2.2138116359710693
Validation loss: 2.2979558360192085

Epoch: 6| Step: 4
Training loss: 2.021538257598877
Validation loss: 2.186368457732662

Epoch: 6| Step: 5
Training loss: 1.9538490772247314
Validation loss: 2.1799818828541744

Epoch: 6| Step: 6
Training loss: 1.9757314920425415
Validation loss: 2.261569594824186

Epoch: 6| Step: 7
Training loss: 2.430718421936035
Validation loss: 2.1992650954954085

Epoch: 6| Step: 8
Training loss: 1.9609768390655518
Validation loss: 2.2024460607959377

Epoch: 6| Step: 9
Training loss: 1.911581039428711
Validation loss: 2.164996093319308

Epoch: 6| Step: 10
Training loss: 2.3399882316589355
Validation loss: 2.132870760015262

Epoch: 6| Step: 11
Training loss: 2.050830602645874
Validation loss: 2.2123533256592287

Epoch: 6| Step: 12
Training loss: 2.285048484802246
Validation loss: 2.1381200513532086

Epoch: 6| Step: 13
Training loss: 2.549459218978882
Validation loss: 2.16021305002192

Epoch: 120| Step: 0
Training loss: 2.2993764877319336
Validation loss: 2.2654437685525544

Epoch: 6| Step: 1
Training loss: 1.7506821155548096
Validation loss: 2.0505258857562976

Epoch: 6| Step: 2
Training loss: 1.9014451503753662
Validation loss: 2.1546265925130537

Epoch: 6| Step: 3
Training loss: 2.640855312347412
Validation loss: 2.2186865473306305

Epoch: 6| Step: 4
Training loss: 2.556678295135498
Validation loss: 2.191995936055337

Epoch: 6| Step: 5
Training loss: 2.45591139793396
Validation loss: 2.1663381207373833

Epoch: 6| Step: 6
Training loss: 1.2939897775650024
Validation loss: 2.159391663407767

Epoch: 6| Step: 7
Training loss: 2.573554039001465
Validation loss: 2.2240833928508144

Epoch: 6| Step: 8
Training loss: 1.5657200813293457
Validation loss: 2.142179835227228

Epoch: 6| Step: 9
Training loss: 2.3218789100646973
Validation loss: 2.132602490404601

Epoch: 6| Step: 10
Training loss: 2.540012836456299
Validation loss: 2.2119901475086006

Epoch: 6| Step: 11
Training loss: 2.4331719875335693
Validation loss: 2.239639502699657

Epoch: 6| Step: 12
Training loss: 2.697686195373535
Validation loss: 2.218390344291605

Epoch: 6| Step: 13
Training loss: 2.37241268157959
Validation loss: 2.235754633462557

Epoch: 121| Step: 0
Training loss: 2.876978874206543
Validation loss: 2.1449114943063385

Epoch: 6| Step: 1
Training loss: 2.4781861305236816
Validation loss: 2.142709938428735

Epoch: 6| Step: 2
Training loss: 1.9276762008666992
Validation loss: 2.2191791457514607

Epoch: 6| Step: 3
Training loss: 1.4873011112213135
Validation loss: 2.1448039008725073

Epoch: 6| Step: 4
Training loss: 2.708151340484619
Validation loss: 2.2448227200456845

Epoch: 6| Step: 5
Training loss: 2.682474136352539
Validation loss: 2.2021578024792414

Epoch: 6| Step: 6
Training loss: 2.7939453125
Validation loss: 2.197650176222606

Epoch: 6| Step: 7
Training loss: 1.2244945764541626
Validation loss: 2.17862852158085

Epoch: 6| Step: 8
Training loss: 1.5223088264465332
Validation loss: 2.2034827868143716

Epoch: 6| Step: 9
Training loss: 2.8067617416381836
Validation loss: 2.2018823854384886

Epoch: 6| Step: 10
Training loss: 2.364713191986084
Validation loss: 2.1791214930113925

Epoch: 6| Step: 11
Training loss: 2.173344135284424
Validation loss: 2.168784934987304

Epoch: 6| Step: 12
Training loss: 2.2655882835388184
Validation loss: 2.1912449585494174

Epoch: 6| Step: 13
Training loss: 1.895590901374817
Validation loss: 2.2195515555720173

Epoch: 122| Step: 0
Training loss: 1.8537827730178833
Validation loss: 2.2255625622246855

Epoch: 6| Step: 1
Training loss: 2.657660484313965
Validation loss: 2.221266446575042

Epoch: 6| Step: 2
Training loss: 1.946537971496582
Validation loss: 2.228059084184708

Epoch: 6| Step: 3
Training loss: 2.9171268939971924
Validation loss: 2.2355344551865772

Epoch: 6| Step: 4
Training loss: 1.8728034496307373
Validation loss: 2.2043234045787523

Epoch: 6| Step: 5
Training loss: 2.1915199756622314
Validation loss: 2.17850580523091

Epoch: 6| Step: 6
Training loss: 2.036123514175415
Validation loss: 2.2487217674973192

Epoch: 6| Step: 7
Training loss: 2.5386857986450195
Validation loss: 2.152772170241161

Epoch: 6| Step: 8
Training loss: 2.2987747192382812
Validation loss: 2.1602153919076406

Epoch: 6| Step: 9
Training loss: 1.7939362525939941
Validation loss: 2.1733195217706824

Epoch: 6| Step: 10
Training loss: 2.0583062171936035
Validation loss: 2.0904072612844486

Epoch: 6| Step: 11
Training loss: 2.2974278926849365
Validation loss: 2.1628368080303235

Epoch: 6| Step: 12
Training loss: 2.185748815536499
Validation loss: 2.240523056317401

Epoch: 6| Step: 13
Training loss: 2.452225923538208
Validation loss: 2.150087146348851

Epoch: 123| Step: 0
Training loss: 2.4403076171875
Validation loss: 2.1452264888312227

Epoch: 6| Step: 1
Training loss: 2.4239799976348877
Validation loss: 2.217237200788272

Epoch: 6| Step: 2
Training loss: 1.8089301586151123
Validation loss: 2.16672848116967

Epoch: 6| Step: 3
Training loss: 2.372774362564087
Validation loss: 2.181755840137441

Epoch: 6| Step: 4
Training loss: 2.374459743499756
Validation loss: 2.1855847322812645

Epoch: 6| Step: 5
Training loss: 2.135420322418213
Validation loss: 2.188135454731603

Epoch: 6| Step: 6
Training loss: 2.1834540367126465
Validation loss: 2.2295991528418755

Epoch: 6| Step: 7
Training loss: 2.6358752250671387
Validation loss: 2.244857329194264

Epoch: 6| Step: 8
Training loss: 2.0603322982788086
Validation loss: 2.2107719054786106

Epoch: 6| Step: 9
Training loss: 2.376364231109619
Validation loss: 2.280814209292012

Epoch: 6| Step: 10
Training loss: 2.9918389320373535
Validation loss: 2.2453486688675417

Epoch: 6| Step: 11
Training loss: 1.0277286767959595
Validation loss: 2.246874242700556

Epoch: 6| Step: 12
Training loss: 1.6853042840957642
Validation loss: 2.2701554003582207

Epoch: 6| Step: 13
Training loss: 2.5822784900665283
Validation loss: 2.222963789457916

Epoch: 124| Step: 0
Training loss: 2.222874641418457
Validation loss: 2.3055488935080906

Epoch: 6| Step: 1
Training loss: 1.7937672138214111
Validation loss: 2.211513465450656

Epoch: 6| Step: 2
Training loss: 2.9574620723724365
Validation loss: 2.1312784712801696

Epoch: 6| Step: 3
Training loss: 3.0720021724700928
Validation loss: 2.2776621028941166

Epoch: 6| Step: 4
Training loss: 2.61649489402771
Validation loss: 2.233049267081804

Epoch: 6| Step: 5
Training loss: 2.193582534790039
Validation loss: 2.1667867117030646

Epoch: 6| Step: 6
Training loss: 2.129789113998413
Validation loss: 2.1400152150020806

Epoch: 6| Step: 7
Training loss: 2.3730430603027344
Validation loss: 2.214479692520634

Epoch: 6| Step: 8
Training loss: 2.1574482917785645
Validation loss: 2.3046263289707962

Epoch: 6| Step: 9
Training loss: 1.0881223678588867
Validation loss: 2.3011663985508743

Epoch: 6| Step: 10
Training loss: 1.4562206268310547
Validation loss: 2.2550735806906097

Epoch: 6| Step: 11
Training loss: 1.8923466205596924
Validation loss: 2.1827612333400275

Epoch: 6| Step: 12
Training loss: 2.0795559883117676
Validation loss: 2.164108266112625

Epoch: 6| Step: 13
Training loss: 2.551173686981201
Validation loss: 2.193846476975308

Epoch: 125| Step: 0
Training loss: 2.0019149780273438
Validation loss: 2.1892369460034113

Epoch: 6| Step: 1
Training loss: 2.366806983947754
Validation loss: 2.2482357589147424

Epoch: 6| Step: 2
Training loss: 2.4866063594818115
Validation loss: 2.1868683497111

Epoch: 6| Step: 3
Training loss: 2.287827491760254
Validation loss: 2.28368547654921

Epoch: 6| Step: 4
Training loss: 1.5475397109985352
Validation loss: 2.1790652672449746

Epoch: 6| Step: 5
Training loss: 2.506852626800537
Validation loss: 2.2113492719588743

Epoch: 6| Step: 6
Training loss: 1.710829257965088
Validation loss: 2.143479839448006

Epoch: 6| Step: 7
Training loss: 2.7205586433410645
Validation loss: 2.1639708319017963

Epoch: 6| Step: 8
Training loss: 1.763819694519043
Validation loss: 2.131014431676557

Epoch: 6| Step: 9
Training loss: 2.4883642196655273
Validation loss: 2.1159437407729444

Epoch: 6| Step: 10
Training loss: 2.476292133331299
Validation loss: 2.1181291226417787

Epoch: 6| Step: 11
Training loss: 1.7701194286346436
Validation loss: 2.164716487289757

Epoch: 6| Step: 12
Training loss: 1.6382397413253784
Validation loss: 2.2693716582431587

Epoch: 6| Step: 13
Training loss: 2.166163444519043
Validation loss: 2.195966857735829

Epoch: 126| Step: 0
Training loss: 1.8686859607696533
Validation loss: 2.262063668620202

Epoch: 6| Step: 1
Training loss: 2.471970558166504
Validation loss: 2.204754965279692

Epoch: 6| Step: 2
Training loss: 1.8732023239135742
Validation loss: 2.1897575086162937

Epoch: 6| Step: 3
Training loss: 2.1890869140625
Validation loss: 2.146049699475688

Epoch: 6| Step: 4
Training loss: 2.6641058921813965
Validation loss: 2.1848408009416316

Epoch: 6| Step: 5
Training loss: 1.8582159280776978
Validation loss: 2.1864536577655422

Epoch: 6| Step: 6
Training loss: 1.6078035831451416
Validation loss: 2.166938663810812

Epoch: 6| Step: 7
Training loss: 2.307739496231079
Validation loss: 2.1583646061599895

Epoch: 6| Step: 8
Training loss: 2.3952224254608154
Validation loss: 2.2132202066401

Epoch: 6| Step: 9
Training loss: 1.655462384223938
Validation loss: 2.222124748332526

Epoch: 6| Step: 10
Training loss: 1.9817609786987305
Validation loss: 2.152890659147693

Epoch: 6| Step: 11
Training loss: 2.37013840675354
Validation loss: 2.2418758356443016

Epoch: 6| Step: 12
Training loss: 2.15488600730896
Validation loss: 2.2003708513834144

Epoch: 6| Step: 13
Training loss: 3.2280445098876953
Validation loss: 2.153606645522579

Epoch: 127| Step: 0
Training loss: 2.241184949874878
Validation loss: 2.0557919522767425

Epoch: 6| Step: 1
Training loss: 2.1665754318237305
Validation loss: 2.1964506641510995

Epoch: 6| Step: 2
Training loss: 2.164175510406494
Validation loss: 2.190331002717377

Epoch: 6| Step: 3
Training loss: 1.5491889715194702
Validation loss: 2.1619363933481197

Epoch: 6| Step: 4
Training loss: 1.5669598579406738
Validation loss: 2.146839746864893

Epoch: 6| Step: 5
Training loss: 1.906924843788147
Validation loss: 2.1887854504328903

Epoch: 6| Step: 6
Training loss: 1.9026868343353271
Validation loss: 2.2391631962150655

Epoch: 6| Step: 7
Training loss: 2.636087417602539
Validation loss: 2.3662210177349787

Epoch: 6| Step: 8
Training loss: 1.943147897720337
Validation loss: 2.2856996905419136

Epoch: 6| Step: 9
Training loss: 1.9368534088134766
Validation loss: 2.3015680159291914

Epoch: 6| Step: 10
Training loss: 2.8350629806518555
Validation loss: 2.3415809010946624

Epoch: 6| Step: 11
Training loss: 2.301032543182373
Validation loss: 2.3187096247109036

Epoch: 6| Step: 12
Training loss: 3.201112747192383
Validation loss: 2.3029526587455504

Epoch: 6| Step: 13
Training loss: 2.6376969814300537
Validation loss: 2.3672273210299912

Epoch: 128| Step: 0
Training loss: 2.2183024883270264
Validation loss: 2.2342765843996437

Epoch: 6| Step: 1
Training loss: 2.18807315826416
Validation loss: 2.200611409320626

Epoch: 6| Step: 2
Training loss: 2.657778024673462
Validation loss: 2.2612959710500573

Epoch: 6| Step: 3
Training loss: 1.7605429887771606
Validation loss: 2.287408323698146

Epoch: 6| Step: 4
Training loss: 2.2205967903137207
Validation loss: 2.319512221121019

Epoch: 6| Step: 5
Training loss: 2.0218777656555176
Validation loss: 2.187420483558409

Epoch: 6| Step: 6
Training loss: 2.326387405395508
Validation loss: 2.185337528105705

Epoch: 6| Step: 7
Training loss: 3.1021711826324463
Validation loss: 2.1676045053748676

Epoch: 6| Step: 8
Training loss: 2.842055320739746
Validation loss: 2.228331983730357

Epoch: 6| Step: 9
Training loss: 2.340036153793335
Validation loss: 2.213013195222424

Epoch: 6| Step: 10
Training loss: 2.1679840087890625
Validation loss: 2.181689329044793

Epoch: 6| Step: 11
Training loss: 1.3780709505081177
Validation loss: 2.2256335417429605

Epoch: 6| Step: 12
Training loss: 2.4189014434814453
Validation loss: 2.1727427385186635

Epoch: 6| Step: 13
Training loss: 1.3415254354476929
Validation loss: 2.1963779464844735

Epoch: 129| Step: 0
Training loss: 2.0203847885131836
Validation loss: 2.1043464714480984

Epoch: 6| Step: 1
Training loss: 2.515702724456787
Validation loss: 2.2296498308899584

Epoch: 6| Step: 2
Training loss: 1.9096795320510864
Validation loss: 2.1882328038574546

Epoch: 6| Step: 3
Training loss: 2.1096272468566895
Validation loss: 2.2506518748498734

Epoch: 6| Step: 4
Training loss: 2.5051498413085938
Validation loss: 2.129763344282745

Epoch: 6| Step: 5
Training loss: 1.8669748306274414
Validation loss: 2.2282621809231338

Epoch: 6| Step: 6
Training loss: 1.7915794849395752
Validation loss: 2.242273125597226

Epoch: 6| Step: 7
Training loss: 2.015064239501953
Validation loss: 2.2131404953618206

Epoch: 6| Step: 8
Training loss: 2.92179536819458
Validation loss: 2.1598833889089604

Epoch: 6| Step: 9
Training loss: 1.8847904205322266
Validation loss: 2.2853926407393588

Epoch: 6| Step: 10
Training loss: 2.0369083881378174
Validation loss: 2.2234293978701354

Epoch: 6| Step: 11
Training loss: 1.9661953449249268
Validation loss: 2.229848974494524

Epoch: 6| Step: 12
Training loss: 2.9565906524658203
Validation loss: 2.1913352230543732

Epoch: 6| Step: 13
Training loss: 2.0270934104919434
Validation loss: 2.193436755928942

Epoch: 130| Step: 0
Training loss: 2.486262798309326
Validation loss: 2.1918869531282814

Epoch: 6| Step: 1
Training loss: 2.260408878326416
Validation loss: 2.151022944399106

Epoch: 6| Step: 2
Training loss: 1.9666006565093994
Validation loss: 2.142096801470685

Epoch: 6| Step: 3
Training loss: 2.273245334625244
Validation loss: 2.1641662813002065

Epoch: 6| Step: 4
Training loss: 1.450034737586975
Validation loss: 2.2354159637164046

Epoch: 6| Step: 5
Training loss: 1.5139179229736328
Validation loss: 2.222337999651509

Epoch: 6| Step: 6
Training loss: 1.9642784595489502
Validation loss: 2.2222449112963933

Epoch: 6| Step: 7
Training loss: 2.3834261894226074
Validation loss: 2.2162478303396576

Epoch: 6| Step: 8
Training loss: 2.570432662963867
Validation loss: 2.2184054108076197

Epoch: 6| Step: 9
Training loss: 2.0895440578460693
Validation loss: 2.135876073632189

Epoch: 6| Step: 10
Training loss: 2.4863405227661133
Validation loss: 2.1243610612807737

Epoch: 6| Step: 11
Training loss: 2.051008462905884
Validation loss: 2.2152906515265025

Epoch: 6| Step: 12
Training loss: 2.4357476234436035
Validation loss: 2.247565092579011

Epoch: 6| Step: 13
Training loss: 1.4534939527511597
Validation loss: 2.187432383978239

Epoch: 131| Step: 0
Training loss: 1.6371949911117554
Validation loss: 2.1419627499836746

Epoch: 6| Step: 1
Training loss: 2.6488828659057617
Validation loss: 2.1800367575819775

Epoch: 6| Step: 2
Training loss: 2.5553319454193115
Validation loss: 2.2309160642726447

Epoch: 6| Step: 3
Training loss: 2.0694868564605713
Validation loss: 2.3185437545981458

Epoch: 6| Step: 4
Training loss: 2.1803579330444336
Validation loss: 2.282407510665155

Epoch: 6| Step: 5
Training loss: 2.337641477584839
Validation loss: 2.1486665561635006

Epoch: 6| Step: 6
Training loss: 1.7961678504943848
Validation loss: 2.213495736481041

Epoch: 6| Step: 7
Training loss: 1.641417145729065
Validation loss: 2.178032680224347

Epoch: 6| Step: 8
Training loss: 2.3065590858459473
Validation loss: 2.2898223964116906

Epoch: 6| Step: 9
Training loss: 2.0336031913757324
Validation loss: 2.258296092351278

Epoch: 6| Step: 10
Training loss: 2.229412078857422
Validation loss: 2.146666298630417

Epoch: 6| Step: 11
Training loss: 1.9639813899993896
Validation loss: 2.3036251145024456

Epoch: 6| Step: 12
Training loss: 2.50787091255188
Validation loss: 2.282866035738299

Epoch: 6| Step: 13
Training loss: 2.773909568786621
Validation loss: 2.207421943705569

Epoch: 132| Step: 0
Training loss: 2.088228464126587
Validation loss: 2.24116615838902

Epoch: 6| Step: 1
Training loss: 2.5042638778686523
Validation loss: 2.211060808550927

Epoch: 6| Step: 2
Training loss: 1.9985480308532715
Validation loss: 2.264727315595073

Epoch: 6| Step: 3
Training loss: 2.2963356971740723
Validation loss: 2.1973041398550874

Epoch: 6| Step: 4
Training loss: 1.9250118732452393
Validation loss: 2.1974186871641423

Epoch: 6| Step: 5
Training loss: 1.9667320251464844
Validation loss: 2.2600896409762803

Epoch: 6| Step: 6
Training loss: 1.9094111919403076
Validation loss: 2.202497498963469

Epoch: 6| Step: 7
Training loss: 2.433553695678711
Validation loss: 2.129488100287735

Epoch: 6| Step: 8
Training loss: 2.1189961433410645
Validation loss: 2.1192454509837653

Epoch: 6| Step: 9
Training loss: 2.8580076694488525
Validation loss: 2.2206589701355144

Epoch: 6| Step: 10
Training loss: 2.1546127796173096
Validation loss: 2.186671751801686

Epoch: 6| Step: 11
Training loss: 2.3984994888305664
Validation loss: 2.16165933557736

Epoch: 6| Step: 12
Training loss: 2.0711889266967773
Validation loss: 2.1471857922051543

Epoch: 6| Step: 13
Training loss: 1.3048847913742065
Validation loss: 2.3065823842120428

Epoch: 133| Step: 0
Training loss: 2.8042492866516113
Validation loss: 2.268363409144904

Epoch: 6| Step: 1
Training loss: 2.347959280014038
Validation loss: 2.0736692079933743

Epoch: 6| Step: 2
Training loss: 2.412092924118042
Validation loss: 2.2045892361671693

Epoch: 6| Step: 3
Training loss: 2.231501579284668
Validation loss: 2.212930638303039

Epoch: 6| Step: 4
Training loss: 2.048041582107544
Validation loss: 2.1812733014424643

Epoch: 6| Step: 5
Training loss: 1.9480817317962646
Validation loss: 2.133224694959579

Epoch: 6| Step: 6
Training loss: 2.076315402984619
Validation loss: 2.2480312124375375

Epoch: 6| Step: 7
Training loss: 1.7922608852386475
Validation loss: 2.1773434044212423

Epoch: 6| Step: 8
Training loss: 2.197467088699341
Validation loss: 2.2492246499625583

Epoch: 6| Step: 9
Training loss: 2.4955358505249023
Validation loss: 2.128741189997683

Epoch: 6| Step: 10
Training loss: 2.2067766189575195
Validation loss: 2.1986478118486303

Epoch: 6| Step: 11
Training loss: 1.452254295349121
Validation loss: 2.1996495108450613

Epoch: 6| Step: 12
Training loss: 1.945225715637207
Validation loss: 2.25862479466264

Epoch: 6| Step: 13
Training loss: 2.9259634017944336
Validation loss: 2.1434370035766275

Epoch: 134| Step: 0
Training loss: 1.6287024021148682
Validation loss: 2.1295407190117785

Epoch: 6| Step: 1
Training loss: 1.4374148845672607
Validation loss: 2.2029380362520934

Epoch: 6| Step: 2
Training loss: 2.46514892578125
Validation loss: 2.247053271980696

Epoch: 6| Step: 3
Training loss: 1.6232432126998901
Validation loss: 2.2295366820468696

Epoch: 6| Step: 4
Training loss: 2.072139263153076
Validation loss: 2.3145498024520053

Epoch: 6| Step: 5
Training loss: 3.043593406677246
Validation loss: 2.215975325594666

Epoch: 6| Step: 6
Training loss: 1.9824111461639404
Validation loss: 2.240806628299016

Epoch: 6| Step: 7
Training loss: 2.3264646530151367
Validation loss: 2.2459825700329197

Epoch: 6| Step: 8
Training loss: 2.811147689819336
Validation loss: 2.193551008419324

Epoch: 6| Step: 9
Training loss: 2.10073184967041
Validation loss: 2.2952433093901603

Epoch: 6| Step: 10
Training loss: 1.5751054286956787
Validation loss: 2.2000702401643157

Epoch: 6| Step: 11
Training loss: 2.252321720123291
Validation loss: 2.2446898311697026

Epoch: 6| Step: 12
Training loss: 2.5776188373565674
Validation loss: 2.166905782556021

Epoch: 6| Step: 13
Training loss: 2.2442128658294678
Validation loss: 2.1923937156636226

Epoch: 135| Step: 0
Training loss: 2.5824568271636963
Validation loss: 2.2091282721488708

Epoch: 6| Step: 1
Training loss: 2.3918299674987793
Validation loss: 2.131424582132729

Epoch: 6| Step: 2
Training loss: 1.9867565631866455
Validation loss: 2.1655810007485012

Epoch: 6| Step: 3
Training loss: 2.32957124710083
Validation loss: 2.130547005643127

Epoch: 6| Step: 4
Training loss: 2.8849992752075195
Validation loss: 2.1467871794136624

Epoch: 6| Step: 5
Training loss: 1.9695886373519897
Validation loss: 2.100791423551498

Epoch: 6| Step: 6
Training loss: 1.908793568611145
Validation loss: 2.171555547304051

Epoch: 6| Step: 7
Training loss: 1.845497965812683
Validation loss: 2.159489475270753

Epoch: 6| Step: 8
Training loss: 1.9321659803390503
Validation loss: 2.2130295794497252

Epoch: 6| Step: 9
Training loss: 1.7656916379928589
Validation loss: 2.205585551518266

Epoch: 6| Step: 10
Training loss: 2.3777713775634766
Validation loss: 2.191744145526681

Epoch: 6| Step: 11
Training loss: 1.997113823890686
Validation loss: 2.1464943142347437

Epoch: 6| Step: 12
Training loss: 2.174769878387451
Validation loss: 2.1956817334698093

Epoch: 6| Step: 13
Training loss: 2.0783402919769287
Validation loss: 2.173990882853026

Epoch: 136| Step: 0
Training loss: 1.7360752820968628
Validation loss: 2.1919347727170555

Epoch: 6| Step: 1
Training loss: 2.5554447174072266
Validation loss: 2.1889491542693107

Epoch: 6| Step: 2
Training loss: 1.6990621089935303
Validation loss: 2.201890624979491

Epoch: 6| Step: 3
Training loss: 2.217418909072876
Validation loss: 2.175654647170856

Epoch: 6| Step: 4
Training loss: 1.922095775604248
Validation loss: 2.1225405995563795

Epoch: 6| Step: 5
Training loss: 2.404066562652588
Validation loss: 2.1143742607485865

Epoch: 6| Step: 6
Training loss: 2.388962984085083
Validation loss: 2.1478712302382275

Epoch: 6| Step: 7
Training loss: 2.09965443611145
Validation loss: 2.101905398471381

Epoch: 6| Step: 8
Training loss: 2.4079720973968506
Validation loss: 2.23712488912767

Epoch: 6| Step: 9
Training loss: 1.7616606950759888
Validation loss: 2.124076020333075

Epoch: 6| Step: 10
Training loss: 2.715805768966675
Validation loss: 2.1922385923324095

Epoch: 6| Step: 11
Training loss: 2.154221534729004
Validation loss: 2.2531523601983183

Epoch: 6| Step: 12
Training loss: 1.5791467428207397
Validation loss: 2.1362122925378944

Epoch: 6| Step: 13
Training loss: 2.024807929992676
Validation loss: 2.1563557988853863

Epoch: 137| Step: 0
Training loss: 1.6017370223999023
Validation loss: 2.2556817441858272

Epoch: 6| Step: 1
Training loss: 2.3740956783294678
Validation loss: 2.2508664233710176

Epoch: 6| Step: 2
Training loss: 2.294198989868164
Validation loss: 2.2605576335742907

Epoch: 6| Step: 3
Training loss: 2.085540533065796
Validation loss: 2.206301740420762

Epoch: 6| Step: 4
Training loss: 2.6548328399658203
Validation loss: 2.2526967551118586

Epoch: 6| Step: 5
Training loss: 1.9367868900299072
Validation loss: 2.2907836975589877

Epoch: 6| Step: 6
Training loss: 1.8213536739349365
Validation loss: 2.3754865405380086

Epoch: 6| Step: 7
Training loss: 2.282357692718506
Validation loss: 2.290620380832303

Epoch: 6| Step: 8
Training loss: 1.7127435207366943
Validation loss: 2.305192889705781

Epoch: 6| Step: 9
Training loss: 2.082766532897949
Validation loss: 2.2430492677996234

Epoch: 6| Step: 10
Training loss: 2.7058358192443848
Validation loss: 2.245700413180936

Epoch: 6| Step: 11
Training loss: 2.361811399459839
Validation loss: 2.1373307589561708

Epoch: 6| Step: 12
Training loss: 2.5244412422180176
Validation loss: 2.321563970658087

Epoch: 6| Step: 13
Training loss: 2.3813273906707764
Validation loss: 2.194425602113047

Epoch: 138| Step: 0
Training loss: 2.3667941093444824
Validation loss: 2.2027963425523494

Epoch: 6| Step: 1
Training loss: 2.1228113174438477
Validation loss: 2.222099822054627

Epoch: 6| Step: 2
Training loss: 2.6261844635009766
Validation loss: 2.27124777916939

Epoch: 6| Step: 3
Training loss: 2.7303617000579834
Validation loss: 2.148746675060641

Epoch: 6| Step: 4
Training loss: 2.1331565380096436
Validation loss: 2.161853610828359

Epoch: 6| Step: 5
Training loss: 1.5363962650299072
Validation loss: 2.1711887749292518

Epoch: 6| Step: 6
Training loss: 2.218667507171631
Validation loss: 2.1673533288381432

Epoch: 6| Step: 7
Training loss: 1.8352831602096558
Validation loss: 2.093848918073921

Epoch: 6| Step: 8
Training loss: 2.156005859375
Validation loss: 2.1680861467956216

Epoch: 6| Step: 9
Training loss: 1.380730390548706
Validation loss: 2.1701453962633686

Epoch: 6| Step: 10
Training loss: 1.9158334732055664
Validation loss: 2.1699747834154355

Epoch: 6| Step: 11
Training loss: 2.189793109893799
Validation loss: 2.245892483700988

Epoch: 6| Step: 12
Training loss: 2.801393985748291
Validation loss: 2.1858751286742506

Epoch: 6| Step: 13
Training loss: 2.4779934883117676
Validation loss: 2.133000176440003

Epoch: 139| Step: 0
Training loss: 2.1068739891052246
Validation loss: 2.1889812613046296

Epoch: 6| Step: 1
Training loss: 1.9285099506378174
Validation loss: 2.247236227476469

Epoch: 6| Step: 2
Training loss: 2.0656561851501465
Validation loss: 2.1464684829917005

Epoch: 6| Step: 3
Training loss: 1.7772743701934814
Validation loss: 2.2105683024211595

Epoch: 6| Step: 4
Training loss: 2.1460494995117188
Validation loss: 2.2039499129018476

Epoch: 6| Step: 5
Training loss: 2.0434694290161133
Validation loss: 2.144969936340086

Epoch: 6| Step: 6
Training loss: 2.52703857421875
Validation loss: 2.1844684513666297

Epoch: 6| Step: 7
Training loss: 2.0063793659210205
Validation loss: 2.201405429070996

Epoch: 6| Step: 8
Training loss: 3.4038591384887695
Validation loss: 2.1861099017563688

Epoch: 6| Step: 9
Training loss: 2.3082809448242188
Validation loss: 2.1747509510286394

Epoch: 6| Step: 10
Training loss: 1.7857121229171753
Validation loss: 2.1987600711084183

Epoch: 6| Step: 11
Training loss: 2.245898485183716
Validation loss: 2.286013210973432

Epoch: 6| Step: 12
Training loss: 2.1775295734405518
Validation loss: 2.1663573031784384

Epoch: 6| Step: 13
Training loss: 1.8281445503234863
Validation loss: 2.1426757035716886

Epoch: 140| Step: 0
Training loss: 2.2971885204315186
Validation loss: 2.093022036296065

Epoch: 6| Step: 1
Training loss: 1.8269355297088623
Validation loss: 2.2453899075908046

Epoch: 6| Step: 2
Training loss: 2.050428867340088
Validation loss: 2.159309789698611

Epoch: 6| Step: 3
Training loss: 1.7567198276519775
Validation loss: 2.253153839418965

Epoch: 6| Step: 4
Training loss: 2.6212964057922363
Validation loss: 2.2505694922580513

Epoch: 6| Step: 5
Training loss: 2.0604248046875
Validation loss: 2.100070274004372

Epoch: 6| Step: 6
Training loss: 1.0149372816085815
Validation loss: 2.2260145448869273

Epoch: 6| Step: 7
Training loss: 2.14346981048584
Validation loss: 2.1882726223238054

Epoch: 6| Step: 8
Training loss: 2.266178607940674
Validation loss: 2.26463919813915

Epoch: 6| Step: 9
Training loss: 2.641277313232422
Validation loss: 2.1941520065389652

Epoch: 6| Step: 10
Training loss: 3.018087863922119
Validation loss: 2.2266670452651156

Epoch: 6| Step: 11
Training loss: 1.9327726364135742
Validation loss: 2.0939945379892984

Epoch: 6| Step: 12
Training loss: 2.0171594619750977
Validation loss: 2.191450604828455

Epoch: 6| Step: 13
Training loss: 3.324943780899048
Validation loss: 2.232450464720367

Epoch: 141| Step: 0
Training loss: 2.345649242401123
Validation loss: 2.1434478400855936

Epoch: 6| Step: 1
Training loss: 2.066709518432617
Validation loss: 2.246874440100885

Epoch: 6| Step: 2
Training loss: 2.289783000946045
Validation loss: 2.2582049139084353

Epoch: 6| Step: 3
Training loss: 2.0941507816314697
Validation loss: 2.1400157636211765

Epoch: 6| Step: 4
Training loss: 1.9487810134887695
Validation loss: 2.2155140035895893

Epoch: 6| Step: 5
Training loss: 1.9866421222686768
Validation loss: 2.2180759855495986

Epoch: 6| Step: 6
Training loss: 2.7093474864959717
Validation loss: 2.205230479599327

Epoch: 6| Step: 7
Training loss: 1.3735078573226929
Validation loss: 2.299294751177552

Epoch: 6| Step: 8
Training loss: 1.5892661809921265
Validation loss: 2.239753359107561

Epoch: 6| Step: 9
Training loss: 2.396646022796631
Validation loss: 2.197141651184328

Epoch: 6| Step: 10
Training loss: 2.1036930084228516
Validation loss: 2.22998139678791

Epoch: 6| Step: 11
Training loss: 2.8323848247528076
Validation loss: 2.2503832206931165

Epoch: 6| Step: 12
Training loss: 1.894793152809143
Validation loss: 2.1458948196903354

Epoch: 6| Step: 13
Training loss: 2.2718396186828613
Validation loss: 2.265768499784572

Epoch: 142| Step: 0
Training loss: 1.6722512245178223
Validation loss: 2.1914337758095033

Epoch: 6| Step: 1
Training loss: 1.8941055536270142
Validation loss: 2.2611865638404764

Epoch: 6| Step: 2
Training loss: 2.059459924697876
Validation loss: 2.1946058811679965

Epoch: 6| Step: 3
Training loss: 2.583331346511841
Validation loss: 2.2586935066407725

Epoch: 6| Step: 4
Training loss: 1.6235318183898926
Validation loss: 2.147727781726468

Epoch: 6| Step: 5
Training loss: 2.3462579250335693
Validation loss: 2.234386808128767

Epoch: 6| Step: 6
Training loss: 1.9106101989746094
Validation loss: 2.1076850532203593

Epoch: 6| Step: 7
Training loss: 2.24715256690979
Validation loss: 2.1828541563403223

Epoch: 6| Step: 8
Training loss: 2.2691898345947266
Validation loss: 2.2107631955095517

Epoch: 6| Step: 9
Training loss: 2.4987006187438965
Validation loss: 2.160858472188314

Epoch: 6| Step: 10
Training loss: 2.208524227142334
Validation loss: 2.2219120302507953

Epoch: 6| Step: 11
Training loss: 2.2643282413482666
Validation loss: 2.1916318555032053

Epoch: 6| Step: 12
Training loss: 2.263127565383911
Validation loss: 2.1698102566503708

Epoch: 6| Step: 13
Training loss: 2.012647867202759
Validation loss: 2.1749721547608734

Epoch: 143| Step: 0
Training loss: 1.8985881805419922
Validation loss: 2.219782381929377

Epoch: 6| Step: 1
Training loss: 1.916090965270996
Validation loss: 2.190774348474318

Epoch: 6| Step: 2
Training loss: 2.5115838050842285
Validation loss: 2.1463574209520893

Epoch: 6| Step: 3
Training loss: 2.7289347648620605
Validation loss: 2.1768655110430974

Epoch: 6| Step: 4
Training loss: 1.9767348766326904
Validation loss: 2.0430387348257084

Epoch: 6| Step: 5
Training loss: 2.302781343460083
Validation loss: 2.208129309838818

Epoch: 6| Step: 6
Training loss: 2.2040019035339355
Validation loss: 2.1373071734623244

Epoch: 6| Step: 7
Training loss: 2.4442930221557617
Validation loss: 2.099663620354027

Epoch: 6| Step: 8
Training loss: 1.9732146263122559
Validation loss: 2.202720457507718

Epoch: 6| Step: 9
Training loss: 2.13604736328125
Validation loss: 2.0846347655019453

Epoch: 6| Step: 10
Training loss: 2.6724398136138916
Validation loss: 2.20340105025999

Epoch: 6| Step: 11
Training loss: 2.273736000061035
Validation loss: 2.232765551536314

Epoch: 6| Step: 12
Training loss: 2.0185766220092773
Validation loss: 2.175900992526803

Epoch: 6| Step: 13
Training loss: 1.5750797986984253
Validation loss: 2.2905285960884503

Epoch: 144| Step: 0
Training loss: 2.452843189239502
Validation loss: 2.2096396364191526

Epoch: 6| Step: 1
Training loss: 2.0929837226867676
Validation loss: 2.2581085030750563

Epoch: 6| Step: 2
Training loss: 2.0200979709625244
Validation loss: 2.235577044948455

Epoch: 6| Step: 3
Training loss: 1.6560640335083008
Validation loss: 2.1976166694395003

Epoch: 6| Step: 4
Training loss: 2.4034552574157715
Validation loss: 2.279858645572457

Epoch: 6| Step: 5
Training loss: 1.6658422946929932
Validation loss: 2.1116297450116885

Epoch: 6| Step: 6
Training loss: 1.6436681747436523
Validation loss: 2.201536778480776

Epoch: 6| Step: 7
Training loss: 2.13724684715271
Validation loss: 2.2019329404318206

Epoch: 6| Step: 8
Training loss: 2.088958263397217
Validation loss: 2.235924264436127

Epoch: 6| Step: 9
Training loss: 2.2487125396728516
Validation loss: 2.2691622254669026

Epoch: 6| Step: 10
Training loss: 2.235386371612549
Validation loss: 2.187346273852933

Epoch: 6| Step: 11
Training loss: 2.042098045349121
Validation loss: 2.2796100185763453

Epoch: 6| Step: 12
Training loss: 3.430650234222412
Validation loss: 2.256205528013168

Epoch: 6| Step: 13
Training loss: 2.26932954788208
Validation loss: 2.2278619735471663

Epoch: 145| Step: 0
Training loss: 2.2546534538269043
Validation loss: 2.20604286655303

Epoch: 6| Step: 1
Training loss: 2.032212257385254
Validation loss: 2.1911416130681194

Epoch: 6| Step: 2
Training loss: 1.9490090608596802
Validation loss: 2.1332403331674556

Epoch: 6| Step: 3
Training loss: 1.9669111967086792
Validation loss: 2.1326959748421945

Epoch: 6| Step: 4
Training loss: 2.772517442703247
Validation loss: 2.13410271111355

Epoch: 6| Step: 5
Training loss: 2.116187572479248
Validation loss: 2.190715164266607

Epoch: 6| Step: 6
Training loss: 2.2265758514404297
Validation loss: 2.130816457092121

Epoch: 6| Step: 7
Training loss: 2.5155277252197266
Validation loss: 2.105543336560649

Epoch: 6| Step: 8
Training loss: 1.6969013214111328
Validation loss: 2.103128203781702

Epoch: 6| Step: 9
Training loss: 1.7170023918151855
Validation loss: 2.1824499535304245

Epoch: 6| Step: 10
Training loss: 1.5528653860092163
Validation loss: 2.1350109602815364

Epoch: 6| Step: 11
Training loss: 2.1577131748199463
Validation loss: 2.1317721092572777

Epoch: 6| Step: 12
Training loss: 2.3375368118286133
Validation loss: 2.103395510745305

Epoch: 6| Step: 13
Training loss: 2.28728985786438
Validation loss: 2.127519726753235

Epoch: 146| Step: 0
Training loss: 1.8855252265930176
Validation loss: 2.2305630432662142

Epoch: 6| Step: 1
Training loss: 2.43447208404541
Validation loss: 2.1325499408988544

Epoch: 6| Step: 2
Training loss: 1.76957368850708
Validation loss: 2.1277484406707106

Epoch: 6| Step: 3
Training loss: 2.2471132278442383
Validation loss: 2.1735338754551385

Epoch: 6| Step: 4
Training loss: 1.7593860626220703
Validation loss: 2.1559276234719063

Epoch: 6| Step: 5
Training loss: 1.8352727890014648
Validation loss: 2.131299057314473

Epoch: 6| Step: 6
Training loss: 2.33384370803833
Validation loss: 2.1187995864499

Epoch: 6| Step: 7
Training loss: 2.0597519874572754
Validation loss: 2.2213861224471882

Epoch: 6| Step: 8
Training loss: 1.7385623455047607
Validation loss: 2.2270019541504564

Epoch: 6| Step: 9
Training loss: 2.2784316539764404
Validation loss: 2.1591199303186066

Epoch: 6| Step: 10
Training loss: 2.6633243560791016
Validation loss: 2.223006312565137

Epoch: 6| Step: 11
Training loss: 2.7479958534240723
Validation loss: 2.1580720563088693

Epoch: 6| Step: 12
Training loss: 2.3716866970062256
Validation loss: 2.2365884280973867

Epoch: 6| Step: 13
Training loss: 2.2193336486816406
Validation loss: 2.163933402748518

Epoch: 147| Step: 0
Training loss: 2.361586332321167
Validation loss: 2.2451111706354285

Epoch: 6| Step: 1
Training loss: 1.2546089887619019
Validation loss: 2.308678980796568

Epoch: 6| Step: 2
Training loss: 1.6103951930999756
Validation loss: 2.2283264539575063

Epoch: 6| Step: 3
Training loss: 2.040003776550293
Validation loss: 2.163044206557735

Epoch: 6| Step: 4
Training loss: 1.8513526916503906
Validation loss: 2.292001801152383

Epoch: 6| Step: 5
Training loss: 2.5431766510009766
Validation loss: 2.2486525684274654

Epoch: 6| Step: 6
Training loss: 2.705841541290283
Validation loss: 2.230058648253

Epoch: 6| Step: 7
Training loss: 2.4461278915405273
Validation loss: 2.273455407029839

Epoch: 6| Step: 8
Training loss: 1.5075023174285889
Validation loss: 2.2177325679409887

Epoch: 6| Step: 9
Training loss: 2.3915252685546875
Validation loss: 2.174392225921795

Epoch: 6| Step: 10
Training loss: 2.1322927474975586
Validation loss: 2.1489834811097834

Epoch: 6| Step: 11
Training loss: 2.8158955574035645
Validation loss: 2.2313478198102725

Epoch: 6| Step: 12
Training loss: 2.3314528465270996
Validation loss: 2.1197470439377653

Epoch: 6| Step: 13
Training loss: 2.495474100112915
Validation loss: 2.1472778704858597

Epoch: 148| Step: 0
Training loss: 2.2714695930480957
Validation loss: 2.2355001088111632

Epoch: 6| Step: 1
Training loss: 1.683777093887329
Validation loss: 2.2776468825596634

Epoch: 6| Step: 2
Training loss: 1.5548889636993408
Validation loss: 2.245717353718255

Epoch: 6| Step: 3
Training loss: 1.7955650091171265
Validation loss: 2.143734360253939

Epoch: 6| Step: 4
Training loss: 2.7304799556732178
Validation loss: 2.123149589825702

Epoch: 6| Step: 5
Training loss: 2.4952774047851562
Validation loss: 2.2045631177963747

Epoch: 6| Step: 6
Training loss: 2.4098434448242188
Validation loss: 2.266105108363654

Epoch: 6| Step: 7
Training loss: 2.799238443374634
Validation loss: 2.0830555961978052

Epoch: 6| Step: 8
Training loss: 2.131734848022461
Validation loss: 2.227557615567279

Epoch: 6| Step: 9
Training loss: 1.7849702835083008
Validation loss: 2.1790570084766676

Epoch: 6| Step: 10
Training loss: 2.205744743347168
Validation loss: 2.137737317751813

Epoch: 6| Step: 11
Training loss: 1.7639455795288086
Validation loss: 2.2863076553549817

Epoch: 6| Step: 12
Training loss: 2.245025157928467
Validation loss: 2.18962368401148

Epoch: 6| Step: 13
Training loss: 2.1964542865753174
Validation loss: 2.1902549830816125

Epoch: 149| Step: 0
Training loss: 2.0774548053741455
Validation loss: 2.266052338384813

Epoch: 6| Step: 1
Training loss: 2.283147096633911
Validation loss: 2.2178253204591813

Epoch: 6| Step: 2
Training loss: 2.2587409019470215
Validation loss: 2.2767422147976455

Epoch: 6| Step: 3
Training loss: 1.8749959468841553
Validation loss: 2.246784364023516

Epoch: 6| Step: 4
Training loss: 3.076143980026245
Validation loss: 2.174715365132978

Epoch: 6| Step: 5
Training loss: 1.4207067489624023
Validation loss: 2.2749486200271116

Epoch: 6| Step: 6
Training loss: 1.945256233215332
Validation loss: 2.173602839951874

Epoch: 6| Step: 7
Training loss: 2.0283565521240234
Validation loss: 2.1868853671576387

Epoch: 6| Step: 8
Training loss: 2.1446003913879395
Validation loss: 2.191744171163087

Epoch: 6| Step: 9
Training loss: 1.7731837034225464
Validation loss: 2.2162340507712415

Epoch: 6| Step: 10
Training loss: 2.116366386413574
Validation loss: 2.1017851932074434

Epoch: 6| Step: 11
Training loss: 2.2307238578796387
Validation loss: 2.1319901622751707

Epoch: 6| Step: 12
Training loss: 2.1063296794891357
Validation loss: 2.1765530340133177

Epoch: 6| Step: 13
Training loss: 2.4975481033325195
Validation loss: 2.190901198694783

Epoch: 150| Step: 0
Training loss: 2.068370819091797
Validation loss: 2.2169548106449906

Epoch: 6| Step: 1
Training loss: 2.3235459327697754
Validation loss: 2.2117547719709334

Epoch: 6| Step: 2
Training loss: 2.150125026702881
Validation loss: 2.236142612272693

Epoch: 6| Step: 3
Training loss: 1.875744104385376
Validation loss: 2.2774549427852837

Epoch: 6| Step: 4
Training loss: 2.6877036094665527
Validation loss: 2.196858148421011

Epoch: 6| Step: 5
Training loss: 2.5121278762817383
Validation loss: 2.215034451535953

Epoch: 6| Step: 6
Training loss: 1.8080055713653564
Validation loss: 2.2219747087006927

Epoch: 6| Step: 7
Training loss: 2.5610008239746094
Validation loss: 2.207404972404562

Epoch: 6| Step: 8
Training loss: 1.8183107376098633
Validation loss: 2.1289829797642206

Epoch: 6| Step: 9
Training loss: 2.1273045539855957
Validation loss: 2.1997457050508067

Epoch: 6| Step: 10
Training loss: 2.207487106323242
Validation loss: 2.1876898978346135

Epoch: 6| Step: 11
Training loss: 2.143089771270752
Validation loss: 2.179280819431428

Epoch: 6| Step: 12
Training loss: 1.8101294040679932
Validation loss: 2.1507673340459026

Epoch: 6| Step: 13
Training loss: 2.3915438652038574
Validation loss: 2.140076801341067

Epoch: 151| Step: 0
Training loss: 2.1073379516601562
Validation loss: 2.197155260270642

Epoch: 6| Step: 1
Training loss: 2.4637112617492676
Validation loss: 2.115794840679374

Epoch: 6| Step: 2
Training loss: 1.8923890590667725
Validation loss: 2.162385138132239

Epoch: 6| Step: 3
Training loss: 3.203094959259033
Validation loss: 2.233826709050004

Epoch: 6| Step: 4
Training loss: 1.8997211456298828
Validation loss: 2.2189027596545476

Epoch: 6| Step: 5
Training loss: 2.674778938293457
Validation loss: 2.249590964727504

Epoch: 6| Step: 6
Training loss: 1.9654687643051147
Validation loss: 2.2249611757134877

Epoch: 6| Step: 7
Training loss: 2.557502508163452
Validation loss: 2.196941739769392

Epoch: 6| Step: 8
Training loss: 1.7684683799743652
Validation loss: 2.2204758762031473

Epoch: 6| Step: 9
Training loss: 1.5435245037078857
Validation loss: 2.1639255067353607

Epoch: 6| Step: 10
Training loss: 1.2087533473968506
Validation loss: 2.0680471902252524

Epoch: 6| Step: 11
Training loss: 2.0861265659332275
Validation loss: 2.142287726043373

Epoch: 6| Step: 12
Training loss: 2.2951245307922363
Validation loss: 2.1431549133793

Epoch: 6| Step: 13
Training loss: 3.075270414352417
Validation loss: 2.0973098444682297

Epoch: 152| Step: 0
Training loss: 2.241105079650879
Validation loss: 2.1721524807714645

Epoch: 6| Step: 1
Training loss: 1.9589166641235352
Validation loss: 2.205382800871326

Epoch: 6| Step: 2
Training loss: 2.0738580226898193
Validation loss: 2.1683222991164013

Epoch: 6| Step: 3
Training loss: 2.440016746520996
Validation loss: 2.218667055970879

Epoch: 6| Step: 4
Training loss: 2.9988760948181152
Validation loss: 2.0833084570464266

Epoch: 6| Step: 5
Training loss: 2.35908842086792
Validation loss: 2.0965286916302097

Epoch: 6| Step: 6
Training loss: 2.62784481048584
Validation loss: 2.168486988672646

Epoch: 6| Step: 7
Training loss: 2.1601061820983887
Validation loss: 2.137250743886476

Epoch: 6| Step: 8
Training loss: 1.5264811515808105
Validation loss: 2.132124852108699

Epoch: 6| Step: 9
Training loss: 1.6651450395584106
Validation loss: 2.254328094502931

Epoch: 6| Step: 10
Training loss: 2.3811838626861572
Validation loss: 2.196457252707533

Epoch: 6| Step: 11
Training loss: 1.3389394283294678
Validation loss: 2.1772828948113228

Epoch: 6| Step: 12
Training loss: 2.1152002811431885
Validation loss: 2.226697241106341

Epoch: 6| Step: 13
Training loss: 2.2979917526245117
Validation loss: 2.196348892745151

Epoch: 153| Step: 0
Training loss: 1.977232575416565
Validation loss: 2.2897984904627644

Epoch: 6| Step: 1
Training loss: 2.02718186378479
Validation loss: 2.2686883172681256

Epoch: 6| Step: 2
Training loss: 1.6420652866363525
Validation loss: 2.1509469093814975

Epoch: 6| Step: 3
Training loss: 1.8821144104003906
Validation loss: 2.2775055541787097

Epoch: 6| Step: 4
Training loss: 2.068606376647949
Validation loss: 2.262102852585495

Epoch: 6| Step: 5
Training loss: 2.156428098678589
Validation loss: 2.174729798429756

Epoch: 6| Step: 6
Training loss: 2.014298915863037
Validation loss: 2.216832673677834

Epoch: 6| Step: 7
Training loss: 1.9815635681152344
Validation loss: 2.179672766757268

Epoch: 6| Step: 8
Training loss: 2.4299588203430176
Validation loss: 2.161449711809876

Epoch: 6| Step: 9
Training loss: 1.8667865991592407
Validation loss: 2.202010408524544

Epoch: 6| Step: 10
Training loss: 2.848710775375366
Validation loss: 2.1421471206090783

Epoch: 6| Step: 11
Training loss: 2.1197242736816406
Validation loss: 2.1917981845076366

Epoch: 6| Step: 12
Training loss: 2.863457202911377
Validation loss: 2.161012404708452

Epoch: 6| Step: 13
Training loss: 2.857469081878662
Validation loss: 2.1340275964429303

Epoch: 154| Step: 0
Training loss: 2.1860909461975098
Validation loss: 2.1434433050053094

Epoch: 6| Step: 1
Training loss: 2.0009372234344482
Validation loss: 2.224283682402744

Epoch: 6| Step: 2
Training loss: 1.874692678451538
Validation loss: 2.1882136201345794

Epoch: 6| Step: 3
Training loss: 1.8135108947753906
Validation loss: 2.107206554823024

Epoch: 6| Step: 4
Training loss: 2.1657211780548096
Validation loss: 2.1499530256435437

Epoch: 6| Step: 5
Training loss: 2.3991599082946777
Validation loss: 2.118314343114053

Epoch: 6| Step: 6
Training loss: 2.815854549407959
Validation loss: 2.143840712885703

Epoch: 6| Step: 7
Training loss: 2.2212259769439697
Validation loss: 2.256537514348184

Epoch: 6| Step: 8
Training loss: 1.954162836074829
Validation loss: 2.1053022235952397

Epoch: 6| Step: 9
Training loss: 2.276865243911743
Validation loss: 2.128204144457335

Epoch: 6| Step: 10
Training loss: 2.0947232246398926
Validation loss: 2.221376734395181

Epoch: 6| Step: 11
Training loss: 1.6942427158355713
Validation loss: 2.2494330021642868

Epoch: 6| Step: 12
Training loss: 2.600236415863037
Validation loss: 2.087559078329353

Epoch: 6| Step: 13
Training loss: 2.641767978668213
Validation loss: 2.1910081166093067

Epoch: 155| Step: 0
Training loss: 2.617485523223877
Validation loss: 2.137926088866367

Epoch: 6| Step: 1
Training loss: 2.058307647705078
Validation loss: 2.1352929504968787

Epoch: 6| Step: 2
Training loss: 2.048981189727783
Validation loss: 2.153000004829899

Epoch: 6| Step: 3
Training loss: 2.4224236011505127
Validation loss: 2.1611534574980378

Epoch: 6| Step: 4
Training loss: 2.4195704460144043
Validation loss: 2.206287476324266

Epoch: 6| Step: 5
Training loss: 2.01597261428833
Validation loss: 2.2507084223531906

Epoch: 6| Step: 6
Training loss: 1.7514431476593018
Validation loss: 2.2028839139528174

Epoch: 6| Step: 7
Training loss: 2.2061901092529297
Validation loss: 2.2096896094660603

Epoch: 6| Step: 8
Training loss: 2.2509145736694336
Validation loss: 2.330071251879456

Epoch: 6| Step: 9
Training loss: 2.3388209342956543
Validation loss: 2.1876101006743727

Epoch: 6| Step: 10
Training loss: 1.9906028509140015
Validation loss: 2.2391855319341025

Epoch: 6| Step: 11
Training loss: 2.127821922302246
Validation loss: 2.206529417345601

Epoch: 6| Step: 12
Training loss: 1.9634541273117065
Validation loss: 2.2274681265636156

Epoch: 6| Step: 13
Training loss: 1.7718920707702637
Validation loss: 2.2524495624726817

Epoch: 156| Step: 0
Training loss: 2.554969310760498
Validation loss: 2.163597560697986

Epoch: 6| Step: 1
Training loss: 1.799422025680542
Validation loss: 2.1432214526719946

Epoch: 6| Step: 2
Training loss: 1.9574483633041382
Validation loss: 2.2736649333789782

Epoch: 6| Step: 3
Training loss: 2.2550461292266846
Validation loss: 2.1418784331249934

Epoch: 6| Step: 4
Training loss: 2.040693759918213
Validation loss: 2.208638004077378

Epoch: 6| Step: 5
Training loss: 1.8825503587722778
Validation loss: 2.2265469438286236

Epoch: 6| Step: 6
Training loss: 1.8786513805389404
Validation loss: 2.26606733311889

Epoch: 6| Step: 7
Training loss: 2.604351043701172
Validation loss: 2.2042240788859706

Epoch: 6| Step: 8
Training loss: 1.7576221227645874
Validation loss: 2.234734107089299

Epoch: 6| Step: 9
Training loss: 2.527247428894043
Validation loss: 2.2054189764043337

Epoch: 6| Step: 10
Training loss: 1.8722100257873535
Validation loss: 2.1913406566907

Epoch: 6| Step: 11
Training loss: 1.647956371307373
Validation loss: 2.225486373388639

Epoch: 6| Step: 12
Training loss: 2.6143789291381836
Validation loss: 2.1890353964221094

Epoch: 6| Step: 13
Training loss: 2.19181489944458
Validation loss: 2.1620179812113443

Epoch: 157| Step: 0
Training loss: 1.4695451259613037
Validation loss: 2.1490000704283356

Epoch: 6| Step: 1
Training loss: 1.5078449249267578
Validation loss: 2.1304873804892264

Epoch: 6| Step: 2
Training loss: 2.1170849800109863
Validation loss: 2.1957117229379635

Epoch: 6| Step: 3
Training loss: 2.629575729370117
Validation loss: 2.1340344669998332

Epoch: 6| Step: 4
Training loss: 2.635986804962158
Validation loss: 2.2264019673870457

Epoch: 6| Step: 5
Training loss: 1.786110281944275
Validation loss: 2.199112634504995

Epoch: 6| Step: 6
Training loss: 1.8538514375686646
Validation loss: 2.167817496484326

Epoch: 6| Step: 7
Training loss: 2.2376151084899902
Validation loss: 2.1065632938056864

Epoch: 6| Step: 8
Training loss: 2.3875789642333984
Validation loss: 2.1366817412837857

Epoch: 6| Step: 9
Training loss: 2.326404094696045
Validation loss: 2.205553226573493

Epoch: 6| Step: 10
Training loss: 2.044991970062256
Validation loss: 2.1669010731481735

Epoch: 6| Step: 11
Training loss: 2.105837345123291
Validation loss: 2.2008121603278705

Epoch: 6| Step: 12
Training loss: 2.8579154014587402
Validation loss: 2.2086843521364274

Epoch: 6| Step: 13
Training loss: 2.272474765777588
Validation loss: 2.1305358538063626

Epoch: 158| Step: 0
Training loss: 2.2466259002685547
Validation loss: 2.158014092394101

Epoch: 6| Step: 1
Training loss: 2.5925703048706055
Validation loss: 2.124277312268493

Epoch: 6| Step: 2
Training loss: 2.0575685501098633
Validation loss: 2.212455743102617

Epoch: 6| Step: 3
Training loss: 1.3996412754058838
Validation loss: 2.1793417289692867

Epoch: 6| Step: 4
Training loss: 2.9026360511779785
Validation loss: 2.167990258944932

Epoch: 6| Step: 5
Training loss: 2.050145149230957
Validation loss: 2.143097815975066

Epoch: 6| Step: 6
Training loss: 1.6543537378311157
Validation loss: 2.2139929392004527

Epoch: 6| Step: 7
Training loss: 2.1824910640716553
Validation loss: 2.2007877390871764

Epoch: 6| Step: 8
Training loss: 2.1150898933410645
Validation loss: 2.1839361062613865

Epoch: 6| Step: 9
Training loss: 1.3956828117370605
Validation loss: 2.218627074713348

Epoch: 6| Step: 10
Training loss: 3.156531810760498
Validation loss: 2.2389975645208873

Epoch: 6| Step: 11
Training loss: 1.8293166160583496
Validation loss: 2.2297894980317805

Epoch: 6| Step: 12
Training loss: 2.361783027648926
Validation loss: 2.112662151295652

Epoch: 6| Step: 13
Training loss: 1.9368975162506104
Validation loss: 2.221368048780708

Epoch: 159| Step: 0
Training loss: 1.8460283279418945
Validation loss: 2.2961355281132523

Epoch: 6| Step: 1
Training loss: 2.5078413486480713
Validation loss: 2.3083807294086744

Epoch: 6| Step: 2
Training loss: 2.5396735668182373
Validation loss: 2.212052395266871

Epoch: 6| Step: 3
Training loss: 2.2586684226989746
Validation loss: 2.2005891697381132

Epoch: 6| Step: 4
Training loss: 2.5816092491149902
Validation loss: 2.185772736867269

Epoch: 6| Step: 5
Training loss: 1.8244704008102417
Validation loss: 2.174732037769851

Epoch: 6| Step: 6
Training loss: 2.189645528793335
Validation loss: 2.1586050961607244

Epoch: 6| Step: 7
Training loss: 2.228421926498413
Validation loss: 2.290340592784266

Epoch: 6| Step: 8
Training loss: 2.1297497749328613
Validation loss: 2.1399239532409178

Epoch: 6| Step: 9
Training loss: 1.665236234664917
Validation loss: 2.264374779116723

Epoch: 6| Step: 10
Training loss: 2.007643222808838
Validation loss: 2.127696939693984

Epoch: 6| Step: 11
Training loss: 2.236142873764038
Validation loss: 2.132511547816697

Epoch: 6| Step: 12
Training loss: 1.2919297218322754
Validation loss: 2.124475963654057

Epoch: 6| Step: 13
Training loss: 2.4020144939422607
Validation loss: 2.1834422747294107

Epoch: 160| Step: 0
Training loss: 2.0840699672698975
Validation loss: 2.2346045996553157

Epoch: 6| Step: 1
Training loss: 1.7729406356811523
Validation loss: 2.1498119882358018

Epoch: 6| Step: 2
Training loss: 1.7216882705688477
Validation loss: 2.189693171490905

Epoch: 6| Step: 3
Training loss: 2.113713026046753
Validation loss: 2.1416499768534014

Epoch: 6| Step: 4
Training loss: 2.5458571910858154
Validation loss: 2.1743435013678765

Epoch: 6| Step: 5
Training loss: 2.2989439964294434
Validation loss: 2.1716847676102833

Epoch: 6| Step: 6
Training loss: 2.2113683223724365
Validation loss: 2.215044198497649

Epoch: 6| Step: 7
Training loss: 1.7516298294067383
Validation loss: 2.25092311059275

Epoch: 6| Step: 8
Training loss: 1.6515727043151855
Validation loss: 2.2355744659259753

Epoch: 6| Step: 9
Training loss: 2.085637331008911
Validation loss: 2.170934948869931

Epoch: 6| Step: 10
Training loss: 1.4085392951965332
Validation loss: 2.228908708018641

Epoch: 6| Step: 11
Training loss: 2.1444177627563477
Validation loss: 2.2085114243210002

Epoch: 6| Step: 12
Training loss: 2.7413086891174316
Validation loss: 2.1621121078409176

Epoch: 6| Step: 13
Training loss: 2.9216086864471436
Validation loss: 2.3225929326908563

Epoch: 161| Step: 0
Training loss: 1.9903106689453125
Validation loss: 2.1148527578641008

Epoch: 6| Step: 1
Training loss: 2.5619688034057617
Validation loss: 2.1611492172364266

Epoch: 6| Step: 2
Training loss: 2.0891213417053223
Validation loss: 2.163298422290433

Epoch: 6| Step: 3
Training loss: 2.478022575378418
Validation loss: 2.190585256904684

Epoch: 6| Step: 4
Training loss: 2.3284225463867188
Validation loss: 2.2405391098350607

Epoch: 6| Step: 5
Training loss: 2.395659923553467
Validation loss: 2.2676636249788347

Epoch: 6| Step: 6
Training loss: 2.4620580673217773
Validation loss: 2.1411130889769523

Epoch: 6| Step: 7
Training loss: 1.3601503372192383
Validation loss: 2.245580127162318

Epoch: 6| Step: 8
Training loss: 1.5796767473220825
Validation loss: 2.1514535693712133

Epoch: 6| Step: 9
Training loss: 1.45222008228302
Validation loss: 2.137750166718678

Epoch: 6| Step: 10
Training loss: 2.0624337196350098
Validation loss: 2.1058011618993615

Epoch: 6| Step: 11
Training loss: 3.072493076324463
Validation loss: 2.1938033808944044

Epoch: 6| Step: 12
Training loss: 2.286616325378418
Validation loss: 2.1833017154406478

Epoch: 6| Step: 13
Training loss: 2.041867971420288
Validation loss: 2.205379378411078

Epoch: 162| Step: 0
Training loss: 1.98997962474823
Validation loss: 2.170009346418483

Epoch: 6| Step: 1
Training loss: 1.7131354808807373
Validation loss: 2.12123098937414

Epoch: 6| Step: 2
Training loss: 2.797700881958008
Validation loss: 2.231292170862998

Epoch: 6| Step: 3
Training loss: 1.9576818943023682
Validation loss: 2.1765043581685712

Epoch: 6| Step: 4
Training loss: 2.440420150756836
Validation loss: 2.1639888235317764

Epoch: 6| Step: 5
Training loss: 2.3010857105255127
Validation loss: 2.2287555074179046

Epoch: 6| Step: 6
Training loss: 1.509857416152954
Validation loss: 2.250867792355117

Epoch: 6| Step: 7
Training loss: 1.8827866315841675
Validation loss: 2.223464342855638

Epoch: 6| Step: 8
Training loss: 2.0993223190307617
Validation loss: 2.2366161269526326

Epoch: 6| Step: 9
Training loss: 2.324428081512451
Validation loss: 2.2510624008793987

Epoch: 6| Step: 10
Training loss: 2.091414451599121
Validation loss: 2.198228277185912

Epoch: 6| Step: 11
Training loss: 1.4647955894470215
Validation loss: 2.2820923559127317

Epoch: 6| Step: 12
Training loss: 2.6863975524902344
Validation loss: 2.1765243443109656

Epoch: 6| Step: 13
Training loss: 2.0520524978637695
Validation loss: 2.234259415698308

Epoch: 163| Step: 0
Training loss: 2.336292266845703
Validation loss: 2.269940282708855

Epoch: 6| Step: 1
Training loss: 2.1640307903289795
Validation loss: 2.1608223094735095

Epoch: 6| Step: 2
Training loss: 2.2282018661499023
Validation loss: 2.21980179766173

Epoch: 6| Step: 3
Training loss: 1.8007243871688843
Validation loss: 2.226321844644444

Epoch: 6| Step: 4
Training loss: 1.4713923931121826
Validation loss: 2.2204348912803074

Epoch: 6| Step: 5
Training loss: 2.4948363304138184
Validation loss: 2.2531212376010035

Epoch: 6| Step: 6
Training loss: 2.6621978282928467
Validation loss: 2.2229219354609007

Epoch: 6| Step: 7
Training loss: 2.543565511703491
Validation loss: 2.3004292288134174

Epoch: 6| Step: 8
Training loss: 1.9675283432006836
Validation loss: 2.1115396484251945

Epoch: 6| Step: 9
Training loss: 2.5694878101348877
Validation loss: 2.2109148322895007

Epoch: 6| Step: 10
Training loss: 2.1570701599121094
Validation loss: 2.2073909697994107

Epoch: 6| Step: 11
Training loss: 1.3753929138183594
Validation loss: 2.201078978917932

Epoch: 6| Step: 12
Training loss: 2.199097156524658
Validation loss: 2.132276263288272

Epoch: 6| Step: 13
Training loss: 2.095602035522461
Validation loss: 2.15830478360576

Epoch: 164| Step: 0
Training loss: 2.3202881813049316
Validation loss: 2.2362364979200464

Epoch: 6| Step: 1
Training loss: 2.5155694484710693
Validation loss: 2.230713786617402

Epoch: 6| Step: 2
Training loss: 2.238948106765747
Validation loss: 2.2731457474411174

Epoch: 6| Step: 3
Training loss: 2.1928930282592773
Validation loss: 2.2233644480346353

Epoch: 6| Step: 4
Training loss: 2.7675840854644775
Validation loss: 2.2287757268515964

Epoch: 6| Step: 5
Training loss: 2.3722615242004395
Validation loss: 2.263422414820681

Epoch: 6| Step: 6
Training loss: 2.49790096282959
Validation loss: 2.245860884266515

Epoch: 6| Step: 7
Training loss: 1.9204764366149902
Validation loss: 2.1815968944180395

Epoch: 6| Step: 8
Training loss: 1.8204387426376343
Validation loss: 2.1951972694807154

Epoch: 6| Step: 9
Training loss: 1.6664059162139893
Validation loss: 2.2881290322990826

Epoch: 6| Step: 10
Training loss: 1.684356451034546
Validation loss: 2.2215822383921635

Epoch: 6| Step: 11
Training loss: 1.7908964157104492
Validation loss: 2.2318401439215547

Epoch: 6| Step: 12
Training loss: 1.7398144006729126
Validation loss: 2.1836337889394453

Epoch: 6| Step: 13
Training loss: 1.2956229448318481
Validation loss: 2.216245226962592

Epoch: 165| Step: 0
Training loss: 1.8676137924194336
Validation loss: 2.18184466644

Epoch: 6| Step: 1
Training loss: 2.323507785797119
Validation loss: 2.214398932713334

Epoch: 6| Step: 2
Training loss: 2.4185681343078613
Validation loss: 2.28197846874114

Epoch: 6| Step: 3
Training loss: 3.0051169395446777
Validation loss: 2.198710395443824

Epoch: 6| Step: 4
Training loss: 2.3887758255004883
Validation loss: 2.234886820598315

Epoch: 6| Step: 5
Training loss: 2.336920738220215
Validation loss: 2.2269645839609127

Epoch: 6| Step: 6
Training loss: 2.1505818367004395
Validation loss: 2.0963924495122765

Epoch: 6| Step: 7
Training loss: 2.583889961242676
Validation loss: 2.0982315681313954

Epoch: 6| Step: 8
Training loss: 1.3319940567016602
Validation loss: 2.242098327605955

Epoch: 6| Step: 9
Training loss: 1.7434077262878418
Validation loss: 2.1519638748579126

Epoch: 6| Step: 10
Training loss: 2.4708900451660156
Validation loss: 2.1086076741577475

Epoch: 6| Step: 11
Training loss: 1.6258933544158936
Validation loss: 2.156285435922684

Epoch: 6| Step: 12
Training loss: 1.6794871091842651
Validation loss: 2.231523136938772

Epoch: 6| Step: 13
Training loss: 2.624908685684204
Validation loss: 2.1913274026686147

Epoch: 166| Step: 0
Training loss: 2.6940388679504395
Validation loss: 2.172217720298357

Epoch: 6| Step: 1
Training loss: 2.163144588470459
Validation loss: 2.2057314982978244

Epoch: 6| Step: 2
Training loss: 1.810522198677063
Validation loss: 2.2657380680884085

Epoch: 6| Step: 3
Training loss: 2.875629425048828
Validation loss: 2.205957906220549

Epoch: 6| Step: 4
Training loss: 2.158686876296997
Validation loss: 2.155208779919532

Epoch: 6| Step: 5
Training loss: 2.371708631515503
Validation loss: 2.1393939756578013

Epoch: 6| Step: 6
Training loss: 2.4554243087768555
Validation loss: 2.2309568056496243

Epoch: 6| Step: 7
Training loss: 2.121096134185791
Validation loss: 2.261451159754107

Epoch: 6| Step: 8
Training loss: 1.5239282846450806
Validation loss: 2.2632665877701132

Epoch: 6| Step: 9
Training loss: 2.230198383331299
Validation loss: 2.1612362323268766

Epoch: 6| Step: 10
Training loss: 1.7223119735717773
Validation loss: 2.206570508659527

Epoch: 6| Step: 11
Training loss: 2.1682872772216797
Validation loss: 2.286036173502604

Epoch: 6| Step: 12
Training loss: 1.3881651163101196
Validation loss: 2.286133514937534

Epoch: 6| Step: 13
Training loss: 2.0544168949127197
Validation loss: 2.1740113663417038

Epoch: 167| Step: 0
Training loss: 1.7914760112762451
Validation loss: 2.2509775520652853

Epoch: 6| Step: 1
Training loss: 2.414957284927368
Validation loss: 2.0967919723961943

Epoch: 6| Step: 2
Training loss: 3.3310937881469727
Validation loss: 2.3032689735453618

Epoch: 6| Step: 3
Training loss: 2.359710693359375
Validation loss: 2.1590872451823246

Epoch: 6| Step: 4
Training loss: 1.7354438304901123
Validation loss: 2.2235518065831994

Epoch: 6| Step: 5
Training loss: 1.7745903730392456
Validation loss: 2.2310513142616517

Epoch: 6| Step: 6
Training loss: 2.4733357429504395
Validation loss: 2.1064391430988105

Epoch: 6| Step: 7
Training loss: 1.3323423862457275
Validation loss: 2.1282060018149753

Epoch: 6| Step: 8
Training loss: 2.0212130546569824
Validation loss: 2.1826233248556814

Epoch: 6| Step: 9
Training loss: 2.569561004638672
Validation loss: 2.2223182673095376

Epoch: 6| Step: 10
Training loss: 2.0339136123657227
Validation loss: 2.1362509765932636

Epoch: 6| Step: 11
Training loss: 2.030534505844116
Validation loss: 2.1865205636588474

Epoch: 6| Step: 12
Training loss: 1.4692068099975586
Validation loss: 2.194800917820264

Epoch: 6| Step: 13
Training loss: 2.512441396713257
Validation loss: 2.18401865677167

Epoch: 168| Step: 0
Training loss: 1.8056504726409912
Validation loss: 2.2222755224474016

Epoch: 6| Step: 1
Training loss: 1.8933995962142944
Validation loss: 2.1800570308521228

Epoch: 6| Step: 2
Training loss: 1.9742426872253418
Validation loss: 2.182167168586485

Epoch: 6| Step: 3
Training loss: 1.866061806678772
Validation loss: 2.211168466075774

Epoch: 6| Step: 4
Training loss: 1.940637230873108
Validation loss: 2.2342560047744424

Epoch: 6| Step: 5
Training loss: 2.7197606563568115
Validation loss: 2.201828954040363

Epoch: 6| Step: 6
Training loss: 2.6014692783355713
Validation loss: 2.183692083563856

Epoch: 6| Step: 7
Training loss: 1.9739006757736206
Validation loss: 2.2054300769682853

Epoch: 6| Step: 8
Training loss: 1.9287867546081543
Validation loss: 2.1274071021746566

Epoch: 6| Step: 9
Training loss: 2.32311749458313
Validation loss: 2.1945888509032545

Epoch: 6| Step: 10
Training loss: 1.544628620147705
Validation loss: 2.1769575329237085

Epoch: 6| Step: 11
Training loss: 2.2645187377929688
Validation loss: 2.181794827984225

Epoch: 6| Step: 12
Training loss: 2.8303329944610596
Validation loss: 2.1799313560608895

Epoch: 6| Step: 13
Training loss: 1.1225571632385254
Validation loss: 2.164952069200495

Epoch: 169| Step: 0
Training loss: 2.4520554542541504
Validation loss: 2.043829523107057

Epoch: 6| Step: 1
Training loss: 2.1517727375030518
Validation loss: 2.161211202221532

Epoch: 6| Step: 2
Training loss: 2.2041120529174805
Validation loss: 2.198306780989452

Epoch: 6| Step: 3
Training loss: 1.9063360691070557
Validation loss: 2.246887424940704

Epoch: 6| Step: 4
Training loss: 2.0757663249969482
Validation loss: 2.2042695450526413

Epoch: 6| Step: 5
Training loss: 2.1729133129119873
Validation loss: 2.1587466578329764

Epoch: 6| Step: 6
Training loss: 2.017732620239258
Validation loss: 2.204536214951546

Epoch: 6| Step: 7
Training loss: 2.404947280883789
Validation loss: 2.2329220182152203

Epoch: 6| Step: 8
Training loss: 2.3822710514068604
Validation loss: 2.1663273585739957

Epoch: 6| Step: 9
Training loss: 2.0396904945373535
Validation loss: 2.1386373017423894

Epoch: 6| Step: 10
Training loss: 1.5662375688552856
Validation loss: 2.2033635570156958

Epoch: 6| Step: 11
Training loss: 2.4170451164245605
Validation loss: 2.159663715670186

Epoch: 6| Step: 12
Training loss: 1.816750168800354
Validation loss: 2.120923608861944

Epoch: 6| Step: 13
Training loss: 2.171943187713623
Validation loss: 2.166795135826193

Epoch: 170| Step: 0
Training loss: 1.5456125736236572
Validation loss: 2.2635290930348058

Epoch: 6| Step: 1
Training loss: 1.9480164051055908
Validation loss: 2.1518040395552114

Epoch: 6| Step: 2
Training loss: 2.2324252128601074
Validation loss: 2.2016490441496654

Epoch: 6| Step: 3
Training loss: 1.9890801906585693
Validation loss: 2.0802905918449484

Epoch: 6| Step: 4
Training loss: 2.9272565841674805
Validation loss: 2.1554180524682485

Epoch: 6| Step: 5
Training loss: 1.787660837173462
Validation loss: 2.0949559134821736

Epoch: 6| Step: 6
Training loss: 1.6846014261245728
Validation loss: 2.2034060942229403

Epoch: 6| Step: 7
Training loss: 2.389878749847412
Validation loss: 2.18381203246373

Epoch: 6| Step: 8
Training loss: 2.2286734580993652
Validation loss: 2.2478362027034966

Epoch: 6| Step: 9
Training loss: 1.9025332927703857
Validation loss: 2.1703947410788587

Epoch: 6| Step: 10
Training loss: 1.8640451431274414
Validation loss: 2.1378450291131132

Epoch: 6| Step: 11
Training loss: 2.079760789871216
Validation loss: 2.143793172733758

Epoch: 6| Step: 12
Training loss: 2.198929786682129
Validation loss: 2.1871347837550665

Epoch: 6| Step: 13
Training loss: 3.451329469680786
Validation loss: 2.1765130078920754

Epoch: 171| Step: 0
Training loss: 1.5337836742401123
Validation loss: 2.1245990491682485

Epoch: 6| Step: 1
Training loss: 2.1649398803710938
Validation loss: 2.2527389885276876

Epoch: 6| Step: 2
Training loss: 1.4538981914520264
Validation loss: 2.13478914383919

Epoch: 6| Step: 3
Training loss: 1.967475414276123
Validation loss: 2.220205742825744

Epoch: 6| Step: 4
Training loss: 1.869215965270996
Validation loss: 2.1461878181785665

Epoch: 6| Step: 5
Training loss: 1.692519187927246
Validation loss: 2.2489919585566365

Epoch: 6| Step: 6
Training loss: 2.0293996334075928
Validation loss: 2.245045477344144

Epoch: 6| Step: 7
Training loss: 1.5919456481933594
Validation loss: 2.148443696319416

Epoch: 6| Step: 8
Training loss: 3.0242159366607666
Validation loss: 2.2066449913927304

Epoch: 6| Step: 9
Training loss: 2.3186142444610596
Validation loss: 2.187291314524989

Epoch: 6| Step: 10
Training loss: 2.189772605895996
Validation loss: 2.191186048651254

Epoch: 6| Step: 11
Training loss: 2.521812915802002
Validation loss: 2.0763096988842054

Epoch: 6| Step: 12
Training loss: 2.4482336044311523
Validation loss: 2.1290137921610186

Epoch: 6| Step: 13
Training loss: 2.185991048812866
Validation loss: 2.209658803478364

Epoch: 172| Step: 0
Training loss: 1.6867526769638062
Validation loss: 2.22978126746352

Epoch: 6| Step: 1
Training loss: 1.899012565612793
Validation loss: 2.1686882934262677

Epoch: 6| Step: 2
Training loss: 1.6610698699951172
Validation loss: 2.0709005337889477

Epoch: 6| Step: 3
Training loss: 2.423427104949951
Validation loss: 2.2434510620691444

Epoch: 6| Step: 4
Training loss: 2.3300018310546875
Validation loss: 2.2247729186088807

Epoch: 6| Step: 5
Training loss: 1.7029802799224854
Validation loss: 2.1214459429505053

Epoch: 6| Step: 6
Training loss: 2.247612714767456
Validation loss: 2.158125123670024

Epoch: 6| Step: 7
Training loss: 2.1921017169952393
Validation loss: 2.150034140515071

Epoch: 6| Step: 8
Training loss: 1.8358221054077148
Validation loss: 2.1198107350257134

Epoch: 6| Step: 9
Training loss: 2.610358476638794
Validation loss: 2.263513885518556

Epoch: 6| Step: 10
Training loss: 2.7273380756378174
Validation loss: 2.186785392863776

Epoch: 6| Step: 11
Training loss: 2.3320956230163574
Validation loss: 2.2730375541153776

Epoch: 6| Step: 12
Training loss: 1.8371275663375854
Validation loss: 2.1678285573118474

Epoch: 6| Step: 13
Training loss: 1.792442798614502
Validation loss: 2.2071589987765075

Epoch: 173| Step: 0
Training loss: 2.1867032051086426
Validation loss: 2.2005467568674395

Epoch: 6| Step: 1
Training loss: 2.427502155303955
Validation loss: 2.3201637985885784

Epoch: 6| Step: 2
Training loss: 2.021829843521118
Validation loss: 2.219741552106796

Epoch: 6| Step: 3
Training loss: 2.473206043243408
Validation loss: 2.1988147868905017

Epoch: 6| Step: 4
Training loss: 2.331144094467163
Validation loss: 2.218955680888186

Epoch: 6| Step: 5
Training loss: 1.6852521896362305
Validation loss: 2.226397816852857

Epoch: 6| Step: 6
Training loss: 2.429562568664551
Validation loss: 2.174103557422597

Epoch: 6| Step: 7
Training loss: 1.365707516670227
Validation loss: 2.2797172582277687

Epoch: 6| Step: 8
Training loss: 1.7945189476013184
Validation loss: 2.117089497145786

Epoch: 6| Step: 9
Training loss: 2.1160824298858643
Validation loss: 2.225188393746653

Epoch: 6| Step: 10
Training loss: 2.441042423248291
Validation loss: 2.150250768148771

Epoch: 6| Step: 11
Training loss: 2.4059228897094727
Validation loss: 2.1379757581218595

Epoch: 6| Step: 12
Training loss: 2.018923282623291
Validation loss: 2.188073694065053

Epoch: 6| Step: 13
Training loss: 2.2174556255340576
Validation loss: 2.176087241018972

Epoch: 174| Step: 0
Training loss: 2.5309369564056396
Validation loss: 2.2199525294765348

Epoch: 6| Step: 1
Training loss: 1.900383472442627
Validation loss: 2.223174569427326

Epoch: 6| Step: 2
Training loss: 2.3157548904418945
Validation loss: 2.1527823017489527

Epoch: 6| Step: 3
Training loss: 1.8830275535583496
Validation loss: 2.2330272120814167

Epoch: 6| Step: 4
Training loss: 1.9768353700637817
Validation loss: 2.140523733631257

Epoch: 6| Step: 5
Training loss: 2.7849249839782715
Validation loss: 2.135604673816312

Epoch: 6| Step: 6
Training loss: 2.3299288749694824
Validation loss: 2.097379308874889

Epoch: 6| Step: 7
Training loss: 2.2984368801116943
Validation loss: 2.252585190598683

Epoch: 6| Step: 8
Training loss: 1.8689192533493042
Validation loss: 2.167546274841473

Epoch: 6| Step: 9
Training loss: 1.8235441446304321
Validation loss: 2.2112951983687696

Epoch: 6| Step: 10
Training loss: 1.4747769832611084
Validation loss: 2.110363769274886

Epoch: 6| Step: 11
Training loss: 2.274716854095459
Validation loss: 2.2029067547090593

Epoch: 6| Step: 12
Training loss: 2.2841339111328125
Validation loss: 2.199690116349087

Epoch: 6| Step: 13
Training loss: 2.375990867614746
Validation loss: 2.1910691876565256

Epoch: 175| Step: 0
Training loss: 2.3800792694091797
Validation loss: 2.160216393009309

Epoch: 6| Step: 1
Training loss: 2.8505160808563232
Validation loss: 2.152753819701492

Epoch: 6| Step: 2
Training loss: 1.700463056564331
Validation loss: 2.1702639607972998

Epoch: 6| Step: 3
Training loss: 2.170316696166992
Validation loss: 2.2296943920914845

Epoch: 6| Step: 4
Training loss: 2.6341328620910645
Validation loss: 2.1489287512276762

Epoch: 6| Step: 5
Training loss: 2.0568294525146484
Validation loss: 2.192624489466349

Epoch: 6| Step: 6
Training loss: 1.6395117044448853
Validation loss: 2.1042313960290726

Epoch: 6| Step: 7
Training loss: 2.385244846343994
Validation loss: 2.1504209913233274

Epoch: 6| Step: 8
Training loss: 1.1935710906982422
Validation loss: 2.180441371856197

Epoch: 6| Step: 9
Training loss: 1.8014264106750488
Validation loss: 2.16835113750991

Epoch: 6| Step: 10
Training loss: 2.5587692260742188
Validation loss: 2.2333904966231315

Epoch: 6| Step: 11
Training loss: 2.6282598972320557
Validation loss: 2.1726499552367837

Epoch: 6| Step: 12
Training loss: 2.1711697578430176
Validation loss: 2.1576029075089322

Epoch: 6| Step: 13
Training loss: 1.085656762123108
Validation loss: 2.227841523385817

Epoch: 176| Step: 0
Training loss: 1.9747388362884521
Validation loss: 2.2143617445422756

Epoch: 6| Step: 1
Training loss: 1.415492296218872
Validation loss: 2.1624453247234388

Epoch: 6| Step: 2
Training loss: 1.7261548042297363
Validation loss: 2.1593198955699964

Epoch: 6| Step: 3
Training loss: 2.200953483581543
Validation loss: 2.1687530638069235

Epoch: 6| Step: 4
Training loss: 1.4309096336364746
Validation loss: 2.244609837890953

Epoch: 6| Step: 5
Training loss: 2.305020332336426
Validation loss: 2.1574229309635777

Epoch: 6| Step: 6
Training loss: 2.1546754837036133
Validation loss: 2.1784182799759733

Epoch: 6| Step: 7
Training loss: 1.8672637939453125
Validation loss: 2.102955333648189

Epoch: 6| Step: 8
Training loss: 2.347116470336914
Validation loss: 2.1906223540665

Epoch: 6| Step: 9
Training loss: 2.338137626647949
Validation loss: 2.148016632244151

Epoch: 6| Step: 10
Training loss: 2.6792802810668945
Validation loss: 2.0865164649101997

Epoch: 6| Step: 11
Training loss: 2.6529102325439453
Validation loss: 2.171195376303888

Epoch: 6| Step: 12
Training loss: 2.469606876373291
Validation loss: 2.1469782629320697

Epoch: 6| Step: 13
Training loss: 1.186780571937561
Validation loss: 2.1996490968170987

Epoch: 177| Step: 0
Training loss: 2.456571578979492
Validation loss: 2.203225719031467

Epoch: 6| Step: 1
Training loss: 1.6655632257461548
Validation loss: 2.1143971784140474

Epoch: 6| Step: 2
Training loss: 1.9924845695495605
Validation loss: 2.1131734373748943

Epoch: 6| Step: 3
Training loss: 1.6512318849563599
Validation loss: 2.181836769145022

Epoch: 6| Step: 4
Training loss: 2.200118064880371
Validation loss: 2.1651089986165366

Epoch: 6| Step: 5
Training loss: 1.9085516929626465
Validation loss: 2.2729110704955233

Epoch: 6| Step: 6
Training loss: 2.501284122467041
Validation loss: 2.19699998312099

Epoch: 6| Step: 7
Training loss: 2.586669921875
Validation loss: 2.249257174871301

Epoch: 6| Step: 8
Training loss: 2.3528571128845215
Validation loss: 2.25199693505482

Epoch: 6| Step: 9
Training loss: 2.1005425453186035
Validation loss: 2.238859699618432

Epoch: 6| Step: 10
Training loss: 1.9262322187423706
Validation loss: 2.222039320135629

Epoch: 6| Step: 11
Training loss: 1.9122862815856934
Validation loss: 2.2226839091188166

Epoch: 6| Step: 12
Training loss: 1.653181791305542
Validation loss: 2.232579126152941

Epoch: 6| Step: 13
Training loss: 2.1699724197387695
Validation loss: 2.146462253344956

Epoch: 178| Step: 0
Training loss: 2.401303291320801
Validation loss: 2.229279825764318

Epoch: 6| Step: 1
Training loss: 2.0703978538513184
Validation loss: 2.242741815505489

Epoch: 6| Step: 2
Training loss: 1.9318301677703857
Validation loss: 2.200987326201572

Epoch: 6| Step: 3
Training loss: 2.486079216003418
Validation loss: 2.171989684463829

Epoch: 6| Step: 4
Training loss: 2.1346538066864014
Validation loss: 2.2360266434249056

Epoch: 6| Step: 5
Training loss: 1.0554344654083252
Validation loss: 2.19642839765036

Epoch: 6| Step: 6
Training loss: 2.172926902770996
Validation loss: 2.156565844371755

Epoch: 6| Step: 7
Training loss: 1.7502281665802002
Validation loss: 2.164359579804123

Epoch: 6| Step: 8
Training loss: 1.9718990325927734
Validation loss: 2.225344363079276

Epoch: 6| Step: 9
Training loss: 2.574357748031616
Validation loss: 2.165657233166438

Epoch: 6| Step: 10
Training loss: 2.041109085083008
Validation loss: 2.1381598595649964

Epoch: 6| Step: 11
Training loss: 2.6453185081481934
Validation loss: 2.2385343069671304

Epoch: 6| Step: 12
Training loss: 2.2725887298583984
Validation loss: 2.2039093868706816

Epoch: 6| Step: 13
Training loss: 1.3235816955566406
Validation loss: 2.1908382446535173

Epoch: 179| Step: 0
Training loss: 2.300746440887451
Validation loss: 2.2138868275509087

Epoch: 6| Step: 1
Training loss: 2.5311217308044434
Validation loss: 2.1627179576504614

Epoch: 6| Step: 2
Training loss: 1.8582104444503784
Validation loss: 2.1880155327499553

Epoch: 6| Step: 3
Training loss: 1.7673463821411133
Validation loss: 2.153523511784051

Epoch: 6| Step: 4
Training loss: 1.7178373336791992
Validation loss: 2.0923189168335288

Epoch: 6| Step: 5
Training loss: 2.519883155822754
Validation loss: 2.162342515043033

Epoch: 6| Step: 6
Training loss: 2.877086639404297
Validation loss: 2.210624251314389

Epoch: 6| Step: 7
Training loss: 1.867948055267334
Validation loss: 2.1215913629019134

Epoch: 6| Step: 8
Training loss: 2.5641136169433594
Validation loss: 2.2649645600267636

Epoch: 6| Step: 9
Training loss: 1.9212896823883057
Validation loss: 2.2218166987101235

Epoch: 6| Step: 10
Training loss: 1.6230332851409912
Validation loss: 2.1172376589108537

Epoch: 6| Step: 11
Training loss: 2.117260217666626
Validation loss: 2.149065629128487

Epoch: 6| Step: 12
Training loss: 1.822084903717041
Validation loss: 2.0920249108345277

Epoch: 6| Step: 13
Training loss: 2.00405216217041
Validation loss: 2.174448593970268

Epoch: 180| Step: 0
Training loss: 1.8992633819580078
Validation loss: 2.207213906831639

Epoch: 6| Step: 1
Training loss: 1.5173726081848145
Validation loss: 2.247656645313386

Epoch: 6| Step: 2
Training loss: 2.452939987182617
Validation loss: 2.1225210376965102

Epoch: 6| Step: 3
Training loss: 2.0284512042999268
Validation loss: 2.232042989423198

Epoch: 6| Step: 4
Training loss: 1.5837962627410889
Validation loss: 2.2146685123443604

Epoch: 6| Step: 5
Training loss: 2.5273096561431885
Validation loss: 2.1241336945564515

Epoch: 6| Step: 6
Training loss: 2.057173252105713
Validation loss: 2.1063137567171486

Epoch: 6| Step: 7
Training loss: 3.333045482635498
Validation loss: 2.1704180676450013

Epoch: 6| Step: 8
Training loss: 2.224841594696045
Validation loss: 2.2787165385420605

Epoch: 6| Step: 9
Training loss: 2.2242112159729004
Validation loss: 2.2147606418978785

Epoch: 6| Step: 10
Training loss: 1.5535361766815186
Validation loss: 2.1502586974892566

Epoch: 6| Step: 11
Training loss: 1.662107229232788
Validation loss: 2.264815230523386

Epoch: 6| Step: 12
Training loss: 1.7119078636169434
Validation loss: 2.2482284320298063

Epoch: 6| Step: 13
Training loss: 2.1344332695007324
Validation loss: 2.175910980470719

Epoch: 181| Step: 0
Training loss: 1.7777819633483887
Validation loss: 2.2160835689113987

Epoch: 6| Step: 1
Training loss: 2.2668185234069824
Validation loss: 2.253935521648776

Epoch: 6| Step: 2
Training loss: 1.987683892250061
Validation loss: 2.163549683427298

Epoch: 6| Step: 3
Training loss: 2.5289745330810547
Validation loss: 2.2351277310361146

Epoch: 6| Step: 4
Training loss: 2.0066096782684326
Validation loss: 2.2019576616184686

Epoch: 6| Step: 5
Training loss: 1.8123812675476074
Validation loss: 2.2843425273895264

Epoch: 6| Step: 6
Training loss: 1.9125531911849976
Validation loss: 2.247368181905439

Epoch: 6| Step: 7
Training loss: 2.228708505630493
Validation loss: 2.2590145757121425

Epoch: 6| Step: 8
Training loss: 2.347031593322754
Validation loss: 2.309214484307074

Epoch: 6| Step: 9
Training loss: 2.3718533515930176
Validation loss: 2.178697188695272

Epoch: 6| Step: 10
Training loss: 1.3150560855865479
Validation loss: 2.245540372786983

Epoch: 6| Step: 11
Training loss: 1.9914642572402954
Validation loss: 2.1548933226575135

Epoch: 6| Step: 12
Training loss: 1.9272948503494263
Validation loss: 2.2769176985627864

Epoch: 6| Step: 13
Training loss: 2.0935678482055664
Validation loss: 2.2164195993895173

Epoch: 182| Step: 0
Training loss: 2.6160848140716553
Validation loss: 2.1585412076724473

Epoch: 6| Step: 1
Training loss: 2.8453168869018555
Validation loss: 2.152627368127146

Epoch: 6| Step: 2
Training loss: 2.0802040100097656
Validation loss: 2.1148934723228536

Epoch: 6| Step: 3
Training loss: 1.8535091876983643
Validation loss: 2.139558192222349

Epoch: 6| Step: 4
Training loss: 1.7662179470062256
Validation loss: 2.155375815206958

Epoch: 6| Step: 5
Training loss: 2.224970817565918
Validation loss: 2.219213437008601

Epoch: 6| Step: 6
Training loss: 1.744363784790039
Validation loss: 2.183659371509347

Epoch: 6| Step: 7
Training loss: 1.8366460800170898
Validation loss: 2.2024276794925814

Epoch: 6| Step: 8
Training loss: 1.6949429512023926
Validation loss: 2.227540986512297

Epoch: 6| Step: 9
Training loss: 1.2895516157150269
Validation loss: 2.1607559496356594

Epoch: 6| Step: 10
Training loss: 1.6502280235290527
Validation loss: 2.1563677557053103

Epoch: 6| Step: 11
Training loss: 2.33001708984375
Validation loss: 2.0692615150123514

Epoch: 6| Step: 12
Training loss: 1.7635382413864136
Validation loss: 2.1524923052839053

Epoch: 6| Step: 13
Training loss: 3.291964054107666
Validation loss: 2.181611248241958

Epoch: 183| Step: 0
Training loss: 1.468770146369934
Validation loss: 2.1543784705541467

Epoch: 6| Step: 1
Training loss: 2.232424259185791
Validation loss: 2.1155399917274393

Epoch: 6| Step: 2
Training loss: 1.8859835863113403
Validation loss: 2.1139792396176245

Epoch: 6| Step: 3
Training loss: 2.035057544708252
Validation loss: 2.1048115966140584

Epoch: 6| Step: 4
Training loss: 2.0807595252990723
Validation loss: 2.1509889594970213

Epoch: 6| Step: 5
Training loss: 2.4790337085723877
Validation loss: 2.240643068026471

Epoch: 6| Step: 6
Training loss: 2.4638853073120117
Validation loss: 2.1824751054086993

Epoch: 6| Step: 7
Training loss: 2.4343013763427734
Validation loss: 2.226939626919326

Epoch: 6| Step: 8
Training loss: 2.2932333946228027
Validation loss: 2.275060228122178

Epoch: 6| Step: 9
Training loss: 2.1751527786254883
Validation loss: 2.235557028042373

Epoch: 6| Step: 10
Training loss: 1.9021790027618408
Validation loss: 2.267395891169066

Epoch: 6| Step: 11
Training loss: 2.231287717819214
Validation loss: 2.273397368769492

Epoch: 6| Step: 12
Training loss: 1.6347286701202393
Validation loss: 2.1886129199817614

Epoch: 6| Step: 13
Training loss: 1.3996254205703735
Validation loss: 2.1537423877305883

Epoch: 184| Step: 0
Training loss: 2.248328924179077
Validation loss: 2.270942085532732

Epoch: 6| Step: 1
Training loss: 2.4113247394561768
Validation loss: 2.190446748528429

Epoch: 6| Step: 2
Training loss: 2.6587584018707275
Validation loss: 2.111397490706495

Epoch: 6| Step: 3
Training loss: 1.9094469547271729
Validation loss: 2.1327328810127835

Epoch: 6| Step: 4
Training loss: 1.9737690687179565
Validation loss: 2.1992083390553794

Epoch: 6| Step: 5
Training loss: 2.7045834064483643
Validation loss: 2.189189475069764

Epoch: 6| Step: 6
Training loss: 1.9174355268478394
Validation loss: 2.1567006867419005

Epoch: 6| Step: 7
Training loss: 1.453816294670105
Validation loss: 2.153147223175213

Epoch: 6| Step: 8
Training loss: 1.5624022483825684
Validation loss: 2.281420862802895

Epoch: 6| Step: 9
Training loss: 2.2039098739624023
Validation loss: 2.1527970324280443

Epoch: 6| Step: 10
Training loss: 2.3378450870513916
Validation loss: 2.0984489430663404

Epoch: 6| Step: 11
Training loss: 1.6892814636230469
Validation loss: 2.1776740358721827

Epoch: 6| Step: 12
Training loss: 2.080918073654175
Validation loss: 2.1861030875995593

Epoch: 6| Step: 13
Training loss: 2.6103734970092773
Validation loss: 2.2525901409887497

Epoch: 185| Step: 0
Training loss: 2.243868350982666
Validation loss: 2.1868392767444735

Epoch: 6| Step: 1
Training loss: 2.115234136581421
Validation loss: 2.271937113936229

Epoch: 6| Step: 2
Training loss: 2.1301493644714355
Validation loss: 2.212899154232394

Epoch: 6| Step: 3
Training loss: 2.3730170726776123
Validation loss: 2.1818094714995353

Epoch: 6| Step: 4
Training loss: 1.7361925840377808
Validation loss: 2.2449075188688052

Epoch: 6| Step: 5
Training loss: 2.0796210765838623
Validation loss: 2.2326425839495916

Epoch: 6| Step: 6
Training loss: 2.027824878692627
Validation loss: 2.1705181214117233

Epoch: 6| Step: 7
Training loss: 2.3870537281036377
Validation loss: 2.25481257900115

Epoch: 6| Step: 8
Training loss: 2.054314136505127
Validation loss: 2.225739061191518

Epoch: 6| Step: 9
Training loss: 2.0540051460266113
Validation loss: 2.1873160818571686

Epoch: 6| Step: 10
Training loss: 1.6500608921051025
Validation loss: 2.2276622761962233

Epoch: 6| Step: 11
Training loss: 2.026926040649414
Validation loss: 2.222175928854173

Epoch: 6| Step: 12
Training loss: 1.98823881149292
Validation loss: 2.1679993098781956

Epoch: 6| Step: 13
Training loss: 2.931105852127075
Validation loss: 2.155985175922353

Epoch: 186| Step: 0
Training loss: 1.6960830688476562
Validation loss: 2.1636803278359036

Epoch: 6| Step: 1
Training loss: 1.814650297164917
Validation loss: 2.1823753720970562

Epoch: 6| Step: 2
Training loss: 2.2595396041870117
Validation loss: 2.1811759253983856

Epoch: 6| Step: 3
Training loss: 1.4701162576675415
Validation loss: 2.183892839698381

Epoch: 6| Step: 4
Training loss: 2.4828248023986816
Validation loss: 2.1444603012454126

Epoch: 6| Step: 5
Training loss: 2.0851144790649414
Validation loss: 2.1529610746650287

Epoch: 6| Step: 6
Training loss: 1.8635900020599365
Validation loss: 2.218430616522348

Epoch: 6| Step: 7
Training loss: 2.088365077972412
Validation loss: 2.2202288796824794

Epoch: 6| Step: 8
Training loss: 2.589496374130249
Validation loss: 2.1848630648787304

Epoch: 6| Step: 9
Training loss: 2.1173648834228516
Validation loss: 2.220766698160479

Epoch: 6| Step: 10
Training loss: 2.4994518756866455
Validation loss: 2.1639606516848326

Epoch: 6| Step: 11
Training loss: 1.7939975261688232
Validation loss: 2.1054576853270173

Epoch: 6| Step: 12
Training loss: 2.2588274478912354
Validation loss: 2.195570122811102

Epoch: 6| Step: 13
Training loss: 1.8719736337661743
Validation loss: 2.141131067788729

Epoch: 187| Step: 0
Training loss: 2.269132614135742
Validation loss: 2.1574607074901624

Epoch: 6| Step: 1
Training loss: 2.166316270828247
Validation loss: 2.195248652529973

Epoch: 6| Step: 2
Training loss: 2.026900291442871
Validation loss: 2.21255938981169

Epoch: 6| Step: 3
Training loss: 1.9828790426254272
Validation loss: 2.2322600913304154

Epoch: 6| Step: 4
Training loss: 1.889578938484192
Validation loss: 2.222992914979176

Epoch: 6| Step: 5
Training loss: 2.3195090293884277
Validation loss: 2.19644748010943

Epoch: 6| Step: 6
Training loss: 2.3978800773620605
Validation loss: 2.166233185798891

Epoch: 6| Step: 7
Training loss: 2.078359842300415
Validation loss: 2.144401373401765

Epoch: 6| Step: 8
Training loss: 1.578709602355957
Validation loss: 2.2433209444886897

Epoch: 6| Step: 9
Training loss: 2.1230854988098145
Validation loss: 2.279127146608086

Epoch: 6| Step: 10
Training loss: 1.5099356174468994
Validation loss: 2.1989123616167294

Epoch: 6| Step: 11
Training loss: 2.464951276779175
Validation loss: 2.257446150625906

Epoch: 6| Step: 12
Training loss: 1.8729689121246338
Validation loss: 2.2278620466109245

Epoch: 6| Step: 13
Training loss: 2.6320977210998535
Validation loss: 2.30913116598642

Epoch: 188| Step: 0
Training loss: 1.7804949283599854
Validation loss: 2.215021735878401

Epoch: 6| Step: 1
Training loss: 2.354515314102173
Validation loss: 2.207005548220809

Epoch: 6| Step: 2
Training loss: 2.4036242961883545
Validation loss: 2.193588343999719

Epoch: 6| Step: 3
Training loss: 2.5199201107025146
Validation loss: 2.2490855083670667

Epoch: 6| Step: 4
Training loss: 2.062288761138916
Validation loss: 2.2127239896405126

Epoch: 6| Step: 5
Training loss: 1.8696465492248535
Validation loss: 2.2264793918978785

Epoch: 6| Step: 6
Training loss: 2.499709129333496
Validation loss: 2.1914831002553306

Epoch: 6| Step: 7
Training loss: 1.945754051208496
Validation loss: 2.181547482808431

Epoch: 6| Step: 8
Training loss: 1.5378844738006592
Validation loss: 2.138827893041795

Epoch: 6| Step: 9
Training loss: 2.1456186771392822
Validation loss: 2.2280570794177312

Epoch: 6| Step: 10
Training loss: 1.6141010522842407
Validation loss: 2.221420911050612

Epoch: 6| Step: 11
Training loss: 1.8979219198226929
Validation loss: 2.2219505361331406

Epoch: 6| Step: 12
Training loss: 2.024110794067383
Validation loss: 2.1205454923773326

Epoch: 6| Step: 13
Training loss: 2.040867805480957
Validation loss: 2.1776068954057592

Epoch: 189| Step: 0
Training loss: 2.506432056427002
Validation loss: 2.1790618896484375

Epoch: 6| Step: 1
Training loss: 2.2359039783477783
Validation loss: 2.1686081206926735

Epoch: 6| Step: 2
Training loss: 2.27313232421875
Validation loss: 2.1089591159615466

Epoch: 6| Step: 3
Training loss: 1.760887622833252
Validation loss: 2.2064664248497254

Epoch: 6| Step: 4
Training loss: 1.9658526182174683
Validation loss: 2.170522879528743

Epoch: 6| Step: 5
Training loss: 2.5524444580078125
Validation loss: 2.1524296422158518

Epoch: 6| Step: 6
Training loss: 2.0931429862976074
Validation loss: 2.140268643697103

Epoch: 6| Step: 7
Training loss: 1.4560678005218506
Validation loss: 2.1534714839791738

Epoch: 6| Step: 8
Training loss: 1.9538836479187012
Validation loss: 2.1340301959745345

Epoch: 6| Step: 9
Training loss: 2.4237775802612305
Validation loss: 2.1420680220409105

Epoch: 6| Step: 10
Training loss: 1.581350564956665
Validation loss: 2.1935640765774633

Epoch: 6| Step: 11
Training loss: 2.2269158363342285
Validation loss: 2.1739474983625513

Epoch: 6| Step: 12
Training loss: 2.2549309730529785
Validation loss: 2.1914481245061403

Epoch: 6| Step: 13
Training loss: 2.0842504501342773
Validation loss: 2.162016587872659

Epoch: 190| Step: 0
Training loss: 1.472832441329956
Validation loss: 2.138953947251843

Epoch: 6| Step: 1
Training loss: 1.7284530401229858
Validation loss: 2.208117643992106

Epoch: 6| Step: 2
Training loss: 1.9183270931243896
Validation loss: 2.1237901538930912

Epoch: 6| Step: 3
Training loss: 1.9104738235473633
Validation loss: 2.2128035483821744

Epoch: 6| Step: 4
Training loss: 1.449636459350586
Validation loss: 2.2307126650246243

Epoch: 6| Step: 5
Training loss: 1.5180902481079102
Validation loss: 2.218901595761699

Epoch: 6| Step: 6
Training loss: 2.128077983856201
Validation loss: 2.1583436868524037

Epoch: 6| Step: 7
Training loss: 2.38698673248291
Validation loss: 2.2944770628406155

Epoch: 6| Step: 8
Training loss: 1.928065299987793
Validation loss: 2.144621267113634

Epoch: 6| Step: 9
Training loss: 1.6267074346542358
Validation loss: 2.128599287361227

Epoch: 6| Step: 10
Training loss: 2.1627509593963623
Validation loss: 2.249177248247208

Epoch: 6| Step: 11
Training loss: 2.398726224899292
Validation loss: 2.2103169477114113

Epoch: 6| Step: 12
Training loss: 2.502140998840332
Validation loss: 2.2880340365953344

Epoch: 6| Step: 13
Training loss: 3.23447585105896
Validation loss: 2.2129054889884046

Epoch: 191| Step: 0
Training loss: 2.204822063446045
Validation loss: 2.2039826813564507

Epoch: 6| Step: 1
Training loss: 1.4112131595611572
Validation loss: 2.1593075977858676

Epoch: 6| Step: 2
Training loss: 2.2019081115722656
Validation loss: 2.2223562809728805

Epoch: 6| Step: 3
Training loss: 2.5398669242858887
Validation loss: 2.1111374337186097

Epoch: 6| Step: 4
Training loss: 2.179165840148926
Validation loss: 2.244988754231443

Epoch: 6| Step: 5
Training loss: 1.6747751235961914
Validation loss: 2.2146778157962266

Epoch: 6| Step: 6
Training loss: 2.4247677326202393
Validation loss: 2.207973328969812

Epoch: 6| Step: 7
Training loss: 1.4474613666534424
Validation loss: 2.24270280971322

Epoch: 6| Step: 8
Training loss: 2.1936209201812744
Validation loss: 2.0853873914287937

Epoch: 6| Step: 9
Training loss: 2.029214382171631
Validation loss: 2.1728547965326617

Epoch: 6| Step: 10
Training loss: 2.0158352851867676
Validation loss: 2.217971222375029

Epoch: 6| Step: 11
Training loss: 2.3985958099365234
Validation loss: 2.1042812767849175

Epoch: 6| Step: 12
Training loss: 2.1234207153320312
Validation loss: 2.226329352266045

Epoch: 6| Step: 13
Training loss: 1.93668532371521
Validation loss: 2.1885078568612375

Epoch: 192| Step: 0
Training loss: 2.040285587310791
Validation loss: 2.1886266508410053

Epoch: 6| Step: 1
Training loss: 1.9634675979614258
Validation loss: 2.1229795486696306

Epoch: 6| Step: 2
Training loss: 2.0519051551818848
Validation loss: 2.1624804414728636

Epoch: 6| Step: 3
Training loss: 2.4682717323303223
Validation loss: 2.1666122585214596

Epoch: 6| Step: 4
Training loss: 2.053222417831421
Validation loss: 2.1641155083974204

Epoch: 6| Step: 5
Training loss: 2.208034038543701
Validation loss: 2.188535899244329

Epoch: 6| Step: 6
Training loss: 1.9928102493286133
Validation loss: 2.191829632687312

Epoch: 6| Step: 7
Training loss: 2.0820472240448
Validation loss: 2.155754122682797

Epoch: 6| Step: 8
Training loss: 1.3059158325195312
Validation loss: 2.1980659577154342

Epoch: 6| Step: 9
Training loss: 2.6212029457092285
Validation loss: 2.084431617490707

Epoch: 6| Step: 10
Training loss: 2.511204242706299
Validation loss: 2.102539849537675

Epoch: 6| Step: 11
Training loss: 1.809939980506897
Validation loss: 2.1994550305028118

Epoch: 6| Step: 12
Training loss: 2.0160250663757324
Validation loss: 2.2033722246846845

Epoch: 6| Step: 13
Training loss: 2.1254420280456543
Validation loss: 2.1889707631962274

Epoch: 193| Step: 0
Training loss: 2.1325321197509766
Validation loss: 2.2233079402677474

Epoch: 6| Step: 1
Training loss: 1.9837863445281982
Validation loss: 2.172427950366851

Epoch: 6| Step: 2
Training loss: 2.0035581588745117
Validation loss: 2.184262360295942

Epoch: 6| Step: 3
Training loss: 1.7913249731063843
Validation loss: 2.1061216785061743

Epoch: 6| Step: 4
Training loss: 1.6801137924194336
Validation loss: 2.2317003998705136

Epoch: 6| Step: 5
Training loss: 2.262537956237793
Validation loss: 2.2541143432740243

Epoch: 6| Step: 6
Training loss: 2.437007188796997
Validation loss: 2.129711087032031

Epoch: 6| Step: 7
Training loss: 2.0895159244537354
Validation loss: 2.2265841730179323

Epoch: 6| Step: 8
Training loss: 2.1850855350494385
Validation loss: 2.1461063379882486

Epoch: 6| Step: 9
Training loss: 1.5883835554122925
Validation loss: 2.1763294512225735

Epoch: 6| Step: 10
Training loss: 2.224069595336914
Validation loss: 2.154968084827546

Epoch: 6| Step: 11
Training loss: 2.173398494720459
Validation loss: 2.1810957872739403

Epoch: 6| Step: 12
Training loss: 1.7986301183700562
Validation loss: 2.166953432944513

Epoch: 6| Step: 13
Training loss: 2.3983421325683594
Validation loss: 2.199386037806029

Epoch: 194| Step: 0
Training loss: 2.320098400115967
Validation loss: 2.165555912961242

Epoch: 6| Step: 1
Training loss: 1.9615854024887085
Validation loss: 2.241896631897137

Epoch: 6| Step: 2
Training loss: 2.213512420654297
Validation loss: 2.110723932584127

Epoch: 6| Step: 3
Training loss: 2.086212635040283
Validation loss: 2.1450344952203895

Epoch: 6| Step: 4
Training loss: 2.3771350383758545
Validation loss: 2.1396309188617173

Epoch: 6| Step: 5
Training loss: 1.932645559310913
Validation loss: 2.1536117112764748

Epoch: 6| Step: 6
Training loss: 2.4495363235473633
Validation loss: 2.171894952815066

Epoch: 6| Step: 7
Training loss: 1.8771748542785645
Validation loss: 2.183759506030749

Epoch: 6| Step: 8
Training loss: 1.3722338676452637
Validation loss: 2.2379579544067383

Epoch: 6| Step: 9
Training loss: 1.8145356178283691
Validation loss: 2.192720418335289

Epoch: 6| Step: 10
Training loss: 1.6195378303527832
Validation loss: 2.1653467121944634

Epoch: 6| Step: 11
Training loss: 2.3109970092773438
Validation loss: 2.2029172169264926

Epoch: 6| Step: 12
Training loss: 2.0649523735046387
Validation loss: 2.1024828303244805

Epoch: 6| Step: 13
Training loss: 3.048643112182617
Validation loss: 2.1098638837055494

Epoch: 195| Step: 0
Training loss: 1.7873470783233643
Validation loss: 2.164274693817221

Epoch: 6| Step: 1
Training loss: 1.725724458694458
Validation loss: 2.160188341653475

Epoch: 6| Step: 2
Training loss: 2.4060771465301514
Validation loss: 2.144142040642359

Epoch: 6| Step: 3
Training loss: 2.233787775039673
Validation loss: 2.1158811969141804

Epoch: 6| Step: 4
Training loss: 1.8713557720184326
Validation loss: 2.1414371049532326

Epoch: 6| Step: 5
Training loss: 1.9933840036392212
Validation loss: 2.167537743045438

Epoch: 6| Step: 6
Training loss: 3.148501396179199
Validation loss: 2.2170547593024468

Epoch: 6| Step: 7
Training loss: 2.745326519012451
Validation loss: 2.176408710018281

Epoch: 6| Step: 8
Training loss: 1.2280824184417725
Validation loss: 2.179193349294765

Epoch: 6| Step: 9
Training loss: 1.5162626504898071
Validation loss: 2.1836982696287093

Epoch: 6| Step: 10
Training loss: 2.078646183013916
Validation loss: 2.1815005169119885

Epoch: 6| Step: 11
Training loss: 2.153981924057007
Validation loss: 2.1435993589380735

Epoch: 6| Step: 12
Training loss: 2.192725419998169
Validation loss: 2.143360359694368

Epoch: 6| Step: 13
Training loss: 1.8736519813537598
Validation loss: 2.1937959066001316

Epoch: 196| Step: 0
Training loss: 1.9883384704589844
Validation loss: 2.2273005375298123

Epoch: 6| Step: 1
Training loss: 2.448690414428711
Validation loss: 2.251792697496312

Epoch: 6| Step: 2
Training loss: 1.5319122076034546
Validation loss: 2.264250447673182

Epoch: 6| Step: 3
Training loss: 2.5684945583343506
Validation loss: 2.1814084040221347

Epoch: 6| Step: 4
Training loss: 2.410922050476074
Validation loss: 2.169254941325034

Epoch: 6| Step: 5
Training loss: 1.5008597373962402
Validation loss: 2.203997741463364

Epoch: 6| Step: 6
Training loss: 2.083611011505127
Validation loss: 2.158744753047984

Epoch: 6| Step: 7
Training loss: 1.7567219734191895
Validation loss: 2.152821365223136

Epoch: 6| Step: 8
Training loss: 2.221416473388672
Validation loss: 2.2167433936108827

Epoch: 6| Step: 9
Training loss: 1.9949411153793335
Validation loss: 2.215845941215433

Epoch: 6| Step: 10
Training loss: 2.0592639446258545
Validation loss: 2.190796567547706

Epoch: 6| Step: 11
Training loss: 2.137739658355713
Validation loss: 2.1344530646518995

Epoch: 6| Step: 12
Training loss: 1.8012220859527588
Validation loss: 2.2182728628958426

Epoch: 6| Step: 13
Training loss: 2.2800023555755615
Validation loss: 2.1868391242078555

Epoch: 197| Step: 0
Training loss: 1.7250597476959229
Validation loss: 2.2003592957732496

Epoch: 6| Step: 1
Training loss: 1.7360613346099854
Validation loss: 2.2702665380252305

Epoch: 6| Step: 2
Training loss: 2.217782497406006
Validation loss: 2.254852484631282

Epoch: 6| Step: 3
Training loss: 2.3179190158843994
Validation loss: 2.246100419311113

Epoch: 6| Step: 4
Training loss: 1.565028190612793
Validation loss: 2.1226912903529342

Epoch: 6| Step: 5
Training loss: 1.971157431602478
Validation loss: 2.2276300204697477

Epoch: 6| Step: 6
Training loss: 2.3951587677001953
Validation loss: 2.1972827308921405

Epoch: 6| Step: 7
Training loss: 2.135448455810547
Validation loss: 2.2134331990313787

Epoch: 6| Step: 8
Training loss: 2.2545485496520996
Validation loss: 2.161709568833792

Epoch: 6| Step: 9
Training loss: 2.0450053215026855
Validation loss: 2.1475336808030323

Epoch: 6| Step: 10
Training loss: 1.7953749895095825
Validation loss: 2.176924818305559

Epoch: 6| Step: 11
Training loss: 3.0303401947021484
Validation loss: 2.191309516147901

Epoch: 6| Step: 12
Training loss: 1.150661587715149
Validation loss: 2.2486178451968777

Epoch: 6| Step: 13
Training loss: 1.9862223863601685
Validation loss: 2.2133785716948973

Epoch: 198| Step: 0
Training loss: 2.2211737632751465
Validation loss: 2.1915504855494343

Epoch: 6| Step: 1
Training loss: 2.1165988445281982
Validation loss: 2.238006555905906

Epoch: 6| Step: 2
Training loss: 2.0331196784973145
Validation loss: 2.2190222432536464

Epoch: 6| Step: 3
Training loss: 1.4715502262115479
Validation loss: 2.1334609318805

Epoch: 6| Step: 4
Training loss: 2.4918413162231445
Validation loss: 2.2339475539422806

Epoch: 6| Step: 5
Training loss: 2.360522508621216
Validation loss: 2.233364043697234

Epoch: 6| Step: 6
Training loss: 2.2465426921844482
Validation loss: 2.217173827591763

Epoch: 6| Step: 7
Training loss: 1.795804738998413
Validation loss: 2.217349575411889

Epoch: 6| Step: 8
Training loss: 2.0558865070343018
Validation loss: 2.1884786467398367

Epoch: 6| Step: 9
Training loss: 2.224397897720337
Validation loss: 2.1054803991830475

Epoch: 6| Step: 10
Training loss: 2.105097770690918
Validation loss: 2.0955012100999073

Epoch: 6| Step: 11
Training loss: 2.1289210319519043
Validation loss: 2.157818901923395

Epoch: 6| Step: 12
Training loss: 1.923379898071289
Validation loss: 2.2215803054071244

Epoch: 6| Step: 13
Training loss: 1.4634878635406494
Validation loss: 2.2174876146419074

Epoch: 199| Step: 0
Training loss: 2.478306770324707
Validation loss: 2.2232533680495394

Epoch: 6| Step: 1
Training loss: 2.3993821144104004
Validation loss: 2.194730935558196

Epoch: 6| Step: 2
Training loss: 1.9441605806350708
Validation loss: 2.218328227279007

Epoch: 6| Step: 3
Training loss: 1.440706729888916
Validation loss: 2.200392130882509

Epoch: 6| Step: 4
Training loss: 1.925870418548584
Validation loss: 2.267809788386027

Epoch: 6| Step: 5
Training loss: 2.565537452697754
Validation loss: 2.252543721147763

Epoch: 6| Step: 6
Training loss: 1.7119815349578857
Validation loss: 2.232563413599486

Epoch: 6| Step: 7
Training loss: 2.245335578918457
Validation loss: 2.2149220358940864

Epoch: 6| Step: 8
Training loss: 1.6860170364379883
Validation loss: 2.2133673403852727

Epoch: 6| Step: 9
Training loss: 1.5832366943359375
Validation loss: 2.190038009356427

Epoch: 6| Step: 10
Training loss: 1.7794616222381592
Validation loss: 2.2194643071902695

Epoch: 6| Step: 11
Training loss: 2.401911735534668
Validation loss: 2.207688449531473

Epoch: 6| Step: 12
Training loss: 2.561802864074707
Validation loss: 2.1955352547348186

Epoch: 6| Step: 13
Training loss: 1.5465328693389893
Validation loss: 2.1274962425231934

Epoch: 200| Step: 0
Training loss: 2.3222551345825195
Validation loss: 2.1622034580476823

Epoch: 6| Step: 1
Training loss: 2.4452462196350098
Validation loss: 2.171195251967317

Epoch: 6| Step: 2
Training loss: 3.5369350910186768
Validation loss: 2.1697651545206704

Epoch: 6| Step: 3
Training loss: 1.8275854587554932
Validation loss: 2.270389703012282

Epoch: 6| Step: 4
Training loss: 2.184084892272949
Validation loss: 2.1894763849114858

Epoch: 6| Step: 5
Training loss: 1.6193485260009766
Validation loss: 2.16676305314546

Epoch: 6| Step: 6
Training loss: 2.708115577697754
Validation loss: 2.1586052397246003

Epoch: 6| Step: 7
Training loss: 2.0271072387695312
Validation loss: 2.150047371464391

Epoch: 6| Step: 8
Training loss: 1.0679187774658203
Validation loss: 2.219021997144145

Epoch: 6| Step: 9
Training loss: 1.8643312454223633
Validation loss: 2.2078442342819704

Epoch: 6| Step: 10
Training loss: 1.9870336055755615
Validation loss: 2.332718362090408

Epoch: 6| Step: 11
Training loss: 1.6467835903167725
Validation loss: 2.1354433054565103

Epoch: 6| Step: 12
Training loss: 2.448862075805664
Validation loss: 2.221770117359777

Epoch: 6| Step: 13
Training loss: 1.8310075998306274
Validation loss: 2.1692369650768977

Epoch: 201| Step: 0
Training loss: 2.3524866104125977
Validation loss: 2.2018845004420124

Epoch: 6| Step: 1
Training loss: 2.015294075012207
Validation loss: 2.207171522161012

Epoch: 6| Step: 2
Training loss: 2.2273306846618652
Validation loss: 2.2545416060314385

Epoch: 6| Step: 3
Training loss: 1.714434266090393
Validation loss: 2.179423047650245

Epoch: 6| Step: 4
Training loss: 2.2470192909240723
Validation loss: 2.157324601245183

Epoch: 6| Step: 5
Training loss: 1.866807460784912
Validation loss: 2.2263514418755808

Epoch: 6| Step: 6
Training loss: 1.818967342376709
Validation loss: 2.2240078551794893

Epoch: 6| Step: 7
Training loss: 2.0567626953125
Validation loss: 2.267727898013207

Epoch: 6| Step: 8
Training loss: 1.844258427619934
Validation loss: 2.2388360500335693

Epoch: 6| Step: 9
Training loss: 2.5716023445129395
Validation loss: 2.2747014825062086

Epoch: 6| Step: 10
Training loss: 1.7971042394638062
Validation loss: 2.1525857294759443

Epoch: 6| Step: 11
Training loss: 2.473968267440796
Validation loss: 2.280467980651445

Epoch: 6| Step: 12
Training loss: 1.640182375907898
Validation loss: 2.1830503581672587

Epoch: 6| Step: 13
Training loss: 2.7074666023254395
Validation loss: 2.280651941094347

Epoch: 202| Step: 0
Training loss: 2.9199459552764893
Validation loss: 2.189240386409144

Epoch: 6| Step: 1
Training loss: 2.100644111633301
Validation loss: 2.1794159668748097

Epoch: 6| Step: 2
Training loss: 1.614243745803833
Validation loss: 2.205083662463773

Epoch: 6| Step: 3
Training loss: 2.601193904876709
Validation loss: 2.130836994417252

Epoch: 6| Step: 4
Training loss: 2.0599746704101562
Validation loss: 2.1315743307913504

Epoch: 6| Step: 5
Training loss: 1.6952905654907227
Validation loss: 2.1343448264624483

Epoch: 6| Step: 6
Training loss: 1.9005482196807861
Validation loss: 2.127318430972356

Epoch: 6| Step: 7
Training loss: 2.452580451965332
Validation loss: 2.1312250668002712

Epoch: 6| Step: 8
Training loss: 2.043846607208252
Validation loss: 2.1982753148642917

Epoch: 6| Step: 9
Training loss: 1.7875077724456787
Validation loss: 2.1667433297762306

Epoch: 6| Step: 10
Training loss: 1.417790174484253
Validation loss: 2.0989169818098827

Epoch: 6| Step: 11
Training loss: 1.5201828479766846
Validation loss: 2.126944480403777

Epoch: 6| Step: 12
Training loss: 1.695434331893921
Validation loss: 2.162696825560703

Epoch: 6| Step: 13
Training loss: 2.2042946815490723
Validation loss: 2.190092461083525

Epoch: 203| Step: 0
Training loss: 1.7845209836959839
Validation loss: 2.2040228843688965

Epoch: 6| Step: 1
Training loss: 1.9761195182800293
Validation loss: 2.2049712980947187

Epoch: 6| Step: 2
Training loss: 1.5243232250213623
Validation loss: 2.1297575978822607

Epoch: 6| Step: 3
Training loss: 1.3916579484939575
Validation loss: 2.1015718034518662

Epoch: 6| Step: 4
Training loss: 2.189883232116699
Validation loss: 2.2294496182472474

Epoch: 6| Step: 5
Training loss: 2.058380126953125
Validation loss: 2.188596058917302

Epoch: 6| Step: 6
Training loss: 3.3180813789367676
Validation loss: 2.176973690268814

Epoch: 6| Step: 7
Training loss: 2.1445157527923584
Validation loss: 2.1189548866723174

Epoch: 6| Step: 8
Training loss: 1.7434582710266113
Validation loss: 2.2059426153859785

Epoch: 6| Step: 9
Training loss: 1.635854959487915
Validation loss: 2.165361653092087

Epoch: 6| Step: 10
Training loss: 2.653892755508423
Validation loss: 2.2212786571953886

Epoch: 6| Step: 11
Training loss: 2.1206846237182617
Validation loss: 2.2397806593166885

Epoch: 6| Step: 12
Training loss: 2.0567853450775146
Validation loss: 2.215104144106629

Epoch: 6| Step: 13
Training loss: 1.9954477548599243
Validation loss: 2.2063448813653763

Epoch: 204| Step: 0
Training loss: 1.8658738136291504
Validation loss: 2.139793247304937

Epoch: 6| Step: 1
Training loss: 2.4534964561462402
Validation loss: 2.158559447975569

Epoch: 6| Step: 2
Training loss: 1.9197337627410889
Validation loss: 2.1251693310276156

Epoch: 6| Step: 3
Training loss: 1.7723060846328735
Validation loss: 2.185614098784744

Epoch: 6| Step: 4
Training loss: 2.091824531555176
Validation loss: 2.1759858413409163

Epoch: 6| Step: 5
Training loss: 2.614530086517334
Validation loss: 2.247454789377028

Epoch: 6| Step: 6
Training loss: 1.602725863456726
Validation loss: 2.1193493130386516

Epoch: 6| Step: 7
Training loss: 1.968213438987732
Validation loss: 2.188414740306075

Epoch: 6| Step: 8
Training loss: 1.4479401111602783
Validation loss: 2.1809014812592538

Epoch: 6| Step: 9
Training loss: 2.182882070541382
Validation loss: 2.1443750063578286

Epoch: 6| Step: 10
Training loss: 1.8555421829223633
Validation loss: 2.20055280962298

Epoch: 6| Step: 11
Training loss: 2.566403388977051
Validation loss: 2.119530680359051

Epoch: 6| Step: 12
Training loss: 2.2622175216674805
Validation loss: 2.222062210882864

Epoch: 6| Step: 13
Training loss: 1.1494990587234497
Validation loss: 2.1128092529953166

Epoch: 205| Step: 0
Training loss: 2.0920705795288086
Validation loss: 2.1542789730974423

Epoch: 6| Step: 1
Training loss: 2.160140037536621
Validation loss: 2.219372933910739

Epoch: 6| Step: 2
Training loss: 1.4903109073638916
Validation loss: 2.140934812125339

Epoch: 6| Step: 3
Training loss: 2.1609177589416504
Validation loss: 2.0875107293487876

Epoch: 6| Step: 4
Training loss: 2.6371541023254395
Validation loss: 2.0967495543982393

Epoch: 6| Step: 5
Training loss: 1.5197784900665283
Validation loss: 2.1063351938801427

Epoch: 6| Step: 6
Training loss: 2.1888341903686523
Validation loss: 2.072596606387887

Epoch: 6| Step: 7
Training loss: 1.9646832942962646
Validation loss: 2.11590903036056

Epoch: 6| Step: 8
Training loss: 1.4566833972930908
Validation loss: 2.193025609498383

Epoch: 6| Step: 9
Training loss: 1.7924299240112305
Validation loss: 2.2687821208789782

Epoch: 6| Step: 10
Training loss: 2.594320774078369
Validation loss: 2.15647610797677

Epoch: 6| Step: 11
Training loss: 2.5935006141662598
Validation loss: 2.1579413414001465

Epoch: 6| Step: 12
Training loss: 2.3739988803863525
Validation loss: 2.174691959093976

Epoch: 6| Step: 13
Training loss: 2.233916759490967
Validation loss: 2.1857559206665202

Epoch: 206| Step: 0
Training loss: 2.2543256282806396
Validation loss: 2.2589879061586116

Epoch: 6| Step: 1
Training loss: 1.8658254146575928
Validation loss: 2.1653397954920286

Epoch: 6| Step: 2
Training loss: 2.260359764099121
Validation loss: 2.163490900429346

Epoch: 6| Step: 3
Training loss: 1.653713583946228
Validation loss: 2.191196823632845

Epoch: 6| Step: 4
Training loss: 1.4194673299789429
Validation loss: 2.146410622904378

Epoch: 6| Step: 5
Training loss: 2.263402223587036
Validation loss: 2.206742645591818

Epoch: 6| Step: 6
Training loss: 2.5530903339385986
Validation loss: 2.1223023681230444

Epoch: 6| Step: 7
Training loss: 2.1788198947906494
Validation loss: 2.227831038095618

Epoch: 6| Step: 8
Training loss: 1.9029343128204346
Validation loss: 2.1570718801149757

Epoch: 6| Step: 9
Training loss: 1.3160758018493652
Validation loss: 2.154824149224066

Epoch: 6| Step: 10
Training loss: 2.0593650341033936
Validation loss: 2.207068920135498

Epoch: 6| Step: 11
Training loss: 2.111330986022949
Validation loss: 2.214918203251336

Epoch: 6| Step: 12
Training loss: 2.378370523452759
Validation loss: 2.196528955172467

Epoch: 6| Step: 13
Training loss: 2.1170096397399902
Validation loss: 2.2079633769168647

Epoch: 207| Step: 0
Training loss: 2.5872387886047363
Validation loss: 2.1157833183965375

Epoch: 6| Step: 1
Training loss: 1.948943853378296
Validation loss: 2.126173834646902

Epoch: 6| Step: 2
Training loss: 1.2790405750274658
Validation loss: 2.2194960835159465

Epoch: 6| Step: 3
Training loss: 1.5458705425262451
Validation loss: 2.224128867990227

Epoch: 6| Step: 4
Training loss: 2.843219518661499
Validation loss: 2.177990876218324

Epoch: 6| Step: 5
Training loss: 1.921966552734375
Validation loss: 2.0835081992610807

Epoch: 6| Step: 6
Training loss: 1.9982125759124756
Validation loss: 2.11564197463374

Epoch: 6| Step: 7
Training loss: 2.49461030960083
Validation loss: 2.1179732943093903

Epoch: 6| Step: 8
Training loss: 2.0889315605163574
Validation loss: 2.136038053420282

Epoch: 6| Step: 9
Training loss: 2.098001003265381
Validation loss: 2.133162235700956

Epoch: 6| Step: 10
Training loss: 2.3434689044952393
Validation loss: 2.1154777080782

Epoch: 6| Step: 11
Training loss: 2.013936996459961
Validation loss: 2.159893646035143

Epoch: 6| Step: 12
Training loss: 1.7314608097076416
Validation loss: 2.1516888679996615

Epoch: 6| Step: 13
Training loss: 2.092376470565796
Validation loss: 2.2169686427680393

Epoch: 208| Step: 0
Training loss: 2.7724671363830566
Validation loss: 2.190283945811692

Epoch: 6| Step: 1
Training loss: 1.9092036485671997
Validation loss: 2.173165423895723

Epoch: 6| Step: 2
Training loss: 1.9329867362976074
Validation loss: 2.236220198292886

Epoch: 6| Step: 3
Training loss: 2.0806727409362793
Validation loss: 2.1822546733322965

Epoch: 6| Step: 4
Training loss: 2.3014283180236816
Validation loss: 2.2511704352594193

Epoch: 6| Step: 5
Training loss: 1.7932541370391846
Validation loss: 2.1879005996129846

Epoch: 6| Step: 6
Training loss: 1.834155559539795
Validation loss: 2.2151629232591197

Epoch: 6| Step: 7
Training loss: 1.5707718133926392
Validation loss: 2.1600240609979116

Epoch: 6| Step: 8
Training loss: 2.3509674072265625
Validation loss: 2.1181634741444744

Epoch: 6| Step: 9
Training loss: 2.0724313259124756
Validation loss: 2.199984295393831

Epoch: 6| Step: 10
Training loss: 2.4049019813537598
Validation loss: 2.1628173166705715

Epoch: 6| Step: 11
Training loss: 2.078662872314453
Validation loss: 2.2280261760116904

Epoch: 6| Step: 12
Training loss: 2.013253688812256
Validation loss: 2.2180450552253315

Epoch: 6| Step: 13
Training loss: 2.088521957397461
Validation loss: 2.2200103523910686

Epoch: 209| Step: 0
Training loss: 2.4568817615509033
Validation loss: 2.1863969320892007

Epoch: 6| Step: 1
Training loss: 2.2126235961914062
Validation loss: 2.195986452923026

Epoch: 6| Step: 2
Training loss: 1.250787615776062
Validation loss: 2.2254810794707267

Epoch: 6| Step: 3
Training loss: 1.7430517673492432
Validation loss: 2.153035622771068

Epoch: 6| Step: 4
Training loss: 2.516352891921997
Validation loss: 2.1409524333092476

Epoch: 6| Step: 5
Training loss: 2.4085018634796143
Validation loss: 2.103652190136653

Epoch: 6| Step: 6
Training loss: 1.942667841911316
Validation loss: 2.159754535203339

Epoch: 6| Step: 7
Training loss: 2.5262444019317627
Validation loss: 2.178414565260692

Epoch: 6| Step: 8
Training loss: 2.413213014602661
Validation loss: 2.135996449378229

Epoch: 6| Step: 9
Training loss: 1.683847427368164
Validation loss: 2.146627600475024

Epoch: 6| Step: 10
Training loss: 1.239769458770752
Validation loss: 2.1614656884183168

Epoch: 6| Step: 11
Training loss: 2.5415921211242676
Validation loss: 2.0724896333550893

Epoch: 6| Step: 12
Training loss: 1.7039715051651
Validation loss: 2.1541846772675872

Epoch: 6| Step: 13
Training loss: 2.197096109390259
Validation loss: 2.110417917210569

Epoch: 210| Step: 0
Training loss: 2.1954593658447266
Validation loss: 2.1780634016119023

Epoch: 6| Step: 1
Training loss: 2.266852378845215
Validation loss: 2.1993859070603565

Epoch: 6| Step: 2
Training loss: 2.206723690032959
Validation loss: 2.114939652463441

Epoch: 6| Step: 3
Training loss: 2.1131844520568848
Validation loss: 2.2065130190182756

Epoch: 6| Step: 4
Training loss: 1.5569806098937988
Validation loss: 2.20322242347143

Epoch: 6| Step: 5
Training loss: 1.6132402420043945
Validation loss: 2.152395176631148

Epoch: 6| Step: 6
Training loss: 2.4148926734924316
Validation loss: 2.202134754068108

Epoch: 6| Step: 7
Training loss: 2.2413628101348877
Validation loss: 2.2244968991125784

Epoch: 6| Step: 8
Training loss: 2.3500499725341797
Validation loss: 2.303054740352015

Epoch: 6| Step: 9
Training loss: 1.6574265956878662
Validation loss: 2.1352899715464604

Epoch: 6| Step: 10
Training loss: 2.0658316612243652
Validation loss: 2.231178734892158

Epoch: 6| Step: 11
Training loss: 1.5373425483703613
Validation loss: 2.2293033676762737

Epoch: 6| Step: 12
Training loss: 1.885104775428772
Validation loss: 2.181484530048986

Epoch: 6| Step: 13
Training loss: 2.658691883087158
Validation loss: 2.1651730319505096

Epoch: 211| Step: 0
Training loss: 2.214836597442627
Validation loss: 2.1870095576009443

Epoch: 6| Step: 1
Training loss: 2.1862306594848633
Validation loss: 2.17863800192392

Epoch: 6| Step: 2
Training loss: 1.5634806156158447
Validation loss: 2.2362471062649965

Epoch: 6| Step: 3
Training loss: 2.030529499053955
Validation loss: 2.1986810084312194

Epoch: 6| Step: 4
Training loss: 1.861708164215088
Validation loss: 2.28456469761428

Epoch: 6| Step: 5
Training loss: 1.6461615562438965
Validation loss: 2.1799137515406453

Epoch: 6| Step: 6
Training loss: 1.8326529264450073
Validation loss: 2.127395431200663

Epoch: 6| Step: 7
Training loss: 2.227921724319458
Validation loss: 2.2080601761418004

Epoch: 6| Step: 8
Training loss: 1.8577626943588257
Validation loss: 2.170362990389588

Epoch: 6| Step: 9
Training loss: 2.0556468963623047
Validation loss: 2.124019492057062

Epoch: 6| Step: 10
Training loss: 2.3780264854431152
Validation loss: 2.09749428174829

Epoch: 6| Step: 11
Training loss: 2.0664520263671875
Validation loss: 2.1593418582793205

Epoch: 6| Step: 12
Training loss: 1.997251033782959
Validation loss: 2.2089739281644105

Epoch: 6| Step: 13
Training loss: 2.3034725189208984
Validation loss: 2.2458556864851262

Epoch: 212| Step: 0
Training loss: 2.189753532409668
Validation loss: 2.152201408980995

Epoch: 6| Step: 1
Training loss: 1.8915817737579346
Validation loss: 2.2148135759497203

Epoch: 6| Step: 2
Training loss: 2.3819339275360107
Validation loss: 2.2428032787897254

Epoch: 6| Step: 3
Training loss: 1.746826171875
Validation loss: 2.223314824924674

Epoch: 6| Step: 4
Training loss: 1.5889549255371094
Validation loss: 2.261479475164926

Epoch: 6| Step: 5
Training loss: 2.7036499977111816
Validation loss: 2.1900290853233746

Epoch: 6| Step: 6
Training loss: 2.083059787750244
Validation loss: 2.17026190347569

Epoch: 6| Step: 7
Training loss: 2.176605463027954
Validation loss: 2.1729514368118776

Epoch: 6| Step: 8
Training loss: 2.0365073680877686
Validation loss: 2.1588551511046705

Epoch: 6| Step: 9
Training loss: 1.3173543214797974
Validation loss: 2.183340526396228

Epoch: 6| Step: 10
Training loss: 2.3454694747924805
Validation loss: 2.27908081136724

Epoch: 6| Step: 11
Training loss: 1.7295353412628174
Validation loss: 2.19180558061087

Epoch: 6| Step: 12
Training loss: 1.6590635776519775
Validation loss: 2.14151414491797

Epoch: 6| Step: 13
Training loss: 2.931154489517212
Validation loss: 2.167332192902924

Epoch: 213| Step: 0
Training loss: 1.9809650182724
Validation loss: 2.2440675791873725

Epoch: 6| Step: 1
Training loss: 2.335881233215332
Validation loss: 2.168732771309473

Epoch: 6| Step: 2
Training loss: 2.2122244834899902
Validation loss: 2.1928477825657016

Epoch: 6| Step: 3
Training loss: 1.6017334461212158
Validation loss: 2.255547279952675

Epoch: 6| Step: 4
Training loss: 2.0910162925720215
Validation loss: 2.14603227953757

Epoch: 6| Step: 5
Training loss: 2.1364481449127197
Validation loss: 2.223474907618697

Epoch: 6| Step: 6
Training loss: 2.057901382446289
Validation loss: 2.1836503064760597

Epoch: 6| Step: 7
Training loss: 2.5754358768463135
Validation loss: 2.2010424034569853

Epoch: 6| Step: 8
Training loss: 2.1235084533691406
Validation loss: 2.088476506612634

Epoch: 6| Step: 9
Training loss: 1.8298442363739014
Validation loss: 2.158249778132285

Epoch: 6| Step: 10
Training loss: 1.4774624109268188
Validation loss: 2.2287986868171283

Epoch: 6| Step: 11
Training loss: 1.8885990381240845
Validation loss: 2.176887135351858

Epoch: 6| Step: 12
Training loss: 2.1521854400634766
Validation loss: 2.126899396219561

Epoch: 6| Step: 13
Training loss: 1.6931971311569214
Validation loss: 2.1937631484000915

Epoch: 214| Step: 0
Training loss: 2.5740535259246826
Validation loss: 2.1975314617156982

Epoch: 6| Step: 1
Training loss: 2.5173416137695312
Validation loss: 2.148503006145518

Epoch: 6| Step: 2
Training loss: 2.0203568935394287
Validation loss: 2.097756585767192

Epoch: 6| Step: 3
Training loss: 2.264655113220215
Validation loss: 2.131779529715097

Epoch: 6| Step: 4
Training loss: 2.070723533630371
Validation loss: 2.0630758218867804

Epoch: 6| Step: 5
Training loss: 1.2779464721679688
Validation loss: 2.237149130913519

Epoch: 6| Step: 6
Training loss: 1.6869304180145264
Validation loss: 2.181125256323045

Epoch: 6| Step: 7
Training loss: 1.6217243671417236
Validation loss: 2.073971789370301

Epoch: 6| Step: 8
Training loss: 3.0469307899475098
Validation loss: 2.141390774839668

Epoch: 6| Step: 9
Training loss: 2.328275680541992
Validation loss: 2.1604212663506948

Epoch: 6| Step: 10
Training loss: 1.3924610614776611
Validation loss: 2.1706854668996667

Epoch: 6| Step: 11
Training loss: 2.4906744956970215
Validation loss: 2.2173492677750124

Epoch: 6| Step: 12
Training loss: 2.3421125411987305
Validation loss: 2.0843013922373452

Epoch: 6| Step: 13
Training loss: 1.1118282079696655
Validation loss: 2.0689958692878805

Epoch: 215| Step: 0
Training loss: 1.6694846153259277
Validation loss: 2.130328480915357

Epoch: 6| Step: 1
Training loss: 2.289832592010498
Validation loss: 2.150887332936769

Epoch: 6| Step: 2
Training loss: 2.022524118423462
Validation loss: 2.2093763620622697

Epoch: 6| Step: 3
Training loss: 1.882230520248413
Validation loss: 2.2508411253652265

Epoch: 6| Step: 4
Training loss: 2.0016062259674072
Validation loss: 2.2391007818201536

Epoch: 6| Step: 5
Training loss: 2.168095588684082
Validation loss: 2.254594720819945

Epoch: 6| Step: 6
Training loss: 1.9713566303253174
Validation loss: 2.1754494995199223

Epoch: 6| Step: 7
Training loss: 1.681525468826294
Validation loss: 2.2489134957713466

Epoch: 6| Step: 8
Training loss: 2.392871379852295
Validation loss: 2.1851443218928512

Epoch: 6| Step: 9
Training loss: 1.4048833847045898
Validation loss: 2.2204771605871056

Epoch: 6| Step: 10
Training loss: 1.9872276782989502
Validation loss: 2.203339324202589

Epoch: 6| Step: 11
Training loss: 2.064786672592163
Validation loss: 2.2305630637753393

Epoch: 6| Step: 12
Training loss: 2.492662191390991
Validation loss: 2.2510977752747072

Epoch: 6| Step: 13
Training loss: 2.0506982803344727
Validation loss: 2.1883694741033737

Epoch: 216| Step: 0
Training loss: 2.218376636505127
Validation loss: 2.2110218309587046

Epoch: 6| Step: 1
Training loss: 3.0039429664611816
Validation loss: 2.1515643904286046

Epoch: 6| Step: 2
Training loss: 2.3632915019989014
Validation loss: 2.179146084734189

Epoch: 6| Step: 3
Training loss: 2.0688865184783936
Validation loss: 2.1680630432662142

Epoch: 6| Step: 4
Training loss: 1.9147579669952393
Validation loss: 2.235130961223315

Epoch: 6| Step: 5
Training loss: 1.9332246780395508
Validation loss: 2.30258870381181

Epoch: 6| Step: 6
Training loss: 1.7984943389892578
Validation loss: 2.2460099048511957

Epoch: 6| Step: 7
Training loss: 1.8665969371795654
Validation loss: 2.135075546080066

Epoch: 6| Step: 8
Training loss: 1.8902544975280762
Validation loss: 2.2366601651714695

Epoch: 6| Step: 9
Training loss: 2.126188039779663
Validation loss: 2.229979289475308

Epoch: 6| Step: 10
Training loss: 1.51435124874115
Validation loss: 2.159461905879359

Epoch: 6| Step: 11
Training loss: 2.278465747833252
Validation loss: 2.138730140142543

Epoch: 6| Step: 12
Training loss: 1.6684792041778564
Validation loss: 2.2058876150397846

Epoch: 6| Step: 13
Training loss: 2.1219427585601807
Validation loss: 2.158293911205825

Epoch: 217| Step: 0
Training loss: 2.1241297721862793
Validation loss: 2.2536417515047136

Epoch: 6| Step: 1
Training loss: 1.9280872344970703
Validation loss: 2.140418078309746

Epoch: 6| Step: 2
Training loss: 2.2660956382751465
Validation loss: 2.152042950353315

Epoch: 6| Step: 3
Training loss: 2.1488397121429443
Validation loss: 2.2139416625422816

Epoch: 6| Step: 4
Training loss: 1.8389283418655396
Validation loss: 2.2408478490767942

Epoch: 6| Step: 5
Training loss: 2.468010425567627
Validation loss: 2.153904302145845

Epoch: 6| Step: 6
Training loss: 2.1760597229003906
Validation loss: 2.275781954488447

Epoch: 6| Step: 7
Training loss: 1.4865540266036987
Validation loss: 2.213385514033738

Epoch: 6| Step: 8
Training loss: 1.9009279012680054
Validation loss: 2.242800328039354

Epoch: 6| Step: 9
Training loss: 1.7514641284942627
Validation loss: 2.2002918502335906

Epoch: 6| Step: 10
Training loss: 2.19673228263855
Validation loss: 2.26283194429131

Epoch: 6| Step: 11
Training loss: 1.6993043422698975
Validation loss: 2.195942864623121

Epoch: 6| Step: 12
Training loss: 2.1666646003723145
Validation loss: 2.167408638103034

Epoch: 6| Step: 13
Training loss: 2.2310380935668945
Validation loss: 2.2509961358962522

Epoch: 218| Step: 0
Training loss: 2.081552267074585
Validation loss: 2.276271386813092

Epoch: 6| Step: 1
Training loss: 1.952179193496704
Validation loss: 2.1579073398343978

Epoch: 6| Step: 2
Training loss: 1.3737800121307373
Validation loss: 2.173302350505706

Epoch: 6| Step: 3
Training loss: 1.4311758279800415
Validation loss: 2.1851087026698615

Epoch: 6| Step: 4
Training loss: 2.6215481758117676
Validation loss: 2.17474619291162

Epoch: 6| Step: 5
Training loss: 2.821037769317627
Validation loss: 2.168066224744243

Epoch: 6| Step: 6
Training loss: 2.059412956237793
Validation loss: 2.1783960993571947

Epoch: 6| Step: 7
Training loss: 2.16083025932312
Validation loss: 2.1555816127407934

Epoch: 6| Step: 8
Training loss: 1.7545808553695679
Validation loss: 2.197595106658115

Epoch: 6| Step: 9
Training loss: 1.8089090585708618
Validation loss: 2.2387822315257084

Epoch: 6| Step: 10
Training loss: 1.4467570781707764
Validation loss: 2.171628846917101

Epoch: 6| Step: 11
Training loss: 2.5774171352386475
Validation loss: 2.1831622405718734

Epoch: 6| Step: 12
Training loss: 1.7628635168075562
Validation loss: 2.1124079099265476

Epoch: 6| Step: 13
Training loss: 2.787266731262207
Validation loss: 2.2698821816393124

Epoch: 219| Step: 0
Training loss: 1.9156686067581177
Validation loss: 2.1425587797677643

Epoch: 6| Step: 1
Training loss: 2.7532577514648438
Validation loss: 2.187486799814368

Epoch: 6| Step: 2
Training loss: 1.8175854682922363
Validation loss: 2.197795829465312

Epoch: 6| Step: 3
Training loss: 2.1072986125946045
Validation loss: 2.193606645830216

Epoch: 6| Step: 4
Training loss: 1.8719966411590576
Validation loss: 2.2240890123510875

Epoch: 6| Step: 5
Training loss: 2.0339741706848145
Validation loss: 2.2259174495614986

Epoch: 6| Step: 6
Training loss: 1.9429851770401
Validation loss: 2.2590672046907487

Epoch: 6| Step: 7
Training loss: 2.303525924682617
Validation loss: 2.21358323097229

Epoch: 6| Step: 8
Training loss: 1.6430778503417969
Validation loss: 2.1819644281941075

Epoch: 6| Step: 9
Training loss: 1.7852020263671875
Validation loss: 2.303705387218024

Epoch: 6| Step: 10
Training loss: 2.3016645908355713
Validation loss: 2.184783125436434

Epoch: 6| Step: 11
Training loss: 2.095642328262329
Validation loss: 2.1466380755106607

Epoch: 6| Step: 12
Training loss: 2.0641396045684814
Validation loss: 2.252353575921828

Epoch: 6| Step: 13
Training loss: 1.96482253074646
Validation loss: 2.235466995546895

Epoch: 220| Step: 0
Training loss: 1.775416374206543
Validation loss: 2.1721416852807485

Epoch: 6| Step: 1
Training loss: 1.543375015258789
Validation loss: 2.1803206782187186

Epoch: 6| Step: 2
Training loss: 1.902802586555481
Validation loss: 2.109305166429089

Epoch: 6| Step: 3
Training loss: 1.5801692008972168
Validation loss: 2.1243437361973587

Epoch: 6| Step: 4
Training loss: 2.4089527130126953
Validation loss: 2.227962165750483

Epoch: 6| Step: 5
Training loss: 2.0412347316741943
Validation loss: 2.167245705922445

Epoch: 6| Step: 6
Training loss: 2.0399973392486572
Validation loss: 2.2046589082287205

Epoch: 6| Step: 7
Training loss: 2.6813271045684814
Validation loss: 2.1112942772526897

Epoch: 6| Step: 8
Training loss: 1.9768850803375244
Validation loss: 2.184170555042964

Epoch: 6| Step: 9
Training loss: 2.147819995880127
Validation loss: 2.2257696582425024

Epoch: 6| Step: 10
Training loss: 1.9068020582199097
Validation loss: 2.1406628931722333

Epoch: 6| Step: 11
Training loss: 2.4479048252105713
Validation loss: 2.159473496098672

Epoch: 6| Step: 12
Training loss: 1.8975096940994263
Validation loss: 2.1454777384317048

Epoch: 6| Step: 13
Training loss: 2.428983449935913
Validation loss: 2.1151410443808443

Epoch: 221| Step: 0
Training loss: 2.377267837524414
Validation loss: 2.190290057530967

Epoch: 6| Step: 1
Training loss: 2.259936809539795
Validation loss: 2.1266521907621816

Epoch: 6| Step: 2
Training loss: 1.386965274810791
Validation loss: 2.104035467229864

Epoch: 6| Step: 3
Training loss: 2.0673775672912598
Validation loss: 2.099351408661053

Epoch: 6| Step: 4
Training loss: 2.102721691131592
Validation loss: 2.193700590441304

Epoch: 6| Step: 5
Training loss: 2.269045829772949
Validation loss: 2.1930553067115044

Epoch: 6| Step: 6
Training loss: 1.457641363143921
Validation loss: 2.195881079601985

Epoch: 6| Step: 7
Training loss: 1.891207218170166
Validation loss: 2.0993095149276075

Epoch: 6| Step: 8
Training loss: 1.5808910131454468
Validation loss: 2.216951817594549

Epoch: 6| Step: 9
Training loss: 2.1889827251434326
Validation loss: 2.2984852098649546

Epoch: 6| Step: 10
Training loss: 2.3685660362243652
Validation loss: 2.131249843105193

Epoch: 6| Step: 11
Training loss: 1.790580153465271
Validation loss: 2.1296559879856725

Epoch: 6| Step: 12
Training loss: 2.2770280838012695
Validation loss: 2.2397184218129804

Epoch: 6| Step: 13
Training loss: 1.1537015438079834
Validation loss: 2.1512433687845864

Epoch: 222| Step: 0
Training loss: 1.9871940612792969
Validation loss: 2.3239343627806632

Epoch: 6| Step: 1
Training loss: 2.0198066234588623
Validation loss: 2.1589836433369625

Epoch: 6| Step: 2
Training loss: 2.1148459911346436
Validation loss: 2.2014443515449442

Epoch: 6| Step: 3
Training loss: 2.2433152198791504
Validation loss: 2.1822751824573805

Epoch: 6| Step: 4
Training loss: 2.188343048095703
Validation loss: 2.228892380191434

Epoch: 6| Step: 5
Training loss: 2.5470073223114014
Validation loss: 2.1790147648062757

Epoch: 6| Step: 6
Training loss: 2.237168788909912
Validation loss: 2.2492204135464084

Epoch: 6| Step: 7
Training loss: 1.8902109861373901
Validation loss: 2.2412260950252576

Epoch: 6| Step: 8
Training loss: 1.1857935190200806
Validation loss: 2.2202351016383015

Epoch: 6| Step: 9
Training loss: 1.7668824195861816
Validation loss: 2.1484489902373283

Epoch: 6| Step: 10
Training loss: 2.0845911502838135
Validation loss: 2.2639374604789158

Epoch: 6| Step: 11
Training loss: 1.386045217514038
Validation loss: 2.2145469034871748

Epoch: 6| Step: 12
Training loss: 2.1351938247680664
Validation loss: 2.2295577192819245

Epoch: 6| Step: 13
Training loss: 1.4579968452453613
Validation loss: 2.3054514623457387

Epoch: 223| Step: 0
Training loss: 2.168274402618408
Validation loss: 2.17092550698147

Epoch: 6| Step: 1
Training loss: 1.8898353576660156
Validation loss: 2.2083443954426754

Epoch: 6| Step: 2
Training loss: 2.586209297180176
Validation loss: 2.213232796679261

Epoch: 6| Step: 3
Training loss: 1.9859678745269775
Validation loss: 2.234508775895642

Epoch: 6| Step: 4
Training loss: 1.5692391395568848
Validation loss: 2.2678508861090547

Epoch: 6| Step: 5
Training loss: 2.0439581871032715
Validation loss: 2.1686760635786158

Epoch: 6| Step: 6
Training loss: 1.9105415344238281
Validation loss: 2.2520727918994043

Epoch: 6| Step: 7
Training loss: 1.7413610219955444
Validation loss: 2.1258108180056334

Epoch: 6| Step: 8
Training loss: 2.6171860694885254
Validation loss: 2.223204279458651

Epoch: 6| Step: 9
Training loss: 1.597994089126587
Validation loss: 2.2532213016222884

Epoch: 6| Step: 10
Training loss: 2.620370388031006
Validation loss: 2.1698395462446314

Epoch: 6| Step: 11
Training loss: 1.6669361591339111
Validation loss: 2.251296088259707

Epoch: 6| Step: 12
Training loss: 2.132680892944336
Validation loss: 2.2056084268836567

Epoch: 6| Step: 13
Training loss: 1.9718843698501587
Validation loss: 2.2269456719839447

Epoch: 224| Step: 0
Training loss: 2.379413604736328
Validation loss: 2.1286651485709736

Epoch: 6| Step: 1
Training loss: 2.0623674392700195
Validation loss: 2.1705024319310344

Epoch: 6| Step: 2
Training loss: 1.9621754884719849
Validation loss: 2.1113206878785165

Epoch: 6| Step: 3
Training loss: 1.7408051490783691
Validation loss: 2.2173560075862433

Epoch: 6| Step: 4
Training loss: 2.1780335903167725
Validation loss: 2.1825518659366074

Epoch: 6| Step: 5
Training loss: 2.023283004760742
Validation loss: 2.197618217878444

Epoch: 6| Step: 6
Training loss: 2.2594733238220215
Validation loss: 2.1591137442537534

Epoch: 6| Step: 7
Training loss: 2.566114902496338
Validation loss: 2.229637797160815

Epoch: 6| Step: 8
Training loss: 1.6424264907836914
Validation loss: 2.20838225144212

Epoch: 6| Step: 9
Training loss: 2.0665483474731445
Validation loss: 2.128321123379533

Epoch: 6| Step: 10
Training loss: 1.6381934881210327
Validation loss: 2.1386395885098364

Epoch: 6| Step: 11
Training loss: 2.0050604343414307
Validation loss: 2.1704842403370845

Epoch: 6| Step: 12
Training loss: 1.905693531036377
Validation loss: 2.0869782099159817

Epoch: 6| Step: 13
Training loss: 2.3065807819366455
Validation loss: 2.1708005371914116

Epoch: 225| Step: 0
Training loss: 2.052008628845215
Validation loss: 2.1326979232090775

Epoch: 6| Step: 1
Training loss: 1.702817440032959
Validation loss: 2.1516479830588064

Epoch: 6| Step: 2
Training loss: 2.400272846221924
Validation loss: 2.1870913902918496

Epoch: 6| Step: 3
Training loss: 1.9269490242004395
Validation loss: 2.174501524176649

Epoch: 6| Step: 4
Training loss: 1.8353766202926636
Validation loss: 2.160019664354222

Epoch: 6| Step: 5
Training loss: 2.059265613555908
Validation loss: 2.185291733793033

Epoch: 6| Step: 6
Training loss: 1.8163355588912964
Validation loss: 2.137656416944278

Epoch: 6| Step: 7
Training loss: 1.9186103343963623
Validation loss: 2.1700514952341714

Epoch: 6| Step: 8
Training loss: 2.3933916091918945
Validation loss: 2.1328830898448987

Epoch: 6| Step: 9
Training loss: 1.5978920459747314
Validation loss: 2.0494222051353863

Epoch: 6| Step: 10
Training loss: 1.7551541328430176
Validation loss: 2.167570311536071

Epoch: 6| Step: 11
Training loss: 1.8325462341308594
Validation loss: 2.1493721495392504

Epoch: 6| Step: 12
Training loss: 2.0586042404174805
Validation loss: 2.102834483628632

Epoch: 6| Step: 13
Training loss: 2.318885326385498
Validation loss: 2.2719892647958573

Epoch: 226| Step: 0
Training loss: 1.771814227104187
Validation loss: 2.1677999675914807

Epoch: 6| Step: 1
Training loss: 2.128164768218994
Validation loss: 2.2025371777114047

Epoch: 6| Step: 2
Training loss: 1.5699567794799805
Validation loss: 2.0860944537706274

Epoch: 6| Step: 3
Training loss: 2.6089653968811035
Validation loss: 2.25448206932314

Epoch: 6| Step: 4
Training loss: 2.1038360595703125
Validation loss: 2.2248416126415296

Epoch: 6| Step: 5
Training loss: 2.390687942504883
Validation loss: 2.166290542130829

Epoch: 6| Step: 6
Training loss: 1.7997558116912842
Validation loss: 2.2795046016734135

Epoch: 6| Step: 7
Training loss: 1.357435941696167
Validation loss: 2.273192619764677

Epoch: 6| Step: 8
Training loss: 1.6498956680297852
Validation loss: 2.2152764874119915

Epoch: 6| Step: 9
Training loss: 2.1504650115966797
Validation loss: 2.201937003802228

Epoch: 6| Step: 10
Training loss: 1.6584043502807617
Validation loss: 2.139539036699521

Epoch: 6| Step: 11
Training loss: 2.25313138961792
Validation loss: 2.228554365455463

Epoch: 6| Step: 12
Training loss: 2.181480884552002
Validation loss: 2.2228642843102895

Epoch: 6| Step: 13
Training loss: 2.299708604812622
Validation loss: 2.2184774337276334

Epoch: 227| Step: 0
Training loss: 2.3675131797790527
Validation loss: 2.1647478841966197

Epoch: 6| Step: 1
Training loss: 2.3296058177948
Validation loss: 2.2839886167997956

Epoch: 6| Step: 2
Training loss: 2.6754660606384277
Validation loss: 2.1588836177702873

Epoch: 6| Step: 3
Training loss: 2.076066732406616
Validation loss: 2.1858412578541744

Epoch: 6| Step: 4
Training loss: 1.5744675397872925
Validation loss: 2.175067524756155

Epoch: 6| Step: 5
Training loss: 1.7402870655059814
Validation loss: 2.1552878528512935

Epoch: 6| Step: 6
Training loss: 2.019129991531372
Validation loss: 2.193916454110094

Epoch: 6| Step: 7
Training loss: 2.1767325401306152
Validation loss: 2.1862964912127425

Epoch: 6| Step: 8
Training loss: 2.10192608833313
Validation loss: 2.1694440892947617

Epoch: 6| Step: 9
Training loss: 2.3354651927948
Validation loss: 2.211468353066393

Epoch: 6| Step: 10
Training loss: 1.4603220224380493
Validation loss: 2.1829251166312926

Epoch: 6| Step: 11
Training loss: 1.850076675415039
Validation loss: 2.1380318236607376

Epoch: 6| Step: 12
Training loss: 1.9697349071502686
Validation loss: 2.18176180829284

Epoch: 6| Step: 13
Training loss: 1.783082365989685
Validation loss: 2.128777427058066

Epoch: 228| Step: 0
Training loss: 1.8074040412902832
Validation loss: 2.2197595719368226

Epoch: 6| Step: 1
Training loss: 2.198680877685547
Validation loss: 2.1759899790569017

Epoch: 6| Step: 2
Training loss: 2.464691162109375
Validation loss: 2.1610896215643933

Epoch: 6| Step: 3
Training loss: 2.1042957305908203
Validation loss: 2.124902532946679

Epoch: 6| Step: 4
Training loss: 2.4632914066314697
Validation loss: 2.228245673641082

Epoch: 6| Step: 5
Training loss: 1.8010478019714355
Validation loss: 2.1653293153291107

Epoch: 6| Step: 6
Training loss: 1.5811569690704346
Validation loss: 2.1173220539605744

Epoch: 6| Step: 7
Training loss: 2.2155632972717285
Validation loss: 2.160432264369021

Epoch: 6| Step: 8
Training loss: 1.5520292520523071
Validation loss: 2.279121042579733

Epoch: 6| Step: 9
Training loss: 1.6335680484771729
Validation loss: 2.2197091758892102

Epoch: 6| Step: 10
Training loss: 1.9687503576278687
Validation loss: 2.236206057251141

Epoch: 6| Step: 11
Training loss: 2.8050312995910645
Validation loss: 2.216707032213929

Epoch: 6| Step: 12
Training loss: 2.382246971130371
Validation loss: 2.2289847302180466

Epoch: 6| Step: 13
Training loss: 1.4553492069244385
Validation loss: 2.17266167876541

Epoch: 229| Step: 0
Training loss: 1.998914122581482
Validation loss: 2.1368571353215042

Epoch: 6| Step: 1
Training loss: 2.0987956523895264
Validation loss: 2.2859815141206146

Epoch: 6| Step: 2
Training loss: 2.0022268295288086
Validation loss: 2.267472092823316

Epoch: 6| Step: 3
Training loss: 2.4490244388580322
Validation loss: 2.210503755077239

Epoch: 6| Step: 4
Training loss: 2.1835875511169434
Validation loss: 2.304724339515932

Epoch: 6| Step: 5
Training loss: 1.5887260437011719
Validation loss: 2.193799549533475

Epoch: 6| Step: 6
Training loss: 2.3550376892089844
Validation loss: 2.2106518565967517

Epoch: 6| Step: 7
Training loss: 2.315837860107422
Validation loss: 2.1520118457014843

Epoch: 6| Step: 8
Training loss: 1.4974485635757446
Validation loss: 2.172958968788065

Epoch: 6| Step: 9
Training loss: 1.563876986503601
Validation loss: 2.1869825470832085

Epoch: 6| Step: 10
Training loss: 1.5431634187698364
Validation loss: 2.141984330710544

Epoch: 6| Step: 11
Training loss: 1.8172495365142822
Validation loss: 2.13637254827766

Epoch: 6| Step: 12
Training loss: 2.0814902782440186
Validation loss: 2.1620378084080194

Epoch: 6| Step: 13
Training loss: 3.216212034225464
Validation loss: 2.1167723824900966

Epoch: 230| Step: 0
Training loss: 2.146606922149658
Validation loss: 2.152429852434384

Epoch: 6| Step: 1
Training loss: 1.8094538450241089
Validation loss: 2.173781262931003

Epoch: 6| Step: 2
Training loss: 1.8886398077011108
Validation loss: 2.198499428328647

Epoch: 6| Step: 3
Training loss: 2.0370185375213623
Validation loss: 2.1971193359744166

Epoch: 6| Step: 4
Training loss: 1.8730623722076416
Validation loss: 2.244854542516893

Epoch: 6| Step: 5
Training loss: 2.154587745666504
Validation loss: 2.239215140701622

Epoch: 6| Step: 6
Training loss: 2.328312873840332
Validation loss: 2.310487867683493

Epoch: 6| Step: 7
Training loss: 1.8449634313583374
Validation loss: 2.157507524695448

Epoch: 6| Step: 8
Training loss: 2.038221597671509
Validation loss: 2.34089659619075

Epoch: 6| Step: 9
Training loss: 1.3561878204345703
Validation loss: 2.1906185560328986

Epoch: 6| Step: 10
Training loss: 1.983115792274475
Validation loss: 2.120828523430773

Epoch: 6| Step: 11
Training loss: 2.745631217956543
Validation loss: 2.262033276660468

Epoch: 6| Step: 12
Training loss: 1.6664109230041504
Validation loss: 2.292856195921539

Epoch: 6| Step: 13
Training loss: 2.098062753677368
Validation loss: 2.256696370340163

Epoch: 231| Step: 0
Training loss: 3.0153794288635254
Validation loss: 2.164473263166284

Epoch: 6| Step: 1
Training loss: 2.6031103134155273
Validation loss: 2.2387504269999843

Epoch: 6| Step: 2
Training loss: 1.6303675174713135
Validation loss: 2.2868945880602767

Epoch: 6| Step: 3
Training loss: 1.9816608428955078
Validation loss: 2.185226503238883

Epoch: 6| Step: 4
Training loss: 2.1320104598999023
Validation loss: 2.2086118933975056

Epoch: 6| Step: 5
Training loss: 1.7271655797958374
Validation loss: 2.25125188724969

Epoch: 6| Step: 6
Training loss: 2.161773681640625
Validation loss: 2.148562809472443

Epoch: 6| Step: 7
Training loss: 1.4701402187347412
Validation loss: 2.102493380987516

Epoch: 6| Step: 8
Training loss: 2.1357836723327637
Validation loss: 2.205377627444524

Epoch: 6| Step: 9
Training loss: 1.7729160785675049
Validation loss: 2.130339676334012

Epoch: 6| Step: 10
Training loss: 1.9638519287109375
Validation loss: 2.0750211054278958

Epoch: 6| Step: 11
Training loss: 2.120058059692383
Validation loss: 2.1910650243041334

Epoch: 6| Step: 12
Training loss: 1.9195847511291504
Validation loss: 2.153219656277728

Epoch: 6| Step: 13
Training loss: 1.9053865671157837
Validation loss: 2.160072103623421

Epoch: 232| Step: 0
Training loss: 2.168090581893921
Validation loss: 2.205940547809806

Epoch: 6| Step: 1
Training loss: 2.134244680404663
Validation loss: 2.1423841548222367

Epoch: 6| Step: 2
Training loss: 1.8784838914871216
Validation loss: 2.217519630667984

Epoch: 6| Step: 3
Training loss: 1.9919586181640625
Validation loss: 2.2198183959530247

Epoch: 6| Step: 4
Training loss: 1.9750924110412598
Validation loss: 2.195251871180791

Epoch: 6| Step: 5
Training loss: 2.076240062713623
Validation loss: 2.239647521767565

Epoch: 6| Step: 6
Training loss: 1.8511829376220703
Validation loss: 2.2225797983907882

Epoch: 6| Step: 7
Training loss: 1.6866388320922852
Validation loss: 2.2874761243020334

Epoch: 6| Step: 8
Training loss: 2.381675958633423
Validation loss: 2.1910753198849258

Epoch: 6| Step: 9
Training loss: 1.5495920181274414
Validation loss: 2.207923525123186

Epoch: 6| Step: 10
Training loss: 2.126540184020996
Validation loss: 2.3103163985795874

Epoch: 6| Step: 11
Training loss: 2.119126319885254
Validation loss: 2.13591093145391

Epoch: 6| Step: 12
Training loss: 1.6036884784698486
Validation loss: 2.105074108287852

Epoch: 6| Step: 13
Training loss: 2.273501396179199
Validation loss: 2.202445771104546

Epoch: 233| Step: 0
Training loss: 2.0048608779907227
Validation loss: 2.25819307245234

Epoch: 6| Step: 1
Training loss: 1.336965799331665
Validation loss: 2.219951791148032

Epoch: 6| Step: 2
Training loss: 1.5477797985076904
Validation loss: 2.197841827587415

Epoch: 6| Step: 3
Training loss: 2.168142795562744
Validation loss: 2.1869856234519713

Epoch: 6| Step: 4
Training loss: 1.8926498889923096
Validation loss: 2.1309240479623117

Epoch: 6| Step: 5
Training loss: 1.6938416957855225
Validation loss: 2.1674241430015972

Epoch: 6| Step: 6
Training loss: 2.828730583190918
Validation loss: 2.1570488406765844

Epoch: 6| Step: 7
Training loss: 2.9168941974639893
Validation loss: 2.070671058470203

Epoch: 6| Step: 8
Training loss: 2.667132616043091
Validation loss: 2.0930490545047227

Epoch: 6| Step: 9
Training loss: 1.5092520713806152
Validation loss: 2.104693633253856

Epoch: 6| Step: 10
Training loss: 1.4633938074111938
Validation loss: 2.163870588425667

Epoch: 6| Step: 11
Training loss: 2.101428508758545
Validation loss: 2.1437135050373692

Epoch: 6| Step: 12
Training loss: 1.702466368675232
Validation loss: 2.1647769122995357

Epoch: 6| Step: 13
Training loss: 2.488537311553955
Validation loss: 2.228350111233291

Epoch: 234| Step: 0
Training loss: 2.183130979537964
Validation loss: 2.200660199247381

Epoch: 6| Step: 1
Training loss: 1.7237927913665771
Validation loss: 2.1331484830507668

Epoch: 6| Step: 2
Training loss: 1.9607053995132446
Validation loss: 2.165559854558719

Epoch: 6| Step: 3
Training loss: 1.822890281677246
Validation loss: 2.1711184337574947

Epoch: 6| Step: 4
Training loss: 1.56342351436615
Validation loss: 2.172510944386964

Epoch: 6| Step: 5
Training loss: 1.759103536605835
Validation loss: 2.1119148346685592

Epoch: 6| Step: 6
Training loss: 1.6596195697784424
Validation loss: 2.2347549135966966

Epoch: 6| Step: 7
Training loss: 2.0496084690093994
Validation loss: 2.239555364014

Epoch: 6| Step: 8
Training loss: 2.283620595932007
Validation loss: 2.2407804740372526

Epoch: 6| Step: 9
Training loss: 2.013310432434082
Validation loss: 2.195304762932562

Epoch: 6| Step: 10
Training loss: 1.7838109731674194
Validation loss: 2.159295815293507

Epoch: 6| Step: 11
Training loss: 2.775752305984497
Validation loss: 2.257820342176704

Epoch: 6| Step: 12
Training loss: 1.8364856243133545
Validation loss: 2.0910748256150113

Epoch: 6| Step: 13
Training loss: 2.3363656997680664
Validation loss: 2.214933968359424

Epoch: 235| Step: 0
Training loss: 1.3057996034622192
Validation loss: 2.1268982195085093

Epoch: 6| Step: 1
Training loss: 1.7988187074661255
Validation loss: 2.193562469174785

Epoch: 6| Step: 2
Training loss: 2.0781335830688477
Validation loss: 2.250876648451692

Epoch: 6| Step: 3
Training loss: 1.4911937713623047
Validation loss: 2.1599153626349663

Epoch: 6| Step: 4
Training loss: 2.314955234527588
Validation loss: 2.2666149088131484

Epoch: 6| Step: 5
Training loss: 1.8779385089874268
Validation loss: 2.0953047557543685

Epoch: 6| Step: 6
Training loss: 2.043795347213745
Validation loss: 2.0692319895631526

Epoch: 6| Step: 7
Training loss: 3.0444929599761963
Validation loss: 2.2395094876648276

Epoch: 6| Step: 8
Training loss: 1.8164563179016113
Validation loss: 2.1456380813352522

Epoch: 6| Step: 9
Training loss: 1.665513515472412
Validation loss: 2.165095090866089

Epoch: 6| Step: 10
Training loss: 1.7661741971969604
Validation loss: 2.1524244457162838

Epoch: 6| Step: 11
Training loss: 1.6678438186645508
Validation loss: 2.1755289980160293

Epoch: 6| Step: 12
Training loss: 2.7811174392700195
Validation loss: 2.122324223159462

Epoch: 6| Step: 13
Training loss: 1.7926058769226074
Validation loss: 2.1612942962236303

Epoch: 236| Step: 0
Training loss: 1.5318435430526733
Validation loss: 2.1727159510376635

Epoch: 6| Step: 1
Training loss: 1.699136734008789
Validation loss: 2.1352162027871735

Epoch: 6| Step: 2
Training loss: 2.144369602203369
Validation loss: 2.153041731926703

Epoch: 6| Step: 3
Training loss: 2.7153549194335938
Validation loss: 2.1526890493208364

Epoch: 6| Step: 4
Training loss: 2.052722454071045
Validation loss: 2.208151986522059

Epoch: 6| Step: 5
Training loss: 2.12699818611145
Validation loss: 2.1670991169509066

Epoch: 6| Step: 6
Training loss: 1.7159996032714844
Validation loss: 2.140688391141994

Epoch: 6| Step: 7
Training loss: 2.5490996837615967
Validation loss: 2.209894211061539

Epoch: 6| Step: 8
Training loss: 1.8511244058609009
Validation loss: 2.241752040001654

Epoch: 6| Step: 9
Training loss: 2.0334126949310303
Validation loss: 2.1552303247554327

Epoch: 6| Step: 10
Training loss: 2.5108871459960938
Validation loss: 2.1745459418142996

Epoch: 6| Step: 11
Training loss: 1.9780998229980469
Validation loss: 2.141376885034705

Epoch: 6| Step: 12
Training loss: 1.4242124557495117
Validation loss: 2.183739677552254

Epoch: 6| Step: 13
Training loss: 1.7664742469787598
Validation loss: 2.143423834154683

Epoch: 237| Step: 0
Training loss: 1.936234951019287
Validation loss: 2.108238381724204

Epoch: 6| Step: 1
Training loss: 2.1046864986419678
Validation loss: 2.318969408671061

Epoch: 6| Step: 2
Training loss: 1.9766188859939575
Validation loss: 2.2415319770895024

Epoch: 6| Step: 3
Training loss: 2.2047314643859863
Validation loss: 2.210720895439066

Epoch: 6| Step: 4
Training loss: 1.9026288986206055
Validation loss: 2.182422640503094

Epoch: 6| Step: 5
Training loss: 1.949312448501587
Validation loss: 2.3111113732860935

Epoch: 6| Step: 6
Training loss: 1.9144489765167236
Validation loss: 2.2574203091283

Epoch: 6| Step: 7
Training loss: 2.0795793533325195
Validation loss: 2.2431719738950013

Epoch: 6| Step: 8
Training loss: 2.0191915035247803
Validation loss: 2.2524026901491228

Epoch: 6| Step: 9
Training loss: 2.1136627197265625
Validation loss: 2.2937198428697485

Epoch: 6| Step: 10
Training loss: 2.0332255363464355
Validation loss: 2.1878320042805006

Epoch: 6| Step: 11
Training loss: 2.593379497528076
Validation loss: 2.1958755011199624

Epoch: 6| Step: 12
Training loss: 1.9475979804992676
Validation loss: 2.2824304283306165

Epoch: 6| Step: 13
Training loss: 1.4351348876953125
Validation loss: 2.230101695624731

Epoch: 238| Step: 0
Training loss: 1.8852825164794922
Validation loss: 2.267979215550166

Epoch: 6| Step: 1
Training loss: 1.6695261001586914
Validation loss: 2.1852666985604072

Epoch: 6| Step: 2
Training loss: 2.502392530441284
Validation loss: 2.1334095167857345

Epoch: 6| Step: 3
Training loss: 1.8440344333648682
Validation loss: 2.1295653389346216

Epoch: 6| Step: 4
Training loss: 1.845633625984192
Validation loss: 2.130752331467085

Epoch: 6| Step: 5
Training loss: 1.9918503761291504
Validation loss: 2.1327580264819566

Epoch: 6| Step: 6
Training loss: 1.9809099435806274
Validation loss: 2.1768607477987967

Epoch: 6| Step: 7
Training loss: 2.605775833129883
Validation loss: 2.1533708956933792

Epoch: 6| Step: 8
Training loss: 1.9067785739898682
Validation loss: 2.081351787813248

Epoch: 6| Step: 9
Training loss: 1.7186388969421387
Validation loss: 2.1443216749416885

Epoch: 6| Step: 10
Training loss: 2.0422019958496094
Validation loss: 2.157209006688928

Epoch: 6| Step: 11
Training loss: 2.059677839279175
Validation loss: 2.1676159994576567

Epoch: 6| Step: 12
Training loss: 1.8077917098999023
Validation loss: 2.183788712306689

Epoch: 6| Step: 13
Training loss: 1.9551734924316406
Validation loss: 2.154137037133658

Epoch: 239| Step: 0
Training loss: 2.0365242958068848
Validation loss: 2.247618729068387

Epoch: 6| Step: 1
Training loss: 1.9345325231552124
Validation loss: 2.171038394333214

Epoch: 6| Step: 2
Training loss: 2.3646044731140137
Validation loss: 2.1630333469760035

Epoch: 6| Step: 3
Training loss: 1.9787062406539917
Validation loss: 2.144729075893279

Epoch: 6| Step: 4
Training loss: 1.6039233207702637
Validation loss: 2.1430498605133383

Epoch: 6| Step: 5
Training loss: 2.037745237350464
Validation loss: 2.270302181602806

Epoch: 6| Step: 6
Training loss: 2.181760787963867
Validation loss: 2.139994334149104

Epoch: 6| Step: 7
Training loss: 1.3585103750228882
Validation loss: 2.1579025483900502

Epoch: 6| Step: 8
Training loss: 2.4491186141967773
Validation loss: 2.2367086154158398

Epoch: 6| Step: 9
Training loss: 1.2860711812973022
Validation loss: 2.265288096602245

Epoch: 6| Step: 10
Training loss: 1.8737001419067383
Validation loss: 2.228709469559372

Epoch: 6| Step: 11
Training loss: 1.7171540260314941
Validation loss: 2.269054623060329

Epoch: 6| Step: 12
Training loss: 2.44464111328125
Validation loss: 2.186224373438025

Epoch: 6| Step: 13
Training loss: 2.128969669342041
Validation loss: 2.1711140678774927

Epoch: 240| Step: 0
Training loss: 1.7492668628692627
Validation loss: 2.1989427945947133

Epoch: 6| Step: 1
Training loss: 1.9267125129699707
Validation loss: 2.178428639647781

Epoch: 6| Step: 2
Training loss: 1.7725749015808105
Validation loss: 2.1467038816021335

Epoch: 6| Step: 3
Training loss: 1.9026570320129395
Validation loss: 2.1869892279307046

Epoch: 6| Step: 4
Training loss: 2.606306314468384
Validation loss: 2.178753101697532

Epoch: 6| Step: 5
Training loss: 1.4921103715896606
Validation loss: 2.247327107255177

Epoch: 6| Step: 6
Training loss: 1.6173714399337769
Validation loss: 2.0980874261548443

Epoch: 6| Step: 7
Training loss: 1.6367461681365967
Validation loss: 2.201110045115153

Epoch: 6| Step: 8
Training loss: 1.8740432262420654
Validation loss: 2.129198182013727

Epoch: 6| Step: 9
Training loss: 2.4555375576019287
Validation loss: 2.2343947374692528

Epoch: 6| Step: 10
Training loss: 2.140690326690674
Validation loss: 2.158895100316694

Epoch: 6| Step: 11
Training loss: 2.719574451446533
Validation loss: 2.108300485918599

Epoch: 6| Step: 12
Training loss: 2.344295024871826
Validation loss: 2.2396252873123332

Epoch: 6| Step: 13
Training loss: 1.5573691129684448
Validation loss: 2.1435044221980597

Epoch: 241| Step: 0
Training loss: 2.111145257949829
Validation loss: 2.1259046036710023

Epoch: 6| Step: 1
Training loss: 1.5506696701049805
Validation loss: 2.1782208899016022

Epoch: 6| Step: 2
Training loss: 2.3758702278137207
Validation loss: 2.154881533756051

Epoch: 6| Step: 3
Training loss: 2.5921010971069336
Validation loss: 2.158109034261396

Epoch: 6| Step: 4
Training loss: 1.5203436613082886
Validation loss: 2.199389168011245

Epoch: 6| Step: 5
Training loss: 1.938582181930542
Validation loss: 2.1604218021515877

Epoch: 6| Step: 6
Training loss: 1.8718098402023315
Validation loss: 2.1477268075430267

Epoch: 6| Step: 7
Training loss: 1.4310561418533325
Validation loss: 2.165660055734778

Epoch: 6| Step: 8
Training loss: 1.438645601272583
Validation loss: 2.131251378725934

Epoch: 6| Step: 9
Training loss: 2.3953113555908203
Validation loss: 2.159075208889541

Epoch: 6| Step: 10
Training loss: 2.3790085315704346
Validation loss: 2.217398549920769

Epoch: 6| Step: 11
Training loss: 1.6901018619537354
Validation loss: 2.1323806457622076

Epoch: 6| Step: 12
Training loss: 2.5514955520629883
Validation loss: 2.1853700401962444

Epoch: 6| Step: 13
Training loss: 1.8999459743499756
Validation loss: 2.2007083892822266

Epoch: 242| Step: 0
Training loss: 2.677520275115967
Validation loss: 2.256063102394022

Epoch: 6| Step: 1
Training loss: 1.4092893600463867
Validation loss: 2.2116434240853913

Epoch: 6| Step: 2
Training loss: 1.8963247537612915
Validation loss: 2.27096567615386

Epoch: 6| Step: 3
Training loss: 1.3986268043518066
Validation loss: 2.222442255225233

Epoch: 6| Step: 4
Training loss: 1.8443787097930908
Validation loss: 2.1838644127691946

Epoch: 6| Step: 5
Training loss: 1.4642796516418457
Validation loss: 2.2294866269634617

Epoch: 6| Step: 6
Training loss: 1.8356664180755615
Validation loss: 2.1321689890277002

Epoch: 6| Step: 7
Training loss: 1.9897100925445557
Validation loss: 2.1741383293623566

Epoch: 6| Step: 8
Training loss: 1.9636117219924927
Validation loss: 2.2121244861233618

Epoch: 6| Step: 9
Training loss: 2.07125186920166
Validation loss: 2.2118359945153676

Epoch: 6| Step: 10
Training loss: 2.802891254425049
Validation loss: 2.19638575789749

Epoch: 6| Step: 11
Training loss: 1.4891432523727417
Validation loss: 2.140174808040742

Epoch: 6| Step: 12
Training loss: 2.2878611087799072
Validation loss: 2.191482118380967

Epoch: 6| Step: 13
Training loss: 2.8555400371551514
Validation loss: 2.0806250751659436

Epoch: 243| Step: 0
Training loss: 2.2072577476501465
Validation loss: 2.25295695822726

Epoch: 6| Step: 1
Training loss: 2.343020439147949
Validation loss: 2.176928030547275

Epoch: 6| Step: 2
Training loss: 2.085252046585083
Validation loss: 2.0892852301238687

Epoch: 6| Step: 3
Training loss: 2.2882237434387207
Validation loss: 2.0639357079741774

Epoch: 6| Step: 4
Training loss: 1.5158581733703613
Validation loss: 2.199803429265176

Epoch: 6| Step: 5
Training loss: 1.9238711595535278
Validation loss: 2.166032703973914

Epoch: 6| Step: 6
Training loss: 1.552066683769226
Validation loss: 2.1012035762110064

Epoch: 6| Step: 7
Training loss: 1.976775884628296
Validation loss: 2.1188642094212193

Epoch: 6| Step: 8
Training loss: 1.6281332969665527
Validation loss: 2.0288978084441154

Epoch: 6| Step: 9
Training loss: 1.8496947288513184
Validation loss: 2.241955384131401

Epoch: 6| Step: 10
Training loss: 2.3906171321868896
Validation loss: 2.15308391791518

Epoch: 6| Step: 11
Training loss: 1.9798649549484253
Validation loss: 2.2186879996330506

Epoch: 6| Step: 12
Training loss: 1.6735804080963135
Validation loss: 2.1491997344519502

Epoch: 6| Step: 13
Training loss: 2.2600979804992676
Validation loss: 2.148004367787351

Epoch: 244| Step: 0
Training loss: 2.4598493576049805
Validation loss: 2.1136458804530482

Epoch: 6| Step: 1
Training loss: 2.2349839210510254
Validation loss: 2.1038374772635837

Epoch: 6| Step: 2
Training loss: 1.9844715595245361
Validation loss: 2.1877653060420865

Epoch: 6| Step: 3
Training loss: 2.8646388053894043
Validation loss: 2.1613883279984996

Epoch: 6| Step: 4
Training loss: 1.3620532751083374
Validation loss: 2.186135102343816

Epoch: 6| Step: 5
Training loss: 2.2528467178344727
Validation loss: 2.1841583867226877

Epoch: 6| Step: 6
Training loss: 2.152799129486084
Validation loss: 2.2297738470057005

Epoch: 6| Step: 7
Training loss: 1.796567440032959
Validation loss: 2.1115449320885444

Epoch: 6| Step: 8
Training loss: 1.4430370330810547
Validation loss: 2.189589087681104

Epoch: 6| Step: 9
Training loss: 2.015545606613159
Validation loss: 2.1400551642141035

Epoch: 6| Step: 10
Training loss: 1.7806947231292725
Validation loss: 2.1045598368490896

Epoch: 6| Step: 11
Training loss: 1.8043290376663208
Validation loss: 2.244593951009935

Epoch: 6| Step: 12
Training loss: 1.9260029792785645
Validation loss: 2.173843110761335

Epoch: 6| Step: 13
Training loss: 1.790936827659607
Validation loss: 2.1657113464929725

Epoch: 245| Step: 0
Training loss: 1.6242902278900146
Validation loss: 2.161806344985962

Epoch: 6| Step: 1
Training loss: 1.9888112545013428
Validation loss: 2.2212723314121203

Epoch: 6| Step: 2
Training loss: 2.0500755310058594
Validation loss: 2.15901784230304

Epoch: 6| Step: 3
Training loss: 3.0890774726867676
Validation loss: 2.1279204071208997

Epoch: 6| Step: 4
Training loss: 1.8278236389160156
Validation loss: 2.194800715292654

Epoch: 6| Step: 5
Training loss: 1.7106013298034668
Validation loss: 2.1283762352440947

Epoch: 6| Step: 6
Training loss: 2.1890854835510254
Validation loss: 2.1516358326840144

Epoch: 6| Step: 7
Training loss: 2.1029672622680664
Validation loss: 2.1497065200600574

Epoch: 6| Step: 8
Training loss: 1.75412917137146
Validation loss: 2.127986292685232

Epoch: 6| Step: 9
Training loss: 2.1164252758026123
Validation loss: 2.186725636964203

Epoch: 6| Step: 10
Training loss: 1.9919319152832031
Validation loss: 2.215650230325678

Epoch: 6| Step: 11
Training loss: 1.7522631883621216
Validation loss: 2.1338535739529516

Epoch: 6| Step: 12
Training loss: 1.5201928615570068
Validation loss: 2.20674495286839

Epoch: 6| Step: 13
Training loss: 0.8594497442245483
Validation loss: 2.094521055939377

Epoch: 246| Step: 0
Training loss: 1.4850819110870361
Validation loss: 2.249482975211195

Epoch: 6| Step: 1
Training loss: 1.9969744682312012
Validation loss: 2.1166716198767386

Epoch: 6| Step: 2
Training loss: 1.4011685848236084
Validation loss: 2.107460800037589

Epoch: 6| Step: 3
Training loss: 2.304332733154297
Validation loss: 2.168000603234896

Epoch: 6| Step: 4
Training loss: 1.7383346557617188
Validation loss: 2.1631167627150014

Epoch: 6| Step: 5
Training loss: 2.0943212509155273
Validation loss: 2.1956243694469495

Epoch: 6| Step: 6
Training loss: 1.9560458660125732
Validation loss: 2.1226126968219714

Epoch: 6| Step: 7
Training loss: 2.4145054817199707
Validation loss: 2.131277873951902

Epoch: 6| Step: 8
Training loss: 2.1031742095947266
Validation loss: 2.120383672816779

Epoch: 6| Step: 9
Training loss: 3.0098376274108887
Validation loss: 2.1094174487616426

Epoch: 6| Step: 10
Training loss: 1.6647783517837524
Validation loss: 2.2169905144681215

Epoch: 6| Step: 11
Training loss: 1.7165892124176025
Validation loss: 2.1705194968049244

Epoch: 6| Step: 12
Training loss: 2.1971793174743652
Validation loss: 2.1261355543649323

Epoch: 6| Step: 13
Training loss: 1.997933268547058
Validation loss: 2.097230924073086

Epoch: 247| Step: 0
Training loss: 2.2147979736328125
Validation loss: 2.1682118395323395

Epoch: 6| Step: 1
Training loss: 1.9418470859527588
Validation loss: 2.1259537435347036

Epoch: 6| Step: 2
Training loss: 2.206214427947998
Validation loss: 2.1284307613167712

Epoch: 6| Step: 3
Training loss: 1.8258700370788574
Validation loss: 2.1854963379521526

Epoch: 6| Step: 4
Training loss: 1.7450473308563232
Validation loss: 2.185708366414552

Epoch: 6| Step: 5
Training loss: 2.3386380672454834
Validation loss: 2.1644226863820064

Epoch: 6| Step: 6
Training loss: 1.5899518728256226
Validation loss: 2.211850978994882

Epoch: 6| Step: 7
Training loss: 1.8783186674118042
Validation loss: 2.1823735044848536

Epoch: 6| Step: 8
Training loss: 1.8080780506134033
Validation loss: 2.146565532171598

Epoch: 6| Step: 9
Training loss: 2.359109878540039
Validation loss: 2.214348457192862

Epoch: 6| Step: 10
Training loss: 1.8755594491958618
Validation loss: 2.110808037942456

Epoch: 6| Step: 11
Training loss: 1.6999123096466064
Validation loss: 2.193315782854634

Epoch: 6| Step: 12
Training loss: 2.0882346630096436
Validation loss: 2.1562185364384807

Epoch: 6| Step: 13
Training loss: 2.0422651767730713
Validation loss: 2.2259576666739678

Epoch: 248| Step: 0
Training loss: 1.3465018272399902
Validation loss: 2.1166682832984516

Epoch: 6| Step: 1
Training loss: 1.7462830543518066
Validation loss: 2.107064449658958

Epoch: 6| Step: 2
Training loss: 2.1562767028808594
Validation loss: 2.1102636142443587

Epoch: 6| Step: 3
Training loss: 1.5952101945877075
Validation loss: 2.1575641016806326

Epoch: 6| Step: 4
Training loss: 2.312540292739868
Validation loss: 2.1649859925752044

Epoch: 6| Step: 5
Training loss: 2.2288479804992676
Validation loss: 2.137123341201454

Epoch: 6| Step: 6
Training loss: 2.032121419906616
Validation loss: 2.074952330640567

Epoch: 6| Step: 7
Training loss: 1.4141812324523926
Validation loss: 2.2214723017907914

Epoch: 6| Step: 8
Training loss: 2.4718637466430664
Validation loss: 2.2241078679279616

Epoch: 6| Step: 9
Training loss: 1.689009428024292
Validation loss: 2.249538880522533

Epoch: 6| Step: 10
Training loss: 1.6595299243927002
Validation loss: 2.109547793224294

Epoch: 6| Step: 11
Training loss: 2.0305063724517822
Validation loss: 2.2241345784997426

Epoch: 6| Step: 12
Training loss: 2.3731777667999268
Validation loss: 2.153371851931336

Epoch: 6| Step: 13
Training loss: 2.044440746307373
Validation loss: 2.193955090738112

Epoch: 249| Step: 0
Training loss: 2.3531670570373535
Validation loss: 2.2220817150608188

Epoch: 6| Step: 1
Training loss: 2.304145336151123
Validation loss: 2.3353264639454503

Epoch: 6| Step: 2
Training loss: 2.0487589836120605
Validation loss: 2.1659479961600354

Epoch: 6| Step: 3
Training loss: 2.0412192344665527
Validation loss: 2.215122115227484

Epoch: 6| Step: 4
Training loss: 2.103745222091675
Validation loss: 2.2068657823788222

Epoch: 6| Step: 5
Training loss: 1.6336162090301514
Validation loss: 2.207458649912188

Epoch: 6| Step: 6
Training loss: 1.5931476354599
Validation loss: 2.30846800855411

Epoch: 6| Step: 7
Training loss: 2.8934569358825684
Validation loss: 2.249577171059065

Epoch: 6| Step: 8
Training loss: 2.100276470184326
Validation loss: 2.2254761008806128

Epoch: 6| Step: 9
Training loss: 1.4750921726226807
Validation loss: 2.317954412070654

Epoch: 6| Step: 10
Training loss: 1.4203367233276367
Validation loss: 2.3088369343870427

Epoch: 6| Step: 11
Training loss: 2.273601531982422
Validation loss: 2.252645751481415

Epoch: 6| Step: 12
Training loss: 2.0196573734283447
Validation loss: 2.2133330581008748

Epoch: 6| Step: 13
Training loss: 1.6131633520126343
Validation loss: 2.262962923255018

Epoch: 250| Step: 0
Training loss: 1.8238000869750977
Validation loss: 2.226576869205762

Epoch: 6| Step: 1
Training loss: 1.8619974851608276
Validation loss: 2.1484791168602566

Epoch: 6| Step: 2
Training loss: 2.4842381477355957
Validation loss: 2.195986513168581

Epoch: 6| Step: 3
Training loss: 1.8715091943740845
Validation loss: 2.2174956990826513

Epoch: 6| Step: 4
Training loss: 2.0919156074523926
Validation loss: 2.161467768812692

Epoch: 6| Step: 5
Training loss: 1.9609917402267456
Validation loss: 2.0947689176887594

Epoch: 6| Step: 6
Training loss: 1.5584053993225098
Validation loss: 2.1344758772080943

Epoch: 6| Step: 7
Training loss: 2.4039833545684814
Validation loss: 2.203689959741408

Epoch: 6| Step: 8
Training loss: 1.9458072185516357
Validation loss: 2.203073678478118

Epoch: 6| Step: 9
Training loss: 1.8924131393432617
Validation loss: 2.1498405036105903

Epoch: 6| Step: 10
Training loss: 2.2548141479492188
Validation loss: 2.107697061313096

Epoch: 6| Step: 11
Training loss: 1.7701494693756104
Validation loss: 2.199753620291269

Epoch: 6| Step: 12
Training loss: 2.3228979110717773
Validation loss: 2.1413487388241674

Epoch: 6| Step: 13
Training loss: 0.7205994725227356
Validation loss: 2.151265431475896

Epoch: 251| Step: 0
Training loss: 1.741336703300476
Validation loss: 2.06007339877467

Epoch: 6| Step: 1
Training loss: 1.7322238683700562
Validation loss: 2.1281463241064422

Epoch: 6| Step: 2
Training loss: 2.1874754428863525
Validation loss: 2.1594807101834204

Epoch: 6| Step: 3
Training loss: 1.6913424730300903
Validation loss: 2.1903621996602705

Epoch: 6| Step: 4
Training loss: 2.257129192352295
Validation loss: 2.0990036815725346

Epoch: 6| Step: 5
Training loss: 1.579225778579712
Validation loss: 2.168216043902982

Epoch: 6| Step: 6
Training loss: 2.3478660583496094
Validation loss: 2.0977068716479885

Epoch: 6| Step: 7
Training loss: 1.9416875839233398
Validation loss: 2.1284737984339395

Epoch: 6| Step: 8
Training loss: 2.456333875656128
Validation loss: 2.101366816028472

Epoch: 6| Step: 9
Training loss: 2.0637567043304443
Validation loss: 2.072081181310838

Epoch: 6| Step: 10
Training loss: 2.341162919998169
Validation loss: 2.035007348624609

Epoch: 6| Step: 11
Training loss: 2.175811767578125
Validation loss: 2.139095498669532

Epoch: 6| Step: 12
Training loss: 1.6849756240844727
Validation loss: 2.110722323899628

Epoch: 6| Step: 13
Training loss: 1.0676188468933105
Validation loss: 2.1743820405775502

Epoch: 252| Step: 0
Training loss: 2.6449167728424072
Validation loss: 2.137382394524031

Epoch: 6| Step: 1
Training loss: 1.4258838891983032
Validation loss: 2.210619762379636

Epoch: 6| Step: 2
Training loss: 2.324925661087036
Validation loss: 2.1260179832417476

Epoch: 6| Step: 3
Training loss: 2.237537384033203
Validation loss: 2.112074951971731

Epoch: 6| Step: 4
Training loss: 1.6822535991668701
Validation loss: 2.126121732496446

Epoch: 6| Step: 5
Training loss: 1.623199224472046
Validation loss: 2.221572350430232

Epoch: 6| Step: 6
Training loss: 1.7088713645935059
Validation loss: 2.2784096810125534

Epoch: 6| Step: 7
Training loss: 1.7794551849365234
Validation loss: 2.2931690267337266

Epoch: 6| Step: 8
Training loss: 2.503906488418579
Validation loss: 2.1797491299208773

Epoch: 6| Step: 9
Training loss: 1.5900633335113525
Validation loss: 2.2192712547958537

Epoch: 6| Step: 10
Training loss: 2.2974464893341064
Validation loss: 2.1420897694044214

Epoch: 6| Step: 11
Training loss: 2.0148048400878906
Validation loss: 2.204572923721806

Epoch: 6| Step: 12
Training loss: 1.8382954597473145
Validation loss: 2.194270033990183

Epoch: 6| Step: 13
Training loss: 2.3548965454101562
Validation loss: 2.130728174281377

Epoch: 253| Step: 0
Training loss: 2.1771836280822754
Validation loss: 2.2419574132529636

Epoch: 6| Step: 1
Training loss: 2.0153305530548096
Validation loss: 2.245450404382521

Epoch: 6| Step: 2
Training loss: 1.4320034980773926
Validation loss: 2.1680941068997948

Epoch: 6| Step: 3
Training loss: 1.8276184797286987
Validation loss: 2.1786232404811408

Epoch: 6| Step: 4
Training loss: 2.0958988666534424
Validation loss: 2.1410417236307615

Epoch: 6| Step: 5
Training loss: 2.404974937438965
Validation loss: 2.1952659404405983

Epoch: 6| Step: 6
Training loss: 1.7473745346069336
Validation loss: 2.118855184124362

Epoch: 6| Step: 7
Training loss: 1.808611512184143
Validation loss: 2.117209683182419

Epoch: 6| Step: 8
Training loss: 1.6200437545776367
Validation loss: 2.0600180343915055

Epoch: 6| Step: 9
Training loss: 1.0837669372558594
Validation loss: 2.235450912547368

Epoch: 6| Step: 10
Training loss: 1.5351600646972656
Validation loss: 2.169883845954813

Epoch: 6| Step: 11
Training loss: 2.6597516536712646
Validation loss: 2.2429764552782943

Epoch: 6| Step: 12
Training loss: 2.8182172775268555
Validation loss: 2.26023857824264

Epoch: 6| Step: 13
Training loss: 1.791190505027771
Validation loss: 2.104252920355848

Epoch: 254| Step: 0
Training loss: 2.0048911571502686
Validation loss: 2.082064345318784

Epoch: 6| Step: 1
Training loss: 1.7759219408035278
Validation loss: 2.214074691136678

Epoch: 6| Step: 2
Training loss: 1.8880014419555664
Validation loss: 2.2341274933148454

Epoch: 6| Step: 3
Training loss: 1.788740634918213
Validation loss: 2.14265610325721

Epoch: 6| Step: 4
Training loss: 1.8523545265197754
Validation loss: 2.1774715428711264

Epoch: 6| Step: 5
Training loss: 2.492896795272827
Validation loss: 2.206615132670249

Epoch: 6| Step: 6
Training loss: 2.0975747108459473
Validation loss: 2.1205412880066903

Epoch: 6| Step: 7
Training loss: 1.7576730251312256
Validation loss: 2.149727754695441

Epoch: 6| Step: 8
Training loss: 1.465132474899292
Validation loss: 2.2472103231696674

Epoch: 6| Step: 9
Training loss: 2.204277753829956
Validation loss: 2.2222820340946154

Epoch: 6| Step: 10
Training loss: 2.3498716354370117
Validation loss: 2.15250886383877

Epoch: 6| Step: 11
Training loss: 1.80035400390625
Validation loss: 2.14159716585631

Epoch: 6| Step: 12
Training loss: 2.004027843475342
Validation loss: 2.055670489547073

Epoch: 6| Step: 13
Training loss: 1.5135653018951416
Validation loss: 2.2121640584802114

Epoch: 255| Step: 0
Training loss: 1.304362177848816
Validation loss: 2.1758465754088534

Epoch: 6| Step: 1
Training loss: 1.6933727264404297
Validation loss: 2.3188343689005864

Epoch: 6| Step: 2
Training loss: 2.3827362060546875
Validation loss: 2.2365911058200303

Epoch: 6| Step: 3
Training loss: 1.7350306510925293
Validation loss: 2.2384805128138554

Epoch: 6| Step: 4
Training loss: 2.1597208976745605
Validation loss: 2.1330980972577165

Epoch: 6| Step: 5
Training loss: 1.922731637954712
Validation loss: 2.217143976560203

Epoch: 6| Step: 6
Training loss: 2.0578463077545166
Validation loss: 2.291471581305227

Epoch: 6| Step: 7
Training loss: 2.2731237411499023
Validation loss: 2.1609361248631633

Epoch: 6| Step: 8
Training loss: 1.9717530012130737
Validation loss: 2.2108298578569965

Epoch: 6| Step: 9
Training loss: 2.1215291023254395
Validation loss: 2.1732102183885473

Epoch: 6| Step: 10
Training loss: 1.6063346862792969
Validation loss: 2.1038830075212704

Epoch: 6| Step: 11
Training loss: 2.075376272201538
Validation loss: 2.210017669585443

Epoch: 6| Step: 12
Training loss: 2.0507352352142334
Validation loss: 2.1911536173153947

Epoch: 6| Step: 13
Training loss: 1.4056082963943481
Validation loss: 2.158025509567671

Epoch: 256| Step: 0
Training loss: 2.0660243034362793
Validation loss: 2.2507602091758483

Epoch: 6| Step: 1
Training loss: 2.019071340560913
Validation loss: 2.1382666813429965

Epoch: 6| Step: 2
Training loss: 2.706007480621338
Validation loss: 2.2475570350564937

Epoch: 6| Step: 3
Training loss: 1.5477263927459717
Validation loss: 2.216956241156465

Epoch: 6| Step: 4
Training loss: 1.5019679069519043
Validation loss: 2.249587553803639

Epoch: 6| Step: 5
Training loss: 1.6453936100006104
Validation loss: 2.2199762277705695

Epoch: 6| Step: 6
Training loss: 1.0708261728286743
Validation loss: 2.1887769750369492

Epoch: 6| Step: 7
Training loss: 2.583627700805664
Validation loss: 2.224201031910476

Epoch: 6| Step: 8
Training loss: 1.8068844079971313
Validation loss: 2.0820470779172835

Epoch: 6| Step: 9
Training loss: 1.2683273553848267
Validation loss: 2.1984123209471345

Epoch: 6| Step: 10
Training loss: 2.772416353225708
Validation loss: 2.156039391794512

Epoch: 6| Step: 11
Training loss: 2.1069302558898926
Validation loss: 2.2261610992493166

Epoch: 6| Step: 12
Training loss: 1.9661399126052856
Validation loss: 2.1327091135004514

Epoch: 6| Step: 13
Training loss: 2.109102487564087
Validation loss: 2.072225703988024

Epoch: 257| Step: 0
Training loss: 2.199291467666626
Validation loss: 2.1757890178311254

Epoch: 6| Step: 1
Training loss: 2.6410601139068604
Validation loss: 2.2000282118397374

Epoch: 6| Step: 2
Training loss: 1.51659095287323
Validation loss: 2.1975246244861233

Epoch: 6| Step: 3
Training loss: 1.822091817855835
Validation loss: 2.1694682477622904

Epoch: 6| Step: 4
Training loss: 1.841707468032837
Validation loss: 2.205861968378867

Epoch: 6| Step: 5
Training loss: 1.687090516090393
Validation loss: 2.2055755879289363

Epoch: 6| Step: 6
Training loss: 2.6299567222595215
Validation loss: 2.1595582372398785

Epoch: 6| Step: 7
Training loss: 2.251391887664795
Validation loss: 2.158087868844309

Epoch: 6| Step: 8
Training loss: 1.9157993793487549
Validation loss: 2.1508972388441845

Epoch: 6| Step: 9
Training loss: 2.1636974811553955
Validation loss: 2.2758423666800223

Epoch: 6| Step: 10
Training loss: 1.6448532342910767
Validation loss: 2.120689651017548

Epoch: 6| Step: 11
Training loss: 2.357429265975952
Validation loss: 2.1680872722338607

Epoch: 6| Step: 12
Training loss: 1.0348320007324219
Validation loss: 2.140855064956091

Epoch: 6| Step: 13
Training loss: 2.1085286140441895
Validation loss: 2.1662707597978654

Epoch: 258| Step: 0
Training loss: 2.218689203262329
Validation loss: 2.2860567364641415

Epoch: 6| Step: 1
Training loss: 1.885758399963379
Validation loss: 2.123458553385991

Epoch: 6| Step: 2
Training loss: 1.6563981771469116
Validation loss: 2.1267363243205573

Epoch: 6| Step: 3
Training loss: 1.8976331949234009
Validation loss: 2.1556790054485364

Epoch: 6| Step: 4
Training loss: 2.181725025177002
Validation loss: 2.2082429752554944

Epoch: 6| Step: 5
Training loss: 2.5391972064971924
Validation loss: 2.0989243035675376

Epoch: 6| Step: 6
Training loss: 1.8822318315505981
Validation loss: 2.1733363354077904

Epoch: 6| Step: 7
Training loss: 1.8940359354019165
Validation loss: 2.093207020913401

Epoch: 6| Step: 8
Training loss: 1.6776189804077148
Validation loss: 2.1304429859243412

Epoch: 6| Step: 9
Training loss: 1.8739922046661377
Validation loss: 2.1900642366819483

Epoch: 6| Step: 10
Training loss: 1.9404433965682983
Validation loss: 2.1882238952062463

Epoch: 6| Step: 11
Training loss: 2.36930513381958
Validation loss: 2.1134150720411733

Epoch: 6| Step: 12
Training loss: 1.6896694898605347
Validation loss: 2.125644608210492

Epoch: 6| Step: 13
Training loss: 2.057509660720825
Validation loss: 2.0750356297339163

Epoch: 259| Step: 0
Training loss: 2.0820388793945312
Validation loss: 2.1411711938919558

Epoch: 6| Step: 1
Training loss: 2.1924304962158203
Validation loss: 2.158025231412662

Epoch: 6| Step: 2
Training loss: 1.745126485824585
Validation loss: 2.1457778689681843

Epoch: 6| Step: 3
Training loss: 1.7834973335266113
Validation loss: 2.167892958528252

Epoch: 6| Step: 4
Training loss: 1.762062668800354
Validation loss: 2.151136311151648

Epoch: 6| Step: 5
Training loss: 1.8704478740692139
Validation loss: 2.143435555119668

Epoch: 6| Step: 6
Training loss: 2.73295259475708
Validation loss: 2.1893163316993305

Epoch: 6| Step: 7
Training loss: 1.9178802967071533
Validation loss: 2.121707095894762

Epoch: 6| Step: 8
Training loss: 1.492268443107605
Validation loss: 2.1137259775592434

Epoch: 6| Step: 9
Training loss: 1.4937399625778198
Validation loss: 2.2044776998540407

Epoch: 6| Step: 10
Training loss: 2.0020618438720703
Validation loss: 2.1547705076074086

Epoch: 6| Step: 11
Training loss: 2.161635637283325
Validation loss: 2.180865010907573

Epoch: 6| Step: 12
Training loss: 2.0154552459716797
Validation loss: 2.166840760938583

Epoch: 6| Step: 13
Training loss: 2.303978443145752
Validation loss: 2.2415274907183904

Epoch: 260| Step: 0
Training loss: 2.1138558387756348
Validation loss: 2.236747157189154

Epoch: 6| Step: 1
Training loss: 1.7698986530303955
Validation loss: 2.2002783821475123

Epoch: 6| Step: 2
Training loss: 2.1633214950561523
Validation loss: 2.212857605308615

Epoch: 6| Step: 3
Training loss: 1.6169265508651733
Validation loss: 2.271341716089556

Epoch: 6| Step: 4
Training loss: 2.1978986263275146
Validation loss: 2.2153343564720562

Epoch: 6| Step: 5
Training loss: 1.6918967962265015
Validation loss: 2.215686749386531

Epoch: 6| Step: 6
Training loss: 2.512007713317871
Validation loss: 2.173052751889793

Epoch: 6| Step: 7
Training loss: 1.6148462295532227
Validation loss: 2.2035323112241683

Epoch: 6| Step: 8
Training loss: 1.418176293373108
Validation loss: 2.210463975065498

Epoch: 6| Step: 9
Training loss: 1.689249873161316
Validation loss: 2.244702903173303

Epoch: 6| Step: 10
Training loss: 2.013913631439209
Validation loss: 2.1546980821958153

Epoch: 6| Step: 11
Training loss: 2.2250776290893555
Validation loss: 2.1902884949919996

Epoch: 6| Step: 12
Training loss: 1.5967693328857422
Validation loss: 2.200026992828615

Epoch: 6| Step: 13
Training loss: 2.3534035682678223
Validation loss: 2.190300815848894

Epoch: 261| Step: 0
Training loss: 2.2743139266967773
Validation loss: 2.1941042677048714

Epoch: 6| Step: 1
Training loss: 1.6749382019042969
Validation loss: 2.200302211187219

Epoch: 6| Step: 2
Training loss: 2.114098072052002
Validation loss: 2.167946054089454

Epoch: 6| Step: 3
Training loss: 1.9619108438491821
Validation loss: 2.1888222156032437

Epoch: 6| Step: 4
Training loss: 1.1654460430145264
Validation loss: 2.1556964458957797

Epoch: 6| Step: 5
Training loss: 2.0289783477783203
Validation loss: 2.1952579944364485

Epoch: 6| Step: 6
Training loss: 1.3186819553375244
Validation loss: 2.1176130861364384

Epoch: 6| Step: 7
Training loss: 1.4675703048706055
Validation loss: 2.2061766552668747

Epoch: 6| Step: 8
Training loss: 2.2724523544311523
Validation loss: 2.130993430332471

Epoch: 6| Step: 9
Training loss: 1.94071364402771
Validation loss: 2.2119598670672347

Epoch: 6| Step: 10
Training loss: 1.9460395574569702
Validation loss: 2.1616852539841847

Epoch: 6| Step: 11
Training loss: 2.52276349067688
Validation loss: 2.1459366583055064

Epoch: 6| Step: 12
Training loss: 2.8846235275268555
Validation loss: 2.1384897116691834

Epoch: 6| Step: 13
Training loss: 1.553178310394287
Validation loss: 2.1988337962858138

Epoch: 262| Step: 0
Training loss: 1.821390986442566
Validation loss: 2.138419169251637

Epoch: 6| Step: 1
Training loss: 1.5347219705581665
Validation loss: 2.2076930166572653

Epoch: 6| Step: 2
Training loss: 1.9348243474960327
Validation loss: 2.189135411734222

Epoch: 6| Step: 3
Training loss: 1.849074125289917
Validation loss: 2.2600106218809723

Epoch: 6| Step: 4
Training loss: 2.1834681034088135
Validation loss: 2.1355169306519213

Epoch: 6| Step: 5
Training loss: 2.410665512084961
Validation loss: 2.16917017070196

Epoch: 6| Step: 6
Training loss: 1.5000563859939575
Validation loss: 2.0897391047528995

Epoch: 6| Step: 7
Training loss: 2.12211012840271
Validation loss: 2.2248504366925967

Epoch: 6| Step: 8
Training loss: 1.834992527961731
Validation loss: 2.192570686340332

Epoch: 6| Step: 9
Training loss: 2.0358619689941406
Validation loss: 2.0600639184316

Epoch: 6| Step: 10
Training loss: 1.8607141971588135
Validation loss: 2.128129597633116

Epoch: 6| Step: 11
Training loss: 1.579046607017517
Validation loss: 2.11282838800902

Epoch: 6| Step: 12
Training loss: 2.5216541290283203
Validation loss: 2.1203580620468303

Epoch: 6| Step: 13
Training loss: 2.4685347080230713
Validation loss: 2.1257320040015766

Epoch: 263| Step: 0
Training loss: 1.7494637966156006
Validation loss: 2.1902475844147387

Epoch: 6| Step: 1
Training loss: 1.4635424613952637
Validation loss: 2.2214080479837235

Epoch: 6| Step: 2
Training loss: 2.1298866271972656
Validation loss: 2.2702447086252193

Epoch: 6| Step: 3
Training loss: 1.8649587631225586
Validation loss: 2.2188549759567424

Epoch: 6| Step: 4
Training loss: 2.019319534301758
Validation loss: 2.123192307769611

Epoch: 6| Step: 5
Training loss: 1.9502596855163574
Validation loss: 2.200863607468144

Epoch: 6| Step: 6
Training loss: 2.544943332672119
Validation loss: 2.1593138428144556

Epoch: 6| Step: 7
Training loss: 2.2929625511169434
Validation loss: 2.173882636972653

Epoch: 6| Step: 8
Training loss: 1.515161395072937
Validation loss: 2.268025213672269

Epoch: 6| Step: 9
Training loss: 2.2235684394836426
Validation loss: 2.160350538069202

Epoch: 6| Step: 10
Training loss: 2.021989583969116
Validation loss: 2.1707004116427515

Epoch: 6| Step: 11
Training loss: 2.4087581634521484
Validation loss: 2.243832313886253

Epoch: 6| Step: 12
Training loss: 1.551922082901001
Validation loss: 2.252762068984329

Epoch: 6| Step: 13
Training loss: 1.6614375114440918
Validation loss: 2.161608349892401

Epoch: 264| Step: 0
Training loss: 2.4146456718444824
Validation loss: 2.2671217687668337

Epoch: 6| Step: 1
Training loss: 1.552307367324829
Validation loss: 2.152815341949463

Epoch: 6| Step: 2
Training loss: 1.8471925258636475
Validation loss: 2.1133826624962593

Epoch: 6| Step: 3
Training loss: 1.8471759557724
Validation loss: 2.202326273405424

Epoch: 6| Step: 4
Training loss: 2.0500693321228027
Validation loss: 2.2349975237282376

Epoch: 6| Step: 5
Training loss: 2.6471166610717773
Validation loss: 2.271768949365103

Epoch: 6| Step: 6
Training loss: 1.5497578382492065
Validation loss: 2.1602043426165016

Epoch: 6| Step: 7
Training loss: 2.2947182655334473
Validation loss: 2.1400259335835776

Epoch: 6| Step: 8
Training loss: 1.5484548807144165
Validation loss: 2.1525094791125228

Epoch: 6| Step: 9
Training loss: 1.579071283340454
Validation loss: 2.175825680455854

Epoch: 6| Step: 10
Training loss: 2.308333396911621
Validation loss: 2.1209158359035367

Epoch: 6| Step: 11
Training loss: 1.969036340713501
Validation loss: 2.1137356527390017

Epoch: 6| Step: 12
Training loss: 1.937129020690918
Validation loss: 2.1783037711215276

Epoch: 6| Step: 13
Training loss: 1.9100241661071777
Validation loss: 2.1372572324609243

Epoch: 265| Step: 0
Training loss: 2.6487691402435303
Validation loss: 2.1340684134473085

Epoch: 6| Step: 1
Training loss: 2.3150644302368164
Validation loss: 2.1141012407118276

Epoch: 6| Step: 2
Training loss: 2.305917263031006
Validation loss: 2.093758976587685

Epoch: 6| Step: 3
Training loss: 1.7105662822723389
Validation loss: 2.245625347219488

Epoch: 6| Step: 4
Training loss: 1.2542940378189087
Validation loss: 2.0575704548948552

Epoch: 6| Step: 5
Training loss: 2.0839791297912598
Validation loss: 2.1551429661371375

Epoch: 6| Step: 6
Training loss: 2.1522741317749023
Validation loss: 2.096521951818979

Epoch: 6| Step: 7
Training loss: 1.7573587894439697
Validation loss: 2.162434470268988

Epoch: 6| Step: 8
Training loss: 2.58837890625
Validation loss: 2.2152159572929464

Epoch: 6| Step: 9
Training loss: 1.5069401264190674
Validation loss: 2.2445901440035914

Epoch: 6| Step: 10
Training loss: 1.8792593479156494
Validation loss: 2.1232873906371412

Epoch: 6| Step: 11
Training loss: 1.2787846326828003
Validation loss: 2.2202572668752363

Epoch: 6| Step: 12
Training loss: 1.8949620723724365
Validation loss: 2.2093040276599187

Epoch: 6| Step: 13
Training loss: 2.780275583267212
Validation loss: 2.182809534893241

Epoch: 266| Step: 0
Training loss: 1.7912871837615967
Validation loss: 2.1864369966650523

Epoch: 6| Step: 1
Training loss: 1.74098539352417
Validation loss: 2.1994342470681794

Epoch: 6| Step: 2
Training loss: 1.409822702407837
Validation loss: 2.243738776894026

Epoch: 6| Step: 3
Training loss: 1.6346110105514526
Validation loss: 2.2642234063917592

Epoch: 6| Step: 4
Training loss: 2.512092351913452
Validation loss: 2.2145603113276984

Epoch: 6| Step: 5
Training loss: 2.6150364875793457
Validation loss: 2.2242917245434177

Epoch: 6| Step: 6
Training loss: 2.650787353515625
Validation loss: 2.157763329885339

Epoch: 6| Step: 7
Training loss: 1.68308424949646
Validation loss: 2.1801369446580128

Epoch: 6| Step: 8
Training loss: 1.3493046760559082
Validation loss: 2.143239087955926

Epoch: 6| Step: 9
Training loss: 1.8573634624481201
Validation loss: 2.1739540894826255

Epoch: 6| Step: 10
Training loss: 1.8469711542129517
Validation loss: 2.1424342201602076

Epoch: 6| Step: 11
Training loss: 2.4262614250183105
Validation loss: 2.122836776958999

Epoch: 6| Step: 12
Training loss: 1.3293319940567017
Validation loss: 2.1928597111855783

Epoch: 6| Step: 13
Training loss: 1.9514440298080444
Validation loss: 2.203760113767398

Epoch: 267| Step: 0
Training loss: 1.808641791343689
Validation loss: 2.256546590917854

Epoch: 6| Step: 1
Training loss: 1.4634795188903809
Validation loss: 2.215120441170149

Epoch: 6| Step: 2
Training loss: 2.0061564445495605
Validation loss: 2.3061140224497807

Epoch: 6| Step: 3
Training loss: 2.224640369415283
Validation loss: 2.2311542726332143

Epoch: 6| Step: 4
Training loss: 2.1722769737243652
Validation loss: 2.2391596327545824

Epoch: 6| Step: 5
Training loss: 1.819597840309143
Validation loss: 2.248672539188016

Epoch: 6| Step: 6
Training loss: 1.8458107709884644
Validation loss: 2.2019848105727986

Epoch: 6| Step: 7
Training loss: 2.1312897205352783
Validation loss: 2.2354554976186445

Epoch: 6| Step: 8
Training loss: 1.3435500860214233
Validation loss: 2.195183064347954

Epoch: 6| Step: 9
Training loss: 2.673593282699585
Validation loss: 2.125301346983961

Epoch: 6| Step: 10
Training loss: 1.8346869945526123
Validation loss: 2.1855018318340345

Epoch: 6| Step: 11
Training loss: 1.2758522033691406
Validation loss: 2.165279003881639

Epoch: 6| Step: 12
Training loss: 2.092074394226074
Validation loss: 2.246178796214442

Epoch: 6| Step: 13
Training loss: 2.2439870834350586
Validation loss: 2.092294734011414

Epoch: 268| Step: 0
Training loss: 1.8653042316436768
Validation loss: 2.17190985269444

Epoch: 6| Step: 1
Training loss: 1.9075652360916138
Validation loss: 2.1397047747847853

Epoch: 6| Step: 2
Training loss: 1.8582348823547363
Validation loss: 2.0682845166934434

Epoch: 6| Step: 3
Training loss: 2.263833522796631
Validation loss: 2.1147891500944733

Epoch: 6| Step: 4
Training loss: 1.7858835458755493
Validation loss: 2.1474853818134596

Epoch: 6| Step: 5
Training loss: 1.8427271842956543
Validation loss: 2.113778006645941

Epoch: 6| Step: 6
Training loss: 2.155148983001709
Validation loss: 2.124034071481356

Epoch: 6| Step: 7
Training loss: 2.113245964050293
Validation loss: 2.1897518045158795

Epoch: 6| Step: 8
Training loss: 2.1829795837402344
Validation loss: 2.165637695661155

Epoch: 6| Step: 9
Training loss: 2.0307350158691406
Validation loss: 2.2012131214141846

Epoch: 6| Step: 10
Training loss: 1.371029019355774
Validation loss: 2.053796434915194

Epoch: 6| Step: 11
Training loss: 2.008991003036499
Validation loss: 2.1552235759714597

Epoch: 6| Step: 12
Training loss: 1.3577072620391846
Validation loss: 2.1024649912311184

Epoch: 6| Step: 13
Training loss: 2.5278525352478027
Validation loss: 2.1789882644530265

Epoch: 269| Step: 0
Training loss: 2.1041862964630127
Validation loss: 2.1508048580538843

Epoch: 6| Step: 1
Training loss: 1.5644478797912598
Validation loss: 2.1544487796803957

Epoch: 6| Step: 2
Training loss: 1.5898454189300537
Validation loss: 2.1586336371719197

Epoch: 6| Step: 3
Training loss: 2.063321113586426
Validation loss: 2.191932670531734

Epoch: 6| Step: 4
Training loss: 1.5964596271514893
Validation loss: 2.2020027355481218

Epoch: 6| Step: 5
Training loss: 1.940098762512207
Validation loss: 2.1897681374703684

Epoch: 6| Step: 6
Training loss: 2.2319183349609375
Validation loss: 2.2147896674371537

Epoch: 6| Step: 7
Training loss: 2.2223410606384277
Validation loss: 2.170904705601354

Epoch: 6| Step: 8
Training loss: 2.181173086166382
Validation loss: 2.282298982784312

Epoch: 6| Step: 9
Training loss: 2.057648181915283
Validation loss: 2.1207438668897076

Epoch: 6| Step: 10
Training loss: 1.4947738647460938
Validation loss: 2.216063035431729

Epoch: 6| Step: 11
Training loss: 1.6411160230636597
Validation loss: 2.1718600155204855

Epoch: 6| Step: 12
Training loss: 3.078885555267334
Validation loss: 2.233064482288976

Epoch: 6| Step: 13
Training loss: 1.8552396297454834
Validation loss: 2.241678681424869

Epoch: 270| Step: 0
Training loss: 2.130188465118408
Validation loss: 2.168827406821712

Epoch: 6| Step: 1
Training loss: 1.4755473136901855
Validation loss: 2.1027160588131157

Epoch: 6| Step: 2
Training loss: 1.2304621934890747
Validation loss: 2.1765684491844586

Epoch: 6| Step: 3
Training loss: 1.8826924562454224
Validation loss: 2.177848668508632

Epoch: 6| Step: 4
Training loss: 1.9942253828048706
Validation loss: 2.2307879796592136

Epoch: 6| Step: 5
Training loss: 1.3475191593170166
Validation loss: 2.2517382457692134

Epoch: 6| Step: 6
Training loss: 1.7477455139160156
Validation loss: 2.221218416767736

Epoch: 6| Step: 7
Training loss: 1.931412696838379
Validation loss: 2.1297985584505144

Epoch: 6| Step: 8
Training loss: 1.91968834400177
Validation loss: 2.1838257876775597

Epoch: 6| Step: 9
Training loss: 2.465104579925537
Validation loss: 2.1829666758096344

Epoch: 6| Step: 10
Training loss: 2.056178092956543
Validation loss: 2.2415133278856993

Epoch: 6| Step: 11
Training loss: 1.7505006790161133
Validation loss: 2.3043526193147064

Epoch: 6| Step: 12
Training loss: 3.11867618560791
Validation loss: 2.1710309777208554

Epoch: 6| Step: 13
Training loss: 1.4861030578613281
Validation loss: 2.167367681380241

Epoch: 271| Step: 0
Training loss: 1.8199944496154785
Validation loss: 2.149431869547854

Epoch: 6| Step: 1
Training loss: 1.9537605047225952
Validation loss: 2.219521927577193

Epoch: 6| Step: 2
Training loss: 2.5793933868408203
Validation loss: 2.213629371376448

Epoch: 6| Step: 3
Training loss: 1.6447155475616455
Validation loss: 2.2240799601360033

Epoch: 6| Step: 4
Training loss: 1.9159917831420898
Validation loss: 2.1649285849704536

Epoch: 6| Step: 5
Training loss: 1.7221680879592896
Validation loss: 2.161128923457156

Epoch: 6| Step: 6
Training loss: 1.7480201721191406
Validation loss: 2.2173069702681674

Epoch: 6| Step: 7
Training loss: 1.392088532447815
Validation loss: 2.201370853249745

Epoch: 6| Step: 8
Training loss: 1.8816603422164917
Validation loss: 2.257012718467302

Epoch: 6| Step: 9
Training loss: 1.5313005447387695
Validation loss: 2.2247954671100905

Epoch: 6| Step: 10
Training loss: 2.602921485900879
Validation loss: 2.211272442212669

Epoch: 6| Step: 11
Training loss: 1.7678455114364624
Validation loss: 2.2151043286887546

Epoch: 6| Step: 12
Training loss: 3.157686233520508
Validation loss: 2.0955171123627694

Epoch: 6| Step: 13
Training loss: 1.1318196058273315
Validation loss: 2.1679883233962522

Epoch: 272| Step: 0
Training loss: 1.9096041917800903
Validation loss: 2.1695662467710433

Epoch: 6| Step: 1
Training loss: 2.1367666721343994
Validation loss: 2.223264245576756

Epoch: 6| Step: 2
Training loss: 2.194899320602417
Validation loss: 2.1234820799161027

Epoch: 6| Step: 3
Training loss: 1.8514325618743896
Validation loss: 2.1275373607553463

Epoch: 6| Step: 4
Training loss: 1.9057672023773193
Validation loss: 2.109845543420443

Epoch: 6| Step: 5
Training loss: 1.9115748405456543
Validation loss: 2.1802128438026673

Epoch: 6| Step: 6
Training loss: 1.4211822748184204
Validation loss: 2.2235112600429083

Epoch: 6| Step: 7
Training loss: 2.2130393981933594
Validation loss: 2.228489750175066

Epoch: 6| Step: 8
Training loss: 1.478165626525879
Validation loss: 2.11819798972017

Epoch: 6| Step: 9
Training loss: 1.79173743724823
Validation loss: 2.2112381304464033

Epoch: 6| Step: 10
Training loss: 1.7818048000335693
Validation loss: 2.1760596177911244

Epoch: 6| Step: 11
Training loss: 1.4293136596679688
Validation loss: 2.1672913541076

Epoch: 6| Step: 12
Training loss: 2.242246389389038
Validation loss: 2.152532313459663

Epoch: 6| Step: 13
Training loss: 2.5584876537323
Validation loss: 2.2331070771781345

Epoch: 273| Step: 0
Training loss: 2.414004325866699
Validation loss: 2.1159653227816344

Epoch: 6| Step: 1
Training loss: 2.045675277709961
Validation loss: 2.2635799889923423

Epoch: 6| Step: 2
Training loss: 1.5721107721328735
Validation loss: 2.201988508624415

Epoch: 6| Step: 3
Training loss: 1.9875980615615845
Validation loss: 2.0355307043239637

Epoch: 6| Step: 4
Training loss: 1.807417392730713
Validation loss: 2.147669247401658

Epoch: 6| Step: 5
Training loss: 2.091409206390381
Validation loss: 2.198080902458519

Epoch: 6| Step: 6
Training loss: 2.033892869949341
Validation loss: 2.0981163081302436

Epoch: 6| Step: 7
Training loss: 2.374681234359741
Validation loss: 2.1910093586931945

Epoch: 6| Step: 8
Training loss: 2.2573866844177246
Validation loss: 2.0854620523350214

Epoch: 6| Step: 9
Training loss: 1.5343396663665771
Validation loss: 2.2387480889597247

Epoch: 6| Step: 10
Training loss: 1.4532992839813232
Validation loss: 2.2046000316578853

Epoch: 6| Step: 11
Training loss: 2.06174898147583
Validation loss: 2.167449599953108

Epoch: 6| Step: 12
Training loss: 1.4947590827941895
Validation loss: 2.248162582356443

Epoch: 6| Step: 13
Training loss: 2.4599053859710693
Validation loss: 2.1414246969325568

Epoch: 274| Step: 0
Training loss: 1.8828761577606201
Validation loss: 2.18998622381559

Epoch: 6| Step: 1
Training loss: 1.9248051643371582
Validation loss: 2.136669458881501

Epoch: 6| Step: 2
Training loss: 1.5199224948883057
Validation loss: 2.230530215847877

Epoch: 6| Step: 3
Training loss: 1.5925337076187134
Validation loss: 2.1557590987092707

Epoch: 6| Step: 4
Training loss: 2.0333251953125
Validation loss: 2.2263216357077322

Epoch: 6| Step: 5
Training loss: 1.8108165264129639
Validation loss: 2.089250044156146

Epoch: 6| Step: 6
Training loss: 2.1128017902374268
Validation loss: 2.0840394496917725

Epoch: 6| Step: 7
Training loss: 2.583491325378418
Validation loss: 2.0992691055420907

Epoch: 6| Step: 8
Training loss: 2.288133144378662
Validation loss: 2.146414295319588

Epoch: 6| Step: 9
Training loss: 1.668879747390747
Validation loss: 2.270797921765235

Epoch: 6| Step: 10
Training loss: 1.4092236757278442
Validation loss: 2.167624681226669

Epoch: 6| Step: 11
Training loss: 2.0071167945861816
Validation loss: 2.124080091394404

Epoch: 6| Step: 12
Training loss: 2.241135597229004
Validation loss: 2.2196544883071736

Epoch: 6| Step: 13
Training loss: 1.907224416732788
Validation loss: 2.104303980386385

Epoch: 275| Step: 0
Training loss: 1.798475980758667
Validation loss: 2.1711815044444096

Epoch: 6| Step: 1
Training loss: 1.8530170917510986
Validation loss: 2.1835118416816957

Epoch: 6| Step: 2
Training loss: 1.6941508054733276
Validation loss: 2.161801633014474

Epoch: 6| Step: 3
Training loss: 1.7074542045593262
Validation loss: 2.2255730141875563

Epoch: 6| Step: 4
Training loss: 1.9810497760772705
Validation loss: 2.2275317663787515

Epoch: 6| Step: 5
Training loss: 1.881152629852295
Validation loss: 2.174978374153055

Epoch: 6| Step: 6
Training loss: 1.7155181169509888
Validation loss: 2.3126837130515807

Epoch: 6| Step: 7
Training loss: 2.133462905883789
Validation loss: 2.23705877283568

Epoch: 6| Step: 8
Training loss: 1.7861303091049194
Validation loss: 2.171092197459231

Epoch: 6| Step: 9
Training loss: 1.8162086009979248
Validation loss: 2.2239229756016887

Epoch: 6| Step: 10
Training loss: 2.249417543411255
Validation loss: 2.341443725811538

Epoch: 6| Step: 11
Training loss: 1.8650081157684326
Validation loss: 2.266014196539438

Epoch: 6| Step: 12
Training loss: 2.298159122467041
Validation loss: 2.2313473660458802

Epoch: 6| Step: 13
Training loss: 2.0120887756347656
Validation loss: 2.189860032450768

Epoch: 276| Step: 0
Training loss: 1.608694076538086
Validation loss: 2.163178297781175

Epoch: 6| Step: 1
Training loss: 1.6636474132537842
Validation loss: 2.2917705633307017

Epoch: 6| Step: 2
Training loss: 2.5473806858062744
Validation loss: 2.187750226707869

Epoch: 6| Step: 3
Training loss: 1.856865644454956
Validation loss: 2.1982098523006646

Epoch: 6| Step: 4
Training loss: 1.2558932304382324
Validation loss: 2.2260534404426493

Epoch: 6| Step: 5
Training loss: 1.7889041900634766
Validation loss: 2.1741744651589343

Epoch: 6| Step: 6
Training loss: 2.078958749771118
Validation loss: 2.1696160403631066

Epoch: 6| Step: 7
Training loss: 1.9286723136901855
Validation loss: 2.1274150827879548

Epoch: 6| Step: 8
Training loss: 2.057459831237793
Validation loss: 2.0852699689967658

Epoch: 6| Step: 9
Training loss: 1.47993803024292
Validation loss: 2.1640572445366972

Epoch: 6| Step: 10
Training loss: 2.1752309799194336
Validation loss: 2.1693782883305706

Epoch: 6| Step: 11
Training loss: 1.9300786256790161
Validation loss: 2.140509036279494

Epoch: 6| Step: 12
Training loss: 1.5134732723236084
Validation loss: 2.0520515416258123

Epoch: 6| Step: 13
Training loss: 2.166583776473999
Validation loss: 2.146188948744087

Epoch: 277| Step: 0
Training loss: 1.6969497203826904
Validation loss: 2.160199890854538

Epoch: 6| Step: 1
Training loss: 1.8200315237045288
Validation loss: 2.21099454100414

Epoch: 6| Step: 2
Training loss: 1.4723659753799438
Validation loss: 2.1288420692566903

Epoch: 6| Step: 3
Training loss: 2.0116982460021973
Validation loss: 2.157141298376104

Epoch: 6| Step: 4
Training loss: 1.8528157472610474
Validation loss: 2.1457306723440848

Epoch: 6| Step: 5
Training loss: 2.4813132286071777
Validation loss: 2.103063109100506

Epoch: 6| Step: 6
Training loss: 2.6495985984802246
Validation loss: 2.046825273062593

Epoch: 6| Step: 7
Training loss: 2.341487407684326
Validation loss: 2.1817196620407926

Epoch: 6| Step: 8
Training loss: 2.1743814945220947
Validation loss: 2.1800667803774596

Epoch: 6| Step: 9
Training loss: 1.5580166578292847
Validation loss: 2.1357974365193355

Epoch: 6| Step: 10
Training loss: 1.7140421867370605
Validation loss: 2.17093684083672

Epoch: 6| Step: 11
Training loss: 1.6661036014556885
Validation loss: 2.1710426961222002

Epoch: 6| Step: 12
Training loss: 1.3321442604064941
Validation loss: 2.2116929818225164

Epoch: 6| Step: 13
Training loss: 1.4067453145980835
Validation loss: 2.1104262182789464

Epoch: 278| Step: 0
Training loss: 2.8444924354553223
Validation loss: 2.218495499703192

Epoch: 6| Step: 1
Training loss: 1.407280683517456
Validation loss: 2.1524694171003116

Epoch: 6| Step: 2
Training loss: 1.6453911066055298
Validation loss: 2.2338262065764396

Epoch: 6| Step: 3
Training loss: 1.5765466690063477
Validation loss: 2.1949832670150267

Epoch: 6| Step: 4
Training loss: 2.0346102714538574
Validation loss: 2.2213483407933223

Epoch: 6| Step: 5
Training loss: 1.8082056045532227
Validation loss: 2.2005093200232393

Epoch: 6| Step: 6
Training loss: 1.6834907531738281
Validation loss: 2.1079379281690045

Epoch: 6| Step: 7
Training loss: 2.5284717082977295
Validation loss: 2.177107910956106

Epoch: 6| Step: 8
Training loss: 1.9846484661102295
Validation loss: 2.1543387341242966

Epoch: 6| Step: 9
Training loss: 2.4697365760803223
Validation loss: 2.190788666407267

Epoch: 6| Step: 10
Training loss: 1.7318600416183472
Validation loss: 2.2506212752352477

Epoch: 6| Step: 11
Training loss: 1.1969201564788818
Validation loss: 2.16005435041202

Epoch: 6| Step: 12
Training loss: 2.0890250205993652
Validation loss: 2.1198572676668883

Epoch: 6| Step: 13
Training loss: 1.3023093938827515
Validation loss: 2.132163457973029

Epoch: 279| Step: 0
Training loss: 2.1975531578063965
Validation loss: 2.151885788927796

Epoch: 6| Step: 1
Training loss: 2.5310330390930176
Validation loss: 2.180823177419683

Epoch: 6| Step: 2
Training loss: 2.081409454345703
Validation loss: 2.0941863803453344

Epoch: 6| Step: 3
Training loss: 1.7651629447937012
Validation loss: 2.133846926432784

Epoch: 6| Step: 4
Training loss: 2.222835063934326
Validation loss: 2.1964105867570445

Epoch: 6| Step: 5
Training loss: 2.1197147369384766
Validation loss: 2.2142460628222396

Epoch: 6| Step: 6
Training loss: 1.747257947921753
Validation loss: 2.2161670884778424

Epoch: 6| Step: 7
Training loss: 1.204757809638977
Validation loss: 2.151884768598823

Epoch: 6| Step: 8
Training loss: 0.8723626136779785
Validation loss: 2.1087724983051257

Epoch: 6| Step: 9
Training loss: 1.7047277688980103
Validation loss: 2.127978350526543

Epoch: 6| Step: 10
Training loss: 2.381580352783203
Validation loss: 2.210313671378679

Epoch: 6| Step: 11
Training loss: 2.3199827671051025
Validation loss: 2.2161622226879163

Epoch: 6| Step: 12
Training loss: 2.2862255573272705
Validation loss: 2.200559180269959

Epoch: 6| Step: 13
Training loss: 1.4812591075897217
Validation loss: 2.1691784410066504

Epoch: 280| Step: 0
Training loss: 1.6721532344818115
Validation loss: 2.141302554838119

Epoch: 6| Step: 1
Training loss: 1.9380080699920654
Validation loss: 2.16664368619201

Epoch: 6| Step: 2
Training loss: 1.7828311920166016
Validation loss: 2.205904479949705

Epoch: 6| Step: 3
Training loss: 1.6124314069747925
Validation loss: 2.158902342601489

Epoch: 6| Step: 4
Training loss: 1.8792716264724731
Validation loss: 2.090142326970254

Epoch: 6| Step: 5
Training loss: 2.5195367336273193
Validation loss: 2.116648879102481

Epoch: 6| Step: 6
Training loss: 1.923203468322754
Validation loss: 2.131915997433406

Epoch: 6| Step: 7
Training loss: 2.1732940673828125
Validation loss: 2.1234085290662703

Epoch: 6| Step: 8
Training loss: 1.7721896171569824
Validation loss: 2.1159125040936213

Epoch: 6| Step: 9
Training loss: 2.793689727783203
Validation loss: 2.195887411794355

Epoch: 6| Step: 10
Training loss: 1.1946157217025757
Validation loss: 2.1043136427479405

Epoch: 6| Step: 11
Training loss: 1.7337167263031006
Validation loss: 2.1378954097788823

Epoch: 6| Step: 12
Training loss: 1.6418030261993408
Validation loss: 2.128065751444909

Epoch: 6| Step: 13
Training loss: 1.5848915576934814
Validation loss: 2.0648573752372497

Epoch: 281| Step: 0
Training loss: 1.7367384433746338
Validation loss: 2.1454633910168885

Epoch: 6| Step: 1
Training loss: 2.5687389373779297
Validation loss: 2.1532809811253704

Epoch: 6| Step: 2
Training loss: 2.5263657569885254
Validation loss: 2.082215009197112

Epoch: 6| Step: 3
Training loss: 1.645115613937378
Validation loss: 2.118775915074092

Epoch: 6| Step: 4
Training loss: 1.9074344635009766
Validation loss: 2.192492021027432

Epoch: 6| Step: 5
Training loss: 1.3669525384902954
Validation loss: 2.1326961004605858

Epoch: 6| Step: 6
Training loss: 2.5189948081970215
Validation loss: 2.1702711261728758

Epoch: 6| Step: 7
Training loss: 1.805104374885559
Validation loss: 2.107635082737092

Epoch: 6| Step: 8
Training loss: 1.9199594259262085
Validation loss: 2.229195143586846

Epoch: 6| Step: 9
Training loss: 1.6072182655334473
Validation loss: 2.1316993108359714

Epoch: 6| Step: 10
Training loss: 1.8448234796524048
Validation loss: 2.14800936688659

Epoch: 6| Step: 11
Training loss: 2.205416679382324
Validation loss: 2.134249743594918

Epoch: 6| Step: 12
Training loss: 1.3138726949691772
Validation loss: 2.167996729573896

Epoch: 6| Step: 13
Training loss: 1.2929600477218628
Validation loss: 2.152094239829689

Epoch: 282| Step: 0
Training loss: 1.5243548154830933
Validation loss: 2.225943224404448

Epoch: 6| Step: 1
Training loss: 1.8955531120300293
Validation loss: 2.2171781037443425

Epoch: 6| Step: 2
Training loss: 1.9389879703521729
Validation loss: 2.228467854120398

Epoch: 6| Step: 3
Training loss: 1.851646900177002
Validation loss: 2.175490774134154

Epoch: 6| Step: 4
Training loss: 2.180210828781128
Validation loss: 2.15262149482645

Epoch: 6| Step: 5
Training loss: 1.9085536003112793
Validation loss: 2.2547943284434657

Epoch: 6| Step: 6
Training loss: 2.3820879459381104
Validation loss: 2.242802809643489

Epoch: 6| Step: 7
Training loss: 1.9268754720687866
Validation loss: 2.2068766188877884

Epoch: 6| Step: 8
Training loss: 1.8241798877716064
Validation loss: 2.2210012020603305

Epoch: 6| Step: 9
Training loss: 1.813095211982727
Validation loss: 2.1190687815348306

Epoch: 6| Step: 10
Training loss: 2.092200994491577
Validation loss: 2.110655751279605

Epoch: 6| Step: 11
Training loss: 2.3032493591308594
Validation loss: 2.2129304780754993

Epoch: 6| Step: 12
Training loss: 1.5336909294128418
Validation loss: 2.2019832646974953

Epoch: 6| Step: 13
Training loss: 1.6574922800064087
Validation loss: 2.1923531896324566

Epoch: 283| Step: 0
Training loss: 2.0360870361328125
Validation loss: 2.144362295827558

Epoch: 6| Step: 1
Training loss: 1.8445024490356445
Validation loss: 2.1073564496091617

Epoch: 6| Step: 2
Training loss: 1.6368353366851807
Validation loss: 2.1683751549772037

Epoch: 6| Step: 3
Training loss: 2.1265172958374023
Validation loss: 2.2044573483928556

Epoch: 6| Step: 4
Training loss: 1.911197304725647
Validation loss: 2.1551995162040956

Epoch: 6| Step: 5
Training loss: 2.0630197525024414
Validation loss: 2.173949408274825

Epoch: 6| Step: 6
Training loss: 1.5746064186096191
Validation loss: 2.177367353952059

Epoch: 6| Step: 7
Training loss: 1.5489914417266846
Validation loss: 2.2027891400039836

Epoch: 6| Step: 8
Training loss: 1.126177430152893
Validation loss: 2.10764241603113

Epoch: 6| Step: 9
Training loss: 2.3516807556152344
Validation loss: 2.1871158102507233

Epoch: 6| Step: 10
Training loss: 2.0171871185302734
Validation loss: 2.182428870149838

Epoch: 6| Step: 11
Training loss: 2.062593460083008
Validation loss: 2.1950816774881012

Epoch: 6| Step: 12
Training loss: 2.019883155822754
Validation loss: 2.214525668851791

Epoch: 6| Step: 13
Training loss: 2.0784976482391357
Validation loss: 2.1463630968524563

Epoch: 284| Step: 0
Training loss: 2.1452701091766357
Validation loss: 2.1609718081771687

Epoch: 6| Step: 1
Training loss: 1.861572265625
Validation loss: 2.224696284981184

Epoch: 6| Step: 2
Training loss: 1.9788424968719482
Validation loss: 2.1219660184716664

Epoch: 6| Step: 3
Training loss: 1.9637670516967773
Validation loss: 2.1699668361294653

Epoch: 6| Step: 4
Training loss: 1.9443602561950684
Validation loss: 2.1745323237552436

Epoch: 6| Step: 5
Training loss: 2.3194942474365234
Validation loss: 2.181861500586233

Epoch: 6| Step: 6
Training loss: 1.8513476848602295
Validation loss: 2.1961064979594243

Epoch: 6| Step: 7
Training loss: 2.4485371112823486
Validation loss: 2.164195719585624

Epoch: 6| Step: 8
Training loss: 1.0749834775924683
Validation loss: 2.131390179357221

Epoch: 6| Step: 9
Training loss: 2.046555995941162
Validation loss: 2.1999649924616658

Epoch: 6| Step: 10
Training loss: 2.2358429431915283
Validation loss: 2.1845687640610563

Epoch: 6| Step: 11
Training loss: 1.8387606143951416
Validation loss: 2.173019301506781

Epoch: 6| Step: 12
Training loss: 2.0945050716400146
Validation loss: 2.2001758301129906

Epoch: 6| Step: 13
Training loss: 1.6949166059494019
Validation loss: 2.20710059647919

Epoch: 285| Step: 0
Training loss: 2.261343479156494
Validation loss: 2.2629043953393095

Epoch: 6| Step: 1
Training loss: 1.8778328895568848
Validation loss: 2.19611350182564

Epoch: 6| Step: 2
Training loss: 2.0354111194610596
Validation loss: 2.2083968244573122

Epoch: 6| Step: 3
Training loss: 2.907306671142578
Validation loss: 2.2802699406941733

Epoch: 6| Step: 4
Training loss: 1.5978662967681885
Validation loss: 2.2397701381355204

Epoch: 6| Step: 5
Training loss: 2.027878522872925
Validation loss: 2.0715702708049486

Epoch: 6| Step: 6
Training loss: 1.6474356651306152
Validation loss: 2.2367071951589277

Epoch: 6| Step: 7
Training loss: 1.7470945119857788
Validation loss: 2.2289630392546296

Epoch: 6| Step: 8
Training loss: 1.9555470943450928
Validation loss: 2.1673939638240363

Epoch: 6| Step: 9
Training loss: 1.4071674346923828
Validation loss: 2.1025024690935687

Epoch: 6| Step: 10
Training loss: 1.5616809129714966
Validation loss: 2.1449430552862023

Epoch: 6| Step: 11
Training loss: 1.9346526861190796
Validation loss: 2.155302793748917

Epoch: 6| Step: 12
Training loss: 1.6532797813415527
Validation loss: 2.194729812683598

Epoch: 6| Step: 13
Training loss: 1.5816502571105957
Validation loss: 2.13860676621878

Epoch: 286| Step: 0
Training loss: 1.8358256816864014
Validation loss: 2.1465763814987673

Epoch: 6| Step: 1
Training loss: 1.8447887897491455
Validation loss: 2.1132666782666276

Epoch: 6| Step: 2
Training loss: 2.050750494003296
Validation loss: 2.2282987153658302

Epoch: 6| Step: 3
Training loss: 1.668095588684082
Validation loss: 2.021237357970207

Epoch: 6| Step: 4
Training loss: 1.1848796606063843
Validation loss: 2.170620600382487

Epoch: 6| Step: 5
Training loss: 2.3274028301239014
Validation loss: 2.1646561084255094

Epoch: 6| Step: 6
Training loss: 2.4427387714385986
Validation loss: 2.11607087555752

Epoch: 6| Step: 7
Training loss: 1.7772324085235596
Validation loss: 2.1729116004000426

Epoch: 6| Step: 8
Training loss: 1.9345297813415527
Validation loss: 2.104745181657935

Epoch: 6| Step: 9
Training loss: 2.1847658157348633
Validation loss: 2.2052923094841743

Epoch: 6| Step: 10
Training loss: 1.5636272430419922
Validation loss: 2.123029480698288

Epoch: 6| Step: 11
Training loss: 0.8832924365997314
Validation loss: 2.202912102463425

Epoch: 6| Step: 12
Training loss: 1.9358454942703247
Validation loss: 2.1752640739563973

Epoch: 6| Step: 13
Training loss: 2.9978277683258057
Validation loss: 2.178497983563331

Epoch: 287| Step: 0
Training loss: 2.5629196166992188
Validation loss: 2.181929028162392

Epoch: 6| Step: 1
Training loss: 2.0027670860290527
Validation loss: 2.1292195345765803

Epoch: 6| Step: 2
Training loss: 1.4350810050964355
Validation loss: 2.0620654090758292

Epoch: 6| Step: 3
Training loss: 2.124892234802246
Validation loss: 2.1225999324552474

Epoch: 6| Step: 4
Training loss: 1.3975913524627686
Validation loss: 2.1303002488228584

Epoch: 6| Step: 5
Training loss: 1.9347038269042969
Validation loss: 2.2265168364330004

Epoch: 6| Step: 6
Training loss: 2.3823978900909424
Validation loss: 2.2612262823248424

Epoch: 6| Step: 7
Training loss: 2.420430898666382
Validation loss: 2.23210891344214

Epoch: 6| Step: 8
Training loss: 1.7180750370025635
Validation loss: 2.2395661902684036

Epoch: 6| Step: 9
Training loss: 1.7980828285217285
Validation loss: 2.245344743933729

Epoch: 6| Step: 10
Training loss: 2.086456060409546
Validation loss: 2.253684328448388

Epoch: 6| Step: 11
Training loss: 1.3369207382202148
Validation loss: 2.226050299982871

Epoch: 6| Step: 12
Training loss: 1.7806161642074585
Validation loss: 2.1510065127444524

Epoch: 6| Step: 13
Training loss: 1.3046813011169434
Validation loss: 2.2069386256638395

Epoch: 288| Step: 0
Training loss: 2.0539755821228027
Validation loss: 2.168107864677265

Epoch: 6| Step: 1
Training loss: 2.383273124694824
Validation loss: 2.201668938000997

Epoch: 6| Step: 2
Training loss: 1.2396109104156494
Validation loss: 2.1418753964926607

Epoch: 6| Step: 3
Training loss: 2.1108319759368896
Validation loss: 2.1861415575909358

Epoch: 6| Step: 4
Training loss: 1.5094496011734009
Validation loss: 2.214409871767926

Epoch: 6| Step: 5
Training loss: 1.624570369720459
Validation loss: 2.0573817427440355

Epoch: 6| Step: 6
Training loss: 1.7991604804992676
Validation loss: 2.238352034681587

Epoch: 6| Step: 7
Training loss: 2.215235710144043
Validation loss: 2.281300296065628

Epoch: 6| Step: 8
Training loss: 1.6246469020843506
Validation loss: 2.1255973846681657

Epoch: 6| Step: 9
Training loss: 1.723146915435791
Validation loss: 2.2104691638741443

Epoch: 6| Step: 10
Training loss: 2.2353286743164062
Validation loss: 2.2512592423346733

Epoch: 6| Step: 11
Training loss: 2.4207403659820557
Validation loss: 2.2229746541669293

Epoch: 6| Step: 12
Training loss: 1.9138679504394531
Validation loss: 2.231383051923526

Epoch: 6| Step: 13
Training loss: 1.2709916830062866
Validation loss: 2.2066287109928746

Epoch: 289| Step: 0
Training loss: 1.920563817024231
Validation loss: 2.2459699723028366

Epoch: 6| Step: 1
Training loss: 2.0814261436462402
Validation loss: 2.317428104339107

Epoch: 6| Step: 2
Training loss: 2.2763144969940186
Validation loss: 2.156904419263204

Epoch: 6| Step: 3
Training loss: 2.5404858589172363
Validation loss: 2.2613486090014057

Epoch: 6| Step: 4
Training loss: 2.192037582397461
Validation loss: 2.2309848570054576

Epoch: 6| Step: 5
Training loss: 1.787573218345642
Validation loss: 2.1950782806642595

Epoch: 6| Step: 6
Training loss: 1.6950448751449585
Validation loss: 2.1520669447478427

Epoch: 6| Step: 7
Training loss: 1.9552443027496338
Validation loss: 2.2276662793210757

Epoch: 6| Step: 8
Training loss: 1.8067748546600342
Validation loss: 2.1686006374256586

Epoch: 6| Step: 9
Training loss: 1.8412325382232666
Validation loss: 2.1657379506736674

Epoch: 6| Step: 10
Training loss: 2.1398463249206543
Validation loss: 2.1356828648556947

Epoch: 6| Step: 11
Training loss: 1.4579271078109741
Validation loss: 2.202571786859984

Epoch: 6| Step: 12
Training loss: 1.9741621017456055
Validation loss: 2.183095637188163

Epoch: 6| Step: 13
Training loss: 1.6666545867919922
Validation loss: 2.16417944815851

Epoch: 290| Step: 0
Training loss: 2.3511850833892822
Validation loss: 2.1688440717676634

Epoch: 6| Step: 1
Training loss: 1.7093849182128906
Validation loss: 2.206687573463686

Epoch: 6| Step: 2
Training loss: 1.273155689239502
Validation loss: 2.2080142728744017

Epoch: 6| Step: 3
Training loss: 2.205782175064087
Validation loss: 2.0884328644762755

Epoch: 6| Step: 4
Training loss: 1.6363624334335327
Validation loss: 2.275888955721291

Epoch: 6| Step: 5
Training loss: 1.6011037826538086
Validation loss: 2.302763932494707

Epoch: 6| Step: 6
Training loss: 1.3755582571029663
Validation loss: 2.155391062459638

Epoch: 6| Step: 7
Training loss: 2.786532402038574
Validation loss: 2.205396221530053

Epoch: 6| Step: 8
Training loss: 2.111112594604492
Validation loss: 2.2968919687373663

Epoch: 6| Step: 9
Training loss: 2.4289255142211914
Validation loss: 2.1659083161302792

Epoch: 6| Step: 10
Training loss: 1.812822699546814
Validation loss: 2.2323849572930285

Epoch: 6| Step: 11
Training loss: 2.031320095062256
Validation loss: 2.2273231296129126

Epoch: 6| Step: 12
Training loss: 1.9159226417541504
Validation loss: 2.1752437955589703

Epoch: 6| Step: 13
Training loss: 1.1090573072433472
Validation loss: 2.28125673724759

Epoch: 291| Step: 0
Training loss: 2.506439685821533
Validation loss: 2.2520841372910367

Epoch: 6| Step: 1
Training loss: 1.8877314329147339
Validation loss: 2.2517865370678645

Epoch: 6| Step: 2
Training loss: 1.594590187072754
Validation loss: 2.224745337681104

Epoch: 6| Step: 3
Training loss: 1.461320400238037
Validation loss: 2.1527939201683126

Epoch: 6| Step: 4
Training loss: 1.2946360111236572
Validation loss: 2.2684902939745175

Epoch: 6| Step: 5
Training loss: 1.6711902618408203
Validation loss: 2.1916065446792112

Epoch: 6| Step: 6
Training loss: 1.558481216430664
Validation loss: 2.1867148722371748

Epoch: 6| Step: 7
Training loss: 2.154271364212036
Validation loss: 2.145050735883815

Epoch: 6| Step: 8
Training loss: 1.7857935428619385
Validation loss: 2.1627949001968547

Epoch: 6| Step: 9
Training loss: 2.3635082244873047
Validation loss: 2.1497798350549515

Epoch: 6| Step: 10
Training loss: 1.928459882736206
Validation loss: 2.2204859872018137

Epoch: 6| Step: 11
Training loss: 1.7443925142288208
Validation loss: 2.1533217378841933

Epoch: 6| Step: 12
Training loss: 2.262214183807373
Validation loss: 2.2040477850103892

Epoch: 6| Step: 13
Training loss: 1.7256652116775513
Validation loss: 2.081415004627679

Epoch: 292| Step: 0
Training loss: 2.403977870941162
Validation loss: 2.1181135741613244

Epoch: 6| Step: 1
Training loss: 1.405606985092163
Validation loss: 2.187002420425415

Epoch: 6| Step: 2
Training loss: 1.5910142660140991
Validation loss: 2.2011234170647076

Epoch: 6| Step: 3
Training loss: 2.32186222076416
Validation loss: 2.0668057600657144

Epoch: 6| Step: 4
Training loss: 2.018044948577881
Validation loss: 2.1228292129373036

Epoch: 6| Step: 5
Training loss: 1.6085808277130127
Validation loss: 2.1583518417932654

Epoch: 6| Step: 6
Training loss: 1.4855279922485352
Validation loss: 2.151915184913143

Epoch: 6| Step: 7
Training loss: 1.6312226057052612
Validation loss: 2.2544580608285885

Epoch: 6| Step: 8
Training loss: 2.2582690715789795
Validation loss: 2.1718071417141984

Epoch: 6| Step: 9
Training loss: 2.1080574989318848
Validation loss: 2.143029611597779

Epoch: 6| Step: 10
Training loss: 1.6781644821166992
Validation loss: 2.165574648047006

Epoch: 6| Step: 11
Training loss: 1.7135025262832642
Validation loss: 2.129835628694104

Epoch: 6| Step: 12
Training loss: 2.2977421283721924
Validation loss: 2.177924766335436

Epoch: 6| Step: 13
Training loss: 2.039693593978882
Validation loss: 2.1217201755892847

Epoch: 293| Step: 0
Training loss: 1.4179542064666748
Validation loss: 2.185629803647277

Epoch: 6| Step: 1
Training loss: 1.8630930185317993
Validation loss: 2.329461083617262

Epoch: 6| Step: 2
Training loss: 1.6211153268814087
Validation loss: 2.185934861501058

Epoch: 6| Step: 3
Training loss: 1.3632599115371704
Validation loss: 2.1928960661734305

Epoch: 6| Step: 4
Training loss: 2.092327117919922
Validation loss: 2.1490534287627026

Epoch: 6| Step: 5
Training loss: 2.100224018096924
Validation loss: 2.2861790567316036

Epoch: 6| Step: 6
Training loss: 1.9226566553115845
Validation loss: 2.3619918977060625

Epoch: 6| Step: 7
Training loss: 2.0338497161865234
Validation loss: 2.253682736427553

Epoch: 6| Step: 8
Training loss: 1.763437271118164
Validation loss: 2.278985841299898

Epoch: 6| Step: 9
Training loss: 2.0586743354797363
Validation loss: 2.2918374410239597

Epoch: 6| Step: 10
Training loss: 1.4439549446105957
Validation loss: 2.274317265838705

Epoch: 6| Step: 11
Training loss: 1.6088058948516846
Validation loss: 2.226422058638706

Epoch: 6| Step: 12
Training loss: 2.487788200378418
Validation loss: 2.226996474368598

Epoch: 6| Step: 13
Training loss: 1.6279571056365967
Validation loss: 2.1576654013767036

Epoch: 294| Step: 0
Training loss: 1.670676589012146
Validation loss: 2.206195472389139

Epoch: 6| Step: 1
Training loss: 1.945404291152954
Validation loss: 2.138725692226041

Epoch: 6| Step: 2
Training loss: 1.503899335861206
Validation loss: 2.1429602958822764

Epoch: 6| Step: 3
Training loss: 1.4866224527359009
Validation loss: 2.1349568367004395

Epoch: 6| Step: 4
Training loss: 2.0607032775878906
Validation loss: 2.2251222838637648

Epoch: 6| Step: 5
Training loss: 1.5353190898895264
Validation loss: 2.1648151797633015

Epoch: 6| Step: 6
Training loss: 1.341078758239746
Validation loss: 2.205831745619415

Epoch: 6| Step: 7
Training loss: 2.609426975250244
Validation loss: 2.037081769717637

Epoch: 6| Step: 8
Training loss: 1.3382700681686401
Validation loss: 2.189652439086668

Epoch: 6| Step: 9
Training loss: 1.6330575942993164
Validation loss: 2.2060037761606197

Epoch: 6| Step: 10
Training loss: 2.670948028564453
Validation loss: 2.087209665647117

Epoch: 6| Step: 11
Training loss: 2.402733087539673
Validation loss: 2.2257806293426023

Epoch: 6| Step: 12
Training loss: 2.2375810146331787
Validation loss: 2.185190030323562

Epoch: 6| Step: 13
Training loss: 2.024749994277954
Validation loss: 2.1803228598768993

Epoch: 295| Step: 0
Training loss: 3.0034842491149902
Validation loss: 2.226539634889172

Epoch: 6| Step: 1
Training loss: 2.5689568519592285
Validation loss: 2.1647872104439685

Epoch: 6| Step: 2
Training loss: 2.0342519283294678
Validation loss: 2.2676413405326104

Epoch: 6| Step: 3
Training loss: 1.1853070259094238
Validation loss: 2.248898808674146

Epoch: 6| Step: 4
Training loss: 1.255122423171997
Validation loss: 2.2497577615963515

Epoch: 6| Step: 5
Training loss: 2.1236772537231445
Validation loss: 2.1604733338920017

Epoch: 6| Step: 6
Training loss: 1.309495449066162
Validation loss: 2.28239768807606

Epoch: 6| Step: 7
Training loss: 2.2590622901916504
Validation loss: 2.2659038882101736

Epoch: 6| Step: 8
Training loss: 2.017928123474121
Validation loss: 2.193357730424532

Epoch: 6| Step: 9
Training loss: 1.939781904220581
Validation loss: 2.2591331812643234

Epoch: 6| Step: 10
Training loss: 1.6359400749206543
Validation loss: 2.292336619028481

Epoch: 6| Step: 11
Training loss: 1.9187543392181396
Validation loss: 2.2254148875513384

Epoch: 6| Step: 12
Training loss: 1.276215672492981
Validation loss: 2.2214766933071997

Epoch: 6| Step: 13
Training loss: 2.1836652755737305
Validation loss: 2.106923034114222

Epoch: 296| Step: 0
Training loss: 2.184361219406128
Validation loss: 2.1692342809451524

Epoch: 6| Step: 1
Training loss: 2.0283308029174805
Validation loss: 2.0766080579450055

Epoch: 6| Step: 2
Training loss: 1.5833765268325806
Validation loss: 2.1668798115945633

Epoch: 6| Step: 3
Training loss: 2.4362642765045166
Validation loss: 2.128463778444516

Epoch: 6| Step: 4
Training loss: 2.074584722518921
Validation loss: 2.194551549932008

Epoch: 6| Step: 5
Training loss: 1.4698171615600586
Validation loss: 2.2647024918627996

Epoch: 6| Step: 6
Training loss: 1.760296106338501
Validation loss: 2.203036536452591

Epoch: 6| Step: 7
Training loss: 2.073396682739258
Validation loss: 2.182337055924118

Epoch: 6| Step: 8
Training loss: 1.0426270961761475
Validation loss: 2.1476293533079085

Epoch: 6| Step: 9
Training loss: 1.804917812347412
Validation loss: 2.164812418722337

Epoch: 6| Step: 10
Training loss: 2.091263771057129
Validation loss: 2.1243567159098964

Epoch: 6| Step: 11
Training loss: 1.8249461650848389
Validation loss: 2.118973829412973

Epoch: 6| Step: 12
Training loss: 2.292999744415283
Validation loss: 2.218602018971597

Epoch: 6| Step: 13
Training loss: 1.608336091041565
Validation loss: 2.1356889432476414

Epoch: 297| Step: 0
Training loss: 1.5098605155944824
Validation loss: 2.0927114922513246

Epoch: 6| Step: 1
Training loss: 1.8045849800109863
Validation loss: 2.202734967713715

Epoch: 6| Step: 2
Training loss: 2.5328774452209473
Validation loss: 2.160424381174067

Epoch: 6| Step: 3
Training loss: 2.3134374618530273
Validation loss: 2.1266435987205914

Epoch: 6| Step: 4
Training loss: 1.6142418384552002
Validation loss: 2.1129145647889827

Epoch: 6| Step: 5
Training loss: 1.5637894868850708
Validation loss: 2.200578776738977

Epoch: 6| Step: 6
Training loss: 2.050504446029663
Validation loss: 2.167132423770043

Epoch: 6| Step: 7
Training loss: 1.6233768463134766
Validation loss: 2.201614968238338

Epoch: 6| Step: 8
Training loss: 0.8179910182952881
Validation loss: 2.2193310299227313

Epoch: 6| Step: 9
Training loss: 1.6011874675750732
Validation loss: 2.241564853217012

Epoch: 6| Step: 10
Training loss: 2.082857608795166
Validation loss: 2.1088259707215014

Epoch: 6| Step: 11
Training loss: 2.5424907207489014
Validation loss: 2.2238301692470426

Epoch: 6| Step: 12
Training loss: 1.3138070106506348
Validation loss: 2.2133264336534726

Epoch: 6| Step: 13
Training loss: 2.2660915851593018
Validation loss: 2.061627790492068

Epoch: 298| Step: 0
Training loss: 1.971513032913208
Validation loss: 2.193322822611819

Epoch: 6| Step: 1
Training loss: 0.9990929961204529
Validation loss: 2.2081697051243117

Epoch: 6| Step: 2
Training loss: 2.0755794048309326
Validation loss: 2.129385712326214

Epoch: 6| Step: 3
Training loss: 1.9886342287063599
Validation loss: 2.217008941917009

Epoch: 6| Step: 4
Training loss: 1.445340633392334
Validation loss: 2.1254908320724324

Epoch: 6| Step: 5
Training loss: 2.155317783355713
Validation loss: 2.2095208373121036

Epoch: 6| Step: 6
Training loss: 1.4552099704742432
Validation loss: 2.2421349017850813

Epoch: 6| Step: 7
Training loss: 1.9097528457641602
Validation loss: 2.0660677315086446

Epoch: 6| Step: 8
Training loss: 1.8059027194976807
Validation loss: 2.2312988542741343

Epoch: 6| Step: 9
Training loss: 2.2340784072875977
Validation loss: 2.0823553826219294

Epoch: 6| Step: 10
Training loss: 1.4801905155181885
Validation loss: 2.21163228378501

Epoch: 6| Step: 11
Training loss: 2.4136674404144287
Validation loss: 2.1813634428926694

Epoch: 6| Step: 12
Training loss: 1.5322072505950928
Validation loss: 2.1526331260640132

Epoch: 6| Step: 13
Training loss: 2.8570947647094727
Validation loss: 2.1681320257084344

Epoch: 299| Step: 0
Training loss: 1.5923011302947998
Validation loss: 2.1475704921189176

Epoch: 6| Step: 1
Training loss: 1.8326529264450073
Validation loss: 2.130912434670233

Epoch: 6| Step: 2
Training loss: 2.1277222633361816
Validation loss: 2.2598480101554625

Epoch: 6| Step: 3
Training loss: 2.071561813354492
Validation loss: 2.1063605021404963

Epoch: 6| Step: 4
Training loss: 1.9116133451461792
Validation loss: 2.1426835483120334

Epoch: 6| Step: 5
Training loss: 2.317936420440674
Validation loss: 2.2640305103794223

Epoch: 6| Step: 6
Training loss: 1.290160894393921
Validation loss: 2.127675912713492

Epoch: 6| Step: 7
Training loss: 1.8477928638458252
Validation loss: 2.10512270978702

Epoch: 6| Step: 8
Training loss: 1.6290051937103271
Validation loss: 2.132146345671787

Epoch: 6| Step: 9
Training loss: 2.2098755836486816
Validation loss: 2.111483138094666

Epoch: 6| Step: 10
Training loss: 1.878190040588379
Validation loss: 2.15932370257634

Epoch: 6| Step: 11
Training loss: 1.5698548555374146
Validation loss: 2.074713381387854

Epoch: 6| Step: 12
Training loss: 1.8670313358306885
Validation loss: 2.1478492777834655

Epoch: 6| Step: 13
Training loss: 2.0107738971710205
Validation loss: 2.1282087487559163

Epoch: 300| Step: 0
Training loss: 2.1881368160247803
Validation loss: 2.1801327120873237

Epoch: 6| Step: 1
Training loss: 1.4847900867462158
Validation loss: 2.2218136095231578

Epoch: 6| Step: 2
Training loss: 1.8376344442367554
Validation loss: 2.073821780502155

Epoch: 6| Step: 3
Training loss: 1.620746374130249
Validation loss: 2.13886325077344

Epoch: 6| Step: 4
Training loss: 1.3905370235443115
Validation loss: 2.118108264861568

Epoch: 6| Step: 5
Training loss: 1.616715669631958
Validation loss: 2.20084261637862

Epoch: 6| Step: 6
Training loss: 1.7199645042419434
Validation loss: 2.226205587387085

Epoch: 6| Step: 7
Training loss: 1.714020013809204
Validation loss: 2.109036648145286

Epoch: 6| Step: 8
Training loss: 2.3769683837890625
Validation loss: 2.187626358001463

Epoch: 6| Step: 9
Training loss: 2.2611732482910156
Validation loss: 2.135759593338095

Epoch: 6| Step: 10
Training loss: 2.0437889099121094
Validation loss: 2.1443422443123272

Epoch: 6| Step: 11
Training loss: 1.5625232458114624
Validation loss: 2.1846982586768364

Epoch: 6| Step: 12
Training loss: 2.1188244819641113
Validation loss: 2.2018201658802647

Epoch: 6| Step: 13
Training loss: 2.854142189025879
Validation loss: 2.1639459568967103

Epoch: 301| Step: 0
Training loss: 1.4699890613555908
Validation loss: 2.2162994543711343

Epoch: 6| Step: 1
Training loss: 2.364849328994751
Validation loss: 2.167035723245272

Epoch: 6| Step: 2
Training loss: 1.445130467414856
Validation loss: 2.1808758602347424

Epoch: 6| Step: 3
Training loss: 2.2406725883483887
Validation loss: 2.1485173215148268

Epoch: 6| Step: 4
Training loss: 1.8737810850143433
Validation loss: 2.1272732057879047

Epoch: 6| Step: 5
Training loss: 2.4083855152130127
Validation loss: 2.226551586581815

Epoch: 6| Step: 6
Training loss: 1.5932824611663818
Validation loss: 2.2429709870328187

Epoch: 6| Step: 7
Training loss: 1.370692253112793
Validation loss: 2.152754391393354

Epoch: 6| Step: 8
Training loss: 2.0933690071105957
Validation loss: 2.200243079534141

Epoch: 6| Step: 9
Training loss: 1.8013314008712769
Validation loss: 2.1747538530698387

Epoch: 6| Step: 10
Training loss: 1.8773186206817627
Validation loss: 2.214401969345667

Epoch: 6| Step: 11
Training loss: 2.276137590408325
Validation loss: 2.1518290581241732

Epoch: 6| Step: 12
Training loss: 1.7631906270980835
Validation loss: 2.2007911589837845

Epoch: 6| Step: 13
Training loss: 2.248263120651245
Validation loss: 2.15963916624746

Epoch: 302| Step: 0
Training loss: 1.7767248153686523
Validation loss: 2.218567975105778

Epoch: 6| Step: 1
Training loss: 1.658156394958496
Validation loss: 2.1432392135743172

Epoch: 6| Step: 2
Training loss: 2.075558662414551
Validation loss: 2.1266090203357

Epoch: 6| Step: 3
Training loss: 2.0202672481536865
Validation loss: 2.187661829815116

Epoch: 6| Step: 4
Training loss: 2.2178399562835693
Validation loss: 2.238002989881782

Epoch: 6| Step: 5
Training loss: 1.8434863090515137
Validation loss: 2.1249963647575787

Epoch: 6| Step: 6
Training loss: 1.6172385215759277
Validation loss: 2.1644366223325013

Epoch: 6| Step: 7
Training loss: 1.466986894607544
Validation loss: 2.1243414109753025

Epoch: 6| Step: 8
Training loss: 1.6512665748596191
Validation loss: 2.185021338924285

Epoch: 6| Step: 9
Training loss: 2.134397029876709
Validation loss: 2.1439534592372116

Epoch: 6| Step: 10
Training loss: 1.970825433731079
Validation loss: 2.1153335468743437

Epoch: 6| Step: 11
Training loss: 2.5940701961517334
Validation loss: 2.200342719272901

Epoch: 6| Step: 12
Training loss: 1.4171154499053955
Validation loss: 2.094006957546357

Epoch: 6| Step: 13
Training loss: 1.7504569292068481
Validation loss: 2.1653422565870386

Epoch: 303| Step: 0
Training loss: 2.3961832523345947
Validation loss: 2.177362190779819

Epoch: 6| Step: 1
Training loss: 2.1706857681274414
Validation loss: 2.1711303316136843

Epoch: 6| Step: 2
Training loss: 1.574162483215332
Validation loss: 2.112416681422982

Epoch: 6| Step: 3
Training loss: 1.667238473892212
Validation loss: 2.1580082831844205

Epoch: 6| Step: 4
Training loss: 1.73960280418396
Validation loss: 2.145770416464857

Epoch: 6| Step: 5
Training loss: 2.0332231521606445
Validation loss: 2.2066507211295505

Epoch: 6| Step: 6
Training loss: 2.2425851821899414
Validation loss: 2.189524386518745

Epoch: 6| Step: 7
Training loss: 1.760400652885437
Validation loss: 2.1068646933442805

Epoch: 6| Step: 8
Training loss: 1.2752482891082764
Validation loss: 2.1564659854417205

Epoch: 6| Step: 9
Training loss: 2.115556478500366
Validation loss: 2.181786242351737

Epoch: 6| Step: 10
Training loss: 2.13411545753479
Validation loss: 2.1523783476121965

Epoch: 6| Step: 11
Training loss: 1.5537259578704834
Validation loss: 2.1611315819524948

Epoch: 6| Step: 12
Training loss: 1.6243081092834473
Validation loss: 2.218918242762166

Epoch: 6| Step: 13
Training loss: 2.9136152267456055
Validation loss: 2.1815517769064954

Epoch: 304| Step: 0
Training loss: 2.2890090942382812
Validation loss: 2.2259812713951193

Epoch: 6| Step: 1
Training loss: 1.5729011297225952
Validation loss: 2.2034342917062903

Epoch: 6| Step: 2
Training loss: 2.5496973991394043
Validation loss: 2.1885525744448424

Epoch: 6| Step: 3
Training loss: 1.5859516859054565
Validation loss: 2.17975385983785

Epoch: 6| Step: 4
Training loss: 2.199324607849121
Validation loss: 2.2189850448280253

Epoch: 6| Step: 5
Training loss: 2.3079147338867188
Validation loss: 2.24676521747343

Epoch: 6| Step: 6
Training loss: 1.9844515323638916
Validation loss: 2.1295492751623994

Epoch: 6| Step: 7
Training loss: 1.3563313484191895
Validation loss: 2.1199376429280927

Epoch: 6| Step: 8
Training loss: 1.9973599910736084
Validation loss: 2.162291890831404

Epoch: 6| Step: 9
Training loss: 1.6026692390441895
Validation loss: 2.1064755019321235

Epoch: 6| Step: 10
Training loss: 2.154888868331909
Validation loss: 2.167094866434733

Epoch: 6| Step: 11
Training loss: 1.6164683103561401
Validation loss: 2.1304027393300045

Epoch: 6| Step: 12
Training loss: 2.068352222442627
Validation loss: 2.2042588162165817

Epoch: 6| Step: 13
Training loss: 1.3134655952453613
Validation loss: 2.2368478710933397

Epoch: 305| Step: 0
Training loss: 2.0094172954559326
Validation loss: 2.080920655240295

Epoch: 6| Step: 1
Training loss: 1.4275891780853271
Validation loss: 2.2151330542820755

Epoch: 6| Step: 2
Training loss: 2.5095510482788086
Validation loss: 2.2684429102046515

Epoch: 6| Step: 3
Training loss: 2.0152769088745117
Validation loss: 2.130130887031555

Epoch: 6| Step: 4
Training loss: 1.8051750659942627
Validation loss: 2.2658481290263515

Epoch: 6| Step: 5
Training loss: 1.4952943325042725
Validation loss: 2.270278899900375

Epoch: 6| Step: 6
Training loss: 1.6849126815795898
Validation loss: 2.1782629387353056

Epoch: 6| Step: 7
Training loss: 1.7637817859649658
Validation loss: 2.241792227632256

Epoch: 6| Step: 8
Training loss: 2.6097564697265625
Validation loss: 2.088552574957571

Epoch: 6| Step: 9
Training loss: 1.845889925956726
Validation loss: 2.1900715853578303

Epoch: 6| Step: 10
Training loss: 1.545546293258667
Validation loss: 2.2815901899850495

Epoch: 6| Step: 11
Training loss: 1.4809445142745972
Validation loss: 2.172902496912146

Epoch: 6| Step: 12
Training loss: 1.8828063011169434
Validation loss: 2.1295508774377967

Epoch: 6| Step: 13
Training loss: 2.5388600826263428
Validation loss: 2.1537034998657885

Epoch: 306| Step: 0
Training loss: 1.5039423704147339
Validation loss: 2.1890894828304166

Epoch: 6| Step: 1
Training loss: 1.7104954719543457
Validation loss: 2.174742748660426

Epoch: 6| Step: 2
Training loss: 1.6617480516433716
Validation loss: 2.088911373128173

Epoch: 6| Step: 3
Training loss: 1.55527663230896
Validation loss: 2.1873055888760473

Epoch: 6| Step: 4
Training loss: 1.8990802764892578
Validation loss: 2.1779081488168366

Epoch: 6| Step: 5
Training loss: 1.8427283763885498
Validation loss: 2.0621298974560154

Epoch: 6| Step: 6
Training loss: 1.720427393913269
Validation loss: 2.1955547948037424

Epoch: 6| Step: 7
Training loss: 1.581428050994873
Validation loss: 2.1040196611035253

Epoch: 6| Step: 8
Training loss: 1.528782606124878
Validation loss: 2.2247206934036745

Epoch: 6| Step: 9
Training loss: 2.6416280269622803
Validation loss: 2.179514570902753

Epoch: 6| Step: 10
Training loss: 1.7791850566864014
Validation loss: 2.2071555404252905

Epoch: 6| Step: 11
Training loss: 2.271118640899658
Validation loss: 2.110821049700501

Epoch: 6| Step: 12
Training loss: 2.2441048622131348
Validation loss: 2.136658735172723

Epoch: 6| Step: 13
Training loss: 2.39322829246521
Validation loss: 2.2139726018392913

Epoch: 307| Step: 0
Training loss: 1.3606035709381104
Validation loss: 2.2043016238879134

Epoch: 6| Step: 1
Training loss: 2.1258792877197266
Validation loss: 2.1585766730769986

Epoch: 6| Step: 2
Training loss: 1.2996054887771606
Validation loss: 2.174910386403402

Epoch: 6| Step: 3
Training loss: 1.6816136837005615
Validation loss: 2.219598142049646

Epoch: 6| Step: 4
Training loss: 1.7872998714447021
Validation loss: 2.155394833575013

Epoch: 6| Step: 5
Training loss: 2.5325369834899902
Validation loss: 2.1921171449845835

Epoch: 6| Step: 6
Training loss: 1.5291569232940674
Validation loss: 2.151878115951374

Epoch: 6| Step: 7
Training loss: 1.662007451057434
Validation loss: 2.2346009233946442

Epoch: 6| Step: 8
Training loss: 2.4088668823242188
Validation loss: 2.2320502778535247

Epoch: 6| Step: 9
Training loss: 2.1459031105041504
Validation loss: 2.0812861188765495

Epoch: 6| Step: 10
Training loss: 1.6089705228805542
Validation loss: 2.234827364644697

Epoch: 6| Step: 11
Training loss: 2.50728178024292
Validation loss: 2.2711540704132407

Epoch: 6| Step: 12
Training loss: 1.7936804294586182
Validation loss: 2.1888363643359114

Epoch: 6| Step: 13
Training loss: 1.449317216873169
Validation loss: 2.1728965082476215

Epoch: 308| Step: 0
Training loss: 2.0060951709747314
Validation loss: 2.1881287277385755

Epoch: 6| Step: 1
Training loss: 1.5391263961791992
Validation loss: 2.2059017868452173

Epoch: 6| Step: 2
Training loss: 1.7296112775802612
Validation loss: 2.279424100793818

Epoch: 6| Step: 3
Training loss: 2.6619348526000977
Validation loss: 2.1448242997610443

Epoch: 6| Step: 4
Training loss: 1.869596004486084
Validation loss: 2.1596081692685365

Epoch: 6| Step: 5
Training loss: 1.8872135877609253
Validation loss: 2.211680091837401

Epoch: 6| Step: 6
Training loss: 1.726140022277832
Validation loss: 2.234510432007492

Epoch: 6| Step: 7
Training loss: 1.6126481294631958
Validation loss: 2.191884740706413

Epoch: 6| Step: 8
Training loss: 1.6705193519592285
Validation loss: 2.2718536469244186

Epoch: 6| Step: 9
Training loss: 1.1811295747756958
Validation loss: 2.2426005537791918

Epoch: 6| Step: 10
Training loss: 1.634405255317688
Validation loss: 2.15424539965968

Epoch: 6| Step: 11
Training loss: 1.4240660667419434
Validation loss: 2.120618470253483

Epoch: 6| Step: 12
Training loss: 2.40334415435791
Validation loss: 2.182476592320268

Epoch: 6| Step: 13
Training loss: 1.581066370010376
Validation loss: 2.1751623563869025

Epoch: 309| Step: 0
Training loss: 1.873530626296997
Validation loss: 2.2133829593658447

Epoch: 6| Step: 1
Training loss: 1.4274272918701172
Validation loss: 2.1388663015057965

Epoch: 6| Step: 2
Training loss: 1.5497450828552246
Validation loss: 2.1337189648741033

Epoch: 6| Step: 3
Training loss: 1.4460052251815796
Validation loss: 2.1003814102500997

Epoch: 6| Step: 4
Training loss: 1.718498706817627
Validation loss: 2.0927571455637612

Epoch: 6| Step: 5
Training loss: 2.24867582321167
Validation loss: 2.1594595037480837

Epoch: 6| Step: 6
Training loss: 2.153857707977295
Validation loss: 2.1111333831664054

Epoch: 6| Step: 7
Training loss: 2.030022621154785
Validation loss: 2.1295520464579263

Epoch: 6| Step: 8
Training loss: 1.6649845838546753
Validation loss: 2.060140399522679

Epoch: 6| Step: 9
Training loss: 1.6503803730010986
Validation loss: 2.1366257077904156

Epoch: 6| Step: 10
Training loss: 2.092818260192871
Validation loss: 2.093419918449976

Epoch: 6| Step: 11
Training loss: 2.541090488433838
Validation loss: 2.153124109391243

Epoch: 6| Step: 12
Training loss: 1.897857666015625
Validation loss: 2.1370745833202074

Epoch: 6| Step: 13
Training loss: 2.065227508544922
Validation loss: 2.1674799547400525

Epoch: 310| Step: 0
Training loss: 2.294248580932617
Validation loss: 2.3250339569584018

Epoch: 6| Step: 1
Training loss: 1.5424566268920898
Validation loss: 2.245694519371115

Epoch: 6| Step: 2
Training loss: 2.1387720108032227
Validation loss: 2.233506397534442

Epoch: 6| Step: 3
Training loss: 1.5482577085494995
Validation loss: 2.3488667318897862

Epoch: 6| Step: 4
Training loss: 2.085697650909424
Validation loss: 2.384110209762409

Epoch: 6| Step: 5
Training loss: 2.2820985317230225
Validation loss: 2.3581803306456535

Epoch: 6| Step: 6
Training loss: 1.903489351272583
Validation loss: 2.342107972791118

Epoch: 6| Step: 7
Training loss: 1.597468614578247
Validation loss: 2.343871078183574

Epoch: 6| Step: 8
Training loss: 1.509645938873291
Validation loss: 2.3922170926165838

Epoch: 6| Step: 9
Training loss: 2.4059267044067383
Validation loss: 2.325811086162444

Epoch: 6| Step: 10
Training loss: 1.8722150325775146
Validation loss: 2.2259812585769163

Epoch: 6| Step: 11
Training loss: 2.1800312995910645
Validation loss: 2.1976916020916355

Epoch: 6| Step: 12
Training loss: 1.6322376728057861
Validation loss: 2.1798455151178504

Epoch: 6| Step: 13
Training loss: 1.103676438331604
Validation loss: 2.2047611769809516

Epoch: 311| Step: 0
Training loss: 1.686953067779541
Validation loss: 2.2306272624641337

Epoch: 6| Step: 1
Training loss: 1.689200758934021
Validation loss: 2.2491954808594077

Epoch: 6| Step: 2
Training loss: 1.6337803602218628
Validation loss: 2.1319845978931715

Epoch: 6| Step: 3
Training loss: 2.4951839447021484
Validation loss: 2.195201184159966

Epoch: 6| Step: 4
Training loss: 2.4733893871307373
Validation loss: 2.1548711997206493

Epoch: 6| Step: 5
Training loss: 1.5871161222457886
Validation loss: 2.1385412780187463

Epoch: 6| Step: 6
Training loss: 2.1924686431884766
Validation loss: 2.137048987932103

Epoch: 6| Step: 7
Training loss: 1.4012326002120972
Validation loss: 2.2238393201622912

Epoch: 6| Step: 8
Training loss: 1.2383167743682861
Validation loss: 2.1593962382244807

Epoch: 6| Step: 9
Training loss: 1.6398881673812866
Validation loss: 2.0782828946267404

Epoch: 6| Step: 10
Training loss: 1.836892008781433
Validation loss: 2.1543950778181835

Epoch: 6| Step: 11
Training loss: 1.9972602128982544
Validation loss: 2.1273920036131337

Epoch: 6| Step: 12
Training loss: 1.562193512916565
Validation loss: 2.0545057609517086

Epoch: 6| Step: 13
Training loss: 2.3979530334472656
Validation loss: 2.076337830994719

Epoch: 312| Step: 0
Training loss: 2.3882460594177246
Validation loss: 2.1652469558100544

Epoch: 6| Step: 1
Training loss: 1.996647834777832
Validation loss: 2.1072055011667232

Epoch: 6| Step: 2
Training loss: 1.5770299434661865
Validation loss: 2.1520386049824376

Epoch: 6| Step: 3
Training loss: 1.2517311573028564
Validation loss: 2.191819744725381

Epoch: 6| Step: 4
Training loss: 2.1385345458984375
Validation loss: 2.170364010718561

Epoch: 6| Step: 5
Training loss: 1.5832228660583496
Validation loss: 2.0646146587146226

Epoch: 6| Step: 6
Training loss: 1.7496081590652466
Validation loss: 2.1935678515382993

Epoch: 6| Step: 7
Training loss: 2.353956460952759
Validation loss: 2.1486734215931227

Epoch: 6| Step: 8
Training loss: 1.9708603620529175
Validation loss: 2.1876930241943686

Epoch: 6| Step: 9
Training loss: 1.7449138164520264
Validation loss: 2.1488615415429555

Epoch: 6| Step: 10
Training loss: 2.2066755294799805
Validation loss: 2.154482715873308

Epoch: 6| Step: 11
Training loss: 1.6492083072662354
Validation loss: 2.240463659327517

Epoch: 6| Step: 12
Training loss: 1.3737568855285645
Validation loss: 2.1886966382303545

Epoch: 6| Step: 13
Training loss: 1.927070140838623
Validation loss: 2.292772780182541

Epoch: 313| Step: 0
Training loss: 1.3859312534332275
Validation loss: 2.1564632410644204

Epoch: 6| Step: 1
Training loss: 2.2088699340820312
Validation loss: 2.251417142088695

Epoch: 6| Step: 2
Training loss: 1.7531423568725586
Validation loss: 2.154346481446297

Epoch: 6| Step: 3
Training loss: 1.8496654033660889
Validation loss: 2.2285134779509677

Epoch: 6| Step: 4
Training loss: 2.30302095413208
Validation loss: 2.1630072721871

Epoch: 6| Step: 5
Training loss: 2.0769574642181396
Validation loss: 2.13432591320366

Epoch: 6| Step: 6
Training loss: 1.291227102279663
Validation loss: 2.164145597847559

Epoch: 6| Step: 7
Training loss: 1.9723374843597412
Validation loss: 2.120467177001379

Epoch: 6| Step: 8
Training loss: 1.2005035877227783
Validation loss: 2.2657514156833773

Epoch: 6| Step: 9
Training loss: 1.6750280857086182
Validation loss: 2.1669044571538127

Epoch: 6| Step: 10
Training loss: 1.911278247833252
Validation loss: 2.235886814773724

Epoch: 6| Step: 11
Training loss: 2.050457715988159
Validation loss: 2.153462826564748

Epoch: 6| Step: 12
Training loss: 1.4830045700073242
Validation loss: 2.275295352423063

Epoch: 6| Step: 13
Training loss: 2.197587728500366
Validation loss: 2.2056417567755586

Epoch: 314| Step: 0
Training loss: 1.6570963859558105
Validation loss: 2.2213105860576836

Epoch: 6| Step: 1
Training loss: 2.5733656883239746
Validation loss: 2.1865855634853406

Epoch: 6| Step: 2
Training loss: 1.651579737663269
Validation loss: 2.2527622484391734

Epoch: 6| Step: 3
Training loss: 0.9795842170715332
Validation loss: 2.176235400220399

Epoch: 6| Step: 4
Training loss: 2.3777670860290527
Validation loss: 2.2564248782332226

Epoch: 6| Step: 5
Training loss: 1.8429069519042969
Validation loss: 2.206830575901975

Epoch: 6| Step: 6
Training loss: 1.7063570022583008
Validation loss: 2.105675264071393

Epoch: 6| Step: 7
Training loss: 2.3115766048431396
Validation loss: 2.176205576107066

Epoch: 6| Step: 8
Training loss: 1.2668993473052979
Validation loss: 2.1317255317523913

Epoch: 6| Step: 9
Training loss: 2.4717519283294678
Validation loss: 2.087841274917767

Epoch: 6| Step: 10
Training loss: 1.4389705657958984
Validation loss: 2.14253879234355

Epoch: 6| Step: 11
Training loss: 1.1152782440185547
Validation loss: 2.220397864618609

Epoch: 6| Step: 12
Training loss: 2.0282840728759766
Validation loss: 2.2594840347125964

Epoch: 6| Step: 13
Training loss: 2.3035311698913574
Validation loss: 2.2204290820706274

Epoch: 315| Step: 0
Training loss: 1.6096694469451904
Validation loss: 2.1576033087186914

Epoch: 6| Step: 1
Training loss: 1.8351070880889893
Validation loss: 2.180245066201815

Epoch: 6| Step: 2
Training loss: 2.4776010513305664
Validation loss: 2.128032849680993

Epoch: 6| Step: 3
Training loss: 1.3153772354125977
Validation loss: 2.180781618241341

Epoch: 6| Step: 4
Training loss: 1.3603620529174805
Validation loss: 2.217860593590685

Epoch: 6| Step: 5
Training loss: 1.8014642000198364
Validation loss: 2.1191858860754196

Epoch: 6| Step: 6
Training loss: 2.297482490539551
Validation loss: 2.147789498811127

Epoch: 6| Step: 7
Training loss: 1.5555553436279297
Validation loss: 2.1715728672601844

Epoch: 6| Step: 8
Training loss: 1.31813383102417
Validation loss: 2.1643757845765803

Epoch: 6| Step: 9
Training loss: 2.1297521591186523
Validation loss: 2.24098047133415

Epoch: 6| Step: 10
Training loss: 2.1847822666168213
Validation loss: 2.2118462593324724

Epoch: 6| Step: 11
Training loss: 2.0036001205444336
Validation loss: 2.1598325390969553

Epoch: 6| Step: 12
Training loss: 2.208865165710449
Validation loss: 2.197439751317424

Epoch: 6| Step: 13
Training loss: 1.2445706129074097
Validation loss: 2.212090702467067

Epoch: 316| Step: 0
Training loss: 2.0417048931121826
Validation loss: 2.136821384071022

Epoch: 6| Step: 1
Training loss: 2.1039910316467285
Validation loss: 2.217715460767028

Epoch: 6| Step: 2
Training loss: 1.3929539918899536
Validation loss: 2.2209549309105

Epoch: 6| Step: 3
Training loss: 0.968474268913269
Validation loss: 2.0852424406236216

Epoch: 6| Step: 4
Training loss: 1.8844653367996216
Validation loss: 2.1896263655795845

Epoch: 6| Step: 5
Training loss: 1.7232911586761475
Validation loss: 2.1402486729365524

Epoch: 6| Step: 6
Training loss: 1.9169518947601318
Validation loss: 2.146071041783979

Epoch: 6| Step: 7
Training loss: 2.593865394592285
Validation loss: 2.2092944063166136

Epoch: 6| Step: 8
Training loss: 1.9281947612762451
Validation loss: 2.168363699349024

Epoch: 6| Step: 9
Training loss: 2.3656158447265625
Validation loss: 2.140921679876184

Epoch: 6| Step: 10
Training loss: 1.824297308921814
Validation loss: 2.0466366583301174

Epoch: 6| Step: 11
Training loss: 2.0046579837799072
Validation loss: 2.156512802647006

Epoch: 6| Step: 12
Training loss: 2.6171460151672363
Validation loss: 2.0668330666839436

Epoch: 6| Step: 13
Training loss: 1.2355751991271973
Validation loss: 2.083024022399738

Epoch: 317| Step: 0
Training loss: 1.3269541263580322
Validation loss: 2.1505873421187043

Epoch: 6| Step: 1
Training loss: 2.0495529174804688
Validation loss: 2.2274942782617386

Epoch: 6| Step: 2
Training loss: 1.6585156917572021
Validation loss: 2.164341954774754

Epoch: 6| Step: 3
Training loss: 2.118225574493408
Validation loss: 2.0993206167733796

Epoch: 6| Step: 4
Training loss: 1.823052167892456
Validation loss: 2.069416187142813

Epoch: 6| Step: 5
Training loss: 1.9061614274978638
Validation loss: 2.1090828129040298

Epoch: 6| Step: 6
Training loss: 1.9440693855285645
Validation loss: 2.108334195229315

Epoch: 6| Step: 7
Training loss: 1.5558037757873535
Validation loss: 2.256806937597131

Epoch: 6| Step: 8
Training loss: 1.6043061017990112
Validation loss: 2.130630636727938

Epoch: 6| Step: 9
Training loss: 2.3728885650634766
Validation loss: 2.0934676995841404

Epoch: 6| Step: 10
Training loss: 1.4224435091018677
Validation loss: 2.166151044189289

Epoch: 6| Step: 11
Training loss: 2.0577168464660645
Validation loss: 2.190873322948333

Epoch: 6| Step: 12
Training loss: 1.4413294792175293
Validation loss: 2.120126316624303

Epoch: 6| Step: 13
Training loss: 1.5400900840759277
Validation loss: 2.163104772567749

Epoch: 318| Step: 0
Training loss: 2.424877405166626
Validation loss: 2.2059925422873548

Epoch: 6| Step: 1
Training loss: 1.709337830543518
Validation loss: 2.1847580504673783

Epoch: 6| Step: 2
Training loss: 1.5672961473464966
Validation loss: 2.281516239207278

Epoch: 6| Step: 3
Training loss: 2.2651021480560303
Validation loss: 2.1099581103171072

Epoch: 6| Step: 4
Training loss: 1.6892499923706055
Validation loss: 2.225704022633132

Epoch: 6| Step: 5
Training loss: 2.268575668334961
Validation loss: 2.12274674189988

Epoch: 6| Step: 6
Training loss: 1.3827461004257202
Validation loss: 2.1945877203377346

Epoch: 6| Step: 7
Training loss: 1.8848011493682861
Validation loss: 2.1797220360848213

Epoch: 6| Step: 8
Training loss: 1.0635989904403687
Validation loss: 2.2257437167629117

Epoch: 6| Step: 9
Training loss: 1.51948082447052
Validation loss: 2.109952606180663

Epoch: 6| Step: 10
Training loss: 2.0622787475585938
Validation loss: 2.135950252573977

Epoch: 6| Step: 11
Training loss: 1.0774154663085938
Validation loss: 2.1485451549612065

Epoch: 6| Step: 12
Training loss: 1.8890351057052612
Validation loss: 2.1107929060536046

Epoch: 6| Step: 13
Training loss: 1.8988195657730103
Validation loss: 2.2517686864381194

Epoch: 319| Step: 0
Training loss: 1.3432605266571045
Validation loss: 2.2451513941569994

Epoch: 6| Step: 1
Training loss: 2.006568431854248
Validation loss: 2.1582765912496917

Epoch: 6| Step: 2
Training loss: 1.5847795009613037
Validation loss: 2.238815530653923

Epoch: 6| Step: 3
Training loss: 1.491203784942627
Validation loss: 2.147103090440073

Epoch: 6| Step: 4
Training loss: 1.8712204694747925
Validation loss: 2.2257719014280584

Epoch: 6| Step: 5
Training loss: 1.691763997077942
Validation loss: 2.15745388051515

Epoch: 6| Step: 6
Training loss: 2.196850299835205
Validation loss: 2.1202118883850756

Epoch: 6| Step: 7
Training loss: 1.678062915802002
Validation loss: 2.1169965344090618

Epoch: 6| Step: 8
Training loss: 2.2416646480560303
Validation loss: 2.1726839337297665

Epoch: 6| Step: 9
Training loss: 2.0290133953094482
Validation loss: 2.13558506068363

Epoch: 6| Step: 10
Training loss: 1.7404135465621948
Validation loss: 2.256632063978462

Epoch: 6| Step: 11
Training loss: 1.5223277807235718
Validation loss: 2.2203582820071968

Epoch: 6| Step: 12
Training loss: 1.583055853843689
Validation loss: 2.207504049424202

Epoch: 6| Step: 13
Training loss: 2.9253625869750977
Validation loss: 2.1991047218281734

Epoch: 320| Step: 0
Training loss: 1.960201621055603
Validation loss: 2.19943303959344

Epoch: 6| Step: 1
Training loss: 1.6089496612548828
Validation loss: 2.1078185573700936

Epoch: 6| Step: 2
Training loss: 1.9351829290390015
Validation loss: 2.148636899968629

Epoch: 6| Step: 3
Training loss: 1.8180291652679443
Validation loss: 2.225978551372405

Epoch: 6| Step: 4
Training loss: 1.7580844163894653
Validation loss: 2.1610126162088044

Epoch: 6| Step: 5
Training loss: 1.8812159299850464
Validation loss: 2.177619006044121

Epoch: 6| Step: 6
Training loss: 1.736051321029663
Validation loss: 2.238063099563763

Epoch: 6| Step: 7
Training loss: 1.9364914894104004
Validation loss: 2.236315455487979

Epoch: 6| Step: 8
Training loss: 1.4481667280197144
Validation loss: 2.2875254974570325

Epoch: 6| Step: 9
Training loss: 1.441164255142212
Validation loss: 2.182369265505063

Epoch: 6| Step: 10
Training loss: 1.8330986499786377
Validation loss: 2.298487550468855

Epoch: 6| Step: 11
Training loss: 2.405557632446289
Validation loss: 2.198569518263622

Epoch: 6| Step: 12
Training loss: 1.9859637022018433
Validation loss: 2.1162039567065496

Epoch: 6| Step: 13
Training loss: 1.7012078762054443
Validation loss: 2.2315076115310832

Epoch: 321| Step: 0
Training loss: 1.5671470165252686
Validation loss: 2.1733256539990826

Epoch: 6| Step: 1
Training loss: 1.6765198707580566
Validation loss: 2.1623299224402315

Epoch: 6| Step: 2
Training loss: 1.9412914514541626
Validation loss: 2.2307281263412966

Epoch: 6| Step: 3
Training loss: 1.2835897207260132
Validation loss: 2.2112931974472536

Epoch: 6| Step: 4
Training loss: 1.9131147861480713
Validation loss: 2.2217191457748413

Epoch: 6| Step: 5
Training loss: 1.28200101852417
Validation loss: 2.145897762749785

Epoch: 6| Step: 6
Training loss: 1.721157193183899
Validation loss: 2.1796474559332735

Epoch: 6| Step: 7
Training loss: 2.4497790336608887
Validation loss: 2.158493952084613

Epoch: 6| Step: 8
Training loss: 1.9018875360488892
Validation loss: 2.189121735993252

Epoch: 6| Step: 9
Training loss: 1.927039384841919
Validation loss: 2.1252955646925074

Epoch: 6| Step: 10
Training loss: 2.196341037750244
Validation loss: 2.219920522423201

Epoch: 6| Step: 11
Training loss: 1.5642378330230713
Validation loss: 2.1933789483962522

Epoch: 6| Step: 12
Training loss: 1.7336115837097168
Validation loss: 2.1776984173764466

Epoch: 6| Step: 13
Training loss: 2.0928845405578613
Validation loss: 2.110841815189649

Epoch: 322| Step: 0
Training loss: 1.4393715858459473
Validation loss: 2.277641378423219

Epoch: 6| Step: 1
Training loss: 1.5747032165527344
Validation loss: 2.1234692271037767

Epoch: 6| Step: 2
Training loss: 2.027858018875122
Validation loss: 2.18766277323487

Epoch: 6| Step: 3
Training loss: 1.9762885570526123
Validation loss: 2.0906168337791198

Epoch: 6| Step: 4
Training loss: 2.0423665046691895
Validation loss: 2.2445947893204226

Epoch: 6| Step: 5
Training loss: 1.9435019493103027
Validation loss: 2.2240592741197154

Epoch: 6| Step: 6
Training loss: 1.229230523109436
Validation loss: 2.1637310571567987

Epoch: 6| Step: 7
Training loss: 1.5196874141693115
Validation loss: 2.2060496755825576

Epoch: 6| Step: 8
Training loss: 1.9776170253753662
Validation loss: 2.213496185118152

Epoch: 6| Step: 9
Training loss: 1.0412161350250244
Validation loss: 2.273812481152114

Epoch: 6| Step: 10
Training loss: 1.8353159427642822
Validation loss: 2.2011549370263213

Epoch: 6| Step: 11
Training loss: 2.3329150676727295
Validation loss: 2.219043408670733

Epoch: 6| Step: 12
Training loss: 1.894522786140442
Validation loss: 2.1281182407051005

Epoch: 6| Step: 13
Training loss: 2.398656129837036
Validation loss: 2.173934354577013

Epoch: 323| Step: 0
Training loss: 1.416908860206604
Validation loss: 2.096817160165438

Epoch: 6| Step: 1
Training loss: 1.6191225051879883
Validation loss: 2.21621472092085

Epoch: 6| Step: 2
Training loss: 2.0060923099517822
Validation loss: 2.217523512019906

Epoch: 6| Step: 3
Training loss: 2.3232154846191406
Validation loss: 2.1669275324831725

Epoch: 6| Step: 4
Training loss: 2.2941389083862305
Validation loss: 2.2231255474910943

Epoch: 6| Step: 5
Training loss: 1.9634380340576172
Validation loss: 2.2042537402081233

Epoch: 6| Step: 6
Training loss: 2.3339130878448486
Validation loss: 2.12285416869707

Epoch: 6| Step: 7
Training loss: 2.2458744049072266
Validation loss: 2.1060841865437006

Epoch: 6| Step: 8
Training loss: 1.4228469133377075
Validation loss: 2.1758789118900093

Epoch: 6| Step: 9
Training loss: 1.1525503396987915
Validation loss: 2.1388054252952657

Epoch: 6| Step: 10
Training loss: 1.813556432723999
Validation loss: 2.25278030672381

Epoch: 6| Step: 11
Training loss: 2.1812901496887207
Validation loss: 2.191835662370087

Epoch: 6| Step: 12
Training loss: 1.6805188655853271
Validation loss: 2.1725847490372194

Epoch: 6| Step: 13
Training loss: 1.260484218597412
Validation loss: 2.140753105122556

Epoch: 324| Step: 0
Training loss: 1.6913641691207886
Validation loss: 2.157985823128813

Epoch: 6| Step: 1
Training loss: 2.01884126663208
Validation loss: 2.146190866347282

Epoch: 6| Step: 2
Training loss: 2.358930826187134
Validation loss: 2.129136347001599

Epoch: 6| Step: 3
Training loss: 2.0137314796447754
Validation loss: 2.181450956611223

Epoch: 6| Step: 4
Training loss: 2.817925214767456
Validation loss: 2.13975461324056

Epoch: 6| Step: 5
Training loss: 1.2831494808197021
Validation loss: 2.17446739955615

Epoch: 6| Step: 6
Training loss: 1.7226378917694092
Validation loss: 2.215684490819131

Epoch: 6| Step: 7
Training loss: 1.6611735820770264
Validation loss: 2.1179325990779425

Epoch: 6| Step: 8
Training loss: 1.4092698097229004
Validation loss: 2.153748522522629

Epoch: 6| Step: 9
Training loss: 1.7116014957427979
Validation loss: 2.120036599456623

Epoch: 6| Step: 10
Training loss: 1.3704644441604614
Validation loss: 2.1492348306922504

Epoch: 6| Step: 11
Training loss: 1.7603132724761963
Validation loss: 2.256812692970358

Epoch: 6| Step: 12
Training loss: 1.1389449834823608
Validation loss: 2.2554207591600317

Epoch: 6| Step: 13
Training loss: 1.9313032627105713
Validation loss: 2.1614924669265747

Epoch: 325| Step: 0
Training loss: 1.8172672986984253
Validation loss: 2.257711333613242

Epoch: 6| Step: 1
Training loss: 1.7862653732299805
Validation loss: 2.273819508091096

Epoch: 6| Step: 2
Training loss: 1.9010993242263794
Validation loss: 2.1303262736207698

Epoch: 6| Step: 3
Training loss: 1.6672136783599854
Validation loss: 2.082204777707336

Epoch: 6| Step: 4
Training loss: 1.4352363348007202
Validation loss: 2.1298414276492212

Epoch: 6| Step: 5
Training loss: 2.0294594764709473
Validation loss: 2.2192794866459344

Epoch: 6| Step: 6
Training loss: 1.9082192182540894
Validation loss: 2.2025661007050545

Epoch: 6| Step: 7
Training loss: 1.668511152267456
Validation loss: 2.145781317064839

Epoch: 6| Step: 8
Training loss: 2.5409598350524902
Validation loss: 2.151899427495977

Epoch: 6| Step: 9
Training loss: 1.4341111183166504
Validation loss: 2.1976595078745196

Epoch: 6| Step: 10
Training loss: 1.7572524547576904
Validation loss: 2.226000532027214

Epoch: 6| Step: 11
Training loss: 1.8670777082443237
Validation loss: 2.152634151520268

Epoch: 6| Step: 12
Training loss: 1.8820486068725586
Validation loss: 2.1995325601229103

Epoch: 6| Step: 13
Training loss: 2.18727445602417
Validation loss: 2.129718433144272

Epoch: 326| Step: 0
Training loss: 1.974579095840454
Validation loss: 2.2614292124266266

Epoch: 6| Step: 1
Training loss: 1.8003863096237183
Validation loss: 2.110255491349005

Epoch: 6| Step: 2
Training loss: 1.632956624031067
Validation loss: 2.153496526902722

Epoch: 6| Step: 3
Training loss: 2.4841833114624023
Validation loss: 2.2251224953641175

Epoch: 6| Step: 4
Training loss: 1.6189374923706055
Validation loss: 2.187329840916459

Epoch: 6| Step: 5
Training loss: 2.100733757019043
Validation loss: 2.1747257940230833

Epoch: 6| Step: 6
Training loss: 1.4065375328063965
Validation loss: 2.2022185479440997

Epoch: 6| Step: 7
Training loss: 1.5709888935089111
Validation loss: 2.1911755351610083

Epoch: 6| Step: 8
Training loss: 1.4533250331878662
Validation loss: 2.172524905973865

Epoch: 6| Step: 9
Training loss: 2.162215232849121
Validation loss: 2.2250940684349305

Epoch: 6| Step: 10
Training loss: 1.5041850805282593
Validation loss: 2.2128519601719354

Epoch: 6| Step: 11
Training loss: 1.7127097845077515
Validation loss: 2.2860059789431992

Epoch: 6| Step: 12
Training loss: 1.4491709470748901
Validation loss: 2.2757649908783617

Epoch: 6| Step: 13
Training loss: 1.5758843421936035
Validation loss: 2.2000543891742663

Epoch: 327| Step: 0
Training loss: 1.7235163450241089
Validation loss: 2.1995725990623556

Epoch: 6| Step: 1
Training loss: 1.2171086072921753
Validation loss: 2.1316855492130404

Epoch: 6| Step: 2
Training loss: 2.525111198425293
Validation loss: 2.106193942408408

Epoch: 6| Step: 3
Training loss: 2.34153413772583
Validation loss: 2.1395815623703824

Epoch: 6| Step: 4
Training loss: 1.9238519668579102
Validation loss: 2.1788363431089666

Epoch: 6| Step: 5
Training loss: 2.372248649597168
Validation loss: 2.1766574485327608

Epoch: 6| Step: 6
Training loss: 2.5313544273376465
Validation loss: 2.1210203939868557

Epoch: 6| Step: 7
Training loss: 1.2970733642578125
Validation loss: 2.136616514575097

Epoch: 6| Step: 8
Training loss: 1.7046927213668823
Validation loss: 2.1938930326892483

Epoch: 6| Step: 9
Training loss: 1.3152300119400024
Validation loss: 2.2301862714111165

Epoch: 6| Step: 10
Training loss: 1.1241329908370972
Validation loss: 2.2219067363328833

Epoch: 6| Step: 11
Training loss: 1.8991508483886719
Validation loss: 2.124546591953565

Epoch: 6| Step: 12
Training loss: 1.5750401020050049
Validation loss: 2.1992025029274727

Epoch: 6| Step: 13
Training loss: 2.1832423210144043
Validation loss: 2.1324178070150395

Epoch: 328| Step: 0
Training loss: 1.4286930561065674
Validation loss: 2.1681689998155

Epoch: 6| Step: 1
Training loss: 1.8293592929840088
Validation loss: 2.1239061893955355

Epoch: 6| Step: 2
Training loss: 1.7011843919754028
Validation loss: 2.090045698227421

Epoch: 6| Step: 3
Training loss: 1.806563138961792
Validation loss: 2.224354155601994

Epoch: 6| Step: 4
Training loss: 2.3949127197265625
Validation loss: 2.2160672962024646

Epoch: 6| Step: 5
Training loss: 1.3551077842712402
Validation loss: 2.216710364946755

Epoch: 6| Step: 6
Training loss: 2.0072484016418457
Validation loss: 2.235126567143266

Epoch: 6| Step: 7
Training loss: 1.9642763137817383
Validation loss: 2.208526985619658

Epoch: 6| Step: 8
Training loss: 2.5356740951538086
Validation loss: 2.1603330399400447

Epoch: 6| Step: 9
Training loss: 1.707301378250122
Validation loss: 2.1674573203568817

Epoch: 6| Step: 10
Training loss: 1.4655354022979736
Validation loss: 2.2373435471647527

Epoch: 6| Step: 11
Training loss: 0.8918179273605347
Validation loss: 2.2000809587458128

Epoch: 6| Step: 12
Training loss: 2.286374807357788
Validation loss: 2.1038444375479095

Epoch: 6| Step: 13
Training loss: 1.1427658796310425
Validation loss: 2.1336227206773657

Epoch: 329| Step: 0
Training loss: 1.3068522214889526
Validation loss: 2.122713173589399

Epoch: 6| Step: 1
Training loss: 1.785772442817688
Validation loss: 2.1401866302695325

Epoch: 6| Step: 2
Training loss: 2.0864675045013428
Validation loss: 2.199292808450678

Epoch: 6| Step: 3
Training loss: 1.8508937358856201
Validation loss: 2.17301143241185

Epoch: 6| Step: 4
Training loss: 2.091914176940918
Validation loss: 2.164774256367837

Epoch: 6| Step: 5
Training loss: 1.7684073448181152
Validation loss: 2.186196877110389

Epoch: 6| Step: 6
Training loss: 1.8705780506134033
Validation loss: 2.180005047910957

Epoch: 6| Step: 7
Training loss: 1.5509175062179565
Validation loss: 2.1123888800221104

Epoch: 6| Step: 8
Training loss: 1.155027151107788
Validation loss: 2.1372183574143278

Epoch: 6| Step: 9
Training loss: 1.7673237323760986
Validation loss: 2.1538904815591793

Epoch: 6| Step: 10
Training loss: 1.7553646564483643
Validation loss: 2.1732650508162794

Epoch: 6| Step: 11
Training loss: 2.6754558086395264
Validation loss: 2.1296312988445325

Epoch: 6| Step: 12
Training loss: 2.0395195484161377
Validation loss: 2.1531774638801493

Epoch: 6| Step: 13
Training loss: 2.051511526107788
Validation loss: 2.1233814890666673

Epoch: 330| Step: 0
Training loss: 1.3137366771697998
Validation loss: 2.2461096573901433

Epoch: 6| Step: 1
Training loss: 1.8597359657287598
Validation loss: 2.239779192914245

Epoch: 6| Step: 2
Training loss: 1.6085861921310425
Validation loss: 2.3011477480652514

Epoch: 6| Step: 3
Training loss: 1.3231505155563354
Validation loss: 2.2321060524191907

Epoch: 6| Step: 4
Training loss: 1.3156044483184814
Validation loss: 2.305951902943273

Epoch: 6| Step: 5
Training loss: 1.9812397956848145
Validation loss: 2.3797511592988045

Epoch: 6| Step: 6
Training loss: 2.2081117630004883
Validation loss: 2.257162283825618

Epoch: 6| Step: 7
Training loss: 2.296395778656006
Validation loss: 2.386521534253192

Epoch: 6| Step: 8
Training loss: 2.319683790206909
Validation loss: 2.211304849193942

Epoch: 6| Step: 9
Training loss: 1.5489453077316284
Validation loss: 2.274105736004409

Epoch: 6| Step: 10
Training loss: 1.8001395463943481
Validation loss: 2.34875702217061

Epoch: 6| Step: 11
Training loss: 2.6836440563201904
Validation loss: 2.1961846556714786

Epoch: 6| Step: 12
Training loss: 0.9657374024391174
Validation loss: 2.279484789858582

Epoch: 6| Step: 13
Training loss: 2.1913561820983887
Validation loss: 2.1976644326281805

Epoch: 331| Step: 0
Training loss: 1.4943695068359375
Validation loss: 2.1057003877496205

Epoch: 6| Step: 1
Training loss: 2.1269850730895996
Validation loss: 2.2414654121604016

Epoch: 6| Step: 2
Training loss: 2.156276226043701
Validation loss: 2.1697030785263225

Epoch: 6| Step: 3
Training loss: 1.2473737001419067
Validation loss: 2.1920298120026946

Epoch: 6| Step: 4
Training loss: 1.4095847606658936
Validation loss: 2.136386752128601

Epoch: 6| Step: 5
Training loss: 1.8465347290039062
Validation loss: 2.069172320827361

Epoch: 6| Step: 6
Training loss: 2.3405003547668457
Validation loss: 2.228375542548395

Epoch: 6| Step: 7
Training loss: 2.218848705291748
Validation loss: 2.1705805358066352

Epoch: 6| Step: 8
Training loss: 1.6300500631332397
Validation loss: 2.145239478798323

Epoch: 6| Step: 9
Training loss: 1.8470871448516846
Validation loss: 2.1486959585579495

Epoch: 6| Step: 10
Training loss: 1.716005802154541
Validation loss: 2.1571186165655813

Epoch: 6| Step: 11
Training loss: 2.1066534519195557
Validation loss: 2.2136421049794843

Epoch: 6| Step: 12
Training loss: 1.5599339008331299
Validation loss: 2.218580074207757

Epoch: 6| Step: 13
Training loss: 0.9106800556182861
Validation loss: 2.185067512655771

Epoch: 332| Step: 0
Training loss: 1.654649019241333
Validation loss: 2.225375558740349

Epoch: 6| Step: 1
Training loss: 1.4677581787109375
Validation loss: 2.088314171760313

Epoch: 6| Step: 2
Training loss: 1.6302553415298462
Validation loss: 2.178820708746551

Epoch: 6| Step: 3
Training loss: 1.8021109104156494
Validation loss: 2.103797035832559

Epoch: 6| Step: 4
Training loss: 1.6760265827178955
Validation loss: 2.2109649040365733

Epoch: 6| Step: 5
Training loss: 1.9594767093658447
Validation loss: 2.249485843925066

Epoch: 6| Step: 6
Training loss: 2.036046028137207
Validation loss: 2.272639277160809

Epoch: 6| Step: 7
Training loss: 2.4377474784851074
Validation loss: 2.2351296883757397

Epoch: 6| Step: 8
Training loss: 1.7482335567474365
Validation loss: 2.211036361673827

Epoch: 6| Step: 9
Training loss: 1.6758637428283691
Validation loss: 2.2727601041076

Epoch: 6| Step: 10
Training loss: 1.7795926332473755
Validation loss: 2.3479516301103818

Epoch: 6| Step: 11
Training loss: 0.8215646743774414
Validation loss: 2.259357161419366

Epoch: 6| Step: 12
Training loss: 1.6246850490570068
Validation loss: 2.257489060842863

Epoch: 6| Step: 13
Training loss: 2.6571013927459717
Validation loss: 2.1756599385251283

Epoch: 333| Step: 0
Training loss: 1.9272464513778687
Validation loss: 2.20457628978196

Epoch: 6| Step: 1
Training loss: 1.8604347705841064
Validation loss: 2.195078683155839

Epoch: 6| Step: 2
Training loss: 2.704051971435547
Validation loss: 2.1492405078744374

Epoch: 6| Step: 3
Training loss: 1.5196402072906494
Validation loss: 2.191673691554736

Epoch: 6| Step: 4
Training loss: 2.512640953063965
Validation loss: 2.125617548983584

Epoch: 6| Step: 5
Training loss: 1.574159860610962
Validation loss: 2.1453507113200363

Epoch: 6| Step: 6
Training loss: 1.909037709236145
Validation loss: 2.186177243468582

Epoch: 6| Step: 7
Training loss: 1.9602158069610596
Validation loss: 2.202118004522016

Epoch: 6| Step: 8
Training loss: 1.4654884338378906
Validation loss: 2.153657636334819

Epoch: 6| Step: 9
Training loss: 1.3382117748260498
Validation loss: 2.243383002537553

Epoch: 6| Step: 10
Training loss: 1.0569337606430054
Validation loss: 2.1840441893505793

Epoch: 6| Step: 11
Training loss: 1.338470458984375
Validation loss: 2.217667536068988

Epoch: 6| Step: 12
Training loss: 2.2640697956085205
Validation loss: 2.2036948383495374

Epoch: 6| Step: 13
Training loss: 1.3873432874679565
Validation loss: 2.151252705563781

Epoch: 334| Step: 0
Training loss: 2.426738739013672
Validation loss: 2.1640891644262497

Epoch: 6| Step: 1
Training loss: 1.9729464054107666
Validation loss: 2.1811009145552114

Epoch: 6| Step: 2
Training loss: 2.16572904586792
Validation loss: 2.1246052095966954

Epoch: 6| Step: 3
Training loss: 1.7220983505249023
Validation loss: 2.1723097421789683

Epoch: 6| Step: 4
Training loss: 1.769136905670166
Validation loss: 2.144209646409558

Epoch: 6| Step: 5
Training loss: 2.0140604972839355
Validation loss: 2.164729848984749

Epoch: 6| Step: 6
Training loss: 1.891326665878296
Validation loss: 2.1852341262243127

Epoch: 6| Step: 7
Training loss: 0.9326251745223999
Validation loss: 2.2267508968230216

Epoch: 6| Step: 8
Training loss: 1.1700024604797363
Validation loss: 2.2203433052186043

Epoch: 6| Step: 9
Training loss: 2.4153504371643066
Validation loss: 2.247349128928236

Epoch: 6| Step: 10
Training loss: 1.87766432762146
Validation loss: 2.1546862715034076

Epoch: 6| Step: 11
Training loss: 1.439590334892273
Validation loss: 2.11553293402477

Epoch: 6| Step: 12
Training loss: 2.235463857650757
Validation loss: 2.1808239170300063

Epoch: 6| Step: 13
Training loss: 1.4404515027999878
Validation loss: 2.147705861317214

Epoch: 335| Step: 0
Training loss: 1.717018961906433
Validation loss: 2.160986452974299

Epoch: 6| Step: 1
Training loss: 1.868685245513916
Validation loss: 2.114772057020536

Epoch: 6| Step: 2
Training loss: 1.849456548690796
Validation loss: 2.1535578761049496

Epoch: 6| Step: 3
Training loss: 1.61417818069458
Validation loss: 2.1772596143907115

Epoch: 6| Step: 4
Training loss: 1.9501149654388428
Validation loss: 2.1602044131166194

Epoch: 6| Step: 5
Training loss: 1.5433186292648315
Validation loss: 2.2486519352082284

Epoch: 6| Step: 6
Training loss: 2.3633904457092285
Validation loss: 2.158620194722247

Epoch: 6| Step: 7
Training loss: 1.9618748426437378
Validation loss: 2.1704681522102764

Epoch: 6| Step: 8
Training loss: 1.790863037109375
Validation loss: 2.1561158536582865

Epoch: 6| Step: 9
Training loss: 1.602433204650879
Validation loss: 2.142688515365765

Epoch: 6| Step: 10
Training loss: 1.7937837839126587
Validation loss: 2.118335344458139

Epoch: 6| Step: 11
Training loss: 1.986951231956482
Validation loss: 2.156576500144056

Epoch: 6| Step: 12
Training loss: 2.3119559288024902
Validation loss: 2.1202940710129274

Epoch: 6| Step: 13
Training loss: 1.9649102687835693
Validation loss: 2.174055540433494

Epoch: 336| Step: 0
Training loss: 2.1724019050598145
Validation loss: 2.1958686279994186

Epoch: 6| Step: 1
Training loss: 2.1355957984924316
Validation loss: 2.244381853329238

Epoch: 6| Step: 2
Training loss: 1.263399600982666
Validation loss: 2.225412727684103

Epoch: 6| Step: 3
Training loss: 1.6378896236419678
Validation loss: 2.168357951666719

Epoch: 6| Step: 4
Training loss: 2.270559072494507
Validation loss: 2.246869743511241

Epoch: 6| Step: 5
Training loss: 1.0842496156692505
Validation loss: 2.160456795846262

Epoch: 6| Step: 6
Training loss: 1.6917734146118164
Validation loss: 2.220089722705144

Epoch: 6| Step: 7
Training loss: 2.394073486328125
Validation loss: 2.273705195355159

Epoch: 6| Step: 8
Training loss: 1.573256254196167
Validation loss: 2.2451559728191746

Epoch: 6| Step: 9
Training loss: 2.0539424419403076
Validation loss: 2.1459445286822576

Epoch: 6| Step: 10
Training loss: 1.6834132671356201
Validation loss: 2.21085040543669

Epoch: 6| Step: 11
Training loss: 1.7710270881652832
Validation loss: 2.247144212004959

Epoch: 6| Step: 12
Training loss: 1.430305004119873
Validation loss: 2.1379264336760326

Epoch: 6| Step: 13
Training loss: 2.395754814147949
Validation loss: 2.172149996603689

Epoch: 337| Step: 0
Training loss: 1.795636773109436
Validation loss: 2.1640613694344797

Epoch: 6| Step: 1
Training loss: 1.503080129623413
Validation loss: 2.196788985242126

Epoch: 6| Step: 2
Training loss: 2.3115274906158447
Validation loss: 2.182695955358526

Epoch: 6| Step: 3
Training loss: 1.682175874710083
Validation loss: 2.1206849544279036

Epoch: 6| Step: 4
Training loss: 1.1310690641403198
Validation loss: 2.1932593417424027

Epoch: 6| Step: 5
Training loss: 1.7438266277313232
Validation loss: 2.135295493628389

Epoch: 6| Step: 6
Training loss: 1.3422424793243408
Validation loss: 2.2590670072904198

Epoch: 6| Step: 7
Training loss: 1.9659433364868164
Validation loss: 2.1156443447195072

Epoch: 6| Step: 8
Training loss: 1.8478775024414062
Validation loss: 2.1834763326952533

Epoch: 6| Step: 9
Training loss: 2.2473134994506836
Validation loss: 2.1215931523230767

Epoch: 6| Step: 10
Training loss: 1.6540191173553467
Validation loss: 2.13895583152771

Epoch: 6| Step: 11
Training loss: 2.23040771484375
Validation loss: 2.070690953603355

Epoch: 6| Step: 12
Training loss: 2.0610179901123047
Validation loss: 2.137283358522641

Epoch: 6| Step: 13
Training loss: 1.4218480587005615
Validation loss: 2.187314174508536

Epoch: 338| Step: 0
Training loss: 2.804868698120117
Validation loss: 2.2278387572175715

Epoch: 6| Step: 1
Training loss: 2.2048072814941406
Validation loss: 2.210537579751784

Epoch: 6| Step: 2
Training loss: 1.6824297904968262
Validation loss: 2.1580841208017

Epoch: 6| Step: 3
Training loss: 1.1121313571929932
Validation loss: 2.232686150458551

Epoch: 6| Step: 4
Training loss: 2.0638771057128906
Validation loss: 2.179877596516763

Epoch: 6| Step: 5
Training loss: 1.3381649255752563
Validation loss: 2.177473924493277

Epoch: 6| Step: 6
Training loss: 1.4373772144317627
Validation loss: 2.198368969783988

Epoch: 6| Step: 7
Training loss: 1.2772409915924072
Validation loss: 2.2566983225525066

Epoch: 6| Step: 8
Training loss: 1.7001547813415527
Validation loss: 2.227298614799335

Epoch: 6| Step: 9
Training loss: 1.5539027452468872
Validation loss: 2.20210773457763

Epoch: 6| Step: 10
Training loss: 2.1174957752227783
Validation loss: 2.203113314925983

Epoch: 6| Step: 11
Training loss: 2.0029382705688477
Validation loss: 2.1887783183846423

Epoch: 6| Step: 12
Training loss: 1.8296499252319336
Validation loss: 2.1473478245478805

Epoch: 6| Step: 13
Training loss: 2.613330841064453
Validation loss: 2.1946312304466002

Epoch: 339| Step: 0
Training loss: 1.9172484874725342
Validation loss: 2.265565836301414

Epoch: 6| Step: 1
Training loss: 1.2228721380233765
Validation loss: 2.161863589799532

Epoch: 6| Step: 2
Training loss: 1.8975592851638794
Validation loss: 2.0917677084604898

Epoch: 6| Step: 3
Training loss: 1.7768943309783936
Validation loss: 2.284603577788158

Epoch: 6| Step: 4
Training loss: 1.6974844932556152
Validation loss: 2.1933977680821575

Epoch: 6| Step: 5
Training loss: 2.0764575004577637
Validation loss: 2.2290382462163127

Epoch: 6| Step: 6
Training loss: 0.9513224363327026
Validation loss: 2.243045614611718

Epoch: 6| Step: 7
Training loss: 1.3112627267837524
Validation loss: 2.229667475146632

Epoch: 6| Step: 8
Training loss: 2.4307684898376465
Validation loss: 2.288054420102027

Epoch: 6| Step: 9
Training loss: 2.502150058746338
Validation loss: 2.1558811356944423

Epoch: 6| Step: 10
Training loss: 2.105354070663452
Validation loss: 2.115872108808128

Epoch: 6| Step: 11
Training loss: 1.7775236368179321
Validation loss: 2.0898709258725567

Epoch: 6| Step: 12
Training loss: 1.6825991868972778
Validation loss: 2.065683190540601

Epoch: 6| Step: 13
Training loss: 2.3058218955993652
Validation loss: 2.119778443408269

Epoch: 340| Step: 0
Training loss: 1.2790607213974
Validation loss: 2.1499311539434616

Epoch: 6| Step: 1
Training loss: 1.8319305181503296
Validation loss: 2.1726631900315643

Epoch: 6| Step: 2
Training loss: 2.148019790649414
Validation loss: 2.1154942538148616

Epoch: 6| Step: 3
Training loss: 1.113625168800354
Validation loss: 2.205762610640577

Epoch: 6| Step: 4
Training loss: 2.0407238006591797
Validation loss: 2.16054965091008

Epoch: 6| Step: 5
Training loss: 1.2997801303863525
Validation loss: 2.1752184424349057

Epoch: 6| Step: 6
Training loss: 1.5336451530456543
Validation loss: 2.205603866166966

Epoch: 6| Step: 7
Training loss: 2.116149663925171
Validation loss: 2.1413186237376225

Epoch: 6| Step: 8
Training loss: 1.821441888809204
Validation loss: 2.1393243510236024

Epoch: 6| Step: 9
Training loss: 3.270352363586426
Validation loss: 2.1717495713182675

Epoch: 6| Step: 10
Training loss: 1.6147946119308472
Validation loss: 2.172371966864473

Epoch: 6| Step: 11
Training loss: 1.6827526092529297
Validation loss: 2.174291773508954

Epoch: 6| Step: 12
Training loss: 2.063030481338501
Validation loss: 2.169238841661843

Epoch: 6| Step: 13
Training loss: 1.1374869346618652
Validation loss: 2.1549517762276436

Epoch: 341| Step: 0
Training loss: 1.9296340942382812
Validation loss: 2.189532890114733

Epoch: 6| Step: 1
Training loss: 2.0204131603240967
Validation loss: 2.1124231584610476

Epoch: 6| Step: 2
Training loss: 1.4657593965530396
Validation loss: 2.2154253734055387

Epoch: 6| Step: 3
Training loss: 2.0054707527160645
Validation loss: 2.1758472650281844

Epoch: 6| Step: 4
Training loss: 2.4677863121032715
Validation loss: 2.142471339112969

Epoch: 6| Step: 5
Training loss: 2.027989387512207
Validation loss: 2.1594612406146143

Epoch: 6| Step: 6
Training loss: 1.618221640586853
Validation loss: 2.162168606635063

Epoch: 6| Step: 7
Training loss: 1.3783202171325684
Validation loss: 2.174155342963434

Epoch: 6| Step: 8
Training loss: 1.9177370071411133
Validation loss: 2.1902195920226393

Epoch: 6| Step: 9
Training loss: 1.9250856637954712
Validation loss: 2.1793326370177732

Epoch: 6| Step: 10
Training loss: 0.9763000011444092
Validation loss: 2.2803444708547285

Epoch: 6| Step: 11
Training loss: 1.9159915447235107
Validation loss: 2.145433436157883

Epoch: 6| Step: 12
Training loss: 1.3061132431030273
Validation loss: 2.203863766885573

Epoch: 6| Step: 13
Training loss: 2.046502113342285
Validation loss: 2.216847147992862

Epoch: 342| Step: 0
Training loss: 1.161397099494934
Validation loss: 2.276369845995339

Epoch: 6| Step: 1
Training loss: 1.7949047088623047
Validation loss: 2.2160615844111287

Epoch: 6| Step: 2
Training loss: 1.5565910339355469
Validation loss: 2.207587472854122

Epoch: 6| Step: 3
Training loss: 1.6461467742919922
Validation loss: 2.1821191092973113

Epoch: 6| Step: 4
Training loss: 1.9406654834747314
Validation loss: 2.200056573396088

Epoch: 6| Step: 5
Training loss: 2.008995532989502
Validation loss: 2.11862745336307

Epoch: 6| Step: 6
Training loss: 1.6650145053863525
Validation loss: 2.207773966173972

Epoch: 6| Step: 7
Training loss: 1.9414564371109009
Validation loss: 2.129812773837838

Epoch: 6| Step: 8
Training loss: 1.9715800285339355
Validation loss: 2.1148418559822986

Epoch: 6| Step: 9
Training loss: 1.8486467599868774
Validation loss: 2.2148396404840613

Epoch: 6| Step: 10
Training loss: 1.2520179748535156
Validation loss: 2.2343793107617285

Epoch: 6| Step: 11
Training loss: 1.8555139303207397
Validation loss: 2.183335103014464

Epoch: 6| Step: 12
Training loss: 1.7163865566253662
Validation loss: 2.130471119316675

Epoch: 6| Step: 13
Training loss: 1.729683518409729
Validation loss: 2.129519203657745

Epoch: 343| Step: 0
Training loss: 1.6539250612258911
Validation loss: 2.077260728805296

Epoch: 6| Step: 1
Training loss: 2.2730143070220947
Validation loss: 2.1355387241609636

Epoch: 6| Step: 2
Training loss: 1.7114248275756836
Validation loss: 2.156544013689923

Epoch: 6| Step: 3
Training loss: 2.349552631378174
Validation loss: 2.2939648038597515

Epoch: 6| Step: 4
Training loss: 1.9400010108947754
Validation loss: 2.142525760076379

Epoch: 6| Step: 5
Training loss: 1.9726698398590088
Validation loss: 2.163338020283689

Epoch: 6| Step: 6
Training loss: 2.192056655883789
Validation loss: 2.234301038967666

Epoch: 6| Step: 7
Training loss: 1.5249323844909668
Validation loss: 2.1609430287473943

Epoch: 6| Step: 8
Training loss: 1.5742268562316895
Validation loss: 2.0960511622890348

Epoch: 6| Step: 9
Training loss: 1.2364624738693237
Validation loss: 2.210347266607387

Epoch: 6| Step: 10
Training loss: 1.5409092903137207
Validation loss: 2.276833424004175

Epoch: 6| Step: 11
Training loss: 1.4263662099838257
Validation loss: 2.092962752106369

Epoch: 6| Step: 12
Training loss: 1.458115577697754
Validation loss: 2.2233612870657318

Epoch: 6| Step: 13
Training loss: 1.3719518184661865
Validation loss: 2.265967684407388

Epoch: 344| Step: 0
Training loss: 1.6421176195144653
Validation loss: 2.121488909567556

Epoch: 6| Step: 1
Training loss: 1.3703389167785645
Validation loss: 2.211779994349326

Epoch: 6| Step: 2
Training loss: 2.070399284362793
Validation loss: 2.1204560802828882

Epoch: 6| Step: 3
Training loss: 1.5817692279815674
Validation loss: 2.202194008775937

Epoch: 6| Step: 4
Training loss: 2.11086368560791
Validation loss: 2.2786532114910822

Epoch: 6| Step: 5
Training loss: 1.712356686592102
Validation loss: 2.200333420948316

Epoch: 6| Step: 6
Training loss: 1.6284449100494385
Validation loss: 2.157866488220871

Epoch: 6| Step: 7
Training loss: 2.318908929824829
Validation loss: 2.176476959259279

Epoch: 6| Step: 8
Training loss: 1.806078314781189
Validation loss: 2.2308151132317

Epoch: 6| Step: 9
Training loss: 2.02156400680542
Validation loss: 2.300184752351494

Epoch: 6| Step: 10
Training loss: 1.6704578399658203
Validation loss: 2.2144718605984925

Epoch: 6| Step: 11
Training loss: 1.3025813102722168
Validation loss: 2.254378511059669

Epoch: 6| Step: 12
Training loss: 1.5075585842132568
Validation loss: 2.218494261464765

Epoch: 6| Step: 13
Training loss: 1.2134865522384644
Validation loss: 2.272718156537702

Epoch: 345| Step: 0
Training loss: 1.6861101388931274
Validation loss: 2.187164250240531

Epoch: 6| Step: 1
Training loss: 1.9431806802749634
Validation loss: 2.1086906386959936

Epoch: 6| Step: 2
Training loss: 1.495802640914917
Validation loss: 2.1734993444975985

Epoch: 6| Step: 3
Training loss: 1.2427843809127808
Validation loss: 2.209571769160609

Epoch: 6| Step: 4
Training loss: 1.745700716972351
Validation loss: 2.213227597616052

Epoch: 6| Step: 5
Training loss: 1.7313767671585083
Validation loss: 2.253072548938054

Epoch: 6| Step: 6
Training loss: 1.5951764583587646
Validation loss: 2.246855205105197

Epoch: 6| Step: 7
Training loss: 1.9717826843261719
Validation loss: 2.12749465562964

Epoch: 6| Step: 8
Training loss: 2.324220895767212
Validation loss: 2.091904963216474

Epoch: 6| Step: 9
Training loss: 1.9351357221603394
Validation loss: 2.1327966643917944

Epoch: 6| Step: 10
Training loss: 1.9033827781677246
Validation loss: 2.227541333885603

Epoch: 6| Step: 11
Training loss: 1.390574336051941
Validation loss: 2.2019880984419133

Epoch: 6| Step: 12
Training loss: 1.5173413753509521
Validation loss: 2.1566953287329724

Epoch: 6| Step: 13
Training loss: 2.3552463054656982
Validation loss: 2.183167211471065

Epoch: 346| Step: 0
Training loss: 1.8212101459503174
Validation loss: 2.1659608656360256

Epoch: 6| Step: 1
Training loss: 1.9776757955551147
Validation loss: 2.2703853255958966

Epoch: 6| Step: 2
Training loss: 1.6704872846603394
Validation loss: 2.123518814322769

Epoch: 6| Step: 3
Training loss: 2.117187023162842
Validation loss: 2.243184430624849

Epoch: 6| Step: 4
Training loss: 1.9059394598007202
Validation loss: 2.1268265939527944

Epoch: 6| Step: 5
Training loss: 2.21940279006958
Validation loss: 2.2018301333150556

Epoch: 6| Step: 6
Training loss: 1.5810580253601074
Validation loss: 2.1696844229134182

Epoch: 6| Step: 7
Training loss: 1.9073976278305054
Validation loss: 2.1324336387777842

Epoch: 6| Step: 8
Training loss: 1.8792672157287598
Validation loss: 2.1211139258518013

Epoch: 6| Step: 9
Training loss: 1.7585008144378662
Validation loss: 2.152002846041033

Epoch: 6| Step: 10
Training loss: 1.6270183324813843
Validation loss: 2.2939558106084026

Epoch: 6| Step: 11
Training loss: 1.7291340827941895
Validation loss: 2.184127602525937

Epoch: 6| Step: 12
Training loss: 1.7719014883041382
Validation loss: 2.193546583575587

Epoch: 6| Step: 13
Training loss: 2.207892417907715
Validation loss: 2.13946888267353

Epoch: 347| Step: 0
Training loss: 1.3510370254516602
Validation loss: 2.1779594318841093

Epoch: 6| Step: 1
Training loss: 2.0054869651794434
Validation loss: 2.3218293266911663

Epoch: 6| Step: 2
Training loss: 2.074622869491577
Validation loss: 2.283374749204164

Epoch: 6| Step: 3
Training loss: 1.733213186264038
Validation loss: 2.243397743471207

Epoch: 6| Step: 4
Training loss: 2.2534711360931396
Validation loss: 2.165239300779117

Epoch: 6| Step: 5
Training loss: 2.0398459434509277
Validation loss: 2.209242210593275

Epoch: 6| Step: 6
Training loss: 1.817657470703125
Validation loss: 2.1521996310962144

Epoch: 6| Step: 7
Training loss: 1.7527263164520264
Validation loss: 2.24409822751117

Epoch: 6| Step: 8
Training loss: 1.6136391162872314
Validation loss: 2.2122501737327984

Epoch: 6| Step: 9
Training loss: 1.3934259414672852
Validation loss: 2.155126012781615

Epoch: 6| Step: 10
Training loss: 1.4412832260131836
Validation loss: 2.178357147401379

Epoch: 6| Step: 11
Training loss: 1.9795135259628296
Validation loss: 2.155090116685437

Epoch: 6| Step: 12
Training loss: 1.4994438886642456
Validation loss: 2.1508913411889026

Epoch: 6| Step: 13
Training loss: 1.5773606300354004
Validation loss: 2.144484346912753

Epoch: 348| Step: 0
Training loss: 2.0765469074249268
Validation loss: 2.1871975583414875

Epoch: 6| Step: 1
Training loss: 1.9380717277526855
Validation loss: 2.2856782867062475

Epoch: 6| Step: 2
Training loss: 1.4689631462097168
Validation loss: 2.1568468514309136

Epoch: 6| Step: 3
Training loss: 1.509411096572876
Validation loss: 2.1476389669602916

Epoch: 6| Step: 4
Training loss: 1.5601603984832764
Validation loss: 2.161337926823606

Epoch: 6| Step: 5
Training loss: 1.936946153640747
Validation loss: 2.2241993975895706

Epoch: 6| Step: 6
Training loss: 1.274514079093933
Validation loss: 2.2321415716601956

Epoch: 6| Step: 7
Training loss: 1.4301187992095947
Validation loss: 2.1739020116867556

Epoch: 6| Step: 8
Training loss: 1.8582847118377686
Validation loss: 2.1661425252114572

Epoch: 6| Step: 9
Training loss: 1.6927529573440552
Validation loss: 2.1835701170788018

Epoch: 6| Step: 10
Training loss: 2.023385763168335
Validation loss: 2.1852266532118603

Epoch: 6| Step: 11
Training loss: 1.8952666521072388
Validation loss: 2.110779834050004

Epoch: 6| Step: 12
Training loss: 2.0609304904937744
Validation loss: 2.2353252313470326

Epoch: 6| Step: 13
Training loss: 1.9832417964935303
Validation loss: 2.206427894612794

Epoch: 349| Step: 0
Training loss: 1.7331807613372803
Validation loss: 2.257003317597092

Epoch: 6| Step: 1
Training loss: 2.542966365814209
Validation loss: 2.2446031237161286

Epoch: 6| Step: 2
Training loss: 1.41608726978302
Validation loss: 2.1567342178795927

Epoch: 6| Step: 3
Training loss: 1.3221287727355957
Validation loss: 2.3549643178139963

Epoch: 6| Step: 4
Training loss: 1.7726972103118896
Validation loss: 2.1629784722482004

Epoch: 6| Step: 5
Training loss: 1.190960168838501
Validation loss: 2.223248538150582

Epoch: 6| Step: 6
Training loss: 1.9370626211166382
Validation loss: 2.143246453295472

Epoch: 6| Step: 7
Training loss: 1.4711720943450928
Validation loss: 2.2334976247561875

Epoch: 6| Step: 8
Training loss: 1.9286432266235352
Validation loss: 2.1763767939741894

Epoch: 6| Step: 9
Training loss: 2.051938533782959
Validation loss: 2.2064413973080215

Epoch: 6| Step: 10
Training loss: 1.5671558380126953
Validation loss: 2.2162488993778022

Epoch: 6| Step: 11
Training loss: 1.1089890003204346
Validation loss: 2.2470940877032537

Epoch: 6| Step: 12
Training loss: 1.9746806621551514
Validation loss: 2.16710332388519

Epoch: 6| Step: 13
Training loss: 2.638305902481079
Validation loss: 2.1401732403744935

Epoch: 350| Step: 0
Training loss: 1.9391543865203857
Validation loss: 2.175165444292048

Epoch: 6| Step: 1
Training loss: 1.1902105808258057
Validation loss: 2.240549880971191

Epoch: 6| Step: 2
Training loss: 2.173985481262207
Validation loss: 2.0965288223758822

Epoch: 6| Step: 3
Training loss: 1.2217365503311157
Validation loss: 2.278706286543159

Epoch: 6| Step: 4
Training loss: 2.0730783939361572
Validation loss: 2.2224738162050963

Epoch: 6| Step: 5
Training loss: 1.633844256401062
Validation loss: 2.2200936309752928

Epoch: 6| Step: 6
Training loss: 1.5710840225219727
Validation loss: 2.3417850437984673

Epoch: 6| Step: 7
Training loss: 1.6665451526641846
Validation loss: 2.1627416405626523

Epoch: 6| Step: 8
Training loss: 2.205775260925293
Validation loss: 2.1504427797050885

Epoch: 6| Step: 9
Training loss: 2.0320327281951904
Validation loss: 2.2085692318536903

Epoch: 6| Step: 10
Training loss: 1.916571021080017
Validation loss: 2.2836823745440413

Epoch: 6| Step: 11
Training loss: 1.0972846746444702
Validation loss: 2.274699781530647

Epoch: 6| Step: 12
Training loss: 2.242920160293579
Validation loss: 2.244566471345963

Epoch: 6| Step: 13
Training loss: 1.6296707391738892
Validation loss: 2.2797712177358647

Epoch: 351| Step: 0
Training loss: 1.299067735671997
Validation loss: 2.2199164231618247

Epoch: 6| Step: 1
Training loss: 2.0859928131103516
Validation loss: 2.178298404139857

Epoch: 6| Step: 2
Training loss: 1.792602300643921
Validation loss: 2.1954965950340353

Epoch: 6| Step: 3
Training loss: 1.9869022369384766
Validation loss: 2.126065338811567

Epoch: 6| Step: 4
Training loss: 1.861910104751587
Validation loss: 2.209596169892178

Epoch: 6| Step: 5
Training loss: 1.4866001605987549
Validation loss: 2.1223880834476923

Epoch: 6| Step: 6
Training loss: 1.8825222253799438
Validation loss: 2.1876182363879297

Epoch: 6| Step: 7
Training loss: 1.4699627161026
Validation loss: 2.216113769879905

Epoch: 6| Step: 8
Training loss: 1.4748003482818604
Validation loss: 2.2409139525505806

Epoch: 6| Step: 9
Training loss: 1.9282947778701782
Validation loss: 2.116513881632077

Epoch: 6| Step: 10
Training loss: 1.504639983177185
Validation loss: 2.135087469572662

Epoch: 6| Step: 11
Training loss: 1.85648775100708
Validation loss: 2.161401899912024

Epoch: 6| Step: 12
Training loss: 1.9567930698394775
Validation loss: 2.226370325652502

Epoch: 6| Step: 13
Training loss: 2.2908735275268555
Validation loss: 2.243045881230344

Epoch: 352| Step: 0
Training loss: 2.0860722064971924
Validation loss: 2.22037261532199

Epoch: 6| Step: 1
Training loss: 1.480899691581726
Validation loss: 2.2503902399411766

Epoch: 6| Step: 2
Training loss: 1.5222541093826294
Validation loss: 2.316783138500747

Epoch: 6| Step: 3
Training loss: 1.7673954963684082
Validation loss: 2.35768481480178

Epoch: 6| Step: 4
Training loss: 2.106487274169922
Validation loss: 2.2544379362496

Epoch: 6| Step: 5
Training loss: 1.9202672243118286
Validation loss: 2.270808069936691

Epoch: 6| Step: 6
Training loss: 1.9663496017456055
Validation loss: 2.2641605741234234

Epoch: 6| Step: 7
Training loss: 1.689296007156372
Validation loss: 2.35557335294703

Epoch: 6| Step: 8
Training loss: 1.9142186641693115
Validation loss: 2.4191985027764433

Epoch: 6| Step: 9
Training loss: 1.8092375993728638
Validation loss: 2.313822125875822

Epoch: 6| Step: 10
Training loss: 2.0668787956237793
Validation loss: 2.404043718050885

Epoch: 6| Step: 11
Training loss: 2.1196787357330322
Validation loss: 2.292882884702375

Epoch: 6| Step: 12
Training loss: 2.182859420776367
Validation loss: 2.3114161337575605

Epoch: 6| Step: 13
Training loss: 1.6951327323913574
Validation loss: 2.1763631015695553

Epoch: 353| Step: 0
Training loss: 2.1975455284118652
Validation loss: 2.288307482196439

Epoch: 6| Step: 1
Training loss: 1.55620539188385
Validation loss: 2.1755408881812968

Epoch: 6| Step: 2
Training loss: 1.3459593057632446
Validation loss: 2.1920017555195797

Epoch: 6| Step: 3
Training loss: 2.2352747917175293
Validation loss: 2.1707875754243586

Epoch: 6| Step: 4
Training loss: 1.2880637645721436
Validation loss: 2.1973115577492663

Epoch: 6| Step: 5
Training loss: 2.2290666103363037
Validation loss: 2.19572022140667

Epoch: 6| Step: 6
Training loss: 1.877115249633789
Validation loss: 2.2859785838793685

Epoch: 6| Step: 7
Training loss: 1.4535164833068848
Validation loss: 2.1773409753717403

Epoch: 6| Step: 8
Training loss: 2.431987762451172
Validation loss: 2.193913741778302

Epoch: 6| Step: 9
Training loss: 1.8160054683685303
Validation loss: 2.152336420551423

Epoch: 6| Step: 10
Training loss: 1.7113876342773438
Validation loss: 2.209193170711558

Epoch: 6| Step: 11
Training loss: 1.3933777809143066
Validation loss: 2.2356883915521766

Epoch: 6| Step: 12
Training loss: 1.6509885787963867
Validation loss: 2.225417926747312

Epoch: 6| Step: 13
Training loss: 1.7623741626739502
Validation loss: 2.202129540904876

Epoch: 354| Step: 0
Training loss: 2.125544548034668
Validation loss: 2.2069830817560994

Epoch: 6| Step: 1
Training loss: 1.791226863861084
Validation loss: 2.1232266631177676

Epoch: 6| Step: 2
Training loss: 2.22192120552063
Validation loss: 2.2178989777001004

Epoch: 6| Step: 3
Training loss: 1.7122408151626587
Validation loss: 2.143645473705825

Epoch: 6| Step: 4
Training loss: 1.2149662971496582
Validation loss: 2.1690071116211596

Epoch: 6| Step: 5
Training loss: 1.777298092842102
Validation loss: 2.2395241491256224

Epoch: 6| Step: 6
Training loss: 2.3451318740844727
Validation loss: 2.1107584302143385

Epoch: 6| Step: 7
Training loss: 1.6727607250213623
Validation loss: 2.1671370998505624

Epoch: 6| Step: 8
Training loss: 1.405240774154663
Validation loss: 2.245718800893394

Epoch: 6| Step: 9
Training loss: 2.299346446990967
Validation loss: 2.216295237182289

Epoch: 6| Step: 10
Training loss: 1.1934747695922852
Validation loss: 2.1633128055962185

Epoch: 6| Step: 11
Training loss: 1.270271897315979
Validation loss: 2.083825367753224

Epoch: 6| Step: 12
Training loss: 2.5129151344299316
Validation loss: 2.2290062212174937

Epoch: 6| Step: 13
Training loss: 1.2877227067947388
Validation loss: 2.128360095844474

Epoch: 355| Step: 0
Training loss: 1.8509219884872437
Validation loss: 2.1468540981251705

Epoch: 6| Step: 1
Training loss: 1.74271821975708
Validation loss: 2.1986335157066264

Epoch: 6| Step: 2
Training loss: 1.5897276401519775
Validation loss: 2.164947103428584

Epoch: 6| Step: 3
Training loss: 1.8162661790847778
Validation loss: 2.12516317700827

Epoch: 6| Step: 4
Training loss: 2.074575424194336
Validation loss: 2.118122741740237

Epoch: 6| Step: 5
Training loss: 0.9768229722976685
Validation loss: 2.1677944224367858

Epoch: 6| Step: 6
Training loss: 2.000523090362549
Validation loss: 2.0499286369610856

Epoch: 6| Step: 7
Training loss: 1.8039470911026
Validation loss: 2.2116063307690363

Epoch: 6| Step: 8
Training loss: 1.4795225858688354
Validation loss: 2.094911544553695

Epoch: 6| Step: 9
Training loss: 1.9866929054260254
Validation loss: 2.2691771266280965

Epoch: 6| Step: 10
Training loss: 1.5477018356323242
Validation loss: 2.217183587371662

Epoch: 6| Step: 11
Training loss: 1.4036616086959839
Validation loss: 2.243186325155279

Epoch: 6| Step: 12
Training loss: 2.4231081008911133
Validation loss: 2.2769482135772705

Epoch: 6| Step: 13
Training loss: 1.3782844543457031
Validation loss: 2.2981534722030803

Epoch: 356| Step: 0
Training loss: 1.733799695968628
Validation loss: 2.1897029030707573

Epoch: 6| Step: 1
Training loss: 1.3298165798187256
Validation loss: 2.2619538384099163

Epoch: 6| Step: 2
Training loss: 2.5655462741851807
Validation loss: 2.2171034530926774

Epoch: 6| Step: 3
Training loss: 2.1326680183410645
Validation loss: 2.180080036963186

Epoch: 6| Step: 4
Training loss: 1.6510004997253418
Validation loss: 2.124359664096627

Epoch: 6| Step: 5
Training loss: 1.719320297241211
Validation loss: 2.190398500811669

Epoch: 6| Step: 6
Training loss: 2.2049636840820312
Validation loss: 2.284083867585787

Epoch: 6| Step: 7
Training loss: 2.009322166442871
Validation loss: 2.187194347381592

Epoch: 6| Step: 8
Training loss: 1.476806879043579
Validation loss: 2.223427500776065

Epoch: 6| Step: 9
Training loss: 1.7540392875671387
Validation loss: 2.1739274096745316

Epoch: 6| Step: 10
Training loss: 2.2746384143829346
Validation loss: 2.205154630445665

Epoch: 6| Step: 11
Training loss: 1.1521235704421997
Validation loss: 2.20144247880546

Epoch: 6| Step: 12
Training loss: 1.3610190153121948
Validation loss: 2.213153813474922

Epoch: 6| Step: 13
Training loss: 1.2320865392684937
Validation loss: 2.250422913541076

Epoch: 357| Step: 0
Training loss: 2.0387613773345947
Validation loss: 2.19477657605243

Epoch: 6| Step: 1
Training loss: 1.6115771532058716
Validation loss: 2.2853190821986042

Epoch: 6| Step: 2
Training loss: 1.5679267644882202
Validation loss: 2.16437562306722

Epoch: 6| Step: 3
Training loss: 1.7564268112182617
Validation loss: 2.1269122733864734

Epoch: 6| Step: 4
Training loss: 2.361182689666748
Validation loss: 2.1001391128827165

Epoch: 6| Step: 5
Training loss: 1.508988380432129
Validation loss: 2.191266744367538

Epoch: 6| Step: 6
Training loss: 1.8547618389129639
Validation loss: 2.215599965023738

Epoch: 6| Step: 7
Training loss: 1.6723817586898804
Validation loss: 2.1545066436131797

Epoch: 6| Step: 8
Training loss: 1.631507396697998
Validation loss: 2.204373263543652

Epoch: 6| Step: 9
Training loss: 1.769611120223999
Validation loss: 2.170561387974729

Epoch: 6| Step: 10
Training loss: 1.9419982433319092
Validation loss: 2.132540597710558

Epoch: 6| Step: 11
Training loss: 1.162163496017456
Validation loss: 2.1580936062720513

Epoch: 6| Step: 12
Training loss: 2.7123682498931885
Validation loss: 2.099615664892299

Epoch: 6| Step: 13
Training loss: 1.5611826181411743
Validation loss: 2.2449989498302503

Epoch: 358| Step: 0
Training loss: 1.519654631614685
Validation loss: 2.198443697344872

Epoch: 6| Step: 1
Training loss: 1.6111551523208618
Validation loss: 2.2679815523086058

Epoch: 6| Step: 2
Training loss: 2.2149834632873535
Validation loss: 2.3487417697906494

Epoch: 6| Step: 3
Training loss: 1.8606160879135132
Validation loss: 2.3441095877719182

Epoch: 6| Step: 4
Training loss: 1.8182413578033447
Validation loss: 2.2756580281001266

Epoch: 6| Step: 5
Training loss: 1.9155075550079346
Validation loss: 2.183256226201211

Epoch: 6| Step: 6
Training loss: 1.6743760108947754
Validation loss: 2.293324967866303

Epoch: 6| Step: 7
Training loss: 1.3519779443740845
Validation loss: 2.3187888412065405

Epoch: 6| Step: 8
Training loss: 1.3836755752563477
Validation loss: 2.2475833956913283

Epoch: 6| Step: 9
Training loss: 1.1635627746582031
Validation loss: 2.2458055224469913

Epoch: 6| Step: 10
Training loss: 2.27685546875
Validation loss: 2.1786326900605233

Epoch: 6| Step: 11
Training loss: 2.4647202491760254
Validation loss: 2.158029087128178

Epoch: 6| Step: 12
Training loss: 1.7748678922653198
Validation loss: 2.3158984338083575

Epoch: 6| Step: 13
Training loss: 2.472655773162842
Validation loss: 2.165088315163889

Epoch: 359| Step: 0
Training loss: 1.3890783786773682
Validation loss: 2.156537404624365

Epoch: 6| Step: 1
Training loss: 1.5035516023635864
Validation loss: 2.1912394685129963

Epoch: 6| Step: 2
Training loss: 1.749143362045288
Validation loss: 2.257621613881921

Epoch: 6| Step: 3
Training loss: 2.1536519527435303
Validation loss: 2.2285852662978636

Epoch: 6| Step: 4
Training loss: 1.1197106838226318
Validation loss: 2.3043696970067997

Epoch: 6| Step: 5
Training loss: 1.0482985973358154
Validation loss: 2.172166065503192

Epoch: 6| Step: 6
Training loss: 1.8815785646438599
Validation loss: 2.2243243827614734

Epoch: 6| Step: 7
Training loss: 1.7119390964508057
Validation loss: 2.224390886163199

Epoch: 6| Step: 8
Training loss: 1.8987783193588257
Validation loss: 2.2848205361315

Epoch: 6| Step: 9
Training loss: 1.530809760093689
Validation loss: 2.2131328710945706

Epoch: 6| Step: 10
Training loss: 1.7475961446762085
Validation loss: 2.2548876065079884

Epoch: 6| Step: 11
Training loss: 1.821834921836853
Validation loss: 2.255781658234135

Epoch: 6| Step: 12
Training loss: 2.473478317260742
Validation loss: 2.102886907515987

Epoch: 6| Step: 13
Training loss: 2.000962018966675
Validation loss: 2.2060764733181206

Epoch: 360| Step: 0
Training loss: 1.4847410917282104
Validation loss: 2.2245380186265513

Epoch: 6| Step: 1
Training loss: 1.1943868398666382
Validation loss: 2.1772907600607923

Epoch: 6| Step: 2
Training loss: 2.0562891960144043
Validation loss: 2.217456974009032

Epoch: 6| Step: 3
Training loss: 1.3172564506530762
Validation loss: 2.2576454134397608

Epoch: 6| Step: 4
Training loss: 2.2001752853393555
Validation loss: 2.112404819457762

Epoch: 6| Step: 5
Training loss: 1.6697059869766235
Validation loss: 2.1880061600797918

Epoch: 6| Step: 6
Training loss: 1.6786590814590454
Validation loss: 2.2348700236248713

Epoch: 6| Step: 7
Training loss: 1.3282995223999023
Validation loss: 2.1934523531185683

Epoch: 6| Step: 8
Training loss: 1.303891897201538
Validation loss: 2.201935545090706

Epoch: 6| Step: 9
Training loss: 1.8090900182724
Validation loss: 2.045769881176692

Epoch: 6| Step: 10
Training loss: 2.370962619781494
Validation loss: 2.23088716178812

Epoch: 6| Step: 11
Training loss: 1.8420218229293823
Validation loss: 2.1376379946226716

Epoch: 6| Step: 12
Training loss: 1.9183140993118286
Validation loss: 2.175091173059197

Epoch: 6| Step: 13
Training loss: 1.6171311140060425
Validation loss: 2.158253829966309

Epoch: 361| Step: 0
Training loss: 1.7866710424423218
Validation loss: 2.2651237518556657

Epoch: 6| Step: 1
Training loss: 1.7516295909881592
Validation loss: 2.193024568660285

Epoch: 6| Step: 2
Training loss: 2.0387649536132812
Validation loss: 2.1877520212563137

Epoch: 6| Step: 3
Training loss: 1.6804856061935425
Validation loss: 2.1684113933194067

Epoch: 6| Step: 4
Training loss: 1.3139618635177612
Validation loss: 2.2613845461158344

Epoch: 6| Step: 5
Training loss: 1.6094852685928345
Validation loss: 2.2162297823095836

Epoch: 6| Step: 6
Training loss: 1.5527727603912354
Validation loss: 2.2539605299631753

Epoch: 6| Step: 7
Training loss: 1.403928518295288
Validation loss: 2.134540057951404

Epoch: 6| Step: 8
Training loss: 1.6357238292694092
Validation loss: 2.2015243858419438

Epoch: 6| Step: 9
Training loss: 1.3865092992782593
Validation loss: 2.132777298650434

Epoch: 6| Step: 10
Training loss: 1.8434762954711914
Validation loss: 2.2322648238110285

Epoch: 6| Step: 11
Training loss: 3.032744884490967
Validation loss: 2.2480672738885366

Epoch: 6| Step: 12
Training loss: 2.074638605117798
Validation loss: 2.1624482729101695

Epoch: 6| Step: 13
Training loss: 1.2555512189865112
Validation loss: 2.255977858779251

Epoch: 362| Step: 0
Training loss: 2.1797854900360107
Validation loss: 2.188793182373047

Epoch: 6| Step: 1
Training loss: 1.614115595817566
Validation loss: 2.188469056160219

Epoch: 6| Step: 2
Training loss: 1.101059913635254
Validation loss: 2.2120587851411555

Epoch: 6| Step: 3
Training loss: 1.9765870571136475
Validation loss: 2.073581052082841

Epoch: 6| Step: 4
Training loss: 2.083787679672241
Validation loss: 2.1375120147582023

Epoch: 6| Step: 5
Training loss: 1.6116424798965454
Validation loss: 2.1659033195946806

Epoch: 6| Step: 6
Training loss: 2.2976598739624023
Validation loss: 2.2649418923162643

Epoch: 6| Step: 7
Training loss: 1.5762927532196045
Validation loss: 2.2088301438157276

Epoch: 6| Step: 8
Training loss: 1.441990613937378
Validation loss: 2.183054208755493

Epoch: 6| Step: 9
Training loss: 2.1989402770996094
Validation loss: 2.2811447830610376

Epoch: 6| Step: 10
Training loss: 1.4740538597106934
Validation loss: 2.1844689743493193

Epoch: 6| Step: 11
Training loss: 1.838714599609375
Validation loss: 2.1098058018633115

Epoch: 6| Step: 12
Training loss: 1.491356611251831
Validation loss: 2.2019977108124764

Epoch: 6| Step: 13
Training loss: 2.0270497798919678
Validation loss: 2.2110029266726587

Epoch: 363| Step: 0
Training loss: 1.8901917934417725
Validation loss: 2.2496106073420536

Epoch: 6| Step: 1
Training loss: 1.6220813989639282
Validation loss: 2.3121940756356842

Epoch: 6| Step: 2
Training loss: 1.7953765392303467
Validation loss: 2.2538316942030385

Epoch: 6| Step: 3
Training loss: 1.7982677221298218
Validation loss: 2.1382069408252673

Epoch: 6| Step: 4
Training loss: 1.3481788635253906
Validation loss: 2.1873998488149335

Epoch: 6| Step: 5
Training loss: 1.5697216987609863
Validation loss: 2.2584989557984056

Epoch: 6| Step: 6
Training loss: 1.4346582889556885
Validation loss: 2.1768348114464873

Epoch: 6| Step: 7
Training loss: 2.3829030990600586
Validation loss: 2.124306176298408

Epoch: 6| Step: 8
Training loss: 1.4669159650802612
Validation loss: 2.0965888705304874

Epoch: 6| Step: 9
Training loss: 2.099501132965088
Validation loss: 2.233306869383781

Epoch: 6| Step: 10
Training loss: 2.0689072608947754
Validation loss: 2.2087776045645438

Epoch: 6| Step: 11
Training loss: 1.2008965015411377
Validation loss: 2.21490906130883

Epoch: 6| Step: 12
Training loss: 2.04170560836792
Validation loss: 2.1897918255098405

Epoch: 6| Step: 13
Training loss: 1.5958319902420044
Validation loss: 2.1907062863790863

Epoch: 364| Step: 0
Training loss: 1.7782316207885742
Validation loss: 2.189122155148496

Epoch: 6| Step: 1
Training loss: 2.3112096786499023
Validation loss: 2.1620145279874086

Epoch: 6| Step: 2
Training loss: 1.4203410148620605
Validation loss: 2.150535234840967

Epoch: 6| Step: 3
Training loss: 1.0533286333084106
Validation loss: 2.105321140699489

Epoch: 6| Step: 4
Training loss: 1.8458678722381592
Validation loss: 2.1801867677319433

Epoch: 6| Step: 5
Training loss: 1.6935584545135498
Validation loss: 2.125885280229712

Epoch: 6| Step: 6
Training loss: 1.9322174787521362
Validation loss: 2.1875324992723364

Epoch: 6| Step: 7
Training loss: 1.9038641452789307
Validation loss: 2.2538724227618148

Epoch: 6| Step: 8
Training loss: 2.0699338912963867
Validation loss: 2.2365058801507436

Epoch: 6| Step: 9
Training loss: 1.7063398361206055
Validation loss: 2.114962531674293

Epoch: 6| Step: 10
Training loss: 1.7339285612106323
Validation loss: 2.245438334762409

Epoch: 6| Step: 11
Training loss: 1.6190251111984253
Validation loss: 2.2116810737117643

Epoch: 6| Step: 12
Training loss: 1.747775912284851
Validation loss: 2.187922308521886

Epoch: 6| Step: 13
Training loss: 1.9772143363952637
Validation loss: 2.23332622743422

Epoch: 365| Step: 0
Training loss: 2.035975456237793
Validation loss: 2.3165651982830417

Epoch: 6| Step: 1
Training loss: 1.3007688522338867
Validation loss: 2.3211563838425504

Epoch: 6| Step: 2
Training loss: 1.3475548028945923
Validation loss: 2.3218710781425558

Epoch: 6| Step: 3
Training loss: 1.1951837539672852
Validation loss: 2.385899956508349

Epoch: 6| Step: 4
Training loss: 1.8865402936935425
Validation loss: 2.3530472145285657

Epoch: 6| Step: 5
Training loss: 2.0576438903808594
Validation loss: 2.3357725374160276

Epoch: 6| Step: 6
Training loss: 1.4428439140319824
Validation loss: 2.3812352739354616

Epoch: 6| Step: 7
Training loss: 1.4073127508163452
Validation loss: 2.3033731675917104

Epoch: 6| Step: 8
Training loss: 1.846541404724121
Validation loss: 2.397672789071196

Epoch: 6| Step: 9
Training loss: 1.8471617698669434
Validation loss: 2.377842087899485

Epoch: 6| Step: 10
Training loss: 2.1165904998779297
Validation loss: 2.2264733570878223

Epoch: 6| Step: 11
Training loss: 2.6089515686035156
Validation loss: 2.1909421874630834

Epoch: 6| Step: 12
Training loss: 2.167307138442993
Validation loss: 2.258533057346139

Epoch: 6| Step: 13
Training loss: 1.880277395248413
Validation loss: 2.218704835061104

Epoch: 366| Step: 0
Training loss: 2.0408241748809814
Validation loss: 2.1899353304216937

Epoch: 6| Step: 1
Training loss: 1.3270848989486694
Validation loss: 2.192419272597118

Epoch: 6| Step: 2
Training loss: 1.6927322149276733
Validation loss: 2.24777554440242

Epoch: 6| Step: 3
Training loss: 1.6153042316436768
Validation loss: 2.228142708860418

Epoch: 6| Step: 4
Training loss: 1.8863909244537354
Validation loss: 2.159449949059435

Epoch: 6| Step: 5
Training loss: 2.0297958850860596
Validation loss: 2.2311924683150424

Epoch: 6| Step: 6
Training loss: 1.7839312553405762
Validation loss: 2.20956160688913

Epoch: 6| Step: 7
Training loss: 1.3702515363693237
Validation loss: 2.158709377370855

Epoch: 6| Step: 8
Training loss: 2.0750503540039062
Validation loss: 2.2074115763428392

Epoch: 6| Step: 9
Training loss: 1.9210270643234253
Validation loss: 2.222170881045762

Epoch: 6| Step: 10
Training loss: 1.4674327373504639
Validation loss: 2.2479780463762182

Epoch: 6| Step: 11
Training loss: 1.3031184673309326
Validation loss: 2.1335966202520553

Epoch: 6| Step: 12
Training loss: 1.6193726062774658
Validation loss: 2.181824452133589

Epoch: 6| Step: 13
Training loss: 1.8628785610198975
Validation loss: 2.168160541083223

Epoch: 367| Step: 0
Training loss: 1.9724700450897217
Validation loss: 2.1980864591495965

Epoch: 6| Step: 1
Training loss: 1.6741706132888794
Validation loss: 2.227128090397004

Epoch: 6| Step: 2
Training loss: 1.625928521156311
Validation loss: 2.2775048363593315

Epoch: 6| Step: 3
Training loss: 1.5667295455932617
Validation loss: 2.1497483048387753

Epoch: 6| Step: 4
Training loss: 2.0787830352783203
Validation loss: 2.1825052217770646

Epoch: 6| Step: 5
Training loss: 1.7291159629821777
Validation loss: 2.1968086611840034

Epoch: 6| Step: 6
Training loss: 1.2670297622680664
Validation loss: 2.138516451722832

Epoch: 6| Step: 7
Training loss: 1.6782801151275635
Validation loss: 2.2414570367464455

Epoch: 6| Step: 8
Training loss: 1.487917423248291
Validation loss: 2.1513021069188274

Epoch: 6| Step: 9
Training loss: 1.4786089658737183
Validation loss: 2.2408188312284407

Epoch: 6| Step: 10
Training loss: 2.525453567504883
Validation loss: 2.2276216463376115

Epoch: 6| Step: 11
Training loss: 1.7119868993759155
Validation loss: 2.118763707017386

Epoch: 6| Step: 12
Training loss: 1.3365460634231567
Validation loss: 2.161183485420801

Epoch: 6| Step: 13
Training loss: 2.238300085067749
Validation loss: 2.1754660965293966

Epoch: 368| Step: 0
Training loss: 2.1586129665374756
Validation loss: 2.1549206087666173

Epoch: 6| Step: 1
Training loss: 1.387509822845459
Validation loss: 2.179515266931185

Epoch: 6| Step: 2
Training loss: 2.0182204246520996
Validation loss: 2.212020786859656

Epoch: 6| Step: 3
Training loss: 1.4423091411590576
Validation loss: 2.2480279732775945

Epoch: 6| Step: 4
Training loss: 1.7908042669296265
Validation loss: 2.307515190493676

Epoch: 6| Step: 5
Training loss: 1.9909822940826416
Validation loss: 2.2127454767944994

Epoch: 6| Step: 6
Training loss: 1.5669209957122803
Validation loss: 2.34712911933981

Epoch: 6| Step: 7
Training loss: 1.2794325351715088
Validation loss: 2.251587898500504

Epoch: 6| Step: 8
Training loss: 1.6777633428573608
Validation loss: 2.2373228457666214

Epoch: 6| Step: 9
Training loss: 1.8248504400253296
Validation loss: 2.216024589794938

Epoch: 6| Step: 10
Training loss: 1.3024238348007202
Validation loss: 2.1930893057136127

Epoch: 6| Step: 11
Training loss: 1.6317219734191895
Validation loss: 2.2017007361176195

Epoch: 6| Step: 12
Training loss: 1.631043791770935
Validation loss: 2.156819471748926

Epoch: 6| Step: 13
Training loss: 2.233110189437866
Validation loss: 2.13826403310222

Epoch: 369| Step: 0
Training loss: 1.4404921531677246
Validation loss: 2.099835547067786

Epoch: 6| Step: 1
Training loss: 2.7883353233337402
Validation loss: 2.185423461339807

Epoch: 6| Step: 2
Training loss: 1.328033208847046
Validation loss: 2.2479205208439983

Epoch: 6| Step: 3
Training loss: 1.6779248714447021
Validation loss: 2.215259728893157

Epoch: 6| Step: 4
Training loss: 1.752868890762329
Validation loss: 2.1217122052305486

Epoch: 6| Step: 5
Training loss: 1.4143950939178467
Validation loss: 2.1483614444732666

Epoch: 6| Step: 6
Training loss: 1.8245501518249512
Validation loss: 2.178112937558082

Epoch: 6| Step: 7
Training loss: 1.5741328001022339
Validation loss: 2.1756247961392967

Epoch: 6| Step: 8
Training loss: 1.7440241575241089
Validation loss: 2.1876725509602535

Epoch: 6| Step: 9
Training loss: 1.7783000469207764
Validation loss: 2.1992929366327103

Epoch: 6| Step: 10
Training loss: 1.8433767557144165
Validation loss: 2.257323921367686

Epoch: 6| Step: 11
Training loss: 1.3867377042770386
Validation loss: 2.239708555641995

Epoch: 6| Step: 12
Training loss: 2.0499815940856934
Validation loss: 2.2325867324747066

Epoch: 6| Step: 13
Training loss: 1.362734317779541
Validation loss: 2.1930180800858365

Epoch: 370| Step: 0
Training loss: 1.5524617433547974
Validation loss: 2.1746442266689834

Epoch: 6| Step: 1
Training loss: 1.0960514545440674
Validation loss: 2.2070625110339095

Epoch: 6| Step: 2
Training loss: 1.169086217880249
Validation loss: 2.2520319928405104

Epoch: 6| Step: 3
Training loss: 1.5863959789276123
Validation loss: 2.242635509019257

Epoch: 6| Step: 4
Training loss: 2.113196849822998
Validation loss: 2.2874406076246694

Epoch: 6| Step: 5
Training loss: 1.8899176120758057
Validation loss: 2.328361392021179

Epoch: 6| Step: 6
Training loss: 1.1882073879241943
Validation loss: 2.225611032978181

Epoch: 6| Step: 7
Training loss: 1.9088234901428223
Validation loss: 2.2261323723741757

Epoch: 6| Step: 8
Training loss: 2.0828633308410645
Validation loss: 2.273246988173454

Epoch: 6| Step: 9
Training loss: 2.5870635509490967
Validation loss: 2.266206120931974

Epoch: 6| Step: 10
Training loss: 1.4542603492736816
Validation loss: 2.1620190707586144

Epoch: 6| Step: 11
Training loss: 1.7241207361221313
Validation loss: 2.2333751442611858

Epoch: 6| Step: 12
Training loss: 1.685661792755127
Validation loss: 2.21667210261027

Epoch: 6| Step: 13
Training loss: 1.9526350498199463
Validation loss: 2.15148728124557

Epoch: 371| Step: 0
Training loss: 1.6934142112731934
Validation loss: 2.3146454749568814

Epoch: 6| Step: 1
Training loss: 1.8231899738311768
Validation loss: 2.203605403182327

Epoch: 6| Step: 2
Training loss: 2.126676082611084
Validation loss: 2.1885278096763034

Epoch: 6| Step: 3
Training loss: 1.7156884670257568
Validation loss: 2.19514278698993

Epoch: 6| Step: 4
Training loss: 1.569757103919983
Validation loss: 2.2259404172179518

Epoch: 6| Step: 5
Training loss: 1.2474422454833984
Validation loss: 2.1738004094810894

Epoch: 6| Step: 6
Training loss: 1.8421695232391357
Validation loss: 2.124397773896494

Epoch: 6| Step: 7
Training loss: 1.9848941564559937
Validation loss: 2.2293461727839645

Epoch: 6| Step: 8
Training loss: 1.7269058227539062
Validation loss: 2.213914632797241

Epoch: 6| Step: 9
Training loss: 1.8321471214294434
Validation loss: 2.1406882398871967

Epoch: 6| Step: 10
Training loss: 1.8087272644042969
Validation loss: 2.0984210391198435

Epoch: 6| Step: 11
Training loss: 1.7868633270263672
Validation loss: 2.1326817133093394

Epoch: 6| Step: 12
Training loss: 1.8448586463928223
Validation loss: 2.0996792034436296

Epoch: 6| Step: 13
Training loss: 1.441759705543518
Validation loss: 2.3038696242916967

Epoch: 372| Step: 0
Training loss: 2.1001484394073486
Validation loss: 2.2177863044123494

Epoch: 6| Step: 1
Training loss: 1.7755606174468994
Validation loss: 2.203185317336872

Epoch: 6| Step: 2
Training loss: 1.94230318069458
Validation loss: 2.156057257806101

Epoch: 6| Step: 3
Training loss: 1.5630271434783936
Validation loss: 2.288584501512589

Epoch: 6| Step: 4
Training loss: 1.4966293573379517
Validation loss: 2.1364804698574926

Epoch: 6| Step: 5
Training loss: 1.3782641887664795
Validation loss: 2.314137766438146

Epoch: 6| Step: 6
Training loss: 1.413952112197876
Validation loss: 2.2552003117017847

Epoch: 6| Step: 7
Training loss: 1.9889557361602783
Validation loss: 2.2898011207580566

Epoch: 6| Step: 8
Training loss: 1.3919559717178345
Validation loss: 2.196132201020436

Epoch: 6| Step: 9
Training loss: 1.3975173234939575
Validation loss: 2.208848222609489

Epoch: 6| Step: 10
Training loss: 1.8819299936294556
Validation loss: 2.2517282168070474

Epoch: 6| Step: 11
Training loss: 1.9932857751846313
Validation loss: 2.3337550804179203

Epoch: 6| Step: 12
Training loss: 1.5982677936553955
Validation loss: 2.215778919958299

Epoch: 6| Step: 13
Training loss: 0.711907148361206
Validation loss: 2.2258388739760204

Epoch: 373| Step: 0
Training loss: 1.9029706716537476
Validation loss: 2.23857521241711

Epoch: 6| Step: 1
Training loss: 1.2669541835784912
Validation loss: 2.264009673108337

Epoch: 6| Step: 2
Training loss: 1.7991061210632324
Validation loss: 2.1527200180997133

Epoch: 6| Step: 3
Training loss: 1.4297795295715332
Validation loss: 2.224682810486004

Epoch: 6| Step: 4
Training loss: 1.5607423782348633
Validation loss: 2.2304663837596936

Epoch: 6| Step: 5
Training loss: 1.734311819076538
Validation loss: 2.1914842423572334

Epoch: 6| Step: 6
Training loss: 1.4035003185272217
Validation loss: 2.11578026125508

Epoch: 6| Step: 7
Training loss: 1.7863740921020508
Validation loss: 2.1660373287816204

Epoch: 6| Step: 8
Training loss: 1.5279691219329834
Validation loss: 2.1909056350749028

Epoch: 6| Step: 9
Training loss: 2.2591278553009033
Validation loss: 2.19128825459429

Epoch: 6| Step: 10
Training loss: 2.1613669395446777
Validation loss: 2.2242475837789555

Epoch: 6| Step: 11
Training loss: 1.1911506652832031
Validation loss: 2.1242856338459957

Epoch: 6| Step: 12
Training loss: 1.8103282451629639
Validation loss: 2.2517482055130826

Epoch: 6| Step: 13
Training loss: 2.3887271881103516
Validation loss: 2.2291979712824666

Epoch: 374| Step: 0
Training loss: 1.313762903213501
Validation loss: 2.2579896616679367

Epoch: 6| Step: 1
Training loss: 2.099907875061035
Validation loss: 2.148095646212178

Epoch: 6| Step: 2
Training loss: 1.9117772579193115
Validation loss: 2.227912543922342

Epoch: 6| Step: 3
Training loss: 1.818568229675293
Validation loss: 2.198530432998493

Epoch: 6| Step: 4
Training loss: 1.3121991157531738
Validation loss: 2.260475238164266

Epoch: 6| Step: 5
Training loss: 2.343550205230713
Validation loss: 2.2589328135213544

Epoch: 6| Step: 6
Training loss: 2.078221559524536
Validation loss: 2.0656322548466344

Epoch: 6| Step: 7
Training loss: 1.3051671981811523
Validation loss: 2.1513839101278656

Epoch: 6| Step: 8
Training loss: 1.4414472579956055
Validation loss: 2.249070396987341

Epoch: 6| Step: 9
Training loss: 2.20685076713562
Validation loss: 2.1661137021997923

Epoch: 6| Step: 10
Training loss: 1.7580811977386475
Validation loss: 2.2311506502089964

Epoch: 6| Step: 11
Training loss: 1.11415696144104
Validation loss: 2.1776416917001047

Epoch: 6| Step: 12
Training loss: 1.6127636432647705
Validation loss: 2.2013769726599417

Epoch: 6| Step: 13
Training loss: 1.6466288566589355
Validation loss: 2.226125640253867

Epoch: 375| Step: 0
Training loss: 2.3407461643218994
Validation loss: 2.2029418163402106

Epoch: 6| Step: 1
Training loss: 1.460579514503479
Validation loss: 2.1359931935546217

Epoch: 6| Step: 2
Training loss: 1.7558188438415527
Validation loss: 2.153039860469039

Epoch: 6| Step: 3
Training loss: 2.0111076831817627
Validation loss: 2.1412093152282057

Epoch: 6| Step: 4
Training loss: 0.9457533955574036
Validation loss: 2.2119156340117097

Epoch: 6| Step: 5
Training loss: 2.1313493251800537
Validation loss: 2.1324905862090406

Epoch: 6| Step: 6
Training loss: 0.8260909914970398
Validation loss: 2.1793605102005826

Epoch: 6| Step: 7
Training loss: 1.7629022598266602
Validation loss: 2.195164377971362

Epoch: 6| Step: 8
Training loss: 1.646451711654663
Validation loss: 2.1706383766666537

Epoch: 6| Step: 9
Training loss: 1.7387722730636597
Validation loss: 2.1728679428818407

Epoch: 6| Step: 10
Training loss: 2.063199520111084
Validation loss: 2.236379215794225

Epoch: 6| Step: 11
Training loss: 2.2491488456726074
Validation loss: 2.3020176990057832

Epoch: 6| Step: 12
Training loss: 1.483925223350525
Validation loss: 2.1656330054806125

Epoch: 6| Step: 13
Training loss: 1.3680524826049805
Validation loss: 2.1508701129626204

Epoch: 376| Step: 0
Training loss: 1.4862949848175049
Validation loss: 2.31892216590143

Epoch: 6| Step: 1
Training loss: 0.9038453698158264
Validation loss: 2.167013035025648

Epoch: 6| Step: 2
Training loss: 1.1794769763946533
Validation loss: 2.144418651057828

Epoch: 6| Step: 3
Training loss: 1.587780237197876
Validation loss: 2.297416079428888

Epoch: 6| Step: 4
Training loss: 1.5531506538391113
Validation loss: 2.2715398855106805

Epoch: 6| Step: 5
Training loss: 1.927282452583313
Validation loss: 2.265772960519278

Epoch: 6| Step: 6
Training loss: 1.5797712802886963
Validation loss: 2.2103582159165414

Epoch: 6| Step: 7
Training loss: 2.368927001953125
Validation loss: 2.2906866458154496

Epoch: 6| Step: 8
Training loss: 1.6638941764831543
Validation loss: 2.274873859138899

Epoch: 6| Step: 9
Training loss: 1.4727705717086792
Validation loss: 2.28563569694437

Epoch: 6| Step: 10
Training loss: 1.9262869358062744
Validation loss: 2.093555642712501

Epoch: 6| Step: 11
Training loss: 2.3075308799743652
Validation loss: 2.165068910967919

Epoch: 6| Step: 12
Training loss: 2.406765937805176
Validation loss: 2.2250258486757994

Epoch: 6| Step: 13
Training loss: 1.4931334257125854
Validation loss: 2.1090947556239303

Epoch: 377| Step: 0
Training loss: 1.1312203407287598
Validation loss: 2.157440762366018

Epoch: 6| Step: 1
Training loss: 1.3471897840499878
Validation loss: 2.17295975582574

Epoch: 6| Step: 2
Training loss: 1.8433784246444702
Validation loss: 2.242880916082731

Epoch: 6| Step: 3
Training loss: 1.729604721069336
Validation loss: 2.1501002311706543

Epoch: 6| Step: 4
Training loss: 1.7553541660308838
Validation loss: 2.1982674060329312

Epoch: 6| Step: 5
Training loss: 1.430078148841858
Validation loss: 2.2212463681415846

Epoch: 6| Step: 6
Training loss: 2.281298875808716
Validation loss: 2.229122882248253

Epoch: 6| Step: 7
Training loss: 1.611067771911621
Validation loss: 2.121817381151261

Epoch: 6| Step: 8
Training loss: 1.5249205827713013
Validation loss: 2.115893748498732

Epoch: 6| Step: 9
Training loss: 1.0721700191497803
Validation loss: 2.154480372705767

Epoch: 6| Step: 10
Training loss: 1.9108997583389282
Validation loss: 2.1707763723147813

Epoch: 6| Step: 11
Training loss: 1.8289637565612793
Validation loss: 2.1047380611460698

Epoch: 6| Step: 12
Training loss: 1.8568285703659058
Validation loss: 2.2404134555529525

Epoch: 6| Step: 13
Training loss: 1.9129019975662231
Validation loss: 2.1267330902878956

Epoch: 378| Step: 0
Training loss: 1.3261579275131226
Validation loss: 2.202093547390353

Epoch: 6| Step: 1
Training loss: 1.9213579893112183
Validation loss: 2.193140461880674

Epoch: 6| Step: 2
Training loss: 1.7322758436203003
Validation loss: 2.244303628962527

Epoch: 6| Step: 3
Training loss: 2.0782501697540283
Validation loss: 2.330722406346311

Epoch: 6| Step: 4
Training loss: 2.2661314010620117
Validation loss: 2.1941625072110083

Epoch: 6| Step: 5
Training loss: 1.3745514154434204
Validation loss: 2.2153667865260953

Epoch: 6| Step: 6
Training loss: 1.3381136655807495
Validation loss: 2.3218416552389822

Epoch: 6| Step: 7
Training loss: 1.8051782846450806
Validation loss: 2.172594129398305

Epoch: 6| Step: 8
Training loss: 1.8315520286560059
Validation loss: 2.259912726699665

Epoch: 6| Step: 9
Training loss: 1.4053535461425781
Validation loss: 2.1754598438098864

Epoch: 6| Step: 10
Training loss: 1.5158641338348389
Validation loss: 2.2298840732984644

Epoch: 6| Step: 11
Training loss: 1.77961266040802
Validation loss: 2.275348374920507

Epoch: 6| Step: 12
Training loss: 1.6019186973571777
Validation loss: 2.218143691298782

Epoch: 6| Step: 13
Training loss: 1.939443826675415
Validation loss: 2.236343909335393

Epoch: 379| Step: 0
Training loss: 1.2285315990447998
Validation loss: 2.216604965989308

Epoch: 6| Step: 1
Training loss: 1.7865209579467773
Validation loss: 2.2395483601477837

Epoch: 6| Step: 2
Training loss: 2.3563337326049805
Validation loss: 2.1453653638080885

Epoch: 6| Step: 3
Training loss: 1.6269159317016602
Validation loss: 2.2111450177367016

Epoch: 6| Step: 4
Training loss: 1.4055180549621582
Validation loss: 2.2206100212630404

Epoch: 6| Step: 5
Training loss: 2.1298694610595703
Validation loss: 2.235171869236936

Epoch: 6| Step: 6
Training loss: 1.0796102285385132
Validation loss: 2.2404639067188388

Epoch: 6| Step: 7
Training loss: 1.8700242042541504
Validation loss: 2.154767820912023

Epoch: 6| Step: 8
Training loss: 1.6064927577972412
Validation loss: 2.2567067479574554

Epoch: 6| Step: 9
Training loss: 1.3555338382720947
Validation loss: 2.204537850554271

Epoch: 6| Step: 10
Training loss: 1.967229962348938
Validation loss: 2.256740818741501

Epoch: 6| Step: 11
Training loss: 1.3885867595672607
Validation loss: 2.1884601808363393

Epoch: 6| Step: 12
Training loss: 1.2419389486312866
Validation loss: 2.3026571017439648

Epoch: 6| Step: 13
Training loss: 1.8081392049789429
Validation loss: 2.2603791221495597

Epoch: 380| Step: 0
Training loss: 1.9388182163238525
Validation loss: 2.1899278484364992

Epoch: 6| Step: 1
Training loss: 1.762519359588623
Validation loss: 2.2741969067563295

Epoch: 6| Step: 2
Training loss: 2.3012847900390625
Validation loss: 2.2004650446676437

Epoch: 6| Step: 3
Training loss: 1.6667912006378174
Validation loss: 2.09820830950173

Epoch: 6| Step: 4
Training loss: 1.4294192790985107
Validation loss: 2.1442152300188617

Epoch: 6| Step: 5
Training loss: 1.5075430870056152
Validation loss: 2.176002343495687

Epoch: 6| Step: 6
Training loss: 1.5673856735229492
Validation loss: 2.253339795656102

Epoch: 6| Step: 7
Training loss: 1.8416547775268555
Validation loss: 2.2323130792187107

Epoch: 6| Step: 8
Training loss: 2.1232047080993652
Validation loss: 2.3190170359867874

Epoch: 6| Step: 9
Training loss: 1.3860934972763062
Validation loss: 2.235595546742921

Epoch: 6| Step: 10
Training loss: 1.9776242971420288
Validation loss: 2.201394952753539

Epoch: 6| Step: 11
Training loss: 1.6304545402526855
Validation loss: 2.2191019391500824

Epoch: 6| Step: 12
Training loss: 2.039332151412964
Validation loss: 2.243973652521769

Epoch: 6| Step: 13
Training loss: 1.2282246351242065
Validation loss: 2.1883652722963722

Epoch: 381| Step: 0
Training loss: 1.7107770442962646
Validation loss: 2.171841629089848

Epoch: 6| Step: 1
Training loss: 1.3267502784729004
Validation loss: 2.23107018650219

Epoch: 6| Step: 2
Training loss: 1.3263368606567383
Validation loss: 2.101123630359609

Epoch: 6| Step: 3
Training loss: 1.9219930171966553
Validation loss: 2.1210385189261487

Epoch: 6| Step: 4
Training loss: 1.7137988805770874
Validation loss: 2.2187046543244393

Epoch: 6| Step: 5
Training loss: 1.6834540367126465
Validation loss: 2.1999495029449463

Epoch: 6| Step: 6
Training loss: 2.074066162109375
Validation loss: 2.1211580179070912

Epoch: 6| Step: 7
Training loss: 1.2268407344818115
Validation loss: 2.1135888638034945

Epoch: 6| Step: 8
Training loss: 1.012913465499878
Validation loss: 2.15154295198379

Epoch: 6| Step: 9
Training loss: 1.6638476848602295
Validation loss: 2.2074303037376812

Epoch: 6| Step: 10
Training loss: 1.7027311325073242
Validation loss: 2.118070307598319

Epoch: 6| Step: 11
Training loss: 2.080244779586792
Validation loss: 2.2245280819554485

Epoch: 6| Step: 12
Training loss: 2.565890312194824
Validation loss: 2.3526682751153105

Epoch: 6| Step: 13
Training loss: 1.6159712076187134
Validation loss: 2.138681452761414

Epoch: 382| Step: 0
Training loss: 1.6494202613830566
Validation loss: 2.215407463812059

Epoch: 6| Step: 1
Training loss: 1.5039161443710327
Validation loss: 2.2280045401665474

Epoch: 6| Step: 2
Training loss: 2.5907845497131348
Validation loss: 2.2698100613009546

Epoch: 6| Step: 3
Training loss: 1.794651985168457
Validation loss: 2.2400373284534743

Epoch: 6| Step: 4
Training loss: 1.6038872003555298
Validation loss: 2.214206054646482

Epoch: 6| Step: 5
Training loss: 1.3162572383880615
Validation loss: 2.227515953843312

Epoch: 6| Step: 6
Training loss: 1.5433517694473267
Validation loss: 2.1400773961056947

Epoch: 6| Step: 7
Training loss: 1.6849654912948608
Validation loss: 2.1467059837874545

Epoch: 6| Step: 8
Training loss: 1.9725956916809082
Validation loss: 2.2012608833210443

Epoch: 6| Step: 9
Training loss: 2.04998779296875
Validation loss: 2.3198508703580467

Epoch: 6| Step: 10
Training loss: 1.4596343040466309
Validation loss: 2.264940719450674

Epoch: 6| Step: 11
Training loss: 1.1323137283325195
Validation loss: 2.162112484696091

Epoch: 6| Step: 12
Training loss: 2.0062198638916016
Validation loss: 2.1778365565884497

Epoch: 6| Step: 13
Training loss: 1.2860803604125977
Validation loss: 2.1625020068178893

Epoch: 383| Step: 0
Training loss: 1.7671706676483154
Validation loss: 2.1010696759787937

Epoch: 6| Step: 1
Training loss: 2.6168248653411865
Validation loss: 2.2420714260429464

Epoch: 6| Step: 2
Training loss: 1.731978416442871
Validation loss: 2.245831541476711

Epoch: 6| Step: 3
Training loss: 1.143349528312683
Validation loss: 2.156079148733488

Epoch: 6| Step: 4
Training loss: 1.8427624702453613
Validation loss: 2.1407486572060535

Epoch: 6| Step: 5
Training loss: 1.3633594512939453
Validation loss: 2.172558899848692

Epoch: 6| Step: 6
Training loss: 1.4793198108673096
Validation loss: 2.074947052104499

Epoch: 6| Step: 7
Training loss: 1.4050732851028442
Validation loss: 2.192605273697966

Epoch: 6| Step: 8
Training loss: 1.7925164699554443
Validation loss: 2.2320716278527373

Epoch: 6| Step: 9
Training loss: 1.5138764381408691
Validation loss: 2.1240174411445536

Epoch: 6| Step: 10
Training loss: 2.0076980590820312
Validation loss: 2.156231035468399

Epoch: 6| Step: 11
Training loss: 2.322331666946411
Validation loss: 2.23807422320048

Epoch: 6| Step: 12
Training loss: 0.8775012493133545
Validation loss: 2.1886519514104372

Epoch: 6| Step: 13
Training loss: 1.483916163444519
Validation loss: 2.2182533946088565

Epoch: 384| Step: 0
Training loss: 1.8481996059417725
Validation loss: 2.196750376814155

Epoch: 6| Step: 1
Training loss: 1.055870771408081
Validation loss: 2.2418082811499156

Epoch: 6| Step: 2
Training loss: 1.7388534545898438
Validation loss: 2.206314686805971

Epoch: 6| Step: 3
Training loss: 1.6903741359710693
Validation loss: 2.2665351642075406

Epoch: 6| Step: 4
Training loss: 1.6315845251083374
Validation loss: 2.148672334609493

Epoch: 6| Step: 5
Training loss: 1.2824407815933228
Validation loss: 2.202294844453053

Epoch: 6| Step: 6
Training loss: 1.9343445301055908
Validation loss: 2.229128843994551

Epoch: 6| Step: 7
Training loss: 1.705758810043335
Validation loss: 2.236612530164821

Epoch: 6| Step: 8
Training loss: 1.6614115238189697
Validation loss: 2.263606050963043

Epoch: 6| Step: 9
Training loss: 1.7138229608535767
Validation loss: 2.2357587160602694

Epoch: 6| Step: 10
Training loss: 2.2314939498901367
Validation loss: 2.2123901946570284

Epoch: 6| Step: 11
Training loss: 1.3783632516860962
Validation loss: 2.355345218412338

Epoch: 6| Step: 12
Training loss: 2.4399125576019287
Validation loss: 2.2445856883961666

Epoch: 6| Step: 13
Training loss: 1.479575753211975
Validation loss: 2.2508457963184645

Epoch: 385| Step: 0
Training loss: 1.3347426652908325
Validation loss: 2.184496236103837

Epoch: 6| Step: 1
Training loss: 1.617748498916626
Validation loss: 2.3078453002437467

Epoch: 6| Step: 2
Training loss: 1.9937312602996826
Validation loss: 2.2213715609683784

Epoch: 6| Step: 3
Training loss: 1.6986697912216187
Validation loss: 2.1773264382475164

Epoch: 6| Step: 4
Training loss: 2.08793568611145
Validation loss: 2.284762805508029

Epoch: 6| Step: 5
Training loss: 2.17527174949646
Validation loss: 2.2672801722762403

Epoch: 6| Step: 6
Training loss: 1.5823931694030762
Validation loss: 2.213274940367668

Epoch: 6| Step: 7
Training loss: 1.6161303520202637
Validation loss: 2.2961126014750493

Epoch: 6| Step: 8
Training loss: 1.8866766691207886
Validation loss: 2.2529847775736163

Epoch: 6| Step: 9
Training loss: 1.7563832998275757
Validation loss: 2.261929048004971

Epoch: 6| Step: 10
Training loss: 1.2801775932312012
Validation loss: 2.2366792540396414

Epoch: 6| Step: 11
Training loss: 1.8533586263656616
Validation loss: 2.1780994989538707

Epoch: 6| Step: 12
Training loss: 1.6095616817474365
Validation loss: 2.2164411903709493

Epoch: 6| Step: 13
Training loss: 1.4378211498260498
Validation loss: 2.2361885655310845

Epoch: 386| Step: 0
Training loss: 1.6740800142288208
Validation loss: 2.199494133713425

Epoch: 6| Step: 1
Training loss: 1.5716629028320312
Validation loss: 2.259818853870515

Epoch: 6| Step: 2
Training loss: 2.0837903022766113
Validation loss: 2.282642736229845

Epoch: 6| Step: 3
Training loss: 1.3605825901031494
Validation loss: 2.1696733710586384

Epoch: 6| Step: 4
Training loss: 2.1647701263427734
Validation loss: 2.2339316080975276

Epoch: 6| Step: 5
Training loss: 1.6899089813232422
Validation loss: 2.320457773823892

Epoch: 6| Step: 6
Training loss: 1.8491230010986328
Validation loss: 2.149720356028567

Epoch: 6| Step: 7
Training loss: 1.6827505826950073
Validation loss: 2.251468648192703

Epoch: 6| Step: 8
Training loss: 0.8993512988090515
Validation loss: 2.18159443460485

Epoch: 6| Step: 9
Training loss: 2.4893383979797363
Validation loss: 2.1521213951931206

Epoch: 6| Step: 10
Training loss: 1.4758484363555908
Validation loss: 2.2100257232624996

Epoch: 6| Step: 11
Training loss: 1.8097426891326904
Validation loss: 2.241290589814545

Epoch: 6| Step: 12
Training loss: 1.970134973526001
Validation loss: 2.2749922070451962

Epoch: 6| Step: 13
Training loss: 1.1026090383529663
Validation loss: 2.1527951584067395

Epoch: 387| Step: 0
Training loss: 1.6019352674484253
Validation loss: 2.140571412219796

Epoch: 6| Step: 1
Training loss: 2.316368579864502
Validation loss: 2.1767770359593053

Epoch: 6| Step: 2
Training loss: 1.3764848709106445
Validation loss: 2.2434989957399267

Epoch: 6| Step: 3
Training loss: 1.5276780128479004
Validation loss: 2.146145761653941

Epoch: 6| Step: 4
Training loss: 1.292207956314087
Validation loss: 2.316545219831569

Epoch: 6| Step: 5
Training loss: 1.4378199577331543
Validation loss: 2.2023975054423013

Epoch: 6| Step: 6
Training loss: 1.3971850872039795
Validation loss: 2.2757333158164896

Epoch: 6| Step: 7
Training loss: 2.0624260902404785
Validation loss: 2.219012757783295

Epoch: 6| Step: 8
Training loss: 2.3005566596984863
Validation loss: 2.270505259113927

Epoch: 6| Step: 9
Training loss: 1.846078872680664
Validation loss: 2.17776124195386

Epoch: 6| Step: 10
Training loss: 2.131662607192993
Validation loss: 2.1412134734533166

Epoch: 6| Step: 11
Training loss: 1.9116764068603516
Validation loss: 2.0809487553053003

Epoch: 6| Step: 12
Training loss: 1.5295251607894897
Validation loss: 2.1912850359434723

Epoch: 6| Step: 13
Training loss: 1.440316915512085
Validation loss: 2.1777225976349204

Epoch: 388| Step: 0
Training loss: 1.868809700012207
Validation loss: 2.230296791240733

Epoch: 6| Step: 1
Training loss: 1.8057935237884521
Validation loss: 2.1469570821331394

Epoch: 6| Step: 2
Training loss: 1.3644969463348389
Validation loss: 2.190446190936591

Epoch: 6| Step: 3
Training loss: 2.214277744293213
Validation loss: 2.169356902440389

Epoch: 6| Step: 4
Training loss: 1.9574599266052246
Validation loss: 2.2613581521536714

Epoch: 6| Step: 5
Training loss: 1.3850857019424438
Validation loss: 2.1523134246949227

Epoch: 6| Step: 6
Training loss: 1.445176124572754
Validation loss: 2.215522627676687

Epoch: 6| Step: 7
Training loss: 1.5546026229858398
Validation loss: 2.2683318456014

Epoch: 6| Step: 8
Training loss: 1.6736942529678345
Validation loss: 2.1035961989433534

Epoch: 6| Step: 9
Training loss: 1.993542194366455
Validation loss: 2.303048037713574

Epoch: 6| Step: 10
Training loss: 1.4596463441848755
Validation loss: 2.2481645871234197

Epoch: 6| Step: 11
Training loss: 2.2697932720184326
Validation loss: 2.2110285066789195

Epoch: 6| Step: 12
Training loss: 1.500846266746521
Validation loss: 2.1740158322036907

Epoch: 6| Step: 13
Training loss: 2.011640787124634
Validation loss: 2.1467514396995626

Epoch: 389| Step: 0
Training loss: 1.9659876823425293
Validation loss: 2.2892585236539125

Epoch: 6| Step: 1
Training loss: 1.304551601409912
Validation loss: 2.2183036906744844

Epoch: 6| Step: 2
Training loss: 1.5580339431762695
Validation loss: 2.2036840736225085

Epoch: 6| Step: 3
Training loss: 1.252305507659912
Validation loss: 2.198301133289132

Epoch: 6| Step: 4
Training loss: 1.453236699104309
Validation loss: 2.1513071265271915

Epoch: 6| Step: 5
Training loss: 1.735586166381836
Validation loss: 2.1433513613157373

Epoch: 6| Step: 6
Training loss: 1.6272517442703247
Validation loss: 2.224471758770686

Epoch: 6| Step: 7
Training loss: 1.8482409715652466
Validation loss: 2.225748109561141

Epoch: 6| Step: 8
Training loss: 1.7766759395599365
Validation loss: 2.2141328909063853

Epoch: 6| Step: 9
Training loss: 1.9241812229156494
Validation loss: 2.1238053306456535

Epoch: 6| Step: 10
Training loss: 1.2597122192382812
Validation loss: 2.179139975578554

Epoch: 6| Step: 11
Training loss: 1.9109234809875488
Validation loss: 2.249889061015139

Epoch: 6| Step: 12
Training loss: 1.895353078842163
Validation loss: 2.160414964922013

Epoch: 6| Step: 13
Training loss: 1.1330509185791016
Validation loss: 2.131145602913313

Epoch: 390| Step: 0
Training loss: 2.165954113006592
Validation loss: 2.214147542112617

Epoch: 6| Step: 1
Training loss: 1.9632439613342285
Validation loss: 2.1427804834099224

Epoch: 6| Step: 2
Training loss: 1.305419683456421
Validation loss: 2.1678049179815475

Epoch: 6| Step: 3
Training loss: 0.9505038261413574
Validation loss: 2.195370033223142

Epoch: 6| Step: 4
Training loss: 1.9770570993423462
Validation loss: 2.1635627362035934

Epoch: 6| Step: 5
Training loss: 1.3823754787445068
Validation loss: 2.1786046233228458

Epoch: 6| Step: 6
Training loss: 1.5647109746932983
Validation loss: 2.200779994328817

Epoch: 6| Step: 7
Training loss: 2.1067957878112793
Validation loss: 2.0800410342472855

Epoch: 6| Step: 8
Training loss: 2.5573906898498535
Validation loss: 2.2390936164445776

Epoch: 6| Step: 9
Training loss: 1.8599053621292114
Validation loss: 2.164910372867379

Epoch: 6| Step: 10
Training loss: 1.0837085247039795
Validation loss: 2.1769803775254117

Epoch: 6| Step: 11
Training loss: 1.091829776763916
Validation loss: 2.2060925729813112

Epoch: 6| Step: 12
Training loss: 1.7208614349365234
Validation loss: 2.1498064840993574

Epoch: 6| Step: 13
Training loss: 1.279276967048645
Validation loss: 2.2412350664856615

Epoch: 391| Step: 0
Training loss: 1.4495790004730225
Validation loss: 2.3579234461630545

Epoch: 6| Step: 1
Training loss: 1.3167660236358643
Validation loss: 2.316243907456757

Epoch: 6| Step: 2
Training loss: 1.488817572593689
Validation loss: 2.1886059994338662

Epoch: 6| Step: 3
Training loss: 1.524968147277832
Validation loss: 2.249122582456117

Epoch: 6| Step: 4
Training loss: 1.8880550861358643
Validation loss: 2.320360496479978

Epoch: 6| Step: 5
Training loss: 1.6039066314697266
Validation loss: 2.315736973157493

Epoch: 6| Step: 6
Training loss: 1.6899582147598267
Validation loss: 2.2257200338507213

Epoch: 6| Step: 7
Training loss: 2.128436803817749
Validation loss: 2.280425715190108

Epoch: 6| Step: 8
Training loss: 1.7185112237930298
Validation loss: 2.2722674274957306

Epoch: 6| Step: 9
Training loss: 2.565702438354492
Validation loss: 2.2959056156937794

Epoch: 6| Step: 10
Training loss: 2.3271665573120117
Validation loss: 2.2087070403560514

Epoch: 6| Step: 11
Training loss: 1.4480034112930298
Validation loss: 2.1878053885634228

Epoch: 6| Step: 12
Training loss: 1.429020881652832
Validation loss: 2.20794875391068

Epoch: 6| Step: 13
Training loss: 1.85958993434906
Validation loss: 2.2250633496110157

Epoch: 392| Step: 0
Training loss: 2.149648904800415
Validation loss: 2.175903458749094

Epoch: 6| Step: 1
Training loss: 2.015775203704834
Validation loss: 2.181987254850326

Epoch: 6| Step: 2
Training loss: 1.5092136859893799
Validation loss: 2.166046521996939

Epoch: 6| Step: 3
Training loss: 1.1209468841552734
Validation loss: 2.125562631955711

Epoch: 6| Step: 4
Training loss: 1.6943399906158447
Validation loss: 2.1968491718333256

Epoch: 6| Step: 5
Training loss: 1.7767049074172974
Validation loss: 2.1040995441457278

Epoch: 6| Step: 6
Training loss: 1.5563642978668213
Validation loss: 2.221783664918715

Epoch: 6| Step: 7
Training loss: 1.9051814079284668
Validation loss: 2.2535874689778974

Epoch: 6| Step: 8
Training loss: 1.8815128803253174
Validation loss: 2.177792392751222

Epoch: 6| Step: 9
Training loss: 1.6756281852722168
Validation loss: 2.125334526902886

Epoch: 6| Step: 10
Training loss: 1.497202754020691
Validation loss: 2.182842182856734

Epoch: 6| Step: 11
Training loss: 1.7727216482162476
Validation loss: 2.225333832925366

Epoch: 6| Step: 12
Training loss: 1.1321908235549927
Validation loss: 2.1710371214856385

Epoch: 6| Step: 13
Training loss: 2.052175998687744
Validation loss: 2.1301801512318272

Epoch: 393| Step: 0
Training loss: 1.5981297492980957
Validation loss: 2.2436379899260817

Epoch: 6| Step: 1
Training loss: 1.783094882965088
Validation loss: 2.1603877954585577

Epoch: 6| Step: 2
Training loss: 1.5952075719833374
Validation loss: 2.1890490811358214

Epoch: 6| Step: 3
Training loss: 2.4310226440429688
Validation loss: 2.1885567813791256

Epoch: 6| Step: 4
Training loss: 1.3712891340255737
Validation loss: 2.232111438628166

Epoch: 6| Step: 5
Training loss: 1.6540086269378662
Validation loss: 2.333491781706451

Epoch: 6| Step: 6
Training loss: 1.2626792192459106
Validation loss: 2.2974390957945134

Epoch: 6| Step: 7
Training loss: 0.8787940740585327
Validation loss: 2.1943068504333496

Epoch: 6| Step: 8
Training loss: 2.281261920928955
Validation loss: 2.206373083976007

Epoch: 6| Step: 9
Training loss: 2.097543478012085
Validation loss: 2.1611032806416994

Epoch: 6| Step: 10
Training loss: 2.359147548675537
Validation loss: 2.187091778683406

Epoch: 6| Step: 11
Training loss: 1.9466313123703003
Validation loss: 2.2553906440734863

Epoch: 6| Step: 12
Training loss: 1.5629631280899048
Validation loss: 2.241694978488389

Epoch: 6| Step: 13
Training loss: 1.890053629875183
Validation loss: 2.236801060297156

Epoch: 394| Step: 0
Training loss: 1.4473987817764282
Validation loss: 2.2525499482308664

Epoch: 6| Step: 1
Training loss: 1.606086254119873
Validation loss: 2.23583476005062

Epoch: 6| Step: 2
Training loss: 1.7501649856567383
Validation loss: 2.2356720534704064

Epoch: 6| Step: 3
Training loss: 1.7308752536773682
Validation loss: 2.1414325045001124

Epoch: 6| Step: 4
Training loss: 2.0725135803222656
Validation loss: 2.190399134030906

Epoch: 6| Step: 5
Training loss: 1.754305362701416
Validation loss: 2.193128252542147

Epoch: 6| Step: 6
Training loss: 2.0430281162261963
Validation loss: 2.1314078146411526

Epoch: 6| Step: 7
Training loss: 1.5362809896469116
Validation loss: 2.2008406808299403

Epoch: 6| Step: 8
Training loss: 1.8265894651412964
Validation loss: 2.180661714205178

Epoch: 6| Step: 9
Training loss: 2.413379669189453
Validation loss: 2.2090509783837105

Epoch: 6| Step: 10
Training loss: 1.2721762657165527
Validation loss: 2.260084875168339

Epoch: 6| Step: 11
Training loss: 1.5538599491119385
Validation loss: 2.148299827370592

Epoch: 6| Step: 12
Training loss: 0.8672149181365967
Validation loss: 2.285171090915639

Epoch: 6| Step: 13
Training loss: 2.2944412231445312
Validation loss: 2.202381739052393

Epoch: 395| Step: 0
Training loss: 1.4589533805847168
Validation loss: 2.185072450227635

Epoch: 6| Step: 1
Training loss: 2.1034440994262695
Validation loss: 2.296966419425062

Epoch: 6| Step: 2
Training loss: 1.8346202373504639
Validation loss: 2.2420294464275403

Epoch: 6| Step: 3
Training loss: 1.5240719318389893
Validation loss: 2.286872722769296

Epoch: 6| Step: 4
Training loss: 1.2929701805114746
Validation loss: 2.2666914437406804

Epoch: 6| Step: 5
Training loss: 1.6840941905975342
Validation loss: 2.22500459096765

Epoch: 6| Step: 6
Training loss: 2.009765148162842
Validation loss: 2.287785135289674

Epoch: 6| Step: 7
Training loss: 2.6365199089050293
Validation loss: 2.266339050826206

Epoch: 6| Step: 8
Training loss: 1.053608775138855
Validation loss: 2.1968433985146145

Epoch: 6| Step: 9
Training loss: 1.5684055089950562
Validation loss: 2.196527255478726

Epoch: 6| Step: 10
Training loss: 1.6471977233886719
Validation loss: 2.2913889346584195

Epoch: 6| Step: 11
Training loss: 1.6748847961425781
Validation loss: 2.1557153053181146

Epoch: 6| Step: 12
Training loss: 1.9421229362487793
Validation loss: 2.1816401058627712

Epoch: 6| Step: 13
Training loss: 1.3179652690887451
Validation loss: 2.361711960966869

Epoch: 396| Step: 0
Training loss: 1.9961603879928589
Validation loss: 2.299018403535248

Epoch: 6| Step: 1
Training loss: 1.2872631549835205
Validation loss: 2.2133384494371313

Epoch: 6| Step: 2
Training loss: 2.046067476272583
Validation loss: 2.1056903587874545

Epoch: 6| Step: 3
Training loss: 1.6862858533859253
Validation loss: 2.141140345604189

Epoch: 6| Step: 4
Training loss: 2.4051408767700195
Validation loss: 2.229596504601099

Epoch: 6| Step: 5
Training loss: 1.0632545948028564
Validation loss: 2.2055853669361403

Epoch: 6| Step: 6
Training loss: 1.607051134109497
Validation loss: 2.223302928350305

Epoch: 6| Step: 7
Training loss: 1.447259545326233
Validation loss: 2.110241784844347

Epoch: 6| Step: 8
Training loss: 1.459441900253296
Validation loss: 2.16424237784519

Epoch: 6| Step: 9
Training loss: 1.710999608039856
Validation loss: 2.2297744904795

Epoch: 6| Step: 10
Training loss: 1.2291768789291382
Validation loss: 2.1482915173294725

Epoch: 6| Step: 11
Training loss: 2.1532928943634033
Validation loss: 2.2790079501367386

Epoch: 6| Step: 12
Training loss: 2.077798843383789
Validation loss: 2.216975841470944

Epoch: 6| Step: 13
Training loss: 1.0898165702819824
Validation loss: 2.2059750377490954

Epoch: 397| Step: 0
Training loss: 1.698655366897583
Validation loss: 2.178475441471223

Epoch: 6| Step: 1
Training loss: 2.169933795928955
Validation loss: 2.206433134694253

Epoch: 6| Step: 2
Training loss: 1.1012084484100342
Validation loss: 2.2015250370066655

Epoch: 6| Step: 3
Training loss: 1.9292895793914795
Validation loss: 2.177602183434271

Epoch: 6| Step: 4
Training loss: 1.7527787685394287
Validation loss: 2.2294253380067888

Epoch: 6| Step: 5
Training loss: 1.1158368587493896
Validation loss: 2.2081192924130346

Epoch: 6| Step: 6
Training loss: 1.917401671409607
Validation loss: 2.340294248314314

Epoch: 6| Step: 7
Training loss: 2.296099901199341
Validation loss: 2.158172845840454

Epoch: 6| Step: 8
Training loss: 1.3567941188812256
Validation loss: 2.1960665167018933

Epoch: 6| Step: 9
Training loss: 1.1683721542358398
Validation loss: 2.3420253492170766

Epoch: 6| Step: 10
Training loss: 1.8166248798370361
Validation loss: 2.1894610902314544

Epoch: 6| Step: 11
Training loss: 1.8098933696746826
Validation loss: 2.219366365863431

Epoch: 6| Step: 12
Training loss: 2.118468999862671
Validation loss: 2.177272173666185

Epoch: 6| Step: 13
Training loss: 1.6657541990280151
Validation loss: 2.2505558408716673

Epoch: 398| Step: 0
Training loss: 1.3904908895492554
Validation loss: 2.1474103286702144

Epoch: 6| Step: 1
Training loss: 2.3559718132019043
Validation loss: 2.1632974878434212

Epoch: 6| Step: 2
Training loss: 1.4888689517974854
Validation loss: 2.1527695296913065

Epoch: 6| Step: 3
Training loss: 1.2114510536193848
Validation loss: 2.13855137876285

Epoch: 6| Step: 4
Training loss: 1.8437803983688354
Validation loss: 2.1513229852081626

Epoch: 6| Step: 5
Training loss: 2.093334674835205
Validation loss: 2.2001894315083823

Epoch: 6| Step: 6
Training loss: 1.663770079612732
Validation loss: 2.239667582255538

Epoch: 6| Step: 7
Training loss: 1.3315834999084473
Validation loss: 2.1847756703694663

Epoch: 6| Step: 8
Training loss: 2.0152034759521484
Validation loss: 2.171195410913037

Epoch: 6| Step: 9
Training loss: 1.6318600177764893
Validation loss: 2.226135084705968

Epoch: 6| Step: 10
Training loss: 2.259084701538086
Validation loss: 2.1733644623910227

Epoch: 6| Step: 11
Training loss: 1.494615077972412
Validation loss: 2.1889915902127504

Epoch: 6| Step: 12
Training loss: 1.4368730783462524
Validation loss: 2.224149486070038

Epoch: 6| Step: 13
Training loss: 1.3689920902252197
Validation loss: 2.237878094437302

Epoch: 399| Step: 0
Training loss: 1.2346339225769043
Validation loss: 2.152134564615065

Epoch: 6| Step: 1
Training loss: 2.0302343368530273
Validation loss: 2.230193325268325

Epoch: 6| Step: 2
Training loss: 1.9222615957260132
Validation loss: 2.2061739711351294

Epoch: 6| Step: 3
Training loss: 1.7650517225265503
Validation loss: 2.287006602492384

Epoch: 6| Step: 4
Training loss: 1.7419390678405762
Validation loss: 2.2107923312853743

Epoch: 6| Step: 5
Training loss: 1.5607514381408691
Validation loss: 2.1366822001754597

Epoch: 6| Step: 6
Training loss: 1.828780174255371
Validation loss: 2.2575671595911824

Epoch: 6| Step: 7
Training loss: 2.1813406944274902
Validation loss: 2.1771621832283596

Epoch: 6| Step: 8
Training loss: 1.3274704217910767
Validation loss: 2.1322138258205947

Epoch: 6| Step: 9
Training loss: 1.2568647861480713
Validation loss: 2.2888013086011334

Epoch: 6| Step: 10
Training loss: 1.660752534866333
Validation loss: 2.2121951298047136

Epoch: 6| Step: 11
Training loss: 1.7810167074203491
Validation loss: 2.142000421400993

Epoch: 6| Step: 12
Training loss: 1.5504605770111084
Validation loss: 2.196383999240014

Epoch: 6| Step: 13
Training loss: 0.9765491485595703
Validation loss: 2.211001726888841

Epoch: 400| Step: 0
Training loss: 1.3637992143630981
Validation loss: 2.178723468575426

Epoch: 6| Step: 1
Training loss: 2.0667262077331543
Validation loss: 2.2267036566170315

Epoch: 6| Step: 2
Training loss: 1.7528760433197021
Validation loss: 2.2170478477272937

Epoch: 6| Step: 3
Training loss: 1.3298064470291138
Validation loss: 2.2931072250489266

Epoch: 6| Step: 4
Training loss: 1.7323116064071655
Validation loss: 2.298184658891411

Epoch: 6| Step: 5
Training loss: 1.4128612279891968
Validation loss: 2.1349012185168523

Epoch: 6| Step: 6
Training loss: 2.423109769821167
Validation loss: 2.2417983290969685

Epoch: 6| Step: 7
Training loss: 1.7763675451278687
Validation loss: 2.2005921397157895

Epoch: 6| Step: 8
Training loss: 1.7617089748382568
Validation loss: 2.2722003280475573

Epoch: 6| Step: 9
Training loss: 1.813685655593872
Validation loss: 2.203511958481163

Epoch: 6| Step: 10
Training loss: 1.4749746322631836
Validation loss: 2.2025676978531705

Epoch: 6| Step: 11
Training loss: 1.3759640455245972
Validation loss: 2.199570930132302

Epoch: 6| Step: 12
Training loss: 1.3748518228530884
Validation loss: 2.2543634676164195

Epoch: 6| Step: 13
Training loss: 2.4428563117980957
Validation loss: 2.1735049524614887

Epoch: 401| Step: 0
Training loss: 1.7848230600357056
Validation loss: 2.1836707694556123

Epoch: 6| Step: 1
Training loss: 1.837088942527771
Validation loss: 2.210349408529138

Epoch: 6| Step: 2
Training loss: 1.7166976928710938
Validation loss: 2.106838151972781

Epoch: 6| Step: 3
Training loss: 2.2748868465423584
Validation loss: 2.1189254189050324

Epoch: 6| Step: 4
Training loss: 1.39895498752594
Validation loss: 2.226038461090416

Epoch: 6| Step: 5
Training loss: 1.2421307563781738
Validation loss: 2.1819309983202206

Epoch: 6| Step: 6
Training loss: 2.3690547943115234
Validation loss: 2.2179372900275776

Epoch: 6| Step: 7
Training loss: 1.216421365737915
Validation loss: 2.173248173088156

Epoch: 6| Step: 8
Training loss: 1.6346728801727295
Validation loss: 2.279110682907925

Epoch: 6| Step: 9
Training loss: 1.736519455909729
Validation loss: 2.2414369224220194

Epoch: 6| Step: 10
Training loss: 1.3138158321380615
Validation loss: 2.2027256386254424

Epoch: 6| Step: 11
Training loss: 1.7577836513519287
Validation loss: 2.2215137968781176

Epoch: 6| Step: 12
Training loss: 1.8844455480575562
Validation loss: 2.209480711208877

Epoch: 6| Step: 13
Training loss: 1.6770761013031006
Validation loss: 2.161034322554065

Epoch: 402| Step: 0
Training loss: 2.191155433654785
Validation loss: 2.0765529909441547

Epoch: 6| Step: 1
Training loss: 0.9150162935256958
Validation loss: 2.1950180325456845

Epoch: 6| Step: 2
Training loss: 1.5529097318649292
Validation loss: 2.2601049356563117

Epoch: 6| Step: 3
Training loss: 1.6223406791687012
Validation loss: 2.219473615769417

Epoch: 6| Step: 4
Training loss: 1.822577714920044
Validation loss: 2.2994516536753666

Epoch: 6| Step: 5
Training loss: 1.3925087451934814
Validation loss: 2.2078779820472962

Epoch: 6| Step: 6
Training loss: 1.5896315574645996
Validation loss: 2.139855912936631

Epoch: 6| Step: 7
Training loss: 1.8366624116897583
Validation loss: 2.225059606695688

Epoch: 6| Step: 8
Training loss: 1.2353596687316895
Validation loss: 2.262095264209214

Epoch: 6| Step: 9
Training loss: 2.119169235229492
Validation loss: 2.2462214180218276

Epoch: 6| Step: 10
Training loss: 2.011589527130127
Validation loss: 2.091117125685497

Epoch: 6| Step: 11
Training loss: 1.5920466184616089
Validation loss: 2.2568995080968386

Epoch: 6| Step: 12
Training loss: 1.9297964572906494
Validation loss: 2.220804516987134

Epoch: 6| Step: 13
Training loss: 1.0407105684280396
Validation loss: 2.1305015856219875

Epoch: 403| Step: 0
Training loss: 1.9733712673187256
Validation loss: 2.14678519515581

Epoch: 6| Step: 1
Training loss: 1.462087631225586
Validation loss: 2.2176235337411203

Epoch: 6| Step: 2
Training loss: 1.6684014797210693
Validation loss: 2.2797643574335242

Epoch: 6| Step: 3
Training loss: 1.9803338050842285
Validation loss: 2.2065954900556997

Epoch: 6| Step: 4
Training loss: 1.6220145225524902
Validation loss: 2.1847532744048745

Epoch: 6| Step: 5
Training loss: 1.6077253818511963
Validation loss: 2.1881386285187094

Epoch: 6| Step: 6
Training loss: 1.3376449346542358
Validation loss: 2.223108614644697

Epoch: 6| Step: 7
Training loss: 1.8046213388442993
Validation loss: 2.276502172152201

Epoch: 6| Step: 8
Training loss: 1.4030784368515015
Validation loss: 2.267266058152722

Epoch: 6| Step: 9
Training loss: 1.398151159286499
Validation loss: 2.2242423385702152

Epoch: 6| Step: 10
Training loss: 1.575896978378296
Validation loss: 2.176934670376521

Epoch: 6| Step: 11
Training loss: 1.287871241569519
Validation loss: 2.2214482394597863

Epoch: 6| Step: 12
Training loss: 1.8723946809768677
Validation loss: 2.338674719615649

Epoch: 6| Step: 13
Training loss: 2.2103209495544434
Validation loss: 2.214392979939779

Epoch: 404| Step: 0
Training loss: 1.1064130067825317
Validation loss: 2.2213458040709138

Epoch: 6| Step: 1
Training loss: 1.4034459590911865
Validation loss: 2.3277522838243874

Epoch: 6| Step: 2
Training loss: 2.328106164932251
Validation loss: 2.2285120256485476

Epoch: 6| Step: 3
Training loss: 1.8411991596221924
Validation loss: 2.2232756307048183

Epoch: 6| Step: 4
Training loss: 1.5235087871551514
Validation loss: 2.184550719876443

Epoch: 6| Step: 5
Training loss: 1.5612878799438477
Validation loss: 2.1981060197276454

Epoch: 6| Step: 6
Training loss: 1.3949172496795654
Validation loss: 2.252697854913691

Epoch: 6| Step: 7
Training loss: 1.4604475498199463
Validation loss: 2.2674741488631054

Epoch: 6| Step: 8
Training loss: 2.2233023643493652
Validation loss: 2.099586195843194

Epoch: 6| Step: 9
Training loss: 1.6606981754302979
Validation loss: 2.1359558323378205

Epoch: 6| Step: 10
Training loss: 1.679539442062378
Validation loss: 2.087857457899278

Epoch: 6| Step: 11
Training loss: 1.2995518445968628
Validation loss: 2.140692905713153

Epoch: 6| Step: 12
Training loss: 1.9273600578308105
Validation loss: 2.182214988175259

Epoch: 6| Step: 13
Training loss: 1.6069859266281128
Validation loss: 2.178808246889422

Epoch: 405| Step: 0
Training loss: 1.6096001863479614
Validation loss: 2.2127309947885494

Epoch: 6| Step: 1
Training loss: 1.6150903701782227
Validation loss: 2.210399345685077

Epoch: 6| Step: 2
Training loss: 2.409503698348999
Validation loss: 2.232888601159537

Epoch: 6| Step: 3
Training loss: 1.1256903409957886
Validation loss: 2.122557109402072

Epoch: 6| Step: 4
Training loss: 0.9300107955932617
Validation loss: 2.1774321140781527

Epoch: 6| Step: 5
Training loss: 1.7307099103927612
Validation loss: 2.237022446047875

Epoch: 6| Step: 6
Training loss: 2.3363397121429443
Validation loss: 2.074358391505416

Epoch: 6| Step: 7
Training loss: 1.3274383544921875
Validation loss: 2.1723668421468427

Epoch: 6| Step: 8
Training loss: 2.1831109523773193
Validation loss: 2.1971635228844097

Epoch: 6| Step: 9
Training loss: 2.353302240371704
Validation loss: 2.245628005714827

Epoch: 6| Step: 10
Training loss: 1.5480831861495972
Validation loss: 2.1360863306189097

Epoch: 6| Step: 11
Training loss: 1.632630467414856
Validation loss: 2.2758769886468047

Epoch: 6| Step: 12
Training loss: 1.1529302597045898
Validation loss: 2.248109307340396

Epoch: 6| Step: 13
Training loss: 1.8759665489196777
Validation loss: 2.1954692050974858

Epoch: 406| Step: 0
Training loss: 1.8758714199066162
Validation loss: 2.2504231186323267

Epoch: 6| Step: 1
Training loss: 1.7469230890274048
Validation loss: 2.2107538074575444

Epoch: 6| Step: 2
Training loss: 1.5590487718582153
Validation loss: 2.2643570207780406

Epoch: 6| Step: 3
Training loss: 1.6271421909332275
Validation loss: 2.2021665137301207

Epoch: 6| Step: 4
Training loss: 1.640697956085205
Validation loss: 2.2912160017157115

Epoch: 6| Step: 5
Training loss: 1.6223680973052979
Validation loss: 2.2441975198766237

Epoch: 6| Step: 6
Training loss: 1.443631649017334
Validation loss: 2.1904057072054957

Epoch: 6| Step: 7
Training loss: 1.138625144958496
Validation loss: 2.2009444134209746

Epoch: 6| Step: 8
Training loss: 1.8318657875061035
Validation loss: 2.305877290746217

Epoch: 6| Step: 9
Training loss: 2.1089885234832764
Validation loss: 2.10711956280534

Epoch: 6| Step: 10
Training loss: 1.5217801332473755
Validation loss: 2.223925082914291

Epoch: 6| Step: 11
Training loss: 1.4262874126434326
Validation loss: 2.137337605158488

Epoch: 6| Step: 12
Training loss: 1.4873032569885254
Validation loss: 2.180533004063432

Epoch: 6| Step: 13
Training loss: 2.198184013366699
Validation loss: 2.129706553233567

Epoch: 407| Step: 0
Training loss: 1.327787160873413
Validation loss: 2.2314992848262993

Epoch: 6| Step: 1
Training loss: 1.7155283689498901
Validation loss: 2.263977309708954

Epoch: 6| Step: 2
Training loss: 1.8164877891540527
Validation loss: 2.2691094234425533

Epoch: 6| Step: 3
Training loss: 0.9618411064147949
Validation loss: 2.222795109595022

Epoch: 6| Step: 4
Training loss: 1.3359026908874512
Validation loss: 2.169948144625592

Epoch: 6| Step: 5
Training loss: 1.6086283922195435
Validation loss: 2.232790077886274

Epoch: 6| Step: 6
Training loss: 2.4646785259246826
Validation loss: 2.2133568179222847

Epoch: 6| Step: 7
Training loss: 2.2659945487976074
Validation loss: 2.261815894034601

Epoch: 6| Step: 8
Training loss: 2.323139190673828
Validation loss: 2.1451434743019844

Epoch: 6| Step: 9
Training loss: 1.3283815383911133
Validation loss: 2.287263462620397

Epoch: 6| Step: 10
Training loss: 1.9243788719177246
Validation loss: 2.153170480523058

Epoch: 6| Step: 11
Training loss: 1.5483238697052002
Validation loss: 2.207011509967107

Epoch: 6| Step: 12
Training loss: 0.7567623853683472
Validation loss: 2.2496912069218133

Epoch: 6| Step: 13
Training loss: 1.460681676864624
Validation loss: 2.2057294871217463

Epoch: 408| Step: 0
Training loss: 1.737596869468689
Validation loss: 2.304336993925033

Epoch: 6| Step: 1
Training loss: 1.4970133304595947
Validation loss: 2.1889065119528

Epoch: 6| Step: 2
Training loss: 1.5982437133789062
Validation loss: 2.282823895895353

Epoch: 6| Step: 3
Training loss: 1.9625004529953003
Validation loss: 2.2841323011664936

Epoch: 6| Step: 4
Training loss: 1.6839463710784912
Validation loss: 2.216074425687072

Epoch: 6| Step: 5
Training loss: 1.8125715255737305
Validation loss: 2.127957546582786

Epoch: 6| Step: 6
Training loss: 1.328134536743164
Validation loss: 2.164433415218066

Epoch: 6| Step: 7
Training loss: 1.652506709098816
Validation loss: 2.147322495778402

Epoch: 6| Step: 8
Training loss: 1.4846856594085693
Validation loss: 2.2787924889595277

Epoch: 6| Step: 9
Training loss: 1.7930877208709717
Validation loss: 2.2019195197730936

Epoch: 6| Step: 10
Training loss: 1.6887149810791016
Validation loss: 2.237225250531268

Epoch: 6| Step: 11
Training loss: 1.90291428565979
Validation loss: 2.156735066444643

Epoch: 6| Step: 12
Training loss: 1.7963674068450928
Validation loss: 2.2132953033652356

Epoch: 6| Step: 13
Training loss: 2.1233675479888916
Validation loss: 2.17647054759405

Epoch: 409| Step: 0
Training loss: 1.8821192979812622
Validation loss: 2.294303519751436

Epoch: 6| Step: 1
Training loss: 1.4573490619659424
Validation loss: 2.265081460757922

Epoch: 6| Step: 2
Training loss: 2.0341262817382812
Validation loss: 2.2234289466693835

Epoch: 6| Step: 3
Training loss: 1.8854591846466064
Validation loss: 2.151982876562303

Epoch: 6| Step: 4
Training loss: 1.2831326723098755
Validation loss: 2.2031093284647953

Epoch: 6| Step: 5
Training loss: 1.506034016609192
Validation loss: 2.265844257928992

Epoch: 6| Step: 6
Training loss: 1.0049984455108643
Validation loss: 2.242084695446876

Epoch: 6| Step: 7
Training loss: 1.3924639225006104
Validation loss: 2.143234322147985

Epoch: 6| Step: 8
Training loss: 1.4379830360412598
Validation loss: 2.1284662549213698

Epoch: 6| Step: 9
Training loss: 1.8827552795410156
Validation loss: 2.231057684908631

Epoch: 6| Step: 10
Training loss: 1.9822243452072144
Validation loss: 2.152796535081761

Epoch: 6| Step: 11
Training loss: 1.7263818979263306
Validation loss: 2.373990274244739

Epoch: 6| Step: 12
Training loss: 1.8677213191986084
Validation loss: 2.3320224490216983

Epoch: 6| Step: 13
Training loss: 1.9144011735916138
Validation loss: 2.3082755663061656

Epoch: 410| Step: 0
Training loss: 1.2731099128723145
Validation loss: 2.3976381183952413

Epoch: 6| Step: 1
Training loss: 2.0454139709472656
Validation loss: 2.2674480317741312

Epoch: 6| Step: 2
Training loss: 2.019402027130127
Validation loss: 2.2701235509687856

Epoch: 6| Step: 3
Training loss: 1.635229468345642
Validation loss: 2.3771894131937334

Epoch: 6| Step: 4
Training loss: 1.8115853071212769
Validation loss: 2.3129550231400358

Epoch: 6| Step: 5
Training loss: 1.7107274532318115
Validation loss: 2.3137445296010664

Epoch: 6| Step: 6
Training loss: 1.698453426361084
Validation loss: 2.2840259639165734

Epoch: 6| Step: 7
Training loss: 1.6277943849563599
Validation loss: 2.2785107666446316

Epoch: 6| Step: 8
Training loss: 1.8569649457931519
Validation loss: 2.301506324480939

Epoch: 6| Step: 9
Training loss: 1.6157557964324951
Validation loss: 2.25038476913206

Epoch: 6| Step: 10
Training loss: 1.641838788986206
Validation loss: 2.236921336061211

Epoch: 6| Step: 11
Training loss: 1.2125359773635864
Validation loss: 2.1539830392406834

Epoch: 6| Step: 12
Training loss: 1.648353099822998
Validation loss: 2.2691427405162523

Epoch: 6| Step: 13
Training loss: 1.6130657196044922
Validation loss: 2.0825144347324165

Epoch: 411| Step: 0
Training loss: 1.7318516969680786
Validation loss: 2.158256358997796

Epoch: 6| Step: 1
Training loss: 1.6137226819992065
Validation loss: 2.2971055648660146

Epoch: 6| Step: 2
Training loss: 1.7431966066360474
Validation loss: 2.1774061918258667

Epoch: 6| Step: 3
Training loss: 1.4507107734680176
Validation loss: 2.144765958991102

Epoch: 6| Step: 4
Training loss: 1.7038764953613281
Validation loss: 2.1732020634476856

Epoch: 6| Step: 5
Training loss: 1.708830714225769
Validation loss: 2.1551936262397358

Epoch: 6| Step: 6
Training loss: 1.4983751773834229
Validation loss: 2.195831180900656

Epoch: 6| Step: 7
Training loss: 1.2952144145965576
Validation loss: 2.21946955239901

Epoch: 6| Step: 8
Training loss: 1.7814383506774902
Validation loss: 2.2148136874680877

Epoch: 6| Step: 9
Training loss: 2.0162782669067383
Validation loss: 2.231274281778643

Epoch: 6| Step: 10
Training loss: 1.5594239234924316
Validation loss: 2.2818733620387253

Epoch: 6| Step: 11
Training loss: 1.2282094955444336
Validation loss: 2.270221607659453

Epoch: 6| Step: 12
Training loss: 2.194924831390381
Validation loss: 2.2152457493607716

Epoch: 6| Step: 13
Training loss: 1.623903751373291
Validation loss: 2.2598133574249926

Epoch: 412| Step: 0
Training loss: 1.5798646211624146
Validation loss: 2.0989052223902878

Epoch: 6| Step: 1
Training loss: 2.124969244003296
Validation loss: 2.113760240616337

Epoch: 6| Step: 2
Training loss: 1.0804418325424194
Validation loss: 2.2381048740879184

Epoch: 6| Step: 3
Training loss: 1.6185028553009033
Validation loss: 2.2700996732199066

Epoch: 6| Step: 4
Training loss: 2.112987518310547
Validation loss: 2.1481929556016

Epoch: 6| Step: 5
Training loss: 1.7275075912475586
Validation loss: 2.159171892750648

Epoch: 6| Step: 6
Training loss: 1.629641056060791
Validation loss: 2.2524710342448246

Epoch: 6| Step: 7
Training loss: 1.2380751371383667
Validation loss: 2.205908921457106

Epoch: 6| Step: 8
Training loss: 1.6353956460952759
Validation loss: 2.2777125912327922

Epoch: 6| Step: 9
Training loss: 1.664695382118225
Validation loss: 2.1875583638427076

Epoch: 6| Step: 10
Training loss: 2.503378391265869
Validation loss: 2.1578613263304516

Epoch: 6| Step: 11
Training loss: 1.8628239631652832
Validation loss: 2.2182142452527116

Epoch: 6| Step: 12
Training loss: 1.2356359958648682
Validation loss: 2.182859477176461

Epoch: 6| Step: 13
Training loss: 0.7838659882545471
Validation loss: 2.1597223153678318

Epoch: 413| Step: 0
Training loss: 1.6727795600891113
Validation loss: 2.294003750688286

Epoch: 6| Step: 1
Training loss: 1.409559726715088
Validation loss: 2.308629926814828

Epoch: 6| Step: 2
Training loss: 1.9913549423217773
Validation loss: 2.2467566792682936

Epoch: 6| Step: 3
Training loss: 1.5576273202896118
Validation loss: 2.232421281517193

Epoch: 6| Step: 4
Training loss: 2.070505142211914
Validation loss: 2.23549469055668

Epoch: 6| Step: 5
Training loss: 1.33243989944458
Validation loss: 2.2064259949550835

Epoch: 6| Step: 6
Training loss: 2.150006055831909
Validation loss: 2.2360422688145793

Epoch: 6| Step: 7
Training loss: 1.503238320350647
Validation loss: 2.1905551520727014

Epoch: 6| Step: 8
Training loss: 1.7453027963638306
Validation loss: 2.275446279074556

Epoch: 6| Step: 9
Training loss: 1.5267894268035889
Validation loss: 2.216831132929812

Epoch: 6| Step: 10
Training loss: 1.0421228408813477
Validation loss: 2.2607795679441063

Epoch: 6| Step: 11
Training loss: 1.7040586471557617
Validation loss: 2.229433354511056

Epoch: 6| Step: 12
Training loss: 1.6607224941253662
Validation loss: 2.242524731543756

Epoch: 6| Step: 13
Training loss: 1.4697784185409546
Validation loss: 2.1807761512776858

Epoch: 414| Step: 0
Training loss: 1.7832034826278687
Validation loss: 2.179478230014924

Epoch: 6| Step: 1
Training loss: 1.9960397481918335
Validation loss: 2.166338998784301

Epoch: 6| Step: 2
Training loss: 1.4067528247833252
Validation loss: 2.299148275006202

Epoch: 6| Step: 3
Training loss: 1.2470664978027344
Validation loss: 2.177728086389521

Epoch: 6| Step: 4
Training loss: 1.865074872970581
Validation loss: 2.096234461312653

Epoch: 6| Step: 5
Training loss: 1.3920693397521973
Validation loss: 2.229045207782458

Epoch: 6| Step: 6
Training loss: 1.2134912014007568
Validation loss: 2.2852685912962882

Epoch: 6| Step: 7
Training loss: 1.7249213457107544
Validation loss: 2.10221206244602

Epoch: 6| Step: 8
Training loss: 1.741947889328003
Validation loss: 2.2115984437286214

Epoch: 6| Step: 9
Training loss: 1.6455509662628174
Validation loss: 2.205249606922109

Epoch: 6| Step: 10
Training loss: 1.7532150745391846
Validation loss: 2.1973667478048675

Epoch: 6| Step: 11
Training loss: 1.4089407920837402
Validation loss: 2.196861426035563

Epoch: 6| Step: 12
Training loss: 2.1301069259643555
Validation loss: 2.162483443496048

Epoch: 6| Step: 13
Training loss: 1.7527936697006226
Validation loss: 2.218071855524535

Epoch: 415| Step: 0
Training loss: 1.6466861963272095
Validation loss: 2.1858653330033824

Epoch: 6| Step: 1
Training loss: 2.232344627380371
Validation loss: 2.2503276396823186

Epoch: 6| Step: 2
Training loss: 2.040236711502075
Validation loss: 2.26675441188197

Epoch: 6| Step: 3
Training loss: 1.5959663391113281
Validation loss: 2.2222852963273243

Epoch: 6| Step: 4
Training loss: 1.9423117637634277
Validation loss: 2.2392452198971986

Epoch: 6| Step: 5
Training loss: 1.5791072845458984
Validation loss: 2.251836038404895

Epoch: 6| Step: 6
Training loss: 1.5926623344421387
Validation loss: 2.20334546027645

Epoch: 6| Step: 7
Training loss: 1.7550203800201416
Validation loss: 2.3011688442640406

Epoch: 6| Step: 8
Training loss: 1.9203312397003174
Validation loss: 2.2639291465923352

Epoch: 6| Step: 9
Training loss: 1.267495036125183
Validation loss: 2.241731587276664

Epoch: 6| Step: 10
Training loss: 0.907576322555542
Validation loss: 2.240843174278095

Epoch: 6| Step: 11
Training loss: 2.0312187671661377
Validation loss: 2.276980097575854

Epoch: 6| Step: 12
Training loss: 1.2162418365478516
Validation loss: 2.2261684479251986

Epoch: 6| Step: 13
Training loss: 2.0448243618011475
Validation loss: 2.3769836733418126

Epoch: 416| Step: 0
Training loss: 2.2003002166748047
Validation loss: 2.3556162849549325

Epoch: 6| Step: 1
Training loss: 1.1620967388153076
Validation loss: 2.2767820999186528

Epoch: 6| Step: 2
Training loss: 1.8771634101867676
Validation loss: 2.3356013041670605

Epoch: 6| Step: 3
Training loss: 1.6260898113250732
Validation loss: 2.2992729986867597

Epoch: 6| Step: 4
Training loss: 1.530519723892212
Validation loss: 2.362437848121889

Epoch: 6| Step: 5
Training loss: 2.1613850593566895
Validation loss: 2.291782218922851

Epoch: 6| Step: 6
Training loss: 1.6986939907073975
Validation loss: 2.296783111428702

Epoch: 6| Step: 7
Training loss: 1.4161105155944824
Validation loss: 2.4078915247353176

Epoch: 6| Step: 8
Training loss: 1.5570991039276123
Validation loss: 2.2453065097972913

Epoch: 6| Step: 9
Training loss: 1.678354024887085
Validation loss: 2.2692251795081684

Epoch: 6| Step: 10
Training loss: 2.2026894092559814
Validation loss: 2.343916690477761

Epoch: 6| Step: 11
Training loss: 1.1579318046569824
Validation loss: 2.28037404757674

Epoch: 6| Step: 12
Training loss: 1.526700496673584
Validation loss: 2.2444762286319526

Epoch: 6| Step: 13
Training loss: 2.068861961364746
Validation loss: 2.2345757689527286

Epoch: 417| Step: 0
Training loss: 1.47048020362854
Validation loss: 2.2073383754299534

Epoch: 6| Step: 1
Training loss: 0.8992832899093628
Validation loss: 2.185115706536078

Epoch: 6| Step: 2
Training loss: 2.243816375732422
Validation loss: 2.1152345749639694

Epoch: 6| Step: 3
Training loss: 1.7213795185089111
Validation loss: 2.1859470913487096

Epoch: 6| Step: 4
Training loss: 1.6996006965637207
Validation loss: 2.1864953374349945

Epoch: 6| Step: 5
Training loss: 1.680521011352539
Validation loss: 2.15717726625422

Epoch: 6| Step: 6
Training loss: 1.4234107732772827
Validation loss: 2.2753901507264827

Epoch: 6| Step: 7
Training loss: 1.9041744470596313
Validation loss: 2.197862063684771

Epoch: 6| Step: 8
Training loss: 1.3362245559692383
Validation loss: 2.1252823734796173

Epoch: 6| Step: 9
Training loss: 1.6136631965637207
Validation loss: 2.194857533260058

Epoch: 6| Step: 10
Training loss: 2.073854923248291
Validation loss: 2.134829940334443

Epoch: 6| Step: 11
Training loss: 1.6439259052276611
Validation loss: 2.2145932054006927

Epoch: 6| Step: 12
Training loss: 1.6919153928756714
Validation loss: 2.2140053267120035

Epoch: 6| Step: 13
Training loss: 1.3744382858276367
Validation loss: 2.2012609179301927

Epoch: 418| Step: 0
Training loss: 1.1259901523590088
Validation loss: 2.1579523945367463

Epoch: 6| Step: 1
Training loss: 1.4218196868896484
Validation loss: 2.2575025712290118

Epoch: 6| Step: 2
Training loss: 1.8124988079071045
Validation loss: 2.274202826202557

Epoch: 6| Step: 3
Training loss: 2.54195499420166
Validation loss: 2.2986503826674594

Epoch: 6| Step: 4
Training loss: 2.0216150283813477
Validation loss: 2.2403563581487185

Epoch: 6| Step: 5
Training loss: 1.3521318435668945
Validation loss: 2.2752263930536087

Epoch: 6| Step: 6
Training loss: 1.523868441581726
Validation loss: 2.195454066799533

Epoch: 6| Step: 7
Training loss: 1.6607130765914917
Validation loss: 2.2926019250705676

Epoch: 6| Step: 8
Training loss: 1.1309062242507935
Validation loss: 2.3040899871498026

Epoch: 6| Step: 9
Training loss: 1.6956987380981445
Validation loss: 2.304544682143837

Epoch: 6| Step: 10
Training loss: 1.4877158403396606
Validation loss: 2.1901646724311252

Epoch: 6| Step: 11
Training loss: 1.8119173049926758
Validation loss: 2.2567945167582524

Epoch: 6| Step: 12
Training loss: 1.1221264600753784
Validation loss: 2.268235142512988

Epoch: 6| Step: 13
Training loss: 2.7161378860473633
Validation loss: 2.365020162315779

Epoch: 419| Step: 0
Training loss: 1.2689077854156494
Validation loss: 2.150136337485365

Epoch: 6| Step: 1
Training loss: 1.9463350772857666
Validation loss: 2.210296243749639

Epoch: 6| Step: 2
Training loss: 1.603486180305481
Validation loss: 2.153710517832028

Epoch: 6| Step: 3
Training loss: 1.7542232275009155
Validation loss: 2.201052070945822

Epoch: 6| Step: 4
Training loss: 1.7600491046905518
Validation loss: 2.205987858515914

Epoch: 6| Step: 5
Training loss: 1.507666826248169
Validation loss: 2.141760940192848

Epoch: 6| Step: 6
Training loss: 1.8443549871444702
Validation loss: 2.1451958456347064

Epoch: 6| Step: 7
Training loss: 2.458284378051758
Validation loss: 2.1276280315973426

Epoch: 6| Step: 8
Training loss: 1.0672054290771484
Validation loss: 2.250345609521353

Epoch: 6| Step: 9
Training loss: 2.092194080352783
Validation loss: 2.1999212336796585

Epoch: 6| Step: 10
Training loss: 1.2179250717163086
Validation loss: 2.157215000480734

Epoch: 6| Step: 11
Training loss: 1.3748881816864014
Validation loss: 2.1236601747492307

Epoch: 6| Step: 12
Training loss: 1.0849614143371582
Validation loss: 2.095475891584991

Epoch: 6| Step: 13
Training loss: 1.426713466644287
Validation loss: 2.3385830848447737

Epoch: 420| Step: 0
Training loss: 2.0661838054656982
Validation loss: 2.2746376183725174

Epoch: 6| Step: 1
Training loss: 1.4503686428070068
Validation loss: 2.2224319058079876

Epoch: 6| Step: 2
Training loss: 1.941828966140747
Validation loss: 2.1414776130389144

Epoch: 6| Step: 3
Training loss: 1.4474743604660034
Validation loss: 2.18132173374135

Epoch: 6| Step: 4
Training loss: 1.2240973711013794
Validation loss: 2.1591425967472855

Epoch: 6| Step: 5
Training loss: 2.1686525344848633
Validation loss: 2.184137290523898

Epoch: 6| Step: 6
Training loss: 1.4094915390014648
Validation loss: 2.2437983251387075

Epoch: 6| Step: 7
Training loss: 1.4769549369812012
Validation loss: 2.2113567757350143

Epoch: 6| Step: 8
Training loss: 1.4263805150985718
Validation loss: 2.1092850726137877

Epoch: 6| Step: 9
Training loss: 1.876389503479004
Validation loss: 2.3293572061805317

Epoch: 6| Step: 10
Training loss: 1.4231619834899902
Validation loss: 2.232473709250009

Epoch: 6| Step: 11
Training loss: 1.3257980346679688
Validation loss: 2.274974887089063

Epoch: 6| Step: 12
Training loss: 2.153266429901123
Validation loss: 2.2204433897490143

Epoch: 6| Step: 13
Training loss: 0.6093087196350098
Validation loss: 2.2282199141799763

Epoch: 421| Step: 0
Training loss: 1.4810760021209717
Validation loss: 2.2455728515501945

Epoch: 6| Step: 1
Training loss: 1.3325982093811035
Validation loss: 2.2505458529277513

Epoch: 6| Step: 2
Training loss: 1.832531213760376
Validation loss: 2.1893855243600826

Epoch: 6| Step: 3
Training loss: 1.9671318531036377
Validation loss: 2.184846826778945

Epoch: 6| Step: 4
Training loss: 1.3250668048858643
Validation loss: 2.2170537248734505

Epoch: 6| Step: 5
Training loss: 1.5826289653778076
Validation loss: 2.1867609600866995

Epoch: 6| Step: 6
Training loss: 1.687626838684082
Validation loss: 2.214729643637134

Epoch: 6| Step: 7
Training loss: 1.3639967441558838
Validation loss: 2.183378299077352

Epoch: 6| Step: 8
Training loss: 1.4538896083831787
Validation loss: 2.2242284949107836

Epoch: 6| Step: 9
Training loss: 1.8439844846725464
Validation loss: 2.1913847705369354

Epoch: 6| Step: 10
Training loss: 1.5609803199768066
Validation loss: 2.1864515696802447

Epoch: 6| Step: 11
Training loss: 2.1778764724731445
Validation loss: 2.182365281607515

Epoch: 6| Step: 12
Training loss: 1.654637336730957
Validation loss: 2.1916468617736653

Epoch: 6| Step: 13
Training loss: 0.8384907841682434
Validation loss: 2.216546609837522

Epoch: 422| Step: 0
Training loss: 1.7105793952941895
Validation loss: 2.244816590380925

Epoch: 6| Step: 1
Training loss: 1.3948569297790527
Validation loss: 2.235286012772591

Epoch: 6| Step: 2
Training loss: 1.6888319253921509
Validation loss: 2.1720496454546527

Epoch: 6| Step: 3
Training loss: 1.3754531145095825
Validation loss: 2.2830641192774617

Epoch: 6| Step: 4
Training loss: 1.6962661743164062
Validation loss: 2.2161108306659165

Epoch: 6| Step: 5
Training loss: 1.5570616722106934
Validation loss: 2.175715264453683

Epoch: 6| Step: 6
Training loss: 1.62577223777771
Validation loss: 2.210570607134091

Epoch: 6| Step: 7
Training loss: 1.7206168174743652
Validation loss: 2.2686077651157173

Epoch: 6| Step: 8
Training loss: 1.802167534828186
Validation loss: 2.321972231711111

Epoch: 6| Step: 9
Training loss: 0.96151202917099
Validation loss: 2.221327990613958

Epoch: 6| Step: 10
Training loss: 1.6002275943756104
Validation loss: 2.284365648864418

Epoch: 6| Step: 11
Training loss: 1.6188628673553467
Validation loss: 2.241886040215851

Epoch: 6| Step: 12
Training loss: 2.19258975982666
Validation loss: 2.253224360045566

Epoch: 6| Step: 13
Training loss: 1.2937971353530884
Validation loss: 2.239738413082656

Epoch: 423| Step: 0
Training loss: 2.1443734169006348
Validation loss: 2.2433255513509116

Epoch: 6| Step: 1
Training loss: 1.4699420928955078
Validation loss: 2.288093366930562

Epoch: 6| Step: 2
Training loss: 2.075519561767578
Validation loss: 2.2585476393340738

Epoch: 6| Step: 3
Training loss: 1.3177950382232666
Validation loss: 2.1929305714945637

Epoch: 6| Step: 4
Training loss: 1.7855682373046875
Validation loss: 2.264195119180987

Epoch: 6| Step: 5
Training loss: 1.1196825504302979
Validation loss: 2.180097941429384

Epoch: 6| Step: 6
Training loss: 1.2062695026397705
Validation loss: 2.0977041964889853

Epoch: 6| Step: 7
Training loss: 1.8173147439956665
Validation loss: 2.191237388118621

Epoch: 6| Step: 8
Training loss: 1.5188559293746948
Validation loss: 2.2117877878168577

Epoch: 6| Step: 9
Training loss: 1.6211094856262207
Validation loss: 2.1533422444456365

Epoch: 6| Step: 10
Training loss: 2.2485456466674805
Validation loss: 2.1683495467708958

Epoch: 6| Step: 11
Training loss: 1.369441032409668
Validation loss: 2.178903151583928

Epoch: 6| Step: 12
Training loss: 1.547670602798462
Validation loss: 2.140263501033988

Epoch: 6| Step: 13
Training loss: 2.2943854331970215
Validation loss: 2.270764477791325

Epoch: 424| Step: 0
Training loss: 1.967283010482788
Validation loss: 2.1175561002505723

Epoch: 6| Step: 1
Training loss: 1.798315167427063
Validation loss: 2.2290863888238066

Epoch: 6| Step: 2
Training loss: 1.3696248531341553
Validation loss: 2.15089939999324

Epoch: 6| Step: 3
Training loss: 1.4278889894485474
Validation loss: 2.2609358808045745

Epoch: 6| Step: 4
Training loss: 1.7333502769470215
Validation loss: 2.2052571773529053

Epoch: 6| Step: 5
Training loss: 1.4886589050292969
Validation loss: 2.172473480624537

Epoch: 6| Step: 6
Training loss: 2.2055156230926514
Validation loss: 2.2646599969556256

Epoch: 6| Step: 7
Training loss: 1.7450473308563232
Validation loss: 2.2636395603097896

Epoch: 6| Step: 8
Training loss: 2.039435625076294
Validation loss: 2.2700533905336933

Epoch: 6| Step: 9
Training loss: 0.7731314301490784
Validation loss: 2.1673980759036158

Epoch: 6| Step: 10
Training loss: 1.7720952033996582
Validation loss: 2.2104191626271894

Epoch: 6| Step: 11
Training loss: 2.4389572143554688
Validation loss: 2.2168906696381105

Epoch: 6| Step: 12
Training loss: 1.4738514423370361
Validation loss: 2.2173688847531556

Epoch: 6| Step: 13
Training loss: 1.0693020820617676
Validation loss: 2.251099204504362

Epoch: 425| Step: 0
Training loss: 1.0900049209594727
Validation loss: 2.2603030589319046

Epoch: 6| Step: 1
Training loss: 2.1113603115081787
Validation loss: 2.2240724845599105

Epoch: 6| Step: 2
Training loss: 1.3582630157470703
Validation loss: 2.198898111620257

Epoch: 6| Step: 3
Training loss: 1.3379051685333252
Validation loss: 2.204553852799118

Epoch: 6| Step: 4
Training loss: 2.160031318664551
Validation loss: 2.3080454436681603

Epoch: 6| Step: 5
Training loss: 2.130810260772705
Validation loss: 2.3751654009665213

Epoch: 6| Step: 6
Training loss: 1.178454875946045
Validation loss: 2.233521133340815

Epoch: 6| Step: 7
Training loss: 2.4913315773010254
Validation loss: 2.317490244424471

Epoch: 6| Step: 8
Training loss: 1.2852718830108643
Validation loss: 2.1706927527663527

Epoch: 6| Step: 9
Training loss: 0.9984307885169983
Validation loss: 2.171746979477585

Epoch: 6| Step: 10
Training loss: 2.02190899848938
Validation loss: 2.170273668022566

Epoch: 6| Step: 11
Training loss: 1.4924653768539429
Validation loss: 2.2487603746434695

Epoch: 6| Step: 12
Training loss: 1.640798807144165
Validation loss: 2.2139905473237396

Epoch: 6| Step: 13
Training loss: 1.2168729305267334
Validation loss: 2.1851339032573085

Epoch: 426| Step: 0
Training loss: 1.4232172966003418
Validation loss: 2.060631599477542

Epoch: 6| Step: 1
Training loss: 2.030445098876953
Validation loss: 2.228475598878758

Epoch: 6| Step: 2
Training loss: 1.3383533954620361
Validation loss: 2.1498171590989634

Epoch: 6| Step: 3
Training loss: 1.5524290800094604
Validation loss: 2.119141609438004

Epoch: 6| Step: 4
Training loss: 1.6720860004425049
Validation loss: 2.214392885085075

Epoch: 6| Step: 5
Training loss: 1.5451833009719849
Validation loss: 2.195987929580032

Epoch: 6| Step: 6
Training loss: 1.5786948204040527
Validation loss: 2.1743304011642293

Epoch: 6| Step: 7
Training loss: 2.3196372985839844
Validation loss: 2.222032076569014

Epoch: 6| Step: 8
Training loss: 1.4417243003845215
Validation loss: 2.219310914316485

Epoch: 6| Step: 9
Training loss: 1.7958389520645142
Validation loss: 2.2586186573069584

Epoch: 6| Step: 10
Training loss: 1.6063027381896973
Validation loss: 2.1978544445448023

Epoch: 6| Step: 11
Training loss: 1.3852429389953613
Validation loss: 2.0380784119329145

Epoch: 6| Step: 12
Training loss: 1.5309929847717285
Validation loss: 2.208073846755489

Epoch: 6| Step: 13
Training loss: 1.6980042457580566
Validation loss: 2.095231292068317

Epoch: 427| Step: 0
Training loss: 1.6817368268966675
Validation loss: 2.167777221689942

Epoch: 6| Step: 1
Training loss: 1.8494477272033691
Validation loss: 2.276727055990568

Epoch: 6| Step: 2
Training loss: 1.8766247034072876
Validation loss: 2.204783352472449

Epoch: 6| Step: 3
Training loss: 1.6964281797409058
Validation loss: 2.260297441995272

Epoch: 6| Step: 4
Training loss: 1.721095323562622
Validation loss: 2.239392770233975

Epoch: 6| Step: 5
Training loss: 2.837568759918213
Validation loss: 2.210203188721852

Epoch: 6| Step: 6
Training loss: 1.1900601387023926
Validation loss: 2.323207478369436

Epoch: 6| Step: 7
Training loss: 1.315490484237671
Validation loss: 2.220251521756572

Epoch: 6| Step: 8
Training loss: 1.6859081983566284
Validation loss: 2.2112757698182137

Epoch: 6| Step: 9
Training loss: 1.383492112159729
Validation loss: 2.255898473083332

Epoch: 6| Step: 10
Training loss: 1.9749544858932495
Validation loss: 2.246854019421403

Epoch: 6| Step: 11
Training loss: 1.3588312864303589
Validation loss: 2.2186230241611438

Epoch: 6| Step: 12
Training loss: 1.4424779415130615
Validation loss: 2.2147707426419823

Epoch: 6| Step: 13
Training loss: 1.0191069841384888
Validation loss: 2.201963614392024

Epoch: 428| Step: 0
Training loss: 1.6879560947418213
Validation loss: 2.268682478576578

Epoch: 6| Step: 1
Training loss: 1.8297199010849
Validation loss: 2.291734175015521

Epoch: 6| Step: 2
Training loss: 1.8207933902740479
Validation loss: 2.226088313646214

Epoch: 6| Step: 3
Training loss: 2.04296875
Validation loss: 2.1706628517438005

Epoch: 6| Step: 4
Training loss: 1.4079285860061646
Validation loss: 2.196373285785798

Epoch: 6| Step: 5
Training loss: 1.669220209121704
Validation loss: 2.2086571442183627

Epoch: 6| Step: 6
Training loss: 2.154561996459961
Validation loss: 2.213854638479089

Epoch: 6| Step: 7
Training loss: 1.3698471784591675
Validation loss: 2.178140955586587

Epoch: 6| Step: 8
Training loss: 1.3753154277801514
Validation loss: 2.1745831530581237

Epoch: 6| Step: 9
Training loss: 1.668363094329834
Validation loss: 2.1794376809109925

Epoch: 6| Step: 10
Training loss: 1.6072983741760254
Validation loss: 2.223854628942346

Epoch: 6| Step: 11
Training loss: 1.2469781637191772
Validation loss: 2.214413724919801

Epoch: 6| Step: 12
Training loss: 1.6312496662139893
Validation loss: 2.2474776134696057

Epoch: 6| Step: 13
Training loss: 1.2517625093460083
Validation loss: 2.14721715963015

Epoch: 429| Step: 0
Training loss: 1.392338514328003
Validation loss: 2.3076657633627615

Epoch: 6| Step: 1
Training loss: 1.2511687278747559
Validation loss: 2.2031598450035177

Epoch: 6| Step: 2
Training loss: 1.6993861198425293
Validation loss: 2.2353267951678206

Epoch: 6| Step: 3
Training loss: 1.940521478652954
Validation loss: 2.1574840699472735

Epoch: 6| Step: 4
Training loss: 1.3556861877441406
Validation loss: 2.2487113078435264

Epoch: 6| Step: 5
Training loss: 1.8713630437850952
Validation loss: 2.2640116009660947

Epoch: 6| Step: 6
Training loss: 1.388427495956421
Validation loss: 2.282060536005164

Epoch: 6| Step: 7
Training loss: 1.4574456214904785
Validation loss: 2.187129195018481

Epoch: 6| Step: 8
Training loss: 1.462792158126831
Validation loss: 2.1307259554504068

Epoch: 6| Step: 9
Training loss: 1.7220546007156372
Validation loss: 2.247273716875302

Epoch: 6| Step: 10
Training loss: 2.1144142150878906
Validation loss: 2.098303420569307

Epoch: 6| Step: 11
Training loss: 1.7173571586608887
Validation loss: 2.261203363377561

Epoch: 6| Step: 12
Training loss: 2.2145884037017822
Validation loss: 2.136933372866723

Epoch: 6| Step: 13
Training loss: 2.597555160522461
Validation loss: 2.1699530847610964

Epoch: 430| Step: 0
Training loss: 1.3186460733413696
Validation loss: 2.168521149184114

Epoch: 6| Step: 1
Training loss: 1.1581233739852905
Validation loss: 2.285171545961852

Epoch: 6| Step: 2
Training loss: 1.3585816621780396
Validation loss: 2.120428687782698

Epoch: 6| Step: 3
Training loss: 1.1149743795394897
Validation loss: 2.1178769244942615

Epoch: 6| Step: 4
Training loss: 1.508399486541748
Validation loss: 2.1447271698264667

Epoch: 6| Step: 5
Training loss: 1.9040241241455078
Validation loss: 2.2536701181883454

Epoch: 6| Step: 6
Training loss: 1.9890011548995972
Validation loss: 2.1886327241056707

Epoch: 6| Step: 7
Training loss: 2.1386284828186035
Validation loss: 2.21090724391322

Epoch: 6| Step: 8
Training loss: 1.7093347311019897
Validation loss: 2.2467751708081973

Epoch: 6| Step: 9
Training loss: 1.4478340148925781
Validation loss: 2.166515164477851

Epoch: 6| Step: 10
Training loss: 1.5827233791351318
Validation loss: 2.2444598726046983

Epoch: 6| Step: 11
Training loss: 2.8800392150878906
Validation loss: 2.1988020430329027

Epoch: 6| Step: 12
Training loss: 1.3324484825134277
Validation loss: 2.270159411173995

Epoch: 6| Step: 13
Training loss: 1.5865769386291504
Validation loss: 2.2206468325789257

Epoch: 431| Step: 0
Training loss: 1.4884555339813232
Validation loss: 2.2155417549994683

Epoch: 6| Step: 1
Training loss: 0.8720940351486206
Validation loss: 2.1919415689283803

Epoch: 6| Step: 2
Training loss: 2.063603401184082
Validation loss: 2.1281251112620034

Epoch: 6| Step: 3
Training loss: 1.4337173700332642
Validation loss: 2.1845191063419467

Epoch: 6| Step: 4
Training loss: 1.4055166244506836
Validation loss: 2.255075629039477

Epoch: 6| Step: 5
Training loss: 2.244515895843506
Validation loss: 2.214556009538712

Epoch: 6| Step: 6
Training loss: 2.2698864936828613
Validation loss: 2.310751748341386

Epoch: 6| Step: 7
Training loss: 1.4513881206512451
Validation loss: 2.242424290667298

Epoch: 6| Step: 8
Training loss: 1.6767632961273193
Validation loss: 2.29504152523574

Epoch: 6| Step: 9
Training loss: 1.4962904453277588
Validation loss: 2.2131942523423063

Epoch: 6| Step: 10
Training loss: 1.2799700498580933
Validation loss: 2.2111615288642144

Epoch: 6| Step: 11
Training loss: 1.5665676593780518
Validation loss: 2.2204644359568113

Epoch: 6| Step: 12
Training loss: 1.9368653297424316
Validation loss: 2.294969335679085

Epoch: 6| Step: 13
Training loss: 1.5291309356689453
Validation loss: 2.261154659332768

Epoch: 432| Step: 0
Training loss: 1.1966586112976074
Validation loss: 2.1998709888868433

Epoch: 6| Step: 1
Training loss: 1.829369306564331
Validation loss: 2.2289286198154574

Epoch: 6| Step: 2
Training loss: 1.9716157913208008
Validation loss: 2.202977672699959

Epoch: 6| Step: 3
Training loss: 1.790090560913086
Validation loss: 2.162882915107153

Epoch: 6| Step: 4
Training loss: 1.317619800567627
Validation loss: 2.3328014035378732

Epoch: 6| Step: 5
Training loss: 1.2578824758529663
Validation loss: 2.230288250471956

Epoch: 6| Step: 6
Training loss: 2.386180877685547
Validation loss: 2.2357027684488604

Epoch: 6| Step: 7
Training loss: 1.5382188558578491
Validation loss: 2.211483193982032

Epoch: 6| Step: 8
Training loss: 1.6409153938293457
Validation loss: 2.2378129882197224

Epoch: 6| Step: 9
Training loss: 1.4568543434143066
Validation loss: 2.302559421908471

Epoch: 6| Step: 10
Training loss: 1.479860544204712
Validation loss: 2.1086342386020127

Epoch: 6| Step: 11
Training loss: 2.189105749130249
Validation loss: 2.221761393290694

Epoch: 6| Step: 12
Training loss: 1.578221082687378
Validation loss: 2.1901304516741025

Epoch: 6| Step: 13
Training loss: 0.5576737523078918
Validation loss: 2.151527848294986

Epoch: 433| Step: 0
Training loss: 1.8735847473144531
Validation loss: 2.1762584435042513

Epoch: 6| Step: 1
Training loss: 1.962756872177124
Validation loss: 2.206320460124682

Epoch: 6| Step: 2
Training loss: 1.6049704551696777
Validation loss: 2.2402135531107583

Epoch: 6| Step: 3
Training loss: 1.7065891027450562
Validation loss: 2.1530997368597213

Epoch: 6| Step: 4
Training loss: 1.369659662246704
Validation loss: 2.2722145024166314

Epoch: 6| Step: 5
Training loss: 1.2543230056762695
Validation loss: 2.147183536201395

Epoch: 6| Step: 6
Training loss: 1.8656840324401855
Validation loss: 2.1387852648253083

Epoch: 6| Step: 7
Training loss: 1.6444811820983887
Validation loss: 2.1643526349016415

Epoch: 6| Step: 8
Training loss: 1.5519614219665527
Validation loss: 2.1893888237655803

Epoch: 6| Step: 9
Training loss: 1.86842942237854
Validation loss: 2.2475031037484445

Epoch: 6| Step: 10
Training loss: 1.5299291610717773
Validation loss: 2.234015998019967

Epoch: 6| Step: 11
Training loss: 1.201852798461914
Validation loss: 2.2601602897849133

Epoch: 6| Step: 12
Training loss: 1.4009673595428467
Validation loss: 2.1409717118868263

Epoch: 6| Step: 13
Training loss: 2.3481481075286865
Validation loss: 2.157913823281565

Epoch: 434| Step: 0
Training loss: 1.3662173748016357
Validation loss: 2.159620313234227

Epoch: 6| Step: 1
Training loss: 1.8719793558120728
Validation loss: 2.163704405548752

Epoch: 6| Step: 2
Training loss: 1.8299813270568848
Validation loss: 2.154718404175133

Epoch: 6| Step: 3
Training loss: 1.9689741134643555
Validation loss: 2.2262127219989734

Epoch: 6| Step: 4
Training loss: 2.4270358085632324
Validation loss: 2.264010193527386

Epoch: 6| Step: 5
Training loss: 1.5425231456756592
Validation loss: 2.1798311177120415

Epoch: 6| Step: 6
Training loss: 2.0194954872131348
Validation loss: 2.3118076632099767

Epoch: 6| Step: 7
Training loss: 1.5560228824615479
Validation loss: 2.28758140020473

Epoch: 6| Step: 8
Training loss: 1.689208745956421
Validation loss: 2.2847627465442946

Epoch: 6| Step: 9
Training loss: 0.854563295841217
Validation loss: 2.1351671167599258

Epoch: 6| Step: 10
Training loss: 1.4186789989471436
Validation loss: 2.2373079048689974

Epoch: 6| Step: 11
Training loss: 1.7493847608566284
Validation loss: 2.262605538932226

Epoch: 6| Step: 12
Training loss: 1.5245099067687988
Validation loss: 2.1927454471588135

Epoch: 6| Step: 13
Training loss: 0.7222040891647339
Validation loss: 2.2443446420854136

Epoch: 435| Step: 0
Training loss: 1.5208138227462769
Validation loss: 2.1356426003158733

Epoch: 6| Step: 1
Training loss: 1.8620288372039795
Validation loss: 2.150804776017384

Epoch: 6| Step: 2
Training loss: 1.6204655170440674
Validation loss: 2.159147652246619

Epoch: 6| Step: 3
Training loss: 1.2785083055496216
Validation loss: 2.2557359357034006

Epoch: 6| Step: 4
Training loss: 1.8212584257125854
Validation loss: 2.196559524023405

Epoch: 6| Step: 5
Training loss: 1.3922317028045654
Validation loss: 2.217735413582094

Epoch: 6| Step: 6
Training loss: 1.6010160446166992
Validation loss: 2.257186076974356

Epoch: 6| Step: 7
Training loss: 1.6727664470672607
Validation loss: 2.2759220651400986

Epoch: 6| Step: 8
Training loss: 1.5993525981903076
Validation loss: 2.2275469303131104

Epoch: 6| Step: 9
Training loss: 1.6664669513702393
Validation loss: 2.201165960681054

Epoch: 6| Step: 10
Training loss: 1.9882688522338867
Validation loss: 2.2682792653319654

Epoch: 6| Step: 11
Training loss: 1.222442865371704
Validation loss: 2.269965297432356

Epoch: 6| Step: 12
Training loss: 1.771464467048645
Validation loss: 2.213707694443323

Epoch: 6| Step: 13
Training loss: 1.2792675495147705
Validation loss: 2.1842026325964157

Epoch: 436| Step: 0
Training loss: 1.2429057359695435
Validation loss: 2.0447768357492264

Epoch: 6| Step: 1
Training loss: 1.8218868970870972
Validation loss: 2.2451730082111974

Epoch: 6| Step: 2
Training loss: 0.9868739247322083
Validation loss: 2.1945055838554137

Epoch: 6| Step: 3
Training loss: 2.2659554481506348
Validation loss: 2.2300928356826946

Epoch: 6| Step: 4
Training loss: 1.8102314472198486
Validation loss: 2.177868438023393

Epoch: 6| Step: 5
Training loss: 1.9411524534225464
Validation loss: 2.130175696906223

Epoch: 6| Step: 6
Training loss: 1.550797462463379
Validation loss: 2.2116266104482833

Epoch: 6| Step: 7
Training loss: 1.5502690076828003
Validation loss: 2.192852549655463

Epoch: 6| Step: 8
Training loss: 1.8639675378799438
Validation loss: 2.157105730425927

Epoch: 6| Step: 9
Training loss: 1.4915907382965088
Validation loss: 2.303246969817787

Epoch: 6| Step: 10
Training loss: 1.3982670307159424
Validation loss: 2.132138822668342

Epoch: 6| Step: 11
Training loss: 1.3404676914215088
Validation loss: 2.207352407516972

Epoch: 6| Step: 12
Training loss: 1.7224596738815308
Validation loss: 2.222165556364162

Epoch: 6| Step: 13
Training loss: 1.5025357007980347
Validation loss: 2.1934872852858676

Epoch: 437| Step: 0
Training loss: 1.5802130699157715
Validation loss: 2.272916750241351

Epoch: 6| Step: 1
Training loss: 1.8167451620101929
Validation loss: 2.1548728789052656

Epoch: 6| Step: 2
Training loss: 1.9468042850494385
Validation loss: 2.2641507887071177

Epoch: 6| Step: 3
Training loss: 1.1607098579406738
Validation loss: 2.2196558073002803

Epoch: 6| Step: 4
Training loss: 1.2416175603866577
Validation loss: 2.093437848552581

Epoch: 6| Step: 5
Training loss: 1.3578968048095703
Validation loss: 2.2844178445877565

Epoch: 6| Step: 6
Training loss: 2.1283786296844482
Validation loss: 2.1975673744755406

Epoch: 6| Step: 7
Training loss: 1.2591543197631836
Validation loss: 2.174371970597134

Epoch: 6| Step: 8
Training loss: 1.407773733139038
Validation loss: 2.2005885237006733

Epoch: 6| Step: 9
Training loss: 1.8358101844787598
Validation loss: 2.249202824408008

Epoch: 6| Step: 10
Training loss: 2.5619454383850098
Validation loss: 2.203708653808922

Epoch: 6| Step: 11
Training loss: 2.120154619216919
Validation loss: 2.2284525261130383

Epoch: 6| Step: 12
Training loss: 1.2333940267562866
Validation loss: 2.241841664878271

Epoch: 6| Step: 13
Training loss: 1.9215213060379028
Validation loss: 2.179894515263137

Epoch: 438| Step: 0
Training loss: 1.8379977941513062
Validation loss: 2.2017583065135504

Epoch: 6| Step: 1
Training loss: 1.3932335376739502
Validation loss: 2.252207274078041

Epoch: 6| Step: 2
Training loss: 1.8411121368408203
Validation loss: 2.2327433555356917

Epoch: 6| Step: 3
Training loss: 1.4461926221847534
Validation loss: 2.1887786952398156

Epoch: 6| Step: 4
Training loss: 1.302796721458435
Validation loss: 2.2830148614862913

Epoch: 6| Step: 5
Training loss: 1.1387925148010254
Validation loss: 2.2102032605037896

Epoch: 6| Step: 6
Training loss: 1.4543122053146362
Validation loss: 2.225919326146444

Epoch: 6| Step: 7
Training loss: 1.3366267681121826
Validation loss: 2.2060250441233316

Epoch: 6| Step: 8
Training loss: 2.0053114891052246
Validation loss: 2.2802640033024613

Epoch: 6| Step: 9
Training loss: 1.5233607292175293
Validation loss: 2.209749931930214

Epoch: 6| Step: 10
Training loss: 1.3508226871490479
Validation loss: 2.2160455514025945

Epoch: 6| Step: 11
Training loss: 1.8761837482452393
Validation loss: 2.317186119735882

Epoch: 6| Step: 12
Training loss: 2.4277284145355225
Validation loss: 2.3040449234747116

Epoch: 6| Step: 13
Training loss: 2.175065755844116
Validation loss: 2.1809528258539017

Epoch: 439| Step: 0
Training loss: 1.6278725862503052
Validation loss: 2.2305449375542263

Epoch: 6| Step: 1
Training loss: 1.5463303327560425
Validation loss: 2.2189136294908423

Epoch: 6| Step: 2
Training loss: 2.2616758346557617
Validation loss: 2.153229646785285

Epoch: 6| Step: 3
Training loss: 1.2731430530548096
Validation loss: 2.209798812866211

Epoch: 6| Step: 4
Training loss: 1.5468580722808838
Validation loss: 2.253991337232692

Epoch: 6| Step: 5
Training loss: 1.6503963470458984
Validation loss: 2.1864896461527836

Epoch: 6| Step: 6
Training loss: 1.5735810995101929
Validation loss: 2.257897764123896

Epoch: 6| Step: 7
Training loss: 1.7190816402435303
Validation loss: 2.170873713749711

Epoch: 6| Step: 8
Training loss: 2.126763105392456
Validation loss: 2.2353482041307675

Epoch: 6| Step: 9
Training loss: 2.167274236679077
Validation loss: 2.188919163519336

Epoch: 6| Step: 10
Training loss: 1.654733419418335
Validation loss: 2.1553411509401057

Epoch: 6| Step: 11
Training loss: 1.2363214492797852
Validation loss: 2.2061092584363875

Epoch: 6| Step: 12
Training loss: 1.2372578382492065
Validation loss: 2.249295450025989

Epoch: 6| Step: 13
Training loss: 1.1678541898727417
Validation loss: 2.2046011981143745

Epoch: 440| Step: 0
Training loss: 1.0569705963134766
Validation loss: 2.2891950632936213

Epoch: 6| Step: 1
Training loss: 1.33733069896698
Validation loss: 2.2323935903528684

Epoch: 6| Step: 2
Training loss: 1.1764543056488037
Validation loss: 2.1184046550463607

Epoch: 6| Step: 3
Training loss: 1.9154276847839355
Validation loss: 2.2565438106495845

Epoch: 6| Step: 4
Training loss: 1.6808878183364868
Validation loss: 2.22633848908127

Epoch: 6| Step: 5
Training loss: 1.6322311162948608
Validation loss: 2.1323334837472565

Epoch: 6| Step: 6
Training loss: 2.076528787612915
Validation loss: 2.1373606099877307

Epoch: 6| Step: 7
Training loss: 1.4581847190856934
Validation loss: 2.1918727813228482

Epoch: 6| Step: 8
Training loss: 1.5638623237609863
Validation loss: 2.193445961962464

Epoch: 6| Step: 9
Training loss: 1.6296058893203735
Validation loss: 2.1990676080026934

Epoch: 6| Step: 10
Training loss: 1.7975618839263916
Validation loss: 2.3179716102538572

Epoch: 6| Step: 11
Training loss: 2.1607213020324707
Validation loss: 2.195380682586342

Epoch: 6| Step: 12
Training loss: 1.7258371114730835
Validation loss: 2.1733724250588367

Epoch: 6| Step: 13
Training loss: 1.3687851428985596
Validation loss: 2.14737452742874

Epoch: 441| Step: 0
Training loss: 2.1184980869293213
Validation loss: 2.160910757639075

Epoch: 6| Step: 1
Training loss: 1.3951942920684814
Validation loss: 2.18841621439944

Epoch: 6| Step: 2
Training loss: 1.7945754528045654
Validation loss: 2.2204202580195602

Epoch: 6| Step: 3
Training loss: 1.6641662120819092
Validation loss: 2.180155542589003

Epoch: 6| Step: 4
Training loss: 1.2555532455444336
Validation loss: 2.08949641771214

Epoch: 6| Step: 5
Training loss: 1.8447693586349487
Validation loss: 2.1670428296571136

Epoch: 6| Step: 6
Training loss: 1.9806691408157349
Validation loss: 2.245384249635922

Epoch: 6| Step: 7
Training loss: 1.480508804321289
Validation loss: 2.240719408117315

Epoch: 6| Step: 8
Training loss: 1.8733139038085938
Validation loss: 2.1840403618351107

Epoch: 6| Step: 9
Training loss: 1.8883403539657593
Validation loss: 2.1300854157376032

Epoch: 6| Step: 10
Training loss: 1.9161659479141235
Validation loss: 2.244436494765743

Epoch: 6| Step: 11
Training loss: 1.5468724966049194
Validation loss: 2.2185113955569524

Epoch: 6| Step: 12
Training loss: 1.547411322593689
Validation loss: 2.2132474709582586

Epoch: 6| Step: 13
Training loss: 1.5725762844085693
Validation loss: 2.238280436044098

Epoch: 442| Step: 0
Training loss: 1.7536927461624146
Validation loss: 2.162795733380061

Epoch: 6| Step: 1
Training loss: 1.2482764720916748
Validation loss: 2.165550042224187

Epoch: 6| Step: 2
Training loss: 1.3608003854751587
Validation loss: 2.257704927075294

Epoch: 6| Step: 3
Training loss: 1.764325737953186
Validation loss: 2.2993269825494416

Epoch: 6| Step: 4
Training loss: 1.9838213920593262
Validation loss: 2.1977932965883644

Epoch: 6| Step: 5
Training loss: 1.9267034530639648
Validation loss: 2.188565141411238

Epoch: 6| Step: 6
Training loss: 1.4997777938842773
Validation loss: 2.1946395827877905

Epoch: 6| Step: 7
Training loss: 1.8069226741790771
Validation loss: 2.1762623171652518

Epoch: 6| Step: 8
Training loss: 1.6230965852737427
Validation loss: 2.225212179204469

Epoch: 6| Step: 9
Training loss: 1.6656794548034668
Validation loss: 2.137943180658484

Epoch: 6| Step: 10
Training loss: 1.6656053066253662
Validation loss: 2.241608013388931

Epoch: 6| Step: 11
Training loss: 1.6182597875595093
Validation loss: 2.1991696934546194

Epoch: 6| Step: 12
Training loss: 1.2584707736968994
Validation loss: 2.2357913473600983

Epoch: 6| Step: 13
Training loss: 1.0867544412612915
Validation loss: 2.2154339180197766

Epoch: 443| Step: 0
Training loss: 1.9547340869903564
Validation loss: 2.1934266808212444

Epoch: 6| Step: 1
Training loss: 1.5510847568511963
Validation loss: 2.2108642952416533

Epoch: 6| Step: 2
Training loss: 1.2157999277114868
Validation loss: 2.1159365523246025

Epoch: 6| Step: 3
Training loss: 1.5009022951126099
Validation loss: 2.224093346185582

Epoch: 6| Step: 4
Training loss: 1.9190335273742676
Validation loss: 2.307744533784928

Epoch: 6| Step: 5
Training loss: 1.422353744506836
Validation loss: 2.18818522268726

Epoch: 6| Step: 6
Training loss: 1.731196641921997
Validation loss: 2.1821744441986084

Epoch: 6| Step: 7
Training loss: 1.4243197441101074
Validation loss: 2.2073042687549385

Epoch: 6| Step: 8
Training loss: 2.1236815452575684
Validation loss: 2.2500553772013676

Epoch: 6| Step: 9
Training loss: 1.5227434635162354
Validation loss: 2.224881297798567

Epoch: 6| Step: 10
Training loss: 1.4572734832763672
Validation loss: 2.248800964765651

Epoch: 6| Step: 11
Training loss: 1.2275702953338623
Validation loss: 2.1993986227179088

Epoch: 6| Step: 12
Training loss: 2.138068199157715
Validation loss: 2.1459331486814763

Epoch: 6| Step: 13
Training loss: 1.305197834968567
Validation loss: 2.19977770697686

Epoch: 444| Step: 0
Training loss: 2.1171231269836426
Validation loss: 2.155830990883612

Epoch: 6| Step: 1
Training loss: 1.3582830429077148
Validation loss: 2.238505563428325

Epoch: 6| Step: 2
Training loss: 1.8012174367904663
Validation loss: 2.079760559143559

Epoch: 6| Step: 3
Training loss: 1.9072926044464111
Validation loss: 2.3031660523465884

Epoch: 6| Step: 4
Training loss: 1.7401442527770996
Validation loss: 2.1817737574218423

Epoch: 6| Step: 5
Training loss: 1.1486042737960815
Validation loss: 2.241027009102606

Epoch: 6| Step: 6
Training loss: 1.1772754192352295
Validation loss: 2.2038610366082962

Epoch: 6| Step: 7
Training loss: 1.4507088661193848
Validation loss: 2.2005382404532483

Epoch: 6| Step: 8
Training loss: 1.9224776029586792
Validation loss: 2.1342658612035934

Epoch: 6| Step: 9
Training loss: 1.1050736904144287
Validation loss: 2.1377097534877

Epoch: 6| Step: 10
Training loss: 1.534574270248413
Validation loss: 2.189203287965508

Epoch: 6| Step: 11
Training loss: 1.9919872283935547
Validation loss: 2.2744870288397676

Epoch: 6| Step: 12
Training loss: 1.9672762155532837
Validation loss: 2.0706378439421296

Epoch: 6| Step: 13
Training loss: 1.6388087272644043
Validation loss: 2.269674707484502

Epoch: 445| Step: 0
Training loss: 1.7907209396362305
Validation loss: 2.2185045096182052

Epoch: 6| Step: 1
Training loss: 1.3744564056396484
Validation loss: 2.1863462848048054

Epoch: 6| Step: 2
Training loss: 1.757151484489441
Validation loss: 2.157445271809896

Epoch: 6| Step: 3
Training loss: 1.610671043395996
Validation loss: 2.1915279511482484

Epoch: 6| Step: 4
Training loss: 1.821808934211731
Validation loss: 2.2939130670280865

Epoch: 6| Step: 5
Training loss: 1.2167119979858398
Validation loss: 2.2913121100394958

Epoch: 6| Step: 6
Training loss: 1.5292763710021973
Validation loss: 2.2929074943706556

Epoch: 6| Step: 7
Training loss: 1.8193244934082031
Validation loss: 2.298671914685157

Epoch: 6| Step: 8
Training loss: 1.6428558826446533
Validation loss: 2.2677879589860157

Epoch: 6| Step: 9
Training loss: 1.6992404460906982
Validation loss: 2.281595250611664

Epoch: 6| Step: 10
Training loss: 1.602562427520752
Validation loss: 2.2815008522361837

Epoch: 6| Step: 11
Training loss: 1.949836254119873
Validation loss: 2.209253582903134

Epoch: 6| Step: 12
Training loss: 1.3478610515594482
Validation loss: 2.2609952239580053

Epoch: 6| Step: 13
Training loss: 1.4025394916534424
Validation loss: 2.236800568078154

Epoch: 446| Step: 0
Training loss: 1.7175533771514893
Validation loss: 2.202381326306251

Epoch: 6| Step: 1
Training loss: 2.2042927742004395
Validation loss: 2.203274414103518

Epoch: 6| Step: 2
Training loss: 1.6578062772750854
Validation loss: 2.1275397500684186

Epoch: 6| Step: 3
Training loss: 1.8149815797805786
Validation loss: 2.1943704235938286

Epoch: 6| Step: 4
Training loss: 1.2749260663986206
Validation loss: 2.281525529840941

Epoch: 6| Step: 5
Training loss: 1.437010407447815
Validation loss: 2.1832095038506294

Epoch: 6| Step: 6
Training loss: 1.665097951889038
Validation loss: 2.1531941339533818

Epoch: 6| Step: 7
Training loss: 1.50192391872406
Validation loss: 2.243386544207091

Epoch: 6| Step: 8
Training loss: 1.7850778102874756
Validation loss: 2.2195128856166715

Epoch: 6| Step: 9
Training loss: 2.3679001331329346
Validation loss: 2.1721691444355953

Epoch: 6| Step: 10
Training loss: 1.1281585693359375
Validation loss: 2.185231900984241

Epoch: 6| Step: 11
Training loss: 1.6278897523880005
Validation loss: 2.0981382477668022

Epoch: 6| Step: 12
Training loss: 0.9569357633590698
Validation loss: 2.2037744393912693

Epoch: 6| Step: 13
Training loss: 1.5950381755828857
Validation loss: 2.124407816958684

Epoch: 447| Step: 0
Training loss: 1.3722765445709229
Validation loss: 2.1135876742742394

Epoch: 6| Step: 1
Training loss: 1.7049416303634644
Validation loss: 2.1496042090077556

Epoch: 6| Step: 2
Training loss: 1.9876813888549805
Validation loss: 2.2076028367524505

Epoch: 6| Step: 3
Training loss: 1.4220128059387207
Validation loss: 2.1704150348581295

Epoch: 6| Step: 4
Training loss: 1.5599462985992432
Validation loss: 2.16010703579072

Epoch: 6| Step: 5
Training loss: 1.5530459880828857
Validation loss: 2.114298000130602

Epoch: 6| Step: 6
Training loss: 1.6195505857467651
Validation loss: 2.216947240214194

Epoch: 6| Step: 7
Training loss: 1.7173128128051758
Validation loss: 2.2326429505502023

Epoch: 6| Step: 8
Training loss: 1.9990246295928955
Validation loss: 2.212442357053039

Epoch: 6| Step: 9
Training loss: 1.1027181148529053
Validation loss: 2.2284771460358814

Epoch: 6| Step: 10
Training loss: 1.7492616176605225
Validation loss: 2.218244191138975

Epoch: 6| Step: 11
Training loss: 1.1835459470748901
Validation loss: 2.2416678526068248

Epoch: 6| Step: 12
Training loss: 2.2081146240234375
Validation loss: 2.204528472756827

Epoch: 6| Step: 13
Training loss: 1.9204769134521484
Validation loss: 2.194723472800306

Epoch: 448| Step: 0
Training loss: 1.0773425102233887
Validation loss: 2.295912286286713

Epoch: 6| Step: 1
Training loss: 1.5813342332839966
Validation loss: 2.1508525827879548

Epoch: 6| Step: 2
Training loss: 1.439205288887024
Validation loss: 2.3108805661560385

Epoch: 6| Step: 3
Training loss: 2.543853282928467
Validation loss: 2.298802742394068

Epoch: 6| Step: 4
Training loss: 2.0115389823913574
Validation loss: 2.270560082568917

Epoch: 6| Step: 5
Training loss: 1.4787282943725586
Validation loss: 2.3158126287562872

Epoch: 6| Step: 6
Training loss: 1.969743013381958
Validation loss: 2.245654962396109

Epoch: 6| Step: 7
Training loss: 1.3405814170837402
Validation loss: 2.325860172189692

Epoch: 6| Step: 8
Training loss: 1.0537161827087402
Validation loss: 2.214873606158841

Epoch: 6| Step: 9
Training loss: 1.8567606210708618
Validation loss: 2.2263871905624226

Epoch: 6| Step: 10
Training loss: 1.685361623764038
Validation loss: 2.17456696110387

Epoch: 6| Step: 11
Training loss: 1.6310484409332275
Validation loss: 2.2628051824467157

Epoch: 6| Step: 12
Training loss: 1.7325825691223145
Validation loss: 2.1722971213761197

Epoch: 6| Step: 13
Training loss: 1.212503433227539
Validation loss: 2.183621721882974

Epoch: 449| Step: 0
Training loss: 1.1634541749954224
Validation loss: 2.1330193396537536

Epoch: 6| Step: 1
Training loss: 1.714918851852417
Validation loss: 2.13947198980598

Epoch: 6| Step: 2
Training loss: 1.0420536994934082
Validation loss: 2.1196354204608547

Epoch: 6| Step: 3
Training loss: 1.5662081241607666
Validation loss: 2.239533301322691

Epoch: 6| Step: 4
Training loss: 1.7813771963119507
Validation loss: 2.215688186307107

Epoch: 6| Step: 5
Training loss: 1.5103679895401
Validation loss: 2.1930376329729633

Epoch: 6| Step: 6
Training loss: 1.3037667274475098
Validation loss: 2.2124700084809334

Epoch: 6| Step: 7
Training loss: 2.2745299339294434
Validation loss: 2.2049500583320536

Epoch: 6| Step: 8
Training loss: 1.857097864151001
Validation loss: 2.270638078771612

Epoch: 6| Step: 9
Training loss: 1.782881498336792
Validation loss: 2.1814755009066675

Epoch: 6| Step: 10
Training loss: 1.3956023454666138
Validation loss: 2.2212223827197985

Epoch: 6| Step: 11
Training loss: 1.6783199310302734
Validation loss: 2.246064970570226

Epoch: 6| Step: 12
Training loss: 1.3992663621902466
Validation loss: 2.1785861702375513

Epoch: 6| Step: 13
Training loss: 1.2088178396224976
Validation loss: 2.211116193443216

Epoch: 450| Step: 0
Training loss: 1.4126030206680298
Validation loss: 2.2676859773615354

Epoch: 6| Step: 1
Training loss: 2.1477503776550293
Validation loss: 2.224341630935669

Epoch: 6| Step: 2
Training loss: 1.7488328218460083
Validation loss: 2.170758811376428

Epoch: 6| Step: 3
Training loss: 1.0526161193847656
Validation loss: 2.2454494789082515

Epoch: 6| Step: 4
Training loss: 1.2532521486282349
Validation loss: 2.2464956109241774

Epoch: 6| Step: 5
Training loss: 1.6339325904846191
Validation loss: 2.2108964074042534

Epoch: 6| Step: 6
Training loss: 1.8794631958007812
Validation loss: 2.1320364885432745

Epoch: 6| Step: 7
Training loss: 1.7083370685577393
Validation loss: 2.270013819458664

Epoch: 6| Step: 8
Training loss: 1.138502597808838
Validation loss: 2.262240561105872

Epoch: 6| Step: 9
Training loss: 1.8617074489593506
Validation loss: 2.3073904283585085

Epoch: 6| Step: 10
Training loss: 1.4590297937393188
Validation loss: 2.24516019000802

Epoch: 6| Step: 11
Training loss: 1.2680937051773071
Validation loss: 2.2301342846244894

Epoch: 6| Step: 12
Training loss: 2.174447536468506
Validation loss: 2.1936774843482563

Epoch: 6| Step: 13
Training loss: 1.043712854385376
Validation loss: 2.292610369702821

Epoch: 451| Step: 0
Training loss: 2.044370174407959
Validation loss: 2.287718403723932

Epoch: 6| Step: 1
Training loss: 1.6858863830566406
Validation loss: 2.2375931483443066

Epoch: 6| Step: 2
Training loss: 1.8820509910583496
Validation loss: 2.300415664590815

Epoch: 6| Step: 3
Training loss: 1.1046388149261475
Validation loss: 2.3058763447628228

Epoch: 6| Step: 4
Training loss: 1.6744775772094727
Validation loss: 2.2463915296780166

Epoch: 6| Step: 5
Training loss: 1.8279821872711182
Validation loss: 2.204978178906184

Epoch: 6| Step: 6
Training loss: 1.3122960329055786
Validation loss: 2.2339031388682704

Epoch: 6| Step: 7
Training loss: 1.5091397762298584
Validation loss: 2.231634480978853

Epoch: 6| Step: 8
Training loss: 1.7766693830490112
Validation loss: 2.2546200213893766

Epoch: 6| Step: 9
Training loss: 1.6167411804199219
Validation loss: 2.252101554665514

Epoch: 6| Step: 10
Training loss: 1.3225573301315308
Validation loss: 2.190112908681234

Epoch: 6| Step: 11
Training loss: 0.9161592721939087
Validation loss: 2.2635682795637395

Epoch: 6| Step: 12
Training loss: 1.7584834098815918
Validation loss: 2.349419830947794

Epoch: 6| Step: 13
Training loss: 2.0843334197998047
Validation loss: 2.167033016040761

Epoch: 452| Step: 0
Training loss: 2.2385942935943604
Validation loss: 2.1996165142264417

Epoch: 6| Step: 1
Training loss: 1.400038242340088
Validation loss: 2.1576465509271108

Epoch: 6| Step: 2
Training loss: 1.4469985961914062
Validation loss: 2.1667913775290213

Epoch: 6| Step: 3
Training loss: 2.155122756958008
Validation loss: 2.1631596370409896

Epoch: 6| Step: 4
Training loss: 1.8309619426727295
Validation loss: 2.2204909440009826

Epoch: 6| Step: 5
Training loss: 1.7978277206420898
Validation loss: 2.1783064155168432

Epoch: 6| Step: 6
Training loss: 1.5448424816131592
Validation loss: 2.1780139387294812

Epoch: 6| Step: 7
Training loss: 1.3759013414382935
Validation loss: 2.1928177161883284

Epoch: 6| Step: 8
Training loss: 1.381374716758728
Validation loss: 2.183661748004216

Epoch: 6| Step: 9
Training loss: 1.3310142755508423
Validation loss: 2.1866381078638057

Epoch: 6| Step: 10
Training loss: 1.5063652992248535
Validation loss: 2.1595918324685868

Epoch: 6| Step: 11
Training loss: 1.6598989963531494
Validation loss: 2.246431089216663

Epoch: 6| Step: 12
Training loss: 1.3058544397354126
Validation loss: 2.170413737655968

Epoch: 6| Step: 13
Training loss: 1.2013156414031982
Validation loss: 2.271457652891836

Epoch: 453| Step: 0
Training loss: 1.4914923906326294
Validation loss: 2.1248117916045652

Epoch: 6| Step: 1
Training loss: 2.0480337142944336
Validation loss: 2.1745395839855237

Epoch: 6| Step: 2
Training loss: 1.0312284231185913
Validation loss: 2.1880286816627748

Epoch: 6| Step: 3
Training loss: 2.15989089012146
Validation loss: 2.201708616748933

Epoch: 6| Step: 4
Training loss: 2.074369430541992
Validation loss: 2.225666431970494

Epoch: 6| Step: 5
Training loss: 1.6024415493011475
Validation loss: 2.231797049122472

Epoch: 6| Step: 6
Training loss: 1.3751990795135498
Validation loss: 2.287304993598692

Epoch: 6| Step: 7
Training loss: 1.6574902534484863
Validation loss: 2.1765775847178634

Epoch: 6| Step: 8
Training loss: 1.4919981956481934
Validation loss: 2.262735842376627

Epoch: 6| Step: 9
Training loss: 1.1987247467041016
Validation loss: 2.193049592356528

Epoch: 6| Step: 10
Training loss: 1.1432125568389893
Validation loss: 2.2120728646555254

Epoch: 6| Step: 11
Training loss: 1.222794771194458
Validation loss: 2.2535056619233984

Epoch: 6| Step: 12
Training loss: 1.43107008934021
Validation loss: 2.2647763682949926

Epoch: 6| Step: 13
Training loss: 2.19374942779541
Validation loss: 2.242924742801215

Epoch: 454| Step: 0
Training loss: 0.902590274810791
Validation loss: 2.337871072112873

Epoch: 6| Step: 1
Training loss: 1.7316001653671265
Validation loss: 2.2576730482039915

Epoch: 6| Step: 2
Training loss: 1.85494863986969
Validation loss: 2.2220609188079834

Epoch: 6| Step: 3
Training loss: 1.7365612983703613
Validation loss: 2.2379610576937274

Epoch: 6| Step: 4
Training loss: 1.342146873474121
Validation loss: 2.225029295490634

Epoch: 6| Step: 5
Training loss: 1.320772409439087
Validation loss: 2.2101714841781126

Epoch: 6| Step: 6
Training loss: 1.7261408567428589
Validation loss: 2.2495046200290805

Epoch: 6| Step: 7
Training loss: 1.9230661392211914
Validation loss: 2.159134441806424

Epoch: 6| Step: 8
Training loss: 1.2311269044876099
Validation loss: 2.1137184507103375

Epoch: 6| Step: 9
Training loss: 2.0912888050079346
Validation loss: 2.1998216644410165

Epoch: 6| Step: 10
Training loss: 1.027825117111206
Validation loss: 2.1723064709735174

Epoch: 6| Step: 11
Training loss: 1.789332389831543
Validation loss: 2.1649845364273235

Epoch: 6| Step: 12
Training loss: 2.341829538345337
Validation loss: 2.2069966767423894

Epoch: 6| Step: 13
Training loss: 1.493569254875183
Validation loss: 2.196415937075051

Epoch: 455| Step: 0
Training loss: 1.4468684196472168
Validation loss: 2.1716950055091613

Epoch: 6| Step: 1
Training loss: 1.344454050064087
Validation loss: 2.170580969061903

Epoch: 6| Step: 2
Training loss: 2.011356830596924
Validation loss: 2.236120311162805

Epoch: 6| Step: 3
Training loss: 2.0235166549682617
Validation loss: 2.2152503998048845

Epoch: 6| Step: 4
Training loss: 1.2452640533447266
Validation loss: 2.224944499231154

Epoch: 6| Step: 5
Training loss: 2.067044258117676
Validation loss: 2.1526063270466302

Epoch: 6| Step: 6
Training loss: 1.9950342178344727
Validation loss: 2.2126423876772643

Epoch: 6| Step: 7
Training loss: 1.5402488708496094
Validation loss: 2.249096216694001

Epoch: 6| Step: 8
Training loss: 1.430625319480896
Validation loss: 2.189952004340387

Epoch: 6| Step: 9
Training loss: 1.756903886795044
Validation loss: 2.2074025933460524

Epoch: 6| Step: 10
Training loss: 1.7178524732589722
Validation loss: 2.1549226955700944

Epoch: 6| Step: 11
Training loss: 1.2214723825454712
Validation loss: 2.225446024248677

Epoch: 6| Step: 12
Training loss: 1.7924469709396362
Validation loss: 2.1285937575883764

Epoch: 6| Step: 13
Training loss: 1.0399328470230103
Validation loss: 2.132337680426977

Epoch: 456| Step: 0
Training loss: 1.552610993385315
Validation loss: 2.21013613670103

Epoch: 6| Step: 1
Training loss: 1.03968346118927
Validation loss: 2.16130127445344

Epoch: 6| Step: 2
Training loss: 1.8237589597702026
Validation loss: 2.2276977608280797

Epoch: 6| Step: 3
Training loss: 1.8167650699615479
Validation loss: 2.2728367800353677

Epoch: 6| Step: 4
Training loss: 1.7748874425888062
Validation loss: 2.2100504406036867

Epoch: 6| Step: 5
Training loss: 1.6928277015686035
Validation loss: 2.213905102463179

Epoch: 6| Step: 6
Training loss: 1.5805715322494507
Validation loss: 2.2371711372047343

Epoch: 6| Step: 7
Training loss: 1.6622753143310547
Validation loss: 2.2046005046495827

Epoch: 6| Step: 8
Training loss: 0.955305814743042
Validation loss: 2.1125094864958074

Epoch: 6| Step: 9
Training loss: 1.4630718231201172
Validation loss: 2.1663264074633197

Epoch: 6| Step: 10
Training loss: 1.847224473953247
Validation loss: 2.2332409299829954

Epoch: 6| Step: 11
Training loss: 1.3562605381011963
Validation loss: 2.2033546201644407

Epoch: 6| Step: 12
Training loss: 1.3429944515228271
Validation loss: 2.2571912247647523

Epoch: 6| Step: 13
Training loss: 1.5499221086502075
Validation loss: 2.301962747368761

Epoch: 457| Step: 0
Training loss: 1.741805076599121
Validation loss: 2.265337315938806

Epoch: 6| Step: 1
Training loss: 1.3443406820297241
Validation loss: 2.283007267982729

Epoch: 6| Step: 2
Training loss: 1.5053424835205078
Validation loss: 2.282268698497485

Epoch: 6| Step: 3
Training loss: 1.2259513139724731
Validation loss: 2.2316204809373423

Epoch: 6| Step: 4
Training loss: 1.7315452098846436
Validation loss: 2.2325864735470025

Epoch: 6| Step: 5
Training loss: 2.3255467414855957
Validation loss: 2.2177337792611893

Epoch: 6| Step: 6
Training loss: 0.9412624835968018
Validation loss: 2.135127700785155

Epoch: 6| Step: 7
Training loss: 1.7938263416290283
Validation loss: 2.2096815237434964

Epoch: 6| Step: 8
Training loss: 1.4675874710083008
Validation loss: 2.2657138968026764

Epoch: 6| Step: 9
Training loss: 1.6095024347305298
Validation loss: 2.225521388874259

Epoch: 6| Step: 10
Training loss: 1.3430886268615723
Validation loss: 2.1697210970745293

Epoch: 6| Step: 11
Training loss: 1.1006355285644531
Validation loss: 2.116712821427212

Epoch: 6| Step: 12
Training loss: 2.0261476039886475
Validation loss: 2.2611270860959123

Epoch: 6| Step: 13
Training loss: 1.8263269662857056
Validation loss: 2.1717402806846042

Epoch: 458| Step: 0
Training loss: 1.3545169830322266
Validation loss: 2.2544215084404073

Epoch: 6| Step: 1
Training loss: 1.4289216995239258
Validation loss: 2.1983215347413094

Epoch: 6| Step: 2
Training loss: 1.3209006786346436
Validation loss: 2.255157423275773

Epoch: 6| Step: 3
Training loss: 2.285595417022705
Validation loss: 2.2248414306230444

Epoch: 6| Step: 4
Training loss: 1.498490810394287
Validation loss: 2.3215639411762194

Epoch: 6| Step: 5
Training loss: 1.7597472667694092
Validation loss: 2.343226589182372

Epoch: 6| Step: 6
Training loss: 1.4295010566711426
Validation loss: 2.2924400824372486

Epoch: 6| Step: 7
Training loss: 1.3380920886993408
Validation loss: 2.2656796183637393

Epoch: 6| Step: 8
Training loss: 2.0881826877593994
Validation loss: 2.2508751294946157

Epoch: 6| Step: 9
Training loss: 1.412018060684204
Validation loss: 2.170616272957094

Epoch: 6| Step: 10
Training loss: 1.70201575756073
Validation loss: 2.300943769434447

Epoch: 6| Step: 11
Training loss: 1.2695125341415405
Validation loss: 2.258647054754278

Epoch: 6| Step: 12
Training loss: 1.8669166564941406
Validation loss: 2.1969806378887546

Epoch: 6| Step: 13
Training loss: 0.9194359183311462
Validation loss: 2.2649881378296883

Epoch: 459| Step: 0
Training loss: 1.2368837594985962
Validation loss: 2.245509224553262

Epoch: 6| Step: 1
Training loss: 2.0929131507873535
Validation loss: 2.2150127195542857

Epoch: 6| Step: 2
Training loss: 1.4125977754592896
Validation loss: 2.245065773687055

Epoch: 6| Step: 3
Training loss: 1.9381108283996582
Validation loss: 2.226089157083983

Epoch: 6| Step: 4
Training loss: 1.8126064538955688
Validation loss: 2.242995831274217

Epoch: 6| Step: 5
Training loss: 0.8839367032051086
Validation loss: 2.226781073436942

Epoch: 6| Step: 6
Training loss: 2.0534095764160156
Validation loss: 2.2351056324538363

Epoch: 6| Step: 7
Training loss: 1.7615056037902832
Validation loss: 2.2173342371499665

Epoch: 6| Step: 8
Training loss: 1.6296637058258057
Validation loss: 2.2561745284706034

Epoch: 6| Step: 9
Training loss: 1.3528261184692383
Validation loss: 2.145700454711914

Epoch: 6| Step: 10
Training loss: 1.9070651531219482
Validation loss: 2.2779057102818645

Epoch: 6| Step: 11
Training loss: 1.6445021629333496
Validation loss: 2.192654930135255

Epoch: 6| Step: 12
Training loss: 1.437434434890747
Validation loss: 2.257256015654533

Epoch: 6| Step: 13
Training loss: 1.9468129873275757
Validation loss: 2.1490327171100083

Epoch: 460| Step: 0
Training loss: 0.8242558240890503
Validation loss: 2.1596397815212125

Epoch: 6| Step: 1
Training loss: 1.706916093826294
Validation loss: 2.3884369993722565

Epoch: 6| Step: 2
Training loss: 1.4965519905090332
Validation loss: 2.2005865368791806

Epoch: 6| Step: 3
Training loss: 1.0316563844680786
Validation loss: 2.224553115906254

Epoch: 6| Step: 4
Training loss: 1.220263123512268
Validation loss: 2.1874223088705413

Epoch: 6| Step: 5
Training loss: 2.3735129833221436
Validation loss: 2.161429835263119

Epoch: 6| Step: 6
Training loss: 1.0483436584472656
Validation loss: 2.259930077419486

Epoch: 6| Step: 7
Training loss: 1.5840747356414795
Validation loss: 2.142253406586186

Epoch: 6| Step: 8
Training loss: 1.7270714044570923
Validation loss: 2.2509288941660235

Epoch: 6| Step: 9
Training loss: 2.5132017135620117
Validation loss: 2.2187276809446272

Epoch: 6| Step: 10
Training loss: 1.5903215408325195
Validation loss: 2.1965223589251117

Epoch: 6| Step: 11
Training loss: 1.2832069396972656
Validation loss: 2.161379806457027

Epoch: 6| Step: 12
Training loss: 1.5048785209655762
Validation loss: 2.1940882000871884

Epoch: 6| Step: 13
Training loss: 1.227189540863037
Validation loss: 2.19414363368865

Epoch: 461| Step: 0
Training loss: 1.1605695486068726
Validation loss: 2.185210950912968

Epoch: 6| Step: 1
Training loss: 2.3384599685668945
Validation loss: 2.221920910701957

Epoch: 6| Step: 2
Training loss: 1.0499533414840698
Validation loss: 2.2728955412423737

Epoch: 6| Step: 3
Training loss: 1.6482805013656616
Validation loss: 2.233588518634919

Epoch: 6| Step: 4
Training loss: 1.426810622215271
Validation loss: 2.200650845804522

Epoch: 6| Step: 5
Training loss: 1.5248031616210938
Validation loss: 2.1139984233405

Epoch: 6| Step: 6
Training loss: 1.6116087436676025
Validation loss: 2.236157601879489

Epoch: 6| Step: 7
Training loss: 1.2830913066864014
Validation loss: 2.3048699337949037

Epoch: 6| Step: 8
Training loss: 1.8131096363067627
Validation loss: 2.18915771284411

Epoch: 6| Step: 9
Training loss: 1.1988270282745361
Validation loss: 2.1789749642854095

Epoch: 6| Step: 10
Training loss: 1.4757590293884277
Validation loss: 2.2389059938410276

Epoch: 6| Step: 11
Training loss: 1.4267868995666504
Validation loss: 2.2655558509211384

Epoch: 6| Step: 12
Training loss: 2.0906834602355957
Validation loss: 2.2264230969131633

Epoch: 6| Step: 13
Training loss: 2.4657716751098633
Validation loss: 2.2021395647397606

Epoch: 462| Step: 0
Training loss: 2.3061351776123047
Validation loss: 2.2784415342474498

Epoch: 6| Step: 1
Training loss: 1.1825330257415771
Validation loss: 2.179787056420439

Epoch: 6| Step: 2
Training loss: 1.5394307374954224
Validation loss: 2.124231484628493

Epoch: 6| Step: 3
Training loss: 1.7752370834350586
Validation loss: 2.1206953422997588

Epoch: 6| Step: 4
Training loss: 1.2014334201812744
Validation loss: 2.1680065636993735

Epoch: 6| Step: 5
Training loss: 1.6972241401672363
Validation loss: 2.112828613609396

Epoch: 6| Step: 6
Training loss: 1.3152470588684082
Validation loss: 2.239250433060431

Epoch: 6| Step: 7
Training loss: 1.9890568256378174
Validation loss: 2.195424169622442

Epoch: 6| Step: 8
Training loss: 1.2963600158691406
Validation loss: 2.1284386650208504

Epoch: 6| Step: 9
Training loss: 1.4328962564468384
Validation loss: 2.1566332258203977

Epoch: 6| Step: 10
Training loss: 1.8834446668624878
Validation loss: 2.2944151842465965

Epoch: 6| Step: 11
Training loss: 1.2795774936676025
Validation loss: 2.250402744098376

Epoch: 6| Step: 12
Training loss: 1.4543702602386475
Validation loss: 2.267653049961213

Epoch: 6| Step: 13
Training loss: 0.9071235656738281
Validation loss: 2.160659569565968

Epoch: 463| Step: 0
Training loss: 1.7057759761810303
Validation loss: 2.191072089697725

Epoch: 6| Step: 1
Training loss: 1.3541755676269531
Validation loss: 2.2116183311708513

Epoch: 6| Step: 2
Training loss: 1.2732341289520264
Validation loss: 2.2075366550876248

Epoch: 6| Step: 3
Training loss: 1.4997142553329468
Validation loss: 2.2618172271277315

Epoch: 6| Step: 4
Training loss: 1.7118957042694092
Validation loss: 2.2350530983299337

Epoch: 6| Step: 5
Training loss: 1.2708512544631958
Validation loss: 2.1978771712190364

Epoch: 6| Step: 6
Training loss: 1.3372292518615723
Validation loss: 2.1914539388431016

Epoch: 6| Step: 7
Training loss: 1.8782391548156738
Validation loss: 2.19134735163822

Epoch: 6| Step: 8
Training loss: 0.9057503938674927
Validation loss: 2.210870756897875

Epoch: 6| Step: 9
Training loss: 1.2894459962844849
Validation loss: 2.1722047405858196

Epoch: 6| Step: 10
Training loss: 1.7195206880569458
Validation loss: 2.2423367474668767

Epoch: 6| Step: 11
Training loss: 1.5918893814086914
Validation loss: 2.2302698730140604

Epoch: 6| Step: 12
Training loss: 2.6993236541748047
Validation loss: 2.159911850447296

Epoch: 6| Step: 13
Training loss: 1.2507243156433105
Validation loss: 2.294070843727358

Epoch: 464| Step: 0
Training loss: 1.0514683723449707
Validation loss: 2.275469264676494

Epoch: 6| Step: 1
Training loss: 1.799447774887085
Validation loss: 2.273279073417828

Epoch: 6| Step: 2
Training loss: 1.2169402837753296
Validation loss: 2.2016381397042224

Epoch: 6| Step: 3
Training loss: 1.4434614181518555
Validation loss: 2.3045568927641837

Epoch: 6| Step: 4
Training loss: 1.1244453191757202
Validation loss: 2.168694665355067

Epoch: 6| Step: 5
Training loss: 1.7426307201385498
Validation loss: 2.2872555691708802

Epoch: 6| Step: 6
Training loss: 1.9879307746887207
Validation loss: 2.2196538063787643

Epoch: 6| Step: 7
Training loss: 1.8617517948150635
Validation loss: 2.311908562978109

Epoch: 6| Step: 8
Training loss: 1.3560208082199097
Validation loss: 2.2224691119245303

Epoch: 6| Step: 9
Training loss: 1.4614520072937012
Validation loss: 2.222089946910899

Epoch: 6| Step: 10
Training loss: 1.7652342319488525
Validation loss: 2.2583016785242225

Epoch: 6| Step: 11
Training loss: 1.391300082206726
Validation loss: 2.286217115258658

Epoch: 6| Step: 12
Training loss: 1.6548289060592651
Validation loss: 2.161517608550287

Epoch: 6| Step: 13
Training loss: 1.6582207679748535
Validation loss: 2.222269550446541

Epoch: 465| Step: 0
Training loss: 0.9686638712882996
Validation loss: 2.235595344215311

Epoch: 6| Step: 1
Training loss: 1.8979742527008057
Validation loss: 2.1653232792372346

Epoch: 6| Step: 2
Training loss: 1.5196120738983154
Validation loss: 2.365959803263346

Epoch: 6| Step: 3
Training loss: 1.7765400409698486
Validation loss: 2.21163430265201

Epoch: 6| Step: 4
Training loss: 1.9245620965957642
Validation loss: 2.2917795206910823

Epoch: 6| Step: 5
Training loss: 1.4348697662353516
Validation loss: 2.2156643457310174

Epoch: 6| Step: 6
Training loss: 1.9928076267242432
Validation loss: 2.2894953707213044

Epoch: 6| Step: 7
Training loss: 1.0702955722808838
Validation loss: 2.2446925537560576

Epoch: 6| Step: 8
Training loss: 1.794234037399292
Validation loss: 2.2504980333389772

Epoch: 6| Step: 9
Training loss: 1.9932438135147095
Validation loss: 2.2156600183056248

Epoch: 6| Step: 10
Training loss: 1.4645602703094482
Validation loss: 2.1540120032525834

Epoch: 6| Step: 11
Training loss: 1.464745044708252
Validation loss: 2.213431577528677

Epoch: 6| Step: 12
Training loss: 1.8451745510101318
Validation loss: 2.141650228090184

Epoch: 6| Step: 13
Training loss: 1.2270368337631226
Validation loss: 2.2181808461425123

Epoch: 466| Step: 0
Training loss: 1.3868951797485352
Validation loss: 2.194797823506017

Epoch: 6| Step: 1
Training loss: 1.687483787536621
Validation loss: 2.2584187189737954

Epoch: 6| Step: 2
Training loss: 0.9469894170761108
Validation loss: 2.185404783935957

Epoch: 6| Step: 3
Training loss: 1.4852375984191895
Validation loss: 2.127070429504559

Epoch: 6| Step: 4
Training loss: 1.2677419185638428
Validation loss: 2.175746433196529

Epoch: 6| Step: 5
Training loss: 1.524246096611023
Validation loss: 2.18033443984165

Epoch: 6| Step: 6
Training loss: 1.4899568557739258
Validation loss: 2.2486161826759257

Epoch: 6| Step: 7
Training loss: 1.6712448596954346
Validation loss: 2.2478195749303347

Epoch: 6| Step: 8
Training loss: 1.3893907070159912
Validation loss: 2.314483554132523

Epoch: 6| Step: 9
Training loss: 1.8011764287948608
Validation loss: 2.210483886862314

Epoch: 6| Step: 10
Training loss: 1.421884536743164
Validation loss: 2.2107967535654702

Epoch: 6| Step: 11
Training loss: 1.592736005783081
Validation loss: 2.209088102463753

Epoch: 6| Step: 12
Training loss: 1.3966505527496338
Validation loss: 2.207917751804475

Epoch: 6| Step: 13
Training loss: 3.007723093032837
Validation loss: 2.209531073929161

Epoch: 467| Step: 0
Training loss: 1.86012601852417
Validation loss: 2.256147797389697

Epoch: 6| Step: 1
Training loss: 1.5376529693603516
Validation loss: 2.2271515092542096

Epoch: 6| Step: 2
Training loss: 1.1776355504989624
Validation loss: 2.22152768411944

Epoch: 6| Step: 3
Training loss: 1.1305214166641235
Validation loss: 2.237966893821634

Epoch: 6| Step: 4
Training loss: 2.0124659538269043
Validation loss: 2.3148074406449513

Epoch: 6| Step: 5
Training loss: 1.0151395797729492
Validation loss: 2.2179408483607794

Epoch: 6| Step: 6
Training loss: 1.4696415662765503
Validation loss: 2.2242726984844414

Epoch: 6| Step: 7
Training loss: 1.8215570449829102
Validation loss: 2.1912694208083616

Epoch: 6| Step: 8
Training loss: 1.3650270700454712
Validation loss: 2.224117943035659

Epoch: 6| Step: 9
Training loss: 1.387283205986023
Validation loss: 2.1994362800352034

Epoch: 6| Step: 10
Training loss: 1.7817606925964355
Validation loss: 2.202404260635376

Epoch: 6| Step: 11
Training loss: 2.0892910957336426
Validation loss: 2.26546561589805

Epoch: 6| Step: 12
Training loss: 1.630307674407959
Validation loss: 2.20464317516614

Epoch: 6| Step: 13
Training loss: 1.2157140970230103
Validation loss: 2.2232649326324463

Epoch: 468| Step: 0
Training loss: 1.6698533296585083
Validation loss: 2.2573973414718465

Epoch: 6| Step: 1
Training loss: 0.7637264728546143
Validation loss: 2.1861368763831353

Epoch: 6| Step: 2
Training loss: 1.260649561882019
Validation loss: 2.1973189538524998

Epoch: 6| Step: 3
Training loss: 1.339988112449646
Validation loss: 2.1868855914761944

Epoch: 6| Step: 4
Training loss: 1.6457898616790771
Validation loss: 2.2613683695434244

Epoch: 6| Step: 5
Training loss: 1.1298936605453491
Validation loss: 2.2337243351885068

Epoch: 6| Step: 6
Training loss: 1.9923217296600342
Validation loss: 2.156360741584532

Epoch: 6| Step: 7
Training loss: 1.7495043277740479
Validation loss: 2.2062751823855984

Epoch: 6| Step: 8
Training loss: 2.4476394653320312
Validation loss: 2.255357993546353

Epoch: 6| Step: 9
Training loss: 1.6668105125427246
Validation loss: 2.171425099013954

Epoch: 6| Step: 10
Training loss: 1.488330602645874
Validation loss: 2.1025394649915796

Epoch: 6| Step: 11
Training loss: 1.419529914855957
Validation loss: 2.145330120158452

Epoch: 6| Step: 12
Training loss: 2.0703206062316895
Validation loss: 2.1898838743086784

Epoch: 6| Step: 13
Training loss: 1.2396024465560913
Validation loss: 2.1604265295049196

Epoch: 469| Step: 0
Training loss: 2.3282551765441895
Validation loss: 2.244268709613431

Epoch: 6| Step: 1
Training loss: 1.7248567342758179
Validation loss: 2.239207631798201

Epoch: 6| Step: 2
Training loss: 1.4651143550872803
Validation loss: 2.193690776824951

Epoch: 6| Step: 3
Training loss: 1.7617785930633545
Validation loss: 2.1448334750308784

Epoch: 6| Step: 4
Training loss: 1.8541245460510254
Validation loss: 2.2305472717490247

Epoch: 6| Step: 5
Training loss: 1.4598629474639893
Validation loss: 2.193188359660487

Epoch: 6| Step: 6
Training loss: 1.8475316762924194
Validation loss: 2.2694842238580026

Epoch: 6| Step: 7
Training loss: 1.5721403360366821
Validation loss: 2.2310804141465055

Epoch: 6| Step: 8
Training loss: 1.3846120834350586
Validation loss: 2.278430933593422

Epoch: 6| Step: 9
Training loss: 0.644328773021698
Validation loss: 2.3223867390745427

Epoch: 6| Step: 10
Training loss: 1.4529080390930176
Validation loss: 2.2741414398275395

Epoch: 6| Step: 11
Training loss: 1.7272815704345703
Validation loss: 2.3755465092197543

Epoch: 6| Step: 12
Training loss: 1.1844289302825928
Validation loss: 2.260509366630226

Epoch: 6| Step: 13
Training loss: 1.182746410369873
Validation loss: 2.300512844516385

Epoch: 470| Step: 0
Training loss: 1.815712809562683
Validation loss: 2.289597229291034

Epoch: 6| Step: 1
Training loss: 1.1774237155914307
Validation loss: 2.2519070691959833

Epoch: 6| Step: 2
Training loss: 1.5331976413726807
Validation loss: 2.269572898905764

Epoch: 6| Step: 3
Training loss: 1.7058463096618652
Validation loss: 2.2347284516980572

Epoch: 6| Step: 4
Training loss: 1.1250357627868652
Validation loss: 2.218109107786609

Epoch: 6| Step: 5
Training loss: 2.2201576232910156
Validation loss: 2.1987013765560683

Epoch: 6| Step: 6
Training loss: 2.0203397274017334
Validation loss: 2.1275408883248605

Epoch: 6| Step: 7
Training loss: 1.150847315788269
Validation loss: 2.1718773790585097

Epoch: 6| Step: 8
Training loss: 1.0821431875228882
Validation loss: 2.209485835926507

Epoch: 6| Step: 9
Training loss: 1.9075653553009033
Validation loss: 2.1959853800394202

Epoch: 6| Step: 10
Training loss: 1.5979349613189697
Validation loss: 2.262542076008294

Epoch: 6| Step: 11
Training loss: 1.6422288417816162
Validation loss: 2.1802850538684475

Epoch: 6| Step: 12
Training loss: 1.8823583126068115
Validation loss: 2.3064774467099096

Epoch: 6| Step: 13
Training loss: 1.0926727056503296
Validation loss: 2.119848120597101

Epoch: 471| Step: 0
Training loss: 1.2228033542633057
Validation loss: 2.2300888056396158

Epoch: 6| Step: 1
Training loss: 1.3304686546325684
Validation loss: 2.191305011831304

Epoch: 6| Step: 2
Training loss: 1.4765911102294922
Validation loss: 2.252183687302374

Epoch: 6| Step: 3
Training loss: 2.5103297233581543
Validation loss: 2.1767606196864957

Epoch: 6| Step: 4
Training loss: 1.2871546745300293
Validation loss: 2.2798369058998684

Epoch: 6| Step: 5
Training loss: 2.172654151916504
Validation loss: 2.2274758226128033

Epoch: 6| Step: 6
Training loss: 0.9430797100067139
Validation loss: 2.3432274095473753

Epoch: 6| Step: 7
Training loss: 1.4040298461914062
Validation loss: 2.269819454480243

Epoch: 6| Step: 8
Training loss: 1.9011934995651245
Validation loss: 2.2712638429416123

Epoch: 6| Step: 9
Training loss: 1.4773459434509277
Validation loss: 2.2981715407422794

Epoch: 6| Step: 10
Training loss: 1.8502238988876343
Validation loss: 2.193633223092684

Epoch: 6| Step: 11
Training loss: 1.5142145156860352
Validation loss: 2.3095072097675775

Epoch: 6| Step: 12
Training loss: 1.5233571529388428
Validation loss: 2.2452706572830037

Epoch: 6| Step: 13
Training loss: 1.649609088897705
Validation loss: 2.1982225371945288

Epoch: 472| Step: 0
Training loss: 1.505562424659729
Validation loss: 2.166576334225234

Epoch: 6| Step: 1
Training loss: 1.954007863998413
Validation loss: 2.122765141148721

Epoch: 6| Step: 2
Training loss: 2.057812213897705
Validation loss: 2.254440886999971

Epoch: 6| Step: 3
Training loss: 1.4141584634780884
Validation loss: 2.201722219426145

Epoch: 6| Step: 4
Training loss: 1.4174895286560059
Validation loss: 2.1988663481127833

Epoch: 6| Step: 5
Training loss: 0.9663571715354919
Validation loss: 2.2162526346022084

Epoch: 6| Step: 6
Training loss: 1.6988401412963867
Validation loss: 2.1189120456736577

Epoch: 6| Step: 7
Training loss: 1.679945945739746
Validation loss: 2.21858077279983

Epoch: 6| Step: 8
Training loss: 0.7191962003707886
Validation loss: 2.1996553610729914

Epoch: 6| Step: 9
Training loss: 1.3495995998382568
Validation loss: 2.1845377183729604

Epoch: 6| Step: 10
Training loss: 1.5770583152770996
Validation loss: 2.1697724147509505

Epoch: 6| Step: 11
Training loss: 1.48488450050354
Validation loss: 2.1818461366879043

Epoch: 6| Step: 12
Training loss: 2.0833823680877686
Validation loss: 2.1512758988206104

Epoch: 6| Step: 13
Training loss: 1.6762436628341675
Validation loss: 2.189794571168961

Epoch: 473| Step: 0
Training loss: 1.5994410514831543
Validation loss: 2.1936950145229215

Epoch: 6| Step: 1
Training loss: 1.989638328552246
Validation loss: 2.3099968817926224

Epoch: 6| Step: 2
Training loss: 0.70622718334198
Validation loss: 2.317692631034441

Epoch: 6| Step: 3
Training loss: 1.4393515586853027
Validation loss: 2.3931417311391523

Epoch: 6| Step: 4
Training loss: 1.4491593837738037
Validation loss: 2.3717706280369915

Epoch: 6| Step: 5
Training loss: 2.2251245975494385
Validation loss: 2.3555932096255723

Epoch: 6| Step: 6
Training loss: 2.5430445671081543
Validation loss: 2.265251187868016

Epoch: 6| Step: 7
Training loss: 1.5660823583602905
Validation loss: 2.346842732480777

Epoch: 6| Step: 8
Training loss: 1.150390386581421
Validation loss: 2.2215285890845844

Epoch: 6| Step: 9
Training loss: 1.7235667705535889
Validation loss: 2.3284642978381087

Epoch: 6| Step: 10
Training loss: 1.2213671207427979
Validation loss: 2.24780684901822

Epoch: 6| Step: 11
Training loss: 1.75009286403656
Validation loss: 2.272355197578348

Epoch: 6| Step: 12
Training loss: 1.1302825212478638
Validation loss: 2.203928509066182

Epoch: 6| Step: 13
Training loss: 1.2705674171447754
Validation loss: 2.2068473318571686

Epoch: 474| Step: 0
Training loss: 1.2836697101593018
Validation loss: 2.2208970951777633

Epoch: 6| Step: 1
Training loss: 1.825789213180542
Validation loss: 2.186117890060589

Epoch: 6| Step: 2
Training loss: 1.8125896453857422
Validation loss: 2.14785482165634

Epoch: 6| Step: 3
Training loss: 2.064173460006714
Validation loss: 2.1884743782781784

Epoch: 6| Step: 4
Training loss: 1.689607858657837
Validation loss: 2.2678546418425856

Epoch: 6| Step: 5
Training loss: 1.2989373207092285
Validation loss: 2.2151393787835234

Epoch: 6| Step: 6
Training loss: 1.1944220066070557
Validation loss: 2.206655627937727

Epoch: 6| Step: 7
Training loss: 1.3875622749328613
Validation loss: 2.2725591082726755

Epoch: 6| Step: 8
Training loss: 1.7433271408081055
Validation loss: 2.0882245571382585

Epoch: 6| Step: 9
Training loss: 1.0498616695404053
Validation loss: 2.198092568305231

Epoch: 6| Step: 10
Training loss: 1.1979084014892578
Validation loss: 2.141952073702248

Epoch: 6| Step: 11
Training loss: 1.772120714187622
Validation loss: 2.13541583348346

Epoch: 6| Step: 12
Training loss: 1.9732635021209717
Validation loss: 2.188384699565108

Epoch: 6| Step: 13
Training loss: 1.6157116889953613
Validation loss: 2.2558601235830658

Epoch: 475| Step: 0
Training loss: 2.185133934020996
Validation loss: 2.272920313701835

Epoch: 6| Step: 1
Training loss: 1.3502182960510254
Validation loss: 2.2691777957383024

Epoch: 6| Step: 2
Training loss: 1.1146714687347412
Validation loss: 2.2868950879702004

Epoch: 6| Step: 3
Training loss: 1.7076573371887207
Validation loss: 2.311889386946155

Epoch: 6| Step: 4
Training loss: 2.0092477798461914
Validation loss: 2.268744476379887

Epoch: 6| Step: 5
Training loss: 1.4563699960708618
Validation loss: 2.254776764941472

Epoch: 6| Step: 6
Training loss: 1.6637451648712158
Validation loss: 2.252066973716982

Epoch: 6| Step: 7
Training loss: 1.3274251222610474
Validation loss: 2.18477266065536

Epoch: 6| Step: 8
Training loss: 1.2959696054458618
Validation loss: 2.258365192720967

Epoch: 6| Step: 9
Training loss: 1.5460317134857178
Validation loss: 2.1314645198083695

Epoch: 6| Step: 10
Training loss: 1.4675195217132568
Validation loss: 2.3134298580949024

Epoch: 6| Step: 11
Training loss: 1.615578293800354
Validation loss: 2.2379936889935563

Epoch: 6| Step: 12
Training loss: 1.62007474899292
Validation loss: 2.246569877029747

Epoch: 6| Step: 13
Training loss: 2.0357141494750977
Validation loss: 2.191837941446612

Epoch: 476| Step: 0
Training loss: 1.3583903312683105
Validation loss: 2.2091840390236146

Epoch: 6| Step: 1
Training loss: 1.1765587329864502
Validation loss: 2.2241278207430275

Epoch: 6| Step: 2
Training loss: 1.7639830112457275
Validation loss: 2.260278167263154

Epoch: 6| Step: 3
Training loss: 1.4260399341583252
Validation loss: 2.096095005671183

Epoch: 6| Step: 4
Training loss: 1.5949037075042725
Validation loss: 2.2361838381777526

Epoch: 6| Step: 5
Training loss: 1.0887038707733154
Validation loss: 2.224652167289488

Epoch: 6| Step: 6
Training loss: 1.2970821857452393
Validation loss: 2.253991684605998

Epoch: 6| Step: 7
Training loss: 1.2225933074951172
Validation loss: 2.2177757614402362

Epoch: 6| Step: 8
Training loss: 1.6782097816467285
Validation loss: 2.1372736115609445

Epoch: 6| Step: 9
Training loss: 1.415726661682129
Validation loss: 2.1549829026704193

Epoch: 6| Step: 10
Training loss: 2.2157692909240723
Validation loss: 2.22090305179678

Epoch: 6| Step: 11
Training loss: 1.9871940612792969
Validation loss: 2.1416375047417096

Epoch: 6| Step: 12
Training loss: 1.6998016834259033
Validation loss: 2.1904652400683333

Epoch: 6| Step: 13
Training loss: 1.3299412727355957
Validation loss: 2.264245110173379

Epoch: 477| Step: 0
Training loss: 1.4040920734405518
Validation loss: 2.208773471975839

Epoch: 6| Step: 1
Training loss: 1.7723311185836792
Validation loss: 2.2074880958885275

Epoch: 6| Step: 2
Training loss: 1.295802354812622
Validation loss: 2.19005064810476

Epoch: 6| Step: 3
Training loss: 1.1429264545440674
Validation loss: 2.195864046773603

Epoch: 6| Step: 4
Training loss: 1.7001888751983643
Validation loss: 2.165019186594153

Epoch: 6| Step: 5
Training loss: 1.503401279449463
Validation loss: 2.243303098986226

Epoch: 6| Step: 6
Training loss: 1.8211605548858643
Validation loss: 2.211093907715172

Epoch: 6| Step: 7
Training loss: 1.7207411527633667
Validation loss: 2.1793180306752524

Epoch: 6| Step: 8
Training loss: 1.8021345138549805
Validation loss: 2.159560267643262

Epoch: 6| Step: 9
Training loss: 1.400964617729187
Validation loss: 2.2361675308596705

Epoch: 6| Step: 10
Training loss: 2.0588836669921875
Validation loss: 2.1767723021968717

Epoch: 6| Step: 11
Training loss: 1.803747534751892
Validation loss: 2.2771602061487015

Epoch: 6| Step: 12
Training loss: 1.509501576423645
Validation loss: 2.2597814798355103

Epoch: 6| Step: 13
Training loss: 0.9478275775909424
Validation loss: 2.2090998567560667

Epoch: 478| Step: 0
Training loss: 1.3986232280731201
Validation loss: 2.219165163655435

Epoch: 6| Step: 1
Training loss: 1.0611449480056763
Validation loss: 2.267869446867256

Epoch: 6| Step: 2
Training loss: 1.400923252105713
Validation loss: 2.3383194015872095

Epoch: 6| Step: 3
Training loss: 1.0596762895584106
Validation loss: 2.2179449091675463

Epoch: 6| Step: 4
Training loss: 2.0430233478546143
Validation loss: 2.1942082284599222

Epoch: 6| Step: 5
Training loss: 1.6452792882919312
Validation loss: 2.2097927934379986

Epoch: 6| Step: 6
Training loss: 1.6115354299545288
Validation loss: 2.3027577861662833

Epoch: 6| Step: 7
Training loss: 1.514188528060913
Validation loss: 2.2609720819739887

Epoch: 6| Step: 8
Training loss: 1.8521428108215332
Validation loss: 2.2649192604967343

Epoch: 6| Step: 9
Training loss: 1.5478568077087402
Validation loss: 2.1716045436038764

Epoch: 6| Step: 10
Training loss: 1.6662757396697998
Validation loss: 2.0973896826467207

Epoch: 6| Step: 11
Training loss: 1.8631696701049805
Validation loss: 2.169285041029735

Epoch: 6| Step: 12
Training loss: 1.4321784973144531
Validation loss: 2.1903110229840843

Epoch: 6| Step: 13
Training loss: 2.3868491649627686
Validation loss: 2.168818866052935

Epoch: 479| Step: 0
Training loss: 1.2940194606781006
Validation loss: 2.2480310265735914

Epoch: 6| Step: 1
Training loss: 2.0447616577148438
Validation loss: 2.1864263755018993

Epoch: 6| Step: 2
Training loss: 1.5898157358169556
Validation loss: 2.178209489391696

Epoch: 6| Step: 3
Training loss: 1.2278759479522705
Validation loss: 2.2054302820595364

Epoch: 6| Step: 4
Training loss: 0.923066258430481
Validation loss: 2.201899056793541

Epoch: 6| Step: 5
Training loss: 1.1162186861038208
Validation loss: 2.141113909341956

Epoch: 6| Step: 6
Training loss: 1.5353946685791016
Validation loss: 2.2128885894693355

Epoch: 6| Step: 7
Training loss: 1.6822724342346191
Validation loss: 2.128451870333764

Epoch: 6| Step: 8
Training loss: 1.7178516387939453
Validation loss: 2.2414957297745572

Epoch: 6| Step: 9
Training loss: 1.1484696865081787
Validation loss: 2.173923089940061

Epoch: 6| Step: 10
Training loss: 1.8555378913879395
Validation loss: 2.082628070667226

Epoch: 6| Step: 11
Training loss: 1.8782669305801392
Validation loss: 2.1230860000015586

Epoch: 6| Step: 12
Training loss: 1.6909728050231934
Validation loss: 2.2532666857524584

Epoch: 6| Step: 13
Training loss: 1.9510366916656494
Validation loss: 2.2209862355263

Epoch: 480| Step: 0
Training loss: 1.6247680187225342
Validation loss: 2.1933532760989283

Epoch: 6| Step: 1
Training loss: 1.9123790264129639
Validation loss: 2.2756823929407264

Epoch: 6| Step: 2
Training loss: 1.2549169063568115
Validation loss: 2.2540774653034825

Epoch: 6| Step: 3
Training loss: 1.4019311666488647
Validation loss: 2.2017299308571765

Epoch: 6| Step: 4
Training loss: 1.2762441635131836
Validation loss: 2.255950022769231

Epoch: 6| Step: 5
Training loss: 1.0370752811431885
Validation loss: 2.2385360540882235

Epoch: 6| Step: 6
Training loss: 1.6541014909744263
Validation loss: 2.3322699249431653

Epoch: 6| Step: 7
Training loss: 1.9603933095932007
Validation loss: 2.1929637885862783

Epoch: 6| Step: 8
Training loss: 1.571686029434204
Validation loss: 2.1458838293629308

Epoch: 6| Step: 9
Training loss: 1.243955135345459
Validation loss: 2.146332415201331

Epoch: 6| Step: 10
Training loss: 1.62125825881958
Validation loss: 2.2208555206175773

Epoch: 6| Step: 11
Training loss: 1.7063325643539429
Validation loss: 2.1982731921698457

Epoch: 6| Step: 12
Training loss: 1.225327968597412
Validation loss: 2.2137969155465402

Epoch: 6| Step: 13
Training loss: 2.097262144088745
Validation loss: 2.203262145801257

Epoch: 481| Step: 0
Training loss: 1.628546953201294
Validation loss: 2.0830268500953593

Epoch: 6| Step: 1
Training loss: 1.4318475723266602
Validation loss: 2.197854224071708

Epoch: 6| Step: 2
Training loss: 2.031909942626953
Validation loss: 2.222053461177375

Epoch: 6| Step: 3
Training loss: 1.2667800188064575
Validation loss: 2.1539760687017955

Epoch: 6| Step: 4
Training loss: 1.2478711605072021
Validation loss: 2.23545947382527

Epoch: 6| Step: 5
Training loss: 1.689756155014038
Validation loss: 2.1941798707490325

Epoch: 6| Step: 6
Training loss: 1.5814155340194702
Validation loss: 2.2415933557735976

Epoch: 6| Step: 7
Training loss: 1.781593918800354
Validation loss: 2.1971440815156504

Epoch: 6| Step: 8
Training loss: 1.219559907913208
Validation loss: 2.2566908995310464

Epoch: 6| Step: 9
Training loss: 1.5938504934310913
Validation loss: 2.226584501163934

Epoch: 6| Step: 10
Training loss: 0.9696889519691467
Validation loss: 2.298163003818963

Epoch: 6| Step: 11
Training loss: 1.2392444610595703
Validation loss: 2.2408318493955877

Epoch: 6| Step: 12
Training loss: 1.764487862586975
Validation loss: 2.1912101494368685

Epoch: 6| Step: 13
Training loss: 2.1933295726776123
Validation loss: 2.2830850872942197

Epoch: 482| Step: 0
Training loss: 1.9521385431289673
Validation loss: 2.206197541247132

Epoch: 6| Step: 1
Training loss: 1.441493272781372
Validation loss: 2.1532612385288363

Epoch: 6| Step: 2
Training loss: 1.2310580015182495
Validation loss: 2.2284145509043047

Epoch: 6| Step: 3
Training loss: 1.2399468421936035
Validation loss: 2.289534238076979

Epoch: 6| Step: 4
Training loss: 1.3772428035736084
Validation loss: 2.2839816795882357

Epoch: 6| Step: 5
Training loss: 1.7770404815673828
Validation loss: 2.1906942090680523

Epoch: 6| Step: 6
Training loss: 2.1534736156463623
Validation loss: 2.2588997169207503

Epoch: 6| Step: 7
Training loss: 1.9538178443908691
Validation loss: 2.2718030316855318

Epoch: 6| Step: 8
Training loss: 1.577307105064392
Validation loss: 2.2440585910633044

Epoch: 6| Step: 9
Training loss: 1.4191312789916992
Validation loss: 2.2483884108963834

Epoch: 6| Step: 10
Training loss: 1.3661946058273315
Validation loss: 2.1831698327936153

Epoch: 6| Step: 11
Training loss: 0.9212489128112793
Validation loss: 2.2634961271798737

Epoch: 6| Step: 12
Training loss: 1.6429870128631592
Validation loss: 2.3260987522781535

Epoch: 6| Step: 13
Training loss: 1.034360408782959
Validation loss: 2.1857905977515766

Epoch: 483| Step: 0
Training loss: 1.6666553020477295
Validation loss: 2.2727361943132136

Epoch: 6| Step: 1
Training loss: 2.375115394592285
Validation loss: 2.236771111847252

Epoch: 6| Step: 2
Training loss: 1.51118004322052
Validation loss: 2.235262473424276

Epoch: 6| Step: 3
Training loss: 0.828742504119873
Validation loss: 2.165088533073343

Epoch: 6| Step: 4
Training loss: 1.2802953720092773
Validation loss: 2.2561978909277145

Epoch: 6| Step: 5
Training loss: 1.50624418258667
Validation loss: 2.200513005256653

Epoch: 6| Step: 6
Training loss: 1.6683460474014282
Validation loss: 2.167941636936639

Epoch: 6| Step: 7
Training loss: 2.0797319412231445
Validation loss: 2.171138641654804

Epoch: 6| Step: 8
Training loss: 1.577943205833435
Validation loss: 2.1624259461638746

Epoch: 6| Step: 9
Training loss: 1.478958010673523
Validation loss: 2.214039789733066

Epoch: 6| Step: 10
Training loss: 1.07712984085083
Validation loss: 2.1507924064513175

Epoch: 6| Step: 11
Training loss: 1.8585408926010132
Validation loss: 2.1405160504002727

Epoch: 6| Step: 12
Training loss: 1.2314198017120361
Validation loss: 2.1910168445238503

Epoch: 6| Step: 13
Training loss: 0.8656819462776184
Validation loss: 2.201486546506164

Epoch: 484| Step: 0
Training loss: 1.8121298551559448
Validation loss: 2.152864453613117

Epoch: 6| Step: 1
Training loss: 1.459355354309082
Validation loss: 2.178395983993366

Epoch: 6| Step: 2
Training loss: 1.5222067832946777
Validation loss: 2.183081329509776

Epoch: 6| Step: 3
Training loss: 1.4343664646148682
Validation loss: 2.2256794732104064

Epoch: 6| Step: 4
Training loss: 1.6540859937667847
Validation loss: 2.254704242111534

Epoch: 6| Step: 5
Training loss: 1.2073643207550049
Validation loss: 2.2032719812085553

Epoch: 6| Step: 6
Training loss: 1.5156900882720947
Validation loss: 2.153799823535386

Epoch: 6| Step: 7
Training loss: 1.5562019348144531
Validation loss: 2.298922710521247

Epoch: 6| Step: 8
Training loss: 1.610841155052185
Validation loss: 2.1843259488382647

Epoch: 6| Step: 9
Training loss: 1.0553560256958008
Validation loss: 2.2699732780456543

Epoch: 6| Step: 10
Training loss: 1.8915891647338867
Validation loss: 2.2524082788857083

Epoch: 6| Step: 11
Training loss: 1.7305834293365479
Validation loss: 2.214386841302277

Epoch: 6| Step: 12
Training loss: 1.5720494985580444
Validation loss: 2.219196081161499

Epoch: 6| Step: 13
Training loss: 1.2388882637023926
Validation loss: 2.20310103765098

Epoch: 485| Step: 0
Training loss: 1.0335773229599
Validation loss: 2.2311758892510527

Epoch: 6| Step: 1
Training loss: 1.4846677780151367
Validation loss: 2.2140684012443788

Epoch: 6| Step: 2
Training loss: 1.431091070175171
Validation loss: 2.268704278494722

Epoch: 6| Step: 3
Training loss: 1.8533637523651123
Validation loss: 2.165004591788015

Epoch: 6| Step: 4
Training loss: 0.8943806886672974
Validation loss: 2.2420693084757817

Epoch: 6| Step: 5
Training loss: 1.1500606536865234
Validation loss: 2.205509119136359

Epoch: 6| Step: 6
Training loss: 1.0665993690490723
Validation loss: 2.200533149062946

Epoch: 6| Step: 7
Training loss: 1.7768325805664062
Validation loss: 2.1393451434309765

Epoch: 6| Step: 8
Training loss: 2.427508592605591
Validation loss: 2.1042921696939776

Epoch: 6| Step: 9
Training loss: 1.4649027585983276
Validation loss: 2.2735717834964877

Epoch: 6| Step: 10
Training loss: 1.4349217414855957
Validation loss: 2.200999880349764

Epoch: 6| Step: 11
Training loss: 0.9563236236572266
Validation loss: 2.142267173336398

Epoch: 6| Step: 12
Training loss: 2.1707444190979004
Validation loss: 2.3053709537752214

Epoch: 6| Step: 13
Training loss: 2.2714834213256836
Validation loss: 2.161636274348023

Epoch: 486| Step: 0
Training loss: 1.789735198020935
Validation loss: 2.260278530018304

Epoch: 6| Step: 1
Training loss: 2.01035213470459
Validation loss: 2.2312485094993346

Epoch: 6| Step: 2
Training loss: 1.929459571838379
Validation loss: 2.290477163048201

Epoch: 6| Step: 3
Training loss: 1.2589080333709717
Validation loss: 2.143260109809137

Epoch: 6| Step: 4
Training loss: 1.592038869857788
Validation loss: 2.2253313474757697

Epoch: 6| Step: 5
Training loss: 1.455615758895874
Validation loss: 2.2359015018709245

Epoch: 6| Step: 6
Training loss: 1.238548994064331
Validation loss: 2.2497038302883023

Epoch: 6| Step: 7
Training loss: 1.252213716506958
Validation loss: 2.2680356758897022

Epoch: 6| Step: 8
Training loss: 1.1597479581832886
Validation loss: 2.302903372754333

Epoch: 6| Step: 9
Training loss: 1.6394264698028564
Validation loss: 2.2147035214208786

Epoch: 6| Step: 10
Training loss: 1.7791645526885986
Validation loss: 2.2881390920249363

Epoch: 6| Step: 11
Training loss: 1.5929900407791138
Validation loss: 2.2820499866239485

Epoch: 6| Step: 12
Training loss: 1.5140522718429565
Validation loss: 2.2031924058032293

Epoch: 6| Step: 13
Training loss: 1.569053292274475
Validation loss: 2.281999695685602

Epoch: 487| Step: 0
Training loss: 2.398381233215332
Validation loss: 2.2037210054295038

Epoch: 6| Step: 1
Training loss: 1.5401673316955566
Validation loss: 2.2484188361834456

Epoch: 6| Step: 2
Training loss: 1.6804215908050537
Validation loss: 2.2866311688576975

Epoch: 6| Step: 3
Training loss: 1.2772490978240967
Validation loss: 2.225213284133583

Epoch: 6| Step: 4
Training loss: 1.8244194984436035
Validation loss: 2.228385620219733

Epoch: 6| Step: 5
Training loss: 0.9646661281585693
Validation loss: 2.2449502124581286

Epoch: 6| Step: 6
Training loss: 1.5886456966400146
Validation loss: 2.269632242059195

Epoch: 6| Step: 7
Training loss: 1.0421231985092163
Validation loss: 2.2399142749847902

Epoch: 6| Step: 8
Training loss: 1.8161267042160034
Validation loss: 2.1938705662245392

Epoch: 6| Step: 9
Training loss: 1.086598515510559
Validation loss: 2.224835270194597

Epoch: 6| Step: 10
Training loss: 1.6856434345245361
Validation loss: 2.252572936396445

Epoch: 6| Step: 11
Training loss: 1.8909547328948975
Validation loss: 2.2147817996240433

Epoch: 6| Step: 12
Training loss: 1.4391416311264038
Validation loss: 2.093391497929891

Epoch: 6| Step: 13
Training loss: 1.5402554273605347
Validation loss: 2.210143548186107

Epoch: 488| Step: 0
Training loss: 0.9877517223358154
Validation loss: 2.190277507228236

Epoch: 6| Step: 1
Training loss: 1.3631293773651123
Validation loss: 2.1470539518581924

Epoch: 6| Step: 2
Training loss: 1.4834413528442383
Validation loss: 2.2477879960049867

Epoch: 6| Step: 3
Training loss: 1.7843750715255737
Validation loss: 2.1409231103876585

Epoch: 6| Step: 4
Training loss: 1.4288403987884521
Validation loss: 2.2765934826225362

Epoch: 6| Step: 5
Training loss: 1.7988033294677734
Validation loss: 2.189504346539897

Epoch: 6| Step: 6
Training loss: 1.4470865726470947
Validation loss: 2.378330945968628

Epoch: 6| Step: 7
Training loss: 1.1681731939315796
Validation loss: 2.230319406396599

Epoch: 6| Step: 8
Training loss: 1.4630193710327148
Validation loss: 2.252619274200932

Epoch: 6| Step: 9
Training loss: 2.701648473739624
Validation loss: 2.17112297396506

Epoch: 6| Step: 10
Training loss: 1.2415204048156738
Validation loss: 2.2757479836863856

Epoch: 6| Step: 11
Training loss: 1.84315824508667
Validation loss: 2.227320680054285

Epoch: 6| Step: 12
Training loss: 1.5025758743286133
Validation loss: 2.187694215005444

Epoch: 6| Step: 13
Training loss: 1.2922065258026123
Validation loss: 2.2016952781267065

Epoch: 489| Step: 0
Training loss: 1.3862180709838867
Validation loss: 2.198757812541018

Epoch: 6| Step: 1
Training loss: 1.5049386024475098
Validation loss: 2.0831060127545427

Epoch: 6| Step: 2
Training loss: 1.769463300704956
Validation loss: 2.192765510210427

Epoch: 6| Step: 3
Training loss: 2.2179176807403564
Validation loss: 2.2886508075139855

Epoch: 6| Step: 4
Training loss: 1.3220312595367432
Validation loss: 2.192519682709889

Epoch: 6| Step: 5
Training loss: 1.3601073026657104
Validation loss: 2.1957641493889595

Epoch: 6| Step: 6
Training loss: 1.4936844110488892
Validation loss: 2.1950868098966536

Epoch: 6| Step: 7
Training loss: 1.6245157718658447
Validation loss: 2.2516564835784254

Epoch: 6| Step: 8
Training loss: 1.6990320682525635
Validation loss: 2.2435989226064375

Epoch: 6| Step: 9
Training loss: 1.0919864177703857
Validation loss: 2.1995638570477887

Epoch: 6| Step: 10
Training loss: 1.6155071258544922
Validation loss: 2.1704633415386243

Epoch: 6| Step: 11
Training loss: 1.2912766933441162
Validation loss: 2.204972267150879

Epoch: 6| Step: 12
Training loss: 1.2957252264022827
Validation loss: 2.204515262316632

Epoch: 6| Step: 13
Training loss: 2.0472445487976074
Validation loss: 2.165064782224676

Epoch: 490| Step: 0
Training loss: 1.8440285921096802
Validation loss: 2.2752697031985045

Epoch: 6| Step: 1
Training loss: 0.9734616279602051
Validation loss: 2.246785984244398

Epoch: 6| Step: 2
Training loss: 2.275665283203125
Validation loss: 2.3365697629990114

Epoch: 6| Step: 3
Training loss: 1.570528268814087
Validation loss: 2.2458503938490346

Epoch: 6| Step: 4
Training loss: 1.4238988161087036
Validation loss: 2.3593344867870374

Epoch: 6| Step: 5
Training loss: 1.5292837619781494
Validation loss: 2.2439881037640315

Epoch: 6| Step: 6
Training loss: 1.9270241260528564
Validation loss: 2.278530172122422

Epoch: 6| Step: 7
Training loss: 1.6027946472167969
Validation loss: 2.3939651161111812

Epoch: 6| Step: 8
Training loss: 1.9593353271484375
Validation loss: 2.328891482404483

Epoch: 6| Step: 9
Training loss: 1.4986121654510498
Validation loss: 2.258913855398855

Epoch: 6| Step: 10
Training loss: 1.390587568283081
Validation loss: 2.284428414478097

Epoch: 6| Step: 11
Training loss: 1.1101154088974
Validation loss: 2.2390713255892516

Epoch: 6| Step: 12
Training loss: 1.0894763469696045
Validation loss: 2.2160850083956154

Epoch: 6| Step: 13
Training loss: 2.339362621307373
Validation loss: 2.21942872898553

Epoch: 491| Step: 0
Training loss: 1.3687372207641602
Validation loss: 2.2014215274523665

Epoch: 6| Step: 1
Training loss: 2.233372211456299
Validation loss: 2.257323363775848

Epoch: 6| Step: 2
Training loss: 1.3187706470489502
Validation loss: 2.2219336853232434

Epoch: 6| Step: 3
Training loss: 1.1243720054626465
Validation loss: 2.224569382206086

Epoch: 6| Step: 4
Training loss: 1.6086136102676392
Validation loss: 2.1376851451012397

Epoch: 6| Step: 5
Training loss: 1.1925253868103027
Validation loss: 2.2318886838933474

Epoch: 6| Step: 6
Training loss: 1.431868314743042
Validation loss: 2.2258835761777815

Epoch: 6| Step: 7
Training loss: 1.2398463487625122
Validation loss: 2.2085260729635916

Epoch: 6| Step: 8
Training loss: 0.7014216184616089
Validation loss: 2.2225973260018135

Epoch: 6| Step: 9
Training loss: 1.6620142459869385
Validation loss: 2.265850861867269

Epoch: 6| Step: 10
Training loss: 1.3308080434799194
Validation loss: 2.24550707878605

Epoch: 6| Step: 11
Training loss: 1.7389529943466187
Validation loss: 2.2590279527889785

Epoch: 6| Step: 12
Training loss: 2.4129457473754883
Validation loss: 2.2313313407282673

Epoch: 6| Step: 13
Training loss: 2.6832852363586426
Validation loss: 2.1191708580140145

Epoch: 492| Step: 0
Training loss: 1.7686545848846436
Validation loss: 2.1924760444189912

Epoch: 6| Step: 1
Training loss: 2.182105779647827
Validation loss: 2.2834053142096407

Epoch: 6| Step: 2
Training loss: 1.4459542036056519
Validation loss: 2.139439349533409

Epoch: 6| Step: 3
Training loss: 1.6166670322418213
Validation loss: 2.1787264552167667

Epoch: 6| Step: 4
Training loss: 1.666785478591919
Validation loss: 2.1577377883336877

Epoch: 6| Step: 5
Training loss: 1.527054786682129
Validation loss: 2.2881218053961314

Epoch: 6| Step: 6
Training loss: 1.7874810695648193
Validation loss: 2.091013762258714

Epoch: 6| Step: 7
Training loss: 1.3353309631347656
Validation loss: 2.2633469258585284

Epoch: 6| Step: 8
Training loss: 1.6788675785064697
Validation loss: 2.202901206990724

Epoch: 6| Step: 9
Training loss: 1.448150873184204
Validation loss: 2.186784573780593

Epoch: 6| Step: 10
Training loss: 1.0706157684326172
Validation loss: 2.1737294543174004

Epoch: 6| Step: 11
Training loss: 1.2804906368255615
Validation loss: 2.1991863801915157

Epoch: 6| Step: 12
Training loss: 1.0441328287124634
Validation loss: 2.2206433537185832

Epoch: 6| Step: 13
Training loss: 1.7399277687072754
Validation loss: 2.152076368690819

Epoch: 493| Step: 0
Training loss: 1.5138014554977417
Validation loss: 2.2224378739633868

Epoch: 6| Step: 1
Training loss: 1.4750025272369385
Validation loss: 2.231071064549108

Epoch: 6| Step: 2
Training loss: 1.8437230587005615
Validation loss: 2.194979900954872

Epoch: 6| Step: 3
Training loss: 1.3357338905334473
Validation loss: 2.261941135570567

Epoch: 6| Step: 4
Training loss: 1.4293018579483032
Validation loss: 2.332413464464167

Epoch: 6| Step: 5
Training loss: 1.3995018005371094
Validation loss: 2.26897907000716

Epoch: 6| Step: 6
Training loss: 1.6709704399108887
Validation loss: 2.274768396090436

Epoch: 6| Step: 7
Training loss: 1.7310911417007446
Validation loss: 2.3242246130461335

Epoch: 6| Step: 8
Training loss: 1.4072175025939941
Validation loss: 2.2683388469039754

Epoch: 6| Step: 9
Training loss: 1.110560655593872
Validation loss: 2.223195937372023

Epoch: 6| Step: 10
Training loss: 1.8588283061981201
Validation loss: 2.2529626392549083

Epoch: 6| Step: 11
Training loss: 1.5361082553863525
Validation loss: 2.2257643412518244

Epoch: 6| Step: 12
Training loss: 1.5242810249328613
Validation loss: 2.2869115503885413

Epoch: 6| Step: 13
Training loss: 2.160158395767212
Validation loss: 2.2780480192553614

Epoch: 494| Step: 0
Training loss: 1.3792074918746948
Validation loss: 2.200851766012048

Epoch: 6| Step: 1
Training loss: 1.4479817152023315
Validation loss: 2.3241257488086657

Epoch: 6| Step: 2
Training loss: 1.0488420724868774
Validation loss: 2.2983828206216135

Epoch: 6| Step: 3
Training loss: 1.1783092021942139
Validation loss: 2.2202249624395884

Epoch: 6| Step: 4
Training loss: 1.549180269241333
Validation loss: 2.226122199848134

Epoch: 6| Step: 5
Training loss: 1.4005651473999023
Validation loss: 2.225056189362721

Epoch: 6| Step: 6
Training loss: 1.773020625114441
Validation loss: 2.1413437486976705

Epoch: 6| Step: 7
Training loss: 1.6971840858459473
Validation loss: 2.2153567908912577

Epoch: 6| Step: 8
Training loss: 1.1360588073730469
Validation loss: 2.2232554856167046

Epoch: 6| Step: 9
Training loss: 1.6318867206573486
Validation loss: 2.24686796434464

Epoch: 6| Step: 10
Training loss: 1.5519813299179077
Validation loss: 2.1551116422940324

Epoch: 6| Step: 11
Training loss: 1.9494730234146118
Validation loss: 2.2151087407142884

Epoch: 6| Step: 12
Training loss: 2.3259530067443848
Validation loss: 2.1724876639663533

Epoch: 6| Step: 13
Training loss: 1.7207276821136475
Validation loss: 2.2156886182805544

Epoch: 495| Step: 0
Training loss: 0.9249762296676636
Validation loss: 2.259514885564004

Epoch: 6| Step: 1
Training loss: 1.7373626232147217
Validation loss: 2.184363954810686

Epoch: 6| Step: 2
Training loss: 1.534778118133545
Validation loss: 2.1596150398254395

Epoch: 6| Step: 3
Training loss: 1.7310795783996582
Validation loss: 2.1930220562924623

Epoch: 6| Step: 4
Training loss: 0.8823162317276001
Validation loss: 2.3073769410451255

Epoch: 6| Step: 5
Training loss: 1.3894448280334473
Validation loss: 2.2031743834095616

Epoch: 6| Step: 6
Training loss: 1.1564466953277588
Validation loss: 2.1716074610269196

Epoch: 6| Step: 7
Training loss: 1.6705067157745361
Validation loss: 2.2573206988714074

Epoch: 6| Step: 8
Training loss: 1.665851354598999
Validation loss: 2.169191098982288

Epoch: 6| Step: 9
Training loss: 1.355621576309204
Validation loss: 2.235201766414027

Epoch: 6| Step: 10
Training loss: 1.7886145114898682
Validation loss: 2.1595298526107625

Epoch: 6| Step: 11
Training loss: 1.796183466911316
Validation loss: 2.1751619974772134

Epoch: 6| Step: 12
Training loss: 2.028432607650757
Validation loss: 2.1875608146831556

Epoch: 6| Step: 13
Training loss: 1.5053346157073975
Validation loss: 2.206959794926387

Epoch: 496| Step: 0
Training loss: 1.3186166286468506
Validation loss: 2.2411764565334527

Epoch: 6| Step: 1
Training loss: 1.1326487064361572
Validation loss: 2.1627997672686012

Epoch: 6| Step: 2
Training loss: 1.3596386909484863
Validation loss: 2.276040719401452

Epoch: 6| Step: 3
Training loss: 1.6607537269592285
Validation loss: 2.376889664639709

Epoch: 6| Step: 4
Training loss: 1.574030876159668
Validation loss: 2.34038786221576

Epoch: 6| Step: 5
Training loss: 1.8292317390441895
Validation loss: 2.3541856017164005

Epoch: 6| Step: 6
Training loss: 2.278120756149292
Validation loss: 2.3642773397507204

Epoch: 6| Step: 7
Training loss: 1.3463616371154785
Validation loss: 2.339201268329415

Epoch: 6| Step: 8
Training loss: 1.1324541568756104
Validation loss: 2.2494570670589322

Epoch: 6| Step: 9
Training loss: 1.364530324935913
Validation loss: 2.297246986819852

Epoch: 6| Step: 10
Training loss: 1.4251857995986938
Validation loss: 2.224323041977421

Epoch: 6| Step: 11
Training loss: 1.9488334655761719
Validation loss: 2.181340297063192

Epoch: 6| Step: 12
Training loss: 2.093961715698242
Validation loss: 2.217583025655439

Epoch: 6| Step: 13
Training loss: 0.9752841591835022
Validation loss: 2.2945675542277675

Epoch: 497| Step: 0
Training loss: 1.1726174354553223
Validation loss: 2.2308822408799203

Epoch: 6| Step: 1
Training loss: 1.4624385833740234
Validation loss: 2.2801766395568848

Epoch: 6| Step: 2
Training loss: 1.7017834186553955
Validation loss: 2.1774621702009633

Epoch: 6| Step: 3
Training loss: 1.4182205200195312
Validation loss: 2.116526380661995

Epoch: 6| Step: 4
Training loss: 1.4167909622192383
Validation loss: 2.183319660925096

Epoch: 6| Step: 5
Training loss: 1.6731088161468506
Validation loss: 2.227799807825396

Epoch: 6| Step: 6
Training loss: 1.326337218284607
Validation loss: 2.1795173896256315

Epoch: 6| Step: 7
Training loss: 1.4204795360565186
Validation loss: 2.2195603104047876

Epoch: 6| Step: 8
Training loss: 2.3003907203674316
Validation loss: 2.2071723066350466

Epoch: 6| Step: 9
Training loss: 1.211958646774292
Validation loss: 2.2515056107633855

Epoch: 6| Step: 10
Training loss: 1.316002368927002
Validation loss: 2.241178834310142

Epoch: 6| Step: 11
Training loss: 1.4061415195465088
Validation loss: 2.2202888304187405

Epoch: 6| Step: 12
Training loss: 1.365074634552002
Validation loss: 2.200940316723239

Epoch: 6| Step: 13
Training loss: 2.316507577896118
Validation loss: 2.132209386876834

Epoch: 498| Step: 0
Training loss: 1.1721162796020508
Validation loss: 2.2262032724195913

Epoch: 6| Step: 1
Training loss: 1.8655979633331299
Validation loss: 2.2390061142624065

Epoch: 6| Step: 2
Training loss: 1.751551628112793
Validation loss: 2.356999058877268

Epoch: 6| Step: 3
Training loss: 1.1125030517578125
Validation loss: 2.247365508028256

Epoch: 6| Step: 4
Training loss: 1.3187768459320068
Validation loss: 2.213138608522313

Epoch: 6| Step: 5
Training loss: 1.6305232048034668
Validation loss: 2.3554983651766213

Epoch: 6| Step: 6
Training loss: 1.5335652828216553
Validation loss: 2.295462409655253

Epoch: 6| Step: 7
Training loss: 1.320906162261963
Validation loss: 2.149680079952363

Epoch: 6| Step: 8
Training loss: 2.246574878692627
Validation loss: 2.256300208389118

Epoch: 6| Step: 9
Training loss: 2.0112521648406982
Validation loss: 2.266059208941716

Epoch: 6| Step: 10
Training loss: 1.1960786581039429
Validation loss: 2.2335906977294595

Epoch: 6| Step: 11
Training loss: 1.5384033918380737
Validation loss: 2.1986337451524633

Epoch: 6| Step: 12
Training loss: 1.0835689306259155
Validation loss: 2.2636971858239945

Epoch: 6| Step: 13
Training loss: 2.1064727306365967
Validation loss: 2.209992854825912

Epoch: 499| Step: 0
Training loss: 1.1292228698730469
Validation loss: 2.186302015858312

Epoch: 6| Step: 1
Training loss: 1.1217339038848877
Validation loss: 2.113850458975761

Epoch: 6| Step: 2
Training loss: 1.9369065761566162
Validation loss: 2.222318149382068

Epoch: 6| Step: 3
Training loss: 1.0463635921478271
Validation loss: 2.2753349850254674

Epoch: 6| Step: 4
Training loss: 1.4679838418960571
Validation loss: 2.189083332656532

Epoch: 6| Step: 5
Training loss: 1.3850295543670654
Validation loss: 2.255479984385993

Epoch: 6| Step: 6
Training loss: 1.2514662742614746
Validation loss: 2.173284328112038

Epoch: 6| Step: 7
Training loss: 1.8175936937332153
Validation loss: 2.238859107417445

Epoch: 6| Step: 8
Training loss: 1.5726574659347534
Validation loss: 2.13831248078295

Epoch: 6| Step: 9
Training loss: 1.6064759492874146
Validation loss: 2.252411965400942

Epoch: 6| Step: 10
Training loss: 1.3717929124832153
Validation loss: 2.2386834300974363

Epoch: 6| Step: 11
Training loss: 1.9036316871643066
Validation loss: 2.172579401282854

Epoch: 6| Step: 12
Training loss: 1.5740621089935303
Validation loss: 2.2402099870866343

Epoch: 6| Step: 13
Training loss: 1.7661656141281128
Validation loss: 2.0971934974834485

Epoch: 500| Step: 0
Training loss: 1.2144412994384766
Validation loss: 2.228730070975519

Epoch: 6| Step: 1
Training loss: 1.8561118841171265
Validation loss: 2.166422402986916

Epoch: 6| Step: 2
Training loss: 1.3661563396453857
Validation loss: 2.2888682298762824

Epoch: 6| Step: 3
Training loss: 1.7788963317871094
Validation loss: 2.1606607590952227

Epoch: 6| Step: 4
Training loss: 1.2216200828552246
Validation loss: 2.1955032886997348

Epoch: 6| Step: 5
Training loss: 1.7704746723175049
Validation loss: 2.223792017147105

Epoch: 6| Step: 6
Training loss: 1.6925430297851562
Validation loss: 2.2151895056488695

Epoch: 6| Step: 7
Training loss: 1.536045789718628
Validation loss: 2.1716285008256153

Epoch: 6| Step: 8
Training loss: 1.6293761730194092
Validation loss: 2.225574488280922

Epoch: 6| Step: 9
Training loss: 1.6547894477844238
Validation loss: 2.221060235013244

Epoch: 6| Step: 10
Training loss: 1.3225017786026
Validation loss: 2.24021041265098

Epoch: 6| Step: 11
Training loss: 1.1066558361053467
Validation loss: 2.1301734370570027

Epoch: 6| Step: 12
Training loss: 1.0269105434417725
Validation loss: 2.233687589245458

Epoch: 6| Step: 13
Training loss: 1.737163782119751
Validation loss: 2.260075407643472

Testing loss: 2.1122321711646186
