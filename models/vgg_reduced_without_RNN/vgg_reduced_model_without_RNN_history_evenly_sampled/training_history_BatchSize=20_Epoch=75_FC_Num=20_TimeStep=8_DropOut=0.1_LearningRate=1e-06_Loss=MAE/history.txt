Epoch: 1| Step: 0
Training loss: 4.9893879890441895
Validation loss: 5.782471077416533

Epoch: 5| Step: 1
Training loss: 4.60650634765625
Validation loss: 5.781338553274831

Epoch: 5| Step: 2
Training loss: 6.089670658111572
Validation loss: 5.774031439135151

Epoch: 5| Step: 3
Training loss: 5.37558650970459
Validation loss: 5.773202706408757

Epoch: 5| Step: 4
Training loss: 5.788670539855957
Validation loss: 5.773394102691322

Epoch: 5| Step: 5
Training loss: 6.514244079589844
Validation loss: 5.766754063226843

Epoch: 5| Step: 6
Training loss: 5.260796070098877
Validation loss: 5.766097217477778

Epoch: 5| Step: 7
Training loss: 6.1196980476379395
Validation loss: 5.763269137310726

Epoch: 5| Step: 8
Training loss: 4.610925674438477
Validation loss: 5.75711860451647

Epoch: 5| Step: 9
Training loss: 6.206482887268066
Validation loss: 5.757383233757429

Epoch: 5| Step: 10
Training loss: 5.685946941375732
Validation loss: 5.749622934608049

Epoch: 2| Step: 0
Training loss: 5.028851509094238
Validation loss: 5.751249374881867

Epoch: 5| Step: 1
Training loss: 5.700189113616943
Validation loss: 5.744677194985011

Epoch: 5| Step: 2
Training loss: 5.687615871429443
Validation loss: 5.747505480243314

Epoch: 5| Step: 3
Training loss: 5.779450416564941
Validation loss: 5.741120810149818

Epoch: 5| Step: 4
Training loss: 5.205959320068359
Validation loss: 5.739035344892932

Epoch: 5| Step: 5
Training loss: 6.2833075523376465
Validation loss: 5.735852723480553

Epoch: 5| Step: 6
Training loss: 4.444904327392578
Validation loss: 5.730956395467122

Epoch: 5| Step: 7
Training loss: 5.367332935333252
Validation loss: 5.73019237928493

Epoch: 5| Step: 8
Training loss: 6.078368186950684
Validation loss: 5.727556905438823

Epoch: 5| Step: 9
Training loss: 5.582188606262207
Validation loss: 5.725100537782074

Epoch: 5| Step: 10
Training loss: 5.758509159088135
Validation loss: 5.719787484856062

Epoch: 3| Step: 0
Training loss: 5.903096675872803
Validation loss: 5.716881957105411

Epoch: 5| Step: 1
Training loss: 5.941425800323486
Validation loss: 5.710653669090681

Epoch: 5| Step: 2
Training loss: 4.987912178039551
Validation loss: 5.709397828707131

Epoch: 5| Step: 3
Training loss: 4.892343521118164
Validation loss: 5.706822236378987

Epoch: 5| Step: 4
Training loss: 4.283468246459961
Validation loss: 5.706631865552676

Epoch: 5| Step: 5
Training loss: 5.385082244873047
Validation loss: 5.703379923297513

Epoch: 5| Step: 6
Training loss: 6.103713035583496
Validation loss: 5.696909694261448

Epoch: 5| Step: 7
Training loss: 6.0622358322143555
Validation loss: 5.695796771716046

Epoch: 5| Step: 8
Training loss: 5.632319927215576
Validation loss: 5.691343845859651

Epoch: 5| Step: 9
Training loss: 5.209961891174316
Validation loss: 5.688108177595241

Epoch: 5| Step: 10
Training loss: 6.198844909667969
Validation loss: 5.687065406512189

Epoch: 4| Step: 0
Training loss: 5.185236930847168
Validation loss: 5.682643023870325

Epoch: 5| Step: 1
Training loss: 4.9298834800720215
Validation loss: 5.681136162050309

Epoch: 5| Step: 2
Training loss: 4.91123104095459
Validation loss: 5.6760189712688485

Epoch: 5| Step: 3
Training loss: 5.698220729827881
Validation loss: 5.672200531087896

Epoch: 5| Step: 4
Training loss: 5.238322734832764
Validation loss: 5.667327598858905

Epoch: 5| Step: 5
Training loss: 5.1848015785217285
Validation loss: 5.665664467760312

Epoch: 5| Step: 6
Training loss: 5.896245002746582
Validation loss: 5.663684768061484

Epoch: 5| Step: 7
Training loss: 6.410597801208496
Validation loss: 5.652399011837539

Epoch: 5| Step: 8
Training loss: 5.388832092285156
Validation loss: 5.652032124098911

Epoch: 5| Step: 9
Training loss: 4.979012489318848
Validation loss: 5.646106596915953

Epoch: 5| Step: 10
Training loss: 6.356480121612549
Validation loss: 5.639889850411364

Epoch: 5| Step: 0
Training loss: 5.788238525390625
Validation loss: 5.635228023734144

Epoch: 5| Step: 1
Training loss: 6.891049385070801
Validation loss: 5.6350989239190215

Epoch: 5| Step: 2
Training loss: 5.02631950378418
Validation loss: 5.625659742662983

Epoch: 5| Step: 3
Training loss: 4.870366096496582
Validation loss: 5.6211977620278635

Epoch: 5| Step: 4
Training loss: 4.57743501663208
Validation loss: 5.614113664114347

Epoch: 5| Step: 5
Training loss: 5.425361633300781
Validation loss: 5.609148497222572

Epoch: 5| Step: 6
Training loss: 4.859167575836182
Validation loss: 5.608983234692645

Epoch: 5| Step: 7
Training loss: 4.981722354888916
Validation loss: 5.598904445607175

Epoch: 5| Step: 8
Training loss: 5.5754923820495605
Validation loss: 5.5959146150978665

Epoch: 5| Step: 9
Training loss: 5.721449851989746
Validation loss: 5.589064680119996

Epoch: 5| Step: 10
Training loss: 5.796192646026611
Validation loss: 5.5837264830066315

Epoch: 6| Step: 0
Training loss: 5.0709547996521
Validation loss: 5.576804914782124

Epoch: 5| Step: 1
Training loss: 5.535956859588623
Validation loss: 5.5697127157642

Epoch: 5| Step: 2
Training loss: 5.145059585571289
Validation loss: 5.562838795364544

Epoch: 5| Step: 3
Training loss: 4.523354530334473
Validation loss: 5.557030611140753

Epoch: 5| Step: 4
Training loss: 5.442187309265137
Validation loss: 5.556184076493786

Epoch: 5| Step: 5
Training loss: 5.6666059494018555
Validation loss: 5.547467821387834

Epoch: 5| Step: 6
Training loss: 6.063605785369873
Validation loss: 5.542663420400312

Epoch: 5| Step: 7
Training loss: 5.1644768714904785
Validation loss: 5.536216951185657

Epoch: 5| Step: 8
Training loss: 5.664793491363525
Validation loss: 5.529353910876859

Epoch: 5| Step: 9
Training loss: 5.299487113952637
Validation loss: 5.523447436671103

Epoch: 5| Step: 10
Training loss: 5.151446342468262
Validation loss: 5.5159348262253625

Epoch: 7| Step: 0
Training loss: 5.061478614807129
Validation loss: 5.5092687145356205

Epoch: 5| Step: 1
Training loss: 5.093020439147949
Validation loss: 5.506303002757411

Epoch: 5| Step: 2
Training loss: 4.222970008850098
Validation loss: 5.498194304845667

Epoch: 5| Step: 3
Training loss: 4.6475019454956055
Validation loss: 5.492942240930373

Epoch: 5| Step: 4
Training loss: 5.371811866760254
Validation loss: 5.482626330467962

Epoch: 5| Step: 5
Training loss: 6.592450141906738
Validation loss: 5.473280773367933

Epoch: 5| Step: 6
Training loss: 6.062330722808838
Validation loss: 5.472122843547534

Epoch: 5| Step: 7
Training loss: 4.069279193878174
Validation loss: 5.463975321862005

Epoch: 5| Step: 8
Training loss: 5.401493072509766
Validation loss: 5.458774623050485

Epoch: 5| Step: 9
Training loss: 6.074948787689209
Validation loss: 5.4530503724211

Epoch: 5| Step: 10
Training loss: 5.4148454666137695
Validation loss: 5.451543710565054

Epoch: 8| Step: 0
Training loss: 5.055349349975586
Validation loss: 5.438543776030182

Epoch: 5| Step: 1
Training loss: 4.1688127517700195
Validation loss: 5.4328688652284685

Epoch: 5| Step: 2
Training loss: 5.400834560394287
Validation loss: 5.426065788474134

Epoch: 5| Step: 3
Training loss: 6.057253837585449
Validation loss: 5.414203141325263

Epoch: 5| Step: 4
Training loss: 5.300719738006592
Validation loss: 5.409205826379919

Epoch: 5| Step: 5
Training loss: 3.911515712738037
Validation loss: 5.401546370598577

Epoch: 5| Step: 6
Training loss: 6.37028169631958
Validation loss: 5.397917583424558

Epoch: 5| Step: 7
Training loss: 4.104318141937256
Validation loss: 5.38626625204599

Epoch: 5| Step: 8
Training loss: 5.973387241363525
Validation loss: 5.382729745680286

Epoch: 5| Step: 9
Training loss: 5.161800384521484
Validation loss: 5.370832576546618

Epoch: 5| Step: 10
Training loss: 5.653295040130615
Validation loss: 5.365104029255528

Epoch: 9| Step: 0
Training loss: 5.33644962310791
Validation loss: 5.362326386154339

Epoch: 5| Step: 1
Training loss: 4.991812705993652
Validation loss: 5.352751198635306

Epoch: 5| Step: 2
Training loss: 4.878907203674316
Validation loss: 5.34030496433217

Epoch: 5| Step: 3
Training loss: 5.112565040588379
Validation loss: 5.337286226211056

Epoch: 5| Step: 4
Training loss: 3.569096803665161
Validation loss: 5.328728727115098

Epoch: 5| Step: 5
Training loss: 5.987276077270508
Validation loss: 5.315446858764977

Epoch: 5| Step: 6
Training loss: 4.009702205657959
Validation loss: 5.306722723027711

Epoch: 5| Step: 7
Training loss: 5.882903099060059
Validation loss: 5.299242117071665

Epoch: 5| Step: 8
Training loss: 6.26780366897583
Validation loss: 5.292133197989515

Epoch: 5| Step: 9
Training loss: 4.585175514221191
Validation loss: 5.283349790880757

Epoch: 5| Step: 10
Training loss: 5.575374603271484
Validation loss: 5.276784968632524

Epoch: 10| Step: 0
Training loss: 5.748284339904785
Validation loss: 5.261748698449904

Epoch: 5| Step: 1
Training loss: 5.437549591064453
Validation loss: 5.257456205224478

Epoch: 5| Step: 2
Training loss: 5.492805004119873
Validation loss: 5.246311623563049

Epoch: 5| Step: 3
Training loss: 4.87958288192749
Validation loss: 5.2366553839816845

Epoch: 5| Step: 4
Training loss: 5.335501670837402
Validation loss: 5.224416158532583

Epoch: 5| Step: 5
Training loss: 4.114888668060303
Validation loss: 5.218472921720115

Epoch: 5| Step: 6
Training loss: 4.706437587738037
Validation loss: 5.209690422140142

Epoch: 5| Step: 7
Training loss: 5.446359634399414
Validation loss: 5.200932379691832

Epoch: 5| Step: 8
Training loss: 5.101346015930176
Validation loss: 5.192637192305698

Epoch: 5| Step: 9
Training loss: 4.987955570220947
Validation loss: 5.182564709776191

Epoch: 5| Step: 10
Training loss: 3.551772117614746
Validation loss: 5.17379968397079

Epoch: 11| Step: 0
Training loss: 5.2958550453186035
Validation loss: 5.159629770504531

Epoch: 5| Step: 1
Training loss: 5.288056373596191
Validation loss: 5.1493355586964595

Epoch: 5| Step: 2
Training loss: 5.388945579528809
Validation loss: 5.14188818265033

Epoch: 5| Step: 3
Training loss: 4.368746757507324
Validation loss: 5.124152324532949

Epoch: 5| Step: 4
Training loss: 5.09614896774292
Validation loss: 5.1197152394120415

Epoch: 5| Step: 5
Training loss: 4.039532661437988
Validation loss: 5.108934899812104

Epoch: 5| Step: 6
Training loss: 5.742033958435059
Validation loss: 5.097152227996498

Epoch: 5| Step: 7
Training loss: 4.631321907043457
Validation loss: 5.087666224407894

Epoch: 5| Step: 8
Training loss: 4.41178035736084
Validation loss: 5.075726201457362

Epoch: 5| Step: 9
Training loss: 5.176748752593994
Validation loss: 5.060314147703109

Epoch: 5| Step: 10
Training loss: 4.286412239074707
Validation loss: 5.056793343636297

Epoch: 12| Step: 0
Training loss: 4.219101905822754
Validation loss: 5.050723542449295

Epoch: 5| Step: 1
Training loss: 3.980072498321533
Validation loss: 5.027934623020951

Epoch: 5| Step: 2
Training loss: 5.096357822418213
Validation loss: 5.020415926492342

Epoch: 5| Step: 3
Training loss: 5.749516487121582
Validation loss: 5.013633502426968

Epoch: 5| Step: 4
Training loss: 4.398207664489746
Validation loss: 5.003854079913068

Epoch: 5| Step: 5
Training loss: 4.246988296508789
Validation loss: 4.990138607640421

Epoch: 5| Step: 6
Training loss: 5.546548366546631
Validation loss: 4.971409346467706

Epoch: 5| Step: 7
Training loss: 6.2992353439331055
Validation loss: 4.9535135146110285

Epoch: 5| Step: 8
Training loss: 5.218058109283447
Validation loss: 4.95294407362579

Epoch: 5| Step: 9
Training loss: 3.251006603240967
Validation loss: 4.9341644881874

Epoch: 5| Step: 10
Training loss: 4.374251365661621
Validation loss: 4.927749890153126

Epoch: 13| Step: 0
Training loss: 4.506528854370117
Validation loss: 4.9123179784385105

Epoch: 5| Step: 1
Training loss: 5.706686019897461
Validation loss: 4.900533076255552

Epoch: 5| Step: 2
Training loss: 4.923020839691162
Validation loss: 4.887917692943286

Epoch: 5| Step: 3
Training loss: 4.35439920425415
Validation loss: 4.875502222327776

Epoch: 5| Step: 4
Training loss: 5.219751834869385
Validation loss: 4.856834098856936

Epoch: 5| Step: 5
Training loss: 4.600531101226807
Validation loss: 4.847183709503502

Epoch: 5| Step: 6
Training loss: 5.216794013977051
Validation loss: 4.833155396164105

Epoch: 5| Step: 7
Training loss: 5.059190273284912
Validation loss: 4.814059831762827

Epoch: 5| Step: 8
Training loss: 3.8979763984680176
Validation loss: 4.807940324147542

Epoch: 5| Step: 9
Training loss: 3.1712586879730225
Validation loss: 4.796482142581735

Epoch: 5| Step: 10
Training loss: 4.180191993713379
Validation loss: 4.780959647188904

Epoch: 14| Step: 0
Training loss: 4.286993503570557
Validation loss: 4.762430498676915

Epoch: 5| Step: 1
Training loss: 5.357203483581543
Validation loss: 4.7461878509931665

Epoch: 5| Step: 2
Training loss: 3.949138641357422
Validation loss: 4.742764575507051

Epoch: 5| Step: 3
Training loss: 3.503678560256958
Validation loss: 4.7256482083310365

Epoch: 5| Step: 4
Training loss: 5.1216559410095215
Validation loss: 4.7105907932404545

Epoch: 5| Step: 5
Training loss: 4.8268256187438965
Validation loss: 4.696585075829619

Epoch: 5| Step: 6
Training loss: 5.162309646606445
Validation loss: 4.673859683416223

Epoch: 5| Step: 7
Training loss: 3.922528028488159
Validation loss: 4.6608840880855436

Epoch: 5| Step: 8
Training loss: 4.226040840148926
Validation loss: 4.6482278480324695

Epoch: 5| Step: 9
Training loss: 4.580665588378906
Validation loss: 4.633526104752735

Epoch: 5| Step: 10
Training loss: 4.184452056884766
Validation loss: 4.626749756515667

Epoch: 15| Step: 0
Training loss: 3.6140036582946777
Validation loss: 4.592193836806922

Epoch: 5| Step: 1
Training loss: 4.136233329772949
Validation loss: 4.5802181459242295

Epoch: 5| Step: 2
Training loss: 4.195916652679443
Validation loss: 4.57623101306218

Epoch: 5| Step: 3
Training loss: 4.32235050201416
Validation loss: 4.5643861729611634

Epoch: 5| Step: 4
Training loss: 5.011666774749756
Validation loss: 4.542501357293898

Epoch: 5| Step: 5
Training loss: 4.539589881896973
Validation loss: 4.531623581404327

Epoch: 5| Step: 6
Training loss: 5.3332929611206055
Validation loss: 4.515102130110546

Epoch: 5| Step: 7
Training loss: 3.6910204887390137
Validation loss: 4.490517416308003

Epoch: 5| Step: 8
Training loss: 2.0480308532714844
Validation loss: 4.471277103629164

Epoch: 5| Step: 9
Training loss: 4.593209266662598
Validation loss: 4.460392962219895

Epoch: 5| Step: 10
Training loss: 6.058457851409912
Validation loss: 4.446433405722341

Epoch: 16| Step: 0
Training loss: 4.767297744750977
Validation loss: 4.437697584911059

Epoch: 5| Step: 1
Training loss: 4.727437496185303
Validation loss: 4.41115600832047

Epoch: 5| Step: 2
Training loss: 4.034220218658447
Validation loss: 4.4028825400978

Epoch: 5| Step: 3
Training loss: 4.266837120056152
Validation loss: 4.372242501986924

Epoch: 5| Step: 4
Training loss: 2.9861364364624023
Validation loss: 4.3613878603904475

Epoch: 5| Step: 5
Training loss: 3.1101651191711426
Validation loss: 4.33654079129619

Epoch: 5| Step: 6
Training loss: 4.138647079467773
Validation loss: 4.3171111588837

Epoch: 5| Step: 7
Training loss: 4.181276798248291
Validation loss: 4.302756191581808

Epoch: 5| Step: 8
Training loss: 3.920137405395508
Validation loss: 4.2780812581380205

Epoch: 5| Step: 9
Training loss: 4.078647613525391
Validation loss: 4.253298267241447

Epoch: 5| Step: 10
Training loss: 5.262311935424805
Validation loss: 4.242604809422647

Epoch: 17| Step: 0
Training loss: 4.399925708770752
Validation loss: 4.224504275988507

Epoch: 5| Step: 1
Training loss: 3.4591422080993652
Validation loss: 4.212067727119692

Epoch: 5| Step: 2
Training loss: 4.17742395401001
Validation loss: 4.197762735428348

Epoch: 5| Step: 3
Training loss: 4.341058254241943
Validation loss: 4.15916693851512

Epoch: 5| Step: 4
Training loss: 4.022677421569824
Validation loss: 4.166140328171433

Epoch: 5| Step: 5
Training loss: 4.29010534286499
Validation loss: 4.136772130125312

Epoch: 5| Step: 6
Training loss: 4.080179214477539
Validation loss: 4.107605388087611

Epoch: 5| Step: 7
Training loss: 3.2466156482696533
Validation loss: 4.071650443538543

Epoch: 5| Step: 8
Training loss: 3.864367723464966
Validation loss: 4.087980562640775

Epoch: 5| Step: 9
Training loss: 4.3084282875061035
Validation loss: 4.0677842991326445

Epoch: 5| Step: 10
Training loss: 3.123544931411743
Validation loss: 4.044860942389375

Epoch: 18| Step: 0
Training loss: 4.505856513977051
Validation loss: 4.015411899935815

Epoch: 5| Step: 1
Training loss: 4.639575004577637
Validation loss: 4.012597801864788

Epoch: 5| Step: 2
Training loss: 3.5001919269561768
Validation loss: 3.979015452887422

Epoch: 5| Step: 3
Training loss: 4.450065612792969
Validation loss: 3.955550111750121

Epoch: 5| Step: 4
Training loss: 3.4505093097686768
Validation loss: 3.9444851388213453

Epoch: 5| Step: 5
Training loss: 3.643536329269409
Validation loss: 3.9258591974935224

Epoch: 5| Step: 6
Training loss: 3.4539618492126465
Validation loss: 3.8976887990069646

Epoch: 5| Step: 7
Training loss: 3.0712943077087402
Validation loss: 3.889761053105836

Epoch: 5| Step: 8
Training loss: 4.738563060760498
Validation loss: 3.870530425861318

Epoch: 5| Step: 9
Training loss: 3.397540330886841
Validation loss: 3.8644930778011197

Epoch: 5| Step: 10
Training loss: 2.3565876483917236
Validation loss: 3.855915920708769

Epoch: 19| Step: 0
Training loss: 4.72337532043457
Validation loss: 3.8188478151957193

Epoch: 5| Step: 1
Training loss: 2.6981873512268066
Validation loss: 3.7919534073081067

Epoch: 5| Step: 2
Training loss: 4.461690425872803
Validation loss: 3.7795911117266585

Epoch: 5| Step: 3
Training loss: 3.599822998046875
Validation loss: 3.75413248103152

Epoch: 5| Step: 4
Training loss: 3.4659321308135986
Validation loss: 3.7268016927985737

Epoch: 5| Step: 5
Training loss: 3.396127700805664
Validation loss: 3.7148074257758354

Epoch: 5| Step: 6
Training loss: 3.8100783824920654
Validation loss: 3.706167410778743

Epoch: 5| Step: 7
Training loss: 3.696775436401367
Validation loss: 3.6769636113156556

Epoch: 5| Step: 8
Training loss: 3.444105625152588
Validation loss: 3.6524966660366265

Epoch: 5| Step: 9
Training loss: 3.5827407836914062
Validation loss: 3.653387767012401

Epoch: 5| Step: 10
Training loss: 2.4733715057373047
Validation loss: 3.6078174191136516

Epoch: 20| Step: 0
Training loss: 3.6131019592285156
Validation loss: 3.61023703698189

Epoch: 5| Step: 1
Training loss: 3.4771034717559814
Validation loss: 3.599136734521517

Epoch: 5| Step: 2
Training loss: 2.9910216331481934
Validation loss: 3.569532263663507

Epoch: 5| Step: 3
Training loss: 2.5798449516296387
Validation loss: 3.550301062163486

Epoch: 5| Step: 4
Training loss: 3.6469643115997314
Validation loss: 3.508607787470664

Epoch: 5| Step: 5
Training loss: 2.8274664878845215
Validation loss: 3.5064481612174743

Epoch: 5| Step: 6
Training loss: 3.2643260955810547
Validation loss: 3.496576560440884

Epoch: 5| Step: 7
Training loss: 3.743009090423584
Validation loss: 3.469413567614812

Epoch: 5| Step: 8
Training loss: 4.279229640960693
Validation loss: 3.454953437210411

Epoch: 5| Step: 9
Training loss: 3.8502585887908936
Validation loss: 3.443854844698342

Epoch: 5| Step: 10
Training loss: 3.187623977661133
Validation loss: 3.412769107408421

Epoch: 21| Step: 0
Training loss: 3.522076368331909
Validation loss: 3.3898820953984417

Epoch: 5| Step: 1
Training loss: 3.0954902172088623
Validation loss: 3.3789207140604653

Epoch: 5| Step: 2
Training loss: 3.6343834400177
Validation loss: 3.32764607860196

Epoch: 5| Step: 3
Training loss: 3.779026746749878
Validation loss: 3.3197469044757146

Epoch: 5| Step: 4
Training loss: 2.8825252056121826
Validation loss: 3.3190527936463714

Epoch: 5| Step: 5
Training loss: 3.3091819286346436
Validation loss: 3.2913729785591044

Epoch: 5| Step: 6
Training loss: 3.866504669189453
Validation loss: 3.278957592543735

Epoch: 5| Step: 7
Training loss: 3.422603130340576
Validation loss: 3.234673269333378

Epoch: 5| Step: 8
Training loss: 2.40910267829895
Validation loss: 3.2151560962841077

Epoch: 5| Step: 9
Training loss: 3.218649387359619
Validation loss: 3.1766723740485405

Epoch: 5| Step: 10
Training loss: 2.248753070831299
Validation loss: 3.173639384649133

Epoch: 22| Step: 0
Training loss: 3.4090511798858643
Validation loss: 3.182866980952601

Epoch: 5| Step: 1
Training loss: 3.014108180999756
Validation loss: 3.1357053633659118

Epoch: 5| Step: 2
Training loss: 4.031968593597412
Validation loss: 3.1113660232995146

Epoch: 5| Step: 3
Training loss: 2.730605125427246
Validation loss: 3.1064917349046275

Epoch: 5| Step: 4
Training loss: 3.0018439292907715
Validation loss: 3.0842518088638142

Epoch: 5| Step: 5
Training loss: 2.6958723068237305
Validation loss: 3.065005615193357

Epoch: 5| Step: 6
Training loss: 3.7756271362304688
Validation loss: 3.041065151973437

Epoch: 5| Step: 7
Training loss: 2.8210020065307617
Validation loss: 3.020075557052448

Epoch: 5| Step: 8
Training loss: 2.431914806365967
Validation loss: 3.02833281793902

Epoch: 5| Step: 9
Training loss: 2.947920083999634
Validation loss: 3.020389195411436

Epoch: 5| Step: 10
Training loss: 2.633322238922119
Validation loss: 2.9993129186732794

Epoch: 23| Step: 0
Training loss: 2.9994330406188965
Validation loss: 2.9123338883922947

Epoch: 5| Step: 1
Training loss: 3.6347930431365967
Validation loss: 2.9208908311782347

Epoch: 5| Step: 2
Training loss: 2.755727767944336
Validation loss: 2.911427515809254

Epoch: 5| Step: 3
Training loss: 3.033473253250122
Validation loss: 2.8792996688555648

Epoch: 5| Step: 4
Training loss: 2.8492729663848877
Validation loss: 2.8602782167414182

Epoch: 5| Step: 5
Training loss: 3.376741409301758
Validation loss: 2.811976553291403

Epoch: 5| Step: 6
Training loss: 2.675081491470337
Validation loss: 2.8098100308449037

Epoch: 5| Step: 7
Training loss: 3.094358444213867
Validation loss: 2.813963459384057

Epoch: 5| Step: 8
Training loss: 2.652909517288208
Validation loss: 2.779267567460255

Epoch: 5| Step: 9
Training loss: 2.2232794761657715
Validation loss: 2.7408909682304627

Epoch: 5| Step: 10
Training loss: 2.7119975090026855
Validation loss: 2.762008974629064

Epoch: 24| Step: 0
Training loss: 2.5031445026397705
Validation loss: 2.7340375813104774

Epoch: 5| Step: 1
Training loss: 2.9720733165740967
Validation loss: 2.738774686731318

Epoch: 5| Step: 2
Training loss: 2.515226364135742
Validation loss: 2.698640300381568

Epoch: 5| Step: 3
Training loss: 2.8202810287475586
Validation loss: 2.6903918712369856

Epoch: 5| Step: 4
Training loss: 2.3721065521240234
Validation loss: 2.6277177923469135

Epoch: 5| Step: 5
Training loss: 2.1476428508758545
Validation loss: 2.644995440718948

Epoch: 5| Step: 6
Training loss: 3.014975070953369
Validation loss: 2.6536113344213015

Epoch: 5| Step: 7
Training loss: 2.7977988719940186
Validation loss: 2.5793594698752127

Epoch: 5| Step: 8
Training loss: 2.5833969116210938
Validation loss: 2.587226560038905

Epoch: 5| Step: 9
Training loss: 3.6569550037384033
Validation loss: 2.577953807769283

Epoch: 5| Step: 10
Training loss: 3.29665470123291
Validation loss: 2.553684083364343

Epoch: 25| Step: 0
Training loss: 3.4144034385681152
Validation loss: 2.505409993151183

Epoch: 5| Step: 1
Training loss: 2.6416146755218506
Validation loss: 2.510102036178753

Epoch: 5| Step: 2
Training loss: 2.430830240249634
Validation loss: 2.5345531330313733

Epoch: 5| Step: 3
Training loss: 2.2177796363830566
Validation loss: 2.480346702760266

Epoch: 5| Step: 4
Training loss: 2.677574396133423
Validation loss: 2.494014691281062

Epoch: 5| Step: 5
Training loss: 2.6862709522247314
Validation loss: 2.4709552385473765

Epoch: 5| Step: 6
Training loss: 2.455156087875366
Validation loss: 2.4663459357394966

Epoch: 5| Step: 7
Training loss: 2.6603121757507324
Validation loss: 2.4598160892404537

Epoch: 5| Step: 8
Training loss: 2.3645567893981934
Validation loss: 2.447840647030902

Epoch: 5| Step: 9
Training loss: 2.688340425491333
Validation loss: 2.4317635028593

Epoch: 5| Step: 10
Training loss: 2.898042678833008
Validation loss: 2.3693317649185017

Epoch: 26| Step: 0
Training loss: 2.704516887664795
Validation loss: 2.4074453102645053

Epoch: 5| Step: 1
Training loss: 3.318845272064209
Validation loss: 2.3468868629906767

Epoch: 5| Step: 2
Training loss: 2.2747645378112793
Validation loss: 2.3830654005850516

Epoch: 5| Step: 3
Training loss: 2.9241936206817627
Validation loss: 2.3812381990494265

Epoch: 5| Step: 4
Training loss: 1.6852411031723022
Validation loss: 2.358410309719783

Epoch: 5| Step: 5
Training loss: 2.857268810272217
Validation loss: 2.3310337117923203

Epoch: 5| Step: 6
Training loss: 2.6095211505889893
Validation loss: 2.3389268485448693

Epoch: 5| Step: 7
Training loss: 2.7401840686798096
Validation loss: 2.3017184298525573

Epoch: 5| Step: 8
Training loss: 2.231492280960083
Validation loss: 2.326753911151681

Epoch: 5| Step: 9
Training loss: 2.841749668121338
Validation loss: 2.338747403954947

Epoch: 5| Step: 10
Training loss: 2.448211431503296
Validation loss: 2.2793932909606607

Epoch: 27| Step: 0
Training loss: 2.538881540298462
Validation loss: 2.2886887391408286

Epoch: 5| Step: 1
Training loss: 2.1364071369171143
Validation loss: 2.2483362382458103

Epoch: 5| Step: 2
Training loss: 2.1642396450042725
Validation loss: 2.2917568683624268

Epoch: 5| Step: 3
Training loss: 2.5875563621520996
Validation loss: 2.2470990534751647

Epoch: 5| Step: 4
Training loss: 2.5528383255004883
Validation loss: 2.233500680615825

Epoch: 5| Step: 5
Training loss: 2.756207227706909
Validation loss: 2.241886813153503

Epoch: 5| Step: 6
Training loss: 2.5729918479919434
Validation loss: 2.2111102970697547

Epoch: 5| Step: 7
Training loss: 2.974125623703003
Validation loss: 2.232171135564004

Epoch: 5| Step: 8
Training loss: 2.477505922317505
Validation loss: 2.216461052176773

Epoch: 5| Step: 9
Training loss: 2.6701502799987793
Validation loss: 2.2184773568184144

Epoch: 5| Step: 10
Training loss: 2.602884292602539
Validation loss: 2.215976749697039

Epoch: 28| Step: 0
Training loss: 2.2605233192443848
Validation loss: 2.205475822571785

Epoch: 5| Step: 1
Training loss: 2.3125739097595215
Validation loss: 2.1942395676848707

Epoch: 5| Step: 2
Training loss: 1.9174768924713135
Validation loss: 2.1672298190414265

Epoch: 5| Step: 3
Training loss: 2.2750792503356934
Validation loss: 2.253522524269678

Epoch: 5| Step: 4
Training loss: 2.691107988357544
Validation loss: 2.2323933647524927

Epoch: 5| Step: 5
Training loss: 2.995522975921631
Validation loss: 2.1969644972073135

Epoch: 5| Step: 6
Training loss: 1.9726965427398682
Validation loss: 2.182591558784567

Epoch: 5| Step: 7
Training loss: 3.115678310394287
Validation loss: 2.2108991069178425

Epoch: 5| Step: 8
Training loss: 2.479938507080078
Validation loss: 2.207070571120067

Epoch: 5| Step: 9
Training loss: 2.7725918292999268
Validation loss: 2.2440160243741927

Epoch: 5| Step: 10
Training loss: 2.666491985321045
Validation loss: 2.1843142445369432

Epoch: 29| Step: 0
Training loss: 2.962839126586914
Validation loss: 2.182817109169499

Epoch: 5| Step: 1
Training loss: 2.610305070877075
Validation loss: 2.1479289134343467

Epoch: 5| Step: 2
Training loss: 2.2020859718322754
Validation loss: 2.202493650938875

Epoch: 5| Step: 3
Training loss: 2.2909655570983887
Validation loss: 2.1711099660524757

Epoch: 5| Step: 4
Training loss: 2.5325329303741455
Validation loss: 2.1743081615817164

Epoch: 5| Step: 5
Training loss: 2.6427040100097656
Validation loss: 2.1733670632044473

Epoch: 5| Step: 6
Training loss: 2.2119946479797363
Validation loss: 2.1764501217872865

Epoch: 5| Step: 7
Training loss: 2.175537586212158
Validation loss: 2.121163591261833

Epoch: 5| Step: 8
Training loss: 2.818068504333496
Validation loss: 2.155646808685795

Epoch: 5| Step: 9
Training loss: 2.623908758163452
Validation loss: 2.1773524489454044

Epoch: 5| Step: 10
Training loss: 2.5237271785736084
Validation loss: 2.140657398008531

Epoch: 30| Step: 0
Training loss: 2.111116647720337
Validation loss: 2.163119718592654

Epoch: 5| Step: 1
Training loss: 2.6979141235351562
Validation loss: 2.137597627537225

Epoch: 5| Step: 2
Training loss: 2.303184986114502
Validation loss: 2.1586863533143075

Epoch: 5| Step: 3
Training loss: 2.406892776489258
Validation loss: 2.1103943470985658

Epoch: 5| Step: 4
Training loss: 2.3349132537841797
Validation loss: 2.1028450304462063

Epoch: 5| Step: 5
Training loss: 2.1829211711883545
Validation loss: 2.1864437544217674

Epoch: 5| Step: 6
Training loss: 3.1507484912872314
Validation loss: 2.15307512334598

Epoch: 5| Step: 7
Training loss: 2.4991869926452637
Validation loss: 2.132516109815208

Epoch: 5| Step: 8
Training loss: 1.7994067668914795
Validation loss: 2.1471773065546507

Epoch: 5| Step: 9
Training loss: 3.173619031906128
Validation loss: 2.1490084535332135

Epoch: 5| Step: 10
Training loss: 2.490039825439453
Validation loss: 2.1216188758932133

Epoch: 31| Step: 0
Training loss: 2.8010759353637695
Validation loss: 2.1340820058699577

Epoch: 5| Step: 1
Training loss: 3.4027023315429688
Validation loss: 2.141235900181596

Epoch: 5| Step: 2
Training loss: 2.485151767730713
Validation loss: 2.1479553971239316

Epoch: 5| Step: 3
Training loss: 2.464581251144409
Validation loss: 2.1603504201417327

Epoch: 5| Step: 4
Training loss: 2.3465323448181152
Validation loss: 2.201987845923311

Epoch: 5| Step: 5
Training loss: 2.4341487884521484
Validation loss: 2.097563651300246

Epoch: 5| Step: 6
Training loss: 2.1286203861236572
Validation loss: 2.18073171313091

Epoch: 5| Step: 7
Training loss: 2.0039758682250977
Validation loss: 2.132790632145379

Epoch: 5| Step: 8
Training loss: 2.0608887672424316
Validation loss: 2.156492489640431

Epoch: 5| Step: 9
Training loss: 2.7812256813049316
Validation loss: 2.0971801088702295

Epoch: 5| Step: 10
Training loss: 2.3962395191192627
Validation loss: 2.1371061263545865

Epoch: 32| Step: 0
Training loss: 1.7271465063095093
Validation loss: 2.137622200032716

Epoch: 5| Step: 1
Training loss: 3.540179491043091
Validation loss: 2.2197324383643364

Epoch: 5| Step: 2
Training loss: 2.044726848602295
Validation loss: 2.119009171762774

Epoch: 5| Step: 3
Training loss: 2.5078341960906982
Validation loss: 2.1524458213519027

Epoch: 5| Step: 4
Training loss: 2.4691078662872314
Validation loss: 2.2215860825712963

Epoch: 5| Step: 5
Training loss: 2.906127452850342
Validation loss: 2.1197908475834835

Epoch: 5| Step: 6
Training loss: 2.342510938644409
Validation loss: 2.080462032748807

Epoch: 5| Step: 7
Training loss: 2.77923583984375
Validation loss: 2.1677549013527493

Epoch: 5| Step: 8
Training loss: 1.975476861000061
Validation loss: 2.179049713637239

Epoch: 5| Step: 9
Training loss: 2.3549418449401855
Validation loss: 2.1375220129566808

Epoch: 5| Step: 10
Training loss: 2.8277621269226074
Validation loss: 2.0954671675159084

Epoch: 33| Step: 0
Training loss: 2.4856808185577393
Validation loss: 2.144047260284424

Epoch: 5| Step: 1
Training loss: 2.729665756225586
Validation loss: 2.1632066901012132

Epoch: 5| Step: 2
Training loss: 2.180981397628784
Validation loss: 2.130516900811144

Epoch: 5| Step: 3
Training loss: 2.456927537918091
Validation loss: 2.1203958911280476

Epoch: 5| Step: 4
Training loss: 2.890723705291748
Validation loss: 2.1121186030808317

Epoch: 5| Step: 5
Training loss: 2.7707152366638184
Validation loss: 2.101624522157895

Epoch: 5| Step: 6
Training loss: 2.6198837757110596
Validation loss: 2.102684631142565

Epoch: 5| Step: 7
Training loss: 1.9897632598876953
Validation loss: 2.1013351358393186

Epoch: 5| Step: 8
Training loss: 2.0772242546081543
Validation loss: 2.0862657126560005

Epoch: 5| Step: 9
Training loss: 2.653308629989624
Validation loss: 2.1409219285493255

Epoch: 5| Step: 10
Training loss: 2.2776691913604736
Validation loss: 2.1143168813438824

Epoch: 34| Step: 0
Training loss: 1.8623371124267578
Validation loss: 2.0607689260154642

Epoch: 5| Step: 1
Training loss: 2.2767977714538574
Validation loss: 2.1616260672128327

Epoch: 5| Step: 2
Training loss: 3.000413179397583
Validation loss: 2.1418660956044353

Epoch: 5| Step: 3
Training loss: 2.3123488426208496
Validation loss: 2.1688709194942186

Epoch: 5| Step: 4
Training loss: 2.340085983276367
Validation loss: 2.1075672026603454

Epoch: 5| Step: 5
Training loss: 3.046234130859375
Validation loss: 2.0938330542656685

Epoch: 5| Step: 6
Training loss: 2.6118416786193848
Validation loss: 2.0686134984416347

Epoch: 5| Step: 7
Training loss: 2.7191290855407715
Validation loss: 2.144701994875426

Epoch: 5| Step: 8
Training loss: 1.8239452838897705
Validation loss: 2.1681832626301754

Epoch: 5| Step: 9
Training loss: 2.3075547218322754
Validation loss: 2.120059564549436

Epoch: 5| Step: 10
Training loss: 2.4824607372283936
Validation loss: 2.1239650326390422

Epoch: 35| Step: 0
Training loss: 2.4678454399108887
Validation loss: 2.104599687360948

Epoch: 5| Step: 1
Training loss: 2.6266226768493652
Validation loss: 2.0920864894825923

Epoch: 5| Step: 2
Training loss: 2.7481777667999268
Validation loss: 2.118935941368021

Epoch: 5| Step: 3
Training loss: 2.260106325149536
Validation loss: 2.168801587115052

Epoch: 5| Step: 4
Training loss: 2.763171434402466
Validation loss: 2.0991872087601693

Epoch: 5| Step: 5
Training loss: 2.518629312515259
Validation loss: 2.083420007459579

Epoch: 5| Step: 6
Training loss: 2.131559133529663
Validation loss: 2.1600377585298274

Epoch: 5| Step: 7
Training loss: 2.8236024379730225
Validation loss: 2.104647518486105

Epoch: 5| Step: 8
Training loss: 2.455198287963867
Validation loss: 2.101205846314789

Epoch: 5| Step: 9
Training loss: 2.0749704837799072
Validation loss: 2.1101872203170613

Epoch: 5| Step: 10
Training loss: 2.2743961811065674
Validation loss: 2.113597636581749

Epoch: 36| Step: 0
Training loss: 2.5107100009918213
Validation loss: 2.1237073790642524

Epoch: 5| Step: 1
Training loss: 2.3517231941223145
Validation loss: 2.090306284607098

Epoch: 5| Step: 2
Training loss: 2.8452839851379395
Validation loss: 2.0421786872289514

Epoch: 5| Step: 3
Training loss: 3.0291898250579834
Validation loss: 2.081373276249055

Epoch: 5| Step: 4
Training loss: 1.9496475458145142
Validation loss: 2.122904359653432

Epoch: 5| Step: 5
Training loss: 1.8365795612335205
Validation loss: 2.1429701748714653

Epoch: 5| Step: 6
Training loss: 2.309030055999756
Validation loss: 2.1145617961883545

Epoch: 5| Step: 7
Training loss: 2.864513397216797
Validation loss: 2.1353892049481793

Epoch: 5| Step: 8
Training loss: 2.4465317726135254
Validation loss: 2.1361296369183447

Epoch: 5| Step: 9
Training loss: 2.449296236038208
Validation loss: 2.11925075387442

Epoch: 5| Step: 10
Training loss: 2.225205183029175
Validation loss: 2.1153099703532394

Epoch: 37| Step: 0
Training loss: 3.045003652572632
Validation loss: 2.1339211284473376

Epoch: 5| Step: 1
Training loss: 2.597600221633911
Validation loss: 2.146873653575938

Epoch: 5| Step: 2
Training loss: 1.6490898132324219
Validation loss: 2.1067048093324066

Epoch: 5| Step: 3
Training loss: 2.3150546550750732
Validation loss: 2.1223376874000794

Epoch: 5| Step: 4
Training loss: 2.5032553672790527
Validation loss: 2.095575183950445

Epoch: 5| Step: 5
Training loss: 2.598114013671875
Validation loss: 2.111836087319159

Epoch: 5| Step: 6
Training loss: 2.5468361377716064
Validation loss: 2.130955703796879

Epoch: 5| Step: 7
Training loss: 2.23327374458313
Validation loss: 2.1375590652547856

Epoch: 5| Step: 8
Training loss: 2.8590455055236816
Validation loss: 2.1359888558746665

Epoch: 5| Step: 9
Training loss: 2.6406607627868652
Validation loss: 2.129757824764457

Epoch: 5| Step: 10
Training loss: 2.05873966217041
Validation loss: 2.146915889555408

Epoch: 38| Step: 0
Training loss: 2.393476963043213
Validation loss: 2.1321250392544653

Epoch: 5| Step: 1
Training loss: 2.618054151535034
Validation loss: 2.1930426269449215

Epoch: 5| Step: 2
Training loss: 2.9278290271759033
Validation loss: 2.1181926496567263

Epoch: 5| Step: 3
Training loss: 2.9202685356140137
Validation loss: 2.12181056058535

Epoch: 5| Step: 4
Training loss: 2.277355670928955
Validation loss: 2.0936589010300173

Epoch: 5| Step: 5
Training loss: 3.0207974910736084
Validation loss: 2.160005769421977

Epoch: 5| Step: 6
Training loss: 1.8600289821624756
Validation loss: 2.144944921616585

Epoch: 5| Step: 7
Training loss: 2.73405122756958
Validation loss: 2.146433030405352

Epoch: 5| Step: 8
Training loss: 2.4652597904205322
Validation loss: 2.134322856062202

Epoch: 5| Step: 9
Training loss: 2.037841558456421
Validation loss: 2.1503204376466813

Epoch: 5| Step: 10
Training loss: 2.0699071884155273
Validation loss: 2.136850748010861

Epoch: 39| Step: 0
Training loss: 3.323028087615967
Validation loss: 2.0929168424298688

Epoch: 5| Step: 1
Training loss: 2.5753235816955566
Validation loss: 2.0972375792841755

Epoch: 5| Step: 2
Training loss: 2.398705244064331
Validation loss: 2.109145510581232

Epoch: 5| Step: 3
Training loss: 2.197880268096924
Validation loss: 2.0953739086786904

Epoch: 5| Step: 4
Training loss: 2.0243277549743652
Validation loss: 2.1352190368918964

Epoch: 5| Step: 5
Training loss: 1.9251785278320312
Validation loss: 2.136239864492929

Epoch: 5| Step: 6
Training loss: 2.640928030014038
Validation loss: 2.1154045699745097

Epoch: 5| Step: 7
Training loss: 2.215731620788574
Validation loss: 2.1572118036208616

Epoch: 5| Step: 8
Training loss: 2.428619861602783
Validation loss: 2.1144872788460023

Epoch: 5| Step: 9
Training loss: 2.6520233154296875
Validation loss: 2.09645406405131

Epoch: 5| Step: 10
Training loss: 2.422015428543091
Validation loss: 2.1531259782852663

Epoch: 40| Step: 0
Training loss: 2.196223020553589
Validation loss: 2.1787471771240234

Epoch: 5| Step: 1
Training loss: 2.7358391284942627
Validation loss: 2.111664936106692

Epoch: 5| Step: 2
Training loss: 2.513094425201416
Validation loss: 2.154807420187099

Epoch: 5| Step: 3
Training loss: 2.993962526321411
Validation loss: 2.111534341689079

Epoch: 5| Step: 4
Training loss: 2.244788408279419
Validation loss: 2.0873237989282094

Epoch: 5| Step: 5
Training loss: 2.331721544265747
Validation loss: 2.1428843557193713

Epoch: 5| Step: 6
Training loss: 1.6057014465332031
Validation loss: 2.087464742763068

Epoch: 5| Step: 7
Training loss: 2.318082571029663
Validation loss: 2.129069359071793

Epoch: 5| Step: 8
Training loss: 2.7926127910614014
Validation loss: 2.0969926926397506

Epoch: 5| Step: 9
Training loss: 2.6559109687805176
Validation loss: 2.1483303013668267

Epoch: 5| Step: 10
Training loss: 2.5293362140655518
Validation loss: 2.119790695046866

Epoch: 41| Step: 0
Training loss: 2.6647138595581055
Validation loss: 2.161045212899485

Epoch: 5| Step: 1
Training loss: 2.0637271404266357
Validation loss: 2.128595620073298

Epoch: 5| Step: 2
Training loss: 2.5197360515594482
Validation loss: 2.115303571506213

Epoch: 5| Step: 3
Training loss: 2.882471799850464
Validation loss: 2.1294917855211484

Epoch: 5| Step: 4
Training loss: 1.7833096981048584
Validation loss: 2.136375901519611

Epoch: 5| Step: 5
Training loss: 2.713627576828003
Validation loss: 2.121656617810649

Epoch: 5| Step: 6
Training loss: 1.9831453561782837
Validation loss: 2.15507399394948

Epoch: 5| Step: 7
Training loss: 2.6192879676818848
Validation loss: 2.0986928375818397

Epoch: 5| Step: 8
Training loss: 2.97640061378479
Validation loss: 2.0775712920773413

Epoch: 5| Step: 9
Training loss: 2.143017292022705
Validation loss: 2.1296287057220296

Epoch: 5| Step: 10
Training loss: 2.677661657333374
Validation loss: 2.1068195450690483

Epoch: 42| Step: 0
Training loss: 2.634984254837036
Validation loss: 2.0768632593975274

Epoch: 5| Step: 1
Training loss: 3.0418999195098877
Validation loss: 2.1492641459229174

Epoch: 5| Step: 2
Training loss: 1.9027239084243774
Validation loss: 2.0978996907511065

Epoch: 5| Step: 3
Training loss: 2.6919775009155273
Validation loss: 2.068123132310888

Epoch: 5| Step: 4
Training loss: 2.1179847717285156
Validation loss: 2.1159809661167923

Epoch: 5| Step: 5
Training loss: 2.2398345470428467
Validation loss: 2.088693029137068

Epoch: 5| Step: 6
Training loss: 2.5636935234069824
Validation loss: 2.1287474555353962

Epoch: 5| Step: 7
Training loss: 2.530390501022339
Validation loss: 2.1089219329177693

Epoch: 5| Step: 8
Training loss: 2.282801866531372
Validation loss: 2.0884386724041355

Epoch: 5| Step: 9
Training loss: 2.4907426834106445
Validation loss: 2.11509887121057

Epoch: 5| Step: 10
Training loss: 2.4175233840942383
Validation loss: 2.130354448031354

Epoch: 43| Step: 0
Training loss: 1.4339402914047241
Validation loss: 2.1578670829854985

Epoch: 5| Step: 1
Training loss: 2.1656365394592285
Validation loss: 2.107229863443682

Epoch: 5| Step: 2
Training loss: 2.8863730430603027
Validation loss: 2.136818447420674

Epoch: 5| Step: 3
Training loss: 1.7878572940826416
Validation loss: 2.124791088924613

Epoch: 5| Step: 4
Training loss: 2.278933048248291
Validation loss: 2.133664931020429

Epoch: 5| Step: 5
Training loss: 2.5378661155700684
Validation loss: 2.0932739716704174

Epoch: 5| Step: 6
Training loss: 3.0657031536102295
Validation loss: 2.1224349083439

Epoch: 5| Step: 7
Training loss: 3.077986478805542
Validation loss: 2.115624843105193

Epoch: 5| Step: 8
Training loss: 2.6889026165008545
Validation loss: 2.156840319274574

Epoch: 5| Step: 9
Training loss: 2.1720833778381348
Validation loss: 2.123408473947997

Epoch: 5| Step: 10
Training loss: 2.869976043701172
Validation loss: 2.0888375466869724

Epoch: 44| Step: 0
Training loss: 2.1763741970062256
Validation loss: 2.092847909978641

Epoch: 5| Step: 1
Training loss: 2.4044032096862793
Validation loss: 2.1795636479572584

Epoch: 5| Step: 2
Training loss: 2.4836032390594482
Validation loss: 2.158454953983266

Epoch: 5| Step: 3
Training loss: 2.607565402984619
Validation loss: 2.117169931370725

Epoch: 5| Step: 4
Training loss: 2.027223825454712
Validation loss: 2.121247499219833

Epoch: 5| Step: 5
Training loss: 2.37086820602417
Validation loss: 2.08444030310518

Epoch: 5| Step: 6
Training loss: 2.2655391693115234
Validation loss: 2.1225407354293333

Epoch: 5| Step: 7
Training loss: 3.225841999053955
Validation loss: 2.1588064675690024

Epoch: 5| Step: 8
Training loss: 2.233067274093628
Validation loss: 2.078880943277831

Epoch: 5| Step: 9
Training loss: 3.005854368209839
Validation loss: 2.1434076242549445

Epoch: 5| Step: 10
Training loss: 1.8609967231750488
Validation loss: 2.164740083038166

Epoch: 45| Step: 0
Training loss: 2.2241783142089844
Validation loss: 2.1006891855629544

Epoch: 5| Step: 1
Training loss: 2.5915920734405518
Validation loss: 2.122523207818308

Epoch: 5| Step: 2
Training loss: 2.0117199420928955
Validation loss: 2.160670562457013

Epoch: 5| Step: 3
Training loss: 2.786242961883545
Validation loss: 2.1562432089159564

Epoch: 5| Step: 4
Training loss: 2.281022548675537
Validation loss: 2.1627152478823097

Epoch: 5| Step: 5
Training loss: 2.5655550956726074
Validation loss: 2.1484310242437545

Epoch: 5| Step: 6
Training loss: 2.4153125286102295
Validation loss: 2.109613803125197

Epoch: 5| Step: 7
Training loss: 2.9274604320526123
Validation loss: 2.152161104704744

Epoch: 5| Step: 8
Training loss: 2.390193223953247
Validation loss: 2.1397451405884116

Epoch: 5| Step: 9
Training loss: 1.9251549243927002
Validation loss: 2.1640984576235534

Epoch: 5| Step: 10
Training loss: 2.518578052520752
Validation loss: 2.1607361737117974

Epoch: 46| Step: 0
Training loss: 3.2999768257141113
Validation loss: 2.1038803080076813

Epoch: 5| Step: 1
Training loss: 2.121260404586792
Validation loss: 2.129241387049357

Epoch: 5| Step: 2
Training loss: 2.367678642272949
Validation loss: 2.12860962652391

Epoch: 5| Step: 3
Training loss: 2.567814350128174
Validation loss: 2.122757737354566

Epoch: 5| Step: 4
Training loss: 2.499943256378174
Validation loss: 2.1490779717763266

Epoch: 5| Step: 5
Training loss: 2.991764783859253
Validation loss: 2.093256422268447

Epoch: 5| Step: 6
Training loss: 1.4709135293960571
Validation loss: 2.131272933816397

Epoch: 5| Step: 7
Training loss: 2.3877525329589844
Validation loss: 2.088803050338581

Epoch: 5| Step: 8
Training loss: 2.716602087020874
Validation loss: 2.136943478738108

Epoch: 5| Step: 9
Training loss: 2.4531776905059814
Validation loss: 2.135190607399069

Epoch: 5| Step: 10
Training loss: 2.026669502258301
Validation loss: 2.158202435380669

Epoch: 47| Step: 0
Training loss: 2.4726805686950684
Validation loss: 2.149803444903384

Epoch: 5| Step: 1
Training loss: 2.382514715194702
Validation loss: 2.1161473399849346

Epoch: 5| Step: 2
Training loss: 1.5211843252182007
Validation loss: 2.1514391399198964

Epoch: 5| Step: 3
Training loss: 2.7200584411621094
Validation loss: 2.130140337892758

Epoch: 5| Step: 4
Training loss: 2.828988790512085
Validation loss: 2.098538665361302

Epoch: 5| Step: 5
Training loss: 2.0600266456604004
Validation loss: 2.100677033906342

Epoch: 5| Step: 6
Training loss: 2.907413959503174
Validation loss: 2.1638645792520173

Epoch: 5| Step: 7
Training loss: 2.466204881668091
Validation loss: 2.1374327572443153

Epoch: 5| Step: 8
Training loss: 2.362234115600586
Validation loss: 2.0919905183135823

Epoch: 5| Step: 9
Training loss: 2.63906192779541
Validation loss: 2.1498270175790273

Epoch: 5| Step: 10
Training loss: 2.440134048461914
Validation loss: 2.084877606361143

Epoch: 48| Step: 0
Training loss: 2.6875884532928467
Validation loss: 2.083973066781157

Epoch: 5| Step: 1
Training loss: 2.5985372066497803
Validation loss: 2.1191823815786712

Epoch: 5| Step: 2
Training loss: 2.384066104888916
Validation loss: 2.0991549107336227

Epoch: 5| Step: 3
Training loss: 2.4584360122680664
Validation loss: 2.118017356882813

Epoch: 5| Step: 4
Training loss: 2.414032459259033
Validation loss: 2.141313232401366

Epoch: 5| Step: 5
Training loss: 2.6061530113220215
Validation loss: 2.104904149168281

Epoch: 5| Step: 6
Training loss: 2.6160874366760254
Validation loss: 2.0907726121205155

Epoch: 5| Step: 7
Training loss: 2.5162534713745117
Validation loss: 2.064948481898154

Epoch: 5| Step: 8
Training loss: 1.3575538396835327
Validation loss: 2.1112192676913355

Epoch: 5| Step: 9
Training loss: 2.4034159183502197
Validation loss: 2.1453120093191824

Epoch: 5| Step: 10
Training loss: 2.4792213439941406
Validation loss: 2.140165675070978

Epoch: 49| Step: 0
Training loss: 3.239839553833008
Validation loss: 2.0493836761802755

Epoch: 5| Step: 1
Training loss: 2.3692526817321777
Validation loss: 2.0908838779695573

Epoch: 5| Step: 2
Training loss: 2.391268253326416
Validation loss: 2.1224573658358667

Epoch: 5| Step: 3
Training loss: 2.1796395778656006
Validation loss: 2.0960439033405756

Epoch: 5| Step: 4
Training loss: 2.1048362255096436
Validation loss: 2.1080337750014437

Epoch: 5| Step: 5
Training loss: 2.4609365463256836
Validation loss: 2.1528056590787825

Epoch: 5| Step: 6
Training loss: 2.081526041030884
Validation loss: 2.110632960514356

Epoch: 5| Step: 7
Training loss: 2.64386248588562
Validation loss: 2.11294718967971

Epoch: 5| Step: 8
Training loss: 3.0232415199279785
Validation loss: 2.1141937163568314

Epoch: 5| Step: 9
Training loss: 2.1245017051696777
Validation loss: 2.1248334171951457

Epoch: 5| Step: 10
Training loss: 1.8390758037567139
Validation loss: 2.1100525407380957

Epoch: 50| Step: 0
Training loss: 2.233717918395996
Validation loss: 2.1056506710667766

Epoch: 5| Step: 1
Training loss: 3.0848755836486816
Validation loss: 2.1317524192153767

Epoch: 5| Step: 2
Training loss: 2.423269271850586
Validation loss: 2.0745846648370065

Epoch: 5| Step: 3
Training loss: 2.044276714324951
Validation loss: 2.15884800752004

Epoch: 5| Step: 4
Training loss: 2.3051421642303467
Validation loss: 2.096650549160537

Epoch: 5| Step: 5
Training loss: 2.6461479663848877
Validation loss: 2.127557244352115

Epoch: 5| Step: 6
Training loss: 2.286957263946533
Validation loss: 2.057957572321738

Epoch: 5| Step: 7
Training loss: 2.5286812782287598
Validation loss: 2.1033967195018644

Epoch: 5| Step: 8
Training loss: 2.4235358238220215
Validation loss: 2.0422914528077647

Epoch: 5| Step: 9
Training loss: 2.14302134513855
Validation loss: 2.0659799139986754

Epoch: 5| Step: 10
Training loss: 2.3373775482177734
Validation loss: 2.0475339889526367

Epoch: 51| Step: 0
Training loss: 2.525585889816284
Validation loss: 2.109713876119224

Epoch: 5| Step: 1
Training loss: 2.127098321914673
Validation loss: 2.077369113122263

Epoch: 5| Step: 2
Training loss: 2.4075260162353516
Validation loss: 2.1058037550218645

Epoch: 5| Step: 3
Training loss: 2.7956066131591797
Validation loss: 2.062744676425893

Epoch: 5| Step: 4
Training loss: 2.2327628135681152
Validation loss: 2.0865495563835226

Epoch: 5| Step: 5
Training loss: 2.9231576919555664
Validation loss: 2.100383335544217

Epoch: 5| Step: 6
Training loss: 2.4764201641082764
Validation loss: 2.1166537013105167

Epoch: 5| Step: 7
Training loss: 2.1415646076202393
Validation loss: 2.0311980144951933

Epoch: 5| Step: 8
Training loss: 2.5549988746643066
Validation loss: 2.136286271515713

Epoch: 5| Step: 9
Training loss: 2.343043088912964
Validation loss: 2.0934056312807146

Epoch: 5| Step: 10
Training loss: 1.9674952030181885
Validation loss: 2.083999563288945

Epoch: 52| Step: 0
Training loss: 2.431668519973755
Validation loss: 2.0537181438938266

Epoch: 5| Step: 1
Training loss: 2.7060461044311523
Validation loss: 2.118121685520295

Epoch: 5| Step: 2
Training loss: 2.6116268634796143
Validation loss: 2.1178683311708513

Epoch: 5| Step: 3
Training loss: 2.752609968185425
Validation loss: 2.1183502033192623

Epoch: 5| Step: 4
Training loss: 2.8192222118377686
Validation loss: 2.1293598528831237

Epoch: 5| Step: 5
Training loss: 1.8575000762939453
Validation loss: 2.0696789756897958

Epoch: 5| Step: 6
Training loss: 2.3359920978546143
Validation loss: 2.126807871685233

Epoch: 5| Step: 7
Training loss: 2.000811815261841
Validation loss: 2.142117507996098

Epoch: 5| Step: 8
Training loss: 1.9873911142349243
Validation loss: 2.1374448550644742

Epoch: 5| Step: 9
Training loss: 2.280592203140259
Validation loss: 2.0410400282952095

Epoch: 5| Step: 10
Training loss: 2.695058584213257
Validation loss: 2.145563130737633

Epoch: 53| Step: 0
Training loss: 2.8204827308654785
Validation loss: 2.110753300369427

Epoch: 5| Step: 1
Training loss: 2.143157482147217
Validation loss: 2.1022420929324244

Epoch: 5| Step: 2
Training loss: 2.0279626846313477
Validation loss: 2.1217119770665325

Epoch: 5| Step: 3
Training loss: 2.1089725494384766
Validation loss: 2.119555104163385

Epoch: 5| Step: 4
Training loss: 2.2799627780914307
Validation loss: 2.1603528838003836

Epoch: 5| Step: 5
Training loss: 2.7035701274871826
Validation loss: 2.131782467647265

Epoch: 5| Step: 6
Training loss: 2.324136257171631
Validation loss: 2.134182758228753

Epoch: 5| Step: 7
Training loss: 2.7465665340423584
Validation loss: 2.086598421937676

Epoch: 5| Step: 8
Training loss: 2.6910908222198486
Validation loss: 2.1157497590587986

Epoch: 5| Step: 9
Training loss: 1.9569482803344727
Validation loss: 2.073182867419335

Epoch: 5| Step: 10
Training loss: 2.3899831771850586
Validation loss: 2.0961629036934144

Epoch: 54| Step: 0
Training loss: 2.353771448135376
Validation loss: 2.0694044495141632

Epoch: 5| Step: 1
Training loss: 2.2238659858703613
Validation loss: 2.1225621725923274

Epoch: 5| Step: 2
Training loss: 2.585202932357788
Validation loss: 2.109551193893597

Epoch: 5| Step: 3
Training loss: 2.777780771255493
Validation loss: 2.0277246070164505

Epoch: 5| Step: 4
Training loss: 2.0767836570739746
Validation loss: 2.096842837590043

Epoch: 5| Step: 5
Training loss: 2.384556293487549
Validation loss: 2.0541807169555337

Epoch: 5| Step: 6
Training loss: 2.3998966217041016
Validation loss: 2.0877118213202364

Epoch: 5| Step: 7
Training loss: 2.489920139312744
Validation loss: 2.0969471264910955

Epoch: 5| Step: 8
Training loss: 1.8959972858428955
Validation loss: 2.1028061630905315

Epoch: 5| Step: 9
Training loss: 2.4095616340637207
Validation loss: 2.0667310171229865

Epoch: 5| Step: 10
Training loss: 2.4551663398742676
Validation loss: 2.066861257758192

Epoch: 55| Step: 0
Training loss: 2.2282283306121826
Validation loss: 2.056001892653845

Epoch: 5| Step: 1
Training loss: 2.6361472606658936
Validation loss: 2.058210426761258

Epoch: 5| Step: 2
Training loss: 2.4668190479278564
Validation loss: 2.116714019929209

Epoch: 5| Step: 3
Training loss: 2.754556179046631
Validation loss: 2.063828368340769

Epoch: 5| Step: 4
Training loss: 2.819427013397217
Validation loss: 2.1018906601013674

Epoch: 5| Step: 5
Training loss: 2.8824305534362793
Validation loss: 2.098050502038771

Epoch: 5| Step: 6
Training loss: 2.5438272953033447
Validation loss: 2.0801320819444555

Epoch: 5| Step: 7
Training loss: 1.5367062091827393
Validation loss: 2.084617284036452

Epoch: 5| Step: 8
Training loss: 2.1404709815979004
Validation loss: 2.0733231857258785

Epoch: 5| Step: 9
Training loss: 1.6444110870361328
Validation loss: 2.076553395999375

Epoch: 5| Step: 10
Training loss: 2.595817804336548
Validation loss: 2.102214741450484

Epoch: 56| Step: 0
Training loss: 2.281860828399658
Validation loss: 2.1422931173796296

Epoch: 5| Step: 1
Training loss: 2.3533082008361816
Validation loss: 2.0905808710282847

Epoch: 5| Step: 2
Training loss: 3.1313767433166504
Validation loss: 2.13204465886598

Epoch: 5| Step: 3
Training loss: 2.389191150665283
Validation loss: 2.132037624236076

Epoch: 5| Step: 4
Training loss: 1.9508107900619507
Validation loss: 2.0429578673455024

Epoch: 5| Step: 5
Training loss: 2.363039970397949
Validation loss: 2.0556063421310915

Epoch: 5| Step: 6
Training loss: 2.554189682006836
Validation loss: 2.085045950387114

Epoch: 5| Step: 7
Training loss: 1.8932186365127563
Validation loss: 2.0685953606841383

Epoch: 5| Step: 8
Training loss: 2.7064623832702637
Validation loss: 2.0664673748836724

Epoch: 5| Step: 9
Training loss: 2.148068904876709
Validation loss: 2.122307332613135

Epoch: 5| Step: 10
Training loss: 2.3411359786987305
Validation loss: 2.058059287327592

Epoch: 57| Step: 0
Training loss: 2.0919289588928223
Validation loss: 2.0879138297932123

Epoch: 5| Step: 1
Training loss: 3.1146044731140137
Validation loss: 2.050877965906615

Epoch: 5| Step: 2
Training loss: 3.167750835418701
Validation loss: 2.077898952268785

Epoch: 5| Step: 3
Training loss: 1.5263559818267822
Validation loss: 2.0946375426425727

Epoch: 5| Step: 4
Training loss: 2.3980813026428223
Validation loss: 2.053739913048283

Epoch: 5| Step: 5
Training loss: 1.7828805446624756
Validation loss: 2.101425720799354

Epoch: 5| Step: 6
Training loss: 2.599205255508423
Validation loss: 2.096790688012236

Epoch: 5| Step: 7
Training loss: 2.3916001319885254
Validation loss: 2.1149605012709096

Epoch: 5| Step: 8
Training loss: 2.094054698944092
Validation loss: 2.103351769908782

Epoch: 5| Step: 9
Training loss: 2.1760926246643066
Validation loss: 2.1262559147291284

Epoch: 5| Step: 10
Training loss: 2.6801960468292236
Validation loss: 2.053523591769639

Epoch: 58| Step: 0
Training loss: 2.416341781616211
Validation loss: 2.1086434113082064

Epoch: 5| Step: 1
Training loss: 2.3224964141845703
Validation loss: 2.0773216447522564

Epoch: 5| Step: 2
Training loss: 2.1766934394836426
Validation loss: 2.0939678850994317

Epoch: 5| Step: 3
Training loss: 2.838205337524414
Validation loss: 2.01078131762884

Epoch: 5| Step: 4
Training loss: 2.3182029724121094
Validation loss: 2.093139015218263

Epoch: 5| Step: 5
Training loss: 2.7477951049804688
Validation loss: 2.0892617241028817

Epoch: 5| Step: 6
Training loss: 1.876936674118042
Validation loss: 2.141724181431596

Epoch: 5| Step: 7
Training loss: 2.2599055767059326
Validation loss: 2.064653017187631

Epoch: 5| Step: 8
Training loss: 2.093590259552002
Validation loss: 2.054850237343901

Epoch: 5| Step: 9
Training loss: 2.465012311935425
Validation loss: 2.0751870088679816

Epoch: 5| Step: 10
Training loss: 2.361429452896118
Validation loss: 2.0967058943163965

Epoch: 59| Step: 0
Training loss: 2.51708984375
Validation loss: 2.1103028943461757

Epoch: 5| Step: 1
Training loss: 2.3995399475097656
Validation loss: 2.0639213156956497

Epoch: 5| Step: 2
Training loss: 2.711893081665039
Validation loss: 2.1118319508849934

Epoch: 5| Step: 3
Training loss: 2.392378330230713
Validation loss: 2.102910440455201

Epoch: 5| Step: 4
Training loss: 2.108715057373047
Validation loss: 2.0573686630495134

Epoch: 5| Step: 5
Training loss: 2.419613838195801
Validation loss: 2.1118212643490044

Epoch: 5| Step: 6
Training loss: 2.393477201461792
Validation loss: 2.0972527470639957

Epoch: 5| Step: 7
Training loss: 2.893223524093628
Validation loss: 2.091307414475308

Epoch: 5| Step: 8
Training loss: 2.045982837677002
Validation loss: 2.124131251406926

Epoch: 5| Step: 9
Training loss: 1.8513774871826172
Validation loss: 2.077427380828447

Epoch: 5| Step: 10
Training loss: 2.4991180896759033
Validation loss: 2.0738637037174676

Epoch: 60| Step: 0
Training loss: 2.46606183052063
Validation loss: 2.0202174750707482

Epoch: 5| Step: 1
Training loss: 1.6210546493530273
Validation loss: 2.066749270244311

Epoch: 5| Step: 2
Training loss: 2.421081304550171
Validation loss: 2.076180896451396

Epoch: 5| Step: 3
Training loss: 2.36112642288208
Validation loss: 2.07732500824877

Epoch: 5| Step: 4
Training loss: 2.3773770332336426
Validation loss: 2.0855502005546325

Epoch: 5| Step: 5
Training loss: 2.413356304168701
Validation loss: 2.090272068977356

Epoch: 5| Step: 6
Training loss: 3.051487445831299
Validation loss: 2.0546794527320453

Epoch: 5| Step: 7
Training loss: 2.2626876831054688
Validation loss: 2.0733478376942296

Epoch: 5| Step: 8
Training loss: 2.658224105834961
Validation loss: 2.069047189527942

Epoch: 5| Step: 9
Training loss: 2.302452325820923
Validation loss: 2.0563387255514822

Epoch: 5| Step: 10
Training loss: 2.4132261276245117
Validation loss: 2.064971295736169

Epoch: 61| Step: 0
Training loss: 2.262856960296631
Validation loss: 2.067918105791974

Epoch: 5| Step: 1
Training loss: 2.7571053504943848
Validation loss: 2.0269554994439565

Epoch: 5| Step: 2
Training loss: 2.5414183139801025
Validation loss: 2.068224847957652

Epoch: 5| Step: 3
Training loss: 2.8984105587005615
Validation loss: 2.1067364561942314

Epoch: 5| Step: 4
Training loss: 2.2340612411499023
Validation loss: 2.1128103938153995

Epoch: 5| Step: 5
Training loss: 1.7380459308624268
Validation loss: 2.0214946949353783

Epoch: 5| Step: 6
Training loss: 2.3494205474853516
Validation loss: 2.0247853975142203

Epoch: 5| Step: 7
Training loss: 2.028451442718506
Validation loss: 2.071480865119606

Epoch: 5| Step: 8
Training loss: 2.688629150390625
Validation loss: 2.0777024556231756

Epoch: 5| Step: 9
Training loss: 2.33096981048584
Validation loss: 2.059817990949077

Epoch: 5| Step: 10
Training loss: 1.8201240301132202
Validation loss: 2.0704397411756617

Epoch: 62| Step: 0
Training loss: 2.332113265991211
Validation loss: 2.025092256966458

Epoch: 5| Step: 1
Training loss: 2.6959338188171387
Validation loss: 2.080105627736738

Epoch: 5| Step: 2
Training loss: 2.2813620567321777
Validation loss: 2.031973978524567

Epoch: 5| Step: 3
Training loss: 2.7624118328094482
Validation loss: 2.08973257259656

Epoch: 5| Step: 4
Training loss: 2.9609971046447754
Validation loss: 2.0611054141034364

Epoch: 5| Step: 5
Training loss: 2.280968427658081
Validation loss: 2.0402433718404462

Epoch: 5| Step: 6
Training loss: 2.2138283252716064
Validation loss: 2.07540100877003

Epoch: 5| Step: 7
Training loss: 2.2575271129608154
Validation loss: 2.079929531261485

Epoch: 5| Step: 8
Training loss: 2.3965344429016113
Validation loss: 2.1190055416476343

Epoch: 5| Step: 9
Training loss: 1.8435043096542358
Validation loss: 2.0749044059425272

Epoch: 5| Step: 10
Training loss: 2.2257895469665527
Validation loss: 2.078835871911818

Epoch: 63| Step: 0
Training loss: 2.5057520866394043
Validation loss: 2.0862453035129014

Epoch: 5| Step: 1
Training loss: 2.9460320472717285
Validation loss: 2.0464917921250865

Epoch: 5| Step: 2
Training loss: 2.2699263095855713
Validation loss: 2.122071612265802

Epoch: 5| Step: 3
Training loss: 2.4112391471862793
Validation loss: 2.0508310679466493

Epoch: 5| Step: 4
Training loss: 2.1102511882781982
Validation loss: 2.073540496569808

Epoch: 5| Step: 5
Training loss: 2.649864435195923
Validation loss: 2.1149700457049954

Epoch: 5| Step: 6
Training loss: 2.4692389965057373
Validation loss: 2.054367733258073

Epoch: 5| Step: 7
Training loss: 2.4663965702056885
Validation loss: 2.083243557201919

Epoch: 5| Step: 8
Training loss: 2.18253231048584
Validation loss: 2.0527524332846365

Epoch: 5| Step: 9
Training loss: 2.6902384757995605
Validation loss: 2.0340319500174573

Epoch: 5| Step: 10
Training loss: 1.5839704275131226
Validation loss: 2.0610697705258607

Epoch: 64| Step: 0
Training loss: 1.7447497844696045
Validation loss: 2.034365036154306

Epoch: 5| Step: 1
Training loss: 2.1948342323303223
Validation loss: 2.0581995774340887

Epoch: 5| Step: 2
Training loss: 3.0914199352264404
Validation loss: 2.0267910021607594

Epoch: 5| Step: 3
Training loss: 2.640930414199829
Validation loss: 2.0804282311470277

Epoch: 5| Step: 4
Training loss: 1.9149293899536133
Validation loss: 2.1021408188727593

Epoch: 5| Step: 5
Training loss: 2.298356771469116
Validation loss: 2.044620804889228

Epoch: 5| Step: 6
Training loss: 2.2117931842803955
Validation loss: 2.0784489967489757

Epoch: 5| Step: 7
Training loss: 2.350496292114258
Validation loss: 2.1429575822686635

Epoch: 5| Step: 8
Training loss: 2.8601670265197754
Validation loss: 2.0697558285087667

Epoch: 5| Step: 9
Training loss: 2.6007912158966064
Validation loss: 2.0425307673792683

Epoch: 5| Step: 10
Training loss: 2.2958762645721436
Validation loss: 2.081718656324571

Epoch: 65| Step: 0
Training loss: 2.5259737968444824
Validation loss: 2.051481585348806

Epoch: 5| Step: 1
Training loss: 1.7029945850372314
Validation loss: 2.1231406068289154

Epoch: 5| Step: 2
Training loss: 2.672147035598755
Validation loss: 2.122670663300381

Epoch: 5| Step: 3
Training loss: 1.7673536539077759
Validation loss: 2.0931869399163032

Epoch: 5| Step: 4
Training loss: 2.0338637828826904
Validation loss: 2.050657974776401

Epoch: 5| Step: 5
Training loss: 2.328387975692749
Validation loss: 2.070470586899788

Epoch: 5| Step: 6
Training loss: 2.1306610107421875
Validation loss: 2.0954229754786335

Epoch: 5| Step: 7
Training loss: 2.2207190990448
Validation loss: 2.050562636826628

Epoch: 5| Step: 8
Training loss: 3.299715042114258
Validation loss: 2.079260728692496

Epoch: 5| Step: 9
Training loss: 2.744417667388916
Validation loss: 2.0936256621473577

Epoch: 5| Step: 10
Training loss: 2.3833935260772705
Validation loss: 2.0244370814292663

Epoch: 66| Step: 0
Training loss: 2.439842939376831
Validation loss: 2.0786607239836004

Epoch: 5| Step: 1
Training loss: 1.8479477167129517
Validation loss: 2.059830152860252

Epoch: 5| Step: 2
Training loss: 2.0125746726989746
Validation loss: 2.1138293589315107

Epoch: 5| Step: 3
Training loss: 2.41882586479187
Validation loss: 2.0691101653601534

Epoch: 5| Step: 4
Training loss: 2.640313148498535
Validation loss: 2.11880297558282

Epoch: 5| Step: 5
Training loss: 2.4112586975097656
Validation loss: 2.1132795861972276

Epoch: 5| Step: 6
Training loss: 1.6567939519882202
Validation loss: 2.059076924477854

Epoch: 5| Step: 7
Training loss: 2.808239698410034
Validation loss: 2.134177506610911

Epoch: 5| Step: 8
Training loss: 2.55470871925354
Validation loss: 2.1335984840187976

Epoch: 5| Step: 9
Training loss: 3.0208468437194824
Validation loss: 2.0567696043240127

Epoch: 5| Step: 10
Training loss: 2.2031424045562744
Validation loss: 2.0466469257108626

Epoch: 67| Step: 0
Training loss: 3.5964508056640625
Validation loss: 2.078473255198489

Epoch: 5| Step: 1
Training loss: 2.4541361331939697
Validation loss: 2.148228047996439

Epoch: 5| Step: 2
Training loss: 1.6978938579559326
Validation loss: 2.076325770347349

Epoch: 5| Step: 3
Training loss: 2.4243786334991455
Validation loss: 2.073011759788759

Epoch: 5| Step: 4
Training loss: 2.0077807903289795
Validation loss: 2.0607004780923166

Epoch: 5| Step: 5
Training loss: 2.235028028488159
Validation loss: 2.154317558452647

Epoch: 5| Step: 6
Training loss: 2.9389967918395996
Validation loss: 2.0806950061551985

Epoch: 5| Step: 7
Training loss: 2.0215625762939453
Validation loss: 2.084729640714584

Epoch: 5| Step: 8
Training loss: 1.9143695831298828
Validation loss: 2.0863473569193194

Epoch: 5| Step: 9
Training loss: 2.194411039352417
Validation loss: 2.041432742149599

Epoch: 5| Step: 10
Training loss: 2.590679883956909
Validation loss: 2.0904741210322224

Epoch: 68| Step: 0
Training loss: 2.207022190093994
Validation loss: 2.0266019964730866

Epoch: 5| Step: 1
Training loss: 2.2590954303741455
Validation loss: 2.077527229503919

Epoch: 5| Step: 2
Training loss: 1.953482985496521
Validation loss: 2.0484580788561093

Epoch: 5| Step: 3
Training loss: 2.4001102447509766
Validation loss: 2.086038399768132

Epoch: 5| Step: 4
Training loss: 1.9492580890655518
Validation loss: 2.0417691635829147

Epoch: 5| Step: 5
Training loss: 3.3343780040740967
Validation loss: 2.0967320114053707

Epoch: 5| Step: 6
Training loss: 2.479583740234375
Validation loss: 2.086259675282304

Epoch: 5| Step: 7
Training loss: 2.2772839069366455
Validation loss: 2.0880507269213275

Epoch: 5| Step: 8
Training loss: 2.7689292430877686
Validation loss: 2.120697375266783

Epoch: 5| Step: 9
Training loss: 2.5780794620513916
Validation loss: 2.057525219455842

Epoch: 5| Step: 10
Training loss: 1.6045492887496948
Validation loss: 2.0386678980242823

Epoch: 69| Step: 0
Training loss: 2.1760761737823486
Validation loss: 2.108910245280112

Epoch: 5| Step: 1
Training loss: 2.5120482444763184
Validation loss: 2.0442189606287147

Epoch: 5| Step: 2
Training loss: 2.3614368438720703
Validation loss: 2.10217046994035

Epoch: 5| Step: 3
Training loss: 2.1508326530456543
Validation loss: 2.09215602695301

Epoch: 5| Step: 4
Training loss: 2.90617036819458
Validation loss: 2.0984728285061416

Epoch: 5| Step: 5
Training loss: 1.9308452606201172
Validation loss: 2.0845440562053392

Epoch: 5| Step: 6
Training loss: 2.371812343597412
Validation loss: 2.0832701319007465

Epoch: 5| Step: 7
Training loss: 2.2312114238739014
Validation loss: 2.1060046508748043

Epoch: 5| Step: 8
Training loss: 2.395413637161255
Validation loss: 2.049645568734856

Epoch: 5| Step: 9
Training loss: 2.4933393001556396
Validation loss: 2.1026451792768253

Epoch: 5| Step: 10
Training loss: 2.845710515975952
Validation loss: 2.1003762650233444

Epoch: 70| Step: 0
Training loss: 2.337127447128296
Validation loss: 2.1197689502469954

Epoch: 5| Step: 1
Training loss: 1.852652907371521
Validation loss: 2.095310929001019

Epoch: 5| Step: 2
Training loss: 2.8985767364501953
Validation loss: 2.0798317258076002

Epoch: 5| Step: 3
Training loss: 2.810960054397583
Validation loss: 2.0853377952370593

Epoch: 5| Step: 4
Training loss: 2.0825533866882324
Validation loss: 2.0743635008412022

Epoch: 5| Step: 5
Training loss: 2.1857211589813232
Validation loss: 2.104864666538854

Epoch: 5| Step: 6
Training loss: 2.4587440490722656
Validation loss: 2.0989802101606965

Epoch: 5| Step: 7
Training loss: 2.235572099685669
Validation loss: 2.100780753679173

Epoch: 5| Step: 8
Training loss: 2.7555365562438965
Validation loss: 2.1171471534236783

Epoch: 5| Step: 9
Training loss: 2.043466567993164
Validation loss: 2.085625566462035

Epoch: 5| Step: 10
Training loss: 2.2909741401672363
Validation loss: 2.077329074182818

Epoch: 71| Step: 0
Training loss: 2.0243515968322754
Validation loss: 2.075368488988569

Epoch: 5| Step: 1
Training loss: 1.986100196838379
Validation loss: 2.0712309934759654

Epoch: 5| Step: 2
Training loss: 2.3723344802856445
Validation loss: 2.06418804840375

Epoch: 5| Step: 3
Training loss: 2.8343684673309326
Validation loss: 2.069974628827905

Epoch: 5| Step: 4
Training loss: 2.6471331119537354
Validation loss: 2.100681015240249

Epoch: 5| Step: 5
Training loss: 2.5476157665252686
Validation loss: 2.071323443484563

Epoch: 5| Step: 6
Training loss: 2.2603917121887207
Validation loss: 2.0827267605771302

Epoch: 5| Step: 7
Training loss: 2.042726993560791
Validation loss: 2.041295679666663

Epoch: 5| Step: 8
Training loss: 2.3563177585601807
Validation loss: 2.106261499466435

Epoch: 5| Step: 9
Training loss: 2.360968828201294
Validation loss: 2.0823066952408

Epoch: 5| Step: 10
Training loss: 2.4260473251342773
Validation loss: 2.06140503832089

Epoch: 72| Step: 0
Training loss: 2.2685630321502686
Validation loss: 2.0823332494305027

Epoch: 5| Step: 1
Training loss: 2.262995719909668
Validation loss: 2.054810831623693

Epoch: 5| Step: 2
Training loss: 3.0826659202575684
Validation loss: 2.031735853482318

Epoch: 5| Step: 3
Training loss: 2.4447784423828125
Validation loss: 2.010535029954808

Epoch: 5| Step: 4
Training loss: 2.837618589401245
Validation loss: 2.0951088961734565

Epoch: 5| Step: 5
Training loss: 1.8032455444335938
Validation loss: 2.1004098743520756

Epoch: 5| Step: 6
Training loss: 2.390664577484131
Validation loss: 2.0812181529178413

Epoch: 5| Step: 7
Training loss: 2.101534605026245
Validation loss: 2.114023349618399

Epoch: 5| Step: 8
Training loss: 2.5830464363098145
Validation loss: 2.0753223998572237

Epoch: 5| Step: 9
Training loss: 2.6487808227539062
Validation loss: 2.0666014840525966

Epoch: 5| Step: 10
Training loss: 1.4240922927856445
Validation loss: 2.0862657485469693

Epoch: 73| Step: 0
Training loss: 2.668768882751465
Validation loss: 2.0854872708679526

Epoch: 5| Step: 1
Training loss: 2.4577548503875732
Validation loss: 2.107124409367961

Epoch: 5| Step: 2
Training loss: 2.0008955001831055
Validation loss: 2.071425114908526

Epoch: 5| Step: 3
Training loss: 2.081357002258301
Validation loss: 2.081014697269727

Epoch: 5| Step: 4
Training loss: 2.4662928581237793
Validation loss: 2.085422620978407

Epoch: 5| Step: 5
Training loss: 2.1779887676239014
Validation loss: 2.0934365436594975

Epoch: 5| Step: 6
Training loss: 2.185502529144287
Validation loss: 2.044339736302694

Epoch: 5| Step: 7
Training loss: 2.175295352935791
Validation loss: 2.0740193218313236

Epoch: 5| Step: 8
Training loss: 2.0244052410125732
Validation loss: 2.0542513401277605

Epoch: 5| Step: 9
Training loss: 2.8891429901123047
Validation loss: 2.0713271325634373

Epoch: 5| Step: 10
Training loss: 3.082517623901367
Validation loss: 1.9873586162444083

Epoch: 74| Step: 0
Training loss: 2.4088971614837646
Validation loss: 2.0603879036441928

Epoch: 5| Step: 1
Training loss: 2.0673468112945557
Validation loss: 2.062440759392195

Epoch: 5| Step: 2
Training loss: 2.1386656761169434
Validation loss: 2.0245944838370047

Epoch: 5| Step: 3
Training loss: 3.421988010406494
Validation loss: 2.0125030356068767

Epoch: 5| Step: 4
Training loss: 2.1602847576141357
Validation loss: 2.061423493969825

Epoch: 5| Step: 5
Training loss: 2.0489485263824463
Validation loss: 2.0400827046363585

Epoch: 5| Step: 6
Training loss: 1.8491716384887695
Validation loss: 2.076909360065255

Epoch: 5| Step: 7
Training loss: 2.7148900032043457
Validation loss: 2.0110897210336502

Epoch: 5| Step: 8
Training loss: 2.3730554580688477
Validation loss: 2.0482837230928483

Epoch: 5| Step: 9
Training loss: 2.8675708770751953
Validation loss: 2.037010810708487

Epoch: 5| Step: 10
Training loss: 1.8610244989395142
Validation loss: 2.0774825311476186

Epoch: 75| Step: 0
Training loss: 2.2064614295959473
Validation loss: 2.039902517872472

Epoch: 5| Step: 1
Training loss: 2.5480833053588867
Validation loss: 2.1084930127666843

Epoch: 5| Step: 2
Training loss: 2.2512354850769043
Validation loss: 2.0608474926282

Epoch: 5| Step: 3
Training loss: 2.052165985107422
Validation loss: 2.062072374487436

Epoch: 5| Step: 4
Training loss: 2.2328600883483887
Validation loss: 2.058065757956556

Epoch: 5| Step: 5
Training loss: 2.633265972137451
Validation loss: 2.104364836087791

Epoch: 5| Step: 6
Training loss: 3.15181040763855
Validation loss: 2.0266327729789158

Epoch: 5| Step: 7
Training loss: 2.0781121253967285
Validation loss: 1.9973274994921941

Epoch: 5| Step: 8
Training loss: 1.5492467880249023
Validation loss: 2.0833341677983603

Epoch: 5| Step: 9
Training loss: 2.4497950077056885
Validation loss: 2.080055840553776

Epoch: 5| Step: 10
Training loss: 2.7537593841552734
Validation loss: 2.1174083858407955

Testing loss: 2.0053532918294272
