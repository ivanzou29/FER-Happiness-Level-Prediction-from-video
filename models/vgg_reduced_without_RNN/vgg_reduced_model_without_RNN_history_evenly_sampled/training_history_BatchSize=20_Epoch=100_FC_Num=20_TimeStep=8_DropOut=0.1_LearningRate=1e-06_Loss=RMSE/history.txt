Epoch: 1| Step: 0
Training loss: 7.994908858609378
Validation loss: 7.975791347260462

Epoch: 5| Step: 1
Training loss: 8.050420657711824
Validation loss: 7.97418209704583

Epoch: 5| Step: 2
Training loss: 9.294929057112691
Validation loss: 7.974683455444108

Epoch: 5| Step: 3
Training loss: 8.261138794655995
Validation loss: 7.974226653225511

Epoch: 5| Step: 4
Training loss: 7.711686211039016
Validation loss: 7.96942916893797

Epoch: 5| Step: 5
Training loss: 7.24167128351706
Validation loss: 7.969571645522841

Epoch: 5| Step: 6
Training loss: 7.4674947154610996
Validation loss: 7.966074463457417

Epoch: 5| Step: 7
Training loss: 7.384474794259951
Validation loss: 7.966289371833109

Epoch: 5| Step: 8
Training loss: 7.528680513439092
Validation loss: 7.96410564060767

Epoch: 5| Step: 9
Training loss: 7.781398541974506
Validation loss: 7.964499270038456

Epoch: 5| Step: 10
Training loss: 8.409178723525812
Validation loss: 7.962108872504988

Epoch: 2| Step: 0
Training loss: 9.178371747459911
Validation loss: 7.95919262057286

Epoch: 5| Step: 1
Training loss: 7.449685508695437
Validation loss: 7.958760703677289

Epoch: 5| Step: 2
Training loss: 7.94127727353147
Validation loss: 7.95865275815678

Epoch: 5| Step: 3
Training loss: 8.53672352243735
Validation loss: 7.954964387961087

Epoch: 5| Step: 4
Training loss: 7.191692158052332
Validation loss: 7.955069194396422

Epoch: 5| Step: 5
Training loss: 7.070853365448461
Validation loss: 7.951960278782718

Epoch: 5| Step: 6
Training loss: 8.509912433106502
Validation loss: 7.950483920960595

Epoch: 5| Step: 7
Training loss: 7.475770595469991
Validation loss: 7.947339955165265

Epoch: 5| Step: 8
Training loss: 8.710864804909674
Validation loss: 7.947463026924692

Epoch: 5| Step: 9
Training loss: 7.207486964758797
Validation loss: 7.9457315349430555

Epoch: 5| Step: 10
Training loss: 7.402416927408743
Validation loss: 7.943393492428668

Epoch: 3| Step: 0
Training loss: 7.024682805512745
Validation loss: 7.939275334878143

Epoch: 5| Step: 1
Training loss: 7.477008164535418
Validation loss: 7.9394689573627995

Epoch: 5| Step: 2
Training loss: 7.761561230393941
Validation loss: 7.935881749691573

Epoch: 5| Step: 3
Training loss: 7.765434892196406
Validation loss: 7.933915272925371

Epoch: 5| Step: 4
Training loss: 8.042420452413467
Validation loss: 7.932641474225841

Epoch: 5| Step: 5
Training loss: 8.386144255038104
Validation loss: 7.930135467741478

Epoch: 5| Step: 6
Training loss: 8.199351810795015
Validation loss: 7.927388005650593

Epoch: 5| Step: 7
Training loss: 8.139561677045858
Validation loss: 7.923682944178852

Epoch: 5| Step: 8
Training loss: 7.530016532970987
Validation loss: 7.923612774177496

Epoch: 5| Step: 9
Training loss: 7.600785124530054
Validation loss: 7.921689915726347

Epoch: 5| Step: 10
Training loss: 8.89741157867236
Validation loss: 7.9176801057676665

Epoch: 4| Step: 0
Training loss: 7.026519133281506
Validation loss: 7.915320733966965

Epoch: 5| Step: 1
Training loss: 8.45782689675248
Validation loss: 7.912367843874449

Epoch: 5| Step: 2
Training loss: 7.315613434337157
Validation loss: 7.9087088397645715

Epoch: 5| Step: 3
Training loss: 8.124822526607408
Validation loss: 7.905755570980611

Epoch: 5| Step: 4
Training loss: 8.205522343143556
Validation loss: 7.9043583193904485

Epoch: 5| Step: 5
Training loss: 7.299745570935375
Validation loss: 7.899450838133105

Epoch: 5| Step: 6
Training loss: 6.86711834036207
Validation loss: 7.898781636189883

Epoch: 5| Step: 7
Training loss: 9.128403538388735
Validation loss: 7.891200291095784

Epoch: 5| Step: 8
Training loss: 7.169601578755664
Validation loss: 7.892132861598123

Epoch: 5| Step: 9
Training loss: 8.26704172493619
Validation loss: 7.890195144321018

Epoch: 5| Step: 10
Training loss: 8.389737954304326
Validation loss: 7.886397367757524

Epoch: 5| Step: 0
Training loss: 6.758330114750344
Validation loss: 7.882091339343714

Epoch: 5| Step: 1
Training loss: 7.8018721656760555
Validation loss: 7.880419136016211

Epoch: 5| Step: 2
Training loss: 7.313576121906298
Validation loss: 7.874664794329812

Epoch: 5| Step: 3
Training loss: 7.4567915816481465
Validation loss: 7.872254040853079

Epoch: 5| Step: 4
Training loss: 8.48565855205191
Validation loss: 7.870343471188642

Epoch: 5| Step: 5
Training loss: 8.555770568567898
Validation loss: 7.869759697232728

Epoch: 5| Step: 6
Training loss: 7.806384325055278
Validation loss: 7.864652263684541

Epoch: 5| Step: 7
Training loss: 7.113735999330033
Validation loss: 7.8600053229688776

Epoch: 5| Step: 8
Training loss: 8.05313536436445
Validation loss: 7.856734895336265

Epoch: 5| Step: 9
Training loss: 7.756881366026641
Validation loss: 7.853899946460651

Epoch: 5| Step: 10
Training loss: 8.947983362188376
Validation loss: 7.851257778689533

Epoch: 6| Step: 0
Training loss: 8.15737334367896
Validation loss: 7.849163432574118

Epoch: 5| Step: 1
Training loss: 6.371557166239368
Validation loss: 7.843863592602838

Epoch: 5| Step: 2
Training loss: 7.606252668093462
Validation loss: 7.842033239865487

Epoch: 5| Step: 3
Training loss: 7.7819872893673505
Validation loss: 7.83672027919751

Epoch: 5| Step: 4
Training loss: 7.198810733486643
Validation loss: 7.83280757517698

Epoch: 5| Step: 5
Training loss: 8.33556224260791
Validation loss: 7.8294646589891075

Epoch: 5| Step: 6
Training loss: 7.8814375465579225
Validation loss: 7.827644904403093

Epoch: 5| Step: 7
Training loss: 8.12168464510962
Validation loss: 7.822319921544974

Epoch: 5| Step: 8
Training loss: 7.775355546187512
Validation loss: 7.819073094323592

Epoch: 5| Step: 9
Training loss: 8.345723922350052
Validation loss: 7.8164312894184915

Epoch: 5| Step: 10
Training loss: 7.981555179505815
Validation loss: 7.811537656518092

Epoch: 7| Step: 0
Training loss: 7.856431899168941
Validation loss: 7.80768224214296

Epoch: 5| Step: 1
Training loss: 7.988454832695349
Validation loss: 7.8060361417205195

Epoch: 5| Step: 2
Training loss: 7.5141216844499334
Validation loss: 7.800951630350745

Epoch: 5| Step: 3
Training loss: 8.156457189508037
Validation loss: 7.794257304891457

Epoch: 5| Step: 4
Training loss: 7.39112178108718
Validation loss: 7.7934405527564286

Epoch: 5| Step: 5
Training loss: 6.8074389215335716
Validation loss: 7.789812566806574

Epoch: 5| Step: 6
Training loss: 8.513403254465544
Validation loss: 7.78363903165822

Epoch: 5| Step: 7
Training loss: 7.138074156320654
Validation loss: 7.782471347908138

Epoch: 5| Step: 8
Training loss: 7.445030439223657
Validation loss: 7.775728192781217

Epoch: 5| Step: 9
Training loss: 8.49418665736837
Validation loss: 7.771837864075597

Epoch: 5| Step: 10
Training loss: 7.8302038177427145
Validation loss: 7.769495867564466

Epoch: 8| Step: 0
Training loss: 6.284565065033588
Validation loss: 7.765177076373275

Epoch: 5| Step: 1
Training loss: 8.761787540133435
Validation loss: 7.763058775328416

Epoch: 5| Step: 2
Training loss: 7.079870147807405
Validation loss: 7.757352339078392

Epoch: 5| Step: 3
Training loss: 6.3915307631917235
Validation loss: 7.751640442597903

Epoch: 5| Step: 4
Training loss: 7.683607899469051
Validation loss: 7.751411558195957

Epoch: 5| Step: 5
Training loss: 6.9829826588618165
Validation loss: 7.7478869465525

Epoch: 5| Step: 6
Training loss: 8.45864456681535
Validation loss: 7.740069801779161

Epoch: 5| Step: 7
Training loss: 8.41120078496641
Validation loss: 7.73787493859474

Epoch: 5| Step: 8
Training loss: 8.251364855141011
Validation loss: 7.732788678990394

Epoch: 5| Step: 9
Training loss: 7.831005426897223
Validation loss: 7.729971122045156

Epoch: 5| Step: 10
Training loss: 8.258619949289159
Validation loss: 7.722463105860985

Epoch: 9| Step: 0
Training loss: 6.844685251092518
Validation loss: 7.7177221836067025

Epoch: 5| Step: 1
Training loss: 8.650184902794798
Validation loss: 7.713679842148817

Epoch: 5| Step: 2
Training loss: 7.337111309095736
Validation loss: 7.710886972664546

Epoch: 5| Step: 3
Training loss: 7.011471204718012
Validation loss: 7.705933396530964

Epoch: 5| Step: 4
Training loss: 8.078730842701011
Validation loss: 7.701926291227985

Epoch: 5| Step: 5
Training loss: 7.961999764291759
Validation loss: 7.695550920195141

Epoch: 5| Step: 6
Training loss: 7.808706110059544
Validation loss: 7.692499146189012

Epoch: 5| Step: 7
Training loss: 7.775564299586362
Validation loss: 7.685383321623439

Epoch: 5| Step: 8
Training loss: 7.132806884496009
Validation loss: 7.680943301201504

Epoch: 5| Step: 9
Training loss: 7.68464719360846
Validation loss: 7.67790254952814

Epoch: 5| Step: 10
Training loss: 7.810888261481508
Validation loss: 7.669127646686803

Epoch: 10| Step: 0
Training loss: 8.938529855574904
Validation loss: 7.667372349616497

Epoch: 5| Step: 1
Training loss: 7.265553595079232
Validation loss: 7.661531816269863

Epoch: 5| Step: 2
Training loss: 7.142910581116372
Validation loss: 7.653936647118294

Epoch: 5| Step: 3
Training loss: 8.325666741142737
Validation loss: 7.646702209210388

Epoch: 5| Step: 4
Training loss: 8.076301058897279
Validation loss: 7.64507653576357

Epoch: 5| Step: 5
Training loss: 7.074967444247232
Validation loss: 7.638085868841656

Epoch: 5| Step: 6
Training loss: 7.013909280913099
Validation loss: 7.630236684199217

Epoch: 5| Step: 7
Training loss: 8.044819215553417
Validation loss: 7.627749469990167

Epoch: 5| Step: 8
Training loss: 7.018639407556195
Validation loss: 7.621320848541987

Epoch: 5| Step: 9
Training loss: 7.094353872803259
Validation loss: 7.616834943893411

Epoch: 5| Step: 10
Training loss: 7.313859862038852
Validation loss: 7.607821046429417

Epoch: 11| Step: 0
Training loss: 8.342893177857933
Validation loss: 7.60201788960593

Epoch: 5| Step: 1
Training loss: 7.811643263571047
Validation loss: 7.599566155071712

Epoch: 5| Step: 2
Training loss: 7.393723336411136
Validation loss: 7.591376269155093

Epoch: 5| Step: 3
Training loss: 7.72513973763999
Validation loss: 7.584751850649686

Epoch: 5| Step: 4
Training loss: 7.85650643087243
Validation loss: 7.580165176451264

Epoch: 5| Step: 5
Training loss: 7.065287352250653
Validation loss: 7.570994427792266

Epoch: 5| Step: 6
Training loss: 6.6282968055512175
Validation loss: 7.567928455799508

Epoch: 5| Step: 7
Training loss: 8.05407369145228
Validation loss: 7.5607939907554895

Epoch: 5| Step: 8
Training loss: 7.006896300371524
Validation loss: 7.5508850636128235

Epoch: 5| Step: 9
Training loss: 7.4482877056471
Validation loss: 7.548391276252262

Epoch: 5| Step: 10
Training loss: 7.37284043585166
Validation loss: 7.535984170803235

Epoch: 12| Step: 0
Training loss: 7.643485503092573
Validation loss: 7.534292864567336

Epoch: 5| Step: 1
Training loss: 7.582146212823052
Validation loss: 7.52652913822064

Epoch: 5| Step: 2
Training loss: 7.7729533749213475
Validation loss: 7.519498730575716

Epoch: 5| Step: 3
Training loss: 8.249657363712286
Validation loss: 7.50911085975441

Epoch: 5| Step: 4
Training loss: 6.99418971202406
Validation loss: 7.50639223991645

Epoch: 5| Step: 5
Training loss: 7.912911846416599
Validation loss: 7.495509695079795

Epoch: 5| Step: 6
Training loss: 7.439945107534396
Validation loss: 7.4868720581325805

Epoch: 5| Step: 7
Training loss: 6.819107071489742
Validation loss: 7.480957870666315

Epoch: 5| Step: 8
Training loss: 7.384833552732418
Validation loss: 7.471273713846835

Epoch: 5| Step: 9
Training loss: 6.160007317774006
Validation loss: 7.468784690031864

Epoch: 5| Step: 10
Training loss: 7.9370652928299945
Validation loss: 7.4580036071425955

Epoch: 13| Step: 0
Training loss: 6.728589610895843
Validation loss: 7.456897864419219

Epoch: 5| Step: 1
Training loss: 8.105392036534566
Validation loss: 7.444411968837269

Epoch: 5| Step: 2
Training loss: 7.44519926707572
Validation loss: 7.4380235812574504

Epoch: 5| Step: 3
Training loss: 7.630134729718233
Validation loss: 7.430829200258777

Epoch: 5| Step: 4
Training loss: 6.944123826149029
Validation loss: 7.417597927109829

Epoch: 5| Step: 5
Training loss: 7.431727886314238
Validation loss: 7.410152613234989

Epoch: 5| Step: 6
Training loss: 6.643541122124361
Validation loss: 7.4012669261160635

Epoch: 5| Step: 7
Training loss: 8.145719899772326
Validation loss: 7.392909084348126

Epoch: 5| Step: 8
Training loss: 6.978070923680696
Validation loss: 7.3864487983882166

Epoch: 5| Step: 9
Training loss: 7.440414242441149
Validation loss: 7.383474207141837

Epoch: 5| Step: 10
Training loss: 7.452022702897647
Validation loss: 7.369216166553245

Epoch: 14| Step: 0
Training loss: 7.626027772770334
Validation loss: 7.360347975663492

Epoch: 5| Step: 1
Training loss: 7.868585305160632
Validation loss: 7.355586732441143

Epoch: 5| Step: 2
Training loss: 7.4469554645450895
Validation loss: 7.344481648147201

Epoch: 5| Step: 3
Training loss: 6.778119045622529
Validation loss: 7.337241673218341

Epoch: 5| Step: 4
Training loss: 7.975035339085838
Validation loss: 7.327990863322016

Epoch: 5| Step: 5
Training loss: 7.3360305796477805
Validation loss: 7.320359049656157

Epoch: 5| Step: 6
Training loss: 5.706466406638845
Validation loss: 7.3080153679453

Epoch: 5| Step: 7
Training loss: 6.758598502429407
Validation loss: 7.300714088089366

Epoch: 5| Step: 8
Training loss: 7.502492363381496
Validation loss: 7.2930412644571945

Epoch: 5| Step: 9
Training loss: 7.128583575745375
Validation loss: 7.2809294238749755

Epoch: 5| Step: 10
Training loss: 7.728048924103667
Validation loss: 7.266774749554161

Epoch: 15| Step: 0
Training loss: 7.441053295025127
Validation loss: 7.26034729429321

Epoch: 5| Step: 1
Training loss: 6.209623608078344
Validation loss: 7.243111777685582

Epoch: 5| Step: 2
Training loss: 7.600201915267253
Validation loss: 7.243432529708886

Epoch: 5| Step: 3
Training loss: 7.0707953693882075
Validation loss: 7.230254246056107

Epoch: 5| Step: 4
Training loss: 7.189342494819154
Validation loss: 7.224946995369819

Epoch: 5| Step: 5
Training loss: 7.106456249669507
Validation loss: 7.2094409192945985

Epoch: 5| Step: 6
Training loss: 8.475989143915502
Validation loss: 7.20733435164312

Epoch: 5| Step: 7
Training loss: 7.500632195848717
Validation loss: 7.187257992529905

Epoch: 5| Step: 8
Training loss: 6.6524452475008085
Validation loss: 7.179823024804805

Epoch: 5| Step: 9
Training loss: 6.191648383475102
Validation loss: 7.169787619032511

Epoch: 5| Step: 10
Training loss: 7.186044031370861
Validation loss: 7.160320472211366

Epoch: 16| Step: 0
Training loss: 7.238306810279344
Validation loss: 7.154038209215974

Epoch: 5| Step: 1
Training loss: 6.693860318283715
Validation loss: 7.145029291170573

Epoch: 5| Step: 2
Training loss: 7.057340374505193
Validation loss: 7.131555583600927

Epoch: 5| Step: 3
Training loss: 7.355200099647825
Validation loss: 7.1195211424766365

Epoch: 5| Step: 4
Training loss: 7.443689159333647
Validation loss: 7.109853315484337

Epoch: 5| Step: 5
Training loss: 7.102934550573892
Validation loss: 7.1008641016560174

Epoch: 5| Step: 6
Training loss: 6.328171718095296
Validation loss: 7.085882009461774

Epoch: 5| Step: 7
Training loss: 6.964197972901238
Validation loss: 7.073372551641899

Epoch: 5| Step: 8
Training loss: 6.67075368852345
Validation loss: 7.064020052630298

Epoch: 5| Step: 9
Training loss: 7.501171783461568
Validation loss: 7.054777769734651

Epoch: 5| Step: 10
Training loss: 7.224905584965794
Validation loss: 7.034842654229143

Epoch: 17| Step: 0
Training loss: 7.677522713153399
Validation loss: 7.028829370934758

Epoch: 5| Step: 1
Training loss: 6.071574861703471
Validation loss: 7.013622523714684

Epoch: 5| Step: 2
Training loss: 7.326973960941611
Validation loss: 7.01040142078208

Epoch: 5| Step: 3
Training loss: 7.6538700063574865
Validation loss: 6.9932638914903436

Epoch: 5| Step: 4
Training loss: 6.797285817326051
Validation loss: 6.991558827593975

Epoch: 5| Step: 5
Training loss: 6.527588616554558
Validation loss: 6.971282688574741

Epoch: 5| Step: 6
Training loss: 6.936266540298636
Validation loss: 6.961832804440674

Epoch: 5| Step: 7
Training loss: 7.186319005385718
Validation loss: 6.950813063765011

Epoch: 5| Step: 8
Training loss: 6.832054142507387
Validation loss: 6.93764223653026

Epoch: 5| Step: 9
Training loss: 7.206283307225987
Validation loss: 6.930411958188786

Epoch: 5| Step: 10
Training loss: 5.671936875523376
Validation loss: 6.921310115460545

Epoch: 18| Step: 0
Training loss: 6.084841118950527
Validation loss: 6.901108143525553

Epoch: 5| Step: 1
Training loss: 6.9839831078009365
Validation loss: 6.883259944002622

Epoch: 5| Step: 2
Training loss: 7.268918052036135
Validation loss: 6.870379711972594

Epoch: 5| Step: 3
Training loss: 6.4609808960717645
Validation loss: 6.868274388844035

Epoch: 5| Step: 4
Training loss: 7.353341060760026
Validation loss: 6.847039629723343

Epoch: 5| Step: 5
Training loss: 6.821204547727153
Validation loss: 6.83972543500826

Epoch: 5| Step: 6
Training loss: 6.750347552358821
Validation loss: 6.828739276701638

Epoch: 5| Step: 7
Training loss: 6.880162468256081
Validation loss: 6.817420238621511

Epoch: 5| Step: 8
Training loss: 6.415512906008994
Validation loss: 6.807350487650314

Epoch: 5| Step: 9
Training loss: 7.391592466490143
Validation loss: 6.793673016330784

Epoch: 5| Step: 10
Training loss: 6.186264377098619
Validation loss: 6.7745329300637245

Epoch: 19| Step: 0
Training loss: 5.6312378945680965
Validation loss: 6.761812858054379

Epoch: 5| Step: 1
Training loss: 5.893811889194045
Validation loss: 6.755901684166813

Epoch: 5| Step: 2
Training loss: 7.03056094713966
Validation loss: 6.737573388388099

Epoch: 5| Step: 3
Training loss: 6.885829926601162
Validation loss: 6.714194207120061

Epoch: 5| Step: 4
Training loss: 6.087914749210303
Validation loss: 6.713045435566886

Epoch: 5| Step: 5
Training loss: 6.678314460490995
Validation loss: 6.697251712896576

Epoch: 5| Step: 6
Training loss: 7.718873304857099
Validation loss: 6.6915708351294345

Epoch: 5| Step: 7
Training loss: 7.129799815573804
Validation loss: 6.66743767597098

Epoch: 5| Step: 8
Training loss: 6.198624292150185
Validation loss: 6.6589479225936765

Epoch: 5| Step: 9
Training loss: 6.754539940991772
Validation loss: 6.6349965553958805

Epoch: 5| Step: 10
Training loss: 6.990699584181081
Validation loss: 6.630355561761622

Epoch: 20| Step: 0
Training loss: 6.538088198398601
Validation loss: 6.606427048445545

Epoch: 5| Step: 1
Training loss: 6.68993867991446
Validation loss: 6.601528121083019

Epoch: 5| Step: 2
Training loss: 6.245592317857363
Validation loss: 6.576804152223771

Epoch: 5| Step: 3
Training loss: 6.918216883960463
Validation loss: 6.57976656340126

Epoch: 5| Step: 4
Training loss: 6.701833605024344
Validation loss: 6.551268642758628

Epoch: 5| Step: 5
Training loss: 7.052302197018799
Validation loss: 6.542260646665617

Epoch: 5| Step: 6
Training loss: 5.653781584087019
Validation loss: 6.520331935273125

Epoch: 5| Step: 7
Training loss: 5.722320942608413
Validation loss: 6.517188159847999

Epoch: 5| Step: 8
Training loss: 7.414052724078117
Validation loss: 6.494180944297386

Epoch: 5| Step: 9
Training loss: 5.948566283266583
Validation loss: 6.470691402461295

Epoch: 5| Step: 10
Training loss: 6.425728117656474
Validation loss: 6.464917761865999

Epoch: 21| Step: 0
Training loss: 7.147952137296393
Validation loss: 6.449316683446685

Epoch: 5| Step: 1
Training loss: 5.928662921508123
Validation loss: 6.441708485873352

Epoch: 5| Step: 2
Training loss: 5.92689772205207
Validation loss: 6.425536120061921

Epoch: 5| Step: 3
Training loss: 7.163641564702222
Validation loss: 6.401524856633193

Epoch: 5| Step: 4
Training loss: 5.871315307903691
Validation loss: 6.389798432615733

Epoch: 5| Step: 5
Training loss: 6.775144298185129
Validation loss: 6.371966707440853

Epoch: 5| Step: 6
Training loss: 5.6722334651273085
Validation loss: 6.356620189277161

Epoch: 5| Step: 7
Training loss: 6.296139203191651
Validation loss: 6.346960844481487

Epoch: 5| Step: 8
Training loss: 6.700982878601216
Validation loss: 6.318435563651681

Epoch: 5| Step: 9
Training loss: 6.768140646715366
Validation loss: 6.3015853561696735

Epoch: 5| Step: 10
Training loss: 4.970032916199887
Validation loss: 6.285933356109264

Epoch: 22| Step: 0
Training loss: 6.876797805154556
Validation loss: 6.280277616704035

Epoch: 5| Step: 1
Training loss: 6.199896214754766
Validation loss: 6.243367951736476

Epoch: 5| Step: 2
Training loss: 5.984815138126559
Validation loss: 6.25564435012833

Epoch: 5| Step: 3
Training loss: 5.964585694012678
Validation loss: 6.227049583013941

Epoch: 5| Step: 4
Training loss: 5.862638088787967
Validation loss: 6.204061446431248

Epoch: 5| Step: 5
Training loss: 7.254670316013193
Validation loss: 6.199580155790625

Epoch: 5| Step: 6
Training loss: 6.581079539874613
Validation loss: 6.174104777127734

Epoch: 5| Step: 7
Training loss: 5.613699858260398
Validation loss: 6.158439137485462

Epoch: 5| Step: 8
Training loss: 6.800804247699484
Validation loss: 6.142848098190049

Epoch: 5| Step: 9
Training loss: 5.53301146310308
Validation loss: 6.130793219405632

Epoch: 5| Step: 10
Training loss: 4.42966876959499
Validation loss: 6.1182393274685625

Epoch: 23| Step: 0
Training loss: 6.183701090745534
Validation loss: 6.08561027192959

Epoch: 5| Step: 1
Training loss: 4.681688699169108
Validation loss: 6.073633054376426

Epoch: 5| Step: 2
Training loss: 6.07629272772373
Validation loss: 6.065498171411042

Epoch: 5| Step: 3
Training loss: 6.124233587154339
Validation loss: 6.037232810140151

Epoch: 5| Step: 4
Training loss: 6.93318605755618
Validation loss: 6.000586436609161

Epoch: 5| Step: 5
Training loss: 6.113944527715988
Validation loss: 5.99861497685312

Epoch: 5| Step: 6
Training loss: 6.796651902319173
Validation loss: 5.9810416401873

Epoch: 5| Step: 7
Training loss: 4.692823515172466
Validation loss: 5.969783992980949

Epoch: 5| Step: 8
Training loss: 6.1056746181502835
Validation loss: 5.948305338596053

Epoch: 5| Step: 9
Training loss: 5.804809076157849
Validation loss: 5.944975258109833

Epoch: 5| Step: 10
Training loss: 5.7471561863008676
Validation loss: 5.923036689138529

Epoch: 24| Step: 0
Training loss: 5.854851443965782
Validation loss: 5.86881024464071

Epoch: 5| Step: 1
Training loss: 6.291406116606388
Validation loss: 5.88072904281342

Epoch: 5| Step: 2
Training loss: 6.540397990771322
Validation loss: 5.840521544850318

Epoch: 5| Step: 3
Training loss: 5.688729289584431
Validation loss: 5.8357605427189645

Epoch: 5| Step: 4
Training loss: 5.830951894845301
Validation loss: 5.821049079059321

Epoch: 5| Step: 5
Training loss: 5.314323561104402
Validation loss: 5.775876000566222

Epoch: 5| Step: 6
Training loss: 5.510521794586099
Validation loss: 5.761444914442265

Epoch: 5| Step: 7
Training loss: 5.653493135610886
Validation loss: 5.766887268839241

Epoch: 5| Step: 8
Training loss: 5.886051902135158
Validation loss: 5.734632959873195

Epoch: 5| Step: 9
Training loss: 5.3985906598547455
Validation loss: 5.707123990808212

Epoch: 5| Step: 10
Training loss: 5.298259362905078
Validation loss: 5.691454488383873

Epoch: 25| Step: 0
Training loss: 6.128422617749063
Validation loss: 5.6632382893554825

Epoch: 5| Step: 1
Training loss: 6.08243609914206
Validation loss: 5.671588950719825

Epoch: 5| Step: 2
Training loss: 5.582069007099824
Validation loss: 5.639669485171414

Epoch: 5| Step: 3
Training loss: 6.475440946315452
Validation loss: 5.608922089046605

Epoch: 5| Step: 4
Training loss: 5.659367329314756
Validation loss: 5.5627070710207445

Epoch: 5| Step: 5
Training loss: 5.889856263043811
Validation loss: 5.5610476832361435

Epoch: 5| Step: 6
Training loss: 4.195178834288254
Validation loss: 5.536815079826255

Epoch: 5| Step: 7
Training loss: 5.160948306334244
Validation loss: 5.524277419353368

Epoch: 5| Step: 8
Training loss: 5.679036644920991
Validation loss: 5.506366442103678

Epoch: 5| Step: 9
Training loss: 4.290300367817357
Validation loss: 5.489013850930068

Epoch: 5| Step: 10
Training loss: 5.389245782856097
Validation loss: 5.463180318734259

Epoch: 26| Step: 0
Training loss: 5.014505136553992
Validation loss: 5.426294915688894

Epoch: 5| Step: 1
Training loss: 5.058239686571469
Validation loss: 5.427635178828182

Epoch: 5| Step: 2
Training loss: 6.045705913915975
Validation loss: 5.385275136769464

Epoch: 5| Step: 3
Training loss: 5.592317195218675
Validation loss: 5.385737710194365

Epoch: 5| Step: 4
Training loss: 5.741259026232733
Validation loss: 5.351721272404862

Epoch: 5| Step: 5
Training loss: 6.287442168013419
Validation loss: 5.3437587275251195

Epoch: 5| Step: 6
Training loss: 5.48796116448722
Validation loss: 5.296055601551517

Epoch: 5| Step: 7
Training loss: 4.32939024792444
Validation loss: 5.258444396138827

Epoch: 5| Step: 8
Training loss: 5.255145866191649
Validation loss: 5.2409747061858445

Epoch: 5| Step: 9
Training loss: 4.336927366247046
Validation loss: 5.2489568003006335

Epoch: 5| Step: 10
Training loss: 4.711747588542362
Validation loss: 5.215224039405803

Epoch: 27| Step: 0
Training loss: 4.840986090848342
Validation loss: 5.179076001693671

Epoch: 5| Step: 1
Training loss: 5.437423179346888
Validation loss: 5.144126204716015

Epoch: 5| Step: 2
Training loss: 5.0379985780308845
Validation loss: 5.114045004544684

Epoch: 5| Step: 3
Training loss: 5.079832007266175
Validation loss: 5.104357096284196

Epoch: 5| Step: 4
Training loss: 4.953929366494126
Validation loss: 5.098634517023668

Epoch: 5| Step: 5
Training loss: 5.295181768969849
Validation loss: 5.048219154911743

Epoch: 5| Step: 6
Training loss: 4.26182929436717
Validation loss: 5.025391126975358

Epoch: 5| Step: 7
Training loss: 5.933575427370492
Validation loss: 5.008985777846351

Epoch: 5| Step: 8
Training loss: 4.362672276633961
Validation loss: 4.988277769646834

Epoch: 5| Step: 9
Training loss: 5.0636397597555405
Validation loss: 4.961679095874779

Epoch: 5| Step: 10
Training loss: 5.244327205130574
Validation loss: 4.939540519796444

Epoch: 28| Step: 0
Training loss: 4.890237128626212
Validation loss: 4.909781348329753

Epoch: 5| Step: 1
Training loss: 4.694116627359708
Validation loss: 4.853665203395029

Epoch: 5| Step: 2
Training loss: 5.522150345625993
Validation loss: 4.85044447022262

Epoch: 5| Step: 3
Training loss: 5.1006714771510495
Validation loss: 4.832465830523289

Epoch: 5| Step: 4
Training loss: 3.7672758796922396
Validation loss: 4.800107086646634

Epoch: 5| Step: 5
Training loss: 4.563803081720944
Validation loss: 4.758553582389455

Epoch: 5| Step: 6
Training loss: 4.1901621540894425
Validation loss: 4.738155896028282

Epoch: 5| Step: 7
Training loss: 4.621472431058122
Validation loss: 4.705996207828506

Epoch: 5| Step: 8
Training loss: 5.4259721298092565
Validation loss: 4.696146102484815

Epoch: 5| Step: 9
Training loss: 4.673782622597664
Validation loss: 4.670073412039118

Epoch: 5| Step: 10
Training loss: 4.577476689911123
Validation loss: 4.655152092249417

Epoch: 29| Step: 0
Training loss: 4.254891441744463
Validation loss: 4.605963130107083

Epoch: 5| Step: 1
Training loss: 4.847030414817209
Validation loss: 4.572789581205043

Epoch: 5| Step: 2
Training loss: 3.8231888066995023
Validation loss: 4.571190778876921

Epoch: 5| Step: 3
Training loss: 4.581674495249517
Validation loss: 4.541907446444136

Epoch: 5| Step: 4
Training loss: 5.020910787446641
Validation loss: 4.472879665705892

Epoch: 5| Step: 5
Training loss: 5.019397873349584
Validation loss: 4.4859605589922715

Epoch: 5| Step: 6
Training loss: 4.40053387784189
Validation loss: 4.452925121209101

Epoch: 5| Step: 7
Training loss: 4.243527813630271
Validation loss: 4.418686302642509

Epoch: 5| Step: 8
Training loss: 3.976853875237952
Validation loss: 4.393025914517279

Epoch: 5| Step: 9
Training loss: 4.396408019383595
Validation loss: 4.372250737624116

Epoch: 5| Step: 10
Training loss: 4.423587966025324
Validation loss: 4.370469760033064

Epoch: 30| Step: 0
Training loss: 2.6666020345802703
Validation loss: 4.290387657263197

Epoch: 5| Step: 1
Training loss: 5.233890522413547
Validation loss: 4.274983980448299

Epoch: 5| Step: 2
Training loss: 4.716267722324264
Validation loss: 4.252827755013184

Epoch: 5| Step: 3
Training loss: 4.052715549655073
Validation loss: 4.205648439130957

Epoch: 5| Step: 4
Training loss: 4.34162664315684
Validation loss: 4.179637887710293

Epoch: 5| Step: 5
Training loss: 3.963813775739556
Validation loss: 4.1365104442428136

Epoch: 5| Step: 6
Training loss: 4.432815012831946
Validation loss: 4.105809611792839

Epoch: 5| Step: 7
Training loss: 3.729329039947508
Validation loss: 4.1049844091543335

Epoch: 5| Step: 8
Training loss: 3.8734574477838892
Validation loss: 4.04846339130795

Epoch: 5| Step: 9
Training loss: 4.015564676863301
Validation loss: 4.019450583313661

Epoch: 5| Step: 10
Training loss: 4.260643142363869
Validation loss: 3.9729811638505645

Epoch: 31| Step: 0
Training loss: 4.43622882527328
Validation loss: 3.952201735770405

Epoch: 5| Step: 1
Training loss: 4.9132609236689975
Validation loss: 3.946102245639506

Epoch: 5| Step: 2
Training loss: 4.0823478028426265
Validation loss: 3.9498688734851655

Epoch: 5| Step: 3
Training loss: 3.3904030722841365
Validation loss: 3.881313221118845

Epoch: 5| Step: 4
Training loss: 3.3033028806430464
Validation loss: 3.8486421274720977

Epoch: 5| Step: 5
Training loss: 4.198763828919178
Validation loss: 3.8067753978509034

Epoch: 5| Step: 6
Training loss: 3.983772142466642
Validation loss: 3.792031779126703

Epoch: 5| Step: 7
Training loss: 3.5577049778575875
Validation loss: 3.7898543235515687

Epoch: 5| Step: 8
Training loss: 3.163064832343143
Validation loss: 3.8028357399207433

Epoch: 5| Step: 9
Training loss: 3.627906817727378
Validation loss: 3.702824760544528

Epoch: 5| Step: 10
Training loss: 3.4140673883957424
Validation loss: 3.698930772829261

Epoch: 32| Step: 0
Training loss: 3.8202379839598155
Validation loss: 3.664804623931195

Epoch: 5| Step: 1
Training loss: 3.9090983267748016
Validation loss: 3.6279283674960334

Epoch: 5| Step: 2
Training loss: 3.1465390826346593
Validation loss: 3.6069833969692557

Epoch: 5| Step: 3
Training loss: 3.7780700427176654
Validation loss: 3.5850540793391703

Epoch: 5| Step: 4
Training loss: 3.1872504641524855
Validation loss: 3.5676247092550657

Epoch: 5| Step: 5
Training loss: 3.888219740988339
Validation loss: 3.5409080986287025

Epoch: 5| Step: 6
Training loss: 2.866757061738122
Validation loss: 3.5209128194944213

Epoch: 5| Step: 7
Training loss: 4.0968159849570505
Validation loss: 3.4770928098584264

Epoch: 5| Step: 8
Training loss: 4.343028715336938
Validation loss: 3.4770842129965085

Epoch: 5| Step: 9
Training loss: 3.1691537092012347
Validation loss: 3.460161570688093

Epoch: 5| Step: 10
Training loss: 3.232815131384109
Validation loss: 3.4149239225067163

Epoch: 33| Step: 0
Training loss: 2.870999746016355
Validation loss: 3.3926628275501742

Epoch: 5| Step: 1
Training loss: 4.080496029339936
Validation loss: 3.3535413827377

Epoch: 5| Step: 2
Training loss: 4.292867449328013
Validation loss: 3.381623829705274

Epoch: 5| Step: 3
Training loss: 3.3990915655612066
Validation loss: 3.342983579313593

Epoch: 5| Step: 4
Training loss: 3.658839946823272
Validation loss: 3.2984004513466956

Epoch: 5| Step: 5
Training loss: 2.532610209892206
Validation loss: 3.2775224036148454

Epoch: 5| Step: 6
Training loss: 3.499563189905506
Validation loss: 3.270402407444709

Epoch: 5| Step: 7
Training loss: 2.977218275346572
Validation loss: 3.2735067772314452

Epoch: 5| Step: 8
Training loss: 3.6522497481218683
Validation loss: 3.1844320409893823

Epoch: 5| Step: 9
Training loss: 2.6618061074851442
Validation loss: 3.174658038077404

Epoch: 5| Step: 10
Training loss: 3.3228603505750627
Validation loss: 3.1711650987285998

Epoch: 34| Step: 0
Training loss: 2.3829955984339883
Validation loss: 3.167886379832003

Epoch: 5| Step: 1
Training loss: 2.7316530467126943
Validation loss: 3.137728499088973

Epoch: 5| Step: 2
Training loss: 3.9226864890897173
Validation loss: 3.128524145099174

Epoch: 5| Step: 3
Training loss: 4.363088468631759
Validation loss: 3.1247492962429737

Epoch: 5| Step: 4
Training loss: 3.362527618862017
Validation loss: 3.0832127999578764

Epoch: 5| Step: 5
Training loss: 2.8848548828862257
Validation loss: 3.133303194505436

Epoch: 5| Step: 6
Training loss: 3.2776433105329725
Validation loss: 3.107280819755809

Epoch: 5| Step: 7
Training loss: 3.477223399917959
Validation loss: 3.057701471754962

Epoch: 5| Step: 8
Training loss: 2.9110422309058293
Validation loss: 3.079818485439792

Epoch: 5| Step: 9
Training loss: 2.790687749996577
Validation loss: 3.04829750394902

Epoch: 5| Step: 10
Training loss: 3.3703570041538953
Validation loss: 3.028912868639215

Epoch: 35| Step: 0
Training loss: 3.3468384072006785
Validation loss: 3.0025696243342535

Epoch: 5| Step: 1
Training loss: 2.837068190466771
Validation loss: 2.9947810290104435

Epoch: 5| Step: 2
Training loss: 3.1438812531815583
Validation loss: 2.982944002204328

Epoch: 5| Step: 3
Training loss: 3.705279017558789
Validation loss: 2.9837948175528304

Epoch: 5| Step: 4
Training loss: 3.571913746167255
Validation loss: 3.0216089906999115

Epoch: 5| Step: 5
Training loss: 2.832024515078199
Validation loss: 2.9675261621138964

Epoch: 5| Step: 6
Training loss: 2.8645176735491082
Validation loss: 2.9679118624302583

Epoch: 5| Step: 7
Training loss: 2.950018808337238
Validation loss: 2.9893861282327876

Epoch: 5| Step: 8
Training loss: 2.620658827057748
Validation loss: 3.009038050363368

Epoch: 5| Step: 9
Training loss: 2.774767661463525
Validation loss: 2.949022568668189

Epoch: 5| Step: 10
Training loss: 3.9473048854198574
Validation loss: 2.9431492739292806

Epoch: 36| Step: 0
Training loss: 3.026759331190737
Validation loss: 2.967405597481641

Epoch: 5| Step: 1
Training loss: 3.0013189595286556
Validation loss: 2.966866467923484

Epoch: 5| Step: 2
Training loss: 3.229637472635416
Validation loss: 2.890604363977261

Epoch: 5| Step: 3
Training loss: 3.5672332373087623
Validation loss: 2.887760158837231

Epoch: 5| Step: 4
Training loss: 3.177719369394503
Validation loss: 2.904465975385413

Epoch: 5| Step: 5
Training loss: 2.622481273078785
Validation loss: 2.934411824075579

Epoch: 5| Step: 6
Training loss: 2.8463681084843158
Validation loss: 2.9131688152424724

Epoch: 5| Step: 7
Training loss: 3.3097715837201465
Validation loss: 2.8549994563694905

Epoch: 5| Step: 8
Training loss: 3.347187022705158
Validation loss: 2.887764956293296

Epoch: 5| Step: 9
Training loss: 3.4690245098744783
Validation loss: 2.871532266900184

Epoch: 5| Step: 10
Training loss: 2.704475462396152
Validation loss: 2.8619343500518264

Epoch: 37| Step: 0
Training loss: 3.8736297892074623
Validation loss: 2.886996666960149

Epoch: 5| Step: 1
Training loss: 2.795075930142369
Validation loss: 2.8907208609435022

Epoch: 5| Step: 2
Training loss: 2.4941990307068624
Validation loss: 2.8606047988908854

Epoch: 5| Step: 3
Training loss: 3.175809477695891
Validation loss: 2.82420471275968

Epoch: 5| Step: 4
Training loss: 2.9528417703754504
Validation loss: 2.8688611328552667

Epoch: 5| Step: 5
Training loss: 2.5418386453280344
Validation loss: 2.922173510750504

Epoch: 5| Step: 6
Training loss: 3.281988442297745
Validation loss: 2.8829477000964774

Epoch: 5| Step: 7
Training loss: 3.0182654329523246
Validation loss: 2.8639614548133685

Epoch: 5| Step: 8
Training loss: 2.989462146673144
Validation loss: 2.9141992113907254

Epoch: 5| Step: 9
Training loss: 3.3323510789041615
Validation loss: 2.8902684979379827

Epoch: 5| Step: 10
Training loss: 3.4250037812817715
Validation loss: 2.848255135851208

Epoch: 38| Step: 0
Training loss: 2.757803681875509
Validation loss: 2.8910792389916447

Epoch: 5| Step: 1
Training loss: 3.343871212482464
Validation loss: 2.9083003268766716

Epoch: 5| Step: 2
Training loss: 2.7063544942579285
Validation loss: 2.902133577905051

Epoch: 5| Step: 3
Training loss: 2.740911550993774
Validation loss: 2.866350737927306

Epoch: 5| Step: 4
Training loss: 3.2077781560204857
Validation loss: 2.8646457149988374

Epoch: 5| Step: 5
Training loss: 3.36438097901356
Validation loss: 2.8723372424606044

Epoch: 5| Step: 6
Training loss: 3.9410775296131115
Validation loss: 2.8730638162960247

Epoch: 5| Step: 7
Training loss: 2.5317334313930164
Validation loss: 2.831049375582098

Epoch: 5| Step: 8
Training loss: 2.6309178267274773
Validation loss: 2.839280857470135

Epoch: 5| Step: 9
Training loss: 3.1452795050643796
Validation loss: 2.8416446147848906

Epoch: 5| Step: 10
Training loss: 3.2669442902232606
Validation loss: 2.909987215984446

Epoch: 39| Step: 0
Training loss: 2.96022914978937
Validation loss: 2.8591643601646974

Epoch: 5| Step: 1
Training loss: 3.223147896919637
Validation loss: 2.853811163005258

Epoch: 5| Step: 2
Training loss: 2.6060708878625496
Validation loss: 2.8288665345033834

Epoch: 5| Step: 3
Training loss: 3.4120643756871014
Validation loss: 2.811484598605043

Epoch: 5| Step: 4
Training loss: 3.024313945055446
Validation loss: 2.8155393942569873

Epoch: 5| Step: 5
Training loss: 3.192060461891442
Validation loss: 2.8729952652681336

Epoch: 5| Step: 6
Training loss: 3.3341950415373436
Validation loss: 2.8345740935497736

Epoch: 5| Step: 7
Training loss: 3.219841633095006
Validation loss: 2.810948053768471

Epoch: 5| Step: 8
Training loss: 2.0652446402404117
Validation loss: 2.8538954962049936

Epoch: 5| Step: 9
Training loss: 3.059130313428333
Validation loss: 2.839877360617945

Epoch: 5| Step: 10
Training loss: 3.0515182718489062
Validation loss: 2.804178687694307

Epoch: 40| Step: 0
Training loss: 2.604908850131358
Validation loss: 2.8902878413615904

Epoch: 5| Step: 1
Training loss: 3.2093479649371752
Validation loss: 2.8071204252412825

Epoch: 5| Step: 2
Training loss: 3.2748048971752484
Validation loss: 2.8500888614513613

Epoch: 5| Step: 3
Training loss: 2.882356767892301
Validation loss: 2.8001882031324397

Epoch: 5| Step: 4
Training loss: 3.496405936000469
Validation loss: 2.8599252837564357

Epoch: 5| Step: 5
Training loss: 3.014734640764197
Validation loss: 2.850743916254932

Epoch: 5| Step: 6
Training loss: 3.441857645002465
Validation loss: 2.833955248330816

Epoch: 5| Step: 7
Training loss: 3.6453787093316166
Validation loss: 2.835475445444988

Epoch: 5| Step: 8
Training loss: 3.037424778889932
Validation loss: 2.882164624306749

Epoch: 5| Step: 9
Training loss: 2.317646691577731
Validation loss: 2.9016775186014443

Epoch: 5| Step: 10
Training loss: 2.5768573765749987
Validation loss: 2.834503575179051

Epoch: 41| Step: 0
Training loss: 2.755604841020562
Validation loss: 2.8311643701288265

Epoch: 5| Step: 1
Training loss: 3.1871873290848014
Validation loss: 2.8016220251620836

Epoch: 5| Step: 2
Training loss: 2.513053290333767
Validation loss: 2.837766973821431

Epoch: 5| Step: 3
Training loss: 2.8182536295022556
Validation loss: 2.8104021458888555

Epoch: 5| Step: 4
Training loss: 3.106652069166649
Validation loss: 2.8293348892650836

Epoch: 5| Step: 5
Training loss: 2.5960347786794067
Validation loss: 2.8461482084200247

Epoch: 5| Step: 6
Training loss: 3.608198758641263
Validation loss: 2.884582084903189

Epoch: 5| Step: 7
Training loss: 2.739319173360202
Validation loss: 2.8256727587304473

Epoch: 5| Step: 8
Training loss: 3.456639775239329
Validation loss: 2.8167717181257776

Epoch: 5| Step: 9
Training loss: 3.492754111524219
Validation loss: 2.8277346388585656

Epoch: 5| Step: 10
Training loss: 3.081531169822226
Validation loss: 2.8052551698681385

Epoch: 42| Step: 0
Training loss: 4.13399265219631
Validation loss: 2.860802291369018

Epoch: 5| Step: 1
Training loss: 3.2931474340792892
Validation loss: 2.8517053325335042

Epoch: 5| Step: 2
Training loss: 3.1506781922768727
Validation loss: 2.7998139227287715

Epoch: 5| Step: 3
Training loss: 3.106319440529864
Validation loss: 2.857178233589808

Epoch: 5| Step: 4
Training loss: 2.829707761846805
Validation loss: 2.8207271919730377

Epoch: 5| Step: 5
Training loss: 3.1861701135808462
Validation loss: 2.836444555048202

Epoch: 5| Step: 6
Training loss: 2.735090064147172
Validation loss: 2.862509401188382

Epoch: 5| Step: 7
Training loss: 2.6408818588380827
Validation loss: 2.8541380184188827

Epoch: 5| Step: 8
Training loss: 3.2108189915972773
Validation loss: 2.811953733346317

Epoch: 5| Step: 9
Training loss: 2.5397937836626605
Validation loss: 2.847439052276651

Epoch: 5| Step: 10
Training loss: 2.455490332619961
Validation loss: 2.8808867139928633

Epoch: 43| Step: 0
Training loss: 2.492334343581152
Validation loss: 2.847335006203505

Epoch: 5| Step: 1
Training loss: 2.9840346536746276
Validation loss: 2.8192354737037526

Epoch: 5| Step: 2
Training loss: 2.5427704483273676
Validation loss: 2.7954741458793664

Epoch: 5| Step: 3
Training loss: 3.289995727072495
Validation loss: 2.8141667922318234

Epoch: 5| Step: 4
Training loss: 2.8817858017813593
Validation loss: 2.7818023688024516

Epoch: 5| Step: 5
Training loss: 3.1813915288653996
Validation loss: 2.831166173899237

Epoch: 5| Step: 6
Training loss: 2.9947193081725056
Validation loss: 2.7759374503425662

Epoch: 5| Step: 7
Training loss: 3.040014750294287
Validation loss: 2.8043323531588134

Epoch: 5| Step: 8
Training loss: 3.8749525005751835
Validation loss: 2.8437247669029477

Epoch: 5| Step: 9
Training loss: 3.804719834709237
Validation loss: 2.8896858824977496

Epoch: 5| Step: 10
Training loss: 2.669339767434327
Validation loss: 2.8048997713521504

Epoch: 44| Step: 0
Training loss: 2.949068543101639
Validation loss: 2.8137888836636353

Epoch: 5| Step: 1
Training loss: 3.762693791769093
Validation loss: 2.7972590034540152

Epoch: 5| Step: 2
Training loss: 3.1339349804860444
Validation loss: 2.815476493046163

Epoch: 5| Step: 3
Training loss: 3.401388356101584
Validation loss: 2.814134984386409

Epoch: 5| Step: 4
Training loss: 3.1234818394821358
Validation loss: 2.8134608706761943

Epoch: 5| Step: 5
Training loss: 2.7392982847110408
Validation loss: 2.8157229516621904

Epoch: 5| Step: 6
Training loss: 2.835472215887991
Validation loss: 2.8059112898028387

Epoch: 5| Step: 7
Training loss: 3.2232921366013314
Validation loss: 2.8553264289488944

Epoch: 5| Step: 8
Training loss: 3.0288361051995936
Validation loss: 2.7966060961735435

Epoch: 5| Step: 9
Training loss: 3.078795539125767
Validation loss: 2.8542116965656494

Epoch: 5| Step: 10
Training loss: 1.8279923610986746
Validation loss: 2.79600004331803

Epoch: 45| Step: 0
Training loss: 2.5928222651652333
Validation loss: 2.8409770620200248

Epoch: 5| Step: 1
Training loss: 3.202215893759979
Validation loss: 2.825076872563506

Epoch: 5| Step: 2
Training loss: 2.5609042153281423
Validation loss: 2.7809105362108046

Epoch: 5| Step: 3
Training loss: 2.2334019602959208
Validation loss: 2.8508259499514534

Epoch: 5| Step: 4
Training loss: 4.0632689701915
Validation loss: 2.888054042464594

Epoch: 5| Step: 5
Training loss: 3.643899255643372
Validation loss: 2.853162607009098

Epoch: 5| Step: 6
Training loss: 2.699713875480224
Validation loss: 2.859675259344074

Epoch: 5| Step: 7
Training loss: 3.1273405846478015
Validation loss: 2.813571783140462

Epoch: 5| Step: 8
Training loss: 3.760284181975004
Validation loss: 2.8097453930678826

Epoch: 5| Step: 9
Training loss: 2.624866573030827
Validation loss: 2.8141005871257097

Epoch: 5| Step: 10
Training loss: 2.804126906620857
Validation loss: 2.7999654636655626

Epoch: 46| Step: 0
Training loss: 3.105519113192244
Validation loss: 2.836226123620427

Epoch: 5| Step: 1
Training loss: 3.9687636968421374
Validation loss: 2.8015117148373014

Epoch: 5| Step: 2
Training loss: 3.1147125285388717
Validation loss: 2.8470848117034415

Epoch: 5| Step: 3
Training loss: 2.25351334821507
Validation loss: 2.859103951108146

Epoch: 5| Step: 4
Training loss: 2.477175663755803
Validation loss: 2.796685556180773

Epoch: 5| Step: 5
Training loss: 3.445624996900083
Validation loss: 2.8095480655501657

Epoch: 5| Step: 6
Training loss: 3.035440910275703
Validation loss: 2.8564816786985214

Epoch: 5| Step: 7
Training loss: 3.4946438814497673
Validation loss: 2.8118616890625563

Epoch: 5| Step: 8
Training loss: 2.8402282370609995
Validation loss: 2.840389773077002

Epoch: 5| Step: 9
Training loss: 2.35424813548769
Validation loss: 2.8028915984881104

Epoch: 5| Step: 10
Training loss: 2.728339897509838
Validation loss: 2.8357329500902626

Epoch: 47| Step: 0
Training loss: 2.8175004375900836
Validation loss: 2.825089004353051

Epoch: 5| Step: 1
Training loss: 3.7025998543945704
Validation loss: 2.8631922337532423

Epoch: 5| Step: 2
Training loss: 1.7605048689857503
Validation loss: 2.811230471175729

Epoch: 5| Step: 3
Training loss: 3.557941665951738
Validation loss: 2.7564192435822705

Epoch: 5| Step: 4
Training loss: 2.512932040897483
Validation loss: 2.8280992195723353

Epoch: 5| Step: 5
Training loss: 3.1624697597098224
Validation loss: 2.813706766922

Epoch: 5| Step: 6
Training loss: 3.0425164764384456
Validation loss: 2.8108116396381044

Epoch: 5| Step: 7
Training loss: 3.0631611947172774
Validation loss: 2.8425581781985665

Epoch: 5| Step: 8
Training loss: 3.5413303140728885
Validation loss: 2.7909433465202205

Epoch: 5| Step: 9
Training loss: 3.2663339821741237
Validation loss: 2.8336411447068173

Epoch: 5| Step: 10
Training loss: 2.576507245750018
Validation loss: 2.8020288084170213

Epoch: 48| Step: 0
Training loss: 2.9084841436800177
Validation loss: 2.837154677635798

Epoch: 5| Step: 1
Training loss: 3.0912698379663666
Validation loss: 2.8552280270296926

Epoch: 5| Step: 2
Training loss: 2.8011184978812236
Validation loss: 2.7675509950432082

Epoch: 5| Step: 3
Training loss: 3.9826002768555573
Validation loss: 2.858062348701418

Epoch: 5| Step: 4
Training loss: 3.208018663176094
Validation loss: 2.7787333494470663

Epoch: 5| Step: 5
Training loss: 2.4179212229653615
Validation loss: 2.8405447584693255

Epoch: 5| Step: 6
Training loss: 2.7658343909356313
Validation loss: 2.851027231047516

Epoch: 5| Step: 7
Training loss: 3.3658659923984167
Validation loss: 2.797645454021543

Epoch: 5| Step: 8
Training loss: 3.031681148109291
Validation loss: 2.8588307584082457

Epoch: 5| Step: 9
Training loss: 2.7485620033469638
Validation loss: 2.7997370311492507

Epoch: 5| Step: 10
Training loss: 2.5261889123113526
Validation loss: 2.773522720518134

Epoch: 49| Step: 0
Training loss: 2.4520783347892103
Validation loss: 2.7600020360560173

Epoch: 5| Step: 1
Training loss: 3.1367062845136804
Validation loss: 2.854165606180031

Epoch: 5| Step: 2
Training loss: 2.8353988934664556
Validation loss: 2.816280278259117

Epoch: 5| Step: 3
Training loss: 3.851074435433698
Validation loss: 2.794368421577221

Epoch: 5| Step: 4
Training loss: 2.435093400797076
Validation loss: 2.803894280883341

Epoch: 5| Step: 5
Training loss: 2.723630098852404
Validation loss: 2.828607358868393

Epoch: 5| Step: 6
Training loss: 3.5227300436954283
Validation loss: 2.8403391070550494

Epoch: 5| Step: 7
Training loss: 3.1751352476614887
Validation loss: 2.825232558243484

Epoch: 5| Step: 8
Training loss: 2.9253519351869697
Validation loss: 2.867986704884455

Epoch: 5| Step: 9
Training loss: 3.0612349719562255
Validation loss: 2.859324428309056

Epoch: 5| Step: 10
Training loss: 2.9378381088142134
Validation loss: 2.8149007306512535

Epoch: 50| Step: 0
Training loss: 2.7860760768244055
Validation loss: 2.803063138345331

Epoch: 5| Step: 1
Training loss: 2.7333142648202338
Validation loss: 2.8398146482205013

Epoch: 5| Step: 2
Training loss: 2.6098629615148305
Validation loss: 2.8336525006799747

Epoch: 5| Step: 3
Training loss: 2.6804561124374198
Validation loss: 2.860364180128454

Epoch: 5| Step: 4
Training loss: 3.635143295255164
Validation loss: 2.7569540517215705

Epoch: 5| Step: 5
Training loss: 2.3847060387467782
Validation loss: 2.7835153145774942

Epoch: 5| Step: 6
Training loss: 3.0196236303886717
Validation loss: 2.8226779306583722

Epoch: 5| Step: 7
Training loss: 3.6769509152063633
Validation loss: 2.8280995930457498

Epoch: 5| Step: 8
Training loss: 2.7830799383374294
Validation loss: 2.8166750328967356

Epoch: 5| Step: 9
Training loss: 3.2224955570731892
Validation loss: 2.826300755655449

Epoch: 5| Step: 10
Training loss: 3.4984492544953825
Validation loss: 2.8304319027048734

Epoch: 51| Step: 0
Training loss: 2.7268680084369707
Validation loss: 2.846209731926383

Epoch: 5| Step: 1
Training loss: 2.6586538769303716
Validation loss: 2.847910429821397

Epoch: 5| Step: 2
Training loss: 3.384155993362976
Validation loss: 2.8369267066545443

Epoch: 5| Step: 3
Training loss: 3.0141708742139954
Validation loss: 2.793363145386292

Epoch: 5| Step: 4
Training loss: 2.9892109141616725
Validation loss: 2.8005922351865777

Epoch: 5| Step: 5
Training loss: 3.2409062439170238
Validation loss: 2.784536733494919

Epoch: 5| Step: 6
Training loss: 2.683528538429383
Validation loss: 2.8273936964449913

Epoch: 5| Step: 7
Training loss: 3.1844614543166196
Validation loss: 2.8299875317014114

Epoch: 5| Step: 8
Training loss: 2.6823797020153
Validation loss: 2.8205916466244076

Epoch: 5| Step: 9
Training loss: 3.645864882559737
Validation loss: 2.8643961491586833

Epoch: 5| Step: 10
Training loss: 2.7479486617355464
Validation loss: 2.850427969775976

Epoch: 52| Step: 0
Training loss: 3.239354083585988
Validation loss: 2.7768620323546824

Epoch: 5| Step: 1
Training loss: 2.9272160799780114
Validation loss: 2.7795850797065214

Epoch: 5| Step: 2
Training loss: 2.69526420218276
Validation loss: 2.804712255261654

Epoch: 5| Step: 3
Training loss: 3.48678491842884
Validation loss: 2.79325895275421

Epoch: 5| Step: 4
Training loss: 3.102421178070072
Validation loss: 2.760284563379692

Epoch: 5| Step: 5
Training loss: 2.943069696884981
Validation loss: 2.8111532781207726

Epoch: 5| Step: 6
Training loss: 3.145213253390262
Validation loss: 2.802913639886706

Epoch: 5| Step: 7
Training loss: 3.314607921215829
Validation loss: 2.790936449066948

Epoch: 5| Step: 8
Training loss: 2.9268335708726103
Validation loss: 2.778589395338426

Epoch: 5| Step: 9
Training loss: 3.195734942802046
Validation loss: 2.7835054634555636

Epoch: 5| Step: 10
Training loss: 2.6115250552438245
Validation loss: 2.740157935328304

Epoch: 53| Step: 0
Training loss: 2.6385329045450048
Validation loss: 2.8553502127646118

Epoch: 5| Step: 1
Training loss: 3.0233469710485816
Validation loss: 2.794595538942562

Epoch: 5| Step: 2
Training loss: 2.929668945253743
Validation loss: 2.785773800174322

Epoch: 5| Step: 3
Training loss: 2.856152161773531
Validation loss: 2.8139473767397987

Epoch: 5| Step: 4
Training loss: 3.0668495586701243
Validation loss: 2.7784238593768102

Epoch: 5| Step: 5
Training loss: 2.9290655264253243
Validation loss: 2.775005618607704

Epoch: 5| Step: 6
Training loss: 3.0647475111546965
Validation loss: 2.8553904589469314

Epoch: 5| Step: 7
Training loss: 3.183307957839354
Validation loss: 2.7997519620560722

Epoch: 5| Step: 8
Training loss: 3.593658711476413
Validation loss: 2.8236421545018167

Epoch: 5| Step: 9
Training loss: 2.856249993322193
Validation loss: 2.799961826910985

Epoch: 5| Step: 10
Training loss: 3.0491953304250514
Validation loss: 2.7580847529242374

Epoch: 54| Step: 0
Training loss: 3.9432343401270518
Validation loss: 2.8361027379414345

Epoch: 5| Step: 1
Training loss: 3.2232487914061596
Validation loss: 2.8101009031115045

Epoch: 5| Step: 2
Training loss: 2.801889282843669
Validation loss: 2.778445081304211

Epoch: 5| Step: 3
Training loss: 3.2656445662354927
Validation loss: 2.823803158594044

Epoch: 5| Step: 4
Training loss: 2.0599644420851124
Validation loss: 2.8704004594294106

Epoch: 5| Step: 5
Training loss: 3.1438284710595035
Validation loss: 2.8223650235558764

Epoch: 5| Step: 6
Training loss: 3.112795228246729
Validation loss: 2.823052159258112

Epoch: 5| Step: 7
Training loss: 2.687295772865692
Validation loss: 2.8375816513802663

Epoch: 5| Step: 8
Training loss: 2.955643644510028
Validation loss: 2.813348911379128

Epoch: 5| Step: 9
Training loss: 2.6323685540605326
Validation loss: 2.7648677077625083

Epoch: 5| Step: 10
Training loss: 2.9883808194196066
Validation loss: 2.881200989661009

Epoch: 55| Step: 0
Training loss: 3.169266854594274
Validation loss: 2.7847191749362206

Epoch: 5| Step: 1
Training loss: 2.9103199343124033
Validation loss: 2.7815817588645433

Epoch: 5| Step: 2
Training loss: 2.9618562666941934
Validation loss: 2.758379809804022

Epoch: 5| Step: 3
Training loss: 3.478206083135773
Validation loss: 2.7623438591169425

Epoch: 5| Step: 4
Training loss: 3.0514924884661814
Validation loss: 2.759276767244277

Epoch: 5| Step: 5
Training loss: 2.641406242779041
Validation loss: 2.8474732916986047

Epoch: 5| Step: 6
Training loss: 2.624031796600009
Validation loss: 2.7901252405557506

Epoch: 5| Step: 7
Training loss: 3.715013437978435
Validation loss: 2.7871479317734837

Epoch: 5| Step: 8
Training loss: 2.947139911738632
Validation loss: 2.793719545352412

Epoch: 5| Step: 9
Training loss: 2.772663019064011
Validation loss: 2.7557306215481874

Epoch: 5| Step: 10
Training loss: 2.7391238582721686
Validation loss: 2.7850196072053977

Epoch: 56| Step: 0
Training loss: 2.61527330228567
Validation loss: 2.79437095643834

Epoch: 5| Step: 1
Training loss: 3.2657737880559665
Validation loss: 2.771628298550472

Epoch: 5| Step: 2
Training loss: 3.5946869002073685
Validation loss: 2.7993919407428476

Epoch: 5| Step: 3
Training loss: 2.5483750682412976
Validation loss: 2.781927521456161

Epoch: 5| Step: 4
Training loss: 3.399753359656277
Validation loss: 2.819548218943307

Epoch: 5| Step: 5
Training loss: 3.3101503207829097
Validation loss: 2.778779613423117

Epoch: 5| Step: 6
Training loss: 2.4089994699454604
Validation loss: 2.8315074896016146

Epoch: 5| Step: 7
Training loss: 3.140488654825689
Validation loss: 2.798589041305564

Epoch: 5| Step: 8
Training loss: 3.3749638308247096
Validation loss: 2.766959890944414

Epoch: 5| Step: 9
Training loss: 2.7200182883264894
Validation loss: 2.7658304627478976

Epoch: 5| Step: 10
Training loss: 2.954153860590788
Validation loss: 2.7995766209750235

Epoch: 57| Step: 0
Training loss: 3.0894597679391853
Validation loss: 2.77977230613125

Epoch: 5| Step: 1
Training loss: 3.4354740067865674
Validation loss: 2.8092888552072317

Epoch: 5| Step: 2
Training loss: 2.958697516004456
Validation loss: 2.759756827979234

Epoch: 5| Step: 3
Training loss: 3.175492952781357
Validation loss: 2.828326391078064

Epoch: 5| Step: 4
Training loss: 2.8174724280320733
Validation loss: 2.817282881455327

Epoch: 5| Step: 5
Training loss: 3.1274706420008402
Validation loss: 2.8121777968617048

Epoch: 5| Step: 6
Training loss: 2.6298614172449417
Validation loss: 2.7890247307829354

Epoch: 5| Step: 7
Training loss: 2.8908572541830044
Validation loss: 2.7466028677711725

Epoch: 5| Step: 8
Training loss: 2.822065997075867
Validation loss: 2.863540895278753

Epoch: 5| Step: 9
Training loss: 3.3788649010746723
Validation loss: 2.812421099833335

Epoch: 5| Step: 10
Training loss: 2.696646363080155
Validation loss: 2.8141886209730447

Epoch: 58| Step: 0
Training loss: 3.0399400870793865
Validation loss: 2.8239493560627142

Epoch: 5| Step: 1
Training loss: 3.5652955447153314
Validation loss: 2.7558827079191652

Epoch: 5| Step: 2
Training loss: 2.833681664839741
Validation loss: 2.824677853843027

Epoch: 5| Step: 3
Training loss: 2.0309667536513873
Validation loss: 2.8492361052805326

Epoch: 5| Step: 4
Training loss: 2.580022402673496
Validation loss: 2.790194655186578

Epoch: 5| Step: 5
Training loss: 3.2778992028743197
Validation loss: 2.7845411840122276

Epoch: 5| Step: 6
Training loss: 3.4086398918741163
Validation loss: 2.8191829734397733

Epoch: 5| Step: 7
Training loss: 2.43568509343668
Validation loss: 2.77224802903149

Epoch: 5| Step: 8
Training loss: 3.547990934289405
Validation loss: 2.8028869489048063

Epoch: 5| Step: 9
Training loss: 2.6294305740478854
Validation loss: 2.751518193075755

Epoch: 5| Step: 10
Training loss: 3.322425798056858
Validation loss: 2.7933750257812595

Epoch: 59| Step: 0
Training loss: 2.6950414548951778
Validation loss: 2.8292051555144258

Epoch: 5| Step: 1
Training loss: 2.603540716601238
Validation loss: 2.76638047893699

Epoch: 5| Step: 2
Training loss: 2.5782090606856936
Validation loss: 2.770893850937069

Epoch: 5| Step: 3
Training loss: 3.41698297726681
Validation loss: 2.803113096213302

Epoch: 5| Step: 4
Training loss: 3.634533546249906
Validation loss: 2.8161073072362965

Epoch: 5| Step: 5
Training loss: 2.4136371916887236
Validation loss: 2.7893833200967366

Epoch: 5| Step: 6
Training loss: 4.023319694498032
Validation loss: 2.701887820794018

Epoch: 5| Step: 7
Training loss: 2.7276575026591487
Validation loss: 2.806459141834199

Epoch: 5| Step: 8
Training loss: 2.744814057714253
Validation loss: 2.754611341304415

Epoch: 5| Step: 9
Training loss: 2.6727131203870647
Validation loss: 2.7688492036478287

Epoch: 5| Step: 10
Training loss: 3.1672505459488027
Validation loss: 2.7277137466577837

Epoch: 60| Step: 0
Training loss: 3.4394578386715287
Validation loss: 2.7643361519085587

Epoch: 5| Step: 1
Training loss: 3.2144349442006206
Validation loss: 2.8149417418525515

Epoch: 5| Step: 2
Training loss: 3.2117776258932493
Validation loss: 2.7703138939816307

Epoch: 5| Step: 3
Training loss: 3.1737519522109157
Validation loss: 2.781999575261973

Epoch: 5| Step: 4
Training loss: 2.6745931619024894
Validation loss: 2.7935538588549402

Epoch: 5| Step: 5
Training loss: 2.5752155880352268
Validation loss: 2.7526529907574364

Epoch: 5| Step: 6
Training loss: 3.251825113612207
Validation loss: 2.809200522711209

Epoch: 5| Step: 7
Training loss: 2.586995717909564
Validation loss: 2.7757191469033384

Epoch: 5| Step: 8
Training loss: 2.8022051268323414
Validation loss: 2.825221785466722

Epoch: 5| Step: 9
Training loss: 3.203531527889667
Validation loss: 2.7803436457960737

Epoch: 5| Step: 10
Training loss: 2.579775565092351
Validation loss: 2.777045934382665

Epoch: 61| Step: 0
Training loss: 2.5426541791621586
Validation loss: 2.7871305289540285

Epoch: 5| Step: 1
Training loss: 3.2895929266749677
Validation loss: 2.7954240368200542

Epoch: 5| Step: 2
Training loss: 2.9712998532617276
Validation loss: 2.7895231109321066

Epoch: 5| Step: 3
Training loss: 3.0053751792848957
Validation loss: 2.789646005721798

Epoch: 5| Step: 4
Training loss: 3.2672150313805943
Validation loss: 2.8202700861286574

Epoch: 5| Step: 5
Training loss: 3.1552974661051176
Validation loss: 2.8025879037195103

Epoch: 5| Step: 6
Training loss: 2.648134467418854
Validation loss: 2.7638930796866648

Epoch: 5| Step: 7
Training loss: 3.877529795155273
Validation loss: 2.7618983398133294

Epoch: 5| Step: 8
Training loss: 2.8312480395986075
Validation loss: 2.78875105551061

Epoch: 5| Step: 9
Training loss: 2.478929321297114
Validation loss: 2.744814912318888

Epoch: 5| Step: 10
Training loss: 2.867860470823981
Validation loss: 2.7547192729860934

Epoch: 62| Step: 0
Training loss: 2.895686651306759
Validation loss: 2.7468422391115364

Epoch: 5| Step: 1
Training loss: 4.1881014263911105
Validation loss: 2.7521895504426452

Epoch: 5| Step: 2
Training loss: 3.084419746422192
Validation loss: 2.797947492649503

Epoch: 5| Step: 3
Training loss: 1.9870161367220938
Validation loss: 2.743211874439335

Epoch: 5| Step: 4
Training loss: 2.7170568872420615
Validation loss: 2.756783749819085

Epoch: 5| Step: 5
Training loss: 2.719673350719354
Validation loss: 2.7598313593159096

Epoch: 5| Step: 6
Training loss: 3.9153935953919037
Validation loss: 2.80502360374088

Epoch: 5| Step: 7
Training loss: 2.5837717812205554
Validation loss: 2.774884069139117

Epoch: 5| Step: 8
Training loss: 2.843793260853122
Validation loss: 2.7917278318602636

Epoch: 5| Step: 9
Training loss: 2.3385679814161557
Validation loss: 2.764655499758578

Epoch: 5| Step: 10
Training loss: 2.780058444801557
Validation loss: 2.7724182234034656

Epoch: 63| Step: 0
Training loss: 3.256653064815212
Validation loss: 2.7159651809069314

Epoch: 5| Step: 1
Training loss: 3.764680356139008
Validation loss: 2.8024992342341712

Epoch: 5| Step: 2
Training loss: 2.6873305511283556
Validation loss: 2.7593975139941564

Epoch: 5| Step: 3
Training loss: 2.5194197755741694
Validation loss: 2.7848327961596717

Epoch: 5| Step: 4
Training loss: 2.444559292070104
Validation loss: 2.7878714065852472

Epoch: 5| Step: 5
Training loss: 3.091129927472416
Validation loss: 2.80314322835965

Epoch: 5| Step: 6
Training loss: 3.0424779219441476
Validation loss: 2.7812464429319412

Epoch: 5| Step: 7
Training loss: 2.402761432344655
Validation loss: 2.8085144060057554

Epoch: 5| Step: 8
Training loss: 3.7275622164512088
Validation loss: 2.751741143368638

Epoch: 5| Step: 9
Training loss: 2.506712580202867
Validation loss: 2.7345231154680913

Epoch: 5| Step: 10
Training loss: 3.3947992603130843
Validation loss: 2.780734523351498

Epoch: 64| Step: 0
Training loss: 2.409524844169574
Validation loss: 2.7809577097909033

Epoch: 5| Step: 1
Training loss: 3.060238061258821
Validation loss: 2.7361455235755834

Epoch: 5| Step: 2
Training loss: 3.1414206336810873
Validation loss: 2.778996169073811

Epoch: 5| Step: 3
Training loss: 2.696743527210234
Validation loss: 2.7873129220278803

Epoch: 5| Step: 4
Training loss: 2.6814428869193816
Validation loss: 2.767305821285682

Epoch: 5| Step: 5
Training loss: 3.1051134206109765
Validation loss: 2.7372187121315967

Epoch: 5| Step: 6
Training loss: 2.285427501262158
Validation loss: 2.778045877077184

Epoch: 5| Step: 7
Training loss: 3.5695794686500273
Validation loss: 2.7906267478821736

Epoch: 5| Step: 8
Training loss: 2.812548149544441
Validation loss: 2.7923433447654573

Epoch: 5| Step: 9
Training loss: 3.969167732421766
Validation loss: 2.7720132921841856

Epoch: 5| Step: 10
Training loss: 3.157645644017643
Validation loss: 2.8038310205919563

Epoch: 65| Step: 0
Training loss: 3.536214394037865
Validation loss: 2.812950778144169

Epoch: 5| Step: 1
Training loss: 3.329662129212866
Validation loss: 2.805687192757257

Epoch: 5| Step: 2
Training loss: 2.8692953484808714
Validation loss: 2.7897112601894976

Epoch: 5| Step: 3
Training loss: 3.0071984394995965
Validation loss: 2.769076741138399

Epoch: 5| Step: 4
Training loss: 2.906149749667535
Validation loss: 2.7652472262411285

Epoch: 5| Step: 5
Training loss: 2.8192588127007285
Validation loss: 2.850251428839953

Epoch: 5| Step: 6
Training loss: 2.8246788821388047
Validation loss: 2.768354761005008

Epoch: 5| Step: 7
Training loss: 3.10387420983416
Validation loss: 2.7737534320678843

Epoch: 5| Step: 8
Training loss: 2.9046910524474816
Validation loss: 2.813023346914784

Epoch: 5| Step: 9
Training loss: 2.6055267647799867
Validation loss: 2.7582064868934695

Epoch: 5| Step: 10
Training loss: 3.002400709252664
Validation loss: 2.759322034422969

Epoch: 66| Step: 0
Training loss: 2.8776819739315913
Validation loss: 2.727630529226337

Epoch: 5| Step: 1
Training loss: 3.348983376954662
Validation loss: 2.8150357991518087

Epoch: 5| Step: 2
Training loss: 3.9049111475097984
Validation loss: 2.789724300699435

Epoch: 5| Step: 3
Training loss: 3.037722255283412
Validation loss: 2.7377504689773193

Epoch: 5| Step: 4
Training loss: 3.1669385860211112
Validation loss: 2.7911111756221607

Epoch: 5| Step: 5
Training loss: 3.206213973588412
Validation loss: 2.7361244101879842

Epoch: 5| Step: 6
Training loss: 2.353319899148752
Validation loss: 2.7890564178026374

Epoch: 5| Step: 7
Training loss: 2.5654066394805937
Validation loss: 2.7939982521220257

Epoch: 5| Step: 8
Training loss: 2.0414129865135933
Validation loss: 2.7993428579095143

Epoch: 5| Step: 9
Training loss: 2.7510871472271075
Validation loss: 2.8092800709046513

Epoch: 5| Step: 10
Training loss: 2.9160955869080945
Validation loss: 2.795213749640878

Epoch: 67| Step: 0
Training loss: 2.7333996586389735
Validation loss: 2.7338371476829875

Epoch: 5| Step: 1
Training loss: 2.5321543455583875
Validation loss: 2.745257394600516

Epoch: 5| Step: 2
Training loss: 3.081798704243839
Validation loss: 2.7277331187686604

Epoch: 5| Step: 3
Training loss: 2.87603127600757
Validation loss: 2.7658781317355134

Epoch: 5| Step: 4
Training loss: 2.9435263967935814
Validation loss: 2.737875715772945

Epoch: 5| Step: 5
Training loss: 2.4960733093475453
Validation loss: 2.786129510104776

Epoch: 5| Step: 6
Training loss: 2.9051037240346345
Validation loss: 2.7286117679704893

Epoch: 5| Step: 7
Training loss: 2.9778732657740354
Validation loss: 2.8120488523929343

Epoch: 5| Step: 8
Training loss: 3.6670388697511274
Validation loss: 2.7725026134627075

Epoch: 5| Step: 9
Training loss: 3.3653604812595104
Validation loss: 2.84209676071607

Epoch: 5| Step: 10
Training loss: 2.73282583766712
Validation loss: 2.7526748090437767

Epoch: 68| Step: 0
Training loss: 3.112238959584038
Validation loss: 2.783515831263088

Epoch: 5| Step: 1
Training loss: 2.8247479250362035
Validation loss: 2.7779188219447146

Epoch: 5| Step: 2
Training loss: 2.5539673889814476
Validation loss: 2.7861594909987355

Epoch: 5| Step: 3
Training loss: 3.302652079382006
Validation loss: 2.7585109748911303

Epoch: 5| Step: 4
Training loss: 2.550468671027843
Validation loss: 2.7777545639490064

Epoch: 5| Step: 5
Training loss: 2.812798208745618
Validation loss: 2.707265924355347

Epoch: 5| Step: 6
Training loss: 2.5884921544416466
Validation loss: 2.7468479378638198

Epoch: 5| Step: 7
Training loss: 3.4981481557696146
Validation loss: 2.772984887800255

Epoch: 5| Step: 8
Training loss: 3.035208565397348
Validation loss: 2.7936482187084213

Epoch: 5| Step: 9
Training loss: 2.486699102853239
Validation loss: 2.756752218198168

Epoch: 5| Step: 10
Training loss: 4.0351973731871125
Validation loss: 2.7745805325212856

Epoch: 69| Step: 0
Training loss: 3.0519006216585725
Validation loss: 2.7794607448523845

Epoch: 5| Step: 1
Training loss: 3.6027235695839126
Validation loss: 2.804830050678421

Epoch: 5| Step: 2
Training loss: 2.4347128950676487
Validation loss: 2.832397831892508

Epoch: 5| Step: 3
Training loss: 2.696900538459522
Validation loss: 2.754257104627519

Epoch: 5| Step: 4
Training loss: 3.006706054102457
Validation loss: 2.8164935309326697

Epoch: 5| Step: 5
Training loss: 2.929460603192878
Validation loss: 2.787331608595788

Epoch: 5| Step: 6
Training loss: 3.7880226202735514
Validation loss: 2.8357022222131336

Epoch: 5| Step: 7
Training loss: 3.3598257782590313
Validation loss: 2.785702233271726

Epoch: 5| Step: 8
Training loss: 2.5813776940633772
Validation loss: 2.8351725743891976

Epoch: 5| Step: 9
Training loss: 2.8744330469131687
Validation loss: 2.7732929798112744

Epoch: 5| Step: 10
Training loss: 2.512303878948939
Validation loss: 2.7651353414983486

Epoch: 70| Step: 0
Training loss: 3.2367760043889184
Validation loss: 2.7314898489522332

Epoch: 5| Step: 1
Training loss: 3.6714116230224123
Validation loss: 2.7967482475266814

Epoch: 5| Step: 2
Training loss: 3.5560568383290443
Validation loss: 2.7561126827690012

Epoch: 5| Step: 3
Training loss: 2.925985128024643
Validation loss: 2.7579153490786035

Epoch: 5| Step: 4
Training loss: 2.9424278643248623
Validation loss: 2.7338161927650093

Epoch: 5| Step: 5
Training loss: 2.6343068033715342
Validation loss: 2.7982320595406094

Epoch: 5| Step: 6
Training loss: 2.9601940338872583
Validation loss: 2.7765585900923986

Epoch: 5| Step: 7
Training loss: 2.538475743500772
Validation loss: 2.7982920447626802

Epoch: 5| Step: 8
Training loss: 2.53910484865525
Validation loss: 2.752212119452933

Epoch: 5| Step: 9
Training loss: 2.9358772503089834
Validation loss: 2.820922490174458

Epoch: 5| Step: 10
Training loss: 2.643629723376337
Validation loss: 2.7542729243238857

Epoch: 71| Step: 0
Training loss: 2.9804941878726874
Validation loss: 2.7720162433146642

Epoch: 5| Step: 1
Training loss: 3.0677964479046467
Validation loss: 2.7893684605211813

Epoch: 5| Step: 2
Training loss: 3.0227188715162883
Validation loss: 2.777516246057846

Epoch: 5| Step: 3
Training loss: 2.7171867524157522
Validation loss: 2.7458181738176286

Epoch: 5| Step: 4
Training loss: 3.0213527539811134
Validation loss: 2.785549712064856

Epoch: 5| Step: 5
Training loss: 2.4881826527941575
Validation loss: 2.765350991003687

Epoch: 5| Step: 6
Training loss: 3.071132094309563
Validation loss: 2.768012528424099

Epoch: 5| Step: 7
Training loss: 2.8712051888980996
Validation loss: 2.7288455118196304

Epoch: 5| Step: 8
Training loss: 3.107154551767475
Validation loss: 2.7562977822570103

Epoch: 5| Step: 9
Training loss: 3.433145574108389
Validation loss: 2.744760223623893

Epoch: 5| Step: 10
Training loss: 3.0446547023381365
Validation loss: 2.7460434185704163

Epoch: 72| Step: 0
Training loss: 2.3346156842656125
Validation loss: 2.7985189614164567

Epoch: 5| Step: 1
Training loss: 2.2647604509544754
Validation loss: 2.7509233932479256

Epoch: 5| Step: 2
Training loss: 3.1380711130675394
Validation loss: 2.8004622940624455

Epoch: 5| Step: 3
Training loss: 3.1793242675861038
Validation loss: 2.767986373356935

Epoch: 5| Step: 4
Training loss: 3.418049524715194
Validation loss: 2.7758861509654222

Epoch: 5| Step: 5
Training loss: 3.199926947713514
Validation loss: 2.81004424994135

Epoch: 5| Step: 6
Training loss: 2.942479883739384
Validation loss: 2.7713679031535574

Epoch: 5| Step: 7
Training loss: 2.814692850379945
Validation loss: 2.7449715844055786

Epoch: 5| Step: 8
Training loss: 3.1137622954601714
Validation loss: 2.7382915390664175

Epoch: 5| Step: 9
Training loss: 2.764275862942726
Validation loss: 2.771199359414363

Epoch: 5| Step: 10
Training loss: 2.904433800676932
Validation loss: 2.7246070904442288

Epoch: 73| Step: 0
Training loss: 2.8657098023358216
Validation loss: 2.767522117298192

Epoch: 5| Step: 1
Training loss: 3.065057581847608
Validation loss: 2.7086563340546816

Epoch: 5| Step: 2
Training loss: 2.549797300622439
Validation loss: 2.7611828128352216

Epoch: 5| Step: 3
Training loss: 2.880838850562481
Validation loss: 2.8073534091843904

Epoch: 5| Step: 4
Training loss: 2.853484543272714
Validation loss: 2.792116268235059

Epoch: 5| Step: 5
Training loss: 3.8106827704336506
Validation loss: 2.7909618948807227

Epoch: 5| Step: 6
Training loss: 2.3117509608266227
Validation loss: 2.7611067655555885

Epoch: 5| Step: 7
Training loss: 2.748834102743918
Validation loss: 2.7838595265841724

Epoch: 5| Step: 8
Training loss: 3.0405351458893994
Validation loss: 2.725053390223751

Epoch: 5| Step: 9
Training loss: 3.233845100670692
Validation loss: 2.7457235548860144

Epoch: 5| Step: 10
Training loss: 3.0638404559536996
Validation loss: 2.7399717427021137

Epoch: 74| Step: 0
Training loss: 3.265848982581155
Validation loss: 2.724642646684316

Epoch: 5| Step: 1
Training loss: 3.52955113958535
Validation loss: 2.739159073518899

Epoch: 5| Step: 2
Training loss: 2.796144528606044
Validation loss: 2.8137568355688343

Epoch: 5| Step: 3
Training loss: 3.1684166606906654
Validation loss: 2.794466078581865

Epoch: 5| Step: 4
Training loss: 2.231313675685092
Validation loss: 2.753061701696537

Epoch: 5| Step: 5
Training loss: 2.700493650872844
Validation loss: 2.7737678872947256

Epoch: 5| Step: 6
Training loss: 3.383841765462588
Validation loss: 2.747030859105124

Epoch: 5| Step: 7
Training loss: 3.2030338925686315
Validation loss: 2.76575860410552

Epoch: 5| Step: 8
Training loss: 2.7310745811433517
Validation loss: 2.7701616193940106

Epoch: 5| Step: 9
Training loss: 2.280197005042639
Validation loss: 2.7194913891221084

Epoch: 5| Step: 10
Training loss: 3.1458920774385484
Validation loss: 2.7313640343246077

Epoch: 75| Step: 0
Training loss: 2.4260626244257377
Validation loss: 2.74403166435097

Epoch: 5| Step: 1
Training loss: 3.0422663337042715
Validation loss: 2.7815108407955713

Epoch: 5| Step: 2
Training loss: 3.5870656086111605
Validation loss: 2.72577200392288

Epoch: 5| Step: 3
Training loss: 2.8713172877477238
Validation loss: 2.764887459332394

Epoch: 5| Step: 4
Training loss: 2.9796165357839897
Validation loss: 2.771802712451782

Epoch: 5| Step: 5
Training loss: 3.127890813790207
Validation loss: 2.7270374297585254

Epoch: 5| Step: 6
Training loss: 2.2983826340921856
Validation loss: 2.7353257849344224

Epoch: 5| Step: 7
Training loss: 3.0443806145776215
Validation loss: 2.7967263816605525

Epoch: 5| Step: 8
Training loss: 3.13599308498749
Validation loss: 2.770597621956161

Epoch: 5| Step: 9
Training loss: 2.6849260646081317
Validation loss: 2.7337798190121734

Epoch: 5| Step: 10
Training loss: 2.718317720971413
Validation loss: 2.7907654907593145

Epoch: 76| Step: 0
Training loss: 3.1478180003698037
Validation loss: 2.7669851607055125

Epoch: 5| Step: 1
Training loss: 3.171386380448885
Validation loss: 2.7979619474919546

Epoch: 5| Step: 2
Training loss: 3.3568888136217803
Validation loss: 2.7513063614966162

Epoch: 5| Step: 3
Training loss: 3.3542687220872964
Validation loss: 2.7829082155024185

Epoch: 5| Step: 4
Training loss: 3.3009294645902685
Validation loss: 2.7987227737242772

Epoch: 5| Step: 5
Training loss: 2.696966487530626
Validation loss: 2.759483461679391

Epoch: 5| Step: 6
Training loss: 2.4151903005616857
Validation loss: 2.718394954903887

Epoch: 5| Step: 7
Training loss: 2.514898728441932
Validation loss: 2.7447300305664886

Epoch: 5| Step: 8
Training loss: 3.4595462250138835
Validation loss: 2.724638549022784

Epoch: 5| Step: 9
Training loss: 2.734655921674376
Validation loss: 2.734722893260436

Epoch: 5| Step: 10
Training loss: 2.604913517986297
Validation loss: 2.7946067618605555

Epoch: 77| Step: 0
Training loss: 2.611845754079484
Validation loss: 2.7875854629180004

Epoch: 5| Step: 1
Training loss: 2.8353746764703316
Validation loss: 2.7744500328899546

Epoch: 5| Step: 2
Training loss: 3.4370295809598534
Validation loss: 2.74400589919152

Epoch: 5| Step: 3
Training loss: 3.3482084408663644
Validation loss: 2.7349369982176173

Epoch: 5| Step: 4
Training loss: 2.6593571161370337
Validation loss: 2.7090303803475235

Epoch: 5| Step: 5
Training loss: 2.7552220440951882
Validation loss: 2.8227212828656567

Epoch: 5| Step: 6
Training loss: 3.238160208175852
Validation loss: 2.7659435632179448

Epoch: 5| Step: 7
Training loss: 2.4817869513442914
Validation loss: 2.698289050570045

Epoch: 5| Step: 8
Training loss: 2.6884297381728772
Validation loss: 2.8158709087947527

Epoch: 5| Step: 9
Training loss: 3.6042492954433123
Validation loss: 2.7344619319943533

Epoch: 5| Step: 10
Training loss: 2.305345240987836
Validation loss: 2.7659227291951543

Epoch: 78| Step: 0
Training loss: 3.032450644648886
Validation loss: 2.7419554993769344

Epoch: 5| Step: 1
Training loss: 2.820454010094666
Validation loss: 2.7880806246330234

Epoch: 5| Step: 2
Training loss: 3.514178576148838
Validation loss: 2.7949533823420336

Epoch: 5| Step: 3
Training loss: 2.7471383551162614
Validation loss: 2.7290005511620365

Epoch: 5| Step: 4
Training loss: 2.472201674681961
Validation loss: 2.814649247911891

Epoch: 5| Step: 5
Training loss: 2.5653672343226095
Validation loss: 2.7810969912657244

Epoch: 5| Step: 6
Training loss: 2.9493434045986424
Validation loss: 2.815929004266452

Epoch: 5| Step: 7
Training loss: 2.8744567689589227
Validation loss: 2.769218748512854

Epoch: 5| Step: 8
Training loss: 3.4779601298805973
Validation loss: 2.7788872983183404

Epoch: 5| Step: 9
Training loss: 3.3030551639561962
Validation loss: 2.766190589861534

Epoch: 5| Step: 10
Training loss: 2.3718780276313125
Validation loss: 2.757379912937576

Epoch: 79| Step: 0
Training loss: 2.14812386737757
Validation loss: 2.705238046076669

Epoch: 5| Step: 1
Training loss: 3.553149081159463
Validation loss: 2.7924169824781053

Epoch: 5| Step: 2
Training loss: 2.244817381060273
Validation loss: 2.776223635206694

Epoch: 5| Step: 3
Training loss: 2.5900004297793706
Validation loss: 2.7187425582419915

Epoch: 5| Step: 4
Training loss: 3.500511949426977
Validation loss: 2.727047784749505

Epoch: 5| Step: 5
Training loss: 2.6045352115517444
Validation loss: 2.7939479183978237

Epoch: 5| Step: 6
Training loss: 2.7461784859792835
Validation loss: 2.8006179429466216

Epoch: 5| Step: 7
Training loss: 3.230879659477189
Validation loss: 2.767969206644344

Epoch: 5| Step: 8
Training loss: 3.4538476800514917
Validation loss: 2.734680554359395

Epoch: 5| Step: 9
Training loss: 3.2683984396008623
Validation loss: 2.7776546100942583

Epoch: 5| Step: 10
Training loss: 2.460341511568291
Validation loss: 2.7513909257593294

Epoch: 80| Step: 0
Training loss: 2.886806460894733
Validation loss: 2.7973413225888026

Epoch: 5| Step: 1
Training loss: 3.2750017530130835
Validation loss: 2.7889073791411723

Epoch: 5| Step: 2
Training loss: 2.876283110519608
Validation loss: 2.757180868391557

Epoch: 5| Step: 3
Training loss: 2.8002283888722705
Validation loss: 2.744355243243853

Epoch: 5| Step: 4
Training loss: 2.3383245105354913
Validation loss: 2.8197102168768255

Epoch: 5| Step: 5
Training loss: 3.1467813911645175
Validation loss: 2.735979427629827

Epoch: 5| Step: 6
Training loss: 2.7555428910562587
Validation loss: 2.8252992329414477

Epoch: 5| Step: 7
Training loss: 3.2242846264774863
Validation loss: 2.764864718403613

Epoch: 5| Step: 8
Training loss: 2.642424111625434
Validation loss: 2.7656318354396148

Epoch: 5| Step: 9
Training loss: 3.529225672228969
Validation loss: 2.73107939757297

Epoch: 5| Step: 10
Training loss: 2.7711243345187637
Validation loss: 2.703334860189469

Epoch: 81| Step: 0
Training loss: 2.516544718871993
Validation loss: 2.725167132239656

Epoch: 5| Step: 1
Training loss: 2.4931404420456196
Validation loss: 2.744299357125237

Epoch: 5| Step: 2
Training loss: 2.7622934738910128
Validation loss: 2.7550542164009957

Epoch: 5| Step: 3
Training loss: 2.445409608320418
Validation loss: 2.783288462837613

Epoch: 5| Step: 4
Training loss: 2.871774937792821
Validation loss: 2.788744371424068

Epoch: 5| Step: 5
Training loss: 3.6842955550800505
Validation loss: 2.732697518749491

Epoch: 5| Step: 6
Training loss: 3.7616794540555256
Validation loss: 2.7671772493002664

Epoch: 5| Step: 7
Training loss: 2.8760748802698
Validation loss: 2.726066739150352

Epoch: 5| Step: 8
Training loss: 3.3167034326045908
Validation loss: 2.766142767776985

Epoch: 5| Step: 9
Training loss: 2.6595067423049943
Validation loss: 2.7476736821202135

Epoch: 5| Step: 10
Training loss: 2.7048892399363575
Validation loss: 2.758768313837429

Epoch: 82| Step: 0
Training loss: 2.6908904579346973
Validation loss: 2.7648789048485534

Epoch: 5| Step: 1
Training loss: 2.322405452384685
Validation loss: 2.799804641259684

Epoch: 5| Step: 2
Training loss: 3.0934252327663154
Validation loss: 2.7545874508413566

Epoch: 5| Step: 3
Training loss: 2.8960398502031777
Validation loss: 2.7974372280799944

Epoch: 5| Step: 4
Training loss: 3.2487978545917566
Validation loss: 2.7135817329346517

Epoch: 5| Step: 5
Training loss: 3.4004526061446207
Validation loss: 2.8049469975530554

Epoch: 5| Step: 6
Training loss: 2.6867005689515513
Validation loss: 2.6878587102298477

Epoch: 5| Step: 7
Training loss: 3.165144219751089
Validation loss: 2.812065220341157

Epoch: 5| Step: 8
Training loss: 2.5339358173843975
Validation loss: 2.7858486688906936

Epoch: 5| Step: 9
Training loss: 3.2013827912517816
Validation loss: 2.7600361433868277

Epoch: 5| Step: 10
Training loss: 3.5591219228475914
Validation loss: 2.745442696505448

Epoch: 83| Step: 0
Training loss: 3.474145765076225
Validation loss: 2.732051810085356

Epoch: 5| Step: 1
Training loss: 2.6775318071914156
Validation loss: 2.7602833104827815

Epoch: 5| Step: 2
Training loss: 3.014066461429
Validation loss: 2.753471128470968

Epoch: 5| Step: 3
Training loss: 3.5348741956282486
Validation loss: 2.7457374163371195

Epoch: 5| Step: 4
Training loss: 3.048701438251166
Validation loss: 2.747089182288436

Epoch: 5| Step: 5
Training loss: 2.9755115806470895
Validation loss: 2.6636638343665773

Epoch: 5| Step: 6
Training loss: 3.041443037059985
Validation loss: 2.755162119567495

Epoch: 5| Step: 7
Training loss: 2.516457366661048
Validation loss: 2.786753260258232

Epoch: 5| Step: 8
Training loss: 2.4565076891815454
Validation loss: 2.779540421071075

Epoch: 5| Step: 9
Training loss: 2.918733100923877
Validation loss: 2.802678955051576

Epoch: 5| Step: 10
Training loss: 3.041258658299976
Validation loss: 2.708925901448574

Epoch: 84| Step: 0
Training loss: 2.8541789553486785
Validation loss: 2.7598397418056164

Epoch: 5| Step: 1
Training loss: 2.5290896769017572
Validation loss: 2.7342990959636917

Epoch: 5| Step: 2
Training loss: 2.9545680158594005
Validation loss: 2.7528251053013797

Epoch: 5| Step: 3
Training loss: 2.459996603676537
Validation loss: 2.8082926391367913

Epoch: 5| Step: 4
Training loss: 3.40305185230623
Validation loss: 2.740527337819214

Epoch: 5| Step: 5
Training loss: 3.0227018343519316
Validation loss: 2.7629051008355154

Epoch: 5| Step: 6
Training loss: 2.577322910267369
Validation loss: 2.7408187877208814

Epoch: 5| Step: 7
Training loss: 2.4956354189071774
Validation loss: 2.725942547618902

Epoch: 5| Step: 8
Training loss: 3.5869430428655025
Validation loss: 2.743008951712247

Epoch: 5| Step: 9
Training loss: 3.4265520018257156
Validation loss: 2.7663481170045077

Epoch: 5| Step: 10
Training loss: 2.9064816618438805
Validation loss: 2.7821475206920896

Epoch: 85| Step: 0
Training loss: 3.3145374294117844
Validation loss: 2.7639099841783925

Epoch: 5| Step: 1
Training loss: 3.181978267506749
Validation loss: 2.7143723063242247

Epoch: 5| Step: 2
Training loss: 2.325762990637039
Validation loss: 2.7530207529696575

Epoch: 5| Step: 3
Training loss: 3.086258574574681
Validation loss: 2.7441126018890674

Epoch: 5| Step: 4
Training loss: 3.1229329711678453
Validation loss: 2.7190624468177944

Epoch: 5| Step: 5
Training loss: 3.0338944373780246
Validation loss: 2.6942851006751787

Epoch: 5| Step: 6
Training loss: 2.29296843806562
Validation loss: 2.756163174474504

Epoch: 5| Step: 7
Training loss: 3.0471494893385156
Validation loss: 2.74457513531435

Epoch: 5| Step: 8
Training loss: 3.4973236477982317
Validation loss: 2.7670096519740635

Epoch: 5| Step: 9
Training loss: 2.680598157062109
Validation loss: 2.6739033755614376

Epoch: 5| Step: 10
Training loss: 2.7516854929689143
Validation loss: 2.76957947824852

Epoch: 86| Step: 0
Training loss: 2.5292178815487985
Validation loss: 2.7548240661784256

Epoch: 5| Step: 1
Training loss: 3.0194134411647777
Validation loss: 2.778918409955317

Epoch: 5| Step: 2
Training loss: 3.4573528937588107
Validation loss: 2.7371191512325965

Epoch: 5| Step: 3
Training loss: 2.6507980944263845
Validation loss: 2.7889426340544667

Epoch: 5| Step: 4
Training loss: 2.9014104109978778
Validation loss: 2.7657873718862125

Epoch: 5| Step: 5
Training loss: 2.948889384288438
Validation loss: 2.6946845951037477

Epoch: 5| Step: 6
Training loss: 2.9201545750189997
Validation loss: 2.7666375010297712

Epoch: 5| Step: 7
Training loss: 3.1524305745284353
Validation loss: 2.767550370702776

Epoch: 5| Step: 8
Training loss: 2.8042626019222148
Validation loss: 2.736120535853362

Epoch: 5| Step: 9
Training loss: 3.0566824328211113
Validation loss: 2.7484225538697458

Epoch: 5| Step: 10
Training loss: 3.137207753222193
Validation loss: 2.7474094076578948

Epoch: 87| Step: 0
Training loss: 2.6754894236678357
Validation loss: 2.7533698535948226

Epoch: 5| Step: 1
Training loss: 2.389247223004153
Validation loss: 2.781856760572482

Epoch: 5| Step: 2
Training loss: 3.5358956085434143
Validation loss: 2.7706079427599337

Epoch: 5| Step: 3
Training loss: 3.122916786103928
Validation loss: 2.727150868115337

Epoch: 5| Step: 4
Training loss: 2.797162771071983
Validation loss: 2.7384108220068133

Epoch: 5| Step: 5
Training loss: 3.319516506148859
Validation loss: 2.7524353181074845

Epoch: 5| Step: 6
Training loss: 2.889519887464648
Validation loss: 2.7428123487455136

Epoch: 5| Step: 7
Training loss: 2.9939093752430064
Validation loss: 2.775847623398814

Epoch: 5| Step: 8
Training loss: 2.5426257674207298
Validation loss: 2.723984247960146

Epoch: 5| Step: 9
Training loss: 3.4526214922964527
Validation loss: 2.7480125069139043

Epoch: 5| Step: 10
Training loss: 2.4609750896186724
Validation loss: 2.72925184865762

Epoch: 88| Step: 0
Training loss: 3.007857364468567
Validation loss: 2.7578264698742725

Epoch: 5| Step: 1
Training loss: 2.881139419651321
Validation loss: 2.721413990008311

Epoch: 5| Step: 2
Training loss: 2.4561378783438244
Validation loss: 2.743730673926422

Epoch: 5| Step: 3
Training loss: 2.81292204339379
Validation loss: 2.7620716974377424

Epoch: 5| Step: 4
Training loss: 2.8365269408309115
Validation loss: 2.773590125287029

Epoch: 5| Step: 5
Training loss: 3.6750913128569898
Validation loss: 2.730967991410059

Epoch: 5| Step: 6
Training loss: 3.5480090777550894
Validation loss: 2.7931137206820544

Epoch: 5| Step: 7
Training loss: 2.5802670914252346
Validation loss: 2.7344722682452467

Epoch: 5| Step: 8
Training loss: 2.825592508886523
Validation loss: 2.628519501733215

Epoch: 5| Step: 9
Training loss: 2.547608626785322
Validation loss: 2.685560387421712

Epoch: 5| Step: 10
Training loss: 2.67323678989441
Validation loss: 2.7550793069022705

Epoch: 89| Step: 0
Training loss: 2.898482576826872
Validation loss: 2.736280916539333

Epoch: 5| Step: 1
Training loss: 2.41858375628578
Validation loss: 2.677861781654943

Epoch: 5| Step: 2
Training loss: 2.6797515594566144
Validation loss: 2.76760862828377

Epoch: 5| Step: 3
Training loss: 3.9568044554176653
Validation loss: 2.7551991303423944

Epoch: 5| Step: 4
Training loss: 2.9158458826391547
Validation loss: 2.679134128432743

Epoch: 5| Step: 5
Training loss: 2.670740701038084
Validation loss: 2.793600666600693

Epoch: 5| Step: 6
Training loss: 2.4426770130310382
Validation loss: 2.703346976913695

Epoch: 5| Step: 7
Training loss: 2.7738911002579187
Validation loss: 2.7549555764317386

Epoch: 5| Step: 8
Training loss: 3.2783459118936467
Validation loss: 2.7157112124417764

Epoch: 5| Step: 9
Training loss: 2.333639590282785
Validation loss: 2.747357333917176

Epoch: 5| Step: 10
Training loss: 3.074078839037503
Validation loss: 2.6885197424957865

Epoch: 90| Step: 0
Training loss: 3.016876435406938
Validation loss: 2.779856494148508

Epoch: 5| Step: 1
Training loss: 3.8184320545352826
Validation loss: 2.708707066788972

Epoch: 5| Step: 2
Training loss: 3.833597187968132
Validation loss: 2.755965648068436

Epoch: 5| Step: 3
Training loss: 2.8580646117950717
Validation loss: 2.6597650249394986

Epoch: 5| Step: 4
Training loss: 3.1495904444310483
Validation loss: 2.6904731591687536

Epoch: 5| Step: 5
Training loss: 2.6688022009861054
Validation loss: 2.7422131962357095

Epoch: 5| Step: 6
Training loss: 2.782622866458417
Validation loss: 2.7617933249293496

Epoch: 5| Step: 7
Training loss: 2.2264299319772887
Validation loss: 2.746563758619773

Epoch: 5| Step: 8
Training loss: 2.7885186014989682
Validation loss: 2.7163694315615015

Epoch: 5| Step: 9
Training loss: 2.41485276604669
Validation loss: 2.7063249706224703

Epoch: 5| Step: 10
Training loss: 2.328834579168591
Validation loss: 2.7418453794401243

Epoch: 91| Step: 0
Training loss: 3.576877693096602
Validation loss: 2.735818414555008

Epoch: 5| Step: 1
Training loss: 3.1105904048799404
Validation loss: 2.7479280961746144

Epoch: 5| Step: 2
Training loss: 3.114368205896569
Validation loss: 2.754289969768173

Epoch: 5| Step: 3
Training loss: 2.120738749715169
Validation loss: 2.8003133964649973

Epoch: 5| Step: 4
Training loss: 2.8243796486087165
Validation loss: 2.7189876172974197

Epoch: 5| Step: 5
Training loss: 2.958960524862627
Validation loss: 2.771761616060505

Epoch: 5| Step: 6
Training loss: 2.537128451351253
Validation loss: 2.741650707179596

Epoch: 5| Step: 7
Training loss: 3.076047554531506
Validation loss: 2.7764918557119422

Epoch: 5| Step: 8
Training loss: 3.0296280444382084
Validation loss: 2.7155651466426

Epoch: 5| Step: 9
Training loss: 2.493501227262848
Validation loss: 2.8382747299220474

Epoch: 5| Step: 10
Training loss: 2.9482898992599296
Validation loss: 2.782771711060978

Epoch: 92| Step: 0
Training loss: 3.4386801341151667
Validation loss: 2.720740261545416

Epoch: 5| Step: 1
Training loss: 2.150333414174243
Validation loss: 2.7699380702512464

Epoch: 5| Step: 2
Training loss: 3.175459316400887
Validation loss: 2.7672609783812767

Epoch: 5| Step: 3
Training loss: 2.440574174613083
Validation loss: 2.781830540298259

Epoch: 5| Step: 4
Training loss: 2.6057545106305833
Validation loss: 2.730906505803083

Epoch: 5| Step: 5
Training loss: 3.273079426921462
Validation loss: 2.7758659697059027

Epoch: 5| Step: 6
Training loss: 2.9144866062026042
Validation loss: 2.7263627166428237

Epoch: 5| Step: 7
Training loss: 2.616452515296432
Validation loss: 2.7512354103396257

Epoch: 5| Step: 8
Training loss: 3.0359080597396857
Validation loss: 2.8016060180442968

Epoch: 5| Step: 9
Training loss: 2.863910350930864
Validation loss: 2.682485017021223

Epoch: 5| Step: 10
Training loss: 2.994012579820766
Validation loss: 2.7872306231150006

Epoch: 93| Step: 0
Training loss: 3.337583899425686
Validation loss: 2.7109783619073706

Epoch: 5| Step: 1
Training loss: 3.1816863354700593
Validation loss: 2.735287105946347

Epoch: 5| Step: 2
Training loss: 2.766262175011334
Validation loss: 2.737601538289477

Epoch: 5| Step: 3
Training loss: 2.2835487384777706
Validation loss: 2.768066766984829

Epoch: 5| Step: 4
Training loss: 2.633403406136379
Validation loss: 2.7593823164197637

Epoch: 5| Step: 5
Training loss: 2.7000491773577284
Validation loss: 2.73863879626044

Epoch: 5| Step: 6
Training loss: 2.8045700176147523
Validation loss: 2.767008919110696

Epoch: 5| Step: 7
Training loss: 2.850172566325926
Validation loss: 2.749848632897664

Epoch: 5| Step: 8
Training loss: 3.1164340301293
Validation loss: 2.7484065983602415

Epoch: 5| Step: 9
Training loss: 2.5317985034574484
Validation loss: 2.737290345971974

Epoch: 5| Step: 10
Training loss: 3.290100948559023
Validation loss: 2.7286846828374873

Epoch: 94| Step: 0
Training loss: 2.788237805080159
Validation loss: 2.7639807667305925

Epoch: 5| Step: 1
Training loss: 3.1912390526218815
Validation loss: 2.7776659697587416

Epoch: 5| Step: 2
Training loss: 3.1872247315270714
Validation loss: 2.7190596531816595

Epoch: 5| Step: 3
Training loss: 2.799792936025652
Validation loss: 2.745323859169624

Epoch: 5| Step: 4
Training loss: 2.6621650807519983
Validation loss: 2.7175108665104672

Epoch: 5| Step: 5
Training loss: 3.0916364752296968
Validation loss: 2.695192810606468

Epoch: 5| Step: 6
Training loss: 2.402042227330203
Validation loss: 2.822670218867333

Epoch: 5| Step: 7
Training loss: 2.939688171925168
Validation loss: 2.755944973497001

Epoch: 5| Step: 8
Training loss: 3.1044869652362492
Validation loss: 2.6994538993442982

Epoch: 5| Step: 9
Training loss: 2.9285836136461425
Validation loss: 2.74460590359178

Epoch: 5| Step: 10
Training loss: 3.2925480656457244
Validation loss: 2.6989184041920007

Epoch: 95| Step: 0
Training loss: 2.65557008905127
Validation loss: 2.6967570861987293

Epoch: 5| Step: 1
Training loss: 2.9751570780342087
Validation loss: 2.7667021362051307

Epoch: 5| Step: 2
Training loss: 3.106293651496686
Validation loss: 2.67956819761725

Epoch: 5| Step: 3
Training loss: 2.9873257574240606
Validation loss: 2.724709208592702

Epoch: 5| Step: 4
Training loss: 2.9322287155811217
Validation loss: 2.7099280815494082

Epoch: 5| Step: 5
Training loss: 2.8030261376339816
Validation loss: 2.7395790000559037

Epoch: 5| Step: 6
Training loss: 2.578120838508715
Validation loss: 2.725930075206408

Epoch: 5| Step: 7
Training loss: 3.586498341303513
Validation loss: 2.6932964606575007

Epoch: 5| Step: 8
Training loss: 2.7853856574086913
Validation loss: 2.7096210103723952

Epoch: 5| Step: 9
Training loss: 3.0926639692894082
Validation loss: 2.717033763910087

Epoch: 5| Step: 10
Training loss: 2.3402131924142524
Validation loss: 2.7549658292794446

Epoch: 96| Step: 0
Training loss: 3.4650529284377463
Validation loss: 2.681770130798718

Epoch: 5| Step: 1
Training loss: 3.0213906311209073
Validation loss: 2.7438619329149074

Epoch: 5| Step: 2
Training loss: 3.117286317258113
Validation loss: 2.6738454416566513

Epoch: 5| Step: 3
Training loss: 3.249927226498935
Validation loss: 2.7685149494864136

Epoch: 5| Step: 4
Training loss: 2.3412364451377004
Validation loss: 2.7586868416748245

Epoch: 5| Step: 5
Training loss: 3.1190683145089544
Validation loss: 2.7656928605021

Epoch: 5| Step: 6
Training loss: 2.8401348904019876
Validation loss: 2.7384303618494155

Epoch: 5| Step: 7
Training loss: 2.7616148933188067
Validation loss: 2.705581013060406

Epoch: 5| Step: 8
Training loss: 2.319821392451841
Validation loss: 2.7224827187928873

Epoch: 5| Step: 9
Training loss: 2.4972595453449378
Validation loss: 2.718797131918277

Epoch: 5| Step: 10
Training loss: 2.438092184268864
Validation loss: 2.7464126305846377

Epoch: 97| Step: 0
Training loss: 2.2310546533036417
Validation loss: 2.7132793695989856

Epoch: 5| Step: 1
Training loss: 3.0840037020946798
Validation loss: 2.708567529843407

Epoch: 5| Step: 2
Training loss: 3.2726454038205772
Validation loss: 2.7656971828356145

Epoch: 5| Step: 3
Training loss: 2.7113225042375286
Validation loss: 2.7677490988381077

Epoch: 5| Step: 4
Training loss: 2.7785787720290758
Validation loss: 2.751895434045908

Epoch: 5| Step: 5
Training loss: 3.1916137777250793
Validation loss: 2.822183213505213

Epoch: 5| Step: 6
Training loss: 2.9272388855858917
Validation loss: 2.7100664132790238

Epoch: 5| Step: 7
Training loss: 2.530653141437132
Validation loss: 2.712504615626655

Epoch: 5| Step: 8
Training loss: 2.7777553419690593
Validation loss: 2.7736989636527793

Epoch: 5| Step: 9
Training loss: 2.8334543164920554
Validation loss: 2.716598809139199

Epoch: 5| Step: 10
Training loss: 3.412418624410712
Validation loss: 2.7511228047937117

Epoch: 98| Step: 0
Training loss: 3.0029158726816374
Validation loss: 2.73501497575813

Epoch: 5| Step: 1
Training loss: 2.8154301955969885
Validation loss: 2.725354900225115

Epoch: 5| Step: 2
Training loss: 2.872497796571582
Validation loss: 2.6548141227471995

Epoch: 5| Step: 3
Training loss: 2.720428737762199
Validation loss: 2.7416721613861608

Epoch: 5| Step: 4
Training loss: 2.3560539265210574
Validation loss: 2.8319751975821155

Epoch: 5| Step: 5
Training loss: 2.6605316659024707
Validation loss: 2.7714252997650957

Epoch: 5| Step: 6
Training loss: 3.1221083423063063
Validation loss: 2.7741088368950813

Epoch: 5| Step: 7
Training loss: 3.0002584346083383
Validation loss: 2.7244277393105922

Epoch: 5| Step: 8
Training loss: 3.526927091168869
Validation loss: 2.7963565380935083

Epoch: 5| Step: 9
Training loss: 3.241215203889554
Validation loss: 2.704710188840679

Epoch: 5| Step: 10
Training loss: 2.6368919033133538
Validation loss: 2.755240794783686

Epoch: 99| Step: 0
Training loss: 2.285514086232395
Validation loss: 2.736203480083359

Epoch: 5| Step: 1
Training loss: 2.7613260078934716
Validation loss: 2.699585676819475

Epoch: 5| Step: 2
Training loss: 2.370796700335929
Validation loss: 2.7647645878488816

Epoch: 5| Step: 3
Training loss: 3.412226482231219
Validation loss: 2.6986391980896594

Epoch: 5| Step: 4
Training loss: 2.6888259455597225
Validation loss: 2.704639816269053

Epoch: 5| Step: 5
Training loss: 2.5480780071372506
Validation loss: 2.7116498019331865

Epoch: 5| Step: 6
Training loss: 3.0338656751335282
Validation loss: 2.720340261311629

Epoch: 5| Step: 7
Training loss: 2.710168207163645
Validation loss: 2.688765263987529

Epoch: 5| Step: 8
Training loss: 2.958493313470904
Validation loss: 2.722276280321011

Epoch: 5| Step: 9
Training loss: 3.836104939024798
Validation loss: 2.7131411865662263

Epoch: 5| Step: 10
Training loss: 3.7162759709533355
Validation loss: 2.730366057617936

Epoch: 100| Step: 0
Training loss: 3.1180418751016954
Validation loss: 2.7481879270493863

Epoch: 5| Step: 1
Training loss: 2.043683891510424
Validation loss: 2.696192617940337

Epoch: 5| Step: 2
Training loss: 2.967969932465545
Validation loss: 2.662945290433854

Epoch: 5| Step: 3
Training loss: 2.8538446360739655
Validation loss: 2.7465312798663826

Epoch: 5| Step: 4
Training loss: 2.0705584685843026
Validation loss: 2.727744665654228

Epoch: 5| Step: 5
Training loss: 2.4613423332381825
Validation loss: 2.77806517505466

Epoch: 5| Step: 6
Training loss: 3.517185119329839
Validation loss: 2.730226127596353

Epoch: 5| Step: 7
Training loss: 3.2572899268942392
Validation loss: 2.7478620920363674

Epoch: 5| Step: 8
Training loss: 2.5216598626965463
Validation loss: 2.7889358585052504

Epoch: 5| Step: 9
Training loss: 3.8962992153296465
Validation loss: 2.6983226648489547

Epoch: 5| Step: 10
Training loss: 2.9055421028611894
Validation loss: 2.6976869306118667

Testing loss: 2.5980805142190126
