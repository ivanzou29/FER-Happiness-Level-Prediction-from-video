Epoch: 1| Step: 0
Training loss: 5.690272064408888
Validation loss: 5.408233506328197

Epoch: 6| Step: 1
Training loss: 4.328784658242038
Validation loss: 5.404183804690597

Epoch: 6| Step: 2
Training loss: 5.476077331732563
Validation loss: 5.39892675444008

Epoch: 6| Step: 3
Training loss: 5.090282921862927
Validation loss: 5.395222755912297

Epoch: 6| Step: 4
Training loss: 5.6181162781244005
Validation loss: 5.3915680490664215

Epoch: 6| Step: 5
Training loss: 5.239982675713009
Validation loss: 5.386097122319731

Epoch: 6| Step: 6
Training loss: 4.780918483834697
Validation loss: 5.381906938990034

Epoch: 6| Step: 7
Training loss: 5.968048853410905
Validation loss: 5.378559558415238

Epoch: 6| Step: 8
Training loss: 5.3205629085366795
Validation loss: 5.373883004680445

Epoch: 6| Step: 9
Training loss: 5.418905098883272
Validation loss: 5.3682890958334495

Epoch: 6| Step: 10
Training loss: 5.178692061799704
Validation loss: 5.362199078307917

Epoch: 6| Step: 11
Training loss: 6.5213866887712175
Validation loss: 5.357926444324548

Epoch: 6| Step: 12
Training loss: 5.285501788813045
Validation loss: 5.3532944857036115

Epoch: 6| Step: 13
Training loss: 6.1169966744661295
Validation loss: 5.347479008911657

Epoch: 2| Step: 0
Training loss: 4.4038187448342505
Validation loss: 5.344586852618861

Epoch: 6| Step: 1
Training loss: 6.157423807928073
Validation loss: 5.335823004163568

Epoch: 6| Step: 2
Training loss: 4.807494495723944
Validation loss: 5.3343774916790965

Epoch: 6| Step: 3
Training loss: 5.293478988321828
Validation loss: 5.328851735130478

Epoch: 6| Step: 4
Training loss: 4.320990566138307
Validation loss: 5.322749890109882

Epoch: 6| Step: 5
Training loss: 5.499619557487555
Validation loss: 5.319984208949491

Epoch: 6| Step: 6
Training loss: 5.542361376056485
Validation loss: 5.313615123825307

Epoch: 6| Step: 7
Training loss: 6.423021942704605
Validation loss: 5.305615096826622

Epoch: 6| Step: 8
Training loss: 5.539545250692755
Validation loss: 5.301363722853522

Epoch: 6| Step: 9
Training loss: 6.030561813069326
Validation loss: 5.299827823949583

Epoch: 6| Step: 10
Training loss: 5.36152201095228
Validation loss: 5.293826072064832

Epoch: 6| Step: 11
Training loss: 4.975632225772176
Validation loss: 5.289220073653423

Epoch: 6| Step: 12
Training loss: 5.1023272047824495
Validation loss: 5.283734145054471

Epoch: 6| Step: 13
Training loss: 5.079936200439638
Validation loss: 5.278172526828642

Epoch: 3| Step: 0
Training loss: 5.4378188467265485
Validation loss: 5.26959853871751

Epoch: 6| Step: 1
Training loss: 3.551928310796351
Validation loss: 5.268933718931009

Epoch: 6| Step: 2
Training loss: 5.130309169443131
Validation loss: 5.262720599592976

Epoch: 6| Step: 3
Training loss: 5.2415238029931475
Validation loss: 5.260558876723456

Epoch: 6| Step: 4
Training loss: 5.223711955636431
Validation loss: 5.256700257039578

Epoch: 6| Step: 5
Training loss: 4.878536213386875
Validation loss: 5.247400279831906

Epoch: 6| Step: 6
Training loss: 5.629799723611713
Validation loss: 5.247394581329979

Epoch: 6| Step: 7
Training loss: 5.315871481588381
Validation loss: 5.244092647268628

Epoch: 6| Step: 8
Training loss: 5.9355783665666735
Validation loss: 5.235699010393314

Epoch: 6| Step: 9
Training loss: 6.11995691820327
Validation loss: 5.2273441275125645

Epoch: 6| Step: 10
Training loss: 5.1378622776578675
Validation loss: 5.2207648833571945

Epoch: 6| Step: 11
Training loss: 5.181687741257706
Validation loss: 5.2202863243927835

Epoch: 6| Step: 12
Training loss: 5.048578783736637
Validation loss: 5.219363868081219

Epoch: 6| Step: 13
Training loss: 6.318238624232559
Validation loss: 5.205392197914669

Epoch: 4| Step: 0
Training loss: 3.148423566385111
Validation loss: 5.20616529202512

Epoch: 6| Step: 1
Training loss: 5.746662664094904
Validation loss: 5.196236076363658

Epoch: 6| Step: 2
Training loss: 5.441609375415006
Validation loss: 5.188957562096499

Epoch: 6| Step: 3
Training loss: 5.663330704342458
Validation loss: 5.185057613545447

Epoch: 6| Step: 4
Training loss: 5.060442094148733
Validation loss: 5.181541991759338

Epoch: 6| Step: 5
Training loss: 5.517972538447305
Validation loss: 5.177453439742358

Epoch: 6| Step: 6
Training loss: 5.575871030905924
Validation loss: 5.176976567917127

Epoch: 6| Step: 7
Training loss: 4.8432112855666976
Validation loss: 5.163726141876573

Epoch: 6| Step: 8
Training loss: 5.593857748176649
Validation loss: 5.1591088328194985

Epoch: 6| Step: 9
Training loss: 4.70071258012935
Validation loss: 5.15668312458674

Epoch: 6| Step: 10
Training loss: 5.454641399117705
Validation loss: 5.14634492338893

Epoch: 6| Step: 11
Training loss: 3.607172570652501
Validation loss: 5.139845253994805

Epoch: 6| Step: 12
Training loss: 6.387721812956228
Validation loss: 5.137202740304925

Epoch: 6| Step: 13
Training loss: 5.6938759414026565
Validation loss: 5.125284864830987

Epoch: 5| Step: 0
Training loss: 5.1683341176117406
Validation loss: 5.122800193342349

Epoch: 6| Step: 1
Training loss: 5.647044747465953
Validation loss: 5.120671454990531

Epoch: 6| Step: 2
Training loss: 5.943498011240447
Validation loss: 5.114786074088056

Epoch: 6| Step: 3
Training loss: 5.51094094025667
Validation loss: 5.105768343781433

Epoch: 6| Step: 4
Training loss: 4.374355159648578
Validation loss: 5.102438394729363

Epoch: 6| Step: 5
Training loss: 5.413541254050047
Validation loss: 5.0924749750895

Epoch: 6| Step: 6
Training loss: 5.5022221324457075
Validation loss: 5.088622842017933

Epoch: 6| Step: 7
Training loss: 4.386640919974077
Validation loss: 5.078384252955575

Epoch: 6| Step: 8
Training loss: 4.833380841427289
Validation loss: 5.075074179528672

Epoch: 6| Step: 9
Training loss: 5.422494814401119
Validation loss: 5.0704561419813325

Epoch: 6| Step: 10
Training loss: 5.285614196831258
Validation loss: 5.068088778204428

Epoch: 6| Step: 11
Training loss: 4.456960639093388
Validation loss: 5.048973942091333

Epoch: 6| Step: 12
Training loss: 4.714396508471356
Validation loss: 5.043470264326145

Epoch: 6| Step: 13
Training loss: 5.057239955188548
Validation loss: 5.036971085073269

Epoch: 6| Step: 0
Training loss: 5.068139220290816
Validation loss: 5.032864013585099

Epoch: 6| Step: 1
Training loss: 5.952589917102589
Validation loss: 5.025809042833563

Epoch: 6| Step: 2
Training loss: 3.967927622258062
Validation loss: 5.021393629749306

Epoch: 6| Step: 3
Training loss: 4.33883762456871
Validation loss: 5.020137124683558

Epoch: 6| Step: 4
Training loss: 4.195782114806683
Validation loss: 5.005680526472892

Epoch: 6| Step: 5
Training loss: 3.7017528712027774
Validation loss: 4.997652911927659

Epoch: 6| Step: 6
Training loss: 5.100447107799756
Validation loss: 4.992141477182788

Epoch: 6| Step: 7
Training loss: 5.3036495311246785
Validation loss: 4.985668324081318

Epoch: 6| Step: 8
Training loss: 6.57823808079022
Validation loss: 4.980552552893678

Epoch: 6| Step: 9
Training loss: 4.60996421022238
Validation loss: 4.971746796675027

Epoch: 6| Step: 10
Training loss: 6.127595312714952
Validation loss: 4.968203016550462

Epoch: 6| Step: 11
Training loss: 4.495971147736526
Validation loss: 4.957243319320091

Epoch: 6| Step: 12
Training loss: 5.20939556225321
Validation loss: 4.944510006459373

Epoch: 6| Step: 13
Training loss: 5.269336513034412
Validation loss: 4.943171060467513

Epoch: 7| Step: 0
Training loss: 4.85446517528569
Validation loss: 4.93402833230831

Epoch: 6| Step: 1
Training loss: 4.934620270965937
Validation loss: 4.923880553106044

Epoch: 6| Step: 2
Training loss: 4.5135776405946295
Validation loss: 4.911612450965876

Epoch: 6| Step: 3
Training loss: 5.059033372547643
Validation loss: 4.910816664026082

Epoch: 6| Step: 4
Training loss: 4.638253270585772
Validation loss: 4.902633068445803

Epoch: 6| Step: 5
Training loss: 5.557200446865366
Validation loss: 4.888055896053624

Epoch: 6| Step: 6
Training loss: 4.987429648455306
Validation loss: 4.881535102566652

Epoch: 6| Step: 7
Training loss: 5.969605709071358
Validation loss: 4.871342604097213

Epoch: 6| Step: 8
Training loss: 4.314905573760987
Validation loss: 4.863240940325426

Epoch: 6| Step: 9
Training loss: 5.383497750967114
Validation loss: 4.862458494921207

Epoch: 6| Step: 10
Training loss: 2.812571630625375
Validation loss: 4.848210456652106

Epoch: 6| Step: 11
Training loss: 4.789297076356373
Validation loss: 4.836175485344895

Epoch: 6| Step: 12
Training loss: 5.064584938508311
Validation loss: 4.8326673009898204

Epoch: 6| Step: 13
Training loss: 6.242228139045591
Validation loss: 4.823612835926057

Epoch: 8| Step: 0
Training loss: 4.595518848568552
Validation loss: 4.818381874563366

Epoch: 6| Step: 1
Training loss: 5.150705766927571
Validation loss: 4.801108096855367

Epoch: 6| Step: 2
Training loss: 4.786570263018449
Validation loss: 4.797362649339287

Epoch: 6| Step: 3
Training loss: 5.156410353508015
Validation loss: 4.7832151628112145

Epoch: 6| Step: 4
Training loss: 5.320598219314906
Validation loss: 4.776440568191702

Epoch: 6| Step: 5
Training loss: 3.651538911154821
Validation loss: 4.766096925895409

Epoch: 6| Step: 6
Training loss: 4.360890552318615
Validation loss: 4.7599912052860915

Epoch: 6| Step: 7
Training loss: 5.732739290615781
Validation loss: 4.739977934469994

Epoch: 6| Step: 8
Training loss: 3.9850403473270153
Validation loss: 4.7370525423585

Epoch: 6| Step: 9
Training loss: 5.722726575399799
Validation loss: 4.72795262360679

Epoch: 6| Step: 10
Training loss: 4.524300975444301
Validation loss: 4.7155694215255135

Epoch: 6| Step: 11
Training loss: 5.120624442168589
Validation loss: 4.699196428381248

Epoch: 6| Step: 12
Training loss: 4.825878620693844
Validation loss: 4.693897515607601

Epoch: 6| Step: 13
Training loss: 3.4127437742027125
Validation loss: 4.691705972972446

Epoch: 9| Step: 0
Training loss: 3.834464417699748
Validation loss: 4.6785332961151145

Epoch: 6| Step: 1
Training loss: 4.823501298814284
Validation loss: 4.662984924339045

Epoch: 6| Step: 2
Training loss: 5.801224467495257
Validation loss: 4.648945709157922

Epoch: 6| Step: 3
Training loss: 4.500503299965786
Validation loss: 4.643382021662103

Epoch: 6| Step: 4
Training loss: 5.179869589618459
Validation loss: 4.629690344536559

Epoch: 6| Step: 5
Training loss: 4.356481979958051
Validation loss: 4.619504983949531

Epoch: 6| Step: 6
Training loss: 4.761578151764531
Validation loss: 4.607267731992759

Epoch: 6| Step: 7
Training loss: 5.540101463683248
Validation loss: 4.588735547318921

Epoch: 6| Step: 8
Training loss: 4.424691641025854
Validation loss: 4.587058712174406

Epoch: 6| Step: 9
Training loss: 4.296964665257635
Validation loss: 4.5701325423117805

Epoch: 6| Step: 10
Training loss: 4.376855511238607
Validation loss: 4.554429120753856

Epoch: 6| Step: 11
Training loss: 4.424735178808771
Validation loss: 4.548963860730328

Epoch: 6| Step: 12
Training loss: 4.506925340222408
Validation loss: 4.537751972431148

Epoch: 6| Step: 13
Training loss: 4.125027049582831
Validation loss: 4.524467038114313

Epoch: 10| Step: 0
Training loss: 3.6704961257413187
Validation loss: 4.506707514612769

Epoch: 6| Step: 1
Training loss: 4.507748185199776
Validation loss: 4.505805524027602

Epoch: 6| Step: 2
Training loss: 3.9638049940073463
Validation loss: 4.487082196852884

Epoch: 6| Step: 3
Training loss: 4.675319460801249
Validation loss: 4.471503929076271

Epoch: 6| Step: 4
Training loss: 4.106053159225623
Validation loss: 4.464629673096343

Epoch: 6| Step: 5
Training loss: 4.910962993714651
Validation loss: 4.4564200892317425

Epoch: 6| Step: 6
Training loss: 4.728397032279866
Validation loss: 4.439556612929201

Epoch: 6| Step: 7
Training loss: 5.04340633086537
Validation loss: 4.421894853368276

Epoch: 6| Step: 8
Training loss: 4.827901989375774
Validation loss: 4.411370892598894

Epoch: 6| Step: 9
Training loss: 4.102169783911333
Validation loss: 4.384624492760962

Epoch: 6| Step: 10
Training loss: 3.6676000505255795
Validation loss: 4.382544813597676

Epoch: 6| Step: 11
Training loss: 5.30564060553553
Validation loss: 4.370941245957554

Epoch: 6| Step: 12
Training loss: 4.719278470187451
Validation loss: 4.352750306534304

Epoch: 6| Step: 13
Training loss: 4.641269009790343
Validation loss: 4.337920448508127

Epoch: 11| Step: 0
Training loss: 4.500580008533123
Validation loss: 4.329729073707977

Epoch: 6| Step: 1
Training loss: 4.392055292083731
Validation loss: 4.3064774186053745

Epoch: 6| Step: 2
Training loss: 4.568636595105236
Validation loss: 4.29433866608828

Epoch: 6| Step: 3
Training loss: 4.004214688958193
Validation loss: 4.275347504389219

Epoch: 6| Step: 4
Training loss: 3.4790795290574827
Validation loss: 4.261699825167509

Epoch: 6| Step: 5
Training loss: 4.411704724969959
Validation loss: 4.249291719873689

Epoch: 6| Step: 6
Training loss: 3.936964210508424
Validation loss: 4.233127179615625

Epoch: 6| Step: 7
Training loss: 4.154072815126035
Validation loss: 4.226452319146395

Epoch: 6| Step: 8
Training loss: 5.0503660239341075
Validation loss: 4.205444479098346

Epoch: 6| Step: 9
Training loss: 4.249135995442329
Validation loss: 4.188950423508079

Epoch: 6| Step: 10
Training loss: 4.31143042527787
Validation loss: 4.178867016436973

Epoch: 6| Step: 11
Training loss: 4.762049199593144
Validation loss: 4.153980670303743

Epoch: 6| Step: 12
Training loss: 4.6318230690114826
Validation loss: 4.134856620729442

Epoch: 6| Step: 13
Training loss: 3.7387308549916902
Validation loss: 4.135424361972536

Epoch: 12| Step: 0
Training loss: 4.039835695381523
Validation loss: 4.102866489933015

Epoch: 6| Step: 1
Training loss: 4.305101101316171
Validation loss: 4.094259168266947

Epoch: 6| Step: 2
Training loss: 4.777693079904933
Validation loss: 4.076669109606931

Epoch: 6| Step: 3
Training loss: 3.9621062651724213
Validation loss: 4.0618593428602905

Epoch: 6| Step: 4
Training loss: 4.377958768619952
Validation loss: 4.038535395848421

Epoch: 6| Step: 5
Training loss: 4.454103810670064
Validation loss: 4.021798880524035

Epoch: 6| Step: 6
Training loss: 4.6140634259650275
Validation loss: 3.9979805591408546

Epoch: 6| Step: 7
Training loss: 4.9708493194365655
Validation loss: 3.977423715856424

Epoch: 6| Step: 8
Training loss: 3.29957390548593
Validation loss: 3.9628084003656783

Epoch: 6| Step: 9
Training loss: 3.360509210783645
Validation loss: 3.9386503561138473

Epoch: 6| Step: 10
Training loss: 3.7939919408733735
Validation loss: 3.936694043022712

Epoch: 6| Step: 11
Training loss: 3.2600593411714125
Validation loss: 3.9130217183010254

Epoch: 6| Step: 12
Training loss: 4.1256179346729995
Validation loss: 3.8913898529162436

Epoch: 6| Step: 13
Training loss: 3.9409856959414653
Validation loss: 3.8837776165657822

Epoch: 13| Step: 0
Training loss: 3.840076458885032
Validation loss: 3.8598015423173133

Epoch: 6| Step: 1
Training loss: 3.1819670283193577
Validation loss: 3.8357252645327655

Epoch: 6| Step: 2
Training loss: 3.3742819128110835
Validation loss: 3.819037107720769

Epoch: 6| Step: 3
Training loss: 2.8695637265680234
Validation loss: 3.801032938080922

Epoch: 6| Step: 4
Training loss: 3.82670099670571
Validation loss: 3.783906958282556

Epoch: 6| Step: 5
Training loss: 4.064073697976331
Validation loss: 3.786985267099458

Epoch: 6| Step: 6
Training loss: 4.039681540297637
Validation loss: 3.7600641568002815

Epoch: 6| Step: 7
Training loss: 4.66894786573738
Validation loss: 3.7312585437138384

Epoch: 6| Step: 8
Training loss: 4.175234923920075
Validation loss: 3.720475099088716

Epoch: 6| Step: 9
Training loss: 3.999059685809466
Validation loss: 3.7071968476531856

Epoch: 6| Step: 10
Training loss: 3.5178645481753676
Validation loss: 3.671888627110148

Epoch: 6| Step: 11
Training loss: 4.192653161232814
Validation loss: 3.651693602266349

Epoch: 6| Step: 12
Training loss: 4.4553024590055275
Validation loss: 3.639281763285873

Epoch: 6| Step: 13
Training loss: 3.509315899209465
Validation loss: 3.629511368594038

Epoch: 14| Step: 0
Training loss: 2.7638406115670744
Validation loss: 3.603494946584734

Epoch: 6| Step: 1
Training loss: 3.253440356474544
Validation loss: 3.581438542804193

Epoch: 6| Step: 2
Training loss: 3.879952987700699
Validation loss: 3.569016434148136

Epoch: 6| Step: 3
Training loss: 4.306551382649621
Validation loss: 3.5591877073698734

Epoch: 6| Step: 4
Training loss: 3.450978712495439
Validation loss: 3.525122616428092

Epoch: 6| Step: 5
Training loss: 3.850280919911097
Validation loss: 3.5106573004429893

Epoch: 6| Step: 6
Training loss: 4.21440273519614
Validation loss: 3.483898924748065

Epoch: 6| Step: 7
Training loss: 3.9370394240564455
Validation loss: 3.4644329120057336

Epoch: 6| Step: 8
Training loss: 2.8789466637682377
Validation loss: 3.447247983528358

Epoch: 6| Step: 9
Training loss: 2.856072191175506
Validation loss: 3.4300263840759517

Epoch: 6| Step: 10
Training loss: 4.0723749891639605
Validation loss: 3.4165663420571635

Epoch: 6| Step: 11
Training loss: 4.0230632126422075
Validation loss: 3.4104653863579526

Epoch: 6| Step: 12
Training loss: 4.057297412376922
Validation loss: 3.38259959702482

Epoch: 6| Step: 13
Training loss: 2.4839489649507165
Validation loss: 3.3499026462377883

Epoch: 15| Step: 0
Training loss: 3.9577979411728252
Validation loss: 3.3257250114820027

Epoch: 6| Step: 1
Training loss: 4.2022459110601185
Validation loss: 3.317776712691807

Epoch: 6| Step: 2
Training loss: 2.730450587833015
Validation loss: 3.314224216986154

Epoch: 6| Step: 3
Training loss: 3.1770710595732865
Validation loss: 3.2821019939223257

Epoch: 6| Step: 4
Training loss: 3.808582481954485
Validation loss: 3.259625284806908

Epoch: 6| Step: 5
Training loss: 2.5643179422790454
Validation loss: 3.2469073632459877

Epoch: 6| Step: 6
Training loss: 3.6721962646192794
Validation loss: 3.2193256026382766

Epoch: 6| Step: 7
Training loss: 3.016806573591655
Validation loss: 3.203536446250268

Epoch: 6| Step: 8
Training loss: 3.9423072170808373
Validation loss: 3.1959641363267925

Epoch: 6| Step: 9
Training loss: 3.4283834076597954
Validation loss: 3.1707741911271294

Epoch: 6| Step: 10
Training loss: 3.316806512948251
Validation loss: 3.156413095720169

Epoch: 6| Step: 11
Training loss: 3.7287300891453317
Validation loss: 3.1383737098719626

Epoch: 6| Step: 12
Training loss: 3.2448932433825473
Validation loss: 3.1310793954065366

Epoch: 6| Step: 13
Training loss: 2.2695157022649455
Validation loss: 3.1069544939447122

Epoch: 16| Step: 0
Training loss: 3.618700539048319
Validation loss: 3.092949361856706

Epoch: 6| Step: 1
Training loss: 3.3599571965533874
Validation loss: 3.083775897359903

Epoch: 6| Step: 2
Training loss: 3.2531627524582802
Validation loss: 3.062901455297127

Epoch: 6| Step: 3
Training loss: 3.1535554469181464
Validation loss: 3.0300836360541545

Epoch: 6| Step: 4
Training loss: 2.8209513524515004
Validation loss: 3.0340573777221045

Epoch: 6| Step: 5
Training loss: 3.242331333876551
Validation loss: 3.0266440093527

Epoch: 6| Step: 6
Training loss: 2.0304371307717464
Validation loss: 2.99279489743058

Epoch: 6| Step: 7
Training loss: 3.054943961770511
Validation loss: 2.9688105768609017

Epoch: 6| Step: 8
Training loss: 3.7202394211539676
Validation loss: 2.967290806166032

Epoch: 6| Step: 9
Training loss: 3.4929840067080415
Validation loss: 2.9540195433023153

Epoch: 6| Step: 10
Training loss: 4.090229646535922
Validation loss: 2.9432675205580807

Epoch: 6| Step: 11
Training loss: 2.7353248908129326
Validation loss: 2.9269912758384367

Epoch: 6| Step: 12
Training loss: 3.5940696242460612
Validation loss: 2.9043959826698207

Epoch: 6| Step: 13
Training loss: 2.6785667455723106
Validation loss: 2.896627383825353

Epoch: 17| Step: 0
Training loss: 3.0153901794403217
Validation loss: 2.9136970860767732

Epoch: 6| Step: 1
Training loss: 3.2158220918420524
Validation loss: 2.8663727023173147

Epoch: 6| Step: 2
Training loss: 3.2527448360585955
Validation loss: 2.858649125119268

Epoch: 6| Step: 3
Training loss: 3.96460561553953
Validation loss: 2.867739244531983

Epoch: 6| Step: 4
Training loss: 2.8985186048815073
Validation loss: 2.858928575413641

Epoch: 6| Step: 5
Training loss: 2.8237039141632465
Validation loss: 2.8457704092245977

Epoch: 6| Step: 6
Training loss: 2.9329324477253005
Validation loss: 2.838058013820311

Epoch: 6| Step: 7
Training loss: 3.5080108246674335
Validation loss: 2.830360721369099

Epoch: 6| Step: 8
Training loss: 3.7071930635949624
Validation loss: 2.838537966742827

Epoch: 6| Step: 9
Training loss: 3.0314397064308545
Validation loss: 2.8215256511854765

Epoch: 6| Step: 10
Training loss: 2.525694791173633
Validation loss: 2.807837944950169

Epoch: 6| Step: 11
Training loss: 2.8333631027752104
Validation loss: 2.7979676997214944

Epoch: 6| Step: 12
Training loss: 2.3351057223905753
Validation loss: 2.790995468633715

Epoch: 6| Step: 13
Training loss: 3.5323727603574393
Validation loss: 2.780820657872066

Epoch: 18| Step: 0
Training loss: 3.101414597681817
Validation loss: 2.781926189839296

Epoch: 6| Step: 1
Training loss: 3.47237200265598
Validation loss: 2.747658955257816

Epoch: 6| Step: 2
Training loss: 2.5305451718715326
Validation loss: 2.772751590964202

Epoch: 6| Step: 3
Training loss: 2.6788775496170567
Validation loss: 2.739316847727707

Epoch: 6| Step: 4
Training loss: 3.108736979139398
Validation loss: 2.743821771879759

Epoch: 6| Step: 5
Training loss: 2.878096695718333
Validation loss: 2.7315226801832044

Epoch: 6| Step: 6
Training loss: 3.300772004424921
Validation loss: 2.7210049017618627

Epoch: 6| Step: 7
Training loss: 2.9712199326511652
Validation loss: 2.7195819170805637

Epoch: 6| Step: 8
Training loss: 2.6884151940870926
Validation loss: 2.7106866023311826

Epoch: 6| Step: 9
Training loss: 2.639197059394514
Validation loss: 2.705950309716343

Epoch: 6| Step: 10
Training loss: 4.163486233284084
Validation loss: 2.6928290521772364

Epoch: 6| Step: 11
Training loss: 3.079729465641904
Validation loss: 2.694275566522831

Epoch: 6| Step: 12
Training loss: 3.3435459252944653
Validation loss: 2.7012563706806088

Epoch: 6| Step: 13
Training loss: 2.786944442605894
Validation loss: 2.696095357886401

Epoch: 19| Step: 0
Training loss: 2.7134080342625198
Validation loss: 2.695160697287233

Epoch: 6| Step: 1
Training loss: 3.2979209650862717
Validation loss: 2.690501221662649

Epoch: 6| Step: 2
Training loss: 3.577501534195737
Validation loss: 2.681124491772737

Epoch: 6| Step: 3
Training loss: 3.415013370739075
Validation loss: 2.6721251813828073

Epoch: 6| Step: 4
Training loss: 2.7546622895608834
Validation loss: 2.687637972312789

Epoch: 6| Step: 5
Training loss: 2.8499840116888944
Validation loss: 2.6790781449114753

Epoch: 6| Step: 6
Training loss: 2.9150611454879627
Validation loss: 2.691016557698521

Epoch: 6| Step: 7
Training loss: 2.331510808433302
Validation loss: 2.682095659172829

Epoch: 6| Step: 8
Training loss: 2.925574097984088
Validation loss: 2.6801669979944864

Epoch: 6| Step: 9
Training loss: 3.541730738041583
Validation loss: 2.663843429960394

Epoch: 6| Step: 10
Training loss: 2.8516243705830755
Validation loss: 2.662688248279626

Epoch: 6| Step: 11
Training loss: 3.172396912880159
Validation loss: 2.6718651028296114

Epoch: 6| Step: 12
Training loss: 2.46815048857622
Validation loss: 2.674406637748462

Epoch: 6| Step: 13
Training loss: 3.5639209255946747
Validation loss: 2.6722503381205867

Epoch: 20| Step: 0
Training loss: 2.636422690265278
Validation loss: 2.6593221113424397

Epoch: 6| Step: 1
Training loss: 3.3353582589545265
Validation loss: 2.6576278500556283

Epoch: 6| Step: 2
Training loss: 3.6915058425305265
Validation loss: 2.6752472557468545

Epoch: 6| Step: 3
Training loss: 2.903580290506527
Validation loss: 2.6506514410836863

Epoch: 6| Step: 4
Training loss: 2.9069260662008434
Validation loss: 2.678854327363652

Epoch: 6| Step: 5
Training loss: 3.221141038205669
Validation loss: 2.673366042079153

Epoch: 6| Step: 6
Training loss: 3.6945929119008456
Validation loss: 2.6617461409869123

Epoch: 6| Step: 7
Training loss: 2.632544167085615
Validation loss: 2.675426231876556

Epoch: 6| Step: 8
Training loss: 3.1580542515738688
Validation loss: 2.6631720612563594

Epoch: 6| Step: 9
Training loss: 2.0013008655419466
Validation loss: 2.65505182410049

Epoch: 6| Step: 10
Training loss: 2.9794649806198
Validation loss: 2.653380691643452

Epoch: 6| Step: 11
Training loss: 3.0909022315862096
Validation loss: 2.6529322926054464

Epoch: 6| Step: 12
Training loss: 2.8234201148911793
Validation loss: 2.644770203168697

Epoch: 6| Step: 13
Training loss: 2.946094034863086
Validation loss: 2.6483774660250194

Epoch: 21| Step: 0
Training loss: 3.94987130740126
Validation loss: 2.6502651836883837

Epoch: 6| Step: 1
Training loss: 3.0707311757321385
Validation loss: 2.6441180494282883

Epoch: 6| Step: 2
Training loss: 2.8110631875420817
Validation loss: 2.670164451012886

Epoch: 6| Step: 3
Training loss: 3.126282390684455
Validation loss: 2.644876978895608

Epoch: 6| Step: 4
Training loss: 2.4960187682827772
Validation loss: 2.660810480148731

Epoch: 6| Step: 5
Training loss: 2.62486575555402
Validation loss: 2.657330155727098

Epoch: 6| Step: 6
Training loss: 3.3586248935445453
Validation loss: 2.634040277248614

Epoch: 6| Step: 7
Training loss: 3.258178983058563
Validation loss: 2.6583566282798987

Epoch: 6| Step: 8
Training loss: 2.778900697288081
Validation loss: 2.651646543839614

Epoch: 6| Step: 9
Training loss: 2.7170147674743292
Validation loss: 2.650935384235358

Epoch: 6| Step: 10
Training loss: 2.812238808265681
Validation loss: 2.657227587096799

Epoch: 6| Step: 11
Training loss: 2.516487305504371
Validation loss: 2.658620436091323

Epoch: 6| Step: 12
Training loss: 3.4907163384354107
Validation loss: 2.646848918889305

Epoch: 6| Step: 13
Training loss: 2.851878025940329
Validation loss: 2.6567217104585077

Epoch: 22| Step: 0
Training loss: 2.5869408818860338
Validation loss: 2.6503690374029962

Epoch: 6| Step: 1
Training loss: 2.906600110694832
Validation loss: 2.662615112861992

Epoch: 6| Step: 2
Training loss: 2.4140540064196254
Validation loss: 2.6454989679269154

Epoch: 6| Step: 3
Training loss: 2.964200197519412
Validation loss: 2.6491612631127444

Epoch: 6| Step: 4
Training loss: 3.3573528502394177
Validation loss: 2.6587335971140953

Epoch: 6| Step: 5
Training loss: 3.173846754753016
Validation loss: 2.6353566642278574

Epoch: 6| Step: 6
Training loss: 3.556223107958653
Validation loss: 2.645409533066885

Epoch: 6| Step: 7
Training loss: 3.054225408623222
Validation loss: 2.6515976740015

Epoch: 6| Step: 8
Training loss: 3.074612700099841
Validation loss: 2.656540966565266

Epoch: 6| Step: 9
Training loss: 2.758214818553937
Validation loss: 2.646749499814197

Epoch: 6| Step: 10
Training loss: 3.127398829054926
Validation loss: 2.648355330579392

Epoch: 6| Step: 11
Training loss: 3.406752243111798
Validation loss: 2.6477660223510466

Epoch: 6| Step: 12
Training loss: 2.941006130446887
Validation loss: 2.644537479434922

Epoch: 6| Step: 13
Training loss: 2.6154989232677472
Validation loss: 2.6284779055827237

Epoch: 23| Step: 0
Training loss: 2.7856103385144038
Validation loss: 2.6426217280406448

Epoch: 6| Step: 1
Training loss: 3.652210971642284
Validation loss: 2.6562652143492667

Epoch: 6| Step: 2
Training loss: 3.077598875364768
Validation loss: 2.645235108511801

Epoch: 6| Step: 3
Training loss: 3.0978866818551842
Validation loss: 2.6636615884908523

Epoch: 6| Step: 4
Training loss: 2.5347753394380614
Validation loss: 2.644092694248811

Epoch: 6| Step: 5
Training loss: 2.5886317850821876
Validation loss: 2.6332222552825777

Epoch: 6| Step: 6
Training loss: 2.925397901287853
Validation loss: 2.6487666980662468

Epoch: 6| Step: 7
Training loss: 3.3605182920076433
Validation loss: 2.6418644320955016

Epoch: 6| Step: 8
Training loss: 2.4722604058087487
Validation loss: 2.638884868377691

Epoch: 6| Step: 9
Training loss: 3.624029753177601
Validation loss: 2.633675793360346

Epoch: 6| Step: 10
Training loss: 3.5709211970009127
Validation loss: 2.6369867640879385

Epoch: 6| Step: 11
Training loss: 3.1355668514609074
Validation loss: 2.634545610096188

Epoch: 6| Step: 12
Training loss: 2.5327661941879644
Validation loss: 2.634843739617953

Epoch: 6| Step: 13
Training loss: 1.7050433073388849
Validation loss: 2.629541131462309

Epoch: 24| Step: 0
Training loss: 2.3529117806786233
Validation loss: 2.650501916632194

Epoch: 6| Step: 1
Training loss: 3.2401587332001203
Validation loss: 2.6352520087543363

Epoch: 6| Step: 2
Training loss: 2.7639866518231053
Validation loss: 2.640144956433771

Epoch: 6| Step: 3
Training loss: 3.3444846228646536
Validation loss: 2.6403682744376322

Epoch: 6| Step: 4
Training loss: 2.539346062891788
Validation loss: 2.655593178967217

Epoch: 6| Step: 5
Training loss: 2.8078553737281715
Validation loss: 2.636120145688678

Epoch: 6| Step: 6
Training loss: 2.809516680818493
Validation loss: 2.628817437466731

Epoch: 6| Step: 7
Training loss: 2.6112264129756686
Validation loss: 2.6347811492521194

Epoch: 6| Step: 8
Training loss: 3.7733815190998223
Validation loss: 2.6458710239921053

Epoch: 6| Step: 9
Training loss: 2.643878715393852
Validation loss: 2.6283572517116305

Epoch: 6| Step: 10
Training loss: 3.3972410003095996
Validation loss: 2.628143719238534

Epoch: 6| Step: 11
Training loss: 3.043692623905765
Validation loss: 2.6386896944092926

Epoch: 6| Step: 12
Training loss: 3.190017304567858
Validation loss: 2.6537894852595545

Epoch: 6| Step: 13
Training loss: 3.0923512697342854
Validation loss: 2.63715925139843

Epoch: 25| Step: 0
Training loss: 2.9984737328451785
Validation loss: 2.6315362236562763

Epoch: 6| Step: 1
Training loss: 2.9019992053966104
Validation loss: 2.6641843384978254

Epoch: 6| Step: 2
Training loss: 3.187875613352644
Validation loss: 2.651978602270436

Epoch: 6| Step: 3
Training loss: 2.4127240961384113
Validation loss: 2.6131692718245723

Epoch: 6| Step: 4
Training loss: 2.8253230762568537
Validation loss: 2.6123223187558207

Epoch: 6| Step: 5
Training loss: 3.4651605403199475
Validation loss: 2.63215623331529

Epoch: 6| Step: 6
Training loss: 2.9796418209005213
Validation loss: 2.6382178936817042

Epoch: 6| Step: 7
Training loss: 3.4383968223766557
Validation loss: 2.6306854513831

Epoch: 6| Step: 8
Training loss: 2.4371389463978193
Validation loss: 2.6365884246885862

Epoch: 6| Step: 9
Training loss: 2.5345785602518576
Validation loss: 2.61877741046375

Epoch: 6| Step: 10
Training loss: 2.744815013190237
Validation loss: 2.618939929970108

Epoch: 6| Step: 11
Training loss: 3.2032341170914944
Validation loss: 2.6382284243199

Epoch: 6| Step: 12
Training loss: 3.320565678536727
Validation loss: 2.6268524942345524

Epoch: 6| Step: 13
Training loss: 3.3975294281146096
Validation loss: 2.627589833574481

Epoch: 26| Step: 0
Training loss: 2.0344492440219453
Validation loss: 2.632577118238488

Epoch: 6| Step: 1
Training loss: 2.947122275858656
Validation loss: 2.623464433084879

Epoch: 6| Step: 2
Training loss: 3.567309161871462
Validation loss: 2.62605446215579

Epoch: 6| Step: 3
Training loss: 2.994523772268416
Validation loss: 2.637156161020649

Epoch: 6| Step: 4
Training loss: 2.342312486404422
Validation loss: 2.63542529929185

Epoch: 6| Step: 5
Training loss: 2.9757987416725515
Validation loss: 2.623182522113929

Epoch: 6| Step: 6
Training loss: 3.1015769516154186
Validation loss: 2.6511408951289126

Epoch: 6| Step: 7
Training loss: 2.5230586945687596
Validation loss: 2.6253211571592354

Epoch: 6| Step: 8
Training loss: 3.4525753636735725
Validation loss: 2.6163860682669964

Epoch: 6| Step: 9
Training loss: 2.974251879063423
Validation loss: 2.6523529661021703

Epoch: 6| Step: 10
Training loss: 3.0568229840270877
Validation loss: 2.6173790264255374

Epoch: 6| Step: 11
Training loss: 3.2016170767008902
Validation loss: 2.6202064495194386

Epoch: 6| Step: 12
Training loss: 3.261576355892559
Validation loss: 2.6255086121869917

Epoch: 6| Step: 13
Training loss: 3.4843210806331175
Validation loss: 2.640275212029242

Epoch: 27| Step: 0
Training loss: 3.118092493991547
Validation loss: 2.646360273326894

Epoch: 6| Step: 1
Training loss: 2.3313446312073274
Validation loss: 2.628313459333618

Epoch: 6| Step: 2
Training loss: 2.8679020378481983
Validation loss: 2.6006194384895047

Epoch: 6| Step: 3
Training loss: 3.4517406605873013
Validation loss: 2.6268040902772114

Epoch: 6| Step: 4
Training loss: 2.5659813841325114
Validation loss: 2.6240984007542933

Epoch: 6| Step: 5
Training loss: 3.2800293604769486
Validation loss: 2.640506272554256

Epoch: 6| Step: 6
Training loss: 3.5732839560537055
Validation loss: 2.613565559065304

Epoch: 6| Step: 7
Training loss: 3.5748145102017017
Validation loss: 2.6189500535777195

Epoch: 6| Step: 8
Training loss: 3.1145050821500164
Validation loss: 2.6390134657502213

Epoch: 6| Step: 9
Training loss: 2.653764526787419
Validation loss: 2.6321658522232916

Epoch: 6| Step: 10
Training loss: 2.9373425380627785
Validation loss: 2.649929868931407

Epoch: 6| Step: 11
Training loss: 2.798134120766961
Validation loss: 2.6300679266333407

Epoch: 6| Step: 12
Training loss: 2.2426470242447882
Validation loss: 2.622329535271867

Epoch: 6| Step: 13
Training loss: 3.1794082556474406
Validation loss: 2.604628375726517

Epoch: 28| Step: 0
Training loss: 2.7946446225932475
Validation loss: 2.620224082395689

Epoch: 6| Step: 1
Training loss: 3.29550836812136
Validation loss: 2.6276306627778947

Epoch: 6| Step: 2
Training loss: 2.7567728909003684
Validation loss: 2.626262265597207

Epoch: 6| Step: 3
Training loss: 2.6537459295010715
Validation loss: 2.6199863240585595

Epoch: 6| Step: 4
Training loss: 3.456114428656801
Validation loss: 2.610608576678554

Epoch: 6| Step: 5
Training loss: 3.5928561218485617
Validation loss: 2.6450202673824816

Epoch: 6| Step: 6
Training loss: 3.3540165237720343
Validation loss: 2.6316643102058457

Epoch: 6| Step: 7
Training loss: 2.572372028811979
Validation loss: 2.630154968779524

Epoch: 6| Step: 8
Training loss: 2.870970514468285
Validation loss: 2.6349768141242684

Epoch: 6| Step: 9
Training loss: 2.7733981277465003
Validation loss: 2.63467238220846

Epoch: 6| Step: 10
Training loss: 2.6709577982720254
Validation loss: 2.6089532118410146

Epoch: 6| Step: 11
Training loss: 2.9109239628098744
Validation loss: 2.6123238084668516

Epoch: 6| Step: 12
Training loss: 2.9753171863885606
Validation loss: 2.6181698827093665

Epoch: 6| Step: 13
Training loss: 2.7989222530021856
Validation loss: 2.642962432905479

Epoch: 29| Step: 0
Training loss: 2.8418336217018507
Validation loss: 2.628160079548891

Epoch: 6| Step: 1
Training loss: 2.871328248289253
Validation loss: 2.630836115752696

Epoch: 6| Step: 2
Training loss: 2.7706125405666286
Validation loss: 2.6241927333931643

Epoch: 6| Step: 3
Training loss: 2.8279171018954696
Validation loss: 2.6126517440422528

Epoch: 6| Step: 4
Training loss: 2.297713976371279
Validation loss: 2.6259572041331887

Epoch: 6| Step: 5
Training loss: 2.566745311803745
Validation loss: 2.636565742990611

Epoch: 6| Step: 6
Training loss: 3.232894927384933
Validation loss: 2.629620509749109

Epoch: 6| Step: 7
Training loss: 2.561570161661639
Validation loss: 2.635005694337249

Epoch: 6| Step: 8
Training loss: 2.7987085225012085
Validation loss: 2.6142340809519196

Epoch: 6| Step: 9
Training loss: 2.7930476250881835
Validation loss: 2.6160567976746654

Epoch: 6| Step: 10
Training loss: 3.0701025194576923
Validation loss: 2.6131983793128826

Epoch: 6| Step: 11
Training loss: 3.905851786343138
Validation loss: 2.6283778242942324

Epoch: 6| Step: 12
Training loss: 3.5414828682872477
Validation loss: 2.6252665455192976

Epoch: 6| Step: 13
Training loss: 3.4279609800897775
Validation loss: 2.632532826854414

Epoch: 30| Step: 0
Training loss: 3.3796817661330234
Validation loss: 2.6168989967454386

Epoch: 6| Step: 1
Training loss: 2.7073147447773445
Validation loss: 2.636722617744699

Epoch: 6| Step: 2
Training loss: 2.750615831258861
Validation loss: 2.637223175424891

Epoch: 6| Step: 3
Training loss: 3.2060045650304514
Validation loss: 2.631685810623324

Epoch: 6| Step: 4
Training loss: 2.3395626045683366
Validation loss: 2.597175102939035

Epoch: 6| Step: 5
Training loss: 2.792051877067226
Validation loss: 2.6176224395058836

Epoch: 6| Step: 6
Training loss: 2.6247338659617405
Validation loss: 2.6093434860038935

Epoch: 6| Step: 7
Training loss: 3.182907985477833
Validation loss: 2.6192906174413872

Epoch: 6| Step: 8
Training loss: 3.1526860425900467
Validation loss: 2.626321949025147

Epoch: 6| Step: 9
Training loss: 2.8019343812816273
Validation loss: 2.6252441917709772

Epoch: 6| Step: 10
Training loss: 2.928900936078135
Validation loss: 2.6113202769728447

Epoch: 6| Step: 11
Training loss: 3.6964316094954004
Validation loss: 2.6189941420100933

Epoch: 6| Step: 12
Training loss: 2.4313401860080495
Validation loss: 2.6131369834218363

Epoch: 6| Step: 13
Training loss: 3.914087230733684
Validation loss: 2.615016506388219

Epoch: 31| Step: 0
Training loss: 3.6322107616560255
Validation loss: 2.6387353514208005

Epoch: 6| Step: 1
Training loss: 2.464970750151568
Validation loss: 2.629879975796312

Epoch: 6| Step: 2
Training loss: 2.9850951918562596
Validation loss: 2.629515477782931

Epoch: 6| Step: 3
Training loss: 2.1445219112672347
Validation loss: 2.6173449348185605

Epoch: 6| Step: 4
Training loss: 3.320583341435205
Validation loss: 2.6311450545555464

Epoch: 6| Step: 5
Training loss: 2.349929800405428
Validation loss: 2.6182082052924596

Epoch: 6| Step: 6
Training loss: 2.5857061645663295
Validation loss: 2.6291017767882767

Epoch: 6| Step: 7
Training loss: 3.551076945969531
Validation loss: 2.618979852995214

Epoch: 6| Step: 8
Training loss: 2.1055280857536576
Validation loss: 2.625143641005418

Epoch: 6| Step: 9
Training loss: 3.09678855182539
Validation loss: 2.623398908300127

Epoch: 6| Step: 10
Training loss: 2.7816299864687815
Validation loss: 2.6337977157092243

Epoch: 6| Step: 11
Training loss: 3.2507273520338096
Validation loss: 2.6169809920229965

Epoch: 6| Step: 12
Training loss: 3.331760480462232
Validation loss: 2.624478039704043

Epoch: 6| Step: 13
Training loss: 3.9142334190709893
Validation loss: 2.6039547807365544

Epoch: 32| Step: 0
Training loss: 2.8987321318305583
Validation loss: 2.603772055640645

Epoch: 6| Step: 1
Training loss: 2.9838134876491775
Validation loss: 2.613200716138633

Epoch: 6| Step: 2
Training loss: 2.7193759767587142
Validation loss: 2.628610989783664

Epoch: 6| Step: 3
Training loss: 2.7359626738361236
Validation loss: 2.6132259001596037

Epoch: 6| Step: 4
Training loss: 3.49228335255408
Validation loss: 2.6153856353943845

Epoch: 6| Step: 5
Training loss: 3.2247534014436003
Validation loss: 2.6510095158998306

Epoch: 6| Step: 6
Training loss: 3.317308354882692
Validation loss: 2.618156630551667

Epoch: 6| Step: 7
Training loss: 3.0636233390981973
Validation loss: 2.628171546922509

Epoch: 6| Step: 8
Training loss: 3.3333142438977723
Validation loss: 2.622037003452756

Epoch: 6| Step: 9
Training loss: 3.181195325700129
Validation loss: 2.6441711722542802

Epoch: 6| Step: 10
Training loss: 2.4283738095958083
Validation loss: 2.618666393721149

Epoch: 6| Step: 11
Training loss: 2.307494442355488
Validation loss: 2.6023172593507273

Epoch: 6| Step: 12
Training loss: 2.884182405499583
Validation loss: 2.6274379936757275

Epoch: 6| Step: 13
Training loss: 2.9435819606240172
Validation loss: 2.6037272092766894

Epoch: 33| Step: 0
Training loss: 2.79876798364161
Validation loss: 2.6086550416853616

Epoch: 6| Step: 1
Training loss: 2.8443703446405677
Validation loss: 2.6108495662308906

Epoch: 6| Step: 2
Training loss: 3.0612592713981597
Validation loss: 2.5967586427443474

Epoch: 6| Step: 3
Training loss: 2.3598749502640577
Validation loss: 2.604838948421403

Epoch: 6| Step: 4
Training loss: 2.847271426222825
Validation loss: 2.621932662088672

Epoch: 6| Step: 5
Training loss: 3.770452799836632
Validation loss: 2.615795135267238

Epoch: 6| Step: 6
Training loss: 3.4424501323204644
Validation loss: 2.619495073087285

Epoch: 6| Step: 7
Training loss: 2.962724372962163
Validation loss: 2.6033790545850954

Epoch: 6| Step: 8
Training loss: 2.686452439651641
Validation loss: 2.6065686314974066

Epoch: 6| Step: 9
Training loss: 2.592443021996075
Validation loss: 2.6173417495431663

Epoch: 6| Step: 10
Training loss: 3.1152385077852682
Validation loss: 2.622416250647953

Epoch: 6| Step: 11
Training loss: 2.8616024159272757
Validation loss: 2.593030552789552

Epoch: 6| Step: 12
Training loss: 3.1324336329414413
Validation loss: 2.624006607842698

Epoch: 6| Step: 13
Training loss: 2.9359193160796817
Validation loss: 2.5906103083591523

Epoch: 34| Step: 0
Training loss: 2.711803726627668
Validation loss: 2.624751281870114

Epoch: 6| Step: 1
Training loss: 3.2984042846799895
Validation loss: 2.6170363937098675

Epoch: 6| Step: 2
Training loss: 1.940827127885978
Validation loss: 2.6145223899621555

Epoch: 6| Step: 3
Training loss: 2.8614557752029617
Validation loss: 2.6274719806687274

Epoch: 6| Step: 4
Training loss: 2.7014387747749202
Validation loss: 2.6044078067170777

Epoch: 6| Step: 5
Training loss: 3.148334208041208
Validation loss: 2.6028475669623035

Epoch: 6| Step: 6
Training loss: 3.24419383281547
Validation loss: 2.6267973434967655

Epoch: 6| Step: 7
Training loss: 3.057267526317909
Validation loss: 2.587032252811766

Epoch: 6| Step: 8
Training loss: 3.840537116315487
Validation loss: 2.607393680346485

Epoch: 6| Step: 9
Training loss: 2.719872604640451
Validation loss: 2.6083216312851905

Epoch: 6| Step: 10
Training loss: 3.2225825630780185
Validation loss: 2.633346545810765

Epoch: 6| Step: 11
Training loss: 2.449965757013916
Validation loss: 2.611143493764269

Epoch: 6| Step: 12
Training loss: 2.9525247599623814
Validation loss: 2.6084296867388344

Epoch: 6| Step: 13
Training loss: 3.2399188457733423
Validation loss: 2.6081142669945456

Epoch: 35| Step: 0
Training loss: 2.8698864117517653
Validation loss: 2.617864613189573

Epoch: 6| Step: 1
Training loss: 3.396766549970003
Validation loss: 2.6157230497556476

Epoch: 6| Step: 2
Training loss: 3.1665794628249526
Validation loss: 2.5906751830521455

Epoch: 6| Step: 3
Training loss: 2.090039509669025
Validation loss: 2.606618748796607

Epoch: 6| Step: 4
Training loss: 3.3354228781920874
Validation loss: 2.6069382909231433

Epoch: 6| Step: 5
Training loss: 3.3039062153619354
Validation loss: 2.611166986351835

Epoch: 6| Step: 6
Training loss: 2.983611163907351
Validation loss: 2.6255173180742637

Epoch: 6| Step: 7
Training loss: 2.7379112701138357
Validation loss: 2.6244955081043186

Epoch: 6| Step: 8
Training loss: 2.639420183695164
Validation loss: 2.623059414398761

Epoch: 6| Step: 9
Training loss: 3.275665617416036
Validation loss: 2.600774122607827

Epoch: 6| Step: 10
Training loss: 2.8804985208320493
Validation loss: 2.6101751340514516

Epoch: 6| Step: 11
Training loss: 2.9826169253098076
Validation loss: 2.6221840066971445

Epoch: 6| Step: 12
Training loss: 2.753932395432183
Validation loss: 2.5969980735130567

Epoch: 6| Step: 13
Training loss: 2.945339860460202
Validation loss: 2.623754702084104

Epoch: 36| Step: 0
Training loss: 2.467044096071339
Validation loss: 2.614457188712209

Epoch: 6| Step: 1
Training loss: 3.3505809564867524
Validation loss: 2.596945615546037

Epoch: 6| Step: 2
Training loss: 3.002738338669818
Validation loss: 2.6038932210451193

Epoch: 6| Step: 3
Training loss: 2.870863551039395
Validation loss: 2.595960886317807

Epoch: 6| Step: 4
Training loss: 2.2712276244754017
Validation loss: 2.6181952079112

Epoch: 6| Step: 5
Training loss: 3.489962763109461
Validation loss: 2.5979606115180234

Epoch: 6| Step: 6
Training loss: 3.24737266566933
Validation loss: 2.6046458305969

Epoch: 6| Step: 7
Training loss: 2.8277386986364412
Validation loss: 2.5945454358877496

Epoch: 6| Step: 8
Training loss: 3.1828919555754167
Validation loss: 2.604997180707855

Epoch: 6| Step: 9
Training loss: 2.643961947988221
Validation loss: 2.6152878208356145

Epoch: 6| Step: 10
Training loss: 2.825377251746226
Validation loss: 2.60573102335714

Epoch: 6| Step: 11
Training loss: 3.028085846544475
Validation loss: 2.6036741582642207

Epoch: 6| Step: 12
Training loss: 3.227542460522039
Validation loss: 2.598654239938601

Epoch: 6| Step: 13
Training loss: 2.520700960913568
Validation loss: 2.629064697323682

Epoch: 37| Step: 0
Training loss: 3.064412823637559
Validation loss: 2.6132470509787575

Epoch: 6| Step: 1
Training loss: 3.26492155976876
Validation loss: 2.6083414232598447

Epoch: 6| Step: 2
Training loss: 3.3792229123653676
Validation loss: 2.602837146308953

Epoch: 6| Step: 3
Training loss: 3.4244295800780566
Validation loss: 2.611397891294917

Epoch: 6| Step: 4
Training loss: 2.9388040123717545
Validation loss: 2.595437388691534

Epoch: 6| Step: 5
Training loss: 3.081703545731551
Validation loss: 2.6196889164629895

Epoch: 6| Step: 6
Training loss: 2.426309377581463
Validation loss: 2.5963198161028465

Epoch: 6| Step: 7
Training loss: 2.807813766895278
Validation loss: 2.609387628678127

Epoch: 6| Step: 8
Training loss: 2.420015962879088
Validation loss: 2.6043624968371732

Epoch: 6| Step: 9
Training loss: 2.773262125837281
Validation loss: 2.597644180120541

Epoch: 6| Step: 10
Training loss: 2.7177465055764487
Validation loss: 2.5911471535022867

Epoch: 6| Step: 11
Training loss: 3.0781934701497975
Validation loss: 2.59993872002356

Epoch: 6| Step: 12
Training loss: 3.210223116146966
Validation loss: 2.600440691563007

Epoch: 6| Step: 13
Training loss: 2.462045087282177
Validation loss: 2.590694433971732

Epoch: 38| Step: 0
Training loss: 2.926181821815126
Validation loss: 2.603326583392322

Epoch: 6| Step: 1
Training loss: 3.119638039060137
Validation loss: 2.604800954707852

Epoch: 6| Step: 2
Training loss: 2.991638611331681
Validation loss: 2.5887151035148084

Epoch: 6| Step: 3
Training loss: 3.4558682829340093
Validation loss: 2.6060554739288384

Epoch: 6| Step: 4
Training loss: 3.2944392024301044
Validation loss: 2.5954747490400907

Epoch: 6| Step: 5
Training loss: 2.575822484036662
Validation loss: 2.628937155028074

Epoch: 6| Step: 6
Training loss: 2.9907631135656403
Validation loss: 2.597610334813559

Epoch: 6| Step: 7
Training loss: 2.5403683165590096
Validation loss: 2.5999693866375733

Epoch: 6| Step: 8
Training loss: 3.2636496670399415
Validation loss: 2.629248067170605

Epoch: 6| Step: 9
Training loss: 2.6143208304822885
Validation loss: 2.5897120586423226

Epoch: 6| Step: 10
Training loss: 3.1960645317657366
Validation loss: 2.5935147847578937

Epoch: 6| Step: 11
Training loss: 2.9731396797079195
Validation loss: 2.59323291094231

Epoch: 6| Step: 12
Training loss: 2.728400979606476
Validation loss: 2.607915628252397

Epoch: 6| Step: 13
Training loss: 2.666502162707153
Validation loss: 2.598586658065241

Epoch: 39| Step: 0
Training loss: 3.4933381030605846
Validation loss: 2.5966048074272643

Epoch: 6| Step: 1
Training loss: 3.0069007978044295
Validation loss: 2.6002678808683277

Epoch: 6| Step: 2
Training loss: 2.6608903630954175
Validation loss: 2.5923433825049336

Epoch: 6| Step: 3
Training loss: 2.2141992886109096
Validation loss: 2.602525953372843

Epoch: 6| Step: 4
Training loss: 2.3061141431537298
Validation loss: 2.5954701284127575

Epoch: 6| Step: 5
Training loss: 2.7030175689340807
Validation loss: 2.612318659244681

Epoch: 6| Step: 6
Training loss: 2.9365414617941186
Validation loss: 2.628949385486302

Epoch: 6| Step: 7
Training loss: 2.7922475884135385
Validation loss: 2.6048740294213895

Epoch: 6| Step: 8
Training loss: 2.9803541968893588
Validation loss: 2.583291108669212

Epoch: 6| Step: 9
Training loss: 3.2061556737160415
Validation loss: 2.6042949941867333

Epoch: 6| Step: 10
Training loss: 3.3328892094064173
Validation loss: 2.582579482561797

Epoch: 6| Step: 11
Training loss: 2.539022310379044
Validation loss: 2.614359513472694

Epoch: 6| Step: 12
Training loss: 3.331923345538128
Validation loss: 2.5932885624492

Epoch: 6| Step: 13
Training loss: 3.587095119477486
Validation loss: 2.609646370491865

Epoch: 40| Step: 0
Training loss: 3.2359341166877833
Validation loss: 2.5797722370361655

Epoch: 6| Step: 1
Training loss: 2.421462288423632
Validation loss: 2.590557437023977

Epoch: 6| Step: 2
Training loss: 3.0962732987341575
Validation loss: 2.603200434118281

Epoch: 6| Step: 3
Training loss: 2.755943205144418
Validation loss: 2.5902400309620504

Epoch: 6| Step: 4
Training loss: 3.084723666039666
Validation loss: 2.59099096951687

Epoch: 6| Step: 5
Training loss: 3.315739612953376
Validation loss: 2.5877886099510072

Epoch: 6| Step: 6
Training loss: 2.5779452174531277
Validation loss: 2.596024938994703

Epoch: 6| Step: 7
Training loss: 3.0802673010825155
Validation loss: 2.5886143811816344

Epoch: 6| Step: 8
Training loss: 3.46268558486845
Validation loss: 2.6018515125794863

Epoch: 6| Step: 9
Training loss: 2.669325297970766
Validation loss: 2.6089880694919545

Epoch: 6| Step: 10
Training loss: 1.6196629104057783
Validation loss: 2.6118954501436424

Epoch: 6| Step: 11
Training loss: 3.2203954546228126
Validation loss: 2.604520799410233

Epoch: 6| Step: 12
Training loss: 3.0628808232410756
Validation loss: 2.6121533183804115

Epoch: 6| Step: 13
Training loss: 3.482265227127386
Validation loss: 2.5966259238184857

Epoch: 41| Step: 0
Training loss: 2.9861397044466385
Validation loss: 2.5869589545645733

Epoch: 6| Step: 1
Training loss: 2.982266145348925
Validation loss: 2.5895722397439664

Epoch: 6| Step: 2
Training loss: 2.7094706763739613
Validation loss: 2.5997683791868895

Epoch: 6| Step: 3
Training loss: 3.11429471280859
Validation loss: 2.596437880397768

Epoch: 6| Step: 4
Training loss: 2.332042700453463
Validation loss: 2.5883617650990423

Epoch: 6| Step: 5
Training loss: 1.7815022206342135
Validation loss: 2.5971740694575898

Epoch: 6| Step: 6
Training loss: 3.9584481205944204
Validation loss: 2.60206871893311

Epoch: 6| Step: 7
Training loss: 3.226664174396824
Validation loss: 2.5970008809814566

Epoch: 6| Step: 8
Training loss: 2.5069321843132504
Validation loss: 2.6063180010369402

Epoch: 6| Step: 9
Training loss: 3.334907319069336
Validation loss: 2.597960698355511

Epoch: 6| Step: 10
Training loss: 2.7058792635590265
Validation loss: 2.5821747257429646

Epoch: 6| Step: 11
Training loss: 3.4778145239381355
Validation loss: 2.574285939880097

Epoch: 6| Step: 12
Training loss: 2.8649501126458063
Validation loss: 2.570118922476324

Epoch: 6| Step: 13
Training loss: 2.2727991630281426
Validation loss: 2.5827066598871813

Epoch: 42| Step: 0
Training loss: 3.064788119287447
Validation loss: 2.592950017788542

Epoch: 6| Step: 1
Training loss: 2.9736636005179555
Validation loss: 2.5838191309664955

Epoch: 6| Step: 2
Training loss: 3.005905537687681
Validation loss: 2.5920704289858194

Epoch: 6| Step: 3
Training loss: 3.111558770337177
Validation loss: 2.5937965666624283

Epoch: 6| Step: 4
Training loss: 3.034600519979019
Validation loss: 2.5907147366396694

Epoch: 6| Step: 5
Training loss: 3.8125943031529816
Validation loss: 2.578086114405587

Epoch: 6| Step: 6
Training loss: 2.8576960402797167
Validation loss: 2.578806515902885

Epoch: 6| Step: 7
Training loss: 3.0020465228232744
Validation loss: 2.590028702914226

Epoch: 6| Step: 8
Training loss: 2.0104581864834663
Validation loss: 2.6084922735287277

Epoch: 6| Step: 9
Training loss: 2.4535417142081313
Validation loss: 2.583100239091646

Epoch: 6| Step: 10
Training loss: 2.765029067150561
Validation loss: 2.5956258186755505

Epoch: 6| Step: 11
Training loss: 3.2914770691426507
Validation loss: 2.5717715566111985

Epoch: 6| Step: 12
Training loss: 2.770236637047102
Validation loss: 2.5720880333297167

Epoch: 6| Step: 13
Training loss: 2.662273085689762
Validation loss: 2.597057989205199

Epoch: 43| Step: 0
Training loss: 3.4760360490621904
Validation loss: 2.5952127974517203

Epoch: 6| Step: 1
Training loss: 2.6401531091276182
Validation loss: 2.586925462978011

Epoch: 6| Step: 2
Training loss: 2.7171056751568354
Validation loss: 2.587735388711088

Epoch: 6| Step: 3
Training loss: 2.612978063766486
Validation loss: 2.584703721709994

Epoch: 6| Step: 4
Training loss: 3.4400794321692323
Validation loss: 2.570602035136055

Epoch: 6| Step: 5
Training loss: 2.9263004509488826
Validation loss: 2.59843647290084

Epoch: 6| Step: 6
Training loss: 3.138654555704394
Validation loss: 2.59322941034752

Epoch: 6| Step: 7
Training loss: 2.460416514638648
Validation loss: 2.577710031951522

Epoch: 6| Step: 8
Training loss: 2.7822015399015165
Validation loss: 2.5766715787152434

Epoch: 6| Step: 9
Training loss: 3.359141213022441
Validation loss: 2.5862971140901596

Epoch: 6| Step: 10
Training loss: 3.002232992098177
Validation loss: 2.5973632439999936

Epoch: 6| Step: 11
Training loss: 3.044481168496062
Validation loss: 2.59315106241872

Epoch: 6| Step: 12
Training loss: 2.7354362826044705
Validation loss: 2.5715980480447027

Epoch: 6| Step: 13
Training loss: 2.750826971383198
Validation loss: 2.5589510895686263

Epoch: 44| Step: 0
Training loss: 3.048801849662562
Validation loss: 2.5776881479586375

Epoch: 6| Step: 1
Training loss: 3.516380940863013
Validation loss: 2.5975833936576653

Epoch: 6| Step: 2
Training loss: 2.9362772567867537
Validation loss: 2.593895995163581

Epoch: 6| Step: 3
Training loss: 2.7328413667893634
Validation loss: 2.5854528969572934

Epoch: 6| Step: 4
Training loss: 3.701961543810333
Validation loss: 2.6029316161812863

Epoch: 6| Step: 5
Training loss: 2.8212300760210436
Validation loss: 2.5739608939996605

Epoch: 6| Step: 6
Training loss: 3.80143558088072
Validation loss: 2.5971630327977113

Epoch: 6| Step: 7
Training loss: 2.9145754447068586
Validation loss: 2.5768907731826682

Epoch: 6| Step: 8
Training loss: 2.3383932314338565
Validation loss: 2.613058774218179

Epoch: 6| Step: 9
Training loss: 3.1710749777618634
Validation loss: 2.6016222396239663

Epoch: 6| Step: 10
Training loss: 2.2232549360523532
Validation loss: 2.5981312060583774

Epoch: 6| Step: 11
Training loss: 2.1053523383576276
Validation loss: 2.611154505695557

Epoch: 6| Step: 12
Training loss: 2.5653350777782027
Validation loss: 2.596660674461024

Epoch: 6| Step: 13
Training loss: 3.0396480045319523
Validation loss: 2.5709074795256024

Epoch: 45| Step: 0
Training loss: 3.5764614719239254
Validation loss: 2.575342870190866

Epoch: 6| Step: 1
Training loss: 2.7267258384769404
Validation loss: 2.6131616731176583

Epoch: 6| Step: 2
Training loss: 2.582402697462968
Validation loss: 2.6088061872969908

Epoch: 6| Step: 3
Training loss: 2.766203394177034
Validation loss: 2.6075184823427278

Epoch: 6| Step: 4
Training loss: 2.844798806422598
Validation loss: 2.5759484384353137

Epoch: 6| Step: 5
Training loss: 2.9770875803065366
Validation loss: 2.584237445272946

Epoch: 6| Step: 6
Training loss: 3.029962954656673
Validation loss: 2.6099293133358112

Epoch: 6| Step: 7
Training loss: 2.828454435772169
Validation loss: 2.5869697820571846

Epoch: 6| Step: 8
Training loss: 2.338884312959223
Validation loss: 2.5931211475978824

Epoch: 6| Step: 9
Training loss: 2.9897010771175063
Validation loss: 2.590670697351608

Epoch: 6| Step: 10
Training loss: 2.391606546991029
Validation loss: 2.5838216392227054

Epoch: 6| Step: 11
Training loss: 3.6868867525856555
Validation loss: 2.5999862141239767

Epoch: 6| Step: 12
Training loss: 3.256819685819647
Validation loss: 2.5791443958209226

Epoch: 6| Step: 13
Training loss: 2.795126938777886
Validation loss: 2.569532879415487

Epoch: 46| Step: 0
Training loss: 3.2196941287322267
Validation loss: 2.5892030178895182

Epoch: 6| Step: 1
Training loss: 3.171221134834805
Validation loss: 2.6001068509771352

Epoch: 6| Step: 2
Training loss: 2.3217920794255043
Validation loss: 2.5847635370642217

Epoch: 6| Step: 3
Training loss: 2.7714186506697747
Validation loss: 2.5905265372680186

Epoch: 6| Step: 4
Training loss: 3.2048210305935596
Validation loss: 2.580634966184105

Epoch: 6| Step: 5
Training loss: 2.4714097772792445
Validation loss: 2.60159353276949

Epoch: 6| Step: 6
Training loss: 2.566749120188802
Validation loss: 2.586486998928116

Epoch: 6| Step: 7
Training loss: 2.952114679192115
Validation loss: 2.58655411493273

Epoch: 6| Step: 8
Training loss: 3.0338493292555766
Validation loss: 2.5884558204005046

Epoch: 6| Step: 9
Training loss: 3.277889601816879
Validation loss: 2.584240202122375

Epoch: 6| Step: 10
Training loss: 2.436873330964199
Validation loss: 2.5988880756014376

Epoch: 6| Step: 11
Training loss: 3.1124626433187417
Validation loss: 2.5661544852373988

Epoch: 6| Step: 12
Training loss: 3.253092834724058
Validation loss: 2.561581247591002

Epoch: 6| Step: 13
Training loss: 3.0717610055722115
Validation loss: 2.6022010962256883

Epoch: 47| Step: 0
Training loss: 2.8978535765730684
Validation loss: 2.571834309813181

Epoch: 6| Step: 1
Training loss: 2.6243588709125514
Validation loss: 2.573458273092181

Epoch: 6| Step: 2
Training loss: 2.741628823603734
Validation loss: 2.5856117950777033

Epoch: 6| Step: 3
Training loss: 2.247346797215135
Validation loss: 2.577735806370571

Epoch: 6| Step: 4
Training loss: 3.116931876120095
Validation loss: 2.5695225940346624

Epoch: 6| Step: 5
Training loss: 2.657195158705923
Validation loss: 2.59098791262763

Epoch: 6| Step: 6
Training loss: 2.8786705469255796
Validation loss: 2.600413547067884

Epoch: 6| Step: 7
Training loss: 2.5025505406842834
Validation loss: 2.5830161693540243

Epoch: 6| Step: 8
Training loss: 3.229040492064113
Validation loss: 2.578934517480852

Epoch: 6| Step: 9
Training loss: 2.9439235822358625
Validation loss: 2.5682675563607846

Epoch: 6| Step: 10
Training loss: 2.6319766203412964
Validation loss: 2.56036787273365

Epoch: 6| Step: 11
Training loss: 3.2304852818500813
Validation loss: 2.577830043512631

Epoch: 6| Step: 12
Training loss: 3.846951027931563
Validation loss: 2.5589405152036346

Epoch: 6| Step: 13
Training loss: 3.0507767172961686
Validation loss: 2.587281126911125

Epoch: 48| Step: 0
Training loss: 2.7027185388049566
Validation loss: 2.5695553347061453

Epoch: 6| Step: 1
Training loss: 2.327008075459119
Validation loss: 2.574025442339571

Epoch: 6| Step: 2
Training loss: 3.0036493992716786
Validation loss: 2.577896998053876

Epoch: 6| Step: 3
Training loss: 3.002550312672038
Validation loss: 2.574864818777228

Epoch: 6| Step: 4
Training loss: 2.8567441083039955
Validation loss: 2.598623146418073

Epoch: 6| Step: 5
Training loss: 2.5077619220707708
Validation loss: 2.5646191240159393

Epoch: 6| Step: 6
Training loss: 3.1210983333625606
Validation loss: 2.606109970712977

Epoch: 6| Step: 7
Training loss: 2.9304603472807584
Validation loss: 2.579427925480733

Epoch: 6| Step: 8
Training loss: 2.992085826132396
Validation loss: 2.558028236333827

Epoch: 6| Step: 9
Training loss: 3.027801597182658
Validation loss: 2.5879876464190965

Epoch: 6| Step: 10
Training loss: 2.6130212218236353
Validation loss: 2.584091334989003

Epoch: 6| Step: 11
Training loss: 3.2561619371451855
Validation loss: 2.5685464198942274

Epoch: 6| Step: 12
Training loss: 3.260975132767547
Validation loss: 2.583448226535844

Epoch: 6| Step: 13
Training loss: 2.966011631547341
Validation loss: 2.579876582324271

Epoch: 49| Step: 0
Training loss: 3.2207700445973755
Validation loss: 2.576959810435113

Epoch: 6| Step: 1
Training loss: 2.3651932477328557
Validation loss: 2.5867711370321556

Epoch: 6| Step: 2
Training loss: 2.86362062865499
Validation loss: 2.570269572359605

Epoch: 6| Step: 3
Training loss: 3.0446030191053337
Validation loss: 2.573806072577879

Epoch: 6| Step: 4
Training loss: 2.5489020208995865
Validation loss: 2.5773963333533634

Epoch: 6| Step: 5
Training loss: 2.6909525672987815
Validation loss: 2.577180209894622

Epoch: 6| Step: 6
Training loss: 3.3352267292052393
Validation loss: 2.550407706065476

Epoch: 6| Step: 7
Training loss: 2.8070092752192664
Validation loss: 2.5489414774353407

Epoch: 6| Step: 8
Training loss: 3.7808529984319614
Validation loss: 2.5803064766901054

Epoch: 6| Step: 9
Training loss: 2.7282539083780897
Validation loss: 2.557473384592104

Epoch: 6| Step: 10
Training loss: 2.643431216380264
Validation loss: 2.573718385777014

Epoch: 6| Step: 11
Training loss: 2.9190180065283124
Validation loss: 2.553310725126652

Epoch: 6| Step: 12
Training loss: 2.7435808690108345
Validation loss: 2.5521172041379225

Epoch: 6| Step: 13
Training loss: 3.1145154930730072
Validation loss: 2.569966270680632

Epoch: 50| Step: 0
Training loss: 2.744582649008102
Validation loss: 2.595880427414218

Epoch: 6| Step: 1
Training loss: 2.710545580234595
Validation loss: 2.5576626789817096

Epoch: 6| Step: 2
Training loss: 2.969077323135394
Validation loss: 2.5883333177582837

Epoch: 6| Step: 3
Training loss: 2.7483084417927417
Validation loss: 2.5521053759435173

Epoch: 6| Step: 4
Training loss: 2.033755942759773
Validation loss: 2.550315356715815

Epoch: 6| Step: 5
Training loss: 3.11205739623931
Validation loss: 2.559900491466738

Epoch: 6| Step: 6
Training loss: 2.4213454128956955
Validation loss: 2.5842785090295073

Epoch: 6| Step: 7
Training loss: 2.9215467952053595
Validation loss: 2.5462580369610897

Epoch: 6| Step: 8
Training loss: 3.8496417039881092
Validation loss: 2.547350735059623

Epoch: 6| Step: 9
Training loss: 2.0329373907007753
Validation loss: 2.5443163179258277

Epoch: 6| Step: 10
Training loss: 2.814907654082667
Validation loss: 2.5778216778020706

Epoch: 6| Step: 11
Training loss: 3.3162733934298454
Validation loss: 2.5535516927546382

Epoch: 6| Step: 12
Training loss: 3.0470868941744036
Validation loss: 2.5910336122262456

Epoch: 6| Step: 13
Training loss: 3.688466866672125
Validation loss: 2.563866946761263

Epoch: 51| Step: 0
Training loss: 3.2296311239296775
Validation loss: 2.5755797867918906

Epoch: 6| Step: 1
Training loss: 2.531558736175124
Validation loss: 2.5934178534674333

Epoch: 6| Step: 2
Training loss: 2.587192380743656
Validation loss: 2.5861516703408176

Epoch: 6| Step: 3
Training loss: 2.8045352480056134
Validation loss: 2.5647659087890506

Epoch: 6| Step: 4
Training loss: 2.628594979482786
Validation loss: 2.5772593715889975

Epoch: 6| Step: 5
Training loss: 2.627201973285468
Validation loss: 2.5740985591151424

Epoch: 6| Step: 6
Training loss: 3.128057128901639
Validation loss: 2.564511959678525

Epoch: 6| Step: 7
Training loss: 2.794889373910216
Validation loss: 2.5756663392466894

Epoch: 6| Step: 8
Training loss: 2.2622677889362794
Validation loss: 2.569316993515357

Epoch: 6| Step: 9
Training loss: 2.4506212809154304
Validation loss: 2.5602061882274176

Epoch: 6| Step: 10
Training loss: 3.0971160456120774
Validation loss: 2.5453633514862006

Epoch: 6| Step: 11
Training loss: 3.2898367289928196
Validation loss: 2.572074056346875

Epoch: 6| Step: 12
Training loss: 3.8614395117817675
Validation loss: 2.5712361747410735

Epoch: 6| Step: 13
Training loss: 3.1404897176728794
Validation loss: 2.542584368730003

Epoch: 52| Step: 0
Training loss: 2.8262440870612076
Validation loss: 2.552534600333178

Epoch: 6| Step: 1
Training loss: 2.680833577005954
Validation loss: 2.564801954713798

Epoch: 6| Step: 2
Training loss: 3.254084881004299
Validation loss: 2.5705742753656136

Epoch: 6| Step: 3
Training loss: 3.1585733153092383
Validation loss: 2.550902125469456

Epoch: 6| Step: 4
Training loss: 2.854485839669644
Validation loss: 2.5711018816065847

Epoch: 6| Step: 5
Training loss: 2.413277408872186
Validation loss: 2.5686311912741004

Epoch: 6| Step: 6
Training loss: 2.295270605983879
Validation loss: 2.5779304557777087

Epoch: 6| Step: 7
Training loss: 3.1239307863234194
Validation loss: 2.5652698650512304

Epoch: 6| Step: 8
Training loss: 3.061374846872556
Validation loss: 2.5477614926915035

Epoch: 6| Step: 9
Training loss: 2.4499004577344805
Validation loss: 2.561078379314093

Epoch: 6| Step: 10
Training loss: 3.2039689603675976
Validation loss: 2.5669564414230925

Epoch: 6| Step: 11
Training loss: 3.068086161551228
Validation loss: 2.576691635687524

Epoch: 6| Step: 12
Training loss: 3.3379630521234516
Validation loss: 2.5596728272141656

Epoch: 6| Step: 13
Training loss: 2.258884373495794
Validation loss: 2.5639828059155065

Epoch: 53| Step: 0
Training loss: 2.98531626292714
Validation loss: 2.566067280265495

Epoch: 6| Step: 1
Training loss: 3.2263508651083126
Validation loss: 2.562898688386318

Epoch: 6| Step: 2
Training loss: 1.990355722847778
Validation loss: 2.5564400264182017

Epoch: 6| Step: 3
Training loss: 2.8349619466928964
Validation loss: 2.55641408843384

Epoch: 6| Step: 4
Training loss: 3.1152570287185726
Validation loss: 2.5559811364434473

Epoch: 6| Step: 5
Training loss: 3.0039579984773774
Validation loss: 2.5699823509530577

Epoch: 6| Step: 6
Training loss: 3.403167449714442
Validation loss: 2.552946159226325

Epoch: 6| Step: 7
Training loss: 3.4027226934494124
Validation loss: 2.5770673614072535

Epoch: 6| Step: 8
Training loss: 2.991401748474512
Validation loss: 2.5544206642288

Epoch: 6| Step: 9
Training loss: 2.529432421259414
Validation loss: 2.5775208183830673

Epoch: 6| Step: 10
Training loss: 2.7193160947549586
Validation loss: 2.5612913633358754

Epoch: 6| Step: 11
Training loss: 2.8481672584624897
Validation loss: 2.5489065881530943

Epoch: 6| Step: 12
Training loss: 2.667375937153629
Validation loss: 2.5750033734103663

Epoch: 6| Step: 13
Training loss: 2.1302505028863643
Validation loss: 2.5641250019929673

Epoch: 54| Step: 0
Training loss: 2.1252757622800065
Validation loss: 2.562882133541703

Epoch: 6| Step: 1
Training loss: 2.442039956818029
Validation loss: 2.5649741579228547

Epoch: 6| Step: 2
Training loss: 2.7251177351129345
Validation loss: 2.562548517627746

Epoch: 6| Step: 3
Training loss: 2.6788670476635486
Validation loss: 2.5729712519128687

Epoch: 6| Step: 4
Training loss: 2.7033133909694826
Validation loss: 2.5679518936426455

Epoch: 6| Step: 5
Training loss: 3.0469613869965033
Validation loss: 2.5536015374286376

Epoch: 6| Step: 6
Training loss: 3.0872497086484283
Validation loss: 2.58655123963019

Epoch: 6| Step: 7
Training loss: 2.816193677099431
Validation loss: 2.580404972491634

Epoch: 6| Step: 8
Training loss: 3.3106937882224927
Validation loss: 2.5657579603952008

Epoch: 6| Step: 9
Training loss: 3.0242650676187015
Validation loss: 2.5585983710931037

Epoch: 6| Step: 10
Training loss: 3.606407101281798
Validation loss: 2.571938234551964

Epoch: 6| Step: 11
Training loss: 3.1694212193204163
Validation loss: 2.5855261952643716

Epoch: 6| Step: 12
Training loss: 2.7469849096882886
Validation loss: 2.575700268862759

Epoch: 6| Step: 13
Training loss: 2.9625342902279406
Validation loss: 2.5764660442046337

Epoch: 55| Step: 0
Training loss: 3.2611435799947266
Validation loss: 2.541893212805948

Epoch: 6| Step: 1
Training loss: 3.0958303527680773
Validation loss: 2.555588863420876

Epoch: 6| Step: 2
Training loss: 2.5859003438902075
Validation loss: 2.584906569073939

Epoch: 6| Step: 3
Training loss: 1.9854986658872351
Validation loss: 2.5728832661356944

Epoch: 6| Step: 4
Training loss: 3.115767459042103
Validation loss: 2.570217333903034

Epoch: 6| Step: 5
Training loss: 3.1503945603082983
Validation loss: 2.5574851639020717

Epoch: 6| Step: 6
Training loss: 2.5017829259415603
Validation loss: 2.5669236745942188

Epoch: 6| Step: 7
Training loss: 2.6883641117964685
Validation loss: 2.5426524419403376

Epoch: 6| Step: 8
Training loss: 3.006390758240743
Validation loss: 2.5573141596060798

Epoch: 6| Step: 9
Training loss: 2.775348875092824
Validation loss: 2.527758372840591

Epoch: 6| Step: 10
Training loss: 2.9004644416637757
Validation loss: 2.552127295478111

Epoch: 6| Step: 11
Training loss: 3.094917616479542
Validation loss: 2.554114380402201

Epoch: 6| Step: 12
Training loss: 3.240437304101711
Validation loss: 2.5591741979819043

Epoch: 6| Step: 13
Training loss: 2.9189154175765046
Validation loss: 2.5747842064483506

Epoch: 56| Step: 0
Training loss: 2.466737337216979
Validation loss: 2.544716996868671

Epoch: 6| Step: 1
Training loss: 2.82623851937447
Validation loss: 2.549505960870302

Epoch: 6| Step: 2
Training loss: 3.2384988782985875
Validation loss: 2.5436976065169072

Epoch: 6| Step: 3
Training loss: 2.6839174744472967
Validation loss: 2.58186710823786

Epoch: 6| Step: 4
Training loss: 2.8437981234660117
Validation loss: 2.5430090849228626

Epoch: 6| Step: 5
Training loss: 2.511953577244404
Validation loss: 2.5455758839104674

Epoch: 6| Step: 6
Training loss: 2.944616584624276
Validation loss: 2.5481782034226574

Epoch: 6| Step: 7
Training loss: 2.6025649879982153
Validation loss: 2.551602916858223

Epoch: 6| Step: 8
Training loss: 2.549725768359305
Validation loss: 2.5351167032950173

Epoch: 6| Step: 9
Training loss: 2.98888802943952
Validation loss: 2.5577668728259537

Epoch: 6| Step: 10
Training loss: 3.139055305803105
Validation loss: 2.549396968622878

Epoch: 6| Step: 11
Training loss: 2.969906872660385
Validation loss: 2.553705065750345

Epoch: 6| Step: 12
Training loss: 2.92609757265538
Validation loss: 2.5671061384347986

Epoch: 6| Step: 13
Training loss: 4.006071489615135
Validation loss: 2.560600957695666

Epoch: 57| Step: 0
Training loss: 2.937104705835247
Validation loss: 2.536550176838925

Epoch: 6| Step: 1
Training loss: 3.284776808590041
Validation loss: 2.536280140594751

Epoch: 6| Step: 2
Training loss: 1.9840645735022795
Validation loss: 2.555037891745998

Epoch: 6| Step: 3
Training loss: 2.7497379871740346
Validation loss: 2.547116300696382

Epoch: 6| Step: 4
Training loss: 3.301574828327521
Validation loss: 2.5637163926310014

Epoch: 6| Step: 5
Training loss: 2.986962759321537
Validation loss: 2.5636791534609755

Epoch: 6| Step: 6
Training loss: 2.677292712938194
Validation loss: 2.5607028394712152

Epoch: 6| Step: 7
Training loss: 3.4084560704846742
Validation loss: 2.5448774260649007

Epoch: 6| Step: 8
Training loss: 3.3038232272891497
Validation loss: 2.528891647349269

Epoch: 6| Step: 9
Training loss: 2.997134429554063
Validation loss: 2.5350313158231397

Epoch: 6| Step: 10
Training loss: 3.0628688356597262
Validation loss: 2.5722657146982217

Epoch: 6| Step: 11
Training loss: 2.0835129723983825
Validation loss: 2.584260623945994

Epoch: 6| Step: 12
Training loss: 2.7857701292484087
Validation loss: 2.56055609911492

Epoch: 6| Step: 13
Training loss: 2.0275633000324373
Validation loss: 2.549274234771864

Epoch: 58| Step: 0
Training loss: 2.104189793928602
Validation loss: 2.5781455259478654

Epoch: 6| Step: 1
Training loss: 2.320522311707711
Validation loss: 2.551350734317473

Epoch: 6| Step: 2
Training loss: 3.3573002995731067
Validation loss: 2.562032143146138

Epoch: 6| Step: 3
Training loss: 3.2232542650636447
Validation loss: 2.5461670056127557

Epoch: 6| Step: 4
Training loss: 3.028223788418574
Validation loss: 2.5638117680384696

Epoch: 6| Step: 5
Training loss: 2.510692808124885
Validation loss: 2.5894379565217522

Epoch: 6| Step: 6
Training loss: 2.3720796599818397
Validation loss: 2.577386508054034

Epoch: 6| Step: 7
Training loss: 3.826585234219739
Validation loss: 2.562504084814194

Epoch: 6| Step: 8
Training loss: 3.541410698710117
Validation loss: 2.5934101588306886

Epoch: 6| Step: 9
Training loss: 3.02199076260178
Validation loss: 2.5666401270290806

Epoch: 6| Step: 10
Training loss: 1.6256209434215203
Validation loss: 2.566859688737017

Epoch: 6| Step: 11
Training loss: 3.255489994324881
Validation loss: 2.571602173236993

Epoch: 6| Step: 12
Training loss: 2.8556789837429064
Validation loss: 2.560553562061117

Epoch: 6| Step: 13
Training loss: 2.281517849182091
Validation loss: 2.5543909170724497

Epoch: 59| Step: 0
Training loss: 2.5309007191743778
Validation loss: 2.5613220112378423

Epoch: 6| Step: 1
Training loss: 2.781412784227366
Validation loss: 2.5594941344193387

Epoch: 6| Step: 2
Training loss: 1.8768823711543956
Validation loss: 2.55766904281314

Epoch: 6| Step: 3
Training loss: 3.392034703437052
Validation loss: 2.556459207220402

Epoch: 6| Step: 4
Training loss: 2.7720202626179966
Validation loss: 2.5629425717110688

Epoch: 6| Step: 5
Training loss: 3.0033037749715397
Validation loss: 2.5465287763961704

Epoch: 6| Step: 6
Training loss: 3.3418502402043844
Validation loss: 2.558908068511278

Epoch: 6| Step: 7
Training loss: 3.1036047373534306
Validation loss: 2.5849868369783375

Epoch: 6| Step: 8
Training loss: 2.7979228012309325
Validation loss: 2.56477196112532

Epoch: 6| Step: 9
Training loss: 2.9032528096655748
Validation loss: 2.5774886602932052

Epoch: 6| Step: 10
Training loss: 2.99452600157706
Validation loss: 2.54192685799811

Epoch: 6| Step: 11
Training loss: 3.0337154154776833
Validation loss: 2.5680781561984136

Epoch: 6| Step: 12
Training loss: 2.6328843104137154
Validation loss: 2.531924088228329

Epoch: 6| Step: 13
Training loss: 2.860621613126904
Validation loss: 2.558988911475445

Epoch: 60| Step: 0
Training loss: 3.077570676511085
Validation loss: 2.5647764941209172

Epoch: 6| Step: 1
Training loss: 2.4004873655114247
Validation loss: 2.574915028456509

Epoch: 6| Step: 2
Training loss: 2.9634171623442036
Validation loss: 2.577239921837434

Epoch: 6| Step: 3
Training loss: 2.484910823212054
Validation loss: 2.5549709341838036

Epoch: 6| Step: 4
Training loss: 2.949640711225247
Validation loss: 2.561346899626747

Epoch: 6| Step: 5
Training loss: 3.55809203378699
Validation loss: 2.5549961142137874

Epoch: 6| Step: 6
Training loss: 2.6202627760753376
Validation loss: 2.5570389496791712

Epoch: 6| Step: 7
Training loss: 3.098423058365077
Validation loss: 2.550447874088987

Epoch: 6| Step: 8
Training loss: 2.5881135664583463
Validation loss: 2.545765877161933

Epoch: 6| Step: 9
Training loss: 2.745285935509505
Validation loss: 2.541935969152478

Epoch: 6| Step: 10
Training loss: 3.404344077994966
Validation loss: 2.5430440228567073

Epoch: 6| Step: 11
Training loss: 2.550950890313983
Validation loss: 2.535134637777398

Epoch: 6| Step: 12
Training loss: 2.6796497753813227
Validation loss: 2.5252248715685437

Epoch: 6| Step: 13
Training loss: 2.7561884520702127
Validation loss: 2.545940089422262

Epoch: 61| Step: 0
Training loss: 3.356577147269052
Validation loss: 2.5552259790059155

Epoch: 6| Step: 1
Training loss: 3.2242648092519732
Validation loss: 2.554247877991243

Epoch: 6| Step: 2
Training loss: 3.297615727381472
Validation loss: 2.5424792501917897

Epoch: 6| Step: 3
Training loss: 2.819991413130436
Validation loss: 2.5518020330870517

Epoch: 6| Step: 4
Training loss: 2.4330309466594016
Validation loss: 2.535388473699262

Epoch: 6| Step: 5
Training loss: 2.6578685541538105
Validation loss: 2.5324130913823577

Epoch: 6| Step: 6
Training loss: 2.8530065773060125
Validation loss: 2.5273798904336617

Epoch: 6| Step: 7
Training loss: 2.985345492919901
Validation loss: 2.5335202343533734

Epoch: 6| Step: 8
Training loss: 2.105307719737805
Validation loss: 2.545228388726755

Epoch: 6| Step: 9
Training loss: 2.727555845477367
Validation loss: 2.543149401314757

Epoch: 6| Step: 10
Training loss: 2.7973709945319345
Validation loss: 2.522074472593993

Epoch: 6| Step: 11
Training loss: 3.1992062299434503
Validation loss: 2.5541774780909687

Epoch: 6| Step: 12
Training loss: 2.942269531662292
Validation loss: 2.55567899792694

Epoch: 6| Step: 13
Training loss: 2.237069485979664
Validation loss: 2.5397362493357396

Epoch: 62| Step: 0
Training loss: 2.5412437107892134
Validation loss: 2.5276353276732606

Epoch: 6| Step: 1
Training loss: 3.0601908483392464
Validation loss: 2.549608336274661

Epoch: 6| Step: 2
Training loss: 2.676459233507114
Validation loss: 2.5460318382563494

Epoch: 6| Step: 3
Training loss: 2.7432126468363585
Validation loss: 2.5371541237164243

Epoch: 6| Step: 4
Training loss: 2.7686681868820493
Validation loss: 2.540174198032816

Epoch: 6| Step: 5
Training loss: 3.4394671273582804
Validation loss: 2.5356225465732147

Epoch: 6| Step: 6
Training loss: 2.9510212827643456
Validation loss: 2.557149808757825

Epoch: 6| Step: 7
Training loss: 2.959430401614803
Validation loss: 2.551429242477607

Epoch: 6| Step: 8
Training loss: 2.0192870946161663
Validation loss: 2.5521659216577453

Epoch: 6| Step: 9
Training loss: 3.2823654458678195
Validation loss: 2.557472429293802

Epoch: 6| Step: 10
Training loss: 2.9685437582555076
Validation loss: 2.5404508585330157

Epoch: 6| Step: 11
Training loss: 3.577357313934757
Validation loss: 2.541016444229854

Epoch: 6| Step: 12
Training loss: 2.5267157739918162
Validation loss: 2.5515812399815863

Epoch: 6| Step: 13
Training loss: 1.8313517988116708
Validation loss: 2.556849212060436

Epoch: 63| Step: 0
Training loss: 2.711212935732961
Validation loss: 2.545230096995089

Epoch: 6| Step: 1
Training loss: 3.084482356930784
Validation loss: 2.5241484378849055

Epoch: 6| Step: 2
Training loss: 2.5593391089897968
Validation loss: 2.5432272997753045

Epoch: 6| Step: 3
Training loss: 2.5423040268351187
Validation loss: 2.557910831619558

Epoch: 6| Step: 4
Training loss: 3.5273505091470403
Validation loss: 2.555895479591807

Epoch: 6| Step: 5
Training loss: 2.8983246403440033
Validation loss: 2.53626073289228

Epoch: 6| Step: 6
Training loss: 3.168330274242976
Validation loss: 2.5399189731117358

Epoch: 6| Step: 7
Training loss: 2.4774793979315537
Validation loss: 2.5550027214847977

Epoch: 6| Step: 8
Training loss: 2.6028552809767382
Validation loss: 2.541597030172539

Epoch: 6| Step: 9
Training loss: 3.5103584684684894
Validation loss: 2.554480918220383

Epoch: 6| Step: 10
Training loss: 2.1397168537241855
Validation loss: 2.5456659862351527

Epoch: 6| Step: 11
Training loss: 2.4903536659540473
Validation loss: 2.5701274908099365

Epoch: 6| Step: 12
Training loss: 3.156173554051789
Validation loss: 2.5367465635713162

Epoch: 6| Step: 13
Training loss: 3.3278298403814466
Validation loss: 2.563839196060823

Epoch: 64| Step: 0
Training loss: 2.7912729944152375
Validation loss: 2.564228899257599

Epoch: 6| Step: 1
Training loss: 2.563413503688696
Validation loss: 2.5259686033953836

Epoch: 6| Step: 2
Training loss: 3.1173062027054352
Validation loss: 2.5451444449624288

Epoch: 6| Step: 3
Training loss: 3.465997377001721
Validation loss: 2.5410142675194076

Epoch: 6| Step: 4
Training loss: 3.322830789028332
Validation loss: 2.5434765584134578

Epoch: 6| Step: 5
Training loss: 2.6871983558461237
Validation loss: 2.5301793197782487

Epoch: 6| Step: 6
Training loss: 2.7416527381550897
Validation loss: 2.5588100296536407

Epoch: 6| Step: 7
Training loss: 2.2480572684517557
Validation loss: 2.543987893275742

Epoch: 6| Step: 8
Training loss: 2.761954938185344
Validation loss: 2.544501841661474

Epoch: 6| Step: 9
Training loss: 2.4397521740489068
Validation loss: 2.5570491980494845

Epoch: 6| Step: 10
Training loss: 2.6146674478281047
Validation loss: 2.5627556855112053

Epoch: 6| Step: 11
Training loss: 2.9708360269827665
Validation loss: 2.564495569196888

Epoch: 6| Step: 12
Training loss: 3.1875837726430323
Validation loss: 2.516179098083947

Epoch: 6| Step: 13
Training loss: 2.9968074659707695
Validation loss: 2.560907247562945

Epoch: 65| Step: 0
Training loss: 2.7061160964082807
Validation loss: 2.5585279285763307

Epoch: 6| Step: 1
Training loss: 2.290814142888039
Validation loss: 2.53570376492395

Epoch: 6| Step: 2
Training loss: 3.425325369868581
Validation loss: 2.5265408875868745

Epoch: 6| Step: 3
Training loss: 3.0815101250651287
Validation loss: 2.539096489640155

Epoch: 6| Step: 4
Training loss: 2.5137347589198633
Validation loss: 2.5493507242707327

Epoch: 6| Step: 5
Training loss: 2.27731988020831
Validation loss: 2.5430974326513844

Epoch: 6| Step: 6
Training loss: 3.065668763325657
Validation loss: 2.540634574781784

Epoch: 6| Step: 7
Training loss: 2.55987060368867
Validation loss: 2.530512748596396

Epoch: 6| Step: 8
Training loss: 2.724454223153033
Validation loss: 2.5493765008214324

Epoch: 6| Step: 9
Training loss: 3.8347034217318035
Validation loss: 2.528282651350345

Epoch: 6| Step: 10
Training loss: 2.5928650230999564
Validation loss: 2.5589000787494585

Epoch: 6| Step: 11
Training loss: 2.2555668100327875
Validation loss: 2.534736663676828

Epoch: 6| Step: 12
Training loss: 2.990774911852154
Validation loss: 2.543041018719328

Epoch: 6| Step: 13
Training loss: 3.138644528700098
Validation loss: 2.5418582066085644

Epoch: 66| Step: 0
Training loss: 2.8770197532381423
Validation loss: 2.529375214273573

Epoch: 6| Step: 1
Training loss: 2.2685014026310437
Validation loss: 2.5463889381863787

Epoch: 6| Step: 2
Training loss: 2.916624523040022
Validation loss: 2.5436045005377754

Epoch: 6| Step: 3
Training loss: 2.608221472960868
Validation loss: 2.5292371694606848

Epoch: 6| Step: 4
Training loss: 3.505579860244975
Validation loss: 2.532827610096484

Epoch: 6| Step: 5
Training loss: 2.33102850385902
Validation loss: 2.5208527660781908

Epoch: 6| Step: 6
Training loss: 2.9302009641191016
Validation loss: 2.545939622196278

Epoch: 6| Step: 7
Training loss: 3.76561562944568
Validation loss: 2.5354558028039746

Epoch: 6| Step: 8
Training loss: 2.7142952563899683
Validation loss: 2.5278203820084175

Epoch: 6| Step: 9
Training loss: 3.334075622561373
Validation loss: 2.526398190067047

Epoch: 6| Step: 10
Training loss: 2.3701819688818815
Validation loss: 2.523742795480058

Epoch: 6| Step: 11
Training loss: 2.7995119078148374
Validation loss: 2.513048606913336

Epoch: 6| Step: 12
Training loss: 2.4827716379902305
Validation loss: 2.534109188365881

Epoch: 6| Step: 13
Training loss: 2.3995016017621515
Validation loss: 2.551474592090374

Epoch: 67| Step: 0
Training loss: 2.010154456661535
Validation loss: 2.5221456598156267

Epoch: 6| Step: 1
Training loss: 2.7970517917784634
Validation loss: 2.514331911011822

Epoch: 6| Step: 2
Training loss: 3.1552796335729165
Validation loss: 2.5455489283256174

Epoch: 6| Step: 3
Training loss: 2.97898593879037
Validation loss: 2.5293657842147974

Epoch: 6| Step: 4
Training loss: 2.8925553758178686
Validation loss: 2.538685222201272

Epoch: 6| Step: 5
Training loss: 1.526868194927177
Validation loss: 2.553091359832811

Epoch: 6| Step: 6
Training loss: 2.670971812577584
Validation loss: 2.5376344310665946

Epoch: 6| Step: 7
Training loss: 3.147442151568976
Validation loss: 2.5349195516382714

Epoch: 6| Step: 8
Training loss: 3.7044222205408914
Validation loss: 2.5209826241564386

Epoch: 6| Step: 9
Training loss: 2.330620573842149
Validation loss: 2.526224074751401

Epoch: 6| Step: 10
Training loss: 2.9586377233516696
Validation loss: 2.5434448357051753

Epoch: 6| Step: 11
Training loss: 3.400316302228396
Validation loss: 2.539561939577575

Epoch: 6| Step: 12
Training loss: 3.3649547989914175
Validation loss: 2.522436913490344

Epoch: 6| Step: 13
Training loss: 1.8776822296577527
Validation loss: 2.5230540845895253

Epoch: 68| Step: 0
Training loss: 2.4621702951371702
Validation loss: 2.5382527630100635

Epoch: 6| Step: 1
Training loss: 3.4284471080583856
Validation loss: 2.540644389843163

Epoch: 6| Step: 2
Training loss: 2.222828514784741
Validation loss: 2.549145873232351

Epoch: 6| Step: 3
Training loss: 3.224232273244447
Validation loss: 2.54674703695675

Epoch: 6| Step: 4
Training loss: 2.9916551878415825
Validation loss: 2.5523834259682756

Epoch: 6| Step: 5
Training loss: 2.4174244010647534
Validation loss: 2.5330625683503603

Epoch: 6| Step: 6
Training loss: 3.567529440894007
Validation loss: 2.5333085646927005

Epoch: 6| Step: 7
Training loss: 2.277160113669782
Validation loss: 2.5296905567217327

Epoch: 6| Step: 8
Training loss: 2.892664504323015
Validation loss: 2.517472020356771

Epoch: 6| Step: 9
Training loss: 2.8455415888005837
Validation loss: 2.5144102811752846

Epoch: 6| Step: 10
Training loss: 2.486671777605765
Validation loss: 2.5347829652899523

Epoch: 6| Step: 11
Training loss: 2.894953605530463
Validation loss: 2.5486927291180326

Epoch: 6| Step: 12
Training loss: 2.6568269888327483
Validation loss: 2.540878654529443

Epoch: 6| Step: 13
Training loss: 3.4130876140017343
Validation loss: 2.5600719679021218

Epoch: 69| Step: 0
Training loss: 2.546335736621106
Validation loss: 2.5454508790129737

Epoch: 6| Step: 1
Training loss: 3.2471324300919244
Validation loss: 2.5571080687373664

Epoch: 6| Step: 2
Training loss: 2.6906182584777802
Validation loss: 2.5525564388475357

Epoch: 6| Step: 3
Training loss: 3.2439740877163157
Validation loss: 2.543065397494137

Epoch: 6| Step: 4
Training loss: 2.7994287861866862
Validation loss: 2.5196129646605323

Epoch: 6| Step: 5
Training loss: 2.228960746689906
Validation loss: 2.5480040128859196

Epoch: 6| Step: 6
Training loss: 2.6716472684838592
Validation loss: 2.520605972648768

Epoch: 6| Step: 7
Training loss: 2.840992019830095
Validation loss: 2.532519471990625

Epoch: 6| Step: 8
Training loss: 3.2779806652604417
Validation loss: 2.5415320849145213

Epoch: 6| Step: 9
Training loss: 3.370980023248235
Validation loss: 2.5316152629388884

Epoch: 6| Step: 10
Training loss: 2.230325938127251
Validation loss: 2.542911979604019

Epoch: 6| Step: 11
Training loss: 3.1498553772681497
Validation loss: 2.548634239412902

Epoch: 6| Step: 12
Training loss: 2.4261109746912513
Validation loss: 2.536549867570814

Epoch: 6| Step: 13
Training loss: 2.8002525692514095
Validation loss: 2.546024160508952

Epoch: 70| Step: 0
Training loss: 3.4980414223854766
Validation loss: 2.5432472505584864

Epoch: 6| Step: 1
Training loss: 2.5143916737844916
Validation loss: 2.548180579754246

Epoch: 6| Step: 2
Training loss: 2.785431365433463
Validation loss: 2.5236677179520526

Epoch: 6| Step: 3
Training loss: 3.2542829902232753
Validation loss: 2.552154796839536

Epoch: 6| Step: 4
Training loss: 2.9244980079721055
Validation loss: 2.559058164199084

Epoch: 6| Step: 5
Training loss: 2.4177157218805965
Validation loss: 2.5197872214035697

Epoch: 6| Step: 6
Training loss: 2.672710622654224
Validation loss: 2.530582258373573

Epoch: 6| Step: 7
Training loss: 2.315340102323784
Validation loss: 2.5157220794079618

Epoch: 6| Step: 8
Training loss: 2.893542822389612
Validation loss: 2.5344282711313517

Epoch: 6| Step: 9
Training loss: 2.6060628370963688
Validation loss: 2.5214847613531246

Epoch: 6| Step: 10
Training loss: 3.024702886697371
Validation loss: 2.535745467532379

Epoch: 6| Step: 11
Training loss: 3.462740805064197
Validation loss: 2.550868829809969

Epoch: 6| Step: 12
Training loss: 2.679146848361061
Validation loss: 2.505381461888698

Epoch: 6| Step: 13
Training loss: 2.223350054588903
Validation loss: 2.5366785668445986

Epoch: 71| Step: 0
Training loss: 2.8408186339802537
Validation loss: 2.520468337027888

Epoch: 6| Step: 1
Training loss: 3.0887549564162797
Validation loss: 2.54294046980702

Epoch: 6| Step: 2
Training loss: 2.9284782660682294
Validation loss: 2.5365353501193977

Epoch: 6| Step: 3
Training loss: 2.7359537852884825
Validation loss: 2.5194994913719535

Epoch: 6| Step: 4
Training loss: 2.1872037414479713
Validation loss: 2.5386978046525663

Epoch: 6| Step: 5
Training loss: 3.146678347916123
Validation loss: 2.525105413727834

Epoch: 6| Step: 6
Training loss: 3.079027382501231
Validation loss: 2.5209497295922842

Epoch: 6| Step: 7
Training loss: 3.0124507662600273
Validation loss: 2.535508733177546

Epoch: 6| Step: 8
Training loss: 2.1961961372904986
Validation loss: 2.519909098322513

Epoch: 6| Step: 9
Training loss: 2.282098377236935
Validation loss: 2.5283778992493593

Epoch: 6| Step: 10
Training loss: 3.150342341394179
Validation loss: 2.520858635025828

Epoch: 6| Step: 11
Training loss: 2.7201902586648163
Validation loss: 2.5284854148662395

Epoch: 6| Step: 12
Training loss: 2.9611500686395322
Validation loss: 2.523752967770845

Epoch: 6| Step: 13
Training loss: 3.2983795637990494
Validation loss: 2.5508289498215997

Epoch: 72| Step: 0
Training loss: 3.1029918077356426
Validation loss: 2.520704940567658

Epoch: 6| Step: 1
Training loss: 2.562433102362528
Validation loss: 2.5417624492003332

Epoch: 6| Step: 2
Training loss: 2.7445359132001195
Validation loss: 2.530885991041023

Epoch: 6| Step: 3
Training loss: 2.6484749490346444
Validation loss: 2.5133016592723676

Epoch: 6| Step: 4
Training loss: 2.6260267701887203
Validation loss: 2.527196934127585

Epoch: 6| Step: 5
Training loss: 2.814408396591144
Validation loss: 2.5334991060280707

Epoch: 6| Step: 6
Training loss: 3.4725003974535325
Validation loss: 2.5198998047728347

Epoch: 6| Step: 7
Training loss: 2.3944251082077965
Validation loss: 2.553828792275556

Epoch: 6| Step: 8
Training loss: 2.691405718489153
Validation loss: 2.5132688222835537

Epoch: 6| Step: 9
Training loss: 2.772626387499001
Validation loss: 2.5315298363542307

Epoch: 6| Step: 10
Training loss: 2.7816878413481447
Validation loss: 2.5448413618583796

Epoch: 6| Step: 11
Training loss: 2.9627058641717468
Validation loss: 2.5174624708620947

Epoch: 6| Step: 12
Training loss: 2.9589618140641565
Validation loss: 2.529067548576133

Epoch: 6| Step: 13
Training loss: 3.1251470912648283
Validation loss: 2.546664049753576

Epoch: 73| Step: 0
Training loss: 2.905660754119411
Validation loss: 2.527925906265449

Epoch: 6| Step: 1
Training loss: 2.8779149412690583
Validation loss: 2.5229002383399486

Epoch: 6| Step: 2
Training loss: 2.9368069419597984
Validation loss: 2.525440297644164

Epoch: 6| Step: 3
Training loss: 2.493290098226842
Validation loss: 2.50266307381476

Epoch: 6| Step: 4
Training loss: 2.2395642183656164
Validation loss: 2.5278467290042173

Epoch: 6| Step: 5
Training loss: 2.9096279407199073
Validation loss: 2.534330051044204

Epoch: 6| Step: 6
Training loss: 2.7032465383736284
Validation loss: 2.5340411497025426

Epoch: 6| Step: 7
Training loss: 2.8481233943610724
Validation loss: 2.515121726554789

Epoch: 6| Step: 8
Training loss: 3.096349067566151
Validation loss: 2.5127744397151384

Epoch: 6| Step: 9
Training loss: 2.966379283172626
Validation loss: 2.5556643453801446

Epoch: 6| Step: 10
Training loss: 3.1659815867039773
Validation loss: 2.533638623583474

Epoch: 6| Step: 11
Training loss: 2.609379933975032
Validation loss: 2.5243043250453647

Epoch: 6| Step: 12
Training loss: 3.0236494596244947
Validation loss: 2.5085402753871904

Epoch: 6| Step: 13
Training loss: 3.0322065908661933
Validation loss: 2.528114541247357

Epoch: 74| Step: 0
Training loss: 2.439108293532316
Validation loss: 2.51660753711859

Epoch: 6| Step: 1
Training loss: 3.010097042306371
Validation loss: 2.534151923287772

Epoch: 6| Step: 2
Training loss: 2.9507447999738563
Validation loss: 2.550858172695119

Epoch: 6| Step: 3
Training loss: 2.3357901127990512
Validation loss: 2.549061677810892

Epoch: 6| Step: 4
Training loss: 2.6244988644307305
Validation loss: 2.537128768632433

Epoch: 6| Step: 5
Training loss: 2.955403735468984
Validation loss: 2.53394048749253

Epoch: 6| Step: 6
Training loss: 2.733157077394326
Validation loss: 2.545196733178952

Epoch: 6| Step: 7
Training loss: 3.093259059600771
Validation loss: 2.5051648409896248

Epoch: 6| Step: 8
Training loss: 2.3044878339754624
Validation loss: 2.5438478468616395

Epoch: 6| Step: 9
Training loss: 2.6147449539709235
Validation loss: 2.529106463079181

Epoch: 6| Step: 10
Training loss: 3.0863437047231277
Validation loss: 2.5338646295449063

Epoch: 6| Step: 11
Training loss: 3.2678187544486414
Validation loss: 2.536653571342514

Epoch: 6| Step: 12
Training loss: 2.5824786792624668
Validation loss: 2.5354198169202493

Epoch: 6| Step: 13
Training loss: 3.8820960997724736
Validation loss: 2.547900209648836

Epoch: 75| Step: 0
Training loss: 2.736623308378047
Validation loss: 2.5272643622726907

Epoch: 6| Step: 1
Training loss: 3.1474444240665935
Validation loss: 2.529739303811918

Epoch: 6| Step: 2
Training loss: 2.807756790007549
Validation loss: 2.5288394939024172

Epoch: 6| Step: 3
Training loss: 3.0735740518804127
Validation loss: 2.526702772697425

Epoch: 6| Step: 4
Training loss: 2.1669985688138356
Validation loss: 2.506661136326987

Epoch: 6| Step: 5
Training loss: 3.9147535616310796
Validation loss: 2.5354405146797525

Epoch: 6| Step: 6
Training loss: 2.876812902323609
Validation loss: 2.5220713250587923

Epoch: 6| Step: 7
Training loss: 2.06908486874301
Validation loss: 2.5066670661156643

Epoch: 6| Step: 8
Training loss: 2.7776463339753548
Validation loss: 2.538247716024524

Epoch: 6| Step: 9
Training loss: 3.3923889353372547
Validation loss: 2.5308608375410886

Epoch: 6| Step: 10
Training loss: 3.1680596617272965
Validation loss: 2.5342361456867692

Epoch: 6| Step: 11
Training loss: 1.9860756262548853
Validation loss: 2.545359431536214

Epoch: 6| Step: 12
Training loss: 2.375386457623071
Validation loss: 2.5242212185179667

Epoch: 6| Step: 13
Training loss: 1.8921869304728576
Validation loss: 2.522754653629623

Epoch: 76| Step: 0
Training loss: 2.051448807830974
Validation loss: 2.517836046255685

Epoch: 6| Step: 1
Training loss: 3.0834162589254253
Validation loss: 2.5372240209134986

Epoch: 6| Step: 2
Training loss: 1.7954103554400556
Validation loss: 2.5266265645298422

Epoch: 6| Step: 3
Training loss: 3.5312269091906137
Validation loss: 2.5231399668044654

Epoch: 6| Step: 4
Training loss: 3.759027169768998
Validation loss: 2.502056416363874

Epoch: 6| Step: 5
Training loss: 2.7649065366817904
Validation loss: 2.5205588069661498

Epoch: 6| Step: 6
Training loss: 2.2983777586267444
Validation loss: 2.5242613482524328

Epoch: 6| Step: 7
Training loss: 2.870641472933443
Validation loss: 2.5279774259820362

Epoch: 6| Step: 8
Training loss: 2.813771617370834
Validation loss: 2.519717892532486

Epoch: 6| Step: 9
Training loss: 3.3077782140368535
Validation loss: 2.531398094845158

Epoch: 6| Step: 10
Training loss: 2.9410956270663537
Validation loss: 2.53065662424965

Epoch: 6| Step: 11
Training loss: 2.3209522534167695
Validation loss: 2.5298979690758228

Epoch: 6| Step: 12
Training loss: 2.298465100504531
Validation loss: 2.520018830832086

Epoch: 6| Step: 13
Training loss: 3.4199197835605397
Validation loss: 2.510793360907071

Epoch: 77| Step: 0
Training loss: 3.0200567540779035
Validation loss: 2.520453575396111

Epoch: 6| Step: 1
Training loss: 3.077267290082123
Validation loss: 2.5245071176592986

Epoch: 6| Step: 2
Training loss: 2.641743801045773
Validation loss: 2.4961342056064066

Epoch: 6| Step: 3
Training loss: 2.815791260005236
Validation loss: 2.4974956448664516

Epoch: 6| Step: 4
Training loss: 2.438249130550821
Validation loss: 2.495249494514787

Epoch: 6| Step: 5
Training loss: 3.4156507206652518
Validation loss: 2.5429378163805034

Epoch: 6| Step: 6
Training loss: 2.737566148490005
Validation loss: 2.5357231794168196

Epoch: 6| Step: 7
Training loss: 2.6501788600804814
Validation loss: 2.5137259820472253

Epoch: 6| Step: 8
Training loss: 2.4035430147794865
Validation loss: 2.5515814308795655

Epoch: 6| Step: 9
Training loss: 3.485448287087744
Validation loss: 2.5625480889450905

Epoch: 6| Step: 10
Training loss: 2.009481367318589
Validation loss: 2.52809058820198

Epoch: 6| Step: 11
Training loss: 2.672779933874215
Validation loss: 2.4972021053920987

Epoch: 6| Step: 12
Training loss: 3.1694801948916713
Validation loss: 2.5357442214736166

Epoch: 6| Step: 13
Training loss: 2.8876527093576954
Validation loss: 2.5457683106279054

Epoch: 78| Step: 0
Training loss: 2.114928444447773
Validation loss: 2.528502575127581

Epoch: 6| Step: 1
Training loss: 3.000449305902781
Validation loss: 2.514311267881474

Epoch: 6| Step: 2
Training loss: 2.70211393818892
Validation loss: 2.5544174165466598

Epoch: 6| Step: 3
Training loss: 3.104615215348913
Validation loss: 2.5191044531083744

Epoch: 6| Step: 4
Training loss: 2.6575525119649694
Validation loss: 2.540529163657289

Epoch: 6| Step: 5
Training loss: 2.0683344766560894
Validation loss: 2.5610034748558066

Epoch: 6| Step: 6
Training loss: 3.2275788043600877
Validation loss: 2.5155046745439797

Epoch: 6| Step: 7
Training loss: 2.656926865449474
Validation loss: 2.5325836431899513

Epoch: 6| Step: 8
Training loss: 3.320271426676102
Validation loss: 2.524756769392802

Epoch: 6| Step: 9
Training loss: 3.2989096487484266
Validation loss: 2.520397723914313

Epoch: 6| Step: 10
Training loss: 2.462821796130083
Validation loss: 2.53222705857875

Epoch: 6| Step: 11
Training loss: 3.1951319263425413
Validation loss: 2.5375645865955825

Epoch: 6| Step: 12
Training loss: 3.080056605871641
Validation loss: 2.534424528481594

Epoch: 6| Step: 13
Training loss: 1.6953954720299302
Validation loss: 2.534107002687376

Epoch: 79| Step: 0
Training loss: 2.7163202236488178
Validation loss: 2.5312194812250994

Epoch: 6| Step: 1
Training loss: 2.7618680964856477
Validation loss: 2.5179396869091835

Epoch: 6| Step: 2
Training loss: 3.03328345610585
Validation loss: 2.5247533840434837

Epoch: 6| Step: 3
Training loss: 2.5238893653514083
Validation loss: 2.512270042145593

Epoch: 6| Step: 4
Training loss: 2.9945693135299365
Validation loss: 2.517508531628422

Epoch: 6| Step: 5
Training loss: 2.0890759349953063
Validation loss: 2.5263525009259546

Epoch: 6| Step: 6
Training loss: 2.3165707200122063
Validation loss: 2.511726382572534

Epoch: 6| Step: 7
Training loss: 2.9904726059371205
Validation loss: 2.5031177522644166

Epoch: 6| Step: 8
Training loss: 2.9132420916494572
Validation loss: 2.527389124019069

Epoch: 6| Step: 9
Training loss: 3.6860238692969496
Validation loss: 2.5229782458181567

Epoch: 6| Step: 10
Training loss: 2.685054819978822
Validation loss: 2.5133100163562574

Epoch: 6| Step: 11
Training loss: 2.74192456672131
Validation loss: 2.5173037616636105

Epoch: 6| Step: 12
Training loss: 2.6296033912667
Validation loss: 2.5195845637492145

Epoch: 6| Step: 13
Training loss: 3.0481935435745147
Validation loss: 2.528860901417718

Epoch: 80| Step: 0
Training loss: 3.0157163932273012
Validation loss: 2.49101817211561

Epoch: 6| Step: 1
Training loss: 3.188160547366028
Validation loss: 2.5247267966071543

Epoch: 6| Step: 2
Training loss: 3.3560963799751233
Validation loss: 2.5003663861046266

Epoch: 6| Step: 3
Training loss: 2.6681218249976077
Validation loss: 2.5249222352463896

Epoch: 6| Step: 4
Training loss: 2.956912886192003
Validation loss: 2.5223838765130195

Epoch: 6| Step: 5
Training loss: 1.9609510565665298
Validation loss: 2.5365282833934044

Epoch: 6| Step: 6
Training loss: 2.523544450979482
Validation loss: 2.518685988283529

Epoch: 6| Step: 7
Training loss: 3.167344188154769
Validation loss: 2.524095495271452

Epoch: 6| Step: 8
Training loss: 2.65072883803733
Validation loss: 2.53529849553128

Epoch: 6| Step: 9
Training loss: 2.963366154108849
Validation loss: 2.533029351943323

Epoch: 6| Step: 10
Training loss: 2.5385345379574478
Validation loss: 2.520036119958108

Epoch: 6| Step: 11
Training loss: 2.663275907404256
Validation loss: 2.536577080998923

Epoch: 6| Step: 12
Training loss: 3.369022161640163
Validation loss: 2.5477274903561744

Epoch: 6| Step: 13
Training loss: 1.4417590198079253
Validation loss: 2.5057118834825203

Epoch: 81| Step: 0
Training loss: 2.8764624814988813
Validation loss: 2.520692788008545

Epoch: 6| Step: 1
Training loss: 2.8663974265885255
Validation loss: 2.5206185960204563

Epoch: 6| Step: 2
Training loss: 2.933381785368292
Validation loss: 2.5054792564209634

Epoch: 6| Step: 3
Training loss: 2.6664378743569435
Validation loss: 2.513539340296748

Epoch: 6| Step: 4
Training loss: 3.213327228598382
Validation loss: 2.519551422503895

Epoch: 6| Step: 5
Training loss: 2.5472891067197083
Validation loss: 2.5255858544268603

Epoch: 6| Step: 6
Training loss: 2.746001197264564
Validation loss: 2.541392408556168

Epoch: 6| Step: 7
Training loss: 2.821143960307856
Validation loss: 2.5303699832786632

Epoch: 6| Step: 8
Training loss: 2.905111110223521
Validation loss: 2.5167203218096876

Epoch: 6| Step: 9
Training loss: 2.86152509720918
Validation loss: 2.5315102793186073

Epoch: 6| Step: 10
Training loss: 3.0290402882347114
Validation loss: 2.498542416109009

Epoch: 6| Step: 11
Training loss: 2.5027120185235763
Validation loss: 2.521353918465994

Epoch: 6| Step: 12
Training loss: 2.7073037366804713
Validation loss: 2.5045174965466916

Epoch: 6| Step: 13
Training loss: 2.422773625182385
Validation loss: 2.523822689624615

Epoch: 82| Step: 0
Training loss: 2.988638982366212
Validation loss: 2.5159590009031056

Epoch: 6| Step: 1
Training loss: 2.669236603804283
Validation loss: 2.501359416154301

Epoch: 6| Step: 2
Training loss: 2.6373664569041084
Validation loss: 2.5314663027791973

Epoch: 6| Step: 3
Training loss: 3.1778805258915606
Validation loss: 2.505504809005747

Epoch: 6| Step: 4
Training loss: 3.029816278609795
Validation loss: 2.531813597896038

Epoch: 6| Step: 5
Training loss: 3.0859459985543576
Validation loss: 2.522748291150324

Epoch: 6| Step: 6
Training loss: 2.6405984549909305
Validation loss: 2.5210656920286443

Epoch: 6| Step: 7
Training loss: 2.324854351937116
Validation loss: 2.5107177072550018

Epoch: 6| Step: 8
Training loss: 2.1023054546836146
Validation loss: 2.4905606136284826

Epoch: 6| Step: 9
Training loss: 2.6254625367060047
Validation loss: 2.499485379237474

Epoch: 6| Step: 10
Training loss: 2.730960305080842
Validation loss: 2.497750342723267

Epoch: 6| Step: 11
Training loss: 3.5901970590896126
Validation loss: 2.5030145559095263

Epoch: 6| Step: 12
Training loss: 2.4805633286594873
Validation loss: 2.524240410549381

Epoch: 6| Step: 13
Training loss: 2.930200313191446
Validation loss: 2.496055093177349

Epoch: 83| Step: 0
Training loss: 2.094275109787067
Validation loss: 2.508770463488682

Epoch: 6| Step: 1
Training loss: 3.1411097517783877
Validation loss: 2.502868610372238

Epoch: 6| Step: 2
Training loss: 2.6634314900032474
Validation loss: 2.495281970173639

Epoch: 6| Step: 3
Training loss: 3.4982529775966276
Validation loss: 2.53056482348989

Epoch: 6| Step: 4
Training loss: 2.872876253643724
Validation loss: 2.5054257294954674

Epoch: 6| Step: 5
Training loss: 2.943037130616102
Validation loss: 2.4855569092027943

Epoch: 6| Step: 6
Training loss: 2.5428086097090263
Validation loss: 2.5023508104462016

Epoch: 6| Step: 7
Training loss: 3.1269284211040085
Validation loss: 2.4975317265634183

Epoch: 6| Step: 8
Training loss: 2.3400638330344283
Validation loss: 2.5264985581668413

Epoch: 6| Step: 9
Training loss: 3.143576227015364
Validation loss: 2.5293228620026493

Epoch: 6| Step: 10
Training loss: 2.534912285726211
Validation loss: 2.51039719977218

Epoch: 6| Step: 11
Training loss: 2.44438470661496
Validation loss: 2.5343792733394044

Epoch: 6| Step: 12
Training loss: 2.7222989475916477
Validation loss: 2.5243967901556

Epoch: 6| Step: 13
Training loss: 2.7606628212249857
Validation loss: 2.5207161929979707

Epoch: 84| Step: 0
Training loss: 2.6904436889948737
Validation loss: 2.516887644730118

Epoch: 6| Step: 1
Training loss: 3.535572613386523
Validation loss: 2.537776886208839

Epoch: 6| Step: 2
Training loss: 2.596609354949626
Validation loss: 2.5197421927519152

Epoch: 6| Step: 3
Training loss: 2.3718784297068933
Validation loss: 2.5209432689994227

Epoch: 6| Step: 4
Training loss: 3.448226008219265
Validation loss: 2.5302520490280087

Epoch: 6| Step: 5
Training loss: 2.634555500041761
Validation loss: 2.489028483366166

Epoch: 6| Step: 6
Training loss: 2.8203851156845845
Validation loss: 2.5199060910210807

Epoch: 6| Step: 7
Training loss: 2.8759127287589066
Validation loss: 2.4853555028276433

Epoch: 6| Step: 8
Training loss: 2.889595136959846
Validation loss: 2.508704801264562

Epoch: 6| Step: 9
Training loss: 2.449368461644936
Validation loss: 2.5086311387033384

Epoch: 6| Step: 10
Training loss: 2.580476740178838
Validation loss: 2.5238244773912197

Epoch: 6| Step: 11
Training loss: 2.5860547733509986
Validation loss: 2.484293984797229

Epoch: 6| Step: 12
Training loss: 2.891084376768722
Validation loss: 2.4971724199000556

Epoch: 6| Step: 13
Training loss: 2.3479984687787185
Validation loss: 2.5294658156434653

Epoch: 85| Step: 0
Training loss: 1.7302039225792132
Validation loss: 2.5165908865903734

Epoch: 6| Step: 1
Training loss: 2.7189878162421115
Validation loss: 2.5173291636698023

Epoch: 6| Step: 2
Training loss: 2.7948541426432083
Validation loss: 2.537391806340299

Epoch: 6| Step: 3
Training loss: 3.0341666435891974
Validation loss: 2.5416368328591488

Epoch: 6| Step: 4
Training loss: 2.930806915045549
Validation loss: 2.5197100633840734

Epoch: 6| Step: 5
Training loss: 3.2650594267176145
Validation loss: 2.5245943720978996

Epoch: 6| Step: 6
Training loss: 2.8785693360990097
Validation loss: 2.4939180966226933

Epoch: 6| Step: 7
Training loss: 2.9473863176290074
Validation loss: 2.525942620451107

Epoch: 6| Step: 8
Training loss: 2.975191857057913
Validation loss: 2.504741742335621

Epoch: 6| Step: 9
Training loss: 2.468077845756909
Validation loss: 2.5180571308428985

Epoch: 6| Step: 10
Training loss: 2.565477920386659
Validation loss: 2.5203811258888345

Epoch: 6| Step: 11
Training loss: 2.9641253941790304
Validation loss: 2.518642917657998

Epoch: 6| Step: 12
Training loss: 3.293964276229506
Validation loss: 2.515923008215676

Epoch: 6| Step: 13
Training loss: 1.9814401384928135
Validation loss: 2.5019976540929734

Epoch: 86| Step: 0
Training loss: 2.9711111216171417
Validation loss: 2.5191475046486125

Epoch: 6| Step: 1
Training loss: 2.7719418213368883
Validation loss: 2.538900881436077

Epoch: 6| Step: 2
Training loss: 2.5933017573195376
Validation loss: 2.5029089318912847

Epoch: 6| Step: 3
Training loss: 2.936014976920613
Validation loss: 2.5143373914153186

Epoch: 6| Step: 4
Training loss: 2.9299941245791534
Validation loss: 2.5214028196138254

Epoch: 6| Step: 5
Training loss: 2.610664642887805
Validation loss: 2.4970964316044473

Epoch: 6| Step: 6
Training loss: 2.4368975946436047
Validation loss: 2.5146904143507456

Epoch: 6| Step: 7
Training loss: 3.239755329501248
Validation loss: 2.515530157903259

Epoch: 6| Step: 8
Training loss: 2.5255161853091144
Validation loss: 2.513781034336439

Epoch: 6| Step: 9
Training loss: 2.303665089524961
Validation loss: 2.527538781908655

Epoch: 6| Step: 10
Training loss: 2.960026019471739
Validation loss: 2.525964963911532

Epoch: 6| Step: 11
Training loss: 3.5686883550286908
Validation loss: 2.4866756168701354

Epoch: 6| Step: 12
Training loss: 2.627710850002005
Validation loss: 2.536482390633536

Epoch: 6| Step: 13
Training loss: 2.0036748265415616
Validation loss: 2.499336532005727

Epoch: 87| Step: 0
Training loss: 3.1690185914582156
Validation loss: 2.5084738508635387

Epoch: 6| Step: 1
Training loss: 3.168542624164147
Validation loss: 2.512340105119983

Epoch: 6| Step: 2
Training loss: 2.7547213166617603
Validation loss: 2.5006247170595595

Epoch: 6| Step: 3
Training loss: 2.3430433098001244
Validation loss: 2.509355914171372

Epoch: 6| Step: 4
Training loss: 2.975452927163382
Validation loss: 2.5072509895519652

Epoch: 6| Step: 5
Training loss: 2.5972564160095803
Validation loss: 2.535466563080577

Epoch: 6| Step: 6
Training loss: 2.7489845828737276
Validation loss: 2.509557868572108

Epoch: 6| Step: 7
Training loss: 2.3899003470167233
Validation loss: 2.5006112069365387

Epoch: 6| Step: 8
Training loss: 2.7659605005937316
Validation loss: 2.5109592032417796

Epoch: 6| Step: 9
Training loss: 2.482522717820449
Validation loss: 2.5032538133070568

Epoch: 6| Step: 10
Training loss: 3.3946118800658462
Validation loss: 2.5033983032099565

Epoch: 6| Step: 11
Training loss: 2.3948424792004808
Validation loss: 2.512892262781107

Epoch: 6| Step: 12
Training loss: 2.4543776502951933
Validation loss: 2.524176460919085

Epoch: 6| Step: 13
Training loss: 3.379540814917012
Validation loss: 2.524603425979653

Epoch: 88| Step: 0
Training loss: 2.818517224497235
Validation loss: 2.4997959299783243

Epoch: 6| Step: 1
Training loss: 2.659427671885849
Validation loss: 2.513892649685512

Epoch: 6| Step: 2
Training loss: 2.5240736593510085
Validation loss: 2.5127538847945217

Epoch: 6| Step: 3
Training loss: 2.5044803526586166
Validation loss: 2.5080067068667344

Epoch: 6| Step: 4
Training loss: 2.648119882088443
Validation loss: 2.5057847233582553

Epoch: 6| Step: 5
Training loss: 3.254107593841944
Validation loss: 2.497858476684992

Epoch: 6| Step: 6
Training loss: 3.2453115831501473
Validation loss: 2.4925793249002

Epoch: 6| Step: 7
Training loss: 2.8451243003682456
Validation loss: 2.5275753303325317

Epoch: 6| Step: 8
Training loss: 3.1039032450963147
Validation loss: 2.5035624286989364

Epoch: 6| Step: 9
Training loss: 2.483113670448095
Validation loss: 2.5199080840199612

Epoch: 6| Step: 10
Training loss: 1.9884720206782553
Validation loss: 2.495441869347851

Epoch: 6| Step: 11
Training loss: 3.0777414150668307
Validation loss: 2.5339727753486945

Epoch: 6| Step: 12
Training loss: 2.639751041406729
Validation loss: 2.5143962863910785

Epoch: 6| Step: 13
Training loss: 2.8486560798351284
Validation loss: 2.4948761700240474

Epoch: 89| Step: 0
Training loss: 2.580061399187601
Validation loss: 2.4979728478597654

Epoch: 6| Step: 1
Training loss: 2.5100099437258288
Validation loss: 2.5175908536722966

Epoch: 6| Step: 2
Training loss: 2.2478332683187703
Validation loss: 2.5100746546446198

Epoch: 6| Step: 3
Training loss: 3.3037771860505907
Validation loss: 2.51432872166639

Epoch: 6| Step: 4
Training loss: 2.637467160856637
Validation loss: 2.535546206109853

Epoch: 6| Step: 5
Training loss: 2.539588850191136
Validation loss: 2.506726986057975

Epoch: 6| Step: 6
Training loss: 2.729865229846745
Validation loss: 2.5275300773135068

Epoch: 6| Step: 7
Training loss: 2.6307602306508886
Validation loss: 2.508088672299901

Epoch: 6| Step: 8
Training loss: 2.7165956402096367
Validation loss: 2.5138349340518187

Epoch: 6| Step: 9
Training loss: 2.959615528035948
Validation loss: 2.4967434479362383

Epoch: 6| Step: 10
Training loss: 3.749107890508142
Validation loss: 2.519408392194211

Epoch: 6| Step: 11
Training loss: 2.904283740303184
Validation loss: 2.5126478355870105

Epoch: 6| Step: 12
Training loss: 2.783537449081336
Validation loss: 2.5316923214063785

Epoch: 6| Step: 13
Training loss: 2.365121172488416
Validation loss: 2.522844697098111

Epoch: 90| Step: 0
Training loss: 2.6412547788202154
Validation loss: 2.494728480292087

Epoch: 6| Step: 1
Training loss: 2.988515328607791
Validation loss: 2.5114804301877105

Epoch: 6| Step: 2
Training loss: 2.979017952006
Validation loss: 2.5234049290133167

Epoch: 6| Step: 3
Training loss: 2.5687439373158285
Validation loss: 2.5089815742470263

Epoch: 6| Step: 4
Training loss: 3.2303096266168474
Validation loss: 2.5133571206984864

Epoch: 6| Step: 5
Training loss: 2.50910208276163
Validation loss: 2.5062214276492534

Epoch: 6| Step: 6
Training loss: 2.407348778274305
Validation loss: 2.5177089136235598

Epoch: 6| Step: 7
Training loss: 3.1645679211487114
Validation loss: 2.5182094975117444

Epoch: 6| Step: 8
Training loss: 3.0136000401556884
Validation loss: 2.501142685732932

Epoch: 6| Step: 9
Training loss: 2.100429073277676
Validation loss: 2.517712102760057

Epoch: 6| Step: 10
Training loss: 2.9332653933662263
Validation loss: 2.5291070824221222

Epoch: 6| Step: 11
Training loss: 2.2068826000824955
Validation loss: 2.508197155750875

Epoch: 6| Step: 12
Training loss: 3.371605755766005
Validation loss: 2.5140875044785904

Epoch: 6| Step: 13
Training loss: 1.9255357318852449
Validation loss: 2.5038781987350025

Epoch: 91| Step: 0
Training loss: 2.617227673578097
Validation loss: 2.5167868852033926

Epoch: 6| Step: 1
Training loss: 2.639991006980375
Validation loss: 2.5136025926589896

Epoch: 6| Step: 2
Training loss: 2.8916447670700043
Validation loss: 2.5219017045591143

Epoch: 6| Step: 3
Training loss: 2.3461337365278374
Validation loss: 2.5205555848160843

Epoch: 6| Step: 4
Training loss: 3.110521728076723
Validation loss: 2.51072530304874

Epoch: 6| Step: 5
Training loss: 3.2574898905388627
Validation loss: 2.5105255430808553

Epoch: 6| Step: 6
Training loss: 2.9183945760032377
Validation loss: 2.527629980569753

Epoch: 6| Step: 7
Training loss: 2.4544552640368003
Validation loss: 2.5036536815603436

Epoch: 6| Step: 8
Training loss: 2.5094155390257034
Validation loss: 2.4948703894657673

Epoch: 6| Step: 9
Training loss: 2.3134709974474013
Validation loss: 2.4911256865144034

Epoch: 6| Step: 10
Training loss: 1.9586093653941608
Validation loss: 2.489821679833832

Epoch: 6| Step: 11
Training loss: 3.482964200138411
Validation loss: 2.4974046279044244

Epoch: 6| Step: 12
Training loss: 3.271176233155936
Validation loss: 2.5011290108213666

Epoch: 6| Step: 13
Training loss: 3.138529063918095
Validation loss: 2.501931957572142

Epoch: 92| Step: 0
Training loss: 2.341196933028837
Validation loss: 2.4949294136227977

Epoch: 6| Step: 1
Training loss: 2.03130786519892
Validation loss: 2.478567725452351

Epoch: 6| Step: 2
Training loss: 3.150874933712919
Validation loss: 2.5119557929148746

Epoch: 6| Step: 3
Training loss: 2.2626975252538273
Validation loss: 2.498051070339256

Epoch: 6| Step: 4
Training loss: 2.522812142846403
Validation loss: 2.520398155188919

Epoch: 6| Step: 5
Training loss: 2.9651313009025078
Validation loss: 2.5130600134904437

Epoch: 6| Step: 6
Training loss: 3.5678504785589764
Validation loss: 2.4740169536767604

Epoch: 6| Step: 7
Training loss: 3.1328819057928965
Validation loss: 2.4888002847203974

Epoch: 6| Step: 8
Training loss: 2.851738075181253
Validation loss: 2.4923188711778463

Epoch: 6| Step: 9
Training loss: 2.563251478213553
Validation loss: 2.4837740620667477

Epoch: 6| Step: 10
Training loss: 2.9658182223918383
Validation loss: 2.4913699964047265

Epoch: 6| Step: 11
Training loss: 3.1569536387894295
Validation loss: 2.485730833720401

Epoch: 6| Step: 12
Training loss: 2.3488995755466893
Validation loss: 2.5086722014818994

Epoch: 6| Step: 13
Training loss: 2.4329191347442753
Validation loss: 2.4987393841276373

Epoch: 93| Step: 0
Training loss: 2.6389111255801962
Validation loss: 2.4926711207367926

Epoch: 6| Step: 1
Training loss: 2.0391750962312187
Validation loss: 2.495294480219526

Epoch: 6| Step: 2
Training loss: 2.1049708979173802
Validation loss: 2.5028541495320247

Epoch: 6| Step: 3
Training loss: 2.3640522857667228
Validation loss: 2.4997013641748245

Epoch: 6| Step: 4
Training loss: 3.3191444406827544
Validation loss: 2.496628082936499

Epoch: 6| Step: 5
Training loss: 3.337889196441327
Validation loss: 2.5063672920002023

Epoch: 6| Step: 6
Training loss: 3.1763619693144896
Validation loss: 2.4942574751309627

Epoch: 6| Step: 7
Training loss: 3.097394549750834
Validation loss: 2.493084479462101

Epoch: 6| Step: 8
Training loss: 3.1420923856948733
Validation loss: 2.4842119772901126

Epoch: 6| Step: 9
Training loss: 2.521377714872305
Validation loss: 2.497148802455284

Epoch: 6| Step: 10
Training loss: 2.7028737916148504
Validation loss: 2.5340837370572755

Epoch: 6| Step: 11
Training loss: 2.7210043845122094
Validation loss: 2.497229636738251

Epoch: 6| Step: 12
Training loss: 2.5723418135428044
Validation loss: 2.4913685609376053

Epoch: 6| Step: 13
Training loss: 2.5209469625121175
Validation loss: 2.514837126477904

Epoch: 94| Step: 0
Training loss: 2.5834799899239402
Validation loss: 2.4935151285547463

Epoch: 6| Step: 1
Training loss: 2.6204966107939573
Validation loss: 2.498532067302108

Epoch: 6| Step: 2
Training loss: 2.4899320052334835
Validation loss: 2.5112990953086705

Epoch: 6| Step: 3
Training loss: 2.277875102168488
Validation loss: 2.4999053255223203

Epoch: 6| Step: 4
Training loss: 2.5288551209908063
Validation loss: 2.5339971462665267

Epoch: 6| Step: 5
Training loss: 3.204854953953284
Validation loss: 2.5079233965848426

Epoch: 6| Step: 6
Training loss: 3.07807496315811
Validation loss: 2.494730168676283

Epoch: 6| Step: 7
Training loss: 2.343841957831418
Validation loss: 2.4943912440029665

Epoch: 6| Step: 8
Training loss: 3.572722108101713
Validation loss: 2.4971474093219195

Epoch: 6| Step: 9
Training loss: 3.056576664167065
Validation loss: 2.5178921357943667

Epoch: 6| Step: 10
Training loss: 2.7811995941052086
Validation loss: 2.490411048716788

Epoch: 6| Step: 11
Training loss: 2.767585189045766
Validation loss: 2.495622753400356

Epoch: 6| Step: 12
Training loss: 2.4873156148537943
Validation loss: 2.5185607643647216

Epoch: 6| Step: 13
Training loss: 2.81999961406624
Validation loss: 2.5034454097209617

Epoch: 95| Step: 0
Training loss: 3.4425732715485475
Validation loss: 2.5010350658528515

Epoch: 6| Step: 1
Training loss: 2.9675232611421807
Validation loss: 2.527288271922455

Epoch: 6| Step: 2
Training loss: 2.5463014670682353
Validation loss: 2.4926839256854616

Epoch: 6| Step: 3
Training loss: 2.6473119814122232
Validation loss: 2.508138785726427

Epoch: 6| Step: 4
Training loss: 2.4730453787657374
Validation loss: 2.5135078945590257

Epoch: 6| Step: 5
Training loss: 2.9192600890933713
Validation loss: 2.526410854006987

Epoch: 6| Step: 6
Training loss: 2.6903679205421107
Validation loss: 2.521094156587811

Epoch: 6| Step: 7
Training loss: 2.3381834938219135
Validation loss: 2.507650111540323

Epoch: 6| Step: 8
Training loss: 3.1277969051097703
Validation loss: 2.5065856182492494

Epoch: 6| Step: 9
Training loss: 3.0625020241244107
Validation loss: 2.520602491713537

Epoch: 6| Step: 10
Training loss: 2.5174536840729833
Validation loss: 2.5118886034462995

Epoch: 6| Step: 11
Training loss: 2.2570037977451185
Validation loss: 2.5189895259907433

Epoch: 6| Step: 12
Training loss: 2.4572785803389943
Validation loss: 2.520543200655525

Epoch: 6| Step: 13
Training loss: 3.2096333697804496
Validation loss: 2.4963037125007097

Epoch: 96| Step: 0
Training loss: 2.377780892418617
Validation loss: 2.5108348263465525

Epoch: 6| Step: 1
Training loss: 3.03949018670776
Validation loss: 2.5150869980554864

Epoch: 6| Step: 2
Training loss: 3.1026100676482953
Validation loss: 2.5086074421227997

Epoch: 6| Step: 3
Training loss: 1.8978592105659162
Validation loss: 2.491633759482717

Epoch: 6| Step: 4
Training loss: 2.775887709899738
Validation loss: 2.50954132143907

Epoch: 6| Step: 5
Training loss: 2.675802188986275
Validation loss: 2.4964611602080757

Epoch: 6| Step: 6
Training loss: 2.510085742291443
Validation loss: 2.538926939268046

Epoch: 6| Step: 7
Training loss: 3.2209787892753834
Validation loss: 2.4772401747326223

Epoch: 6| Step: 8
Training loss: 2.8166533426575335
Validation loss: 2.5195480357567486

Epoch: 6| Step: 9
Training loss: 3.099463225622673
Validation loss: 2.5439598078201873

Epoch: 6| Step: 10
Training loss: 2.6048469773815373
Validation loss: 2.525913675658144

Epoch: 6| Step: 11
Training loss: 3.167299023449297
Validation loss: 2.5149516643536614

Epoch: 6| Step: 12
Training loss: 2.283765999206057
Validation loss: 2.4981188341495497

Epoch: 6| Step: 13
Training loss: 3.2223617881570057
Validation loss: 2.5349474717823375

Epoch: 97| Step: 0
Training loss: 2.8658876720918167
Validation loss: 2.511023610976921

Epoch: 6| Step: 1
Training loss: 2.4205499777579926
Validation loss: 2.5016751081547475

Epoch: 6| Step: 2
Training loss: 2.759493134714176
Validation loss: 2.496500344727833

Epoch: 6| Step: 3
Training loss: 3.1275029649118204
Validation loss: 2.494230208020472

Epoch: 6| Step: 4
Training loss: 3.1602971784668585
Validation loss: 2.501242795308837

Epoch: 6| Step: 5
Training loss: 2.5368483058881157
Validation loss: 2.5076490084482925

Epoch: 6| Step: 6
Training loss: 2.427024240279201
Validation loss: 2.4875334809316847

Epoch: 6| Step: 7
Training loss: 3.3179940779841797
Validation loss: 2.5182634134064976

Epoch: 6| Step: 8
Training loss: 2.872511408611381
Validation loss: 2.500986933993502

Epoch: 6| Step: 9
Training loss: 2.03245625991959
Validation loss: 2.5124779487776414

Epoch: 6| Step: 10
Training loss: 2.8167690514309336
Validation loss: 2.5017245702207456

Epoch: 6| Step: 11
Training loss: 2.6983317837662595
Validation loss: 2.5100207364848064

Epoch: 6| Step: 12
Training loss: 2.9313889915845204
Validation loss: 2.5114504663642916

Epoch: 6| Step: 13
Training loss: 2.4933191677785875
Validation loss: 2.4851775939024634

Epoch: 98| Step: 0
Training loss: 3.07277807580525
Validation loss: 2.5153339013489964

Epoch: 6| Step: 1
Training loss: 2.4516087602441106
Validation loss: 2.5279333935619457

Epoch: 6| Step: 2
Training loss: 2.361810904625208
Validation loss: 2.5011631013557873

Epoch: 6| Step: 3
Training loss: 2.6691418326615333
Validation loss: 2.5160238471709127

Epoch: 6| Step: 4
Training loss: 2.830165064011423
Validation loss: 2.499507553042338

Epoch: 6| Step: 5
Training loss: 2.7296572722326404
Validation loss: 2.498270248543372

Epoch: 6| Step: 6
Training loss: 2.6903875053408277
Validation loss: 2.47492483502826

Epoch: 6| Step: 7
Training loss: 3.0616994317436443
Validation loss: 2.507464144224655

Epoch: 6| Step: 8
Training loss: 3.1188776697237057
Validation loss: 2.51421505475069

Epoch: 6| Step: 9
Training loss: 3.406093208834078
Validation loss: 2.497766769878833

Epoch: 6| Step: 10
Training loss: 2.4162854080250264
Validation loss: 2.5034720961901846

Epoch: 6| Step: 11
Training loss: 3.178144450770509
Validation loss: 2.50143634593618

Epoch: 6| Step: 12
Training loss: 2.0793886859926123
Validation loss: 2.4872806960078564

Epoch: 6| Step: 13
Training loss: 2.072338221623938
Validation loss: 2.4791547223991977

Epoch: 99| Step: 0
Training loss: 3.0031596075598452
Validation loss: 2.4853131408835405

Epoch: 6| Step: 1
Training loss: 3.1549885561292674
Validation loss: 2.5307699872813076

Epoch: 6| Step: 2
Training loss: 2.6924849121747774
Validation loss: 2.4889129276297077

Epoch: 6| Step: 3
Training loss: 2.5978100723958266
Validation loss: 2.4923501738425227

Epoch: 6| Step: 4
Training loss: 2.125609590945072
Validation loss: 2.53057239921994

Epoch: 6| Step: 5
Training loss: 2.468982637284862
Validation loss: 2.4943127001634453

Epoch: 6| Step: 6
Training loss: 2.8357678407304423
Validation loss: 2.502683020171922

Epoch: 6| Step: 7
Training loss: 3.343253268129107
Validation loss: 2.4954310166171596

Epoch: 6| Step: 8
Training loss: 2.4307378234338586
Validation loss: 2.522039470846359

Epoch: 6| Step: 9
Training loss: 2.9673736594219724
Validation loss: 2.495252058925181

Epoch: 6| Step: 10
Training loss: 2.1212486365094185
Validation loss: 2.5272362040728265

Epoch: 6| Step: 11
Training loss: 2.486666983671739
Validation loss: 2.495475201339171

Epoch: 6| Step: 12
Training loss: 2.7074085319475345
Validation loss: 2.505699336946732

Epoch: 6| Step: 13
Training loss: 3.6847054188554442
Validation loss: 2.5072289915921213

Epoch: 100| Step: 0
Training loss: 2.5212509082646926
Validation loss: 2.496523575010479

Epoch: 6| Step: 1
Training loss: 2.6554871305147745
Validation loss: 2.5129894079714905

Epoch: 6| Step: 2
Training loss: 3.1681803716116654
Validation loss: 2.519842867680014

Epoch: 6| Step: 3
Training loss: 2.2065044483284333
Validation loss: 2.496703501231568

Epoch: 6| Step: 4
Training loss: 2.1405871311374387
Validation loss: 2.486110927712932

Epoch: 6| Step: 5
Training loss: 2.0198018171328505
Validation loss: 2.5171024053130924

Epoch: 6| Step: 6
Training loss: 3.003170722033823
Validation loss: 2.4978399030237917

Epoch: 6| Step: 7
Training loss: 3.4464188440779973
Validation loss: 2.525473191579619

Epoch: 6| Step: 8
Training loss: 2.8442477953837653
Validation loss: 2.5073342281096673

Epoch: 6| Step: 9
Training loss: 3.304405831672409
Validation loss: 2.520168296722189

Epoch: 6| Step: 10
Training loss: 3.1683371972855294
Validation loss: 2.4931164121090306

Epoch: 6| Step: 11
Training loss: 2.321937788143881
Validation loss: 2.511174202341895

Epoch: 6| Step: 12
Training loss: 2.7153192556540624
Validation loss: 2.511167957530503

Epoch: 6| Step: 13
Training loss: 2.8335398056494983
Validation loss: 2.531220453521084

Epoch: 101| Step: 0
Training loss: 2.5284316774008224
Validation loss: 2.499487092101422

Epoch: 6| Step: 1
Training loss: 2.925276627460721
Validation loss: 2.5324192443235605

Epoch: 6| Step: 2
Training loss: 2.9490229459525055
Validation loss: 2.5047653137741577

Epoch: 6| Step: 3
Training loss: 2.919076160447542
Validation loss: 2.506822997750655

Epoch: 6| Step: 4
Training loss: 2.765481891270016
Validation loss: 2.5024750107360454

Epoch: 6| Step: 5
Training loss: 2.972433756097385
Validation loss: 2.495621263366717

Epoch: 6| Step: 6
Training loss: 3.3723246955978396
Validation loss: 2.514449895596744

Epoch: 6| Step: 7
Training loss: 2.7871578776383643
Validation loss: 2.497771703649477

Epoch: 6| Step: 8
Training loss: 2.929159132042026
Validation loss: 2.527173426849644

Epoch: 6| Step: 9
Training loss: 1.5777941064183676
Validation loss: 2.4868565452758578

Epoch: 6| Step: 10
Training loss: 2.713215247575336
Validation loss: 2.500638208656088

Epoch: 6| Step: 11
Training loss: 2.062776026895259
Validation loss: 2.4924764610636516

Epoch: 6| Step: 12
Training loss: 2.7310756287245566
Validation loss: 2.4778162096917

Epoch: 6| Step: 13
Training loss: 3.4898448485506584
Validation loss: 2.485377847049124

Epoch: 102| Step: 0
Training loss: 2.8467150311377956
Validation loss: 2.4762578416930747

Epoch: 6| Step: 1
Training loss: 3.1280737446826365
Validation loss: 2.4993025104122983

Epoch: 6| Step: 2
Training loss: 2.96031661556944
Validation loss: 2.5024256823406144

Epoch: 6| Step: 3
Training loss: 2.8717151618120234
Validation loss: 2.491117791175268

Epoch: 6| Step: 4
Training loss: 3.1401840583650755
Validation loss: 2.492356179852349

Epoch: 6| Step: 5
Training loss: 2.6248612140115646
Validation loss: 2.5076528217300824

Epoch: 6| Step: 6
Training loss: 3.0954428000756273
Validation loss: 2.4985685639445148

Epoch: 6| Step: 7
Training loss: 2.563441964052232
Validation loss: 2.5011300414519804

Epoch: 6| Step: 8
Training loss: 2.0625332916347223
Validation loss: 2.4917503480409353

Epoch: 6| Step: 9
Training loss: 2.434033594443469
Validation loss: 2.5141888657065623

Epoch: 6| Step: 10
Training loss: 2.231486020040345
Validation loss: 2.5165574741641237

Epoch: 6| Step: 11
Training loss: 1.9580015415462235
Validation loss: 2.5085368742850025

Epoch: 6| Step: 12
Training loss: 2.936976122303509
Validation loss: 2.5091345676347214

Epoch: 6| Step: 13
Training loss: 4.026287484241744
Validation loss: 2.499691464243411

Epoch: 103| Step: 0
Training loss: 2.810677170798394
Validation loss: 2.501206109121324

Epoch: 6| Step: 1
Training loss: 2.2103788391193846
Validation loss: 2.5063141200540837

Epoch: 6| Step: 2
Training loss: 3.0052114362166247
Validation loss: 2.5237226447965564

Epoch: 6| Step: 3
Training loss: 2.2307239927566904
Validation loss: 2.5016111371184384

Epoch: 6| Step: 4
Training loss: 2.454166944295439
Validation loss: 2.5074405950894962

Epoch: 6| Step: 5
Training loss: 3.0922892811559612
Validation loss: 2.5085530815992807

Epoch: 6| Step: 6
Training loss: 3.158603055469922
Validation loss: 2.4975815293501107

Epoch: 6| Step: 7
Training loss: 2.761988431073488
Validation loss: 2.496012563612955

Epoch: 6| Step: 8
Training loss: 2.991429643796046
Validation loss: 2.497341413883526

Epoch: 6| Step: 9
Training loss: 2.48107989134078
Validation loss: 2.52918571544328

Epoch: 6| Step: 10
Training loss: 2.7498000679164263
Validation loss: 2.4801769603994854

Epoch: 6| Step: 11
Training loss: 2.576752175774789
Validation loss: 2.4978615341363444

Epoch: 6| Step: 12
Training loss: 2.3313429949419064
Validation loss: 2.4912656795239885

Epoch: 6| Step: 13
Training loss: 3.9850568599305936
Validation loss: 2.4879932355039305

Epoch: 104| Step: 0
Training loss: 2.790768739900699
Validation loss: 2.502665817062915

Epoch: 6| Step: 1
Training loss: 2.444534324188104
Validation loss: 2.529000560301515

Epoch: 6| Step: 2
Training loss: 2.3321838840138143
Validation loss: 2.4780005730989796

Epoch: 6| Step: 3
Training loss: 2.800815214964687
Validation loss: 2.50970993200453

Epoch: 6| Step: 4
Training loss: 3.5074861030548017
Validation loss: 2.5000577550800194

Epoch: 6| Step: 5
Training loss: 2.872122610083615
Validation loss: 2.497442493958562

Epoch: 6| Step: 6
Training loss: 3.1610020282549387
Validation loss: 2.506429552687056

Epoch: 6| Step: 7
Training loss: 2.569291024883019
Validation loss: 2.491142683225778

Epoch: 6| Step: 8
Training loss: 3.356934694602092
Validation loss: 2.485416544100144

Epoch: 6| Step: 9
Training loss: 2.467086907837163
Validation loss: 2.493584240091558

Epoch: 6| Step: 10
Training loss: 2.70848214156369
Validation loss: 2.489486211206467

Epoch: 6| Step: 11
Training loss: 2.339296407477546
Validation loss: 2.4983844212971507

Epoch: 6| Step: 12
Training loss: 2.231885042832938
Validation loss: 2.512161607013841

Epoch: 6| Step: 13
Training loss: 2.58686180537182
Validation loss: 2.5024175399014346

Epoch: 105| Step: 0
Training loss: 3.0521795021156217
Validation loss: 2.4893758598708984

Epoch: 6| Step: 1
Training loss: 2.9919562586580613
Validation loss: 2.5050924282564577

Epoch: 6| Step: 2
Training loss: 2.287887844704698
Validation loss: 2.4862810983719856

Epoch: 6| Step: 3
Training loss: 1.792652908464388
Validation loss: 2.4945920863141238

Epoch: 6| Step: 4
Training loss: 2.949854740510506
Validation loss: 2.495799645043088

Epoch: 6| Step: 5
Training loss: 2.671866969046319
Validation loss: 2.505286279075963

Epoch: 6| Step: 6
Training loss: 3.1040482637153244
Validation loss: 2.4920867273087386

Epoch: 6| Step: 7
Training loss: 2.6213775344697408
Validation loss: 2.473921053248776

Epoch: 6| Step: 8
Training loss: 3.2105648817686876
Validation loss: 2.4843402018334726

Epoch: 6| Step: 9
Training loss: 3.1719736168474926
Validation loss: 2.4944225895204992

Epoch: 6| Step: 10
Training loss: 2.487873996242414
Validation loss: 2.5083370146436343

Epoch: 6| Step: 11
Training loss: 2.5972210741862196
Validation loss: 2.514945397321778

Epoch: 6| Step: 12
Training loss: 2.554027320416968
Validation loss: 2.501231307679456

Epoch: 6| Step: 13
Training loss: 2.914440795234273
Validation loss: 2.488858525275126

Epoch: 106| Step: 0
Training loss: 2.0734665363408786
Validation loss: 2.493057222145165

Epoch: 6| Step: 1
Training loss: 1.8254425714090408
Validation loss: 2.508711521768325

Epoch: 6| Step: 2
Training loss: 2.853852656185202
Validation loss: 2.4847258097428946

Epoch: 6| Step: 3
Training loss: 2.5414528261707647
Validation loss: 2.4965891920490884

Epoch: 6| Step: 4
Training loss: 2.719693338133016
Validation loss: 2.471730188537006

Epoch: 6| Step: 5
Training loss: 2.8416673348911727
Validation loss: 2.490200565694944

Epoch: 6| Step: 6
Training loss: 2.6335799459878144
Validation loss: 2.4753020354487103

Epoch: 6| Step: 7
Training loss: 3.197665292674424
Validation loss: 2.484581915298658

Epoch: 6| Step: 8
Training loss: 2.9918176009021455
Validation loss: 2.497001233795412

Epoch: 6| Step: 9
Training loss: 3.2959175346668954
Validation loss: 2.4965778000691063

Epoch: 6| Step: 10
Training loss: 2.2486003124890663
Validation loss: 2.5149097723942577

Epoch: 6| Step: 11
Training loss: 3.544168658141985
Validation loss: 2.49257008269987

Epoch: 6| Step: 12
Training loss: 2.321469208078715
Validation loss: 2.480033330769461

Epoch: 6| Step: 13
Training loss: 3.241821856735139
Validation loss: 2.524904773971083

Epoch: 107| Step: 0
Training loss: 3.1888529580189506
Validation loss: 2.5128571086488614

Epoch: 6| Step: 1
Training loss: 2.647646445455714
Validation loss: 2.4931616388713245

Epoch: 6| Step: 2
Training loss: 2.859706838561367
Validation loss: 2.522541484051993

Epoch: 6| Step: 3
Training loss: 2.8509139486149397
Validation loss: 2.4899353545287095

Epoch: 6| Step: 4
Training loss: 2.5615943610916165
Validation loss: 2.495236239368326

Epoch: 6| Step: 5
Training loss: 3.284165894215385
Validation loss: 2.5025904821556315

Epoch: 6| Step: 6
Training loss: 2.7441943180356527
Validation loss: 2.507260113219227

Epoch: 6| Step: 7
Training loss: 2.826214645684263
Validation loss: 2.521119506167054

Epoch: 6| Step: 8
Training loss: 2.5104418129406803
Validation loss: 2.4886495838820353

Epoch: 6| Step: 9
Training loss: 2.497814558379825
Validation loss: 2.5131953404185756

Epoch: 6| Step: 10
Training loss: 3.0977818582666936
Validation loss: 2.4848642072031737

Epoch: 6| Step: 11
Training loss: 2.559610738365896
Validation loss: 2.4831478952612436

Epoch: 6| Step: 12
Training loss: 2.2028491341235195
Validation loss: 2.5078334092533674

Epoch: 6| Step: 13
Training loss: 2.4619904702604103
Validation loss: 2.5083811943201217

Epoch: 108| Step: 0
Training loss: 2.1547098602617427
Validation loss: 2.5116434498258458

Epoch: 6| Step: 1
Training loss: 2.100515906223074
Validation loss: 2.515555737820313

Epoch: 6| Step: 2
Training loss: 2.205187974732823
Validation loss: 2.5025442856220863

Epoch: 6| Step: 3
Training loss: 2.504014130409273
Validation loss: 2.5150171114983007

Epoch: 6| Step: 4
Training loss: 2.9079294581928363
Validation loss: 2.4964027078132855

Epoch: 6| Step: 5
Training loss: 2.979748080057351
Validation loss: 2.4957038194429235

Epoch: 6| Step: 6
Training loss: 3.3486926189431827
Validation loss: 2.4988009140846392

Epoch: 6| Step: 7
Training loss: 2.7323658564553446
Validation loss: 2.511560156062267

Epoch: 6| Step: 8
Training loss: 2.9082209968914423
Validation loss: 2.476817186170271

Epoch: 6| Step: 9
Training loss: 3.6788082813723455
Validation loss: 2.4897496682799893

Epoch: 6| Step: 10
Training loss: 2.333732559474022
Validation loss: 2.474110752110336

Epoch: 6| Step: 11
Training loss: 2.6287746538211505
Validation loss: 2.495334790568589

Epoch: 6| Step: 12
Training loss: 2.931856618875244
Validation loss: 2.497601490628502

Epoch: 6| Step: 13
Training loss: 2.2252704284573697
Validation loss: 2.5023405726677215

Epoch: 109| Step: 0
Training loss: 2.7516280470259216
Validation loss: 2.516262158463001

Epoch: 6| Step: 1
Training loss: 2.210308619047749
Validation loss: 2.492408705849339

Epoch: 6| Step: 2
Training loss: 2.5656495626298335
Validation loss: 2.5028299741966324

Epoch: 6| Step: 3
Training loss: 3.3024037363142122
Validation loss: 2.4889978022396035

Epoch: 6| Step: 4
Training loss: 2.421121098479925
Validation loss: 2.497452108198743

Epoch: 6| Step: 5
Training loss: 2.430151008968702
Validation loss: 2.5004966991002915

Epoch: 6| Step: 6
Training loss: 2.5893731013242043
Validation loss: 2.4945749116786318

Epoch: 6| Step: 7
Training loss: 1.9511324064216955
Validation loss: 2.4998953541009308

Epoch: 6| Step: 8
Training loss: 3.061894882520699
Validation loss: 2.5029893645496104

Epoch: 6| Step: 9
Training loss: 3.7973672681142276
Validation loss: 2.519460808024497

Epoch: 6| Step: 10
Training loss: 2.1499794715078733
Validation loss: 2.5021951267358555

Epoch: 6| Step: 11
Training loss: 3.36345109499642
Validation loss: 2.493177625317031

Epoch: 6| Step: 12
Training loss: 2.1530442664259595
Validation loss: 2.500071474304659

Epoch: 6| Step: 13
Training loss: 3.4106054894978217
Validation loss: 2.493379671706357

Epoch: 110| Step: 0
Training loss: 2.625801872211027
Validation loss: 2.4976803703492787

Epoch: 6| Step: 1
Training loss: 2.956193893577649
Validation loss: 2.4829268658915122

Epoch: 6| Step: 2
Training loss: 2.88772057685727
Validation loss: 2.475403199386128

Epoch: 6| Step: 3
Training loss: 2.347819343271568
Validation loss: 2.48557556124135

Epoch: 6| Step: 4
Training loss: 2.3614573605039992
Validation loss: 2.494340452513557

Epoch: 6| Step: 5
Training loss: 2.485017897236348
Validation loss: 2.5012611151396813

Epoch: 6| Step: 6
Training loss: 2.257399999826417
Validation loss: 2.495949996343639

Epoch: 6| Step: 7
Training loss: 2.957740688510193
Validation loss: 2.506491238547721

Epoch: 6| Step: 8
Training loss: 2.341182675918623
Validation loss: 2.50549192889027

Epoch: 6| Step: 9
Training loss: 3.3178322537852654
Validation loss: 2.4876845389619326

Epoch: 6| Step: 10
Training loss: 2.9150029114697213
Validation loss: 2.509589158475449

Epoch: 6| Step: 11
Training loss: 3.2045454643834876
Validation loss: 2.497117465493032

Epoch: 6| Step: 12
Training loss: 2.540535461424543
Validation loss: 2.503788501688658

Epoch: 6| Step: 13
Training loss: 3.0953429773747216
Validation loss: 2.495551753156181

Epoch: 111| Step: 0
Training loss: 2.185153683772403
Validation loss: 2.505776144742812

Epoch: 6| Step: 1
Training loss: 2.9888435183850923
Validation loss: 2.4986084274779223

Epoch: 6| Step: 2
Training loss: 3.040864934599377
Validation loss: 2.4897429393247026

Epoch: 6| Step: 3
Training loss: 2.757737372134223
Validation loss: 2.521996805138776

Epoch: 6| Step: 4
Training loss: 2.541576185856801
Validation loss: 2.5046648567590775

Epoch: 6| Step: 5
Training loss: 2.4809844674881543
Validation loss: 2.4810569866030168

Epoch: 6| Step: 6
Training loss: 2.418764344007754
Validation loss: 2.4988440456063166

Epoch: 6| Step: 7
Training loss: 1.9080826126823436
Validation loss: 2.510347059943736

Epoch: 6| Step: 8
Training loss: 3.110071152244187
Validation loss: 2.498397999897806

Epoch: 6| Step: 9
Training loss: 3.3975284456770294
Validation loss: 2.4861249538535874

Epoch: 6| Step: 10
Training loss: 3.389795298514723
Validation loss: 2.5167970234729466

Epoch: 6| Step: 11
Training loss: 1.903308349697045
Validation loss: 2.49149393223792

Epoch: 6| Step: 12
Training loss: 2.7284658177607732
Validation loss: 2.502775481015726

Epoch: 6| Step: 13
Training loss: 3.122559929937654
Validation loss: 2.5003510597837

Epoch: 112| Step: 0
Training loss: 2.5751741109705075
Validation loss: 2.489553119690446

Epoch: 6| Step: 1
Training loss: 3.6736845711420396
Validation loss: 2.511386151240971

Epoch: 6| Step: 2
Training loss: 2.5273054494417235
Validation loss: 2.513080624564009

Epoch: 6| Step: 3
Training loss: 2.8937051394715567
Validation loss: 2.4920011081584126

Epoch: 6| Step: 4
Training loss: 3.035433369950361
Validation loss: 2.4819369646844818

Epoch: 6| Step: 5
Training loss: 2.5973700573666405
Validation loss: 2.494098767403535

Epoch: 6| Step: 6
Training loss: 1.8208744998820425
Validation loss: 2.4976199993444945

Epoch: 6| Step: 7
Training loss: 3.412456213142699
Validation loss: 2.508939678653995

Epoch: 6| Step: 8
Training loss: 1.5409689002936962
Validation loss: 2.5009790646600583

Epoch: 6| Step: 9
Training loss: 2.735339185474943
Validation loss: 2.495225008166953

Epoch: 6| Step: 10
Training loss: 3.0469613869965033
Validation loss: 2.516688662681897

Epoch: 6| Step: 11
Training loss: 2.566727756004443
Validation loss: 2.5013422808100887

Epoch: 6| Step: 12
Training loss: 2.350582691756172
Validation loss: 2.4810883414586047

Epoch: 6| Step: 13
Training loss: 2.9380289778348287
Validation loss: 2.5136138350676394

Epoch: 113| Step: 0
Training loss: 2.0021703388258025
Validation loss: 2.486173528112037

Epoch: 6| Step: 1
Training loss: 3.4180940267220117
Validation loss: 2.4927168492354626

Epoch: 6| Step: 2
Training loss: 2.765491978091763
Validation loss: 2.509440691926357

Epoch: 6| Step: 3
Training loss: 3.12347374838271
Validation loss: 2.503420315373631

Epoch: 6| Step: 4
Training loss: 2.3888016273273256
Validation loss: 2.498392383970733

Epoch: 6| Step: 5
Training loss: 2.414869846288143
Validation loss: 2.5010395759889867

Epoch: 6| Step: 6
Training loss: 3.0087218656282393
Validation loss: 2.517523386902508

Epoch: 6| Step: 7
Training loss: 2.1587485612379624
Validation loss: 2.494956996763398

Epoch: 6| Step: 8
Training loss: 2.705706559870945
Validation loss: 2.5038581723097697

Epoch: 6| Step: 9
Training loss: 2.4744081964889224
Validation loss: 2.5072463709575508

Epoch: 6| Step: 10
Training loss: 2.5943342722777065
Validation loss: 2.5154600818658603

Epoch: 6| Step: 11
Training loss: 3.318407225642711
Validation loss: 2.4818196945838995

Epoch: 6| Step: 12
Training loss: 2.8104793495406324
Validation loss: 2.4912559930435725

Epoch: 6| Step: 13
Training loss: 2.806383985281675
Validation loss: 2.4853505433775926

Epoch: 114| Step: 0
Training loss: 2.7568598066182415
Validation loss: 2.4805770947254926

Epoch: 6| Step: 1
Training loss: 2.7152822895017987
Validation loss: 2.4974916456795326

Epoch: 6| Step: 2
Training loss: 2.28471842426988
Validation loss: 2.51615266966964

Epoch: 6| Step: 3
Training loss: 2.9755066127738874
Validation loss: 2.47563233056702

Epoch: 6| Step: 4
Training loss: 2.9255597548940213
Validation loss: 2.491660463396264

Epoch: 6| Step: 5
Training loss: 3.1081132485316942
Validation loss: 2.511747077566919

Epoch: 6| Step: 6
Training loss: 2.1452372071680816
Validation loss: 2.507537539467787

Epoch: 6| Step: 7
Training loss: 2.3761503545666725
Validation loss: 2.4838957316212653

Epoch: 6| Step: 8
Training loss: 3.1839729691704677
Validation loss: 2.5020144519438525

Epoch: 6| Step: 9
Training loss: 3.3944000464610884
Validation loss: 2.4774061325117334

Epoch: 6| Step: 10
Training loss: 3.06600144745456
Validation loss: 2.508669233849538

Epoch: 6| Step: 11
Training loss: 2.0587419894444188
Validation loss: 2.4822271624114434

Epoch: 6| Step: 12
Training loss: 2.0454728077545257
Validation loss: 2.500926630506446

Epoch: 6| Step: 13
Training loss: 2.9000188826899898
Validation loss: 2.4990606840376453

Epoch: 115| Step: 0
Training loss: 2.5140984683785983
Validation loss: 2.503253271033694

Epoch: 6| Step: 1
Training loss: 2.5040490739053753
Validation loss: 2.4887027443697445

Epoch: 6| Step: 2
Training loss: 2.907636250315357
Validation loss: 2.5253925740799055

Epoch: 6| Step: 3
Training loss: 2.983620433383397
Validation loss: 2.488061058926894

Epoch: 6| Step: 4
Training loss: 2.9435835805450297
Validation loss: 2.481129679251695

Epoch: 6| Step: 5
Training loss: 2.8307732254338225
Validation loss: 2.5066381820420864

Epoch: 6| Step: 6
Training loss: 2.782946894044078
Validation loss: 2.509164676610775

Epoch: 6| Step: 7
Training loss: 2.4055475968524624
Validation loss: 2.4960742901986754

Epoch: 6| Step: 8
Training loss: 2.581369012116456
Validation loss: 2.4947290793962873

Epoch: 6| Step: 9
Training loss: 2.494461791675101
Validation loss: 2.4978621499367684

Epoch: 6| Step: 10
Training loss: 3.1409377516462813
Validation loss: 2.5165258960134853

Epoch: 6| Step: 11
Training loss: 3.1895387898496494
Validation loss: 2.4938691201571266

Epoch: 6| Step: 12
Training loss: 2.024531830721848
Validation loss: 2.5061718589538966

Epoch: 6| Step: 13
Training loss: 2.7717239459143
Validation loss: 2.498075609546119

Epoch: 116| Step: 0
Training loss: 2.2460322894104756
Validation loss: 2.487471341434741

Epoch: 6| Step: 1
Training loss: 2.2602242125635126
Validation loss: 2.5194853691749772

Epoch: 6| Step: 2
Training loss: 1.9898450056895085
Validation loss: 2.5121272406926924

Epoch: 6| Step: 3
Training loss: 2.798409834681875
Validation loss: 2.5091795669797126

Epoch: 6| Step: 4
Training loss: 2.473041715301737
Validation loss: 2.51870229110943

Epoch: 6| Step: 5
Training loss: 2.920078643366864
Validation loss: 2.4965566117106484

Epoch: 6| Step: 6
Training loss: 3.051018660486721
Validation loss: 2.4913043437752274

Epoch: 6| Step: 7
Training loss: 2.20733294830196
Validation loss: 2.517553647582304

Epoch: 6| Step: 8
Training loss: 2.760391110475867
Validation loss: 2.506569594073673

Epoch: 6| Step: 9
Training loss: 3.236592440266406
Validation loss: 2.5008783704733357

Epoch: 6| Step: 10
Training loss: 3.3156027028217636
Validation loss: 2.496345632227041

Epoch: 6| Step: 11
Training loss: 3.1884798526016715
Validation loss: 2.4913238243703

Epoch: 6| Step: 12
Training loss: 2.679802272107092
Validation loss: 2.513985923996309

Epoch: 6| Step: 13
Training loss: 2.7941062478225653
Validation loss: 2.525301327102999

Epoch: 117| Step: 0
Training loss: 3.2686131873592967
Validation loss: 2.500785803608513

Epoch: 6| Step: 1
Training loss: 2.8305586149652346
Validation loss: 2.508938246086593

Epoch: 6| Step: 2
Training loss: 2.5785083832485225
Validation loss: 2.5104980891258317

Epoch: 6| Step: 3
Training loss: 2.246745829258188
Validation loss: 2.5114826677117232

Epoch: 6| Step: 4
Training loss: 3.216024337306385
Validation loss: 2.4972091699657035

Epoch: 6| Step: 5
Training loss: 2.097203381631305
Validation loss: 2.5080988733273983

Epoch: 6| Step: 6
Training loss: 3.2007359969608884
Validation loss: 2.494631546831575

Epoch: 6| Step: 7
Training loss: 2.9509055865136684
Validation loss: 2.5088355119092767

Epoch: 6| Step: 8
Training loss: 2.3511761826442306
Validation loss: 2.5001277921685996

Epoch: 6| Step: 9
Training loss: 2.8444000171960178
Validation loss: 2.5133807296583783

Epoch: 6| Step: 10
Training loss: 2.273578442796042
Validation loss: 2.4780236767884634

Epoch: 6| Step: 11
Training loss: 2.8027934955382623
Validation loss: 2.4676437921409224

Epoch: 6| Step: 12
Training loss: 2.437957525107046
Validation loss: 2.5149050200552012

Epoch: 6| Step: 13
Training loss: 2.9395006549832527
Validation loss: 2.5117754293099344

Epoch: 118| Step: 0
Training loss: 2.3710080780187726
Validation loss: 2.487943617917873

Epoch: 6| Step: 1
Training loss: 2.8448472473756614
Validation loss: 2.491066941175019

Epoch: 6| Step: 2
Training loss: 2.7785513997975886
Validation loss: 2.5143522898955752

Epoch: 6| Step: 3
Training loss: 3.6084815566796875
Validation loss: 2.5076179877477545

Epoch: 6| Step: 4
Training loss: 2.514964710086596
Validation loss: 2.499216344511193

Epoch: 6| Step: 5
Training loss: 3.4365119207589774
Validation loss: 2.4778243491685807

Epoch: 6| Step: 6
Training loss: 2.8788501004213125
Validation loss: 2.5114563133904078

Epoch: 6| Step: 7
Training loss: 2.225662852787309
Validation loss: 2.486350589366485

Epoch: 6| Step: 8
Training loss: 2.160677358949063
Validation loss: 2.4928219589688694

Epoch: 6| Step: 9
Training loss: 2.021721425186252
Validation loss: 2.5105790848328806

Epoch: 6| Step: 10
Training loss: 2.99024011572767
Validation loss: 2.4825558747471685

Epoch: 6| Step: 11
Training loss: 2.1167506369007145
Validation loss: 2.4887773011583363

Epoch: 6| Step: 12
Training loss: 2.7695080066130604
Validation loss: 2.4930785101691115

Epoch: 6| Step: 13
Training loss: 3.272106255025537
Validation loss: 2.4839647743424713

Epoch: 119| Step: 0
Training loss: 2.6966868559274517
Validation loss: 2.4979745894706262

Epoch: 6| Step: 1
Training loss: 2.2077970273392937
Validation loss: 2.488188714197838

Epoch: 6| Step: 2
Training loss: 2.602992767236006
Validation loss: 2.51029026566149

Epoch: 6| Step: 3
Training loss: 2.7803999212480957
Validation loss: 2.4905768082261024

Epoch: 6| Step: 4
Training loss: 2.6857943777994873
Validation loss: 2.5211031976178577

Epoch: 6| Step: 5
Training loss: 2.1802902208731543
Validation loss: 2.509881344232598

Epoch: 6| Step: 6
Training loss: 2.7446038449114893
Validation loss: 2.492595443643436

Epoch: 6| Step: 7
Training loss: 2.960185818639023
Validation loss: 2.4881013597321093

Epoch: 6| Step: 8
Training loss: 3.3311089405304113
Validation loss: 2.4978446272764034

Epoch: 6| Step: 9
Training loss: 2.440914403581238
Validation loss: 2.4856308615882927

Epoch: 6| Step: 10
Training loss: 2.9249170144853642
Validation loss: 2.4858294802189334

Epoch: 6| Step: 11
Training loss: 3.1305227687698
Validation loss: 2.4689669624715607

Epoch: 6| Step: 12
Training loss: 2.410168318509594
Validation loss: 2.490061562944188

Epoch: 6| Step: 13
Training loss: 2.6036024372482673
Validation loss: 2.5050242758926697

Epoch: 120| Step: 0
Training loss: 2.2808643171802725
Validation loss: 2.491765733950503

Epoch: 6| Step: 1
Training loss: 3.1117319346691397
Validation loss: 2.491519151851401

Epoch: 6| Step: 2
Training loss: 2.419070681425195
Validation loss: 2.5177811528877125

Epoch: 6| Step: 3
Training loss: 2.4347034942763575
Validation loss: 2.5129143514404926

Epoch: 6| Step: 4
Training loss: 2.570018623967356
Validation loss: 2.5088672767770466

Epoch: 6| Step: 5
Training loss: 3.6814263967015632
Validation loss: 2.5110218569766274

Epoch: 6| Step: 6
Training loss: 2.2068115124986947
Validation loss: 2.503914851403502

Epoch: 6| Step: 7
Training loss: 2.4699933747731673
Validation loss: 2.4918660011059983

Epoch: 6| Step: 8
Training loss: 3.383390663550715
Validation loss: 2.4963863774565693

Epoch: 6| Step: 9
Training loss: 2.5249926614182594
Validation loss: 2.4838857738544737

Epoch: 6| Step: 10
Training loss: 3.284566601827526
Validation loss: 2.507993386770842

Epoch: 6| Step: 11
Training loss: 2.136284430122037
Validation loss: 2.4925169841241885

Epoch: 6| Step: 12
Training loss: 2.3391167175084364
Validation loss: 2.513082581150987

Epoch: 6| Step: 13
Training loss: 2.8851846172426696
Validation loss: 2.482368067767094

Epoch: 121| Step: 0
Training loss: 2.1435464567752005
Validation loss: 2.5263940763023847

Epoch: 6| Step: 1
Training loss: 3.34302206226478
Validation loss: 2.5114943850779565

Epoch: 6| Step: 2
Training loss: 2.4961054030073258
Validation loss: 2.4844701605178945

Epoch: 6| Step: 3
Training loss: 2.826258596738743
Validation loss: 2.5098939924329096

Epoch: 6| Step: 4
Training loss: 3.4376306682373623
Validation loss: 2.4871255491488835

Epoch: 6| Step: 5
Training loss: 3.138869976635638
Validation loss: 2.4782226066576305

Epoch: 6| Step: 6
Training loss: 2.575168555955756
Validation loss: 2.4914054105058674

Epoch: 6| Step: 7
Training loss: 2.3949647296387018
Validation loss: 2.504467178611664

Epoch: 6| Step: 8
Training loss: 2.894429440580479
Validation loss: 2.5335330994743392

Epoch: 6| Step: 9
Training loss: 2.747068663487107
Validation loss: 2.511921928969677

Epoch: 6| Step: 10
Training loss: 2.621187074821898
Validation loss: 2.4899148015430725

Epoch: 6| Step: 11
Training loss: 2.1552561805494
Validation loss: 2.5120007172277767

Epoch: 6| Step: 12
Training loss: 2.435550007516029
Validation loss: 2.4809541673817295

Epoch: 6| Step: 13
Training loss: 2.2032845080915426
Validation loss: 2.4803572222940895

Epoch: 122| Step: 0
Training loss: 3.120087233326481
Validation loss: 2.4983786072980645

Epoch: 6| Step: 1
Training loss: 3.5225885895309643
Validation loss: 2.5050073160584523

Epoch: 6| Step: 2
Training loss: 3.0382904405717257
Validation loss: 2.5204407818441625

Epoch: 6| Step: 3
Training loss: 2.129069190832991
Validation loss: 2.4976859755604046

Epoch: 6| Step: 4
Training loss: 2.882615493617803
Validation loss: 2.4870620037693754

Epoch: 6| Step: 5
Training loss: 2.280956301660654
Validation loss: 2.510621112363006

Epoch: 6| Step: 6
Training loss: 2.5564091565267346
Validation loss: 2.497820383955318

Epoch: 6| Step: 7
Training loss: 2.3237363683373577
Validation loss: 2.514240342153179

Epoch: 6| Step: 8
Training loss: 2.8687249409031983
Validation loss: 2.503234838790115

Epoch: 6| Step: 9
Training loss: 3.0446938557183096
Validation loss: 2.4985173843585633

Epoch: 6| Step: 10
Training loss: 2.8033875239332295
Validation loss: 2.494770924875886

Epoch: 6| Step: 11
Training loss: 2.1888652355940703
Validation loss: 2.5063435868015644

Epoch: 6| Step: 12
Training loss: 2.336058954762168
Validation loss: 2.486033747463402

Epoch: 6| Step: 13
Training loss: 2.598837310072967
Validation loss: 2.506993066317367

Epoch: 123| Step: 0
Training loss: 2.9015786971141893
Validation loss: 2.5268921604695733

Epoch: 6| Step: 1
Training loss: 2.677471701706657
Validation loss: 2.5084832623717817

Epoch: 6| Step: 2
Training loss: 2.3795224348542825
Validation loss: 2.488881004913882

Epoch: 6| Step: 3
Training loss: 2.960538731599171
Validation loss: 2.5185807110357206

Epoch: 6| Step: 4
Training loss: 2.4262562162387464
Validation loss: 2.4877187998211094

Epoch: 6| Step: 5
Training loss: 3.336600387428159
Validation loss: 2.5117069714191773

Epoch: 6| Step: 6
Training loss: 2.3553120575213944
Validation loss: 2.474467851191416

Epoch: 6| Step: 7
Training loss: 2.741307826652065
Validation loss: 2.503257284570683

Epoch: 6| Step: 8
Training loss: 2.803118593682801
Validation loss: 2.4820412914745624

Epoch: 6| Step: 9
Training loss: 2.0033913707524844
Validation loss: 2.4833008893785506

Epoch: 6| Step: 10
Training loss: 3.1179692332650433
Validation loss: 2.4572203247289837

Epoch: 6| Step: 11
Training loss: 2.5513024724996565
Validation loss: 2.5000796777067

Epoch: 6| Step: 12
Training loss: 2.936389307295861
Validation loss: 2.4963257451176544

Epoch: 6| Step: 13
Training loss: 2.8721529920520283
Validation loss: 2.477979923192418

Epoch: 124| Step: 0
Training loss: 3.101909935082147
Validation loss: 2.516665868617095

Epoch: 6| Step: 1
Training loss: 3.1361011928074514
Validation loss: 2.479656960688251

Epoch: 6| Step: 2
Training loss: 3.313385467221484
Validation loss: 2.490772300301848

Epoch: 6| Step: 3
Training loss: 2.692955778006045
Validation loss: 2.4670328721351567

Epoch: 6| Step: 4
Training loss: 2.7238112945452437
Validation loss: 2.496657292291077

Epoch: 6| Step: 5
Training loss: 2.2470695697861114
Validation loss: 2.494484031717513

Epoch: 6| Step: 6
Training loss: 2.097080599260534
Validation loss: 2.516898961080886

Epoch: 6| Step: 7
Training loss: 2.2594319907528533
Validation loss: 2.498189583389958

Epoch: 6| Step: 8
Training loss: 2.047351810742522
Validation loss: 2.506161091560112

Epoch: 6| Step: 9
Training loss: 2.841692001662392
Validation loss: 2.500057583832775

Epoch: 6| Step: 10
Training loss: 2.5418423034350943
Validation loss: 2.484471187224492

Epoch: 6| Step: 11
Training loss: 3.4199149035301586
Validation loss: 2.498045830269119

Epoch: 6| Step: 12
Training loss: 2.5676001989616224
Validation loss: 2.5010707418324287

Epoch: 6| Step: 13
Training loss: 2.7585536403975697
Validation loss: 2.4828227838554824

Epoch: 125| Step: 0
Training loss: 2.8116452083737373
Validation loss: 2.4876381161155314

Epoch: 6| Step: 1
Training loss: 2.8496746345980077
Validation loss: 2.5003275205536677

Epoch: 6| Step: 2
Training loss: 3.0383572973776998
Validation loss: 2.5015628790178264

Epoch: 6| Step: 3
Training loss: 2.0603779366468884
Validation loss: 2.4859072974318166

Epoch: 6| Step: 4
Training loss: 2.1398699466011246
Validation loss: 2.501444971205588

Epoch: 6| Step: 5
Training loss: 2.206177240744298
Validation loss: 2.490029794974581

Epoch: 6| Step: 6
Training loss: 3.1432291498107827
Validation loss: 2.499244447587485

Epoch: 6| Step: 7
Training loss: 1.9215967860864385
Validation loss: 2.482810345975608

Epoch: 6| Step: 8
Training loss: 2.7780952992691392
Validation loss: 2.5331367419904667

Epoch: 6| Step: 9
Training loss: 3.097504466548529
Validation loss: 2.516823713013318

Epoch: 6| Step: 10
Training loss: 2.677946987935054
Validation loss: 2.5057836757149623

Epoch: 6| Step: 11
Training loss: 3.0288170558104626
Validation loss: 2.5192825213688366

Epoch: 6| Step: 12
Training loss: 2.7529080360646443
Validation loss: 2.4892722282249236

Epoch: 6| Step: 13
Training loss: 3.7020014736475555
Validation loss: 2.501240859183706

Epoch: 126| Step: 0
Training loss: 2.4646670222214655
Validation loss: 2.506117541245937

Epoch: 6| Step: 1
Training loss: 2.3371942003921453
Validation loss: 2.5013368600765418

Epoch: 6| Step: 2
Training loss: 3.092001989504629
Validation loss: 2.4945058635588926

Epoch: 6| Step: 3
Training loss: 2.8201193281047092
Validation loss: 2.486745697352077

Epoch: 6| Step: 4
Training loss: 3.267856255441109
Validation loss: 2.5138085085278505

Epoch: 6| Step: 5
Training loss: 2.103656958858887
Validation loss: 2.4922591921837567

Epoch: 6| Step: 6
Training loss: 2.6577932026301028
Validation loss: 2.5243156335370753

Epoch: 6| Step: 7
Training loss: 2.8039543872611525
Validation loss: 2.4927983291023823

Epoch: 6| Step: 8
Training loss: 2.4353365956488324
Validation loss: 2.520752711690383

Epoch: 6| Step: 9
Training loss: 2.4973637986871604
Validation loss: 2.507387030284112

Epoch: 6| Step: 10
Training loss: 3.0318793203951806
Validation loss: 2.475649416044684

Epoch: 6| Step: 11
Training loss: 2.832338682127955
Validation loss: 2.511247475881395

Epoch: 6| Step: 12
Training loss: 2.9438845464002457
Validation loss: 2.493608680866075

Epoch: 6| Step: 13
Training loss: 2.4355864227192145
Validation loss: 2.518263001108667

Epoch: 127| Step: 0
Training loss: 2.371752476197634
Validation loss: 2.495311102307229

Epoch: 6| Step: 1
Training loss: 2.1592967304889554
Validation loss: 2.495900755715996

Epoch: 6| Step: 2
Training loss: 3.2882366094914763
Validation loss: 2.5229776874619017

Epoch: 6| Step: 3
Training loss: 2.3880175164441306
Validation loss: 2.4804664674463703

Epoch: 6| Step: 4
Training loss: 2.9403507116905727
Validation loss: 2.4895381835009553

Epoch: 6| Step: 5
Training loss: 2.5646739205156273
Validation loss: 2.499984160752521

Epoch: 6| Step: 6
Training loss: 2.666952495356412
Validation loss: 2.4861537699926406

Epoch: 6| Step: 7
Training loss: 2.7593731233238326
Validation loss: 2.4980788971237007

Epoch: 6| Step: 8
Training loss: 2.5336842076435846
Validation loss: 2.4956872636590006

Epoch: 6| Step: 9
Training loss: 2.620399076047201
Validation loss: 2.4951352743796806

Epoch: 6| Step: 10
Training loss: 3.3173513335182205
Validation loss: 2.4790577353121726

Epoch: 6| Step: 11
Training loss: 3.472904226505461
Validation loss: 2.5063864524858963

Epoch: 6| Step: 12
Training loss: 2.1987867998315074
Validation loss: 2.5113017260181985

Epoch: 6| Step: 13
Training loss: 2.0772707911630914
Validation loss: 2.481779113582865

Epoch: 128| Step: 0
Training loss: 3.341524898981406
Validation loss: 2.5062307586229995

Epoch: 6| Step: 1
Training loss: 2.1489953998642473
Validation loss: 2.4951550749111324

Epoch: 6| Step: 2
Training loss: 3.26430955885883
Validation loss: 2.504428663319833

Epoch: 6| Step: 3
Training loss: 2.385730395168871
Validation loss: 2.5005591054447045

Epoch: 6| Step: 4
Training loss: 2.713341078907302
Validation loss: 2.472924784299821

Epoch: 6| Step: 5
Training loss: 2.140798854032988
Validation loss: 2.465080979302184

Epoch: 6| Step: 6
Training loss: 1.8972845147653163
Validation loss: 2.488531476304551

Epoch: 6| Step: 7
Training loss: 3.466259999142135
Validation loss: 2.513110997395776

Epoch: 6| Step: 8
Training loss: 2.0568302715565063
Validation loss: 2.5159209529599083

Epoch: 6| Step: 9
Training loss: 2.3758915683331003
Validation loss: 2.4890132025891587

Epoch: 6| Step: 10
Training loss: 2.957156381516895
Validation loss: 2.5102090676122617

Epoch: 6| Step: 11
Training loss: 3.2502746465983936
Validation loss: 2.477342576870006

Epoch: 6| Step: 12
Training loss: 2.968099422445036
Validation loss: 2.503174304741579

Epoch: 6| Step: 13
Training loss: 2.6100801896970847
Validation loss: 2.4772231281683563

Epoch: 129| Step: 0
Training loss: 3.0138804078654213
Validation loss: 2.5086950247465207

Epoch: 6| Step: 1
Training loss: 2.5915237432323597
Validation loss: 2.5046876960687636

Epoch: 6| Step: 2
Training loss: 2.107676974068907
Validation loss: 2.4874152059578156

Epoch: 6| Step: 3
Training loss: 2.858728554615602
Validation loss: 2.5072770608824144

Epoch: 6| Step: 4
Training loss: 3.2458491594731025
Validation loss: 2.4886434236776926

Epoch: 6| Step: 5
Training loss: 2.8295340215724285
Validation loss: 2.4858169431659203

Epoch: 6| Step: 6
Training loss: 2.1803246664063454
Validation loss: 2.479550411988236

Epoch: 6| Step: 7
Training loss: 2.937731307642154
Validation loss: 2.4995830393267515

Epoch: 6| Step: 8
Training loss: 2.489981796320668
Validation loss: 2.482244186488105

Epoch: 6| Step: 9
Training loss: 3.505560953089419
Validation loss: 2.4907889618312056

Epoch: 6| Step: 10
Training loss: 2.231270827936151
Validation loss: 2.5034499190988484

Epoch: 6| Step: 11
Training loss: 2.4848482652848762
Validation loss: 2.4735448807635945

Epoch: 6| Step: 12
Training loss: 2.4569807911651034
Validation loss: 2.479838623439048

Epoch: 6| Step: 13
Training loss: 2.7254995990501647
Validation loss: 2.474308949588748

Epoch: 130| Step: 0
Training loss: 2.261349873612
Validation loss: 2.4822284053841974

Epoch: 6| Step: 1
Training loss: 2.4992691879215108
Validation loss: 2.487703555827177

Epoch: 6| Step: 2
Training loss: 1.872218866876651
Validation loss: 2.489236052038117

Epoch: 6| Step: 3
Training loss: 2.915939422040982
Validation loss: 2.491207706205253

Epoch: 6| Step: 4
Training loss: 2.8860771075209755
Validation loss: 2.5001147284895633

Epoch: 6| Step: 5
Training loss: 2.725263400865219
Validation loss: 2.4805893042939817

Epoch: 6| Step: 6
Training loss: 2.934979595262866
Validation loss: 2.48516572460199

Epoch: 6| Step: 7
Training loss: 2.787478213374781
Validation loss: 2.487170909587041

Epoch: 6| Step: 8
Training loss: 3.046654952490704
Validation loss: 2.5069500555681397

Epoch: 6| Step: 9
Training loss: 2.645919728307849
Validation loss: 2.501002391723723

Epoch: 6| Step: 10
Training loss: 2.917820366248969
Validation loss: 2.4898574938327322

Epoch: 6| Step: 11
Training loss: 2.915333325024103
Validation loss: 2.511589865437467

Epoch: 6| Step: 12
Training loss: 2.4728620060892332
Validation loss: 2.4855943214368854

Epoch: 6| Step: 13
Training loss: 3.1182188082416182
Validation loss: 2.4965615088518316

Epoch: 131| Step: 0
Training loss: 2.9215668704507904
Validation loss: 2.5062090616516763

Epoch: 6| Step: 1
Training loss: 2.585034999499797
Validation loss: 2.4881901257413648

Epoch: 6| Step: 2
Training loss: 2.694790997017884
Validation loss: 2.492798790862375

Epoch: 6| Step: 3
Training loss: 3.0578306763839245
Validation loss: 2.5067067742700857

Epoch: 6| Step: 4
Training loss: 2.239181470671784
Validation loss: 2.470860195326893

Epoch: 6| Step: 5
Training loss: 2.71323247064425
Validation loss: 2.498216282903104

Epoch: 6| Step: 6
Training loss: 3.2962450627914563
Validation loss: 2.487345271111986

Epoch: 6| Step: 7
Training loss: 2.8393799456839424
Validation loss: 2.4829996834483823

Epoch: 6| Step: 8
Training loss: 2.889630780773616
Validation loss: 2.5083066851881615

Epoch: 6| Step: 9
Training loss: 2.5625922954034137
Validation loss: 2.497538002391263

Epoch: 6| Step: 10
Training loss: 2.185208019070241
Validation loss: 2.4999776839213945

Epoch: 6| Step: 11
Training loss: 2.9253428070809804
Validation loss: 2.5034057967886847

Epoch: 6| Step: 12
Training loss: 2.4481070153649735
Validation loss: 2.505552058039397

Epoch: 6| Step: 13
Training loss: 2.261171686557137
Validation loss: 2.474106033311641

Epoch: 132| Step: 0
Training loss: 2.33559800554763
Validation loss: 2.522797729255303

Epoch: 6| Step: 1
Training loss: 2.6453010644457122
Validation loss: 2.5185634419467764

Epoch: 6| Step: 2
Training loss: 2.76554189438607
Validation loss: 2.5128227191925085

Epoch: 6| Step: 3
Training loss: 3.4252770638997276
Validation loss: 2.5186242458574797

Epoch: 6| Step: 4
Training loss: 2.69811423816704
Validation loss: 2.4991101732282752

Epoch: 6| Step: 5
Training loss: 2.6531542521415408
Validation loss: 2.500332205245171

Epoch: 6| Step: 6
Training loss: 2.801538000728376
Validation loss: 2.4939493401529047

Epoch: 6| Step: 7
Training loss: 2.4661077532032
Validation loss: 2.4900621209597364

Epoch: 6| Step: 8
Training loss: 2.7832188870167713
Validation loss: 2.4957113910811572

Epoch: 6| Step: 9
Training loss: 2.8032683711135897
Validation loss: 2.4916021653810687

Epoch: 6| Step: 10
Training loss: 1.9976790789753203
Validation loss: 2.51171305158257

Epoch: 6| Step: 11
Training loss: 3.3823288358136705
Validation loss: 2.493601059663431

Epoch: 6| Step: 12
Training loss: 2.5122502596651275
Validation loss: 2.5000063239807213

Epoch: 6| Step: 13
Training loss: 2.66187409041981
Validation loss: 2.5224611610915355

Epoch: 133| Step: 0
Training loss: 2.5973060773435073
Validation loss: 2.473512997054603

Epoch: 6| Step: 1
Training loss: 2.57936547231613
Validation loss: 2.504852709880868

Epoch: 6| Step: 2
Training loss: 2.6851698954160304
Validation loss: 2.5044842076152714

Epoch: 6| Step: 3
Training loss: 2.6056420584577995
Validation loss: 2.504563761090421

Epoch: 6| Step: 4
Training loss: 2.3347542614251027
Validation loss: 2.490065003694896

Epoch: 6| Step: 5
Training loss: 2.368568244342284
Validation loss: 2.4862865065619597

Epoch: 6| Step: 6
Training loss: 2.759230208783286
Validation loss: 2.499097944381738

Epoch: 6| Step: 7
Training loss: 2.6052654135540654
Validation loss: 2.511743103112396

Epoch: 6| Step: 8
Training loss: 2.9250971525311096
Validation loss: 2.4838515003774826

Epoch: 6| Step: 9
Training loss: 2.654946579620239
Validation loss: 2.4959448514933027

Epoch: 6| Step: 10
Training loss: 2.6235383823757616
Validation loss: 2.518530301515313

Epoch: 6| Step: 11
Training loss: 2.9165865932553814
Validation loss: 2.4932911470068855

Epoch: 6| Step: 12
Training loss: 3.0825530602806825
Validation loss: 2.4679449016585835

Epoch: 6| Step: 13
Training loss: 3.778176690214213
Validation loss: 2.4900586050478735

Epoch: 134| Step: 0
Training loss: 2.8729223954381298
Validation loss: 2.483688409244171

Epoch: 6| Step: 1
Training loss: 2.3887535199788665
Validation loss: 2.491312402139272

Epoch: 6| Step: 2
Training loss: 3.6321560174226963
Validation loss: 2.4803066312756736

Epoch: 6| Step: 3
Training loss: 2.556447953671567
Validation loss: 2.4903937103944433

Epoch: 6| Step: 4
Training loss: 3.038354001654132
Validation loss: 2.506209212020282

Epoch: 6| Step: 5
Training loss: 2.2802757377531226
Validation loss: 2.499665831720425

Epoch: 6| Step: 6
Training loss: 2.2319903686753166
Validation loss: 2.493993087016369

Epoch: 6| Step: 7
Training loss: 2.757584084191138
Validation loss: 2.4887096965806994

Epoch: 6| Step: 8
Training loss: 2.234803058728825
Validation loss: 2.488074156013171

Epoch: 6| Step: 9
Training loss: 2.629806659104433
Validation loss: 2.4956192848718657

Epoch: 6| Step: 10
Training loss: 2.951809060101097
Validation loss: 2.495424815622622

Epoch: 6| Step: 11
Training loss: 3.1146000039835697
Validation loss: 2.494713041234733

Epoch: 6| Step: 12
Training loss: 2.2479034828834124
Validation loss: 2.5142555960439563

Epoch: 6| Step: 13
Training loss: 2.4191960438534514
Validation loss: 2.481137627039491

Epoch: 135| Step: 0
Training loss: 2.827518292679036
Validation loss: 2.4733513490426344

Epoch: 6| Step: 1
Training loss: 2.5823750000177266
Validation loss: 2.5115487778888927

Epoch: 6| Step: 2
Training loss: 2.4775619656139845
Validation loss: 2.4889196701592207

Epoch: 6| Step: 3
Training loss: 2.236275458236275
Validation loss: 2.4829882084699317

Epoch: 6| Step: 4
Training loss: 2.8605971095846856
Validation loss: 2.503125248219291

Epoch: 6| Step: 5
Training loss: 2.962798567909048
Validation loss: 2.5032587091238567

Epoch: 6| Step: 6
Training loss: 2.9128259893865613
Validation loss: 2.4792110666290874

Epoch: 6| Step: 7
Training loss: 2.6111234186662498
Validation loss: 2.4994783452006426

Epoch: 6| Step: 8
Training loss: 2.576083212853082
Validation loss: 2.4862083789854488

Epoch: 6| Step: 9
Training loss: 3.20607119650981
Validation loss: 2.494724167354173

Epoch: 6| Step: 10
Training loss: 2.6901596570761934
Validation loss: 2.4908406408881465

Epoch: 6| Step: 11
Training loss: 2.1536585397280157
Validation loss: 2.4884796452418896

Epoch: 6| Step: 12
Training loss: 2.631836209270626
Validation loss: 2.4839375067426848

Epoch: 6| Step: 13
Training loss: 3.1737222037613737
Validation loss: 2.4895431330641102

Epoch: 136| Step: 0
Training loss: 3.064277288912465
Validation loss: 2.4996608934836027

Epoch: 6| Step: 1
Training loss: 2.477144287317642
Validation loss: 2.510844026841623

Epoch: 6| Step: 2
Training loss: 3.0528533970919307
Validation loss: 2.5126099884997317

Epoch: 6| Step: 3
Training loss: 2.6465815790209155
Validation loss: 2.515128493617831

Epoch: 6| Step: 4
Training loss: 2.0089806153352923
Validation loss: 2.5141733748462496

Epoch: 6| Step: 5
Training loss: 2.404252945152336
Validation loss: 2.5168050022511634

Epoch: 6| Step: 6
Training loss: 2.857591082972746
Validation loss: 2.4898859311174153

Epoch: 6| Step: 7
Training loss: 2.2336029639626105
Validation loss: 2.496884685586231

Epoch: 6| Step: 8
Training loss: 3.268593930663357
Validation loss: 2.5067648406629415

Epoch: 6| Step: 9
Training loss: 2.862341504102611
Validation loss: 2.503272645328106

Epoch: 6| Step: 10
Training loss: 2.6787441361470377
Validation loss: 2.518577587126308

Epoch: 6| Step: 11
Training loss: 2.8663092575236235
Validation loss: 2.5001183092159143

Epoch: 6| Step: 12
Training loss: 1.4793829244925985
Validation loss: 2.486889338254898

Epoch: 6| Step: 13
Training loss: 3.856413906082548
Validation loss: 2.504645118613002

Epoch: 137| Step: 0
Training loss: 2.589015638425767
Validation loss: 2.5021936011705512

Epoch: 6| Step: 1
Training loss: 2.6374080406898934
Validation loss: 2.526508630068978

Epoch: 6| Step: 2
Training loss: 2.4210374922246296
Validation loss: 2.499677795238136

Epoch: 6| Step: 3
Training loss: 2.6255367275292456
Validation loss: 2.522582286859832

Epoch: 6| Step: 4
Training loss: 2.5050294829440034
Validation loss: 2.496990791332239

Epoch: 6| Step: 5
Training loss: 2.7586229554528763
Validation loss: 2.5008267091972676

Epoch: 6| Step: 6
Training loss: 3.105997215746278
Validation loss: 2.5059581370714734

Epoch: 6| Step: 7
Training loss: 2.261182968639109
Validation loss: 2.4825507589353055

Epoch: 6| Step: 8
Training loss: 3.11142069169425
Validation loss: 2.4733016517642077

Epoch: 6| Step: 9
Training loss: 2.884965459659816
Validation loss: 2.492847295753606

Epoch: 6| Step: 10
Training loss: 2.7070432280128216
Validation loss: 2.4821678661559523

Epoch: 6| Step: 11
Training loss: 2.3381637120553727
Validation loss: 2.459123790614037

Epoch: 6| Step: 12
Training loss: 3.2112953747683797
Validation loss: 2.4999831937409596

Epoch: 6| Step: 13
Training loss: 2.8011073477295794
Validation loss: 2.478914657721284

Epoch: 138| Step: 0
Training loss: 3.222687914143685
Validation loss: 2.48719728210583

Epoch: 6| Step: 1
Training loss: 2.5752069778959332
Validation loss: 2.5208183575596124

Epoch: 6| Step: 2
Training loss: 3.0924934378502686
Validation loss: 2.492306489688729

Epoch: 6| Step: 3
Training loss: 2.975282248563683
Validation loss: 2.50350093384659

Epoch: 6| Step: 4
Training loss: 2.2436097847738603
Validation loss: 2.4859984373062116

Epoch: 6| Step: 5
Training loss: 3.0821757506326737
Validation loss: 2.482574850868008

Epoch: 6| Step: 6
Training loss: 2.336069568995959
Validation loss: 2.492571945850402

Epoch: 6| Step: 7
Training loss: 2.587929871459481
Validation loss: 2.4806609596284264

Epoch: 6| Step: 8
Training loss: 2.325526073374439
Validation loss: 2.4789396728255517

Epoch: 6| Step: 9
Training loss: 3.2166908862794905
Validation loss: 2.5140466096887097

Epoch: 6| Step: 10
Training loss: 2.135152350714229
Validation loss: 2.489530736740305

Epoch: 6| Step: 11
Training loss: 2.450768280238185
Validation loss: 2.4964972116729935

Epoch: 6| Step: 12
Training loss: 2.551657837151272
Validation loss: 2.4998283819543965

Epoch: 6| Step: 13
Training loss: 2.8535450353549403
Validation loss: 2.496871719934198

Epoch: 139| Step: 0
Training loss: 3.1452663154830787
Validation loss: 2.5096851638429083

Epoch: 6| Step: 1
Training loss: 2.489360485451209
Validation loss: 2.5256107924871007

Epoch: 6| Step: 2
Training loss: 2.4409315944839984
Validation loss: 2.5122170456464725

Epoch: 6| Step: 3
Training loss: 3.979674435052293
Validation loss: 2.491964803898792

Epoch: 6| Step: 4
Training loss: 2.273198065979749
Validation loss: 2.4976438709924427

Epoch: 6| Step: 5
Training loss: 2.7626272215396073
Validation loss: 2.498389066535197

Epoch: 6| Step: 6
Training loss: 2.349282410814877
Validation loss: 2.5044433934979358

Epoch: 6| Step: 7
Training loss: 2.826834284008241
Validation loss: 2.510674006744001

Epoch: 6| Step: 8
Training loss: 2.6009990093342243
Validation loss: 2.5067711399074493

Epoch: 6| Step: 9
Training loss: 2.769706085669538
Validation loss: 2.5124839709554303

Epoch: 6| Step: 10
Training loss: 2.048165649718431
Validation loss: 2.5280742034418804

Epoch: 6| Step: 11
Training loss: 2.584346039504829
Validation loss: 2.5052630195296848

Epoch: 6| Step: 12
Training loss: 2.875540143564081
Validation loss: 2.5126186116333464

Epoch: 6| Step: 13
Training loss: 1.7976063442473087
Validation loss: 2.5004782444861577

Epoch: 140| Step: 0
Training loss: 2.6362770897462386
Validation loss: 2.499356449521783

Epoch: 6| Step: 1
Training loss: 2.4159021374037914
Validation loss: 2.5134044944545666

Epoch: 6| Step: 2
Training loss: 2.6100732474444364
Validation loss: 2.5280371820618655

Epoch: 6| Step: 3
Training loss: 2.5926576635227776
Validation loss: 2.47983699418022

Epoch: 6| Step: 4
Training loss: 2.439619951980496
Validation loss: 2.508650405039692

Epoch: 6| Step: 5
Training loss: 2.7874103001415937
Validation loss: 2.4742323995097446

Epoch: 6| Step: 6
Training loss: 2.1096869344008464
Validation loss: 2.501922599806909

Epoch: 6| Step: 7
Training loss: 2.840885606148491
Validation loss: 2.501725216837504

Epoch: 6| Step: 8
Training loss: 2.3256737009847597
Validation loss: 2.481692721992901

Epoch: 6| Step: 9
Training loss: 2.8706487816860164
Validation loss: 2.4818921045931104

Epoch: 6| Step: 10
Training loss: 3.324188770199345
Validation loss: 2.516466928629237

Epoch: 6| Step: 11
Training loss: 2.89149800082617
Validation loss: 2.486469361420285

Epoch: 6| Step: 12
Training loss: 3.430842941402917
Validation loss: 2.505438563905904

Epoch: 6| Step: 13
Training loss: 2.1208376791359296
Validation loss: 2.51169061706411

Epoch: 141| Step: 0
Training loss: 2.2558629684089344
Validation loss: 2.4945605445818075

Epoch: 6| Step: 1
Training loss: 2.5885691548556733
Validation loss: 2.4963780551157138

Epoch: 6| Step: 2
Training loss: 2.5976899338452855
Validation loss: 2.494634208477425

Epoch: 6| Step: 3
Training loss: 2.164425375360715
Validation loss: 2.4911342095831257

Epoch: 6| Step: 4
Training loss: 2.1604970487271196
Validation loss: 2.5034845028438095

Epoch: 6| Step: 5
Training loss: 2.8396838955180987
Validation loss: 2.4893386713048904

Epoch: 6| Step: 6
Training loss: 2.648585132546376
Validation loss: 2.489498787963813

Epoch: 6| Step: 7
Training loss: 3.086764376956501
Validation loss: 2.4892847581744157

Epoch: 6| Step: 8
Training loss: 3.0021777196196537
Validation loss: 2.5003828170917988

Epoch: 6| Step: 9
Training loss: 2.4016284901295726
Validation loss: 2.4768262418450466

Epoch: 6| Step: 10
Training loss: 3.254410172329724
Validation loss: 2.468315743649028

Epoch: 6| Step: 11
Training loss: 2.9921664643108485
Validation loss: 2.511697085125773

Epoch: 6| Step: 12
Training loss: 2.6064411047525984
Validation loss: 2.487494312844031

Epoch: 6| Step: 13
Training loss: 3.2115445270946688
Validation loss: 2.4798108101072462

Epoch: 142| Step: 0
Training loss: 2.2362865460790835
Validation loss: 2.5035573240682507

Epoch: 6| Step: 1
Training loss: 2.5932803360721994
Validation loss: 2.49341211774018

Epoch: 6| Step: 2
Training loss: 2.555765187147187
Validation loss: 2.502325200041663

Epoch: 6| Step: 3
Training loss: 3.479084463157258
Validation loss: 2.480593464049443

Epoch: 6| Step: 4
Training loss: 2.3476471099421703
Validation loss: 2.4734534447348664

Epoch: 6| Step: 5
Training loss: 2.1795748336277194
Validation loss: 2.4878985549402395

Epoch: 6| Step: 6
Training loss: 2.257326489578811
Validation loss: 2.5060565842655196

Epoch: 6| Step: 7
Training loss: 2.275473715120512
Validation loss: 2.483684586006044

Epoch: 6| Step: 8
Training loss: 3.1910878352954812
Validation loss: 2.505149602356148

Epoch: 6| Step: 9
Training loss: 2.904240067009146
Validation loss: 2.4848983707651837

Epoch: 6| Step: 10
Training loss: 3.1736829894700205
Validation loss: 2.5057043666183008

Epoch: 6| Step: 11
Training loss: 2.6320027993833732
Validation loss: 2.4667718942070533

Epoch: 6| Step: 12
Training loss: 3.141332594077515
Validation loss: 2.479046075593349

Epoch: 6| Step: 13
Training loss: 2.143982085629961
Validation loss: 2.5046376415366463

Epoch: 143| Step: 0
Training loss: 2.8481848373974885
Validation loss: 2.47492177099432

Epoch: 6| Step: 1
Training loss: 3.0764815692321634
Validation loss: 2.4915918623443574

Epoch: 6| Step: 2
Training loss: 2.398305883120164
Validation loss: 2.4848937818112815

Epoch: 6| Step: 3
Training loss: 2.5020003898736176
Validation loss: 2.4851158504321127

Epoch: 6| Step: 4
Training loss: 2.7908007763975666
Validation loss: 2.5027685340741996

Epoch: 6| Step: 5
Training loss: 2.5138924834598626
Validation loss: 2.4659161682568986

Epoch: 6| Step: 6
Training loss: 2.8358446846898357
Validation loss: 2.4914318009692074

Epoch: 6| Step: 7
Training loss: 2.700973448288482
Validation loss: 2.4716880359558018

Epoch: 6| Step: 8
Training loss: 2.488233341252878
Validation loss: 2.4871246400144593

Epoch: 6| Step: 9
Training loss: 3.0560015805624823
Validation loss: 2.4862930262765794

Epoch: 6| Step: 10
Training loss: 2.9086521844683326
Validation loss: 2.471333423188019

Epoch: 6| Step: 11
Training loss: 2.4920492582336022
Validation loss: 2.4839886425353397

Epoch: 6| Step: 12
Training loss: 2.8271765198572893
Validation loss: 2.4850048242763423

Epoch: 6| Step: 13
Training loss: 1.803831021081342
Validation loss: 2.483090048341125

Epoch: 144| Step: 0
Training loss: 2.8010292954252667
Validation loss: 2.476863812863984

Epoch: 6| Step: 1
Training loss: 3.6183162765300043
Validation loss: 2.4990924049130645

Epoch: 6| Step: 2
Training loss: 2.8341006380678824
Validation loss: 2.4815663885762436

Epoch: 6| Step: 3
Training loss: 2.4920304108382147
Validation loss: 2.490920219454639

Epoch: 6| Step: 4
Training loss: 2.8169383314896206
Validation loss: 2.5015533277183017

Epoch: 6| Step: 5
Training loss: 2.390778081642636
Validation loss: 2.494800474528236

Epoch: 6| Step: 6
Training loss: 2.54330756161466
Validation loss: 2.4844168589006475

Epoch: 6| Step: 7
Training loss: 2.505351252190117
Validation loss: 2.4842405927152096

Epoch: 6| Step: 8
Training loss: 2.644390603950136
Validation loss: 2.4838054208120104

Epoch: 6| Step: 9
Training loss: 2.6658911372034533
Validation loss: 2.5096526769031096

Epoch: 6| Step: 10
Training loss: 2.0061778973608932
Validation loss: 2.5020950153037105

Epoch: 6| Step: 11
Training loss: 2.709525760385276
Validation loss: 2.498464964212303

Epoch: 6| Step: 12
Training loss: 2.686730740479659
Validation loss: 2.4997256282250397

Epoch: 6| Step: 13
Training loss: 2.9460255698177535
Validation loss: 2.510297862748604

Epoch: 145| Step: 0
Training loss: 2.4241719828110573
Validation loss: 2.4998246172432155

Epoch: 6| Step: 1
Training loss: 2.228767668289781
Validation loss: 2.5063120037292896

Epoch: 6| Step: 2
Training loss: 2.111953628580055
Validation loss: 2.480400622853958

Epoch: 6| Step: 3
Training loss: 2.829944678530823
Validation loss: 2.4767699416946427

Epoch: 6| Step: 4
Training loss: 2.886960237594579
Validation loss: 2.486610304237612

Epoch: 6| Step: 5
Training loss: 2.5683695861845495
Validation loss: 2.482472034617335

Epoch: 6| Step: 6
Training loss: 2.6617741307217893
Validation loss: 2.4788929874469527

Epoch: 6| Step: 7
Training loss: 2.4965942072147103
Validation loss: 2.4642910470027775

Epoch: 6| Step: 8
Training loss: 3.7002722459589195
Validation loss: 2.4783034101794765

Epoch: 6| Step: 9
Training loss: 2.9907659834234
Validation loss: 2.47152407475633

Epoch: 6| Step: 10
Training loss: 2.8160510216122225
Validation loss: 2.504257648720697

Epoch: 6| Step: 11
Training loss: 2.258224080200839
Validation loss: 2.484451677662837

Epoch: 6| Step: 12
Training loss: 2.6722761600344156
Validation loss: 2.4735644348929995

Epoch: 6| Step: 13
Training loss: 2.755551370323585
Validation loss: 2.5058866639127984

Epoch: 146| Step: 0
Training loss: 2.002129732111004
Validation loss: 2.4754064585609448

Epoch: 6| Step: 1
Training loss: 3.1420022402439107
Validation loss: 2.4867062575750927

Epoch: 6| Step: 2
Training loss: 2.792769247545855
Validation loss: 2.505625325123992

Epoch: 6| Step: 3
Training loss: 3.130607456821448
Validation loss: 2.490726963250997

Epoch: 6| Step: 4
Training loss: 2.377788312340016
Validation loss: 2.4847333673732064

Epoch: 6| Step: 5
Training loss: 3.397104286800803
Validation loss: 2.4788288266459437

Epoch: 6| Step: 6
Training loss: 1.963936203664365
Validation loss: 2.4891777276242553

Epoch: 6| Step: 7
Training loss: 2.7778503556836496
Validation loss: 2.5008430843668417

Epoch: 6| Step: 8
Training loss: 2.4144386566326026
Validation loss: 2.469995523254156

Epoch: 6| Step: 9
Training loss: 2.2998513381016967
Validation loss: 2.480710649504028

Epoch: 6| Step: 10
Training loss: 2.619692477604113
Validation loss: 2.5013880014475394

Epoch: 6| Step: 11
Training loss: 3.048146456966941
Validation loss: 2.47960585549656

Epoch: 6| Step: 12
Training loss: 1.814581695042019
Validation loss: 2.4951997448426044

Epoch: 6| Step: 13
Training loss: 3.486592224546914
Validation loss: 2.5038020724838255

Epoch: 147| Step: 0
Training loss: 2.8413531923833735
Validation loss: 2.514846185924757

Epoch: 6| Step: 1
Training loss: 2.493737769993213
Validation loss: 2.479666146597922

Epoch: 6| Step: 2
Training loss: 2.896588746117706
Validation loss: 2.506956338496789

Epoch: 6| Step: 3
Training loss: 3.0982588462090757
Validation loss: 2.497257969541724

Epoch: 6| Step: 4
Training loss: 2.573103760211669
Validation loss: 2.510715917303219

Epoch: 6| Step: 5
Training loss: 2.6522561959154647
Validation loss: 2.5094063945899645

Epoch: 6| Step: 6
Training loss: 2.3614898701970874
Validation loss: 2.4801141388681174

Epoch: 6| Step: 7
Training loss: 1.9133576632934355
Validation loss: 2.480709010483616

Epoch: 6| Step: 8
Training loss: 2.2430224841041557
Validation loss: 2.514533722687484

Epoch: 6| Step: 9
Training loss: 3.461994638298903
Validation loss: 2.5239057544245274

Epoch: 6| Step: 10
Training loss: 2.111913552227292
Validation loss: 2.500117432492153

Epoch: 6| Step: 11
Training loss: 3.05663454097837
Validation loss: 2.4995538405722444

Epoch: 6| Step: 12
Training loss: 3.054341406374994
Validation loss: 2.525490541831197

Epoch: 6| Step: 13
Training loss: 2.627968880351552
Validation loss: 2.5214204505352593

Epoch: 148| Step: 0
Training loss: 2.762814489216558
Validation loss: 2.5013843231245443

Epoch: 6| Step: 1
Training loss: 2.0540435129922106
Validation loss: 2.4996878152170536

Epoch: 6| Step: 2
Training loss: 2.1293078122569264
Validation loss: 2.4706215950674153

Epoch: 6| Step: 3
Training loss: 2.881259075820762
Validation loss: 2.493627402216015

Epoch: 6| Step: 4
Training loss: 2.69076304508043
Validation loss: 2.519219617179645

Epoch: 6| Step: 5
Training loss: 2.712865314406767
Validation loss: 2.4926644017249244

Epoch: 6| Step: 6
Training loss: 3.157553224333986
Validation loss: 2.496891561625719

Epoch: 6| Step: 7
Training loss: 2.5035051569107485
Validation loss: 2.463389980843693

Epoch: 6| Step: 8
Training loss: 2.253668020474353
Validation loss: 2.499037756370699

Epoch: 6| Step: 9
Training loss: 3.1622058837187357
Validation loss: 2.5048848737421827

Epoch: 6| Step: 10
Training loss: 2.6506901616040883
Validation loss: 2.467362376958846

Epoch: 6| Step: 11
Training loss: 3.2166972605250157
Validation loss: 2.4722952132745117

Epoch: 6| Step: 12
Training loss: 2.2583430633710684
Validation loss: 2.4756184106670904

Epoch: 6| Step: 13
Training loss: 3.0640118039852484
Validation loss: 2.494096104672332

Epoch: 149| Step: 0
Training loss: 3.1752342137733547
Validation loss: 2.5005988634305405

Epoch: 6| Step: 1
Training loss: 2.8288411450841657
Validation loss: 2.472337849082136

Epoch: 6| Step: 2
Training loss: 2.572910468419649
Validation loss: 2.4985954882132457

Epoch: 6| Step: 3
Training loss: 2.739896246344898
Validation loss: 2.4991996837726846

Epoch: 6| Step: 4
Training loss: 2.6151766667398397
Validation loss: 2.4776648428303214

Epoch: 6| Step: 5
Training loss: 2.8549856045922892
Validation loss: 2.501887340211862

Epoch: 6| Step: 6
Training loss: 2.4951404070287015
Validation loss: 2.4970731563448374

Epoch: 6| Step: 7
Training loss: 2.202683641309811
Validation loss: 2.4686064392193527

Epoch: 6| Step: 8
Training loss: 2.7692544688531133
Validation loss: 2.4752249241683186

Epoch: 6| Step: 9
Training loss: 2.4575091990301625
Validation loss: 2.4744882164899895

Epoch: 6| Step: 10
Training loss: 3.1573508580640777
Validation loss: 2.5017611791235352

Epoch: 6| Step: 11
Training loss: 2.5480512465469167
Validation loss: 2.498726660996661

Epoch: 6| Step: 12
Training loss: 2.5272431862116904
Validation loss: 2.465687698961789

Epoch: 6| Step: 13
Training loss: 2.0168254737222746
Validation loss: 2.5120281348599285

Epoch: 150| Step: 0
Training loss: 2.909366372461362
Validation loss: 2.5122173395416443

Epoch: 6| Step: 1
Training loss: 2.560880474877753
Validation loss: 2.4963744289735756

Epoch: 6| Step: 2
Training loss: 2.426540090208115
Validation loss: 2.4748648215350966

Epoch: 6| Step: 3
Training loss: 3.452973099211309
Validation loss: 2.500685769028858

Epoch: 6| Step: 4
Training loss: 2.4757000597770773
Validation loss: 2.4863371986199296

Epoch: 6| Step: 5
Training loss: 2.5576138316129184
Validation loss: 2.4633663043706138

Epoch: 6| Step: 6
Training loss: 1.9816849264272018
Validation loss: 2.4886136999623774

Epoch: 6| Step: 7
Training loss: 2.4451402109894853
Validation loss: 2.483018407352353

Epoch: 6| Step: 8
Training loss: 2.944635207116617
Validation loss: 2.5016964919308955

Epoch: 6| Step: 9
Training loss: 2.865546897897128
Validation loss: 2.482045720442475

Epoch: 6| Step: 10
Training loss: 3.074704666221597
Validation loss: 2.503054841278791

Epoch: 6| Step: 11
Training loss: 2.6246865403257282
Validation loss: 2.4816767824280666

Epoch: 6| Step: 12
Training loss: 2.525043555157878
Validation loss: 2.4906570961776615

Epoch: 6| Step: 13
Training loss: 2.4263061348711803
Validation loss: 2.5027241067901658

Epoch: 151| Step: 0
Training loss: 2.808761485559725
Validation loss: 2.4934108366454786

Epoch: 6| Step: 1
Training loss: 2.5631042326332594
Validation loss: 2.4842632998921634

Epoch: 6| Step: 2
Training loss: 3.158887761821345
Validation loss: 2.4839583326312447

Epoch: 6| Step: 3
Training loss: 2.598490874934511
Validation loss: 2.494949896527995

Epoch: 6| Step: 4
Training loss: 1.817168307674539
Validation loss: 2.5071401153743382

Epoch: 6| Step: 5
Training loss: 3.222975244628825
Validation loss: 2.4904501225507683

Epoch: 6| Step: 6
Training loss: 2.7192059715517427
Validation loss: 2.502821507345286

Epoch: 6| Step: 7
Training loss: 2.920879990172857
Validation loss: 2.4844045690808536

Epoch: 6| Step: 8
Training loss: 2.672658437344956
Validation loss: 2.5086387070913783

Epoch: 6| Step: 9
Training loss: 2.2712383317411478
Validation loss: 2.5018192501456236

Epoch: 6| Step: 10
Training loss: 3.0989438011192
Validation loss: 2.4878552748769507

Epoch: 6| Step: 11
Training loss: 2.6512081091492607
Validation loss: 2.497229623392531

Epoch: 6| Step: 12
Training loss: 2.440549556723744
Validation loss: 2.5011897486280774

Epoch: 6| Step: 13
Training loss: 2.2568707993710473
Validation loss: 2.483778571549289

Epoch: 152| Step: 0
Training loss: 3.007766525115354
Validation loss: 2.509791094107805

Epoch: 6| Step: 1
Training loss: 2.798542229052134
Validation loss: 2.485876449904013

Epoch: 6| Step: 2
Training loss: 2.991598285400046
Validation loss: 2.514210957759684

Epoch: 6| Step: 3
Training loss: 2.790474328632995
Validation loss: 2.4777302722765957

Epoch: 6| Step: 4
Training loss: 2.8248612766470154
Validation loss: 2.5210413649073713

Epoch: 6| Step: 5
Training loss: 2.3957162137360535
Validation loss: 2.5051357738121403

Epoch: 6| Step: 6
Training loss: 2.253456216241635
Validation loss: 2.5169545062077687

Epoch: 6| Step: 7
Training loss: 2.7355779127217423
Validation loss: 2.4989076853245193

Epoch: 6| Step: 8
Training loss: 2.3596587357847394
Validation loss: 2.47362194285034

Epoch: 6| Step: 9
Training loss: 2.977915538935121
Validation loss: 2.532637438321789

Epoch: 6| Step: 10
Training loss: 3.2095850859971558
Validation loss: 2.5063310475195073

Epoch: 6| Step: 11
Training loss: 2.2076246695993706
Validation loss: 2.484249098127289

Epoch: 6| Step: 12
Training loss: 2.2236702320701407
Validation loss: 2.4936002269122364

Epoch: 6| Step: 13
Training loss: 2.399439698619153
Validation loss: 2.5026043155445565

Epoch: 153| Step: 0
Training loss: 2.4118561275838104
Validation loss: 2.495228987356097

Epoch: 6| Step: 1
Training loss: 2.9091828017459833
Validation loss: 2.5185621212238036

Epoch: 6| Step: 2
Training loss: 3.2073666656206266
Validation loss: 2.4847404039448593

Epoch: 6| Step: 3
Training loss: 2.4950606188548314
Validation loss: 2.492893942448663

Epoch: 6| Step: 4
Training loss: 2.8138385554392884
Validation loss: 2.489163430822831

Epoch: 6| Step: 5
Training loss: 3.1701670591215314
Validation loss: 2.501755392441924

Epoch: 6| Step: 6
Training loss: 2.3447416115198023
Validation loss: 2.49018097130369

Epoch: 6| Step: 7
Training loss: 2.219254986959262
Validation loss: 2.5080613817920057

Epoch: 6| Step: 8
Training loss: 2.33140159298143
Validation loss: 2.4804249031054986

Epoch: 6| Step: 9
Training loss: 2.7044660295753307
Validation loss: 2.5008838465306455

Epoch: 6| Step: 10
Training loss: 2.685852787974321
Validation loss: 2.511581704733977

Epoch: 6| Step: 11
Training loss: 2.800171342784258
Validation loss: 2.508688936246607

Epoch: 6| Step: 12
Training loss: 2.8709633726243675
Validation loss: 2.4844182199609137

Epoch: 6| Step: 13
Training loss: 2.1738280153231666
Validation loss: 2.4713940908896066

Epoch: 154| Step: 0
Training loss: 2.774611877242642
Validation loss: 2.5051386371549076

Epoch: 6| Step: 1
Training loss: 2.682965023124159
Validation loss: 2.4816934399423745

Epoch: 6| Step: 2
Training loss: 2.5442395763110595
Validation loss: 2.4600853354286714

Epoch: 6| Step: 3
Training loss: 3.089554687559266
Validation loss: 2.5181014219910174

Epoch: 6| Step: 4
Training loss: 2.497204170920882
Validation loss: 2.4906654036677183

Epoch: 6| Step: 5
Training loss: 2.642432141835726
Validation loss: 2.49766420333495

Epoch: 6| Step: 6
Training loss: 2.599078851528911
Validation loss: 2.504610197762681

Epoch: 6| Step: 7
Training loss: 3.0472490130019256
Validation loss: 2.4970775103984737

Epoch: 6| Step: 8
Training loss: 1.6209073982216315
Validation loss: 2.4973020613722094

Epoch: 6| Step: 9
Training loss: 2.5634462423802145
Validation loss: 2.5184243428558166

Epoch: 6| Step: 10
Training loss: 2.9767627398403382
Validation loss: 2.5134951339906277

Epoch: 6| Step: 11
Training loss: 2.8417519057868104
Validation loss: 2.5033956252805836

Epoch: 6| Step: 12
Training loss: 2.460796824476279
Validation loss: 2.4893070032751914

Epoch: 6| Step: 13
Training loss: 3.1991147128039517
Validation loss: 2.5010919073239153

Epoch: 155| Step: 0
Training loss: 1.969378900745031
Validation loss: 2.471009028408528

Epoch: 6| Step: 1
Training loss: 3.0124718185942765
Validation loss: 2.4710018977476085

Epoch: 6| Step: 2
Training loss: 3.2762293597593293
Validation loss: 2.489148692100787

Epoch: 6| Step: 3
Training loss: 2.2082495643514237
Validation loss: 2.4932796165714626

Epoch: 6| Step: 4
Training loss: 3.0432157012277683
Validation loss: 2.4869705400197577

Epoch: 6| Step: 5
Training loss: 2.322205256390489
Validation loss: 2.469558823204008

Epoch: 6| Step: 6
Training loss: 2.5697664649035845
Validation loss: 2.4926894727105937

Epoch: 6| Step: 7
Training loss: 3.39441353228351
Validation loss: 2.489899625048637

Epoch: 6| Step: 8
Training loss: 2.803989844299732
Validation loss: 2.500298732424149

Epoch: 6| Step: 9
Training loss: 2.5482862810074347
Validation loss: 2.480262138605613

Epoch: 6| Step: 10
Training loss: 1.95341989961176
Validation loss: 2.4682873580174007

Epoch: 6| Step: 11
Training loss: 2.5423946171979055
Validation loss: 2.485327524303075

Epoch: 6| Step: 12
Training loss: 2.9417045208996178
Validation loss: 2.48775672158812

Epoch: 6| Step: 13
Training loss: 2.6479646603856644
Validation loss: 2.4986606435172702

Epoch: 156| Step: 0
Training loss: 2.2819935880097852
Validation loss: 2.4820255710535637

Epoch: 6| Step: 1
Training loss: 2.3964021974882397
Validation loss: 2.47636618637886

Epoch: 6| Step: 2
Training loss: 2.7325871317409356
Validation loss: 2.4893624091898094

Epoch: 6| Step: 3
Training loss: 3.089118959319019
Validation loss: 2.4920442328926744

Epoch: 6| Step: 4
Training loss: 2.3669207834993817
Validation loss: 2.4835137698183685

Epoch: 6| Step: 5
Training loss: 3.520965182452113
Validation loss: 2.5086866972527417

Epoch: 6| Step: 6
Training loss: 2.5209309792851005
Validation loss: 2.4815908361417316

Epoch: 6| Step: 7
Training loss: 2.5250375121701083
Validation loss: 2.5005191233236777

Epoch: 6| Step: 8
Training loss: 2.582887539289873
Validation loss: 2.48988561090504

Epoch: 6| Step: 9
Training loss: 2.9286182944771233
Validation loss: 2.501632836051014

Epoch: 6| Step: 10
Training loss: 2.3567366848714446
Validation loss: 2.5095055462421363

Epoch: 6| Step: 11
Training loss: 2.818293221081276
Validation loss: 2.5045466742828206

Epoch: 6| Step: 12
Training loss: 2.130011875137394
Validation loss: 2.4706357952676177

Epoch: 6| Step: 13
Training loss: 2.986262977543157
Validation loss: 2.4922563994211715

Epoch: 157| Step: 0
Training loss: 3.1149713961296746
Validation loss: 2.482267943676724

Epoch: 6| Step: 1
Training loss: 2.0059252229485116
Validation loss: 2.5054901914816363

Epoch: 6| Step: 2
Training loss: 2.9552946647984415
Validation loss: 2.4831636085770286

Epoch: 6| Step: 3
Training loss: 2.6556944322206726
Validation loss: 2.5127964467712824

Epoch: 6| Step: 4
Training loss: 2.404746440440251
Validation loss: 2.478057977590193

Epoch: 6| Step: 5
Training loss: 2.534652307205154
Validation loss: 2.4785502360160123

Epoch: 6| Step: 6
Training loss: 2.3560238717040427
Validation loss: 2.491363585159687

Epoch: 6| Step: 7
Training loss: 2.6669793144370755
Validation loss: 2.5126862218317965

Epoch: 6| Step: 8
Training loss: 3.0125340250080255
Validation loss: 2.494301162116778

Epoch: 6| Step: 9
Training loss: 1.749663048048899
Validation loss: 2.486610359910426

Epoch: 6| Step: 10
Training loss: 2.5842547978004866
Validation loss: 2.4939604871543595

Epoch: 6| Step: 11
Training loss: 2.6496296677845015
Validation loss: 2.519062945695586

Epoch: 6| Step: 12
Training loss: 3.2386107789022254
Validation loss: 2.507407026991046

Epoch: 6| Step: 13
Training loss: 3.631623629390424
Validation loss: 2.5028291547590897

Epoch: 158| Step: 0
Training loss: 2.88219645877965
Validation loss: 2.4833499741339105

Epoch: 6| Step: 1
Training loss: 2.948779910955858
Validation loss: 2.496716434899418

Epoch: 6| Step: 2
Training loss: 3.6694521438424164
Validation loss: 2.483370761075874

Epoch: 6| Step: 3
Training loss: 1.7517655866562916
Validation loss: 2.488168080843164

Epoch: 6| Step: 4
Training loss: 3.095188615564158
Validation loss: 2.479560434208457

Epoch: 6| Step: 5
Training loss: 2.4769071224881682
Validation loss: 2.4946127138076415

Epoch: 6| Step: 6
Training loss: 2.730923987164314
Validation loss: 2.4760098415045113

Epoch: 6| Step: 7
Training loss: 2.8772527741947402
Validation loss: 2.479418426315926

Epoch: 6| Step: 8
Training loss: 2.9264159793703226
Validation loss: 2.494773927537715

Epoch: 6| Step: 9
Training loss: 2.3996443802896024
Validation loss: 2.476228731287089

Epoch: 6| Step: 10
Training loss: 2.3757659279386614
Validation loss: 2.4863264628742154

Epoch: 6| Step: 11
Training loss: 2.055207161404378
Validation loss: 2.487246234308946

Epoch: 6| Step: 12
Training loss: 2.385635854542968
Validation loss: 2.52172723303097

Epoch: 6| Step: 13
Training loss: 1.7401805317059684
Validation loss: 2.5163413069798346

Epoch: 159| Step: 0
Training loss: 2.700593678231656
Validation loss: 2.4997028543403244

Epoch: 6| Step: 1
Training loss: 2.8162985687199127
Validation loss: 2.4769273435300456

Epoch: 6| Step: 2
Training loss: 2.781221625365486
Validation loss: 2.4967485346674287

Epoch: 6| Step: 3
Training loss: 2.2832490705920314
Validation loss: 2.505154367061392

Epoch: 6| Step: 4
Training loss: 2.9391306145748697
Validation loss: 2.489835684040843

Epoch: 6| Step: 5
Training loss: 3.325649146480037
Validation loss: 2.5063886556894355

Epoch: 6| Step: 6
Training loss: 2.7505983221957213
Validation loss: 2.4933068591186314

Epoch: 6| Step: 7
Training loss: 2.28104441513308
Validation loss: 2.508430319751317

Epoch: 6| Step: 8
Training loss: 2.979965867480716
Validation loss: 2.4623782387282067

Epoch: 6| Step: 9
Training loss: 2.575980757072794
Validation loss: 2.4927311323415253

Epoch: 6| Step: 10
Training loss: 2.192417938019006
Validation loss: 2.492425142496418

Epoch: 6| Step: 11
Training loss: 2.5276395692408733
Validation loss: 2.5031202952995812

Epoch: 6| Step: 12
Training loss: 2.5856118357293068
Validation loss: 2.503799573144927

Epoch: 6| Step: 13
Training loss: 2.373601602151225
Validation loss: 2.5154341106361686

Epoch: 160| Step: 0
Training loss: 3.4285764523878077
Validation loss: 2.502541722537712

Epoch: 6| Step: 1
Training loss: 2.9199009719151463
Validation loss: 2.504103694984842

Epoch: 6| Step: 2
Training loss: 2.9716692575502965
Validation loss: 2.4791939591639034

Epoch: 6| Step: 3
Training loss: 2.5312004555457053
Validation loss: 2.485336613954136

Epoch: 6| Step: 4
Training loss: 1.7774208806667118
Validation loss: 2.5130457984891

Epoch: 6| Step: 5
Training loss: 2.6153822409071004
Validation loss: 2.4947432471924498

Epoch: 6| Step: 6
Training loss: 3.5932277134062383
Validation loss: 2.4707247259916

Epoch: 6| Step: 7
Training loss: 2.1795490179883465
Validation loss: 2.473925693644226

Epoch: 6| Step: 8
Training loss: 2.4327116664210164
Validation loss: 2.4841461850198714

Epoch: 6| Step: 9
Training loss: 2.77913319473661
Validation loss: 2.495428948593358

Epoch: 6| Step: 10
Training loss: 1.919433159004498
Validation loss: 2.485400349917644

Epoch: 6| Step: 11
Training loss: 2.106271452752048
Validation loss: 2.5157615498703745

Epoch: 6| Step: 12
Training loss: 2.688843945538352
Validation loss: 2.493592801021076

Epoch: 6| Step: 13
Training loss: 3.126795901194552
Validation loss: 2.467815237258873

Epoch: 161| Step: 0
Training loss: 2.875032839380213
Validation loss: 2.4688766735678978

Epoch: 6| Step: 1
Training loss: 2.079019454402644
Validation loss: 2.4900823345253738

Epoch: 6| Step: 2
Training loss: 2.604231464851382
Validation loss: 2.489006790938351

Epoch: 6| Step: 3
Training loss: 2.676228328583237
Validation loss: 2.481782236811093

Epoch: 6| Step: 4
Training loss: 2.8047138521024375
Validation loss: 2.492542639765981

Epoch: 6| Step: 5
Training loss: 2.6217213091174782
Validation loss: 2.5258710226140653

Epoch: 6| Step: 6
Training loss: 2.7843163549410277
Validation loss: 2.5126288427340855

Epoch: 6| Step: 7
Training loss: 2.7081602090131014
Validation loss: 2.513243397599381

Epoch: 6| Step: 8
Training loss: 2.633450575121946
Validation loss: 2.485953060630558

Epoch: 6| Step: 9
Training loss: 2.830337249287114
Validation loss: 2.5188741508984416

Epoch: 6| Step: 10
Training loss: 2.8009871615980777
Validation loss: 2.5104186777515207

Epoch: 6| Step: 11
Training loss: 3.036663609017076
Validation loss: 2.4952682410542586

Epoch: 6| Step: 12
Training loss: 2.767411511668359
Validation loss: 2.484429420560848

Epoch: 6| Step: 13
Training loss: 1.9558183333942258
Validation loss: 2.4982346772629236

Epoch: 162| Step: 0
Training loss: 2.75996984548267
Validation loss: 2.5030688718202154

Epoch: 6| Step: 1
Training loss: 2.591847744796799
Validation loss: 2.486748004038791

Epoch: 6| Step: 2
Training loss: 2.838984594289185
Validation loss: 2.5055569140656875

Epoch: 6| Step: 3
Training loss: 2.2663850758985906
Validation loss: 2.5276389951792932

Epoch: 6| Step: 4
Training loss: 2.624246943402716
Validation loss: 2.488760000383401

Epoch: 6| Step: 5
Training loss: 2.80972398875314
Validation loss: 2.46318032314839

Epoch: 6| Step: 6
Training loss: 2.893725243085581
Validation loss: 2.4782993412310677

Epoch: 6| Step: 7
Training loss: 2.297561750443463
Validation loss: 2.4953951202885807

Epoch: 6| Step: 8
Training loss: 2.2925523838061186
Validation loss: 2.47646922662452

Epoch: 6| Step: 9
Training loss: 2.613756532884385
Validation loss: 2.4965454865695644

Epoch: 6| Step: 10
Training loss: 2.825003571634651
Validation loss: 2.478777037815475

Epoch: 6| Step: 11
Training loss: 2.754599539422947
Validation loss: 2.49124827202833

Epoch: 6| Step: 12
Training loss: 2.650416352295453
Validation loss: 2.4679766921384436

Epoch: 6| Step: 13
Training loss: 3.5671254965113475
Validation loss: 2.5037194803502123

Epoch: 163| Step: 0
Training loss: 2.4907583126828037
Validation loss: 2.476073702620483

Epoch: 6| Step: 1
Training loss: 2.815137262470353
Validation loss: 2.466866602051956

Epoch: 6| Step: 2
Training loss: 2.7294526180886285
Validation loss: 2.503624749410013

Epoch: 6| Step: 3
Training loss: 2.652146164918203
Validation loss: 2.464959298367563

Epoch: 6| Step: 4
Training loss: 1.7348845137271989
Validation loss: 2.487493609966782

Epoch: 6| Step: 5
Training loss: 2.30658884014558
Validation loss: 2.48044327127001

Epoch: 6| Step: 6
Training loss: 2.1028054117827923
Validation loss: 2.487407239578911

Epoch: 6| Step: 7
Training loss: 2.317461825059457
Validation loss: 2.4709173979008616

Epoch: 6| Step: 8
Training loss: 3.050812822439862
Validation loss: 2.454242222763924

Epoch: 6| Step: 9
Training loss: 3.181550101344199
Validation loss: 2.493409217283257

Epoch: 6| Step: 10
Training loss: 2.8145502035326295
Validation loss: 2.4850332954278924

Epoch: 6| Step: 11
Training loss: 3.5261834180428937
Validation loss: 2.480415897776864

Epoch: 6| Step: 12
Training loss: 2.3174937173867276
Validation loss: 2.504699407352218

Epoch: 6| Step: 13
Training loss: 3.001850193420757
Validation loss: 2.5146684988009933

Epoch: 164| Step: 0
Training loss: 2.5635822150846916
Validation loss: 2.510482155788959

Epoch: 6| Step: 1
Training loss: 3.204625071527098
Validation loss: 2.4718505840745477

Epoch: 6| Step: 2
Training loss: 2.3358142016477124
Validation loss: 2.4900792278849484

Epoch: 6| Step: 3
Training loss: 2.5252665690599896
Validation loss: 2.5235065753117643

Epoch: 6| Step: 4
Training loss: 2.62664888456622
Validation loss: 2.47871028732041

Epoch: 6| Step: 5
Training loss: 3.164726884577449
Validation loss: 2.500098408023519

Epoch: 6| Step: 6
Training loss: 2.76574155055437
Validation loss: 2.5055609382371062

Epoch: 6| Step: 7
Training loss: 2.27993799392978
Validation loss: 2.487258301884457

Epoch: 6| Step: 8
Training loss: 2.2117307069078618
Validation loss: 2.4998878597416905

Epoch: 6| Step: 9
Training loss: 2.8998437642072243
Validation loss: 2.4825779756767843

Epoch: 6| Step: 10
Training loss: 2.233496860191951
Validation loss: 2.4786123695518714

Epoch: 6| Step: 11
Training loss: 2.996712791022837
Validation loss: 2.4960098099712322

Epoch: 6| Step: 12
Training loss: 2.4343206749707584
Validation loss: 2.487515510374273

Epoch: 6| Step: 13
Training loss: 2.440146843134312
Validation loss: 2.4949365992020973

Epoch: 165| Step: 0
Training loss: 2.9002171731068835
Validation loss: 2.477798324889839

Epoch: 6| Step: 1
Training loss: 2.2849054182582136
Validation loss: 2.492338012631189

Epoch: 6| Step: 2
Training loss: 3.083830990881677
Validation loss: 2.5095589738897384

Epoch: 6| Step: 3
Training loss: 2.885280968588708
Validation loss: 2.495223456764354

Epoch: 6| Step: 4
Training loss: 2.8651007352631717
Validation loss: 2.4918303713260705

Epoch: 6| Step: 5
Training loss: 1.8778856324866942
Validation loss: 2.5058556612950347

Epoch: 6| Step: 6
Training loss: 2.614068840643928
Validation loss: 2.477104303981931

Epoch: 6| Step: 7
Training loss: 2.76066187123399
Validation loss: 2.4970674963717583

Epoch: 6| Step: 8
Training loss: 1.9349513364680548
Validation loss: 2.4950624693569945

Epoch: 6| Step: 9
Training loss: 2.2846639510443674
Validation loss: 2.499297719164806

Epoch: 6| Step: 10
Training loss: 2.5692081571881555
Validation loss: 2.4926030123818133

Epoch: 6| Step: 11
Training loss: 2.7286212657665425
Validation loss: 2.51734616473302

Epoch: 6| Step: 12
Training loss: 2.8019862010433605
Validation loss: 2.514495022079545

Epoch: 6| Step: 13
Training loss: 3.432018834540342
Validation loss: 2.4880719798676663

Epoch: 166| Step: 0
Training loss: 2.626800464604643
Validation loss: 2.513481953135669

Epoch: 6| Step: 1
Training loss: 2.5542127068888507
Validation loss: 2.4843437908490524

Epoch: 6| Step: 2
Training loss: 1.93032048148873
Validation loss: 2.4899929868231427

Epoch: 6| Step: 3
Training loss: 3.086483214208656
Validation loss: 2.474064164718051

Epoch: 6| Step: 4
Training loss: 2.370812991769566
Validation loss: 2.4925286785382412

Epoch: 6| Step: 5
Training loss: 2.754304637906111
Validation loss: 2.4921476438291945

Epoch: 6| Step: 6
Training loss: 2.309961420537966
Validation loss: 2.4947178608122824

Epoch: 6| Step: 7
Training loss: 2.542146001757273
Validation loss: 2.5001659768905515

Epoch: 6| Step: 8
Training loss: 3.2631096164389706
Validation loss: 2.4918466039680123

Epoch: 6| Step: 9
Training loss: 3.146030007250178
Validation loss: 2.4941067442734153

Epoch: 6| Step: 10
Training loss: 2.80648295703622
Validation loss: 2.5019096628245543

Epoch: 6| Step: 11
Training loss: 2.579429065460311
Validation loss: 2.516816378052581

Epoch: 6| Step: 12
Training loss: 2.534689179877175
Validation loss: 2.4791940020774823

Epoch: 6| Step: 13
Training loss: 2.3896526278952837
Validation loss: 2.4884987523543054

Epoch: 167| Step: 0
Training loss: 3.027847897789927
Validation loss: 2.509870632077379

Epoch: 6| Step: 1
Training loss: 2.584894159979928
Validation loss: 2.5146559592322784

Epoch: 6| Step: 2
Training loss: 2.351544047438503
Validation loss: 2.509484725496543

Epoch: 6| Step: 3
Training loss: 2.907704471342226
Validation loss: 2.4996480406894

Epoch: 6| Step: 4
Training loss: 3.0378537949218836
Validation loss: 2.5055644896934703

Epoch: 6| Step: 5
Training loss: 2.4483940037878758
Validation loss: 2.509857405119997

Epoch: 6| Step: 6
Training loss: 2.470151672339736
Validation loss: 2.5198849848729

Epoch: 6| Step: 7
Training loss: 2.499598661633159
Validation loss: 2.5287167193108657

Epoch: 6| Step: 8
Training loss: 2.9973721120753543
Validation loss: 2.517327245008998

Epoch: 6| Step: 9
Training loss: 2.439490068337657
Validation loss: 2.512997616131382

Epoch: 6| Step: 10
Training loss: 1.8076955983339567
Validation loss: 2.4911043797441375

Epoch: 6| Step: 11
Training loss: 2.781332807701161
Validation loss: 2.5236169498607595

Epoch: 6| Step: 12
Training loss: 3.302510006331388
Validation loss: 2.509313895078782

Epoch: 6| Step: 13
Training loss: 1.7072022655727652
Validation loss: 2.4975994654595373

Epoch: 168| Step: 0
Training loss: 2.104929669217838
Validation loss: 2.522792429821345

Epoch: 6| Step: 1
Training loss: 2.4184502783098987
Validation loss: 2.4936386986989914

Epoch: 6| Step: 2
Training loss: 2.6687598556586716
Validation loss: 2.500591756660079

Epoch: 6| Step: 3
Training loss: 2.729846190287235
Validation loss: 2.4766089782877145

Epoch: 6| Step: 4
Training loss: 2.706115039164834
Validation loss: 2.4990000006615443

Epoch: 6| Step: 5
Training loss: 2.6328042593354435
Validation loss: 2.4682263168980723

Epoch: 6| Step: 6
Training loss: 2.1308907035391766
Validation loss: 2.505352375735881

Epoch: 6| Step: 7
Training loss: 3.133336962704552
Validation loss: 2.4949804222592715

Epoch: 6| Step: 8
Training loss: 2.5727903718621126
Validation loss: 2.5013037655721333

Epoch: 6| Step: 9
Training loss: 3.2761309702011507
Validation loss: 2.498257344469336

Epoch: 6| Step: 10
Training loss: 3.018880875240294
Validation loss: 2.4873146449783614

Epoch: 6| Step: 11
Training loss: 2.455185334771323
Validation loss: 2.483002804108849

Epoch: 6| Step: 12
Training loss: 2.583380688469118
Validation loss: 2.4934395161472995

Epoch: 6| Step: 13
Training loss: 2.35481721334722
Validation loss: 2.491194851990924

Epoch: 169| Step: 0
Training loss: 2.237487119499086
Validation loss: 2.500522834701898

Epoch: 6| Step: 1
Training loss: 2.746836403151358
Validation loss: 2.4922500876633356

Epoch: 6| Step: 2
Training loss: 2.2838038950439827
Validation loss: 2.49213825086774

Epoch: 6| Step: 3
Training loss: 2.7818248883278165
Validation loss: 2.477907818907677

Epoch: 6| Step: 4
Training loss: 2.146280211301023
Validation loss: 2.4853319082174625

Epoch: 6| Step: 5
Training loss: 2.4712284057476404
Validation loss: 2.4813986510171273

Epoch: 6| Step: 6
Training loss: 2.9520621834488394
Validation loss: 2.4836143133455892

Epoch: 6| Step: 7
Training loss: 3.6342148565957637
Validation loss: 2.4957972856047674

Epoch: 6| Step: 8
Training loss: 2.8078613175111133
Validation loss: 2.472645938003365

Epoch: 6| Step: 9
Training loss: 1.8407029010757512
Validation loss: 2.4617522474907654

Epoch: 6| Step: 10
Training loss: 2.9092703270853963
Validation loss: 2.467789340128582

Epoch: 6| Step: 11
Training loss: 2.3330413317757417
Validation loss: 2.476567388024887

Epoch: 6| Step: 12
Training loss: 3.121157916463368
Validation loss: 2.4825339460768485

Epoch: 6| Step: 13
Training loss: 2.5579804362428042
Validation loss: 2.493724580315961

Epoch: 170| Step: 0
Training loss: 2.6039643984761955
Validation loss: 2.501259021187963

Epoch: 6| Step: 1
Training loss: 3.31989054074297
Validation loss: 2.5032882384640818

Epoch: 6| Step: 2
Training loss: 2.6772591400802632
Validation loss: 2.494529685360733

Epoch: 6| Step: 3
Training loss: 2.865930266017101
Validation loss: 2.494801818620111

Epoch: 6| Step: 4
Training loss: 2.1555302842396844
Validation loss: 2.4826732319223095

Epoch: 6| Step: 5
Training loss: 3.156768151987927
Validation loss: 2.506338087895809

Epoch: 6| Step: 6
Training loss: 2.5838027855695174
Validation loss: 2.5043652102190768

Epoch: 6| Step: 7
Training loss: 2.62011955337901
Validation loss: 2.507075802157508

Epoch: 6| Step: 8
Training loss: 2.527458742523785
Validation loss: 2.48604318720727

Epoch: 6| Step: 9
Training loss: 3.0067901062701505
Validation loss: 2.4988905957489487

Epoch: 6| Step: 10
Training loss: 2.2823199545637767
Validation loss: 2.500300313488267

Epoch: 6| Step: 11
Training loss: 1.9834513880218063
Validation loss: 2.4683588355921002

Epoch: 6| Step: 12
Training loss: 2.4451442087781228
Validation loss: 2.492630461850439

Epoch: 6| Step: 13
Training loss: 1.8540741186583232
Validation loss: 2.531079284388367

Epoch: 171| Step: 0
Training loss: 2.7158331296330958
Validation loss: 2.5085707793272762

Epoch: 6| Step: 1
Training loss: 2.1395089240230156
Validation loss: 2.5034401666053148

Epoch: 6| Step: 2
Training loss: 2.9778505276891902
Validation loss: 2.5001508995373216

Epoch: 6| Step: 3
Training loss: 2.8133403794108496
Validation loss: 2.5160306495077687

Epoch: 6| Step: 4
Training loss: 2.950635395480192
Validation loss: 2.509262855988785

Epoch: 6| Step: 5
Training loss: 2.7209251734922173
Validation loss: 2.517439851322667

Epoch: 6| Step: 6
Training loss: 3.385003699521814
Validation loss: 2.5084225616621225

Epoch: 6| Step: 7
Training loss: 1.861585569240373
Validation loss: 2.5120098338494734

Epoch: 6| Step: 8
Training loss: 1.8943180554174546
Validation loss: 2.490313449981875

Epoch: 6| Step: 9
Training loss: 2.496717777959848
Validation loss: 2.5173001361308587

Epoch: 6| Step: 10
Training loss: 2.418940384343486
Validation loss: 2.517883061852641

Epoch: 6| Step: 11
Training loss: 2.41304503297737
Validation loss: 2.512086556875605

Epoch: 6| Step: 12
Training loss: 3.069263851861907
Validation loss: 2.527648028012996

Epoch: 6| Step: 13
Training loss: 3.002475353079457
Validation loss: 2.514621068317887

Epoch: 172| Step: 0
Training loss: 2.947131336507422
Validation loss: 2.500942795907569

Epoch: 6| Step: 1
Training loss: 2.7224802318797603
Validation loss: 2.492643624405711

Epoch: 6| Step: 2
Training loss: 2.9198562257461105
Validation loss: 2.492910295683342

Epoch: 6| Step: 3
Training loss: 2.8488554346074637
Validation loss: 2.4858184901260727

Epoch: 6| Step: 4
Training loss: 2.798888094699463
Validation loss: 2.5061908669837996

Epoch: 6| Step: 5
Training loss: 3.293371571873542
Validation loss: 2.5075414234627735

Epoch: 6| Step: 6
Training loss: 2.2312272313770127
Validation loss: 2.48050663274547

Epoch: 6| Step: 7
Training loss: 2.515969389093975
Validation loss: 2.4596800357798636

Epoch: 6| Step: 8
Training loss: 2.606110134991529
Validation loss: 2.4783440905036023

Epoch: 6| Step: 9
Training loss: 2.661766965007846
Validation loss: 2.50511508969634

Epoch: 6| Step: 10
Training loss: 2.380137859166501
Validation loss: 2.4739050356311023

Epoch: 6| Step: 11
Training loss: 2.895333079940688
Validation loss: 2.484802186664591

Epoch: 6| Step: 12
Training loss: 1.9248555959068707
Validation loss: 2.4790471490136583

Epoch: 6| Step: 13
Training loss: 1.690047143131901
Validation loss: 2.475503272841217

Epoch: 173| Step: 0
Training loss: 3.1635829232424815
Validation loss: 2.4702637075078764

Epoch: 6| Step: 1
Training loss: 2.3033869807854592
Validation loss: 2.5044535909478296

Epoch: 6| Step: 2
Training loss: 2.291265475672993
Validation loss: 2.472059743920599

Epoch: 6| Step: 3
Training loss: 2.2556822339811613
Validation loss: 2.5026758957594994

Epoch: 6| Step: 4
Training loss: 2.570419355681578
Validation loss: 2.4952044391613937

Epoch: 6| Step: 5
Training loss: 2.5153909894251822
Validation loss: 2.484830055552054

Epoch: 6| Step: 6
Training loss: 2.4578919957443492
Validation loss: 2.4782521529409802

Epoch: 6| Step: 7
Training loss: 2.6873914120050246
Validation loss: 2.465890512132195

Epoch: 6| Step: 8
Training loss: 2.87973345980136
Validation loss: 2.4716240884921894

Epoch: 6| Step: 9
Training loss: 2.2143778100616345
Validation loss: 2.478077779050844

Epoch: 6| Step: 10
Training loss: 2.555231998757523
Validation loss: 2.4989525379796143

Epoch: 6| Step: 11
Training loss: 3.1468680661076784
Validation loss: 2.477639028991966

Epoch: 6| Step: 12
Training loss: 2.7596470077735353
Validation loss: 2.462236765197896

Epoch: 6| Step: 13
Training loss: 3.372621899346582
Validation loss: 2.470938986644116

Epoch: 174| Step: 0
Training loss: 2.548135831509049
Validation loss: 2.492331653763914

Epoch: 6| Step: 1
Training loss: 3.0737343082903936
Validation loss: 2.470520752101666

Epoch: 6| Step: 2
Training loss: 2.3941588368892495
Validation loss: 2.4812134572847446

Epoch: 6| Step: 3
Training loss: 3.7781321384308857
Validation loss: 2.4710710688551276

Epoch: 6| Step: 4
Training loss: 2.3589778338494964
Validation loss: 2.5083069079972926

Epoch: 6| Step: 5
Training loss: 1.6262759554504786
Validation loss: 2.4941543294905744

Epoch: 6| Step: 6
Training loss: 2.0887344410908653
Validation loss: 2.4907686104188005

Epoch: 6| Step: 7
Training loss: 2.7498376104786053
Validation loss: 2.4763644202537582

Epoch: 6| Step: 8
Training loss: 3.0699083678645787
Validation loss: 2.4875546482411455

Epoch: 6| Step: 9
Training loss: 2.7204950804901653
Validation loss: 2.494533802857426

Epoch: 6| Step: 10
Training loss: 2.5218171861112406
Validation loss: 2.501839612086543

Epoch: 6| Step: 11
Training loss: 2.4080142204650525
Validation loss: 2.4983930252932094

Epoch: 6| Step: 12
Training loss: 2.1690237966298755
Validation loss: 2.499387305049245

Epoch: 6| Step: 13
Training loss: 3.2238881109146416
Validation loss: 2.497433169157264

Epoch: 175| Step: 0
Training loss: 2.626777773538831
Validation loss: 2.4795477403543225

Epoch: 6| Step: 1
Training loss: 1.857669464842088
Validation loss: 2.468384348700585

Epoch: 6| Step: 2
Training loss: 2.2592575570339237
Validation loss: 2.5094825301191097

Epoch: 6| Step: 3
Training loss: 2.858241122197718
Validation loss: 2.5041452353650717

Epoch: 6| Step: 4
Training loss: 2.060449216435761
Validation loss: 2.5017322435321354

Epoch: 6| Step: 5
Training loss: 2.653435685980768
Validation loss: 2.483360324268896

Epoch: 6| Step: 6
Training loss: 2.964449045799506
Validation loss: 2.4658967853174163

Epoch: 6| Step: 7
Training loss: 2.914381239898893
Validation loss: 2.5068624579993823

Epoch: 6| Step: 8
Training loss: 3.1508033515198517
Validation loss: 2.4858642611474258

Epoch: 6| Step: 9
Training loss: 2.6123663836172404
Validation loss: 2.4854482854232263

Epoch: 6| Step: 10
Training loss: 2.364558607691974
Validation loss: 2.485037987287203

Epoch: 6| Step: 11
Training loss: 3.131473093213561
Validation loss: 2.4874480760835467

Epoch: 6| Step: 12
Training loss: 2.3358296142976758
Validation loss: 2.5106921832183815

Epoch: 6| Step: 13
Training loss: 2.88481058487307
Validation loss: 2.492276235682516

Epoch: 176| Step: 0
Training loss: 2.7790880694468285
Validation loss: 2.495593002894639

Epoch: 6| Step: 1
Training loss: 1.88026826151889
Validation loss: 2.4762761186043054

Epoch: 6| Step: 2
Training loss: 2.5650593142130083
Validation loss: 2.4808107682422684

Epoch: 6| Step: 3
Training loss: 2.4726747629638712
Validation loss: 2.50604211829253

Epoch: 6| Step: 4
Training loss: 1.970172307761869
Validation loss: 2.4928517805958075

Epoch: 6| Step: 5
Training loss: 3.1526907312716066
Validation loss: 2.500445422618388

Epoch: 6| Step: 6
Training loss: 2.143200515302174
Validation loss: 2.479854157169016

Epoch: 6| Step: 7
Training loss: 2.765162973550418
Validation loss: 2.455546096479831

Epoch: 6| Step: 8
Training loss: 2.2849845104402045
Validation loss: 2.471058294042229

Epoch: 6| Step: 9
Training loss: 2.724609375
Validation loss: 2.4880308213027105

Epoch: 6| Step: 10
Training loss: 3.143941314518409
Validation loss: 2.4676644745198195

Epoch: 6| Step: 11
Training loss: 3.2226985674304935
Validation loss: 2.48715192730242

Epoch: 6| Step: 12
Training loss: 2.8465498670548324
Validation loss: 2.4830769734908973

Epoch: 6| Step: 13
Training loss: 2.700278045325001
Validation loss: 2.474793580555173

Epoch: 177| Step: 0
Training loss: 2.2416020602685798
Validation loss: 2.485477108375994

Epoch: 6| Step: 1
Training loss: 3.3846230540155338
Validation loss: 2.488886963673378

Epoch: 6| Step: 2
Training loss: 2.594398509382913
Validation loss: 2.5070511634032298

Epoch: 6| Step: 3
Training loss: 2.305609050063744
Validation loss: 2.4794221250771056

Epoch: 6| Step: 4
Training loss: 3.0061491887881187
Validation loss: 2.4663373909109505

Epoch: 6| Step: 5
Training loss: 3.2036065460725003
Validation loss: 2.5079831158052217

Epoch: 6| Step: 6
Training loss: 2.231812080942823
Validation loss: 2.4866429695315047

Epoch: 6| Step: 7
Training loss: 2.976459651581912
Validation loss: 2.466558143597522

Epoch: 6| Step: 8
Training loss: 2.3571038841559626
Validation loss: 2.496045486908213

Epoch: 6| Step: 9
Training loss: 2.9597078452399326
Validation loss: 2.483391044074408

Epoch: 6| Step: 10
Training loss: 1.9584786854904461
Validation loss: 2.5078114572928634

Epoch: 6| Step: 11
Training loss: 2.5897700096437797
Validation loss: 2.4923868947244583

Epoch: 6| Step: 12
Training loss: 2.205262898626122
Validation loss: 2.4966627611774608

Epoch: 6| Step: 13
Training loss: 2.7210398710022132
Validation loss: 2.500143471569532

Epoch: 178| Step: 0
Training loss: 2.5286453409453102
Validation loss: 2.498702594495541

Epoch: 6| Step: 1
Training loss: 2.5578811701538133
Validation loss: 2.5127799857501882

Epoch: 6| Step: 2
Training loss: 2.470256683664861
Validation loss: 2.4979441762753143

Epoch: 6| Step: 3
Training loss: 3.2580149196613326
Validation loss: 2.5059268898105524

Epoch: 6| Step: 4
Training loss: 2.3180303685632118
Validation loss: 2.5094785541212143

Epoch: 6| Step: 5
Training loss: 2.858564751898389
Validation loss: 2.487408389266193

Epoch: 6| Step: 6
Training loss: 2.1002317845631135
Validation loss: 2.4997660353095337

Epoch: 6| Step: 7
Training loss: 2.410774337182075
Validation loss: 2.5314479939332113

Epoch: 6| Step: 8
Training loss: 2.413725104102335
Validation loss: 2.5168660528694686

Epoch: 6| Step: 9
Training loss: 2.68404947600834
Validation loss: 2.4782763994159964

Epoch: 6| Step: 10
Training loss: 3.5499125510177074
Validation loss: 2.4996740200442598

Epoch: 6| Step: 11
Training loss: 2.647028545443333
Validation loss: 2.4967148033059203

Epoch: 6| Step: 12
Training loss: 2.099821709830082
Validation loss: 2.5255507592322095

Epoch: 6| Step: 13
Training loss: 2.8606849546444297
Validation loss: 2.4925511888451735

Epoch: 179| Step: 0
Training loss: 2.5752014229520794
Validation loss: 2.510567518408009

Epoch: 6| Step: 1
Training loss: 2.6965739518657483
Validation loss: 2.485640675706184

Epoch: 6| Step: 2
Training loss: 2.868956973519429
Validation loss: 2.488083971312472

Epoch: 6| Step: 3
Training loss: 2.1287960478931254
Validation loss: 2.4760895498700854

Epoch: 6| Step: 4
Training loss: 2.0078930077943675
Validation loss: 2.493683967391499

Epoch: 6| Step: 5
Training loss: 2.5682600459048364
Validation loss: 2.4974501054917164

Epoch: 6| Step: 6
Training loss: 2.6294614933877125
Validation loss: 2.4977963313020752

Epoch: 6| Step: 7
Training loss: 2.70447572686729
Validation loss: 2.49866621882727

Epoch: 6| Step: 8
Training loss: 2.9205769802319774
Validation loss: 2.497505839889964

Epoch: 6| Step: 9
Training loss: 2.2934912844904582
Validation loss: 2.475400557452583

Epoch: 6| Step: 10
Training loss: 2.903513943309751
Validation loss: 2.4863954216013213

Epoch: 6| Step: 11
Training loss: 3.3193653865180113
Validation loss: 2.477399842938394

Epoch: 6| Step: 12
Training loss: 2.3877173799146405
Validation loss: 2.4739686484950267

Epoch: 6| Step: 13
Training loss: 2.252357942799109
Validation loss: 2.485210757702537

Epoch: 180| Step: 0
Training loss: 2.771515946211784
Validation loss: 2.479423196008186

Epoch: 6| Step: 1
Training loss: 2.110725479151622
Validation loss: 2.4942896980186187

Epoch: 6| Step: 2
Training loss: 2.790704324071192
Validation loss: 2.4962970813165763

Epoch: 6| Step: 3
Training loss: 2.807559187580265
Validation loss: 2.4720452133023882

Epoch: 6| Step: 4
Training loss: 1.9742012243545906
Validation loss: 2.5018501050153983

Epoch: 6| Step: 5
Training loss: 2.5065925459183953
Validation loss: 2.4750927306240786

Epoch: 6| Step: 6
Training loss: 3.4258707485013224
Validation loss: 2.4698007252373695

Epoch: 6| Step: 7
Training loss: 2.6339565247906624
Validation loss: 2.4889815438083733

Epoch: 6| Step: 8
Training loss: 3.0852498121219036
Validation loss: 2.480830128695112

Epoch: 6| Step: 9
Training loss: 2.429594277313798
Validation loss: 2.489103832210304

Epoch: 6| Step: 10
Training loss: 2.4001683255613204
Validation loss: 2.4787214242493563

Epoch: 6| Step: 11
Training loss: 1.9110083054582137
Validation loss: 2.49117868096373

Epoch: 6| Step: 12
Training loss: 3.273808933935071
Validation loss: 2.4630054083690216

Epoch: 6| Step: 13
Training loss: 1.95905015555451
Validation loss: 2.481513205379232

Epoch: 181| Step: 0
Training loss: 2.390130883308122
Validation loss: 2.4807163509304058

Epoch: 6| Step: 1
Training loss: 2.891951467980031
Validation loss: 2.4867495442342262

Epoch: 6| Step: 2
Training loss: 2.344849595572068
Validation loss: 2.478210197154958

Epoch: 6| Step: 3
Training loss: 2.537625983357022
Validation loss: 2.4938457685173576

Epoch: 6| Step: 4
Training loss: 2.7174553254920166
Validation loss: 2.4665176082439966

Epoch: 6| Step: 5
Training loss: 2.552129742466396
Validation loss: 2.494827255525079

Epoch: 6| Step: 6
Training loss: 3.5752191863191563
Validation loss: 2.4551753660221256

Epoch: 6| Step: 7
Training loss: 2.12628550074306
Validation loss: 2.464472023557403

Epoch: 6| Step: 8
Training loss: 2.734515987576195
Validation loss: 2.469300907090985

Epoch: 6| Step: 9
Training loss: 3.0909235209367885
Validation loss: 2.50503797405776

Epoch: 6| Step: 10
Training loss: 2.076242842228429
Validation loss: 2.4783507231749176

Epoch: 6| Step: 11
Training loss: 2.4944628430457114
Validation loss: 2.467442222331279

Epoch: 6| Step: 12
Training loss: 2.5980415230619776
Validation loss: 2.47175019471095

Epoch: 6| Step: 13
Training loss: 2.3866209518948924
Validation loss: 2.4755735189225856

Epoch: 182| Step: 0
Training loss: 2.5483562631949717
Validation loss: 2.4793559676259656

Epoch: 6| Step: 1
Training loss: 3.3038070624132785
Validation loss: 2.4824004625419813

Epoch: 6| Step: 2
Training loss: 3.268594951854627
Validation loss: 2.4960023460565157

Epoch: 6| Step: 3
Training loss: 2.067142002242246
Validation loss: 2.4739579326497623

Epoch: 6| Step: 4
Training loss: 1.757922359848237
Validation loss: 2.4671013310128904

Epoch: 6| Step: 5
Training loss: 2.6634293416287806
Validation loss: 2.4807410931295633

Epoch: 6| Step: 6
Training loss: 2.6644937384373097
Validation loss: 2.5024333985783564

Epoch: 6| Step: 7
Training loss: 2.4510681859916446
Validation loss: 2.4954710905323605

Epoch: 6| Step: 8
Training loss: 2.810317061242502
Validation loss: 2.481904856179807

Epoch: 6| Step: 9
Training loss: 3.3844369419449176
Validation loss: 2.4827591841073273

Epoch: 6| Step: 10
Training loss: 2.7570820562405736
Validation loss: 2.492622306955375

Epoch: 6| Step: 11
Training loss: 2.0592954767875766
Validation loss: 2.494812269218015

Epoch: 6| Step: 12
Training loss: 2.065471012071819
Validation loss: 2.4799091871004206

Epoch: 6| Step: 13
Training loss: 2.3496310898180903
Validation loss: 2.5099253159378168

Epoch: 183| Step: 0
Training loss: 3.157375172905955
Validation loss: 2.487117622557518

Epoch: 6| Step: 1
Training loss: 2.6344094343186204
Validation loss: 2.4742729970475184

Epoch: 6| Step: 2
Training loss: 2.086791360235216
Validation loss: 2.515105102884906

Epoch: 6| Step: 3
Training loss: 2.6933596405626683
Validation loss: 2.4790439225465892

Epoch: 6| Step: 4
Training loss: 2.350402444508932
Validation loss: 2.4936822232980544

Epoch: 6| Step: 5
Training loss: 2.736080226519487
Validation loss: 2.501090631187922

Epoch: 6| Step: 6
Training loss: 2.224897223681315
Validation loss: 2.518377094068432

Epoch: 6| Step: 7
Training loss: 3.5347411865711584
Validation loss: 2.510008871290539

Epoch: 6| Step: 8
Training loss: 2.5461318915367173
Validation loss: 2.4749947194539974

Epoch: 6| Step: 9
Training loss: 2.4802916936685397
Validation loss: 2.498834767072511

Epoch: 6| Step: 10
Training loss: 2.404300841538158
Validation loss: 2.4996683259621895

Epoch: 6| Step: 11
Training loss: 2.625198720040475
Validation loss: 2.5037370192346535

Epoch: 6| Step: 12
Training loss: 2.798346446742886
Validation loss: 2.5015041943144

Epoch: 6| Step: 13
Training loss: 2.170525330447338
Validation loss: 2.4691951688352454

Epoch: 184| Step: 0
Training loss: 2.520215129449479
Validation loss: 2.4945914573743164

Epoch: 6| Step: 1
Training loss: 1.9417979039166644
Validation loss: 2.495536069560551

Epoch: 6| Step: 2
Training loss: 2.901395126716706
Validation loss: 2.498110653042898

Epoch: 6| Step: 3
Training loss: 2.9355109765249288
Validation loss: 2.4996275588478643

Epoch: 6| Step: 4
Training loss: 2.737410947143757
Validation loss: 2.4894601600325275

Epoch: 6| Step: 5
Training loss: 2.1935752429530613
Validation loss: 2.50620220912993

Epoch: 6| Step: 6
Training loss: 2.924512356269444
Validation loss: 2.500287266090709

Epoch: 6| Step: 7
Training loss: 2.665761009046898
Validation loss: 2.4806296996167605

Epoch: 6| Step: 8
Training loss: 2.4335662203436352
Validation loss: 2.484439317847514

Epoch: 6| Step: 9
Training loss: 2.415190201845413
Validation loss: 2.527815362874071

Epoch: 6| Step: 10
Training loss: 2.955080384066387
Validation loss: 2.5142553176816715

Epoch: 6| Step: 11
Training loss: 2.770265210259581
Validation loss: 2.513140984264877

Epoch: 6| Step: 12
Training loss: 2.8673707659200494
Validation loss: 2.507338572524345

Epoch: 6| Step: 13
Training loss: 2.0956993707372593
Validation loss: 2.5032677459541506

Epoch: 185| Step: 0
Training loss: 2.258269055942697
Validation loss: 2.492372174550173

Epoch: 6| Step: 1
Training loss: 2.402199444662336
Validation loss: 2.5063248295098113

Epoch: 6| Step: 2
Training loss: 2.8309763660367415
Validation loss: 2.4878043087286197

Epoch: 6| Step: 3
Training loss: 3.248024266589235
Validation loss: 2.4876573811815224

Epoch: 6| Step: 4
Training loss: 2.954139172022988
Validation loss: 2.473041675909622

Epoch: 6| Step: 5
Training loss: 2.4705599174158865
Validation loss: 2.497682012602514

Epoch: 6| Step: 6
Training loss: 2.5931728594177446
Validation loss: 2.493777757008495

Epoch: 6| Step: 7
Training loss: 2.50770554359025
Validation loss: 2.485300212858044

Epoch: 6| Step: 8
Training loss: 2.5149602544840586
Validation loss: 2.4809070502549377

Epoch: 6| Step: 9
Training loss: 2.136229854910626
Validation loss: 2.500461560372495

Epoch: 6| Step: 10
Training loss: 1.8233052157524365
Validation loss: 2.491286991088992

Epoch: 6| Step: 11
Training loss: 3.088450815924193
Validation loss: 2.487660097694285

Epoch: 6| Step: 12
Training loss: 2.9984397009542794
Validation loss: 2.4897709264078487

Epoch: 6| Step: 13
Training loss: 2.645108361431225
Validation loss: 2.5005045212524433

Epoch: 186| Step: 0
Training loss: 2.3732443896068296
Validation loss: 2.503351749841638

Epoch: 6| Step: 1
Training loss: 2.2489571803839308
Validation loss: 2.474404551619652

Epoch: 6| Step: 2
Training loss: 3.092092821581032
Validation loss: 2.4879277812574103

Epoch: 6| Step: 3
Training loss: 2.3505417138548674
Validation loss: 2.4927351875028188

Epoch: 6| Step: 4
Training loss: 2.879073201570255
Validation loss: 2.490981723340559

Epoch: 6| Step: 5
Training loss: 2.48693945621656
Validation loss: 2.4836141781245407

Epoch: 6| Step: 6
Training loss: 2.5834655932953168
Validation loss: 2.465398345876809

Epoch: 6| Step: 7
Training loss: 2.8359620484689927
Validation loss: 2.4912065886290877

Epoch: 6| Step: 8
Training loss: 2.658746421391886
Validation loss: 2.4938665265692617

Epoch: 6| Step: 9
Training loss: 2.749115368134268
Validation loss: 2.4821417831010333

Epoch: 6| Step: 10
Training loss: 2.3596827830470954
Validation loss: 2.4878565423450425

Epoch: 6| Step: 11
Training loss: 2.434309215905526
Validation loss: 2.5141905185895896

Epoch: 6| Step: 12
Training loss: 3.3321880916339857
Validation loss: 2.4843960043510114

Epoch: 6| Step: 13
Training loss: 1.9652162354279863
Validation loss: 2.5024377627702625

Epoch: 187| Step: 0
Training loss: 3.570339478238472
Validation loss: 2.49934087596202

Epoch: 6| Step: 1
Training loss: 2.622800723162713
Validation loss: 2.5025460506862585

Epoch: 6| Step: 2
Training loss: 2.757311032444231
Validation loss: 2.4820864050181792

Epoch: 6| Step: 3
Training loss: 3.123907127015817
Validation loss: 2.4777108948447175

Epoch: 6| Step: 4
Training loss: 2.4317858304097606
Validation loss: 2.4921607924756

Epoch: 6| Step: 5
Training loss: 2.4061652825044533
Validation loss: 2.482960842383672

Epoch: 6| Step: 6
Training loss: 2.9474235274964222
Validation loss: 2.467834550072832

Epoch: 6| Step: 7
Training loss: 1.8222206821603133
Validation loss: 2.489590242238721

Epoch: 6| Step: 8
Training loss: 2.217532078834577
Validation loss: 2.4902671698241154

Epoch: 6| Step: 9
Training loss: 2.4158319697968906
Validation loss: 2.4936588344399024

Epoch: 6| Step: 10
Training loss: 2.518151761705976
Validation loss: 2.4871022187165623

Epoch: 6| Step: 11
Training loss: 2.662237621865005
Validation loss: 2.4998961037407192

Epoch: 6| Step: 12
Training loss: 2.504877006419928
Validation loss: 2.509889593199346

Epoch: 6| Step: 13
Training loss: 1.7619816146263763
Validation loss: 2.4902272139431614

Epoch: 188| Step: 0
Training loss: 2.7650454501232993
Validation loss: 2.466708039627163

Epoch: 6| Step: 1
Training loss: 2.6094524806049173
Validation loss: 2.4724805544925053

Epoch: 6| Step: 2
Training loss: 2.304139256328691
Validation loss: 2.496308049410896

Epoch: 6| Step: 3
Training loss: 2.8246890951920833
Validation loss: 2.479325223674469

Epoch: 6| Step: 4
Training loss: 2.2813746797117163
Validation loss: 2.4842322255573186

Epoch: 6| Step: 5
Training loss: 2.539531582270367
Validation loss: 2.4756985758743255

Epoch: 6| Step: 6
Training loss: 2.4237387100436814
Validation loss: 2.481358908771757

Epoch: 6| Step: 7
Training loss: 2.67489756450426
Validation loss: 2.5026159013586993

Epoch: 6| Step: 8
Training loss: 2.8342061287939457
Validation loss: 2.479852387325285

Epoch: 6| Step: 9
Training loss: 2.7591045692097698
Validation loss: 2.492061968134571

Epoch: 6| Step: 10
Training loss: 2.477917033028104
Validation loss: 2.478081431966216

Epoch: 6| Step: 11
Training loss: 3.0304910555218036
Validation loss: 2.4626055310751815

Epoch: 6| Step: 12
Training loss: 2.7504944790256154
Validation loss: 2.502218890189758

Epoch: 6| Step: 13
Training loss: 2.102616283453335
Validation loss: 2.4750672607712514

Epoch: 189| Step: 0
Training loss: 2.598973724584676
Validation loss: 2.495272146715417

Epoch: 6| Step: 1
Training loss: 2.9243998506863482
Validation loss: 2.4762132327913604

Epoch: 6| Step: 2
Training loss: 2.6515529616661455
Validation loss: 2.4763410505524717

Epoch: 6| Step: 3
Training loss: 2.888324874040822
Validation loss: 2.4936393412440365

Epoch: 6| Step: 4
Training loss: 3.0064538835001744
Validation loss: 2.4822097013411977

Epoch: 6| Step: 5
Training loss: 2.434863890304064
Validation loss: 2.5022913819809385

Epoch: 6| Step: 6
Training loss: 2.664389492338221
Validation loss: 2.4911168660028946

Epoch: 6| Step: 7
Training loss: 2.5987502469002597
Validation loss: 2.504029737356368

Epoch: 6| Step: 8
Training loss: 1.9828393956878598
Validation loss: 2.486848987912691

Epoch: 6| Step: 9
Training loss: 2.883052991641379
Validation loss: 2.50384585197789

Epoch: 6| Step: 10
Training loss: 2.8037825375631997
Validation loss: 2.4716369988501197

Epoch: 6| Step: 11
Training loss: 2.8416381372117816
Validation loss: 2.5086806220174207

Epoch: 6| Step: 12
Training loss: 1.706593891742915
Validation loss: 2.4958005849145013

Epoch: 6| Step: 13
Training loss: 2.321639275682508
Validation loss: 2.4858782608352508

Epoch: 190| Step: 0
Training loss: 2.7458937071519287
Validation loss: 2.4766764173532567

Epoch: 6| Step: 1
Training loss: 2.629017072271762
Validation loss: 2.4956164866241326

Epoch: 6| Step: 2
Training loss: 2.2792583812087974
Validation loss: 2.5164302147928166

Epoch: 6| Step: 3
Training loss: 3.62645034715234
Validation loss: 2.478221450122745

Epoch: 6| Step: 4
Training loss: 2.417311867274426
Validation loss: 2.491857793297607

Epoch: 6| Step: 5
Training loss: 2.0163783358593084
Validation loss: 2.477488830947853

Epoch: 6| Step: 6
Training loss: 2.2391385605239122
Validation loss: 2.466552560151976

Epoch: 6| Step: 7
Training loss: 3.266099229173034
Validation loss: 2.497035521851545

Epoch: 6| Step: 8
Training loss: 2.142432125267205
Validation loss: 2.4834249367934733

Epoch: 6| Step: 9
Training loss: 2.1040429434582033
Validation loss: 2.46105861831293

Epoch: 6| Step: 10
Training loss: 2.1808143902156214
Validation loss: 2.4663999500876517

Epoch: 6| Step: 11
Training loss: 2.6842469332502423
Validation loss: 2.4697653542687905

Epoch: 6| Step: 12
Training loss: 3.1899359875417965
Validation loss: 2.4831364498754747

Epoch: 6| Step: 13
Training loss: 2.733020032589435
Validation loss: 2.479422975773302

Epoch: 191| Step: 0
Training loss: 2.3815849769451622
Validation loss: 2.483586749776078

Epoch: 6| Step: 1
Training loss: 3.015857904957239
Validation loss: 2.4752568746378962

Epoch: 6| Step: 2
Training loss: 2.1536965108595667
Validation loss: 2.4655376691535347

Epoch: 6| Step: 3
Training loss: 2.5785697784539314
Validation loss: 2.4827367058315493

Epoch: 6| Step: 4
Training loss: 3.0449428594329837
Validation loss: 2.5027990617537874

Epoch: 6| Step: 5
Training loss: 2.305750507962269
Validation loss: 2.4897352094985337

Epoch: 6| Step: 6
Training loss: 2.6714709238493795
Validation loss: 2.4976860864122834

Epoch: 6| Step: 7
Training loss: 2.3768329574313247
Validation loss: 2.5005821719199184

Epoch: 6| Step: 8
Training loss: 3.019342374631294
Validation loss: 2.5266500809542047

Epoch: 6| Step: 9
Training loss: 2.4438199006447077
Validation loss: 2.5091151394956173

Epoch: 6| Step: 10
Training loss: 2.5052384806277654
Validation loss: 2.4704587180705126

Epoch: 6| Step: 11
Training loss: 2.366001247383105
Validation loss: 2.488952762468215

Epoch: 6| Step: 12
Training loss: 2.843296559831288
Validation loss: 2.499774891962915

Epoch: 6| Step: 13
Training loss: 3.0540770874486944
Validation loss: 2.5015728709498646

Epoch: 192| Step: 0
Training loss: 2.848742451877478
Validation loss: 2.4908064111333905

Epoch: 6| Step: 1
Training loss: 2.098905223493198
Validation loss: 2.5109664950746415

Epoch: 6| Step: 2
Training loss: 2.2791640268295406
Validation loss: 2.487013994224428

Epoch: 6| Step: 3
Training loss: 3.0318178254608616
Validation loss: 2.531679717301941

Epoch: 6| Step: 4
Training loss: 2.8890794075800725
Validation loss: 2.497493525175004

Epoch: 6| Step: 5
Training loss: 2.7747806359268563
Validation loss: 2.499422565551808

Epoch: 6| Step: 6
Training loss: 2.446335746030358
Validation loss: 2.549587879219657

Epoch: 6| Step: 7
Training loss: 2.7590322417711635
Validation loss: 2.490355946136772

Epoch: 6| Step: 8
Training loss: 2.3535861309459762
Validation loss: 2.5007567839459433

Epoch: 6| Step: 9
Training loss: 2.815391579964527
Validation loss: 2.506203758850997

Epoch: 6| Step: 10
Training loss: 3.1679747707248582
Validation loss: 2.494974353722672

Epoch: 6| Step: 11
Training loss: 2.4056308494728667
Validation loss: 2.504829487759422

Epoch: 6| Step: 12
Training loss: 2.030841727674456
Validation loss: 2.4809225028945954

Epoch: 6| Step: 13
Training loss: 2.5263844575354346
Validation loss: 2.4825035719410082

Epoch: 193| Step: 0
Training loss: 2.465135946954852
Validation loss: 2.5106219231306386

Epoch: 6| Step: 1
Training loss: 2.0961515403740263
Validation loss: 2.516153216804513

Epoch: 6| Step: 2
Training loss: 2.8970353264253013
Validation loss: 2.5029892605901076

Epoch: 6| Step: 3
Training loss: 2.11197214246931
Validation loss: 2.5118506806204097

Epoch: 6| Step: 4
Training loss: 2.9496964831922186
Validation loss: 2.4916046105904464

Epoch: 6| Step: 5
Training loss: 1.8324541526981577
Validation loss: 2.47593971859234

Epoch: 6| Step: 6
Training loss: 2.8681693825495436
Validation loss: 2.4964535405251227

Epoch: 6| Step: 7
Training loss: 3.0714211828199973
Validation loss: 2.4792694259391235

Epoch: 6| Step: 8
Training loss: 2.6038588278338146
Validation loss: 2.509354542117972

Epoch: 6| Step: 9
Training loss: 2.613004798122691
Validation loss: 2.474310080495668

Epoch: 6| Step: 10
Training loss: 3.048388921760238
Validation loss: 2.4837824519271736

Epoch: 6| Step: 11
Training loss: 2.8238839231955213
Validation loss: 2.4697296848805395

Epoch: 6| Step: 12
Training loss: 2.7413262647742984
Validation loss: 2.4877889452066095

Epoch: 6| Step: 13
Training loss: 2.0284514882956044
Validation loss: 2.475778963186842

Epoch: 194| Step: 0
Training loss: 2.7386870471260396
Validation loss: 2.4850802218752754

Epoch: 6| Step: 1
Training loss: 2.538408118799633
Validation loss: 2.480707653588849

Epoch: 6| Step: 2
Training loss: 2.754133066346569
Validation loss: 2.493100057655615

Epoch: 6| Step: 3
Training loss: 2.132685954493339
Validation loss: 2.492895668068604

Epoch: 6| Step: 4
Training loss: 3.0474823175281873
Validation loss: 2.520864858373415

Epoch: 6| Step: 5
Training loss: 3.1460498625822835
Validation loss: 2.4861890356664533

Epoch: 6| Step: 6
Training loss: 1.914088346345742
Validation loss: 2.4723474458482255

Epoch: 6| Step: 7
Training loss: 2.524490278558114
Validation loss: 2.510867773785401

Epoch: 6| Step: 8
Training loss: 2.3218212424379137
Validation loss: 2.487496835780088

Epoch: 6| Step: 9
Training loss: 2.77719660931215
Validation loss: 2.4811533758178452

Epoch: 6| Step: 10
Training loss: 3.1537433906331698
Validation loss: 2.509429068152661

Epoch: 6| Step: 11
Training loss: 2.063269847186933
Validation loss: 2.4742476555254496

Epoch: 6| Step: 12
Training loss: 2.152590756513382
Validation loss: 2.495507135754319

Epoch: 6| Step: 13
Training loss: 3.21275155830301
Validation loss: 2.4599095528688713

Epoch: 195| Step: 0
Training loss: 2.4212606327609203
Validation loss: 2.500234439071062

Epoch: 6| Step: 1
Training loss: 2.6804641176571202
Validation loss: 2.47646941658369

Epoch: 6| Step: 2
Training loss: 3.032645621958456
Validation loss: 2.5124348870308473

Epoch: 6| Step: 3
Training loss: 2.134724524993195
Validation loss: 2.472221796292977

Epoch: 6| Step: 4
Training loss: 3.364195447988726
Validation loss: 2.50115266704381

Epoch: 6| Step: 5
Training loss: 2.6198632980675773
Validation loss: 2.4902115040194728

Epoch: 6| Step: 6
Training loss: 1.4940388164865253
Validation loss: 2.4832899278408402

Epoch: 6| Step: 7
Training loss: 2.6696268182337417
Validation loss: 2.4753096425654437

Epoch: 6| Step: 8
Training loss: 2.6776570893979907
Validation loss: 2.4751958969017296

Epoch: 6| Step: 9
Training loss: 2.09381422257497
Validation loss: 2.512413309963142

Epoch: 6| Step: 10
Training loss: 1.7314676196215313
Validation loss: 2.5168912372441055

Epoch: 6| Step: 11
Training loss: 2.480215369071311
Validation loss: 2.4870099029333956

Epoch: 6| Step: 12
Training loss: 3.388928529545753
Validation loss: 2.5058744967814843

Epoch: 6| Step: 13
Training loss: 3.065145167635889
Validation loss: 2.498689200177116

Epoch: 196| Step: 0
Training loss: 3.0584751072036336
Validation loss: 2.4824448476955916

Epoch: 6| Step: 1
Training loss: 2.7066239660242855
Validation loss: 2.477834214381507

Epoch: 6| Step: 2
Training loss: 2.7735330914424243
Validation loss: 2.5123772149492023

Epoch: 6| Step: 3
Training loss: 2.773847522783269
Validation loss: 2.461302886886148

Epoch: 6| Step: 4
Training loss: 2.005505137750573
Validation loss: 2.4860986235814395

Epoch: 6| Step: 5
Training loss: 1.9758357344084134
Validation loss: 2.492941967301404

Epoch: 6| Step: 6
Training loss: 2.432340688163794
Validation loss: 2.4911469292982007

Epoch: 6| Step: 7
Training loss: 2.505592575795951
Validation loss: 2.484932502907279

Epoch: 6| Step: 8
Training loss: 2.5776884691983786
Validation loss: 2.4921208463809084

Epoch: 6| Step: 9
Training loss: 1.8667063073081798
Validation loss: 2.4866702584967038

Epoch: 6| Step: 10
Training loss: 2.6748767075691173
Validation loss: 2.4798937209102276

Epoch: 6| Step: 11
Training loss: 3.0481558430597184
Validation loss: 2.489126974972185

Epoch: 6| Step: 12
Training loss: 3.0257877805813207
Validation loss: 2.474542134976545

Epoch: 6| Step: 13
Training loss: 2.6243131738126886
Validation loss: 2.5179776310425646

Epoch: 197| Step: 0
Training loss: 2.6875607683275495
Validation loss: 2.472291919926679

Epoch: 6| Step: 1
Training loss: 3.1620653419185536
Validation loss: 2.504819498199659

Epoch: 6| Step: 2
Training loss: 1.931594832661523
Validation loss: 2.5111497324338643

Epoch: 6| Step: 3
Training loss: 3.540436265431841
Validation loss: 2.470090746829019

Epoch: 6| Step: 4
Training loss: 2.8284023422906945
Validation loss: 2.457665526000058

Epoch: 6| Step: 5
Training loss: 2.7039059960542353
Validation loss: 2.5010749454246084

Epoch: 6| Step: 6
Training loss: 2.2846192862045855
Validation loss: 2.4860550863483026

Epoch: 6| Step: 7
Training loss: 1.9096188403574148
Validation loss: 2.499736726906052

Epoch: 6| Step: 8
Training loss: 2.0538796116613063
Validation loss: 2.4833379711854677

Epoch: 6| Step: 9
Training loss: 2.977003330217318
Validation loss: 2.4791429814439288

Epoch: 6| Step: 10
Training loss: 2.451938026117981
Validation loss: 2.4929921054945687

Epoch: 6| Step: 11
Training loss: 3.1928853934364945
Validation loss: 2.4868041679783626

Epoch: 6| Step: 12
Training loss: 2.140386637761142
Validation loss: 2.4915755282371927

Epoch: 6| Step: 13
Training loss: 1.8951686769968576
Validation loss: 2.496716125831128

Epoch: 198| Step: 0
Training loss: 3.0646039003001455
Validation loss: 2.4987421501509255

Epoch: 6| Step: 1
Training loss: 2.6035523465679695
Validation loss: 2.480162595174955

Epoch: 6| Step: 2
Training loss: 2.393852199832892
Validation loss: 2.5151131002812868

Epoch: 6| Step: 3
Training loss: 2.3345601285477597
Validation loss: 2.4855048686150707

Epoch: 6| Step: 4
Training loss: 2.566338803872592
Validation loss: 2.4927920917346316

Epoch: 6| Step: 5
Training loss: 3.179113387781733
Validation loss: 2.4852880315906467

Epoch: 6| Step: 6
Training loss: 2.2478341168462386
Validation loss: 2.4765816007150385

Epoch: 6| Step: 7
Training loss: 2.6779322978856888
Validation loss: 2.506836847667162

Epoch: 6| Step: 8
Training loss: 2.850084397254258
Validation loss: 2.4851385300114894

Epoch: 6| Step: 9
Training loss: 2.555838416058943
Validation loss: 2.492458566773071

Epoch: 6| Step: 10
Training loss: 1.6939416080215748
Validation loss: 2.504972615175726

Epoch: 6| Step: 11
Training loss: 2.7722165281160427
Validation loss: 2.488625421989821

Epoch: 6| Step: 12
Training loss: 2.8280769470516223
Validation loss: 2.4885525897975627

Epoch: 6| Step: 13
Training loss: 2.4674773014033327
Validation loss: 2.4891921793448266

Epoch: 199| Step: 0
Training loss: 2.962024821227017
Validation loss: 2.4917039952856883

Epoch: 6| Step: 1
Training loss: 2.2612266202764975
Validation loss: 2.511325844300037

Epoch: 6| Step: 2
Training loss: 2.935942703737821
Validation loss: 2.4810279387061627

Epoch: 6| Step: 3
Training loss: 3.0438950271051
Validation loss: 2.466198453772679

Epoch: 6| Step: 4
Training loss: 1.9909059478985152
Validation loss: 2.4890083626955635

Epoch: 6| Step: 5
Training loss: 2.518906058879424
Validation loss: 2.489563216460529

Epoch: 6| Step: 6
Training loss: 3.175828095826076
Validation loss: 2.4737510448372086

Epoch: 6| Step: 7
Training loss: 2.4435632073314326
Validation loss: 2.493328177913587

Epoch: 6| Step: 8
Training loss: 3.085275158845015
Validation loss: 2.491649543779373

Epoch: 6| Step: 9
Training loss: 2.4052613444301154
Validation loss: 2.4784524298425836

Epoch: 6| Step: 10
Training loss: 2.235704999840873
Validation loss: 2.4973351847829752

Epoch: 6| Step: 11
Training loss: 2.5057841146202624
Validation loss: 2.479894486933949

Epoch: 6| Step: 12
Training loss: 2.0606685945980483
Validation loss: 2.485968809840142

Epoch: 6| Step: 13
Training loss: 2.361803434508646
Validation loss: 2.468624868320152

Epoch: 200| Step: 0
Training loss: 2.265046354918415
Validation loss: 2.4989825090618556

Epoch: 6| Step: 1
Training loss: 2.9186200458096216
Validation loss: 2.4905420339216406

Epoch: 6| Step: 2
Training loss: 2.1903833187942134
Validation loss: 2.4853077212917944

Epoch: 6| Step: 3
Training loss: 2.8118627886009917
Validation loss: 2.474018125648063

Epoch: 6| Step: 4
Training loss: 2.768274277576395
Validation loss: 2.4696932748546465

Epoch: 6| Step: 5
Training loss: 2.5932054062828893
Validation loss: 2.4626158143255865

Epoch: 6| Step: 6
Training loss: 2.7293780198898365
Validation loss: 2.5048757577987995

Epoch: 6| Step: 7
Training loss: 2.42821593046839
Validation loss: 2.47627995638653

Epoch: 6| Step: 8
Training loss: 2.9847426262957835
Validation loss: 2.483969747396101

Epoch: 6| Step: 9
Training loss: 2.3105198398275695
Validation loss: 2.506917853266412

Epoch: 6| Step: 10
Training loss: 1.894933410118725
Validation loss: 2.4680962860756606

Epoch: 6| Step: 11
Training loss: 2.519679244078895
Validation loss: 2.4930701726727413

Epoch: 6| Step: 12
Training loss: 2.850126725441207
Validation loss: 2.4752454137376847

Epoch: 6| Step: 13
Training loss: 3.0731719002627322
Validation loss: 2.4879697045491875

Epoch: 201| Step: 0
Training loss: 2.5737856325459205
Validation loss: 2.4761555846793932

Epoch: 6| Step: 1
Training loss: 2.00046796092392
Validation loss: 2.507640016543301

Epoch: 6| Step: 2
Training loss: 2.18037168641449
Validation loss: 2.4657726119561154

Epoch: 6| Step: 3
Training loss: 3.4580115356252903
Validation loss: 2.4998046429506995

Epoch: 6| Step: 4
Training loss: 2.7956660550857713
Validation loss: 2.4760215372642524

Epoch: 6| Step: 5
Training loss: 3.157072356706212
Validation loss: 2.5033561206252006

Epoch: 6| Step: 6
Training loss: 2.495175857003479
Validation loss: 2.5017923964362474

Epoch: 6| Step: 7
Training loss: 2.495723499902156
Validation loss: 2.5093423693254278

Epoch: 6| Step: 8
Training loss: 2.3280158305334515
Validation loss: 2.49536029190129

Epoch: 6| Step: 9
Training loss: 2.479628725563201
Validation loss: 2.495886098378678

Epoch: 6| Step: 10
Training loss: 2.505048898764049
Validation loss: 2.4882067777732484

Epoch: 6| Step: 11
Training loss: 2.34008563643035
Validation loss: 2.4773437389893616

Epoch: 6| Step: 12
Training loss: 2.5142556959688713
Validation loss: 2.507261674556246

Epoch: 6| Step: 13
Training loss: 2.8678406847088094
Validation loss: 2.494378985854986

Epoch: 202| Step: 0
Training loss: 2.739718028964817
Validation loss: 2.506184217974558

Epoch: 6| Step: 1
Training loss: 3.180705139625756
Validation loss: 2.503182728409363

Epoch: 6| Step: 2
Training loss: 2.7422891364322233
Validation loss: 2.4862463433817834

Epoch: 6| Step: 3
Training loss: 2.4439227265099555
Validation loss: 2.4613989550217408

Epoch: 6| Step: 4
Training loss: 2.842546145317053
Validation loss: 2.4906183786471847

Epoch: 6| Step: 5
Training loss: 2.7146946269183636
Validation loss: 2.5002504264346332

Epoch: 6| Step: 6
Training loss: 2.201420875688637
Validation loss: 2.482952020744552

Epoch: 6| Step: 7
Training loss: 2.4486445433734314
Validation loss: 2.5022865216664787

Epoch: 6| Step: 8
Training loss: 2.028485456272086
Validation loss: 2.5038241374117494

Epoch: 6| Step: 9
Training loss: 2.4950260272608347
Validation loss: 2.5218364716648476

Epoch: 6| Step: 10
Training loss: 2.492052893755399
Validation loss: 2.5272936998850906

Epoch: 6| Step: 11
Training loss: 2.972779761416526
Validation loss: 2.4874061610058233

Epoch: 6| Step: 12
Training loss: 2.6970716844536304
Validation loss: 2.488213690157415

Epoch: 6| Step: 13
Training loss: 2.1366396371537237
Validation loss: 2.4847788911630175

Epoch: 203| Step: 0
Training loss: 2.4092260015309144
Validation loss: 2.484259187559792

Epoch: 6| Step: 1
Training loss: 2.098582711382826
Validation loss: 2.4907272318915106

Epoch: 6| Step: 2
Training loss: 2.285904512408568
Validation loss: 2.488811574271355

Epoch: 6| Step: 3
Training loss: 3.310579426923295
Validation loss: 2.485891107477575

Epoch: 6| Step: 4
Training loss: 2.7263420474933846
Validation loss: 2.4718484569115065

Epoch: 6| Step: 5
Training loss: 3.339190360063677
Validation loss: 2.5015524484230145

Epoch: 6| Step: 6
Training loss: 2.041413103304548
Validation loss: 2.46156928434195

Epoch: 6| Step: 7
Training loss: 2.5903776375138126
Validation loss: 2.4777808776166665

Epoch: 6| Step: 8
Training loss: 2.7683593681101843
Validation loss: 2.4647519729793568

Epoch: 6| Step: 9
Training loss: 1.6032765961889823
Validation loss: 2.478519102983153

Epoch: 6| Step: 10
Training loss: 2.399520877856207
Validation loss: 2.479017350569157

Epoch: 6| Step: 11
Training loss: 2.7903760707166034
Validation loss: 2.458379403175031

Epoch: 6| Step: 12
Training loss: 2.7738700421948987
Validation loss: 2.4728927992930183

Epoch: 6| Step: 13
Training loss: 2.65888056927212
Validation loss: 2.4575857155751657

Epoch: 204| Step: 0
Training loss: 2.2315468128584075
Validation loss: 2.4911871621732447

Epoch: 6| Step: 1
Training loss: 2.4235186506072752
Validation loss: 2.4845562249182573

Epoch: 6| Step: 2
Training loss: 1.7094524331137415
Validation loss: 2.503541243133554

Epoch: 6| Step: 3
Training loss: 3.1785853769844374
Validation loss: 2.471084276221077

Epoch: 6| Step: 4
Training loss: 2.123500294770898
Validation loss: 2.4721512320158383

Epoch: 6| Step: 5
Training loss: 2.15799896517385
Validation loss: 2.4722282079221922

Epoch: 6| Step: 6
Training loss: 2.703479368762902
Validation loss: 2.496851037177276

Epoch: 6| Step: 7
Training loss: 2.1847947968380854
Validation loss: 2.488524791443786

Epoch: 6| Step: 8
Training loss: 2.4324598778359108
Validation loss: 2.503057610726879

Epoch: 6| Step: 9
Training loss: 2.4290627415336825
Validation loss: 2.463545234297935

Epoch: 6| Step: 10
Training loss: 3.221649789570273
Validation loss: 2.483716337077

Epoch: 6| Step: 11
Training loss: 3.2951853974069034
Validation loss: 2.470990416852671

Epoch: 6| Step: 12
Training loss: 2.9855437062491363
Validation loss: 2.4819676545934968

Epoch: 6| Step: 13
Training loss: 2.5577731381733377
Validation loss: 2.4826623646793915

Epoch: 205| Step: 0
Training loss: 3.179299370698738
Validation loss: 2.481430064576462

Epoch: 6| Step: 1
Training loss: 3.015504666630482
Validation loss: 2.4903595728068457

Epoch: 6| Step: 2
Training loss: 2.472916768649023
Validation loss: 2.4838548238118032

Epoch: 6| Step: 3
Training loss: 2.3172686098993367
Validation loss: 2.5082872097538997

Epoch: 6| Step: 4
Training loss: 2.3052096535089515
Validation loss: 2.5073821604207613

Epoch: 6| Step: 5
Training loss: 2.84524027582432
Validation loss: 2.4939115372202694

Epoch: 6| Step: 6
Training loss: 2.5037228521588335
Validation loss: 2.490846903727045

Epoch: 6| Step: 7
Training loss: 2.341100797690328
Validation loss: 2.5020049833143165

Epoch: 6| Step: 8
Training loss: 2.5254527450910635
Validation loss: 2.4802778888085295

Epoch: 6| Step: 9
Training loss: 2.631060189765329
Validation loss: 2.4903148325260758

Epoch: 6| Step: 10
Training loss: 2.465757560309189
Validation loss: 2.5190925380901197

Epoch: 6| Step: 11
Training loss: 2.7298182420694435
Validation loss: 2.480614881770622

Epoch: 6| Step: 12
Training loss: 2.49296734605712
Validation loss: 2.5002923907269614

Epoch: 6| Step: 13
Training loss: 2.048099646505956
Validation loss: 2.478228792765297

Epoch: 206| Step: 0
Training loss: 2.305687432047492
Validation loss: 2.4894739175784344

Epoch: 6| Step: 1
Training loss: 2.052954113030771
Validation loss: 2.4980119583794194

Epoch: 6| Step: 2
Training loss: 3.1538905020739487
Validation loss: 2.4730895783318085

Epoch: 6| Step: 3
Training loss: 2.641797770266372
Validation loss: 2.485872891977181

Epoch: 6| Step: 4
Training loss: 2.510492241910318
Validation loss: 2.491450566459067

Epoch: 6| Step: 5
Training loss: 2.6313670007784253
Validation loss: 2.4939931301892657

Epoch: 6| Step: 6
Training loss: 2.768967844227029
Validation loss: 2.4819724317816707

Epoch: 6| Step: 7
Training loss: 2.8499533933877625
Validation loss: 2.4908536502844436

Epoch: 6| Step: 8
Training loss: 2.7562292811854148
Validation loss: 2.469563109501179

Epoch: 6| Step: 9
Training loss: 2.2238720081260546
Validation loss: 2.4690520435517413

Epoch: 6| Step: 10
Training loss: 2.0522080462620798
Validation loss: 2.500881657954331

Epoch: 6| Step: 11
Training loss: 2.6202023577985325
Validation loss: 2.5052725720355578

Epoch: 6| Step: 12
Training loss: 2.799700114675981
Validation loss: 2.474532040112953

Epoch: 6| Step: 13
Training loss: 2.5566021105471326
Validation loss: 2.520686634411934

Epoch: 207| Step: 0
Training loss: 2.8543202899511737
Validation loss: 2.5106488559882267

Epoch: 6| Step: 1
Training loss: 2.6192189090416718
Validation loss: 2.4783565179552594

Epoch: 6| Step: 2
Training loss: 1.8330862427863102
Validation loss: 2.4761459265753327

Epoch: 6| Step: 3
Training loss: 2.3066137507695688
Validation loss: 2.514088576193767

Epoch: 6| Step: 4
Training loss: 2.7113458946930664
Validation loss: 2.484490037275846

Epoch: 6| Step: 5
Training loss: 2.591349582552802
Validation loss: 2.471843761796745

Epoch: 6| Step: 6
Training loss: 2.616789465855452
Validation loss: 2.4994106315833724

Epoch: 6| Step: 7
Training loss: 2.9230585811981618
Validation loss: 2.473232060525172

Epoch: 6| Step: 8
Training loss: 2.2046036323800524
Validation loss: 2.4974177930135633

Epoch: 6| Step: 9
Training loss: 2.3933238832965475
Validation loss: 2.4903496223562525

Epoch: 6| Step: 10
Training loss: 2.9411097322633775
Validation loss: 2.507990543042334

Epoch: 6| Step: 11
Training loss: 2.8345617735371453
Validation loss: 2.528774548452386

Epoch: 6| Step: 12
Training loss: 2.6564632554560004
Validation loss: 2.4916571730088752

Epoch: 6| Step: 13
Training loss: 2.8061291912896684
Validation loss: 2.4794103396348337

Epoch: 208| Step: 0
Training loss: 3.1955187294962806
Validation loss: 2.494046572522617

Epoch: 6| Step: 1
Training loss: 2.4480295899229705
Validation loss: 2.4681872225762094

Epoch: 6| Step: 2
Training loss: 2.3606936578156485
Validation loss: 2.4756658821541073

Epoch: 6| Step: 3
Training loss: 2.882147983783492
Validation loss: 2.496398468626437

Epoch: 6| Step: 4
Training loss: 2.0728940595100136
Validation loss: 2.476444078903857

Epoch: 6| Step: 5
Training loss: 3.121488963899377
Validation loss: 2.481536099707549

Epoch: 6| Step: 6
Training loss: 2.993400148723591
Validation loss: 2.4848320870013825

Epoch: 6| Step: 7
Training loss: 2.5875606916745673
Validation loss: 2.45457905635896

Epoch: 6| Step: 8
Training loss: 2.364786775102402
Validation loss: 2.5004163477411048

Epoch: 6| Step: 9
Training loss: 2.1603483973439315
Validation loss: 2.489287790110963

Epoch: 6| Step: 10
Training loss: 2.139025236575651
Validation loss: 2.484260858292384

Epoch: 6| Step: 11
Training loss: 2.7133800924647624
Validation loss: 2.4954315015186674

Epoch: 6| Step: 12
Training loss: 2.614823551971868
Validation loss: 2.515017387227937

Epoch: 6| Step: 13
Training loss: 2.231217934941714
Validation loss: 2.4832371397920365

Epoch: 209| Step: 0
Training loss: 2.195085941448361
Validation loss: 2.5180150925245566

Epoch: 6| Step: 1
Training loss: 2.8682663054746316
Validation loss: 2.4855120587490536

Epoch: 6| Step: 2
Training loss: 2.1949677654845217
Validation loss: 2.5079001338964373

Epoch: 6| Step: 3
Training loss: 1.7106905545603255
Validation loss: 2.4847207551456436

Epoch: 6| Step: 4
Training loss: 2.346184343690593
Validation loss: 2.4566539449469933

Epoch: 6| Step: 5
Training loss: 3.114471552617392
Validation loss: 2.4590562543440626

Epoch: 6| Step: 6
Training loss: 2.634667080110191
Validation loss: 2.4860761275489858

Epoch: 6| Step: 7
Training loss: 2.9823585608456304
Validation loss: 2.4939313772781593

Epoch: 6| Step: 8
Training loss: 2.939047223324698
Validation loss: 2.4680514205908537

Epoch: 6| Step: 9
Training loss: 2.795383076765673
Validation loss: 2.477760416256665

Epoch: 6| Step: 10
Training loss: 3.027420928955718
Validation loss: 2.472524548490448

Epoch: 6| Step: 11
Training loss: 2.2717434053993832
Validation loss: 2.502159093843883

Epoch: 6| Step: 12
Training loss: 2.194802981943281
Validation loss: 2.4947331744700296

Epoch: 6| Step: 13
Training loss: 2.547372593861763
Validation loss: 2.4938585849103743

Epoch: 210| Step: 0
Training loss: 2.6354291913082966
Validation loss: 2.4756692880289917

Epoch: 6| Step: 1
Training loss: 2.6471550010836093
Validation loss: 2.4882508996582082

Epoch: 6| Step: 2
Training loss: 2.0267107201272245
Validation loss: 2.500971446441061

Epoch: 6| Step: 3
Training loss: 2.3592048229966354
Validation loss: 2.4831249177132384

Epoch: 6| Step: 4
Training loss: 2.219001218516087
Validation loss: 2.4760062228070336

Epoch: 6| Step: 5
Training loss: 2.789954633173015
Validation loss: 2.5026872825173787

Epoch: 6| Step: 6
Training loss: 2.769356575476074
Validation loss: 2.5157948923649114

Epoch: 6| Step: 7
Training loss: 3.3072717540872416
Validation loss: 2.466801251315395

Epoch: 6| Step: 8
Training loss: 2.908303796423276
Validation loss: 2.4928659189540463

Epoch: 6| Step: 9
Training loss: 2.493064797708092
Validation loss: 2.48835118790256

Epoch: 6| Step: 10
Training loss: 2.5253004631829072
Validation loss: 2.491692244528458

Epoch: 6| Step: 11
Training loss: 1.9317678750979628
Validation loss: 2.484827331818505

Epoch: 6| Step: 12
Training loss: 2.570117235738135
Validation loss: 2.471586565404414

Epoch: 6| Step: 13
Training loss: 2.5338285522629946
Validation loss: 2.4695424139564226

Epoch: 211| Step: 0
Training loss: 2.8416542463133725
Validation loss: 2.462286043926407

Epoch: 6| Step: 1
Training loss: 3.323272606292608
Validation loss: 2.4856838628307893

Epoch: 6| Step: 2
Training loss: 2.5457254635631354
Validation loss: 2.494370739038211

Epoch: 6| Step: 3
Training loss: 3.0332449414575686
Validation loss: 2.5027066806558955

Epoch: 6| Step: 4
Training loss: 2.5706449253117882
Validation loss: 2.494214633288151

Epoch: 6| Step: 5
Training loss: 2.340997529274192
Validation loss: 2.466383020895641

Epoch: 6| Step: 6
Training loss: 2.0681133754353955
Validation loss: 2.510209073739976

Epoch: 6| Step: 7
Training loss: 2.3797627928676803
Validation loss: 2.471696371937019

Epoch: 6| Step: 8
Training loss: 2.785002673437181
Validation loss: 2.5067922828359532

Epoch: 6| Step: 9
Training loss: 2.1262120548834123
Validation loss: 2.488689603206138

Epoch: 6| Step: 10
Training loss: 2.588928060776454
Validation loss: 2.4926563168773597

Epoch: 6| Step: 11
Training loss: 2.042765911820443
Validation loss: 2.4831422128392546

Epoch: 6| Step: 12
Training loss: 2.8148358288012156
Validation loss: 2.4906354194783735

Epoch: 6| Step: 13
Training loss: 2.070621683317845
Validation loss: 2.4643128815718596

Epoch: 212| Step: 0
Training loss: 2.343333703263074
Validation loss: 2.4829955494061116

Epoch: 6| Step: 1
Training loss: 2.0833501306492437
Validation loss: 2.499304908596954

Epoch: 6| Step: 2
Training loss: 2.891282785166271
Validation loss: 2.493226474497014

Epoch: 6| Step: 3
Training loss: 2.872094718157526
Validation loss: 2.4832495014614366

Epoch: 6| Step: 4
Training loss: 2.195540772648687
Validation loss: 2.475039141086411

Epoch: 6| Step: 5
Training loss: 3.143888685075849
Validation loss: 2.502177546306683

Epoch: 6| Step: 6
Training loss: 2.0932156464525367
Validation loss: 2.472940010025383

Epoch: 6| Step: 7
Training loss: 2.653430115102416
Validation loss: 2.489647045359443

Epoch: 6| Step: 8
Training loss: 2.8487153353555086
Validation loss: 2.489120515207339

Epoch: 6| Step: 9
Training loss: 2.1934323116142758
Validation loss: 2.497177550928506

Epoch: 6| Step: 10
Training loss: 2.2881240743860802
Validation loss: 2.474872544977034

Epoch: 6| Step: 11
Training loss: 3.553532607721593
Validation loss: 2.470890280976852

Epoch: 6| Step: 12
Training loss: 2.0610758170333208
Validation loss: 2.4874108849772756

Epoch: 6| Step: 13
Training loss: 2.0331902260788004
Validation loss: 2.4964306669598075

Epoch: 213| Step: 0
Training loss: 2.6541880065283663
Validation loss: 2.5120538234059326

Epoch: 6| Step: 1
Training loss: 2.5648647654913095
Validation loss: 2.490644707456839

Epoch: 6| Step: 2
Training loss: 2.7384189892136375
Validation loss: 2.4777156129860436

Epoch: 6| Step: 3
Training loss: 2.4829730030609363
Validation loss: 2.4727801316026

Epoch: 6| Step: 4
Training loss: 2.6247562113589487
Validation loss: 2.483495046552288

Epoch: 6| Step: 5
Training loss: 1.805985813554067
Validation loss: 2.4644225992125155

Epoch: 6| Step: 6
Training loss: 2.548490234428138
Validation loss: 2.4908644262123634

Epoch: 6| Step: 7
Training loss: 2.053955411848637
Validation loss: 2.4768851396675022

Epoch: 6| Step: 8
Training loss: 2.8334135904352
Validation loss: 2.490295032113948

Epoch: 6| Step: 9
Training loss: 3.2374082338738046
Validation loss: 2.5093175198904976

Epoch: 6| Step: 10
Training loss: 2.7132134022400396
Validation loss: 2.465798509473567

Epoch: 6| Step: 11
Training loss: 2.237129700776355
Validation loss: 2.521446883214531

Epoch: 6| Step: 12
Training loss: 2.7460633624852306
Validation loss: 2.4930590988138417

Epoch: 6| Step: 13
Training loss: 2.34117371426205
Validation loss: 2.4803848858331787

Epoch: 214| Step: 0
Training loss: 2.6226788203654867
Validation loss: 2.4710136701226206

Epoch: 6| Step: 1
Training loss: 2.761235001861332
Validation loss: 2.4805489372512963

Epoch: 6| Step: 2
Training loss: 2.653342417153507
Validation loss: 2.4993119431219037

Epoch: 6| Step: 3
Training loss: 2.504790389529091
Validation loss: 2.4990048550575836

Epoch: 6| Step: 4
Training loss: 1.994377936609414
Validation loss: 2.4966918982492827

Epoch: 6| Step: 5
Training loss: 2.436843001025201
Validation loss: 2.4733757430636643

Epoch: 6| Step: 6
Training loss: 2.8748797515932045
Validation loss: 2.4894034458462895

Epoch: 6| Step: 7
Training loss: 3.1464780100610668
Validation loss: 2.46614383673563

Epoch: 6| Step: 8
Training loss: 2.451288981888813
Validation loss: 2.4447137059591086

Epoch: 6| Step: 9
Training loss: 2.466091994624724
Validation loss: 2.5030757134601855

Epoch: 6| Step: 10
Training loss: 2.6944730916636037
Validation loss: 2.5091236086093023

Epoch: 6| Step: 11
Training loss: 2.267337967068249
Validation loss: 2.4688788427499357

Epoch: 6| Step: 12
Training loss: 1.7074091512659348
Validation loss: 2.470948523479859

Epoch: 6| Step: 13
Training loss: 3.5357789560764274
Validation loss: 2.4887100839014082

Epoch: 215| Step: 0
Training loss: 1.8067521344387758
Validation loss: 2.480478878063544

Epoch: 6| Step: 1
Training loss: 2.1473356993665256
Validation loss: 2.488329240245986

Epoch: 6| Step: 2
Training loss: 2.570459796430101
Validation loss: 2.4581099463099085

Epoch: 6| Step: 3
Training loss: 2.876112681148478
Validation loss: 2.4834925866485853

Epoch: 6| Step: 4
Training loss: 2.2270012674178177
Validation loss: 2.4838192968943082

Epoch: 6| Step: 5
Training loss: 2.2079515546998785
Validation loss: 2.5024229255111914

Epoch: 6| Step: 6
Training loss: 2.537630211256323
Validation loss: 2.4624291121975252

Epoch: 6| Step: 7
Training loss: 3.0279841182599636
Validation loss: 2.4883061807289226

Epoch: 6| Step: 8
Training loss: 2.55160663330632
Validation loss: 2.4726703109902584

Epoch: 6| Step: 9
Training loss: 3.223493617535937
Validation loss: 2.4775537973369373

Epoch: 6| Step: 10
Training loss: 2.88008811842368
Validation loss: 2.4829864687371495

Epoch: 6| Step: 11
Training loss: 3.122685758075725
Validation loss: 2.4999165408242088

Epoch: 6| Step: 12
Training loss: 2.3164925004363033
Validation loss: 2.4958751099413816

Epoch: 6| Step: 13
Training loss: 1.6767592344016977
Validation loss: 2.4703722533358126

Epoch: 216| Step: 0
Training loss: 2.2308905047430794
Validation loss: 2.4920250799241437

Epoch: 6| Step: 1
Training loss: 2.9435249388363873
Validation loss: 2.508701886809527

Epoch: 6| Step: 2
Training loss: 2.1022861752091666
Validation loss: 2.4613488898622196

Epoch: 6| Step: 3
Training loss: 2.55539024090151
Validation loss: 2.469632235266816

Epoch: 6| Step: 4
Training loss: 2.1670542394788512
Validation loss: 2.4693788485848303

Epoch: 6| Step: 5
Training loss: 3.357136819132561
Validation loss: 2.4777280104803663

Epoch: 6| Step: 6
Training loss: 2.7839539488897036
Validation loss: 2.5025390662288736

Epoch: 6| Step: 7
Training loss: 2.243215292120165
Validation loss: 2.4981723985958073

Epoch: 6| Step: 8
Training loss: 2.880855568058925
Validation loss: 2.498076286355405

Epoch: 6| Step: 9
Training loss: 1.89576231295966
Validation loss: 2.4729306228951176

Epoch: 6| Step: 10
Training loss: 2.471803828588083
Validation loss: 2.509328845860894

Epoch: 6| Step: 11
Training loss: 2.732059217467481
Validation loss: 2.460903255903472

Epoch: 6| Step: 12
Training loss: 2.6103864525469453
Validation loss: 2.454204019738971

Epoch: 6| Step: 13
Training loss: 2.7076953332098816
Validation loss: 2.4700688891257214

Epoch: 217| Step: 0
Training loss: 2.35505847299475
Validation loss: 2.4903350445552204

Epoch: 6| Step: 1
Training loss: 3.6275762414051385
Validation loss: 2.476400063437427

Epoch: 6| Step: 2
Training loss: 2.750805650086596
Validation loss: 2.4803678381426386

Epoch: 6| Step: 3
Training loss: 2.6635918970683963
Validation loss: 2.5042776335624386

Epoch: 6| Step: 4
Training loss: 2.6250787450695956
Validation loss: 2.4964371283473468

Epoch: 6| Step: 5
Training loss: 2.7997250660384587
Validation loss: 2.4935548076240006

Epoch: 6| Step: 6
Training loss: 1.9498221585288584
Validation loss: 2.4975028713070664

Epoch: 6| Step: 7
Training loss: 2.34511282399314
Validation loss: 2.499921146297752

Epoch: 6| Step: 8
Training loss: 2.267146264088353
Validation loss: 2.5189622803059524

Epoch: 6| Step: 9
Training loss: 2.228455819373071
Validation loss: 2.48554366476772

Epoch: 6| Step: 10
Training loss: 1.947813578715057
Validation loss: 2.4955398058135048

Epoch: 6| Step: 11
Training loss: 2.8956573396256386
Validation loss: 2.486394143077729

Epoch: 6| Step: 12
Training loss: 2.7378347253174904
Validation loss: 2.474629588918319

Epoch: 6| Step: 13
Training loss: 2.5065353801854826
Validation loss: 2.483189996812684

Epoch: 218| Step: 0
Training loss: 2.4795391112879703
Validation loss: 2.4820137920342336

Epoch: 6| Step: 1
Training loss: 2.0483949565179524
Validation loss: 2.47372947234459

Epoch: 6| Step: 2
Training loss: 2.3807480170327704
Validation loss: 2.5142530153286984

Epoch: 6| Step: 3
Training loss: 2.9292486650503435
Validation loss: 2.489870619565735

Epoch: 6| Step: 4
Training loss: 2.946572112843418
Validation loss: 2.505520952031241

Epoch: 6| Step: 5
Training loss: 2.102569225500664
Validation loss: 2.471133154428722

Epoch: 6| Step: 6
Training loss: 2.9008164013028095
Validation loss: 2.489056748848446

Epoch: 6| Step: 7
Training loss: 2.272143857807267
Validation loss: 2.474904276510159

Epoch: 6| Step: 8
Training loss: 2.565123912651367
Validation loss: 2.4752673303359414

Epoch: 6| Step: 9
Training loss: 2.525878481493416
Validation loss: 2.499894338856537

Epoch: 6| Step: 10
Training loss: 2.8910380300358005
Validation loss: 2.499965737220847

Epoch: 6| Step: 11
Training loss: 2.3918009340387942
Validation loss: 2.4786190852837464

Epoch: 6| Step: 12
Training loss: 2.640266529558509
Validation loss: 2.4859140831765525

Epoch: 6| Step: 13
Training loss: 2.7262089453627056
Validation loss: 2.476257780093423

Epoch: 219| Step: 0
Training loss: 2.542658680002958
Validation loss: 2.4919369170701193

Epoch: 6| Step: 1
Training loss: 2.620455304544001
Validation loss: 2.463627231505282

Epoch: 6| Step: 2
Training loss: 2.982719561416337
Validation loss: 2.5166240398276987

Epoch: 6| Step: 3
Training loss: 2.32680663601403
Validation loss: 2.4964681175128316

Epoch: 6| Step: 4
Training loss: 2.016975719110955
Validation loss: 2.5026174297397255

Epoch: 6| Step: 5
Training loss: 2.3518333912700893
Validation loss: 2.4656146576190356

Epoch: 6| Step: 6
Training loss: 2.9829158711093764
Validation loss: 2.4908907019901725

Epoch: 6| Step: 7
Training loss: 2.1175910593245453
Validation loss: 2.484839431775626

Epoch: 6| Step: 8
Training loss: 2.6933643321654888
Validation loss: 2.499128326097408

Epoch: 6| Step: 9
Training loss: 2.104960930613483
Validation loss: 2.5119891185674392

Epoch: 6| Step: 10
Training loss: 2.9650177634416313
Validation loss: 2.4964018801044037

Epoch: 6| Step: 11
Training loss: 2.4487264281341288
Validation loss: 2.514880529872136

Epoch: 6| Step: 12
Training loss: 2.882981540923843
Validation loss: 2.51280983373744

Epoch: 6| Step: 13
Training loss: 2.9245806727651114
Validation loss: 2.519636199080514

Epoch: 220| Step: 0
Training loss: 3.3294245372171205
Validation loss: 2.488070706327085

Epoch: 6| Step: 1
Training loss: 1.9534992317254827
Validation loss: 2.505554497308731

Epoch: 6| Step: 2
Training loss: 2.905841429509213
Validation loss: 2.505104344367906

Epoch: 6| Step: 3
Training loss: 2.20886230131446
Validation loss: 2.503116764443577

Epoch: 6| Step: 4
Training loss: 3.1119187268036814
Validation loss: 2.4865555545766624

Epoch: 6| Step: 5
Training loss: 2.5620596902818993
Validation loss: 2.5071124392664106

Epoch: 6| Step: 6
Training loss: 2.444197915631045
Validation loss: 2.4714450941126

Epoch: 6| Step: 7
Training loss: 2.757877684084908
Validation loss: 2.5013543669845353

Epoch: 6| Step: 8
Training loss: 2.4784973480536716
Validation loss: 2.4708215027147737

Epoch: 6| Step: 9
Training loss: 1.994271299319455
Validation loss: 2.5246385196192516

Epoch: 6| Step: 10
Training loss: 2.7230061507363956
Validation loss: 2.4619993003651026

Epoch: 6| Step: 11
Training loss: 2.041747798734926
Validation loss: 2.465356979318789

Epoch: 6| Step: 12
Training loss: 2.7621142847392193
Validation loss: 2.4741527660154023

Epoch: 6| Step: 13
Training loss: 1.6439776360877123
Validation loss: 2.4897342817530315

Epoch: 221| Step: 0
Training loss: 2.6646912132139784
Validation loss: 2.4394128002785047

Epoch: 6| Step: 1
Training loss: 2.370321383676497
Validation loss: 2.4782194039443173

Epoch: 6| Step: 2
Training loss: 2.581245245017043
Validation loss: 2.4935236023313734

Epoch: 6| Step: 3
Training loss: 2.8036453733680644
Validation loss: 2.474889376734741

Epoch: 6| Step: 4
Training loss: 2.56901503631955
Validation loss: 2.4773484909445798

Epoch: 6| Step: 5
Training loss: 1.7857100214226078
Validation loss: 2.457150081888032

Epoch: 6| Step: 6
Training loss: 2.7533496916549
Validation loss: 2.4936486452777373

Epoch: 6| Step: 7
Training loss: 1.7486786622336365
Validation loss: 2.498068443771655

Epoch: 6| Step: 8
Training loss: 2.7004285825436942
Validation loss: 2.483729882329258

Epoch: 6| Step: 9
Training loss: 3.1204388710835125
Validation loss: 2.4813968988053046

Epoch: 6| Step: 10
Training loss: 2.572529401991139
Validation loss: 2.4597383582038543

Epoch: 6| Step: 11
Training loss: 2.2933935652445223
Validation loss: 2.4827487860327078

Epoch: 6| Step: 12
Training loss: 2.7390386429143216
Validation loss: 2.4649449916230473

Epoch: 6| Step: 13
Training loss: 2.4055860519923287
Validation loss: 2.478816851447696

Epoch: 222| Step: 0
Training loss: 2.67004313887704
Validation loss: 2.4976231032772254

Epoch: 6| Step: 1
Training loss: 2.45127964466772
Validation loss: 2.493892076838656

Epoch: 6| Step: 2
Training loss: 2.8681077026191404
Validation loss: 2.4664834416204267

Epoch: 6| Step: 3
Training loss: 2.358949938751901
Validation loss: 2.478577424284043

Epoch: 6| Step: 4
Training loss: 2.1401455753046554
Validation loss: 2.4643658482065756

Epoch: 6| Step: 5
Training loss: 2.0471100417442765
Validation loss: 2.470152774533491

Epoch: 6| Step: 6
Training loss: 1.835581643537757
Validation loss: 2.4701568735067987

Epoch: 6| Step: 7
Training loss: 2.996517385202251
Validation loss: 2.466780332021174

Epoch: 6| Step: 8
Training loss: 2.3574200545638164
Validation loss: 2.4882968484768866

Epoch: 6| Step: 9
Training loss: 2.934650743750092
Validation loss: 2.491183402412328

Epoch: 6| Step: 10
Training loss: 2.648848690194463
Validation loss: 2.4777534167690303

Epoch: 6| Step: 11
Training loss: 2.170506547089751
Validation loss: 2.4886742379385227

Epoch: 6| Step: 12
Training loss: 3.4787579751343074
Validation loss: 2.4732270565516727

Epoch: 6| Step: 13
Training loss: 2.35507467082674
Validation loss: 2.5118288464393794

Epoch: 223| Step: 0
Training loss: 1.8332870506455603
Validation loss: 2.482682198084733

Epoch: 6| Step: 1
Training loss: 2.412132602842362
Validation loss: 2.4932692063336264

Epoch: 6| Step: 2
Training loss: 3.2334081706664137
Validation loss: 2.500369329756394

Epoch: 6| Step: 3
Training loss: 2.0813877048701475
Validation loss: 2.4574539637659814

Epoch: 6| Step: 4
Training loss: 2.81763515036567
Validation loss: 2.497643589752358

Epoch: 6| Step: 5
Training loss: 3.2311242025594935
Validation loss: 2.4918150820107123

Epoch: 6| Step: 6
Training loss: 2.4454255976741073
Validation loss: 2.489316155634629

Epoch: 6| Step: 7
Training loss: 2.7110138368439896
Validation loss: 2.4651053199682083

Epoch: 6| Step: 8
Training loss: 2.1152803622078533
Validation loss: 2.480627902422814

Epoch: 6| Step: 9
Training loss: 2.5816474663956486
Validation loss: 2.48006674839134

Epoch: 6| Step: 10
Training loss: 2.489322845579236
Validation loss: 2.507647066023704

Epoch: 6| Step: 11
Training loss: 2.5554280272282663
Validation loss: 2.4665202056447018

Epoch: 6| Step: 12
Training loss: 2.4805278620847737
Validation loss: 2.4971737072779323

Epoch: 6| Step: 13
Training loss: 2.4594154131621426
Validation loss: 2.4416688282854953

Epoch: 224| Step: 0
Training loss: 2.1747263023663135
Validation loss: 2.477701833091068

Epoch: 6| Step: 1
Training loss: 2.5685674894888555
Validation loss: 2.5019206759915424

Epoch: 6| Step: 2
Training loss: 2.7727143540344366
Validation loss: 2.512568103412357

Epoch: 6| Step: 3
Training loss: 1.994428503645178
Validation loss: 2.47771998553619

Epoch: 6| Step: 4
Training loss: 2.144271306749844
Validation loss: 2.4730524900584077

Epoch: 6| Step: 5
Training loss: 3.0492642938026004
Validation loss: 2.5045899330673302

Epoch: 6| Step: 6
Training loss: 3.2044293980885246
Validation loss: 2.5112807823498007

Epoch: 6| Step: 7
Training loss: 2.9525139393424915
Validation loss: 2.4888042700613418

Epoch: 6| Step: 8
Training loss: 3.0943846388797502
Validation loss: 2.491107682181969

Epoch: 6| Step: 9
Training loss: 2.5302142626233683
Validation loss: 2.4598498171204763

Epoch: 6| Step: 10
Training loss: 2.5164312172533134
Validation loss: 2.5027557566501257

Epoch: 6| Step: 11
Training loss: 2.106221080547534
Validation loss: 2.502625262165646

Epoch: 6| Step: 12
Training loss: 1.9146271787430427
Validation loss: 2.466179472746942

Epoch: 6| Step: 13
Training loss: 1.8876347500025301
Validation loss: 2.4907164553700283

Epoch: 225| Step: 0
Training loss: 2.0539421789393852
Validation loss: 2.5042134239367875

Epoch: 6| Step: 1
Training loss: 2.602529718264182
Validation loss: 2.4802419990171454

Epoch: 6| Step: 2
Training loss: 2.5985129872434825
Validation loss: 2.5168995615284993

Epoch: 6| Step: 3
Training loss: 2.2490939329282185
Validation loss: 2.470952649664681

Epoch: 6| Step: 4
Training loss: 2.320255779767593
Validation loss: 2.514072718637422

Epoch: 6| Step: 5
Training loss: 2.532575472190092
Validation loss: 2.4982145599321424

Epoch: 6| Step: 6
Training loss: 2.871802168660448
Validation loss: 2.500055437601349

Epoch: 6| Step: 7
Training loss: 1.8738023111626154
Validation loss: 2.490308838064174

Epoch: 6| Step: 8
Training loss: 2.9184177773235356
Validation loss: 2.494008421571074

Epoch: 6| Step: 9
Training loss: 2.314771207045482
Validation loss: 2.4694493275369527

Epoch: 6| Step: 10
Training loss: 2.563238735247517
Validation loss: 2.486527126630548

Epoch: 6| Step: 11
Training loss: 2.6917938706266793
Validation loss: 2.482323471590657

Epoch: 6| Step: 12
Training loss: 2.8859812784308088
Validation loss: 2.524834268687311

Epoch: 6| Step: 13
Training loss: 3.5074727800853354
Validation loss: 2.490224528026797

Epoch: 226| Step: 0
Training loss: 2.4860908772682913
Validation loss: 2.4598058528173525

Epoch: 6| Step: 1
Training loss: 1.8268093363301767
Validation loss: 2.502934831308117

Epoch: 6| Step: 2
Training loss: 2.5618480690450065
Validation loss: 2.490248991480797

Epoch: 6| Step: 3
Training loss: 2.5302521422420163
Validation loss: 2.4967946628577717

Epoch: 6| Step: 4
Training loss: 2.4923260210817784
Validation loss: 2.4828566068914415

Epoch: 6| Step: 5
Training loss: 2.3575391890341995
Validation loss: 2.4855205897216686

Epoch: 6| Step: 6
Training loss: 1.9905662971117093
Validation loss: 2.498047688822476

Epoch: 6| Step: 7
Training loss: 3.361412530489865
Validation loss: 2.477638073953425

Epoch: 6| Step: 8
Training loss: 2.549106112115617
Validation loss: 2.447898065779546

Epoch: 6| Step: 9
Training loss: 2.4306038358222564
Validation loss: 2.473223111412865

Epoch: 6| Step: 10
Training loss: 2.6918771273726576
Validation loss: 2.507050318758512

Epoch: 6| Step: 11
Training loss: 2.8570623999575115
Validation loss: 2.4797589580451826

Epoch: 6| Step: 12
Training loss: 3.002389909566608
Validation loss: 2.4816601971143664

Epoch: 6| Step: 13
Training loss: 2.222769414236656
Validation loss: 2.464669946101035

Epoch: 227| Step: 0
Training loss: 2.35974896227279
Validation loss: 2.4831768006651016

Epoch: 6| Step: 1
Training loss: 2.1104675854197965
Validation loss: 2.4729092257029976

Epoch: 6| Step: 2
Training loss: 2.3493981016687044
Validation loss: 2.4553519771944026

Epoch: 6| Step: 3
Training loss: 2.5860213989292924
Validation loss: 2.458396403645706

Epoch: 6| Step: 4
Training loss: 2.897517549265789
Validation loss: 2.4911395887132755

Epoch: 6| Step: 5
Training loss: 2.7905600237997827
Validation loss: 2.4795821405226075

Epoch: 6| Step: 6
Training loss: 2.7697123695624826
Validation loss: 2.499656470086864

Epoch: 6| Step: 7
Training loss: 2.511205641571688
Validation loss: 2.5231206800375108

Epoch: 6| Step: 8
Training loss: 2.9584115962748716
Validation loss: 2.469032038877265

Epoch: 6| Step: 9
Training loss: 2.4149898982182294
Validation loss: 2.49558290535206

Epoch: 6| Step: 10
Training loss: 2.2511118155203533
Validation loss: 2.520155304374559

Epoch: 6| Step: 11
Training loss: 2.437219065591282
Validation loss: 2.5191578898677034

Epoch: 6| Step: 12
Training loss: 2.8046534119131032
Validation loss: 2.4704341167563055

Epoch: 6| Step: 13
Training loss: 2.0455221116822724
Validation loss: 2.5177084309761133

Epoch: 228| Step: 0
Training loss: 2.135504173408705
Validation loss: 2.5129680294963137

Epoch: 6| Step: 1
Training loss: 2.7212588255515295
Validation loss: 2.476350131779153

Epoch: 6| Step: 2
Training loss: 2.7076797479224846
Validation loss: 2.501377129420111

Epoch: 6| Step: 3
Training loss: 2.6752292035742458
Validation loss: 2.494427154777938

Epoch: 6| Step: 4
Training loss: 2.4019118998599263
Validation loss: 2.470009113650501

Epoch: 6| Step: 5
Training loss: 2.5322525487964724
Validation loss: 2.492649807635529

Epoch: 6| Step: 6
Training loss: 2.5847592161622885
Validation loss: 2.5068185808557772

Epoch: 6| Step: 7
Training loss: 2.8652803070193618
Validation loss: 2.4633167272291616

Epoch: 6| Step: 8
Training loss: 2.9560025843504474
Validation loss: 2.5007645781182926

Epoch: 6| Step: 9
Training loss: 2.4300088455290374
Validation loss: 2.522916122719223

Epoch: 6| Step: 10
Training loss: 3.000255891694809
Validation loss: 2.523275871234877

Epoch: 6| Step: 11
Training loss: 2.415136993187305
Validation loss: 2.5008764699444654

Epoch: 6| Step: 12
Training loss: 1.943713346669304
Validation loss: 2.463684541663234

Epoch: 6| Step: 13
Training loss: 1.929950958676442
Validation loss: 2.476602322319178

Epoch: 229| Step: 0
Training loss: 2.741655173079527
Validation loss: 2.4798204937390977

Epoch: 6| Step: 1
Training loss: 2.561849837280795
Validation loss: 2.4642875967933833

Epoch: 6| Step: 2
Training loss: 2.283768295941407
Validation loss: 2.485639707755656

Epoch: 6| Step: 3
Training loss: 2.9148483239523717
Validation loss: 2.479602846356789

Epoch: 6| Step: 4
Training loss: 2.6658054590352918
Validation loss: 2.4801349043483496

Epoch: 6| Step: 5
Training loss: 2.267881335375106
Validation loss: 2.4728887219602145

Epoch: 6| Step: 6
Training loss: 2.3545176039106703
Validation loss: 2.4885871673268785

Epoch: 6| Step: 7
Training loss: 2.5984096725175787
Validation loss: 2.503618565637896

Epoch: 6| Step: 8
Training loss: 2.2914320623359683
Validation loss: 2.476609492752967

Epoch: 6| Step: 9
Training loss: 1.946477946883827
Validation loss: 2.4865158813514032

Epoch: 6| Step: 10
Training loss: 2.8212310901256568
Validation loss: 2.4743874803398413

Epoch: 6| Step: 11
Training loss: 2.6641233554724577
Validation loss: 2.5095516871611174

Epoch: 6| Step: 12
Training loss: 2.3017468328784587
Validation loss: 2.4803902810400436

Epoch: 6| Step: 13
Training loss: 3.3700440364869606
Validation loss: 2.491531621626354

Epoch: 230| Step: 0
Training loss: 2.868903288558463
Validation loss: 2.4746135002605785

Epoch: 6| Step: 1
Training loss: 2.752164249159524
Validation loss: 2.4774181259118686

Epoch: 6| Step: 2
Training loss: 2.7288009942148275
Validation loss: 2.5067114961297734

Epoch: 6| Step: 3
Training loss: 2.53124406601952
Validation loss: 2.4928599738191424

Epoch: 6| Step: 4
Training loss: 3.1200814258513945
Validation loss: 2.4895096922998055

Epoch: 6| Step: 5
Training loss: 2.0371121839026656
Validation loss: 2.4935108505306376

Epoch: 6| Step: 6
Training loss: 2.407911247392101
Validation loss: 2.4791245777931192

Epoch: 6| Step: 7
Training loss: 2.228337273243531
Validation loss: 2.4987753606588194

Epoch: 6| Step: 8
Training loss: 2.890139647281102
Validation loss: 2.473051495929947

Epoch: 6| Step: 9
Training loss: 2.393645030775389
Validation loss: 2.489737530405302

Epoch: 6| Step: 10
Training loss: 2.0360446389406675
Validation loss: 2.5091710265353284

Epoch: 6| Step: 11
Training loss: 2.3714253478102187
Validation loss: 2.4633362178904106

Epoch: 6| Step: 12
Training loss: 2.6483168672978423
Validation loss: 2.484683252374817

Epoch: 6| Step: 13
Training loss: 2.4420529416943118
Validation loss: 2.48143060696982

Epoch: 231| Step: 0
Training loss: 2.323102410478348
Validation loss: 2.477534481127468

Epoch: 6| Step: 1
Training loss: 2.4773333099058634
Validation loss: 2.481129268016012

Epoch: 6| Step: 2
Training loss: 2.775440449170122
Validation loss: 2.459126773209479

Epoch: 6| Step: 3
Training loss: 2.3991018363070125
Validation loss: 2.4959482851608152

Epoch: 6| Step: 4
Training loss: 2.403744669019131
Validation loss: 2.4879020481436243

Epoch: 6| Step: 5
Training loss: 2.949877371098094
Validation loss: 2.4691931598216565

Epoch: 6| Step: 6
Training loss: 2.5982593725353467
Validation loss: 2.491570263230034

Epoch: 6| Step: 7
Training loss: 2.6835266726799305
Validation loss: 2.5171716575256164

Epoch: 6| Step: 8
Training loss: 2.638350551193197
Validation loss: 2.5019441894736465

Epoch: 6| Step: 9
Training loss: 2.356019823887944
Validation loss: 2.471367545582069

Epoch: 6| Step: 10
Training loss: 1.947678563326418
Validation loss: 2.490293878097343

Epoch: 6| Step: 11
Training loss: 3.0423048908799832
Validation loss: 2.4813864278674735

Epoch: 6| Step: 12
Training loss: 2.600586487572698
Validation loss: 2.471290260703321

Epoch: 6| Step: 13
Training loss: 1.5206838124947666
Validation loss: 2.4980389358553547

Epoch: 232| Step: 0
Training loss: 2.539958338057895
Validation loss: 2.4787434290521233

Epoch: 6| Step: 1
Training loss: 2.817955236611408
Validation loss: 2.502646980987765

Epoch: 6| Step: 2
Training loss: 1.718409279083261
Validation loss: 2.4848102119498985

Epoch: 6| Step: 3
Training loss: 1.8108945510682009
Validation loss: 2.470233350622184

Epoch: 6| Step: 4
Training loss: 2.5637985288880474
Validation loss: 2.490133085722374

Epoch: 6| Step: 5
Training loss: 2.5882591129165764
Validation loss: 2.5023429833082136

Epoch: 6| Step: 6
Training loss: 2.556560051728827
Validation loss: 2.4966703014131553

Epoch: 6| Step: 7
Training loss: 2.4937214211568763
Validation loss: 2.4966090010731192

Epoch: 6| Step: 8
Training loss: 2.425505249244233
Validation loss: 2.4718724841020827

Epoch: 6| Step: 9
Training loss: 2.668117803875317
Validation loss: 2.467807756632318

Epoch: 6| Step: 10
Training loss: 2.02981963046936
Validation loss: 2.481853526125325

Epoch: 6| Step: 11
Training loss: 2.9065672998621466
Validation loss: 2.5040754201865796

Epoch: 6| Step: 12
Training loss: 3.4179549385881667
Validation loss: 2.484880128385277

Epoch: 6| Step: 13
Training loss: 2.91403468223569
Validation loss: 2.4788051864589145

Epoch: 233| Step: 0
Training loss: 2.6749180647521165
Validation loss: 2.4594065122798914

Epoch: 6| Step: 1
Training loss: 2.696661746897255
Validation loss: 2.4688346373719066

Epoch: 6| Step: 2
Training loss: 1.9315584201890006
Validation loss: 2.467725072434876

Epoch: 6| Step: 3
Training loss: 2.937870570407137
Validation loss: 2.4834393115353888

Epoch: 6| Step: 4
Training loss: 2.821911472156675
Validation loss: 2.4905435136125145

Epoch: 6| Step: 5
Training loss: 2.7435770453856922
Validation loss: 2.464503400615576

Epoch: 6| Step: 6
Training loss: 2.869331244465565
Validation loss: 2.499845118493359

Epoch: 6| Step: 7
Training loss: 2.0802276987375614
Validation loss: 2.5214434842706637

Epoch: 6| Step: 8
Training loss: 2.512279489434292
Validation loss: 2.4573713703963485

Epoch: 6| Step: 9
Training loss: 2.869914989740958
Validation loss: 2.484650336386348

Epoch: 6| Step: 10
Training loss: 2.2534430968432395
Validation loss: 2.492646372509746

Epoch: 6| Step: 11
Training loss: 2.6495314057823602
Validation loss: 2.4655485713242746

Epoch: 6| Step: 12
Training loss: 2.1324789044856156
Validation loss: 2.4796032733539963

Epoch: 6| Step: 13
Training loss: 1.7408850895023729
Validation loss: 2.5030911972104555

Epoch: 234| Step: 0
Training loss: 3.2038626961118526
Validation loss: 2.494710514292591

Epoch: 6| Step: 1
Training loss: 2.878340728991766
Validation loss: 2.4964309524442254

Epoch: 6| Step: 2
Training loss: 3.124938964247692
Validation loss: 2.493248992899154

Epoch: 6| Step: 3
Training loss: 2.3113753187123542
Validation loss: 2.506099096822714

Epoch: 6| Step: 4
Training loss: 2.4911321719528305
Validation loss: 2.501868991151748

Epoch: 6| Step: 5
Training loss: 2.3371723700221225
Validation loss: 2.48111136059911

Epoch: 6| Step: 6
Training loss: 2.840150000680807
Validation loss: 2.5396946728229635

Epoch: 6| Step: 7
Training loss: 1.908192004949367
Validation loss: 2.4993703910731537

Epoch: 6| Step: 8
Training loss: 2.1851485556725123
Validation loss: 2.5100741899346977

Epoch: 6| Step: 9
Training loss: 2.369160148118755
Validation loss: 2.4923682124005078

Epoch: 6| Step: 10
Training loss: 2.502311972643511
Validation loss: 2.489156844986993

Epoch: 6| Step: 11
Training loss: 2.119967279181692
Validation loss: 2.5180105593427506

Epoch: 6| Step: 12
Training loss: 2.1017081624995853
Validation loss: 2.476887668234845

Epoch: 6| Step: 13
Training loss: 2.3414584337642848
Validation loss: 2.4723963924050207

Epoch: 235| Step: 0
Training loss: 2.6014867089947655
Validation loss: 2.5070784966071287

Epoch: 6| Step: 1
Training loss: 2.013718760820553
Validation loss: 2.499764805672106

Epoch: 6| Step: 2
Training loss: 1.8548562414188778
Validation loss: 2.4844831846981807

Epoch: 6| Step: 3
Training loss: 2.343529550993154
Validation loss: 2.471828746081581

Epoch: 6| Step: 4
Training loss: 2.524908717554443
Validation loss: 2.5053250124438855

Epoch: 6| Step: 5
Training loss: 3.106925574662074
Validation loss: 2.479645578797539

Epoch: 6| Step: 6
Training loss: 1.9413391347294537
Validation loss: 2.466047227820014

Epoch: 6| Step: 7
Training loss: 3.252417912074073
Validation loss: 2.494422920455696

Epoch: 6| Step: 8
Training loss: 3.104378678081769
Validation loss: 2.4807072381494804

Epoch: 6| Step: 9
Training loss: 2.6522884672131286
Validation loss: 2.529668193469512

Epoch: 6| Step: 10
Training loss: 2.0794554158866103
Validation loss: 2.514122405856853

Epoch: 6| Step: 11
Training loss: 2.5093776299069734
Validation loss: 2.498036977748065

Epoch: 6| Step: 12
Training loss: 2.70639581089265
Validation loss: 2.4784002286991473

Epoch: 6| Step: 13
Training loss: 2.067936984727227
Validation loss: 2.503630904495723

Epoch: 236| Step: 0
Training loss: 2.9434742338757993
Validation loss: 2.475512145878809

Epoch: 6| Step: 1
Training loss: 2.1426139557310497
Validation loss: 2.5036826676455792

Epoch: 6| Step: 2
Training loss: 2.281095943735995
Validation loss: 2.504010190776183

Epoch: 6| Step: 3
Training loss: 2.5247284507145342
Validation loss: 2.4939352706416322

Epoch: 6| Step: 4
Training loss: 3.021223494666378
Validation loss: 2.46587969360524

Epoch: 6| Step: 5
Training loss: 2.1150323801289996
Validation loss: 2.479857899474615

Epoch: 6| Step: 6
Training loss: 2.238710904783767
Validation loss: 2.501487873690035

Epoch: 6| Step: 7
Training loss: 2.044235974316313
Validation loss: 2.477672323702428

Epoch: 6| Step: 8
Training loss: 2.65752981432952
Validation loss: 2.481565792492725

Epoch: 6| Step: 9
Training loss: 2.4277211171261586
Validation loss: 2.487406164097768

Epoch: 6| Step: 10
Training loss: 2.3001009545768025
Validation loss: 2.482175022577804

Epoch: 6| Step: 11
Training loss: 2.8972013978909725
Validation loss: 2.4781164080220734

Epoch: 6| Step: 12
Training loss: 3.277753147384719
Validation loss: 2.5082557502969034

Epoch: 6| Step: 13
Training loss: 2.25496211187163
Validation loss: 2.454332575813609

Epoch: 237| Step: 0
Training loss: 2.438782085792251
Validation loss: 2.466094071656661

Epoch: 6| Step: 1
Training loss: 2.5153789518405185
Validation loss: 2.482012684778753

Epoch: 6| Step: 2
Training loss: 2.385994409508243
Validation loss: 2.46568223207423

Epoch: 6| Step: 3
Training loss: 2.8241599935537387
Validation loss: 2.475600632701614

Epoch: 6| Step: 4
Training loss: 3.5241473850947433
Validation loss: 2.4822994143978607

Epoch: 6| Step: 5
Training loss: 2.2928129854860764
Validation loss: 2.5002431710224293

Epoch: 6| Step: 6
Training loss: 2.1001491402845627
Validation loss: 2.4768764288729717

Epoch: 6| Step: 7
Training loss: 2.0716260665552912
Validation loss: 2.4913424538138447

Epoch: 6| Step: 8
Training loss: 2.4182783430890087
Validation loss: 2.472683459530099

Epoch: 6| Step: 9
Training loss: 2.639686372507658
Validation loss: 2.488291986584309

Epoch: 6| Step: 10
Training loss: 2.2978854908446644
Validation loss: 2.4939028159946535

Epoch: 6| Step: 11
Training loss: 2.537799039611707
Validation loss: 2.508994230048548

Epoch: 6| Step: 12
Training loss: 2.5867177471872114
Validation loss: 2.494448568827612

Epoch: 6| Step: 13
Training loss: 2.313457703100894
Validation loss: 2.480320372926566

Epoch: 238| Step: 0
Training loss: 2.4085707929112923
Validation loss: 2.4847910687359924

Epoch: 6| Step: 1
Training loss: 1.8617304780360961
Validation loss: 2.4775143338526955

Epoch: 6| Step: 2
Training loss: 3.0470707757114575
Validation loss: 2.4935850687357144

Epoch: 6| Step: 3
Training loss: 2.3896153131643736
Validation loss: 2.5043562712708756

Epoch: 6| Step: 4
Training loss: 2.9213279171151614
Validation loss: 2.4760317435710637

Epoch: 6| Step: 5
Training loss: 2.624473700669407
Validation loss: 2.484245135405556

Epoch: 6| Step: 6
Training loss: 2.500683023608592
Validation loss: 2.483757121243551

Epoch: 6| Step: 7
Training loss: 2.6664355495753242
Validation loss: 2.47618573281689

Epoch: 6| Step: 8
Training loss: 2.6178839368978664
Validation loss: 2.4708213221782653

Epoch: 6| Step: 9
Training loss: 2.6494615763570315
Validation loss: 2.4759267240213645

Epoch: 6| Step: 10
Training loss: 2.2581888169035125
Validation loss: 2.5065573504810468

Epoch: 6| Step: 11
Training loss: 2.4264497926062303
Validation loss: 2.4795363124698007

Epoch: 6| Step: 12
Training loss: 2.4106430971644763
Validation loss: 2.485788324229457

Epoch: 6| Step: 13
Training loss: 2.0650489546397184
Validation loss: 2.4664640527449238

Epoch: 239| Step: 0
Training loss: 2.831491732014557
Validation loss: 2.5011947525191536

Epoch: 6| Step: 1
Training loss: 2.118183647687809
Validation loss: 2.497918687979533

Epoch: 6| Step: 2
Training loss: 2.317902311858577
Validation loss: 2.4688966021423093

Epoch: 6| Step: 3
Training loss: 2.6861590211425
Validation loss: 2.476660836261686

Epoch: 6| Step: 4
Training loss: 2.423565379248403
Validation loss: 2.4554860217573466

Epoch: 6| Step: 5
Training loss: 2.442356943804178
Validation loss: 2.4895409983634718

Epoch: 6| Step: 6
Training loss: 3.187279338304583
Validation loss: 2.481319457762195

Epoch: 6| Step: 7
Training loss: 2.2822184140178665
Validation loss: 2.4804222809903433

Epoch: 6| Step: 8
Training loss: 2.1459495982057804
Validation loss: 2.438532639733332

Epoch: 6| Step: 9
Training loss: 2.574764118686646
Validation loss: 2.465109048265192

Epoch: 6| Step: 10
Training loss: 2.4332708202675724
Validation loss: 2.487364635843993

Epoch: 6| Step: 11
Training loss: 2.727170247984698
Validation loss: 2.4895109599553717

Epoch: 6| Step: 12
Training loss: 2.1461690127823116
Validation loss: 2.516099538944455

Epoch: 6| Step: 13
Training loss: 2.8988120770109793
Validation loss: 2.48821872735596

Epoch: 240| Step: 0
Training loss: 2.7702082356703492
Validation loss: 2.4987471194436037

Epoch: 6| Step: 1
Training loss: 2.7375907952566925
Validation loss: 2.511162291552831

Epoch: 6| Step: 2
Training loss: 2.6976743218606227
Validation loss: 2.513869474868566

Epoch: 6| Step: 3
Training loss: 2.699304957469231
Validation loss: 2.4753693438972557

Epoch: 6| Step: 4
Training loss: 2.4284456765451155
Validation loss: 2.503770601723959

Epoch: 6| Step: 5
Training loss: 2.254024191800181
Validation loss: 2.5133688589060403

Epoch: 6| Step: 6
Training loss: 2.2856561619316613
Validation loss: 2.485234201825225

Epoch: 6| Step: 7
Training loss: 2.864996215658035
Validation loss: 2.4818898321284975

Epoch: 6| Step: 8
Training loss: 2.684459385639081
Validation loss: 2.4879208835354056

Epoch: 6| Step: 9
Training loss: 2.2810429518291846
Validation loss: 2.512320609931305

Epoch: 6| Step: 10
Training loss: 1.9660166582195402
Validation loss: 2.495183819641931

Epoch: 6| Step: 11
Training loss: 2.153647247892113
Validation loss: 2.470800130835773

Epoch: 6| Step: 12
Training loss: 2.3341733464948176
Validation loss: 2.503682019486468

Epoch: 6| Step: 13
Training loss: 2.9141037352561736
Validation loss: 2.502909921330546

Epoch: 241| Step: 0
Training loss: 2.212927902998566
Validation loss: 2.5081604731594114

Epoch: 6| Step: 1
Training loss: 2.263461217549267
Validation loss: 2.492180787913661

Epoch: 6| Step: 2
Training loss: 2.5846816410316067
Validation loss: 2.5046739458343983

Epoch: 6| Step: 3
Training loss: 2.713893191558575
Validation loss: 2.4967761670189574

Epoch: 6| Step: 4
Training loss: 2.112257281021426
Validation loss: 2.467994228457804

Epoch: 6| Step: 5
Training loss: 2.641918520148199
Validation loss: 2.4725240891652183

Epoch: 6| Step: 6
Training loss: 2.2031569241855355
Validation loss: 2.464845399570155

Epoch: 6| Step: 7
Training loss: 2.3658229810544884
Validation loss: 2.467628788269321

Epoch: 6| Step: 8
Training loss: 2.6995922663790552
Validation loss: 2.4757680369469917

Epoch: 6| Step: 9
Training loss: 2.7369286520107736
Validation loss: 2.478778300100284

Epoch: 6| Step: 10
Training loss: 2.98116621303578
Validation loss: 2.4922267537705216

Epoch: 6| Step: 11
Training loss: 2.9326301952966594
Validation loss: 2.482453680431339

Epoch: 6| Step: 12
Training loss: 2.4866855840841233
Validation loss: 2.4703817658967675

Epoch: 6| Step: 13
Training loss: 1.4560293071333423
Validation loss: 2.5104337935147916

Epoch: 242| Step: 0
Training loss: 2.1938218455491194
Validation loss: 2.4995891212893167

Epoch: 6| Step: 1
Training loss: 2.4586737014576086
Validation loss: 2.4573906056741777

Epoch: 6| Step: 2
Training loss: 2.4141756790444124
Validation loss: 2.4898620303937116

Epoch: 6| Step: 3
Training loss: 2.4627008811227586
Validation loss: 2.4944124476715093

Epoch: 6| Step: 4
Training loss: 3.2557048612200066
Validation loss: 2.454686002809914

Epoch: 6| Step: 5
Training loss: 2.0414418336764886
Validation loss: 2.4787770171307537

Epoch: 6| Step: 6
Training loss: 1.7342392464510987
Validation loss: 2.4781886479617845

Epoch: 6| Step: 7
Training loss: 2.8340918890594082
Validation loss: 2.475837120715153

Epoch: 6| Step: 8
Training loss: 1.8408439493053097
Validation loss: 2.4755412781739152

Epoch: 6| Step: 9
Training loss: 2.4894928430261687
Validation loss: 2.486690085193936

Epoch: 6| Step: 10
Training loss: 2.601050065810871
Validation loss: 2.49271644711054

Epoch: 6| Step: 11
Training loss: 2.5399977619431615
Validation loss: 2.5007299465066724

Epoch: 6| Step: 12
Training loss: 2.6138303262562372
Validation loss: 2.453927909274734

Epoch: 6| Step: 13
Training loss: 3.342311656727026
Validation loss: 2.496753805183586

Epoch: 243| Step: 0
Training loss: 2.602932955651884
Validation loss: 2.487931581488074

Epoch: 6| Step: 1
Training loss: 2.4220630203603637
Validation loss: 2.4837217972995917

Epoch: 6| Step: 2
Training loss: 2.9036266012652514
Validation loss: 2.500761197195272

Epoch: 6| Step: 3
Training loss: 2.195343343171901
Validation loss: 2.4773507147985403

Epoch: 6| Step: 4
Training loss: 3.0925470961343633
Validation loss: 2.5057371656406837

Epoch: 6| Step: 5
Training loss: 2.3168327363499195
Validation loss: 2.4647731294726345

Epoch: 6| Step: 6
Training loss: 2.8334312609036614
Validation loss: 2.5270573490411374

Epoch: 6| Step: 7
Training loss: 2.40901916488682
Validation loss: 2.482496186177174

Epoch: 6| Step: 8
Training loss: 1.7132391232565964
Validation loss: 2.496468054871503

Epoch: 6| Step: 9
Training loss: 2.9609481287944126
Validation loss: 2.5050993339590053

Epoch: 6| Step: 10
Training loss: 1.9307097534268425
Validation loss: 2.4958950612428223

Epoch: 6| Step: 11
Training loss: 2.4832732438705056
Validation loss: 2.4827775773376404

Epoch: 6| Step: 12
Training loss: 2.0461031790825954
Validation loss: 2.45767553263208

Epoch: 6| Step: 13
Training loss: 2.2972975361707166
Validation loss: 2.4958205080508296

Epoch: 244| Step: 0
Training loss: 2.4430759915100815
Validation loss: 2.4741947812793406

Epoch: 6| Step: 1
Training loss: 2.4238107144255334
Validation loss: 2.477941216568809

Epoch: 6| Step: 2
Training loss: 2.2669621172189363
Validation loss: 2.4496309692664466

Epoch: 6| Step: 3
Training loss: 2.0964276855719395
Validation loss: 2.4731592357752166

Epoch: 6| Step: 4
Training loss: 2.205038984304415
Validation loss: 2.5143766282064233

Epoch: 6| Step: 5
Training loss: 2.2209066735540057
Validation loss: 2.4704341136431194

Epoch: 6| Step: 6
Training loss: 2.453222576557585
Validation loss: 2.485514530062716

Epoch: 6| Step: 7
Training loss: 3.0175316668146985
Validation loss: 2.4823600206444816

Epoch: 6| Step: 8
Training loss: 2.489092684058097
Validation loss: 2.4592747037362757

Epoch: 6| Step: 9
Training loss: 2.7368729870517225
Validation loss: 2.4644630036259865

Epoch: 6| Step: 10
Training loss: 2.361010963210908
Validation loss: 2.4903702592541475

Epoch: 6| Step: 11
Training loss: 2.309268859158542
Validation loss: 2.5179592393884866

Epoch: 6| Step: 12
Training loss: 2.9198632480004822
Validation loss: 2.485122204036307

Epoch: 6| Step: 13
Training loss: 3.0667592228176805
Validation loss: 2.4863613652201946

Epoch: 245| Step: 0
Training loss: 2.5715568336408627
Validation loss: 2.4844792398914737

Epoch: 6| Step: 1
Training loss: 2.4673817379949967
Validation loss: 2.4438661404050457

Epoch: 6| Step: 2
Training loss: 1.972401698845569
Validation loss: 2.502374578568574

Epoch: 6| Step: 3
Training loss: 2.7899401910585535
Validation loss: 2.489731144302583

Epoch: 6| Step: 4
Training loss: 3.0291361566307504
Validation loss: 2.4758304243592932

Epoch: 6| Step: 5
Training loss: 2.2911996076487626
Validation loss: 2.514414431879126

Epoch: 6| Step: 6
Training loss: 2.7506948806910874
Validation loss: 2.460996089510663

Epoch: 6| Step: 7
Training loss: 2.0785120553407377
Validation loss: 2.4799300804149373

Epoch: 6| Step: 8
Training loss: 2.6402852217892447
Validation loss: 2.506152874307416

Epoch: 6| Step: 9
Training loss: 2.411847033114874
Validation loss: 2.478090321635532

Epoch: 6| Step: 10
Training loss: 2.7655475842691506
Validation loss: 2.4972615512845286

Epoch: 6| Step: 11
Training loss: 1.8802669301152715
Validation loss: 2.4625179405676985

Epoch: 6| Step: 12
Training loss: 2.5139886497902917
Validation loss: 2.5000934009127116

Epoch: 6| Step: 13
Training loss: 2.143429443593394
Validation loss: 2.459525482693742

Epoch: 246| Step: 0
Training loss: 2.169470794242018
Validation loss: 2.48351889809818

Epoch: 6| Step: 1
Training loss: 2.5181617977647264
Validation loss: 2.4756844761650014

Epoch: 6| Step: 2
Training loss: 2.4862993572815313
Validation loss: 2.484150031283553

Epoch: 6| Step: 3
Training loss: 2.7023060169877584
Validation loss: 2.4597251477612865

Epoch: 6| Step: 4
Training loss: 2.149611051996552
Validation loss: 2.4986534460753105

Epoch: 6| Step: 5
Training loss: 2.0867918172402766
Validation loss: 2.47802623729963

Epoch: 6| Step: 6
Training loss: 3.1383508448045525
Validation loss: 2.4771122315673026

Epoch: 6| Step: 7
Training loss: 2.622925801724582
Validation loss: 2.518206162407063

Epoch: 6| Step: 8
Training loss: 2.993908419628441
Validation loss: 2.478900621808793

Epoch: 6| Step: 9
Training loss: 2.6525438370888845
Validation loss: 2.495359413505839

Epoch: 6| Step: 10
Training loss: 2.6869362528159795
Validation loss: 2.4964174298946493

Epoch: 6| Step: 11
Training loss: 2.3809026349638356
Validation loss: 2.4850231544616075

Epoch: 6| Step: 12
Training loss: 1.9101196784826622
Validation loss: 2.4862903123946016

Epoch: 6| Step: 13
Training loss: 1.7023132209438772
Validation loss: 2.4969169105048374

Epoch: 247| Step: 0
Training loss: 2.481934122088892
Validation loss: 2.4737385579768016

Epoch: 6| Step: 1
Training loss: 2.6336821526260135
Validation loss: 2.4806428597080323

Epoch: 6| Step: 2
Training loss: 1.835556705023955
Validation loss: 2.485004155770857

Epoch: 6| Step: 3
Training loss: 2.3272004820030134
Validation loss: 2.496388201302488

Epoch: 6| Step: 4
Training loss: 1.9619718460528377
Validation loss: 2.4623154581616027

Epoch: 6| Step: 5
Training loss: 3.039399822117275
Validation loss: 2.4839485748234433

Epoch: 6| Step: 6
Training loss: 1.7754080827146352
Validation loss: 2.4686215763067167

Epoch: 6| Step: 7
Training loss: 2.410566941052441
Validation loss: 2.492363112615006

Epoch: 6| Step: 8
Training loss: 2.6450412996525547
Validation loss: 2.482435928180635

Epoch: 6| Step: 9
Training loss: 2.1637385707753913
Validation loss: 2.4837270247547556

Epoch: 6| Step: 10
Training loss: 2.9136821917969917
Validation loss: 2.4588559797682286

Epoch: 6| Step: 11
Training loss: 2.3245008281428126
Validation loss: 2.4678996298500238

Epoch: 6| Step: 12
Training loss: 3.0002781421151123
Validation loss: 2.4949376822262685

Epoch: 6| Step: 13
Training loss: 3.0417722570477097
Validation loss: 2.4899922239061336

Epoch: 248| Step: 0
Training loss: 2.6582988242497434
Validation loss: 2.4684513379200475

Epoch: 6| Step: 1
Training loss: 2.268598302388256
Validation loss: 2.467536245235855

Epoch: 6| Step: 2
Training loss: 2.549449719163811
Validation loss: 2.503817808739317

Epoch: 6| Step: 3
Training loss: 2.6534698298183734
Validation loss: 2.507191874581981

Epoch: 6| Step: 4
Training loss: 2.0504326805704376
Validation loss: 2.4756161500480713

Epoch: 6| Step: 5
Training loss: 2.6439192048163425
Validation loss: 2.5241310606341147

Epoch: 6| Step: 6
Training loss: 2.2178272961384584
Validation loss: 2.501424905827349

Epoch: 6| Step: 7
Training loss: 2.492810784251204
Validation loss: 2.452457280410728

Epoch: 6| Step: 8
Training loss: 2.1122581840119103
Validation loss: 2.4707288525501703

Epoch: 6| Step: 9
Training loss: 2.636213511345142
Validation loss: 2.4695254357152363

Epoch: 6| Step: 10
Training loss: 2.8067998130851555
Validation loss: 2.4815232553139035

Epoch: 6| Step: 11
Training loss: 2.895408507730082
Validation loss: 2.49601160430656

Epoch: 6| Step: 12
Training loss: 1.8222132897093466
Validation loss: 2.5026208675692403

Epoch: 6| Step: 13
Training loss: 2.8548277671691853
Validation loss: 2.4962382307111044

Epoch: 249| Step: 0
Training loss: 2.4571502123054096
Validation loss: 2.4899146131244754

Epoch: 6| Step: 1
Training loss: 2.454087767010071
Validation loss: 2.4748649644852865

Epoch: 6| Step: 2
Training loss: 2.2313260703917006
Validation loss: 2.487799355190771

Epoch: 6| Step: 3
Training loss: 2.527865560868149
Validation loss: 2.4672609591790224

Epoch: 6| Step: 4
Training loss: 2.3661539068524444
Validation loss: 2.4724546398675873

Epoch: 6| Step: 5
Training loss: 2.538648178335127
Validation loss: 2.480233802872569

Epoch: 6| Step: 6
Training loss: 3.292547341529932
Validation loss: 2.485658381863106

Epoch: 6| Step: 7
Training loss: 2.771287283364844
Validation loss: 2.4803238344255685

Epoch: 6| Step: 8
Training loss: 2.2848391581882264
Validation loss: 2.4873976705116165

Epoch: 6| Step: 9
Training loss: 1.813702809030764
Validation loss: 2.4884432200673783

Epoch: 6| Step: 10
Training loss: 2.493411155376967
Validation loss: 2.4864170203021208

Epoch: 6| Step: 11
Training loss: 2.0699886428595167
Validation loss: 2.4636669169154852

Epoch: 6| Step: 12
Training loss: 2.878860204113618
Validation loss: 2.4857453243025516

Epoch: 6| Step: 13
Training loss: 1.768342012185753
Validation loss: 2.496640711511348

Epoch: 250| Step: 0
Training loss: 3.060238840343794
Validation loss: 2.4405834803122612

Epoch: 6| Step: 1
Training loss: 2.7183799053282423
Validation loss: 2.4858559345185425

Epoch: 6| Step: 2
Training loss: 2.011992263718401
Validation loss: 2.4859276669855905

Epoch: 6| Step: 3
Training loss: 2.542545500191576
Validation loss: 2.4810116115143814

Epoch: 6| Step: 4
Training loss: 2.5417229901519542
Validation loss: 2.4714137854771057

Epoch: 6| Step: 5
Training loss: 2.2727604542824236
Validation loss: 2.5163656938022276

Epoch: 6| Step: 6
Training loss: 3.0634726711901488
Validation loss: 2.496700297581671

Epoch: 6| Step: 7
Training loss: 1.5540224119163408
Validation loss: 2.50403736777076

Epoch: 6| Step: 8
Training loss: 2.4198036442062136
Validation loss: 2.493701781439647

Epoch: 6| Step: 9
Training loss: 2.2069086361474057
Validation loss: 2.4984122802825808

Epoch: 6| Step: 10
Training loss: 2.3443307792786707
Validation loss: 2.49692513351136

Epoch: 6| Step: 11
Training loss: 2.6618543854000514
Validation loss: 2.4954875285824185

Epoch: 6| Step: 12
Training loss: 2.314520391460523
Validation loss: 2.472593390320205

Epoch: 6| Step: 13
Training loss: 2.6183622086760177
Validation loss: 2.497579321456843

Epoch: 251| Step: 0
Training loss: 2.4262500254706216
Validation loss: 2.5011954074726113

Epoch: 6| Step: 1
Training loss: 2.2289660948839787
Validation loss: 2.4820537618704273

Epoch: 6| Step: 2
Training loss: 2.1651105305426217
Validation loss: 2.481200413358121

Epoch: 6| Step: 3
Training loss: 2.4295760248744083
Validation loss: 2.496642804202299

Epoch: 6| Step: 4
Training loss: 2.1887541309363456
Validation loss: 2.524087146474461

Epoch: 6| Step: 5
Training loss: 2.346775391111839
Validation loss: 2.494213355689149

Epoch: 6| Step: 6
Training loss: 2.385192882807552
Validation loss: 2.4919678325745713

Epoch: 6| Step: 7
Training loss: 2.5939757467178732
Validation loss: 2.461300198570082

Epoch: 6| Step: 8
Training loss: 2.7861044020195362
Validation loss: 2.4674737086344076

Epoch: 6| Step: 9
Training loss: 2.4841751881986145
Validation loss: 2.464882580130955

Epoch: 6| Step: 10
Training loss: 2.275456217201053
Validation loss: 2.4744737638484025

Epoch: 6| Step: 11
Training loss: 2.1995364784568263
Validation loss: 2.442155428357042

Epoch: 6| Step: 12
Training loss: 3.2473336065714227
Validation loss: 2.5039712425419074

Epoch: 6| Step: 13
Training loss: 3.0253630428152785
Validation loss: 2.5033111241288344

Epoch: 252| Step: 0
Training loss: 2.4442869723296785
Validation loss: 2.4785456684073703

Epoch: 6| Step: 1
Training loss: 2.7267212917138317
Validation loss: 2.4498667698962038

Epoch: 6| Step: 2
Training loss: 2.4991768435476325
Validation loss: 2.4743495629659673

Epoch: 6| Step: 3
Training loss: 2.131761676300486
Validation loss: 2.4700543659968193

Epoch: 6| Step: 4
Training loss: 2.1143807249924804
Validation loss: 2.44698544089063

Epoch: 6| Step: 5
Training loss: 2.9551500915518036
Validation loss: 2.472102567861864

Epoch: 6| Step: 6
Training loss: 2.505336787260854
Validation loss: 2.4800266798564423

Epoch: 6| Step: 7
Training loss: 1.9268207336762628
Validation loss: 2.474158309513857

Epoch: 6| Step: 8
Training loss: 2.266495110059437
Validation loss: 2.492333258397109

Epoch: 6| Step: 9
Training loss: 2.826122185956374
Validation loss: 2.5168837130247823

Epoch: 6| Step: 10
Training loss: 2.668289098315383
Validation loss: 2.495786465235201

Epoch: 6| Step: 11
Training loss: 2.6706405375658275
Validation loss: 2.4717995949228078

Epoch: 6| Step: 12
Training loss: 2.0158901779446445
Validation loss: 2.5091034253227464

Epoch: 6| Step: 13
Training loss: 2.82706536943486
Validation loss: 2.474829902078181

Epoch: 253| Step: 0
Training loss: 2.8590833171220464
Validation loss: 2.491522480492046

Epoch: 6| Step: 1
Training loss: 2.708136879080332
Validation loss: 2.510587661843207

Epoch: 6| Step: 2
Training loss: 2.8310898893443586
Validation loss: 2.517008961304164

Epoch: 6| Step: 3
Training loss: 2.517518272901814
Validation loss: 2.4847074453792626

Epoch: 6| Step: 4
Training loss: 2.281881166698991
Validation loss: 2.494731093536283

Epoch: 6| Step: 5
Training loss: 1.9050267781856107
Validation loss: 2.471527673565988

Epoch: 6| Step: 6
Training loss: 2.417650734936988
Validation loss: 2.480303844693181

Epoch: 6| Step: 7
Training loss: 1.7684839109164001
Validation loss: 2.5013701089021767

Epoch: 6| Step: 8
Training loss: 2.6489109752610407
Validation loss: 2.5279532236858318

Epoch: 6| Step: 9
Training loss: 2.626090413636915
Validation loss: 2.484611734709848

Epoch: 6| Step: 10
Training loss: 2.477379408441089
Validation loss: 2.465589445977009

Epoch: 6| Step: 11
Training loss: 2.4429845484316375
Validation loss: 2.446820573509612

Epoch: 6| Step: 12
Training loss: 2.394857014188572
Validation loss: 2.4923595865772987

Epoch: 6| Step: 13
Training loss: 2.19657638929651
Validation loss: 2.493421156327832

Epoch: 254| Step: 0
Training loss: 2.324045998700789
Validation loss: 2.491097509342149

Epoch: 6| Step: 1
Training loss: 1.8545941992208348
Validation loss: 2.4630172418632843

Epoch: 6| Step: 2
Training loss: 1.9411966068664992
Validation loss: 2.4817951511399006

Epoch: 6| Step: 3
Training loss: 2.5536496915456803
Validation loss: 2.4862863952018275

Epoch: 6| Step: 4
Training loss: 2.5748223623094333
Validation loss: 2.4745592554353837

Epoch: 6| Step: 5
Training loss: 3.0940910690802568
Validation loss: 2.4870992542083865

Epoch: 6| Step: 6
Training loss: 3.1881775977277864
Validation loss: 2.4778242322549673

Epoch: 6| Step: 7
Training loss: 2.153331716771105
Validation loss: 2.47317246671525

Epoch: 6| Step: 8
Training loss: 2.708088193705381
Validation loss: 2.476517562223009

Epoch: 6| Step: 9
Training loss: 2.221065441357751
Validation loss: 2.4820292228067546

Epoch: 6| Step: 10
Training loss: 2.6738880448910587
Validation loss: 2.499450937089348

Epoch: 6| Step: 11
Training loss: 2.595014516683264
Validation loss: 2.4699715598009595

Epoch: 6| Step: 12
Training loss: 2.1207629203973912
Validation loss: 2.4904640182269273

Epoch: 6| Step: 13
Training loss: 1.713263754835791
Validation loss: 2.460788239046096

Epoch: 255| Step: 0
Training loss: 2.4652276322066022
Validation loss: 2.477573025960393

Epoch: 6| Step: 1
Training loss: 2.634155112215756
Validation loss: 2.501622962209452

Epoch: 6| Step: 2
Training loss: 2.615481421245498
Validation loss: 2.485101672108233

Epoch: 6| Step: 3
Training loss: 2.184293303919789
Validation loss: 2.488706796824009

Epoch: 6| Step: 4
Training loss: 3.170257306170763
Validation loss: 2.4879944802328424

Epoch: 6| Step: 5
Training loss: 2.31318736815047
Validation loss: 2.4685972401948755

Epoch: 6| Step: 6
Training loss: 2.188480702319266
Validation loss: 2.4498307793921006

Epoch: 6| Step: 7
Training loss: 2.160595040481922
Validation loss: 2.4956323309927892

Epoch: 6| Step: 8
Training loss: 2.3999690530689093
Validation loss: 2.4838312810026717

Epoch: 6| Step: 9
Training loss: 2.3963761309091307
Validation loss: 2.4842535721770034

Epoch: 6| Step: 10
Training loss: 2.7654244732762128
Validation loss: 2.4814741013655817

Epoch: 6| Step: 11
Training loss: 2.2496496563587365
Validation loss: 2.467626319301927

Epoch: 6| Step: 12
Training loss: 2.323212016079306
Validation loss: 2.4657147296210007

Epoch: 6| Step: 13
Training loss: 2.528792047382028
Validation loss: 2.487899048522962

Epoch: 256| Step: 0
Training loss: 2.2297625116723694
Validation loss: 2.494408287322664

Epoch: 6| Step: 1
Training loss: 2.111645980749699
Validation loss: 2.5064068172136267

Epoch: 6| Step: 2
Training loss: 2.371966784162649
Validation loss: 2.4649417529373117

Epoch: 6| Step: 3
Training loss: 2.1541895212797106
Validation loss: 2.469726180506365

Epoch: 6| Step: 4
Training loss: 2.019054600083637
Validation loss: 2.4929338247373294

Epoch: 6| Step: 5
Training loss: 2.6502537084085187
Validation loss: 2.5079441832708915

Epoch: 6| Step: 6
Training loss: 3.006458165819013
Validation loss: 2.466525958581303

Epoch: 6| Step: 7
Training loss: 2.6942348813845713
Validation loss: 2.473656219187332

Epoch: 6| Step: 8
Training loss: 2.7240651233131388
Validation loss: 2.514330860812206

Epoch: 6| Step: 9
Training loss: 1.973698346438732
Validation loss: 2.5098057887277285

Epoch: 6| Step: 10
Training loss: 2.584160046938533
Validation loss: 2.4960452650587293

Epoch: 6| Step: 11
Training loss: 2.731852735971087
Validation loss: 2.5054928374992524

Epoch: 6| Step: 12
Training loss: 2.412019822160995
Validation loss: 2.4959564338111306

Epoch: 6| Step: 13
Training loss: 2.640635202602563
Validation loss: 2.491039227482722

Epoch: 257| Step: 0
Training loss: 2.5533511898555146
Validation loss: 2.5262525501948607

Epoch: 6| Step: 1
Training loss: 2.5083063417758833
Validation loss: 2.4790168169550175

Epoch: 6| Step: 2
Training loss: 2.3039299188525435
Validation loss: 2.4948047976101497

Epoch: 6| Step: 3
Training loss: 2.127388677497378
Validation loss: 2.498310037310142

Epoch: 6| Step: 4
Training loss: 2.4697305204903537
Validation loss: 2.4979076817995183

Epoch: 6| Step: 5
Training loss: 3.218085655613479
Validation loss: 2.4664047813357235

Epoch: 6| Step: 6
Training loss: 2.3104650461986673
Validation loss: 2.4869816646983227

Epoch: 6| Step: 7
Training loss: 2.1774304370301865
Validation loss: 2.4834371292639483

Epoch: 6| Step: 8
Training loss: 2.3676501536462338
Validation loss: 2.4441299810890063

Epoch: 6| Step: 9
Training loss: 2.5060737262484563
Validation loss: 2.468613576799623

Epoch: 6| Step: 10
Training loss: 2.008546450164462
Validation loss: 2.501041949957376

Epoch: 6| Step: 11
Training loss: 2.1999671976938555
Validation loss: 2.469500516781663

Epoch: 6| Step: 12
Training loss: 3.1641673883077788
Validation loss: 2.4923058190272647

Epoch: 6| Step: 13
Training loss: 2.307185484177299
Validation loss: 2.476142451988509

Epoch: 258| Step: 0
Training loss: 2.1142024431621036
Validation loss: 2.513021342724691

Epoch: 6| Step: 1
Training loss: 2.5212733197398554
Validation loss: 2.4871169535891586

Epoch: 6| Step: 2
Training loss: 2.57168319932523
Validation loss: 2.464325691872438

Epoch: 6| Step: 3
Training loss: 2.6294540582717483
Validation loss: 2.513420843777641

Epoch: 6| Step: 4
Training loss: 2.606084336246038
Validation loss: 2.451911525290471

Epoch: 6| Step: 5
Training loss: 2.0955476018786836
Validation loss: 2.490911767697553

Epoch: 6| Step: 6
Training loss: 2.387627211771674
Validation loss: 2.487510234712564

Epoch: 6| Step: 7
Training loss: 2.4070328268895964
Validation loss: 2.485884025692992

Epoch: 6| Step: 8
Training loss: 2.770015873226586
Validation loss: 2.496803094701072

Epoch: 6| Step: 9
Training loss: 1.6664609146273035
Validation loss: 2.47920395232038

Epoch: 6| Step: 10
Training loss: 2.5517615498202635
Validation loss: 2.459448821151651

Epoch: 6| Step: 11
Training loss: 2.554913338761043
Validation loss: 2.4751244272257535

Epoch: 6| Step: 12
Training loss: 2.9667357990339367
Validation loss: 2.47647768471066

Epoch: 6| Step: 13
Training loss: 1.6488971521333884
Validation loss: 2.51699758331755

Epoch: 259| Step: 0
Training loss: 2.7678575717908114
Validation loss: 2.4711489493298853

Epoch: 6| Step: 1
Training loss: 2.079484881842091
Validation loss: 2.484830217531569

Epoch: 6| Step: 2
Training loss: 2.4628081462944085
Validation loss: 2.5037754069381224

Epoch: 6| Step: 3
Training loss: 2.1787501134560534
Validation loss: 2.482062139987065

Epoch: 6| Step: 4
Training loss: 2.815169445107912
Validation loss: 2.492631631241074

Epoch: 6| Step: 5
Training loss: 2.6362088989121504
Validation loss: 2.490268779905438

Epoch: 6| Step: 6
Training loss: 1.761612645779296
Validation loss: 2.4718166280694995

Epoch: 6| Step: 7
Training loss: 1.5931832296834934
Validation loss: 2.4769356246185037

Epoch: 6| Step: 8
Training loss: 2.938631529697792
Validation loss: 2.4921966880711004

Epoch: 6| Step: 9
Training loss: 2.8798468824585535
Validation loss: 2.5048556907343444

Epoch: 6| Step: 10
Training loss: 2.409357417694338
Validation loss: 2.4586249352883196

Epoch: 6| Step: 11
Training loss: 2.5745736370983443
Validation loss: 2.491776328973453

Epoch: 6| Step: 12
Training loss: 2.2063942319068452
Validation loss: 2.492699743956394

Epoch: 6| Step: 13
Training loss: 2.674824921056869
Validation loss: 2.476496134946301

Epoch: 260| Step: 0
Training loss: 2.4794607442189527
Validation loss: 2.44978141755532

Epoch: 6| Step: 1
Training loss: 3.047041355384488
Validation loss: 2.4812827895452236

Epoch: 6| Step: 2
Training loss: 2.5789432036471722
Validation loss: 2.4929168217273023

Epoch: 6| Step: 3
Training loss: 2.6767118520315467
Validation loss: 2.4662617254021346

Epoch: 6| Step: 4
Training loss: 1.61136955439164
Validation loss: 2.4866604535970596

Epoch: 6| Step: 5
Training loss: 2.080538502640126
Validation loss: 2.505861612427855

Epoch: 6| Step: 6
Training loss: 1.4009776993037872
Validation loss: 2.4454199471080043

Epoch: 6| Step: 7
Training loss: 2.9988800183470024
Validation loss: 2.4502372562363353

Epoch: 6| Step: 8
Training loss: 2.2194298790538776
Validation loss: 2.4681347669302247

Epoch: 6| Step: 9
Training loss: 2.797092706316158
Validation loss: 2.417626285515835

Epoch: 6| Step: 10
Training loss: 2.79825298099296
Validation loss: 2.4688188037809606

Epoch: 6| Step: 11
Training loss: 2.7161285214529243
Validation loss: 2.4782494478393575

Epoch: 6| Step: 12
Training loss: 2.114428083862436
Validation loss: 2.4852645518719774

Epoch: 6| Step: 13
Training loss: 1.759627562260671
Validation loss: 2.4746981877920495

Epoch: 261| Step: 0
Training loss: 2.1288228149863015
Validation loss: 2.4585233583278727

Epoch: 6| Step: 1
Training loss: 3.058698045845117
Validation loss: 2.4898626100762367

Epoch: 6| Step: 2
Training loss: 2.3959829090253955
Validation loss: 2.500643899504498

Epoch: 6| Step: 3
Training loss: 2.0800039645303943
Validation loss: 2.4813902753094594

Epoch: 6| Step: 4
Training loss: 2.2632727678460642
Validation loss: 2.48586607311883

Epoch: 6| Step: 5
Training loss: 2.312364110304752
Validation loss: 2.5101362448000852

Epoch: 6| Step: 6
Training loss: 1.7442151915532642
Validation loss: 2.4883365087609297

Epoch: 6| Step: 7
Training loss: 2.6805321610593276
Validation loss: 2.482020312643476

Epoch: 6| Step: 8
Training loss: 2.5552580310100788
Validation loss: 2.529504773680737

Epoch: 6| Step: 9
Training loss: 2.3322322381850378
Validation loss: 2.5054343788905107

Epoch: 6| Step: 10
Training loss: 2.6106823598502373
Validation loss: 2.504763150082967

Epoch: 6| Step: 11
Training loss: 2.397233791428997
Validation loss: 2.4970892891996996

Epoch: 6| Step: 12
Training loss: 2.353138139138388
Validation loss: 2.480475341850128

Epoch: 6| Step: 13
Training loss: 3.4073187874896704
Validation loss: 2.4919375595395814

Epoch: 262| Step: 0
Training loss: 2.269357277378901
Validation loss: 2.512101705464633

Epoch: 6| Step: 1
Training loss: 2.582641621756577
Validation loss: 2.4520724789533093

Epoch: 6| Step: 2
Training loss: 3.0423890566757197
Validation loss: 2.49763513354619

Epoch: 6| Step: 3
Training loss: 3.009739642368381
Validation loss: 2.468588768089401

Epoch: 6| Step: 4
Training loss: 2.8713245947800585
Validation loss: 2.4714580173344953

Epoch: 6| Step: 5
Training loss: 1.708722985032462
Validation loss: 2.4817544184037317

Epoch: 6| Step: 6
Training loss: 2.45774959379427
Validation loss: 2.4891124837352563

Epoch: 6| Step: 7
Training loss: 1.9326544435677546
Validation loss: 2.467302967116826

Epoch: 6| Step: 8
Training loss: 2.1411564299564723
Validation loss: 2.4667353438694706

Epoch: 6| Step: 9
Training loss: 2.7377133290678484
Validation loss: 2.4743559120970255

Epoch: 6| Step: 10
Training loss: 2.025029914540809
Validation loss: 2.473860530420456

Epoch: 6| Step: 11
Training loss: 2.46116486967382
Validation loss: 2.5037588471871977

Epoch: 6| Step: 12
Training loss: 2.5174550099600292
Validation loss: 2.4788044945627408

Epoch: 6| Step: 13
Training loss: 1.6768595465233453
Validation loss: 2.47568640328189

Epoch: 263| Step: 0
Training loss: 2.809227883769488
Validation loss: 2.455601020221746

Epoch: 6| Step: 1
Training loss: 2.894440478344342
Validation loss: 2.4894902783470574

Epoch: 6| Step: 2
Training loss: 2.325478707530397
Validation loss: 2.4781500087371438

Epoch: 6| Step: 3
Training loss: 1.8849328475849705
Validation loss: 2.4730306113651777

Epoch: 6| Step: 4
Training loss: 2.519186685347782
Validation loss: 2.461103589400369

Epoch: 6| Step: 5
Training loss: 2.066858714419913
Validation loss: 2.4747434787061104

Epoch: 6| Step: 6
Training loss: 3.0556489255877075
Validation loss: 2.512187414101588

Epoch: 6| Step: 7
Training loss: 2.0305404597583916
Validation loss: 2.4738254257968824

Epoch: 6| Step: 8
Training loss: 2.4312024070180542
Validation loss: 2.472640703191914

Epoch: 6| Step: 9
Training loss: 2.512223117432099
Validation loss: 2.4570010624692107

Epoch: 6| Step: 10
Training loss: 2.5086441324853888
Validation loss: 2.4691704521440756

Epoch: 6| Step: 11
Training loss: 2.3734053227225504
Validation loss: 2.499507078162506

Epoch: 6| Step: 12
Training loss: 2.3956147025046506
Validation loss: 2.4804807844024275

Epoch: 6| Step: 13
Training loss: 2.117329610299233
Validation loss: 2.4888924022521337

Epoch: 264| Step: 0
Training loss: 1.7776007497914654
Validation loss: 2.4782506178091026

Epoch: 6| Step: 1
Training loss: 2.344568236890909
Validation loss: 2.464057315995206

Epoch: 6| Step: 2
Training loss: 1.9696449788663533
Validation loss: 2.4938325002558943

Epoch: 6| Step: 3
Training loss: 2.5060076056484486
Validation loss: 2.47724491032849

Epoch: 6| Step: 4
Training loss: 2.615486708327065
Validation loss: 2.491671769825627

Epoch: 6| Step: 5
Training loss: 2.3089778987178673
Validation loss: 2.4652381821770213

Epoch: 6| Step: 6
Training loss: 1.9649929953103273
Validation loss: 2.4690738775502927

Epoch: 6| Step: 7
Training loss: 2.5471912959930134
Validation loss: 2.475014127473689

Epoch: 6| Step: 8
Training loss: 2.256165745395719
Validation loss: 2.4695930116410163

Epoch: 6| Step: 9
Training loss: 3.4102686702904292
Validation loss: 2.480324385329563

Epoch: 6| Step: 10
Training loss: 2.858765250475145
Validation loss: 2.482318208647822

Epoch: 6| Step: 11
Training loss: 2.352005115308843
Validation loss: 2.514808450417146

Epoch: 6| Step: 12
Training loss: 1.9552131171786995
Validation loss: 2.4938081932592393

Epoch: 6| Step: 13
Training loss: 2.902302347660617
Validation loss: 2.4856560210494703

Epoch: 265| Step: 0
Training loss: 2.151993683249126
Validation loss: 2.4938372567717817

Epoch: 6| Step: 1
Training loss: 2.408540304545599
Validation loss: 2.48495376252561

Epoch: 6| Step: 2
Training loss: 2.1804252661179397
Validation loss: 2.474539800853802

Epoch: 6| Step: 3
Training loss: 2.0066258824070324
Validation loss: 2.4938058694588876

Epoch: 6| Step: 4
Training loss: 1.785881179095056
Validation loss: 2.498825328457881

Epoch: 6| Step: 5
Training loss: 2.6279171674381243
Validation loss: 2.499379862503582

Epoch: 6| Step: 6
Training loss: 2.398835686549208
Validation loss: 2.498227401629958

Epoch: 6| Step: 7
Training loss: 2.156237616019691
Validation loss: 2.510948157228365

Epoch: 6| Step: 8
Training loss: 2.4225768026139
Validation loss: 2.5125215199593294

Epoch: 6| Step: 9
Training loss: 2.561916750148682
Validation loss: 2.5078274924450787

Epoch: 6| Step: 10
Training loss: 2.544414244208354
Validation loss: 2.5200031072379634

Epoch: 6| Step: 11
Training loss: 3.702829341111271
Validation loss: 2.5134665588948018

Epoch: 6| Step: 12
Training loss: 2.547393278033443
Validation loss: 2.4874585477858906

Epoch: 6| Step: 13
Training loss: 2.3401235371771483
Validation loss: 2.4966416649284193

Epoch: 266| Step: 0
Training loss: 2.2782359657420446
Validation loss: 2.5036724972623032

Epoch: 6| Step: 1
Training loss: 2.4995906494698272
Validation loss: 2.493587830195518

Epoch: 6| Step: 2
Training loss: 2.17595908843878
Validation loss: 2.4604921895462346

Epoch: 6| Step: 3
Training loss: 2.127273017080031
Validation loss: 2.499077968384508

Epoch: 6| Step: 4
Training loss: 2.6764944198154006
Validation loss: 2.446961389866668

Epoch: 6| Step: 5
Training loss: 1.8047642547006426
Validation loss: 2.4663836112936837

Epoch: 6| Step: 6
Training loss: 2.5764800401473775
Validation loss: 2.4645873636314315

Epoch: 6| Step: 7
Training loss: 2.211234029018934
Validation loss: 2.4760393789896185

Epoch: 6| Step: 8
Training loss: 2.5105087664370784
Validation loss: 2.4545809728907244

Epoch: 6| Step: 9
Training loss: 3.162774169858469
Validation loss: 2.469878481770706

Epoch: 6| Step: 10
Training loss: 2.372929925744778
Validation loss: 2.4548433930583307

Epoch: 6| Step: 11
Training loss: 2.117874315633789
Validation loss: 2.468304260646147

Epoch: 6| Step: 12
Training loss: 2.7284198544842306
Validation loss: 2.4826391926342715

Epoch: 6| Step: 13
Training loss: 2.3898719149947274
Validation loss: 2.477110077874622

Epoch: 267| Step: 0
Training loss: 2.4845876542733563
Validation loss: 2.5099815541664783

Epoch: 6| Step: 1
Training loss: 2.6571402460369633
Validation loss: 2.44205541604604

Epoch: 6| Step: 2
Training loss: 2.4106480422833707
Validation loss: 2.46203594496115

Epoch: 6| Step: 3
Training loss: 2.561223340098198
Validation loss: 2.479110548239612

Epoch: 6| Step: 4
Training loss: 2.4495890214281593
Validation loss: 2.512355703202832

Epoch: 6| Step: 5
Training loss: 2.591249570575095
Validation loss: 2.4835441439863404

Epoch: 6| Step: 6
Training loss: 2.5929504449053993
Validation loss: 2.4684793405180003

Epoch: 6| Step: 7
Training loss: 2.025275143427602
Validation loss: 2.4903519354844095

Epoch: 6| Step: 8
Training loss: 2.743841036804776
Validation loss: 2.5026112486005254

Epoch: 6| Step: 9
Training loss: 2.1817903390466116
Validation loss: 2.4662065416754295

Epoch: 6| Step: 10
Training loss: 1.9976883880810898
Validation loss: 2.4764949600069297

Epoch: 6| Step: 11
Training loss: 2.4529648260805295
Validation loss: 2.482155870917963

Epoch: 6| Step: 12
Training loss: 2.4260338300090014
Validation loss: 2.459343784069176

Epoch: 6| Step: 13
Training loss: 1.9359265367937974
Validation loss: 2.478061516218672

Epoch: 268| Step: 0
Training loss: 3.242987476608181
Validation loss: 2.491705953225404

Epoch: 6| Step: 1
Training loss: 2.2609832569229558
Validation loss: 2.42086779410851

Epoch: 6| Step: 2
Training loss: 2.0891068630030363
Validation loss: 2.4904116385655644

Epoch: 6| Step: 3
Training loss: 2.5151907030613234
Validation loss: 2.480976051116078

Epoch: 6| Step: 4
Training loss: 2.386989646809263
Validation loss: 2.451673036322509

Epoch: 6| Step: 5
Training loss: 2.536272223588149
Validation loss: 2.4611476096865648

Epoch: 6| Step: 6
Training loss: 2.2121000973781255
Validation loss: 2.5154455792658514

Epoch: 6| Step: 7
Training loss: 2.6659726988302417
Validation loss: 2.4613186657111386

Epoch: 6| Step: 8
Training loss: 2.1654748817806793
Validation loss: 2.494041057811157

Epoch: 6| Step: 9
Training loss: 2.598530970559338
Validation loss: 2.4558142270399235

Epoch: 6| Step: 10
Training loss: 2.4654843907942308
Validation loss: 2.4648605046306487

Epoch: 6| Step: 11
Training loss: 2.4763274938713327
Validation loss: 2.509623848133133

Epoch: 6| Step: 12
Training loss: 1.942125152790196
Validation loss: 2.4799849246572827

Epoch: 6| Step: 13
Training loss: 1.778441909411884
Validation loss: 2.490669483292915

Epoch: 269| Step: 0
Training loss: 2.1310464442977084
Validation loss: 2.4574852014487316

Epoch: 6| Step: 1
Training loss: 2.1836766208489156
Validation loss: 2.4665567716426025

Epoch: 6| Step: 2
Training loss: 1.9574336629956803
Validation loss: 2.495051926305483

Epoch: 6| Step: 3
Training loss: 2.1881969976361515
Validation loss: 2.4670321977205516

Epoch: 6| Step: 4
Training loss: 2.4987800482602984
Validation loss: 2.4756883945999153

Epoch: 6| Step: 5
Training loss: 3.3613391900420724
Validation loss: 2.4855611483147566

Epoch: 6| Step: 6
Training loss: 2.4234635588415014
Validation loss: 2.4721633058706427

Epoch: 6| Step: 7
Training loss: 2.400099188026554
Validation loss: 2.4502920013161265

Epoch: 6| Step: 8
Training loss: 2.568362902504707
Validation loss: 2.5123396857275657

Epoch: 6| Step: 9
Training loss: 2.727368429701159
Validation loss: 2.480103678019748

Epoch: 6| Step: 10
Training loss: 2.3440040959267097
Validation loss: 2.4843505849920073

Epoch: 6| Step: 11
Training loss: 1.8989043740958755
Validation loss: 2.4551251655969586

Epoch: 6| Step: 12
Training loss: 2.2186725226830877
Validation loss: 2.480673416811061

Epoch: 6| Step: 13
Training loss: 2.6473566511067563
Validation loss: 2.462074290418717

Epoch: 270| Step: 0
Training loss: 2.76707274049825
Validation loss: 2.4669322836019503

Epoch: 6| Step: 1
Training loss: 2.134524597912668
Validation loss: 2.474420044867115

Epoch: 6| Step: 2
Training loss: 2.284203068098595
Validation loss: 2.503862987594616

Epoch: 6| Step: 3
Training loss: 2.690337258082217
Validation loss: 2.5097068287195783

Epoch: 6| Step: 4
Training loss: 2.9046319538651626
Validation loss: 2.4716308346215934

Epoch: 6| Step: 5
Training loss: 2.3830054033084496
Validation loss: 2.461711309124567

Epoch: 6| Step: 6
Training loss: 2.4831618699995435
Validation loss: 2.4763714619713126

Epoch: 6| Step: 7
Training loss: 2.5366455781872954
Validation loss: 2.510094545169974

Epoch: 6| Step: 8
Training loss: 2.1379250533239866
Validation loss: 2.5277043917198982

Epoch: 6| Step: 9
Training loss: 2.0500930067224163
Validation loss: 2.4600080358355827

Epoch: 6| Step: 10
Training loss: 2.743621625047711
Validation loss: 2.5405123601166513

Epoch: 6| Step: 11
Training loss: 2.4202820492153196
Validation loss: 2.4916190379457195

Epoch: 6| Step: 12
Training loss: 2.1037749375912598
Validation loss: 2.4975897327188776

Epoch: 6| Step: 13
Training loss: 1.870052103448898
Validation loss: 2.5070033055484235

Epoch: 271| Step: 0
Training loss: 1.4713585597510006
Validation loss: 2.4921374649475556

Epoch: 6| Step: 1
Training loss: 1.5718355147330068
Validation loss: 2.4773874469062833

Epoch: 6| Step: 2
Training loss: 1.5492353060439341
Validation loss: 2.4585434031498474

Epoch: 6| Step: 3
Training loss: 2.9436140348941437
Validation loss: 2.4630591795839565

Epoch: 6| Step: 4
Training loss: 2.696579433613011
Validation loss: 2.4658215143588045

Epoch: 6| Step: 5
Training loss: 2.430374391858347
Validation loss: 2.460390462526827

Epoch: 6| Step: 6
Training loss: 2.7184968150844444
Validation loss: 2.5095012443986975

Epoch: 6| Step: 7
Training loss: 2.35118551179018
Validation loss: 2.447981627542065

Epoch: 6| Step: 8
Training loss: 2.3172226186137332
Validation loss: 2.4851557863660716

Epoch: 6| Step: 9
Training loss: 2.440741315700215
Validation loss: 2.5035505677125744

Epoch: 6| Step: 10
Training loss: 2.5857833401462185
Validation loss: 2.5011126626362987

Epoch: 6| Step: 11
Training loss: 2.186009907699148
Validation loss: 2.491866780938982

Epoch: 6| Step: 12
Training loss: 3.1325774830020916
Validation loss: 2.472757213227533

Epoch: 6| Step: 13
Training loss: 2.6408745461551697
Validation loss: 2.4635356771276675

Epoch: 272| Step: 0
Training loss: 2.6221601474368708
Validation loss: 2.490419555702026

Epoch: 6| Step: 1
Training loss: 2.6251303322543857
Validation loss: 2.4685600065386994

Epoch: 6| Step: 2
Training loss: 2.5162129159422286
Validation loss: 2.4492882782835648

Epoch: 6| Step: 3
Training loss: 2.2208912148247912
Validation loss: 2.5015872930804703

Epoch: 6| Step: 4
Training loss: 2.411710809682831
Validation loss: 2.457254468351157

Epoch: 6| Step: 5
Training loss: 1.906509506822159
Validation loss: 2.4663943163914164

Epoch: 6| Step: 6
Training loss: 2.3815651552400503
Validation loss: 2.4924714782404767

Epoch: 6| Step: 7
Training loss: 2.139616011456998
Validation loss: 2.476159570182867

Epoch: 6| Step: 8
Training loss: 2.6624075931757156
Validation loss: 2.4810591492689853

Epoch: 6| Step: 9
Training loss: 2.014141986186982
Validation loss: 2.4937292013370915

Epoch: 6| Step: 10
Training loss: 2.6353306712317184
Validation loss: 2.486071494880598

Epoch: 6| Step: 11
Training loss: 2.569195814962362
Validation loss: 2.488770493862922

Epoch: 6| Step: 12
Training loss: 2.4408853936582857
Validation loss: 2.45357140619776

Epoch: 6| Step: 13
Training loss: 2.6821178392299667
Validation loss: 2.51122473910883

Epoch: 273| Step: 0
Training loss: 2.722086207782795
Validation loss: 2.484331430496981

Epoch: 6| Step: 1
Training loss: 2.678934152657527
Validation loss: 2.4758119753754957

Epoch: 6| Step: 2
Training loss: 2.0766797310350356
Validation loss: 2.510102705601788

Epoch: 6| Step: 3
Training loss: 2.501458886768844
Validation loss: 2.486776828421732

Epoch: 6| Step: 4
Training loss: 2.25640836038432
Validation loss: 2.445859653170357

Epoch: 6| Step: 5
Training loss: 2.5273716731938913
Validation loss: 2.4561037207650065

Epoch: 6| Step: 6
Training loss: 1.9614174548032441
Validation loss: 2.468403990446744

Epoch: 6| Step: 7
Training loss: 2.1974233884335237
Validation loss: 2.5118505499812707

Epoch: 6| Step: 8
Training loss: 2.1957392701976226
Validation loss: 2.491772853547507

Epoch: 6| Step: 9
Training loss: 2.058369054239824
Validation loss: 2.495561662318931

Epoch: 6| Step: 10
Training loss: 3.0269575106433577
Validation loss: 2.4923658877718635

Epoch: 6| Step: 11
Training loss: 1.5612341521583495
Validation loss: 2.4731915562952826

Epoch: 6| Step: 12
Training loss: 2.796724027682714
Validation loss: 2.4681216107771387

Epoch: 6| Step: 13
Training loss: 3.088640251108737
Validation loss: 2.463924334965603

Epoch: 274| Step: 0
Training loss: 2.1607341855516546
Validation loss: 2.466935593457677

Epoch: 6| Step: 1
Training loss: 1.5868852912055293
Validation loss: 2.5085277225583513

Epoch: 6| Step: 2
Training loss: 2.3202046070638116
Validation loss: 2.46626337922129

Epoch: 6| Step: 3
Training loss: 2.986071678512401
Validation loss: 2.4956682865708637

Epoch: 6| Step: 4
Training loss: 1.6588655368608891
Validation loss: 2.5011194881024017

Epoch: 6| Step: 5
Training loss: 2.4713013418572864
Validation loss: 2.451671384163551

Epoch: 6| Step: 6
Training loss: 1.816804378726139
Validation loss: 2.4658369586081776

Epoch: 6| Step: 7
Training loss: 2.5708671365635185
Validation loss: 2.477899152057766

Epoch: 6| Step: 8
Training loss: 2.4872091190353784
Validation loss: 2.44473239067224

Epoch: 6| Step: 9
Training loss: 2.068373207283776
Validation loss: 2.4529156569098753

Epoch: 6| Step: 10
Training loss: 3.0090437313615257
Validation loss: 2.461873392886315

Epoch: 6| Step: 11
Training loss: 2.8399313974825566
Validation loss: 2.478528032973456

Epoch: 6| Step: 12
Training loss: 2.5355818616033856
Validation loss: 2.474255623347385

Epoch: 6| Step: 13
Training loss: 2.531788238944784
Validation loss: 2.447052697431436

Epoch: 275| Step: 0
Training loss: 1.8949763139034554
Validation loss: 2.4679252936548393

Epoch: 6| Step: 1
Training loss: 2.157107970335471
Validation loss: 2.4752628664540137

Epoch: 6| Step: 2
Training loss: 3.2074024947369217
Validation loss: 2.5007786860927963

Epoch: 6| Step: 3
Training loss: 2.6793618407481334
Validation loss: 2.4943119087616283

Epoch: 6| Step: 4
Training loss: 2.330660674440259
Validation loss: 2.496646246664829

Epoch: 6| Step: 5
Training loss: 2.1561910648861056
Validation loss: 2.464039842173935

Epoch: 6| Step: 6
Training loss: 2.7419560435282535
Validation loss: 2.4605442632085825

Epoch: 6| Step: 7
Training loss: 2.243992308387562
Validation loss: 2.5051881464740804

Epoch: 6| Step: 8
Training loss: 2.1338648173766517
Validation loss: 2.5155154692062296

Epoch: 6| Step: 9
Training loss: 2.4401223186413503
Validation loss: 2.4729611457107237

Epoch: 6| Step: 10
Training loss: 2.2632164089618
Validation loss: 2.498619570110324

Epoch: 6| Step: 11
Training loss: 2.496154115809568
Validation loss: 2.4740184795190414

Epoch: 6| Step: 12
Training loss: 2.4382047368016515
Validation loss: 2.4911503767826044

Epoch: 6| Step: 13
Training loss: 2.2169016271368145
Validation loss: 2.4849823498073795

Epoch: 276| Step: 0
Training loss: 2.659790372404238
Validation loss: 2.479805049739498

Epoch: 6| Step: 1
Training loss: 2.654830373744148
Validation loss: 2.5016249718237473

Epoch: 6| Step: 2
Training loss: 2.4399524968635524
Validation loss: 2.475421020712879

Epoch: 6| Step: 3
Training loss: 1.4579309544167993
Validation loss: 2.4697976558844488

Epoch: 6| Step: 4
Training loss: 2.3892456263930932
Validation loss: 2.477873023034089

Epoch: 6| Step: 5
Training loss: 1.8820176088845098
Validation loss: 2.4948764700722137

Epoch: 6| Step: 6
Training loss: 2.459731324108
Validation loss: 2.464572299544966

Epoch: 6| Step: 7
Training loss: 2.477672821391735
Validation loss: 2.514977305199461

Epoch: 6| Step: 8
Training loss: 2.1310879508691327
Validation loss: 2.475867854136505

Epoch: 6| Step: 9
Training loss: 2.285735332443205
Validation loss: 2.468126145741981

Epoch: 6| Step: 10
Training loss: 2.935845091514058
Validation loss: 2.501854590114238

Epoch: 6| Step: 11
Training loss: 2.5560682572577162
Validation loss: 2.51222536551976

Epoch: 6| Step: 12
Training loss: 2.943667815209255
Validation loss: 2.4853792230554586

Epoch: 6| Step: 13
Training loss: 1.6288030577981272
Validation loss: 2.4979490789066117

Epoch: 277| Step: 0
Training loss: 2.911018806996949
Validation loss: 2.4924625493502512

Epoch: 6| Step: 1
Training loss: 2.512056841128218
Validation loss: 2.4791163784713124

Epoch: 6| Step: 2
Training loss: 2.5447171671254236
Validation loss: 2.4622035574629777

Epoch: 6| Step: 3
Training loss: 2.0125159600614233
Validation loss: 2.453551263288157

Epoch: 6| Step: 4
Training loss: 2.558941300643522
Validation loss: 2.4808363672032945

Epoch: 6| Step: 5
Training loss: 2.1671932998722636
Validation loss: 2.4762767366667484

Epoch: 6| Step: 6
Training loss: 2.447541314965767
Validation loss: 2.512475427458323

Epoch: 6| Step: 7
Training loss: 2.5597567877870877
Validation loss: 2.4791818316533467

Epoch: 6| Step: 8
Training loss: 1.8903508263396682
Validation loss: 2.4636036348374466

Epoch: 6| Step: 9
Training loss: 2.4333446981434648
Validation loss: 2.4862334686721073

Epoch: 6| Step: 10
Training loss: 2.5065800856118554
Validation loss: 2.4238968035836566

Epoch: 6| Step: 11
Training loss: 2.197613687709957
Validation loss: 2.4622513885786828

Epoch: 6| Step: 12
Training loss: 2.4409218269404644
Validation loss: 2.456660072663544

Epoch: 6| Step: 13
Training loss: 2.5911834151771016
Validation loss: 2.4921896910679484

Epoch: 278| Step: 0
Training loss: 2.3913361731963376
Validation loss: 2.4656934434435485

Epoch: 6| Step: 1
Training loss: 2.088928820970114
Validation loss: 2.461385794111922

Epoch: 6| Step: 2
Training loss: 2.0175202205358427
Validation loss: 2.4444456037146964

Epoch: 6| Step: 3
Training loss: 2.158612159874161
Validation loss: 2.4595655798134555

Epoch: 6| Step: 4
Training loss: 2.275364324720589
Validation loss: 2.487968687014432

Epoch: 6| Step: 5
Training loss: 2.4180799714424284
Validation loss: 2.4673239734151147

Epoch: 6| Step: 6
Training loss: 2.2563340781652967
Validation loss: 2.50809008490959

Epoch: 6| Step: 7
Training loss: 2.2429191644994706
Validation loss: 2.4851856195228406

Epoch: 6| Step: 8
Training loss: 1.7367450912887241
Validation loss: 2.450798252694801

Epoch: 6| Step: 9
Training loss: 2.947099462316074
Validation loss: 2.478291569505524

Epoch: 6| Step: 10
Training loss: 2.431039807959154
Validation loss: 2.455455071859333

Epoch: 6| Step: 11
Training loss: 3.0486512313052736
Validation loss: 2.45725023413585

Epoch: 6| Step: 12
Training loss: 2.508196554753114
Validation loss: 2.4602787801043573

Epoch: 6| Step: 13
Training loss: 2.3038257086779756
Validation loss: 2.4809362142675027

Epoch: 279| Step: 0
Training loss: 2.4997640498396256
Validation loss: 2.493021985757473

Epoch: 6| Step: 1
Training loss: 2.244311134494125
Validation loss: 2.4743877258886107

Epoch: 6| Step: 2
Training loss: 2.4976704234036387
Validation loss: 2.4662507671330496

Epoch: 6| Step: 3
Training loss: 2.1234247315326766
Validation loss: 2.4467672218230296

Epoch: 6| Step: 4
Training loss: 2.0824436831329702
Validation loss: 2.4477211173520206

Epoch: 6| Step: 5
Training loss: 2.1594585926973036
Validation loss: 2.488176260640063

Epoch: 6| Step: 6
Training loss: 2.0126133383355076
Validation loss: 2.5080851060190774

Epoch: 6| Step: 7
Training loss: 3.024327819796769
Validation loss: 2.471372598444721

Epoch: 6| Step: 8
Training loss: 2.8194583856982325
Validation loss: 2.505465288492162

Epoch: 6| Step: 9
Training loss: 2.419092955412981
Validation loss: 2.486561692116538

Epoch: 6| Step: 10
Training loss: 2.2747009541915078
Validation loss: 2.491575797815137

Epoch: 6| Step: 11
Training loss: 2.650197122547792
Validation loss: 2.505756283370519

Epoch: 6| Step: 12
Training loss: 2.086593696163355
Validation loss: 2.4962458911042207

Epoch: 6| Step: 13
Training loss: 2.4452268932823693
Validation loss: 2.509862383559027

Epoch: 280| Step: 0
Training loss: 2.460077335258565
Validation loss: 2.48818076214423

Epoch: 6| Step: 1
Training loss: 2.604335097906001
Validation loss: 2.4976331130234306

Epoch: 6| Step: 2
Training loss: 2.357548998650161
Validation loss: 2.4862726844629566

Epoch: 6| Step: 3
Training loss: 1.8785043393639083
Validation loss: 2.4580274933589776

Epoch: 6| Step: 4
Training loss: 2.0890806141697835
Validation loss: 2.4964051190529815

Epoch: 6| Step: 5
Training loss: 2.3480088259581446
Validation loss: 2.487858641394438

Epoch: 6| Step: 6
Training loss: 2.5006142815262704
Validation loss: 2.5048180329551175

Epoch: 6| Step: 7
Training loss: 2.347248162521893
Validation loss: 2.463051171378843

Epoch: 6| Step: 8
Training loss: 2.2226769525137016
Validation loss: 2.4498649459491446

Epoch: 6| Step: 9
Training loss: 2.115039143662271
Validation loss: 2.4513520417125507

Epoch: 6| Step: 10
Training loss: 2.9507107024057766
Validation loss: 2.4921409501519323

Epoch: 6| Step: 11
Training loss: 2.3136076465343147
Validation loss: 2.505610497531995

Epoch: 6| Step: 12
Training loss: 2.2521062105788943
Validation loss: 2.4870983790799497

Epoch: 6| Step: 13
Training loss: 3.0998690423684003
Validation loss: 2.48893387617445

Epoch: 281| Step: 0
Training loss: 2.4878872210586698
Validation loss: 2.511895496588404

Epoch: 6| Step: 1
Training loss: 3.127218145878087
Validation loss: 2.4858213808763634

Epoch: 6| Step: 2
Training loss: 1.8524326259701174
Validation loss: 2.4646858604327497

Epoch: 6| Step: 3
Training loss: 2.5705232388911967
Validation loss: 2.4720281361001053

Epoch: 6| Step: 4
Training loss: 1.886181677913816
Validation loss: 2.4702970684138976

Epoch: 6| Step: 5
Training loss: 2.478835545928234
Validation loss: 2.456271001734412

Epoch: 6| Step: 6
Training loss: 2.5725148514002885
Validation loss: 2.471128698640317

Epoch: 6| Step: 7
Training loss: 2.3503599418778984
Validation loss: 2.4928030783358195

Epoch: 6| Step: 8
Training loss: 1.9571298052856763
Validation loss: 2.4497494390933685

Epoch: 6| Step: 9
Training loss: 2.2405359652185877
Validation loss: 2.4716652697780073

Epoch: 6| Step: 10
Training loss: 2.2770121678164204
Validation loss: 2.4683163637047367

Epoch: 6| Step: 11
Training loss: 2.365123591832946
Validation loss: 2.4822648881905076

Epoch: 6| Step: 12
Training loss: 2.3561711062875914
Validation loss: 2.479828458128371

Epoch: 6| Step: 13
Training loss: 2.5563570219361567
Validation loss: 2.45175969677306

Epoch: 282| Step: 0
Training loss: 2.2688602893598975
Validation loss: 2.4684514646246516

Epoch: 6| Step: 1
Training loss: 2.4911877770508073
Validation loss: 2.4762721845348854

Epoch: 6| Step: 2
Training loss: 1.8481081516812454
Validation loss: 2.449109386492234

Epoch: 6| Step: 3
Training loss: 2.241903572846934
Validation loss: 2.4818607991440893

Epoch: 6| Step: 4
Training loss: 2.0959091440776416
Validation loss: 2.4853030196264956

Epoch: 6| Step: 5
Training loss: 2.2807293650529847
Validation loss: 2.4656115565411847

Epoch: 6| Step: 6
Training loss: 2.535085151039795
Validation loss: 2.479032189339598

Epoch: 6| Step: 7
Training loss: 2.6529797337890666
Validation loss: 2.4489295823965325

Epoch: 6| Step: 8
Training loss: 2.232049118253536
Validation loss: 2.4771929693710617

Epoch: 6| Step: 9
Training loss: 2.7143390872555013
Validation loss: 2.4798917712185538

Epoch: 6| Step: 10
Training loss: 2.7750568658999173
Validation loss: 2.461096802956336

Epoch: 6| Step: 11
Training loss: 2.6007056672471354
Validation loss: 2.4815568842812463

Epoch: 6| Step: 12
Training loss: 2.251524408826984
Validation loss: 2.490981656959171

Epoch: 6| Step: 13
Training loss: 1.7552924508635226
Validation loss: 2.4803267160758757

Epoch: 283| Step: 0
Training loss: 2.161370431116085
Validation loss: 2.4961489333795277

Epoch: 6| Step: 1
Training loss: 2.476222836279504
Validation loss: 2.533308872332566

Epoch: 6| Step: 2
Training loss: 2.7228508199733583
Validation loss: 2.543345211955377

Epoch: 6| Step: 3
Training loss: 2.2791445696757417
Validation loss: 2.478845893194339

Epoch: 6| Step: 4
Training loss: 2.1920133623495532
Validation loss: 2.4633780148895212

Epoch: 6| Step: 5
Training loss: 2.0409893417491296
Validation loss: 2.4752582482437973

Epoch: 6| Step: 6
Training loss: 2.4943250141378055
Validation loss: 2.529601899103288

Epoch: 6| Step: 7
Training loss: 2.920389705676285
Validation loss: 2.489240463055346

Epoch: 6| Step: 8
Training loss: 1.7252905808217045
Validation loss: 2.4669319708021686

Epoch: 6| Step: 9
Training loss: 2.760741237536315
Validation loss: 2.489828247951612

Epoch: 6| Step: 10
Training loss: 2.240273965021799
Validation loss: 2.459780341405214

Epoch: 6| Step: 11
Training loss: 2.138381116079971
Validation loss: 2.497439480134033

Epoch: 6| Step: 12
Training loss: 2.3822845374366115
Validation loss: 2.4995712804819528

Epoch: 6| Step: 13
Training loss: 2.4474789708357263
Validation loss: 2.4812984144532044

Epoch: 284| Step: 0
Training loss: 3.1937054834417373
Validation loss: 2.4818698198889235

Epoch: 6| Step: 1
Training loss: 2.2325182048743106
Validation loss: 2.5030826759362736

Epoch: 6| Step: 2
Training loss: 2.175311327170708
Validation loss: 2.4882901691674797

Epoch: 6| Step: 3
Training loss: 2.7589254321937142
Validation loss: 2.500688142307952

Epoch: 6| Step: 4
Training loss: 2.0190554266733254
Validation loss: 2.490598550797781

Epoch: 6| Step: 5
Training loss: 2.248796246971763
Validation loss: 2.5008664793304387

Epoch: 6| Step: 6
Training loss: 3.0947764841942274
Validation loss: 2.48571343593757

Epoch: 6| Step: 7
Training loss: 2.6399129776628185
Validation loss: 2.5133914426633335

Epoch: 6| Step: 8
Training loss: 1.9938022427306263
Validation loss: 2.488855580369725

Epoch: 6| Step: 9
Training loss: 1.8195714792969453
Validation loss: 2.50463634571252

Epoch: 6| Step: 10
Training loss: 2.147576731864169
Validation loss: 2.4982154424546414

Epoch: 6| Step: 11
Training loss: 1.890764089465023
Validation loss: 2.4677241208315954

Epoch: 6| Step: 12
Training loss: 2.1235120837409194
Validation loss: 2.550741084211184

Epoch: 6| Step: 13
Training loss: 2.7673696413843354
Validation loss: 2.4898112227038376

Epoch: 285| Step: 0
Training loss: 2.357129070109551
Validation loss: 2.5240912507952644

Epoch: 6| Step: 1
Training loss: 2.0987553904624905
Validation loss: 2.512110830904449

Epoch: 6| Step: 2
Training loss: 1.9552127513588315
Validation loss: 2.4883086734789943

Epoch: 6| Step: 3
Training loss: 2.314386165632139
Validation loss: 2.519097378191452

Epoch: 6| Step: 4
Training loss: 2.2135445149721256
Validation loss: 2.5062191977030044

Epoch: 6| Step: 5
Training loss: 2.5656757679608058
Validation loss: 2.4804797601782487

Epoch: 6| Step: 6
Training loss: 2.030715637344594
Validation loss: 2.462546645678872

Epoch: 6| Step: 7
Training loss: 2.568048935611111
Validation loss: 2.496134751993963

Epoch: 6| Step: 8
Training loss: 2.438358449156872
Validation loss: 2.4764126828441952

Epoch: 6| Step: 9
Training loss: 2.6274760239920045
Validation loss: 2.473130989699676

Epoch: 6| Step: 10
Training loss: 2.5295090516398395
Validation loss: 2.5015006657890613

Epoch: 6| Step: 11
Training loss: 2.2562093884308165
Validation loss: 2.4541633320408356

Epoch: 6| Step: 12
Training loss: 2.073768351302942
Validation loss: 2.494610107633139

Epoch: 6| Step: 13
Training loss: 3.176758112703644
Validation loss: 2.528454751191688

Epoch: 286| Step: 0
Training loss: 2.3573145679997105
Validation loss: 2.4877233959300717

Epoch: 6| Step: 1
Training loss: 2.4336027632006045
Validation loss: 2.4607725099518962

Epoch: 6| Step: 2
Training loss: 2.3950850824840537
Validation loss: 2.458431529410668

Epoch: 6| Step: 3
Training loss: 2.215782437561935
Validation loss: 2.4678255735962606

Epoch: 6| Step: 4
Training loss: 2.864036387622627
Validation loss: 2.4668002962379645

Epoch: 6| Step: 5
Training loss: 2.2461778177202176
Validation loss: 2.450141179451881

Epoch: 6| Step: 6
Training loss: 2.3198565410786296
Validation loss: 2.506413117869353

Epoch: 6| Step: 7
Training loss: 2.4402733699686645
Validation loss: 2.477238020116296

Epoch: 6| Step: 8
Training loss: 2.5490482162219426
Validation loss: 2.455933010297212

Epoch: 6| Step: 9
Training loss: 2.0191713820447137
Validation loss: 2.4618348959066907

Epoch: 6| Step: 10
Training loss: 2.4449768811090453
Validation loss: 2.4603257150145943

Epoch: 6| Step: 11
Training loss: 1.956612547895571
Validation loss: 2.4514061762580273

Epoch: 6| Step: 12
Training loss: 2.223357132017463
Validation loss: 2.451031873197328

Epoch: 6| Step: 13
Training loss: 2.13849483784946
Validation loss: 2.4280187149426706

Epoch: 287| Step: 0
Training loss: 2.4352442745372094
Validation loss: 2.4620841833373985

Epoch: 6| Step: 1
Training loss: 2.0712714511494923
Validation loss: 2.4408879847254896

Epoch: 6| Step: 2
Training loss: 2.359332962166889
Validation loss: 2.4384853873379693

Epoch: 6| Step: 3
Training loss: 2.5583017896101334
Validation loss: 2.4641342773653707

Epoch: 6| Step: 4
Training loss: 2.975750028807486
Validation loss: 2.4553059600068186

Epoch: 6| Step: 5
Training loss: 2.925352424191844
Validation loss: 2.470603354668579

Epoch: 6| Step: 6
Training loss: 2.5678459785714423
Validation loss: 2.4722643099684194

Epoch: 6| Step: 7
Training loss: 1.910016325835912
Validation loss: 2.4873573083176295

Epoch: 6| Step: 8
Training loss: 1.8649271926781696
Validation loss: 2.4583933450817375

Epoch: 6| Step: 9
Training loss: 1.8913038942230687
Validation loss: 2.4105587223017944

Epoch: 6| Step: 10
Training loss: 2.79174795079867
Validation loss: 2.4866686615496993

Epoch: 6| Step: 11
Training loss: 1.8739506646240247
Validation loss: 2.4892067875267

Epoch: 6| Step: 12
Training loss: 2.084250921991581
Validation loss: 2.458028742832675

Epoch: 6| Step: 13
Training loss: 2.2795060690204734
Validation loss: 2.4840889382486684

Epoch: 288| Step: 0
Training loss: 2.1977413764465923
Validation loss: 2.471189459547881

Epoch: 6| Step: 1
Training loss: 2.1425073519817612
Validation loss: 2.468329474159408

Epoch: 6| Step: 2
Training loss: 2.2097365281831265
Validation loss: 2.4828613854668173

Epoch: 6| Step: 3
Training loss: 2.3355277732352535
Validation loss: 2.467532132558713

Epoch: 6| Step: 4
Training loss: 1.739887172943336
Validation loss: 2.4661611189296337

Epoch: 6| Step: 5
Training loss: 3.325026811764109
Validation loss: 2.4453333429484

Epoch: 6| Step: 6
Training loss: 2.912929120192446
Validation loss: 2.509364882049209

Epoch: 6| Step: 7
Training loss: 2.7678491302233623
Validation loss: 2.532828722466086

Epoch: 6| Step: 8
Training loss: 2.2118120923653515
Validation loss: 2.479079808483351

Epoch: 6| Step: 9
Training loss: 1.8472441199525689
Validation loss: 2.461748665111502

Epoch: 6| Step: 10
Training loss: 2.0406635181477903
Validation loss: 2.453947800976318

Epoch: 6| Step: 11
Training loss: 2.387681233183183
Validation loss: 2.4919758183231377

Epoch: 6| Step: 12
Training loss: 2.2760506519922994
Validation loss: 2.476479120527568

Epoch: 6| Step: 13
Training loss: 1.9812723369121434
Validation loss: 2.5095889582539974

Epoch: 289| Step: 0
Training loss: 2.3064684177752843
Validation loss: 2.487443921607266

Epoch: 6| Step: 1
Training loss: 2.115303242725568
Validation loss: 2.495087668312878

Epoch: 6| Step: 2
Training loss: 2.2638595542749407
Validation loss: 2.479533779366037

Epoch: 6| Step: 3
Training loss: 1.7590148882471675
Validation loss: 2.4579456097284402

Epoch: 6| Step: 4
Training loss: 2.2386067471659756
Validation loss: 2.4826680502649054

Epoch: 6| Step: 5
Training loss: 2.828445332126144
Validation loss: 2.5122858876102847

Epoch: 6| Step: 6
Training loss: 1.9291728951317229
Validation loss: 2.484265956135352

Epoch: 6| Step: 7
Training loss: 2.0229424419653266
Validation loss: 2.514704873391268

Epoch: 6| Step: 8
Training loss: 2.3603113602673753
Validation loss: 2.5136720442998737

Epoch: 6| Step: 9
Training loss: 2.019457345344419
Validation loss: 2.487387916404811

Epoch: 6| Step: 10
Training loss: 3.296266038527978
Validation loss: 2.49478785770391

Epoch: 6| Step: 11
Training loss: 2.4513823521436566
Validation loss: 2.4870883042576053

Epoch: 6| Step: 12
Training loss: 2.4621274947150753
Validation loss: 2.5002302140711987

Epoch: 6| Step: 13
Training loss: 3.000544021870877
Validation loss: 2.5277529671739156

Epoch: 290| Step: 0
Training loss: 2.173224599298605
Validation loss: 2.496053664512912

Epoch: 6| Step: 1
Training loss: 2.113145185733524
Validation loss: 2.4971316228182827

Epoch: 6| Step: 2
Training loss: 1.960611141448919
Validation loss: 2.464700619063313

Epoch: 6| Step: 3
Training loss: 2.421533572833619
Validation loss: 2.5078181858130546

Epoch: 6| Step: 4
Training loss: 2.414446753873197
Validation loss: 2.4592149932230862

Epoch: 6| Step: 5
Training loss: 2.7687683345971226
Validation loss: 2.487305534727223

Epoch: 6| Step: 6
Training loss: 2.3553698568002006
Validation loss: 2.4815529265581056

Epoch: 6| Step: 7
Training loss: 2.7303020551930794
Validation loss: 2.460641269463301

Epoch: 6| Step: 8
Training loss: 2.3499695715050253
Validation loss: 2.4859131983494898

Epoch: 6| Step: 9
Training loss: 2.149338079181445
Validation loss: 2.4747811025806996

Epoch: 6| Step: 10
Training loss: 2.2477144713115713
Validation loss: 2.466922013148517

Epoch: 6| Step: 11
Training loss: 2.3636383543472976
Validation loss: 2.4430566288358846

Epoch: 6| Step: 12
Training loss: 2.231928199255814
Validation loss: 2.4502231115008817

Epoch: 6| Step: 13
Training loss: 2.7935852650796726
Validation loss: 2.4509770505063213

Epoch: 291| Step: 0
Training loss: 1.9861718400445705
Validation loss: 2.4538370581290065

Epoch: 6| Step: 1
Training loss: 2.5681246922247474
Validation loss: 2.469469371913628

Epoch: 6| Step: 2
Training loss: 2.3693103902425445
Validation loss: 2.4875152114994217

Epoch: 6| Step: 3
Training loss: 2.3059744652213583
Validation loss: 2.482552850078893

Epoch: 6| Step: 4
Training loss: 2.224802278455921
Validation loss: 2.460065688748452

Epoch: 6| Step: 5
Training loss: 2.2889533423738575
Validation loss: 2.4929627164253376

Epoch: 6| Step: 6
Training loss: 2.5772731414031282
Validation loss: 2.4644059903629105

Epoch: 6| Step: 7
Training loss: 2.2435880002165227
Validation loss: 2.463486110159068

Epoch: 6| Step: 8
Training loss: 3.0340277146020984
Validation loss: 2.465606638478456

Epoch: 6| Step: 9
Training loss: 2.5007231620089043
Validation loss: 2.49307849680117

Epoch: 6| Step: 10
Training loss: 2.2711860546123313
Validation loss: 2.4557716175353237

Epoch: 6| Step: 11
Training loss: 2.315981023397758
Validation loss: 2.4801798892515663

Epoch: 6| Step: 12
Training loss: 2.147872795103405
Validation loss: 2.482019351027698

Epoch: 6| Step: 13
Training loss: 1.4501150809035017
Validation loss: 2.4785447685378275

Epoch: 292| Step: 0
Training loss: 2.2731061870980613
Validation loss: 2.4883676132318926

Epoch: 6| Step: 1
Training loss: 2.3696042053079736
Validation loss: 2.4802184710119053

Epoch: 6| Step: 2
Training loss: 2.3092372662221146
Validation loss: 2.484084376696206

Epoch: 6| Step: 3
Training loss: 2.3363949126911994
Validation loss: 2.511759598996805

Epoch: 6| Step: 4
Training loss: 2.080187469617208
Validation loss: 2.5015502491586235

Epoch: 6| Step: 5
Training loss: 2.49987163214135
Validation loss: 2.495561928384442

Epoch: 6| Step: 6
Training loss: 2.503795413035361
Validation loss: 2.515416375076559

Epoch: 6| Step: 7
Training loss: 2.389953918012774
Validation loss: 2.5289184403766156

Epoch: 6| Step: 8
Training loss: 2.551868061146866
Validation loss: 2.4806852290643393

Epoch: 6| Step: 9
Training loss: 2.092101515697468
Validation loss: 2.4830255313813

Epoch: 6| Step: 10
Training loss: 2.3077246358025345
Validation loss: 2.4719546064402484

Epoch: 6| Step: 11
Training loss: 2.3903991991503903
Validation loss: 2.487461976162498

Epoch: 6| Step: 12
Training loss: 2.116763815064659
Validation loss: 2.4885241908459235

Epoch: 6| Step: 13
Training loss: 2.493829264133999
Validation loss: 2.4938525059340177

Epoch: 293| Step: 0
Training loss: 2.295193738052745
Validation loss: 2.4990639554446537

Epoch: 6| Step: 1
Training loss: 2.2633121655597472
Validation loss: 2.451377015451732

Epoch: 6| Step: 2
Training loss: 2.8066356130620265
Validation loss: 2.510757820015412

Epoch: 6| Step: 3
Training loss: 2.101412742979689
Validation loss: 2.4696969557420716

Epoch: 6| Step: 4
Training loss: 2.941882982666648
Validation loss: 2.487942273212185

Epoch: 6| Step: 5
Training loss: 2.271856748148185
Validation loss: 2.4523178778250285

Epoch: 6| Step: 6
Training loss: 2.0336421085899254
Validation loss: 2.47202980472852

Epoch: 6| Step: 7
Training loss: 2.6461638196661696
Validation loss: 2.4741461386689867

Epoch: 6| Step: 8
Training loss: 2.335517666958347
Validation loss: 2.471306055637731

Epoch: 6| Step: 9
Training loss: 2.3724224760455694
Validation loss: 2.4940439780913817

Epoch: 6| Step: 10
Training loss: 1.5791931314523855
Validation loss: 2.5066191855862208

Epoch: 6| Step: 11
Training loss: 2.3026588951727764
Validation loss: 2.486783923127411

Epoch: 6| Step: 12
Training loss: 2.5371916935981553
Validation loss: 2.485985012694433

Epoch: 6| Step: 13
Training loss: 2.2757648733265463
Validation loss: 2.4407497479217444

Epoch: 294| Step: 0
Training loss: 2.520701150082037
Validation loss: 2.472714768159393

Epoch: 6| Step: 1
Training loss: 2.6859022314608834
Validation loss: 2.4314431347630556

Epoch: 6| Step: 2
Training loss: 1.8581835351392098
Validation loss: 2.4697870859463036

Epoch: 6| Step: 3
Training loss: 3.0519384321549725
Validation loss: 2.481722413937164

Epoch: 6| Step: 4
Training loss: 2.4869380181921192
Validation loss: 2.4329970842490005

Epoch: 6| Step: 5
Training loss: 2.8276341470724145
Validation loss: 2.4791803736181546

Epoch: 6| Step: 6
Training loss: 2.933932471498697
Validation loss: 2.498611288040595

Epoch: 6| Step: 7
Training loss: 1.6925556603073724
Validation loss: 2.530739852723029

Epoch: 6| Step: 8
Training loss: 2.439001159092126
Validation loss: 2.459336763438536

Epoch: 6| Step: 9
Training loss: 1.7515167747606835
Validation loss: 2.4892876562279733

Epoch: 6| Step: 10
Training loss: 1.5636808129731046
Validation loss: 2.450881931577228

Epoch: 6| Step: 11
Training loss: 1.9859408710970357
Validation loss: 2.4879376094993186

Epoch: 6| Step: 12
Training loss: 2.447636094483673
Validation loss: 2.468708749833822

Epoch: 6| Step: 13
Training loss: 2.014524647417775
Validation loss: 2.4603573569935793

Epoch: 295| Step: 0
Training loss: 2.2394422146597783
Validation loss: 2.479708837627779

Epoch: 6| Step: 1
Training loss: 2.311594089706319
Validation loss: 2.47845664386862

Epoch: 6| Step: 2
Training loss: 2.0366051142122155
Validation loss: 2.446179293431338

Epoch: 6| Step: 3
Training loss: 2.1710706360236194
Validation loss: 2.469350641802344

Epoch: 6| Step: 4
Training loss: 2.8707162206612953
Validation loss: 2.487256451760307

Epoch: 6| Step: 5
Training loss: 2.1754478870375884
Validation loss: 2.4780474713357385

Epoch: 6| Step: 6
Training loss: 2.3732963273917322
Validation loss: 2.4979613113248686

Epoch: 6| Step: 7
Training loss: 2.2402196882010945
Validation loss: 2.4758863047748116

Epoch: 6| Step: 8
Training loss: 2.2779916983328405
Validation loss: 2.4614923464034506

Epoch: 6| Step: 9
Training loss: 1.8274108926572636
Validation loss: 2.4912198158209153

Epoch: 6| Step: 10
Training loss: 2.343854571234878
Validation loss: 2.477782904498864

Epoch: 6| Step: 11
Training loss: 2.5378420669680293
Validation loss: 2.4855671016247514

Epoch: 6| Step: 12
Training loss: 2.3591506548191847
Validation loss: 2.50183224754076

Epoch: 6| Step: 13
Training loss: 2.2964512440601075
Validation loss: 2.4812021672585383

Epoch: 296| Step: 0
Training loss: 1.6748603477904747
Validation loss: 2.474360758893353

Epoch: 6| Step: 1
Training loss: 2.4805117145331685
Validation loss: 2.469797499147014

Epoch: 6| Step: 2
Training loss: 2.1281818802411987
Validation loss: 2.4686899225898395

Epoch: 6| Step: 3
Training loss: 2.3924803671036297
Validation loss: 2.480612517190528

Epoch: 6| Step: 4
Training loss: 2.3221122363792595
Validation loss: 2.5184485379839794

Epoch: 6| Step: 5
Training loss: 1.9118251881590391
Validation loss: 2.472240786405724

Epoch: 6| Step: 6
Training loss: 2.1147906823435156
Validation loss: 2.4535524439902945

Epoch: 6| Step: 7
Training loss: 2.582811200279467
Validation loss: 2.4972071532047035

Epoch: 6| Step: 8
Training loss: 2.833155925656841
Validation loss: 2.507745641149948

Epoch: 6| Step: 9
Training loss: 2.9371142844336546
Validation loss: 2.453399029452807

Epoch: 6| Step: 10
Training loss: 1.8599043020630501
Validation loss: 2.4999980290723025

Epoch: 6| Step: 11
Training loss: 2.863871556486642
Validation loss: 2.477410372118053

Epoch: 6| Step: 12
Training loss: 1.897830944728557
Validation loss: 2.469630451869216

Epoch: 6| Step: 13
Training loss: 1.6069759524432707
Validation loss: 2.503033934612204

Epoch: 297| Step: 0
Training loss: 1.7218460634434423
Validation loss: 2.4827377043425836

Epoch: 6| Step: 1
Training loss: 2.539058086684866
Validation loss: 2.459496640172504

Epoch: 6| Step: 2
Training loss: 2.836772028770181
Validation loss: 2.501498962502612

Epoch: 6| Step: 3
Training loss: 1.8650390522731437
Validation loss: 2.5307534491786825

Epoch: 6| Step: 4
Training loss: 2.5529298481311153
Validation loss: 2.487841326502513

Epoch: 6| Step: 5
Training loss: 2.430724385770896
Validation loss: 2.4992234834015736

Epoch: 6| Step: 6
Training loss: 2.0261862212115016
Validation loss: 2.501548683744418

Epoch: 6| Step: 7
Training loss: 2.442712248342884
Validation loss: 2.4720328163458785

Epoch: 6| Step: 8
Training loss: 2.7042067463573636
Validation loss: 2.4874881559623727

Epoch: 6| Step: 9
Training loss: 2.5813242165007786
Validation loss: 2.4919340699356423

Epoch: 6| Step: 10
Training loss: 2.6844140011104676
Validation loss: 2.492125428199206

Epoch: 6| Step: 11
Training loss: 2.129411829839017
Validation loss: 2.465307969952144

Epoch: 6| Step: 12
Training loss: 1.6152168097688355
Validation loss: 2.4598760833947537

Epoch: 6| Step: 13
Training loss: 2.218275959792912
Validation loss: 2.484924164902785

Epoch: 298| Step: 0
Training loss: 2.5120961334396776
Validation loss: 2.4854498743869393

Epoch: 6| Step: 1
Training loss: 2.330243574025756
Validation loss: 2.4918813816718886

Epoch: 6| Step: 2
Training loss: 2.221131564424574
Validation loss: 2.4735232204490223

Epoch: 6| Step: 3
Training loss: 2.6256636734266157
Validation loss: 2.4778987578741853

Epoch: 6| Step: 4
Training loss: 2.3876571683430683
Validation loss: 2.5054171670458834

Epoch: 6| Step: 5
Training loss: 2.9126866751510603
Validation loss: 2.488883847815611

Epoch: 6| Step: 6
Training loss: 2.1113580495176416
Validation loss: 2.4758439609820275

Epoch: 6| Step: 7
Training loss: 1.8886730111245937
Validation loss: 2.528116137365342

Epoch: 6| Step: 8
Training loss: 2.3041954420430217
Validation loss: 2.439202493703489

Epoch: 6| Step: 9
Training loss: 1.9976885074283182
Validation loss: 2.469524057103919

Epoch: 6| Step: 10
Training loss: 2.691970301017918
Validation loss: 2.4922389021523124

Epoch: 6| Step: 11
Training loss: 2.1637695334537335
Validation loss: 2.4796547027171743

Epoch: 6| Step: 12
Training loss: 2.184592139894307
Validation loss: 2.490456194905936

Epoch: 6| Step: 13
Training loss: 2.0287621154235365
Validation loss: 2.4903021898874216

Epoch: 299| Step: 0
Training loss: 2.1862220300855864
Validation loss: 2.4566297584751364

Epoch: 6| Step: 1
Training loss: 2.2290201109248042
Validation loss: 2.4724485471487596

Epoch: 6| Step: 2
Training loss: 3.0901030035041916
Validation loss: 2.511504550836466

Epoch: 6| Step: 3
Training loss: 2.213312066830112
Validation loss: 2.490452454114556

Epoch: 6| Step: 4
Training loss: 1.8637488716065786
Validation loss: 2.466627257957151

Epoch: 6| Step: 5
Training loss: 2.2136619146259946
Validation loss: 2.475455553828663

Epoch: 6| Step: 6
Training loss: 2.463534870635667
Validation loss: 2.4701100179807742

Epoch: 6| Step: 7
Training loss: 2.4183443976301877
Validation loss: 2.5130773101960435

Epoch: 6| Step: 8
Training loss: 3.1402634749456353
Validation loss: 2.4955151723285733

Epoch: 6| Step: 9
Training loss: 2.094867237409236
Validation loss: 2.481057943942007

Epoch: 6| Step: 10
Training loss: 2.094650530380041
Validation loss: 2.4772418351933494

Epoch: 6| Step: 11
Training loss: 1.8607112026267505
Validation loss: 2.48432879805807

Epoch: 6| Step: 12
Training loss: 2.213616247977627
Validation loss: 2.470161498659929

Epoch: 6| Step: 13
Training loss: 1.7222383645371064
Validation loss: 2.496404523431808

Epoch: 300| Step: 0
Training loss: 2.424456002479522
Validation loss: 2.4619921738066584

Epoch: 6| Step: 1
Training loss: 1.971627751006931
Validation loss: 2.492799231025496

Epoch: 6| Step: 2
Training loss: 2.083162440602453
Validation loss: 2.4967131593896816

Epoch: 6| Step: 3
Training loss: 2.6246730055819274
Validation loss: 2.4850243202106

Epoch: 6| Step: 4
Training loss: 2.0323756693482244
Validation loss: 2.4804145438224117

Epoch: 6| Step: 5
Training loss: 2.9335217422608095
Validation loss: 2.4795434423675626

Epoch: 6| Step: 6
Training loss: 2.1274574879792967
Validation loss: 2.4705065719941754

Epoch: 6| Step: 7
Training loss: 1.910521552293018
Validation loss: 2.457596917981602

Epoch: 6| Step: 8
Training loss: 2.1932368664654294
Validation loss: 2.509138658610498

Epoch: 6| Step: 9
Training loss: 2.318979310575495
Validation loss: 2.491411720802145

Epoch: 6| Step: 10
Training loss: 2.531529163931736
Validation loss: 2.47945519396438

Epoch: 6| Step: 11
Training loss: 2.4416169830926524
Validation loss: 2.4749003640847675

Epoch: 6| Step: 12
Training loss: 2.371322495111952
Validation loss: 2.5068886049552024

Epoch: 6| Step: 13
Training loss: 2.3363032740381224
Validation loss: 2.47562456289557

Testing loss: 2.5026181710519917
