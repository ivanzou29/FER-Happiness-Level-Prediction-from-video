Epoch: 1| Step: 0
Training loss: 5.219220161437988
Validation loss: 5.001673544606855

Epoch: 5| Step: 1
Training loss: 4.804379463195801
Validation loss: 5.000501273780741

Epoch: 5| Step: 2
Training loss: 4.4093194007873535
Validation loss: 4.996521447294501

Epoch: 5| Step: 3
Training loss: 4.505593299865723
Validation loss: 4.994830869859265

Epoch: 5| Step: 4
Training loss: 4.502320766448975
Validation loss: 4.991717600053357

Epoch: 5| Step: 5
Training loss: 4.966531276702881
Validation loss: 4.991059708338912

Epoch: 5| Step: 6
Training loss: 5.034858226776123
Validation loss: 4.988476258452221

Epoch: 5| Step: 7
Training loss: 5.998091697692871
Validation loss: 4.986068771731469

Epoch: 5| Step: 8
Training loss: 3.8382015228271484
Validation loss: 4.983855693571029

Epoch: 5| Step: 9
Training loss: 5.673384666442871
Validation loss: 4.981230315341745

Epoch: 5| Step: 10
Training loss: 3.4944400787353516
Validation loss: 4.97760203576857

Epoch: 2| Step: 0
Training loss: 4.983403205871582
Validation loss: 4.975360680651921

Epoch: 5| Step: 1
Training loss: 5.900723934173584
Validation loss: 4.973653752316711

Epoch: 5| Step: 2
Training loss: 3.718005657196045
Validation loss: 4.971406162426036

Epoch: 5| Step: 3
Training loss: 4.04982328414917
Validation loss: 4.967761562716577

Epoch: 5| Step: 4
Training loss: 5.839146137237549
Validation loss: 4.966337188597648

Epoch: 5| Step: 5
Training loss: 5.04099178314209
Validation loss: 4.965106025818856

Epoch: 5| Step: 6
Training loss: 4.921442985534668
Validation loss: 4.964293982392999

Epoch: 5| Step: 7
Training loss: 4.426784515380859
Validation loss: 4.95985205968221

Epoch: 5| Step: 8
Training loss: 4.386075496673584
Validation loss: 4.957134933881862

Epoch: 5| Step: 9
Training loss: 4.281147480010986
Validation loss: 4.952758189170591

Epoch: 5| Step: 10
Training loss: 4.816725730895996
Validation loss: 4.951207196840676

Epoch: 3| Step: 0
Training loss: 4.198700428009033
Validation loss: 4.9488920140010055

Epoch: 5| Step: 1
Training loss: 4.698876857757568
Validation loss: 4.946221002968409

Epoch: 5| Step: 2
Training loss: 3.9726181030273438
Validation loss: 4.943810550115442

Epoch: 5| Step: 3
Training loss: 5.356407165527344
Validation loss: 4.940012511386667

Epoch: 5| Step: 4
Training loss: 5.461698532104492
Validation loss: 4.9384761574447795

Epoch: 5| Step: 5
Training loss: 5.814472198486328
Validation loss: 4.9374601097517115

Epoch: 5| Step: 6
Training loss: 4.249936103820801
Validation loss: 4.934023344388572

Epoch: 5| Step: 7
Training loss: 4.652797698974609
Validation loss: 4.9327818193743305

Epoch: 5| Step: 8
Training loss: 4.89645528793335
Validation loss: 4.930426674504434

Epoch: 5| Step: 9
Training loss: 3.660632371902466
Validation loss: 4.92845804460587

Epoch: 5| Step: 10
Training loss: 5.133998870849609
Validation loss: 4.925579353045392

Epoch: 4| Step: 0
Training loss: 4.977123737335205
Validation loss: 4.921623460708126

Epoch: 5| Step: 1
Training loss: 3.980717182159424
Validation loss: 4.918206179013816

Epoch: 5| Step: 2
Training loss: 3.881981611251831
Validation loss: 4.9184314461164576

Epoch: 5| Step: 3
Training loss: 5.5113205909729
Validation loss: 4.915113879788306

Epoch: 5| Step: 4
Training loss: 4.863600730895996
Validation loss: 4.911801927833147

Epoch: 5| Step: 5
Training loss: 5.69799280166626
Validation loss: 4.910933873986685

Epoch: 5| Step: 6
Training loss: 5.351558208465576
Validation loss: 4.906799485606532

Epoch: 5| Step: 7
Training loss: 4.800047397613525
Validation loss: 4.904368210864323

Epoch: 5| Step: 8
Training loss: 3.4864864349365234
Validation loss: 4.900515987027076

Epoch: 5| Step: 9
Training loss: 3.879366636276245
Validation loss: 4.898159186045329

Epoch: 5| Step: 10
Training loss: 5.403680801391602
Validation loss: 4.897747480741111

Epoch: 5| Step: 0
Training loss: 4.437860012054443
Validation loss: 4.8937705306596655

Epoch: 5| Step: 1
Training loss: 5.2353410720825195
Validation loss: 4.892267606591665

Epoch: 5| Step: 2
Training loss: 5.240726470947266
Validation loss: 4.889804752924109

Epoch: 5| Step: 3
Training loss: 3.6104137897491455
Validation loss: 4.8878283962126705

Epoch: 5| Step: 4
Training loss: 5.070528984069824
Validation loss: 4.883144209461827

Epoch: 5| Step: 5
Training loss: 3.3872733116149902
Validation loss: 4.8829066881569485

Epoch: 5| Step: 6
Training loss: 4.20930814743042
Validation loss: 4.877980401439052

Epoch: 5| Step: 7
Training loss: 5.29643440246582
Validation loss: 4.8771287600199384

Epoch: 5| Step: 8
Training loss: 4.8016276359558105
Validation loss: 4.873432292733141

Epoch: 5| Step: 9
Training loss: 4.539332389831543
Validation loss: 4.871007950075211

Epoch: 5| Step: 10
Training loss: 5.725417613983154
Validation loss: 4.867731022578414

Epoch: 6| Step: 0
Training loss: 4.4863762855529785
Validation loss: 4.8660468747538905

Epoch: 5| Step: 1
Training loss: 5.109915733337402
Validation loss: 4.861992715507426

Epoch: 5| Step: 2
Training loss: 5.268941879272461
Validation loss: 4.859652452571417

Epoch: 5| Step: 3
Training loss: 4.954518795013428
Validation loss: 4.855525078312043

Epoch: 5| Step: 4
Training loss: 4.997107982635498
Validation loss: 4.853326551375851

Epoch: 5| Step: 5
Training loss: 4.345827579498291
Validation loss: 4.849839789893037

Epoch: 5| Step: 6
Training loss: 4.357522010803223
Validation loss: 4.848780344891292

Epoch: 5| Step: 7
Training loss: 4.6699395179748535
Validation loss: 4.8445880746328704

Epoch: 5| Step: 8
Training loss: 3.6221764087677
Validation loss: 4.841824229045581

Epoch: 5| Step: 9
Training loss: 4.915406703948975
Validation loss: 4.839405039305328

Epoch: 5| Step: 10
Training loss: 4.266317367553711
Validation loss: 4.8338307052530265

Epoch: 7| Step: 0
Training loss: 4.82738733291626
Validation loss: 4.83239020070722

Epoch: 5| Step: 1
Training loss: 3.86657452583313
Validation loss: 4.829155173352969

Epoch: 5| Step: 2
Training loss: 5.081490516662598
Validation loss: 4.826903163745839

Epoch: 5| Step: 3
Training loss: 5.0476579666137695
Validation loss: 4.822129023972378

Epoch: 5| Step: 4
Training loss: 3.5097789764404297
Validation loss: 4.817262413681195

Epoch: 5| Step: 5
Training loss: 5.823973655700684
Validation loss: 4.817385914505169

Epoch: 5| Step: 6
Training loss: 4.229633808135986
Validation loss: 4.81178278564125

Epoch: 5| Step: 7
Training loss: 4.891499996185303
Validation loss: 4.8069718012245755

Epoch: 5| Step: 8
Training loss: 4.856110572814941
Validation loss: 4.804028182901362

Epoch: 5| Step: 9
Training loss: 4.705211639404297
Validation loss: 4.80029643991942

Epoch: 5| Step: 10
Training loss: 3.6647772789001465
Validation loss: 4.797401392331687

Epoch: 8| Step: 0
Training loss: 4.716495513916016
Validation loss: 4.795271073618243

Epoch: 5| Step: 1
Training loss: 3.6615753173828125
Validation loss: 4.790331107313915

Epoch: 5| Step: 2
Training loss: 4.291703701019287
Validation loss: 4.787912707174978

Epoch: 5| Step: 3
Training loss: 4.203741550445557
Validation loss: 4.783333296416908

Epoch: 5| Step: 4
Training loss: 4.555881500244141
Validation loss: 4.780851805081931

Epoch: 5| Step: 5
Training loss: 4.5004987716674805
Validation loss: 4.776922692534744

Epoch: 5| Step: 6
Training loss: 3.861577272415161
Validation loss: 4.773619700503605

Epoch: 5| Step: 7
Training loss: 5.358223915100098
Validation loss: 4.768226403062061

Epoch: 5| Step: 8
Training loss: 4.250874996185303
Validation loss: 4.763451278850597

Epoch: 5| Step: 9
Training loss: 5.583378791809082
Validation loss: 4.757560283906998

Epoch: 5| Step: 10
Training loss: 5.324559211730957
Validation loss: 4.754524918012722

Epoch: 9| Step: 0
Training loss: 5.001105308532715
Validation loss: 4.752903107673891

Epoch: 5| Step: 1
Training loss: 4.461218357086182
Validation loss: 4.7461022920505975

Epoch: 5| Step: 2
Training loss: 5.633798122406006
Validation loss: 4.743381848899267

Epoch: 5| Step: 3
Training loss: 4.07477331161499
Validation loss: 4.740719810608895

Epoch: 5| Step: 4
Training loss: 4.246544361114502
Validation loss: 4.735740625730124

Epoch: 5| Step: 5
Training loss: 3.7465577125549316
Validation loss: 4.72897881333546

Epoch: 5| Step: 6
Training loss: 4.694305419921875
Validation loss: 4.724578639512421

Epoch: 5| Step: 7
Training loss: 4.712360858917236
Validation loss: 4.719511719160183

Epoch: 5| Step: 8
Training loss: 4.582413673400879
Validation loss: 4.718193720745784

Epoch: 5| Step: 9
Training loss: 4.836284637451172
Validation loss: 4.7139492342548985

Epoch: 5| Step: 10
Training loss: 3.5546064376831055
Validation loss: 4.706151067569691

Epoch: 10| Step: 0
Training loss: 5.218993186950684
Validation loss: 4.7054359682144655

Epoch: 5| Step: 1
Training loss: 4.732072353363037
Validation loss: 4.696827078378329

Epoch: 5| Step: 2
Training loss: 4.167893409729004
Validation loss: 4.693157160153953

Epoch: 5| Step: 3
Training loss: 4.541018962860107
Validation loss: 4.6919048678490425

Epoch: 5| Step: 4
Training loss: 4.152189254760742
Validation loss: 4.685420415734732

Epoch: 5| Step: 5
Training loss: 5.268221378326416
Validation loss: 4.6788191487712245

Epoch: 5| Step: 6
Training loss: 3.931729793548584
Validation loss: 4.67580133868802

Epoch: 5| Step: 7
Training loss: 3.792774200439453
Validation loss: 4.6676724674881145

Epoch: 5| Step: 8
Training loss: 5.40796422958374
Validation loss: 4.665490791361819

Epoch: 5| Step: 9
Training loss: 2.7243971824645996
Validation loss: 4.656468734946302

Epoch: 5| Step: 10
Training loss: 5.30341100692749
Validation loss: 4.658913607238441

Epoch: 11| Step: 0
Training loss: 4.065400123596191
Validation loss: 4.647940892045216

Epoch: 5| Step: 1
Training loss: 5.048447608947754
Validation loss: 4.644864348955052

Epoch: 5| Step: 2
Training loss: 4.460357189178467
Validation loss: 4.639903837634671

Epoch: 5| Step: 3
Training loss: 4.009642601013184
Validation loss: 4.6324207039289576

Epoch: 5| Step: 4
Training loss: 4.464555740356445
Validation loss: 4.626075267791748

Epoch: 5| Step: 5
Training loss: 3.3609185218811035
Validation loss: 4.622623346185171

Epoch: 5| Step: 6
Training loss: 4.845783710479736
Validation loss: 4.617020422412503

Epoch: 5| Step: 7
Training loss: 5.158987522125244
Validation loss: 4.611345609029134

Epoch: 5| Step: 8
Training loss: 4.2695536613464355
Validation loss: 4.60681543555311

Epoch: 5| Step: 9
Training loss: 4.655388832092285
Validation loss: 4.600264318527714

Epoch: 5| Step: 10
Training loss: 4.073758602142334
Validation loss: 4.595813238492576

Epoch: 12| Step: 0
Training loss: 5.081391334533691
Validation loss: 4.588801204517323

Epoch: 5| Step: 1
Training loss: 4.197103023529053
Validation loss: 4.585022177747501

Epoch: 5| Step: 2
Training loss: 3.9117541313171387
Validation loss: 4.579429103482154

Epoch: 5| Step: 3
Training loss: 3.7725746631622314
Validation loss: 4.5716912592611

Epoch: 5| Step: 4
Training loss: 4.620657444000244
Validation loss: 4.563765623236216

Epoch: 5| Step: 5
Training loss: 3.3840274810791016
Validation loss: 4.558381701028475

Epoch: 5| Step: 6
Training loss: 3.859572172164917
Validation loss: 4.549406266981555

Epoch: 5| Step: 7
Training loss: 5.34777307510376
Validation loss: 4.544344548256166

Epoch: 5| Step: 8
Training loss: 5.025810241699219
Validation loss: 4.536608180692119

Epoch: 5| Step: 9
Training loss: 3.8242125511169434
Validation loss: 4.5326576258546565

Epoch: 5| Step: 10
Training loss: 4.8202595710754395
Validation loss: 4.521161697244131

Epoch: 13| Step: 0
Training loss: 4.365342617034912
Validation loss: 4.519416727045531

Epoch: 5| Step: 1
Training loss: 4.524602890014648
Validation loss: 4.508979341035248

Epoch: 5| Step: 2
Training loss: 4.738028526306152
Validation loss: 4.50211061457152

Epoch: 5| Step: 3
Training loss: 4.120734214782715
Validation loss: 4.496925994914065

Epoch: 5| Step: 4
Training loss: 3.9294841289520264
Validation loss: 4.486336415813815

Epoch: 5| Step: 5
Training loss: 4.682246208190918
Validation loss: 4.48048786963186

Epoch: 5| Step: 6
Training loss: 4.579924583435059
Validation loss: 4.473939300865255

Epoch: 5| Step: 7
Training loss: 4.642129421234131
Validation loss: 4.465574100453367

Epoch: 5| Step: 8
Training loss: 3.6556365489959717
Validation loss: 4.4568265638043805

Epoch: 5| Step: 9
Training loss: 3.7358291149139404
Validation loss: 4.451855490284581

Epoch: 5| Step: 10
Training loss: 3.855320692062378
Validation loss: 4.439730234043573

Epoch: 14| Step: 0
Training loss: 4.668842792510986
Validation loss: 4.433727969405472

Epoch: 5| Step: 1
Training loss: 3.854217052459717
Validation loss: 4.422410754747288

Epoch: 5| Step: 2
Training loss: 4.627160549163818
Validation loss: 4.417595765923941

Epoch: 5| Step: 3
Training loss: 3.382401704788208
Validation loss: 4.406360851821079

Epoch: 5| Step: 4
Training loss: 3.842777729034424
Validation loss: 4.399806586644983

Epoch: 5| Step: 5
Training loss: 4.321996212005615
Validation loss: 4.387632769923056

Epoch: 5| Step: 6
Training loss: 3.9244046211242676
Validation loss: 4.385869251784458

Epoch: 5| Step: 7
Training loss: 3.9857337474823
Validation loss: 4.371733527029714

Epoch: 5| Step: 8
Training loss: 4.330813884735107
Validation loss: 4.364232488857803

Epoch: 5| Step: 9
Training loss: 4.206255912780762
Validation loss: 4.358176098074964

Epoch: 5| Step: 10
Training loss: 4.923005104064941
Validation loss: 4.3459480859900035

Epoch: 15| Step: 0
Training loss: 5.166463375091553
Validation loss: 4.3402814865112305

Epoch: 5| Step: 1
Training loss: 5.206772327423096
Validation loss: 4.3275685412909395

Epoch: 5| Step: 2
Training loss: 4.191669464111328
Validation loss: 4.320566864423855

Epoch: 5| Step: 3
Training loss: 3.7352423667907715
Validation loss: 4.313294397887363

Epoch: 5| Step: 4
Training loss: 3.347348690032959
Validation loss: 4.300639321727138

Epoch: 5| Step: 5
Training loss: 3.5443642139434814
Validation loss: 4.289648632849416

Epoch: 5| Step: 6
Training loss: 4.163580894470215
Validation loss: 4.279002199890793

Epoch: 5| Step: 7
Training loss: 3.1513800621032715
Validation loss: 4.266691515522618

Epoch: 5| Step: 8
Training loss: 3.1556143760681152
Validation loss: 4.265473704184255

Epoch: 5| Step: 9
Training loss: 5.204672813415527
Validation loss: 4.24991887615573

Epoch: 5| Step: 10
Training loss: 4.095046043395996
Validation loss: 4.2418782223937335

Epoch: 16| Step: 0
Training loss: 5.479639053344727
Validation loss: 4.22912460245112

Epoch: 5| Step: 1
Training loss: 4.969364643096924
Validation loss: 4.221206982930501

Epoch: 5| Step: 2
Training loss: 4.7358856201171875
Validation loss: 4.20961372826689

Epoch: 5| Step: 3
Training loss: 4.4338274002075195
Validation loss: 4.196902172539824

Epoch: 5| Step: 4
Training loss: 4.055926322937012
Validation loss: 4.184756801974389

Epoch: 5| Step: 5
Training loss: 2.864290714263916
Validation loss: 4.170398345557592

Epoch: 5| Step: 6
Training loss: 4.018164157867432
Validation loss: 4.165706757576235

Epoch: 5| Step: 7
Training loss: 3.3185882568359375
Validation loss: 4.158109744389852

Epoch: 5| Step: 8
Training loss: 2.7612524032592773
Validation loss: 4.139200097771101

Epoch: 5| Step: 9
Training loss: 3.8509063720703125
Validation loss: 4.1274998931474585

Epoch: 5| Step: 10
Training loss: 3.2163002490997314
Validation loss: 4.118336021259267

Epoch: 17| Step: 0
Training loss: 4.42617654800415
Validation loss: 4.107776247045045

Epoch: 5| Step: 1
Training loss: 4.3451433181762695
Validation loss: 4.092904570282147

Epoch: 5| Step: 2
Training loss: 4.609065055847168
Validation loss: 4.0800892486367175

Epoch: 5| Step: 3
Training loss: 3.8669962882995605
Validation loss: 4.067604352069157

Epoch: 5| Step: 4
Training loss: 4.259821891784668
Validation loss: 4.05419179701036

Epoch: 5| Step: 5
Training loss: 3.123051404953003
Validation loss: 4.043203764064337

Epoch: 5| Step: 6
Training loss: 3.0117721557617188
Validation loss: 4.033026672178699

Epoch: 5| Step: 7
Training loss: 3.683605909347534
Validation loss: 4.016177449175107

Epoch: 5| Step: 8
Training loss: 3.552536725997925
Validation loss: 4.003510295703847

Epoch: 5| Step: 9
Training loss: 4.484105110168457
Validation loss: 3.988006381578343

Epoch: 5| Step: 10
Training loss: 3.112464189529419
Validation loss: 3.9779535262815413

Epoch: 18| Step: 0
Training loss: 3.4502906799316406
Validation loss: 3.963996430878998

Epoch: 5| Step: 1
Training loss: 4.257419586181641
Validation loss: 3.96001519439041

Epoch: 5| Step: 2
Training loss: 4.066525459289551
Validation loss: 3.9390406300944667

Epoch: 5| Step: 3
Training loss: 2.6586251258850098
Validation loss: 3.9357865907812632

Epoch: 5| Step: 4
Training loss: 4.164252758026123
Validation loss: 3.9113387907705

Epoch: 5| Step: 5
Training loss: 3.8535149097442627
Validation loss: 3.9001702903419413

Epoch: 5| Step: 6
Training loss: 5.518352508544922
Validation loss: 3.8859009947828067

Epoch: 5| Step: 7
Training loss: 3.469621181488037
Validation loss: 3.8769418116538756

Epoch: 5| Step: 8
Training loss: 2.7938148975372314
Validation loss: 3.8546637694040933

Epoch: 5| Step: 9
Training loss: 3.9273838996887207
Validation loss: 3.839773549828478

Epoch: 5| Step: 10
Training loss: 2.9604501724243164
Validation loss: 3.8317935415493545

Epoch: 19| Step: 0
Training loss: 3.3001811504364014
Validation loss: 3.8176087256400817

Epoch: 5| Step: 1
Training loss: 2.836872100830078
Validation loss: 3.8067252302682526

Epoch: 5| Step: 2
Training loss: 3.224463701248169
Validation loss: 3.7868748582819456

Epoch: 5| Step: 3
Training loss: 3.88139271736145
Validation loss: 3.781091982318509

Epoch: 5| Step: 4
Training loss: 3.893794536590576
Validation loss: 3.7619524924985823

Epoch: 5| Step: 5
Training loss: 3.741180419921875
Validation loss: 3.7452911100079938

Epoch: 5| Step: 6
Training loss: 4.562220096588135
Validation loss: 3.7425669777777886

Epoch: 5| Step: 7
Training loss: 3.735349655151367
Validation loss: 3.7160753793613885

Epoch: 5| Step: 8
Training loss: 3.7072196006774902
Validation loss: 3.700467945427023

Epoch: 5| Step: 9
Training loss: 3.604520082473755
Validation loss: 3.6949637628370717

Epoch: 5| Step: 10
Training loss: 3.1716930866241455
Validation loss: 3.667975817957232

Epoch: 20| Step: 0
Training loss: 3.322969436645508
Validation loss: 3.658694621055357

Epoch: 5| Step: 1
Training loss: 3.6302523612976074
Validation loss: 3.6380046772700485

Epoch: 5| Step: 2
Training loss: 3.9505558013916016
Validation loss: 3.6330173143776516

Epoch: 5| Step: 3
Training loss: 3.4855453968048096
Validation loss: 3.6075582401726836

Epoch: 5| Step: 4
Training loss: 3.425572156906128
Validation loss: 3.588744301949778

Epoch: 5| Step: 5
Training loss: 3.441939115524292
Validation loss: 3.5837067147736907

Epoch: 5| Step: 6
Training loss: 2.9173049926757812
Validation loss: 3.5660254545109247

Epoch: 5| Step: 7
Training loss: 3.1244056224823
Validation loss: 3.548669033153083

Epoch: 5| Step: 8
Training loss: 3.936857223510742
Validation loss: 3.5362197814449186

Epoch: 5| Step: 9
Training loss: 2.7539401054382324
Validation loss: 3.5159414481091242

Epoch: 5| Step: 10
Training loss: 4.220486164093018
Validation loss: 3.507164462920158

Epoch: 21| Step: 0
Training loss: 1.9174327850341797
Validation loss: 3.4884841006289244

Epoch: 5| Step: 1
Training loss: 4.186418056488037
Validation loss: 3.46290684259066

Epoch: 5| Step: 2
Training loss: 4.051760673522949
Validation loss: 3.443974784625474

Epoch: 5| Step: 3
Training loss: 3.4045510292053223
Validation loss: 3.4214975680074384

Epoch: 5| Step: 4
Training loss: 3.041694164276123
Validation loss: 3.401638966734691

Epoch: 5| Step: 5
Training loss: 3.4860713481903076
Validation loss: 3.3912855937916744

Epoch: 5| Step: 6
Training loss: 2.559105396270752
Validation loss: 3.384417418510683

Epoch: 5| Step: 7
Training loss: 3.337777614593506
Validation loss: 3.352841179857972

Epoch: 5| Step: 8
Training loss: 3.737819194793701
Validation loss: 3.3256438675747124

Epoch: 5| Step: 9
Training loss: 3.364910125732422
Validation loss: 3.30101260318551

Epoch: 5| Step: 10
Training loss: 3.1819047927856445
Validation loss: 3.294266982745099

Epoch: 22| Step: 0
Training loss: 2.4172401428222656
Validation loss: 3.281710183748635

Epoch: 5| Step: 1
Training loss: 3.281062364578247
Validation loss: 3.250269425812588

Epoch: 5| Step: 2
Training loss: 3.2176079750061035
Validation loss: 3.2400849557692006

Epoch: 5| Step: 3
Training loss: 2.497955799102783
Validation loss: 3.217470948414136

Epoch: 5| Step: 4
Training loss: 3.564547061920166
Validation loss: 3.1799557644833802

Epoch: 5| Step: 5
Training loss: 3.2534193992614746
Validation loss: 3.186820614722467

Epoch: 5| Step: 6
Training loss: 3.2181098461151123
Validation loss: 3.150877726975308

Epoch: 5| Step: 7
Training loss: 3.6459274291992188
Validation loss: 3.148525253418953

Epoch: 5| Step: 8
Training loss: 3.476909637451172
Validation loss: 3.11306433780219

Epoch: 5| Step: 9
Training loss: 2.827319383621216
Validation loss: 3.084295836828088

Epoch: 5| Step: 10
Training loss: 2.8749051094055176
Validation loss: 3.0750716937485563

Epoch: 23| Step: 0
Training loss: 3.0487427711486816
Validation loss: 3.050599482751662

Epoch: 5| Step: 1
Training loss: 3.3174972534179688
Validation loss: 3.034928321838379

Epoch: 5| Step: 2
Training loss: 3.3661160469055176
Validation loss: 3.0034599201653593

Epoch: 5| Step: 3
Training loss: 2.8031628131866455
Validation loss: 2.9897774675840973

Epoch: 5| Step: 4
Training loss: 2.668071746826172
Validation loss: 2.9565196139838106

Epoch: 5| Step: 5
Training loss: 2.9965033531188965
Validation loss: 2.9526276126984627

Epoch: 5| Step: 6
Training loss: 3.1118552684783936
Validation loss: 2.923279926341067

Epoch: 5| Step: 7
Training loss: 2.595194101333618
Validation loss: 2.903362279297203

Epoch: 5| Step: 8
Training loss: 2.656883955001831
Validation loss: 2.8998530398132982

Epoch: 5| Step: 9
Training loss: 3.220344066619873
Validation loss: 2.8635851721609793

Epoch: 5| Step: 10
Training loss: 2.882011890411377
Validation loss: 2.839894910012522

Epoch: 24| Step: 0
Training loss: 3.773293972015381
Validation loss: 2.8412174024889545

Epoch: 5| Step: 1
Training loss: 2.832376003265381
Validation loss: 2.7988374181973037

Epoch: 5| Step: 2
Training loss: 2.6534087657928467
Validation loss: 2.783290240072435

Epoch: 5| Step: 3
Training loss: 3.05910062789917
Validation loss: 2.752968877874395

Epoch: 5| Step: 4
Training loss: 2.6473584175109863
Validation loss: 2.740699350192983

Epoch: 5| Step: 5
Training loss: 2.6447606086730957
Validation loss: 2.7022993615878526

Epoch: 5| Step: 6
Training loss: 2.436490535736084
Validation loss: 2.690706194088023

Epoch: 5| Step: 7
Training loss: 2.423457622528076
Validation loss: 2.660706566226098

Epoch: 5| Step: 8
Training loss: 2.8974602222442627
Validation loss: 2.65155001096828

Epoch: 5| Step: 9
Training loss: 3.2179512977600098
Validation loss: 2.6311611155027985

Epoch: 5| Step: 10
Training loss: 2.5679078102111816
Validation loss: 2.620207058486118

Epoch: 25| Step: 0
Training loss: 2.516879081726074
Validation loss: 2.5985488968510784

Epoch: 5| Step: 1
Training loss: 2.5045998096466064
Validation loss: 2.5786179906578472

Epoch: 5| Step: 2
Training loss: 2.8769233226776123
Validation loss: 2.571674623797017

Epoch: 5| Step: 3
Training loss: 2.5686733722686768
Validation loss: 2.535118115845547

Epoch: 5| Step: 4
Training loss: 3.018538236618042
Validation loss: 2.5198373717646443

Epoch: 5| Step: 5
Training loss: 1.9976228475570679
Validation loss: 2.5147956622544156

Epoch: 5| Step: 6
Training loss: 2.8961939811706543
Validation loss: 2.499350301681026

Epoch: 5| Step: 7
Training loss: 2.5823280811309814
Validation loss: 2.4929634960748817

Epoch: 5| Step: 8
Training loss: 3.073248863220215
Validation loss: 2.4669022867756505

Epoch: 5| Step: 9
Training loss: 2.583789587020874
Validation loss: 2.456276780815535

Epoch: 5| Step: 10
Training loss: 2.707441806793213
Validation loss: 2.4226408132942776

Epoch: 26| Step: 0
Training loss: 2.080221176147461
Validation loss: 2.4255681704449397

Epoch: 5| Step: 1
Training loss: 3.012467622756958
Validation loss: 2.4162741168852775

Epoch: 5| Step: 2
Training loss: 2.824094533920288
Validation loss: 2.3937021429820726

Epoch: 5| Step: 3
Training loss: 2.5809378623962402
Validation loss: 2.3696448674765964

Epoch: 5| Step: 4
Training loss: 2.1244189739227295
Validation loss: 2.3703613537614063

Epoch: 5| Step: 5
Training loss: 3.1079928874969482
Validation loss: 2.3551552270048406

Epoch: 5| Step: 6
Training loss: 2.0945003032684326
Validation loss: 2.3589033272958573

Epoch: 5| Step: 7
Training loss: 2.8297336101531982
Validation loss: 2.3487615892964024

Epoch: 5| Step: 8
Training loss: 2.241405487060547
Validation loss: 2.326074779674571

Epoch: 5| Step: 9
Training loss: 2.1944403648376465
Validation loss: 2.303772557166315

Epoch: 5| Step: 10
Training loss: 3.026360273361206
Validation loss: 2.300516543849822

Epoch: 27| Step: 0
Training loss: 2.4868156909942627
Validation loss: 2.281067922551145

Epoch: 5| Step: 1
Training loss: 2.4721670150756836
Validation loss: 2.2668074741158435

Epoch: 5| Step: 2
Training loss: 2.7069919109344482
Validation loss: 2.252119148931196

Epoch: 5| Step: 3
Training loss: 2.0474536418914795
Validation loss: 2.257038116455078

Epoch: 5| Step: 4
Training loss: 2.9472439289093018
Validation loss: 2.2386345389068767

Epoch: 5| Step: 5
Training loss: 2.1680057048797607
Validation loss: 2.242680007411588

Epoch: 5| Step: 6
Training loss: 3.1968636512756348
Validation loss: 2.2362056445049983

Epoch: 5| Step: 7
Training loss: 2.055032253265381
Validation loss: 2.205126864935762

Epoch: 5| Step: 8
Training loss: 2.31455659866333
Validation loss: 2.165884041017102

Epoch: 5| Step: 9
Training loss: 2.582082986831665
Validation loss: 2.188745332020585

Epoch: 5| Step: 10
Training loss: 2.452683210372925
Validation loss: 2.1633122582589426

Epoch: 28| Step: 0
Training loss: 2.278599262237549
Validation loss: 2.1675807404261764

Epoch: 5| Step: 1
Training loss: 2.074828624725342
Validation loss: 2.1448322124378656

Epoch: 5| Step: 2
Training loss: 2.6108314990997314
Validation loss: 2.173981007709298

Epoch: 5| Step: 3
Training loss: 2.1705322265625
Validation loss: 2.165685853650493

Epoch: 5| Step: 4
Training loss: 2.8424148559570312
Validation loss: 2.1567546039499264

Epoch: 5| Step: 5
Training loss: 2.3769068717956543
Validation loss: 2.1579236676616054

Epoch: 5| Step: 6
Training loss: 2.5738778114318848
Validation loss: 2.1496695241620465

Epoch: 5| Step: 7
Training loss: 2.4437928199768066
Validation loss: 2.1629974239615986

Epoch: 5| Step: 8
Training loss: 2.9324305057525635
Validation loss: 2.1402609604661182

Epoch: 5| Step: 9
Training loss: 1.9943692684173584
Validation loss: 2.116690565181035

Epoch: 5| Step: 10
Training loss: 2.666389226913452
Validation loss: 2.1172948319424867

Epoch: 29| Step: 0
Training loss: 2.7430903911590576
Validation loss: 2.1245710811307355

Epoch: 5| Step: 1
Training loss: 2.010272264480591
Validation loss: 2.15203566833209

Epoch: 5| Step: 2
Training loss: 2.6692681312561035
Validation loss: 2.117963347383725

Epoch: 5| Step: 3
Training loss: 2.9402623176574707
Validation loss: 2.108289650691453

Epoch: 5| Step: 4
Training loss: 2.9884581565856934
Validation loss: 2.1197185926539923

Epoch: 5| Step: 5
Training loss: 2.1842429637908936
Validation loss: 2.1242576081265687

Epoch: 5| Step: 6
Training loss: 1.7511913776397705
Validation loss: 2.103940899654101

Epoch: 5| Step: 7
Training loss: 1.9423946142196655
Validation loss: 2.131659864097513

Epoch: 5| Step: 8
Training loss: 2.613438606262207
Validation loss: 2.1016337230641353

Epoch: 5| Step: 9
Training loss: 2.9115874767303467
Validation loss: 2.0932646451457853

Epoch: 5| Step: 10
Training loss: 2.0111734867095947
Validation loss: 2.0915365231934415

Epoch: 30| Step: 0
Training loss: 2.479189157485962
Validation loss: 2.1094973792311964

Epoch: 5| Step: 1
Training loss: 2.0778441429138184
Validation loss: 2.1044891598404094

Epoch: 5| Step: 2
Training loss: 2.13362717628479
Validation loss: 2.094338111979987

Epoch: 5| Step: 3
Training loss: 2.7317581176757812
Validation loss: 2.0771195888519287

Epoch: 5| Step: 4
Training loss: 2.488234758377075
Validation loss: 2.098785831082252

Epoch: 5| Step: 5
Training loss: 1.569543480873108
Validation loss: 2.0698627105323215

Epoch: 5| Step: 6
Training loss: 2.2823081016540527
Validation loss: 2.0939142306645713

Epoch: 5| Step: 7
Training loss: 3.1793370246887207
Validation loss: 2.0826978670653475

Epoch: 5| Step: 8
Training loss: 3.0648791790008545
Validation loss: 2.0777359880426878

Epoch: 5| Step: 9
Training loss: 2.3324732780456543
Validation loss: 2.1215376905215684

Epoch: 5| Step: 10
Training loss: 2.3862268924713135
Validation loss: 2.0545089065387683

Epoch: 31| Step: 0
Training loss: 2.130159616470337
Validation loss: 2.0983134943951844

Epoch: 5| Step: 1
Training loss: 2.0099830627441406
Validation loss: 2.0920988282849713

Epoch: 5| Step: 2
Training loss: 1.7772992849349976
Validation loss: 2.09234703740766

Epoch: 5| Step: 3
Training loss: 1.8483692407608032
Validation loss: 2.0884879071225404

Epoch: 5| Step: 4
Training loss: 2.835597276687622
Validation loss: 2.082216562763337

Epoch: 5| Step: 5
Training loss: 2.3124496936798096
Validation loss: 2.075917056811753

Epoch: 5| Step: 6
Training loss: 3.0095884799957275
Validation loss: 2.0660940113887993

Epoch: 5| Step: 7
Training loss: 3.045208692550659
Validation loss: 2.0693641298560688

Epoch: 5| Step: 8
Training loss: 1.9646713733673096
Validation loss: 2.0901804457428637

Epoch: 5| Step: 9
Training loss: 2.405804395675659
Validation loss: 2.090673815819525

Epoch: 5| Step: 10
Training loss: 3.3506407737731934
Validation loss: 2.0741094158541773

Epoch: 32| Step: 0
Training loss: 2.2346911430358887
Validation loss: 2.0552720280103784

Epoch: 5| Step: 1
Training loss: 2.2286219596862793
Validation loss: 2.0928865696794245

Epoch: 5| Step: 2
Training loss: 2.6700568199157715
Validation loss: 2.043349596761888

Epoch: 5| Step: 3
Training loss: 2.7377641201019287
Validation loss: 2.078625153469783

Epoch: 5| Step: 4
Training loss: 2.3819026947021484
Validation loss: 2.067147577962568

Epoch: 5| Step: 5
Training loss: 2.3006844520568848
Validation loss: 2.0609723073180004

Epoch: 5| Step: 6
Training loss: 2.5153138637542725
Validation loss: 2.091527050541293

Epoch: 5| Step: 7
Training loss: 1.9970932006835938
Validation loss: 2.0868988754928752

Epoch: 5| Step: 8
Training loss: 2.310563325881958
Validation loss: 2.0683739762152396

Epoch: 5| Step: 9
Training loss: 2.873025417327881
Validation loss: 2.074054032243708

Epoch: 5| Step: 10
Training loss: 2.2431726455688477
Validation loss: 2.1020472254804385

Epoch: 33| Step: 0
Training loss: 2.3413734436035156
Validation loss: 2.0574094595447665

Epoch: 5| Step: 1
Training loss: 3.141709804534912
Validation loss: 2.0779434173337874

Epoch: 5| Step: 2
Training loss: 2.3934881687164307
Validation loss: 2.0610568600316204

Epoch: 5| Step: 3
Training loss: 2.317957639694214
Validation loss: 2.087816446058212

Epoch: 5| Step: 4
Training loss: 2.791703701019287
Validation loss: 2.072101416126374

Epoch: 5| Step: 5
Training loss: 2.4108214378356934
Validation loss: 2.0796087826451948

Epoch: 5| Step: 6
Training loss: 1.620888113975525
Validation loss: 2.0703160737150457

Epoch: 5| Step: 7
Training loss: 1.8107261657714844
Validation loss: 2.0526375591114

Epoch: 5| Step: 8
Training loss: 2.052579164505005
Validation loss: 2.0731267031802925

Epoch: 5| Step: 9
Training loss: 2.8096630573272705
Validation loss: 2.0756044003271286

Epoch: 5| Step: 10
Training loss: 2.8622875213623047
Validation loss: 2.0762889974860737

Epoch: 34| Step: 0
Training loss: 2.8113021850585938
Validation loss: 2.049952478818996

Epoch: 5| Step: 1
Training loss: 2.2449910640716553
Validation loss: 2.0902045567830405

Epoch: 5| Step: 2
Training loss: 1.921542763710022
Validation loss: 2.054959540726036

Epoch: 5| Step: 3
Training loss: 2.2871253490448
Validation loss: 2.059624197662518

Epoch: 5| Step: 4
Training loss: 2.677842140197754
Validation loss: 2.0379086514954925

Epoch: 5| Step: 5
Training loss: 2.366375207901001
Validation loss: 2.062838710764403

Epoch: 5| Step: 6
Training loss: 2.211726188659668
Validation loss: 2.0602532586743756

Epoch: 5| Step: 7
Training loss: 2.2275445461273193
Validation loss: 2.0976888069542508

Epoch: 5| Step: 8
Training loss: 2.313241958618164
Validation loss: 2.0540469423417123

Epoch: 5| Step: 9
Training loss: 2.86271333694458
Validation loss: 2.0844872074742473

Epoch: 5| Step: 10
Training loss: 2.65816330909729
Validation loss: 2.0740633049318866

Epoch: 35| Step: 0
Training loss: 2.4787728786468506
Validation loss: 2.0709856325580227

Epoch: 5| Step: 1
Training loss: 2.1851532459259033
Validation loss: 2.085231306732342

Epoch: 5| Step: 2
Training loss: 2.612941265106201
Validation loss: 2.0677033880705475

Epoch: 5| Step: 3
Training loss: 2.5318374633789062
Validation loss: 2.0550578204534387

Epoch: 5| Step: 4
Training loss: 2.5059704780578613
Validation loss: 2.059685622492144

Epoch: 5| Step: 5
Training loss: 2.110771656036377
Validation loss: 2.0491384306261615

Epoch: 5| Step: 6
Training loss: 2.814182996749878
Validation loss: 2.068275213241577

Epoch: 5| Step: 7
Training loss: 2.87737774848938
Validation loss: 2.059747803595758

Epoch: 5| Step: 8
Training loss: 2.273784637451172
Validation loss: 2.0355592517442602

Epoch: 5| Step: 9
Training loss: 2.561647891998291
Validation loss: 2.045017985887425

Epoch: 5| Step: 10
Training loss: 1.3968501091003418
Validation loss: 2.062068368798943

Epoch: 36| Step: 0
Training loss: 2.0087637901306152
Validation loss: 2.0481684720644386

Epoch: 5| Step: 1
Training loss: 2.614109516143799
Validation loss: 2.05539079635374

Epoch: 5| Step: 2
Training loss: 1.8994762897491455
Validation loss: 2.038838586499614

Epoch: 5| Step: 3
Training loss: 3.2587826251983643
Validation loss: 2.040118299504762

Epoch: 5| Step: 4
Training loss: 2.4465389251708984
Validation loss: 2.04618477564986

Epoch: 5| Step: 5
Training loss: 2.432424783706665
Validation loss: 2.0657909044655423

Epoch: 5| Step: 6
Training loss: 2.7941856384277344
Validation loss: 2.068879924794679

Epoch: 5| Step: 7
Training loss: 2.6314175128936768
Validation loss: 2.0346523433603267

Epoch: 5| Step: 8
Training loss: 1.3714178800582886
Validation loss: 2.067978782038535

Epoch: 5| Step: 9
Training loss: 2.239570140838623
Validation loss: 2.068601922322345

Epoch: 5| Step: 10
Training loss: 2.673283815383911
Validation loss: 2.0502538963030745

Epoch: 37| Step: 0
Training loss: 1.6325559616088867
Validation loss: 2.0408259104656916

Epoch: 5| Step: 1
Training loss: 3.1841928958892822
Validation loss: 2.0396015759437316

Epoch: 5| Step: 2
Training loss: 2.618652820587158
Validation loss: 2.0394165259535595

Epoch: 5| Step: 3
Training loss: 2.4688971042633057
Validation loss: 2.039823556459078

Epoch: 5| Step: 4
Training loss: 1.7117429971694946
Validation loss: 2.0236371640236146

Epoch: 5| Step: 5
Training loss: 2.2932558059692383
Validation loss: 2.0660596329678773

Epoch: 5| Step: 6
Training loss: 2.5671632289886475
Validation loss: 2.0724187768915647

Epoch: 5| Step: 7
Training loss: 2.9241068363189697
Validation loss: 2.0805294000974266

Epoch: 5| Step: 8
Training loss: 2.4168734550476074
Validation loss: 2.0670525104768815

Epoch: 5| Step: 9
Training loss: 2.81672739982605
Validation loss: 2.0440494860372236

Epoch: 5| Step: 10
Training loss: 1.6644254922866821
Validation loss: 2.075143988414477

Epoch: 38| Step: 0
Training loss: 2.266329050064087
Validation loss: 2.0602475007375083

Epoch: 5| Step: 1
Training loss: 2.506072521209717
Validation loss: 2.0338544281580115

Epoch: 5| Step: 2
Training loss: 2.3967068195343018
Validation loss: 2.0457509666360836

Epoch: 5| Step: 3
Training loss: 2.1158783435821533
Validation loss: 2.0335407128898044

Epoch: 5| Step: 4
Training loss: 2.5196027755737305
Validation loss: 2.0541438761577813

Epoch: 5| Step: 5
Training loss: 2.2953381538391113
Validation loss: 2.0367307688600276

Epoch: 5| Step: 6
Training loss: 2.486222743988037
Validation loss: 2.012060549951369

Epoch: 5| Step: 7
Training loss: 2.151766538619995
Validation loss: 2.0348413170024915

Epoch: 5| Step: 8
Training loss: 3.2649319171905518
Validation loss: 2.0442158342689596

Epoch: 5| Step: 9
Training loss: 2.0714306831359863
Validation loss: 2.0453615316780667

Epoch: 5| Step: 10
Training loss: 2.2440860271453857
Validation loss: 2.033981054059921

Epoch: 39| Step: 0
Training loss: 3.100245952606201
Validation loss: 2.0431496302286782

Epoch: 5| Step: 1
Training loss: 2.3919849395751953
Validation loss: 2.0258558488661245

Epoch: 5| Step: 2
Training loss: 2.0563111305236816
Validation loss: 2.066986532621486

Epoch: 5| Step: 3
Training loss: 2.2021822929382324
Validation loss: 2.067993228153516

Epoch: 5| Step: 4
Training loss: 1.6565742492675781
Validation loss: 2.0479223830725557

Epoch: 5| Step: 5
Training loss: 2.0140254497528076
Validation loss: 2.046173490503783

Epoch: 5| Step: 6
Training loss: 2.7275304794311523
Validation loss: 2.0515049285786127

Epoch: 5| Step: 7
Training loss: 1.9068663120269775
Validation loss: 2.064333228654759

Epoch: 5| Step: 8
Training loss: 2.968249559402466
Validation loss: 2.043188736002932

Epoch: 5| Step: 9
Training loss: 2.644129514694214
Validation loss: 2.060808099726195

Epoch: 5| Step: 10
Training loss: 2.5509192943573
Validation loss: 2.0399679022450603

Epoch: 40| Step: 0
Training loss: 1.9775311946868896
Validation loss: 2.0254822597708753

Epoch: 5| Step: 1
Training loss: 1.6162532567977905
Validation loss: 2.042105690125496

Epoch: 5| Step: 2
Training loss: 2.412360191345215
Validation loss: 2.0674287426856255

Epoch: 5| Step: 3
Training loss: 2.4570369720458984
Validation loss: 2.0374328333844423

Epoch: 5| Step: 4
Training loss: 2.5817923545837402
Validation loss: 2.0237860756535686

Epoch: 5| Step: 5
Training loss: 2.2528481483459473
Validation loss: 2.027618049293436

Epoch: 5| Step: 6
Training loss: 2.4935922622680664
Validation loss: 2.0558569738941808

Epoch: 5| Step: 7
Training loss: 2.5477569103240967
Validation loss: 2.0302300427549627

Epoch: 5| Step: 8
Training loss: 2.277705669403076
Validation loss: 2.042614847101191

Epoch: 5| Step: 9
Training loss: 2.9079394340515137
Validation loss: 2.0205472720566617

Epoch: 5| Step: 10
Training loss: 2.631929397583008
Validation loss: 2.0476470942138345

Epoch: 41| Step: 0
Training loss: 2.3963775634765625
Validation loss: 2.0267233412752867

Epoch: 5| Step: 1
Training loss: 2.6939539909362793
Validation loss: 2.0527736269017702

Epoch: 5| Step: 2
Training loss: 2.8378281593322754
Validation loss: 2.0387498101880475

Epoch: 5| Step: 3
Training loss: 1.6872625350952148
Validation loss: 2.058187133522444

Epoch: 5| Step: 4
Training loss: 2.4374096393585205
Validation loss: 2.055531083896596

Epoch: 5| Step: 5
Training loss: 2.4898924827575684
Validation loss: 2.0409083340757634

Epoch: 5| Step: 6
Training loss: 2.2558698654174805
Validation loss: 2.0606838772373814

Epoch: 5| Step: 7
Training loss: 1.9957072734832764
Validation loss: 2.0684336526419527

Epoch: 5| Step: 8
Training loss: 2.5924692153930664
Validation loss: 2.0400707696073797

Epoch: 5| Step: 9
Training loss: 2.1094889640808105
Validation loss: 2.0455784913032287

Epoch: 5| Step: 10
Training loss: 2.7683441638946533
Validation loss: 2.037289910419013

Epoch: 42| Step: 0
Training loss: 2.0938024520874023
Validation loss: 2.0700741608937583

Epoch: 5| Step: 1
Training loss: 2.0403335094451904
Validation loss: 2.0458621542940856

Epoch: 5| Step: 2
Training loss: 2.662341356277466
Validation loss: 2.0818405253912813

Epoch: 5| Step: 3
Training loss: 2.059630870819092
Validation loss: 2.065901243558494

Epoch: 5| Step: 4
Training loss: 2.8741962909698486
Validation loss: 2.037902439794233

Epoch: 5| Step: 5
Training loss: 2.766047954559326
Validation loss: 2.0451966921488443

Epoch: 5| Step: 6
Training loss: 2.3696467876434326
Validation loss: 2.0346147937159382

Epoch: 5| Step: 7
Training loss: 2.341975212097168
Validation loss: 2.0413500493572605

Epoch: 5| Step: 8
Training loss: 2.3839728832244873
Validation loss: 2.0622602944732993

Epoch: 5| Step: 9
Training loss: 2.4104220867156982
Validation loss: 2.025977397477755

Epoch: 5| Step: 10
Training loss: 2.1927661895751953
Validation loss: 2.040458559989929

Epoch: 43| Step: 0
Training loss: 2.2612390518188477
Validation loss: 2.0399352042905745

Epoch: 5| Step: 1
Training loss: 1.886651635169983
Validation loss: 2.0579349969023015

Epoch: 5| Step: 2
Training loss: 1.819898009300232
Validation loss: 2.0594257513682046

Epoch: 5| Step: 3
Training loss: 2.7293152809143066
Validation loss: 2.0520031939270678

Epoch: 5| Step: 4
Training loss: 2.320889949798584
Validation loss: 2.027963443468976

Epoch: 5| Step: 5
Training loss: 3.0034096240997314
Validation loss: 2.062823069992886

Epoch: 5| Step: 6
Training loss: 2.4314980506896973
Validation loss: 2.049181451079666

Epoch: 5| Step: 7
Training loss: 2.138448715209961
Validation loss: 2.029755087308986

Epoch: 5| Step: 8
Training loss: 2.337847948074341
Validation loss: 2.037960380636236

Epoch: 5| Step: 9
Training loss: 2.5993034839630127
Validation loss: 2.02431978717927

Epoch: 5| Step: 10
Training loss: 2.7658793926239014
Validation loss: 2.0370527031601116

Epoch: 44| Step: 0
Training loss: 2.3504748344421387
Validation loss: 2.0519175952480686

Epoch: 5| Step: 1
Training loss: 2.408269166946411
Validation loss: 2.0671696111720097

Epoch: 5| Step: 2
Training loss: 2.6430487632751465
Validation loss: 2.0580878103933027

Epoch: 5| Step: 3
Training loss: 2.2354636192321777
Validation loss: 2.021905641401968

Epoch: 5| Step: 4
Training loss: 2.6515755653381348
Validation loss: 2.0300251489044516

Epoch: 5| Step: 5
Training loss: 2.22444486618042
Validation loss: 2.047428947623058

Epoch: 5| Step: 6
Training loss: 2.072004795074463
Validation loss: 2.0435521987176712

Epoch: 5| Step: 7
Training loss: 2.5716962814331055
Validation loss: 2.030898194159231

Epoch: 5| Step: 8
Training loss: 2.0099520683288574
Validation loss: 2.06101897967759

Epoch: 5| Step: 9
Training loss: 2.939534902572632
Validation loss: 2.046390684702063

Epoch: 5| Step: 10
Training loss: 1.9249000549316406
Validation loss: 2.020063249013757

Epoch: 45| Step: 0
Training loss: 2.4101004600524902
Validation loss: 2.0571510714869343

Epoch: 5| Step: 1
Training loss: 2.1268115043640137
Validation loss: 2.0633744873026365

Epoch: 5| Step: 2
Training loss: 2.280783176422119
Validation loss: 2.023580612674836

Epoch: 5| Step: 3
Training loss: 2.5200881958007812
Validation loss: 2.0570527456140004

Epoch: 5| Step: 4
Training loss: 2.494473695755005
Validation loss: 2.024862530410931

Epoch: 5| Step: 5
Training loss: 2.097827434539795
Validation loss: 2.0562973048097346

Epoch: 5| Step: 6
Training loss: 2.1912951469421387
Validation loss: 2.0475870973320416

Epoch: 5| Step: 7
Training loss: 2.2902469635009766
Validation loss: 2.0443001613822034

Epoch: 5| Step: 8
Training loss: 2.179324150085449
Validation loss: 2.0636038998121857

Epoch: 5| Step: 9
Training loss: 2.3222403526306152
Validation loss: 2.0329133438807663

Epoch: 5| Step: 10
Training loss: 3.4993011951446533
Validation loss: 2.046444187882126

Epoch: 46| Step: 0
Training loss: 1.8684813976287842
Validation loss: 2.0526728988975607

Epoch: 5| Step: 1
Training loss: 2.2796289920806885
Validation loss: 2.0483109515200377

Epoch: 5| Step: 2
Training loss: 1.7801491022109985
Validation loss: 2.0669437557138424

Epoch: 5| Step: 3
Training loss: 2.5391952991485596
Validation loss: 2.062758746967521

Epoch: 5| Step: 4
Training loss: 2.6128170490264893
Validation loss: 2.0389791586065806

Epoch: 5| Step: 5
Training loss: 1.9583402872085571
Validation loss: 2.0536707729421635

Epoch: 5| Step: 6
Training loss: 3.082841157913208
Validation loss: 2.032646663727299

Epoch: 5| Step: 7
Training loss: 2.7377586364746094
Validation loss: 2.028012337223176

Epoch: 5| Step: 8
Training loss: 2.3980519771575928
Validation loss: 2.035932578066344

Epoch: 5| Step: 9
Training loss: 2.926054000854492
Validation loss: 2.0074346885886243

Epoch: 5| Step: 10
Training loss: 1.8837026357650757
Validation loss: 2.0608120105599843

Epoch: 47| Step: 0
Training loss: 2.915417432785034
Validation loss: 2.0469838367995394

Epoch: 5| Step: 1
Training loss: 2.65728759765625
Validation loss: 2.0403559105370634

Epoch: 5| Step: 2
Training loss: 2.036250352859497
Validation loss: 2.0376142224957867

Epoch: 5| Step: 3
Training loss: 3.3266654014587402
Validation loss: 2.020508684137816

Epoch: 5| Step: 4
Training loss: 2.431361675262451
Validation loss: 2.052932140647724

Epoch: 5| Step: 5
Training loss: 2.2297420501708984
Validation loss: 2.057672018645912

Epoch: 5| Step: 6
Training loss: 1.672075629234314
Validation loss: 2.0078362623850503

Epoch: 5| Step: 7
Training loss: 2.757498264312744
Validation loss: 2.035042223109994

Epoch: 5| Step: 8
Training loss: 2.2843618392944336
Validation loss: 2.0333761912520214

Epoch: 5| Step: 9
Training loss: 1.9877068996429443
Validation loss: 2.0381795219195786

Epoch: 5| Step: 10
Training loss: 1.7432594299316406
Validation loss: 2.057205015613187

Epoch: 48| Step: 0
Training loss: 1.7764463424682617
Validation loss: 2.0563257842935543

Epoch: 5| Step: 1
Training loss: 2.1330628395080566
Validation loss: 2.0474544532837404

Epoch: 5| Step: 2
Training loss: 2.0428874492645264
Validation loss: 2.0544903944897395

Epoch: 5| Step: 3
Training loss: 1.717604398727417
Validation loss: 2.0458589497432915

Epoch: 5| Step: 4
Training loss: 2.3715672492980957
Validation loss: 2.0535554796136837

Epoch: 5| Step: 5
Training loss: 2.619910717010498
Validation loss: 2.0442730611370457

Epoch: 5| Step: 6
Training loss: 2.779864549636841
Validation loss: 2.0268815614843882

Epoch: 5| Step: 7
Training loss: 2.6373724937438965
Validation loss: 2.027396096978136

Epoch: 5| Step: 8
Training loss: 2.50582218170166
Validation loss: 2.054776901839882

Epoch: 5| Step: 9
Training loss: 3.0272536277770996
Validation loss: 2.0522821154645694

Epoch: 5| Step: 10
Training loss: 2.3209376335144043
Validation loss: 2.064828389434404

Epoch: 49| Step: 0
Training loss: 3.3970787525177
Validation loss: 2.0370326490812403

Epoch: 5| Step: 1
Training loss: 2.0766539573669434
Validation loss: 2.024963655779439

Epoch: 5| Step: 2
Training loss: 2.1306235790252686
Validation loss: 2.0608865573842037

Epoch: 5| Step: 3
Training loss: 2.0060200691223145
Validation loss: 2.0130042209420154

Epoch: 5| Step: 4
Training loss: 2.124253034591675
Validation loss: 2.042626909030381

Epoch: 5| Step: 5
Training loss: 1.934967041015625
Validation loss: 2.0393912010295416

Epoch: 5| Step: 6
Training loss: 2.7732205390930176
Validation loss: 2.036901289416898

Epoch: 5| Step: 7
Training loss: 2.5680112838745117
Validation loss: 2.0456813945565173

Epoch: 5| Step: 8
Training loss: 2.479130268096924
Validation loss: 2.063935682337771

Epoch: 5| Step: 9
Training loss: 1.8045337200164795
Validation loss: 2.0396370349391812

Epoch: 5| Step: 10
Training loss: 2.7021703720092773
Validation loss: 2.0306989377544773

Epoch: 50| Step: 0
Training loss: 2.440134048461914
Validation loss: 2.039852885789769

Epoch: 5| Step: 1
Training loss: 2.603543281555176
Validation loss: 2.058123254006909

Epoch: 5| Step: 2
Training loss: 2.569596290588379
Validation loss: 2.0273753212344263

Epoch: 5| Step: 3
Training loss: 2.1912317276000977
Validation loss: 2.0499488474220358

Epoch: 5| Step: 4
Training loss: 2.6899588108062744
Validation loss: 2.029878798351493

Epoch: 5| Step: 5
Training loss: 1.9980294704437256
Validation loss: 2.0508644939750753

Epoch: 5| Step: 6
Training loss: 1.6701974868774414
Validation loss: 2.0341920942388554

Epoch: 5| Step: 7
Training loss: 2.38173246383667
Validation loss: 2.0542818013057915

Epoch: 5| Step: 8
Training loss: 2.001535177230835
Validation loss: 2.042386762557491

Epoch: 5| Step: 9
Training loss: 2.3568942546844482
Validation loss: 2.0517773538507442

Epoch: 5| Step: 10
Training loss: 2.912588119506836
Validation loss: 2.025682104531155

Epoch: 51| Step: 0
Training loss: 2.605297565460205
Validation loss: 2.026883386796521

Epoch: 5| Step: 1
Training loss: 2.3585617542266846
Validation loss: 2.0376282609919065

Epoch: 5| Step: 2
Training loss: 2.2986843585968018
Validation loss: 2.0118305196044264

Epoch: 5| Step: 3
Training loss: 2.473018169403076
Validation loss: 2.0433735411654235

Epoch: 5| Step: 4
Training loss: 1.9528024196624756
Validation loss: 2.0163922002238612

Epoch: 5| Step: 5
Training loss: 1.6721500158309937
Validation loss: 2.0353884363687165

Epoch: 5| Step: 6
Training loss: 2.2513203620910645
Validation loss: 2.0225262334269862

Epoch: 5| Step: 7
Training loss: 2.6218655109405518
Validation loss: 2.027136653982183

Epoch: 5| Step: 8
Training loss: 2.5589988231658936
Validation loss: 2.0084356415656304

Epoch: 5| Step: 9
Training loss: 2.4444923400878906
Validation loss: 2.0536848832202215

Epoch: 5| Step: 10
Training loss: 2.634222984313965
Validation loss: 2.0206366738965436

Epoch: 52| Step: 0
Training loss: 2.532386302947998
Validation loss: 1.999467711294851

Epoch: 5| Step: 1
Training loss: 1.6606452465057373
Validation loss: 2.0082829229293333

Epoch: 5| Step: 2
Training loss: 2.779301166534424
Validation loss: 2.0249362350792013

Epoch: 5| Step: 3
Training loss: 2.190307855606079
Validation loss: 2.03039248143473

Epoch: 5| Step: 4
Training loss: 2.472679615020752
Validation loss: 2.0021501689828853

Epoch: 5| Step: 5
Training loss: 2.1378440856933594
Validation loss: 2.0253711387675297

Epoch: 5| Step: 6
Training loss: 1.8723427057266235
Validation loss: 2.0426784458980767

Epoch: 5| Step: 7
Training loss: 2.646515369415283
Validation loss: 2.019448367498254

Epoch: 5| Step: 8
Training loss: 2.7925872802734375
Validation loss: 2.037807850427525

Epoch: 5| Step: 9
Training loss: 2.1520466804504395
Validation loss: 2.026016091787687

Epoch: 5| Step: 10
Training loss: 2.64628267288208
Validation loss: 2.034341102005333

Epoch: 53| Step: 0
Training loss: 2.087815046310425
Validation loss: 2.039773266802552

Epoch: 5| Step: 1
Training loss: 1.834545373916626
Validation loss: 2.0472356657828055

Epoch: 5| Step: 2
Training loss: 2.1855411529541016
Validation loss: 2.032089223143875

Epoch: 5| Step: 3
Training loss: 2.7415618896484375
Validation loss: 2.018232842927338

Epoch: 5| Step: 4
Training loss: 1.968768835067749
Validation loss: 2.0162003296677784

Epoch: 5| Step: 5
Training loss: 3.3276124000549316
Validation loss: 2.0184049503777617

Epoch: 5| Step: 6
Training loss: 1.73296320438385
Validation loss: 2.0213717901578514

Epoch: 5| Step: 7
Training loss: 2.7506637573242188
Validation loss: 2.081173845516738

Epoch: 5| Step: 8
Training loss: 2.015810489654541
Validation loss: 2.054865816588043

Epoch: 5| Step: 9
Training loss: 2.1522762775421143
Validation loss: 2.0333668160182174

Epoch: 5| Step: 10
Training loss: 3.049586534500122
Validation loss: 2.025607878162015

Epoch: 54| Step: 0
Training loss: 2.2431206703186035
Validation loss: 2.0283000789662844

Epoch: 5| Step: 1
Training loss: 2.8022091388702393
Validation loss: 2.074833872497723

Epoch: 5| Step: 2
Training loss: 2.2473223209381104
Validation loss: 2.0274123991689375

Epoch: 5| Step: 3
Training loss: 2.939772605895996
Validation loss: 2.040009057650002

Epoch: 5| Step: 4
Training loss: 2.742213726043701
Validation loss: 2.0484642969664706

Epoch: 5| Step: 5
Training loss: 2.3281407356262207
Validation loss: 2.0213727028139177

Epoch: 5| Step: 6
Training loss: 1.7012779712677002
Validation loss: 2.038286829507479

Epoch: 5| Step: 7
Training loss: 2.4156270027160645
Validation loss: 2.0243268602637836

Epoch: 5| Step: 8
Training loss: 2.329345226287842
Validation loss: 2.0398388665209533

Epoch: 5| Step: 9
Training loss: 2.083726167678833
Validation loss: 2.0496405683537966

Epoch: 5| Step: 10
Training loss: 1.8924771547317505
Validation loss: 1.9944551862696165

Epoch: 55| Step: 0
Training loss: 2.197474956512451
Validation loss: 2.004473065817228

Epoch: 5| Step: 1
Training loss: 3.1620049476623535
Validation loss: 2.0272810946228685

Epoch: 5| Step: 2
Training loss: 1.6696656942367554
Validation loss: 2.0087664857987435

Epoch: 5| Step: 3
Training loss: 2.1527042388916016
Validation loss: 2.0012781825116885

Epoch: 5| Step: 4
Training loss: 2.8028478622436523
Validation loss: 2.0266103949598087

Epoch: 5| Step: 5
Training loss: 1.9056155681610107
Validation loss: 2.0339847123751076

Epoch: 5| Step: 6
Training loss: 2.387965679168701
Validation loss: 2.023065124788592

Epoch: 5| Step: 7
Training loss: 2.002108097076416
Validation loss: 2.0369275052060365

Epoch: 5| Step: 8
Training loss: 2.609107494354248
Validation loss: 2.0097723545566684

Epoch: 5| Step: 9
Training loss: 2.6226513385772705
Validation loss: 2.0391919664157334

Epoch: 5| Step: 10
Training loss: 2.2185044288635254
Validation loss: 1.9830326521268455

Epoch: 56| Step: 0
Training loss: 1.6284029483795166
Validation loss: 2.0110404619606594

Epoch: 5| Step: 1
Training loss: 2.225064516067505
Validation loss: 2.0330259389774774

Epoch: 5| Step: 2
Training loss: 2.5771968364715576
Validation loss: 2.015085571555681

Epoch: 5| Step: 3
Training loss: 1.942749261856079
Validation loss: 2.013282843815383

Epoch: 5| Step: 4
Training loss: 2.2289676666259766
Validation loss: 2.022878626341461

Epoch: 5| Step: 5
Training loss: 2.296109676361084
Validation loss: 2.00676284041456

Epoch: 5| Step: 6
Training loss: 2.916445255279541
Validation loss: 2.026128258756412

Epoch: 5| Step: 7
Training loss: 2.142059326171875
Validation loss: 2.0343678843590522

Epoch: 5| Step: 8
Training loss: 2.434303045272827
Validation loss: 2.006872288642391

Epoch: 5| Step: 9
Training loss: 2.760298490524292
Validation loss: 2.0242598466975714

Epoch: 5| Step: 10
Training loss: 2.3262417316436768
Validation loss: 2.0019629860437043

Epoch: 57| Step: 0
Training loss: 1.9938194751739502
Validation loss: 2.0107746213995

Epoch: 5| Step: 1
Training loss: 1.704018235206604
Validation loss: 2.005983673116212

Epoch: 5| Step: 2
Training loss: 2.5218937397003174
Validation loss: 2.0196411853195517

Epoch: 5| Step: 3
Training loss: 2.420231342315674
Validation loss: 2.0034071988956903

Epoch: 5| Step: 4
Training loss: 2.313311815261841
Validation loss: 2.0230543075069303

Epoch: 5| Step: 5
Training loss: 2.529062509536743
Validation loss: 2.0069909813583537

Epoch: 5| Step: 6
Training loss: 2.2099902629852295
Validation loss: 1.9938992184977378

Epoch: 5| Step: 7
Training loss: 2.3601927757263184
Validation loss: 1.9756179291714904

Epoch: 5| Step: 8
Training loss: 2.829641342163086
Validation loss: 2.0075043760320193

Epoch: 5| Step: 9
Training loss: 2.308668851852417
Validation loss: 1.999699205480596

Epoch: 5| Step: 10
Training loss: 2.4735615253448486
Validation loss: 2.007508406075098

Epoch: 58| Step: 0
Training loss: 2.862166404724121
Validation loss: 2.0279638895424466

Epoch: 5| Step: 1
Training loss: 2.288538694381714
Validation loss: 2.0118865941160466

Epoch: 5| Step: 2
Training loss: 2.9365038871765137
Validation loss: 1.9980599059853503

Epoch: 5| Step: 3
Training loss: 2.5234310626983643
Validation loss: 2.015451790184103

Epoch: 5| Step: 4
Training loss: 1.6193559169769287
Validation loss: 2.0001306251813005

Epoch: 5| Step: 5
Training loss: 2.0059800148010254
Validation loss: 2.000268208083286

Epoch: 5| Step: 6
Training loss: 2.3190457820892334
Validation loss: 2.0228631701520694

Epoch: 5| Step: 7
Training loss: 2.152101755142212
Validation loss: 2.047536729484476

Epoch: 5| Step: 8
Training loss: 2.1867613792419434
Validation loss: 2.0137408459058372

Epoch: 5| Step: 9
Training loss: 2.3329005241394043
Validation loss: 2.0126660229057394

Epoch: 5| Step: 10
Training loss: 2.293754816055298
Validation loss: 1.9949138625975578

Epoch: 59| Step: 0
Training loss: 2.3699283599853516
Validation loss: 2.005813093595607

Epoch: 5| Step: 1
Training loss: 2.5836918354034424
Validation loss: 2.0425908027156705

Epoch: 5| Step: 2
Training loss: 2.3291196823120117
Validation loss: 2.012831587945261

Epoch: 5| Step: 3
Training loss: 2.37709379196167
Validation loss: 1.9992607511499876

Epoch: 5| Step: 4
Training loss: 1.8146785497665405
Validation loss: 2.0345750675406507

Epoch: 5| Step: 5
Training loss: 2.5238089561462402
Validation loss: 2.0077024236802132

Epoch: 5| Step: 6
Training loss: 2.615696668624878
Validation loss: 1.9926111493059384

Epoch: 5| Step: 7
Training loss: 2.543788433074951
Validation loss: 2.019932851996473

Epoch: 5| Step: 8
Training loss: 2.115290641784668
Validation loss: 1.9857299456032373

Epoch: 5| Step: 9
Training loss: 2.4699349403381348
Validation loss: 2.0418671690007693

Epoch: 5| Step: 10
Training loss: 1.5937232971191406
Validation loss: 2.040353657096945

Epoch: 60| Step: 0
Training loss: 2.2657999992370605
Validation loss: 2.009421569044872

Epoch: 5| Step: 1
Training loss: 2.620758533477783
Validation loss: 1.975523171886321

Epoch: 5| Step: 2
Training loss: 2.367600440979004
Validation loss: 2.008875277734572

Epoch: 5| Step: 3
Training loss: 2.5779130458831787
Validation loss: 2.0104478789914038

Epoch: 5| Step: 4
Training loss: 2.2986676692962646
Validation loss: 1.9986786521891111

Epoch: 5| Step: 5
Training loss: 2.3975093364715576
Validation loss: 2.0071198401912564

Epoch: 5| Step: 6
Training loss: 1.9277902841567993
Validation loss: 2.0208003264601513

Epoch: 5| Step: 7
Training loss: 2.6100988388061523
Validation loss: 1.9948823798087336

Epoch: 5| Step: 8
Training loss: 2.6161158084869385
Validation loss: 2.021964201363184

Epoch: 5| Step: 9
Training loss: 1.7971446514129639
Validation loss: 2.010300897782849

Epoch: 5| Step: 10
Training loss: 2.124619960784912
Validation loss: 1.9948510559656287

Epoch: 61| Step: 0
Training loss: 2.8413777351379395
Validation loss: 1.9758357245434996

Epoch: 5| Step: 1
Training loss: 2.0990145206451416
Validation loss: 1.9916174052863993

Epoch: 5| Step: 2
Training loss: 2.4323618412017822
Validation loss: 2.0082240514857794

Epoch: 5| Step: 3
Training loss: 2.3837146759033203
Validation loss: 2.008503839533816

Epoch: 5| Step: 4
Training loss: 2.2610905170440674
Validation loss: 2.03623693220077

Epoch: 5| Step: 5
Training loss: 2.368126392364502
Validation loss: 2.024608788951751

Epoch: 5| Step: 6
Training loss: 2.2872607707977295
Validation loss: 1.9746380441932267

Epoch: 5| Step: 7
Training loss: 2.22078275680542
Validation loss: 2.00992073551301

Epoch: 5| Step: 8
Training loss: 1.7054221630096436
Validation loss: 1.9730357790506015

Epoch: 5| Step: 9
Training loss: 2.4333107471466064
Validation loss: 1.9997827365834226

Epoch: 5| Step: 10
Training loss: 2.423499822616577
Validation loss: 2.004867207619452

Epoch: 62| Step: 0
Training loss: 1.9508148431777954
Validation loss: 2.01531744387842

Epoch: 5| Step: 1
Training loss: 1.5708084106445312
Validation loss: 2.012354338040916

Epoch: 5| Step: 2
Training loss: 2.653700351715088
Validation loss: 2.026080431476716

Epoch: 5| Step: 3
Training loss: 2.1252963542938232
Validation loss: 1.9872926409526537

Epoch: 5| Step: 4
Training loss: 2.693127393722534
Validation loss: 2.0322963781254266

Epoch: 5| Step: 5
Training loss: 2.4474172592163086
Validation loss: 2.0160874089887066

Epoch: 5| Step: 6
Training loss: 2.611166477203369
Validation loss: 1.9968910012193906

Epoch: 5| Step: 7
Training loss: 2.859013557434082
Validation loss: 2.0009783711484683

Epoch: 5| Step: 8
Training loss: 1.917506456375122
Validation loss: 2.0164287090301514

Epoch: 5| Step: 9
Training loss: 2.239321231842041
Validation loss: 2.0298622077511204

Epoch: 5| Step: 10
Training loss: 2.333552122116089
Validation loss: 2.0042835230468423

Epoch: 63| Step: 0
Training loss: 2.282623529434204
Validation loss: 2.0138888000160136

Epoch: 5| Step: 1
Training loss: 2.707451581954956
Validation loss: 2.032942730893371

Epoch: 5| Step: 2
Training loss: 2.268488645553589
Validation loss: 2.004445766889921

Epoch: 5| Step: 3
Training loss: 2.387315273284912
Validation loss: 2.02969923070682

Epoch: 5| Step: 4
Training loss: 2.3318285942077637
Validation loss: 1.9982987552560785

Epoch: 5| Step: 5
Training loss: 2.163194179534912
Validation loss: 2.0209004564951827

Epoch: 5| Step: 6
Training loss: 2.023320198059082
Validation loss: 2.0162250354725826

Epoch: 5| Step: 7
Training loss: 1.7616004943847656
Validation loss: 2.003060304990379

Epoch: 5| Step: 8
Training loss: 2.38293194770813
Validation loss: 2.0201351937427314

Epoch: 5| Step: 9
Training loss: 2.3762757778167725
Validation loss: 2.0295767015026462

Epoch: 5| Step: 10
Training loss: 2.583650827407837
Validation loss: 2.027998649945823

Epoch: 64| Step: 0
Training loss: 1.9327752590179443
Validation loss: 2.0198161832747923

Epoch: 5| Step: 1
Training loss: 2.0462002754211426
Validation loss: 2.0343354645595757

Epoch: 5| Step: 2
Training loss: 2.5306506156921387
Validation loss: 2.0260456890188236

Epoch: 5| Step: 3
Training loss: 2.7604317665100098
Validation loss: 2.010837706186438

Epoch: 5| Step: 4
Training loss: 2.0507264137268066
Validation loss: 2.0402451074251564

Epoch: 5| Step: 5
Training loss: 2.1781046390533447
Validation loss: 2.0210733772605978

Epoch: 5| Step: 6
Training loss: 2.1607887744903564
Validation loss: 2.0428825270745063

Epoch: 5| Step: 7
Training loss: 2.8089964389801025
Validation loss: 2.014929243313369

Epoch: 5| Step: 8
Training loss: 1.9061505794525146
Validation loss: 2.0238190286902973

Epoch: 5| Step: 9
Training loss: 3.0030107498168945
Validation loss: 2.034793189776841

Epoch: 5| Step: 10
Training loss: 1.8355222940444946
Validation loss: 2.040557876709969

Epoch: 65| Step: 0
Training loss: 1.984654426574707
Validation loss: 2.025827210436585

Epoch: 5| Step: 1
Training loss: 2.549375057220459
Validation loss: 1.9989224736408522

Epoch: 5| Step: 2
Training loss: 2.756436586380005
Validation loss: 2.027150906542296

Epoch: 5| Step: 3
Training loss: 2.852187156677246
Validation loss: 2.0288975546436925

Epoch: 5| Step: 4
Training loss: 1.760364294052124
Validation loss: 2.0104173203950286

Epoch: 5| Step: 5
Training loss: 2.380519390106201
Validation loss: 2.0193259972398

Epoch: 5| Step: 6
Training loss: 2.4997341632843018
Validation loss: 2.005241337642875

Epoch: 5| Step: 7
Training loss: 1.7685436010360718
Validation loss: 2.0081317053046277

Epoch: 5| Step: 8
Training loss: 2.289677381515503
Validation loss: 2.0194480342249714

Epoch: 5| Step: 9
Training loss: 2.665585517883301
Validation loss: 2.0032688763833817

Epoch: 5| Step: 10
Training loss: 1.8741923570632935
Validation loss: 2.0165992808598343

Epoch: 66| Step: 0
Training loss: 2.0902466773986816
Validation loss: 2.0217068554252706

Epoch: 5| Step: 1
Training loss: 1.7799484729766846
Validation loss: 2.0126088421831847

Epoch: 5| Step: 2
Training loss: 2.2857813835144043
Validation loss: 1.9804719712144585

Epoch: 5| Step: 3
Training loss: 1.8905856609344482
Validation loss: 1.9953348187990085

Epoch: 5| Step: 4
Training loss: 2.3240342140197754
Validation loss: 2.0098932853309055

Epoch: 5| Step: 5
Training loss: 1.7336854934692383
Validation loss: 2.0013712477940384

Epoch: 5| Step: 6
Training loss: 3.083071231842041
Validation loss: 2.0052623633415467

Epoch: 5| Step: 7
Training loss: 2.033968925476074
Validation loss: 1.9797106058366838

Epoch: 5| Step: 8
Training loss: 2.5421862602233887
Validation loss: 1.9719890343245638

Epoch: 5| Step: 9
Training loss: 2.918679714202881
Validation loss: 1.991854542045183

Epoch: 5| Step: 10
Training loss: 2.616926908493042
Validation loss: 1.992678047508322

Epoch: 67| Step: 0
Training loss: 2.649193286895752
Validation loss: 1.9921321381804764

Epoch: 5| Step: 1
Training loss: 2.596892833709717
Validation loss: 1.9850113891786145

Epoch: 5| Step: 2
Training loss: 2.136930465698242
Validation loss: 2.00514732381349

Epoch: 5| Step: 3
Training loss: 2.086282253265381
Validation loss: 2.0115281433187504

Epoch: 5| Step: 4
Training loss: 1.3379273414611816
Validation loss: 2.0228763344467326

Epoch: 5| Step: 5
Training loss: 1.9833627939224243
Validation loss: 2.027632826118059

Epoch: 5| Step: 6
Training loss: 1.920257568359375
Validation loss: 1.9880084414635935

Epoch: 5| Step: 7
Training loss: 2.234570026397705
Validation loss: 1.9835035826570244

Epoch: 5| Step: 8
Training loss: 2.6168644428253174
Validation loss: 1.966257405537431

Epoch: 5| Step: 9
Training loss: 2.123450517654419
Validation loss: 1.9797309290978216

Epoch: 5| Step: 10
Training loss: 3.536085605621338
Validation loss: 1.9913124435691423

Epoch: 68| Step: 0
Training loss: 2.5903048515319824
Validation loss: 2.0325308256251837

Epoch: 5| Step: 1
Training loss: 2.2423923015594482
Validation loss: 2.01034854432588

Epoch: 5| Step: 2
Training loss: 2.7984414100646973
Validation loss: 1.9935437863872898

Epoch: 5| Step: 3
Training loss: 2.649933338165283
Validation loss: 1.9965330810957058

Epoch: 5| Step: 4
Training loss: 2.2451541423797607
Validation loss: 1.9950489562044862

Epoch: 5| Step: 5
Training loss: 2.630199432373047
Validation loss: 1.9952473832714943

Epoch: 5| Step: 6
Training loss: 2.3443026542663574
Validation loss: 2.001536512887606

Epoch: 5| Step: 7
Training loss: 1.487684965133667
Validation loss: 2.0134891515137046

Epoch: 5| Step: 8
Training loss: 2.4481940269470215
Validation loss: 2.014752858428545

Epoch: 5| Step: 9
Training loss: 1.6823209524154663
Validation loss: 1.9952848598521242

Epoch: 5| Step: 10
Training loss: 2.1404330730438232
Validation loss: 1.9959166883140482

Epoch: 69| Step: 0
Training loss: 1.577650785446167
Validation loss: 1.9938414404469151

Epoch: 5| Step: 1
Training loss: 2.811401844024658
Validation loss: 2.0091733163402927

Epoch: 5| Step: 2
Training loss: 1.838666558265686
Validation loss: 2.015229237976895

Epoch: 5| Step: 3
Training loss: 2.4560513496398926
Validation loss: 2.004043707283594

Epoch: 5| Step: 4
Training loss: 2.417235851287842
Validation loss: 2.02522785176513

Epoch: 5| Step: 5
Training loss: 2.796537399291992
Validation loss: 2.023306421054307

Epoch: 5| Step: 6
Training loss: 2.5605907440185547
Validation loss: 1.9918304361322874

Epoch: 5| Step: 7
Training loss: 1.8883755207061768
Validation loss: 2.016326609478202

Epoch: 5| Step: 8
Training loss: 2.663797378540039
Validation loss: 2.023625273858347

Epoch: 5| Step: 9
Training loss: 2.0449302196502686
Validation loss: 2.0047442964328233

Epoch: 5| Step: 10
Training loss: 2.108501672744751
Validation loss: 2.0397080554757068

Epoch: 70| Step: 0
Training loss: 2.1075243949890137
Validation loss: 2.001036656800137

Epoch: 5| Step: 1
Training loss: 2.161072254180908
Validation loss: 2.019805357020388

Epoch: 5| Step: 2
Training loss: 2.5690956115722656
Validation loss: 2.0153205958745812

Epoch: 5| Step: 3
Training loss: 2.7892773151397705
Validation loss: 1.9957042932510376

Epoch: 5| Step: 4
Training loss: 2.577216625213623
Validation loss: 2.014748095184244

Epoch: 5| Step: 5
Training loss: 2.164769411087036
Validation loss: 2.012691297838765

Epoch: 5| Step: 6
Training loss: 1.956477403640747
Validation loss: 2.011590947387039

Epoch: 5| Step: 7
Training loss: 2.5374717712402344
Validation loss: 2.013637492733617

Epoch: 5| Step: 8
Training loss: 2.082974910736084
Validation loss: 2.0120129815993772

Epoch: 5| Step: 9
Training loss: 2.250795841217041
Validation loss: 2.0243228866207983

Epoch: 5| Step: 10
Training loss: 1.7776347398757935
Validation loss: 2.011440661645705

Epoch: 71| Step: 0
Training loss: 2.320679187774658
Validation loss: 2.0134529041987594

Epoch: 5| Step: 1
Training loss: 2.532773494720459
Validation loss: 2.01117270223556

Epoch: 5| Step: 2
Training loss: 2.569349765777588
Validation loss: 1.9875945404011717

Epoch: 5| Step: 3
Training loss: 2.1276938915252686
Validation loss: 2.026833730359231

Epoch: 5| Step: 4
Training loss: 1.9719772338867188
Validation loss: 2.006448171472037

Epoch: 5| Step: 5
Training loss: 2.2528228759765625
Validation loss: 2.0066912943317043

Epoch: 5| Step: 6
Training loss: 2.9116578102111816
Validation loss: 2.020632654108027

Epoch: 5| Step: 7
Training loss: 1.8308016061782837
Validation loss: 1.996471615247829

Epoch: 5| Step: 8
Training loss: 2.169309377670288
Validation loss: 2.0054945330465994

Epoch: 5| Step: 9
Training loss: 2.816767930984497
Validation loss: 2.014853513368996

Epoch: 5| Step: 10
Training loss: 1.526627540588379
Validation loss: 2.022156653865691

Epoch: 72| Step: 0
Training loss: 2.923165798187256
Validation loss: 2.0200399493658416

Epoch: 5| Step: 1
Training loss: 2.2513694763183594
Validation loss: 2.032467024300688

Epoch: 5| Step: 2
Training loss: 2.2424228191375732
Validation loss: 2.0107564233964488

Epoch: 5| Step: 3
Training loss: 2.296062469482422
Validation loss: 2.0094819145817913

Epoch: 5| Step: 4
Training loss: 1.656334638595581
Validation loss: 1.9892456044432938

Epoch: 5| Step: 5
Training loss: 1.9566682577133179
Validation loss: 1.998327225767156

Epoch: 5| Step: 6
Training loss: 2.407848834991455
Validation loss: 1.9972169065988192

Epoch: 5| Step: 7
Training loss: 2.5188727378845215
Validation loss: 2.0134963245802027

Epoch: 5| Step: 8
Training loss: 2.4663500785827637
Validation loss: 1.9957007105632494

Epoch: 5| Step: 9
Training loss: 2.206177234649658
Validation loss: 1.995334925190095

Epoch: 5| Step: 10
Training loss: 2.159656286239624
Validation loss: 2.01220779777855

Epoch: 73| Step: 0
Training loss: 2.3672971725463867
Validation loss: 2.033990119093208

Epoch: 5| Step: 1
Training loss: 1.7221629619598389
Validation loss: 1.994494838099326

Epoch: 5| Step: 2
Training loss: 2.4304757118225098
Validation loss: 2.013095586530624

Epoch: 5| Step: 3
Training loss: 2.5755114555358887
Validation loss: 2.0304911969810404

Epoch: 5| Step: 4
Training loss: 2.564534902572632
Validation loss: 2.0421348566650064

Epoch: 5| Step: 5
Training loss: 2.691601276397705
Validation loss: 2.0053575654183664

Epoch: 5| Step: 6
Training loss: 1.775902509689331
Validation loss: 2.0304775545673985

Epoch: 5| Step: 7
Training loss: 2.0844318866729736
Validation loss: 2.012777159290929

Epoch: 5| Step: 8
Training loss: 1.8930429220199585
Validation loss: 2.017896294593811

Epoch: 5| Step: 9
Training loss: 2.5587291717529297
Validation loss: 1.9987809965687413

Epoch: 5| Step: 10
Training loss: 2.3194124698638916
Validation loss: 1.997804485341554

Epoch: 74| Step: 0
Training loss: 2.4146437644958496
Validation loss: 2.0395501082943333

Epoch: 5| Step: 1
Training loss: 3.2685017585754395
Validation loss: 1.9987647353961904

Epoch: 5| Step: 2
Training loss: 1.475403904914856
Validation loss: 1.9997030278687835

Epoch: 5| Step: 3
Training loss: 2.8301422595977783
Validation loss: 1.99946032544618

Epoch: 5| Step: 4
Training loss: 2.553586959838867
Validation loss: 2.016519538817867

Epoch: 5| Step: 5
Training loss: 1.923525094985962
Validation loss: 2.027382170000384

Epoch: 5| Step: 6
Training loss: 1.6024324893951416
Validation loss: 2.0024511865390244

Epoch: 5| Step: 7
Training loss: 2.3069608211517334
Validation loss: 2.0097428547438754

Epoch: 5| Step: 8
Training loss: 1.8730895519256592
Validation loss: 2.0342101589325936

Epoch: 5| Step: 9
Training loss: 2.65372896194458
Validation loss: 2.0129422141659643

Epoch: 5| Step: 10
Training loss: 2.0075173377990723
Validation loss: 1.987768344981696

Epoch: 75| Step: 0
Training loss: 2.232038974761963
Validation loss: 2.0469482201401905

Epoch: 5| Step: 1
Training loss: 2.1009225845336914
Validation loss: 2.0152424202170423

Epoch: 5| Step: 2
Training loss: 1.8929147720336914
Validation loss: 2.0007063355497134

Epoch: 5| Step: 3
Training loss: 2.0585358142852783
Validation loss: 2.025386392429311

Epoch: 5| Step: 4
Training loss: 2.21122670173645
Validation loss: 2.0193159041866178

Epoch: 5| Step: 5
Training loss: 2.2900772094726562
Validation loss: 2.005093974451865

Epoch: 5| Step: 6
Training loss: 1.9547771215438843
Validation loss: 2.016836622709869

Epoch: 5| Step: 7
Training loss: 2.617152690887451
Validation loss: 2.019923251162293

Epoch: 5| Step: 8
Training loss: 2.7611987590789795
Validation loss: 2.0315085816127

Epoch: 5| Step: 9
Training loss: 2.4422245025634766
Validation loss: 2.014519122339064

Epoch: 5| Step: 10
Training loss: 2.388943910598755
Validation loss: 2.0291825571367816

Epoch: 76| Step: 0
Training loss: 2.2412686347961426
Validation loss: 2.0206892336568525

Epoch: 5| Step: 1
Training loss: 1.944088339805603
Validation loss: 2.022199543573523

Epoch: 5| Step: 2
Training loss: 2.570622682571411
Validation loss: 2.023018649829331

Epoch: 5| Step: 3
Training loss: 1.5240111351013184
Validation loss: 2.0324731129471973

Epoch: 5| Step: 4
Training loss: 2.391040802001953
Validation loss: 2.0151144202037523

Epoch: 5| Step: 5
Training loss: 2.55014967918396
Validation loss: 2.016771779265455

Epoch: 5| Step: 6
Training loss: 2.740710735321045
Validation loss: 2.0004417716815905

Epoch: 5| Step: 7
Training loss: 2.1754446029663086
Validation loss: 2.018547013241758

Epoch: 5| Step: 8
Training loss: 2.050041913986206
Validation loss: 2.0304320217460714

Epoch: 5| Step: 9
Training loss: 2.4466376304626465
Validation loss: 2.013770616182717

Epoch: 5| Step: 10
Training loss: 2.4969632625579834
Validation loss: 1.9564072278238112

Epoch: 77| Step: 0
Training loss: 1.958013892173767
Validation loss: 2.0170259719253867

Epoch: 5| Step: 1
Training loss: 2.3964080810546875
Validation loss: 2.0190427290496005

Epoch: 5| Step: 2
Training loss: 2.7123050689697266
Validation loss: 2.032327316140616

Epoch: 5| Step: 3
Training loss: 2.226372003555298
Validation loss: 2.0184283359076387

Epoch: 5| Step: 4
Training loss: 2.078213930130005
Validation loss: 1.9953173745063044

Epoch: 5| Step: 5
Training loss: 1.6718724966049194
Validation loss: 2.0226125281344176

Epoch: 5| Step: 6
Training loss: 2.117737293243408
Validation loss: 2.018485998594633

Epoch: 5| Step: 7
Training loss: 2.3223798274993896
Validation loss: 2.0239390865448983

Epoch: 5| Step: 8
Training loss: 2.3498101234436035
Validation loss: 2.0145138143211283

Epoch: 5| Step: 9
Training loss: 2.4728450775146484
Validation loss: 2.0549673470117713

Epoch: 5| Step: 10
Training loss: 2.8860385417938232
Validation loss: 2.0177496171766713

Epoch: 78| Step: 0
Training loss: 2.2388787269592285
Validation loss: 2.0203574831767748

Epoch: 5| Step: 1
Training loss: 2.4426403045654297
Validation loss: 2.029764001087476

Epoch: 5| Step: 2
Training loss: 2.0991311073303223
Validation loss: 2.032568291951251

Epoch: 5| Step: 3
Training loss: 3.043370008468628
Validation loss: 2.014392295191365

Epoch: 5| Step: 4
Training loss: 2.1855177879333496
Validation loss: 2.018584265503832

Epoch: 5| Step: 5
Training loss: 1.6098238229751587
Validation loss: 2.055209522606224

Epoch: 5| Step: 6
Training loss: 2.0282633304595947
Validation loss: 2.0063297671656453

Epoch: 5| Step: 7
Training loss: 2.1502912044525146
Validation loss: 2.0549647231255808

Epoch: 5| Step: 8
Training loss: 2.8582019805908203
Validation loss: 2.064073734385993

Epoch: 5| Step: 9
Training loss: 1.9278295040130615
Validation loss: 2.0476446331188245

Epoch: 5| Step: 10
Training loss: 2.4070959091186523
Validation loss: 2.0341998146426294

Epoch: 79| Step: 0
Training loss: 1.8903484344482422
Validation loss: 2.046095114882274

Epoch: 5| Step: 1
Training loss: 1.8049440383911133
Validation loss: 2.0269714106795607

Epoch: 5| Step: 2
Training loss: 2.7321438789367676
Validation loss: 2.039781025660935

Epoch: 5| Step: 3
Training loss: 1.9797626733779907
Validation loss: 2.0303040371146253

Epoch: 5| Step: 4
Training loss: 1.7896217107772827
Validation loss: 2.0501654327556653

Epoch: 5| Step: 5
Training loss: 2.9807515144348145
Validation loss: 2.0357361942209224

Epoch: 5| Step: 6
Training loss: 3.0856099128723145
Validation loss: 2.037471543076218

Epoch: 5| Step: 7
Training loss: 2.566776990890503
Validation loss: 2.0353526428181636

Epoch: 5| Step: 8
Training loss: 1.6695709228515625
Validation loss: 2.023796760907737

Epoch: 5| Step: 9
Training loss: 1.904799461364746
Validation loss: 2.01280475688237

Epoch: 5| Step: 10
Training loss: 2.6242353916168213
Validation loss: 2.027729224133235

Epoch: 80| Step: 0
Training loss: 2.3156332969665527
Validation loss: 2.0286865042101954

Epoch: 5| Step: 1
Training loss: 1.9961540699005127
Validation loss: 1.9992490404395646

Epoch: 5| Step: 2
Training loss: 2.0472588539123535
Validation loss: 2.021912546568019

Epoch: 5| Step: 3
Training loss: 2.2436633110046387
Validation loss: 2.0064018157220658

Epoch: 5| Step: 4
Training loss: 2.247507333755493
Validation loss: 2.036725846670007

Epoch: 5| Step: 5
Training loss: 2.220320463180542
Validation loss: 2.013152604461998

Epoch: 5| Step: 6
Training loss: 2.0650370121002197
Validation loss: 2.0238655715860348

Epoch: 5| Step: 7
Training loss: 2.548633098602295
Validation loss: 2.018768548965454

Epoch: 5| Step: 8
Training loss: 2.419064998626709
Validation loss: 2.0237270375733734

Epoch: 5| Step: 9
Training loss: 2.5210931301116943
Validation loss: 2.035425154752629

Epoch: 5| Step: 10
Training loss: 2.242417097091675
Validation loss: 2.021211885636853

Epoch: 81| Step: 0
Training loss: 2.1099085807800293
Validation loss: 2.0326481134660783

Epoch: 5| Step: 1
Training loss: 2.968351364135742
Validation loss: 2.0247948105617235

Epoch: 5| Step: 2
Training loss: 2.3259239196777344
Validation loss: 2.037449409884791

Epoch: 5| Step: 3
Training loss: 1.5797418355941772
Validation loss: 2.062172669236378

Epoch: 5| Step: 4
Training loss: 2.4719014167785645
Validation loss: 2.023753945545484

Epoch: 5| Step: 5
Training loss: 2.0254178047180176
Validation loss: 2.04464465571988

Epoch: 5| Step: 6
Training loss: 2.968867301940918
Validation loss: 2.0501276126471897

Epoch: 5| Step: 7
Training loss: 2.0530624389648438
Validation loss: 2.0399808781121367

Epoch: 5| Step: 8
Training loss: 2.4325811862945557
Validation loss: 2.038107814327363

Epoch: 5| Step: 9
Training loss: 1.9008945226669312
Validation loss: 2.0442849743750786

Epoch: 5| Step: 10
Training loss: 2.0916030406951904
Validation loss: 2.0315358177308114

Epoch: 82| Step: 0
Training loss: 1.9108238220214844
Validation loss: 2.030737066781649

Epoch: 5| Step: 1
Training loss: 1.8905515670776367
Validation loss: 2.0199439435876827

Epoch: 5| Step: 2
Training loss: 2.46647310256958
Validation loss: 2.014243870653132

Epoch: 5| Step: 3
Training loss: 2.421020984649658
Validation loss: 2.0187390645345054

Epoch: 5| Step: 4
Training loss: 2.0416271686553955
Validation loss: 2.027990359132008

Epoch: 5| Step: 5
Training loss: 2.6717543601989746
Validation loss: 2.02331946485786

Epoch: 5| Step: 6
Training loss: 2.1078364849090576
Validation loss: 2.0397975085884013

Epoch: 5| Step: 7
Training loss: 2.1863601207733154
Validation loss: 2.0117533976031887

Epoch: 5| Step: 8
Training loss: 2.756507158279419
Validation loss: 2.031486613776094

Epoch: 5| Step: 9
Training loss: 2.6382651329040527
Validation loss: 2.042746989957748

Epoch: 5| Step: 10
Training loss: 2.1064276695251465
Validation loss: 2.0383047339736775

Epoch: 83| Step: 0
Training loss: 2.1925063133239746
Validation loss: 2.0217810523125435

Epoch: 5| Step: 1
Training loss: 1.9508072137832642
Validation loss: 2.032322311914095

Epoch: 5| Step: 2
Training loss: 2.2577016353607178
Validation loss: 2.0619993632839573

Epoch: 5| Step: 3
Training loss: 1.4133421182632446
Validation loss: 2.0462160161746445

Epoch: 5| Step: 4
Training loss: 2.3293051719665527
Validation loss: 2.030485696690057

Epoch: 5| Step: 5
Training loss: 2.1291463375091553
Validation loss: 2.0376979074170514

Epoch: 5| Step: 6
Training loss: 2.3924243450164795
Validation loss: 2.026719324050411

Epoch: 5| Step: 7
Training loss: 2.655191421508789
Validation loss: 2.062674812091294

Epoch: 5| Step: 8
Training loss: 2.6963374614715576
Validation loss: 2.012779038439515

Epoch: 5| Step: 9
Training loss: 2.774322986602783
Validation loss: 2.0473350888939312

Epoch: 5| Step: 10
Training loss: 2.0875236988067627
Validation loss: 2.0360668295173237

Epoch: 84| Step: 0
Training loss: 1.683240532875061
Validation loss: 2.0329511755256244

Epoch: 5| Step: 1
Training loss: 2.795478105545044
Validation loss: 2.0083103308113675

Epoch: 5| Step: 2
Training loss: 2.116917371749878
Validation loss: 2.022473760830459

Epoch: 5| Step: 3
Training loss: 2.463676929473877
Validation loss: 2.0226936763332737

Epoch: 5| Step: 4
Training loss: 2.4069178104400635
Validation loss: 2.0355422522432063

Epoch: 5| Step: 5
Training loss: 2.0661659240722656
Validation loss: 2.013199665213144

Epoch: 5| Step: 6
Training loss: 2.5013279914855957
Validation loss: 2.01329102054719

Epoch: 5| Step: 7
Training loss: 1.7184314727783203
Validation loss: 2.049137005241968

Epoch: 5| Step: 8
Training loss: 2.487161159515381
Validation loss: 2.0149887761762066

Epoch: 5| Step: 9
Training loss: 2.4275970458984375
Validation loss: 2.021424674218701

Epoch: 5| Step: 10
Training loss: 2.2922682762145996
Validation loss: 2.017179827536306

Epoch: 85| Step: 0
Training loss: 2.2283823490142822
Validation loss: 2.0411793519091863

Epoch: 5| Step: 1
Training loss: 2.045785427093506
Validation loss: 2.0535848435535224

Epoch: 5| Step: 2
Training loss: 2.5429558753967285
Validation loss: 2.015447933186767

Epoch: 5| Step: 3
Training loss: 2.5741405487060547
Validation loss: 2.0213234911682787

Epoch: 5| Step: 4
Training loss: 1.4025994539260864
Validation loss: 2.0265604860039166

Epoch: 5| Step: 5
Training loss: 2.0399272441864014
Validation loss: 2.0290177086348176

Epoch: 5| Step: 6
Training loss: 2.452691078186035
Validation loss: 2.0449370491889214

Epoch: 5| Step: 7
Training loss: 2.3551204204559326
Validation loss: 2.040293276950877

Epoch: 5| Step: 8
Training loss: 2.0191988945007324
Validation loss: 2.0052818585467596

Epoch: 5| Step: 9
Training loss: 2.844600200653076
Validation loss: 2.0277082125345864

Epoch: 5| Step: 10
Training loss: 2.1479759216308594
Validation loss: 2.044622270009851

Epoch: 86| Step: 0
Training loss: 2.734243631362915
Validation loss: 1.9992103038295623

Epoch: 5| Step: 1
Training loss: 2.3866536617279053
Validation loss: 2.0342406149833434

Epoch: 5| Step: 2
Training loss: 2.466130018234253
Validation loss: 2.029067390708513

Epoch: 5| Step: 3
Training loss: 1.9689216613769531
Validation loss: 2.0273564836030364

Epoch: 5| Step: 4
Training loss: 2.647747039794922
Validation loss: 2.0518380788064774

Epoch: 5| Step: 5
Training loss: 2.3312671184539795
Validation loss: 2.023888155978213

Epoch: 5| Step: 6
Training loss: 2.1729393005371094
Validation loss: 2.0360546881152737

Epoch: 5| Step: 7
Training loss: 2.3011298179626465
Validation loss: 2.0486205034358527

Epoch: 5| Step: 8
Training loss: 2.0517795085906982
Validation loss: 2.0416653181916926

Epoch: 5| Step: 9
Training loss: 2.2046408653259277
Validation loss: 2.0384490028504403

Epoch: 5| Step: 10
Training loss: 1.5868397951126099
Validation loss: 2.0217082961913078

Epoch: 87| Step: 0
Training loss: 2.1707684993743896
Validation loss: 2.0308703632764917

Epoch: 5| Step: 1
Training loss: 2.4597959518432617
Validation loss: 2.0206802737328315

Epoch: 5| Step: 2
Training loss: 2.2508013248443604
Validation loss: 2.0236492362073673

Epoch: 5| Step: 3
Training loss: 2.386518716812134
Validation loss: 2.037695866759105

Epoch: 5| Step: 4
Training loss: 2.1841721534729004
Validation loss: 2.021812282582765

Epoch: 5| Step: 5
Training loss: 2.4129638671875
Validation loss: 2.0222437817563295

Epoch: 5| Step: 6
Training loss: 2.1882526874542236
Validation loss: 2.004792937668421

Epoch: 5| Step: 7
Training loss: 1.6293585300445557
Validation loss: 2.050846251108313

Epoch: 5| Step: 8
Training loss: 2.7849233150482178
Validation loss: 2.022617087569288

Epoch: 5| Step: 9
Training loss: 2.601616621017456
Validation loss: 2.0325331329017557

Epoch: 5| Step: 10
Training loss: 1.6712957620620728
Validation loss: 2.0381780003988617

Epoch: 88| Step: 0
Training loss: 2.7102925777435303
Validation loss: 2.041186527539325

Epoch: 5| Step: 1
Training loss: 2.8782641887664795
Validation loss: 1.991692263592956

Epoch: 5| Step: 2
Training loss: 2.162682056427002
Validation loss: 2.0486015914588847

Epoch: 5| Step: 3
Training loss: 1.820593237876892
Validation loss: 1.9855151330271075

Epoch: 5| Step: 4
Training loss: 2.102074384689331
Validation loss: 2.036353585540607

Epoch: 5| Step: 5
Training loss: 2.4722495079040527
Validation loss: 2.0194340264925392

Epoch: 5| Step: 6
Training loss: 1.9930356740951538
Validation loss: 2.0028354942157702

Epoch: 5| Step: 7
Training loss: 2.2739450931549072
Validation loss: 2.032903014972646

Epoch: 5| Step: 8
Training loss: 2.2369961738586426
Validation loss: 2.0328534546718804

Epoch: 5| Step: 9
Training loss: 1.587599277496338
Validation loss: 2.0128460571330082

Epoch: 5| Step: 10
Training loss: 2.5220696926116943
Validation loss: 2.0196101537314792

Epoch: 89| Step: 0
Training loss: 1.4005969762802124
Validation loss: 1.9976492287010275

Epoch: 5| Step: 1
Training loss: 2.617323398590088
Validation loss: 2.014721632003784

Epoch: 5| Step: 2
Training loss: 2.965519666671753
Validation loss: 2.0115097402244486

Epoch: 5| Step: 3
Training loss: 2.3431644439697266
Validation loss: 2.0177930016671457

Epoch: 5| Step: 4
Training loss: 1.8719367980957031
Validation loss: 2.0109079037943194

Epoch: 5| Step: 5
Training loss: 2.1048476696014404
Validation loss: 1.972420648861957

Epoch: 5| Step: 6
Training loss: 2.0916659832000732
Validation loss: 1.9989963321275608

Epoch: 5| Step: 7
Training loss: 1.6506805419921875
Validation loss: 1.9978732511561403

Epoch: 5| Step: 8
Training loss: 2.6723415851593018
Validation loss: 1.9880674436528196

Epoch: 5| Step: 9
Training loss: 2.1144306659698486
Validation loss: 2.022177516773183

Epoch: 5| Step: 10
Training loss: 3.1002511978149414
Validation loss: 1.9943907671077277

Epoch: 90| Step: 0
Training loss: 2.0985805988311768
Validation loss: 2.009183232502271

Epoch: 5| Step: 1
Training loss: 2.3366353511810303
Validation loss: 2.0088960483510006

Epoch: 5| Step: 2
Training loss: 1.8335987329483032
Validation loss: 2.021297130533444

Epoch: 5| Step: 3
Training loss: 2.382206439971924
Validation loss: 2.0092124938964844

Epoch: 5| Step: 4
Training loss: 1.9251835346221924
Validation loss: 2.028064243255123

Epoch: 5| Step: 5
Training loss: 2.3775217533111572
Validation loss: 2.023849884668986

Epoch: 5| Step: 6
Training loss: 2.127983570098877
Validation loss: 2.031977007465978

Epoch: 5| Step: 7
Training loss: 2.7763774394989014
Validation loss: 2.0382962431958926

Epoch: 5| Step: 8
Training loss: 2.245594024658203
Validation loss: 2.0283534667825185

Epoch: 5| Step: 9
Training loss: 2.383002281188965
Validation loss: 1.9996408480469898

Epoch: 5| Step: 10
Training loss: 2.0625510215759277
Validation loss: 2.0010388256401144

Epoch: 91| Step: 0
Training loss: 2.3422789573669434
Validation loss: 2.0240535710447576

Epoch: 5| Step: 1
Training loss: 2.431504726409912
Validation loss: 2.0349368767071794

Epoch: 5| Step: 2
Training loss: 2.5015757083892822
Validation loss: 2.014598118361606

Epoch: 5| Step: 3
Training loss: 2.4378576278686523
Validation loss: 2.0196443232156898

Epoch: 5| Step: 4
Training loss: 2.048327922821045
Validation loss: 2.009090610729751

Epoch: 5| Step: 5
Training loss: 2.018603801727295
Validation loss: 1.9890909528219571

Epoch: 5| Step: 6
Training loss: 1.7756630182266235
Validation loss: 2.0337155762539116

Epoch: 5| Step: 7
Training loss: 2.153259515762329
Validation loss: 2.0278526659934752

Epoch: 5| Step: 8
Training loss: 2.786726713180542
Validation loss: 2.0365686570444415

Epoch: 5| Step: 9
Training loss: 1.8207429647445679
Validation loss: 2.0567159114345426

Epoch: 5| Step: 10
Training loss: 2.3791377544403076
Validation loss: 2.0376119895647933

Epoch: 92| Step: 0
Training loss: 2.349465847015381
Validation loss: 2.0401019716775544

Epoch: 5| Step: 1
Training loss: 1.5875520706176758
Validation loss: 2.0563294567087644

Epoch: 5| Step: 2
Training loss: 2.36133074760437
Validation loss: 2.0505030065454464

Epoch: 5| Step: 3
Training loss: 2.7667012214660645
Validation loss: 2.041409261765019

Epoch: 5| Step: 4
Training loss: 1.930281400680542
Validation loss: 2.074072901920606

Epoch: 5| Step: 5
Training loss: 2.8527865409851074
Validation loss: 2.049915188102312

Epoch: 5| Step: 6
Training loss: 2.1664600372314453
Validation loss: 2.0301465795886133

Epoch: 5| Step: 7
Training loss: 2.0075156688690186
Validation loss: 2.0687946478525796

Epoch: 5| Step: 8
Training loss: 2.0523648262023926
Validation loss: 2.0080465898718884

Epoch: 5| Step: 9
Training loss: 1.9877485036849976
Validation loss: 2.02820449490701

Epoch: 5| Step: 10
Training loss: 2.487027406692505
Validation loss: 2.037396128459643

Epoch: 93| Step: 0
Training loss: 2.565885066986084
Validation loss: 2.0210926148199264

Epoch: 5| Step: 1
Training loss: 2.373913288116455
Validation loss: 2.0505767829956545

Epoch: 5| Step: 2
Training loss: 2.0436768531799316
Validation loss: 2.04816040941464

Epoch: 5| Step: 3
Training loss: 2.4781672954559326
Validation loss: 2.043451557877243

Epoch: 5| Step: 4
Training loss: 2.07676362991333
Validation loss: 2.0197624826944

Epoch: 5| Step: 5
Training loss: 1.8912639617919922
Validation loss: 2.0313808943635676

Epoch: 5| Step: 6
Training loss: 2.3240716457366943
Validation loss: 2.0409708561435824

Epoch: 5| Step: 7
Training loss: 2.097872257232666
Validation loss: 2.017199311205136

Epoch: 5| Step: 8
Training loss: 2.3577189445495605
Validation loss: 2.034499663178639

Epoch: 5| Step: 9
Training loss: 2.402153253555298
Validation loss: 2.0588361063311176

Epoch: 5| Step: 10
Training loss: 2.016752004623413
Validation loss: 2.0531951458223405

Epoch: 94| Step: 0
Training loss: 2.5768213272094727
Validation loss: 2.0202998320261636

Epoch: 5| Step: 1
Training loss: 2.249427318572998
Validation loss: 1.9997948984945975

Epoch: 5| Step: 2
Training loss: 2.136230230331421
Validation loss: 2.0063420059860393

Epoch: 5| Step: 3
Training loss: 2.2472808361053467
Validation loss: 1.9974318204387542

Epoch: 5| Step: 4
Training loss: 2.197981357574463
Validation loss: 2.021804899297735

Epoch: 5| Step: 5
Training loss: 2.0601534843444824
Validation loss: 2.013535068881127

Epoch: 5| Step: 6
Training loss: 2.893889904022217
Validation loss: 2.012519374970467

Epoch: 5| Step: 7
Training loss: 2.099321126937866
Validation loss: 2.015550034020537

Epoch: 5| Step: 8
Training loss: 1.9739742279052734
Validation loss: 2.037738193747818

Epoch: 5| Step: 9
Training loss: 2.0959584712982178
Validation loss: 1.9967771730115336

Epoch: 5| Step: 10
Training loss: 2.2818968296051025
Validation loss: 2.01527730623881

Epoch: 95| Step: 0
Training loss: 2.1996102333068848
Validation loss: 1.9945356948401338

Epoch: 5| Step: 1
Training loss: 1.828761100769043
Validation loss: 2.0427469027939664

Epoch: 5| Step: 2
Training loss: 2.692936658859253
Validation loss: 2.024510984779686

Epoch: 5| Step: 3
Training loss: 1.7703548669815063
Validation loss: 1.9923349465093305

Epoch: 5| Step: 4
Training loss: 2.184602975845337
Validation loss: 2.042040181416337

Epoch: 5| Step: 5
Training loss: 2.076547384262085
Validation loss: 1.9957046098606561

Epoch: 5| Step: 6
Training loss: 2.6430554389953613
Validation loss: 2.007316408618804

Epoch: 5| Step: 7
Training loss: 2.6333963871002197
Validation loss: 2.0222906053707166

Epoch: 5| Step: 8
Training loss: 1.836458444595337
Validation loss: 2.0247722825696393

Epoch: 5| Step: 9
Training loss: 2.413574695587158
Validation loss: 2.0095310493182112

Epoch: 5| Step: 10
Training loss: 2.679879903793335
Validation loss: 2.01040974227331

Epoch: 96| Step: 0
Training loss: 2.4292149543762207
Validation loss: 1.993703854981289

Epoch: 5| Step: 1
Training loss: 2.40619158744812
Validation loss: 1.9960037328863656

Epoch: 5| Step: 2
Training loss: 2.4762654304504395
Validation loss: 2.0113240288149927

Epoch: 5| Step: 3
Training loss: 2.2160935401916504
Validation loss: 2.0170366892250637

Epoch: 5| Step: 4
Training loss: 2.3744187355041504
Validation loss: 2.0504247949969385

Epoch: 5| Step: 5
Training loss: 1.890323281288147
Validation loss: 1.9994890741122666

Epoch: 5| Step: 6
Training loss: 1.8797518014907837
Validation loss: 1.997833037889132

Epoch: 5| Step: 7
Training loss: 2.319819927215576
Validation loss: 2.041033688411918

Epoch: 5| Step: 8
Training loss: 3.0335662364959717
Validation loss: 2.0633227030436196

Epoch: 5| Step: 9
Training loss: 1.5493991374969482
Validation loss: 2.0164445343837945

Epoch: 5| Step: 10
Training loss: 1.9077361822128296
Validation loss: 2.029734242346979

Epoch: 97| Step: 0
Training loss: 2.551384449005127
Validation loss: 1.999040029382193

Epoch: 5| Step: 1
Training loss: 2.2593421936035156
Validation loss: 2.044330420032624

Epoch: 5| Step: 2
Training loss: 1.9670099020004272
Validation loss: 2.047500370651163

Epoch: 5| Step: 3
Training loss: 2.2435545921325684
Validation loss: 2.065681888211158

Epoch: 5| Step: 4
Training loss: 1.9428164958953857
Validation loss: 2.0170016609212404

Epoch: 5| Step: 5
Training loss: 2.7179689407348633
Validation loss: 2.0570074230112056

Epoch: 5| Step: 6
Training loss: 1.7022809982299805
Validation loss: 2.051941183305556

Epoch: 5| Step: 7
Training loss: 1.8791927099227905
Validation loss: 2.026155274401429

Epoch: 5| Step: 8
Training loss: 2.103318929672241
Validation loss: 2.0289769275214082

Epoch: 5| Step: 9
Training loss: 2.3997254371643066
Validation loss: 2.054003656551402

Epoch: 5| Step: 10
Training loss: 3.149228572845459
Validation loss: 2.0515823800076722

Epoch: 98| Step: 0
Training loss: 2.138288974761963
Validation loss: 2.0548550646792174

Epoch: 5| Step: 1
Training loss: 3.2436599731445312
Validation loss: 2.021134655962708

Epoch: 5| Step: 2
Training loss: 2.397667646408081
Validation loss: 2.0294174635282127

Epoch: 5| Step: 3
Training loss: 2.3603601455688477
Validation loss: 2.035767593691426

Epoch: 5| Step: 4
Training loss: 1.8974584341049194
Validation loss: 2.028858079705187

Epoch: 5| Step: 5
Training loss: 2.624906063079834
Validation loss: 2.058090011278788

Epoch: 5| Step: 6
Training loss: 2.434103012084961
Validation loss: 2.034151905326433

Epoch: 5| Step: 7
Training loss: 1.673126459121704
Validation loss: 2.032643659140474

Epoch: 5| Step: 8
Training loss: 1.9862998723983765
Validation loss: 2.016471670519921

Epoch: 5| Step: 9
Training loss: 2.2009408473968506
Validation loss: 2.030190029451924

Epoch: 5| Step: 10
Training loss: 1.6050829887390137
Validation loss: 2.0588766733805337

Epoch: 99| Step: 0
Training loss: 2.0585532188415527
Validation loss: 2.0590578535551667

Epoch: 5| Step: 1
Training loss: 2.4182562828063965
Validation loss: 2.0519164403279624

Epoch: 5| Step: 2
Training loss: 1.9616518020629883
Validation loss: 2.06281445359671

Epoch: 5| Step: 3
Training loss: 2.473952531814575
Validation loss: 2.013288874779978

Epoch: 5| Step: 4
Training loss: 2.2141165733337402
Validation loss: 2.0193823383700464

Epoch: 5| Step: 5
Training loss: 2.2399163246154785
Validation loss: 1.9966920575787943

Epoch: 5| Step: 6
Training loss: 1.5248943567276
Validation loss: 2.0169170159165577

Epoch: 5| Step: 7
Training loss: 2.0901148319244385
Validation loss: 2.0702099620655017

Epoch: 5| Step: 8
Training loss: 2.2961413860321045
Validation loss: 2.027112163523192

Epoch: 5| Step: 9
Training loss: 2.2833030223846436
Validation loss: 2.049657860109883

Epoch: 5| Step: 10
Training loss: 3.1424968242645264
Validation loss: 2.0349384213006623

Epoch: 100| Step: 0
Training loss: 2.9837806224823
Validation loss: 2.0221213935523905

Epoch: 5| Step: 1
Training loss: 1.8873684406280518
Validation loss: 2.038459194603787

Epoch: 5| Step: 2
Training loss: 2.4950568675994873
Validation loss: 2.019149213708857

Epoch: 5| Step: 3
Training loss: 2.2176482677459717
Validation loss: 2.0727106614779403

Epoch: 5| Step: 4
Training loss: 2.0607120990753174
Validation loss: 2.0577809195364676

Epoch: 5| Step: 5
Training loss: 2.169793128967285
Validation loss: 2.0368930883305048

Epoch: 5| Step: 6
Training loss: 1.9088184833526611
Validation loss: 2.0338167426406697

Epoch: 5| Step: 7
Training loss: 1.8838564157485962
Validation loss: 2.0095745466088735

Epoch: 5| Step: 8
Training loss: 2.661130905151367
Validation loss: 2.0399616508073706

Epoch: 5| Step: 9
Training loss: 2.014688014984131
Validation loss: 2.0237157344818115

Epoch: 5| Step: 10
Training loss: 2.155324935913086
Validation loss: 2.022664996885484

Epoch: 101| Step: 0
Training loss: 1.7815828323364258
Validation loss: 2.0196670665535876

Epoch: 5| Step: 1
Training loss: 1.948686957359314
Validation loss: 2.027071042727399

Epoch: 5| Step: 2
Training loss: 1.9180324077606201
Validation loss: 1.9964783012226064

Epoch: 5| Step: 3
Training loss: 2.8549373149871826
Validation loss: 2.0182106853813253

Epoch: 5| Step: 4
Training loss: 2.6522746086120605
Validation loss: 2.025583244139148

Epoch: 5| Step: 5
Training loss: 1.97086501121521
Validation loss: 2.0190595978049823

Epoch: 5| Step: 6
Training loss: 2.729097604751587
Validation loss: 2.0094456980305333

Epoch: 5| Step: 7
Training loss: 1.7081091403961182
Validation loss: 2.052916649849184

Epoch: 5| Step: 8
Training loss: 2.149386167526245
Validation loss: 2.051118743035101

Epoch: 5| Step: 9
Training loss: 2.593855381011963
Validation loss: 2.051139857179375

Epoch: 5| Step: 10
Training loss: 2.018125534057617
Validation loss: 2.0425278550835064

Epoch: 102| Step: 0
Training loss: 2.032764434814453
Validation loss: 2.0231704494004608

Epoch: 5| Step: 1
Training loss: 2.413980007171631
Validation loss: 2.037652929623922

Epoch: 5| Step: 2
Training loss: 2.5031063556671143
Validation loss: 2.0184808751588226

Epoch: 5| Step: 3
Training loss: 1.8976256847381592
Validation loss: 2.0334629730511735

Epoch: 5| Step: 4
Training loss: 2.590310573577881
Validation loss: 2.0391034144227222

Epoch: 5| Step: 5
Training loss: 2.1150903701782227
Validation loss: 2.0056146588376773

Epoch: 5| Step: 6
Training loss: 2.8678689002990723
Validation loss: 2.0394087119769027

Epoch: 5| Step: 7
Training loss: 1.6792571544647217
Validation loss: 2.0337415305517053

Epoch: 5| Step: 8
Training loss: 2.432002305984497
Validation loss: 2.038671385857367

Epoch: 5| Step: 9
Training loss: 2.33950138092041
Validation loss: 2.0322374156726304

Epoch: 5| Step: 10
Training loss: 1.6106786727905273
Validation loss: 2.004766236069382

Epoch: 103| Step: 0
Training loss: 2.0700948238372803
Validation loss: 2.0460271989145586

Epoch: 5| Step: 1
Training loss: 1.5609850883483887
Validation loss: 2.056629357799407

Epoch: 5| Step: 2
Training loss: 1.4713760614395142
Validation loss: 2.0442776397992204

Epoch: 5| Step: 3
Training loss: 2.3367998600006104
Validation loss: 2.0471825856034473

Epoch: 5| Step: 4
Training loss: 2.2602267265319824
Validation loss: 2.001748336258755

Epoch: 5| Step: 5
Training loss: 2.8573620319366455
Validation loss: 1.989360919562719

Epoch: 5| Step: 6
Training loss: 2.171311616897583
Validation loss: 2.001200165799869

Epoch: 5| Step: 7
Training loss: 1.946743369102478
Validation loss: 2.0086325676210466

Epoch: 5| Step: 8
Training loss: 2.167445659637451
Validation loss: 2.030236098074144

Epoch: 5| Step: 9
Training loss: 2.1237969398498535
Validation loss: 1.9920168486974572

Epoch: 5| Step: 10
Training loss: 3.5068187713623047
Validation loss: 1.9917849494564919

Epoch: 104| Step: 0
Training loss: 2.9623703956604004
Validation loss: 2.0273603085548646

Epoch: 5| Step: 1
Training loss: 1.982980728149414
Validation loss: 2.039894619295674

Epoch: 5| Step: 2
Training loss: 2.5360333919525146
Validation loss: 2.047674602077853

Epoch: 5| Step: 3
Training loss: 2.2336010932922363
Validation loss: 2.048451481326934

Epoch: 5| Step: 4
Training loss: 2.363175630569458
Validation loss: 2.0361673831939697

Epoch: 5| Step: 5
Training loss: 1.7228294610977173
Validation loss: 2.0157996223818873

Epoch: 5| Step: 6
Training loss: 1.6086422204971313
Validation loss: 2.0192614588686215

Epoch: 5| Step: 7
Training loss: 2.2277517318725586
Validation loss: 2.0403498218905542

Epoch: 5| Step: 8
Training loss: 1.9358341693878174
Validation loss: 2.055355038694156

Epoch: 5| Step: 9
Training loss: 2.77111554145813
Validation loss: 2.0308942769163396

Epoch: 5| Step: 10
Training loss: 2.2141103744506836
Validation loss: 2.0191407998402915

Epoch: 105| Step: 0
Training loss: 2.445169448852539
Validation loss: 2.040489847942065

Epoch: 5| Step: 1
Training loss: 2.394798755645752
Validation loss: 2.0503900102389756

Epoch: 5| Step: 2
Training loss: 2.7616896629333496
Validation loss: 2.036651983056017

Epoch: 5| Step: 3
Training loss: 2.199862241744995
Validation loss: 2.012306087760515

Epoch: 5| Step: 4
Training loss: 2.4332680702209473
Validation loss: 2.0592997304854856

Epoch: 5| Step: 5
Training loss: 1.5665321350097656
Validation loss: 2.0821075285634687

Epoch: 5| Step: 6
Training loss: 1.6686756610870361
Validation loss: 2.0350677582525436

Epoch: 5| Step: 7
Training loss: 3.093635082244873
Validation loss: 2.056215300354906

Epoch: 5| Step: 8
Training loss: 2.024759531021118
Validation loss: 2.0282285162197646

Epoch: 5| Step: 9
Training loss: 1.9702961444854736
Validation loss: 2.0725420175060147

Epoch: 5| Step: 10
Training loss: 2.02947735786438
Validation loss: 2.0588345553285334

Epoch: 106| Step: 0
Training loss: 2.8315157890319824
Validation loss: 2.0342909366853776

Epoch: 5| Step: 1
Training loss: 1.6904537677764893
Validation loss: 2.0316131832779094

Epoch: 5| Step: 2
Training loss: 2.2162091732025146
Validation loss: 2.0471020103782736

Epoch: 5| Step: 3
Training loss: 1.9029302597045898
Validation loss: 2.047063366059334

Epoch: 5| Step: 4
Training loss: 2.7500228881835938
Validation loss: 2.0299354548095376

Epoch: 5| Step: 5
Training loss: 2.369220018386841
Validation loss: 2.0311698247027654

Epoch: 5| Step: 6
Training loss: 2.164363145828247
Validation loss: 2.043926949142128

Epoch: 5| Step: 7
Training loss: 1.9982236623764038
Validation loss: 2.044522320070574

Epoch: 5| Step: 8
Training loss: 1.7028629779815674
Validation loss: 2.021381799892713

Epoch: 5| Step: 9
Training loss: 2.193006992340088
Validation loss: 2.0489494364748717

Epoch: 5| Step: 10
Training loss: 2.6403915882110596
Validation loss: 2.0324146286133797

Epoch: 107| Step: 0
Training loss: 2.0777957439422607
Validation loss: 2.053153545625748

Epoch: 5| Step: 1
Training loss: 2.2224202156066895
Validation loss: 2.011610013182445

Epoch: 5| Step: 2
Training loss: 1.9317346811294556
Validation loss: 2.029225641681302

Epoch: 5| Step: 3
Training loss: 2.110292434692383
Validation loss: 2.0073554003110496

Epoch: 5| Step: 4
Training loss: 2.326273202896118
Validation loss: 2.0199530329755557

Epoch: 5| Step: 5
Training loss: 2.5692174434661865
Validation loss: 2.0563174870706376

Epoch: 5| Step: 6
Training loss: 3.0311646461486816
Validation loss: 2.0424982886160574

Epoch: 5| Step: 7
Training loss: 2.537161350250244
Validation loss: 2.031037535718692

Epoch: 5| Step: 8
Training loss: 1.8638290166854858
Validation loss: 2.0392886387404574

Epoch: 5| Step: 9
Training loss: 2.3441162109375
Validation loss: 2.0693105818122945

Epoch: 5| Step: 10
Training loss: 1.5437729358673096
Validation loss: 2.0303040704419537

Epoch: 108| Step: 0
Training loss: 1.9933255910873413
Validation loss: 2.056123415629069

Epoch: 5| Step: 1
Training loss: 1.859928846359253
Validation loss: 2.049838391683435

Epoch: 5| Step: 2
Training loss: 2.131256341934204
Validation loss: 2.058392801592427

Epoch: 5| Step: 3
Training loss: 2.731257915496826
Validation loss: 2.0177353018073627

Epoch: 5| Step: 4
Training loss: 2.2653403282165527
Validation loss: 2.035225490088104

Epoch: 5| Step: 5
Training loss: 2.526989221572876
Validation loss: 2.033582127222451

Epoch: 5| Step: 6
Training loss: 2.0937139987945557
Validation loss: 2.0585841440385386

Epoch: 5| Step: 7
Training loss: 1.9187259674072266
Validation loss: 2.0513446818115892

Epoch: 5| Step: 8
Training loss: 2.197133779525757
Validation loss: 2.086151405047345

Epoch: 5| Step: 9
Training loss: 2.4412293434143066
Validation loss: 2.0743386001997095

Epoch: 5| Step: 10
Training loss: 2.0847604274749756
Validation loss: 2.024420258819416

Epoch: 109| Step: 0
Training loss: 2.1115710735321045
Validation loss: 2.0283966307998984

Epoch: 5| Step: 1
Training loss: 2.688380479812622
Validation loss: 2.0198913876728346

Epoch: 5| Step: 2
Training loss: 2.0911922454833984
Validation loss: 2.0624143308208835

Epoch: 5| Step: 3
Training loss: 1.8580442667007446
Validation loss: 2.0262376416114067

Epoch: 5| Step: 4
Training loss: 2.1160149574279785
Validation loss: 2.0528316267075075

Epoch: 5| Step: 5
Training loss: 2.528761386871338
Validation loss: 2.026260260612734

Epoch: 5| Step: 6
Training loss: 2.1479034423828125
Validation loss: 2.0566470289743073

Epoch: 5| Step: 7
Training loss: 2.777585029602051
Validation loss: 2.0556916216368317

Epoch: 5| Step: 8
Training loss: 2.151063919067383
Validation loss: 2.042018753226085

Epoch: 5| Step: 9
Training loss: 1.9221681356430054
Validation loss: 2.045688008749357

Epoch: 5| Step: 10
Training loss: 2.080862283706665
Validation loss: 2.053725286196637

Epoch: 110| Step: 0
Training loss: 2.5601606369018555
Validation loss: 2.049727830835568

Epoch: 5| Step: 1
Training loss: 1.789339303970337
Validation loss: 2.039340011535152

Epoch: 5| Step: 2
Training loss: 2.066671848297119
Validation loss: 2.0086697058011125

Epoch: 5| Step: 3
Training loss: 2.079336643218994
Validation loss: 2.0818355801284953

Epoch: 5| Step: 4
Training loss: 2.039400815963745
Validation loss: 2.065291425233246

Epoch: 5| Step: 5
Training loss: 2.4472973346710205
Validation loss: 2.0424297432745657

Epoch: 5| Step: 6
Training loss: 2.1232736110687256
Validation loss: 2.071659311171501

Epoch: 5| Step: 7
Training loss: 2.170846462249756
Validation loss: 2.044145066251037

Epoch: 5| Step: 8
Training loss: 2.8851566314697266
Validation loss: 2.0209989214456208

Epoch: 5| Step: 9
Training loss: 2.160430669784546
Validation loss: 2.056938884078815

Epoch: 5| Step: 10
Training loss: 2.1211929321289062
Validation loss: 2.0332048118755384

Epoch: 111| Step: 0
Training loss: 2.039285182952881
Validation loss: 2.023015420923951

Epoch: 5| Step: 1
Training loss: 2.0336709022521973
Validation loss: 2.048406926534509

Epoch: 5| Step: 2
Training loss: 2.7336297035217285
Validation loss: 2.038773839191724

Epoch: 5| Step: 3
Training loss: 2.1567606925964355
Validation loss: 2.066132084015877

Epoch: 5| Step: 4
Training loss: 1.8066753149032593
Validation loss: 2.072677885332415

Epoch: 5| Step: 5
Training loss: 1.96356201171875
Validation loss: 2.0670264946517123

Epoch: 5| Step: 6
Training loss: 2.7037370204925537
Validation loss: 2.0168893414158977

Epoch: 5| Step: 7
Training loss: 2.378357410430908
Validation loss: 2.0409549179897515

Epoch: 5| Step: 8
Training loss: 2.5162930488586426
Validation loss: 2.0461234187567108

Epoch: 5| Step: 9
Training loss: 2.157283306121826
Validation loss: 2.026244806986983

Epoch: 5| Step: 10
Training loss: 1.9487742185592651
Validation loss: 2.05113507598959

Epoch: 112| Step: 0
Training loss: 2.6420207023620605
Validation loss: 2.0521318258777743

Epoch: 5| Step: 1
Training loss: 1.9176479578018188
Validation loss: 2.01967203745278

Epoch: 5| Step: 2
Training loss: 1.8582580089569092
Validation loss: 2.043445235939436

Epoch: 5| Step: 3
Training loss: 2.9322798252105713
Validation loss: 2.0370543233809935

Epoch: 5| Step: 4
Training loss: 2.0808167457580566
Validation loss: 2.041505080397411

Epoch: 5| Step: 5
Training loss: 1.7870066165924072
Validation loss: 1.9978705580516527

Epoch: 5| Step: 6
Training loss: 2.802666187286377
Validation loss: 2.0299489677593274

Epoch: 5| Step: 7
Training loss: 2.019515037536621
Validation loss: 2.0159130737345707

Epoch: 5| Step: 8
Training loss: 2.279710292816162
Validation loss: 2.0167560051846247

Epoch: 5| Step: 9
Training loss: 2.1177761554718018
Validation loss: 2.0365311202182563

Epoch: 5| Step: 10
Training loss: 2.039179563522339
Validation loss: 2.022369796229947

Epoch: 113| Step: 0
Training loss: 2.025740385055542
Validation loss: 2.0355497880648543

Epoch: 5| Step: 1
Training loss: 1.8156416416168213
Validation loss: 2.004776116340391

Epoch: 5| Step: 2
Training loss: 2.5418941974639893
Validation loss: 2.0437065837203816

Epoch: 5| Step: 3
Training loss: 2.4502005577087402
Validation loss: 2.030957711640225

Epoch: 5| Step: 4
Training loss: 2.463805675506592
Validation loss: 2.0024330346815047

Epoch: 5| Step: 5
Training loss: 2.347796678543091
Validation loss: 2.052854004726615

Epoch: 5| Step: 6
Training loss: 1.8015995025634766
Validation loss: 2.02476466278876

Epoch: 5| Step: 7
Training loss: 2.3450677394866943
Validation loss: 2.0774184350044496

Epoch: 5| Step: 8
Training loss: 1.9374778270721436
Validation loss: 2.014264980951945

Epoch: 5| Step: 9
Training loss: 2.6388845443725586
Validation loss: 2.041256122691657

Epoch: 5| Step: 10
Training loss: 2.1127407550811768
Validation loss: 2.0454920209864134

Epoch: 114| Step: 0
Training loss: 1.8299665451049805
Validation loss: 2.048602678442514

Epoch: 5| Step: 1
Training loss: 2.305006742477417
Validation loss: 2.066051188335624

Epoch: 5| Step: 2
Training loss: 2.0939443111419678
Validation loss: 1.9911381826605847

Epoch: 5| Step: 3
Training loss: 2.1256935596466064
Validation loss: 2.0408330373866583

Epoch: 5| Step: 4
Training loss: 2.866893768310547
Validation loss: 2.0244913434469574

Epoch: 5| Step: 5
Training loss: 2.0344150066375732
Validation loss: 2.044789198906191

Epoch: 5| Step: 6
Training loss: 3.0661540031433105
Validation loss: 2.0310020062231247

Epoch: 5| Step: 7
Training loss: 2.114902973175049
Validation loss: 2.0427005316621516

Epoch: 5| Step: 8
Training loss: 1.742095708847046
Validation loss: 2.0329149179561163

Epoch: 5| Step: 9
Training loss: 2.0953807830810547
Validation loss: 2.068992232763639

Epoch: 5| Step: 10
Training loss: 1.9460934400558472
Validation loss: 2.035977973732897

Epoch: 115| Step: 0
Training loss: 2.50767183303833
Validation loss: 2.0317775510972544

Epoch: 5| Step: 1
Training loss: 2.051994800567627
Validation loss: 2.0670724504737445

Epoch: 5| Step: 2
Training loss: 2.687615156173706
Validation loss: 2.065569769951605

Epoch: 5| Step: 3
Training loss: 1.4949705600738525
Validation loss: 2.028796952257874

Epoch: 5| Step: 4
Training loss: 2.748591661453247
Validation loss: 2.027599270625781

Epoch: 5| Step: 5
Training loss: 2.7438530921936035
Validation loss: 2.037658212005451

Epoch: 5| Step: 6
Training loss: 1.8391259908676147
Validation loss: 2.0434998696850193

Epoch: 5| Step: 7
Training loss: 2.6005935668945312
Validation loss: 2.0103541497261292

Epoch: 5| Step: 8
Training loss: 1.5768611431121826
Validation loss: 2.0212593745159846

Epoch: 5| Step: 9
Training loss: 2.1132333278656006
Validation loss: 1.9989159491754347

Epoch: 5| Step: 10
Training loss: 2.0747640132904053
Validation loss: 2.0400010667821413

Epoch: 116| Step: 0
Training loss: 2.2635674476623535
Validation loss: 2.0219757531278875

Epoch: 5| Step: 1
Training loss: 2.2718677520751953
Validation loss: 2.0266684639838433

Epoch: 5| Step: 2
Training loss: 1.6522905826568604
Validation loss: 2.0159209800022904

Epoch: 5| Step: 3
Training loss: 1.7382786273956299
Validation loss: 2.0102581003660798

Epoch: 5| Step: 4
Training loss: 2.28391695022583
Validation loss: 2.038226940298593

Epoch: 5| Step: 5
Training loss: 2.591073989868164
Validation loss: 2.019812271159182

Epoch: 5| Step: 6
Training loss: 2.380297899246216
Validation loss: 2.0377234361504994

Epoch: 5| Step: 7
Training loss: 2.430694580078125
Validation loss: 1.9968259321746005

Epoch: 5| Step: 8
Training loss: 2.6350646018981934
Validation loss: 2.029317705861984

Epoch: 5| Step: 9
Training loss: 2.09785795211792
Validation loss: 2.0436836417003343

Epoch: 5| Step: 10
Training loss: 1.7885825634002686
Validation loss: 2.0354046565230175

Epoch: 117| Step: 0
Training loss: 1.7147247791290283
Validation loss: 2.029441770686898

Epoch: 5| Step: 1
Training loss: 2.6656391620635986
Validation loss: 2.018799207543814

Epoch: 5| Step: 2
Training loss: 2.244014024734497
Validation loss: 2.053146070049655

Epoch: 5| Step: 3
Training loss: 2.234705686569214
Validation loss: 2.023771248837953

Epoch: 5| Step: 4
Training loss: 1.9054771661758423
Validation loss: 2.0423398594702444

Epoch: 5| Step: 5
Training loss: 2.1876468658447266
Validation loss: 2.0131217382287465

Epoch: 5| Step: 6
Training loss: 2.202308177947998
Validation loss: 2.0520635189548617

Epoch: 5| Step: 7
Training loss: 3.117708921432495
Validation loss: 2.0174216044846403

Epoch: 5| Step: 8
Training loss: 1.618692398071289
Validation loss: 2.0363509757544405

Epoch: 5| Step: 9
Training loss: 2.0680088996887207
Validation loss: 2.031103568692361

Epoch: 5| Step: 10
Training loss: 2.399691104888916
Validation loss: 2.047331585679003

Epoch: 118| Step: 0
Training loss: 2.6034131050109863
Validation loss: 2.046590884526571

Epoch: 5| Step: 1
Training loss: 2.343135356903076
Validation loss: 2.0848643651572605

Epoch: 5| Step: 2
Training loss: 1.6567939519882202
Validation loss: 2.0237225281294955

Epoch: 5| Step: 3
Training loss: 2.4357593059539795
Validation loss: 2.038563702696113

Epoch: 5| Step: 4
Training loss: 2.4791455268859863
Validation loss: 2.0281263987223306

Epoch: 5| Step: 5
Training loss: 2.3751895427703857
Validation loss: 2.0494034098040674

Epoch: 5| Step: 6
Training loss: 1.8712555170059204
Validation loss: 2.0946991007815123

Epoch: 5| Step: 7
Training loss: 1.8455162048339844
Validation loss: 2.041853279195806

Epoch: 5| Step: 8
Training loss: 2.1059823036193848
Validation loss: 2.0593074483256184

Epoch: 5| Step: 9
Training loss: 2.6830973625183105
Validation loss: 2.046478625266783

Epoch: 5| Step: 10
Training loss: 2.1364386081695557
Validation loss: 2.0429864814204555

Epoch: 119| Step: 0
Training loss: 1.8199079036712646
Validation loss: 2.024612316521265

Epoch: 5| Step: 1
Training loss: 3.1993629932403564
Validation loss: 2.0194964383238103

Epoch: 5| Step: 2
Training loss: 2.29138445854187
Validation loss: 2.0789918143262147

Epoch: 5| Step: 3
Training loss: 2.1739625930786133
Validation loss: 2.067031547587405

Epoch: 5| Step: 4
Training loss: 1.8009144067764282
Validation loss: 2.063787752582181

Epoch: 5| Step: 5
Training loss: 2.5259294509887695
Validation loss: 2.080428123474121

Epoch: 5| Step: 6
Training loss: 2.127264976501465
Validation loss: 2.068956646867978

Epoch: 5| Step: 7
Training loss: 2.1584341526031494
Validation loss: 2.0596942414519606

Epoch: 5| Step: 8
Training loss: 1.748199224472046
Validation loss: 2.062605083629649

Epoch: 5| Step: 9
Training loss: 2.3209071159362793
Validation loss: 2.0545611432803574

Epoch: 5| Step: 10
Training loss: 1.9334936141967773
Validation loss: 2.0540216045994915

Epoch: 120| Step: 0
Training loss: 2.3095431327819824
Validation loss: 2.0619862053983953

Epoch: 5| Step: 1
Training loss: 2.2441327571868896
Validation loss: 2.034277000734883

Epoch: 5| Step: 2
Training loss: 2.4969704151153564
Validation loss: 2.0469272828871206

Epoch: 5| Step: 3
Training loss: 2.3076064586639404
Validation loss: 2.060718761977329

Epoch: 5| Step: 4
Training loss: 2.2010579109191895
Validation loss: 2.0542925198872886

Epoch: 5| Step: 5
Training loss: 2.2972047328948975
Validation loss: 2.0384727062717563

Epoch: 5| Step: 6
Training loss: 2.4931676387786865
Validation loss: 2.0356476922189035

Epoch: 5| Step: 7
Training loss: 2.0087475776672363
Validation loss: 2.054401155441038

Epoch: 5| Step: 8
Training loss: 1.7575790882110596
Validation loss: 2.0666364546745055

Epoch: 5| Step: 9
Training loss: 2.355358839035034
Validation loss: 2.03963368169723

Epoch: 5| Step: 10
Training loss: 1.8149126768112183
Validation loss: 2.0503444274266562

Epoch: 121| Step: 0
Training loss: 2.2503323554992676
Validation loss: 2.0187215676871677

Epoch: 5| Step: 1
Training loss: 1.8499199151992798
Validation loss: 2.0315931894445933

Epoch: 5| Step: 2
Training loss: 2.449465751647949
Validation loss: 2.0336309171492055

Epoch: 5| Step: 3
Training loss: 2.2995312213897705
Validation loss: 2.027600578082505

Epoch: 5| Step: 4
Training loss: 2.1926331520080566
Validation loss: 2.03374812423542

Epoch: 5| Step: 5
Training loss: 2.2001969814300537
Validation loss: 2.030263075264551

Epoch: 5| Step: 6
Training loss: 2.2346084117889404
Validation loss: 2.0444642984738914

Epoch: 5| Step: 7
Training loss: 2.5037264823913574
Validation loss: 2.0240713037470335

Epoch: 5| Step: 8
Training loss: 1.9302072525024414
Validation loss: 2.025649138676223

Epoch: 5| Step: 9
Training loss: 1.7278385162353516
Validation loss: 2.0473326611262497

Epoch: 5| Step: 10
Training loss: 2.6725826263427734
Validation loss: 1.979590953037303

Epoch: 122| Step: 0
Training loss: 2.5518598556518555
Validation loss: 2.047221055594824

Epoch: 5| Step: 1
Training loss: 2.656283140182495
Validation loss: 2.037968397140503

Epoch: 5| Step: 2
Training loss: 1.7649517059326172
Validation loss: 2.0337348625224125

Epoch: 5| Step: 3
Training loss: 1.9535577297210693
Validation loss: 2.011229294602589

Epoch: 5| Step: 4
Training loss: 2.4234747886657715
Validation loss: 2.0247063790598223

Epoch: 5| Step: 5
Training loss: 1.9470269680023193
Validation loss: 2.067743227046023

Epoch: 5| Step: 6
Training loss: 2.8765714168548584
Validation loss: 2.041528376199866

Epoch: 5| Step: 7
Training loss: 2.0262327194213867
Validation loss: 2.051214438612743

Epoch: 5| Step: 8
Training loss: 2.573333740234375
Validation loss: 2.0301664285762335

Epoch: 5| Step: 9
Training loss: 1.7469784021377563
Validation loss: 2.034342281280025

Epoch: 5| Step: 10
Training loss: 2.1220943927764893
Validation loss: 2.054778498987998

Epoch: 123| Step: 0
Training loss: 1.6140018701553345
Validation loss: 2.076320440538468

Epoch: 5| Step: 1
Training loss: 1.8339277505874634
Validation loss: 2.0487808360848376

Epoch: 5| Step: 2
Training loss: 1.905591368675232
Validation loss: 2.052626258583479

Epoch: 5| Step: 3
Training loss: 2.2505784034729004
Validation loss: 2.0800291415183776

Epoch: 5| Step: 4
Training loss: 2.228550910949707
Validation loss: 2.0581385102323306

Epoch: 5| Step: 5
Training loss: 2.1087100505828857
Validation loss: 2.028015693028768

Epoch: 5| Step: 6
Training loss: 2.4064395427703857
Validation loss: 2.0498353896602506

Epoch: 5| Step: 7
Training loss: 3.1541037559509277
Validation loss: 2.0216861232634513

Epoch: 5| Step: 8
Training loss: 2.186563730239868
Validation loss: 2.015399286823888

Epoch: 5| Step: 9
Training loss: 2.11881947517395
Validation loss: 2.0470703494164253

Epoch: 5| Step: 10
Training loss: 2.425640821456909
Validation loss: 2.0485502942915885

Epoch: 124| Step: 0
Training loss: 1.8874801397323608
Validation loss: 2.0252732333316597

Epoch: 5| Step: 1
Training loss: 2.4104199409484863
Validation loss: 2.026132088835521

Epoch: 5| Step: 2
Training loss: 2.0565385818481445
Validation loss: 2.012629370535574

Epoch: 5| Step: 3
Training loss: 2.004394054412842
Validation loss: 2.0270893291760514

Epoch: 5| Step: 4
Training loss: 2.4382126331329346
Validation loss: 2.0314128193804013

Epoch: 5| Step: 5
Training loss: 2.5052614212036133
Validation loss: 2.0562499633399387

Epoch: 5| Step: 6
Training loss: 2.4704666137695312
Validation loss: 2.027853391503775

Epoch: 5| Step: 7
Training loss: 1.901455283164978
Validation loss: 2.0775197654642086

Epoch: 5| Step: 8
Training loss: 2.57712721824646
Validation loss: 2.0630987087885537

Epoch: 5| Step: 9
Training loss: 1.9454708099365234
Validation loss: 2.054959056197956

Epoch: 5| Step: 10
Training loss: 1.7387709617614746
Validation loss: 1.9952389091573737

Epoch: 125| Step: 0
Training loss: 2.0295794010162354
Validation loss: 2.036840823388869

Epoch: 5| Step: 1
Training loss: 2.485164165496826
Validation loss: 2.057168706770866

Epoch: 5| Step: 2
Training loss: 2.2349188327789307
Validation loss: 2.04105895052674

Epoch: 5| Step: 3
Training loss: 2.0118021965026855
Validation loss: 2.0268665218865998

Epoch: 5| Step: 4
Training loss: 2.421124219894409
Validation loss: 2.0438653551122195

Epoch: 5| Step: 5
Training loss: 1.7841498851776123
Validation loss: 2.048267415774766

Epoch: 5| Step: 6
Training loss: 2.454610586166382
Validation loss: 2.0614001110035884

Epoch: 5| Step: 7
Training loss: 2.648355007171631
Validation loss: 2.074243382741046

Epoch: 5| Step: 8
Training loss: 1.9173057079315186
Validation loss: 2.0776929111890894

Epoch: 5| Step: 9
Training loss: 1.7642688751220703
Validation loss: 2.0898476275064612

Epoch: 5| Step: 10
Training loss: 2.554192066192627
Validation loss: 2.061875908605514

Epoch: 126| Step: 0
Training loss: 1.9333915710449219
Validation loss: 2.0430459514740975

Epoch: 5| Step: 1
Training loss: 2.0682532787323
Validation loss: 2.022202632760489

Epoch: 5| Step: 2
Training loss: 2.3985610008239746
Validation loss: 2.0470826266914286

Epoch: 5| Step: 3
Training loss: 2.2778735160827637
Validation loss: 2.05770113647625

Epoch: 5| Step: 4
Training loss: 1.5404835939407349
Validation loss: 2.0510911838982695

Epoch: 5| Step: 5
Training loss: 2.2320401668548584
Validation loss: 2.059106389681498

Epoch: 5| Step: 6
Training loss: 2.099055051803589
Validation loss: 2.065881562489335

Epoch: 5| Step: 7
Training loss: 1.863264799118042
Validation loss: 2.0701830079478603

Epoch: 5| Step: 8
Training loss: 3.1030664443969727
Validation loss: 2.018587350845337

Epoch: 5| Step: 9
Training loss: 2.1208407878875732
Validation loss: 2.0577400756138626

Epoch: 5| Step: 10
Training loss: 2.7849369049072266
Validation loss: 2.0017018625813146

Epoch: 127| Step: 0
Training loss: 1.8905473947525024
Validation loss: 2.0070438615737425

Epoch: 5| Step: 1
Training loss: 2.1333701610565186
Validation loss: 2.05791074486189

Epoch: 5| Step: 2
Training loss: 2.0579605102539062
Validation loss: 2.0118815514349166

Epoch: 5| Step: 3
Training loss: 2.640296459197998
Validation loss: 2.057688122154564

Epoch: 5| Step: 4
Training loss: 1.7180726528167725
Validation loss: 2.040921554770521

Epoch: 5| Step: 5
Training loss: 2.2161197662353516
Validation loss: 2.050912641709851

Epoch: 5| Step: 6
Training loss: 2.158916473388672
Validation loss: 2.0357582940850207

Epoch: 5| Step: 7
Training loss: 2.5662598609924316
Validation loss: 2.087501695079188

Epoch: 5| Step: 8
Training loss: 2.6102328300476074
Validation loss: 2.027261377662741

Epoch: 5| Step: 9
Training loss: 1.8348290920257568
Validation loss: 2.0331565731315204

Epoch: 5| Step: 10
Training loss: 2.084148406982422
Validation loss: 2.0292428975464194

Epoch: 128| Step: 0
Training loss: 1.8327045440673828
Validation loss: 2.015566623339089

Epoch: 5| Step: 1
Training loss: 2.3077547550201416
Validation loss: 2.020588569743659

Epoch: 5| Step: 2
Training loss: 2.1167116165161133
Validation loss: 2.0372152020854335

Epoch: 5| Step: 3
Training loss: 2.154510498046875
Validation loss: 2.0444802776459725

Epoch: 5| Step: 4
Training loss: 2.781970500946045
Validation loss: 2.052369467673763

Epoch: 5| Step: 5
Training loss: 1.9516788721084595
Validation loss: 2.04404801963478

Epoch: 5| Step: 6
Training loss: 2.1670076847076416
Validation loss: 2.026427843237436

Epoch: 5| Step: 7
Training loss: 2.2406623363494873
Validation loss: 2.0777850638153734

Epoch: 5| Step: 8
Training loss: 2.3877792358398438
Validation loss: 2.0381260430941017

Epoch: 5| Step: 9
Training loss: 1.9686403274536133
Validation loss: 2.045218103675432

Epoch: 5| Step: 10
Training loss: 2.5809366703033447
Validation loss: 2.070336913549772

Epoch: 129| Step: 0
Training loss: 2.2414870262145996
Validation loss: 2.0461696527337514

Epoch: 5| Step: 1
Training loss: 2.2665812969207764
Validation loss: 2.0026958219466673

Epoch: 5| Step: 2
Training loss: 2.220127582550049
Validation loss: 2.019147619124382

Epoch: 5| Step: 3
Training loss: 2.1754472255706787
Validation loss: 2.0170801788248043

Epoch: 5| Step: 4
Training loss: 2.6532974243164062
Validation loss: 2.0635221030122493

Epoch: 5| Step: 5
Training loss: 2.6294360160827637
Validation loss: 2.080746385358995

Epoch: 5| Step: 6
Training loss: 1.8655952215194702
Validation loss: 2.0167664520202147

Epoch: 5| Step: 7
Training loss: 2.4280967712402344
Validation loss: 2.029168454549646

Epoch: 5| Step: 8
Training loss: 1.7334964275360107
Validation loss: 2.0207253027987737

Epoch: 5| Step: 9
Training loss: 2.306427478790283
Validation loss: 2.043686928287629

Epoch: 5| Step: 10
Training loss: 1.7547470331192017
Validation loss: 2.0358850391962195

Epoch: 130| Step: 0
Training loss: 2.511141538619995
Validation loss: 2.0672631212460097

Epoch: 5| Step: 1
Training loss: 1.7870960235595703
Validation loss: 2.016619731021184

Epoch: 5| Step: 2
Training loss: 1.948240876197815
Validation loss: 2.041425299900834

Epoch: 5| Step: 3
Training loss: 2.1899352073669434
Validation loss: 2.082992192237608

Epoch: 5| Step: 4
Training loss: 2.59553861618042
Validation loss: 2.0833011263160297

Epoch: 5| Step: 5
Training loss: 2.348543643951416
Validation loss: 2.046919386873963

Epoch: 5| Step: 6
Training loss: 1.8869622945785522
Validation loss: 2.045006298249768

Epoch: 5| Step: 7
Training loss: 2.2524003982543945
Validation loss: 2.034481253675235

Epoch: 5| Step: 8
Training loss: 2.487903356552124
Validation loss: 2.056339026779257

Epoch: 5| Step: 9
Training loss: 1.859262466430664
Validation loss: 2.061999959330405

Epoch: 5| Step: 10
Training loss: 2.287890672683716
Validation loss: 2.013879402991264

Epoch: 131| Step: 0
Training loss: 1.9773833751678467
Validation loss: 2.028135448373774

Epoch: 5| Step: 1
Training loss: 2.3131420612335205
Validation loss: 2.0680220332196964

Epoch: 5| Step: 2
Training loss: 2.6753406524658203
Validation loss: 2.053868180962019

Epoch: 5| Step: 3
Training loss: 1.800649642944336
Validation loss: 2.018757894474973

Epoch: 5| Step: 4
Training loss: 2.6935160160064697
Validation loss: 2.0348514946558143

Epoch: 5| Step: 5
Training loss: 1.9742155075073242
Validation loss: 2.0533984297065326

Epoch: 5| Step: 6
Training loss: 1.7448961734771729
Validation loss: 2.053608731556964

Epoch: 5| Step: 7
Training loss: 2.2646477222442627
Validation loss: 1.9935820128328057

Epoch: 5| Step: 8
Training loss: 2.630368709564209
Validation loss: 1.9968999073069582

Epoch: 5| Step: 9
Training loss: 2.0667011737823486
Validation loss: 2.0527830957084574

Epoch: 5| Step: 10
Training loss: 2.049375534057617
Validation loss: 2.0287770942975114

Epoch: 132| Step: 0
Training loss: 2.5663087368011475
Validation loss: 2.025639159705049

Epoch: 5| Step: 1
Training loss: 2.0389199256896973
Validation loss: 2.060332703334029

Epoch: 5| Step: 2
Training loss: 2.284554958343506
Validation loss: 1.9920597999326644

Epoch: 5| Step: 3
Training loss: 2.186856746673584
Validation loss: 2.0491011552913214

Epoch: 5| Step: 4
Training loss: 2.325568675994873
Validation loss: 2.0492517358513287

Epoch: 5| Step: 5
Training loss: 1.4410645961761475
Validation loss: 2.0395617279955136

Epoch: 5| Step: 6
Training loss: 2.4341983795166016
Validation loss: 2.0558141918592554

Epoch: 5| Step: 7
Training loss: 2.527191162109375
Validation loss: 2.0816699227979107

Epoch: 5| Step: 8
Training loss: 2.0664191246032715
Validation loss: 2.083679969592761

Epoch: 5| Step: 9
Training loss: 2.4830029010772705
Validation loss: 2.083604181966474

Epoch: 5| Step: 10
Training loss: 2.0913686752319336
Validation loss: 2.028308747917093

Epoch: 133| Step: 0
Training loss: 2.0497031211853027
Validation loss: 2.055408711074501

Epoch: 5| Step: 1
Training loss: 3.1002819538116455
Validation loss: 2.039719263712565

Epoch: 5| Step: 2
Training loss: 2.1719536781311035
Validation loss: 2.0804392214744323

Epoch: 5| Step: 3
Training loss: 2.116241931915283
Validation loss: 2.0417728167708202

Epoch: 5| Step: 4
Training loss: 1.763033151626587
Validation loss: 2.0580414264432845

Epoch: 5| Step: 5
Training loss: 1.865971565246582
Validation loss: 2.067014904432399

Epoch: 5| Step: 6
Training loss: 2.194359302520752
Validation loss: 2.038902997970581

Epoch: 5| Step: 7
Training loss: 2.2155158519744873
Validation loss: 2.064015378234207

Epoch: 5| Step: 8
Training loss: 2.2865872383117676
Validation loss: 2.0407873328014086

Epoch: 5| Step: 9
Training loss: 2.7567832469940186
Validation loss: 2.065470895459575

Epoch: 5| Step: 10
Training loss: 1.7340095043182373
Validation loss: 2.0666911525111042

Epoch: 134| Step: 0
Training loss: 1.8564506769180298
Validation loss: 2.0779302581664054

Epoch: 5| Step: 1
Training loss: 2.2562036514282227
Validation loss: 2.0618619380458707

Epoch: 5| Step: 2
Training loss: 2.03448486328125
Validation loss: 2.017662291885704

Epoch: 5| Step: 3
Training loss: 2.184941530227661
Validation loss: 2.066782933409496

Epoch: 5| Step: 4
Training loss: 2.419037342071533
Validation loss: 2.057480655690675

Epoch: 5| Step: 5
Training loss: 1.9836137294769287
Validation loss: 2.0463316645673526

Epoch: 5| Step: 6
Training loss: 1.8777170181274414
Validation loss: 2.076939321333362

Epoch: 5| Step: 7
Training loss: 2.2898879051208496
Validation loss: 2.0774887838671283

Epoch: 5| Step: 8
Training loss: 1.815084457397461
Validation loss: 2.0823411787709882

Epoch: 5| Step: 9
Training loss: 2.3847241401672363
Validation loss: 2.051954233518211

Epoch: 5| Step: 10
Training loss: 3.1047537326812744
Validation loss: 2.0773316173143286

Epoch: 135| Step: 0
Training loss: 2.4322543144226074
Validation loss: 2.065361733077675

Epoch: 5| Step: 1
Training loss: 1.6176459789276123
Validation loss: 2.041295684793944

Epoch: 5| Step: 2
Training loss: 2.394984006881714
Validation loss: 2.0463493485604562

Epoch: 5| Step: 3
Training loss: 1.8959629535675049
Validation loss: 2.039673743709441

Epoch: 5| Step: 4
Training loss: 2.3239173889160156
Validation loss: 2.0392570444332656

Epoch: 5| Step: 5
Training loss: 1.8450877666473389
Validation loss: 2.0277137294892342

Epoch: 5| Step: 6
Training loss: 2.5058093070983887
Validation loss: 2.0288822420181765

Epoch: 5| Step: 7
Training loss: 1.954755187034607
Validation loss: 2.028884195512341

Epoch: 5| Step: 8
Training loss: 2.144242525100708
Validation loss: 2.0376305644230177

Epoch: 5| Step: 9
Training loss: 2.366489887237549
Validation loss: 2.0111279500428068

Epoch: 5| Step: 10
Training loss: 2.943110227584839
Validation loss: 2.0026140815468243

Epoch: 136| Step: 0
Training loss: 2.5928893089294434
Validation loss: 2.027506700126074

Epoch: 5| Step: 1
Training loss: 1.7401851415634155
Validation loss: 2.062565095963017

Epoch: 5| Step: 2
Training loss: 3.042755126953125
Validation loss: 2.045304500928489

Epoch: 5| Step: 3
Training loss: 1.4948089122772217
Validation loss: 2.057692227825042

Epoch: 5| Step: 4
Training loss: 1.9570512771606445
Validation loss: 2.020607498384291

Epoch: 5| Step: 5
Training loss: 2.0725677013397217
Validation loss: 2.0294133065849222

Epoch: 5| Step: 6
Training loss: 2.400023937225342
Validation loss: 2.017924495922622

Epoch: 5| Step: 7
Training loss: 1.87322998046875
Validation loss: 2.0430541487150293

Epoch: 5| Step: 8
Training loss: 2.037259578704834
Validation loss: 2.0318918151240193

Epoch: 5| Step: 9
Training loss: 2.506030559539795
Validation loss: 2.015611735723352

Epoch: 5| Step: 10
Training loss: 2.1277546882629395
Validation loss: 2.0332336759054535

Epoch: 137| Step: 0
Training loss: 2.248058319091797
Validation loss: 2.0234374218089606

Epoch: 5| Step: 1
Training loss: 2.1413683891296387
Validation loss: 2.0788524778940345

Epoch: 5| Step: 2
Training loss: 2.0274739265441895
Validation loss: 2.0657423926937963

Epoch: 5| Step: 3
Training loss: 1.9056994915008545
Validation loss: 2.0421035341037217

Epoch: 5| Step: 4
Training loss: 2.541839122772217
Validation loss: 2.0690924941852527

Epoch: 5| Step: 5
Training loss: 2.599907398223877
Validation loss: 2.05750060337846

Epoch: 5| Step: 6
Training loss: 1.913622260093689
Validation loss: 2.045087005502434

Epoch: 5| Step: 7
Training loss: 2.4839119911193848
Validation loss: 2.058834006709437

Epoch: 5| Step: 8
Training loss: 1.9310922622680664
Validation loss: 2.018265357581518

Epoch: 5| Step: 9
Training loss: 2.0134880542755127
Validation loss: 2.043555409677567

Epoch: 5| Step: 10
Training loss: 1.971813678741455
Validation loss: 2.095632555664227

Epoch: 138| Step: 0
Training loss: 2.892885684967041
Validation loss: 2.0397984661081785

Epoch: 5| Step: 1
Training loss: 1.969125509262085
Validation loss: 2.034769745283229

Epoch: 5| Step: 2
Training loss: 1.3996078968048096
Validation loss: 2.0601024166230233

Epoch: 5| Step: 3
Training loss: 2.25995135307312
Validation loss: 2.055389188951062

Epoch: 5| Step: 4
Training loss: 1.887173056602478
Validation loss: 2.028421735250822

Epoch: 5| Step: 5
Training loss: 2.414708137512207
Validation loss: 2.059735575029927

Epoch: 5| Step: 6
Training loss: 1.9460420608520508
Validation loss: 2.034041243214761

Epoch: 5| Step: 7
Training loss: 2.1384100914001465
Validation loss: 2.046059258522526

Epoch: 5| Step: 8
Training loss: 2.16660213470459
Validation loss: 2.0443751632526355

Epoch: 5| Step: 9
Training loss: 2.197960376739502
Validation loss: 2.0654097808304654

Epoch: 5| Step: 10
Training loss: 2.7810187339782715
Validation loss: 2.0188436149269022

Epoch: 139| Step: 0
Training loss: 2.494152069091797
Validation loss: 2.046959944950637

Epoch: 5| Step: 1
Training loss: 2.108250856399536
Validation loss: 2.0781957564815396

Epoch: 5| Step: 2
Training loss: 2.3359577655792236
Validation loss: 2.047837722686029

Epoch: 5| Step: 3
Training loss: 2.416321277618408
Validation loss: 2.0346727473761446

Epoch: 5| Step: 4
Training loss: 2.100705623626709
Validation loss: 2.0870642149320213

Epoch: 5| Step: 5
Training loss: 2.3047969341278076
Validation loss: 2.0697609686082408

Epoch: 5| Step: 6
Training loss: 1.943701982498169
Validation loss: 2.08997134623989

Epoch: 5| Step: 7
Training loss: 2.834968328475952
Validation loss: 2.0572400169987834

Epoch: 5| Step: 8
Training loss: 1.9491631984710693
Validation loss: 2.0366530367123183

Epoch: 5| Step: 9
Training loss: 1.945296049118042
Validation loss: 2.083039770844162

Epoch: 5| Step: 10
Training loss: 1.7421596050262451
Validation loss: 2.0630940442444174

Epoch: 140| Step: 0
Training loss: 2.148881673812866
Validation loss: 2.027607290975509

Epoch: 5| Step: 1
Training loss: 2.7483561038970947
Validation loss: 2.0708922878388436

Epoch: 5| Step: 2
Training loss: 2.4594931602478027
Validation loss: 2.0697336248172227

Epoch: 5| Step: 3
Training loss: 2.476125717163086
Validation loss: 2.0552849718319472

Epoch: 5| Step: 4
Training loss: 2.189753293991089
Validation loss: 2.090019259401547

Epoch: 5| Step: 5
Training loss: 2.2742536067962646
Validation loss: 2.0968726655488372

Epoch: 5| Step: 6
Training loss: 1.8566757440567017
Validation loss: 2.043081025923452

Epoch: 5| Step: 7
Training loss: 1.8055585622787476
Validation loss: 2.066810687383016

Epoch: 5| Step: 8
Training loss: 1.6919304132461548
Validation loss: 2.0692878051470687

Epoch: 5| Step: 9
Training loss: 2.4395337104797363
Validation loss: 2.069254295800322

Epoch: 5| Step: 10
Training loss: 1.8939076662063599
Validation loss: 2.072166447998375

Epoch: 141| Step: 0
Training loss: 1.8945614099502563
Validation loss: 2.051547129948934

Epoch: 5| Step: 1
Training loss: 2.22908616065979
Validation loss: 2.030984306848177

Epoch: 5| Step: 2
Training loss: 1.9394149780273438
Validation loss: 2.059777352117723

Epoch: 5| Step: 3
Training loss: 2.30094051361084
Validation loss: 2.0473378806985836

Epoch: 5| Step: 4
Training loss: 2.028895139694214
Validation loss: 2.03432826072939

Epoch: 5| Step: 5
Training loss: 2.4780972003936768
Validation loss: 2.0601740216696136

Epoch: 5| Step: 6
Training loss: 2.120317220687866
Validation loss: 2.031803807904643

Epoch: 5| Step: 7
Training loss: 1.8443372249603271
Validation loss: 2.0583148335897796

Epoch: 5| Step: 8
Training loss: 2.631497621536255
Validation loss: 2.0153061959051315

Epoch: 5| Step: 9
Training loss: 2.459489107131958
Validation loss: 2.000703950082102

Epoch: 5| Step: 10
Training loss: 2.2721502780914307
Validation loss: 2.0436010886264104

Epoch: 142| Step: 0
Training loss: 2.1478183269500732
Validation loss: 2.0412464757119455

Epoch: 5| Step: 1
Training loss: 2.25126314163208
Validation loss: 2.0465776317863056

Epoch: 5| Step: 2
Training loss: 2.39481782913208
Validation loss: 2.0275097816221175

Epoch: 5| Step: 3
Training loss: 2.2878799438476562
Validation loss: 2.015672163296771

Epoch: 5| Step: 4
Training loss: 1.892657995223999
Validation loss: 2.0300138073582805

Epoch: 5| Step: 5
Training loss: 1.746063470840454
Validation loss: 2.0316943481404293

Epoch: 5| Step: 6
Training loss: 1.713880181312561
Validation loss: 2.029771647145671

Epoch: 5| Step: 7
Training loss: 2.6921050548553467
Validation loss: 2.038547237714132

Epoch: 5| Step: 8
Training loss: 2.2418577671051025
Validation loss: 2.0660366986387517

Epoch: 5| Step: 9
Training loss: 2.2821688652038574
Validation loss: 2.04971718916329

Epoch: 5| Step: 10
Training loss: 2.6455085277557373
Validation loss: 2.0753814084555513

Epoch: 143| Step: 0
Training loss: 2.1106808185577393
Validation loss: 2.0628979693176928

Epoch: 5| Step: 1
Training loss: 2.5697743892669678
Validation loss: 2.0693573926084783

Epoch: 5| Step: 2
Training loss: 1.3187686204910278
Validation loss: 2.0756132820601105

Epoch: 5| Step: 3
Training loss: 3.107243537902832
Validation loss: 2.051453085355861

Epoch: 5| Step: 4
Training loss: 2.0228681564331055
Validation loss: 2.0438665728415213

Epoch: 5| Step: 5
Training loss: 2.6978824138641357
Validation loss: 2.058819459330651

Epoch: 5| Step: 6
Training loss: 1.7384898662567139
Validation loss: 2.0593726378615185

Epoch: 5| Step: 7
Training loss: 2.2964444160461426
Validation loss: 2.0519463862142255

Epoch: 5| Step: 8
Training loss: 2.1178736686706543
Validation loss: 2.098535773574665

Epoch: 5| Step: 9
Training loss: 2.345371961593628
Validation loss: 2.08282454552189

Epoch: 5| Step: 10
Training loss: 1.5955694913864136
Validation loss: 2.1522994323443343

Epoch: 144| Step: 0
Training loss: 1.4203553199768066
Validation loss: 2.081962393176171

Epoch: 5| Step: 1
Training loss: 2.6991829872131348
Validation loss: 2.0895355260500343

Epoch: 5| Step: 2
Training loss: 2.604297637939453
Validation loss: 2.093647790211503

Epoch: 5| Step: 3
Training loss: 1.924602746963501
Validation loss: 2.100425640741984

Epoch: 5| Step: 4
Training loss: 2.550201416015625
Validation loss: 2.0700026840291996

Epoch: 5| Step: 5
Training loss: 2.5975544452667236
Validation loss: 2.0644775693134596

Epoch: 5| Step: 6
Training loss: 2.365729570388794
Validation loss: 2.052922405222411

Epoch: 5| Step: 7
Training loss: 1.6423059701919556
Validation loss: 2.041992611782525

Epoch: 5| Step: 8
Training loss: 2.010261058807373
Validation loss: 2.0782352570564515

Epoch: 5| Step: 9
Training loss: 1.9431126117706299
Validation loss: 2.0575806697209678

Epoch: 5| Step: 10
Training loss: 2.420339822769165
Validation loss: 2.055133870852891

Epoch: 145| Step: 0
Training loss: 2.3364524841308594
Validation loss: 2.063383851000058

Epoch: 5| Step: 1
Training loss: 2.17219614982605
Validation loss: 2.0284365902664843

Epoch: 5| Step: 2
Training loss: 2.5798068046569824
Validation loss: 2.057207804854198

Epoch: 5| Step: 3
Training loss: 1.9585745334625244
Validation loss: 2.064280181802729

Epoch: 5| Step: 4
Training loss: 2.373161792755127
Validation loss: 2.0604047211267615

Epoch: 5| Step: 5
Training loss: 2.0452332496643066
Validation loss: 2.082569783733737

Epoch: 5| Step: 6
Training loss: 1.6116126775741577
Validation loss: 2.064345969948717

Epoch: 5| Step: 7
Training loss: 2.348649501800537
Validation loss: 2.0551601840603735

Epoch: 5| Step: 8
Training loss: 1.9569618701934814
Validation loss: 2.0372576252106698

Epoch: 5| Step: 9
Training loss: 2.358543872833252
Validation loss: 2.0276739187138055

Epoch: 5| Step: 10
Training loss: 2.08602237701416
Validation loss: 2.037387635118218

Epoch: 146| Step: 0
Training loss: 1.7765271663665771
Validation loss: 2.0407204909991195

Epoch: 5| Step: 1
Training loss: 2.265810966491699
Validation loss: 2.0592330732653217

Epoch: 5| Step: 2
Training loss: 2.134167194366455
Validation loss: 2.0131882134304253

Epoch: 5| Step: 3
Training loss: 2.4230875968933105
Validation loss: 2.0313482028181835

Epoch: 5| Step: 4
Training loss: 1.993343710899353
Validation loss: 2.0235451306066206

Epoch: 5| Step: 5
Training loss: 1.9893745183944702
Validation loss: 2.028170588195965

Epoch: 5| Step: 6
Training loss: 2.2090249061584473
Validation loss: 2.059059126402742

Epoch: 5| Step: 7
Training loss: 1.9099676609039307
Validation loss: 2.0355535694347915

Epoch: 5| Step: 8
Training loss: 2.2185311317443848
Validation loss: 2.016268409708495

Epoch: 5| Step: 9
Training loss: 2.419105291366577
Validation loss: 2.067256931335695

Epoch: 5| Step: 10
Training loss: 2.5864293575286865
Validation loss: 2.0522044935534076

Epoch: 147| Step: 0
Training loss: 1.3487294912338257
Validation loss: 2.0473106317622687

Epoch: 5| Step: 1
Training loss: 1.982098937034607
Validation loss: 2.066624141508533

Epoch: 5| Step: 2
Training loss: 2.641645908355713
Validation loss: 2.013595316999702

Epoch: 5| Step: 3
Training loss: 2.320486068725586
Validation loss: 2.0041778472162064

Epoch: 5| Step: 4
Training loss: 1.6960487365722656
Validation loss: 2.054480073272541

Epoch: 5| Step: 5
Training loss: 2.1499710083007812
Validation loss: 2.0775387376867314

Epoch: 5| Step: 6
Training loss: 2.6682145595550537
Validation loss: 2.065886894861857

Epoch: 5| Step: 7
Training loss: 2.34425950050354
Validation loss: 2.0324836431011075

Epoch: 5| Step: 8
Training loss: 2.1350364685058594
Validation loss: 2.0781581094188075

Epoch: 5| Step: 9
Training loss: 2.134589672088623
Validation loss: 2.058984142477794

Epoch: 5| Step: 10
Training loss: 2.676027774810791
Validation loss: 2.109730261628346

Epoch: 148| Step: 0
Training loss: 2.2817091941833496
Validation loss: 2.0447493253215665

Epoch: 5| Step: 1
Training loss: 1.9846694469451904
Validation loss: 2.060699896145892

Epoch: 5| Step: 2
Training loss: 2.4748661518096924
Validation loss: 2.033537398102463

Epoch: 5| Step: 3
Training loss: 2.5520873069763184
Validation loss: 2.0584646424939557

Epoch: 5| Step: 4
Training loss: 2.3244996070861816
Validation loss: 2.050789504922846

Epoch: 5| Step: 5
Training loss: 2.0853617191314697
Validation loss: 2.079342144791798

Epoch: 5| Step: 6
Training loss: 2.142808198928833
Validation loss: 2.06946918272203

Epoch: 5| Step: 7
Training loss: 2.083496570587158
Validation loss: 2.042861937194742

Epoch: 5| Step: 8
Training loss: 1.927849531173706
Validation loss: 2.0506031615759737

Epoch: 5| Step: 9
Training loss: 2.6325881481170654
Validation loss: 2.0445298802468086

Epoch: 5| Step: 10
Training loss: 1.5206506252288818
Validation loss: 2.0607326876732612

Epoch: 149| Step: 0
Training loss: 2.0667006969451904
Validation loss: 2.075160704633241

Epoch: 5| Step: 1
Training loss: 2.300732135772705
Validation loss: 2.0551141846564507

Epoch: 5| Step: 2
Training loss: 2.1242289543151855
Validation loss: 2.03923693267248

Epoch: 5| Step: 3
Training loss: 2.4549434185028076
Validation loss: 2.044175046746449

Epoch: 5| Step: 4
Training loss: 1.982596755027771
Validation loss: 2.0730656962240896

Epoch: 5| Step: 5
Training loss: 2.298811674118042
Validation loss: 2.0452448552654636

Epoch: 5| Step: 6
Training loss: 2.180600643157959
Validation loss: 2.0991160126142603

Epoch: 5| Step: 7
Training loss: 1.7464927434921265
Validation loss: 2.0629270140842726

Epoch: 5| Step: 8
Training loss: 2.397388458251953
Validation loss: 2.0748893701902

Epoch: 5| Step: 9
Training loss: 1.6189082860946655
Validation loss: 2.0831072535566104

Epoch: 5| Step: 10
Training loss: 2.7222957611083984
Validation loss: 2.0820930491211596

Epoch: 150| Step: 0
Training loss: 2.377326488494873
Validation loss: 2.0833999854262157

Epoch: 5| Step: 1
Training loss: 2.201979160308838
Validation loss: 2.070618203891221

Epoch: 5| Step: 2
Training loss: 2.3065643310546875
Validation loss: 2.059167984993227

Epoch: 5| Step: 3
Training loss: 2.4094650745391846
Validation loss: 2.081102627579884

Epoch: 5| Step: 4
Training loss: 2.281055450439453
Validation loss: 2.049257222042289

Epoch: 5| Step: 5
Training loss: 2.455190658569336
Validation loss: 2.0357248885657198

Epoch: 5| Step: 6
Training loss: 2.1895713806152344
Validation loss: 2.092609852872869

Epoch: 5| Step: 7
Training loss: 1.3739665746688843
Validation loss: 2.0837299541760514

Epoch: 5| Step: 8
Training loss: 1.9174435138702393
Validation loss: 2.0270831328566357

Epoch: 5| Step: 9
Training loss: 1.8091762065887451
Validation loss: 2.0343618316035115

Epoch: 5| Step: 10
Training loss: 2.801239490509033
Validation loss: 2.0452083669682986

Epoch: 151| Step: 0
Training loss: 2.1696484088897705
Validation loss: 2.0473417928141933

Epoch: 5| Step: 1
Training loss: 2.121445417404175
Validation loss: 2.0636468933474634

Epoch: 5| Step: 2
Training loss: 2.052381992340088
Validation loss: 2.0034436025927143

Epoch: 5| Step: 3
Training loss: 1.9838289022445679
Validation loss: 2.051751373916544

Epoch: 5| Step: 4
Training loss: 2.046602725982666
Validation loss: 2.0533047145412815

Epoch: 5| Step: 5
Training loss: 2.139861822128296
Validation loss: 2.0177460652525707

Epoch: 5| Step: 6
Training loss: 2.2833094596862793
Validation loss: 2.0697706489152807

Epoch: 5| Step: 7
Training loss: 2.239809274673462
Validation loss: 2.057398555099323

Epoch: 5| Step: 8
Training loss: 1.920578956604004
Validation loss: 2.0402200965471167

Epoch: 5| Step: 9
Training loss: 2.5555825233459473
Validation loss: 2.044651572422315

Epoch: 5| Step: 10
Training loss: 2.2781691551208496
Validation loss: 2.0413902369878625

Epoch: 152| Step: 0
Training loss: 2.132204055786133
Validation loss: 2.046515328909761

Epoch: 5| Step: 1
Training loss: 2.379950761795044
Validation loss: 2.0491344851832234

Epoch: 5| Step: 2
Training loss: 1.9489787817001343
Validation loss: 2.055338375030025

Epoch: 5| Step: 3
Training loss: 2.3673179149627686
Validation loss: 2.037322308427544

Epoch: 5| Step: 4
Training loss: 1.8935520648956299
Validation loss: 2.053564016537

Epoch: 5| Step: 5
Training loss: 2.352626085281372
Validation loss: 2.0507421314075427

Epoch: 5| Step: 6
Training loss: 2.200474977493286
Validation loss: 2.048989595905427

Epoch: 5| Step: 7
Training loss: 2.4406654834747314
Validation loss: 2.0613246630596858

Epoch: 5| Step: 8
Training loss: 1.7814325094223022
Validation loss: 2.0367231369018555

Epoch: 5| Step: 9
Training loss: 2.0556225776672363
Validation loss: 2.034836998549841

Epoch: 5| Step: 10
Training loss: 2.3248143196105957
Validation loss: 2.0544467779897873

Epoch: 153| Step: 0
Training loss: 1.6772270202636719
Validation loss: 2.0175879898891655

Epoch: 5| Step: 1
Training loss: 2.1751456260681152
Validation loss: 2.05549975620803

Epoch: 5| Step: 2
Training loss: 2.9763102531433105
Validation loss: 2.060430784379282

Epoch: 5| Step: 3
Training loss: 2.859480381011963
Validation loss: 2.0645519533464984

Epoch: 5| Step: 4
Training loss: 2.1437385082244873
Validation loss: 2.010562289145685

Epoch: 5| Step: 5
Training loss: 2.3965556621551514
Validation loss: 2.036742996144038

Epoch: 5| Step: 6
Training loss: 1.8282654285430908
Validation loss: 2.0541708777027745

Epoch: 5| Step: 7
Training loss: 2.0061111450195312
Validation loss: 2.0157885461725216

Epoch: 5| Step: 8
Training loss: 1.9473707675933838
Validation loss: 2.031392556364818

Epoch: 5| Step: 9
Training loss: 1.6315038204193115
Validation loss: 2.08988421194015

Epoch: 5| Step: 10
Training loss: 2.273364305496216
Validation loss: 2.0518639433768486

Epoch: 154| Step: 0
Training loss: 2.3840103149414062
Validation loss: 2.0627368624492357

Epoch: 5| Step: 1
Training loss: 1.8084707260131836
Validation loss: 2.0469992519706808

Epoch: 5| Step: 2
Training loss: 2.098346710205078
Validation loss: 2.043521281211607

Epoch: 5| Step: 3
Training loss: 2.363114595413208
Validation loss: 2.0428757872632755

Epoch: 5| Step: 4
Training loss: 2.270601272583008
Validation loss: 2.0423442407320906

Epoch: 5| Step: 5
Training loss: 2.1791799068450928
Validation loss: 2.0304701225731963

Epoch: 5| Step: 6
Training loss: 2.1512866020202637
Validation loss: 2.0508764405404367

Epoch: 5| Step: 7
Training loss: 2.158468723297119
Validation loss: 2.0715767363066315

Epoch: 5| Step: 8
Training loss: 2.157219409942627
Validation loss: 2.0397343686831895

Epoch: 5| Step: 9
Training loss: 2.3539376258850098
Validation loss: 2.0211801234111992

Epoch: 5| Step: 10
Training loss: 1.8567324876785278
Validation loss: 2.0721892823455152

Epoch: 155| Step: 0
Training loss: 3.1012492179870605
Validation loss: 2.0971648641811904

Epoch: 5| Step: 1
Training loss: 2.0060245990753174
Validation loss: 2.053164884608279

Epoch: 5| Step: 2
Training loss: 1.523210883140564
Validation loss: 2.052464190349784

Epoch: 5| Step: 3
Training loss: 1.984419584274292
Validation loss: 2.0796554268047376

Epoch: 5| Step: 4
Training loss: 1.8982093334197998
Validation loss: 2.087303405166954

Epoch: 5| Step: 5
Training loss: 2.043423652648926
Validation loss: 2.0530988964983212

Epoch: 5| Step: 6
Training loss: 2.6627254486083984
Validation loss: 2.0503618153192664

Epoch: 5| Step: 7
Training loss: 2.402588367462158
Validation loss: 2.0354941685994468

Epoch: 5| Step: 8
Training loss: 1.9022375345230103
Validation loss: 2.0472544572686635

Epoch: 5| Step: 9
Training loss: 1.8604904413223267
Validation loss: 2.054886858950379

Epoch: 5| Step: 10
Training loss: 2.380417823791504
Validation loss: 2.0862335056386967

Epoch: 156| Step: 0
Training loss: 2.799870729446411
Validation loss: 2.038961613050071

Epoch: 5| Step: 1
Training loss: 2.187438488006592
Validation loss: 2.0625743160965624

Epoch: 5| Step: 2
Training loss: 2.51326060295105
Validation loss: 2.062414135984195

Epoch: 5| Step: 3
Training loss: 2.014413595199585
Validation loss: 2.06548031427527

Epoch: 5| Step: 4
Training loss: 1.9831287860870361
Validation loss: 2.0298112951299196

Epoch: 5| Step: 5
Training loss: 2.0711429119110107
Validation loss: 2.0811011509228776

Epoch: 5| Step: 6
Training loss: 1.376145362854004
Validation loss: 2.0855195137762252

Epoch: 5| Step: 7
Training loss: 2.236877918243408
Validation loss: 2.0940631487036265

Epoch: 5| Step: 8
Training loss: 1.6906646490097046
Validation loss: 2.076744423117689

Epoch: 5| Step: 9
Training loss: 1.9976444244384766
Validation loss: 2.1214952571417696

Epoch: 5| Step: 10
Training loss: 3.148707151412964
Validation loss: 2.077007293701172

Epoch: 157| Step: 0
Training loss: 2.1729178428649902
Validation loss: 2.115193418277207

Epoch: 5| Step: 1
Training loss: 2.301163673400879
Validation loss: 2.08338959499072

Epoch: 5| Step: 2
Training loss: 2.564148426055908
Validation loss: 2.082112801972256

Epoch: 5| Step: 3
Training loss: 2.5643935203552246
Validation loss: 2.0986989723738803

Epoch: 5| Step: 4
Training loss: 2.3413028717041016
Validation loss: 2.1064096061132287

Epoch: 5| Step: 5
Training loss: 1.7058706283569336
Validation loss: 2.1182943441534556

Epoch: 5| Step: 6
Training loss: 1.953259825706482
Validation loss: 2.0713079642224055

Epoch: 5| Step: 7
Training loss: 2.193314552307129
Validation loss: 2.107487060690439

Epoch: 5| Step: 8
Training loss: 1.9086427688598633
Validation loss: 2.0832113245482087

Epoch: 5| Step: 9
Training loss: 2.1592061519622803
Validation loss: 2.093901959798669

Epoch: 5| Step: 10
Training loss: 2.1454601287841797
Validation loss: 2.039429094201775

Epoch: 158| Step: 0
Training loss: 2.172208786010742
Validation loss: 2.067200586359988

Epoch: 5| Step: 1
Training loss: 2.407027006149292
Validation loss: 2.0722165799910024

Epoch: 5| Step: 2
Training loss: 1.887791633605957
Validation loss: 2.109973180678583

Epoch: 5| Step: 3
Training loss: 2.2903823852539062
Validation loss: 2.0846103955340642

Epoch: 5| Step: 4
Training loss: 1.7061452865600586
Validation loss: 2.068767234843264

Epoch: 5| Step: 5
Training loss: 2.033473253250122
Validation loss: 2.0596982945678053

Epoch: 5| Step: 6
Training loss: 2.173205852508545
Validation loss: 2.076501402803647

Epoch: 5| Step: 7
Training loss: 2.5860798358917236
Validation loss: 2.097823635224373

Epoch: 5| Step: 8
Training loss: 2.2781500816345215
Validation loss: 2.0737163392446374

Epoch: 5| Step: 9
Training loss: 2.561488628387451
Validation loss: 2.093421379725138

Epoch: 5| Step: 10
Training loss: 1.8022394180297852
Validation loss: 2.0762160657554545

Epoch: 159| Step: 0
Training loss: 2.1293323040008545
Validation loss: 2.0762629816609044

Epoch: 5| Step: 1
Training loss: 2.251788377761841
Validation loss: 2.0597359518851004

Epoch: 5| Step: 2
Training loss: 2.219449043273926
Validation loss: 2.0757338616155807

Epoch: 5| Step: 3
Training loss: 2.154306173324585
Validation loss: 2.088472427860383

Epoch: 5| Step: 4
Training loss: 2.3465685844421387
Validation loss: 2.077686043195827

Epoch: 5| Step: 5
Training loss: 2.0242104530334473
Validation loss: 2.0742823129059165

Epoch: 5| Step: 6
Training loss: 1.6972824335098267
Validation loss: 2.0565054467929307

Epoch: 5| Step: 7
Training loss: 2.116013526916504
Validation loss: 2.068302751869284

Epoch: 5| Step: 8
Training loss: 2.2952780723571777
Validation loss: 2.042397061983744

Epoch: 5| Step: 9
Training loss: 2.2647080421447754
Validation loss: 2.055312310495684

Epoch: 5| Step: 10
Training loss: 2.4078731536865234
Validation loss: 2.040417625058082

Epoch: 160| Step: 0
Training loss: 2.201202869415283
Validation loss: 2.0328882291752803

Epoch: 5| Step: 1
Training loss: 2.9420433044433594
Validation loss: 2.044197267101657

Epoch: 5| Step: 2
Training loss: 2.2463786602020264
Validation loss: 2.0343349056859172

Epoch: 5| Step: 3
Training loss: 2.0042338371276855
Validation loss: 2.0842508462167557

Epoch: 5| Step: 4
Training loss: 1.8380415439605713
Validation loss: 2.072324393897928

Epoch: 5| Step: 5
Training loss: 2.0328209400177
Validation loss: 2.0767329931259155

Epoch: 5| Step: 6
Training loss: 1.5458133220672607
Validation loss: 2.121299596243007

Epoch: 5| Step: 7
Training loss: 1.4198707342147827
Validation loss: 2.0738538234464583

Epoch: 5| Step: 8
Training loss: 2.8038086891174316
Validation loss: 2.0389936854762416

Epoch: 5| Step: 9
Training loss: 2.3895883560180664
Validation loss: 2.051073892142183

Epoch: 5| Step: 10
Training loss: 2.837116003036499
Validation loss: 2.017032556636359

Epoch: 161| Step: 0
Training loss: 1.710375189781189
Validation loss: 2.0747144478623585

Epoch: 5| Step: 1
Training loss: 1.7284057140350342
Validation loss: 2.0685264654057

Epoch: 5| Step: 2
Training loss: 1.9835901260375977
Validation loss: 2.0725794581956762

Epoch: 5| Step: 3
Training loss: 2.654757022857666
Validation loss: 2.097084414574408

Epoch: 5| Step: 4
Training loss: 1.6782569885253906
Validation loss: 2.0338841638257428

Epoch: 5| Step: 5
Training loss: 3.1859989166259766
Validation loss: 2.064076808191115

Epoch: 5| Step: 6
Training loss: 2.7724881172180176
Validation loss: 2.0882012690267255

Epoch: 5| Step: 7
Training loss: 2.224351167678833
Validation loss: 2.045746298246486

Epoch: 5| Step: 8
Training loss: 1.900867223739624
Validation loss: 2.051908249496132

Epoch: 5| Step: 9
Training loss: 2.035940408706665
Validation loss: 2.1340762799785984

Epoch: 5| Step: 10
Training loss: 1.9374663829803467
Validation loss: 2.0679700246421238

Epoch: 162| Step: 0
Training loss: 2.321929931640625
Validation loss: 2.05909054253691

Epoch: 5| Step: 1
Training loss: 1.3969542980194092
Validation loss: 2.056022006978271

Epoch: 5| Step: 2
Training loss: 2.419290781021118
Validation loss: 2.0425174479843466

Epoch: 5| Step: 3
Training loss: 2.462005615234375
Validation loss: 2.097305413215391

Epoch: 5| Step: 4
Training loss: 2.431434392929077
Validation loss: 2.079173759747577

Epoch: 5| Step: 5
Training loss: 1.9133094549179077
Validation loss: 2.0850327168741534

Epoch: 5| Step: 6
Training loss: 2.355867862701416
Validation loss: 2.0791503306358092

Epoch: 5| Step: 7
Training loss: 2.2975316047668457
Validation loss: 2.0946034180220736

Epoch: 5| Step: 8
Training loss: 1.6947252750396729
Validation loss: 2.062231207406649

Epoch: 5| Step: 9
Training loss: 2.0642459392547607
Validation loss: 2.0722750861157655

Epoch: 5| Step: 10
Training loss: 2.663691759109497
Validation loss: 2.063417955111432

Epoch: 163| Step: 0
Training loss: 1.9732637405395508
Validation loss: 2.060823978916291

Epoch: 5| Step: 1
Training loss: 2.4099297523498535
Validation loss: 2.0255573488050893

Epoch: 5| Step: 2
Training loss: 2.346433162689209
Validation loss: 2.044215320259012

Epoch: 5| Step: 3
Training loss: 2.3428187370300293
Validation loss: 2.016783079793376

Epoch: 5| Step: 4
Training loss: 1.5429548025131226
Validation loss: 2.07251876143999

Epoch: 5| Step: 5
Training loss: 1.8392467498779297
Validation loss: 2.0657062043425856

Epoch: 5| Step: 6
Training loss: 2.8185958862304688
Validation loss: 2.0572585880115466

Epoch: 5| Step: 7
Training loss: 2.2665915489196777
Validation loss: 2.0384031918741043

Epoch: 5| Step: 8
Training loss: 2.405454158782959
Validation loss: 2.0583208196906635

Epoch: 5| Step: 9
Training loss: 1.551788568496704
Validation loss: 2.0633628573468936

Epoch: 5| Step: 10
Training loss: 2.145768642425537
Validation loss: 2.046624632291896

Epoch: 164| Step: 0
Training loss: 2.922996759414673
Validation loss: 2.0011156425681165

Epoch: 5| Step: 1
Training loss: 1.816124677658081
Validation loss: 2.06752105938491

Epoch: 5| Step: 2
Training loss: 1.9355376958847046
Validation loss: 2.048352973435515

Epoch: 5| Step: 3
Training loss: 2.138613700866699
Validation loss: 2.04820220188428

Epoch: 5| Step: 4
Training loss: 2.038963794708252
Validation loss: 2.0077037644642655

Epoch: 5| Step: 5
Training loss: 2.3297886848449707
Validation loss: 2.0796771100772324

Epoch: 5| Step: 6
Training loss: 2.1384785175323486
Validation loss: 2.057436817435808

Epoch: 5| Step: 7
Training loss: 2.068540096282959
Validation loss: 2.0171939352507233

Epoch: 5| Step: 8
Training loss: 2.566704273223877
Validation loss: 2.0523744347274944

Epoch: 5| Step: 9
Training loss: 1.8390986919403076
Validation loss: 2.017303805197439

Epoch: 5| Step: 10
Training loss: 2.0417587757110596
Validation loss: 2.0541947169970443

Epoch: 165| Step: 0
Training loss: 2.0803894996643066
Validation loss: 2.0387518995551654

Epoch: 5| Step: 1
Training loss: 2.0682449340820312
Validation loss: 2.0250844314534175

Epoch: 5| Step: 2
Training loss: 2.1894125938415527
Validation loss: 2.0675312960019676

Epoch: 5| Step: 3
Training loss: 1.8626468181610107
Validation loss: 2.1007777939560595

Epoch: 5| Step: 4
Training loss: 1.452054738998413
Validation loss: 2.0972316752197924

Epoch: 5| Step: 5
Training loss: 2.2893028259277344
Validation loss: 2.0522165144643476

Epoch: 5| Step: 6
Training loss: 2.088273048400879
Validation loss: 2.0509281837812035

Epoch: 5| Step: 7
Training loss: 2.3053715229034424
Validation loss: 2.0640671407022784

Epoch: 5| Step: 8
Training loss: 2.2754712104797363
Validation loss: 2.0913669434926843

Epoch: 5| Step: 9
Training loss: 2.7946815490722656
Validation loss: 2.0845443715331373

Epoch: 5| Step: 10
Training loss: 2.2385308742523193
Validation loss: 2.0841615276951946

Epoch: 166| Step: 0
Training loss: 1.8753494024276733
Validation loss: 2.085828547836632

Epoch: 5| Step: 1
Training loss: 2.2018065452575684
Validation loss: 2.0650573212613343

Epoch: 5| Step: 2
Training loss: 2.161161184310913
Validation loss: 2.104866438014533

Epoch: 5| Step: 3
Training loss: 1.7912324666976929
Validation loss: 2.0572317607941164

Epoch: 5| Step: 4
Training loss: 2.7203667163848877
Validation loss: 2.0560394012799827

Epoch: 5| Step: 5
Training loss: 1.8107389211654663
Validation loss: 2.072496014256631

Epoch: 5| Step: 6
Training loss: 2.0701916217803955
Validation loss: 2.082687526620844

Epoch: 5| Step: 7
Training loss: 2.036825656890869
Validation loss: 2.084228091342475

Epoch: 5| Step: 8
Training loss: 2.45051646232605
Validation loss: 2.0776143484218146

Epoch: 5| Step: 9
Training loss: 2.2476775646209717
Validation loss: 2.104064364587107

Epoch: 5| Step: 10
Training loss: 2.302685022354126
Validation loss: 2.059109772405317

Epoch: 167| Step: 0
Training loss: 2.2783029079437256
Validation loss: 2.1154293091066423

Epoch: 5| Step: 1
Training loss: 1.2321088314056396
Validation loss: 2.0740446762372087

Epoch: 5| Step: 2
Training loss: 2.147087574005127
Validation loss: 2.117483728675432

Epoch: 5| Step: 3
Training loss: 1.3666718006134033
Validation loss: 2.089249377609581

Epoch: 5| Step: 4
Training loss: 2.816556692123413
Validation loss: 2.0963928289310907

Epoch: 5| Step: 5
Training loss: 2.1446900367736816
Validation loss: 2.055823867039014

Epoch: 5| Step: 6
Training loss: 2.515357494354248
Validation loss: 2.0642472736297117

Epoch: 5| Step: 7
Training loss: 2.634722948074341
Validation loss: 2.0711248587536555

Epoch: 5| Step: 8
Training loss: 2.4185943603515625
Validation loss: 2.057435930416148

Epoch: 5| Step: 9
Training loss: 2.1847939491271973
Validation loss: 2.080285652991264

Epoch: 5| Step: 10
Training loss: 2.1208810806274414
Validation loss: 2.104752112460393

Epoch: 168| Step: 0
Training loss: 2.7560839653015137
Validation loss: 2.0668843920512865

Epoch: 5| Step: 1
Training loss: 1.9289413690567017
Validation loss: 2.0370133256399505

Epoch: 5| Step: 2
Training loss: 2.4147965908050537
Validation loss: 2.0711576836083525

Epoch: 5| Step: 3
Training loss: 2.042313814163208
Validation loss: 2.0549889021022345

Epoch: 5| Step: 4
Training loss: 2.072455883026123
Validation loss: 2.0742588594395626

Epoch: 5| Step: 5
Training loss: 1.991296410560608
Validation loss: 2.0639631312380553

Epoch: 5| Step: 6
Training loss: 2.5835561752319336
Validation loss: 2.0609709883248932

Epoch: 5| Step: 7
Training loss: 2.089839220046997
Validation loss: 2.063593133803337

Epoch: 5| Step: 8
Training loss: 1.8585971593856812
Validation loss: 2.042211769729532

Epoch: 5| Step: 9
Training loss: 1.690433144569397
Validation loss: 2.0481429279491468

Epoch: 5| Step: 10
Training loss: 2.3029792308807373
Validation loss: 2.0547114726035827

Epoch: 169| Step: 0
Training loss: 1.296194314956665
Validation loss: 2.045067428260721

Epoch: 5| Step: 1
Training loss: 2.318269729614258
Validation loss: 2.0527314652678785

Epoch: 5| Step: 2
Training loss: 1.79049551486969
Validation loss: 2.0491776184369157

Epoch: 5| Step: 3
Training loss: 2.7333016395568848
Validation loss: 2.0248048715693976

Epoch: 5| Step: 4
Training loss: 2.421745777130127
Validation loss: 2.054370831417781

Epoch: 5| Step: 5
Training loss: 2.2449259757995605
Validation loss: 2.022175265896705

Epoch: 5| Step: 6
Training loss: 2.431504726409912
Validation loss: 2.0499322209306943

Epoch: 5| Step: 7
Training loss: 1.7195689678192139
Validation loss: 2.0249908329338155

Epoch: 5| Step: 8
Training loss: 2.0491116046905518
Validation loss: 2.0556925804384294

Epoch: 5| Step: 9
Training loss: 2.9279286861419678
Validation loss: 2.0337551947562926

Epoch: 5| Step: 10
Training loss: 1.995784044265747
Validation loss: 2.0513588100351314

Epoch: 170| Step: 0
Training loss: 2.5957202911376953
Validation loss: 2.0408739761639665

Epoch: 5| Step: 1
Training loss: 2.2051925659179688
Validation loss: 2.068075790200182

Epoch: 5| Step: 2
Training loss: 2.283721685409546
Validation loss: 2.0255224192014305

Epoch: 5| Step: 3
Training loss: 1.8816688060760498
Validation loss: 2.105980602643823

Epoch: 5| Step: 4
Training loss: 2.1550612449645996
Validation loss: 2.0947452745129986

Epoch: 5| Step: 5
Training loss: 1.5982431173324585
Validation loss: 2.040318032746674

Epoch: 5| Step: 6
Training loss: 2.417356014251709
Validation loss: 2.0657769351877193

Epoch: 5| Step: 7
Training loss: 2.6322171688079834
Validation loss: 2.0173812245809906

Epoch: 5| Step: 8
Training loss: 2.2976670265197754
Validation loss: 2.0538071868240193

Epoch: 5| Step: 9
Training loss: 1.9608147144317627
Validation loss: 2.096505085627238

Epoch: 5| Step: 10
Training loss: 1.6755378246307373
Validation loss: 2.068629377631731

Epoch: 171| Step: 0
Training loss: 2.2628767490386963
Validation loss: 2.0648686296196392

Epoch: 5| Step: 1
Training loss: 2.3489856719970703
Validation loss: 2.0493519793274584

Epoch: 5| Step: 2
Training loss: 1.9433224201202393
Validation loss: 2.075418342826187

Epoch: 5| Step: 3
Training loss: 1.8821369409561157
Validation loss: 2.071497953066262

Epoch: 5| Step: 4
Training loss: 1.9516175985336304
Validation loss: 2.0418098434325187

Epoch: 5| Step: 5
Training loss: 1.3606452941894531
Validation loss: 2.060137342381221

Epoch: 5| Step: 6
Training loss: 2.3022265434265137
Validation loss: 2.052745944710188

Epoch: 5| Step: 7
Training loss: 2.160618543624878
Validation loss: 2.066256600041543

Epoch: 5| Step: 8
Training loss: 1.9023845195770264
Validation loss: 2.0579609460728143

Epoch: 5| Step: 9
Training loss: 2.6340136528015137
Validation loss: 2.0751775605704195

Epoch: 5| Step: 10
Training loss: 2.9580109119415283
Validation loss: 2.066341843656314

Epoch: 172| Step: 0
Training loss: 2.3446061611175537
Validation loss: 2.082833618246099

Epoch: 5| Step: 1
Training loss: 2.061763286590576
Validation loss: 2.1341665560199368

Epoch: 5| Step: 2
Training loss: 2.211127519607544
Validation loss: 2.088184779690158

Epoch: 5| Step: 3
Training loss: 1.7103807926177979
Validation loss: 2.050172480203772

Epoch: 5| Step: 4
Training loss: 2.365358829498291
Validation loss: 2.041748184029774

Epoch: 5| Step: 5
Training loss: 2.2382287979125977
Validation loss: 2.1259376618169967

Epoch: 5| Step: 6
Training loss: 1.8819477558135986
Validation loss: 2.1065893019399335

Epoch: 5| Step: 7
Training loss: 2.4875986576080322
Validation loss: 2.0762262626360823

Epoch: 5| Step: 8
Training loss: 2.120950698852539
Validation loss: 2.057000390944942

Epoch: 5| Step: 9
Training loss: 2.026327610015869
Validation loss: 2.0740693717874508

Epoch: 5| Step: 10
Training loss: 2.2394027709960938
Validation loss: 2.0983993750746532

Epoch: 173| Step: 0
Training loss: 1.962224006652832
Validation loss: 2.0702276358040432

Epoch: 5| Step: 1
Training loss: 2.396350622177124
Validation loss: 2.060299757988222

Epoch: 5| Step: 2
Training loss: 2.1119790077209473
Validation loss: 2.062141969639768

Epoch: 5| Step: 3
Training loss: 1.776157021522522
Validation loss: 2.0592388799113612

Epoch: 5| Step: 4
Training loss: 2.437565326690674
Validation loss: 2.102457833546464

Epoch: 5| Step: 5
Training loss: 2.5041747093200684
Validation loss: 2.0611776895420526

Epoch: 5| Step: 6
Training loss: 2.7212815284729004
Validation loss: 2.0802169794677408

Epoch: 5| Step: 7
Training loss: 2.2642407417297363
Validation loss: 2.0545179997721026

Epoch: 5| Step: 8
Training loss: 2.1590068340301514
Validation loss: 2.0664960889406103

Epoch: 5| Step: 9
Training loss: 1.5230283737182617
Validation loss: 2.0534853653241227

Epoch: 5| Step: 10
Training loss: 1.7748055458068848
Validation loss: 2.061540442128335

Epoch: 174| Step: 0
Training loss: 1.8471447229385376
Validation loss: 2.0188202499061503

Epoch: 5| Step: 1
Training loss: 2.4186084270477295
Validation loss: 2.049305456940846

Epoch: 5| Step: 2
Training loss: 1.8982317447662354
Validation loss: 2.0717778180235173

Epoch: 5| Step: 3
Training loss: 1.9864978790283203
Validation loss: 2.084975757906514

Epoch: 5| Step: 4
Training loss: 2.528576374053955
Validation loss: 2.080043885015672

Epoch: 5| Step: 5
Training loss: 2.1752238273620605
Validation loss: 2.0456815611931587

Epoch: 5| Step: 6
Training loss: 2.4283204078674316
Validation loss: 2.0703378672240884

Epoch: 5| Step: 7
Training loss: 2.5054802894592285
Validation loss: 2.070593080212993

Epoch: 5| Step: 8
Training loss: 1.829118013381958
Validation loss: 2.0718722369081233

Epoch: 5| Step: 9
Training loss: 1.9502451419830322
Validation loss: 2.0589118362754903

Epoch: 5| Step: 10
Training loss: 1.8481671810150146
Validation loss: 2.0729619123602427

Epoch: 175| Step: 0
Training loss: 2.002622127532959
Validation loss: 2.0874230964209444

Epoch: 5| Step: 1
Training loss: 1.8961522579193115
Validation loss: 2.114540457725525

Epoch: 5| Step: 2
Training loss: 1.9587339162826538
Validation loss: 2.1000482331040087

Epoch: 5| Step: 3
Training loss: 2.115973949432373
Validation loss: 2.0914320099738335

Epoch: 5| Step: 4
Training loss: 1.844612717628479
Validation loss: 2.019611249687851

Epoch: 5| Step: 5
Training loss: 2.6663432121276855
Validation loss: 2.053573105924873

Epoch: 5| Step: 6
Training loss: 2.1600966453552246
Validation loss: 2.0784207620928363

Epoch: 5| Step: 7
Training loss: 2.0715584754943848
Validation loss: 2.036132551008655

Epoch: 5| Step: 8
Training loss: 2.870340347290039
Validation loss: 2.0702242235983572

Epoch: 5| Step: 9
Training loss: 1.9524517059326172
Validation loss: 2.0661595970071773

Epoch: 5| Step: 10
Training loss: 2.125247001647949
Validation loss: 2.0694615238456318

Epoch: 176| Step: 0
Training loss: 2.140653133392334
Validation loss: 2.0492805793721187

Epoch: 5| Step: 1
Training loss: 2.4891793727874756
Validation loss: 2.084456446350262

Epoch: 5| Step: 2
Training loss: 1.8555580377578735
Validation loss: 2.0677702414092196

Epoch: 5| Step: 3
Training loss: 1.6909059286117554
Validation loss: 2.0460410220648653

Epoch: 5| Step: 4
Training loss: 2.287057399749756
Validation loss: 2.078827509316065

Epoch: 5| Step: 5
Training loss: 2.342970371246338
Validation loss: 2.0569432525224585

Epoch: 5| Step: 6
Training loss: 1.840803861618042
Validation loss: 2.031685447180143

Epoch: 5| Step: 7
Training loss: 2.1646409034729004
Validation loss: 2.0597075928923902

Epoch: 5| Step: 8
Training loss: 2.5070300102233887
Validation loss: 2.0601167704469416

Epoch: 5| Step: 9
Training loss: 2.1935698986053467
Validation loss: 2.0573063332547425

Epoch: 5| Step: 10
Training loss: 2.1244845390319824
Validation loss: 2.0391037297505203

Epoch: 177| Step: 0
Training loss: 1.884958267211914
Validation loss: 2.066019883719824

Epoch: 5| Step: 1
Training loss: 2.2183127403259277
Validation loss: 2.058850888283022

Epoch: 5| Step: 2
Training loss: 2.1787030696868896
Validation loss: 2.046619111491788

Epoch: 5| Step: 3
Training loss: 2.2529664039611816
Validation loss: 2.060195517796342

Epoch: 5| Step: 4
Training loss: 1.7988237142562866
Validation loss: 2.0710540151083343

Epoch: 5| Step: 5
Training loss: 2.4697864055633545
Validation loss: 2.0797309516578593

Epoch: 5| Step: 6
Training loss: 2.087423801422119
Validation loss: 2.042445707064803

Epoch: 5| Step: 7
Training loss: 2.633716583251953
Validation loss: 2.050023137882192

Epoch: 5| Step: 8
Training loss: 1.9555785655975342
Validation loss: 2.0592352459507604

Epoch: 5| Step: 9
Training loss: 2.191605806350708
Validation loss: 2.0991300716195056

Epoch: 5| Step: 10
Training loss: 1.7794055938720703
Validation loss: 2.0926506544954036

Epoch: 178| Step: 0
Training loss: 2.070056438446045
Validation loss: 2.073433728628261

Epoch: 5| Step: 1
Training loss: 2.2784676551818848
Validation loss: 2.0846888557557137

Epoch: 5| Step: 2
Training loss: 2.088155746459961
Validation loss: 2.071581229086845

Epoch: 5| Step: 3
Training loss: 2.5936005115509033
Validation loss: 2.0892597552268737

Epoch: 5| Step: 4
Training loss: 2.2474212646484375
Validation loss: 2.0960532183288247

Epoch: 5| Step: 5
Training loss: 2.418898344039917
Validation loss: 2.1097633595107705

Epoch: 5| Step: 6
Training loss: 2.2459235191345215
Validation loss: 2.092091593691098

Epoch: 5| Step: 7
Training loss: 2.080376625061035
Validation loss: 2.0702806544560257

Epoch: 5| Step: 8
Training loss: 1.6713953018188477
Validation loss: 2.0902776436139177

Epoch: 5| Step: 9
Training loss: 2.135655164718628
Validation loss: 2.0831571035487677

Epoch: 5| Step: 10
Training loss: 1.6910916566848755
Validation loss: 2.09195254951395

Epoch: 179| Step: 0
Training loss: 1.9899171590805054
Validation loss: 2.124565860276581

Epoch: 5| Step: 1
Training loss: 2.743872880935669
Validation loss: 2.0451611959806053

Epoch: 5| Step: 2
Training loss: 1.6446586847305298
Validation loss: 2.0568563515140164

Epoch: 5| Step: 3
Training loss: 1.7528293132781982
Validation loss: 2.061439375723562

Epoch: 5| Step: 4
Training loss: 2.3797409534454346
Validation loss: 2.083492389289282

Epoch: 5| Step: 5
Training loss: 2.4207451343536377
Validation loss: 2.064684590985698

Epoch: 5| Step: 6
Training loss: 2.3509750366210938
Validation loss: 2.0707595399630967

Epoch: 5| Step: 7
Training loss: 1.5979697704315186
Validation loss: 2.044088994303057

Epoch: 5| Step: 8
Training loss: 2.8932125568389893
Validation loss: 2.0769285848063808

Epoch: 5| Step: 9
Training loss: 1.6583563089370728
Validation loss: 2.0458485259804675

Epoch: 5| Step: 10
Training loss: 2.076991081237793
Validation loss: 2.084424857170351

Epoch: 180| Step: 0
Training loss: 2.3422460556030273
Validation loss: 2.0633993430804183

Epoch: 5| Step: 1
Training loss: 2.4816834926605225
Validation loss: 2.081091393706619

Epoch: 5| Step: 2
Training loss: 2.118943929672241
Validation loss: 2.066136811369209

Epoch: 5| Step: 3
Training loss: 1.2767444849014282
Validation loss: 2.045365018229331

Epoch: 5| Step: 4
Training loss: 1.9981677532196045
Validation loss: 2.0613210675536946

Epoch: 5| Step: 5
Training loss: 2.5653343200683594
Validation loss: 2.090680665867303

Epoch: 5| Step: 6
Training loss: 1.1967132091522217
Validation loss: 2.0821943847081994

Epoch: 5| Step: 7
Training loss: 2.046647310256958
Validation loss: 2.0729731180334605

Epoch: 5| Step: 8
Training loss: 2.5308234691619873
Validation loss: 2.074004715488803

Epoch: 5| Step: 9
Training loss: 2.3025288581848145
Validation loss: 2.08319103845986

Epoch: 5| Step: 10
Training loss: 2.9039671421051025
Validation loss: 2.0408736608361684

Epoch: 181| Step: 0
Training loss: 1.4876952171325684
Validation loss: 2.068107920308267

Epoch: 5| Step: 1
Training loss: 2.4898173809051514
Validation loss: 2.057126655373522

Epoch: 5| Step: 2
Training loss: 1.4830131530761719
Validation loss: 2.064924740022229

Epoch: 5| Step: 3
Training loss: 2.0406200885772705
Validation loss: 2.077100546129288

Epoch: 5| Step: 4
Training loss: 2.3016934394836426
Validation loss: 2.058795393154185

Epoch: 5| Step: 5
Training loss: 3.001847982406616
Validation loss: 2.077863989337798

Epoch: 5| Step: 6
Training loss: 2.3397486209869385
Validation loss: 2.0617070326241116

Epoch: 5| Step: 7
Training loss: 2.234605312347412
Validation loss: 2.0195894164423787

Epoch: 5| Step: 8
Training loss: 2.416900157928467
Validation loss: 2.0301241592694352

Epoch: 5| Step: 9
Training loss: 1.7891628742218018
Validation loss: 2.064698170590144

Epoch: 5| Step: 10
Training loss: 1.6763122081756592
Validation loss: 2.0766717362147507

Epoch: 182| Step: 0
Training loss: 1.8452352285385132
Validation loss: 2.089994981724729

Epoch: 5| Step: 1
Training loss: 1.7628806829452515
Validation loss: 2.0575063536244054

Epoch: 5| Step: 2
Training loss: 2.0732433795928955
Validation loss: 2.084729726596545

Epoch: 5| Step: 3
Training loss: 2.470338821411133
Validation loss: 2.0649123076469666

Epoch: 5| Step: 4
Training loss: 1.5635977983474731
Validation loss: 2.037309838879493

Epoch: 5| Step: 5
Training loss: 2.2205419540405273
Validation loss: 2.048165193168066

Epoch: 5| Step: 6
Training loss: 2.3838114738464355
Validation loss: 2.080721770563433

Epoch: 5| Step: 7
Training loss: 2.473008394241333
Validation loss: 2.0607859870438934

Epoch: 5| Step: 8
Training loss: 2.448251247406006
Validation loss: 2.0291126261475267

Epoch: 5| Step: 9
Training loss: 2.0437283515930176
Validation loss: 2.0879302652933265

Epoch: 5| Step: 10
Training loss: 2.4191372394561768
Validation loss: 2.0464547423906225

Epoch: 183| Step: 0
Training loss: 1.7349754571914673
Validation loss: 2.0504177321669874

Epoch: 5| Step: 1
Training loss: 2.103841781616211
Validation loss: 2.0841563452956495

Epoch: 5| Step: 2
Training loss: 2.405661106109619
Validation loss: 2.0547842594885055

Epoch: 5| Step: 3
Training loss: 1.9992730617523193
Validation loss: 2.060979796994117

Epoch: 5| Step: 4
Training loss: 2.456080198287964
Validation loss: 2.060091846732683

Epoch: 5| Step: 5
Training loss: 2.3896241188049316
Validation loss: 2.0899459956794657

Epoch: 5| Step: 6
Training loss: 1.8122600317001343
Validation loss: 2.1235978193180536

Epoch: 5| Step: 7
Training loss: 2.0237860679626465
Validation loss: 2.0496532417112783

Epoch: 5| Step: 8
Training loss: 2.32783842086792
Validation loss: 2.0929754728912027

Epoch: 5| Step: 9
Training loss: 1.5644338130950928
Validation loss: 2.04859519902096

Epoch: 5| Step: 10
Training loss: 2.8173131942749023
Validation loss: 2.0974051285815496

Epoch: 184| Step: 0
Training loss: 2.2592105865478516
Validation loss: 2.08482176257718

Epoch: 5| Step: 1
Training loss: 1.8284423351287842
Validation loss: 2.0755971913696616

Epoch: 5| Step: 2
Training loss: 2.2343249320983887
Validation loss: 2.0447186039340113

Epoch: 5| Step: 3
Training loss: 1.303127408027649
Validation loss: 2.0585854168861144

Epoch: 5| Step: 4
Training loss: 2.5872137546539307
Validation loss: 2.069166075798773

Epoch: 5| Step: 5
Training loss: 2.3459858894348145
Validation loss: 2.06107231109373

Epoch: 5| Step: 6
Training loss: 2.1151325702667236
Validation loss: 2.0732469815079884

Epoch: 5| Step: 7
Training loss: 2.047273635864258
Validation loss: 2.0649590133338847

Epoch: 5| Step: 8
Training loss: 1.7254040241241455
Validation loss: 2.051815399559595

Epoch: 5| Step: 9
Training loss: 2.000027656555176
Validation loss: 2.070614976267661

Epoch: 5| Step: 10
Training loss: 3.071558952331543
Validation loss: 2.0585422772233204

Epoch: 185| Step: 0
Training loss: 1.5164844989776611
Validation loss: 2.07833126155279

Epoch: 5| Step: 1
Training loss: 2.376537561416626
Validation loss: 2.0585709284710627

Epoch: 5| Step: 2
Training loss: 2.1574227809906006
Validation loss: 2.0724865390408422

Epoch: 5| Step: 3
Training loss: 2.407339334487915
Validation loss: 2.083423558101859

Epoch: 5| Step: 4
Training loss: 1.872995376586914
Validation loss: 2.098864404104089

Epoch: 5| Step: 5
Training loss: 1.3839819431304932
Validation loss: 2.067432811183314

Epoch: 5| Step: 6
Training loss: 2.8379247188568115
Validation loss: 2.1039917058842157

Epoch: 5| Step: 7
Training loss: 1.8953173160552979
Validation loss: 2.071897183695147

Epoch: 5| Step: 8
Training loss: 2.5677826404571533
Validation loss: 2.086934761334491

Epoch: 5| Step: 9
Training loss: 2.171628952026367
Validation loss: 2.106854020908315

Epoch: 5| Step: 10
Training loss: 2.0748348236083984
Validation loss: 2.0875351582804034

Epoch: 186| Step: 0
Training loss: 2.3943350315093994
Validation loss: 2.0883099827715146

Epoch: 5| Step: 1
Training loss: 1.755922555923462
Validation loss: 2.0740999047474196

Epoch: 5| Step: 2
Training loss: 2.2214736938476562
Validation loss: 2.0946406933569137

Epoch: 5| Step: 3
Training loss: 2.029153823852539
Validation loss: 2.1246851272480463

Epoch: 5| Step: 4
Training loss: 1.4869502782821655
Validation loss: 2.110746314448695

Epoch: 5| Step: 5
Training loss: 2.034071683883667
Validation loss: 2.0752281924729705

Epoch: 5| Step: 6
Training loss: 1.8643367290496826
Validation loss: 2.0667393592096146

Epoch: 5| Step: 7
Training loss: 2.8744778633117676
Validation loss: 2.062854064408169

Epoch: 5| Step: 8
Training loss: 2.0731875896453857
Validation loss: 2.0957093751558693

Epoch: 5| Step: 9
Training loss: 2.244483232498169
Validation loss: 2.0936476005020963

Epoch: 5| Step: 10
Training loss: 2.477566957473755
Validation loss: 2.124889583997829

Epoch: 187| Step: 0
Training loss: 2.278440237045288
Validation loss: 2.115260539516326

Epoch: 5| Step: 1
Training loss: 2.8444671630859375
Validation loss: 2.083778755639189

Epoch: 5| Step: 2
Training loss: 1.630873441696167
Validation loss: 2.088850954527496

Epoch: 5| Step: 3
Training loss: 1.9201734066009521
Validation loss: 2.0482682053760817

Epoch: 5| Step: 4
Training loss: 1.9776127338409424
Validation loss: 2.066019997801832

Epoch: 5| Step: 5
Training loss: 2.591360569000244
Validation loss: 2.0790733034892748

Epoch: 5| Step: 6
Training loss: 2.3497252464294434
Validation loss: 2.085053538763395

Epoch: 5| Step: 7
Training loss: 1.8842567205429077
Validation loss: 2.046011858088996

Epoch: 5| Step: 8
Training loss: 2.438462734222412
Validation loss: 2.0521103079601

Epoch: 5| Step: 9
Training loss: 2.048001527786255
Validation loss: 2.0469573569554154

Epoch: 5| Step: 10
Training loss: 1.6589949131011963
Validation loss: 2.081965523381387

Epoch: 188| Step: 0
Training loss: 2.2238428592681885
Validation loss: 2.080750109047018

Epoch: 5| Step: 1
Training loss: 1.3850476741790771
Validation loss: 2.049921397239931

Epoch: 5| Step: 2
Training loss: 2.8192107677459717
Validation loss: 2.047643247471061

Epoch: 5| Step: 3
Training loss: 1.4944584369659424
Validation loss: 2.0498363946073797

Epoch: 5| Step: 4
Training loss: 2.0686206817626953
Validation loss: 2.0498758093003304

Epoch: 5| Step: 5
Training loss: 2.2565009593963623
Validation loss: 2.058048845619284

Epoch: 5| Step: 6
Training loss: 1.8399648666381836
Validation loss: 2.0518125718639744

Epoch: 5| Step: 7
Training loss: 2.818321704864502
Validation loss: 2.0645717728522515

Epoch: 5| Step: 8
Training loss: 2.1717658042907715
Validation loss: 2.0057316031507266

Epoch: 5| Step: 9
Training loss: 1.9944229125976562
Validation loss: 2.058295724212482

Epoch: 5| Step: 10
Training loss: 2.3687117099761963
Validation loss: 2.051027949138354

Epoch: 189| Step: 0
Training loss: 1.8476766347885132
Validation loss: 2.0653565237599034

Epoch: 5| Step: 1
Training loss: 2.6143598556518555
Validation loss: 2.0786143323426605

Epoch: 5| Step: 2
Training loss: 1.6596357822418213
Validation loss: 2.082752614892939

Epoch: 5| Step: 3
Training loss: 1.9416860342025757
Validation loss: 2.0713118084015383

Epoch: 5| Step: 4
Training loss: 2.068347930908203
Validation loss: 2.0551404786366287

Epoch: 5| Step: 5
Training loss: 2.4093708992004395
Validation loss: 2.0773023533564743

Epoch: 5| Step: 6
Training loss: 2.3756585121154785
Validation loss: 2.0641752417369554

Epoch: 5| Step: 7
Training loss: 1.7018039226531982
Validation loss: 2.0365218834210466

Epoch: 5| Step: 8
Training loss: 2.4346835613250732
Validation loss: 2.047189812506399

Epoch: 5| Step: 9
Training loss: 2.35089373588562
Validation loss: 2.0626341348053305

Epoch: 5| Step: 10
Training loss: 2.0286715030670166
Validation loss: 2.03820353041413

Epoch: 190| Step: 0
Training loss: 2.0505213737487793
Validation loss: 2.076326726585306

Epoch: 5| Step: 1
Training loss: 2.018415927886963
Validation loss: 2.0212011798735587

Epoch: 5| Step: 2
Training loss: 2.3522276878356934
Validation loss: 2.0848852165283693

Epoch: 5| Step: 3
Training loss: 2.2557132244110107
Validation loss: 2.1153837301397838

Epoch: 5| Step: 4
Training loss: 2.0591344833374023
Validation loss: 2.0664574766671784

Epoch: 5| Step: 5
Training loss: 2.2949557304382324
Validation loss: 2.1160550066219863

Epoch: 5| Step: 6
Training loss: 2.1993355751037598
Validation loss: 2.115680279270295

Epoch: 5| Step: 7
Training loss: 2.311593532562256
Validation loss: 2.0559260614456667

Epoch: 5| Step: 8
Training loss: 1.8145990371704102
Validation loss: 2.069477951654824

Epoch: 5| Step: 9
Training loss: 2.04463529586792
Validation loss: 2.1028016613375757

Epoch: 5| Step: 10
Training loss: 1.8336596488952637
Validation loss: 2.097226560756724

Epoch: 191| Step: 0
Training loss: 1.9755767583847046
Validation loss: 2.113752941931448

Epoch: 5| Step: 1
Training loss: 2.6243367195129395
Validation loss: 2.06019546908717

Epoch: 5| Step: 2
Training loss: 2.120633602142334
Validation loss: 2.0732099804826962

Epoch: 5| Step: 3
Training loss: 2.3525125980377197
Validation loss: 2.0714990451771724

Epoch: 5| Step: 4
Training loss: 2.1110310554504395
Validation loss: 2.0511038867376183

Epoch: 5| Step: 5
Training loss: 1.3725974559783936
Validation loss: 2.0641599778206117

Epoch: 5| Step: 6
Training loss: 1.937447190284729
Validation loss: 2.0519122231391167

Epoch: 5| Step: 7
Training loss: 2.289935350418091
Validation loss: 2.074265269822972

Epoch: 5| Step: 8
Training loss: 2.943086624145508
Validation loss: 2.0498316698176886

Epoch: 5| Step: 9
Training loss: 2.036310911178589
Validation loss: 2.0479931023813065

Epoch: 5| Step: 10
Training loss: 1.6459777355194092
Validation loss: 2.086424135392712

Epoch: 192| Step: 0
Training loss: 1.5712764263153076
Validation loss: 2.0740806236062

Epoch: 5| Step: 1
Training loss: 2.6299731731414795
Validation loss: 2.0296138166099467

Epoch: 5| Step: 2
Training loss: 2.38801646232605
Validation loss: 2.0234496683202763

Epoch: 5| Step: 3
Training loss: 2.5205740928649902
Validation loss: 2.0712059620888

Epoch: 5| Step: 4
Training loss: 1.899881362915039
Validation loss: 2.1405288993671374

Epoch: 5| Step: 5
Training loss: 1.9853999614715576
Validation loss: 2.036097703441497

Epoch: 5| Step: 6
Training loss: 1.5590909719467163
Validation loss: 2.0305895984813733

Epoch: 5| Step: 7
Training loss: 1.6855173110961914
Validation loss: 2.056081438577303

Epoch: 5| Step: 8
Training loss: 1.838769555091858
Validation loss: 2.093423028146067

Epoch: 5| Step: 9
Training loss: 2.2109391689300537
Validation loss: 2.0182836824847805

Epoch: 5| Step: 10
Training loss: 3.0812270641326904
Validation loss: 2.0763746307742212

Epoch: 193| Step: 0
Training loss: 2.3995132446289062
Validation loss: 2.029212826041765

Epoch: 5| Step: 1
Training loss: 2.2358295917510986
Validation loss: 2.0275951059915687

Epoch: 5| Step: 2
Training loss: 1.9336369037628174
Validation loss: 2.0529920183202273

Epoch: 5| Step: 3
Training loss: 1.5245907306671143
Validation loss: 2.0532222922130297

Epoch: 5| Step: 4
Training loss: 1.806051254272461
Validation loss: 2.071019918687882

Epoch: 5| Step: 5
Training loss: 2.2595512866973877
Validation loss: 2.0909374990770893

Epoch: 5| Step: 6
Training loss: 2.3975391387939453
Validation loss: 2.108995135112475

Epoch: 5| Step: 7
Training loss: 2.1885619163513184
Validation loss: 2.022641521628185

Epoch: 5| Step: 8
Training loss: 2.536437749862671
Validation loss: 2.022455343636133

Epoch: 5| Step: 9
Training loss: 2.3953311443328857
Validation loss: 2.0410414139429727

Epoch: 5| Step: 10
Training loss: 1.5967450141906738
Validation loss: 2.040293191068916

Epoch: 194| Step: 0
Training loss: 1.8670727014541626
Validation loss: 2.047592609159408

Epoch: 5| Step: 1
Training loss: 1.7097352743148804
Validation loss: 2.0945329640501287

Epoch: 5| Step: 2
Training loss: 1.6364428997039795
Validation loss: 2.0317620436350503

Epoch: 5| Step: 3
Training loss: 3.0187275409698486
Validation loss: 2.063312865072681

Epoch: 5| Step: 4
Training loss: 1.9672191143035889
Validation loss: 2.0624092240487375

Epoch: 5| Step: 5
Training loss: 2.5241916179656982
Validation loss: 2.0972898134621243

Epoch: 5| Step: 6
Training loss: 2.4651293754577637
Validation loss: 2.082376244247601

Epoch: 5| Step: 7
Training loss: 2.2335753440856934
Validation loss: 2.061751578443794

Epoch: 5| Step: 8
Training loss: 2.016843318939209
Validation loss: 2.094256603589622

Epoch: 5| Step: 9
Training loss: 1.6508519649505615
Validation loss: 2.025899585857186

Epoch: 5| Step: 10
Training loss: 2.245252847671509
Validation loss: 2.0698176891573015

Epoch: 195| Step: 0
Training loss: 2.9396889209747314
Validation loss: 2.07452888898952

Epoch: 5| Step: 1
Training loss: 2.048260450363159
Validation loss: 2.051561504281977

Epoch: 5| Step: 2
Training loss: 1.7918487787246704
Validation loss: 2.030568415118802

Epoch: 5| Step: 3
Training loss: 1.783515214920044
Validation loss: 2.0477107968381656

Epoch: 5| Step: 4
Training loss: 2.162604808807373
Validation loss: 2.0597861402778217

Epoch: 5| Step: 5
Training loss: 1.718435525894165
Validation loss: 2.052226229380536

Epoch: 5| Step: 6
Training loss: 1.7739346027374268
Validation loss: 2.0996684797348513

Epoch: 5| Step: 7
Training loss: 1.9340898990631104
Validation loss: 2.055441935857137

Epoch: 5| Step: 8
Training loss: 1.906485915184021
Validation loss: 2.075218421156688

Epoch: 5| Step: 9
Training loss: 2.7321317195892334
Validation loss: 2.0799693599823983

Epoch: 5| Step: 10
Training loss: 2.3726038932800293
Validation loss: 2.0810779140841578

Epoch: 196| Step: 0
Training loss: 2.4918179512023926
Validation loss: 2.0709334675983717

Epoch: 5| Step: 1
Training loss: 2.2655580043792725
Validation loss: 2.0793960248270342

Epoch: 5| Step: 2
Training loss: 1.7372945547103882
Validation loss: 2.0781988379775838

Epoch: 5| Step: 3
Training loss: 1.9281498193740845
Validation loss: 2.0724295339276715

Epoch: 5| Step: 4
Training loss: 2.030122756958008
Validation loss: 2.0990532418733

Epoch: 5| Step: 5
Training loss: 2.3534820079803467
Validation loss: 2.081738878321904

Epoch: 5| Step: 6
Training loss: 2.676708698272705
Validation loss: 2.1114014246130504

Epoch: 5| Step: 7
Training loss: 2.3917877674102783
Validation loss: 2.083574975690534

Epoch: 5| Step: 8
Training loss: 1.6624892950057983
Validation loss: 2.0619250215509886

Epoch: 5| Step: 9
Training loss: 1.957638144493103
Validation loss: 2.1104193041401524

Epoch: 5| Step: 10
Training loss: 2.0144851207733154
Validation loss: 2.156399337194299

Epoch: 197| Step: 0
Training loss: 2.462054967880249
Validation loss: 2.087975566105176

Epoch: 5| Step: 1
Training loss: 2.6975553035736084
Validation loss: 2.10450618625969

Epoch: 5| Step: 2
Training loss: 1.986816644668579
Validation loss: 2.067856275907127

Epoch: 5| Step: 3
Training loss: 1.8841098546981812
Validation loss: 2.0949002414621334

Epoch: 5| Step: 4
Training loss: 2.3841001987457275
Validation loss: 2.0836056688780427

Epoch: 5| Step: 5
Training loss: 1.9503965377807617
Validation loss: 2.077876869068351

Epoch: 5| Step: 6
Training loss: 2.0475616455078125
Validation loss: 2.076417321799904

Epoch: 5| Step: 7
Training loss: 1.8088951110839844
Validation loss: 2.0953223448927685

Epoch: 5| Step: 8
Training loss: 1.9666051864624023
Validation loss: 2.044995441231676

Epoch: 5| Step: 9
Training loss: 1.7899013757705688
Validation loss: 2.0386257774086407

Epoch: 5| Step: 10
Training loss: 2.019904136657715
Validation loss: 2.1233866983844387

Epoch: 198| Step: 0
Training loss: 1.9375247955322266
Validation loss: 2.084824659491098

Epoch: 5| Step: 1
Training loss: 2.37638783454895
Validation loss: 2.036536375681559

Epoch: 5| Step: 2
Training loss: 2.086716890335083
Validation loss: 2.0616335766289824

Epoch: 5| Step: 3
Training loss: 2.613523006439209
Validation loss: 2.070850513314688

Epoch: 5| Step: 4
Training loss: 1.716508150100708
Validation loss: 2.0906343203718945

Epoch: 5| Step: 5
Training loss: 2.1875457763671875
Validation loss: 2.0688934646626955

Epoch: 5| Step: 6
Training loss: 2.338456630706787
Validation loss: 2.0659399801684963

Epoch: 5| Step: 7
Training loss: 1.9775108098983765
Validation loss: 2.0779436031977334

Epoch: 5| Step: 8
Training loss: 2.0009777545928955
Validation loss: 2.0764231015277166

Epoch: 5| Step: 9
Training loss: 2.329134702682495
Validation loss: 2.0748496927240843

Epoch: 5| Step: 10
Training loss: 1.6948660612106323
Validation loss: 2.0546392394650366

Epoch: 199| Step: 0
Training loss: 1.9169483184814453
Validation loss: 2.0541912535185456

Epoch: 5| Step: 1
Training loss: 2.363213300704956
Validation loss: 2.0734397570292153

Epoch: 5| Step: 2
Training loss: 1.8168989419937134
Validation loss: 2.067818190461846

Epoch: 5| Step: 3
Training loss: 2.492868423461914
Validation loss: 2.0226846471909554

Epoch: 5| Step: 4
Training loss: 1.9778518676757812
Validation loss: 2.081351803195092

Epoch: 5| Step: 5
Training loss: 1.8476269245147705
Validation loss: 2.1218271101674726

Epoch: 5| Step: 6
Training loss: 1.7826780080795288
Validation loss: 2.0588072910103747

Epoch: 5| Step: 7
Training loss: 2.3468174934387207
Validation loss: 2.0940298085571616

Epoch: 5| Step: 8
Training loss: 2.321871519088745
Validation loss: 2.0880645257170483

Epoch: 5| Step: 9
Training loss: 2.348027229309082
Validation loss: 2.1098876114814513

Epoch: 5| Step: 10
Training loss: 2.122621774673462
Validation loss: 2.0761268933614097

Epoch: 200| Step: 0
Training loss: 1.9651310443878174
Validation loss: 2.074527205959443

Epoch: 5| Step: 1
Training loss: 2.117838144302368
Validation loss: 2.063455961083853

Epoch: 5| Step: 2
Training loss: 1.7313209772109985
Validation loss: 2.078403893337455

Epoch: 5| Step: 3
Training loss: 2.2239794731140137
Validation loss: 2.070096415858115

Epoch: 5| Step: 4
Training loss: 2.520167112350464
Validation loss: 2.052275332071448

Epoch: 5| Step: 5
Training loss: 2.3009116649627686
Validation loss: 2.0788499821898756

Epoch: 5| Step: 6
Training loss: 1.9685577154159546
Validation loss: 2.0989208990527737

Epoch: 5| Step: 7
Training loss: 1.8162643909454346
Validation loss: 2.0677876241745485

Epoch: 5| Step: 8
Training loss: 2.2001943588256836
Validation loss: 2.061654080626785

Epoch: 5| Step: 9
Training loss: 1.9228922128677368
Validation loss: 2.0506252665673532

Epoch: 5| Step: 10
Training loss: 2.725088119506836
Validation loss: 2.0741603502663235

Epoch: 201| Step: 0
Training loss: 2.1242010593414307
Validation loss: 2.065384780206988

Epoch: 5| Step: 1
Training loss: 1.9311416149139404
Validation loss: 2.1039955667270127

Epoch: 5| Step: 2
Training loss: 2.7071356773376465
Validation loss: 2.1403082160539526

Epoch: 5| Step: 3
Training loss: 2.211452007293701
Validation loss: 2.022057984464912

Epoch: 5| Step: 4
Training loss: 2.151430606842041
Validation loss: 2.0814956682984547

Epoch: 5| Step: 5
Training loss: 1.4902712106704712
Validation loss: 2.1279675088902956

Epoch: 5| Step: 6
Training loss: 2.110034465789795
Validation loss: 2.051397232599156

Epoch: 5| Step: 7
Training loss: 2.3990488052368164
Validation loss: 2.0798526271697013

Epoch: 5| Step: 8
Training loss: 1.9108270406723022
Validation loss: 2.0216808639546877

Epoch: 5| Step: 9
Training loss: 2.259533405303955
Validation loss: 2.0501404705867974

Epoch: 5| Step: 10
Training loss: 2.0241141319274902
Validation loss: 2.080114424869578

Epoch: 202| Step: 0
Training loss: 2.730001449584961
Validation loss: 2.092300466311875

Epoch: 5| Step: 1
Training loss: 2.5030131340026855
Validation loss: 2.086352034281659

Epoch: 5| Step: 2
Training loss: 1.7007557153701782
Validation loss: 2.053995939993089

Epoch: 5| Step: 3
Training loss: 1.9947322607040405
Validation loss: 2.043728595138878

Epoch: 5| Step: 4
Training loss: 1.5578721761703491
Validation loss: 2.0675727423801216

Epoch: 5| Step: 5
Training loss: 2.112379789352417
Validation loss: 2.0798618306395826

Epoch: 5| Step: 6
Training loss: 1.644802451133728
Validation loss: 2.0760900871728056

Epoch: 5| Step: 7
Training loss: 1.3207178115844727
Validation loss: 2.0519974359902005

Epoch: 5| Step: 8
Training loss: 2.4706478118896484
Validation loss: 2.0008200830028904

Epoch: 5| Step: 9
Training loss: 2.0700724124908447
Validation loss: 2.044997038379792

Epoch: 5| Step: 10
Training loss: 3.2286646366119385
Validation loss: 2.070961181835462

Epoch: 203| Step: 0
Training loss: 3.105149269104004
Validation loss: 2.0650476255724506

Epoch: 5| Step: 1
Training loss: 1.9463096857070923
Validation loss: 2.044258702185846

Epoch: 5| Step: 2
Training loss: 1.8846664428710938
Validation loss: 2.0434677447042158

Epoch: 5| Step: 3
Training loss: 2.0059902667999268
Validation loss: 2.0634066584289714

Epoch: 5| Step: 4
Training loss: 1.76894211769104
Validation loss: 2.0499148061198573

Epoch: 5| Step: 5
Training loss: 2.955047607421875
Validation loss: 2.077036790950324

Epoch: 5| Step: 6
Training loss: 2.1367788314819336
Validation loss: 2.1061413493207706

Epoch: 5| Step: 7
Training loss: 1.5805296897888184
Validation loss: 2.1123009368937504

Epoch: 5| Step: 8
Training loss: 1.9335016012191772
Validation loss: 2.1059703339812574

Epoch: 5| Step: 9
Training loss: 2.0926671028137207
Validation loss: 2.093310639422427

Epoch: 5| Step: 10
Training loss: 1.712170958518982
Validation loss: 2.0651032591378815

Epoch: 204| Step: 0
Training loss: 2.6007962226867676
Validation loss: 2.1082952740371868

Epoch: 5| Step: 1
Training loss: 2.4965245723724365
Validation loss: 2.097272421724053

Epoch: 5| Step: 2
Training loss: 2.4398930072784424
Validation loss: 2.133183462645418

Epoch: 5| Step: 3
Training loss: 1.821160912513733
Validation loss: 2.1015572906822286

Epoch: 5| Step: 4
Training loss: 1.8989607095718384
Validation loss: 2.052235057277064

Epoch: 5| Step: 5
Training loss: 2.32993221282959
Validation loss: 2.0878552903411207

Epoch: 5| Step: 6
Training loss: 1.833780288696289
Validation loss: 2.0720871930481284

Epoch: 5| Step: 7
Training loss: 1.6894080638885498
Validation loss: 2.0686441929109636

Epoch: 5| Step: 8
Training loss: 2.589092254638672
Validation loss: 2.068492481785436

Epoch: 5| Step: 9
Training loss: 1.7045629024505615
Validation loss: 2.091822819043231

Epoch: 5| Step: 10
Training loss: 1.9255056381225586
Validation loss: 2.0546548187091784

Epoch: 205| Step: 0
Training loss: 2.031601905822754
Validation loss: 2.097933582080308

Epoch: 5| Step: 1
Training loss: 1.9101924896240234
Validation loss: 2.0827644640399563

Epoch: 5| Step: 2
Training loss: 1.9294723272323608
Validation loss: 2.0793440470131497

Epoch: 5| Step: 3
Training loss: 2.011183500289917
Validation loss: 2.101865568468648

Epoch: 5| Step: 4
Training loss: 1.9806315898895264
Validation loss: 2.1168766303728987

Epoch: 5| Step: 5
Training loss: 1.8753812313079834
Validation loss: 2.083649835278911

Epoch: 5| Step: 6
Training loss: 2.1612162590026855
Validation loss: 2.096130427493844

Epoch: 5| Step: 7
Training loss: 2.4438388347625732
Validation loss: 2.1050518007688623

Epoch: 5| Step: 8
Training loss: 1.993664026260376
Validation loss: 2.1062694621342484

Epoch: 5| Step: 9
Training loss: 2.4923958778381348
Validation loss: 2.1019999032379477

Epoch: 5| Step: 10
Training loss: 2.4325008392333984
Validation loss: 2.0810937150832145

Epoch: 206| Step: 0
Training loss: 2.1498615741729736
Validation loss: 2.059374063245712

Epoch: 5| Step: 1
Training loss: 1.8134351968765259
Validation loss: 2.0750642848271195

Epoch: 5| Step: 2
Training loss: 2.777900218963623
Validation loss: 2.041806362008536

Epoch: 5| Step: 3
Training loss: 2.07161021232605
Validation loss: 2.0822233602564824

Epoch: 5| Step: 4
Training loss: 2.0108766555786133
Validation loss: 2.0630833987266786

Epoch: 5| Step: 5
Training loss: 2.3263638019561768
Validation loss: 2.114022413889567

Epoch: 5| Step: 6
Training loss: 2.0038106441497803
Validation loss: 2.0641757416468796

Epoch: 5| Step: 7
Training loss: 2.177696943283081
Validation loss: 2.084838890260266

Epoch: 5| Step: 8
Training loss: 2.164630174636841
Validation loss: 2.1114077311690136

Epoch: 5| Step: 9
Training loss: 2.201108455657959
Validation loss: 2.071675915871897

Epoch: 5| Step: 10
Training loss: 1.4715789556503296
Validation loss: 2.049662963036568

Epoch: 207| Step: 0
Training loss: 2.1580474376678467
Validation loss: 2.0509393266452256

Epoch: 5| Step: 1
Training loss: 1.9045984745025635
Validation loss: 2.014189907299575

Epoch: 5| Step: 2
Training loss: 2.0215749740600586
Validation loss: 2.0229546434135846

Epoch: 5| Step: 3
Training loss: 2.0436530113220215
Validation loss: 2.0161680098502868

Epoch: 5| Step: 4
Training loss: 1.6363025903701782
Validation loss: 2.087893319386308

Epoch: 5| Step: 5
Training loss: 2.1180834770202637
Validation loss: 2.061565519661032

Epoch: 5| Step: 6
Training loss: 1.8286285400390625
Validation loss: 2.0580733565874

Epoch: 5| Step: 7
Training loss: 2.3782646656036377
Validation loss: 2.060894138069563

Epoch: 5| Step: 8
Training loss: 2.468262195587158
Validation loss: 2.0225591121181363

Epoch: 5| Step: 9
Training loss: 2.62631893157959
Validation loss: 2.0632681051890054

Epoch: 5| Step: 10
Training loss: 1.8680247068405151
Validation loss: 2.031269419577814

Epoch: 208| Step: 0
Training loss: 2.1200191974639893
Validation loss: 2.107959267913654

Epoch: 5| Step: 1
Training loss: 1.9926319122314453
Validation loss: 2.0892512426581433

Epoch: 5| Step: 2
Training loss: 3.167334794998169
Validation loss: 2.051701755933864

Epoch: 5| Step: 3
Training loss: 3.1745717525482178
Validation loss: 2.0746885397100963

Epoch: 5| Step: 4
Training loss: 1.6790151596069336
Validation loss: 2.0660300331731

Epoch: 5| Step: 5
Training loss: 2.0592823028564453
Validation loss: 2.1122661764903734

Epoch: 5| Step: 6
Training loss: 1.5264041423797607
Validation loss: 2.1092189947764077

Epoch: 5| Step: 7
Training loss: 1.3914954662322998
Validation loss: 2.09891600249916

Epoch: 5| Step: 8
Training loss: 2.2155158519744873
Validation loss: 2.091244219451822

Epoch: 5| Step: 9
Training loss: 1.8059723377227783
Validation loss: 2.0541278880129576

Epoch: 5| Step: 10
Training loss: 2.1947853565216064
Validation loss: 2.080159748754194

Epoch: 209| Step: 0
Training loss: 2.94486141204834
Validation loss: 2.102630202488233

Epoch: 5| Step: 1
Training loss: 2.0029518604278564
Validation loss: 2.0931616239650275

Epoch: 5| Step: 2
Training loss: 2.030958652496338
Validation loss: 2.0518554090171732

Epoch: 5| Step: 3
Training loss: 2.3898983001708984
Validation loss: 2.111029931294021

Epoch: 5| Step: 4
Training loss: 1.7551292181015015
Validation loss: 2.078389706150178

Epoch: 5| Step: 5
Training loss: 2.4364852905273438
Validation loss: 2.070827945586174

Epoch: 5| Step: 6
Training loss: 2.060302257537842
Validation loss: 2.054386754189768

Epoch: 5| Step: 7
Training loss: 1.759381890296936
Validation loss: 2.068459810749177

Epoch: 5| Step: 8
Training loss: 2.26570200920105
Validation loss: 2.0916632375409527

Epoch: 5| Step: 9
Training loss: 1.4949840307235718
Validation loss: 2.0889388220284575

Epoch: 5| Step: 10
Training loss: 2.0837268829345703
Validation loss: 2.076490902131604

Epoch: 210| Step: 0
Training loss: 1.6936746835708618
Validation loss: 2.071108810363277

Epoch: 5| Step: 1
Training loss: 2.410759210586548
Validation loss: 2.0717922987476474

Epoch: 5| Step: 2
Training loss: 0.9725278615951538
Validation loss: 2.064087158890181

Epoch: 5| Step: 3
Training loss: 2.990665912628174
Validation loss: 2.0905861252097675

Epoch: 5| Step: 4
Training loss: 2.137803554534912
Validation loss: 2.086033824951418

Epoch: 5| Step: 5
Training loss: 2.2765891551971436
Validation loss: 2.0755608594545754

Epoch: 5| Step: 6
Training loss: 2.024202823638916
Validation loss: 2.0312805714145785

Epoch: 5| Step: 7
Training loss: 1.7531582117080688
Validation loss: 2.0791443265894407

Epoch: 5| Step: 8
Training loss: 2.2179272174835205
Validation loss: 2.0651906562107865

Epoch: 5| Step: 9
Training loss: 1.9016090631484985
Validation loss: 2.078771630922953

Epoch: 5| Step: 10
Training loss: 2.728198766708374
Validation loss: 2.087802504980436

Epoch: 211| Step: 0
Training loss: 2.467970132827759
Validation loss: 2.0731613712926067

Epoch: 5| Step: 1
Training loss: 1.8768765926361084
Validation loss: 2.0881245495170675

Epoch: 5| Step: 2
Training loss: 2.091181516647339
Validation loss: 2.117057957956868

Epoch: 5| Step: 3
Training loss: 2.6942036151885986
Validation loss: 2.1030042991843274

Epoch: 5| Step: 4
Training loss: 2.5530362129211426
Validation loss: 2.100979802429035

Epoch: 5| Step: 5
Training loss: 2.078650951385498
Validation loss: 2.0842032637647403

Epoch: 5| Step: 6
Training loss: 2.44887375831604
Validation loss: 2.041206761073041

Epoch: 5| Step: 7
Training loss: 2.152278423309326
Validation loss: 2.084544130550918

Epoch: 5| Step: 8
Training loss: 1.700178861618042
Validation loss: 2.0931433631527807

Epoch: 5| Step: 9
Training loss: 1.0030126571655273
Validation loss: 2.0614122318965133

Epoch: 5| Step: 10
Training loss: 1.9331187009811401
Validation loss: 2.0529538252020396

Epoch: 212| Step: 0
Training loss: 1.7972583770751953
Validation loss: 2.0617518912079515

Epoch: 5| Step: 1
Training loss: 2.028383731842041
Validation loss: 2.0741204254088865

Epoch: 5| Step: 2
Training loss: 2.6220672130584717
Validation loss: 2.057183660486693

Epoch: 5| Step: 3
Training loss: 1.8008625507354736
Validation loss: 2.07696976969319

Epoch: 5| Step: 4
Training loss: 2.2751357555389404
Validation loss: 2.087827382549163

Epoch: 5| Step: 5
Training loss: 2.567034959793091
Validation loss: 2.0860162422221196

Epoch: 5| Step: 6
Training loss: 2.217658519744873
Validation loss: 2.0975308187546267

Epoch: 5| Step: 7
Training loss: 1.7488248348236084
Validation loss: 2.0707035449243363

Epoch: 5| Step: 8
Training loss: 2.1679351329803467
Validation loss: 2.0584835044799314

Epoch: 5| Step: 9
Training loss: 2.2356019020080566
Validation loss: 2.0556192577526136

Epoch: 5| Step: 10
Training loss: 1.7726030349731445
Validation loss: 2.0641923335290726

Epoch: 213| Step: 0
Training loss: 1.7583421468734741
Validation loss: 2.0595720967938824

Epoch: 5| Step: 1
Training loss: 1.9993776082992554
Validation loss: 2.0507892767588296

Epoch: 5| Step: 2
Training loss: 2.3576560020446777
Validation loss: 2.0428830039116646

Epoch: 5| Step: 3
Training loss: 2.504336357116699
Validation loss: 2.0593073432163527

Epoch: 5| Step: 4
Training loss: 2.326411724090576
Validation loss: 2.0849533465600785

Epoch: 5| Step: 5
Training loss: 1.9535754919052124
Validation loss: 2.097118790431689

Epoch: 5| Step: 6
Training loss: 1.791049599647522
Validation loss: 2.100965035858975

Epoch: 5| Step: 7
Training loss: 2.431358814239502
Validation loss: 2.1341316558981456

Epoch: 5| Step: 8
Training loss: 1.6908090114593506
Validation loss: 2.0473087423591205

Epoch: 5| Step: 9
Training loss: 1.627234697341919
Validation loss: 2.1022601435261388

Epoch: 5| Step: 10
Training loss: 2.4114327430725098
Validation loss: 2.1002191946070683

Epoch: 214| Step: 0
Training loss: 2.2787327766418457
Validation loss: 2.1115699327120216

Epoch: 5| Step: 1
Training loss: 2.155099391937256
Validation loss: 2.0636035498752388

Epoch: 5| Step: 2
Training loss: 1.8807874917984009
Validation loss: 2.089561272692937

Epoch: 5| Step: 3
Training loss: 1.326390266418457
Validation loss: 2.0610046925083285

Epoch: 5| Step: 4
Training loss: 2.196974277496338
Validation loss: 2.1210937371817966

Epoch: 5| Step: 5
Training loss: 2.1099629402160645
Validation loss: 2.0770804753867527

Epoch: 5| Step: 6
Training loss: 2.3947482109069824
Validation loss: 2.0608147626282065

Epoch: 5| Step: 7
Training loss: 1.585330843925476
Validation loss: 2.1015890900806715

Epoch: 5| Step: 8
Training loss: 2.444370746612549
Validation loss: 2.037739174340361

Epoch: 5| Step: 9
Training loss: 2.270028591156006
Validation loss: 2.0810151715432443

Epoch: 5| Step: 10
Training loss: 2.2367942333221436
Validation loss: 2.092462506345523

Epoch: 215| Step: 0
Training loss: 2.1054115295410156
Validation loss: 2.0986791092862367

Epoch: 5| Step: 1
Training loss: 2.455591917037964
Validation loss: 2.0519107259729856

Epoch: 5| Step: 2
Training loss: 1.9638087749481201
Validation loss: 2.0919847091039023

Epoch: 5| Step: 3
Training loss: 2.093271017074585
Validation loss: 2.0476290987383936

Epoch: 5| Step: 4
Training loss: 1.9772783517837524
Validation loss: 2.016542738483798

Epoch: 5| Step: 5
Training loss: 1.8542149066925049
Validation loss: 2.1070417191392634

Epoch: 5| Step: 6
Training loss: 2.6670119762420654
Validation loss: 2.1086863381888277

Epoch: 5| Step: 7
Training loss: 2.321300983428955
Validation loss: 2.102257228666736

Epoch: 5| Step: 8
Training loss: 1.506716251373291
Validation loss: 2.048544446627299

Epoch: 5| Step: 9
Training loss: 1.685609221458435
Validation loss: 2.039706651882459

Epoch: 5| Step: 10
Training loss: 2.403836250305176
Validation loss: 2.08117074863885

Epoch: 216| Step: 0
Training loss: 1.7097742557525635
Validation loss: 2.110527148810766

Epoch: 5| Step: 1
Training loss: 1.7001855373382568
Validation loss: 2.0865189952235066

Epoch: 5| Step: 2
Training loss: 2.374243974685669
Validation loss: 2.0744946118324035

Epoch: 5| Step: 3
Training loss: 1.679260015487671
Validation loss: 2.0804344902756395

Epoch: 5| Step: 4
Training loss: 2.8442232608795166
Validation loss: 2.0573626897668325

Epoch: 5| Step: 5
Training loss: 2.2639575004577637
Validation loss: 2.0959581354612946

Epoch: 5| Step: 6
Training loss: 1.8383365869522095
Validation loss: 2.0952082410935433

Epoch: 5| Step: 7
Training loss: 2.7904810905456543
Validation loss: 2.049216721647529

Epoch: 5| Step: 8
Training loss: 2.443052291870117
Validation loss: 2.129992784992341

Epoch: 5| Step: 9
Training loss: 1.3513046503067017
Validation loss: 2.095148371111962

Epoch: 5| Step: 10
Training loss: 1.8247617483139038
Validation loss: 2.0839296592179166

Epoch: 217| Step: 0
Training loss: 2.6121163368225098
Validation loss: 2.1002320281920897

Epoch: 5| Step: 1
Training loss: 2.171800374984741
Validation loss: 2.0804091204879103

Epoch: 5| Step: 2
Training loss: 1.6713415384292603
Validation loss: 2.120341001018401

Epoch: 5| Step: 3
Training loss: 2.8231678009033203
Validation loss: 2.0588168995354765

Epoch: 5| Step: 4
Training loss: 1.895886778831482
Validation loss: 2.1221132483533633

Epoch: 5| Step: 5
Training loss: 1.4129688739776611
Validation loss: 2.0731516768855434

Epoch: 5| Step: 6
Training loss: 2.2071890830993652
Validation loss: 2.129672687540772

Epoch: 5| Step: 7
Training loss: 1.1069462299346924
Validation loss: 2.08960553907579

Epoch: 5| Step: 8
Training loss: 2.4368183612823486
Validation loss: 2.0559192062706075

Epoch: 5| Step: 9
Training loss: 2.187004804611206
Validation loss: 2.0676893508562477

Epoch: 5| Step: 10
Training loss: 2.5170419216156006
Validation loss: 2.0404050978281165

Epoch: 218| Step: 0
Training loss: 2.2117881774902344
Validation loss: 2.0684364636739097

Epoch: 5| Step: 1
Training loss: 2.423434019088745
Validation loss: 2.1221296594988917

Epoch: 5| Step: 2
Training loss: 1.3627296686172485
Validation loss: 2.0576576084219

Epoch: 5| Step: 3
Training loss: 2.2924892902374268
Validation loss: 2.0560267330497823

Epoch: 5| Step: 4
Training loss: 2.407352924346924
Validation loss: 2.0608379302486295

Epoch: 5| Step: 5
Training loss: 1.493791937828064
Validation loss: 2.0571792125701904

Epoch: 5| Step: 6
Training loss: 2.228349208831787
Validation loss: 2.0467834652111097

Epoch: 5| Step: 7
Training loss: 2.1431450843811035
Validation loss: 2.053498121999925

Epoch: 5| Step: 8
Training loss: 1.9682979583740234
Validation loss: 2.0541504249777844

Epoch: 5| Step: 9
Training loss: 2.494202136993408
Validation loss: 2.0850590480271207

Epoch: 5| Step: 10
Training loss: 1.9914662837982178
Validation loss: 2.0632919111559467

Epoch: 219| Step: 0
Training loss: 2.1766231060028076
Validation loss: 2.0767169549900997

Epoch: 5| Step: 1
Training loss: 1.669215202331543
Validation loss: 2.0519519595689673

Epoch: 5| Step: 2
Training loss: 2.395355224609375
Validation loss: 2.0935007269664476

Epoch: 5| Step: 3
Training loss: 1.73055899143219
Validation loss: 2.0340327293642106

Epoch: 5| Step: 4
Training loss: 1.9758491516113281
Validation loss: 2.056328422279768

Epoch: 5| Step: 5
Training loss: 2.073136568069458
Validation loss: 2.0640420503513788

Epoch: 5| Step: 6
Training loss: 2.2025258541107178
Validation loss: 2.064068894232473

Epoch: 5| Step: 7
Training loss: 2.109658718109131
Validation loss: 2.1053543347184376

Epoch: 5| Step: 8
Training loss: 2.247055768966675
Validation loss: 2.061175820648029

Epoch: 5| Step: 9
Training loss: 2.2664170265197754
Validation loss: 2.041872707746362

Epoch: 5| Step: 10
Training loss: 2.2826621532440186
Validation loss: 2.061007676586028

Epoch: 220| Step: 0
Training loss: 1.937103509902954
Validation loss: 2.068286225359927

Epoch: 5| Step: 1
Training loss: 1.9082742929458618
Validation loss: 2.073273665161543

Epoch: 5| Step: 2
Training loss: 2.3687572479248047
Validation loss: 2.075315139626944

Epoch: 5| Step: 3
Training loss: 2.1048810482025146
Validation loss: 2.1147801030066704

Epoch: 5| Step: 4
Training loss: 1.7085535526275635
Validation loss: 2.078260016697709

Epoch: 5| Step: 5
Training loss: 2.371168375015259
Validation loss: 2.1117703555732645

Epoch: 5| Step: 6
Training loss: 2.330226182937622
Validation loss: 2.068974966643959

Epoch: 5| Step: 7
Training loss: 2.210578680038452
Validation loss: 2.076243982520155

Epoch: 5| Step: 8
Training loss: 2.165531635284424
Validation loss: 2.070873286134453

Epoch: 5| Step: 9
Training loss: 1.8238537311553955
Validation loss: 2.092189318390303

Epoch: 5| Step: 10
Training loss: 2.102825880050659
Validation loss: 2.0770263800057034

Epoch: 221| Step: 0
Training loss: 2.582242012023926
Validation loss: 2.1062723616118073

Epoch: 5| Step: 1
Training loss: 1.713958740234375
Validation loss: 2.0879373012050504

Epoch: 5| Step: 2
Training loss: 2.4695560932159424
Validation loss: 2.101352350686186

Epoch: 5| Step: 3
Training loss: 2.2761483192443848
Validation loss: 2.1028453816649733

Epoch: 5| Step: 4
Training loss: 1.3460004329681396
Validation loss: 2.0930493800870833

Epoch: 5| Step: 5
Training loss: 2.5892064571380615
Validation loss: 2.101974707777782

Epoch: 5| Step: 6
Training loss: 2.2123405933380127
Validation loss: 2.019379727302059

Epoch: 5| Step: 7
Training loss: 1.7008100748062134
Validation loss: 2.080133717547181

Epoch: 5| Step: 8
Training loss: 1.4985841512680054
Validation loss: 2.0490584040200837

Epoch: 5| Step: 9
Training loss: 2.1031007766723633
Validation loss: 2.1144582584340084

Epoch: 5| Step: 10
Training loss: 2.4198954105377197
Validation loss: 2.0483038194717897

Epoch: 222| Step: 0
Training loss: 1.9940922260284424
Validation loss: 2.0892394793930875

Epoch: 5| Step: 1
Training loss: 2.837369680404663
Validation loss: 2.053533209267483

Epoch: 5| Step: 2
Training loss: 2.363438367843628
Validation loss: 2.0638769313853276

Epoch: 5| Step: 3
Training loss: 2.7212204933166504
Validation loss: 2.068770367612121

Epoch: 5| Step: 4
Training loss: 2.3071677684783936
Validation loss: 2.0825748033421014

Epoch: 5| Step: 5
Training loss: 1.3920048475265503
Validation loss: 2.0946474293226838

Epoch: 5| Step: 6
Training loss: 1.6352351903915405
Validation loss: 2.0390570753364154

Epoch: 5| Step: 7
Training loss: 2.022550582885742
Validation loss: 2.0580618355863836

Epoch: 5| Step: 8
Training loss: 2.2764854431152344
Validation loss: 2.0604527458067863

Epoch: 5| Step: 9
Training loss: 1.706064224243164
Validation loss: 2.1049120413359774

Epoch: 5| Step: 10
Training loss: 1.9109522104263306
Validation loss: 2.0660404569359234

Epoch: 223| Step: 0
Training loss: 1.804303526878357
Validation loss: 2.085715998885452

Epoch: 5| Step: 1
Training loss: 2.609201669692993
Validation loss: 2.0841467252341648

Epoch: 5| Step: 2
Training loss: 1.7575763463974
Validation loss: 2.0917466866072787

Epoch: 5| Step: 3
Training loss: 1.5774914026260376
Validation loss: 2.0583758931006155

Epoch: 5| Step: 4
Training loss: 1.8955767154693604
Validation loss: 2.08245777058345

Epoch: 5| Step: 5
Training loss: 2.2847204208374023
Validation loss: 2.1185121356800036

Epoch: 5| Step: 6
Training loss: 1.7565618753433228
Validation loss: 2.107074788821641

Epoch: 5| Step: 7
Training loss: 2.348360300064087
Validation loss: 2.079798621516074

Epoch: 5| Step: 8
Training loss: 1.855400800704956
Validation loss: 2.0896199787816694

Epoch: 5| Step: 9
Training loss: 2.4354443550109863
Validation loss: 2.10795493536098

Epoch: 5| Step: 10
Training loss: 2.12787127494812
Validation loss: 2.105623327275758

Epoch: 224| Step: 0
Training loss: 2.7014052867889404
Validation loss: 2.0948051791037283

Epoch: 5| Step: 1
Training loss: 2.009706974029541
Validation loss: 2.0966321037661646

Epoch: 5| Step: 2
Training loss: 1.7236671447753906
Validation loss: 2.1015804608662925

Epoch: 5| Step: 3
Training loss: 2.2947051525115967
Validation loss: 2.088954552527397

Epoch: 5| Step: 4
Training loss: 1.9963678121566772
Validation loss: 2.102105786723475

Epoch: 5| Step: 5
Training loss: 2.4415500164031982
Validation loss: 2.089419185474355

Epoch: 5| Step: 6
Training loss: 2.527540445327759
Validation loss: 2.103432152860908

Epoch: 5| Step: 7
Training loss: 1.204978346824646
Validation loss: 2.08922420137672

Epoch: 5| Step: 8
Training loss: 1.8576946258544922
Validation loss: 2.049928334451491

Epoch: 5| Step: 9
Training loss: 2.1941425800323486
Validation loss: 2.0949969983869985

Epoch: 5| Step: 10
Training loss: 1.7833459377288818
Validation loss: 2.07528265060917

Epoch: 225| Step: 0
Training loss: 2.1902377605438232
Validation loss: 2.086135748893984

Epoch: 5| Step: 1
Training loss: 2.198667526245117
Validation loss: 2.0851392438334804

Epoch: 5| Step: 2
Training loss: 2.652127265930176
Validation loss: 2.077375647842243

Epoch: 5| Step: 3
Training loss: 1.8493455648422241
Validation loss: 2.0968754817080755

Epoch: 5| Step: 4
Training loss: 2.173527240753174
Validation loss: 2.1112295222538773

Epoch: 5| Step: 5
Training loss: 1.7906513214111328
Validation loss: 2.0964949028466338

Epoch: 5| Step: 6
Training loss: 2.0210251808166504
Validation loss: 2.0649878325000888

Epoch: 5| Step: 7
Training loss: 1.8417432308197021
Validation loss: 2.029731972243196

Epoch: 5| Step: 8
Training loss: 1.8787355422973633
Validation loss: 2.0593377826034382

Epoch: 5| Step: 9
Training loss: 2.063702344894409
Validation loss: 2.065756493999112

Epoch: 5| Step: 10
Training loss: 2.2525155544281006
Validation loss: 2.0650149032633793

Epoch: 226| Step: 0
Training loss: 2.109135389328003
Validation loss: 2.101109263717487

Epoch: 5| Step: 1
Training loss: 1.725367784500122
Validation loss: 2.1038025297144407

Epoch: 5| Step: 2
Training loss: 2.179398775100708
Validation loss: 2.0799191344168877

Epoch: 5| Step: 3
Training loss: 2.631877899169922
Validation loss: 2.043564159383056

Epoch: 5| Step: 4
Training loss: 1.6867176294326782
Validation loss: 2.069018675434974

Epoch: 5| Step: 5
Training loss: 2.658522844314575
Validation loss: 2.078355825075539

Epoch: 5| Step: 6
Training loss: 2.3973259925842285
Validation loss: 2.0907949516850133

Epoch: 5| Step: 7
Training loss: 1.7561779022216797
Validation loss: 2.1202764664926836

Epoch: 5| Step: 8
Training loss: 2.3657052516937256
Validation loss: 2.0919304047861407

Epoch: 5| Step: 9
Training loss: 2.2530927658081055
Validation loss: 2.077207028224904

Epoch: 5| Step: 10
Training loss: 0.9403681755065918
Validation loss: 2.064779209834273

Epoch: 227| Step: 0
Training loss: 2.032052993774414
Validation loss: 2.11839823825385

Epoch: 5| Step: 1
Training loss: 2.383375644683838
Validation loss: 2.077352387930757

Epoch: 5| Step: 2
Training loss: 2.219435453414917
Validation loss: 2.077495721078688

Epoch: 5| Step: 3
Training loss: 2.029714345932007
Validation loss: 2.072472140353213

Epoch: 5| Step: 4
Training loss: 1.6820392608642578
Validation loss: 2.0836820269143708

Epoch: 5| Step: 5
Training loss: 2.000152111053467
Validation loss: 2.095674794207337

Epoch: 5| Step: 6
Training loss: 2.0481326580047607
Validation loss: 2.0944039385805846

Epoch: 5| Step: 7
Training loss: 2.087568521499634
Validation loss: 2.097138458682645

Epoch: 5| Step: 8
Training loss: 2.0193614959716797
Validation loss: 2.0421886828637894

Epoch: 5| Step: 9
Training loss: 2.352027416229248
Validation loss: 2.088013449022847

Epoch: 5| Step: 10
Training loss: 1.8600867986679077
Validation loss: 2.0616740642055387

Epoch: 228| Step: 0
Training loss: 2.268702507019043
Validation loss: 2.1038094438532347

Epoch: 5| Step: 1
Training loss: 1.8717553615570068
Validation loss: 2.070190739888017

Epoch: 5| Step: 2
Training loss: 2.1575844287872314
Validation loss: 2.070005597606782

Epoch: 5| Step: 3
Training loss: 1.906749963760376
Validation loss: 2.0963890834521224

Epoch: 5| Step: 4
Training loss: 2.635240316390991
Validation loss: 2.0526276121857348

Epoch: 5| Step: 5
Training loss: 2.2078945636749268
Validation loss: 2.0963868902575586

Epoch: 5| Step: 6
Training loss: 1.5554141998291016
Validation loss: 2.054023540148171

Epoch: 5| Step: 7
Training loss: 2.4747061729431152
Validation loss: 2.0689061559656614

Epoch: 5| Step: 8
Training loss: 2.282214641571045
Validation loss: 2.0790491629672307

Epoch: 5| Step: 9
Training loss: 1.5068715810775757
Validation loss: 2.1145194140813683

Epoch: 5| Step: 10
Training loss: 2.0988986492156982
Validation loss: 2.0760269690585393

Epoch: 229| Step: 0
Training loss: 2.3667702674865723
Validation loss: 2.092363611344368

Epoch: 5| Step: 1
Training loss: 2.2823996543884277
Validation loss: 2.0893001671760314

Epoch: 5| Step: 2
Training loss: 1.8895337581634521
Validation loss: 2.0591128808195873

Epoch: 5| Step: 3
Training loss: 2.5990068912506104
Validation loss: 2.0925055652536373

Epoch: 5| Step: 4
Training loss: 1.7299511432647705
Validation loss: 2.06950984462615

Epoch: 5| Step: 5
Training loss: 2.051943302154541
Validation loss: 2.082118270217731

Epoch: 5| Step: 6
Training loss: 2.020033359527588
Validation loss: 2.096670748085104

Epoch: 5| Step: 7
Training loss: 2.378817558288574
Validation loss: 2.0792318749171432

Epoch: 5| Step: 8
Training loss: 1.7874114513397217
Validation loss: 2.088728004886258

Epoch: 5| Step: 9
Training loss: 2.22210693359375
Validation loss: 2.0737187324031705

Epoch: 5| Step: 10
Training loss: 1.5298274755477905
Validation loss: 2.0582917069876068

Epoch: 230| Step: 0
Training loss: 1.799085259437561
Validation loss: 2.017962706986294

Epoch: 5| Step: 1
Training loss: 2.3673009872436523
Validation loss: 2.069587133264029

Epoch: 5| Step: 2
Training loss: 2.265862464904785
Validation loss: 2.0893786555977276

Epoch: 5| Step: 3
Training loss: 1.897857427597046
Validation loss: 2.083546705143426

Epoch: 5| Step: 4
Training loss: 2.348545551300049
Validation loss: 2.062471297479445

Epoch: 5| Step: 5
Training loss: 1.8821157217025757
Validation loss: 2.0778552498868716

Epoch: 5| Step: 6
Training loss: 2.395449638366699
Validation loss: 2.0468790197885163

Epoch: 5| Step: 7
Training loss: 2.2298173904418945
Validation loss: 2.0730690033205095

Epoch: 5| Step: 8
Training loss: 1.8178126811981201
Validation loss: 2.132606860130064

Epoch: 5| Step: 9
Training loss: 1.9856468439102173
Validation loss: 2.1018947670536656

Epoch: 5| Step: 10
Training loss: 1.9174171686172485
Validation loss: 2.079045964825538

Epoch: 231| Step: 0
Training loss: 2.222907781600952
Validation loss: 2.083742539087931

Epoch: 5| Step: 1
Training loss: 1.934665322303772
Validation loss: 2.0650943786867204

Epoch: 5| Step: 2
Training loss: 2.110013484954834
Validation loss: 2.0930217594228764

Epoch: 5| Step: 3
Training loss: 1.844747543334961
Validation loss: 2.0926409652156215

Epoch: 5| Step: 4
Training loss: 2.325136184692383
Validation loss: 2.1003660924973024

Epoch: 5| Step: 5
Training loss: 2.0267701148986816
Validation loss: 2.0343086258057625

Epoch: 5| Step: 6
Training loss: 1.7883764505386353
Validation loss: 2.0473460587122108

Epoch: 5| Step: 7
Training loss: 1.8228172063827515
Validation loss: 2.0419201825254705

Epoch: 5| Step: 8
Training loss: 2.3662097454071045
Validation loss: 2.0524112011796687

Epoch: 5| Step: 9
Training loss: 1.687656044960022
Validation loss: 2.029920886921626

Epoch: 5| Step: 10
Training loss: 2.6595299243927
Validation loss: 2.0727767047061714

Epoch: 232| Step: 0
Training loss: 2.4796853065490723
Validation loss: 2.097599599951057

Epoch: 5| Step: 1
Training loss: 2.565786838531494
Validation loss: 2.091009852706745

Epoch: 5| Step: 2
Training loss: 1.3055610656738281
Validation loss: 2.0786529048796623

Epoch: 5| Step: 3
Training loss: 2.468085765838623
Validation loss: 2.093465725580851

Epoch: 5| Step: 4
Training loss: 1.9497168064117432
Validation loss: 2.059874451288613

Epoch: 5| Step: 5
Training loss: 1.6705007553100586
Validation loss: 2.0913483993981474

Epoch: 5| Step: 6
Training loss: 1.9899154901504517
Validation loss: 2.06712281832131

Epoch: 5| Step: 7
Training loss: 3.061239004135132
Validation loss: 2.0932003221204205

Epoch: 5| Step: 8
Training loss: 1.0329958200454712
Validation loss: 2.0766941578157487

Epoch: 5| Step: 9
Training loss: 2.429442882537842
Validation loss: 2.0461304751775597

Epoch: 5| Step: 10
Training loss: 2.027498960494995
Validation loss: 2.0421955829025595

Epoch: 233| Step: 0
Training loss: 1.5534104108810425
Validation loss: 2.0818241796185895

Epoch: 5| Step: 1
Training loss: 1.9738414287567139
Validation loss: 2.055350875341764

Epoch: 5| Step: 2
Training loss: 1.8514400720596313
Validation loss: 2.0797491996519026

Epoch: 5| Step: 3
Training loss: 2.300818920135498
Validation loss: 2.0910875951090167

Epoch: 5| Step: 4
Training loss: 2.7041072845458984
Validation loss: 2.0951971007931616

Epoch: 5| Step: 5
Training loss: 2.52302885055542
Validation loss: 2.1270386198515534

Epoch: 5| Step: 6
Training loss: 1.8509279489517212
Validation loss: 2.1040719145087787

Epoch: 5| Step: 7
Training loss: 1.7496578693389893
Validation loss: 2.0792685426691526

Epoch: 5| Step: 8
Training loss: 2.2757859230041504
Validation loss: 2.0100414522232546

Epoch: 5| Step: 9
Training loss: 1.9879417419433594
Validation loss: 2.136444171269735

Epoch: 5| Step: 10
Training loss: 1.8152172565460205
Validation loss: 2.1013847602311

Epoch: 234| Step: 0
Training loss: 2.097494125366211
Validation loss: 2.0989868999809347

Epoch: 5| Step: 1
Training loss: 2.1412055492401123
Validation loss: 2.043993637125979

Epoch: 5| Step: 2
Training loss: 2.4826133251190186
Validation loss: 2.1273826629884782

Epoch: 5| Step: 3
Training loss: 2.089364528656006
Validation loss: 2.0736037723479734

Epoch: 5| Step: 4
Training loss: 1.3453481197357178
Validation loss: 2.125243325387278

Epoch: 5| Step: 5
Training loss: 1.7691211700439453
Validation loss: 2.1355265827589136

Epoch: 5| Step: 6
Training loss: 2.5318610668182373
Validation loss: 2.11624050653109

Epoch: 5| Step: 7
Training loss: 2.5432815551757812
Validation loss: 2.1018173258791686

Epoch: 5| Step: 8
Training loss: 1.9642646312713623
Validation loss: 2.1162594210716987

Epoch: 5| Step: 9
Training loss: 1.6115386486053467
Validation loss: 2.0699825145865

Epoch: 5| Step: 10
Training loss: 2.420261859893799
Validation loss: 2.025296216369957

Epoch: 235| Step: 0
Training loss: 2.1377341747283936
Validation loss: 2.1248448792324273

Epoch: 5| Step: 1
Training loss: 2.5537829399108887
Validation loss: 2.0608807802200317

Epoch: 5| Step: 2
Training loss: 2.7201995849609375
Validation loss: 2.1250077191219536

Epoch: 5| Step: 3
Training loss: 2.0053510665893555
Validation loss: 2.029243319265304

Epoch: 5| Step: 4
Training loss: 1.9059340953826904
Validation loss: 2.102450418215926

Epoch: 5| Step: 5
Training loss: 1.6783396005630493
Validation loss: 2.084865004785599

Epoch: 5| Step: 6
Training loss: 2.0445148944854736
Validation loss: 2.064584429546069

Epoch: 5| Step: 7
Training loss: 1.3310747146606445
Validation loss: 2.0666647893126293

Epoch: 5| Step: 8
Training loss: 2.5174903869628906
Validation loss: 2.102922139629241

Epoch: 5| Step: 9
Training loss: 1.798182725906372
Validation loss: 2.1103781679625153

Epoch: 5| Step: 10
Training loss: 2.091331958770752
Validation loss: 2.079890654933068

Epoch: 236| Step: 0
Training loss: 2.133899450302124
Validation loss: 2.028389069341844

Epoch: 5| Step: 1
Training loss: 2.234116554260254
Validation loss: 2.0682414539398684

Epoch: 5| Step: 2
Training loss: 1.8220150470733643
Validation loss: 2.0598492417284238

Epoch: 5| Step: 3
Training loss: 2.5818557739257812
Validation loss: 2.101479240643081

Epoch: 5| Step: 4
Training loss: 1.990776777267456
Validation loss: 2.0468670629685923

Epoch: 5| Step: 5
Training loss: 2.44486665725708
Validation loss: 2.094469117861922

Epoch: 5| Step: 6
Training loss: 1.5614712238311768
Validation loss: 2.0698897351500807

Epoch: 5| Step: 7
Training loss: 1.9566978216171265
Validation loss: 2.0867958709757817

Epoch: 5| Step: 8
Training loss: 1.9352811574935913
Validation loss: 2.066421260115921

Epoch: 5| Step: 9
Training loss: 2.080817222595215
Validation loss: 2.0873468691302883

Epoch: 5| Step: 10
Training loss: 1.86549973487854
Validation loss: 2.0750311292627805

Epoch: 237| Step: 0
Training loss: 1.431907296180725
Validation loss: 2.046219079725204

Epoch: 5| Step: 1
Training loss: 1.7087929248809814
Validation loss: 2.1002912880271993

Epoch: 5| Step: 2
Training loss: 2.866354465484619
Validation loss: 2.0731496964731524

Epoch: 5| Step: 3
Training loss: 1.6268939971923828
Validation loss: 2.0805089755724837

Epoch: 5| Step: 4
Training loss: 2.4628868103027344
Validation loss: 2.0846718370273547

Epoch: 5| Step: 5
Training loss: 2.2250564098358154
Validation loss: 2.1326128616127917

Epoch: 5| Step: 6
Training loss: 2.1746251583099365
Validation loss: 2.0849508188104116

Epoch: 5| Step: 7
Training loss: 1.9337332248687744
Validation loss: 2.103188973601146

Epoch: 5| Step: 8
Training loss: 2.2235312461853027
Validation loss: 2.1540354785098823

Epoch: 5| Step: 9
Training loss: 2.0245509147644043
Validation loss: 2.0796643636559926

Epoch: 5| Step: 10
Training loss: 2.308795690536499
Validation loss: 2.1177305995777087

Epoch: 238| Step: 0
Training loss: 2.151655673980713
Validation loss: 2.1126696871173

Epoch: 5| Step: 1
Training loss: 1.425771713256836
Validation loss: 2.0501337179573635

Epoch: 5| Step: 2
Training loss: 1.900633454322815
Validation loss: 2.080067229527299

Epoch: 5| Step: 3
Training loss: 2.2289540767669678
Validation loss: 2.093228006875643

Epoch: 5| Step: 4
Training loss: 1.7201650142669678
Validation loss: 2.0859652642280824

Epoch: 5| Step: 5
Training loss: 1.9439551830291748
Validation loss: 2.083781467970981

Epoch: 5| Step: 6
Training loss: 1.8372859954833984
Validation loss: 2.1058193996388423

Epoch: 5| Step: 7
Training loss: 1.8252582550048828
Validation loss: 2.0374724429140807

Epoch: 5| Step: 8
Training loss: 2.7639734745025635
Validation loss: 2.0540084954231017

Epoch: 5| Step: 9
Training loss: 2.591452121734619
Validation loss: 2.0672740295369136

Epoch: 5| Step: 10
Training loss: 2.116161584854126
Validation loss: 2.0871214071909585

Epoch: 239| Step: 0
Training loss: 1.5316745042800903
Validation loss: 2.1182195883925243

Epoch: 5| Step: 1
Training loss: 1.9353878498077393
Validation loss: 2.0965182242854947

Epoch: 5| Step: 2
Training loss: 1.8921680450439453
Validation loss: 2.076210028381758

Epoch: 5| Step: 3
Training loss: 2.634059190750122
Validation loss: 2.07704331028846

Epoch: 5| Step: 4
Training loss: 2.5575058460235596
Validation loss: 2.0654842263908795

Epoch: 5| Step: 5
Training loss: 2.135701894760132
Validation loss: 2.056345917845285

Epoch: 5| Step: 6
Training loss: 2.2212443351745605
Validation loss: 2.0818448681985178

Epoch: 5| Step: 7
Training loss: 1.6100561618804932
Validation loss: 2.064190944035848

Epoch: 5| Step: 8
Training loss: 1.8868367671966553
Validation loss: 2.112223558528449

Epoch: 5| Step: 9
Training loss: 2.1302027702331543
Validation loss: 2.069866203492688

Epoch: 5| Step: 10
Training loss: 1.9218602180480957
Validation loss: 2.0668215213283414

Epoch: 240| Step: 0
Training loss: 1.8510370254516602
Validation loss: 2.16232576165148

Epoch: 5| Step: 1
Training loss: 2.0261523723602295
Validation loss: 2.085684448160151

Epoch: 5| Step: 2
Training loss: 2.699615716934204
Validation loss: 2.096250794267142

Epoch: 5| Step: 3
Training loss: 2.3806252479553223
Validation loss: 2.0961369211955736

Epoch: 5| Step: 4
Training loss: 2.119568347930908
Validation loss: 2.087222376177388

Epoch: 5| Step: 5
Training loss: 2.4093079566955566
Validation loss: 2.0821628673102266

Epoch: 5| Step: 6
Training loss: 2.0448546409606934
Validation loss: 2.079077684751121

Epoch: 5| Step: 7
Training loss: 1.8425953388214111
Validation loss: 2.0618462152378534

Epoch: 5| Step: 8
Training loss: 2.0479815006256104
Validation loss: 2.0674958523883613

Epoch: 5| Step: 9
Training loss: 1.5148578882217407
Validation loss: 2.0813448864926576

Epoch: 5| Step: 10
Training loss: 1.3680552244186401
Validation loss: 2.0953870281096427

Epoch: 241| Step: 0
Training loss: 2.1162056922912598
Validation loss: 2.0562643312638804

Epoch: 5| Step: 1
Training loss: 2.1356425285339355
Validation loss: 2.086606844778984

Epoch: 5| Step: 2
Training loss: 1.4262679815292358
Validation loss: 2.0749037060686337

Epoch: 5| Step: 3
Training loss: 2.7407941818237305
Validation loss: 2.049993554751078

Epoch: 5| Step: 4
Training loss: 2.072650194168091
Validation loss: 2.1134905071668726

Epoch: 5| Step: 5
Training loss: 2.2607388496398926
Validation loss: 2.1462929402628252

Epoch: 5| Step: 6
Training loss: 2.0544400215148926
Validation loss: 2.137980334220394

Epoch: 5| Step: 7
Training loss: 2.601985216140747
Validation loss: 2.07883011141131

Epoch: 5| Step: 8
Training loss: 2.183568000793457
Validation loss: 2.098569372648834

Epoch: 5| Step: 9
Training loss: 0.9971687197685242
Validation loss: 2.111956839920372

Epoch: 5| Step: 10
Training loss: 1.9459576606750488
Validation loss: 2.0747300527429067

Epoch: 242| Step: 0
Training loss: 2.279710292816162
Validation loss: 2.0576222481266147

Epoch: 5| Step: 1
Training loss: 1.8463926315307617
Validation loss: 2.047415497482464

Epoch: 5| Step: 2
Training loss: 2.6207680702209473
Validation loss: 2.0450708699482743

Epoch: 5| Step: 3
Training loss: 2.4099955558776855
Validation loss: 2.1107611579279744

Epoch: 5| Step: 4
Training loss: 2.111875057220459
Validation loss: 2.120028567570512

Epoch: 5| Step: 5
Training loss: 1.8601239919662476
Validation loss: 2.0829196860713344

Epoch: 5| Step: 6
Training loss: 2.652979612350464
Validation loss: 2.064520970467598

Epoch: 5| Step: 7
Training loss: 1.8579130172729492
Validation loss: 2.0907437083541707

Epoch: 5| Step: 8
Training loss: 1.7253468036651611
Validation loss: 2.09763309519778

Epoch: 5| Step: 9
Training loss: 1.337571620941162
Validation loss: 2.0973224870620237

Epoch: 5| Step: 10
Training loss: 1.9949594736099243
Validation loss: 2.1011500204763105

Epoch: 243| Step: 0
Training loss: 2.256699562072754
Validation loss: 2.082817633946737

Epoch: 5| Step: 1
Training loss: 1.9245017766952515
Validation loss: 2.105279025211129

Epoch: 5| Step: 2
Training loss: 1.9422829151153564
Validation loss: 2.1154942345875565

Epoch: 5| Step: 3
Training loss: 2.8188600540161133
Validation loss: 2.115116306530532

Epoch: 5| Step: 4
Training loss: 1.8457167148590088
Validation loss: 2.078546266401968

Epoch: 5| Step: 5
Training loss: 2.3033406734466553
Validation loss: 2.0668414074887513

Epoch: 5| Step: 6
Training loss: 1.6253678798675537
Validation loss: 2.0845500756335515

Epoch: 5| Step: 7
Training loss: 1.4538352489471436
Validation loss: 2.1092945888478267

Epoch: 5| Step: 8
Training loss: 2.1196115016937256
Validation loss: 2.0654574542917232

Epoch: 5| Step: 9
Training loss: 2.213484764099121
Validation loss: 2.1162451685115857

Epoch: 5| Step: 10
Training loss: 1.9920458793640137
Validation loss: 2.0777125563672794

Epoch: 244| Step: 0
Training loss: 2.4450900554656982
Validation loss: 2.0444920960293023

Epoch: 5| Step: 1
Training loss: 1.6479346752166748
Validation loss: 2.0476524727318877

Epoch: 5| Step: 2
Training loss: 1.9065618515014648
Validation loss: 2.076373812972858

Epoch: 5| Step: 3
Training loss: 1.9549509286880493
Validation loss: 2.073938064677741

Epoch: 5| Step: 4
Training loss: 1.7960551977157593
Validation loss: 2.107168951342183

Epoch: 5| Step: 5
Training loss: 2.0963852405548096
Validation loss: 2.0776407898113294

Epoch: 5| Step: 6
Training loss: 2.38163423538208
Validation loss: 2.0713064388562272

Epoch: 5| Step: 7
Training loss: 1.8859771490097046
Validation loss: 2.0673347570562877

Epoch: 5| Step: 8
Training loss: 2.2916786670684814
Validation loss: 2.0524855941854496

Epoch: 5| Step: 9
Training loss: 1.8334802389144897
Validation loss: 2.088174917364633

Epoch: 5| Step: 10
Training loss: 2.179511070251465
Validation loss: 2.0927063534336705

Epoch: 245| Step: 0
Training loss: 2.1293561458587646
Validation loss: 2.0752039263325353

Epoch: 5| Step: 1
Training loss: 1.9545173645019531
Validation loss: 2.0521141585483345

Epoch: 5| Step: 2
Training loss: 1.956435203552246
Validation loss: 2.1258618677816083

Epoch: 5| Step: 3
Training loss: 2.451625108718872
Validation loss: 2.0706386514889297

Epoch: 5| Step: 4
Training loss: 1.9086925983428955
Validation loss: 2.087817120295699

Epoch: 5| Step: 5
Training loss: 1.8198391199111938
Validation loss: 2.0820593372468026

Epoch: 5| Step: 6
Training loss: 1.6731640100479126
Validation loss: 2.0681625027810373

Epoch: 5| Step: 7
Training loss: 1.8529455661773682
Validation loss: 2.062441364411385

Epoch: 5| Step: 8
Training loss: 2.1998775005340576
Validation loss: 2.06749471797738

Epoch: 5| Step: 9
Training loss: 2.5082695484161377
Validation loss: 2.061850901572935

Epoch: 5| Step: 10
Training loss: 2.192141532897949
Validation loss: 2.1165808580254994

Epoch: 246| Step: 0
Training loss: 2.501404285430908
Validation loss: 2.1124818965952885

Epoch: 5| Step: 1
Training loss: 1.9229192733764648
Validation loss: 2.102137550230949

Epoch: 5| Step: 2
Training loss: 1.4639136791229248
Validation loss: 2.1274627049764

Epoch: 5| Step: 3
Training loss: 1.693399429321289
Validation loss: 2.1024835314801944

Epoch: 5| Step: 4
Training loss: 2.2203595638275146
Validation loss: 2.0930614266344296

Epoch: 5| Step: 5
Training loss: 2.1304125785827637
Validation loss: 2.0659440871207946

Epoch: 5| Step: 6
Training loss: 2.1804604530334473
Validation loss: 2.0409214150521064

Epoch: 5| Step: 7
Training loss: 2.8040435314178467
Validation loss: 2.123220834680783

Epoch: 5| Step: 8
Training loss: 1.6670501232147217
Validation loss: 2.0572871879864763

Epoch: 5| Step: 9
Training loss: 1.6831386089324951
Validation loss: 2.1430133734979937

Epoch: 5| Step: 10
Training loss: 2.2145252227783203
Validation loss: 2.093323364052721

Epoch: 247| Step: 0
Training loss: 2.310652732849121
Validation loss: 2.0871684192329325

Epoch: 5| Step: 1
Training loss: 1.739511489868164
Validation loss: 2.1107656186626804

Epoch: 5| Step: 2
Training loss: 2.105351209640503
Validation loss: 2.1417955326777633

Epoch: 5| Step: 3
Training loss: 1.4781744480133057
Validation loss: 2.0836665822613623

Epoch: 5| Step: 4
Training loss: 2.504350185394287
Validation loss: 2.0669864723759312

Epoch: 5| Step: 5
Training loss: 2.164700984954834
Validation loss: 2.12381753870236

Epoch: 5| Step: 6
Training loss: 1.5718748569488525
Validation loss: 2.091091171387703

Epoch: 5| Step: 7
Training loss: 2.2083826065063477
Validation loss: 2.1179023993912565

Epoch: 5| Step: 8
Training loss: 1.2607780694961548
Validation loss: 2.1065548389188704

Epoch: 5| Step: 9
Training loss: 2.481325149536133
Validation loss: 2.0925482473065777

Epoch: 5| Step: 10
Training loss: 2.9655518531799316
Validation loss: 2.0847240237779516

Epoch: 248| Step: 0
Training loss: 1.812936782836914
Validation loss: 2.0938032750160462

Epoch: 5| Step: 1
Training loss: 2.2854199409484863
Validation loss: 2.13625398758919

Epoch: 5| Step: 2
Training loss: 2.4061942100524902
Validation loss: 2.046462551239998

Epoch: 5| Step: 3
Training loss: 1.9640718698501587
Validation loss: 2.0935782360774216

Epoch: 5| Step: 4
Training loss: 2.5679123401641846
Validation loss: 2.1370040396208405

Epoch: 5| Step: 5
Training loss: 1.9910236597061157
Validation loss: 2.123129924138387

Epoch: 5| Step: 6
Training loss: 1.3004127740859985
Validation loss: 2.1230466519632647

Epoch: 5| Step: 7
Training loss: 1.9970163106918335
Validation loss: 2.1344064435651227

Epoch: 5| Step: 8
Training loss: 2.691990613937378
Validation loss: 2.1016432508345573

Epoch: 5| Step: 9
Training loss: 1.5046218633651733
Validation loss: 2.106958655900853

Epoch: 5| Step: 10
Training loss: 2.2965800762176514
Validation loss: 2.138021082006475

Epoch: 249| Step: 0
Training loss: 2.3263702392578125
Validation loss: 2.0411857622925953

Epoch: 5| Step: 1
Training loss: 2.3401992321014404
Validation loss: 2.1145986767225367

Epoch: 5| Step: 2
Training loss: 1.814223289489746
Validation loss: 2.1365804415877148

Epoch: 5| Step: 3
Training loss: 2.491551160812378
Validation loss: 2.0803506887087257

Epoch: 5| Step: 4
Training loss: 1.4400875568389893
Validation loss: 2.1664003018409974

Epoch: 5| Step: 5
Training loss: 2.249966859817505
Validation loss: 2.106127287751885

Epoch: 5| Step: 6
Training loss: 2.649209499359131
Validation loss: 2.1001903164771294

Epoch: 5| Step: 7
Training loss: 1.4818389415740967
Validation loss: 2.1214974836636613

Epoch: 5| Step: 8
Training loss: 1.8829495906829834
Validation loss: 2.0892982457273748

Epoch: 5| Step: 9
Training loss: 1.917069673538208
Validation loss: 2.0470686753590903

Epoch: 5| Step: 10
Training loss: 1.8398016691207886
Validation loss: 2.075723453234601

Epoch: 250| Step: 0
Training loss: 1.9064878225326538
Validation loss: 2.1046655536979757

Epoch: 5| Step: 1
Training loss: 1.566576361656189
Validation loss: 2.097223269042148

Epoch: 5| Step: 2
Training loss: 1.871169090270996
Validation loss: 2.072002257070234

Epoch: 5| Step: 3
Training loss: 1.918163537979126
Validation loss: 2.0899151909735894

Epoch: 5| Step: 4
Training loss: 3.1542153358459473
Validation loss: 2.089442535113263

Epoch: 5| Step: 5
Training loss: 1.4662991762161255
Validation loss: 2.0831464887947164

Epoch: 5| Step: 6
Training loss: 1.9480068683624268
Validation loss: 2.055161194134784

Epoch: 5| Step: 7
Training loss: 3.308603286743164
Validation loss: 2.1144165544099707

Epoch: 5| Step: 8
Training loss: 2.1740708351135254
Validation loss: 2.091955518209806

Epoch: 5| Step: 9
Training loss: 1.4592713117599487
Validation loss: 2.1088701012314006

Epoch: 5| Step: 10
Training loss: 2.0450544357299805
Validation loss: 2.079434960119186

Epoch: 251| Step: 0
Training loss: 2.1360690593719482
Validation loss: 2.0793874597036712

Epoch: 5| Step: 1
Training loss: 2.539440155029297
Validation loss: 2.096214857152713

Epoch: 5| Step: 2
Training loss: 1.8571832180023193
Validation loss: 2.0574937635852444

Epoch: 5| Step: 3
Training loss: 2.6230061054229736
Validation loss: 2.0652540511982416

Epoch: 5| Step: 4
Training loss: 1.3527390956878662
Validation loss: 2.0505464653814993

Epoch: 5| Step: 5
Training loss: 2.179011344909668
Validation loss: 2.063090729457076

Epoch: 5| Step: 6
Training loss: 1.7302868366241455
Validation loss: 2.0628202615245694

Epoch: 5| Step: 7
Training loss: 1.8210303783416748
Validation loss: 2.0943319618061023

Epoch: 5| Step: 8
Training loss: 2.523268461227417
Validation loss: 2.0814485883200042

Epoch: 5| Step: 9
Training loss: 1.8856942653656006
Validation loss: 2.0608312865739227

Epoch: 5| Step: 10
Training loss: 1.9889205694198608
Validation loss: 2.0944716481752295

Epoch: 252| Step: 0
Training loss: 1.8241958618164062
Validation loss: 2.0751767261053926

Epoch: 5| Step: 1
Training loss: 1.8168227672576904
Validation loss: 2.0534842296313216

Epoch: 5| Step: 2
Training loss: 2.57586932182312
Validation loss: 2.093808295906231

Epoch: 5| Step: 3
Training loss: 1.9770694971084595
Validation loss: 2.073002653737222

Epoch: 5| Step: 4
Training loss: 1.9084526300430298
Validation loss: 2.092320637036395

Epoch: 5| Step: 5
Training loss: 2.213958263397217
Validation loss: 2.122740750671715

Epoch: 5| Step: 6
Training loss: 2.0071656703948975
Validation loss: 2.105822468316683

Epoch: 5| Step: 7
Training loss: 2.2528576850891113
Validation loss: 2.096675927921008

Epoch: 5| Step: 8
Training loss: 2.119356155395508
Validation loss: 2.182652114540018

Epoch: 5| Step: 9
Training loss: 1.3516136407852173
Validation loss: 2.094343295661352

Epoch: 5| Step: 10
Training loss: 2.1553051471710205
Validation loss: 2.1306681709904827

Epoch: 253| Step: 0
Training loss: 2.4745917320251465
Validation loss: 2.090393545807049

Epoch: 5| Step: 1
Training loss: 1.5985066890716553
Validation loss: 2.113768046902072

Epoch: 5| Step: 2
Training loss: 1.4927964210510254
Validation loss: 2.097503505727296

Epoch: 5| Step: 3
Training loss: 1.901419997215271
Validation loss: 2.101607584184216

Epoch: 5| Step: 4
Training loss: 2.1109538078308105
Validation loss: 2.1383710740714945

Epoch: 5| Step: 5
Training loss: 1.77780282497406
Validation loss: 2.07893136624367

Epoch: 5| Step: 6
Training loss: 2.080169677734375
Validation loss: 2.1011028020612654

Epoch: 5| Step: 7
Training loss: 2.519803524017334
Validation loss: 2.062034422351468

Epoch: 5| Step: 8
Training loss: 2.32246470451355
Validation loss: 2.0478273284050728

Epoch: 5| Step: 9
Training loss: 2.2123045921325684
Validation loss: 2.0953924681550715

Epoch: 5| Step: 10
Training loss: 1.678553819656372
Validation loss: 2.078829919138262

Epoch: 254| Step: 0
Training loss: 2.654608726501465
Validation loss: 2.039162201266135

Epoch: 5| Step: 1
Training loss: 1.4361671209335327
Validation loss: 2.056289456223929

Epoch: 5| Step: 2
Training loss: 2.096999406814575
Validation loss: 2.033885343100435

Epoch: 5| Step: 3
Training loss: 2.0009167194366455
Validation loss: 2.0962739272784163

Epoch: 5| Step: 4
Training loss: 1.9968082904815674
Validation loss: 2.0951146874376523

Epoch: 5| Step: 5
Training loss: 2.0718655586242676
Validation loss: 2.0522500981566725

Epoch: 5| Step: 6
Training loss: 1.925502061843872
Validation loss: 2.057153650509414

Epoch: 5| Step: 7
Training loss: 2.1909337043762207
Validation loss: 2.049775767069991

Epoch: 5| Step: 8
Training loss: 1.6698856353759766
Validation loss: 2.086715030413802

Epoch: 5| Step: 9
Training loss: 1.8052051067352295
Validation loss: 2.0362292207697386

Epoch: 5| Step: 10
Training loss: 2.267448902130127
Validation loss: 2.0666526927742908

Epoch: 255| Step: 0
Training loss: 2.208880662918091
Validation loss: 2.055385381944718

Epoch: 5| Step: 1
Training loss: 1.836316704750061
Validation loss: 2.1232746390886206

Epoch: 5| Step: 2
Training loss: 1.5551795959472656
Validation loss: 2.059608406918023

Epoch: 5| Step: 3
Training loss: 1.7778675556182861
Validation loss: 2.0617961140089136

Epoch: 5| Step: 4
Training loss: 2.7325921058654785
Validation loss: 2.0623385226854714

Epoch: 5| Step: 5
Training loss: 2.023653030395508
Validation loss: 2.0582734718117663

Epoch: 5| Step: 6
Training loss: 2.09865140914917
Validation loss: 2.0742562970807477

Epoch: 5| Step: 7
Training loss: 2.213301420211792
Validation loss: 2.0918127182991273

Epoch: 5| Step: 8
Training loss: 1.932189702987671
Validation loss: 2.0625655804910967

Epoch: 5| Step: 9
Training loss: 1.8845103979110718
Validation loss: 2.134654265578075

Epoch: 5| Step: 10
Training loss: 2.347459316253662
Validation loss: 2.108734530787314

Epoch: 256| Step: 0
Training loss: 1.6894038915634155
Validation loss: 2.0406824311902447

Epoch: 5| Step: 1
Training loss: 1.930261254310608
Validation loss: 2.1383814068250757

Epoch: 5| Step: 2
Training loss: 1.9052680730819702
Validation loss: 2.1221675488256637

Epoch: 5| Step: 3
Training loss: 1.8447320461273193
Validation loss: 2.0870076661468833

Epoch: 5| Step: 4
Training loss: 1.6419214010238647
Validation loss: 2.082914703635759

Epoch: 5| Step: 5
Training loss: 2.4923977851867676
Validation loss: 2.075153011147694

Epoch: 5| Step: 6
Training loss: 2.1170477867126465
Validation loss: 2.1312287430609427

Epoch: 5| Step: 7
Training loss: 1.8598991632461548
Validation loss: 2.0637965856059903

Epoch: 5| Step: 8
Training loss: 1.7317968606948853
Validation loss: 2.09865818741501

Epoch: 5| Step: 9
Training loss: 2.2186684608459473
Validation loss: 2.079514636788317

Epoch: 5| Step: 10
Training loss: 2.897404432296753
Validation loss: 2.128376522371846

Epoch: 257| Step: 0
Training loss: 1.971165418624878
Validation loss: 2.130938809405091

Epoch: 5| Step: 1
Training loss: 1.329099178314209
Validation loss: 2.0890139328536166

Epoch: 5| Step: 2
Training loss: 1.7813663482666016
Validation loss: 2.091600005344678

Epoch: 5| Step: 3
Training loss: 2.0205254554748535
Validation loss: 2.0803965060941634

Epoch: 5| Step: 4
Training loss: 2.8253443241119385
Validation loss: 2.0769209067026773

Epoch: 5| Step: 5
Training loss: 2.421396255493164
Validation loss: 2.114748485626713

Epoch: 5| Step: 6
Training loss: 2.170444965362549
Validation loss: 2.0091008806741364

Epoch: 5| Step: 7
Training loss: 1.9613348245620728
Validation loss: 2.116525652588055

Epoch: 5| Step: 8
Training loss: 2.2145276069641113
Validation loss: 2.0670751102509035

Epoch: 5| Step: 9
Training loss: 1.99712336063385
Validation loss: 2.1169170397584156

Epoch: 5| Step: 10
Training loss: 1.6969077587127686
Validation loss: 2.1392554031905306

Epoch: 258| Step: 0
Training loss: 2.657219409942627
Validation loss: 2.0806331070520545

Epoch: 5| Step: 1
Training loss: 1.5506184101104736
Validation loss: 2.0403965609048003

Epoch: 5| Step: 2
Training loss: 2.4162778854370117
Validation loss: 2.0347037443550686

Epoch: 5| Step: 3
Training loss: 1.9442813396453857
Validation loss: 2.0742677706544117

Epoch: 5| Step: 4
Training loss: 2.0963802337646484
Validation loss: 2.1050413116332023

Epoch: 5| Step: 5
Training loss: 1.7249199151992798
Validation loss: 2.1373410045459704

Epoch: 5| Step: 6
Training loss: 1.8012993335723877
Validation loss: 2.133185177721003

Epoch: 5| Step: 7
Training loss: 2.2084765434265137
Validation loss: 2.0930532486208024

Epoch: 5| Step: 8
Training loss: 2.2266788482666016
Validation loss: 2.0661376086614465

Epoch: 5| Step: 9
Training loss: 1.560190200805664
Validation loss: 2.117613225854853

Epoch: 5| Step: 10
Training loss: 2.2315735816955566
Validation loss: 2.0762524374069704

Epoch: 259| Step: 0
Training loss: 1.7997856140136719
Validation loss: 2.1201335191726685

Epoch: 5| Step: 1
Training loss: 2.1251606941223145
Validation loss: 2.0760913869386077

Epoch: 5| Step: 2
Training loss: 2.1398916244506836
Validation loss: 2.0687700266479165

Epoch: 5| Step: 3
Training loss: 1.4852269887924194
Validation loss: 2.100541541653295

Epoch: 5| Step: 4
Training loss: 2.3426806926727295
Validation loss: 2.1018617563350226

Epoch: 5| Step: 5
Training loss: 2.279916286468506
Validation loss: 2.102038069437909

Epoch: 5| Step: 6
Training loss: 1.6556024551391602
Validation loss: 2.079784624038204

Epoch: 5| Step: 7
Training loss: 2.4732396602630615
Validation loss: 2.0777844716143865

Epoch: 5| Step: 8
Training loss: 1.6224828958511353
Validation loss: 2.0993140794897593

Epoch: 5| Step: 9
Training loss: 1.5542222261428833
Validation loss: 2.096136253367188

Epoch: 5| Step: 10
Training loss: 2.4519295692443848
Validation loss: 2.1315208891386628

Epoch: 260| Step: 0
Training loss: 1.1628085374832153
Validation loss: 2.1414309573429886

Epoch: 5| Step: 1
Training loss: 2.120209217071533
Validation loss: 2.098692246662673

Epoch: 5| Step: 2
Training loss: 2.1520187854766846
Validation loss: 2.07324267074626

Epoch: 5| Step: 3
Training loss: 1.5334137678146362
Validation loss: 2.095658286925285

Epoch: 5| Step: 4
Training loss: 2.0817084312438965
Validation loss: 2.0562474958358274

Epoch: 5| Step: 5
Training loss: 2.7193474769592285
Validation loss: 2.1206317793938423

Epoch: 5| Step: 6
Training loss: 2.1118788719177246
Validation loss: 2.1150219966006536

Epoch: 5| Step: 7
Training loss: 2.374560832977295
Validation loss: 2.095128890006773

Epoch: 5| Step: 8
Training loss: 1.8284984827041626
Validation loss: 2.0801782646486835

Epoch: 5| Step: 9
Training loss: 2.7102553844451904
Validation loss: 2.1019802157596876

Epoch: 5| Step: 10
Training loss: 1.4257895946502686
Validation loss: 2.137921082076206

Epoch: 261| Step: 0
Training loss: 1.6835482120513916
Validation loss: 2.047917504464426

Epoch: 5| Step: 1
Training loss: 2.1825850009918213
Validation loss: 2.10526402150431

Epoch: 5| Step: 2
Training loss: 2.341297149658203
Validation loss: 2.102689557178046

Epoch: 5| Step: 3
Training loss: 2.484642505645752
Validation loss: 2.039102251811694

Epoch: 5| Step: 4
Training loss: 1.786527395248413
Validation loss: 2.0677189275782597

Epoch: 5| Step: 5
Training loss: 2.3617515563964844
Validation loss: 2.079947115272604

Epoch: 5| Step: 6
Training loss: 2.229983329772949
Validation loss: 2.06032387415568

Epoch: 5| Step: 7
Training loss: 1.8515468835830688
Validation loss: 2.1051998394791798

Epoch: 5| Step: 8
Training loss: 1.7848182916641235
Validation loss: 2.1188066249252646

Epoch: 5| Step: 9
Training loss: 1.7977502346038818
Validation loss: 2.048993429829997

Epoch: 5| Step: 10
Training loss: 1.90543794631958
Validation loss: 2.0314172057695288

Epoch: 262| Step: 0
Training loss: 2.2505314350128174
Validation loss: 2.10268666667323

Epoch: 5| Step: 1
Training loss: 2.4101810455322266
Validation loss: 2.1273568009817474

Epoch: 5| Step: 2
Training loss: 2.32340407371521
Validation loss: 2.0597869721792077

Epoch: 5| Step: 3
Training loss: 1.684037446975708
Validation loss: 2.0802844288528606

Epoch: 5| Step: 4
Training loss: 1.5461814403533936
Validation loss: 2.0734764158084826

Epoch: 5| Step: 5
Training loss: 1.8345861434936523
Validation loss: 2.0839754343032837

Epoch: 5| Step: 6
Training loss: 1.6996265649795532
Validation loss: 2.0871229069207304

Epoch: 5| Step: 7
Training loss: 2.109999656677246
Validation loss: 2.126696253335604

Epoch: 5| Step: 8
Training loss: 2.1040477752685547
Validation loss: 2.0648072560628257

Epoch: 5| Step: 9
Training loss: 2.2057547569274902
Validation loss: 2.101305136116602

Epoch: 5| Step: 10
Training loss: 1.6976087093353271
Validation loss: 2.0739330848058066

Epoch: 263| Step: 0
Training loss: 1.6915953159332275
Validation loss: 2.090961548589891

Epoch: 5| Step: 1
Training loss: 2.0346968173980713
Validation loss: 2.085317729621805

Epoch: 5| Step: 2
Training loss: 1.4483829736709595
Validation loss: 2.0560646377583986

Epoch: 5| Step: 3
Training loss: 2.128720760345459
Validation loss: 2.016814139581496

Epoch: 5| Step: 4
Training loss: 1.9717941284179688
Validation loss: 2.0462977296562603

Epoch: 5| Step: 5
Training loss: 2.8503506183624268
Validation loss: 2.068615392972064

Epoch: 5| Step: 6
Training loss: 2.6911401748657227
Validation loss: 2.0942187539992796

Epoch: 5| Step: 7
Training loss: 2.0769476890563965
Validation loss: 2.108482596694782

Epoch: 5| Step: 8
Training loss: 2.1947569847106934
Validation loss: 2.048351046859577

Epoch: 5| Step: 9
Training loss: 2.111445426940918
Validation loss: 2.063972206525905

Epoch: 5| Step: 10
Training loss: 1.3130441904067993
Validation loss: 2.0466585108028945

Epoch: 264| Step: 0
Training loss: 2.613797664642334
Validation loss: 2.112013946297348

Epoch: 5| Step: 1
Training loss: 2.067964792251587
Validation loss: 2.11239129753523

Epoch: 5| Step: 2
Training loss: 1.6778854131698608
Validation loss: 2.0977094288795226

Epoch: 5| Step: 3
Training loss: 1.9011523723602295
Validation loss: 2.08377642016257

Epoch: 5| Step: 4
Training loss: 2.015338182449341
Validation loss: 2.107903403620566

Epoch: 5| Step: 5
Training loss: 1.4978456497192383
Validation loss: 2.131005781953053

Epoch: 5| Step: 6
Training loss: 2.221762180328369
Validation loss: 2.1459984907539944

Epoch: 5| Step: 7
Training loss: 1.7980291843414307
Validation loss: 2.0960989152231524

Epoch: 5| Step: 8
Training loss: 2.0834810733795166
Validation loss: 2.0977431061447307

Epoch: 5| Step: 9
Training loss: 2.0146689414978027
Validation loss: 2.1243146888671385

Epoch: 5| Step: 10
Training loss: 2.502833604812622
Validation loss: 2.132849888135028

Epoch: 265| Step: 0
Training loss: 1.8783515691757202
Validation loss: 2.100828634795322

Epoch: 5| Step: 1
Training loss: 1.8360837697982788
Validation loss: 2.129880537268936

Epoch: 5| Step: 2
Training loss: 2.512237071990967
Validation loss: 2.102783864544284

Epoch: 5| Step: 3
Training loss: 2.7441086769104004
Validation loss: 2.1216054834345335

Epoch: 5| Step: 4
Training loss: 1.4968949556350708
Validation loss: 2.0760179591435257

Epoch: 5| Step: 5
Training loss: 1.8730624914169312
Validation loss: 2.1275534655458186

Epoch: 5| Step: 6
Training loss: 1.7575000524520874
Validation loss: 2.1089635202961583

Epoch: 5| Step: 7
Training loss: 2.129286527633667
Validation loss: 2.061458264627764

Epoch: 5| Step: 8
Training loss: 2.5476086139678955
Validation loss: 2.091143291483643

Epoch: 5| Step: 9
Training loss: 1.7419970035552979
Validation loss: 2.1199613822403776

Epoch: 5| Step: 10
Training loss: 1.495713472366333
Validation loss: 2.098910093307495

Epoch: 266| Step: 0
Training loss: 2.3199563026428223
Validation loss: 2.1035052525099887

Epoch: 5| Step: 1
Training loss: 1.821743369102478
Validation loss: 2.114859163120229

Epoch: 5| Step: 2
Training loss: 2.425656795501709
Validation loss: 2.0661663137456423

Epoch: 5| Step: 3
Training loss: 1.8782402276992798
Validation loss: 2.120743804080512

Epoch: 5| Step: 4
Training loss: 1.3368656635284424
Validation loss: 2.0865074126951155

Epoch: 5| Step: 5
Training loss: 2.108086109161377
Validation loss: 2.1209694172746394

Epoch: 5| Step: 6
Training loss: 2.5303945541381836
Validation loss: 2.092401022552162

Epoch: 5| Step: 7
Training loss: 1.9810329675674438
Validation loss: 2.175921704179497

Epoch: 5| Step: 8
Training loss: 1.840539574623108
Validation loss: 2.112979527442686

Epoch: 5| Step: 9
Training loss: 1.7611995935440063
Validation loss: 2.1212204579384095

Epoch: 5| Step: 10
Training loss: 2.227515459060669
Validation loss: 2.122007942968799

Epoch: 267| Step: 0
Training loss: 2.05281138420105
Validation loss: 2.100294792523948

Epoch: 5| Step: 1
Training loss: 1.6102259159088135
Validation loss: 2.1401008213720014

Epoch: 5| Step: 2
Training loss: 1.8796710968017578
Validation loss: 2.0969202031371412

Epoch: 5| Step: 3
Training loss: 2.689070463180542
Validation loss: 2.080220571128271

Epoch: 5| Step: 4
Training loss: 1.83743155002594
Validation loss: 2.07481877521802

Epoch: 5| Step: 5
Training loss: 1.7222692966461182
Validation loss: 2.140325020718318

Epoch: 5| Step: 6
Training loss: 1.7401012182235718
Validation loss: 2.097846528535248

Epoch: 5| Step: 7
Training loss: 2.089095115661621
Validation loss: 2.088788124822801

Epoch: 5| Step: 8
Training loss: 1.9298861026763916
Validation loss: 2.1367127972264446

Epoch: 5| Step: 9
Training loss: 2.0910255908966064
Validation loss: 2.141994014863045

Epoch: 5| Step: 10
Training loss: 2.1352343559265137
Validation loss: 2.087881741985198

Epoch: 268| Step: 0
Training loss: 1.3767249584197998
Validation loss: 2.0976864214866393

Epoch: 5| Step: 1
Training loss: 2.20007586479187
Validation loss: 2.0881716717955885

Epoch: 5| Step: 2
Training loss: 2.3501763343811035
Validation loss: 2.103001143342705

Epoch: 5| Step: 3
Training loss: 2.0259714126586914
Validation loss: 2.117197267470821

Epoch: 5| Step: 4
Training loss: 1.7452049255371094
Validation loss: 2.085995074241392

Epoch: 5| Step: 5
Training loss: 2.027083158493042
Validation loss: 2.077492638300824

Epoch: 5| Step: 6
Training loss: 1.8390133380889893
Validation loss: 2.088705814012917

Epoch: 5| Step: 7
Training loss: 2.3533616065979004
Validation loss: 2.122059909246301

Epoch: 5| Step: 8
Training loss: 2.363677501678467
Validation loss: 2.092814172467878

Epoch: 5| Step: 9
Training loss: 1.7294620275497437
Validation loss: 2.128867005789152

Epoch: 5| Step: 10
Training loss: 2.4169528484344482
Validation loss: 2.0799612370870446

Epoch: 269| Step: 0
Training loss: 2.3676838874816895
Validation loss: 2.1275851418895106

Epoch: 5| Step: 1
Training loss: 2.356703996658325
Validation loss: 2.064348009324843

Epoch: 5| Step: 2
Training loss: 2.723203182220459
Validation loss: 2.1147363211518977

Epoch: 5| Step: 3
Training loss: 1.5915758609771729
Validation loss: 2.0952626812842583

Epoch: 5| Step: 4
Training loss: 2.423586368560791
Validation loss: 2.115282856008058

Epoch: 5| Step: 5
Training loss: 2.0172276496887207
Validation loss: 2.0684692641740203

Epoch: 5| Step: 6
Training loss: 2.61088490486145
Validation loss: 2.117739139064666

Epoch: 5| Step: 7
Training loss: 1.2201917171478271
Validation loss: 2.1053136881961616

Epoch: 5| Step: 8
Training loss: 1.892848253250122
Validation loss: 2.049272221903647

Epoch: 5| Step: 9
Training loss: 1.536784052848816
Validation loss: 2.067889203307449

Epoch: 5| Step: 10
Training loss: 1.5336307287216187
Validation loss: 2.112077013138802

Epoch: 270| Step: 0
Training loss: 2.0758469104766846
Validation loss: 2.0805634593450897

Epoch: 5| Step: 1
Training loss: 1.90060293674469
Validation loss: 2.097127435027912

Epoch: 5| Step: 2
Training loss: 1.6623179912567139
Validation loss: 2.061360313046363

Epoch: 5| Step: 3
Training loss: 2.4488582611083984
Validation loss: 2.084485588535186

Epoch: 5| Step: 4
Training loss: 1.6235967874526978
Validation loss: 2.0667515852118052

Epoch: 5| Step: 5
Training loss: 1.9380710124969482
Validation loss: 2.103049962751327

Epoch: 5| Step: 6
Training loss: 2.3024814128875732
Validation loss: 2.0820608100583478

Epoch: 5| Step: 7
Training loss: 3.4024910926818848
Validation loss: 2.075425350537864

Epoch: 5| Step: 8
Training loss: 1.558922529220581
Validation loss: 2.0421085280756794

Epoch: 5| Step: 9
Training loss: 1.7355905771255493
Validation loss: 2.0945125382433654

Epoch: 5| Step: 10
Training loss: 1.095571517944336
Validation loss: 2.108447051817371

Epoch: 271| Step: 0
Training loss: 1.313499093055725
Validation loss: 2.1096740820074595

Epoch: 5| Step: 1
Training loss: 2.6389272212982178
Validation loss: 2.11386106347525

Epoch: 5| Step: 2
Training loss: 2.616718292236328
Validation loss: 2.131205097321541

Epoch: 5| Step: 3
Training loss: 1.6807540655136108
Validation loss: 2.098230852875658

Epoch: 5| Step: 4
Training loss: 1.8451530933380127
Validation loss: 2.102790412082467

Epoch: 5| Step: 5
Training loss: 2.260101318359375
Validation loss: 2.0860783874347644

Epoch: 5| Step: 6
Training loss: 2.456176280975342
Validation loss: 2.0903834835175545

Epoch: 5| Step: 7
Training loss: 1.513979196548462
Validation loss: 2.111897871058474

Epoch: 5| Step: 8
Training loss: 1.7475166320800781
Validation loss: 2.138322235435568

Epoch: 5| Step: 9
Training loss: 2.1656181812286377
Validation loss: 2.0906241017003215

Epoch: 5| Step: 10
Training loss: 1.6416043043136597
Validation loss: 2.0847734123147945

Epoch: 272| Step: 0
Training loss: 1.503415822982788
Validation loss: 2.118676357371833

Epoch: 5| Step: 1
Training loss: 1.9475873708724976
Validation loss: 2.11385287392524

Epoch: 5| Step: 2
Training loss: 2.116243362426758
Validation loss: 2.101262923209898

Epoch: 5| Step: 3
Training loss: 2.580490827560425
Validation loss: 2.129616824529504

Epoch: 5| Step: 4
Training loss: 1.5528228282928467
Validation loss: 2.0805641476826002

Epoch: 5| Step: 5
Training loss: 2.418671131134033
Validation loss: 2.09735688342843

Epoch: 5| Step: 6
Training loss: 2.372715711593628
Validation loss: 2.081543348168814

Epoch: 5| Step: 7
Training loss: 1.0754388570785522
Validation loss: 2.1010453854837725

Epoch: 5| Step: 8
Training loss: 2.144347906112671
Validation loss: 2.0886599966274795

Epoch: 5| Step: 9
Training loss: 2.256105899810791
Validation loss: 2.0643024598398516

Epoch: 5| Step: 10
Training loss: 1.9397506713867188
Validation loss: 2.086425203149037

Epoch: 273| Step: 0
Training loss: 2.209493637084961
Validation loss: 2.0576058497992893

Epoch: 5| Step: 1
Training loss: 1.7238813638687134
Validation loss: 2.0665142830982

Epoch: 5| Step: 2
Training loss: 1.6079715490341187
Validation loss: 2.0886797892150057

Epoch: 5| Step: 3
Training loss: 1.4896684885025024
Validation loss: 2.0996773576223724

Epoch: 5| Step: 4
Training loss: 2.217045307159424
Validation loss: 2.063172307065738

Epoch: 5| Step: 5
Training loss: 1.7500050067901611
Validation loss: 2.107144840302006

Epoch: 5| Step: 6
Training loss: 2.3936409950256348
Validation loss: 2.0640609572010655

Epoch: 5| Step: 7
Training loss: 2.2196288108825684
Validation loss: 2.114256940862184

Epoch: 5| Step: 8
Training loss: 1.6955015659332275
Validation loss: 2.130707909983973

Epoch: 5| Step: 9
Training loss: 2.7780394554138184
Validation loss: 2.095823044418007

Epoch: 5| Step: 10
Training loss: 1.8339831829071045
Validation loss: 2.0946672936921478

Epoch: 274| Step: 0
Training loss: 2.218968629837036
Validation loss: 2.1543458866816696

Epoch: 5| Step: 1
Training loss: 1.5909826755523682
Validation loss: 2.110732688698717

Epoch: 5| Step: 2
Training loss: 2.403290271759033
Validation loss: 2.050563702019312

Epoch: 5| Step: 3
Training loss: 1.4772335290908813
Validation loss: 2.1005384870754775

Epoch: 5| Step: 4
Training loss: 2.476686477661133
Validation loss: 2.097480845707719

Epoch: 5| Step: 5
Training loss: 1.394744634628296
Validation loss: 2.101100565284811

Epoch: 5| Step: 6
Training loss: 1.7700344324111938
Validation loss: 2.092454210404427

Epoch: 5| Step: 7
Training loss: 2.311328887939453
Validation loss: 2.1126462157054613

Epoch: 5| Step: 8
Training loss: 1.692826509475708
Validation loss: 2.079827675255396

Epoch: 5| Step: 9
Training loss: 2.1286563873291016
Validation loss: 2.1025523280584686

Epoch: 5| Step: 10
Training loss: 2.2891933917999268
Validation loss: 2.1124307622191725

Epoch: 275| Step: 0
Training loss: 1.2120659351348877
Validation loss: 2.072634555960214

Epoch: 5| Step: 1
Training loss: 2.161259889602661
Validation loss: 2.089785869403552

Epoch: 5| Step: 2
Training loss: 2.008918523788452
Validation loss: 2.0976096968497

Epoch: 5| Step: 3
Training loss: 2.170485734939575
Validation loss: 2.0976346295367003

Epoch: 5| Step: 4
Training loss: 2.0855438709259033
Validation loss: 2.141406815539124

Epoch: 5| Step: 5
Training loss: 1.7192977666854858
Validation loss: 2.081056874285462

Epoch: 5| Step: 6
Training loss: 2.3695294857025146
Validation loss: 2.063461740811666

Epoch: 5| Step: 7
Training loss: 1.9296867847442627
Validation loss: 2.1189309884143133

Epoch: 5| Step: 8
Training loss: 2.2383313179016113
Validation loss: 2.0937216679255166

Epoch: 5| Step: 9
Training loss: 1.931576132774353
Validation loss: 2.08367056615891

Epoch: 5| Step: 10
Training loss: 2.2089312076568604
Validation loss: 2.1453595520347677

Epoch: 276| Step: 0
Training loss: 2.1263022422790527
Validation loss: 2.1310148572409027

Epoch: 5| Step: 1
Training loss: 1.4259436130523682
Validation loss: 2.1251907566542267

Epoch: 5| Step: 2
Training loss: 1.7156713008880615
Validation loss: 2.1076830817807104

Epoch: 5| Step: 3
Training loss: 2.365725040435791
Validation loss: 2.0472697109304447

Epoch: 5| Step: 4
Training loss: 2.1764585971832275
Validation loss: 2.124091236822067

Epoch: 5| Step: 5
Training loss: 2.064178228378296
Validation loss: 2.1101390136185514

Epoch: 5| Step: 6
Training loss: 2.8894386291503906
Validation loss: 2.0955610211177538

Epoch: 5| Step: 7
Training loss: 1.9315452575683594
Validation loss: 2.1134915351867676

Epoch: 5| Step: 8
Training loss: 1.8651609420776367
Validation loss: 2.1289907219589397

Epoch: 5| Step: 9
Training loss: 1.9790254831314087
Validation loss: 2.0762601129470335

Epoch: 5| Step: 10
Training loss: 1.6459782123565674
Validation loss: 2.125841802166354

Epoch: 277| Step: 0
Training loss: 1.7813260555267334
Validation loss: 2.054805063432263

Epoch: 5| Step: 1
Training loss: 2.226849317550659
Validation loss: 2.1076330625882713

Epoch: 5| Step: 2
Training loss: 2.548591136932373
Validation loss: 2.085148093520954

Epoch: 5| Step: 3
Training loss: 1.8291298151016235
Validation loss: 2.0982978907964562

Epoch: 5| Step: 4
Training loss: 1.867500901222229
Validation loss: 2.11980652552779

Epoch: 5| Step: 5
Training loss: 1.7936265468597412
Validation loss: 2.124840969680458

Epoch: 5| Step: 6
Training loss: 2.627577543258667
Validation loss: 2.0989125069751533

Epoch: 5| Step: 7
Training loss: 1.6222217082977295
Validation loss: 2.083902023171866

Epoch: 5| Step: 8
Training loss: 1.6933562755584717
Validation loss: 2.0686012339848343

Epoch: 5| Step: 9
Training loss: 1.7683954238891602
Validation loss: 2.070771380137372

Epoch: 5| Step: 10
Training loss: 2.451111316680908
Validation loss: 2.0885118258896695

Epoch: 278| Step: 0
Training loss: 1.8070895671844482
Validation loss: 2.1320391496022544

Epoch: 5| Step: 1
Training loss: 1.8991056680679321
Validation loss: 2.0016577256623136

Epoch: 5| Step: 2
Training loss: 1.920779824256897
Validation loss: 2.0361461293312813

Epoch: 5| Step: 3
Training loss: 1.7981634140014648
Validation loss: 2.061459961757865

Epoch: 5| Step: 4
Training loss: 2.0074045658111572
Validation loss: 2.103798991890364

Epoch: 5| Step: 5
Training loss: 1.989938735961914
Validation loss: 2.0620943500149633

Epoch: 5| Step: 6
Training loss: 1.872206449508667
Validation loss: 2.1146244054199546

Epoch: 5| Step: 7
Training loss: 1.8926023244857788
Validation loss: 2.0958963696674635

Epoch: 5| Step: 8
Training loss: 2.450441837310791
Validation loss: 2.055732624505156

Epoch: 5| Step: 9
Training loss: 2.788132667541504
Validation loss: 2.0901614004565823

Epoch: 5| Step: 10
Training loss: 1.5665067434310913
Validation loss: 2.092551987658265

Epoch: 279| Step: 0
Training loss: 2.169442653656006
Validation loss: 2.1330739323810866

Epoch: 5| Step: 1
Training loss: 2.0915427207946777
Validation loss: 2.0895267327626548

Epoch: 5| Step: 2
Training loss: 2.0044429302215576
Validation loss: 2.089772044971425

Epoch: 5| Step: 3
Training loss: 2.0669665336608887
Validation loss: 2.0773699719418763

Epoch: 5| Step: 4
Training loss: 2.0188400745391846
Validation loss: 2.061625708815872

Epoch: 5| Step: 5
Training loss: 1.5410298109054565
Validation loss: 2.122225752440832

Epoch: 5| Step: 6
Training loss: 1.7193281650543213
Validation loss: 2.0566769056422736

Epoch: 5| Step: 7
Training loss: 2.0134518146514893
Validation loss: 2.0804985543733

Epoch: 5| Step: 8
Training loss: 2.517232656478882
Validation loss: 2.1319958356118973

Epoch: 5| Step: 9
Training loss: 1.9166752099990845
Validation loss: 2.102879665231192

Epoch: 5| Step: 10
Training loss: 2.194901466369629
Validation loss: 2.077425872125933

Epoch: 280| Step: 0
Training loss: 2.4214935302734375
Validation loss: 2.091997277352118

Epoch: 5| Step: 1
Training loss: 1.576960802078247
Validation loss: 2.082965640611546

Epoch: 5| Step: 2
Training loss: 2.243377923965454
Validation loss: 2.0702071702608498

Epoch: 5| Step: 3
Training loss: 2.5557808876037598
Validation loss: 2.0964811527600853

Epoch: 5| Step: 4
Training loss: 1.884408950805664
Validation loss: 2.0935056132654988

Epoch: 5| Step: 5
Training loss: 2.2219080924987793
Validation loss: 2.1354586129547446

Epoch: 5| Step: 6
Training loss: 1.203091025352478
Validation loss: 2.0839494710327475

Epoch: 5| Step: 7
Training loss: 1.8194077014923096
Validation loss: 2.080991341221717

Epoch: 5| Step: 8
Training loss: 2.005638837814331
Validation loss: 2.1119596291613836

Epoch: 5| Step: 9
Training loss: 2.1739840507507324
Validation loss: 2.1105914320997012

Epoch: 5| Step: 10
Training loss: 1.9271159172058105
Validation loss: 2.141745385303292

Epoch: 281| Step: 0
Training loss: 1.6118247509002686
Validation loss: 2.053632467023788

Epoch: 5| Step: 1
Training loss: 2.1741414070129395
Validation loss: 2.0852846971122165

Epoch: 5| Step: 2
Training loss: 1.4205504655838013
Validation loss: 2.0742277483786307

Epoch: 5| Step: 3
Training loss: 2.1972193717956543
Validation loss: 2.0731281298463062

Epoch: 5| Step: 4
Training loss: 2.6161131858825684
Validation loss: 2.131259859249156

Epoch: 5| Step: 5
Training loss: 2.2168965339660645
Validation loss: 2.1000982394782444

Epoch: 5| Step: 6
Training loss: 2.190774440765381
Validation loss: 2.1016107964259323

Epoch: 5| Step: 7
Training loss: 2.294238567352295
Validation loss: 2.0940617733104254

Epoch: 5| Step: 8
Training loss: 1.6880700588226318
Validation loss: 2.0930441323147027

Epoch: 5| Step: 9
Training loss: 2.068617343902588
Validation loss: 2.1389125777829077

Epoch: 5| Step: 10
Training loss: 1.2325588464736938
Validation loss: 2.118125190017044

Epoch: 282| Step: 0
Training loss: 2.60608172416687
Validation loss: 2.074274359210845

Epoch: 5| Step: 1
Training loss: 1.7384637594223022
Validation loss: 2.0571353358607136

Epoch: 5| Step: 2
Training loss: 1.7908029556274414
Validation loss: 2.116819011267795

Epoch: 5| Step: 3
Training loss: 2.150222063064575
Validation loss: 2.0772837490163822

Epoch: 5| Step: 4
Training loss: 2.054628849029541
Validation loss: 2.120038850333101

Epoch: 5| Step: 5
Training loss: 1.854745626449585
Validation loss: 2.076943075785073

Epoch: 5| Step: 6
Training loss: 1.7232677936553955
Validation loss: 2.119126145557691

Epoch: 5| Step: 7
Training loss: 2.0973095893859863
Validation loss: 2.0388637883688814

Epoch: 5| Step: 8
Training loss: 1.7599265575408936
Validation loss: 2.105438184994523

Epoch: 5| Step: 9
Training loss: 1.5666117668151855
Validation loss: 2.100137928480743

Epoch: 5| Step: 10
Training loss: 2.639646053314209
Validation loss: 2.105532661561043

Epoch: 283| Step: 0
Training loss: 1.7121193408966064
Validation loss: 2.097402964868853

Epoch: 5| Step: 1
Training loss: 2.44142746925354
Validation loss: 2.089605480112055

Epoch: 5| Step: 2
Training loss: 2.32212495803833
Validation loss: 2.1119937101999917

Epoch: 5| Step: 3
Training loss: 2.025522232055664
Validation loss: 2.1062778734391734

Epoch: 5| Step: 4
Training loss: 2.2568678855895996
Validation loss: 2.0955561860915153

Epoch: 5| Step: 5
Training loss: 1.9173282384872437
Validation loss: 2.1031853998861005

Epoch: 5| Step: 6
Training loss: 1.827683448791504
Validation loss: 2.088140112097545

Epoch: 5| Step: 7
Training loss: 2.056676149368286
Validation loss: 2.0876984493706816

Epoch: 5| Step: 8
Training loss: 2.301957607269287
Validation loss: 2.1112667770795923

Epoch: 5| Step: 9
Training loss: 1.5914093255996704
Validation loss: 2.1153949768312517

Epoch: 5| Step: 10
Training loss: 1.2768508195877075
Validation loss: 2.11368445299005

Epoch: 284| Step: 0
Training loss: 1.7890808582305908
Validation loss: 2.1135441436562488

Epoch: 5| Step: 1
Training loss: 2.0491740703582764
Validation loss: 2.0795280164287937

Epoch: 5| Step: 2
Training loss: 1.6452093124389648
Validation loss: 2.138748149718008

Epoch: 5| Step: 3
Training loss: 1.7774959802627563
Validation loss: 2.136509633833362

Epoch: 5| Step: 4
Training loss: 1.9526348114013672
Validation loss: 2.1076839482912453

Epoch: 5| Step: 5
Training loss: 1.8706188201904297
Validation loss: 2.0661173969186764

Epoch: 5| Step: 6
Training loss: 2.117006301879883
Validation loss: 2.083174060749751

Epoch: 5| Step: 7
Training loss: 1.6003875732421875
Validation loss: 2.1135690494250228

Epoch: 5| Step: 8
Training loss: 2.0264980792999268
Validation loss: 2.0906930713243383

Epoch: 5| Step: 9
Training loss: 3.2050869464874268
Validation loss: 2.1249618197000153

Epoch: 5| Step: 10
Training loss: 1.7262811660766602
Validation loss: 2.1443658285243536

Epoch: 285| Step: 0
Training loss: 2.0730984210968018
Validation loss: 2.0662083420702206

Epoch: 5| Step: 1
Training loss: 1.915207862854004
Validation loss: 2.1021562853167133

Epoch: 5| Step: 2
Training loss: 1.8591890335083008
Validation loss: 2.129244681327574

Epoch: 5| Step: 3
Training loss: 1.4222499132156372
Validation loss: 2.0718169878887873

Epoch: 5| Step: 4
Training loss: 2.7062387466430664
Validation loss: 2.139944262402032

Epoch: 5| Step: 5
Training loss: 1.8284257650375366
Validation loss: 2.115586483350364

Epoch: 5| Step: 6
Training loss: 2.082785129547119
Validation loss: 2.1339788744526524

Epoch: 5| Step: 7
Training loss: 1.768864393234253
Validation loss: 2.1585945185794624

Epoch: 5| Step: 8
Training loss: 2.30376935005188
Validation loss: 2.084197166145489

Epoch: 5| Step: 9
Training loss: 2.189969778060913
Validation loss: 2.121415727881975

Epoch: 5| Step: 10
Training loss: 1.4418154954910278
Validation loss: 2.130269629980928

Epoch: 286| Step: 0
Training loss: 1.8238433599472046
Validation loss: 2.1520564786849485

Epoch: 5| Step: 1
Training loss: 2.1953814029693604
Validation loss: 2.139847619559175

Epoch: 5| Step: 2
Training loss: 1.889830231666565
Validation loss: 2.175894627007105

Epoch: 5| Step: 3
Training loss: 2.0082716941833496
Validation loss: 2.125926674053233

Epoch: 5| Step: 4
Training loss: 1.550339937210083
Validation loss: 2.1089289316567044

Epoch: 5| Step: 5
Training loss: 1.221910834312439
Validation loss: 2.121833973033454

Epoch: 5| Step: 6
Training loss: 1.8021577596664429
Validation loss: 2.118808069536763

Epoch: 5| Step: 7
Training loss: 1.8868767023086548
Validation loss: 2.114024067437777

Epoch: 5| Step: 8
Training loss: 2.62947678565979
Validation loss: 2.084372507628574

Epoch: 5| Step: 9
Training loss: 1.4554719924926758
Validation loss: 2.111261220388515

Epoch: 5| Step: 10
Training loss: 3.193126916885376
Validation loss: 2.0686341434396724

Epoch: 287| Step: 0
Training loss: 2.111621618270874
Validation loss: 2.072867016638479

Epoch: 5| Step: 1
Training loss: 1.789691686630249
Validation loss: 2.1167534089857534

Epoch: 5| Step: 2
Training loss: 2.0889148712158203
Validation loss: 2.0492538893094627

Epoch: 5| Step: 3
Training loss: 2.3340682983398438
Validation loss: 2.1372762367289555

Epoch: 5| Step: 4
Training loss: 1.7206302881240845
Validation loss: 2.0803949730370634

Epoch: 5| Step: 5
Training loss: 1.473240613937378
Validation loss: 2.095009990917739

Epoch: 5| Step: 6
Training loss: 1.238269567489624
Validation loss: 2.082923389250232

Epoch: 5| Step: 7
Training loss: 3.0003345012664795
Validation loss: 2.1117710375016734

Epoch: 5| Step: 8
Training loss: 1.9205901622772217
Validation loss: 2.1126297853326284

Epoch: 5| Step: 9
Training loss: 1.7326185703277588
Validation loss: 2.1103043043485252

Epoch: 5| Step: 10
Training loss: 2.3710732460021973
Validation loss: 2.1368614640287174

Epoch: 288| Step: 0
Training loss: 2.228523015975952
Validation loss: 2.0962511570222917

Epoch: 5| Step: 1
Training loss: 2.3986477851867676
Validation loss: 2.126763447638481

Epoch: 5| Step: 2
Training loss: 1.6135587692260742
Validation loss: 2.0844873818018104

Epoch: 5| Step: 3
Training loss: 1.5889103412628174
Validation loss: 2.1275771023124777

Epoch: 5| Step: 4
Training loss: 1.8180749416351318
Validation loss: 2.054832232895718

Epoch: 5| Step: 5
Training loss: 2.204721212387085
Validation loss: 2.131922515489722

Epoch: 5| Step: 6
Training loss: 1.8616571426391602
Validation loss: 2.1275160697198685

Epoch: 5| Step: 7
Training loss: 1.8854774236679077
Validation loss: 2.087968623766335

Epoch: 5| Step: 8
Training loss: 1.6770801544189453
Validation loss: 2.0812543335781304

Epoch: 5| Step: 9
Training loss: 2.5132384300231934
Validation loss: 2.0367165175817346

Epoch: 5| Step: 10
Training loss: 1.7001221179962158
Validation loss: 2.0809420052395073

Epoch: 289| Step: 0
Training loss: 1.6264145374298096
Validation loss: 2.111726963391868

Epoch: 5| Step: 1
Training loss: 1.6291649341583252
Validation loss: 2.1246279490891324

Epoch: 5| Step: 2
Training loss: 1.6938526630401611
Validation loss: 2.134570373001919

Epoch: 5| Step: 3
Training loss: 2.2778873443603516
Validation loss: 2.1108994740311817

Epoch: 5| Step: 4
Training loss: 1.929388403892517
Validation loss: 2.082691914291792

Epoch: 5| Step: 5
Training loss: 2.0360140800476074
Validation loss: 2.103734903438117

Epoch: 5| Step: 6
Training loss: 2.6815273761749268
Validation loss: 2.1158094662491993

Epoch: 5| Step: 7
Training loss: 2.3005454540252686
Validation loss: 2.098049509909845

Epoch: 5| Step: 8
Training loss: 1.7446101903915405
Validation loss: 2.0811758195200274

Epoch: 5| Step: 9
Training loss: 1.9055731296539307
Validation loss: 2.1310969783413793

Epoch: 5| Step: 10
Training loss: 2.156430959701538
Validation loss: 2.0941535734361216

Epoch: 290| Step: 0
Training loss: 2.255125045776367
Validation loss: 2.0961437661160707

Epoch: 5| Step: 1
Training loss: 2.3904831409454346
Validation loss: 2.113807203949139

Epoch: 5| Step: 2
Training loss: 1.9865357875823975
Validation loss: 2.14591960753164

Epoch: 5| Step: 3
Training loss: 1.8321139812469482
Validation loss: 2.105112680824854

Epoch: 5| Step: 4
Training loss: 1.4480820894241333
Validation loss: 2.0926197369893393

Epoch: 5| Step: 5
Training loss: 2.087217092514038
Validation loss: 2.1110352059846282

Epoch: 5| Step: 6
Training loss: 1.673874855041504
Validation loss: 2.112488931225192

Epoch: 5| Step: 7
Training loss: 1.8803428411483765
Validation loss: 2.096989844435005

Epoch: 5| Step: 8
Training loss: 1.8138935565948486
Validation loss: 2.1112155222123667

Epoch: 5| Step: 9
Training loss: 2.6346371173858643
Validation loss: 2.107831152536536

Epoch: 5| Step: 10
Training loss: 1.87699556350708
Validation loss: 2.1420628947596394

Epoch: 291| Step: 0
Training loss: 2.1712422370910645
Validation loss: 2.100643191286313

Epoch: 5| Step: 1
Training loss: 1.9722864627838135
Validation loss: 2.0779342843640234

Epoch: 5| Step: 2
Training loss: 2.0144858360290527
Validation loss: 2.080409783189015

Epoch: 5| Step: 3
Training loss: 1.9951858520507812
Validation loss: 2.0963867684846282

Epoch: 5| Step: 4
Training loss: 2.448758363723755
Validation loss: 2.1014430381918467

Epoch: 5| Step: 5
Training loss: 1.9143530130386353
Validation loss: 2.107940104699904

Epoch: 5| Step: 6
Training loss: 1.7091872692108154
Validation loss: 2.0831294367390294

Epoch: 5| Step: 7
Training loss: 1.616973876953125
Validation loss: 2.102972645913401

Epoch: 5| Step: 8
Training loss: 2.4038875102996826
Validation loss: 2.0864315071413593

Epoch: 5| Step: 9
Training loss: 2.230787754058838
Validation loss: 2.0767541675157446

Epoch: 5| Step: 10
Training loss: 1.4391260147094727
Validation loss: 2.1012397658440376

Epoch: 292| Step: 0
Training loss: 2.324758529663086
Validation loss: 2.081618215448113

Epoch: 5| Step: 1
Training loss: 1.7439041137695312
Validation loss: 2.0519858355163247

Epoch: 5| Step: 2
Training loss: 2.021794080734253
Validation loss: 2.1381972169363372

Epoch: 5| Step: 3
Training loss: 1.2461602687835693
Validation loss: 2.0824231921985583

Epoch: 5| Step: 4
Training loss: 1.3759567737579346
Validation loss: 2.0977886223023936

Epoch: 5| Step: 5
Training loss: 1.8067290782928467
Validation loss: 2.112491435902093

Epoch: 5| Step: 6
Training loss: 1.6482398509979248
Validation loss: 2.082983821950933

Epoch: 5| Step: 7
Training loss: 3.024596691131592
Validation loss: 2.0719707717177687

Epoch: 5| Step: 8
Training loss: 2.227851390838623
Validation loss: 2.1143087571667087

Epoch: 5| Step: 9
Training loss: 2.295336961746216
Validation loss: 2.078838194570234

Epoch: 5| Step: 10
Training loss: 1.7463608980178833
Validation loss: 2.102249276253485

Epoch: 293| Step: 0
Training loss: 2.1269869804382324
Validation loss: 2.1088453236446587

Epoch: 5| Step: 1
Training loss: 2.5181493759155273
Validation loss: 2.0460019252633534

Epoch: 5| Step: 2
Training loss: 1.9653314352035522
Validation loss: 2.087109870808099

Epoch: 5| Step: 3
Training loss: 1.857357382774353
Validation loss: 2.06314262395264

Epoch: 5| Step: 4
Training loss: 2.1665117740631104
Validation loss: 2.0883078613588886

Epoch: 5| Step: 5
Training loss: 1.727698564529419
Validation loss: 2.1097063351702947

Epoch: 5| Step: 6
Training loss: 1.7415472269058228
Validation loss: 2.0976002293248333

Epoch: 5| Step: 7
Training loss: 1.6673732995986938
Validation loss: 2.059882240910684

Epoch: 5| Step: 8
Training loss: 2.036168336868286
Validation loss: 2.087964342486474

Epoch: 5| Step: 9
Training loss: 1.9132745265960693
Validation loss: 2.102919643925082

Epoch: 5| Step: 10
Training loss: 1.840937852859497
Validation loss: 2.099673819798295

Epoch: 294| Step: 0
Training loss: 2.329878568649292
Validation loss: 2.0344896213982695

Epoch: 5| Step: 1
Training loss: 2.084786891937256
Validation loss: 2.089237404125993

Epoch: 5| Step: 2
Training loss: 1.8157360553741455
Validation loss: 2.0903583765029907

Epoch: 5| Step: 3
Training loss: 2.1870694160461426
Validation loss: 2.0967129533008864

Epoch: 5| Step: 4
Training loss: 1.8123595714569092
Validation loss: 2.103508908261535

Epoch: 5| Step: 5
Training loss: 1.2409921884536743
Validation loss: 2.11138932166561

Epoch: 5| Step: 6
Training loss: 2.3835110664367676
Validation loss: 2.1398307572128954

Epoch: 5| Step: 7
Training loss: 1.930385947227478
Validation loss: 2.0789041993438557

Epoch: 5| Step: 8
Training loss: 1.8869022130966187
Validation loss: 2.0955744456219416

Epoch: 5| Step: 9
Training loss: 1.9108062982559204
Validation loss: 2.116507584048856

Epoch: 5| Step: 10
Training loss: 1.9411585330963135
Validation loss: 2.0872806964382047

Epoch: 295| Step: 0
Training loss: 2.004181385040283
Validation loss: 2.0858146849498955

Epoch: 5| Step: 1
Training loss: 1.6292279958724976
Validation loss: 2.129817085881387

Epoch: 5| Step: 2
Training loss: 1.3508399724960327
Validation loss: 2.122848579960485

Epoch: 5| Step: 3
Training loss: 2.490424394607544
Validation loss: 2.0953684673514417

Epoch: 5| Step: 4
Training loss: 2.3719825744628906
Validation loss: 2.0744578787075576

Epoch: 5| Step: 5
Training loss: 2.2533161640167236
Validation loss: 2.079277318011048

Epoch: 5| Step: 6
Training loss: 1.6425771713256836
Validation loss: 2.141470669418253

Epoch: 5| Step: 7
Training loss: 2.2055141925811768
Validation loss: 2.080108869460321

Epoch: 5| Step: 8
Training loss: 1.2293236255645752
Validation loss: 2.096488950073078

Epoch: 5| Step: 9
Training loss: 2.8577044010162354
Validation loss: 2.1162921177443637

Epoch: 5| Step: 10
Training loss: 1.619165062904358
Validation loss: 2.0783289401761946

Epoch: 296| Step: 0
Training loss: 2.375023365020752
Validation loss: 2.0842930450234363

Epoch: 5| Step: 1
Training loss: 1.7643285989761353
Validation loss: 2.0876149900497927

Epoch: 5| Step: 2
Training loss: 2.163316249847412
Validation loss: 2.127347869257773

Epoch: 5| Step: 3
Training loss: 1.653167724609375
Validation loss: 2.1138906555791057

Epoch: 5| Step: 4
Training loss: 2.291268825531006
Validation loss: 2.135653685497981

Epoch: 5| Step: 5
Training loss: 1.843865156173706
Validation loss: 2.1676373404841267

Epoch: 5| Step: 6
Training loss: 1.7811243534088135
Validation loss: 2.0874315282349944

Epoch: 5| Step: 7
Training loss: 1.8205907344818115
Validation loss: 2.098529128618138

Epoch: 5| Step: 8
Training loss: 1.7930724620819092
Validation loss: 2.122559619206254

Epoch: 5| Step: 9
Training loss: 2.2734832763671875
Validation loss: 2.0995410475679623

Epoch: 5| Step: 10
Training loss: 1.8289068937301636
Validation loss: 2.0875195149452455

Epoch: 297| Step: 0
Training loss: 2.266237735748291
Validation loss: 2.1256941569748746

Epoch: 5| Step: 1
Training loss: 1.8961347341537476
Validation loss: 2.0558348214754494

Epoch: 5| Step: 2
Training loss: 2.028477668762207
Validation loss: 2.0754191311456824

Epoch: 5| Step: 3
Training loss: 2.1890740394592285
Validation loss: 2.0911848480983446

Epoch: 5| Step: 4
Training loss: 1.9902788400650024
Validation loss: 2.1022651862072688

Epoch: 5| Step: 5
Training loss: 1.3519413471221924
Validation loss: 2.125367723485475

Epoch: 5| Step: 6
Training loss: 2.4360618591308594
Validation loss: 2.0784396791970856

Epoch: 5| Step: 7
Training loss: 1.846789002418518
Validation loss: 2.0934941614827802

Epoch: 5| Step: 8
Training loss: 1.9988759756088257
Validation loss: 2.1265128145935717

Epoch: 5| Step: 9
Training loss: 1.8735004663467407
Validation loss: 2.094390546121905

Epoch: 5| Step: 10
Training loss: 1.5208063125610352
Validation loss: 2.1019242348209506

Epoch: 298| Step: 0
Training loss: 1.8532276153564453
Validation loss: 2.1189678061393

Epoch: 5| Step: 1
Training loss: 2.115560293197632
Validation loss: 2.1166790172617924

Epoch: 5| Step: 2
Training loss: 2.638385534286499
Validation loss: 2.0521396936908847

Epoch: 5| Step: 3
Training loss: 1.4934780597686768
Validation loss: 2.1121217819952194

Epoch: 5| Step: 4
Training loss: 1.659811019897461
Validation loss: 2.13949413453379

Epoch: 5| Step: 5
Training loss: 1.4743664264678955
Validation loss: 2.1098106061258624

Epoch: 5| Step: 6
Training loss: 2.5615339279174805
Validation loss: 2.1326887722938292

Epoch: 5| Step: 7
Training loss: 1.9452018737792969
Validation loss: 2.0772127336071384

Epoch: 5| Step: 8
Training loss: 1.8629833459854126
Validation loss: 2.10137745898257

Epoch: 5| Step: 9
Training loss: 1.805572271347046
Validation loss: 2.09212790894252

Epoch: 5| Step: 10
Training loss: 1.9775800704956055
Validation loss: 2.0524321217690744

Epoch: 299| Step: 0
Training loss: 2.164503335952759
Validation loss: 2.064536245920325

Epoch: 5| Step: 1
Training loss: 1.310988426208496
Validation loss: 2.1406778699608258

Epoch: 5| Step: 2
Training loss: 1.6579147577285767
Validation loss: 2.0797643302589335

Epoch: 5| Step: 3
Training loss: 2.0217692852020264
Validation loss: 2.123435348592779

Epoch: 5| Step: 4
Training loss: 2.353224992752075
Validation loss: 2.09194375366293

Epoch: 5| Step: 5
Training loss: 2.2579498291015625
Validation loss: 2.068591115295246

Epoch: 5| Step: 6
Training loss: 1.6524966955184937
Validation loss: 2.1076305861114175

Epoch: 5| Step: 7
Training loss: 2.308943033218384
Validation loss: 2.080321891333467

Epoch: 5| Step: 8
Training loss: 2.123673439025879
Validation loss: 2.1064568027373283

Epoch: 5| Step: 9
Training loss: 2.1046862602233887
Validation loss: 2.084242105484009

Epoch: 5| Step: 10
Training loss: 1.4753925800323486
Validation loss: 2.132421954985588

Epoch: 300| Step: 0
Training loss: 2.117065906524658
Validation loss: 2.0616835599304526

Epoch: 5| Step: 1
Training loss: 2.44355845451355
Validation loss: 2.0854348059623473

Epoch: 5| Step: 2
Training loss: 1.9178333282470703
Validation loss: 2.092468520646454

Epoch: 5| Step: 3
Training loss: 2.0088143348693848
Validation loss: 2.0702529068916076

Epoch: 5| Step: 4
Training loss: 1.1389219760894775
Validation loss: 2.1208803756262666

Epoch: 5| Step: 5
Training loss: 2.2561845779418945
Validation loss: 2.0782246435842207

Epoch: 5| Step: 6
Training loss: 1.9166247844696045
Validation loss: 2.10981438877762

Epoch: 5| Step: 7
Training loss: 1.857669472694397
Validation loss: 2.092513325393841

Epoch: 5| Step: 8
Training loss: 2.024170398712158
Validation loss: 2.097175839126751

Epoch: 5| Step: 9
Training loss: 1.6031535863876343
Validation loss: 2.12693198521932

Epoch: 5| Step: 10
Training loss: 2.056265115737915
Validation loss: 2.1065501500201482

Epoch: 301| Step: 0
Training loss: 1.7705491781234741
Validation loss: 2.096343855704031

Epoch: 5| Step: 1
Training loss: 1.812652587890625
Validation loss: 2.077020802805501

Epoch: 5| Step: 2
Training loss: 1.9401737451553345
Validation loss: 2.087551680944299

Epoch: 5| Step: 3
Training loss: 2.158296823501587
Validation loss: 2.0410404756505

Epoch: 5| Step: 4
Training loss: 1.8979251384735107
Validation loss: 2.0867087789761123

Epoch: 5| Step: 5
Training loss: 1.7034794092178345
Validation loss: 2.1091941146440405

Epoch: 5| Step: 6
Training loss: 2.5304887294769287
Validation loss: 2.113996959501697

Epoch: 5| Step: 7
Training loss: 2.112194061279297
Validation loss: 2.0867508137097923

Epoch: 5| Step: 8
Training loss: 1.9084056615829468
Validation loss: 2.1191544122593378

Epoch: 5| Step: 9
Training loss: 1.6477752923965454
Validation loss: 2.084345112564743

Epoch: 5| Step: 10
Training loss: 1.8287397623062134
Validation loss: 2.111965489643876

Epoch: 302| Step: 0
Training loss: 1.9780769348144531
Validation loss: 2.094955510990594

Epoch: 5| Step: 1
Training loss: 2.133267641067505
Validation loss: 2.120346979428363

Epoch: 5| Step: 2
Training loss: 1.415146827697754
Validation loss: 2.096510802545855

Epoch: 5| Step: 3
Training loss: 1.6002395153045654
Validation loss: 2.072450836499532

Epoch: 5| Step: 4
Training loss: 2.192697763442993
Validation loss: 2.0457596958324475

Epoch: 5| Step: 5
Training loss: 2.3395750522613525
Validation loss: 2.1119250302673667

Epoch: 5| Step: 6
Training loss: 1.8395885229110718
Validation loss: 2.0676039444502963

Epoch: 5| Step: 7
Training loss: 1.5285195112228394
Validation loss: 2.0757871225316036

Epoch: 5| Step: 8
Training loss: 1.981220006942749
Validation loss: 2.1031439535079466

Epoch: 5| Step: 9
Training loss: 2.5634448528289795
Validation loss: 2.073602564873234

Epoch: 5| Step: 10
Training loss: 1.8104710578918457
Validation loss: 2.134260900558964

Epoch: 303| Step: 0
Training loss: 2.6073715686798096
Validation loss: 2.076690912246704

Epoch: 5| Step: 1
Training loss: 2.0319101810455322
Validation loss: 2.095383251866987

Epoch: 5| Step: 2
Training loss: 2.013822317123413
Validation loss: 2.0855040601504746

Epoch: 5| Step: 3
Training loss: 1.25265634059906
Validation loss: 2.140861544557797

Epoch: 5| Step: 4
Training loss: 2.766181707382202
Validation loss: 2.089296478097157

Epoch: 5| Step: 5
Training loss: 1.5961480140686035
Validation loss: 2.090442616452453

Epoch: 5| Step: 6
Training loss: 1.7538913488388062
Validation loss: 2.065231151478265

Epoch: 5| Step: 7
Training loss: 2.005152463912964
Validation loss: 2.1375440205297163

Epoch: 5| Step: 8
Training loss: 1.8664871454238892
Validation loss: 2.082564297542777

Epoch: 5| Step: 9
Training loss: 1.6504848003387451
Validation loss: 2.1033874224591

Epoch: 5| Step: 10
Training loss: 1.9018285274505615
Validation loss: 2.1116720425185336

Epoch: 304| Step: 0
Training loss: 1.9777429103851318
Validation loss: 2.135090656177972

Epoch: 5| Step: 1
Training loss: 1.9745171070098877
Validation loss: 2.0484660710057905

Epoch: 5| Step: 2
Training loss: 2.1484761238098145
Validation loss: 2.123269622043897

Epoch: 5| Step: 3
Training loss: 2.0432493686676025
Validation loss: 2.1127562279342325

Epoch: 5| Step: 4
Training loss: 2.1095595359802246
Validation loss: 2.1142722534877

Epoch: 5| Step: 5
Training loss: 1.8113672733306885
Validation loss: 2.108918882185413

Epoch: 5| Step: 6
Training loss: 1.5201107263565063
Validation loss: 2.1532226890646

Epoch: 5| Step: 7
Training loss: 2.26469087600708
Validation loss: 2.057497662882651

Epoch: 5| Step: 8
Training loss: 1.74420964717865
Validation loss: 2.111251305508357

Epoch: 5| Step: 9
Training loss: 1.8542989492416382
Validation loss: 2.095310309881805

Epoch: 5| Step: 10
Training loss: 2.178705930709839
Validation loss: 2.1195992705642537

Epoch: 305| Step: 0
Training loss: 1.7894868850708008
Validation loss: 2.1094845546189176

Epoch: 5| Step: 1
Training loss: 2.0882408618927
Validation loss: 2.102262758439587

Epoch: 5| Step: 2
Training loss: 2.1371841430664062
Validation loss: 2.091327710818219

Epoch: 5| Step: 3
Training loss: 1.879420280456543
Validation loss: 2.124823054959697

Epoch: 5| Step: 4
Training loss: 1.5812760591506958
Validation loss: 2.0755875033717

Epoch: 5| Step: 5
Training loss: 1.5880186557769775
Validation loss: 2.114484102495255

Epoch: 5| Step: 6
Training loss: 1.8546918630599976
Validation loss: 2.1018131497085735

Epoch: 5| Step: 7
Training loss: 2.540808916091919
Validation loss: 2.121832009284727

Epoch: 5| Step: 8
Training loss: 1.8052648305892944
Validation loss: 2.067606641400245

Epoch: 5| Step: 9
Training loss: 1.7763888835906982
Validation loss: 2.127784049639138

Epoch: 5| Step: 10
Training loss: 2.0031752586364746
Validation loss: 2.101034228519727

Epoch: 306| Step: 0
Training loss: 1.7953052520751953
Validation loss: 2.1268696554245485

Epoch: 5| Step: 1
Training loss: 2.104140043258667
Validation loss: 2.116936440108925

Epoch: 5| Step: 2
Training loss: 2.301058769226074
Validation loss: 2.1521772056497555

Epoch: 5| Step: 3
Training loss: 1.7328884601593018
Validation loss: 2.091617125336842

Epoch: 5| Step: 4
Training loss: 1.7035131454467773
Validation loss: 2.1205212967370146

Epoch: 5| Step: 5
Training loss: 2.314423084259033
Validation loss: 2.1415351680530015

Epoch: 5| Step: 6
Training loss: 2.158698558807373
Validation loss: 2.1129727158495175

Epoch: 5| Step: 7
Training loss: 1.965078592300415
Validation loss: 2.0949554417722966

Epoch: 5| Step: 8
Training loss: 2.3022027015686035
Validation loss: 2.094668319148402

Epoch: 5| Step: 9
Training loss: 1.3681306838989258
Validation loss: 2.157224455187398

Epoch: 5| Step: 10
Training loss: 1.4392553567886353
Validation loss: 2.0498309032891386

Epoch: 307| Step: 0
Training loss: 1.936722993850708
Validation loss: 2.0346737843687817

Epoch: 5| Step: 1
Training loss: 1.867773413658142
Validation loss: 2.105611740901906

Epoch: 5| Step: 2
Training loss: 2.5379695892333984
Validation loss: 2.0812617694177935

Epoch: 5| Step: 3
Training loss: 1.3200713396072388
Validation loss: 2.1200468437646025

Epoch: 5| Step: 4
Training loss: 2.300602674484253
Validation loss: 2.103047501656317

Epoch: 5| Step: 5
Training loss: 1.8828586339950562
Validation loss: 2.072533454946292

Epoch: 5| Step: 6
Training loss: 1.5513391494750977
Validation loss: 2.055158559994031

Epoch: 5| Step: 7
Training loss: 2.1221542358398438
Validation loss: 2.1382478219206615

Epoch: 5| Step: 8
Training loss: 1.755607008934021
Validation loss: 2.084175052181367

Epoch: 5| Step: 9
Training loss: 2.1048128604888916
Validation loss: 2.0785303385026994

Epoch: 5| Step: 10
Training loss: 1.594064474105835
Validation loss: 2.038085550390264

Epoch: 308| Step: 0
Training loss: 1.9785778522491455
Validation loss: 2.110303819820445

Epoch: 5| Step: 1
Training loss: 2.304495334625244
Validation loss: 2.1400496062412055

Epoch: 5| Step: 2
Training loss: 1.6891262531280518
Validation loss: 2.102823903483729

Epoch: 5| Step: 3
Training loss: 2.1550936698913574
Validation loss: 2.075443684413869

Epoch: 5| Step: 4
Training loss: 2.6646485328674316
Validation loss: 2.1189725475926555

Epoch: 5| Step: 5
Training loss: 1.9524612426757812
Validation loss: 2.08766842913884

Epoch: 5| Step: 6
Training loss: 1.5981513261795044
Validation loss: 2.1313261652505524

Epoch: 5| Step: 7
Training loss: 2.211761951446533
Validation loss: 2.0517694809103526

Epoch: 5| Step: 8
Training loss: 2.0769999027252197
Validation loss: 2.1144535772262083

Epoch: 5| Step: 9
Training loss: 1.2235047817230225
Validation loss: 2.1261667102895756

Epoch: 5| Step: 10
Training loss: 1.3636943101882935
Validation loss: 2.118944114254367

Epoch: 309| Step: 0
Training loss: 1.8944530487060547
Validation loss: 2.1126806171991492

Epoch: 5| Step: 1
Training loss: 1.926721215248108
Validation loss: 2.10288324663716

Epoch: 5| Step: 2
Training loss: 2.2276711463928223
Validation loss: 2.106881703099897

Epoch: 5| Step: 3
Training loss: 1.9918533563613892
Validation loss: 2.127841206007106

Epoch: 5| Step: 4
Training loss: 1.8961334228515625
Validation loss: 2.117898041202176

Epoch: 5| Step: 5
Training loss: 2.0735740661621094
Validation loss: 2.1041288273308867

Epoch: 5| Step: 6
Training loss: 1.9554229974746704
Validation loss: 2.151291316555392

Epoch: 5| Step: 7
Training loss: 1.5245548486709595
Validation loss: 2.160180890431968

Epoch: 5| Step: 8
Training loss: 1.8115618228912354
Validation loss: 2.096569404807142

Epoch: 5| Step: 9
Training loss: 1.936545729637146
Validation loss: 2.1547867431435535

Epoch: 5| Step: 10
Training loss: 1.9247291088104248
Validation loss: 2.1442131714154313

Epoch: 310| Step: 0
Training loss: 1.5387237071990967
Validation loss: 2.0760379760496077

Epoch: 5| Step: 1
Training loss: 2.37172794342041
Validation loss: 2.0594289136189285

Epoch: 5| Step: 2
Training loss: 2.0011439323425293
Validation loss: 2.1468363615774337

Epoch: 5| Step: 3
Training loss: 2.181767702102661
Validation loss: 2.12208770039261

Epoch: 5| Step: 4
Training loss: 1.5080814361572266
Validation loss: 2.1371510016020907

Epoch: 5| Step: 5
Training loss: 1.7321407794952393
Validation loss: 2.137584804206766

Epoch: 5| Step: 6
Training loss: 1.8997091054916382
Validation loss: 2.073419387622546

Epoch: 5| Step: 7
Training loss: 2.3666067123413086
Validation loss: 2.1515110756761286

Epoch: 5| Step: 8
Training loss: 2.140242099761963
Validation loss: 2.083743523525935

Epoch: 5| Step: 9
Training loss: 1.7459704875946045
Validation loss: 2.0885696180405153

Epoch: 5| Step: 10
Training loss: 1.6822282075881958
Validation loss: 2.06468371165696

Epoch: 311| Step: 0
Training loss: 1.916023850440979
Validation loss: 2.131587407922232

Epoch: 5| Step: 1
Training loss: 2.516169309616089
Validation loss: 2.123501977612895

Epoch: 5| Step: 2
Training loss: 2.223867654800415
Validation loss: 2.124013903320477

Epoch: 5| Step: 3
Training loss: 2.141040325164795
Validation loss: 2.063357014809885

Epoch: 5| Step: 4
Training loss: 2.7257721424102783
Validation loss: 2.089757914184242

Epoch: 5| Step: 5
Training loss: 1.882631540298462
Validation loss: 2.061013521686677

Epoch: 5| Step: 6
Training loss: 1.8091239929199219
Validation loss: 2.0776027453842985

Epoch: 5| Step: 7
Training loss: 1.8043224811553955
Validation loss: 2.085882612453994

Epoch: 5| Step: 8
Training loss: 1.8319501876831055
Validation loss: 2.073329274372388

Epoch: 5| Step: 9
Training loss: 0.9937506914138794
Validation loss: 2.067037646488477

Epoch: 5| Step: 10
Training loss: 1.3440674543380737
Validation loss: 2.0461554360646073

Epoch: 312| Step: 0
Training loss: 2.151829481124878
Validation loss: 2.106820414143224

Epoch: 5| Step: 1
Training loss: 1.6603610515594482
Validation loss: 2.154599133358207

Epoch: 5| Step: 2
Training loss: 2.1733105182647705
Validation loss: 2.092800404435845

Epoch: 5| Step: 3
Training loss: 1.741697907447815
Validation loss: 2.063641667366028

Epoch: 5| Step: 4
Training loss: 2.2731528282165527
Validation loss: 2.1135559633213985

Epoch: 5| Step: 5
Training loss: 1.8648561239242554
Validation loss: 2.0873414239575787

Epoch: 5| Step: 6
Training loss: 1.8086798191070557
Validation loss: 2.0416264751906037

Epoch: 5| Step: 7
Training loss: 1.7774503231048584
Validation loss: 2.0991088523659656

Epoch: 5| Step: 8
Training loss: 2.05853271484375
Validation loss: 2.0584222398778445

Epoch: 5| Step: 9
Training loss: 1.475151777267456
Validation loss: 2.054245340567763

Epoch: 5| Step: 10
Training loss: 2.1247501373291016
Validation loss: 2.1044182726131972

Epoch: 313| Step: 0
Training loss: 1.8614870309829712
Validation loss: 2.0719418705150647

Epoch: 5| Step: 1
Training loss: 1.9141556024551392
Validation loss: 2.067631426677909

Epoch: 5| Step: 2
Training loss: 2.8971691131591797
Validation loss: 2.0911250460532402

Epoch: 5| Step: 3
Training loss: 2.513514280319214
Validation loss: 2.079488162071474

Epoch: 5| Step: 4
Training loss: 1.4090847969055176
Validation loss: 2.117083539244949

Epoch: 5| Step: 5
Training loss: 2.1210110187530518
Validation loss: 2.1255802031486266

Epoch: 5| Step: 6
Training loss: 1.4828659296035767
Validation loss: 2.0958949135195826

Epoch: 5| Step: 7
Training loss: 1.3158925771713257
Validation loss: 2.121549138458826

Epoch: 5| Step: 8
Training loss: 1.5048139095306396
Validation loss: 2.095809534031858

Epoch: 5| Step: 9
Training loss: 2.219902515411377
Validation loss: 2.0666249670008177

Epoch: 5| Step: 10
Training loss: 2.0479953289031982
Validation loss: 2.119421805104902

Epoch: 314| Step: 0
Training loss: 2.3792502880096436
Validation loss: 2.0321448054364932

Epoch: 5| Step: 1
Training loss: 2.1860592365264893
Validation loss: 2.1203326358590076

Epoch: 5| Step: 2
Training loss: 1.837887167930603
Validation loss: 2.124174036005492

Epoch: 5| Step: 3
Training loss: 1.2873038053512573
Validation loss: 2.0675079591812624

Epoch: 5| Step: 4
Training loss: 1.600476622581482
Validation loss: 2.1476714405962216

Epoch: 5| Step: 5
Training loss: 1.7381649017333984
Validation loss: 2.122842223413529

Epoch: 5| Step: 6
Training loss: 1.9761192798614502
Validation loss: 2.0763099821664954

Epoch: 5| Step: 7
Training loss: 1.6662559509277344
Validation loss: 2.104957244729483

Epoch: 5| Step: 8
Training loss: 2.6286885738372803
Validation loss: 2.1285197504105104

Epoch: 5| Step: 9
Training loss: 1.5254884958267212
Validation loss: 2.146525408632012

Epoch: 5| Step: 10
Training loss: 2.1924285888671875
Validation loss: 2.142247074393816

Epoch: 315| Step: 0
Training loss: 2.7441389560699463
Validation loss: 2.078646509878097

Epoch: 5| Step: 1
Training loss: 2.07802152633667
Validation loss: 2.108389751885527

Epoch: 5| Step: 2
Training loss: 1.6825376749038696
Validation loss: 2.109844296209274

Epoch: 5| Step: 3
Training loss: 1.9670127630233765
Validation loss: 2.095674217388194

Epoch: 5| Step: 4
Training loss: 2.0261635780334473
Validation loss: 2.116926263737422

Epoch: 5| Step: 5
Training loss: 1.8928797245025635
Validation loss: 2.0960562395793136

Epoch: 5| Step: 6
Training loss: 2.123772144317627
Validation loss: 2.097399906445575

Epoch: 5| Step: 7
Training loss: 1.4874383211135864
Validation loss: 2.099488099416097

Epoch: 5| Step: 8
Training loss: 1.732860803604126
Validation loss: 2.085521396770272

Epoch: 5| Step: 9
Training loss: 1.2525084018707275
Validation loss: 2.100984965601275

Epoch: 5| Step: 10
Training loss: 2.0444931983947754
Validation loss: 2.062903845182029

Epoch: 316| Step: 0
Training loss: 1.4188895225524902
Validation loss: 2.144973163963646

Epoch: 5| Step: 1
Training loss: 2.257699489593506
Validation loss: 2.095809148203942

Epoch: 5| Step: 2
Training loss: 2.161348581314087
Validation loss: 2.1442606602945635

Epoch: 5| Step: 3
Training loss: 1.552985429763794
Validation loss: 2.145191672027752

Epoch: 5| Step: 4
Training loss: 2.0188958644866943
Validation loss: 2.0828616862655966

Epoch: 5| Step: 5
Training loss: 1.6818082332611084
Validation loss: 2.1137941165636946

Epoch: 5| Step: 6
Training loss: 1.4746835231781006
Validation loss: 2.1290109516471944

Epoch: 5| Step: 7
Training loss: 2.3805365562438965
Validation loss: 2.1439104028927383

Epoch: 5| Step: 8
Training loss: 1.9993455410003662
Validation loss: 2.090384852501654

Epoch: 5| Step: 9
Training loss: 2.3405299186706543
Validation loss: 2.059642599474999

Epoch: 5| Step: 10
Training loss: 1.4282569885253906
Validation loss: 2.068400472723028

Epoch: 317| Step: 0
Training loss: 2.8405051231384277
Validation loss: 2.1132563224402805

Epoch: 5| Step: 1
Training loss: 2.1724650859832764
Validation loss: 2.049624519963418

Epoch: 5| Step: 2
Training loss: 1.521637201309204
Validation loss: 2.0498618425861483

Epoch: 5| Step: 3
Training loss: 1.3334563970565796
Validation loss: 2.106911183685385

Epoch: 5| Step: 4
Training loss: 2.453798294067383
Validation loss: 2.1191917773216002

Epoch: 5| Step: 5
Training loss: 1.8858642578125
Validation loss: 2.1051481898112963

Epoch: 5| Step: 6
Training loss: 1.4181197881698608
Validation loss: 2.1038045870360507

Epoch: 5| Step: 7
Training loss: 1.681217908859253
Validation loss: 2.1137836646008235

Epoch: 5| Step: 8
Training loss: 1.5328572988510132
Validation loss: 2.1084683684892553

Epoch: 5| Step: 9
Training loss: 2.2881722450256348
Validation loss: 2.0718476721035537

Epoch: 5| Step: 10
Training loss: 1.6662445068359375
Validation loss: 2.090140852876889

Epoch: 318| Step: 0
Training loss: 2.3327383995056152
Validation loss: 2.1257172399951565

Epoch: 5| Step: 1
Training loss: 1.7562267780303955
Validation loss: 2.074261047506845

Epoch: 5| Step: 2
Training loss: 1.6351953744888306
Validation loss: 2.0567330057903

Epoch: 5| Step: 3
Training loss: 1.4601409435272217
Validation loss: 2.0948184767077045

Epoch: 5| Step: 4
Training loss: 1.4071531295776367
Validation loss: 2.1649917735848376

Epoch: 5| Step: 5
Training loss: 2.1494035720825195
Validation loss: 2.0905490613752797

Epoch: 5| Step: 6
Training loss: 2.908987045288086
Validation loss: 2.1229525176427697

Epoch: 5| Step: 7
Training loss: 1.609341025352478
Validation loss: 2.1238073072125836

Epoch: 5| Step: 8
Training loss: 1.979593276977539
Validation loss: 2.0972850348359797

Epoch: 5| Step: 9
Training loss: 1.454769492149353
Validation loss: 2.104605620907199

Epoch: 5| Step: 10
Training loss: 2.125633716583252
Validation loss: 2.158617465726791

Epoch: 319| Step: 0
Training loss: 2.1095900535583496
Validation loss: 2.089454861097438

Epoch: 5| Step: 1
Training loss: 2.388568639755249
Validation loss: 2.108965616072378

Epoch: 5| Step: 2
Training loss: 1.4854586124420166
Validation loss: 2.0882324736605407

Epoch: 5| Step: 3
Training loss: 1.9507430791854858
Validation loss: 2.082953558173231

Epoch: 5| Step: 4
Training loss: 2.1240038871765137
Validation loss: 2.1340668842356694

Epoch: 5| Step: 5
Training loss: 2.0125088691711426
Validation loss: 2.0989194223957677

Epoch: 5| Step: 6
Training loss: 1.6549221277236938
Validation loss: 2.0827396467167842

Epoch: 5| Step: 7
Training loss: 1.9353091716766357
Validation loss: 2.1232608236292356

Epoch: 5| Step: 8
Training loss: 2.059232234954834
Validation loss: 2.1061125775819183

Epoch: 5| Step: 9
Training loss: 2.0804860591888428
Validation loss: 2.0588255287498556

Epoch: 5| Step: 10
Training loss: 1.5502023696899414
Validation loss: 2.134799729111374

Epoch: 320| Step: 0
Training loss: 1.412177324295044
Validation loss: 2.1334146133033176

Epoch: 5| Step: 1
Training loss: 1.3452765941619873
Validation loss: 2.0754470722649687

Epoch: 5| Step: 2
Training loss: 2.402069330215454
Validation loss: 2.1091791788736978

Epoch: 5| Step: 3
Training loss: 1.5617061853408813
Validation loss: 2.109012249977358

Epoch: 5| Step: 4
Training loss: 1.789886474609375
Validation loss: 2.107568176843787

Epoch: 5| Step: 5
Training loss: 2.563838481903076
Validation loss: 2.107763208368773

Epoch: 5| Step: 6
Training loss: 2.3782143592834473
Validation loss: 2.1313158619788384

Epoch: 5| Step: 7
Training loss: 1.5684411525726318
Validation loss: 2.0954139412090345

Epoch: 5| Step: 8
Training loss: 2.08943510055542
Validation loss: 2.0588021150199314

Epoch: 5| Step: 9
Training loss: 1.989518165588379
Validation loss: 2.1487641026896815

Epoch: 5| Step: 10
Training loss: 1.939845323562622
Validation loss: 2.1211719923121954

Epoch: 321| Step: 0
Training loss: 2.2715816497802734
Validation loss: 2.146630830662225

Epoch: 5| Step: 1
Training loss: 1.3307125568389893
Validation loss: 2.1127183578347646

Epoch: 5| Step: 2
Training loss: 1.725581169128418
Validation loss: 2.1222923981246127

Epoch: 5| Step: 3
Training loss: 1.3870307207107544
Validation loss: 2.0896891445241947

Epoch: 5| Step: 4
Training loss: 1.6216201782226562
Validation loss: 2.0953125979310725

Epoch: 5| Step: 5
Training loss: 1.9765222072601318
Validation loss: 2.087440771441306

Epoch: 5| Step: 6
Training loss: 2.448270320892334
Validation loss: 2.1239164285762335

Epoch: 5| Step: 7
Training loss: 2.460204601287842
Validation loss: 2.211886246999105

Epoch: 5| Step: 8
Training loss: 1.890038251876831
Validation loss: 2.1203343073527017

Epoch: 5| Step: 9
Training loss: 1.6877739429473877
Validation loss: 2.122131824493408

Epoch: 5| Step: 10
Training loss: 2.089761257171631
Validation loss: 2.104871344822709

Epoch: 322| Step: 0
Training loss: 1.6943296194076538
Validation loss: 2.118290724292878

Epoch: 5| Step: 1
Training loss: 1.5918024778366089
Validation loss: 2.1206119624517297

Epoch: 5| Step: 2
Training loss: 2.4887208938598633
Validation loss: 2.1168883462106027

Epoch: 5| Step: 3
Training loss: 1.845800757408142
Validation loss: 2.0524807642864924

Epoch: 5| Step: 4
Training loss: 2.0067977905273438
Validation loss: 2.087805914622481

Epoch: 5| Step: 5
Training loss: 2.066140651702881
Validation loss: 2.064717329958434

Epoch: 5| Step: 6
Training loss: 1.6837819814682007
Validation loss: 2.101036525541736

Epoch: 5| Step: 7
Training loss: 1.855118751525879
Validation loss: 2.127075413221954

Epoch: 5| Step: 8
Training loss: 1.850385069847107
Validation loss: 2.0793954556988132

Epoch: 5| Step: 9
Training loss: 1.9363607168197632
Validation loss: 2.0804765327002412

Epoch: 5| Step: 10
Training loss: 1.8821794986724854
Validation loss: 2.134512982060832

Epoch: 323| Step: 0
Training loss: 1.6306753158569336
Validation loss: 2.0748523204557356

Epoch: 5| Step: 1
Training loss: 2.0256457328796387
Validation loss: 2.091352184613546

Epoch: 5| Step: 2
Training loss: 1.8146946430206299
Validation loss: 2.0790776796238397

Epoch: 5| Step: 3
Training loss: 2.158250570297241
Validation loss: 2.0847806456268474

Epoch: 5| Step: 4
Training loss: 1.502089262008667
Validation loss: 2.118772129858694

Epoch: 5| Step: 5
Training loss: 1.8217509984970093
Validation loss: 2.1162225251556723

Epoch: 5| Step: 6
Training loss: 1.9584767818450928
Validation loss: 2.0695384240919545

Epoch: 5| Step: 7
Training loss: 2.1882834434509277
Validation loss: 2.0811978899022585

Epoch: 5| Step: 8
Training loss: 1.7187306880950928
Validation loss: 2.1206484507488947

Epoch: 5| Step: 9
Training loss: 1.5908310413360596
Validation loss: 2.0649263371703444

Epoch: 5| Step: 10
Training loss: 2.4158973693847656
Validation loss: 2.132311528728854

Epoch: 324| Step: 0
Training loss: 1.605851411819458
Validation loss: 2.0933273018047376

Epoch: 5| Step: 1
Training loss: 2.561894655227661
Validation loss: 2.104594851052889

Epoch: 5| Step: 2
Training loss: 1.948001503944397
Validation loss: 2.0648608476884904

Epoch: 5| Step: 3
Training loss: 2.3434576988220215
Validation loss: 2.046924683355516

Epoch: 5| Step: 4
Training loss: 1.652777910232544
Validation loss: 2.104362710829704

Epoch: 5| Step: 5
Training loss: 1.5663946866989136
Validation loss: 2.1656348448927685

Epoch: 5| Step: 6
Training loss: 1.8019962310791016
Validation loss: 2.1033067446883007

Epoch: 5| Step: 7
Training loss: 1.7471067905426025
Validation loss: 2.0971530842524704

Epoch: 5| Step: 8
Training loss: 2.21710467338562
Validation loss: 2.0835313335541756

Epoch: 5| Step: 9
Training loss: 1.7413148880004883
Validation loss: 2.1512045809017715

Epoch: 5| Step: 10
Training loss: 1.6963567733764648
Validation loss: 2.0764514092476136

Epoch: 325| Step: 0
Training loss: 2.667006254196167
Validation loss: 2.1532423726973997

Epoch: 5| Step: 1
Training loss: 1.9542922973632812
Validation loss: 2.104276439195038

Epoch: 5| Step: 2
Training loss: 1.6168960332870483
Validation loss: 2.0755351628026655

Epoch: 5| Step: 3
Training loss: 1.7171437740325928
Validation loss: 2.1031740320626127

Epoch: 5| Step: 4
Training loss: 1.4911301136016846
Validation loss: 2.0826640205998577

Epoch: 5| Step: 5
Training loss: 1.9495054483413696
Validation loss: 2.06284938832765

Epoch: 5| Step: 6
Training loss: 1.2366360425949097
Validation loss: 2.1371728733021724

Epoch: 5| Step: 7
Training loss: 2.0252671241760254
Validation loss: 2.0970365616583053

Epoch: 5| Step: 8
Training loss: 1.4982578754425049
Validation loss: 2.1261696892399944

Epoch: 5| Step: 9
Training loss: 1.5869194269180298
Validation loss: 2.1214038582258326

Epoch: 5| Step: 10
Training loss: 3.2443366050720215
Validation loss: 2.04723003602797

Epoch: 326| Step: 0
Training loss: 1.4773451089859009
Validation loss: 2.118519083146126

Epoch: 5| Step: 1
Training loss: 1.8269922733306885
Validation loss: 2.0946524373946653

Epoch: 5| Step: 2
Training loss: 1.867662787437439
Validation loss: 2.1362827849644486

Epoch: 5| Step: 3
Training loss: 2.0086193084716797
Validation loss: 2.0671623137689408

Epoch: 5| Step: 4
Training loss: 2.0753331184387207
Validation loss: 2.1084512459334506

Epoch: 5| Step: 5
Training loss: 2.0457606315612793
Validation loss: 2.099435688346945

Epoch: 5| Step: 6
Training loss: 1.9022657871246338
Validation loss: 2.088073453595561

Epoch: 5| Step: 7
Training loss: 1.4728952646255493
Validation loss: 2.0969357772540023

Epoch: 5| Step: 8
Training loss: 2.132667064666748
Validation loss: 2.0830412257102227

Epoch: 5| Step: 9
Training loss: 1.7347179651260376
Validation loss: 2.089526435380341

Epoch: 5| Step: 10
Training loss: 2.2628300189971924
Validation loss: 2.1230481106747865

Epoch: 327| Step: 0
Training loss: 1.8151658773422241
Validation loss: 2.128522680651757

Epoch: 5| Step: 1
Training loss: 2.3306784629821777
Validation loss: 2.0849083674851285

Epoch: 5| Step: 2
Training loss: 1.8860175609588623
Validation loss: 2.0804936578196864

Epoch: 5| Step: 3
Training loss: 1.7242543697357178
Validation loss: 2.112423828853074

Epoch: 5| Step: 4
Training loss: 2.4561498165130615
Validation loss: 2.093813714160714

Epoch: 5| Step: 5
Training loss: 1.3625690937042236
Validation loss: 2.098744664140927

Epoch: 5| Step: 6
Training loss: 1.75678288936615
Validation loss: 2.1300808024662796

Epoch: 5| Step: 7
Training loss: 2.0240418910980225
Validation loss: 2.0895713734370407

Epoch: 5| Step: 8
Training loss: 1.4587576389312744
Validation loss: 2.086141411976148

Epoch: 5| Step: 9
Training loss: 2.4442527294158936
Validation loss: 2.075911984648756

Epoch: 5| Step: 10
Training loss: 1.733482837677002
Validation loss: 2.0556484935104207

Epoch: 328| Step: 0
Training loss: 2.1159565448760986
Validation loss: 2.0825387841911724

Epoch: 5| Step: 1
Training loss: 1.63461172580719
Validation loss: 2.0676584525774886

Epoch: 5| Step: 2
Training loss: 1.8393781185150146
Validation loss: 2.080838430312372

Epoch: 5| Step: 3
Training loss: 1.2300773859024048
Validation loss: 2.11385182667804

Epoch: 5| Step: 4
Training loss: 2.271481990814209
Validation loss: 2.084119568588913

Epoch: 5| Step: 5
Training loss: 1.2835274934768677
Validation loss: 2.0722297763311737

Epoch: 5| Step: 6
Training loss: 2.302424907684326
Validation loss: 2.106524987887311

Epoch: 5| Step: 7
Training loss: 2.4013185501098633
Validation loss: 2.1055254013307634

Epoch: 5| Step: 8
Training loss: 1.9440186023712158
Validation loss: 2.065042273972624

Epoch: 5| Step: 9
Training loss: 1.9096511602401733
Validation loss: 2.137650902553271

Epoch: 5| Step: 10
Training loss: 1.7311452627182007
Validation loss: 2.1073367159853698

Epoch: 329| Step: 0
Training loss: 2.137202501296997
Validation loss: 2.1002890615053076

Epoch: 5| Step: 1
Training loss: 2.388956308364868
Validation loss: 2.0910713775183565

Epoch: 5| Step: 2
Training loss: 1.8409194946289062
Validation loss: 2.0948831573609383

Epoch: 5| Step: 3
Training loss: 1.76682448387146
Validation loss: 2.0924651648408625

Epoch: 5| Step: 4
Training loss: 1.7661911249160767
Validation loss: 2.0660096727391726

Epoch: 5| Step: 5
Training loss: 1.5845390558242798
Validation loss: 2.1655745839559906

Epoch: 5| Step: 6
Training loss: 2.1954147815704346
Validation loss: 2.1217614040579846

Epoch: 5| Step: 7
Training loss: 2.1850550174713135
Validation loss: 2.0935956457609772

Epoch: 5| Step: 8
Training loss: 1.6502920389175415
Validation loss: 2.11508781679215

Epoch: 5| Step: 9
Training loss: 1.4338345527648926
Validation loss: 2.193443775177002

Epoch: 5| Step: 10
Training loss: 1.8778507709503174
Validation loss: 2.1151808615653747

Epoch: 330| Step: 0
Training loss: 1.4711469411849976
Validation loss: 2.1141585393618514

Epoch: 5| Step: 1
Training loss: 2.165234088897705
Validation loss: 2.0686312798530824

Epoch: 5| Step: 2
Training loss: 2.0616273880004883
Validation loss: 2.067126707364154

Epoch: 5| Step: 3
Training loss: 2.0563712120056152
Validation loss: 2.1386304632309945

Epoch: 5| Step: 4
Training loss: 1.7998489141464233
Validation loss: 2.155985168231431

Epoch: 5| Step: 5
Training loss: 1.6808080673217773
Validation loss: 2.1602545374183246

Epoch: 5| Step: 6
Training loss: 2.086214065551758
Validation loss: 2.0670241514841714

Epoch: 5| Step: 7
Training loss: 1.6333938837051392
Validation loss: 2.1216575432849187

Epoch: 5| Step: 8
Training loss: 2.038684844970703
Validation loss: 2.1117236050226356

Epoch: 5| Step: 9
Training loss: 2.063262462615967
Validation loss: 2.096745721755489

Epoch: 5| Step: 10
Training loss: 1.5690940618515015
Validation loss: 2.05561650183893

Epoch: 331| Step: 0
Training loss: 1.825162649154663
Validation loss: 2.134889098905748

Epoch: 5| Step: 1
Training loss: 1.950311303138733
Validation loss: 2.111477759576613

Epoch: 5| Step: 2
Training loss: 1.5224474668502808
Validation loss: 2.1088809877313595

Epoch: 5| Step: 3
Training loss: 1.557672142982483
Validation loss: 2.077034270891579

Epoch: 5| Step: 4
Training loss: 2.7990360260009766
Validation loss: 2.103045509707543

Epoch: 5| Step: 5
Training loss: 1.9040762186050415
Validation loss: 2.0734480401521087

Epoch: 5| Step: 6
Training loss: 1.3708300590515137
Validation loss: 2.0717824941040366

Epoch: 5| Step: 7
Training loss: 1.7833553552627563
Validation loss: 2.094847197173744

Epoch: 5| Step: 8
Training loss: 2.036487102508545
Validation loss: 2.0733934448611353

Epoch: 5| Step: 9
Training loss: 1.9984267950057983
Validation loss: 2.1299993940578994

Epoch: 5| Step: 10
Training loss: 1.508093237876892
Validation loss: 2.1065021548219907

Epoch: 332| Step: 0
Training loss: 2.167513370513916
Validation loss: 2.085903803507487

Epoch: 5| Step: 1
Training loss: 2.4407477378845215
Validation loss: 2.1157429167019424

Epoch: 5| Step: 2
Training loss: 1.9163191318511963
Validation loss: 2.1138676417771207

Epoch: 5| Step: 3
Training loss: 1.728231430053711
Validation loss: 2.0646156841708767

Epoch: 5| Step: 4
Training loss: 1.620491623878479
Validation loss: 2.0735923885017313

Epoch: 5| Step: 5
Training loss: 2.134219169616699
Validation loss: 2.0972699067925893

Epoch: 5| Step: 6
Training loss: 2.499602794647217
Validation loss: 2.1172419132724887

Epoch: 5| Step: 7
Training loss: 2.0890965461730957
Validation loss: 2.0893188612435454

Epoch: 5| Step: 8
Training loss: 1.4589284658432007
Validation loss: 2.083277471603886

Epoch: 5| Step: 9
Training loss: 1.167431354522705
Validation loss: 2.1135687020517167

Epoch: 5| Step: 10
Training loss: 1.3328465223312378
Validation loss: 2.1051179875609694

Epoch: 333| Step: 0
Training loss: 1.6322307586669922
Validation loss: 2.0719360946327128

Epoch: 5| Step: 1
Training loss: 2.2520363330841064
Validation loss: 2.0664279986453313

Epoch: 5| Step: 2
Training loss: 2.188795566558838
Validation loss: 2.0655215478712514

Epoch: 5| Step: 3
Training loss: 1.4159514904022217
Validation loss: 2.0927335113607426

Epoch: 5| Step: 4
Training loss: 2.232861042022705
Validation loss: 2.0933340352068663

Epoch: 5| Step: 5
Training loss: 2.1383769512176514
Validation loss: 2.046786686425568

Epoch: 5| Step: 6
Training loss: 1.6219797134399414
Validation loss: 2.110700850845665

Epoch: 5| Step: 7
Training loss: 2.281384229660034
Validation loss: 2.107433497264821

Epoch: 5| Step: 8
Training loss: 1.8971561193466187
Validation loss: 2.1142193783995924

Epoch: 5| Step: 9
Training loss: 1.2685129642486572
Validation loss: 2.0868870237822175

Epoch: 5| Step: 10
Training loss: 1.5295755863189697
Validation loss: 2.077375941379096

Epoch: 334| Step: 0
Training loss: 2.0294487476348877
Validation loss: 2.1090172824039253

Epoch: 5| Step: 1
Training loss: 2.0210559368133545
Validation loss: 2.1135548250649565

Epoch: 5| Step: 2
Training loss: 1.4099937677383423
Validation loss: 2.11283802986145

Epoch: 5| Step: 3
Training loss: 1.5730712413787842
Validation loss: 2.126048593110936

Epoch: 5| Step: 4
Training loss: 2.3720500469207764
Validation loss: 2.1090595491470827

Epoch: 5| Step: 5
Training loss: 2.253678321838379
Validation loss: 2.1218644572842504

Epoch: 5| Step: 6
Training loss: 1.5392534732818604
Validation loss: 2.093215573218561

Epoch: 5| Step: 7
Training loss: 2.219456434249878
Validation loss: 2.0755346975018902

Epoch: 5| Step: 8
Training loss: 1.8064171075820923
Validation loss: 2.0896804089187295

Epoch: 5| Step: 9
Training loss: 1.740527868270874
Validation loss: 2.09599708741711

Epoch: 5| Step: 10
Training loss: 1.6020479202270508
Validation loss: 2.1328730301190446

Epoch: 335| Step: 0
Training loss: 1.7697231769561768
Validation loss: 2.1161529069305747

Epoch: 5| Step: 1
Training loss: 1.7856111526489258
Validation loss: 2.1091353226733465

Epoch: 5| Step: 2
Training loss: 2.0280022621154785
Validation loss: 2.095143260494355

Epoch: 5| Step: 3
Training loss: 1.8959087133407593
Validation loss: 2.1028034687042236

Epoch: 5| Step: 4
Training loss: 1.5575367212295532
Validation loss: 2.1459129266841437

Epoch: 5| Step: 5
Training loss: 1.3490864038467407
Validation loss: 2.047878384590149

Epoch: 5| Step: 6
Training loss: 2.1703763008117676
Validation loss: 2.079719064056232

Epoch: 5| Step: 7
Training loss: 1.6430184841156006
Validation loss: 2.1243948705734743

Epoch: 5| Step: 8
Training loss: 2.2517731189727783
Validation loss: 2.1082314073398547

Epoch: 5| Step: 9
Training loss: 1.667101263999939
Validation loss: 2.0767980262797368

Epoch: 5| Step: 10
Training loss: 2.4518160820007324
Validation loss: 2.1488641846564507

Epoch: 336| Step: 0
Training loss: 1.8625684976577759
Validation loss: 2.1046011217178835

Epoch: 5| Step: 1
Training loss: 1.4768211841583252
Validation loss: 2.085723065560864

Epoch: 5| Step: 2
Training loss: 2.1437039375305176
Validation loss: 2.0686647577952315

Epoch: 5| Step: 3
Training loss: 1.5954002141952515
Validation loss: 2.059206147347727

Epoch: 5| Step: 4
Training loss: 1.3494865894317627
Validation loss: 2.136281987672211

Epoch: 5| Step: 5
Training loss: 1.585943579673767
Validation loss: 2.126781480286711

Epoch: 5| Step: 6
Training loss: 1.8154423236846924
Validation loss: 2.1312672040795766

Epoch: 5| Step: 7
Training loss: 2.026980400085449
Validation loss: 2.1243372040410198

Epoch: 5| Step: 8
Training loss: 2.282240629196167
Validation loss: 2.0984303169353034

Epoch: 5| Step: 9
Training loss: 1.715188980102539
Validation loss: 2.1476137971365326

Epoch: 5| Step: 10
Training loss: 2.5144424438476562
Validation loss: 2.094188064657232

Epoch: 337| Step: 0
Training loss: 1.438458800315857
Validation loss: 2.0796374390202184

Epoch: 5| Step: 1
Training loss: 1.701778769493103
Validation loss: 2.1581357140694895

Epoch: 5| Step: 2
Training loss: 1.8189756870269775
Validation loss: 2.068083135030603

Epoch: 5| Step: 3
Training loss: 1.794348120689392
Validation loss: 2.112314457534462

Epoch: 5| Step: 4
Training loss: 2.551159620285034
Validation loss: 2.0868697627898185

Epoch: 5| Step: 5
Training loss: 2.4549245834350586
Validation loss: 2.1129482215450657

Epoch: 5| Step: 6
Training loss: 1.5719398260116577
Validation loss: 2.0664516559211155

Epoch: 5| Step: 7
Training loss: 1.3480117321014404
Validation loss: 2.0584805601386615

Epoch: 5| Step: 8
Training loss: 1.8495681285858154
Validation loss: 2.070544312077184

Epoch: 5| Step: 9
Training loss: 1.9653679132461548
Validation loss: 2.096603126936061

Epoch: 5| Step: 10
Training loss: 1.801137089729309
Validation loss: 2.095597228696269

Epoch: 338| Step: 0
Training loss: 1.3521089553833008
Validation loss: 2.072942792728383

Epoch: 5| Step: 1
Training loss: 2.0015482902526855
Validation loss: 2.076584997997489

Epoch: 5| Step: 2
Training loss: 1.923140525817871
Validation loss: 2.1194119632885022

Epoch: 5| Step: 3
Training loss: 1.553173303604126
Validation loss: 2.1325585226858816

Epoch: 5| Step: 4
Training loss: 1.7430177927017212
Validation loss: 2.0694188212835662

Epoch: 5| Step: 5
Training loss: 1.7369734048843384
Validation loss: 2.121212827262058

Epoch: 5| Step: 6
Training loss: 2.118325710296631
Validation loss: 2.0775994023969098

Epoch: 5| Step: 7
Training loss: 2.1314241886138916
Validation loss: 2.1383734210844962

Epoch: 5| Step: 8
Training loss: 1.9724814891815186
Validation loss: 2.1204548599899455

Epoch: 5| Step: 9
Training loss: 2.4060912132263184
Validation loss: 2.1142475528101765

Epoch: 5| Step: 10
Training loss: 1.6761351823806763
Validation loss: 2.1420082238412674

Epoch: 339| Step: 0
Training loss: 1.6776460409164429
Validation loss: 2.112804930697205

Epoch: 5| Step: 1
Training loss: 2.2559754848480225
Validation loss: 2.1602831963569886

Epoch: 5| Step: 2
Training loss: 1.6371256113052368
Validation loss: 2.1836752891540527

Epoch: 5| Step: 3
Training loss: 1.1405136585235596
Validation loss: 2.1801276770971154

Epoch: 5| Step: 4
Training loss: 2.412463665008545
Validation loss: 2.129433770333567

Epoch: 5| Step: 5
Training loss: 2.1458780765533447
Validation loss: 2.0856762316919144

Epoch: 5| Step: 6
Training loss: 2.451610565185547
Validation loss: 2.1282297834273307

Epoch: 5| Step: 7
Training loss: 1.7746673822402954
Validation loss: 2.118935808058708

Epoch: 5| Step: 8
Training loss: 1.8994114398956299
Validation loss: 2.1337509962820236

Epoch: 5| Step: 9
Training loss: 1.4926477670669556
Validation loss: 2.159431360101187

Epoch: 5| Step: 10
Training loss: 1.4844286441802979
Validation loss: 2.10422505358214

Epoch: 340| Step: 0
Training loss: 1.3812472820281982
Validation loss: 2.1066510946519914

Epoch: 5| Step: 1
Training loss: 1.2387603521347046
Validation loss: 2.1139098854475122

Epoch: 5| Step: 2
Training loss: 1.7497446537017822
Validation loss: 2.1031663071724678

Epoch: 5| Step: 3
Training loss: 2.3906140327453613
Validation loss: 2.1215880147872435

Epoch: 5| Step: 4
Training loss: 2.279355525970459
Validation loss: 2.1025562978559926

Epoch: 5| Step: 5
Training loss: 2.4632179737091064
Validation loss: 2.131939420136072

Epoch: 5| Step: 6
Training loss: 1.915461778640747
Validation loss: 2.086812065493676

Epoch: 5| Step: 7
Training loss: 2.079725742340088
Validation loss: 2.1355370859945975

Epoch: 5| Step: 8
Training loss: 1.731781005859375
Validation loss: 2.0833272357140817

Epoch: 5| Step: 9
Training loss: 1.622953176498413
Validation loss: 2.1115637466471684

Epoch: 5| Step: 10
Training loss: 1.29794180393219
Validation loss: 2.102676349301492

Epoch: 341| Step: 0
Training loss: 1.8066387176513672
Validation loss: 2.1112795042735275

Epoch: 5| Step: 1
Training loss: 1.5902940034866333
Validation loss: 2.0964683768569783

Epoch: 5| Step: 2
Training loss: 1.2922929525375366
Validation loss: 2.1260034422720633

Epoch: 5| Step: 3
Training loss: 1.8665287494659424
Validation loss: 2.1078248972533853

Epoch: 5| Step: 4
Training loss: 2.457254409790039
Validation loss: 2.109945809969338

Epoch: 5| Step: 5
Training loss: 1.8796093463897705
Validation loss: 2.0748051815135504

Epoch: 5| Step: 6
Training loss: 2.149526596069336
Validation loss: 2.0784228860691027

Epoch: 5| Step: 7
Training loss: 1.5362900495529175
Validation loss: 2.094919930222214

Epoch: 5| Step: 8
Training loss: 1.821700096130371
Validation loss: 2.0742805081029094

Epoch: 5| Step: 9
Training loss: 1.9650189876556396
Validation loss: 2.1373886651890253

Epoch: 5| Step: 10
Training loss: 1.9814668893814087
Validation loss: 2.086588616012245

Epoch: 342| Step: 0
Training loss: 1.7455673217773438
Validation loss: 2.1240736515291276

Epoch: 5| Step: 1
Training loss: 2.3576645851135254
Validation loss: 2.073960009441581

Epoch: 5| Step: 2
Training loss: 1.3141286373138428
Validation loss: 2.0623839798794

Epoch: 5| Step: 3
Training loss: 1.7436769008636475
Validation loss: 2.0596129227710027

Epoch: 5| Step: 4
Training loss: 1.4140734672546387
Validation loss: 2.0853451708311677

Epoch: 5| Step: 5
Training loss: 2.648705244064331
Validation loss: 2.0710311243610997

Epoch: 5| Step: 6
Training loss: 2.389979839324951
Validation loss: 2.128548765695223

Epoch: 5| Step: 7
Training loss: 1.101951003074646
Validation loss: 2.0595824385202057

Epoch: 5| Step: 8
Training loss: 1.8849213123321533
Validation loss: 2.08983241486293

Epoch: 5| Step: 9
Training loss: 1.8376554250717163
Validation loss: 2.117830732817291

Epoch: 5| Step: 10
Training loss: 1.7892190217971802
Validation loss: 2.093295543424545

Epoch: 343| Step: 0
Training loss: 1.729549765586853
Validation loss: 2.092422357169531

Epoch: 5| Step: 1
Training loss: 2.283674955368042
Validation loss: 2.0404003897020893

Epoch: 5| Step: 2
Training loss: 1.8438389301300049
Validation loss: 2.125148839848016

Epoch: 5| Step: 3
Training loss: 1.8744773864746094
Validation loss: 2.1060737691899782

Epoch: 5| Step: 4
Training loss: 1.9949737787246704
Validation loss: 2.1539893163147794

Epoch: 5| Step: 5
Training loss: 1.2908155918121338
Validation loss: 2.139162753217964

Epoch: 5| Step: 6
Training loss: 1.2114098072052002
Validation loss: 2.068141746264632

Epoch: 5| Step: 7
Training loss: 2.022346258163452
Validation loss: 2.0732705529018114

Epoch: 5| Step: 8
Training loss: 2.20483660697937
Validation loss: 2.147604444975494

Epoch: 5| Step: 9
Training loss: 1.5590900182724
Validation loss: 2.1125274832530687

Epoch: 5| Step: 10
Training loss: 2.4078192710876465
Validation loss: 2.1116593499337473

Epoch: 344| Step: 0
Training loss: 2.1544198989868164
Validation loss: 2.0844258300719725

Epoch: 5| Step: 1
Training loss: 1.7796554565429688
Validation loss: 2.117242408055131

Epoch: 5| Step: 2
Training loss: 1.939347505569458
Validation loss: 2.1347241811854865

Epoch: 5| Step: 3
Training loss: 1.8741165399551392
Validation loss: 2.0942017955164753

Epoch: 5| Step: 4
Training loss: 1.9222157001495361
Validation loss: 2.1225786209106445

Epoch: 5| Step: 5
Training loss: 1.5332664251327515
Validation loss: 2.0807332659280426

Epoch: 5| Step: 6
Training loss: 1.4138284921646118
Validation loss: 2.1138543211003786

Epoch: 5| Step: 7
Training loss: 1.5010265111923218
Validation loss: 2.0590728149619153

Epoch: 5| Step: 8
Training loss: 1.9533023834228516
Validation loss: 2.148991330977409

Epoch: 5| Step: 9
Training loss: 1.9901926517486572
Validation loss: 2.0609109658066944

Epoch: 5| Step: 10
Training loss: 2.0225331783294678
Validation loss: 2.1636099225731305

Epoch: 345| Step: 0
Training loss: 1.125113844871521
Validation loss: 2.071147362391154

Epoch: 5| Step: 1
Training loss: 1.7518041133880615
Validation loss: 2.1430682110530075

Epoch: 5| Step: 2
Training loss: 1.909552812576294
Validation loss: 2.099501484183855

Epoch: 5| Step: 3
Training loss: 2.013697862625122
Validation loss: 2.157567959959789

Epoch: 5| Step: 4
Training loss: 1.5906530618667603
Validation loss: 2.095027847956586

Epoch: 5| Step: 5
Training loss: 1.6829665899276733
Validation loss: 2.127552637489893

Epoch: 5| Step: 6
Training loss: 2.010190010070801
Validation loss: 2.0934723936101443

Epoch: 5| Step: 7
Training loss: 2.5666491985321045
Validation loss: 2.077993041725569

Epoch: 5| Step: 8
Training loss: 1.7310879230499268
Validation loss: 2.128549442496351

Epoch: 5| Step: 9
Training loss: 1.5944249629974365
Validation loss: 2.1147011633842223

Epoch: 5| Step: 10
Training loss: 1.9758692979812622
Validation loss: 2.0948092424741356

Epoch: 346| Step: 0
Training loss: 1.9452857971191406
Validation loss: 2.107987939670522

Epoch: 5| Step: 1
Training loss: 1.9082050323486328
Validation loss: 2.11245112393492

Epoch: 5| Step: 2
Training loss: 1.62441086769104
Validation loss: 2.097268722390616

Epoch: 5| Step: 3
Training loss: 1.967431664466858
Validation loss: 2.1165396910841747

Epoch: 5| Step: 4
Training loss: 1.7724593877792358
Validation loss: 2.1135808396083053

Epoch: 5| Step: 5
Training loss: 1.9030942916870117
Validation loss: 2.0898100919620965

Epoch: 5| Step: 6
Training loss: 2.01129412651062
Validation loss: 2.087380629713817

Epoch: 5| Step: 7
Training loss: 2.030503988265991
Validation loss: 2.1060073734611593

Epoch: 5| Step: 8
Training loss: 1.635310173034668
Validation loss: 2.167980250491891

Epoch: 5| Step: 9
Training loss: 1.7447926998138428
Validation loss: 2.1218320400484147

Epoch: 5| Step: 10
Training loss: 1.731950044631958
Validation loss: 2.0738874353388304

Epoch: 347| Step: 0
Training loss: 1.8699373006820679
Validation loss: 2.1009324366046536

Epoch: 5| Step: 1
Training loss: 2.0717806816101074
Validation loss: 2.1367940479709255

Epoch: 5| Step: 2
Training loss: 2.171596050262451
Validation loss: 2.118507872345627

Epoch: 5| Step: 3
Training loss: 2.0131332874298096
Validation loss: 2.1072812990475724

Epoch: 5| Step: 4
Training loss: 2.150486469268799
Validation loss: 2.0874185690315823

Epoch: 5| Step: 5
Training loss: 1.4726961851119995
Validation loss: 2.097505610476258

Epoch: 5| Step: 6
Training loss: 1.7097980976104736
Validation loss: 2.12484973220415

Epoch: 5| Step: 7
Training loss: 1.883766770362854
Validation loss: 2.091107564587747

Epoch: 5| Step: 8
Training loss: 1.6414960622787476
Validation loss: 2.0687765998225056

Epoch: 5| Step: 9
Training loss: 1.0330698490142822
Validation loss: 2.061515164631669

Epoch: 5| Step: 10
Training loss: 2.0519590377807617
Validation loss: 2.0597987110896776

Epoch: 348| Step: 0
Training loss: 2.352200508117676
Validation loss: 2.0564703941345215

Epoch: 5| Step: 1
Training loss: 2.1899120807647705
Validation loss: 2.0875525141275055

Epoch: 5| Step: 2
Training loss: 2.17703914642334
Validation loss: 2.1267098214036677

Epoch: 5| Step: 3
Training loss: 1.8314836025238037
Validation loss: 2.1141265335903374

Epoch: 5| Step: 4
Training loss: 1.4548091888427734
Validation loss: 2.0960158558302027

Epoch: 5| Step: 5
Training loss: 1.759617805480957
Validation loss: 2.0977065614474717

Epoch: 5| Step: 6
Training loss: 1.4009336233139038
Validation loss: 2.040187184528638

Epoch: 5| Step: 7
Training loss: 1.998230218887329
Validation loss: 2.029745522365775

Epoch: 5| Step: 8
Training loss: 1.7277610301971436
Validation loss: 2.0681537582028295

Epoch: 5| Step: 9
Training loss: 1.8306047916412354
Validation loss: 2.076166965628183

Epoch: 5| Step: 10
Training loss: 1.3056786060333252
Validation loss: 2.092097318300637

Epoch: 349| Step: 0
Training loss: 2.033562183380127
Validation loss: 2.085920786344877

Epoch: 5| Step: 1
Training loss: 1.314445972442627
Validation loss: 2.1364300968826457

Epoch: 5| Step: 2
Training loss: 1.8149268627166748
Validation loss: 2.0998649904804845

Epoch: 5| Step: 3
Training loss: 1.524268388748169
Validation loss: 2.1037270715159755

Epoch: 5| Step: 4
Training loss: 1.8669679164886475
Validation loss: 2.1761445588963007

Epoch: 5| Step: 5
Training loss: 1.4609766006469727
Validation loss: 2.1175562861145183

Epoch: 5| Step: 6
Training loss: 2.2681822776794434
Validation loss: 2.066047248019967

Epoch: 5| Step: 7
Training loss: 1.9403682947158813
Validation loss: 2.0810502318925757

Epoch: 5| Step: 8
Training loss: 1.9908850193023682
Validation loss: 2.104430099969269

Epoch: 5| Step: 9
Training loss: 2.05271053314209
Validation loss: 2.084108334715648

Epoch: 5| Step: 10
Training loss: 1.8804774284362793
Validation loss: 2.074396712805635

Epoch: 350| Step: 0
Training loss: 1.6137101650238037
Validation loss: 2.1241869195815055

Epoch: 5| Step: 1
Training loss: 2.2365291118621826
Validation loss: 2.1139622029437812

Epoch: 5| Step: 2
Training loss: 1.5489845275878906
Validation loss: 2.1070565741549254

Epoch: 5| Step: 3
Training loss: 1.9999361038208008
Validation loss: 2.1327922267298542

Epoch: 5| Step: 4
Training loss: 1.9252140522003174
Validation loss: 2.1598589856137513

Epoch: 5| Step: 5
Training loss: 2.25712513923645
Validation loss: 2.1590612703754055

Epoch: 5| Step: 6
Training loss: 1.5435645580291748
Validation loss: 2.108308272977029

Epoch: 5| Step: 7
Training loss: 1.7364057302474976
Validation loss: 2.0825793358587448

Epoch: 5| Step: 8
Training loss: 2.3981142044067383
Validation loss: 2.133208772187592

Epoch: 5| Step: 9
Training loss: 1.642053246498108
Validation loss: 2.1385196485827045

Epoch: 5| Step: 10
Training loss: 1.262218713760376
Validation loss: 2.137506120948381

Epoch: 351| Step: 0
Training loss: 1.7877105474472046
Validation loss: 2.0596213456123107

Epoch: 5| Step: 1
Training loss: 2.0849251747131348
Validation loss: 2.108271239906229

Epoch: 5| Step: 2
Training loss: 2.2091140747070312
Validation loss: 2.0997244094007756

Epoch: 5| Step: 3
Training loss: 1.7367416620254517
Validation loss: 2.1188050341862503

Epoch: 5| Step: 4
Training loss: 1.7062991857528687
Validation loss: 2.082366126839833

Epoch: 5| Step: 5
Training loss: 2.3478028774261475
Validation loss: 2.049526599145705

Epoch: 5| Step: 6
Training loss: 1.8694484233856201
Validation loss: 2.1131126893463956

Epoch: 5| Step: 7
Training loss: 1.6253855228424072
Validation loss: 2.11131485303243

Epoch: 5| Step: 8
Training loss: 1.2600812911987305
Validation loss: 2.1007681405672463

Epoch: 5| Step: 9
Training loss: 1.6310479640960693
Validation loss: 2.0971349593131774

Epoch: 5| Step: 10
Training loss: 2.3659586906433105
Validation loss: 2.133271922347366

Epoch: 352| Step: 0
Training loss: 2.0496222972869873
Validation loss: 2.0888975909961167

Epoch: 5| Step: 1
Training loss: 1.7623577117919922
Validation loss: 2.069599166993172

Epoch: 5| Step: 2
Training loss: 2.084127426147461
Validation loss: 2.051066683184716

Epoch: 5| Step: 3
Training loss: 1.5149270296096802
Validation loss: 2.132888432471983

Epoch: 5| Step: 4
Training loss: 1.1828582286834717
Validation loss: 2.1157136091621975

Epoch: 5| Step: 5
Training loss: 2.5482566356658936
Validation loss: 2.129603378234371

Epoch: 5| Step: 6
Training loss: 1.9986493587493896
Validation loss: 2.1148844688169417

Epoch: 5| Step: 7
Training loss: 2.002962827682495
Validation loss: 2.1252941341810327

Epoch: 5| Step: 8
Training loss: 1.3688905239105225
Validation loss: 2.0978865110745994

Epoch: 5| Step: 9
Training loss: 1.3790652751922607
Validation loss: 2.125801514553767

Epoch: 5| Step: 10
Training loss: 1.9569793939590454
Validation loss: 2.0988982236513527

Epoch: 353| Step: 0
Training loss: 1.3019338846206665
Validation loss: 2.0429093786465224

Epoch: 5| Step: 1
Training loss: 1.4854705333709717
Validation loss: 2.089499681226669

Epoch: 5| Step: 2
Training loss: 1.6682720184326172
Validation loss: 2.1499978111636255

Epoch: 5| Step: 3
Training loss: 2.101301670074463
Validation loss: 2.1233810993932907

Epoch: 5| Step: 4
Training loss: 1.8468067646026611
Validation loss: 2.1746081344542967

Epoch: 5| Step: 5
Training loss: 1.8585641384124756
Validation loss: 2.0455434117265927

Epoch: 5| Step: 6
Training loss: 2.1866540908813477
Validation loss: 2.1529827758830082

Epoch: 5| Step: 7
Training loss: 1.8840348720550537
Validation loss: 2.12658275840103

Epoch: 5| Step: 8
Training loss: 1.4455407857894897
Validation loss: 2.12769151759404

Epoch: 5| Step: 9
Training loss: 1.766379952430725
Validation loss: 2.108038435700119

Epoch: 5| Step: 10
Training loss: 2.3364357948303223
Validation loss: 2.1478300556059806

Epoch: 354| Step: 0
Training loss: 2.156982183456421
Validation loss: 2.1047190722598823

Epoch: 5| Step: 1
Training loss: 1.7146663665771484
Validation loss: 2.147029483190147

Epoch: 5| Step: 2
Training loss: 1.81951105594635
Validation loss: 2.1308133627778743

Epoch: 5| Step: 3
Training loss: 2.0371594429016113
Validation loss: 2.1200381940410984

Epoch: 5| Step: 4
Training loss: 1.474509358406067
Validation loss: 2.148715190989997

Epoch: 5| Step: 5
Training loss: 2.1256916522979736
Validation loss: 2.038868481113065

Epoch: 5| Step: 6
Training loss: 1.7518609762191772
Validation loss: 2.0434219709006687

Epoch: 5| Step: 7
Training loss: 2.2718405723571777
Validation loss: 2.103378777862877

Epoch: 5| Step: 8
Training loss: 1.6372137069702148
Validation loss: 2.1344614285294727

Epoch: 5| Step: 9
Training loss: 1.4725019931793213
Validation loss: 2.1297459525446736

Epoch: 5| Step: 10
Training loss: 1.822403907775879
Validation loss: 2.090595893962409

Epoch: 355| Step: 0
Training loss: 2.0509347915649414
Validation loss: 2.1198576637493667

Epoch: 5| Step: 1
Training loss: 1.4725711345672607
Validation loss: 2.100311072923804

Epoch: 5| Step: 2
Training loss: 1.3870623111724854
Validation loss: 2.108486331919188

Epoch: 5| Step: 3
Training loss: 1.7604873180389404
Validation loss: 2.075981852828815

Epoch: 5| Step: 4
Training loss: 2.18420147895813
Validation loss: 2.1387450797583467

Epoch: 5| Step: 5
Training loss: 1.3868558406829834
Validation loss: 2.0901702155349073

Epoch: 5| Step: 6
Training loss: 1.7693145275115967
Validation loss: 2.079745090135964

Epoch: 5| Step: 7
Training loss: 1.7613229751586914
Validation loss: 2.1162532362886655

Epoch: 5| Step: 8
Training loss: 2.1162328720092773
Validation loss: 2.071076523873114

Epoch: 5| Step: 9
Training loss: 2.303163766860962
Validation loss: 2.072892658172115

Epoch: 5| Step: 10
Training loss: 1.5575478076934814
Validation loss: 2.093652945692821

Epoch: 356| Step: 0
Training loss: 2.0840494632720947
Validation loss: 2.1168317717890583

Epoch: 5| Step: 1
Training loss: 1.5991493463516235
Validation loss: 2.1107285791827786

Epoch: 5| Step: 2
Training loss: 1.5602365732192993
Validation loss: 2.1284433744286977

Epoch: 5| Step: 3
Training loss: 2.255063772201538
Validation loss: 2.137925688938428

Epoch: 5| Step: 4
Training loss: 1.9899437427520752
Validation loss: 2.0978929458125943

Epoch: 5| Step: 5
Training loss: 1.6044994592666626
Validation loss: 2.1104533877424014

Epoch: 5| Step: 6
Training loss: 1.3038136959075928
Validation loss: 2.0364552249190626

Epoch: 5| Step: 7
Training loss: 2.0161237716674805
Validation loss: 2.048749082831926

Epoch: 5| Step: 8
Training loss: 1.7929608821868896
Validation loss: 2.1054356482721146

Epoch: 5| Step: 9
Training loss: 1.7787072658538818
Validation loss: 2.13421731610452

Epoch: 5| Step: 10
Training loss: 1.756861686706543
Validation loss: 2.092032350519652

Epoch: 357| Step: 0
Training loss: 1.164150595664978
Validation loss: 2.0831117642823087

Epoch: 5| Step: 1
Training loss: 2.2077341079711914
Validation loss: 2.081679838959889

Epoch: 5| Step: 2
Training loss: 1.3042347431182861
Validation loss: 2.061061630966843

Epoch: 5| Step: 3
Training loss: 2.1920135021209717
Validation loss: 2.1347062292919365

Epoch: 5| Step: 4
Training loss: 1.8464988470077515
Validation loss: 2.112048661837014

Epoch: 5| Step: 5
Training loss: 2.4379870891571045
Validation loss: 2.0887077226433703

Epoch: 5| Step: 6
Training loss: 2.0604374408721924
Validation loss: 2.122774952201433

Epoch: 5| Step: 7
Training loss: 1.615984559059143
Validation loss: 2.069413318428942

Epoch: 5| Step: 8
Training loss: 1.8966232538223267
Validation loss: 2.122134393261325

Epoch: 5| Step: 9
Training loss: 1.9339758157730103
Validation loss: 2.105030393087736

Epoch: 5| Step: 10
Training loss: 1.2527321577072144
Validation loss: 2.135352567959857

Epoch: 358| Step: 0
Training loss: 1.820167899131775
Validation loss: 2.0613023927134853

Epoch: 5| Step: 1
Training loss: 1.7198879718780518
Validation loss: 2.0795380453909598

Epoch: 5| Step: 2
Training loss: 2.233118772506714
Validation loss: 2.116434510036181

Epoch: 5| Step: 3
Training loss: 1.5148626565933228
Validation loss: 2.1360165906208817

Epoch: 5| Step: 4
Training loss: 1.7641185522079468
Validation loss: 2.149362956323931

Epoch: 5| Step: 5
Training loss: 1.8861945867538452
Validation loss: 2.1175841464791247

Epoch: 5| Step: 6
Training loss: 1.8474094867706299
Validation loss: 2.0804465573321105

Epoch: 5| Step: 7
Training loss: 2.3398118019104004
Validation loss: 2.1401114027987242

Epoch: 5| Step: 8
Training loss: 1.3027836084365845
Validation loss: 2.130067335662021

Epoch: 5| Step: 9
Training loss: 1.6978943347930908
Validation loss: 2.1367256026114188

Epoch: 5| Step: 10
Training loss: 1.8100309371948242
Validation loss: 2.120393458233085

Epoch: 359| Step: 0
Training loss: 1.6854578256607056
Validation loss: 2.088611170809756

Epoch: 5| Step: 1
Training loss: 2.6925368309020996
Validation loss: 2.1112065443428616

Epoch: 5| Step: 2
Training loss: 1.86147141456604
Validation loss: 2.069003633273545

Epoch: 5| Step: 3
Training loss: 1.991121530532837
Validation loss: 2.093342593921128

Epoch: 5| Step: 4
Training loss: 1.7436250448226929
Validation loss: 2.079681258047781

Epoch: 5| Step: 5
Training loss: 1.8079960346221924
Validation loss: 2.087448003471539

Epoch: 5| Step: 6
Training loss: 2.0444774627685547
Validation loss: 2.063711799601073

Epoch: 5| Step: 7
Training loss: 1.3855444192886353
Validation loss: 2.107546019297774

Epoch: 5| Step: 8
Training loss: 1.4767545461654663
Validation loss: 2.1155011423172487

Epoch: 5| Step: 9
Training loss: 1.2577097415924072
Validation loss: 2.103512889595442

Epoch: 5| Step: 10
Training loss: 2.0289320945739746
Validation loss: 2.0850684950428624

Epoch: 360| Step: 0
Training loss: 2.5275425910949707
Validation loss: 2.113186510660315

Epoch: 5| Step: 1
Training loss: 1.8835604190826416
Validation loss: 2.115567473955052

Epoch: 5| Step: 2
Training loss: 1.2039083242416382
Validation loss: 2.1408911520434963

Epoch: 5| Step: 3
Training loss: 2.6273205280303955
Validation loss: 2.0767448730366205

Epoch: 5| Step: 4
Training loss: 1.5294030904769897
Validation loss: 2.032075383329904

Epoch: 5| Step: 5
Training loss: 1.3687248229980469
Validation loss: 2.087200162231281

Epoch: 5| Step: 6
Training loss: 1.3642542362213135
Validation loss: 2.1115583271108647

Epoch: 5| Step: 7
Training loss: 1.6939599514007568
Validation loss: 2.0348393173627954

Epoch: 5| Step: 8
Training loss: 2.0132651329040527
Validation loss: 2.056022858106962

Epoch: 5| Step: 9
Training loss: 1.7346214056015015
Validation loss: 2.1213171123176493

Epoch: 5| Step: 10
Training loss: 1.705384612083435
Validation loss: 2.12256291092083

Epoch: 361| Step: 0
Training loss: 1.9514992237091064
Validation loss: 2.123717931009108

Epoch: 5| Step: 1
Training loss: 1.5601049661636353
Validation loss: 2.146759481840236

Epoch: 5| Step: 2
Training loss: 1.2606546878814697
Validation loss: 2.070785641670227

Epoch: 5| Step: 3
Training loss: 2.318554401397705
Validation loss: 2.101016272780716

Epoch: 5| Step: 4
Training loss: 1.9743385314941406
Validation loss: 2.1398747544134817

Epoch: 5| Step: 5
Training loss: 2.8590445518493652
Validation loss: 2.0928682229852162

Epoch: 5| Step: 6
Training loss: 1.5391731262207031
Validation loss: 2.073423724020681

Epoch: 5| Step: 7
Training loss: 1.2564356327056885
Validation loss: 2.1089253912689867

Epoch: 5| Step: 8
Training loss: 2.086318016052246
Validation loss: 2.117894018850019

Epoch: 5| Step: 9
Training loss: 1.6413071155548096
Validation loss: 2.0530144040302565

Epoch: 5| Step: 10
Training loss: 1.4066321849822998
Validation loss: 2.118997076506256

Epoch: 362| Step: 0
Training loss: 1.7475159168243408
Validation loss: 2.0956137308510403

Epoch: 5| Step: 1
Training loss: 1.803055763244629
Validation loss: 2.092127543623729

Epoch: 5| Step: 2
Training loss: 2.083815097808838
Validation loss: 2.0791684645478443

Epoch: 5| Step: 3
Training loss: 2.2580454349517822
Validation loss: 2.093364525866765

Epoch: 5| Step: 4
Training loss: 1.7692409753799438
Validation loss: 2.1153844441137006

Epoch: 5| Step: 5
Training loss: 1.716156244277954
Validation loss: 2.0871561317033667

Epoch: 5| Step: 6
Training loss: 1.2315435409545898
Validation loss: 2.1039801182285434

Epoch: 5| Step: 7
Training loss: 1.4192335605621338
Validation loss: 2.119702334045082

Epoch: 5| Step: 8
Training loss: 1.942842721939087
Validation loss: 2.0842396315707954

Epoch: 5| Step: 9
Training loss: 1.931148886680603
Validation loss: 2.0933614905162523

Epoch: 5| Step: 10
Training loss: 2.0224642753601074
Validation loss: 2.136630372334552

Epoch: 363| Step: 0
Training loss: 1.9385871887207031
Validation loss: 2.050328452100036

Epoch: 5| Step: 1
Training loss: 1.3397021293640137
Validation loss: 2.0988245779468166

Epoch: 5| Step: 2
Training loss: 1.645316481590271
Validation loss: 2.103628396987915

Epoch: 5| Step: 3
Training loss: 2.0157394409179688
Validation loss: 2.059984698090502

Epoch: 5| Step: 4
Training loss: 1.3632657527923584
Validation loss: 2.0945023875082693

Epoch: 5| Step: 5
Training loss: 1.4680345058441162
Validation loss: 2.1252672902999388

Epoch: 5| Step: 6
Training loss: 1.6922649145126343
Validation loss: 2.138212414198024

Epoch: 5| Step: 7
Training loss: 1.8445980548858643
Validation loss: 2.107612813672712

Epoch: 5| Step: 8
Training loss: 2.024163246154785
Validation loss: 2.104108779661117

Epoch: 5| Step: 9
Training loss: 2.164767026901245
Validation loss: 2.1185155350674867

Epoch: 5| Step: 10
Training loss: 2.336954355239868
Validation loss: 2.118564436512609

Epoch: 364| Step: 0
Training loss: 1.8523451089859009
Validation loss: 2.1269180031232935

Epoch: 5| Step: 1
Training loss: 1.1178175210952759
Validation loss: 2.027992290835227

Epoch: 5| Step: 2
Training loss: 1.9751726388931274
Validation loss: 2.1129903844607774

Epoch: 5| Step: 3
Training loss: 2.1630659103393555
Validation loss: 2.115338438300676

Epoch: 5| Step: 4
Training loss: 1.3252427577972412
Validation loss: 2.056095894946847

Epoch: 5| Step: 5
Training loss: 1.9751344919204712
Validation loss: 2.122387086191485

Epoch: 5| Step: 6
Training loss: 2.1322250366210938
Validation loss: 2.151667821791864

Epoch: 5| Step: 7
Training loss: 1.3716126680374146
Validation loss: 2.0834383810720136

Epoch: 5| Step: 8
Training loss: 1.9339431524276733
Validation loss: 2.1040073466557327

Epoch: 5| Step: 9
Training loss: 2.032806873321533
Validation loss: 2.1028938626730316

Epoch: 5| Step: 10
Training loss: 2.0979058742523193
Validation loss: 2.0723364173725085

Epoch: 365| Step: 0
Training loss: 1.6290935277938843
Validation loss: 2.141563633436798

Epoch: 5| Step: 1
Training loss: 1.647404432296753
Validation loss: 2.0889493521823677

Epoch: 5| Step: 2
Training loss: 1.7623484134674072
Validation loss: 2.0705701394747664

Epoch: 5| Step: 3
Training loss: 1.752971887588501
Validation loss: 2.0514404671166533

Epoch: 5| Step: 4
Training loss: 1.8561429977416992
Validation loss: 2.1154107175847536

Epoch: 5| Step: 5
Training loss: 2.174313545227051
Validation loss: 2.0833892258264686

Epoch: 5| Step: 6
Training loss: 1.7608108520507812
Validation loss: 2.1032630423063874

Epoch: 5| Step: 7
Training loss: 2.3256850242614746
Validation loss: 2.0809382738605624

Epoch: 5| Step: 8
Training loss: 1.670007348060608
Validation loss: 2.100742461860821

Epoch: 5| Step: 9
Training loss: 1.6176071166992188
Validation loss: 2.130212281339912

Epoch: 5| Step: 10
Training loss: 1.5504339933395386
Validation loss: 2.084745644241251

Epoch: 366| Step: 0
Training loss: 1.9300305843353271
Validation loss: 2.1637245326913814

Epoch: 5| Step: 1
Training loss: 1.5474350452423096
Validation loss: 2.127003813302645

Epoch: 5| Step: 2
Training loss: 1.8481807708740234
Validation loss: 2.094790079260385

Epoch: 5| Step: 3
Training loss: 1.6555817127227783
Validation loss: 2.1751134882691088

Epoch: 5| Step: 4
Training loss: 1.9796336889266968
Validation loss: 2.0566136913914836

Epoch: 5| Step: 5
Training loss: 2.058964252471924
Validation loss: 2.1328637958854757

Epoch: 5| Step: 6
Training loss: 1.8241838216781616
Validation loss: 2.121651061119572

Epoch: 5| Step: 7
Training loss: 1.6253688335418701
Validation loss: 2.0550766298847813

Epoch: 5| Step: 8
Training loss: 1.429561972618103
Validation loss: 2.0871725338761524

Epoch: 5| Step: 9
Training loss: 1.2961534261703491
Validation loss: 2.1217107221644413

Epoch: 5| Step: 10
Training loss: 2.4743950366973877
Validation loss: 2.128286364257977

Epoch: 367| Step: 0
Training loss: 1.9762725830078125
Validation loss: 2.1514578224510275

Epoch: 5| Step: 1
Training loss: 2.019880533218384
Validation loss: 2.1136276234862623

Epoch: 5| Step: 2
Training loss: 2.0707008838653564
Validation loss: 2.102357332424451

Epoch: 5| Step: 3
Training loss: 1.313305139541626
Validation loss: 2.0958584265042375

Epoch: 5| Step: 4
Training loss: 1.4962763786315918
Validation loss: 2.130020326183688

Epoch: 5| Step: 5
Training loss: 1.6474182605743408
Validation loss: 2.1372128340505783

Epoch: 5| Step: 6
Training loss: 1.9302895069122314
Validation loss: 2.0859179291673886

Epoch: 5| Step: 7
Training loss: 1.3337821960449219
Validation loss: 2.069875201871318

Epoch: 5| Step: 8
Training loss: 1.9336979389190674
Validation loss: 2.1302527586619058

Epoch: 5| Step: 9
Training loss: 1.8359403610229492
Validation loss: 2.071786721547445

Epoch: 5| Step: 10
Training loss: 1.8818120956420898
Validation loss: 2.124176033081547

Epoch: 368| Step: 0
Training loss: 2.2760186195373535
Validation loss: 2.078996668579758

Epoch: 5| Step: 1
Training loss: 1.4719598293304443
Validation loss: 2.121397426051478

Epoch: 5| Step: 2
Training loss: 1.808680534362793
Validation loss: 2.127885457008116

Epoch: 5| Step: 3
Training loss: 1.5788793563842773
Validation loss: 2.0614560111876457

Epoch: 5| Step: 4
Training loss: 1.9698737859725952
Validation loss: 2.0877314357347387

Epoch: 5| Step: 5
Training loss: 1.6258713006973267
Validation loss: 2.1206907636375836

Epoch: 5| Step: 6
Training loss: 2.096844434738159
Validation loss: 2.108751017560241

Epoch: 5| Step: 7
Training loss: 0.9720743298530579
Validation loss: 2.1526160342718965

Epoch: 5| Step: 8
Training loss: 2.1991493701934814
Validation loss: 2.118609607860606

Epoch: 5| Step: 9
Training loss: 2.0550150871276855
Validation loss: 2.078888456026713

Epoch: 5| Step: 10
Training loss: 1.4115607738494873
Validation loss: 2.0745426788124988

Epoch: 369| Step: 0
Training loss: 2.0681421756744385
Validation loss: 2.071537950987457

Epoch: 5| Step: 1
Training loss: 2.04541015625
Validation loss: 2.045997932393064

Epoch: 5| Step: 2
Training loss: 1.6240224838256836
Validation loss: 2.0893194829263995

Epoch: 5| Step: 3
Training loss: 1.9172947406768799
Validation loss: 2.1207643414056427

Epoch: 5| Step: 4
Training loss: 1.7546005249023438
Validation loss: 2.0904299007949008

Epoch: 5| Step: 5
Training loss: 2.256960391998291
Validation loss: 2.083326975504557

Epoch: 5| Step: 6
Training loss: 1.6447277069091797
Validation loss: 2.1447997862292874

Epoch: 5| Step: 7
Training loss: 2.0660440921783447
Validation loss: 2.1149858838768414

Epoch: 5| Step: 8
Training loss: 1.222210168838501
Validation loss: 2.1314970267716276

Epoch: 5| Step: 9
Training loss: 1.4041728973388672
Validation loss: 2.1491014380608835

Epoch: 5| Step: 10
Training loss: 1.7653424739837646
Validation loss: 2.111861567343435

Epoch: 370| Step: 0
Training loss: 1.732020378112793
Validation loss: 2.0634361031234905

Epoch: 5| Step: 1
Training loss: 1.937008261680603
Validation loss: 2.1637657406509563

Epoch: 5| Step: 2
Training loss: 2.0848841667175293
Validation loss: 2.162702101533131

Epoch: 5| Step: 3
Training loss: 1.4108511209487915
Validation loss: 2.1158605455070414

Epoch: 5| Step: 4
Training loss: 1.9164403676986694
Validation loss: 2.1770900500717985

Epoch: 5| Step: 5
Training loss: 1.9618275165557861
Validation loss: 2.094538034931306

Epoch: 5| Step: 6
Training loss: 1.7195059061050415
Validation loss: 2.111730593507008

Epoch: 5| Step: 7
Training loss: 1.6125710010528564
Validation loss: 2.1183828948646464

Epoch: 5| Step: 8
Training loss: 1.568617582321167
Validation loss: 2.0868441110016196

Epoch: 5| Step: 9
Training loss: 1.989964485168457
Validation loss: 2.0889702791808755

Epoch: 5| Step: 10
Training loss: 1.6793665885925293
Validation loss: 2.1259026681223223

Epoch: 371| Step: 0
Training loss: 1.8437137603759766
Validation loss: 2.1175967698456137

Epoch: 5| Step: 1
Training loss: 1.4996713399887085
Validation loss: 2.097504587583644

Epoch: 5| Step: 2
Training loss: 2.0446674823760986
Validation loss: 2.169379775242139

Epoch: 5| Step: 3
Training loss: 1.7867845296859741
Validation loss: 2.1102473658900105

Epoch: 5| Step: 4
Training loss: 1.55277681350708
Validation loss: 2.058092448019212

Epoch: 5| Step: 5
Training loss: 2.2574024200439453
Validation loss: 2.1429001182638188

Epoch: 5| Step: 6
Training loss: 1.7859392166137695
Validation loss: 2.1207799603862147

Epoch: 5| Step: 7
Training loss: 1.1823012828826904
Validation loss: 2.1331171656167633

Epoch: 5| Step: 8
Training loss: 1.8151143789291382
Validation loss: 2.0750374460733063

Epoch: 5| Step: 9
Training loss: 1.867374062538147
Validation loss: 2.051829009927729

Epoch: 5| Step: 10
Training loss: 1.8379602432250977
Validation loss: 2.105903180696631

Epoch: 372| Step: 0
Training loss: 1.559049367904663
Validation loss: 2.1509934394590315

Epoch: 5| Step: 1
Training loss: 1.7921340465545654
Validation loss: 2.0922450352740545

Epoch: 5| Step: 2
Training loss: 1.793959617614746
Validation loss: 2.08104601470373

Epoch: 5| Step: 3
Training loss: 1.707288384437561
Validation loss: 2.1515601706761185

Epoch: 5| Step: 4
Training loss: 2.2910714149475098
Validation loss: 2.056911506960469

Epoch: 5| Step: 5
Training loss: 1.3680479526519775
Validation loss: 2.0566058094783495

Epoch: 5| Step: 6
Training loss: 1.674431562423706
Validation loss: 2.1121537364939207

Epoch: 5| Step: 7
Training loss: 1.8012062311172485
Validation loss: 2.0567898775941584

Epoch: 5| Step: 8
Training loss: 1.8956167697906494
Validation loss: 2.0993342271415134

Epoch: 5| Step: 9
Training loss: 1.8201496601104736
Validation loss: 2.1178911898725774

Epoch: 5| Step: 10
Training loss: 1.9949475526809692
Validation loss: 2.137387510268919

Epoch: 373| Step: 0
Training loss: 1.3061515092849731
Validation loss: 2.163873093102568

Epoch: 5| Step: 1
Training loss: 1.512730598449707
Validation loss: 2.064300255108905

Epoch: 5| Step: 2
Training loss: 1.746512770652771
Validation loss: 2.065957315506474

Epoch: 5| Step: 3
Training loss: 2.9025254249572754
Validation loss: 2.1390862503359394

Epoch: 5| Step: 4
Training loss: 2.1514413356781006
Validation loss: 2.104396422704061

Epoch: 5| Step: 5
Training loss: 1.3919029235839844
Validation loss: 2.1199358150523198

Epoch: 5| Step: 6
Training loss: 1.6663343906402588
Validation loss: 2.1235698551260014

Epoch: 5| Step: 7
Training loss: 1.837953805923462
Validation loss: 2.1461231375253327

Epoch: 5| Step: 8
Training loss: 1.3687220811843872
Validation loss: 2.1223433991914153

Epoch: 5| Step: 9
Training loss: 1.9281904697418213
Validation loss: 2.1421009032957015

Epoch: 5| Step: 10
Training loss: 1.6874279975891113
Validation loss: 2.05344323701756

Epoch: 374| Step: 0
Training loss: 1.2314761877059937
Validation loss: 2.14836424012338

Epoch: 5| Step: 1
Training loss: 1.2297155857086182
Validation loss: 2.0991147231030207

Epoch: 5| Step: 2
Training loss: 1.478943109512329
Validation loss: 2.1354733897793676

Epoch: 5| Step: 3
Training loss: 2.0012407302856445
Validation loss: 2.100167833348756

Epoch: 5| Step: 4
Training loss: 1.584235668182373
Validation loss: 2.1347991779286373

Epoch: 5| Step: 5
Training loss: 1.8385196924209595
Validation loss: 2.1462770303090415

Epoch: 5| Step: 6
Training loss: 1.6823899745941162
Validation loss: 2.0895414121689333

Epoch: 5| Step: 7
Training loss: 1.5872787237167358
Validation loss: 2.113114751795287

Epoch: 5| Step: 8
Training loss: 2.7955799102783203
Validation loss: 2.099358750927833

Epoch: 5| Step: 9
Training loss: 1.8935534954071045
Validation loss: 2.13324168164243

Epoch: 5| Step: 10
Training loss: 2.1681175231933594
Validation loss: 2.131841640318594

Epoch: 375| Step: 0
Training loss: 1.9721307754516602
Validation loss: 2.137197325306554

Epoch: 5| Step: 1
Training loss: 1.862776756286621
Validation loss: 2.108528785808112

Epoch: 5| Step: 2
Training loss: 1.9549366235733032
Validation loss: 2.080377112152756

Epoch: 5| Step: 3
Training loss: 1.3678184747695923
Validation loss: 2.1069589199558383

Epoch: 5| Step: 4
Training loss: 1.7950866222381592
Validation loss: 2.1086422730517644

Epoch: 5| Step: 5
Training loss: 2.1596813201904297
Validation loss: 2.132977580511442

Epoch: 5| Step: 6
Training loss: 1.385076642036438
Validation loss: 2.091735642443421

Epoch: 5| Step: 7
Training loss: 1.7266496419906616
Validation loss: 2.145314311468473

Epoch: 5| Step: 8
Training loss: 1.7648744583129883
Validation loss: 2.1033162942496677

Epoch: 5| Step: 9
Training loss: 1.4670546054840088
Validation loss: 2.15577313592357

Epoch: 5| Step: 10
Training loss: 1.7823988199234009
Validation loss: 2.170028381450202

Epoch: 376| Step: 0
Training loss: 2.049450397491455
Validation loss: 2.1477484856882403

Epoch: 5| Step: 1
Training loss: 2.0252280235290527
Validation loss: 2.0934607277634325

Epoch: 5| Step: 2
Training loss: 1.845995306968689
Validation loss: 2.1552202957932667

Epoch: 5| Step: 3
Training loss: 1.8061679601669312
Validation loss: 2.1163222866673626

Epoch: 5| Step: 4
Training loss: 2.0570459365844727
Validation loss: 2.1133975367392264

Epoch: 5| Step: 5
Training loss: 1.541468620300293
Validation loss: 2.0974527225699475

Epoch: 5| Step: 6
Training loss: 1.2957204580307007
Validation loss: 2.0826516561610724

Epoch: 5| Step: 7
Training loss: 1.7787847518920898
Validation loss: 2.1939957013694187

Epoch: 5| Step: 8
Training loss: 1.5926849842071533
Validation loss: 2.149035729387755

Epoch: 5| Step: 9
Training loss: 2.0188424587249756
Validation loss: 2.0798985906826553

Epoch: 5| Step: 10
Training loss: 1.8444265127182007
Validation loss: 2.044693713547081

Epoch: 377| Step: 0
Training loss: 2.2109766006469727
Validation loss: 2.089740204554732

Epoch: 5| Step: 1
Training loss: 1.9233570098876953
Validation loss: 2.1434016971177954

Epoch: 5| Step: 2
Training loss: 1.8366413116455078
Validation loss: 2.123309617401451

Epoch: 5| Step: 3
Training loss: 1.7424834966659546
Validation loss: 2.129471631460292

Epoch: 5| Step: 4
Training loss: 1.7783418893814087
Validation loss: 2.1062270364453717

Epoch: 5| Step: 5
Training loss: 1.3743938207626343
Validation loss: 2.10790938972145

Epoch: 5| Step: 6
Training loss: 1.701685905456543
Validation loss: 2.1164749194216985

Epoch: 5| Step: 7
Training loss: 2.0134482383728027
Validation loss: 2.1194256967113865

Epoch: 5| Step: 8
Training loss: 1.3754234313964844
Validation loss: 2.11076888474085

Epoch: 5| Step: 9
Training loss: 2.1742758750915527
Validation loss: 2.1484492645468762

Epoch: 5| Step: 10
Training loss: 1.9270660877227783
Validation loss: 2.1195880149000432

Epoch: 378| Step: 0
Training loss: 1.3979804515838623
Validation loss: 2.1204849609764675

Epoch: 5| Step: 1
Training loss: 1.710662841796875
Validation loss: 2.128487810011833

Epoch: 5| Step: 2
Training loss: 0.999118983745575
Validation loss: 2.1155710143427693

Epoch: 5| Step: 3
Training loss: 1.651050329208374
Validation loss: 2.070110579972626

Epoch: 5| Step: 4
Training loss: 1.7267252206802368
Validation loss: 2.11244535446167

Epoch: 5| Step: 5
Training loss: 1.711745262145996
Validation loss: 2.1170453256176365

Epoch: 5| Step: 6
Training loss: 1.2027885913848877
Validation loss: 2.1302867679185766

Epoch: 5| Step: 7
Training loss: 2.697313070297241
Validation loss: 2.0995364586512246

Epoch: 5| Step: 8
Training loss: 2.3826024532318115
Validation loss: 2.107343198150717

Epoch: 5| Step: 9
Training loss: 1.8663533926010132
Validation loss: 2.075216063889124

Epoch: 5| Step: 10
Training loss: 2.096200942993164
Validation loss: 2.0777307377066663

Epoch: 379| Step: 0
Training loss: 1.6779024600982666
Validation loss: 2.0903661174158894

Epoch: 5| Step: 1
Training loss: 1.2940618991851807
Validation loss: 2.1151230617236068

Epoch: 5| Step: 2
Training loss: 1.6380151510238647
Validation loss: 2.0505449566789853

Epoch: 5| Step: 3
Training loss: 2.083035945892334
Validation loss: 2.093174521641065

Epoch: 5| Step: 4
Training loss: 2.4911181926727295
Validation loss: 2.1086302957227154

Epoch: 5| Step: 5
Training loss: 1.885767936706543
Validation loss: 2.0232683740636355

Epoch: 5| Step: 6
Training loss: 1.8763091564178467
Validation loss: 2.0837901176944857

Epoch: 5| Step: 7
Training loss: 1.9102134704589844
Validation loss: 2.126130565520256

Epoch: 5| Step: 8
Training loss: 1.2493053674697876
Validation loss: 2.1005875897663895

Epoch: 5| Step: 9
Training loss: 1.6610794067382812
Validation loss: 2.0787532521832373

Epoch: 5| Step: 10
Training loss: 1.8656644821166992
Validation loss: 2.0727423698671403

Epoch: 380| Step: 0
Training loss: 2.5086162090301514
Validation loss: 2.0250542086939656

Epoch: 5| Step: 1
Training loss: 1.555161714553833
Validation loss: 2.093193769454956

Epoch: 5| Step: 2
Training loss: 1.7155240774154663
Validation loss: 2.121516602013701

Epoch: 5| Step: 3
Training loss: 1.7603124380111694
Validation loss: 2.091715758846652

Epoch: 5| Step: 4
Training loss: 2.075437307357788
Validation loss: 2.073209952282649

Epoch: 5| Step: 5
Training loss: 1.3464922904968262
Validation loss: 2.043850223223368

Epoch: 5| Step: 6
Training loss: 1.4298851490020752
Validation loss: 2.0855836945195354

Epoch: 5| Step: 7
Training loss: 1.7628166675567627
Validation loss: 2.0820242640792683

Epoch: 5| Step: 8
Training loss: 1.8592545986175537
Validation loss: 2.184432714216171

Epoch: 5| Step: 9
Training loss: 1.6229873895645142
Validation loss: 2.106214213114913

Epoch: 5| Step: 10
Training loss: 1.4463045597076416
Validation loss: 2.0728240769396544

Epoch: 381| Step: 0
Training loss: 1.479311227798462
Validation loss: 2.1010319763614285

Epoch: 5| Step: 1
Training loss: 1.7841846942901611
Validation loss: 2.086069389056134

Epoch: 5| Step: 2
Training loss: 2.553513765335083
Validation loss: 2.1317780453671693

Epoch: 5| Step: 3
Training loss: 1.4552390575408936
Validation loss: 2.1119568373567317

Epoch: 5| Step: 4
Training loss: 1.6092815399169922
Validation loss: 2.1137674675192883

Epoch: 5| Step: 5
Training loss: 1.7191808223724365
Validation loss: 2.083298644711894

Epoch: 5| Step: 6
Training loss: 1.9388399124145508
Validation loss: 2.1148718967232654

Epoch: 5| Step: 7
Training loss: 1.5493483543395996
Validation loss: 2.0739494151966547

Epoch: 5| Step: 8
Training loss: 1.739731788635254
Validation loss: 2.130974470287241

Epoch: 5| Step: 9
Training loss: 1.7662464380264282
Validation loss: 2.09354829788208

Epoch: 5| Step: 10
Training loss: 1.8304681777954102
Validation loss: 2.0711438476398425

Epoch: 382| Step: 0
Training loss: 2.634371280670166
Validation loss: 2.1190325547290105

Epoch: 5| Step: 1
Training loss: 1.9883044958114624
Validation loss: 2.117802304606284

Epoch: 5| Step: 2
Training loss: 1.5625799894332886
Validation loss: 2.089094777261057

Epoch: 5| Step: 3
Training loss: 1.107909083366394
Validation loss: 2.1019023118480558

Epoch: 5| Step: 4
Training loss: 2.091975450515747
Validation loss: 2.083309934985253

Epoch: 5| Step: 5
Training loss: 1.4729355573654175
Validation loss: 2.034575112404362

Epoch: 5| Step: 6
Training loss: 2.6063928604125977
Validation loss: 2.0988703261139574

Epoch: 5| Step: 7
Training loss: 1.3756581544876099
Validation loss: 2.1063621249250186

Epoch: 5| Step: 8
Training loss: 1.7868316173553467
Validation loss: 2.119369363272062

Epoch: 5| Step: 9
Training loss: 1.1341583728790283
Validation loss: 2.085829498947308

Epoch: 5| Step: 10
Training loss: 1.8793681859970093
Validation loss: 2.1394344939980456

Epoch: 383| Step: 0
Training loss: 1.1206295490264893
Validation loss: 2.108627524427188

Epoch: 5| Step: 1
Training loss: 1.595229983329773
Validation loss: 2.1012747492841495

Epoch: 5| Step: 2
Training loss: 1.8587398529052734
Validation loss: 2.0535605902312906

Epoch: 5| Step: 3
Training loss: 1.9848740100860596
Validation loss: 2.092361375849734

Epoch: 5| Step: 4
Training loss: 2.2407917976379395
Validation loss: 2.1253386928189184

Epoch: 5| Step: 5
Training loss: 1.949167013168335
Validation loss: 2.132539523545132

Epoch: 5| Step: 6
Training loss: 1.736432671546936
Validation loss: 2.1490434164642007

Epoch: 5| Step: 7
Training loss: 1.7168867588043213
Validation loss: 2.1426158669174358

Epoch: 5| Step: 8
Training loss: 1.785495400428772
Validation loss: 2.083695593700614

Epoch: 5| Step: 9
Training loss: 1.40088951587677
Validation loss: 2.0896453216511715

Epoch: 5| Step: 10
Training loss: 2.272336006164551
Validation loss: 2.135371910628452

Epoch: 384| Step: 0
Training loss: 1.6191879510879517
Validation loss: 2.0971230178750973

Epoch: 5| Step: 1
Training loss: 1.496611475944519
Validation loss: 2.0810835976754465

Epoch: 5| Step: 2
Training loss: 1.8865766525268555
Validation loss: 2.0850557665671072

Epoch: 5| Step: 3
Training loss: 1.9438087940216064
Validation loss: 2.073274717536024

Epoch: 5| Step: 4
Training loss: 1.5562461614608765
Validation loss: 2.0505889128613215

Epoch: 5| Step: 5
Training loss: 1.9030771255493164
Validation loss: 2.0998023530488372

Epoch: 5| Step: 6
Training loss: 1.5797357559204102
Validation loss: 2.093653960894513

Epoch: 5| Step: 7
Training loss: 1.6574594974517822
Validation loss: 2.126122628488848

Epoch: 5| Step: 8
Training loss: 2.433382749557495
Validation loss: 2.0605075974618234

Epoch: 5| Step: 9
Training loss: 1.4458131790161133
Validation loss: 2.086318528780373

Epoch: 5| Step: 10
Training loss: 1.8443998098373413
Validation loss: 2.101443206110308

Epoch: 385| Step: 0
Training loss: 1.8666458129882812
Validation loss: 2.0700212870874712

Epoch: 5| Step: 1
Training loss: 2.247556447982788
Validation loss: 2.133786073295019

Epoch: 5| Step: 2
Training loss: 1.372140884399414
Validation loss: 2.1270342924261607

Epoch: 5| Step: 3
Training loss: 1.637444257736206
Validation loss: 2.0967962652124386

Epoch: 5| Step: 4
Training loss: 1.994436264038086
Validation loss: 2.074852789601972

Epoch: 5| Step: 5
Training loss: 1.5223259925842285
Validation loss: 2.0955673251100766

Epoch: 5| Step: 6
Training loss: 1.8890173435211182
Validation loss: 2.1059132558043285

Epoch: 5| Step: 7
Training loss: 1.4496667385101318
Validation loss: 2.0724641148762037

Epoch: 5| Step: 8
Training loss: 1.1421617269515991
Validation loss: 2.0978174414685977

Epoch: 5| Step: 9
Training loss: 2.014270305633545
Validation loss: 2.065116714405757

Epoch: 5| Step: 10
Training loss: 1.70213782787323
Validation loss: 2.066959434939969

Epoch: 386| Step: 0
Training loss: 1.89521062374115
Validation loss: 2.1191066567615797

Epoch: 5| Step: 1
Training loss: 1.877719521522522
Validation loss: 2.086148346624067

Epoch: 5| Step: 2
Training loss: 1.634577989578247
Validation loss: 2.0924653878775974

Epoch: 5| Step: 3
Training loss: 1.7095905542373657
Validation loss: 2.148522327023168

Epoch: 5| Step: 4
Training loss: 1.9491627216339111
Validation loss: 2.082347786554726

Epoch: 5| Step: 5
Training loss: 2.47163987159729
Validation loss: 2.1334686881752423

Epoch: 5| Step: 6
Training loss: 1.5633960962295532
Validation loss: 2.1467065042065037

Epoch: 5| Step: 7
Training loss: 1.847290277481079
Validation loss: 2.0530282528169694

Epoch: 5| Step: 8
Training loss: 1.4494842290878296
Validation loss: 2.1709833888597387

Epoch: 5| Step: 9
Training loss: 1.7970510721206665
Validation loss: 2.13120299513622

Epoch: 5| Step: 10
Training loss: 1.1340326070785522
Validation loss: 2.116571207200327

Epoch: 387| Step: 0
Training loss: 2.2670743465423584
Validation loss: 2.125677613801854

Epoch: 5| Step: 1
Training loss: 1.8060442209243774
Validation loss: 2.125869038284466

Epoch: 5| Step: 2
Training loss: 1.5453983545303345
Validation loss: 2.1204988546268915

Epoch: 5| Step: 3
Training loss: 1.5434232950210571
Validation loss: 2.1233428665386733

Epoch: 5| Step: 4
Training loss: 1.7044559717178345
Validation loss: 2.1304634283947688

Epoch: 5| Step: 5
Training loss: 1.6248592138290405
Validation loss: 2.1383661377814507

Epoch: 5| Step: 6
Training loss: 1.4993515014648438
Validation loss: 2.1640152033939155

Epoch: 5| Step: 7
Training loss: 1.524827241897583
Validation loss: 2.1155595548691286

Epoch: 5| Step: 8
Training loss: 1.2847532033920288
Validation loss: 2.05779412100392

Epoch: 5| Step: 9
Training loss: 2.2116262912750244
Validation loss: 2.113439811173306

Epoch: 5| Step: 10
Training loss: 1.8528419733047485
Validation loss: 2.118759121946109

Epoch: 388| Step: 0
Training loss: 1.8198482990264893
Validation loss: 2.081691913707282

Epoch: 5| Step: 1
Training loss: 1.397653579711914
Validation loss: 2.1041583438073435

Epoch: 5| Step: 2
Training loss: 2.2856249809265137
Validation loss: 2.0832005623848207

Epoch: 5| Step: 3
Training loss: 1.6781470775604248
Validation loss: 2.139581859752696

Epoch: 5| Step: 4
Training loss: 1.240884780883789
Validation loss: 2.099503030059158

Epoch: 5| Step: 5
Training loss: 1.759006142616272
Validation loss: 2.169489724661714

Epoch: 5| Step: 6
Training loss: 1.1660263538360596
Validation loss: 2.164570641774003

Epoch: 5| Step: 7
Training loss: 2.1493418216705322
Validation loss: 2.0815291507269746

Epoch: 5| Step: 8
Training loss: 2.0594942569732666
Validation loss: 2.0607588957714778

Epoch: 5| Step: 9
Training loss: 1.6091258525848389
Validation loss: 2.0909432570139566

Epoch: 5| Step: 10
Training loss: 2.2059364318847656
Validation loss: 2.146060582130186

Epoch: 389| Step: 0
Training loss: 1.5417238473892212
Validation loss: 2.0727042075126403

Epoch: 5| Step: 1
Training loss: 1.911386489868164
Validation loss: 2.1087018802601802

Epoch: 5| Step: 2
Training loss: 2.3384387493133545
Validation loss: 2.109625374117205

Epoch: 5| Step: 3
Training loss: 1.9460890293121338
Validation loss: 2.0808853154541342

Epoch: 5| Step: 4
Training loss: 1.5331904888153076
Validation loss: 2.094165168782716

Epoch: 5| Step: 5
Training loss: 0.9870866537094116
Validation loss: 2.0737757323890604

Epoch: 5| Step: 6
Training loss: 1.4350626468658447
Validation loss: 2.087325434530935

Epoch: 5| Step: 7
Training loss: 1.8348745107650757
Validation loss: 2.123646019607462

Epoch: 5| Step: 8
Training loss: 1.7229763269424438
Validation loss: 2.1058920609053744

Epoch: 5| Step: 9
Training loss: 1.6792417764663696
Validation loss: 2.123719599939162

Epoch: 5| Step: 10
Training loss: 2.5015499591827393
Validation loss: 2.1127956208362373

Epoch: 390| Step: 0
Training loss: 1.9645192623138428
Validation loss: 2.1320456817585933

Epoch: 5| Step: 1
Training loss: 1.6890647411346436
Validation loss: 2.117355781216775

Epoch: 5| Step: 2
Training loss: 1.7926673889160156
Validation loss: 2.078118734462287

Epoch: 5| Step: 3
Training loss: 2.2088077068328857
Validation loss: 2.117606868026077

Epoch: 5| Step: 4
Training loss: 2.0351510047912598
Validation loss: 2.093605992614582

Epoch: 5| Step: 5
Training loss: 1.59805428981781
Validation loss: 2.0902156035105386

Epoch: 5| Step: 6
Training loss: 1.363223671913147
Validation loss: 2.0758780817831717

Epoch: 5| Step: 7
Training loss: 1.4537200927734375
Validation loss: 2.0339406844108336

Epoch: 5| Step: 8
Training loss: 1.3518283367156982
Validation loss: 2.054033353764524

Epoch: 5| Step: 9
Training loss: 1.4742300510406494
Validation loss: 2.0901562834298737

Epoch: 5| Step: 10
Training loss: 2.3107292652130127
Validation loss: 2.1446036215751403

Epoch: 391| Step: 0
Training loss: 2.0969412326812744
Validation loss: 2.0772847821635585

Epoch: 5| Step: 1
Training loss: 2.0587992668151855
Validation loss: 2.118367209229418

Epoch: 5| Step: 2
Training loss: 1.513561487197876
Validation loss: 2.1061934014802337

Epoch: 5| Step: 3
Training loss: 1.3168418407440186
Validation loss: 2.1420357893872004

Epoch: 5| Step: 4
Training loss: 1.7780818939208984
Validation loss: 2.082263492768811

Epoch: 5| Step: 5
Training loss: 1.7619184255599976
Validation loss: 2.079179679193804

Epoch: 5| Step: 6
Training loss: 1.6167752742767334
Validation loss: 2.0884991179230394

Epoch: 5| Step: 7
Training loss: 1.6352094411849976
Validation loss: 2.080923709818112

Epoch: 5| Step: 8
Training loss: 1.7520780563354492
Validation loss: 2.1188935246518863

Epoch: 5| Step: 9
Training loss: 1.2846472263336182
Validation loss: 2.0989072707391556

Epoch: 5| Step: 10
Training loss: 2.1015865802764893
Validation loss: 2.100013117636404

Epoch: 392| Step: 0
Training loss: 2.0094351768493652
Validation loss: 2.0769717001145884

Epoch: 5| Step: 1
Training loss: 1.6314647197723389
Validation loss: 2.089620933737806

Epoch: 5| Step: 2
Training loss: 1.3667747974395752
Validation loss: 2.092773484927352

Epoch: 5| Step: 3
Training loss: 2.2646121978759766
Validation loss: 2.1011393018948135

Epoch: 5| Step: 4
Training loss: 1.6902738809585571
Validation loss: 2.1002801028631066

Epoch: 5| Step: 5
Training loss: 1.7545839548110962
Validation loss: 2.041749749132382

Epoch: 5| Step: 6
Training loss: 1.8686625957489014
Validation loss: 2.09565984049151

Epoch: 5| Step: 7
Training loss: 1.6240355968475342
Validation loss: 2.055671784185594

Epoch: 5| Step: 8
Training loss: 1.7113029956817627
Validation loss: 2.1012400811718357

Epoch: 5| Step: 9
Training loss: 1.8239500522613525
Validation loss: 2.0574621051870365

Epoch: 5| Step: 10
Training loss: 1.3154476881027222
Validation loss: 2.0775680003627652

Epoch: 393| Step: 0
Training loss: 1.8769056797027588
Validation loss: 2.0671058342021

Epoch: 5| Step: 1
Training loss: 1.6066452264785767
Validation loss: 2.0576104810160976

Epoch: 5| Step: 2
Training loss: 1.9478965997695923
Validation loss: 2.119900647030082

Epoch: 5| Step: 3
Training loss: 1.9483305215835571
Validation loss: 2.0922843717759654

Epoch: 5| Step: 4
Training loss: 1.9701364040374756
Validation loss: 2.0964130945103143

Epoch: 5| Step: 5
Training loss: 1.4976540803909302
Validation loss: 2.072270219044019

Epoch: 5| Step: 6
Training loss: 1.5897880792617798
Validation loss: 2.0930233078618206

Epoch: 5| Step: 7
Training loss: 1.6779552698135376
Validation loss: 2.0926917086365404

Epoch: 5| Step: 8
Training loss: 1.8162044286727905
Validation loss: 2.1422899256470385

Epoch: 5| Step: 9
Training loss: 1.3199042081832886
Validation loss: 2.1112724375981156

Epoch: 5| Step: 10
Training loss: 1.5796507596969604
Validation loss: 2.091511362342424

Epoch: 394| Step: 0
Training loss: 1.925074815750122
Validation loss: 2.098488994823989

Epoch: 5| Step: 1
Training loss: 1.7036606073379517
Validation loss: 2.0751850605010986

Epoch: 5| Step: 2
Training loss: 1.4537036418914795
Validation loss: 2.0647400527872066

Epoch: 5| Step: 3
Training loss: 1.935387372970581
Validation loss: 2.0927495059146675

Epoch: 5| Step: 4
Training loss: 1.2093344926834106
Validation loss: 2.0879321047054824

Epoch: 5| Step: 5
Training loss: 1.6611671447753906
Validation loss: 2.1261139710744223

Epoch: 5| Step: 6
Training loss: 2.0039029121398926
Validation loss: 2.0594361584673644

Epoch: 5| Step: 7
Training loss: 1.7087116241455078
Validation loss: 2.0791232867907454

Epoch: 5| Step: 8
Training loss: 2.236509084701538
Validation loss: 2.041837448714882

Epoch: 5| Step: 9
Training loss: 1.8049150705337524
Validation loss: 2.085650533758184

Epoch: 5| Step: 10
Training loss: 1.6642848253250122
Validation loss: 2.105476804958877

Epoch: 395| Step: 0
Training loss: 1.310664176940918
Validation loss: 2.117069983995089

Epoch: 5| Step: 1
Training loss: 1.716850996017456
Validation loss: 2.0513353168323474

Epoch: 5| Step: 2
Training loss: 2.2781777381896973
Validation loss: 2.0720735096162364

Epoch: 5| Step: 3
Training loss: 2.332364559173584
Validation loss: 2.0618352582377772

Epoch: 5| Step: 4
Training loss: 2.1665396690368652
Validation loss: 2.0513847425419796

Epoch: 5| Step: 5
Training loss: 1.1368505954742432
Validation loss: 2.122736007936539

Epoch: 5| Step: 6
Training loss: 1.0914205312728882
Validation loss: 2.080377806899368

Epoch: 5| Step: 7
Training loss: 2.156506299972534
Validation loss: 2.0923851869439565

Epoch: 5| Step: 8
Training loss: 1.5129927396774292
Validation loss: 2.0772234227067683

Epoch: 5| Step: 9
Training loss: 1.6702749729156494
Validation loss: 2.0819678844944125

Epoch: 5| Step: 10
Training loss: 1.7870792150497437
Validation loss: 2.078338414110163

Epoch: 396| Step: 0
Training loss: 2.031383752822876
Validation loss: 2.1442603424031246

Epoch: 5| Step: 1
Training loss: 2.008396625518799
Validation loss: 2.069997864384805

Epoch: 5| Step: 2
Training loss: 1.9860166311264038
Validation loss: 2.170053251328007

Epoch: 5| Step: 3
Training loss: 1.7770553827285767
Validation loss: 2.1187495300846715

Epoch: 5| Step: 4
Training loss: 2.069723606109619
Validation loss: 2.1192641899149907

Epoch: 5| Step: 5
Training loss: 1.5164520740509033
Validation loss: 2.1112015990800757

Epoch: 5| Step: 6
Training loss: 1.3212193250656128
Validation loss: 2.092297330979378

Epoch: 5| Step: 7
Training loss: 1.6823780536651611
Validation loss: 2.0904841371761855

Epoch: 5| Step: 8
Training loss: 1.6039886474609375
Validation loss: 2.100375594631318

Epoch: 5| Step: 9
Training loss: 1.6765282154083252
Validation loss: 2.06460218275747

Epoch: 5| Step: 10
Training loss: 1.3195863962173462
Validation loss: 2.0869792251176733

Epoch: 397| Step: 0
Training loss: 1.0040667057037354
Validation loss: 2.042777354999255

Epoch: 5| Step: 1
Training loss: 2.492424964904785
Validation loss: 2.129092029345933

Epoch: 5| Step: 2
Training loss: 1.6733996868133545
Validation loss: 2.1029554618302213

Epoch: 5| Step: 3
Training loss: 2.2166152000427246
Validation loss: 2.143936682772893

Epoch: 5| Step: 4
Training loss: 1.4254889488220215
Validation loss: 2.1094378873866093

Epoch: 5| Step: 5
Training loss: 1.4336140155792236
Validation loss: 2.0634772187920025

Epoch: 5| Step: 6
Training loss: 1.739546537399292
Validation loss: 2.1094139468285347

Epoch: 5| Step: 7
Training loss: 1.5354275703430176
Validation loss: 2.098685501724161

Epoch: 5| Step: 8
Training loss: 1.9529542922973633
Validation loss: 2.096829116985362

Epoch: 5| Step: 9
Training loss: 1.5712506771087646
Validation loss: 2.0861193979940107

Epoch: 5| Step: 10
Training loss: 1.7274320125579834
Validation loss: 2.0854318141937256

Epoch: 398| Step: 0
Training loss: 1.684427261352539
Validation loss: 2.117037157858572

Epoch: 5| Step: 1
Training loss: 1.8306331634521484
Validation loss: 2.0375932160244195

Epoch: 5| Step: 2
Training loss: 1.984033226966858
Validation loss: 2.0898877523278676

Epoch: 5| Step: 3
Training loss: 1.1230897903442383
Validation loss: 2.084584069508378

Epoch: 5| Step: 4
Training loss: 1.60285222530365
Validation loss: 2.100963347701616

Epoch: 5| Step: 5
Training loss: 1.7067897319793701
Validation loss: 2.100826382637024

Epoch: 5| Step: 6
Training loss: 1.7559711933135986
Validation loss: 2.090939247480003

Epoch: 5| Step: 7
Training loss: 1.5080757141113281
Validation loss: 2.095183326352027

Epoch: 5| Step: 8
Training loss: 1.6999094486236572
Validation loss: 2.104545065151748

Epoch: 5| Step: 9
Training loss: 2.2574832439422607
Validation loss: 2.0345956394749303

Epoch: 5| Step: 10
Training loss: 1.7205730676651
Validation loss: 2.105251104600968

Epoch: 399| Step: 0
Training loss: 1.36306631565094
Validation loss: 2.1015540579313874

Epoch: 5| Step: 1
Training loss: 1.8009300231933594
Validation loss: 2.0661887494466638

Epoch: 5| Step: 2
Training loss: 2.0197956562042236
Validation loss: 2.067228178824148

Epoch: 5| Step: 3
Training loss: 1.5530990362167358
Validation loss: 2.0945143468918337

Epoch: 5| Step: 4
Training loss: 1.589768648147583
Validation loss: 2.1278577466164865

Epoch: 5| Step: 5
Training loss: 1.2545448541641235
Validation loss: 2.100907534681341

Epoch: 5| Step: 6
Training loss: 1.9633533954620361
Validation loss: 2.0809286550808976

Epoch: 5| Step: 7
Training loss: 1.1966559886932373
Validation loss: 2.126762864410236

Epoch: 5| Step: 8
Training loss: 1.4345779418945312
Validation loss: 2.09697433440916

Epoch: 5| Step: 9
Training loss: 2.7854058742523193
Validation loss: 2.1022414366404214

Epoch: 5| Step: 10
Training loss: 2.005969762802124
Validation loss: 2.0832397117409656

Epoch: 400| Step: 0
Training loss: 2.3417282104492188
Validation loss: 2.1493187771048596

Epoch: 5| Step: 1
Training loss: 1.5875775814056396
Validation loss: 2.1085668943261586

Epoch: 5| Step: 2
Training loss: 1.3561623096466064
Validation loss: 2.1019660375451528

Epoch: 5| Step: 3
Training loss: 1.8307945728302002
Validation loss: 2.059687937459638

Epoch: 5| Step: 4
Training loss: 1.8191566467285156
Validation loss: 2.082315388546195

Epoch: 5| Step: 5
Training loss: 1.3623828887939453
Validation loss: 2.052476893189133

Epoch: 5| Step: 6
Training loss: 2.177823066711426
Validation loss: 2.113539598321402

Epoch: 5| Step: 7
Training loss: 1.4647209644317627
Validation loss: 2.1260248114985805

Epoch: 5| Step: 8
Training loss: 1.5283622741699219
Validation loss: 2.0945696600021853

Epoch: 5| Step: 9
Training loss: 1.9589450359344482
Validation loss: 2.11419782587277

Epoch: 5| Step: 10
Training loss: 1.4798107147216797
Validation loss: 2.0868837500131256

Epoch: 401| Step: 0
Training loss: 1.3094233274459839
Validation loss: 2.1262175152378697

Epoch: 5| Step: 1
Training loss: 1.3700895309448242
Validation loss: 2.0895323676447712

Epoch: 5| Step: 2
Training loss: 2.168623447418213
Validation loss: 2.0725145006692536

Epoch: 5| Step: 3
Training loss: 1.557583212852478
Validation loss: 2.1397108621494745

Epoch: 5| Step: 4
Training loss: 2.1160976886749268
Validation loss: 2.07175398642017

Epoch: 5| Step: 5
Training loss: 1.98312246799469
Validation loss: 2.0813765013089744

Epoch: 5| Step: 6
Training loss: 1.3753780126571655
Validation loss: 2.1303319161938084

Epoch: 5| Step: 7
Training loss: 1.5995838642120361
Validation loss: 2.067160639711606

Epoch: 5| Step: 8
Training loss: 1.4060570001602173
Validation loss: 2.080106153283068

Epoch: 5| Step: 9
Training loss: 1.5658400058746338
Validation loss: 2.1408550559833484

Epoch: 5| Step: 10
Training loss: 2.130943536758423
Validation loss: 2.10843910196776

Epoch: 402| Step: 0
Training loss: 1.432505488395691
Validation loss: 2.1773884065689577

Epoch: 5| Step: 1
Training loss: 0.8839662671089172
Validation loss: 2.0849991613818752

Epoch: 5| Step: 2
Training loss: 1.7272777557373047
Validation loss: 2.035830695142028

Epoch: 5| Step: 3
Training loss: 1.7137196063995361
Validation loss: 2.144242540482552

Epoch: 5| Step: 4
Training loss: 2.181018829345703
Validation loss: 2.0714413812083583

Epoch: 5| Step: 5
Training loss: 1.771731972694397
Validation loss: 2.1068054950365456

Epoch: 5| Step: 6
Training loss: 1.3092248439788818
Validation loss: 2.0866279243141093

Epoch: 5| Step: 7
Training loss: 1.6370347738265991
Validation loss: 2.117108623186747

Epoch: 5| Step: 8
Training loss: 2.0431690216064453
Validation loss: 2.084695816040039

Epoch: 5| Step: 9
Training loss: 2.3817269802093506
Validation loss: 2.122124574517691

Epoch: 5| Step: 10
Training loss: 1.626883864402771
Validation loss: 2.0871466603330386

Epoch: 403| Step: 0
Training loss: 2.019880533218384
Validation loss: 2.1348644571919597

Epoch: 5| Step: 1
Training loss: 1.1042875051498413
Validation loss: 2.050523893807524

Epoch: 5| Step: 2
Training loss: 1.6843392848968506
Validation loss: 2.093556143904245

Epoch: 5| Step: 3
Training loss: 1.5198777914047241
Validation loss: 2.114055138762279

Epoch: 5| Step: 4
Training loss: 1.5533841848373413
Validation loss: 2.1127760512854463

Epoch: 5| Step: 5
Training loss: 1.5166645050048828
Validation loss: 2.099613828043784

Epoch: 5| Step: 6
Training loss: 1.4084453582763672
Validation loss: 2.0789246636052288

Epoch: 5| Step: 7
Training loss: 2.0506515502929688
Validation loss: 2.102683380085935

Epoch: 5| Step: 8
Training loss: 2.045792818069458
Validation loss: 2.0345027241655576

Epoch: 5| Step: 9
Training loss: 1.7636951208114624
Validation loss: 2.0662473427352084

Epoch: 5| Step: 10
Training loss: 1.9527473449707031
Validation loss: 2.0820505439594226

Epoch: 404| Step: 0
Training loss: 1.2943329811096191
Validation loss: 2.0369866689046225

Epoch: 5| Step: 1
Training loss: 1.6673732995986938
Validation loss: 2.111580628220753

Epoch: 5| Step: 2
Training loss: 1.4555509090423584
Validation loss: 2.0999281598675634

Epoch: 5| Step: 3
Training loss: 1.7342389822006226
Validation loss: 2.067241936601618

Epoch: 5| Step: 4
Training loss: 1.7408206462860107
Validation loss: 2.0864350949564288

Epoch: 5| Step: 5
Training loss: 1.5982930660247803
Validation loss: 2.0909283975119233

Epoch: 5| Step: 6
Training loss: 2.1104862689971924
Validation loss: 2.0965357467692387

Epoch: 5| Step: 7
Training loss: 2.0342535972595215
Validation loss: 2.0909821435969365

Epoch: 5| Step: 8
Training loss: 2.0124971866607666
Validation loss: 2.064432176210547

Epoch: 5| Step: 9
Training loss: 1.7719234228134155
Validation loss: 2.0889220596641622

Epoch: 5| Step: 10
Training loss: 1.5744824409484863
Validation loss: 2.076348063766315

Epoch: 405| Step: 0
Training loss: 1.9333375692367554
Validation loss: 2.1268286012834117

Epoch: 5| Step: 1
Training loss: 1.8471519947052002
Validation loss: 2.0970593857508835

Epoch: 5| Step: 2
Training loss: 1.601192831993103
Validation loss: 2.0782502633269115

Epoch: 5| Step: 3
Training loss: 1.9931808710098267
Validation loss: 2.1012711473690566

Epoch: 5| Step: 4
Training loss: 1.8162387609481812
Validation loss: 2.1095342559199177

Epoch: 5| Step: 5
Training loss: 1.3305299282073975
Validation loss: 2.123826995972664

Epoch: 5| Step: 6
Training loss: 2.0161290168762207
Validation loss: 2.057440580860261

Epoch: 5| Step: 7
Training loss: 1.633443832397461
Validation loss: 2.1298441028082244

Epoch: 5| Step: 8
Training loss: 1.7504088878631592
Validation loss: 2.0554087444018294

Epoch: 5| Step: 9
Training loss: 1.1327506303787231
Validation loss: 2.0532820916944936

Epoch: 5| Step: 10
Training loss: 1.7393579483032227
Validation loss: 2.09251876800291

Epoch: 406| Step: 0
Training loss: 1.6379473209381104
Validation loss: 2.1352441182700534

Epoch: 5| Step: 1
Training loss: 1.940894365310669
Validation loss: 2.0922727507929646

Epoch: 5| Step: 2
Training loss: 1.689536690711975
Validation loss: 2.1176181454812326

Epoch: 5| Step: 3
Training loss: 1.2629377841949463
Validation loss: 2.068698856138414

Epoch: 5| Step: 4
Training loss: 1.911096215248108
Validation loss: 2.1118499835332236

Epoch: 5| Step: 5
Training loss: 1.247391939163208
Validation loss: 2.073501750987063

Epoch: 5| Step: 6
Training loss: 2.3727591037750244
Validation loss: 2.105038001973142

Epoch: 5| Step: 7
Training loss: 1.6714283227920532
Validation loss: 2.13974440738719

Epoch: 5| Step: 8
Training loss: 1.655830979347229
Validation loss: 2.0534002011822117

Epoch: 5| Step: 9
Training loss: 1.5782655477523804
Validation loss: 2.145349133399225

Epoch: 5| Step: 10
Training loss: 2.0246500968933105
Validation loss: 2.038049943985478

Epoch: 407| Step: 0
Training loss: 1.609128713607788
Validation loss: 2.084726789946197

Epoch: 5| Step: 1
Training loss: 2.3939990997314453
Validation loss: 2.0086330431763844

Epoch: 5| Step: 2
Training loss: 1.3301537036895752
Validation loss: 2.1750339077365015

Epoch: 5| Step: 3
Training loss: 1.8110193014144897
Validation loss: 2.129439861543717

Epoch: 5| Step: 4
Training loss: 1.4548909664154053
Validation loss: 2.0979795020113707

Epoch: 5| Step: 5
Training loss: 2.2418761253356934
Validation loss: 2.117031676794893

Epoch: 5| Step: 6
Training loss: 2.113417863845825
Validation loss: 2.0526700455655336

Epoch: 5| Step: 7
Training loss: 1.2645000219345093
Validation loss: 2.139735285953809

Epoch: 5| Step: 8
Training loss: 1.7565138339996338
Validation loss: 2.095622290847122

Epoch: 5| Step: 9
Training loss: 1.4843723773956299
Validation loss: 2.1171364463785642

Epoch: 5| Step: 10
Training loss: 1.3956211805343628
Validation loss: 2.1054209483567106

Epoch: 408| Step: 0
Training loss: 1.7244713306427002
Validation loss: 2.133978469397432

Epoch: 5| Step: 1
Training loss: 1.5673754215240479
Validation loss: 2.1119839555473736

Epoch: 5| Step: 2
Training loss: 1.3513917922973633
Validation loss: 2.0999473935814312

Epoch: 5| Step: 3
Training loss: 1.8749278783798218
Validation loss: 2.0745302336190337

Epoch: 5| Step: 4
Training loss: 2.1684813499450684
Validation loss: 2.1757407842143888

Epoch: 5| Step: 5
Training loss: 2.0603973865509033
Validation loss: 2.1140864074871106

Epoch: 5| Step: 6
Training loss: 1.8020942211151123
Validation loss: 2.1248770606133247

Epoch: 5| Step: 7
Training loss: 1.6765950918197632
Validation loss: 2.097337890696782

Epoch: 5| Step: 8
Training loss: 1.734229326248169
Validation loss: 2.119346007224052

Epoch: 5| Step: 9
Training loss: 1.3199069499969482
Validation loss: 2.118392159861903

Epoch: 5| Step: 10
Training loss: 1.2189199924468994
Validation loss: 2.1341171572285313

Epoch: 409| Step: 0
Training loss: 1.2054522037506104
Validation loss: 2.1684286414936023

Epoch: 5| Step: 1
Training loss: 1.8027633428573608
Validation loss: 2.1398094097773233

Epoch: 5| Step: 2
Training loss: 2.2731356620788574
Validation loss: 2.0785834917458157

Epoch: 5| Step: 3
Training loss: 1.675280213356018
Validation loss: 2.125643314853791

Epoch: 5| Step: 4
Training loss: 1.713571310043335
Validation loss: 2.0925207586698633

Epoch: 5| Step: 5
Training loss: 2.048826217651367
Validation loss: 2.114350285581363

Epoch: 5| Step: 6
Training loss: 1.2413111925125122
Validation loss: 2.079133936153945

Epoch: 5| Step: 7
Training loss: 1.151490569114685
Validation loss: 2.13811356277876

Epoch: 5| Step: 8
Training loss: 1.835218071937561
Validation loss: 2.0452161886358775

Epoch: 5| Step: 9
Training loss: 1.8277868032455444
Validation loss: 2.0851594632671726

Epoch: 5| Step: 10
Training loss: 1.9007824659347534
Validation loss: 2.1518966305640435

Epoch: 410| Step: 0
Training loss: 1.652329444885254
Validation loss: 2.0745672577170917

Epoch: 5| Step: 1
Training loss: 1.6855919361114502
Validation loss: 2.076237504200269

Epoch: 5| Step: 2
Training loss: 2.2128143310546875
Validation loss: 2.073399246379893

Epoch: 5| Step: 3
Training loss: 2.0848937034606934
Validation loss: 2.0489191585971462

Epoch: 5| Step: 4
Training loss: 1.3917567729949951
Validation loss: 2.088958635125109

Epoch: 5| Step: 5
Training loss: 1.4459826946258545
Validation loss: 2.041065344246485

Epoch: 5| Step: 6
Training loss: 1.6916135549545288
Validation loss: 2.0896918978742374

Epoch: 5| Step: 7
Training loss: 1.9372036457061768
Validation loss: 2.1481616573949016

Epoch: 5| Step: 8
Training loss: 1.5324654579162598
Validation loss: 2.0812245748376332

Epoch: 5| Step: 9
Training loss: 1.1823225021362305
Validation loss: 2.0841039303810365

Epoch: 5| Step: 10
Training loss: 1.91861093044281
Validation loss: 2.0657966636842295

Epoch: 411| Step: 0
Training loss: 1.3386818170547485
Validation loss: 2.0615138494840233

Epoch: 5| Step: 1
Training loss: 2.2997887134552
Validation loss: 2.0941208357452066

Epoch: 5| Step: 2
Training loss: 1.9044126272201538
Validation loss: 2.05407702794639

Epoch: 5| Step: 3
Training loss: 2.097560167312622
Validation loss: 2.0607006626744426

Epoch: 5| Step: 4
Training loss: 1.0718557834625244
Validation loss: 2.106396059836111

Epoch: 5| Step: 5
Training loss: 1.5522329807281494
Validation loss: 2.052679313126431

Epoch: 5| Step: 6
Training loss: 1.6985409259796143
Validation loss: 2.0898564682211926

Epoch: 5| Step: 7
Training loss: 1.3541324138641357
Validation loss: 2.0820716478491343

Epoch: 5| Step: 8
Training loss: 1.7875003814697266
Validation loss: 2.043714231060397

Epoch: 5| Step: 9
Training loss: 1.3178696632385254
Validation loss: 2.0829625873155493

Epoch: 5| Step: 10
Training loss: 1.9843772649765015
Validation loss: 2.1368886616922196

Epoch: 412| Step: 0
Training loss: 1.7695280313491821
Validation loss: 2.1055592580508162

Epoch: 5| Step: 1
Training loss: 1.8785899877548218
Validation loss: 2.107641822548323

Epoch: 5| Step: 2
Training loss: 1.7231696844100952
Validation loss: 2.1095599961537186

Epoch: 5| Step: 3
Training loss: 2.179652690887451
Validation loss: 2.090517997741699

Epoch: 5| Step: 4
Training loss: 1.3096894025802612
Validation loss: 2.0894290631817234

Epoch: 5| Step: 5
Training loss: 1.5991270542144775
Validation loss: 2.1170878794885453

Epoch: 5| Step: 6
Training loss: 1.5768800973892212
Validation loss: 2.081141092443979

Epoch: 5| Step: 7
Training loss: 1.2706067562103271
Validation loss: 2.104153052453072

Epoch: 5| Step: 8
Training loss: 1.878493070602417
Validation loss: 2.1100010230977047

Epoch: 5| Step: 9
Training loss: 1.8396291732788086
Validation loss: 2.1100805100574287

Epoch: 5| Step: 10
Training loss: 1.3313020467758179
Validation loss: 2.0982085863749185

Epoch: 413| Step: 0
Training loss: 1.89102041721344
Validation loss: 2.1313159875972296

Epoch: 5| Step: 1
Training loss: 1.7830499410629272
Validation loss: 2.078701170541907

Epoch: 5| Step: 2
Training loss: 1.3620299100875854
Validation loss: 2.111926458215201

Epoch: 5| Step: 3
Training loss: 1.8866533041000366
Validation loss: 2.083755798237298

Epoch: 5| Step: 4
Training loss: 1.8939796686172485
Validation loss: 2.1333611972870363

Epoch: 5| Step: 5
Training loss: 1.8881103992462158
Validation loss: 2.110070184994769

Epoch: 5| Step: 6
Training loss: 1.693121314048767
Validation loss: 2.120016344131962

Epoch: 5| Step: 7
Training loss: 1.246896505355835
Validation loss: 2.178031513767858

Epoch: 5| Step: 8
Training loss: 1.803318977355957
Validation loss: 2.159515501350485

Epoch: 5| Step: 9
Training loss: 2.013073682785034
Validation loss: 2.0331714204562608

Epoch: 5| Step: 10
Training loss: 1.3746167421340942
Validation loss: 2.0885142049481793

Epoch: 414| Step: 0
Training loss: 1.2418328523635864
Validation loss: 2.0762379656555834

Epoch: 5| Step: 1
Training loss: 1.691537618637085
Validation loss: 2.113559656245734

Epoch: 5| Step: 2
Training loss: 1.7880922555923462
Validation loss: 2.1155603393431632

Epoch: 5| Step: 3
Training loss: 2.241364002227783
Validation loss: 2.0868432239819596

Epoch: 5| Step: 4
Training loss: 1.091500163078308
Validation loss: 2.1611240166489796

Epoch: 5| Step: 5
Training loss: 1.3650319576263428
Validation loss: 2.075452366182881

Epoch: 5| Step: 6
Training loss: 1.9829994440078735
Validation loss: 2.0847106223465293

Epoch: 5| Step: 7
Training loss: 1.7319501638412476
Validation loss: 2.0941605747386975

Epoch: 5| Step: 8
Training loss: 1.637457251548767
Validation loss: 2.1409128391614525

Epoch: 5| Step: 9
Training loss: 1.684126615524292
Validation loss: 2.111024779658164

Epoch: 5| Step: 10
Training loss: 2.2833738327026367
Validation loss: 2.1309233609066216

Epoch: 415| Step: 0
Training loss: 1.1784913539886475
Validation loss: 2.0885628654110815

Epoch: 5| Step: 1
Training loss: 1.5184853076934814
Validation loss: 2.0501395989489812

Epoch: 5| Step: 2
Training loss: 2.123076915740967
Validation loss: 2.079959438693139

Epoch: 5| Step: 3
Training loss: 1.8667566776275635
Validation loss: 2.0389262642911685

Epoch: 5| Step: 4
Training loss: 1.5088884830474854
Validation loss: 2.096767484500844

Epoch: 5| Step: 5
Training loss: 1.784987211227417
Validation loss: 2.154495152094031

Epoch: 5| Step: 6
Training loss: 1.5219597816467285
Validation loss: 2.082924682606933

Epoch: 5| Step: 7
Training loss: 1.9337139129638672
Validation loss: 2.1152132224011164

Epoch: 5| Step: 8
Training loss: 1.4146021604537964
Validation loss: 2.044521991924573

Epoch: 5| Step: 9
Training loss: 2.434190273284912
Validation loss: 2.1016203921328307

Epoch: 5| Step: 10
Training loss: 1.4493157863616943
Validation loss: 2.1075856429274364

Epoch: 416| Step: 0
Training loss: 1.8126722574234009
Validation loss: 2.05699909117914

Epoch: 5| Step: 1
Training loss: 1.996776819229126
Validation loss: 2.100249037947706

Epoch: 5| Step: 2
Training loss: 1.3721174001693726
Validation loss: 2.0480932766391384

Epoch: 5| Step: 3
Training loss: 1.4848673343658447
Validation loss: 2.1269831772773498

Epoch: 5| Step: 4
Training loss: 2.38395619392395
Validation loss: 2.124876199230071

Epoch: 5| Step: 5
Training loss: 1.1590672731399536
Validation loss: 2.138120807627196

Epoch: 5| Step: 6
Training loss: 1.9015312194824219
Validation loss: 2.121552028963643

Epoch: 5| Step: 7
Training loss: 1.306483507156372
Validation loss: 2.048436790384272

Epoch: 5| Step: 8
Training loss: 2.0040841102600098
Validation loss: 2.101506210142566

Epoch: 5| Step: 9
Training loss: 1.6728178262710571
Validation loss: 2.06231754056869

Epoch: 5| Step: 10
Training loss: 1.3128252029418945
Validation loss: 2.0769222961959017

Epoch: 417| Step: 0
Training loss: 1.8156423568725586
Validation loss: 2.145045526566044

Epoch: 5| Step: 1
Training loss: 1.1995229721069336
Validation loss: 2.106019530245053

Epoch: 5| Step: 2
Training loss: 1.7254116535186768
Validation loss: 2.091380630770037

Epoch: 5| Step: 3
Training loss: 2.493879556655884
Validation loss: 2.1546877404694915

Epoch: 5| Step: 4
Training loss: 1.0820894241333008
Validation loss: 2.049447164740614

Epoch: 5| Step: 5
Training loss: 1.2590277194976807
Validation loss: 2.08215896801282

Epoch: 5| Step: 6
Training loss: 2.7440404891967773
Validation loss: 2.078492531212427

Epoch: 5| Step: 7
Training loss: 1.295245885848999
Validation loss: 2.038974259489326

Epoch: 5| Step: 8
Training loss: 1.9187500476837158
Validation loss: 2.0896841608067995

Epoch: 5| Step: 9
Training loss: 1.8194434642791748
Validation loss: 2.104253145956224

Epoch: 5| Step: 10
Training loss: 1.099508285522461
Validation loss: 2.1287950059419036

Epoch: 418| Step: 0
Training loss: 1.5640507936477661
Validation loss: 2.083406142009202

Epoch: 5| Step: 1
Training loss: 1.5110833644866943
Validation loss: 2.0494974684971634

Epoch: 5| Step: 2
Training loss: 1.7963298559188843
Validation loss: 2.144890659598894

Epoch: 5| Step: 3
Training loss: 2.5372958183288574
Validation loss: 2.0777656698739655

Epoch: 5| Step: 4
Training loss: 1.3997846841812134
Validation loss: 2.1343800765211864

Epoch: 5| Step: 5
Training loss: 1.633487343788147
Validation loss: 2.1106266180674234

Epoch: 5| Step: 6
Training loss: 1.4943538904190063
Validation loss: 2.0936381868136826

Epoch: 5| Step: 7
Training loss: 1.4757212400436401
Validation loss: 2.088377862848261

Epoch: 5| Step: 8
Training loss: 1.4587910175323486
Validation loss: 2.1310814478064097

Epoch: 5| Step: 9
Training loss: 2.3002655506134033
Validation loss: 2.0927128048353296

Epoch: 5| Step: 10
Training loss: 1.283106803894043
Validation loss: 2.113369321310392

Epoch: 419| Step: 0
Training loss: 1.4476150274276733
Validation loss: 2.154669464275401

Epoch: 5| Step: 1
Training loss: 1.3552169799804688
Validation loss: 2.106313766971711

Epoch: 5| Step: 2
Training loss: 1.8966432809829712
Validation loss: 2.101150579349969

Epoch: 5| Step: 3
Training loss: 1.5390430688858032
Validation loss: 2.1123192130878405

Epoch: 5| Step: 4
Training loss: 1.8144216537475586
Validation loss: 2.0870067842545046

Epoch: 5| Step: 5
Training loss: 1.7324721813201904
Validation loss: 2.080040119027579

Epoch: 5| Step: 6
Training loss: 1.7842128276824951
Validation loss: 2.058215877061249

Epoch: 5| Step: 7
Training loss: 2.018517017364502
Validation loss: 2.100227709739439

Epoch: 5| Step: 8
Training loss: 1.7823665142059326
Validation loss: 2.1063228666141467

Epoch: 5| Step: 9
Training loss: 1.7722505331039429
Validation loss: 2.033373422520135

Epoch: 5| Step: 10
Training loss: 1.4344515800476074
Validation loss: 2.0157769969714585

Epoch: 420| Step: 0
Training loss: 1.2771947383880615
Validation loss: 2.0520202831555436

Epoch: 5| Step: 1
Training loss: 1.279768705368042
Validation loss: 2.0731258802516486

Epoch: 5| Step: 2
Training loss: 1.694562315940857
Validation loss: 2.0847311430079962

Epoch: 5| Step: 3
Training loss: 1.1052477359771729
Validation loss: 2.1049005587895713

Epoch: 5| Step: 4
Training loss: 1.6072959899902344
Validation loss: 2.0959595980182772

Epoch: 5| Step: 5
Training loss: 1.9266506433486938
Validation loss: 2.0687569084987847

Epoch: 5| Step: 6
Training loss: 1.7982919216156006
Validation loss: 2.103215834145905

Epoch: 5| Step: 7
Training loss: 2.2826621532440186
Validation loss: 2.0859399149494786

Epoch: 5| Step: 8
Training loss: 2.0625505447387695
Validation loss: 2.0345759417421077

Epoch: 5| Step: 9
Training loss: 2.1021416187286377
Validation loss: 2.0462447058769966

Epoch: 5| Step: 10
Training loss: 1.3605808019638062
Validation loss: 2.08954870059926

Epoch: 421| Step: 0
Training loss: 1.6861371994018555
Validation loss: 2.082504258360914

Epoch: 5| Step: 1
Training loss: 1.094205617904663
Validation loss: 2.0812542053960983

Epoch: 5| Step: 2
Training loss: 1.120676875114441
Validation loss: 2.1016199178593133

Epoch: 5| Step: 3
Training loss: 1.4861845970153809
Validation loss: 2.115410734248418

Epoch: 5| Step: 4
Training loss: 2.2829842567443848
Validation loss: 2.149498244767548

Epoch: 5| Step: 5
Training loss: 1.861307144165039
Validation loss: 2.0614832780694448

Epoch: 5| Step: 6
Training loss: 1.640832543373108
Validation loss: 2.142341052332232

Epoch: 5| Step: 7
Training loss: 2.3184564113616943
Validation loss: 2.116877022609916

Epoch: 5| Step: 8
Training loss: 1.7511402368545532
Validation loss: 2.12885562322473

Epoch: 5| Step: 9
Training loss: 1.33759605884552
Validation loss: 2.064032769972278

Epoch: 5| Step: 10
Training loss: 1.7693438529968262
Validation loss: 2.1612994363231044

Epoch: 422| Step: 0
Training loss: 1.9482886791229248
Validation loss: 2.0698546542916247

Epoch: 5| Step: 1
Training loss: 1.8179689645767212
Validation loss: 2.0576731261386665

Epoch: 5| Step: 2
Training loss: 1.3920972347259521
Validation loss: 2.0903132218186573

Epoch: 5| Step: 3
Training loss: 1.364932894706726
Validation loss: 2.0916674060206257

Epoch: 5| Step: 4
Training loss: 1.1822847127914429
Validation loss: 2.110193270508961

Epoch: 5| Step: 5
Training loss: 1.9755580425262451
Validation loss: 2.0403280591451995

Epoch: 5| Step: 6
Training loss: 1.5344194173812866
Validation loss: 2.074097212924752

Epoch: 5| Step: 7
Training loss: 2.3250060081481934
Validation loss: 2.0875789375715357

Epoch: 5| Step: 8
Training loss: 1.7850643396377563
Validation loss: 2.0970020178825624

Epoch: 5| Step: 9
Training loss: 1.9071409702301025
Validation loss: 2.0696845823718655

Epoch: 5| Step: 10
Training loss: 1.1606539487838745
Validation loss: 2.019342748067712

Epoch: 423| Step: 0
Training loss: 0.8772425651550293
Validation loss: 2.1086302162498556

Epoch: 5| Step: 1
Training loss: 1.9884605407714844
Validation loss: 2.0694864167962024

Epoch: 5| Step: 2
Training loss: 1.6263110637664795
Validation loss: 2.0822322137894167

Epoch: 5| Step: 3
Training loss: 2.1121201515197754
Validation loss: 2.064641137276926

Epoch: 5| Step: 4
Training loss: 1.9120874404907227
Validation loss: 2.079350577887668

Epoch: 5| Step: 5
Training loss: 1.2922762632369995
Validation loss: 2.1358269901685816

Epoch: 5| Step: 6
Training loss: 1.6304534673690796
Validation loss: 2.091701715223251

Epoch: 5| Step: 7
Training loss: 2.225149154663086
Validation loss: 2.040501993189576

Epoch: 5| Step: 8
Training loss: 1.8086210489273071
Validation loss: 2.1182242849821686

Epoch: 5| Step: 9
Training loss: 0.967208743095398
Validation loss: 2.0865107249188166

Epoch: 5| Step: 10
Training loss: 2.0002408027648926
Validation loss: 2.0944474973986225

Epoch: 424| Step: 0
Training loss: 1.3028112649917603
Validation loss: 2.1218029337544597

Epoch: 5| Step: 1
Training loss: 1.9690967798233032
Validation loss: 2.0853977254641953

Epoch: 5| Step: 2
Training loss: 1.5191385746002197
Validation loss: 2.0539473231120775

Epoch: 5| Step: 3
Training loss: 1.8057724237442017
Validation loss: 2.0591307455493557

Epoch: 5| Step: 4
Training loss: 1.9363586902618408
Validation loss: 2.104188429412021

Epoch: 5| Step: 5
Training loss: 1.5012314319610596
Validation loss: 2.1243694328492686

Epoch: 5| Step: 6
Training loss: 1.0007272958755493
Validation loss: 2.114382913035731

Epoch: 5| Step: 7
Training loss: 2.0210092067718506
Validation loss: 2.092618344932474

Epoch: 5| Step: 8
Training loss: 0.9889549016952515
Validation loss: 2.079421195932614

Epoch: 5| Step: 9
Training loss: 2.0328526496887207
Validation loss: 2.1026737946335987

Epoch: 5| Step: 10
Training loss: 2.168867588043213
Validation loss: 2.1343080869285007

Epoch: 425| Step: 0
Training loss: 1.8457450866699219
Validation loss: 2.1174641783519457

Epoch: 5| Step: 1
Training loss: 1.8450806140899658
Validation loss: 2.1445056520482546

Epoch: 5| Step: 2
Training loss: 2.3778843879699707
Validation loss: 2.0767615866917435

Epoch: 5| Step: 3
Training loss: 1.9797875881195068
Validation loss: 2.0948160386854604

Epoch: 5| Step: 4
Training loss: 1.3693809509277344
Validation loss: 2.0278284754804385

Epoch: 5| Step: 5
Training loss: 1.5692247152328491
Validation loss: 2.0577798953620334

Epoch: 5| Step: 6
Training loss: 1.5335233211517334
Validation loss: 2.092900881203272

Epoch: 5| Step: 7
Training loss: 1.477791666984558
Validation loss: 2.1296014760130193

Epoch: 5| Step: 8
Training loss: 1.2476184368133545
Validation loss: 2.1024694353021602

Epoch: 5| Step: 9
Training loss: 0.9462659955024719
Validation loss: 2.088009795834941

Epoch: 5| Step: 10
Training loss: 2.0063323974609375
Validation loss: 2.0949223041534424

Epoch: 426| Step: 0
Training loss: 1.9382765293121338
Validation loss: 2.0554909347206034

Epoch: 5| Step: 1
Training loss: 1.3871912956237793
Validation loss: 2.092118634972521

Epoch: 5| Step: 2
Training loss: 1.2172996997833252
Validation loss: 2.0360526756573747

Epoch: 5| Step: 3
Training loss: 1.1592360734939575
Validation loss: 2.0635853787904144

Epoch: 5| Step: 4
Training loss: 1.3910748958587646
Validation loss: 2.105517929600131

Epoch: 5| Step: 5
Training loss: 1.4019712209701538
Validation loss: 2.04374248109838

Epoch: 5| Step: 6
Training loss: 1.8368732929229736
Validation loss: 2.1310018826556463

Epoch: 5| Step: 7
Training loss: 2.4618804454803467
Validation loss: 2.1051688963367092

Epoch: 5| Step: 8
Training loss: 1.8841590881347656
Validation loss: 2.049298108264964

Epoch: 5| Step: 9
Training loss: 1.9969288110733032
Validation loss: 2.1372115996576126

Epoch: 5| Step: 10
Training loss: 1.6826677322387695
Validation loss: 2.1116189213209253

Epoch: 427| Step: 0
Training loss: 2.1062426567077637
Validation loss: 2.116901756614767

Epoch: 5| Step: 1
Training loss: 1.9662479162216187
Validation loss: 2.0887579302633963

Epoch: 5| Step: 2
Training loss: 1.7525842189788818
Validation loss: 2.117119155904298

Epoch: 5| Step: 3
Training loss: 0.909506618976593
Validation loss: 2.0549554901738323

Epoch: 5| Step: 4
Training loss: 0.9629830121994019
Validation loss: 2.141652942985617

Epoch: 5| Step: 5
Training loss: 2.5495405197143555
Validation loss: 2.064600277972478

Epoch: 5| Step: 6
Training loss: 1.5378143787384033
Validation loss: 2.1193577794618506

Epoch: 5| Step: 7
Training loss: 2.0769903659820557
Validation loss: 2.1196097225271244

Epoch: 5| Step: 8
Training loss: 1.996294379234314
Validation loss: 2.0691838751557055

Epoch: 5| Step: 9
Training loss: 1.3756320476531982
Validation loss: 2.1277131752301286

Epoch: 5| Step: 10
Training loss: 1.1910276412963867
Validation loss: 2.1493089327248196

Epoch: 428| Step: 0
Training loss: 1.2529133558273315
Validation loss: 2.1112693253383843

Epoch: 5| Step: 1
Training loss: 1.827770471572876
Validation loss: 2.099416394387522

Epoch: 5| Step: 2
Training loss: 1.1085320711135864
Validation loss: 2.1104466889494207

Epoch: 5| Step: 3
Training loss: 2.0388975143432617
Validation loss: 2.1326473169429327

Epoch: 5| Step: 4
Training loss: 1.9367973804473877
Validation loss: 2.0646589981612338

Epoch: 5| Step: 5
Training loss: 1.0979818105697632
Validation loss: 2.1098747586691253

Epoch: 5| Step: 6
Training loss: 1.3940675258636475
Validation loss: 2.120798408344228

Epoch: 5| Step: 7
Training loss: 2.157252788543701
Validation loss: 2.1153952754953855

Epoch: 5| Step: 8
Training loss: 1.341210961341858
Validation loss: 2.094609675868865

Epoch: 5| Step: 9
Training loss: 1.9907375574111938
Validation loss: 2.0855085977943997

Epoch: 5| Step: 10
Training loss: 2.446723222732544
Validation loss: 2.081066805829284

Epoch: 429| Step: 0
Training loss: 1.6291402578353882
Validation loss: 2.0557599093324397

Epoch: 5| Step: 1
Training loss: 1.646512746810913
Validation loss: 2.060481407309091

Epoch: 5| Step: 2
Training loss: 0.7013166546821594
Validation loss: 2.1181058012029177

Epoch: 5| Step: 3
Training loss: 1.2969071865081787
Validation loss: 2.0749640631419357

Epoch: 5| Step: 4
Training loss: 1.233460783958435
Validation loss: 2.0822029447042816

Epoch: 5| Step: 5
Training loss: 2.5588040351867676
Validation loss: 2.1276010595342165

Epoch: 5| Step: 6
Training loss: 2.2801756858825684
Validation loss: 2.1291295148993052

Epoch: 5| Step: 7
Training loss: 1.8910472393035889
Validation loss: 2.0870620781375515

Epoch: 5| Step: 8
Training loss: 1.4179009199142456
Validation loss: 2.067268704855314

Epoch: 5| Step: 9
Training loss: 1.8623735904693604
Validation loss: 2.1034787957386305

Epoch: 5| Step: 10
Training loss: 1.6888227462768555
Validation loss: 2.065529969430739

Epoch: 430| Step: 0
Training loss: 1.2877452373504639
Validation loss: 2.120769710950954

Epoch: 5| Step: 1
Training loss: 1.4240176677703857
Validation loss: 2.0916305690683346

Epoch: 5| Step: 2
Training loss: 1.609153151512146
Validation loss: 2.03147312389907

Epoch: 5| Step: 3
Training loss: 1.7001869678497314
Validation loss: 2.050360744999301

Epoch: 5| Step: 4
Training loss: 1.4670614004135132
Validation loss: 2.044139523659983

Epoch: 5| Step: 5
Training loss: 1.789573311805725
Validation loss: 2.064078187429777

Epoch: 5| Step: 6
Training loss: 1.3110448122024536
Validation loss: 2.1064812137234594

Epoch: 5| Step: 7
Training loss: 1.743682622909546
Validation loss: 2.0025287751228578

Epoch: 5| Step: 8
Training loss: 2.0040736198425293
Validation loss: 2.062584525795393

Epoch: 5| Step: 9
Training loss: 2.117319107055664
Validation loss: 2.0832481268913514

Epoch: 5| Step: 10
Training loss: 1.6352325677871704
Validation loss: 2.099100337233595

Epoch: 431| Step: 0
Training loss: 1.6070884466171265
Validation loss: 2.0616807014711442

Epoch: 5| Step: 1
Training loss: 1.4886367321014404
Validation loss: 2.096348790712254

Epoch: 5| Step: 2
Training loss: 1.3066877126693726
Validation loss: 2.105673228540728

Epoch: 5| Step: 3
Training loss: 2.355700969696045
Validation loss: 2.0906851009656022

Epoch: 5| Step: 4
Training loss: 1.7278270721435547
Validation loss: 2.096674567909651

Epoch: 5| Step: 5
Training loss: 1.3569729328155518
Validation loss: 2.0901079536766134

Epoch: 5| Step: 6
Training loss: 1.4031529426574707
Validation loss: 2.137123118164719

Epoch: 5| Step: 7
Training loss: 1.7593234777450562
Validation loss: 2.0418968764684533

Epoch: 5| Step: 8
Training loss: 2.176220178604126
Validation loss: 2.1376374998400287

Epoch: 5| Step: 9
Training loss: 1.3336975574493408
Validation loss: 2.109233876710297

Epoch: 5| Step: 10
Training loss: 1.6877682209014893
Validation loss: 2.128246248409312

Epoch: 432| Step: 0
Training loss: 1.6643463373184204
Validation loss: 2.1487094868895826

Epoch: 5| Step: 1
Training loss: 1.868422508239746
Validation loss: 2.0907874850816626

Epoch: 5| Step: 2
Training loss: 2.040038824081421
Validation loss: 2.07330645027981

Epoch: 5| Step: 3
Training loss: 1.0226311683654785
Validation loss: 2.093134936466012

Epoch: 5| Step: 4
Training loss: 1.5503698587417603
Validation loss: 2.075697683518933

Epoch: 5| Step: 5
Training loss: 1.598772406578064
Validation loss: 2.048020819182037

Epoch: 5| Step: 6
Training loss: 1.280381679534912
Validation loss: 2.0811239314335648

Epoch: 5| Step: 7
Training loss: 1.334079384803772
Validation loss: 2.034345813976821

Epoch: 5| Step: 8
Training loss: 1.5788178443908691
Validation loss: 2.0776766500165387

Epoch: 5| Step: 9
Training loss: 2.3078715801239014
Validation loss: 2.0833792532643964

Epoch: 5| Step: 10
Training loss: 1.4557992219924927
Validation loss: 2.118976713508688

Epoch: 433| Step: 0
Training loss: 1.354506254196167
Validation loss: 2.0984669167508363

Epoch: 5| Step: 1
Training loss: 1.39353346824646
Validation loss: 2.100600286196637

Epoch: 5| Step: 2
Training loss: 1.9895048141479492
Validation loss: 2.101180775191194

Epoch: 5| Step: 3
Training loss: 2.0818018913269043
Validation loss: 2.084120636345238

Epoch: 5| Step: 4
Training loss: 1.3431625366210938
Validation loss: 2.069736203839702

Epoch: 5| Step: 5
Training loss: 1.2183153629302979
Validation loss: 2.0610775691206737

Epoch: 5| Step: 6
Training loss: 2.2226691246032715
Validation loss: 2.047426321173227

Epoch: 5| Step: 7
Training loss: 1.9643465280532837
Validation loss: 2.1213604378443893

Epoch: 5| Step: 8
Training loss: 1.4283926486968994
Validation loss: 2.108677448764924

Epoch: 5| Step: 9
Training loss: 1.20858633518219
Validation loss: 2.0829233866865917

Epoch: 5| Step: 10
Training loss: 2.0130934715270996
Validation loss: 2.074417487267525

Epoch: 434| Step: 0
Training loss: 1.8815263509750366
Validation loss: 2.0664523288767827

Epoch: 5| Step: 1
Training loss: 1.417622685432434
Validation loss: 2.0749510283111245

Epoch: 5| Step: 2
Training loss: 1.784480094909668
Validation loss: 2.0750072310047765

Epoch: 5| Step: 3
Training loss: 1.8103452920913696
Validation loss: 2.0617125623969623

Epoch: 5| Step: 4
Training loss: 2.0133023262023926
Validation loss: 2.0692364118432485

Epoch: 5| Step: 5
Training loss: 1.5493700504302979
Validation loss: 2.041112220415505

Epoch: 5| Step: 6
Training loss: 0.9771370887756348
Validation loss: 2.062564734489687

Epoch: 5| Step: 7
Training loss: 1.6670429706573486
Validation loss: 2.073765854681692

Epoch: 5| Step: 8
Training loss: 1.3863685131072998
Validation loss: 2.093949238459269

Epoch: 5| Step: 9
Training loss: 1.6737735271453857
Validation loss: 2.1145743221364994

Epoch: 5| Step: 10
Training loss: 2.2361555099487305
Validation loss: 2.1225724169003066

Epoch: 435| Step: 0
Training loss: 1.155895471572876
Validation loss: 2.0233329931894937

Epoch: 5| Step: 1
Training loss: 1.600165605545044
Validation loss: 2.1161240813552693

Epoch: 5| Step: 2
Training loss: 1.4446756839752197
Validation loss: 2.1026146514441377

Epoch: 5| Step: 3
Training loss: 1.7040252685546875
Validation loss: 2.085447029400897

Epoch: 5| Step: 4
Training loss: 1.8851474523544312
Validation loss: 2.0844478530268513

Epoch: 5| Step: 5
Training loss: 2.0811374187469482
Validation loss: 2.135912405547275

Epoch: 5| Step: 6
Training loss: 1.493780493736267
Validation loss: 2.070651364582841

Epoch: 5| Step: 7
Training loss: 1.543053388595581
Validation loss: 2.1197656341778335

Epoch: 5| Step: 8
Training loss: 1.6877635717391968
Validation loss: 2.1136831442515054

Epoch: 5| Step: 9
Training loss: 1.6747801303863525
Validation loss: 2.129018965587821

Epoch: 5| Step: 10
Training loss: 1.781620740890503
Validation loss: 2.123753370777253

Epoch: 436| Step: 0
Training loss: 1.088539719581604
Validation loss: 2.089716466524268

Epoch: 5| Step: 1
Training loss: 1.7324292659759521
Validation loss: 2.0805147617093978

Epoch: 5| Step: 2
Training loss: 1.6191641092300415
Validation loss: 2.0756029390519664

Epoch: 5| Step: 3
Training loss: 2.135457992553711
Validation loss: 2.091856110480524

Epoch: 5| Step: 4
Training loss: 1.6383603811264038
Validation loss: 2.0132358574098155

Epoch: 5| Step: 5
Training loss: 1.5443238019943237
Validation loss: 2.0980569880495787

Epoch: 5| Step: 6
Training loss: 1.5861350297927856
Validation loss: 2.0981601527942124

Epoch: 5| Step: 7
Training loss: 1.6930358409881592
Validation loss: 2.0820980866750083

Epoch: 5| Step: 8
Training loss: 1.672601342201233
Validation loss: 2.0822073259661273

Epoch: 5| Step: 9
Training loss: 2.024841547012329
Validation loss: 2.0743801042597783

Epoch: 5| Step: 10
Training loss: 1.4796335697174072
Validation loss: 2.061487800331526

Epoch: 437| Step: 0
Training loss: 1.5982211828231812
Validation loss: 2.1433184403245167

Epoch: 5| Step: 1
Training loss: 1.181017279624939
Validation loss: 2.110917798934444

Epoch: 5| Step: 2
Training loss: 1.9958934783935547
Validation loss: 2.093687089540625

Epoch: 5| Step: 3
Training loss: 1.694128394126892
Validation loss: 2.0908134265612532

Epoch: 5| Step: 4
Training loss: 1.16585373878479
Validation loss: 2.094363716340834

Epoch: 5| Step: 5
Training loss: 1.7488046884536743
Validation loss: 2.0811149304912937

Epoch: 5| Step: 6
Training loss: 1.495830774307251
Validation loss: 2.0664420538051154

Epoch: 5| Step: 7
Training loss: 1.882651686668396
Validation loss: 2.146223980893371

Epoch: 5| Step: 8
Training loss: 1.8784410953521729
Validation loss: 2.0846456930201542

Epoch: 5| Step: 9
Training loss: 1.653948426246643
Validation loss: 2.061668639541954

Epoch: 5| Step: 10
Training loss: 1.5115894079208374
Validation loss: 2.034708785754378

Epoch: 438| Step: 0
Training loss: 1.983259916305542
Validation loss: 2.0520302095720844

Epoch: 5| Step: 1
Training loss: 2.0555903911590576
Validation loss: 2.141295835536013

Epoch: 5| Step: 2
Training loss: 1.5830262899398804
Validation loss: 2.099565713636337

Epoch: 5| Step: 3
Training loss: 1.2778875827789307
Validation loss: 2.039167978430307

Epoch: 5| Step: 4
Training loss: 1.3385021686553955
Validation loss: 2.0476002436812206

Epoch: 5| Step: 5
Training loss: 1.4699621200561523
Validation loss: 2.0707825691469255

Epoch: 5| Step: 6
Training loss: 1.9306386709213257
Validation loss: 2.044369174588111

Epoch: 5| Step: 7
Training loss: 1.2407087087631226
Validation loss: 2.09023339902201

Epoch: 5| Step: 8
Training loss: 1.347220778465271
Validation loss: 2.09776492785382

Epoch: 5| Step: 9
Training loss: 1.6055183410644531
Validation loss: 2.0674444270390335

Epoch: 5| Step: 10
Training loss: 1.7041282653808594
Validation loss: 2.077330962304146

Epoch: 439| Step: 0
Training loss: 1.6004102230072021
Validation loss: 2.098986784617106

Epoch: 5| Step: 1
Training loss: 1.3026994466781616
Validation loss: 2.053373784147283

Epoch: 5| Step: 2
Training loss: 1.4404555559158325
Validation loss: 2.0627669185720463

Epoch: 5| Step: 3
Training loss: 2.2235515117645264
Validation loss: 2.084238202341141

Epoch: 5| Step: 4
Training loss: 1.7551374435424805
Validation loss: 2.096091333255973

Epoch: 5| Step: 5
Training loss: 1.6992957592010498
Validation loss: 2.0899030034260084

Epoch: 5| Step: 6
Training loss: 1.4641319513320923
Validation loss: 2.102480169265501

Epoch: 5| Step: 7
Training loss: 1.4636691808700562
Validation loss: 2.0984032205356065

Epoch: 5| Step: 8
Training loss: 2.1960132122039795
Validation loss: 2.0798325346362208

Epoch: 5| Step: 9
Training loss: 1.201253056526184
Validation loss: 2.0949148708774197

Epoch: 5| Step: 10
Training loss: 1.3994172811508179
Validation loss: 2.052301911897557

Epoch: 440| Step: 0
Training loss: 1.8914474248886108
Validation loss: 2.1084424423915085

Epoch: 5| Step: 1
Training loss: 1.3857933282852173
Validation loss: 2.1042797591096614

Epoch: 5| Step: 2
Training loss: 0.9803431630134583
Validation loss: 2.0914481891098844

Epoch: 5| Step: 3
Training loss: 1.9998868703842163
Validation loss: 2.0828095866787817

Epoch: 5| Step: 4
Training loss: 1.1508076190948486
Validation loss: 2.069857261514151

Epoch: 5| Step: 5
Training loss: 1.6758981943130493
Validation loss: 2.0690733719897527

Epoch: 5| Step: 6
Training loss: 1.5464922189712524
Validation loss: 2.0830519865917903

Epoch: 5| Step: 7
Training loss: 1.9213907718658447
Validation loss: 2.076979011617681

Epoch: 5| Step: 8
Training loss: 1.6347213983535767
Validation loss: 2.062466157379971

Epoch: 5| Step: 9
Training loss: 1.6227188110351562
Validation loss: 2.1192532136876094

Epoch: 5| Step: 10
Training loss: 1.8454468250274658
Validation loss: 2.141237089710851

Epoch: 441| Step: 0
Training loss: 1.342331051826477
Validation loss: 2.014537929206766

Epoch: 5| Step: 1
Training loss: 1.4556890726089478
Validation loss: 2.0533062681075065

Epoch: 5| Step: 2
Training loss: 1.8398780822753906
Validation loss: 2.101905361298592

Epoch: 5| Step: 3
Training loss: 2.05176043510437
Validation loss: 2.048504783261207

Epoch: 5| Step: 4
Training loss: 1.98479425907135
Validation loss: 2.0292791320431616

Epoch: 5| Step: 5
Training loss: 1.2736181020736694
Validation loss: 2.0564217516171035

Epoch: 5| Step: 6
Training loss: 1.663916826248169
Validation loss: 2.093852804553124

Epoch: 5| Step: 7
Training loss: 1.8864471912384033
Validation loss: 2.0764203943232054

Epoch: 5| Step: 8
Training loss: 1.569283127784729
Validation loss: 2.088633116855416

Epoch: 5| Step: 9
Training loss: 1.1412461996078491
Validation loss: 2.0769913068381687

Epoch: 5| Step: 10
Training loss: 1.4829981327056885
Validation loss: 2.064273993174235

Epoch: 442| Step: 0
Training loss: 1.4849625825881958
Validation loss: 2.087348912351875

Epoch: 5| Step: 1
Training loss: 1.6579835414886475
Validation loss: 2.082233331536734

Epoch: 5| Step: 2
Training loss: 1.5921709537506104
Validation loss: 2.13100294656651

Epoch: 5| Step: 3
Training loss: 1.3694546222686768
Validation loss: 2.0791896517558763

Epoch: 5| Step: 4
Training loss: 2.102238416671753
Validation loss: 2.054407427387853

Epoch: 5| Step: 5
Training loss: 1.285128116607666
Validation loss: 2.072870182734664

Epoch: 5| Step: 6
Training loss: 1.1350294351577759
Validation loss: 2.1122314635143487

Epoch: 5| Step: 7
Training loss: 1.5237910747528076
Validation loss: 2.1057714903226463

Epoch: 5| Step: 8
Training loss: 2.1110053062438965
Validation loss: 2.1052412192026773

Epoch: 5| Step: 9
Training loss: 2.256260633468628
Validation loss: 2.0726679742977185

Epoch: 5| Step: 10
Training loss: 1.4867199659347534
Validation loss: 2.081869045893351

Epoch: 443| Step: 0
Training loss: 0.679017186164856
Validation loss: 2.0678392584605882

Epoch: 5| Step: 1
Training loss: 1.69417405128479
Validation loss: 2.100013845710344

Epoch: 5| Step: 2
Training loss: 1.6816707849502563
Validation loss: 2.0742621831996466

Epoch: 5| Step: 3
Training loss: 1.3862366676330566
Validation loss: 2.0623874971943517

Epoch: 5| Step: 4
Training loss: 2.1144282817840576
Validation loss: 2.088206991072624

Epoch: 5| Step: 5
Training loss: 1.949385404586792
Validation loss: 2.084909999242393

Epoch: 5| Step: 6
Training loss: 1.1249678134918213
Validation loss: 2.141414209078717

Epoch: 5| Step: 7
Training loss: 1.319521188735962
Validation loss: 2.090089480082194

Epoch: 5| Step: 8
Training loss: 1.7982219457626343
Validation loss: 2.0384425655488045

Epoch: 5| Step: 9
Training loss: 2.3170037269592285
Validation loss: 2.09072894178411

Epoch: 5| Step: 10
Training loss: 1.2223267555236816
Validation loss: 2.060141719797606

Epoch: 444| Step: 0
Training loss: 1.5774285793304443
Validation loss: 2.0814335589767783

Epoch: 5| Step: 1
Training loss: 1.9371916055679321
Validation loss: 2.0629645521922777

Epoch: 5| Step: 2
Training loss: 2.0484251976013184
Validation loss: 2.1057504646239744

Epoch: 5| Step: 3
Training loss: 1.566312313079834
Validation loss: 2.1039435222584713

Epoch: 5| Step: 4
Training loss: 1.085938811302185
Validation loss: 2.112614062524611

Epoch: 5| Step: 5
Training loss: 1.2592360973358154
Validation loss: 2.010274814021203

Epoch: 5| Step: 6
Training loss: 1.2898228168487549
Validation loss: 2.0671634674072266

Epoch: 5| Step: 7
Training loss: 1.9729074239730835
Validation loss: 2.1050099275445424

Epoch: 5| Step: 8
Training loss: 1.468707799911499
Validation loss: 2.0680041313171387

Epoch: 5| Step: 9
Training loss: 1.7059047222137451
Validation loss: 2.081602801558792

Epoch: 5| Step: 10
Training loss: 1.579798698425293
Validation loss: 2.0718045465407835

Epoch: 445| Step: 0
Training loss: 2.0698046684265137
Validation loss: 2.064102754797987

Epoch: 5| Step: 1
Training loss: 1.6625257730484009
Validation loss: 2.0408605414052166

Epoch: 5| Step: 2
Training loss: 1.9416322708129883
Validation loss: 2.017856905537267

Epoch: 5| Step: 3
Training loss: 1.3563119173049927
Validation loss: 2.0417149656562397

Epoch: 5| Step: 4
Training loss: 1.338277816772461
Validation loss: 2.0113101800282798

Epoch: 5| Step: 5
Training loss: 1.6412160396575928
Validation loss: 2.0928171039909444

Epoch: 5| Step: 6
Training loss: 1.7467658519744873
Validation loss: 2.0899555042225826

Epoch: 5| Step: 7
Training loss: 1.3122837543487549
Validation loss: 2.0979175695808987

Epoch: 5| Step: 8
Training loss: 1.211152195930481
Validation loss: 2.112645233831098

Epoch: 5| Step: 9
Training loss: 1.4904143810272217
Validation loss: 2.1075429352380897

Epoch: 5| Step: 10
Training loss: 1.7507765293121338
Validation loss: 2.0949610561452885

Epoch: 446| Step: 0
Training loss: 1.8569793701171875
Validation loss: 2.1040963178039878

Epoch: 5| Step: 1
Training loss: 1.2566883563995361
Validation loss: 2.1003207006762104

Epoch: 5| Step: 2
Training loss: 1.755059838294983
Validation loss: 2.032061675543426

Epoch: 5| Step: 3
Training loss: 1.6991081237792969
Validation loss: 2.030220598302862

Epoch: 5| Step: 4
Training loss: 0.8778169751167297
Validation loss: 2.0952750546957857

Epoch: 5| Step: 5
Training loss: 1.2860887050628662
Validation loss: 2.0659465200157574

Epoch: 5| Step: 6
Training loss: 1.6593258380889893
Validation loss: 2.0924541078588015

Epoch: 5| Step: 7
Training loss: 1.642132043838501
Validation loss: 2.123781581078806

Epoch: 5| Step: 8
Training loss: 2.081214427947998
Validation loss: 2.016001283481557

Epoch: 5| Step: 9
Training loss: 2.270998239517212
Validation loss: 2.031871852054391

Epoch: 5| Step: 10
Training loss: 1.2692294120788574
Validation loss: 2.0435570260529876

Epoch: 447| Step: 0
Training loss: 1.4965035915374756
Validation loss: 2.0771854513434955

Epoch: 5| Step: 1
Training loss: 1.866701364517212
Validation loss: 2.0520669926879225

Epoch: 5| Step: 2
Training loss: 1.6756384372711182
Validation loss: 2.061542503295406

Epoch: 5| Step: 3
Training loss: 1.6123327016830444
Validation loss: 2.0198648886014055

Epoch: 5| Step: 4
Training loss: 1.1991088390350342
Validation loss: 2.046881465501683

Epoch: 5| Step: 5
Training loss: 1.8863788843154907
Validation loss: 2.07571397032789

Epoch: 5| Step: 6
Training loss: 1.6054179668426514
Validation loss: 2.0717480900467082

Epoch: 5| Step: 7
Training loss: 1.6204490661621094
Validation loss: 2.0999896423791045

Epoch: 5| Step: 8
Training loss: 1.7290325164794922
Validation loss: 2.104551076889038

Epoch: 5| Step: 9
Training loss: 1.345115303993225
Validation loss: 2.005418046828239

Epoch: 5| Step: 10
Training loss: 1.990885615348816
Validation loss: 2.0135578840009627

Epoch: 448| Step: 0
Training loss: 1.6419315338134766
Validation loss: 2.11440437070785

Epoch: 5| Step: 1
Training loss: 1.6233917474746704
Validation loss: 2.0940272179982995

Epoch: 5| Step: 2
Training loss: 2.087352752685547
Validation loss: 2.1087922947381132

Epoch: 5| Step: 3
Training loss: 1.6094688177108765
Validation loss: 2.1465530831326722

Epoch: 5| Step: 4
Training loss: 1.8626514673233032
Validation loss: 2.0688804682864936

Epoch: 5| Step: 5
Training loss: 1.3678196668624878
Validation loss: 2.0617424518831315

Epoch: 5| Step: 6
Training loss: 1.6104294061660767
Validation loss: 2.064749135765978

Epoch: 5| Step: 7
Training loss: 1.415113091468811
Validation loss: 2.0589572973148798

Epoch: 5| Step: 8
Training loss: 1.5108256340026855
Validation loss: 2.0927397704893544

Epoch: 5| Step: 9
Training loss: 1.2951136827468872
Validation loss: 2.047185936281758

Epoch: 5| Step: 10
Training loss: 1.7692787647247314
Validation loss: 2.073441956632881

Epoch: 449| Step: 0
Training loss: 1.6618915796279907
Validation loss: 2.078007108421736

Epoch: 5| Step: 1
Training loss: 2.061558961868286
Validation loss: 2.0396262291939027

Epoch: 5| Step: 2
Training loss: 2.21813702583313
Validation loss: 1.9943695863087971

Epoch: 5| Step: 3
Training loss: 1.4131940603256226
Validation loss: 2.0878829468962965

Epoch: 5| Step: 4
Training loss: 1.1956743001937866
Validation loss: 2.0893410880078553

Epoch: 5| Step: 5
Training loss: 1.5416799783706665
Validation loss: 2.1175572628616006

Epoch: 5| Step: 6
Training loss: 1.5472043752670288
Validation loss: 2.0672783441441034

Epoch: 5| Step: 7
Training loss: 1.8167765140533447
Validation loss: 2.0807375292624197

Epoch: 5| Step: 8
Training loss: 1.468462586402893
Validation loss: 2.037735290424798

Epoch: 5| Step: 9
Training loss: 1.5744609832763672
Validation loss: 2.1024079258723924

Epoch: 5| Step: 10
Training loss: 1.0875078439712524
Validation loss: 2.046608571083315

Epoch: 450| Step: 0
Training loss: 1.4604291915893555
Validation loss: 2.068063912853118

Epoch: 5| Step: 1
Training loss: 1.544703722000122
Validation loss: 2.1347218123815392

Epoch: 5| Step: 2
Training loss: 1.6524559259414673
Validation loss: 2.0940631435763453

Epoch: 5| Step: 3
Training loss: 1.5844049453735352
Validation loss: 2.0475448972435406

Epoch: 5| Step: 4
Training loss: 1.3326549530029297
Validation loss: 2.0845572563909713

Epoch: 5| Step: 5
Training loss: 1.3807704448699951
Validation loss: 2.1594364463642077

Epoch: 5| Step: 6
Training loss: 2.1949706077575684
Validation loss: 2.0504546960194907

Epoch: 5| Step: 7
Training loss: 1.7334293127059937
Validation loss: 2.04308126049657

Epoch: 5| Step: 8
Training loss: 1.1543532609939575
Validation loss: 2.1136188045624764

Epoch: 5| Step: 9
Training loss: 1.3679331541061401
Validation loss: 2.075883403901131

Epoch: 5| Step: 10
Training loss: 2.205719470977783
Validation loss: 2.0727547599423315

Epoch: 451| Step: 0
Training loss: 1.3617143630981445
Validation loss: 2.1140012048905894

Epoch: 5| Step: 1
Training loss: 1.7522480487823486
Validation loss: 2.109740852027811

Epoch: 5| Step: 2
Training loss: 2.3240232467651367
Validation loss: 2.0792793381598687

Epoch: 5| Step: 3
Training loss: 1.5593456029891968
Validation loss: 2.0551115261611117

Epoch: 5| Step: 4
Training loss: 1.7712993621826172
Validation loss: 2.0759066458671325

Epoch: 5| Step: 5
Training loss: 1.6632318496704102
Validation loss: 2.0702112643949446

Epoch: 5| Step: 6
Training loss: 1.2722562551498413
Validation loss: 2.0925973935793807

Epoch: 5| Step: 7
Training loss: 1.210095763206482
Validation loss: 2.0981915381646927

Epoch: 5| Step: 8
Training loss: 1.7337620258331299
Validation loss: 2.0760698151844803

Epoch: 5| Step: 9
Training loss: 1.4057220220565796
Validation loss: 2.0495477850719164

Epoch: 5| Step: 10
Training loss: 1.232616662979126
Validation loss: 2.110533889903817

Epoch: 452| Step: 0
Training loss: 2.173703670501709
Validation loss: 2.102231534578467

Epoch: 5| Step: 1
Training loss: 0.9955814480781555
Validation loss: 2.0853720044576995

Epoch: 5| Step: 2
Training loss: 2.0935187339782715
Validation loss: 2.1465531574782504

Epoch: 5| Step: 3
Training loss: 1.9528322219848633
Validation loss: 2.0676678572931597

Epoch: 5| Step: 4
Training loss: 1.5282037258148193
Validation loss: 2.127861366477064

Epoch: 5| Step: 5
Training loss: 1.5281072854995728
Validation loss: 2.0646327926266577

Epoch: 5| Step: 6
Training loss: 1.4097034931182861
Validation loss: 2.093762651566536

Epoch: 5| Step: 7
Training loss: 1.4944360256195068
Validation loss: 2.07728757140457

Epoch: 5| Step: 8
Training loss: 1.811437964439392
Validation loss: 2.072953624110068

Epoch: 5| Step: 9
Training loss: 1.43939208984375
Validation loss: 2.05604350566864

Epoch: 5| Step: 10
Training loss: 1.119105339050293
Validation loss: 2.074990410958567

Epoch: 453| Step: 0
Training loss: 1.218801498413086
Validation loss: 2.0992421168153004

Epoch: 5| Step: 1
Training loss: 1.5622029304504395
Validation loss: 2.080981919842382

Epoch: 5| Step: 2
Training loss: 1.8903615474700928
Validation loss: 2.0801467972417034

Epoch: 5| Step: 3
Training loss: 1.4748036861419678
Validation loss: 2.108753381236907

Epoch: 5| Step: 4
Training loss: 1.6597650051116943
Validation loss: 2.084333663345665

Epoch: 5| Step: 5
Training loss: 2.142129898071289
Validation loss: 2.085175674448731

Epoch: 5| Step: 6
Training loss: 2.135624408721924
Validation loss: 2.1087663532585226

Epoch: 5| Step: 7
Training loss: 1.522412896156311
Validation loss: 2.0909150864488337

Epoch: 5| Step: 8
Training loss: 1.4039428234100342
Validation loss: 2.131934837628436

Epoch: 5| Step: 9
Training loss: 0.8333641290664673
Validation loss: 2.056569157108184

Epoch: 5| Step: 10
Training loss: 1.6454106569290161
Validation loss: 2.101969426678073

Epoch: 454| Step: 0
Training loss: 1.8606491088867188
Validation loss: 2.095948685881912

Epoch: 5| Step: 1
Training loss: 1.9990036487579346
Validation loss: 2.0284366453847578

Epoch: 5| Step: 2
Training loss: 2.0256829261779785
Validation loss: 2.0469248397375948

Epoch: 5| Step: 3
Training loss: 1.851467490196228
Validation loss: 2.1120749391535276

Epoch: 5| Step: 4
Training loss: 1.4156639575958252
Validation loss: 2.0976621873917116

Epoch: 5| Step: 5
Training loss: 1.1573193073272705
Validation loss: 2.10683637280618

Epoch: 5| Step: 6
Training loss: 1.351293921470642
Validation loss: 2.0442449277447117

Epoch: 5| Step: 7
Training loss: 1.1090415716171265
Validation loss: 2.0383653538201445

Epoch: 5| Step: 8
Training loss: 1.737998604774475
Validation loss: 2.0771798446614254

Epoch: 5| Step: 9
Training loss: 1.8256111145019531
Validation loss: 2.0203098814974547

Epoch: 5| Step: 10
Training loss: 1.4091765880584717
Validation loss: 2.1157172238954933

Epoch: 455| Step: 0
Training loss: 2.5399909019470215
Validation loss: 2.058311236801968

Epoch: 5| Step: 1
Training loss: 1.83100163936615
Validation loss: 2.090270975584625

Epoch: 5| Step: 2
Training loss: 1.4988926649093628
Validation loss: 2.092645029867849

Epoch: 5| Step: 3
Training loss: 1.5917081832885742
Validation loss: 2.0767191148573354

Epoch: 5| Step: 4
Training loss: 1.1062721014022827
Validation loss: 2.0373256616694952

Epoch: 5| Step: 5
Training loss: 1.9192473888397217
Validation loss: 2.0301360289255777

Epoch: 5| Step: 6
Training loss: 1.4116131067276
Validation loss: 2.0741385682936637

Epoch: 5| Step: 7
Training loss: 1.5619380474090576
Validation loss: 2.078066566938995

Epoch: 5| Step: 8
Training loss: 1.2117365598678589
Validation loss: 2.07800914138876

Epoch: 5| Step: 9
Training loss: 1.3313422203063965
Validation loss: 2.067564924558004

Epoch: 5| Step: 10
Training loss: 1.357556700706482
Validation loss: 2.0215664179094377

Epoch: 456| Step: 0
Training loss: 1.8350391387939453
Validation loss: 2.0449735861952587

Epoch: 5| Step: 1
Training loss: 1.4081032276153564
Validation loss: 2.1031787882569017

Epoch: 5| Step: 2
Training loss: 1.7550909519195557
Validation loss: 2.0274355488438762

Epoch: 5| Step: 3
Training loss: 1.7016109228134155
Validation loss: 2.0461397837567072

Epoch: 5| Step: 4
Training loss: 1.9484074115753174
Validation loss: 2.089850846157279

Epoch: 5| Step: 5
Training loss: 1.41469407081604
Validation loss: 2.060846531262962

Epoch: 5| Step: 6
Training loss: 1.8124984502792358
Validation loss: 2.0703797263483845

Epoch: 5| Step: 7
Training loss: 1.714406967163086
Validation loss: 2.1206397869253673

Epoch: 5| Step: 8
Training loss: 1.2744863033294678
Validation loss: 2.0635476881457913

Epoch: 5| Step: 9
Training loss: 1.3573806285858154
Validation loss: 2.133109151676137

Epoch: 5| Step: 10
Training loss: 1.3872721195220947
Validation loss: 2.08485831240172

Epoch: 457| Step: 0
Training loss: 1.998011589050293
Validation loss: 2.0479415103953373

Epoch: 5| Step: 1
Training loss: 1.6566442251205444
Validation loss: 2.121978332919459

Epoch: 5| Step: 2
Training loss: 1.7538998126983643
Validation loss: 2.061671374946512

Epoch: 5| Step: 3
Training loss: 2.0513007640838623
Validation loss: 2.0762016952678723

Epoch: 5| Step: 4
Training loss: 1.0531246662139893
Validation loss: 2.1274723340106267

Epoch: 5| Step: 5
Training loss: 1.6799602508544922
Validation loss: 2.0727360094747236

Epoch: 5| Step: 6
Training loss: 1.6130874156951904
Validation loss: 2.0418152347687752

Epoch: 5| Step: 7
Training loss: 1.7298851013183594
Validation loss: 2.0751619787626367

Epoch: 5| Step: 8
Training loss: 1.2705838680267334
Validation loss: 2.070915578514017

Epoch: 5| Step: 9
Training loss: 1.9343078136444092
Validation loss: 2.107897017591743

Epoch: 5| Step: 10
Training loss: 0.9896739721298218
Validation loss: 2.0526754035744617

Epoch: 458| Step: 0
Training loss: 1.8669294118881226
Validation loss: 2.1275149237725044

Epoch: 5| Step: 1
Training loss: 1.4349550008773804
Validation loss: 2.081044808510811

Epoch: 5| Step: 2
Training loss: 1.7701715230941772
Validation loss: 2.1336343390967256

Epoch: 5| Step: 3
Training loss: 1.3444037437438965
Validation loss: 2.0695458791589223

Epoch: 5| Step: 4
Training loss: 1.5285375118255615
Validation loss: 2.115141535318026

Epoch: 5| Step: 5
Training loss: 1.377953290939331
Validation loss: 2.1244948551219

Epoch: 5| Step: 6
Training loss: 1.601413369178772
Validation loss: 2.017163138235769

Epoch: 5| Step: 7
Training loss: 1.6966861486434937
Validation loss: 2.0667685180582027

Epoch: 5| Step: 8
Training loss: 1.7675491571426392
Validation loss: 2.0845146717563754

Epoch: 5| Step: 9
Training loss: 1.712898850440979
Validation loss: 2.1635968864604993

Epoch: 5| Step: 10
Training loss: 1.3379442691802979
Validation loss: 2.0505572288267073

Epoch: 459| Step: 0
Training loss: 1.1870331764221191
Validation loss: 2.0576972038515153

Epoch: 5| Step: 1
Training loss: 1.8787533044815063
Validation loss: 2.063199600865764

Epoch: 5| Step: 2
Training loss: 0.8548265695571899
Validation loss: 2.0714934359314623

Epoch: 5| Step: 3
Training loss: 1.3564379215240479
Validation loss: 2.063519044588971

Epoch: 5| Step: 4
Training loss: 1.6270511150360107
Validation loss: 2.1119600854894167

Epoch: 5| Step: 5
Training loss: 1.3821138143539429
Validation loss: 2.1402957029240106

Epoch: 5| Step: 6
Training loss: 1.7069599628448486
Validation loss: 2.0170861226256176

Epoch: 5| Step: 7
Training loss: 1.3769328594207764
Validation loss: 2.0765899124965874

Epoch: 5| Step: 8
Training loss: 1.7818113565444946
Validation loss: 2.090204827247127

Epoch: 5| Step: 9
Training loss: 2.054171085357666
Validation loss: 2.082489836600519

Epoch: 5| Step: 10
Training loss: 2.2339110374450684
Validation loss: 2.1315410393540577

Epoch: 460| Step: 0
Training loss: 1.3959825038909912
Validation loss: 2.0665820311474543

Epoch: 5| Step: 1
Training loss: 2.2809793949127197
Validation loss: 2.0696672316520446

Epoch: 5| Step: 2
Training loss: 1.8005549907684326
Validation loss: 2.092932712647223

Epoch: 5| Step: 3
Training loss: 1.6312450170516968
Validation loss: 2.0227885489822715

Epoch: 5| Step: 4
Training loss: 1.413169026374817
Validation loss: 2.0959639805619434

Epoch: 5| Step: 5
Training loss: 1.9477100372314453
Validation loss: 2.0753369831269786

Epoch: 5| Step: 6
Training loss: 1.3368146419525146
Validation loss: 2.088935213704263

Epoch: 5| Step: 7
Training loss: 1.3831404447555542
Validation loss: 2.074915865416168

Epoch: 5| Step: 8
Training loss: 1.2553192377090454
Validation loss: 2.0916689416413665

Epoch: 5| Step: 9
Training loss: 1.2720943689346313
Validation loss: 2.104756662922521

Epoch: 5| Step: 10
Training loss: 1.6677439212799072
Validation loss: 2.08378497246773

Epoch: 461| Step: 0
Training loss: 1.1876955032348633
Validation loss: 2.0780647621359876

Epoch: 5| Step: 1
Training loss: 1.8483511209487915
Validation loss: 2.061153575938235

Epoch: 5| Step: 2
Training loss: 2.425231456756592
Validation loss: 2.049671583278205

Epoch: 5| Step: 3
Training loss: 1.242884874343872
Validation loss: 2.088428828024095

Epoch: 5| Step: 4
Training loss: 1.7713239192962646
Validation loss: 2.0421608058355187

Epoch: 5| Step: 5
Training loss: 1.3115687370300293
Validation loss: 2.03329364971448

Epoch: 5| Step: 6
Training loss: 1.917425513267517
Validation loss: 2.0579310386411604

Epoch: 5| Step: 7
Training loss: 2.0005905628204346
Validation loss: 2.0804980749725015

Epoch: 5| Step: 8
Training loss: 1.14015793800354
Validation loss: 2.076195920667341

Epoch: 5| Step: 9
Training loss: 1.3640567064285278
Validation loss: 2.072472672308645

Epoch: 5| Step: 10
Training loss: 1.1934272050857544
Validation loss: 2.050363617558633

Epoch: 462| Step: 0
Training loss: 2.2069008350372314
Validation loss: 2.0451869451871483

Epoch: 5| Step: 1
Training loss: 1.5266087055206299
Validation loss: 2.094204277120611

Epoch: 5| Step: 2
Training loss: 1.829939842224121
Validation loss: 2.095079393797023

Epoch: 5| Step: 3
Training loss: 1.3794599771499634
Validation loss: 2.101185401280721

Epoch: 5| Step: 4
Training loss: 1.3078253269195557
Validation loss: 2.102860748126943

Epoch: 5| Step: 5
Training loss: 1.502586007118225
Validation loss: 2.1054184385525283

Epoch: 5| Step: 6
Training loss: 1.8967819213867188
Validation loss: 2.133508397686866

Epoch: 5| Step: 7
Training loss: 1.6815614700317383
Validation loss: 2.083464241796924

Epoch: 5| Step: 8
Training loss: 1.5190050601959229
Validation loss: 2.085019528224904

Epoch: 5| Step: 9
Training loss: 1.124005913734436
Validation loss: 2.126805123462472

Epoch: 5| Step: 10
Training loss: 1.3466296195983887
Validation loss: 2.127116234071793

Epoch: 463| Step: 0
Training loss: 1.512829065322876
Validation loss: 2.058714724356128

Epoch: 5| Step: 1
Training loss: 1.772117018699646
Validation loss: 2.092001902159824

Epoch: 5| Step: 2
Training loss: 1.3847057819366455
Validation loss: 2.130526614445512

Epoch: 5| Step: 3
Training loss: 1.078126311302185
Validation loss: 2.086777041035314

Epoch: 5| Step: 4
Training loss: 1.7003650665283203
Validation loss: 2.043904854405311

Epoch: 5| Step: 5
Training loss: 1.5869921445846558
Validation loss: 2.0454117559617564

Epoch: 5| Step: 6
Training loss: 1.442028284072876
Validation loss: 2.134908612056445

Epoch: 5| Step: 7
Training loss: 1.9818804264068604
Validation loss: 2.084448556746206

Epoch: 5| Step: 8
Training loss: 1.4313234090805054
Validation loss: 2.0695435565005065

Epoch: 5| Step: 9
Training loss: 2.1750166416168213
Validation loss: 2.0532578229904175

Epoch: 5| Step: 10
Training loss: 1.3594223260879517
Validation loss: 2.0783978328909924

Epoch: 464| Step: 0
Training loss: 1.846557378768921
Validation loss: 2.110007018171331

Epoch: 5| Step: 1
Training loss: 1.290671467781067
Validation loss: 2.008071140576434

Epoch: 5| Step: 2
Training loss: 1.8392744064331055
Validation loss: 2.077677528063456

Epoch: 5| Step: 3
Training loss: 2.2763519287109375
Validation loss: 2.0336215585790653

Epoch: 5| Step: 4
Training loss: 1.449329137802124
Validation loss: 2.0682655367799985

Epoch: 5| Step: 5
Training loss: 1.5808141231536865
Validation loss: 2.0245435648067023

Epoch: 5| Step: 6
Training loss: 1.3306821584701538
Validation loss: 2.039933899397491

Epoch: 5| Step: 7
Training loss: 1.134447455406189
Validation loss: 2.1372223054209063

Epoch: 5| Step: 8
Training loss: 1.846731185913086
Validation loss: 2.061129072661041

Epoch: 5| Step: 9
Training loss: 1.1625667810440063
Validation loss: 2.0828965274236535

Epoch: 5| Step: 10
Training loss: 1.2199828624725342
Validation loss: 2.0981238503609934

Epoch: 465| Step: 0
Training loss: 1.4164810180664062
Validation loss: 2.0881039583554832

Epoch: 5| Step: 1
Training loss: 1.7204357385635376
Validation loss: 2.132123262651505

Epoch: 5| Step: 2
Training loss: 1.3748865127563477
Validation loss: 2.050876195712756

Epoch: 5| Step: 3
Training loss: 1.4371494054794312
Validation loss: 2.078261967628233

Epoch: 5| Step: 4
Training loss: 1.6510556936264038
Validation loss: 2.0978767179673716

Epoch: 5| Step: 5
Training loss: 1.710485816001892
Validation loss: 2.0910729157027377

Epoch: 5| Step: 6
Training loss: 1.6216719150543213
Validation loss: 2.0909290006083827

Epoch: 5| Step: 7
Training loss: 2.001579999923706
Validation loss: 2.0633566520547353

Epoch: 5| Step: 8
Training loss: 1.3378736972808838
Validation loss: 2.09956572773636

Epoch: 5| Step: 9
Training loss: 1.6292695999145508
Validation loss: 2.0411854226102113

Epoch: 5| Step: 10
Training loss: 1.573889970779419
Validation loss: 2.1465124263558337

Epoch: 466| Step: 0
Training loss: 1.6045329570770264
Validation loss: 2.067192187873266

Epoch: 5| Step: 1
Training loss: 1.304566502571106
Validation loss: 2.072686367137458

Epoch: 5| Step: 2
Training loss: 1.5692065954208374
Validation loss: 2.055750959662981

Epoch: 5| Step: 3
Training loss: 1.7968041896820068
Validation loss: 2.0608092123462307

Epoch: 5| Step: 4
Training loss: 1.6806972026824951
Validation loss: 2.0500436188072286

Epoch: 5| Step: 5
Training loss: 1.3804969787597656
Validation loss: 2.0893011990413872

Epoch: 5| Step: 6
Training loss: 1.3000606298446655
Validation loss: 2.080879721590268

Epoch: 5| Step: 7
Training loss: 1.6497894525527954
Validation loss: 2.077231204637917

Epoch: 5| Step: 8
Training loss: 1.4598894119262695
Validation loss: 2.049317740624951

Epoch: 5| Step: 9
Training loss: 1.7624199390411377
Validation loss: 2.071911924628801

Epoch: 5| Step: 10
Training loss: 2.083623170852661
Validation loss: 2.074884139081483

Epoch: 467| Step: 0
Training loss: 1.8182790279388428
Validation loss: 2.057659246588266

Epoch: 5| Step: 1
Training loss: 1.4324066638946533
Validation loss: 2.0327683456482424

Epoch: 5| Step: 2
Training loss: 1.3711434602737427
Validation loss: 2.072570995617938

Epoch: 5| Step: 3
Training loss: 1.333850383758545
Validation loss: 2.057126901483023

Epoch: 5| Step: 4
Training loss: 1.8570598363876343
Validation loss: 2.0905815760294595

Epoch: 5| Step: 5
Training loss: 1.4626811742782593
Validation loss: 2.08012459867744

Epoch: 5| Step: 6
Training loss: 1.867074728012085
Validation loss: 2.109412782935686

Epoch: 5| Step: 7
Training loss: 1.7502715587615967
Validation loss: 2.0802307077633437

Epoch: 5| Step: 8
Training loss: 1.5490652322769165
Validation loss: 2.066677663915901

Epoch: 5| Step: 9
Training loss: 1.8384767770767212
Validation loss: 2.1080867808352233

Epoch: 5| Step: 10
Training loss: 0.8029110431671143
Validation loss: 2.067739591803602

Epoch: 468| Step: 0
Training loss: 1.9274688959121704
Validation loss: 2.0903311826849498

Epoch: 5| Step: 1
Training loss: 1.6122734546661377
Validation loss: 2.092120134702293

Epoch: 5| Step: 2
Training loss: 1.6062196493148804
Validation loss: 2.1029713461475987

Epoch: 5| Step: 3
Training loss: 1.4462372064590454
Validation loss: 2.0712783182820966

Epoch: 5| Step: 4
Training loss: 1.511973261833191
Validation loss: 2.055726117985223

Epoch: 5| Step: 5
Training loss: 1.6632840633392334
Validation loss: 2.0951431233395814

Epoch: 5| Step: 6
Training loss: 1.030495047569275
Validation loss: 2.080523116614229

Epoch: 5| Step: 7
Training loss: 1.8003151416778564
Validation loss: 2.0611786175799627

Epoch: 5| Step: 8
Training loss: 1.4282991886138916
Validation loss: 2.0745165296780166

Epoch: 5| Step: 9
Training loss: 1.4615247249603271
Validation loss: 2.0408184348895984

Epoch: 5| Step: 10
Training loss: 1.910625696182251
Validation loss: 2.064332967163414

Epoch: 469| Step: 0
Training loss: 1.4594128131866455
Validation loss: 2.076514788853225

Epoch: 5| Step: 1
Training loss: 2.348989486694336
Validation loss: 2.05930309654564

Epoch: 5| Step: 2
Training loss: 1.8994598388671875
Validation loss: 2.1154636759911813

Epoch: 5| Step: 3
Training loss: 1.7075374126434326
Validation loss: 2.069343259257655

Epoch: 5| Step: 4
Training loss: 1.325429916381836
Validation loss: 2.0550441613761325

Epoch: 5| Step: 5
Training loss: 1.2313830852508545
Validation loss: 2.0584295898355465

Epoch: 5| Step: 6
Training loss: 1.1781225204467773
Validation loss: 2.0927834523621427

Epoch: 5| Step: 7
Training loss: 1.9336248636245728
Validation loss: 2.0740982165900608

Epoch: 5| Step: 8
Training loss: 1.428807020187378
Validation loss: 2.115731857156241

Epoch: 5| Step: 9
Training loss: 1.5395267009735107
Validation loss: 2.066796402777395

Epoch: 5| Step: 10
Training loss: 0.943155825138092
Validation loss: 2.0228728953228203

Epoch: 470| Step: 0
Training loss: 0.9587465524673462
Validation loss: 2.0249582131703696

Epoch: 5| Step: 1
Training loss: 1.486993432044983
Validation loss: 2.0530341440631497

Epoch: 5| Step: 2
Training loss: 1.2337639331817627
Validation loss: 2.105649317464521

Epoch: 5| Step: 3
Training loss: 1.3564138412475586
Validation loss: 2.0897580205753283

Epoch: 5| Step: 4
Training loss: 1.9537969827651978
Validation loss: 2.0781004069953837

Epoch: 5| Step: 5
Training loss: 1.8230565786361694
Validation loss: 2.0629673337423675

Epoch: 5| Step: 6
Training loss: 2.289890766143799
Validation loss: 2.0843971083241124

Epoch: 5| Step: 7
Training loss: 1.4800876379013062
Validation loss: 2.108363469441732

Epoch: 5| Step: 8
Training loss: 1.6691211462020874
Validation loss: 2.1026711899747133

Epoch: 5| Step: 9
Training loss: 1.5663456916809082
Validation loss: 2.079167289118613

Epoch: 5| Step: 10
Training loss: 1.0963720083236694
Validation loss: 2.127306927916824

Epoch: 471| Step: 0
Training loss: 1.203492283821106
Validation loss: 2.086334205442859

Epoch: 5| Step: 1
Training loss: 1.4336146116256714
Validation loss: 2.0683509419041295

Epoch: 5| Step: 2
Training loss: 1.5469253063201904
Validation loss: 2.036056307054335

Epoch: 5| Step: 3
Training loss: 1.7085157632827759
Validation loss: 2.104522620477984

Epoch: 5| Step: 4
Training loss: 1.997214674949646
Validation loss: 2.089781125386556

Epoch: 5| Step: 5
Training loss: 1.5341691970825195
Validation loss: 2.0746123790740967

Epoch: 5| Step: 6
Training loss: 1.3795650005340576
Validation loss: 2.0423636718462874

Epoch: 5| Step: 7
Training loss: 1.293737769126892
Validation loss: 2.076811171347095

Epoch: 5| Step: 8
Training loss: 1.7599842548370361
Validation loss: 2.1040062417266188

Epoch: 5| Step: 9
Training loss: 1.3377158641815186
Validation loss: 2.0612615128999114

Epoch: 5| Step: 10
Training loss: 1.8012433052062988
Validation loss: 2.0841617789319766

Epoch: 472| Step: 0
Training loss: 0.8909424543380737
Validation loss: 2.0778034117914017

Epoch: 5| Step: 1
Training loss: 1.3763397932052612
Validation loss: 2.1290899374151744

Epoch: 5| Step: 2
Training loss: 1.9209842681884766
Validation loss: 2.064624922249907

Epoch: 5| Step: 3
Training loss: 1.469773292541504
Validation loss: 2.0567460213938067

Epoch: 5| Step: 4
Training loss: 1.202889084815979
Validation loss: 2.0577406191056773

Epoch: 5| Step: 5
Training loss: 1.5930376052856445
Validation loss: 2.033276488704066

Epoch: 5| Step: 6
Training loss: 2.10481595993042
Validation loss: 2.120927723505164

Epoch: 5| Step: 7
Training loss: 1.2117178440093994
Validation loss: 2.098782047148674

Epoch: 5| Step: 8
Training loss: 1.3780587911605835
Validation loss: 2.0965761394910913

Epoch: 5| Step: 9
Training loss: 2.234056234359741
Validation loss: 2.0323157361758653

Epoch: 5| Step: 10
Training loss: 1.8199185132980347
Validation loss: 2.099398745003567

Epoch: 473| Step: 0
Training loss: 1.9545730352401733
Validation loss: 2.064486316455308

Epoch: 5| Step: 1
Training loss: 0.8833690881729126
Validation loss: 2.0765357773791076

Epoch: 5| Step: 2
Training loss: 1.4657151699066162
Validation loss: 2.139992437055034

Epoch: 5| Step: 3
Training loss: 1.315251350402832
Validation loss: 2.0946855339952695

Epoch: 5| Step: 4
Training loss: 1.2857096195220947
Validation loss: 2.0198604958031767

Epoch: 5| Step: 5
Training loss: 2.0744919776916504
Validation loss: 2.0177871258028093

Epoch: 5| Step: 6
Training loss: 1.1906170845031738
Validation loss: 2.070963574993995

Epoch: 5| Step: 7
Training loss: 1.9997475147247314
Validation loss: 2.101289985000446

Epoch: 5| Step: 8
Training loss: 1.1081292629241943
Validation loss: 2.0976670301088722

Epoch: 5| Step: 9
Training loss: 1.700295090675354
Validation loss: 2.0922674902023806

Epoch: 5| Step: 10
Training loss: 2.0102100372314453
Validation loss: 2.0622188891133955

Epoch: 474| Step: 0
Training loss: 1.7383155822753906
Validation loss: 2.087544887296615

Epoch: 5| Step: 1
Training loss: 1.1562808752059937
Validation loss: 2.0536762540058424

Epoch: 5| Step: 2
Training loss: 1.56548011302948
Validation loss: 2.084982551554198

Epoch: 5| Step: 3
Training loss: 1.3424079418182373
Validation loss: 2.0788707040971324

Epoch: 5| Step: 4
Training loss: 1.2673814296722412
Validation loss: 2.0581163449953963

Epoch: 5| Step: 5
Training loss: 1.2732402086257935
Validation loss: 2.0816873042814192

Epoch: 5| Step: 6
Training loss: 1.4391405582427979
Validation loss: 2.0714215591389644

Epoch: 5| Step: 7
Training loss: 1.5593488216400146
Validation loss: 2.0648287034803823

Epoch: 5| Step: 8
Training loss: 1.879219651222229
Validation loss: 2.056488698528659

Epoch: 5| Step: 9
Training loss: 2.105114698410034
Validation loss: 2.0534856178427257

Epoch: 5| Step: 10
Training loss: 1.9578251838684082
Validation loss: 2.033021716661351

Epoch: 475| Step: 0
Training loss: 1.6800544261932373
Validation loss: 2.044240087591192

Epoch: 5| Step: 1
Training loss: 1.5209615230560303
Validation loss: 2.112639065711729

Epoch: 5| Step: 2
Training loss: 1.914584755897522
Validation loss: 2.0341806975744103

Epoch: 5| Step: 3
Training loss: 1.6797746419906616
Validation loss: 2.070094439291185

Epoch: 5| Step: 4
Training loss: 1.1956994533538818
Validation loss: 2.063387745170183

Epoch: 5| Step: 5
Training loss: 1.0885459184646606
Validation loss: 2.0835071199683735

Epoch: 5| Step: 6
Training loss: 1.3575800657272339
Validation loss: 2.1156446292836177

Epoch: 5| Step: 7
Training loss: 1.1800132989883423
Validation loss: 2.0317360431917253

Epoch: 5| Step: 8
Training loss: 2.2769017219543457
Validation loss: 2.0423668199969875

Epoch: 5| Step: 9
Training loss: 1.1971652507781982
Validation loss: 1.994744849461381

Epoch: 5| Step: 10
Training loss: 1.7086560726165771
Validation loss: 2.0240008126022997

Epoch: 476| Step: 0
Training loss: 2.0397117137908936
Validation loss: 2.078836476931008

Epoch: 5| Step: 1
Training loss: 2.0384914875030518
Validation loss: 2.042177572045275

Epoch: 5| Step: 2
Training loss: 1.0390167236328125
Validation loss: 2.0585638502592682

Epoch: 5| Step: 3
Training loss: 1.663037896156311
Validation loss: 2.0836831292798443

Epoch: 5| Step: 4
Training loss: 1.8136398792266846
Validation loss: 2.0605463686809746

Epoch: 5| Step: 5
Training loss: 0.7141579389572144
Validation loss: 2.0955928589708064

Epoch: 5| Step: 6
Training loss: 1.391389012336731
Validation loss: 2.060103584361333

Epoch: 5| Step: 7
Training loss: 1.420003890991211
Validation loss: 2.0569725318621566

Epoch: 5| Step: 8
Training loss: 1.7097342014312744
Validation loss: 2.0582765251077633

Epoch: 5| Step: 9
Training loss: 1.4133843183517456
Validation loss: 2.017713333970757

Epoch: 5| Step: 10
Training loss: 1.6744565963745117
Validation loss: 2.0524166950615506

Epoch: 477| Step: 0
Training loss: 1.805480718612671
Validation loss: 2.117617663516793

Epoch: 5| Step: 1
Training loss: 1.633275032043457
Validation loss: 2.0347671201152187

Epoch: 5| Step: 2
Training loss: 1.2577804327011108
Validation loss: 2.0425697193350842

Epoch: 5| Step: 3
Training loss: 1.965842843055725
Validation loss: 2.0453103793564664

Epoch: 5| Step: 4
Training loss: 2.1992554664611816
Validation loss: 2.0813726314934353

Epoch: 5| Step: 5
Training loss: 1.438535451889038
Validation loss: 2.0265791031622116

Epoch: 5| Step: 6
Training loss: 1.4811519384384155
Validation loss: 2.0689958013514036

Epoch: 5| Step: 7
Training loss: 1.4508949518203735
Validation loss: 2.0250541497302312

Epoch: 5| Step: 8
Training loss: 1.3536174297332764
Validation loss: 2.0662129002232708

Epoch: 5| Step: 9
Training loss: 0.7492111325263977
Validation loss: 2.093201675722676

Epoch: 5| Step: 10
Training loss: 1.8676869869232178
Validation loss: 2.078441084072154

Epoch: 478| Step: 0
Training loss: 1.4983408451080322
Validation loss: 2.0497580241131526

Epoch: 5| Step: 1
Training loss: 1.5365419387817383
Validation loss: 2.0506125252733947

Epoch: 5| Step: 2
Training loss: 1.9837760925292969
Validation loss: 2.064479625353249

Epoch: 5| Step: 3
Training loss: 1.4631035327911377
Validation loss: 2.0717139628625687

Epoch: 5| Step: 4
Training loss: 1.6326558589935303
Validation loss: 2.0480965965537616

Epoch: 5| Step: 5
Training loss: 1.320039987564087
Validation loss: 2.1228659499076104

Epoch: 5| Step: 6
Training loss: 1.0626755952835083
Validation loss: 2.036794998312509

Epoch: 5| Step: 7
Training loss: 1.998008131980896
Validation loss: 2.0385012293374665

Epoch: 5| Step: 8
Training loss: 0.8674976229667664
Validation loss: 2.0374492137662825

Epoch: 5| Step: 9
Training loss: 1.7044483423233032
Validation loss: 2.021188241179271

Epoch: 5| Step: 10
Training loss: 1.8817893266677856
Validation loss: 2.0389898207879837

Epoch: 479| Step: 0
Training loss: 1.8125931024551392
Validation loss: 2.0780268023090978

Epoch: 5| Step: 1
Training loss: 1.6475909948349
Validation loss: 2.0470450770470405

Epoch: 5| Step: 2
Training loss: 1.3852148056030273
Validation loss: 2.105901969376431

Epoch: 5| Step: 3
Training loss: 1.2041091918945312
Validation loss: 2.093856196249685

Epoch: 5| Step: 4
Training loss: 1.8365392684936523
Validation loss: 2.0854501570424726

Epoch: 5| Step: 5
Training loss: 1.3873231410980225
Validation loss: 2.0629740927809026

Epoch: 5| Step: 6
Training loss: 1.3561338186264038
Validation loss: 2.0685967117227535

Epoch: 5| Step: 7
Training loss: 1.3955178260803223
Validation loss: 2.019671127360354

Epoch: 5| Step: 8
Training loss: 1.552181363105774
Validation loss: 2.08391890218181

Epoch: 5| Step: 9
Training loss: 1.7566673755645752
Validation loss: 2.0694386266892955

Epoch: 5| Step: 10
Training loss: 1.2795366048812866
Validation loss: 2.0204354704067273

Epoch: 480| Step: 0
Training loss: 1.1687953472137451
Validation loss: 2.0854693048743793

Epoch: 5| Step: 1
Training loss: 1.1275444030761719
Validation loss: 2.051437344602359

Epoch: 5| Step: 2
Training loss: 1.7935943603515625
Validation loss: 2.046116098280876

Epoch: 5| Step: 3
Training loss: 1.2973239421844482
Validation loss: 2.0274397980782295

Epoch: 5| Step: 4
Training loss: 1.6140644550323486
Validation loss: 2.06276862852035

Epoch: 5| Step: 5
Training loss: 1.2460826635360718
Validation loss: 2.028986228409634

Epoch: 5| Step: 6
Training loss: 1.8234745264053345
Validation loss: 2.046454983372842

Epoch: 5| Step: 7
Training loss: 1.3545383214950562
Validation loss: 2.0696186096437517

Epoch: 5| Step: 8
Training loss: 1.7582098245620728
Validation loss: 2.0952825123263943

Epoch: 5| Step: 9
Training loss: 2.0275187492370605
Validation loss: 2.0459274476574314

Epoch: 5| Step: 10
Training loss: 1.5376274585723877
Validation loss: 2.0176798989695888

Epoch: 481| Step: 0
Training loss: 2.019134044647217
Validation loss: 2.087667078100225

Epoch: 5| Step: 1
Training loss: 1.612440824508667
Validation loss: 2.074516902687729

Epoch: 5| Step: 2
Training loss: 1.5877363681793213
Validation loss: 2.0697311714131343

Epoch: 5| Step: 3
Training loss: 1.8859800100326538
Validation loss: 2.105584806011569

Epoch: 5| Step: 4
Training loss: 1.6864280700683594
Validation loss: 1.9725065897869807

Epoch: 5| Step: 5
Training loss: 1.4186581373214722
Validation loss: 2.07720987642965

Epoch: 5| Step: 6
Training loss: 1.8704103231430054
Validation loss: 2.131402446377662

Epoch: 5| Step: 7
Training loss: 1.332971215248108
Validation loss: 2.1163783150334514

Epoch: 5| Step: 8
Training loss: 1.1283454895019531
Validation loss: 2.0532080832348076

Epoch: 5| Step: 9
Training loss: 1.5950682163238525
Validation loss: 2.1082095740943827

Epoch: 5| Step: 10
Training loss: 0.9825143218040466
Validation loss: 2.072373164597378

Epoch: 482| Step: 0
Training loss: 1.6159025430679321
Validation loss: 2.02930591183324

Epoch: 5| Step: 1
Training loss: 1.4849145412445068
Validation loss: 2.096218421895017

Epoch: 5| Step: 2
Training loss: 1.1300655603408813
Validation loss: 2.0798932378010084

Epoch: 5| Step: 3
Training loss: 1.563989281654358
Validation loss: 2.00943051615069

Epoch: 5| Step: 4
Training loss: 1.7354700565338135
Validation loss: 2.040891775520899

Epoch: 5| Step: 5
Training loss: 1.9809353351593018
Validation loss: 2.0431765125643824

Epoch: 5| Step: 6
Training loss: 1.9660365581512451
Validation loss: 2.0235676034804313

Epoch: 5| Step: 7
Training loss: 1.305772066116333
Validation loss: 2.085738374340919

Epoch: 5| Step: 8
Training loss: 1.158292531967163
Validation loss: 2.0110630553255797

Epoch: 5| Step: 9
Training loss: 1.5651262998580933
Validation loss: 2.0573602081626974

Epoch: 5| Step: 10
Training loss: 1.2613472938537598
Validation loss: 2.0598528615890013

Epoch: 483| Step: 0
Training loss: 1.3147708177566528
Validation loss: 2.0639641464397473

Epoch: 5| Step: 1
Training loss: 1.3828061819076538
Validation loss: 2.0792877558738954

Epoch: 5| Step: 2
Training loss: 1.7553800344467163
Validation loss: 2.1013825798547394

Epoch: 5| Step: 3
Training loss: 1.7243152856826782
Validation loss: 2.089208895160306

Epoch: 5| Step: 4
Training loss: 1.2807317972183228
Validation loss: 2.0214913429752475

Epoch: 5| Step: 5
Training loss: 1.826818823814392
Validation loss: 2.0432604025768977

Epoch: 5| Step: 6
Training loss: 1.781327247619629
Validation loss: 2.1345387274219143

Epoch: 5| Step: 7
Training loss: 1.247241497039795
Validation loss: 2.0661791473306637

Epoch: 5| Step: 8
Training loss: 2.0956039428710938
Validation loss: 2.0508494800136936

Epoch: 5| Step: 9
Training loss: 1.0893843173980713
Validation loss: 2.086728363908747

Epoch: 5| Step: 10
Training loss: 1.4362322092056274
Validation loss: 2.1207263559423466

Epoch: 484| Step: 0
Training loss: 2.0235846042633057
Validation loss: 2.074999842592465

Epoch: 5| Step: 1
Training loss: 1.258277177810669
Validation loss: 2.054396272987448

Epoch: 5| Step: 2
Training loss: 1.9206438064575195
Validation loss: 2.0458186621307046

Epoch: 5| Step: 3
Training loss: 1.2621172666549683
Validation loss: 2.056634843990367

Epoch: 5| Step: 4
Training loss: 1.4318431615829468
Validation loss: 2.0876456255553872

Epoch: 5| Step: 5
Training loss: 1.159571886062622
Validation loss: 2.053445167438958

Epoch: 5| Step: 6
Training loss: 1.3820102214813232
Validation loss: 2.093838381510909

Epoch: 5| Step: 7
Training loss: 1.5070476531982422
Validation loss: 2.0833934724971814

Epoch: 5| Step: 8
Training loss: 1.675890326499939
Validation loss: 2.1011367459451

Epoch: 5| Step: 9
Training loss: 2.2929930686950684
Validation loss: 2.062040244379351

Epoch: 5| Step: 10
Training loss: 0.9103371500968933
Validation loss: 2.080113108440112

Epoch: 485| Step: 0
Training loss: 1.7568143606185913
Validation loss: 2.0644790203340593

Epoch: 5| Step: 1
Training loss: 1.607248306274414
Validation loss: 2.016891212873561

Epoch: 5| Step: 2
Training loss: 1.4912283420562744
Validation loss: 2.036054979088486

Epoch: 5| Step: 3
Training loss: 2.5107758045196533
Validation loss: 2.092468430919032

Epoch: 5| Step: 4
Training loss: 1.7075870037078857
Validation loss: 2.055567437602628

Epoch: 5| Step: 5
Training loss: 1.3507070541381836
Validation loss: 2.0827009677886963

Epoch: 5| Step: 6
Training loss: 0.8324023485183716
Validation loss: 2.120107503347499

Epoch: 5| Step: 7
Training loss: 1.3832857608795166
Validation loss: 2.091673684376542

Epoch: 5| Step: 8
Training loss: 1.794499158859253
Validation loss: 2.007203826340296

Epoch: 5| Step: 9
Training loss: 1.0089397430419922
Validation loss: 2.037859803886824

Epoch: 5| Step: 10
Training loss: 1.3020002841949463
Validation loss: 2.065452298810405

Epoch: 486| Step: 0
Training loss: 1.5029518604278564
Validation loss: 2.092664828864477

Epoch: 5| Step: 1
Training loss: 1.4071643352508545
Validation loss: 2.132503604376188

Epoch: 5| Step: 2
Training loss: 1.396423578262329
Validation loss: 2.0864207731780184

Epoch: 5| Step: 3
Training loss: 2.0789735317230225
Validation loss: 2.0522564354763237

Epoch: 5| Step: 4
Training loss: 1.9969978332519531
Validation loss: 2.1393124877765612

Epoch: 5| Step: 5
Training loss: 1.2350612878799438
Validation loss: 2.119238554790456

Epoch: 5| Step: 6
Training loss: 1.0754395723342896
Validation loss: 2.0804282952380437

Epoch: 5| Step: 7
Training loss: 1.0666158199310303
Validation loss: 2.078512937791886

Epoch: 5| Step: 8
Training loss: 2.1624557971954346
Validation loss: 2.0242470759217457

Epoch: 5| Step: 9
Training loss: 1.4811776876449585
Validation loss: 2.0936062233422392

Epoch: 5| Step: 10
Training loss: 1.5880637168884277
Validation loss: 2.073193678291895

Epoch: 487| Step: 0
Training loss: 1.7148643732070923
Validation loss: 2.0044259832751368

Epoch: 5| Step: 1
Training loss: 1.5305922031402588
Validation loss: 2.069701102472121

Epoch: 5| Step: 2
Training loss: 1.7187528610229492
Validation loss: 2.0852151609236196

Epoch: 5| Step: 3
Training loss: 1.4971206188201904
Validation loss: 2.0485993969825005

Epoch: 5| Step: 4
Training loss: 1.2718712091445923
Validation loss: 2.1435325171357844

Epoch: 5| Step: 5
Training loss: 1.4538731575012207
Validation loss: 2.0629589916557394

Epoch: 5| Step: 6
Training loss: 1.3693565130233765
Validation loss: 2.054714519490478

Epoch: 5| Step: 7
Training loss: 1.3272593021392822
Validation loss: 2.0403014793190906

Epoch: 5| Step: 8
Training loss: 1.411841869354248
Validation loss: 2.074711335602627

Epoch: 5| Step: 9
Training loss: 2.027134418487549
Validation loss: 2.099779462301603

Epoch: 5| Step: 10
Training loss: 1.4252874851226807
Validation loss: 2.0218752404694915

Epoch: 488| Step: 0
Training loss: 1.56552255153656
Validation loss: 2.0847064154122465

Epoch: 5| Step: 1
Training loss: 1.5220563411712646
Validation loss: 2.033729249431241

Epoch: 5| Step: 2
Training loss: 1.9281208515167236
Validation loss: 2.050416431119365

Epoch: 5| Step: 3
Training loss: 1.4236608743667603
Validation loss: 2.0347341619512087

Epoch: 5| Step: 4
Training loss: 0.9326038360595703
Validation loss: 2.1342713627763974

Epoch: 5| Step: 5
Training loss: 1.7052137851715088
Validation loss: 2.0834397346742692

Epoch: 5| Step: 6
Training loss: 1.4429142475128174
Validation loss: 2.070776272845525

Epoch: 5| Step: 7
Training loss: 2.2006447315216064
Validation loss: 2.0047709877772997

Epoch: 5| Step: 8
Training loss: 1.3490327596664429
Validation loss: 2.0955344528280277

Epoch: 5| Step: 9
Training loss: 1.0554742813110352
Validation loss: 2.1050602441192954

Epoch: 5| Step: 10
Training loss: 1.5810586214065552
Validation loss: 2.024694010775576

Epoch: 489| Step: 0
Training loss: 1.5893819332122803
Validation loss: 2.036386497559086

Epoch: 5| Step: 1
Training loss: 1.4051992893218994
Validation loss: 2.025362927426574

Epoch: 5| Step: 2
Training loss: 1.6527531147003174
Validation loss: 2.0455929207545456

Epoch: 5| Step: 3
Training loss: 2.0624518394470215
Validation loss: 2.0295371701640468

Epoch: 5| Step: 4
Training loss: 1.7203460931777954
Validation loss: 2.0702820490765315

Epoch: 5| Step: 5
Training loss: 1.6767578125
Validation loss: 2.051225657104164

Epoch: 5| Step: 6
Training loss: 1.391775369644165
Validation loss: 2.0427497356168685

Epoch: 5| Step: 7
Training loss: 1.1464412212371826
Validation loss: 2.0807010653198406

Epoch: 5| Step: 8
Training loss: 1.3694093227386475
Validation loss: 2.026787975782989

Epoch: 5| Step: 9
Training loss: 1.3210948705673218
Validation loss: 2.077846985991283

Epoch: 5| Step: 10
Training loss: 1.4461010694503784
Validation loss: 2.1027558631794427

Epoch: 490| Step: 0
Training loss: 1.5604915618896484
Validation loss: 2.0715248584747314

Epoch: 5| Step: 1
Training loss: 1.516659140586853
Validation loss: 2.0482684719947075

Epoch: 5| Step: 2
Training loss: 1.868166208267212
Validation loss: 2.0596352866900864

Epoch: 5| Step: 3
Training loss: 1.9430125951766968
Validation loss: 2.013341119212489

Epoch: 5| Step: 4
Training loss: 1.2405264377593994
Validation loss: 2.090401049583189

Epoch: 5| Step: 5
Training loss: 1.4424546957015991
Validation loss: 2.1013961940683346

Epoch: 5| Step: 6
Training loss: 0.928784966468811
Validation loss: 2.114501004577965

Epoch: 5| Step: 7
Training loss: 1.5592046976089478
Validation loss: 2.0286771533309773

Epoch: 5| Step: 8
Training loss: 1.3844248056411743
Validation loss: 2.092304159236211

Epoch: 5| Step: 9
Training loss: 1.6142746210098267
Validation loss: 2.0797865288231963

Epoch: 5| Step: 10
Training loss: 1.4803171157836914
Validation loss: 2.0522975742176013

Epoch: 491| Step: 0
Training loss: 1.6606900691986084
Validation loss: 2.054347904779578

Epoch: 5| Step: 1
Training loss: 1.6594867706298828
Validation loss: 2.0740084135404198

Epoch: 5| Step: 2
Training loss: 1.9717973470687866
Validation loss: 2.1050162597369124

Epoch: 5| Step: 3
Training loss: 1.1643470525741577
Validation loss: 2.084252449773973

Epoch: 5| Step: 4
Training loss: 1.5102550983428955
Validation loss: 2.1771340895724554

Epoch: 5| Step: 5
Training loss: 1.2602956295013428
Validation loss: 2.0773438125528316

Epoch: 5| Step: 6
Training loss: 0.8581790924072266
Validation loss: 2.1496935390656993

Epoch: 5| Step: 7
Training loss: 2.163435697555542
Validation loss: 2.088760596449657

Epoch: 5| Step: 8
Training loss: 1.8244054317474365
Validation loss: 2.0658440615541194

Epoch: 5| Step: 9
Training loss: 1.4778351783752441
Validation loss: 2.09529774419723

Epoch: 5| Step: 10
Training loss: 1.0819419622421265
Validation loss: 2.064889748891195

Epoch: 492| Step: 0
Training loss: 1.2718175649642944
Validation loss: 2.1001550433456257

Epoch: 5| Step: 1
Training loss: 1.2442060708999634
Validation loss: 2.1008329083842616

Epoch: 5| Step: 2
Training loss: 1.642108678817749
Validation loss: 2.058109196283484

Epoch: 5| Step: 3
Training loss: 1.2656524181365967
Validation loss: 2.102557636076404

Epoch: 5| Step: 4
Training loss: 1.8044391870498657
Validation loss: 1.9906123761207826

Epoch: 5| Step: 5
Training loss: 1.6879323720932007
Validation loss: 2.098694419348112

Epoch: 5| Step: 6
Training loss: 1.1758453845977783
Validation loss: 2.0247998404246506

Epoch: 5| Step: 7
Training loss: 1.0736520290374756
Validation loss: 2.043038219533941

Epoch: 5| Step: 8
Training loss: 1.9762169122695923
Validation loss: 2.067632294470264

Epoch: 5| Step: 9
Training loss: 1.6308034658432007
Validation loss: 2.0644733495609735

Epoch: 5| Step: 10
Training loss: 1.6988635063171387
Validation loss: 2.0426431753302134

Epoch: 493| Step: 0
Training loss: 1.5697020292282104
Validation loss: 2.1165110129182056

Epoch: 5| Step: 1
Training loss: 1.1199489831924438
Validation loss: 2.024767373197822

Epoch: 5| Step: 2
Training loss: 1.8701794147491455
Validation loss: 2.045018239687848

Epoch: 5| Step: 3
Training loss: 1.6403453350067139
Validation loss: 2.0210394064585366

Epoch: 5| Step: 4
Training loss: 1.316068410873413
Validation loss: 2.042517351847823

Epoch: 5| Step: 5
Training loss: 1.8459937572479248
Validation loss: 2.0465482473373413

Epoch: 5| Step: 6
Training loss: 1.55983567237854
Validation loss: 2.0763191715363534

Epoch: 5| Step: 7
Training loss: 1.346199631690979
Validation loss: 2.060657396111437

Epoch: 5| Step: 8
Training loss: 1.3450424671173096
Validation loss: 2.031623282740193

Epoch: 5| Step: 9
Training loss: 1.7077308893203735
Validation loss: 2.067128468585271

Epoch: 5| Step: 10
Training loss: 1.0776447057724
Validation loss: 2.0695579436517533

Epoch: 494| Step: 0
Training loss: 1.5745891332626343
Validation loss: 2.045533562219271

Epoch: 5| Step: 1
Training loss: 1.5695942640304565
Validation loss: 2.100730001285512

Epoch: 5| Step: 2
Training loss: 1.828951120376587
Validation loss: 2.054950124473982

Epoch: 5| Step: 3
Training loss: 0.9358924627304077
Validation loss: 2.116224865759573

Epoch: 5| Step: 4
Training loss: 0.8716023564338684
Validation loss: 2.102168727946538

Epoch: 5| Step: 5
Training loss: 1.938201665878296
Validation loss: 2.1257140533898466

Epoch: 5| Step: 6
Training loss: 1.472430944442749
Validation loss: 2.0789259531164683

Epoch: 5| Step: 7
Training loss: 1.8768205642700195
Validation loss: 2.0527968381040838

Epoch: 5| Step: 8
Training loss: 0.7833505272865295
Validation loss: 2.080612033926031

Epoch: 5| Step: 9
Training loss: 2.0646183490753174
Validation loss: 2.0331686594152965

Epoch: 5| Step: 10
Training loss: 1.9272831678390503
Validation loss: 2.1161926228513

Epoch: 495| Step: 0
Training loss: 1.5861070156097412
Validation loss: 2.0904115374370287

Epoch: 5| Step: 1
Training loss: 1.5795681476593018
Validation loss: 2.0639389484159407

Epoch: 5| Step: 2
Training loss: 1.8570442199707031
Validation loss: 2.075169704293692

Epoch: 5| Step: 3
Training loss: 1.0990054607391357
Validation loss: 2.08497178810899

Epoch: 5| Step: 4
Training loss: 1.5280193090438843
Validation loss: 2.107166909402417

Epoch: 5| Step: 5
Training loss: 1.7821792364120483
Validation loss: 1.9765288086347683

Epoch: 5| Step: 6
Training loss: 1.321424126625061
Validation loss: 2.084596513420023

Epoch: 5| Step: 7
Training loss: 1.5579051971435547
Validation loss: 2.074128807231944

Epoch: 5| Step: 8
Training loss: 1.6101500988006592
Validation loss: 2.058989319750058

Epoch: 5| Step: 9
Training loss: 1.3403488397598267
Validation loss: 2.0161356900327947

Epoch: 5| Step: 10
Training loss: 1.6053062677383423
Validation loss: 2.026875158791901

Epoch: 496| Step: 0
Training loss: 1.7275230884552002
Validation loss: 2.0108595766046995

Epoch: 5| Step: 1
Training loss: 1.6346994638442993
Validation loss: 2.093841706552813

Epoch: 5| Step: 2
Training loss: 1.7807248830795288
Validation loss: 2.0379178549653743

Epoch: 5| Step: 3
Training loss: 1.4827067852020264
Validation loss: 2.1056344009214834

Epoch: 5| Step: 4
Training loss: 1.0950061082839966
Validation loss: 2.062223357539023

Epoch: 5| Step: 5
Training loss: 1.8292620182037354
Validation loss: 2.0868414601972027

Epoch: 5| Step: 6
Training loss: 1.1110116243362427
Validation loss: 2.0792768078465618

Epoch: 5| Step: 7
Training loss: 1.477786660194397
Validation loss: 2.0576644200150684

Epoch: 5| Step: 8
Training loss: 1.432102918624878
Validation loss: 2.0669730555626655

Epoch: 5| Step: 9
Training loss: 1.3792006969451904
Validation loss: 2.0125482325912802

Epoch: 5| Step: 10
Training loss: 1.6038413047790527
Validation loss: 2.060254758404147

Epoch: 497| Step: 0
Training loss: 1.7941572666168213
Validation loss: 2.043958562676625

Epoch: 5| Step: 1
Training loss: 1.3982276916503906
Validation loss: 2.0489005914298435

Epoch: 5| Step: 2
Training loss: 2.069481611251831
Validation loss: 2.0774990230478267

Epoch: 5| Step: 3
Training loss: 1.4183844327926636
Validation loss: 2.1088992216253795

Epoch: 5| Step: 4
Training loss: 1.8045858144760132
Validation loss: 2.07832432305941

Epoch: 5| Step: 5
Training loss: 1.2206416130065918
Validation loss: 2.110241779717066

Epoch: 5| Step: 6
Training loss: 1.4936134815216064
Validation loss: 2.1065435999183246

Epoch: 5| Step: 7
Training loss: 0.7762414813041687
Validation loss: 2.101401577713669

Epoch: 5| Step: 8
Training loss: 1.314847707748413
Validation loss: 2.066490207948992

Epoch: 5| Step: 9
Training loss: 1.8024413585662842
Validation loss: 2.069453066395175

Epoch: 5| Step: 10
Training loss: 1.1371840238571167
Validation loss: 2.070441997179421

Epoch: 498| Step: 0
Training loss: 1.170599341392517
Validation loss: 2.0942934815601637

Epoch: 5| Step: 1
Training loss: 1.3977272510528564
Validation loss: 2.034231653777502

Epoch: 5| Step: 2
Training loss: 1.145672082901001
Validation loss: 2.0712972494863693

Epoch: 5| Step: 3
Training loss: 1.4785014390945435
Validation loss: 2.02278814008159

Epoch: 5| Step: 4
Training loss: 1.6958061456680298
Validation loss: 2.040680052131735

Epoch: 5| Step: 5
Training loss: 1.4380000829696655
Validation loss: 2.0984595873022593

Epoch: 5| Step: 6
Training loss: 1.905071496963501
Validation loss: 2.0230865760516097

Epoch: 5| Step: 7
Training loss: 1.042541742324829
Validation loss: 2.1139241828713367

Epoch: 5| Step: 8
Training loss: 1.4115670919418335
Validation loss: 2.0674383819744153

Epoch: 5| Step: 9
Training loss: 2.0454699993133545
Validation loss: 2.053521990776062

Epoch: 5| Step: 10
Training loss: 1.4575984477996826
Validation loss: 2.0541838394698275

Epoch: 499| Step: 0
Training loss: 1.4025943279266357
Validation loss: 2.0261465477687057

Epoch: 5| Step: 1
Training loss: 1.7056529521942139
Validation loss: 2.0353652392664263

Epoch: 5| Step: 2
Training loss: 1.6290117502212524
Validation loss: 2.0651195228740735

Epoch: 5| Step: 3
Training loss: 1.516327142715454
Validation loss: 2.110398745024076

Epoch: 5| Step: 4
Training loss: 1.8122724294662476
Validation loss: 2.1006708645051524

Epoch: 5| Step: 5
Training loss: 1.3798983097076416
Validation loss: 2.117500397466844

Epoch: 5| Step: 6
Training loss: 0.8428741693496704
Validation loss: 2.109758448857133

Epoch: 5| Step: 7
Training loss: 1.9268054962158203
Validation loss: 2.0350350064616047

Epoch: 5| Step: 8
Training loss: 1.2842313051223755
Validation loss: 2.0576987586995608

Epoch: 5| Step: 9
Training loss: 1.1304435729980469
Validation loss: 2.081894904054621

Epoch: 5| Step: 10
Training loss: 1.728810429573059
Validation loss: 2.0445259027583624

Epoch: 500| Step: 0
Training loss: 1.0184128284454346
Validation loss: 2.020022907564717

Epoch: 5| Step: 1
Training loss: 1.601253867149353
Validation loss: 2.1085871496508197

Epoch: 5| Step: 2
Training loss: 1.7007135152816772
Validation loss: 2.0157907393670853

Epoch: 5| Step: 3
Training loss: 0.7254923582077026
Validation loss: 2.0592139741425872

Epoch: 5| Step: 4
Training loss: 1.472493290901184
Validation loss: 2.0340549099829888

Epoch: 5| Step: 5
Training loss: 1.7787948846817017
Validation loss: 2.0531886393024075

Epoch: 5| Step: 6
Training loss: 1.7085033655166626
Validation loss: 1.9787261434780654

Epoch: 5| Step: 7
Training loss: 1.5426944494247437
Validation loss: 2.0607387173560356

Epoch: 5| Step: 8
Training loss: 1.630467414855957
Validation loss: 2.082348732538121

Epoch: 5| Step: 9
Training loss: 1.5169379711151123
Validation loss: 2.0426455595160045

Epoch: 5| Step: 10
Training loss: 1.490204930305481
Validation loss: 2.0393542935771327

Epoch: 501| Step: 0
Training loss: 1.503886103630066
Validation loss: 2.0884852691363265

Epoch: 5| Step: 1
Training loss: 1.7591559886932373
Validation loss: 1.9915730158487956

Epoch: 5| Step: 2
Training loss: 1.398352861404419
Validation loss: 1.9967724674491472

Epoch: 5| Step: 3
Training loss: 1.6353404521942139
Validation loss: 2.0696283771145727

Epoch: 5| Step: 4
Training loss: 1.2921693325042725
Validation loss: 2.097760364573489

Epoch: 5| Step: 5
Training loss: 1.496839165687561
Validation loss: 2.062835278049592

Epoch: 5| Step: 6
Training loss: 1.4072469472885132
Validation loss: 1.9868538251487158

Epoch: 5| Step: 7
Training loss: 1.3957111835479736
Validation loss: 2.053077923354282

Epoch: 5| Step: 8
Training loss: 1.3386074304580688
Validation loss: 2.098651432221936

Epoch: 5| Step: 9
Training loss: 1.2281067371368408
Validation loss: 2.036254375211654

Epoch: 5| Step: 10
Training loss: 1.8076826333999634
Validation loss: 2.025860519819362

Epoch: 502| Step: 0
Training loss: 1.4612563848495483
Validation loss: 2.0343690123609317

Epoch: 5| Step: 1
Training loss: 1.4414366483688354
Validation loss: 2.06503140541815

Epoch: 5| Step: 2
Training loss: 1.5104478597640991
Validation loss: 2.082369719782183

Epoch: 5| Step: 3
Training loss: 1.8400285243988037
Validation loss: 2.075625918244803

Epoch: 5| Step: 4
Training loss: 1.5893735885620117
Validation loss: 2.0233729244560323

Epoch: 5| Step: 5
Training loss: 1.791863203048706
Validation loss: 2.0363758584504486

Epoch: 5| Step: 6
Training loss: 1.7494617700576782
Validation loss: 2.0780975228996685

Epoch: 5| Step: 7
Training loss: 1.057364821434021
Validation loss: 2.0077415102271625

Epoch: 5| Step: 8
Training loss: 1.5370687246322632
Validation loss: 2.0762347329047417

Epoch: 5| Step: 9
Training loss: 1.4942724704742432
Validation loss: 2.1034214714522004

Epoch: 5| Step: 10
Training loss: 1.178949236869812
Validation loss: 2.0213972624912055

Epoch: 503| Step: 0
Training loss: 2.0630176067352295
Validation loss: 2.054680105178587

Epoch: 5| Step: 1
Training loss: 1.6130008697509766
Validation loss: 2.0847652112284014

Epoch: 5| Step: 2
Training loss: 1.7917420864105225
Validation loss: 2.0679483106059413

Epoch: 5| Step: 3
Training loss: 1.260575294494629
Validation loss: 2.0119716775032783

Epoch: 5| Step: 4
Training loss: 1.3252261877059937
Validation loss: 2.031965142937117

Epoch: 5| Step: 5
Training loss: 1.5626018047332764
Validation loss: 2.0645001601147395

Epoch: 5| Step: 6
Training loss: 1.4667994976043701
Validation loss: 2.044800836552856

Epoch: 5| Step: 7
Training loss: 1.1900486946105957
Validation loss: 2.056430434667936

Epoch: 5| Step: 8
Training loss: 1.1530996561050415
Validation loss: 2.0960711586859917

Epoch: 5| Step: 9
Training loss: 1.9423863887786865
Validation loss: 2.0572492640505553

Epoch: 5| Step: 10
Training loss: 1.239254117012024
Validation loss: 2.044057184650052

Epoch: 504| Step: 0
Training loss: 2.0445199012756348
Validation loss: 2.0383046006643646

Epoch: 5| Step: 1
Training loss: 1.6296501159667969
Validation loss: 2.1139402748436056

Epoch: 5| Step: 2
Training loss: 1.6054067611694336
Validation loss: 2.06181965720269

Epoch: 5| Step: 3
Training loss: 1.7841895818710327
Validation loss: 2.0664425460241174

Epoch: 5| Step: 4
Training loss: 1.196349859237671
Validation loss: 2.109640065059867

Epoch: 5| Step: 5
Training loss: 0.6734361052513123
Validation loss: 2.0329051684307795

Epoch: 5| Step: 6
Training loss: 1.4674967527389526
Validation loss: 2.046491438342679

Epoch: 5| Step: 7
Training loss: 1.345355749130249
Validation loss: 2.0868141933154036

Epoch: 5| Step: 8
Training loss: 1.6736265420913696
Validation loss: 2.051718515734519

Epoch: 5| Step: 9
Training loss: 1.5856159925460815
Validation loss: 2.0666022031537947

Epoch: 5| Step: 10
Training loss: 1.497330904006958
Validation loss: 2.072454421750961

Epoch: 505| Step: 0
Training loss: 1.257727026939392
Validation loss: 2.042256042521487

Epoch: 5| Step: 1
Training loss: 1.8016166687011719
Validation loss: 2.042398565558977

Epoch: 5| Step: 2
Training loss: 1.609153151512146
Validation loss: 2.0624048556050947

Epoch: 5| Step: 3
Training loss: 1.3197078704833984
Validation loss: 2.074618249811152

Epoch: 5| Step: 4
Training loss: 1.0557498931884766
Validation loss: 2.0330625477657525

Epoch: 5| Step: 5
Training loss: 1.3972465991973877
Validation loss: 2.0532107135300994

Epoch: 5| Step: 6
Training loss: 1.3872134685516357
Validation loss: 2.055916181174658

Epoch: 5| Step: 7
Training loss: 1.3591214418411255
Validation loss: 2.028523487429465

Epoch: 5| Step: 8
Training loss: 2.076916456222534
Validation loss: 2.0887676054431545

Epoch: 5| Step: 9
Training loss: 1.306657075881958
Validation loss: 2.0776506431641115

Epoch: 5| Step: 10
Training loss: 1.5807993412017822
Validation loss: 2.0817604257214453

Epoch: 506| Step: 0
Training loss: 1.0232666730880737
Validation loss: 2.0398155258547876

Epoch: 5| Step: 1
Training loss: 1.6869604587554932
Validation loss: 2.0600973201054398

Epoch: 5| Step: 2
Training loss: 1.1773786544799805
Validation loss: 2.1155362090756817

Epoch: 5| Step: 3
Training loss: 1.5065971612930298
Validation loss: 1.995563466061828

Epoch: 5| Step: 4
Training loss: 1.0939581394195557
Validation loss: 2.04780210474486

Epoch: 5| Step: 5
Training loss: 1.8763411045074463
Validation loss: 2.051523018908757

Epoch: 5| Step: 6
Training loss: 1.756158471107483
Validation loss: 2.1153541598268735

Epoch: 5| Step: 7
Training loss: 1.8181102275848389
Validation loss: 2.080972698427016

Epoch: 5| Step: 8
Training loss: 1.7996362447738647
Validation loss: 2.058197625221745

Epoch: 5| Step: 9
Training loss: 1.2205082178115845
Validation loss: 2.0874290056126092

Epoch: 5| Step: 10
Training loss: 1.522234320640564
Validation loss: 2.042697719348374

Epoch: 507| Step: 0
Training loss: 1.3669037818908691
Validation loss: 2.0316157905004357

Epoch: 5| Step: 1
Training loss: 1.42160964012146
Validation loss: 2.0341988302046254

Epoch: 5| Step: 2
Training loss: 0.7143847346305847
Validation loss: 2.0762102078366023

Epoch: 5| Step: 3
Training loss: 1.9324764013290405
Validation loss: 2.064548820577642

Epoch: 5| Step: 4
Training loss: 1.4603722095489502
Validation loss: 1.986600742545179

Epoch: 5| Step: 5
Training loss: 1.7677333354949951
Validation loss: 2.0077510802976546

Epoch: 5| Step: 6
Training loss: 1.050161600112915
Validation loss: 2.01355242729187

Epoch: 5| Step: 7
Training loss: 1.6627546548843384
Validation loss: 2.0152485524454424

Epoch: 5| Step: 8
Training loss: 1.6921241283416748
Validation loss: 2.069901727860974

Epoch: 5| Step: 9
Training loss: 1.6627721786499023
Validation loss: 2.027992917645362

Epoch: 5| Step: 10
Training loss: 1.2569055557250977
Validation loss: 2.0363517089556624

Epoch: 508| Step: 0
Training loss: 1.303701400756836
Validation loss: 2.1088093198755735

Epoch: 5| Step: 1
Training loss: 1.4752552509307861
Validation loss: 2.063261126959196

Epoch: 5| Step: 2
Training loss: 1.1002323627471924
Validation loss: 2.038748223294494

Epoch: 5| Step: 3
Training loss: 1.6783390045166016
Validation loss: 2.0374852136899064

Epoch: 5| Step: 4
Training loss: 1.7337480783462524
Validation loss: 2.070719688169418

Epoch: 5| Step: 5
Training loss: 1.5457700490951538
Validation loss: 2.0424227535083728

Epoch: 5| Step: 6
Training loss: 1.2335537672042847
Validation loss: 2.0241148241104616

Epoch: 5| Step: 7
Training loss: 1.9948740005493164
Validation loss: 2.0758033516586467

Epoch: 5| Step: 8
Training loss: 1.010154366493225
Validation loss: 2.054214664684829

Epoch: 5| Step: 9
Training loss: 1.5482563972473145
Validation loss: 2.0795815683180288

Epoch: 5| Step: 10
Training loss: 1.6331558227539062
Validation loss: 2.064177123449182

Epoch: 509| Step: 0
Training loss: 1.4478943347930908
Validation loss: 2.0662870868559806

Epoch: 5| Step: 1
Training loss: 1.4040180444717407
Validation loss: 2.1336635081998763

Epoch: 5| Step: 2
Training loss: 1.6710439920425415
Validation loss: 2.0823000650252066

Epoch: 5| Step: 3
Training loss: 1.2460730075836182
Validation loss: 2.085355415139147

Epoch: 5| Step: 4
Training loss: 1.615704894065857
Validation loss: 2.044658384015483

Epoch: 5| Step: 5
Training loss: 0.8468496203422546
Validation loss: 2.0998659621002855

Epoch: 5| Step: 6
Training loss: 1.184826135635376
Validation loss: 2.0853229030486076

Epoch: 5| Step: 7
Training loss: 1.9474947452545166
Validation loss: 2.062944035376272

Epoch: 5| Step: 8
Training loss: 1.3482803106307983
Validation loss: 2.052445756491794

Epoch: 5| Step: 9
Training loss: 1.918410301208496
Validation loss: 2.1509312173371673

Epoch: 5| Step: 10
Training loss: 1.4895243644714355
Validation loss: 2.0916936500098116

Epoch: 510| Step: 0
Training loss: 1.252308964729309
Validation loss: 2.059511580774861

Epoch: 5| Step: 1
Training loss: 1.5298148393630981
Validation loss: 2.053799398483769

Epoch: 5| Step: 2
Training loss: 2.3313345909118652
Validation loss: 2.0460339335985083

Epoch: 5| Step: 3
Training loss: 1.5334683656692505
Validation loss: 2.08699123321041

Epoch: 5| Step: 4
Training loss: 1.9378697872161865
Validation loss: 2.094474087479294

Epoch: 5| Step: 5
Training loss: 1.5207699537277222
Validation loss: 2.0868258681348575

Epoch: 5| Step: 6
Training loss: 1.3050800561904907
Validation loss: 2.0451282070529078

Epoch: 5| Step: 7
Training loss: 1.4503809213638306
Validation loss: 2.0507681600509153

Epoch: 5| Step: 8
Training loss: 1.1509711742401123
Validation loss: 2.086757572748328

Epoch: 5| Step: 9
Training loss: 1.2675621509552002
Validation loss: 2.0207290021322106

Epoch: 5| Step: 10
Training loss: 0.7807804346084595
Validation loss: 2.0711348338793685

Epoch: 511| Step: 0
Training loss: 1.3164360523223877
Validation loss: 2.067150035212117

Epoch: 5| Step: 1
Training loss: 1.435642957687378
Validation loss: 2.0694129210646435

Epoch: 5| Step: 2
Training loss: 1.669019341468811
Validation loss: 2.054164186600716

Epoch: 5| Step: 3
Training loss: 1.356616497039795
Validation loss: 2.045197061313096

Epoch: 5| Step: 4
Training loss: 1.1891800165176392
Validation loss: 2.0627565999184885

Epoch: 5| Step: 5
Training loss: 1.3022770881652832
Validation loss: 2.1164337640167563

Epoch: 5| Step: 6
Training loss: 1.5502595901489258
Validation loss: 2.075786389330382

Epoch: 5| Step: 7
Training loss: 1.295130968093872
Validation loss: 2.0598988661202053

Epoch: 5| Step: 8
Training loss: 2.0577874183654785
Validation loss: 2.0695141259060112

Epoch: 5| Step: 9
Training loss: 0.9988018274307251
Validation loss: 2.090575692474201

Epoch: 5| Step: 10
Training loss: 2.104043483734131
Validation loss: 2.0391533169695126

Epoch: 512| Step: 0
Training loss: 1.628338098526001
Validation loss: 2.064661140082985

Epoch: 5| Step: 1
Training loss: 1.5287736654281616
Validation loss: 2.055405124541252

Epoch: 5| Step: 2
Training loss: 1.0685241222381592
Validation loss: 2.0599991044690533

Epoch: 5| Step: 3
Training loss: 1.498689889907837
Validation loss: 2.0921116618699926

Epoch: 5| Step: 4
Training loss: 1.7188222408294678
Validation loss: 2.060475516062911

Epoch: 5| Step: 5
Training loss: 1.4657608270645142
Validation loss: 2.0276325466812297

Epoch: 5| Step: 6
Training loss: 1.6466410160064697
Validation loss: 2.008332478102817

Epoch: 5| Step: 7
Training loss: 1.600670576095581
Validation loss: 2.092102648109518

Epoch: 5| Step: 8
Training loss: 1.2430713176727295
Validation loss: 2.012829875433317

Epoch: 5| Step: 9
Training loss: 1.2828466892242432
Validation loss: 2.071152615290816

Epoch: 5| Step: 10
Training loss: 1.1826502084732056
Validation loss: 2.1000254090114305

Epoch: 513| Step: 0
Training loss: 1.189756989479065
Validation loss: 2.056197717625608

Epoch: 5| Step: 1
Training loss: 1.696042776107788
Validation loss: 1.9972000378434376

Epoch: 5| Step: 2
Training loss: 1.303612232208252
Validation loss: 2.0913599101446008

Epoch: 5| Step: 3
Training loss: 1.5962153673171997
Validation loss: 2.1002181640235325

Epoch: 5| Step: 4
Training loss: 1.3617428541183472
Validation loss: 2.0304152375908306

Epoch: 5| Step: 5
Training loss: 1.7664661407470703
Validation loss: 2.098041055023029

Epoch: 5| Step: 6
Training loss: 1.6686359643936157
Validation loss: 2.036622046142496

Epoch: 5| Step: 7
Training loss: 1.507210612297058
Validation loss: 2.0852016377192673

Epoch: 5| Step: 8
Training loss: 1.1699597835540771
Validation loss: 2.0521935045078235

Epoch: 5| Step: 9
Training loss: 1.7677924633026123
Validation loss: 2.0738609901038547

Epoch: 5| Step: 10
Training loss: 1.0760775804519653
Validation loss: 2.0376277277546544

Epoch: 514| Step: 0
Training loss: 1.4897212982177734
Validation loss: 2.0530938948354414

Epoch: 5| Step: 1
Training loss: 0.8747266530990601
Validation loss: 2.0493003206868328

Epoch: 5| Step: 2
Training loss: 1.4131287336349487
Validation loss: 2.0441880482499317

Epoch: 5| Step: 3
Training loss: 1.1559162139892578
Validation loss: 2.0339214180105474

Epoch: 5| Step: 4
Training loss: 1.379652738571167
Validation loss: 2.07529882718158

Epoch: 5| Step: 5
Training loss: 2.2648918628692627
Validation loss: 2.0900610672530306

Epoch: 5| Step: 6
Training loss: 1.264595866203308
Validation loss: 2.0490843096087055

Epoch: 5| Step: 7
Training loss: 1.564032793045044
Validation loss: 2.120342195674937

Epoch: 5| Step: 8
Training loss: 1.3976936340332031
Validation loss: 2.021527187798613

Epoch: 5| Step: 9
Training loss: 1.6474440097808838
Validation loss: 2.0236379895158993

Epoch: 5| Step: 10
Training loss: 1.658246636390686
Validation loss: 2.0398679266693773

Epoch: 515| Step: 0
Training loss: 1.2789316177368164
Validation loss: 1.9828181792330999

Epoch: 5| Step: 1
Training loss: 1.501929759979248
Validation loss: 2.0879298974108953

Epoch: 5| Step: 2
Training loss: 1.2623299360275269
Validation loss: 2.055004753092284

Epoch: 5| Step: 3
Training loss: 1.7251182794570923
Validation loss: 2.052531547443841

Epoch: 5| Step: 4
Training loss: 0.9474563598632812
Validation loss: 2.032151299138223

Epoch: 5| Step: 5
Training loss: 1.4414167404174805
Validation loss: 2.0099411843925394

Epoch: 5| Step: 6
Training loss: 1.3463903665542603
Validation loss: 2.0184472517300676

Epoch: 5| Step: 7
Training loss: 1.3494269847869873
Validation loss: 2.0367081870314894

Epoch: 5| Step: 8
Training loss: 1.9052050113677979
Validation loss: 2.0920060142394035

Epoch: 5| Step: 9
Training loss: 2.0179080963134766
Validation loss: 2.0518317709686937

Epoch: 5| Step: 10
Training loss: 0.9830881953239441
Validation loss: 2.0237428962543444

Epoch: 516| Step: 0
Training loss: 1.2877086400985718
Validation loss: 2.0883147460158153

Epoch: 5| Step: 1
Training loss: 1.2876425981521606
Validation loss: 2.053143301317769

Epoch: 5| Step: 2
Training loss: 1.2043777704238892
Validation loss: 2.074221908405263

Epoch: 5| Step: 3
Training loss: 1.280866026878357
Validation loss: 2.025887845664896

Epoch: 5| Step: 4
Training loss: 0.8861671686172485
Validation loss: 2.0674211953275945

Epoch: 5| Step: 5
Training loss: 1.7786365747451782
Validation loss: 2.0721363918755644

Epoch: 5| Step: 6
Training loss: 1.4745876789093018
Validation loss: 2.012235482533773

Epoch: 5| Step: 7
Training loss: 1.8449420928955078
Validation loss: 2.06665329522984

Epoch: 5| Step: 8
Training loss: 2.1178641319274902
Validation loss: 2.027191695346627

Epoch: 5| Step: 9
Training loss: 1.0367505550384521
Validation loss: 2.0904373430436656

Epoch: 5| Step: 10
Training loss: 1.5480791330337524
Validation loss: 2.086194578037467

Epoch: 517| Step: 0
Training loss: 1.5715452432632446
Validation loss: 2.094705286846366

Epoch: 5| Step: 1
Training loss: 1.572389006614685
Validation loss: 2.0720297469887683

Epoch: 5| Step: 2
Training loss: 1.641636848449707
Validation loss: 2.035905662403312

Epoch: 5| Step: 3
Training loss: 1.3641903400421143
Validation loss: 2.0369536312677528

Epoch: 5| Step: 4
Training loss: 1.4448153972625732
Validation loss: 2.0483151507633988

Epoch: 5| Step: 5
Training loss: 1.0145351886749268
Validation loss: 2.068199444842595

Epoch: 5| Step: 6
Training loss: 2.1070141792297363
Validation loss: 2.021034845741846

Epoch: 5| Step: 7
Training loss: 1.2543989419937134
Validation loss: 2.0766462484995523

Epoch: 5| Step: 8
Training loss: 1.240826964378357
Validation loss: 2.0296081650641655

Epoch: 5| Step: 9
Training loss: 1.1662712097167969
Validation loss: 2.012733969637143

Epoch: 5| Step: 10
Training loss: 1.5120501518249512
Validation loss: 2.114652288857327

Epoch: 518| Step: 0
Training loss: 0.8830459713935852
Validation loss: 2.0996360868536015

Epoch: 5| Step: 1
Training loss: 1.3514540195465088
Validation loss: 2.0694539354693506

Epoch: 5| Step: 2
Training loss: 1.0889854431152344
Validation loss: 2.0238925103218324

Epoch: 5| Step: 3
Training loss: 1.5429779291152954
Validation loss: 2.0418508937281947

Epoch: 5| Step: 4
Training loss: 1.7540947198867798
Validation loss: 2.0873791812568583

Epoch: 5| Step: 5
Training loss: 1.3533453941345215
Validation loss: 2.045458156575439

Epoch: 5| Step: 6
Training loss: 1.7300941944122314
Validation loss: 2.053644278998016

Epoch: 5| Step: 7
Training loss: 1.6045023202896118
Validation loss: 2.083185952196839

Epoch: 5| Step: 8
Training loss: 1.0018246173858643
Validation loss: 2.064087648545542

Epoch: 5| Step: 9
Training loss: 1.7764383554458618
Validation loss: 2.0995971079795592

Epoch: 5| Step: 10
Training loss: 2.2019457817077637
Validation loss: 2.0813928470816663

Epoch: 519| Step: 0
Training loss: 1.4393240213394165
Validation loss: 2.0684304762912054

Epoch: 5| Step: 1
Training loss: 1.6022727489471436
Validation loss: 2.0453461190705657

Epoch: 5| Step: 2
Training loss: 1.8677905797958374
Validation loss: 2.06623274536543

Epoch: 5| Step: 3
Training loss: 1.8733640909194946
Validation loss: 2.0813546783180645

Epoch: 5| Step: 4
Training loss: 1.324480652809143
Validation loss: 2.082349031202255

Epoch: 5| Step: 5
Training loss: 1.3574680089950562
Validation loss: 2.062320183682185

Epoch: 5| Step: 6
Training loss: 1.3225561380386353
Validation loss: 2.0506458487561954

Epoch: 5| Step: 7
Training loss: 0.9639900326728821
Validation loss: 2.0859249484154487

Epoch: 5| Step: 8
Training loss: 1.3636244535446167
Validation loss: 2.0482117450365456

Epoch: 5| Step: 9
Training loss: 1.456899642944336
Validation loss: 2.0386706911107546

Epoch: 5| Step: 10
Training loss: 1.403270959854126
Validation loss: 2.104078438974196

Epoch: 520| Step: 0
Training loss: 1.7543500661849976
Validation loss: 2.0549142078686784

Epoch: 5| Step: 1
Training loss: 1.295526385307312
Validation loss: 2.099958735127603

Epoch: 5| Step: 2
Training loss: 1.1633453369140625
Validation loss: 2.079502526149955

Epoch: 5| Step: 3
Training loss: 1.551389217376709
Validation loss: 2.0419231755759126

Epoch: 5| Step: 4
Training loss: 1.6584584712982178
Validation loss: 2.0749073284928516

Epoch: 5| Step: 5
Training loss: 1.404360055923462
Validation loss: 2.0520300967718965

Epoch: 5| Step: 6
Training loss: 1.3724262714385986
Validation loss: 2.0621954189833773

Epoch: 5| Step: 7
Training loss: 1.5752991437911987
Validation loss: 2.061935620923196

Epoch: 5| Step: 8
Training loss: 1.0181410312652588
Validation loss: 2.0522329858554307

Epoch: 5| Step: 9
Training loss: 1.810418725013733
Validation loss: 1.9920380884601223

Epoch: 5| Step: 10
Training loss: 1.3651591539382935
Validation loss: 2.056618088035173

Epoch: 521| Step: 0
Training loss: 2.369793653488159
Validation loss: 1.9996175394263318

Epoch: 5| Step: 1
Training loss: 1.289878249168396
Validation loss: 2.120730250112472

Epoch: 5| Step: 2
Training loss: 0.9699365496635437
Validation loss: 2.043696644485638

Epoch: 5| Step: 3
Training loss: 1.4848257303237915
Validation loss: 2.0952695672230055

Epoch: 5| Step: 4
Training loss: 1.8447939157485962
Validation loss: 2.058141282809678

Epoch: 5| Step: 5
Training loss: 1.18605637550354
Validation loss: 2.0393290442805134

Epoch: 5| Step: 6
Training loss: 1.6168851852416992
Validation loss: 2.072252347905149

Epoch: 5| Step: 7
Training loss: 1.4154222011566162
Validation loss: 2.0686134369142595

Epoch: 5| Step: 8
Training loss: 1.4727013111114502
Validation loss: 2.0276801483605498

Epoch: 5| Step: 9
Training loss: 0.9976194500923157
Validation loss: 2.088257970348481

Epoch: 5| Step: 10
Training loss: 1.3961994647979736
Validation loss: 2.0155034603611117

Epoch: 522| Step: 0
Training loss: 1.4061732292175293
Validation loss: 2.016243361657666

Epoch: 5| Step: 1
Training loss: 1.3690743446350098
Validation loss: 2.0492122942401516

Epoch: 5| Step: 2
Training loss: 1.3183834552764893
Validation loss: 2.0749814202708583

Epoch: 5| Step: 3
Training loss: 1.60880446434021
Validation loss: 2.018163606684695

Epoch: 5| Step: 4
Training loss: 1.6430418491363525
Validation loss: 2.072468532029019

Epoch: 5| Step: 5
Training loss: 1.6231549978256226
Validation loss: 2.120806683776199

Epoch: 5| Step: 6
Training loss: 1.256197452545166
Validation loss: 2.0926762998745008

Epoch: 5| Step: 7
Training loss: 1.5774694681167603
Validation loss: 2.0424625988929503

Epoch: 5| Step: 8
Training loss: 1.2471529245376587
Validation loss: 1.9813210900111864

Epoch: 5| Step: 9
Training loss: 0.9913328289985657
Validation loss: 2.0169443161256853

Epoch: 5| Step: 10
Training loss: 1.7860175371170044
Validation loss: 2.056465491171806

Epoch: 523| Step: 0
Training loss: 0.998742938041687
Validation loss: 2.101529376481169

Epoch: 5| Step: 1
Training loss: 1.5523731708526611
Validation loss: 2.1042247510725454

Epoch: 5| Step: 2
Training loss: 1.7404632568359375
Validation loss: 2.0201385251937376

Epoch: 5| Step: 3
Training loss: 1.063452959060669
Validation loss: 2.0411384003136748

Epoch: 5| Step: 4
Training loss: 1.3805325031280518
Validation loss: 2.128861745198568

Epoch: 5| Step: 5
Training loss: 1.7973108291625977
Validation loss: 2.1040956871483916

Epoch: 5| Step: 6
Training loss: 1.697617769241333
Validation loss: 2.092929486305483

Epoch: 5| Step: 7
Training loss: 1.2880548238754272
Validation loss: 2.012069539357257

Epoch: 5| Step: 8
Training loss: 1.6437479257583618
Validation loss: 2.1294353623544016

Epoch: 5| Step: 9
Training loss: 1.2004488706588745
Validation loss: 2.103491613941808

Epoch: 5| Step: 10
Training loss: 1.3421796560287476
Validation loss: 2.0744129560327016

Epoch: 524| Step: 0
Training loss: 1.4637941122055054
Validation loss: 2.063708172049574

Epoch: 5| Step: 1
Training loss: 1.9175567626953125
Validation loss: 2.0676930476260442

Epoch: 5| Step: 2
Training loss: 1.2967853546142578
Validation loss: 2.022135760194512

Epoch: 5| Step: 3
Training loss: 2.0233874320983887
Validation loss: 2.0566276145237747

Epoch: 5| Step: 4
Training loss: 1.3805193901062012
Validation loss: 2.0398704467281217

Epoch: 5| Step: 5
Training loss: 1.6847174167633057
Validation loss: 2.072378476460775

Epoch: 5| Step: 6
Training loss: 1.4775655269622803
Validation loss: 2.0541566418063257

Epoch: 5| Step: 7
Training loss: 1.0051069259643555
Validation loss: 2.1228598574156403

Epoch: 5| Step: 8
Training loss: 1.1436117887496948
Validation loss: 1.9981898825655702

Epoch: 5| Step: 9
Training loss: 1.08284592628479
Validation loss: 2.0530530534764773

Epoch: 5| Step: 10
Training loss: 1.270250916481018
Validation loss: 2.051263372103373

Epoch: 525| Step: 0
Training loss: 1.4576003551483154
Validation loss: 2.0872462859717746

Epoch: 5| Step: 1
Training loss: 1.5583168268203735
Validation loss: 2.074796900954298

Epoch: 5| Step: 2
Training loss: 1.4372369050979614
Validation loss: 2.084921711234636

Epoch: 5| Step: 3
Training loss: 1.5114295482635498
Validation loss: 2.115821064159434

Epoch: 5| Step: 4
Training loss: 1.640268087387085
Validation loss: 2.0805589870740007

Epoch: 5| Step: 5
Training loss: 1.5106370449066162
Validation loss: 2.03621369536205

Epoch: 5| Step: 6
Training loss: 1.499781847000122
Validation loss: 2.0637389357371996

Epoch: 5| Step: 7
Training loss: 0.9905036091804504
Validation loss: 2.086474480167512

Epoch: 5| Step: 8
Training loss: 1.4105913639068604
Validation loss: 2.0097521940867105

Epoch: 5| Step: 9
Training loss: 1.4352939128875732
Validation loss: 2.0594248617849042

Epoch: 5| Step: 10
Training loss: 1.5161023139953613
Validation loss: 2.048665726056663

Epoch: 526| Step: 0
Training loss: 1.5766570568084717
Validation loss: 2.07931794915148

Epoch: 5| Step: 1
Training loss: 1.2337967157363892
Validation loss: 2.0359183408880748

Epoch: 5| Step: 2
Training loss: 1.4619957208633423
Validation loss: 2.054976050571729

Epoch: 5| Step: 3
Training loss: 1.439793348312378
Validation loss: 2.068811567880774

Epoch: 5| Step: 4
Training loss: 1.8619199991226196
Validation loss: 2.036967876136944

Epoch: 5| Step: 5
Training loss: 1.0730602741241455
Validation loss: 2.1002901818162654

Epoch: 5| Step: 6
Training loss: 1.5967941284179688
Validation loss: 2.029850697004667

Epoch: 5| Step: 7
Training loss: 1.0695831775665283
Validation loss: 2.094574205337032

Epoch: 5| Step: 8
Training loss: 1.45760977268219
Validation loss: 2.065986133390857

Epoch: 5| Step: 9
Training loss: 1.5038647651672363
Validation loss: 2.0394811758431057

Epoch: 5| Step: 10
Training loss: 1.593597412109375
Validation loss: 2.0580608152574107

Epoch: 527| Step: 0
Training loss: 1.4079476594924927
Validation loss: 2.1067459634555283

Epoch: 5| Step: 1
Training loss: 1.1914823055267334
Validation loss: 2.0506878796444146

Epoch: 5| Step: 2
Training loss: 1.2697211503982544
Validation loss: 2.0493045391574984

Epoch: 5| Step: 3
Training loss: 1.8021414279937744
Validation loss: 2.067554466186031

Epoch: 5| Step: 4
Training loss: 1.9078083038330078
Validation loss: 2.0283827076676073

Epoch: 5| Step: 5
Training loss: 1.5300636291503906
Validation loss: 2.035798870107179

Epoch: 5| Step: 6
Training loss: 1.0124354362487793
Validation loss: 2.084432654483344

Epoch: 5| Step: 7
Training loss: 1.3078199625015259
Validation loss: 2.060568248071978

Epoch: 5| Step: 8
Training loss: 1.0993684530258179
Validation loss: 2.035734861127792

Epoch: 5| Step: 9
Training loss: 1.69004225730896
Validation loss: 2.04979432013727

Epoch: 5| Step: 10
Training loss: 1.484990119934082
Validation loss: 1.9739245407042965

Epoch: 528| Step: 0
Training loss: 1.6450179815292358
Validation loss: 2.016853804229408

Epoch: 5| Step: 1
Training loss: 1.404656171798706
Validation loss: 2.025625635218877

Epoch: 5| Step: 2
Training loss: 1.2404752969741821
Validation loss: 2.037754243420016

Epoch: 5| Step: 3
Training loss: 1.3139326572418213
Validation loss: 2.037842026320837

Epoch: 5| Step: 4
Training loss: 1.3989007472991943
Validation loss: 2.0207638073992986

Epoch: 5| Step: 5
Training loss: 1.2796175479888916
Validation loss: 2.0583718387029504

Epoch: 5| Step: 6
Training loss: 1.7248808145523071
Validation loss: 2.091645448438583

Epoch: 5| Step: 7
Training loss: 2.001189708709717
Validation loss: 2.0334312197982625

Epoch: 5| Step: 8
Training loss: 1.4860172271728516
Validation loss: 2.031226235051309

Epoch: 5| Step: 9
Training loss: 1.442741870880127
Validation loss: 2.102060954416952

Epoch: 5| Step: 10
Training loss: 0.9439573884010315
Validation loss: 2.079168212029242

Epoch: 529| Step: 0
Training loss: 1.8237063884735107
Validation loss: 2.0520939109145955

Epoch: 5| Step: 1
Training loss: 1.3256999254226685
Validation loss: 2.033805242148779

Epoch: 5| Step: 2
Training loss: 1.344543695449829
Validation loss: 2.1313794838484896

Epoch: 5| Step: 3
Training loss: 1.814366102218628
Validation loss: 1.9967103914547992

Epoch: 5| Step: 4
Training loss: 0.9318463206291199
Validation loss: 2.0535205205281577

Epoch: 5| Step: 5
Training loss: 1.5489667654037476
Validation loss: 2.0420679661535446

Epoch: 5| Step: 6
Training loss: 1.2153056859970093
Validation loss: 2.0266899293468845

Epoch: 5| Step: 7
Training loss: 1.161405324935913
Validation loss: 2.04972884731908

Epoch: 5| Step: 8
Training loss: 1.4943631887435913
Validation loss: 2.0227989458268687

Epoch: 5| Step: 9
Training loss: 1.221686601638794
Validation loss: 2.057534010179581

Epoch: 5| Step: 10
Training loss: 1.7422664165496826
Validation loss: 2.0163641539953088

Epoch: 530| Step: 0
Training loss: 1.1718246936798096
Validation loss: 2.0379839597209806

Epoch: 5| Step: 1
Training loss: 1.0612528324127197
Validation loss: 2.0648023659183132

Epoch: 5| Step: 2
Training loss: 1.728034257888794
Validation loss: 2.005310276503204

Epoch: 5| Step: 3
Training loss: 1.6375644207000732
Validation loss: 1.9939377051527782

Epoch: 5| Step: 4
Training loss: 1.370478868484497
Validation loss: 2.02065888784265

Epoch: 5| Step: 5
Training loss: 1.4591983556747437
Validation loss: 2.035232029935365

Epoch: 5| Step: 6
Training loss: 1.1719516515731812
Validation loss: 2.0193045549495245

Epoch: 5| Step: 7
Training loss: 1.6950962543487549
Validation loss: 2.0768425054447626

Epoch: 5| Step: 8
Training loss: 1.4646168947219849
Validation loss: 2.0655404803573445

Epoch: 5| Step: 9
Training loss: 1.303952932357788
Validation loss: 1.9618491434281873

Epoch: 5| Step: 10
Training loss: 1.6539969444274902
Validation loss: 2.042201477994201

Epoch: 531| Step: 0
Training loss: 1.3590421676635742
Validation loss: 2.0336432431333806

Epoch: 5| Step: 1
Training loss: 1.3383092880249023
Validation loss: 2.112608245624009

Epoch: 5| Step: 2
Training loss: 1.343051552772522
Validation loss: 2.0383492503114926

Epoch: 5| Step: 3
Training loss: 1.741672158241272
Validation loss: 2.0104013796775573

Epoch: 5| Step: 4
Training loss: 1.336538553237915
Validation loss: 2.0499461402175245

Epoch: 5| Step: 5
Training loss: 1.3080209493637085
Validation loss: 1.9995125967969176

Epoch: 5| Step: 6
Training loss: 1.591918706893921
Validation loss: 2.069808058841254

Epoch: 5| Step: 7
Training loss: 0.669576108455658
Validation loss: 2.058703145673198

Epoch: 5| Step: 8
Training loss: 1.3524713516235352
Validation loss: 2.046969485539262

Epoch: 5| Step: 9
Training loss: 2.0702455043792725
Validation loss: 2.012705038952571

Epoch: 5| Step: 10
Training loss: 1.5435572862625122
Validation loss: 2.057399260100498

Epoch: 532| Step: 0
Training loss: 1.6039451360702515
Validation loss: 2.0200524150684314

Epoch: 5| Step: 1
Training loss: 1.0234863758087158
Validation loss: 2.086356584743787

Epoch: 5| Step: 2
Training loss: 1.4659960269927979
Validation loss: 2.012419637813363

Epoch: 5| Step: 3
Training loss: 0.9808864593505859
Validation loss: 2.0351126681091967

Epoch: 5| Step: 4
Training loss: 1.6721616983413696
Validation loss: 2.011817552710092

Epoch: 5| Step: 5
Training loss: 1.1060149669647217
Validation loss: 2.125407043323722

Epoch: 5| Step: 6
Training loss: 1.1594703197479248
Validation loss: 2.047330935796102

Epoch: 5| Step: 7
Training loss: 1.4362839460372925
Validation loss: 2.066790288494479

Epoch: 5| Step: 8
Training loss: 1.8540208339691162
Validation loss: 2.078214410812624

Epoch: 5| Step: 9
Training loss: 2.024233341217041
Validation loss: 2.0703145175851803

Epoch: 5| Step: 10
Training loss: 1.1514732837677002
Validation loss: 2.0381537483584498

Epoch: 533| Step: 0
Training loss: 1.715425729751587
Validation loss: 1.9962992206696542

Epoch: 5| Step: 1
Training loss: 1.690599799156189
Validation loss: 2.0600583040586082

Epoch: 5| Step: 2
Training loss: 1.533240556716919
Validation loss: 2.01835826904543

Epoch: 5| Step: 3
Training loss: 1.0286191701889038
Validation loss: 2.0189068048231062

Epoch: 5| Step: 4
Training loss: 1.4755632877349854
Validation loss: 2.016218057242773

Epoch: 5| Step: 5
Training loss: 1.2423875331878662
Validation loss: 2.0581463972727456

Epoch: 5| Step: 6
Training loss: 1.6611779928207397
Validation loss: 2.0278991627436813

Epoch: 5| Step: 7
Training loss: 1.3433988094329834
Validation loss: 2.071518405791252

Epoch: 5| Step: 8
Training loss: 1.0245473384857178
Validation loss: 2.0334787138046755

Epoch: 5| Step: 9
Training loss: 1.0178242921829224
Validation loss: 2.032189784511443

Epoch: 5| Step: 10
Training loss: 2.1748454570770264
Validation loss: 1.9978256328131563

Epoch: 534| Step: 0
Training loss: 1.7071129083633423
Validation loss: 2.065882654600246

Epoch: 5| Step: 1
Training loss: 1.535780906677246
Validation loss: 2.056290588071269

Epoch: 5| Step: 2
Training loss: 0.9701240658760071
Validation loss: 2.064316018935173

Epoch: 5| Step: 3
Training loss: 1.1087138652801514
Validation loss: 2.093696196873983

Epoch: 5| Step: 4
Training loss: 1.588071584701538
Validation loss: 2.0704223648194344

Epoch: 5| Step: 5
Training loss: 1.8115606307983398
Validation loss: 1.9542529172794794

Epoch: 5| Step: 6
Training loss: 0.9342212677001953
Validation loss: 2.074859937032064

Epoch: 5| Step: 7
Training loss: 1.514718770980835
Validation loss: 2.02912724274461

Epoch: 5| Step: 8
Training loss: 1.8129246234893799
Validation loss: 2.059453397668818

Epoch: 5| Step: 9
Training loss: 1.770277738571167
Validation loss: 2.09360497484925

Epoch: 5| Step: 10
Training loss: 0.5915055274963379
Validation loss: 2.0693259559651858

Epoch: 535| Step: 0
Training loss: 0.8226820826530457
Validation loss: 2.002135084521386

Epoch: 5| Step: 1
Training loss: 1.589355230331421
Validation loss: 2.017490202380765

Epoch: 5| Step: 2
Training loss: 1.7040437459945679
Validation loss: 2.0416083899877404

Epoch: 5| Step: 3
Training loss: 0.7325326204299927
Validation loss: 2.051389971087056

Epoch: 5| Step: 4
Training loss: 1.324739933013916
Validation loss: 2.0362109304756246

Epoch: 5| Step: 5
Training loss: 1.3520587682724
Validation loss: 2.0030600409353934

Epoch: 5| Step: 6
Training loss: 1.9987926483154297
Validation loss: 2.015171727826518

Epoch: 5| Step: 7
Training loss: 2.288290500640869
Validation loss: 2.0513373831267

Epoch: 5| Step: 8
Training loss: 1.26444673538208
Validation loss: 1.9821115668101976

Epoch: 5| Step: 9
Training loss: 1.240816354751587
Validation loss: 2.070398703698189

Epoch: 5| Step: 10
Training loss: 1.0437251329421997
Validation loss: 2.06521237152879

Epoch: 536| Step: 0
Training loss: 0.8671079874038696
Validation loss: 2.027226532659223

Epoch: 5| Step: 1
Training loss: 1.9490177631378174
Validation loss: 2.0242789842749156

Epoch: 5| Step: 2
Training loss: 0.8981606364250183
Validation loss: 2.0548878062155937

Epoch: 5| Step: 3
Training loss: 1.7570606470108032
Validation loss: 2.0436914595224525

Epoch: 5| Step: 4
Training loss: 1.0181881189346313
Validation loss: 2.0002987666796614

Epoch: 5| Step: 5
Training loss: 1.5745246410369873
Validation loss: 2.0537373455621863

Epoch: 5| Step: 6
Training loss: 1.6547603607177734
Validation loss: 2.0834263960520425

Epoch: 5| Step: 7
Training loss: 1.1168650388717651
Validation loss: 2.0400954651576217

Epoch: 5| Step: 8
Training loss: 1.7613475322723389
Validation loss: 2.044211954198858

Epoch: 5| Step: 9
Training loss: 1.5813053846359253
Validation loss: 2.04697008286753

Epoch: 5| Step: 10
Training loss: 1.608734130859375
Validation loss: 2.022113175802333

Epoch: 537| Step: 0
Training loss: 0.9777072668075562
Validation loss: 2.060491467034945

Epoch: 5| Step: 1
Training loss: 1.8429901599884033
Validation loss: 1.9752027360341882

Epoch: 5| Step: 2
Training loss: 1.2892628908157349
Validation loss: 2.041321616018972

Epoch: 5| Step: 3
Training loss: 1.4236514568328857
Validation loss: 2.090392912587812

Epoch: 5| Step: 4
Training loss: 1.7189632654190063
Validation loss: 2.0743781558928953

Epoch: 5| Step: 5
Training loss: 1.6299021244049072
Validation loss: 2.0035814803133727

Epoch: 5| Step: 6
Training loss: 1.5125691890716553
Validation loss: 2.050833467514284

Epoch: 5| Step: 7
Training loss: 0.8032954931259155
Validation loss: 2.0251904123572895

Epoch: 5| Step: 8
Training loss: 1.4421756267547607
Validation loss: 2.0348157626326366

Epoch: 5| Step: 9
Training loss: 1.1822659969329834
Validation loss: 2.085267183601215

Epoch: 5| Step: 10
Training loss: 1.6956690549850464
Validation loss: 2.0632433250386226

Epoch: 538| Step: 0
Training loss: 1.1590217351913452
Validation loss: 2.084891762784732

Epoch: 5| Step: 1
Training loss: 1.4746674299240112
Validation loss: 2.0625584484428487

Epoch: 5| Step: 2
Training loss: 1.2258790731430054
Validation loss: 2.070063555112449

Epoch: 5| Step: 3
Training loss: 1.1575682163238525
Validation loss: 2.036779039649553

Epoch: 5| Step: 4
Training loss: 1.160711646080017
Validation loss: 2.057245380134993

Epoch: 5| Step: 5
Training loss: 1.7447826862335205
Validation loss: 2.0233876089895926

Epoch: 5| Step: 6
Training loss: 1.401601791381836
Validation loss: 1.9979167010194512

Epoch: 5| Step: 7
Training loss: 1.643310546875
Validation loss: 2.054419068879979

Epoch: 5| Step: 8
Training loss: 0.8884871602058411
Validation loss: 2.071551681846701

Epoch: 5| Step: 9
Training loss: 1.6657803058624268
Validation loss: 2.0573869623163694

Epoch: 5| Step: 10
Training loss: 1.8414920568466187
Validation loss: 2.008967443179059

Epoch: 539| Step: 0
Training loss: 1.5737292766571045
Validation loss: 2.0090185852460962

Epoch: 5| Step: 1
Training loss: 2.121670961380005
Validation loss: 2.025800279391709

Epoch: 5| Step: 2
Training loss: 0.7315224409103394
Validation loss: 2.013874852529136

Epoch: 5| Step: 3
Training loss: 1.5536905527114868
Validation loss: 2.085974217743002

Epoch: 5| Step: 4
Training loss: 1.900970220565796
Validation loss: 2.073349516878846

Epoch: 5| Step: 5
Training loss: 1.296745777130127
Validation loss: 2.0571459724057104

Epoch: 5| Step: 6
Training loss: 1.2309856414794922
Validation loss: 2.049625809474658

Epoch: 5| Step: 7
Training loss: 1.0951544046401978
Validation loss: 2.0258224677014094

Epoch: 5| Step: 8
Training loss: 1.072829246520996
Validation loss: 2.052666849987481

Epoch: 5| Step: 9
Training loss: 1.5634034872055054
Validation loss: 2.0550349271425636

Epoch: 5| Step: 10
Training loss: 1.2082936763763428
Validation loss: 2.0374952259884087

Epoch: 540| Step: 0
Training loss: 1.0568879842758179
Validation loss: 2.024691459953144

Epoch: 5| Step: 1
Training loss: 1.696149468421936
Validation loss: 2.0675344095435193

Epoch: 5| Step: 2
Training loss: 0.6584789156913757
Validation loss: 2.0314199642468522

Epoch: 5| Step: 3
Training loss: 1.7576980590820312
Validation loss: 2.0337825539291545

Epoch: 5| Step: 4
Training loss: 1.9692161083221436
Validation loss: 2.0690113600864204

Epoch: 5| Step: 5
Training loss: 1.059935450553894
Validation loss: 2.0902051746204333

Epoch: 5| Step: 6
Training loss: 1.401294469833374
Validation loss: 2.0190565124634774

Epoch: 5| Step: 7
Training loss: 1.2174535989761353
Validation loss: 2.042740627001691

Epoch: 5| Step: 8
Training loss: 1.7420333623886108
Validation loss: 2.0605703823028074

Epoch: 5| Step: 9
Training loss: 1.312321424484253
Validation loss: 2.03040091324878

Epoch: 5| Step: 10
Training loss: 1.5439751148223877
Validation loss: 1.9902143337393319

Epoch: 541| Step: 0
Training loss: 2.015092372894287
Validation loss: 1.9766826911639142

Epoch: 5| Step: 1
Training loss: 0.7589825391769409
Validation loss: 2.0972619005428847

Epoch: 5| Step: 2
Training loss: 1.4219168424606323
Validation loss: 2.015512858667681

Epoch: 5| Step: 3
Training loss: 0.9947347640991211
Validation loss: 2.033321060160155

Epoch: 5| Step: 4
Training loss: 1.6054645776748657
Validation loss: 2.046570288237705

Epoch: 5| Step: 5
Training loss: 1.2230935096740723
Validation loss: 2.042335228253436

Epoch: 5| Step: 6
Training loss: 1.8838891983032227
Validation loss: 2.0614341048784155

Epoch: 5| Step: 7
Training loss: 1.5387614965438843
Validation loss: 2.0438559965420793

Epoch: 5| Step: 8
Training loss: 1.343555212020874
Validation loss: 2.038447849212154

Epoch: 5| Step: 9
Training loss: 0.7175901532173157
Validation loss: 2.1120275669200446

Epoch: 5| Step: 10
Training loss: 1.7994493246078491
Validation loss: 2.021691455635973

Epoch: 542| Step: 0
Training loss: 1.270769715309143
Validation loss: 2.0713809561985794

Epoch: 5| Step: 1
Training loss: 1.5380767583847046
Validation loss: 2.0616236655942854

Epoch: 5| Step: 2
Training loss: 0.9737130999565125
Validation loss: 2.064781382519712

Epoch: 5| Step: 3
Training loss: 1.415213704109192
Validation loss: 2.080682905771399

Epoch: 5| Step: 4
Training loss: 1.3150317668914795
Validation loss: 2.0547527690087595

Epoch: 5| Step: 5
Training loss: 1.578181266784668
Validation loss: 1.9913864981743596

Epoch: 5| Step: 6
Training loss: 1.4230327606201172
Validation loss: 2.0753288653589066

Epoch: 5| Step: 7
Training loss: 1.5316075086593628
Validation loss: 2.0673453936012844

Epoch: 5| Step: 8
Training loss: 1.455977201461792
Validation loss: 2.0247055638221

Epoch: 5| Step: 9
Training loss: 1.7520389556884766
Validation loss: 2.0481326246774323

Epoch: 5| Step: 10
Training loss: 1.1200230121612549
Validation loss: 2.009872982578893

Epoch: 543| Step: 0
Training loss: 1.3744316101074219
Validation loss: 2.0142490786890828

Epoch: 5| Step: 1
Training loss: 1.2026058435440063
Validation loss: 2.061688479556832

Epoch: 5| Step: 2
Training loss: 1.1326287984848022
Validation loss: 2.0373488831263717

Epoch: 5| Step: 3
Training loss: 1.6378428936004639
Validation loss: 2.0196689982568063

Epoch: 5| Step: 4
Training loss: 1.862522840499878
Validation loss: 2.00437331199646

Epoch: 5| Step: 5
Training loss: 1.7164280414581299
Validation loss: 2.0188450838929866

Epoch: 5| Step: 6
Training loss: 1.5717030763626099
Validation loss: 2.056527255683817

Epoch: 5| Step: 7
Training loss: 1.5276952981948853
Validation loss: 2.060479981924898

Epoch: 5| Step: 8
Training loss: 1.073352336883545
Validation loss: 1.9781603338897868

Epoch: 5| Step: 9
Training loss: 1.419725775718689
Validation loss: 2.0884589815652497

Epoch: 5| Step: 10
Training loss: 0.8115981817245483
Validation loss: 2.02378910844044

Epoch: 544| Step: 0
Training loss: 1.6965011358261108
Validation loss: 2.09762914206392

Epoch: 5| Step: 1
Training loss: 1.8306217193603516
Validation loss: 2.0149068140214488

Epoch: 5| Step: 2
Training loss: 1.3424935340881348
Validation loss: 2.1101227255277735

Epoch: 5| Step: 3
Training loss: 1.2116862535476685
Validation loss: 2.042530717388276

Epoch: 5| Step: 4
Training loss: 1.237793207168579
Validation loss: 2.093741055457823

Epoch: 5| Step: 5
Training loss: 1.450334072113037
Validation loss: 2.0587493937502623

Epoch: 5| Step: 6
Training loss: 1.3760286569595337
Validation loss: 1.999710480372111

Epoch: 5| Step: 7
Training loss: 1.4404376745224
Validation loss: 2.0621193326929563

Epoch: 5| Step: 8
Training loss: 1.589784860610962
Validation loss: 2.048926768764373

Epoch: 5| Step: 9
Training loss: 1.2099885940551758
Validation loss: 1.9663668665834653

Epoch: 5| Step: 10
Training loss: 1.3599110841751099
Validation loss: 2.0877794245237946

Epoch: 545| Step: 0
Training loss: 2.060929298400879
Validation loss: 2.0160716887443297

Epoch: 5| Step: 1
Training loss: 1.3648288249969482
Validation loss: 2.035139094116867

Epoch: 5| Step: 2
Training loss: 1.1609786748886108
Validation loss: 2.018324823789699

Epoch: 5| Step: 3
Training loss: 1.679809331893921
Validation loss: 2.0486967307265087

Epoch: 5| Step: 4
Training loss: 1.491145372390747
Validation loss: 2.091464081118184

Epoch: 5| Step: 5
Training loss: 1.1148123741149902
Validation loss: 2.0471115137941096

Epoch: 5| Step: 6
Training loss: 1.4296443462371826
Validation loss: 2.021997877346572

Epoch: 5| Step: 7
Training loss: 1.2481107711791992
Validation loss: 2.0188764692634664

Epoch: 5| Step: 8
Training loss: 0.5903735160827637
Validation loss: 2.020143219219741

Epoch: 5| Step: 9
Training loss: 1.3559653759002686
Validation loss: 2.012584432478874

Epoch: 5| Step: 10
Training loss: 1.79476797580719
Validation loss: 2.098347697206723

Epoch: 546| Step: 0
Training loss: 1.306829571723938
Validation loss: 2.058454918605025

Epoch: 5| Step: 1
Training loss: 1.5719279050827026
Validation loss: 2.047784620715726

Epoch: 5| Step: 2
Training loss: 2.1253914833068848
Validation loss: 2.0872280110595045

Epoch: 5| Step: 3
Training loss: 1.9213249683380127
Validation loss: 2.062517027701101

Epoch: 5| Step: 4
Training loss: 1.2094473838806152
Validation loss: 2.127602954064646

Epoch: 5| Step: 5
Training loss: 1.2064622640609741
Validation loss: 2.050434010003203

Epoch: 5| Step: 6
Training loss: 0.9947913885116577
Validation loss: 2.0524753268047045

Epoch: 5| Step: 7
Training loss: 1.7573163509368896
Validation loss: 2.0045432634251092

Epoch: 5| Step: 8
Training loss: 0.9079117774963379
Validation loss: 1.9841112218877321

Epoch: 5| Step: 9
Training loss: 1.0488022565841675
Validation loss: 1.9999391314803914

Epoch: 5| Step: 10
Training loss: 1.5486435890197754
Validation loss: 2.026601870854696

Epoch: 547| Step: 0
Training loss: 1.3020164966583252
Validation loss: 2.0433861158227407

Epoch: 5| Step: 1
Training loss: 1.1132256984710693
Validation loss: 2.0142845235845095

Epoch: 5| Step: 2
Training loss: 1.4938364028930664
Validation loss: 2.0582748125958186

Epoch: 5| Step: 3
Training loss: 1.458120346069336
Validation loss: 2.0158719631933395

Epoch: 5| Step: 4
Training loss: 0.8193981051445007
Validation loss: 2.0158778313667542

Epoch: 5| Step: 5
Training loss: 1.8544257879257202
Validation loss: 2.0173667143749934

Epoch: 5| Step: 6
Training loss: 1.289655327796936
Validation loss: 2.0431448695480183

Epoch: 5| Step: 7
Training loss: 1.2924606800079346
Validation loss: 2.047743119219298

Epoch: 5| Step: 8
Training loss: 1.3002240657806396
Validation loss: 2.051543381906325

Epoch: 5| Step: 9
Training loss: 2.0370683670043945
Validation loss: 2.078041504788142

Epoch: 5| Step: 10
Training loss: 1.0386708974838257
Validation loss: 2.0527218157245266

Epoch: 548| Step: 0
Training loss: 1.2584415674209595
Validation loss: 2.031153994221841

Epoch: 5| Step: 1
Training loss: 1.1820523738861084
Validation loss: 2.1068833156298568

Epoch: 5| Step: 2
Training loss: 1.111916422843933
Validation loss: 2.0786005681560886

Epoch: 5| Step: 3
Training loss: 1.3229937553405762
Validation loss: 2.0124358528403827

Epoch: 5| Step: 4
Training loss: 1.6452243328094482
Validation loss: 2.058234997974929

Epoch: 5| Step: 5
Training loss: 1.2622148990631104
Validation loss: 2.0388943341470536

Epoch: 5| Step: 6
Training loss: 2.0202698707580566
Validation loss: 2.0348557964448006

Epoch: 5| Step: 7
Training loss: 1.6343262195587158
Validation loss: 2.039722466981539

Epoch: 5| Step: 8
Training loss: 1.328617811203003
Validation loss: 2.01796132005671

Epoch: 5| Step: 9
Training loss: 1.4060509204864502
Validation loss: 2.123194556082449

Epoch: 5| Step: 10
Training loss: 1.419646143913269
Validation loss: 2.0506841726200555

Epoch: 549| Step: 0
Training loss: 1.6074453592300415
Validation loss: 2.0716440113641883

Epoch: 5| Step: 1
Training loss: 1.4243366718292236
Validation loss: 2.087169716435094

Epoch: 5| Step: 2
Training loss: 1.2101587057113647
Validation loss: 2.043592063329553

Epoch: 5| Step: 3
Training loss: 1.3798127174377441
Validation loss: 2.0774504676941903

Epoch: 5| Step: 4
Training loss: 1.2396581172943115
Validation loss: 2.051882804081004

Epoch: 5| Step: 5
Training loss: 1.4312893152236938
Validation loss: 2.0792114427012782

Epoch: 5| Step: 6
Training loss: 1.287374496459961
Validation loss: 2.0609609080899145

Epoch: 5| Step: 7
Training loss: 1.118342638015747
Validation loss: 2.0265796543449484

Epoch: 5| Step: 8
Training loss: 1.1751177310943604
Validation loss: 2.058288194799936

Epoch: 5| Step: 9
Training loss: 1.5583598613739014
Validation loss: 1.9933301915404618

Epoch: 5| Step: 10
Training loss: 1.314461588859558
Validation loss: 2.0719578625053487

Epoch: 550| Step: 0
Training loss: 1.7861614227294922
Validation loss: 2.0368957211894374

Epoch: 5| Step: 1
Training loss: 1.7849737405776978
Validation loss: 2.0679327236708773

Epoch: 5| Step: 2
Training loss: 1.6469862461090088
Validation loss: 2.0510881921296478

Epoch: 5| Step: 3
Training loss: 1.386033535003662
Validation loss: 2.05092978349296

Epoch: 5| Step: 4
Training loss: 1.3085641860961914
Validation loss: 2.0468971985642628

Epoch: 5| Step: 5
Training loss: 0.9878653287887573
Validation loss: 2.0397983007533576

Epoch: 5| Step: 6
Training loss: 1.442411184310913
Validation loss: 2.028255824119814

Epoch: 5| Step: 7
Training loss: 1.4646662473678589
Validation loss: 2.066942491839009

Epoch: 5| Step: 8
Training loss: 1.3216981887817383
Validation loss: 2.080353178003783

Epoch: 5| Step: 9
Training loss: 1.0430492162704468
Validation loss: 2.0262759782934703

Epoch: 5| Step: 10
Training loss: 1.0516505241394043
Validation loss: 2.0623497142586658

Testing loss: 2.207725246747335
