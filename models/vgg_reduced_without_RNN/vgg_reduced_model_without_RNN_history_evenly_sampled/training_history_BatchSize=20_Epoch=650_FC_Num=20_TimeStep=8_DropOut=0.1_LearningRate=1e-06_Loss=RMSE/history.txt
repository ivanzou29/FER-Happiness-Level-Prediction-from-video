Epoch: 1| Step: 0
Training loss: 6.445352746086468
Validation loss: 6.859529249310857

Epoch: 5| Step: 1
Training loss: 8.149375152037875
Validation loss: 6.855700484846247

Epoch: 5| Step: 2
Training loss: 7.135147631694401
Validation loss: 6.851202752737603

Epoch: 5| Step: 3
Training loss: 5.090906765553327
Validation loss: 6.848369312134317

Epoch: 5| Step: 4
Training loss: 7.157406909162709
Validation loss: 6.841755123984739

Epoch: 5| Step: 5
Training loss: 7.5928959621344
Validation loss: 6.8398694798964375

Epoch: 5| Step: 6
Training loss: 7.094682674180323
Validation loss: 6.835749949424112

Epoch: 5| Step: 7
Training loss: 7.535242818806764
Validation loss: 6.836233402533907

Epoch: 5| Step: 8
Training loss: 5.903630074198291
Validation loss: 6.829428911190777

Epoch: 5| Step: 9
Training loss: 6.1131817209350015
Validation loss: 6.827604722339555

Epoch: 5| Step: 10
Training loss: 6.331674592824086
Validation loss: 6.825550131788059

Epoch: 2| Step: 0
Training loss: 6.101713483947402
Validation loss: 6.8211751995381045

Epoch: 5| Step: 1
Training loss: 7.877228678852452
Validation loss: 6.816285963589984

Epoch: 5| Step: 2
Training loss: 6.698707672287227
Validation loss: 6.814406451173768

Epoch: 5| Step: 3
Training loss: 6.660439762110834
Validation loss: 6.8110043420263136

Epoch: 5| Step: 4
Training loss: 6.450959292497282
Validation loss: 6.807822979334864

Epoch: 5| Step: 5
Training loss: 6.948088941673548
Validation loss: 6.805584537036165

Epoch: 5| Step: 6
Training loss: 6.247600247302772
Validation loss: 6.802645174477272

Epoch: 5| Step: 7
Training loss: 6.43528161204073
Validation loss: 6.7999981267927705

Epoch: 5| Step: 8
Training loss: 6.408274856254278
Validation loss: 6.795477096101213

Epoch: 5| Step: 9
Training loss: 7.763475822996298
Validation loss: 6.79235683336436

Epoch: 5| Step: 10
Training loss: 6.994689561937048
Validation loss: 6.789074997479936

Epoch: 3| Step: 0
Training loss: 6.6211070012773
Validation loss: 6.785430337999153

Epoch: 5| Step: 1
Training loss: 6.948644536071181
Validation loss: 6.781470743397889

Epoch: 5| Step: 2
Training loss: 6.7592907297610445
Validation loss: 6.777642092643014

Epoch: 5| Step: 3
Training loss: 6.229811755133098
Validation loss: 6.776989429301288

Epoch: 5| Step: 4
Training loss: 6.224226031006473
Validation loss: 6.771492046816331

Epoch: 5| Step: 5
Training loss: 8.080721351225542
Validation loss: 6.767507801952161

Epoch: 5| Step: 6
Training loss: 6.922578728511609
Validation loss: 6.762420463007083

Epoch: 5| Step: 7
Training loss: 6.388386751796368
Validation loss: 6.759810200372723

Epoch: 5| Step: 8
Training loss: 6.884099868076606
Validation loss: 6.757798624531252

Epoch: 5| Step: 9
Training loss: 6.744297303059863
Validation loss: 6.757022372318817

Epoch: 5| Step: 10
Training loss: 6.324553209288316
Validation loss: 6.751716292267335

Epoch: 4| Step: 0
Training loss: 7.2105214173530765
Validation loss: 6.745275754601725

Epoch: 5| Step: 1
Training loss: 6.7140477958662
Validation loss: 6.745974015738902

Epoch: 5| Step: 2
Training loss: 7.090666113205097
Validation loss: 6.741038886592319

Epoch: 5| Step: 3
Training loss: 6.43082504128902
Validation loss: 6.73748127349139

Epoch: 5| Step: 4
Training loss: 5.855775587149048
Validation loss: 6.733248169607228

Epoch: 5| Step: 5
Training loss: 6.777344031430109
Validation loss: 6.7291951716233385

Epoch: 5| Step: 6
Training loss: 6.795113872503036
Validation loss: 6.724936272524718

Epoch: 5| Step: 7
Training loss: 6.7407915387473345
Validation loss: 6.721060794433324

Epoch: 5| Step: 8
Training loss: 6.711434005116142
Validation loss: 6.716390695258441

Epoch: 5| Step: 9
Training loss: 5.482855692334858
Validation loss: 6.713952966369184

Epoch: 5| Step: 10
Training loss: 8.02945389312233
Validation loss: 6.711674202728072

Epoch: 5| Step: 0
Training loss: 7.793061755397393
Validation loss: 6.7078372733951

Epoch: 5| Step: 1
Training loss: 7.23576114302066
Validation loss: 6.7021848730346045

Epoch: 5| Step: 2
Training loss: 5.317243365796641
Validation loss: 6.6991509728704495

Epoch: 5| Step: 3
Training loss: 6.485088851425913
Validation loss: 6.695064271519142

Epoch: 5| Step: 4
Training loss: 6.620937325309297
Validation loss: 6.691564533652238

Epoch: 5| Step: 5
Training loss: 6.165152217721456
Validation loss: 6.688501908029417

Epoch: 5| Step: 6
Training loss: 6.986687672027772
Validation loss: 6.681724737278523

Epoch: 5| Step: 7
Training loss: 7.347666114261055
Validation loss: 6.678884527981418

Epoch: 5| Step: 8
Training loss: 5.836348962130663
Validation loss: 6.674755930251213

Epoch: 5| Step: 9
Training loss: 7.318293697163257
Validation loss: 6.673787938373796

Epoch: 5| Step: 10
Training loss: 5.798301500695592
Validation loss: 6.667001089301505

Epoch: 6| Step: 0
Training loss: 7.486389016596219
Validation loss: 6.662494105313144

Epoch: 5| Step: 1
Training loss: 6.176388406073228
Validation loss: 6.660320840611625

Epoch: 5| Step: 2
Training loss: 5.8903018447914794
Validation loss: 6.652846613295711

Epoch: 5| Step: 3
Training loss: 7.666046725653474
Validation loss: 6.6511220390813754

Epoch: 5| Step: 4
Training loss: 5.857336233847914
Validation loss: 6.6444442531219705

Epoch: 5| Step: 5
Training loss: 7.056001086782082
Validation loss: 6.6441956027575895

Epoch: 5| Step: 6
Training loss: 6.389056099440423
Validation loss: 6.638470904109325

Epoch: 5| Step: 7
Training loss: 6.36259000523427
Validation loss: 6.633776194410908

Epoch: 5| Step: 8
Training loss: 6.392186950967038
Validation loss: 6.628997070599952

Epoch: 5| Step: 9
Training loss: 6.547216147044716
Validation loss: 6.626586733332846

Epoch: 5| Step: 10
Training loss: 6.962401641753638
Validation loss: 6.621079129579126

Epoch: 7| Step: 0
Training loss: 6.913460536118844
Validation loss: 6.619549587050453

Epoch: 5| Step: 1
Training loss: 6.5574996062848365
Validation loss: 6.61304485040333

Epoch: 5| Step: 2
Training loss: 6.9735900766483905
Validation loss: 6.609274259185595

Epoch: 5| Step: 3
Training loss: 5.805957680889963
Validation loss: 6.602986833961831

Epoch: 5| Step: 4
Training loss: 6.508726277946436
Validation loss: 6.59978765715989

Epoch: 5| Step: 5
Training loss: 7.035337624761499
Validation loss: 6.593274609725718

Epoch: 5| Step: 6
Training loss: 6.293054221370214
Validation loss: 6.590582253811262

Epoch: 5| Step: 7
Training loss: 6.117491187185558
Validation loss: 6.583835678696149

Epoch: 5| Step: 8
Training loss: 6.971285918828789
Validation loss: 6.58180913678512

Epoch: 5| Step: 9
Training loss: 6.348164042189125
Validation loss: 6.572856553788635

Epoch: 5| Step: 10
Training loss: 6.865332169467049
Validation loss: 6.573808250128533

Epoch: 8| Step: 0
Training loss: 6.534274774309072
Validation loss: 6.569268255660523

Epoch: 5| Step: 1
Training loss: 7.03120496947386
Validation loss: 6.562371065481673

Epoch: 5| Step: 2
Training loss: 6.337070199210105
Validation loss: 6.55596347967429

Epoch: 5| Step: 3
Training loss: 7.160878912402842
Validation loss: 6.552489725118404

Epoch: 5| Step: 4
Training loss: 6.476435569191186
Validation loss: 6.5493776412907545

Epoch: 5| Step: 5
Training loss: 7.165688765883009
Validation loss: 6.542112892387496

Epoch: 5| Step: 6
Training loss: 5.08146825042508
Validation loss: 6.538092677845757

Epoch: 5| Step: 7
Training loss: 6.156045823172692
Validation loss: 6.5312472052631225

Epoch: 5| Step: 8
Training loss: 6.310844582017443
Validation loss: 6.522804382502067

Epoch: 5| Step: 9
Training loss: 5.505057697045757
Validation loss: 6.519531190229847

Epoch: 5| Step: 10
Training loss: 7.86602901956388
Validation loss: 6.512486491581865

Epoch: 9| Step: 0
Training loss: 6.8407031379374095
Validation loss: 6.510776871755806

Epoch: 5| Step: 1
Training loss: 6.817245370539238
Validation loss: 6.504926352860435

Epoch: 5| Step: 2
Training loss: 5.610067765749689
Validation loss: 6.497403660432759

Epoch: 5| Step: 3
Training loss: 7.599047410393632
Validation loss: 6.4944401983161395

Epoch: 5| Step: 4
Training loss: 6.361410279251512
Validation loss: 6.485955585491449

Epoch: 5| Step: 5
Training loss: 6.077010260887956
Validation loss: 6.4790816235376045

Epoch: 5| Step: 6
Training loss: 5.902740566161302
Validation loss: 6.477570530403142

Epoch: 5| Step: 7
Training loss: 6.354049965042135
Validation loss: 6.469931148019358

Epoch: 5| Step: 8
Training loss: 5.9949478495845385
Validation loss: 6.464945488339167

Epoch: 5| Step: 9
Training loss: 5.899861427878121
Validation loss: 6.454571683614858

Epoch: 5| Step: 10
Training loss: 7.632628830073294
Validation loss: 6.451812298369882

Epoch: 10| Step: 0
Training loss: 6.441640170669183
Validation loss: 6.438369859466088

Epoch: 5| Step: 1
Training loss: 6.376737470032677
Validation loss: 6.43530803843918

Epoch: 5| Step: 2
Training loss: 6.315682996722357
Validation loss: 6.432503854328062

Epoch: 5| Step: 3
Training loss: 6.677828345986218
Validation loss: 6.4280192141750705

Epoch: 5| Step: 4
Training loss: 6.460225703781473
Validation loss: 6.418792293694536

Epoch: 5| Step: 5
Training loss: 6.064409093036606
Validation loss: 6.414992429531726

Epoch: 5| Step: 6
Training loss: 6.817029934307472
Validation loss: 6.407584176345328

Epoch: 5| Step: 7
Training loss: 6.664927096701486
Validation loss: 6.401186043938974

Epoch: 5| Step: 8
Training loss: 6.254513750943569
Validation loss: 6.397130504025926

Epoch: 5| Step: 9
Training loss: 5.684718195792661
Validation loss: 6.3886575958677945

Epoch: 5| Step: 10
Training loss: 6.712019134857947
Validation loss: 6.375609273667288

Epoch: 11| Step: 0
Training loss: 5.686477736941768
Validation loss: 6.372983156230208

Epoch: 5| Step: 1
Training loss: 6.734235368241375
Validation loss: 6.371979514432861

Epoch: 5| Step: 2
Training loss: 5.9468326504953914
Validation loss: 6.362152308271507

Epoch: 5| Step: 3
Training loss: 7.074938328342765
Validation loss: 6.348038857110553

Epoch: 5| Step: 4
Training loss: 6.774230417833914
Validation loss: 6.342874859923852

Epoch: 5| Step: 5
Training loss: 6.652897093288511
Validation loss: 6.3355346064428995

Epoch: 5| Step: 6
Training loss: 5.173854852292705
Validation loss: 6.32648399564329

Epoch: 5| Step: 7
Training loss: 6.119956294882304
Validation loss: 6.316778298568905

Epoch: 5| Step: 8
Training loss: 4.9285076682189874
Validation loss: 6.3199769303697915

Epoch: 5| Step: 9
Training loss: 7.099453821800033
Validation loss: 6.3033453627985265

Epoch: 5| Step: 10
Training loss: 7.113365445170308
Validation loss: 6.299859314034737

Epoch: 12| Step: 0
Training loss: 6.806813798012294
Validation loss: 6.288752663843148

Epoch: 5| Step: 1
Training loss: 5.978886649811072
Validation loss: 6.288878318124247

Epoch: 5| Step: 2
Training loss: 5.868644360778798
Validation loss: 6.27408636678392

Epoch: 5| Step: 3
Training loss: 6.149728486805396
Validation loss: 6.26998794390432

Epoch: 5| Step: 4
Training loss: 7.474427431562066
Validation loss: 6.254867407396743

Epoch: 5| Step: 5
Training loss: 5.868715536810585
Validation loss: 6.250342909727358

Epoch: 5| Step: 6
Training loss: 6.416858059229215
Validation loss: 6.245889344736893

Epoch: 5| Step: 7
Training loss: 6.8294986416850065
Validation loss: 6.229519785654439

Epoch: 5| Step: 8
Training loss: 5.2056665943145175
Validation loss: 6.227452612075173

Epoch: 5| Step: 9
Training loss: 5.580838951019532
Validation loss: 6.211231280722341

Epoch: 5| Step: 10
Training loss: 6.2405763917423425
Validation loss: 6.211916252271893

Epoch: 13| Step: 0
Training loss: 4.939021009049469
Validation loss: 6.188632497255141

Epoch: 5| Step: 1
Training loss: 6.443062166341847
Validation loss: 6.186246438156801

Epoch: 5| Step: 2
Training loss: 6.500270251011234
Validation loss: 6.180040599900568

Epoch: 5| Step: 3
Training loss: 6.578957403074944
Validation loss: 6.17253755684285

Epoch: 5| Step: 4
Training loss: 6.492238325707337
Validation loss: 6.1715287572112345

Epoch: 5| Step: 5
Training loss: 5.070765776276925
Validation loss: 6.147854871893806

Epoch: 5| Step: 6
Training loss: 6.185152475486722
Validation loss: 6.143810730144326

Epoch: 5| Step: 7
Training loss: 6.962186313870304
Validation loss: 6.126923507476634

Epoch: 5| Step: 8
Training loss: 5.50922417912978
Validation loss: 6.127374988449025

Epoch: 5| Step: 9
Training loss: 6.679710343528191
Validation loss: 6.117225730775587

Epoch: 5| Step: 10
Training loss: 5.929310501437831
Validation loss: 6.105184664269223

Epoch: 14| Step: 0
Training loss: 6.482100857805417
Validation loss: 6.08853870465003

Epoch: 5| Step: 1
Training loss: 6.59625514744653
Validation loss: 6.080105012462828

Epoch: 5| Step: 2
Training loss: 7.054600171196058
Validation loss: 6.072556701786396

Epoch: 5| Step: 3
Training loss: 5.935799445514736
Validation loss: 6.060006694055601

Epoch: 5| Step: 4
Training loss: 5.949180277288602
Validation loss: 6.04632044683339

Epoch: 5| Step: 5
Training loss: 6.789980844911684
Validation loss: 6.035522967183473

Epoch: 5| Step: 6
Training loss: 6.820629344104414
Validation loss: 6.030469708446418

Epoch: 5| Step: 7
Training loss: 5.18843235691337
Validation loss: 6.012926801217373

Epoch: 5| Step: 8
Training loss: 4.7606974156548585
Validation loss: 6.009038447859199

Epoch: 5| Step: 9
Training loss: 4.958952066407159
Validation loss: 5.99047624164513

Epoch: 5| Step: 10
Training loss: 5.279460174823637
Validation loss: 5.97881723813305

Epoch: 15| Step: 0
Training loss: 6.092816873167219
Validation loss: 5.973374936212378

Epoch: 5| Step: 1
Training loss: 5.352234824612785
Validation loss: 5.955816695920315

Epoch: 5| Step: 2
Training loss: 6.54852201370392
Validation loss: 5.9497303030980735

Epoch: 5| Step: 3
Training loss: 5.639263126041941
Validation loss: 5.942753331441634

Epoch: 5| Step: 4
Training loss: 6.720157635520184
Validation loss: 5.925859589202576

Epoch: 5| Step: 5
Training loss: 5.789493766092762
Validation loss: 5.915877207952316

Epoch: 5| Step: 6
Training loss: 5.166519757715086
Validation loss: 5.896802116983682

Epoch: 5| Step: 7
Training loss: 5.782984457935423
Validation loss: 5.889722635571747

Epoch: 5| Step: 8
Training loss: 5.687824617281472
Validation loss: 5.874266296526588

Epoch: 5| Step: 9
Training loss: 6.111715741542625
Validation loss: 5.871283248091866

Epoch: 5| Step: 10
Training loss: 6.028301882286949
Validation loss: 5.857960425474359

Epoch: 16| Step: 0
Training loss: 6.044485798083442
Validation loss: 5.841300492655403

Epoch: 5| Step: 1
Training loss: 6.136264640960043
Validation loss: 5.821934842672955

Epoch: 5| Step: 2
Training loss: 5.883402233782968
Validation loss: 5.81147326397486

Epoch: 5| Step: 3
Training loss: 5.685482799256764
Validation loss: 5.796425496847607

Epoch: 5| Step: 4
Training loss: 6.123753323481091
Validation loss: 5.78234373487338

Epoch: 5| Step: 5
Training loss: 5.645785773758496
Validation loss: 5.777842971843078

Epoch: 5| Step: 6
Training loss: 4.8216006939556
Validation loss: 5.754822758071683

Epoch: 5| Step: 7
Training loss: 6.087932294030479
Validation loss: 5.749516342388003

Epoch: 5| Step: 8
Training loss: 6.020563808159102
Validation loss: 5.727133250413358

Epoch: 5| Step: 9
Training loss: 4.47560458228306
Validation loss: 5.70934640858707

Epoch: 5| Step: 10
Training loss: 6.447630679228799
Validation loss: 5.701400640447241

Epoch: 17| Step: 0
Training loss: 5.465833834654749
Validation loss: 5.688432002520855

Epoch: 5| Step: 1
Training loss: 5.564605314477228
Validation loss: 5.662416226096628

Epoch: 5| Step: 2
Training loss: 5.8596383404364545
Validation loss: 5.658093869110268

Epoch: 5| Step: 3
Training loss: 5.158724474315749
Validation loss: 5.650615250708195

Epoch: 5| Step: 4
Training loss: 5.972655611306375
Validation loss: 5.629665369710025

Epoch: 5| Step: 5
Training loss: 5.720218324029298
Validation loss: 5.61632475205558

Epoch: 5| Step: 6
Training loss: 6.168099554799673
Validation loss: 5.589360668859806

Epoch: 5| Step: 7
Training loss: 5.33080307226441
Validation loss: 5.58126469239634

Epoch: 5| Step: 8
Training loss: 4.4516579871817274
Validation loss: 5.560876557559814

Epoch: 5| Step: 9
Training loss: 6.1250432849833745
Validation loss: 5.552043306149128

Epoch: 5| Step: 10
Training loss: 5.82572498967068
Validation loss: 5.531639043262359

Epoch: 18| Step: 0
Training loss: 5.880369289505297
Validation loss: 5.528483100198567

Epoch: 5| Step: 1
Training loss: 6.37260840939196
Validation loss: 5.500195127812562

Epoch: 5| Step: 2
Training loss: 5.826481564430998
Validation loss: 5.494733647659009

Epoch: 5| Step: 3
Training loss: 4.85107891234203
Validation loss: 5.475300521345713

Epoch: 5| Step: 4
Training loss: 5.052613199769439
Validation loss: 5.453661873083784

Epoch: 5| Step: 5
Training loss: 4.77033118835647
Validation loss: 5.42891979560826

Epoch: 5| Step: 6
Training loss: 4.5288513148675715
Validation loss: 5.423945894222363

Epoch: 5| Step: 7
Training loss: 4.718181045286269
Validation loss: 5.395029250469032

Epoch: 5| Step: 8
Training loss: 6.114042796515817
Validation loss: 5.385229847432361

Epoch: 5| Step: 9
Training loss: 5.555859320071363
Validation loss: 5.373018521965564

Epoch: 5| Step: 10
Training loss: 5.933676040410283
Validation loss: 5.343498158320888

Epoch: 19| Step: 0
Training loss: 5.5175247162791194
Validation loss: 5.334747616590006

Epoch: 5| Step: 1
Training loss: 4.930441531204579
Validation loss: 5.308378466404307

Epoch: 5| Step: 2
Training loss: 5.625500126963539
Validation loss: 5.298603176322688

Epoch: 5| Step: 3
Training loss: 5.360049725202241
Validation loss: 5.284200095946551

Epoch: 5| Step: 4
Training loss: 5.427484342534039
Validation loss: 5.27051182734686

Epoch: 5| Step: 5
Training loss: 4.667503327346539
Validation loss: 5.233607042840132

Epoch: 5| Step: 6
Training loss: 5.897023255021441
Validation loss: 5.2225482557153375

Epoch: 5| Step: 7
Training loss: 5.783457071847624
Validation loss: 5.188952520736759

Epoch: 5| Step: 8
Training loss: 5.265923828339064
Validation loss: 5.186387076246102

Epoch: 5| Step: 9
Training loss: 4.756055084525516
Validation loss: 5.152373607965417

Epoch: 5| Step: 10
Training loss: 4.250328500057194
Validation loss: 5.136950687839961

Epoch: 20| Step: 0
Training loss: 5.502490433472737
Validation loss: 5.124382021802525

Epoch: 5| Step: 1
Training loss: 4.493443268771507
Validation loss: 5.091113483909562

Epoch: 5| Step: 2
Training loss: 5.489111612840258
Validation loss: 5.082006321940703

Epoch: 5| Step: 3
Training loss: 4.2007335113145485
Validation loss: 5.053850878576787

Epoch: 5| Step: 4
Training loss: 6.411832730858304
Validation loss: 5.05217408417043

Epoch: 5| Step: 5
Training loss: 5.821300120695964
Validation loss: 5.012415510775934

Epoch: 5| Step: 6
Training loss: 4.954082793522252
Validation loss: 4.992030889222414

Epoch: 5| Step: 7
Training loss: 4.188730770694191
Validation loss: 4.966791308773557

Epoch: 5| Step: 8
Training loss: 4.864756067164887
Validation loss: 4.951503770029172

Epoch: 5| Step: 9
Training loss: 4.0550240614020785
Validation loss: 4.943120096191025

Epoch: 5| Step: 10
Training loss: 4.995838722478501
Validation loss: 4.911819990500492

Epoch: 21| Step: 0
Training loss: 4.225572960280223
Validation loss: 4.877305807827781

Epoch: 5| Step: 1
Training loss: 4.652384952391543
Validation loss: 4.869754559705269

Epoch: 5| Step: 2
Training loss: 5.891808671692261
Validation loss: 4.864975708454394

Epoch: 5| Step: 3
Training loss: 4.712610558141324
Validation loss: 4.825509135525164

Epoch: 5| Step: 4
Training loss: 4.836175324195497
Validation loss: 4.799652382609864

Epoch: 5| Step: 5
Training loss: 4.514779932482326
Validation loss: 4.780576674205072

Epoch: 5| Step: 6
Training loss: 4.790801437323951
Validation loss: 4.762216917946002

Epoch: 5| Step: 7
Training loss: 4.899970439899576
Validation loss: 4.724250048654031

Epoch: 5| Step: 8
Training loss: 4.88811547972378
Validation loss: 4.7023852494968645

Epoch: 5| Step: 9
Training loss: 3.710875050872567
Validation loss: 4.682215789498048

Epoch: 5| Step: 10
Training loss: 5.727608911685123
Validation loss: 4.693101258062396

Epoch: 22| Step: 0
Training loss: 4.38638067938449
Validation loss: 4.635323505449425

Epoch: 5| Step: 1
Training loss: 4.785988448043381
Validation loss: 4.618271311774853

Epoch: 5| Step: 2
Training loss: 4.545411598696261
Validation loss: 4.59500911785789

Epoch: 5| Step: 3
Training loss: 4.66983916665309
Validation loss: 4.574161592270044

Epoch: 5| Step: 4
Training loss: 3.844081213102138
Validation loss: 4.5545175678584675

Epoch: 5| Step: 5
Training loss: 4.300402050295932
Validation loss: 4.529106235566082

Epoch: 5| Step: 6
Training loss: 5.568398423661751
Validation loss: 4.505492034501832

Epoch: 5| Step: 7
Training loss: 4.709006854920938
Validation loss: 4.482453184737619

Epoch: 5| Step: 8
Training loss: 4.1647557009046485
Validation loss: 4.471128459971568

Epoch: 5| Step: 9
Training loss: 4.774248769094893
Validation loss: 4.435713620318389

Epoch: 5| Step: 10
Training loss: 4.327819152381792
Validation loss: 4.390852584957497

Epoch: 23| Step: 0
Training loss: 5.047973891104572
Validation loss: 4.357235356998121

Epoch: 5| Step: 1
Training loss: 4.593706610857483
Validation loss: 4.341354865374379

Epoch: 5| Step: 2
Training loss: 3.8355194299051822
Validation loss: 4.349781833449355

Epoch: 5| Step: 3
Training loss: 4.944438646196449
Validation loss: 4.305729186894464

Epoch: 5| Step: 4
Training loss: 4.560842970848298
Validation loss: 4.276479006565216

Epoch: 5| Step: 5
Training loss: 3.4659069885611378
Validation loss: 4.2694804059812315

Epoch: 5| Step: 6
Training loss: 3.3251036778398038
Validation loss: 4.204614605495846

Epoch: 5| Step: 7
Training loss: 3.6328237882049086
Validation loss: 4.207303678531798

Epoch: 5| Step: 8
Training loss: 5.007631962180562
Validation loss: 4.170454107066258

Epoch: 5| Step: 9
Training loss: 4.484709085919302
Validation loss: 4.142226104841749

Epoch: 5| Step: 10
Training loss: 4.013414301345931
Validation loss: 4.126445985426851

Epoch: 24| Step: 0
Training loss: 3.436829241420088
Validation loss: 4.102151422913519

Epoch: 5| Step: 1
Training loss: 4.339899565769558
Validation loss: 4.063147374169436

Epoch: 5| Step: 2
Training loss: 3.935446794245466
Validation loss: 4.032190564031541

Epoch: 5| Step: 3
Training loss: 3.4800649766227227
Validation loss: 4.009641796483097

Epoch: 5| Step: 4
Training loss: 4.880731197046429
Validation loss: 3.981251171537718

Epoch: 5| Step: 5
Training loss: 4.593152065677502
Validation loss: 3.979211340659204

Epoch: 5| Step: 6
Training loss: 3.886261112740801
Validation loss: 3.933083013477815

Epoch: 5| Step: 7
Training loss: 3.619741637984241
Validation loss: 3.8992105682090163

Epoch: 5| Step: 8
Training loss: 3.1651672695126463
Validation loss: 3.8937955331254352

Epoch: 5| Step: 9
Training loss: 4.948827762710638
Validation loss: 3.8602281198535535

Epoch: 5| Step: 10
Training loss: 3.8715562592253736
Validation loss: 3.8415673801485695

Epoch: 25| Step: 0
Training loss: 3.386605829558528
Validation loss: 3.8116329813687284

Epoch: 5| Step: 1
Training loss: 3.6421080094168405
Validation loss: 3.773689208801684

Epoch: 5| Step: 2
Training loss: 4.532219723821871
Validation loss: 3.7646518941398717

Epoch: 5| Step: 3
Training loss: 4.00839163776801
Validation loss: 3.746270148103733

Epoch: 5| Step: 4
Training loss: 3.3290392555679342
Validation loss: 3.7012390094265633

Epoch: 5| Step: 5
Training loss: 3.396887835888093
Validation loss: 3.7071921590717007

Epoch: 5| Step: 6
Training loss: 3.3053751200806607
Validation loss: 3.65674722938484

Epoch: 5| Step: 7
Training loss: 4.199259629161487
Validation loss: 3.6487788261419842

Epoch: 5| Step: 8
Training loss: 4.099074068418841
Validation loss: 3.625583088350851

Epoch: 5| Step: 9
Training loss: 3.8566242252829173
Validation loss: 3.6037554449704055

Epoch: 5| Step: 10
Training loss: 3.57902881917891
Validation loss: 3.5575307872210438

Epoch: 26| Step: 0
Training loss: 4.358722378134827
Validation loss: 3.5322026622857177

Epoch: 5| Step: 1
Training loss: 2.7914055564574163
Validation loss: 3.5307282470638803

Epoch: 5| Step: 2
Training loss: 4.8454832852061225
Validation loss: 3.4843920326487985

Epoch: 5| Step: 3
Training loss: 2.8979004724865036
Validation loss: 3.4648151726938528

Epoch: 5| Step: 4
Training loss: 3.1805442761735288
Validation loss: 3.4352162908946995

Epoch: 5| Step: 5
Training loss: 3.861242298181521
Validation loss: 3.418352183034034

Epoch: 5| Step: 6
Training loss: 2.7240715124907373
Validation loss: 3.3829763568361906

Epoch: 5| Step: 7
Training loss: 3.6331135942932042
Validation loss: 3.3639002982002615

Epoch: 5| Step: 8
Training loss: 3.6484063941560767
Validation loss: 3.3136561847331687

Epoch: 5| Step: 9
Training loss: 3.320222453972002
Validation loss: 3.352389396289247

Epoch: 5| Step: 10
Training loss: 3.3015704955091305
Validation loss: 3.314000349276249

Epoch: 27| Step: 0
Training loss: 3.470748463142954
Validation loss: 3.2546825264181694

Epoch: 5| Step: 1
Training loss: 3.264441900997442
Validation loss: 3.2188913322471917

Epoch: 5| Step: 2
Training loss: 2.892263412097608
Validation loss: 3.248525113674573

Epoch: 5| Step: 3
Training loss: 3.068661622058679
Validation loss: 3.235667461048271

Epoch: 5| Step: 4
Training loss: 3.183296873140164
Validation loss: 3.1751859155569555

Epoch: 5| Step: 5
Training loss: 3.798662557646793
Validation loss: 3.1605175517600026

Epoch: 5| Step: 6
Training loss: 3.3145931036753407
Validation loss: 3.1327726034114196

Epoch: 5| Step: 7
Training loss: 3.4781408263306544
Validation loss: 3.157121781398424

Epoch: 5| Step: 8
Training loss: 2.648013280691167
Validation loss: 3.1175664452994107

Epoch: 5| Step: 9
Training loss: 4.629106296771713
Validation loss: 3.1154533737951735

Epoch: 5| Step: 10
Training loss: 2.736507173026616
Validation loss: 3.1054752914494994

Epoch: 28| Step: 0
Training loss: 3.3319217713092413
Validation loss: 3.1004501980463446

Epoch: 5| Step: 1
Training loss: 3.015615196409745
Validation loss: 3.054624015258144

Epoch: 5| Step: 2
Training loss: 3.167982597650068
Validation loss: 3.0383341816743297

Epoch: 5| Step: 3
Training loss: 3.201010550436588
Validation loss: 3.0306642163185664

Epoch: 5| Step: 4
Training loss: 3.409937271480895
Validation loss: 3.0341642338645993

Epoch: 5| Step: 5
Training loss: 2.696537347654833
Validation loss: 2.9817762966010126

Epoch: 5| Step: 6
Training loss: 2.628826712642223
Validation loss: 3.008758543595525

Epoch: 5| Step: 7
Training loss: 3.800727428278674
Validation loss: 2.9903849042776693

Epoch: 5| Step: 8
Training loss: 2.902388601867855
Validation loss: 2.9675923420285946

Epoch: 5| Step: 9
Training loss: 3.971356594731157
Validation loss: 2.9428332012725824

Epoch: 5| Step: 10
Training loss: 3.3956778711099354
Validation loss: 2.9090070187573427

Epoch: 29| Step: 0
Training loss: 3.0568070728941983
Validation loss: 2.9283048460120895

Epoch: 5| Step: 1
Training loss: 3.3288175193708813
Validation loss: 2.9084484294646775

Epoch: 5| Step: 2
Training loss: 3.486738284477474
Validation loss: 2.90265828143589

Epoch: 5| Step: 3
Training loss: 3.296963658880843
Validation loss: 2.909579872522531

Epoch: 5| Step: 4
Training loss: 3.1939363010960293
Validation loss: 2.891735532509822

Epoch: 5| Step: 5
Training loss: 3.00085723073636
Validation loss: 2.8789357162024856

Epoch: 5| Step: 6
Training loss: 2.6913675380187168
Validation loss: 2.8917327576367575

Epoch: 5| Step: 7
Training loss: 3.26016991669793
Validation loss: 2.8770151134064075

Epoch: 5| Step: 8
Training loss: 3.589084150542148
Validation loss: 2.8394505433849857

Epoch: 5| Step: 9
Training loss: 2.128031531702633
Validation loss: 2.8389935828686017

Epoch: 5| Step: 10
Training loss: 3.303555919360426
Validation loss: 2.889101301220506

Epoch: 30| Step: 0
Training loss: 3.4212446633779194
Validation loss: 2.8585565539827615

Epoch: 5| Step: 1
Training loss: 3.590398668770365
Validation loss: 2.8415314915010113

Epoch: 5| Step: 2
Training loss: 2.8819029492272374
Validation loss: 2.8415260710551444

Epoch: 5| Step: 3
Training loss: 2.881469579178302
Validation loss: 2.8197064037487847

Epoch: 5| Step: 4
Training loss: 3.3518147406993184
Validation loss: 2.8318593632661124

Epoch: 5| Step: 5
Training loss: 3.255233805238883
Validation loss: 2.839894942120285

Epoch: 5| Step: 6
Training loss: 3.2814787285420612
Validation loss: 2.791879498580541

Epoch: 5| Step: 7
Training loss: 2.727567995589247
Validation loss: 2.7931333642946785

Epoch: 5| Step: 8
Training loss: 3.275619034829956
Validation loss: 2.803090226404969

Epoch: 5| Step: 9
Training loss: 2.329636460787114
Validation loss: 2.7820641023350845

Epoch: 5| Step: 10
Training loss: 3.2340496102268887
Validation loss: 2.784947658231135

Epoch: 31| Step: 0
Training loss: 2.7522594533198848
Validation loss: 2.748127489051594

Epoch: 5| Step: 1
Training loss: 3.0693547354161086
Validation loss: 2.7814021320682447

Epoch: 5| Step: 2
Training loss: 2.335680689138867
Validation loss: 2.772543216201586

Epoch: 5| Step: 3
Training loss: 2.6900294620644774
Validation loss: 2.7569683235062623

Epoch: 5| Step: 4
Training loss: 2.9522096537338958
Validation loss: 2.7669530902873283

Epoch: 5| Step: 5
Training loss: 2.7848651835548828
Validation loss: 2.749781192490881

Epoch: 5| Step: 6
Training loss: 3.2406667061074397
Validation loss: 2.7822444898795244

Epoch: 5| Step: 7
Training loss: 3.244578020257953
Validation loss: 2.7444592383727193

Epoch: 5| Step: 8
Training loss: 3.136383380752355
Validation loss: 2.7474923376667215

Epoch: 5| Step: 9
Training loss: 3.0725875074745823
Validation loss: 2.782650826962763

Epoch: 5| Step: 10
Training loss: 4.287399664502798
Validation loss: 2.737889954980935

Epoch: 32| Step: 0
Training loss: 3.1291913725330156
Validation loss: 2.7682622366712346

Epoch: 5| Step: 1
Training loss: 2.653473783286978
Validation loss: 2.745228846857828

Epoch: 5| Step: 2
Training loss: 3.032460236567785
Validation loss: 2.7486406427011296

Epoch: 5| Step: 3
Training loss: 3.515054071479875
Validation loss: 2.730719735885765

Epoch: 5| Step: 4
Training loss: 2.530453968858786
Validation loss: 2.728514228793607

Epoch: 5| Step: 5
Training loss: 2.791589441702155
Validation loss: 2.746764658933522

Epoch: 5| Step: 6
Training loss: 2.398388691259524
Validation loss: 2.733264990546691

Epoch: 5| Step: 7
Training loss: 3.063472515537652
Validation loss: 2.7607562196234516

Epoch: 5| Step: 8
Training loss: 3.5959532245143997
Validation loss: 2.7320180524745705

Epoch: 5| Step: 9
Training loss: 3.0342650215812403
Validation loss: 2.7564731550256045

Epoch: 5| Step: 10
Training loss: 3.889632868370485
Validation loss: 2.73963788565925

Epoch: 33| Step: 0
Training loss: 2.7726740256368774
Validation loss: 2.7361949464799595

Epoch: 5| Step: 1
Training loss: 3.31365442852629
Validation loss: 2.7171847399491833

Epoch: 5| Step: 2
Training loss: 2.94984245526168
Validation loss: 2.7494122519409623

Epoch: 5| Step: 3
Training loss: 3.092935782514849
Validation loss: 2.733883676291579

Epoch: 5| Step: 4
Training loss: 3.4093641691796344
Validation loss: 2.7496697291841246

Epoch: 5| Step: 5
Training loss: 2.514459565115743
Validation loss: 2.7070397694712347

Epoch: 5| Step: 6
Training loss: 2.9625280129440172
Validation loss: 2.7544061799721287

Epoch: 5| Step: 7
Training loss: 3.122851434237989
Validation loss: 2.751271735950435

Epoch: 5| Step: 8
Training loss: 3.163674714614342
Validation loss: 2.7337649929211794

Epoch: 5| Step: 9
Training loss: 2.9063755131352265
Validation loss: 2.761589678389308

Epoch: 5| Step: 10
Training loss: 3.3170954658725025
Validation loss: 2.7318381969040524

Epoch: 34| Step: 0
Training loss: 3.093902430006306
Validation loss: 2.7428320002361803

Epoch: 5| Step: 1
Training loss: 3.3437126371488777
Validation loss: 2.7104534319734968

Epoch: 5| Step: 2
Training loss: 2.4540893214353483
Validation loss: 2.699088598744346

Epoch: 5| Step: 3
Training loss: 3.381786587316793
Validation loss: 2.7080321631195385

Epoch: 5| Step: 4
Training loss: 3.484235410075253
Validation loss: 2.6904132084456926

Epoch: 5| Step: 5
Training loss: 2.848674157921157
Validation loss: 2.721778104559771

Epoch: 5| Step: 6
Training loss: 2.512357686885087
Validation loss: 2.706425162304465

Epoch: 5| Step: 7
Training loss: 3.890463829532274
Validation loss: 2.726554699704524

Epoch: 5| Step: 8
Training loss: 2.9970902000704616
Validation loss: 2.7204236499212486

Epoch: 5| Step: 9
Training loss: 2.6617443928828353
Validation loss: 2.729996361041725

Epoch: 5| Step: 10
Training loss: 2.8413617512131966
Validation loss: 2.718440225728173

Epoch: 35| Step: 0
Training loss: 3.3782407954269935
Validation loss: 2.695988300925548

Epoch: 5| Step: 1
Training loss: 3.0199238076609065
Validation loss: 2.717952644821959

Epoch: 5| Step: 2
Training loss: 3.76279251127539
Validation loss: 2.7252021656605816

Epoch: 5| Step: 3
Training loss: 3.0697761824344294
Validation loss: 2.718573202764469

Epoch: 5| Step: 4
Training loss: 3.3999408772881883
Validation loss: 2.7112287058975273

Epoch: 5| Step: 5
Training loss: 2.7600388658247255
Validation loss: 2.7059475546506873

Epoch: 5| Step: 6
Training loss: 2.887324412898527
Validation loss: 2.75091159884263

Epoch: 5| Step: 7
Training loss: 3.0674439053431373
Validation loss: 2.7195949860850854

Epoch: 5| Step: 8
Training loss: 3.1203615477961595
Validation loss: 2.721541946997033

Epoch: 5| Step: 9
Training loss: 2.3498444728925034
Validation loss: 2.7108125179387588

Epoch: 5| Step: 10
Training loss: 2.7796218907213257
Validation loss: 2.7106118858497763

Epoch: 36| Step: 0
Training loss: 4.3065044355592175
Validation loss: 2.690497285918147

Epoch: 5| Step: 1
Training loss: 2.8366249449276926
Validation loss: 2.7061780353746223

Epoch: 5| Step: 2
Training loss: 2.8696587745834776
Validation loss: 2.6999528167883002

Epoch: 5| Step: 3
Training loss: 2.6618762400495046
Validation loss: 2.734015052648531

Epoch: 5| Step: 4
Training loss: 2.5987950173681194
Validation loss: 2.701723197977716

Epoch: 5| Step: 5
Training loss: 2.628562870811369
Validation loss: 2.722012732841814

Epoch: 5| Step: 6
Training loss: 2.9701077217577843
Validation loss: 2.6957973458486304

Epoch: 5| Step: 7
Training loss: 3.1420623374985817
Validation loss: 2.7431461769075556

Epoch: 5| Step: 8
Training loss: 2.9773356717594917
Validation loss: 2.7411826618537627

Epoch: 5| Step: 9
Training loss: 3.397769836084956
Validation loss: 2.7109489103784425

Epoch: 5| Step: 10
Training loss: 3.0259100687867058
Validation loss: 2.6841539432709407

Epoch: 37| Step: 0
Training loss: 3.214557472729862
Validation loss: 2.740889271483111

Epoch: 5| Step: 1
Training loss: 3.8122322113544675
Validation loss: 2.7198427837926187

Epoch: 5| Step: 2
Training loss: 2.92209367392782
Validation loss: 2.7552336358171408

Epoch: 5| Step: 3
Training loss: 2.5739406962287683
Validation loss: 2.733078006598807

Epoch: 5| Step: 4
Training loss: 3.287608062940699
Validation loss: 2.686493523205208

Epoch: 5| Step: 5
Training loss: 3.012640390250997
Validation loss: 2.709065523084137

Epoch: 5| Step: 6
Training loss: 3.006565539004934
Validation loss: 2.7480491717878257

Epoch: 5| Step: 7
Training loss: 2.617463236844814
Validation loss: 2.6970212261831668

Epoch: 5| Step: 8
Training loss: 2.994104951271501
Validation loss: 2.729606608144847

Epoch: 5| Step: 9
Training loss: 3.199024683617118
Validation loss: 2.704816600133842

Epoch: 5| Step: 10
Training loss: 2.5008131612108
Validation loss: 2.7557641128716726

Epoch: 38| Step: 0
Training loss: 3.239373808501207
Validation loss: 2.6911295472589245

Epoch: 5| Step: 1
Training loss: 3.2250761806746184
Validation loss: 2.730178362433935

Epoch: 5| Step: 2
Training loss: 2.5456275927565324
Validation loss: 2.721629333165689

Epoch: 5| Step: 3
Training loss: 2.8299261438013037
Validation loss: 2.704986456749804

Epoch: 5| Step: 4
Training loss: 2.7933159032230805
Validation loss: 2.7100686656318764

Epoch: 5| Step: 5
Training loss: 2.8200090831583253
Validation loss: 2.7214559333583828

Epoch: 5| Step: 6
Training loss: 3.5572391951094806
Validation loss: 2.712380084785855

Epoch: 5| Step: 7
Training loss: 3.1750669156930247
Validation loss: 2.749903018095252

Epoch: 5| Step: 8
Training loss: 2.7855935629512287
Validation loss: 2.740603258314202

Epoch: 5| Step: 9
Training loss: 3.161913332596509
Validation loss: 2.733999040719248

Epoch: 5| Step: 10
Training loss: 3.1932847133856055
Validation loss: 2.7213049135472542

Epoch: 39| Step: 0
Training loss: 2.614255623714997
Validation loss: 2.704240052920149

Epoch: 5| Step: 1
Training loss: 3.572527375807093
Validation loss: 2.7091114437789536

Epoch: 5| Step: 2
Training loss: 2.978637772853987
Validation loss: 2.7589964048814477

Epoch: 5| Step: 3
Training loss: 2.3332743183120646
Validation loss: 2.7104260735696415

Epoch: 5| Step: 4
Training loss: 3.387269218438167
Validation loss: 2.6957990252730717

Epoch: 5| Step: 5
Training loss: 2.6667056577534
Validation loss: 2.7058749934729156

Epoch: 5| Step: 6
Training loss: 3.302912530769334
Validation loss: 2.7043245930373736

Epoch: 5| Step: 7
Training loss: 2.6896569223971625
Validation loss: 2.694023538668333

Epoch: 5| Step: 8
Training loss: 3.7727795771705295
Validation loss: 2.7269553536655744

Epoch: 5| Step: 9
Training loss: 3.067292336893936
Validation loss: 2.705733109469069

Epoch: 5| Step: 10
Training loss: 2.6153622767629345
Validation loss: 2.7467555197410602

Epoch: 40| Step: 0
Training loss: 3.120977635903307
Validation loss: 2.7050146425749455

Epoch: 5| Step: 1
Training loss: 3.059143874387352
Validation loss: 2.6968919822055426

Epoch: 5| Step: 2
Training loss: 3.1026059180414802
Validation loss: 2.682574758256802

Epoch: 5| Step: 3
Training loss: 3.1258218828881597
Validation loss: 2.7192563877310105

Epoch: 5| Step: 4
Training loss: 2.2608440598672677
Validation loss: 2.6932787055580922

Epoch: 5| Step: 5
Training loss: 3.771983749225193
Validation loss: 2.640682811314173

Epoch: 5| Step: 6
Training loss: 2.4815149699060695
Validation loss: 2.6898474070098084

Epoch: 5| Step: 7
Training loss: 2.734990426697095
Validation loss: 2.7101299665602654

Epoch: 5| Step: 8
Training loss: 3.2870220460584707
Validation loss: 2.749232543063631

Epoch: 5| Step: 9
Training loss: 2.5393118867910727
Validation loss: 2.7317890339579223

Epoch: 5| Step: 10
Training loss: 3.807989109656846
Validation loss: 2.6640792113360297

Epoch: 41| Step: 0
Training loss: 3.0337947899679567
Validation loss: 2.7401927190862048

Epoch: 5| Step: 1
Training loss: 2.9841219010804187
Validation loss: 2.747117823617261

Epoch: 5| Step: 2
Training loss: 3.1245669255578505
Validation loss: 2.6922361971117965

Epoch: 5| Step: 3
Training loss: 2.779848324185126
Validation loss: 2.7179129932440094

Epoch: 5| Step: 4
Training loss: 3.205122459797723
Validation loss: 2.7198923672050044

Epoch: 5| Step: 5
Training loss: 2.8939325328626344
Validation loss: 2.7371480645403685

Epoch: 5| Step: 6
Training loss: 3.117588715319611
Validation loss: 2.7182809691279832

Epoch: 5| Step: 7
Training loss: 3.262487921564537
Validation loss: 2.733301712087578

Epoch: 5| Step: 8
Training loss: 3.151990679286595
Validation loss: 2.6965293278798583

Epoch: 5| Step: 9
Training loss: 2.889713947962636
Validation loss: 2.6756989391778685

Epoch: 5| Step: 10
Training loss: 3.0540861430531807
Validation loss: 2.661166034877582

Epoch: 42| Step: 0
Training loss: 3.3127041160026147
Validation loss: 2.691469079938735

Epoch: 5| Step: 1
Training loss: 3.215915802465507
Validation loss: 2.703467145476541

Epoch: 5| Step: 2
Training loss: 3.3802356375995806
Validation loss: 2.6989020767061054

Epoch: 5| Step: 3
Training loss: 3.0462423597012247
Validation loss: 2.695708293011642

Epoch: 5| Step: 4
Training loss: 3.330784124895775
Validation loss: 2.7324335165351283

Epoch: 5| Step: 5
Training loss: 2.622241796359409
Validation loss: 2.6984272217712304

Epoch: 5| Step: 6
Training loss: 2.9985192141150256
Validation loss: 2.7184446797767436

Epoch: 5| Step: 7
Training loss: 3.437163180409066
Validation loss: 2.6965373704720124

Epoch: 5| Step: 8
Training loss: 2.6037666216982225
Validation loss: 2.75012065906148

Epoch: 5| Step: 9
Training loss: 2.726552181716239
Validation loss: 2.7061559061549283

Epoch: 5| Step: 10
Training loss: 2.853540690662497
Validation loss: 2.7324724357559784

Epoch: 43| Step: 0
Training loss: 3.3682284770677997
Validation loss: 2.701354816251167

Epoch: 5| Step: 1
Training loss: 2.416601530929241
Validation loss: 2.6838596497241154

Epoch: 5| Step: 2
Training loss: 3.575457649015346
Validation loss: 2.700768485821286

Epoch: 5| Step: 3
Training loss: 3.4900122231867847
Validation loss: 2.742029568411009

Epoch: 5| Step: 4
Training loss: 2.634062880446895
Validation loss: 2.7145431280108

Epoch: 5| Step: 5
Training loss: 3.312139527482458
Validation loss: 2.7188929943461817

Epoch: 5| Step: 6
Training loss: 3.201159660497594
Validation loss: 2.6904726760693722

Epoch: 5| Step: 7
Training loss: 2.8688058885104355
Validation loss: 2.702428835865617

Epoch: 5| Step: 8
Training loss: 2.6139047560264856
Validation loss: 2.6980244902473616

Epoch: 5| Step: 9
Training loss: 3.0819546650121157
Validation loss: 2.702859144090526

Epoch: 5| Step: 10
Training loss: 2.6941702813563673
Validation loss: 2.7007040259377058

Epoch: 44| Step: 0
Training loss: 2.469648077137398
Validation loss: 2.7078246977634275

Epoch: 5| Step: 1
Training loss: 4.063040359946322
Validation loss: 2.714816380596917

Epoch: 5| Step: 2
Training loss: 2.9262002357185066
Validation loss: 2.6855940731968686

Epoch: 5| Step: 3
Training loss: 2.457046290413773
Validation loss: 2.742679826258435

Epoch: 5| Step: 4
Training loss: 2.602942939610643
Validation loss: 2.6834169093024416

Epoch: 5| Step: 5
Training loss: 3.0990398150505514
Validation loss: 2.6940396863696967

Epoch: 5| Step: 6
Training loss: 3.1070299362935683
Validation loss: 2.666617558075833

Epoch: 5| Step: 7
Training loss: 2.351639553087693
Validation loss: 2.732586396212869

Epoch: 5| Step: 8
Training loss: 3.109823223376508
Validation loss: 2.717293189299412

Epoch: 5| Step: 9
Training loss: 3.4336151365410466
Validation loss: 2.7109826627267815

Epoch: 5| Step: 10
Training loss: 3.5731897425862282
Validation loss: 2.6859173962002973

Epoch: 45| Step: 0
Training loss: 3.3269146791507342
Validation loss: 2.6483160522194904

Epoch: 5| Step: 1
Training loss: 2.890500947507034
Validation loss: 2.6857545168077923

Epoch: 5| Step: 2
Training loss: 2.936293171467412
Validation loss: 2.7318397668980423

Epoch: 5| Step: 3
Training loss: 3.101941294564079
Validation loss: 2.709515581593782

Epoch: 5| Step: 4
Training loss: 3.3044358466534702
Validation loss: 2.6586999740710375

Epoch: 5| Step: 5
Training loss: 2.8692167413533443
Validation loss: 2.6707690476573616

Epoch: 5| Step: 6
Training loss: 3.192185193629092
Validation loss: 2.768729563539759

Epoch: 5| Step: 7
Training loss: 2.918484602630868
Validation loss: 2.659013711543832

Epoch: 5| Step: 8
Training loss: 3.387044395973488
Validation loss: 2.685621734202257

Epoch: 5| Step: 9
Training loss: 2.9829823704862615
Validation loss: 2.713770497599594

Epoch: 5| Step: 10
Training loss: 2.1955514146574426
Validation loss: 2.6824027350982034

Epoch: 46| Step: 0
Training loss: 2.5519910107995405
Validation loss: 2.669161380151488

Epoch: 5| Step: 1
Training loss: 2.031345541247667
Validation loss: 2.6978664478248326

Epoch: 5| Step: 2
Training loss: 3.271041539524666
Validation loss: 2.705826198236323

Epoch: 5| Step: 3
Training loss: 3.188412554391981
Validation loss: 2.737479671879094

Epoch: 5| Step: 4
Training loss: 3.4673863385307793
Validation loss: 2.649713619520497

Epoch: 5| Step: 5
Training loss: 3.119103629144248
Validation loss: 2.6920723125377317

Epoch: 5| Step: 6
Training loss: 3.4705230030725853
Validation loss: 2.7180849628506953

Epoch: 5| Step: 7
Training loss: 2.4374786767271446
Validation loss: 2.706056172031629

Epoch: 5| Step: 8
Training loss: 3.6425891211295154
Validation loss: 2.7005265997732546

Epoch: 5| Step: 9
Training loss: 2.076459059137377
Validation loss: 2.6602104855724167

Epoch: 5| Step: 10
Training loss: 3.286660375092567
Validation loss: 2.73753936352694

Epoch: 47| Step: 0
Training loss: 3.4872132104793647
Validation loss: 2.6984097521962798

Epoch: 5| Step: 1
Training loss: 3.4541987480143193
Validation loss: 2.701666300929603

Epoch: 5| Step: 2
Training loss: 2.703906965985847
Validation loss: 2.686557490036082

Epoch: 5| Step: 3
Training loss: 2.9368262634325024
Validation loss: 2.7255557163907906

Epoch: 5| Step: 4
Training loss: 3.082827930440824
Validation loss: 2.685169031375676

Epoch: 5| Step: 5
Training loss: 2.8867889519648013
Validation loss: 2.703937720127698

Epoch: 5| Step: 6
Training loss: 2.9835753642812013
Validation loss: 2.6992244291518115

Epoch: 5| Step: 7
Training loss: 2.9907168765888033
Validation loss: 2.710216050198347

Epoch: 5| Step: 8
Training loss: 2.969782920636309
Validation loss: 2.6865646745555303

Epoch: 5| Step: 9
Training loss: 3.229899678045251
Validation loss: 2.698430905112356

Epoch: 5| Step: 10
Training loss: 2.482025667111629
Validation loss: 2.680949871157562

Epoch: 48| Step: 0
Training loss: 3.475526805437901
Validation loss: 2.6978830875561153

Epoch: 5| Step: 1
Training loss: 2.2355736138482603
Validation loss: 2.688807149330751

Epoch: 5| Step: 2
Training loss: 2.6326487685550117
Validation loss: 2.7044761505898114

Epoch: 5| Step: 3
Training loss: 2.927694308952833
Validation loss: 2.716949790979476

Epoch: 5| Step: 4
Training loss: 3.025544765380168
Validation loss: 2.7144035019577086

Epoch: 5| Step: 5
Training loss: 3.480500671719844
Validation loss: 2.6755339784069774

Epoch: 5| Step: 6
Training loss: 3.558937299038342
Validation loss: 2.6859992726694206

Epoch: 5| Step: 7
Training loss: 2.4861138933996143
Validation loss: 2.6739282217989677

Epoch: 5| Step: 8
Training loss: 2.0951251168775324
Validation loss: 2.6691519944543467

Epoch: 5| Step: 9
Training loss: 3.602436480944968
Validation loss: 2.6948906538508663

Epoch: 5| Step: 10
Training loss: 3.259973774201855
Validation loss: 2.6738256484433487

Epoch: 49| Step: 0
Training loss: 3.2572785083946996
Validation loss: 2.6900225393486483

Epoch: 5| Step: 1
Training loss: 3.2262265674755484
Validation loss: 2.6916644042234883

Epoch: 5| Step: 2
Training loss: 3.1120638315768976
Validation loss: 2.6807371798436077

Epoch: 5| Step: 3
Training loss: 2.985823514430512
Validation loss: 2.7095294655391484

Epoch: 5| Step: 4
Training loss: 3.101282371342822
Validation loss: 2.7137141280482195

Epoch: 5| Step: 5
Training loss: 2.861590584965703
Validation loss: 2.6878974946831704

Epoch: 5| Step: 6
Training loss: 3.2510273116720803
Validation loss: 2.6535180613464755

Epoch: 5| Step: 7
Training loss: 2.934411880862646
Validation loss: 2.721877166064144

Epoch: 5| Step: 8
Training loss: 2.7200015464946614
Validation loss: 2.716495552791546

Epoch: 5| Step: 9
Training loss: 3.280205987416835
Validation loss: 2.664520256100663

Epoch: 5| Step: 10
Training loss: 2.7372950194096566
Validation loss: 2.705785508653738

Epoch: 50| Step: 0
Training loss: 2.7640871416700317
Validation loss: 2.680127262311224

Epoch: 5| Step: 1
Training loss: 3.096770382373782
Validation loss: 2.691297702447989

Epoch: 5| Step: 2
Training loss: 2.581917764590718
Validation loss: 2.6967162322073195

Epoch: 5| Step: 3
Training loss: 3.1254951084838924
Validation loss: 2.6811985221181853

Epoch: 5| Step: 4
Training loss: 3.0175714881601774
Validation loss: 2.7003502233506893

Epoch: 5| Step: 5
Training loss: 2.693225351032266
Validation loss: 2.6745841374580817

Epoch: 5| Step: 6
Training loss: 2.9396245862056447
Validation loss: 2.6540930853709632

Epoch: 5| Step: 7
Training loss: 3.541074606082838
Validation loss: 2.709383473344789

Epoch: 5| Step: 8
Training loss: 3.1829485842153185
Validation loss: 2.7133919385220886

Epoch: 5| Step: 9
Training loss: 3.0420726000106164
Validation loss: 2.6699422540611644

Epoch: 5| Step: 10
Training loss: 3.160173451455811
Validation loss: 2.691797851618704

Epoch: 51| Step: 0
Training loss: 2.9683545300945786
Validation loss: 2.673167784941379

Epoch: 5| Step: 1
Training loss: 2.7638119719349463
Validation loss: 2.732735032655579

Epoch: 5| Step: 2
Training loss: 2.9321685458004363
Validation loss: 2.690459876286315

Epoch: 5| Step: 3
Training loss: 3.165497179077415
Validation loss: 2.689079181281699

Epoch: 5| Step: 4
Training loss: 3.271074776130934
Validation loss: 2.710004416555511

Epoch: 5| Step: 5
Training loss: 2.7128647871002305
Validation loss: 2.6503607323508795

Epoch: 5| Step: 6
Training loss: 3.6634697993936483
Validation loss: 2.700177351164158

Epoch: 5| Step: 7
Training loss: 2.686765082365521
Validation loss: 2.677456959260076

Epoch: 5| Step: 8
Training loss: 3.1771231393457064
Validation loss: 2.6490082963748924

Epoch: 5| Step: 9
Training loss: 2.716853302315473
Validation loss: 2.667189039959712

Epoch: 5| Step: 10
Training loss: 2.789858749806533
Validation loss: 2.7480170473694643

Epoch: 52| Step: 0
Training loss: 3.3369536449126618
Validation loss: 2.669772299606348

Epoch: 5| Step: 1
Training loss: 2.850125052402272
Validation loss: 2.6567513385459547

Epoch: 5| Step: 2
Training loss: 2.954856405367742
Validation loss: 2.6809524750070914

Epoch: 5| Step: 3
Training loss: 2.937328090101432
Validation loss: 2.6971842739795617

Epoch: 5| Step: 4
Training loss: 2.3682839652313494
Validation loss: 2.726381233269263

Epoch: 5| Step: 5
Training loss: 3.4058318275154007
Validation loss: 2.6969404913670383

Epoch: 5| Step: 6
Training loss: 3.3545612711226944
Validation loss: 2.7170910741621843

Epoch: 5| Step: 7
Training loss: 2.6640204373168563
Validation loss: 2.7194543759851446

Epoch: 5| Step: 8
Training loss: 3.4385020789489187
Validation loss: 2.722909018029577

Epoch: 5| Step: 9
Training loss: 3.183332374000072
Validation loss: 2.6899981648428613

Epoch: 5| Step: 10
Training loss: 2.1460906926852994
Validation loss: 2.698799904429326

Epoch: 53| Step: 0
Training loss: 3.1670073944959447
Validation loss: 2.6884820912716947

Epoch: 5| Step: 1
Training loss: 2.922318531990822
Validation loss: 2.715472668352341

Epoch: 5| Step: 2
Training loss: 3.909205180992004
Validation loss: 2.6720032233315245

Epoch: 5| Step: 3
Training loss: 2.6622155910693106
Validation loss: 2.6806695050559135

Epoch: 5| Step: 4
Training loss: 2.9879905010720953
Validation loss: 2.696007992285628

Epoch: 5| Step: 5
Training loss: 3.1672308235235302
Validation loss: 2.6599664158242655

Epoch: 5| Step: 6
Training loss: 2.289803550989478
Validation loss: 2.711810655188917

Epoch: 5| Step: 7
Training loss: 2.7940277439452075
Validation loss: 2.6899414925007537

Epoch: 5| Step: 8
Training loss: 3.3507212759117486
Validation loss: 2.6955177441802984

Epoch: 5| Step: 9
Training loss: 2.5978645872164283
Validation loss: 2.688495101671991

Epoch: 5| Step: 10
Training loss: 3.0362425913431768
Validation loss: 2.7023212528464216

Epoch: 54| Step: 0
Training loss: 2.928780132925072
Validation loss: 2.6530668716810366

Epoch: 5| Step: 1
Training loss: 2.597684702323033
Validation loss: 2.678378766158337

Epoch: 5| Step: 2
Training loss: 2.893856737050954
Validation loss: 2.702092290388704

Epoch: 5| Step: 3
Training loss: 2.9425511861155713
Validation loss: 2.6679490717372047

Epoch: 5| Step: 4
Training loss: 3.7190614457702296
Validation loss: 2.6863386330570833

Epoch: 5| Step: 5
Training loss: 3.475140981764574
Validation loss: 2.679618406677126

Epoch: 5| Step: 6
Training loss: 2.6900486061781623
Validation loss: 2.6844179791992238

Epoch: 5| Step: 7
Training loss: 2.69389735126414
Validation loss: 2.682260100747129

Epoch: 5| Step: 8
Training loss: 2.9760009556327844
Validation loss: 2.6568826355149726

Epoch: 5| Step: 9
Training loss: 3.205117847817143
Validation loss: 2.699046406587033

Epoch: 5| Step: 10
Training loss: 3.1142686835906996
Validation loss: 2.684031833575803

Epoch: 55| Step: 0
Training loss: 2.2456289855429032
Validation loss: 2.6919419386145176

Epoch: 5| Step: 1
Training loss: 2.727722970326026
Validation loss: 2.667470357773467

Epoch: 5| Step: 2
Training loss: 3.1807109863268055
Validation loss: 2.6558250169309683

Epoch: 5| Step: 3
Training loss: 3.4370406797619344
Validation loss: 2.683909656237771

Epoch: 5| Step: 4
Training loss: 2.9838895552703955
Validation loss: 2.681518921896698

Epoch: 5| Step: 5
Training loss: 3.6276919136836123
Validation loss: 2.6443367981687254

Epoch: 5| Step: 6
Training loss: 2.474323692782296
Validation loss: 2.6821973208019196

Epoch: 5| Step: 7
Training loss: 2.78014137375142
Validation loss: 2.697602003813018

Epoch: 5| Step: 8
Training loss: 3.365475531387528
Validation loss: 2.71484449222366

Epoch: 5| Step: 9
Training loss: 2.8855895026231515
Validation loss: 2.7061382842150987

Epoch: 5| Step: 10
Training loss: 3.021166202139046
Validation loss: 2.6937644161537824

Epoch: 56| Step: 0
Training loss: 2.998257448834604
Validation loss: 2.71272953431379

Epoch: 5| Step: 1
Training loss: 2.772334435544107
Validation loss: 2.696444710218416

Epoch: 5| Step: 2
Training loss: 2.822586199759366
Validation loss: 2.6732307184429938

Epoch: 5| Step: 3
Training loss: 2.807793642552842
Validation loss: 2.7068664825468574

Epoch: 5| Step: 4
Training loss: 3.5512245161732623
Validation loss: 2.650679682408294

Epoch: 5| Step: 5
Training loss: 3.4110852840769876
Validation loss: 2.6857389025157357

Epoch: 5| Step: 6
Training loss: 3.112063218688177
Validation loss: 2.6821322090945205

Epoch: 5| Step: 7
Training loss: 2.8752199171791286
Validation loss: 2.667901716088472

Epoch: 5| Step: 8
Training loss: 2.3545280336731054
Validation loss: 2.694126384995985

Epoch: 5| Step: 9
Training loss: 3.042641853530011
Validation loss: 2.6900002005075683

Epoch: 5| Step: 10
Training loss: 3.3774814666759103
Validation loss: 2.6693947960106263

Epoch: 57| Step: 0
Training loss: 2.7386487423082095
Validation loss: 2.6440770152388726

Epoch: 5| Step: 1
Training loss: 3.232668071487173
Validation loss: 2.6767307063776986

Epoch: 5| Step: 2
Training loss: 2.67692392272919
Validation loss: 2.7028487552362246

Epoch: 5| Step: 3
Training loss: 3.4351425410073704
Validation loss: 2.7114882026113123

Epoch: 5| Step: 4
Training loss: 3.420969943541489
Validation loss: 2.6544607130729463

Epoch: 5| Step: 5
Training loss: 3.262274524599752
Validation loss: 2.6433811414209223

Epoch: 5| Step: 6
Training loss: 2.8656389175792585
Validation loss: 2.6588245343712487

Epoch: 5| Step: 7
Training loss: 2.8103599883845387
Validation loss: 2.6329864165051196

Epoch: 5| Step: 8
Training loss: 2.4233094920052967
Validation loss: 2.6835408028576535

Epoch: 5| Step: 9
Training loss: 2.856543467864837
Validation loss: 2.6360112646717653

Epoch: 5| Step: 10
Training loss: 3.218731037565503
Validation loss: 2.665985880622751

Epoch: 58| Step: 0
Training loss: 2.5733255738386793
Validation loss: 2.680543055303225

Epoch: 5| Step: 1
Training loss: 2.5941105787286
Validation loss: 2.638905147105897

Epoch: 5| Step: 2
Training loss: 2.945799769561508
Validation loss: 2.715921560350506

Epoch: 5| Step: 3
Training loss: 2.9204001554883314
Validation loss: 2.6777303386335976

Epoch: 5| Step: 4
Training loss: 3.152910788965693
Validation loss: 2.7228670066768226

Epoch: 5| Step: 5
Training loss: 2.475939940172481
Validation loss: 2.7294025790420067

Epoch: 5| Step: 6
Training loss: 3.5912442967243097
Validation loss: 2.696398419780422

Epoch: 5| Step: 7
Training loss: 3.398901475825771
Validation loss: 2.6643285313283194

Epoch: 5| Step: 8
Training loss: 3.1711524177907866
Validation loss: 2.689392642507899

Epoch: 5| Step: 9
Training loss: 2.9378359987982585
Validation loss: 2.679476912878409

Epoch: 5| Step: 10
Training loss: 3.3089632550825234
Validation loss: 2.6920649055954287

Epoch: 59| Step: 0
Training loss: 3.18986004991779
Validation loss: 2.6749125050697553

Epoch: 5| Step: 1
Training loss: 2.7449975030050404
Validation loss: 2.6627944441465803

Epoch: 5| Step: 2
Training loss: 3.1091747123582123
Validation loss: 2.671526886376878

Epoch: 5| Step: 3
Training loss: 2.5619657005974137
Validation loss: 2.7027062779300106

Epoch: 5| Step: 4
Training loss: 3.289629164785764
Validation loss: 2.7053151113752936

Epoch: 5| Step: 5
Training loss: 3.357822503047935
Validation loss: 2.6699395828229364

Epoch: 5| Step: 6
Training loss: 2.802268597648248
Validation loss: 2.6762970122738317

Epoch: 5| Step: 7
Training loss: 2.7811169538928904
Validation loss: 2.6301933306827925

Epoch: 5| Step: 8
Training loss: 3.0599494745409057
Validation loss: 2.6861181204903044

Epoch: 5| Step: 9
Training loss: 2.8885500497257284
Validation loss: 2.686183609908284

Epoch: 5| Step: 10
Training loss: 3.231764619971406
Validation loss: 2.6625030479045892

Epoch: 60| Step: 0
Training loss: 2.941524589356689
Validation loss: 2.6814531015260448

Epoch: 5| Step: 1
Training loss: 2.846284512397293
Validation loss: 2.6488455534489592

Epoch: 5| Step: 2
Training loss: 1.7232893215194138
Validation loss: 2.664472513340453

Epoch: 5| Step: 3
Training loss: 2.726804356382364
Validation loss: 2.68715031192983

Epoch: 5| Step: 4
Training loss: 3.02455059527953
Validation loss: 2.6423209954250706

Epoch: 5| Step: 5
Training loss: 4.16643681210078
Validation loss: 2.6524952969290916

Epoch: 5| Step: 6
Training loss: 2.2458510823394793
Validation loss: 2.70315487060507

Epoch: 5| Step: 7
Training loss: 2.849350831903478
Validation loss: 2.67583913528661

Epoch: 5| Step: 8
Training loss: 3.038431842551123
Validation loss: 2.685193952861134

Epoch: 5| Step: 9
Training loss: 3.3718030411021696
Validation loss: 2.6874729793303445

Epoch: 5| Step: 10
Training loss: 3.326390203813272
Validation loss: 2.6944905353840163

Epoch: 61| Step: 0
Training loss: 2.5127362078568174
Validation loss: 2.642647622159301

Epoch: 5| Step: 1
Training loss: 2.8887951807164125
Validation loss: 2.6789424495131513

Epoch: 5| Step: 2
Training loss: 3.219780025668879
Validation loss: 2.6663922532719875

Epoch: 5| Step: 3
Training loss: 3.229783489423061
Validation loss: 2.662371412807242

Epoch: 5| Step: 4
Training loss: 2.4498065443928323
Validation loss: 2.674501346943847

Epoch: 5| Step: 5
Training loss: 3.2053543892304766
Validation loss: 2.6935739449068405

Epoch: 5| Step: 6
Training loss: 2.966667167434936
Validation loss: 2.6748030418574804

Epoch: 5| Step: 7
Training loss: 2.7785954183326687
Validation loss: 2.663246674372286

Epoch: 5| Step: 8
Training loss: 3.4369603513728784
Validation loss: 2.6925515425766995

Epoch: 5| Step: 9
Training loss: 3.4606538057842147
Validation loss: 2.640272345710144

Epoch: 5| Step: 10
Training loss: 2.848701107447525
Validation loss: 2.6515126361896253

Epoch: 62| Step: 0
Training loss: 2.798943548491177
Validation loss: 2.6775969666192534

Epoch: 5| Step: 1
Training loss: 3.413248274930483
Validation loss: 2.6705296388022095

Epoch: 5| Step: 2
Training loss: 2.795066717781195
Validation loss: 2.7100754841670263

Epoch: 5| Step: 3
Training loss: 2.9024549747888027
Validation loss: 2.6592912784187965

Epoch: 5| Step: 4
Training loss: 3.447083310069198
Validation loss: 2.665631496782804

Epoch: 5| Step: 5
Training loss: 2.763644268855055
Validation loss: 2.701766728947287

Epoch: 5| Step: 6
Training loss: 3.1627295429622606
Validation loss: 2.643563741259357

Epoch: 5| Step: 7
Training loss: 3.1191155534762576
Validation loss: 2.6318848387143596

Epoch: 5| Step: 8
Training loss: 2.372650791597792
Validation loss: 2.6476918511908063

Epoch: 5| Step: 9
Training loss: 3.0914419793451913
Validation loss: 2.6606488917521465

Epoch: 5| Step: 10
Training loss: 3.0756801442297887
Validation loss: 2.6637408618973617

Epoch: 63| Step: 0
Training loss: 3.374572302951033
Validation loss: 2.7071975831870057

Epoch: 5| Step: 1
Training loss: 2.751863974974322
Validation loss: 2.702745922110144

Epoch: 5| Step: 2
Training loss: 3.4251850440165117
Validation loss: 2.637499866797603

Epoch: 5| Step: 3
Training loss: 2.7553162772961928
Validation loss: 2.7060910549747126

Epoch: 5| Step: 4
Training loss: 2.356516944880989
Validation loss: 2.6772397752413153

Epoch: 5| Step: 5
Training loss: 3.797424276675568
Validation loss: 2.662198821811862

Epoch: 5| Step: 6
Training loss: 2.812049405772265
Validation loss: 2.743653528088756

Epoch: 5| Step: 7
Training loss: 2.9278376321225945
Validation loss: 2.6779485675054566

Epoch: 5| Step: 8
Training loss: 2.547754054106252
Validation loss: 2.6644224653166773

Epoch: 5| Step: 9
Training loss: 2.9578538604601254
Validation loss: 2.6512910487991577

Epoch: 5| Step: 10
Training loss: 2.840835251282052
Validation loss: 2.6329166633597607

Epoch: 64| Step: 0
Training loss: 3.033710700096079
Validation loss: 2.6571541807792736

Epoch: 5| Step: 1
Training loss: 2.8653583564795806
Validation loss: 2.6772626591169537

Epoch: 5| Step: 2
Training loss: 2.6939693034178336
Validation loss: 2.676070706542474

Epoch: 5| Step: 3
Training loss: 3.1531464076000706
Validation loss: 2.6489632393502323

Epoch: 5| Step: 4
Training loss: 2.9030043003051738
Validation loss: 2.64715515700426

Epoch: 5| Step: 5
Training loss: 3.564335132892977
Validation loss: 2.6156833441003777

Epoch: 5| Step: 6
Training loss: 3.128652955278868
Validation loss: 2.6347718473608617

Epoch: 5| Step: 7
Training loss: 2.903143093681001
Validation loss: 2.676924936913753

Epoch: 5| Step: 8
Training loss: 2.7152856261347793
Validation loss: 2.6793702089967377

Epoch: 5| Step: 9
Training loss: 2.547190453587667
Validation loss: 2.6555767694891

Epoch: 5| Step: 10
Training loss: 3.6401864634951973
Validation loss: 2.6899207159961938

Epoch: 65| Step: 0
Training loss: 3.2224653707675275
Validation loss: 2.6821705143384285

Epoch: 5| Step: 1
Training loss: 2.958922815469385
Validation loss: 2.685643886093

Epoch: 5| Step: 2
Training loss: 3.0699138042762755
Validation loss: 2.656452077167764

Epoch: 5| Step: 3
Training loss: 2.0383102958835013
Validation loss: 2.650346246327671

Epoch: 5| Step: 4
Training loss: 3.019888596406263
Validation loss: 2.6554102632540215

Epoch: 5| Step: 5
Training loss: 2.946565639725996
Validation loss: 2.667689297184015

Epoch: 5| Step: 6
Training loss: 3.1554875727689713
Validation loss: 2.645035939831867

Epoch: 5| Step: 7
Training loss: 2.5780093080398463
Validation loss: 2.6265368135580336

Epoch: 5| Step: 8
Training loss: 3.1446363348609694
Validation loss: 2.6721917198383522

Epoch: 5| Step: 9
Training loss: 3.5769584786530317
Validation loss: 2.6658646033651245

Epoch: 5| Step: 10
Training loss: 2.72689939674657
Validation loss: 2.679804116054937

Epoch: 66| Step: 0
Training loss: 3.4035619926293244
Validation loss: 2.6403996919451656

Epoch: 5| Step: 1
Training loss: 2.8658184556130255
Validation loss: 2.619443179182638

Epoch: 5| Step: 2
Training loss: 3.078618044021395
Validation loss: 2.658342332413587

Epoch: 5| Step: 3
Training loss: 3.034438353956528
Validation loss: 2.676278385729243

Epoch: 5| Step: 4
Training loss: 3.2130921645565307
Validation loss: 2.7094383310974477

Epoch: 5| Step: 5
Training loss: 2.602140620150524
Validation loss: 2.641946521990498

Epoch: 5| Step: 6
Training loss: 3.898702914389971
Validation loss: 2.6517650170943434

Epoch: 5| Step: 7
Training loss: 1.9407937755077644
Validation loss: 2.658901270145569

Epoch: 5| Step: 8
Training loss: 2.7724304950006187
Validation loss: 2.674713152967254

Epoch: 5| Step: 9
Training loss: 2.794584903090012
Validation loss: 2.6983573066899917

Epoch: 5| Step: 10
Training loss: 2.7936368129937397
Validation loss: 2.675829851574251

Epoch: 67| Step: 0
Training loss: 2.8953399969813765
Validation loss: 2.696671418065487

Epoch: 5| Step: 1
Training loss: 3.2605630437555853
Validation loss: 2.697953775574872

Epoch: 5| Step: 2
Training loss: 2.8286737573507663
Validation loss: 2.6548257337851737

Epoch: 5| Step: 3
Training loss: 3.2998655234015493
Validation loss: 2.648558822187303

Epoch: 5| Step: 4
Training loss: 3.5096832928051924
Validation loss: 2.6477698400704575

Epoch: 5| Step: 5
Training loss: 3.2797715989117036
Validation loss: 2.667454845487877

Epoch: 5| Step: 6
Training loss: 2.4712816608969024
Validation loss: 2.686811551178047

Epoch: 5| Step: 7
Training loss: 2.3339720147096874
Validation loss: 2.6927928864078705

Epoch: 5| Step: 8
Training loss: 3.033218688335394
Validation loss: 2.6629459652925767

Epoch: 5| Step: 9
Training loss: 2.552987189057927
Validation loss: 2.6636136845260707

Epoch: 5| Step: 10
Training loss: 3.150848147332141
Validation loss: 2.699389440359325

Epoch: 68| Step: 0
Training loss: 2.56651475465072
Validation loss: 2.629441475269926

Epoch: 5| Step: 1
Training loss: 3.352890214050497
Validation loss: 2.6702184612238837

Epoch: 5| Step: 2
Training loss: 2.9161755466236228
Validation loss: 2.6260561500618476

Epoch: 5| Step: 3
Training loss: 2.981108950431168
Validation loss: 2.667099827789977

Epoch: 5| Step: 4
Training loss: 2.5862987070120282
Validation loss: 2.7114791780503484

Epoch: 5| Step: 5
Training loss: 3.098194975025214
Validation loss: 2.647582575559652

Epoch: 5| Step: 6
Training loss: 3.5986245971751547
Validation loss: 2.6500640432645066

Epoch: 5| Step: 7
Training loss: 3.000626180784044
Validation loss: 2.707247513725544

Epoch: 5| Step: 8
Training loss: 2.5490576629761135
Validation loss: 2.6058253538833704

Epoch: 5| Step: 9
Training loss: 2.9930037936292697
Validation loss: 2.648417636928619

Epoch: 5| Step: 10
Training loss: 2.8063001326604953
Validation loss: 2.635320987024079

Epoch: 69| Step: 0
Training loss: 2.438740243584275
Validation loss: 2.664774688523183

Epoch: 5| Step: 1
Training loss: 2.374726129100453
Validation loss: 2.6776225445285937

Epoch: 5| Step: 2
Training loss: 2.549262396403429
Validation loss: 2.6741522800425916

Epoch: 5| Step: 3
Training loss: 3.0717307350844254
Validation loss: 2.6927980483519147

Epoch: 5| Step: 4
Training loss: 2.828429484968722
Validation loss: 2.648781817963266

Epoch: 5| Step: 5
Training loss: 3.509808148958099
Validation loss: 2.6528772926645607

Epoch: 5| Step: 6
Training loss: 3.534968081361227
Validation loss: 2.6439320796188004

Epoch: 5| Step: 7
Training loss: 2.8090403152728816
Validation loss: 2.6738898301181098

Epoch: 5| Step: 8
Training loss: 3.327125363372073
Validation loss: 2.6296696788235723

Epoch: 5| Step: 9
Training loss: 2.797776913271161
Validation loss: 2.692617375374445

Epoch: 5| Step: 10
Training loss: 3.081734801371839
Validation loss: 2.6673649333870553

Epoch: 70| Step: 0
Training loss: 3.681481314938487
Validation loss: 2.666050126984889

Epoch: 5| Step: 1
Training loss: 2.800461584600387
Validation loss: 2.669702684637813

Epoch: 5| Step: 2
Training loss: 3.2234274941241488
Validation loss: 2.6526575917253967

Epoch: 5| Step: 3
Training loss: 2.627394537728349
Validation loss: 2.696924786893621

Epoch: 5| Step: 4
Training loss: 2.4016302770557543
Validation loss: 2.6144945023095367

Epoch: 5| Step: 5
Training loss: 3.152363716828029
Validation loss: 2.6321835140675387

Epoch: 5| Step: 6
Training loss: 2.763630897029462
Validation loss: 2.6458284570017447

Epoch: 5| Step: 7
Training loss: 3.3658372335717526
Validation loss: 2.6563333284745982

Epoch: 5| Step: 8
Training loss: 2.6718871356175424
Validation loss: 2.686549164214175

Epoch: 5| Step: 9
Training loss: 2.8204245928101015
Validation loss: 2.67964351659453

Epoch: 5| Step: 10
Training loss: 2.9710538257100145
Validation loss: 2.6679551158110977

Epoch: 71| Step: 0
Training loss: 3.517425482963106
Validation loss: 2.646266581712665

Epoch: 5| Step: 1
Training loss: 2.832453160921373
Validation loss: 2.627754378766541

Epoch: 5| Step: 2
Training loss: 2.6365794053168154
Validation loss: 2.695863363749156

Epoch: 5| Step: 3
Training loss: 3.1504943035966004
Validation loss: 2.6663135754975373

Epoch: 5| Step: 4
Training loss: 2.485909809603304
Validation loss: 2.66785967838154

Epoch: 5| Step: 5
Training loss: 2.3674998061634214
Validation loss: 2.6361917133222676

Epoch: 5| Step: 6
Training loss: 2.5680260967818147
Validation loss: 2.670096177009691

Epoch: 5| Step: 7
Training loss: 2.878039039214492
Validation loss: 2.67026559625346

Epoch: 5| Step: 8
Training loss: 3.242846318605578
Validation loss: 2.656869987503733

Epoch: 5| Step: 9
Training loss: 3.0543292291598325
Validation loss: 2.6612231812905787

Epoch: 5| Step: 10
Training loss: 3.6224778707919585
Validation loss: 2.689193724157366

Epoch: 72| Step: 0
Training loss: 3.1705408156047334
Validation loss: 2.710085331660457

Epoch: 5| Step: 1
Training loss: 2.35906323526775
Validation loss: 2.6508572109294763

Epoch: 5| Step: 2
Training loss: 3.365098061571053
Validation loss: 2.6356240406198186

Epoch: 5| Step: 3
Training loss: 2.8744566030711707
Validation loss: 2.6320920245481587

Epoch: 5| Step: 4
Training loss: 2.398098502292343
Validation loss: 2.6393879687456896

Epoch: 5| Step: 5
Training loss: 3.8986535022041937
Validation loss: 2.6850387757827683

Epoch: 5| Step: 6
Training loss: 2.3935528945449223
Validation loss: 2.6425965243951075

Epoch: 5| Step: 7
Training loss: 3.045254007152542
Validation loss: 2.6490746383687833

Epoch: 5| Step: 8
Training loss: 2.9195207709455366
Validation loss: 2.656678967037169

Epoch: 5| Step: 9
Training loss: 2.95844770040312
Validation loss: 2.5933922991586704

Epoch: 5| Step: 10
Training loss: 2.9195957371687014
Validation loss: 2.6545260428538486

Epoch: 73| Step: 0
Training loss: 2.9335651421707643
Validation loss: 2.6400814740917196

Epoch: 5| Step: 1
Training loss: 3.450199735084202
Validation loss: 2.6705351432909223

Epoch: 5| Step: 2
Training loss: 2.6739860359860135
Validation loss: 2.707548958063584

Epoch: 5| Step: 3
Training loss: 2.9350530294017503
Validation loss: 2.6550436196323366

Epoch: 5| Step: 4
Training loss: 2.7410546378166813
Validation loss: 2.6470909227294532

Epoch: 5| Step: 5
Training loss: 2.7895450975923413
Validation loss: 2.647234022622827

Epoch: 5| Step: 6
Training loss: 3.689232629313104
Validation loss: 2.6589287768928864

Epoch: 5| Step: 7
Training loss: 2.47388889148361
Validation loss: 2.7071524709532664

Epoch: 5| Step: 8
Training loss: 2.910012875295779
Validation loss: 2.633201778963354

Epoch: 5| Step: 9
Training loss: 3.5281312386632453
Validation loss: 2.642363404987931

Epoch: 5| Step: 10
Training loss: 2.1546297481949517
Validation loss: 2.6110359914690084

Epoch: 74| Step: 0
Training loss: 3.031011670368599
Validation loss: 2.6285302604367193

Epoch: 5| Step: 1
Training loss: 3.3717806968193895
Validation loss: 2.673691185136258

Epoch: 5| Step: 2
Training loss: 3.06406082550112
Validation loss: 2.6795601906777162

Epoch: 5| Step: 3
Training loss: 2.8294303789864226
Validation loss: 2.670731642458306

Epoch: 5| Step: 4
Training loss: 3.3718536687393645
Validation loss: 2.652499094310696

Epoch: 5| Step: 5
Training loss: 2.252985351298153
Validation loss: 2.6479898332681895

Epoch: 5| Step: 6
Training loss: 2.4256233987112443
Validation loss: 2.662920005732155

Epoch: 5| Step: 7
Training loss: 2.917610197494924
Validation loss: 2.701490380403554

Epoch: 5| Step: 8
Training loss: 3.2425163378042883
Validation loss: 2.644082511774553

Epoch: 5| Step: 9
Training loss: 2.2698429175991346
Validation loss: 2.663966075295047

Epoch: 5| Step: 10
Training loss: 3.198933310345129
Validation loss: 2.648298025565023

Epoch: 75| Step: 0
Training loss: 2.4561697172677612
Validation loss: 2.662324282455355

Epoch: 5| Step: 1
Training loss: 2.403802890681712
Validation loss: 2.6292638706860902

Epoch: 5| Step: 2
Training loss: 3.0688087721905117
Validation loss: 2.6415685599044254

Epoch: 5| Step: 3
Training loss: 2.9055453851188338
Validation loss: 2.6913771558181736

Epoch: 5| Step: 4
Training loss: 3.4822616668665667
Validation loss: 2.689357223634063

Epoch: 5| Step: 5
Training loss: 2.7208445581396425
Validation loss: 2.6255700761490846

Epoch: 5| Step: 6
Training loss: 2.726358750389911
Validation loss: 2.679489244646582

Epoch: 5| Step: 7
Training loss: 3.794923005862222
Validation loss: 2.671628011703111

Epoch: 5| Step: 8
Training loss: 2.425681881550963
Validation loss: 2.6754962220528484

Epoch: 5| Step: 9
Training loss: 3.023922272687392
Validation loss: 2.6708468752471273

Epoch: 5| Step: 10
Training loss: 2.9474437500534263
Validation loss: 2.6371107313688613

Epoch: 76| Step: 0
Training loss: 3.1787731908746553
Validation loss: 2.680827850765932

Epoch: 5| Step: 1
Training loss: 2.207924451102189
Validation loss: 2.5964654633740154

Epoch: 5| Step: 2
Training loss: 3.326829685072412
Validation loss: 2.6052204206898657

Epoch: 5| Step: 3
Training loss: 3.810226262700633
Validation loss: 2.667068728649317

Epoch: 5| Step: 4
Training loss: 3.26378904870823
Validation loss: 2.7166983284443034

Epoch: 5| Step: 5
Training loss: 2.4530167282411184
Validation loss: 2.6194811083021965

Epoch: 5| Step: 6
Training loss: 3.059303639780788
Validation loss: 2.6005443317537793

Epoch: 5| Step: 7
Training loss: 2.4964339572170906
Validation loss: 2.6725740159416578

Epoch: 5| Step: 8
Training loss: 3.514963859274635
Validation loss: 2.645053803597075

Epoch: 5| Step: 9
Training loss: 2.38707943952015
Validation loss: 2.6306766125233976

Epoch: 5| Step: 10
Training loss: 2.130483284688399
Validation loss: 2.7053103751110936

Epoch: 77| Step: 0
Training loss: 2.5237103483005217
Validation loss: 2.638657900946899

Epoch: 5| Step: 1
Training loss: 3.4549140265846425
Validation loss: 2.6591211590098554

Epoch: 5| Step: 2
Training loss: 2.590356836370983
Validation loss: 2.665964221214628

Epoch: 5| Step: 3
Training loss: 2.809458126073105
Validation loss: 2.619363514009758

Epoch: 5| Step: 4
Training loss: 2.5482011396584725
Validation loss: 2.6469314687335315

Epoch: 5| Step: 5
Training loss: 2.812667926437531
Validation loss: 2.619711191374981

Epoch: 5| Step: 6
Training loss: 3.410838964404663
Validation loss: 2.633078550646103

Epoch: 5| Step: 7
Training loss: 2.817708765806681
Validation loss: 2.6762107255952006

Epoch: 5| Step: 8
Training loss: 2.9222984619090626
Validation loss: 2.6234243598989093

Epoch: 5| Step: 9
Training loss: 2.816124255153719
Validation loss: 2.61842319419886

Epoch: 5| Step: 10
Training loss: 3.126461907807949
Validation loss: 2.638345630585403

Epoch: 78| Step: 0
Training loss: 3.1509837415851396
Validation loss: 2.6320689495659937

Epoch: 5| Step: 1
Training loss: 2.974586451661919
Validation loss: 2.616107322153966

Epoch: 5| Step: 2
Training loss: 2.5951904525400122
Validation loss: 2.651399546003332

Epoch: 5| Step: 3
Training loss: 2.8654109429768266
Validation loss: 2.639939324662734

Epoch: 5| Step: 4
Training loss: 2.7486882982879344
Validation loss: 2.6315954046215135

Epoch: 5| Step: 5
Training loss: 3.2863741147010854
Validation loss: 2.6851150870195286

Epoch: 5| Step: 6
Training loss: 2.8032840203095635
Validation loss: 2.6321957216499663

Epoch: 5| Step: 7
Training loss: 2.6442667210409003
Validation loss: 2.6264894686768225

Epoch: 5| Step: 8
Training loss: 3.2401869887094104
Validation loss: 2.6765551631204283

Epoch: 5| Step: 9
Training loss: 3.302522567914483
Validation loss: 2.628393957838358

Epoch: 5| Step: 10
Training loss: 2.814385777977407
Validation loss: 2.642680392038648

Epoch: 79| Step: 0
Training loss: 3.1890440548293744
Validation loss: 2.6261606331420033

Epoch: 5| Step: 1
Training loss: 3.076053290125021
Validation loss: 2.6299030436649957

Epoch: 5| Step: 2
Training loss: 3.3416155125483264
Validation loss: 2.659717970814636

Epoch: 5| Step: 3
Training loss: 3.2513160975160194
Validation loss: 2.686229354873813

Epoch: 5| Step: 4
Training loss: 2.9765842867476944
Validation loss: 2.6837429142440166

Epoch: 5| Step: 5
Training loss: 2.5577070490609195
Validation loss: 2.6251543012389837

Epoch: 5| Step: 6
Training loss: 3.08712521645151
Validation loss: 2.6070791254818237

Epoch: 5| Step: 7
Training loss: 3.3480781280443948
Validation loss: 2.6830392530263953

Epoch: 5| Step: 8
Training loss: 2.385160096431246
Validation loss: 2.6232567998977365

Epoch: 5| Step: 9
Training loss: 2.6461802177616414
Validation loss: 2.6101499697042443

Epoch: 5| Step: 10
Training loss: 2.342714818592404
Validation loss: 2.6241848349391113

Epoch: 80| Step: 0
Training loss: 3.2531878169404913
Validation loss: 2.6091342161833064

Epoch: 5| Step: 1
Training loss: 3.5051246999632526
Validation loss: 2.641219881109827

Epoch: 5| Step: 2
Training loss: 2.720465458705866
Validation loss: 2.6238290301102496

Epoch: 5| Step: 3
Training loss: 2.5478036509724786
Validation loss: 2.6929126139249364

Epoch: 5| Step: 4
Training loss: 2.965507101402598
Validation loss: 2.636452593144669

Epoch: 5| Step: 5
Training loss: 2.8156562049821603
Validation loss: 2.6268439313557277

Epoch: 5| Step: 6
Training loss: 2.7465252164262632
Validation loss: 2.654710757743302

Epoch: 5| Step: 7
Training loss: 3.464329970671229
Validation loss: 2.666250471033313

Epoch: 5| Step: 8
Training loss: 2.5299777377509916
Validation loss: 2.6169278864141376

Epoch: 5| Step: 9
Training loss: 2.6825163120651943
Validation loss: 2.662752817789301

Epoch: 5| Step: 10
Training loss: 2.918279056825001
Validation loss: 2.6800826342321087

Epoch: 81| Step: 0
Training loss: 2.9954752177902435
Validation loss: 2.644087409101622

Epoch: 5| Step: 1
Training loss: 2.290565283856934
Validation loss: 2.646553449921617

Epoch: 5| Step: 2
Training loss: 3.1792132799590176
Validation loss: 2.6295245720813663

Epoch: 5| Step: 3
Training loss: 2.760283230609423
Validation loss: 2.6430602620984787

Epoch: 5| Step: 4
Training loss: 3.377203892872505
Validation loss: 2.6472825130234274

Epoch: 5| Step: 5
Training loss: 2.5351978175160195
Validation loss: 2.680816906995967

Epoch: 5| Step: 6
Training loss: 3.5027298499416655
Validation loss: 2.6356256990528277

Epoch: 5| Step: 7
Training loss: 2.5943468625080515
Validation loss: 2.6414183747388402

Epoch: 5| Step: 8
Training loss: 3.263389588891697
Validation loss: 2.6435461379918337

Epoch: 5| Step: 9
Training loss: 2.100941279037824
Validation loss: 2.6493079176609524

Epoch: 5| Step: 10
Training loss: 2.810759366017227
Validation loss: 2.6251534486953307

Epoch: 82| Step: 0
Training loss: 3.31002196705147
Validation loss: 2.682839699247758

Epoch: 5| Step: 1
Training loss: 2.4420655359820405
Validation loss: 2.660997462138826

Epoch: 5| Step: 2
Training loss: 2.715493367366315
Validation loss: 2.6000310421897725

Epoch: 5| Step: 3
Training loss: 2.9076152589081397
Validation loss: 2.6489767080520594

Epoch: 5| Step: 4
Training loss: 2.978652340612337
Validation loss: 2.618953999444347

Epoch: 5| Step: 5
Training loss: 2.666375283375248
Validation loss: 2.640851871176107

Epoch: 5| Step: 6
Training loss: 2.407817577676042
Validation loss: 2.598393264003371

Epoch: 5| Step: 7
Training loss: 3.391713332496422
Validation loss: 2.60657527130565

Epoch: 5| Step: 8
Training loss: 3.446708137021689
Validation loss: 2.6179410459093675

Epoch: 5| Step: 9
Training loss: 3.180582056578313
Validation loss: 2.632591394314031

Epoch: 5| Step: 10
Training loss: 2.7694340569103555
Validation loss: 2.6501342882589247

Epoch: 83| Step: 0
Training loss: 2.532053407868134
Validation loss: 2.673552544860661

Epoch: 5| Step: 1
Training loss: 3.0552230326501273
Validation loss: 2.674491138377339

Epoch: 5| Step: 2
Training loss: 2.7943108595191166
Validation loss: 2.6451319841367913

Epoch: 5| Step: 3
Training loss: 2.656686275781547
Validation loss: 2.622575230840017

Epoch: 5| Step: 4
Training loss: 3.5136312977524278
Validation loss: 2.6039334756775285

Epoch: 5| Step: 5
Training loss: 2.617109337393933
Validation loss: 2.6284628693220733

Epoch: 5| Step: 6
Training loss: 2.8954006027264265
Validation loss: 2.649633014526677

Epoch: 5| Step: 7
Training loss: 3.5261176968392434
Validation loss: 2.6196160172060696

Epoch: 5| Step: 8
Training loss: 2.9653974375428076
Validation loss: 2.617982691477338

Epoch: 5| Step: 9
Training loss: 2.663298735109395
Validation loss: 2.599798244145226

Epoch: 5| Step: 10
Training loss: 2.9156152919268306
Validation loss: 2.5804230323298722

Epoch: 84| Step: 0
Training loss: 2.957344391341499
Validation loss: 2.6359058473951977

Epoch: 5| Step: 1
Training loss: 2.909731348752256
Validation loss: 2.6464278567572297

Epoch: 5| Step: 2
Training loss: 2.2862214564590264
Validation loss: 2.6553544872391717

Epoch: 5| Step: 3
Training loss: 3.0603726841982044
Validation loss: 2.6569164730875974

Epoch: 5| Step: 4
Training loss: 2.139388012413239
Validation loss: 2.6274773763183337

Epoch: 5| Step: 5
Training loss: 3.147333069753713
Validation loss: 2.6247358189207093

Epoch: 5| Step: 6
Training loss: 3.2507734112048
Validation loss: 2.610353979460525

Epoch: 5| Step: 7
Training loss: 3.0637889407300634
Validation loss: 2.6417019730254254

Epoch: 5| Step: 8
Training loss: 2.4135729839700715
Validation loss: 2.6488409233309427

Epoch: 5| Step: 9
Training loss: 3.4664562992921666
Validation loss: 2.639375977034141

Epoch: 5| Step: 10
Training loss: 2.810935284548486
Validation loss: 2.6239016589237054

Epoch: 85| Step: 0
Training loss: 2.3988423456224903
Validation loss: 2.6262342907808343

Epoch: 5| Step: 1
Training loss: 3.0483285420086226
Validation loss: 2.650555462820836

Epoch: 5| Step: 2
Training loss: 3.2424310431872283
Validation loss: 2.6550945850266254

Epoch: 5| Step: 3
Training loss: 2.455421878902596
Validation loss: 2.644260713955725

Epoch: 5| Step: 4
Training loss: 2.712721355916636
Validation loss: 2.67099364157647

Epoch: 5| Step: 5
Training loss: 3.3086757537155402
Validation loss: 2.5839533589399495

Epoch: 5| Step: 6
Training loss: 3.4722184719489295
Validation loss: 2.672926368670514

Epoch: 5| Step: 7
Training loss: 2.327946700878817
Validation loss: 2.6184829642725562

Epoch: 5| Step: 8
Training loss: 2.9255701862392254
Validation loss: 2.6396124356440582

Epoch: 5| Step: 9
Training loss: 3.0467764031522995
Validation loss: 2.6341469964324093

Epoch: 5| Step: 10
Training loss: 3.3549592560569566
Validation loss: 2.693986095688483

Epoch: 86| Step: 0
Training loss: 2.9276636890024306
Validation loss: 2.655977335283745

Epoch: 5| Step: 1
Training loss: 2.3733814144979064
Validation loss: 2.612428039024446

Epoch: 5| Step: 2
Training loss: 2.641667538310809
Validation loss: 2.605584756622393

Epoch: 5| Step: 3
Training loss: 3.562385423390506
Validation loss: 2.6025731943855908

Epoch: 5| Step: 4
Training loss: 2.5058720291781524
Validation loss: 2.589485949629015

Epoch: 5| Step: 5
Training loss: 3.6141356411734593
Validation loss: 2.650985125991943

Epoch: 5| Step: 6
Training loss: 3.4794503893872424
Validation loss: 2.6352335036006633

Epoch: 5| Step: 7
Training loss: 2.2462990310403974
Validation loss: 2.584737665599438

Epoch: 5| Step: 8
Training loss: 2.6011269694558297
Validation loss: 2.6369023799417564

Epoch: 5| Step: 9
Training loss: 3.0560855251747485
Validation loss: 2.616283179088046

Epoch: 5| Step: 10
Training loss: 2.587011845930572
Validation loss: 2.6766407184428314

Epoch: 87| Step: 0
Training loss: 2.141546677470152
Validation loss: 2.630482859596984

Epoch: 5| Step: 1
Training loss: 3.0941114118227824
Validation loss: 2.641735403858405

Epoch: 5| Step: 2
Training loss: 2.919860798378782
Validation loss: 2.592492814100494

Epoch: 5| Step: 3
Training loss: 3.250289904062285
Validation loss: 2.6235435467093633

Epoch: 5| Step: 4
Training loss: 3.702854066104048
Validation loss: 2.618015899347708

Epoch: 5| Step: 5
Training loss: 2.751179962167982
Validation loss: 2.6336644618954352

Epoch: 5| Step: 6
Training loss: 2.538794494569566
Validation loss: 2.641712956559787

Epoch: 5| Step: 7
Training loss: 2.9528211003312617
Validation loss: 2.6082249200154455

Epoch: 5| Step: 8
Training loss: 2.2246953262725144
Validation loss: 2.646179588036349

Epoch: 5| Step: 9
Training loss: 3.381002104692275
Validation loss: 2.624366841618933

Epoch: 5| Step: 10
Training loss: 2.433507339143551
Validation loss: 2.66465231419475

Epoch: 88| Step: 0
Training loss: 3.099212755717199
Validation loss: 2.6017128594448753

Epoch: 5| Step: 1
Training loss: 2.397961000706013
Validation loss: 2.5727577964182164

Epoch: 5| Step: 2
Training loss: 4.0089611764589925
Validation loss: 2.6032520491223248

Epoch: 5| Step: 3
Training loss: 2.6580949546897252
Validation loss: 2.655036345954715

Epoch: 5| Step: 4
Training loss: 2.14279154268397
Validation loss: 2.657830739762169

Epoch: 5| Step: 5
Training loss: 2.516131616603701
Validation loss: 2.607473555885322

Epoch: 5| Step: 6
Training loss: 2.764312518916772
Validation loss: 2.57298387892455

Epoch: 5| Step: 7
Training loss: 3.332430780926735
Validation loss: 2.655878880517442

Epoch: 5| Step: 8
Training loss: 3.389263811547448
Validation loss: 2.6662303281730964

Epoch: 5| Step: 9
Training loss: 3.066782234612711
Validation loss: 2.6066255497727284

Epoch: 5| Step: 10
Training loss: 2.588963055355532
Validation loss: 2.641435650553426

Epoch: 89| Step: 0
Training loss: 2.3842512946079832
Validation loss: 2.6158642982873412

Epoch: 5| Step: 1
Training loss: 2.9107095282045177
Validation loss: 2.62633076154291

Epoch: 5| Step: 2
Training loss: 3.1978592924424074
Validation loss: 2.6473223219015325

Epoch: 5| Step: 3
Training loss: 2.4244350561820145
Validation loss: 2.630667348742865

Epoch: 5| Step: 4
Training loss: 2.729253714146349
Validation loss: 2.6241746299254274

Epoch: 5| Step: 5
Training loss: 2.714898373719809
Validation loss: 2.6374478061513367

Epoch: 5| Step: 6
Training loss: 2.8007099137206244
Validation loss: 2.6298332828239914

Epoch: 5| Step: 7
Training loss: 3.578638164919371
Validation loss: 2.6174098031077198

Epoch: 5| Step: 8
Training loss: 3.446761123007324
Validation loss: 2.6202591012374294

Epoch: 5| Step: 9
Training loss: 2.9566916266946426
Validation loss: 2.6307150559869528

Epoch: 5| Step: 10
Training loss: 2.624801355747709
Validation loss: 2.630640370939059

Epoch: 90| Step: 0
Training loss: 3.3039039061568003
Validation loss: 2.641627986794675

Epoch: 5| Step: 1
Training loss: 2.8752889073376924
Validation loss: 2.5807362448092555

Epoch: 5| Step: 2
Training loss: 2.656783196283973
Validation loss: 2.616745758611776

Epoch: 5| Step: 3
Training loss: 2.3155085607743997
Validation loss: 2.6369904729735043

Epoch: 5| Step: 4
Training loss: 3.021535822424796
Validation loss: 2.639893799181086

Epoch: 5| Step: 5
Training loss: 2.6444178321667593
Validation loss: 2.5818414257019064

Epoch: 5| Step: 6
Training loss: 2.7131751771552004
Validation loss: 2.630316092323363

Epoch: 5| Step: 7
Training loss: 2.2623201667593977
Validation loss: 2.6713803177660447

Epoch: 5| Step: 8
Training loss: 2.7047258168310107
Validation loss: 2.618288380494608

Epoch: 5| Step: 9
Training loss: 4.194997651346161
Validation loss: 2.614834756254617

Epoch: 5| Step: 10
Training loss: 2.8944592589204454
Validation loss: 2.6552220526457937

Epoch: 91| Step: 0
Training loss: 2.3388909388473036
Validation loss: 2.6043559380117087

Epoch: 5| Step: 1
Training loss: 3.47746131507972
Validation loss: 2.6811982171048108

Epoch: 5| Step: 2
Training loss: 2.051889349067798
Validation loss: 2.598059307357041

Epoch: 5| Step: 3
Training loss: 3.296333159987889
Validation loss: 2.616101196512163

Epoch: 5| Step: 4
Training loss: 2.862532742908565
Validation loss: 2.6101905570510193

Epoch: 5| Step: 5
Training loss: 3.057267526317909
Validation loss: 2.6324926024802413

Epoch: 5| Step: 6
Training loss: 3.209151687950324
Validation loss: 2.630442163353814

Epoch: 5| Step: 7
Training loss: 2.8759341173650546
Validation loss: 2.6403808092504324

Epoch: 5| Step: 8
Training loss: 2.8366350309204424
Validation loss: 2.6318659080786486

Epoch: 5| Step: 9
Training loss: 3.352888507449031
Validation loss: 2.623911093145217

Epoch: 5| Step: 10
Training loss: 2.3855811871649686
Validation loss: 2.65744178089956

Epoch: 92| Step: 0
Training loss: 2.3902065933191503
Validation loss: 2.6213397325451138

Epoch: 5| Step: 1
Training loss: 2.8567819980529516
Validation loss: 2.6229601785176615

Epoch: 5| Step: 2
Training loss: 2.77260342803195
Validation loss: 2.649968163687378

Epoch: 5| Step: 3
Training loss: 3.3007543799756913
Validation loss: 2.6647375849672414

Epoch: 5| Step: 4
Training loss: 3.1746750672843533
Validation loss: 2.618633139275969

Epoch: 5| Step: 5
Training loss: 3.0281554481384902
Validation loss: 2.615129652422232

Epoch: 5| Step: 6
Training loss: 2.631152708017247
Validation loss: 2.638076410573749

Epoch: 5| Step: 7
Training loss: 3.1874468929878153
Validation loss: 2.648623429322574

Epoch: 5| Step: 8
Training loss: 3.099390456047067
Validation loss: 2.6500422846802043

Epoch: 5| Step: 9
Training loss: 2.496932245584186
Validation loss: 2.6325843974885896

Epoch: 5| Step: 10
Training loss: 2.7155692249536076
Validation loss: 2.6859488583708964

Epoch: 93| Step: 0
Training loss: 3.3479090698637086
Validation loss: 2.613604954565633

Epoch: 5| Step: 1
Training loss: 2.8703090711312536
Validation loss: 2.652954824712661

Epoch: 5| Step: 2
Training loss: 2.106135275232079
Validation loss: 2.621045315007072

Epoch: 5| Step: 3
Training loss: 3.2966294038966137
Validation loss: 2.624739385423423

Epoch: 5| Step: 4
Training loss: 3.6757291005698947
Validation loss: 2.6136954639761125

Epoch: 5| Step: 5
Training loss: 2.5421701047333842
Validation loss: 2.596125399987588

Epoch: 5| Step: 6
Training loss: 2.9417041967085367
Validation loss: 2.6571024502252194

Epoch: 5| Step: 7
Training loss: 3.0715003591366807
Validation loss: 2.5425972041203715

Epoch: 5| Step: 8
Training loss: 2.567231624732536
Validation loss: 2.6181799143150957

Epoch: 5| Step: 9
Training loss: 2.710865734370693
Validation loss: 2.6575640242195493

Epoch: 5| Step: 10
Training loss: 2.7639907059906577
Validation loss: 2.6224636358280042

Epoch: 94| Step: 0
Training loss: 3.065173480801246
Validation loss: 2.639965174202282

Epoch: 5| Step: 1
Training loss: 2.2176052955305496
Validation loss: 2.6101592139787932

Epoch: 5| Step: 2
Training loss: 2.8704168858285564
Validation loss: 2.661206525233465

Epoch: 5| Step: 3
Training loss: 2.657207271641893
Validation loss: 2.6095558896169404

Epoch: 5| Step: 4
Training loss: 2.6433182925277032
Validation loss: 2.687170435355456

Epoch: 5| Step: 5
Training loss: 3.5300731216940586
Validation loss: 2.6078234584018767

Epoch: 5| Step: 6
Training loss: 3.556368855667398
Validation loss: 2.6442049819809843

Epoch: 5| Step: 7
Training loss: 2.659886373086398
Validation loss: 2.6102234083354365

Epoch: 5| Step: 8
Training loss: 2.9846878287245593
Validation loss: 2.5924892200468106

Epoch: 5| Step: 9
Training loss: 3.1965725007041996
Validation loss: 2.5293905360170177

Epoch: 5| Step: 10
Training loss: 2.0219468919097783
Validation loss: 2.609840430646374

Epoch: 95| Step: 0
Training loss: 2.779058214289626
Validation loss: 2.6527875711711646

Epoch: 5| Step: 1
Training loss: 2.7908422097214647
Validation loss: 2.617548095859561

Epoch: 5| Step: 2
Training loss: 2.4685776082944217
Validation loss: 2.638586311303832

Epoch: 5| Step: 3
Training loss: 3.64467176552874
Validation loss: 2.5909109836029844

Epoch: 5| Step: 4
Training loss: 3.41432199430372
Validation loss: 2.6346781795721874

Epoch: 5| Step: 5
Training loss: 2.6037670795321857
Validation loss: 2.6944644810803715

Epoch: 5| Step: 6
Training loss: 2.74018077838711
Validation loss: 2.6237779889317956

Epoch: 5| Step: 7
Training loss: 2.136006852135401
Validation loss: 2.6453400667952636

Epoch: 5| Step: 8
Training loss: 2.554326863163161
Validation loss: 2.689952712699535

Epoch: 5| Step: 9
Training loss: 2.7783754903077487
Validation loss: 2.656772583835031

Epoch: 5| Step: 10
Training loss: 3.254014250392929
Validation loss: 2.572734084137331

Epoch: 96| Step: 0
Training loss: 2.5342625716515594
Validation loss: 2.6505888854782773

Epoch: 5| Step: 1
Training loss: 3.1910328454001164
Validation loss: 2.6794151689885886

Epoch: 5| Step: 2
Training loss: 3.047608116178549
Validation loss: 2.6259313045649453

Epoch: 5| Step: 3
Training loss: 2.6622989668192427
Validation loss: 2.5960923396926856

Epoch: 5| Step: 4
Training loss: 2.476596868138157
Validation loss: 2.618409406785674

Epoch: 5| Step: 5
Training loss: 2.3999732254442177
Validation loss: 2.6530361569056917

Epoch: 5| Step: 6
Training loss: 2.8868353669145987
Validation loss: 2.594135412449144

Epoch: 5| Step: 7
Training loss: 3.662796029375321
Validation loss: 2.6069711949909626

Epoch: 5| Step: 8
Training loss: 3.007518565690598
Validation loss: 2.6842645207855234

Epoch: 5| Step: 9
Training loss: 2.778836092145065
Validation loss: 2.6699268449550027

Epoch: 5| Step: 10
Training loss: 2.961210776729882
Validation loss: 2.65100059587866

Epoch: 97| Step: 0
Training loss: 3.000440883029311
Validation loss: 2.5768121185015964

Epoch: 5| Step: 1
Training loss: 2.968969397217865
Validation loss: 2.6080273336268713

Epoch: 5| Step: 2
Training loss: 3.0736854410547214
Validation loss: 2.5897057309848104

Epoch: 5| Step: 3
Training loss: 3.2893937548915058
Validation loss: 2.5820752380684016

Epoch: 5| Step: 4
Training loss: 2.3881213473122602
Validation loss: 2.5929758028653382

Epoch: 5| Step: 5
Training loss: 2.6898956267234637
Validation loss: 2.634301058715235

Epoch: 5| Step: 6
Training loss: 2.778589669362804
Validation loss: 2.6260465517290807

Epoch: 5| Step: 7
Training loss: 3.2396458234412497
Validation loss: 2.601630076504723

Epoch: 5| Step: 8
Training loss: 2.9217623928626844
Validation loss: 2.608603213206406

Epoch: 5| Step: 9
Training loss: 2.2952353924809046
Validation loss: 2.634294481005132

Epoch: 5| Step: 10
Training loss: 2.874671917315461
Validation loss: 2.6159125753849297

Epoch: 98| Step: 0
Training loss: 3.2217699716433987
Validation loss: 2.601942315559577

Epoch: 5| Step: 1
Training loss: 2.9935479719129345
Validation loss: 2.6280365163018256

Epoch: 5| Step: 2
Training loss: 2.449995243301445
Validation loss: 2.6464727157410413

Epoch: 5| Step: 3
Training loss: 3.3990079554447585
Validation loss: 2.635519041691094

Epoch: 5| Step: 4
Training loss: 2.943626670116722
Validation loss: 2.616309237857248

Epoch: 5| Step: 5
Training loss: 2.7006898175410794
Validation loss: 2.6583398481807317

Epoch: 5| Step: 6
Training loss: 2.814643551633831
Validation loss: 2.6033191100707525

Epoch: 5| Step: 7
Training loss: 2.664403720157754
Validation loss: 2.589485634307902

Epoch: 5| Step: 8
Training loss: 2.8865538925566225
Validation loss: 2.5992271630699073

Epoch: 5| Step: 9
Training loss: 3.118282880947518
Validation loss: 2.661643308136261

Epoch: 5| Step: 10
Training loss: 3.0033050451382444
Validation loss: 2.62213611001962

Epoch: 99| Step: 0
Training loss: 3.486696162953042
Validation loss: 2.605077886987118

Epoch: 5| Step: 1
Training loss: 2.353403479725695
Validation loss: 2.6102807713754044

Epoch: 5| Step: 2
Training loss: 2.220208669082985
Validation loss: 2.6716277084758344

Epoch: 5| Step: 3
Training loss: 2.6607339150572424
Validation loss: 2.608975036004096

Epoch: 5| Step: 4
Training loss: 2.9023907376537976
Validation loss: 2.626544736172918

Epoch: 5| Step: 5
Training loss: 2.9131587777412777
Validation loss: 2.595909260651499

Epoch: 5| Step: 6
Training loss: 2.6234754040486434
Validation loss: 2.5955266895406104

Epoch: 5| Step: 7
Training loss: 3.083240421716722
Validation loss: 2.586984223598389

Epoch: 5| Step: 8
Training loss: 3.4491710551540353
Validation loss: 2.5727842955415436

Epoch: 5| Step: 9
Training loss: 2.6423832383790957
Validation loss: 2.6080812377675713

Epoch: 5| Step: 10
Training loss: 2.8212865272898786
Validation loss: 2.602677603654994

Epoch: 100| Step: 0
Training loss: 2.9680145959006827
Validation loss: 2.661099242892116

Epoch: 5| Step: 1
Training loss: 2.7943396984951447
Validation loss: 2.5855061250235725

Epoch: 5| Step: 2
Training loss: 3.1238872835874028
Validation loss: 2.577218865448311

Epoch: 5| Step: 3
Training loss: 2.1175101059061094
Validation loss: 2.6069824182709316

Epoch: 5| Step: 4
Training loss: 2.9437915709976075
Validation loss: 2.5644437119659726

Epoch: 5| Step: 5
Training loss: 2.4700371971881645
Validation loss: 2.66200248633619

Epoch: 5| Step: 6
Training loss: 3.060741776210808
Validation loss: 2.609941973710879

Epoch: 5| Step: 7
Training loss: 2.936447604347991
Validation loss: 2.636909528641755

Epoch: 5| Step: 8
Training loss: 3.5691618619915135
Validation loss: 2.6616099433845135

Epoch: 5| Step: 9
Training loss: 2.583899302678856
Validation loss: 2.6455550302168627

Epoch: 5| Step: 10
Training loss: 3.083686877077401
Validation loss: 2.6797112010294053

Epoch: 101| Step: 0
Training loss: 2.3701306670017392
Validation loss: 2.580594758405487

Epoch: 5| Step: 1
Training loss: 3.624093567219252
Validation loss: 2.588778241199968

Epoch: 5| Step: 2
Training loss: 2.3015612071979565
Validation loss: 2.6222290057036113

Epoch: 5| Step: 3
Training loss: 2.885015870683674
Validation loss: 2.7522565881239127

Epoch: 5| Step: 4
Training loss: 2.481775038970127
Validation loss: 2.63299876057176

Epoch: 5| Step: 5
Training loss: 3.364228472976202
Validation loss: 2.603074778050311

Epoch: 5| Step: 6
Training loss: 2.97566173470699
Validation loss: 2.6280849365795396

Epoch: 5| Step: 7
Training loss: 3.4160087851471688
Validation loss: 2.6633546951277958

Epoch: 5| Step: 8
Training loss: 2.9419808807996564
Validation loss: 2.6170825166420166

Epoch: 5| Step: 9
Training loss: 2.9170533241835623
Validation loss: 2.6059450583511166

Epoch: 5| Step: 10
Training loss: 2.2355599629127196
Validation loss: 2.6009635320772087

Epoch: 102| Step: 0
Training loss: 2.9944196298578016
Validation loss: 2.580211257924633

Epoch: 5| Step: 1
Training loss: 2.60608021940132
Validation loss: 2.621764531525935

Epoch: 5| Step: 2
Training loss: 3.09957229986294
Validation loss: 2.5869218329460013

Epoch: 5| Step: 3
Training loss: 2.215589394437989
Validation loss: 2.5825859805497977

Epoch: 5| Step: 4
Training loss: 3.1362558215662357
Validation loss: 2.5934041150057054

Epoch: 5| Step: 5
Training loss: 3.0011294146315484
Validation loss: 2.62126997168293

Epoch: 5| Step: 6
Training loss: 2.657775440888386
Validation loss: 2.648986412984957

Epoch: 5| Step: 7
Training loss: 2.9529627195305075
Validation loss: 2.559383623293775

Epoch: 5| Step: 8
Training loss: 2.773326602921511
Validation loss: 2.5873999960095118

Epoch: 5| Step: 9
Training loss: 2.7808441551789747
Validation loss: 2.592510504940074

Epoch: 5| Step: 10
Training loss: 3.1008765857867937
Validation loss: 2.6289398640277937

Epoch: 103| Step: 0
Training loss: 2.861130639249294
Validation loss: 2.6496119538789635

Epoch: 5| Step: 1
Training loss: 2.184374729314741
Validation loss: 2.5643583692795895

Epoch: 5| Step: 2
Training loss: 3.033620949268839
Validation loss: 2.6110191487929817

Epoch: 5| Step: 3
Training loss: 2.989081860174005
Validation loss: 2.607959263288335

Epoch: 5| Step: 4
Training loss: 3.321441243113826
Validation loss: 2.6294398080615404

Epoch: 5| Step: 5
Training loss: 3.489445713043455
Validation loss: 2.6250105748742425

Epoch: 5| Step: 6
Training loss: 2.347821983542673
Validation loss: 2.6299910874849153

Epoch: 5| Step: 7
Training loss: 2.457255585197911
Validation loss: 2.701586539994359

Epoch: 5| Step: 8
Training loss: 2.4814287865939275
Validation loss: 2.5922565413157224

Epoch: 5| Step: 9
Training loss: 3.419328830960228
Validation loss: 2.5869736706678528

Epoch: 5| Step: 10
Training loss: 2.7280176864789016
Validation loss: 2.6170090079567427

Epoch: 104| Step: 0
Training loss: 2.396667523213721
Validation loss: 2.6131105349279027

Epoch: 5| Step: 1
Training loss: 2.2923726699395415
Validation loss: 2.6113976959342224

Epoch: 5| Step: 2
Training loss: 3.3656336480528113
Validation loss: 2.6354136883833412

Epoch: 5| Step: 3
Training loss: 2.476440908052409
Validation loss: 2.6438236298949525

Epoch: 5| Step: 4
Training loss: 3.020931654459115
Validation loss: 2.6268666413686845

Epoch: 5| Step: 5
Training loss: 3.0824784992640732
Validation loss: 2.565050474089753

Epoch: 5| Step: 6
Training loss: 3.0692180206728312
Validation loss: 2.603638205447248

Epoch: 5| Step: 7
Training loss: 2.9211031460362222
Validation loss: 2.6524249453197566

Epoch: 5| Step: 8
Training loss: 3.4512674850579126
Validation loss: 2.5712276370223592

Epoch: 5| Step: 9
Training loss: 2.5702786428894253
Validation loss: 2.6450882591650013

Epoch: 5| Step: 10
Training loss: 2.742912522676519
Validation loss: 2.5964960683258504

Epoch: 105| Step: 0
Training loss: 2.417339384785039
Validation loss: 2.6135196192952694

Epoch: 5| Step: 1
Training loss: 2.9231825570081456
Validation loss: 2.5900297659717415

Epoch: 5| Step: 2
Training loss: 3.41402702400404
Validation loss: 2.625904524129088

Epoch: 5| Step: 3
Training loss: 2.7596907230911727
Validation loss: 2.664190875128652

Epoch: 5| Step: 4
Training loss: 2.9120135838432817
Validation loss: 2.6139519875447847

Epoch: 5| Step: 5
Training loss: 2.9472445922667343
Validation loss: 2.623516165365072

Epoch: 5| Step: 6
Training loss: 2.2529751922284618
Validation loss: 2.6031832285612397

Epoch: 5| Step: 7
Training loss: 2.962335181178351
Validation loss: 2.589322413599623

Epoch: 5| Step: 8
Training loss: 3.3790657138130062
Validation loss: 2.614210769889726

Epoch: 5| Step: 9
Training loss: 2.946916947617422
Validation loss: 2.617399430636396

Epoch: 5| Step: 10
Training loss: 2.1423107109001145
Validation loss: 2.631578819199879

Epoch: 106| Step: 0
Training loss: 3.1096683536339187
Validation loss: 2.639678055211626

Epoch: 5| Step: 1
Training loss: 3.2777189601498895
Validation loss: 2.6090866292055623

Epoch: 5| Step: 2
Training loss: 3.1268108461833855
Validation loss: 2.578577422925604

Epoch: 5| Step: 3
Training loss: 3.395233397740762
Validation loss: 2.6479740417924953

Epoch: 5| Step: 4
Training loss: 2.873852376354621
Validation loss: 2.607767784307281

Epoch: 5| Step: 5
Training loss: 2.2556972428884836
Validation loss: 2.5900698094666743

Epoch: 5| Step: 6
Training loss: 1.940731000232088
Validation loss: 2.5757913706915367

Epoch: 5| Step: 7
Training loss: 3.3171467847297427
Validation loss: 2.59306042910936

Epoch: 5| Step: 8
Training loss: 3.103013628817547
Validation loss: 2.640225052937753

Epoch: 5| Step: 9
Training loss: 2.4964825681065967
Validation loss: 2.54009970608406

Epoch: 5| Step: 10
Training loss: 2.439816181419205
Validation loss: 2.582163720284379

Epoch: 107| Step: 0
Training loss: 2.997584960344314
Validation loss: 2.6036863774221097

Epoch: 5| Step: 1
Training loss: 2.421208443745388
Validation loss: 2.5986894014695037

Epoch: 5| Step: 2
Training loss: 3.1205895390206195
Validation loss: 2.639152034973063

Epoch: 5| Step: 3
Training loss: 2.7948675356953396
Validation loss: 2.5821751695344917

Epoch: 5| Step: 4
Training loss: 2.511624774984301
Validation loss: 2.61804083141303

Epoch: 5| Step: 5
Training loss: 2.1358922165240246
Validation loss: 2.6155100423231956

Epoch: 5| Step: 6
Training loss: 3.333478320465381
Validation loss: 2.693716950926771

Epoch: 5| Step: 7
Training loss: 2.502511384311204
Validation loss: 2.627718699808518

Epoch: 5| Step: 8
Training loss: 3.1557647029833675
Validation loss: 2.626421300934192

Epoch: 5| Step: 9
Training loss: 3.3529840757934437
Validation loss: 2.6371174400979687

Epoch: 5| Step: 10
Training loss: 2.8893076601294663
Validation loss: 2.677311411901987

Epoch: 108| Step: 0
Training loss: 2.910319278938118
Validation loss: 2.598321597510287

Epoch: 5| Step: 1
Training loss: 3.2832510523160088
Validation loss: 2.601815538517855

Epoch: 5| Step: 2
Training loss: 2.9123120816228814
Validation loss: 2.620705133728176

Epoch: 5| Step: 3
Training loss: 2.9315967086359205
Validation loss: 2.630804666865306

Epoch: 5| Step: 4
Training loss: 2.5745693772614713
Validation loss: 2.613785979079794

Epoch: 5| Step: 5
Training loss: 2.3523205520666806
Validation loss: 2.6492301395351774

Epoch: 5| Step: 6
Training loss: 2.974246267798151
Validation loss: 2.6112089569317845

Epoch: 5| Step: 7
Training loss: 2.6085995189949123
Validation loss: 2.6575368409802094

Epoch: 5| Step: 8
Training loss: 3.1113863626454767
Validation loss: 2.609581227682519

Epoch: 5| Step: 9
Training loss: 2.986846539524819
Validation loss: 2.6323731664053325

Epoch: 5| Step: 10
Training loss: 2.722251391308615
Validation loss: 2.6694920195451726

Epoch: 109| Step: 0
Training loss: 2.3807589327472263
Validation loss: 2.6416528561351016

Epoch: 5| Step: 1
Training loss: 2.825689542219309
Validation loss: 2.5800781061210474

Epoch: 5| Step: 2
Training loss: 2.406147744123942
Validation loss: 2.610343862781497

Epoch: 5| Step: 3
Training loss: 3.047195652448217
Validation loss: 2.5875596979463587

Epoch: 5| Step: 4
Training loss: 3.4247998144301657
Validation loss: 2.6230696589355484

Epoch: 5| Step: 5
Training loss: 3.5253296231304656
Validation loss: 2.5823774560684223

Epoch: 5| Step: 6
Training loss: 2.652996179623231
Validation loss: 2.6004410780156024

Epoch: 5| Step: 7
Training loss: 2.5062272715310883
Validation loss: 2.644323751798399

Epoch: 5| Step: 8
Training loss: 3.0799855452359357
Validation loss: 2.6339514606846595

Epoch: 5| Step: 9
Training loss: 2.9561890545424
Validation loss: 2.5493359569139264

Epoch: 5| Step: 10
Training loss: 2.54229802487512
Validation loss: 2.6089935043506842

Epoch: 110| Step: 0
Training loss: 2.5135741789119863
Validation loss: 2.6604042758563646

Epoch: 5| Step: 1
Training loss: 3.2207392499111083
Validation loss: 2.6351913533525035

Epoch: 5| Step: 2
Training loss: 2.7624833533704645
Validation loss: 2.5556830625467937

Epoch: 5| Step: 3
Training loss: 2.5329499364484485
Validation loss: 2.6438061932031074

Epoch: 5| Step: 4
Training loss: 3.2342947982206067
Validation loss: 2.605272335161431

Epoch: 5| Step: 5
Training loss: 1.8002901214337057
Validation loss: 2.5899683375562637

Epoch: 5| Step: 6
Training loss: 2.975542990234044
Validation loss: 2.592310617139476

Epoch: 5| Step: 7
Training loss: 2.743946695772037
Validation loss: 2.631218825009859

Epoch: 5| Step: 8
Training loss: 3.356251244571391
Validation loss: 2.6018647650185924

Epoch: 5| Step: 9
Training loss: 3.7134421800267545
Validation loss: 2.661936310518117

Epoch: 5| Step: 10
Training loss: 2.2017495481305023
Validation loss: 2.65502999148833

Epoch: 111| Step: 0
Training loss: 2.6753537915579804
Validation loss: 2.61303668639989

Epoch: 5| Step: 1
Training loss: 2.546260829896888
Validation loss: 2.6460555050095675

Epoch: 5| Step: 2
Training loss: 2.833983870229538
Validation loss: 2.613059304496195

Epoch: 5| Step: 3
Training loss: 3.017217976333733
Validation loss: 2.630114024756065

Epoch: 5| Step: 4
Training loss: 3.043685417351768
Validation loss: 2.590190563738575

Epoch: 5| Step: 5
Training loss: 3.0755037096770512
Validation loss: 2.5760801586746553

Epoch: 5| Step: 6
Training loss: 3.1318577098654643
Validation loss: 2.6061550269148706

Epoch: 5| Step: 7
Training loss: 2.9640180923280393
Validation loss: 2.644690036876404

Epoch: 5| Step: 8
Training loss: 2.273723361471116
Validation loss: 2.6174700527388075

Epoch: 5| Step: 9
Training loss: 2.8354658254771348
Validation loss: 2.6256573513704944

Epoch: 5| Step: 10
Training loss: 3.1686186212093754
Validation loss: 2.6285086220458265

Epoch: 112| Step: 0
Training loss: 2.160947906402885
Validation loss: 2.6241686745401154

Epoch: 5| Step: 1
Training loss: 3.2231299959550492
Validation loss: 2.63136133056801

Epoch: 5| Step: 2
Training loss: 2.9673371818115855
Validation loss: 2.628187407634113

Epoch: 5| Step: 3
Training loss: 2.2692204851914672
Validation loss: 2.688080728015647

Epoch: 5| Step: 4
Training loss: 2.4436632145840056
Validation loss: 2.63690121328141

Epoch: 5| Step: 5
Training loss: 3.5124695583123975
Validation loss: 2.574026851630422

Epoch: 5| Step: 6
Training loss: 3.101855670131613
Validation loss: 2.5567123638789804

Epoch: 5| Step: 7
Training loss: 2.9103325502386346
Validation loss: 2.6167252405556565

Epoch: 5| Step: 8
Training loss: 2.6700744808538364
Validation loss: 2.5741167687673787

Epoch: 5| Step: 9
Training loss: 2.580807117217739
Validation loss: 2.6308267648322374

Epoch: 5| Step: 10
Training loss: 2.823332883736471
Validation loss: 2.6430756105686632

Epoch: 113| Step: 0
Training loss: 3.090761841617157
Validation loss: 2.6442270881815952

Epoch: 5| Step: 1
Training loss: 2.5749369011712555
Validation loss: 2.5470213599836127

Epoch: 5| Step: 2
Training loss: 2.6636201821337835
Validation loss: 2.637448482674167

Epoch: 5| Step: 3
Training loss: 3.5692461620891853
Validation loss: 2.5295431848525154

Epoch: 5| Step: 4
Training loss: 2.752214840315377
Validation loss: 2.5598899445579573

Epoch: 5| Step: 5
Training loss: 3.1846258631788653
Validation loss: 2.596564045237441

Epoch: 5| Step: 6
Training loss: 2.858558246301369
Validation loss: 2.57224869390625

Epoch: 5| Step: 7
Training loss: 2.9406401711862067
Validation loss: 2.613397700486223

Epoch: 5| Step: 8
Training loss: 2.5785882706992207
Validation loss: 2.615319000499512

Epoch: 5| Step: 9
Training loss: 2.208106395169054
Validation loss: 2.5946256699075803

Epoch: 5| Step: 10
Training loss: 3.137052715380267
Validation loss: 2.5441205437357364

Epoch: 114| Step: 0
Training loss: 2.9728492142836136
Validation loss: 2.6611973426824433

Epoch: 5| Step: 1
Training loss: 2.742779094644303
Validation loss: 2.5990043202211814

Epoch: 5| Step: 2
Training loss: 2.6647760325036254
Validation loss: 2.5766282217314473

Epoch: 5| Step: 3
Training loss: 2.686980175045973
Validation loss: 2.5860704492473174

Epoch: 5| Step: 4
Training loss: 2.58712750393533
Validation loss: 2.5968030985630657

Epoch: 5| Step: 5
Training loss: 3.01086350306995
Validation loss: 2.6646442249130575

Epoch: 5| Step: 6
Training loss: 2.957964126400334
Validation loss: 2.609947232723636

Epoch: 5| Step: 7
Training loss: 2.8428284545732527
Validation loss: 2.639827107011643

Epoch: 5| Step: 8
Training loss: 2.48434486610803
Validation loss: 2.613986671636158

Epoch: 5| Step: 9
Training loss: 2.632073182575636
Validation loss: 2.6414216979155465

Epoch: 5| Step: 10
Training loss: 3.5076886603366044
Validation loss: 2.5360494850435056

Epoch: 115| Step: 0
Training loss: 2.9586891354359084
Validation loss: 2.603898313088178

Epoch: 5| Step: 1
Training loss: 2.671236285333767
Validation loss: 2.6065358433235732

Epoch: 5| Step: 2
Training loss: 2.700466634904814
Validation loss: 2.6126198064196435

Epoch: 5| Step: 3
Training loss: 2.960224156269063
Validation loss: 2.6329851361383714

Epoch: 5| Step: 4
Training loss: 3.06526308557903
Validation loss: 2.612064709624079

Epoch: 5| Step: 5
Training loss: 3.149445705994133
Validation loss: 2.5531706538983325

Epoch: 5| Step: 6
Training loss: 3.1801694462574126
Validation loss: 2.568549268441662

Epoch: 5| Step: 7
Training loss: 2.653703523607118
Validation loss: 2.6069668553359784

Epoch: 5| Step: 8
Training loss: 2.201799792245943
Validation loss: 2.6309657184652977

Epoch: 5| Step: 9
Training loss: 2.7072595277125955
Validation loss: 2.7008090013460584

Epoch: 5| Step: 10
Training loss: 3.407660655924392
Validation loss: 2.6249778031730617

Epoch: 116| Step: 0
Training loss: 2.52190435267198
Validation loss: 2.657072478711761

Epoch: 5| Step: 1
Training loss: 2.710224156698708
Validation loss: 2.653480976227335

Epoch: 5| Step: 2
Training loss: 2.3698357099415683
Validation loss: 2.6146960533039043

Epoch: 5| Step: 3
Training loss: 2.41059146951742
Validation loss: 2.5875279737405648

Epoch: 5| Step: 4
Training loss: 3.0751456931730443
Validation loss: 2.6205803287448877

Epoch: 5| Step: 5
Training loss: 2.6535958886554876
Validation loss: 2.6099827558298023

Epoch: 5| Step: 6
Training loss: 3.490548177913668
Validation loss: 2.619701864353562

Epoch: 5| Step: 7
Training loss: 2.8261408299953485
Validation loss: 2.655698416164322

Epoch: 5| Step: 8
Training loss: 3.230117280561063
Validation loss: 2.5711434777074076

Epoch: 5| Step: 9
Training loss: 3.189624900887535
Validation loss: 2.568244976014898

Epoch: 5| Step: 10
Training loss: 2.8904021306080465
Validation loss: 2.543045759811029

Epoch: 117| Step: 0
Training loss: 2.52747147722309
Validation loss: 2.654783780655812

Epoch: 5| Step: 1
Training loss: 2.704486746475037
Validation loss: 2.662846523352589

Epoch: 5| Step: 2
Training loss: 2.9735964116717044
Validation loss: 2.6555246664553294

Epoch: 5| Step: 3
Training loss: 2.558902541301905
Validation loss: 2.622642372466545

Epoch: 5| Step: 4
Training loss: 2.7939706565883453
Validation loss: 2.5964247661379702

Epoch: 5| Step: 5
Training loss: 2.9314875654893457
Validation loss: 2.5943154999637943

Epoch: 5| Step: 6
Training loss: 2.8224458102353513
Validation loss: 2.6771112760325093

Epoch: 5| Step: 7
Training loss: 2.7107691643859035
Validation loss: 2.6556263605953787

Epoch: 5| Step: 8
Training loss: 2.7607721543684445
Validation loss: 2.568384330943624

Epoch: 5| Step: 9
Training loss: 3.6107402382834706
Validation loss: 2.59115955342761

Epoch: 5| Step: 10
Training loss: 2.814675655210892
Validation loss: 2.6022699831519724

Epoch: 118| Step: 0
Training loss: 3.170576609688344
Validation loss: 2.6263207171444773

Epoch: 5| Step: 1
Training loss: 2.881129820462521
Validation loss: 2.5488312279265837

Epoch: 5| Step: 2
Training loss: 3.27690359804144
Validation loss: 2.582024480552587

Epoch: 5| Step: 3
Training loss: 2.242585469193851
Validation loss: 2.632137889504476

Epoch: 5| Step: 4
Training loss: 3.1680334721925867
Validation loss: 2.6016882813327364

Epoch: 5| Step: 5
Training loss: 3.0030529065166967
Validation loss: 2.5974899156084845

Epoch: 5| Step: 6
Training loss: 2.458664780164369
Validation loss: 2.627573353608995

Epoch: 5| Step: 7
Training loss: 2.89723135228566
Validation loss: 2.610136667988252

Epoch: 5| Step: 8
Training loss: 2.6555032914718946
Validation loss: 2.5850719647470184

Epoch: 5| Step: 9
Training loss: 2.8458787265655503
Validation loss: 2.5976245938337614

Epoch: 5| Step: 10
Training loss: 2.8986054651993087
Validation loss: 2.5651987202775453

Epoch: 119| Step: 0
Training loss: 3.0199503342542413
Validation loss: 2.5981886712916555

Epoch: 5| Step: 1
Training loss: 3.098852708229258
Validation loss: 2.562805287653643

Epoch: 5| Step: 2
Training loss: 3.1761699593467503
Validation loss: 2.5987566571031344

Epoch: 5| Step: 3
Training loss: 3.1370978595425867
Validation loss: 2.629229276971293

Epoch: 5| Step: 4
Training loss: 3.070929001897045
Validation loss: 2.66739664802412

Epoch: 5| Step: 5
Training loss: 2.4973252292765653
Validation loss: 2.6778343631211743

Epoch: 5| Step: 6
Training loss: 2.458170179567287
Validation loss: 2.598548459481013

Epoch: 5| Step: 7
Training loss: 2.3271362458044575
Validation loss: 2.627657625627015

Epoch: 5| Step: 8
Training loss: 3.013336103601223
Validation loss: 2.547575314245253

Epoch: 5| Step: 9
Training loss: 2.95777809054536
Validation loss: 2.6200657383983934

Epoch: 5| Step: 10
Training loss: 2.5692031460660356
Validation loss: 2.567992557935256

Epoch: 120| Step: 0
Training loss: 3.3231743181524687
Validation loss: 2.6067456167810823

Epoch: 5| Step: 1
Training loss: 2.593098662070946
Validation loss: 2.539264017064191

Epoch: 5| Step: 2
Training loss: 3.333364025610447
Validation loss: 2.6167183707966717

Epoch: 5| Step: 3
Training loss: 3.3447746061786727
Validation loss: 2.6549829596602637

Epoch: 5| Step: 4
Training loss: 2.808595787334101
Validation loss: 2.5732181135506473

Epoch: 5| Step: 5
Training loss: 2.1683969435669765
Validation loss: 2.6416897783180326

Epoch: 5| Step: 6
Training loss: 2.7849751931255082
Validation loss: 2.629214006605587

Epoch: 5| Step: 7
Training loss: 2.413663664527729
Validation loss: 2.5887013064243267

Epoch: 5| Step: 8
Training loss: 2.35027828192151
Validation loss: 2.622029476886994

Epoch: 5| Step: 9
Training loss: 3.1145823977329714
Validation loss: 2.6398037762508424

Epoch: 5| Step: 10
Training loss: 2.8532407237856137
Validation loss: 2.562774206337558

Epoch: 121| Step: 0
Training loss: 2.7954720329532767
Validation loss: 2.640220883489558

Epoch: 5| Step: 1
Training loss: 3.006095098680275
Validation loss: 2.594896127795054

Epoch: 5| Step: 2
Training loss: 3.3299310646138855
Validation loss: 2.577784979539624

Epoch: 5| Step: 3
Training loss: 2.518506313301672
Validation loss: 2.6111826057423606

Epoch: 5| Step: 4
Training loss: 2.884978186460435
Validation loss: 2.5868135490182946

Epoch: 5| Step: 5
Training loss: 2.773365976190417
Validation loss: 2.615847918897894

Epoch: 5| Step: 6
Training loss: 2.8308203903889066
Validation loss: 2.521619773911144

Epoch: 5| Step: 7
Training loss: 2.9202587532988
Validation loss: 2.6142535761402708

Epoch: 5| Step: 8
Training loss: 2.97039171300873
Validation loss: 2.5451641354500176

Epoch: 5| Step: 9
Training loss: 2.517686934742541
Validation loss: 2.618276048342777

Epoch: 5| Step: 10
Training loss: 2.8046013864032426
Validation loss: 2.578859852819693

Epoch: 122| Step: 0
Training loss: 3.3933307030398425
Validation loss: 2.5933950670353045

Epoch: 5| Step: 1
Training loss: 2.8083442502889677
Validation loss: 2.63683720318434

Epoch: 5| Step: 2
Training loss: 2.297079894599945
Validation loss: 2.6775478973276066

Epoch: 5| Step: 3
Training loss: 3.1775401969906234
Validation loss: 2.639235825572413

Epoch: 5| Step: 4
Training loss: 2.6263113833357172
Validation loss: 2.6328063796317838

Epoch: 5| Step: 5
Training loss: 3.204599329620369
Validation loss: 2.6881282860876023

Epoch: 5| Step: 6
Training loss: 3.4823728548323545
Validation loss: 2.6904911738541726

Epoch: 5| Step: 7
Training loss: 2.786961381133438
Validation loss: 2.6197298668471714

Epoch: 5| Step: 8
Training loss: 2.350387025982214
Validation loss: 2.5590748659989093

Epoch: 5| Step: 9
Training loss: 2.364724164849671
Validation loss: 2.626137452351599

Epoch: 5| Step: 10
Training loss: 1.9737258277654666
Validation loss: 2.6404024124868255

Epoch: 123| Step: 0
Training loss: 2.9316300526021055
Validation loss: 2.616583475623629

Epoch: 5| Step: 1
Training loss: 2.544517315131574
Validation loss: 2.618461007877683

Epoch: 5| Step: 2
Training loss: 2.4766295029875502
Validation loss: 2.612925087746035

Epoch: 5| Step: 3
Training loss: 2.992312914259346
Validation loss: 2.527114527848063

Epoch: 5| Step: 4
Training loss: 3.3999411577855003
Validation loss: 2.610146657786612

Epoch: 5| Step: 5
Training loss: 2.6713140244547318
Validation loss: 2.5721422720351486

Epoch: 5| Step: 6
Training loss: 2.810968957187447
Validation loss: 2.6327894936514884

Epoch: 5| Step: 7
Training loss: 2.4035373606784742
Validation loss: 2.6451789570615367

Epoch: 5| Step: 8
Training loss: 2.403572376212976
Validation loss: 2.586566573549

Epoch: 5| Step: 9
Training loss: 3.0857681421091034
Validation loss: 2.6278421404443812

Epoch: 5| Step: 10
Training loss: 3.230190205125931
Validation loss: 2.574320560885482

Epoch: 124| Step: 0
Training loss: 3.368315824085338
Validation loss: 2.5896669717652823

Epoch: 5| Step: 1
Training loss: 2.5039046312823845
Validation loss: 2.598087135592444

Epoch: 5| Step: 2
Training loss: 3.118692823356067
Validation loss: 2.540472559742551

Epoch: 5| Step: 3
Training loss: 2.9398463192172537
Validation loss: 2.6242655152828456

Epoch: 5| Step: 4
Training loss: 3.2862937309689855
Validation loss: 2.6261605696894326

Epoch: 5| Step: 5
Training loss: 1.6520034042720495
Validation loss: 2.6124953030724924

Epoch: 5| Step: 6
Training loss: 3.172715249601469
Validation loss: 2.572299969223893

Epoch: 5| Step: 7
Training loss: 2.2359116612080348
Validation loss: 2.592676394445035

Epoch: 5| Step: 8
Training loss: 2.848128584423576
Validation loss: 2.571869510067679

Epoch: 5| Step: 9
Training loss: 2.8253105870558866
Validation loss: 2.5488042026670596

Epoch: 5| Step: 10
Training loss: 2.707350674894068
Validation loss: 2.558980965044336

Epoch: 125| Step: 0
Training loss: 2.352065225896973
Validation loss: 2.588831351876658

Epoch: 5| Step: 1
Training loss: 2.498851989374526
Validation loss: 2.612997318142481

Epoch: 5| Step: 2
Training loss: 2.808934134069978
Validation loss: 2.648652558544877

Epoch: 5| Step: 3
Training loss: 3.001583476194355
Validation loss: 2.5705452910928277

Epoch: 5| Step: 4
Training loss: 2.843797285085072
Validation loss: 2.6300854617163725

Epoch: 5| Step: 5
Training loss: 2.4759960790365847
Validation loss: 2.6080858930639774

Epoch: 5| Step: 6
Training loss: 3.13696850534133
Validation loss: 2.5235968926480923

Epoch: 5| Step: 7
Training loss: 2.9014447592499506
Validation loss: 2.634006427564791

Epoch: 5| Step: 8
Training loss: 3.4115732576459727
Validation loss: 2.558496224151678

Epoch: 5| Step: 9
Training loss: 2.741906219575984
Validation loss: 2.599876374996478

Epoch: 5| Step: 10
Training loss: 2.467180453309136
Validation loss: 2.63996235852878

Epoch: 126| Step: 0
Training loss: 3.0090467422521217
Validation loss: 2.6423156417290654

Epoch: 5| Step: 1
Training loss: 2.8217384347578096
Validation loss: 2.6240506015467338

Epoch: 5| Step: 2
Training loss: 2.790116653191319
Validation loss: 2.5708049191895608

Epoch: 5| Step: 3
Training loss: 3.1611346226245978
Validation loss: 2.5843207307873435

Epoch: 5| Step: 4
Training loss: 2.6173523808254395
Validation loss: 2.5596222925023038

Epoch: 5| Step: 5
Training loss: 2.848126910210899
Validation loss: 2.593605870713518

Epoch: 5| Step: 6
Training loss: 3.069507755491579
Validation loss: 2.583981549420793

Epoch: 5| Step: 7
Training loss: 2.912296363358686
Validation loss: 2.6645652934779127

Epoch: 5| Step: 8
Training loss: 2.6391541487125196
Validation loss: 2.6074656028532845

Epoch: 5| Step: 9
Training loss: 2.6725335452880095
Validation loss: 2.600032043969498

Epoch: 5| Step: 10
Training loss: 2.232151979700248
Validation loss: 2.5508834827676883

Epoch: 127| Step: 0
Training loss: 1.8693587954120785
Validation loss: 2.6101968861215856

Epoch: 5| Step: 1
Training loss: 2.7803127981440654
Validation loss: 2.569229358058039

Epoch: 5| Step: 2
Training loss: 2.847482935022892
Validation loss: 2.5156340392851013

Epoch: 5| Step: 3
Training loss: 2.9119215558668423
Validation loss: 2.5696600489762167

Epoch: 5| Step: 4
Training loss: 3.064863577415632
Validation loss: 2.6033728162761345

Epoch: 5| Step: 5
Training loss: 3.278194203478155
Validation loss: 2.634896107603442

Epoch: 5| Step: 6
Training loss: 3.1294173491156925
Validation loss: 2.6535864778526523

Epoch: 5| Step: 7
Training loss: 2.385235064616601
Validation loss: 2.6283060087775665

Epoch: 5| Step: 8
Training loss: 2.8158314789013956
Validation loss: 2.5788907198895252

Epoch: 5| Step: 9
Training loss: 2.8340242515823904
Validation loss: 2.5881928404700494

Epoch: 5| Step: 10
Training loss: 2.8539567485010093
Validation loss: 2.616643506693456

Epoch: 128| Step: 0
Training loss: 2.4145802556814524
Validation loss: 2.6000763259945594

Epoch: 5| Step: 1
Training loss: 3.102364001739962
Validation loss: 2.5730398393647556

Epoch: 5| Step: 2
Training loss: 3.0145207888730594
Validation loss: 2.5844672154558586

Epoch: 5| Step: 3
Training loss: 3.035314607355389
Validation loss: 2.6401062725487785

Epoch: 5| Step: 4
Training loss: 2.3934423263865727
Validation loss: 2.617304891354359

Epoch: 5| Step: 5
Training loss: 2.8481568784689717
Validation loss: 2.6030007359038

Epoch: 5| Step: 6
Training loss: 3.3018821550732564
Validation loss: 2.5888143587968826

Epoch: 5| Step: 7
Training loss: 2.7156635171948396
Validation loss: 2.6585475204896807

Epoch: 5| Step: 8
Training loss: 2.465283724877672
Validation loss: 2.5948378155651555

Epoch: 5| Step: 9
Training loss: 2.4033401531840513
Validation loss: 2.5932047419441817

Epoch: 5| Step: 10
Training loss: 2.72838559997991
Validation loss: 2.6206342896786596

Epoch: 129| Step: 0
Training loss: 2.2461767562787167
Validation loss: 2.57804211992607

Epoch: 5| Step: 1
Training loss: 2.6365620432309944
Validation loss: 2.604169642949198

Epoch: 5| Step: 2
Training loss: 2.720077891917462
Validation loss: 2.667404348363377

Epoch: 5| Step: 3
Training loss: 3.4899176745829137
Validation loss: 2.592356971327264

Epoch: 5| Step: 4
Training loss: 2.8527090615532744
Validation loss: 2.575250618631178

Epoch: 5| Step: 5
Training loss: 2.470850762943164
Validation loss: 2.6124738537374514

Epoch: 5| Step: 6
Training loss: 2.5498034719393408
Validation loss: 2.5722119315812777

Epoch: 5| Step: 7
Training loss: 2.311225024140474
Validation loss: 2.636142875955483

Epoch: 5| Step: 8
Training loss: 2.853517128945959
Validation loss: 2.604598473629811

Epoch: 5| Step: 9
Training loss: 3.4355996167426874
Validation loss: 2.588974698325388

Epoch: 5| Step: 10
Training loss: 3.213078214508453
Validation loss: 2.573604955166815

Epoch: 130| Step: 0
Training loss: 2.8167788699522496
Validation loss: 2.5867000841238763

Epoch: 5| Step: 1
Training loss: 2.8504775400125015
Validation loss: 2.5662729463401073

Epoch: 5| Step: 2
Training loss: 3.2365034535903927
Validation loss: 2.5540570507293383

Epoch: 5| Step: 3
Training loss: 2.512028652787045
Validation loss: 2.6170305592244616

Epoch: 5| Step: 4
Training loss: 3.5952445198273555
Validation loss: 2.5946570435233935

Epoch: 5| Step: 5
Training loss: 3.1474938126094925
Validation loss: 2.5752035413980305

Epoch: 5| Step: 6
Training loss: 2.3446489771693666
Validation loss: 2.6086431376775976

Epoch: 5| Step: 7
Training loss: 2.3440364408296857
Validation loss: 2.5780374929145524

Epoch: 5| Step: 8
Training loss: 2.7451821519349577
Validation loss: 2.590420725770935

Epoch: 5| Step: 9
Training loss: 2.639717623318709
Validation loss: 2.598692722069827

Epoch: 5| Step: 10
Training loss: 2.322601114459745
Validation loss: 2.6070800724363905

Epoch: 131| Step: 0
Training loss: 3.382166706138654
Validation loss: 2.632655610377557

Epoch: 5| Step: 1
Training loss: 2.9608708276011058
Validation loss: 2.649570436811643

Epoch: 5| Step: 2
Training loss: 3.3113975849721333
Validation loss: 2.588985538182303

Epoch: 5| Step: 3
Training loss: 2.5380123842567004
Validation loss: 2.5743069605075117

Epoch: 5| Step: 4
Training loss: 2.8819694630304196
Validation loss: 2.5971781885746

Epoch: 5| Step: 5
Training loss: 2.270366679081357
Validation loss: 2.5553747800984126

Epoch: 5| Step: 6
Training loss: 2.4758108063242954
Validation loss: 2.573522987447324

Epoch: 5| Step: 7
Training loss: 3.3821550043048783
Validation loss: 2.6583857468046297

Epoch: 5| Step: 8
Training loss: 2.5086560123098076
Validation loss: 2.6100816011290444

Epoch: 5| Step: 9
Training loss: 2.170036251099323
Validation loss: 2.578144833863534

Epoch: 5| Step: 10
Training loss: 3.064260327198758
Validation loss: 2.5970582063743644

Epoch: 132| Step: 0
Training loss: 2.5372767345505793
Validation loss: 2.60497913968147

Epoch: 5| Step: 1
Training loss: 2.710592902101016
Validation loss: 2.5356531619869864

Epoch: 5| Step: 2
Training loss: 2.643054724638766
Validation loss: 2.6332113025355874

Epoch: 5| Step: 3
Training loss: 2.751998608594365
Validation loss: 2.5222316949326253

Epoch: 5| Step: 4
Training loss: 2.497381937560457
Validation loss: 2.556324871390964

Epoch: 5| Step: 5
Training loss: 2.863778480977597
Validation loss: 2.6433783579961703

Epoch: 5| Step: 6
Training loss: 3.0195580958743533
Validation loss: 2.5897969123028632

Epoch: 5| Step: 7
Training loss: 2.8986309634726433
Validation loss: 2.6333925748583824

Epoch: 5| Step: 8
Training loss: 3.102013543144289
Validation loss: 2.6048035470848476

Epoch: 5| Step: 9
Training loss: 2.8769179870987265
Validation loss: 2.6482694326115492

Epoch: 5| Step: 10
Training loss: 3.0783164647384904
Validation loss: 2.622719074045812

Epoch: 133| Step: 0
Training loss: 2.5238595143137315
Validation loss: 2.6244593052210354

Epoch: 5| Step: 1
Training loss: 2.891905794690797
Validation loss: 2.5814392365308625

Epoch: 5| Step: 2
Training loss: 3.181882358498308
Validation loss: 2.6323761056022588

Epoch: 5| Step: 3
Training loss: 2.693621649638298
Validation loss: 2.5814401591253944

Epoch: 5| Step: 4
Training loss: 3.395936664031124
Validation loss: 2.6154286831490676

Epoch: 5| Step: 5
Training loss: 3.0990588943877446
Validation loss: 2.624348681228633

Epoch: 5| Step: 6
Training loss: 2.265925315158139
Validation loss: 2.582482326459681

Epoch: 5| Step: 7
Training loss: 1.9261121484938097
Validation loss: 2.651547508654925

Epoch: 5| Step: 8
Training loss: 2.907541295789064
Validation loss: 2.5679680414361483

Epoch: 5| Step: 9
Training loss: 2.4875723938495407
Validation loss: 2.5680200790688805

Epoch: 5| Step: 10
Training loss: 3.015752918119615
Validation loss: 2.577302759732561

Epoch: 134| Step: 0
Training loss: 2.1703692369068723
Validation loss: 2.635836934033996

Epoch: 5| Step: 1
Training loss: 2.6696136899503937
Validation loss: 2.624762557073268

Epoch: 5| Step: 2
Training loss: 3.6560384575054443
Validation loss: 2.555555947829697

Epoch: 5| Step: 3
Training loss: 2.5737098572885784
Validation loss: 2.581407202731945

Epoch: 5| Step: 4
Training loss: 2.743514736925037
Validation loss: 2.5853610696086915

Epoch: 5| Step: 5
Training loss: 2.779937949002671
Validation loss: 2.627591978079588

Epoch: 5| Step: 6
Training loss: 2.76958686116373
Validation loss: 2.627668189805822

Epoch: 5| Step: 7
Training loss: 3.074980237943834
Validation loss: 2.5513739434753786

Epoch: 5| Step: 8
Training loss: 2.6606394683179255
Validation loss: 2.5721799308729705

Epoch: 5| Step: 9
Training loss: 2.990744937735877
Validation loss: 2.621600861103267

Epoch: 5| Step: 10
Training loss: 3.0139487554070534
Validation loss: 2.6164329571268543

Epoch: 135| Step: 0
Training loss: 3.08147685548681
Validation loss: 2.566619842681772

Epoch: 5| Step: 1
Training loss: 2.854003196174527
Validation loss: 2.6512909472704056

Epoch: 5| Step: 2
Training loss: 2.5951750184356075
Validation loss: 2.6168625339819394

Epoch: 5| Step: 3
Training loss: 3.1665820227570523
Validation loss: 2.6019972108176495

Epoch: 5| Step: 4
Training loss: 2.2337883666019835
Validation loss: 2.6470127908469596

Epoch: 5| Step: 5
Training loss: 3.4051535705351417
Validation loss: 2.67325056688813

Epoch: 5| Step: 6
Training loss: 2.860478422790666
Validation loss: 2.618286248931111

Epoch: 5| Step: 7
Training loss: 2.738039972012129
Validation loss: 2.589853722055666

Epoch: 5| Step: 8
Training loss: 2.4124996718964824
Validation loss: 2.6380560516188902

Epoch: 5| Step: 9
Training loss: 2.8749621844914515
Validation loss: 2.618281107518403

Epoch: 5| Step: 10
Training loss: 2.6689420072644645
Validation loss: 2.6305730796862323

Epoch: 136| Step: 0
Training loss: 2.384161895388065
Validation loss: 2.605906807273473

Epoch: 5| Step: 1
Training loss: 2.724584173270543
Validation loss: 2.611990410959433

Epoch: 5| Step: 2
Training loss: 3.0133636376311532
Validation loss: 2.6069731646982857

Epoch: 5| Step: 3
Training loss: 3.416824166614238
Validation loss: 2.613579402438907

Epoch: 5| Step: 4
Training loss: 3.138139186964577
Validation loss: 2.6844621637130537

Epoch: 5| Step: 5
Training loss: 2.593142794577666
Validation loss: 2.630359032179106

Epoch: 5| Step: 6
Training loss: 3.2019479961663664
Validation loss: 2.5928631919733487

Epoch: 5| Step: 7
Training loss: 2.041911739769629
Validation loss: 2.6372248265336395

Epoch: 5| Step: 8
Training loss: 2.8866668820399437
Validation loss: 2.5926494840901104

Epoch: 5| Step: 9
Training loss: 2.6170864712018598
Validation loss: 2.584416433992868

Epoch: 5| Step: 10
Training loss: 2.3363509306681927
Validation loss: 2.670716546036942

Epoch: 137| Step: 0
Training loss: 2.982967504167689
Validation loss: 2.61799797349548

Epoch: 5| Step: 1
Training loss: 2.85293270269446
Validation loss: 2.6361949594546066

Epoch: 5| Step: 2
Training loss: 2.604649999905799
Validation loss: 2.6058788480780346

Epoch: 5| Step: 3
Training loss: 2.268972725352501
Validation loss: 2.554283755188347

Epoch: 5| Step: 4
Training loss: 2.341058533553921
Validation loss: 2.646959278561464

Epoch: 5| Step: 5
Training loss: 2.5301875957855264
Validation loss: 2.668090323642004

Epoch: 5| Step: 6
Training loss: 2.653558242345553
Validation loss: 2.5673025853532057

Epoch: 5| Step: 7
Training loss: 3.1823380503835454
Validation loss: 2.5514865869854293

Epoch: 5| Step: 8
Training loss: 2.779488166236287
Validation loss: 2.575298586947849

Epoch: 5| Step: 9
Training loss: 3.4157283393883913
Validation loss: 2.6261765753077695

Epoch: 5| Step: 10
Training loss: 3.314971146033649
Validation loss: 2.6456236914095483

Epoch: 138| Step: 0
Training loss: 2.1554013116234176
Validation loss: 2.598404082327695

Epoch: 5| Step: 1
Training loss: 3.0847667936100893
Validation loss: 2.5614701729578218

Epoch: 5| Step: 2
Training loss: 3.127128639037008
Validation loss: 2.571918234207995

Epoch: 5| Step: 3
Training loss: 3.4607776751330355
Validation loss: 2.6339463211375627

Epoch: 5| Step: 4
Training loss: 2.655459297524733
Validation loss: 2.6034100516688516

Epoch: 5| Step: 5
Training loss: 3.279216317782875
Validation loss: 2.5740323523392012

Epoch: 5| Step: 6
Training loss: 3.139838732326017
Validation loss: 2.5281017742953176

Epoch: 5| Step: 7
Training loss: 2.369755626586068
Validation loss: 2.590147145029711

Epoch: 5| Step: 8
Training loss: 2.599926866823294
Validation loss: 2.628765903133572

Epoch: 5| Step: 9
Training loss: 2.029725309494054
Validation loss: 2.5753335537008626

Epoch: 5| Step: 10
Training loss: 2.3200075096798076
Validation loss: 2.6528722385848518

Epoch: 139| Step: 0
Training loss: 2.7385299069072424
Validation loss: 2.59467125059861

Epoch: 5| Step: 1
Training loss: 2.435201784111452
Validation loss: 2.653227312095253

Epoch: 5| Step: 2
Training loss: 2.670766410842206
Validation loss: 2.5671735454285387

Epoch: 5| Step: 3
Training loss: 3.3681959160116706
Validation loss: 2.6580323485738675

Epoch: 5| Step: 4
Training loss: 2.795388791198376
Validation loss: 2.623850771578318

Epoch: 5| Step: 5
Training loss: 2.8608391353712426
Validation loss: 2.573267675912054

Epoch: 5| Step: 6
Training loss: 2.9624842325426757
Validation loss: 2.6099449568316686

Epoch: 5| Step: 7
Training loss: 2.773843225164856
Validation loss: 2.58449431863101

Epoch: 5| Step: 8
Training loss: 2.4333273556605386
Validation loss: 2.63010137473106

Epoch: 5| Step: 9
Training loss: 2.764166409624065
Validation loss: 2.5964655502615073

Epoch: 5| Step: 10
Training loss: 3.008336881034922
Validation loss: 2.5965997326751475

Epoch: 140| Step: 0
Training loss: 3.165669652354673
Validation loss: 2.6001706841940746

Epoch: 5| Step: 1
Training loss: 2.165493268386782
Validation loss: 2.586350060622146

Epoch: 5| Step: 2
Training loss: 3.4151595598648004
Validation loss: 2.620933922864187

Epoch: 5| Step: 3
Training loss: 3.364861129457236
Validation loss: 2.581895543913728

Epoch: 5| Step: 4
Training loss: 2.8672320702853904
Validation loss: 2.6830569879799624

Epoch: 5| Step: 5
Training loss: 2.996318147255928
Validation loss: 2.588224686282195

Epoch: 5| Step: 6
Training loss: 2.364584319216709
Validation loss: 2.584634631430524

Epoch: 5| Step: 7
Training loss: 2.4654560567900305
Validation loss: 2.5729526684816975

Epoch: 5| Step: 8
Training loss: 3.3660614892394376
Validation loss: 2.5134114221986836

Epoch: 5| Step: 9
Training loss: 1.8195063561865474
Validation loss: 2.5609029579857516

Epoch: 5| Step: 10
Training loss: 2.3621825635676523
Validation loss: 2.5913743141238927

Epoch: 141| Step: 0
Training loss: 2.620199446039161
Validation loss: 2.5943400807284323

Epoch: 5| Step: 1
Training loss: 2.5801182295449516
Validation loss: 2.5827745535568716

Epoch: 5| Step: 2
Training loss: 3.398773948413897
Validation loss: 2.5762420241467323

Epoch: 5| Step: 3
Training loss: 2.4286229785288573
Validation loss: 2.636247474668695

Epoch: 5| Step: 4
Training loss: 2.885348230828815
Validation loss: 2.570939288164143

Epoch: 5| Step: 5
Training loss: 2.7931733596654498
Validation loss: 2.6010899603471507

Epoch: 5| Step: 6
Training loss: 3.3850510306857533
Validation loss: 2.5597698174936365

Epoch: 5| Step: 7
Training loss: 2.471186919962955
Validation loss: 2.6087709881841326

Epoch: 5| Step: 8
Training loss: 3.1384451973606193
Validation loss: 2.5764136995406877

Epoch: 5| Step: 9
Training loss: 2.649462386244936
Validation loss: 2.6152728082359653

Epoch: 5| Step: 10
Training loss: 2.425066905720933
Validation loss: 2.641381629287797

Epoch: 142| Step: 0
Training loss: 2.97443784643743
Validation loss: 2.627465345858362

Epoch: 5| Step: 1
Training loss: 3.041257403984418
Validation loss: 2.6150825093264918

Epoch: 5| Step: 2
Training loss: 2.2858148131232765
Validation loss: 2.624229462601819

Epoch: 5| Step: 3
Training loss: 2.6806750910519948
Validation loss: 2.5333466287705515

Epoch: 5| Step: 4
Training loss: 2.7793844588547465
Validation loss: 2.63310481804162

Epoch: 5| Step: 5
Training loss: 1.9717771478667687
Validation loss: 2.589181836999333

Epoch: 5| Step: 6
Training loss: 2.8244656656683413
Validation loss: 2.629293803305926

Epoch: 5| Step: 7
Training loss: 3.6943154149162325
Validation loss: 2.600765450209974

Epoch: 5| Step: 8
Training loss: 2.6641904738667765
Validation loss: 2.6192464928910804

Epoch: 5| Step: 9
Training loss: 2.381534321148624
Validation loss: 2.5654126253501457

Epoch: 5| Step: 10
Training loss: 3.1819363076712674
Validation loss: 2.5670318667586147

Epoch: 143| Step: 0
Training loss: 2.391139455055721
Validation loss: 2.620354355754604

Epoch: 5| Step: 1
Training loss: 2.1180224584554064
Validation loss: 2.547401444778087

Epoch: 5| Step: 2
Training loss: 2.8253250171412367
Validation loss: 2.575900431462882

Epoch: 5| Step: 3
Training loss: 2.9544301857504003
Validation loss: 2.5702531457820212

Epoch: 5| Step: 4
Training loss: 2.859345983139142
Validation loss: 2.5945027110811494

Epoch: 5| Step: 5
Training loss: 3.017624898504811
Validation loss: 2.612791070641474

Epoch: 5| Step: 6
Training loss: 2.6026184871499205
Validation loss: 2.583736255938871

Epoch: 5| Step: 7
Training loss: 3.033752981089356
Validation loss: 2.5767881744098284

Epoch: 5| Step: 8
Training loss: 2.7711430044343417
Validation loss: 2.550107402377474

Epoch: 5| Step: 9
Training loss: 3.3129840713058183
Validation loss: 2.58716053312468

Epoch: 5| Step: 10
Training loss: 2.961310290217614
Validation loss: 2.5612061338163943

Epoch: 144| Step: 0
Training loss: 2.621139412267589
Validation loss: 2.59748203860122

Epoch: 5| Step: 1
Training loss: 2.861880346136188
Validation loss: 2.5562284805118547

Epoch: 5| Step: 2
Training loss: 3.0156414446604733
Validation loss: 2.590915555466387

Epoch: 5| Step: 3
Training loss: 2.7100328150659228
Validation loss: 2.643821415648973

Epoch: 5| Step: 4
Training loss: 2.5234169029127473
Validation loss: 2.602110612126387

Epoch: 5| Step: 5
Training loss: 2.455427704825179
Validation loss: 2.589452244703279

Epoch: 5| Step: 6
Training loss: 2.44741526128723
Validation loss: 2.5676089873727874

Epoch: 5| Step: 7
Training loss: 3.0553116807042056
Validation loss: 2.572377695505768

Epoch: 5| Step: 8
Training loss: 3.27655361685506
Validation loss: 2.619722513713929

Epoch: 5| Step: 9
Training loss: 2.405457403262151
Validation loss: 2.64894028133187

Epoch: 5| Step: 10
Training loss: 2.5116136686137525
Validation loss: 2.5709589845132212

Epoch: 145| Step: 0
Training loss: 2.8185706849166623
Validation loss: 2.615704150636734

Epoch: 5| Step: 1
Training loss: 3.113819262493425
Validation loss: 2.60443928003327

Epoch: 5| Step: 2
Training loss: 2.400872699697718
Validation loss: 2.6047821623579863

Epoch: 5| Step: 3
Training loss: 2.709890905626636
Validation loss: 2.5704108711022693

Epoch: 5| Step: 4
Training loss: 2.9484238115325465
Validation loss: 2.5811500102287477

Epoch: 5| Step: 5
Training loss: 2.887251086054578
Validation loss: 2.560802077271731

Epoch: 5| Step: 6
Training loss: 2.5987121730471627
Validation loss: 2.6081791260101674

Epoch: 5| Step: 7
Training loss: 2.350319467297617
Validation loss: 2.6091495067951964

Epoch: 5| Step: 8
Training loss: 3.305297795209177
Validation loss: 2.5852412698127973

Epoch: 5| Step: 9
Training loss: 2.91074573255798
Validation loss: 2.5648341999040642

Epoch: 5| Step: 10
Training loss: 2.877535655499239
Validation loss: 2.698290291398525

Epoch: 146| Step: 0
Training loss: 2.196004846619641
Validation loss: 2.5888498678688827

Epoch: 5| Step: 1
Training loss: 2.4062523779919256
Validation loss: 2.6242160026770054

Epoch: 5| Step: 2
Training loss: 3.122816314679666
Validation loss: 2.587199944247829

Epoch: 5| Step: 3
Training loss: 2.365329529464972
Validation loss: 2.6233032757051022

Epoch: 5| Step: 4
Training loss: 2.189137853813521
Validation loss: 2.5797211251460825

Epoch: 5| Step: 5
Training loss: 2.893568035691031
Validation loss: 2.547196053514754

Epoch: 5| Step: 6
Training loss: 3.312717358637433
Validation loss: 2.5949017492529842

Epoch: 5| Step: 7
Training loss: 2.6426784499156226
Validation loss: 2.571431168598687

Epoch: 5| Step: 8
Training loss: 2.9028454599799773
Validation loss: 2.556931173877946

Epoch: 5| Step: 9
Training loss: 3.1274131612819986
Validation loss: 2.6092766977890083

Epoch: 5| Step: 10
Training loss: 2.7650871831521204
Validation loss: 2.5502511381163617

Epoch: 147| Step: 0
Training loss: 2.181926493412702
Validation loss: 2.57042926246714

Epoch: 5| Step: 1
Training loss: 2.632666609256551
Validation loss: 2.6016396860866275

Epoch: 5| Step: 2
Training loss: 2.928515879007842
Validation loss: 2.6234286234695214

Epoch: 5| Step: 3
Training loss: 3.2929678811720384
Validation loss: 2.5890215637696627

Epoch: 5| Step: 4
Training loss: 2.3711832397265007
Validation loss: 2.5482625336680482

Epoch: 5| Step: 5
Training loss: 2.9007509771935704
Validation loss: 2.611421156783865

Epoch: 5| Step: 6
Training loss: 3.198508755589473
Validation loss: 2.6019728984580497

Epoch: 5| Step: 7
Training loss: 2.4618337785340225
Validation loss: 2.6765849389816

Epoch: 5| Step: 8
Training loss: 2.763020814157978
Validation loss: 2.5239448917303835

Epoch: 5| Step: 9
Training loss: 3.252159574903231
Validation loss: 2.6161311043250035

Epoch: 5| Step: 10
Training loss: 2.85042032856551
Validation loss: 2.594953684427784

Epoch: 148| Step: 0
Training loss: 2.343791808709131
Validation loss: 2.5638372162134027

Epoch: 5| Step: 1
Training loss: 2.3896073313281017
Validation loss: 2.5803495165332864

Epoch: 5| Step: 2
Training loss: 3.420994614869813
Validation loss: 2.622986852182559

Epoch: 5| Step: 3
Training loss: 2.4383850447133524
Validation loss: 2.5901884120215803

Epoch: 5| Step: 4
Training loss: 2.7100563046282584
Validation loss: 2.5830641343941894

Epoch: 5| Step: 5
Training loss: 2.936485927127819
Validation loss: 2.602445746693594

Epoch: 5| Step: 6
Training loss: 2.3866007724204157
Validation loss: 2.542410705478083

Epoch: 5| Step: 7
Training loss: 2.5628349271401643
Validation loss: 2.5886826309172797

Epoch: 5| Step: 8
Training loss: 3.2200726504452515
Validation loss: 2.6054567123764487

Epoch: 5| Step: 9
Training loss: 3.1683084515098416
Validation loss: 2.6321789130779485

Epoch: 5| Step: 10
Training loss: 2.977668456621898
Validation loss: 2.6055265256864137

Epoch: 149| Step: 0
Training loss: 2.679806631570846
Validation loss: 2.614364307621131

Epoch: 5| Step: 1
Training loss: 3.060155009663155
Validation loss: 2.625668369801309

Epoch: 5| Step: 2
Training loss: 2.384859100434355
Validation loss: 2.5907800490562067

Epoch: 5| Step: 3
Training loss: 2.585137280890004
Validation loss: 2.567104026289105

Epoch: 5| Step: 4
Training loss: 2.652764670410085
Validation loss: 2.616120374005532

Epoch: 5| Step: 5
Training loss: 3.1507456911077703
Validation loss: 2.6479596743819234

Epoch: 5| Step: 6
Training loss: 3.0768521383250973
Validation loss: 2.6623716034646483

Epoch: 5| Step: 7
Training loss: 3.0009943585747965
Validation loss: 2.628091932702804

Epoch: 5| Step: 8
Training loss: 2.437062248634007
Validation loss: 2.5584665113553595

Epoch: 5| Step: 9
Training loss: 3.2087779707185495
Validation loss: 2.5780473574981824

Epoch: 5| Step: 10
Training loss: 2.2825977054670985
Validation loss: 2.560092058790539

Epoch: 150| Step: 0
Training loss: 2.829015096463012
Validation loss: 2.579188726346305

Epoch: 5| Step: 1
Training loss: 2.36372520123106
Validation loss: 2.569821593081851

Epoch: 5| Step: 2
Training loss: 3.450836389855477
Validation loss: 2.61597919516011

Epoch: 5| Step: 3
Training loss: 2.4849563014526823
Validation loss: 2.6579069525149044

Epoch: 5| Step: 4
Training loss: 2.934561050578146
Validation loss: 2.6094494055537423

Epoch: 5| Step: 5
Training loss: 2.5677479295340624
Validation loss: 2.6068241147172078

Epoch: 5| Step: 6
Training loss: 2.7502651953706105
Validation loss: 2.66311509480327

Epoch: 5| Step: 7
Training loss: 2.8980903520419496
Validation loss: 2.590095412392248

Epoch: 5| Step: 8
Training loss: 2.792074847390409
Validation loss: 2.5957592869879598

Epoch: 5| Step: 9
Training loss: 2.695796491871361
Validation loss: 2.632683383554042

Epoch: 5| Step: 10
Training loss: 2.231994000512267
Validation loss: 2.597851967653332

Epoch: 151| Step: 0
Training loss: 2.5367432316150036
Validation loss: 2.650845386186962

Epoch: 5| Step: 1
Training loss: 3.170202857425146
Validation loss: 2.5219829063285455

Epoch: 5| Step: 2
Training loss: 2.4504549110185763
Validation loss: 2.578751761233588

Epoch: 5| Step: 3
Training loss: 3.367184384514945
Validation loss: 2.5369959769290324

Epoch: 5| Step: 4
Training loss: 2.7269823685605195
Validation loss: 2.5549858455676473

Epoch: 5| Step: 5
Training loss: 3.157546881707485
Validation loss: 2.6029111084064125

Epoch: 5| Step: 6
Training loss: 2.67784424493096
Validation loss: 2.578358915723224

Epoch: 5| Step: 7
Training loss: 2.5899875422586836
Validation loss: 2.608178670916533

Epoch: 5| Step: 8
Training loss: 2.387090126525549
Validation loss: 2.580226259912283

Epoch: 5| Step: 9
Training loss: 2.6707934594314655
Validation loss: 2.6173082147834266

Epoch: 5| Step: 10
Training loss: 2.6254645345279775
Validation loss: 2.5509944586021045

Epoch: 152| Step: 0
Training loss: 2.5828939084644595
Validation loss: 2.559550351730338

Epoch: 5| Step: 1
Training loss: 2.4757836498033394
Validation loss: 2.600974336753987

Epoch: 5| Step: 2
Training loss: 2.523302009653499
Validation loss: 2.5317969542143444

Epoch: 5| Step: 3
Training loss: 3.38948581385679
Validation loss: 2.61247859050529

Epoch: 5| Step: 4
Training loss: 2.805876923296049
Validation loss: 2.603809458855105

Epoch: 5| Step: 5
Training loss: 2.6477546824429257
Validation loss: 2.5732558901431446

Epoch: 5| Step: 6
Training loss: 3.619646394225004
Validation loss: 2.5510113770030194

Epoch: 5| Step: 7
Training loss: 2.899509447635284
Validation loss: 2.527901652262033

Epoch: 5| Step: 8
Training loss: 2.555977032177671
Validation loss: 2.623999152385298

Epoch: 5| Step: 9
Training loss: 3.0038727558783678
Validation loss: 2.613735651013228

Epoch: 5| Step: 10
Training loss: 2.371261867238112
Validation loss: 2.5847728656848634

Epoch: 153| Step: 0
Training loss: 2.576843313040383
Validation loss: 2.5868750682042614

Epoch: 5| Step: 1
Training loss: 2.943044097559645
Validation loss: 2.672537961693467

Epoch: 5| Step: 2
Training loss: 2.7268420406765452
Validation loss: 2.6056904993681766

Epoch: 5| Step: 3
Training loss: 2.737666301814436
Validation loss: 2.6379944820736156

Epoch: 5| Step: 4
Training loss: 2.9250650382350942
Validation loss: 2.550597039369452

Epoch: 5| Step: 5
Training loss: 2.8833568028136134
Validation loss: 2.584227004137884

Epoch: 5| Step: 6
Training loss: 1.8211614241886633
Validation loss: 2.57683172270409

Epoch: 5| Step: 7
Training loss: 2.764016756031792
Validation loss: 2.598093210953321

Epoch: 5| Step: 8
Training loss: 2.7354850041922
Validation loss: 2.5738761905846212

Epoch: 5| Step: 9
Training loss: 3.0430192074001843
Validation loss: 2.5644500099853427

Epoch: 5| Step: 10
Training loss: 3.1010028324550967
Validation loss: 2.549771914414437

Epoch: 154| Step: 0
Training loss: 2.5119135233821637
Validation loss: 2.606872095058959

Epoch: 5| Step: 1
Training loss: 2.732177548940688
Validation loss: 2.5786777951522923

Epoch: 5| Step: 2
Training loss: 3.258192008255298
Validation loss: 2.6141344521895507

Epoch: 5| Step: 3
Training loss: 2.6153350195346476
Validation loss: 2.620266616255877

Epoch: 5| Step: 4
Training loss: 2.3810554404887663
Validation loss: 2.613352056963704

Epoch: 5| Step: 5
Training loss: 2.7076732320130255
Validation loss: 2.658411002306305

Epoch: 5| Step: 6
Training loss: 2.759775559933241
Validation loss: 2.6181956779095374

Epoch: 5| Step: 7
Training loss: 2.9071229013472406
Validation loss: 2.634264784273994

Epoch: 5| Step: 8
Training loss: 2.048309522365715
Validation loss: 2.616788025711787

Epoch: 5| Step: 9
Training loss: 3.345887401202539
Validation loss: 2.594267965292216

Epoch: 5| Step: 10
Training loss: 3.084581758164749
Validation loss: 2.504851554895142

Epoch: 155| Step: 0
Training loss: 2.7119952949663158
Validation loss: 2.562678095053381

Epoch: 5| Step: 1
Training loss: 3.0724529541486136
Validation loss: 2.571395242521112

Epoch: 5| Step: 2
Training loss: 3.206060934162358
Validation loss: 2.579291030843797

Epoch: 5| Step: 3
Training loss: 1.8287969805092636
Validation loss: 2.598348367229432

Epoch: 5| Step: 4
Training loss: 2.9452896724393063
Validation loss: 2.6287979537379127

Epoch: 5| Step: 5
Training loss: 2.1083731073339473
Validation loss: 2.594373637666458

Epoch: 5| Step: 6
Training loss: 2.693269967413331
Validation loss: 2.605690793542986

Epoch: 5| Step: 7
Training loss: 3.49513737901055
Validation loss: 2.645561550858611

Epoch: 5| Step: 8
Training loss: 2.814641518677309
Validation loss: 2.62567786895014

Epoch: 5| Step: 9
Training loss: 2.873883403719829
Validation loss: 2.583574848086121

Epoch: 5| Step: 10
Training loss: 2.590383067873162
Validation loss: 2.5967348243283372

Epoch: 156| Step: 0
Training loss: 3.0928830560085085
Validation loss: 2.5729141590720133

Epoch: 5| Step: 1
Training loss: 2.2354065974548845
Validation loss: 2.633499690209223

Epoch: 5| Step: 2
Training loss: 2.9402611923971316
Validation loss: 2.586147160933441

Epoch: 5| Step: 3
Training loss: 3.038352275321312
Validation loss: 2.590661064894513

Epoch: 5| Step: 4
Training loss: 2.985881644803984
Validation loss: 2.6239894126790553

Epoch: 5| Step: 5
Training loss: 2.7242562670212473
Validation loss: 2.6363008951495677

Epoch: 5| Step: 6
Training loss: 2.932039420535512
Validation loss: 2.541517223710079

Epoch: 5| Step: 7
Training loss: 2.9252110983812387
Validation loss: 2.601015804533005

Epoch: 5| Step: 8
Training loss: 2.362317807877475
Validation loss: 2.6195794033829936

Epoch: 5| Step: 9
Training loss: 2.636838557029266
Validation loss: 2.623087004285716

Epoch: 5| Step: 10
Training loss: 2.552903885528944
Validation loss: 2.595214190297937

Epoch: 157| Step: 0
Training loss: 2.687472054979394
Validation loss: 2.6260761978902734

Epoch: 5| Step: 1
Training loss: 3.2653893198634556
Validation loss: 2.600010016558515

Epoch: 5| Step: 2
Training loss: 3.624527867581986
Validation loss: 2.582211458913754

Epoch: 5| Step: 3
Training loss: 2.3936308868493588
Validation loss: 2.561103536334095

Epoch: 5| Step: 4
Training loss: 2.054616020322726
Validation loss: 2.625632120600789

Epoch: 5| Step: 5
Training loss: 2.723017708251844
Validation loss: 2.6378630593867616

Epoch: 5| Step: 6
Training loss: 3.1472042877443447
Validation loss: 2.6898078557917864

Epoch: 5| Step: 7
Training loss: 2.7041657489447855
Validation loss: 2.670451907567194

Epoch: 5| Step: 8
Training loss: 2.5278453771287883
Validation loss: 2.611227443840753

Epoch: 5| Step: 9
Training loss: 2.911830998808997
Validation loss: 2.6273508693242253

Epoch: 5| Step: 10
Training loss: 2.2279893017893824
Validation loss: 2.608708838022778

Epoch: 158| Step: 0
Training loss: 2.4252947873929913
Validation loss: 2.6383139729011176

Epoch: 5| Step: 1
Training loss: 2.4382576376307323
Validation loss: 2.6422622797866717

Epoch: 5| Step: 2
Training loss: 2.784705426510848
Validation loss: 2.5954997178670567

Epoch: 5| Step: 3
Training loss: 3.06940724468752
Validation loss: 2.6671922252982334

Epoch: 5| Step: 4
Training loss: 2.432650020321133
Validation loss: 2.6688237172884746

Epoch: 5| Step: 5
Training loss: 2.989925954150656
Validation loss: 2.636480389527232

Epoch: 5| Step: 6
Training loss: 2.627803758363296
Validation loss: 2.576779105901309

Epoch: 5| Step: 7
Training loss: 2.462901467065747
Validation loss: 2.6214776223910543

Epoch: 5| Step: 8
Training loss: 2.9342896795411857
Validation loss: 2.552436850002044

Epoch: 5| Step: 9
Training loss: 3.257935446196261
Validation loss: 2.5492633789136727

Epoch: 5| Step: 10
Training loss: 2.690406203816521
Validation loss: 2.594074397502319

Epoch: 159| Step: 0
Training loss: 3.2458125794856767
Validation loss: 2.627395348563954

Epoch: 5| Step: 1
Training loss: 2.946373867171124
Validation loss: 2.557669745449724

Epoch: 5| Step: 2
Training loss: 2.4934048444859207
Validation loss: 2.565777574121087

Epoch: 5| Step: 3
Training loss: 3.166963278949929
Validation loss: 2.571431389926096

Epoch: 5| Step: 4
Training loss: 2.640272670016052
Validation loss: 2.735425174931923

Epoch: 5| Step: 5
Training loss: 2.8536690234050623
Validation loss: 2.6002353706422796

Epoch: 5| Step: 6
Training loss: 2.5466230771027494
Validation loss: 2.5912873306427997

Epoch: 5| Step: 7
Training loss: 2.1805908081487932
Validation loss: 2.631778437412686

Epoch: 5| Step: 8
Training loss: 2.530967602459523
Validation loss: 2.6034508969658083

Epoch: 5| Step: 9
Training loss: 2.4340912875168788
Validation loss: 2.5980179828346452

Epoch: 5| Step: 10
Training loss: 3.4835943194241517
Validation loss: 2.6167687737559726

Epoch: 160| Step: 0
Training loss: 2.1603022658818753
Validation loss: 2.5754309605717887

Epoch: 5| Step: 1
Training loss: 2.3789115617564365
Validation loss: 2.569068798050066

Epoch: 5| Step: 2
Training loss: 3.4334302913221717
Validation loss: 2.6384083346108635

Epoch: 5| Step: 3
Training loss: 2.7295830290115863
Validation loss: 2.6000424443133716

Epoch: 5| Step: 4
Training loss: 3.1707773799362253
Validation loss: 2.6048921371147276

Epoch: 5| Step: 5
Training loss: 2.742984927484737
Validation loss: 2.641175577416896

Epoch: 5| Step: 6
Training loss: 2.804973619578402
Validation loss: 2.6206397492971725

Epoch: 5| Step: 7
Training loss: 1.9126265141148486
Validation loss: 2.530493062634804

Epoch: 5| Step: 8
Training loss: 2.6294950418202494
Validation loss: 2.631933218876254

Epoch: 5| Step: 9
Training loss: 3.239726628674098
Validation loss: 2.5718049335346533

Epoch: 5| Step: 10
Training loss: 2.831389845200652
Validation loss: 2.615497992103519

Epoch: 161| Step: 0
Training loss: 3.987271441662771
Validation loss: 2.5644524352185183

Epoch: 5| Step: 1
Training loss: 2.833117046702692
Validation loss: 2.5706543724831485

Epoch: 5| Step: 2
Training loss: 2.3839960879607394
Validation loss: 2.6031127969582615

Epoch: 5| Step: 3
Training loss: 2.028619442051102
Validation loss: 2.6279432552229443

Epoch: 5| Step: 4
Training loss: 2.2617074705906672
Validation loss: 2.6582481613913624

Epoch: 5| Step: 5
Training loss: 2.715297831152069
Validation loss: 2.546378750610123

Epoch: 5| Step: 6
Training loss: 2.308641152451952
Validation loss: 2.5827445984539508

Epoch: 5| Step: 7
Training loss: 3.108815511849931
Validation loss: 2.651238897318472

Epoch: 5| Step: 8
Training loss: 2.484335653125426
Validation loss: 2.5717185770952224

Epoch: 5| Step: 9
Training loss: 3.3629075040957512
Validation loss: 2.599869194479332

Epoch: 5| Step: 10
Training loss: 3.4219294852879005
Validation loss: 2.5372451798550246

Epoch: 162| Step: 0
Training loss: 2.5122318485320596
Validation loss: 2.580518990859307

Epoch: 5| Step: 1
Training loss: 2.444178894338403
Validation loss: 2.550330406899409

Epoch: 5| Step: 2
Training loss: 2.9981166968152135
Validation loss: 2.559023054200036

Epoch: 5| Step: 3
Training loss: 2.9065635265926413
Validation loss: 2.5403982581894846

Epoch: 5| Step: 4
Training loss: 2.4699528335206917
Validation loss: 2.5857464475300667

Epoch: 5| Step: 5
Training loss: 3.0620741256123485
Validation loss: 2.582197045284501

Epoch: 5| Step: 6
Training loss: 2.7128540651784196
Validation loss: 2.5953557025408633

Epoch: 5| Step: 7
Training loss: 2.280003350740614
Validation loss: 2.626144893928908

Epoch: 5| Step: 8
Training loss: 2.973322990325364
Validation loss: 2.582374185966455

Epoch: 5| Step: 9
Training loss: 2.6883092149889096
Validation loss: 2.5997484302370326

Epoch: 5| Step: 10
Training loss: 3.1093020023230924
Validation loss: 2.5681151488991887

Epoch: 163| Step: 0
Training loss: 2.818369526359057
Validation loss: 2.6053960334056843

Epoch: 5| Step: 1
Training loss: 2.6710922254595406
Validation loss: 2.5937138404307407

Epoch: 5| Step: 2
Training loss: 2.979116550548657
Validation loss: 2.681042326825759

Epoch: 5| Step: 3
Training loss: 3.6490755033869804
Validation loss: 2.605296043052528

Epoch: 5| Step: 4
Training loss: 2.4713193825999524
Validation loss: 2.6584037296451997

Epoch: 5| Step: 5
Training loss: 2.2029583374184285
Validation loss: 2.6067851596042066

Epoch: 5| Step: 6
Training loss: 2.7435780881930776
Validation loss: 2.552444947376919

Epoch: 5| Step: 7
Training loss: 2.2806978994663827
Validation loss: 2.614251607995811

Epoch: 5| Step: 8
Training loss: 2.980292118783199
Validation loss: 2.6378822963663033

Epoch: 5| Step: 9
Training loss: 2.9945785490859156
Validation loss: 2.5765461691028135

Epoch: 5| Step: 10
Training loss: 2.661794194618204
Validation loss: 2.6171725629473017

Epoch: 164| Step: 0
Training loss: 2.538240739916522
Validation loss: 2.653298313945328

Epoch: 5| Step: 1
Training loss: 2.579734623442201
Validation loss: 2.5944528211890963

Epoch: 5| Step: 2
Training loss: 3.0308162732850814
Validation loss: 2.555664424626704

Epoch: 5| Step: 3
Training loss: 2.8144989539392005
Validation loss: 2.5664211668645276

Epoch: 5| Step: 4
Training loss: 2.5921105408468286
Validation loss: 2.600154245382695

Epoch: 5| Step: 5
Training loss: 3.2845172419357525
Validation loss: 2.617532707887014

Epoch: 5| Step: 6
Training loss: 3.1977908495942984
Validation loss: 2.5753752272864325

Epoch: 5| Step: 7
Training loss: 2.7134853559766285
Validation loss: 2.617002814873255

Epoch: 5| Step: 8
Training loss: 2.4172229017095366
Validation loss: 2.588047177359871

Epoch: 5| Step: 9
Training loss: 2.798943037401339
Validation loss: 2.6602279111101317

Epoch: 5| Step: 10
Training loss: 2.290808522781709
Validation loss: 2.62996212881062

Epoch: 165| Step: 0
Training loss: 3.008396161410471
Validation loss: 2.6092877912866457

Epoch: 5| Step: 1
Training loss: 2.9007365113621764
Validation loss: 2.5982371140120333

Epoch: 5| Step: 2
Training loss: 2.886429830295926
Validation loss: 2.618145924200605

Epoch: 5| Step: 3
Training loss: 2.3320154032975515
Validation loss: 2.5374582356418114

Epoch: 5| Step: 4
Training loss: 2.7056122731037027
Validation loss: 2.596362614190808

Epoch: 5| Step: 5
Training loss: 2.3417878138833768
Validation loss: 2.6232427339555104

Epoch: 5| Step: 6
Training loss: 2.914966596408733
Validation loss: 2.634402698257424

Epoch: 5| Step: 7
Training loss: 2.762651126922195
Validation loss: 2.492586672558717

Epoch: 5| Step: 8
Training loss: 2.821187483298118
Validation loss: 2.583876338049478

Epoch: 5| Step: 9
Training loss: 2.464940669214288
Validation loss: 2.5883235136713387

Epoch: 5| Step: 10
Training loss: 3.310699549392493
Validation loss: 2.603223688177076

Epoch: 166| Step: 0
Training loss: 2.5978373299491246
Validation loss: 2.615480613577666

Epoch: 5| Step: 1
Training loss: 2.7655877579589943
Validation loss: 2.6100842167451956

Epoch: 5| Step: 2
Training loss: 2.1648900622146683
Validation loss: 2.597091170468837

Epoch: 5| Step: 3
Training loss: 3.2765240741126482
Validation loss: 2.5338946277910672

Epoch: 5| Step: 4
Training loss: 2.630455524172275
Validation loss: 2.6269427882586336

Epoch: 5| Step: 5
Training loss: 2.9850143626520893
Validation loss: 2.558084610129212

Epoch: 5| Step: 6
Training loss: 2.7511804821308194
Validation loss: 2.572883330403989

Epoch: 5| Step: 7
Training loss: 2.875396701146616
Validation loss: 2.5753558747958416

Epoch: 5| Step: 8
Training loss: 2.5527440883040144
Validation loss: 2.547016663533704

Epoch: 5| Step: 9
Training loss: 2.913120802831501
Validation loss: 2.6238647883397594

Epoch: 5| Step: 10
Training loss: 3.0509441102696813
Validation loss: 2.573434830759023

Epoch: 167| Step: 0
Training loss: 2.7969045797307595
Validation loss: 2.6463186761824997

Epoch: 5| Step: 1
Training loss: 2.6159799095747247
Validation loss: 2.596148997862266

Epoch: 5| Step: 2
Training loss: 2.1973494992672267
Validation loss: 2.5992840182191146

Epoch: 5| Step: 3
Training loss: 2.534663124498718
Validation loss: 2.628730347131445

Epoch: 5| Step: 4
Training loss: 3.338126328808567
Validation loss: 2.566959143926258

Epoch: 5| Step: 5
Training loss: 2.3515348211034555
Validation loss: 2.5374061127824383

Epoch: 5| Step: 6
Training loss: 2.7564982884133773
Validation loss: 2.611477351818349

Epoch: 5| Step: 7
Training loss: 2.807948350034666
Validation loss: 2.6177469457913602

Epoch: 5| Step: 8
Training loss: 3.0244101209309964
Validation loss: 2.5649460673807423

Epoch: 5| Step: 9
Training loss: 2.725628974490033
Validation loss: 2.631513864714128

Epoch: 5| Step: 10
Training loss: 3.1968308551085896
Validation loss: 2.5769034207825423

Epoch: 168| Step: 0
Training loss: 2.5394948737927736
Validation loss: 2.7035474729820343

Epoch: 5| Step: 1
Training loss: 2.7384502451250845
Validation loss: 2.552777844560011

Epoch: 5| Step: 2
Training loss: 2.6285030061393675
Validation loss: 2.588604032472857

Epoch: 5| Step: 3
Training loss: 3.1106242828337654
Validation loss: 2.660556808530872

Epoch: 5| Step: 4
Training loss: 1.986438189282538
Validation loss: 2.6091784007173513

Epoch: 5| Step: 5
Training loss: 3.178375198283238
Validation loss: 2.6406934971622653

Epoch: 5| Step: 6
Training loss: 3.276510539663854
Validation loss: 2.568113249214147

Epoch: 5| Step: 7
Training loss: 2.4882666858384606
Validation loss: 2.537795723179801

Epoch: 5| Step: 8
Training loss: 3.1038834274071276
Validation loss: 2.616373894702193

Epoch: 5| Step: 9
Training loss: 2.3079105921969134
Validation loss: 2.585144066978299

Epoch: 5| Step: 10
Training loss: 2.8475398705749777
Validation loss: 2.5857490530617118

Epoch: 169| Step: 0
Training loss: 2.5549030737958924
Validation loss: 2.6191538858822425

Epoch: 5| Step: 1
Training loss: 2.7722952196257022
Validation loss: 2.6131419936835476

Epoch: 5| Step: 2
Training loss: 2.5960560853598174
Validation loss: 2.6315941917704344

Epoch: 5| Step: 3
Training loss: 2.4215782722080608
Validation loss: 2.544854004536442

Epoch: 5| Step: 4
Training loss: 3.2994470190796923
Validation loss: 2.5819252442545553

Epoch: 5| Step: 5
Training loss: 2.9441945511762264
Validation loss: 2.5624098923250056

Epoch: 5| Step: 6
Training loss: 2.5028563394563883
Validation loss: 2.6541336710720516

Epoch: 5| Step: 7
Training loss: 2.677076307552237
Validation loss: 2.5678994802501207

Epoch: 5| Step: 8
Training loss: 2.76279265635768
Validation loss: 2.625047119780284

Epoch: 5| Step: 9
Training loss: 3.0105793698879655
Validation loss: 2.624227301672106

Epoch: 5| Step: 10
Training loss: 2.743781688741809
Validation loss: 2.6329264489108444

Epoch: 170| Step: 0
Training loss: 3.093360799333158
Validation loss: 2.5518820704411067

Epoch: 5| Step: 1
Training loss: 2.47040068090805
Validation loss: 2.58414354099914

Epoch: 5| Step: 2
Training loss: 3.115136564148265
Validation loss: 2.639457919472427

Epoch: 5| Step: 3
Training loss: 2.621367075010568
Validation loss: 2.5700940512050625

Epoch: 5| Step: 4
Training loss: 2.2392803844806535
Validation loss: 2.5605242395840135

Epoch: 5| Step: 5
Training loss: 2.2853762789704266
Validation loss: 2.5691093428812515

Epoch: 5| Step: 6
Training loss: 3.2074622585963226
Validation loss: 2.645752473822433

Epoch: 5| Step: 7
Training loss: 1.975801102616564
Validation loss: 2.612417360225261

Epoch: 5| Step: 8
Training loss: 3.4807313762183822
Validation loss: 2.5943888947190463

Epoch: 5| Step: 9
Training loss: 2.7677069979257536
Validation loss: 2.6398403251596188

Epoch: 5| Step: 10
Training loss: 2.8699520410126023
Validation loss: 2.60477071110314

Epoch: 171| Step: 0
Training loss: 2.989421472365668
Validation loss: 2.5573922070211257

Epoch: 5| Step: 1
Training loss: 2.707230641781881
Validation loss: 2.618746871098597

Epoch: 5| Step: 2
Training loss: 2.7268269145607054
Validation loss: 2.6441295552145885

Epoch: 5| Step: 3
Training loss: 2.3454043843710206
Validation loss: 2.6377530296035583

Epoch: 5| Step: 4
Training loss: 3.3621698153587616
Validation loss: 2.5885171044587936

Epoch: 5| Step: 5
Training loss: 2.790142288408064
Validation loss: 2.5478989650065893

Epoch: 5| Step: 6
Training loss: 2.894553324709179
Validation loss: 2.6224703165299013

Epoch: 5| Step: 7
Training loss: 2.809845243652028
Validation loss: 2.635207641696214

Epoch: 5| Step: 8
Training loss: 2.5002269641847565
Validation loss: 2.5242394254087057

Epoch: 5| Step: 9
Training loss: 2.881317660846773
Validation loss: 2.6303440149562904

Epoch: 5| Step: 10
Training loss: 2.3293216369428413
Validation loss: 2.6058538537593647

Epoch: 172| Step: 0
Training loss: 2.947497460491196
Validation loss: 2.6086724450445065

Epoch: 5| Step: 1
Training loss: 3.0233129037028714
Validation loss: 2.5298092761645115

Epoch: 5| Step: 2
Training loss: 2.9308934692368362
Validation loss: 2.6187090977695195

Epoch: 5| Step: 3
Training loss: 2.502842145885445
Validation loss: 2.551907270903367

Epoch: 5| Step: 4
Training loss: 2.711663492486554
Validation loss: 2.5515473855062036

Epoch: 5| Step: 5
Training loss: 2.8786582891752546
Validation loss: 2.5752988059519364

Epoch: 5| Step: 6
Training loss: 2.266067040827921
Validation loss: 2.629029130735638

Epoch: 5| Step: 7
Training loss: 3.125853612663314
Validation loss: 2.589603607264953

Epoch: 5| Step: 8
Training loss: 2.7644693147498676
Validation loss: 2.6256594925720558

Epoch: 5| Step: 9
Training loss: 2.7370245603407892
Validation loss: 2.584047582637347

Epoch: 5| Step: 10
Training loss: 2.713033344203092
Validation loss: 2.541259148613345

Epoch: 173| Step: 0
Training loss: 2.1429980413345167
Validation loss: 2.625860960794386

Epoch: 5| Step: 1
Training loss: 3.0490206474988835
Validation loss: 2.6295840527752743

Epoch: 5| Step: 2
Training loss: 3.441613804839968
Validation loss: 2.597159712215791

Epoch: 5| Step: 3
Training loss: 2.8966336870968203
Validation loss: 2.527895605458132

Epoch: 5| Step: 4
Training loss: 3.266542150758301
Validation loss: 2.6075691014740996

Epoch: 5| Step: 5
Training loss: 2.41349049924028
Validation loss: 2.556497967505089

Epoch: 5| Step: 6
Training loss: 3.082234693806206
Validation loss: 2.5453971472075065

Epoch: 5| Step: 7
Training loss: 2.657973056005078
Validation loss: 2.638977586377825

Epoch: 5| Step: 8
Training loss: 2.463313333415537
Validation loss: 2.585699026990274

Epoch: 5| Step: 9
Training loss: 1.8065312202938095
Validation loss: 2.6021054018071132

Epoch: 5| Step: 10
Training loss: 2.745702767246607
Validation loss: 2.5364801215951926

Epoch: 174| Step: 0
Training loss: 2.7225565077957277
Validation loss: 2.6385478693313176

Epoch: 5| Step: 1
Training loss: 2.888289874484182
Validation loss: 2.607404949985467

Epoch: 5| Step: 2
Training loss: 2.613338635189491
Validation loss: 2.6640966847031136

Epoch: 5| Step: 3
Training loss: 2.3446190812191317
Validation loss: 2.6400673608709897

Epoch: 5| Step: 4
Training loss: 2.582860677815561
Validation loss: 2.5922616127027975

Epoch: 5| Step: 5
Training loss: 3.045435795409248
Validation loss: 2.6064193105188473

Epoch: 5| Step: 6
Training loss: 2.8453019487079554
Validation loss: 2.6435325805254166

Epoch: 5| Step: 7
Training loss: 3.1433840347143818
Validation loss: 2.5187724581144986

Epoch: 5| Step: 8
Training loss: 3.0751084781524027
Validation loss: 2.6934912545772587

Epoch: 5| Step: 9
Training loss: 2.397059439236064
Validation loss: 2.570641017984275

Epoch: 5| Step: 10
Training loss: 2.272589141809558
Validation loss: 2.6501393030615854

Epoch: 175| Step: 0
Training loss: 2.655468455508497
Validation loss: 2.639273343490656

Epoch: 5| Step: 1
Training loss: 3.345981886920139
Validation loss: 2.669854708645886

Epoch: 5| Step: 2
Training loss: 2.3781338143905923
Validation loss: 2.6127876541407713

Epoch: 5| Step: 3
Training loss: 2.8850363654054543
Validation loss: 2.6100583855791877

Epoch: 5| Step: 4
Training loss: 2.1639878022560546
Validation loss: 2.579428357818296

Epoch: 5| Step: 5
Training loss: 3.4761872164019825
Validation loss: 2.5625584183263523

Epoch: 5| Step: 6
Training loss: 2.658254607498795
Validation loss: 2.6208954171171617

Epoch: 5| Step: 7
Training loss: 2.734326345828296
Validation loss: 2.59793305625778

Epoch: 5| Step: 8
Training loss: 2.4855658598058947
Validation loss: 2.689052123092005

Epoch: 5| Step: 9
Training loss: 2.526802394143692
Validation loss: 2.5839299423715976

Epoch: 5| Step: 10
Training loss: 3.0073349610768725
Validation loss: 2.5957628345398907

Epoch: 176| Step: 0
Training loss: 3.143861839170727
Validation loss: 2.5566195794488227

Epoch: 5| Step: 1
Training loss: 2.9355517480623226
Validation loss: 2.5908970388997767

Epoch: 5| Step: 2
Training loss: 2.5862507702405475
Validation loss: 2.6070586896661334

Epoch: 5| Step: 3
Training loss: 3.1899848676938456
Validation loss: 2.565127739434402

Epoch: 5| Step: 4
Training loss: 2.4129297259168436
Validation loss: 2.6061430072165646

Epoch: 5| Step: 5
Training loss: 2.569796988784934
Validation loss: 2.6172622290423435

Epoch: 5| Step: 6
Training loss: 2.4481994357368713
Validation loss: 2.591750387150466

Epoch: 5| Step: 7
Training loss: 3.075192986611934
Validation loss: 2.5891849331509276

Epoch: 5| Step: 8
Training loss: 2.250600310881161
Validation loss: 2.596167266145377

Epoch: 5| Step: 9
Training loss: 2.4282139667330194
Validation loss: 2.539509270346927

Epoch: 5| Step: 10
Training loss: 2.7261433538805298
Validation loss: 2.6011082284243963

Epoch: 177| Step: 0
Training loss: 2.4617192071341014
Validation loss: 2.621806418505228

Epoch: 5| Step: 1
Training loss: 2.5009858095116537
Validation loss: 2.5648803390077037

Epoch: 5| Step: 2
Training loss: 2.341643543966398
Validation loss: 2.646124477773561

Epoch: 5| Step: 3
Training loss: 2.979048524305782
Validation loss: 2.646506716925989

Epoch: 5| Step: 4
Training loss: 2.2698532112487926
Validation loss: 2.597713250062145

Epoch: 5| Step: 5
Training loss: 3.0691241811200376
Validation loss: 2.599708383959151

Epoch: 5| Step: 6
Training loss: 2.7663487925860744
Validation loss: 2.593770091946022

Epoch: 5| Step: 7
Training loss: 3.371794555948932
Validation loss: 2.588751111078989

Epoch: 5| Step: 8
Training loss: 2.7655854303147795
Validation loss: 2.5538665806247183

Epoch: 5| Step: 9
Training loss: 2.820637945698691
Validation loss: 2.6621114685851106

Epoch: 5| Step: 10
Training loss: 2.8797263396899204
Validation loss: 2.570447210876177

Epoch: 178| Step: 0
Training loss: 2.3752708280642088
Validation loss: 2.6075448862914588

Epoch: 5| Step: 1
Training loss: 3.3841941778146087
Validation loss: 2.5993399045979433

Epoch: 5| Step: 2
Training loss: 2.882254693874455
Validation loss: 2.5763100294695422

Epoch: 5| Step: 3
Training loss: 2.79415838341794
Validation loss: 2.606688545736761

Epoch: 5| Step: 4
Training loss: 2.375996731861834
Validation loss: 2.6067491906870375

Epoch: 5| Step: 5
Training loss: 2.0763723683913824
Validation loss: 2.568960796453892

Epoch: 5| Step: 6
Training loss: 2.5913631993404547
Validation loss: 2.6029124232647542

Epoch: 5| Step: 7
Training loss: 2.3899934221121315
Validation loss: 2.5663515858879724

Epoch: 5| Step: 8
Training loss: 3.635357758810802
Validation loss: 2.6039340319347515

Epoch: 5| Step: 9
Training loss: 2.620830039389703
Validation loss: 2.6026850039586984

Epoch: 5| Step: 10
Training loss: 2.5435641246621463
Validation loss: 2.537519013645643

Epoch: 179| Step: 0
Training loss: 2.6770887758271424
Validation loss: 2.62772642666451

Epoch: 5| Step: 1
Training loss: 3.075267104046487
Validation loss: 2.6164248520201956

Epoch: 5| Step: 2
Training loss: 2.7101214936953655
Validation loss: 2.569729269512288

Epoch: 5| Step: 3
Training loss: 3.3933419447704036
Validation loss: 2.5491447901081643

Epoch: 5| Step: 4
Training loss: 1.845376154280572
Validation loss: 2.585732737710714

Epoch: 5| Step: 5
Training loss: 3.232837698659873
Validation loss: 2.5640598634725027

Epoch: 5| Step: 6
Training loss: 3.3798626378605485
Validation loss: 2.6095931981432066

Epoch: 5| Step: 7
Training loss: 2.2742626881785903
Validation loss: 2.6396711849732575

Epoch: 5| Step: 8
Training loss: 2.988141623831559
Validation loss: 2.5709668555319745

Epoch: 5| Step: 9
Training loss: 2.1732294264139584
Validation loss: 2.58954011201934

Epoch: 5| Step: 10
Training loss: 1.9300097609554785
Validation loss: 2.5353208060869017

Epoch: 180| Step: 0
Training loss: 2.4850556982541243
Validation loss: 2.551047131892937

Epoch: 5| Step: 1
Training loss: 2.8235802990638024
Validation loss: 2.600335967694113

Epoch: 5| Step: 2
Training loss: 2.6955134662397233
Validation loss: 2.6089740081795307

Epoch: 5| Step: 3
Training loss: 2.5272576200970533
Validation loss: 2.6060077500648693

Epoch: 5| Step: 4
Training loss: 2.1948165604878906
Validation loss: 2.637539850542497

Epoch: 5| Step: 5
Training loss: 3.2285184312128608
Validation loss: 2.5413987122542547

Epoch: 5| Step: 6
Training loss: 2.793805446543912
Validation loss: 2.560175727238601

Epoch: 5| Step: 7
Training loss: 3.023801481038151
Validation loss: 2.553060472546832

Epoch: 5| Step: 8
Training loss: 3.0820210387782363
Validation loss: 2.548339339238834

Epoch: 5| Step: 9
Training loss: 2.248181243778337
Validation loss: 2.646843009678218

Epoch: 5| Step: 10
Training loss: 3.1814496830173646
Validation loss: 2.5902210636893535

Epoch: 181| Step: 0
Training loss: 2.456560778188399
Validation loss: 2.669964413137071

Epoch: 5| Step: 1
Training loss: 2.5651725230653786
Validation loss: 2.552716234763481

Epoch: 5| Step: 2
Training loss: 2.811670308121104
Validation loss: 2.5804692116098833

Epoch: 5| Step: 3
Training loss: 2.615540945874233
Validation loss: 2.5718050720933885

Epoch: 5| Step: 4
Training loss: 2.7433342342753764
Validation loss: 2.552321062364748

Epoch: 5| Step: 5
Training loss: 3.2397762294307717
Validation loss: 2.549998044755778

Epoch: 5| Step: 6
Training loss: 2.548254096040715
Validation loss: 2.5600877848710417

Epoch: 5| Step: 7
Training loss: 2.8344261829335093
Validation loss: 2.5852720086304504

Epoch: 5| Step: 8
Training loss: 3.4175432212792165
Validation loss: 2.554630004560956

Epoch: 5| Step: 9
Training loss: 2.16183356892482
Validation loss: 2.595700255881382

Epoch: 5| Step: 10
Training loss: 2.6160147245558494
Validation loss: 2.5810139777063488

Epoch: 182| Step: 0
Training loss: 3.1525588405360483
Validation loss: 2.5800855970798087

Epoch: 5| Step: 1
Training loss: 3.306479687275166
Validation loss: 2.567538966304679

Epoch: 5| Step: 2
Training loss: 2.642544471994465
Validation loss: 2.5983110866793897

Epoch: 5| Step: 3
Training loss: 2.7887510665419595
Validation loss: 2.57208019514517

Epoch: 5| Step: 4
Training loss: 2.5628027388218535
Validation loss: 2.609399324937061

Epoch: 5| Step: 5
Training loss: 2.7637772934289297
Validation loss: 2.4923555143472633

Epoch: 5| Step: 6
Training loss: 2.639179714529171
Validation loss: 2.565220731805267

Epoch: 5| Step: 7
Training loss: 2.4933013818430942
Validation loss: 2.64050110159006

Epoch: 5| Step: 8
Training loss: 1.9650804744869144
Validation loss: 2.6118320399154897

Epoch: 5| Step: 9
Training loss: 2.9159034457030786
Validation loss: 2.6315730939172863

Epoch: 5| Step: 10
Training loss: 2.8009671584481453
Validation loss: 2.5899987817244257

Epoch: 183| Step: 0
Training loss: 2.2817034336060074
Validation loss: 2.5999665961789895

Epoch: 5| Step: 1
Training loss: 2.9957636485972716
Validation loss: 2.5668298610168807

Epoch: 5| Step: 2
Training loss: 2.8758903451635263
Validation loss: 2.6131925598032337

Epoch: 5| Step: 3
Training loss: 2.8745614422216517
Validation loss: 2.670450275562364

Epoch: 5| Step: 4
Training loss: 2.1402018330664485
Validation loss: 2.534737193652021

Epoch: 5| Step: 5
Training loss: 3.1537970651810694
Validation loss: 2.5844730604653336

Epoch: 5| Step: 6
Training loss: 2.345324991638952
Validation loss: 2.611765821830128

Epoch: 5| Step: 7
Training loss: 2.901805309187575
Validation loss: 2.6006047187693726

Epoch: 5| Step: 8
Training loss: 2.8563974021088896
Validation loss: 2.653699904738513

Epoch: 5| Step: 9
Training loss: 3.2182489394019713
Validation loss: 2.612210880466373

Epoch: 5| Step: 10
Training loss: 2.7261993253774075
Validation loss: 2.606018538746772

Epoch: 184| Step: 0
Training loss: 3.1676547533392174
Validation loss: 2.655627513237294

Epoch: 5| Step: 1
Training loss: 3.071092656925524
Validation loss: 2.553475763819746

Epoch: 5| Step: 2
Training loss: 2.3583454639495764
Validation loss: 2.5708893558345887

Epoch: 5| Step: 3
Training loss: 2.0917847933095306
Validation loss: 2.5263095285326465

Epoch: 5| Step: 4
Training loss: 2.9070937049756886
Validation loss: 2.593632278904113

Epoch: 5| Step: 5
Training loss: 2.535935856600621
Validation loss: 2.627534259255771

Epoch: 5| Step: 6
Training loss: 3.1322109187054776
Validation loss: 2.562179189189354

Epoch: 5| Step: 7
Training loss: 2.655456873347273
Validation loss: 2.5730245394140745

Epoch: 5| Step: 8
Training loss: 2.3760744976990353
Validation loss: 2.6205919251567673

Epoch: 5| Step: 9
Training loss: 2.827079453227886
Validation loss: 2.557353851248668

Epoch: 5| Step: 10
Training loss: 2.75584224530688
Validation loss: 2.5913962991933057

Epoch: 185| Step: 0
Training loss: 2.659323675464999
Validation loss: 2.597347463530671

Epoch: 5| Step: 1
Training loss: 2.9055865771370106
Validation loss: 2.637698591771145

Epoch: 5| Step: 2
Training loss: 3.471279287520348
Validation loss: 2.603698654614938

Epoch: 5| Step: 3
Training loss: 2.4896220333225147
Validation loss: 2.5975374949484915

Epoch: 5| Step: 4
Training loss: 2.0646679206198084
Validation loss: 2.6284264470097547

Epoch: 5| Step: 5
Training loss: 2.3315234885475475
Validation loss: 2.6220714701157313

Epoch: 5| Step: 6
Training loss: 2.683561499789158
Validation loss: 2.622900430322376

Epoch: 5| Step: 7
Training loss: 2.239067858139197
Validation loss: 2.5946418364621184

Epoch: 5| Step: 8
Training loss: 3.121365073469459
Validation loss: 2.549063846140873

Epoch: 5| Step: 9
Training loss: 3.138024767270399
Validation loss: 2.623476508275999

Epoch: 5| Step: 10
Training loss: 2.5188099856368478
Validation loss: 2.6375029149768614

Epoch: 186| Step: 0
Training loss: 2.412372479008585
Validation loss: 2.5891953315197527

Epoch: 5| Step: 1
Training loss: 2.5228607179930838
Validation loss: 2.573852632533918

Epoch: 5| Step: 2
Training loss: 2.8740209488075363
Validation loss: 2.588871307950924

Epoch: 5| Step: 3
Training loss: 2.7417383940183155
Validation loss: 2.561618129453122

Epoch: 5| Step: 4
Training loss: 2.4645278172005627
Validation loss: 2.6787109547267676

Epoch: 5| Step: 5
Training loss: 2.100946499193724
Validation loss: 2.606819668606275

Epoch: 5| Step: 6
Training loss: 3.2044938302816233
Validation loss: 2.5105980104810453

Epoch: 5| Step: 7
Training loss: 2.746745871849357
Validation loss: 2.5603964130095136

Epoch: 5| Step: 8
Training loss: 3.1403219351985956
Validation loss: 2.585122934150176

Epoch: 5| Step: 9
Training loss: 2.9234135294940247
Validation loss: 2.567469722163764

Epoch: 5| Step: 10
Training loss: 2.9354250458127797
Validation loss: 2.558817196147274

Epoch: 187| Step: 0
Training loss: 3.3062923493584577
Validation loss: 2.6062878783180397

Epoch: 5| Step: 1
Training loss: 2.7993109979316104
Validation loss: 2.6071847712366427

Epoch: 5| Step: 2
Training loss: 2.6146685420484626
Validation loss: 2.576853172246788

Epoch: 5| Step: 3
Training loss: 2.2744211906822605
Validation loss: 2.62584350733564

Epoch: 5| Step: 4
Training loss: 2.43158973732521
Validation loss: 2.6394299655317797

Epoch: 5| Step: 5
Training loss: 2.502636854029072
Validation loss: 2.629317670959744

Epoch: 5| Step: 6
Training loss: 2.6228226305219304
Validation loss: 2.5671913767934225

Epoch: 5| Step: 7
Training loss: 2.795198758723437
Validation loss: 2.555445371732615

Epoch: 5| Step: 8
Training loss: 2.972653362658749
Validation loss: 2.592196911226058

Epoch: 5| Step: 9
Training loss: 2.8106505352995397
Validation loss: 2.6008639676576326

Epoch: 5| Step: 10
Training loss: 2.8193758521377874
Validation loss: 2.487730542553486

Epoch: 188| Step: 0
Training loss: 2.943914511714414
Validation loss: 2.582981108100901

Epoch: 5| Step: 1
Training loss: 2.639503737536424
Validation loss: 2.6309829420890143

Epoch: 5| Step: 2
Training loss: 3.1463582861918145
Validation loss: 2.585155001240041

Epoch: 5| Step: 3
Training loss: 2.9606063778408163
Validation loss: 2.523548699423019

Epoch: 5| Step: 4
Training loss: 2.5105378265478957
Validation loss: 2.582533557421556

Epoch: 5| Step: 5
Training loss: 2.5485741499721946
Validation loss: 2.6138047223882674

Epoch: 5| Step: 6
Training loss: 2.3479218039220906
Validation loss: 2.6098268415025827

Epoch: 5| Step: 7
Training loss: 2.8760360841145416
Validation loss: 2.5677957354968024

Epoch: 5| Step: 8
Training loss: 2.353742229268541
Validation loss: 2.6135227386031548

Epoch: 5| Step: 9
Training loss: 2.38533961631128
Validation loss: 2.6172089165815478

Epoch: 5| Step: 10
Training loss: 3.089457298446732
Validation loss: 2.564886568987493

Epoch: 189| Step: 0
Training loss: 2.458218868198535
Validation loss: 2.5817600302836254

Epoch: 5| Step: 1
Training loss: 2.876210828478747
Validation loss: 2.625673855078205

Epoch: 5| Step: 2
Training loss: 2.492362467683744
Validation loss: 2.5600508794596166

Epoch: 5| Step: 3
Training loss: 2.5937583647443714
Validation loss: 2.5820886595224057

Epoch: 5| Step: 4
Training loss: 2.3251775735293
Validation loss: 2.602857459649811

Epoch: 5| Step: 5
Training loss: 3.6243447336353065
Validation loss: 2.608786464688889

Epoch: 5| Step: 6
Training loss: 1.6379456212212917
Validation loss: 2.622456883746327

Epoch: 5| Step: 7
Training loss: 3.277614505027535
Validation loss: 2.5563305215082632

Epoch: 5| Step: 8
Training loss: 2.657047466171388
Validation loss: 2.552688860969828

Epoch: 5| Step: 9
Training loss: 2.739813752631534
Validation loss: 2.533202110960342

Epoch: 5| Step: 10
Training loss: 3.0706819501301306
Validation loss: 2.5356289970626507

Epoch: 190| Step: 0
Training loss: 2.859965612564898
Validation loss: 2.525783716869094

Epoch: 5| Step: 1
Training loss: 2.52733742950451
Validation loss: 2.6648792091190168

Epoch: 5| Step: 2
Training loss: 2.5848310702407864
Validation loss: 2.6128401816095215

Epoch: 5| Step: 3
Training loss: 2.405611225900441
Validation loss: 2.6531205226392207

Epoch: 5| Step: 4
Training loss: 2.4475476467026414
Validation loss: 2.5373724177493724

Epoch: 5| Step: 5
Training loss: 3.161202350708354
Validation loss: 2.621988433355702

Epoch: 5| Step: 6
Training loss: 3.1622530814415257
Validation loss: 2.605449910317231

Epoch: 5| Step: 7
Training loss: 3.1257915257344844
Validation loss: 2.5356962732739263

Epoch: 5| Step: 8
Training loss: 2.4226527780202267
Validation loss: 2.6397423280768044

Epoch: 5| Step: 9
Training loss: 2.7050370526552485
Validation loss: 2.615810109587141

Epoch: 5| Step: 10
Training loss: 2.539022310379044
Validation loss: 2.578095051034325

Epoch: 191| Step: 0
Training loss: 3.468743401598454
Validation loss: 2.5898914529813393

Epoch: 5| Step: 1
Training loss: 3.225661773205937
Validation loss: 2.531922705116536

Epoch: 5| Step: 2
Training loss: 1.963414667881071
Validation loss: 2.5664467579806063

Epoch: 5| Step: 3
Training loss: 2.62793068547338
Validation loss: 2.533822063801717

Epoch: 5| Step: 4
Training loss: 2.128073993357283
Validation loss: 2.589157159736759

Epoch: 5| Step: 5
Training loss: 3.257951545949822
Validation loss: 2.610378126354496

Epoch: 5| Step: 6
Training loss: 2.0648158394482015
Validation loss: 2.602481335745049

Epoch: 5| Step: 7
Training loss: 2.9838906738974154
Validation loss: 2.5475569853196083

Epoch: 5| Step: 8
Training loss: 2.7241101973282027
Validation loss: 2.6110444009841416

Epoch: 5| Step: 9
Training loss: 2.300484448704331
Validation loss: 2.6438945478141216

Epoch: 5| Step: 10
Training loss: 2.3003724128415493
Validation loss: 2.593053891129487

Epoch: 192| Step: 0
Training loss: 2.3012191278064176
Validation loss: 2.584166699681265

Epoch: 5| Step: 1
Training loss: 3.3027208035831457
Validation loss: 2.5911948275415972

Epoch: 5| Step: 2
Training loss: 3.1100743719696045
Validation loss: 2.5514906341696637

Epoch: 5| Step: 3
Training loss: 2.579545802863804
Validation loss: 2.5267653008633437

Epoch: 5| Step: 4
Training loss: 2.337863600087902
Validation loss: 2.5762147988262467

Epoch: 5| Step: 5
Training loss: 1.98881778335385
Validation loss: 2.597639594933318

Epoch: 5| Step: 6
Training loss: 2.4929435324641207
Validation loss: 2.6117824000664815

Epoch: 5| Step: 7
Training loss: 2.9280594434697167
Validation loss: 2.558021853352065

Epoch: 5| Step: 8
Training loss: 3.530689701426795
Validation loss: 2.6189777038853923

Epoch: 5| Step: 9
Training loss: 2.658373623326396
Validation loss: 2.5316650048393945

Epoch: 5| Step: 10
Training loss: 2.2261818008214957
Validation loss: 2.5834226946768464

Epoch: 193| Step: 0
Training loss: 2.95393320155567
Validation loss: 2.628116312173935

Epoch: 5| Step: 1
Training loss: 2.641358584019322
Validation loss: 2.60841934637324

Epoch: 5| Step: 2
Training loss: 3.032788073261047
Validation loss: 2.6080069190029866

Epoch: 5| Step: 3
Training loss: 3.1739543244140735
Validation loss: 2.597908500607699

Epoch: 5| Step: 4
Training loss: 2.3172263226436867
Validation loss: 2.584906711889252

Epoch: 5| Step: 5
Training loss: 1.5873833440736616
Validation loss: 2.6830805598746124

Epoch: 5| Step: 6
Training loss: 2.525620027465003
Validation loss: 2.552954601429898

Epoch: 5| Step: 7
Training loss: 3.6985935218562465
Validation loss: 2.619290488245883

Epoch: 5| Step: 8
Training loss: 3.0116899343019985
Validation loss: 2.5483052847557164

Epoch: 5| Step: 9
Training loss: 2.854652047941979
Validation loss: 2.561690123739916

Epoch: 5| Step: 10
Training loss: 1.6705479569229356
Validation loss: 2.5855205068197784

Epoch: 194| Step: 0
Training loss: 3.0020493818944765
Validation loss: 2.5989619301135183

Epoch: 5| Step: 1
Training loss: 3.0541226774606636
Validation loss: 2.6244533446207354

Epoch: 5| Step: 2
Training loss: 3.1009643900431088
Validation loss: 2.5996234130036573

Epoch: 5| Step: 3
Training loss: 3.147023226477409
Validation loss: 2.578613713227052

Epoch: 5| Step: 4
Training loss: 1.9563304994248125
Validation loss: 2.5558832892338623

Epoch: 5| Step: 5
Training loss: 2.5754694353355103
Validation loss: 2.6146425600742123

Epoch: 5| Step: 6
Training loss: 2.4362877986005396
Validation loss: 2.6519079247047714

Epoch: 5| Step: 7
Training loss: 2.253984525964216
Validation loss: 2.6304252870490363

Epoch: 5| Step: 8
Training loss: 3.0765951779685152
Validation loss: 2.585092919485539

Epoch: 5| Step: 9
Training loss: 2.133687716593536
Validation loss: 2.5313753906978165

Epoch: 5| Step: 10
Training loss: 3.062360332184667
Validation loss: 2.583599458602921

Epoch: 195| Step: 0
Training loss: 2.7342680119973397
Validation loss: 2.6434573624775393

Epoch: 5| Step: 1
Training loss: 3.4114924693644384
Validation loss: 2.5351052154516505

Epoch: 5| Step: 2
Training loss: 2.784342300445659
Validation loss: 2.567904875281954

Epoch: 5| Step: 3
Training loss: 2.9956641653912213
Validation loss: 2.6067006337301817

Epoch: 5| Step: 4
Training loss: 3.368335218496674
Validation loss: 2.6458241558876647

Epoch: 5| Step: 5
Training loss: 2.4212661470062873
Validation loss: 2.4995304651178007

Epoch: 5| Step: 6
Training loss: 2.5015180747038523
Validation loss: 2.658698656910768

Epoch: 5| Step: 7
Training loss: 2.402522879024177
Validation loss: 2.5900447002010316

Epoch: 5| Step: 8
Training loss: 2.423078274988489
Validation loss: 2.572652068740921

Epoch: 5| Step: 9
Training loss: 2.8611811369028954
Validation loss: 2.652592827700069

Epoch: 5| Step: 10
Training loss: 2.165729307714991
Validation loss: 2.58157911458276

Epoch: 196| Step: 0
Training loss: 3.0008427707728877
Validation loss: 2.6017328445710115

Epoch: 5| Step: 1
Training loss: 2.170908102064632
Validation loss: 2.576544795019669

Epoch: 5| Step: 2
Training loss: 2.19559137602572
Validation loss: 2.642705928592457

Epoch: 5| Step: 3
Training loss: 2.1973321387502205
Validation loss: 2.6449908451852595

Epoch: 5| Step: 4
Training loss: 3.3330275554279023
Validation loss: 2.655733442175875

Epoch: 5| Step: 5
Training loss: 2.9585416657784243
Validation loss: 2.633241829918532

Epoch: 5| Step: 6
Training loss: 2.893445427769711
Validation loss: 2.6124272147114156

Epoch: 5| Step: 7
Training loss: 2.394008062809598
Validation loss: 2.5738978460319273

Epoch: 5| Step: 8
Training loss: 2.3985666246478865
Validation loss: 2.5904009557150234

Epoch: 5| Step: 9
Training loss: 2.74352568663149
Validation loss: 2.6408701039792124

Epoch: 5| Step: 10
Training loss: 3.1162323599819906
Validation loss: 2.608098105313877

Epoch: 197| Step: 0
Training loss: 2.5231233289031323
Validation loss: 2.5480477603451024

Epoch: 5| Step: 1
Training loss: 2.528527856517563
Validation loss: 2.6329787411109513

Epoch: 5| Step: 2
Training loss: 2.8497288491275454
Validation loss: 2.587872551893424

Epoch: 5| Step: 3
Training loss: 2.5199516477941515
Validation loss: 2.5729757784341634

Epoch: 5| Step: 4
Training loss: 3.077675878610634
Validation loss: 2.6089844681916943

Epoch: 5| Step: 5
Training loss: 2.902240078744419
Validation loss: 2.6082646025885357

Epoch: 5| Step: 6
Training loss: 2.741837612338054
Validation loss: 2.5618545875946643

Epoch: 5| Step: 7
Training loss: 2.4033564224227506
Validation loss: 2.643709820970764

Epoch: 5| Step: 8
Training loss: 3.037738894263574
Validation loss: 2.5806982787046766

Epoch: 5| Step: 9
Training loss: 2.7216848558829203
Validation loss: 2.5528101833837833

Epoch: 5| Step: 10
Training loss: 2.644899599012216
Validation loss: 2.613431455128528

Epoch: 198| Step: 0
Training loss: 2.323030774060879
Validation loss: 2.586938903862995

Epoch: 5| Step: 1
Training loss: 2.514586334943099
Validation loss: 2.511252734343261

Epoch: 5| Step: 2
Training loss: 2.8070600670074017
Validation loss: 2.4905648154022475

Epoch: 5| Step: 3
Training loss: 2.0761742865475763
Validation loss: 2.579905462260341

Epoch: 5| Step: 4
Training loss: 2.7471334949852766
Validation loss: 2.5363502564484617

Epoch: 5| Step: 5
Training loss: 2.2048378636961012
Validation loss: 2.6086380116553753

Epoch: 5| Step: 6
Training loss: 3.275785273397765
Validation loss: 2.5920185369237396

Epoch: 5| Step: 7
Training loss: 3.301312682579707
Validation loss: 2.5746728879082417

Epoch: 5| Step: 8
Training loss: 2.7991172284500623
Validation loss: 2.5696451279672377

Epoch: 5| Step: 9
Training loss: 2.915850461560841
Validation loss: 2.5455501937554907

Epoch: 5| Step: 10
Training loss: 2.5324938508361092
Validation loss: 2.5536231108182617

Epoch: 199| Step: 0
Training loss: 2.5368295093789337
Validation loss: 2.523348417455521

Epoch: 5| Step: 1
Training loss: 2.9857484543071373
Validation loss: 2.5427378739375355

Epoch: 5| Step: 2
Training loss: 2.2839742619522343
Validation loss: 2.5859853176673444

Epoch: 5| Step: 3
Training loss: 2.7300356192588175
Validation loss: 2.578810071864208

Epoch: 5| Step: 4
Training loss: 2.0920466996007874
Validation loss: 2.618145387608966

Epoch: 5| Step: 5
Training loss: 2.922011101964687
Validation loss: 2.58970283443305

Epoch: 5| Step: 6
Training loss: 3.2664252217911285
Validation loss: 2.5207192908653937

Epoch: 5| Step: 7
Training loss: 2.7925034782367515
Validation loss: 2.61050589974569

Epoch: 5| Step: 8
Training loss: 2.756928212982577
Validation loss: 2.615618574132823

Epoch: 5| Step: 9
Training loss: 3.0293285139486543
Validation loss: 2.5868060844798726

Epoch: 5| Step: 10
Training loss: 2.2638891476226015
Validation loss: 2.583348778973894

Epoch: 200| Step: 0
Training loss: 2.963614428833158
Validation loss: 2.6195438831893365

Epoch: 5| Step: 1
Training loss: 2.4981776271122125
Validation loss: 2.5937931122936075

Epoch: 5| Step: 2
Training loss: 2.5854888250182855
Validation loss: 2.633620923736285

Epoch: 5| Step: 3
Training loss: 2.646087684320301
Validation loss: 2.4962093707725534

Epoch: 5| Step: 4
Training loss: 2.9484532455403962
Validation loss: 2.608051361497368

Epoch: 5| Step: 5
Training loss: 2.7803224881517896
Validation loss: 2.6460459685655286

Epoch: 5| Step: 6
Training loss: 2.6388521281130233
Validation loss: 2.581374624300307

Epoch: 5| Step: 7
Training loss: 2.591420241862381
Validation loss: 2.5562997154810754

Epoch: 5| Step: 8
Training loss: 2.4875438322106387
Validation loss: 2.545452661660745

Epoch: 5| Step: 9
Training loss: 3.109939907266158
Validation loss: 2.590798221612062

Epoch: 5| Step: 10
Training loss: 2.5121517490424985
Validation loss: 2.6487465035486215

Epoch: 201| Step: 0
Training loss: 3.4068257256518684
Validation loss: 2.5562927214442874

Epoch: 5| Step: 1
Training loss: 1.9596565591848114
Validation loss: 2.5945971208028262

Epoch: 5| Step: 2
Training loss: 2.3914173284234774
Validation loss: 2.578938492762477

Epoch: 5| Step: 3
Training loss: 2.3701166845320336
Validation loss: 2.6332121748627064

Epoch: 5| Step: 4
Training loss: 3.2832809702252654
Validation loss: 2.638186476428752

Epoch: 5| Step: 5
Training loss: 2.2046475391294527
Validation loss: 2.635848812489802

Epoch: 5| Step: 6
Training loss: 2.5326296025484725
Validation loss: 2.606116479873792

Epoch: 5| Step: 7
Training loss: 3.046993155511493
Validation loss: 2.5894711413754874

Epoch: 5| Step: 8
Training loss: 3.235834501903034
Validation loss: 2.5320489215876774

Epoch: 5| Step: 9
Training loss: 3.0394159812603987
Validation loss: 2.582407809048617

Epoch: 5| Step: 10
Training loss: 2.032186908325879
Validation loss: 2.551139701958327

Epoch: 202| Step: 0
Training loss: 2.3606493205341987
Validation loss: 2.5638373802008227

Epoch: 5| Step: 1
Training loss: 2.53436445617364
Validation loss: 2.5483773558622453

Epoch: 5| Step: 2
Training loss: 2.997109928409973
Validation loss: 2.629739425482175

Epoch: 5| Step: 3
Training loss: 2.772448640146424
Validation loss: 2.637465840868693

Epoch: 5| Step: 4
Training loss: 2.6175436660053686
Validation loss: 2.5868883002472938

Epoch: 5| Step: 5
Training loss: 2.204673926016306
Validation loss: 2.5402795643443414

Epoch: 5| Step: 6
Training loss: 2.5066186077333366
Validation loss: 2.548936420435007

Epoch: 5| Step: 7
Training loss: 3.282349320590045
Validation loss: 2.5942019007021413

Epoch: 5| Step: 8
Training loss: 2.275513530244209
Validation loss: 2.6376053088140794

Epoch: 5| Step: 9
Training loss: 2.872357522404067
Validation loss: 2.65194681345289

Epoch: 5| Step: 10
Training loss: 2.841613134362822
Validation loss: 2.626322341430754

Epoch: 203| Step: 0
Training loss: 2.8537313495950563
Validation loss: 2.5471364001718095

Epoch: 5| Step: 1
Training loss: 3.2871726217548787
Validation loss: 2.6008589406435174

Epoch: 5| Step: 2
Training loss: 2.4628718448803215
Validation loss: 2.554095393779331

Epoch: 5| Step: 3
Training loss: 2.360259237760461
Validation loss: 2.5863267172973807

Epoch: 5| Step: 4
Training loss: 2.9584962146316407
Validation loss: 2.620186916435537

Epoch: 5| Step: 5
Training loss: 2.1296603765740585
Validation loss: 2.5979222636025177

Epoch: 5| Step: 6
Training loss: 2.6102970344508196
Validation loss: 2.581068799601828

Epoch: 5| Step: 7
Training loss: 2.6584784640533483
Validation loss: 2.509694377746077

Epoch: 5| Step: 8
Training loss: 2.826372056474064
Validation loss: 2.58201721663181

Epoch: 5| Step: 9
Training loss: 3.1964891128104016
Validation loss: 2.5580241393613377

Epoch: 5| Step: 10
Training loss: 2.470871122777794
Validation loss: 2.6468998958202663

Epoch: 204| Step: 0
Training loss: 2.1023357344424607
Validation loss: 2.6187498500631174

Epoch: 5| Step: 1
Training loss: 1.9751527606458603
Validation loss: 2.581970277171554

Epoch: 5| Step: 2
Training loss: 3.1962325210302223
Validation loss: 2.5692164441777017

Epoch: 5| Step: 3
Training loss: 3.0333471221051496
Validation loss: 2.6193033001023753

Epoch: 5| Step: 4
Training loss: 2.1688112013918395
Validation loss: 2.551966960397558

Epoch: 5| Step: 5
Training loss: 3.3626083072959743
Validation loss: 2.495738941953508

Epoch: 5| Step: 6
Training loss: 3.1386518210700354
Validation loss: 2.584047886716813

Epoch: 5| Step: 7
Training loss: 2.5275633538189224
Validation loss: 2.6681579725490883

Epoch: 5| Step: 8
Training loss: 2.408540304545599
Validation loss: 2.4745218581829587

Epoch: 5| Step: 9
Training loss: 2.9529782213337414
Validation loss: 2.5776700033182918

Epoch: 5| Step: 10
Training loss: 2.893014446065564
Validation loss: 2.583650330046523

Epoch: 205| Step: 0
Training loss: 2.8122178677935854
Validation loss: 2.5875148757507755

Epoch: 5| Step: 1
Training loss: 3.3878647780292863
Validation loss: 2.5930243607682306

Epoch: 5| Step: 2
Training loss: 2.3323597125584787
Validation loss: 2.570053533878566

Epoch: 5| Step: 3
Training loss: 2.458376178260335
Validation loss: 2.5802840026916716

Epoch: 5| Step: 4
Training loss: 2.897147413364675
Validation loss: 2.561641822535571

Epoch: 5| Step: 5
Training loss: 2.9357672917603037
Validation loss: 2.5557382241757334

Epoch: 5| Step: 6
Training loss: 3.1124805679633902
Validation loss: 2.583015528199673

Epoch: 5| Step: 7
Training loss: 2.4191873711902248
Validation loss: 2.532874722924209

Epoch: 5| Step: 8
Training loss: 2.3296975578843186
Validation loss: 2.5968969996676865

Epoch: 5| Step: 9
Training loss: 2.230494724529965
Validation loss: 2.5329853076518343

Epoch: 5| Step: 10
Training loss: 2.435277169841539
Validation loss: 2.54544377761672

Epoch: 206| Step: 0
Training loss: 2.8743759804906666
Validation loss: 2.59268303027908

Epoch: 5| Step: 1
Training loss: 2.2539977479870976
Validation loss: 2.5805447913655337

Epoch: 5| Step: 2
Training loss: 2.337318037977874
Validation loss: 2.504133970922036

Epoch: 5| Step: 3
Training loss: 3.048166793464762
Validation loss: 2.61033189674532

Epoch: 5| Step: 4
Training loss: 3.176714282671331
Validation loss: 2.5523403323776988

Epoch: 5| Step: 5
Training loss: 2.01370064597384
Validation loss: 2.584613162155391

Epoch: 5| Step: 6
Training loss: 2.163992209274173
Validation loss: 2.62408615940996

Epoch: 5| Step: 7
Training loss: 3.1406169530661057
Validation loss: 2.5655121536241525

Epoch: 5| Step: 8
Training loss: 2.728107091401388
Validation loss: 2.547551471219572

Epoch: 5| Step: 9
Training loss: 2.642819006655756
Validation loss: 2.5697091152992244

Epoch: 5| Step: 10
Training loss: 3.2061489810608186
Validation loss: 2.5568518921589707

Epoch: 207| Step: 0
Training loss: 2.4791963933450094
Validation loss: 2.5902757045774907

Epoch: 5| Step: 1
Training loss: 3.0859160217310304
Validation loss: 2.5259590093961086

Epoch: 5| Step: 2
Training loss: 2.6704970705051636
Validation loss: 2.612642366306556

Epoch: 5| Step: 3
Training loss: 2.7762532299697957
Validation loss: 2.58839619090066

Epoch: 5| Step: 4
Training loss: 2.824441186104506
Validation loss: 2.527306498307371

Epoch: 5| Step: 5
Training loss: 2.5639493611612383
Validation loss: 2.6756010750125943

Epoch: 5| Step: 6
Training loss: 2.8146543940438153
Validation loss: 2.5668883715607733

Epoch: 5| Step: 7
Training loss: 2.3802707811395387
Validation loss: 2.6048812581449776

Epoch: 5| Step: 8
Training loss: 2.992306380736486
Validation loss: 2.6262464869705795

Epoch: 5| Step: 9
Training loss: 2.3350777463202084
Validation loss: 2.56789996744073

Epoch: 5| Step: 10
Training loss: 2.7401274417559867
Validation loss: 2.5884217658113653

Epoch: 208| Step: 0
Training loss: 2.892975217774383
Validation loss: 2.577354536282712

Epoch: 5| Step: 1
Training loss: 2.738300317978145
Validation loss: 2.618531426101514

Epoch: 5| Step: 2
Training loss: 2.5454834488986458
Validation loss: 2.602432937550017

Epoch: 5| Step: 3
Training loss: 2.4836228869643877
Validation loss: 2.5477595099094215

Epoch: 5| Step: 4
Training loss: 2.785362118339291
Validation loss: 2.5337775294204437

Epoch: 5| Step: 5
Training loss: 2.967405958605756
Validation loss: 2.6145487918164623

Epoch: 5| Step: 6
Training loss: 2.4394478473346632
Validation loss: 2.5827230380291595

Epoch: 5| Step: 7
Training loss: 3.3789055443911837
Validation loss: 2.6153260641003455

Epoch: 5| Step: 8
Training loss: 3.148183353285402
Validation loss: 2.5839897592675554

Epoch: 5| Step: 9
Training loss: 1.9263104375211386
Validation loss: 2.64625534000734

Epoch: 5| Step: 10
Training loss: 2.1239018688270375
Validation loss: 2.578783676911124

Epoch: 209| Step: 0
Training loss: 2.661952282083096
Validation loss: 2.595018463380473

Epoch: 5| Step: 1
Training loss: 2.779720528777872
Validation loss: 2.613032398514975

Epoch: 5| Step: 2
Training loss: 2.726035867893075
Validation loss: 2.5859699109063206

Epoch: 5| Step: 3
Training loss: 2.6054848551788603
Validation loss: 2.5748083762736047

Epoch: 5| Step: 4
Training loss: 2.2229905773723337
Validation loss: 2.584273980481321

Epoch: 5| Step: 5
Training loss: 2.4635762917233963
Validation loss: 2.620518379909872

Epoch: 5| Step: 6
Training loss: 3.29078784912804
Validation loss: 2.70951906062916

Epoch: 5| Step: 7
Training loss: 2.766335950947726
Validation loss: 2.6101981334691886

Epoch: 5| Step: 8
Training loss: 2.569107840086543
Validation loss: 2.596258824843696

Epoch: 5| Step: 9
Training loss: 3.0717003090627655
Validation loss: 2.549880216014198

Epoch: 5| Step: 10
Training loss: 2.5594190358529465
Validation loss: 2.5455668668557303

Epoch: 210| Step: 0
Training loss: 2.7990898015321006
Validation loss: 2.5776934121082355

Epoch: 5| Step: 1
Training loss: 2.892749397518434
Validation loss: 2.6256293173839422

Epoch: 5| Step: 2
Training loss: 2.583611863000415
Validation loss: 2.6183188263166497

Epoch: 5| Step: 3
Training loss: 2.8336690442031505
Validation loss: 2.591461896158089

Epoch: 5| Step: 4
Training loss: 2.5830841456998392
Validation loss: 2.5331167156252956

Epoch: 5| Step: 5
Training loss: 2.5830919911850443
Validation loss: 2.635058281897573

Epoch: 5| Step: 6
Training loss: 2.355597193617857
Validation loss: 2.5407563678573886

Epoch: 5| Step: 7
Training loss: 2.4608044785167387
Validation loss: 2.6224563177320306

Epoch: 5| Step: 8
Training loss: 2.5681722246452736
Validation loss: 2.6054405686493176

Epoch: 5| Step: 9
Training loss: 3.285168732790642
Validation loss: 2.565653703381702

Epoch: 5| Step: 10
Training loss: 2.741262774492062
Validation loss: 2.6318845830209154

Epoch: 211| Step: 0
Training loss: 3.090605553854157
Validation loss: 2.6501198899957714

Epoch: 5| Step: 1
Training loss: 2.475240456816525
Validation loss: 2.624669055615395

Epoch: 5| Step: 2
Training loss: 2.5944326031088134
Validation loss: 2.630411224353627

Epoch: 5| Step: 3
Training loss: 2.994366442581144
Validation loss: 2.6018073051074815

Epoch: 5| Step: 4
Training loss: 2.871172471816181
Validation loss: 2.550572912500363

Epoch: 5| Step: 5
Training loss: 2.58721597190697
Validation loss: 2.5691118245861264

Epoch: 5| Step: 6
Training loss: 2.957138482874445
Validation loss: 2.58602560768312

Epoch: 5| Step: 7
Training loss: 2.5984862872949726
Validation loss: 2.7036454463599746

Epoch: 5| Step: 8
Training loss: 2.247890543204022
Validation loss: 2.6132338729397833

Epoch: 5| Step: 9
Training loss: 2.770437848159369
Validation loss: 2.575173831229012

Epoch: 5| Step: 10
Training loss: 2.505879735826771
Validation loss: 2.620304261957021

Epoch: 212| Step: 0
Training loss: 2.7357939607883908
Validation loss: 2.5903659147473714

Epoch: 5| Step: 1
Training loss: 3.152025473787029
Validation loss: 2.55092712456593

Epoch: 5| Step: 2
Training loss: 2.775568441644949
Validation loss: 2.6021190923580537

Epoch: 5| Step: 3
Training loss: 2.25054130400694
Validation loss: 2.673147139882965

Epoch: 5| Step: 4
Training loss: 2.1751956939354407
Validation loss: 2.609561507002425

Epoch: 5| Step: 5
Training loss: 2.9822097033341977
Validation loss: 2.61746357670947

Epoch: 5| Step: 6
Training loss: 2.395531997527476
Validation loss: 2.5639233731591133

Epoch: 5| Step: 7
Training loss: 3.064520344626048
Validation loss: 2.5831004698401134

Epoch: 5| Step: 8
Training loss: 2.5657127523341803
Validation loss: 2.6245839550535

Epoch: 5| Step: 9
Training loss: 2.8819287607361166
Validation loss: 2.5792350738368657

Epoch: 5| Step: 10
Training loss: 2.9264868584433454
Validation loss: 2.4964730908185766

Epoch: 213| Step: 0
Training loss: 2.3498291521667185
Validation loss: 2.6053007461300877

Epoch: 5| Step: 1
Training loss: 3.1758025709424214
Validation loss: 2.593381808879411

Epoch: 5| Step: 2
Training loss: 2.3024409319894166
Validation loss: 2.615768547038164

Epoch: 5| Step: 3
Training loss: 2.9707039275660487
Validation loss: 2.6079685389201894

Epoch: 5| Step: 4
Training loss: 2.595400365620173
Validation loss: 2.5940552329390774

Epoch: 5| Step: 5
Training loss: 2.3296199837411766
Validation loss: 2.5994569865322514

Epoch: 5| Step: 6
Training loss: 2.86505446750068
Validation loss: 2.5821724134588058

Epoch: 5| Step: 7
Training loss: 2.0610765110937828
Validation loss: 2.6096603181565317

Epoch: 5| Step: 8
Training loss: 2.9166269753798106
Validation loss: 2.567790448061125

Epoch: 5| Step: 9
Training loss: 2.329003699463936
Validation loss: 2.636754593994841

Epoch: 5| Step: 10
Training loss: 3.323619676483194
Validation loss: 2.604841692324757

Epoch: 214| Step: 0
Training loss: 2.2357282475323257
Validation loss: 2.5570349543876976

Epoch: 5| Step: 1
Training loss: 2.591314344182309
Validation loss: 2.6130378436027244

Epoch: 5| Step: 2
Training loss: 2.768747409793512
Validation loss: 2.5479357375393636

Epoch: 5| Step: 3
Training loss: 3.1600605840549103
Validation loss: 2.5291504472011535

Epoch: 5| Step: 4
Training loss: 3.104618594322165
Validation loss: 2.6116466266161025

Epoch: 5| Step: 5
Training loss: 2.732741734595585
Validation loss: 2.545517782841588

Epoch: 5| Step: 6
Training loss: 2.0792078624407893
Validation loss: 2.5353306361581347

Epoch: 5| Step: 7
Training loss: 2.5010615955868487
Validation loss: 2.625183477010472

Epoch: 5| Step: 8
Training loss: 2.8842019141805406
Validation loss: 2.553463311415543

Epoch: 5| Step: 9
Training loss: 2.9599728585622693
Validation loss: 2.556260482839201

Epoch: 5| Step: 10
Training loss: 2.1852327859163654
Validation loss: 2.6256317276038317

Epoch: 215| Step: 0
Training loss: 2.894189070477495
Validation loss: 2.6187206985518543

Epoch: 5| Step: 1
Training loss: 2.566342055448327
Validation loss: 2.610021010035228

Epoch: 5| Step: 2
Training loss: 2.433685154063209
Validation loss: 2.6216643455257853

Epoch: 5| Step: 3
Training loss: 2.8736152631277827
Validation loss: 2.577215899157447

Epoch: 5| Step: 4
Training loss: 2.2013417054049285
Validation loss: 2.5944663940224006

Epoch: 5| Step: 5
Training loss: 2.5540701677306936
Validation loss: 2.6087619723825313

Epoch: 5| Step: 6
Training loss: 3.0527871701488767
Validation loss: 2.649177708458802

Epoch: 5| Step: 7
Training loss: 3.253252602602185
Validation loss: 2.599031476475235

Epoch: 5| Step: 8
Training loss: 2.0710627509998583
Validation loss: 2.5746106629291696

Epoch: 5| Step: 9
Training loss: 3.095567111808978
Validation loss: 2.6078172395721686

Epoch: 5| Step: 10
Training loss: 2.7551731523215888
Validation loss: 2.584130542919293

Epoch: 216| Step: 0
Training loss: 2.6765825171760427
Validation loss: 2.6094922329290857

Epoch: 5| Step: 1
Training loss: 1.9965819715433166
Validation loss: 2.6101787337089335

Epoch: 5| Step: 2
Training loss: 3.183774678524421
Validation loss: 2.5889108034425177

Epoch: 5| Step: 3
Training loss: 2.8050436574764968
Validation loss: 2.6016038184761996

Epoch: 5| Step: 4
Training loss: 2.7688992186694326
Validation loss: 2.630836537693196

Epoch: 5| Step: 5
Training loss: 2.5629361409519467
Validation loss: 2.5941972115968692

Epoch: 5| Step: 6
Training loss: 2.400984315883723
Validation loss: 2.626563967228011

Epoch: 5| Step: 7
Training loss: 3.089446957425646
Validation loss: 2.59119309021393

Epoch: 5| Step: 8
Training loss: 3.0588827763942965
Validation loss: 2.623866071202865

Epoch: 5| Step: 9
Training loss: 2.6040098117637656
Validation loss: 2.597687700506665

Epoch: 5| Step: 10
Training loss: 2.0888794002024356
Validation loss: 2.5932042871884207

Epoch: 217| Step: 0
Training loss: 3.0535743031372715
Validation loss: 2.527527058793903

Epoch: 5| Step: 1
Training loss: 2.5213941680586585
Validation loss: 2.6188891331845494

Epoch: 5| Step: 2
Training loss: 3.4268983522406025
Validation loss: 2.6527287286600147

Epoch: 5| Step: 3
Training loss: 2.3217818106719648
Validation loss: 2.598307351195031

Epoch: 5| Step: 4
Training loss: 2.5242897696674125
Validation loss: 2.598242338501917

Epoch: 5| Step: 5
Training loss: 2.5614458102157607
Validation loss: 2.6592363685441063

Epoch: 5| Step: 6
Training loss: 2.2593303712945687
Validation loss: 2.650998341692497

Epoch: 5| Step: 7
Training loss: 3.221690492129124
Validation loss: 2.5771889507160735

Epoch: 5| Step: 8
Training loss: 2.9032442690491274
Validation loss: 2.5743366234199057

Epoch: 5| Step: 9
Training loss: 2.560509071100127
Validation loss: 2.5743493637332797

Epoch: 5| Step: 10
Training loss: 2.360469538968248
Validation loss: 2.5888113394437067

Epoch: 218| Step: 0
Training loss: 1.892482570129516
Validation loss: 2.592886380545409

Epoch: 5| Step: 1
Training loss: 2.7833507190854245
Validation loss: 2.532231763222801

Epoch: 5| Step: 2
Training loss: 2.321755830522702
Validation loss: 2.576277269657711

Epoch: 5| Step: 3
Training loss: 2.8139049835430994
Validation loss: 2.608581339742263

Epoch: 5| Step: 4
Training loss: 3.068208628835966
Validation loss: 2.565730559379415

Epoch: 5| Step: 5
Training loss: 2.873499935067174
Validation loss: 2.5257277487853855

Epoch: 5| Step: 6
Training loss: 2.6351796723406884
Validation loss: 2.550964993082378

Epoch: 5| Step: 7
Training loss: 2.984236629134324
Validation loss: 2.553993255451507

Epoch: 5| Step: 8
Training loss: 3.1986535100482123
Validation loss: 2.617161281492937

Epoch: 5| Step: 9
Training loss: 2.6282025737404116
Validation loss: 2.622945875433819

Epoch: 5| Step: 10
Training loss: 2.139243578160383
Validation loss: 2.624357116464952

Epoch: 219| Step: 0
Training loss: 2.5280379649341578
Validation loss: 2.6313000164968683

Epoch: 5| Step: 1
Training loss: 2.5359553178406897
Validation loss: 2.6143350571971995

Epoch: 5| Step: 2
Training loss: 2.817043618554802
Validation loss: 2.5415651942317736

Epoch: 5| Step: 3
Training loss: 2.93228189162979
Validation loss: 2.5731296604756144

Epoch: 5| Step: 4
Training loss: 3.2624811983114843
Validation loss: 2.6198475679922852

Epoch: 5| Step: 5
Training loss: 2.761022498868456
Validation loss: 2.5914015404427264

Epoch: 5| Step: 6
Training loss: 2.628668537700676
Validation loss: 2.625741229903021

Epoch: 5| Step: 7
Training loss: 2.2286871159572264
Validation loss: 2.638816965465454

Epoch: 5| Step: 8
Training loss: 2.549416987771726
Validation loss: 2.536718849686852

Epoch: 5| Step: 9
Training loss: 2.930485242951289
Validation loss: 2.5910478203702145

Epoch: 5| Step: 10
Training loss: 2.78458787166445
Validation loss: 2.6742690305827237

Epoch: 220| Step: 0
Training loss: 3.1842527117098056
Validation loss: 2.6454214412213064

Epoch: 5| Step: 1
Training loss: 2.553430650548043
Validation loss: 2.6503236697955046

Epoch: 5| Step: 2
Training loss: 3.4721021521259083
Validation loss: 2.5772907566710392

Epoch: 5| Step: 3
Training loss: 2.7067182175498634
Validation loss: 2.559932422853184

Epoch: 5| Step: 4
Training loss: 3.0172004339888168
Validation loss: 2.548263794229266

Epoch: 5| Step: 5
Training loss: 2.582276764016635
Validation loss: 2.5604302536105883

Epoch: 5| Step: 6
Training loss: 2.445872964705804
Validation loss: 2.5815530806171902

Epoch: 5| Step: 7
Training loss: 2.2614017455478463
Validation loss: 2.6120569001242013

Epoch: 5| Step: 8
Training loss: 2.6628538729333595
Validation loss: 2.5530809138266433

Epoch: 5| Step: 9
Training loss: 3.0399247150133863
Validation loss: 2.6462416685412666

Epoch: 5| Step: 10
Training loss: 2.4745561914667773
Validation loss: 2.567602780972386

Epoch: 221| Step: 0
Training loss: 3.1122843104623956
Validation loss: 2.5897928324257298

Epoch: 5| Step: 1
Training loss: 2.6414538104185095
Validation loss: 2.580813561060803

Epoch: 5| Step: 2
Training loss: 2.057208932750162
Validation loss: 2.6090644119573634

Epoch: 5| Step: 3
Training loss: 3.107149027049386
Validation loss: 2.576793992565026

Epoch: 5| Step: 4
Training loss: 2.930513229988511
Validation loss: 2.6141864053858623

Epoch: 5| Step: 5
Training loss: 3.217829600467757
Validation loss: 2.5720495478535197

Epoch: 5| Step: 6
Training loss: 2.10142363475921
Validation loss: 2.5706338964208175

Epoch: 5| Step: 7
Training loss: 2.94731982404398
Validation loss: 2.629966775593925

Epoch: 5| Step: 8
Training loss: 2.4021643098635095
Validation loss: 2.5713491295907023

Epoch: 5| Step: 9
Training loss: 2.0999898592386175
Validation loss: 2.622880316191349

Epoch: 5| Step: 10
Training loss: 2.8984546095350807
Validation loss: 2.4837478085411133

Epoch: 222| Step: 0
Training loss: 2.840810577071665
Validation loss: 2.661152779115807

Epoch: 5| Step: 1
Training loss: 2.6369548324576266
Validation loss: 2.5811350314880883

Epoch: 5| Step: 2
Training loss: 2.347048764964386
Validation loss: 2.6709680337805657

Epoch: 5| Step: 3
Training loss: 2.809477305008168
Validation loss: 2.5868455683931364

Epoch: 5| Step: 4
Training loss: 2.0329254283222347
Validation loss: 2.5169642852744407

Epoch: 5| Step: 5
Training loss: 2.3915022692740373
Validation loss: 2.628625458072928

Epoch: 5| Step: 6
Training loss: 2.281526104665904
Validation loss: 2.6601036507116733

Epoch: 5| Step: 7
Training loss: 3.0923529659216986
Validation loss: 2.6505219652659204

Epoch: 5| Step: 8
Training loss: 2.401744240490339
Validation loss: 2.537756211545415

Epoch: 5| Step: 9
Training loss: 3.707880756892868
Validation loss: 2.618795707872124

Epoch: 5| Step: 10
Training loss: 2.723357494796471
Validation loss: 2.697501839858348

Epoch: 223| Step: 0
Training loss: 3.025695430800301
Validation loss: 2.679492934885362

Epoch: 5| Step: 1
Training loss: 2.824990827832481
Validation loss: 2.6175086402172605

Epoch: 5| Step: 2
Training loss: 2.3654774951174713
Validation loss: 2.4958384845491555

Epoch: 5| Step: 3
Training loss: 2.8152073015816983
Validation loss: 2.7231065091186664

Epoch: 5| Step: 4
Training loss: 3.0077800005853796
Validation loss: 2.589586621232742

Epoch: 5| Step: 5
Training loss: 2.342797454545506
Validation loss: 2.620674399658654

Epoch: 5| Step: 6
Training loss: 2.4762973583300854
Validation loss: 2.554147870630087

Epoch: 5| Step: 7
Training loss: 2.867705337369504
Validation loss: 2.5748788881398537

Epoch: 5| Step: 8
Training loss: 2.3840485915601985
Validation loss: 2.653074279274824

Epoch: 5| Step: 9
Training loss: 2.896737558999395
Validation loss: 2.597058931916672

Epoch: 5| Step: 10
Training loss: 2.896825624969002
Validation loss: 2.6092335131664637

Epoch: 224| Step: 0
Training loss: 2.6452906094505506
Validation loss: 2.6637032146018487

Epoch: 5| Step: 1
Training loss: 3.19953277872508
Validation loss: 2.57059152664963

Epoch: 5| Step: 2
Training loss: 2.3465253546641653
Validation loss: 2.5980580285259256

Epoch: 5| Step: 3
Training loss: 2.8015561275547993
Validation loss: 2.555168789655003

Epoch: 5| Step: 4
Training loss: 2.9191581620391864
Validation loss: 2.5371464423440435

Epoch: 5| Step: 5
Training loss: 1.5050493924219766
Validation loss: 2.61169496204521

Epoch: 5| Step: 6
Training loss: 3.107223916836434
Validation loss: 2.5826215355512168

Epoch: 5| Step: 7
Training loss: 2.4200267014724948
Validation loss: 2.614806579764686

Epoch: 5| Step: 8
Training loss: 2.2858285811492256
Validation loss: 2.572556670300249

Epoch: 5| Step: 9
Training loss: 2.3227832111517213
Validation loss: 2.5513750638359154

Epoch: 5| Step: 10
Training loss: 3.673827086655887
Validation loss: 2.5657651974078974

Epoch: 225| Step: 0
Training loss: 3.1070046135727263
Validation loss: 2.565233105149114

Epoch: 5| Step: 1
Training loss: 2.4011954191439666
Validation loss: 2.611734296437412

Epoch: 5| Step: 2
Training loss: 2.188141429047305
Validation loss: 2.624503977057068

Epoch: 5| Step: 3
Training loss: 2.5226172658318675
Validation loss: 2.6145106656334876

Epoch: 5| Step: 4
Training loss: 3.147248680255676
Validation loss: 2.5205627949814073

Epoch: 5| Step: 5
Training loss: 2.3432297192705946
Validation loss: 2.6631706577462047

Epoch: 5| Step: 6
Training loss: 3.2483065668226248
Validation loss: 2.571341556351145

Epoch: 5| Step: 7
Training loss: 2.9410953028081552
Validation loss: 2.581315487695812

Epoch: 5| Step: 8
Training loss: 3.146417390949791
Validation loss: 2.572076356778282

Epoch: 5| Step: 9
Training loss: 2.456091575269709
Validation loss: 2.5917236274252637

Epoch: 5| Step: 10
Training loss: 2.338027988308735
Validation loss: 2.6456838237238474

Epoch: 226| Step: 0
Training loss: 2.8079664354790816
Validation loss: 2.5538358111292654

Epoch: 5| Step: 1
Training loss: 2.303572459342109
Validation loss: 2.5392265717383142

Epoch: 5| Step: 2
Training loss: 2.4748207489761733
Validation loss: 2.566099370689074

Epoch: 5| Step: 3
Training loss: 2.5031387652567534
Validation loss: 2.5672528209545535

Epoch: 5| Step: 4
Training loss: 3.0895201155474874
Validation loss: 2.5333327122845666

Epoch: 5| Step: 5
Training loss: 2.757396374827859
Validation loss: 2.713456589230694

Epoch: 5| Step: 6
Training loss: 2.60115089253368
Validation loss: 2.6651657731443166

Epoch: 5| Step: 7
Training loss: 2.573924301048039
Validation loss: 2.5923981972086563

Epoch: 5| Step: 8
Training loss: 2.8772166455813424
Validation loss: 2.5703519300801467

Epoch: 5| Step: 9
Training loss: 2.9140752633559295
Validation loss: 2.601662317536593

Epoch: 5| Step: 10
Training loss: 2.584673708128404
Validation loss: 2.5044131796493687

Epoch: 227| Step: 0
Training loss: 2.51689883375949
Validation loss: 2.609720143538432

Epoch: 5| Step: 1
Training loss: 3.0950342460549494
Validation loss: 2.5372227629507185

Epoch: 5| Step: 2
Training loss: 2.852478381918349
Validation loss: 2.5534730862015533

Epoch: 5| Step: 3
Training loss: 2.686800133708515
Validation loss: 2.579216874477637

Epoch: 5| Step: 4
Training loss: 2.746481117937818
Validation loss: 2.5504756649530327

Epoch: 5| Step: 5
Training loss: 2.55027300925262
Validation loss: 2.555780696745421

Epoch: 5| Step: 6
Training loss: 2.713354171357365
Validation loss: 2.5956544670844903

Epoch: 5| Step: 7
Training loss: 3.0070828432140257
Validation loss: 2.599737496214797

Epoch: 5| Step: 8
Training loss: 2.946106659449474
Validation loss: 2.585344558446273

Epoch: 5| Step: 9
Training loss: 2.1672958291942233
Validation loss: 2.6154250485685715

Epoch: 5| Step: 10
Training loss: 2.488384538120687
Validation loss: 2.5691333325946264

Epoch: 228| Step: 0
Training loss: 2.3036990357431537
Validation loss: 2.5959051108814264

Epoch: 5| Step: 1
Training loss: 2.8065748744581787
Validation loss: 2.616342370941936

Epoch: 5| Step: 2
Training loss: 3.325407109398382
Validation loss: 2.609474391958914

Epoch: 5| Step: 3
Training loss: 2.47563177965445
Validation loss: 2.5715206192106588

Epoch: 5| Step: 4
Training loss: 2.738183557179843
Validation loss: 2.5746228059394793

Epoch: 5| Step: 5
Training loss: 2.8301384434350183
Validation loss: 2.5559200933355846

Epoch: 5| Step: 6
Training loss: 2.8064525437698262
Validation loss: 2.5351193224351176

Epoch: 5| Step: 7
Training loss: 2.0456498534466974
Validation loss: 2.527702914005372

Epoch: 5| Step: 8
Training loss: 2.884122556010895
Validation loss: 2.541683928903279

Epoch: 5| Step: 9
Training loss: 2.4281733170541613
Validation loss: 2.558382272955364

Epoch: 5| Step: 10
Training loss: 2.7785132155132426
Validation loss: 2.631625227917892

Epoch: 229| Step: 0
Training loss: 3.2455024410198074
Validation loss: 2.554180832972636

Epoch: 5| Step: 1
Training loss: 2.890803481081921
Validation loss: 2.5049391516563744

Epoch: 5| Step: 2
Training loss: 3.281072993272569
Validation loss: 2.5953586639038213

Epoch: 5| Step: 3
Training loss: 2.8704431328614923
Validation loss: 2.625154972140839

Epoch: 5| Step: 4
Training loss: 2.2191325113167992
Validation loss: 2.6611552587960317

Epoch: 5| Step: 5
Training loss: 2.647105554405058
Validation loss: 2.586992181127644

Epoch: 5| Step: 6
Training loss: 2.9356550550800398
Validation loss: 2.540330567602105

Epoch: 5| Step: 7
Training loss: 1.9052058002113728
Validation loss: 2.6109238826320285

Epoch: 5| Step: 8
Training loss: 2.2418159416253354
Validation loss: 2.593625185380359

Epoch: 5| Step: 9
Training loss: 2.6908491690335006
Validation loss: 2.5957838442044907

Epoch: 5| Step: 10
Training loss: 2.0373271705016616
Validation loss: 2.5778707061280133

Epoch: 230| Step: 0
Training loss: 2.5947533930208593
Validation loss: 2.6624174349905347

Epoch: 5| Step: 1
Training loss: 2.556810436044385
Validation loss: 2.5320519721782544

Epoch: 5| Step: 2
Training loss: 2.6476614836379095
Validation loss: 2.624092700183251

Epoch: 5| Step: 3
Training loss: 2.520765844865626
Validation loss: 2.577336590220296

Epoch: 5| Step: 4
Training loss: 3.301386056600221
Validation loss: 2.5726929865843866

Epoch: 5| Step: 5
Training loss: 2.5740552743224714
Validation loss: 2.533754354356092

Epoch: 5| Step: 6
Training loss: 2.303447946088241
Validation loss: 2.584979977088163

Epoch: 5| Step: 7
Training loss: 2.7981593417100323
Validation loss: 2.5875718227914843

Epoch: 5| Step: 8
Training loss: 2.6415089589244487
Validation loss: 2.6035621558348865

Epoch: 5| Step: 9
Training loss: 2.58556646814226
Validation loss: 2.645466803743662

Epoch: 5| Step: 10
Training loss: 3.178505567722506
Validation loss: 2.546183765794422

Epoch: 231| Step: 0
Training loss: 2.848228198306608
Validation loss: 2.584577352852579

Epoch: 5| Step: 1
Training loss: 2.3865301429160444
Validation loss: 2.5828470797266427

Epoch: 5| Step: 2
Training loss: 2.9358528876179024
Validation loss: 2.6245232015760616

Epoch: 5| Step: 3
Training loss: 3.332020373846552
Validation loss: 2.589170160306041

Epoch: 5| Step: 4
Training loss: 2.8101650294107627
Validation loss: 2.5899360786411956

Epoch: 5| Step: 5
Training loss: 3.194969401324969
Validation loss: 2.552017375469575

Epoch: 5| Step: 6
Training loss: 2.2452915517192147
Validation loss: 2.5122585712647996

Epoch: 5| Step: 7
Training loss: 2.3228844154297237
Validation loss: 2.563160604808494

Epoch: 5| Step: 8
Training loss: 2.641955700614836
Validation loss: 2.6130926078002905

Epoch: 5| Step: 9
Training loss: 2.4242298122280235
Validation loss: 2.604289635164806

Epoch: 5| Step: 10
Training loss: 2.0608916513984212
Validation loss: 2.608151988333224

Epoch: 232| Step: 0
Training loss: 3.04023120051148
Validation loss: 2.6363754519318263

Epoch: 5| Step: 1
Training loss: 2.912713032409386
Validation loss: 2.5703367288300742

Epoch: 5| Step: 2
Training loss: 2.617701511295738
Validation loss: 2.5914104014739308

Epoch: 5| Step: 3
Training loss: 2.9474736791831644
Validation loss: 2.5443149768164064

Epoch: 5| Step: 4
Training loss: 2.893182231660865
Validation loss: 2.60274802536507

Epoch: 5| Step: 5
Training loss: 1.9503744059369064
Validation loss: 2.6118562762063022

Epoch: 5| Step: 6
Training loss: 2.7859048359015617
Validation loss: 2.551884522687571

Epoch: 5| Step: 7
Training loss: 2.3203994272305986
Validation loss: 2.5822470220503515

Epoch: 5| Step: 8
Training loss: 2.5938321755501903
Validation loss: 2.5632202222784066

Epoch: 5| Step: 9
Training loss: 2.806874562112472
Validation loss: 2.6122036151042387

Epoch: 5| Step: 10
Training loss: 2.2403096167276724
Validation loss: 2.6157961594315173

Epoch: 233| Step: 0
Training loss: 2.7055714732316973
Validation loss: 2.6224417284025496

Epoch: 5| Step: 1
Training loss: 3.013181180432209
Validation loss: 2.6344109572771943

Epoch: 5| Step: 2
Training loss: 1.8872738607992556
Validation loss: 2.6163811494638263

Epoch: 5| Step: 3
Training loss: 2.5503839764688765
Validation loss: 2.584654009666321

Epoch: 5| Step: 4
Training loss: 2.7522099891489633
Validation loss: 2.5168186118513867

Epoch: 5| Step: 5
Training loss: 2.5116392986255303
Validation loss: 2.660231867063281

Epoch: 5| Step: 6
Training loss: 3.0158530035446454
Validation loss: 2.572844496119123

Epoch: 5| Step: 7
Training loss: 2.956298092215022
Validation loss: 2.584601192051979

Epoch: 5| Step: 8
Training loss: 3.0597677693724132
Validation loss: 2.5716727052254744

Epoch: 5| Step: 9
Training loss: 2.114828900389718
Validation loss: 2.629400184739451

Epoch: 5| Step: 10
Training loss: 2.781228740482301
Validation loss: 2.550036385502004

Epoch: 234| Step: 0
Training loss: 3.0239418259731976
Validation loss: 2.5748418492400202

Epoch: 5| Step: 1
Training loss: 2.5628562307470077
Validation loss: 2.577207686632134

Epoch: 5| Step: 2
Training loss: 2.5976758913143723
Validation loss: 2.672267328269554

Epoch: 5| Step: 3
Training loss: 2.828528106792564
Validation loss: 2.5574271459405846

Epoch: 5| Step: 4
Training loss: 2.601136318730836
Validation loss: 2.6357596279341853

Epoch: 5| Step: 5
Training loss: 2.470547564890371
Validation loss: 2.5523650733141934

Epoch: 5| Step: 6
Training loss: 3.131652312788078
Validation loss: 2.5776877212965044

Epoch: 5| Step: 7
Training loss: 2.5757252014559953
Validation loss: 2.6078739408695037

Epoch: 5| Step: 8
Training loss: 2.625833469860187
Validation loss: 2.546662738067173

Epoch: 5| Step: 9
Training loss: 3.2144168463706517
Validation loss: 2.575930632856427

Epoch: 5| Step: 10
Training loss: 1.4220738533896997
Validation loss: 2.5813533295185564

Epoch: 235| Step: 0
Training loss: 2.797897748582574
Validation loss: 2.5781086085579346

Epoch: 5| Step: 1
Training loss: 2.272789721931439
Validation loss: 2.5850384992905853

Epoch: 5| Step: 2
Training loss: 2.5138584355242046
Validation loss: 2.5767926086650745

Epoch: 5| Step: 3
Training loss: 2.925502055844015
Validation loss: 2.6512354602587056

Epoch: 5| Step: 4
Training loss: 2.7185603108496244
Validation loss: 2.5643463406189935

Epoch: 5| Step: 5
Training loss: 2.681987965004222
Validation loss: 2.660651633984506

Epoch: 5| Step: 6
Training loss: 2.583444459637461
Validation loss: 2.5820911625096232

Epoch: 5| Step: 7
Training loss: 2.688054493323364
Validation loss: 2.539054593183576

Epoch: 5| Step: 8
Training loss: 2.7267446375131623
Validation loss: 2.564916701166124

Epoch: 5| Step: 9
Training loss: 3.1804760604170927
Validation loss: 2.5458519171241645

Epoch: 5| Step: 10
Training loss: 1.9652326741189408
Validation loss: 2.6130486493702896

Epoch: 236| Step: 0
Training loss: 2.941885251865552
Validation loss: 2.5810062033798062

Epoch: 5| Step: 1
Training loss: 2.5087424957360827
Validation loss: 2.5785150953133416

Epoch: 5| Step: 2
Training loss: 2.4729504161696694
Validation loss: 2.564482893392731

Epoch: 5| Step: 3
Training loss: 2.8998263339955352
Validation loss: 2.6176704226894802

Epoch: 5| Step: 4
Training loss: 2.5831442322789218
Validation loss: 2.586632538791177

Epoch: 5| Step: 5
Training loss: 2.7843506063812025
Validation loss: 2.573834127181285

Epoch: 5| Step: 6
Training loss: 3.072917270121542
Validation loss: 2.61445829135535

Epoch: 5| Step: 7
Training loss: 3.058040875857137
Validation loss: 2.560807139872232

Epoch: 5| Step: 8
Training loss: 2.365929196753422
Validation loss: 2.560670830590911

Epoch: 5| Step: 9
Training loss: 2.3673134949645265
Validation loss: 2.5361603073720973

Epoch: 5| Step: 10
Training loss: 2.013449507681509
Validation loss: 2.6751043922464928

Epoch: 237| Step: 0
Training loss: 2.501240708516415
Validation loss: 2.6020034928201405

Epoch: 5| Step: 1
Training loss: 3.055466340429087
Validation loss: 2.5360337799697388

Epoch: 5| Step: 2
Training loss: 3.0971529961924276
Validation loss: 2.5703869391915743

Epoch: 5| Step: 3
Training loss: 2.4585970936459427
Validation loss: 2.538924248830607

Epoch: 5| Step: 4
Training loss: 2.1496434381812994
Validation loss: 2.563904070215317

Epoch: 5| Step: 5
Training loss: 2.0961921455529504
Validation loss: 2.544355050593958

Epoch: 5| Step: 6
Training loss: 3.2012532045228435
Validation loss: 2.6022491411183517

Epoch: 5| Step: 7
Training loss: 2.506191787614458
Validation loss: 2.578873796007148

Epoch: 5| Step: 8
Training loss: 2.681214278545601
Validation loss: 2.6319008382560747

Epoch: 5| Step: 9
Training loss: 2.6406705051090213
Validation loss: 2.570524019794587

Epoch: 5| Step: 10
Training loss: 2.8204304255719452
Validation loss: 2.489927851812857

Epoch: 238| Step: 0
Training loss: 2.4993254705254353
Validation loss: 2.564486015365138

Epoch: 5| Step: 1
Training loss: 2.4902016312185515
Validation loss: 2.5390113167853468

Epoch: 5| Step: 2
Training loss: 2.552055379493882
Validation loss: 2.6017013020557918

Epoch: 5| Step: 3
Training loss: 3.1944137092622884
Validation loss: 2.6205000436581942

Epoch: 5| Step: 4
Training loss: 2.51763305130638
Validation loss: 2.5914185363428213

Epoch: 5| Step: 5
Training loss: 2.3680035786472806
Validation loss: 2.5736427116375027

Epoch: 5| Step: 6
Training loss: 2.7655727575507987
Validation loss: 2.632659871657421

Epoch: 5| Step: 7
Training loss: 2.541595510101675
Validation loss: 2.579733603842825

Epoch: 5| Step: 8
Training loss: 3.1569655711991564
Validation loss: 2.6134159119595712

Epoch: 5| Step: 9
Training loss: 1.8547063606415173
Validation loss: 2.6349748935652597

Epoch: 5| Step: 10
Training loss: 3.188972880829809
Validation loss: 2.5292314132066207

Epoch: 239| Step: 0
Training loss: 2.7395798328991323
Validation loss: 2.6543676444523157

Epoch: 5| Step: 1
Training loss: 2.5982612077523957
Validation loss: 2.550810416133282

Epoch: 5| Step: 2
Training loss: 3.0128007224265927
Validation loss: 2.5918922774283883

Epoch: 5| Step: 3
Training loss: 2.8043545071027607
Validation loss: 2.547203233561414

Epoch: 5| Step: 4
Training loss: 2.5935281865515276
Validation loss: 2.580306690301441

Epoch: 5| Step: 5
Training loss: 2.2868482276118787
Validation loss: 2.6375940311654538

Epoch: 5| Step: 6
Training loss: 2.290883872690158
Validation loss: 2.5357749385392414

Epoch: 5| Step: 7
Training loss: 2.637248210730268
Validation loss: 2.621388034961948

Epoch: 5| Step: 8
Training loss: 3.133441053392102
Validation loss: 2.642096962404284

Epoch: 5| Step: 9
Training loss: 2.376460078312846
Validation loss: 2.6347043366360756

Epoch: 5| Step: 10
Training loss: 2.755805130606516
Validation loss: 2.5791349986337155

Epoch: 240| Step: 0
Training loss: 2.8749326615118376
Validation loss: 2.555939789576214

Epoch: 5| Step: 1
Training loss: 2.529096370099263
Validation loss: 2.5852940832749565

Epoch: 5| Step: 2
Training loss: 2.2473058465215763
Validation loss: 2.6115892464581507

Epoch: 5| Step: 3
Training loss: 3.2451074894528573
Validation loss: 2.651756236896005

Epoch: 5| Step: 4
Training loss: 3.2153619508502596
Validation loss: 2.5482134381967763

Epoch: 5| Step: 5
Training loss: 2.229114341715921
Validation loss: 2.5840484993400974

Epoch: 5| Step: 6
Training loss: 3.202938911801081
Validation loss: 2.5934218544915857

Epoch: 5| Step: 7
Training loss: 2.196953753908799
Validation loss: 2.600871074459049

Epoch: 5| Step: 8
Training loss: 2.21788083097393
Validation loss: 2.5075256676353375

Epoch: 5| Step: 9
Training loss: 2.270432311412694
Validation loss: 2.6078040458914598

Epoch: 5| Step: 10
Training loss: 2.868680892477623
Validation loss: 2.574993518072903

Epoch: 241| Step: 0
Training loss: 2.3221106962814915
Validation loss: 2.55272966596245

Epoch: 5| Step: 1
Training loss: 2.471980046139277
Validation loss: 2.6213761535692472

Epoch: 5| Step: 2
Training loss: 2.625874146733781
Validation loss: 2.5473845507081943

Epoch: 5| Step: 3
Training loss: 2.1295412568938956
Validation loss: 2.5884370520036146

Epoch: 5| Step: 4
Training loss: 3.0183223065982845
Validation loss: 2.6463975008555987

Epoch: 5| Step: 5
Training loss: 2.57563532056363
Validation loss: 2.617397105394975

Epoch: 5| Step: 6
Training loss: 2.8984764898510456
Validation loss: 2.5834560987006383

Epoch: 5| Step: 7
Training loss: 2.5319077378950623
Validation loss: 2.6005213928573663

Epoch: 5| Step: 8
Training loss: 3.275092751157824
Validation loss: 2.611171761816872

Epoch: 5| Step: 9
Training loss: 2.6388197828468685
Validation loss: 2.6166604542493572

Epoch: 5| Step: 10
Training loss: 3.177091321257675
Validation loss: 2.5483449728573513

Epoch: 242| Step: 0
Training loss: 2.439127452115025
Validation loss: 2.5758784654144167

Epoch: 5| Step: 1
Training loss: 2.695308519443392
Validation loss: 2.5921238233071944

Epoch: 5| Step: 2
Training loss: 2.3822138800443335
Validation loss: 2.650345298388029

Epoch: 5| Step: 3
Training loss: 2.71710084905323
Validation loss: 2.6281591743304693

Epoch: 5| Step: 4
Training loss: 2.599139302182955
Validation loss: 2.644832367158921

Epoch: 5| Step: 5
Training loss: 3.1053388460448055
Validation loss: 2.567782813408111

Epoch: 5| Step: 6
Training loss: 2.387492801994937
Validation loss: 2.5712753842714653

Epoch: 5| Step: 7
Training loss: 3.200138244026934
Validation loss: 2.591123197426473

Epoch: 5| Step: 8
Training loss: 2.524068936453931
Validation loss: 2.564631554241445

Epoch: 5| Step: 9
Training loss: 2.8582573045530317
Validation loss: 2.5990550800216243

Epoch: 5| Step: 10
Training loss: 2.0796287660165116
Validation loss: 2.5921731982540983

Epoch: 243| Step: 0
Training loss: 2.5636933502083643
Validation loss: 2.610566611176545

Epoch: 5| Step: 1
Training loss: 3.042404259560006
Validation loss: 2.6329111746720533

Epoch: 5| Step: 2
Training loss: 2.5973059855489415
Validation loss: 2.6355633393082063

Epoch: 5| Step: 3
Training loss: 3.1670754486723247
Validation loss: 2.6132629816705655

Epoch: 5| Step: 4
Training loss: 2.1235197184675396
Validation loss: 2.5821911161942017

Epoch: 5| Step: 5
Training loss: 2.4712992194083143
Validation loss: 2.579947311409958

Epoch: 5| Step: 6
Training loss: 3.2919175901422695
Validation loss: 2.563275041682166

Epoch: 5| Step: 7
Training loss: 2.894276060729254
Validation loss: 2.619943207348579

Epoch: 5| Step: 8
Training loss: 2.2408148521530373
Validation loss: 2.568012567889156

Epoch: 5| Step: 9
Training loss: 2.13045866473909
Validation loss: 2.637311710723961

Epoch: 5| Step: 10
Training loss: 2.5411591778844143
Validation loss: 2.5445927325941997

Epoch: 244| Step: 0
Training loss: 2.2207935217556747
Validation loss: 2.609904393169162

Epoch: 5| Step: 1
Training loss: 2.8448884802014147
Validation loss: 2.6238481384198113

Epoch: 5| Step: 2
Training loss: 2.7096375088528584
Validation loss: 2.5824035065415805

Epoch: 5| Step: 3
Training loss: 2.608187376657235
Validation loss: 2.5512606413354146

Epoch: 5| Step: 4
Training loss: 2.7635071830069498
Validation loss: 2.5849296019083075

Epoch: 5| Step: 5
Training loss: 2.7548263852338795
Validation loss: 2.5615446759519283

Epoch: 5| Step: 6
Training loss: 2.3585222736962312
Validation loss: 2.5956412105925675

Epoch: 5| Step: 7
Training loss: 3.0437576387846104
Validation loss: 2.569632422693716

Epoch: 5| Step: 8
Training loss: 3.390060448121677
Validation loss: 2.5909520652736275

Epoch: 5| Step: 9
Training loss: 2.0522046771375497
Validation loss: 2.578038479374614

Epoch: 5| Step: 10
Training loss: 2.791119327313721
Validation loss: 2.5751222228829485

Epoch: 245| Step: 0
Training loss: 2.4157453183785376
Validation loss: 2.564731295748284

Epoch: 5| Step: 1
Training loss: 2.752610614712518
Validation loss: 2.628121123660322

Epoch: 5| Step: 2
Training loss: 2.5761170862255773
Validation loss: 2.6083091026133918

Epoch: 5| Step: 3
Training loss: 2.3849463741903447
Validation loss: 2.516163673476625

Epoch: 5| Step: 4
Training loss: 2.859887249197947
Validation loss: 2.6152662473646706

Epoch: 5| Step: 5
Training loss: 2.407682116504025
Validation loss: 2.6072743363836257

Epoch: 5| Step: 6
Training loss: 2.2584418769267227
Validation loss: 2.57254391861736

Epoch: 5| Step: 7
Training loss: 2.549038956498234
Validation loss: 2.518944802651082

Epoch: 5| Step: 8
Training loss: 3.734194443938559
Validation loss: 2.603739440000809

Epoch: 5| Step: 9
Training loss: 2.7542659443454975
Validation loss: 2.554114612263767

Epoch: 5| Step: 10
Training loss: 2.2243948038392753
Validation loss: 2.6467509333412886

Epoch: 246| Step: 0
Training loss: 2.55039332479228
Validation loss: 2.674045167153155

Epoch: 5| Step: 1
Training loss: 2.354243983346624
Validation loss: 2.660147723008889

Epoch: 5| Step: 2
Training loss: 3.1502375982382667
Validation loss: 2.5674216075768217

Epoch: 5| Step: 3
Training loss: 2.863747011114032
Validation loss: 2.5996935979403655

Epoch: 5| Step: 4
Training loss: 2.572305202541719
Validation loss: 2.6279282758986877

Epoch: 5| Step: 5
Training loss: 2.8427450898728317
Validation loss: 2.6166149602282474

Epoch: 5| Step: 6
Training loss: 2.78506859083651
Validation loss: 2.55815305755749

Epoch: 5| Step: 7
Training loss: 2.533057521144363
Validation loss: 2.551139658747621

Epoch: 5| Step: 8
Training loss: 2.802288336268447
Validation loss: 2.6520603365659463

Epoch: 5| Step: 9
Training loss: 2.406754279862249
Validation loss: 2.6045113618849305

Epoch: 5| Step: 10
Training loss: 2.2909157187295794
Validation loss: 2.6061367656867387

Epoch: 247| Step: 0
Training loss: 2.650903414635623
Validation loss: 2.567446632546734

Epoch: 5| Step: 1
Training loss: 2.7280377001520577
Validation loss: 2.541453269003356

Epoch: 5| Step: 2
Training loss: 2.8662523620835296
Validation loss: 2.5658505122854436

Epoch: 5| Step: 3
Training loss: 3.0842685483980956
Validation loss: 2.495795635948265

Epoch: 5| Step: 4
Training loss: 2.1956272103298233
Validation loss: 2.625962639993401

Epoch: 5| Step: 5
Training loss: 3.0018219183875505
Validation loss: 2.5806204652694134

Epoch: 5| Step: 6
Training loss: 2.6642226900954493
Validation loss: 2.620920377544731

Epoch: 5| Step: 7
Training loss: 2.9710864058711492
Validation loss: 2.5611584520931334

Epoch: 5| Step: 8
Training loss: 2.1460207020951128
Validation loss: 2.629099323432189

Epoch: 5| Step: 9
Training loss: 2.739550939641589
Validation loss: 2.65636334017593

Epoch: 5| Step: 10
Training loss: 2.7139815683547193
Validation loss: 2.5975548533738957

Epoch: 248| Step: 0
Training loss: 2.3097297984376377
Validation loss: 2.610214785011514

Epoch: 5| Step: 1
Training loss: 2.802878814059086
Validation loss: 2.586498108895489

Epoch: 5| Step: 2
Training loss: 2.178998940931941
Validation loss: 2.5825080165197196

Epoch: 5| Step: 3
Training loss: 2.5781506161428625
Validation loss: 2.6785389590700337

Epoch: 5| Step: 4
Training loss: 3.1975258620515907
Validation loss: 2.6002390195532366

Epoch: 5| Step: 5
Training loss: 2.4628894633472678
Validation loss: 2.6085005890330764

Epoch: 5| Step: 6
Training loss: 3.4831313578138468
Validation loss: 2.5927144105927926

Epoch: 5| Step: 7
Training loss: 2.1943239857679635
Validation loss: 2.638071203749555

Epoch: 5| Step: 8
Training loss: 2.0391499584632284
Validation loss: 2.598432001585309

Epoch: 5| Step: 9
Training loss: 3.1396917218536546
Validation loss: 2.6614794594945446

Epoch: 5| Step: 10
Training loss: 2.3954997507699143
Validation loss: 2.6656244751202247

Epoch: 249| Step: 0
Training loss: 2.786881221636825
Validation loss: 2.5670356797119336

Epoch: 5| Step: 1
Training loss: 2.58904602745401
Validation loss: 2.5328566438964377

Epoch: 5| Step: 2
Training loss: 2.82839500866529
Validation loss: 2.5556949072856496

Epoch: 5| Step: 3
Training loss: 2.6035713023866522
Validation loss: 2.5453973848989655

Epoch: 5| Step: 4
Training loss: 2.0754664344949867
Validation loss: 2.5219869276699445

Epoch: 5| Step: 5
Training loss: 2.198020920533299
Validation loss: 2.6288285079909905

Epoch: 5| Step: 6
Training loss: 2.3684982850493554
Validation loss: 2.6816963781707495

Epoch: 5| Step: 7
Training loss: 3.0112681169230133
Validation loss: 2.525830297292442

Epoch: 5| Step: 8
Training loss: 2.3225499934306826
Validation loss: 2.6216074843525754

Epoch: 5| Step: 9
Training loss: 3.141244400207653
Validation loss: 2.5837625735081478

Epoch: 5| Step: 10
Training loss: 3.081648770231028
Validation loss: 2.551251026386143

Epoch: 250| Step: 0
Training loss: 2.69227849504338
Validation loss: 2.6399253272144825

Epoch: 5| Step: 1
Training loss: 2.165130131534988
Validation loss: 2.6344345839447447

Epoch: 5| Step: 2
Training loss: 2.848979292007336
Validation loss: 2.578785277456443

Epoch: 5| Step: 3
Training loss: 3.265336749483032
Validation loss: 2.541690727118659

Epoch: 5| Step: 4
Training loss: 2.8919633396194073
Validation loss: 2.585690954436423

Epoch: 5| Step: 5
Training loss: 2.0511125569437776
Validation loss: 2.5808266433934848

Epoch: 5| Step: 6
Training loss: 2.7145562108856955
Validation loss: 2.5510100504677675

Epoch: 5| Step: 7
Training loss: 2.763381737889823
Validation loss: 2.533784185951805

Epoch: 5| Step: 8
Training loss: 2.1662445635322904
Validation loss: 2.6485163332415986

Epoch: 5| Step: 9
Training loss: 2.849245232473925
Validation loss: 2.5754654417590137

Epoch: 5| Step: 10
Training loss: 2.2079273666446038
Validation loss: 2.654837240482288

Epoch: 251| Step: 0
Training loss: 2.7222190735813885
Validation loss: 2.6185191479626053

Epoch: 5| Step: 1
Training loss: 2.6210080628807755
Validation loss: 2.589609984670588

Epoch: 5| Step: 2
Training loss: 2.692277255253038
Validation loss: 2.6072199524330237

Epoch: 5| Step: 3
Training loss: 1.928773300514719
Validation loss: 2.6089781469887936

Epoch: 5| Step: 4
Training loss: 3.2452369412996305
Validation loss: 2.6142450014133645

Epoch: 5| Step: 5
Training loss: 2.602937810242119
Validation loss: 2.6650170163844566

Epoch: 5| Step: 6
Training loss: 3.0138861035530904
Validation loss: 2.58644768101555

Epoch: 5| Step: 7
Training loss: 2.3549053979812355
Validation loss: 2.6297455339784808

Epoch: 5| Step: 8
Training loss: 2.872156976548638
Validation loss: 2.5773277434677877

Epoch: 5| Step: 9
Training loss: 2.557907827904416
Validation loss: 2.5913334172237685

Epoch: 5| Step: 10
Training loss: 2.4033443197068918
Validation loss: 2.6836329591006947

Epoch: 252| Step: 0
Training loss: 2.5446668542480935
Validation loss: 2.5582627890939245

Epoch: 5| Step: 1
Training loss: 2.5824520905030655
Validation loss: 2.6026836151105455

Epoch: 5| Step: 2
Training loss: 3.021583008096401
Validation loss: 2.5725237974174346

Epoch: 5| Step: 3
Training loss: 2.8915016288455897
Validation loss: 2.5699011066409483

Epoch: 5| Step: 4
Training loss: 2.6229616152724904
Validation loss: 2.565394684687966

Epoch: 5| Step: 5
Training loss: 2.828787541631304
Validation loss: 2.5616072633576197

Epoch: 5| Step: 6
Training loss: 2.6811787095629276
Validation loss: 2.5584293330498435

Epoch: 5| Step: 7
Training loss: 2.1308912629731904
Validation loss: 2.614249490302098

Epoch: 5| Step: 8
Training loss: 2.6961323693603756
Validation loss: 2.608082273807651

Epoch: 5| Step: 9
Training loss: 2.8611226395392224
Validation loss: 2.5767327241846365

Epoch: 5| Step: 10
Training loss: 2.201277587301843
Validation loss: 2.602762379360001

Epoch: 253| Step: 0
Training loss: 3.002594938150976
Validation loss: 2.5505642774702197

Epoch: 5| Step: 1
Training loss: 2.344995091642599
Validation loss: 2.647714550861614

Epoch: 5| Step: 2
Training loss: 2.5455978093145646
Validation loss: 2.588791034722026

Epoch: 5| Step: 3
Training loss: 2.745521105861456
Validation loss: 2.638025161099357

Epoch: 5| Step: 4
Training loss: 2.6351575058075407
Validation loss: 2.5951063511663306

Epoch: 5| Step: 5
Training loss: 2.910286673881101
Validation loss: 2.5856670548891834

Epoch: 5| Step: 6
Training loss: 2.598030877884989
Validation loss: 2.5835426581844536

Epoch: 5| Step: 7
Training loss: 2.4130615331943317
Validation loss: 2.5719053138931334

Epoch: 5| Step: 8
Training loss: 2.257674797109175
Validation loss: 2.5820835046120902

Epoch: 5| Step: 9
Training loss: 2.998748200238329
Validation loss: 2.5435551342401395

Epoch: 5| Step: 10
Training loss: 2.7563017686752738
Validation loss: 2.600483852639354

Epoch: 254| Step: 0
Training loss: 2.365819756214848
Validation loss: 2.5533857573628493

Epoch: 5| Step: 1
Training loss: 1.81109966246504
Validation loss: 2.661286422301536

Epoch: 5| Step: 2
Training loss: 2.474584903008928
Validation loss: 2.5326618069056264

Epoch: 5| Step: 3
Training loss: 2.6839213830659263
Validation loss: 2.5765334023397397

Epoch: 5| Step: 4
Training loss: 2.7301082782441983
Validation loss: 2.6394088147291876

Epoch: 5| Step: 5
Training loss: 2.699205323998809
Validation loss: 2.5649288231037066

Epoch: 5| Step: 6
Training loss: 2.818011499667072
Validation loss: 2.5439872846096656

Epoch: 5| Step: 7
Training loss: 2.9183596102847584
Validation loss: 2.5447835684053715

Epoch: 5| Step: 8
Training loss: 3.111555552147762
Validation loss: 2.631883426312166

Epoch: 5| Step: 9
Training loss: 2.5558233973066713
Validation loss: 2.6156264455278224

Epoch: 5| Step: 10
Training loss: 3.110498579973253
Validation loss: 2.6169587164036128

Epoch: 255| Step: 0
Training loss: 2.340554258451483
Validation loss: 2.653995996114457

Epoch: 5| Step: 1
Training loss: 2.2273633085667925
Validation loss: 2.599670045060766

Epoch: 5| Step: 2
Training loss: 2.752739408858433
Validation loss: 2.6388986012730373

Epoch: 5| Step: 3
Training loss: 2.8329812186359518
Validation loss: 2.5775154683439165

Epoch: 5| Step: 4
Training loss: 2.852003758399916
Validation loss: 2.6634424195427524

Epoch: 5| Step: 5
Training loss: 3.1964055735620036
Validation loss: 2.6108279109176995

Epoch: 5| Step: 6
Training loss: 2.419276855811653
Validation loss: 2.573031882524967

Epoch: 5| Step: 7
Training loss: 2.56873604800851
Validation loss: 2.594005932358754

Epoch: 5| Step: 8
Training loss: 2.2980034579789694
Validation loss: 2.589249236620129

Epoch: 5| Step: 9
Training loss: 2.6858975268236067
Validation loss: 2.593365034427425

Epoch: 5| Step: 10
Training loss: 2.870516556830765
Validation loss: 2.576444841191612

Epoch: 256| Step: 0
Training loss: 3.1264254561419658
Validation loss: 2.5598170724078892

Epoch: 5| Step: 1
Training loss: 3.419205551899467
Validation loss: 2.5035691338228867

Epoch: 5| Step: 2
Training loss: 2.242018955820958
Validation loss: 2.6278538599254744

Epoch: 5| Step: 3
Training loss: 2.209002723246632
Validation loss: 2.5988707556742385

Epoch: 5| Step: 4
Training loss: 2.582353303478123
Validation loss: 2.553561781437757

Epoch: 5| Step: 5
Training loss: 2.7583773199379285
Validation loss: 2.581982874571107

Epoch: 5| Step: 6
Training loss: 2.3459399355510744
Validation loss: 2.5980061129769862

Epoch: 5| Step: 7
Training loss: 1.6375434636761452
Validation loss: 2.610258360988072

Epoch: 5| Step: 8
Training loss: 2.8761889445668607
Validation loss: 2.534108465033467

Epoch: 5| Step: 9
Training loss: 2.6259557709698935
Validation loss: 2.51382862854237

Epoch: 5| Step: 10
Training loss: 2.668969431662423
Validation loss: 2.643262945121291

Epoch: 257| Step: 0
Training loss: 2.98181649829707
Validation loss: 2.6096305051537154

Epoch: 5| Step: 1
Training loss: 2.5382197932972024
Validation loss: 2.516479557991796

Epoch: 5| Step: 2
Training loss: 2.250180343182133
Validation loss: 2.593144666040349

Epoch: 5| Step: 3
Training loss: 2.9175253739352724
Validation loss: 2.5008968098337983

Epoch: 5| Step: 4
Training loss: 2.8209352941600576
Validation loss: 2.61125297971165

Epoch: 5| Step: 5
Training loss: 2.402669050320633
Validation loss: 2.548222720538235

Epoch: 5| Step: 6
Training loss: 3.4667410316805185
Validation loss: 2.6094082132728196

Epoch: 5| Step: 7
Training loss: 2.088787403696359
Validation loss: 2.578199889784856

Epoch: 5| Step: 8
Training loss: 2.4825377958710853
Validation loss: 2.6323798638350313

Epoch: 5| Step: 9
Training loss: 2.3662576895144016
Validation loss: 2.5606654183154416

Epoch: 5| Step: 10
Training loss: 2.690142463541961
Validation loss: 2.6156666430818887

Epoch: 258| Step: 0
Training loss: 3.36590225933689
Validation loss: 2.6546425112076

Epoch: 5| Step: 1
Training loss: 2.8060819511817625
Validation loss: 2.6121794046087223

Epoch: 5| Step: 2
Training loss: 2.4423713912605307
Validation loss: 2.646806011188802

Epoch: 5| Step: 3
Training loss: 2.00573694436794
Validation loss: 2.599523444197867

Epoch: 5| Step: 4
Training loss: 2.821466437046026
Validation loss: 2.5719240334764955

Epoch: 5| Step: 5
Training loss: 3.1966712506380386
Validation loss: 2.5772195388814083

Epoch: 5| Step: 6
Training loss: 2.524310170734518
Validation loss: 2.552398973190584

Epoch: 5| Step: 7
Training loss: 2.407161391422575
Validation loss: 2.613867848391799

Epoch: 5| Step: 8
Training loss: 2.642567569009543
Validation loss: 2.618129191400272

Epoch: 5| Step: 9
Training loss: 1.7316514358854247
Validation loss: 2.6117095593829176

Epoch: 5| Step: 10
Training loss: 2.788354094481793
Validation loss: 2.5447729623698763

Epoch: 259| Step: 0
Training loss: 2.828998241177252
Validation loss: 2.59083488001406

Epoch: 5| Step: 1
Training loss: 2.2472374168838987
Validation loss: 2.5937326615771226

Epoch: 5| Step: 2
Training loss: 2.635580628211312
Validation loss: 2.6811703259232416

Epoch: 5| Step: 3
Training loss: 2.7335182809673713
Validation loss: 2.5310022092822466

Epoch: 5| Step: 4
Training loss: 2.514225825379868
Validation loss: 2.5897872399693656

Epoch: 5| Step: 5
Training loss: 2.414583217915973
Validation loss: 2.6056178666896472

Epoch: 5| Step: 6
Training loss: 2.7658992135696563
Validation loss: 2.6113940675238942

Epoch: 5| Step: 7
Training loss: 2.617158622013022
Validation loss: 2.5229811326043947

Epoch: 5| Step: 8
Training loss: 3.1893619260346195
Validation loss: 2.596382417349359

Epoch: 5| Step: 9
Training loss: 2.4263807161112623
Validation loss: 2.572687106341094

Epoch: 5| Step: 10
Training loss: 2.4076391396566557
Validation loss: 2.5858744872689905

Epoch: 260| Step: 0
Training loss: 2.732348404960705
Validation loss: 2.6437009306240706

Epoch: 5| Step: 1
Training loss: 2.320988617592595
Validation loss: 2.526334380297503

Epoch: 5| Step: 2
Training loss: 3.1487032870423888
Validation loss: 2.5885601830803897

Epoch: 5| Step: 3
Training loss: 2.905179062280178
Validation loss: 2.5643875409465244

Epoch: 5| Step: 4
Training loss: 3.369485234866869
Validation loss: 2.55565887033973

Epoch: 5| Step: 5
Training loss: 2.352628548623661
Validation loss: 2.638333566117982

Epoch: 5| Step: 6
Training loss: 2.197269205726249
Validation loss: 2.6062057030217103

Epoch: 5| Step: 7
Training loss: 2.228191114731479
Validation loss: 2.670530829170455

Epoch: 5| Step: 8
Training loss: 2.827584568044061
Validation loss: 2.5717885426813853

Epoch: 5| Step: 9
Training loss: 2.700546446004058
Validation loss: 2.628419965788625

Epoch: 5| Step: 10
Training loss: 2.322203921692615
Validation loss: 2.592030589481122

Epoch: 261| Step: 0
Training loss: 2.1208375667187522
Validation loss: 2.530925982686883

Epoch: 5| Step: 1
Training loss: 2.9613597236681444
Validation loss: 2.5598602664661434

Epoch: 5| Step: 2
Training loss: 2.177873848182257
Validation loss: 2.5754636221513185

Epoch: 5| Step: 3
Training loss: 2.8065411490993917
Validation loss: 2.598162606413664

Epoch: 5| Step: 4
Training loss: 2.425542601611327
Validation loss: 2.6272163615121995

Epoch: 5| Step: 5
Training loss: 2.57268954573191
Validation loss: 2.5999918876817985

Epoch: 5| Step: 6
Training loss: 3.0876302591251807
Validation loss: 2.578204545341109

Epoch: 5| Step: 7
Training loss: 2.5058996207736075
Validation loss: 2.5577420778963966

Epoch: 5| Step: 8
Training loss: 2.2313273525987993
Validation loss: 2.575572003029894

Epoch: 5| Step: 9
Training loss: 2.863846914249153
Validation loss: 2.5192410341895406

Epoch: 5| Step: 10
Training loss: 3.0704288217965967
Validation loss: 2.534617305687071

Epoch: 262| Step: 0
Training loss: 2.5645252691203946
Validation loss: 2.5389133800199764

Epoch: 5| Step: 1
Training loss: 2.6569882432866314
Validation loss: 2.607286895592495

Epoch: 5| Step: 2
Training loss: 2.2771809488670542
Validation loss: 2.5721816760592913

Epoch: 5| Step: 3
Training loss: 3.0853675798885525
Validation loss: 2.6441653006885173

Epoch: 5| Step: 4
Training loss: 2.9315389657486453
Validation loss: 2.5991386650058512

Epoch: 5| Step: 5
Training loss: 3.2457809940243094
Validation loss: 2.574187513199234

Epoch: 5| Step: 6
Training loss: 2.7335358994329613
Validation loss: 2.604045951424464

Epoch: 5| Step: 7
Training loss: 3.366402589871676
Validation loss: 2.56578173165218

Epoch: 5| Step: 8
Training loss: 1.8918150632126909
Validation loss: 2.647526816680498

Epoch: 5| Step: 9
Training loss: 2.109429252774536
Validation loss: 2.6433189782164828

Epoch: 5| Step: 10
Training loss: 2.2500998156977454
Validation loss: 2.594488776789553

Epoch: 263| Step: 0
Training loss: 2.4947661927474947
Validation loss: 2.6157106952182088

Epoch: 5| Step: 1
Training loss: 2.7488090363772524
Validation loss: 2.6190553350152497

Epoch: 5| Step: 2
Training loss: 2.3318439453151094
Validation loss: 2.5226214446986757

Epoch: 5| Step: 3
Training loss: 2.2818909881123632
Validation loss: 2.6048479202266663

Epoch: 5| Step: 4
Training loss: 2.9950148170372146
Validation loss: 2.588114709545991

Epoch: 5| Step: 5
Training loss: 2.454688673304442
Validation loss: 2.5281539571571465

Epoch: 5| Step: 6
Training loss: 2.8249936973028853
Validation loss: 2.5949832827346326

Epoch: 5| Step: 7
Training loss: 1.949652369397163
Validation loss: 2.545370654542391

Epoch: 5| Step: 8
Training loss: 2.363422887671963
Validation loss: 2.560102556299639

Epoch: 5| Step: 9
Training loss: 2.873909287254841
Validation loss: 2.5518740918334775

Epoch: 5| Step: 10
Training loss: 3.4495040758260638
Validation loss: 2.5805163487528997

Epoch: 264| Step: 0
Training loss: 2.297996091694907
Validation loss: 2.549229503210156

Epoch: 5| Step: 1
Training loss: 2.3410688195947196
Validation loss: 2.5793804215768965

Epoch: 5| Step: 2
Training loss: 2.841350675075578
Validation loss: 2.6047393776142393

Epoch: 5| Step: 3
Training loss: 2.591948653536717
Validation loss: 2.5602325924645593

Epoch: 5| Step: 4
Training loss: 3.024741037176568
Validation loss: 2.584595435114752

Epoch: 5| Step: 5
Training loss: 2.8628250737076
Validation loss: 2.5289822244811737

Epoch: 5| Step: 6
Training loss: 2.468729912398498
Validation loss: 2.6150119026440395

Epoch: 5| Step: 7
Training loss: 2.4379140062132367
Validation loss: 2.5354644559223196

Epoch: 5| Step: 8
Training loss: 2.8563893891427385
Validation loss: 2.5511396607574213

Epoch: 5| Step: 9
Training loss: 3.0347254384768445
Validation loss: 2.563730660169685

Epoch: 5| Step: 10
Training loss: 2.5091530137549496
Validation loss: 2.573157670646127

Epoch: 265| Step: 0
Training loss: 2.887440675068247
Validation loss: 2.594845191298563

Epoch: 5| Step: 1
Training loss: 3.167216972586569
Validation loss: 2.554214280676056

Epoch: 5| Step: 2
Training loss: 2.6990588702537064
Validation loss: 2.539912686937332

Epoch: 5| Step: 3
Training loss: 1.8888431696251802
Validation loss: 2.6360664414576784

Epoch: 5| Step: 4
Training loss: 2.6494144224566654
Validation loss: 2.615715466798289

Epoch: 5| Step: 5
Training loss: 3.151834704436347
Validation loss: 2.5713688930885623

Epoch: 5| Step: 6
Training loss: 1.9276966528018324
Validation loss: 2.6739114636770704

Epoch: 5| Step: 7
Training loss: 2.1988056668971017
Validation loss: 2.5921327164846124

Epoch: 5| Step: 8
Training loss: 2.971198427541519
Validation loss: 2.5286537902699404

Epoch: 5| Step: 9
Training loss: 2.5337158248997964
Validation loss: 2.5337940629615536

Epoch: 5| Step: 10
Training loss: 2.3136789564275175
Validation loss: 2.543288429802602

Epoch: 266| Step: 0
Training loss: 2.364405038528353
Validation loss: 2.5468602273475995

Epoch: 5| Step: 1
Training loss: 3.3951686528469267
Validation loss: 2.529663433386183

Epoch: 5| Step: 2
Training loss: 2.011257911415259
Validation loss: 2.627877979668645

Epoch: 5| Step: 3
Training loss: 2.2171213324299743
Validation loss: 2.544958739908942

Epoch: 5| Step: 4
Training loss: 2.8839858233755504
Validation loss: 2.6120462580849577

Epoch: 5| Step: 5
Training loss: 2.7982887658786098
Validation loss: 2.597630205439435

Epoch: 5| Step: 6
Training loss: 3.0285516113599416
Validation loss: 2.5888999132654016

Epoch: 5| Step: 7
Training loss: 2.65738958708956
Validation loss: 2.6087896378081497

Epoch: 5| Step: 8
Training loss: 2.769471333316966
Validation loss: 2.584108746038284

Epoch: 5| Step: 9
Training loss: 2.1672022108748976
Validation loss: 2.5876653559675518

Epoch: 5| Step: 10
Training loss: 2.214897356948815
Validation loss: 2.665435449744288

Epoch: 267| Step: 0
Training loss: 2.733934639485018
Validation loss: 2.5655380415946136

Epoch: 5| Step: 1
Training loss: 2.7391303864078242
Validation loss: 2.6336268251375836

Epoch: 5| Step: 2
Training loss: 3.2470551867598827
Validation loss: 2.54905541468599

Epoch: 5| Step: 3
Training loss: 2.4027451590772158
Validation loss: 2.62365781903597

Epoch: 5| Step: 4
Training loss: 2.0462396232514313
Validation loss: 2.592339893565039

Epoch: 5| Step: 5
Training loss: 2.926424941187005
Validation loss: 2.578216014161679

Epoch: 5| Step: 6
Training loss: 2.7758258690376287
Validation loss: 2.655811749955668

Epoch: 5| Step: 7
Training loss: 2.927044054810879
Validation loss: 2.638430984922247

Epoch: 5| Step: 8
Training loss: 2.0262390537425183
Validation loss: 2.5554105080458043

Epoch: 5| Step: 9
Training loss: 2.9077653113404733
Validation loss: 2.6054763578596045

Epoch: 5| Step: 10
Training loss: 1.8148849843891703
Validation loss: 2.553421650689304

Epoch: 268| Step: 0
Training loss: 1.979627682716251
Validation loss: 2.545060347334309

Epoch: 5| Step: 1
Training loss: 2.626083604497168
Validation loss: 2.523164903637943

Epoch: 5| Step: 2
Training loss: 3.369334799658161
Validation loss: 2.5520919816400296

Epoch: 5| Step: 3
Training loss: 2.5709782349871872
Validation loss: 2.558204724632339

Epoch: 5| Step: 4
Training loss: 2.4119137580408645
Validation loss: 2.538069390504025

Epoch: 5| Step: 5
Training loss: 3.469210757334958
Validation loss: 2.604981213244589

Epoch: 5| Step: 6
Training loss: 1.9563777845286219
Validation loss: 2.6062718489236607

Epoch: 5| Step: 7
Training loss: 2.9352413178362533
Validation loss: 2.5134808694323394

Epoch: 5| Step: 8
Training loss: 2.525543751097671
Validation loss: 2.5975180489922303

Epoch: 5| Step: 9
Training loss: 2.4555059650452
Validation loss: 2.579442595101003

Epoch: 5| Step: 10
Training loss: 2.0104600839093822
Validation loss: 2.5613260989316013

Epoch: 269| Step: 0
Training loss: 2.6444216188501763
Validation loss: 2.5029318686521043

Epoch: 5| Step: 1
Training loss: 1.9583671106983216
Validation loss: 2.576173422435569

Epoch: 5| Step: 2
Training loss: 2.7829166519234336
Validation loss: 2.5486054024521536

Epoch: 5| Step: 3
Training loss: 2.9659949117193736
Validation loss: 2.571418195987753

Epoch: 5| Step: 4
Training loss: 3.15928941680572
Validation loss: 2.552622393160234

Epoch: 5| Step: 5
Training loss: 2.9018532914896973
Validation loss: 2.587630989793937

Epoch: 5| Step: 6
Training loss: 2.201985382336458
Validation loss: 2.565845981187279

Epoch: 5| Step: 7
Training loss: 2.5686744177620744
Validation loss: 2.52242138791083

Epoch: 5| Step: 8
Training loss: 2.043165500130935
Validation loss: 2.5549668433461745

Epoch: 5| Step: 9
Training loss: 2.370357795136703
Validation loss: 2.6220843202026547

Epoch: 5| Step: 10
Training loss: 3.4070153732647155
Validation loss: 2.5808302770319034

Epoch: 270| Step: 0
Training loss: 3.0425775984159897
Validation loss: 2.6510899939446397

Epoch: 5| Step: 1
Training loss: 1.9895465175025178
Validation loss: 2.597926729874548

Epoch: 5| Step: 2
Training loss: 2.5017021106883526
Validation loss: 2.505493728713373

Epoch: 5| Step: 3
Training loss: 2.8209969913070414
Validation loss: 2.632501509254591

Epoch: 5| Step: 4
Training loss: 2.3000261139423817
Validation loss: 2.6100724459607685

Epoch: 5| Step: 5
Training loss: 2.9307636369913292
Validation loss: 2.6235359541094287

Epoch: 5| Step: 6
Training loss: 2.4433301989477574
Validation loss: 2.610397815331014

Epoch: 5| Step: 7
Training loss: 3.3214257382382266
Validation loss: 2.5850181431160504

Epoch: 5| Step: 8
Training loss: 2.811580762050196
Validation loss: 2.5772975574512205

Epoch: 5| Step: 9
Training loss: 2.330676837241345
Validation loss: 2.520068821972379

Epoch: 5| Step: 10
Training loss: 2.289813234300941
Validation loss: 2.6740624967848823

Epoch: 271| Step: 0
Training loss: 2.930801220601243
Validation loss: 2.6283226460640066

Epoch: 5| Step: 1
Training loss: 2.1827154969470466
Validation loss: 2.5444202764408517

Epoch: 5| Step: 2
Training loss: 2.455358958057872
Validation loss: 2.605817866084205

Epoch: 5| Step: 3
Training loss: 3.1783660467178274
Validation loss: 2.5491747966012217

Epoch: 5| Step: 4
Training loss: 2.7812895182684474
Validation loss: 2.5887195381368016

Epoch: 5| Step: 5
Training loss: 2.399824207543506
Validation loss: 2.5710450508774128

Epoch: 5| Step: 6
Training loss: 2.110457192195357
Validation loss: 2.6371838061147637

Epoch: 5| Step: 7
Training loss: 2.270195185970485
Validation loss: 2.57899193033078

Epoch: 5| Step: 8
Training loss: 3.2815047392281276
Validation loss: 2.561253227104895

Epoch: 5| Step: 9
Training loss: 2.675832572500508
Validation loss: 2.592261657205955

Epoch: 5| Step: 10
Training loss: 2.3465746325449603
Validation loss: 2.5335957211418063

Epoch: 272| Step: 0
Training loss: 2.237862486220426
Validation loss: 2.642455591035517

Epoch: 5| Step: 1
Training loss: 2.7487473669382125
Validation loss: 2.614270004744217

Epoch: 5| Step: 2
Training loss: 2.8565668376926814
Validation loss: 2.623922686561113

Epoch: 5| Step: 3
Training loss: 2.2133530001551716
Validation loss: 2.5976554106369347

Epoch: 5| Step: 4
Training loss: 2.5595164724521515
Validation loss: 2.6796307062225715

Epoch: 5| Step: 5
Training loss: 2.579562254741379
Validation loss: 2.5201344576812046

Epoch: 5| Step: 6
Training loss: 3.181083953660962
Validation loss: 2.570675623256138

Epoch: 5| Step: 7
Training loss: 2.0951704075229918
Validation loss: 2.577896703690807

Epoch: 5| Step: 8
Training loss: 2.6275950728764115
Validation loss: 2.547899851449513

Epoch: 5| Step: 9
Training loss: 3.328771107599919
Validation loss: 2.591391814246375

Epoch: 5| Step: 10
Training loss: 2.0995305671983195
Validation loss: 2.5659874236110127

Epoch: 273| Step: 0
Training loss: 2.2153225066779214
Validation loss: 2.653632386719842

Epoch: 5| Step: 1
Training loss: 2.799001471401535
Validation loss: 2.5897008001133184

Epoch: 5| Step: 2
Training loss: 1.9903941141849533
Validation loss: 2.5542267956623728

Epoch: 5| Step: 3
Training loss: 2.600656162507058
Validation loss: 2.5635648596304477

Epoch: 5| Step: 4
Training loss: 2.4024224493270365
Validation loss: 2.595565593367338

Epoch: 5| Step: 5
Training loss: 2.7777614359904774
Validation loss: 2.586928808588587

Epoch: 5| Step: 6
Training loss: 3.166562446753105
Validation loss: 2.6159333683379136

Epoch: 5| Step: 7
Training loss: 2.5051397894498937
Validation loss: 2.5872738668491646

Epoch: 5| Step: 8
Training loss: 2.891592492756377
Validation loss: 2.641918166933198

Epoch: 5| Step: 9
Training loss: 2.912523942447861
Validation loss: 2.535114786972651

Epoch: 5| Step: 10
Training loss: 2.203944817996291
Validation loss: 2.6229772318670665

Epoch: 274| Step: 0
Training loss: 1.8655864922464704
Validation loss: 2.5842769753753037

Epoch: 5| Step: 1
Training loss: 2.5445015736607073
Validation loss: 2.5048029764399367

Epoch: 5| Step: 2
Training loss: 2.7765681260824224
Validation loss: 2.6350478514468163

Epoch: 5| Step: 3
Training loss: 2.3395386562231457
Validation loss: 2.5256974160241343

Epoch: 5| Step: 4
Training loss: 3.4596293368828697
Validation loss: 2.6551710819739966

Epoch: 5| Step: 5
Training loss: 2.487058138300867
Validation loss: 2.644279632931503

Epoch: 5| Step: 6
Training loss: 2.2497693049525305
Validation loss: 2.6299034560071566

Epoch: 5| Step: 7
Training loss: 2.797202490701525
Validation loss: 2.594683463740181

Epoch: 5| Step: 8
Training loss: 2.468628602725031
Validation loss: 2.6321316638388725

Epoch: 5| Step: 9
Training loss: 2.8380925841119438
Validation loss: 2.546542599626582

Epoch: 5| Step: 10
Training loss: 2.5770225248407077
Validation loss: 2.5301934633448058

Epoch: 275| Step: 0
Training loss: 2.2639844545295715
Validation loss: 2.5770062368104827

Epoch: 5| Step: 1
Training loss: 2.338810509490711
Validation loss: 2.6037739814924943

Epoch: 5| Step: 2
Training loss: 2.1461189104680694
Validation loss: 2.6348675209984935

Epoch: 5| Step: 3
Training loss: 2.4237711713002974
Validation loss: 2.679061710863295

Epoch: 5| Step: 4
Training loss: 2.4909735805438173
Validation loss: 2.574870743829199

Epoch: 5| Step: 5
Training loss: 2.9595159575619734
Validation loss: 2.685733298415553

Epoch: 5| Step: 6
Training loss: 2.8354876873493673
Validation loss: 2.558745382024568

Epoch: 5| Step: 7
Training loss: 2.2269459176795863
Validation loss: 2.629640644467083

Epoch: 5| Step: 8
Training loss: 3.463746594937047
Validation loss: 2.5492496870914487

Epoch: 5| Step: 9
Training loss: 2.728938512996371
Validation loss: 2.5881511563435966

Epoch: 5| Step: 10
Training loss: 2.249750229429506
Validation loss: 2.5977056244012813

Epoch: 276| Step: 0
Training loss: 2.1815806272174627
Validation loss: 2.5661153393241496

Epoch: 5| Step: 1
Training loss: 3.3624738727674814
Validation loss: 2.6119225921129527

Epoch: 5| Step: 2
Training loss: 3.1457705123051913
Validation loss: 2.5782890439165205

Epoch: 5| Step: 3
Training loss: 2.8637578341219982
Validation loss: 2.569084318141392

Epoch: 5| Step: 4
Training loss: 2.6226461847252494
Validation loss: 2.551164371132512

Epoch: 5| Step: 5
Training loss: 2.0767961426606525
Validation loss: 2.5506551202222028

Epoch: 5| Step: 6
Training loss: 2.6866929372760455
Validation loss: 2.601204540021831

Epoch: 5| Step: 7
Training loss: 2.4202448126807554
Validation loss: 2.5652134512822693

Epoch: 5| Step: 8
Training loss: 2.6531068044157604
Validation loss: 2.5208869056497423

Epoch: 5| Step: 9
Training loss: 2.032866084501655
Validation loss: 2.62484761668414

Epoch: 5| Step: 10
Training loss: 2.25104837365117
Validation loss: 2.603659331750511

Epoch: 277| Step: 0
Training loss: 2.608598148037201
Validation loss: 2.559978056454377

Epoch: 5| Step: 1
Training loss: 2.209839672987626
Validation loss: 2.527422110253214

Epoch: 5| Step: 2
Training loss: 2.098889093385014
Validation loss: 2.6341628046200123

Epoch: 5| Step: 3
Training loss: 2.4809125848612936
Validation loss: 2.6555465548547526

Epoch: 5| Step: 4
Training loss: 3.0339711353636387
Validation loss: 2.613882369844303

Epoch: 5| Step: 5
Training loss: 3.0059142625146293
Validation loss: 2.613381983485414

Epoch: 5| Step: 6
Training loss: 2.9516494536225526
Validation loss: 2.5982735421533483

Epoch: 5| Step: 7
Training loss: 2.6473003635657406
Validation loss: 2.572382007805533

Epoch: 5| Step: 8
Training loss: 2.7073564870740254
Validation loss: 2.6182337239950995

Epoch: 5| Step: 9
Training loss: 2.5248254319078947
Validation loss: 2.6263395193679977

Epoch: 5| Step: 10
Training loss: 2.859704337409709
Validation loss: 2.5658042337601605

Epoch: 278| Step: 0
Training loss: 2.6200818810517217
Validation loss: 2.589249019786108

Epoch: 5| Step: 1
Training loss: 2.5538005630782927
Validation loss: 2.6902123129015174

Epoch: 5| Step: 2
Training loss: 2.8303653842415804
Validation loss: 2.622698042623263

Epoch: 5| Step: 3
Training loss: 3.1664184841142724
Validation loss: 2.5957301073992824

Epoch: 5| Step: 4
Training loss: 2.4621085151042643
Validation loss: 2.6075981672615773

Epoch: 5| Step: 5
Training loss: 1.866381227717562
Validation loss: 2.565183761325393

Epoch: 5| Step: 6
Training loss: 2.950034325610099
Validation loss: 2.555218226548245

Epoch: 5| Step: 7
Training loss: 2.51225880086661
Validation loss: 2.5597728811175444

Epoch: 5| Step: 8
Training loss: 2.5108479700464787
Validation loss: 2.651832283934299

Epoch: 5| Step: 9
Training loss: 2.6462583325686873
Validation loss: 2.5943853373831995

Epoch: 5| Step: 10
Training loss: 2.443475685431097
Validation loss: 2.616924143216656

Epoch: 279| Step: 0
Training loss: 1.9690924452608614
Validation loss: 2.571581523283479

Epoch: 5| Step: 1
Training loss: 3.2102015781985496
Validation loss: 2.5820238093655754

Epoch: 5| Step: 2
Training loss: 2.3018307324310707
Validation loss: 2.595249696263953

Epoch: 5| Step: 3
Training loss: 2.193974097127673
Validation loss: 2.5730296158274366

Epoch: 5| Step: 4
Training loss: 2.3528256493144104
Validation loss: 2.5963367225377834

Epoch: 5| Step: 5
Training loss: 2.302453772197807
Validation loss: 2.591982291877556

Epoch: 5| Step: 6
Training loss: 2.415374201972228
Validation loss: 2.5362853668668954

Epoch: 5| Step: 7
Training loss: 3.5597571806659416
Validation loss: 2.6337580109692693

Epoch: 5| Step: 8
Training loss: 2.3948894687065994
Validation loss: 2.5990792204294273

Epoch: 5| Step: 9
Training loss: 2.836426747893728
Validation loss: 2.6131781365459434

Epoch: 5| Step: 10
Training loss: 2.0623561924592937
Validation loss: 2.564456386964117

Epoch: 280| Step: 0
Training loss: 2.2800647321513248
Validation loss: 2.6402990804233264

Epoch: 5| Step: 1
Training loss: 1.99068079799858
Validation loss: 2.475846760867831

Epoch: 5| Step: 2
Training loss: 2.6594931158244566
Validation loss: 2.5779380926978805

Epoch: 5| Step: 3
Training loss: 2.6783302362024917
Validation loss: 2.545622929990051

Epoch: 5| Step: 4
Training loss: 2.442161309021877
Validation loss: 2.588434530392269

Epoch: 5| Step: 5
Training loss: 3.2174195437979467
Validation loss: 2.6243233480044457

Epoch: 5| Step: 6
Training loss: 2.4892049419404896
Validation loss: 2.6294277544059574

Epoch: 5| Step: 7
Training loss: 2.2685527957509333
Validation loss: 2.528851787253845

Epoch: 5| Step: 8
Training loss: 2.4011291907212007
Validation loss: 2.5198056465157266

Epoch: 5| Step: 9
Training loss: 2.943508739263418
Validation loss: 2.5175113549315355

Epoch: 5| Step: 10
Training loss: 2.6667425820353063
Validation loss: 2.6620337274844004

Epoch: 281| Step: 0
Training loss: 2.798770709623492
Validation loss: 2.5657891534429207

Epoch: 5| Step: 1
Training loss: 2.5093368698396534
Validation loss: 2.576087902089679

Epoch: 5| Step: 2
Training loss: 2.537040022327227
Validation loss: 2.632430122743753

Epoch: 5| Step: 3
Training loss: 3.316290216471671
Validation loss: 2.5442652121894795

Epoch: 5| Step: 4
Training loss: 2.6707416830143154
Validation loss: 2.583130197017588

Epoch: 5| Step: 5
Training loss: 2.6473509773768593
Validation loss: 2.6563859242473873

Epoch: 5| Step: 6
Training loss: 2.5616450860780047
Validation loss: 2.5633175693941856

Epoch: 5| Step: 7
Training loss: 2.2007965336527233
Validation loss: 2.62359909905227

Epoch: 5| Step: 8
Training loss: 2.2168689329560647
Validation loss: 2.6124786209257724

Epoch: 5| Step: 9
Training loss: 2.7357197098071726
Validation loss: 2.52403431582502

Epoch: 5| Step: 10
Training loss: 2.385401585515975
Validation loss: 2.546637965891947

Epoch: 282| Step: 0
Training loss: 2.4035938018975385
Validation loss: 2.5364538349665007

Epoch: 5| Step: 1
Training loss: 2.406791130750258
Validation loss: 2.539158530868543

Epoch: 5| Step: 2
Training loss: 2.4026396778480588
Validation loss: 2.5376233950911775

Epoch: 5| Step: 3
Training loss: 2.710016803337451
Validation loss: 2.61350847411511

Epoch: 5| Step: 4
Training loss: 2.956745330412069
Validation loss: 2.68911995586337

Epoch: 5| Step: 5
Training loss: 3.4496016673245053
Validation loss: 2.565483887103547

Epoch: 5| Step: 6
Training loss: 2.315932947601386
Validation loss: 2.553736720234099

Epoch: 5| Step: 7
Training loss: 2.0634588844708324
Validation loss: 2.549450622162158

Epoch: 5| Step: 8
Training loss: 3.1435113046478347
Validation loss: 2.6093476144022767

Epoch: 5| Step: 9
Training loss: 2.5504197803618114
Validation loss: 2.5915015950287748

Epoch: 5| Step: 10
Training loss: 2.747357572798361
Validation loss: 2.610791209199773

Epoch: 283| Step: 0
Training loss: 2.1904088978964933
Validation loss: 2.5561833315769213

Epoch: 5| Step: 1
Training loss: 2.9238969467309444
Validation loss: 2.580141834715939

Epoch: 5| Step: 2
Training loss: 2.3600112360347367
Validation loss: 2.5991994052330094

Epoch: 5| Step: 3
Training loss: 3.5781214018557916
Validation loss: 2.661564694179678

Epoch: 5| Step: 4
Training loss: 2.4563251202382546
Validation loss: 2.587622322388209

Epoch: 5| Step: 5
Training loss: 1.8128444738910545
Validation loss: 2.6156772831327557

Epoch: 5| Step: 6
Training loss: 2.948862380165986
Validation loss: 2.6196093605412596

Epoch: 5| Step: 7
Training loss: 2.3120126984059435
Validation loss: 2.5369697340448285

Epoch: 5| Step: 8
Training loss: 2.361165560923526
Validation loss: 2.600894584920858

Epoch: 5| Step: 9
Training loss: 2.7694852795572107
Validation loss: 2.6343944693791714

Epoch: 5| Step: 10
Training loss: 2.6578313271799274
Validation loss: 2.669084619509149

Epoch: 284| Step: 0
Training loss: 2.754533412213445
Validation loss: 2.661268644378213

Epoch: 5| Step: 1
Training loss: 2.464991351996489
Validation loss: 2.608430701018282

Epoch: 5| Step: 2
Training loss: 2.6713823901702503
Validation loss: 2.6087112972882864

Epoch: 5| Step: 3
Training loss: 2.12363333791984
Validation loss: 2.5300204198498717

Epoch: 5| Step: 4
Training loss: 2.355808012207459
Validation loss: 2.6149977001990323

Epoch: 5| Step: 5
Training loss: 3.2225252991860347
Validation loss: 2.637046986411238

Epoch: 5| Step: 6
Training loss: 2.144341687994669
Validation loss: 2.611101825515491

Epoch: 5| Step: 7
Training loss: 2.5955776531586685
Validation loss: 2.6958353751411726

Epoch: 5| Step: 8
Training loss: 2.8617768752734896
Validation loss: 2.5957228472651828

Epoch: 5| Step: 9
Training loss: 2.9856890436801615
Validation loss: 2.557883812087811

Epoch: 5| Step: 10
Training loss: 2.4950107380056847
Validation loss: 2.5307020887971143

Epoch: 285| Step: 0
Training loss: 1.9777927716302377
Validation loss: 2.58070201285611

Epoch: 5| Step: 1
Training loss: 2.6577880894135935
Validation loss: 2.5646070815840023

Epoch: 5| Step: 2
Training loss: 2.4309230986733863
Validation loss: 2.579792496474446

Epoch: 5| Step: 3
Training loss: 2.5992414871932037
Validation loss: 2.620952294227632

Epoch: 5| Step: 4
Training loss: 2.669611278626026
Validation loss: 2.61207997326687

Epoch: 5| Step: 5
Training loss: 2.43512903956465
Validation loss: 2.5657014174707657

Epoch: 5| Step: 6
Training loss: 2.854899922502518
Validation loss: 2.5953323137789974

Epoch: 5| Step: 7
Training loss: 2.645115392003101
Validation loss: 2.5949901586614654

Epoch: 5| Step: 8
Training loss: 2.4322813852053398
Validation loss: 2.6182284796684114

Epoch: 5| Step: 9
Training loss: 2.822908004991444
Validation loss: 2.5912033588324803

Epoch: 5| Step: 10
Training loss: 2.964084854805823
Validation loss: 2.5000295862887763

Epoch: 286| Step: 0
Training loss: 2.829498631847945
Validation loss: 2.6053279425341835

Epoch: 5| Step: 1
Training loss: 2.1598827333760586
Validation loss: 2.5571908613693557

Epoch: 5| Step: 2
Training loss: 2.392432832004246
Validation loss: 2.5066321493994046

Epoch: 5| Step: 3
Training loss: 2.7551919303266357
Validation loss: 2.543809700062473

Epoch: 5| Step: 4
Training loss: 2.97123646259233
Validation loss: 2.6149340014755484

Epoch: 5| Step: 5
Training loss: 2.6446868535162382
Validation loss: 2.5006724509444376

Epoch: 5| Step: 6
Training loss: 2.5396190796219966
Validation loss: 2.5670611438631448

Epoch: 5| Step: 7
Training loss: 3.0743322872537986
Validation loss: 2.6227249564798845

Epoch: 5| Step: 8
Training loss: 1.8425335508110179
Validation loss: 2.5350910568153333

Epoch: 5| Step: 9
Training loss: 2.5102160572818906
Validation loss: 2.575761287100435

Epoch: 5| Step: 10
Training loss: 2.565846560688703
Validation loss: 2.623056894795623

Epoch: 287| Step: 0
Training loss: 2.56460308208862
Validation loss: 2.563433914415781

Epoch: 5| Step: 1
Training loss: 2.6175477648205283
Validation loss: 2.579621155260112

Epoch: 5| Step: 2
Training loss: 2.7918490639688756
Validation loss: 2.5688185437152855

Epoch: 5| Step: 3
Training loss: 2.9915007358392636
Validation loss: 2.5161581736168896

Epoch: 5| Step: 4
Training loss: 2.094000274731054
Validation loss: 2.5752894240988002

Epoch: 5| Step: 5
Training loss: 2.1670005492177564
Validation loss: 2.4973565605521615

Epoch: 5| Step: 6
Training loss: 2.9018736672958085
Validation loss: 2.590522156210142

Epoch: 5| Step: 7
Training loss: 2.4292896595130222
Validation loss: 2.5353836242521757

Epoch: 5| Step: 8
Training loss: 2.4532581463294356
Validation loss: 2.51759219170659

Epoch: 5| Step: 9
Training loss: 2.982155818601036
Validation loss: 2.5910193302915903

Epoch: 5| Step: 10
Training loss: 1.9992370342269719
Validation loss: 2.590565318263232

Epoch: 288| Step: 0
Training loss: 2.3428479302454464
Validation loss: 2.566597362207769

Epoch: 5| Step: 1
Training loss: 2.310204474907221
Validation loss: 2.5938933839787146

Epoch: 5| Step: 2
Training loss: 2.0441270392965314
Validation loss: 2.5819635209684786

Epoch: 5| Step: 3
Training loss: 2.393396902311572
Validation loss: 2.5730721088504325

Epoch: 5| Step: 4
Training loss: 2.0460527238960395
Validation loss: 2.576669426653236

Epoch: 5| Step: 5
Training loss: 2.6904772745621366
Validation loss: 2.6184378597676745

Epoch: 5| Step: 6
Training loss: 2.566878137505311
Validation loss: 2.5794610333834345

Epoch: 5| Step: 7
Training loss: 3.1145295783840146
Validation loss: 2.6692509825073647

Epoch: 5| Step: 8
Training loss: 2.744646583694295
Validation loss: 2.533361181698156

Epoch: 5| Step: 9
Training loss: 3.289047422397151
Validation loss: 2.542619086647891

Epoch: 5| Step: 10
Training loss: 2.7085689344388895
Validation loss: 2.550912069863006

Epoch: 289| Step: 0
Training loss: 3.088765454132063
Validation loss: 2.608098619398803

Epoch: 5| Step: 1
Training loss: 2.7950287591208687
Validation loss: 2.546471441051486

Epoch: 5| Step: 2
Training loss: 2.4464431440060586
Validation loss: 2.5804151499184953

Epoch: 5| Step: 3
Training loss: 2.519704508184091
Validation loss: 2.553986396631521

Epoch: 5| Step: 4
Training loss: 2.2517659356828283
Validation loss: 2.554326472744731

Epoch: 5| Step: 5
Training loss: 2.798516926365124
Validation loss: 2.6101217121936866

Epoch: 5| Step: 6
Training loss: 2.4772904827318376
Validation loss: 2.613224321689473

Epoch: 5| Step: 7
Training loss: 2.1140189584334883
Validation loss: 2.525037811680092

Epoch: 5| Step: 8
Training loss: 2.7045095789593914
Validation loss: 2.5642900355000484

Epoch: 5| Step: 9
Training loss: 2.6472355188349592
Validation loss: 2.549121272019649

Epoch: 5| Step: 10
Training loss: 2.440382988686351
Validation loss: 2.561362627150205

Epoch: 290| Step: 0
Training loss: 2.8760347577410075
Validation loss: 2.5474805778191256

Epoch: 5| Step: 1
Training loss: 2.839240218600902
Validation loss: 2.586432821170869

Epoch: 5| Step: 2
Training loss: 3.3905601671058925
Validation loss: 2.5799593294381213

Epoch: 5| Step: 3
Training loss: 2.478198741378508
Validation loss: 2.645821062065531

Epoch: 5| Step: 4
Training loss: 2.474857742382729
Validation loss: 2.5641272375696094

Epoch: 5| Step: 5
Training loss: 2.787733685743783
Validation loss: 2.5771010159253014

Epoch: 5| Step: 6
Training loss: 2.36624559856475
Validation loss: 2.641649571097506

Epoch: 5| Step: 7
Training loss: 2.3881335271759463
Validation loss: 2.5307219488895645

Epoch: 5| Step: 8
Training loss: 2.2717033142954985
Validation loss: 2.5823102007337213

Epoch: 5| Step: 9
Training loss: 2.58305470184284
Validation loss: 2.6005176290017578

Epoch: 5| Step: 10
Training loss: 2.142526937201897
Validation loss: 2.5671737256801306

Epoch: 291| Step: 0
Training loss: 2.904548557153386
Validation loss: 2.552788495669317

Epoch: 5| Step: 1
Training loss: 2.5958577060524757
Validation loss: 2.538749847472693

Epoch: 5| Step: 2
Training loss: 2.8573519528034943
Validation loss: 2.4945102251767604

Epoch: 5| Step: 3
Training loss: 2.8181676766384753
Validation loss: 2.6240552617293407

Epoch: 5| Step: 4
Training loss: 2.4747897280371207
Validation loss: 2.6353125820174323

Epoch: 5| Step: 5
Training loss: 2.2356848445365856
Validation loss: 2.579751447767477

Epoch: 5| Step: 6
Training loss: 2.6296928781963254
Validation loss: 2.5892357512916835

Epoch: 5| Step: 7
Training loss: 2.6425326527406963
Validation loss: 2.6087789185653643

Epoch: 5| Step: 8
Training loss: 2.6426374903831613
Validation loss: 2.5338782739851506

Epoch: 5| Step: 9
Training loss: 2.7896001388427245
Validation loss: 2.5862440861821634

Epoch: 5| Step: 10
Training loss: 2.446561159393493
Validation loss: 2.67524342932507

Epoch: 292| Step: 0
Training loss: 3.0315734061530706
Validation loss: 2.6002472303236095

Epoch: 5| Step: 1
Training loss: 2.8277155964461427
Validation loss: 2.6082097684712373

Epoch: 5| Step: 2
Training loss: 2.553233254797877
Validation loss: 2.631036443152415

Epoch: 5| Step: 3
Training loss: 2.874694476272075
Validation loss: 2.6225815613034955

Epoch: 5| Step: 4
Training loss: 2.462462906146598
Validation loss: 2.595266071805242

Epoch: 5| Step: 5
Training loss: 2.292935164821383
Validation loss: 2.5540073273677044

Epoch: 5| Step: 6
Training loss: 3.2831249874513673
Validation loss: 2.6330979160481407

Epoch: 5| Step: 7
Training loss: 2.372282581717864
Validation loss: 2.5448764811489144

Epoch: 5| Step: 8
Training loss: 2.3364194034820214
Validation loss: 2.577306953380391

Epoch: 5| Step: 9
Training loss: 2.5875648379840617
Validation loss: 2.62354073002347

Epoch: 5| Step: 10
Training loss: 2.3509307722497157
Validation loss: 2.6213554927856255

Epoch: 293| Step: 0
Training loss: 2.5448770936318112
Validation loss: 2.4936703590096307

Epoch: 5| Step: 1
Training loss: 2.3655343404957057
Validation loss: 2.5452015548636324

Epoch: 5| Step: 2
Training loss: 2.373478753621018
Validation loss: 2.6064155591146196

Epoch: 5| Step: 3
Training loss: 3.083110354497194
Validation loss: 2.5581773384166797

Epoch: 5| Step: 4
Training loss: 2.8658404187152486
Validation loss: 2.5544479803238778

Epoch: 5| Step: 5
Training loss: 1.7991292330776167
Validation loss: 2.5461174216719065

Epoch: 5| Step: 6
Training loss: 2.9188686959353496
Validation loss: 2.4995578118444346

Epoch: 5| Step: 7
Training loss: 3.031710088361928
Validation loss: 2.5887011974892116

Epoch: 5| Step: 8
Training loss: 2.2571493580709037
Validation loss: 2.6266213686938924

Epoch: 5| Step: 9
Training loss: 2.5410674175640184
Validation loss: 2.5948124585120764

Epoch: 5| Step: 10
Training loss: 2.297629200122087
Validation loss: 2.5602829449074163

Epoch: 294| Step: 0
Training loss: 3.2903200767213194
Validation loss: 2.5994810541728266

Epoch: 5| Step: 1
Training loss: 3.110441858726595
Validation loss: 2.6259090907150147

Epoch: 5| Step: 2
Training loss: 2.415277959019154
Validation loss: 2.5055880308822482

Epoch: 5| Step: 3
Training loss: 1.8238170761522123
Validation loss: 2.607222726278928

Epoch: 5| Step: 4
Training loss: 2.474263179802922
Validation loss: 2.5926434216820566

Epoch: 5| Step: 5
Training loss: 2.3056628216324486
Validation loss: 2.5519392550902498

Epoch: 5| Step: 6
Training loss: 2.4935160476966756
Validation loss: 2.561339478976617

Epoch: 5| Step: 7
Training loss: 3.1956443707546587
Validation loss: 2.560236564241469

Epoch: 5| Step: 8
Training loss: 2.1081152651143866
Validation loss: 2.606986032170565

Epoch: 5| Step: 9
Training loss: 2.679953514663879
Validation loss: 2.614622326527318

Epoch: 5| Step: 10
Training loss: 2.1320442800378787
Validation loss: 2.5277416669605723

Epoch: 295| Step: 0
Training loss: 2.603893163941718
Validation loss: 2.5926468241868377

Epoch: 5| Step: 1
Training loss: 2.6476372604161886
Validation loss: 2.5234486467801074

Epoch: 5| Step: 2
Training loss: 2.6086069221541033
Validation loss: 2.5582919561127695

Epoch: 5| Step: 3
Training loss: 2.4700725248245377
Validation loss: 2.6151255821673622

Epoch: 5| Step: 4
Training loss: 2.1140708364927097
Validation loss: 2.6316639000878883

Epoch: 5| Step: 5
Training loss: 2.4156510641609104
Validation loss: 2.5781167356794294

Epoch: 5| Step: 6
Training loss: 2.436541540044225
Validation loss: 2.554259398173411

Epoch: 5| Step: 7
Training loss: 2.406986767816881
Validation loss: 2.6291311330249805

Epoch: 5| Step: 8
Training loss: 2.9828715906539736
Validation loss: 2.632187513142982

Epoch: 5| Step: 9
Training loss: 3.257598064875824
Validation loss: 2.666687551603775

Epoch: 5| Step: 10
Training loss: 1.8357455538789753
Validation loss: 2.600361741642487

Epoch: 296| Step: 0
Training loss: 2.3041807490419175
Validation loss: 2.6023962464864936

Epoch: 5| Step: 1
Training loss: 2.3012850198562425
Validation loss: 2.5973402019952836

Epoch: 5| Step: 2
Training loss: 2.3785018201287365
Validation loss: 2.603887842489984

Epoch: 5| Step: 3
Training loss: 2.4571351725277544
Validation loss: 2.5791804972413686

Epoch: 5| Step: 4
Training loss: 2.5666646841792917
Validation loss: 2.603148889982892

Epoch: 5| Step: 5
Training loss: 2.770768033360054
Validation loss: 2.6220990083135978

Epoch: 5| Step: 6
Training loss: 3.138377585913642
Validation loss: 2.6008620711930566

Epoch: 5| Step: 7
Training loss: 2.6263216415431008
Validation loss: 2.5300585871004957

Epoch: 5| Step: 8
Training loss: 2.332218335185639
Validation loss: 2.637034917946839

Epoch: 5| Step: 9
Training loss: 2.8367972423774583
Validation loss: 2.6158900897620936

Epoch: 5| Step: 10
Training loss: 2.554480121373177
Validation loss: 2.5773999191107975

Epoch: 297| Step: 0
Training loss: 2.3975337310741187
Validation loss: 2.5698949496690258

Epoch: 5| Step: 1
Training loss: 2.1819879021523376
Validation loss: 2.62362487995844

Epoch: 5| Step: 2
Training loss: 2.5699402327953815
Validation loss: 2.592998122371059

Epoch: 5| Step: 3
Training loss: 3.3908374913164283
Validation loss: 2.5580068654589896

Epoch: 5| Step: 4
Training loss: 2.7623853944506664
Validation loss: 2.6913908161396085

Epoch: 5| Step: 5
Training loss: 2.4731621247369033
Validation loss: 2.5866856350497676

Epoch: 5| Step: 6
Training loss: 2.530272683688618
Validation loss: 2.5597266179029865

Epoch: 5| Step: 7
Training loss: 2.162018288999937
Validation loss: 2.607488113931687

Epoch: 5| Step: 8
Training loss: 2.413162606911316
Validation loss: 2.615931522978595

Epoch: 5| Step: 9
Training loss: 2.1876743792102893
Validation loss: 2.613800687340957

Epoch: 5| Step: 10
Training loss: 2.8193224069860636
Validation loss: 2.6116633258565796

Epoch: 298| Step: 0
Training loss: 3.0627835200892304
Validation loss: 2.649826552367783

Epoch: 5| Step: 1
Training loss: 2.331870937747735
Validation loss: 2.603592380984684

Epoch: 5| Step: 2
Training loss: 3.4060281103814303
Validation loss: 2.5792746249452767

Epoch: 5| Step: 3
Training loss: 2.5154765778347556
Validation loss: 2.5324946738349476

Epoch: 5| Step: 4
Training loss: 2.143377831186485
Validation loss: 2.5786924233083925

Epoch: 5| Step: 5
Training loss: 2.2585878723764754
Validation loss: 2.513223771709401

Epoch: 5| Step: 6
Training loss: 2.427754801804652
Validation loss: 2.5621500113900186

Epoch: 5| Step: 7
Training loss: 2.1559379462404644
Validation loss: 2.5869361132227087

Epoch: 5| Step: 8
Training loss: 2.776294622771146
Validation loss: 2.601553014296794

Epoch: 5| Step: 9
Training loss: 2.7185526809120404
Validation loss: 2.621352417027854

Epoch: 5| Step: 10
Training loss: 2.4573490198117316
Validation loss: 2.523527229573168

Epoch: 299| Step: 0
Training loss: 3.2461179876971924
Validation loss: 2.5426154599064765

Epoch: 5| Step: 1
Training loss: 2.484012793282261
Validation loss: 2.654993421871125

Epoch: 5| Step: 2
Training loss: 3.1927538189699756
Validation loss: 2.663473705402436

Epoch: 5| Step: 3
Training loss: 2.8749242026247237
Validation loss: 2.617323617298937

Epoch: 5| Step: 4
Training loss: 1.7556552789561541
Validation loss: 2.467733649833695

Epoch: 5| Step: 5
Training loss: 2.345948879000414
Validation loss: 2.595983793421734

Epoch: 5| Step: 6
Training loss: 2.800811384350179
Validation loss: 2.6126576707303046

Epoch: 5| Step: 7
Training loss: 2.0032462953690113
Validation loss: 2.527916148306269

Epoch: 5| Step: 8
Training loss: 2.6049386876481853
Validation loss: 2.5830511090480193

Epoch: 5| Step: 9
Training loss: 2.1616695683836546
Validation loss: 2.6343578711901556

Epoch: 5| Step: 10
Training loss: 2.5426089827774416
Validation loss: 2.5613611853686566

Epoch: 300| Step: 0
Training loss: 2.6271832787189533
Validation loss: 2.620515920474505

Epoch: 5| Step: 1
Training loss: 2.3179460267900054
Validation loss: 2.5692305973560763

Epoch: 5| Step: 2
Training loss: 2.0843790354539506
Validation loss: 2.613135125296097

Epoch: 5| Step: 3
Training loss: 2.708093299988324
Validation loss: 2.552722141928784

Epoch: 5| Step: 4
Training loss: 2.9348073752520767
Validation loss: 2.6000011747288947

Epoch: 5| Step: 5
Training loss: 2.428732926745048
Validation loss: 2.596239150097588

Epoch: 5| Step: 6
Training loss: 2.6202768795387934
Validation loss: 2.5820637575963645

Epoch: 5| Step: 7
Training loss: 2.7806791083948403
Validation loss: 2.595115690519589

Epoch: 5| Step: 8
Training loss: 2.5021437989953395
Validation loss: 2.5474022730244177

Epoch: 5| Step: 9
Training loss: 2.5051927043932207
Validation loss: 2.520619810399413

Epoch: 5| Step: 10
Training loss: 2.604556814850125
Validation loss: 2.597919553836735

Epoch: 301| Step: 0
Training loss: 2.672358418952844
Validation loss: 2.5703176047099308

Epoch: 5| Step: 1
Training loss: 2.237279537997015
Validation loss: 2.5270963158027278

Epoch: 5| Step: 2
Training loss: 2.573974968303144
Validation loss: 2.551709166557906

Epoch: 5| Step: 3
Training loss: 2.2566787354650413
Validation loss: 2.583244090634361

Epoch: 5| Step: 4
Training loss: 2.848262685662628
Validation loss: 2.601021803073609

Epoch: 5| Step: 5
Training loss: 2.468507102895821
Validation loss: 2.483968175030838

Epoch: 5| Step: 6
Training loss: 2.792966274447111
Validation loss: 2.576753960645585

Epoch: 5| Step: 7
Training loss: 2.8734821791128615
Validation loss: 2.5960503706124474

Epoch: 5| Step: 8
Training loss: 2.6462400429186492
Validation loss: 2.5777469878691095

Epoch: 5| Step: 9
Training loss: 2.3937180399939915
Validation loss: 2.54831033294835

Epoch: 5| Step: 10
Training loss: 2.5133611313608997
Validation loss: 2.5107868006648553

Epoch: 302| Step: 0
Training loss: 2.9728856242607993
Validation loss: 2.587958920073554

Epoch: 5| Step: 1
Training loss: 2.2977605656586473
Validation loss: 2.5808182009754503

Epoch: 5| Step: 2
Training loss: 2.943465971962405
Validation loss: 2.6056749847974543

Epoch: 5| Step: 3
Training loss: 2.7064003037082953
Validation loss: 2.562692374374905

Epoch: 5| Step: 4
Training loss: 2.4122900520642383
Validation loss: 2.596278330590347

Epoch: 5| Step: 5
Training loss: 2.3956658567412448
Validation loss: 2.598383791396223

Epoch: 5| Step: 6
Training loss: 2.5971950953444467
Validation loss: 2.594387161506579

Epoch: 5| Step: 7
Training loss: 2.543990672580246
Validation loss: 2.593833845878487

Epoch: 5| Step: 8
Training loss: 2.259576761568072
Validation loss: 2.612465845273266

Epoch: 5| Step: 9
Training loss: 2.6924400171312284
Validation loss: 2.6027396904968536

Epoch: 5| Step: 10
Training loss: 2.657258683711129
Validation loss: 2.602326607304829

Epoch: 303| Step: 0
Training loss: 2.5375681074050482
Validation loss: 2.6361986480596897

Epoch: 5| Step: 1
Training loss: 2.976198028918174
Validation loss: 2.565070846805112

Epoch: 5| Step: 2
Training loss: 2.158893899279714
Validation loss: 2.6592572189667876

Epoch: 5| Step: 3
Training loss: 2.9366983171966416
Validation loss: 2.610497738918709

Epoch: 5| Step: 4
Training loss: 2.030940927319761
Validation loss: 2.5678143862002543

Epoch: 5| Step: 5
Training loss: 2.8757412825555666
Validation loss: 2.5679084673046355

Epoch: 5| Step: 6
Training loss: 2.442505904691308
Validation loss: 2.593027717294477

Epoch: 5| Step: 7
Training loss: 2.572492515619807
Validation loss: 2.5439736500482986

Epoch: 5| Step: 8
Training loss: 3.236297625695529
Validation loss: 2.579248296371059

Epoch: 5| Step: 9
Training loss: 2.3218862417778094
Validation loss: 2.6270990363737003

Epoch: 5| Step: 10
Training loss: 2.305709663919283
Validation loss: 2.5503264423125076

Epoch: 304| Step: 0
Training loss: 2.2322292027802875
Validation loss: 2.614420016766029

Epoch: 5| Step: 1
Training loss: 2.2494139437896123
Validation loss: 2.539239100017012

Epoch: 5| Step: 2
Training loss: 2.1111142370412783
Validation loss: 2.549582804396675

Epoch: 5| Step: 3
Training loss: 2.8070107191456684
Validation loss: 2.607177003167645

Epoch: 5| Step: 4
Training loss: 3.45446323337996
Validation loss: 2.6482980913912857

Epoch: 5| Step: 5
Training loss: 2.3389238641358383
Validation loss: 2.563592986307519

Epoch: 5| Step: 6
Training loss: 1.9537246393960568
Validation loss: 2.6107686637572525

Epoch: 5| Step: 7
Training loss: 2.607337201633118
Validation loss: 2.6374423006487517

Epoch: 5| Step: 8
Training loss: 2.870049568306466
Validation loss: 2.6376503557502238

Epoch: 5| Step: 9
Training loss: 2.9676804071364167
Validation loss: 2.4729356300601464

Epoch: 5| Step: 10
Training loss: 1.850614409617713
Validation loss: 2.6471951319475697

Epoch: 305| Step: 0
Training loss: 1.8648573249671194
Validation loss: 2.5136396303052972

Epoch: 5| Step: 1
Training loss: 2.9550744136729006
Validation loss: 2.5671232682217004

Epoch: 5| Step: 2
Training loss: 2.6482260290469224
Validation loss: 2.613881771569115

Epoch: 5| Step: 3
Training loss: 2.4278631199206937
Validation loss: 2.555000642478966

Epoch: 5| Step: 4
Training loss: 1.9205496335099987
Validation loss: 2.6384939580041173

Epoch: 5| Step: 5
Training loss: 3.0396892617174363
Validation loss: 2.5570345082380737

Epoch: 5| Step: 6
Training loss: 2.7135111879673763
Validation loss: 2.6406989259875773

Epoch: 5| Step: 7
Training loss: 3.0324331904235455
Validation loss: 2.563619989667202

Epoch: 5| Step: 8
Training loss: 2.3138542333996823
Validation loss: 2.5589965863900836

Epoch: 5| Step: 9
Training loss: 2.529546659058497
Validation loss: 2.6628549954900196

Epoch: 5| Step: 10
Training loss: 3.0382326851512036
Validation loss: 2.5738186307510156

Epoch: 306| Step: 0
Training loss: 2.4275098652349465
Validation loss: 2.6361749992756147

Epoch: 5| Step: 1
Training loss: 1.5207637701281227
Validation loss: 2.6199630191657004

Epoch: 5| Step: 2
Training loss: 3.0429109266710075
Validation loss: 2.561163442920524

Epoch: 5| Step: 3
Training loss: 2.514299789999291
Validation loss: 2.5766146753227295

Epoch: 5| Step: 4
Training loss: 2.425405377985007
Validation loss: 2.57239742419316

Epoch: 5| Step: 5
Training loss: 2.6083928618376855
Validation loss: 2.605374842466362

Epoch: 5| Step: 6
Training loss: 3.0748457893222536
Validation loss: 2.6175829027152324

Epoch: 5| Step: 7
Training loss: 2.387650877494252
Validation loss: 2.483446674880834

Epoch: 5| Step: 8
Training loss: 3.1016344499289934
Validation loss: 2.582886482225718

Epoch: 5| Step: 9
Training loss: 2.6266229244727386
Validation loss: 2.5272204340859923

Epoch: 5| Step: 10
Training loss: 2.324689032155037
Validation loss: 2.608440897846434

Epoch: 307| Step: 0
Training loss: 2.902785502478762
Validation loss: 2.5896119210545367

Epoch: 5| Step: 1
Training loss: 2.618062069651771
Validation loss: 2.568460523826004

Epoch: 5| Step: 2
Training loss: 2.9478166291389836
Validation loss: 2.567528363905007

Epoch: 5| Step: 3
Training loss: 2.6191597410865595
Validation loss: 2.5529477157189127

Epoch: 5| Step: 4
Training loss: 2.0805986639609464
Validation loss: 2.6415568673020813

Epoch: 5| Step: 5
Training loss: 2.1645920308745787
Validation loss: 2.5121600038205143

Epoch: 5| Step: 6
Training loss: 2.181912069757021
Validation loss: 2.5276565577533425

Epoch: 5| Step: 7
Training loss: 2.9173395379794926
Validation loss: 2.6310717809109594

Epoch: 5| Step: 8
Training loss: 3.0037806848045325
Validation loss: 2.5488342544079012

Epoch: 5| Step: 9
Training loss: 2.2909394468633026
Validation loss: 2.5737963172415177

Epoch: 5| Step: 10
Training loss: 2.5058315926704244
Validation loss: 2.555406706839868

Epoch: 308| Step: 0
Training loss: 2.341481955179122
Validation loss: 2.591929407976195

Epoch: 5| Step: 1
Training loss: 2.9525262134754646
Validation loss: 2.636946218774583

Epoch: 5| Step: 2
Training loss: 2.232589114675663
Validation loss: 2.512409464111461

Epoch: 5| Step: 3
Training loss: 2.1898497903599687
Validation loss: 2.5426133405239164

Epoch: 5| Step: 4
Training loss: 2.8057973042021525
Validation loss: 2.7093866549677155

Epoch: 5| Step: 5
Training loss: 2.881645152370376
Validation loss: 2.537210392444954

Epoch: 5| Step: 6
Training loss: 2.282927536464806
Validation loss: 2.617825511438828

Epoch: 5| Step: 7
Training loss: 2.511376815943341
Validation loss: 2.571402234362365

Epoch: 5| Step: 8
Training loss: 2.6668647056793935
Validation loss: 2.567599616860616

Epoch: 5| Step: 9
Training loss: 2.9179287132774583
Validation loss: 2.5549995658502813

Epoch: 5| Step: 10
Training loss: 2.089545854388937
Validation loss: 2.59511053777712

Epoch: 309| Step: 0
Training loss: 2.8845168453894403
Validation loss: 2.4571964182250814

Epoch: 5| Step: 1
Training loss: 3.1716270913645013
Validation loss: 2.5958448224276043

Epoch: 5| Step: 2
Training loss: 2.321285775791741
Validation loss: 2.539130376850361

Epoch: 5| Step: 3
Training loss: 2.5993465115856487
Validation loss: 2.609973885166626

Epoch: 5| Step: 4
Training loss: 2.812357835355539
Validation loss: 2.6104534559215224

Epoch: 5| Step: 5
Training loss: 2.244132444468064
Validation loss: 2.6163674120402574

Epoch: 5| Step: 6
Training loss: 2.6382680452630294
Validation loss: 2.5685918585401213

Epoch: 5| Step: 7
Training loss: 2.605845274020038
Validation loss: 2.5446703833650397

Epoch: 5| Step: 8
Training loss: 2.2065729526239246
Validation loss: 2.52793390670918

Epoch: 5| Step: 9
Training loss: 1.8643667070368681
Validation loss: 2.609576931663829

Epoch: 5| Step: 10
Training loss: 2.349415860725214
Validation loss: 2.633357522333384

Epoch: 310| Step: 0
Training loss: 3.1065380246892733
Validation loss: 2.562589262161247

Epoch: 5| Step: 1
Training loss: 2.607880489864147
Validation loss: 2.671330883323633

Epoch: 5| Step: 2
Training loss: 2.2570091851233034
Validation loss: 2.549953230883978

Epoch: 5| Step: 3
Training loss: 2.965459023464771
Validation loss: 2.574763482447172

Epoch: 5| Step: 4
Training loss: 2.4274168535758687
Validation loss: 2.6532028585115377

Epoch: 5| Step: 5
Training loss: 2.372630593792643
Validation loss: 2.6096325190255127

Epoch: 5| Step: 6
Training loss: 2.3339633318219786
Validation loss: 2.602363543660001

Epoch: 5| Step: 7
Training loss: 2.505313471903023
Validation loss: 2.527044807542618

Epoch: 5| Step: 8
Training loss: 2.810689216068495
Validation loss: 2.5667864196907884

Epoch: 5| Step: 9
Training loss: 2.427181312864533
Validation loss: 2.6409681291060525

Epoch: 5| Step: 10
Training loss: 2.222266513330098
Validation loss: 2.61048857833548

Epoch: 311| Step: 0
Training loss: 2.6679317533237366
Validation loss: 2.5454746042404

Epoch: 5| Step: 1
Training loss: 3.5066032789276482
Validation loss: 2.640445331039359

Epoch: 5| Step: 2
Training loss: 2.607898957114715
Validation loss: 2.575248316057829

Epoch: 5| Step: 3
Training loss: 2.3971940088165082
Validation loss: 2.5718238601900163

Epoch: 5| Step: 4
Training loss: 2.0811988068204204
Validation loss: 2.556027513586938

Epoch: 5| Step: 5
Training loss: 2.2550108531682267
Validation loss: 2.6880970468416794

Epoch: 5| Step: 6
Training loss: 2.5824897578314223
Validation loss: 2.659065801166007

Epoch: 5| Step: 7
Training loss: 2.4997602347793833
Validation loss: 2.563978139534084

Epoch: 5| Step: 8
Training loss: 2.3046900862339834
Validation loss: 2.594962257697056

Epoch: 5| Step: 9
Training loss: 2.440861071942025
Validation loss: 2.59999852062117

Epoch: 5| Step: 10
Training loss: 2.5242993090757953
Validation loss: 2.550465376096395

Epoch: 312| Step: 0
Training loss: 2.231195388253836
Validation loss: 2.578961920854395

Epoch: 5| Step: 1
Training loss: 2.7822281906749797
Validation loss: 2.542601927890696

Epoch: 5| Step: 2
Training loss: 2.7575719798732594
Validation loss: 2.499503547843518

Epoch: 5| Step: 3
Training loss: 2.2291823651007605
Validation loss: 2.6063105658017935

Epoch: 5| Step: 4
Training loss: 2.2184685542018996
Validation loss: 2.5801924613512717

Epoch: 5| Step: 5
Training loss: 2.8311848816109317
Validation loss: 2.536729899703554

Epoch: 5| Step: 6
Training loss: 2.610625372903298
Validation loss: 2.5776965697971965

Epoch: 5| Step: 7
Training loss: 2.7923208485564404
Validation loss: 2.6528940908874565

Epoch: 5| Step: 8
Training loss: 2.186080581094245
Validation loss: 2.5974736305777584

Epoch: 5| Step: 9
Training loss: 3.136887485245968
Validation loss: 2.591820652740895

Epoch: 5| Step: 10
Training loss: 2.4917193603897614
Validation loss: 2.615785718817445

Epoch: 313| Step: 0
Training loss: 1.9977770014353426
Validation loss: 2.6724817152892446

Epoch: 5| Step: 1
Training loss: 3.1379446861979092
Validation loss: 2.607027981557575

Epoch: 5| Step: 2
Training loss: 2.5442706875653
Validation loss: 2.584947384179227

Epoch: 5| Step: 3
Training loss: 2.6908085883373096
Validation loss: 2.598732008612666

Epoch: 5| Step: 4
Training loss: 2.431344402608454
Validation loss: 2.549019843565823

Epoch: 5| Step: 5
Training loss: 3.02434705512831
Validation loss: 2.552874493263086

Epoch: 5| Step: 6
Training loss: 2.0567157438204497
Validation loss: 2.704219448840354

Epoch: 5| Step: 7
Training loss: 2.0363908709370704
Validation loss: 2.569073339430285

Epoch: 5| Step: 8
Training loss: 2.586527224138048
Validation loss: 2.5070531359440826

Epoch: 5| Step: 9
Training loss: 2.0605744129528345
Validation loss: 2.622610348297137

Epoch: 5| Step: 10
Training loss: 3.419875584174148
Validation loss: 2.606464163675776

Epoch: 314| Step: 0
Training loss: 3.1275026599802587
Validation loss: 2.600169369921188

Epoch: 5| Step: 1
Training loss: 2.095306842520385
Validation loss: 2.586948581891176

Epoch: 5| Step: 2
Training loss: 2.7696763876264123
Validation loss: 2.585784262182233

Epoch: 5| Step: 3
Training loss: 2.5782454029058175
Validation loss: 2.523522173454861

Epoch: 5| Step: 4
Training loss: 2.1472536466645047
Validation loss: 2.6197942005005688

Epoch: 5| Step: 5
Training loss: 2.4399222052007397
Validation loss: 2.583684286782958

Epoch: 5| Step: 6
Training loss: 2.2321059436470643
Validation loss: 2.6001380529582154

Epoch: 5| Step: 7
Training loss: 2.8106015897916423
Validation loss: 2.5497741987712774

Epoch: 5| Step: 8
Training loss: 2.9347334475246676
Validation loss: 2.535813892658203

Epoch: 5| Step: 9
Training loss: 2.314351655047572
Validation loss: 2.528561542677087

Epoch: 5| Step: 10
Training loss: 1.9738910700494336
Validation loss: 2.5688323807306586

Epoch: 315| Step: 0
Training loss: 2.970188314459548
Validation loss: 2.6083614362266654

Epoch: 5| Step: 1
Training loss: 3.06440893351661
Validation loss: 2.5557111004233954

Epoch: 5| Step: 2
Training loss: 2.1630236614553873
Validation loss: 2.629295073769857

Epoch: 5| Step: 3
Training loss: 2.411652778931733
Validation loss: 2.57952131268714

Epoch: 5| Step: 4
Training loss: 2.23234519259431
Validation loss: 2.5599137903342144

Epoch: 5| Step: 5
Training loss: 2.3874904053180694
Validation loss: 2.718007717279981

Epoch: 5| Step: 6
Training loss: 2.696373506775946
Validation loss: 2.582160584936307

Epoch: 5| Step: 7
Training loss: 2.501009737187237
Validation loss: 2.6612308561431184

Epoch: 5| Step: 8
Training loss: 2.7014790192784326
Validation loss: 2.571751769292899

Epoch: 5| Step: 9
Training loss: 2.2493087978430615
Validation loss: 2.6329458607076086

Epoch: 5| Step: 10
Training loss: 2.1798185356978177
Validation loss: 2.552705011915172

Epoch: 316| Step: 0
Training loss: 2.7026178843488937
Validation loss: 2.6402799018332503

Epoch: 5| Step: 1
Training loss: 1.8871796797217502
Validation loss: 2.575348138138884

Epoch: 5| Step: 2
Training loss: 3.2301051755144528
Validation loss: 2.5968990293373606

Epoch: 5| Step: 3
Training loss: 2.418021304741107
Validation loss: 2.5561609955068367

Epoch: 5| Step: 4
Training loss: 2.512504300545575
Validation loss: 2.642560041740892

Epoch: 5| Step: 5
Training loss: 2.39248066606353
Validation loss: 2.6346599851679096

Epoch: 5| Step: 6
Training loss: 2.379636855910902
Validation loss: 2.5029300603291396

Epoch: 5| Step: 7
Training loss: 2.9046555934423814
Validation loss: 2.497025624697705

Epoch: 5| Step: 8
Training loss: 3.0202440059688587
Validation loss: 2.629912807286131

Epoch: 5| Step: 9
Training loss: 2.817986625612575
Validation loss: 2.5982333182334743

Epoch: 5| Step: 10
Training loss: 1.733277738425414
Validation loss: 2.567616814245341

Epoch: 317| Step: 0
Training loss: 2.497967179662328
Validation loss: 2.6034061277865135

Epoch: 5| Step: 1
Training loss: 2.6150390916750688
Validation loss: 2.610533795636218

Epoch: 5| Step: 2
Training loss: 2.465491546771091
Validation loss: 2.6070840756018954

Epoch: 5| Step: 3
Training loss: 2.9571046202815565
Validation loss: 2.5696569223156907

Epoch: 5| Step: 4
Training loss: 2.4701223301421122
Validation loss: 2.5254021347011135

Epoch: 5| Step: 5
Training loss: 2.336978948117178
Validation loss: 2.558230087285526

Epoch: 5| Step: 6
Training loss: 2.493675051067188
Validation loss: 2.5620459157504194

Epoch: 5| Step: 7
Training loss: 2.5786751824757435
Validation loss: 2.584916487777041

Epoch: 5| Step: 8
Training loss: 2.5600909562641916
Validation loss: 2.5920620953886773

Epoch: 5| Step: 9
Training loss: 2.3443271180736796
Validation loss: 2.670788770414629

Epoch: 5| Step: 10
Training loss: 2.920414034087147
Validation loss: 2.5323068439879233

Epoch: 318| Step: 0
Training loss: 2.1450019139279095
Validation loss: 2.5387212880254726

Epoch: 5| Step: 1
Training loss: 2.8858803239992126
Validation loss: 2.598799716920359

Epoch: 5| Step: 2
Training loss: 2.860132335989039
Validation loss: 2.6083967086823057

Epoch: 5| Step: 3
Training loss: 2.6507461073322562
Validation loss: 2.5703787138237018

Epoch: 5| Step: 4
Training loss: 2.004021059431943
Validation loss: 2.520874654305299

Epoch: 5| Step: 5
Training loss: 2.866408738649608
Validation loss: 2.5408958844520995

Epoch: 5| Step: 6
Training loss: 3.1235827474708993
Validation loss: 2.6142757198697644

Epoch: 5| Step: 7
Training loss: 2.2331201190612218
Validation loss: 2.571438036718265

Epoch: 5| Step: 8
Training loss: 2.1780568794971145
Validation loss: 2.5469345366651295

Epoch: 5| Step: 9
Training loss: 2.3985194089739212
Validation loss: 2.6075401877531137

Epoch: 5| Step: 10
Training loss: 2.449718466951208
Validation loss: 2.647128435363388

Epoch: 319| Step: 0
Training loss: 2.3534772307877088
Validation loss: 2.6046335076713385

Epoch: 5| Step: 1
Training loss: 2.418295793493906
Validation loss: 2.590029166146046

Epoch: 5| Step: 2
Training loss: 2.75669436170634
Validation loss: 2.612577559217788

Epoch: 5| Step: 3
Training loss: 2.968025520667403
Validation loss: 2.5945014077705637

Epoch: 5| Step: 4
Training loss: 3.004787122450627
Validation loss: 2.592919847538989

Epoch: 5| Step: 5
Training loss: 2.266265462916245
Validation loss: 2.6342222234037673

Epoch: 5| Step: 6
Training loss: 2.315658268451448
Validation loss: 2.582194599983169

Epoch: 5| Step: 7
Training loss: 2.580805731496341
Validation loss: 2.6245001157259455

Epoch: 5| Step: 8
Training loss: 2.644287007940891
Validation loss: 2.565752457933809

Epoch: 5| Step: 9
Training loss: 1.9237846873070452
Validation loss: 2.598980503150887

Epoch: 5| Step: 10
Training loss: 2.7060055241271117
Validation loss: 2.5392140989268888

Epoch: 320| Step: 0
Training loss: 3.2400258407033258
Validation loss: 2.556372643270666

Epoch: 5| Step: 1
Training loss: 2.9518778756164203
Validation loss: 2.565949232287345

Epoch: 5| Step: 2
Training loss: 2.866974617437561
Validation loss: 2.608590196468267

Epoch: 5| Step: 3
Training loss: 2.2996719872808975
Validation loss: 2.580495186967541

Epoch: 5| Step: 4
Training loss: 2.411000998668867
Validation loss: 2.655718780809327

Epoch: 5| Step: 5
Training loss: 2.4924200541417254
Validation loss: 2.5983005856725785

Epoch: 5| Step: 6
Training loss: 2.348394649112137
Validation loss: 2.5403019633565784

Epoch: 5| Step: 7
Training loss: 1.9151287612255643
Validation loss: 2.605097953071635

Epoch: 5| Step: 8
Training loss: 2.453451049907206
Validation loss: 2.5636240806968846

Epoch: 5| Step: 9
Training loss: 2.3920485303542285
Validation loss: 2.5187056438782998

Epoch: 5| Step: 10
Training loss: 2.8953479021505006
Validation loss: 2.6448368259432016

Epoch: 321| Step: 0
Training loss: 2.142619742004092
Validation loss: 2.6053561093592914

Epoch: 5| Step: 1
Training loss: 2.952976122135984
Validation loss: 2.577975900066909

Epoch: 5| Step: 2
Training loss: 2.6580172774397024
Validation loss: 2.634163997797101

Epoch: 5| Step: 3
Training loss: 2.044205183849997
Validation loss: 2.6082912751738796

Epoch: 5| Step: 4
Training loss: 1.9318029260287986
Validation loss: 2.5785279079413725

Epoch: 5| Step: 5
Training loss: 2.5613428620110392
Validation loss: 2.5834131284755686

Epoch: 5| Step: 6
Training loss: 2.4894367212089983
Validation loss: 2.562802725817603

Epoch: 5| Step: 7
Training loss: 2.4750419304889
Validation loss: 2.6020676864100643

Epoch: 5| Step: 8
Training loss: 2.388458666639658
Validation loss: 2.551308045314166

Epoch: 5| Step: 9
Training loss: 3.0137872185578525
Validation loss: 2.599455110738086

Epoch: 5| Step: 10
Training loss: 2.5444027187455824
Validation loss: 2.5739652609163675

Epoch: 322| Step: 0
Training loss: 2.9286756064995436
Validation loss: 2.573254032111252

Epoch: 5| Step: 1
Training loss: 2.3982704924550253
Validation loss: 2.517578298110375

Epoch: 5| Step: 2
Training loss: 2.5992860657505985
Validation loss: 2.5405704626390073

Epoch: 5| Step: 3
Training loss: 2.5893328638904642
Validation loss: 2.5671450705112036

Epoch: 5| Step: 4
Training loss: 1.8621420906830808
Validation loss: 2.5790272615211913

Epoch: 5| Step: 5
Training loss: 2.669555638944003
Validation loss: 2.5719897961467773

Epoch: 5| Step: 6
Training loss: 2.560971711484753
Validation loss: 2.523504539439159

Epoch: 5| Step: 7
Training loss: 2.093708891963228
Validation loss: 2.5952539517908177

Epoch: 5| Step: 8
Training loss: 2.997458016783209
Validation loss: 2.6183159810009227

Epoch: 5| Step: 9
Training loss: 2.328169035015075
Validation loss: 2.573207671539581

Epoch: 5| Step: 10
Training loss: 3.1816903819390467
Validation loss: 2.5690537768115016

Epoch: 323| Step: 0
Training loss: 2.5203837054151044
Validation loss: 2.627219470412689

Epoch: 5| Step: 1
Training loss: 2.25987893548295
Validation loss: 2.5813956597015792

Epoch: 5| Step: 2
Training loss: 1.7976921545469156
Validation loss: 2.536196992345354

Epoch: 5| Step: 3
Training loss: 3.096044440963327
Validation loss: 2.605111712526884

Epoch: 5| Step: 4
Training loss: 2.4519612656002847
Validation loss: 2.6194959578115076

Epoch: 5| Step: 5
Training loss: 2.392656547662456
Validation loss: 2.5111056810980905

Epoch: 5| Step: 6
Training loss: 1.5709320668053905
Validation loss: 2.57915719737087

Epoch: 5| Step: 7
Training loss: 2.6634151981202865
Validation loss: 2.636053661961343

Epoch: 5| Step: 8
Training loss: 3.171457347714773
Validation loss: 2.551612324012786

Epoch: 5| Step: 9
Training loss: 3.0438491272499775
Validation loss: 2.533971982169465

Epoch: 5| Step: 10
Training loss: 2.264095763705189
Validation loss: 2.6226464369206295

Epoch: 324| Step: 0
Training loss: 2.2985960033748767
Validation loss: 2.5743501663803716

Epoch: 5| Step: 1
Training loss: 2.5929062171744683
Validation loss: 2.538637579991937

Epoch: 5| Step: 2
Training loss: 2.7012356897457868
Validation loss: 2.5951733539097757

Epoch: 5| Step: 3
Training loss: 2.601409449385477
Validation loss: 2.590022090963832

Epoch: 5| Step: 4
Training loss: 2.547940645601522
Validation loss: 2.5673539125227487

Epoch: 5| Step: 5
Training loss: 2.143644778502578
Validation loss: 2.52660765595645

Epoch: 5| Step: 6
Training loss: 2.760373490673665
Validation loss: 2.5436779646439427

Epoch: 5| Step: 7
Training loss: 2.863816444162316
Validation loss: 2.559235044267721

Epoch: 5| Step: 8
Training loss: 2.576252852895935
Validation loss: 2.6774469697390293

Epoch: 5| Step: 9
Training loss: 2.6318512472015283
Validation loss: 2.61989227051522

Epoch: 5| Step: 10
Training loss: 2.7887881702391053
Validation loss: 2.5274725321056986

Epoch: 325| Step: 0
Training loss: 2.1641499746112474
Validation loss: 2.532149921215383

Epoch: 5| Step: 1
Training loss: 2.4861563767823767
Validation loss: 2.6321817190592203

Epoch: 5| Step: 2
Training loss: 2.3541641797978143
Validation loss: 2.591797295382937

Epoch: 5| Step: 3
Training loss: 2.327089732362515
Validation loss: 2.5111784196481106

Epoch: 5| Step: 4
Training loss: 2.3052932201901535
Validation loss: 2.5134516704638985

Epoch: 5| Step: 5
Training loss: 3.539096857371515
Validation loss: 2.639477659114891

Epoch: 5| Step: 6
Training loss: 2.442051184346674
Validation loss: 2.5643150610386423

Epoch: 5| Step: 7
Training loss: 2.848025618512947
Validation loss: 2.618406348128001

Epoch: 5| Step: 8
Training loss: 2.306082093450842
Validation loss: 2.567431538910409

Epoch: 5| Step: 9
Training loss: 2.7933595183912177
Validation loss: 2.5588452678098625

Epoch: 5| Step: 10
Training loss: 2.7554339561071877
Validation loss: 2.537514569357749

Epoch: 326| Step: 0
Training loss: 2.4984265144111397
Validation loss: 2.652445512937063

Epoch: 5| Step: 1
Training loss: 2.487769153544622
Validation loss: 2.6369475497168366

Epoch: 5| Step: 2
Training loss: 2.7547405304891828
Validation loss: 2.5937923186282474

Epoch: 5| Step: 3
Training loss: 3.036149617244021
Validation loss: 2.578226563164444

Epoch: 5| Step: 4
Training loss: 2.3887964373695496
Validation loss: 2.559897418982391

Epoch: 5| Step: 5
Training loss: 3.177942345395709
Validation loss: 2.5769104901997433

Epoch: 5| Step: 6
Training loss: 2.0724089749988446
Validation loss: 2.605913113299669

Epoch: 5| Step: 7
Training loss: 2.533022883700778
Validation loss: 2.607630092653222

Epoch: 5| Step: 8
Training loss: 2.151093107505908
Validation loss: 2.5436947644060317

Epoch: 5| Step: 9
Training loss: 2.6134284965873666
Validation loss: 2.622446312260526

Epoch: 5| Step: 10
Training loss: 1.7139352812104955
Validation loss: 2.5357211573966887

Epoch: 327| Step: 0
Training loss: 2.773473691032575
Validation loss: 2.639134551873804

Epoch: 5| Step: 1
Training loss: 1.9763789638300757
Validation loss: 2.5883133544646304

Epoch: 5| Step: 2
Training loss: 2.251603720590103
Validation loss: 2.518072897131164

Epoch: 5| Step: 3
Training loss: 2.716693407250852
Validation loss: 2.539004134271691

Epoch: 5| Step: 4
Training loss: 2.2275425945623577
Validation loss: 2.5585396529315783

Epoch: 5| Step: 5
Training loss: 2.891225556543632
Validation loss: 2.6579390307807245

Epoch: 5| Step: 6
Training loss: 3.1533543362499383
Validation loss: 2.5729638239369397

Epoch: 5| Step: 7
Training loss: 2.164765942544028
Validation loss: 2.5675963219467715

Epoch: 5| Step: 8
Training loss: 2.5559450373344323
Validation loss: 2.5908469004768206

Epoch: 5| Step: 9
Training loss: 2.1069070577884284
Validation loss: 2.6108370943674304

Epoch: 5| Step: 10
Training loss: 2.546123463965584
Validation loss: 2.5403100186773253

Epoch: 328| Step: 0
Training loss: 2.4289361215093836
Validation loss: 2.6116401479259883

Epoch: 5| Step: 1
Training loss: 2.4314556005473063
Validation loss: 2.68293607915482

Epoch: 5| Step: 2
Training loss: 2.5745761374340956
Validation loss: 2.597161251094801

Epoch: 5| Step: 3
Training loss: 2.7477928320741443
Validation loss: 2.608468827614597

Epoch: 5| Step: 4
Training loss: 2.6787957578908284
Validation loss: 2.524404769286582

Epoch: 5| Step: 5
Training loss: 3.3225881160994972
Validation loss: 2.5141439427644503

Epoch: 5| Step: 6
Training loss: 2.129026972996257
Validation loss: 2.6060749024154246

Epoch: 5| Step: 7
Training loss: 2.8374130571800196
Validation loss: 2.6552031353617

Epoch: 5| Step: 8
Training loss: 1.7851912413658968
Validation loss: 2.60324154736592

Epoch: 5| Step: 9
Training loss: 2.312764126926764
Validation loss: 2.600625511877744

Epoch: 5| Step: 10
Training loss: 2.5072300314739966
Validation loss: 2.5471679450577653

Epoch: 329| Step: 0
Training loss: 2.229445989583778
Validation loss: 2.5146162909653142

Epoch: 5| Step: 1
Training loss: 2.757584948783239
Validation loss: 2.6327415338193036

Epoch: 5| Step: 2
Training loss: 2.762844088429569
Validation loss: 2.5945059658963863

Epoch: 5| Step: 3
Training loss: 2.0733645416969284
Validation loss: 2.5356027541853385

Epoch: 5| Step: 4
Training loss: 2.8591253453063823
Validation loss: 2.5855600906783245

Epoch: 5| Step: 5
Training loss: 2.9900959563406992
Validation loss: 2.5780051314453876

Epoch: 5| Step: 6
Training loss: 2.847520613089179
Validation loss: 2.5753118107794233

Epoch: 5| Step: 7
Training loss: 2.305183383159066
Validation loss: 2.614246034030068

Epoch: 5| Step: 8
Training loss: 3.0418111340080904
Validation loss: 2.535729025573453

Epoch: 5| Step: 9
Training loss: 2.2387318848218336
Validation loss: 2.5830965555493433

Epoch: 5| Step: 10
Training loss: 2.0438903713724983
Validation loss: 2.552060393145994

Epoch: 330| Step: 0
Training loss: 2.620074237325011
Validation loss: 2.567440965953132

Epoch: 5| Step: 1
Training loss: 2.2744437281703687
Validation loss: 2.6245583672046804

Epoch: 5| Step: 2
Training loss: 2.067052959928204
Validation loss: 2.6681039081367697

Epoch: 5| Step: 3
Training loss: 3.2163167107576527
Validation loss: 2.515100649569679

Epoch: 5| Step: 4
Training loss: 2.8110598797793473
Validation loss: 2.5735957469406716

Epoch: 5| Step: 5
Training loss: 2.530074423498238
Validation loss: 2.6228732910169135

Epoch: 5| Step: 6
Training loss: 2.3274997153112973
Validation loss: 2.5473710717021745

Epoch: 5| Step: 7
Training loss: 2.7997813548142694
Validation loss: 2.5849707726876225

Epoch: 5| Step: 8
Training loss: 2.4890404805025415
Validation loss: 2.5781924092568502

Epoch: 5| Step: 9
Training loss: 2.8502200794575097
Validation loss: 2.631589625795133

Epoch: 5| Step: 10
Training loss: 2.3109662924024574
Validation loss: 2.6283011337410462

Epoch: 331| Step: 0
Training loss: 2.3778286201571337
Validation loss: 2.682781552194375

Epoch: 5| Step: 1
Training loss: 2.428653509291636
Validation loss: 2.6716173661020957

Epoch: 5| Step: 2
Training loss: 2.0752894050359676
Validation loss: 2.5741087873703603

Epoch: 5| Step: 3
Training loss: 2.7587137019574315
Validation loss: 2.54290362100584

Epoch: 5| Step: 4
Training loss: 2.7127427128785424
Validation loss: 2.570137341864596

Epoch: 5| Step: 5
Training loss: 2.2977880622335194
Validation loss: 2.5740776060040678

Epoch: 5| Step: 6
Training loss: 2.2308647485667312
Validation loss: 2.6301101385204615

Epoch: 5| Step: 7
Training loss: 2.3736504183627694
Validation loss: 2.5355723241997774

Epoch: 5| Step: 8
Training loss: 2.9873552869917854
Validation loss: 2.610088396028799

Epoch: 5| Step: 9
Training loss: 2.3877803857543647
Validation loss: 2.6323924016269347

Epoch: 5| Step: 10
Training loss: 2.606889191696107
Validation loss: 2.5693527840189607

Epoch: 332| Step: 0
Training loss: 2.2607086508716634
Validation loss: 2.5827013910664576

Epoch: 5| Step: 1
Training loss: 1.9160215978500175
Validation loss: 2.5752233539599656

Epoch: 5| Step: 2
Training loss: 3.3809310226738027
Validation loss: 2.5395514712335

Epoch: 5| Step: 3
Training loss: 1.8910473438511266
Validation loss: 2.542269318732379

Epoch: 5| Step: 4
Training loss: 2.6840839410268127
Validation loss: 2.522240121020289

Epoch: 5| Step: 5
Training loss: 2.293865178098257
Validation loss: 2.5804873216655846

Epoch: 5| Step: 6
Training loss: 2.3016567151376806
Validation loss: 2.539806719962813

Epoch: 5| Step: 7
Training loss: 2.5888755680209035
Validation loss: 2.546893682108735

Epoch: 5| Step: 8
Training loss: 2.288224206736348
Validation loss: 2.578261268472406

Epoch: 5| Step: 9
Training loss: 3.0292820785623484
Validation loss: 2.560439078646767

Epoch: 5| Step: 10
Training loss: 2.5382846051467225
Validation loss: 2.614803441399247

Epoch: 333| Step: 0
Training loss: 2.2182766046681635
Validation loss: 2.6508862469426493

Epoch: 5| Step: 1
Training loss: 2.5819920985590725
Validation loss: 2.588658932299115

Epoch: 5| Step: 2
Training loss: 2.524942522055712
Validation loss: 2.6036027405208633

Epoch: 5| Step: 3
Training loss: 3.602097080631767
Validation loss: 2.6078311871891704

Epoch: 5| Step: 4
Training loss: 2.177490877642613
Validation loss: 2.614424598999226

Epoch: 5| Step: 5
Training loss: 2.6906196762546237
Validation loss: 2.5778917005079665

Epoch: 5| Step: 6
Training loss: 2.7372341357858536
Validation loss: 2.5635136266041734

Epoch: 5| Step: 7
Training loss: 2.0522338373080062
Validation loss: 2.5491454407872807

Epoch: 5| Step: 8
Training loss: 2.344806382212027
Validation loss: 2.5634740363370807

Epoch: 5| Step: 9
Training loss: 2.205066123368856
Validation loss: 2.6123713040916887

Epoch: 5| Step: 10
Training loss: 2.509858909684167
Validation loss: 2.6329007863474634

Epoch: 334| Step: 0
Training loss: 2.3303444543084866
Validation loss: 2.5849335074727717

Epoch: 5| Step: 1
Training loss: 2.9640584717412994
Validation loss: 2.6196949740208493

Epoch: 5| Step: 2
Training loss: 2.8313553207378455
Validation loss: 2.5671088098222525

Epoch: 5| Step: 3
Training loss: 2.6371828476111814
Validation loss: 2.5973856304270027

Epoch: 5| Step: 4
Training loss: 2.6711576513840143
Validation loss: 2.645147463540787

Epoch: 5| Step: 5
Training loss: 2.5423141551104864
Validation loss: 2.5210364604060076

Epoch: 5| Step: 6
Training loss: 2.4515225953646635
Validation loss: 2.565413392319901

Epoch: 5| Step: 7
Training loss: 2.586530173803572
Validation loss: 2.4928537129525266

Epoch: 5| Step: 8
Training loss: 2.662881628633769
Validation loss: 2.5956224032852866

Epoch: 5| Step: 9
Training loss: 1.5635629471616863
Validation loss: 2.5323158358744124

Epoch: 5| Step: 10
Training loss: 2.6617822816979477
Validation loss: 2.56356269856566

Epoch: 335| Step: 0
Training loss: 2.1460095922677
Validation loss: 2.6609348751775315

Epoch: 5| Step: 1
Training loss: 2.436980950282249
Validation loss: 2.541572317560673

Epoch: 5| Step: 2
Training loss: 1.8738705094096433
Validation loss: 2.5830375318114163

Epoch: 5| Step: 3
Training loss: 2.605678658558549
Validation loss: 2.5819383547135373

Epoch: 5| Step: 4
Training loss: 2.424569483029833
Validation loss: 2.554215176971525

Epoch: 5| Step: 5
Training loss: 2.4913458763312444
Validation loss: 2.627742272501898

Epoch: 5| Step: 6
Training loss: 2.3308690432269215
Validation loss: 2.568448529348703

Epoch: 5| Step: 7
Training loss: 2.710886138517415
Validation loss: 2.556415150427232

Epoch: 5| Step: 8
Training loss: 2.892627908817875
Validation loss: 2.580218755451849

Epoch: 5| Step: 9
Training loss: 2.4908100973581013
Validation loss: 2.610279362015406

Epoch: 5| Step: 10
Training loss: 2.8153571980565673
Validation loss: 2.554755454420121

Epoch: 336| Step: 0
Training loss: 2.5295975554264425
Validation loss: 2.633389580332176

Epoch: 5| Step: 1
Training loss: 2.21069927751917
Validation loss: 2.620553070029174

Epoch: 5| Step: 2
Training loss: 3.1698410954645038
Validation loss: 2.6543573014687007

Epoch: 5| Step: 3
Training loss: 2.226455846541018
Validation loss: 2.5724603639333137

Epoch: 5| Step: 4
Training loss: 2.3162347688292515
Validation loss: 2.551943786770467

Epoch: 5| Step: 5
Training loss: 2.5390439076843325
Validation loss: 2.582268685728215

Epoch: 5| Step: 6
Training loss: 2.5640980459442435
Validation loss: 2.5749242976755293

Epoch: 5| Step: 7
Training loss: 2.1801151416713807
Validation loss: 2.6005866640296857

Epoch: 5| Step: 8
Training loss: 3.2784190726950904
Validation loss: 2.5627694807360992

Epoch: 5| Step: 9
Training loss: 2.2528644977293673
Validation loss: 2.5703446431460844

Epoch: 5| Step: 10
Training loss: 2.804952114872861
Validation loss: 2.5918873101634596

Epoch: 337| Step: 0
Training loss: 2.486875415388764
Validation loss: 2.6208776743127036

Epoch: 5| Step: 1
Training loss: 2.7479816312439747
Validation loss: 2.6377326457987844

Epoch: 5| Step: 2
Training loss: 2.746247418853422
Validation loss: 2.5981740157502116

Epoch: 5| Step: 3
Training loss: 2.8592512593828174
Validation loss: 2.5813677836116566

Epoch: 5| Step: 4
Training loss: 2.2983876132802594
Validation loss: 2.599392393145846

Epoch: 5| Step: 5
Training loss: 2.4971984424621034
Validation loss: 2.599709762563259

Epoch: 5| Step: 6
Training loss: 2.5130125898842017
Validation loss: 2.603621336577543

Epoch: 5| Step: 7
Training loss: 2.600520294655952
Validation loss: 2.6229967954838567

Epoch: 5| Step: 8
Training loss: 2.0864755458061497
Validation loss: 2.5790107267075943

Epoch: 5| Step: 9
Training loss: 2.333468558162371
Validation loss: 2.533783769097033

Epoch: 5| Step: 10
Training loss: 2.8210682371555182
Validation loss: 2.5468154277184714

Epoch: 338| Step: 0
Training loss: 2.576703876343482
Validation loss: 2.656420350569003

Epoch: 5| Step: 1
Training loss: 2.4157240991633975
Validation loss: 2.596369954489671

Epoch: 5| Step: 2
Training loss: 2.750373988296953
Validation loss: 2.5179251853550326

Epoch: 5| Step: 3
Training loss: 2.7668418147094194
Validation loss: 2.5554966080090966

Epoch: 5| Step: 4
Training loss: 2.3730584289520684
Validation loss: 2.6259829433394466

Epoch: 5| Step: 5
Training loss: 2.576102740999248
Validation loss: 2.634834437947662

Epoch: 5| Step: 6
Training loss: 1.5663823532602839
Validation loss: 2.600306229191366

Epoch: 5| Step: 7
Training loss: 2.3762289180552862
Validation loss: 2.539738713814315

Epoch: 5| Step: 8
Training loss: 2.293717893952649
Validation loss: 2.6065580427828765

Epoch: 5| Step: 9
Training loss: 2.4004806116803405
Validation loss: 2.6744067997489775

Epoch: 5| Step: 10
Training loss: 3.266373835952316
Validation loss: 2.620753602397912

Epoch: 339| Step: 0
Training loss: 2.4396369565504714
Validation loss: 2.565848860708583

Epoch: 5| Step: 1
Training loss: 2.7858538295742328
Validation loss: 2.498055324681103

Epoch: 5| Step: 2
Training loss: 2.1274514363323633
Validation loss: 2.585887475591426

Epoch: 5| Step: 3
Training loss: 2.3217167057177512
Validation loss: 2.576153516670955

Epoch: 5| Step: 4
Training loss: 2.179325853104861
Validation loss: 2.530842020874138

Epoch: 5| Step: 5
Training loss: 2.029962336937803
Validation loss: 2.5257569301738108

Epoch: 5| Step: 6
Training loss: 2.493146562346777
Validation loss: 2.588972016822768

Epoch: 5| Step: 7
Training loss: 2.8162697006328923
Validation loss: 2.5889591588404883

Epoch: 5| Step: 8
Training loss: 2.999612942204302
Validation loss: 2.5211149180636165

Epoch: 5| Step: 9
Training loss: 3.0000174839781857
Validation loss: 2.5754337258526174

Epoch: 5| Step: 10
Training loss: 2.60634734340164
Validation loss: 2.47780373917907

Epoch: 340| Step: 0
Training loss: 1.9258931651684572
Validation loss: 2.567504633781609

Epoch: 5| Step: 1
Training loss: 2.648585132546376
Validation loss: 2.6389156167130947

Epoch: 5| Step: 2
Training loss: 2.605070481179744
Validation loss: 2.576869150846202

Epoch: 5| Step: 3
Training loss: 2.724488702104806
Validation loss: 2.528274458338426

Epoch: 5| Step: 4
Training loss: 2.677541334899922
Validation loss: 2.5981344365935413

Epoch: 5| Step: 5
Training loss: 2.5123260855384406
Validation loss: 2.5449335572730414

Epoch: 5| Step: 6
Training loss: 2.7342792603216837
Validation loss: 2.511811899889552

Epoch: 5| Step: 7
Training loss: 2.92222258596414
Validation loss: 2.588723224076322

Epoch: 5| Step: 8
Training loss: 2.02721955905743
Validation loss: 2.572437580713503

Epoch: 5| Step: 9
Training loss: 2.4167153802982506
Validation loss: 2.636887007205853

Epoch: 5| Step: 10
Training loss: 2.3747552444427407
Validation loss: 2.6406977522671706

Epoch: 341| Step: 0
Training loss: 2.2068030855512317
Validation loss: 2.577202357827182

Epoch: 5| Step: 1
Training loss: 2.635053546802995
Validation loss: 2.5408428685440647

Epoch: 5| Step: 2
Training loss: 2.166093554870645
Validation loss: 2.5662158148653216

Epoch: 5| Step: 3
Training loss: 2.5618340161803497
Validation loss: 2.6058978155030195

Epoch: 5| Step: 4
Training loss: 2.523347457365807
Validation loss: 2.545339560761621

Epoch: 5| Step: 5
Training loss: 3.3413094143306936
Validation loss: 2.5912290989608686

Epoch: 5| Step: 6
Training loss: 2.2719044973355347
Validation loss: 2.5787882598363745

Epoch: 5| Step: 7
Training loss: 2.7397960004950392
Validation loss: 2.6044425322739486

Epoch: 5| Step: 8
Training loss: 2.227178548615838
Validation loss: 2.5770822742598023

Epoch: 5| Step: 9
Training loss: 2.637672263210335
Validation loss: 2.564799145984603

Epoch: 5| Step: 10
Training loss: 1.7247338601067854
Validation loss: 2.614948729749679

Epoch: 342| Step: 0
Training loss: 3.2228925398696378
Validation loss: 2.5623612475102666

Epoch: 5| Step: 1
Training loss: 2.9951858040008603
Validation loss: 2.6100191496911633

Epoch: 5| Step: 2
Training loss: 2.319518290528802
Validation loss: 2.5057165811275373

Epoch: 5| Step: 3
Training loss: 1.920234165813221
Validation loss: 2.5541745573078285

Epoch: 5| Step: 4
Training loss: 2.982899086176565
Validation loss: 2.6051552400288807

Epoch: 5| Step: 5
Training loss: 2.4533621315026073
Validation loss: 2.5753768757404085

Epoch: 5| Step: 6
Training loss: 2.171300359217712
Validation loss: 2.5523764473147925

Epoch: 5| Step: 7
Training loss: 2.0616145689828835
Validation loss: 2.538413681544663

Epoch: 5| Step: 8
Training loss: 2.4789448059142107
Validation loss: 2.607274776886143

Epoch: 5| Step: 9
Training loss: 2.2378607816033003
Validation loss: 2.6001677569041943

Epoch: 5| Step: 10
Training loss: 2.904436427485324
Validation loss: 2.631488104592403

Epoch: 343| Step: 0
Training loss: 1.8882077740604875
Validation loss: 2.6159986714634464

Epoch: 5| Step: 1
Training loss: 2.75752935495946
Validation loss: 2.601306293059756

Epoch: 5| Step: 2
Training loss: 2.7086015910785246
Validation loss: 2.571646719508887

Epoch: 5| Step: 3
Training loss: 2.7043917119016965
Validation loss: 2.595749424531087

Epoch: 5| Step: 4
Training loss: 2.637709141977121
Validation loss: 2.588168031943388

Epoch: 5| Step: 5
Training loss: 2.4765455564286327
Validation loss: 2.6003004478702163

Epoch: 5| Step: 6
Training loss: 3.271366165075156
Validation loss: 2.597213444119061

Epoch: 5| Step: 7
Training loss: 2.157891464169705
Validation loss: 2.5261529537475633

Epoch: 5| Step: 8
Training loss: 1.9944879152855177
Validation loss: 2.5974447396950406

Epoch: 5| Step: 9
Training loss: 1.908640691279103
Validation loss: 2.5777133109540844

Epoch: 5| Step: 10
Training loss: 2.8213065553877477
Validation loss: 2.601791214607256

Epoch: 344| Step: 0
Training loss: 2.400501270397941
Validation loss: 2.5712204303401447

Epoch: 5| Step: 1
Training loss: 2.3192367371877625
Validation loss: 2.522103741992876

Epoch: 5| Step: 2
Training loss: 2.0086269285413665
Validation loss: 2.6772192812805615

Epoch: 5| Step: 3
Training loss: 2.5312228731185322
Validation loss: 2.5731260458521845

Epoch: 5| Step: 4
Training loss: 1.9809046760243147
Validation loss: 2.6561092930586696

Epoch: 5| Step: 5
Training loss: 2.4928369901500678
Validation loss: 2.5426939373218223

Epoch: 5| Step: 6
Training loss: 2.8029460122621432
Validation loss: 2.619771527036159

Epoch: 5| Step: 7
Training loss: 2.544704706114405
Validation loss: 2.553487451133471

Epoch: 5| Step: 8
Training loss: 2.352356329978972
Validation loss: 2.673092976895382

Epoch: 5| Step: 9
Training loss: 2.567491554461799
Validation loss: 2.575091125965805

Epoch: 5| Step: 10
Training loss: 3.183864689630739
Validation loss: 2.637029336725156

Epoch: 345| Step: 0
Training loss: 2.8241946903960913
Validation loss: 2.529659087788132

Epoch: 5| Step: 1
Training loss: 2.0609774894391975
Validation loss: 2.5445594249009784

Epoch: 5| Step: 2
Training loss: 2.8652187313180644
Validation loss: 2.627388273502606

Epoch: 5| Step: 3
Training loss: 2.627977680517956
Validation loss: 2.633870973865787

Epoch: 5| Step: 4
Training loss: 2.8576823576696597
Validation loss: 2.5490147500115286

Epoch: 5| Step: 5
Training loss: 2.0224665959903945
Validation loss: 2.60773315710076

Epoch: 5| Step: 6
Training loss: 2.2823159849565067
Validation loss: 2.599847207103685

Epoch: 5| Step: 7
Training loss: 2.435084393113905
Validation loss: 2.6679037724568957

Epoch: 5| Step: 8
Training loss: 2.1820736748121843
Validation loss: 2.4737333275501974

Epoch: 5| Step: 9
Training loss: 2.788475423621458
Validation loss: 2.5488166637522074

Epoch: 5| Step: 10
Training loss: 2.6313432618056876
Validation loss: 2.546031861415421

Epoch: 346| Step: 0
Training loss: 3.344959503749795
Validation loss: 2.56155295570785

Epoch: 5| Step: 1
Training loss: 2.120792262111205
Validation loss: 2.6177932212186383

Epoch: 5| Step: 2
Training loss: 2.4630416351900526
Validation loss: 2.5155231463108527

Epoch: 5| Step: 3
Training loss: 2.8780231337687856
Validation loss: 2.578881319292723

Epoch: 5| Step: 4
Training loss: 2.3360477281162533
Validation loss: 2.581442170161849

Epoch: 5| Step: 5
Training loss: 2.451799168052193
Validation loss: 2.655134810721056

Epoch: 5| Step: 6
Training loss: 2.676437497936181
Validation loss: 2.5656648845774197

Epoch: 5| Step: 7
Training loss: 2.255966117942638
Validation loss: 2.537280008214105

Epoch: 5| Step: 8
Training loss: 2.2334206416965765
Validation loss: 2.571523129493454

Epoch: 5| Step: 9
Training loss: 2.3673281989758537
Validation loss: 2.5783055207166403

Epoch: 5| Step: 10
Training loss: 2.2696243240784875
Validation loss: 2.578609868678457

Epoch: 347| Step: 0
Training loss: 2.8633974892205263
Validation loss: 2.5482437831235796

Epoch: 5| Step: 1
Training loss: 2.336995781355622
Validation loss: 2.5550656096082824

Epoch: 5| Step: 2
Training loss: 3.150189917758029
Validation loss: 2.639087148856407

Epoch: 5| Step: 3
Training loss: 2.6457695139799986
Validation loss: 2.524595790703994

Epoch: 5| Step: 4
Training loss: 1.495024216624827
Validation loss: 2.585638334489711

Epoch: 5| Step: 5
Training loss: 2.618253211922862
Validation loss: 2.541349494775241

Epoch: 5| Step: 6
Training loss: 2.3882101989898894
Validation loss: 2.595809409536075

Epoch: 5| Step: 7
Training loss: 2.390779078885045
Validation loss: 2.5899312026499457

Epoch: 5| Step: 8
Training loss: 1.7768084380154299
Validation loss: 2.6049090705826337

Epoch: 5| Step: 9
Training loss: 2.8425793596259514
Validation loss: 2.564581627053529

Epoch: 5| Step: 10
Training loss: 2.4766378782335385
Validation loss: 2.585000600340501

Epoch: 348| Step: 0
Training loss: 3.4938695897361436
Validation loss: 2.5373162415269856

Epoch: 5| Step: 1
Training loss: 2.359977392637948
Validation loss: 2.562886086708275

Epoch: 5| Step: 2
Training loss: 2.8137333179116624
Validation loss: 2.613897538036135

Epoch: 5| Step: 3
Training loss: 2.384561865847314
Validation loss: 2.5243222835362067

Epoch: 5| Step: 4
Training loss: 2.859518912607514
Validation loss: 2.619617918687781

Epoch: 5| Step: 5
Training loss: 2.7811411289808867
Validation loss: 2.5606340151783913

Epoch: 5| Step: 6
Training loss: 2.1394469646416012
Validation loss: 2.591299610188876

Epoch: 5| Step: 7
Training loss: 1.7493439534585047
Validation loss: 2.568848174696928

Epoch: 5| Step: 8
Training loss: 2.1248682766647606
Validation loss: 2.5228318943321066

Epoch: 5| Step: 9
Training loss: 2.396551726622074
Validation loss: 2.5797312844018085

Epoch: 5| Step: 10
Training loss: 2.7121391161793773
Validation loss: 2.543977430043771

Epoch: 349| Step: 0
Training loss: 1.634256408940272
Validation loss: 2.5626778529624747

Epoch: 5| Step: 1
Training loss: 2.781458214670369
Validation loss: 2.545750749138488

Epoch: 5| Step: 2
Training loss: 2.31412737521685
Validation loss: 2.582590644081979

Epoch: 5| Step: 3
Training loss: 2.3802911144416234
Validation loss: 2.569697375063049

Epoch: 5| Step: 4
Training loss: 1.7272089097677088
Validation loss: 2.5824850961024635

Epoch: 5| Step: 5
Training loss: 2.797837075933264
Validation loss: 2.5516250979146626

Epoch: 5| Step: 6
Training loss: 2.389085261334407
Validation loss: 2.6270754657154036

Epoch: 5| Step: 7
Training loss: 2.350749841735698
Validation loss: 2.5967314883899926

Epoch: 5| Step: 8
Training loss: 2.7031029496368517
Validation loss: 2.5391233425880753

Epoch: 5| Step: 9
Training loss: 2.802966681765178
Validation loss: 2.5799947730788326

Epoch: 5| Step: 10
Training loss: 2.7646412797119013
Validation loss: 2.593953152472066

Epoch: 350| Step: 0
Training loss: 2.019868036813028
Validation loss: 2.5454788503247596

Epoch: 5| Step: 1
Training loss: 2.4121574119078084
Validation loss: 2.5880708171933646

Epoch: 5| Step: 2
Training loss: 2.2536357538820546
Validation loss: 2.558037554716976

Epoch: 5| Step: 3
Training loss: 3.044071413964434
Validation loss: 2.633779339529417

Epoch: 5| Step: 4
Training loss: 2.5697454969209135
Validation loss: 2.5606217617784033

Epoch: 5| Step: 5
Training loss: 2.4350987858091444
Validation loss: 2.6045467061666554

Epoch: 5| Step: 6
Training loss: 2.8089366804287708
Validation loss: 2.6275755713026316

Epoch: 5| Step: 7
Training loss: 2.5652724364158024
Validation loss: 2.659373416492632

Epoch: 5| Step: 8
Training loss: 2.770240337811115
Validation loss: 2.5063572214990972

Epoch: 5| Step: 9
Training loss: 1.9391492161814643
Validation loss: 2.5634668358590433

Epoch: 5| Step: 10
Training loss: 2.3448945366217258
Validation loss: 2.5448966547267915

Epoch: 351| Step: 0
Training loss: 2.4875738315072593
Validation loss: 2.5744976206540198

Epoch: 5| Step: 1
Training loss: 1.9139039265866657
Validation loss: 2.6062704491995277

Epoch: 5| Step: 2
Training loss: 2.417750827909471
Validation loss: 2.6030168218820102

Epoch: 5| Step: 3
Training loss: 2.1269307060916733
Validation loss: 2.583540404677857

Epoch: 5| Step: 4
Training loss: 2.5134733487733456
Validation loss: 2.569786896001981

Epoch: 5| Step: 5
Training loss: 2.554796222391437
Validation loss: 2.580497268283171

Epoch: 5| Step: 6
Training loss: 2.559719158503557
Validation loss: 2.5535484329238387

Epoch: 5| Step: 7
Training loss: 2.5554741164605645
Validation loss: 2.504337681309348

Epoch: 5| Step: 8
Training loss: 2.5624094691218007
Validation loss: 2.6393311703270386

Epoch: 5| Step: 9
Training loss: 2.707488930944639
Validation loss: 2.534495099764224

Epoch: 5| Step: 10
Training loss: 3.4683947681984537
Validation loss: 2.595269776105786

Epoch: 352| Step: 0
Training loss: 3.2338159050287922
Validation loss: 2.5557950647564516

Epoch: 5| Step: 1
Training loss: 2.3831760817004604
Validation loss: 2.601015252579839

Epoch: 5| Step: 2
Training loss: 2.5565291832866563
Validation loss: 2.5653030227646108

Epoch: 5| Step: 3
Training loss: 2.187699336097708
Validation loss: 2.524446174650754

Epoch: 5| Step: 4
Training loss: 2.051485649116336
Validation loss: 2.5673712069145433

Epoch: 5| Step: 5
Training loss: 2.3636185838790897
Validation loss: 2.581344206534801

Epoch: 5| Step: 6
Training loss: 2.34254831661198
Validation loss: 2.560505755047324

Epoch: 5| Step: 7
Training loss: 3.120676635828402
Validation loss: 2.5661743976344074

Epoch: 5| Step: 8
Training loss: 2.5461055786944278
Validation loss: 2.538163817636217

Epoch: 5| Step: 9
Training loss: 2.339838145763583
Validation loss: 2.595193397298225

Epoch: 5| Step: 10
Training loss: 2.64387853503869
Validation loss: 2.525827363014003

Epoch: 353| Step: 0
Training loss: 3.128954559600916
Validation loss: 2.6019815786546574

Epoch: 5| Step: 1
Training loss: 2.2737680306330517
Validation loss: 2.5482800818715967

Epoch: 5| Step: 2
Training loss: 2.6385990474428858
Validation loss: 2.6164313845108063

Epoch: 5| Step: 3
Training loss: 1.8141907008408278
Validation loss: 2.527418404902189

Epoch: 5| Step: 4
Training loss: 2.180529797422803
Validation loss: 2.5004145565666875

Epoch: 5| Step: 5
Training loss: 2.9679639880008355
Validation loss: 2.627581575554847

Epoch: 5| Step: 6
Training loss: 2.4242510553408634
Validation loss: 2.570184709389543

Epoch: 5| Step: 7
Training loss: 2.0266848395603616
Validation loss: 2.5649163993163535

Epoch: 5| Step: 8
Training loss: 3.258584349606586
Validation loss: 2.631692218533988

Epoch: 5| Step: 9
Training loss: 2.5142786439263647
Validation loss: 2.5922211283581498

Epoch: 5| Step: 10
Training loss: 2.954905946787124
Validation loss: 2.563983803782127

Epoch: 354| Step: 0
Training loss: 2.7165637817871273
Validation loss: 2.4997685109913945

Epoch: 5| Step: 1
Training loss: 2.527660414890448
Validation loss: 2.550343689828965

Epoch: 5| Step: 2
Training loss: 2.6556842874726287
Validation loss: 2.5288842064808685

Epoch: 5| Step: 3
Training loss: 2.556605094738551
Validation loss: 2.614040579402145

Epoch: 5| Step: 4
Training loss: 1.887604436448258
Validation loss: 2.6105101225462657

Epoch: 5| Step: 5
Training loss: 2.3428324620013536
Validation loss: 2.580631095837645

Epoch: 5| Step: 6
Training loss: 2.618827010230989
Validation loss: 2.5496192600435412

Epoch: 5| Step: 7
Training loss: 2.0834138727514846
Validation loss: 2.5670218859419944

Epoch: 5| Step: 8
Training loss: 2.9881519962855427
Validation loss: 2.597754682066425

Epoch: 5| Step: 9
Training loss: 2.712760290498826
Validation loss: 2.550020822869894

Epoch: 5| Step: 10
Training loss: 2.528150002411325
Validation loss: 2.6054562656628484

Epoch: 355| Step: 0
Training loss: 2.5924299626835974
Validation loss: 2.6168886604558845

Epoch: 5| Step: 1
Training loss: 2.1048134543063903
Validation loss: 2.5179772879311155

Epoch: 5| Step: 2
Training loss: 1.8745077758652202
Validation loss: 2.5880272539585425

Epoch: 5| Step: 3
Training loss: 2.550259453533007
Validation loss: 2.4882408295023892

Epoch: 5| Step: 4
Training loss: 2.5652944633006873
Validation loss: 2.6158922252381545

Epoch: 5| Step: 5
Training loss: 3.1459214827627227
Validation loss: 2.560710673937126

Epoch: 5| Step: 6
Training loss: 2.30733438858424
Validation loss: 2.4639599604186766

Epoch: 5| Step: 7
Training loss: 2.4762157113148286
Validation loss: 2.5615244543395614

Epoch: 5| Step: 8
Training loss: 2.7709665385951374
Validation loss: 2.5880238572673

Epoch: 5| Step: 9
Training loss: 3.0280710441892253
Validation loss: 2.5922956445389493

Epoch: 5| Step: 10
Training loss: 2.1081700026783587
Validation loss: 2.5646441173546677

Epoch: 356| Step: 0
Training loss: 2.4511463908660303
Validation loss: 2.624540782007278

Epoch: 5| Step: 1
Training loss: 2.7184885710503544
Validation loss: 2.600452533548597

Epoch: 5| Step: 2
Training loss: 2.457081416698957
Validation loss: 2.6149096182201848

Epoch: 5| Step: 3
Training loss: 2.076701773973847
Validation loss: 2.5270138529810886

Epoch: 5| Step: 4
Training loss: 2.301627296628507
Validation loss: 2.6638831819025652

Epoch: 5| Step: 5
Training loss: 2.547763318499877
Validation loss: 2.593308062362925

Epoch: 5| Step: 6
Training loss: 2.5824727706729242
Validation loss: 2.5984875155992557

Epoch: 5| Step: 7
Training loss: 2.651067187792851
Validation loss: 2.5676233630798055

Epoch: 5| Step: 8
Training loss: 2.4217700566350957
Validation loss: 2.521877752480651

Epoch: 5| Step: 9
Training loss: 2.3359734267722176
Validation loss: 2.612829598687501

Epoch: 5| Step: 10
Training loss: 3.0920952889686326
Validation loss: 2.567359302709725

Epoch: 357| Step: 0
Training loss: 2.956417448370294
Validation loss: 2.586609794669981

Epoch: 5| Step: 1
Training loss: 2.3963895621971343
Validation loss: 2.5889422270034523

Epoch: 5| Step: 2
Training loss: 2.0771904471686256
Validation loss: 2.5737141065950384

Epoch: 5| Step: 3
Training loss: 2.6827182368857314
Validation loss: 2.59862055379476

Epoch: 5| Step: 4
Training loss: 2.4564073313248507
Validation loss: 2.5728894383756393

Epoch: 5| Step: 5
Training loss: 2.1863033836481987
Validation loss: 2.6195423603952297

Epoch: 5| Step: 6
Training loss: 2.403658375374973
Validation loss: 2.562523122183434

Epoch: 5| Step: 7
Training loss: 2.86320530893495
Validation loss: 2.560898935687238

Epoch: 5| Step: 8
Training loss: 2.11323138335054
Validation loss: 2.611784594359633

Epoch: 5| Step: 9
Training loss: 2.421526385412268
Validation loss: 2.5237849247907262

Epoch: 5| Step: 10
Training loss: 2.315698628149521
Validation loss: 2.581294100062234

Epoch: 358| Step: 0
Training loss: 2.9832897509866996
Validation loss: 2.5015583226835676

Epoch: 5| Step: 1
Training loss: 2.746994022919742
Validation loss: 2.58799048446448

Epoch: 5| Step: 2
Training loss: 2.4462043671403766
Validation loss: 2.6092323007286873

Epoch: 5| Step: 3
Training loss: 1.9016004672997158
Validation loss: 2.5103056967419004

Epoch: 5| Step: 4
Training loss: 2.214013968550287
Validation loss: 2.629328741327855

Epoch: 5| Step: 5
Training loss: 2.7253536834771968
Validation loss: 2.648161597120175

Epoch: 5| Step: 6
Training loss: 1.9870323350691481
Validation loss: 2.56705571909534

Epoch: 5| Step: 7
Training loss: 2.78615249428949
Validation loss: 2.5576627441336313

Epoch: 5| Step: 8
Training loss: 2.3944975957948027
Validation loss: 2.594230531236495

Epoch: 5| Step: 9
Training loss: 2.429154708684559
Validation loss: 2.5785368519869603

Epoch: 5| Step: 10
Training loss: 2.0572989805711237
Validation loss: 2.553351370580869

Epoch: 359| Step: 0
Training loss: 1.9439362096367363
Validation loss: 2.570509305759598

Epoch: 5| Step: 1
Training loss: 2.3872390404730406
Validation loss: 2.581499231302846

Epoch: 5| Step: 2
Training loss: 2.686322508730224
Validation loss: 2.562718910052814

Epoch: 5| Step: 3
Training loss: 2.473411794156586
Validation loss: 2.527828914209685

Epoch: 5| Step: 4
Training loss: 2.1663363522830763
Validation loss: 2.6383361265181846

Epoch: 5| Step: 5
Training loss: 2.390044098132004
Validation loss: 2.6576372098918006

Epoch: 5| Step: 6
Training loss: 2.02330953421676
Validation loss: 2.6054919100187433

Epoch: 5| Step: 7
Training loss: 2.551537674679733
Validation loss: 2.624599531226633

Epoch: 5| Step: 8
Training loss: 2.9374026018593633
Validation loss: 2.662340408650041

Epoch: 5| Step: 9
Training loss: 2.5987175859904132
Validation loss: 2.553102387186199

Epoch: 5| Step: 10
Training loss: 2.803601578054856
Validation loss: 2.603418323584381

Epoch: 360| Step: 0
Training loss: 2.8204581521589422
Validation loss: 2.591058357696865

Epoch: 5| Step: 1
Training loss: 2.4706802548039826
Validation loss: 2.615920287132874

Epoch: 5| Step: 2
Training loss: 2.903853381940306
Validation loss: 2.5816859597321784

Epoch: 5| Step: 3
Training loss: 1.7068528839432933
Validation loss: 2.555679576724387

Epoch: 5| Step: 4
Training loss: 2.50692077184075
Validation loss: 2.5880085171241136

Epoch: 5| Step: 5
Training loss: 2.572767019102686
Validation loss: 2.585557642608466

Epoch: 5| Step: 6
Training loss: 2.174199788007111
Validation loss: 2.5444687060744515

Epoch: 5| Step: 7
Training loss: 2.2988540531274633
Validation loss: 2.6862504366922044

Epoch: 5| Step: 8
Training loss: 2.1494584310788696
Validation loss: 2.590236790581008

Epoch: 5| Step: 9
Training loss: 3.238461037351213
Validation loss: 2.6348800518179636

Epoch: 5| Step: 10
Training loss: 2.3570257958743244
Validation loss: 2.6210591247441917

Epoch: 361| Step: 0
Training loss: 2.432863863854204
Validation loss: 2.559326950059523

Epoch: 5| Step: 1
Training loss: 1.9530465682494247
Validation loss: 2.476942335581517

Epoch: 5| Step: 2
Training loss: 2.9849787396004515
Validation loss: 2.5440054790269238

Epoch: 5| Step: 3
Training loss: 2.4415251924151335
Validation loss: 2.641334692199531

Epoch: 5| Step: 4
Training loss: 2.3464301488995045
Validation loss: 2.568552223781335

Epoch: 5| Step: 5
Training loss: 2.639446469567142
Validation loss: 2.5276126257330698

Epoch: 5| Step: 6
Training loss: 2.5550604965005403
Validation loss: 2.500329348701998

Epoch: 5| Step: 7
Training loss: 1.5499758226293316
Validation loss: 2.591755754295294

Epoch: 5| Step: 8
Training loss: 2.013532750293654
Validation loss: 2.5684141975053243

Epoch: 5| Step: 9
Training loss: 2.2092469562726684
Validation loss: 2.593015861174089

Epoch: 5| Step: 10
Training loss: 3.633276993784263
Validation loss: 2.6533693931224693

Epoch: 362| Step: 0
Training loss: 1.7096127472009108
Validation loss: 2.6044030405052414

Epoch: 5| Step: 1
Training loss: 1.8177185568389929
Validation loss: 2.507157544437229

Epoch: 5| Step: 2
Training loss: 2.4049849714733553
Validation loss: 2.5700421548178163

Epoch: 5| Step: 3
Training loss: 2.5130082256943025
Validation loss: 2.5602467472425086

Epoch: 5| Step: 4
Training loss: 2.7146519435390877
Validation loss: 2.565173593425568

Epoch: 5| Step: 5
Training loss: 2.357329334380065
Validation loss: 2.5847620736217154

Epoch: 5| Step: 6
Training loss: 2.265292228726961
Validation loss: 2.5831864834930927

Epoch: 5| Step: 7
Training loss: 3.174493620132618
Validation loss: 2.6068564872113758

Epoch: 5| Step: 8
Training loss: 2.6679167400334083
Validation loss: 2.6254612419290755

Epoch: 5| Step: 9
Training loss: 2.468316341893735
Validation loss: 2.6004227273690272

Epoch: 5| Step: 10
Training loss: 2.6693578094950676
Validation loss: 2.5552085236526563

Epoch: 363| Step: 0
Training loss: 2.1925755065652233
Validation loss: 2.5938061341034153

Epoch: 5| Step: 1
Training loss: 2.605037991032549
Validation loss: 2.54381134377683

Epoch: 5| Step: 2
Training loss: 2.2597619322909
Validation loss: 2.590623651948959

Epoch: 5| Step: 3
Training loss: 2.327342061749346
Validation loss: 2.59799344574926

Epoch: 5| Step: 4
Training loss: 2.8285249037446207
Validation loss: 2.5455019946835455

Epoch: 5| Step: 5
Training loss: 2.1629722961471667
Validation loss: 2.5086432434123953

Epoch: 5| Step: 6
Training loss: 2.424052483981912
Validation loss: 2.6012885418042413

Epoch: 5| Step: 7
Training loss: 2.515715034721797
Validation loss: 2.5676814951100715

Epoch: 5| Step: 8
Training loss: 2.763403652371684
Validation loss: 2.556242464906252

Epoch: 5| Step: 9
Training loss: 2.0152944840903477
Validation loss: 2.6072725802724053

Epoch: 5| Step: 10
Training loss: 3.3168292275723106
Validation loss: 2.6230053660349317

Epoch: 364| Step: 0
Training loss: 2.5989917047125317
Validation loss: 2.5627887382076824

Epoch: 5| Step: 1
Training loss: 2.132224536380083
Validation loss: 2.5302964630873257

Epoch: 5| Step: 2
Training loss: 2.6252894469035586
Validation loss: 2.574603739545544

Epoch: 5| Step: 3
Training loss: 3.1751906630571236
Validation loss: 2.5795693566249365

Epoch: 5| Step: 4
Training loss: 1.9573038181687692
Validation loss: 2.5230734064122147

Epoch: 5| Step: 5
Training loss: 2.598610609462175
Validation loss: 2.5095345020230404

Epoch: 5| Step: 6
Training loss: 2.583835081370746
Validation loss: 2.581356663481388

Epoch: 5| Step: 7
Training loss: 1.813918840895477
Validation loss: 2.6006242707823555

Epoch: 5| Step: 8
Training loss: 2.510866581236353
Validation loss: 2.5931004851221626

Epoch: 5| Step: 9
Training loss: 2.356538697221042
Validation loss: 2.594180018467766

Epoch: 5| Step: 10
Training loss: 2.5626024365303297
Validation loss: 2.533578034297561

Epoch: 365| Step: 0
Training loss: 2.3180790179709425
Validation loss: 2.487234591331263

Epoch: 5| Step: 1
Training loss: 1.9125982795346188
Validation loss: 2.5660272688265673

Epoch: 5| Step: 2
Training loss: 2.5956555456159465
Validation loss: 2.6500269978425566

Epoch: 5| Step: 3
Training loss: 2.9306302194188865
Validation loss: 2.666582938451334

Epoch: 5| Step: 4
Training loss: 2.564558551419653
Validation loss: 2.446244493972186

Epoch: 5| Step: 5
Training loss: 2.1680603557856375
Validation loss: 2.4707118295437347

Epoch: 5| Step: 6
Training loss: 3.2825316333045476
Validation loss: 2.5585151129859742

Epoch: 5| Step: 7
Training loss: 2.42576601573442
Validation loss: 2.609366212746174

Epoch: 5| Step: 8
Training loss: 2.064551518025417
Validation loss: 2.599453507140108

Epoch: 5| Step: 9
Training loss: 2.4499999143639375
Validation loss: 2.557352292425511

Epoch: 5| Step: 10
Training loss: 2.0246929265541427
Validation loss: 2.5260790845059433

Epoch: 366| Step: 0
Training loss: 1.8817387601806372
Validation loss: 2.5786673503952495

Epoch: 5| Step: 1
Training loss: 2.1501375997114396
Validation loss: 2.5572462140316183

Epoch: 5| Step: 2
Training loss: 2.24288440467365
Validation loss: 2.5616101546492405

Epoch: 5| Step: 3
Training loss: 2.5472928505963384
Validation loss: 2.5541856241475354

Epoch: 5| Step: 4
Training loss: 2.9106821698649488
Validation loss: 2.541210134231955

Epoch: 5| Step: 5
Training loss: 2.2913217689607834
Validation loss: 2.4904335627234326

Epoch: 5| Step: 6
Training loss: 2.337152375672544
Validation loss: 2.5848145710658907

Epoch: 5| Step: 7
Training loss: 2.4525816491832937
Validation loss: 2.604117473178673

Epoch: 5| Step: 8
Training loss: 2.9538841281033252
Validation loss: 2.5436503000749817

Epoch: 5| Step: 9
Training loss: 2.4887009869993726
Validation loss: 2.5416172671010107

Epoch: 5| Step: 10
Training loss: 2.948424134984779
Validation loss: 2.6044862210680075

Epoch: 367| Step: 0
Training loss: 2.717213426656021
Validation loss: 2.5011736965453237

Epoch: 5| Step: 1
Training loss: 2.223075304266853
Validation loss: 2.6010984128600216

Epoch: 5| Step: 2
Training loss: 2.501107256780127
Validation loss: 2.565160511214845

Epoch: 5| Step: 3
Training loss: 2.6738005720994096
Validation loss: 2.6110443185091685

Epoch: 5| Step: 4
Training loss: 2.2154246380901528
Validation loss: 2.5216637096899133

Epoch: 5| Step: 5
Training loss: 2.9836519174232206
Validation loss: 2.5643058084560533

Epoch: 5| Step: 6
Training loss: 2.918804983401243
Validation loss: 2.611285421001559

Epoch: 5| Step: 7
Training loss: 2.102099949065652
Validation loss: 2.6405661243201015

Epoch: 5| Step: 8
Training loss: 1.85231865359472
Validation loss: 2.6753638444726495

Epoch: 5| Step: 9
Training loss: 2.1223367944162645
Validation loss: 2.609729301907296

Epoch: 5| Step: 10
Training loss: 2.666307415207661
Validation loss: 2.6291202490429515

Epoch: 368| Step: 0
Training loss: 2.1133559349528164
Validation loss: 2.57765111163229

Epoch: 5| Step: 1
Training loss: 2.615650511404159
Validation loss: 2.666856327990348

Epoch: 5| Step: 2
Training loss: 3.1684449539977293
Validation loss: 2.6434938812375277

Epoch: 5| Step: 3
Training loss: 2.5220648749626777
Validation loss: 2.5865374974041355

Epoch: 5| Step: 4
Training loss: 2.0218779102522646
Validation loss: 2.5887416566661114

Epoch: 5| Step: 5
Training loss: 1.8932991976862052
Validation loss: 2.5966482445300865

Epoch: 5| Step: 6
Training loss: 2.7228774387264814
Validation loss: 2.5181735105216045

Epoch: 5| Step: 7
Training loss: 2.428150340847697
Validation loss: 2.621258039876105

Epoch: 5| Step: 8
Training loss: 2.3423435314443775
Validation loss: 2.590580590817459

Epoch: 5| Step: 9
Training loss: 2.4002973570989776
Validation loss: 2.6153502263525423

Epoch: 5| Step: 10
Training loss: 2.3982537910608817
Validation loss: 2.5719702995683056

Epoch: 369| Step: 0
Training loss: 2.543849716294057
Validation loss: 2.555094396735645

Epoch: 5| Step: 1
Training loss: 2.2557333906919967
Validation loss: 2.582954586049866

Epoch: 5| Step: 2
Training loss: 2.432851613930211
Validation loss: 2.5491798561456886

Epoch: 5| Step: 3
Training loss: 2.4079724376913356
Validation loss: 2.5916832049085836

Epoch: 5| Step: 4
Training loss: 2.4200768471173326
Validation loss: 2.5048770852263225

Epoch: 5| Step: 5
Training loss: 2.9223443128692046
Validation loss: 2.6545835610896202

Epoch: 5| Step: 6
Training loss: 2.3627756634098396
Validation loss: 2.594504813767355

Epoch: 5| Step: 7
Training loss: 2.4530598820104257
Validation loss: 2.572355646555259

Epoch: 5| Step: 8
Training loss: 2.1355771880565357
Validation loss: 2.6753518530304854

Epoch: 5| Step: 9
Training loss: 2.842183949959558
Validation loss: 2.507046983124898

Epoch: 5| Step: 10
Training loss: 2.953255463801372
Validation loss: 2.552998522128503

Epoch: 370| Step: 0
Training loss: 2.3699425506067167
Validation loss: 2.5208018812920763

Epoch: 5| Step: 1
Training loss: 2.365125305533824
Validation loss: 2.607623455530877

Epoch: 5| Step: 2
Training loss: 2.752201066445554
Validation loss: 2.4965336045683975

Epoch: 5| Step: 3
Training loss: 2.3992923368785126
Validation loss: 2.6378623713079015

Epoch: 5| Step: 4
Training loss: 2.5570983710076565
Validation loss: 2.577425822951746

Epoch: 5| Step: 5
Training loss: 2.5148975908121884
Validation loss: 2.5720575336471456

Epoch: 5| Step: 6
Training loss: 2.638326513587233
Validation loss: 2.6468501896440055

Epoch: 5| Step: 7
Training loss: 2.1579983022858142
Validation loss: 2.6241773965958957

Epoch: 5| Step: 8
Training loss: 2.5741315951376094
Validation loss: 2.5182005611315703

Epoch: 5| Step: 9
Training loss: 2.26862552185742
Validation loss: 2.5406763745513254

Epoch: 5| Step: 10
Training loss: 2.244428943144058
Validation loss: 2.6326415780978074

Epoch: 371| Step: 0
Training loss: 2.0096102136370613
Validation loss: 2.5723935105582223

Epoch: 5| Step: 1
Training loss: 2.4543848386547413
Validation loss: 2.5624888089963833

Epoch: 5| Step: 2
Training loss: 3.189760192180309
Validation loss: 2.5750721167996926

Epoch: 5| Step: 3
Training loss: 2.2188548748321524
Validation loss: 2.588862349105852

Epoch: 5| Step: 4
Training loss: 2.192219683518991
Validation loss: 2.480623385145793

Epoch: 5| Step: 5
Training loss: 1.9299148240343003
Validation loss: 2.5890528636984773

Epoch: 5| Step: 6
Training loss: 1.6430539996513394
Validation loss: 2.588414944737399

Epoch: 5| Step: 7
Training loss: 2.8891891625028006
Validation loss: 2.571994309444081

Epoch: 5| Step: 8
Training loss: 2.7375806927219184
Validation loss: 2.5685278224149197

Epoch: 5| Step: 9
Training loss: 2.7529459692672122
Validation loss: 2.601950651011484

Epoch: 5| Step: 10
Training loss: 2.3581086859402878
Validation loss: 2.6474609844644585

Epoch: 372| Step: 0
Training loss: 2.6321818787887135
Validation loss: 2.5365199704646986

Epoch: 5| Step: 1
Training loss: 2.2660004403365566
Validation loss: 2.6066754063360955

Epoch: 5| Step: 2
Training loss: 1.9275958505193596
Validation loss: 2.5792394114478263

Epoch: 5| Step: 3
Training loss: 2.241681084946939
Validation loss: 2.597788765298535

Epoch: 5| Step: 4
Training loss: 3.151537105399361
Validation loss: 2.5772505186031105

Epoch: 5| Step: 5
Training loss: 2.308185470288877
Validation loss: 2.588183028422092

Epoch: 5| Step: 6
Training loss: 2.579375455064597
Validation loss: 2.5688791895087397

Epoch: 5| Step: 7
Training loss: 2.610421707461017
Validation loss: 2.5992288605068055

Epoch: 5| Step: 8
Training loss: 2.1794826178841014
Validation loss: 2.5337009684405842

Epoch: 5| Step: 9
Training loss: 2.6442379584581506
Validation loss: 2.5443715667876763

Epoch: 5| Step: 10
Training loss: 2.699869565992098
Validation loss: 2.544249166872344

Epoch: 373| Step: 0
Training loss: 2.100166850046602
Validation loss: 2.5197143396587944

Epoch: 5| Step: 1
Training loss: 2.633803636668288
Validation loss: 2.5689821889701028

Epoch: 5| Step: 2
Training loss: 2.595679151712799
Validation loss: 2.5963623653667542

Epoch: 5| Step: 3
Training loss: 2.4613606407053155
Validation loss: 2.5436321615733886

Epoch: 5| Step: 4
Training loss: 2.304803981100429
Validation loss: 2.6214348040365008

Epoch: 5| Step: 5
Training loss: 3.200692644259229
Validation loss: 2.608209587615426

Epoch: 5| Step: 6
Training loss: 2.086311221130149
Validation loss: 2.5527434114269134

Epoch: 5| Step: 7
Training loss: 2.4901948334789594
Validation loss: 2.550278831605582

Epoch: 5| Step: 8
Training loss: 2.24588452235422
Validation loss: 2.522636497504906

Epoch: 5| Step: 9
Training loss: 2.3114933194066603
Validation loss: 2.566353498364889

Epoch: 5| Step: 10
Training loss: 3.0797418520857036
Validation loss: 2.617691099826868

Epoch: 374| Step: 0
Training loss: 1.9352301560766683
Validation loss: 2.588050089632605

Epoch: 5| Step: 1
Training loss: 2.746175968247097
Validation loss: 2.527211628981704

Epoch: 5| Step: 2
Training loss: 3.3940974442313085
Validation loss: 2.613410007591137

Epoch: 5| Step: 3
Training loss: 2.278268511821376
Validation loss: 2.6525680531963265

Epoch: 5| Step: 4
Training loss: 2.8450143539522497
Validation loss: 2.517590741660261

Epoch: 5| Step: 5
Training loss: 2.363680517344451
Validation loss: 2.568596172205403

Epoch: 5| Step: 6
Training loss: 2.195589312820708
Validation loss: 2.579855200648683

Epoch: 5| Step: 7
Training loss: 2.647679223180154
Validation loss: 2.5644529760472032

Epoch: 5| Step: 8
Training loss: 2.028129528258078
Validation loss: 2.5561700960422713

Epoch: 5| Step: 9
Training loss: 2.243223050861039
Validation loss: 2.6231327926248413

Epoch: 5| Step: 10
Training loss: 2.3921119204590826
Validation loss: 2.634212355077358

Epoch: 375| Step: 0
Training loss: 2.261104098326576
Validation loss: 2.5333299050958273

Epoch: 5| Step: 1
Training loss: 1.7522137128088071
Validation loss: 2.5601798247733814

Epoch: 5| Step: 2
Training loss: 2.749571853600628
Validation loss: 2.6328708421546554

Epoch: 5| Step: 3
Training loss: 3.062327788824386
Validation loss: 2.584654084056566

Epoch: 5| Step: 4
Training loss: 2.088895265195237
Validation loss: 2.544896728264459

Epoch: 5| Step: 5
Training loss: 2.4915538209433628
Validation loss: 2.6273125200726026

Epoch: 5| Step: 6
Training loss: 2.985135286163221
Validation loss: 2.6033163377278945

Epoch: 5| Step: 7
Training loss: 2.406726641325956
Validation loss: 2.6253555338349455

Epoch: 5| Step: 8
Training loss: 2.624136464815449
Validation loss: 2.5243900123936265

Epoch: 5| Step: 9
Training loss: 2.545743445158627
Validation loss: 2.5476813364521305

Epoch: 5| Step: 10
Training loss: 1.9716118493391
Validation loss: 2.640274762467882

Epoch: 376| Step: 0
Training loss: 2.770892713861758
Validation loss: 2.5295968728624523

Epoch: 5| Step: 1
Training loss: 2.6648589702743024
Validation loss: 2.6222441446791014

Epoch: 5| Step: 2
Training loss: 2.4609252929384744
Validation loss: 2.572716079936522

Epoch: 5| Step: 3
Training loss: 1.9156553530505278
Validation loss: 2.6066994604370435

Epoch: 5| Step: 4
Training loss: 2.625249759962861
Validation loss: 2.5624085806949872

Epoch: 5| Step: 5
Training loss: 2.2708975639941986
Validation loss: 2.546417013965065

Epoch: 5| Step: 6
Training loss: 2.423964552686248
Validation loss: 2.5683350336880344

Epoch: 5| Step: 7
Training loss: 1.8149089589680942
Validation loss: 2.5644550973741405

Epoch: 5| Step: 8
Training loss: 2.552165428450128
Validation loss: 2.5731279139396244

Epoch: 5| Step: 9
Training loss: 3.0289433148162606
Validation loss: 2.597903296169494

Epoch: 5| Step: 10
Training loss: 2.7670471500450637
Validation loss: 2.517561689643136

Epoch: 377| Step: 0
Training loss: 2.877005499565694
Validation loss: 2.6032676549455847

Epoch: 5| Step: 1
Training loss: 2.1113623405457793
Validation loss: 2.620757191438501

Epoch: 5| Step: 2
Training loss: 2.6042706481519318
Validation loss: 2.544355478815317

Epoch: 5| Step: 3
Training loss: 2.201990904322383
Validation loss: 2.610192256688873

Epoch: 5| Step: 4
Training loss: 2.109805705991647
Validation loss: 2.6576267156447173

Epoch: 5| Step: 5
Training loss: 3.131625057456317
Validation loss: 2.6333181273567967

Epoch: 5| Step: 6
Training loss: 2.709930232793395
Validation loss: 2.583235433816055

Epoch: 5| Step: 7
Training loss: 1.9691504419373798
Validation loss: 2.5958477876767385

Epoch: 5| Step: 8
Training loss: 2.4963851543699622
Validation loss: 2.5429274587156954

Epoch: 5| Step: 9
Training loss: 2.3081829912641
Validation loss: 2.613564899901918

Epoch: 5| Step: 10
Training loss: 2.5887978399508205
Validation loss: 2.587561905350077

Epoch: 378| Step: 0
Training loss: 2.0419707039460495
Validation loss: 2.5729651212187883

Epoch: 5| Step: 1
Training loss: 2.221642019769965
Validation loss: 2.613400383412568

Epoch: 5| Step: 2
Training loss: 2.3103545262814915
Validation loss: 2.5749766347836385

Epoch: 5| Step: 3
Training loss: 2.388907420162903
Validation loss: 2.5719798325763668

Epoch: 5| Step: 4
Training loss: 2.1087950863000935
Validation loss: 2.6764509634362805

Epoch: 5| Step: 5
Training loss: 2.814727070994965
Validation loss: 2.584310480453124

Epoch: 5| Step: 6
Training loss: 2.038849099637472
Validation loss: 2.613373194990193

Epoch: 5| Step: 7
Training loss: 2.9286904227774335
Validation loss: 2.591481333149381

Epoch: 5| Step: 8
Training loss: 2.7690207114390493
Validation loss: 2.546694381432382

Epoch: 5| Step: 9
Training loss: 2.161783829658247
Validation loss: 2.561904827103466

Epoch: 5| Step: 10
Training loss: 2.8585467363626798
Validation loss: 2.577977691051526

Epoch: 379| Step: 0
Training loss: 2.744128635149518
Validation loss: 2.5092761632159077

Epoch: 5| Step: 1
Training loss: 2.8272454174320676
Validation loss: 2.528202804856194

Epoch: 5| Step: 2
Training loss: 1.7170275293452755
Validation loss: 2.579286215237367

Epoch: 5| Step: 3
Training loss: 2.4939706575675875
Validation loss: 2.548990880220306

Epoch: 5| Step: 4
Training loss: 2.620442930738862
Validation loss: 2.572263775222635

Epoch: 5| Step: 5
Training loss: 2.793223293416107
Validation loss: 2.4722189010475524

Epoch: 5| Step: 6
Training loss: 1.8536120310273165
Validation loss: 2.582726860573287

Epoch: 5| Step: 7
Training loss: 2.5875956126068704
Validation loss: 2.6036914895620464

Epoch: 5| Step: 8
Training loss: 2.5184474299512347
Validation loss: 2.5594814889350057

Epoch: 5| Step: 9
Training loss: 1.9198316550958527
Validation loss: 2.5254755710033403

Epoch: 5| Step: 10
Training loss: 1.7774344955585808
Validation loss: 2.588168413294815

Epoch: 380| Step: 0
Training loss: 3.111246283940096
Validation loss: 2.5161222978937747

Epoch: 5| Step: 1
Training loss: 2.8964828933640008
Validation loss: 2.5468596113152624

Epoch: 5| Step: 2
Training loss: 2.1801991289518314
Validation loss: 2.578515186285512

Epoch: 5| Step: 3
Training loss: 2.615779304282641
Validation loss: 2.6112532330073885

Epoch: 5| Step: 4
Training loss: 1.9695650865734353
Validation loss: 2.5549810493713156

Epoch: 5| Step: 5
Training loss: 2.226359896895138
Validation loss: 2.591264902414161

Epoch: 5| Step: 6
Training loss: 2.3315556998179905
Validation loss: 2.6158476572266864

Epoch: 5| Step: 7
Training loss: 2.1432186480264424
Validation loss: 2.5396161380575717

Epoch: 5| Step: 8
Training loss: 2.4029338825160997
Validation loss: 2.595541878577386

Epoch: 5| Step: 9
Training loss: 2.2762661145984215
Validation loss: 2.600919314440656

Epoch: 5| Step: 10
Training loss: 1.9733620768893698
Validation loss: 2.561889446643415

Epoch: 381| Step: 0
Training loss: 2.4952029935710596
Validation loss: 2.6112832041994563

Epoch: 5| Step: 1
Training loss: 2.471578981057845
Validation loss: 2.5731598684861163

Epoch: 5| Step: 2
Training loss: 3.3022978960639127
Validation loss: 2.612936519943413

Epoch: 5| Step: 3
Training loss: 2.2882213935043345
Validation loss: 2.604187435600565

Epoch: 5| Step: 4
Training loss: 2.5273631830662273
Validation loss: 2.5457704142926625

Epoch: 5| Step: 5
Training loss: 2.1621899818067645
Validation loss: 2.5749809571671225

Epoch: 5| Step: 6
Training loss: 2.5566231863244546
Validation loss: 2.553991739747227

Epoch: 5| Step: 7
Training loss: 1.8615072510419515
Validation loss: 2.5167970173612724

Epoch: 5| Step: 8
Training loss: 2.5614380845899327
Validation loss: 2.608662918368305

Epoch: 5| Step: 9
Training loss: 1.882716259534616
Validation loss: 2.6096589428442694

Epoch: 5| Step: 10
Training loss: 2.31340060868221
Validation loss: 2.526534694455438

Epoch: 382| Step: 0
Training loss: 3.1356319383160853
Validation loss: 2.5747319819247045

Epoch: 5| Step: 1
Training loss: 2.6804135954254344
Validation loss: 2.5743921765399973

Epoch: 5| Step: 2
Training loss: 2.4678466689396417
Validation loss: 2.5429636952359878

Epoch: 5| Step: 3
Training loss: 2.4316812167169215
Validation loss: 2.6333364249782814

Epoch: 5| Step: 4
Training loss: 1.8765753803557557
Validation loss: 2.556773779118812

Epoch: 5| Step: 5
Training loss: 2.573183908110199
Validation loss: 2.5232821958080787

Epoch: 5| Step: 6
Training loss: 2.345847450155149
Validation loss: 2.547291721395418

Epoch: 5| Step: 7
Training loss: 1.9706338013931242
Validation loss: 2.5284136102028416

Epoch: 5| Step: 8
Training loss: 2.614180109510149
Validation loss: 2.5739649556457747

Epoch: 5| Step: 9
Training loss: 2.5889151679175555
Validation loss: 2.538051260601712

Epoch: 5| Step: 10
Training loss: 2.3159643462538226
Validation loss: 2.640358084396853

Epoch: 383| Step: 0
Training loss: 2.52809624767575
Validation loss: 2.5822631568961216

Epoch: 5| Step: 1
Training loss: 2.7711787952572102
Validation loss: 2.5779009421179677

Epoch: 5| Step: 2
Training loss: 2.3598483791784552
Validation loss: 2.593720628789799

Epoch: 5| Step: 3
Training loss: 2.3145468648606426
Validation loss: 2.595791454771072

Epoch: 5| Step: 4
Training loss: 1.9624382446680309
Validation loss: 2.613807496602281

Epoch: 5| Step: 5
Training loss: 2.4442290321957585
Validation loss: 2.515312901563592

Epoch: 5| Step: 6
Training loss: 2.2740954728361724
Validation loss: 2.5944565651875533

Epoch: 5| Step: 7
Training loss: 2.4674209687196553
Validation loss: 2.6533435901114424

Epoch: 5| Step: 8
Training loss: 2.2606637236653713
Validation loss: 2.620099371423131

Epoch: 5| Step: 9
Training loss: 2.5721670029024772
Validation loss: 2.5498325708344973

Epoch: 5| Step: 10
Training loss: 3.034443696773621
Validation loss: 2.476638990997374

Epoch: 384| Step: 0
Training loss: 2.614598055085053
Validation loss: 2.5645409286689387

Epoch: 5| Step: 1
Training loss: 2.1501522365166967
Validation loss: 2.547552768863131

Epoch: 5| Step: 2
Training loss: 2.969732824567962
Validation loss: 2.602696949992209

Epoch: 5| Step: 3
Training loss: 2.5061624868434658
Validation loss: 2.6043986975553453

Epoch: 5| Step: 4
Training loss: 2.3034255888810393
Validation loss: 2.554282993407856

Epoch: 5| Step: 5
Training loss: 2.3545442351541945
Validation loss: 2.5889185713612766

Epoch: 5| Step: 6
Training loss: 2.1027720774488343
Validation loss: 2.58681195344033

Epoch: 5| Step: 7
Training loss: 2.521654000696955
Validation loss: 2.5597409287119555

Epoch: 5| Step: 8
Training loss: 2.0388806726057425
Validation loss: 2.578662532132845

Epoch: 5| Step: 9
Training loss: 2.10811775321631
Validation loss: 2.582706495608928

Epoch: 5| Step: 10
Training loss: 2.589205517959785
Validation loss: 2.564851637726162

Epoch: 385| Step: 0
Training loss: 2.3884109516757106
Validation loss: 2.6075387287367633

Epoch: 5| Step: 1
Training loss: 2.2425762198432944
Validation loss: 2.616332146117157

Epoch: 5| Step: 2
Training loss: 2.2108734445088163
Validation loss: 2.633592480013342

Epoch: 5| Step: 3
Training loss: 1.8580203210399011
Validation loss: 2.587258476679114

Epoch: 5| Step: 4
Training loss: 2.55299662123687
Validation loss: 2.5634726482464996

Epoch: 5| Step: 5
Training loss: 3.1976934763076352
Validation loss: 2.597167548742826

Epoch: 5| Step: 6
Training loss: 2.330064413792957
Validation loss: 2.56470855532198

Epoch: 5| Step: 7
Training loss: 2.1175059399301928
Validation loss: 2.5666969918658444

Epoch: 5| Step: 8
Training loss: 2.247820116102049
Validation loss: 2.605776317311408

Epoch: 5| Step: 9
Training loss: 2.9827819087286724
Validation loss: 2.5305633626417707

Epoch: 5| Step: 10
Training loss: 2.463829642004856
Validation loss: 2.625745184114745

Epoch: 386| Step: 0
Training loss: 2.6296604202698566
Validation loss: 2.570186185620818

Epoch: 5| Step: 1
Training loss: 2.052502997485631
Validation loss: 2.6100605592218904

Epoch: 5| Step: 2
Training loss: 1.6593499593048684
Validation loss: 2.5815447428604745

Epoch: 5| Step: 3
Training loss: 2.804703651317962
Validation loss: 2.60843196100441

Epoch: 5| Step: 4
Training loss: 1.8512424884569054
Validation loss: 2.5399092687982368

Epoch: 5| Step: 5
Training loss: 2.518821154931125
Validation loss: 2.6381629844243566

Epoch: 5| Step: 6
Training loss: 2.5171091191823796
Validation loss: 2.5865467487600204

Epoch: 5| Step: 7
Training loss: 3.1453545481812775
Validation loss: 2.6093856381965854

Epoch: 5| Step: 8
Training loss: 2.533095922973817
Validation loss: 2.5807464268899425

Epoch: 5| Step: 9
Training loss: 2.4032798369966306
Validation loss: 2.5795205424582686

Epoch: 5| Step: 10
Training loss: 2.4745487726584376
Validation loss: 2.6562000759772775

Epoch: 387| Step: 0
Training loss: 2.50839625899593
Validation loss: 2.626979588316874

Epoch: 5| Step: 1
Training loss: 3.065518818143129
Validation loss: 2.611349442376783

Epoch: 5| Step: 2
Training loss: 2.240404968950087
Validation loss: 2.6457774807440946

Epoch: 5| Step: 3
Training loss: 2.3452597269707
Validation loss: 2.666617967144244

Epoch: 5| Step: 4
Training loss: 2.0533211810301477
Validation loss: 2.474176817455561

Epoch: 5| Step: 5
Training loss: 1.948573493035513
Validation loss: 2.572053093222023

Epoch: 5| Step: 6
Training loss: 2.1970554369954347
Validation loss: 2.6055899093132426

Epoch: 5| Step: 7
Training loss: 2.417566614189857
Validation loss: 2.6298235856837184

Epoch: 5| Step: 8
Training loss: 2.8816095752550623
Validation loss: 2.494054543905981

Epoch: 5| Step: 9
Training loss: 2.26064315809699
Validation loss: 2.611015606259909

Epoch: 5| Step: 10
Training loss: 2.5858976701048917
Validation loss: 2.5453813537689203

Epoch: 388| Step: 0
Training loss: 2.0193430593379587
Validation loss: 2.6143433349954504

Epoch: 5| Step: 1
Training loss: 2.1484279562998254
Validation loss: 2.565746659703597

Epoch: 5| Step: 2
Training loss: 2.8514875846323617
Validation loss: 2.5625229706173607

Epoch: 5| Step: 3
Training loss: 2.7202441615022823
Validation loss: 2.5501980251654666

Epoch: 5| Step: 4
Training loss: 3.0251954953414466
Validation loss: 2.599296892194452

Epoch: 5| Step: 5
Training loss: 2.3452992722902604
Validation loss: 2.561838259667259

Epoch: 5| Step: 6
Training loss: 2.527786805645631
Validation loss: 2.5959889681318287

Epoch: 5| Step: 7
Training loss: 1.640628342398009
Validation loss: 2.673243162458106

Epoch: 5| Step: 8
Training loss: 2.3178404923952933
Validation loss: 2.637088897987845

Epoch: 5| Step: 9
Training loss: 2.1521606367419586
Validation loss: 2.6402841886757966

Epoch: 5| Step: 10
Training loss: 2.5788081333340416
Validation loss: 2.5289702171229878

Epoch: 389| Step: 0
Training loss: 2.6326562852105
Validation loss: 2.5809843463416575

Epoch: 5| Step: 1
Training loss: 2.3965304369490883
Validation loss: 2.500779965463383

Epoch: 5| Step: 2
Training loss: 2.6162727237594883
Validation loss: 2.607790579833629

Epoch: 5| Step: 3
Training loss: 2.4522128018857625
Validation loss: 2.651167183731265

Epoch: 5| Step: 4
Training loss: 1.7644959612416684
Validation loss: 2.547926456667817

Epoch: 5| Step: 5
Training loss: 2.5365447252249282
Validation loss: 2.578731440929077

Epoch: 5| Step: 6
Training loss: 2.4931562209164775
Validation loss: 2.5573549719968196

Epoch: 5| Step: 7
Training loss: 1.8149798299125812
Validation loss: 2.585455972785335

Epoch: 5| Step: 8
Training loss: 2.911837876659051
Validation loss: 2.6101671214809032

Epoch: 5| Step: 9
Training loss: 1.7466277600946842
Validation loss: 2.5900851492790484

Epoch: 5| Step: 10
Training loss: 2.7390800758402873
Validation loss: 2.5180132319102153

Epoch: 390| Step: 0
Training loss: 2.350312569304644
Validation loss: 2.5945405779458492

Epoch: 5| Step: 1
Training loss: 2.403698050998406
Validation loss: 2.5844965851928827

Epoch: 5| Step: 2
Training loss: 2.235476135809097
Validation loss: 2.6172333665727563

Epoch: 5| Step: 3
Training loss: 2.0416096530142
Validation loss: 2.6496984478568124

Epoch: 5| Step: 4
Training loss: 2.530375482642922
Validation loss: 2.571774814277016

Epoch: 5| Step: 5
Training loss: 2.4867498215517765
Validation loss: 2.541089760196695

Epoch: 5| Step: 6
Training loss: 2.8610328079257226
Validation loss: 2.541439726764493

Epoch: 5| Step: 7
Training loss: 2.2417555336431376
Validation loss: 2.6768420052272486

Epoch: 5| Step: 8
Training loss: 2.7622141521888723
Validation loss: 2.5700889959256603

Epoch: 5| Step: 9
Training loss: 2.3381260854498804
Validation loss: 2.5572805464361417

Epoch: 5| Step: 10
Training loss: 2.0863368191490586
Validation loss: 2.5477714835552616

Epoch: 391| Step: 0
Training loss: 2.1026969031847167
Validation loss: 2.561975691105169

Epoch: 5| Step: 1
Training loss: 1.9550905027197778
Validation loss: 2.5374079020923723

Epoch: 5| Step: 2
Training loss: 2.4482426744178314
Validation loss: 2.6348160008892774

Epoch: 5| Step: 3
Training loss: 2.2722935895689282
Validation loss: 2.5774977123805387

Epoch: 5| Step: 4
Training loss: 2.749320206283671
Validation loss: 2.602570262902686

Epoch: 5| Step: 5
Training loss: 2.57775164125975
Validation loss: 2.5713023847195555

Epoch: 5| Step: 6
Training loss: 2.4751771728602256
Validation loss: 2.5092984752673853

Epoch: 5| Step: 7
Training loss: 2.8823175599856383
Validation loss: 2.6049278019837923

Epoch: 5| Step: 8
Training loss: 2.080329127681478
Validation loss: 2.578649636165559

Epoch: 5| Step: 9
Training loss: 2.1546995697900595
Validation loss: 2.543846122800309

Epoch: 5| Step: 10
Training loss: 2.582208993769889
Validation loss: 2.588581340336628

Epoch: 392| Step: 0
Training loss: 1.9612921891740933
Validation loss: 2.5752936225183896

Epoch: 5| Step: 1
Training loss: 2.6186502041613253
Validation loss: 2.551435012957648

Epoch: 5| Step: 2
Training loss: 2.84301211666567
Validation loss: 2.585246933089105

Epoch: 5| Step: 3
Training loss: 2.2605759759364332
Validation loss: 2.5657289072257465

Epoch: 5| Step: 4
Training loss: 2.228522899993603
Validation loss: 2.5203757725496687

Epoch: 5| Step: 5
Training loss: 2.319574309296617
Validation loss: 2.5200972265817247

Epoch: 5| Step: 6
Training loss: 2.4968634002377907
Validation loss: 2.6325202994696593

Epoch: 5| Step: 7
Training loss: 2.000312065573813
Validation loss: 2.562440524847943

Epoch: 5| Step: 8
Training loss: 2.184960116932446
Validation loss: 2.667262907308061

Epoch: 5| Step: 9
Training loss: 2.696773409559981
Validation loss: 2.5089849006670533

Epoch: 5| Step: 10
Training loss: 2.6235896363486524
Validation loss: 2.544214639473365

Epoch: 393| Step: 0
Training loss: 2.355188457456324
Validation loss: 2.5119260919499697

Epoch: 5| Step: 1
Training loss: 2.882539400226797
Validation loss: 2.581733115372551

Epoch: 5| Step: 2
Training loss: 1.3480603925126156
Validation loss: 2.5765358261490507

Epoch: 5| Step: 3
Training loss: 2.3918348255476665
Validation loss: 2.614515127101208

Epoch: 5| Step: 4
Training loss: 2.664288284712523
Validation loss: 2.5317378676024704

Epoch: 5| Step: 5
Training loss: 3.09340920160693
Validation loss: 2.613013666345359

Epoch: 5| Step: 6
Training loss: 2.0032693843610647
Validation loss: 2.627582898556903

Epoch: 5| Step: 7
Training loss: 1.8027116271926105
Validation loss: 2.554853197318555

Epoch: 5| Step: 8
Training loss: 2.6560156326121147
Validation loss: 2.617435225772944

Epoch: 5| Step: 9
Training loss: 2.5876392861439
Validation loss: 2.57073570168857

Epoch: 5| Step: 10
Training loss: 2.615448878111536
Validation loss: 2.5297464513198973

Epoch: 394| Step: 0
Training loss: 2.579636749008654
Validation loss: 2.571112228970628

Epoch: 5| Step: 1
Training loss: 2.426782766785682
Validation loss: 2.651300237618602

Epoch: 5| Step: 2
Training loss: 2.5811936120623846
Validation loss: 2.541042767397309

Epoch: 5| Step: 3
Training loss: 2.9386391561447036
Validation loss: 2.6213848032558484

Epoch: 5| Step: 4
Training loss: 2.0303377890835708
Validation loss: 2.5955427339334265

Epoch: 5| Step: 5
Training loss: 2.5743407248048804
Validation loss: 2.535467732936876

Epoch: 5| Step: 6
Training loss: 2.067727025585739
Validation loss: 2.570634323256433

Epoch: 5| Step: 7
Training loss: 2.307527918951518
Validation loss: 2.551801425280196

Epoch: 5| Step: 8
Training loss: 2.3830974471017363
Validation loss: 2.59625636810061

Epoch: 5| Step: 9
Training loss: 2.3508579554773306
Validation loss: 2.5902027099198466

Epoch: 5| Step: 10
Training loss: 1.7624581893398614
Validation loss: 2.5833653505255216

Epoch: 395| Step: 0
Training loss: 2.717831949912483
Validation loss: 2.529674158509128

Epoch: 5| Step: 1
Training loss: 2.637141350682402
Validation loss: 2.6220608159253023

Epoch: 5| Step: 2
Training loss: 1.7750520456769883
Validation loss: 2.620698205925905

Epoch: 5| Step: 3
Training loss: 2.6508252568278294
Validation loss: 2.5700604266272196

Epoch: 5| Step: 4
Training loss: 2.434202457919254
Validation loss: 2.66991240363819

Epoch: 5| Step: 5
Training loss: 2.614283712983389
Validation loss: 2.516900104936012

Epoch: 5| Step: 6
Training loss: 2.8426825228076513
Validation loss: 2.525874090815436

Epoch: 5| Step: 7
Training loss: 2.5254800283563337
Validation loss: 2.549166612407258

Epoch: 5| Step: 8
Training loss: 2.1959736870264517
Validation loss: 2.551579283276476

Epoch: 5| Step: 9
Training loss: 2.161378704274148
Validation loss: 2.608907548537296

Epoch: 5| Step: 10
Training loss: 2.209840320324753
Validation loss: 2.5301300563050364

Epoch: 396| Step: 0
Training loss: 2.134428090095694
Validation loss: 2.594997157071734

Epoch: 5| Step: 1
Training loss: 2.920074560964044
Validation loss: 2.5655611663751654

Epoch: 5| Step: 2
Training loss: 2.797491676924991
Validation loss: 2.5413656582676523

Epoch: 5| Step: 3
Training loss: 2.5980854798395256
Validation loss: 2.641183351291457

Epoch: 5| Step: 4
Training loss: 2.7702055676472686
Validation loss: 2.560107136616841

Epoch: 5| Step: 5
Training loss: 1.848218384732268
Validation loss: 2.5442061440854573

Epoch: 5| Step: 6
Training loss: 2.336131518417573
Validation loss: 2.535637211807965

Epoch: 5| Step: 7
Training loss: 1.9774391130219986
Validation loss: 2.579210868959099

Epoch: 5| Step: 8
Training loss: 2.5045717399437577
Validation loss: 2.58032929723561

Epoch: 5| Step: 9
Training loss: 2.1892590670718595
Validation loss: 2.5468464048345463

Epoch: 5| Step: 10
Training loss: 2.3553554830314964
Validation loss: 2.584778005313471

Epoch: 397| Step: 0
Training loss: 2.3043939953138284
Validation loss: 2.5782870254490646

Epoch: 5| Step: 1
Training loss: 2.355843635953063
Validation loss: 2.6059834298687665

Epoch: 5| Step: 2
Training loss: 1.7385419671492852
Validation loss: 2.5496228104594496

Epoch: 5| Step: 3
Training loss: 2.6307413801142463
Validation loss: 2.5996821390631113

Epoch: 5| Step: 4
Training loss: 1.9781946974493805
Validation loss: 2.5904071475744077

Epoch: 5| Step: 5
Training loss: 2.794927760983713
Validation loss: 2.6063092944620023

Epoch: 5| Step: 6
Training loss: 1.9716846452776327
Validation loss: 2.4781838996865475

Epoch: 5| Step: 7
Training loss: 2.533429279099957
Validation loss: 2.5659104359304874

Epoch: 5| Step: 8
Training loss: 2.965649883459308
Validation loss: 2.550294576620921

Epoch: 5| Step: 9
Training loss: 2.103951496667542
Validation loss: 2.5681426327821932

Epoch: 5| Step: 10
Training loss: 2.788948377309994
Validation loss: 2.5908461583524014

Epoch: 398| Step: 0
Training loss: 2.9141840768769804
Validation loss: 2.5785643500599744

Epoch: 5| Step: 1
Training loss: 2.616316465361908
Validation loss: 2.561393905252599

Epoch: 5| Step: 2
Training loss: 2.8607612959780337
Validation loss: 2.582572111008411

Epoch: 5| Step: 3
Training loss: 2.3263037809932783
Validation loss: 2.6093523077211103

Epoch: 5| Step: 4
Training loss: 1.8749682741659999
Validation loss: 2.524301074669784

Epoch: 5| Step: 5
Training loss: 2.4395713808031303
Validation loss: 2.5739701019154984

Epoch: 5| Step: 6
Training loss: 2.081312445542879
Validation loss: 2.548249472285545

Epoch: 5| Step: 7
Training loss: 2.2597406199661823
Validation loss: 2.596505949668238

Epoch: 5| Step: 8
Training loss: 2.8211378754867873
Validation loss: 2.5313273764547137

Epoch: 5| Step: 9
Training loss: 2.132647609275358
Validation loss: 2.4820753389622427

Epoch: 5| Step: 10
Training loss: 2.234072257919868
Validation loss: 2.613405924848426

Epoch: 399| Step: 0
Training loss: 2.310793891659099
Validation loss: 2.5841872669249173

Epoch: 5| Step: 1
Training loss: 3.0697083012177933
Validation loss: 2.5174271539651283

Epoch: 5| Step: 2
Training loss: 2.476560093249767
Validation loss: 2.571109472004177

Epoch: 5| Step: 3
Training loss: 2.172729104695322
Validation loss: 2.605442216284247

Epoch: 5| Step: 4
Training loss: 2.5087871618326782
Validation loss: 2.6155248692905353

Epoch: 5| Step: 5
Training loss: 2.079498410817975
Validation loss: 2.587519199481816

Epoch: 5| Step: 6
Training loss: 2.492305071218947
Validation loss: 2.542847850275746

Epoch: 5| Step: 7
Training loss: 2.33612906904824
Validation loss: 2.5811050409692817

Epoch: 5| Step: 8
Training loss: 2.561176981967272
Validation loss: 2.5556702487405536

Epoch: 5| Step: 9
Training loss: 2.4859531596306157
Validation loss: 2.5882888273981

Epoch: 5| Step: 10
Training loss: 1.5786286862745869
Validation loss: 2.5734418887846537

Epoch: 400| Step: 0
Training loss: 2.418910913757989
Validation loss: 2.536018596418984

Epoch: 5| Step: 1
Training loss: 1.827044828118642
Validation loss: 2.571704276117214

Epoch: 5| Step: 2
Training loss: 2.8575159919137754
Validation loss: 2.4851099703163397

Epoch: 5| Step: 3
Training loss: 2.735393487077186
Validation loss: 2.5814858350873204

Epoch: 5| Step: 4
Training loss: 2.2298480504702636
Validation loss: 2.6303105845638806

Epoch: 5| Step: 5
Training loss: 2.286810173706783
Validation loss: 2.5981535848816915

Epoch: 5| Step: 6
Training loss: 2.328668825267392
Validation loss: 2.577247392198694

Epoch: 5| Step: 7
Training loss: 3.0334469414140925
Validation loss: 2.5747601528909287

Epoch: 5| Step: 8
Training loss: 2.006779505175234
Validation loss: 2.6066494956569675

Epoch: 5| Step: 9
Training loss: 2.24872637835443
Validation loss: 2.5704444940879263

Epoch: 5| Step: 10
Training loss: 2.113041382889418
Validation loss: 2.5989660385056745

Epoch: 401| Step: 0
Training loss: 2.035701627381247
Validation loss: 2.5611906310476766

Epoch: 5| Step: 1
Training loss: 2.0624549167214057
Validation loss: 2.518905277239987

Epoch: 5| Step: 2
Training loss: 2.920359825538647
Validation loss: 2.6237405254682646

Epoch: 5| Step: 3
Training loss: 1.873983998005392
Validation loss: 2.583311194134127

Epoch: 5| Step: 4
Training loss: 2.3140367093088234
Validation loss: 2.5958490320433927

Epoch: 5| Step: 5
Training loss: 2.6103905626003066
Validation loss: 2.560840134627769

Epoch: 5| Step: 6
Training loss: 1.7940269123555141
Validation loss: 2.5065074539753036

Epoch: 5| Step: 7
Training loss: 3.2893905657255536
Validation loss: 2.49994619937145

Epoch: 5| Step: 8
Training loss: 2.362581209270477
Validation loss: 2.6014959998209184

Epoch: 5| Step: 9
Training loss: 2.4987393061536425
Validation loss: 2.616709311347914

Epoch: 5| Step: 10
Training loss: 2.443751607830953
Validation loss: 2.5371280502026976

Epoch: 402| Step: 0
Training loss: 2.2711218087818863
Validation loss: 2.483806617064646

Epoch: 5| Step: 1
Training loss: 2.1397745712479335
Validation loss: 2.5233573119835784

Epoch: 5| Step: 2
Training loss: 2.552569523386662
Validation loss: 2.57139985556324

Epoch: 5| Step: 3
Training loss: 2.941857048840577
Validation loss: 2.5664315146204406

Epoch: 5| Step: 4
Training loss: 1.9775278500839542
Validation loss: 2.6595395859233206

Epoch: 5| Step: 5
Training loss: 2.145700160464967
Validation loss: 2.5644318416569405

Epoch: 5| Step: 6
Training loss: 2.3993386430263817
Validation loss: 2.5227242170337547

Epoch: 5| Step: 7
Training loss: 2.9994210638287595
Validation loss: 2.6168174407338305

Epoch: 5| Step: 8
Training loss: 2.190014837728602
Validation loss: 2.6094378893075265

Epoch: 5| Step: 9
Training loss: 2.750205465790682
Validation loss: 2.603101859340519

Epoch: 5| Step: 10
Training loss: 2.056841747162351
Validation loss: 2.5297923112287797

Epoch: 403| Step: 0
Training loss: 2.1828553072009362
Validation loss: 2.607281088453097

Epoch: 5| Step: 1
Training loss: 1.9313401161081767
Validation loss: 2.5589383582482146

Epoch: 5| Step: 2
Training loss: 1.9998007913561398
Validation loss: 2.649527521902731

Epoch: 5| Step: 3
Training loss: 2.0781837397713416
Validation loss: 2.5474586494989024

Epoch: 5| Step: 4
Training loss: 2.547680873570536
Validation loss: 2.559260949654989

Epoch: 5| Step: 5
Training loss: 2.235778154603896
Validation loss: 2.5707001189195897

Epoch: 5| Step: 6
Training loss: 2.601762643624465
Validation loss: 2.553970212634229

Epoch: 5| Step: 7
Training loss: 2.855329476233291
Validation loss: 2.629215402890715

Epoch: 5| Step: 8
Training loss: 1.7805172266267393
Validation loss: 2.6039645382772467

Epoch: 5| Step: 9
Training loss: 2.7166829637221968
Validation loss: 2.602114433283281

Epoch: 5| Step: 10
Training loss: 2.8123886086339707
Validation loss: 2.61876268120676

Epoch: 404| Step: 0
Training loss: 2.334405811520115
Validation loss: 2.667238601627659

Epoch: 5| Step: 1
Training loss: 3.5076515483676003
Validation loss: 2.569305387187566

Epoch: 5| Step: 2
Training loss: 2.106094408938686
Validation loss: 2.6059437401040917

Epoch: 5| Step: 3
Training loss: 2.767383081297626
Validation loss: 2.656346590914703

Epoch: 5| Step: 4
Training loss: 2.478797553871601
Validation loss: 2.515151825015061

Epoch: 5| Step: 5
Training loss: 2.135115501442086
Validation loss: 2.612570535286854

Epoch: 5| Step: 6
Training loss: 2.5924951666232365
Validation loss: 2.570473359317595

Epoch: 5| Step: 7
Training loss: 2.00336138064046
Validation loss: 2.573211508218927

Epoch: 5| Step: 8
Training loss: 2.4572224019567748
Validation loss: 2.484703129491647

Epoch: 5| Step: 9
Training loss: 1.9901286537908864
Validation loss: 2.52974995260844

Epoch: 5| Step: 10
Training loss: 1.8349993967164422
Validation loss: 2.6350921900630206

Epoch: 405| Step: 0
Training loss: 1.807631300382171
Validation loss: 2.642995295879111

Epoch: 5| Step: 1
Training loss: 2.920976633283378
Validation loss: 2.670245365591691

Epoch: 5| Step: 2
Training loss: 2.9562816400427594
Validation loss: 2.615174900250392

Epoch: 5| Step: 3
Training loss: 1.9113215536990424
Validation loss: 2.559058176220572

Epoch: 5| Step: 4
Training loss: 2.9735646608056445
Validation loss: 2.5324147192103097

Epoch: 5| Step: 5
Training loss: 2.473023494308062
Validation loss: 2.6195955715419657

Epoch: 5| Step: 6
Training loss: 1.9867123632594637
Validation loss: 2.606022341876841

Epoch: 5| Step: 7
Training loss: 2.2211725683245747
Validation loss: 2.606878011284995

Epoch: 5| Step: 8
Training loss: 2.077419304594537
Validation loss: 2.5224061549437886

Epoch: 5| Step: 9
Training loss: 2.2850554615193124
Validation loss: 2.604448906811391

Epoch: 5| Step: 10
Training loss: 2.5634553570551497
Validation loss: 2.6304218262041568

Epoch: 406| Step: 0
Training loss: 1.7089926060069642
Validation loss: 2.5567585542930473

Epoch: 5| Step: 1
Training loss: 2.048424636486177
Validation loss: 2.609750832739486

Epoch: 5| Step: 2
Training loss: 2.941204575797041
Validation loss: 2.588867158535019

Epoch: 5| Step: 3
Training loss: 2.258669997267236
Validation loss: 2.5617024030530597

Epoch: 5| Step: 4
Training loss: 2.3879645010579593
Validation loss: 2.5838626818065555

Epoch: 5| Step: 5
Training loss: 3.0165446564112948
Validation loss: 2.481439931984525

Epoch: 5| Step: 6
Training loss: 2.482704608702426
Validation loss: 2.608389084769346

Epoch: 5| Step: 7
Training loss: 2.2843085909478122
Validation loss: 2.567386206543427

Epoch: 5| Step: 8
Training loss: 2.421018190488109
Validation loss: 2.591992799689662

Epoch: 5| Step: 9
Training loss: 2.0462596638147788
Validation loss: 2.520287228725183

Epoch: 5| Step: 10
Training loss: 1.7202480376844576
Validation loss: 2.503816982457817

Epoch: 407| Step: 0
Training loss: 2.0040345030077713
Validation loss: 2.4840227154500987

Epoch: 5| Step: 1
Training loss: 2.2197552405139866
Validation loss: 2.6156540368786483

Epoch: 5| Step: 2
Training loss: 2.9582923205760943
Validation loss: 2.61835699887527

Epoch: 5| Step: 3
Training loss: 2.1217679520628834
Validation loss: 2.5908441654999086

Epoch: 5| Step: 4
Training loss: 3.1375752534998282
Validation loss: 2.530701075781335

Epoch: 5| Step: 5
Training loss: 1.9213991894250635
Validation loss: 2.5672963991821787

Epoch: 5| Step: 6
Training loss: 2.172781775564696
Validation loss: 2.5565266612894813

Epoch: 5| Step: 7
Training loss: 1.83409656185591
Validation loss: 2.609441510613427

Epoch: 5| Step: 8
Training loss: 2.0416730634109044
Validation loss: 2.548866401874972

Epoch: 5| Step: 9
Training loss: 2.854599764372985
Validation loss: 2.5969437685403447

Epoch: 5| Step: 10
Training loss: 2.6558659893031513
Validation loss: 2.597309175654956

Epoch: 408| Step: 0
Training loss: 2.378142035244094
Validation loss: 2.575805834099383

Epoch: 5| Step: 1
Training loss: 2.5369038487589357
Validation loss: 2.53697935208835

Epoch: 5| Step: 2
Training loss: 1.9230845917035304
Validation loss: 2.4654999608922634

Epoch: 5| Step: 3
Training loss: 1.729380314815007
Validation loss: 2.607045748801154

Epoch: 5| Step: 4
Training loss: 2.0258393043588034
Validation loss: 2.6297784958269967

Epoch: 5| Step: 5
Training loss: 2.1334120358413777
Validation loss: 2.5634167409734667

Epoch: 5| Step: 6
Training loss: 2.587651079715262
Validation loss: 2.552310977315091

Epoch: 5| Step: 7
Training loss: 2.899009463076034
Validation loss: 2.5497343378583035

Epoch: 5| Step: 8
Training loss: 2.565235724520688
Validation loss: 2.5855020472995536

Epoch: 5| Step: 9
Training loss: 3.000627769909124
Validation loss: 2.483038456795548

Epoch: 5| Step: 10
Training loss: 1.959425506670929
Validation loss: 2.610418667924392

Epoch: 409| Step: 0
Training loss: 2.4436930696143992
Validation loss: 2.5008447327440666

Epoch: 5| Step: 1
Training loss: 2.394953580020218
Validation loss: 2.576340310145007

Epoch: 5| Step: 2
Training loss: 2.396171369063455
Validation loss: 2.5290660189472023

Epoch: 5| Step: 3
Training loss: 2.0171320995520987
Validation loss: 2.5288544924623557

Epoch: 5| Step: 4
Training loss: 2.8189983317737983
Validation loss: 2.500290790176431

Epoch: 5| Step: 5
Training loss: 1.9925930433195336
Validation loss: 2.6216647009806358

Epoch: 5| Step: 6
Training loss: 2.3418751656598658
Validation loss: 2.5939469685829852

Epoch: 5| Step: 7
Training loss: 2.9678200319228125
Validation loss: 2.571579585285703

Epoch: 5| Step: 8
Training loss: 2.410003113170845
Validation loss: 2.504712639542274

Epoch: 5| Step: 9
Training loss: 1.984445765878015
Validation loss: 2.503104425611798

Epoch: 5| Step: 10
Training loss: 2.3933579524730044
Validation loss: 2.5861635599122814

Epoch: 410| Step: 0
Training loss: 1.8519783036009538
Validation loss: 2.6248625842885356

Epoch: 5| Step: 1
Training loss: 2.1564171767733633
Validation loss: 2.5692451635534233

Epoch: 5| Step: 2
Training loss: 2.1868373412111115
Validation loss: 2.5865361038501247

Epoch: 5| Step: 3
Training loss: 2.1555470965679366
Validation loss: 2.577983272829584

Epoch: 5| Step: 4
Training loss: 2.756518614259308
Validation loss: 2.5403694094801392

Epoch: 5| Step: 5
Training loss: 2.6755536727469162
Validation loss: 2.5759431080206032

Epoch: 5| Step: 6
Training loss: 2.699148086086608
Validation loss: 2.590565596342682

Epoch: 5| Step: 7
Training loss: 2.2905474848726763
Validation loss: 2.555125680834491

Epoch: 5| Step: 8
Training loss: 2.463671131778071
Validation loss: 2.516462729354692

Epoch: 5| Step: 9
Training loss: 2.81719062453788
Validation loss: 2.539849794056574

Epoch: 5| Step: 10
Training loss: 1.8937677162273368
Validation loss: 2.5283075121118737

Epoch: 411| Step: 0
Training loss: 2.4571339111228636
Validation loss: 2.588402459362186

Epoch: 5| Step: 1
Training loss: 2.8140178399405036
Validation loss: 2.5155523074768174

Epoch: 5| Step: 2
Training loss: 2.7140181129880014
Validation loss: 2.57687049988474

Epoch: 5| Step: 3
Training loss: 2.22405779316136
Validation loss: 2.474960763081012

Epoch: 5| Step: 4
Training loss: 2.2677776764720092
Validation loss: 2.512973818922871

Epoch: 5| Step: 5
Training loss: 2.1600090100842215
Validation loss: 2.5286316591436706

Epoch: 5| Step: 6
Training loss: 2.561725499410949
Validation loss: 2.6289878200769246

Epoch: 5| Step: 7
Training loss: 2.2395874259970476
Validation loss: 2.5750025022713388

Epoch: 5| Step: 8
Training loss: 1.7803914192683707
Validation loss: 2.662401042537585

Epoch: 5| Step: 9
Training loss: 2.5244664789952265
Validation loss: 2.6654698457469648

Epoch: 5| Step: 10
Training loss: 2.2150891687773577
Validation loss: 2.5566046053955733

Epoch: 412| Step: 0
Training loss: 2.8665213577643276
Validation loss: 2.575897219819533

Epoch: 5| Step: 1
Training loss: 2.6818885771941794
Validation loss: 2.613919817675431

Epoch: 5| Step: 2
Training loss: 2.251210946480898
Validation loss: 2.550476291168739

Epoch: 5| Step: 3
Training loss: 2.4364006302029377
Validation loss: 2.6159469434000204

Epoch: 5| Step: 4
Training loss: 1.4824262978308116
Validation loss: 2.5677883574443925

Epoch: 5| Step: 5
Training loss: 2.4260621330563046
Validation loss: 2.60456888419277

Epoch: 5| Step: 6
Training loss: 2.2898200021824904
Validation loss: 2.5670457323794182

Epoch: 5| Step: 7
Training loss: 2.2082322895277433
Validation loss: 2.565266829978265

Epoch: 5| Step: 8
Training loss: 2.302418565003792
Validation loss: 2.596634061106501

Epoch: 5| Step: 9
Training loss: 2.167276027771774
Validation loss: 2.588097860343366

Epoch: 5| Step: 10
Training loss: 2.4359550470548452
Validation loss: 2.5997057095834313

Epoch: 413| Step: 0
Training loss: 2.3922494592497583
Validation loss: 2.4445692506266288

Epoch: 5| Step: 1
Training loss: 1.9988744668096896
Validation loss: 2.5770039159095046

Epoch: 5| Step: 2
Training loss: 2.0333289438210724
Validation loss: 2.5817215340794974

Epoch: 5| Step: 3
Training loss: 2.0857718755568677
Validation loss: 2.530232386874789

Epoch: 5| Step: 4
Training loss: 2.5859510530883036
Validation loss: 2.5102899051592718

Epoch: 5| Step: 5
Training loss: 2.4437322903745087
Validation loss: 2.5385129060215563

Epoch: 5| Step: 6
Training loss: 2.8099410389589203
Validation loss: 2.5928845494338844

Epoch: 5| Step: 7
Training loss: 2.7088548207124843
Validation loss: 2.6216153905717205

Epoch: 5| Step: 8
Training loss: 1.6939012129171862
Validation loss: 2.4737754649703056

Epoch: 5| Step: 9
Training loss: 2.8821739585415247
Validation loss: 2.5533203328218086

Epoch: 5| Step: 10
Training loss: 2.443207636206834
Validation loss: 2.602151099749635

Epoch: 414| Step: 0
Training loss: 2.526559699251018
Validation loss: 2.528943975094116

Epoch: 5| Step: 1
Training loss: 2.3476800139838225
Validation loss: 2.592132808462378

Epoch: 5| Step: 2
Training loss: 2.3384755103276884
Validation loss: 2.5264701768202174

Epoch: 5| Step: 3
Training loss: 2.13779345723194
Validation loss: 2.5511295082309737

Epoch: 5| Step: 4
Training loss: 1.4111067931208456
Validation loss: 2.4507861635447186

Epoch: 5| Step: 5
Training loss: 3.127722660374824
Validation loss: 2.5446805032293436

Epoch: 5| Step: 6
Training loss: 2.5128791940465565
Validation loss: 2.554151954749697

Epoch: 5| Step: 7
Training loss: 2.446155439370776
Validation loss: 2.532814412436603

Epoch: 5| Step: 8
Training loss: 2.5746652218863835
Validation loss: 2.577647525229723

Epoch: 5| Step: 9
Training loss: 2.51601193692358
Validation loss: 2.6135483893742943

Epoch: 5| Step: 10
Training loss: 1.948803568869018
Validation loss: 2.606544885020639

Epoch: 415| Step: 0
Training loss: 1.9066275551036744
Validation loss: 2.57078805725603

Epoch: 5| Step: 1
Training loss: 2.2806372668792845
Validation loss: 2.6033693421174813

Epoch: 5| Step: 2
Training loss: 2.3887690900981
Validation loss: 2.580617634020139

Epoch: 5| Step: 3
Training loss: 2.5284491219239915
Validation loss: 2.61566647156266

Epoch: 5| Step: 4
Training loss: 2.352434877311112
Validation loss: 2.5766974321721854

Epoch: 5| Step: 5
Training loss: 2.246989461346959
Validation loss: 2.5887368536883466

Epoch: 5| Step: 6
Training loss: 2.64077189561715
Validation loss: 2.5778303766686355

Epoch: 5| Step: 7
Training loss: 2.2743699301683864
Validation loss: 2.562698568658616

Epoch: 5| Step: 8
Training loss: 2.7375372339790878
Validation loss: 2.599452516972105

Epoch: 5| Step: 9
Training loss: 2.577479796159298
Validation loss: 2.56588088492409

Epoch: 5| Step: 10
Training loss: 1.959533127726872
Validation loss: 2.4927490724979027

Epoch: 416| Step: 0
Training loss: 2.794697857188872
Validation loss: 2.582651818163389

Epoch: 5| Step: 1
Training loss: 1.9966182728773898
Validation loss: 2.647259447461529

Epoch: 5| Step: 2
Training loss: 1.573233322033331
Validation loss: 2.539895353447451

Epoch: 5| Step: 3
Training loss: 2.8482425959914504
Validation loss: 2.657678245000087

Epoch: 5| Step: 4
Training loss: 2.2631246515888495
Validation loss: 2.607221141224487

Epoch: 5| Step: 5
Training loss: 1.7740903484556931
Validation loss: 2.6030613269214533

Epoch: 5| Step: 6
Training loss: 2.569519384396773
Validation loss: 2.5876501890568013

Epoch: 5| Step: 7
Training loss: 2.0436568259369006
Validation loss: 2.533656358572811

Epoch: 5| Step: 8
Training loss: 3.017576702821267
Validation loss: 2.480555839970176

Epoch: 5| Step: 9
Training loss: 2.7084633037974832
Validation loss: 2.583375566900124

Epoch: 5| Step: 10
Training loss: 1.7520662099006796
Validation loss: 2.5643053145841477

Epoch: 417| Step: 0
Training loss: 2.573154814248377
Validation loss: 2.5962162719079624

Epoch: 5| Step: 1
Training loss: 1.8495774069967053
Validation loss: 2.5998676364957896

Epoch: 5| Step: 2
Training loss: 2.2889352183709626
Validation loss: 2.556725208058364

Epoch: 5| Step: 3
Training loss: 2.0753910753252147
Validation loss: 2.591761314313259

Epoch: 5| Step: 4
Training loss: 2.761996804232064
Validation loss: 2.6589360630623795

Epoch: 5| Step: 5
Training loss: 2.00465447509394
Validation loss: 2.651262314073243

Epoch: 5| Step: 6
Training loss: 2.3418202912064263
Validation loss: 2.5671949198836574

Epoch: 5| Step: 7
Training loss: 2.709809258142561
Validation loss: 2.5290760542692334

Epoch: 5| Step: 8
Training loss: 2.151770652171062
Validation loss: 2.626701862935274

Epoch: 5| Step: 9
Training loss: 2.313182008541194
Validation loss: 2.571133725230804

Epoch: 5| Step: 10
Training loss: 2.578105209737016
Validation loss: 2.5440854875711394

Epoch: 418| Step: 0
Training loss: 2.280563982928502
Validation loss: 2.6120473710697882

Epoch: 5| Step: 1
Training loss: 2.067505974720598
Validation loss: 2.5604845550357913

Epoch: 5| Step: 2
Training loss: 1.5990683883251433
Validation loss: 2.5540051883290165

Epoch: 5| Step: 3
Training loss: 2.298929346751966
Validation loss: 2.6055156523172505

Epoch: 5| Step: 4
Training loss: 2.7237012655547184
Validation loss: 2.5342686351288637

Epoch: 5| Step: 5
Training loss: 2.317685267872997
Validation loss: 2.5624436793226986

Epoch: 5| Step: 6
Training loss: 2.423420369956534
Validation loss: 2.590369010473373

Epoch: 5| Step: 7
Training loss: 2.621244832671843
Validation loss: 2.6231952133225955

Epoch: 5| Step: 8
Training loss: 2.0422232381762577
Validation loss: 2.5807673581415407

Epoch: 5| Step: 9
Training loss: 1.863553329212363
Validation loss: 2.598309098565694

Epoch: 5| Step: 10
Training loss: 3.6586656985721846
Validation loss: 2.5157284056477263

Epoch: 419| Step: 0
Training loss: 2.632647319558715
Validation loss: 2.5570606955852897

Epoch: 5| Step: 1
Training loss: 2.590064498216103
Validation loss: 2.5660370297210346

Epoch: 5| Step: 2
Training loss: 2.425030037605426
Validation loss: 2.593489205703454

Epoch: 5| Step: 3
Training loss: 2.817904133554245
Validation loss: 2.575798397377939

Epoch: 5| Step: 4
Training loss: 2.5262119406240275
Validation loss: 2.549630541219099

Epoch: 5| Step: 5
Training loss: 2.6859362288777713
Validation loss: 2.5183917691287356

Epoch: 5| Step: 6
Training loss: 2.399681042298506
Validation loss: 2.5422558665554966

Epoch: 5| Step: 7
Training loss: 1.649155808281808
Validation loss: 2.568414965075974

Epoch: 5| Step: 8
Training loss: 1.6199670760023313
Validation loss: 2.5620617015214013

Epoch: 5| Step: 9
Training loss: 2.34556631281655
Validation loss: 2.5367620712084893

Epoch: 5| Step: 10
Training loss: 1.921247302260084
Validation loss: 2.5222898577416033

Epoch: 420| Step: 0
Training loss: 1.7111890773363958
Validation loss: 2.5653119219784886

Epoch: 5| Step: 1
Training loss: 3.110034048501224
Validation loss: 2.6353513158396455

Epoch: 5| Step: 2
Training loss: 2.394397028635248
Validation loss: 2.511918135436396

Epoch: 5| Step: 3
Training loss: 2.648163097648641
Validation loss: 2.5061806111353957

Epoch: 5| Step: 4
Training loss: 2.5006916996594373
Validation loss: 2.5478396782793458

Epoch: 5| Step: 5
Training loss: 1.9579815717731979
Validation loss: 2.6066486532888002

Epoch: 5| Step: 6
Training loss: 2.2030851752827854
Validation loss: 2.6545564158980093

Epoch: 5| Step: 7
Training loss: 2.4465971183593362
Validation loss: 2.5622314824666725

Epoch: 5| Step: 8
Training loss: 1.7312478406321146
Validation loss: 2.5364245012212723

Epoch: 5| Step: 9
Training loss: 2.887798184938413
Validation loss: 2.514072155754026

Epoch: 5| Step: 10
Training loss: 2.1372301790248907
Validation loss: 2.6095564446756807

Epoch: 421| Step: 0
Training loss: 2.0872574533961576
Validation loss: 2.494349625459687

Epoch: 5| Step: 1
Training loss: 2.6521914723522633
Validation loss: 2.5750954287438534

Epoch: 5| Step: 2
Training loss: 2.620232567111078
Validation loss: 2.582959660812606

Epoch: 5| Step: 3
Training loss: 1.7424669939634092
Validation loss: 2.6240954571704838

Epoch: 5| Step: 4
Training loss: 2.7081222647559136
Validation loss: 2.6054053752332784

Epoch: 5| Step: 5
Training loss: 2.2428437977116995
Validation loss: 2.5212660699173677

Epoch: 5| Step: 6
Training loss: 2.140821573183816
Validation loss: 2.481581816448904

Epoch: 5| Step: 7
Training loss: 2.5472906042710206
Validation loss: 2.6581590648256737

Epoch: 5| Step: 8
Training loss: 2.019647886350209
Validation loss: 2.529800372652902

Epoch: 5| Step: 9
Training loss: 1.8986474694199462
Validation loss: 2.5692873350130174

Epoch: 5| Step: 10
Training loss: 2.728481633842273
Validation loss: 2.5972190388457883

Epoch: 422| Step: 0
Training loss: 1.876448326226743
Validation loss: 2.543284089340912

Epoch: 5| Step: 1
Training loss: 2.2502684962819184
Validation loss: 2.507213601903443

Epoch: 5| Step: 2
Training loss: 2.8472133129776505
Validation loss: 2.5833273992427292

Epoch: 5| Step: 3
Training loss: 2.4348405855544195
Validation loss: 2.5728630554212204

Epoch: 5| Step: 4
Training loss: 2.213399426247121
Validation loss: 2.511242560929748

Epoch: 5| Step: 5
Training loss: 2.2060987815148416
Validation loss: 2.5253612769535265

Epoch: 5| Step: 6
Training loss: 2.215082926005162
Validation loss: 2.541170331671595

Epoch: 5| Step: 7
Training loss: 2.886596346726211
Validation loss: 2.6051567613920623

Epoch: 5| Step: 8
Training loss: 1.9500226215126353
Validation loss: 2.553722460104378

Epoch: 5| Step: 9
Training loss: 2.291670007414261
Validation loss: 2.6197439369719344

Epoch: 5| Step: 10
Training loss: 2.6501170546392463
Validation loss: 2.6141256014986904

Epoch: 423| Step: 0
Training loss: 2.4361389468362096
Validation loss: 2.5580132795463473

Epoch: 5| Step: 1
Training loss: 1.9099249514470227
Validation loss: 2.600295989618901

Epoch: 5| Step: 2
Training loss: 1.5593066580862234
Validation loss: 2.66596645601519

Epoch: 5| Step: 3
Training loss: 2.7941080397331484
Validation loss: 2.545878433983542

Epoch: 5| Step: 4
Training loss: 2.320584265209884
Validation loss: 2.5814477573591037

Epoch: 5| Step: 5
Training loss: 2.0408424997597643
Validation loss: 2.577322392033158

Epoch: 5| Step: 6
Training loss: 3.2569901048125214
Validation loss: 2.6375447648777155

Epoch: 5| Step: 7
Training loss: 1.9041600261324807
Validation loss: 2.5607203424689713

Epoch: 5| Step: 8
Training loss: 2.331379810636107
Validation loss: 2.5864297554252134

Epoch: 5| Step: 9
Training loss: 2.408723228951173
Validation loss: 2.602922842631829

Epoch: 5| Step: 10
Training loss: 2.377789315030321
Validation loss: 2.5441228593663827

Epoch: 424| Step: 0
Training loss: 2.711851729877592
Validation loss: 2.5716635488965576

Epoch: 5| Step: 1
Training loss: 2.587962576387736
Validation loss: 2.5684241230045863

Epoch: 5| Step: 2
Training loss: 2.137735017047902
Validation loss: 2.5067774478289393

Epoch: 5| Step: 3
Training loss: 2.1365167776886786
Validation loss: 2.5537284618166898

Epoch: 5| Step: 4
Training loss: 2.106603426386474
Validation loss: 2.5162474714919676

Epoch: 5| Step: 5
Training loss: 2.2786225119714296
Validation loss: 2.5152336829731645

Epoch: 5| Step: 6
Training loss: 2.1312530741291864
Validation loss: 2.55378377960301

Epoch: 5| Step: 7
Training loss: 1.9920083358084675
Validation loss: 2.5690100896848724

Epoch: 5| Step: 8
Training loss: 2.3152097342544207
Validation loss: 2.559170550624795

Epoch: 5| Step: 9
Training loss: 3.267780669342679
Validation loss: 2.6367820799592883

Epoch: 5| Step: 10
Training loss: 2.3738682710693726
Validation loss: 2.5465085170887374

Epoch: 425| Step: 0
Training loss: 2.8092544478880006
Validation loss: 2.5417463275671395

Epoch: 5| Step: 1
Training loss: 2.520979590678721
Validation loss: 2.6522343267579536

Epoch: 5| Step: 2
Training loss: 2.076497064137835
Validation loss: 2.5834524737171067

Epoch: 5| Step: 3
Training loss: 2.07576600608641
Validation loss: 2.5995883499029597

Epoch: 5| Step: 4
Training loss: 2.129731016770988
Validation loss: 2.5319782183373705

Epoch: 5| Step: 5
Training loss: 2.5697909582596075
Validation loss: 2.5337786727383675

Epoch: 5| Step: 6
Training loss: 2.3916446281596238
Validation loss: 2.597306678449777

Epoch: 5| Step: 7
Training loss: 1.9588204312396889
Validation loss: 2.631248960455087

Epoch: 5| Step: 8
Training loss: 2.343755900057678
Validation loss: 2.6201058932846966

Epoch: 5| Step: 9
Training loss: 2.902903116573377
Validation loss: 2.5806124990201087

Epoch: 5| Step: 10
Training loss: 2.1663674979418697
Validation loss: 2.5786257996074218

Epoch: 426| Step: 0
Training loss: 2.4014875173186727
Validation loss: 2.5831501552117495

Epoch: 5| Step: 1
Training loss: 2.5759278153618426
Validation loss: 2.534010773806146

Epoch: 5| Step: 2
Training loss: 2.4104551751289947
Validation loss: 2.5354494408523687

Epoch: 5| Step: 3
Training loss: 2.5057706036680187
Validation loss: 2.5738810412134807

Epoch: 5| Step: 4
Training loss: 2.4627054312745664
Validation loss: 2.6061879211981918

Epoch: 5| Step: 5
Training loss: 2.2398186375221765
Validation loss: 2.665787946861194

Epoch: 5| Step: 6
Training loss: 2.687884902005561
Validation loss: 2.5467859088155698

Epoch: 5| Step: 7
Training loss: 2.6049952498555577
Validation loss: 2.561086976892612

Epoch: 5| Step: 8
Training loss: 1.8824577155563267
Validation loss: 2.6100043508721043

Epoch: 5| Step: 9
Training loss: 2.2934580188316214
Validation loss: 2.5791706847026483

Epoch: 5| Step: 10
Training loss: 2.312547013088413
Validation loss: 2.5734208331974355

Epoch: 427| Step: 0
Training loss: 2.771425704926482
Validation loss: 2.579545409305462

Epoch: 5| Step: 1
Training loss: 2.608313613020802
Validation loss: 2.549936815187201

Epoch: 5| Step: 2
Training loss: 2.2143063170709496
Validation loss: 2.57465554846735

Epoch: 5| Step: 3
Training loss: 2.2918528972441057
Validation loss: 2.547510298996007

Epoch: 5| Step: 4
Training loss: 2.0859897335527684
Validation loss: 2.566131623553128

Epoch: 5| Step: 5
Training loss: 2.229626070498281
Validation loss: 2.5707528521659806

Epoch: 5| Step: 6
Training loss: 2.418586220728628
Validation loss: 2.626559529154557

Epoch: 5| Step: 7
Training loss: 2.3062759356603992
Validation loss: 2.6354417389122866

Epoch: 5| Step: 8
Training loss: 2.3783516574074417
Validation loss: 2.6354053332835634

Epoch: 5| Step: 9
Training loss: 2.735065307674325
Validation loss: 2.5998212333028805

Epoch: 5| Step: 10
Training loss: 2.197969505313725
Validation loss: 2.55063452180303

Epoch: 428| Step: 0
Training loss: 2.301636515849653
Validation loss: 2.564092559917203

Epoch: 5| Step: 1
Training loss: 1.9318643870412366
Validation loss: 2.5110725183008116

Epoch: 5| Step: 2
Training loss: 2.6365456757433128
Validation loss: 2.535227458199087

Epoch: 5| Step: 3
Training loss: 2.427645791387191
Validation loss: 2.631945842563937

Epoch: 5| Step: 4
Training loss: 2.2372011038330237
Validation loss: 2.5393761185406825

Epoch: 5| Step: 5
Training loss: 2.147231328675421
Validation loss: 2.584261431450907

Epoch: 5| Step: 6
Training loss: 3.0928101316105505
Validation loss: 2.517780784294129

Epoch: 5| Step: 7
Training loss: 1.794617603235478
Validation loss: 2.56807505356702

Epoch: 5| Step: 8
Training loss: 1.903117811568391
Validation loss: 2.694220732122154

Epoch: 5| Step: 9
Training loss: 2.3864714998581085
Validation loss: 2.5882469001657533

Epoch: 5| Step: 10
Training loss: 2.784825544800235
Validation loss: 2.586716360667861

Epoch: 429| Step: 0
Training loss: 2.2505729793436076
Validation loss: 2.585000896869835

Epoch: 5| Step: 1
Training loss: 2.173078903135017
Validation loss: 2.522155311519517

Epoch: 5| Step: 2
Training loss: 2.212321680501635
Validation loss: 2.618655613092942

Epoch: 5| Step: 3
Training loss: 2.1796190257921717
Validation loss: 2.5647430237319733

Epoch: 5| Step: 4
Training loss: 2.618707744831052
Validation loss: 2.5492522806490236

Epoch: 5| Step: 5
Training loss: 2.6522226657111507
Validation loss: 2.5482867900562187

Epoch: 5| Step: 6
Training loss: 1.667792782222904
Validation loss: 2.5299152950620982

Epoch: 5| Step: 7
Training loss: 2.123884693744408
Validation loss: 2.581833230372265

Epoch: 5| Step: 8
Training loss: 3.4360881333511006
Validation loss: 2.5550182522670704

Epoch: 5| Step: 9
Training loss: 2.2177175349350287
Validation loss: 2.563604333493312

Epoch: 5| Step: 10
Training loss: 1.571745109879362
Validation loss: 2.61961895212245

Epoch: 430| Step: 0
Training loss: 2.9774950223764214
Validation loss: 2.5640072575353288

Epoch: 5| Step: 1
Training loss: 2.4171930156464825
Validation loss: 2.5837754891015106

Epoch: 5| Step: 2
Training loss: 2.6051391210034667
Validation loss: 2.596952651135058

Epoch: 5| Step: 3
Training loss: 2.696497383069721
Validation loss: 2.5398720959231205

Epoch: 5| Step: 4
Training loss: 2.9067897500509003
Validation loss: 2.5928472100985354

Epoch: 5| Step: 5
Training loss: 1.579869278920431
Validation loss: 2.565848556970194

Epoch: 5| Step: 6
Training loss: 2.6248163431497664
Validation loss: 2.5645345618969

Epoch: 5| Step: 7
Training loss: 1.8514771904587268
Validation loss: 2.643022036027923

Epoch: 5| Step: 8
Training loss: 2.051390116088656
Validation loss: 2.6133853393702555

Epoch: 5| Step: 9
Training loss: 2.240834322931883
Validation loss: 2.6054840021027847

Epoch: 5| Step: 10
Training loss: 1.6629477335411795
Validation loss: 2.613616983106027

Epoch: 431| Step: 0
Training loss: 1.804442682215786
Validation loss: 2.686782403425241

Epoch: 5| Step: 1
Training loss: 2.2052599795610526
Validation loss: 2.5734873176993367

Epoch: 5| Step: 2
Training loss: 2.8139992850329176
Validation loss: 2.5907226955745792

Epoch: 5| Step: 3
Training loss: 1.8392492415030066
Validation loss: 2.5997104469344117

Epoch: 5| Step: 4
Training loss: 2.4140227971932355
Validation loss: 2.5233635929202967

Epoch: 5| Step: 5
Training loss: 2.001240941348235
Validation loss: 2.598051524831092

Epoch: 5| Step: 6
Training loss: 2.2344978138709584
Validation loss: 2.6272608566901146

Epoch: 5| Step: 7
Training loss: 2.4632247710233446
Validation loss: 2.6067155894833673

Epoch: 5| Step: 8
Training loss: 2.959010964453553
Validation loss: 2.635503810687095

Epoch: 5| Step: 9
Training loss: 1.9619727574517098
Validation loss: 2.5675115333730476

Epoch: 5| Step: 10
Training loss: 2.4024603590538076
Validation loss: 2.563911484442724

Epoch: 432| Step: 0
Training loss: 2.512149566200756
Validation loss: 2.614757050800844

Epoch: 5| Step: 1
Training loss: 2.6658288911251997
Validation loss: 2.5674037228915725

Epoch: 5| Step: 2
Training loss: 1.979444370529702
Validation loss: 2.5382689775320793

Epoch: 5| Step: 3
Training loss: 1.8637986334551637
Validation loss: 2.604862421102396

Epoch: 5| Step: 4
Training loss: 2.4060381511222473
Validation loss: 2.640940982781171

Epoch: 5| Step: 5
Training loss: 2.348383786011688
Validation loss: 2.5295273937762213

Epoch: 5| Step: 6
Training loss: 2.892900880351769
Validation loss: 2.598901986305722

Epoch: 5| Step: 7
Training loss: 2.320700359358887
Validation loss: 2.5117200727903755

Epoch: 5| Step: 8
Training loss: 2.800810107477512
Validation loss: 2.6226149494556332

Epoch: 5| Step: 9
Training loss: 2.117231305221702
Validation loss: 2.6417644421175033

Epoch: 5| Step: 10
Training loss: 1.8631409406315973
Validation loss: 2.5909973078877933

Epoch: 433| Step: 0
Training loss: 2.6954934764309733
Validation loss: 2.537436891566433

Epoch: 5| Step: 1
Training loss: 2.1246122118592017
Validation loss: 2.5452277028002914

Epoch: 5| Step: 2
Training loss: 2.4651517116449004
Validation loss: 2.4844278123705767

Epoch: 5| Step: 3
Training loss: 2.2924160396796895
Validation loss: 2.6185221007520867

Epoch: 5| Step: 4
Training loss: 2.7514473834156514
Validation loss: 2.5675000407003283

Epoch: 5| Step: 5
Training loss: 2.0260976147874064
Validation loss: 2.57286847541764

Epoch: 5| Step: 6
Training loss: 2.447469132007619
Validation loss: 2.6175950804512196

Epoch: 5| Step: 7
Training loss: 2.0227342952259577
Validation loss: 2.644507299595802

Epoch: 5| Step: 8
Training loss: 1.5902847315799575
Validation loss: 2.564390377118649

Epoch: 5| Step: 9
Training loss: 2.3732628743646167
Validation loss: 2.5302953475781345

Epoch: 5| Step: 10
Training loss: 2.569938191809854
Validation loss: 2.5472905297960438

Epoch: 434| Step: 0
Training loss: 2.2391215240088655
Validation loss: 2.5595393411393164

Epoch: 5| Step: 1
Training loss: 2.5485145580586193
Validation loss: 2.5806420114713333

Epoch: 5| Step: 2
Training loss: 2.289526882522823
Validation loss: 2.5399180536032526

Epoch: 5| Step: 3
Training loss: 2.4352847082861993
Validation loss: 2.5590468990380173

Epoch: 5| Step: 4
Training loss: 2.3152402159139456
Validation loss: 2.6033532455157813

Epoch: 5| Step: 5
Training loss: 2.2423547556098486
Validation loss: 2.570503789533091

Epoch: 5| Step: 6
Training loss: 2.391703443432761
Validation loss: 2.606824041943058

Epoch: 5| Step: 7
Training loss: 2.1740560215081306
Validation loss: 2.5787500851127683

Epoch: 5| Step: 8
Training loss: 2.0009685793596854
Validation loss: 2.534888268474581

Epoch: 5| Step: 9
Training loss: 2.867410344499063
Validation loss: 2.4904598368707918

Epoch: 5| Step: 10
Training loss: 1.8994660279684525
Validation loss: 2.540514086692639

Epoch: 435| Step: 0
Training loss: 2.0335635581250178
Validation loss: 2.5568014711439044

Epoch: 5| Step: 1
Training loss: 2.4661795839754816
Validation loss: 2.6194968797251477

Epoch: 5| Step: 2
Training loss: 2.6696608443002807
Validation loss: 2.6247381244750505

Epoch: 5| Step: 3
Training loss: 2.3009700471005288
Validation loss: 2.6302053910641745

Epoch: 5| Step: 4
Training loss: 2.5795654896487825
Validation loss: 2.5973941354618075

Epoch: 5| Step: 5
Training loss: 2.6076287005400847
Validation loss: 2.5495211314687585

Epoch: 5| Step: 6
Training loss: 1.8716901812119415
Validation loss: 2.550805217108518

Epoch: 5| Step: 7
Training loss: 2.371655367808482
Validation loss: 2.6114216800316448

Epoch: 5| Step: 8
Training loss: 2.1754752856573343
Validation loss: 2.5722478796402206

Epoch: 5| Step: 9
Training loss: 2.1516563023860042
Validation loss: 2.5774765377469357

Epoch: 5| Step: 10
Training loss: 2.41552581386082
Validation loss: 2.5000281322085933

Epoch: 436| Step: 0
Training loss: 2.232229630009814
Validation loss: 2.516710930918333

Epoch: 5| Step: 1
Training loss: 1.792728848499729
Validation loss: 2.5566144774709323

Epoch: 5| Step: 2
Training loss: 1.9837009757029003
Validation loss: 2.5575377285744536

Epoch: 5| Step: 3
Training loss: 2.7106349457427923
Validation loss: 2.572318778621473

Epoch: 5| Step: 4
Training loss: 2.2048612205792364
Validation loss: 2.5923539511556024

Epoch: 5| Step: 5
Training loss: 2.5155011259109443
Validation loss: 2.5390619790050644

Epoch: 5| Step: 6
Training loss: 2.4166319175940463
Validation loss: 2.5874687657416233

Epoch: 5| Step: 7
Training loss: 2.166253808618577
Validation loss: 2.4862816737338425

Epoch: 5| Step: 8
Training loss: 2.703841274376868
Validation loss: 2.572036688999171

Epoch: 5| Step: 9
Training loss: 2.3461135136816353
Validation loss: 2.6169023050156337

Epoch: 5| Step: 10
Training loss: 2.2501552316310907
Validation loss: 2.526666528217622

Epoch: 437| Step: 0
Training loss: 2.1647990932146923
Validation loss: 2.5803667431982458

Epoch: 5| Step: 1
Training loss: 1.9187083634322932
Validation loss: 2.6117789258061204

Epoch: 5| Step: 2
Training loss: 2.093473273821657
Validation loss: 2.5480028417424005

Epoch: 5| Step: 3
Training loss: 2.2279978626247816
Validation loss: 2.556784836713357

Epoch: 5| Step: 4
Training loss: 2.0664415554787587
Validation loss: 2.5835530043443975

Epoch: 5| Step: 5
Training loss: 3.0701599859742714
Validation loss: 2.4990408964989483

Epoch: 5| Step: 6
Training loss: 2.7733024456828925
Validation loss: 2.63646919555296

Epoch: 5| Step: 7
Training loss: 2.894212630595519
Validation loss: 2.612228202232978

Epoch: 5| Step: 8
Training loss: 1.9478019503780994
Validation loss: 2.5589516515966557

Epoch: 5| Step: 9
Training loss: 2.324048050454274
Validation loss: 2.625187571709717

Epoch: 5| Step: 10
Training loss: 2.459457873022997
Validation loss: 2.6008055472398226

Epoch: 438| Step: 0
Training loss: 2.2826887845270574
Validation loss: 2.5440051495030493

Epoch: 5| Step: 1
Training loss: 2.3229122304375087
Validation loss: 2.5434584181688704

Epoch: 5| Step: 2
Training loss: 1.9143547613485787
Validation loss: 2.5569212338440015

Epoch: 5| Step: 3
Training loss: 2.2391258896281987
Validation loss: 2.5064680812133298

Epoch: 5| Step: 4
Training loss: 2.767819756813524
Validation loss: 2.6399507000839124

Epoch: 5| Step: 5
Training loss: 2.393010264705031
Validation loss: 2.501607797306633

Epoch: 5| Step: 6
Training loss: 2.0506470845250275
Validation loss: 2.5613984722509695

Epoch: 5| Step: 7
Training loss: 2.3594697844811225
Validation loss: 2.618305765841592

Epoch: 5| Step: 8
Training loss: 2.4067526948651627
Validation loss: 2.504614169206137

Epoch: 5| Step: 9
Training loss: 2.197162540984701
Validation loss: 2.606630421090054

Epoch: 5| Step: 10
Training loss: 2.746226756536217
Validation loss: 2.6127955193464913

Epoch: 439| Step: 0
Training loss: 2.731561575779127
Validation loss: 2.5844579402889565

Epoch: 5| Step: 1
Training loss: 2.1979827388818056
Validation loss: 2.537268228057615

Epoch: 5| Step: 2
Training loss: 2.454988585715553
Validation loss: 2.5744189959230677

Epoch: 5| Step: 3
Training loss: 2.240925822687053
Validation loss: 2.5417261229335115

Epoch: 5| Step: 4
Training loss: 2.7649789691421858
Validation loss: 2.5995271591970126

Epoch: 5| Step: 5
Training loss: 2.1958722795752004
Validation loss: 2.533334440717903

Epoch: 5| Step: 6
Training loss: 2.1060056550329493
Validation loss: 2.604869624269717

Epoch: 5| Step: 7
Training loss: 2.383359552341464
Validation loss: 2.4912688479714817

Epoch: 5| Step: 8
Training loss: 2.088732614770172
Validation loss: 2.644387350428038

Epoch: 5| Step: 9
Training loss: 1.9211815303994058
Validation loss: 2.613799812458706

Epoch: 5| Step: 10
Training loss: 2.1221698539268754
Validation loss: 2.6037535965344034

Epoch: 440| Step: 0
Training loss: 2.479100608479884
Validation loss: 2.6200573138077297

Epoch: 5| Step: 1
Training loss: 1.983821401194462
Validation loss: 2.517547027055459

Epoch: 5| Step: 2
Training loss: 1.7910132954123685
Validation loss: 2.5730932210928823

Epoch: 5| Step: 3
Training loss: 2.5813781558682467
Validation loss: 2.650823572121003

Epoch: 5| Step: 4
Training loss: 3.2160412399437672
Validation loss: 2.5806822850712985

Epoch: 5| Step: 5
Training loss: 2.329040756871371
Validation loss: 2.5718837971685695

Epoch: 5| Step: 6
Training loss: 2.616520309809715
Validation loss: 2.551480124338306

Epoch: 5| Step: 7
Training loss: 2.2793066029475892
Validation loss: 2.558085669424741

Epoch: 5| Step: 8
Training loss: 2.58730462115243
Validation loss: 2.5926958055219544

Epoch: 5| Step: 9
Training loss: 1.856510809355525
Validation loss: 2.545562341447427

Epoch: 5| Step: 10
Training loss: 2.0219064465395893
Validation loss: 2.5167561075178084

Epoch: 441| Step: 0
Training loss: 1.8227476931776978
Validation loss: 2.6302733476746907

Epoch: 5| Step: 1
Training loss: 1.440675793329504
Validation loss: 2.5389772018101615

Epoch: 5| Step: 2
Training loss: 2.7880953439530463
Validation loss: 2.676457112831206

Epoch: 5| Step: 3
Training loss: 2.366858128965259
Validation loss: 2.531062985318563

Epoch: 5| Step: 4
Training loss: 2.359030186801604
Validation loss: 2.561234894967418

Epoch: 5| Step: 5
Training loss: 2.342751252044288
Validation loss: 2.6224061971216197

Epoch: 5| Step: 6
Training loss: 2.7350157940563693
Validation loss: 2.57841339039645

Epoch: 5| Step: 7
Training loss: 2.2917230656937506
Validation loss: 2.6124306778057194

Epoch: 5| Step: 8
Training loss: 2.277687216976933
Validation loss: 2.538962636645018

Epoch: 5| Step: 9
Training loss: 2.0548053896194123
Validation loss: 2.668089487700401

Epoch: 5| Step: 10
Training loss: 2.8638765515089357
Validation loss: 2.5309626067859

Epoch: 442| Step: 0
Training loss: 2.237810601354954
Validation loss: 2.5529872683875876

Epoch: 5| Step: 1
Training loss: 2.204459036730509
Validation loss: 2.5445069518060355

Epoch: 5| Step: 2
Training loss: 2.1025229602698547
Validation loss: 2.579313853416021

Epoch: 5| Step: 3
Training loss: 1.6666763623273484
Validation loss: 2.5479382690461594

Epoch: 5| Step: 4
Training loss: 1.733953613778381
Validation loss: 2.524119227236268

Epoch: 5| Step: 5
Training loss: 2.539104003567041
Validation loss: 2.5869216406919118

Epoch: 5| Step: 6
Training loss: 2.5472671113333822
Validation loss: 2.5232301367328733

Epoch: 5| Step: 7
Training loss: 2.610367637553384
Validation loss: 2.556165831612024

Epoch: 5| Step: 8
Training loss: 2.2701308070738095
Validation loss: 2.4896420403978534

Epoch: 5| Step: 9
Training loss: 2.858139688440314
Validation loss: 2.5131067007039074

Epoch: 5| Step: 10
Training loss: 2.4257631654418477
Validation loss: 2.582295000384327

Epoch: 443| Step: 0
Training loss: 2.0598342314011706
Validation loss: 2.5893811346770796

Epoch: 5| Step: 1
Training loss: 2.24057810373855
Validation loss: 2.5399998754337076

Epoch: 5| Step: 2
Training loss: 1.8724651368057181
Validation loss: 2.548739159420319

Epoch: 5| Step: 3
Training loss: 2.675195783063768
Validation loss: 2.588348703023074

Epoch: 5| Step: 4
Training loss: 2.384778321878311
Validation loss: 2.5748119178433595

Epoch: 5| Step: 5
Training loss: 2.0813486436716153
Validation loss: 2.531686348970401

Epoch: 5| Step: 6
Training loss: 2.446197057276822
Validation loss: 2.4969175614467827

Epoch: 5| Step: 7
Training loss: 2.8220721643792803
Validation loss: 2.629736612020598

Epoch: 5| Step: 8
Training loss: 2.7007908086853103
Validation loss: 2.5835454584439845

Epoch: 5| Step: 9
Training loss: 1.8996166444828002
Validation loss: 2.54545409784951

Epoch: 5| Step: 10
Training loss: 2.11969476301818
Validation loss: 2.543256923486964

Epoch: 444| Step: 0
Training loss: 1.6012101693005083
Validation loss: 2.579917738346237

Epoch: 5| Step: 1
Training loss: 2.0774167797253806
Validation loss: 2.4940569049929775

Epoch: 5| Step: 2
Training loss: 2.080009695727419
Validation loss: 2.529110118315362

Epoch: 5| Step: 3
Training loss: 2.3981758496836423
Validation loss: 2.5327671213538427

Epoch: 5| Step: 4
Training loss: 2.816076928724365
Validation loss: 2.612454682840432

Epoch: 5| Step: 5
Training loss: 2.3645299717823995
Validation loss: 2.510350883424315

Epoch: 5| Step: 6
Training loss: 2.5500492839164566
Validation loss: 2.5410255949690197

Epoch: 5| Step: 7
Training loss: 2.8905232179610283
Validation loss: 2.562556491512242

Epoch: 5| Step: 8
Training loss: 1.7297591913902277
Validation loss: 2.56686606272555

Epoch: 5| Step: 9
Training loss: 2.3923440374962577
Validation loss: 2.571331559361613

Epoch: 5| Step: 10
Training loss: 2.3208029899690996
Validation loss: 2.595656988595518

Epoch: 445| Step: 0
Training loss: 2.2333773006077853
Validation loss: 2.6509901517567513

Epoch: 5| Step: 1
Training loss: 2.105171819637949
Validation loss: 2.5164658029146474

Epoch: 5| Step: 2
Training loss: 3.127670367850749
Validation loss: 2.5631172093155903

Epoch: 5| Step: 3
Training loss: 1.9625871262374877
Validation loss: 2.5064797422430933

Epoch: 5| Step: 4
Training loss: 2.10633053951055
Validation loss: 2.535490595076401

Epoch: 5| Step: 5
Training loss: 2.11829586507144
Validation loss: 2.5975941985771045

Epoch: 5| Step: 6
Training loss: 2.3551843069730256
Validation loss: 2.5595477205309143

Epoch: 5| Step: 7
Training loss: 2.9668523244591944
Validation loss: 2.5174813381439063

Epoch: 5| Step: 8
Training loss: 2.321417445900216
Validation loss: 2.5845296202305597

Epoch: 5| Step: 9
Training loss: 2.2167342794714235
Validation loss: 2.6043250415183574

Epoch: 5| Step: 10
Training loss: 1.723347773771209
Validation loss: 2.5483057113072545

Epoch: 446| Step: 0
Training loss: 2.5580169726502877
Validation loss: 2.572318046101013

Epoch: 5| Step: 1
Training loss: 2.673818673227907
Validation loss: 2.5904709021317607

Epoch: 5| Step: 2
Training loss: 1.9686440938892817
Validation loss: 2.575119082943639

Epoch: 5| Step: 3
Training loss: 1.9835775379962246
Validation loss: 2.6292541826587428

Epoch: 5| Step: 4
Training loss: 1.9424676277281248
Validation loss: 2.597225533767486

Epoch: 5| Step: 5
Training loss: 2.624947138662782
Validation loss: 2.517306552607387

Epoch: 5| Step: 6
Training loss: 2.42181701590744
Validation loss: 2.5461368383166736

Epoch: 5| Step: 7
Training loss: 2.4132889678031435
Validation loss: 2.5922254422613986

Epoch: 5| Step: 8
Training loss: 1.9020046425370638
Validation loss: 2.5339571848798035

Epoch: 5| Step: 9
Training loss: 3.0525077203626423
Validation loss: 2.5931025622521653

Epoch: 5| Step: 10
Training loss: 2.1201449637963408
Validation loss: 2.578625362164356

Epoch: 447| Step: 0
Training loss: 1.8520982184596835
Validation loss: 2.5739641359467442

Epoch: 5| Step: 1
Training loss: 2.790294556741081
Validation loss: 2.595741422738523

Epoch: 5| Step: 2
Training loss: 2.505637773808085
Validation loss: 2.5845701496693514

Epoch: 5| Step: 3
Training loss: 1.8539328552729064
Validation loss: 2.5850796951116455

Epoch: 5| Step: 4
Training loss: 2.762999328088558
Validation loss: 2.57383575122329

Epoch: 5| Step: 5
Training loss: 1.7071243365503594
Validation loss: 2.6009592730785265

Epoch: 5| Step: 6
Training loss: 2.617191326081625
Validation loss: 2.565805161976619

Epoch: 5| Step: 7
Training loss: 2.1137945147699164
Validation loss: 2.550214122522428

Epoch: 5| Step: 8
Training loss: 2.567603448939945
Validation loss: 2.5460625641179733

Epoch: 5| Step: 9
Training loss: 2.127650011020838
Validation loss: 2.646217673552489

Epoch: 5| Step: 10
Training loss: 1.473537191697638
Validation loss: 2.556552088723234

Epoch: 448| Step: 0
Training loss: 3.0069177659172475
Validation loss: 2.5064932053924207

Epoch: 5| Step: 1
Training loss: 1.7811030946351398
Validation loss: 2.5471244522253396

Epoch: 5| Step: 2
Training loss: 2.0135439990313486
Validation loss: 2.5432267231840537

Epoch: 5| Step: 3
Training loss: 2.502654954684043
Validation loss: 2.6087230073894694

Epoch: 5| Step: 4
Training loss: 2.41579209868747
Validation loss: 2.5100368034842444

Epoch: 5| Step: 5
Training loss: 2.2601321227351376
Validation loss: 2.556717855213501

Epoch: 5| Step: 6
Training loss: 2.0417202404025825
Validation loss: 2.6142614016327324

Epoch: 5| Step: 7
Training loss: 1.8324576656348692
Validation loss: 2.5174746415607037

Epoch: 5| Step: 8
Training loss: 2.3247143641746613
Validation loss: 2.5924284704408413

Epoch: 5| Step: 9
Training loss: 2.108669247712011
Validation loss: 2.5444846573145763

Epoch: 5| Step: 10
Training loss: 2.3060688598952046
Validation loss: 2.547957363931724

Epoch: 449| Step: 0
Training loss: 2.1700451504277556
Validation loss: 2.650042124092443

Epoch: 5| Step: 1
Training loss: 2.1595427209223645
Validation loss: 2.6142325285873627

Epoch: 5| Step: 2
Training loss: 2.3805160713061926
Validation loss: 2.542291096183583

Epoch: 5| Step: 3
Training loss: 2.616529786322178
Validation loss: 2.4985159848058416

Epoch: 5| Step: 4
Training loss: 1.9216585114905134
Validation loss: 2.5978733038369386

Epoch: 5| Step: 5
Training loss: 2.673800839604664
Validation loss: 2.5642458093215743

Epoch: 5| Step: 6
Training loss: 2.305232820813181
Validation loss: 2.6581092769624517

Epoch: 5| Step: 7
Training loss: 2.3325170269801556
Validation loss: 2.565047042974351

Epoch: 5| Step: 8
Training loss: 1.6112997896419585
Validation loss: 2.5724225024092577

Epoch: 5| Step: 9
Training loss: 2.127066785229294
Validation loss: 2.595489561068328

Epoch: 5| Step: 10
Training loss: 3.024025241393249
Validation loss: 2.659065860941029

Epoch: 450| Step: 0
Training loss: 2.042146769017471
Validation loss: 2.495743038965463

Epoch: 5| Step: 1
Training loss: 1.9278534733583852
Validation loss: 2.584607774227073

Epoch: 5| Step: 2
Training loss: 2.941670480641026
Validation loss: 2.4717001566727266

Epoch: 5| Step: 3
Training loss: 1.8672167404630557
Validation loss: 2.579061711525435

Epoch: 5| Step: 4
Training loss: 1.8580341152389328
Validation loss: 2.525582573725909

Epoch: 5| Step: 5
Training loss: 2.2732240766781673
Validation loss: 2.5633026144659685

Epoch: 5| Step: 6
Training loss: 2.019154614979223
Validation loss: 2.5473053069978695

Epoch: 5| Step: 7
Training loss: 2.6659932677061637
Validation loss: 2.5432125139989195

Epoch: 5| Step: 8
Training loss: 1.8126932238482607
Validation loss: 2.576009490602506

Epoch: 5| Step: 9
Training loss: 2.453537827275758
Validation loss: 2.48439834985165

Epoch: 5| Step: 10
Training loss: 2.9564158354813954
Validation loss: 2.5356305985609335

Epoch: 451| Step: 0
Training loss: 2.6844391358854987
Validation loss: 2.580896150492952

Epoch: 5| Step: 1
Training loss: 2.8071289487166244
Validation loss: 2.4878006762725597

Epoch: 5| Step: 2
Training loss: 1.811591611335117
Validation loss: 2.5766978749172162

Epoch: 5| Step: 3
Training loss: 2.136398486696131
Validation loss: 2.559923081323983

Epoch: 5| Step: 4
Training loss: 1.9187411677750583
Validation loss: 2.612039482018933

Epoch: 5| Step: 5
Training loss: 2.81525523544677
Validation loss: 2.487633256027173

Epoch: 5| Step: 6
Training loss: 1.8046221700626197
Validation loss: 2.5862668176594465

Epoch: 5| Step: 7
Training loss: 2.775763597332959
Validation loss: 2.5795827235371775

Epoch: 5| Step: 8
Training loss: 1.9044516163090899
Validation loss: 2.62642523167185

Epoch: 5| Step: 9
Training loss: 2.9102475145609694
Validation loss: 2.5636888172975647

Epoch: 5| Step: 10
Training loss: 2.006479258525385
Validation loss: 2.6011259109336446

Epoch: 452| Step: 0
Training loss: 2.070903880748882
Validation loss: 2.5952240863993903

Epoch: 5| Step: 1
Training loss: 2.334204806209503
Validation loss: 2.523971339108594

Epoch: 5| Step: 2
Training loss: 3.1145678533639316
Validation loss: 2.559414900039081

Epoch: 5| Step: 3
Training loss: 1.673370191857131
Validation loss: 2.5032859546994173

Epoch: 5| Step: 4
Training loss: 2.113458030202745
Validation loss: 2.5082415474186175

Epoch: 5| Step: 5
Training loss: 2.295580233026545
Validation loss: 2.6687454406879163

Epoch: 5| Step: 6
Training loss: 2.9366845155563936
Validation loss: 2.6533372151657715

Epoch: 5| Step: 7
Training loss: 2.5387402139209314
Validation loss: 2.5828804882171275

Epoch: 5| Step: 8
Training loss: 1.7909750231817552
Validation loss: 2.561110846558213

Epoch: 5| Step: 9
Training loss: 1.821282124442214
Validation loss: 2.57998143115575

Epoch: 5| Step: 10
Training loss: 2.397317034409604
Validation loss: 2.534458215164992

Epoch: 453| Step: 0
Training loss: 2.525095297648592
Validation loss: 2.5254922999942

Epoch: 5| Step: 1
Training loss: 2.561838948651559
Validation loss: 2.639583799108958

Epoch: 5| Step: 2
Training loss: 2.259813524165537
Validation loss: 2.616930689155462

Epoch: 5| Step: 3
Training loss: 2.138710335163599
Validation loss: 2.5747467708989626

Epoch: 5| Step: 4
Training loss: 2.524710886049329
Validation loss: 2.5372735149387977

Epoch: 5| Step: 5
Training loss: 1.9884448031025028
Validation loss: 2.5588682997884176

Epoch: 5| Step: 6
Training loss: 2.802286719748744
Validation loss: 2.5486255012487375

Epoch: 5| Step: 7
Training loss: 2.6152647328626832
Validation loss: 2.5981928943771937

Epoch: 5| Step: 8
Training loss: 2.2021233195629595
Validation loss: 2.538869429726519

Epoch: 5| Step: 9
Training loss: 1.8926424344280612
Validation loss: 2.5687927786248053

Epoch: 5| Step: 10
Training loss: 1.9897780863992407
Validation loss: 2.5780954080215217

Epoch: 454| Step: 0
Training loss: 1.8052052997696428
Validation loss: 2.5589766511998677

Epoch: 5| Step: 1
Training loss: 2.118101141044749
Validation loss: 2.6189592276350564

Epoch: 5| Step: 2
Training loss: 2.5236160640309877
Validation loss: 2.628647230576945

Epoch: 5| Step: 3
Training loss: 2.796108801546218
Validation loss: 2.5630007238860077

Epoch: 5| Step: 4
Training loss: 2.226291787271002
Validation loss: 2.4856117540893896

Epoch: 5| Step: 5
Training loss: 2.4353071276785245
Validation loss: 2.4780208524639873

Epoch: 5| Step: 6
Training loss: 2.7182032594446945
Validation loss: 2.560627245730291

Epoch: 5| Step: 7
Training loss: 2.2390231355985595
Validation loss: 2.562750050059695

Epoch: 5| Step: 8
Training loss: 2.2727152407934574
Validation loss: 2.613909259720673

Epoch: 5| Step: 9
Training loss: 2.309271130529474
Validation loss: 2.515142791131885

Epoch: 5| Step: 10
Training loss: 2.0190224809079926
Validation loss: 2.5359326742071215

Epoch: 455| Step: 0
Training loss: 1.8292932934331931
Validation loss: 2.5694074885459934

Epoch: 5| Step: 1
Training loss: 2.3185121892428087
Validation loss: 2.560830055097154

Epoch: 5| Step: 2
Training loss: 2.0528536543232
Validation loss: 2.4936261335688443

Epoch: 5| Step: 3
Training loss: 2.816636498043256
Validation loss: 2.557333405027117

Epoch: 5| Step: 4
Training loss: 2.2844447927602527
Validation loss: 2.520801281265487

Epoch: 5| Step: 5
Training loss: 2.1219784066758165
Validation loss: 2.5668533646700755

Epoch: 5| Step: 6
Training loss: 3.250257921988383
Validation loss: 2.5978929602861407

Epoch: 5| Step: 7
Training loss: 2.5533453072382524
Validation loss: 2.5210850524787904

Epoch: 5| Step: 8
Training loss: 2.3087416341699236
Validation loss: 2.597147634106151

Epoch: 5| Step: 9
Training loss: 1.515858583049531
Validation loss: 2.5575121806286716

Epoch: 5| Step: 10
Training loss: 2.6013252218828122
Validation loss: 2.5438817655088326

Epoch: 456| Step: 0
Training loss: 2.8978366280387053
Validation loss: 2.4919256051567262

Epoch: 5| Step: 1
Training loss: 2.408184809433341
Validation loss: 2.543814296614791

Epoch: 5| Step: 2
Training loss: 1.8683041860511396
Validation loss: 2.5721201672445453

Epoch: 5| Step: 3
Training loss: 2.06500369609659
Validation loss: 2.57212932643313

Epoch: 5| Step: 4
Training loss: 2.1184040248469587
Validation loss: 2.5616124814911134

Epoch: 5| Step: 5
Training loss: 3.0279986060881336
Validation loss: 2.5997720179061696

Epoch: 5| Step: 6
Training loss: 2.075120862635104
Validation loss: 2.5276491903312697

Epoch: 5| Step: 7
Training loss: 2.4287901567485815
Validation loss: 2.561044563293307

Epoch: 5| Step: 8
Training loss: 2.383868274364992
Validation loss: 2.619506808381738

Epoch: 5| Step: 9
Training loss: 1.7136641422859855
Validation loss: 2.596314995546795

Epoch: 5| Step: 10
Training loss: 2.0239629468277913
Validation loss: 2.618869829619085

Epoch: 457| Step: 0
Training loss: 2.204223899843405
Validation loss: 2.591212879454793

Epoch: 5| Step: 1
Training loss: 1.7127506629542777
Validation loss: 2.541773796009231

Epoch: 5| Step: 2
Training loss: 2.3126889744431667
Validation loss: 2.5155780909898415

Epoch: 5| Step: 3
Training loss: 2.7842848432439293
Validation loss: 2.5685158013031377

Epoch: 5| Step: 4
Training loss: 3.2430595236369837
Validation loss: 2.504465825376188

Epoch: 5| Step: 5
Training loss: 2.763175181045574
Validation loss: 2.599874039999395

Epoch: 5| Step: 6
Training loss: 2.159425139224623
Validation loss: 2.517886028807113

Epoch: 5| Step: 7
Training loss: 1.703147608055758
Validation loss: 2.544813704899673

Epoch: 5| Step: 8
Training loss: 2.2343504577569324
Validation loss: 2.560974097467613

Epoch: 5| Step: 9
Training loss: 2.2390546544344185
Validation loss: 2.670223738814033

Epoch: 5| Step: 10
Training loss: 1.832841510982134
Validation loss: 2.6478586588287016

Epoch: 458| Step: 0
Training loss: 2.1567005294939947
Validation loss: 2.490534986978292

Epoch: 5| Step: 1
Training loss: 1.7675628830057613
Validation loss: 2.5134107806283654

Epoch: 5| Step: 2
Training loss: 2.067566284630099
Validation loss: 2.475744150854337

Epoch: 5| Step: 3
Training loss: 2.139394364621794
Validation loss: 2.625111637583562

Epoch: 5| Step: 4
Training loss: 2.2411888104844544
Validation loss: 2.6209043505869474

Epoch: 5| Step: 5
Training loss: 2.5735678421484964
Validation loss: 2.577440447272257

Epoch: 5| Step: 6
Training loss: 2.2509659706909155
Validation loss: 2.546629436810881

Epoch: 5| Step: 7
Training loss: 2.660947975948945
Validation loss: 2.54470898421032

Epoch: 5| Step: 8
Training loss: 2.2341937011578055
Validation loss: 2.5766276088363442

Epoch: 5| Step: 9
Training loss: 2.6955884709261246
Validation loss: 2.6404592014548887

Epoch: 5| Step: 10
Training loss: 2.2119301229066495
Validation loss: 2.5806325919219493

Epoch: 459| Step: 0
Training loss: 2.198220821024271
Validation loss: 2.5887918992405874

Epoch: 5| Step: 1
Training loss: 2.3625714205487216
Validation loss: 2.5907618298648987

Epoch: 5| Step: 2
Training loss: 2.3553381736583985
Validation loss: 2.5771778762186024

Epoch: 5| Step: 3
Training loss: 2.0541581897160905
Validation loss: 2.5582564477836742

Epoch: 5| Step: 4
Training loss: 1.818117775114253
Validation loss: 2.6173523964970973

Epoch: 5| Step: 5
Training loss: 2.618599217701242
Validation loss: 2.5566907132765277

Epoch: 5| Step: 6
Training loss: 1.9298175968686362
Validation loss: 2.5264828748993735

Epoch: 5| Step: 7
Training loss: 2.420418479771219
Validation loss: 2.6138661457496415

Epoch: 5| Step: 8
Training loss: 2.653086225498142
Validation loss: 2.600788524954146

Epoch: 5| Step: 9
Training loss: 2.7910906259057664
Validation loss: 2.5261550808509527

Epoch: 5| Step: 10
Training loss: 1.994913129038525
Validation loss: 2.488453817904149

Epoch: 460| Step: 0
Training loss: 2.3428222854692806
Validation loss: 2.5400833710335093

Epoch: 5| Step: 1
Training loss: 1.7737431199825484
Validation loss: 2.53621735221589

Epoch: 5| Step: 2
Training loss: 2.1355649074799996
Validation loss: 2.5651951644361866

Epoch: 5| Step: 3
Training loss: 3.2270573936160316
Validation loss: 2.584022790863547

Epoch: 5| Step: 4
Training loss: 2.2974323452856127
Validation loss: 2.5443737723644846

Epoch: 5| Step: 5
Training loss: 2.077336785691069
Validation loss: 2.536946722540776

Epoch: 5| Step: 6
Training loss: 1.7103580556190625
Validation loss: 2.572451283656236

Epoch: 5| Step: 7
Training loss: 2.1089882955357497
Validation loss: 2.566268221187474

Epoch: 5| Step: 8
Training loss: 2.0521134763204603
Validation loss: 2.529590767276296

Epoch: 5| Step: 9
Training loss: 2.3401308727346595
Validation loss: 2.567768750092206

Epoch: 5| Step: 10
Training loss: 3.3062841287448714
Validation loss: 2.455406688631914

Epoch: 461| Step: 0
Training loss: 2.069862633537866
Validation loss: 2.6811683351874303

Epoch: 5| Step: 1
Training loss: 1.9118919054065229
Validation loss: 2.6025114158370615

Epoch: 5| Step: 2
Training loss: 2.264862774193018
Validation loss: 2.5703319782339773

Epoch: 5| Step: 3
Training loss: 2.1394724841005526
Validation loss: 2.4869175966090484

Epoch: 5| Step: 4
Training loss: 2.3495279933822903
Validation loss: 2.555659934653195

Epoch: 5| Step: 5
Training loss: 1.7494741739752817
Validation loss: 2.611795233538803

Epoch: 5| Step: 6
Training loss: 2.5126534676060497
Validation loss: 2.5754616203822867

Epoch: 5| Step: 7
Training loss: 2.786627125604016
Validation loss: 2.551918090399604

Epoch: 5| Step: 8
Training loss: 2.380921661087948
Validation loss: 2.5210105689956976

Epoch: 5| Step: 9
Training loss: 2.5923482945050407
Validation loss: 2.5810840235609733

Epoch: 5| Step: 10
Training loss: 2.0340884989912595
Validation loss: 2.5380682652801396

Epoch: 462| Step: 0
Training loss: 2.740776024792725
Validation loss: 2.643353658125057

Epoch: 5| Step: 1
Training loss: 2.4643668364762825
Validation loss: 2.6030381177008617

Epoch: 5| Step: 2
Training loss: 2.2797259112462873
Validation loss: 2.5598548334488074

Epoch: 5| Step: 3
Training loss: 1.8696490545972972
Validation loss: 2.6222655717770937

Epoch: 5| Step: 4
Training loss: 1.8352014892510555
Validation loss: 2.5630380689357177

Epoch: 5| Step: 5
Training loss: 2.193261542647846
Validation loss: 2.5315062731052165

Epoch: 5| Step: 6
Training loss: 2.2051565124256403
Validation loss: 2.580692598492694

Epoch: 5| Step: 7
Training loss: 1.633036912892176
Validation loss: 2.574103833593405

Epoch: 5| Step: 8
Training loss: 2.1849090490900096
Validation loss: 2.59144772441418

Epoch: 5| Step: 9
Training loss: 3.225323972767555
Validation loss: 2.6564894141844464

Epoch: 5| Step: 10
Training loss: 2.1552422421422732
Validation loss: 2.511603063367105

Epoch: 463| Step: 0
Training loss: 2.0490959872414956
Validation loss: 2.6002261127771287

Epoch: 5| Step: 1
Training loss: 2.680736636654205
Validation loss: 2.6017794063042214

Epoch: 5| Step: 2
Training loss: 1.9153344112866337
Validation loss: 2.5514451682875725

Epoch: 5| Step: 3
Training loss: 2.7774036685365866
Validation loss: 2.5017816506704125

Epoch: 5| Step: 4
Training loss: 1.8999766950683838
Validation loss: 2.5551540629465994

Epoch: 5| Step: 5
Training loss: 1.5966793141962483
Validation loss: 2.571375839139839

Epoch: 5| Step: 6
Training loss: 2.275667754884561
Validation loss: 2.6398740009840385

Epoch: 5| Step: 7
Training loss: 2.0838331258814837
Validation loss: 2.5237790382689935

Epoch: 5| Step: 8
Training loss: 2.7631967520312033
Validation loss: 2.627268993745139

Epoch: 5| Step: 9
Training loss: 2.288359341993381
Validation loss: 2.666982339016472

Epoch: 5| Step: 10
Training loss: 2.756299606188247
Validation loss: 2.5693612331791313

Epoch: 464| Step: 0
Training loss: 1.72627393978018
Validation loss: 2.596577188413259

Epoch: 5| Step: 1
Training loss: 2.795443887965151
Validation loss: 2.5659971606790895

Epoch: 5| Step: 2
Training loss: 1.9076434811166243
Validation loss: 2.5520143969636315

Epoch: 5| Step: 3
Training loss: 2.4033703107101143
Validation loss: 2.5796456400168277

Epoch: 5| Step: 4
Training loss: 2.4244190267335184
Validation loss: 2.5986560176583042

Epoch: 5| Step: 5
Training loss: 2.145036370384763
Validation loss: 2.548670180544135

Epoch: 5| Step: 6
Training loss: 2.1652529089951846
Validation loss: 2.521818710987751

Epoch: 5| Step: 7
Training loss: 2.715352796952942
Validation loss: 2.6121364632800574

Epoch: 5| Step: 8
Training loss: 2.120897034573392
Validation loss: 2.5635133365897893

Epoch: 5| Step: 9
Training loss: 2.3009534683927217
Validation loss: 2.5390973417985276

Epoch: 5| Step: 10
Training loss: 2.2386320947624876
Validation loss: 2.536666153764928

Epoch: 465| Step: 0
Training loss: 2.0583765831031577
Validation loss: 2.650977431147509

Epoch: 5| Step: 1
Training loss: 2.0744040311257077
Validation loss: 2.568965516654014

Epoch: 5| Step: 2
Training loss: 2.48528498652235
Validation loss: 2.553026755173266

Epoch: 5| Step: 3
Training loss: 2.899423107776814
Validation loss: 2.5144521580065144

Epoch: 5| Step: 4
Training loss: 1.9650728308306413
Validation loss: 2.6062015725973366

Epoch: 5| Step: 5
Training loss: 2.3236571587150197
Validation loss: 2.5565296505828776

Epoch: 5| Step: 6
Training loss: 2.0793674741516504
Validation loss: 2.5389339776085373

Epoch: 5| Step: 7
Training loss: 2.4501610605666895
Validation loss: 2.556967354312682

Epoch: 5| Step: 8
Training loss: 2.065602137082721
Validation loss: 2.5191567470377527

Epoch: 5| Step: 9
Training loss: 1.8502803821994318
Validation loss: 2.6277436773738927

Epoch: 5| Step: 10
Training loss: 2.400894149474312
Validation loss: 2.5881775251008983

Epoch: 466| Step: 0
Training loss: 2.9078925628544967
Validation loss: 2.5796944562883377

Epoch: 5| Step: 1
Training loss: 2.2599628069019904
Validation loss: 2.597577629962857

Epoch: 5| Step: 2
Training loss: 2.3829919966332382
Validation loss: 2.4781059366716343

Epoch: 5| Step: 3
Training loss: 1.7788340597871717
Validation loss: 2.6169209417548394

Epoch: 5| Step: 4
Training loss: 2.1965285221977258
Validation loss: 2.571923118432936

Epoch: 5| Step: 5
Training loss: 2.1922743874567074
Validation loss: 2.536630439735162

Epoch: 5| Step: 6
Training loss: 2.887748317857711
Validation loss: 2.547484343553888

Epoch: 5| Step: 7
Training loss: 1.9183119332815404
Validation loss: 2.511762295566543

Epoch: 5| Step: 8
Training loss: 2.262900457191278
Validation loss: 2.5391602472590535

Epoch: 5| Step: 9
Training loss: 2.2795507294569526
Validation loss: 2.5985789017825347

Epoch: 5| Step: 10
Training loss: 1.65125825185396
Validation loss: 2.595372188537858

Epoch: 467| Step: 0
Training loss: 1.566084602798897
Validation loss: 2.605317839794713

Epoch: 5| Step: 1
Training loss: 2.3966739893533027
Validation loss: 2.5214173357362433

Epoch: 5| Step: 2
Training loss: 1.9841989754528733
Validation loss: 2.5830288891882542

Epoch: 5| Step: 3
Training loss: 2.876918484336172
Validation loss: 2.6018750792122205

Epoch: 5| Step: 4
Training loss: 2.5516135477541497
Validation loss: 2.649143043826177

Epoch: 5| Step: 5
Training loss: 2.5342913593832073
Validation loss: 2.5788410225377163

Epoch: 5| Step: 6
Training loss: 1.8617413633496351
Validation loss: 2.5822460838593804

Epoch: 5| Step: 7
Training loss: 2.286484760893476
Validation loss: 2.6118406147118343

Epoch: 5| Step: 8
Training loss: 2.0615753644351327
Validation loss: 2.585864374455099

Epoch: 5| Step: 9
Training loss: 2.4358026512459197
Validation loss: 2.5309853738908896

Epoch: 5| Step: 10
Training loss: 2.391453717772273
Validation loss: 2.5211561547671537

Epoch: 468| Step: 0
Training loss: 2.755010288863173
Validation loss: 2.599359098743323

Epoch: 5| Step: 1
Training loss: 2.2678805994766713
Validation loss: 2.6173810950624556

Epoch: 5| Step: 2
Training loss: 1.9518988460729474
Validation loss: 2.5200194574950365

Epoch: 5| Step: 3
Training loss: 2.575504427639994
Validation loss: 2.599201797056302

Epoch: 5| Step: 4
Training loss: 2.1164096656228204
Validation loss: 2.558857484632692

Epoch: 5| Step: 5
Training loss: 2.062404167954441
Validation loss: 2.574257483883327

Epoch: 5| Step: 6
Training loss: 2.4871900432452407
Validation loss: 2.523783243146445

Epoch: 5| Step: 7
Training loss: 1.9040302422509923
Validation loss: 2.524061656065384

Epoch: 5| Step: 8
Training loss: 2.099007226518074
Validation loss: 2.620252972582552

Epoch: 5| Step: 9
Training loss: 2.6930368740760042
Validation loss: 2.6285256842625304

Epoch: 5| Step: 10
Training loss: 2.0236614795572887
Validation loss: 2.6095443846471547

Epoch: 469| Step: 0
Training loss: 2.3006309887663794
Validation loss: 2.630513404999701

Epoch: 5| Step: 1
Training loss: 2.135824570813352
Validation loss: 2.543164140079651

Epoch: 5| Step: 2
Training loss: 2.4337754771070252
Validation loss: 2.563703820971677

Epoch: 5| Step: 3
Training loss: 2.8670619344631123
Validation loss: 2.659685721226769

Epoch: 5| Step: 4
Training loss: 2.3561531957679427
Validation loss: 2.509065615706952

Epoch: 5| Step: 5
Training loss: 2.04949701698088
Validation loss: 2.5082095088804324

Epoch: 5| Step: 6
Training loss: 1.5678871365430012
Validation loss: 2.535185329939721

Epoch: 5| Step: 7
Training loss: 2.296253249945337
Validation loss: 2.501710689952249

Epoch: 5| Step: 8
Training loss: 1.6645549350014175
Validation loss: 2.6777636174120714

Epoch: 5| Step: 9
Training loss: 2.0917928857702974
Validation loss: 2.5323079241903406

Epoch: 5| Step: 10
Training loss: 2.472925638526982
Validation loss: 2.564134984087547

Epoch: 470| Step: 0
Training loss: 2.4223118541866375
Validation loss: 2.595711192095181

Epoch: 5| Step: 1
Training loss: 1.7398203690203566
Validation loss: 2.5746249119169895

Epoch: 5| Step: 2
Training loss: 2.2389754305705836
Validation loss: 2.580660291180046

Epoch: 5| Step: 3
Training loss: 2.1862647792519456
Validation loss: 2.609094115484385

Epoch: 5| Step: 4
Training loss: 1.6098808308444026
Validation loss: 2.605401942159809

Epoch: 5| Step: 5
Training loss: 2.8036942702395566
Validation loss: 2.6066660946309126

Epoch: 5| Step: 6
Training loss: 2.0263883658531836
Validation loss: 2.558535301269201

Epoch: 5| Step: 7
Training loss: 2.2863665122767816
Validation loss: 2.5869598494249613

Epoch: 5| Step: 8
Training loss: 1.907829943178058
Validation loss: 2.6262899677710694

Epoch: 5| Step: 9
Training loss: 2.845907210530967
Validation loss: 2.5673785457247127

Epoch: 5| Step: 10
Training loss: 2.6989145286908793
Validation loss: 2.478997391667525

Epoch: 471| Step: 0
Training loss: 2.1355876823114364
Validation loss: 2.6078758253537364

Epoch: 5| Step: 1
Training loss: 2.1544604407959294
Validation loss: 2.53792225870367

Epoch: 5| Step: 2
Training loss: 1.943026444177126
Validation loss: 2.6355481002921177

Epoch: 5| Step: 3
Training loss: 2.7779279435152366
Validation loss: 2.514173749067078

Epoch: 5| Step: 4
Training loss: 2.205157053018901
Validation loss: 2.616914152840293

Epoch: 5| Step: 5
Training loss: 2.4936037254934718
Validation loss: 2.5979336700473783

Epoch: 5| Step: 6
Training loss: 2.330156502440705
Validation loss: 2.608365809926991

Epoch: 5| Step: 7
Training loss: 3.0702096858779515
Validation loss: 2.556684859400231

Epoch: 5| Step: 8
Training loss: 2.1779526673805605
Validation loss: 2.561507348162036

Epoch: 5| Step: 9
Training loss: 1.6749100988374337
Validation loss: 2.499655242446734

Epoch: 5| Step: 10
Training loss: 2.0623419730017463
Validation loss: 2.5712979868593187

Epoch: 472| Step: 0
Training loss: 2.349958106945874
Validation loss: 2.5563570254461285

Epoch: 5| Step: 1
Training loss: 2.339448975135637
Validation loss: 2.5834201830562677

Epoch: 5| Step: 2
Training loss: 2.304288667986582
Validation loss: 2.568959977154002

Epoch: 5| Step: 3
Training loss: 2.6498529933244352
Validation loss: 2.5914481552410855

Epoch: 5| Step: 4
Training loss: 2.7469672038950343
Validation loss: 2.5857261940918175

Epoch: 5| Step: 5
Training loss: 2.552946284749956
Validation loss: 2.574632784175113

Epoch: 5| Step: 6
Training loss: 2.2164110562175265
Validation loss: 2.598171487801559

Epoch: 5| Step: 7
Training loss: 1.5671076928277137
Validation loss: 2.5221475112827236

Epoch: 5| Step: 8
Training loss: 2.6128473990867334
Validation loss: 2.5976822035050646

Epoch: 5| Step: 9
Training loss: 1.6709135624498088
Validation loss: 2.56803407312477

Epoch: 5| Step: 10
Training loss: 2.3340282994690034
Validation loss: 2.5539997980640305

Epoch: 473| Step: 0
Training loss: 1.8802430914909287
Validation loss: 2.581568003307247

Epoch: 5| Step: 1
Training loss: 2.302043782120267
Validation loss: 2.5905398298292703

Epoch: 5| Step: 2
Training loss: 2.3324444530942254
Validation loss: 2.592713197351649

Epoch: 5| Step: 3
Training loss: 1.9238903984408813
Validation loss: 2.5842320158879786

Epoch: 5| Step: 4
Training loss: 2.7195676253772847
Validation loss: 2.609338221844363

Epoch: 5| Step: 5
Training loss: 2.3439491695972765
Validation loss: 2.5919313416382606

Epoch: 5| Step: 6
Training loss: 2.1677204161684087
Validation loss: 2.445916513883556

Epoch: 5| Step: 7
Training loss: 2.1342190865669233
Validation loss: 2.579676522528932

Epoch: 5| Step: 8
Training loss: 2.4291533346012044
Validation loss: 2.5480286822350005

Epoch: 5| Step: 9
Training loss: 2.2497841413586195
Validation loss: 2.5922586695589325

Epoch: 5| Step: 10
Training loss: 2.230927481970127
Validation loss: 2.59667252085055

Epoch: 474| Step: 0
Training loss: 2.199162158949399
Validation loss: 2.625035847752623

Epoch: 5| Step: 1
Training loss: 2.616238458993447
Validation loss: 2.5965317892798274

Epoch: 5| Step: 2
Training loss: 2.2035792538538606
Validation loss: 2.612769461837073

Epoch: 5| Step: 3
Training loss: 1.7462719990594526
Validation loss: 2.497366903964856

Epoch: 5| Step: 4
Training loss: 1.9178170884220307
Validation loss: 2.4774405479299104

Epoch: 5| Step: 5
Training loss: 2.3711635321666145
Validation loss: 2.680046714475983

Epoch: 5| Step: 6
Training loss: 2.004112069489317
Validation loss: 2.5876363298168465

Epoch: 5| Step: 7
Training loss: 2.5514342332452795
Validation loss: 2.5285727398672733

Epoch: 5| Step: 8
Training loss: 2.051184274944368
Validation loss: 2.604227568539797

Epoch: 5| Step: 9
Training loss: 2.053252905079649
Validation loss: 2.5374016192952644

Epoch: 5| Step: 10
Training loss: 3.211906194169824
Validation loss: 2.6220123098223103

Epoch: 475| Step: 0
Training loss: 2.597568596529835
Validation loss: 2.5034889732382495

Epoch: 5| Step: 1
Training loss: 2.1218406528395293
Validation loss: 2.5669508326713015

Epoch: 5| Step: 2
Training loss: 2.4545003352208705
Validation loss: 2.465751054916739

Epoch: 5| Step: 3
Training loss: 2.029919702229021
Validation loss: 2.5972950669076744

Epoch: 5| Step: 4
Training loss: 2.2842661110200337
Validation loss: 2.5540536199016772

Epoch: 5| Step: 5
Training loss: 2.149170795489464
Validation loss: 2.5403256841947575

Epoch: 5| Step: 6
Training loss: 2.5687655631751776
Validation loss: 2.5214918463472293

Epoch: 5| Step: 7
Training loss: 1.6850568251267521
Validation loss: 2.547273150899923

Epoch: 5| Step: 8
Training loss: 2.046423476409466
Validation loss: 2.5369509768350937

Epoch: 5| Step: 9
Training loss: 2.4172754726663643
Validation loss: 2.525739101654307

Epoch: 5| Step: 10
Training loss: 2.671833149543175
Validation loss: 2.6286923681205585

Epoch: 476| Step: 0
Training loss: 2.147034787113426
Validation loss: 2.620106042008978

Epoch: 5| Step: 1
Training loss: 1.526485738708271
Validation loss: 2.5403622807598865

Epoch: 5| Step: 2
Training loss: 2.04820301567357
Validation loss: 2.5763098249801115

Epoch: 5| Step: 3
Training loss: 2.2354633375014203
Validation loss: 2.5808666101547404

Epoch: 5| Step: 4
Training loss: 2.032696956837138
Validation loss: 2.535534662580616

Epoch: 5| Step: 5
Training loss: 2.6818947112533214
Validation loss: 2.6043031783881396

Epoch: 5| Step: 6
Training loss: 2.8043483858522604
Validation loss: 2.581237028427483

Epoch: 5| Step: 7
Training loss: 1.5483761064077846
Validation loss: 2.591949171813789

Epoch: 5| Step: 8
Training loss: 2.15315023775632
Validation loss: 2.498324684018037

Epoch: 5| Step: 9
Training loss: 2.1596014541708692
Validation loss: 2.4824905502834604

Epoch: 5| Step: 10
Training loss: 2.961724732759471
Validation loss: 2.518775682545633

Epoch: 477| Step: 0
Training loss: 2.6662458047954534
Validation loss: 2.564963020691888

Epoch: 5| Step: 1
Training loss: 2.04548178278966
Validation loss: 2.5237507634732452

Epoch: 5| Step: 2
Training loss: 1.867716694302699
Validation loss: 2.605143736290164

Epoch: 5| Step: 3
Training loss: 2.405108887235763
Validation loss: 2.496309050709241

Epoch: 5| Step: 4
Training loss: 2.1740753225211873
Validation loss: 2.5764997632926705

Epoch: 5| Step: 5
Training loss: 2.255968654347168
Validation loss: 2.61395162564699

Epoch: 5| Step: 6
Training loss: 2.332239394108303
Validation loss: 2.46860931377766

Epoch: 5| Step: 7
Training loss: 2.536894074805538
Validation loss: 2.5197670828358802

Epoch: 5| Step: 8
Training loss: 2.616139125087572
Validation loss: 2.5478033782879455

Epoch: 5| Step: 9
Training loss: 2.325906195470263
Validation loss: 2.5398970481437244

Epoch: 5| Step: 10
Training loss: 1.5403279170887885
Validation loss: 2.5597099403864765

Epoch: 478| Step: 0
Training loss: 2.0740708120575233
Validation loss: 2.5283443799744423

Epoch: 5| Step: 1
Training loss: 2.17203241230647
Validation loss: 2.5497329764731993

Epoch: 5| Step: 2
Training loss: 1.8943141537582044
Validation loss: 2.5722891965885135

Epoch: 5| Step: 3
Training loss: 2.320258759669384
Validation loss: 2.5270975808352683

Epoch: 5| Step: 4
Training loss: 2.060634231523564
Validation loss: 2.510980616176614

Epoch: 5| Step: 5
Training loss: 1.9324777792853507
Validation loss: 2.560569911696814

Epoch: 5| Step: 6
Training loss: 2.243396712093251
Validation loss: 2.5121080898062385

Epoch: 5| Step: 7
Training loss: 3.1017995594819063
Validation loss: 2.533448914418191

Epoch: 5| Step: 8
Training loss: 1.728159584402962
Validation loss: 2.538057043316248

Epoch: 5| Step: 9
Training loss: 2.3076486992994973
Validation loss: 2.57051019188528

Epoch: 5| Step: 10
Training loss: 2.4848147788760926
Validation loss: 2.5142944553203925

Epoch: 479| Step: 0
Training loss: 2.2724157180516493
Validation loss: 2.5860642940926297

Epoch: 5| Step: 1
Training loss: 2.2222275680901546
Validation loss: 2.548447215839346

Epoch: 5| Step: 2
Training loss: 2.2585292853145145
Validation loss: 2.5607924450885244

Epoch: 5| Step: 3
Training loss: 1.9220059978220834
Validation loss: 2.5130237910662245

Epoch: 5| Step: 4
Training loss: 2.78457477165465
Validation loss: 2.554654375102193

Epoch: 5| Step: 5
Training loss: 2.2007905753374493
Validation loss: 2.568392039668007

Epoch: 5| Step: 6
Training loss: 2.4431559160081324
Validation loss: 2.589540902532963

Epoch: 5| Step: 7
Training loss: 2.5450277357707294
Validation loss: 2.553824948561596

Epoch: 5| Step: 8
Training loss: 1.9653692130605487
Validation loss: 2.5572459473664684

Epoch: 5| Step: 9
Training loss: 2.280980760545882
Validation loss: 2.532257359694474

Epoch: 5| Step: 10
Training loss: 1.7731984519333883
Validation loss: 2.5951402390083946

Epoch: 480| Step: 0
Training loss: 2.5414107042678746
Validation loss: 2.562003468994898

Epoch: 5| Step: 1
Training loss: 2.3019473580871255
Validation loss: 2.5842809712072503

Epoch: 5| Step: 2
Training loss: 1.4977025876067893
Validation loss: 2.514430156775302

Epoch: 5| Step: 3
Training loss: 2.4329340302303475
Validation loss: 2.5514822042032055

Epoch: 5| Step: 4
Training loss: 1.8210176731029202
Validation loss: 2.617348149474484

Epoch: 5| Step: 5
Training loss: 2.0862079116479637
Validation loss: 2.500592408695833

Epoch: 5| Step: 6
Training loss: 2.3587986324211245
Validation loss: 2.579702442266758

Epoch: 5| Step: 7
Training loss: 1.80861906029806
Validation loss: 2.5766159757412583

Epoch: 5| Step: 8
Training loss: 2.1907185446102426
Validation loss: 2.510823955404088

Epoch: 5| Step: 9
Training loss: 1.8917567751200914
Validation loss: 2.4848291796244317

Epoch: 5| Step: 10
Training loss: 3.2177184590807784
Validation loss: 2.546661359940055

Epoch: 481| Step: 0
Training loss: 1.9419605837631644
Validation loss: 2.65176091412926

Epoch: 5| Step: 1
Training loss: 2.6627992560329603
Validation loss: 2.5553127478395092

Epoch: 5| Step: 2
Training loss: 2.4518686953076303
Validation loss: 2.582668559956654

Epoch: 5| Step: 3
Training loss: 1.9948586302457971
Validation loss: 2.5449466185488796

Epoch: 5| Step: 4
Training loss: 2.0571539981669025
Validation loss: 2.5088531468456376

Epoch: 5| Step: 5
Training loss: 2.16496340731736
Validation loss: 2.5168069019565347

Epoch: 5| Step: 6
Training loss: 2.725407309233008
Validation loss: 2.534883867107519

Epoch: 5| Step: 7
Training loss: 1.5528110701135418
Validation loss: 2.5857549065752856

Epoch: 5| Step: 8
Training loss: 2.2832751756301572
Validation loss: 2.582044075959204

Epoch: 5| Step: 9
Training loss: 2.1405453632326705
Validation loss: 2.535426624853638

Epoch: 5| Step: 10
Training loss: 2.744634769788368
Validation loss: 2.712105189171481

Epoch: 482| Step: 0
Training loss: 2.0624724877574363
Validation loss: 2.5415257886081464

Epoch: 5| Step: 1
Training loss: 1.5616877924420816
Validation loss: 2.5734196008983163

Epoch: 5| Step: 2
Training loss: 2.6568549869692637
Validation loss: 2.5818948290042822

Epoch: 5| Step: 3
Training loss: 2.0802589875155353
Validation loss: 2.5517555520213775

Epoch: 5| Step: 4
Training loss: 1.718428980585441
Validation loss: 2.5722453042855005

Epoch: 5| Step: 5
Training loss: 2.7032312802275418
Validation loss: 2.5795048347083425

Epoch: 5| Step: 6
Training loss: 2.1292168906820925
Validation loss: 2.5521842928202294

Epoch: 5| Step: 7
Training loss: 1.7999457616051822
Validation loss: 2.6353489295872747

Epoch: 5| Step: 8
Training loss: 2.8981785414346417
Validation loss: 2.603931783276503

Epoch: 5| Step: 9
Training loss: 2.4579759003875497
Validation loss: 2.5955578616387176

Epoch: 5| Step: 10
Training loss: 2.28016406824171
Validation loss: 2.5362141742188617

Epoch: 483| Step: 0
Training loss: 2.136110655122181
Validation loss: 2.54596773112418

Epoch: 5| Step: 1
Training loss: 1.8941762060598457
Validation loss: 2.5985378025687553

Epoch: 5| Step: 2
Training loss: 2.3929261744613264
Validation loss: 2.7145827825365627

Epoch: 5| Step: 3
Training loss: 2.7300948294913012
Validation loss: 2.5774159082458494

Epoch: 5| Step: 4
Training loss: 2.344820007216216
Validation loss: 2.5613680234395786

Epoch: 5| Step: 5
Training loss: 2.2302018254728715
Validation loss: 2.454827257225897

Epoch: 5| Step: 6
Training loss: 2.5282351588897423
Validation loss: 2.5469885591362034

Epoch: 5| Step: 7
Training loss: 2.2087259723282564
Validation loss: 2.6045487544824146

Epoch: 5| Step: 8
Training loss: 1.6378119193448903
Validation loss: 2.553516376528024

Epoch: 5| Step: 9
Training loss: 2.0003802414877696
Validation loss: 2.543730352041194

Epoch: 5| Step: 10
Training loss: 2.526316697921506
Validation loss: 2.556877308337232

Epoch: 484| Step: 0
Training loss: 2.061248052537136
Validation loss: 2.51193944630329

Epoch: 5| Step: 1
Training loss: 1.6906496959299833
Validation loss: 2.609053452125335

Epoch: 5| Step: 2
Training loss: 2.0749528810597515
Validation loss: 2.5623282538324195

Epoch: 5| Step: 3
Training loss: 2.0716882129550234
Validation loss: 2.5757853930165986

Epoch: 5| Step: 4
Training loss: 2.7254956625814852
Validation loss: 2.5177465914043844

Epoch: 5| Step: 5
Training loss: 2.161547910986587
Validation loss: 2.5705934933165806

Epoch: 5| Step: 6
Training loss: 2.671181304291097
Validation loss: 2.5457370273468105

Epoch: 5| Step: 7
Training loss: 2.5231412825910646
Validation loss: 2.6330887221246497

Epoch: 5| Step: 8
Training loss: 2.023435261257509
Validation loss: 2.5321710759846434

Epoch: 5| Step: 9
Training loss: 1.7679156407948087
Validation loss: 2.5173119343692716

Epoch: 5| Step: 10
Training loss: 2.685668321117611
Validation loss: 2.4529848316706673

Epoch: 485| Step: 0
Training loss: 2.2970268562616876
Validation loss: 2.4661055160920506

Epoch: 5| Step: 1
Training loss: 2.1738984267116583
Validation loss: 2.6528737480452302

Epoch: 5| Step: 2
Training loss: 2.1756403276429017
Validation loss: 2.5258257979287784

Epoch: 5| Step: 3
Training loss: 2.122948273138647
Validation loss: 2.5273229920174693

Epoch: 5| Step: 4
Training loss: 1.5091459870602346
Validation loss: 2.6014920392999112

Epoch: 5| Step: 5
Training loss: 3.00363463524339
Validation loss: 2.565865452363455

Epoch: 5| Step: 6
Training loss: 2.5165948360709973
Validation loss: 2.5399482690227893

Epoch: 5| Step: 7
Training loss: 2.039228410657752
Validation loss: 2.6041487747726264

Epoch: 5| Step: 8
Training loss: 2.0849549912093193
Validation loss: 2.6022035897191196

Epoch: 5| Step: 9
Training loss: 2.020591236307924
Validation loss: 2.5743195032911186

Epoch: 5| Step: 10
Training loss: 2.368916802081818
Validation loss: 2.489804098527204

Epoch: 486| Step: 0
Training loss: 2.175896413826916
Validation loss: 2.51886370140735

Epoch: 5| Step: 1
Training loss: 2.323055918900285
Validation loss: 2.4686902590515

Epoch: 5| Step: 2
Training loss: 2.187195456967662
Validation loss: 2.5599659831773014

Epoch: 5| Step: 3
Training loss: 1.9623866103149772
Validation loss: 2.6120512086064394

Epoch: 5| Step: 4
Training loss: 1.8893784756491263
Validation loss: 2.574489070350188

Epoch: 5| Step: 5
Training loss: 2.456716932803033
Validation loss: 2.6055358198179506

Epoch: 5| Step: 6
Training loss: 1.9182819802143882
Validation loss: 2.508621377227203

Epoch: 5| Step: 7
Training loss: 2.110125598875523
Validation loss: 2.6397688078866834

Epoch: 5| Step: 8
Training loss: 2.123502091189604
Validation loss: 2.6379997872022853

Epoch: 5| Step: 9
Training loss: 3.2551529454923256
Validation loss: 2.563660300674912

Epoch: 5| Step: 10
Training loss: 1.9089258517916692
Validation loss: 2.5154187538216735

Epoch: 487| Step: 0
Training loss: 1.9563005191020162
Validation loss: 2.5826921219657804

Epoch: 5| Step: 1
Training loss: 1.9844571794929744
Validation loss: 2.589685827272941

Epoch: 5| Step: 2
Training loss: 2.5584729814055165
Validation loss: 2.5747177245681514

Epoch: 5| Step: 3
Training loss: 2.3691618588998455
Validation loss: 2.473949756618242

Epoch: 5| Step: 4
Training loss: 1.9175126102435716
Validation loss: 2.641759600165485

Epoch: 5| Step: 5
Training loss: 2.1139119277190987
Validation loss: 2.561197013138931

Epoch: 5| Step: 6
Training loss: 2.6795223618941164
Validation loss: 2.5774806933160685

Epoch: 5| Step: 7
Training loss: 1.8671939482637414
Validation loss: 2.587526721409158

Epoch: 5| Step: 8
Training loss: 2.2700761938541447
Validation loss: 2.513773514065554

Epoch: 5| Step: 9
Training loss: 2.623659972617737
Validation loss: 2.634968129761697

Epoch: 5| Step: 10
Training loss: 1.9581534390982351
Validation loss: 2.530166882412289

Epoch: 488| Step: 0
Training loss: 2.5901076698752563
Validation loss: 2.5589288407734188

Epoch: 5| Step: 1
Training loss: 2.610304158783241
Validation loss: 2.5277990376878363

Epoch: 5| Step: 2
Training loss: 2.545882704568764
Validation loss: 2.5884867567602177

Epoch: 5| Step: 3
Training loss: 2.47738037082308
Validation loss: 2.6105956804159343

Epoch: 5| Step: 4
Training loss: 1.6255372699793502
Validation loss: 2.4865531513127586

Epoch: 5| Step: 5
Training loss: 2.514500811048958
Validation loss: 2.5491073561684545

Epoch: 5| Step: 6
Training loss: 2.0404084539089125
Validation loss: 2.6177485156584224

Epoch: 5| Step: 7
Training loss: 1.8715642604287748
Validation loss: 2.5442157559330996

Epoch: 5| Step: 8
Training loss: 2.1082871634311986
Validation loss: 2.6168297493896393

Epoch: 5| Step: 9
Training loss: 2.4744631175331224
Validation loss: 2.6063366564098693

Epoch: 5| Step: 10
Training loss: 1.5661525758734098
Validation loss: 2.5449511352304532

Epoch: 489| Step: 0
Training loss: 1.9262733062977901
Validation loss: 2.5876706840309787

Epoch: 5| Step: 1
Training loss: 1.7145721289947276
Validation loss: 2.5421486257566364

Epoch: 5| Step: 2
Training loss: 2.1656549977348347
Validation loss: 2.5555770342410065

Epoch: 5| Step: 3
Training loss: 2.6803374544885354
Validation loss: 2.624618134310305

Epoch: 5| Step: 4
Training loss: 2.401292425095605
Validation loss: 2.56837594844069

Epoch: 5| Step: 5
Training loss: 1.9157033932251122
Validation loss: 2.5678631683161104

Epoch: 5| Step: 6
Training loss: 2.3297284640133356
Validation loss: 2.595638016461236

Epoch: 5| Step: 7
Training loss: 2.7868043108382654
Validation loss: 2.6050008662501885

Epoch: 5| Step: 8
Training loss: 1.984209008670947
Validation loss: 2.4841047452015754

Epoch: 5| Step: 9
Training loss: 2.3286299189978856
Validation loss: 2.5429015835240585

Epoch: 5| Step: 10
Training loss: 2.343529754462804
Validation loss: 2.6028283113745196

Epoch: 490| Step: 0
Training loss: 1.6505320471489706
Validation loss: 2.5574377235557026

Epoch: 5| Step: 1
Training loss: 2.448972650115886
Validation loss: 2.5642645288342956

Epoch: 5| Step: 2
Training loss: 2.2031914450723833
Validation loss: 2.616823258060227

Epoch: 5| Step: 3
Training loss: 2.9823911773960448
Validation loss: 2.5405276510202714

Epoch: 5| Step: 4
Training loss: 2.2514455178531056
Validation loss: 2.5382984631739376

Epoch: 5| Step: 5
Training loss: 2.0086738134249207
Validation loss: 2.6344419534286927

Epoch: 5| Step: 6
Training loss: 2.087781569627629
Validation loss: 2.580996377916619

Epoch: 5| Step: 7
Training loss: 1.5987149860046443
Validation loss: 2.608878054158058

Epoch: 5| Step: 8
Training loss: 2.3988058695764756
Validation loss: 2.589283869433689

Epoch: 5| Step: 9
Training loss: 2.235892893988044
Validation loss: 2.5830985464393557

Epoch: 5| Step: 10
Training loss: 2.3791059839244997
Validation loss: 2.636204507222722

Epoch: 491| Step: 0
Training loss: 2.345335563937643
Validation loss: 2.547770195079162

Epoch: 5| Step: 1
Training loss: 2.3567241404142383
Validation loss: 2.5957422306224265

Epoch: 5| Step: 2
Training loss: 1.8832540034012684
Validation loss: 2.6194376769434964

Epoch: 5| Step: 3
Training loss: 2.775834114565511
Validation loss: 2.6205497771289465

Epoch: 5| Step: 4
Training loss: 2.0222167821375483
Validation loss: 2.566264287216552

Epoch: 5| Step: 5
Training loss: 2.183602157330919
Validation loss: 2.5633835928641857

Epoch: 5| Step: 6
Training loss: 2.2416954431022167
Validation loss: 2.567828985390385

Epoch: 5| Step: 7
Training loss: 2.245960317877678
Validation loss: 2.514051435031167

Epoch: 5| Step: 8
Training loss: 2.050435587498477
Validation loss: 2.540880421214831

Epoch: 5| Step: 9
Training loss: 1.5282835739643807
Validation loss: 2.471131394937916

Epoch: 5| Step: 10
Training loss: 1.9201217966390107
Validation loss: 2.6352018007464566

Epoch: 492| Step: 0
Training loss: 2.556887831076441
Validation loss: 2.5609744102929755

Epoch: 5| Step: 1
Training loss: 2.2364543496037044
Validation loss: 2.6104980688876593

Epoch: 5| Step: 2
Training loss: 1.2908174071161649
Validation loss: 2.5474848567882855

Epoch: 5| Step: 3
Training loss: 2.1929594305402373
Validation loss: 2.5360988569324316

Epoch: 5| Step: 4
Training loss: 2.243414034967152
Validation loss: 2.54736909364814

Epoch: 5| Step: 5
Training loss: 3.3872162872535525
Validation loss: 2.532271004695943

Epoch: 5| Step: 6
Training loss: 2.2361023101738753
Validation loss: 2.583338929672081

Epoch: 5| Step: 7
Training loss: 2.1113018136586144
Validation loss: 2.5201908409108915

Epoch: 5| Step: 8
Training loss: 2.009066891222635
Validation loss: 2.612769336243899

Epoch: 5| Step: 9
Training loss: 1.767955019059341
Validation loss: 2.5134022362016952

Epoch: 5| Step: 10
Training loss: 2.1600097827336633
Validation loss: 2.5546229547728134

Epoch: 493| Step: 0
Training loss: 2.987181936275418
Validation loss: 2.5610101191820682

Epoch: 5| Step: 1
Training loss: 2.463418345896493
Validation loss: 2.562225393112313

Epoch: 5| Step: 2
Training loss: 1.377107695432805
Validation loss: 2.566488440017223

Epoch: 5| Step: 3
Training loss: 1.6640623567249793
Validation loss: 2.560386978052452

Epoch: 5| Step: 4
Training loss: 2.532126757578078
Validation loss: 2.4531403256244513

Epoch: 5| Step: 5
Training loss: 1.7663108371373006
Validation loss: 2.5929250461605204

Epoch: 5| Step: 6
Training loss: 1.8510939250632659
Validation loss: 2.612341098081219

Epoch: 5| Step: 7
Training loss: 2.317994883678935
Validation loss: 2.52882017457182

Epoch: 5| Step: 8
Training loss: 2.259412574719432
Validation loss: 2.5484838864052337

Epoch: 5| Step: 9
Training loss: 2.9329730925289823
Validation loss: 2.616103989359749

Epoch: 5| Step: 10
Training loss: 2.266453768979232
Validation loss: 2.5279152041492092

Epoch: 494| Step: 0
Training loss: 2.5226311591144874
Validation loss: 2.5111481602425436

Epoch: 5| Step: 1
Training loss: 2.097031711686043
Validation loss: 2.4927328272207987

Epoch: 5| Step: 2
Training loss: 1.9986230163125382
Validation loss: 2.582632756448429

Epoch: 5| Step: 3
Training loss: 2.6756614936704786
Validation loss: 2.5881369134775887

Epoch: 5| Step: 4
Training loss: 1.7794232956897946
Validation loss: 2.6042088867374638

Epoch: 5| Step: 5
Training loss: 2.9238819430793423
Validation loss: 2.508385797027651

Epoch: 5| Step: 6
Training loss: 2.186629312804855
Validation loss: 2.5001607638116203

Epoch: 5| Step: 7
Training loss: 1.7363649928638256
Validation loss: 2.5433915574370185

Epoch: 5| Step: 8
Training loss: 1.8165871806939642
Validation loss: 2.5967132842993563

Epoch: 5| Step: 9
Training loss: 2.6244087461630774
Validation loss: 2.56984813744576

Epoch: 5| Step: 10
Training loss: 2.0520264541824385
Validation loss: 2.537605797945232

Epoch: 495| Step: 0
Training loss: 2.1297181427417087
Validation loss: 2.5470038785976863

Epoch: 5| Step: 1
Training loss: 1.9196743034245778
Validation loss: 2.564621498108698

Epoch: 5| Step: 2
Training loss: 2.006794593552227
Validation loss: 2.638128486996361

Epoch: 5| Step: 3
Training loss: 2.163127821264932
Validation loss: 2.5912037407265562

Epoch: 5| Step: 4
Training loss: 2.7605192825149696
Validation loss: 2.5677243042760156

Epoch: 5| Step: 5
Training loss: 2.3327684626986716
Validation loss: 2.5795610676138194

Epoch: 5| Step: 6
Training loss: 2.902473867793241
Validation loss: 2.6550096041795714

Epoch: 5| Step: 7
Training loss: 1.9068371228182452
Validation loss: 2.5355882484993257

Epoch: 5| Step: 8
Training loss: 2.1827264199456176
Validation loss: 2.52251909908844

Epoch: 5| Step: 9
Training loss: 2.152051957804308
Validation loss: 2.6080353527714104

Epoch: 5| Step: 10
Training loss: 2.1005120470572796
Validation loss: 2.5698018750463585

Epoch: 496| Step: 0
Training loss: 1.9659748196701676
Validation loss: 2.5885710999411686

Epoch: 5| Step: 1
Training loss: 2.138240070385525
Validation loss: 2.4693842268303987

Epoch: 5| Step: 2
Training loss: 2.343883866619717
Validation loss: 2.5429005662947897

Epoch: 5| Step: 3
Training loss: 2.3075328784059215
Validation loss: 2.570376092711494

Epoch: 5| Step: 4
Training loss: 2.2364382520987336
Validation loss: 2.508578506810578

Epoch: 5| Step: 5
Training loss: 1.6647833753689718
Validation loss: 2.5750169591587144

Epoch: 5| Step: 6
Training loss: 2.172094320297139
Validation loss: 2.581634233309756

Epoch: 5| Step: 7
Training loss: 1.6576152428887203
Validation loss: 2.525377600640978

Epoch: 5| Step: 8
Training loss: 2.1919228663900037
Validation loss: 2.475860789242075

Epoch: 5| Step: 9
Training loss: 2.841276329579767
Validation loss: 2.6006703121659425

Epoch: 5| Step: 10
Training loss: 2.7120188554429028
Validation loss: 2.4301114107714925

Epoch: 497| Step: 0
Training loss: 1.9351723748445067
Validation loss: 2.5425096842266712

Epoch: 5| Step: 1
Training loss: 2.2545258250598543
Validation loss: 2.5735585162443093

Epoch: 5| Step: 2
Training loss: 2.6271094066547156
Validation loss: 2.5566020333351442

Epoch: 5| Step: 3
Training loss: 2.607966791140448
Validation loss: 2.550927758710679

Epoch: 5| Step: 4
Training loss: 2.5447832188340476
Validation loss: 2.5459521164340337

Epoch: 5| Step: 5
Training loss: 2.065570741711276
Validation loss: 2.51684195712027

Epoch: 5| Step: 6
Training loss: 1.7754135885736437
Validation loss: 2.560191745838618

Epoch: 5| Step: 7
Training loss: 1.3848761553428548
Validation loss: 2.528260817117475

Epoch: 5| Step: 8
Training loss: 2.3439901610353484
Validation loss: 2.5069931276731157

Epoch: 5| Step: 9
Training loss: 2.458650719364742
Validation loss: 2.5599570173101944

Epoch: 5| Step: 10
Training loss: 2.5203762323086756
Validation loss: 2.5697414101495863

Epoch: 498| Step: 0
Training loss: 2.5414910073369836
Validation loss: 2.456037356110957

Epoch: 5| Step: 1
Training loss: 2.30950300509746
Validation loss: 2.513858597672893

Epoch: 5| Step: 2
Training loss: 2.1408981928559965
Validation loss: 2.558913717934078

Epoch: 5| Step: 3
Training loss: 2.3361966298774868
Validation loss: 2.5506331166740064

Epoch: 5| Step: 4
Training loss: 2.600742978530319
Validation loss: 2.6270694222480864

Epoch: 5| Step: 5
Training loss: 2.2475349910672753
Validation loss: 2.595220855204911

Epoch: 5| Step: 6
Training loss: 2.219276150924828
Validation loss: 2.543225171830372

Epoch: 5| Step: 7
Training loss: 2.267219455948604
Validation loss: 2.5436169079781084

Epoch: 5| Step: 8
Training loss: 1.7230057480772096
Validation loss: 2.5676218304603386

Epoch: 5| Step: 9
Training loss: 1.8139122032444408
Validation loss: 2.5289536743467704

Epoch: 5| Step: 10
Training loss: 2.12022368006815
Validation loss: 2.5986237560985224

Epoch: 499| Step: 0
Training loss: 2.5994053967682778
Validation loss: 2.4804692522958756

Epoch: 5| Step: 1
Training loss: 1.9953750540801378
Validation loss: 2.659947340486663

Epoch: 5| Step: 2
Training loss: 2.046555355826685
Validation loss: 2.6084254320681337

Epoch: 5| Step: 3
Training loss: 2.1896633894561868
Validation loss: 2.614745708921421

Epoch: 5| Step: 4
Training loss: 2.953119832998125
Validation loss: 2.5759497471519515

Epoch: 5| Step: 5
Training loss: 1.6489602656623217
Validation loss: 2.577566297743186

Epoch: 5| Step: 6
Training loss: 1.5220505098190098
Validation loss: 2.6184890167878137

Epoch: 5| Step: 7
Training loss: 2.7189158246562473
Validation loss: 2.5303644676920403

Epoch: 5| Step: 8
Training loss: 2.6046701376919272
Validation loss: 2.526288841205386

Epoch: 5| Step: 9
Training loss: 1.758103749200681
Validation loss: 2.597548411583781

Epoch: 5| Step: 10
Training loss: 1.9316487712321906
Validation loss: 2.622113766736664

Epoch: 500| Step: 0
Training loss: 2.2789009227566184
Validation loss: 2.5238412295153956

Epoch: 5| Step: 1
Training loss: 1.871975939644957
Validation loss: 2.5900687137623137

Epoch: 5| Step: 2
Training loss: 2.0193308983594274
Validation loss: 2.583813430826141

Epoch: 5| Step: 3
Training loss: 1.8542201930974531
Validation loss: 2.5110626438026444

Epoch: 5| Step: 4
Training loss: 2.55705464204088
Validation loss: 2.6063296092664703

Epoch: 5| Step: 5
Training loss: 1.7395663536598425
Validation loss: 2.578971014491256

Epoch: 5| Step: 6
Training loss: 1.9000657245913162
Validation loss: 2.5650954589562693

Epoch: 5| Step: 7
Training loss: 2.852395466419512
Validation loss: 2.6482105293992775

Epoch: 5| Step: 8
Training loss: 2.0216102155502043
Validation loss: 2.556670259746273

Epoch: 5| Step: 9
Training loss: 2.5731431395489186
Validation loss: 2.5536795095782203

Epoch: 5| Step: 10
Training loss: 3.1716303989450294
Validation loss: 2.4917688400315243

Epoch: 501| Step: 0
Training loss: 1.9905224592546347
Validation loss: 2.638433511220073

Epoch: 5| Step: 1
Training loss: 1.7872754629532779
Validation loss: 2.542515726019366

Epoch: 5| Step: 2
Training loss: 2.5400866511725715
Validation loss: 2.6017681339756256

Epoch: 5| Step: 3
Training loss: 1.992182353891944
Validation loss: 2.5545637086883906

Epoch: 5| Step: 4
Training loss: 1.8970345544719516
Validation loss: 2.5437641493017864

Epoch: 5| Step: 5
Training loss: 1.9275402524037832
Validation loss: 2.567683009722263

Epoch: 5| Step: 6
Training loss: 2.1677408734405423
Validation loss: 2.588911708025753

Epoch: 5| Step: 7
Training loss: 2.4525746499618015
Validation loss: 2.6123802186253013

Epoch: 5| Step: 8
Training loss: 2.676999715446654
Validation loss: 2.517972443640448

Epoch: 5| Step: 9
Training loss: 2.4970497843615043
Validation loss: 2.605316483838192

Epoch: 5| Step: 10
Training loss: 2.1997742840544694
Validation loss: 2.61629244970572

Epoch: 502| Step: 0
Training loss: 2.3746970134011924
Validation loss: 2.516555552877551

Epoch: 5| Step: 1
Training loss: 2.2746436206742846
Validation loss: 2.4999071298802793

Epoch: 5| Step: 2
Training loss: 1.956512869824011
Validation loss: 2.6226474613419253

Epoch: 5| Step: 3
Training loss: 2.4527644967679274
Validation loss: 2.545729062712095

Epoch: 5| Step: 4
Training loss: 2.195105926460349
Validation loss: 2.5434634039142177

Epoch: 5| Step: 5
Training loss: 2.7878430689972413
Validation loss: 2.540428922009208

Epoch: 5| Step: 6
Training loss: 2.169544533952287
Validation loss: 2.6018977963061083

Epoch: 5| Step: 7
Training loss: 1.839477372996967
Validation loss: 2.5071066475527624

Epoch: 5| Step: 8
Training loss: 1.8165199818434823
Validation loss: 2.4851410831920213

Epoch: 5| Step: 9
Training loss: 1.7040845635120987
Validation loss: 2.5425345803131703

Epoch: 5| Step: 10
Training loss: 2.0856814566639543
Validation loss: 2.6016762311443413

Epoch: 503| Step: 0
Training loss: 2.0549574990065826
Validation loss: 2.579862613751425

Epoch: 5| Step: 1
Training loss: 1.909539058648423
Validation loss: 2.5403181062663194

Epoch: 5| Step: 2
Training loss: 2.0663823665399668
Validation loss: 2.548083619199235

Epoch: 5| Step: 3
Training loss: 1.894942783609169
Validation loss: 2.4685500004106253

Epoch: 5| Step: 4
Training loss: 2.262464858145753
Validation loss: 2.5721071123917096

Epoch: 5| Step: 5
Training loss: 2.674657075951605
Validation loss: 2.510544019826926

Epoch: 5| Step: 6
Training loss: 2.321376055867538
Validation loss: 2.578462337873619

Epoch: 5| Step: 7
Training loss: 2.4049666313981213
Validation loss: 2.597806832575663

Epoch: 5| Step: 8
Training loss: 1.6366101504329373
Validation loss: 2.6546526715253815

Epoch: 5| Step: 9
Training loss: 2.098200153894576
Validation loss: 2.4986185820501765

Epoch: 5| Step: 10
Training loss: 2.0277816505337083
Validation loss: 2.5814321805090312

Epoch: 504| Step: 0
Training loss: 2.2070620374304504
Validation loss: 2.495458846421023

Epoch: 5| Step: 1
Training loss: 2.255922470201234
Validation loss: 2.5450129292274495

Epoch: 5| Step: 2
Training loss: 2.7828479419745262
Validation loss: 2.5162925876421056

Epoch: 5| Step: 3
Training loss: 2.0992345005093314
Validation loss: 2.5281241007013238

Epoch: 5| Step: 4
Training loss: 2.814932894135547
Validation loss: 2.5402277436062253

Epoch: 5| Step: 5
Training loss: 2.4601584518388844
Validation loss: 2.550378319208781

Epoch: 5| Step: 6
Training loss: 1.5926985918956746
Validation loss: 2.489992670742845

Epoch: 5| Step: 7
Training loss: 1.574635339332183
Validation loss: 2.515739059741399

Epoch: 5| Step: 8
Training loss: 2.2926133252403957
Validation loss: 2.5892172152861828

Epoch: 5| Step: 9
Training loss: 2.2875292333183705
Validation loss: 2.5501421173999774

Epoch: 5| Step: 10
Training loss: 2.2939520681906163
Validation loss: 2.522666617075298

Epoch: 505| Step: 0
Training loss: 2.164203955919447
Validation loss: 2.546549144267287

Epoch: 5| Step: 1
Training loss: 2.0179804560506023
Validation loss: 2.561850036419893

Epoch: 5| Step: 2
Training loss: 2.492616144227217
Validation loss: 2.5042192172231887

Epoch: 5| Step: 3
Training loss: 2.3984125490164407
Validation loss: 2.56817815914835

Epoch: 5| Step: 4
Training loss: 2.1882488603792694
Validation loss: 2.5446982947498498

Epoch: 5| Step: 5
Training loss: 2.3395081854210513
Validation loss: 2.5482590356828565

Epoch: 5| Step: 6
Training loss: 2.8151295555209668
Validation loss: 2.5708385061084122

Epoch: 5| Step: 7
Training loss: 1.703599006415904
Validation loss: 2.561273683073048

Epoch: 5| Step: 8
Training loss: 1.8327609237867786
Validation loss: 2.5581184783059747

Epoch: 5| Step: 9
Training loss: 1.9871731351383308
Validation loss: 2.449586428052372

Epoch: 5| Step: 10
Training loss: 1.936943528033067
Validation loss: 2.502058152058442

Epoch: 506| Step: 0
Training loss: 2.310085685924281
Validation loss: 2.588402674286257

Epoch: 5| Step: 1
Training loss: 1.6272316793821984
Validation loss: 2.571049099181733

Epoch: 5| Step: 2
Training loss: 2.105298660004072
Validation loss: 2.6179110823908256

Epoch: 5| Step: 3
Training loss: 2.0184474375837915
Validation loss: 2.6058533461181956

Epoch: 5| Step: 4
Training loss: 1.3358613823515808
Validation loss: 2.621904017254498

Epoch: 5| Step: 5
Training loss: 1.96580369679857
Validation loss: 2.6026606290734793

Epoch: 5| Step: 6
Training loss: 2.0145375475041303
Validation loss: 2.617777165811761

Epoch: 5| Step: 7
Training loss: 2.821700327928376
Validation loss: 2.5335652852639736

Epoch: 5| Step: 8
Training loss: 2.7519909847300372
Validation loss: 2.4677236512630287

Epoch: 5| Step: 9
Training loss: 2.1773419629634754
Validation loss: 2.5501128270078812

Epoch: 5| Step: 10
Training loss: 2.1596240859173537
Validation loss: 2.5891371419008817

Epoch: 507| Step: 0
Training loss: 1.6613215407100448
Validation loss: 2.5301904814388982

Epoch: 5| Step: 1
Training loss: 2.0513605952508804
Validation loss: 2.5296323786137753

Epoch: 5| Step: 2
Training loss: 2.1531914289660707
Validation loss: 2.5558420862261535

Epoch: 5| Step: 3
Training loss: 2.087811717441631
Validation loss: 2.5629530122827133

Epoch: 5| Step: 4
Training loss: 2.099300940281362
Validation loss: 2.5946807767749247

Epoch: 5| Step: 5
Training loss: 2.2064294585382447
Validation loss: 2.582276868258855

Epoch: 5| Step: 6
Training loss: 2.4582200320583962
Validation loss: 2.6109126694215936

Epoch: 5| Step: 7
Training loss: 2.090351820176857
Validation loss: 2.567705286499231

Epoch: 5| Step: 8
Training loss: 2.7974528136718337
Validation loss: 2.5958444614619913

Epoch: 5| Step: 9
Training loss: 2.5720409390764285
Validation loss: 2.48002259357791

Epoch: 5| Step: 10
Training loss: 1.4725580562163287
Validation loss: 2.5520055453056387

Epoch: 508| Step: 0
Training loss: 2.6027369325577445
Validation loss: 2.5182480483950584

Epoch: 5| Step: 1
Training loss: 2.0304251536627653
Validation loss: 2.536852317813169

Epoch: 5| Step: 2
Training loss: 1.9683991376884633
Validation loss: 2.622726997440966

Epoch: 5| Step: 3
Training loss: 2.4290670602398134
Validation loss: 2.5518391421840834

Epoch: 5| Step: 4
Training loss: 1.8046503104469342
Validation loss: 2.604170681529898

Epoch: 5| Step: 5
Training loss: 1.7943681562260643
Validation loss: 2.5642973716312243

Epoch: 5| Step: 6
Training loss: 2.5203183386321766
Validation loss: 2.6126212841860204

Epoch: 5| Step: 7
Training loss: 2.4843813338288956
Validation loss: 2.516383921873065

Epoch: 5| Step: 8
Training loss: 1.977144298946696
Validation loss: 2.5496943838189425

Epoch: 5| Step: 9
Training loss: 2.5990421584886927
Validation loss: 2.57689974778188

Epoch: 5| Step: 10
Training loss: 1.7017005072780396
Validation loss: 2.4890252564479645

Epoch: 509| Step: 0
Training loss: 1.7525289518438152
Validation loss: 2.515822821459105

Epoch: 5| Step: 1
Training loss: 2.009942375989263
Validation loss: 2.519173819214632

Epoch: 5| Step: 2
Training loss: 2.1115712353168736
Validation loss: 2.5757281545339867

Epoch: 5| Step: 3
Training loss: 1.9825469480249507
Validation loss: 2.586996630594727

Epoch: 5| Step: 4
Training loss: 1.88381652653807
Validation loss: 2.469554234812742

Epoch: 5| Step: 5
Training loss: 2.85649105198422
Validation loss: 2.554462577625052

Epoch: 5| Step: 6
Training loss: 2.113661641914103
Validation loss: 2.544430256242904

Epoch: 5| Step: 7
Training loss: 2.469438094808079
Validation loss: 2.5410737129883896

Epoch: 5| Step: 8
Training loss: 2.1908661147787516
Validation loss: 2.6030796934366993

Epoch: 5| Step: 9
Training loss: 2.115809030572305
Validation loss: 2.5702517673371337

Epoch: 5| Step: 10
Training loss: 2.456025273960304
Validation loss: 2.5356621359406626

Epoch: 510| Step: 0
Training loss: 2.3388808471025966
Validation loss: 2.5013612476480516

Epoch: 5| Step: 1
Training loss: 1.864272199987862
Validation loss: 2.5403719798108053

Epoch: 5| Step: 2
Training loss: 2.2219047147370765
Validation loss: 2.571809429213548

Epoch: 5| Step: 3
Training loss: 2.6396300117281433
Validation loss: 2.5992848644534203

Epoch: 5| Step: 4
Training loss: 2.0765910976900614
Validation loss: 2.60491382602703

Epoch: 5| Step: 5
Training loss: 2.4482894180787764
Validation loss: 2.5673937225512526

Epoch: 5| Step: 6
Training loss: 2.3469474852399492
Validation loss: 2.640649531226769

Epoch: 5| Step: 7
Training loss: 2.071800877322591
Validation loss: 2.61112698068933

Epoch: 5| Step: 8
Training loss: 2.430670242025843
Validation loss: 2.532247845203436

Epoch: 5| Step: 9
Training loss: 1.6487680980507544
Validation loss: 2.543537863872837

Epoch: 5| Step: 10
Training loss: 1.66416780380391
Validation loss: 2.5156325830146455

Epoch: 511| Step: 0
Training loss: 2.252502956578964
Validation loss: 2.6111718123794176

Epoch: 5| Step: 1
Training loss: 2.333687096980606
Validation loss: 2.5832505993556962

Epoch: 5| Step: 2
Training loss: 2.7830309362854337
Validation loss: 2.5653027509408597

Epoch: 5| Step: 3
Training loss: 1.6091910692310876
Validation loss: 2.594481239474553

Epoch: 5| Step: 4
Training loss: 2.2311094736677513
Validation loss: 2.5476557520552494

Epoch: 5| Step: 5
Training loss: 1.5151051681828218
Validation loss: 2.5064904100791328

Epoch: 5| Step: 6
Training loss: 2.3176034853647325
Validation loss: 2.6015234099298032

Epoch: 5| Step: 7
Training loss: 2.288322563488708
Validation loss: 2.5077923572748375

Epoch: 5| Step: 8
Training loss: 2.3831371649014708
Validation loss: 2.541877018377084

Epoch: 5| Step: 9
Training loss: 2.43823328970224
Validation loss: 2.522942528042941

Epoch: 5| Step: 10
Training loss: 2.0387079507969204
Validation loss: 2.5733965487268065

Epoch: 512| Step: 0
Training loss: 2.615845019932267
Validation loss: 2.5316961485983227

Epoch: 5| Step: 1
Training loss: 1.9420158918066404
Validation loss: 2.563031343346091

Epoch: 5| Step: 2
Training loss: 2.5959138232182677
Validation loss: 2.591327812757817

Epoch: 5| Step: 3
Training loss: 1.7361735735359118
Validation loss: 2.52006584944945

Epoch: 5| Step: 4
Training loss: 2.593812505129771
Validation loss: 2.6017713895552634

Epoch: 5| Step: 5
Training loss: 1.8739130684384948
Validation loss: 2.5527270026257862

Epoch: 5| Step: 6
Training loss: 1.5330368048970864
Validation loss: 2.5631297428439606

Epoch: 5| Step: 7
Training loss: 2.504796005440289
Validation loss: 2.559987244564627

Epoch: 5| Step: 8
Training loss: 1.8992417127381498
Validation loss: 2.5832779455317283

Epoch: 5| Step: 9
Training loss: 2.36818691596576
Validation loss: 2.6163955727011086

Epoch: 5| Step: 10
Training loss: 1.9768181435739256
Validation loss: 2.5463852020417406

Epoch: 513| Step: 0
Training loss: 2.74270190334665
Validation loss: 2.5804772766555977

Epoch: 5| Step: 1
Training loss: 2.138832176854816
Validation loss: 2.554724354443784

Epoch: 5| Step: 2
Training loss: 2.17648441040429
Validation loss: 2.6220942204853674

Epoch: 5| Step: 3
Training loss: 2.5664619892634266
Validation loss: 2.5819227674188503

Epoch: 5| Step: 4
Training loss: 2.204174684487118
Validation loss: 2.574411473538528

Epoch: 5| Step: 5
Training loss: 2.4251128180304895
Validation loss: 2.5921206535229477

Epoch: 5| Step: 6
Training loss: 2.3819989926314444
Validation loss: 2.5691505456572012

Epoch: 5| Step: 7
Training loss: 1.6859614104518996
Validation loss: 2.538814478167535

Epoch: 5| Step: 8
Training loss: 2.3375987394153244
Validation loss: 2.6033466752848944

Epoch: 5| Step: 9
Training loss: 1.4653414681781263
Validation loss: 2.45301540096746

Epoch: 5| Step: 10
Training loss: 1.563266032315011
Validation loss: 2.586044651328756

Epoch: 514| Step: 0
Training loss: 1.848241088441169
Validation loss: 2.5260396362201805

Epoch: 5| Step: 1
Training loss: 1.904047271802853
Validation loss: 2.596533949562786

Epoch: 5| Step: 2
Training loss: 1.9363426320308075
Validation loss: 2.635968660031033

Epoch: 5| Step: 3
Training loss: 2.0864444645233284
Validation loss: 2.5898640741848054

Epoch: 5| Step: 4
Training loss: 2.4250423270395407
Validation loss: 2.661205532032087

Epoch: 5| Step: 5
Training loss: 2.470376649780062
Validation loss: 2.502839619980642

Epoch: 5| Step: 6
Training loss: 1.839794376949986
Validation loss: 2.533883713124594

Epoch: 5| Step: 7
Training loss: 2.0049544004358673
Validation loss: 2.532468781130782

Epoch: 5| Step: 8
Training loss: 2.2765645023879104
Validation loss: 2.581672500436086

Epoch: 5| Step: 9
Training loss: 2.717890724231032
Validation loss: 2.564844801446341

Epoch: 5| Step: 10
Training loss: 1.9573631385908152
Validation loss: 2.48562897106016

Epoch: 515| Step: 0
Training loss: 1.9413683022180974
Validation loss: 2.62475216091576

Epoch: 5| Step: 1
Training loss: 2.0660964358590057
Validation loss: 2.592513207504323

Epoch: 5| Step: 2
Training loss: 2.129924229809935
Validation loss: 2.6063088444518314

Epoch: 5| Step: 3
Training loss: 1.6066672499379937
Validation loss: 2.5889691263816417

Epoch: 5| Step: 4
Training loss: 2.69038103616969
Validation loss: 2.6110076659805426

Epoch: 5| Step: 5
Training loss: 1.6222309581892966
Validation loss: 2.58036945550078

Epoch: 5| Step: 6
Training loss: 2.4553278854410494
Validation loss: 2.5854839986456786

Epoch: 5| Step: 7
Training loss: 2.1040186940149566
Validation loss: 2.5439311798863935

Epoch: 5| Step: 8
Training loss: 2.420598044153019
Validation loss: 2.582582606481992

Epoch: 5| Step: 9
Training loss: 2.144253405306428
Validation loss: 2.61051580269329

Epoch: 5| Step: 10
Training loss: 2.4003604300379133
Validation loss: 2.567955546497061

Epoch: 516| Step: 0
Training loss: 2.8845449478157277
Validation loss: 2.580400179827675

Epoch: 5| Step: 1
Training loss: 2.234140450497969
Validation loss: 2.5926798819433046

Epoch: 5| Step: 2
Training loss: 2.303746952876592
Validation loss: 2.542255854454556

Epoch: 5| Step: 3
Training loss: 1.8521231273356655
Validation loss: 2.5213721069161603

Epoch: 5| Step: 4
Training loss: 2.2181466585178375
Validation loss: 2.509468714214445

Epoch: 5| Step: 5
Training loss: 1.7663870998122289
Validation loss: 2.6800826887556193

Epoch: 5| Step: 6
Training loss: 2.4161631509059265
Validation loss: 2.4991245387895296

Epoch: 5| Step: 7
Training loss: 1.8286018727739914
Validation loss: 2.646697916537249

Epoch: 5| Step: 8
Training loss: 1.7955694348414695
Validation loss: 2.602032337027098

Epoch: 5| Step: 9
Training loss: 2.173189492682577
Validation loss: 2.540495768378058

Epoch: 5| Step: 10
Training loss: 1.9420819401921883
Validation loss: 2.5848062368870175

Epoch: 517| Step: 0
Training loss: 2.2244136680678377
Validation loss: 2.5463945454133756

Epoch: 5| Step: 1
Training loss: 1.8405021250825742
Validation loss: 2.6165636161727286

Epoch: 5| Step: 2
Training loss: 2.3639388249351736
Validation loss: 2.543659565305127

Epoch: 5| Step: 3
Training loss: 2.321215110438544
Validation loss: 2.5470926833584597

Epoch: 5| Step: 4
Training loss: 1.7863533130023612
Validation loss: 2.6081085914467663

Epoch: 5| Step: 5
Training loss: 2.277771060695927
Validation loss: 2.50657620268417

Epoch: 5| Step: 6
Training loss: 2.0359487326861805
Validation loss: 2.542301012747771

Epoch: 5| Step: 7
Training loss: 2.3219822485324904
Validation loss: 2.5833327481616175

Epoch: 5| Step: 8
Training loss: 2.063941105312831
Validation loss: 2.5251303108465954

Epoch: 5| Step: 9
Training loss: 2.9440758332457837
Validation loss: 2.545321745521976

Epoch: 5| Step: 10
Training loss: 1.8810461472483877
Validation loss: 2.5097745709846158

Epoch: 518| Step: 0
Training loss: 2.189527171751893
Validation loss: 2.6212274971372302

Epoch: 5| Step: 1
Training loss: 2.0031826207388157
Validation loss: 2.6235611679058497

Epoch: 5| Step: 2
Training loss: 1.9657736790257083
Validation loss: 2.48356831092643

Epoch: 5| Step: 3
Training loss: 2.3818667676868976
Validation loss: 2.5518419491039546

Epoch: 5| Step: 4
Training loss: 2.4064723320834185
Validation loss: 2.535053457824396

Epoch: 5| Step: 5
Training loss: 2.397293364656651
Validation loss: 2.550627182558347

Epoch: 5| Step: 6
Training loss: 2.1569524533014683
Validation loss: 2.4531871692938174

Epoch: 5| Step: 7
Training loss: 2.094303684187263
Validation loss: 2.5781691581297923

Epoch: 5| Step: 8
Training loss: 2.0649127141871917
Validation loss: 2.6259944026477404

Epoch: 5| Step: 9
Training loss: 1.9619031253583892
Validation loss: 2.5282989587112064

Epoch: 5| Step: 10
Training loss: 1.8639103689091454
Validation loss: 2.4868983974568994

Epoch: 519| Step: 0
Training loss: 1.9068614416850098
Validation loss: 2.5883244125170433

Epoch: 5| Step: 1
Training loss: 1.8498889425811575
Validation loss: 2.531528625183464

Epoch: 5| Step: 2
Training loss: 2.9144123266268838
Validation loss: 2.4589831677143357

Epoch: 5| Step: 3
Training loss: 2.730523235776118
Validation loss: 2.519608982264221

Epoch: 5| Step: 4
Training loss: 2.655521247975566
Validation loss: 2.5842231014738153

Epoch: 5| Step: 5
Training loss: 1.802922562419907
Validation loss: 2.4957836250601737

Epoch: 5| Step: 6
Training loss: 1.8593712173551662
Validation loss: 2.584401651745895

Epoch: 5| Step: 7
Training loss: 1.9323135607799455
Validation loss: 2.5331541581604284

Epoch: 5| Step: 8
Training loss: 2.1599990759953536
Validation loss: 2.5737709067773484

Epoch: 5| Step: 9
Training loss: 1.8034305571450706
Validation loss: 2.5164270922888123

Epoch: 5| Step: 10
Training loss: 1.5942311776018996
Validation loss: 2.5701872668599437

Epoch: 520| Step: 0
Training loss: 1.804082727865647
Validation loss: 2.5569750984593758

Epoch: 5| Step: 1
Training loss: 1.928733064548707
Validation loss: 2.5802254203437833

Epoch: 5| Step: 2
Training loss: 2.607942656325411
Validation loss: 2.554651247135909

Epoch: 5| Step: 3
Training loss: 1.7777626298550464
Validation loss: 2.543741908769432

Epoch: 5| Step: 4
Training loss: 1.6119588461372127
Validation loss: 2.555378287404496

Epoch: 5| Step: 5
Training loss: 2.479392375341854
Validation loss: 2.5705424562264088

Epoch: 5| Step: 6
Training loss: 2.631464129001047
Validation loss: 2.588476805188878

Epoch: 5| Step: 7
Training loss: 1.9019037321379308
Validation loss: 2.490586395444149

Epoch: 5| Step: 8
Training loss: 1.9509509384423238
Validation loss: 2.635877950612186

Epoch: 5| Step: 9
Training loss: 1.9156339461598428
Validation loss: 2.5479377860879824

Epoch: 5| Step: 10
Training loss: 2.3548041524260483
Validation loss: 2.6408616399436333

Epoch: 521| Step: 0
Training loss: 2.1315123679016788
Validation loss: 2.5649731879272313

Epoch: 5| Step: 1
Training loss: 2.1994414140582403
Validation loss: 2.5751742125136765

Epoch: 5| Step: 2
Training loss: 1.9018313365967363
Validation loss: 2.5339009460947692

Epoch: 5| Step: 3
Training loss: 2.197007254774767
Validation loss: 2.536465130730512

Epoch: 5| Step: 4
Training loss: 2.2036123615975534
Validation loss: 2.601945870445878

Epoch: 5| Step: 5
Training loss: 1.5199382011499485
Validation loss: 2.601331731190095

Epoch: 5| Step: 6
Training loss: 2.734004142679956
Validation loss: 2.5963959573857314

Epoch: 5| Step: 7
Training loss: 1.6781784020705384
Validation loss: 2.5953975149343846

Epoch: 5| Step: 8
Training loss: 2.7189373083375648
Validation loss: 2.5431985083580724

Epoch: 5| Step: 9
Training loss: 2.2545445429263133
Validation loss: 2.5058257775349126

Epoch: 5| Step: 10
Training loss: 1.9702552006593201
Validation loss: 2.5763322276709477

Epoch: 522| Step: 0
Training loss: 1.9543866164567039
Validation loss: 2.5660142609033536

Epoch: 5| Step: 1
Training loss: 1.9963009123977191
Validation loss: 2.4751457949103193

Epoch: 5| Step: 2
Training loss: 1.8016615430963143
Validation loss: 2.537555380943846

Epoch: 5| Step: 3
Training loss: 2.1410194646101086
Validation loss: 2.467071040168184

Epoch: 5| Step: 4
Training loss: 2.2751932083082167
Validation loss: 2.647031858671345

Epoch: 5| Step: 5
Training loss: 1.6340704639654386
Validation loss: 2.571493003944277

Epoch: 5| Step: 6
Training loss: 1.8232567024981277
Validation loss: 2.5055003406732186

Epoch: 5| Step: 7
Training loss: 3.0241974262499816
Validation loss: 2.581938881950385

Epoch: 5| Step: 8
Training loss: 2.1161644071877523
Validation loss: 2.5402496606739535

Epoch: 5| Step: 9
Training loss: 2.451008168867203
Validation loss: 2.6290970953226305

Epoch: 5| Step: 10
Training loss: 1.9092669142677778
Validation loss: 2.5115984333820527

Epoch: 523| Step: 0
Training loss: 2.342935853061295
Validation loss: 2.551792314187852

Epoch: 5| Step: 1
Training loss: 1.9583473272702892
Validation loss: 2.5479019785087997

Epoch: 5| Step: 2
Training loss: 2.5161907436558684
Validation loss: 2.580928010847282

Epoch: 5| Step: 3
Training loss: 1.7539537589046794
Validation loss: 2.5764429476482906

Epoch: 5| Step: 4
Training loss: 2.2321262380798736
Validation loss: 2.533234203803035

Epoch: 5| Step: 5
Training loss: 2.049268764244732
Validation loss: 2.494408022161855

Epoch: 5| Step: 6
Training loss: 1.9168418790370652
Validation loss: 2.6789728060247273

Epoch: 5| Step: 7
Training loss: 2.546659495591591
Validation loss: 2.5867048889013358

Epoch: 5| Step: 8
Training loss: 2.033145665539547
Validation loss: 2.5710147028502415

Epoch: 5| Step: 9
Training loss: 1.9492956845804774
Validation loss: 2.5200219234529246

Epoch: 5| Step: 10
Training loss: 2.229186215418962
Validation loss: 2.550078560963957

Epoch: 524| Step: 0
Training loss: 2.30152557198396
Validation loss: 2.53330266589345

Epoch: 5| Step: 1
Training loss: 2.196454277286899
Validation loss: 2.6276692298307336

Epoch: 5| Step: 2
Training loss: 2.698149583893189
Validation loss: 2.5536314042116013

Epoch: 5| Step: 3
Training loss: 1.9183942085945453
Validation loss: 2.5895262703193507

Epoch: 5| Step: 4
Training loss: 2.206204041604801
Validation loss: 2.638042381391438

Epoch: 5| Step: 5
Training loss: 2.3586568181443455
Validation loss: 2.518864133962385

Epoch: 5| Step: 6
Training loss: 2.304835945133248
Validation loss: 2.5758848121098885

Epoch: 5| Step: 7
Training loss: 1.6456569705904402
Validation loss: 2.639234399619706

Epoch: 5| Step: 8
Training loss: 2.7092045678693157
Validation loss: 2.588116562852529

Epoch: 5| Step: 9
Training loss: 2.1657986613961424
Validation loss: 2.5918148158939633

Epoch: 5| Step: 10
Training loss: 1.8348781694927605
Validation loss: 2.590301813682719

Epoch: 525| Step: 0
Training loss: 2.34215745862103
Validation loss: 2.587454631079329

Epoch: 5| Step: 1
Training loss: 2.3630646409319613
Validation loss: 2.5864278216148175

Epoch: 5| Step: 2
Training loss: 2.21175668590247
Validation loss: 2.5511172101843176

Epoch: 5| Step: 3
Training loss: 2.64472002851641
Validation loss: 2.5453877311835047

Epoch: 5| Step: 4
Training loss: 2.0154147962627627
Validation loss: 2.6073909509273787

Epoch: 5| Step: 5
Training loss: 1.7694812624441292
Validation loss: 2.516876427130757

Epoch: 5| Step: 6
Training loss: 1.9970624331293216
Validation loss: 2.554204112267253

Epoch: 5| Step: 7
Training loss: 1.7341650758461329
Validation loss: 2.6004772505129408

Epoch: 5| Step: 8
Training loss: 1.5686885350561084
Validation loss: 2.487067807114815

Epoch: 5| Step: 9
Training loss: 3.101291442864799
Validation loss: 2.541572640339193

Epoch: 5| Step: 10
Training loss: 1.498942558765802
Validation loss: 2.596777609653018

Epoch: 526| Step: 0
Training loss: 2.0592408294269764
Validation loss: 2.576764473847755

Epoch: 5| Step: 1
Training loss: 2.24692176483681
Validation loss: 2.543533267828868

Epoch: 5| Step: 2
Training loss: 1.9635342733579588
Validation loss: 2.5381895249804662

Epoch: 5| Step: 3
Training loss: 2.6763530482230684
Validation loss: 2.5638286888531012

Epoch: 5| Step: 4
Training loss: 2.3180692470301874
Validation loss: 2.5497267637619343

Epoch: 5| Step: 5
Training loss: 2.3542864158579064
Validation loss: 2.5714438390636656

Epoch: 5| Step: 6
Training loss: 2.1251170182265273
Validation loss: 2.6298600992884196

Epoch: 5| Step: 7
Training loss: 1.8217006514864342
Validation loss: 2.564580560444809

Epoch: 5| Step: 8
Training loss: 1.8582604537951062
Validation loss: 2.5409354602652687

Epoch: 5| Step: 9
Training loss: 1.9911664552757402
Validation loss: 2.565184662782623

Epoch: 5| Step: 10
Training loss: 2.172860450297834
Validation loss: 2.53990874141626

Epoch: 527| Step: 0
Training loss: 2.032153002220151
Validation loss: 2.489146952039062

Epoch: 5| Step: 1
Training loss: 2.501531322697171
Validation loss: 2.5888063959756074

Epoch: 5| Step: 2
Training loss: 2.0446791190527027
Validation loss: 2.4826126126691275

Epoch: 5| Step: 3
Training loss: 2.0145247657675664
Validation loss: 2.571319848467556

Epoch: 5| Step: 4
Training loss: 2.2833784442352933
Validation loss: 2.5247378772781723

Epoch: 5| Step: 5
Training loss: 2.1985830468947536
Validation loss: 2.430294559683447

Epoch: 5| Step: 6
Training loss: 1.9521417202626428
Validation loss: 2.5894521645106843

Epoch: 5| Step: 7
Training loss: 2.2437807596377497
Validation loss: 2.5373639307739477

Epoch: 5| Step: 8
Training loss: 2.205563109241088
Validation loss: 2.6839971367400595

Epoch: 5| Step: 9
Training loss: 1.8391502677049247
Validation loss: 2.61057100671496

Epoch: 5| Step: 10
Training loss: 2.55671895769036
Validation loss: 2.5385325262557776

Epoch: 528| Step: 0
Training loss: 1.831397754319795
Validation loss: 2.5576136832641647

Epoch: 5| Step: 1
Training loss: 2.6217029392314277
Validation loss: 2.5518453025353147

Epoch: 5| Step: 2
Training loss: 1.8027413844409368
Validation loss: 2.489912336656035

Epoch: 5| Step: 3
Training loss: 2.1120811904993686
Validation loss: 2.554585473657906

Epoch: 5| Step: 4
Training loss: 1.8535630890343382
Validation loss: 2.646542443854285

Epoch: 5| Step: 5
Training loss: 2.1614698172268034
Validation loss: 2.571454338085269

Epoch: 5| Step: 6
Training loss: 2.5200229845058444
Validation loss: 2.5779229893847653

Epoch: 5| Step: 7
Training loss: 2.0347987939214986
Validation loss: 2.4896654989123865

Epoch: 5| Step: 8
Training loss: 1.7379255638117364
Validation loss: 2.6321828439831876

Epoch: 5| Step: 9
Training loss: 2.5855400955611567
Validation loss: 2.499232319923541

Epoch: 5| Step: 10
Training loss: 2.1782192083971537
Validation loss: 2.5925338954266004

Epoch: 529| Step: 0
Training loss: 1.9358441445022347
Validation loss: 2.5326183514247673

Epoch: 5| Step: 1
Training loss: 1.5210306570862215
Validation loss: 2.5452784316501136

Epoch: 5| Step: 2
Training loss: 1.8889022418404124
Validation loss: 2.5799369274387676

Epoch: 5| Step: 3
Training loss: 1.8309096296708596
Validation loss: 2.632877010571329

Epoch: 5| Step: 4
Training loss: 3.0917021784495176
Validation loss: 2.5070001488060263

Epoch: 5| Step: 5
Training loss: 1.9791943062977164
Validation loss: 2.490246017335543

Epoch: 5| Step: 6
Training loss: 2.226559930097201
Validation loss: 2.4538977572199423

Epoch: 5| Step: 7
Training loss: 2.310790074142208
Validation loss: 2.5872539900091627

Epoch: 5| Step: 8
Training loss: 2.4075696224868723
Validation loss: 2.6326605649911525

Epoch: 5| Step: 9
Training loss: 1.7654574154342182
Validation loss: 2.5856666216118014

Epoch: 5| Step: 10
Training loss: 2.4214648483973344
Validation loss: 2.5689417239628782

Epoch: 530| Step: 0
Training loss: 1.6349566677312541
Validation loss: 2.536348075228082

Epoch: 5| Step: 1
Training loss: 2.3829232612256694
Validation loss: 2.6201076378591215

Epoch: 5| Step: 2
Training loss: 2.589503017007617
Validation loss: 2.4393398954499075

Epoch: 5| Step: 3
Training loss: 2.0620530540086466
Validation loss: 2.6059795194528155

Epoch: 5| Step: 4
Training loss: 2.4435890632573227
Validation loss: 2.519167316414119

Epoch: 5| Step: 5
Training loss: 1.9846015260214813
Validation loss: 2.592888639771399

Epoch: 5| Step: 6
Training loss: 1.7830865326752408
Validation loss: 2.538268943192227

Epoch: 5| Step: 7
Training loss: 2.407555758423766
Validation loss: 2.6183069006436805

Epoch: 5| Step: 8
Training loss: 2.0755393786461367
Validation loss: 2.5781539055231493

Epoch: 5| Step: 9
Training loss: 1.6199704610227255
Validation loss: 2.499607780411971

Epoch: 5| Step: 10
Training loss: 2.6029074002068366
Validation loss: 2.4823069443015524

Epoch: 531| Step: 0
Training loss: 2.1630939836546177
Validation loss: 2.5816259295782698

Epoch: 5| Step: 1
Training loss: 1.634568579681167
Validation loss: 2.597629309320313

Epoch: 5| Step: 2
Training loss: 2.3974116116361643
Validation loss: 2.589337633090184

Epoch: 5| Step: 3
Training loss: 2.4025797410130365
Validation loss: 2.5153320158192263

Epoch: 5| Step: 4
Training loss: 2.614902968201989
Validation loss: 2.544282532030463

Epoch: 5| Step: 5
Training loss: 1.8994160080926732
Validation loss: 2.5886180212195633

Epoch: 5| Step: 6
Training loss: 1.3842846205854813
Validation loss: 2.5223792200725303

Epoch: 5| Step: 7
Training loss: 2.218240813808193
Validation loss: 2.6293711113320684

Epoch: 5| Step: 8
Training loss: 2.6876421158940493
Validation loss: 2.6382254867842856

Epoch: 5| Step: 9
Training loss: 2.1551530784528836
Validation loss: 2.5904098592607427

Epoch: 5| Step: 10
Training loss: 1.9528177858971845
Validation loss: 2.49081991834395

Epoch: 532| Step: 0
Training loss: 1.589737347315687
Validation loss: 2.56384436165553

Epoch: 5| Step: 1
Training loss: 2.034476197709831
Validation loss: 2.5358072677402315

Epoch: 5| Step: 2
Training loss: 2.0506897533532604
Validation loss: 2.592365240685628

Epoch: 5| Step: 3
Training loss: 2.0452668373600154
Validation loss: 2.543780267216964

Epoch: 5| Step: 4
Training loss: 1.9386020725465458
Validation loss: 2.535427330620824

Epoch: 5| Step: 5
Training loss: 2.3936398513192176
Validation loss: 2.584130462809569

Epoch: 5| Step: 6
Training loss: 2.301081017750189
Validation loss: 2.5326943550076746

Epoch: 5| Step: 7
Training loss: 2.758930098717946
Validation loss: 2.556193710747596

Epoch: 5| Step: 8
Training loss: 1.857851253583366
Validation loss: 2.511226501134393

Epoch: 5| Step: 9
Training loss: 2.140380511278951
Validation loss: 2.5215607548450274

Epoch: 5| Step: 10
Training loss: 1.8427090696768604
Validation loss: 2.5736862678324517

Epoch: 533| Step: 0
Training loss: 2.7253510590248697
Validation loss: 2.5143815023657043

Epoch: 5| Step: 1
Training loss: 2.3915131359022714
Validation loss: 2.5306659015959645

Epoch: 5| Step: 2
Training loss: 2.22903176966087
Validation loss: 2.5688617091685444

Epoch: 5| Step: 3
Training loss: 1.9638836374831623
Validation loss: 2.5337305851504492

Epoch: 5| Step: 4
Training loss: 1.6142872036325406
Validation loss: 2.548792086519235

Epoch: 5| Step: 5
Training loss: 1.378686168711342
Validation loss: 2.5440122216604997

Epoch: 5| Step: 6
Training loss: 2.2883945571181235
Validation loss: 2.5332567126739503

Epoch: 5| Step: 7
Training loss: 2.5141861870344746
Validation loss: 2.6224700115289563

Epoch: 5| Step: 8
Training loss: 1.9208771510998066
Validation loss: 2.531126528004385

Epoch: 5| Step: 9
Training loss: 1.849003113396903
Validation loss: 2.5670313534375935

Epoch: 5| Step: 10
Training loss: 2.212106779684046
Validation loss: 2.5635858621652075

Epoch: 534| Step: 0
Training loss: 1.425792202842134
Validation loss: 2.519180528326629

Epoch: 5| Step: 1
Training loss: 2.319135682144282
Validation loss: 2.5828418052369706

Epoch: 5| Step: 2
Training loss: 2.464240675962846
Validation loss: 2.6390664883017494

Epoch: 5| Step: 3
Training loss: 1.7894347357497256
Validation loss: 2.5709312909197233

Epoch: 5| Step: 4
Training loss: 1.911453898439451
Validation loss: 2.577429718004342

Epoch: 5| Step: 5
Training loss: 2.3872746945469263
Validation loss: 2.5324818965706695

Epoch: 5| Step: 6
Training loss: 1.9506538322002172
Validation loss: 2.5885253494397764

Epoch: 5| Step: 7
Training loss: 2.3138108533279094
Validation loss: 2.4927879430794095

Epoch: 5| Step: 8
Training loss: 2.314411919464421
Validation loss: 2.5454026503633913

Epoch: 5| Step: 9
Training loss: 2.2016472155135047
Validation loss: 2.5666585793732004

Epoch: 5| Step: 10
Training loss: 2.2446744199316213
Validation loss: 2.4749338116521735

Epoch: 535| Step: 0
Training loss: 1.7694900878430293
Validation loss: 2.61741643402394

Epoch: 5| Step: 1
Training loss: 1.9961031262201814
Validation loss: 2.632784142969392

Epoch: 5| Step: 2
Training loss: 1.850309245579104
Validation loss: 2.505098162713078

Epoch: 5| Step: 3
Training loss: 1.9940448554913879
Validation loss: 2.522360512407176

Epoch: 5| Step: 4
Training loss: 2.2341726785038456
Validation loss: 2.5814564504618227

Epoch: 5| Step: 5
Training loss: 2.8743394839287983
Validation loss: 2.6554078264810594

Epoch: 5| Step: 6
Training loss: 1.6870178664187914
Validation loss: 2.569827119252255

Epoch: 5| Step: 7
Training loss: 2.696206295700878
Validation loss: 2.4980104220492194

Epoch: 5| Step: 8
Training loss: 1.6862189764133915
Validation loss: 2.584080531150724

Epoch: 5| Step: 9
Training loss: 2.434415577463385
Validation loss: 2.6179184249436944

Epoch: 5| Step: 10
Training loss: 2.1457052717297085
Validation loss: 2.635711549986935

Epoch: 536| Step: 0
Training loss: 1.8110591817924764
Validation loss: 2.58460414093991

Epoch: 5| Step: 1
Training loss: 2.1422385935182007
Validation loss: 2.54511479638199

Epoch: 5| Step: 2
Training loss: 1.748353251454971
Validation loss: 2.563815085814849

Epoch: 5| Step: 3
Training loss: 2.112927532385007
Validation loss: 2.6021438624564968

Epoch: 5| Step: 4
Training loss: 2.0814249326029115
Validation loss: 2.4850773653377125

Epoch: 5| Step: 5
Training loss: 2.392934045592903
Validation loss: 2.580466656381962

Epoch: 5| Step: 6
Training loss: 2.096156203753883
Validation loss: 2.5467987300772505

Epoch: 5| Step: 7
Training loss: 2.2331196920020595
Validation loss: 2.538141580553219

Epoch: 5| Step: 8
Training loss: 2.687325405393373
Validation loss: 2.504837292798896

Epoch: 5| Step: 9
Training loss: 2.241385818340456
Validation loss: 2.4391915410420713

Epoch: 5| Step: 10
Training loss: 1.6297925554978765
Validation loss: 2.5432247474508043

Epoch: 537| Step: 0
Training loss: 2.407460589378443
Validation loss: 2.596912570628923

Epoch: 5| Step: 1
Training loss: 2.3563691248238454
Validation loss: 2.5985597941178242

Epoch: 5| Step: 2
Training loss: 2.484074508440249
Validation loss: 2.54961365739473

Epoch: 5| Step: 3
Training loss: 1.8804408922021882
Validation loss: 2.5570173940802654

Epoch: 5| Step: 4
Training loss: 1.961185029353516
Validation loss: 2.560656969496295

Epoch: 5| Step: 5
Training loss: 1.6646625708418998
Validation loss: 2.539595450102257

Epoch: 5| Step: 6
Training loss: 1.5781036979823897
Validation loss: 2.5589747617617515

Epoch: 5| Step: 7
Training loss: 2.085717807587638
Validation loss: 2.531991990899334

Epoch: 5| Step: 8
Training loss: 2.135895900139829
Validation loss: 2.536514400534551

Epoch: 5| Step: 9
Training loss: 2.0416758660349257
Validation loss: 2.519206626554021

Epoch: 5| Step: 10
Training loss: 2.7457005095784863
Validation loss: 2.47995085467258

Epoch: 538| Step: 0
Training loss: 1.7954840542439217
Validation loss: 2.523018523351338

Epoch: 5| Step: 1
Training loss: 2.5034734438186135
Validation loss: 2.5792208354086426

Epoch: 5| Step: 2
Training loss: 1.8806538850867651
Validation loss: 2.565076842453231

Epoch: 5| Step: 3
Training loss: 1.9031678594263735
Validation loss: 2.542370430134971

Epoch: 5| Step: 4
Training loss: 1.8267847348548705
Validation loss: 2.566505882581919

Epoch: 5| Step: 5
Training loss: 2.1539991489504353
Validation loss: 2.5711178136881845

Epoch: 5| Step: 6
Training loss: 2.7794312091459488
Validation loss: 2.5172827508140325

Epoch: 5| Step: 7
Training loss: 1.9734783008311285
Validation loss: 2.4738979931107528

Epoch: 5| Step: 8
Training loss: 1.8858311304722066
Validation loss: 2.534339392580725

Epoch: 5| Step: 9
Training loss: 2.360320552295519
Validation loss: 2.5770999007801225

Epoch: 5| Step: 10
Training loss: 2.446792788238898
Validation loss: 2.580575621889572

Epoch: 539| Step: 0
Training loss: 2.088600544721895
Validation loss: 2.4725818836365394

Epoch: 5| Step: 1
Training loss: 1.3628521000585174
Validation loss: 2.594356094415461

Epoch: 5| Step: 2
Training loss: 2.099179984254024
Validation loss: 2.6080375575894967

Epoch: 5| Step: 3
Training loss: 2.5758710776700093
Validation loss: 2.5520544141311645

Epoch: 5| Step: 4
Training loss: 1.9126991866360872
Validation loss: 2.5667978945845307

Epoch: 5| Step: 5
Training loss: 1.9014995354514668
Validation loss: 2.5845393806821417

Epoch: 5| Step: 6
Training loss: 2.686919659786685
Validation loss: 2.530041876143206

Epoch: 5| Step: 7
Training loss: 1.8790776101245035
Validation loss: 2.550204921316592

Epoch: 5| Step: 8
Training loss: 2.555702404511532
Validation loss: 2.5476330534236222

Epoch: 5| Step: 9
Training loss: 1.7487691228992146
Validation loss: 2.5747547259240733

Epoch: 5| Step: 10
Training loss: 2.1765950459979218
Validation loss: 2.5233999000805265

Epoch: 540| Step: 0
Training loss: 2.332484113469458
Validation loss: 2.5880933394686885

Epoch: 5| Step: 1
Training loss: 1.9553737054908455
Validation loss: 2.5181311264743202

Epoch: 5| Step: 2
Training loss: 2.4702985711281094
Validation loss: 2.549391045708138

Epoch: 5| Step: 3
Training loss: 3.0589070945216754
Validation loss: 2.6800289299483544

Epoch: 5| Step: 4
Training loss: 1.5569650654141358
Validation loss: 2.452724701326692

Epoch: 5| Step: 5
Training loss: 2.0266601350745974
Validation loss: 2.5361162012072778

Epoch: 5| Step: 6
Training loss: 1.5850305077778624
Validation loss: 2.539925526744882

Epoch: 5| Step: 7
Training loss: 1.8792485105816408
Validation loss: 2.477349755509524

Epoch: 5| Step: 8
Training loss: 2.1506782083045963
Validation loss: 2.5497251278828625

Epoch: 5| Step: 9
Training loss: 2.0396316143344078
Validation loss: 2.5903314072467465

Epoch: 5| Step: 10
Training loss: 1.859165981309127
Validation loss: 2.573178997385897

Epoch: 541| Step: 0
Training loss: 1.685938784057015
Validation loss: 2.4796645957995773

Epoch: 5| Step: 1
Training loss: 2.0553056490544552
Validation loss: 2.6118332423125077

Epoch: 5| Step: 2
Training loss: 2.307259265910399
Validation loss: 2.5625352579447944

Epoch: 5| Step: 3
Training loss: 2.1347631679566144
Validation loss: 2.6556233158420506

Epoch: 5| Step: 4
Training loss: 2.5631122322945856
Validation loss: 2.60540573831817

Epoch: 5| Step: 5
Training loss: 2.4990127521508563
Validation loss: 2.437313713231222

Epoch: 5| Step: 6
Training loss: 1.9403214983640082
Validation loss: 2.506350382679584

Epoch: 5| Step: 7
Training loss: 2.2565179301182856
Validation loss: 2.497159575856841

Epoch: 5| Step: 8
Training loss: 1.5818416528943544
Validation loss: 2.622978891454641

Epoch: 5| Step: 9
Training loss: 1.6738270567063758
Validation loss: 2.6113389240981335

Epoch: 5| Step: 10
Training loss: 2.739703670126344
Validation loss: 2.568357238930844

Epoch: 542| Step: 0
Training loss: 1.774061454542832
Validation loss: 2.498665414440287

Epoch: 5| Step: 1
Training loss: 2.1691970232572255
Validation loss: 2.551423579496868

Epoch: 5| Step: 2
Training loss: 1.7591765811893165
Validation loss: 2.504286865313874

Epoch: 5| Step: 3
Training loss: 1.7039629773295373
Validation loss: 2.5422265548827734

Epoch: 5| Step: 4
Training loss: 2.553882997161322
Validation loss: 2.508366926741839

Epoch: 5| Step: 5
Training loss: 1.8644372325182321
Validation loss: 2.564921908568823

Epoch: 5| Step: 6
Training loss: 2.0370622082641794
Validation loss: 2.5087739613518405

Epoch: 5| Step: 7
Training loss: 2.4889026386963526
Validation loss: 2.568224161313942

Epoch: 5| Step: 8
Training loss: 2.538225992763082
Validation loss: 2.5208599591219847

Epoch: 5| Step: 9
Training loss: 1.930279845470556
Validation loss: 2.4727314995241017

Epoch: 5| Step: 10
Training loss: 2.4821979892955244
Validation loss: 2.5873239655190017

Epoch: 543| Step: 0
Training loss: 2.618428496880128
Validation loss: 2.5909088740422566

Epoch: 5| Step: 1
Training loss: 2.480719606225071
Validation loss: 2.513999606983197

Epoch: 5| Step: 2
Training loss: 2.126087359308554
Validation loss: 2.485732927345434

Epoch: 5| Step: 3
Training loss: 1.4563831186642058
Validation loss: 2.583058485189332

Epoch: 5| Step: 4
Training loss: 1.9953422550142583
Validation loss: 2.510696398270999

Epoch: 5| Step: 5
Training loss: 2.8432413841069386
Validation loss: 2.5741741018388056

Epoch: 5| Step: 6
Training loss: 2.3609284598318196
Validation loss: 2.477690169060908

Epoch: 5| Step: 7
Training loss: 1.8842057261185714
Validation loss: 2.5619753528854914

Epoch: 5| Step: 8
Training loss: 1.826774098040145
Validation loss: 2.4958697091755373

Epoch: 5| Step: 9
Training loss: 1.8816757252725445
Validation loss: 2.6028599515295254

Epoch: 5| Step: 10
Training loss: 1.1152912933736245
Validation loss: 2.6201462999916334

Epoch: 544| Step: 0
Training loss: 1.7379842097198333
Validation loss: 2.451864547985549

Epoch: 5| Step: 1
Training loss: 2.2620492011873945
Validation loss: 2.570028562223067

Epoch: 5| Step: 2
Training loss: 2.4093281267606335
Validation loss: 2.5496086982559705

Epoch: 5| Step: 3
Training loss: 2.0391354602607863
Validation loss: 2.5363946829914235

Epoch: 5| Step: 4
Training loss: 2.6940568293388005
Validation loss: 2.5275816593615206

Epoch: 5| Step: 5
Training loss: 2.264919197375944
Validation loss: 2.5118027162079994

Epoch: 5| Step: 6
Training loss: 1.7993135573883485
Validation loss: 2.4953081547431673

Epoch: 5| Step: 7
Training loss: 2.26306660338466
Validation loss: 2.578559211965203

Epoch: 5| Step: 8
Training loss: 2.024566453275977
Validation loss: 2.5330373514493574

Epoch: 5| Step: 9
Training loss: 1.7200551019758081
Validation loss: 2.5380521686655304

Epoch: 5| Step: 10
Training loss: 1.7834280651398424
Validation loss: 2.5617357370384006

Epoch: 545| Step: 0
Training loss: 1.876488793900468
Validation loss: 2.548457394140858

Epoch: 5| Step: 1
Training loss: 1.972162468173655
Validation loss: 2.5079132623101485

Epoch: 5| Step: 2
Training loss: 2.2964780295774725
Validation loss: 2.573284692952805

Epoch: 5| Step: 3
Training loss: 1.7570220526373537
Validation loss: 2.5386299596599042

Epoch: 5| Step: 4
Training loss: 2.1479477202732613
Validation loss: 2.513855727945505

Epoch: 5| Step: 5
Training loss: 1.9508193177712794
Validation loss: 2.6351034297749396

Epoch: 5| Step: 6
Training loss: 1.7636261149370531
Validation loss: 2.548800284991493

Epoch: 5| Step: 7
Training loss: 2.8724262493018378
Validation loss: 2.463421351390729

Epoch: 5| Step: 8
Training loss: 2.1298434093386356
Validation loss: 2.508933723071521

Epoch: 5| Step: 9
Training loss: 2.43591942037219
Validation loss: 2.5467405904682807

Epoch: 5| Step: 10
Training loss: 1.5398514173095197
Validation loss: 2.656525885040049

Epoch: 546| Step: 0
Training loss: 2.699284907412157
Validation loss: 2.4785359182517483

Epoch: 5| Step: 1
Training loss: 1.63594375507139
Validation loss: 2.5256398696620646

Epoch: 5| Step: 2
Training loss: 1.961117253670635
Validation loss: 2.5856299523997746

Epoch: 5| Step: 3
Training loss: 2.2044749351455684
Validation loss: 2.566534410538985

Epoch: 5| Step: 4
Training loss: 1.9313985057632657
Validation loss: 2.4346938123078674

Epoch: 5| Step: 5
Training loss: 1.6082625016079835
Validation loss: 2.5342167461036946

Epoch: 5| Step: 6
Training loss: 2.0390994481506395
Validation loss: 2.641292418988915

Epoch: 5| Step: 7
Training loss: 2.8277671123853936
Validation loss: 2.436651643334404

Epoch: 5| Step: 8
Training loss: 2.000638978927764
Validation loss: 2.5471502392276903

Epoch: 5| Step: 9
Training loss: 1.837525999443208
Validation loss: 2.5216852614873964

Epoch: 5| Step: 10
Training loss: 1.8795681935386084
Validation loss: 2.477619374576432

Epoch: 547| Step: 0
Training loss: 1.8133483742810061
Validation loss: 2.5602784580268643

Epoch: 5| Step: 1
Training loss: 1.5916258924897133
Validation loss: 2.5824258906184214

Epoch: 5| Step: 2
Training loss: 1.4860927881713617
Validation loss: 2.617655974157554

Epoch: 5| Step: 3
Training loss: 2.2638696645012764
Validation loss: 2.5440720308898466

Epoch: 5| Step: 4
Training loss: 2.921175459897074
Validation loss: 2.488604007280177

Epoch: 5| Step: 5
Training loss: 1.7333613002183723
Validation loss: 2.592135322520035

Epoch: 5| Step: 6
Training loss: 2.493216849103349
Validation loss: 2.502907407785322

Epoch: 5| Step: 7
Training loss: 1.8791381946557997
Validation loss: 2.5878191520803284

Epoch: 5| Step: 8
Training loss: 2.3611646521487835
Validation loss: 2.555278793816324

Epoch: 5| Step: 9
Training loss: 1.9588708207601484
Validation loss: 2.597643143864989

Epoch: 5| Step: 10
Training loss: 1.844749438425194
Validation loss: 2.5790455914419455

Epoch: 548| Step: 0
Training loss: 1.744828006498799
Validation loss: 2.6017181212965435

Epoch: 5| Step: 1
Training loss: 2.4497364719895987
Validation loss: 2.498341772333968

Epoch: 5| Step: 2
Training loss: 2.2146881963880287
Validation loss: 2.5253298860435804

Epoch: 5| Step: 3
Training loss: 1.6514943060965903
Validation loss: 2.4742162150164435

Epoch: 5| Step: 4
Training loss: 2.7575041947112426
Validation loss: 2.578975525511723

Epoch: 5| Step: 5
Training loss: 1.6545262993952756
Validation loss: 2.607624712957663

Epoch: 5| Step: 6
Training loss: 1.7070551331549357
Validation loss: 2.580695928342158

Epoch: 5| Step: 7
Training loss: 1.9598203721743417
Validation loss: 2.5626021073970193

Epoch: 5| Step: 8
Training loss: 2.563114185696466
Validation loss: 2.5741327075849982

Epoch: 5| Step: 9
Training loss: 1.8411669983966983
Validation loss: 2.571228757705493

Epoch: 5| Step: 10
Training loss: 1.8414043441069898
Validation loss: 2.5474868664521764

Epoch: 549| Step: 0
Training loss: 1.575994658877428
Validation loss: 2.517224111783621

Epoch: 5| Step: 1
Training loss: 1.8620608509704173
Validation loss: 2.6082636511495654

Epoch: 5| Step: 2
Training loss: 1.9050567519377573
Validation loss: 2.632382591691219

Epoch: 5| Step: 3
Training loss: 1.294610816108077
Validation loss: 2.5742040695326285

Epoch: 5| Step: 4
Training loss: 2.2842231084212004
Validation loss: 2.544346999011405

Epoch: 5| Step: 5
Training loss: 2.346126521361506
Validation loss: 2.6260860635992795

Epoch: 5| Step: 6
Training loss: 1.948798247028214
Validation loss: 2.625359141973164

Epoch: 5| Step: 7
Training loss: 2.6760268940907017
Validation loss: 2.5245078660837557

Epoch: 5| Step: 8
Training loss: 2.0295740109049896
Validation loss: 2.5968261547121676

Epoch: 5| Step: 9
Training loss: 2.2549059682047847
Validation loss: 2.554968391583997

Epoch: 5| Step: 10
Training loss: 2.6987480934634593
Validation loss: 2.5097809745249284

Epoch: 550| Step: 0
Training loss: 1.5655353817445776
Validation loss: 2.568400528920128

Epoch: 5| Step: 1
Training loss: 2.0528713075388243
Validation loss: 2.569979649384544

Epoch: 5| Step: 2
Training loss: 1.8859644422526651
Validation loss: 2.5361571394119546

Epoch: 5| Step: 3
Training loss: 2.315879002693091
Validation loss: 2.5132587003829325

Epoch: 5| Step: 4
Training loss: 2.256715712735095
Validation loss: 2.4665242675207533

Epoch: 5| Step: 5
Training loss: 2.0424533288635844
Validation loss: 2.5907246776355066

Epoch: 5| Step: 6
Training loss: 1.4315945772725418
Validation loss: 2.5073760237455605

Epoch: 5| Step: 7
Training loss: 1.9765785427724067
Validation loss: 2.630834070363493

Epoch: 5| Step: 8
Training loss: 2.101895103936945
Validation loss: 2.657792516817254

Epoch: 5| Step: 9
Training loss: 1.9655254538942013
Validation loss: 2.580634717830425

Epoch: 5| Step: 10
Training loss: 2.7185912688824065
Validation loss: 2.6171252769012323

Epoch: 551| Step: 0
Training loss: 1.973694903696105
Validation loss: 2.5416885454381672

Epoch: 5| Step: 1
Training loss: 2.063073512015266
Validation loss: 2.4934597542550025

Epoch: 5| Step: 2
Training loss: 1.88325128151503
Validation loss: 2.5782937649366953

Epoch: 5| Step: 3
Training loss: 1.6459816813509855
Validation loss: 2.5085062631358253

Epoch: 5| Step: 4
Training loss: 1.864677625719166
Validation loss: 2.5720254039334964

Epoch: 5| Step: 5
Training loss: 1.3485720853509529
Validation loss: 2.521004649556151

Epoch: 5| Step: 6
Training loss: 2.78793183817793
Validation loss: 2.559918635873749

Epoch: 5| Step: 7
Training loss: 3.057741789470494
Validation loss: 2.495027603446193

Epoch: 5| Step: 8
Training loss: 1.593114464396872
Validation loss: 2.614081178913761

Epoch: 5| Step: 9
Training loss: 1.6380921203271
Validation loss: 2.5850247361302063

Epoch: 5| Step: 10
Training loss: 1.8925272301915768
Validation loss: 2.5918090423383204

Epoch: 552| Step: 0
Training loss: 2.015114298151109
Validation loss: 2.5648934536323003

Epoch: 5| Step: 1
Training loss: 1.5606879599035377
Validation loss: 2.6179295866030468

Epoch: 5| Step: 2
Training loss: 1.7245323708300668
Validation loss: 2.6120701076560935

Epoch: 5| Step: 3
Training loss: 2.1270071535981065
Validation loss: 2.3890416870399567

Epoch: 5| Step: 4
Training loss: 2.643990443052255
Validation loss: 2.5446323939722633

Epoch: 5| Step: 5
Training loss: 2.3429956875353146
Validation loss: 2.511694659987357

Epoch: 5| Step: 6
Training loss: 2.1734905134985216
Validation loss: 2.5794612420954506

Epoch: 5| Step: 7
Training loss: 2.1959332983243587
Validation loss: 2.532223614372851

Epoch: 5| Step: 8
Training loss: 2.148307879612573
Validation loss: 2.5620212973182515

Epoch: 5| Step: 9
Training loss: 2.1874361301362133
Validation loss: 2.525138362788064

Epoch: 5| Step: 10
Training loss: 1.2201540268926485
Validation loss: 2.6577909985755226

Epoch: 553| Step: 0
Training loss: 2.3047829818343573
Validation loss: 2.586293429649196

Epoch: 5| Step: 1
Training loss: 2.215611561894522
Validation loss: 2.5374589691328326

Epoch: 5| Step: 2
Training loss: 2.525470493407858
Validation loss: 2.6355160768174093

Epoch: 5| Step: 3
Training loss: 1.5394168968555004
Validation loss: 2.543804417191602

Epoch: 5| Step: 4
Training loss: 1.2398508995922068
Validation loss: 2.5770827368343974

Epoch: 5| Step: 5
Training loss: 1.786902710685401
Validation loss: 2.567777628779882

Epoch: 5| Step: 6
Training loss: 2.127978873592569
Validation loss: 2.5491124309322686

Epoch: 5| Step: 7
Training loss: 1.7623720163181686
Validation loss: 2.6057063444222655

Epoch: 5| Step: 8
Training loss: 2.322313467035052
Validation loss: 2.5326793042828224

Epoch: 5| Step: 9
Training loss: 1.992553976421529
Validation loss: 2.5162966944884313

Epoch: 5| Step: 10
Training loss: 2.6224328158112273
Validation loss: 2.56083575734232

Epoch: 554| Step: 0
Training loss: 2.291335503896899
Validation loss: 2.5513099273672357

Epoch: 5| Step: 1
Training loss: 1.9729311307748163
Validation loss: 2.4840876446056255

Epoch: 5| Step: 2
Training loss: 2.7913224496762115
Validation loss: 2.566514655761583

Epoch: 5| Step: 3
Training loss: 1.5929718361787708
Validation loss: 2.441613622115325

Epoch: 5| Step: 4
Training loss: 2.150553600985209
Validation loss: 2.5818392898645803

Epoch: 5| Step: 5
Training loss: 1.5526638182917918
Validation loss: 2.6216601450921218

Epoch: 5| Step: 6
Training loss: 2.20290530577096
Validation loss: 2.538740055381042

Epoch: 5| Step: 7
Training loss: 1.929734449549048
Validation loss: 2.522275500117091

Epoch: 5| Step: 8
Training loss: 2.123519157091517
Validation loss: 2.53762399012989

Epoch: 5| Step: 9
Training loss: 2.2982708069851103
Validation loss: 2.5863796761090576

Epoch: 5| Step: 10
Training loss: 1.5420650105013565
Validation loss: 2.438112540066813

Epoch: 555| Step: 0
Training loss: 2.5363456392939296
Validation loss: 2.4845753178345595

Epoch: 5| Step: 1
Training loss: 1.6671464308995647
Validation loss: 2.5199658396085827

Epoch: 5| Step: 2
Training loss: 2.2296174089820413
Validation loss: 2.5431280868592547

Epoch: 5| Step: 3
Training loss: 2.293207471336119
Validation loss: 2.568597630885349

Epoch: 5| Step: 4
Training loss: 1.4714902111613175
Validation loss: 2.560449419539951

Epoch: 5| Step: 5
Training loss: 2.226883500366946
Validation loss: 2.5129379446667413

Epoch: 5| Step: 6
Training loss: 2.341285325174391
Validation loss: 2.5100683427530517

Epoch: 5| Step: 7
Training loss: 2.221793008785733
Validation loss: 2.5273068350803882

Epoch: 5| Step: 8
Training loss: 1.6809307376678033
Validation loss: 2.6199298790299266

Epoch: 5| Step: 9
Training loss: 1.9245430019943095
Validation loss: 2.616385106553518

Epoch: 5| Step: 10
Training loss: 2.3388755463707627
Validation loss: 2.493472647172324

Epoch: 556| Step: 0
Training loss: 1.9446124307032884
Validation loss: 2.664076433177504

Epoch: 5| Step: 1
Training loss: 2.3242822462111805
Validation loss: 2.5090855183183343

Epoch: 5| Step: 2
Training loss: 1.4220907026730145
Validation loss: 2.5086431238473827

Epoch: 5| Step: 3
Training loss: 2.6321319696682215
Validation loss: 2.4924818347256585

Epoch: 5| Step: 4
Training loss: 2.150978610859485
Validation loss: 2.6628951289865883

Epoch: 5| Step: 5
Training loss: 2.284141380376998
Validation loss: 2.4713449014521376

Epoch: 5| Step: 6
Training loss: 2.510000444997315
Validation loss: 2.586329465972425

Epoch: 5| Step: 7
Training loss: 1.8200988644167713
Validation loss: 2.5406247818817875

Epoch: 5| Step: 8
Training loss: 2.195706369492299
Validation loss: 2.517518258645326

Epoch: 5| Step: 9
Training loss: 2.1896915901443132
Validation loss: 2.551719297186965

Epoch: 5| Step: 10
Training loss: 1.577015704070124
Validation loss: 2.5809430563469467

Epoch: 557| Step: 0
Training loss: 2.8018679246508924
Validation loss: 2.5843747524422005

Epoch: 5| Step: 1
Training loss: 1.4172191477546623
Validation loss: 2.568057471918319

Epoch: 5| Step: 2
Training loss: 1.933987664066015
Validation loss: 2.625579061085719

Epoch: 5| Step: 3
Training loss: 2.0294004970084885
Validation loss: 2.613080828983594

Epoch: 5| Step: 4
Training loss: 1.8098544841040651
Validation loss: 2.657038660975582

Epoch: 5| Step: 5
Training loss: 1.8975877155038199
Validation loss: 2.587626216458008

Epoch: 5| Step: 6
Training loss: 1.7653993445488878
Validation loss: 2.4806480755659437

Epoch: 5| Step: 7
Training loss: 2.4751902728683013
Validation loss: 2.620373007075954

Epoch: 5| Step: 8
Training loss: 2.1110754999983103
Validation loss: 2.6288397754587374

Epoch: 5| Step: 9
Training loss: 1.747992999562577
Validation loss: 2.5594252651032128

Epoch: 5| Step: 10
Training loss: 1.8405670882280576
Validation loss: 2.5078307697943107

Epoch: 558| Step: 0
Training loss: 1.798070228121685
Validation loss: 2.617114358662668

Epoch: 5| Step: 1
Training loss: 2.1781722513817527
Validation loss: 2.492663888002087

Epoch: 5| Step: 2
Training loss: 1.833645302787741
Validation loss: 2.575601292547063

Epoch: 5| Step: 3
Training loss: 2.598938864798752
Validation loss: 2.5604960711873805

Epoch: 5| Step: 4
Training loss: 2.1672501756424016
Validation loss: 2.444810570669467

Epoch: 5| Step: 5
Training loss: 2.013896703887626
Validation loss: 2.5084264218025063

Epoch: 5| Step: 6
Training loss: 2.003177978957651
Validation loss: 2.6489652475141146

Epoch: 5| Step: 7
Training loss: 1.9025376238718126
Validation loss: 2.6027984634544983

Epoch: 5| Step: 8
Training loss: 1.8725957078500939
Validation loss: 2.684261903912741

Epoch: 5| Step: 9
Training loss: 1.704826484979433
Validation loss: 2.555318264253432

Epoch: 5| Step: 10
Training loss: 2.8687128068761014
Validation loss: 2.5319388396862377

Epoch: 559| Step: 0
Training loss: 2.457704291171543
Validation loss: 2.531699644152625

Epoch: 5| Step: 1
Training loss: 1.9207138647741608
Validation loss: 2.5667537305944133

Epoch: 5| Step: 2
Training loss: 1.8417858718106506
Validation loss: 2.595271255354993

Epoch: 5| Step: 3
Training loss: 1.8759995021738072
Validation loss: 2.561347535195323

Epoch: 5| Step: 4
Training loss: 2.2618246893704113
Validation loss: 2.568131958505019

Epoch: 5| Step: 5
Training loss: 1.5846411757937877
Validation loss: 2.617015506662253

Epoch: 5| Step: 6
Training loss: 2.72412840176751
Validation loss: 2.5575134155805612

Epoch: 5| Step: 7
Training loss: 1.839230769390927
Validation loss: 2.592104951907383

Epoch: 5| Step: 8
Training loss: 1.9230126216115164
Validation loss: 2.5016218523605795

Epoch: 5| Step: 9
Training loss: 2.238069587539273
Validation loss: 2.4921064620501836

Epoch: 5| Step: 10
Training loss: 1.6385456532185103
Validation loss: 2.5821037886084715

Epoch: 560| Step: 0
Training loss: 1.9940441978821082
Validation loss: 2.6141950783711256

Epoch: 5| Step: 1
Training loss: 2.2585775273841255
Validation loss: 2.5248636878424415

Epoch: 5| Step: 2
Training loss: 2.068050660462824
Validation loss: 2.536906785383979

Epoch: 5| Step: 3
Training loss: 1.9367638081444543
Validation loss: 2.488690529280848

Epoch: 5| Step: 4
Training loss: 1.5029259595521098
Validation loss: 2.635387576298243

Epoch: 5| Step: 5
Training loss: 2.603894903625801
Validation loss: 2.5229002505337275

Epoch: 5| Step: 6
Training loss: 1.9718156591031772
Validation loss: 2.5422285081980647

Epoch: 5| Step: 7
Training loss: 1.563459559484567
Validation loss: 2.542227939447665

Epoch: 5| Step: 8
Training loss: 2.46896226187719
Validation loss: 2.585288206902218

Epoch: 5| Step: 9
Training loss: 2.309881635333397
Validation loss: 2.5126409353261865

Epoch: 5| Step: 10
Training loss: 1.950691354900862
Validation loss: 2.5810952566050784

Epoch: 561| Step: 0
Training loss: 2.0058887334679025
Validation loss: 2.567843033400947

Epoch: 5| Step: 1
Training loss: 1.8577757296761312
Validation loss: 2.5472978565131053

Epoch: 5| Step: 2
Training loss: 2.245153718031425
Validation loss: 2.552851793835163

Epoch: 5| Step: 3
Training loss: 2.491469515992739
Validation loss: 2.6032631702628484

Epoch: 5| Step: 4
Training loss: 1.8386127865213397
Validation loss: 2.515405789939272

Epoch: 5| Step: 5
Training loss: 1.6469437036533885
Validation loss: 2.589021608328514

Epoch: 5| Step: 6
Training loss: 2.1958293917172385
Validation loss: 2.525824997116314

Epoch: 5| Step: 7
Training loss: 1.8087127844113116
Validation loss: 2.6009399118447876

Epoch: 5| Step: 8
Training loss: 2.692564517127499
Validation loss: 2.521153119464525

Epoch: 5| Step: 9
Training loss: 1.9642467767398426
Validation loss: 2.5142462499879

Epoch: 5| Step: 10
Training loss: 1.8309063090922895
Validation loss: 2.609747680435571

Epoch: 562| Step: 0
Training loss: 1.7097429259625636
Validation loss: 2.6545638985265683

Epoch: 5| Step: 1
Training loss: 2.284165492019806
Validation loss: 2.481933113958279

Epoch: 5| Step: 2
Training loss: 3.05417279446253
Validation loss: 2.5713615083397205

Epoch: 5| Step: 3
Training loss: 1.7530159166639498
Validation loss: 2.5575018058063748

Epoch: 5| Step: 4
Training loss: 2.1806672331551624
Validation loss: 2.5564223838039157

Epoch: 5| Step: 5
Training loss: 2.0612037515627954
Validation loss: 2.485946961291283

Epoch: 5| Step: 6
Training loss: 1.7814913134495605
Validation loss: 2.6181996082673304

Epoch: 5| Step: 7
Training loss: 2.058582168343844
Validation loss: 2.439510559595012

Epoch: 5| Step: 8
Training loss: 1.3849369690940243
Validation loss: 2.5814541926513015

Epoch: 5| Step: 9
Training loss: 1.8682509709675625
Validation loss: 2.537987049868226

Epoch: 5| Step: 10
Training loss: 2.161435622743233
Validation loss: 2.5633613895418264

Epoch: 563| Step: 0
Training loss: 1.8804011435374808
Validation loss: 2.4605045576487665

Epoch: 5| Step: 1
Training loss: 2.6901436156894425
Validation loss: 2.46022845456586

Epoch: 5| Step: 2
Training loss: 2.2874624238810406
Validation loss: 2.540127886700978

Epoch: 5| Step: 3
Training loss: 2.3101373923921744
Validation loss: 2.5470498938005757

Epoch: 5| Step: 4
Training loss: 1.8142432675582993
Validation loss: 2.5572342070548135

Epoch: 5| Step: 5
Training loss: 1.9703106219942974
Validation loss: 2.661302808133815

Epoch: 5| Step: 6
Training loss: 1.8562924775166658
Validation loss: 2.5883119192766135

Epoch: 5| Step: 7
Training loss: 1.596118438723947
Validation loss: 2.509982932516085

Epoch: 5| Step: 8
Training loss: 2.15496743799378
Validation loss: 2.6004664339124317

Epoch: 5| Step: 9
Training loss: 1.5307655346593187
Validation loss: 2.6382136957963125

Epoch: 5| Step: 10
Training loss: 2.318167571671716
Validation loss: 2.50539854914253

Epoch: 564| Step: 0
Training loss: 1.492170483557057
Validation loss: 2.5951827769888114

Epoch: 5| Step: 1
Training loss: 2.295206411051048
Validation loss: 2.48563043046962

Epoch: 5| Step: 2
Training loss: 2.7627299182891387
Validation loss: 2.5568633950939366

Epoch: 5| Step: 3
Training loss: 2.497808354065403
Validation loss: 2.539476134224841

Epoch: 5| Step: 4
Training loss: 2.0334497131853215
Validation loss: 2.5169128747241536

Epoch: 5| Step: 5
Training loss: 1.7261660021345133
Validation loss: 2.576882801372454

Epoch: 5| Step: 6
Training loss: 1.821156122096064
Validation loss: 2.5564077866622754

Epoch: 5| Step: 7
Training loss: 2.4515354327621655
Validation loss: 2.587411068368964

Epoch: 5| Step: 8
Training loss: 1.3090467437575422
Validation loss: 2.536560148188606

Epoch: 5| Step: 9
Training loss: 2.274288791533235
Validation loss: 2.5323156587096527

Epoch: 5| Step: 10
Training loss: 1.8796585702294997
Validation loss: 2.512501718031475

Epoch: 565| Step: 0
Training loss: 1.8892479287287984
Validation loss: 2.6101725627241863

Epoch: 5| Step: 1
Training loss: 1.9650694336405319
Validation loss: 2.4910229103348622

Epoch: 5| Step: 2
Training loss: 1.5940277755117014
Validation loss: 2.525063681086275

Epoch: 5| Step: 3
Training loss: 2.111269516885731
Validation loss: 2.5087328471007724

Epoch: 5| Step: 4
Training loss: 1.7561658818744983
Validation loss: 2.5795279565227593

Epoch: 5| Step: 5
Training loss: 2.11352706861523
Validation loss: 2.5545308280590824

Epoch: 5| Step: 6
Training loss: 1.992458250309573
Validation loss: 2.6019573301917966

Epoch: 5| Step: 7
Training loss: 2.2308362133685353
Validation loss: 2.58425009858246

Epoch: 5| Step: 8
Training loss: 2.7029893433152274
Validation loss: 2.5998637868919445

Epoch: 5| Step: 9
Training loss: 1.8377795778752872
Validation loss: 2.5761366529257934

Epoch: 5| Step: 10
Training loss: 1.924829832209873
Validation loss: 2.567485808087155

Epoch: 566| Step: 0
Training loss: 1.3444878969623062
Validation loss: 2.6715517806258724

Epoch: 5| Step: 1
Training loss: 1.7560867315132251
Validation loss: 2.515977338909551

Epoch: 5| Step: 2
Training loss: 2.117052587736243
Validation loss: 2.5839385363423135

Epoch: 5| Step: 3
Training loss: 1.663937559496839
Validation loss: 2.5788952693227096

Epoch: 5| Step: 4
Training loss: 1.82668338894441
Validation loss: 2.451449688840284

Epoch: 5| Step: 5
Training loss: 2.367206837792301
Validation loss: 2.4763799322965965

Epoch: 5| Step: 6
Training loss: 2.3893377291491356
Validation loss: 2.473125718597345

Epoch: 5| Step: 7
Training loss: 2.0453091521559927
Validation loss: 2.6020000345678227

Epoch: 5| Step: 8
Training loss: 2.815531135713451
Validation loss: 2.55103503293003

Epoch: 5| Step: 9
Training loss: 2.1272707755369584
Validation loss: 2.575103721676173

Epoch: 5| Step: 10
Training loss: 1.6223025307888195
Validation loss: 2.4884609181307744

Epoch: 567| Step: 0
Training loss: 1.8211593295366415
Validation loss: 2.5858719829868173

Epoch: 5| Step: 1
Training loss: 1.8310766925761082
Validation loss: 2.5647911695767367

Epoch: 5| Step: 2
Training loss: 1.7431888867061187
Validation loss: 2.49656231905103

Epoch: 5| Step: 3
Training loss: 1.4370218393926655
Validation loss: 2.5601160909430662

Epoch: 5| Step: 4
Training loss: 2.497717292046878
Validation loss: 2.539854310970003

Epoch: 5| Step: 5
Training loss: 2.052793957456227
Validation loss: 2.5812062902249955

Epoch: 5| Step: 6
Training loss: 2.969660247995617
Validation loss: 2.434946016342116

Epoch: 5| Step: 7
Training loss: 1.842174179896116
Validation loss: 2.5815691830570637

Epoch: 5| Step: 8
Training loss: 2.347453738600743
Validation loss: 2.5289589882401122

Epoch: 5| Step: 9
Training loss: 2.0754266874690113
Validation loss: 2.55847701553413

Epoch: 5| Step: 10
Training loss: 2.0084996810126534
Validation loss: 2.487518606303382

Epoch: 568| Step: 0
Training loss: 2.370877553016799
Validation loss: 2.5794756034293034

Epoch: 5| Step: 1
Training loss: 1.8528334364123962
Validation loss: 2.593630661821606

Epoch: 5| Step: 2
Training loss: 1.919009670119896
Validation loss: 2.543217819267951

Epoch: 5| Step: 3
Training loss: 1.4423709938634368
Validation loss: 2.5282430944728134

Epoch: 5| Step: 4
Training loss: 2.2402052141601434
Validation loss: 2.5873872649669143

Epoch: 5| Step: 5
Training loss: 1.3418516011856498
Validation loss: 2.528717220133413

Epoch: 5| Step: 6
Training loss: 1.8496270989572854
Validation loss: 2.5425550310997496

Epoch: 5| Step: 7
Training loss: 2.3036819592020144
Validation loss: 2.5306086444891234

Epoch: 5| Step: 8
Training loss: 2.4183743680508627
Validation loss: 2.467445463968897

Epoch: 5| Step: 9
Training loss: 2.756958394264868
Validation loss: 2.589877998713213

Epoch: 5| Step: 10
Training loss: 2.204406906429153
Validation loss: 2.5088897488037185

Epoch: 569| Step: 0
Training loss: 2.5169557641150475
Validation loss: 2.555119365851936

Epoch: 5| Step: 1
Training loss: 2.094548770499735
Validation loss: 2.4803891172473715

Epoch: 5| Step: 2
Training loss: 2.085575029404981
Validation loss: 2.6268629445393867

Epoch: 5| Step: 3
Training loss: 2.9319317575920416
Validation loss: 2.5419057239073815

Epoch: 5| Step: 4
Training loss: 2.2313765033154622
Validation loss: 2.516299584864722

Epoch: 5| Step: 5
Training loss: 1.4096812877547746
Validation loss: 2.4995253450733212

Epoch: 5| Step: 6
Training loss: 1.7749779686433609
Validation loss: 2.5636719585589804

Epoch: 5| Step: 7
Training loss: 1.99420817500826
Validation loss: 2.594134139589627

Epoch: 5| Step: 8
Training loss: 1.8190401402973326
Validation loss: 2.614023291221189

Epoch: 5| Step: 9
Training loss: 1.9100567688419563
Validation loss: 2.5194464546288424

Epoch: 5| Step: 10
Training loss: 2.0911933890351313
Validation loss: 2.532318154200699

Epoch: 570| Step: 0
Training loss: 1.5642237501071161
Validation loss: 2.4700852668531974

Epoch: 5| Step: 1
Training loss: 1.6588385165527786
Validation loss: 2.6091665963699526

Epoch: 5| Step: 2
Training loss: 1.8472142406600316
Validation loss: 2.524850133791637

Epoch: 5| Step: 3
Training loss: 2.0095055711246137
Validation loss: 2.483085109144898

Epoch: 5| Step: 4
Training loss: 2.179995169852969
Validation loss: 2.472808154641465

Epoch: 5| Step: 5
Training loss: 2.210136025674357
Validation loss: 2.5411951319258046

Epoch: 5| Step: 6
Training loss: 2.129086884001037
Validation loss: 2.4462220427717853

Epoch: 5| Step: 7
Training loss: 1.742921135909062
Validation loss: 2.5623484961149545

Epoch: 5| Step: 8
Training loss: 2.7770448247515196
Validation loss: 2.5457977189784455

Epoch: 5| Step: 9
Training loss: 1.832021359414933
Validation loss: 2.5866005812022825

Epoch: 5| Step: 10
Training loss: 2.3881669715641376
Validation loss: 2.5798659357287588

Epoch: 571| Step: 0
Training loss: 2.2208280905637237
Validation loss: 2.730999701513647

Epoch: 5| Step: 1
Training loss: 1.8531588983893
Validation loss: 2.4570404970221444

Epoch: 5| Step: 2
Training loss: 2.4864950670891037
Validation loss: 2.5618841550233182

Epoch: 5| Step: 3
Training loss: 2.46626543012182
Validation loss: 2.5303214043665045

Epoch: 5| Step: 4
Training loss: 2.0163118833255544
Validation loss: 2.482898949829035

Epoch: 5| Step: 5
Training loss: 1.982563002500467
Validation loss: 2.6114564468138295

Epoch: 5| Step: 6
Training loss: 2.125906246145658
Validation loss: 2.6808088798786893

Epoch: 5| Step: 7
Training loss: 1.695728936445996
Validation loss: 2.4273725088535882

Epoch: 5| Step: 8
Training loss: 2.189225524451883
Validation loss: 2.55136413552684

Epoch: 5| Step: 9
Training loss: 1.8828520078194169
Validation loss: 2.5019660079634747

Epoch: 5| Step: 10
Training loss: 1.6869100316449903
Validation loss: 2.572414107153839

Epoch: 572| Step: 0
Training loss: 3.2908358108795825
Validation loss: 2.568575358354242

Epoch: 5| Step: 1
Training loss: 2.317783608803628
Validation loss: 2.4705681804157424

Epoch: 5| Step: 2
Training loss: 1.5578905397876839
Validation loss: 2.5339051711037954

Epoch: 5| Step: 3
Training loss: 1.7417127022142438
Validation loss: 2.449588020917083

Epoch: 5| Step: 4
Training loss: 1.81387237682814
Validation loss: 2.4228475787169743

Epoch: 5| Step: 5
Training loss: 2.1084567861889116
Validation loss: 2.5334190642016052

Epoch: 5| Step: 6
Training loss: 2.1410027609196645
Validation loss: 2.5423497842555602

Epoch: 5| Step: 7
Training loss: 1.7147266113314612
Validation loss: 2.500581492200615

Epoch: 5| Step: 8
Training loss: 1.8725499994709884
Validation loss: 2.5644876133376964

Epoch: 5| Step: 9
Training loss: 2.3543619620638383
Validation loss: 2.543331420738161

Epoch: 5| Step: 10
Training loss: 1.4535629268864914
Validation loss: 2.5175740110793527

Epoch: 573| Step: 0
Training loss: 1.950637209535355
Validation loss: 2.5661110314789295

Epoch: 5| Step: 1
Training loss: 2.422029847147812
Validation loss: 2.5830418789168674

Epoch: 5| Step: 2
Training loss: 1.9711558461850096
Validation loss: 2.5659497957798503

Epoch: 5| Step: 3
Training loss: 1.6939233810815446
Validation loss: 2.5097357326365115

Epoch: 5| Step: 4
Training loss: 2.867280631150958
Validation loss: 2.4455634527653265

Epoch: 5| Step: 5
Training loss: 2.025979702221791
Validation loss: 2.4986778300834844

Epoch: 5| Step: 6
Training loss: 1.918654682388857
Validation loss: 2.6072334548696

Epoch: 5| Step: 7
Training loss: 1.6377573291589531
Validation loss: 2.6139866029843746

Epoch: 5| Step: 8
Training loss: 1.3444238348284085
Validation loss: 2.5366962361131984

Epoch: 5| Step: 9
Training loss: 1.8960964383615895
Validation loss: 2.5277880896020997

Epoch: 5| Step: 10
Training loss: 2.5438379071016732
Validation loss: 2.5615498311614973

Epoch: 574| Step: 0
Training loss: 1.172426170432254
Validation loss: 2.5139809486243636

Epoch: 5| Step: 1
Training loss: 2.0996672866286636
Validation loss: 2.548864438559655

Epoch: 5| Step: 2
Training loss: 2.1291633660675964
Validation loss: 2.574751140963362

Epoch: 5| Step: 3
Training loss: 1.9785509322876917
Validation loss: 2.57511038288254

Epoch: 5| Step: 4
Training loss: 1.9388279209674082
Validation loss: 2.560086995777346

Epoch: 5| Step: 5
Training loss: 2.1060952013674266
Validation loss: 2.536807957898149

Epoch: 5| Step: 6
Training loss: 1.4819139658399503
Validation loss: 2.682636654001041

Epoch: 5| Step: 7
Training loss: 1.8751672034416123
Validation loss: 2.5757706707183994

Epoch: 5| Step: 8
Training loss: 2.719289441140326
Validation loss: 2.516747208759554

Epoch: 5| Step: 9
Training loss: 2.7234886352851007
Validation loss: 2.610207192436041

Epoch: 5| Step: 10
Training loss: 1.9091758786526905
Validation loss: 2.5108944987835162

Epoch: 575| Step: 0
Training loss: 2.5723259642873084
Validation loss: 2.573013901331448

Epoch: 5| Step: 1
Training loss: 1.4921692852086907
Validation loss: 2.6203761397491974

Epoch: 5| Step: 2
Training loss: 2.0368421604240012
Validation loss: 2.463381447119928

Epoch: 5| Step: 3
Training loss: 1.5926053293509048
Validation loss: 2.5422874861170546

Epoch: 5| Step: 4
Training loss: 1.7798097375917368
Validation loss: 2.5858298777685658

Epoch: 5| Step: 5
Training loss: 1.8466508964985284
Validation loss: 2.5682084064336372

Epoch: 5| Step: 6
Training loss: 1.9758685556160525
Validation loss: 2.5405662325691676

Epoch: 5| Step: 7
Training loss: 2.282595198652592
Validation loss: 2.5357887546776334

Epoch: 5| Step: 8
Training loss: 1.9187734745341691
Validation loss: 2.584486574612274

Epoch: 5| Step: 9
Training loss: 2.58482249213102
Validation loss: 2.528648409835743

Epoch: 5| Step: 10
Training loss: 1.9809770702977998
Validation loss: 2.5647985712442636

Epoch: 576| Step: 0
Training loss: 1.5981868991195027
Validation loss: 2.576307175571785

Epoch: 5| Step: 1
Training loss: 1.6135360110212307
Validation loss: 2.5087617806328795

Epoch: 5| Step: 2
Training loss: 1.876749494067513
Validation loss: 2.4743005752664935

Epoch: 5| Step: 3
Training loss: 1.9911688500372138
Validation loss: 2.5182915034550417

Epoch: 5| Step: 4
Training loss: 2.6445911124594685
Validation loss: 2.4689928327131514

Epoch: 5| Step: 5
Training loss: 2.291897109034007
Validation loss: 2.5934188202380106

Epoch: 5| Step: 6
Training loss: 1.9718415948181365
Validation loss: 2.398913307261287

Epoch: 5| Step: 7
Training loss: 2.042636589049632
Validation loss: 2.5584434436947645

Epoch: 5| Step: 8
Training loss: 1.9839829786055025
Validation loss: 2.513121308100156

Epoch: 5| Step: 9
Training loss: 2.307160063033668
Validation loss: 2.475332564235875

Epoch: 5| Step: 10
Training loss: 1.7131656438994742
Validation loss: 2.426421855421569

Epoch: 577| Step: 0
Training loss: 2.081335012171718
Validation loss: 2.527361028577681

Epoch: 5| Step: 1
Training loss: 1.7350453636329328
Validation loss: 2.489257414965699

Epoch: 5| Step: 2
Training loss: 2.1288143033111595
Validation loss: 2.5486029656597013

Epoch: 5| Step: 3
Training loss: 2.388940354712018
Validation loss: 2.532785816427458

Epoch: 5| Step: 4
Training loss: 2.0460778933825012
Validation loss: 2.6441321167892533

Epoch: 5| Step: 5
Training loss: 2.3020149899747837
Validation loss: 2.4879637090738473

Epoch: 5| Step: 6
Training loss: 1.9798210935972442
Validation loss: 2.617147349314561

Epoch: 5| Step: 7
Training loss: 2.055479875952761
Validation loss: 2.4743315836884068

Epoch: 5| Step: 8
Training loss: 2.019771362433468
Validation loss: 2.5412186154238747

Epoch: 5| Step: 9
Training loss: 2.0446573139138873
Validation loss: 2.588331239277125

Epoch: 5| Step: 10
Training loss: 1.9157884562267935
Validation loss: 2.6498553021792004

Epoch: 578| Step: 0
Training loss: 1.5758953395501303
Validation loss: 2.5470090592120713

Epoch: 5| Step: 1
Training loss: 1.5782054465156756
Validation loss: 2.5775741953314255

Epoch: 5| Step: 2
Training loss: 2.4983212556689143
Validation loss: 2.5580521786372366

Epoch: 5| Step: 3
Training loss: 2.2609986524345906
Validation loss: 2.5744728987318424

Epoch: 5| Step: 4
Training loss: 1.717596950432176
Validation loss: 2.592383162812459

Epoch: 5| Step: 5
Training loss: 2.261846298284432
Validation loss: 2.6164035034880553

Epoch: 5| Step: 6
Training loss: 2.038829220110315
Validation loss: 2.6003031689574883

Epoch: 5| Step: 7
Training loss: 1.5098939276064
Validation loss: 2.5518518024331613

Epoch: 5| Step: 8
Training loss: 1.9590265453968352
Validation loss: 2.5358537186353507

Epoch: 5| Step: 9
Training loss: 2.5692524216757335
Validation loss: 2.629259677030486

Epoch: 5| Step: 10
Training loss: 2.455113862110622
Validation loss: 2.5799396312500273

Epoch: 579| Step: 0
Training loss: 1.8509529494658892
Validation loss: 2.543349897041241

Epoch: 5| Step: 1
Training loss: 2.6769585685502073
Validation loss: 2.5458183892600954

Epoch: 5| Step: 2
Training loss: 2.083899141408067
Validation loss: 2.590291484581803

Epoch: 5| Step: 3
Training loss: 2.2137780156831823
Validation loss: 2.564951862423298

Epoch: 5| Step: 4
Training loss: 1.9606191065088332
Validation loss: 2.543305134362176

Epoch: 5| Step: 5
Training loss: 1.6329160958604074
Validation loss: 2.4712207684319316

Epoch: 5| Step: 6
Training loss: 1.8118812557242736
Validation loss: 2.489732604396523

Epoch: 5| Step: 7
Training loss: 1.8804174995490959
Validation loss: 2.6105813513241967

Epoch: 5| Step: 8
Training loss: 1.6859894101951778
Validation loss: 2.6033143556523477

Epoch: 5| Step: 9
Training loss: 2.5207949758926924
Validation loss: 2.5257538283351106

Epoch: 5| Step: 10
Training loss: 1.427398349863953
Validation loss: 2.5746955114513104

Epoch: 580| Step: 0
Training loss: 2.9758867112408107
Validation loss: 2.5406054169541967

Epoch: 5| Step: 1
Training loss: 1.8801869173670689
Validation loss: 2.52080967145483

Epoch: 5| Step: 2
Training loss: 2.240652163459279
Validation loss: 2.5480171590355973

Epoch: 5| Step: 3
Training loss: 1.7757333019813604
Validation loss: 2.5398932802439202

Epoch: 5| Step: 4
Training loss: 1.3869968189238777
Validation loss: 2.5121691096592733

Epoch: 5| Step: 5
Training loss: 1.9796545999950022
Validation loss: 2.5653238601679575

Epoch: 5| Step: 6
Training loss: 2.110767046458245
Validation loss: 2.5613976415242803

Epoch: 5| Step: 7
Training loss: 1.8649313475831006
Validation loss: 2.596293427349141

Epoch: 5| Step: 8
Training loss: 1.9457638381648252
Validation loss: 2.4975282334845956

Epoch: 5| Step: 9
Training loss: 1.8193470109407035
Validation loss: 2.53675810967057

Epoch: 5| Step: 10
Training loss: 1.7297024720189234
Validation loss: 2.4851735846930647

Epoch: 581| Step: 0
Training loss: 2.0313450717684933
Validation loss: 2.4528307116734136

Epoch: 5| Step: 1
Training loss: 1.8433347331358485
Validation loss: 2.4518266278679177

Epoch: 5| Step: 2
Training loss: 2.417173288669742
Validation loss: 2.558686564037307

Epoch: 5| Step: 3
Training loss: 1.5514714701245633
Validation loss: 2.4912372312333853

Epoch: 5| Step: 4
Training loss: 1.9167680575325103
Validation loss: 2.5145018876856886

Epoch: 5| Step: 5
Training loss: 2.1170480830048226
Validation loss: 2.544156064955588

Epoch: 5| Step: 6
Training loss: 2.9610176981429577
Validation loss: 2.464656897312511

Epoch: 5| Step: 7
Training loss: 1.5799864564387591
Validation loss: 2.524635099078345

Epoch: 5| Step: 8
Training loss: 2.2119808902708313
Validation loss: 2.534294188773296

Epoch: 5| Step: 9
Training loss: 1.8382708068110052
Validation loss: 2.589345219040168

Epoch: 5| Step: 10
Training loss: 1.6959147987512264
Validation loss: 2.5734161918996197

Epoch: 582| Step: 0
Training loss: 2.0143397765552358
Validation loss: 2.4794646928742456

Epoch: 5| Step: 1
Training loss: 2.210641254756788
Validation loss: 2.5406887534072133

Epoch: 5| Step: 2
Training loss: 1.783550316394135
Validation loss: 2.5363416932777905

Epoch: 5| Step: 3
Training loss: 1.9180601140964904
Validation loss: 2.5222702920784856

Epoch: 5| Step: 4
Training loss: 1.6801207937229525
Validation loss: 2.5645826916625403

Epoch: 5| Step: 5
Training loss: 1.8967645754401825
Validation loss: 2.61263599704153

Epoch: 5| Step: 6
Training loss: 2.514496259806778
Validation loss: 2.5808995843776437

Epoch: 5| Step: 7
Training loss: 1.8501651174730493
Validation loss: 2.556885658352417

Epoch: 5| Step: 8
Training loss: 2.5037072351072553
Validation loss: 2.6058253573267103

Epoch: 5| Step: 9
Training loss: 2.0021179429105116
Validation loss: 2.545785082497505

Epoch: 5| Step: 10
Training loss: 2.1517787406369706
Validation loss: 2.496936538280675

Epoch: 583| Step: 0
Training loss: 2.304523423383529
Validation loss: 2.5721636650017694

Epoch: 5| Step: 1
Training loss: 1.9574052830139252
Validation loss: 2.5969340635946754

Epoch: 5| Step: 2
Training loss: 2.302687782806312
Validation loss: 2.493988076899431

Epoch: 5| Step: 3
Training loss: 1.2803731569610026
Validation loss: 2.668836044488687

Epoch: 5| Step: 4
Training loss: 2.5443970028463054
Validation loss: 2.589499127245159

Epoch: 5| Step: 5
Training loss: 1.9155249788890576
Validation loss: 2.572042520892789

Epoch: 5| Step: 6
Training loss: 2.692235102041708
Validation loss: 2.4619919790859672

Epoch: 5| Step: 7
Training loss: 1.9832161350511008
Validation loss: 2.5543272897127913

Epoch: 5| Step: 8
Training loss: 1.4550067653695353
Validation loss: 2.5680985607979734

Epoch: 5| Step: 9
Training loss: 1.7420398324557762
Validation loss: 2.5967538782888244

Epoch: 5| Step: 10
Training loss: 1.6406167892977206
Validation loss: 2.4918938311159367

Epoch: 584| Step: 0
Training loss: 1.5475585660190019
Validation loss: 2.522174422200996

Epoch: 5| Step: 1
Training loss: 2.4757031414871387
Validation loss: 2.4953304108718597

Epoch: 5| Step: 2
Training loss: 2.3509502437620875
Validation loss: 2.6097646040094458

Epoch: 5| Step: 3
Training loss: 2.215667302382881
Validation loss: 2.576193683555623

Epoch: 5| Step: 4
Training loss: 2.1071229568908745
Validation loss: 2.5873201487758557

Epoch: 5| Step: 5
Training loss: 1.8447266271216571
Validation loss: 2.540215950879988

Epoch: 5| Step: 6
Training loss: 1.6612301214333376
Validation loss: 2.5245140382921862

Epoch: 5| Step: 7
Training loss: 1.2537197081233369
Validation loss: 2.585906005723107

Epoch: 5| Step: 8
Training loss: 2.1861748087337483
Validation loss: 2.5802424600533285

Epoch: 5| Step: 9
Training loss: 1.6596332758537486
Validation loss: 2.50823944089679

Epoch: 5| Step: 10
Training loss: 2.0235832485892313
Validation loss: 2.542725810549767

Epoch: 585| Step: 0
Training loss: 2.1928682125516867
Validation loss: 2.5706931690479937

Epoch: 5| Step: 1
Training loss: 1.97123355740092
Validation loss: 2.5744148792276587

Epoch: 5| Step: 2
Training loss: 1.9281047554128015
Validation loss: 2.5593012061124565

Epoch: 5| Step: 3
Training loss: 2.1109579292850498
Validation loss: 2.612063789013142

Epoch: 5| Step: 4
Training loss: 1.825372890367486
Validation loss: 2.6174374510769325

Epoch: 5| Step: 5
Training loss: 1.9203444177940792
Validation loss: 2.5968601928729482

Epoch: 5| Step: 6
Training loss: 1.4116128177723501
Validation loss: 2.5614370687169448

Epoch: 5| Step: 7
Training loss: 2.5667339795025903
Validation loss: 2.6278960144561267

Epoch: 5| Step: 8
Training loss: 2.476419727530177
Validation loss: 2.5993920114685736

Epoch: 5| Step: 9
Training loss: 2.2372804970934155
Validation loss: 2.652661422700104

Epoch: 5| Step: 10
Training loss: 1.3560097793687826
Validation loss: 2.5070324921892735

Epoch: 586| Step: 0
Training loss: 1.8994591244253056
Validation loss: 2.558475907301717

Epoch: 5| Step: 1
Training loss: 2.0154978394133622
Validation loss: 2.4962848448511066

Epoch: 5| Step: 2
Training loss: 2.3116184306962344
Validation loss: 2.6107147915373177

Epoch: 5| Step: 3
Training loss: 2.04989529319017
Validation loss: 2.572133909752809

Epoch: 5| Step: 4
Training loss: 1.8714913919277893
Validation loss: 2.5096652986751695

Epoch: 5| Step: 5
Training loss: 2.6019393143962413
Validation loss: 2.5143255955329584

Epoch: 5| Step: 6
Training loss: 1.9020152346846257
Validation loss: 2.542440453655035

Epoch: 5| Step: 7
Training loss: 1.8440863738900803
Validation loss: 2.5403249616232513

Epoch: 5| Step: 8
Training loss: 1.7802799327269403
Validation loss: 2.676735320816464

Epoch: 5| Step: 9
Training loss: 1.796039021949545
Validation loss: 2.4929366815278042

Epoch: 5| Step: 10
Training loss: 1.6307001641503895
Validation loss: 2.488941773291267

Epoch: 587| Step: 0
Training loss: 2.5588795276650425
Validation loss: 2.607017325873442

Epoch: 5| Step: 1
Training loss: 1.7637814374753862
Validation loss: 2.5884537365704365

Epoch: 5| Step: 2
Training loss: 2.2671084053024066
Validation loss: 2.563170644668755

Epoch: 5| Step: 3
Training loss: 1.8129583634205
Validation loss: 2.508903639423799

Epoch: 5| Step: 4
Training loss: 2.099762212823831
Validation loss: 2.532694886422446

Epoch: 5| Step: 5
Training loss: 1.9876529322871577
Validation loss: 2.536082259569432

Epoch: 5| Step: 6
Training loss: 1.8383851961836288
Validation loss: 2.5618012183576466

Epoch: 5| Step: 7
Training loss: 1.7179595516803405
Validation loss: 2.565730194177108

Epoch: 5| Step: 8
Training loss: 2.3257356197761823
Validation loss: 2.511852231959664

Epoch: 5| Step: 9
Training loss: 1.756708366338247
Validation loss: 2.5382249261893857

Epoch: 5| Step: 10
Training loss: 1.7761120227589575
Validation loss: 2.4897834064830704

Epoch: 588| Step: 0
Training loss: 2.1658428044079656
Validation loss: 2.556069229128204

Epoch: 5| Step: 1
Training loss: 2.2052880889159914
Validation loss: 2.545800964062146

Epoch: 5| Step: 2
Training loss: 1.9396189515981437
Validation loss: 2.587313322815936

Epoch: 5| Step: 3
Training loss: 2.59511419982118
Validation loss: 2.45830473579916

Epoch: 5| Step: 4
Training loss: 2.3900200570833077
Validation loss: 2.550026139107874

Epoch: 5| Step: 5
Training loss: 2.356542440626754
Validation loss: 2.4710992404377645

Epoch: 5| Step: 6
Training loss: 1.65087775089615
Validation loss: 2.6127028490193487

Epoch: 5| Step: 7
Training loss: 1.841414184294266
Validation loss: 2.568381021066001

Epoch: 5| Step: 8
Training loss: 1.9701070195867223
Validation loss: 2.503198429640788

Epoch: 5| Step: 9
Training loss: 1.301344466064731
Validation loss: 2.4868677735514964

Epoch: 5| Step: 10
Training loss: 1.5196289188014105
Validation loss: 2.4892948261668733

Epoch: 589| Step: 0
Training loss: 1.477410047991212
Validation loss: 2.5986493911575335

Epoch: 5| Step: 1
Training loss: 2.0089609149569605
Validation loss: 2.527220010062088

Epoch: 5| Step: 2
Training loss: 1.7653918492140384
Validation loss: 2.5032352658527453

Epoch: 5| Step: 3
Training loss: 2.4528504236200535
Validation loss: 2.543813474254802

Epoch: 5| Step: 4
Training loss: 1.8086389655440707
Validation loss: 2.6114311161443404

Epoch: 5| Step: 5
Training loss: 2.606973605251692
Validation loss: 2.4721898156718627

Epoch: 5| Step: 6
Training loss: 2.0871867464500835
Validation loss: 2.51367261135238

Epoch: 5| Step: 7
Training loss: 1.9168459836034213
Validation loss: 2.5068586087452163

Epoch: 5| Step: 8
Training loss: 1.6026973518336851
Validation loss: 2.576211414423854

Epoch: 5| Step: 9
Training loss: 1.8552879486335727
Validation loss: 2.554148732822507

Epoch: 5| Step: 10
Training loss: 1.8801756950215531
Validation loss: 2.490066450208959

Epoch: 590| Step: 0
Training loss: 1.783188685079815
Validation loss: 2.487486391550223

Epoch: 5| Step: 1
Training loss: 1.7548897413521394
Validation loss: 2.5800604308896102

Epoch: 5| Step: 2
Training loss: 2.0058747080186237
Validation loss: 2.521515381683416

Epoch: 5| Step: 3
Training loss: 2.2468474873223196
Validation loss: 2.498172360626168

Epoch: 5| Step: 4
Training loss: 2.8441049542919177
Validation loss: 2.6636379915226933

Epoch: 5| Step: 5
Training loss: 1.9218942284591318
Validation loss: 2.5454263710045657

Epoch: 5| Step: 6
Training loss: 1.778315553025104
Validation loss: 2.5004558445026315

Epoch: 5| Step: 7
Training loss: 1.9568405819902588
Validation loss: 2.491689833872436

Epoch: 5| Step: 8
Training loss: 1.7960581373987479
Validation loss: 2.4943200725218113

Epoch: 5| Step: 9
Training loss: 1.9230560147542684
Validation loss: 2.4724789286799864

Epoch: 5| Step: 10
Training loss: 2.24673617256403
Validation loss: 2.551287905350213

Epoch: 591| Step: 0
Training loss: 1.4944365962475148
Validation loss: 2.592118555825844

Epoch: 5| Step: 1
Training loss: 2.310925127864215
Validation loss: 2.503251458334348

Epoch: 5| Step: 2
Training loss: 1.803511132954966
Validation loss: 2.577521767245516

Epoch: 5| Step: 3
Training loss: 2.4598492835171077
Validation loss: 2.498889380043508

Epoch: 5| Step: 4
Training loss: 2.4095486906110732
Validation loss: 2.582860596425753

Epoch: 5| Step: 5
Training loss: 1.8375610964213012
Validation loss: 2.4818249244960042

Epoch: 5| Step: 6
Training loss: 1.7881106714009904
Validation loss: 2.530843991079727

Epoch: 5| Step: 7
Training loss: 1.594620186597738
Validation loss: 2.495370144292241

Epoch: 5| Step: 8
Training loss: 2.06579453873405
Validation loss: 2.4190912470907957

Epoch: 5| Step: 9
Training loss: 1.982004867817187
Validation loss: 2.5686837319564653

Epoch: 5| Step: 10
Training loss: 1.8372954196317024
Validation loss: 2.4944959450634814

Epoch: 592| Step: 0
Training loss: 1.642391960852561
Validation loss: 2.510296108241214

Epoch: 5| Step: 1
Training loss: 1.641979566597966
Validation loss: 2.518785829095084

Epoch: 5| Step: 2
Training loss: 1.7538196567832416
Validation loss: 2.608391844594994

Epoch: 5| Step: 3
Training loss: 2.1823912774585694
Validation loss: 2.4323179494735014

Epoch: 5| Step: 4
Training loss: 2.1026683294563435
Validation loss: 2.507022943321471

Epoch: 5| Step: 5
Training loss: 1.7075924856403477
Validation loss: 2.6385845551429776

Epoch: 5| Step: 6
Training loss: 2.1113360296307855
Validation loss: 2.5605832025821584

Epoch: 5| Step: 7
Training loss: 2.41036981412368
Validation loss: 2.62128495971577

Epoch: 5| Step: 8
Training loss: 2.061076395417055
Validation loss: 2.551336826607227

Epoch: 5| Step: 9
Training loss: 2.225375424547931
Validation loss: 2.587921995072282

Epoch: 5| Step: 10
Training loss: 2.4332249639060475
Validation loss: 2.493942957639508

Epoch: 593| Step: 0
Training loss: 2.4908059814251433
Validation loss: 2.510585609878227

Epoch: 5| Step: 1
Training loss: 1.537135200332011
Validation loss: 2.4493541517533437

Epoch: 5| Step: 2
Training loss: 1.97390634943034
Validation loss: 2.6067453512457717

Epoch: 5| Step: 3
Training loss: 1.8843843855236637
Validation loss: 2.580377835802136

Epoch: 5| Step: 4
Training loss: 1.529574119410573
Validation loss: 2.5820951413706648

Epoch: 5| Step: 5
Training loss: 2.0212195771239143
Validation loss: 2.4632719193542454

Epoch: 5| Step: 6
Training loss: 1.8828478291469517
Validation loss: 2.4702348959254694

Epoch: 5| Step: 7
Training loss: 2.1974953221953752
Validation loss: 2.516132172913086

Epoch: 5| Step: 8
Training loss: 2.3118872990710333
Validation loss: 2.515492837254889

Epoch: 5| Step: 9
Training loss: 1.9262641471526465
Validation loss: 2.430109964437657

Epoch: 5| Step: 10
Training loss: 2.2565526912461764
Validation loss: 2.561170497227248

Epoch: 594| Step: 0
Training loss: 2.4353165261396748
Validation loss: 2.4434395095100565

Epoch: 5| Step: 1
Training loss: 2.072088782326781
Validation loss: 2.580308899935805

Epoch: 5| Step: 2
Training loss: 1.5734627472595435
Validation loss: 2.4718546957894354

Epoch: 5| Step: 3
Training loss: 2.2689069457191318
Validation loss: 2.5875015934099115

Epoch: 5| Step: 4
Training loss: 1.8972817501759671
Validation loss: 2.5340918323776074

Epoch: 5| Step: 5
Training loss: 1.478650428341127
Validation loss: 2.613134862372179

Epoch: 5| Step: 6
Training loss: 1.631058549425324
Validation loss: 2.4535096207097165

Epoch: 5| Step: 7
Training loss: 2.092832335739382
Validation loss: 2.555036792055559

Epoch: 5| Step: 8
Training loss: 2.0208279193399274
Validation loss: 2.5778471736424224

Epoch: 5| Step: 9
Training loss: 1.9849841166708788
Validation loss: 2.578812026298788

Epoch: 5| Step: 10
Training loss: 2.3368371360223135
Validation loss: 2.5064314571878406

Epoch: 595| Step: 0
Training loss: 2.077488278242294
Validation loss: 2.537779071252109

Epoch: 5| Step: 1
Training loss: 1.792783839844637
Validation loss: 2.566403741704682

Epoch: 5| Step: 2
Training loss: 2.1412151108018826
Validation loss: 2.6037874574926487

Epoch: 5| Step: 3
Training loss: 1.8158888869637877
Validation loss: 2.4965011395434797

Epoch: 5| Step: 4
Training loss: 1.5987264690800023
Validation loss: 2.5154480578608984

Epoch: 5| Step: 5
Training loss: 1.9509656031483407
Validation loss: 2.5605381634722666

Epoch: 5| Step: 6
Training loss: 2.174430715664526
Validation loss: 2.6028416455148746

Epoch: 5| Step: 7
Training loss: 2.3055312858846375
Validation loss: 2.483671414162452

Epoch: 5| Step: 8
Training loss: 1.746583055043207
Validation loss: 2.6171486766116967

Epoch: 5| Step: 9
Training loss: 1.8917131051344576
Validation loss: 2.466324565592589

Epoch: 5| Step: 10
Training loss: 2.3245580601849674
Validation loss: 2.5080132089613656

Epoch: 596| Step: 0
Training loss: 1.9982345656972105
Validation loss: 2.6182469238679653

Epoch: 5| Step: 1
Training loss: 2.1055047593018807
Validation loss: 2.558959982821205

Epoch: 5| Step: 2
Training loss: 2.0673597475980734
Validation loss: 2.4854322203808854

Epoch: 5| Step: 3
Training loss: 2.1486863980469786
Validation loss: 2.5373385646517552

Epoch: 5| Step: 4
Training loss: 2.1205515581270475
Validation loss: 2.5401902044989897

Epoch: 5| Step: 5
Training loss: 2.5065894070683856
Validation loss: 2.484380552162224

Epoch: 5| Step: 6
Training loss: 1.4356282529017688
Validation loss: 2.510559492235657

Epoch: 5| Step: 7
Training loss: 1.935288674755958
Validation loss: 2.5213327064911417

Epoch: 5| Step: 8
Training loss: 2.2495525762955766
Validation loss: 2.472907513090277

Epoch: 5| Step: 9
Training loss: 1.8921616669835786
Validation loss: 2.458488920018251

Epoch: 5| Step: 10
Training loss: 1.5421850604469924
Validation loss: 2.52888681484227

Epoch: 597| Step: 0
Training loss: 2.273977628431765
Validation loss: 2.5501222235744248

Epoch: 5| Step: 1
Training loss: 1.6435836272658244
Validation loss: 2.5859751502662123

Epoch: 5| Step: 2
Training loss: 2.0863092784105346
Validation loss: 2.566334224687981

Epoch: 5| Step: 3
Training loss: 2.024264958103427
Validation loss: 2.588649199759462

Epoch: 5| Step: 4
Training loss: 1.496825992681903
Validation loss: 2.5546597378946356

Epoch: 5| Step: 5
Training loss: 2.3166666383080057
Validation loss: 2.5441448073692547

Epoch: 5| Step: 6
Training loss: 2.25649426266097
Validation loss: 2.499802558034344

Epoch: 5| Step: 7
Training loss: 1.7100781237731066
Validation loss: 2.5362426264499773

Epoch: 5| Step: 8
Training loss: 1.9824106300673994
Validation loss: 2.494428950251728

Epoch: 5| Step: 9
Training loss: 1.9551370251726419
Validation loss: 2.652397979076114

Epoch: 5| Step: 10
Training loss: 2.1370291475727896
Validation loss: 2.49056232027826

Epoch: 598| Step: 0
Training loss: 1.8712442930818733
Validation loss: 2.5079897988885476

Epoch: 5| Step: 1
Training loss: 2.208975524614786
Validation loss: 2.546115889196543

Epoch: 5| Step: 2
Training loss: 2.1117821416114757
Validation loss: 2.506891810924641

Epoch: 5| Step: 3
Training loss: 2.3277626523679937
Validation loss: 2.4721786057647894

Epoch: 5| Step: 4
Training loss: 2.326581814738916
Validation loss: 2.4594812426243267

Epoch: 5| Step: 5
Training loss: 1.3465407467897872
Validation loss: 2.57943417101219

Epoch: 5| Step: 6
Training loss: 2.4176459027575987
Validation loss: 2.516156725800759

Epoch: 5| Step: 7
Training loss: 2.033183307532803
Validation loss: 2.4356292074663752

Epoch: 5| Step: 8
Training loss: 1.8335611750891185
Validation loss: 2.5601086326784452

Epoch: 5| Step: 9
Training loss: 1.8328029414429325
Validation loss: 2.5771073377249345

Epoch: 5| Step: 10
Training loss: 1.6890154497649446
Validation loss: 2.5055017414405594

Epoch: 599| Step: 0
Training loss: 1.7658485338613856
Validation loss: 2.6294393780971013

Epoch: 5| Step: 1
Training loss: 2.0342208264788084
Validation loss: 2.5733128887291854

Epoch: 5| Step: 2
Training loss: 1.800440890569974
Validation loss: 2.453826126909419

Epoch: 5| Step: 3
Training loss: 2.318552499261877
Validation loss: 2.5665295630061786

Epoch: 5| Step: 4
Training loss: 2.4611433639403115
Validation loss: 2.5497239726117606

Epoch: 5| Step: 5
Training loss: 2.090870827675321
Validation loss: 2.4714417596956624

Epoch: 5| Step: 6
Training loss: 1.711839899522882
Validation loss: 2.497867238495128

Epoch: 5| Step: 7
Training loss: 2.046858925792681
Validation loss: 2.573795969618578

Epoch: 5| Step: 8
Training loss: 2.407339567739266
Validation loss: 2.5690067806134693

Epoch: 5| Step: 9
Training loss: 1.6924074658746031
Validation loss: 2.6138044320690774

Epoch: 5| Step: 10
Training loss: 1.6791951012235065
Validation loss: 2.5590378958896465

Epoch: 600| Step: 0
Training loss: 1.5139744216290194
Validation loss: 2.5478920525523288

Epoch: 5| Step: 1
Training loss: 1.7897995675676732
Validation loss: 2.5314033711996826

Epoch: 5| Step: 2
Training loss: 2.4994393673750284
Validation loss: 2.5851294217782

Epoch: 5| Step: 3
Training loss: 1.8321414743544127
Validation loss: 2.571756579070673

Epoch: 5| Step: 4
Training loss: 1.7436692304602688
Validation loss: 2.516392766902111

Epoch: 5| Step: 5
Training loss: 1.8780539754681516
Validation loss: 2.4878448084511215

Epoch: 5| Step: 6
Training loss: 2.127827838422799
Validation loss: 2.515873473740655

Epoch: 5| Step: 7
Training loss: 1.7745067717078213
Validation loss: 2.4598225917368506

Epoch: 5| Step: 8
Training loss: 2.0086882941044673
Validation loss: 2.542746068741145

Epoch: 5| Step: 9
Training loss: 1.4729784706598619
Validation loss: 2.4742963562343867

Epoch: 5| Step: 10
Training loss: 2.1357046785972376
Validation loss: 2.5860336301209497

Epoch: 601| Step: 0
Training loss: 2.181417455503036
Validation loss: 2.454333077713479

Epoch: 5| Step: 1
Training loss: 2.146206227713218
Validation loss: 2.4821158226805675

Epoch: 5| Step: 2
Training loss: 2.4884615702544615
Validation loss: 2.6148496488172412

Epoch: 5| Step: 3
Training loss: 1.621409851876021
Validation loss: 2.506233448866597

Epoch: 5| Step: 4
Training loss: 2.4145678142567824
Validation loss: 2.601810784800552

Epoch: 5| Step: 5
Training loss: 1.7432580233342365
Validation loss: 2.542004178730898

Epoch: 5| Step: 6
Training loss: 1.3818372315309753
Validation loss: 2.43568039386919

Epoch: 5| Step: 7
Training loss: 1.7141668074105068
Validation loss: 2.6259277665287803

Epoch: 5| Step: 8
Training loss: 1.89487370807466
Validation loss: 2.5631482844719593

Epoch: 5| Step: 9
Training loss: 2.1391924220239806
Validation loss: 2.621631283124637

Epoch: 5| Step: 10
Training loss: 2.1257296038953197
Validation loss: 2.5012765885993398

Epoch: 602| Step: 0
Training loss: 2.3275337236462748
Validation loss: 2.496753206565226

Epoch: 5| Step: 1
Training loss: 1.605732026057915
Validation loss: 2.570991626622946

Epoch: 5| Step: 2
Training loss: 1.7008902911240882
Validation loss: 2.5742093816386897

Epoch: 5| Step: 3
Training loss: 1.9977752709764918
Validation loss: 2.54411191905109

Epoch: 5| Step: 4
Training loss: 1.9708285788007598
Validation loss: 2.5810784013094348

Epoch: 5| Step: 5
Training loss: 1.463631171298604
Validation loss: 2.5149965484040284

Epoch: 5| Step: 6
Training loss: 2.607855074325274
Validation loss: 2.5292321470562564

Epoch: 5| Step: 7
Training loss: 2.0028743354964345
Validation loss: 2.50021156420794

Epoch: 5| Step: 8
Training loss: 2.167556751040658
Validation loss: 2.5587498685877024

Epoch: 5| Step: 9
Training loss: 1.6397438953051637
Validation loss: 2.5045688923302563

Epoch: 5| Step: 10
Training loss: 1.5903889988741333
Validation loss: 2.599997563199273

Epoch: 603| Step: 0
Training loss: 1.9956506883142868
Validation loss: 2.5014862554571766

Epoch: 5| Step: 1
Training loss: 1.6577974683707521
Validation loss: 2.5408200192496064

Epoch: 5| Step: 2
Training loss: 1.6340042948392084
Validation loss: 2.494217562615653

Epoch: 5| Step: 3
Training loss: 2.166666385454991
Validation loss: 2.647268889472075

Epoch: 5| Step: 4
Training loss: 2.0700441582434026
Validation loss: 2.6246292010581813

Epoch: 5| Step: 5
Training loss: 1.4623447107539551
Validation loss: 2.6070292766391403

Epoch: 5| Step: 6
Training loss: 2.0904491082570384
Validation loss: 2.505756505383329

Epoch: 5| Step: 7
Training loss: 1.7631817682722135
Validation loss: 2.49256612600737

Epoch: 5| Step: 8
Training loss: 1.9058377179672361
Validation loss: 2.476761731472578

Epoch: 5| Step: 9
Training loss: 2.255881146742882
Validation loss: 2.5712333999606747

Epoch: 5| Step: 10
Training loss: 2.7244529104939623
Validation loss: 2.554574687537025

Epoch: 604| Step: 0
Training loss: 1.774135301072909
Validation loss: 2.544506499933453

Epoch: 5| Step: 1
Training loss: 2.467260370029987
Validation loss: 2.5986162919425975

Epoch: 5| Step: 2
Training loss: 2.2739958716483373
Validation loss: 2.432792467794911

Epoch: 5| Step: 3
Training loss: 1.4413620856737637
Validation loss: 2.522607340995454

Epoch: 5| Step: 4
Training loss: 1.553582800587091
Validation loss: 2.549024518724628

Epoch: 5| Step: 5
Training loss: 2.2118640481376444
Validation loss: 2.6517989678233604

Epoch: 5| Step: 6
Training loss: 2.1945256353668388
Validation loss: 2.5540642867694086

Epoch: 5| Step: 7
Training loss: 1.9033929019275753
Validation loss: 2.541288282799519

Epoch: 5| Step: 8
Training loss: 1.6376614643891425
Validation loss: 2.455237764275255

Epoch: 5| Step: 9
Training loss: 2.171108741886942
Validation loss: 2.4582528999216824

Epoch: 5| Step: 10
Training loss: 1.903763259070067
Validation loss: 2.4810790192555703

Epoch: 605| Step: 0
Training loss: 2.080448085497496
Validation loss: 2.5505892215812582

Epoch: 5| Step: 1
Training loss: 2.0573879814941285
Validation loss: 2.558895024398221

Epoch: 5| Step: 2
Training loss: 2.469285930937936
Validation loss: 2.4406455636174114

Epoch: 5| Step: 3
Training loss: 2.145530148417247
Validation loss: 2.5735617039102983

Epoch: 5| Step: 4
Training loss: 1.7327921750086592
Validation loss: 2.521173937398046

Epoch: 5| Step: 5
Training loss: 1.8986723954675986
Validation loss: 2.555619214566783

Epoch: 5| Step: 6
Training loss: 2.4281791101659165
Validation loss: 2.5616729045811213

Epoch: 5| Step: 7
Training loss: 1.3577744279973785
Validation loss: 2.639805861305163

Epoch: 5| Step: 8
Training loss: 2.0518661100048
Validation loss: 2.560162218945775

Epoch: 5| Step: 9
Training loss: 2.0093960584423964
Validation loss: 2.4994299166838925

Epoch: 5| Step: 10
Training loss: 1.745249704240447
Validation loss: 2.4781954362209526

Epoch: 606| Step: 0
Training loss: 2.2985926842183013
Validation loss: 2.496405186830554

Epoch: 5| Step: 1
Training loss: 1.9717663258925866
Validation loss: 2.5895717759354167

Epoch: 5| Step: 2
Training loss: 1.6555776130919357
Validation loss: 2.4562775431935084

Epoch: 5| Step: 3
Training loss: 1.948768211999031
Validation loss: 2.5339516568670195

Epoch: 5| Step: 4
Training loss: 1.7610182627695437
Validation loss: 2.558561987273862

Epoch: 5| Step: 5
Training loss: 1.8351801182545455
Validation loss: 2.551364165671192

Epoch: 5| Step: 6
Training loss: 1.5703045289705575
Validation loss: 2.5865385202683377

Epoch: 5| Step: 7
Training loss: 2.0363665183622848
Validation loss: 2.5339482084290714

Epoch: 5| Step: 8
Training loss: 2.587196804103163
Validation loss: 2.5163008920024335

Epoch: 5| Step: 9
Training loss: 2.0441897884429214
Validation loss: 2.558849951566694

Epoch: 5| Step: 10
Training loss: 1.6043367502120789
Validation loss: 2.568686957110037

Epoch: 607| Step: 0
Training loss: 2.2212473823905468
Validation loss: 2.5547677329461855

Epoch: 5| Step: 1
Training loss: 1.7660461193642243
Validation loss: 2.5636916432428953

Epoch: 5| Step: 2
Training loss: 1.4227763243126652
Validation loss: 2.509602283161075

Epoch: 5| Step: 3
Training loss: 2.1118715559092243
Validation loss: 2.4933150410785894

Epoch: 5| Step: 4
Training loss: 1.5225379831371086
Validation loss: 2.4931799841497013

Epoch: 5| Step: 5
Training loss: 1.9127788988592018
Validation loss: 2.5639404442195506

Epoch: 5| Step: 6
Training loss: 1.902536370710484
Validation loss: 2.495277273432215

Epoch: 5| Step: 7
Training loss: 2.3850440410330447
Validation loss: 2.5355635915747654

Epoch: 5| Step: 8
Training loss: 2.070654844373535
Validation loss: 2.5946095941542113

Epoch: 5| Step: 9
Training loss: 2.3913180275476766
Validation loss: 2.4322493811383517

Epoch: 5| Step: 10
Training loss: 2.5617917640567347
Validation loss: 2.429819657999155

Epoch: 608| Step: 0
Training loss: 2.289803550989478
Validation loss: 2.542607884769343

Epoch: 5| Step: 1
Training loss: 2.1321145057847124
Validation loss: 2.4988271176936534

Epoch: 5| Step: 2
Training loss: 1.9714253730629512
Validation loss: 2.4521526935930695

Epoch: 5| Step: 3
Training loss: 1.7917218828194696
Validation loss: 2.429962894904695

Epoch: 5| Step: 4
Training loss: 1.8860002180162063
Validation loss: 2.4267660651268126

Epoch: 5| Step: 5
Training loss: 2.2686084965906352
Validation loss: 2.5146188866001684

Epoch: 5| Step: 6
Training loss: 1.63963106110972
Validation loss: 2.565331050436917

Epoch: 5| Step: 7
Training loss: 1.8901440978244943
Validation loss: 2.5411339364088605

Epoch: 5| Step: 8
Training loss: 2.2128042152011576
Validation loss: 2.5256362469603086

Epoch: 5| Step: 9
Training loss: 1.3382629322016493
Validation loss: 2.5907246192523057

Epoch: 5| Step: 10
Training loss: 2.326025406512565
Validation loss: 2.5104866775460586

Epoch: 609| Step: 0
Training loss: 1.6362293759088786
Validation loss: 2.6184175409961843

Epoch: 5| Step: 1
Training loss: 1.9818158205183722
Validation loss: 2.5454424572443064

Epoch: 5| Step: 2
Training loss: 1.9804954150810612
Validation loss: 2.5675305176379934

Epoch: 5| Step: 3
Training loss: 2.106604105447006
Validation loss: 2.4942044936770937

Epoch: 5| Step: 4
Training loss: 2.163558846266055
Validation loss: 2.5994581344939434

Epoch: 5| Step: 5
Training loss: 1.4567855341413576
Validation loss: 2.514191375110904

Epoch: 5| Step: 6
Training loss: 2.4372117287783546
Validation loss: 2.5330595847615855

Epoch: 5| Step: 7
Training loss: 1.7491503424001618
Validation loss: 2.5799714527393416

Epoch: 5| Step: 8
Training loss: 1.9335174237224073
Validation loss: 2.550108096541813

Epoch: 5| Step: 9
Training loss: 2.042549163151972
Validation loss: 2.5759171514503363

Epoch: 5| Step: 10
Training loss: 2.3796022897093416
Validation loss: 2.5555289094188787

Epoch: 610| Step: 0
Training loss: 1.6767621492964082
Validation loss: 2.5115459759534766

Epoch: 5| Step: 1
Training loss: 1.652380038825618
Validation loss: 2.503848141375153

Epoch: 5| Step: 2
Training loss: 1.9051674442342512
Validation loss: 2.5857162071094177

Epoch: 5| Step: 3
Training loss: 1.8915046348020887
Validation loss: 2.4803231109116943

Epoch: 5| Step: 4
Training loss: 2.297992979173418
Validation loss: 2.5778149490142233

Epoch: 5| Step: 5
Training loss: 2.3186047367134104
Validation loss: 2.4076055675204455

Epoch: 5| Step: 6
Training loss: 1.9449202666819019
Validation loss: 2.444743647781184

Epoch: 5| Step: 7
Training loss: 2.2450861785592364
Validation loss: 2.5130423330953344

Epoch: 5| Step: 8
Training loss: 1.6606683636833677
Validation loss: 2.594698111332335

Epoch: 5| Step: 9
Training loss: 1.3264090279630847
Validation loss: 2.591980728164301

Epoch: 5| Step: 10
Training loss: 2.8740942813749903
Validation loss: 2.5342542988358017

Epoch: 611| Step: 0
Training loss: 1.8245144263397857
Validation loss: 2.5722504181162082

Epoch: 5| Step: 1
Training loss: 1.8116160243143722
Validation loss: 2.518933531621361

Epoch: 5| Step: 2
Training loss: 1.66918914960072
Validation loss: 2.451597688376208

Epoch: 5| Step: 3
Training loss: 1.624809620782457
Validation loss: 2.52044143484783

Epoch: 5| Step: 4
Training loss: 2.2645352603848155
Validation loss: 2.4927646162781363

Epoch: 5| Step: 5
Training loss: 2.054999150185514
Validation loss: 2.495647334974785

Epoch: 5| Step: 6
Training loss: 2.2218621147629847
Validation loss: 2.515303134932145

Epoch: 5| Step: 7
Training loss: 2.664960693012243
Validation loss: 2.502617649982223

Epoch: 5| Step: 8
Training loss: 1.9338061899949144
Validation loss: 2.571484139081807

Epoch: 5| Step: 9
Training loss: 2.041295725023572
Validation loss: 2.5585462199899167

Epoch: 5| Step: 10
Training loss: 1.3854316433357576
Validation loss: 2.5173330182997473

Epoch: 612| Step: 0
Training loss: 1.8336002487893128
Validation loss: 2.531874025377837

Epoch: 5| Step: 1
Training loss: 2.7817825493312585
Validation loss: 2.6139778116182386

Epoch: 5| Step: 2
Training loss: 1.9256417183303511
Validation loss: 2.479972099106895

Epoch: 5| Step: 3
Training loss: 2.024842470423143
Validation loss: 2.4589637926792025

Epoch: 5| Step: 4
Training loss: 1.4545391134102188
Validation loss: 2.4064099541397237

Epoch: 5| Step: 5
Training loss: 1.6815698766059195
Validation loss: 2.5734629810583787

Epoch: 5| Step: 6
Training loss: 2.047235471710482
Validation loss: 2.5591282475140678

Epoch: 5| Step: 7
Training loss: 1.8412946742504568
Validation loss: 2.5382582685255715

Epoch: 5| Step: 8
Training loss: 1.9125186844455329
Validation loss: 2.4409967808083732

Epoch: 5| Step: 9
Training loss: 1.745393207155929
Validation loss: 2.4531411229932227

Epoch: 5| Step: 10
Training loss: 1.6829698296039586
Validation loss: 2.5400736062867666

Epoch: 613| Step: 0
Training loss: 1.644648531902044
Validation loss: 2.494335551011763

Epoch: 5| Step: 1
Training loss: 2.286279229612883
Validation loss: 2.522224397043843

Epoch: 5| Step: 2
Training loss: 2.07316916252252
Validation loss: 2.6196391226108604

Epoch: 5| Step: 3
Training loss: 2.145997704688673
Validation loss: 2.591940560883957

Epoch: 5| Step: 4
Training loss: 1.5238599142686375
Validation loss: 2.59234235896438

Epoch: 5| Step: 5
Training loss: 2.4260907305916537
Validation loss: 2.466390339534628

Epoch: 5| Step: 6
Training loss: 1.7277064611606565
Validation loss: 2.522165071437806

Epoch: 5| Step: 7
Training loss: 1.7887387711594376
Validation loss: 2.6214120176271933

Epoch: 5| Step: 8
Training loss: 2.0014154670545388
Validation loss: 2.5172890069347837

Epoch: 5| Step: 9
Training loss: 1.6585976139262575
Validation loss: 2.550554882532259

Epoch: 5| Step: 10
Training loss: 1.7500543585917905
Validation loss: 2.4670232453428054

Epoch: 614| Step: 0
Training loss: 1.1773784346303102
Validation loss: 2.524835262734215

Epoch: 5| Step: 1
Training loss: 2.1301863715074223
Validation loss: 2.5478308116144683

Epoch: 5| Step: 2
Training loss: 1.6661135073458686
Validation loss: 2.530043172127895

Epoch: 5| Step: 3
Training loss: 1.6797575470268986
Validation loss: 2.51744400059565

Epoch: 5| Step: 4
Training loss: 1.5607266853640553
Validation loss: 2.520419444195095

Epoch: 5| Step: 5
Training loss: 2.203767074198582
Validation loss: 2.488062986761323

Epoch: 5| Step: 6
Training loss: 2.2382816760743487
Validation loss: 2.5251289392423564

Epoch: 5| Step: 7
Training loss: 2.2483289659296046
Validation loss: 2.5574532941826633

Epoch: 5| Step: 8
Training loss: 2.2427430212371324
Validation loss: 2.5611929672792875

Epoch: 5| Step: 9
Training loss: 2.081518972617814
Validation loss: 2.587537259204208

Epoch: 5| Step: 10
Training loss: 1.7800941732761812
Validation loss: 2.506358525639198

Epoch: 615| Step: 0
Training loss: 1.6207354413881618
Validation loss: 2.494112224919695

Epoch: 5| Step: 1
Training loss: 1.203472632185322
Validation loss: 2.542064710891876

Epoch: 5| Step: 2
Training loss: 1.7026647243269613
Validation loss: 2.6001092104145007

Epoch: 5| Step: 3
Training loss: 2.3932953923263254
Validation loss: 2.5398987912875506

Epoch: 5| Step: 4
Training loss: 2.0019228751525575
Validation loss: 2.5376044507636886

Epoch: 5| Step: 5
Training loss: 2.013771683654922
Validation loss: 2.5058712230120266

Epoch: 5| Step: 6
Training loss: 2.5459607127320614
Validation loss: 2.53516972973673

Epoch: 5| Step: 7
Training loss: 2.228704767115834
Validation loss: 2.4906520196504593

Epoch: 5| Step: 8
Training loss: 1.807802426797272
Validation loss: 2.4536658911425957

Epoch: 5| Step: 9
Training loss: 1.3298470048457838
Validation loss: 2.5545427855216216

Epoch: 5| Step: 10
Training loss: 1.9258805378975201
Validation loss: 2.577185477568593

Epoch: 616| Step: 0
Training loss: 1.6783673443547558
Validation loss: 2.631261752569558

Epoch: 5| Step: 1
Training loss: 2.4880249274682456
Validation loss: 2.481157581640211

Epoch: 5| Step: 2
Training loss: 2.228704981068414
Validation loss: 2.558538390419194

Epoch: 5| Step: 3
Training loss: 1.8671010528089118
Validation loss: 2.5699979233840105

Epoch: 5| Step: 4
Training loss: 1.6280437720129295
Validation loss: 2.5764051521130784

Epoch: 5| Step: 5
Training loss: 2.1022840204333906
Validation loss: 2.5322113500460794

Epoch: 5| Step: 6
Training loss: 1.4188720516187308
Validation loss: 2.535286465505997

Epoch: 5| Step: 7
Training loss: 2.074675256526656
Validation loss: 2.5251413882240676

Epoch: 5| Step: 8
Training loss: 2.8118473567311852
Validation loss: 2.580376031580693

Epoch: 5| Step: 9
Training loss: 1.8247473398135134
Validation loss: 2.475397843020864

Epoch: 5| Step: 10
Training loss: 1.8380888326304103
Validation loss: 2.543046215471514

Epoch: 617| Step: 0
Training loss: 1.7578491885277143
Validation loss: 2.5008028489665497

Epoch: 5| Step: 1
Training loss: 1.6259245076596127
Validation loss: 2.5337343187072174

Epoch: 5| Step: 2
Training loss: 2.170427018090434
Validation loss: 2.5386358016472155

Epoch: 5| Step: 3
Training loss: 2.312786393860334
Validation loss: 2.5167678278352366

Epoch: 5| Step: 4
Training loss: 1.9054106443459993
Validation loss: 2.4931202918350412

Epoch: 5| Step: 5
Training loss: 1.6911152860300598
Validation loss: 2.4642208741097282

Epoch: 5| Step: 6
Training loss: 2.071224141486117
Validation loss: 2.548024253259783

Epoch: 5| Step: 7
Training loss: 1.66918914960072
Validation loss: 2.512554284067835

Epoch: 5| Step: 8
Training loss: 2.630075724566798
Validation loss: 2.4843276417860003

Epoch: 5| Step: 9
Training loss: 1.9833287762608254
Validation loss: 2.4821626318022987

Epoch: 5| Step: 10
Training loss: 1.529445207400643
Validation loss: 2.5258865614982957

Epoch: 618| Step: 0
Training loss: 2.171361080264508
Validation loss: 2.620583733129603

Epoch: 5| Step: 1
Training loss: 1.6866751880329975
Validation loss: 2.5573855547988593

Epoch: 5| Step: 2
Training loss: 2.413171795221122
Validation loss: 2.547636322836016

Epoch: 5| Step: 3
Training loss: 1.9988961749992202
Validation loss: 2.4316651812668937

Epoch: 5| Step: 4
Training loss: 2.3655582272417113
Validation loss: 2.5330863377519637

Epoch: 5| Step: 5
Training loss: 2.411132515852807
Validation loss: 2.458837904403261

Epoch: 5| Step: 6
Training loss: 1.6986604321398822
Validation loss: 2.552724113324159

Epoch: 5| Step: 7
Training loss: 1.5107915040482005
Validation loss: 2.4607710128802656

Epoch: 5| Step: 8
Training loss: 2.076291530315496
Validation loss: 2.5055873995867395

Epoch: 5| Step: 9
Training loss: 2.168338228650716
Validation loss: 2.5106924691233368

Epoch: 5| Step: 10
Training loss: 1.700502108304815
Validation loss: 2.541438406329297

Epoch: 619| Step: 0
Training loss: 1.6624360351877296
Validation loss: 2.453581190254986

Epoch: 5| Step: 1
Training loss: 1.547078514197779
Validation loss: 2.585398665799452

Epoch: 5| Step: 2
Training loss: 1.8757903658491661
Validation loss: 2.5256373604671176

Epoch: 5| Step: 3
Training loss: 1.95180375232072
Validation loss: 2.5377645820465595

Epoch: 5| Step: 4
Training loss: 2.0596171953012092
Validation loss: 2.5045159488530366

Epoch: 5| Step: 5
Training loss: 2.1372868481818563
Validation loss: 2.5384260249778454

Epoch: 5| Step: 6
Training loss: 1.9725141115251914
Validation loss: 2.586093387453661

Epoch: 5| Step: 7
Training loss: 1.8043494630439492
Validation loss: 2.519805475593163

Epoch: 5| Step: 8
Training loss: 2.488124393327951
Validation loss: 2.539050930555314

Epoch: 5| Step: 9
Training loss: 2.0208273294366217
Validation loss: 2.5653563995968467

Epoch: 5| Step: 10
Training loss: 1.3063440371161883
Validation loss: 2.5018176679919994

Epoch: 620| Step: 0
Training loss: 1.9105280414870518
Validation loss: 2.5275384309665734

Epoch: 5| Step: 1
Training loss: 1.6579384025202848
Validation loss: 2.5891475157079293

Epoch: 5| Step: 2
Training loss: 1.433076271396569
Validation loss: 2.637281356821221

Epoch: 5| Step: 3
Training loss: 2.015201376230543
Validation loss: 2.5065667364566195

Epoch: 5| Step: 4
Training loss: 1.9877902100969558
Validation loss: 2.4450277439008516

Epoch: 5| Step: 5
Training loss: 2.1655876211488296
Validation loss: 2.4728524740412685

Epoch: 5| Step: 6
Training loss: 1.507618155332715
Validation loss: 2.602874755018725

Epoch: 5| Step: 7
Training loss: 1.982749152768591
Validation loss: 2.580134550590789

Epoch: 5| Step: 8
Training loss: 1.6745357553304518
Validation loss: 2.461427377909891

Epoch: 5| Step: 9
Training loss: 2.019611762856529
Validation loss: 2.5284912113468625

Epoch: 5| Step: 10
Training loss: 2.7666085428620466
Validation loss: 2.4670503283941883

Epoch: 621| Step: 0
Training loss: 1.993762003704038
Validation loss: 2.4392105833595554

Epoch: 5| Step: 1
Training loss: 1.6596051905970335
Validation loss: 2.5336192088008356

Epoch: 5| Step: 2
Training loss: 1.933190136023941
Validation loss: 2.504674778997986

Epoch: 5| Step: 3
Training loss: 2.4089663147809914
Validation loss: 2.4532808445443473

Epoch: 5| Step: 4
Training loss: 1.818387892813934
Validation loss: 2.573811176584215

Epoch: 5| Step: 5
Training loss: 1.9561145942796858
Validation loss: 2.405934994378292

Epoch: 5| Step: 6
Training loss: 1.8102009760731665
Validation loss: 2.570907773691748

Epoch: 5| Step: 7
Training loss: 1.7013213379959236
Validation loss: 2.496020458875457

Epoch: 5| Step: 8
Training loss: 1.7235320410299628
Validation loss: 2.5369458059970995

Epoch: 5| Step: 9
Training loss: 1.8667182492327097
Validation loss: 2.4839269350488165

Epoch: 5| Step: 10
Training loss: 2.382709238285063
Validation loss: 2.4851406736517245

Epoch: 622| Step: 0
Training loss: 1.4428192077705528
Validation loss: 2.4735820020741315

Epoch: 5| Step: 1
Training loss: 1.6342925158486803
Validation loss: 2.4778590495060953

Epoch: 5| Step: 2
Training loss: 2.4404031142260734
Validation loss: 2.4778886973775376

Epoch: 5| Step: 3
Training loss: 1.985215977562537
Validation loss: 2.4945425167385356

Epoch: 5| Step: 4
Training loss: 2.0594973815767963
Validation loss: 2.5005639342590715

Epoch: 5| Step: 5
Training loss: 1.5431339996310303
Validation loss: 2.4252220395525157

Epoch: 5| Step: 6
Training loss: 2.147339030262495
Validation loss: 2.551690615150468

Epoch: 5| Step: 7
Training loss: 1.8519707724569825
Validation loss: 2.532602847770167

Epoch: 5| Step: 8
Training loss: 2.413780714458937
Validation loss: 2.4926170349028225

Epoch: 5| Step: 9
Training loss: 1.394790753494127
Validation loss: 2.5531128110137913

Epoch: 5| Step: 10
Training loss: 2.3390781888773278
Validation loss: 2.584394935129967

Epoch: 623| Step: 0
Training loss: 1.9603852486060669
Validation loss: 2.4902810824777486

Epoch: 5| Step: 1
Training loss: 2.296875830410139
Validation loss: 2.5553845355339555

Epoch: 5| Step: 2
Training loss: 2.1361359912143763
Validation loss: 2.465161247990694

Epoch: 5| Step: 3
Training loss: 2.0244272528815337
Validation loss: 2.5034015720208185

Epoch: 5| Step: 4
Training loss: 1.9942800863520738
Validation loss: 2.5762476813330037

Epoch: 5| Step: 5
Training loss: 1.6236659956677268
Validation loss: 2.599632013277408

Epoch: 5| Step: 6
Training loss: 1.7555698584659345
Validation loss: 2.5359762578913707

Epoch: 5| Step: 7
Training loss: 2.0899233793970744
Validation loss: 2.5345490009902187

Epoch: 5| Step: 8
Training loss: 1.535503629639788
Validation loss: 2.438844073045768

Epoch: 5| Step: 9
Training loss: 1.8372827025142673
Validation loss: 2.457247946185501

Epoch: 5| Step: 10
Training loss: 1.6096974762726095
Validation loss: 2.5686960971023995

Epoch: 624| Step: 0
Training loss: 1.8406415048063265
Validation loss: 2.5254348829551603

Epoch: 5| Step: 1
Training loss: 1.66782966409092
Validation loss: 2.559318170772106

Epoch: 5| Step: 2
Training loss: 2.1797193299297244
Validation loss: 2.5564474933801082

Epoch: 5| Step: 3
Training loss: 1.3364387597989413
Validation loss: 2.559596447862208

Epoch: 5| Step: 4
Training loss: 1.5631979337239348
Validation loss: 2.478627054567715

Epoch: 5| Step: 5
Training loss: 1.791002712390407
Validation loss: 2.5157307300884626

Epoch: 5| Step: 6
Training loss: 2.3432474233291023
Validation loss: 2.6062509149527306

Epoch: 5| Step: 7
Training loss: 1.8299779386180746
Validation loss: 2.4353791300398138

Epoch: 5| Step: 8
Training loss: 2.198959633450204
Validation loss: 2.511151797720058

Epoch: 5| Step: 9
Training loss: 2.0147874851661354
Validation loss: 2.572591733116202

Epoch: 5| Step: 10
Training loss: 1.7763855751264515
Validation loss: 2.578144751330477

Epoch: 625| Step: 0
Training loss: 1.5630479996059832
Validation loss: 2.572735892721493

Epoch: 5| Step: 1
Training loss: 2.6460879546271787
Validation loss: 2.602045424995326

Epoch: 5| Step: 2
Training loss: 2.039430782339668
Validation loss: 2.446546687429283

Epoch: 5| Step: 3
Training loss: 2.01918106437123
Validation loss: 2.4911632291682344

Epoch: 5| Step: 4
Training loss: 2.041351086367188
Validation loss: 2.5418592605634633

Epoch: 5| Step: 5
Training loss: 1.9635460513712717
Validation loss: 2.480478822769876

Epoch: 5| Step: 6
Training loss: 2.0470540208644126
Validation loss: 2.5334839093104393

Epoch: 5| Step: 7
Training loss: 1.6668029570485325
Validation loss: 2.528915832047833

Epoch: 5| Step: 8
Training loss: 1.9394891433982349
Validation loss: 2.518331942476024

Epoch: 5| Step: 9
Training loss: 1.5340374857016505
Validation loss: 2.553565145661867

Epoch: 5| Step: 10
Training loss: 1.4953878545159982
Validation loss: 2.4928859442154896

Epoch: 626| Step: 0
Training loss: 1.8689984593392723
Validation loss: 2.4689226133003195

Epoch: 5| Step: 1
Training loss: 1.9553613905291323
Validation loss: 2.5625574669245506

Epoch: 5| Step: 2
Training loss: 1.770033270420815
Validation loss: 2.5119257745472043

Epoch: 5| Step: 3
Training loss: 1.6332529742396151
Validation loss: 2.5034488474375065

Epoch: 5| Step: 4
Training loss: 1.7331037931799036
Validation loss: 2.6232001144621337

Epoch: 5| Step: 5
Training loss: 2.8909831057212902
Validation loss: 2.4920655491156034

Epoch: 5| Step: 6
Training loss: 1.497786796503682
Validation loss: 2.57096617647246

Epoch: 5| Step: 7
Training loss: 1.9839276988599128
Validation loss: 2.46680088549688

Epoch: 5| Step: 8
Training loss: 1.8365621599810786
Validation loss: 2.4736444697523523

Epoch: 5| Step: 9
Training loss: 1.9139797893481538
Validation loss: 2.536093882485988

Epoch: 5| Step: 10
Training loss: 1.5485848888843823
Validation loss: 2.5624411501405833

Epoch: 627| Step: 0
Training loss: 2.0972137268545565
Validation loss: 2.562822418178294

Epoch: 5| Step: 1
Training loss: 1.6736040532907304
Validation loss: 2.5243005039113218

Epoch: 5| Step: 2
Training loss: 2.17910693240549
Validation loss: 2.521479258865673

Epoch: 5| Step: 3
Training loss: 1.8150464290008426
Validation loss: 2.490265327597438

Epoch: 5| Step: 4
Training loss: 1.9374317649392911
Validation loss: 2.548498809087644

Epoch: 5| Step: 5
Training loss: 2.0903379052161397
Validation loss: 2.542876921900608

Epoch: 5| Step: 6
Training loss: 1.5110377470763594
Validation loss: 2.512689540796738

Epoch: 5| Step: 7
Training loss: 2.3307973386430842
Validation loss: 2.440614517960611

Epoch: 5| Step: 8
Training loss: 1.4791846833900368
Validation loss: 2.4955559105714684

Epoch: 5| Step: 9
Training loss: 1.568522785647521
Validation loss: 2.489051611379125

Epoch: 5| Step: 10
Training loss: 2.609431648781605
Validation loss: 2.509380506798759

Epoch: 628| Step: 0
Training loss: 2.110800819292139
Validation loss: 2.526786751316315

Epoch: 5| Step: 1
Training loss: 1.4424500859713651
Validation loss: 2.565106220826498

Epoch: 5| Step: 2
Training loss: 1.5308891182531361
Validation loss: 2.514640534457515

Epoch: 5| Step: 3
Training loss: 2.5034792531538343
Validation loss: 2.512033696320003

Epoch: 5| Step: 4
Training loss: 1.9461380765530598
Validation loss: 2.5288152658953833

Epoch: 5| Step: 5
Training loss: 2.0008180852476083
Validation loss: 2.6228225318009164

Epoch: 5| Step: 6
Training loss: 2.0930577742270855
Validation loss: 2.584529362331949

Epoch: 5| Step: 7
Training loss: 1.5840897342811369
Validation loss: 2.4850567195606925

Epoch: 5| Step: 8
Training loss: 1.4646245767023514
Validation loss: 2.549758163990852

Epoch: 5| Step: 9
Training loss: 1.6954515813215407
Validation loss: 2.6178741910880023

Epoch: 5| Step: 10
Training loss: 2.1260536050219905
Validation loss: 2.507585750573531

Epoch: 629| Step: 0
Training loss: 2.2403575061859393
Validation loss: 2.5678749928128948

Epoch: 5| Step: 1
Training loss: 2.077720201117287
Validation loss: 2.556142582719839

Epoch: 5| Step: 2
Training loss: 2.1535273515121505
Validation loss: 2.5751050407775917

Epoch: 5| Step: 3
Training loss: 1.4354019610902493
Validation loss: 2.4867531689474287

Epoch: 5| Step: 4
Training loss: 2.058950317309568
Validation loss: 2.532540465757251

Epoch: 5| Step: 5
Training loss: 2.3899970133615134
Validation loss: 2.5322440547854717

Epoch: 5| Step: 6
Training loss: 1.4860082374847585
Validation loss: 2.4949160473421594

Epoch: 5| Step: 7
Training loss: 1.6186374669376677
Validation loss: 2.473666546663481

Epoch: 5| Step: 8
Training loss: 1.6876058192100116
Validation loss: 2.5712216108495167

Epoch: 5| Step: 9
Training loss: 1.6065036380464242
Validation loss: 2.4699098124626198

Epoch: 5| Step: 10
Training loss: 2.0695920446386746
Validation loss: 2.5431634525883786

Epoch: 630| Step: 0
Training loss: 1.7575247295913425
Validation loss: 2.5464430880089184

Epoch: 5| Step: 1
Training loss: 2.389401889642735
Validation loss: 2.555919265843414

Epoch: 5| Step: 2
Training loss: 1.6905260152273316
Validation loss: 2.606107496696404

Epoch: 5| Step: 3
Training loss: 1.817629822471921
Validation loss: 2.6038329349092155

Epoch: 5| Step: 4
Training loss: 1.8939176529301167
Validation loss: 2.589090714223654

Epoch: 5| Step: 5
Training loss: 1.5907395297264497
Validation loss: 2.4800865581053158

Epoch: 5| Step: 6
Training loss: 2.4696537729610566
Validation loss: 2.59564364223846

Epoch: 5| Step: 7
Training loss: 2.0619116435244997
Validation loss: 2.4625034728483035

Epoch: 5| Step: 8
Training loss: 1.931572121233786
Validation loss: 2.513546631784105

Epoch: 5| Step: 9
Training loss: 2.1050350046758473
Validation loss: 2.5302625011338304

Epoch: 5| Step: 10
Training loss: 1.6910622050813116
Validation loss: 2.59490454219425

Epoch: 631| Step: 0
Training loss: 1.9889879450943364
Validation loss: 2.5206194879889763

Epoch: 5| Step: 1
Training loss: 2.0427234276254875
Validation loss: 2.516543492339417

Epoch: 5| Step: 2
Training loss: 2.1706212218976937
Validation loss: 2.519282804263689

Epoch: 5| Step: 3
Training loss: 1.8499058261305514
Validation loss: 2.572197593977641

Epoch: 5| Step: 4
Training loss: 2.2023238220071044
Validation loss: 2.484877358280247

Epoch: 5| Step: 5
Training loss: 1.8484499236823615
Validation loss: 2.588242621232125

Epoch: 5| Step: 6
Training loss: 1.7581830121669533
Validation loss: 2.493848475205243

Epoch: 5| Step: 7
Training loss: 1.5070627354585435
Validation loss: 2.5134561083413756

Epoch: 5| Step: 8
Training loss: 1.51486328490136
Validation loss: 2.5730685957724195

Epoch: 5| Step: 9
Training loss: 1.9476862752461512
Validation loss: 2.5578798992983995

Epoch: 5| Step: 10
Training loss: 1.8469821595475056
Validation loss: 2.483137091008437

Epoch: 632| Step: 0
Training loss: 1.6992682789566833
Validation loss: 2.512353469517594

Epoch: 5| Step: 1
Training loss: 2.2151661256445037
Validation loss: 2.5479938921356236

Epoch: 5| Step: 2
Training loss: 2.293354060537723
Validation loss: 2.5108128077126963

Epoch: 5| Step: 3
Training loss: 1.8696847599958835
Validation loss: 2.489418308182593

Epoch: 5| Step: 4
Training loss: 1.2828728702292949
Validation loss: 2.5796025119061485

Epoch: 5| Step: 5
Training loss: 1.749241664612011
Validation loss: 2.4729842633076418

Epoch: 5| Step: 6
Training loss: 1.5065192967194079
Validation loss: 2.522032647105864

Epoch: 5| Step: 7
Training loss: 2.510006999123834
Validation loss: 2.5220343517720973

Epoch: 5| Step: 8
Training loss: 2.141841570568544
Validation loss: 2.483172896111667

Epoch: 5| Step: 9
Training loss: 1.9131963521767497
Validation loss: 2.4811513940521266

Epoch: 5| Step: 10
Training loss: 1.7052933774452328
Validation loss: 2.564039712688533

Epoch: 633| Step: 0
Training loss: 2.467717014961435
Validation loss: 2.4575495783648615

Epoch: 5| Step: 1
Training loss: 1.4674948340979768
Validation loss: 2.55588841674412

Epoch: 5| Step: 2
Training loss: 1.9312255536849994
Validation loss: 2.501662799616631

Epoch: 5| Step: 3
Training loss: 1.6541403524129858
Validation loss: 2.42463080485342

Epoch: 5| Step: 4
Training loss: 2.074492068341976
Validation loss: 2.5085701022835334

Epoch: 5| Step: 5
Training loss: 1.780953231985687
Validation loss: 2.4593824800496233

Epoch: 5| Step: 6
Training loss: 1.4181891656231784
Validation loss: 2.529996831396556

Epoch: 5| Step: 7
Training loss: 1.803571413733497
Validation loss: 2.525719393203661

Epoch: 5| Step: 8
Training loss: 1.863016425612684
Validation loss: 2.593725100320044

Epoch: 5| Step: 9
Training loss: 2.4976898009737774
Validation loss: 2.473862148070956

Epoch: 5| Step: 10
Training loss: 1.9356597651906078
Validation loss: 2.5775185834823966

Epoch: 634| Step: 0
Training loss: 1.9134560383296286
Validation loss: 2.479312662520719

Epoch: 5| Step: 1
Training loss: 1.583915661921878
Validation loss: 2.47967321409063

Epoch: 5| Step: 2
Training loss: 1.5446043206596674
Validation loss: 2.491467904629442

Epoch: 5| Step: 3
Training loss: 2.000538991779314
Validation loss: 2.56597677533646

Epoch: 5| Step: 4
Training loss: 1.6832208419579153
Validation loss: 2.4747789981367307

Epoch: 5| Step: 5
Training loss: 1.795418190231379
Validation loss: 2.580877492012735

Epoch: 5| Step: 6
Training loss: 1.8323503228609088
Validation loss: 2.4897601884786136

Epoch: 5| Step: 7
Training loss: 1.8868021502335577
Validation loss: 2.5606746009558523

Epoch: 5| Step: 8
Training loss: 2.7230543067271453
Validation loss: 2.558586489696796

Epoch: 5| Step: 9
Training loss: 1.9691150871729113
Validation loss: 2.482724907469108

Epoch: 5| Step: 10
Training loss: 1.9683526258737116
Validation loss: 2.526496584572609

Epoch: 635| Step: 0
Training loss: 1.7445756769054048
Validation loss: 2.5903698784240206

Epoch: 5| Step: 1
Training loss: 2.2817437669625638
Validation loss: 2.5918171383691178

Epoch: 5| Step: 2
Training loss: 1.91650471486846
Validation loss: 2.462622524753143

Epoch: 5| Step: 3
Training loss: 1.801392292276679
Validation loss: 2.527283792399005

Epoch: 5| Step: 4
Training loss: 1.231362396764341
Validation loss: 2.4996939399991267

Epoch: 5| Step: 5
Training loss: 2.5390404333476204
Validation loss: 2.6071606370488083

Epoch: 5| Step: 6
Training loss: 2.4869190361915727
Validation loss: 2.4546090971694943

Epoch: 5| Step: 7
Training loss: 1.7939250448594826
Validation loss: 2.5495993892869713

Epoch: 5| Step: 8
Training loss: 1.5285383855001045
Validation loss: 2.49699307366766

Epoch: 5| Step: 9
Training loss: 1.6496959781880507
Validation loss: 2.4363205714324723

Epoch: 5| Step: 10
Training loss: 1.571961102108754
Validation loss: 2.5492711565197816

Epoch: 636| Step: 0
Training loss: 1.6161431520197815
Validation loss: 2.522781747591964

Epoch: 5| Step: 1
Training loss: 1.6823347655012397
Validation loss: 2.560355550973988

Epoch: 5| Step: 2
Training loss: 1.6297368920833823
Validation loss: 2.546687879444502

Epoch: 5| Step: 3
Training loss: 1.8915948823368751
Validation loss: 2.515356886352867

Epoch: 5| Step: 4
Training loss: 1.855456542928595
Validation loss: 2.575587954739863

Epoch: 5| Step: 5
Training loss: 2.152833969312606
Validation loss: 2.520078086414742

Epoch: 5| Step: 6
Training loss: 2.5305236904661164
Validation loss: 2.541945844239352

Epoch: 5| Step: 7
Training loss: 1.7444936773044004
Validation loss: 2.5906594746549327

Epoch: 5| Step: 8
Training loss: 2.0151725083711503
Validation loss: 2.583655442140576

Epoch: 5| Step: 9
Training loss: 1.437611285338688
Validation loss: 2.5604319917866727

Epoch: 5| Step: 10
Training loss: 1.903254735373796
Validation loss: 2.5131586838576605

Epoch: 637| Step: 0
Training loss: 2.1692241711003692
Validation loss: 2.585415246026781

Epoch: 5| Step: 1
Training loss: 1.830328045922787
Validation loss: 2.5553523356332715

Epoch: 5| Step: 2
Training loss: 2.1382800993186297
Validation loss: 2.431177805479206

Epoch: 5| Step: 3
Training loss: 2.084529101210032
Validation loss: 2.481822916409389

Epoch: 5| Step: 4
Training loss: 1.9015019804477535
Validation loss: 2.4350390478296835

Epoch: 5| Step: 5
Training loss: 2.0051748561954534
Validation loss: 2.5628083576521465

Epoch: 5| Step: 6
Training loss: 1.4385144344609357
Validation loss: 2.4809793102032627

Epoch: 5| Step: 7
Training loss: 2.0633649457359677
Validation loss: 2.428763233408193

Epoch: 5| Step: 8
Training loss: 1.779275770512359
Validation loss: 2.556653384808853

Epoch: 5| Step: 9
Training loss: 1.712180465625308
Validation loss: 2.58934459529414

Epoch: 5| Step: 10
Training loss: 2.250061564133061
Validation loss: 2.557263981286447

Epoch: 638| Step: 0
Training loss: 2.198302489732645
Validation loss: 2.482258153920721

Epoch: 5| Step: 1
Training loss: 1.7842070812842967
Validation loss: 2.608505491738234

Epoch: 5| Step: 2
Training loss: 1.9934413180663781
Validation loss: 2.4153886059777436

Epoch: 5| Step: 3
Training loss: 2.173522434179391
Validation loss: 2.542531488859851

Epoch: 5| Step: 4
Training loss: 2.0994130313355104
Validation loss: 2.564883255595666

Epoch: 5| Step: 5
Training loss: 1.8915563133865845
Validation loss: 2.4398493492171993

Epoch: 5| Step: 6
Training loss: 1.6401050288598984
Validation loss: 2.477899796615034

Epoch: 5| Step: 7
Training loss: 1.8598237337658403
Validation loss: 2.544899614364384

Epoch: 5| Step: 8
Training loss: 1.6995964244435928
Validation loss: 2.520938878369844

Epoch: 5| Step: 9
Training loss: 1.8334696314460228
Validation loss: 2.5277802286545996

Epoch: 5| Step: 10
Training loss: 1.934179783647472
Validation loss: 2.5175612405714705

Epoch: 639| Step: 0
Training loss: 1.729060372758581
Validation loss: 2.5113039483888264

Epoch: 5| Step: 1
Training loss: 1.9627911442841601
Validation loss: 2.4531595679520897

Epoch: 5| Step: 2
Training loss: 1.9401838725740306
Validation loss: 2.5691412426348625

Epoch: 5| Step: 3
Training loss: 1.7277920172793846
Validation loss: 2.4981012948174266

Epoch: 5| Step: 4
Training loss: 1.523517939082296
Validation loss: 2.525818685000054

Epoch: 5| Step: 5
Training loss: 1.6616196588941057
Validation loss: 2.5001532035973906

Epoch: 5| Step: 6
Training loss: 1.45941596943693
Validation loss: 2.517825664748181

Epoch: 5| Step: 7
Training loss: 2.1403971084355624
Validation loss: 2.462031557051507

Epoch: 5| Step: 8
Training loss: 2.5922749932844904
Validation loss: 2.4363383734878847

Epoch: 5| Step: 9
Training loss: 2.166569218522663
Validation loss: 2.4869407200280342

Epoch: 5| Step: 10
Training loss: 1.59891182731402
Validation loss: 2.4340015902440766

Epoch: 640| Step: 0
Training loss: 2.5267173780956886
Validation loss: 2.5150499613373043

Epoch: 5| Step: 1
Training loss: 1.7259076978330008
Validation loss: 2.529754766238902

Epoch: 5| Step: 2
Training loss: 1.5717008915178712
Validation loss: 2.593209290486003

Epoch: 5| Step: 3
Training loss: 2.2302356070344946
Validation loss: 2.5767909352494747

Epoch: 5| Step: 4
Training loss: 1.8988765004895205
Validation loss: 2.5561190477775764

Epoch: 5| Step: 5
Training loss: 1.5829825096296728
Validation loss: 2.5577505233141418

Epoch: 5| Step: 6
Training loss: 1.5414786181159448
Validation loss: 2.4803781407745267

Epoch: 5| Step: 7
Training loss: 2.2352427684861937
Validation loss: 2.429684206931305

Epoch: 5| Step: 8
Training loss: 2.0912435531744857
Validation loss: 2.5396765656267926

Epoch: 5| Step: 9
Training loss: 1.8684952756859248
Validation loss: 2.578301911360827

Epoch: 5| Step: 10
Training loss: 1.743564147342399
Validation loss: 2.5046780328369094

Epoch: 641| Step: 0
Training loss: 1.451091204489345
Validation loss: 2.563582132082799

Epoch: 5| Step: 1
Training loss: 2.057300834796291
Validation loss: 2.470144096041669

Epoch: 5| Step: 2
Training loss: 2.0476121812580685
Validation loss: 2.6116810605843455

Epoch: 5| Step: 3
Training loss: 1.2688549881515347
Validation loss: 2.5276688497583777

Epoch: 5| Step: 4
Training loss: 1.8646381164118095
Validation loss: 2.488455110822723

Epoch: 5| Step: 5
Training loss: 2.1511375522871297
Validation loss: 2.477357272517279

Epoch: 5| Step: 6
Training loss: 2.1750138468685263
Validation loss: 2.5493258806704

Epoch: 5| Step: 7
Training loss: 1.6639891415755241
Validation loss: 2.6015914062502308

Epoch: 5| Step: 8
Training loss: 1.8616410239607166
Validation loss: 2.5376299192940888

Epoch: 5| Step: 9
Training loss: 1.509922113241415
Validation loss: 2.5438592891774006

Epoch: 5| Step: 10
Training loss: 2.680120583283965
Validation loss: 2.6192269017517944

Epoch: 642| Step: 0
Training loss: 1.816154216385633
Validation loss: 2.454192373560808

Epoch: 5| Step: 1
Training loss: 1.7855524003355019
Validation loss: 2.4401071245316053

Epoch: 5| Step: 2
Training loss: 1.8259303948170968
Validation loss: 2.469379321472252

Epoch: 5| Step: 3
Training loss: 1.7417879886746994
Validation loss: 2.5323111172133492

Epoch: 5| Step: 4
Training loss: 1.3383263094342825
Validation loss: 2.5228808481247302

Epoch: 5| Step: 5
Training loss: 2.050912151700238
Validation loss: 2.486134782004245

Epoch: 5| Step: 6
Training loss: 2.3162791328224417
Validation loss: 2.556007015633191

Epoch: 5| Step: 7
Training loss: 2.4301895653209393
Validation loss: 2.513691664650181

Epoch: 5| Step: 8
Training loss: 2.0779008099083724
Validation loss: 2.506962816727859

Epoch: 5| Step: 9
Training loss: 1.8505375596620157
Validation loss: 2.4376367320795524

Epoch: 5| Step: 10
Training loss: 1.2580266260837765
Validation loss: 2.490402948318671

Epoch: 643| Step: 0
Training loss: 1.8594102615731434
Validation loss: 2.592342779258859

Epoch: 5| Step: 1
Training loss: 1.8625194983773827
Validation loss: 2.4527160238823003

Epoch: 5| Step: 2
Training loss: 1.709622090838044
Validation loss: 2.615866485726311

Epoch: 5| Step: 3
Training loss: 1.674686598993747
Validation loss: 2.551667801707572

Epoch: 5| Step: 4
Training loss: 1.5077530448932164
Validation loss: 2.5258566538820983

Epoch: 5| Step: 5
Training loss: 2.1968885310096833
Validation loss: 2.5555976048607105

Epoch: 5| Step: 6
Training loss: 1.9420173650293242
Validation loss: 2.432429654118796

Epoch: 5| Step: 7
Training loss: 1.6763477568315313
Validation loss: 2.4664167086987354

Epoch: 5| Step: 8
Training loss: 1.5125305992373015
Validation loss: 2.4099264804714857

Epoch: 5| Step: 9
Training loss: 1.7416231755328069
Validation loss: 2.525545972101858

Epoch: 5| Step: 10
Training loss: 2.637974599650899
Validation loss: 2.595768235856167

Epoch: 644| Step: 0
Training loss: 1.556532335523275
Validation loss: 2.567710684934331

Epoch: 5| Step: 1
Training loss: 1.7368907381698862
Validation loss: 2.4965702341391265

Epoch: 5| Step: 2
Training loss: 1.6189614853733971
Validation loss: 2.4052141439975694

Epoch: 5| Step: 3
Training loss: 1.5445996899798233
Validation loss: 2.5017137109282803

Epoch: 5| Step: 4
Training loss: 1.4155814090442533
Validation loss: 2.520101839935336

Epoch: 5| Step: 5
Training loss: 1.8785929269922899
Validation loss: 2.460454293513886

Epoch: 5| Step: 6
Training loss: 2.40994988891928
Validation loss: 2.4303182856649266

Epoch: 5| Step: 7
Training loss: 1.6524262824763332
Validation loss: 2.5742856271785453

Epoch: 5| Step: 8
Training loss: 2.035347664117992
Validation loss: 2.5591481274285877

Epoch: 5| Step: 9
Training loss: 1.8910636077826175
Validation loss: 2.545627892865184

Epoch: 5| Step: 10
Training loss: 2.1363548512896124
Validation loss: 2.552630217777628

Epoch: 645| Step: 0
Training loss: 1.3698619297509935
Validation loss: 2.4036960992290206

Epoch: 5| Step: 1
Training loss: 1.63068057239329
Validation loss: 2.5726336833015093

Epoch: 5| Step: 2
Training loss: 1.7186080874030467
Validation loss: 2.512906129236066

Epoch: 5| Step: 3
Training loss: 2.1116038662013166
Validation loss: 2.4746753555531362

Epoch: 5| Step: 4
Training loss: 1.7894613829136774
Validation loss: 2.469128996155282

Epoch: 5| Step: 5
Training loss: 2.2509283693661453
Validation loss: 2.49052886025937

Epoch: 5| Step: 6
Training loss: 1.5423415828825255
Validation loss: 2.5793107026766227

Epoch: 5| Step: 7
Training loss: 2.430898971517101
Validation loss: 2.4601952947501777

Epoch: 5| Step: 8
Training loss: 1.5460407820500606
Validation loss: 2.5524251247327117

Epoch: 5| Step: 9
Training loss: 1.8697864528856045
Validation loss: 2.4775340449782917

Epoch: 5| Step: 10
Training loss: 1.7615972844983825
Validation loss: 2.589845480313782

Epoch: 646| Step: 0
Training loss: 1.80293499294224
Validation loss: 2.4404749000588493

Epoch: 5| Step: 1
Training loss: 2.1364954634747058
Validation loss: 2.598571204670145

Epoch: 5| Step: 2
Training loss: 1.4462063061865382
Validation loss: 2.613611402882437

Epoch: 5| Step: 3
Training loss: 2.805982540443356
Validation loss: 2.4953774775690336

Epoch: 5| Step: 4
Training loss: 1.5179201032899998
Validation loss: 2.429951918004886

Epoch: 5| Step: 5
Training loss: 1.2436945188790023
Validation loss: 2.5453116090703567

Epoch: 5| Step: 6
Training loss: 1.79101276293477
Validation loss: 2.5197867437325256

Epoch: 5| Step: 7
Training loss: 2.2759054624771435
Validation loss: 2.601863324496511

Epoch: 5| Step: 8
Training loss: 1.445627786425038
Validation loss: 2.4941946264032415

Epoch: 5| Step: 9
Training loss: 1.5275962991530305
Validation loss: 2.5458389470942606

Epoch: 5| Step: 10
Training loss: 1.9515930271128101
Validation loss: 2.4928007037202318

Epoch: 647| Step: 0
Training loss: 1.5903632137812598
Validation loss: 2.6528220596516094

Epoch: 5| Step: 1
Training loss: 2.0308834038553103
Validation loss: 2.4961614996754005

Epoch: 5| Step: 2
Training loss: 1.9948773344948798
Validation loss: 2.5579357521965753

Epoch: 5| Step: 3
Training loss: 2.0561535612640363
Validation loss: 2.5503096007912367

Epoch: 5| Step: 4
Training loss: 1.6991587661152887
Validation loss: 2.5410981378766486

Epoch: 5| Step: 5
Training loss: 2.244603042171388
Validation loss: 2.507817685928173

Epoch: 5| Step: 6
Training loss: 1.7755297447899285
Validation loss: 2.553927999050944

Epoch: 5| Step: 7
Training loss: 1.916078525642311
Validation loss: 2.5256930483769557

Epoch: 5| Step: 8
Training loss: 1.5770346774713433
Validation loss: 2.584212702938491

Epoch: 5| Step: 9
Training loss: 2.0499871742033395
Validation loss: 2.544944273447373

Epoch: 5| Step: 10
Training loss: 2.441818031679512
Validation loss: 2.4670280473129

Epoch: 648| Step: 0
Training loss: 1.872713029404099
Validation loss: 2.556191308769146

Epoch: 5| Step: 1
Training loss: 1.5272394715441264
Validation loss: 2.5415692365367675

Epoch: 5| Step: 2
Training loss: 1.6543425606608555
Validation loss: 2.437704559947545

Epoch: 5| Step: 3
Training loss: 1.8710913926908102
Validation loss: 2.3888104317708483

Epoch: 5| Step: 4
Training loss: 1.6777829750491409
Validation loss: 2.5416122257878397

Epoch: 5| Step: 5
Training loss: 1.9869216437323112
Validation loss: 2.5513152595084514

Epoch: 5| Step: 6
Training loss: 1.6921678198517995
Validation loss: 2.6161164826614502

Epoch: 5| Step: 7
Training loss: 1.7162211454206633
Validation loss: 2.538705815582042

Epoch: 5| Step: 8
Training loss: 2.3445801345625306
Validation loss: 2.4601052581047296

Epoch: 5| Step: 9
Training loss: 1.8483587949608316
Validation loss: 2.574154605869558

Epoch: 5| Step: 10
Training loss: 2.645538003213436
Validation loss: 2.5664487018521367

Epoch: 649| Step: 0
Training loss: 1.8494481114113417
Validation loss: 2.4798354372859492

Epoch: 5| Step: 1
Training loss: 2.332012131706861
Validation loss: 2.5403953881678007

Epoch: 5| Step: 2
Training loss: 2.15242959628455
Validation loss: 2.5469055858421017

Epoch: 5| Step: 3
Training loss: 1.5164414399282986
Validation loss: 2.510443770563102

Epoch: 5| Step: 4
Training loss: 1.827125080230517
Validation loss: 2.559337163725104

Epoch: 5| Step: 5
Training loss: 1.340962201728611
Validation loss: 2.643753426679853

Epoch: 5| Step: 6
Training loss: 1.825497426215358
Validation loss: 2.5499372072831012

Epoch: 5| Step: 7
Training loss: 2.168176149637509
Validation loss: 2.548292590790711

Epoch: 5| Step: 8
Training loss: 1.675928780701799
Validation loss: 2.500521098966858

Epoch: 5| Step: 9
Training loss: 1.7203555151111682
Validation loss: 2.4628734811984065

Epoch: 5| Step: 10
Training loss: 2.099234273361205
Validation loss: 2.531613404725138

Epoch: 650| Step: 0
Training loss: 1.9986998385110535
Validation loss: 2.602586157489497

Epoch: 5| Step: 1
Training loss: 1.6226391882773115
Validation loss: 2.539045649394496

Epoch: 5| Step: 2
Training loss: 2.048710240553738
Validation loss: 2.519408841954188

Epoch: 5| Step: 3
Training loss: 2.8484227283155445
Validation loss: 2.5364731497221404

Epoch: 5| Step: 4
Training loss: 1.6147166371434407
Validation loss: 2.501160935573394

Epoch: 5| Step: 5
Training loss: 1.9289859005940275
Validation loss: 2.5929043578986057

Epoch: 5| Step: 6
Training loss: 1.5364030817302374
Validation loss: 2.620251371928949

Epoch: 5| Step: 7
Training loss: 1.7614080658396303
Validation loss: 2.4922548543997887

Epoch: 5| Step: 8
Training loss: 1.7194082213519952
Validation loss: 2.584045321634259

Epoch: 5| Step: 9
Training loss: 1.4054386765473463
Validation loss: 2.5092296759879185

Epoch: 5| Step: 10
Training loss: 1.821065787776162
Validation loss: 2.500841318100736

Testing loss: 3.231431105568292
