Epoch: 1| Step: 0
Training loss: 5.418301418792847
Validation loss: 5.380065042487045

Epoch: 5| Step: 1
Training loss: 5.4444507590190225
Validation loss: 5.37499339701158

Epoch: 5| Step: 2
Training loss: 5.275005915489315
Validation loss: 5.374473643304229

Epoch: 5| Step: 3
Training loss: 4.910927067890308
Validation loss: 5.366404141610173

Epoch: 5| Step: 4
Training loss: 6.077391278617657
Validation loss: 5.36134494900116

Epoch: 5| Step: 5
Training loss: 5.586185732574451
Validation loss: 5.357559488310471

Epoch: 5| Step: 6
Training loss: 4.8604507482156505
Validation loss: 5.354542872201925

Epoch: 5| Step: 7
Training loss: 6.050269620578033
Validation loss: 5.347147763955569

Epoch: 5| Step: 8
Training loss: 3.731043650481961
Validation loss: 5.343244466212979

Epoch: 5| Step: 9
Training loss: 6.5206800286387825
Validation loss: 5.337408740356721

Epoch: 5| Step: 10
Training loss: 5.054947482325832
Validation loss: 5.335046073378717

Epoch: 2| Step: 0
Training loss: 5.454060034393153
Validation loss: 5.33035151831864

Epoch: 5| Step: 1
Training loss: 5.7878278272813155
Validation loss: 5.322259567361158

Epoch: 5| Step: 2
Training loss: 4.3265353702398555
Validation loss: 5.319942623713848

Epoch: 5| Step: 3
Training loss: 4.885572657368805
Validation loss: 5.313717299572175

Epoch: 5| Step: 4
Training loss: 5.827337544196656
Validation loss: 5.31242067493762

Epoch: 5| Step: 5
Training loss: 5.191849137840272
Validation loss: 5.3078251015642826

Epoch: 5| Step: 6
Training loss: 5.690987995098176
Validation loss: 5.3031718849530884

Epoch: 5| Step: 7
Training loss: 6.305199055202969
Validation loss: 5.296500071696354

Epoch: 5| Step: 8
Training loss: 5.509762509415106
Validation loss: 5.295766561707241

Epoch: 5| Step: 9
Training loss: 4.597044302015945
Validation loss: 5.288624233890181

Epoch: 5| Step: 10
Training loss: 5.009306257874504
Validation loss: 5.285138867207032

Epoch: 3| Step: 0
Training loss: 4.673299616874787
Validation loss: 5.28074808363645

Epoch: 5| Step: 1
Training loss: 5.212173978640599
Validation loss: 5.277846588538222

Epoch: 5| Step: 2
Training loss: 5.837727263313187
Validation loss: 5.270750564663984

Epoch: 5| Step: 3
Training loss: 5.789856479163919
Validation loss: 5.2664922544905455

Epoch: 5| Step: 4
Training loss: 4.886814765993172
Validation loss: 5.2634382366804155

Epoch: 5| Step: 5
Training loss: 4.938376626528634
Validation loss: 5.256566286863967

Epoch: 5| Step: 6
Training loss: 5.872921190353695
Validation loss: 5.253013320323977

Epoch: 5| Step: 7
Training loss: 4.448010314860837
Validation loss: 5.246254240504668

Epoch: 5| Step: 8
Training loss: 5.410226230650737
Validation loss: 5.246530850607556

Epoch: 5| Step: 9
Training loss: 5.377925520216971
Validation loss: 5.238424318724019

Epoch: 5| Step: 10
Training loss: 5.814271718386953
Validation loss: 5.231432840854394

Epoch: 4| Step: 0
Training loss: 4.8066311014229095
Validation loss: 5.229316266419486

Epoch: 5| Step: 1
Training loss: 5.319415628849309
Validation loss: 5.224052629145385

Epoch: 5| Step: 2
Training loss: 5.3653396023991125
Validation loss: 5.218313172231492

Epoch: 5| Step: 3
Training loss: 4.841328464761602
Validation loss: 5.2122334752071335

Epoch: 5| Step: 4
Training loss: 5.215670653658227
Validation loss: 5.205553273498651

Epoch: 5| Step: 5
Training loss: 4.804689881859166
Validation loss: 5.199956795849786

Epoch: 5| Step: 6
Training loss: 5.6165246479556865
Validation loss: 5.194962772426008

Epoch: 5| Step: 7
Training loss: 4.794489065242355
Validation loss: 5.1888027045462035

Epoch: 5| Step: 8
Training loss: 5.459288166580566
Validation loss: 5.182870278779025

Epoch: 5| Step: 9
Training loss: 6.296723243266685
Validation loss: 5.175103050372251

Epoch: 5| Step: 10
Training loss: 5.101939165542976
Validation loss: 5.176305052491668

Epoch: 5| Step: 0
Training loss: 5.5245040878127485
Validation loss: 5.163591731507787

Epoch: 5| Step: 1
Training loss: 5.751373790328205
Validation loss: 5.157123070886302

Epoch: 5| Step: 2
Training loss: 4.375185063398948
Validation loss: 5.152140811957988

Epoch: 5| Step: 3
Training loss: 5.753249204041886
Validation loss: 5.146200627861107

Epoch: 5| Step: 4
Training loss: 4.992733443470503
Validation loss: 5.142769428691116

Epoch: 5| Step: 5
Training loss: 5.840468847188594
Validation loss: 5.13177949033243

Epoch: 5| Step: 6
Training loss: 5.506230899634774
Validation loss: 5.125059161981497

Epoch: 5| Step: 7
Training loss: 3.8325492361032705
Validation loss: 5.120288428907146

Epoch: 5| Step: 8
Training loss: 4.61663763447985
Validation loss: 5.114554650886432

Epoch: 5| Step: 9
Training loss: 5.3844652448409756
Validation loss: 5.107404752651761

Epoch: 5| Step: 10
Training loss: 5.144506038757512
Validation loss: 5.097805059650798

Epoch: 6| Step: 0
Training loss: 4.554362107132113
Validation loss: 5.091786883844435

Epoch: 5| Step: 1
Training loss: 3.8168496505872467
Validation loss: 5.086986184813455

Epoch: 5| Step: 2
Training loss: 4.648640604150071
Validation loss: 5.079660795971447

Epoch: 5| Step: 3
Training loss: 5.525822449655543
Validation loss: 5.068851713234254

Epoch: 5| Step: 4
Training loss: 5.81120039654701
Validation loss: 5.064168501409087

Epoch: 5| Step: 5
Training loss: 6.294245850199522
Validation loss: 5.0554917538190765

Epoch: 5| Step: 6
Training loss: 5.715201522464699
Validation loss: 5.0449000117647635

Epoch: 5| Step: 7
Training loss: 4.62927481556163
Validation loss: 5.039640349782547

Epoch: 5| Step: 8
Training loss: 4.924466858486514
Validation loss: 5.03459093344427

Epoch: 5| Step: 9
Training loss: 5.018998102157729
Validation loss: 5.022933983463416

Epoch: 5| Step: 10
Training loss: 4.8016852202096185
Validation loss: 5.016951781518163

Epoch: 7| Step: 0
Training loss: 3.832235068404186
Validation loss: 5.00628607413571

Epoch: 5| Step: 1
Training loss: 4.953681409131377
Validation loss: 4.999080755989242

Epoch: 5| Step: 2
Training loss: 5.613709881370977
Validation loss: 4.992167583192639

Epoch: 5| Step: 3
Training loss: 5.988061471627382
Validation loss: 4.980237762801907

Epoch: 5| Step: 4
Training loss: 4.069884411344393
Validation loss: 4.975438492071295

Epoch: 5| Step: 5
Training loss: 4.976011907520337
Validation loss: 4.963404645742544

Epoch: 5| Step: 6
Training loss: 5.354446858992205
Validation loss: 4.956132986720263

Epoch: 5| Step: 7
Training loss: 5.678508651948494
Validation loss: 4.949028866111157

Epoch: 5| Step: 8
Training loss: 4.008233894071672
Validation loss: 4.934561801607572

Epoch: 5| Step: 9
Training loss: 6.122361529627509
Validation loss: 4.928949718496169

Epoch: 5| Step: 10
Training loss: 3.7794248100923507
Validation loss: 4.918816466503347

Epoch: 8| Step: 0
Training loss: 4.963629621411602
Validation loss: 4.906674713318323

Epoch: 5| Step: 1
Training loss: 4.5165868876450785
Validation loss: 4.8983942808351895

Epoch: 5| Step: 2
Training loss: 4.253963641715695
Validation loss: 4.891739204479504

Epoch: 5| Step: 3
Training loss: 4.549967445005552
Validation loss: 4.879939000333301

Epoch: 5| Step: 4
Training loss: 5.603198888475536
Validation loss: 4.865915366109678

Epoch: 5| Step: 5
Training loss: 4.7519549312188305
Validation loss: 4.86085705907293

Epoch: 5| Step: 6
Training loss: 4.579358660508822
Validation loss: 4.849770848161746

Epoch: 5| Step: 7
Training loss: 4.946357411762464
Validation loss: 4.8380207688416395

Epoch: 5| Step: 8
Training loss: 5.173321570615734
Validation loss: 4.823821500022906

Epoch: 5| Step: 9
Training loss: 5.09148895070071
Validation loss: 4.817212026142337

Epoch: 5| Step: 10
Training loss: 5.699685593349611
Validation loss: 4.800822976960313

Epoch: 9| Step: 0
Training loss: 5.053779154883788
Validation loss: 4.788942789986042

Epoch: 5| Step: 1
Training loss: 4.300715391397996
Validation loss: 4.777420398710133

Epoch: 5| Step: 2
Training loss: 4.849415474501637
Validation loss: 4.764330340885691

Epoch: 5| Step: 3
Training loss: 5.934647366750259
Validation loss: 4.75069771237009

Epoch: 5| Step: 4
Training loss: 4.234218242601172
Validation loss: 4.735599107911332

Epoch: 5| Step: 5
Training loss: 5.211982404958752
Validation loss: 4.72874037567877

Epoch: 5| Step: 6
Training loss: 5.076544225113305
Validation loss: 4.709136129260121

Epoch: 5| Step: 7
Training loss: 4.125121606132462
Validation loss: 4.69227715881518

Epoch: 5| Step: 8
Training loss: 4.686163749969512
Validation loss: 4.68150906028829

Epoch: 5| Step: 9
Training loss: 4.7924062185807665
Validation loss: 4.668187273096851

Epoch: 5| Step: 10
Training loss: 4.1653114149304145
Validation loss: 4.646983708312794

Epoch: 10| Step: 0
Training loss: 5.369727986868059
Validation loss: 4.637028566976144

Epoch: 5| Step: 1
Training loss: 3.9159054253119794
Validation loss: 4.61860899843982

Epoch: 5| Step: 2
Training loss: 4.065770871875686
Validation loss: 4.608054199974446

Epoch: 5| Step: 3
Training loss: 5.269902967685303
Validation loss: 4.597281638653116

Epoch: 5| Step: 4
Training loss: 4.437662470892351
Validation loss: 4.577291339177214

Epoch: 5| Step: 5
Training loss: 4.12219050127582
Validation loss: 4.5598321403305935

Epoch: 5| Step: 6
Training loss: 4.646295544450111
Validation loss: 4.54755912505236

Epoch: 5| Step: 7
Training loss: 5.309779289529427
Validation loss: 4.529808904379509

Epoch: 5| Step: 8
Training loss: 4.93894782749324
Validation loss: 4.514942718158117

Epoch: 5| Step: 9
Training loss: 4.117847599627718
Validation loss: 4.4956694699874715

Epoch: 5| Step: 10
Training loss: 4.478309490186289
Validation loss: 4.480880324025184

Epoch: 11| Step: 0
Training loss: 4.112138522416172
Validation loss: 4.462039378182724

Epoch: 5| Step: 1
Training loss: 4.528979344195167
Validation loss: 4.444901000862605

Epoch: 5| Step: 2
Training loss: 3.873272172200953
Validation loss: 4.431400125779905

Epoch: 5| Step: 3
Training loss: 4.340260153501544
Validation loss: 4.409008525549222

Epoch: 5| Step: 4
Training loss: 4.824139477777337
Validation loss: 4.394705303359453

Epoch: 5| Step: 5
Training loss: 4.6259278062727756
Validation loss: 4.374082855333219

Epoch: 5| Step: 6
Training loss: 4.978958678856135
Validation loss: 4.359079315135071

Epoch: 5| Step: 7
Training loss: 4.439470954855858
Validation loss: 4.3447192091910685

Epoch: 5| Step: 8
Training loss: 4.3827143639442045
Validation loss: 4.317913885587403

Epoch: 5| Step: 9
Training loss: 4.340178194387093
Validation loss: 4.29921499605104

Epoch: 5| Step: 10
Training loss: 4.597250299025457
Validation loss: 4.281882386448518

Epoch: 12| Step: 0
Training loss: 3.7430138680978007
Validation loss: 4.25935898500051

Epoch: 5| Step: 1
Training loss: 3.5944819492805378
Validation loss: 4.244884679537612

Epoch: 5| Step: 2
Training loss: 4.698211232132745
Validation loss: 4.223298531924769

Epoch: 5| Step: 3
Training loss: 4.9076269853732235
Validation loss: 4.217145663815612

Epoch: 5| Step: 4
Training loss: 4.26003874926786
Validation loss: 4.185140607164512

Epoch: 5| Step: 5
Training loss: 4.5173509724560486
Validation loss: 4.170933921064647

Epoch: 5| Step: 6
Training loss: 4.15807560572435
Validation loss: 4.152490722233382

Epoch: 5| Step: 7
Training loss: 4.229186761116183
Validation loss: 4.132260158012159

Epoch: 5| Step: 8
Training loss: 4.653957545068372
Validation loss: 4.112428565386268

Epoch: 5| Step: 9
Training loss: 4.5691955766604515
Validation loss: 4.093892657109761

Epoch: 5| Step: 10
Training loss: 3.2889998695046434
Validation loss: 4.07593934665825

Epoch: 13| Step: 0
Training loss: 3.513028690827982
Validation loss: 4.050451690671841

Epoch: 5| Step: 1
Training loss: 3.6296058859088167
Validation loss: 4.0294717432794505

Epoch: 5| Step: 2
Training loss: 4.171737154279906
Validation loss: 4.0049631632153835

Epoch: 5| Step: 3
Training loss: 4.857640192872276
Validation loss: 3.9886355908018865

Epoch: 5| Step: 4
Training loss: 3.364901941919757
Validation loss: 3.966888761278904

Epoch: 5| Step: 5
Training loss: 4.606658445388664
Validation loss: 3.949625545700666

Epoch: 5| Step: 6
Training loss: 4.022457499732993
Validation loss: 3.9298812331455846

Epoch: 5| Step: 7
Training loss: 4.644851558025698
Validation loss: 3.914228644457513

Epoch: 5| Step: 8
Training loss: 4.3996398258179985
Validation loss: 3.881905443401623

Epoch: 5| Step: 9
Training loss: 3.426134497982617
Validation loss: 3.859811648615374

Epoch: 5| Step: 10
Training loss: 3.6027389226887023
Validation loss: 3.831866877774661

Epoch: 14| Step: 0
Training loss: 4.073724352793039
Validation loss: 3.8215980738083566

Epoch: 5| Step: 1
Training loss: 3.61399209118449
Validation loss: 3.7873177986691626

Epoch: 5| Step: 2
Training loss: 3.5948890539459857
Validation loss: 3.774665116661032

Epoch: 5| Step: 3
Training loss: 3.390675346598414
Validation loss: 3.7514848688457927

Epoch: 5| Step: 4
Training loss: 3.6533947090460193
Validation loss: 3.735998857061681

Epoch: 5| Step: 5
Training loss: 3.7926472803636133
Validation loss: 3.688136350891375

Epoch: 5| Step: 6
Training loss: 3.8305838025915526
Validation loss: 3.6765520395887097

Epoch: 5| Step: 7
Training loss: 3.7129326205459687
Validation loss: 3.667467756008481

Epoch: 5| Step: 8
Training loss: 4.458698412246792
Validation loss: 3.6476378561789704

Epoch: 5| Step: 9
Training loss: 3.7231300268672394
Validation loss: 3.6225937568184663

Epoch: 5| Step: 10
Training loss: 4.393746240649508
Validation loss: 3.600344075004585

Epoch: 15| Step: 0
Training loss: 4.301445545029655
Validation loss: 3.582987170277249

Epoch: 5| Step: 1
Training loss: 4.0750994804736775
Validation loss: 3.54650064950076

Epoch: 5| Step: 2
Training loss: 3.414065572706712
Validation loss: 3.5314816852561175

Epoch: 5| Step: 3
Training loss: 3.8755155651068853
Validation loss: 3.495148907952815

Epoch: 5| Step: 4
Training loss: 3.4317705437042596
Validation loss: 3.4768578881685293

Epoch: 5| Step: 5
Training loss: 3.7696741897283514
Validation loss: 3.4545737546793025

Epoch: 5| Step: 6
Training loss: 3.438411383754583
Validation loss: 3.4260728310465343

Epoch: 5| Step: 7
Training loss: 2.711801616575208
Validation loss: 3.40981247098029

Epoch: 5| Step: 8
Training loss: 3.7873727707848897
Validation loss: 3.3836802143892064

Epoch: 5| Step: 9
Training loss: 3.207584458842496
Validation loss: 3.358935557815903

Epoch: 5| Step: 10
Training loss: 3.7210677161017833
Validation loss: 3.3426807140221064

Epoch: 16| Step: 0
Training loss: 3.2299033688478556
Validation loss: 3.324694630209239

Epoch: 5| Step: 1
Training loss: 2.341568198345383
Validation loss: 3.3091995620833035

Epoch: 5| Step: 2
Training loss: 3.9231036567927844
Validation loss: 3.2898645749785986

Epoch: 5| Step: 3
Training loss: 3.3673351990065172
Validation loss: 3.2745876807000314

Epoch: 5| Step: 4
Training loss: 3.2559949895834275
Validation loss: 3.2459467570072964

Epoch: 5| Step: 5
Training loss: 3.626511488871703
Validation loss: 3.232353822949514

Epoch: 5| Step: 6
Training loss: 2.5133240406495307
Validation loss: 3.2216895260958545

Epoch: 5| Step: 7
Training loss: 3.571985566437919
Validation loss: 3.1953653318717636

Epoch: 5| Step: 8
Training loss: 3.875699503120536
Validation loss: 3.1591703139727425

Epoch: 5| Step: 9
Training loss: 3.631914975444081
Validation loss: 3.148848401548757

Epoch: 5| Step: 10
Training loss: 3.9231406065718706
Validation loss: 3.1382160836610242

Epoch: 17| Step: 0
Training loss: 3.0341730869738313
Validation loss: 3.0972714320820627

Epoch: 5| Step: 1
Training loss: 3.878073918992132
Validation loss: 3.0887820223234237

Epoch: 5| Step: 2
Training loss: 3.8546408834062422
Validation loss: 3.0936257627552055

Epoch: 5| Step: 3
Training loss: 3.2914570769852416
Validation loss: 3.063009158232344

Epoch: 5| Step: 4
Training loss: 3.4936486244848304
Validation loss: 3.033862643243464

Epoch: 5| Step: 5
Training loss: 3.184431506433297
Validation loss: 3.0270516834295846

Epoch: 5| Step: 6
Training loss: 3.1017432940851735
Validation loss: 2.9968389175465124

Epoch: 5| Step: 7
Training loss: 3.1491592375105837
Validation loss: 3.0032821184612035

Epoch: 5| Step: 8
Training loss: 2.616240190468454
Validation loss: 2.9591114806524965

Epoch: 5| Step: 9
Training loss: 2.6323295172891163
Validation loss: 2.9456023213491593

Epoch: 5| Step: 10
Training loss: 3.48121136792867
Validation loss: 2.946918972836814

Epoch: 18| Step: 0
Training loss: 3.036061352035758
Validation loss: 2.9165262783268004

Epoch: 5| Step: 1
Training loss: 2.8624427889641346
Validation loss: 2.911285809717449

Epoch: 5| Step: 2
Training loss: 2.8851599917683224
Validation loss: 2.8866663527339926

Epoch: 5| Step: 3
Training loss: 4.049671046708344
Validation loss: 2.8765096174222267

Epoch: 5| Step: 4
Training loss: 3.3672976730272026
Validation loss: 2.856685286753058

Epoch: 5| Step: 5
Training loss: 3.243324907559163
Validation loss: 2.8421009424981287

Epoch: 5| Step: 6
Training loss: 3.264392236806143
Validation loss: 2.8494339871478394

Epoch: 5| Step: 7
Training loss: 2.9012679189303685
Validation loss: 2.8201867109242906

Epoch: 5| Step: 8
Training loss: 3.3031528958935437
Validation loss: 2.8151001809496936

Epoch: 5| Step: 9
Training loss: 3.0454890302261046
Validation loss: 2.781574792114862

Epoch: 5| Step: 10
Training loss: 2.194432961424495
Validation loss: 2.7891904933063496

Epoch: 19| Step: 0
Training loss: 3.2630520408378136
Validation loss: 2.789683137950728

Epoch: 5| Step: 1
Training loss: 3.323025947774853
Validation loss: 2.787185299637992

Epoch: 5| Step: 2
Training loss: 3.4955565993602584
Validation loss: 2.7584049583479193

Epoch: 5| Step: 3
Training loss: 2.407184369876178
Validation loss: 2.7545119455645364

Epoch: 5| Step: 4
Training loss: 1.9122212175618696
Validation loss: 2.744191213669976

Epoch: 5| Step: 5
Training loss: 3.130349882271471
Validation loss: 2.733662534088433

Epoch: 5| Step: 6
Training loss: 3.8420839498185893
Validation loss: 2.7324991259035762

Epoch: 5| Step: 7
Training loss: 3.3448989177763804
Validation loss: 2.72286587967412

Epoch: 5| Step: 8
Training loss: 2.818074614479872
Validation loss: 2.7226621462640903

Epoch: 5| Step: 9
Training loss: 3.1286872472806206
Validation loss: 2.7131810524486006

Epoch: 5| Step: 10
Training loss: 2.6264237675288853
Validation loss: 2.7059761852167226

Epoch: 20| Step: 0
Training loss: 3.056388205931381
Validation loss: 2.698629732518971

Epoch: 5| Step: 1
Training loss: 2.005733734920757
Validation loss: 2.7046052748027947

Epoch: 5| Step: 2
Training loss: 3.1567228359661783
Validation loss: 2.688354482264

Epoch: 5| Step: 3
Training loss: 3.220872049892666
Validation loss: 2.708257871638263

Epoch: 5| Step: 4
Training loss: 2.648306244154854
Validation loss: 2.670371469662251

Epoch: 5| Step: 5
Training loss: 3.1554289401386697
Validation loss: 2.6886333204146013

Epoch: 5| Step: 6
Training loss: 3.145612409973113
Validation loss: 2.677081758359747

Epoch: 5| Step: 7
Training loss: 3.3374871757346662
Validation loss: 2.6777642263064667

Epoch: 5| Step: 8
Training loss: 3.1583664851264674
Validation loss: 2.679129663573352

Epoch: 5| Step: 9
Training loss: 3.231843704193091
Validation loss: 2.676190685483118

Epoch: 5| Step: 10
Training loss: 2.8487471386575827
Validation loss: 2.658063164755307

Epoch: 21| Step: 0
Training loss: 3.256061769635316
Validation loss: 2.6582873180705513

Epoch: 5| Step: 1
Training loss: 2.872693006971801
Validation loss: 2.6653021915802646

Epoch: 5| Step: 2
Training loss: 3.264551743819315
Validation loss: 2.6474157757036316

Epoch: 5| Step: 3
Training loss: 2.964676320772756
Validation loss: 2.6550927939209488

Epoch: 5| Step: 4
Training loss: 2.9751354411092508
Validation loss: 2.6532149288007996

Epoch: 5| Step: 5
Training loss: 2.5657597718984304
Validation loss: 2.6640572140534498

Epoch: 5| Step: 6
Training loss: 3.172951651814666
Validation loss: 2.6475230760759803

Epoch: 5| Step: 7
Training loss: 3.008162837247264
Validation loss: 2.636569888076493

Epoch: 5| Step: 8
Training loss: 2.9983404655718053
Validation loss: 2.633332616513353

Epoch: 5| Step: 9
Training loss: 3.0427678523020663
Validation loss: 2.651453761516897

Epoch: 5| Step: 10
Training loss: 3.0037981467767754
Validation loss: 2.639756005039573

Epoch: 22| Step: 0
Training loss: 3.3698358940669344
Validation loss: 2.655440772929707

Epoch: 5| Step: 1
Training loss: 2.8073371123891864
Validation loss: 2.6200485408544436

Epoch: 5| Step: 2
Training loss: 3.7466124174550557
Validation loss: 2.6370146967774857

Epoch: 5| Step: 3
Training loss: 2.6956931909594526
Validation loss: 2.650359314318183

Epoch: 5| Step: 4
Training loss: 2.954309296673278
Validation loss: 2.6374793974439097

Epoch: 5| Step: 5
Training loss: 2.569114707432085
Validation loss: 2.637218139949967

Epoch: 5| Step: 6
Training loss: 3.367448199241193
Validation loss: 2.6447842903245817

Epoch: 5| Step: 7
Training loss: 2.9509290169865925
Validation loss: 2.635962634035438

Epoch: 5| Step: 8
Training loss: 2.2925708951980694
Validation loss: 2.6420152915168083

Epoch: 5| Step: 9
Training loss: 2.7062153873476675
Validation loss: 2.630668759848928

Epoch: 5| Step: 10
Training loss: 3.3607385041768767
Validation loss: 2.6374634293131667

Epoch: 23| Step: 0
Training loss: 3.087175569979448
Validation loss: 2.631575819687207

Epoch: 5| Step: 1
Training loss: 3.27327930004432
Validation loss: 2.6540886807737536

Epoch: 5| Step: 2
Training loss: 2.902878477143672
Validation loss: 2.6409068332497734

Epoch: 5| Step: 3
Training loss: 3.662568460807598
Validation loss: 2.6501633389641266

Epoch: 5| Step: 4
Training loss: 2.927549675732563
Validation loss: 2.657768541228999

Epoch: 5| Step: 5
Training loss: 2.538323679317251
Validation loss: 2.6547771098105666

Epoch: 5| Step: 6
Training loss: 2.5356680848577486
Validation loss: 2.640277441386389

Epoch: 5| Step: 7
Training loss: 2.6024298611001604
Validation loss: 2.627638631852565

Epoch: 5| Step: 8
Training loss: 2.8639343266336446
Validation loss: 2.622285004322999

Epoch: 5| Step: 9
Training loss: 3.4244467072586326
Validation loss: 2.6325840673665124

Epoch: 5| Step: 10
Training loss: 2.963657227169878
Validation loss: 2.6405703437082084

Epoch: 24| Step: 0
Training loss: 2.7928250789369726
Validation loss: 2.6178806190960895

Epoch: 5| Step: 1
Training loss: 3.153377320975462
Validation loss: 2.623403107415618

Epoch: 5| Step: 2
Training loss: 4.042459678849865
Validation loss: 2.6262445190283157

Epoch: 5| Step: 3
Training loss: 2.834432912148686
Validation loss: 2.6446915170794147

Epoch: 5| Step: 4
Training loss: 2.67951497670875
Validation loss: 2.6312716577807898

Epoch: 5| Step: 5
Training loss: 2.772008307346815
Validation loss: 2.6304655215949353

Epoch: 5| Step: 6
Training loss: 2.788467728483984
Validation loss: 2.6208227764013334

Epoch: 5| Step: 7
Training loss: 2.651458817333558
Validation loss: 2.6142404080782793

Epoch: 5| Step: 8
Training loss: 2.618806617142996
Validation loss: 2.6338271695018998

Epoch: 5| Step: 9
Training loss: 3.4099228681863143
Validation loss: 2.6179598172454286

Epoch: 5| Step: 10
Training loss: 2.864582593513162
Validation loss: 2.6378245412723476

Epoch: 25| Step: 0
Training loss: 3.291828360791185
Validation loss: 2.630065226593492

Epoch: 5| Step: 1
Training loss: 3.0357968551562156
Validation loss: 2.636254118495164

Epoch: 5| Step: 2
Training loss: 2.828099877683222
Validation loss: 2.628315390124923

Epoch: 5| Step: 3
Training loss: 2.857868068482271
Validation loss: 2.640579144596126

Epoch: 5| Step: 4
Training loss: 2.932080890856339
Validation loss: 2.628606688780398

Epoch: 5| Step: 5
Training loss: 3.309854278583724
Validation loss: 2.643035884191491

Epoch: 5| Step: 6
Training loss: 3.254238299478088
Validation loss: 2.62747134841105

Epoch: 5| Step: 7
Training loss: 2.8083041788582004
Validation loss: 2.6256130252744363

Epoch: 5| Step: 8
Training loss: 3.1666265953607162
Validation loss: 2.6458857205486694

Epoch: 5| Step: 9
Training loss: 2.467027860263818
Validation loss: 2.637671702404952

Epoch: 5| Step: 10
Training loss: 2.9266273079950484
Validation loss: 2.6317531386907222

Epoch: 26| Step: 0
Training loss: 3.473076536407826
Validation loss: 2.628552007883677

Epoch: 5| Step: 1
Training loss: 3.304630793091704
Validation loss: 2.6189280717321197

Epoch: 5| Step: 2
Training loss: 2.8857449965616615
Validation loss: 2.6277531075577163

Epoch: 5| Step: 3
Training loss: 3.0327764384166267
Validation loss: 2.6316910115723786

Epoch: 5| Step: 4
Training loss: 3.2841473094876603
Validation loss: 2.617687213755821

Epoch: 5| Step: 5
Training loss: 3.274573372578465
Validation loss: 2.629219265097321

Epoch: 5| Step: 6
Training loss: 2.6424587586504
Validation loss: 2.6303044003820393

Epoch: 5| Step: 7
Training loss: 2.536081765255658
Validation loss: 2.609735640937523

Epoch: 5| Step: 8
Training loss: 2.5095809452966633
Validation loss: 2.6101105829525344

Epoch: 5| Step: 9
Training loss: 3.0813179302658673
Validation loss: 2.6257053419862157

Epoch: 5| Step: 10
Training loss: 2.6050990355660995
Validation loss: 2.61877863610336

Epoch: 27| Step: 0
Training loss: 3.2946949480984413
Validation loss: 2.6269046262811337

Epoch: 5| Step: 1
Training loss: 3.568808207396301
Validation loss: 2.6186396280768722

Epoch: 5| Step: 2
Training loss: 2.95687015150048
Validation loss: 2.6222986208040484

Epoch: 5| Step: 3
Training loss: 3.2447080810623063
Validation loss: 2.6310004803304317

Epoch: 5| Step: 4
Training loss: 2.80417630523189
Validation loss: 2.6104381533060415

Epoch: 5| Step: 5
Training loss: 2.944362335339789
Validation loss: 2.616319170771681

Epoch: 5| Step: 6
Training loss: 2.995392121643232
Validation loss: 2.616233698656141

Epoch: 5| Step: 7
Training loss: 2.6287086265163238
Validation loss: 2.6272554723052766

Epoch: 5| Step: 8
Training loss: 2.8324928907151996
Validation loss: 2.6333692347923394

Epoch: 5| Step: 9
Training loss: 2.7507558997518355
Validation loss: 2.622829893837018

Epoch: 5| Step: 10
Training loss: 2.7309438922360716
Validation loss: 2.6241451840474577

Epoch: 28| Step: 0
Training loss: 2.8651599835370813
Validation loss: 2.6205896125307233

Epoch: 5| Step: 1
Training loss: 2.787775421220981
Validation loss: 2.602103688512744

Epoch: 5| Step: 2
Training loss: 2.5902879889192922
Validation loss: 2.6208594726274197

Epoch: 5| Step: 3
Training loss: 3.0060076958918835
Validation loss: 2.6149190633150003

Epoch: 5| Step: 4
Training loss: 3.143264648102392
Validation loss: 2.6063016059168915

Epoch: 5| Step: 5
Training loss: 3.2585103044638166
Validation loss: 2.5997050686006413

Epoch: 5| Step: 6
Training loss: 3.1168379432276008
Validation loss: 2.626884969289265

Epoch: 5| Step: 7
Training loss: 2.7516923378806495
Validation loss: 2.630161086057824

Epoch: 5| Step: 8
Training loss: 2.8660214415105556
Validation loss: 2.6287181907478714

Epoch: 5| Step: 9
Training loss: 3.294390424686132
Validation loss: 2.626682627033778

Epoch: 5| Step: 10
Training loss: 3.0540853623986792
Validation loss: 2.6182563970685453

Epoch: 29| Step: 0
Training loss: 2.834723935419296
Validation loss: 2.632277287183907

Epoch: 5| Step: 1
Training loss: 2.8357548930749696
Validation loss: 2.630558020804656

Epoch: 5| Step: 2
Training loss: 2.822120319572596
Validation loss: 2.6257606337974924

Epoch: 5| Step: 3
Training loss: 2.6863805524184596
Validation loss: 2.6214794570007065

Epoch: 5| Step: 4
Training loss: 3.193857323323258
Validation loss: 2.616628391160192

Epoch: 5| Step: 5
Training loss: 3.4625466353928736
Validation loss: 2.6368379960465695

Epoch: 5| Step: 6
Training loss: 3.085533868974994
Validation loss: 2.6269302098182474

Epoch: 5| Step: 7
Training loss: 2.9756072506518456
Validation loss: 2.601390755721566

Epoch: 5| Step: 8
Training loss: 2.9714019174218755
Validation loss: 2.60584161721853

Epoch: 5| Step: 9
Training loss: 2.9115594745099056
Validation loss: 2.6153340981144075

Epoch: 5| Step: 10
Training loss: 2.999902882593481
Validation loss: 2.629048304612948

Epoch: 30| Step: 0
Training loss: 2.9754772861275938
Validation loss: 2.626904733631991

Epoch: 5| Step: 1
Training loss: 2.594749441968426
Validation loss: 2.637189626148814

Epoch: 5| Step: 2
Training loss: 2.153152341627527
Validation loss: 2.6495591375237426

Epoch: 5| Step: 3
Training loss: 3.5485216259275205
Validation loss: 2.6329024153376173

Epoch: 5| Step: 4
Training loss: 3.4015450837684305
Validation loss: 2.611010841309701

Epoch: 5| Step: 5
Training loss: 3.143893386877449
Validation loss: 2.6108964150904246

Epoch: 5| Step: 6
Training loss: 3.078249391472542
Validation loss: 2.631866546586191

Epoch: 5| Step: 7
Training loss: 3.610340468183522
Validation loss: 2.6214907717024345

Epoch: 5| Step: 8
Training loss: 2.772228482489269
Validation loss: 2.604788356939325

Epoch: 5| Step: 9
Training loss: 2.3812793239279793
Validation loss: 2.6272781124079865

Epoch: 5| Step: 10
Training loss: 2.604967609577563
Validation loss: 2.624954422468635

Epoch: 31| Step: 0
Training loss: 2.776444473291163
Validation loss: 2.607766404064597

Epoch: 5| Step: 1
Training loss: 3.4333897379220235
Validation loss: 2.6055435376805143

Epoch: 5| Step: 2
Training loss: 3.0646956999972352
Validation loss: 2.622921635076519

Epoch: 5| Step: 3
Training loss: 3.246207885939055
Validation loss: 2.6206903321560726

Epoch: 5| Step: 4
Training loss: 2.745848296090449
Validation loss: 2.609414037292477

Epoch: 5| Step: 5
Training loss: 2.954476990606781
Validation loss: 2.617408704156614

Epoch: 5| Step: 6
Training loss: 2.3867979645265365
Validation loss: 2.6299684990054906

Epoch: 5| Step: 7
Training loss: 3.5937162978209107
Validation loss: 2.6138885379554315

Epoch: 5| Step: 8
Training loss: 2.8636720814754906
Validation loss: 2.627338036213743

Epoch: 5| Step: 9
Training loss: 2.3931034181009734
Validation loss: 2.6181373240334125

Epoch: 5| Step: 10
Training loss: 3.0315356562406772
Validation loss: 2.6121275096384964

Epoch: 32| Step: 0
Training loss: 2.3320384065400033
Validation loss: 2.6108587314390284

Epoch: 5| Step: 1
Training loss: 2.2119610577237183
Validation loss: 2.6079858947616312

Epoch: 5| Step: 2
Training loss: 2.963422150484129
Validation loss: 2.6209714597008325

Epoch: 5| Step: 3
Training loss: 3.286270515084756
Validation loss: 2.610562518094798

Epoch: 5| Step: 4
Training loss: 2.932157487436159
Validation loss: 2.6218291868196917

Epoch: 5| Step: 5
Training loss: 3.013913474346463
Validation loss: 2.6039443438391694

Epoch: 5| Step: 6
Training loss: 3.0032774188911984
Validation loss: 2.6089525780433664

Epoch: 5| Step: 7
Training loss: 2.8626731653600213
Validation loss: 2.607504180092196

Epoch: 5| Step: 8
Training loss: 2.5005569791230644
Validation loss: 2.619615122736069

Epoch: 5| Step: 9
Training loss: 3.7781498077562556
Validation loss: 2.6226492443032265

Epoch: 5| Step: 10
Training loss: 3.5230386512492027
Validation loss: 2.6007808018524754

Epoch: 33| Step: 0
Training loss: 2.8309908514599273
Validation loss: 2.6112873992356818

Epoch: 5| Step: 1
Training loss: 2.7304151363320974
Validation loss: 2.621239605127781

Epoch: 5| Step: 2
Training loss: 2.7676392025557957
Validation loss: 2.6132877991777574

Epoch: 5| Step: 3
Training loss: 2.981177409505889
Validation loss: 2.6094949621151975

Epoch: 5| Step: 4
Training loss: 3.4452513258989392
Validation loss: 2.612047777397465

Epoch: 5| Step: 5
Training loss: 2.555342657324844
Validation loss: 2.6098863074817897

Epoch: 5| Step: 6
Training loss: 3.8850869591994965
Validation loss: 2.6338271062340266

Epoch: 5| Step: 7
Training loss: 2.877047597417814
Validation loss: 2.6000613497996814

Epoch: 5| Step: 8
Training loss: 2.4065597136693997
Validation loss: 2.6022167093368216

Epoch: 5| Step: 9
Training loss: 2.7071721644420195
Validation loss: 2.6109072797974453

Epoch: 5| Step: 10
Training loss: 2.949258038593851
Validation loss: 2.609257034740854

Epoch: 34| Step: 0
Training loss: 3.1240577803188128
Validation loss: 2.6051337519091224

Epoch: 5| Step: 1
Training loss: 2.9091929639991614
Validation loss: 2.6117659219506435

Epoch: 5| Step: 2
Training loss: 3.2700383056356856
Validation loss: 2.612414404460964

Epoch: 5| Step: 3
Training loss: 2.638231355050155
Validation loss: 2.5902319636528004

Epoch: 5| Step: 4
Training loss: 2.9759198794193273
Validation loss: 2.61057626642457

Epoch: 5| Step: 5
Training loss: 3.0309394598703903
Validation loss: 2.613646717286921

Epoch: 5| Step: 6
Training loss: 2.7399006842274285
Validation loss: 2.6133286948703858

Epoch: 5| Step: 7
Training loss: 2.866820434024416
Validation loss: 2.6126918107429287

Epoch: 5| Step: 8
Training loss: 3.5935844051522046
Validation loss: 2.6136336697573426

Epoch: 5| Step: 9
Training loss: 2.226367928553094
Validation loss: 2.6281882982112075

Epoch: 5| Step: 10
Training loss: 2.9180092764086667
Validation loss: 2.6043687691969075

Epoch: 35| Step: 0
Training loss: 3.16328869058229
Validation loss: 2.6256674090467533

Epoch: 5| Step: 1
Training loss: 3.080862619062892
Validation loss: 2.6022480702455053

Epoch: 5| Step: 2
Training loss: 2.9014252021610605
Validation loss: 2.6223500906200856

Epoch: 5| Step: 3
Training loss: 2.7093385053770507
Validation loss: 2.6063662120073245

Epoch: 5| Step: 4
Training loss: 2.5193163403074816
Validation loss: 2.6117432504454143

Epoch: 5| Step: 5
Training loss: 2.994076603094883
Validation loss: 2.5906419587000507

Epoch: 5| Step: 6
Training loss: 2.527344599020578
Validation loss: 2.6038831855954543

Epoch: 5| Step: 7
Training loss: 3.0398051867052462
Validation loss: 2.621343813688779

Epoch: 5| Step: 8
Training loss: 3.202548835852548
Validation loss: 2.608587892857561

Epoch: 5| Step: 9
Training loss: 3.1329866203950214
Validation loss: 2.6311025932718017

Epoch: 5| Step: 10
Training loss: 3.133756043618898
Validation loss: 2.604163218506202

Epoch: 36| Step: 0
Training loss: 3.1850416389749747
Validation loss: 2.608067531331423

Epoch: 5| Step: 1
Training loss: 2.865331064372749
Validation loss: 2.6084993261316884

Epoch: 5| Step: 2
Training loss: 2.5959079452086815
Validation loss: 2.6081295193536644

Epoch: 5| Step: 3
Training loss: 2.5194917897527653
Validation loss: 2.594998366281308

Epoch: 5| Step: 4
Training loss: 3.2829750975803957
Validation loss: 2.596724605226955

Epoch: 5| Step: 5
Training loss: 3.3080809284721693
Validation loss: 2.597910540342013

Epoch: 5| Step: 6
Training loss: 3.0090087097285325
Validation loss: 2.617258078845292

Epoch: 5| Step: 7
Training loss: 2.7655731023886823
Validation loss: 2.6004350337721336

Epoch: 5| Step: 8
Training loss: 2.421050491266592
Validation loss: 2.601562030938406

Epoch: 5| Step: 9
Training loss: 2.969383091932611
Validation loss: 2.609341859008353

Epoch: 5| Step: 10
Training loss: 3.4830103370059686
Validation loss: 2.6244432764308137

Epoch: 37| Step: 0
Training loss: 3.451915822696849
Validation loss: 2.6189963473910933

Epoch: 5| Step: 1
Training loss: 2.9518074446941416
Validation loss: 2.600614197087863

Epoch: 5| Step: 2
Training loss: 2.6519191666161075
Validation loss: 2.6088446071383617

Epoch: 5| Step: 3
Training loss: 2.4222246471396778
Validation loss: 2.5961700784620834

Epoch: 5| Step: 4
Training loss: 2.4212737290731616
Validation loss: 2.591788764068813

Epoch: 5| Step: 5
Training loss: 3.253504404302148
Validation loss: 2.612264798380886

Epoch: 5| Step: 6
Training loss: 3.278578042725042
Validation loss: 2.5993828689497156

Epoch: 5| Step: 7
Training loss: 3.1684958211164833
Validation loss: 2.5983262475996045

Epoch: 5| Step: 8
Training loss: 3.0006199831881912
Validation loss: 2.6145761356827473

Epoch: 5| Step: 9
Training loss: 2.3201055466550717
Validation loss: 2.5974037172873166

Epoch: 5| Step: 10
Training loss: 3.2857187993747203
Validation loss: 2.606715323944998

Epoch: 38| Step: 0
Training loss: 3.1002900326321066
Validation loss: 2.583168717881079

Epoch: 5| Step: 1
Training loss: 2.7393961988773783
Validation loss: 2.6008755297532233

Epoch: 5| Step: 2
Training loss: 3.4269885172767047
Validation loss: 2.587414706631902

Epoch: 5| Step: 3
Training loss: 2.8243570254337
Validation loss: 2.5998692181448977

Epoch: 5| Step: 4
Training loss: 3.346744088142401
Validation loss: 2.6150350408861747

Epoch: 5| Step: 5
Training loss: 2.9138957530731657
Validation loss: 2.5919863163825383

Epoch: 5| Step: 6
Training loss: 2.543106942589665
Validation loss: 2.605675922423636

Epoch: 5| Step: 7
Training loss: 2.7713534409588316
Validation loss: 2.616799525285831

Epoch: 5| Step: 8
Training loss: 2.602930665747687
Validation loss: 2.5977269696818914

Epoch: 5| Step: 9
Training loss: 3.3427132398538233
Validation loss: 2.6120655183481314

Epoch: 5| Step: 10
Training loss: 2.6343804736097494
Validation loss: 2.6232860837493495

Epoch: 39| Step: 0
Training loss: 2.6197266061842983
Validation loss: 2.601032752395081

Epoch: 5| Step: 1
Training loss: 2.7782340681638225
Validation loss: 2.6067585660202366

Epoch: 5| Step: 2
Training loss: 2.5790175309045758
Validation loss: 2.5966151494254386

Epoch: 5| Step: 3
Training loss: 3.319871437846738
Validation loss: 2.615463052621725

Epoch: 5| Step: 4
Training loss: 2.565233029196293
Validation loss: 2.614841188793224

Epoch: 5| Step: 5
Training loss: 2.8640455446298105
Validation loss: 2.6084504312304344

Epoch: 5| Step: 6
Training loss: 3.2363343132296
Validation loss: 2.6163918140444875

Epoch: 5| Step: 7
Training loss: 3.3562322065567236
Validation loss: 2.6156659462236944

Epoch: 5| Step: 8
Training loss: 3.0555871287554566
Validation loss: 2.589395629103318

Epoch: 5| Step: 9
Training loss: 2.8670996878583046
Validation loss: 2.610627261293417

Epoch: 5| Step: 10
Training loss: 2.951129703485503
Validation loss: 2.599814128069027

Epoch: 40| Step: 0
Training loss: 2.9742756065824048
Validation loss: 2.596869666595311

Epoch: 5| Step: 1
Training loss: 2.588163311105227
Validation loss: 2.6114140384439013

Epoch: 5| Step: 2
Training loss: 2.697484829977545
Validation loss: 2.6139288622730805

Epoch: 5| Step: 3
Training loss: 3.0531451534047296
Validation loss: 2.601138314539459

Epoch: 5| Step: 4
Training loss: 3.2208963293418305
Validation loss: 2.5946131027675152

Epoch: 5| Step: 5
Training loss: 3.199396410283777
Validation loss: 2.6047685665092914

Epoch: 5| Step: 6
Training loss: 3.1984337669242686
Validation loss: 2.5776275582450077

Epoch: 5| Step: 7
Training loss: 3.0678197627833073
Validation loss: 2.5913770574449484

Epoch: 5| Step: 8
Training loss: 2.7467873621165335
Validation loss: 2.5973154314888522

Epoch: 5| Step: 9
Training loss: 2.640787966061561
Validation loss: 2.582544282360961

Epoch: 5| Step: 10
Training loss: 2.9192452249529577
Validation loss: 2.5737180291787873

Epoch: 41| Step: 0
Training loss: 3.052043424134915
Validation loss: 2.5897450182416364

Epoch: 5| Step: 1
Training loss: 3.203658045633468
Validation loss: 2.5687010054185735

Epoch: 5| Step: 2
Training loss: 2.869193142175928
Validation loss: 2.5880996572006527

Epoch: 5| Step: 3
Training loss: 2.534212803853947
Validation loss: 2.5973025930958893

Epoch: 5| Step: 4
Training loss: 2.777662642530008
Validation loss: 2.598287562214261

Epoch: 5| Step: 5
Training loss: 3.684650548672495
Validation loss: 2.59587872778779

Epoch: 5| Step: 6
Training loss: 2.6667343568158
Validation loss: 2.5955286521295666

Epoch: 5| Step: 7
Training loss: 2.4413626949239853
Validation loss: 2.6032835206551055

Epoch: 5| Step: 8
Training loss: 3.1669869177318937
Validation loss: 2.594855661830189

Epoch: 5| Step: 9
Training loss: 3.248277794754779
Validation loss: 2.6015287904169986

Epoch: 5| Step: 10
Training loss: 2.250893945067363
Validation loss: 2.5979437205847216

Epoch: 42| Step: 0
Training loss: 2.155399541791131
Validation loss: 2.5833188548428283

Epoch: 5| Step: 1
Training loss: 2.88150681284136
Validation loss: 2.5986220276836733

Epoch: 5| Step: 2
Training loss: 2.994581415287152
Validation loss: 2.582495516980909

Epoch: 5| Step: 3
Training loss: 3.512917115773226
Validation loss: 2.5951045532332437

Epoch: 5| Step: 4
Training loss: 2.8468801856386294
Validation loss: 2.5968269178336865

Epoch: 5| Step: 5
Training loss: 2.543433456033355
Validation loss: 2.5843959776895726

Epoch: 5| Step: 6
Training loss: 2.9844400288951656
Validation loss: 2.6190144161750752

Epoch: 5| Step: 7
Training loss: 3.300704539835329
Validation loss: 2.5602388998416776

Epoch: 5| Step: 8
Training loss: 3.4316004673144787
Validation loss: 2.587337149687602

Epoch: 5| Step: 9
Training loss: 3.1332327163719977
Validation loss: 2.585318910951088

Epoch: 5| Step: 10
Training loss: 2.1755880547432804
Validation loss: 2.578980449055906

Epoch: 43| Step: 0
Training loss: 3.2266644699572606
Validation loss: 2.578449385723825

Epoch: 5| Step: 1
Training loss: 2.860864136868289
Validation loss: 2.5784184850339846

Epoch: 5| Step: 2
Training loss: 3.233250666738105
Validation loss: 2.581153832122796

Epoch: 5| Step: 3
Training loss: 2.741992302275133
Validation loss: 2.590694293454589

Epoch: 5| Step: 4
Training loss: 2.8982359618168863
Validation loss: 2.6028931730813607

Epoch: 5| Step: 5
Training loss: 2.297697789226258
Validation loss: 2.606117607195443

Epoch: 5| Step: 6
Training loss: 3.2518038512098424
Validation loss: 2.5973747634451763

Epoch: 5| Step: 7
Training loss: 3.0589457537108284
Validation loss: 2.602320330022882

Epoch: 5| Step: 8
Training loss: 2.6757179865354344
Validation loss: 2.5932422471567613

Epoch: 5| Step: 9
Training loss: 2.8426308578122876
Validation loss: 2.6067349815790095

Epoch: 5| Step: 10
Training loss: 3.1364692788306314
Validation loss: 2.611618557084346

Epoch: 44| Step: 0
Training loss: 3.0783384607338107
Validation loss: 2.599071842902341

Epoch: 5| Step: 1
Training loss: 2.524418218081686
Validation loss: 2.5976915059645145

Epoch: 5| Step: 2
Training loss: 3.2380627235147896
Validation loss: 2.5926454101851024

Epoch: 5| Step: 3
Training loss: 2.5937894335587206
Validation loss: 2.6130665542345244

Epoch: 5| Step: 4
Training loss: 2.9125787879863485
Validation loss: 2.5878413367535757

Epoch: 5| Step: 5
Training loss: 3.36374993331722
Validation loss: 2.6018326102476803

Epoch: 5| Step: 6
Training loss: 2.61340194902389
Validation loss: 2.591098801834328

Epoch: 5| Step: 7
Training loss: 2.944620471067185
Validation loss: 2.5987911977425737

Epoch: 5| Step: 8
Training loss: 3.0229794650628055
Validation loss: 2.596759790911663

Epoch: 5| Step: 9
Training loss: 2.465705636256682
Validation loss: 2.5946967498260745

Epoch: 5| Step: 10
Training loss: 3.380525516309329
Validation loss: 2.5941534023937263

Epoch: 45| Step: 0
Training loss: 3.1052049440819482
Validation loss: 2.5910434817495567

Epoch: 5| Step: 1
Training loss: 2.9864028512151695
Validation loss: 2.615961165191432

Epoch: 5| Step: 2
Training loss: 2.7698284898949677
Validation loss: 2.578093628057015

Epoch: 5| Step: 3
Training loss: 2.313898230884017
Validation loss: 2.589001454776775

Epoch: 5| Step: 4
Training loss: 2.8910449573527166
Validation loss: 2.5996324353518

Epoch: 5| Step: 5
Training loss: 3.557228337287827
Validation loss: 2.606348044718574

Epoch: 5| Step: 6
Training loss: 2.721754671890455
Validation loss: 2.598772843337592

Epoch: 5| Step: 7
Training loss: 2.880399195237664
Validation loss: 2.5844501297006888

Epoch: 5| Step: 8
Training loss: 3.076163039421835
Validation loss: 2.59468467902416

Epoch: 5| Step: 9
Training loss: 2.6206371745421078
Validation loss: 2.5831329451241887

Epoch: 5| Step: 10
Training loss: 3.0177359826732038
Validation loss: 2.6026305664663143

Epoch: 46| Step: 0
Training loss: 2.784874344050751
Validation loss: 2.612793151741522

Epoch: 5| Step: 1
Training loss: 2.8547749857241307
Validation loss: 2.579206175460696

Epoch: 5| Step: 2
Training loss: 3.3451817379606377
Validation loss: 2.5880186864426773

Epoch: 5| Step: 3
Training loss: 3.0007062716404134
Validation loss: 2.5818777058709683

Epoch: 5| Step: 4
Training loss: 3.4067841557239
Validation loss: 2.5859908395328386

Epoch: 5| Step: 5
Training loss: 2.7123489443297824
Validation loss: 2.5798276050374294

Epoch: 5| Step: 6
Training loss: 2.1289960649775614
Validation loss: 2.5805124523985254

Epoch: 5| Step: 7
Training loss: 3.12952522698928
Validation loss: 2.579325501179139

Epoch: 5| Step: 8
Training loss: 2.4023368028989998
Validation loss: 2.5787082384051456

Epoch: 5| Step: 9
Training loss: 3.0103886656905394
Validation loss: 2.58979080461106

Epoch: 5| Step: 10
Training loss: 2.8463841908166505
Validation loss: 2.604488644948033

Epoch: 47| Step: 0
Training loss: 2.2372709061109077
Validation loss: 2.594586608716863

Epoch: 5| Step: 1
Training loss: 1.8871443053328991
Validation loss: 2.5693565176970865

Epoch: 5| Step: 2
Training loss: 2.802407871062572
Validation loss: 2.590316291328192

Epoch: 5| Step: 3
Training loss: 2.4825678556605424
Validation loss: 2.5714467252769913

Epoch: 5| Step: 4
Training loss: 3.62657986118643
Validation loss: 2.5879364639900153

Epoch: 5| Step: 5
Training loss: 3.161452886753743
Validation loss: 2.6034722857346804

Epoch: 5| Step: 6
Training loss: 2.780762533266452
Validation loss: 2.577892333986434

Epoch: 5| Step: 7
Training loss: 3.0404592408087847
Validation loss: 2.586751350480377

Epoch: 5| Step: 8
Training loss: 2.5594586257407372
Validation loss: 2.5698084851516625

Epoch: 5| Step: 9
Training loss: 3.975899571768024
Validation loss: 2.582440279641473

Epoch: 5| Step: 10
Training loss: 2.807696839902735
Validation loss: 2.5922307204042325

Epoch: 48| Step: 0
Training loss: 3.143964216392661
Validation loss: 2.5730157874347226

Epoch: 5| Step: 1
Training loss: 2.855550240372767
Validation loss: 2.574837425564395

Epoch: 5| Step: 2
Training loss: 3.0184234126562313
Validation loss: 2.5753187402232216

Epoch: 5| Step: 3
Training loss: 2.9376348910912897
Validation loss: 2.5705147342095995

Epoch: 5| Step: 4
Training loss: 2.3056123591195687
Validation loss: 2.6071183308832273

Epoch: 5| Step: 5
Training loss: 3.177938594246476
Validation loss: 2.5707182977960623

Epoch: 5| Step: 6
Training loss: 2.8493451420181244
Validation loss: 2.5920747362166594

Epoch: 5| Step: 7
Training loss: 3.0798200403624345
Validation loss: 2.5823828506355992

Epoch: 5| Step: 8
Training loss: 2.545290776037685
Validation loss: 2.553026804376977

Epoch: 5| Step: 9
Training loss: 2.948724930201062
Validation loss: 2.5652869391435478

Epoch: 5| Step: 10
Training loss: 3.2000466045323774
Validation loss: 2.5775801275823778

Epoch: 49| Step: 0
Training loss: 2.4598008210098086
Validation loss: 2.5630111309626

Epoch: 5| Step: 1
Training loss: 2.748718223093193
Validation loss: 2.591685027966286

Epoch: 5| Step: 2
Training loss: 2.9032283374474543
Validation loss: 2.5666349670611144

Epoch: 5| Step: 3
Training loss: 3.1332703063253255
Validation loss: 2.5918626200844996

Epoch: 5| Step: 4
Training loss: 3.013749087636929
Validation loss: 2.57496770525301

Epoch: 5| Step: 5
Training loss: 2.6454822177148736
Validation loss: 2.5674420862921012

Epoch: 5| Step: 6
Training loss: 3.4475457183041622
Validation loss: 2.5752116916247343

Epoch: 5| Step: 7
Training loss: 2.9294163285960426
Validation loss: 2.575031013752008

Epoch: 5| Step: 8
Training loss: 3.1104584153054877
Validation loss: 2.5881064067956547

Epoch: 5| Step: 9
Training loss: 2.230368697132042
Validation loss: 2.576071244911307

Epoch: 5| Step: 10
Training loss: 3.0653122426430657
Validation loss: 2.5931746092595946

Epoch: 50| Step: 0
Training loss: 3.0132704323417925
Validation loss: 2.5779012096299128

Epoch: 5| Step: 1
Training loss: 2.0993924760786684
Validation loss: 2.5695870453488685

Epoch: 5| Step: 2
Training loss: 2.7737165283824115
Validation loss: 2.571892205119752

Epoch: 5| Step: 3
Training loss: 2.5797568041008136
Validation loss: 2.5640338595929917

Epoch: 5| Step: 4
Training loss: 2.6300729143891926
Validation loss: 2.5889650050961817

Epoch: 5| Step: 5
Training loss: 3.3253371333100796
Validation loss: 2.579592376491772

Epoch: 5| Step: 6
Training loss: 2.797044290714967
Validation loss: 2.5793876631064103

Epoch: 5| Step: 7
Training loss: 3.496005503643601
Validation loss: 2.5634633046172137

Epoch: 5| Step: 8
Training loss: 3.126895939758567
Validation loss: 2.5672533941468583

Epoch: 5| Step: 9
Training loss: 3.190461073651862
Validation loss: 2.582190329883816

Epoch: 5| Step: 10
Training loss: 2.645759331176417
Validation loss: 2.578378574781975

Epoch: 51| Step: 0
Training loss: 2.4520620971209532
Validation loss: 2.56118942289279

Epoch: 5| Step: 1
Training loss: 2.568033152701979
Validation loss: 2.583349449816661

Epoch: 5| Step: 2
Training loss: 2.8522794475427893
Validation loss: 2.5809731808548313

Epoch: 5| Step: 3
Training loss: 2.9623821830660817
Validation loss: 2.5630998267076004

Epoch: 5| Step: 4
Training loss: 2.6988055165434743
Validation loss: 2.5767391961253368

Epoch: 5| Step: 5
Training loss: 3.421076293817148
Validation loss: 2.5845959945420196

Epoch: 5| Step: 6
Training loss: 2.632038670589124
Validation loss: 2.5865724717958045

Epoch: 5| Step: 7
Training loss: 3.2245233109539995
Validation loss: 2.5813494582628955

Epoch: 5| Step: 8
Training loss: 2.996868088190185
Validation loss: 2.565982989666066

Epoch: 5| Step: 9
Training loss: 2.808814282838236
Validation loss: 2.571297094524483

Epoch: 5| Step: 10
Training loss: 3.055994715101855
Validation loss: 2.5786532907668533

Epoch: 52| Step: 0
Training loss: 3.2352404334974274
Validation loss: 2.578221550678268

Epoch: 5| Step: 1
Training loss: 2.6304111112981783
Validation loss: 2.581307421296384

Epoch: 5| Step: 2
Training loss: 2.6752374917962345
Validation loss: 2.582328159884337

Epoch: 5| Step: 3
Training loss: 2.6209029058572835
Validation loss: 2.596936581888914

Epoch: 5| Step: 4
Training loss: 2.5075188105325474
Validation loss: 2.572630081932297

Epoch: 5| Step: 5
Training loss: 3.00500388857674
Validation loss: 2.590214735295813

Epoch: 5| Step: 6
Training loss: 2.6280315695540093
Validation loss: 2.5930945681101543

Epoch: 5| Step: 7
Training loss: 3.3671908987076815
Validation loss: 2.5850609155911064

Epoch: 5| Step: 8
Training loss: 2.710651305644726
Validation loss: 2.5750123147643125

Epoch: 5| Step: 9
Training loss: 3.186869689853192
Validation loss: 2.590197541465384

Epoch: 5| Step: 10
Training loss: 3.2795277753358363
Validation loss: 2.5919536276076225

Epoch: 53| Step: 0
Training loss: 2.694127892277029
Validation loss: 2.583890895104278

Epoch: 5| Step: 1
Training loss: 2.558223691779872
Validation loss: 2.5708723179527584

Epoch: 5| Step: 2
Training loss: 3.3663608040688966
Validation loss: 2.5557279635267935

Epoch: 5| Step: 3
Training loss: 2.3369750713541766
Validation loss: 2.572477406744046

Epoch: 5| Step: 4
Training loss: 3.2685673795783603
Validation loss: 2.5748758902798445

Epoch: 5| Step: 5
Training loss: 2.2773329667478945
Validation loss: 2.5968629294115253

Epoch: 5| Step: 6
Training loss: 3.189528175307298
Validation loss: 2.5805665607300807

Epoch: 5| Step: 7
Training loss: 2.459001342617939
Validation loss: 2.5922714152465725

Epoch: 5| Step: 8
Training loss: 3.2941744623173186
Validation loss: 2.590519650483174

Epoch: 5| Step: 9
Training loss: 2.78248020353584
Validation loss: 2.56811702761943

Epoch: 5| Step: 10
Training loss: 3.4271251517452783
Validation loss: 2.5827012133875002

Epoch: 54| Step: 0
Training loss: 2.23400182208582
Validation loss: 2.5763177856272352

Epoch: 5| Step: 1
Training loss: 2.7352893281589488
Validation loss: 2.582037879434306

Epoch: 5| Step: 2
Training loss: 2.923686236224014
Validation loss: 2.5997137859530426

Epoch: 5| Step: 3
Training loss: 3.268072789720439
Validation loss: 2.5740893028577156

Epoch: 5| Step: 4
Training loss: 2.8866492070763217
Validation loss: 2.5872428644609733

Epoch: 5| Step: 5
Training loss: 3.1587952275240494
Validation loss: 2.5802872635200305

Epoch: 5| Step: 6
Training loss: 2.758297107685308
Validation loss: 2.566676009794675

Epoch: 5| Step: 7
Training loss: 2.588509102097782
Validation loss: 2.581945662544238

Epoch: 5| Step: 8
Training loss: 3.1542058689464594
Validation loss: 2.5704296584186133

Epoch: 5| Step: 9
Training loss: 3.0936254611139247
Validation loss: 2.5685195930896554

Epoch: 5| Step: 10
Training loss: 2.7651514197444937
Validation loss: 2.5751816122124516

Epoch: 55| Step: 0
Training loss: 3.073985147870929
Validation loss: 2.565257371960324

Epoch: 5| Step: 1
Training loss: 2.468975877689581
Validation loss: 2.5886887610301623

Epoch: 5| Step: 2
Training loss: 3.154591039398688
Validation loss: 2.5700831077295585

Epoch: 5| Step: 3
Training loss: 2.7262705124647866
Validation loss: 2.561088065977225

Epoch: 5| Step: 4
Training loss: 2.8571425097329066
Validation loss: 2.5749703585285286

Epoch: 5| Step: 5
Training loss: 2.805178288524228
Validation loss: 2.5833518890630076

Epoch: 5| Step: 6
Training loss: 2.0751393604589374
Validation loss: 2.591367814429886

Epoch: 5| Step: 7
Training loss: 2.802478313379151
Validation loss: 2.5815586407618056

Epoch: 5| Step: 8
Training loss: 3.294912323544988
Validation loss: 2.5802730626917145

Epoch: 5| Step: 9
Training loss: 2.634734677415078
Validation loss: 2.579682575658716

Epoch: 5| Step: 10
Training loss: 3.6020860932697927
Validation loss: 2.585635885750313

Epoch: 56| Step: 0
Training loss: 3.245354045956459
Validation loss: 2.5885719714657633

Epoch: 5| Step: 1
Training loss: 2.5282746712759527
Validation loss: 2.5751725310777465

Epoch: 5| Step: 2
Training loss: 2.7551185482709917
Validation loss: 2.5784541969276167

Epoch: 5| Step: 3
Training loss: 2.404500449120473
Validation loss: 2.545999349898738

Epoch: 5| Step: 4
Training loss: 2.3445204422169983
Validation loss: 2.5679393287421672

Epoch: 5| Step: 5
Training loss: 3.229037981648136
Validation loss: 2.5702570955910633

Epoch: 5| Step: 6
Training loss: 3.393140150040936
Validation loss: 2.5754093409106447

Epoch: 5| Step: 7
Training loss: 3.055600237278855
Validation loss: 2.5571717341765643

Epoch: 5| Step: 8
Training loss: 2.5438464359683386
Validation loss: 2.5656697966941096

Epoch: 5| Step: 9
Training loss: 3.1653152058164524
Validation loss: 2.579965228381977

Epoch: 5| Step: 10
Training loss: 2.758225191268746
Validation loss: 2.56104868946836

Epoch: 57| Step: 0
Training loss: 2.5918682580128434
Validation loss: 2.5663935017209427

Epoch: 5| Step: 1
Training loss: 3.4121216728456116
Validation loss: 2.560878320557385

Epoch: 5| Step: 2
Training loss: 2.7913153602884564
Validation loss: 2.565347086812685

Epoch: 5| Step: 3
Training loss: 3.0895406427261385
Validation loss: 2.594998985210663

Epoch: 5| Step: 4
Training loss: 2.4783923010960804
Validation loss: 2.575638317539716

Epoch: 5| Step: 5
Training loss: 2.359821504696298
Validation loss: 2.5661354977857624

Epoch: 5| Step: 6
Training loss: 3.1401418437628252
Validation loss: 2.5566383598139177

Epoch: 5| Step: 7
Training loss: 2.5832685544495675
Validation loss: 2.559341334723384

Epoch: 5| Step: 8
Training loss: 3.2435873295856297
Validation loss: 2.5619647429715773

Epoch: 5| Step: 9
Training loss: 2.768589478396921
Validation loss: 2.581313687109206

Epoch: 5| Step: 10
Training loss: 2.8903105693641176
Validation loss: 2.566959525432388

Epoch: 58| Step: 0
Training loss: 3.641961110401276
Validation loss: 2.544536903172533

Epoch: 5| Step: 1
Training loss: 2.3549316198703387
Validation loss: 2.5578806058860692

Epoch: 5| Step: 2
Training loss: 2.3021897051186926
Validation loss: 2.586022359542888

Epoch: 5| Step: 3
Training loss: 2.929418281901189
Validation loss: 2.5684147923975513

Epoch: 5| Step: 4
Training loss: 2.45064210068044
Validation loss: 2.5669421578576266

Epoch: 5| Step: 5
Training loss: 2.6956463150961234
Validation loss: 2.5733464170124702

Epoch: 5| Step: 6
Training loss: 2.87695196479313
Validation loss: 2.557637116246486

Epoch: 5| Step: 7
Training loss: 2.1791130594208563
Validation loss: 2.5438269897478114

Epoch: 5| Step: 8
Training loss: 3.9303278922627105
Validation loss: 2.5501633199515923

Epoch: 5| Step: 9
Training loss: 2.786898160548621
Validation loss: 2.5708012604116757

Epoch: 5| Step: 10
Training loss: 3.0638999074916664
Validation loss: 2.5641390562990654

Epoch: 59| Step: 0
Training loss: 3.0006832298472013
Validation loss: 2.576215820813393

Epoch: 5| Step: 1
Training loss: 2.2396014782074434
Validation loss: 2.5836440138379313

Epoch: 5| Step: 2
Training loss: 3.305042581442624
Validation loss: 2.558988891439089

Epoch: 5| Step: 3
Training loss: 2.932318317479679
Validation loss: 2.5598570316940767

Epoch: 5| Step: 4
Training loss: 3.050405481619603
Validation loss: 2.570542822241

Epoch: 5| Step: 5
Training loss: 2.6193829338301278
Validation loss: 2.5780990380514743

Epoch: 5| Step: 6
Training loss: 2.7089387852711235
Validation loss: 2.5464072120932078

Epoch: 5| Step: 7
Training loss: 3.4629797152157282
Validation loss: 2.564684985032155

Epoch: 5| Step: 8
Training loss: 2.130265164413889
Validation loss: 2.5639940793860436

Epoch: 5| Step: 9
Training loss: 2.786924595311321
Validation loss: 2.571660831399524

Epoch: 5| Step: 10
Training loss: 3.052717505351661
Validation loss: 2.5650955229199703

Epoch: 60| Step: 0
Training loss: 3.0945754057929613
Validation loss: 2.5681369247996004

Epoch: 5| Step: 1
Training loss: 2.345986685023202
Validation loss: 2.577659850856918

Epoch: 5| Step: 2
Training loss: 2.51883800343387
Validation loss: 2.5687517886745277

Epoch: 5| Step: 3
Training loss: 2.3966341974484537
Validation loss: 2.5559010519206207

Epoch: 5| Step: 4
Training loss: 3.1179164712910836
Validation loss: 2.5745568127927263

Epoch: 5| Step: 5
Training loss: 3.1483684371302494
Validation loss: 2.5711304507993247

Epoch: 5| Step: 6
Training loss: 3.0592497101515757
Validation loss: 2.579417732232048

Epoch: 5| Step: 7
Training loss: 2.531571921140448
Validation loss: 2.5606001517399277

Epoch: 5| Step: 8
Training loss: 2.444437766306839
Validation loss: 2.54842147214002

Epoch: 5| Step: 9
Training loss: 2.7328546275430026
Validation loss: 2.563444686761785

Epoch: 5| Step: 10
Training loss: 3.8989451962670176
Validation loss: 2.5635140041228492

Epoch: 61| Step: 0
Training loss: 2.9701187993703293
Validation loss: 2.568622754683455

Epoch: 5| Step: 1
Training loss: 2.869573862957401
Validation loss: 2.5493757647256787

Epoch: 5| Step: 2
Training loss: 2.9013267573335866
Validation loss: 2.5476413965049294

Epoch: 5| Step: 3
Training loss: 3.044970264258304
Validation loss: 2.5667553056812604

Epoch: 5| Step: 4
Training loss: 3.023923534193518
Validation loss: 2.5604089638615775

Epoch: 5| Step: 5
Training loss: 2.8326045015186865
Validation loss: 2.5528515528208655

Epoch: 5| Step: 6
Training loss: 2.5500598489058466
Validation loss: 2.5551714193437634

Epoch: 5| Step: 7
Training loss: 2.5120757280889374
Validation loss: 2.5626190582077353

Epoch: 5| Step: 8
Training loss: 3.3783047355667217
Validation loss: 2.5584613579492044

Epoch: 5| Step: 9
Training loss: 2.942721818651116
Validation loss: 2.5725837609391182

Epoch: 5| Step: 10
Training loss: 2.377904521331153
Validation loss: 2.570223728490547

Epoch: 62| Step: 0
Training loss: 2.90587309987811
Validation loss: 2.5489000415191754

Epoch: 5| Step: 1
Training loss: 2.8240176560603727
Validation loss: 2.560239087090134

Epoch: 5| Step: 2
Training loss: 2.056026819981895
Validation loss: 2.57694115628329

Epoch: 5| Step: 3
Training loss: 2.2267593029115265
Validation loss: 2.5601521773013354

Epoch: 5| Step: 4
Training loss: 3.2128643556581853
Validation loss: 2.560663978644236

Epoch: 5| Step: 5
Training loss: 3.4101800207683834
Validation loss: 2.5750610919367434

Epoch: 5| Step: 6
Training loss: 2.625568873208049
Validation loss: 2.555102778664222

Epoch: 5| Step: 7
Training loss: 2.858685853386064
Validation loss: 2.5641530815339264

Epoch: 5| Step: 8
Training loss: 2.9339825287489196
Validation loss: 2.5447523657014584

Epoch: 5| Step: 9
Training loss: 3.149775142818513
Validation loss: 2.5477890366503093

Epoch: 5| Step: 10
Training loss: 2.9759177964045027
Validation loss: 2.5642956640680876

Epoch: 63| Step: 0
Training loss: 2.868830155725909
Validation loss: 2.573688399478704

Epoch: 5| Step: 1
Training loss: 2.497329429934347
Validation loss: 2.5838814005841413

Epoch: 5| Step: 2
Training loss: 2.7686741286790415
Validation loss: 2.5785991174330034

Epoch: 5| Step: 3
Training loss: 2.5951933004897225
Validation loss: 2.5544609407644248

Epoch: 5| Step: 4
Training loss: 2.3580202166634625
Validation loss: 2.5759516400625966

Epoch: 5| Step: 5
Training loss: 2.7146566861699273
Validation loss: 2.5732374741484882

Epoch: 5| Step: 6
Training loss: 3.597859562234945
Validation loss: 2.569563105765381

Epoch: 5| Step: 7
Training loss: 2.462702623735083
Validation loss: 2.5614056585260223

Epoch: 5| Step: 8
Training loss: 3.3189769257803383
Validation loss: 2.576591190069029

Epoch: 5| Step: 9
Training loss: 3.075950512868695
Validation loss: 2.5567819610214446

Epoch: 5| Step: 10
Training loss: 3.001736138567322
Validation loss: 2.5498348963589863

Epoch: 64| Step: 0
Training loss: 2.4668833761988744
Validation loss: 2.5579219163703013

Epoch: 5| Step: 1
Training loss: 2.0625727091602153
Validation loss: 2.5552178774011574

Epoch: 5| Step: 2
Training loss: 2.8990214702946737
Validation loss: 2.5496120023385442

Epoch: 5| Step: 3
Training loss: 2.601680077081005
Validation loss: 2.5434033697097904

Epoch: 5| Step: 4
Training loss: 3.2840362345082292
Validation loss: 2.5533302055468674

Epoch: 5| Step: 5
Training loss: 3.3885339714374916
Validation loss: 2.5603408100423746

Epoch: 5| Step: 6
Training loss: 2.3132378715511335
Validation loss: 2.5685533556126496

Epoch: 5| Step: 7
Training loss: 3.0001115778200846
Validation loss: 2.5536632001554413

Epoch: 5| Step: 8
Training loss: 3.214438356075183
Validation loss: 2.551930617651313

Epoch: 5| Step: 9
Training loss: 2.5643993874677213
Validation loss: 2.561359617974536

Epoch: 5| Step: 10
Training loss: 3.130405176524896
Validation loss: 2.553179317265132

Epoch: 65| Step: 0
Training loss: 2.6775618149062486
Validation loss: 2.570681652703403

Epoch: 5| Step: 1
Training loss: 3.203311226246183
Validation loss: 2.5644240900375723

Epoch: 5| Step: 2
Training loss: 2.9104675536097693
Validation loss: 2.5706287005890704

Epoch: 5| Step: 3
Training loss: 3.0604046251143635
Validation loss: 2.548209004009372

Epoch: 5| Step: 4
Training loss: 2.6411414008284226
Validation loss: 2.5676609673840822

Epoch: 5| Step: 5
Training loss: 2.743589559048158
Validation loss: 2.536514673421996

Epoch: 5| Step: 6
Training loss: 2.909810500119629
Validation loss: 2.5470705332870676

Epoch: 5| Step: 7
Training loss: 2.5459878698750757
Validation loss: 2.562050630679018

Epoch: 5| Step: 8
Training loss: 2.636259544793002
Validation loss: 2.5604274651171126

Epoch: 5| Step: 9
Training loss: 3.3339101451259787
Validation loss: 2.56633126579515

Epoch: 5| Step: 10
Training loss: 2.338224994200652
Validation loss: 2.576064109499641

Epoch: 66| Step: 0
Training loss: 2.7944889226432146
Validation loss: 2.556659396185926

Epoch: 5| Step: 1
Training loss: 2.986256909815513
Validation loss: 2.5689438375914517

Epoch: 5| Step: 2
Training loss: 2.1548276992564084
Validation loss: 2.5501908525453496

Epoch: 5| Step: 3
Training loss: 3.1183752411949177
Validation loss: 2.5660427034112057

Epoch: 5| Step: 4
Training loss: 2.3953486629575598
Validation loss: 2.540043505398684

Epoch: 5| Step: 5
Training loss: 3.1384995893326497
Validation loss: 2.5485113400697146

Epoch: 5| Step: 6
Training loss: 2.3769504167828144
Validation loss: 2.543652862051057

Epoch: 5| Step: 7
Training loss: 2.9406985461192634
Validation loss: 2.5635243306121294

Epoch: 5| Step: 8
Training loss: 3.193247232597058
Validation loss: 2.540926313237255

Epoch: 5| Step: 9
Training loss: 2.9258048816740057
Validation loss: 2.5499798569033483

Epoch: 5| Step: 10
Training loss: 3.0814513227761156
Validation loss: 2.544322553924213

Epoch: 67| Step: 0
Training loss: 2.590516338209248
Validation loss: 2.5666388445293005

Epoch: 5| Step: 1
Training loss: 2.333501355615667
Validation loss: 2.5685359978167366

Epoch: 5| Step: 2
Training loss: 2.9822695030555137
Validation loss: 2.5441104498589926

Epoch: 5| Step: 3
Training loss: 2.923403090453395
Validation loss: 2.5679904874491855

Epoch: 5| Step: 4
Training loss: 2.470158718276083
Validation loss: 2.5420687871953214

Epoch: 5| Step: 5
Training loss: 3.147471087916071
Validation loss: 2.5419423400830583

Epoch: 5| Step: 6
Training loss: 2.49767758262194
Validation loss: 2.568048426486524

Epoch: 5| Step: 7
Training loss: 2.4445070152751645
Validation loss: 2.550548599453443

Epoch: 5| Step: 8
Training loss: 3.5042260405733843
Validation loss: 2.5365128703429254

Epoch: 5| Step: 9
Training loss: 3.456370489907148
Validation loss: 2.5565708776062332

Epoch: 5| Step: 10
Training loss: 2.3516959219053906
Validation loss: 2.540372537875973

Epoch: 68| Step: 0
Training loss: 3.5984044989904196
Validation loss: 2.539540763849561

Epoch: 5| Step: 1
Training loss: 2.4948957789178996
Validation loss: 2.54769627943234

Epoch: 5| Step: 2
Training loss: 3.2572296133414236
Validation loss: 2.5659870759292613

Epoch: 5| Step: 3
Training loss: 2.464057131841856
Validation loss: 2.5434700391283376

Epoch: 5| Step: 4
Training loss: 2.946773743330961
Validation loss: 2.5557448531007965

Epoch: 5| Step: 5
Training loss: 2.7121021945907215
Validation loss: 2.5465724394678158

Epoch: 5| Step: 6
Training loss: 3.2152679274764933
Validation loss: 2.5592774948671955

Epoch: 5| Step: 7
Training loss: 2.549780750198823
Validation loss: 2.5433360791378687

Epoch: 5| Step: 8
Training loss: 2.476667817099686
Validation loss: 2.532899058861065

Epoch: 5| Step: 9
Training loss: 2.7015208517452813
Validation loss: 2.5348768625264397

Epoch: 5| Step: 10
Training loss: 2.4555127617207844
Validation loss: 2.5445312349276508

Epoch: 69| Step: 0
Training loss: 2.9914306002024578
Validation loss: 2.5447482997412454

Epoch: 5| Step: 1
Training loss: 2.8205259458974514
Validation loss: 2.553563074521138

Epoch: 5| Step: 2
Training loss: 2.7948365694965625
Validation loss: 2.58598302564359

Epoch: 5| Step: 3
Training loss: 2.458619979267559
Validation loss: 2.5532177176761435

Epoch: 5| Step: 4
Training loss: 2.6878713306898154
Validation loss: 2.5463761611732356

Epoch: 5| Step: 5
Training loss: 2.771721279350222
Validation loss: 2.5545522320279868

Epoch: 5| Step: 6
Training loss: 2.7491761620819997
Validation loss: 2.5789377710688934

Epoch: 5| Step: 7
Training loss: 2.638492603551153
Validation loss: 2.5575864992121025

Epoch: 5| Step: 8
Training loss: 3.220841996418569
Validation loss: 2.564940616150768

Epoch: 5| Step: 9
Training loss: 2.963152939834296
Validation loss: 2.5613596209772074

Epoch: 5| Step: 10
Training loss: 2.966117896712345
Validation loss: 2.5560307802858175

Epoch: 70| Step: 0
Training loss: 3.158804133879367
Validation loss: 2.5458830741286196

Epoch: 5| Step: 1
Training loss: 3.096915119115292
Validation loss: 2.5643493987753367

Epoch: 5| Step: 2
Training loss: 3.2627835848392674
Validation loss: 2.5874725624497565

Epoch: 5| Step: 3
Training loss: 3.2496475615506357
Validation loss: 2.5599263610778804

Epoch: 5| Step: 4
Training loss: 2.741668043358485
Validation loss: 2.565157869779481

Epoch: 5| Step: 5
Training loss: 2.82225616347895
Validation loss: 2.54499746783659

Epoch: 5| Step: 6
Training loss: 2.4227395760218755
Validation loss: 2.584239221005733

Epoch: 5| Step: 7
Training loss: 2.571871113919072
Validation loss: 2.5697025807590257

Epoch: 5| Step: 8
Training loss: 2.172818863869132
Validation loss: 2.5654311135044576

Epoch: 5| Step: 9
Training loss: 2.8519380505054626
Validation loss: 2.553013916988994

Epoch: 5| Step: 10
Training loss: 2.138357702023728
Validation loss: 2.5677140156443143

Epoch: 71| Step: 0
Training loss: 3.067199060279332
Validation loss: 2.564175292997857

Epoch: 5| Step: 1
Training loss: 2.7532487233102767
Validation loss: 2.5342094240552733

Epoch: 5| Step: 2
Training loss: 3.0068107224807474
Validation loss: 2.553389705653457

Epoch: 5| Step: 3
Training loss: 2.9555411975036994
Validation loss: 2.5378822823502354

Epoch: 5| Step: 4
Training loss: 3.3479065061524627
Validation loss: 2.553227510471719

Epoch: 5| Step: 5
Training loss: 2.8751898993096585
Validation loss: 2.538231411475745

Epoch: 5| Step: 6
Training loss: 2.856923871503817
Validation loss: 2.5515677047760903

Epoch: 5| Step: 7
Training loss: 2.345893185147313
Validation loss: 2.5518831870624332

Epoch: 5| Step: 8
Training loss: 2.497215436851478
Validation loss: 2.552502930941514

Epoch: 5| Step: 9
Training loss: 2.6136233529230686
Validation loss: 2.557219908784173

Epoch: 5| Step: 10
Training loss: 2.4775329036433105
Validation loss: 2.5348133471033925

Epoch: 72| Step: 0
Training loss: 3.1015648061133585
Validation loss: 2.5387440128164633

Epoch: 5| Step: 1
Training loss: 2.6241024844462446
Validation loss: 2.5545620969814107

Epoch: 5| Step: 2
Training loss: 3.3379573380090783
Validation loss: 2.5508046412251693

Epoch: 5| Step: 3
Training loss: 2.9562147013389604
Validation loss: 2.552642781706865

Epoch: 5| Step: 4
Training loss: 2.521066029635331
Validation loss: 2.552123105658157

Epoch: 5| Step: 5
Training loss: 3.2557022249023153
Validation loss: 2.560048785526717

Epoch: 5| Step: 6
Training loss: 2.117796525246222
Validation loss: 2.5639028023452877

Epoch: 5| Step: 7
Training loss: 2.7836892222161884
Validation loss: 2.55433842213113

Epoch: 5| Step: 8
Training loss: 3.0800480910671073
Validation loss: 2.5492603489192476

Epoch: 5| Step: 9
Training loss: 2.679924690270236
Validation loss: 2.5456163537627647

Epoch: 5| Step: 10
Training loss: 2.4423885719081935
Validation loss: 2.539582137201844

Epoch: 73| Step: 0
Training loss: 2.601715541611044
Validation loss: 2.5467567675599474

Epoch: 5| Step: 1
Training loss: 2.2191262799192
Validation loss: 2.55449196867912

Epoch: 5| Step: 2
Training loss: 3.734977896955626
Validation loss: 2.5402181772217136

Epoch: 5| Step: 3
Training loss: 2.887445794459592
Validation loss: 2.5764195822241

Epoch: 5| Step: 4
Training loss: 2.881425560093791
Validation loss: 2.5470808962471594

Epoch: 5| Step: 5
Training loss: 2.491656590657184
Validation loss: 2.5251962474811602

Epoch: 5| Step: 6
Training loss: 2.9140800086919554
Validation loss: 2.551980720015792

Epoch: 5| Step: 7
Training loss: 2.85606017034923
Validation loss: 2.549818689027899

Epoch: 5| Step: 8
Training loss: 3.2338520309106147
Validation loss: 2.539701650993826

Epoch: 5| Step: 9
Training loss: 2.4944948618475227
Validation loss: 2.5388970454146698

Epoch: 5| Step: 10
Training loss: 2.3033406088125736
Validation loss: 2.537395921471362

Epoch: 74| Step: 0
Training loss: 2.847278794964568
Validation loss: 2.550955928246255

Epoch: 5| Step: 1
Training loss: 2.473634740178878
Validation loss: 2.5457419477042182

Epoch: 5| Step: 2
Training loss: 2.528521538981961
Validation loss: 2.5515284973370234

Epoch: 5| Step: 3
Training loss: 3.2093753030956984
Validation loss: 2.546208410995136

Epoch: 5| Step: 4
Training loss: 2.540444523218194
Validation loss: 2.5850391022577464

Epoch: 5| Step: 5
Training loss: 2.80597914172337
Validation loss: 2.554714488109924

Epoch: 5| Step: 6
Training loss: 3.0552147607814857
Validation loss: 2.5696146322122217

Epoch: 5| Step: 7
Training loss: 2.921118653674098
Validation loss: 2.566115993692399

Epoch: 5| Step: 8
Training loss: 3.1819575873712695
Validation loss: 2.5490505957653635

Epoch: 5| Step: 9
Training loss: 2.580564697034084
Validation loss: 2.549462560212694

Epoch: 5| Step: 10
Training loss: 2.5701797590213142
Validation loss: 2.5640273285864312

Epoch: 75| Step: 0
Training loss: 2.328209894667822
Validation loss: 2.550504436541273

Epoch: 5| Step: 1
Training loss: 2.472687297704464
Validation loss: 2.542707123024123

Epoch: 5| Step: 2
Training loss: 2.8106773404504444
Validation loss: 2.5441132159298285

Epoch: 5| Step: 3
Training loss: 3.1283219038263885
Validation loss: 2.557118191511831

Epoch: 5| Step: 4
Training loss: 2.990306452225701
Validation loss: 2.5351130415505962

Epoch: 5| Step: 5
Training loss: 2.8061902793867626
Validation loss: 2.550014089086587

Epoch: 5| Step: 6
Training loss: 3.159607263134293
Validation loss: 2.550476798775258

Epoch: 5| Step: 7
Training loss: 2.6964779310661995
Validation loss: 2.513999757905577

Epoch: 5| Step: 8
Training loss: 2.955260458374364
Validation loss: 2.537892662625742

Epoch: 5| Step: 9
Training loss: 2.6404448679141903
Validation loss: 2.556097866545446

Epoch: 5| Step: 10
Training loss: 2.8536598331010303
Validation loss: 2.5470782954460645

Epoch: 76| Step: 0
Training loss: 2.772536268349607
Validation loss: 2.5448786570743263

Epoch: 5| Step: 1
Training loss: 3.1578191501371866
Validation loss: 2.5448252839077434

Epoch: 5| Step: 2
Training loss: 2.4665388031201463
Validation loss: 2.5220632404545733

Epoch: 5| Step: 3
Training loss: 2.444739521403998
Validation loss: 2.539470808015236

Epoch: 5| Step: 4
Training loss: 3.1591350098270476
Validation loss: 2.541411044215619

Epoch: 5| Step: 5
Training loss: 2.936073118998814
Validation loss: 2.5373336239571675

Epoch: 5| Step: 6
Training loss: 2.1727010130428983
Validation loss: 2.552860404056012

Epoch: 5| Step: 7
Training loss: 2.9910022589325225
Validation loss: 2.5500728165687394

Epoch: 5| Step: 8
Training loss: 2.4873081382484896
Validation loss: 2.5282710401816684

Epoch: 5| Step: 9
Training loss: 3.3049236961709427
Validation loss: 2.534376480459992

Epoch: 5| Step: 10
Training loss: 2.661942698577765
Validation loss: 2.5264456003661735

Epoch: 77| Step: 0
Training loss: 2.7515883627027553
Validation loss: 2.5494509117651236

Epoch: 5| Step: 1
Training loss: 2.9886377059664517
Validation loss: 2.5508513828314685

Epoch: 5| Step: 2
Training loss: 2.6114457188836573
Validation loss: 2.542501191208425

Epoch: 5| Step: 3
Training loss: 2.807036794629926
Validation loss: 2.527696812465277

Epoch: 5| Step: 4
Training loss: 2.879334540839478
Validation loss: 2.527782328019826

Epoch: 5| Step: 5
Training loss: 3.1376567117529133
Validation loss: 2.5426581627696425

Epoch: 5| Step: 6
Training loss: 3.1027055070733103
Validation loss: 2.5508726287330155

Epoch: 5| Step: 7
Training loss: 2.1445265806387006
Validation loss: 2.545398715366426

Epoch: 5| Step: 8
Training loss: 2.505716559130527
Validation loss: 2.5666703155304127

Epoch: 5| Step: 9
Training loss: 2.3979259032318194
Validation loss: 2.537253460095694

Epoch: 5| Step: 10
Training loss: 3.4628431184611483
Validation loss: 2.5548027639510966

Epoch: 78| Step: 0
Training loss: 2.7379320822652207
Validation loss: 2.5140451810510953

Epoch: 5| Step: 1
Training loss: 2.7577449801125002
Validation loss: 2.540138112467473

Epoch: 5| Step: 2
Training loss: 2.9567409760929397
Validation loss: 2.5493133104504873

Epoch: 5| Step: 3
Training loss: 2.345740934983575
Validation loss: 2.542594181306069

Epoch: 5| Step: 4
Training loss: 3.1870010583862043
Validation loss: 2.5420315909361895

Epoch: 5| Step: 5
Training loss: 2.397989734516331
Validation loss: 2.533601291417311

Epoch: 5| Step: 6
Training loss: 3.0640321908061585
Validation loss: 2.5507252062684698

Epoch: 5| Step: 7
Training loss: 3.2649709238156803
Validation loss: 2.5364929828213083

Epoch: 5| Step: 8
Training loss: 2.734278998733271
Validation loss: 2.5360377284867526

Epoch: 5| Step: 9
Training loss: 2.7031093001598805
Validation loss: 2.5414722491997113

Epoch: 5| Step: 10
Training loss: 2.632368101201074
Validation loss: 2.528258298355776

Epoch: 79| Step: 0
Training loss: 3.114507225578183
Validation loss: 2.537632093351166

Epoch: 5| Step: 1
Training loss: 2.623021697309125
Validation loss: 2.558461106942087

Epoch: 5| Step: 2
Training loss: 2.760793830488414
Validation loss: 2.530192536249054

Epoch: 5| Step: 3
Training loss: 2.5990230779030523
Validation loss: 2.5378919686557477

Epoch: 5| Step: 4
Training loss: 3.220522198242098
Validation loss: 2.548442373134475

Epoch: 5| Step: 5
Training loss: 2.3924240623229682
Validation loss: 2.54657724546063

Epoch: 5| Step: 6
Training loss: 3.0824282237016423
Validation loss: 2.552553344466755

Epoch: 5| Step: 7
Training loss: 2.3916589832071726
Validation loss: 2.5442590999875363

Epoch: 5| Step: 8
Training loss: 3.1608932635332225
Validation loss: 2.521687502156181

Epoch: 5| Step: 9
Training loss: 2.535144964583895
Validation loss: 2.5372402379681867

Epoch: 5| Step: 10
Training loss: 2.777982957467738
Validation loss: 2.538788196522792

Epoch: 80| Step: 0
Training loss: 3.0633917308245735
Validation loss: 2.550421126302559

Epoch: 5| Step: 1
Training loss: 2.5228168680962897
Validation loss: 2.5519088300388013

Epoch: 5| Step: 2
Training loss: 3.3519467575924984
Validation loss: 2.5394809990755958

Epoch: 5| Step: 3
Training loss: 2.741350181965068
Validation loss: 2.5435093380289095

Epoch: 5| Step: 4
Training loss: 1.825227838168256
Validation loss: 2.5383552195958465

Epoch: 5| Step: 5
Training loss: 3.1394930645361376
Validation loss: 2.5479016132664847

Epoch: 5| Step: 6
Training loss: 2.583377089181137
Validation loss: 2.5594628315982084

Epoch: 5| Step: 7
Training loss: 2.4095513621894034
Validation loss: 2.5775418802623387

Epoch: 5| Step: 8
Training loss: 2.881340333263127
Validation loss: 2.5187896652109165

Epoch: 5| Step: 9
Training loss: 2.894949322983323
Validation loss: 2.5388846032964

Epoch: 5| Step: 10
Training loss: 3.089490790769968
Validation loss: 2.559841707031042

Epoch: 81| Step: 0
Training loss: 2.5223198178137882
Validation loss: 2.5500090161171594

Epoch: 5| Step: 1
Training loss: 2.905422133799791
Validation loss: 2.5597980259301094

Epoch: 5| Step: 2
Training loss: 3.1920872012013146
Validation loss: 2.549579116169473

Epoch: 5| Step: 3
Training loss: 3.103517161441564
Validation loss: 2.5265529607757036

Epoch: 5| Step: 4
Training loss: 2.973130217173315
Validation loss: 2.5358771181524227

Epoch: 5| Step: 5
Training loss: 2.556636894812023
Validation loss: 2.554904137420785

Epoch: 5| Step: 6
Training loss: 3.3174933459194347
Validation loss: 2.528034295978755

Epoch: 5| Step: 7
Training loss: 2.632615260311632
Validation loss: 2.5431994901868555

Epoch: 5| Step: 8
Training loss: 2.3108227807716673
Validation loss: 2.5361050413657558

Epoch: 5| Step: 9
Training loss: 2.456197673055806
Validation loss: 2.544310930812963

Epoch: 5| Step: 10
Training loss: 2.4673939131142286
Validation loss: 2.5601583166480624

Epoch: 82| Step: 0
Training loss: 2.8867436925406698
Validation loss: 2.543505604709853

Epoch: 5| Step: 1
Training loss: 2.8227792028386696
Validation loss: 2.5717107138599418

Epoch: 5| Step: 2
Training loss: 2.635176777130619
Validation loss: 2.537738494600735

Epoch: 5| Step: 3
Training loss: 2.4775834250622744
Validation loss: 2.567499355731416

Epoch: 5| Step: 4
Training loss: 3.042048147308322
Validation loss: 2.561644074290225

Epoch: 5| Step: 5
Training loss: 2.643720449007421
Validation loss: 2.533021419209835

Epoch: 5| Step: 6
Training loss: 2.873768086420052
Validation loss: 2.5501670193972794

Epoch: 5| Step: 7
Training loss: 2.4100747365166297
Validation loss: 2.532022900801779

Epoch: 5| Step: 8
Training loss: 2.340367635881496
Validation loss: 2.532631405355461

Epoch: 5| Step: 9
Training loss: 2.9709409960855298
Validation loss: 2.555152439572132

Epoch: 5| Step: 10
Training loss: 3.432484522463028
Validation loss: 2.5506695362024083

Epoch: 83| Step: 0
Training loss: 3.126694029367711
Validation loss: 2.5628000979573566

Epoch: 5| Step: 1
Training loss: 2.95637809362996
Validation loss: 2.5377388734282498

Epoch: 5| Step: 2
Training loss: 2.98653138231809
Validation loss: 2.5554768772536294

Epoch: 5| Step: 3
Training loss: 3.841773540695532
Validation loss: 2.545700994451905

Epoch: 5| Step: 4
Training loss: 2.5499376476368862
Validation loss: 2.5528459743377474

Epoch: 5| Step: 5
Training loss: 2.7896749214101586
Validation loss: 2.546674710326379

Epoch: 5| Step: 6
Training loss: 1.8662368716719064
Validation loss: 2.537657891952269

Epoch: 5| Step: 7
Training loss: 2.643849136982811
Validation loss: 2.5428081156946405

Epoch: 5| Step: 8
Training loss: 2.5149193952926874
Validation loss: 2.547400508849345

Epoch: 5| Step: 9
Training loss: 2.318810795812134
Validation loss: 2.5402728440975575

Epoch: 5| Step: 10
Training loss: 2.5882417951594014
Validation loss: 2.5563162387417657

Epoch: 84| Step: 0
Training loss: 2.308527860007786
Validation loss: 2.5569546030889154

Epoch: 5| Step: 1
Training loss: 2.891328963056162
Validation loss: 2.5443202777714595

Epoch: 5| Step: 2
Training loss: 2.5522977051261164
Validation loss: 2.5414774067934145

Epoch: 5| Step: 3
Training loss: 3.4667111840201867
Validation loss: 2.5379178883567373

Epoch: 5| Step: 4
Training loss: 2.64359608375766
Validation loss: 2.539100667636645

Epoch: 5| Step: 5
Training loss: 2.458742549479628
Validation loss: 2.5698207815383602

Epoch: 5| Step: 6
Training loss: 2.4315532622672347
Validation loss: 2.5547984370308594

Epoch: 5| Step: 7
Training loss: 3.3588064732859784
Validation loss: 2.534461141474068

Epoch: 5| Step: 8
Training loss: 2.9334277881962616
Validation loss: 2.552585801632778

Epoch: 5| Step: 9
Training loss: 2.4562701818981423
Validation loss: 2.5688483004414993

Epoch: 5| Step: 10
Training loss: 2.8142317632575824
Validation loss: 2.5114685208509497

Epoch: 85| Step: 0
Training loss: 2.6712447644522896
Validation loss: 2.52495804330168

Epoch: 5| Step: 1
Training loss: 2.3408126735443253
Validation loss: 2.5436730080428696

Epoch: 5| Step: 2
Training loss: 2.5119187437084616
Validation loss: 2.5523962733502588

Epoch: 5| Step: 3
Training loss: 2.8105749535765154
Validation loss: 2.5603742248349204

Epoch: 5| Step: 4
Training loss: 3.0873521097570946
Validation loss: 2.5335795040320206

Epoch: 5| Step: 5
Training loss: 2.7784080129501825
Validation loss: 2.5467911140321267

Epoch: 5| Step: 6
Training loss: 2.4945307033023303
Validation loss: 2.5392568155780673

Epoch: 5| Step: 7
Training loss: 2.959491144980711
Validation loss: 2.5194370810216267

Epoch: 5| Step: 8
Training loss: 2.820358487332827
Validation loss: 2.5349087551599894

Epoch: 5| Step: 9
Training loss: 3.354497304854175
Validation loss: 2.5170049299725648

Epoch: 5| Step: 10
Training loss: 2.490833261319063
Validation loss: 2.5493215223307715

Epoch: 86| Step: 0
Training loss: 3.0320825121781794
Validation loss: 2.5450689677976412

Epoch: 5| Step: 1
Training loss: 2.92836005082713
Validation loss: 2.5459162708573606

Epoch: 5| Step: 2
Training loss: 2.5907896682071505
Validation loss: 2.5301056542174827

Epoch: 5| Step: 3
Training loss: 2.592924974973685
Validation loss: 2.5436428993561915

Epoch: 5| Step: 4
Training loss: 2.7757841256768545
Validation loss: 2.5469865188829677

Epoch: 5| Step: 5
Training loss: 3.0319491494476662
Validation loss: 2.5310078308457813

Epoch: 5| Step: 6
Training loss: 2.2703560727185352
Validation loss: 2.5400531097846377

Epoch: 5| Step: 7
Training loss: 3.2079208571263003
Validation loss: 2.521822195835408

Epoch: 5| Step: 8
Training loss: 2.6509466747560015
Validation loss: 2.533948892856105

Epoch: 5| Step: 9
Training loss: 2.462079851741226
Validation loss: 2.56279534389424

Epoch: 5| Step: 10
Training loss: 2.7687053874880005
Validation loss: 2.510220029047793

Epoch: 87| Step: 0
Training loss: 2.887244645094177
Validation loss: 2.557611587335917

Epoch: 5| Step: 1
Training loss: 2.928676583399295
Validation loss: 2.5313969423501343

Epoch: 5| Step: 2
Training loss: 2.8073681105548665
Validation loss: 2.5263871050085434

Epoch: 5| Step: 3
Training loss: 3.2042570765273477
Validation loss: 2.535376631163273

Epoch: 5| Step: 4
Training loss: 3.2516193757039162
Validation loss: 2.5493606003013918

Epoch: 5| Step: 5
Training loss: 2.77625640744737
Validation loss: 2.5288118190702162

Epoch: 5| Step: 6
Training loss: 1.9483473670504088
Validation loss: 2.536935859405342

Epoch: 5| Step: 7
Training loss: 2.5984172882193195
Validation loss: 2.5464080562678184

Epoch: 5| Step: 8
Training loss: 2.464459614511635
Validation loss: 2.5231002104205977

Epoch: 5| Step: 9
Training loss: 2.861765711526871
Validation loss: 2.540286907245716

Epoch: 5| Step: 10
Training loss: 2.4517322644401003
Validation loss: 2.528502577155375

Epoch: 88| Step: 0
Training loss: 2.482056501558478
Validation loss: 2.518967807628503

Epoch: 5| Step: 1
Training loss: 2.963928483458012
Validation loss: 2.5492849900207055

Epoch: 5| Step: 2
Training loss: 2.7755603671263396
Validation loss: 2.5417623155598377

Epoch: 5| Step: 3
Training loss: 3.006765842395056
Validation loss: 2.55244261418657

Epoch: 5| Step: 4
Training loss: 2.33869347932699
Validation loss: 2.5396765807683304

Epoch: 5| Step: 5
Training loss: 2.821397567357933
Validation loss: 2.5348040465043717

Epoch: 5| Step: 6
Training loss: 2.5032211532888877
Validation loss: 2.53407863523189

Epoch: 5| Step: 7
Training loss: 2.5952830552389274
Validation loss: 2.5333642195770927

Epoch: 5| Step: 8
Training loss: 2.856802194586055
Validation loss: 2.5586963980219917

Epoch: 5| Step: 9
Training loss: 2.808634666176667
Validation loss: 2.554761888712306

Epoch: 5| Step: 10
Training loss: 3.2054806862705805
Validation loss: 2.5341162739776575

Epoch: 89| Step: 0
Training loss: 2.7298462776249672
Validation loss: 2.538914113090607

Epoch: 5| Step: 1
Training loss: 3.012597179823964
Validation loss: 2.540926050913001

Epoch: 5| Step: 2
Training loss: 2.9385054470581022
Validation loss: 2.5430238970847148

Epoch: 5| Step: 3
Training loss: 2.305230235188091
Validation loss: 2.5435547542630834

Epoch: 5| Step: 4
Training loss: 2.49409215965172
Validation loss: 2.5443673601660333

Epoch: 5| Step: 5
Training loss: 2.7089674769660426
Validation loss: 2.5299878515340724

Epoch: 5| Step: 6
Training loss: 2.4853099287401825
Validation loss: 2.522999786386699

Epoch: 5| Step: 7
Training loss: 2.841297811096678
Validation loss: 2.5277451051029893

Epoch: 5| Step: 8
Training loss: 3.0164790550047296
Validation loss: 2.534081039960305

Epoch: 5| Step: 9
Training loss: 2.786762389709467
Validation loss: 2.528001364888169

Epoch: 5| Step: 10
Training loss: 3.0987000600861534
Validation loss: 2.523735196201517

Epoch: 90| Step: 0
Training loss: 2.1325292154616227
Validation loss: 2.5446317653109456

Epoch: 5| Step: 1
Training loss: 3.216075786285946
Validation loss: 2.553017178506454

Epoch: 5| Step: 2
Training loss: 2.40287683046342
Validation loss: 2.5415587224956577

Epoch: 5| Step: 3
Training loss: 2.7123732928377886
Validation loss: 2.540340385856415

Epoch: 5| Step: 4
Training loss: 3.358602177639752
Validation loss: 2.5123999571081903

Epoch: 5| Step: 5
Training loss: 2.9406458465777745
Validation loss: 2.514971756874495

Epoch: 5| Step: 6
Training loss: 2.5532494093280684
Validation loss: 2.521736092358332

Epoch: 5| Step: 7
Training loss: 2.397831147428519
Validation loss: 2.536461326400434

Epoch: 5| Step: 8
Training loss: 2.697248918728811
Validation loss: 2.5282601042797768

Epoch: 5| Step: 9
Training loss: 2.881716967162634
Validation loss: 2.545698576530828

Epoch: 5| Step: 10
Training loss: 2.8304587161596753
Validation loss: 2.54422433139562

Epoch: 91| Step: 0
Training loss: 2.696160136190072
Validation loss: 2.5377289925779642

Epoch: 5| Step: 1
Training loss: 2.691350706548827
Validation loss: 2.514543138022316

Epoch: 5| Step: 2
Training loss: 2.7290089297150266
Validation loss: 2.5350549676601424

Epoch: 5| Step: 3
Training loss: 3.196007091137177
Validation loss: 2.535264131390743

Epoch: 5| Step: 4
Training loss: 2.3756815283838444
Validation loss: 2.5337964497480328

Epoch: 5| Step: 5
Training loss: 3.4202930155373807
Validation loss: 2.5408220836251107

Epoch: 5| Step: 6
Training loss: 2.526083677801157
Validation loss: 2.5434156818718883

Epoch: 5| Step: 7
Training loss: 3.0461661272238576
Validation loss: 2.5390642083779924

Epoch: 5| Step: 8
Training loss: 2.457501728759654
Validation loss: 2.5483027586436116

Epoch: 5| Step: 9
Training loss: 2.656114552354298
Validation loss: 2.5247357474576675

Epoch: 5| Step: 10
Training loss: 2.2246412052225133
Validation loss: 2.5381588856183153

Epoch: 92| Step: 0
Training loss: 2.806692952495845
Validation loss: 2.5337431578050507

Epoch: 5| Step: 1
Training loss: 2.6878332774194478
Validation loss: 2.5587826459088636

Epoch: 5| Step: 2
Training loss: 2.451808308810927
Validation loss: 2.5523740919647144

Epoch: 5| Step: 3
Training loss: 3.3130776243595226
Validation loss: 2.552690984038618

Epoch: 5| Step: 4
Training loss: 2.679862147387026
Validation loss: 2.542822367467019

Epoch: 5| Step: 5
Training loss: 2.4293481522340894
Validation loss: 2.529443804629361

Epoch: 5| Step: 6
Training loss: 2.6127939268797298
Validation loss: 2.5308426529608283

Epoch: 5| Step: 7
Training loss: 2.5123345315829226
Validation loss: 2.5306449409041436

Epoch: 5| Step: 8
Training loss: 2.8187353738544885
Validation loss: 2.54473374846668

Epoch: 5| Step: 9
Training loss: 2.5844589570325813
Validation loss: 2.5291266245906634

Epoch: 5| Step: 10
Training loss: 3.422584077012746
Validation loss: 2.5241682464540824

Epoch: 93| Step: 0
Training loss: 2.129660712428399
Validation loss: 2.5533651940244937

Epoch: 5| Step: 1
Training loss: 2.864788995931627
Validation loss: 2.53359152192511

Epoch: 5| Step: 2
Training loss: 2.8157592538205525
Validation loss: 2.5388099836388216

Epoch: 5| Step: 3
Training loss: 2.3819488461092018
Validation loss: 2.547439200661898

Epoch: 5| Step: 4
Training loss: 2.325188442510063
Validation loss: 2.5346673371115385

Epoch: 5| Step: 5
Training loss: 3.456953731034123
Validation loss: 2.542802067539309

Epoch: 5| Step: 6
Training loss: 2.937556002468576
Validation loss: 2.5399215418795533

Epoch: 5| Step: 7
Training loss: 2.3664675584056867
Validation loss: 2.5428500783458685

Epoch: 5| Step: 8
Training loss: 3.2164332375958966
Validation loss: 2.530148315920217

Epoch: 5| Step: 9
Training loss: 2.8034783522312856
Validation loss: 2.5489450871297206

Epoch: 5| Step: 10
Training loss: 2.7060871101675463
Validation loss: 2.5289047042970343

Epoch: 94| Step: 0
Training loss: 2.4813203085827915
Validation loss: 2.526329192803525

Epoch: 5| Step: 1
Training loss: 2.940084740591732
Validation loss: 2.5140703019089075

Epoch: 5| Step: 2
Training loss: 3.060793965875208
Validation loss: 2.5101629081378793

Epoch: 5| Step: 3
Training loss: 2.578634223354531
Validation loss: 2.542295992958368

Epoch: 5| Step: 4
Training loss: 2.794680453682639
Validation loss: 2.5455342773915675

Epoch: 5| Step: 5
Training loss: 2.7723052816576734
Validation loss: 2.5562046334528628

Epoch: 5| Step: 6
Training loss: 2.9329469173399785
Validation loss: 2.54675648922686

Epoch: 5| Step: 7
Training loss: 2.4207780876574825
Validation loss: 2.547216364721393

Epoch: 5| Step: 8
Training loss: 3.192497076333424
Validation loss: 2.55285304309224

Epoch: 5| Step: 9
Training loss: 2.304672499785666
Validation loss: 2.5494564685156567

Epoch: 5| Step: 10
Training loss: 2.434216464050344
Validation loss: 2.526153803168359

Epoch: 95| Step: 0
Training loss: 2.4404203087304777
Validation loss: 2.543341576169587

Epoch: 5| Step: 1
Training loss: 2.748539883786905
Validation loss: 2.5461757476833102

Epoch: 5| Step: 2
Training loss: 2.802512002556831
Validation loss: 2.5273872626981295

Epoch: 5| Step: 3
Training loss: 2.6217023026489104
Validation loss: 2.5485723202180988

Epoch: 5| Step: 4
Training loss: 2.2811062911244337
Validation loss: 2.5475223397275895

Epoch: 5| Step: 5
Training loss: 2.668800503612489
Validation loss: 2.5273554374481773

Epoch: 5| Step: 6
Training loss: 3.1703780827852657
Validation loss: 2.5323783813466365

Epoch: 5| Step: 7
Training loss: 2.9999419842514476
Validation loss: 2.5347924277872727

Epoch: 5| Step: 8
Training loss: 2.776299861235207
Validation loss: 2.5267319123870187

Epoch: 5| Step: 9
Training loss: 3.200603106408381
Validation loss: 2.547600801839219

Epoch: 5| Step: 10
Training loss: 2.242028420151622
Validation loss: 2.533957554155484

Epoch: 96| Step: 0
Training loss: 2.767404877941312
Validation loss: 2.5258518439873954

Epoch: 5| Step: 1
Training loss: 2.954430347147731
Validation loss: 2.5424443861722086

Epoch: 5| Step: 2
Training loss: 2.445211097637936
Validation loss: 2.52831801433623

Epoch: 5| Step: 3
Training loss: 2.5523250750794646
Validation loss: 2.5307785439798414

Epoch: 5| Step: 4
Training loss: 2.928110741058448
Validation loss: 2.5390184079010587

Epoch: 5| Step: 5
Training loss: 2.879925696156215
Validation loss: 2.5304108472816123

Epoch: 5| Step: 6
Training loss: 2.0949737616377644
Validation loss: 2.5189511940744858

Epoch: 5| Step: 7
Training loss: 3.026938291900519
Validation loss: 2.5429593622850852

Epoch: 5| Step: 8
Training loss: 2.834881714736587
Validation loss: 2.5237235112884

Epoch: 5| Step: 9
Training loss: 2.3572451850015805
Validation loss: 2.559862047091252

Epoch: 5| Step: 10
Training loss: 3.2760184589932564
Validation loss: 2.5476657413211363

Epoch: 97| Step: 0
Training loss: 2.9912745425105793
Validation loss: 2.5217827612703547

Epoch: 5| Step: 1
Training loss: 2.5681965475358193
Validation loss: 2.5588901834324327

Epoch: 5| Step: 2
Training loss: 2.8733942274410422
Validation loss: 2.5439228075052474

Epoch: 5| Step: 3
Training loss: 2.7489648084334166
Validation loss: 2.5369598431253118

Epoch: 5| Step: 4
Training loss: 2.8254438304809533
Validation loss: 2.5376354231301406

Epoch: 5| Step: 5
Training loss: 3.1466180357434888
Validation loss: 2.5369716479555335

Epoch: 5| Step: 6
Training loss: 3.080776873122715
Validation loss: 2.536518463522365

Epoch: 5| Step: 7
Training loss: 2.7333019657971325
Validation loss: 2.5340003118685677

Epoch: 5| Step: 8
Training loss: 2.2452871980880738
Validation loss: 2.520744008578607

Epoch: 5| Step: 9
Training loss: 2.4915337258111214
Validation loss: 2.5107305503513593

Epoch: 5| Step: 10
Training loss: 2.26595509196239
Validation loss: 2.5222092594475995

Epoch: 98| Step: 0
Training loss: 2.341266893447075
Validation loss: 2.5342381486597207

Epoch: 5| Step: 1
Training loss: 2.935255613617483
Validation loss: 2.5366906721285174

Epoch: 5| Step: 2
Training loss: 3.055799511119904
Validation loss: 2.51963578751605

Epoch: 5| Step: 3
Training loss: 2.544676223574368
Validation loss: 2.5338511853590013

Epoch: 5| Step: 4
Training loss: 2.964918052737418
Validation loss: 2.5206753671025153

Epoch: 5| Step: 5
Training loss: 3.214102936649343
Validation loss: 2.5423611355017135

Epoch: 5| Step: 6
Training loss: 2.7759793520882345
Validation loss: 2.539534871198073

Epoch: 5| Step: 7
Training loss: 2.1119546445903814
Validation loss: 2.538283292160117

Epoch: 5| Step: 8
Training loss: 2.946824715145852
Validation loss: 2.5525833274625613

Epoch: 5| Step: 9
Training loss: 2.4941232272910248
Validation loss: 2.5254056420127307

Epoch: 5| Step: 10
Training loss: 2.4797619871551086
Validation loss: 2.562262528343636

Epoch: 99| Step: 0
Training loss: 2.7490537922946667
Validation loss: 2.5191540385388764

Epoch: 5| Step: 1
Training loss: 3.228062758902782
Validation loss: 2.540183597050051

Epoch: 5| Step: 2
Training loss: 2.8702728551162835
Validation loss: 2.537700465081519

Epoch: 5| Step: 3
Training loss: 2.72194694134911
Validation loss: 2.5397904779105955

Epoch: 5| Step: 4
Training loss: 2.0134253512863687
Validation loss: 2.540208753101819

Epoch: 5| Step: 5
Training loss: 2.58758280524843
Validation loss: 2.5318175884345955

Epoch: 5| Step: 6
Training loss: 2.857514656943764
Validation loss: 2.529771307830142

Epoch: 5| Step: 7
Training loss: 2.7254508739152663
Validation loss: 2.5529808035142554

Epoch: 5| Step: 8
Training loss: 2.8607507949984012
Validation loss: 2.525728350686646

Epoch: 5| Step: 9
Training loss: 2.5546145180826274
Validation loss: 2.5141719697332143

Epoch: 5| Step: 10
Training loss: 2.708228701013075
Validation loss: 2.527939718652109

Epoch: 100| Step: 0
Training loss: 3.028448954005433
Validation loss: 2.524573641267222

Epoch: 5| Step: 1
Training loss: 2.4897164557922897
Validation loss: 2.548030794094848

Epoch: 5| Step: 2
Training loss: 2.969419704992781
Validation loss: 2.5186850732376036

Epoch: 5| Step: 3
Training loss: 2.7759748859973477
Validation loss: 2.5392932367356704

Epoch: 5| Step: 4
Training loss: 2.6267040716047854
Validation loss: 2.543901860307681

Epoch: 5| Step: 5
Training loss: 2.800715702412465
Validation loss: 2.5515982338646865

Epoch: 5| Step: 6
Training loss: 3.1621796457023654
Validation loss: 2.545485223466548

Epoch: 5| Step: 7
Training loss: 2.176457572209748
Validation loss: 2.549832368746017

Epoch: 5| Step: 8
Training loss: 2.3398514940136876
Validation loss: 2.524641896491293

Epoch: 5| Step: 9
Training loss: 2.994012898347907
Validation loss: 2.5274462156960364

Epoch: 5| Step: 10
Training loss: 2.3491993940423086
Validation loss: 2.559464815330204

Epoch: 101| Step: 0
Training loss: 2.7157219872752827
Validation loss: 2.523497537812851

Epoch: 5| Step: 1
Training loss: 2.9182079783962935
Validation loss: 2.5120804602673097

Epoch: 5| Step: 2
Training loss: 3.5613513901839613
Validation loss: 2.525431680223073

Epoch: 5| Step: 3
Training loss: 2.6500424723550458
Validation loss: 2.5333951152668504

Epoch: 5| Step: 4
Training loss: 2.6069943652631693
Validation loss: 2.5257055037133993

Epoch: 5| Step: 5
Training loss: 2.1452819955411613
Validation loss: 2.5513174595849533

Epoch: 5| Step: 6
Training loss: 2.47168971933464
Validation loss: 2.5454332105896205

Epoch: 5| Step: 7
Training loss: 2.5173305629469827
Validation loss: 2.5389877795512037

Epoch: 5| Step: 8
Training loss: 3.1836278995484384
Validation loss: 2.5551648526416653

Epoch: 5| Step: 9
Training loss: 2.396714277983871
Validation loss: 2.524226182846375

Epoch: 5| Step: 10
Training loss: 2.863664921429629
Validation loss: 2.5468236748311166

Epoch: 102| Step: 0
Training loss: 3.215268372388522
Validation loss: 2.5415432532042783

Epoch: 5| Step: 1
Training loss: 2.647681654478713
Validation loss: 2.5404878387763623

Epoch: 5| Step: 2
Training loss: 2.7639066886222197
Validation loss: 2.5332745145981446

Epoch: 5| Step: 3
Training loss: 2.4540604672556503
Validation loss: 2.5282398628500533

Epoch: 5| Step: 4
Training loss: 2.777742209736613
Validation loss: 2.534440049315227

Epoch: 5| Step: 5
Training loss: 2.63339706858833
Validation loss: 2.524169298654604

Epoch: 5| Step: 6
Training loss: 2.5363321031392068
Validation loss: 2.538493044268046

Epoch: 5| Step: 7
Training loss: 2.2703024100639304
Validation loss: 2.530804634286325

Epoch: 5| Step: 8
Training loss: 2.7646471439252096
Validation loss: 2.5512585125545035

Epoch: 5| Step: 9
Training loss: 3.2149259202173464
Validation loss: 2.54016846959078

Epoch: 5| Step: 10
Training loss: 2.609629818472196
Validation loss: 2.513270123347234

Epoch: 103| Step: 0
Training loss: 2.3884249268684625
Validation loss: 2.557550688393356

Epoch: 5| Step: 1
Training loss: 2.540339691545917
Validation loss: 2.523513040517072

Epoch: 5| Step: 2
Training loss: 2.658125630299493
Validation loss: 2.511276468234586

Epoch: 5| Step: 3
Training loss: 2.951016919999203
Validation loss: 2.5203557281960447

Epoch: 5| Step: 4
Training loss: 2.506684521990281
Validation loss: 2.56857184611251

Epoch: 5| Step: 5
Training loss: 2.4766402849081812
Validation loss: 2.5365217245201905

Epoch: 5| Step: 6
Training loss: 2.8107949916811807
Validation loss: 2.523877804058372

Epoch: 5| Step: 7
Training loss: 2.9454416909456453
Validation loss: 2.5266273447952647

Epoch: 5| Step: 8
Training loss: 2.567432587359833
Validation loss: 2.5125878109476925

Epoch: 5| Step: 9
Training loss: 3.2666201010778138
Validation loss: 2.526193273012268

Epoch: 5| Step: 10
Training loss: 2.6388521281130233
Validation loss: 2.505727379590136

Epoch: 104| Step: 0
Training loss: 2.735186647117134
Validation loss: 2.547208318157489

Epoch: 5| Step: 1
Training loss: 2.6442321878709523
Validation loss: 2.5241964139951247

Epoch: 5| Step: 2
Training loss: 3.1544994371878956
Validation loss: 2.528862549779758

Epoch: 5| Step: 3
Training loss: 2.4823686667561833
Validation loss: 2.526966529431856

Epoch: 5| Step: 4
Training loss: 3.001147686454815
Validation loss: 2.528651241484563

Epoch: 5| Step: 5
Training loss: 2.6861344350148246
Validation loss: 2.516218715223199

Epoch: 5| Step: 6
Training loss: 2.956511800839533
Validation loss: 2.539319723145485

Epoch: 5| Step: 7
Training loss: 2.3315189891600636
Validation loss: 2.531598739472083

Epoch: 5| Step: 8
Training loss: 2.8042330147847014
Validation loss: 2.5184290641229676

Epoch: 5| Step: 9
Training loss: 2.4781842141695463
Validation loss: 2.530764746073908

Epoch: 5| Step: 10
Training loss: 2.4999503130743572
Validation loss: 2.55463355002001

Epoch: 105| Step: 0
Training loss: 2.5813261561208574
Validation loss: 2.5474862455396665

Epoch: 5| Step: 1
Training loss: 2.8069432784962127
Validation loss: 2.527928729596436

Epoch: 5| Step: 2
Training loss: 2.7377257824459673
Validation loss: 2.530767034418404

Epoch: 5| Step: 3
Training loss: 2.8845097370852892
Validation loss: 2.5524682510405516

Epoch: 5| Step: 4
Training loss: 2.6199367374324507
Validation loss: 2.5436155025000105

Epoch: 5| Step: 5
Training loss: 3.4382298475018986
Validation loss: 2.5198402204528705

Epoch: 5| Step: 6
Training loss: 2.8200106049737306
Validation loss: 2.519926014834871

Epoch: 5| Step: 7
Training loss: 2.109680266720364
Validation loss: 2.5456773015460845

Epoch: 5| Step: 8
Training loss: 2.7353390983125965
Validation loss: 2.525859759654356

Epoch: 5| Step: 9
Training loss: 2.7079306865594712
Validation loss: 2.5348261985817913

Epoch: 5| Step: 10
Training loss: 2.218510896935825
Validation loss: 2.5330421770500933

Epoch: 106| Step: 0
Training loss: 3.069479948349608
Validation loss: 2.5586091883460607

Epoch: 5| Step: 1
Training loss: 3.038007773825749
Validation loss: 2.529239770362873

Epoch: 5| Step: 2
Training loss: 2.764417395442368
Validation loss: 2.5536952627393434

Epoch: 5| Step: 3
Training loss: 3.028100018944461
Validation loss: 2.5284660299677113

Epoch: 5| Step: 4
Training loss: 2.473172825371837
Validation loss: 2.5356692232791076

Epoch: 5| Step: 5
Training loss: 1.9971889768382214
Validation loss: 2.5516296773740588

Epoch: 5| Step: 6
Training loss: 2.719241569189631
Validation loss: 2.5354032651633833

Epoch: 5| Step: 7
Training loss: 3.0216349272648726
Validation loss: 2.5375938248252563

Epoch: 5| Step: 8
Training loss: 2.7844930022267005
Validation loss: 2.5208329462023804

Epoch: 5| Step: 9
Training loss: 2.3490741529197257
Validation loss: 2.5483577017713306

Epoch: 5| Step: 10
Training loss: 2.3404047170964106
Validation loss: 2.509317254261857

Epoch: 107| Step: 0
Training loss: 2.468755215023665
Validation loss: 2.5502068634945636

Epoch: 5| Step: 1
Training loss: 3.325017346788632
Validation loss: 2.5269383410282815

Epoch: 5| Step: 2
Training loss: 2.992778988535363
Validation loss: 2.5450676724132184

Epoch: 5| Step: 3
Training loss: 2.401791789836766
Validation loss: 2.5184985160142235

Epoch: 5| Step: 4
Training loss: 2.998874771174761
Validation loss: 2.5324430966996316

Epoch: 5| Step: 5
Training loss: 2.327109710716899
Validation loss: 2.543214703444368

Epoch: 5| Step: 6
Training loss: 3.0244383424517816
Validation loss: 2.524133051312706

Epoch: 5| Step: 7
Training loss: 2.3633259414356385
Validation loss: 2.5622607884077278

Epoch: 5| Step: 8
Training loss: 2.5701642674890337
Validation loss: 2.536368036660101

Epoch: 5| Step: 9
Training loss: 2.456461101904958
Validation loss: 2.5381675153808088

Epoch: 5| Step: 10
Training loss: 2.724009895687642
Validation loss: 2.531115613555524

Epoch: 108| Step: 0
Training loss: 2.464864933267482
Validation loss: 2.541926998185479

Epoch: 5| Step: 1
Training loss: 3.064635330336511
Validation loss: 2.533396191463461

Epoch: 5| Step: 2
Training loss: 2.926848559393537
Validation loss: 2.5316881078937525

Epoch: 5| Step: 3
Training loss: 2.4740522400283225
Validation loss: 2.5424680018182304

Epoch: 5| Step: 4
Training loss: 2.4584605512729967
Validation loss: 2.517641177120921

Epoch: 5| Step: 5
Training loss: 3.027701276771258
Validation loss: 2.5203111623520393

Epoch: 5| Step: 6
Training loss: 2.529123142712153
Validation loss: 2.55233595909693

Epoch: 5| Step: 7
Training loss: 2.707906386150523
Validation loss: 2.541964632667447

Epoch: 5| Step: 8
Training loss: 2.8375468246024633
Validation loss: 2.5257554421849098

Epoch: 5| Step: 9
Training loss: 2.840191301699416
Validation loss: 2.5217348973243667

Epoch: 5| Step: 10
Training loss: 2.4288607352904257
Validation loss: 2.5402744608337287

Epoch: 109| Step: 0
Training loss: 2.681893644461435
Validation loss: 2.5264034819374914

Epoch: 5| Step: 1
Training loss: 2.687950185285784
Validation loss: 2.522342351919985

Epoch: 5| Step: 2
Training loss: 2.5873118087959672
Validation loss: 2.521230501762524

Epoch: 5| Step: 3
Training loss: 3.1786576836456932
Validation loss: 2.543305267417605

Epoch: 5| Step: 4
Training loss: 1.960387255305793
Validation loss: 2.540138148800561

Epoch: 5| Step: 5
Training loss: 2.3100026022495954
Validation loss: 2.5485242824161527

Epoch: 5| Step: 6
Training loss: 2.5309071249739965
Validation loss: 2.524871239556542

Epoch: 5| Step: 7
Training loss: 3.2451130731805096
Validation loss: 2.5536637613394526

Epoch: 5| Step: 8
Training loss: 3.156843677245276
Validation loss: 2.5527030776635793

Epoch: 5| Step: 9
Training loss: 2.6178323890647253
Validation loss: 2.553517792118042

Epoch: 5| Step: 10
Training loss: 2.9497608217166476
Validation loss: 2.5400981417186146

Epoch: 110| Step: 0
Training loss: 2.726163993503751
Validation loss: 2.5469346192029905

Epoch: 5| Step: 1
Training loss: 2.4642076835362063
Validation loss: 2.5573431068778647

Epoch: 5| Step: 2
Training loss: 2.143271710393424
Validation loss: 2.531149208556666

Epoch: 5| Step: 3
Training loss: 3.203381039690598
Validation loss: 2.5654156612499324

Epoch: 5| Step: 4
Training loss: 3.041367154638112
Validation loss: 2.5562488723889993

Epoch: 5| Step: 5
Training loss: 2.3428630930961254
Validation loss: 2.5236457493175535

Epoch: 5| Step: 6
Training loss: 2.548963755071933
Validation loss: 2.5309645556264995

Epoch: 5| Step: 7
Training loss: 2.5852800438189014
Validation loss: 2.54401835309828

Epoch: 5| Step: 8
Training loss: 2.740291711774295
Validation loss: 2.514390515533586

Epoch: 5| Step: 9
Training loss: 2.6478558016869234
Validation loss: 2.549629906248958

Epoch: 5| Step: 10
Training loss: 3.199286864211173
Validation loss: 2.530981110581969

Epoch: 111| Step: 0
Training loss: 2.4971813524820012
Validation loss: 2.5204493146155103

Epoch: 5| Step: 1
Training loss: 2.471876554814174
Validation loss: 2.5260035872351083

Epoch: 5| Step: 2
Training loss: 2.981438435291364
Validation loss: 2.537801790337654

Epoch: 5| Step: 3
Training loss: 2.9988940107614277
Validation loss: 2.539555083170401

Epoch: 5| Step: 4
Training loss: 2.5595978841275393
Validation loss: 2.506106683087041

Epoch: 5| Step: 5
Training loss: 2.8834695868372413
Validation loss: 2.518554355155133

Epoch: 5| Step: 6
Training loss: 2.2963117051490616
Validation loss: 2.5268440290789242

Epoch: 5| Step: 7
Training loss: 2.9992485694764195
Validation loss: 2.5326746278002332

Epoch: 5| Step: 8
Training loss: 2.764760027607081
Validation loss: 2.546712861523426

Epoch: 5| Step: 9
Training loss: 2.8957925331662837
Validation loss: 2.5137775821942707

Epoch: 5| Step: 10
Training loss: 2.344180461771985
Validation loss: 2.536709037627833

Epoch: 112| Step: 0
Training loss: 2.619921449109804
Validation loss: 2.5341203934161736

Epoch: 5| Step: 1
Training loss: 3.0748307468386127
Validation loss: 2.525494188089364

Epoch: 5| Step: 2
Training loss: 2.7268807736426814
Validation loss: 2.542773346922729

Epoch: 5| Step: 3
Training loss: 3.39324315678876
Validation loss: 2.526716407110734

Epoch: 5| Step: 4
Training loss: 2.1911634014837764
Validation loss: 2.525323723950569

Epoch: 5| Step: 5
Training loss: 2.3496424545026984
Validation loss: 2.5346399818062606

Epoch: 5| Step: 6
Training loss: 2.8660660299293594
Validation loss: 2.5316620550456785

Epoch: 5| Step: 7
Training loss: 2.715278777252126
Validation loss: 2.5236242457542306

Epoch: 5| Step: 8
Training loss: 2.692938248185208
Validation loss: 2.523611167580998

Epoch: 5| Step: 9
Training loss: 2.5977537208569395
Validation loss: 2.5126256144959775

Epoch: 5| Step: 10
Training loss: 2.2947454636318354
Validation loss: 2.5448652791330915

Epoch: 113| Step: 0
Training loss: 2.494648355231608
Validation loss: 2.5280062624687747

Epoch: 5| Step: 1
Training loss: 1.9710778295090987
Validation loss: 2.5537201712482633

Epoch: 5| Step: 2
Training loss: 2.7279774838969852
Validation loss: 2.5171260219208467

Epoch: 5| Step: 3
Training loss: 2.696813281647084
Validation loss: 2.511708447317167

Epoch: 5| Step: 4
Training loss: 2.4904237443315878
Validation loss: 2.5375902212096775

Epoch: 5| Step: 5
Training loss: 3.2265317605981254
Validation loss: 2.5132497627199752

Epoch: 5| Step: 6
Training loss: 2.9757311203094976
Validation loss: 2.5178440298868607

Epoch: 5| Step: 7
Training loss: 3.573514675146009
Validation loss: 2.5289040321902667

Epoch: 5| Step: 8
Training loss: 2.358341521214087
Validation loss: 2.5125594347006976

Epoch: 5| Step: 9
Training loss: 2.928043646888396
Validation loss: 2.5122443593821027

Epoch: 5| Step: 10
Training loss: 1.9087592947483152
Validation loss: 2.550349285847971

Epoch: 114| Step: 0
Training loss: 2.615689888243861
Validation loss: 2.536775509062843

Epoch: 5| Step: 1
Training loss: 2.823767830504059
Validation loss: 2.5437011228688395

Epoch: 5| Step: 2
Training loss: 2.707608424276196
Validation loss: 2.523427186238348

Epoch: 5| Step: 3
Training loss: 2.1325305570714015
Validation loss: 2.5072437293467593

Epoch: 5| Step: 4
Training loss: 2.831173260387727
Validation loss: 2.5518296434398557

Epoch: 5| Step: 5
Training loss: 2.8963503661894197
Validation loss: 2.5108708909507427

Epoch: 5| Step: 6
Training loss: 2.1914292060615246
Validation loss: 2.527615104568069

Epoch: 5| Step: 7
Training loss: 2.788974108751221
Validation loss: 2.509223707300975

Epoch: 5| Step: 8
Training loss: 2.9652675079556974
Validation loss: 2.514415882737634

Epoch: 5| Step: 9
Training loss: 2.853177049878626
Validation loss: 2.5132077893485594

Epoch: 5| Step: 10
Training loss: 2.8425749981731805
Validation loss: 2.5477699233972775

Epoch: 115| Step: 0
Training loss: 2.3991469536152854
Validation loss: 2.5338739760854576

Epoch: 5| Step: 1
Training loss: 2.555114710373392
Validation loss: 2.534361854461371

Epoch: 5| Step: 2
Training loss: 2.656100639183077
Validation loss: 2.5365532917528975

Epoch: 5| Step: 3
Training loss: 2.133047796551748
Validation loss: 2.5387539028437174

Epoch: 5| Step: 4
Training loss: 3.5016696217333965
Validation loss: 2.5311608683050997

Epoch: 5| Step: 5
Training loss: 2.236701660943712
Validation loss: 2.5108354655119873

Epoch: 5| Step: 6
Training loss: 2.42985970724009
Validation loss: 2.5161146317872656

Epoch: 5| Step: 7
Training loss: 3.1201168818466205
Validation loss: 2.5165170820141314

Epoch: 5| Step: 8
Training loss: 2.890717705966949
Validation loss: 2.5304284625493576

Epoch: 5| Step: 9
Training loss: 2.6860834868714716
Validation loss: 2.5318184794953784

Epoch: 5| Step: 10
Training loss: 2.8256542730977263
Validation loss: 2.5417028125658527

Epoch: 116| Step: 0
Training loss: 3.032810399459119
Validation loss: 2.531136367781294

Epoch: 5| Step: 1
Training loss: 2.9396000923600014
Validation loss: 2.5336244274078443

Epoch: 5| Step: 2
Training loss: 2.448642303918202
Validation loss: 2.5272756210014804

Epoch: 5| Step: 3
Training loss: 2.654972801572062
Validation loss: 2.5375429231545454

Epoch: 5| Step: 4
Training loss: 2.4538820884314227
Validation loss: 2.5322170620669784

Epoch: 5| Step: 5
Training loss: 2.8166871162289184
Validation loss: 2.5327135881025256

Epoch: 5| Step: 6
Training loss: 2.977218115184593
Validation loss: 2.5344674624115213

Epoch: 5| Step: 7
Training loss: 2.6131342688311476
Validation loss: 2.505117796488473

Epoch: 5| Step: 8
Training loss: 2.7324566024307653
Validation loss: 2.5303056931218033

Epoch: 5| Step: 9
Training loss: 2.559208221031929
Validation loss: 2.5349824308177444

Epoch: 5| Step: 10
Training loss: 2.568564519195502
Validation loss: 2.5315193418846054

Epoch: 117| Step: 0
Training loss: 3.271679390176319
Validation loss: 2.532751093280211

Epoch: 5| Step: 1
Training loss: 2.358541682535124
Validation loss: 2.526678713937203

Epoch: 5| Step: 2
Training loss: 2.7621800578302276
Validation loss: 2.538832068450537

Epoch: 5| Step: 3
Training loss: 2.0920302886812525
Validation loss: 2.519304703078147

Epoch: 5| Step: 4
Training loss: 2.8774904162448665
Validation loss: 2.5044050006786254

Epoch: 5| Step: 5
Training loss: 2.6493210120616135
Validation loss: 2.505352173129305

Epoch: 5| Step: 6
Training loss: 2.2187547280704463
Validation loss: 2.5416095649226347

Epoch: 5| Step: 7
Training loss: 2.6129459456799267
Validation loss: 2.5204135376073444

Epoch: 5| Step: 8
Training loss: 2.4774842096435656
Validation loss: 2.517797673359637

Epoch: 5| Step: 9
Training loss: 3.2498262799124165
Validation loss: 2.546862355275148

Epoch: 5| Step: 10
Training loss: 2.790653405466784
Validation loss: 2.5195892858947664

Epoch: 118| Step: 0
Training loss: 2.6851389960144485
Validation loss: 2.5031190550197655

Epoch: 5| Step: 1
Training loss: 2.996028974049197
Validation loss: 2.5188382273470054

Epoch: 5| Step: 2
Training loss: 2.8594475408639055
Validation loss: 2.5337895170326337

Epoch: 5| Step: 3
Training loss: 2.640183090161126
Validation loss: 2.5425561175353075

Epoch: 5| Step: 4
Training loss: 2.3949759787547467
Validation loss: 2.5285469773335816

Epoch: 5| Step: 5
Training loss: 2.7547812945171053
Validation loss: 2.518513279943824

Epoch: 5| Step: 6
Training loss: 2.209604784982294
Validation loss: 2.538562788463013

Epoch: 5| Step: 7
Training loss: 2.2241585587027037
Validation loss: 2.5339623567578577

Epoch: 5| Step: 8
Training loss: 2.4955706458665405
Validation loss: 2.5254948174541054

Epoch: 5| Step: 9
Training loss: 2.4854646608291806
Validation loss: 2.538691367009715

Epoch: 5| Step: 10
Training loss: 3.639440122660779
Validation loss: 2.52666714917328

Epoch: 119| Step: 0
Training loss: 2.39009048370437
Validation loss: 2.514912796883357

Epoch: 5| Step: 1
Training loss: 3.0624487736368593
Validation loss: 2.5012464953638123

Epoch: 5| Step: 2
Training loss: 2.6766657126279707
Validation loss: 2.5473299911647183

Epoch: 5| Step: 3
Training loss: 2.9264596475999394
Validation loss: 2.5440422393137445

Epoch: 5| Step: 4
Training loss: 2.616250397034682
Validation loss: 2.52421552699687

Epoch: 5| Step: 5
Training loss: 2.4271260095427123
Validation loss: 2.5101167825396438

Epoch: 5| Step: 6
Training loss: 2.4727131383537806
Validation loss: 2.5298529937151133

Epoch: 5| Step: 7
Training loss: 1.9703013045426259
Validation loss: 2.5355283513812465

Epoch: 5| Step: 8
Training loss: 2.894314612391073
Validation loss: 2.5550710628428033

Epoch: 5| Step: 9
Training loss: 3.113204514767548
Validation loss: 2.525911123092901

Epoch: 5| Step: 10
Training loss: 2.918321539656945
Validation loss: 2.547805526558293

Epoch: 120| Step: 0
Training loss: 2.3663458508213595
Validation loss: 2.540394263974176

Epoch: 5| Step: 1
Training loss: 2.6811546113090254
Validation loss: 2.5446368802319346

Epoch: 5| Step: 2
Training loss: 2.7432992099974274
Validation loss: 2.5531862535603365

Epoch: 5| Step: 3
Training loss: 2.785634731372442
Validation loss: 2.5537076748608087

Epoch: 5| Step: 4
Training loss: 2.411742246542388
Validation loss: 2.5513394331154475

Epoch: 5| Step: 5
Training loss: 2.1566336470154046
Validation loss: 2.5408963233459505

Epoch: 5| Step: 6
Training loss: 2.976181686751693
Validation loss: 2.5403569594357074

Epoch: 5| Step: 7
Training loss: 2.781349951844691
Validation loss: 2.54884547418349

Epoch: 5| Step: 8
Training loss: 2.9073836873898644
Validation loss: 2.5359010512292954

Epoch: 5| Step: 9
Training loss: 2.5289759841086354
Validation loss: 2.561714648281782

Epoch: 5| Step: 10
Training loss: 3.242134553408039
Validation loss: 2.549655212426594

Epoch: 121| Step: 0
Training loss: 2.3667179057345864
Validation loss: 2.542860366761998

Epoch: 5| Step: 1
Training loss: 2.676351622888588
Validation loss: 2.5604228843716865

Epoch: 5| Step: 2
Training loss: 2.9170583916051767
Validation loss: 2.5328678028681915

Epoch: 5| Step: 3
Training loss: 2.62563552429371
Validation loss: 2.5162115888912515

Epoch: 5| Step: 4
Training loss: 2.4961885962577344
Validation loss: 2.542555535750384

Epoch: 5| Step: 5
Training loss: 2.7219841673514584
Validation loss: 2.551353182050553

Epoch: 5| Step: 6
Training loss: 2.846238273827644
Validation loss: 2.5429477233657583

Epoch: 5| Step: 7
Training loss: 2.6972328311106084
Validation loss: 2.535057694059185

Epoch: 5| Step: 8
Training loss: 2.286850521251678
Validation loss: 2.5283724472516322

Epoch: 5| Step: 9
Training loss: 2.8637062163317366
Validation loss: 2.520569363343713

Epoch: 5| Step: 10
Training loss: 3.0616067634693214
Validation loss: 2.5276672579219928

Epoch: 122| Step: 0
Training loss: 2.297898979038241
Validation loss: 2.540257346791521

Epoch: 5| Step: 1
Training loss: 3.215940415878983
Validation loss: 2.522108577331966

Epoch: 5| Step: 2
Training loss: 2.744116819013732
Validation loss: 2.5241586537370173

Epoch: 5| Step: 3
Training loss: 2.0081489963801484
Validation loss: 2.5379269962259947

Epoch: 5| Step: 4
Training loss: 2.707340283389714
Validation loss: 2.540914028361588

Epoch: 5| Step: 5
Training loss: 2.4870624521633333
Validation loss: 2.5046011023145867

Epoch: 5| Step: 6
Training loss: 2.39365160468439
Validation loss: 2.5272529224236853

Epoch: 5| Step: 7
Training loss: 2.8320357960631615
Validation loss: 2.5406630077812897

Epoch: 5| Step: 8
Training loss: 3.585657312421473
Validation loss: 2.5232835257444264

Epoch: 5| Step: 9
Training loss: 2.0922806551694584
Validation loss: 2.55296980274855

Epoch: 5| Step: 10
Training loss: 3.0155366084135222
Validation loss: 2.532378978630126

Epoch: 123| Step: 0
Training loss: 2.4982665728131273
Validation loss: 2.5298258670542872

Epoch: 5| Step: 1
Training loss: 2.751636105126439
Validation loss: 2.5227128699053125

Epoch: 5| Step: 2
Training loss: 2.7737315707047903
Validation loss: 2.5250797021162374

Epoch: 5| Step: 3
Training loss: 2.6875014194218636
Validation loss: 2.506425722201772

Epoch: 5| Step: 4
Training loss: 2.4672256785670648
Validation loss: 2.521288658180575

Epoch: 5| Step: 5
Training loss: 2.7308146812896994
Validation loss: 2.525875942086971

Epoch: 5| Step: 6
Training loss: 2.8675363936438663
Validation loss: 2.52726589654245

Epoch: 5| Step: 7
Training loss: 2.4855119514799577
Validation loss: 2.5340910554222162

Epoch: 5| Step: 8
Training loss: 2.694353281250811
Validation loss: 2.5282621576168407

Epoch: 5| Step: 9
Training loss: 2.6844766155722875
Validation loss: 2.5353231039699504

Epoch: 5| Step: 10
Training loss: 2.830843298797839
Validation loss: 2.5511979071200654

Epoch: 124| Step: 0
Training loss: 2.6958283303954818
Validation loss: 2.5373032369583632

Epoch: 5| Step: 1
Training loss: 2.8372406290632157
Validation loss: 2.5262037672816615

Epoch: 5| Step: 2
Training loss: 3.0309797343473637
Validation loss: 2.5178408704449775

Epoch: 5| Step: 3
Training loss: 2.678700523898597
Validation loss: 2.541180972920026

Epoch: 5| Step: 4
Training loss: 3.1805829561062904
Validation loss: 2.5226612533425055

Epoch: 5| Step: 5
Training loss: 2.4165042515691053
Validation loss: 2.5367665875562904

Epoch: 5| Step: 6
Training loss: 2.937199354004766
Validation loss: 2.5324805896863367

Epoch: 5| Step: 7
Training loss: 2.2702012771908002
Validation loss: 2.5458663300930815

Epoch: 5| Step: 8
Training loss: 2.562341638649448
Validation loss: 2.5403096089485224

Epoch: 5| Step: 9
Training loss: 2.2736263655508955
Validation loss: 2.519960913175963

Epoch: 5| Step: 10
Training loss: 2.60445117667843
Validation loss: 2.523252627149174

Epoch: 125| Step: 0
Training loss: 2.558041578508197
Validation loss: 2.532089205691721

Epoch: 5| Step: 1
Training loss: 2.752454356023843
Validation loss: 2.5509872751568397

Epoch: 5| Step: 2
Training loss: 3.038670531739805
Validation loss: 2.4929644558804016

Epoch: 5| Step: 3
Training loss: 2.5474021693678446
Validation loss: 2.5337443011384844

Epoch: 5| Step: 4
Training loss: 2.786482699754128
Validation loss: 2.5436534324985653

Epoch: 5| Step: 5
Training loss: 2.6560272123367525
Validation loss: 2.5238699522626526

Epoch: 5| Step: 6
Training loss: 2.8519848654453783
Validation loss: 2.5505054356606065

Epoch: 5| Step: 7
Training loss: 2.6552739762435094
Validation loss: 2.518385915809579

Epoch: 5| Step: 8
Training loss: 2.3974762521786825
Validation loss: 2.5179136379122773

Epoch: 5| Step: 9
Training loss: 2.1365636458930166
Validation loss: 2.530839548238629

Epoch: 5| Step: 10
Training loss: 2.9108150274176356
Validation loss: 2.507832554649577

Epoch: 126| Step: 0
Training loss: 2.37831185968975
Validation loss: 2.565092233784472

Epoch: 5| Step: 1
Training loss: 3.0012925860185056
Validation loss: 2.515342500366033

Epoch: 5| Step: 2
Training loss: 2.575200774874516
Validation loss: 2.523326312948183

Epoch: 5| Step: 3
Training loss: 2.516455850760773
Validation loss: 2.5233992127922664

Epoch: 5| Step: 4
Training loss: 2.4399423345411733
Validation loss: 2.562474317444468

Epoch: 5| Step: 5
Training loss: 2.602645419525882
Validation loss: 2.55070503858587

Epoch: 5| Step: 6
Training loss: 2.479938600610723
Validation loss: 2.5355212070279833

Epoch: 5| Step: 7
Training loss: 2.776134544283668
Validation loss: 2.560134982846425

Epoch: 5| Step: 8
Training loss: 3.106417222002434
Validation loss: 2.5613134364682537

Epoch: 5| Step: 9
Training loss: 3.097118355036265
Validation loss: 2.544641768462751

Epoch: 5| Step: 10
Training loss: 2.613254609706327
Validation loss: 2.522386248687408

Epoch: 127| Step: 0
Training loss: 2.509150163166964
Validation loss: 2.5275460745957976

Epoch: 5| Step: 1
Training loss: 2.5079406515397267
Validation loss: 2.5576016268920694

Epoch: 5| Step: 2
Training loss: 2.21466375894526
Validation loss: 2.5574269725202603

Epoch: 5| Step: 3
Training loss: 2.493991115453293
Validation loss: 2.529862857192376

Epoch: 5| Step: 4
Training loss: 2.9619934292758385
Validation loss: 2.5417719805232113

Epoch: 5| Step: 5
Training loss: 2.7418076993927234
Validation loss: 2.5504795488951575

Epoch: 5| Step: 6
Training loss: 2.2421490071145986
Validation loss: 2.526619525895756

Epoch: 5| Step: 7
Training loss: 2.842096875273167
Validation loss: 2.5188111683182473

Epoch: 5| Step: 8
Training loss: 2.259173764966139
Validation loss: 2.5345993660269315

Epoch: 5| Step: 9
Training loss: 3.3257374684214485
Validation loss: 2.531244899046293

Epoch: 5| Step: 10
Training loss: 3.232102927523572
Validation loss: 2.5240813723815565

Epoch: 128| Step: 0
Training loss: 2.394180645563849
Validation loss: 2.525376226125593

Epoch: 5| Step: 1
Training loss: 2.779376481203577
Validation loss: 2.5496535493534958

Epoch: 5| Step: 2
Training loss: 3.2190061300645367
Validation loss: 2.541431139384131

Epoch: 5| Step: 3
Training loss: 2.490070939030169
Validation loss: 2.5445800321985383

Epoch: 5| Step: 4
Training loss: 2.3559453428304615
Validation loss: 2.5096862073038184

Epoch: 5| Step: 5
Training loss: 2.3176082175130537
Validation loss: 2.53646378850206

Epoch: 5| Step: 6
Training loss: 2.8689082748200674
Validation loss: 2.534804464202732

Epoch: 5| Step: 7
Training loss: 2.567354674419075
Validation loss: 2.525717514411981

Epoch: 5| Step: 8
Training loss: 2.6421327518721736
Validation loss: 2.5291675786231633

Epoch: 5| Step: 9
Training loss: 2.190919002552269
Validation loss: 2.5056174652424477

Epoch: 5| Step: 10
Training loss: 3.4351068662763984
Validation loss: 2.4983111193849945

Epoch: 129| Step: 0
Training loss: 2.8236719132324635
Validation loss: 2.530492841779157

Epoch: 5| Step: 1
Training loss: 2.705503795197419
Validation loss: 2.5444854492318

Epoch: 5| Step: 2
Training loss: 2.769693259597225
Validation loss: 2.5460681725671974

Epoch: 5| Step: 3
Training loss: 2.4915139175935783
Validation loss: 2.540093233641934

Epoch: 5| Step: 4
Training loss: 2.558761754234908
Validation loss: 2.541074697655919

Epoch: 5| Step: 5
Training loss: 2.6354635684296643
Validation loss: 2.5339088204294367

Epoch: 5| Step: 6
Training loss: 3.053884415293522
Validation loss: 2.5259247526449853

Epoch: 5| Step: 7
Training loss: 2.8787792079435994
Validation loss: 2.5357574766766597

Epoch: 5| Step: 8
Training loss: 2.22725326798525
Validation loss: 2.536276969246526

Epoch: 5| Step: 9
Training loss: 2.91373030581829
Validation loss: 2.5072742925163007

Epoch: 5| Step: 10
Training loss: 2.172718789833895
Validation loss: 2.549719999038231

Epoch: 130| Step: 0
Training loss: 2.838994168019259
Validation loss: 2.5462105767207057

Epoch: 5| Step: 1
Training loss: 2.6143079716541235
Validation loss: 2.521654235543194

Epoch: 5| Step: 2
Training loss: 2.5995817691704315
Validation loss: 2.5424366663327462

Epoch: 5| Step: 3
Training loss: 2.3336887316024604
Validation loss: 2.5617546430166667

Epoch: 5| Step: 4
Training loss: 2.80987816570244
Validation loss: 2.5608496725291547

Epoch: 5| Step: 5
Training loss: 2.4020842125111606
Validation loss: 2.5370328008866054

Epoch: 5| Step: 6
Training loss: 2.8917567331613805
Validation loss: 2.5328424251190658

Epoch: 5| Step: 7
Training loss: 2.4986414078840666
Validation loss: 2.547997308987519

Epoch: 5| Step: 8
Training loss: 2.6591166566907853
Validation loss: 2.5685523505384826

Epoch: 5| Step: 9
Training loss: 2.8626753307768724
Validation loss: 2.530531807306084

Epoch: 5| Step: 10
Training loss: 2.842863678359867
Validation loss: 2.564707704676187

Epoch: 131| Step: 0
Training loss: 2.505328793448327
Validation loss: 2.5711520994601806

Epoch: 5| Step: 1
Training loss: 2.9881526345892273
Validation loss: 2.5868041499597627

Epoch: 5| Step: 2
Training loss: 2.295619387849573
Validation loss: 2.558890593191688

Epoch: 5| Step: 3
Training loss: 2.961422842705158
Validation loss: 2.5429285827975745

Epoch: 5| Step: 4
Training loss: 2.908526769579464
Validation loss: 2.529976403227151

Epoch: 5| Step: 5
Training loss: 2.2088796791474823
Validation loss: 2.5561228489271324

Epoch: 5| Step: 6
Training loss: 2.487124570953214
Validation loss: 2.5627615570312874

Epoch: 5| Step: 7
Training loss: 2.9580524651528206
Validation loss: 2.5548361006590126

Epoch: 5| Step: 8
Training loss: 2.774488566927951
Validation loss: 2.5604866856579003

Epoch: 5| Step: 9
Training loss: 2.266912370809673
Validation loss: 2.5579779086609724

Epoch: 5| Step: 10
Training loss: 2.7848571359915937
Validation loss: 2.550870279029428

Epoch: 132| Step: 0
Training loss: 2.693388852296317
Validation loss: 2.545360720729065

Epoch: 5| Step: 1
Training loss: 2.4734878467440917
Validation loss: 2.552315479708849

Epoch: 5| Step: 2
Training loss: 2.594736945576939
Validation loss: 2.5429463966566304

Epoch: 5| Step: 3
Training loss: 2.934426830674938
Validation loss: 2.541008538448955

Epoch: 5| Step: 4
Training loss: 3.08637012394693
Validation loss: 2.516852476120656

Epoch: 5| Step: 5
Training loss: 2.492333865277343
Validation loss: 2.534472604926058

Epoch: 5| Step: 6
Training loss: 2.6889195795996206
Validation loss: 2.513471334352828

Epoch: 5| Step: 7
Training loss: 2.300480406802305
Validation loss: 2.516289278523643

Epoch: 5| Step: 8
Training loss: 3.010386764923449
Validation loss: 2.5075781478255563

Epoch: 5| Step: 9
Training loss: 2.9323201062374373
Validation loss: 2.5163592846051

Epoch: 5| Step: 10
Training loss: 1.8934213434950726
Validation loss: 2.548457710011593

Epoch: 133| Step: 0
Training loss: 2.992107499848462
Validation loss: 2.525376199731642

Epoch: 5| Step: 1
Training loss: 2.69637686680761
Validation loss: 2.5255294586656873

Epoch: 5| Step: 2
Training loss: 1.9197460260897794
Validation loss: 2.547479554367535

Epoch: 5| Step: 3
Training loss: 2.6869685512529475
Validation loss: 2.554684792543178

Epoch: 5| Step: 4
Training loss: 2.666512534535001
Validation loss: 2.5197494652724415

Epoch: 5| Step: 5
Training loss: 2.7304119928270403
Validation loss: 2.5327130840213816

Epoch: 5| Step: 6
Training loss: 2.5730661407995714
Validation loss: 2.513365252177263

Epoch: 5| Step: 7
Training loss: 2.97852571079235
Validation loss: 2.563677137490472

Epoch: 5| Step: 8
Training loss: 2.7203036725001266
Validation loss: 2.5241249078022983

Epoch: 5| Step: 9
Training loss: 2.443392453781631
Validation loss: 2.5330912502965512

Epoch: 5| Step: 10
Training loss: 2.822088554133808
Validation loss: 2.5162848089654117

Epoch: 134| Step: 0
Training loss: 2.5976112763376555
Validation loss: 2.509829392278851

Epoch: 5| Step: 1
Training loss: 2.62928694396013
Validation loss: 2.526688200697356

Epoch: 5| Step: 2
Training loss: 1.963389653022534
Validation loss: 2.5339408729581767

Epoch: 5| Step: 3
Training loss: 2.205491762922909
Validation loss: 2.537259037496997

Epoch: 5| Step: 4
Training loss: 2.8385223294687285
Validation loss: 2.5165279222509978

Epoch: 5| Step: 5
Training loss: 2.2051691622732084
Validation loss: 2.5442580712096032

Epoch: 5| Step: 6
Training loss: 2.925804229768317
Validation loss: 2.5470111034733676

Epoch: 5| Step: 7
Training loss: 3.733005160712643
Validation loss: 2.556231233469898

Epoch: 5| Step: 8
Training loss: 2.1838097098735476
Validation loss: 2.528353576576954

Epoch: 5| Step: 9
Training loss: 2.6883857509408533
Validation loss: 2.559436236119277

Epoch: 5| Step: 10
Training loss: 2.9912095027849155
Validation loss: 2.5407937775207716

Epoch: 135| Step: 0
Training loss: 3.051905777662938
Validation loss: 2.542487954022149

Epoch: 5| Step: 1
Training loss: 2.6266389907146976
Validation loss: 2.5321269479178468

Epoch: 5| Step: 2
Training loss: 2.2602169341225706
Validation loss: 2.543332965979127

Epoch: 5| Step: 3
Training loss: 3.555221886343075
Validation loss: 2.540858131225555

Epoch: 5| Step: 4
Training loss: 2.2915544193405744
Validation loss: 2.5295655552907306

Epoch: 5| Step: 5
Training loss: 2.4069171327495553
Validation loss: 2.553845888651653

Epoch: 5| Step: 6
Training loss: 2.184683594305263
Validation loss: 2.5269522805552596

Epoch: 5| Step: 7
Training loss: 2.965554856977225
Validation loss: 2.5549834886095293

Epoch: 5| Step: 8
Training loss: 2.469412026790313
Validation loss: 2.569421192682213

Epoch: 5| Step: 9
Training loss: 2.5601232718054026
Validation loss: 2.5380287912216573

Epoch: 5| Step: 10
Training loss: 2.560769217677777
Validation loss: 2.54607099591829

Epoch: 136| Step: 0
Training loss: 2.6527981937636977
Validation loss: 2.534922359594949

Epoch: 5| Step: 1
Training loss: 2.178763244903803
Validation loss: 2.5647723849382578

Epoch: 5| Step: 2
Training loss: 3.017553789849286
Validation loss: 2.5326587104868796

Epoch: 5| Step: 3
Training loss: 1.8979098367690281
Validation loss: 2.523092467972821

Epoch: 5| Step: 4
Training loss: 2.7089570916637085
Validation loss: 2.5442537596078445

Epoch: 5| Step: 5
Training loss: 2.2325985121911605
Validation loss: 2.534736883151301

Epoch: 5| Step: 6
Training loss: 2.9258190605867904
Validation loss: 2.543619970395785

Epoch: 5| Step: 7
Training loss: 2.5551570729088904
Validation loss: 2.553148066551458

Epoch: 5| Step: 8
Training loss: 3.1395296682434397
Validation loss: 2.5315315893102257

Epoch: 5| Step: 9
Training loss: 2.661599908834352
Validation loss: 2.523097994375964

Epoch: 5| Step: 10
Training loss: 2.988367416037128
Validation loss: 2.5197404387161226

Epoch: 137| Step: 0
Training loss: 3.3556657051662793
Validation loss: 2.53048852090677

Epoch: 5| Step: 1
Training loss: 3.1807303253383266
Validation loss: 2.546054157462417

Epoch: 5| Step: 2
Training loss: 2.8449875371086795
Validation loss: 2.5353407220152975

Epoch: 5| Step: 3
Training loss: 2.4801477900430293
Validation loss: 2.539993382550993

Epoch: 5| Step: 4
Training loss: 2.7103243527438585
Validation loss: 2.550989356428527

Epoch: 5| Step: 5
Training loss: 2.5028852979018286
Validation loss: 2.5282233051548637

Epoch: 5| Step: 6
Training loss: 2.1755206570127887
Validation loss: 2.503072661353647

Epoch: 5| Step: 7
Training loss: 1.8431341791554992
Validation loss: 2.5374155301358132

Epoch: 5| Step: 8
Training loss: 2.9597188006681177
Validation loss: 2.525107914821667

Epoch: 5| Step: 9
Training loss: 2.44614052692768
Validation loss: 2.5274995734653403

Epoch: 5| Step: 10
Training loss: 2.272687126151874
Validation loss: 2.5217166581180868

Epoch: 138| Step: 0
Training loss: 2.789488687730612
Validation loss: 2.5279249124197394

Epoch: 5| Step: 1
Training loss: 2.329516206375869
Validation loss: 2.5237299749221545

Epoch: 5| Step: 2
Training loss: 3.1218575508615207
Validation loss: 2.5177354713094138

Epoch: 5| Step: 3
Training loss: 2.5148398554269025
Validation loss: 2.524932261146927

Epoch: 5| Step: 4
Training loss: 3.2756078257963006
Validation loss: 2.5410667486742624

Epoch: 5| Step: 5
Training loss: 2.3122928629715505
Validation loss: 2.510150243930322

Epoch: 5| Step: 6
Training loss: 2.793444186205938
Validation loss: 2.5144737002461555

Epoch: 5| Step: 7
Training loss: 2.2569771775700396
Validation loss: 2.5250850840629995

Epoch: 5| Step: 8
Training loss: 2.3728187985175238
Validation loss: 2.5397403500693003

Epoch: 5| Step: 9
Training loss: 2.9392092987017286
Validation loss: 2.5091908516830954

Epoch: 5| Step: 10
Training loss: 2.3243000945914916
Validation loss: 2.5265177328990402

Epoch: 139| Step: 0
Training loss: 3.300007999294874
Validation loss: 2.521313263549272

Epoch: 5| Step: 1
Training loss: 2.7814799867328652
Validation loss: 2.5132211654531282

Epoch: 5| Step: 2
Training loss: 2.257019642938364
Validation loss: 2.525465807636956

Epoch: 5| Step: 3
Training loss: 2.3495483897880907
Validation loss: 2.511463707899054

Epoch: 5| Step: 4
Training loss: 2.8123607177154697
Validation loss: 2.5161157576589694

Epoch: 5| Step: 5
Training loss: 2.4266615297801106
Validation loss: 2.5506482675022117

Epoch: 5| Step: 6
Training loss: 2.7390222784767904
Validation loss: 2.5318725207330255

Epoch: 5| Step: 7
Training loss: 3.1145445822321944
Validation loss: 2.5380298578777767

Epoch: 5| Step: 8
Training loss: 2.5662314066559397
Validation loss: 2.552838979876794

Epoch: 5| Step: 9
Training loss: 2.490123312474329
Validation loss: 2.5523565357495346

Epoch: 5| Step: 10
Training loss: 1.709490159529965
Validation loss: 2.5611408830221007

Epoch: 140| Step: 0
Training loss: 2.9885866495290316
Validation loss: 2.542391680861512

Epoch: 5| Step: 1
Training loss: 2.0741040329182323
Validation loss: 2.5496067817654553

Epoch: 5| Step: 2
Training loss: 2.3033579984118093
Validation loss: 2.530744844277874

Epoch: 5| Step: 3
Training loss: 2.4460370145228825
Validation loss: 2.5378347695215813

Epoch: 5| Step: 4
Training loss: 3.248119984238088
Validation loss: 2.571887890503542

Epoch: 5| Step: 5
Training loss: 2.8923694192727085
Validation loss: 2.518240185154106

Epoch: 5| Step: 6
Training loss: 2.7011516622695932
Validation loss: 2.5327796299625

Epoch: 5| Step: 7
Training loss: 2.0198670925191218
Validation loss: 2.5596486697111978

Epoch: 5| Step: 8
Training loss: 2.7901534823788303
Validation loss: 2.5218358586689185

Epoch: 5| Step: 9
Training loss: 2.93237263018337
Validation loss: 2.5211142215090625

Epoch: 5| Step: 10
Training loss: 2.489013085171124
Validation loss: 2.531247516622253

Epoch: 141| Step: 0
Training loss: 2.510601263791109
Validation loss: 2.5172276187778286

Epoch: 5| Step: 1
Training loss: 2.5336528722950225
Validation loss: 2.5164695029990805

Epoch: 5| Step: 2
Training loss: 3.150522757855609
Validation loss: 2.530267352290416

Epoch: 5| Step: 3
Training loss: 2.5509881816307627
Validation loss: 2.5248936194045726

Epoch: 5| Step: 4
Training loss: 2.299249161607615
Validation loss: 2.524811308024108

Epoch: 5| Step: 5
Training loss: 2.1575610832681997
Validation loss: 2.538830928418093

Epoch: 5| Step: 6
Training loss: 3.1532132487050544
Validation loss: 2.526331191897732

Epoch: 5| Step: 7
Training loss: 2.284772478792186
Validation loss: 2.528526020368175

Epoch: 5| Step: 8
Training loss: 2.6663814531230052
Validation loss: 2.5244201983784698

Epoch: 5| Step: 9
Training loss: 2.851824521084714
Validation loss: 2.5230446888222122

Epoch: 5| Step: 10
Training loss: 2.7929829203639653
Validation loss: 2.5227072887985154

Epoch: 142| Step: 0
Training loss: 2.8051054491699836
Validation loss: 2.49992239226609

Epoch: 5| Step: 1
Training loss: 2.912917825091759
Validation loss: 2.535107113578656

Epoch: 5| Step: 2
Training loss: 3.100113768181966
Validation loss: 2.512473262244004

Epoch: 5| Step: 3
Training loss: 2.134861894201124
Validation loss: 2.5419184648956397

Epoch: 5| Step: 4
Training loss: 2.6504376715783433
Validation loss: 2.5410345186735466

Epoch: 5| Step: 5
Training loss: 2.5622859028022176
Validation loss: 2.542629165271597

Epoch: 5| Step: 6
Training loss: 2.439844520023944
Validation loss: 2.543613437368001

Epoch: 5| Step: 7
Training loss: 2.581504040794897
Validation loss: 2.5592865823173065

Epoch: 5| Step: 8
Training loss: 2.2851617796741324
Validation loss: 2.5472896371025655

Epoch: 5| Step: 9
Training loss: 2.3997282351168416
Validation loss: 2.5177352523893695

Epoch: 5| Step: 10
Training loss: 3.016075930704562
Validation loss: 2.5284581092791294

Epoch: 143| Step: 0
Training loss: 2.516326332658954
Validation loss: 2.545958534710602

Epoch: 5| Step: 1
Training loss: 2.182500848933838
Validation loss: 2.5355096300188036

Epoch: 5| Step: 2
Training loss: 3.529205135299438
Validation loss: 2.556459352627722

Epoch: 5| Step: 3
Training loss: 2.1854627659544534
Validation loss: 2.5403791448334823

Epoch: 5| Step: 4
Training loss: 2.465686394104791
Validation loss: 2.5230102969874686

Epoch: 5| Step: 5
Training loss: 2.6738896498696754
Validation loss: 2.533784586617977

Epoch: 5| Step: 6
Training loss: 2.2415498365094773
Validation loss: 2.56163592593134

Epoch: 5| Step: 7
Training loss: 2.814589847206091
Validation loss: 2.547804088676373

Epoch: 5| Step: 8
Training loss: 2.3441557469426115
Validation loss: 2.5290038021028916

Epoch: 5| Step: 9
Training loss: 2.689274579052062
Validation loss: 2.5652162875406312

Epoch: 5| Step: 10
Training loss: 3.122593525325039
Validation loss: 2.5347331581511003

Epoch: 144| Step: 0
Training loss: 2.77453402481761
Validation loss: 2.542971169508536

Epoch: 5| Step: 1
Training loss: 2.9065374416825156
Validation loss: 2.5750348825597906

Epoch: 5| Step: 2
Training loss: 3.3140389088641267
Validation loss: 2.5657293069001517

Epoch: 5| Step: 3
Training loss: 2.857349115828614
Validation loss: 2.5282257489148483

Epoch: 5| Step: 4
Training loss: 2.45236806672124
Validation loss: 2.5738413892955396

Epoch: 5| Step: 5
Training loss: 2.394213308412686
Validation loss: 2.542968541317281

Epoch: 5| Step: 6
Training loss: 2.0764622740888194
Validation loss: 2.5531918784923207

Epoch: 5| Step: 7
Training loss: 2.6822541070672536
Validation loss: 2.5251617255575125

Epoch: 5| Step: 8
Training loss: 2.396159429057351
Validation loss: 2.524887339481756

Epoch: 5| Step: 9
Training loss: 2.2942255010611396
Validation loss: 2.529654268908429

Epoch: 5| Step: 10
Training loss: 2.7452855012767814
Validation loss: 2.525566337644699

Epoch: 145| Step: 0
Training loss: 2.322234208878646
Validation loss: 2.5273610366925188

Epoch: 5| Step: 1
Training loss: 3.2166053515768716
Validation loss: 2.536177024512956

Epoch: 5| Step: 2
Training loss: 2.696212662467937
Validation loss: 2.5139003399042905

Epoch: 5| Step: 3
Training loss: 2.4878173587340977
Validation loss: 2.538569219362797

Epoch: 5| Step: 4
Training loss: 2.9477163365819563
Validation loss: 2.5230999960303033

Epoch: 5| Step: 5
Training loss: 2.655850279408559
Validation loss: 2.540750343070212

Epoch: 5| Step: 6
Training loss: 2.627362323642022
Validation loss: 2.545726703729335

Epoch: 5| Step: 7
Training loss: 2.5628269266132517
Validation loss: 2.5099170977306087

Epoch: 5| Step: 8
Training loss: 2.3128206185439484
Validation loss: 2.5320838619188706

Epoch: 5| Step: 9
Training loss: 2.4777296907902966
Validation loss: 2.525337212011532

Epoch: 5| Step: 10
Training loss: 2.553595446569881
Validation loss: 2.516274204048388

Epoch: 146| Step: 0
Training loss: 2.3455054257797103
Validation loss: 2.538391656719501

Epoch: 5| Step: 1
Training loss: 2.492745937813527
Validation loss: 2.536392363337472

Epoch: 5| Step: 2
Training loss: 2.464939411803772
Validation loss: 2.5653445325116473

Epoch: 5| Step: 3
Training loss: 2.602394955995059
Validation loss: 2.5489477343027347

Epoch: 5| Step: 4
Training loss: 2.96854921967019
Validation loss: 2.537534507469549

Epoch: 5| Step: 5
Training loss: 3.545404473864834
Validation loss: 2.5365897820484786

Epoch: 5| Step: 6
Training loss: 2.878898796579141
Validation loss: 2.5384600564676636

Epoch: 5| Step: 7
Training loss: 1.920204118567636
Validation loss: 2.5329601446357377

Epoch: 5| Step: 8
Training loss: 2.1696749734716105
Validation loss: 2.5314949521762307

Epoch: 5| Step: 9
Training loss: 2.4155974708557784
Validation loss: 2.5503309296132466

Epoch: 5| Step: 10
Training loss: 2.7088844814461135
Validation loss: 2.533131270885803

Epoch: 147| Step: 0
Training loss: 2.7744489517891626
Validation loss: 2.520553414337677

Epoch: 5| Step: 1
Training loss: 2.8288762059126777
Validation loss: 2.522026782923242

Epoch: 5| Step: 2
Training loss: 2.5506950702684357
Validation loss: 2.5385687507801973

Epoch: 5| Step: 3
Training loss: 2.3821649390639426
Validation loss: 2.525114495219689

Epoch: 5| Step: 4
Training loss: 2.737965869019289
Validation loss: 2.543070495403814

Epoch: 5| Step: 5
Training loss: 3.1825199492758975
Validation loss: 2.5469269904789043

Epoch: 5| Step: 6
Training loss: 2.473181308725189
Validation loss: 2.555169641469781

Epoch: 5| Step: 7
Training loss: 2.711121566635913
Validation loss: 2.5378874330975436

Epoch: 5| Step: 8
Training loss: 2.7430517676819566
Validation loss: 2.514465935314184

Epoch: 5| Step: 9
Training loss: 2.0895943466104208
Validation loss: 2.5136096820218747

Epoch: 5| Step: 10
Training loss: 2.572290372620844
Validation loss: 2.515752221637384

Epoch: 148| Step: 0
Training loss: 2.85164895122591
Validation loss: 2.533266472325445

Epoch: 5| Step: 1
Training loss: 3.114156908593845
Validation loss: 2.53970339931889

Epoch: 5| Step: 2
Training loss: 2.1957809654327405
Validation loss: 2.5305876377352834

Epoch: 5| Step: 3
Training loss: 3.536556341791686
Validation loss: 2.532321265209014

Epoch: 5| Step: 4
Training loss: 2.306717731630901
Validation loss: 2.5155964898616316

Epoch: 5| Step: 5
Training loss: 2.624292005701531
Validation loss: 2.5629141798229123

Epoch: 5| Step: 6
Training loss: 2.465038164938233
Validation loss: 2.519280803646893

Epoch: 5| Step: 7
Training loss: 2.3372171526640986
Validation loss: 2.5269919413353485

Epoch: 5| Step: 8
Training loss: 2.528231952606972
Validation loss: 2.5187278225253507

Epoch: 5| Step: 9
Training loss: 1.8193966767865195
Validation loss: 2.549299151280549

Epoch: 5| Step: 10
Training loss: 2.6593562196097573
Validation loss: 2.5229109657941056

Epoch: 149| Step: 0
Training loss: 3.5506664295327766
Validation loss: 2.5102907507564614

Epoch: 5| Step: 1
Training loss: 2.197681167303974
Validation loss: 2.5437455631316275

Epoch: 5| Step: 2
Training loss: 2.6442401224251033
Validation loss: 2.538572648900054

Epoch: 5| Step: 3
Training loss: 2.584372147508959
Validation loss: 2.532784154423795

Epoch: 5| Step: 4
Training loss: 2.0825011562238873
Validation loss: 2.537583547384973

Epoch: 5| Step: 5
Training loss: 2.6671059862495956
Validation loss: 2.4975753039277775

Epoch: 5| Step: 6
Training loss: 2.602770184243804
Validation loss: 2.5489459229205855

Epoch: 5| Step: 7
Training loss: 2.5718914156606565
Validation loss: 2.5240778053363844

Epoch: 5| Step: 8
Training loss: 2.696844842947698
Validation loss: 2.55674434962132

Epoch: 5| Step: 9
Training loss: 2.0392170697670697
Validation loss: 2.5235995704739964

Epoch: 5| Step: 10
Training loss: 2.8140204664243864
Validation loss: 2.53063426143024

Epoch: 150| Step: 0
Training loss: 2.8702854809348546
Validation loss: 2.5364778687261618

Epoch: 5| Step: 1
Training loss: 2.4349746337760005
Validation loss: 2.5139081147415308

Epoch: 5| Step: 2
Training loss: 2.7287837820369107
Validation loss: 2.5313193421745077

Epoch: 5| Step: 3
Training loss: 2.7265499081908384
Validation loss: 2.5313201756828922

Epoch: 5| Step: 4
Training loss: 2.6943902690811403
Validation loss: 2.5248426211060213

Epoch: 5| Step: 5
Training loss: 2.228825219169278
Validation loss: 2.545445821120807

Epoch: 5| Step: 6
Training loss: 2.9820554017229983
Validation loss: 2.546095581293669

Epoch: 5| Step: 7
Training loss: 2.6735347478180507
Validation loss: 2.553593009017589

Epoch: 5| Step: 8
Training loss: 3.0048386970681054
Validation loss: 2.5390412461469576

Epoch: 5| Step: 9
Training loss: 1.924539471319375
Validation loss: 2.555348292558745

Epoch: 5| Step: 10
Training loss: 2.560332614480244
Validation loss: 2.541387005662151

Epoch: 151| Step: 0
Training loss: 2.6431461014246946
Validation loss: 2.5417124822943116

Epoch: 5| Step: 1
Training loss: 2.6314588740210367
Validation loss: 2.5578469851259378

Epoch: 5| Step: 2
Training loss: 2.94087025899631
Validation loss: 2.5392070608580446

Epoch: 5| Step: 3
Training loss: 2.227575988329682
Validation loss: 2.5345440204674956

Epoch: 5| Step: 4
Training loss: 2.986875754542075
Validation loss: 2.540869997652388

Epoch: 5| Step: 5
Training loss: 3.1559455649222534
Validation loss: 2.5363721524414258

Epoch: 5| Step: 6
Training loss: 1.823556130284075
Validation loss: 2.549960246330195

Epoch: 5| Step: 7
Training loss: 2.7226908392877722
Validation loss: 2.550313874008578

Epoch: 5| Step: 8
Training loss: 2.469905631081182
Validation loss: 2.5169997364916417

Epoch: 5| Step: 9
Training loss: 2.5939399006277783
Validation loss: 2.5641701350683754

Epoch: 5| Step: 10
Training loss: 2.407399386069256
Validation loss: 2.546348118168217

Epoch: 152| Step: 0
Training loss: 2.2212876328182225
Validation loss: 2.5449236741359975

Epoch: 5| Step: 1
Training loss: 2.5222304914939238
Validation loss: 2.530979125289548

Epoch: 5| Step: 2
Training loss: 2.10312466897721
Validation loss: 2.547071830672395

Epoch: 5| Step: 3
Training loss: 2.7588437667419248
Validation loss: 2.550000365102614

Epoch: 5| Step: 4
Training loss: 2.18952488505144
Validation loss: 2.5439862038239314

Epoch: 5| Step: 5
Training loss: 2.207318258612905
Validation loss: 2.558039068024006

Epoch: 5| Step: 6
Training loss: 3.44787889596279
Validation loss: 2.5232818249700877

Epoch: 5| Step: 7
Training loss: 2.4167304743093143
Validation loss: 2.5361177407359086

Epoch: 5| Step: 8
Training loss: 2.8274163470048594
Validation loss: 2.535634550233398

Epoch: 5| Step: 9
Training loss: 2.8958127869533485
Validation loss: 2.5124647248326957

Epoch: 5| Step: 10
Training loss: 3.000688632766317
Validation loss: 2.5246619494636686

Epoch: 153| Step: 0
Training loss: 3.472623020352122
Validation loss: 2.5617441282597166

Epoch: 5| Step: 1
Training loss: 2.873733573292513
Validation loss: 2.5459685044551557

Epoch: 5| Step: 2
Training loss: 2.834860857420099
Validation loss: 2.5318620124955413

Epoch: 5| Step: 3
Training loss: 2.0587199858265097
Validation loss: 2.546588325182443

Epoch: 5| Step: 4
Training loss: 1.9516229575866086
Validation loss: 2.549988865893396

Epoch: 5| Step: 5
Training loss: 2.5385521008936207
Validation loss: 2.5034789674491384

Epoch: 5| Step: 6
Training loss: 2.3107534462947337
Validation loss: 2.549689440924743

Epoch: 5| Step: 7
Training loss: 2.112894244904114
Validation loss: 2.5428814384777767

Epoch: 5| Step: 8
Training loss: 2.6547361660201823
Validation loss: 2.532717045813052

Epoch: 5| Step: 9
Training loss: 2.815877285407624
Validation loss: 2.5278409229324628

Epoch: 5| Step: 10
Training loss: 2.7490983698712936
Validation loss: 2.552717734152364

Epoch: 154| Step: 0
Training loss: 3.1536148703976927
Validation loss: 2.5596917524353313

Epoch: 5| Step: 1
Training loss: 2.878029595366705
Validation loss: 2.5334198216304715

Epoch: 5| Step: 2
Training loss: 2.5355740571728442
Validation loss: 2.5296770746442565

Epoch: 5| Step: 3
Training loss: 2.0255210488684585
Validation loss: 2.5187481241115646

Epoch: 5| Step: 4
Training loss: 2.677911731681196
Validation loss: 2.5263861927519287

Epoch: 5| Step: 5
Training loss: 2.8395116052969764
Validation loss: 2.5460395894852517

Epoch: 5| Step: 6
Training loss: 2.3118703861401944
Validation loss: 2.564204430755475

Epoch: 5| Step: 7
Training loss: 2.182668964360697
Validation loss: 2.548285949019043

Epoch: 5| Step: 8
Training loss: 3.1245167167803634
Validation loss: 2.549982943348116

Epoch: 5| Step: 9
Training loss: 2.575131707387855
Validation loss: 2.55304611726228

Epoch: 5| Step: 10
Training loss: 2.2520137887874747
Validation loss: 2.5348349155426058

Epoch: 155| Step: 0
Training loss: 2.2628082655503685
Validation loss: 2.50576320975168

Epoch: 5| Step: 1
Training loss: 2.491690559230127
Validation loss: 2.5677638809281764

Epoch: 5| Step: 2
Training loss: 2.5813138718357442
Validation loss: 2.5154156489167727

Epoch: 5| Step: 3
Training loss: 2.6644896223596657
Validation loss: 2.520761287645805

Epoch: 5| Step: 4
Training loss: 2.5828385238121045
Validation loss: 2.538022310468021

Epoch: 5| Step: 5
Training loss: 3.257674619103356
Validation loss: 2.5436995324987484

Epoch: 5| Step: 6
Training loss: 2.72477528056716
Validation loss: 2.506960461660158

Epoch: 5| Step: 7
Training loss: 2.616065852523359
Validation loss: 2.511612373326644

Epoch: 5| Step: 8
Training loss: 2.639136893904764
Validation loss: 2.5564895450250247

Epoch: 5| Step: 9
Training loss: 1.9629110306775162
Validation loss: 2.5236110944389343

Epoch: 5| Step: 10
Training loss: 2.648660025911466
Validation loss: 2.569205278438391

Epoch: 156| Step: 0
Training loss: 3.1516660129567287
Validation loss: 2.529875841740092

Epoch: 5| Step: 1
Training loss: 2.5928056215634325
Validation loss: 2.5203980260099765

Epoch: 5| Step: 2
Training loss: 2.021474231934094
Validation loss: 2.5313480980551746

Epoch: 5| Step: 3
Training loss: 2.227850397638179
Validation loss: 2.533632656747285

Epoch: 5| Step: 4
Training loss: 2.882313093228253
Validation loss: 2.5614023236164853

Epoch: 5| Step: 5
Training loss: 2.8809182991855273
Validation loss: 2.5558317447466985

Epoch: 5| Step: 6
Training loss: 2.9515580152535077
Validation loss: 2.5386843911110013

Epoch: 5| Step: 7
Training loss: 2.6671091149761694
Validation loss: 2.5431155777390697

Epoch: 5| Step: 8
Training loss: 2.3896687907796896
Validation loss: 2.524756649067777

Epoch: 5| Step: 9
Training loss: 2.5235996253307946
Validation loss: 2.5386909146069057

Epoch: 5| Step: 10
Training loss: 2.5009355701809453
Validation loss: 2.529050085004082

Epoch: 157| Step: 0
Training loss: 2.3543192271084066
Validation loss: 2.542011863577476

Epoch: 5| Step: 1
Training loss: 2.9469339374946983
Validation loss: 2.5472587861483644

Epoch: 5| Step: 2
Training loss: 2.433470500929494
Validation loss: 2.5268233722528595

Epoch: 5| Step: 3
Training loss: 2.838241103938655
Validation loss: 2.532570526252443

Epoch: 5| Step: 4
Training loss: 2.5952075401913928
Validation loss: 2.547857346616972

Epoch: 5| Step: 5
Training loss: 2.760906958073766
Validation loss: 2.5378515140186995

Epoch: 5| Step: 6
Training loss: 2.1621715671102786
Validation loss: 2.5229033487677923

Epoch: 5| Step: 7
Training loss: 2.6627595909260386
Validation loss: 2.561741687953287

Epoch: 5| Step: 8
Training loss: 2.130347871446174
Validation loss: 2.5193285829484915

Epoch: 5| Step: 9
Training loss: 2.563439731878276
Validation loss: 2.552483817833608

Epoch: 5| Step: 10
Training loss: 3.3044981845891708
Validation loss: 2.528153827360459

Epoch: 158| Step: 0
Training loss: 1.7744354935371665
Validation loss: 2.528173033141642

Epoch: 5| Step: 1
Training loss: 2.9339555499474397
Validation loss: 2.558703034813117

Epoch: 5| Step: 2
Training loss: 2.991524645339616
Validation loss: 2.530235960441463

Epoch: 5| Step: 3
Training loss: 3.2503296611557673
Validation loss: 2.5419152052742313

Epoch: 5| Step: 4
Training loss: 2.512771884005021
Validation loss: 2.554933070858275

Epoch: 5| Step: 5
Training loss: 2.6774491729328713
Validation loss: 2.5461646661661526

Epoch: 5| Step: 6
Training loss: 2.3787428826422565
Validation loss: 2.5217500865654796

Epoch: 5| Step: 7
Training loss: 2.472318749799538
Validation loss: 2.527825235823344

Epoch: 5| Step: 8
Training loss: 2.7506869931852953
Validation loss: 2.547459444517022

Epoch: 5| Step: 9
Training loss: 2.387624715373759
Validation loss: 2.543133823755668

Epoch: 5| Step: 10
Training loss: 1.8665850317792723
Validation loss: 2.5314086272885525

Epoch: 159| Step: 0
Training loss: 2.3611411248587033
Validation loss: 2.555646320234896

Epoch: 5| Step: 1
Training loss: 2.7741534961018437
Validation loss: 2.5523244001001086

Epoch: 5| Step: 2
Training loss: 3.13948455904927
Validation loss: 2.5155781837284827

Epoch: 5| Step: 3
Training loss: 2.057340004912408
Validation loss: 2.544359027508138

Epoch: 5| Step: 4
Training loss: 2.143897013169283
Validation loss: 2.54860783672753

Epoch: 5| Step: 5
Training loss: 2.69048462965679
Validation loss: 2.5187890474022607

Epoch: 5| Step: 6
Training loss: 2.6737624969119036
Validation loss: 2.5249446801309134

Epoch: 5| Step: 7
Training loss: 2.586888533135402
Validation loss: 2.5362557496661533

Epoch: 5| Step: 8
Training loss: 2.3776981687538803
Validation loss: 2.5361719137576784

Epoch: 5| Step: 9
Training loss: 3.3503099782069783
Validation loss: 2.5214464938054

Epoch: 5| Step: 10
Training loss: 2.319282380138214
Validation loss: 2.5267936372972057

Epoch: 160| Step: 0
Training loss: 2.9833284310526147
Validation loss: 2.511487086611638

Epoch: 5| Step: 1
Training loss: 3.045485272504851
Validation loss: 2.5429980863857424

Epoch: 5| Step: 2
Training loss: 1.7731321634948622
Validation loss: 2.5414849853000447

Epoch: 5| Step: 3
Training loss: 2.8343238968958095
Validation loss: 2.5257767266357773

Epoch: 5| Step: 4
Training loss: 2.9675889806735927
Validation loss: 2.5320657002966063

Epoch: 5| Step: 5
Training loss: 2.3402555736943604
Validation loss: 2.53825928963528

Epoch: 5| Step: 6
Training loss: 2.171863363769975
Validation loss: 2.548170046209981

Epoch: 5| Step: 7
Training loss: 2.4763677382075557
Validation loss: 2.5562420206241008

Epoch: 5| Step: 8
Training loss: 2.54206121748857
Validation loss: 2.545011876578566

Epoch: 5| Step: 9
Training loss: 2.701327393220557
Validation loss: 2.5623932212674205

Epoch: 5| Step: 10
Training loss: 2.417055120708456
Validation loss: 2.545311419716544

Epoch: 161| Step: 0
Training loss: 2.6671383460442573
Validation loss: 2.511777338943156

Epoch: 5| Step: 1
Training loss: 3.0257899868556084
Validation loss: 2.518319107605865

Epoch: 5| Step: 2
Training loss: 2.1808047695521973
Validation loss: 2.523951415740703

Epoch: 5| Step: 3
Training loss: 2.4051141411230015
Validation loss: 2.5397891949748184

Epoch: 5| Step: 4
Training loss: 2.2804558821887193
Validation loss: 2.553896710319182

Epoch: 5| Step: 5
Training loss: 3.303545959845795
Validation loss: 2.5426311555833196

Epoch: 5| Step: 6
Training loss: 2.626956936858294
Validation loss: 2.5047993456067608

Epoch: 5| Step: 7
Training loss: 2.318434857856591
Validation loss: 2.5601940208982676

Epoch: 5| Step: 8
Training loss: 2.676546530333543
Validation loss: 2.5585310087172513

Epoch: 5| Step: 9
Training loss: 2.5866531349922783
Validation loss: 2.5557380817366617

Epoch: 5| Step: 10
Training loss: 2.050692892441803
Validation loss: 2.556544839669123

Epoch: 162| Step: 0
Training loss: 1.825252199383518
Validation loss: 2.5327778029685675

Epoch: 5| Step: 1
Training loss: 3.589114043380907
Validation loss: 2.537904012594239

Epoch: 5| Step: 2
Training loss: 2.4435856483393956
Validation loss: 2.549822558889454

Epoch: 5| Step: 3
Training loss: 2.5310601057242916
Validation loss: 2.5344294940662504

Epoch: 5| Step: 4
Training loss: 2.7148065139083086
Validation loss: 2.551246505533699

Epoch: 5| Step: 5
Training loss: 2.6492484772481535
Validation loss: 2.5330860169282627

Epoch: 5| Step: 6
Training loss: 2.479552380558751
Validation loss: 2.558946129490593

Epoch: 5| Step: 7
Training loss: 2.716171708293105
Validation loss: 2.5573238474952587

Epoch: 5| Step: 8
Training loss: 1.866793986076998
Validation loss: 2.5686987458776853

Epoch: 5| Step: 9
Training loss: 2.800229410582656
Validation loss: 2.5663212243143687

Epoch: 5| Step: 10
Training loss: 2.6102278908811742
Validation loss: 2.558519380514552

Epoch: 163| Step: 0
Training loss: 2.904735047278022
Validation loss: 2.5331022270768324

Epoch: 5| Step: 1
Training loss: 2.287306597095416
Validation loss: 2.521749281408887

Epoch: 5| Step: 2
Training loss: 2.1684814946513296
Validation loss: 2.5396525308448865

Epoch: 5| Step: 3
Training loss: 2.6665981005754644
Validation loss: 2.551604682146626

Epoch: 5| Step: 4
Training loss: 2.189308726630506
Validation loss: 2.5794395240288672

Epoch: 5| Step: 5
Training loss: 2.542370422572224
Validation loss: 2.5424496839690605

Epoch: 5| Step: 6
Training loss: 2.89730771813244
Validation loss: 2.5337854729398908

Epoch: 5| Step: 7
Training loss: 2.870023151530284
Validation loss: 2.532377874161732

Epoch: 5| Step: 8
Training loss: 2.102680121835745
Validation loss: 2.5384781491133195

Epoch: 5| Step: 9
Training loss: 3.1360656134300315
Validation loss: 2.54037107762201

Epoch: 5| Step: 10
Training loss: 2.59284148333496
Validation loss: 2.5252575520726124

Epoch: 164| Step: 0
Training loss: 3.0661219762737217
Validation loss: 2.527336030695877

Epoch: 5| Step: 1
Training loss: 2.4574003442716386
Validation loss: 2.520302306661949

Epoch: 5| Step: 2
Training loss: 2.3739475126690808
Validation loss: 2.5339188355603266

Epoch: 5| Step: 3
Training loss: 2.9097069310221735
Validation loss: 2.5553635338127454

Epoch: 5| Step: 4
Training loss: 2.1782209596881703
Validation loss: 2.5021383180111507

Epoch: 5| Step: 5
Training loss: 2.3637326652742523
Validation loss: 2.505924027879982

Epoch: 5| Step: 6
Training loss: 1.7372173353838825
Validation loss: 2.5156414887729857

Epoch: 5| Step: 7
Training loss: 2.9071376634459667
Validation loss: 2.5447846322302006

Epoch: 5| Step: 8
Training loss: 3.33012666638925
Validation loss: 2.5224507254436443

Epoch: 5| Step: 9
Training loss: 2.433162154965669
Validation loss: 2.527861317651426

Epoch: 5| Step: 10
Training loss: 2.3125057735886543
Validation loss: 2.5245380181637698

Epoch: 165| Step: 0
Training loss: 2.296884238295888
Validation loss: 2.529070770018263

Epoch: 5| Step: 1
Training loss: 2.5242924142594867
Validation loss: 2.5615011119651117

Epoch: 5| Step: 2
Training loss: 3.3530807790835535
Validation loss: 2.549625901358427

Epoch: 5| Step: 3
Training loss: 2.550051340820477
Validation loss: 2.544325174671275

Epoch: 5| Step: 4
Training loss: 2.3394087194386732
Validation loss: 2.5125811227489123

Epoch: 5| Step: 5
Training loss: 2.669279298846459
Validation loss: 2.551223681587869

Epoch: 5| Step: 6
Training loss: 2.3250195574194237
Validation loss: 2.52669495910444

Epoch: 5| Step: 7
Training loss: 2.81044864018951
Validation loss: 2.543813788686594

Epoch: 5| Step: 8
Training loss: 2.5942223360105445
Validation loss: 2.5225606492279704

Epoch: 5| Step: 9
Training loss: 2.4877369523410167
Validation loss: 2.5654280236605804

Epoch: 5| Step: 10
Training loss: 2.5109053224544486
Validation loss: 2.5451604700302277

Epoch: 166| Step: 0
Training loss: 2.3702192877872053
Validation loss: 2.5323981716020443

Epoch: 5| Step: 1
Training loss: 2.290006475481098
Validation loss: 2.555621379339264

Epoch: 5| Step: 2
Training loss: 2.5812773880879503
Validation loss: 2.5334476636881726

Epoch: 5| Step: 3
Training loss: 2.7321053813141454
Validation loss: 2.5249812818410318

Epoch: 5| Step: 4
Training loss: 2.9666784186255466
Validation loss: 2.5445540791065873

Epoch: 5| Step: 5
Training loss: 2.1972211367023977
Validation loss: 2.5734538629772254

Epoch: 5| Step: 6
Training loss: 2.7696268040969287
Validation loss: 2.5454348532555957

Epoch: 5| Step: 7
Training loss: 2.5622150914046196
Validation loss: 2.5532662194094

Epoch: 5| Step: 8
Training loss: 2.3288215772815777
Validation loss: 2.545504015480584

Epoch: 5| Step: 9
Training loss: 2.592988051675675
Validation loss: 2.550480840525739

Epoch: 5| Step: 10
Training loss: 2.7422104532960296
Validation loss: 2.5262366989719283

Epoch: 167| Step: 0
Training loss: 2.7966901835323155
Validation loss: 2.564931811600294

Epoch: 5| Step: 1
Training loss: 2.5027264986231317
Validation loss: 2.547370801487303

Epoch: 5| Step: 2
Training loss: 1.7874732142222132
Validation loss: 2.5480848486597116

Epoch: 5| Step: 3
Training loss: 2.877594979157892
Validation loss: 2.545033324843197

Epoch: 5| Step: 4
Training loss: 2.3844568800959913
Validation loss: 2.5537659803554904

Epoch: 5| Step: 5
Training loss: 2.329922692485784
Validation loss: 2.5318098291045463

Epoch: 5| Step: 6
Training loss: 3.398260984550217
Validation loss: 2.553744830553241

Epoch: 5| Step: 7
Training loss: 2.6475138896401287
Validation loss: 2.5238530957053724

Epoch: 5| Step: 8
Training loss: 2.2707370306003933
Validation loss: 2.5263116930509173

Epoch: 5| Step: 9
Training loss: 2.062912408460541
Validation loss: 2.552584664730017

Epoch: 5| Step: 10
Training loss: 3.0613394893402694
Validation loss: 2.5384968304047053

Epoch: 168| Step: 0
Training loss: 3.381049350842071
Validation loss: 2.531828882606814

Epoch: 5| Step: 1
Training loss: 2.6713321424322456
Validation loss: 2.5439422600475337

Epoch: 5| Step: 2
Training loss: 2.5269824186859995
Validation loss: 2.532753970951928

Epoch: 5| Step: 3
Training loss: 2.881420430006355
Validation loss: 2.528701678367255

Epoch: 5| Step: 4
Training loss: 2.6101122517033053
Validation loss: 2.5418973620003014

Epoch: 5| Step: 5
Training loss: 2.389873810473384
Validation loss: 2.5238746156024865

Epoch: 5| Step: 6
Training loss: 2.576470693938678
Validation loss: 2.5452792172770855

Epoch: 5| Step: 7
Training loss: 2.5993004664792148
Validation loss: 2.5507011288552017

Epoch: 5| Step: 8
Training loss: 2.5325535372980776
Validation loss: 2.5490818564839186

Epoch: 5| Step: 9
Training loss: 1.7748431714044637
Validation loss: 2.548593309500922

Epoch: 5| Step: 10
Training loss: 2.402643944817381
Validation loss: 2.550330876336649

Epoch: 169| Step: 0
Training loss: 2.6781536194241395
Validation loss: 2.5363834647411534

Epoch: 5| Step: 1
Training loss: 2.6026910390370652
Validation loss: 2.529886233586319

Epoch: 5| Step: 2
Training loss: 1.5583736101681163
Validation loss: 2.524864210751776

Epoch: 5| Step: 3
Training loss: 2.5871477781126955
Validation loss: 2.527569469880981

Epoch: 5| Step: 4
Training loss: 2.196526351329517
Validation loss: 2.5394218610796297

Epoch: 5| Step: 5
Training loss: 2.7783848438243877
Validation loss: 2.5392862917685464

Epoch: 5| Step: 6
Training loss: 2.933453146337158
Validation loss: 2.553768393398938

Epoch: 5| Step: 7
Training loss: 2.7455540176827102
Validation loss: 2.5249929274284626

Epoch: 5| Step: 8
Training loss: 2.2439725462650193
Validation loss: 2.535496656122516

Epoch: 5| Step: 9
Training loss: 3.0150001945938376
Validation loss: 2.560822602916319

Epoch: 5| Step: 10
Training loss: 2.7853629743089363
Validation loss: 2.554348258804795

Epoch: 170| Step: 0
Training loss: 2.698709486798185
Validation loss: 2.532976510948116

Epoch: 5| Step: 1
Training loss: 2.046069736638392
Validation loss: 2.557627410499249

Epoch: 5| Step: 2
Training loss: 3.200063889580941
Validation loss: 2.564760918974402

Epoch: 5| Step: 3
Training loss: 2.8398111753418886
Validation loss: 2.550174077985079

Epoch: 5| Step: 4
Training loss: 2.749155348328272
Validation loss: 2.526263461298972

Epoch: 5| Step: 5
Training loss: 2.396576398529886
Validation loss: 2.5191866354831203

Epoch: 5| Step: 6
Training loss: 2.8167066691641014
Validation loss: 2.545088519359596

Epoch: 5| Step: 7
Training loss: 2.019424288073517
Validation loss: 2.5576853106548727

Epoch: 5| Step: 8
Training loss: 2.7866640009099206
Validation loss: 2.556181252528391

Epoch: 5| Step: 9
Training loss: 2.0881607837231306
Validation loss: 2.54845895941074

Epoch: 5| Step: 10
Training loss: 2.384808814105228
Validation loss: 2.5424213556518023

Epoch: 171| Step: 0
Training loss: 2.8296892255654593
Validation loss: 2.5562209206431525

Epoch: 5| Step: 1
Training loss: 2.2666998056719385
Validation loss: 2.5372202237837858

Epoch: 5| Step: 2
Training loss: 2.7262671018236344
Validation loss: 2.532744950254974

Epoch: 5| Step: 3
Training loss: 3.0095485680776384
Validation loss: 2.5480622272968705

Epoch: 5| Step: 4
Training loss: 2.7130998677687064
Validation loss: 2.538047806117921

Epoch: 5| Step: 5
Training loss: 2.397120707624079
Validation loss: 2.5149001576140533

Epoch: 5| Step: 6
Training loss: 2.524562242538095
Validation loss: 2.564801708825173

Epoch: 5| Step: 7
Training loss: 2.69209694823547
Validation loss: 2.5400175463259584

Epoch: 5| Step: 8
Training loss: 2.319555499475907
Validation loss: 2.5216817856002556

Epoch: 5| Step: 9
Training loss: 2.214740838245148
Validation loss: 2.539019833593582

Epoch: 5| Step: 10
Training loss: 2.331593125687598
Validation loss: 2.538408609630567

Epoch: 172| Step: 0
Training loss: 2.3600347745887276
Validation loss: 2.542300471240231

Epoch: 5| Step: 1
Training loss: 3.0796752743645275
Validation loss: 2.5338364278344008

Epoch: 5| Step: 2
Training loss: 2.612935726205956
Validation loss: 2.5601800801180734

Epoch: 5| Step: 3
Training loss: 2.6035930052559717
Validation loss: 2.5256405253816925

Epoch: 5| Step: 4
Training loss: 2.3044559685739694
Validation loss: 2.5292714158100553

Epoch: 5| Step: 5
Training loss: 2.1655543724532222
Validation loss: 2.538456361169056

Epoch: 5| Step: 6
Training loss: 2.655195138947628
Validation loss: 2.5337626601697343

Epoch: 5| Step: 7
Training loss: 2.75759515094956
Validation loss: 2.5458490220339325

Epoch: 5| Step: 8
Training loss: 2.052476280530694
Validation loss: 2.52519036424939

Epoch: 5| Step: 9
Training loss: 2.8647170896802794
Validation loss: 2.545455319515753

Epoch: 5| Step: 10
Training loss: 2.6870674849831664
Validation loss: 2.548202278516982

Epoch: 173| Step: 0
Training loss: 2.9106879036699898
Validation loss: 2.5344430843837125

Epoch: 5| Step: 1
Training loss: 1.9867117032231005
Validation loss: 2.5597162350299936

Epoch: 5| Step: 2
Training loss: 2.7692600650134365
Validation loss: 2.5358000645250254

Epoch: 5| Step: 3
Training loss: 2.864435439482428
Validation loss: 2.5371057474557754

Epoch: 5| Step: 4
Training loss: 2.6776310895926505
Validation loss: 2.5203076560883884

Epoch: 5| Step: 5
Training loss: 1.597305893664448
Validation loss: 2.536443078878172

Epoch: 5| Step: 6
Training loss: 2.7422876584272666
Validation loss: 2.544882038821378

Epoch: 5| Step: 7
Training loss: 2.316555487986087
Validation loss: 2.5407775004094337

Epoch: 5| Step: 8
Training loss: 2.620091708667583
Validation loss: 2.548114786141057

Epoch: 5| Step: 9
Training loss: 3.2565082528179454
Validation loss: 2.540432714342949

Epoch: 5| Step: 10
Training loss: 2.1120958652702764
Validation loss: 2.538909353681299

Epoch: 174| Step: 0
Training loss: 2.2950496556846227
Validation loss: 2.5662103518471078

Epoch: 5| Step: 1
Training loss: 2.9058565263084235
Validation loss: 2.5284969155493853

Epoch: 5| Step: 2
Training loss: 2.2915689852154713
Validation loss: 2.5297985364137396

Epoch: 5| Step: 3
Training loss: 2.7999098524840678
Validation loss: 2.551961459342306

Epoch: 5| Step: 4
Training loss: 2.3117757126937684
Validation loss: 2.541000915138208

Epoch: 5| Step: 5
Training loss: 2.9503228350356197
Validation loss: 2.570065376227802

Epoch: 5| Step: 6
Training loss: 3.0287452653004805
Validation loss: 2.5507898239933615

Epoch: 5| Step: 7
Training loss: 2.83640253967335
Validation loss: 2.5307977237646453

Epoch: 5| Step: 8
Training loss: 1.9345820203693553
Validation loss: 2.5683433409627487

Epoch: 5| Step: 9
Training loss: 2.3638259638255645
Validation loss: 2.527711942553804

Epoch: 5| Step: 10
Training loss: 2.2300293818706396
Validation loss: 2.5441014684213674

Epoch: 175| Step: 0
Training loss: 2.3315246133930616
Validation loss: 2.538291368531967

Epoch: 5| Step: 1
Training loss: 2.752272620515039
Validation loss: 2.5661634923893604

Epoch: 5| Step: 2
Training loss: 2.505042236489816
Validation loss: 2.5144417543712416

Epoch: 5| Step: 3
Training loss: 2.281820565553696
Validation loss: 2.5584750034807135

Epoch: 5| Step: 4
Training loss: 2.193255889978591
Validation loss: 2.5484181051495245

Epoch: 5| Step: 5
Training loss: 2.709885890711993
Validation loss: 2.575201362225924

Epoch: 5| Step: 6
Training loss: 2.381737037973378
Validation loss: 2.5340568438573237

Epoch: 5| Step: 7
Training loss: 2.603433114051444
Validation loss: 2.519233819223649

Epoch: 5| Step: 8
Training loss: 2.0170297385176186
Validation loss: 2.5473823517637104

Epoch: 5| Step: 9
Training loss: 3.464001128427793
Validation loss: 2.522658043532196

Epoch: 5| Step: 10
Training loss: 2.6032314503165552
Validation loss: 2.530131732211062

Epoch: 176| Step: 0
Training loss: 2.653721671975189
Validation loss: 2.538175616361843

Epoch: 5| Step: 1
Training loss: 2.9770134211331554
Validation loss: 2.540709659490937

Epoch: 5| Step: 2
Training loss: 2.0256715908889382
Validation loss: 2.5169750808065756

Epoch: 5| Step: 3
Training loss: 2.594499227021213
Validation loss: 2.539657417565501

Epoch: 5| Step: 4
Training loss: 2.093960765649594
Validation loss: 2.5623211331773166

Epoch: 5| Step: 5
Training loss: 3.0799547363026845
Validation loss: 2.5450171297454527

Epoch: 5| Step: 6
Training loss: 3.059262023647778
Validation loss: 2.5478561899958674

Epoch: 5| Step: 7
Training loss: 2.550615056978273
Validation loss: 2.581481196869213

Epoch: 5| Step: 8
Training loss: 2.287643669911431
Validation loss: 2.5354312548041307

Epoch: 5| Step: 9
Training loss: 2.899265058060765
Validation loss: 2.5038006851001895

Epoch: 5| Step: 10
Training loss: 1.5521792781113641
Validation loss: 2.5594030745194027

Epoch: 177| Step: 0
Training loss: 2.681867063426585
Validation loss: 2.5259450207460197

Epoch: 5| Step: 1
Training loss: 2.3492828167576576
Validation loss: 2.5511262171677522

Epoch: 5| Step: 2
Training loss: 2.917427472387381
Validation loss: 2.533499049361827

Epoch: 5| Step: 3
Training loss: 1.9045100166175568
Validation loss: 2.5211362040678726

Epoch: 5| Step: 4
Training loss: 1.9287826949665599
Validation loss: 2.528336682990661

Epoch: 5| Step: 5
Training loss: 1.7453972368152262
Validation loss: 2.5234920508892786

Epoch: 5| Step: 6
Training loss: 2.7549579316681463
Validation loss: 2.5564278712486317

Epoch: 5| Step: 7
Training loss: 2.4865296814782964
Validation loss: 2.5664581724610764

Epoch: 5| Step: 8
Training loss: 3.4372820698407813
Validation loss: 2.5486883757308947

Epoch: 5| Step: 9
Training loss: 2.554276086186239
Validation loss: 2.547093237938136

Epoch: 5| Step: 10
Training loss: 2.799651488685577
Validation loss: 2.5416424160235325

Epoch: 178| Step: 0
Training loss: 2.704974649701876
Validation loss: 2.5300293033346914

Epoch: 5| Step: 1
Training loss: 2.866863845726986
Validation loss: 2.5480814802183014

Epoch: 5| Step: 2
Training loss: 2.4975743924384233
Validation loss: 2.549365592101945

Epoch: 5| Step: 3
Training loss: 2.7080036745201435
Validation loss: 2.520508511256363

Epoch: 5| Step: 4
Training loss: 2.2586919530303557
Validation loss: 2.5194800617563264

Epoch: 5| Step: 5
Training loss: 2.536062116963264
Validation loss: 2.550505783442496

Epoch: 5| Step: 6
Training loss: 2.1626333206622594
Validation loss: 2.5454718305846957

Epoch: 5| Step: 7
Training loss: 2.2105946628860575
Validation loss: 2.51068090219972

Epoch: 5| Step: 8
Training loss: 2.6468402018055497
Validation loss: 2.5099066916399213

Epoch: 5| Step: 9
Training loss: 2.5404573805202855
Validation loss: 2.572965897395557

Epoch: 5| Step: 10
Training loss: 2.760657898540831
Validation loss: 2.5479000235059353

Epoch: 179| Step: 0
Training loss: 2.4356448621089295
Validation loss: 2.5274754482452337

Epoch: 5| Step: 1
Training loss: 2.980367316323604
Validation loss: 2.502450306194015

Epoch: 5| Step: 2
Training loss: 2.3005074563190595
Validation loss: 2.520727426054594

Epoch: 5| Step: 3
Training loss: 2.899138908140037
Validation loss: 2.539250491418636

Epoch: 5| Step: 4
Training loss: 2.786142396693119
Validation loss: 2.5773932668056703

Epoch: 5| Step: 5
Training loss: 2.182458681499803
Validation loss: 2.524157981382162

Epoch: 5| Step: 6
Training loss: 2.695323999352734
Validation loss: 2.554625759637472

Epoch: 5| Step: 7
Training loss: 2.433619907783527
Validation loss: 2.5417948495007274

Epoch: 5| Step: 8
Training loss: 2.4808730869698117
Validation loss: 2.5655237001689

Epoch: 5| Step: 9
Training loss: 2.3858057451623975
Validation loss: 2.5605995910749164

Epoch: 5| Step: 10
Training loss: 2.5930728258174076
Validation loss: 2.542638001679122

Epoch: 180| Step: 0
Training loss: 2.696977626222586
Validation loss: 2.525271373978303

Epoch: 5| Step: 1
Training loss: 2.3697978819601415
Validation loss: 2.5599249685599834

Epoch: 5| Step: 2
Training loss: 2.5790907467055963
Validation loss: 2.5286972064167124

Epoch: 5| Step: 3
Training loss: 2.321232468842352
Validation loss: 2.546969409679773

Epoch: 5| Step: 4
Training loss: 3.224704900443805
Validation loss: 2.543005342804481

Epoch: 5| Step: 5
Training loss: 2.3706738070254216
Validation loss: 2.5523725351223185

Epoch: 5| Step: 6
Training loss: 2.602010968935084
Validation loss: 2.563183442983117

Epoch: 5| Step: 7
Training loss: 2.1030453126953197
Validation loss: 2.52868416766018

Epoch: 5| Step: 8
Training loss: 2.8454908135989263
Validation loss: 2.54615382624908

Epoch: 5| Step: 9
Training loss: 2.259516828419872
Validation loss: 2.523017770420681

Epoch: 5| Step: 10
Training loss: 2.460743633081814
Validation loss: 2.5498172532866543

Epoch: 181| Step: 0
Training loss: 1.9599055276212467
Validation loss: 2.5089881933638427

Epoch: 5| Step: 1
Training loss: 2.6691740784515874
Validation loss: 2.5390228960026486

Epoch: 5| Step: 2
Training loss: 2.497066684283148
Validation loss: 2.525336781072829

Epoch: 5| Step: 3
Training loss: 2.0535135723043525
Validation loss: 2.522001091767273

Epoch: 5| Step: 4
Training loss: 2.547477978432423
Validation loss: 2.517690938507594

Epoch: 5| Step: 5
Training loss: 2.706613219380215
Validation loss: 2.5310649361076147

Epoch: 5| Step: 6
Training loss: 2.9276716697650413
Validation loss: 2.533484354547836

Epoch: 5| Step: 7
Training loss: 2.6661477974905976
Validation loss: 2.541785576464785

Epoch: 5| Step: 8
Training loss: 2.4294564974466697
Validation loss: 2.490195898490273

Epoch: 5| Step: 9
Training loss: 2.3952777937174483
Validation loss: 2.5334407067441544

Epoch: 5| Step: 10
Training loss: 2.9071906423608125
Validation loss: 2.5498172532866543

Epoch: 182| Step: 0
Training loss: 2.2685088646900295
Validation loss: 2.538085002176404

Epoch: 5| Step: 1
Training loss: 2.2112024370925325
Validation loss: 2.5302242113215017

Epoch: 5| Step: 2
Training loss: 2.2026880791472347
Validation loss: 2.5220176018770606

Epoch: 5| Step: 3
Training loss: 3.176549013993907
Validation loss: 2.5611202718417143

Epoch: 5| Step: 4
Training loss: 2.2530466222159413
Validation loss: 2.5599109767424637

Epoch: 5| Step: 5
Training loss: 2.624341882222821
Validation loss: 2.521788589422964

Epoch: 5| Step: 6
Training loss: 2.518192947164043
Validation loss: 2.5471486369204874

Epoch: 5| Step: 7
Training loss: 2.351835216030625
Validation loss: 2.517018743214836

Epoch: 5| Step: 8
Training loss: 3.1596042448010238
Validation loss: 2.520521881164311

Epoch: 5| Step: 9
Training loss: 2.911458588101416
Validation loss: 2.5479133352044694

Epoch: 5| Step: 10
Training loss: 1.991415135875226
Validation loss: 2.512441172569486

Epoch: 183| Step: 0
Training loss: 2.716811179391485
Validation loss: 2.51341157519635

Epoch: 5| Step: 1
Training loss: 2.729260527959905
Validation loss: 2.536341536609503

Epoch: 5| Step: 2
Training loss: 2.5630418158136585
Validation loss: 2.547888320624176

Epoch: 5| Step: 3
Training loss: 2.5991967244156675
Validation loss: 2.5406357765662926

Epoch: 5| Step: 4
Training loss: 2.729498127229673
Validation loss: 2.5461685073480593

Epoch: 5| Step: 5
Training loss: 2.607869244890089
Validation loss: 2.5595234997474243

Epoch: 5| Step: 6
Training loss: 2.8172510496430894
Validation loss: 2.528903102594337

Epoch: 5| Step: 7
Training loss: 2.5081607184681665
Validation loss: 2.549594633233308

Epoch: 5| Step: 8
Training loss: 2.1749871001463945
Validation loss: 2.540910428445902

Epoch: 5| Step: 9
Training loss: 2.3421989903794826
Validation loss: 2.576839160422884

Epoch: 5| Step: 10
Training loss: 2.2283954771854297
Validation loss: 2.544020719711408

Epoch: 184| Step: 0
Training loss: 2.37931912852834
Validation loss: 2.541992469884557

Epoch: 5| Step: 1
Training loss: 2.696329649136534
Validation loss: 2.5527894125504003

Epoch: 5| Step: 2
Training loss: 2.5528337478267105
Validation loss: 2.542946006507234

Epoch: 5| Step: 3
Training loss: 3.037916423368743
Validation loss: 2.530381813786422

Epoch: 5| Step: 4
Training loss: 3.2359121604380428
Validation loss: 2.5484029460923994

Epoch: 5| Step: 5
Training loss: 1.8592154811102977
Validation loss: 2.553172678164695

Epoch: 5| Step: 6
Training loss: 2.6467195863822086
Validation loss: 2.525299962697925

Epoch: 5| Step: 7
Training loss: 2.380264771263302
Validation loss: 2.5473552920113827

Epoch: 5| Step: 8
Training loss: 2.395517466634898
Validation loss: 2.5478898550520235

Epoch: 5| Step: 9
Training loss: 2.1018879578162903
Validation loss: 2.522362954224519

Epoch: 5| Step: 10
Training loss: 2.507040885509734
Validation loss: 2.5322010740455205

Epoch: 185| Step: 0
Training loss: 2.5684147933956925
Validation loss: 2.52960261409651

Epoch: 5| Step: 1
Training loss: 2.672392321024041
Validation loss: 2.527552054786409

Epoch: 5| Step: 2
Training loss: 3.02995587282184
Validation loss: 2.5417834231064824

Epoch: 5| Step: 3
Training loss: 2.0790070691009164
Validation loss: 2.5386643701348466

Epoch: 5| Step: 4
Training loss: 2.7952382503774684
Validation loss: 2.5457239157462515

Epoch: 5| Step: 5
Training loss: 2.0730025179415703
Validation loss: 2.5550360254827464

Epoch: 5| Step: 6
Training loss: 2.7778235770794404
Validation loss: 2.549465837334544

Epoch: 5| Step: 7
Training loss: 2.5558800203404
Validation loss: 2.542275724121722

Epoch: 5| Step: 8
Training loss: 2.1340848041262075
Validation loss: 2.546091387085902

Epoch: 5| Step: 9
Training loss: 2.5677055890195675
Validation loss: 2.5669404490576935

Epoch: 5| Step: 10
Training loss: 2.3419521302592896
Validation loss: 2.5250109977811617

Epoch: 186| Step: 0
Training loss: 2.1447791562511407
Validation loss: 2.5520548772240432

Epoch: 5| Step: 1
Training loss: 3.014862122174521
Validation loss: 2.540701084778434

Epoch: 5| Step: 2
Training loss: 2.19336307080332
Validation loss: 2.528353589758389

Epoch: 5| Step: 3
Training loss: 2.8280570512059136
Validation loss: 2.5377977304146158

Epoch: 5| Step: 4
Training loss: 2.5709992856499873
Validation loss: 2.56526808618111

Epoch: 5| Step: 5
Training loss: 2.5652436245931156
Validation loss: 2.52665158667975

Epoch: 5| Step: 6
Training loss: 2.6315855342381007
Validation loss: 2.513612079815097

Epoch: 5| Step: 7
Training loss: 2.071114438765549
Validation loss: 2.535506324747705

Epoch: 5| Step: 8
Training loss: 2.6275547855955645
Validation loss: 2.5351570023592873

Epoch: 5| Step: 9
Training loss: 2.9408430190956922
Validation loss: 2.5026288403243395

Epoch: 5| Step: 10
Training loss: 2.107454230738063
Validation loss: 2.525071999242086

Epoch: 187| Step: 0
Training loss: 2.7967433791917222
Validation loss: 2.527973669218351

Epoch: 5| Step: 1
Training loss: 2.4781682437620876
Validation loss: 2.5558994962235277

Epoch: 5| Step: 2
Training loss: 1.9494996871771884
Validation loss: 2.566536711940186

Epoch: 5| Step: 3
Training loss: 2.8585006961444663
Validation loss: 2.5436851868721373

Epoch: 5| Step: 4
Training loss: 2.5667783795440586
Validation loss: 2.517833837796169

Epoch: 5| Step: 5
Training loss: 2.490364484192954
Validation loss: 2.502263097973917

Epoch: 5| Step: 6
Training loss: 2.5365148351330604
Validation loss: 2.536709547989239

Epoch: 5| Step: 7
Training loss: 2.1746358544704307
Validation loss: 2.5190023085943833

Epoch: 5| Step: 8
Training loss: 3.2196645085675453
Validation loss: 2.512615271658406

Epoch: 5| Step: 9
Training loss: 2.386869584981645
Validation loss: 2.5183189304744262

Epoch: 5| Step: 10
Training loss: 2.2373062859758037
Validation loss: 2.5296807614855252

Epoch: 188| Step: 0
Training loss: 2.8075020356820555
Validation loss: 2.521405450965885

Epoch: 5| Step: 1
Training loss: 2.6921448600699995
Validation loss: 2.5045115534797295

Epoch: 5| Step: 2
Training loss: 2.090343836194329
Validation loss: 2.528328153516898

Epoch: 5| Step: 3
Training loss: 2.6037773349918547
Validation loss: 2.5780859821508066

Epoch: 5| Step: 4
Training loss: 2.166594088390268
Validation loss: 2.5414989267477597

Epoch: 5| Step: 5
Training loss: 3.0506596461639894
Validation loss: 2.5301132941439715

Epoch: 5| Step: 6
Training loss: 2.3810366156981733
Validation loss: 2.528428595066286

Epoch: 5| Step: 7
Training loss: 2.673365127234891
Validation loss: 2.558934529222084

Epoch: 5| Step: 8
Training loss: 2.62539815153846
Validation loss: 2.561249430566531

Epoch: 5| Step: 9
Training loss: 2.147352575852874
Validation loss: 2.532385231369929

Epoch: 5| Step: 10
Training loss: 2.2555681841621507
Validation loss: 2.564000556484877

Epoch: 189| Step: 0
Training loss: 2.3616166739151723
Validation loss: 2.5308574907453525

Epoch: 5| Step: 1
Training loss: 1.7490102830282472
Validation loss: 2.5368083813300184

Epoch: 5| Step: 2
Training loss: 2.9486608925001803
Validation loss: 2.5307401768831554

Epoch: 5| Step: 3
Training loss: 2.7171289280813316
Validation loss: 2.5338107107251027

Epoch: 5| Step: 4
Training loss: 2.9459635776358195
Validation loss: 2.554578910467335

Epoch: 5| Step: 5
Training loss: 2.3136501029782424
Validation loss: 2.5338641444101486

Epoch: 5| Step: 6
Training loss: 2.5642327753652405
Validation loss: 2.5321823695926415

Epoch: 5| Step: 7
Training loss: 2.5303506077519446
Validation loss: 2.556308924333852

Epoch: 5| Step: 8
Training loss: 2.7302328943814036
Validation loss: 2.562251794551122

Epoch: 5| Step: 9
Training loss: 2.462556724088655
Validation loss: 2.519091846064779

Epoch: 5| Step: 10
Training loss: 2.281514714180412
Validation loss: 2.536919050253685

Epoch: 190| Step: 0
Training loss: 2.4054949678167383
Validation loss: 2.582751199257008

Epoch: 5| Step: 1
Training loss: 1.9786237741719945
Validation loss: 2.542429595842704

Epoch: 5| Step: 2
Training loss: 2.6688091691401654
Validation loss: 2.5645424331401605

Epoch: 5| Step: 3
Training loss: 3.3868651748911742
Validation loss: 2.5704491956058666

Epoch: 5| Step: 4
Training loss: 1.9572934034122262
Validation loss: 2.573145958100003

Epoch: 5| Step: 5
Training loss: 2.427246633992723
Validation loss: 2.536699344784095

Epoch: 5| Step: 6
Training loss: 2.7118874240510644
Validation loss: 2.544584273730714

Epoch: 5| Step: 7
Training loss: 2.2594230214103237
Validation loss: 2.543225872409312

Epoch: 5| Step: 8
Training loss: 2.6851780641639187
Validation loss: 2.5487539976262727

Epoch: 5| Step: 9
Training loss: 2.6779829559581487
Validation loss: 2.5200929509567143

Epoch: 5| Step: 10
Training loss: 2.2945516863995103
Validation loss: 2.523224029457011

Epoch: 191| Step: 0
Training loss: 2.020566929302218
Validation loss: 2.524364879472815

Epoch: 5| Step: 1
Training loss: 2.1272131670696046
Validation loss: 2.5541006091926532

Epoch: 5| Step: 2
Training loss: 2.321467667554352
Validation loss: 2.5345294571363333

Epoch: 5| Step: 3
Training loss: 2.8981252332419505
Validation loss: 2.5364136565692874

Epoch: 5| Step: 4
Training loss: 2.6520925860806677
Validation loss: 2.5389789607312094

Epoch: 5| Step: 5
Training loss: 2.483636038421088
Validation loss: 2.5185407513717823

Epoch: 5| Step: 6
Training loss: 2.151358986664465
Validation loss: 2.528828902097948

Epoch: 5| Step: 7
Training loss: 2.192896698195124
Validation loss: 2.5291935750632675

Epoch: 5| Step: 8
Training loss: 3.1240609856293062
Validation loss: 2.5256250337062216

Epoch: 5| Step: 9
Training loss: 2.7966915475362217
Validation loss: 2.5177975990304837

Epoch: 5| Step: 10
Training loss: 2.795273476803232
Validation loss: 2.531777061038586

Epoch: 192| Step: 0
Training loss: 2.8552314461393404
Validation loss: 2.5108868534721287

Epoch: 5| Step: 1
Training loss: 2.223305981004067
Validation loss: 2.559656461832836

Epoch: 5| Step: 2
Training loss: 2.744265907115693
Validation loss: 2.526669675608942

Epoch: 5| Step: 3
Training loss: 2.09203496124784
Validation loss: 2.5151254612337968

Epoch: 5| Step: 4
Training loss: 2.8059049636342834
Validation loss: 2.5215725189147764

Epoch: 5| Step: 5
Training loss: 2.4032802338185997
Validation loss: 2.5333165623050893

Epoch: 5| Step: 6
Training loss: 2.368135772221485
Validation loss: 2.5548915414647353

Epoch: 5| Step: 7
Training loss: 2.533687501126182
Validation loss: 2.532716310948739

Epoch: 5| Step: 8
Training loss: 2.868658286230547
Validation loss: 2.5489383736372

Epoch: 5| Step: 9
Training loss: 2.288482905105041
Validation loss: 2.5805549364507097

Epoch: 5| Step: 10
Training loss: 2.214289627862803
Validation loss: 2.553806551055069

Epoch: 193| Step: 0
Training loss: 2.52858527936367
Validation loss: 2.5680506925893023

Epoch: 5| Step: 1
Training loss: 2.9396455112498723
Validation loss: 2.5169530119964434

Epoch: 5| Step: 2
Training loss: 2.5766807441113024
Validation loss: 2.5419859427592053

Epoch: 5| Step: 3
Training loss: 2.346811355154506
Validation loss: 2.5250434658127343

Epoch: 5| Step: 4
Training loss: 2.8156131045548527
Validation loss: 2.5698461971432005

Epoch: 5| Step: 5
Training loss: 2.193349483260475
Validation loss: 2.541160225067312

Epoch: 5| Step: 6
Training loss: 2.3406614170882984
Validation loss: 2.5255902816407727

Epoch: 5| Step: 7
Training loss: 1.7953682594504772
Validation loss: 2.517613628670474

Epoch: 5| Step: 8
Training loss: 2.910008123327499
Validation loss: 2.5350814639681594

Epoch: 5| Step: 9
Training loss: 2.705975126971212
Validation loss: 2.515448192389836

Epoch: 5| Step: 10
Training loss: 2.2292155204006776
Validation loss: 2.519423109581097

Epoch: 194| Step: 0
Training loss: 2.1922539416119062
Validation loss: 2.5531893682600137

Epoch: 5| Step: 1
Training loss: 2.497383846907877
Validation loss: 2.545594274433742

Epoch: 5| Step: 2
Training loss: 2.6234354170245138
Validation loss: 2.5533366424265793

Epoch: 5| Step: 3
Training loss: 2.3374715507530426
Validation loss: 2.525680900533048

Epoch: 5| Step: 4
Training loss: 2.158408811960408
Validation loss: 2.4984995625762196

Epoch: 5| Step: 5
Training loss: 3.0406099513152944
Validation loss: 2.5620072744222573

Epoch: 5| Step: 6
Training loss: 2.3167596711442324
Validation loss: 2.535933393986433

Epoch: 5| Step: 7
Training loss: 2.6918673846949943
Validation loss: 2.5779730246439727

Epoch: 5| Step: 8
Training loss: 2.270984492972547
Validation loss: 2.5684187410411226

Epoch: 5| Step: 9
Training loss: 2.3205159416021024
Validation loss: 2.5392028689018753

Epoch: 5| Step: 10
Training loss: 3.1998105648713038
Validation loss: 2.501469262411675

Epoch: 195| Step: 0
Training loss: 2.6574893528463934
Validation loss: 2.540382797978111

Epoch: 5| Step: 1
Training loss: 2.2818067733440768
Validation loss: 2.5243710185175003

Epoch: 5| Step: 2
Training loss: 2.2438502509797797
Validation loss: 2.5067136044469676

Epoch: 5| Step: 3
Training loss: 2.561592313456395
Validation loss: 2.5241077858285483

Epoch: 5| Step: 4
Training loss: 2.8071117921481044
Validation loss: 2.52844616635065

Epoch: 5| Step: 5
Training loss: 2.9253837203337696
Validation loss: 2.5311222932929454

Epoch: 5| Step: 6
Training loss: 2.21528053349955
Validation loss: 2.5005678229344364

Epoch: 5| Step: 7
Training loss: 2.806931302090552
Validation loss: 2.5286724620214662

Epoch: 5| Step: 8
Training loss: 2.6907492224608798
Validation loss: 2.5342910225267583

Epoch: 5| Step: 9
Training loss: 1.7357153996795363
Validation loss: 2.5117745597169865

Epoch: 5| Step: 10
Training loss: 2.4668546716680275
Validation loss: 2.5355541956532246

Epoch: 196| Step: 0
Training loss: 2.3997306195714527
Validation loss: 2.546064324185595

Epoch: 5| Step: 1
Training loss: 2.186304037954125
Validation loss: 2.5480424973283635

Epoch: 5| Step: 2
Training loss: 2.8554690839816836
Validation loss: 2.541708496196039

Epoch: 5| Step: 3
Training loss: 2.441898876080293
Validation loss: 2.5725594117643

Epoch: 5| Step: 4
Training loss: 2.9451575605280356
Validation loss: 2.551668673780218

Epoch: 5| Step: 5
Training loss: 3.0765398465432177
Validation loss: 2.511869378277083

Epoch: 5| Step: 6
Training loss: 2.3186036055999573
Validation loss: 2.5585596746915242

Epoch: 5| Step: 7
Training loss: 2.1401948148521477
Validation loss: 2.5719161937953596

Epoch: 5| Step: 8
Training loss: 2.770660901739507
Validation loss: 2.553658566116031

Epoch: 5| Step: 9
Training loss: 1.8168134991630172
Validation loss: 2.526212412513486

Epoch: 5| Step: 10
Training loss: 2.539799040556625
Validation loss: 2.546701676645035

Epoch: 197| Step: 0
Training loss: 2.431364504905196
Validation loss: 2.5356114047800835

Epoch: 5| Step: 1
Training loss: 2.37664657534346
Validation loss: 2.5578039454980734

Epoch: 5| Step: 2
Training loss: 2.523543884113448
Validation loss: 2.5562509584027686

Epoch: 5| Step: 3
Training loss: 1.72000423098199
Validation loss: 2.538909161325649

Epoch: 5| Step: 4
Training loss: 3.091776979711336
Validation loss: 2.5456581019432916

Epoch: 5| Step: 5
Training loss: 2.2279491724349576
Validation loss: 2.5470295520772894

Epoch: 5| Step: 6
Training loss: 3.196413032512235
Validation loss: 2.5152839424863154

Epoch: 5| Step: 7
Training loss: 2.3873829518331604
Validation loss: 2.576757054816666

Epoch: 5| Step: 8
Training loss: 2.210218980046615
Validation loss: 2.533019960790577

Epoch: 5| Step: 9
Training loss: 2.8119465601307665
Validation loss: 2.5331885478878866

Epoch: 5| Step: 10
Training loss: 2.3669785007585045
Validation loss: 2.5527765410363217

Epoch: 198| Step: 0
Training loss: 2.563429315040781
Validation loss: 2.5758391109752394

Epoch: 5| Step: 1
Training loss: 2.7769609447695935
Validation loss: 2.5673497585361793

Epoch: 5| Step: 2
Training loss: 2.7720548380041734
Validation loss: 2.563910427554167

Epoch: 5| Step: 3
Training loss: 2.8806398883549877
Validation loss: 2.537889483696132

Epoch: 5| Step: 4
Training loss: 2.4535303449136032
Validation loss: 2.523792833735152

Epoch: 5| Step: 5
Training loss: 1.9951959371312797
Validation loss: 2.5286419790511525

Epoch: 5| Step: 6
Training loss: 2.189551345296329
Validation loss: 2.5210630104944136

Epoch: 5| Step: 7
Training loss: 2.859462715846358
Validation loss: 2.5787565897677247

Epoch: 5| Step: 8
Training loss: 2.4246518858545705
Validation loss: 2.5301836756282547

Epoch: 5| Step: 9
Training loss: 2.1374178061939277
Validation loss: 2.537072909355658

Epoch: 5| Step: 10
Training loss: 2.4105564570356264
Validation loss: 2.5224299160149415

Epoch: 199| Step: 0
Training loss: 2.743213950518682
Validation loss: 2.532613595874052

Epoch: 5| Step: 1
Training loss: 2.377098762357378
Validation loss: 2.5032068870240916

Epoch: 5| Step: 2
Training loss: 2.6144298087915185
Validation loss: 2.553750514487262

Epoch: 5| Step: 3
Training loss: 2.314293037382781
Validation loss: 2.5167709081529566

Epoch: 5| Step: 4
Training loss: 1.9245196498661548
Validation loss: 2.527568275069357

Epoch: 5| Step: 5
Training loss: 2.9769914773518558
Validation loss: 2.5506160228857615

Epoch: 5| Step: 6
Training loss: 1.9982178615819073
Validation loss: 2.516098820623547

Epoch: 5| Step: 7
Training loss: 2.7662107203022313
Validation loss: 2.5362066456654824

Epoch: 5| Step: 8
Training loss: 2.4195958395870623
Validation loss: 2.549183035578005

Epoch: 5| Step: 9
Training loss: 2.5044688338162415
Validation loss: 2.522056402547555

Epoch: 5| Step: 10
Training loss: 2.857036029998394
Validation loss: 2.542906819879188

Epoch: 200| Step: 0
Training loss: 2.594789135989243
Validation loss: 2.539258140176515

Epoch: 5| Step: 1
Training loss: 2.489044886716509
Validation loss: 2.5512407095057767

Epoch: 5| Step: 2
Training loss: 2.921461759505994
Validation loss: 2.536721388850337

Epoch: 5| Step: 3
Training loss: 2.7431073941725934
Validation loss: 2.5410158792437763

Epoch: 5| Step: 4
Training loss: 2.410818840464141
Validation loss: 2.548784802318962

Epoch: 5| Step: 5
Training loss: 2.773785894298341
Validation loss: 2.5543616011317396

Epoch: 5| Step: 6
Training loss: 2.087384697019706
Validation loss: 2.5919368152293503

Epoch: 5| Step: 7
Training loss: 1.941639446782664
Validation loss: 2.5824684742303727

Epoch: 5| Step: 8
Training loss: 2.3079453023977545
Validation loss: 2.543793944134732

Epoch: 5| Step: 9
Training loss: 2.5945952543400663
Validation loss: 2.5631523612516696

Epoch: 5| Step: 10
Training loss: 2.721039520520624
Validation loss: 2.5413829897993914

Epoch: 201| Step: 0
Training loss: 2.280739505033255
Validation loss: 2.548615966385719

Epoch: 5| Step: 1
Training loss: 2.7767000163236677
Validation loss: 2.5654471112814994

Epoch: 5| Step: 2
Training loss: 2.435861966354933
Validation loss: 2.5579800974948688

Epoch: 5| Step: 3
Training loss: 2.820032671204821
Validation loss: 2.56194463374699

Epoch: 5| Step: 4
Training loss: 1.82433728766203
Validation loss: 2.537987510477363

Epoch: 5| Step: 5
Training loss: 2.758914197936338
Validation loss: 2.534349521580562

Epoch: 5| Step: 6
Training loss: 2.2701038157044553
Validation loss: 2.5343773453324316

Epoch: 5| Step: 7
Training loss: 2.3983689090227736
Validation loss: 2.5621466304219314

Epoch: 5| Step: 8
Training loss: 2.7507126491652283
Validation loss: 2.5556304356520796

Epoch: 5| Step: 9
Training loss: 2.809496398950629
Validation loss: 2.522681599491681

Epoch: 5| Step: 10
Training loss: 2.2180493820169276
Validation loss: 2.547076925595813

Epoch: 202| Step: 0
Training loss: 2.6699334837096753
Validation loss: 2.54118458859384

Epoch: 5| Step: 1
Training loss: 1.6905887028716422
Validation loss: 2.5305588960073035

Epoch: 5| Step: 2
Training loss: 2.6156464096159326
Validation loss: 2.530376359014346

Epoch: 5| Step: 3
Training loss: 2.8400890553977938
Validation loss: 2.57723320247269

Epoch: 5| Step: 4
Training loss: 2.387171126478172
Validation loss: 2.521945968849022

Epoch: 5| Step: 5
Training loss: 2.343986194153316
Validation loss: 2.561982704650489

Epoch: 5| Step: 6
Training loss: 2.489929707159268
Validation loss: 2.5385163386645844

Epoch: 5| Step: 7
Training loss: 2.319517468224887
Validation loss: 2.5256806213999186

Epoch: 5| Step: 8
Training loss: 1.8759144142734645
Validation loss: 2.553053028313621

Epoch: 5| Step: 9
Training loss: 2.7792666789469984
Validation loss: 2.5506882377573348

Epoch: 5| Step: 10
Training loss: 3.284297581421714
Validation loss: 2.538800964264005

Epoch: 203| Step: 0
Training loss: 2.679235036480896
Validation loss: 2.5664285488473815

Epoch: 5| Step: 1
Training loss: 2.5303551304775835
Validation loss: 2.536174013252341

Epoch: 5| Step: 2
Training loss: 3.0294490852213922
Validation loss: 2.5442439070817056

Epoch: 5| Step: 3
Training loss: 2.671086066592854
Validation loss: 2.5358884538902586

Epoch: 5| Step: 4
Training loss: 1.8601004844102567
Validation loss: 2.5611642947434814

Epoch: 5| Step: 5
Training loss: 2.5286467552510765
Validation loss: 2.5540788250351354

Epoch: 5| Step: 6
Training loss: 2.5149659424859045
Validation loss: 2.5313816438910846

Epoch: 5| Step: 7
Training loss: 2.043152080646984
Validation loss: 2.530688084831038

Epoch: 5| Step: 8
Training loss: 2.8823847259472535
Validation loss: 2.537681870868743

Epoch: 5| Step: 9
Training loss: 2.1892547109164844
Validation loss: 2.5558633708853504

Epoch: 5| Step: 10
Training loss: 2.1777915228628344
Validation loss: 2.5122714748540065

Epoch: 204| Step: 0
Training loss: 2.2587432526834403
Validation loss: 2.5623002313339582

Epoch: 5| Step: 1
Training loss: 2.642052349331418
Validation loss: 2.557182450194175

Epoch: 5| Step: 2
Training loss: 2.160404129016464
Validation loss: 2.561133229547934

Epoch: 5| Step: 3
Training loss: 2.4775477233663166
Validation loss: 2.5307542930033917

Epoch: 5| Step: 4
Training loss: 2.3331418867136215
Validation loss: 2.559526880174067

Epoch: 5| Step: 5
Training loss: 2.52347774886874
Validation loss: 2.53608878925328

Epoch: 5| Step: 6
Training loss: 2.957270865766398
Validation loss: 2.5109140224017605

Epoch: 5| Step: 7
Training loss: 2.0502872126281133
Validation loss: 2.5333279044406707

Epoch: 5| Step: 8
Training loss: 2.3199518096785883
Validation loss: 2.5018737580060146

Epoch: 5| Step: 9
Training loss: 2.842821074295993
Validation loss: 2.5443057542769494

Epoch: 5| Step: 10
Training loss: 2.5606766703492263
Validation loss: 2.549592833371362

Epoch: 205| Step: 0
Training loss: 2.7567766962229885
Validation loss: 2.5272137927273404

Epoch: 5| Step: 1
Training loss: 2.462360273550614
Validation loss: 2.5459861319071537

Epoch: 5| Step: 2
Training loss: 2.5087513339842635
Validation loss: 2.54432728557477

Epoch: 5| Step: 3
Training loss: 2.6192291950267204
Validation loss: 2.561082267697428

Epoch: 5| Step: 4
Training loss: 2.5913459943333335
Validation loss: 2.5302128127181747

Epoch: 5| Step: 5
Training loss: 2.1164837895887123
Validation loss: 2.5668256532479847

Epoch: 5| Step: 6
Training loss: 2.0206010298246695
Validation loss: 2.5262745814029066

Epoch: 5| Step: 7
Training loss: 2.6786694608641817
Validation loss: 2.565215056297076

Epoch: 5| Step: 8
Training loss: 2.2327743879393065
Validation loss: 2.541224723841819

Epoch: 5| Step: 9
Training loss: 2.6521130828107826
Validation loss: 2.5193019774391443

Epoch: 5| Step: 10
Training loss: 2.4519841159225173
Validation loss: 2.5708026485340705

Epoch: 206| Step: 0
Training loss: 2.5520892915202027
Validation loss: 2.568869737804967

Epoch: 5| Step: 1
Training loss: 2.737653761077093
Validation loss: 2.5194553703092937

Epoch: 5| Step: 2
Training loss: 2.334810425212224
Validation loss: 2.523420422127095

Epoch: 5| Step: 3
Training loss: 2.675435064712269
Validation loss: 2.520000985114938

Epoch: 5| Step: 4
Training loss: 2.647846887500944
Validation loss: 2.551349760649597

Epoch: 5| Step: 5
Training loss: 2.711423802800129
Validation loss: 2.562108971198778

Epoch: 5| Step: 6
Training loss: 2.391426899374361
Validation loss: 2.559913272080761

Epoch: 5| Step: 7
Training loss: 2.1107426483557608
Validation loss: 2.5601314219746345

Epoch: 5| Step: 8
Training loss: 2.134243663137215
Validation loss: 2.5315857045204133

Epoch: 5| Step: 9
Training loss: 2.4013325369538987
Validation loss: 2.532463168884133

Epoch: 5| Step: 10
Training loss: 2.4739714826267876
Validation loss: 2.506175430003125

Epoch: 207| Step: 0
Training loss: 1.7402162219127193
Validation loss: 2.568800170758193

Epoch: 5| Step: 1
Training loss: 1.9885079904711784
Validation loss: 2.5288634337717504

Epoch: 5| Step: 2
Training loss: 2.5777595029745854
Validation loss: 2.5292644681575567

Epoch: 5| Step: 3
Training loss: 2.1411613293675247
Validation loss: 2.5287421313678164

Epoch: 5| Step: 4
Training loss: 2.280752258346495
Validation loss: 2.5384803103249993

Epoch: 5| Step: 5
Training loss: 2.406034781999708
Validation loss: 2.5309032008665397

Epoch: 5| Step: 6
Training loss: 2.7593119492029015
Validation loss: 2.537368732991029

Epoch: 5| Step: 7
Training loss: 2.2438094489847553
Validation loss: 2.529970807744432

Epoch: 5| Step: 8
Training loss: 2.883463468169074
Validation loss: 2.5303507257846496

Epoch: 5| Step: 9
Training loss: 2.683657982736333
Validation loss: 2.568004677333258

Epoch: 5| Step: 10
Training loss: 3.0925369196347843
Validation loss: 2.551177605505011

Epoch: 208| Step: 0
Training loss: 2.3128719546197964
Validation loss: 2.5537668835843967

Epoch: 5| Step: 1
Training loss: 3.219533732283
Validation loss: 2.543427010217916

Epoch: 5| Step: 2
Training loss: 2.7790852383680997
Validation loss: 2.5688991087283375

Epoch: 5| Step: 3
Training loss: 3.161324227435661
Validation loss: 2.544209752437173

Epoch: 5| Step: 4
Training loss: 1.7632369374329917
Validation loss: 2.5673642285598426

Epoch: 5| Step: 5
Training loss: 2.0865169106188284
Validation loss: 2.5791267902312596

Epoch: 5| Step: 6
Training loss: 2.83429563299764
Validation loss: 2.539218261585595

Epoch: 5| Step: 7
Training loss: 2.3885078779365765
Validation loss: 2.5553396004284754

Epoch: 5| Step: 8
Training loss: 1.7446363541289036
Validation loss: 2.518118799619509

Epoch: 5| Step: 9
Training loss: 2.200793391997589
Validation loss: 2.570427717557659

Epoch: 5| Step: 10
Training loss: 2.470979770054246
Validation loss: 2.5502779108061713

Epoch: 209| Step: 0
Training loss: 2.8078715068240263
Validation loss: 2.5122525505876103

Epoch: 5| Step: 1
Training loss: 2.6679940397033
Validation loss: 2.5381111769659843

Epoch: 5| Step: 2
Training loss: 2.8923801351783816
Validation loss: 2.5799018948907686

Epoch: 5| Step: 3
Training loss: 2.0059987941825796
Validation loss: 2.513187386903247

Epoch: 5| Step: 4
Training loss: 2.602875707442592
Validation loss: 2.5716520717884763

Epoch: 5| Step: 5
Training loss: 1.9570234530782806
Validation loss: 2.5227665493193134

Epoch: 5| Step: 6
Training loss: 2.567932325475626
Validation loss: 2.5573340075093114

Epoch: 5| Step: 7
Training loss: 2.24738870194513
Validation loss: 2.5712691029700423

Epoch: 5| Step: 8
Training loss: 2.7845519963275
Validation loss: 2.5501817196144336

Epoch: 5| Step: 9
Training loss: 2.079383641033833
Validation loss: 2.5589805032048556

Epoch: 5| Step: 10
Training loss: 2.1654569354217736
Validation loss: 2.569984623330836

Epoch: 210| Step: 0
Training loss: 2.560682256801943
Validation loss: 2.5327001469165618

Epoch: 5| Step: 1
Training loss: 2.3252816470610993
Validation loss: 2.528786454347582

Epoch: 5| Step: 2
Training loss: 2.318622011832123
Validation loss: 2.5352623891050863

Epoch: 5| Step: 3
Training loss: 3.005264431558206
Validation loss: 2.5679410169109027

Epoch: 5| Step: 4
Training loss: 2.2426886978624605
Validation loss: 2.547806003504251

Epoch: 5| Step: 5
Training loss: 2.4404346699566486
Validation loss: 2.540710160976522

Epoch: 5| Step: 6
Training loss: 3.061553497410242
Validation loss: 2.5415217195034185

Epoch: 5| Step: 7
Training loss: 2.1685063425876847
Validation loss: 2.5210675844559014

Epoch: 5| Step: 8
Training loss: 1.9308175550311972
Validation loss: 2.534315785908543

Epoch: 5| Step: 9
Training loss: 2.9052670364950495
Validation loss: 2.5343467913850057

Epoch: 5| Step: 10
Training loss: 2.118910422764423
Validation loss: 2.517238631634657

Epoch: 211| Step: 0
Training loss: 1.8253033372844654
Validation loss: 2.531876614458371

Epoch: 5| Step: 1
Training loss: 2.5105594789607957
Validation loss: 2.5252750175073504

Epoch: 5| Step: 2
Training loss: 2.5370482921221775
Validation loss: 2.5497680937426117

Epoch: 5| Step: 3
Training loss: 2.5193221131103765
Validation loss: 2.51621016301113

Epoch: 5| Step: 4
Training loss: 2.805697033612394
Validation loss: 2.554607961489659

Epoch: 5| Step: 5
Training loss: 2.4465632058528866
Validation loss: 2.5288371835384376

Epoch: 5| Step: 6
Training loss: 2.2742713893300945
Validation loss: 2.5091655133917765

Epoch: 5| Step: 7
Training loss: 2.120588435614733
Validation loss: 2.552037477531263

Epoch: 5| Step: 8
Training loss: 2.4273767798723838
Validation loss: 2.546563191882602

Epoch: 5| Step: 9
Training loss: 2.7430874035323716
Validation loss: 2.54353160881622

Epoch: 5| Step: 10
Training loss: 2.928849652329342
Validation loss: 2.5017208421798207

Epoch: 212| Step: 0
Training loss: 2.4962794275129956
Validation loss: 2.538102082383427

Epoch: 5| Step: 1
Training loss: 1.9132581616741873
Validation loss: 2.5324512883729207

Epoch: 5| Step: 2
Training loss: 2.9950504799283997
Validation loss: 2.549195982056722

Epoch: 5| Step: 3
Training loss: 1.920391533686404
Validation loss: 2.5287322913987222

Epoch: 5| Step: 4
Training loss: 2.5684496961601804
Validation loss: 2.5685725896821325

Epoch: 5| Step: 5
Training loss: 2.4381424472930693
Validation loss: 2.530229387790271

Epoch: 5| Step: 6
Training loss: 2.004676715349072
Validation loss: 2.5488367457957737

Epoch: 5| Step: 7
Training loss: 2.6002329501919
Validation loss: 2.558300354621332

Epoch: 5| Step: 8
Training loss: 2.7651791832863077
Validation loss: 2.5462633811917277

Epoch: 5| Step: 9
Training loss: 2.8378136684120006
Validation loss: 2.554400682287138

Epoch: 5| Step: 10
Training loss: 2.454160046743932
Validation loss: 2.5604242891344886

Epoch: 213| Step: 0
Training loss: 2.28397791551512
Validation loss: 2.549909791591413

Epoch: 5| Step: 1
Training loss: 2.043257917139828
Validation loss: 2.5647487012842882

Epoch: 5| Step: 2
Training loss: 2.2612412760720737
Validation loss: 2.5480877150509413

Epoch: 5| Step: 3
Training loss: 2.650932914336894
Validation loss: 2.5554076899973954

Epoch: 5| Step: 4
Training loss: 2.25632995717401
Validation loss: 2.536834880546173

Epoch: 5| Step: 5
Training loss: 2.2297417680195126
Validation loss: 2.540017123933721

Epoch: 5| Step: 6
Training loss: 2.885178006397712
Validation loss: 2.53435855477424

Epoch: 5| Step: 7
Training loss: 2.503992897474557
Validation loss: 2.5144357827630284

Epoch: 5| Step: 8
Training loss: 2.3929663269249892
Validation loss: 2.5486011092699146

Epoch: 5| Step: 9
Training loss: 2.6848727847175904
Validation loss: 2.5548470281650113

Epoch: 5| Step: 10
Training loss: 2.780568843110718
Validation loss: 2.5325568524965374

Epoch: 214| Step: 0
Training loss: 2.3509108949144877
Validation loss: 2.542029597129526

Epoch: 5| Step: 1
Training loss: 2.7871627535182815
Validation loss: 2.5382471221420353

Epoch: 5| Step: 2
Training loss: 3.0278130936580205
Validation loss: 2.565728923212724

Epoch: 5| Step: 3
Training loss: 2.3598928325372723
Validation loss: 2.553387956157355

Epoch: 5| Step: 4
Training loss: 2.2333324641135883
Validation loss: 2.5572182962450056

Epoch: 5| Step: 5
Training loss: 2.6358596871676974
Validation loss: 2.5361752201830066

Epoch: 5| Step: 6
Training loss: 1.8718567887122455
Validation loss: 2.5392121402638703

Epoch: 5| Step: 7
Training loss: 2.3789585652729737
Validation loss: 2.549885934703057

Epoch: 5| Step: 8
Training loss: 2.585086371271961
Validation loss: 2.523496892711365

Epoch: 5| Step: 9
Training loss: 2.274813206308639
Validation loss: 2.530244521985548

Epoch: 5| Step: 10
Training loss: 2.537929716509337
Validation loss: 2.547587517690369

Epoch: 215| Step: 0
Training loss: 2.8185310972351436
Validation loss: 2.5207523267505794

Epoch: 5| Step: 1
Training loss: 2.5010074492918997
Validation loss: 2.5207588783468378

Epoch: 5| Step: 2
Training loss: 2.123432029733917
Validation loss: 2.509182991731635

Epoch: 5| Step: 3
Training loss: 2.9810014601137307
Validation loss: 2.5161292772500694

Epoch: 5| Step: 4
Training loss: 2.006613525540319
Validation loss: 2.543728767736344

Epoch: 5| Step: 5
Training loss: 2.114576355369843
Validation loss: 2.556037549370084

Epoch: 5| Step: 6
Training loss: 2.5664123813782354
Validation loss: 2.5502587699649633

Epoch: 5| Step: 7
Training loss: 2.5087856412977843
Validation loss: 2.5421316332454027

Epoch: 5| Step: 8
Training loss: 2.293138020130955
Validation loss: 2.574593586443969

Epoch: 5| Step: 9
Training loss: 2.568207687714116
Validation loss: 2.5109766874736925

Epoch: 5| Step: 10
Training loss: 2.472371402863803
Validation loss: 2.5350736853013585

Epoch: 216| Step: 0
Training loss: 2.3661377848654066
Validation loss: 2.5320381017318865

Epoch: 5| Step: 1
Training loss: 2.329093168551436
Validation loss: 2.520615729921067

Epoch: 5| Step: 2
Training loss: 1.9584949372620308
Validation loss: 2.5438287221363622

Epoch: 5| Step: 3
Training loss: 2.6362837821203176
Validation loss: 2.52213107063426

Epoch: 5| Step: 4
Training loss: 2.6337864373306807
Validation loss: 2.5430101656198185

Epoch: 5| Step: 5
Training loss: 2.3014163839104276
Validation loss: 2.5382904640886763

Epoch: 5| Step: 6
Training loss: 2.992116424274151
Validation loss: 2.5387446146611667

Epoch: 5| Step: 7
Training loss: 2.5367367465664654
Validation loss: 2.571810961331145

Epoch: 5| Step: 8
Training loss: 2.028430801636775
Validation loss: 2.5386908237224026

Epoch: 5| Step: 9
Training loss: 2.9673162913481925
Validation loss: 2.568893268700599

Epoch: 5| Step: 10
Training loss: 1.9270901516630505
Validation loss: 2.5511682198599157

Epoch: 217| Step: 0
Training loss: 2.781586530234698
Validation loss: 2.563076342645995

Epoch: 5| Step: 1
Training loss: 2.0636193676922
Validation loss: 2.55358606328591

Epoch: 5| Step: 2
Training loss: 2.0190592053647327
Validation loss: 2.531308016358406

Epoch: 5| Step: 3
Training loss: 2.683294687723387
Validation loss: 2.577212316128182

Epoch: 5| Step: 4
Training loss: 1.8123649678409437
Validation loss: 2.53064272133592

Epoch: 5| Step: 5
Training loss: 2.197684313408126
Validation loss: 2.5479056933119617

Epoch: 5| Step: 6
Training loss: 2.955475210071333
Validation loss: 2.5345996037195344

Epoch: 5| Step: 7
Training loss: 2.4409476131707826
Validation loss: 2.5345496513705097

Epoch: 5| Step: 8
Training loss: 2.2538018425571305
Validation loss: 2.5444246885156625

Epoch: 5| Step: 9
Training loss: 2.6765946314498126
Validation loss: 2.5338663277687634

Epoch: 5| Step: 10
Training loss: 2.818584472803391
Validation loss: 2.520525573260285

Epoch: 218| Step: 0
Training loss: 2.4800459854415573
Validation loss: 2.5284653780225708

Epoch: 5| Step: 1
Training loss: 1.9551825100130518
Validation loss: 2.525112303278474

Epoch: 5| Step: 2
Training loss: 2.808806728304565
Validation loss: 2.540954675374057

Epoch: 5| Step: 3
Training loss: 2.88463884099569
Validation loss: 2.5239573993697806

Epoch: 5| Step: 4
Training loss: 2.9016960314631146
Validation loss: 2.547815797982302

Epoch: 5| Step: 5
Training loss: 2.412449171094138
Validation loss: 2.534242554183041

Epoch: 5| Step: 6
Training loss: 2.571215624544708
Validation loss: 2.5272222630686683

Epoch: 5| Step: 7
Training loss: 2.313468627143155
Validation loss: 2.512864476590899

Epoch: 5| Step: 8
Training loss: 2.062956903884901
Validation loss: 2.535494833614135

Epoch: 5| Step: 9
Training loss: 2.0388302725607295
Validation loss: 2.5258259978781124

Epoch: 5| Step: 10
Training loss: 2.3351448270659367
Validation loss: 2.503398305258085

Epoch: 219| Step: 0
Training loss: 2.389062607779541
Validation loss: 2.538644886238978

Epoch: 5| Step: 1
Training loss: 2.482264167824357
Validation loss: 2.506212808589141

Epoch: 5| Step: 2
Training loss: 2.2605530892499797
Validation loss: 2.5346108632431785

Epoch: 5| Step: 3
Training loss: 2.0423851565474975
Validation loss: 2.5454901171181628

Epoch: 5| Step: 4
Training loss: 2.421350730017766
Validation loss: 2.541330403705177

Epoch: 5| Step: 5
Training loss: 2.623153491207451
Validation loss: 2.5474596266667087

Epoch: 5| Step: 6
Training loss: 2.6782803858722297
Validation loss: 2.5581199655090225

Epoch: 5| Step: 7
Training loss: 1.9843088574537506
Validation loss: 2.544679744618711

Epoch: 5| Step: 8
Training loss: 2.8688286598076047
Validation loss: 2.540655733573045

Epoch: 5| Step: 9
Training loss: 2.5515563628385127
Validation loss: 2.554430361084589

Epoch: 5| Step: 10
Training loss: 2.5212264161716145
Validation loss: 2.537574474147667

Epoch: 220| Step: 0
Training loss: 2.830493756951619
Validation loss: 2.552693659464322

Epoch: 5| Step: 1
Training loss: 2.1508482568226315
Validation loss: 2.5282104971774895

Epoch: 5| Step: 2
Training loss: 2.449359311780942
Validation loss: 2.530394877228803

Epoch: 5| Step: 3
Training loss: 2.3491557532421563
Validation loss: 2.5508973286298846

Epoch: 5| Step: 4
Training loss: 2.4342608325909585
Validation loss: 2.549769438519203

Epoch: 5| Step: 5
Training loss: 2.6002710934672724
Validation loss: 2.565245411475194

Epoch: 5| Step: 6
Training loss: 1.7404661013604203
Validation loss: 2.5102755932815053

Epoch: 5| Step: 7
Training loss: 2.5078410209388693
Validation loss: 2.5369744117047164

Epoch: 5| Step: 8
Training loss: 2.308901280608634
Validation loss: 2.5512725312249236

Epoch: 5| Step: 9
Training loss: 2.6542533101821757
Validation loss: 2.5346117260127348

Epoch: 5| Step: 10
Training loss: 2.78776755310504
Validation loss: 2.558900492514539

Epoch: 221| Step: 0
Training loss: 2.692101376352057
Validation loss: 2.538090755522134

Epoch: 5| Step: 1
Training loss: 2.5116825842737946
Validation loss: 2.5209513526191496

Epoch: 5| Step: 2
Training loss: 1.842479914914185
Validation loss: 2.531750921010037

Epoch: 5| Step: 3
Training loss: 2.421432848531528
Validation loss: 2.535409366863658

Epoch: 5| Step: 4
Training loss: 2.1847083670965044
Validation loss: 2.548291007310216

Epoch: 5| Step: 5
Training loss: 2.2718576926473344
Validation loss: 2.5877167636933973

Epoch: 5| Step: 6
Training loss: 2.619614207714472
Validation loss: 2.573091991625845

Epoch: 5| Step: 7
Training loss: 2.242341252282313
Validation loss: 2.5433721500732664

Epoch: 5| Step: 8
Training loss: 2.5922628528571754
Validation loss: 2.557759459830728

Epoch: 5| Step: 9
Training loss: 2.1428566319601265
Validation loss: 2.563314829047387

Epoch: 5| Step: 10
Training loss: 3.340945342132039
Validation loss: 2.5483444125140675

Epoch: 222| Step: 0
Training loss: 2.1122692456140144
Validation loss: 2.5671235797984133

Epoch: 5| Step: 1
Training loss: 2.742965544392085
Validation loss: 2.56728757874499

Epoch: 5| Step: 2
Training loss: 2.0265757846323327
Validation loss: 2.5417939952209325

Epoch: 5| Step: 3
Training loss: 1.9726497838886907
Validation loss: 2.5261356344316446

Epoch: 5| Step: 4
Training loss: 2.3131005821804833
Validation loss: 2.5382303812647224

Epoch: 5| Step: 5
Training loss: 1.9363851723916279
Validation loss: 2.5454309978735687

Epoch: 5| Step: 6
Training loss: 2.3877083932093126
Validation loss: 2.534917279684014

Epoch: 5| Step: 7
Training loss: 2.719934665792846
Validation loss: 2.5012356975426293

Epoch: 5| Step: 8
Training loss: 2.591945066146586
Validation loss: 2.538345515868757

Epoch: 5| Step: 9
Training loss: 3.2191632940630357
Validation loss: 2.5332740136645775

Epoch: 5| Step: 10
Training loss: 2.341321577209178
Validation loss: 2.576548215798796

Epoch: 223| Step: 0
Training loss: 2.4415324186148872
Validation loss: 2.578934506546085

Epoch: 5| Step: 1
Training loss: 2.746399342882593
Validation loss: 2.571494553198481

Epoch: 5| Step: 2
Training loss: 2.7983280435239117
Validation loss: 2.5516929424979877

Epoch: 5| Step: 3
Training loss: 2.428867606527087
Validation loss: 2.5445000482723463

Epoch: 5| Step: 4
Training loss: 2.564003573059592
Validation loss: 2.538074127751716

Epoch: 5| Step: 5
Training loss: 2.2492135050832713
Validation loss: 2.5594578064040405

Epoch: 5| Step: 6
Training loss: 2.364408870316273
Validation loss: 2.566460744632873

Epoch: 5| Step: 7
Training loss: 1.6674775376301105
Validation loss: 2.537582336072794

Epoch: 5| Step: 8
Training loss: 2.4066595744541877
Validation loss: 2.547082716001145

Epoch: 5| Step: 9
Training loss: 2.3718624471500624
Validation loss: 2.5333335643578225

Epoch: 5| Step: 10
Training loss: 2.618263319582075
Validation loss: 2.548970198955161

Epoch: 224| Step: 0
Training loss: 2.3685870675690337
Validation loss: 2.544357536291996

Epoch: 5| Step: 1
Training loss: 2.335049769914662
Validation loss: 2.517621141543844

Epoch: 5| Step: 2
Training loss: 2.5288079809234874
Validation loss: 2.5589499224333756

Epoch: 5| Step: 3
Training loss: 2.4409143059053084
Validation loss: 2.5545301917980723

Epoch: 5| Step: 4
Training loss: 2.5882778122795895
Validation loss: 2.5379621849316543

Epoch: 5| Step: 5
Training loss: 2.4315094326431708
Validation loss: 2.558840380663649

Epoch: 5| Step: 6
Training loss: 2.4570398861198086
Validation loss: 2.5591950472211797

Epoch: 5| Step: 7
Training loss: 2.654624082314123
Validation loss: 2.571247291779474

Epoch: 5| Step: 8
Training loss: 2.2910580838456904
Validation loss: 2.5439278422240297

Epoch: 5| Step: 9
Training loss: 2.1760159542256194
Validation loss: 2.532453054863502

Epoch: 5| Step: 10
Training loss: 2.6426315358608305
Validation loss: 2.55407806520101

Epoch: 225| Step: 0
Training loss: 2.4193548072281703
Validation loss: 2.541954127825762

Epoch: 5| Step: 1
Training loss: 2.493582499526695
Validation loss: 2.532449472277594

Epoch: 5| Step: 2
Training loss: 2.2753217825892125
Validation loss: 2.540719635705695

Epoch: 5| Step: 3
Training loss: 2.486044460755288
Validation loss: 2.566437550542395

Epoch: 5| Step: 4
Training loss: 1.9371495083687882
Validation loss: 2.5329383745082703

Epoch: 5| Step: 5
Training loss: 2.6931598415143876
Validation loss: 2.5666642826528974

Epoch: 5| Step: 6
Training loss: 2.204635318865838
Validation loss: 2.5571633249435353

Epoch: 5| Step: 7
Training loss: 2.6592205715503816
Validation loss: 2.5498171075005582

Epoch: 5| Step: 8
Training loss: 2.924837456775944
Validation loss: 2.514422607348832

Epoch: 5| Step: 9
Training loss: 2.587275133175073
Validation loss: 2.514249804470656

Epoch: 5| Step: 10
Training loss: 2.22380939732393
Validation loss: 2.5415139928265353

Epoch: 226| Step: 0
Training loss: 1.857429191502743
Validation loss: 2.531319774626644

Epoch: 5| Step: 1
Training loss: 2.6047016255545477
Validation loss: 2.5283529002678535

Epoch: 5| Step: 2
Training loss: 2.500927085640285
Validation loss: 2.5234210093396343

Epoch: 5| Step: 3
Training loss: 2.804551315189082
Validation loss: 2.55612240362125

Epoch: 5| Step: 4
Training loss: 2.8054369931825747
Validation loss: 2.5022528168061817

Epoch: 5| Step: 5
Training loss: 2.247855754188463
Validation loss: 2.515460948146419

Epoch: 5| Step: 6
Training loss: 2.2987559395527195
Validation loss: 2.553771173603632

Epoch: 5| Step: 7
Training loss: 1.876325011968105
Validation loss: 2.537801045833717

Epoch: 5| Step: 8
Training loss: 2.84728884321803
Validation loss: 2.5266368560997847

Epoch: 5| Step: 9
Training loss: 2.452472284065136
Validation loss: 2.5517531358186805

Epoch: 5| Step: 10
Training loss: 2.347732415764777
Validation loss: 2.5612934192190235

Epoch: 227| Step: 0
Training loss: 2.2055286254754773
Validation loss: 2.5597109168835015

Epoch: 5| Step: 1
Training loss: 2.536594917228387
Validation loss: 2.571778840499049

Epoch: 5| Step: 2
Training loss: 3.06762049257241
Validation loss: 2.560420980981942

Epoch: 5| Step: 3
Training loss: 2.0111259698172534
Validation loss: 2.5721557692397066

Epoch: 5| Step: 4
Training loss: 2.180993130049977
Validation loss: 2.5577157075865915

Epoch: 5| Step: 5
Training loss: 2.4826715735452893
Validation loss: 2.556467453306585

Epoch: 5| Step: 6
Training loss: 2.1216118673283244
Validation loss: 2.5825026867392555

Epoch: 5| Step: 7
Training loss: 2.234909740562673
Validation loss: 2.5402270573386763

Epoch: 5| Step: 8
Training loss: 1.7792480998048528
Validation loss: 2.530847278128826

Epoch: 5| Step: 9
Training loss: 3.1043479576338457
Validation loss: 2.550151277615542

Epoch: 5| Step: 10
Training loss: 2.6769395980148074
Validation loss: 2.534747714243511

Epoch: 228| Step: 0
Training loss: 2.1172672270793447
Validation loss: 2.5429889256063696

Epoch: 5| Step: 1
Training loss: 2.6409639220021344
Validation loss: 2.549308231058442

Epoch: 5| Step: 2
Training loss: 1.580928993058942
Validation loss: 2.5616237764018908

Epoch: 5| Step: 3
Training loss: 1.8109697919966568
Validation loss: 2.575417812009037

Epoch: 5| Step: 4
Training loss: 2.8030803187795126
Validation loss: 2.557377288616701

Epoch: 5| Step: 5
Training loss: 2.516366979511083
Validation loss: 2.5683836631791515

Epoch: 5| Step: 6
Training loss: 2.3482351493841027
Validation loss: 2.5336795269448227

Epoch: 5| Step: 7
Training loss: 2.8659192848313033
Validation loss: 2.556075623003778

Epoch: 5| Step: 8
Training loss: 2.828045922959987
Validation loss: 2.49648053586854

Epoch: 5| Step: 9
Training loss: 2.954074606023704
Validation loss: 2.5447764147762904

Epoch: 5| Step: 10
Training loss: 2.387536640784825
Validation loss: 2.5282008315783324

Epoch: 229| Step: 0
Training loss: 3.0900222977509637
Validation loss: 2.528150495233834

Epoch: 5| Step: 1
Training loss: 2.421084662657649
Validation loss: 2.5604470135438415

Epoch: 5| Step: 2
Training loss: 2.640714294007298
Validation loss: 2.5226452139045

Epoch: 5| Step: 3
Training loss: 2.2980495226564512
Validation loss: 2.5394907267301283

Epoch: 5| Step: 4
Training loss: 2.257991057730471
Validation loss: 2.5578973504533526

Epoch: 5| Step: 5
Training loss: 2.2028522728468034
Validation loss: 2.5231232709878033

Epoch: 5| Step: 6
Training loss: 2.1655206828568643
Validation loss: 2.5364381869755133

Epoch: 5| Step: 7
Training loss: 2.2988936707414287
Validation loss: 2.559160547162769

Epoch: 5| Step: 8
Training loss: 1.8487029064852858
Validation loss: 2.5679179954249496

Epoch: 5| Step: 9
Training loss: 2.1237714245250476
Validation loss: 2.5582867031478074

Epoch: 5| Step: 10
Training loss: 3.347637732865211
Validation loss: 2.5673897204071383

Epoch: 230| Step: 0
Training loss: 2.33179077748851
Validation loss: 2.5397624954302196

Epoch: 5| Step: 1
Training loss: 2.2533964377187785
Validation loss: 2.520720132455443

Epoch: 5| Step: 2
Training loss: 2.898547394100985
Validation loss: 2.5321452629914307

Epoch: 5| Step: 3
Training loss: 2.8760405606207033
Validation loss: 2.5422150931170653

Epoch: 5| Step: 4
Training loss: 2.1845912668027223
Validation loss: 2.5649752853361627

Epoch: 5| Step: 5
Training loss: 2.664456961952962
Validation loss: 2.5284421076280092

Epoch: 5| Step: 6
Training loss: 2.841675724973439
Validation loss: 2.5415149682451346

Epoch: 5| Step: 7
Training loss: 2.1359232479978982
Validation loss: 2.548629435287215

Epoch: 5| Step: 8
Training loss: 2.5754044483658007
Validation loss: 2.538093620069323

Epoch: 5| Step: 9
Training loss: 1.985546697285982
Validation loss: 2.529432194230013

Epoch: 5| Step: 10
Training loss: 1.4457947622352336
Validation loss: 2.5444145222938817

Epoch: 231| Step: 0
Training loss: 2.510035875071655
Validation loss: 2.565063300004235

Epoch: 5| Step: 1
Training loss: 2.2822665732144785
Validation loss: 2.563151385065558

Epoch: 5| Step: 2
Training loss: 2.8771539994791295
Validation loss: 2.5238392700955052

Epoch: 5| Step: 3
Training loss: 2.532485942745076
Validation loss: 2.5297818744078393

Epoch: 5| Step: 4
Training loss: 2.291059852947185
Validation loss: 2.5345285670286453

Epoch: 5| Step: 5
Training loss: 2.7524597264807413
Validation loss: 2.5382237414436464

Epoch: 5| Step: 6
Training loss: 1.8610824951261997
Validation loss: 2.5406137639412414

Epoch: 5| Step: 7
Training loss: 2.195241146353473
Validation loss: 2.535133896029542

Epoch: 5| Step: 8
Training loss: 2.5366577968200055
Validation loss: 2.531712211197541

Epoch: 5| Step: 9
Training loss: 2.17364978315776
Validation loss: 2.550107364175811

Epoch: 5| Step: 10
Training loss: 2.5771418691004304
Validation loss: 2.537571693877387

Epoch: 232| Step: 0
Training loss: 2.3436379978121233
Validation loss: 2.5659319338065245

Epoch: 5| Step: 1
Training loss: 2.2965633673983556
Validation loss: 2.545055526389409

Epoch: 5| Step: 2
Training loss: 2.6672987983423737
Validation loss: 2.557494400062068

Epoch: 5| Step: 3
Training loss: 2.5144215424032645
Validation loss: 2.5566624855970685

Epoch: 5| Step: 4
Training loss: 2.673852824284433
Validation loss: 2.5653804728723326

Epoch: 5| Step: 5
Training loss: 2.38504164189547
Validation loss: 2.52140055734025

Epoch: 5| Step: 6
Training loss: 1.959602053200899
Validation loss: 2.5204269380248805

Epoch: 5| Step: 7
Training loss: 1.9152869842667026
Validation loss: 2.5439340247563824

Epoch: 5| Step: 8
Training loss: 2.6235379279920914
Validation loss: 2.55380725274665

Epoch: 5| Step: 9
Training loss: 2.886494422631002
Validation loss: 2.538092835248359

Epoch: 5| Step: 10
Training loss: 2.172857377976768
Validation loss: 2.5610085836059753

Epoch: 233| Step: 0
Training loss: 2.5373196767993087
Validation loss: 2.549113342598538

Epoch: 5| Step: 1
Training loss: 2.322424957738392
Validation loss: 2.529609487851656

Epoch: 5| Step: 2
Training loss: 2.7136875242740524
Validation loss: 2.5380426900389903

Epoch: 5| Step: 3
Training loss: 2.333292506632803
Validation loss: 2.531211568139829

Epoch: 5| Step: 4
Training loss: 2.5715935480086407
Validation loss: 2.521324470559799

Epoch: 5| Step: 5
Training loss: 1.9386909270248738
Validation loss: 2.5697938173987724

Epoch: 5| Step: 6
Training loss: 2.2992732185136293
Validation loss: 2.562751531573931

Epoch: 5| Step: 7
Training loss: 2.6160483542940094
Validation loss: 2.55240052097722

Epoch: 5| Step: 8
Training loss: 2.4120730007378866
Validation loss: 2.5420546179283474

Epoch: 5| Step: 9
Training loss: 2.20373461790986
Validation loss: 2.5545001257757454

Epoch: 5| Step: 10
Training loss: 2.5614852756998143
Validation loss: 2.5554217320539823

Epoch: 234| Step: 0
Training loss: 2.1535196017473033
Validation loss: 2.5407012431959553

Epoch: 5| Step: 1
Training loss: 2.7488028781691507
Validation loss: 2.53817164844487

Epoch: 5| Step: 2
Training loss: 2.260220520603645
Validation loss: 2.5479414203460173

Epoch: 5| Step: 3
Training loss: 2.2376908460667218
Validation loss: 2.566893101564227

Epoch: 5| Step: 4
Training loss: 2.22865523654077
Validation loss: 2.550616757618476

Epoch: 5| Step: 5
Training loss: 2.9337689668670484
Validation loss: 2.578717390100418

Epoch: 5| Step: 6
Training loss: 2.5177517069777755
Validation loss: 2.5273208942994287

Epoch: 5| Step: 7
Training loss: 2.3156372646568126
Validation loss: 2.544864439987295

Epoch: 5| Step: 8
Training loss: 2.304782050827984
Validation loss: 2.574416258430894

Epoch: 5| Step: 9
Training loss: 2.375566916815759
Validation loss: 2.5148843592026355

Epoch: 5| Step: 10
Training loss: 2.4662918214108713
Validation loss: 2.545718431411578

Epoch: 235| Step: 0
Training loss: 2.619917809019834
Validation loss: 2.5378733526125377

Epoch: 5| Step: 1
Training loss: 2.2879455757804106
Validation loss: 2.5457936239739793

Epoch: 5| Step: 2
Training loss: 2.571928496053546
Validation loss: 2.5487754641891844

Epoch: 5| Step: 3
Training loss: 2.1888993283435405
Validation loss: 2.5424842081117855

Epoch: 5| Step: 4
Training loss: 2.761607382335056
Validation loss: 2.5423919652184126

Epoch: 5| Step: 5
Training loss: 1.715798566199523
Validation loss: 2.5565645972792677

Epoch: 5| Step: 6
Training loss: 2.706984746624375
Validation loss: 2.5503438084441887

Epoch: 5| Step: 7
Training loss: 1.9990464559999224
Validation loss: 2.5291065198438427

Epoch: 5| Step: 8
Training loss: 3.1403987670188567
Validation loss: 2.5423193593987725

Epoch: 5| Step: 9
Training loss: 2.338622932183191
Validation loss: 2.550141082953022

Epoch: 5| Step: 10
Training loss: 1.7493357078770673
Validation loss: 2.5276867939803633

Epoch: 236| Step: 0
Training loss: 2.6739653502668075
Validation loss: 2.5271728496388866

Epoch: 5| Step: 1
Training loss: 2.3631934788065756
Validation loss: 2.51684516059701

Epoch: 5| Step: 2
Training loss: 1.980986217183168
Validation loss: 2.535388951969917

Epoch: 5| Step: 3
Training loss: 2.4396723334944213
Validation loss: 2.5396827272158973

Epoch: 5| Step: 4
Training loss: 2.261997238697151
Validation loss: 2.542431745628693

Epoch: 5| Step: 5
Training loss: 2.2618933101354597
Validation loss: 2.532651662298938

Epoch: 5| Step: 6
Training loss: 3.1498450831511637
Validation loss: 2.5297392774634893

Epoch: 5| Step: 7
Training loss: 2.254647118305274
Validation loss: 2.534814355441623

Epoch: 5| Step: 8
Training loss: 2.250875938301359
Validation loss: 2.478611272154251

Epoch: 5| Step: 9
Training loss: 2.685982919145868
Validation loss: 2.52217264139633

Epoch: 5| Step: 10
Training loss: 1.7002251812514924
Validation loss: 2.5137855409810745

Epoch: 237| Step: 0
Training loss: 2.5390123567765026
Validation loss: 2.53693477157345

Epoch: 5| Step: 1
Training loss: 2.179624604442307
Validation loss: 2.5261883399497704

Epoch: 5| Step: 2
Training loss: 2.568630143313916
Validation loss: 2.552464623227923

Epoch: 5| Step: 3
Training loss: 2.096217281698117
Validation loss: 2.559504426044632

Epoch: 5| Step: 4
Training loss: 2.451524540429212
Validation loss: 2.5153978872379295

Epoch: 5| Step: 5
Training loss: 2.178800559669172
Validation loss: 2.52119465245927

Epoch: 5| Step: 6
Training loss: 2.4969498146889526
Validation loss: 2.5525699241171904

Epoch: 5| Step: 7
Training loss: 2.697498706467312
Validation loss: 2.5605331443933537

Epoch: 5| Step: 8
Training loss: 2.6884153714544663
Validation loss: 2.580482224158233

Epoch: 5| Step: 9
Training loss: 2.331005286087595
Validation loss: 2.6214964437039385

Epoch: 5| Step: 10
Training loss: 2.220920199853802
Validation loss: 2.554776114943039

Epoch: 238| Step: 0
Training loss: 2.6939957650426756
Validation loss: 2.567247162920515

Epoch: 5| Step: 1
Training loss: 2.5927612074511464
Validation loss: 2.5791907361563253

Epoch: 5| Step: 2
Training loss: 2.368227387201029
Validation loss: 2.5632633979952493

Epoch: 5| Step: 3
Training loss: 2.6563945955301644
Validation loss: 2.55977911251125

Epoch: 5| Step: 4
Training loss: 2.1485818710370506
Validation loss: 2.5312615620561596

Epoch: 5| Step: 5
Training loss: 3.004392269585631
Validation loss: 2.5987729084453526

Epoch: 5| Step: 6
Training loss: 2.027746142252386
Validation loss: 2.5470015414295584

Epoch: 5| Step: 7
Training loss: 2.652374851679302
Validation loss: 2.557432367590968

Epoch: 5| Step: 8
Training loss: 2.2039911177399096
Validation loss: 2.563816649707952

Epoch: 5| Step: 9
Training loss: 1.4320014613373189
Validation loss: 2.587323324441302

Epoch: 5| Step: 10
Training loss: 2.461026435334956
Validation loss: 2.5811683677830075

Epoch: 239| Step: 0
Training loss: 2.7466700072715717
Validation loss: 2.5795416426708186

Epoch: 5| Step: 1
Training loss: 2.150157448082393
Validation loss: 2.5430852729331654

Epoch: 5| Step: 2
Training loss: 2.583312301139943
Validation loss: 2.5233366606492313

Epoch: 5| Step: 3
Training loss: 1.8745002716422425
Validation loss: 2.531486537652068

Epoch: 5| Step: 4
Training loss: 1.8118633599119596
Validation loss: 2.5237530845884057

Epoch: 5| Step: 5
Training loss: 2.3749769109306333
Validation loss: 2.552871748735832

Epoch: 5| Step: 6
Training loss: 2.2251045673958667
Validation loss: 2.5466398252227935

Epoch: 5| Step: 7
Training loss: 2.122874711819739
Validation loss: 2.5457919241398703

Epoch: 5| Step: 8
Training loss: 2.7226707863111774
Validation loss: 2.5562556178293003

Epoch: 5| Step: 9
Training loss: 2.5278197227975645
Validation loss: 2.547038789917135

Epoch: 5| Step: 10
Training loss: 2.9581628848836936
Validation loss: 2.5874294161798503

Epoch: 240| Step: 0
Training loss: 1.8789455227306422
Validation loss: 2.566323787632835

Epoch: 5| Step: 1
Training loss: 2.0505304673672415
Validation loss: 2.5260216117919514

Epoch: 5| Step: 2
Training loss: 2.6306930749975543
Validation loss: 2.515294885882868

Epoch: 5| Step: 3
Training loss: 1.587151349447064
Validation loss: 2.5593310634776265

Epoch: 5| Step: 4
Training loss: 2.277783097930319
Validation loss: 2.536998662843107

Epoch: 5| Step: 5
Training loss: 1.87937074499026
Validation loss: 2.5368960625429073

Epoch: 5| Step: 6
Training loss: 3.566511338556455
Validation loss: 2.5433916662968525

Epoch: 5| Step: 7
Training loss: 2.0230221119462795
Validation loss: 2.5476530773766237

Epoch: 5| Step: 8
Training loss: 2.5605220138774487
Validation loss: 2.524949132836821

Epoch: 5| Step: 9
Training loss: 2.997161794231466
Validation loss: 2.5389769402942415

Epoch: 5| Step: 10
Training loss: 2.0116471657470174
Validation loss: 2.5412051778615408

Epoch: 241| Step: 0
Training loss: 1.9656378352924226
Validation loss: 2.571980019966803

Epoch: 5| Step: 1
Training loss: 2.9726076460485316
Validation loss: 2.5369228660237466

Epoch: 5| Step: 2
Training loss: 2.39735114628953
Validation loss: 2.511524457597741

Epoch: 5| Step: 3
Training loss: 2.427197520526482
Validation loss: 2.583832054214633

Epoch: 5| Step: 4
Training loss: 2.066173057162041
Validation loss: 2.5500213305670782

Epoch: 5| Step: 5
Training loss: 2.597081997146479
Validation loss: 2.526000459311866

Epoch: 5| Step: 6
Training loss: 2.1901496099292603
Validation loss: 2.5776610169797345

Epoch: 5| Step: 7
Training loss: 2.191112587031774
Validation loss: 2.5917187597428915

Epoch: 5| Step: 8
Training loss: 2.0631518634294146
Validation loss: 2.5748440267250956

Epoch: 5| Step: 9
Training loss: 2.6944992828906167
Validation loss: 2.5484182972904224

Epoch: 5| Step: 10
Training loss: 2.4331249195709335
Validation loss: 2.5736568967548448

Epoch: 242| Step: 0
Training loss: 2.480934688029802
Validation loss: 2.543148115033158

Epoch: 5| Step: 1
Training loss: 2.4844052294925305
Validation loss: 2.5533153457407485

Epoch: 5| Step: 2
Training loss: 2.4182264840804524
Validation loss: 2.5160310652281788

Epoch: 5| Step: 3
Training loss: 2.429914163399954
Validation loss: 2.5505589769282735

Epoch: 5| Step: 4
Training loss: 2.189912065630511
Validation loss: 2.540721127038975

Epoch: 5| Step: 5
Training loss: 2.0418978449930365
Validation loss: 2.5064066678797112

Epoch: 5| Step: 6
Training loss: 2.788944872344479
Validation loss: 2.5549372610872236

Epoch: 5| Step: 7
Training loss: 2.321403683539484
Validation loss: 2.563622775688125

Epoch: 5| Step: 8
Training loss: 3.0322292358583223
Validation loss: 2.5998894580410012

Epoch: 5| Step: 9
Training loss: 1.822414903158485
Validation loss: 2.571929728070327

Epoch: 5| Step: 10
Training loss: 2.149746582709936
Validation loss: 2.5329898590724627

Epoch: 243| Step: 0
Training loss: 2.0160665102462696
Validation loss: 2.5338856647772507

Epoch: 5| Step: 1
Training loss: 2.76983907734805
Validation loss: 2.5341348002701674

Epoch: 5| Step: 2
Training loss: 2.0226788958257553
Validation loss: 2.570408332804322

Epoch: 5| Step: 3
Training loss: 2.2190393608422183
Validation loss: 2.5463398956919874

Epoch: 5| Step: 4
Training loss: 2.613170581521356
Validation loss: 2.5579346296984284

Epoch: 5| Step: 5
Training loss: 2.350086851747057
Validation loss: 2.5255615556192623

Epoch: 5| Step: 6
Training loss: 2.2446667724230185
Validation loss: 2.5366794708519764

Epoch: 5| Step: 7
Training loss: 2.629822887215285
Validation loss: 2.5229215661851967

Epoch: 5| Step: 8
Training loss: 2.559202258716432
Validation loss: 2.5727444353996365

Epoch: 5| Step: 9
Training loss: 2.349646614775284
Validation loss: 2.5420215795300396

Epoch: 5| Step: 10
Training loss: 2.454753748086581
Validation loss: 2.5242656960336625

Epoch: 244| Step: 0
Training loss: 1.9343526564680393
Validation loss: 2.5198880003384243

Epoch: 5| Step: 1
Training loss: 1.891207203402896
Validation loss: 2.5308332263439044

Epoch: 5| Step: 2
Training loss: 2.249911624444404
Validation loss: 2.558750065463283

Epoch: 5| Step: 3
Training loss: 2.5544786280366862
Validation loss: 2.5271943027191734

Epoch: 5| Step: 4
Training loss: 3.104997783911954
Validation loss: 2.5710316395774178

Epoch: 5| Step: 5
Training loss: 2.0235010085578216
Validation loss: 2.5649513846676113

Epoch: 5| Step: 6
Training loss: 2.148821654220738
Validation loss: 2.5262601276937593

Epoch: 5| Step: 7
Training loss: 2.2287663846100982
Validation loss: 2.5809919071794294

Epoch: 5| Step: 8
Training loss: 2.875141637879117
Validation loss: 2.597844114441037

Epoch: 5| Step: 9
Training loss: 2.75639518649509
Validation loss: 2.5167696338553096

Epoch: 5| Step: 10
Training loss: 2.3748609602534394
Validation loss: 2.5698927061414034

Epoch: 245| Step: 0
Training loss: 2.0554990144920726
Validation loss: 2.571336446694951

Epoch: 5| Step: 1
Training loss: 2.028258718070552
Validation loss: 2.5618960071163928

Epoch: 5| Step: 2
Training loss: 2.1537943692322448
Validation loss: 2.531834451706718

Epoch: 5| Step: 3
Training loss: 2.007293752904447
Validation loss: 2.5510057231441894

Epoch: 5| Step: 4
Training loss: 2.3688477589104413
Validation loss: 2.5821091926830246

Epoch: 5| Step: 5
Training loss: 2.57121516091459
Validation loss: 2.552006290186173

Epoch: 5| Step: 6
Training loss: 2.6494278308076176
Validation loss: 2.552583684502495

Epoch: 5| Step: 7
Training loss: 3.050768745973095
Validation loss: 2.5639880962039507

Epoch: 5| Step: 8
Training loss: 2.3606082143835696
Validation loss: 2.528603531884619

Epoch: 5| Step: 9
Training loss: 2.8578867556944982
Validation loss: 2.5333045360237785

Epoch: 5| Step: 10
Training loss: 1.9484173612310975
Validation loss: 2.5506566127819768

Epoch: 246| Step: 0
Training loss: 2.949845526578683
Validation loss: 2.5431198862301545

Epoch: 5| Step: 1
Training loss: 1.5519382571149842
Validation loss: 2.5237701378626918

Epoch: 5| Step: 2
Training loss: 2.5944009906125833
Validation loss: 2.5397057674293273

Epoch: 5| Step: 3
Training loss: 2.5683599319747494
Validation loss: 2.5634887512511044

Epoch: 5| Step: 4
Training loss: 2.092953089035694
Validation loss: 2.537541168289521

Epoch: 5| Step: 5
Training loss: 2.239694305745969
Validation loss: 2.5425574051246906

Epoch: 5| Step: 6
Training loss: 2.4191641125308
Validation loss: 2.5624956815749744

Epoch: 5| Step: 7
Training loss: 2.6447656434621747
Validation loss: 2.564367044836044

Epoch: 5| Step: 8
Training loss: 2.117396383081051
Validation loss: 2.56294386806373

Epoch: 5| Step: 9
Training loss: 1.813814607254318
Validation loss: 2.552899983182608

Epoch: 5| Step: 10
Training loss: 2.912291615116359
Validation loss: 2.5741852071851925

Epoch: 247| Step: 0
Training loss: 1.7020174677543034
Validation loss: 2.5601796265057204

Epoch: 5| Step: 1
Training loss: 2.287488793517632
Validation loss: 2.5367744651228836

Epoch: 5| Step: 2
Training loss: 2.5957680630221214
Validation loss: 2.544427422003252

Epoch: 5| Step: 3
Training loss: 2.763865627870382
Validation loss: 2.52470069832505

Epoch: 5| Step: 4
Training loss: 2.8086673477568014
Validation loss: 2.5465619153789794

Epoch: 5| Step: 5
Training loss: 2.2282915863638366
Validation loss: 2.5484744440628546

Epoch: 5| Step: 6
Training loss: 2.635711432295557
Validation loss: 2.5485119828630713

Epoch: 5| Step: 7
Training loss: 2.1582219049663682
Validation loss: 2.5237590107869705

Epoch: 5| Step: 8
Training loss: 2.2466173175444184
Validation loss: 2.526309502148446

Epoch: 5| Step: 9
Training loss: 2.5305735308160764
Validation loss: 2.5616689835685365

Epoch: 5| Step: 10
Training loss: 1.8887875668458614
Validation loss: 2.5148375403567993

Epoch: 248| Step: 0
Training loss: 1.9095672136070732
Validation loss: 2.5730940410693566

Epoch: 5| Step: 1
Training loss: 2.2421697423145353
Validation loss: 2.573492587453333

Epoch: 5| Step: 2
Training loss: 2.4857552011376565
Validation loss: 2.5627415420899857

Epoch: 5| Step: 3
Training loss: 2.5509504230007902
Validation loss: 2.5427989824603703

Epoch: 5| Step: 4
Training loss: 2.424704394069637
Validation loss: 2.5713638303455237

Epoch: 5| Step: 5
Training loss: 2.4158746035225147
Validation loss: 2.5667342611627175

Epoch: 5| Step: 6
Training loss: 2.7709636131769284
Validation loss: 2.5411948141434983

Epoch: 5| Step: 7
Training loss: 2.1062382864697122
Validation loss: 2.565041541986279

Epoch: 5| Step: 8
Training loss: 2.056529216882502
Validation loss: 2.5381933863117805

Epoch: 5| Step: 9
Training loss: 2.4133839070130128
Validation loss: 2.5556837597107043

Epoch: 5| Step: 10
Training loss: 2.6626369208290237
Validation loss: 2.54709850291631

Epoch: 249| Step: 0
Training loss: 2.4092715230013844
Validation loss: 2.569312152230255

Epoch: 5| Step: 1
Training loss: 2.2605029908556813
Validation loss: 2.5404286101858786

Epoch: 5| Step: 2
Training loss: 2.4179539595291786
Validation loss: 2.5505043169283685

Epoch: 5| Step: 3
Training loss: 2.15056446561175
Validation loss: 2.5450678396246196

Epoch: 5| Step: 4
Training loss: 2.496727327221894
Validation loss: 2.5251418105665233

Epoch: 5| Step: 5
Training loss: 1.8249621295918939
Validation loss: 2.5332809498146998

Epoch: 5| Step: 6
Training loss: 1.9775716143154194
Validation loss: 2.5507836229015277

Epoch: 5| Step: 7
Training loss: 2.8229486292382067
Validation loss: 2.5317008911894416

Epoch: 5| Step: 8
Training loss: 2.3544942127220656
Validation loss: 2.535774398671044

Epoch: 5| Step: 9
Training loss: 2.6619780767671557
Validation loss: 2.558618179977429

Epoch: 5| Step: 10
Training loss: 2.556320648336315
Validation loss: 2.5639935359609067

Epoch: 250| Step: 0
Training loss: 2.1157240648614914
Validation loss: 2.5801519297182955

Epoch: 5| Step: 1
Training loss: 2.6186573057680707
Validation loss: 2.5502882778222618

Epoch: 5| Step: 2
Training loss: 3.005726276546806
Validation loss: 2.5186329832676275

Epoch: 5| Step: 3
Training loss: 2.4027166805939877
Validation loss: 2.5820947467116087

Epoch: 5| Step: 4
Training loss: 2.072619725210003
Validation loss: 2.5456833509267307

Epoch: 5| Step: 5
Training loss: 2.5533636086696725
Validation loss: 2.540147245176554

Epoch: 5| Step: 6
Training loss: 2.4187909578704763
Validation loss: 2.51932940210737

Epoch: 5| Step: 7
Training loss: 2.0752989404272997
Validation loss: 2.583780690246402

Epoch: 5| Step: 8
Training loss: 2.4657735144074016
Validation loss: 2.563974261041755

Epoch: 5| Step: 9
Training loss: 1.55363935093471
Validation loss: 2.5728214597198074

Epoch: 5| Step: 10
Training loss: 2.3547840040412362
Validation loss: 2.5373115644972777

Epoch: 251| Step: 0
Training loss: 2.44928718240099
Validation loss: 2.517230046223985

Epoch: 5| Step: 1
Training loss: 2.2396820638022987
Validation loss: 2.570120377798331

Epoch: 5| Step: 2
Training loss: 2.712308421599017
Validation loss: 2.529995005432968

Epoch: 5| Step: 3
Training loss: 2.35055966713223
Validation loss: 2.528127439961068

Epoch: 5| Step: 4
Training loss: 2.243765883535626
Validation loss: 2.57367222780987

Epoch: 5| Step: 5
Training loss: 1.9688937422336399
Validation loss: 2.5342868548096296

Epoch: 5| Step: 6
Training loss: 2.2792780465963975
Validation loss: 2.558627201635982

Epoch: 5| Step: 7
Training loss: 1.7910330635311749
Validation loss: 2.5222272155763727

Epoch: 5| Step: 8
Training loss: 1.8728815190712838
Validation loss: 2.543595271390759

Epoch: 5| Step: 9
Training loss: 2.823092456331937
Validation loss: 2.570833244874849

Epoch: 5| Step: 10
Training loss: 2.9456828969684072
Validation loss: 2.5621760934226914

Epoch: 252| Step: 0
Training loss: 2.5294377939447887
Validation loss: 2.5436712735325675

Epoch: 5| Step: 1
Training loss: 2.390944316207629
Validation loss: 2.5328362646025058

Epoch: 5| Step: 2
Training loss: 2.211061939201798
Validation loss: 2.555182223011883

Epoch: 5| Step: 3
Training loss: 2.3386999018658954
Validation loss: 2.572414059317547

Epoch: 5| Step: 4
Training loss: 2.7145734254466416
Validation loss: 2.5474303245521983

Epoch: 5| Step: 5
Training loss: 2.7126482312180777
Validation loss: 2.5027680321564154

Epoch: 5| Step: 6
Training loss: 2.4703523288824
Validation loss: 2.5462822037082398

Epoch: 5| Step: 7
Training loss: 2.1056774368618596
Validation loss: 2.560092957033725

Epoch: 5| Step: 8
Training loss: 2.386846810509292
Validation loss: 2.5931278722590148

Epoch: 5| Step: 9
Training loss: 2.187467084364522
Validation loss: 2.549954874659651

Epoch: 5| Step: 10
Training loss: 2.019955146027176
Validation loss: 2.5934581367522296

Epoch: 253| Step: 0
Training loss: 2.4252963602723168
Validation loss: 2.5537652894441383

Epoch: 5| Step: 1
Training loss: 2.174834505997871
Validation loss: 2.5626901535524866

Epoch: 5| Step: 2
Training loss: 2.32624382465082
Validation loss: 2.536764974648041

Epoch: 5| Step: 3
Training loss: 3.035467929621035
Validation loss: 2.512954147060199

Epoch: 5| Step: 4
Training loss: 2.1997053512583764
Validation loss: 2.571167761522515

Epoch: 5| Step: 5
Training loss: 2.524692282480346
Validation loss: 2.5498648062555342

Epoch: 5| Step: 6
Training loss: 2.244081767001761
Validation loss: 2.5568347657495427

Epoch: 5| Step: 7
Training loss: 2.1667403306420705
Validation loss: 2.5752486754306316

Epoch: 5| Step: 8
Training loss: 2.4776859082048306
Validation loss: 2.548760138276661

Epoch: 5| Step: 9
Training loss: 1.9827823405155265
Validation loss: 2.5589259674909135

Epoch: 5| Step: 10
Training loss: 2.2846930662057865
Validation loss: 2.547414126075456

Epoch: 254| Step: 0
Training loss: 2.369453478705637
Validation loss: 2.5381428744222614

Epoch: 5| Step: 1
Training loss: 2.559076953716223
Validation loss: 2.568250995197282

Epoch: 5| Step: 2
Training loss: 2.1677080977178687
Validation loss: 2.5389477250604457

Epoch: 5| Step: 3
Training loss: 2.5702800342863186
Validation loss: 2.567612638718138

Epoch: 5| Step: 4
Training loss: 2.047504823187619
Validation loss: 2.5673134098684236

Epoch: 5| Step: 5
Training loss: 2.1936412164826797
Validation loss: 2.5711628918158747

Epoch: 5| Step: 6
Training loss: 2.492458221177231
Validation loss: 2.574383293777639

Epoch: 5| Step: 7
Training loss: 2.2423582643351896
Validation loss: 2.5661903618065875

Epoch: 5| Step: 8
Training loss: 2.7040066907337184
Validation loss: 2.5654676896982744

Epoch: 5| Step: 9
Training loss: 2.1117803352230125
Validation loss: 2.5510308202123375

Epoch: 5| Step: 10
Training loss: 2.5950362911148988
Validation loss: 2.576105989207336

Epoch: 255| Step: 0
Training loss: 2.4426363112209857
Validation loss: 2.5524390345481556

Epoch: 5| Step: 1
Training loss: 2.4813382764818632
Validation loss: 2.5476638585885145

Epoch: 5| Step: 2
Training loss: 1.8521930248730962
Validation loss: 2.5637424217296867

Epoch: 5| Step: 3
Training loss: 2.596297334580217
Validation loss: 2.5507215799970218

Epoch: 5| Step: 4
Training loss: 2.54436439386386
Validation loss: 2.561283238877901

Epoch: 5| Step: 5
Training loss: 2.6077332957166757
Validation loss: 2.54279213175699

Epoch: 5| Step: 6
Training loss: 2.0004717747251943
Validation loss: 2.5235147817716097

Epoch: 5| Step: 7
Training loss: 2.744316991385387
Validation loss: 2.5587086335903106

Epoch: 5| Step: 8
Training loss: 1.9183023632652856
Validation loss: 2.5596787704056974

Epoch: 5| Step: 9
Training loss: 2.4755836261083886
Validation loss: 2.5301851463212075

Epoch: 5| Step: 10
Training loss: 2.004393163348346
Validation loss: 2.5284976009450544

Epoch: 256| Step: 0
Training loss: 2.0606895361233653
Validation loss: 2.5536105898615635

Epoch: 5| Step: 1
Training loss: 1.9371677236813676
Validation loss: 2.563214535339494

Epoch: 5| Step: 2
Training loss: 2.065501831814783
Validation loss: 2.5415894388872142

Epoch: 5| Step: 3
Training loss: 2.8152948691922997
Validation loss: 2.542228924676557

Epoch: 5| Step: 4
Training loss: 2.190922049545592
Validation loss: 2.564299073194765

Epoch: 5| Step: 5
Training loss: 2.6788749686322983
Validation loss: 2.5387031799456126

Epoch: 5| Step: 6
Training loss: 1.4637055310955287
Validation loss: 2.5351566443819125

Epoch: 5| Step: 7
Training loss: 2.7810822339839927
Validation loss: 2.5756301646816313

Epoch: 5| Step: 8
Training loss: 2.832937624356755
Validation loss: 2.5340233470939566

Epoch: 5| Step: 9
Training loss: 2.40263858629655
Validation loss: 2.5873812397703517

Epoch: 5| Step: 10
Training loss: 2.4897213396157385
Validation loss: 2.5773062590814826

Epoch: 257| Step: 0
Training loss: 2.1482101042656634
Validation loss: 2.5344183753510743

Epoch: 5| Step: 1
Training loss: 2.1524890774439775
Validation loss: 2.5603427830812397

Epoch: 5| Step: 2
Training loss: 2.427576650711686
Validation loss: 2.5668252837070686

Epoch: 5| Step: 3
Training loss: 1.990395072461588
Validation loss: 2.561546174176396

Epoch: 5| Step: 4
Training loss: 1.7588632113655587
Validation loss: 2.536032871183207

Epoch: 5| Step: 5
Training loss: 2.232415253503413
Validation loss: 2.558839990933875

Epoch: 5| Step: 6
Training loss: 2.8832638601705747
Validation loss: 2.5382475392737978

Epoch: 5| Step: 7
Training loss: 2.2576977129733917
Validation loss: 2.553223608620011

Epoch: 5| Step: 8
Training loss: 1.8773506053302516
Validation loss: 2.531940986229337

Epoch: 5| Step: 9
Training loss: 3.062160239543581
Validation loss: 2.542214325703315

Epoch: 5| Step: 10
Training loss: 2.6780578284369425
Validation loss: 2.5587956264736174

Epoch: 258| Step: 0
Training loss: 2.193354809587301
Validation loss: 2.5210505434074055

Epoch: 5| Step: 1
Training loss: 1.9114254594378783
Validation loss: 2.5587898024602342

Epoch: 5| Step: 2
Training loss: 2.370131874117558
Validation loss: 2.5234257395450053

Epoch: 5| Step: 3
Training loss: 3.2968985751063946
Validation loss: 2.5581483444645885

Epoch: 5| Step: 4
Training loss: 2.1179089882868
Validation loss: 2.5627170733918074

Epoch: 5| Step: 5
Training loss: 2.2426946511731995
Validation loss: 2.5743968021367354

Epoch: 5| Step: 6
Training loss: 2.6690106123952315
Validation loss: 2.5308792873822035

Epoch: 5| Step: 7
Training loss: 2.1864793848845
Validation loss: 2.57317220564646

Epoch: 5| Step: 8
Training loss: 2.303693033094635
Validation loss: 2.5547337390661

Epoch: 5| Step: 9
Training loss: 2.1536528938174646
Validation loss: 2.5444437926407817

Epoch: 5| Step: 10
Training loss: 2.043945779084992
Validation loss: 2.579236593591857

Epoch: 259| Step: 0
Training loss: 2.6520390960607862
Validation loss: 2.541959702981402

Epoch: 5| Step: 1
Training loss: 2.4458268572208723
Validation loss: 2.5583902062152437

Epoch: 5| Step: 2
Training loss: 2.1126059195244427
Validation loss: 2.5500693401678687

Epoch: 5| Step: 3
Training loss: 1.9340167575098355
Validation loss: 2.586348417179679

Epoch: 5| Step: 4
Training loss: 2.3418536843479445
Validation loss: 2.5633200187016736

Epoch: 5| Step: 5
Training loss: 1.7870247242374715
Validation loss: 2.5723022754330604

Epoch: 5| Step: 6
Training loss: 3.0198840173340122
Validation loss: 2.537233568274941

Epoch: 5| Step: 7
Training loss: 2.4361059652999337
Validation loss: 2.57565706573077

Epoch: 5| Step: 8
Training loss: 2.414048870751878
Validation loss: 2.5631410590741286

Epoch: 5| Step: 9
Training loss: 2.291678850546151
Validation loss: 2.531664819528047

Epoch: 5| Step: 10
Training loss: 2.080775356297268
Validation loss: 2.544429025016539

Epoch: 260| Step: 0
Training loss: 1.8639567368361518
Validation loss: 2.574856670439496

Epoch: 5| Step: 1
Training loss: 1.6417244270090767
Validation loss: 2.516289678919058

Epoch: 5| Step: 2
Training loss: 2.1698437529886876
Validation loss: 2.557276227718276

Epoch: 5| Step: 3
Training loss: 2.633329708563648
Validation loss: 2.5750380683981704

Epoch: 5| Step: 4
Training loss: 2.8990954862977305
Validation loss: 2.5353074242262603

Epoch: 5| Step: 5
Training loss: 2.2989581775420365
Validation loss: 2.543278205614528

Epoch: 5| Step: 6
Training loss: 2.0996870443483004
Validation loss: 2.5229328260035246

Epoch: 5| Step: 7
Training loss: 1.9715049481060132
Validation loss: 2.5430641212509615

Epoch: 5| Step: 8
Training loss: 2.2771589619699
Validation loss: 2.563562692565478

Epoch: 5| Step: 9
Training loss: 2.945373534523853
Validation loss: 2.563782311835555

Epoch: 5| Step: 10
Training loss: 2.561965049171727
Validation loss: 2.554363927551102

Epoch: 261| Step: 0
Training loss: 2.248656295511935
Validation loss: 2.5688884745188965

Epoch: 5| Step: 1
Training loss: 2.4695579076026313
Validation loss: 2.5282912935295654

Epoch: 5| Step: 2
Training loss: 2.63376742740581
Validation loss: 2.5469935908144303

Epoch: 5| Step: 3
Training loss: 2.140587799417291
Validation loss: 2.568912470286636

Epoch: 5| Step: 4
Training loss: 2.224843429028525
Validation loss: 2.5299251289099915

Epoch: 5| Step: 5
Training loss: 2.535928241292113
Validation loss: 2.558269983175128

Epoch: 5| Step: 6
Training loss: 2.070210925795416
Validation loss: 2.565927030184532

Epoch: 5| Step: 7
Training loss: 1.8978870363012716
Validation loss: 2.5847404491908503

Epoch: 5| Step: 8
Training loss: 2.685321901088095
Validation loss: 2.565071507436472

Epoch: 5| Step: 9
Training loss: 2.5759344794132915
Validation loss: 2.5616756887165817

Epoch: 5| Step: 10
Training loss: 2.1100008565891932
Validation loss: 2.5445129022098567

Epoch: 262| Step: 0
Training loss: 1.538198238087787
Validation loss: 2.556182900322421

Epoch: 5| Step: 1
Training loss: 2.109005478882128
Validation loss: 2.5396714094231103

Epoch: 5| Step: 2
Training loss: 2.392991633590694
Validation loss: 2.531596358714866

Epoch: 5| Step: 3
Training loss: 2.3587607285134795
Validation loss: 2.598496069316598

Epoch: 5| Step: 4
Training loss: 2.178681828651914
Validation loss: 2.5670712323828018

Epoch: 5| Step: 5
Training loss: 2.1915704186292513
Validation loss: 2.5462846955795095

Epoch: 5| Step: 6
Training loss: 2.2825654300198663
Validation loss: 2.5701186731064665

Epoch: 5| Step: 7
Training loss: 1.8924197041095496
Validation loss: 2.521458220789257

Epoch: 5| Step: 8
Training loss: 2.309822181694375
Validation loss: 2.5479266518642927

Epoch: 5| Step: 9
Training loss: 3.069084407198789
Validation loss: 2.5761514985205567

Epoch: 5| Step: 10
Training loss: 3.055369893608232
Validation loss: 2.579689342307589

Epoch: 263| Step: 0
Training loss: 2.7940507833552815
Validation loss: 2.5436268541449505

Epoch: 5| Step: 1
Training loss: 2.029524671969898
Validation loss: 2.5588280876162224

Epoch: 5| Step: 2
Training loss: 1.693589842709376
Validation loss: 2.5596986430399578

Epoch: 5| Step: 3
Training loss: 2.5388148729909528
Validation loss: 2.550044729516887

Epoch: 5| Step: 4
Training loss: 2.4315807166628725
Validation loss: 2.5662526735757454

Epoch: 5| Step: 5
Training loss: 1.7563959135754699
Validation loss: 2.5690853459586993

Epoch: 5| Step: 6
Training loss: 1.9360575690301038
Validation loss: 2.5061040632915055

Epoch: 5| Step: 7
Training loss: 2.275386852867045
Validation loss: 2.5432839724124405

Epoch: 5| Step: 8
Training loss: 2.705430916046056
Validation loss: 2.552294873596336

Epoch: 5| Step: 9
Training loss: 2.7942812523317277
Validation loss: 2.5148916233445107

Epoch: 5| Step: 10
Training loss: 2.7241572835610306
Validation loss: 2.542381828177767

Epoch: 264| Step: 0
Training loss: 2.2578729007653955
Validation loss: 2.5402439566231414

Epoch: 5| Step: 1
Training loss: 2.457066376500202
Validation loss: 2.5449058761322334

Epoch: 5| Step: 2
Training loss: 2.7597873090255254
Validation loss: 2.5517290138525976

Epoch: 5| Step: 3
Training loss: 2.0062827134361974
Validation loss: 2.5565107109785488

Epoch: 5| Step: 4
Training loss: 1.8938307892842914
Validation loss: 2.5885665957389254

Epoch: 5| Step: 5
Training loss: 2.2245426050737556
Validation loss: 2.5693912061212414

Epoch: 5| Step: 6
Training loss: 2.108507783429889
Validation loss: 2.547753806572301

Epoch: 5| Step: 7
Training loss: 2.525220589397284
Validation loss: 2.563041201170015

Epoch: 5| Step: 8
Training loss: 2.4724446909767193
Validation loss: 2.542688831599493

Epoch: 5| Step: 9
Training loss: 2.5837488968195816
Validation loss: 2.555886216088591

Epoch: 5| Step: 10
Training loss: 2.2280016079799254
Validation loss: 2.5563804403637844

Epoch: 265| Step: 0
Training loss: 2.323796184177288
Validation loss: 2.586006112336747

Epoch: 5| Step: 1
Training loss: 2.3839202807237894
Validation loss: 2.5497877359566115

Epoch: 5| Step: 2
Training loss: 2.433258670375595
Validation loss: 2.542364401609966

Epoch: 5| Step: 3
Training loss: 2.0661292079689053
Validation loss: 2.568477161491621

Epoch: 5| Step: 4
Training loss: 2.4185848406409427
Validation loss: 2.5552390940198753

Epoch: 5| Step: 5
Training loss: 2.550049657899129
Validation loss: 2.5410524658686273

Epoch: 5| Step: 6
Training loss: 2.3177960554231065
Validation loss: 2.5442823577141915

Epoch: 5| Step: 7
Training loss: 2.297472298738433
Validation loss: 2.5485546060382305

Epoch: 5| Step: 8
Training loss: 2.524442584763918
Validation loss: 2.591961568891336

Epoch: 5| Step: 9
Training loss: 2.207318798676734
Validation loss: 2.556362411242163

Epoch: 5| Step: 10
Training loss: 2.2701146332956896
Validation loss: 2.5634169159887454

Epoch: 266| Step: 0
Training loss: 2.8965479200084494
Validation loss: 2.5372441522747677

Epoch: 5| Step: 1
Training loss: 2.904318875484089
Validation loss: 2.554935815178059

Epoch: 5| Step: 2
Training loss: 1.9873831468695053
Validation loss: 2.569914648535555

Epoch: 5| Step: 3
Training loss: 2.4693574761589816
Validation loss: 2.5397462339164245

Epoch: 5| Step: 4
Training loss: 2.072374461459198
Validation loss: 2.593725875226358

Epoch: 5| Step: 5
Training loss: 2.9947443065492063
Validation loss: 2.5705844478329074

Epoch: 5| Step: 6
Training loss: 1.854336105777072
Validation loss: 2.5742264761088256

Epoch: 5| Step: 7
Training loss: 1.8090283920016947
Validation loss: 2.585958967202475

Epoch: 5| Step: 8
Training loss: 2.3531073378347154
Validation loss: 2.5842030741868265

Epoch: 5| Step: 9
Training loss: 2.075219439197984
Validation loss: 2.5590166757032726

Epoch: 5| Step: 10
Training loss: 1.468612664477656
Validation loss: 2.5672389269935803

Epoch: 267| Step: 0
Training loss: 2.5462467846407693
Validation loss: 2.580828467166715

Epoch: 5| Step: 1
Training loss: 2.490675033775151
Validation loss: 2.623955989257345

Epoch: 5| Step: 2
Training loss: 2.07467789965059
Validation loss: 2.539154571050245

Epoch: 5| Step: 3
Training loss: 1.9699243343170747
Validation loss: 2.5937924075820358

Epoch: 5| Step: 4
Training loss: 2.3838010644669185
Validation loss: 2.5372384374255477

Epoch: 5| Step: 5
Training loss: 2.643064827656904
Validation loss: 2.561533504794369

Epoch: 5| Step: 6
Training loss: 2.529504998676634
Validation loss: 2.567658408395841

Epoch: 5| Step: 7
Training loss: 2.0986659853706726
Validation loss: 2.5748110655571272

Epoch: 5| Step: 8
Training loss: 2.149917813881571
Validation loss: 2.575134685039322

Epoch: 5| Step: 9
Training loss: 1.9264938552643602
Validation loss: 2.610184273144856

Epoch: 5| Step: 10
Training loss: 2.840497850650618
Validation loss: 2.539390420870432

Epoch: 268| Step: 0
Training loss: 2.1824978994247974
Validation loss: 2.556794191713836

Epoch: 5| Step: 1
Training loss: 1.8820359777483815
Validation loss: 2.5575763457141183

Epoch: 5| Step: 2
Training loss: 2.2255249818536607
Validation loss: 2.58572873619058

Epoch: 5| Step: 3
Training loss: 2.184929127187543
Validation loss: 2.581110705375135

Epoch: 5| Step: 4
Training loss: 2.4055965576710507
Validation loss: 2.5362505309139745

Epoch: 5| Step: 5
Training loss: 2.6309124800342745
Validation loss: 2.579189229295943

Epoch: 5| Step: 6
Training loss: 1.70465208413654
Validation loss: 2.5573951161098734

Epoch: 5| Step: 7
Training loss: 2.5667980713668075
Validation loss: 2.5395045085197676

Epoch: 5| Step: 8
Training loss: 2.3880295969983574
Validation loss: 2.5749109175322586

Epoch: 5| Step: 9
Training loss: 2.620230565299938
Validation loss: 2.5765939312202915

Epoch: 5| Step: 10
Training loss: 2.505766988048724
Validation loss: 2.5534551379549244

Epoch: 269| Step: 0
Training loss: 2.612728955763104
Validation loss: 2.549388330615287

Epoch: 5| Step: 1
Training loss: 2.3034962824565217
Validation loss: 2.4974398445442088

Epoch: 5| Step: 2
Training loss: 1.9386534180186288
Validation loss: 2.5536775208501683

Epoch: 5| Step: 3
Training loss: 2.5826057106679876
Validation loss: 2.5663412273208275

Epoch: 5| Step: 4
Training loss: 2.5502104653662556
Validation loss: 2.6132281418013767

Epoch: 5| Step: 5
Training loss: 2.5162299714141727
Validation loss: 2.574993942692473

Epoch: 5| Step: 6
Training loss: 1.6599790949826503
Validation loss: 2.570323322810833

Epoch: 5| Step: 7
Training loss: 2.363069988297487
Validation loss: 2.603873311573139

Epoch: 5| Step: 8
Training loss: 2.3991009419024567
Validation loss: 2.5584835266403667

Epoch: 5| Step: 9
Training loss: 2.1259447129561924
Validation loss: 2.5632442030988773

Epoch: 5| Step: 10
Training loss: 2.3167986738435626
Validation loss: 2.547213268885681

Epoch: 270| Step: 0
Training loss: 2.1552289673850127
Validation loss: 2.5484928599428534

Epoch: 5| Step: 1
Training loss: 2.274728205448046
Validation loss: 2.5509515968109695

Epoch: 5| Step: 2
Training loss: 2.070969042050683
Validation loss: 2.56736662407932

Epoch: 5| Step: 3
Training loss: 2.5595723617528043
Validation loss: 2.5813009548503696

Epoch: 5| Step: 4
Training loss: 2.4286711796542275
Validation loss: 2.558016901494197

Epoch: 5| Step: 5
Training loss: 2.139364052158598
Validation loss: 2.568624433420487

Epoch: 5| Step: 6
Training loss: 2.362976357204928
Validation loss: 2.565175695167946

Epoch: 5| Step: 7
Training loss: 2.8106189795411147
Validation loss: 2.4937537548016255

Epoch: 5| Step: 8
Training loss: 2.3805875802998777
Validation loss: 2.573179302251586

Epoch: 5| Step: 9
Training loss: 2.4888758166098546
Validation loss: 2.527483648918727

Epoch: 5| Step: 10
Training loss: 1.7937275396662133
Validation loss: 2.555022316433002

Epoch: 271| Step: 0
Training loss: 2.125508303715565
Validation loss: 2.5822947780024816

Epoch: 5| Step: 1
Training loss: 1.970035194043874
Validation loss: 2.5391921870554945

Epoch: 5| Step: 2
Training loss: 2.2131601760339703
Validation loss: 2.571745534013194

Epoch: 5| Step: 3
Training loss: 3.001990293869603
Validation loss: 2.561862916383671

Epoch: 5| Step: 4
Training loss: 2.105251548760178
Validation loss: 2.5567686207967655

Epoch: 5| Step: 5
Training loss: 2.045354963055616
Validation loss: 2.5448660084744716

Epoch: 5| Step: 6
Training loss: 2.8216041713793003
Validation loss: 2.5377166255501127

Epoch: 5| Step: 7
Training loss: 1.7939203932375483
Validation loss: 2.6013117597361335

Epoch: 5| Step: 8
Training loss: 2.7200024230329154
Validation loss: 2.516658076832805

Epoch: 5| Step: 9
Training loss: 2.3057141102679175
Validation loss: 2.5542043963127825

Epoch: 5| Step: 10
Training loss: 2.1532641760327245
Validation loss: 2.556896216149583

Epoch: 272| Step: 0
Training loss: 2.0416799531880603
Validation loss: 2.526345100272826

Epoch: 5| Step: 1
Training loss: 2.407162381877685
Validation loss: 2.5332647984932377

Epoch: 5| Step: 2
Training loss: 1.8830316186560756
Validation loss: 2.551552626222444

Epoch: 5| Step: 3
Training loss: 2.158429688864393
Validation loss: 2.562024258186791

Epoch: 5| Step: 4
Training loss: 2.116337116248689
Validation loss: 2.577991724531453

Epoch: 5| Step: 5
Training loss: 2.2956478447819904
Validation loss: 2.549122322971576

Epoch: 5| Step: 6
Training loss: 2.922810124372147
Validation loss: 2.5973622481000542

Epoch: 5| Step: 7
Training loss: 2.150535308377741
Validation loss: 2.5721412723501444

Epoch: 5| Step: 8
Training loss: 3.007935201941217
Validation loss: 2.5567588310359475

Epoch: 5| Step: 9
Training loss: 2.2871377293289363
Validation loss: 2.556479889072257

Epoch: 5| Step: 10
Training loss: 1.6955940258938673
Validation loss: 2.570483415495719

Epoch: 273| Step: 0
Training loss: 1.9792521876546747
Validation loss: 2.576476509825751

Epoch: 5| Step: 1
Training loss: 2.2999323005664145
Validation loss: 2.5677465038178533

Epoch: 5| Step: 2
Training loss: 2.360953907938
Validation loss: 2.5552198293133586

Epoch: 5| Step: 3
Training loss: 2.310378777136241
Validation loss: 2.5756257234483617

Epoch: 5| Step: 4
Training loss: 1.7420755530001677
Validation loss: 2.5563130716914535

Epoch: 5| Step: 5
Training loss: 1.7377569543762184
Validation loss: 2.5397200396389517

Epoch: 5| Step: 6
Training loss: 2.5147778524040922
Validation loss: 2.5692439023103915

Epoch: 5| Step: 7
Training loss: 2.6933355627743145
Validation loss: 2.5372210371662276

Epoch: 5| Step: 8
Training loss: 2.1867562255700976
Validation loss: 2.5812084265861017

Epoch: 5| Step: 9
Training loss: 2.843288845356708
Validation loss: 2.577769154800429

Epoch: 5| Step: 10
Training loss: 2.5552795843948366
Validation loss: 2.565150807949143

Epoch: 274| Step: 0
Training loss: 1.457622990857987
Validation loss: 2.562449588074668

Epoch: 5| Step: 1
Training loss: 2.569060324976652
Validation loss: 2.549499940670765

Epoch: 5| Step: 2
Training loss: 2.3304612899082846
Validation loss: 2.562426198101167

Epoch: 5| Step: 3
Training loss: 1.9471333878745394
Validation loss: 2.5555460345480414

Epoch: 5| Step: 4
Training loss: 2.260414814984901
Validation loss: 2.554644465346641

Epoch: 5| Step: 5
Training loss: 2.1990378052990636
Validation loss: 2.587261874375187

Epoch: 5| Step: 6
Training loss: 2.727084571676845
Validation loss: 2.626308183555533

Epoch: 5| Step: 7
Training loss: 2.6229521619977016
Validation loss: 2.5596085238839

Epoch: 5| Step: 8
Training loss: 1.9844995895081603
Validation loss: 2.5370168578656074

Epoch: 5| Step: 9
Training loss: 2.7759167402737215
Validation loss: 2.53897146158001

Epoch: 5| Step: 10
Training loss: 2.309718959936286
Validation loss: 2.544239503762024

Epoch: 275| Step: 0
Training loss: 2.3346303899696363
Validation loss: 2.5520942578930534

Epoch: 5| Step: 1
Training loss: 2.2232420673921607
Validation loss: 2.5853386782218335

Epoch: 5| Step: 2
Training loss: 2.582793476752388
Validation loss: 2.559304632910647

Epoch: 5| Step: 3
Training loss: 2.9159256856734395
Validation loss: 2.5592895423428654

Epoch: 5| Step: 4
Training loss: 2.334369145683495
Validation loss: 2.543008512314588

Epoch: 5| Step: 5
Training loss: 2.0651512445292624
Validation loss: 2.5684729404514974

Epoch: 5| Step: 6
Training loss: 2.0498488858979558
Validation loss: 2.584485863395351

Epoch: 5| Step: 7
Training loss: 2.5508682680110804
Validation loss: 2.5892879169446053

Epoch: 5| Step: 8
Training loss: 2.0618693225570826
Validation loss: 2.5609550250587456

Epoch: 5| Step: 9
Training loss: 1.8381773576021163
Validation loss: 2.5491827977366928

Epoch: 5| Step: 10
Training loss: 2.1710246225767955
Validation loss: 2.553883541232087

Epoch: 276| Step: 0
Training loss: 2.3300458933031085
Validation loss: 2.5800771169631087

Epoch: 5| Step: 1
Training loss: 1.9463547821356992
Validation loss: 2.5939803541942705

Epoch: 5| Step: 2
Training loss: 2.187388934994367
Validation loss: 2.5576244545641615

Epoch: 5| Step: 3
Training loss: 1.9993763189618505
Validation loss: 2.5781168639550924

Epoch: 5| Step: 4
Training loss: 2.792141878665797
Validation loss: 2.550380899556227

Epoch: 5| Step: 5
Training loss: 2.2659867622682404
Validation loss: 2.5569083034202498

Epoch: 5| Step: 6
Training loss: 2.6138614301312404
Validation loss: 2.5819553692178157

Epoch: 5| Step: 7
Training loss: 2.272434498395831
Validation loss: 2.5862123963930848

Epoch: 5| Step: 8
Training loss: 2.5960850144089225
Validation loss: 2.5684417809957933

Epoch: 5| Step: 9
Training loss: 1.9512875267784742
Validation loss: 2.5535071269832907

Epoch: 5| Step: 10
Training loss: 2.2460200820120173
Validation loss: 2.5582279778326704

Epoch: 277| Step: 0
Training loss: 2.427584016644415
Validation loss: 2.5414288909039673

Epoch: 5| Step: 1
Training loss: 2.1366782454813205
Validation loss: 2.566941900189445

Epoch: 5| Step: 2
Training loss: 2.0675057440865925
Validation loss: 2.5550501829618537

Epoch: 5| Step: 3
Training loss: 2.42189577155281
Validation loss: 2.5494085599987164

Epoch: 5| Step: 4
Training loss: 3.0223531823986542
Validation loss: 2.5555392109938393

Epoch: 5| Step: 5
Training loss: 2.146425727133275
Validation loss: 2.550412239461828

Epoch: 5| Step: 6
Training loss: 1.8398810704813573
Validation loss: 2.5528979828010105

Epoch: 5| Step: 7
Training loss: 2.3101391468827597
Validation loss: 2.522928616152234

Epoch: 5| Step: 8
Training loss: 2.1905168710706313
Validation loss: 2.5582183334521864

Epoch: 5| Step: 9
Training loss: 2.5209087539193398
Validation loss: 2.544296419860135

Epoch: 5| Step: 10
Training loss: 2.4250357399105997
Validation loss: 2.5451225191782108

Epoch: 278| Step: 0
Training loss: 1.7068310932335564
Validation loss: 2.5820165077133512

Epoch: 5| Step: 1
Training loss: 2.2383231114172806
Validation loss: 2.596023273038774

Epoch: 5| Step: 2
Training loss: 2.34377522772881
Validation loss: 2.5580466185107382

Epoch: 5| Step: 3
Training loss: 2.593407022251375
Validation loss: 2.586387549263476

Epoch: 5| Step: 4
Training loss: 2.1655832173774154
Validation loss: 2.5864144603430512

Epoch: 5| Step: 5
Training loss: 2.842699464695843
Validation loss: 2.584903963684861

Epoch: 5| Step: 6
Training loss: 2.665976276037454
Validation loss: 2.593202321851737

Epoch: 5| Step: 7
Training loss: 2.2588823681009775
Validation loss: 2.5336063092081393

Epoch: 5| Step: 8
Training loss: 1.9634575324074068
Validation loss: 2.582644257221892

Epoch: 5| Step: 9
Training loss: 1.802814386809511
Validation loss: 2.568971328575613

Epoch: 5| Step: 10
Training loss: 2.606858279006074
Validation loss: 2.5563512485267

Epoch: 279| Step: 0
Training loss: 2.4517400440236803
Validation loss: 2.5708601183371917

Epoch: 5| Step: 1
Training loss: 2.9572826364309246
Validation loss: 2.5549172259912347

Epoch: 5| Step: 2
Training loss: 2.0069651912451367
Validation loss: 2.5490731686313444

Epoch: 5| Step: 3
Training loss: 2.2756816890688776
Validation loss: 2.5707461696962084

Epoch: 5| Step: 4
Training loss: 2.3579867491345743
Validation loss: 2.5620411667919183

Epoch: 5| Step: 5
Training loss: 2.1766368888854957
Validation loss: 2.5850129999979656

Epoch: 5| Step: 6
Training loss: 2.143032530010363
Validation loss: 2.568882268215848

Epoch: 5| Step: 7
Training loss: 1.903285363367238
Validation loss: 2.565217860573339

Epoch: 5| Step: 8
Training loss: 2.3029001320285087
Validation loss: 2.5703538590296695

Epoch: 5| Step: 9
Training loss: 2.2824182523730987
Validation loss: 2.555258457404269

Epoch: 5| Step: 10
Training loss: 2.3443233551625915
Validation loss: 2.526450174730063

Epoch: 280| Step: 0
Training loss: 2.0724270368554834
Validation loss: 2.5739786753569

Epoch: 5| Step: 1
Training loss: 2.4774666949669393
Validation loss: 2.5697746293815316

Epoch: 5| Step: 2
Training loss: 2.141297283552443
Validation loss: 2.575818180482579

Epoch: 5| Step: 3
Training loss: 2.67696052794057
Validation loss: 2.531610355631391

Epoch: 5| Step: 4
Training loss: 2.2942883725024523
Validation loss: 2.591719671753981

Epoch: 5| Step: 5
Training loss: 2.561902232345275
Validation loss: 2.561472198672058

Epoch: 5| Step: 6
Training loss: 2.1030865783356
Validation loss: 2.570208541443907

Epoch: 5| Step: 7
Training loss: 1.8773937839376298
Validation loss: 2.585628740791908

Epoch: 5| Step: 8
Training loss: 2.5664832627631164
Validation loss: 2.5984442315819036

Epoch: 5| Step: 9
Training loss: 2.5982999305299033
Validation loss: 2.5489281188061024

Epoch: 5| Step: 10
Training loss: 2.0645209150633788
Validation loss: 2.580901750791987

Epoch: 281| Step: 0
Training loss: 2.07897736701187
Validation loss: 2.5581753110955154

Epoch: 5| Step: 1
Training loss: 3.146029249410592
Validation loss: 2.5757113616570964

Epoch: 5| Step: 2
Training loss: 2.695356904921808
Validation loss: 2.586700254590556

Epoch: 5| Step: 3
Training loss: 2.2077771572083793
Validation loss: 2.6018652990559876

Epoch: 5| Step: 4
Training loss: 1.6833556818973592
Validation loss: 2.5808799425352666

Epoch: 5| Step: 5
Training loss: 2.3255262784192854
Validation loss: 2.5604311447263552

Epoch: 5| Step: 6
Training loss: 2.082041556098437
Validation loss: 2.5731547634369476

Epoch: 5| Step: 7
Training loss: 2.160837242023872
Validation loss: 2.613504720134644

Epoch: 5| Step: 8
Training loss: 2.074097480749075
Validation loss: 2.5457045825579576

Epoch: 5| Step: 9
Training loss: 2.0317980687137216
Validation loss: 2.5791456929759766

Epoch: 5| Step: 10
Training loss: 2.4721468962815365
Validation loss: 2.5637151406676923

Epoch: 282| Step: 0
Training loss: 2.687309347088091
Validation loss: 2.5683019680228285

Epoch: 5| Step: 1
Training loss: 2.0288112378705696
Validation loss: 2.5622283407378377

Epoch: 5| Step: 2
Training loss: 2.58160516913966
Validation loss: 2.566923939255276

Epoch: 5| Step: 3
Training loss: 2.7418816116006344
Validation loss: 2.5378248920751783

Epoch: 5| Step: 4
Training loss: 1.950928146826269
Validation loss: 2.5569212428676527

Epoch: 5| Step: 5
Training loss: 2.346690863282273
Validation loss: 2.558765963241641

Epoch: 5| Step: 6
Training loss: 1.7465055180726465
Validation loss: 2.535907485846267

Epoch: 5| Step: 7
Training loss: 2.536192789349046
Validation loss: 2.560682800429218

Epoch: 5| Step: 8
Training loss: 2.254826666858653
Validation loss: 2.5864572340109557

Epoch: 5| Step: 9
Training loss: 2.1550986491766695
Validation loss: 2.6058630227650066

Epoch: 5| Step: 10
Training loss: 1.8837331206863417
Validation loss: 2.548052666179247

Epoch: 283| Step: 0
Training loss: 2.8831285753110114
Validation loss: 2.5682971687446106

Epoch: 5| Step: 1
Training loss: 2.5581974101122893
Validation loss: 2.5972924630882344

Epoch: 5| Step: 2
Training loss: 1.7344430446164298
Validation loss: 2.5702421890198623

Epoch: 5| Step: 3
Training loss: 2.1477517993108215
Validation loss: 2.5988972474810548

Epoch: 5| Step: 4
Training loss: 2.3497311377427277
Validation loss: 2.5480613560021483

Epoch: 5| Step: 5
Training loss: 2.192942578873382
Validation loss: 2.575826774645057

Epoch: 5| Step: 6
Training loss: 1.8166949955309255
Validation loss: 2.5625895262695466

Epoch: 5| Step: 7
Training loss: 2.4864782870871327
Validation loss: 2.5708269216077553

Epoch: 5| Step: 8
Training loss: 1.7512554025396514
Validation loss: 2.5437524727442007

Epoch: 5| Step: 9
Training loss: 2.3393463472185716
Validation loss: 2.564082100739635

Epoch: 5| Step: 10
Training loss: 2.292129805033157
Validation loss: 2.581335479783721

Epoch: 284| Step: 0
Training loss: 2.567239425793423
Validation loss: 2.557609737986037

Epoch: 5| Step: 1
Training loss: 2.0669477651018826
Validation loss: 2.5509145994211027

Epoch: 5| Step: 2
Training loss: 2.09418927039949
Validation loss: 2.5448365304247416

Epoch: 5| Step: 3
Training loss: 1.7304456722193169
Validation loss: 2.5768798565817117

Epoch: 5| Step: 4
Training loss: 2.2524321444470052
Validation loss: 2.585900983337899

Epoch: 5| Step: 5
Training loss: 2.1697095875286783
Validation loss: 2.5353292958569873

Epoch: 5| Step: 6
Training loss: 2.36691343023964
Validation loss: 2.593653576656468

Epoch: 5| Step: 7
Training loss: 2.5104673599464395
Validation loss: 2.559526646799571

Epoch: 5| Step: 8
Training loss: 2.0080487895220758
Validation loss: 2.5869481765761613

Epoch: 5| Step: 9
Training loss: 2.416370954727529
Validation loss: 2.5564616881689877

Epoch: 5| Step: 10
Training loss: 2.7014023247400756
Validation loss: 2.5939469097781513

Epoch: 285| Step: 0
Training loss: 2.1948756533357323
Validation loss: 2.582871185019763

Epoch: 5| Step: 1
Training loss: 2.298517587019807
Validation loss: 2.5790450407509966

Epoch: 5| Step: 2
Training loss: 2.6671083104468294
Validation loss: 2.5395404203706153

Epoch: 5| Step: 3
Training loss: 1.904079139194758
Validation loss: 2.5470788309053307

Epoch: 5| Step: 4
Training loss: 2.9638831149180773
Validation loss: 2.594711833062369

Epoch: 5| Step: 5
Training loss: 2.493148953085336
Validation loss: 2.576166103206399

Epoch: 5| Step: 6
Training loss: 1.9998488369082796
Validation loss: 2.566470675689071

Epoch: 5| Step: 7
Training loss: 2.0723749216435072
Validation loss: 2.570675377929337

Epoch: 5| Step: 8
Training loss: 1.541166619662049
Validation loss: 2.555974552764654

Epoch: 5| Step: 9
Training loss: 2.448759044963495
Validation loss: 2.5857143382019436

Epoch: 5| Step: 10
Training loss: 2.465336431483125
Validation loss: 2.5706147515738555

Epoch: 286| Step: 0
Training loss: 2.286476314766519
Validation loss: 2.5807807863972267

Epoch: 5| Step: 1
Training loss: 2.178860415157482
Validation loss: 2.5425266994188784

Epoch: 5| Step: 2
Training loss: 2.4633926013153755
Validation loss: 2.535358157424707

Epoch: 5| Step: 3
Training loss: 1.5423745085430034
Validation loss: 2.560223519887637

Epoch: 5| Step: 4
Training loss: 2.2132312751511374
Validation loss: 2.573168284223242

Epoch: 5| Step: 5
Training loss: 2.5573789085739804
Validation loss: 2.6059963897814677

Epoch: 5| Step: 6
Training loss: 1.9299932693205961
Validation loss: 2.527815873002749

Epoch: 5| Step: 7
Training loss: 2.6314380352038835
Validation loss: 2.5542332563783625

Epoch: 5| Step: 8
Training loss: 2.6320621315425927
Validation loss: 2.5830412873933595

Epoch: 5| Step: 9
Training loss: 2.2318981821292487
Validation loss: 2.6038204446980857

Epoch: 5| Step: 10
Training loss: 2.3688754368082603
Validation loss: 2.5901080746958556

Epoch: 287| Step: 0
Training loss: 2.372577536052573
Validation loss: 2.5772850823775717

Epoch: 5| Step: 1
Training loss: 2.566209573627054
Validation loss: 2.5922702512458864

Epoch: 5| Step: 2
Training loss: 1.9785320134439717
Validation loss: 2.5563847816545846

Epoch: 5| Step: 3
Training loss: 2.539931491919138
Validation loss: 2.544555955072653

Epoch: 5| Step: 4
Training loss: 2.0904736291571964
Validation loss: 2.555004280738061

Epoch: 5| Step: 5
Training loss: 1.9831593311607052
Validation loss: 2.5301784048360174

Epoch: 5| Step: 6
Training loss: 1.8662885473094017
Validation loss: 2.5815710827709135

Epoch: 5| Step: 7
Training loss: 2.333038879162139
Validation loss: 2.5420090417690564

Epoch: 5| Step: 8
Training loss: 2.308182061629122
Validation loss: 2.572131012350191

Epoch: 5| Step: 9
Training loss: 2.5934695356472424
Validation loss: 2.556282387805155

Epoch: 5| Step: 10
Training loss: 2.6651286120272397
Validation loss: 2.5738664504544233

Epoch: 288| Step: 0
Training loss: 2.636269221663094
Validation loss: 2.5250132507281937

Epoch: 5| Step: 1
Training loss: 2.3139040009838445
Validation loss: 2.5832169420880815

Epoch: 5| Step: 2
Training loss: 2.39937083819049
Validation loss: 2.567469266843795

Epoch: 5| Step: 3
Training loss: 2.1951980289467063
Validation loss: 2.5498642472516426

Epoch: 5| Step: 4
Training loss: 2.4876897039872103
Validation loss: 2.5695485523450863

Epoch: 5| Step: 5
Training loss: 2.2163284411805466
Validation loss: 2.582190698715043

Epoch: 5| Step: 6
Training loss: 2.635424848903172
Validation loss: 2.5978871360954514

Epoch: 5| Step: 7
Training loss: 1.9270625620229458
Validation loss: 2.572176359765575

Epoch: 5| Step: 8
Training loss: 1.6835796594583285
Validation loss: 2.5704480795696116

Epoch: 5| Step: 9
Training loss: 1.8230948079577458
Validation loss: 2.5353969086412165

Epoch: 5| Step: 10
Training loss: 2.3353555522162646
Validation loss: 2.573511597328783

Epoch: 289| Step: 0
Training loss: 2.3000803269996104
Validation loss: 2.5785513248505034

Epoch: 5| Step: 1
Training loss: 1.874648188328101
Validation loss: 2.585017005601227

Epoch: 5| Step: 2
Training loss: 1.9965630444346658
Validation loss: 2.5284282107881313

Epoch: 5| Step: 3
Training loss: 2.7353947944861012
Validation loss: 2.5828551353622684

Epoch: 5| Step: 4
Training loss: 1.8458455348705873
Validation loss: 2.5404615027951087

Epoch: 5| Step: 5
Training loss: 2.6189473626322703
Validation loss: 2.614839560316344

Epoch: 5| Step: 6
Training loss: 2.6593282478069042
Validation loss: 2.5793389458864784

Epoch: 5| Step: 7
Training loss: 1.592573217628147
Validation loss: 2.5804735332376616

Epoch: 5| Step: 8
Training loss: 2.196489229151114
Validation loss: 2.5696481209553914

Epoch: 5| Step: 9
Training loss: 2.2086443652036425
Validation loss: 2.559923400787219

Epoch: 5| Step: 10
Training loss: 2.8092941662931197
Validation loss: 2.5900568539949425

Epoch: 290| Step: 0
Training loss: 2.083294168739945
Validation loss: 2.591988394899929

Epoch: 5| Step: 1
Training loss: 2.3917434170555514
Validation loss: 2.588709829097428

Epoch: 5| Step: 2
Training loss: 2.220607570984564
Validation loss: 2.562881042218582

Epoch: 5| Step: 3
Training loss: 2.105247018777322
Validation loss: 2.5819337118473094

Epoch: 5| Step: 4
Training loss: 2.769160451668733
Validation loss: 2.5846148781169487

Epoch: 5| Step: 5
Training loss: 1.942186778184261
Validation loss: 2.610164386122369

Epoch: 5| Step: 6
Training loss: 2.1912361935813287
Validation loss: 2.591303569469364

Epoch: 5| Step: 7
Training loss: 2.633901399190554
Validation loss: 2.6141467151277133

Epoch: 5| Step: 8
Training loss: 1.980102746012344
Validation loss: 2.590600509425866

Epoch: 5| Step: 9
Training loss: 2.3639956064586833
Validation loss: 2.602729925409307

Epoch: 5| Step: 10
Training loss: 2.2408751790981887
Validation loss: 2.5871124934107446

Epoch: 291| Step: 0
Training loss: 1.9724912064504967
Validation loss: 2.5790238867737503

Epoch: 5| Step: 1
Training loss: 2.2297692479717357
Validation loss: 2.5993572391517996

Epoch: 5| Step: 2
Training loss: 2.5581014144932324
Validation loss: 2.5771016177652735

Epoch: 5| Step: 3
Training loss: 2.6976272152802823
Validation loss: 2.5809868901309843

Epoch: 5| Step: 4
Training loss: 2.1953222742915193
Validation loss: 2.537961509162794

Epoch: 5| Step: 5
Training loss: 1.766893184583131
Validation loss: 2.566010220640971

Epoch: 5| Step: 6
Training loss: 2.5695278280205818
Validation loss: 2.576298461113723

Epoch: 5| Step: 7
Training loss: 1.8443386625241305
Validation loss: 2.5644888964134718

Epoch: 5| Step: 8
Training loss: 2.1614968415165983
Validation loss: 2.5461799422555424

Epoch: 5| Step: 9
Training loss: 2.8137855135058936
Validation loss: 2.56551741977433

Epoch: 5| Step: 10
Training loss: 1.8663680700626066
Validation loss: 2.573201051236787

Epoch: 292| Step: 0
Training loss: 2.4503934194024994
Validation loss: 2.563614961621779

Epoch: 5| Step: 1
Training loss: 2.0666064217718247
Validation loss: 2.5826843010741696

Epoch: 5| Step: 2
Training loss: 1.858732737683586
Validation loss: 2.576605897729236

Epoch: 5| Step: 3
Training loss: 2.6295182534581834
Validation loss: 2.5266362807957385

Epoch: 5| Step: 4
Training loss: 2.3606136683120615
Validation loss: 2.5640321108606243

Epoch: 5| Step: 5
Training loss: 2.809532125489964
Validation loss: 2.5630621924922985

Epoch: 5| Step: 6
Training loss: 1.668885026248052
Validation loss: 2.5567277168245397

Epoch: 5| Step: 7
Training loss: 2.402503428541073
Validation loss: 2.5361328054240753

Epoch: 5| Step: 8
Training loss: 2.294336382261119
Validation loss: 2.5523820780490696

Epoch: 5| Step: 9
Training loss: 2.1031219482399734
Validation loss: 2.521089330488766

Epoch: 5| Step: 10
Training loss: 1.983606565177901
Validation loss: 2.5624332654393362

Epoch: 293| Step: 0
Training loss: 2.1122112279948424
Validation loss: 2.568884139389354

Epoch: 5| Step: 1
Training loss: 2.284627739196862
Validation loss: 2.590925681217156

Epoch: 5| Step: 2
Training loss: 2.2295097253471403
Validation loss: 2.5569854633875244

Epoch: 5| Step: 3
Training loss: 2.2065638764672495
Validation loss: 2.580213567991993

Epoch: 5| Step: 4
Training loss: 2.352076071994634
Validation loss: 2.547761832294979

Epoch: 5| Step: 5
Training loss: 2.379735341784047
Validation loss: 2.536133299727901

Epoch: 5| Step: 6
Training loss: 1.5551138441846095
Validation loss: 2.5929890601311274

Epoch: 5| Step: 7
Training loss: 2.4609190925030817
Validation loss: 2.5629512550607867

Epoch: 5| Step: 8
Training loss: 2.3763443003348925
Validation loss: 2.5931501627744935

Epoch: 5| Step: 9
Training loss: 2.493686524159347
Validation loss: 2.576168308431136

Epoch: 5| Step: 10
Training loss: 2.379395082357442
Validation loss: 2.5723355777001125

Epoch: 294| Step: 0
Training loss: 1.9721090936526449
Validation loss: 2.5718992913017216

Epoch: 5| Step: 1
Training loss: 2.29064928070564
Validation loss: 2.556441635938426

Epoch: 5| Step: 2
Training loss: 2.8413303687111355
Validation loss: 2.5603697821705405

Epoch: 5| Step: 3
Training loss: 2.4437069237856472
Validation loss: 2.599809793230814

Epoch: 5| Step: 4
Training loss: 2.2831457961352166
Validation loss: 2.601181145701824

Epoch: 5| Step: 5
Training loss: 2.433702493996476
Validation loss: 2.6138392868151783

Epoch: 5| Step: 6
Training loss: 1.6533167073480333
Validation loss: 2.557506161232068

Epoch: 5| Step: 7
Training loss: 2.3350230184396614
Validation loss: 2.5958855667775413

Epoch: 5| Step: 8
Training loss: 1.998206765199552
Validation loss: 2.5979245189425684

Epoch: 5| Step: 9
Training loss: 2.600514152014536
Validation loss: 2.5999143302377314

Epoch: 5| Step: 10
Training loss: 1.7850566811204125
Validation loss: 2.5780663496986174

Epoch: 295| Step: 0
Training loss: 2.149037003537171
Validation loss: 2.5641022931829234

Epoch: 5| Step: 1
Training loss: 2.39588389688845
Validation loss: 2.584640912486423

Epoch: 5| Step: 2
Training loss: 2.3793956835654146
Validation loss: 2.5722737356999206

Epoch: 5| Step: 3
Training loss: 2.1987215228727903
Validation loss: 2.569500779991497

Epoch: 5| Step: 4
Training loss: 2.137984268922804
Validation loss: 2.581255366492538

Epoch: 5| Step: 5
Training loss: 2.0538673069259437
Validation loss: 2.612387680745636

Epoch: 5| Step: 6
Training loss: 2.268378222561132
Validation loss: 2.6089128371493526

Epoch: 5| Step: 7
Training loss: 2.459923429305403
Validation loss: 2.6011982777721863

Epoch: 5| Step: 8
Training loss: 2.336900799494854
Validation loss: 2.604960764907411

Epoch: 5| Step: 9
Training loss: 1.8780648296448008
Validation loss: 2.5737672980348183

Epoch: 5| Step: 10
Training loss: 2.4489590204438856
Validation loss: 2.6451351882834495

Epoch: 296| Step: 0
Training loss: 1.4286493586673925
Validation loss: 2.5678990889002202

Epoch: 5| Step: 1
Training loss: 2.532163855338592
Validation loss: 2.614593759465377

Epoch: 5| Step: 2
Training loss: 2.3875611062743185
Validation loss: 2.6012074139103882

Epoch: 5| Step: 3
Training loss: 2.287161809383732
Validation loss: 2.5831902338963215

Epoch: 5| Step: 4
Training loss: 2.1811315203736523
Validation loss: 2.594705892060138

Epoch: 5| Step: 5
Training loss: 2.699978005354976
Validation loss: 2.5801386790259966

Epoch: 5| Step: 6
Training loss: 2.067711920619002
Validation loss: 2.5883514188468446

Epoch: 5| Step: 7
Training loss: 2.24416208547452
Validation loss: 2.5653537993358007

Epoch: 5| Step: 8
Training loss: 1.7974298698528364
Validation loss: 2.59130514843111

Epoch: 5| Step: 9
Training loss: 2.560893229578457
Validation loss: 2.593894640154654

Epoch: 5| Step: 10
Training loss: 2.0639806114661194
Validation loss: 2.517790217014605

Epoch: 297| Step: 0
Training loss: 2.700235575536163
Validation loss: 2.552398560380362

Epoch: 5| Step: 1
Training loss: 2.2489585585518235
Validation loss: 2.603299924934861

Epoch: 5| Step: 2
Training loss: 2.2395252545536724
Validation loss: 2.5758483746296017

Epoch: 5| Step: 3
Training loss: 1.859818926477865
Validation loss: 2.5525593423997353

Epoch: 5| Step: 4
Training loss: 2.0885592211764856
Validation loss: 2.5666766220696626

Epoch: 5| Step: 5
Training loss: 2.4105273784862185
Validation loss: 2.5145974241060842

Epoch: 5| Step: 6
Training loss: 1.9314033200535161
Validation loss: 2.5445396294870286

Epoch: 5| Step: 7
Training loss: 2.961609132630432
Validation loss: 2.542014029852865

Epoch: 5| Step: 8
Training loss: 1.6841385882473652
Validation loss: 2.584882532350884

Epoch: 5| Step: 9
Training loss: 2.281279054221552
Validation loss: 2.5398819008094002

Epoch: 5| Step: 10
Training loss: 2.094672725670346
Validation loss: 2.5660501913842246

Epoch: 298| Step: 0
Training loss: 2.4626430837820092
Validation loss: 2.592105196195025

Epoch: 5| Step: 1
Training loss: 2.408733424004462
Validation loss: 2.5547406209667574

Epoch: 5| Step: 2
Training loss: 2.067291012664274
Validation loss: 2.5455905038887874

Epoch: 5| Step: 3
Training loss: 2.5909025809709694
Validation loss: 2.5912752746283667

Epoch: 5| Step: 4
Training loss: 2.0783867922068837
Validation loss: 2.546794859647437

Epoch: 5| Step: 5
Training loss: 1.9154146362099194
Validation loss: 2.555653744375175

Epoch: 5| Step: 6
Training loss: 2.1356428321225636
Validation loss: 2.584741303658092

Epoch: 5| Step: 7
Training loss: 2.1257473248596477
Validation loss: 2.5596689972836293

Epoch: 5| Step: 8
Training loss: 2.445953772556405
Validation loss: 2.5771464081916067

Epoch: 5| Step: 9
Training loss: 2.474529021177151
Validation loss: 2.5494706036840573

Epoch: 5| Step: 10
Training loss: 1.7252096684507559
Validation loss: 2.603269220742085

Epoch: 299| Step: 0
Training loss: 2.176761207903083
Validation loss: 2.5843413523565903

Epoch: 5| Step: 1
Training loss: 2.2700065600934796
Validation loss: 2.567925880257211

Epoch: 5| Step: 2
Training loss: 1.9190966364475797
Validation loss: 2.57900428233618

Epoch: 5| Step: 3
Training loss: 2.38641325498577
Validation loss: 2.5922474339578248

Epoch: 5| Step: 4
Training loss: 2.2632647618097095
Validation loss: 2.5765876002011865

Epoch: 5| Step: 5
Training loss: 2.7954165955848325
Validation loss: 2.558649114394737

Epoch: 5| Step: 6
Training loss: 1.5853270309447023
Validation loss: 2.5616008182375194

Epoch: 5| Step: 7
Training loss: 2.193733271782285
Validation loss: 2.5736619739131275

Epoch: 5| Step: 8
Training loss: 2.33657419974977
Validation loss: 2.522155286616532

Epoch: 5| Step: 9
Training loss: 2.263643858689333
Validation loss: 2.5528903959981255

Epoch: 5| Step: 10
Training loss: 2.200158252226159
Validation loss: 2.6042104810084763

Epoch: 300| Step: 0
Training loss: 2.6830317590392827
Validation loss: 2.6298084888784135

Epoch: 5| Step: 1
Training loss: 1.471458210825178
Validation loss: 2.6051276919832613

Epoch: 5| Step: 2
Training loss: 2.308141983676282
Validation loss: 2.5799810754231856

Epoch: 5| Step: 3
Training loss: 2.463968402659953
Validation loss: 2.5941568908710657

Epoch: 5| Step: 4
Training loss: 2.3627039180528575
Validation loss: 2.593408462527944

Epoch: 5| Step: 5
Training loss: 2.503825979389282
Validation loss: 2.6203044101808555

Epoch: 5| Step: 6
Training loss: 1.5865481098477443
Validation loss: 2.608507048985243

Epoch: 5| Step: 7
Training loss: 2.2072008455994534
Validation loss: 2.573331346025974

Epoch: 5| Step: 8
Training loss: 1.7874305311455505
Validation loss: 2.59028918647125

Epoch: 5| Step: 9
Training loss: 2.3184426733798134
Validation loss: 2.5456140777597773

Epoch: 5| Step: 10
Training loss: 2.828742534174151
Validation loss: 2.60493012064101

Epoch: 301| Step: 0
Training loss: 2.8858520693441125
Validation loss: 2.6043487122596845

Epoch: 5| Step: 1
Training loss: 1.5889921039603576
Validation loss: 2.6027838929671545

Epoch: 5| Step: 2
Training loss: 2.0663028683969134
Validation loss: 2.5482464018499313

Epoch: 5| Step: 3
Training loss: 2.0939934432428955
Validation loss: 2.588027518442625

Epoch: 5| Step: 4
Training loss: 1.7287793319321079
Validation loss: 2.5920704467883957

Epoch: 5| Step: 5
Training loss: 2.7401590262159305
Validation loss: 2.6070292795892116

Epoch: 5| Step: 6
Training loss: 2.378776960195087
Validation loss: 2.5424926074132057

Epoch: 5| Step: 7
Training loss: 2.256598228570063
Validation loss: 2.534348888345397

Epoch: 5| Step: 8
Training loss: 2.5197312859666217
Validation loss: 2.5490015964350103

Epoch: 5| Step: 9
Training loss: 2.082067550142337
Validation loss: 2.5840460051935406

Epoch: 5| Step: 10
Training loss: 2.192148446722868
Validation loss: 2.5941056522768102

Epoch: 302| Step: 0
Training loss: 1.8523973602813186
Validation loss: 2.5420980381617775

Epoch: 5| Step: 1
Training loss: 2.272417921340288
Validation loss: 2.5552925085129456

Epoch: 5| Step: 2
Training loss: 2.293171706307527
Validation loss: 2.5906856288757547

Epoch: 5| Step: 3
Training loss: 2.2867338554735754
Validation loss: 2.5724546181940213

Epoch: 5| Step: 4
Training loss: 1.8235341652006558
Validation loss: 2.5575721031748846

Epoch: 5| Step: 5
Training loss: 2.4001818349619573
Validation loss: 2.5927319871994876

Epoch: 5| Step: 6
Training loss: 2.2767226352021015
Validation loss: 2.5844631013746526

Epoch: 5| Step: 7
Training loss: 1.857472833201154
Validation loss: 2.5599536855206813

Epoch: 5| Step: 8
Training loss: 2.409536421102184
Validation loss: 2.5692463998503823

Epoch: 5| Step: 9
Training loss: 2.1797795976986887
Validation loss: 2.5930453283578916

Epoch: 5| Step: 10
Training loss: 3.1063803816206064
Validation loss: 2.549635550087276

Epoch: 303| Step: 0
Training loss: 2.8064431138912416
Validation loss: 2.5572219323514687

Epoch: 5| Step: 1
Training loss: 1.6924213420446395
Validation loss: 2.591846202762955

Epoch: 5| Step: 2
Training loss: 2.5566348432063157
Validation loss: 2.5561197899549786

Epoch: 5| Step: 3
Training loss: 2.020802671324413
Validation loss: 2.581974981035326

Epoch: 5| Step: 4
Training loss: 2.9658487699799534
Validation loss: 2.557590340280055

Epoch: 5| Step: 5
Training loss: 2.3057838030772104
Validation loss: 2.5758664522325585

Epoch: 5| Step: 6
Training loss: 2.0115761715630467
Validation loss: 2.579393318363057

Epoch: 5| Step: 7
Training loss: 2.224774522822185
Validation loss: 2.5893432349332346

Epoch: 5| Step: 8
Training loss: 2.3927034804533416
Validation loss: 2.607657970152215

Epoch: 5| Step: 9
Training loss: 1.7225589508466308
Validation loss: 2.61664597368755

Epoch: 5| Step: 10
Training loss: 1.6053984318019479
Validation loss: 2.5979960962314026

Epoch: 304| Step: 0
Training loss: 1.927098873866199
Validation loss: 2.5510271154871766

Epoch: 5| Step: 1
Training loss: 2.0551028683943335
Validation loss: 2.632414196050991

Epoch: 5| Step: 2
Training loss: 1.8994330790138994
Validation loss: 2.5485486278519556

Epoch: 5| Step: 3
Training loss: 2.494739624839805
Validation loss: 2.6159123098001187

Epoch: 5| Step: 4
Training loss: 2.5261379472664167
Validation loss: 2.5646680788634715

Epoch: 5| Step: 5
Training loss: 2.2937111375723167
Validation loss: 2.5772088405253517

Epoch: 5| Step: 6
Training loss: 1.9123038795990785
Validation loss: 2.5842808005809874

Epoch: 5| Step: 7
Training loss: 1.9371284620848934
Validation loss: 2.6142307340017923

Epoch: 5| Step: 8
Training loss: 1.800834737715673
Validation loss: 2.586136576830769

Epoch: 5| Step: 9
Training loss: 2.9055156805520914
Validation loss: 2.548412131672918

Epoch: 5| Step: 10
Training loss: 2.2811298077417836
Validation loss: 2.5577681327122708

Epoch: 305| Step: 0
Training loss: 1.8208650069751764
Validation loss: 2.533284600039564

Epoch: 5| Step: 1
Training loss: 1.6883109228235313
Validation loss: 2.59243464608537

Epoch: 5| Step: 2
Training loss: 3.374961146378279
Validation loss: 2.598815007176355

Epoch: 5| Step: 3
Training loss: 2.6930617513110446
Validation loss: 2.560815661276457

Epoch: 5| Step: 4
Training loss: 1.883624269862397
Validation loss: 2.58270702120004

Epoch: 5| Step: 5
Training loss: 1.6633388038091712
Validation loss: 2.57678826395062

Epoch: 5| Step: 6
Training loss: 2.082607626085854
Validation loss: 2.5579240681694215

Epoch: 5| Step: 7
Training loss: 2.3514350527068335
Validation loss: 2.56996015675909

Epoch: 5| Step: 8
Training loss: 2.1679339981730466
Validation loss: 2.5484017298631243

Epoch: 5| Step: 9
Training loss: 2.2643867002559213
Validation loss: 2.554352323534918

Epoch: 5| Step: 10
Training loss: 1.777360182466104
Validation loss: 2.5678060737199617

Epoch: 306| Step: 0
Training loss: 2.049178014503799
Validation loss: 2.541911974392266

Epoch: 5| Step: 1
Training loss: 2.046088147528961
Validation loss: 2.602488103205021

Epoch: 5| Step: 2
Training loss: 2.1101077467178753
Validation loss: 2.585232054442779

Epoch: 5| Step: 3
Training loss: 2.2786737814506286
Validation loss: 2.5647296074659813

Epoch: 5| Step: 4
Training loss: 2.0415718160381977
Validation loss: 2.5654970476073955

Epoch: 5| Step: 5
Training loss: 1.7831781224715555
Validation loss: 2.5702619500576502

Epoch: 5| Step: 6
Training loss: 2.9679119332607073
Validation loss: 2.601227614813164

Epoch: 5| Step: 7
Training loss: 2.302304759243931
Validation loss: 2.5156062365009033

Epoch: 5| Step: 8
Training loss: 2.143024742293365
Validation loss: 2.556412658402381

Epoch: 5| Step: 9
Training loss: 1.5443694505086232
Validation loss: 2.6198689912062316

Epoch: 5| Step: 10
Training loss: 2.9090521644591445
Validation loss: 2.574915218620199

Epoch: 307| Step: 0
Training loss: 1.659984552817113
Validation loss: 2.5594128546668085

Epoch: 5| Step: 1
Training loss: 1.9923159688778236
Validation loss: 2.5539288452567486

Epoch: 5| Step: 2
Training loss: 2.561349564009234
Validation loss: 2.6006064517812

Epoch: 5| Step: 3
Training loss: 1.92361730979291
Validation loss: 2.5943015093285045

Epoch: 5| Step: 4
Training loss: 2.4926565081741447
Validation loss: 2.5889035949871464

Epoch: 5| Step: 5
Training loss: 1.6850366626905202
Validation loss: 2.600886151459169

Epoch: 5| Step: 6
Training loss: 2.677235006545641
Validation loss: 2.599251634262457

Epoch: 5| Step: 7
Training loss: 2.5786926569366906
Validation loss: 2.6301874137801065

Epoch: 5| Step: 8
Training loss: 2.1267246652584926
Validation loss: 2.553871438139724

Epoch: 5| Step: 9
Training loss: 2.3424512189184847
Validation loss: 2.601770317500433

Epoch: 5| Step: 10
Training loss: 2.3147065229163384
Validation loss: 2.624150888412251

Epoch: 308| Step: 0
Training loss: 2.4773081911362684
Validation loss: 2.598016846077826

Epoch: 5| Step: 1
Training loss: 2.215662782936065
Validation loss: 2.5637687915470844

Epoch: 5| Step: 2
Training loss: 2.638168727473499
Validation loss: 2.5604097478497367

Epoch: 5| Step: 3
Training loss: 1.7058141633810686
Validation loss: 2.55368979251234

Epoch: 5| Step: 4
Training loss: 2.1362246093669643
Validation loss: 2.558506907567635

Epoch: 5| Step: 5
Training loss: 2.5946935752807634
Validation loss: 2.5675661842719273

Epoch: 5| Step: 6
Training loss: 2.1287062244763866
Validation loss: 2.564126649681129

Epoch: 5| Step: 7
Training loss: 1.8523031435424906
Validation loss: 2.601927792498016

Epoch: 5| Step: 8
Training loss: 2.2666649897887066
Validation loss: 2.5634414240103243

Epoch: 5| Step: 9
Training loss: 1.935953692229184
Validation loss: 2.609707007613134

Epoch: 5| Step: 10
Training loss: 2.543329591244219
Validation loss: 2.5096108292885564

Epoch: 309| Step: 0
Training loss: 2.0196554415090193
Validation loss: 2.6098038476535654

Epoch: 5| Step: 1
Training loss: 1.8051616491704061
Validation loss: 2.5460913181137563

Epoch: 5| Step: 2
Training loss: 2.2603898171325953
Validation loss: 2.5942318831053566

Epoch: 5| Step: 3
Training loss: 3.0739865439523157
Validation loss: 2.5530731247312657

Epoch: 5| Step: 4
Training loss: 1.9705858299652639
Validation loss: 2.6039238056435923

Epoch: 5| Step: 5
Training loss: 2.7074590788026907
Validation loss: 2.6099475116847937

Epoch: 5| Step: 6
Training loss: 1.498484561248765
Validation loss: 2.581998302144071

Epoch: 5| Step: 7
Training loss: 1.766460727288568
Validation loss: 2.5970752610070718

Epoch: 5| Step: 8
Training loss: 2.675786507037491
Validation loss: 2.617955419424007

Epoch: 5| Step: 9
Training loss: 1.837012637635329
Validation loss: 2.5925076322881955

Epoch: 5| Step: 10
Training loss: 2.153235941161708
Validation loss: 2.580368837533201

Epoch: 310| Step: 0
Training loss: 2.0586460982729817
Validation loss: 2.5780032092152356

Epoch: 5| Step: 1
Training loss: 1.557370884474171
Validation loss: 2.5669593226948444

Epoch: 5| Step: 2
Training loss: 2.1136077233813757
Validation loss: 2.5487530984044824

Epoch: 5| Step: 3
Training loss: 2.5605779743415558
Validation loss: 2.5550289808283715

Epoch: 5| Step: 4
Training loss: 2.353745673241997
Validation loss: 2.5358280846644217

Epoch: 5| Step: 5
Training loss: 1.7941861808602713
Validation loss: 2.5713153419625274

Epoch: 5| Step: 6
Training loss: 2.0740297737890545
Validation loss: 2.579981702426639

Epoch: 5| Step: 7
Training loss: 2.359763612384819
Validation loss: 2.567437236478977

Epoch: 5| Step: 8
Training loss: 1.8314914843595353
Validation loss: 2.5032998446672843

Epoch: 5| Step: 9
Training loss: 2.629328292819925
Validation loss: 2.5503337683496006

Epoch: 5| Step: 10
Training loss: 2.728021619308362
Validation loss: 2.599998989964834

Epoch: 311| Step: 0
Training loss: 2.506107879947034
Validation loss: 2.567003993478379

Epoch: 5| Step: 1
Training loss: 2.142915822542655
Validation loss: 2.559967093768952

Epoch: 5| Step: 2
Training loss: 2.1984502015224767
Validation loss: 2.6048955708600845

Epoch: 5| Step: 3
Training loss: 2.6085037330160543
Validation loss: 2.5851150591276673

Epoch: 5| Step: 4
Training loss: 2.9203748472854008
Validation loss: 2.5613846556297033

Epoch: 5| Step: 5
Training loss: 2.1540265990220346
Validation loss: 2.5776959820197964

Epoch: 5| Step: 6
Training loss: 1.9160673890815931
Validation loss: 2.572621819889966

Epoch: 5| Step: 7
Training loss: 1.8046887550514779
Validation loss: 2.639660677572413

Epoch: 5| Step: 8
Training loss: 1.8504933034615407
Validation loss: 2.5876737017429585

Epoch: 5| Step: 9
Training loss: 1.9263799947533173
Validation loss: 2.5707512486141555

Epoch: 5| Step: 10
Training loss: 2.1112167794847663
Validation loss: 2.58773692625975

Epoch: 312| Step: 0
Training loss: 2.382149826206284
Validation loss: 2.588344764974499

Epoch: 5| Step: 1
Training loss: 2.6150000697294558
Validation loss: 2.562057230763985

Epoch: 5| Step: 2
Training loss: 2.012444167221561
Validation loss: 2.59154193431485

Epoch: 5| Step: 3
Training loss: 2.487784199797475
Validation loss: 2.548188771139374

Epoch: 5| Step: 4
Training loss: 1.576575925862486
Validation loss: 2.5620798306229267

Epoch: 5| Step: 5
Training loss: 1.5213533670731738
Validation loss: 2.5793614827839835

Epoch: 5| Step: 6
Training loss: 1.944645840190795
Validation loss: 2.597511626850046

Epoch: 5| Step: 7
Training loss: 2.5551073388472365
Validation loss: 2.6197190671091035

Epoch: 5| Step: 8
Training loss: 2.4070318363811767
Validation loss: 2.5328230988709897

Epoch: 5| Step: 9
Training loss: 2.3922462700340237
Validation loss: 2.5442514370429903

Epoch: 5| Step: 10
Training loss: 2.3273176803230027
Validation loss: 2.579423455006696

Epoch: 313| Step: 0
Training loss: 2.0672038221111335
Validation loss: 2.554537146503668

Epoch: 5| Step: 1
Training loss: 1.6011552246300125
Validation loss: 2.6088322686695045

Epoch: 5| Step: 2
Training loss: 2.4604210690150228
Validation loss: 2.5726905382284917

Epoch: 5| Step: 3
Training loss: 2.5005207473086375
Validation loss: 2.592890797157356

Epoch: 5| Step: 4
Training loss: 2.752679906192253
Validation loss: 2.5624480163439722

Epoch: 5| Step: 5
Training loss: 1.95394550636388
Validation loss: 2.613432180049078

Epoch: 5| Step: 6
Training loss: 1.9346851081814875
Validation loss: 2.563115347934871

Epoch: 5| Step: 7
Training loss: 2.164726733786557
Validation loss: 2.59612982886396

Epoch: 5| Step: 8
Training loss: 2.1556809268729653
Validation loss: 2.6086938971365248

Epoch: 5| Step: 9
Training loss: 2.614826378538101
Validation loss: 2.597746912444048

Epoch: 5| Step: 10
Training loss: 2.049719428424293
Validation loss: 2.56786698402847

Epoch: 314| Step: 0
Training loss: 2.1226680526433346
Validation loss: 2.6033750683714016

Epoch: 5| Step: 1
Training loss: 2.320711454778804
Validation loss: 2.554756447863048

Epoch: 5| Step: 2
Training loss: 2.145303666998897
Validation loss: 2.567681605935384

Epoch: 5| Step: 3
Training loss: 2.293030200245313
Validation loss: 2.6220533959996497

Epoch: 5| Step: 4
Training loss: 1.6793729265751762
Validation loss: 2.5778023287602703

Epoch: 5| Step: 5
Training loss: 2.580888411570899
Validation loss: 2.566021090570799

Epoch: 5| Step: 6
Training loss: 2.260557413480382
Validation loss: 2.6024614607856176

Epoch: 5| Step: 7
Training loss: 2.2714628577750746
Validation loss: 2.561916738140607

Epoch: 5| Step: 8
Training loss: 1.8701539675927894
Validation loss: 2.5835773178804433

Epoch: 5| Step: 9
Training loss: 2.508940731110267
Validation loss: 2.61512299414074

Epoch: 5| Step: 10
Training loss: 2.084562727268243
Validation loss: 2.584102885819581

Epoch: 315| Step: 0
Training loss: 2.2795520891286474
Validation loss: 2.597072219669941

Epoch: 5| Step: 1
Training loss: 2.0709414120670715
Validation loss: 2.590465247307162

Epoch: 5| Step: 2
Training loss: 2.1156984843306765
Validation loss: 2.5813528746612144

Epoch: 5| Step: 3
Training loss: 2.8419629864466933
Validation loss: 2.6299380486522588

Epoch: 5| Step: 4
Training loss: 2.165433043412548
Validation loss: 2.582627994720137

Epoch: 5| Step: 5
Training loss: 1.8827206917693746
Validation loss: 2.5698217801308676

Epoch: 5| Step: 6
Training loss: 1.9230227880927906
Validation loss: 2.613238933047772

Epoch: 5| Step: 7
Training loss: 2.191666259572193
Validation loss: 2.5657298244784137

Epoch: 5| Step: 8
Training loss: 1.9939538044337182
Validation loss: 2.6104860907916243

Epoch: 5| Step: 9
Training loss: 2.3903384566771044
Validation loss: 2.547711191131079

Epoch: 5| Step: 10
Training loss: 2.285583769103285
Validation loss: 2.608839190640264

Epoch: 316| Step: 0
Training loss: 2.428735282723781
Validation loss: 2.5982988096830155

Epoch: 5| Step: 1
Training loss: 2.357300003807933
Validation loss: 2.5411052342665053

Epoch: 5| Step: 2
Training loss: 1.849393129043959
Validation loss: 2.553494950824694

Epoch: 5| Step: 3
Training loss: 2.309703476274699
Validation loss: 2.5924426867623884

Epoch: 5| Step: 4
Training loss: 2.765523876345751
Validation loss: 2.5973185189317727

Epoch: 5| Step: 5
Training loss: 1.9957084507851537
Validation loss: 2.599049505029188

Epoch: 5| Step: 6
Training loss: 2.1473223757309805
Validation loss: 2.6007095520774435

Epoch: 5| Step: 7
Training loss: 1.757425765834282
Validation loss: 2.6184638549939443

Epoch: 5| Step: 8
Training loss: 1.708242793901637
Validation loss: 2.58803640390341

Epoch: 5| Step: 9
Training loss: 2.1021343148145295
Validation loss: 2.5909610782392645

Epoch: 5| Step: 10
Training loss: 2.4524684926535745
Validation loss: 2.6118738437448394

Epoch: 317| Step: 0
Training loss: 2.0666713724800596
Validation loss: 2.5324037242649813

Epoch: 5| Step: 1
Training loss: 1.9668348776546705
Validation loss: 2.5881109930234834

Epoch: 5| Step: 2
Training loss: 2.7456100276588287
Validation loss: 2.596229963890291

Epoch: 5| Step: 3
Training loss: 1.8921563118365383
Validation loss: 2.589871977331464

Epoch: 5| Step: 4
Training loss: 2.04938289379055
Validation loss: 2.5619411934687317

Epoch: 5| Step: 5
Training loss: 2.211157797901466
Validation loss: 2.590084187202894

Epoch: 5| Step: 6
Training loss: 2.5395930748226685
Validation loss: 2.5853650052608743

Epoch: 5| Step: 7
Training loss: 1.7046236916128834
Validation loss: 2.5717758739146714

Epoch: 5| Step: 8
Training loss: 2.8922086759232033
Validation loss: 2.538036455782373

Epoch: 5| Step: 9
Training loss: 1.9129600619799851
Validation loss: 2.5794163089905324

Epoch: 5| Step: 10
Training loss: 1.9255434086695253
Validation loss: 2.5818385530946233

Epoch: 318| Step: 0
Training loss: 1.859200990372294
Validation loss: 2.595730236779804

Epoch: 5| Step: 1
Training loss: 2.881596999053409
Validation loss: 2.587917686873493

Epoch: 5| Step: 2
Training loss: 1.8231559451056156
Validation loss: 2.6017573818628397

Epoch: 5| Step: 3
Training loss: 1.8817255198575402
Validation loss: 2.582652241027522

Epoch: 5| Step: 4
Training loss: 2.2478438748891048
Validation loss: 2.5386495618221114

Epoch: 5| Step: 5
Training loss: 1.7979389523760108
Validation loss: 2.5858428752377933

Epoch: 5| Step: 6
Training loss: 2.0586361383058844
Validation loss: 2.5546332178529543

Epoch: 5| Step: 7
Training loss: 2.2832070930648793
Validation loss: 2.5802469102306596

Epoch: 5| Step: 8
Training loss: 2.4015714070658163
Validation loss: 2.586374591206207

Epoch: 5| Step: 9
Training loss: 2.7806411248132044
Validation loss: 2.5350241225385446

Epoch: 5| Step: 10
Training loss: 2.0551890642204094
Validation loss: 2.5744271536125676

Epoch: 319| Step: 0
Training loss: 2.0386950867050166
Validation loss: 2.595993592773362

Epoch: 5| Step: 1
Training loss: 1.9063970790467675
Validation loss: 2.5493418900127427

Epoch: 5| Step: 2
Training loss: 2.2912412306331094
Validation loss: 2.5610649878949303

Epoch: 5| Step: 3
Training loss: 1.8484307051184679
Validation loss: 2.6177749251274274

Epoch: 5| Step: 4
Training loss: 2.0144131588258363
Validation loss: 2.5831401890358103

Epoch: 5| Step: 5
Training loss: 2.928652486443644
Validation loss: 2.5882584136316695

Epoch: 5| Step: 6
Training loss: 2.3719401475003483
Validation loss: 2.5622742616241116

Epoch: 5| Step: 7
Training loss: 2.0542542903800096
Validation loss: 2.5930530626348682

Epoch: 5| Step: 8
Training loss: 1.9120860580565684
Validation loss: 2.5913989079478816

Epoch: 5| Step: 9
Training loss: 1.9966813209942698
Validation loss: 2.577736028151188

Epoch: 5| Step: 10
Training loss: 2.597870185474985
Validation loss: 2.591862756581857

Epoch: 320| Step: 0
Training loss: 2.3775013249952153
Validation loss: 2.6312644216654593

Epoch: 5| Step: 1
Training loss: 2.0842564127300527
Validation loss: 2.6207838151383203

Epoch: 5| Step: 2
Training loss: 2.2292225792073133
Validation loss: 2.606981893148772

Epoch: 5| Step: 3
Training loss: 2.1090566889459135
Validation loss: 2.6129665640534085

Epoch: 5| Step: 4
Training loss: 1.9431084092230382
Validation loss: 2.6075929241572426

Epoch: 5| Step: 5
Training loss: 1.6817405750730177
Validation loss: 2.591789690892356

Epoch: 5| Step: 6
Training loss: 2.0580657918958694
Validation loss: 2.559619904758556

Epoch: 5| Step: 7
Training loss: 2.1973868239143406
Validation loss: 2.6112001660317574

Epoch: 5| Step: 8
Training loss: 2.6408676848540233
Validation loss: 2.5787517940402123

Epoch: 5| Step: 9
Training loss: 1.8249402467534603
Validation loss: 2.5501806459776986

Epoch: 5| Step: 10
Training loss: 2.797768647195254
Validation loss: 2.5951091942689666

Epoch: 321| Step: 0
Training loss: 2.0943873559854254
Validation loss: 2.526635839424821

Epoch: 5| Step: 1
Training loss: 2.215755429753293
Validation loss: 2.6138782927432995

Epoch: 5| Step: 2
Training loss: 2.1227060165440053
Validation loss: 2.5883363252883473

Epoch: 5| Step: 3
Training loss: 2.6175518636292696
Validation loss: 2.570157670268327

Epoch: 5| Step: 4
Training loss: 2.3816525497000347
Validation loss: 2.5404462942420074

Epoch: 5| Step: 5
Training loss: 2.3919895242187343
Validation loss: 2.5654643660648055

Epoch: 5| Step: 6
Training loss: 2.6423777344278667
Validation loss: 2.572047160682488

Epoch: 5| Step: 7
Training loss: 1.933537646163653
Validation loss: 2.6039047499992023

Epoch: 5| Step: 8
Training loss: 1.6355521840441434
Validation loss: 2.591269198122563

Epoch: 5| Step: 9
Training loss: 1.6440375305031454
Validation loss: 2.586622871473878

Epoch: 5| Step: 10
Training loss: 2.381571261944562
Validation loss: 2.529055795041808

Epoch: 322| Step: 0
Training loss: 1.7247832784100472
Validation loss: 2.5944257089060283

Epoch: 5| Step: 1
Training loss: 2.280187699137582
Validation loss: 2.569485675473936

Epoch: 5| Step: 2
Training loss: 2.4655184298499346
Validation loss: 2.610792528926962

Epoch: 5| Step: 3
Training loss: 2.3236011357716237
Validation loss: 2.55603232587324

Epoch: 5| Step: 4
Training loss: 2.495085463350181
Validation loss: 2.5277167392739823

Epoch: 5| Step: 5
Training loss: 1.7498270358031565
Validation loss: 2.59013824899396

Epoch: 5| Step: 6
Training loss: 2.3677715928006715
Validation loss: 2.6410115170223873

Epoch: 5| Step: 7
Training loss: 2.1798420512873844
Validation loss: 2.5664435015429854

Epoch: 5| Step: 8
Training loss: 1.965678528752771
Validation loss: 2.5784749966555482

Epoch: 5| Step: 9
Training loss: 2.1955928962808042
Validation loss: 2.601893766440549

Epoch: 5| Step: 10
Training loss: 2.3757149473532975
Validation loss: 2.5925904306287815

Epoch: 323| Step: 0
Training loss: 1.9142612899002953
Validation loss: 2.573503701717639

Epoch: 5| Step: 1
Training loss: 2.2125122069975753
Validation loss: 2.5314376236890106

Epoch: 5| Step: 2
Training loss: 1.9455966971667389
Validation loss: 2.581770068316789

Epoch: 5| Step: 3
Training loss: 2.3281608425171942
Validation loss: 2.6158069685054772

Epoch: 5| Step: 4
Training loss: 2.432085332076159
Validation loss: 2.5682875631739353

Epoch: 5| Step: 5
Training loss: 1.8835943980712282
Validation loss: 2.5709116167948443

Epoch: 5| Step: 6
Training loss: 2.5924235249701395
Validation loss: 2.5760232531650176

Epoch: 5| Step: 7
Training loss: 1.9594084717052946
Validation loss: 2.5837857117920375

Epoch: 5| Step: 8
Training loss: 2.394752081540688
Validation loss: 2.552262796433539

Epoch: 5| Step: 9
Training loss: 1.8104544968890508
Validation loss: 2.5954707042630853

Epoch: 5| Step: 10
Training loss: 2.189285094919608
Validation loss: 2.520014606956967

Epoch: 324| Step: 0
Training loss: 2.016985175566695
Validation loss: 2.5417414680608013

Epoch: 5| Step: 1
Training loss: 2.355416317889178
Validation loss: 2.598430920259833

Epoch: 5| Step: 2
Training loss: 1.9385839322043623
Validation loss: 2.6117387754084183

Epoch: 5| Step: 3
Training loss: 1.8596046370063024
Validation loss: 2.5836252209051036

Epoch: 5| Step: 4
Training loss: 2.171434316591679
Validation loss: 2.5994073840434875

Epoch: 5| Step: 5
Training loss: 2.2281167478261454
Validation loss: 2.6022573613088547

Epoch: 5| Step: 6
Training loss: 2.246282367250206
Validation loss: 2.5651903153719546

Epoch: 5| Step: 7
Training loss: 2.5705264851738496
Validation loss: 2.568905571962971

Epoch: 5| Step: 8
Training loss: 2.235096528189762
Validation loss: 2.5830870695229176

Epoch: 5| Step: 9
Training loss: 2.4824560659771677
Validation loss: 2.5553690255377286

Epoch: 5| Step: 10
Training loss: 1.8916932548077223
Validation loss: 2.590376773524479

Epoch: 325| Step: 0
Training loss: 2.8910010840652425
Validation loss: 2.5945028405228774

Epoch: 5| Step: 1
Training loss: 2.0094412642924184
Validation loss: 2.5513651724923445

Epoch: 5| Step: 2
Training loss: 2.318555995506012
Validation loss: 2.6329911708957394

Epoch: 5| Step: 3
Training loss: 2.0002353052954276
Validation loss: 2.5375381374316985

Epoch: 5| Step: 4
Training loss: 2.3051066389261234
Validation loss: 2.58458010041236

Epoch: 5| Step: 5
Training loss: 2.0983475268881016
Validation loss: 2.640657556154365

Epoch: 5| Step: 6
Training loss: 1.3809039204492857
Validation loss: 2.563803678565709

Epoch: 5| Step: 7
Training loss: 2.0879313908336092
Validation loss: 2.579504136031764

Epoch: 5| Step: 8
Training loss: 2.3035398567714473
Validation loss: 2.6279501639258167

Epoch: 5| Step: 9
Training loss: 2.278367612292978
Validation loss: 2.544079045423101

Epoch: 5| Step: 10
Training loss: 2.1884885461658734
Validation loss: 2.6086508394677392

Epoch: 326| Step: 0
Training loss: 2.365890399351666
Validation loss: 2.6059401847688655

Epoch: 5| Step: 1
Training loss: 2.632880597691285
Validation loss: 2.5942054582895278

Epoch: 5| Step: 2
Training loss: 1.3439119374483397
Validation loss: 2.6126641135352107

Epoch: 5| Step: 3
Training loss: 2.3175838365585695
Validation loss: 2.594419202034509

Epoch: 5| Step: 4
Training loss: 1.7552089823222634
Validation loss: 2.563291384460674

Epoch: 5| Step: 5
Training loss: 2.458876070359876
Validation loss: 2.626455713966893

Epoch: 5| Step: 6
Training loss: 2.3069272295285104
Validation loss: 2.686516261458631

Epoch: 5| Step: 7
Training loss: 2.19364165122753
Validation loss: 2.5561362421673564

Epoch: 5| Step: 8
Training loss: 1.8643399156062854
Validation loss: 2.5544936978492934

Epoch: 5| Step: 9
Training loss: 2.306473586246488
Validation loss: 2.612732369396931

Epoch: 5| Step: 10
Training loss: 2.0163148394456654
Validation loss: 2.5512302609464483

Epoch: 327| Step: 0
Training loss: 2.4014703418966126
Validation loss: 2.5426493949935685

Epoch: 5| Step: 1
Training loss: 2.3924754840866327
Validation loss: 2.5773401482096787

Epoch: 5| Step: 2
Training loss: 1.6395905639540704
Validation loss: 2.5962700736955333

Epoch: 5| Step: 3
Training loss: 1.7818617188632082
Validation loss: 2.572660679458992

Epoch: 5| Step: 4
Training loss: 1.9678365616813787
Validation loss: 2.612459078146051

Epoch: 5| Step: 5
Training loss: 1.9864743759342294
Validation loss: 2.610501142703557

Epoch: 5| Step: 6
Training loss: 1.508200639961288
Validation loss: 2.607640038965361

Epoch: 5| Step: 7
Training loss: 2.7564508031934882
Validation loss: 2.619088985419811

Epoch: 5| Step: 8
Training loss: 2.4308605244968056
Validation loss: 2.600801707895641

Epoch: 5| Step: 9
Training loss: 2.6753102131590834
Validation loss: 2.6060809837478924

Epoch: 5| Step: 10
Training loss: 2.20974192290519
Validation loss: 2.6015540608200793

Epoch: 328| Step: 0
Training loss: 2.2626741331753175
Validation loss: 2.6018122701841846

Epoch: 5| Step: 1
Training loss: 1.7829791593761761
Validation loss: 2.609095612934088

Epoch: 5| Step: 2
Training loss: 2.341460877558644
Validation loss: 2.5440567350893684

Epoch: 5| Step: 3
Training loss: 2.054388568439943
Validation loss: 2.6063649441373036

Epoch: 5| Step: 4
Training loss: 2.2884239373696618
Validation loss: 2.561921657443829

Epoch: 5| Step: 5
Training loss: 2.0247790039411773
Validation loss: 2.582013392044205

Epoch: 5| Step: 6
Training loss: 2.043671642049568
Validation loss: 2.533441729795593

Epoch: 5| Step: 7
Training loss: 2.629706205776366
Validation loss: 2.5707199841398736

Epoch: 5| Step: 8
Training loss: 2.0707653773905585
Validation loss: 2.551104334252852

Epoch: 5| Step: 9
Training loss: 2.3032288153968157
Validation loss: 2.564191901480293

Epoch: 5| Step: 10
Training loss: 1.8423192566790028
Validation loss: 2.529830605551328

Epoch: 329| Step: 0
Training loss: 2.3682985625465096
Validation loss: 2.598514901207748

Epoch: 5| Step: 1
Training loss: 1.8888873477380985
Validation loss: 2.5453978945254936

Epoch: 5| Step: 2
Training loss: 2.021464442647806
Validation loss: 2.544531818275867

Epoch: 5| Step: 3
Training loss: 2.0070048685741817
Validation loss: 2.51346851314143

Epoch: 5| Step: 4
Training loss: 1.9933782870774543
Validation loss: 2.535067176767738

Epoch: 5| Step: 5
Training loss: 2.489185402536477
Validation loss: 2.562815485956418

Epoch: 5| Step: 6
Training loss: 2.157238830282852
Validation loss: 2.5903622603409917

Epoch: 5| Step: 7
Training loss: 2.261272274348353
Validation loss: 2.6165836054426768

Epoch: 5| Step: 8
Training loss: 2.167186479080059
Validation loss: 2.575677283883464

Epoch: 5| Step: 9
Training loss: 1.9327509729187775
Validation loss: 2.5597873218635687

Epoch: 5| Step: 10
Training loss: 2.4433151716812396
Validation loss: 2.575114262522068

Epoch: 330| Step: 0
Training loss: 2.52793790032975
Validation loss: 2.5810968726020076

Epoch: 5| Step: 1
Training loss: 1.6691477269459694
Validation loss: 2.580813097168214

Epoch: 5| Step: 2
Training loss: 2.4494914947941435
Validation loss: 2.589770682782861

Epoch: 5| Step: 3
Training loss: 2.506861806571821
Validation loss: 2.642106724627681

Epoch: 5| Step: 4
Training loss: 2.093091035455132
Validation loss: 2.587959881453874

Epoch: 5| Step: 5
Training loss: 1.9369326960736821
Validation loss: 2.6035754517537235

Epoch: 5| Step: 6
Training loss: 2.16165401691313
Validation loss: 2.593651668989118

Epoch: 5| Step: 7
Training loss: 2.340522884081812
Validation loss: 2.5961084635391556

Epoch: 5| Step: 8
Training loss: 2.0589834347503664
Validation loss: 2.5778430584436918

Epoch: 5| Step: 9
Training loss: 1.4030766604110534
Validation loss: 2.5784862723843855

Epoch: 5| Step: 10
Training loss: 2.3567130122108266
Validation loss: 2.6214454216532235

Epoch: 331| Step: 0
Training loss: 2.2865823583195453
Validation loss: 2.5753616713006147

Epoch: 5| Step: 1
Training loss: 2.0361070516955526
Validation loss: 2.567794448582286

Epoch: 5| Step: 2
Training loss: 1.8387433626741052
Validation loss: 2.528416521201263

Epoch: 5| Step: 3
Training loss: 2.4550602562496113
Validation loss: 2.573176160439559

Epoch: 5| Step: 4
Training loss: 2.2528248114744893
Validation loss: 2.5844052287756996

Epoch: 5| Step: 5
Training loss: 2.0338008416121487
Validation loss: 2.6192549288985787

Epoch: 5| Step: 6
Training loss: 2.06401480331583
Validation loss: 2.5877291196243557

Epoch: 5| Step: 7
Training loss: 1.8648703015102894
Validation loss: 2.5437876695517145

Epoch: 5| Step: 8
Training loss: 2.602888897541644
Validation loss: 2.6320030146432347

Epoch: 5| Step: 9
Training loss: 2.132310409972891
Validation loss: 2.599493974017205

Epoch: 5| Step: 10
Training loss: 1.7853418833836743
Validation loss: 2.55788265148133

Epoch: 332| Step: 0
Training loss: 2.5946442314986684
Validation loss: 2.5986541284611313

Epoch: 5| Step: 1
Training loss: 2.001731361573948
Validation loss: 2.5566421030353434

Epoch: 5| Step: 2
Training loss: 1.6803564114798504
Validation loss: 2.5932408868633128

Epoch: 5| Step: 3
Training loss: 1.998023129020979
Validation loss: 2.586382014368046

Epoch: 5| Step: 4
Training loss: 2.434108820455013
Validation loss: 2.582229572635301

Epoch: 5| Step: 5
Training loss: 1.9501420702898995
Validation loss: 2.6071424418631426

Epoch: 5| Step: 6
Training loss: 2.2466887374306994
Validation loss: 2.6331758192167802

Epoch: 5| Step: 7
Training loss: 2.041822181020838
Validation loss: 2.6016148993630543

Epoch: 5| Step: 8
Training loss: 2.262593734232676
Validation loss: 2.5473570531985934

Epoch: 5| Step: 9
Training loss: 2.5841486987445017
Validation loss: 2.604803772466021

Epoch: 5| Step: 10
Training loss: 1.9815753200364756
Validation loss: 2.607246614073268

Epoch: 333| Step: 0
Training loss: 1.3140913081328214
Validation loss: 2.5455589429798438

Epoch: 5| Step: 1
Training loss: 1.93351594402328
Validation loss: 2.5951817061636473

Epoch: 5| Step: 2
Training loss: 1.7132666076229282
Validation loss: 2.562465470404277

Epoch: 5| Step: 3
Training loss: 2.5881036174142364
Validation loss: 2.5877762384533276

Epoch: 5| Step: 4
Training loss: 1.788661795306791
Validation loss: 2.617186865257807

Epoch: 5| Step: 5
Training loss: 2.814301740187174
Validation loss: 2.577759819232821

Epoch: 5| Step: 6
Training loss: 2.766873525063755
Validation loss: 2.6149138966543237

Epoch: 5| Step: 7
Training loss: 2.4829944157439665
Validation loss: 2.6643102786439963

Epoch: 5| Step: 8
Training loss: 1.8276629393824413
Validation loss: 2.5955755651693235

Epoch: 5| Step: 9
Training loss: 1.720635299125246
Validation loss: 2.5225339126596023

Epoch: 5| Step: 10
Training loss: 1.7284616925290197
Validation loss: 2.5837181101144004

Epoch: 334| Step: 0
Training loss: 2.3427797470866474
Validation loss: 2.5611487797098342

Epoch: 5| Step: 1
Training loss: 2.070707808847101
Validation loss: 2.5698251360373097

Epoch: 5| Step: 2
Training loss: 1.8360012611517802
Validation loss: 2.605751886732979

Epoch: 5| Step: 3
Training loss: 2.5960033693747264
Validation loss: 2.5553926937943188

Epoch: 5| Step: 4
Training loss: 1.5312391786776829
Validation loss: 2.545839615737169

Epoch: 5| Step: 5
Training loss: 2.208374802781848
Validation loss: 2.615744804694326

Epoch: 5| Step: 6
Training loss: 2.5847278543208567
Validation loss: 2.563687730817754

Epoch: 5| Step: 7
Training loss: 2.1901603869926864
Validation loss: 2.6103969751545075

Epoch: 5| Step: 8
Training loss: 1.9819587354435144
Validation loss: 2.5711491241760327

Epoch: 5| Step: 9
Training loss: 2.0692503309702426
Validation loss: 2.579346967752479

Epoch: 5| Step: 10
Training loss: 2.296835451369498
Validation loss: 2.5190545786928777

Epoch: 335| Step: 0
Training loss: 2.473177452659091
Validation loss: 2.5771134008683134

Epoch: 5| Step: 1
Training loss: 1.9522943790416813
Validation loss: 2.5585006820934733

Epoch: 5| Step: 2
Training loss: 2.250945104681216
Validation loss: 2.548520306972103

Epoch: 5| Step: 3
Training loss: 1.871472792170572
Validation loss: 2.617488121285249

Epoch: 5| Step: 4
Training loss: 1.825981383154603
Validation loss: 2.5558353376883387

Epoch: 5| Step: 5
Training loss: 2.2303055204132876
Validation loss: 2.60758358820038

Epoch: 5| Step: 6
Training loss: 2.847022217546282
Validation loss: 2.6317953138073595

Epoch: 5| Step: 7
Training loss: 2.1285057321067584
Validation loss: 2.6086687892578766

Epoch: 5| Step: 8
Training loss: 1.7285436250821835
Validation loss: 2.617224735980173

Epoch: 5| Step: 9
Training loss: 2.043859692350872
Validation loss: 2.600265012349819

Epoch: 5| Step: 10
Training loss: 2.53112142730827
Validation loss: 2.615129218144377

Epoch: 336| Step: 0
Training loss: 2.719609004275967
Validation loss: 2.6187252615121572

Epoch: 5| Step: 1
Training loss: 1.8754505887622503
Validation loss: 2.608811139053455

Epoch: 5| Step: 2
Training loss: 1.915289598384997
Validation loss: 2.558847048139405

Epoch: 5| Step: 3
Training loss: 1.9167559298862304
Validation loss: 2.5990591981302615

Epoch: 5| Step: 4
Training loss: 2.1932515417615583
Validation loss: 2.6138593665551215

Epoch: 5| Step: 5
Training loss: 1.980159456979952
Validation loss: 2.564469983601606

Epoch: 5| Step: 6
Training loss: 1.7131001639001047
Validation loss: 2.54693052049037

Epoch: 5| Step: 7
Training loss: 2.6850763969989657
Validation loss: 2.5812766650619583

Epoch: 5| Step: 8
Training loss: 2.330177989268185
Validation loss: 2.6045544663318356

Epoch: 5| Step: 9
Training loss: 2.078111920996789
Validation loss: 2.59893087479893

Epoch: 5| Step: 10
Training loss: 1.7169899685432781
Validation loss: 2.5607076820159405

Epoch: 337| Step: 0
Training loss: 2.2208269096505866
Validation loss: 2.5781309444076803

Epoch: 5| Step: 1
Training loss: 1.719330290889427
Validation loss: 2.608846181379713

Epoch: 5| Step: 2
Training loss: 2.415578125650633
Validation loss: 2.567084127095006

Epoch: 5| Step: 3
Training loss: 1.94331600581711
Validation loss: 2.646471922374844

Epoch: 5| Step: 4
Training loss: 1.8269517834527762
Validation loss: 2.5691120451154745

Epoch: 5| Step: 5
Training loss: 2.1879492162219196
Validation loss: 2.5552771012952595

Epoch: 5| Step: 6
Training loss: 2.075069504458523
Validation loss: 2.621514382794806

Epoch: 5| Step: 7
Training loss: 2.4145777871499097
Validation loss: 2.568727983025534

Epoch: 5| Step: 8
Training loss: 2.3188864696063365
Validation loss: 2.584034519587813

Epoch: 5| Step: 9
Training loss: 2.032679832169804
Validation loss: 2.5749361793517345

Epoch: 5| Step: 10
Training loss: 2.1804128007534382
Validation loss: 2.5645373349284606

Epoch: 338| Step: 0
Training loss: 1.9385863304288289
Validation loss: 2.6357553998723158

Epoch: 5| Step: 1
Training loss: 2.1018658387174205
Validation loss: 2.571235182680154

Epoch: 5| Step: 2
Training loss: 2.1372888561165477
Validation loss: 2.546794044289561

Epoch: 5| Step: 3
Training loss: 2.3437123613514235
Validation loss: 2.591979281159986

Epoch: 5| Step: 4
Training loss: 1.8873000740122
Validation loss: 2.574199388815166

Epoch: 5| Step: 5
Training loss: 2.015240654784931
Validation loss: 2.6091484358067927

Epoch: 5| Step: 6
Training loss: 2.2836348726665863
Validation loss: 2.5793750306693664

Epoch: 5| Step: 7
Training loss: 2.0810471261154277
Validation loss: 2.612189521048831

Epoch: 5| Step: 8
Training loss: 2.616434290665329
Validation loss: 2.584779275837609

Epoch: 5| Step: 9
Training loss: 1.7515569300567242
Validation loss: 2.6188943683570662

Epoch: 5| Step: 10
Training loss: 2.1124889982941495
Validation loss: 2.5915540988931993

Epoch: 339| Step: 0
Training loss: 2.127328158295897
Validation loss: 2.587821208683024

Epoch: 5| Step: 1
Training loss: 1.939245729603749
Validation loss: 2.5503401273488198

Epoch: 5| Step: 2
Training loss: 1.7770694730634804
Validation loss: 2.5833714178363016

Epoch: 5| Step: 3
Training loss: 2.1607326407705694
Validation loss: 2.574018489494757

Epoch: 5| Step: 4
Training loss: 2.1802244994731685
Validation loss: 2.5916629612652216

Epoch: 5| Step: 5
Training loss: 2.021435546285274
Validation loss: 2.5582537130386727

Epoch: 5| Step: 6
Training loss: 2.2982175886494804
Validation loss: 2.5618590627084994

Epoch: 5| Step: 7
Training loss: 2.756124871629353
Validation loss: 2.5915564809556906

Epoch: 5| Step: 8
Training loss: 2.4845114616487414
Validation loss: 2.6355598822921453

Epoch: 5| Step: 9
Training loss: 1.8168951217539688
Validation loss: 2.6223464304386046

Epoch: 5| Step: 10
Training loss: 1.9817213803377405
Validation loss: 2.611889198803549

Epoch: 340| Step: 0
Training loss: 2.2199611313312633
Validation loss: 2.6050498327860128

Epoch: 5| Step: 1
Training loss: 2.126459518058055
Validation loss: 2.594708205031358

Epoch: 5| Step: 2
Training loss: 1.8184876688637985
Validation loss: 2.6072500565170675

Epoch: 5| Step: 3
Training loss: 1.5918024168327611
Validation loss: 2.587329728275243

Epoch: 5| Step: 4
Training loss: 2.215073131275397
Validation loss: 2.612336386088738

Epoch: 5| Step: 5
Training loss: 1.7536779990067843
Validation loss: 2.592156873887501

Epoch: 5| Step: 6
Training loss: 2.1216591771611157
Validation loss: 2.6181643934611083

Epoch: 5| Step: 7
Training loss: 2.030783966595643
Validation loss: 2.590938811437478

Epoch: 5| Step: 8
Training loss: 2.6537559918171123
Validation loss: 2.6347861154366834

Epoch: 5| Step: 9
Training loss: 2.5146154427447027
Validation loss: 2.6172605305674046

Epoch: 5| Step: 10
Training loss: 2.2061792940475464
Validation loss: 2.5774286666590096

Epoch: 341| Step: 0
Training loss: 2.0230393183644955
Validation loss: 2.5934902021021506

Epoch: 5| Step: 1
Training loss: 2.960132982772193
Validation loss: 2.6088138099910236

Epoch: 5| Step: 2
Training loss: 2.130704515740847
Validation loss: 2.6013713681343495

Epoch: 5| Step: 3
Training loss: 1.651578035886048
Validation loss: 2.631557177624684

Epoch: 5| Step: 4
Training loss: 1.7591679073433573
Validation loss: 2.5098601537833907

Epoch: 5| Step: 5
Training loss: 1.6616756890962938
Validation loss: 2.5874139070467765

Epoch: 5| Step: 6
Training loss: 2.076643681141296
Validation loss: 2.575150073996942

Epoch: 5| Step: 7
Training loss: 2.4701407655767142
Validation loss: 2.584910729558476

Epoch: 5| Step: 8
Training loss: 1.7542789462559412
Validation loss: 2.5574999192882717

Epoch: 5| Step: 9
Training loss: 1.8278762778602677
Validation loss: 2.5579200722559676

Epoch: 5| Step: 10
Training loss: 2.394337682072229
Validation loss: 2.590511426693985

Epoch: 342| Step: 0
Training loss: 2.0869446798175204
Validation loss: 2.557014594846835

Epoch: 5| Step: 1
Training loss: 1.6219067109229086
Validation loss: 2.566010522362071

Epoch: 5| Step: 2
Training loss: 1.8992750416066768
Validation loss: 2.5855844542508946

Epoch: 5| Step: 3
Training loss: 2.035731726645806
Validation loss: 2.587749809138029

Epoch: 5| Step: 4
Training loss: 2.596296783598784
Validation loss: 2.5802006753057407

Epoch: 5| Step: 5
Training loss: 2.0431087876239986
Validation loss: 2.599167175076189

Epoch: 5| Step: 6
Training loss: 2.1910795080400387
Validation loss: 2.568945988141875

Epoch: 5| Step: 7
Training loss: 2.3623143764011725
Validation loss: 2.639231504000837

Epoch: 5| Step: 8
Training loss: 2.282326117887699
Validation loss: 2.6135575411946124

Epoch: 5| Step: 9
Training loss: 1.9998346498802275
Validation loss: 2.591689509932864

Epoch: 5| Step: 10
Training loss: 2.0807454502835596
Validation loss: 2.5703245815294

Epoch: 343| Step: 0
Training loss: 1.6629389161976205
Validation loss: 2.579131758216395

Epoch: 5| Step: 1
Training loss: 2.0689206609028874
Validation loss: 2.608503746775271

Epoch: 5| Step: 2
Training loss: 2.5532003851492098
Validation loss: 2.6021499490351645

Epoch: 5| Step: 3
Training loss: 2.4482714023984853
Validation loss: 2.655273878729011

Epoch: 5| Step: 4
Training loss: 1.8831755102190604
Validation loss: 2.631267224724749

Epoch: 5| Step: 5
Training loss: 1.5930575942351912
Validation loss: 2.5728007348552286

Epoch: 5| Step: 6
Training loss: 2.0467969573773077
Validation loss: 2.6108419151132773

Epoch: 5| Step: 7
Training loss: 2.4049285629036214
Validation loss: 2.616727377309587

Epoch: 5| Step: 8
Training loss: 2.6549198185941627
Validation loss: 2.5792019530939703

Epoch: 5| Step: 9
Training loss: 2.0725622081738555
Validation loss: 2.579245413918056

Epoch: 5| Step: 10
Training loss: 1.6338697597094805
Validation loss: 2.6417138784836367

Epoch: 344| Step: 0
Training loss: 1.9844216168552444
Validation loss: 2.63816724263898

Epoch: 5| Step: 1
Training loss: 1.6763747793659283
Validation loss: 2.6128191265957317

Epoch: 5| Step: 2
Training loss: 2.546447062668858
Validation loss: 2.5705126552831516

Epoch: 5| Step: 3
Training loss: 2.2908043597310943
Validation loss: 2.5895129606751612

Epoch: 5| Step: 4
Training loss: 2.6943339022566164
Validation loss: 2.6047454650174315

Epoch: 5| Step: 5
Training loss: 1.9982891513860042
Validation loss: 2.5920098846840314

Epoch: 5| Step: 6
Training loss: 2.3969191923879385
Validation loss: 2.6064846759528377

Epoch: 5| Step: 7
Training loss: 1.5586431586290566
Validation loss: 2.559674521836413

Epoch: 5| Step: 8
Training loss: 1.8074038980982075
Validation loss: 2.6039256604971124

Epoch: 5| Step: 9
Training loss: 2.1671709671985075
Validation loss: 2.5819916477858302

Epoch: 5| Step: 10
Training loss: 2.256274270220377
Validation loss: 2.5781850052727595

Epoch: 345| Step: 0
Training loss: 2.467528705062788
Validation loss: 2.582764336293796

Epoch: 5| Step: 1
Training loss: 2.3008741997950413
Validation loss: 2.556469382202999

Epoch: 5| Step: 2
Training loss: 1.7601051807402524
Validation loss: 2.5822037651353718

Epoch: 5| Step: 3
Training loss: 2.208466243942788
Validation loss: 2.6249803463248447

Epoch: 5| Step: 4
Training loss: 2.4021825720829675
Validation loss: 2.6200557785919485

Epoch: 5| Step: 5
Training loss: 2.320843465658519
Validation loss: 2.57778140824102

Epoch: 5| Step: 6
Training loss: 1.9629135813722902
Validation loss: 2.635887510227079

Epoch: 5| Step: 7
Training loss: 2.0552430072791212
Validation loss: 2.6482988304845767

Epoch: 5| Step: 8
Training loss: 2.1138193288089195
Validation loss: 2.6175739412600123

Epoch: 5| Step: 9
Training loss: 1.798078714304714
Validation loss: 2.609768179183884

Epoch: 5| Step: 10
Training loss: 2.162301569307491
Validation loss: 2.6018785258069763

Epoch: 346| Step: 0
Training loss: 1.6073612836725257
Validation loss: 2.537013157433415

Epoch: 5| Step: 1
Training loss: 2.5515675756680802
Validation loss: 2.6763243660942546

Epoch: 5| Step: 2
Training loss: 2.6331607576953404
Validation loss: 2.5707497009064704

Epoch: 5| Step: 3
Training loss: 2.0623257881340153
Validation loss: 2.574236526588466

Epoch: 5| Step: 4
Training loss: 2.2555809740952957
Validation loss: 2.6218633286538306

Epoch: 5| Step: 5
Training loss: 2.118446792017187
Validation loss: 2.5922614846325946

Epoch: 5| Step: 6
Training loss: 2.0722277725027216
Validation loss: 2.5712459587344463

Epoch: 5| Step: 7
Training loss: 1.962132367244872
Validation loss: 2.567334528026722

Epoch: 5| Step: 8
Training loss: 1.5142584076576042
Validation loss: 2.6322571950346436

Epoch: 5| Step: 9
Training loss: 1.8926004225418311
Validation loss: 2.5613367214999876

Epoch: 5| Step: 10
Training loss: 2.0198773616916483
Validation loss: 2.56011785436685

Epoch: 347| Step: 0
Training loss: 2.131668063241095
Validation loss: 2.602050502920106

Epoch: 5| Step: 1
Training loss: 1.6324566174945383
Validation loss: 2.5775112292828877

Epoch: 5| Step: 2
Training loss: 1.9496778050808492
Validation loss: 2.5743075978556713

Epoch: 5| Step: 3
Training loss: 2.134327668186009
Validation loss: 2.5894100907768345

Epoch: 5| Step: 4
Training loss: 2.531610722211438
Validation loss: 2.5799099080505017

Epoch: 5| Step: 5
Training loss: 2.2316836707692635
Validation loss: 2.558940523218329

Epoch: 5| Step: 6
Training loss: 1.5111361226103157
Validation loss: 2.6241338407361443

Epoch: 5| Step: 7
Training loss: 2.2307102052635486
Validation loss: 2.5714895550059707

Epoch: 5| Step: 8
Training loss: 2.090868205021312
Validation loss: 2.5630144692801533

Epoch: 5| Step: 9
Training loss: 2.5533268189243383
Validation loss: 2.5958276031762204

Epoch: 5| Step: 10
Training loss: 2.1943594061662224
Validation loss: 2.567333110568714

Epoch: 348| Step: 0
Training loss: 2.2583161422619464
Validation loss: 2.646104614778445

Epoch: 5| Step: 1
Training loss: 1.6433240215251768
Validation loss: 2.496243858673481

Epoch: 5| Step: 2
Training loss: 2.1765642657687
Validation loss: 2.594760237940667

Epoch: 5| Step: 3
Training loss: 1.8800115367860077
Validation loss: 2.6121485604127104

Epoch: 5| Step: 4
Training loss: 2.02935926031242
Validation loss: 2.6404167938332073

Epoch: 5| Step: 5
Training loss: 2.6660186655774787
Validation loss: 2.624976243977595

Epoch: 5| Step: 6
Training loss: 1.7702746987410416
Validation loss: 2.5932904471523393

Epoch: 5| Step: 7
Training loss: 1.7609494172499434
Validation loss: 2.5707479088752097

Epoch: 5| Step: 8
Training loss: 2.4325932731662743
Validation loss: 2.5892561960914513

Epoch: 5| Step: 9
Training loss: 2.163721711906577
Validation loss: 2.58866958036367

Epoch: 5| Step: 10
Training loss: 2.5619610475531607
Validation loss: 2.581443586824366

Epoch: 349| Step: 0
Training loss: 1.964513064516996
Validation loss: 2.616281037071934

Epoch: 5| Step: 1
Training loss: 1.7632336922360232
Validation loss: 2.602823521586493

Epoch: 5| Step: 2
Training loss: 1.7667561511403216
Validation loss: 2.581736347559873

Epoch: 5| Step: 3
Training loss: 2.6072306702190184
Validation loss: 2.5930512079132573

Epoch: 5| Step: 4
Training loss: 2.5634828868969604
Validation loss: 2.627679460297745

Epoch: 5| Step: 5
Training loss: 1.6539085680080887
Validation loss: 2.6093725222017716

Epoch: 5| Step: 6
Training loss: 1.6720325716578652
Validation loss: 2.5841036913896236

Epoch: 5| Step: 7
Training loss: 1.7689101453336753
Validation loss: 2.6020354878402805

Epoch: 5| Step: 8
Training loss: 2.5142495322255964
Validation loss: 2.643699653507021

Epoch: 5| Step: 9
Training loss: 2.364239660710988
Validation loss: 2.601961275718121

Epoch: 5| Step: 10
Training loss: 2.442361629475062
Validation loss: 2.5755776313292067

Epoch: 350| Step: 0
Training loss: 2.6565501324004845
Validation loss: 2.585095478074252

Epoch: 5| Step: 1
Training loss: 1.9597911751693358
Validation loss: 2.5737302291928246

Epoch: 5| Step: 2
Training loss: 2.3630050119418713
Validation loss: 2.591603604388864

Epoch: 5| Step: 3
Training loss: 1.9147710617506852
Validation loss: 2.551519709804518

Epoch: 5| Step: 4
Training loss: 1.9512162303751583
Validation loss: 2.541104782293446

Epoch: 5| Step: 5
Training loss: 1.9091986067436948
Validation loss: 2.5742863521680723

Epoch: 5| Step: 6
Training loss: 2.031014061943445
Validation loss: 2.618995894177129

Epoch: 5| Step: 7
Training loss: 2.431478839685708
Validation loss: 2.6239041620831336

Epoch: 5| Step: 8
Training loss: 1.885318971354391
Validation loss: 2.585120875400858

Epoch: 5| Step: 9
Training loss: 1.9120730902216718
Validation loss: 2.5829435015344027

Epoch: 5| Step: 10
Training loss: 2.02791497740379
Validation loss: 2.5461937573112454

Epoch: 351| Step: 0
Training loss: 1.5008599677185728
Validation loss: 2.6143567913259993

Epoch: 5| Step: 1
Training loss: 2.1494091819004106
Validation loss: 2.5930568215068988

Epoch: 5| Step: 2
Training loss: 2.792905238569841
Validation loss: 2.590079258041681

Epoch: 5| Step: 3
Training loss: 2.568470581896144
Validation loss: 2.6510142950228497

Epoch: 5| Step: 4
Training loss: 2.0986382656106444
Validation loss: 2.618779312064896

Epoch: 5| Step: 5
Training loss: 1.8635465485061264
Validation loss: 2.5941849062375226

Epoch: 5| Step: 6
Training loss: 2.067281094347567
Validation loss: 2.6332140626321228

Epoch: 5| Step: 7
Training loss: 2.4527209489785724
Validation loss: 2.5844718498030224

Epoch: 5| Step: 8
Training loss: 1.8594791158809665
Validation loss: 2.5902092927066436

Epoch: 5| Step: 9
Training loss: 2.026989032973519
Validation loss: 2.664938767458938

Epoch: 5| Step: 10
Training loss: 1.7566616105447834
Validation loss: 2.658922177189246

Epoch: 352| Step: 0
Training loss: 1.7236808100169116
Validation loss: 2.647135152600319

Epoch: 5| Step: 1
Training loss: 1.8259481527607608
Validation loss: 2.6135789708461377

Epoch: 5| Step: 2
Training loss: 2.4471636215835675
Validation loss: 2.6096064525276983

Epoch: 5| Step: 3
Training loss: 1.8505163013572037
Validation loss: 2.61827831209743

Epoch: 5| Step: 4
Training loss: 2.4126448434624677
Validation loss: 2.6023213368321487

Epoch: 5| Step: 5
Training loss: 2.1606894967955252
Validation loss: 2.611188225519076

Epoch: 5| Step: 6
Training loss: 2.2943814814223247
Validation loss: 2.646636765974639

Epoch: 5| Step: 7
Training loss: 2.0602138449032315
Validation loss: 2.633983372273615

Epoch: 5| Step: 8
Training loss: 1.9736911589516917
Validation loss: 2.5852950828321353

Epoch: 5| Step: 9
Training loss: 2.2659630884933466
Validation loss: 2.584011979793868

Epoch: 5| Step: 10
Training loss: 1.9496642312717125
Validation loss: 2.6397745794904677

Epoch: 353| Step: 0
Training loss: 2.0403834481859295
Validation loss: 2.5700548106843426

Epoch: 5| Step: 1
Training loss: 1.8705852032477037
Validation loss: 2.588065975329276

Epoch: 5| Step: 2
Training loss: 2.5754790628952637
Validation loss: 2.5354771534454152

Epoch: 5| Step: 3
Training loss: 1.8607960888281119
Validation loss: 2.6282126207011514

Epoch: 5| Step: 4
Training loss: 2.0843904737730314
Validation loss: 2.538925527154775

Epoch: 5| Step: 5
Training loss: 2.2438208183652275
Validation loss: 2.548534651536076

Epoch: 5| Step: 6
Training loss: 2.014937409216853
Validation loss: 2.565527005738737

Epoch: 5| Step: 7
Training loss: 2.4242898038728002
Validation loss: 2.5417461782922803

Epoch: 5| Step: 8
Training loss: 2.1643050846238414
Validation loss: 2.580640483603289

Epoch: 5| Step: 9
Training loss: 2.31222264456614
Validation loss: 2.6311047144522637

Epoch: 5| Step: 10
Training loss: 1.5425578282427213
Validation loss: 2.586314858212959

Epoch: 354| Step: 0
Training loss: 1.9157775046549428
Validation loss: 2.59727596953903

Epoch: 5| Step: 1
Training loss: 2.17413629505042
Validation loss: 2.5589674424299824

Epoch: 5| Step: 2
Training loss: 1.8734393936669433
Validation loss: 2.5879517589924212

Epoch: 5| Step: 3
Training loss: 2.878055607293632
Validation loss: 2.612637441436377

Epoch: 5| Step: 4
Training loss: 2.154832678226963
Validation loss: 2.565515717020313

Epoch: 5| Step: 5
Training loss: 1.7609519220013765
Validation loss: 2.6031283789955753

Epoch: 5| Step: 6
Training loss: 2.3110039485433824
Validation loss: 2.5503528151433867

Epoch: 5| Step: 7
Training loss: 1.6042858508864217
Validation loss: 2.5786703408649427

Epoch: 5| Step: 8
Training loss: 1.9202801049078573
Validation loss: 2.590428265004136

Epoch: 5| Step: 9
Training loss: 2.394269172801206
Validation loss: 2.5955861730069576

Epoch: 5| Step: 10
Training loss: 2.100034477314171
Validation loss: 2.595372498698811

Epoch: 355| Step: 0
Training loss: 2.3667714977776946
Validation loss: 2.6153449287026493

Epoch: 5| Step: 1
Training loss: 1.6583161332406176
Validation loss: 2.6007278878855775

Epoch: 5| Step: 2
Training loss: 1.9748432386934742
Validation loss: 2.6388779640151516

Epoch: 5| Step: 3
Training loss: 2.08536924701426
Validation loss: 2.6185173337968592

Epoch: 5| Step: 4
Training loss: 1.9439138263707754
Validation loss: 2.6228450244570642

Epoch: 5| Step: 5
Training loss: 1.423809370589791
Validation loss: 2.607565483958362

Epoch: 5| Step: 6
Training loss: 2.198819979735424
Validation loss: 2.639691961708099

Epoch: 5| Step: 7
Training loss: 2.2816298704150215
Validation loss: 2.529728171576157

Epoch: 5| Step: 8
Training loss: 2.572768501823872
Validation loss: 2.6147843424868116

Epoch: 5| Step: 9
Training loss: 2.1799708903407757
Validation loss: 2.6392935216147957

Epoch: 5| Step: 10
Training loss: 2.012589053440509
Validation loss: 2.5896637247274787

Epoch: 356| Step: 0
Training loss: 2.0704913367997797
Validation loss: 2.5929114069249266

Epoch: 5| Step: 1
Training loss: 1.878340415850975
Validation loss: 2.5992735517179524

Epoch: 5| Step: 2
Training loss: 2.225213214216643
Validation loss: 2.6167495931769267

Epoch: 5| Step: 3
Training loss: 1.7051627191661882
Validation loss: 2.58640755368827

Epoch: 5| Step: 4
Training loss: 2.429149212346476
Validation loss: 2.5969251582311736

Epoch: 5| Step: 5
Training loss: 1.8185756403138271
Validation loss: 2.583325302344418

Epoch: 5| Step: 6
Training loss: 2.1250980578966865
Validation loss: 2.606523910950013

Epoch: 5| Step: 7
Training loss: 2.111139986052666
Validation loss: 2.5807135818368647

Epoch: 5| Step: 8
Training loss: 2.666265298519606
Validation loss: 2.5729562823523175

Epoch: 5| Step: 9
Training loss: 1.7023429124820464
Validation loss: 2.5835332392878105

Epoch: 5| Step: 10
Training loss: 1.893792077028261
Validation loss: 2.5669831047980973

Epoch: 357| Step: 0
Training loss: 1.7795487025714156
Validation loss: 2.586322640371533

Epoch: 5| Step: 1
Training loss: 2.2133821916166605
Validation loss: 2.608330800461708

Epoch: 5| Step: 2
Training loss: 1.7654237885729527
Validation loss: 2.574449734504018

Epoch: 5| Step: 3
Training loss: 2.175536547722721
Validation loss: 2.577769279115312

Epoch: 5| Step: 4
Training loss: 1.9577719986388034
Validation loss: 2.556285103598679

Epoch: 5| Step: 5
Training loss: 2.918868859299034
Validation loss: 2.5818763197312298

Epoch: 5| Step: 6
Training loss: 2.0454785191450764
Validation loss: 2.5259019318067857

Epoch: 5| Step: 7
Training loss: 2.1906604279661277
Validation loss: 2.5841869375645974

Epoch: 5| Step: 8
Training loss: 1.5661538698450934
Validation loss: 2.602706408871502

Epoch: 5| Step: 9
Training loss: 1.682881144732492
Validation loss: 2.591318359831472

Epoch: 5| Step: 10
Training loss: 2.3117913887392234
Validation loss: 2.6344550983648585

Epoch: 358| Step: 0
Training loss: 2.256743815055123
Validation loss: 2.636608679269261

Epoch: 5| Step: 1
Training loss: 1.5887290552230844
Validation loss: 2.549062156533254

Epoch: 5| Step: 2
Training loss: 1.476541508924041
Validation loss: 2.6159923074301927

Epoch: 5| Step: 3
Training loss: 1.7417699202209722
Validation loss: 2.6489061623410968

Epoch: 5| Step: 4
Training loss: 2.621884813619987
Validation loss: 2.5912886612925226

Epoch: 5| Step: 5
Training loss: 1.9758350707386647
Validation loss: 2.646953930372693

Epoch: 5| Step: 6
Training loss: 2.4648540031111037
Validation loss: 2.599789114888089

Epoch: 5| Step: 7
Training loss: 1.818690416336671
Validation loss: 2.57173837463742

Epoch: 5| Step: 8
Training loss: 1.7126193206873361
Validation loss: 2.622859487410667

Epoch: 5| Step: 9
Training loss: 2.5934021498204554
Validation loss: 2.6440498300527975

Epoch: 5| Step: 10
Training loss: 2.1193037541619146
Validation loss: 2.6599189701023938

Epoch: 359| Step: 0
Training loss: 1.8985029295646805
Validation loss: 2.625209663249027

Epoch: 5| Step: 1
Training loss: 1.8500622171816918
Validation loss: 2.554656891923102

Epoch: 5| Step: 2
Training loss: 2.611727447906078
Validation loss: 2.6100897524528968

Epoch: 5| Step: 3
Training loss: 1.4903800363209998
Validation loss: 2.6064766943307696

Epoch: 5| Step: 4
Training loss: 2.2534424620317024
Validation loss: 2.6341476183286723

Epoch: 5| Step: 5
Training loss: 1.7370503728894342
Validation loss: 2.5811261957682015

Epoch: 5| Step: 6
Training loss: 1.5749213305005507
Validation loss: 2.638284551708355

Epoch: 5| Step: 7
Training loss: 2.1348149886361503
Validation loss: 2.6135768354417723

Epoch: 5| Step: 8
Training loss: 2.1225205710484705
Validation loss: 2.6343618144144965

Epoch: 5| Step: 9
Training loss: 2.5317632837633552
Validation loss: 2.603010656570573

Epoch: 5| Step: 10
Training loss: 2.225341462068852
Validation loss: 2.579863195072925

Epoch: 360| Step: 0
Training loss: 2.36832735422853
Validation loss: 2.576382244071208

Epoch: 5| Step: 1
Training loss: 2.0084399716041688
Validation loss: 2.5923391479123095

Epoch: 5| Step: 2
Training loss: 2.6207296968558076
Validation loss: 2.6305095749051604

Epoch: 5| Step: 3
Training loss: 2.2095857943236346
Validation loss: 2.586878221622697

Epoch: 5| Step: 4
Training loss: 1.9785820214596388
Validation loss: 2.6337103549519365

Epoch: 5| Step: 5
Training loss: 1.8899195592403317
Validation loss: 2.6535504370964254

Epoch: 5| Step: 6
Training loss: 1.754181702187707
Validation loss: 2.641716857751141

Epoch: 5| Step: 7
Training loss: 1.9227227302971477
Validation loss: 2.61356427212711

Epoch: 5| Step: 8
Training loss: 2.1548402019828625
Validation loss: 2.606062619693858

Epoch: 5| Step: 9
Training loss: 2.0667045969199798
Validation loss: 2.5721597011767603

Epoch: 5| Step: 10
Training loss: 1.972427505978905
Validation loss: 2.6595472829852334

Epoch: 361| Step: 0
Training loss: 2.497217728220972
Validation loss: 2.5586819040279014

Epoch: 5| Step: 1
Training loss: 1.7201366726224432
Validation loss: 2.6061220456508165

Epoch: 5| Step: 2
Training loss: 1.6111188902977696
Validation loss: 2.60531582750775

Epoch: 5| Step: 3
Training loss: 2.1157894234034234
Validation loss: 2.6288640324345947

Epoch: 5| Step: 4
Training loss: 1.849757542058214
Validation loss: 2.5850094039744986

Epoch: 5| Step: 5
Training loss: 1.9518554223331097
Validation loss: 2.601704058136612

Epoch: 5| Step: 6
Training loss: 2.14679191684015
Validation loss: 2.608297395568354

Epoch: 5| Step: 7
Training loss: 2.069501840476789
Validation loss: 2.5963918844222507

Epoch: 5| Step: 8
Training loss: 2.2420522403126597
Validation loss: 2.562402170606362

Epoch: 5| Step: 9
Training loss: 2.128565993809551
Validation loss: 2.545739065580341

Epoch: 5| Step: 10
Training loss: 2.2682143574759333
Validation loss: 2.5835513596188204

Epoch: 362| Step: 0
Training loss: 1.8426305314181493
Validation loss: 2.530733344186703

Epoch: 5| Step: 1
Training loss: 2.1823565367993694
Validation loss: 2.6237985759237232

Epoch: 5| Step: 2
Training loss: 1.8276935296448538
Validation loss: 2.5861932360203816

Epoch: 5| Step: 3
Training loss: 2.372556835173124
Validation loss: 2.5854198023232433

Epoch: 5| Step: 4
Training loss: 2.365703457497562
Validation loss: 2.604821422015

Epoch: 5| Step: 5
Training loss: 1.7575706485098042
Validation loss: 2.5916474141584693

Epoch: 5| Step: 6
Training loss: 1.1551024954595088
Validation loss: 2.592995771293308

Epoch: 5| Step: 7
Training loss: 1.8010004865867046
Validation loss: 2.5642485476736954

Epoch: 5| Step: 8
Training loss: 2.802649562496159
Validation loss: 2.5662478310051626

Epoch: 5| Step: 9
Training loss: 2.0858243418657354
Validation loss: 2.5763452427055133

Epoch: 5| Step: 10
Training loss: 2.374902823618444
Validation loss: 2.562830029596272

Epoch: 363| Step: 0
Training loss: 2.252413832427284
Validation loss: 2.5859283832750823

Epoch: 5| Step: 1
Training loss: 2.02534094871879
Validation loss: 2.6288476140926846

Epoch: 5| Step: 2
Training loss: 1.8189979358009174
Validation loss: 2.6246283776468617

Epoch: 5| Step: 3
Training loss: 2.1145229111731614
Validation loss: 2.6117655931234465

Epoch: 5| Step: 4
Training loss: 2.5678375294173366
Validation loss: 2.54133939291857

Epoch: 5| Step: 5
Training loss: 1.8667377903989724
Validation loss: 2.5770869029863603

Epoch: 5| Step: 6
Training loss: 1.4466195459792897
Validation loss: 2.616272815378528

Epoch: 5| Step: 7
Training loss: 1.8350904093202134
Validation loss: 2.614268866228524

Epoch: 5| Step: 8
Training loss: 1.553207229494476
Validation loss: 2.5859685666147296

Epoch: 5| Step: 9
Training loss: 2.665414774611136
Validation loss: 2.5995743758114678

Epoch: 5| Step: 10
Training loss: 2.032884145847828
Validation loss: 2.538283786045158

Epoch: 364| Step: 0
Training loss: 1.843151577317773
Validation loss: 2.626048379241848

Epoch: 5| Step: 1
Training loss: 2.1205071468866965
Validation loss: 2.61389555736392

Epoch: 5| Step: 2
Training loss: 2.474259229063313
Validation loss: 2.6213952396620366

Epoch: 5| Step: 3
Training loss: 2.3838290688214014
Validation loss: 2.5704708639670946

Epoch: 5| Step: 4
Training loss: 2.1162660289682367
Validation loss: 2.5945836163364526

Epoch: 5| Step: 5
Training loss: 2.033797324766541
Validation loss: 2.583440721511323

Epoch: 5| Step: 6
Training loss: 1.6837610573182524
Validation loss: 2.564531883829328

Epoch: 5| Step: 7
Training loss: 2.2843386499771747
Validation loss: 2.571711492409031

Epoch: 5| Step: 8
Training loss: 1.4006030827330518
Validation loss: 2.6245653610070367

Epoch: 5| Step: 9
Training loss: 2.133374597726535
Validation loss: 2.6228507424012166

Epoch: 5| Step: 10
Training loss: 2.1434839467256586
Validation loss: 2.666728577709103

Epoch: 365| Step: 0
Training loss: 1.9118887254784076
Validation loss: 2.626063501080205

Epoch: 5| Step: 1
Training loss: 1.8960799032427935
Validation loss: 2.5847163856308804

Epoch: 5| Step: 2
Training loss: 2.4111921412050683
Validation loss: 2.6051130715422297

Epoch: 5| Step: 3
Training loss: 1.8291859604752814
Validation loss: 2.582101195284093

Epoch: 5| Step: 4
Training loss: 2.1939362797346993
Validation loss: 2.6371299903626424

Epoch: 5| Step: 5
Training loss: 2.275861149546558
Validation loss: 2.6128969956458814

Epoch: 5| Step: 6
Training loss: 1.976346332052849
Validation loss: 2.5334857438903913

Epoch: 5| Step: 7
Training loss: 1.7788048408294888
Validation loss: 2.6007646478293527

Epoch: 5| Step: 8
Training loss: 2.1461762336402583
Validation loss: 2.614695904762139

Epoch: 5| Step: 9
Training loss: 2.294485289256557
Validation loss: 2.550448498301172

Epoch: 5| Step: 10
Training loss: 1.7145724766303723
Validation loss: 2.5701314408120868

Epoch: 366| Step: 0
Training loss: 2.07704088428501
Validation loss: 2.620543898616738

Epoch: 5| Step: 1
Training loss: 1.5948994549238922
Validation loss: 2.5822563195540855

Epoch: 5| Step: 2
Training loss: 1.91409837338832
Validation loss: 2.5560543772218516

Epoch: 5| Step: 3
Training loss: 2.1896726445483132
Validation loss: 2.5598502857290244

Epoch: 5| Step: 4
Training loss: 2.138506209693796
Validation loss: 2.577377668435558

Epoch: 5| Step: 5
Training loss: 1.8548438375089153
Validation loss: 2.5975914174101375

Epoch: 5| Step: 6
Training loss: 1.6464542553591444
Validation loss: 2.6302949013724395

Epoch: 5| Step: 7
Training loss: 2.300920725093871
Validation loss: 2.6222432452396673

Epoch: 5| Step: 8
Training loss: 2.1111323065558185
Validation loss: 2.599662765359365

Epoch: 5| Step: 9
Training loss: 2.4384836999607695
Validation loss: 2.6479034916364803

Epoch: 5| Step: 10
Training loss: 2.0935951289504002
Validation loss: 2.5958778290888804

Epoch: 367| Step: 0
Training loss: 1.964772581476232
Validation loss: 2.6190954554724764

Epoch: 5| Step: 1
Training loss: 2.5676814471856106
Validation loss: 2.588486622065638

Epoch: 5| Step: 2
Training loss: 2.0886178958011072
Validation loss: 2.5819040751511757

Epoch: 5| Step: 3
Training loss: 1.9404729983253088
Validation loss: 2.6571189014166863

Epoch: 5| Step: 4
Training loss: 2.0254451262480893
Validation loss: 2.5727649624234967

Epoch: 5| Step: 5
Training loss: 1.718923455935817
Validation loss: 2.6036890073397294

Epoch: 5| Step: 6
Training loss: 2.1746881502580555
Validation loss: 2.5613551549996876

Epoch: 5| Step: 7
Training loss: 2.0218419445230658
Validation loss: 2.57235505755747

Epoch: 5| Step: 8
Training loss: 1.7527687785217687
Validation loss: 2.643904140500342

Epoch: 5| Step: 9
Training loss: 2.4773928817549447
Validation loss: 2.632399654119193

Epoch: 5| Step: 10
Training loss: 1.9503660323099363
Validation loss: 2.639080920641724

Epoch: 368| Step: 0
Training loss: 2.101026842565885
Validation loss: 2.579057777188645

Epoch: 5| Step: 1
Training loss: 1.5841710819033692
Validation loss: 2.588798128122949

Epoch: 5| Step: 2
Training loss: 1.8405021250825742
Validation loss: 2.546120071784813

Epoch: 5| Step: 3
Training loss: 2.336197344256481
Validation loss: 2.521852738875509

Epoch: 5| Step: 4
Training loss: 2.8155871084968136
Validation loss: 2.5769496203565394

Epoch: 5| Step: 5
Training loss: 2.047868094607208
Validation loss: 2.6230672585782955

Epoch: 5| Step: 6
Training loss: 1.999001372885984
Validation loss: 2.545304829590769

Epoch: 5| Step: 7
Training loss: 2.2612526632433507
Validation loss: 2.58497503026001

Epoch: 5| Step: 8
Training loss: 2.202704639778683
Validation loss: 2.6047153615134078

Epoch: 5| Step: 9
Training loss: 1.8045111896213413
Validation loss: 2.604840534433325

Epoch: 5| Step: 10
Training loss: 1.9666641326931076
Validation loss: 2.6129967804935506

Epoch: 369| Step: 0
Training loss: 2.4614205991285214
Validation loss: 2.5661603584715067

Epoch: 5| Step: 1
Training loss: 1.8631015906899562
Validation loss: 2.586084122580082

Epoch: 5| Step: 2
Training loss: 1.7868240545588345
Validation loss: 2.6416983881793565

Epoch: 5| Step: 3
Training loss: 2.018083832132755
Validation loss: 2.610659870423096

Epoch: 5| Step: 4
Training loss: 2.2263685710844787
Validation loss: 2.6100564530688475

Epoch: 5| Step: 5
Training loss: 1.9792394791979129
Validation loss: 2.621555012269435

Epoch: 5| Step: 6
Training loss: 2.119180002154315
Validation loss: 2.634346333429752

Epoch: 5| Step: 7
Training loss: 2.401453364913627
Validation loss: 2.6676285845650565

Epoch: 5| Step: 8
Training loss: 2.6138449204958776
Validation loss: 2.63918171556672

Epoch: 5| Step: 9
Training loss: 2.0509609761275676
Validation loss: 2.653847316023938

Epoch: 5| Step: 10
Training loss: 1.6816492733971138
Validation loss: 2.6377196532642784

Epoch: 370| Step: 0
Training loss: 1.8969282265348777
Validation loss: 2.612187670100455

Epoch: 5| Step: 1
Training loss: 1.9194547719473658
Validation loss: 2.58792317885984

Epoch: 5| Step: 2
Training loss: 2.1916477661864997
Validation loss: 2.639053190506779

Epoch: 5| Step: 3
Training loss: 2.1019125721295984
Validation loss: 2.60709156959773

Epoch: 5| Step: 4
Training loss: 1.9391036626364444
Validation loss: 2.60413824020786

Epoch: 5| Step: 5
Training loss: 2.388981172962501
Validation loss: 2.631325791125539

Epoch: 5| Step: 6
Training loss: 1.8834411711187868
Validation loss: 2.5692843146638884

Epoch: 5| Step: 7
Training loss: 2.1641880921644963
Validation loss: 2.5621513531698428

Epoch: 5| Step: 8
Training loss: 1.984826404562109
Validation loss: 2.6259816058636747

Epoch: 5| Step: 9
Training loss: 1.8505483819779307
Validation loss: 2.574671488430308

Epoch: 5| Step: 10
Training loss: 2.4639170214874597
Validation loss: 2.616494064041293

Epoch: 371| Step: 0
Training loss: 2.11288634610285
Validation loss: 2.586498782886086

Epoch: 5| Step: 1
Training loss: 2.233349544788944
Validation loss: 2.6034946408033215

Epoch: 5| Step: 2
Training loss: 1.386458423518009
Validation loss: 2.5876077035986262

Epoch: 5| Step: 3
Training loss: 1.687683519344935
Validation loss: 2.581008609082945

Epoch: 5| Step: 4
Training loss: 2.4330612261273306
Validation loss: 2.553712811758844

Epoch: 5| Step: 5
Training loss: 1.3375569839460053
Validation loss: 2.581597232741137

Epoch: 5| Step: 6
Training loss: 1.984518211183152
Validation loss: 2.5663619214376956

Epoch: 5| Step: 7
Training loss: 2.005965158557394
Validation loss: 2.6706390794245563

Epoch: 5| Step: 8
Training loss: 2.5763005129819225
Validation loss: 2.631761971986645

Epoch: 5| Step: 9
Training loss: 2.3498249922173082
Validation loss: 2.579943154845454

Epoch: 5| Step: 10
Training loss: 2.674879916338955
Validation loss: 2.6379772634124965

Epoch: 372| Step: 0
Training loss: 1.9325383552406712
Validation loss: 2.5996951974457203

Epoch: 5| Step: 1
Training loss: 2.1572979578073506
Validation loss: 2.6141800840128027

Epoch: 5| Step: 2
Training loss: 1.9614396991003284
Validation loss: 2.6043222872268705

Epoch: 5| Step: 3
Training loss: 1.8402891490592954
Validation loss: 2.5675821168258564

Epoch: 5| Step: 4
Training loss: 1.7945000917738123
Validation loss: 2.5955068561477

Epoch: 5| Step: 5
Training loss: 1.993109396260076
Validation loss: 2.5466595590116747

Epoch: 5| Step: 6
Training loss: 1.842495572357862
Validation loss: 2.5805656487510777

Epoch: 5| Step: 7
Training loss: 2.6879624257243093
Validation loss: 2.5939048368018276

Epoch: 5| Step: 8
Training loss: 2.3784321530223984
Validation loss: 2.631417358920333

Epoch: 5| Step: 9
Training loss: 1.8086999322358575
Validation loss: 2.6473952948975303

Epoch: 5| Step: 10
Training loss: 1.5741033393449781
Validation loss: 2.5490776274640514

Epoch: 373| Step: 0
Training loss: 1.775476031877228
Validation loss: 2.5974285358078997

Epoch: 5| Step: 1
Training loss: 2.0730055082315153
Validation loss: 2.6105013833056074

Epoch: 5| Step: 2
Training loss: 1.586779140899006
Validation loss: 2.604742160007084

Epoch: 5| Step: 3
Training loss: 2.080256924533677
Validation loss: 2.5807287597126125

Epoch: 5| Step: 4
Training loss: 2.371865864812777
Validation loss: 2.608930684907594

Epoch: 5| Step: 5
Training loss: 2.2019487852954174
Validation loss: 2.5723090923918908

Epoch: 5| Step: 6
Training loss: 1.4470228642817045
Validation loss: 2.6448160111106582

Epoch: 5| Step: 7
Training loss: 2.124177436945975
Validation loss: 2.5918922081913878

Epoch: 5| Step: 8
Training loss: 2.5789468091232726
Validation loss: 2.6124279899582015

Epoch: 5| Step: 9
Training loss: 1.857244537263324
Validation loss: 2.5924780432941676

Epoch: 5| Step: 10
Training loss: 1.7502807664437887
Validation loss: 2.6199721485790857

Epoch: 374| Step: 0
Training loss: 2.190503592398736
Validation loss: 2.5655086841545995

Epoch: 5| Step: 1
Training loss: 2.316002127018876
Validation loss: 2.633681982280049

Epoch: 5| Step: 2
Training loss: 1.982522114441571
Validation loss: 2.6256366383528844

Epoch: 5| Step: 3
Training loss: 1.7810464039946778
Validation loss: 2.6647079182019433

Epoch: 5| Step: 4
Training loss: 2.0479630934250865
Validation loss: 2.5677060452960467

Epoch: 5| Step: 5
Training loss: 2.375470365827227
Validation loss: 2.613155980572439

Epoch: 5| Step: 6
Training loss: 2.015604063413248
Validation loss: 2.571437962942655

Epoch: 5| Step: 7
Training loss: 1.80618065829641
Validation loss: 2.5610160302405096

Epoch: 5| Step: 8
Training loss: 2.1207593229179516
Validation loss: 2.6156278118215903

Epoch: 5| Step: 9
Training loss: 2.1359213504027252
Validation loss: 2.6498116319281206

Epoch: 5| Step: 10
Training loss: 1.726631888121567
Validation loss: 2.6203926992208055

Epoch: 375| Step: 0
Training loss: 1.7984152122196957
Validation loss: 2.5922330820655617

Epoch: 5| Step: 1
Training loss: 1.8266822142647063
Validation loss: 2.609363399914821

Epoch: 5| Step: 2
Training loss: 2.4004542914220006
Validation loss: 2.6363983764227865

Epoch: 5| Step: 3
Training loss: 1.7139786121631975
Validation loss: 2.620175401397145

Epoch: 5| Step: 4
Training loss: 2.1474911356733024
Validation loss: 2.645575047537862

Epoch: 5| Step: 5
Training loss: 2.1261899645636975
Validation loss: 2.6349956761965436

Epoch: 5| Step: 6
Training loss: 2.2161864393901887
Validation loss: 2.5923685664199

Epoch: 5| Step: 7
Training loss: 1.9743745175536442
Validation loss: 2.5292832930132074

Epoch: 5| Step: 8
Training loss: 2.3135264412626424
Validation loss: 2.5771278658095347

Epoch: 5| Step: 9
Training loss: 1.6084824837159846
Validation loss: 2.638542216981574

Epoch: 5| Step: 10
Training loss: 2.1161343253033467
Validation loss: 2.5967979299178525

Epoch: 376| Step: 0
Training loss: 1.4147969230262487
Validation loss: 2.631158500469641

Epoch: 5| Step: 1
Training loss: 2.2470921693988073
Validation loss: 2.575218098200489

Epoch: 5| Step: 2
Training loss: 2.176915528859032
Validation loss: 2.5914102293385235

Epoch: 5| Step: 3
Training loss: 1.7616202925343956
Validation loss: 2.604927097332039

Epoch: 5| Step: 4
Training loss: 2.3290610255906334
Validation loss: 2.562942808775609

Epoch: 5| Step: 5
Training loss: 1.9973764497362683
Validation loss: 2.6077753382721047

Epoch: 5| Step: 6
Training loss: 2.738213857999611
Validation loss: 2.5680441867725627

Epoch: 5| Step: 7
Training loss: 1.5801178086700127
Validation loss: 2.5710397541701155

Epoch: 5| Step: 8
Training loss: 1.7343165757245025
Validation loss: 2.5931783768529257

Epoch: 5| Step: 9
Training loss: 2.0852511416154167
Validation loss: 2.5614998519132075

Epoch: 5| Step: 10
Training loss: 2.0399930153521475
Validation loss: 2.630016656594613

Epoch: 377| Step: 0
Training loss: 1.9343870442990718
Validation loss: 2.603075686082717

Epoch: 5| Step: 1
Training loss: 1.648433305635585
Validation loss: 2.617123893757076

Epoch: 5| Step: 2
Training loss: 2.2833431517489693
Validation loss: 2.6499920724760644

Epoch: 5| Step: 3
Training loss: 1.8880429251244333
Validation loss: 2.593917669280183

Epoch: 5| Step: 4
Training loss: 1.7883727897256567
Validation loss: 2.5704113234077504

Epoch: 5| Step: 5
Training loss: 2.1551826157163996
Validation loss: 2.606496744237016

Epoch: 5| Step: 6
Training loss: 2.204394468519497
Validation loss: 2.554983060162673

Epoch: 5| Step: 7
Training loss: 1.72697837274436
Validation loss: 2.5767120656013676

Epoch: 5| Step: 8
Training loss: 2.4099176372209232
Validation loss: 2.6273756610925085

Epoch: 5| Step: 9
Training loss: 2.0300136618318905
Validation loss: 2.66190005632793

Epoch: 5| Step: 10
Training loss: 2.3399257741061823
Validation loss: 2.5891188448080285

Epoch: 378| Step: 0
Training loss: 1.8558273450768816
Validation loss: 2.617196181651302

Epoch: 5| Step: 1
Training loss: 1.7406054100153296
Validation loss: 2.617400892971245

Epoch: 5| Step: 2
Training loss: 2.6655346335223866
Validation loss: 2.5802958636618336

Epoch: 5| Step: 3
Training loss: 1.8014530410003595
Validation loss: 2.5467663239797127

Epoch: 5| Step: 4
Training loss: 2.33277868308962
Validation loss: 2.6223537331994677

Epoch: 5| Step: 5
Training loss: 2.0589339899836183
Validation loss: 2.5849051696818064

Epoch: 5| Step: 6
Training loss: 1.6144642037362966
Validation loss: 2.571582556084166

Epoch: 5| Step: 7
Training loss: 1.1995175265915634
Validation loss: 2.618719965305615

Epoch: 5| Step: 8
Training loss: 2.3438824425469766
Validation loss: 2.59046844088918

Epoch: 5| Step: 9
Training loss: 1.824129482266133
Validation loss: 2.628410751600691

Epoch: 5| Step: 10
Training loss: 2.4100338798135943
Validation loss: 2.590757506597838

Epoch: 379| Step: 0
Training loss: 2.302880875422239
Validation loss: 2.639120464674008

Epoch: 5| Step: 1
Training loss: 1.7470727689159646
Validation loss: 2.61971779395836

Epoch: 5| Step: 2
Training loss: 1.9713322492529208
Validation loss: 2.6690282667120875

Epoch: 5| Step: 3
Training loss: 2.262169880256271
Validation loss: 2.6184374123314806

Epoch: 5| Step: 4
Training loss: 1.686824239424331
Validation loss: 2.5758175315649194

Epoch: 5| Step: 5
Training loss: 2.5781592164514464
Validation loss: 2.628102178107379

Epoch: 5| Step: 6
Training loss: 2.0453958772664937
Validation loss: 2.5674312213799277

Epoch: 5| Step: 7
Training loss: 1.4633971535503152
Validation loss: 2.593369633103471

Epoch: 5| Step: 8
Training loss: 2.009974996117083
Validation loss: 2.6140380952384077

Epoch: 5| Step: 9
Training loss: 2.1297180307932866
Validation loss: 2.6719423611923054

Epoch: 5| Step: 10
Training loss: 1.9202164106794768
Validation loss: 2.59312849509502

Epoch: 380| Step: 0
Training loss: 1.7028091557764462
Validation loss: 2.584061060317651

Epoch: 5| Step: 1
Training loss: 2.328952104743454
Validation loss: 2.610214904834661

Epoch: 5| Step: 2
Training loss: 1.8719678521411829
Validation loss: 2.603356804383922

Epoch: 5| Step: 3
Training loss: 2.0230182228040765
Validation loss: 2.5740536399614458

Epoch: 5| Step: 4
Training loss: 1.2832570986377685
Validation loss: 2.603407244465093

Epoch: 5| Step: 5
Training loss: 2.578711425670256
Validation loss: 2.6759831436718065

Epoch: 5| Step: 6
Training loss: 1.4627111755236264
Validation loss: 2.6049238486487942

Epoch: 5| Step: 7
Training loss: 2.230634105318553
Validation loss: 2.5779599591551094

Epoch: 5| Step: 8
Training loss: 1.826451766652545
Validation loss: 2.673657401172975

Epoch: 5| Step: 9
Training loss: 2.178146528578203
Validation loss: 2.5912529951916574

Epoch: 5| Step: 10
Training loss: 2.26793631682561
Validation loss: 2.632874567548995

Epoch: 381| Step: 0
Training loss: 1.668008343764918
Validation loss: 2.6828193636894513

Epoch: 5| Step: 1
Training loss: 1.8702353656768884
Validation loss: 2.6444801396758026

Epoch: 5| Step: 2
Training loss: 2.193998656349849
Validation loss: 2.5534354878084087

Epoch: 5| Step: 3
Training loss: 1.920814655844794
Validation loss: 2.5601485153156958

Epoch: 5| Step: 4
Training loss: 1.5495786063291508
Validation loss: 2.5422365533806914

Epoch: 5| Step: 5
Training loss: 2.4152449887563976
Validation loss: 2.574669645857881

Epoch: 5| Step: 6
Training loss: 2.3805002468968732
Validation loss: 2.5489916365421452

Epoch: 5| Step: 7
Training loss: 1.9421876374886817
Validation loss: 2.5969666975767343

Epoch: 5| Step: 8
Training loss: 2.396871645849236
Validation loss: 2.6234901361622525

Epoch: 5| Step: 9
Training loss: 1.871908946039952
Validation loss: 2.5698609274446387

Epoch: 5| Step: 10
Training loss: 1.8316394248628172
Validation loss: 2.5483207482093633

Epoch: 382| Step: 0
Training loss: 1.8658812354911247
Validation loss: 2.5781285419856177

Epoch: 5| Step: 1
Training loss: 1.94997481549946
Validation loss: 2.5807273789160363

Epoch: 5| Step: 2
Training loss: 1.9476748297670057
Validation loss: 2.53729351910419

Epoch: 5| Step: 3
Training loss: 1.7325464868295075
Validation loss: 2.620330715620602

Epoch: 5| Step: 4
Training loss: 2.4357042789453436
Validation loss: 2.6571765092110886

Epoch: 5| Step: 5
Training loss: 2.2783689726707266
Validation loss: 2.587202713794789

Epoch: 5| Step: 6
Training loss: 1.6373510482251206
Validation loss: 2.6017322178826703

Epoch: 5| Step: 7
Training loss: 2.6826605583270524
Validation loss: 2.6654285083574463

Epoch: 5| Step: 8
Training loss: 1.8516779996363186
Validation loss: 2.67480828164875

Epoch: 5| Step: 9
Training loss: 2.469479223787629
Validation loss: 2.6389654946843377

Epoch: 5| Step: 10
Training loss: 1.818866073207933
Validation loss: 2.6561422211546706

Epoch: 383| Step: 0
Training loss: 2.2321478140639717
Validation loss: 2.6470189737648355

Epoch: 5| Step: 1
Training loss: 2.0845082848069256
Validation loss: 2.5856506041784635

Epoch: 5| Step: 2
Training loss: 2.2665819975054986
Validation loss: 2.6055898955386385

Epoch: 5| Step: 3
Training loss: 2.025741855695826
Validation loss: 2.6294933278479338

Epoch: 5| Step: 4
Training loss: 1.777094024888404
Validation loss: 2.6240663494135554

Epoch: 5| Step: 5
Training loss: 1.7062289449769048
Validation loss: 2.62240257514455

Epoch: 5| Step: 6
Training loss: 1.8733840336619039
Validation loss: 2.5820984033867895

Epoch: 5| Step: 7
Training loss: 1.9077179056596556
Validation loss: 2.603811751924742

Epoch: 5| Step: 8
Training loss: 2.0573606326619425
Validation loss: 2.576162105734183

Epoch: 5| Step: 9
Training loss: 2.2142307301036297
Validation loss: 2.5903455143351333

Epoch: 5| Step: 10
Training loss: 1.708096518811239
Validation loss: 2.6159254792462097

Epoch: 384| Step: 0
Training loss: 1.824508872640189
Validation loss: 2.5767986427021943

Epoch: 5| Step: 1
Training loss: 1.9383878826929226
Validation loss: 2.625329331474325

Epoch: 5| Step: 2
Training loss: 2.297546807477499
Validation loss: 2.591378277247428

Epoch: 5| Step: 3
Training loss: 2.0427013681757593
Validation loss: 2.5868236863661087

Epoch: 5| Step: 4
Training loss: 1.4773239513666236
Validation loss: 2.613441119411397

Epoch: 5| Step: 5
Training loss: 1.957700877497322
Validation loss: 2.612460976005133

Epoch: 5| Step: 6
Training loss: 2.0317771814386165
Validation loss: 2.631644173436078

Epoch: 5| Step: 7
Training loss: 2.0125197510312827
Validation loss: 2.6534150873920073

Epoch: 5| Step: 8
Training loss: 1.4049934707435587
Validation loss: 2.587988572622731

Epoch: 5| Step: 9
Training loss: 1.9715217576206163
Validation loss: 2.604155616654774

Epoch: 5| Step: 10
Training loss: 2.8078218335743244
Validation loss: 2.562876046733579

Epoch: 385| Step: 0
Training loss: 2.0131108180401918
Validation loss: 2.604258636491317

Epoch: 5| Step: 1
Training loss: 1.5902838320480368
Validation loss: 2.6095124512379284

Epoch: 5| Step: 2
Training loss: 2.0529538807619727
Validation loss: 2.6566993579398885

Epoch: 5| Step: 3
Training loss: 1.7199589032431022
Validation loss: 2.567553052346422

Epoch: 5| Step: 4
Training loss: 1.9259410118703593
Validation loss: 2.5617164661468457

Epoch: 5| Step: 5
Training loss: 1.87268209236657
Validation loss: 2.616450977965517

Epoch: 5| Step: 6
Training loss: 1.885278313831254
Validation loss: 2.652644326304538

Epoch: 5| Step: 7
Training loss: 2.082525198281416
Validation loss: 2.6125264493366136

Epoch: 5| Step: 8
Training loss: 2.3488013193189152
Validation loss: 2.6202360580468866

Epoch: 5| Step: 9
Training loss: 2.0203270294304256
Validation loss: 2.5951508041718387

Epoch: 5| Step: 10
Training loss: 2.672558078116957
Validation loss: 2.5761749390210382

Epoch: 386| Step: 0
Training loss: 1.7010100645768884
Validation loss: 2.6037345721361698

Epoch: 5| Step: 1
Training loss: 1.5402542379996171
Validation loss: 2.6233144564748887

Epoch: 5| Step: 2
Training loss: 2.2399819189431827
Validation loss: 2.6167981694007034

Epoch: 5| Step: 3
Training loss: 2.4315812069171203
Validation loss: 2.613402379664935

Epoch: 5| Step: 4
Training loss: 1.6572000190079283
Validation loss: 2.628930852546002

Epoch: 5| Step: 5
Training loss: 1.84462581458361
Validation loss: 2.5407486711413103

Epoch: 5| Step: 6
Training loss: 1.8731560222817598
Validation loss: 2.5924443302970395

Epoch: 5| Step: 7
Training loss: 2.251684511943648
Validation loss: 2.59886706045214

Epoch: 5| Step: 8
Training loss: 1.9523367550019748
Validation loss: 2.59395912731845

Epoch: 5| Step: 9
Training loss: 2.609066242521916
Validation loss: 2.5996322233284572

Epoch: 5| Step: 10
Training loss: 2.1141529365587903
Validation loss: 2.6307631092827783

Epoch: 387| Step: 0
Training loss: 1.8489129790711776
Validation loss: 2.6053591488982146

Epoch: 5| Step: 1
Training loss: 2.2611403705766833
Validation loss: 2.5640459557090916

Epoch: 5| Step: 2
Training loss: 1.7909085939597658
Validation loss: 2.5811665809987137

Epoch: 5| Step: 3
Training loss: 1.8506582120203898
Validation loss: 2.5625353234730475

Epoch: 5| Step: 4
Training loss: 1.982414839407928
Validation loss: 2.5746273056595474

Epoch: 5| Step: 5
Training loss: 2.222891367726917
Validation loss: 2.6336346539039717

Epoch: 5| Step: 6
Training loss: 1.748292430487706
Validation loss: 2.605906205199659

Epoch: 5| Step: 7
Training loss: 1.780150492446309
Validation loss: 2.620900001723274

Epoch: 5| Step: 8
Training loss: 1.6972099971105497
Validation loss: 2.602066619403471

Epoch: 5| Step: 9
Training loss: 2.135634682543795
Validation loss: 2.642070458382597

Epoch: 5| Step: 10
Training loss: 2.5704459761541196
Validation loss: 2.6071139580401033

Epoch: 388| Step: 0
Training loss: 1.7665642459738615
Validation loss: 2.605546405799289

Epoch: 5| Step: 1
Training loss: 2.3357585723631455
Validation loss: 2.6657000995977467

Epoch: 5| Step: 2
Training loss: 1.9344214931440917
Validation loss: 2.6032711863569884

Epoch: 5| Step: 3
Training loss: 1.9780941181875864
Validation loss: 2.6681626585026668

Epoch: 5| Step: 4
Training loss: 2.23340420207225
Validation loss: 2.6177576596501635

Epoch: 5| Step: 5
Training loss: 1.8113080413343328
Validation loss: 2.5713810823143888

Epoch: 5| Step: 6
Training loss: 1.3765271982262701
Validation loss: 2.5547409511128816

Epoch: 5| Step: 7
Training loss: 2.4832343595951776
Validation loss: 2.5553757321679598

Epoch: 5| Step: 8
Training loss: 1.6983417220777306
Validation loss: 2.6746417026348936

Epoch: 5| Step: 9
Training loss: 1.9586104609503496
Validation loss: 2.6376441187971826

Epoch: 5| Step: 10
Training loss: 2.255157493623211
Validation loss: 2.603091543113832

Epoch: 389| Step: 0
Training loss: 1.660056149325918
Validation loss: 2.6603320244404327

Epoch: 5| Step: 1
Training loss: 1.7231699897612804
Validation loss: 2.555302746832115

Epoch: 5| Step: 2
Training loss: 1.6236032204952475
Validation loss: 2.6176240006332225

Epoch: 5| Step: 3
Training loss: 1.4506960020558612
Validation loss: 2.601847054029965

Epoch: 5| Step: 4
Training loss: 1.7720934778576853
Validation loss: 2.57113310803469

Epoch: 5| Step: 5
Training loss: 2.324872401027805
Validation loss: 2.6446611334928445

Epoch: 5| Step: 6
Training loss: 1.9109453003069923
Validation loss: 2.6222107870014693

Epoch: 5| Step: 7
Training loss: 2.546186201881571
Validation loss: 2.610555365006587

Epoch: 5| Step: 8
Training loss: 2.1673134303067445
Validation loss: 2.6323202038127427

Epoch: 5| Step: 9
Training loss: 2.4679740941930803
Validation loss: 2.659265250404187

Epoch: 5| Step: 10
Training loss: 2.145116062714526
Validation loss: 2.5760759650200455

Epoch: 390| Step: 0
Training loss: 2.491510185592933
Validation loss: 2.6726198068024107

Epoch: 5| Step: 1
Training loss: 2.254558396162438
Validation loss: 2.591876073941641

Epoch: 5| Step: 2
Training loss: 2.189984463849983
Validation loss: 2.623861009117155

Epoch: 5| Step: 3
Training loss: 2.1555057291562214
Validation loss: 2.6253253229285334

Epoch: 5| Step: 4
Training loss: 2.438531901717375
Validation loss: 2.6362455482281755

Epoch: 5| Step: 5
Training loss: 1.4056426538128015
Validation loss: 2.63837429027615

Epoch: 5| Step: 6
Training loss: 1.4466799478902745
Validation loss: 2.6290755971374633

Epoch: 5| Step: 7
Training loss: 1.025903076003357
Validation loss: 2.614205039912319

Epoch: 5| Step: 8
Training loss: 2.0946367577996057
Validation loss: 2.572246296953492

Epoch: 5| Step: 9
Training loss: 1.8848747261371486
Validation loss: 2.5709135931886467

Epoch: 5| Step: 10
Training loss: 2.103103129711056
Validation loss: 2.604348977547168

Epoch: 391| Step: 0
Training loss: 1.7671177722993303
Validation loss: 2.620432138342059

Epoch: 5| Step: 1
Training loss: 2.000343412480163
Validation loss: 2.5845604528159423

Epoch: 5| Step: 2
Training loss: 2.429161971683665
Validation loss: 2.6426742736672195

Epoch: 5| Step: 3
Training loss: 1.9234173176355025
Validation loss: 2.61383671026531

Epoch: 5| Step: 4
Training loss: 1.0254995524360353
Validation loss: 2.6455121635500833

Epoch: 5| Step: 5
Training loss: 2.2537048355629543
Validation loss: 2.5692265786157016

Epoch: 5| Step: 6
Training loss: 1.9207331669218903
Validation loss: 2.537964842550046

Epoch: 5| Step: 7
Training loss: 2.659688989770862
Validation loss: 2.579291351883906

Epoch: 5| Step: 8
Training loss: 1.6649774892390743
Validation loss: 2.6313284440809257

Epoch: 5| Step: 9
Training loss: 1.8438512483372602
Validation loss: 2.571502847773969

Epoch: 5| Step: 10
Training loss: 2.2096898093391557
Validation loss: 2.680995935875401

Epoch: 392| Step: 0
Training loss: 2.1528529068611078
Validation loss: 2.5829589293248305

Epoch: 5| Step: 1
Training loss: 2.036880553461249
Validation loss: 2.630845508541485

Epoch: 5| Step: 2
Training loss: 2.7167186821792586
Validation loss: 2.5677428965925655

Epoch: 5| Step: 3
Training loss: 2.0345339711508497
Validation loss: 2.575603652535458

Epoch: 5| Step: 4
Training loss: 1.689528552890813
Validation loss: 2.590943997213022

Epoch: 5| Step: 5
Training loss: 1.5553519204608721
Validation loss: 2.6152515179379034

Epoch: 5| Step: 6
Training loss: 1.653209702858278
Validation loss: 2.605106128845968

Epoch: 5| Step: 7
Training loss: 1.7308248665825545
Validation loss: 2.614706103139709

Epoch: 5| Step: 8
Training loss: 2.192565285070635
Validation loss: 2.624060111436792

Epoch: 5| Step: 9
Training loss: 1.762445202780488
Validation loss: 2.587138996619013

Epoch: 5| Step: 10
Training loss: 1.8956836459693647
Validation loss: 2.6611819397778604

Epoch: 393| Step: 0
Training loss: 2.3133147582848377
Validation loss: 2.622485230250785

Epoch: 5| Step: 1
Training loss: 2.0959042526390532
Validation loss: 2.5773406356051023

Epoch: 5| Step: 2
Training loss: 1.2559352157735257
Validation loss: 2.5936868795578913

Epoch: 5| Step: 3
Training loss: 1.7924837940074032
Validation loss: 2.610334380507669

Epoch: 5| Step: 4
Training loss: 1.8696011700369848
Validation loss: 2.6181654108235435

Epoch: 5| Step: 5
Training loss: 2.2877558080503406
Validation loss: 2.649586299080556

Epoch: 5| Step: 6
Training loss: 2.0201259305621493
Validation loss: 2.563628435721308

Epoch: 5| Step: 7
Training loss: 2.1148522367331792
Validation loss: 2.5879884993189264

Epoch: 5| Step: 8
Training loss: 1.495092789184907
Validation loss: 2.608209168894859

Epoch: 5| Step: 9
Training loss: 1.608836037469958
Validation loss: 2.6545116201235226

Epoch: 5| Step: 10
Training loss: 2.6866857492827796
Validation loss: 2.6203296531156752

Epoch: 394| Step: 0
Training loss: 1.8593204394117182
Validation loss: 2.6042460577563586

Epoch: 5| Step: 1
Training loss: 2.391825455590304
Validation loss: 2.5673014999034516

Epoch: 5| Step: 2
Training loss: 1.6277245642318556
Validation loss: 2.616957338069556

Epoch: 5| Step: 3
Training loss: 2.209905916170459
Validation loss: 2.5822363067971046

Epoch: 5| Step: 4
Training loss: 1.5778003018671347
Validation loss: 2.55849491752937

Epoch: 5| Step: 5
Training loss: 1.8535668835320416
Validation loss: 2.559722461553945

Epoch: 5| Step: 6
Training loss: 2.4570162094941583
Validation loss: 2.6209291241043395

Epoch: 5| Step: 7
Training loss: 1.7825839752918473
Validation loss: 2.6359449683356515

Epoch: 5| Step: 8
Training loss: 1.9440597115714195
Validation loss: 2.6120484330178346

Epoch: 5| Step: 9
Training loss: 1.980991452552499
Validation loss: 2.6190840863753526

Epoch: 5| Step: 10
Training loss: 2.264592639257079
Validation loss: 2.582445474044705

Epoch: 395| Step: 0
Training loss: 1.4056192891033308
Validation loss: 2.6141951636886804

Epoch: 5| Step: 1
Training loss: 1.9980853572059394
Validation loss: 2.621197475338784

Epoch: 5| Step: 2
Training loss: 2.2414961224126113
Validation loss: 2.644753814748084

Epoch: 5| Step: 3
Training loss: 2.0289199376222933
Validation loss: 2.69117038698879

Epoch: 5| Step: 4
Training loss: 1.6958025386679276
Validation loss: 2.600511177791837

Epoch: 5| Step: 5
Training loss: 1.7186750222238034
Validation loss: 2.627027349844964

Epoch: 5| Step: 6
Training loss: 2.307719986700688
Validation loss: 2.593044056940601

Epoch: 5| Step: 7
Training loss: 1.93072982004623
Validation loss: 2.596652387188819

Epoch: 5| Step: 8
Training loss: 2.106773411042311
Validation loss: 2.617382331150591

Epoch: 5| Step: 9
Training loss: 2.2376307529200554
Validation loss: 2.6566595245598617

Epoch: 5| Step: 10
Training loss: 2.088483991960214
Validation loss: 2.6427194495564743

Epoch: 396| Step: 0
Training loss: 2.163724907388533
Validation loss: 2.632479649331597

Epoch: 5| Step: 1
Training loss: 2.1964368011462208
Validation loss: 2.643165109851239

Epoch: 5| Step: 2
Training loss: 1.6361075559763485
Validation loss: 2.6756179289065374

Epoch: 5| Step: 3
Training loss: 1.9528118645466617
Validation loss: 2.5876148369005976

Epoch: 5| Step: 4
Training loss: 2.173390799486199
Validation loss: 2.6131912304966995

Epoch: 5| Step: 5
Training loss: 1.637344277235562
Validation loss: 2.5963264939701927

Epoch: 5| Step: 6
Training loss: 1.66804915151744
Validation loss: 2.611012573305796

Epoch: 5| Step: 7
Training loss: 2.084256870290939
Validation loss: 2.625288578291252

Epoch: 5| Step: 8
Training loss: 2.6484059919885543
Validation loss: 2.5706646593192666

Epoch: 5| Step: 9
Training loss: 2.087646013281471
Validation loss: 2.6541016627235

Epoch: 5| Step: 10
Training loss: 1.7656268904684294
Validation loss: 2.5874454275555534

Epoch: 397| Step: 0
Training loss: 1.7487903228757269
Validation loss: 2.6179721038830466

Epoch: 5| Step: 1
Training loss: 1.743888401021839
Validation loss: 2.655712775494856

Epoch: 5| Step: 2
Training loss: 1.79864414860623
Validation loss: 2.5858627450793463

Epoch: 5| Step: 3
Training loss: 1.9294162822195717
Validation loss: 2.6197873701033725

Epoch: 5| Step: 4
Training loss: 1.4076153802416809
Validation loss: 2.6062401921539795

Epoch: 5| Step: 5
Training loss: 2.5258976426638116
Validation loss: 2.658630899416368

Epoch: 5| Step: 6
Training loss: 2.301148260665948
Validation loss: 2.6443276268398366

Epoch: 5| Step: 7
Training loss: 2.153946572231784
Validation loss: 2.617164579636097

Epoch: 5| Step: 8
Training loss: 2.0889445714540686
Validation loss: 2.6129331271801353

Epoch: 5| Step: 9
Training loss: 1.8847480417330722
Validation loss: 2.565519938928875

Epoch: 5| Step: 10
Training loss: 1.8344300269950446
Validation loss: 2.6372816047008523

Epoch: 398| Step: 0
Training loss: 1.7064362979671335
Validation loss: 2.5929096984313524

Epoch: 5| Step: 1
Training loss: 1.7357974705842611
Validation loss: 2.6154904359385873

Epoch: 5| Step: 2
Training loss: 2.193778156849718
Validation loss: 2.6009560568941548

Epoch: 5| Step: 3
Training loss: 2.500978469103139
Validation loss: 2.6615363429618677

Epoch: 5| Step: 4
Training loss: 1.9410890131983705
Validation loss: 2.6324936503376115

Epoch: 5| Step: 5
Training loss: 1.824789019369078
Validation loss: 2.5755962241884633

Epoch: 5| Step: 6
Training loss: 1.864844412258176
Validation loss: 2.658552476993366

Epoch: 5| Step: 7
Training loss: 1.145912664730528
Validation loss: 2.579537252894691

Epoch: 5| Step: 8
Training loss: 2.56683085977421
Validation loss: 2.6436843028415145

Epoch: 5| Step: 9
Training loss: 2.2302824299984554
Validation loss: 2.685020165006306

Epoch: 5| Step: 10
Training loss: 1.7729411501899162
Validation loss: 2.637745340866062

Epoch: 399| Step: 0
Training loss: 1.647039028156958
Validation loss: 2.5881509235691023

Epoch: 5| Step: 1
Training loss: 2.113853616819832
Validation loss: 2.648511621239804

Epoch: 5| Step: 2
Training loss: 1.4410493403663316
Validation loss: 2.5890188169625308

Epoch: 5| Step: 3
Training loss: 2.3105001307811257
Validation loss: 2.6070496979351496

Epoch: 5| Step: 4
Training loss: 1.7606309463135144
Validation loss: 2.6254349937532098

Epoch: 5| Step: 5
Training loss: 2.2879654791168442
Validation loss: 2.5641742542142896

Epoch: 5| Step: 6
Training loss: 2.10811899726617
Validation loss: 2.576518340045053

Epoch: 5| Step: 7
Training loss: 1.7167633365831354
Validation loss: 2.6684945946659924

Epoch: 5| Step: 8
Training loss: 1.7978467221171601
Validation loss: 2.641786361070568

Epoch: 5| Step: 9
Training loss: 2.2829314005734207
Validation loss: 2.681581477763716

Epoch: 5| Step: 10
Training loss: 2.4001376311257543
Validation loss: 2.6095688131221184

Epoch: 400| Step: 0
Training loss: 2.518733976327365
Validation loss: 2.6156553541523007

Epoch: 5| Step: 1
Training loss: 2.1553137031807346
Validation loss: 2.624810749621061

Epoch: 5| Step: 2
Training loss: 1.7503534368826652
Validation loss: 2.5957456152384437

Epoch: 5| Step: 3
Training loss: 1.566295210786317
Validation loss: 2.622882833031873

Epoch: 5| Step: 4
Training loss: 1.3016298750604107
Validation loss: 2.5787989536283256

Epoch: 5| Step: 5
Training loss: 2.1971519067795118
Validation loss: 2.591499558164066

Epoch: 5| Step: 6
Training loss: 1.650989744250435
Validation loss: 2.6537798800044614

Epoch: 5| Step: 7
Training loss: 2.115450213155488
Validation loss: 2.6224881746644155

Epoch: 5| Step: 8
Training loss: 2.1260196259131914
Validation loss: 2.6108819202342164

Epoch: 5| Step: 9
Training loss: 1.7982045437877272
Validation loss: 2.6190742412748804

Epoch: 5| Step: 10
Training loss: 1.525879062499992
Validation loss: 2.6073367916216212

Epoch: 401| Step: 0
Training loss: 1.5312819185628201
Validation loss: 2.6064264906954158

Epoch: 5| Step: 1
Training loss: 1.8180681399007084
Validation loss: 2.650622368646899

Epoch: 5| Step: 2
Training loss: 2.1476181409888477
Validation loss: 2.6346384326370966

Epoch: 5| Step: 3
Training loss: 2.077445586004909
Validation loss: 2.5692496806742957

Epoch: 5| Step: 4
Training loss: 1.4686676976296547
Validation loss: 2.6539169817532278

Epoch: 5| Step: 5
Training loss: 1.9789267411283646
Validation loss: 2.638528172771121

Epoch: 5| Step: 6
Training loss: 2.577713072264321
Validation loss: 2.5748493813193387

Epoch: 5| Step: 7
Training loss: 2.2409481650830005
Validation loss: 2.6044255426183334

Epoch: 5| Step: 8
Training loss: 1.7362475210217436
Validation loss: 2.595040257536995

Epoch: 5| Step: 9
Training loss: 1.6082527914617486
Validation loss: 2.610780151548655

Epoch: 5| Step: 10
Training loss: 2.256453266656434
Validation loss: 2.5868036683116005

Epoch: 402| Step: 0
Training loss: 1.786786092899361
Validation loss: 2.626963844251524

Epoch: 5| Step: 1
Training loss: 1.264602672087576
Validation loss: 2.605290624096897

Epoch: 5| Step: 2
Training loss: 2.4147087145801938
Validation loss: 2.5754577820778914

Epoch: 5| Step: 3
Training loss: 1.5019047088161133
Validation loss: 2.5966342970697016

Epoch: 5| Step: 4
Training loss: 1.7177306880695355
Validation loss: 2.6414804904705624

Epoch: 5| Step: 5
Training loss: 2.331547212447054
Validation loss: 2.6377298039303074

Epoch: 5| Step: 6
Training loss: 2.5446935567370335
Validation loss: 2.6418522517235465

Epoch: 5| Step: 7
Training loss: 1.44679060951457
Validation loss: 2.6095029001204932

Epoch: 5| Step: 8
Training loss: 1.7714605529596583
Validation loss: 2.657594803386987

Epoch: 5| Step: 9
Training loss: 2.1587033895950754
Validation loss: 2.649602878214012

Epoch: 5| Step: 10
Training loss: 2.411429144817922
Validation loss: 2.665522259315516

Epoch: 403| Step: 0
Training loss: 1.9191537836028638
Validation loss: 2.606912318444108

Epoch: 5| Step: 1
Training loss: 1.716611190319243
Validation loss: 2.694273516009609

Epoch: 5| Step: 2
Training loss: 1.793789278989311
Validation loss: 2.6179914968135622

Epoch: 5| Step: 3
Training loss: 1.9803502876922785
Validation loss: 2.6108398422771173

Epoch: 5| Step: 4
Training loss: 2.3746209093012354
Validation loss: 2.6196252819009027

Epoch: 5| Step: 5
Training loss: 2.052234185833434
Validation loss: 2.606243726423225

Epoch: 5| Step: 6
Training loss: 2.245925180495075
Validation loss: 2.6138576825424136

Epoch: 5| Step: 7
Training loss: 1.9291576322120167
Validation loss: 2.6332708644843286

Epoch: 5| Step: 8
Training loss: 1.5130792848345505
Validation loss: 2.593125351254606

Epoch: 5| Step: 9
Training loss: 2.264597061054789
Validation loss: 2.6085176789280013

Epoch: 5| Step: 10
Training loss: 1.6449278582027256
Validation loss: 2.5420888237150536

Epoch: 404| Step: 0
Training loss: 1.8537609070696883
Validation loss: 2.5575029655832853

Epoch: 5| Step: 1
Training loss: 1.8499953965825724
Validation loss: 2.602631963222924

Epoch: 5| Step: 2
Training loss: 2.209993194466033
Validation loss: 2.5880108331091978

Epoch: 5| Step: 3
Training loss: 1.694757678397038
Validation loss: 2.673276812603127

Epoch: 5| Step: 4
Training loss: 1.5892857877630275
Validation loss: 2.6438486938471373

Epoch: 5| Step: 5
Training loss: 1.6469337872720333
Validation loss: 2.649595199674058

Epoch: 5| Step: 6
Training loss: 2.632120556560352
Validation loss: 2.620599819765831

Epoch: 5| Step: 7
Training loss: 2.0509118029501474
Validation loss: 2.6320054175654675

Epoch: 5| Step: 8
Training loss: 2.2748932781968167
Validation loss: 2.57486047479247

Epoch: 5| Step: 9
Training loss: 1.6421267947401814
Validation loss: 2.6663781466322547

Epoch: 5| Step: 10
Training loss: 2.081881691318685
Validation loss: 2.691057954539059

Epoch: 405| Step: 0
Training loss: 1.5706725206028558
Validation loss: 2.6298838389765598

Epoch: 5| Step: 1
Training loss: 1.7970683781601302
Validation loss: 2.6572385672378798

Epoch: 5| Step: 2
Training loss: 1.6339766445428463
Validation loss: 2.6235186415313674

Epoch: 5| Step: 3
Training loss: 2.3895241190971626
Validation loss: 2.6452854051967325

Epoch: 5| Step: 4
Training loss: 1.82325781400223
Validation loss: 2.6434278879712836

Epoch: 5| Step: 5
Training loss: 2.0772268319053997
Validation loss: 2.630139228126597

Epoch: 5| Step: 6
Training loss: 1.8260086068183476
Validation loss: 2.5952371612865077

Epoch: 5| Step: 7
Training loss: 2.066427710264864
Validation loss: 2.629550478180182

Epoch: 5| Step: 8
Training loss: 1.2836243099352325
Validation loss: 2.6031749561448696

Epoch: 5| Step: 9
Training loss: 2.204765196255074
Validation loss: 2.6503490098599785

Epoch: 5| Step: 10
Training loss: 2.4353837828187777
Validation loss: 2.610909999649244

Epoch: 406| Step: 0
Training loss: 2.1595033069257594
Validation loss: 2.6583554980374653

Epoch: 5| Step: 1
Training loss: 1.6612442580239382
Validation loss: 2.634971491234136

Epoch: 5| Step: 2
Training loss: 1.8177956138431173
Validation loss: 2.660040371943366

Epoch: 5| Step: 3
Training loss: 1.8187891926426107
Validation loss: 2.6092606238747247

Epoch: 5| Step: 4
Training loss: 2.294942445054089
Validation loss: 2.6678002409861197

Epoch: 5| Step: 5
Training loss: 1.58075540218127
Validation loss: 2.625711652210464

Epoch: 5| Step: 6
Training loss: 2.158311715134373
Validation loss: 2.5922648762656766

Epoch: 5| Step: 7
Training loss: 1.306059795202505
Validation loss: 2.647901799745724

Epoch: 5| Step: 8
Training loss: 2.5013372659401525
Validation loss: 2.5946217354576637

Epoch: 5| Step: 9
Training loss: 1.803541471888105
Validation loss: 2.630298938406978

Epoch: 5| Step: 10
Training loss: 2.0321856177924187
Validation loss: 2.6240384342301137

Epoch: 407| Step: 0
Training loss: 1.8911519222709556
Validation loss: 2.641472213762985

Epoch: 5| Step: 1
Training loss: 1.520877976829191
Validation loss: 2.620574300625241

Epoch: 5| Step: 2
Training loss: 2.0814084379357776
Validation loss: 2.6105532197637222

Epoch: 5| Step: 3
Training loss: 1.6117478442466855
Validation loss: 2.622143936429768

Epoch: 5| Step: 4
Training loss: 2.047653050367409
Validation loss: 2.633300085164194

Epoch: 5| Step: 5
Training loss: 2.203978244777972
Validation loss: 2.63418766463522

Epoch: 5| Step: 6
Training loss: 1.9513247318362794
Validation loss: 2.5654784310206518

Epoch: 5| Step: 7
Training loss: 1.9171718332510155
Validation loss: 2.640580055265479

Epoch: 5| Step: 8
Training loss: 2.7281111114952443
Validation loss: 2.5818529756758415

Epoch: 5| Step: 9
Training loss: 1.4702847355522748
Validation loss: 2.634643196696198

Epoch: 5| Step: 10
Training loss: 1.7871569350954577
Validation loss: 2.618742949393835

Epoch: 408| Step: 0
Training loss: 1.8010502612245531
Validation loss: 2.6328451410743883

Epoch: 5| Step: 1
Training loss: 2.4615716995003427
Validation loss: 2.5913669646208954

Epoch: 5| Step: 2
Training loss: 1.8980930471133068
Validation loss: 2.67320851931165

Epoch: 5| Step: 3
Training loss: 1.383131087505667
Validation loss: 2.6193239026890027

Epoch: 5| Step: 4
Training loss: 1.5567709606175282
Validation loss: 2.6181922909821322

Epoch: 5| Step: 5
Training loss: 1.691113876199042
Validation loss: 2.6736813924908307

Epoch: 5| Step: 6
Training loss: 2.5746887426307365
Validation loss: 2.582557029336253

Epoch: 5| Step: 7
Training loss: 1.6895579752055891
Validation loss: 2.6417324275231344

Epoch: 5| Step: 8
Training loss: 1.7834599488608298
Validation loss: 2.6059502752579884

Epoch: 5| Step: 9
Training loss: 2.09167890456471
Validation loss: 2.618680572353027

Epoch: 5| Step: 10
Training loss: 1.994939123004055
Validation loss: 2.601204370505671

Epoch: 409| Step: 0
Training loss: 1.7560396876271005
Validation loss: 2.674119692592691

Epoch: 5| Step: 1
Training loss: 2.2825015044860226
Validation loss: 2.6345258670712246

Epoch: 5| Step: 2
Training loss: 1.5700142800234458
Validation loss: 2.637451979983385

Epoch: 5| Step: 3
Training loss: 2.224633381674681
Validation loss: 2.6011275203997015

Epoch: 5| Step: 4
Training loss: 2.3638500695553155
Validation loss: 2.653152439434469

Epoch: 5| Step: 5
Training loss: 1.7723087970603348
Validation loss: 2.597625762343575

Epoch: 5| Step: 6
Training loss: 1.8635775732337951
Validation loss: 2.6480774112708168

Epoch: 5| Step: 7
Training loss: 1.9523578815780702
Validation loss: 2.6596277349867705

Epoch: 5| Step: 8
Training loss: 1.9158196305289208
Validation loss: 2.6014145443193444

Epoch: 5| Step: 9
Training loss: 1.9811618652957348
Validation loss: 2.5869944395552116

Epoch: 5| Step: 10
Training loss: 1.3089323602107454
Validation loss: 2.6434298421513067

Epoch: 410| Step: 0
Training loss: 1.8423227508049573
Validation loss: 2.5951491020918454

Epoch: 5| Step: 1
Training loss: 2.026981622771641
Validation loss: 2.6015655952131445

Epoch: 5| Step: 2
Training loss: 2.2478396322669765
Validation loss: 2.614904308403095

Epoch: 5| Step: 3
Training loss: 2.514147780864498
Validation loss: 2.632854659120674

Epoch: 5| Step: 4
Training loss: 1.602232183611222
Validation loss: 2.6049681951380133

Epoch: 5| Step: 5
Training loss: 1.483265190845282
Validation loss: 2.616734423392716

Epoch: 5| Step: 6
Training loss: 2.3232036008512686
Validation loss: 2.611054674988989

Epoch: 5| Step: 7
Training loss: 1.8036859548807904
Validation loss: 2.627598129618876

Epoch: 5| Step: 8
Training loss: 1.8736070545071868
Validation loss: 2.6359707646524595

Epoch: 5| Step: 9
Training loss: 1.7827999666193017
Validation loss: 2.594593648726507

Epoch: 5| Step: 10
Training loss: 1.4396083960258363
Validation loss: 2.682289590106992

Epoch: 411| Step: 0
Training loss: 1.6565593214711565
Validation loss: 2.5580710657394854

Epoch: 5| Step: 1
Training loss: 1.9568878547687287
Validation loss: 2.6042308535305203

Epoch: 5| Step: 2
Training loss: 1.875607900621009
Validation loss: 2.6659686047491618

Epoch: 5| Step: 3
Training loss: 1.648912768076797
Validation loss: 2.585253618733944

Epoch: 5| Step: 4
Training loss: 1.5040402043122865
Validation loss: 2.6316238874647095

Epoch: 5| Step: 5
Training loss: 1.558399924557114
Validation loss: 2.676055674249075

Epoch: 5| Step: 6
Training loss: 2.585889372132858
Validation loss: 2.6703432033062096

Epoch: 5| Step: 7
Training loss: 2.1178295105206946
Validation loss: 2.658730604130887

Epoch: 5| Step: 8
Training loss: 1.9972836406155627
Validation loss: 2.6234807053129034

Epoch: 5| Step: 9
Training loss: 2.0481609934768787
Validation loss: 2.6163914524841685

Epoch: 5| Step: 10
Training loss: 2.0140746312334663
Validation loss: 2.635404477246696

Epoch: 412| Step: 0
Training loss: 1.977447492575144
Validation loss: 2.6401681773680616

Epoch: 5| Step: 1
Training loss: 1.700671537380105
Validation loss: 2.641880371684805

Epoch: 5| Step: 2
Training loss: 2.0695787965087233
Validation loss: 2.633905495909986

Epoch: 5| Step: 3
Training loss: 1.8829126608391555
Validation loss: 2.5886439564035477

Epoch: 5| Step: 4
Training loss: 2.0078104813265023
Validation loss: 2.6168335867707335

Epoch: 5| Step: 5
Training loss: 1.6550682458319372
Validation loss: 2.6253533171954753

Epoch: 5| Step: 6
Training loss: 1.5322754209665579
Validation loss: 2.627069396875838

Epoch: 5| Step: 7
Training loss: 2.3948038515431116
Validation loss: 2.5940287154014983

Epoch: 5| Step: 8
Training loss: 2.32879772323712
Validation loss: 2.6350270799290367

Epoch: 5| Step: 9
Training loss: 1.7063786636300915
Validation loss: 2.6013787800379276

Epoch: 5| Step: 10
Training loss: 1.909916462893902
Validation loss: 2.6427081442581097

Epoch: 413| Step: 0
Training loss: 2.2547518038287264
Validation loss: 2.660237598125534

Epoch: 5| Step: 1
Training loss: 2.329142917609792
Validation loss: 2.598875086160081

Epoch: 5| Step: 2
Training loss: 1.8447042032707297
Validation loss: 2.6124824715672132

Epoch: 5| Step: 3
Training loss: 1.4803326627241191
Validation loss: 2.609998639653738

Epoch: 5| Step: 4
Training loss: 2.4806396425506563
Validation loss: 2.5669106632237684

Epoch: 5| Step: 5
Training loss: 1.8137728726859397
Validation loss: 2.661394218226578

Epoch: 5| Step: 6
Training loss: 1.2714496379273477
Validation loss: 2.633857566132459

Epoch: 5| Step: 7
Training loss: 1.8472104331128736
Validation loss: 2.6564867728458923

Epoch: 5| Step: 8
Training loss: 1.328020428299334
Validation loss: 2.609133263096319

Epoch: 5| Step: 9
Training loss: 2.00842560784342
Validation loss: 2.6549785768168985

Epoch: 5| Step: 10
Training loss: 2.273619549465761
Validation loss: 2.6097755549610366

Epoch: 414| Step: 0
Training loss: 1.669474509475022
Validation loss: 2.6635645510880614

Epoch: 5| Step: 1
Training loss: 1.4857693999280552
Validation loss: 2.6281697306405705

Epoch: 5| Step: 2
Training loss: 2.0841152504007847
Validation loss: 2.666600142566953

Epoch: 5| Step: 3
Training loss: 1.9733434103480785
Validation loss: 2.572690000127983

Epoch: 5| Step: 4
Training loss: 2.142979684232324
Validation loss: 2.629178673129612

Epoch: 5| Step: 5
Training loss: 1.937260459120445
Validation loss: 2.6158045438426685

Epoch: 5| Step: 6
Training loss: 1.6964308745863346
Validation loss: 2.6522902331484484

Epoch: 5| Step: 7
Training loss: 1.96293252928685
Validation loss: 2.6542766781283573

Epoch: 5| Step: 8
Training loss: 2.005263079271606
Validation loss: 2.608814334744441

Epoch: 5| Step: 9
Training loss: 1.2281298494121915
Validation loss: 2.614519290477185

Epoch: 5| Step: 10
Training loss: 2.417656454647048
Validation loss: 2.601210067031025

Epoch: 415| Step: 0
Training loss: 1.7282680873026457
Validation loss: 2.6225103563940446

Epoch: 5| Step: 1
Training loss: 1.7758364143983323
Validation loss: 2.601181905574563

Epoch: 5| Step: 2
Training loss: 1.9666486151992895
Validation loss: 2.6350438392001223

Epoch: 5| Step: 3
Training loss: 2.105258003968907
Validation loss: 2.551336130265143

Epoch: 5| Step: 4
Training loss: 2.409271127166218
Validation loss: 2.5502694637628727

Epoch: 5| Step: 5
Training loss: 1.7793579761051193
Validation loss: 2.59334238395068

Epoch: 5| Step: 6
Training loss: 1.4023925857753798
Validation loss: 2.5817450789138747

Epoch: 5| Step: 7
Training loss: 1.4476427418325097
Validation loss: 2.638512086619689

Epoch: 5| Step: 8
Training loss: 1.3881033848398268
Validation loss: 2.500996190192239

Epoch: 5| Step: 9
Training loss: 2.1634853433456818
Validation loss: 2.6503177818739427

Epoch: 5| Step: 10
Training loss: 2.646508879037849
Validation loss: 2.5988057481972424

Epoch: 416| Step: 0
Training loss: 2.169814305424691
Validation loss: 2.6969096022985606

Epoch: 5| Step: 1
Training loss: 1.8590335051506481
Validation loss: 2.630104697586023

Epoch: 5| Step: 2
Training loss: 1.95314324942646
Validation loss: 2.605815739077023

Epoch: 5| Step: 3
Training loss: 1.8341674063353353
Validation loss: 2.658261564725274

Epoch: 5| Step: 4
Training loss: 2.3694196695530927
Validation loss: 2.6524478712438935

Epoch: 5| Step: 5
Training loss: 2.105609726299849
Validation loss: 2.6257863173270066

Epoch: 5| Step: 6
Training loss: 2.0849879242984155
Validation loss: 2.6950268066568883

Epoch: 5| Step: 7
Training loss: 1.2209666219518334
Validation loss: 2.6719433734298437

Epoch: 5| Step: 8
Training loss: 1.8050297664396435
Validation loss: 2.729574473771135

Epoch: 5| Step: 9
Training loss: 1.5312963206233356
Validation loss: 2.6715577071540864

Epoch: 5| Step: 10
Training loss: 2.4174037883434405
Validation loss: 2.6676460836949922

Epoch: 417| Step: 0
Training loss: 1.9263181731025818
Validation loss: 2.6142833089644917

Epoch: 5| Step: 1
Training loss: 1.7325453171300957
Validation loss: 2.6165656139308675

Epoch: 5| Step: 2
Training loss: 2.59342255880959
Validation loss: 2.629090106749676

Epoch: 5| Step: 3
Training loss: 1.5129042912660569
Validation loss: 2.6636450636572864

Epoch: 5| Step: 4
Training loss: 2.029089850108174
Validation loss: 2.6039005135329383

Epoch: 5| Step: 5
Training loss: 1.9641588962785883
Validation loss: 2.5812764525240595

Epoch: 5| Step: 6
Training loss: 1.9609223019440303
Validation loss: 2.6117378919827923

Epoch: 5| Step: 7
Training loss: 1.712068993564148
Validation loss: 2.624807427877838

Epoch: 5| Step: 8
Training loss: 1.5266783062242684
Validation loss: 2.6316232328245346

Epoch: 5| Step: 9
Training loss: 1.8095187958549892
Validation loss: 2.64394490587721

Epoch: 5| Step: 10
Training loss: 2.448133310241073
Validation loss: 2.6378265277879036

Epoch: 418| Step: 0
Training loss: 1.76666128079775
Validation loss: 2.6119163958027793

Epoch: 5| Step: 1
Training loss: 2.0584273153411865
Validation loss: 2.590731689547315

Epoch: 5| Step: 2
Training loss: 1.4122852938700943
Validation loss: 2.609282810959513

Epoch: 5| Step: 3
Training loss: 1.8778412590294098
Validation loss: 2.645926094964467

Epoch: 5| Step: 4
Training loss: 1.8675723776522433
Validation loss: 2.630725641995547

Epoch: 5| Step: 5
Training loss: 1.9471837125057827
Validation loss: 2.622444085341401

Epoch: 5| Step: 6
Training loss: 2.1398539024465943
Validation loss: 2.6674880472720366

Epoch: 5| Step: 7
Training loss: 2.1065253329651825
Validation loss: 2.6449451294432187

Epoch: 5| Step: 8
Training loss: 1.5203881679103617
Validation loss: 2.6449324456709085

Epoch: 5| Step: 9
Training loss: 1.9417944660068227
Validation loss: 2.6546622910053146

Epoch: 5| Step: 10
Training loss: 2.3311354867254503
Validation loss: 2.641020133948383

Epoch: 419| Step: 0
Training loss: 2.107265406501687
Validation loss: 2.6383627224676

Epoch: 5| Step: 1
Training loss: 1.4734049950227228
Validation loss: 2.589868094062391

Epoch: 5| Step: 2
Training loss: 2.3594200685756572
Validation loss: 2.6672422463404497

Epoch: 5| Step: 3
Training loss: 1.9731433229317632
Validation loss: 2.6239533698826287

Epoch: 5| Step: 4
Training loss: 1.6194514400766569
Validation loss: 2.649014192045885

Epoch: 5| Step: 5
Training loss: 1.390870490533014
Validation loss: 2.647361151153209

Epoch: 5| Step: 6
Training loss: 2.2793703042879683
Validation loss: 2.6486126622214154

Epoch: 5| Step: 7
Training loss: 1.377256665692668
Validation loss: 2.645237716504386

Epoch: 5| Step: 8
Training loss: 2.1672545760266257
Validation loss: 2.707807201715017

Epoch: 5| Step: 9
Training loss: 2.1717347024295615
Validation loss: 2.642502550900851

Epoch: 5| Step: 10
Training loss: 1.9375612802966478
Validation loss: 2.6299306592366984

Epoch: 420| Step: 0
Training loss: 1.2724599538171322
Validation loss: 2.680682209091768

Epoch: 5| Step: 1
Training loss: 1.8329909033749918
Validation loss: 2.656729994660972

Epoch: 5| Step: 2
Training loss: 2.1927230604920056
Validation loss: 2.693746189240075

Epoch: 5| Step: 3
Training loss: 2.101864704398383
Validation loss: 2.6139111682960516

Epoch: 5| Step: 4
Training loss: 2.040013818507048
Validation loss: 2.634677428873659

Epoch: 5| Step: 5
Training loss: 1.9629090872887969
Validation loss: 2.596784528216076

Epoch: 5| Step: 6
Training loss: 2.1096234210632785
Validation loss: 2.603994948765572

Epoch: 5| Step: 7
Training loss: 1.6014434025839588
Validation loss: 2.6308023992722744

Epoch: 5| Step: 8
Training loss: 1.5880535272085576
Validation loss: 2.5979180677076146

Epoch: 5| Step: 9
Training loss: 1.9191242784906126
Validation loss: 2.6079578915025485

Epoch: 5| Step: 10
Training loss: 2.4562238813181243
Validation loss: 2.6209327275766814

Epoch: 421| Step: 0
Training loss: 2.0207704619495246
Validation loss: 2.6313955387034906

Epoch: 5| Step: 1
Training loss: 2.210460490068872
Validation loss: 2.630819760390263

Epoch: 5| Step: 2
Training loss: 2.0960238052283042
Validation loss: 2.5956524927386577

Epoch: 5| Step: 3
Training loss: 1.517235598209333
Validation loss: 2.5771387157056234

Epoch: 5| Step: 4
Training loss: 2.110581568620434
Validation loss: 2.553619306951684

Epoch: 5| Step: 5
Training loss: 1.6361230025464681
Validation loss: 2.6468924767581328

Epoch: 5| Step: 6
Training loss: 1.7310380881717813
Validation loss: 2.658579130095979

Epoch: 5| Step: 7
Training loss: 2.1477425855904473
Validation loss: 2.5907773219249273

Epoch: 5| Step: 8
Training loss: 1.6346838781411126
Validation loss: 2.6403735184823574

Epoch: 5| Step: 9
Training loss: 1.5045983245505614
Validation loss: 2.655962301715735

Epoch: 5| Step: 10
Training loss: 2.291683012008174
Validation loss: 2.635341837939877

Epoch: 422| Step: 0
Training loss: 1.8050551267115167
Validation loss: 2.651206737017443

Epoch: 5| Step: 1
Training loss: 1.99873944134813
Validation loss: 2.712327168387634

Epoch: 5| Step: 2
Training loss: 1.7630172646813687
Validation loss: 2.684275152521262

Epoch: 5| Step: 3
Training loss: 1.6457962643597528
Validation loss: 2.6464790616933604

Epoch: 5| Step: 4
Training loss: 2.3388162181293892
Validation loss: 2.6707571469325724

Epoch: 5| Step: 5
Training loss: 1.29308482222461
Validation loss: 2.6442217199238267

Epoch: 5| Step: 6
Training loss: 1.959001717913791
Validation loss: 2.6449888679274323

Epoch: 5| Step: 7
Training loss: 2.2467822271938878
Validation loss: 2.6148141604556683

Epoch: 5| Step: 8
Training loss: 2.272940564984198
Validation loss: 2.6529271168711555

Epoch: 5| Step: 9
Training loss: 1.9637039549229298
Validation loss: 2.6219926220193783

Epoch: 5| Step: 10
Training loss: 1.5273176810535005
Validation loss: 2.6735988012750584

Epoch: 423| Step: 0
Training loss: 2.0560785378621658
Validation loss: 2.657141100860205

Epoch: 5| Step: 1
Training loss: 1.8281204353992826
Validation loss: 2.580680420465477

Epoch: 5| Step: 2
Training loss: 2.423087720881846
Validation loss: 2.580391968495289

Epoch: 5| Step: 3
Training loss: 2.113706535375237
Validation loss: 2.606598762774064

Epoch: 5| Step: 4
Training loss: 2.056831314796047
Validation loss: 2.597052346749061

Epoch: 5| Step: 5
Training loss: 1.5690556141106404
Validation loss: 2.6310027750358524

Epoch: 5| Step: 6
Training loss: 1.8568394145810638
Validation loss: 2.683065275908481

Epoch: 5| Step: 7
Training loss: 1.1739179986198016
Validation loss: 2.599075152657206

Epoch: 5| Step: 8
Training loss: 2.177639891623294
Validation loss: 2.609791755369556

Epoch: 5| Step: 9
Training loss: 1.8710264699542685
Validation loss: 2.655911192739533

Epoch: 5| Step: 10
Training loss: 1.9731526269631
Validation loss: 2.617184647577085

Epoch: 424| Step: 0
Training loss: 1.4687296277520399
Validation loss: 2.5827077607001008

Epoch: 5| Step: 1
Training loss: 1.5815777163856126
Validation loss: 2.6173249513631056

Epoch: 5| Step: 2
Training loss: 2.0694236142719538
Validation loss: 2.6168920774803968

Epoch: 5| Step: 3
Training loss: 2.0582775473917914
Validation loss: 2.584925330376374

Epoch: 5| Step: 4
Training loss: 1.97527829394531
Validation loss: 2.617192873752583

Epoch: 5| Step: 5
Training loss: 2.103361813049638
Validation loss: 2.687936887074382

Epoch: 5| Step: 6
Training loss: 2.1410395088666236
Validation loss: 2.720809487454408

Epoch: 5| Step: 7
Training loss: 2.09773308242088
Validation loss: 2.717019659779254

Epoch: 5| Step: 8
Training loss: 1.8659647365480334
Validation loss: 2.6333081349228658

Epoch: 5| Step: 9
Training loss: 2.1375310215176855
Validation loss: 2.6531009014125195

Epoch: 5| Step: 10
Training loss: 1.420173213495222
Validation loss: 2.6548586855262326

Epoch: 425| Step: 0
Training loss: 1.6665222900163497
Validation loss: 2.6667612386541015

Epoch: 5| Step: 1
Training loss: 2.1365533796123852
Validation loss: 2.659870957771084

Epoch: 5| Step: 2
Training loss: 1.6500693104376092
Validation loss: 2.604411568888043

Epoch: 5| Step: 3
Training loss: 2.1291588869593476
Validation loss: 2.6380352245856176

Epoch: 5| Step: 4
Training loss: 1.956030187962835
Validation loss: 2.6355646524673113

Epoch: 5| Step: 5
Training loss: 1.8844962920822705
Validation loss: 2.61272199405569

Epoch: 5| Step: 6
Training loss: 2.103662172275933
Validation loss: 2.6247311457839118

Epoch: 5| Step: 7
Training loss: 1.6667595440099383
Validation loss: 2.5872502881042463

Epoch: 5| Step: 8
Training loss: 1.5695139054687726
Validation loss: 2.651812620306184

Epoch: 5| Step: 9
Training loss: 2.3146886005607574
Validation loss: 2.6274151920042463

Epoch: 5| Step: 10
Training loss: 1.4688312426884447
Validation loss: 2.6247784530349385

Epoch: 426| Step: 0
Training loss: 2.0075301034838913
Validation loss: 2.6040573143098387

Epoch: 5| Step: 1
Training loss: 1.7991245949110684
Validation loss: 2.607482146981066

Epoch: 5| Step: 2
Training loss: 1.9472961117300658
Validation loss: 2.6239925986778236

Epoch: 5| Step: 3
Training loss: 1.6518882321979882
Validation loss: 2.651338870343125

Epoch: 5| Step: 4
Training loss: 1.9563667555022248
Validation loss: 2.5748241664397966

Epoch: 5| Step: 5
Training loss: 1.4628180166237053
Validation loss: 2.5846227278826337

Epoch: 5| Step: 6
Training loss: 1.9175548845018502
Validation loss: 2.6142014624701155

Epoch: 5| Step: 7
Training loss: 2.0440992797659194
Validation loss: 2.6105468753535317

Epoch: 5| Step: 8
Training loss: 2.004048660304293
Validation loss: 2.6573844345075015

Epoch: 5| Step: 9
Training loss: 2.2574477379580276
Validation loss: 2.602146163890312

Epoch: 5| Step: 10
Training loss: 1.686947979530335
Validation loss: 2.6644548374972623

Epoch: 427| Step: 0
Training loss: 2.109231336434419
Validation loss: 2.6167114128449853

Epoch: 5| Step: 1
Training loss: 2.1181093580850865
Validation loss: 2.602993661016237

Epoch: 5| Step: 2
Training loss: 2.218940189430535
Validation loss: 2.633380259896239

Epoch: 5| Step: 3
Training loss: 1.4460614712418796
Validation loss: 2.6243283076033523

Epoch: 5| Step: 4
Training loss: 1.7471362251313605
Validation loss: 2.6379907065725434

Epoch: 5| Step: 5
Training loss: 1.666866465354671
Validation loss: 2.656900027879464

Epoch: 5| Step: 6
Training loss: 1.8196166185963116
Validation loss: 2.615563623667267

Epoch: 5| Step: 7
Training loss: 2.2150002614316078
Validation loss: 2.63100286614195

Epoch: 5| Step: 8
Training loss: 1.6921625362678845
Validation loss: 2.6337076099764514

Epoch: 5| Step: 9
Training loss: 2.3287843116284233
Validation loss: 2.646210235139292

Epoch: 5| Step: 10
Training loss: 1.675504577134135
Validation loss: 2.5996691683814683

Epoch: 428| Step: 0
Training loss: 1.856556334730107
Validation loss: 2.629129292053584

Epoch: 5| Step: 1
Training loss: 1.6153748899732996
Validation loss: 2.6256035385842145

Epoch: 5| Step: 2
Training loss: 1.651793981406243
Validation loss: 2.664379941654048

Epoch: 5| Step: 3
Training loss: 1.361121447949938
Validation loss: 2.6447059448956236

Epoch: 5| Step: 4
Training loss: 1.589282637420174
Validation loss: 2.5833407774734285

Epoch: 5| Step: 5
Training loss: 1.6109417446313654
Validation loss: 2.6068927860568083

Epoch: 5| Step: 6
Training loss: 1.6366294526934262
Validation loss: 2.6369702679905913

Epoch: 5| Step: 7
Training loss: 2.0075092012377427
Validation loss: 2.6130935761214404

Epoch: 5| Step: 8
Training loss: 2.538017363023698
Validation loss: 2.590020147957835

Epoch: 5| Step: 9
Training loss: 1.986098014533457
Validation loss: 2.619997679455658

Epoch: 5| Step: 10
Training loss: 2.407769751246641
Validation loss: 2.693158497419832

Epoch: 429| Step: 0
Training loss: 1.6939304889077416
Validation loss: 2.6330245000721324

Epoch: 5| Step: 1
Training loss: 2.4645204649447217
Validation loss: 2.6378440603750097

Epoch: 5| Step: 2
Training loss: 2.3156197613490845
Validation loss: 2.67164692303755

Epoch: 5| Step: 3
Training loss: 1.7274530107922585
Validation loss: 2.631437489631886

Epoch: 5| Step: 4
Training loss: 1.8141726306799144
Validation loss: 2.6359531077602645

Epoch: 5| Step: 5
Training loss: 1.3945304379073484
Validation loss: 2.6894613207734803

Epoch: 5| Step: 6
Training loss: 2.004411362311338
Validation loss: 2.5773977726302477

Epoch: 5| Step: 7
Training loss: 1.9458018840178808
Validation loss: 2.6082169948301255

Epoch: 5| Step: 8
Training loss: 2.134939174455677
Validation loss: 2.6242838745576487

Epoch: 5| Step: 9
Training loss: 1.2543070975391688
Validation loss: 2.5772925978669186

Epoch: 5| Step: 10
Training loss: 2.0749575920827033
Validation loss: 2.6121905309241416

Epoch: 430| Step: 0
Training loss: 1.8185369648652119
Validation loss: 2.6145024898515636

Epoch: 5| Step: 1
Training loss: 2.137847992527545
Validation loss: 2.632224824243561

Epoch: 5| Step: 2
Training loss: 1.162957710481253
Validation loss: 2.5781320770057157

Epoch: 5| Step: 3
Training loss: 1.822881302263459
Validation loss: 2.663831715795036

Epoch: 5| Step: 4
Training loss: 1.3975505466907896
Validation loss: 2.5981116708062713

Epoch: 5| Step: 5
Training loss: 2.752319744697331
Validation loss: 2.652983760462277

Epoch: 5| Step: 6
Training loss: 1.6159953270315837
Validation loss: 2.637572489488169

Epoch: 5| Step: 7
Training loss: 2.239207982982431
Validation loss: 2.591214186398137

Epoch: 5| Step: 8
Training loss: 1.4455455695206536
Validation loss: 2.5731838881843734

Epoch: 5| Step: 9
Training loss: 2.011806330579928
Validation loss: 2.6269831251804105

Epoch: 5| Step: 10
Training loss: 2.236913772592315
Validation loss: 2.623506021267147

Epoch: 431| Step: 0
Training loss: 1.5422491399472293
Validation loss: 2.6345615380135987

Epoch: 5| Step: 1
Training loss: 2.4381890912348654
Validation loss: 2.569923247476893

Epoch: 5| Step: 2
Training loss: 2.335289396368
Validation loss: 2.6081769001788824

Epoch: 5| Step: 3
Training loss: 2.129852252725226
Validation loss: 2.664312274759294

Epoch: 5| Step: 4
Training loss: 1.979264414197197
Validation loss: 2.5948098166338447

Epoch: 5| Step: 5
Training loss: 1.3967098027459204
Validation loss: 2.64272787368935

Epoch: 5| Step: 6
Training loss: 1.4205712010425402
Validation loss: 2.6109944314733626

Epoch: 5| Step: 7
Training loss: 1.9732033150385817
Validation loss: 2.6239112484930294

Epoch: 5| Step: 8
Training loss: 1.5995108512374394
Validation loss: 2.6007506317574056

Epoch: 5| Step: 9
Training loss: 2.015736894680618
Validation loss: 2.5871789253211013

Epoch: 5| Step: 10
Training loss: 1.6460346227599043
Validation loss: 2.6037986393593164

Epoch: 432| Step: 0
Training loss: 1.9165617527098033
Validation loss: 2.6292334165599724

Epoch: 5| Step: 1
Training loss: 2.2820184536855583
Validation loss: 2.6225504425686648

Epoch: 5| Step: 2
Training loss: 1.7149918129505892
Validation loss: 2.5811188230439823

Epoch: 5| Step: 3
Training loss: 1.831144138440065
Validation loss: 2.6234195070617683

Epoch: 5| Step: 4
Training loss: 1.5530693796433692
Validation loss: 2.6283787557723293

Epoch: 5| Step: 5
Training loss: 1.8577771413661064
Validation loss: 2.648357733184925

Epoch: 5| Step: 6
Training loss: 1.8791872318041924
Validation loss: 2.66307313989553

Epoch: 5| Step: 7
Training loss: 1.870148868143048
Validation loss: 2.6029719359141765

Epoch: 5| Step: 8
Training loss: 2.2391219499233217
Validation loss: 2.5816752927939732

Epoch: 5| Step: 9
Training loss: 1.780322452441683
Validation loss: 2.6048657781213698

Epoch: 5| Step: 10
Training loss: 1.925809910311422
Validation loss: 2.649432465705674

Epoch: 433| Step: 0
Training loss: 2.355993411717165
Validation loss: 2.6227367164211093

Epoch: 5| Step: 1
Training loss: 1.9231626337464607
Validation loss: 2.5656249627888026

Epoch: 5| Step: 2
Training loss: 1.5265850709712687
Validation loss: 2.601453377833627

Epoch: 5| Step: 3
Training loss: 1.8215043255201986
Validation loss: 2.633342687710396

Epoch: 5| Step: 4
Training loss: 2.0209949730268395
Validation loss: 2.6636054053708964

Epoch: 5| Step: 5
Training loss: 1.490073099071375
Validation loss: 2.5943187767537523

Epoch: 5| Step: 6
Training loss: 1.344566407705443
Validation loss: 2.6123975127730112

Epoch: 5| Step: 7
Training loss: 2.3172191203577857
Validation loss: 2.62939978791822

Epoch: 5| Step: 8
Training loss: 1.8042452712111356
Validation loss: 2.6599389149883126

Epoch: 5| Step: 9
Training loss: 2.1233829628829954
Validation loss: 2.677355255519045

Epoch: 5| Step: 10
Training loss: 1.731262989202034
Validation loss: 2.6778052622145228

Epoch: 434| Step: 0
Training loss: 1.7365872132961089
Validation loss: 2.648288207753255

Epoch: 5| Step: 1
Training loss: 1.8725339567112969
Validation loss: 2.612414045294158

Epoch: 5| Step: 2
Training loss: 2.0035022826632773
Validation loss: 2.617439280682844

Epoch: 5| Step: 3
Training loss: 1.5093250495432828
Validation loss: 2.564048519302497

Epoch: 5| Step: 4
Training loss: 2.3072993591961093
Validation loss: 2.618428177701315

Epoch: 5| Step: 5
Training loss: 2.0599306459696245
Validation loss: 2.59616234458381

Epoch: 5| Step: 6
Training loss: 2.6421058610590302
Validation loss: 2.586685538913947

Epoch: 5| Step: 7
Training loss: 1.576961730676528
Validation loss: 2.5977004915994764

Epoch: 5| Step: 8
Training loss: 1.477000257400356
Validation loss: 2.6303215796036805

Epoch: 5| Step: 9
Training loss: 1.7391474590815845
Validation loss: 2.6252960198334643

Epoch: 5| Step: 10
Training loss: 1.3052583462123717
Validation loss: 2.5804148031872174

Epoch: 435| Step: 0
Training loss: 1.9112422173031614
Validation loss: 2.6335506150057575

Epoch: 5| Step: 1
Training loss: 1.3687372633807382
Validation loss: 2.657924954509572

Epoch: 5| Step: 2
Training loss: 1.692415566190731
Validation loss: 2.6173405026615515

Epoch: 5| Step: 3
Training loss: 1.9007221179800171
Validation loss: 2.634628073503364

Epoch: 5| Step: 4
Training loss: 2.1545654572135247
Validation loss: 2.660590781006307

Epoch: 5| Step: 5
Training loss: 1.6980819231676356
Validation loss: 2.6778070228106516

Epoch: 5| Step: 6
Training loss: 1.7455924251042392
Validation loss: 2.63794344092348

Epoch: 5| Step: 7
Training loss: 2.1229537760966712
Validation loss: 2.628572095194341

Epoch: 5| Step: 8
Training loss: 2.3511258857413457
Validation loss: 2.68227640337394

Epoch: 5| Step: 9
Training loss: 1.9131741077459947
Validation loss: 2.6534084256659716

Epoch: 5| Step: 10
Training loss: 1.6872150745742178
Validation loss: 2.670374588802661

Epoch: 436| Step: 0
Training loss: 1.9134235171863614
Validation loss: 2.6223469182675747

Epoch: 5| Step: 1
Training loss: 1.8472716755887904
Validation loss: 2.610560520652863

Epoch: 5| Step: 2
Training loss: 1.8637537966816824
Validation loss: 2.5795562897801316

Epoch: 5| Step: 3
Training loss: 1.3366450170696424
Validation loss: 2.6713903736377826

Epoch: 5| Step: 4
Training loss: 1.9843253182026588
Validation loss: 2.6571412504060032

Epoch: 5| Step: 5
Training loss: 2.4028388280836355
Validation loss: 2.66205657739786

Epoch: 5| Step: 6
Training loss: 1.9081533341564094
Validation loss: 2.587483864360852

Epoch: 5| Step: 7
Training loss: 1.7623532795540615
Validation loss: 2.6017122731517555

Epoch: 5| Step: 8
Training loss: 2.0485406752149817
Validation loss: 2.640760660615658

Epoch: 5| Step: 9
Training loss: 1.593787772535116
Validation loss: 2.6060251947126183

Epoch: 5| Step: 10
Training loss: 1.8784064185211569
Validation loss: 2.6663138735602105

Epoch: 437| Step: 0
Training loss: 1.7259137069551278
Validation loss: 2.63081764482684

Epoch: 5| Step: 1
Training loss: 2.6023070040478795
Validation loss: 2.6820047319250326

Epoch: 5| Step: 2
Training loss: 2.0015967670637167
Validation loss: 2.616338951239773

Epoch: 5| Step: 3
Training loss: 1.5823499570468482
Validation loss: 2.6131021683616793

Epoch: 5| Step: 4
Training loss: 2.0914284660404845
Validation loss: 2.6203173344842856

Epoch: 5| Step: 5
Training loss: 1.548398433311811
Validation loss: 2.619318272962657

Epoch: 5| Step: 6
Training loss: 1.8610917828949574
Validation loss: 2.577810131644828

Epoch: 5| Step: 7
Training loss: 1.3018773132098558
Validation loss: 2.691296831801863

Epoch: 5| Step: 8
Training loss: 1.6302769883134178
Validation loss: 2.646127959740664

Epoch: 5| Step: 9
Training loss: 2.2104433403838613
Validation loss: 2.678599298061662

Epoch: 5| Step: 10
Training loss: 1.513619186961039
Validation loss: 2.626074655454682

Epoch: 438| Step: 0
Training loss: 1.7851919091333859
Validation loss: 2.6583230506167563

Epoch: 5| Step: 1
Training loss: 1.4880015994083873
Validation loss: 2.639398407298776

Epoch: 5| Step: 2
Training loss: 1.7083695182999838
Validation loss: 2.6656954545159315

Epoch: 5| Step: 3
Training loss: 2.3007565871051874
Validation loss: 2.5799126963539667

Epoch: 5| Step: 4
Training loss: 2.4013366076743456
Validation loss: 2.646271144645616

Epoch: 5| Step: 5
Training loss: 1.6569775117166547
Validation loss: 2.6468735929235194

Epoch: 5| Step: 6
Training loss: 1.7502772247895313
Validation loss: 2.6735583365450983

Epoch: 5| Step: 7
Training loss: 1.6532471984811856
Validation loss: 2.6052427730585017

Epoch: 5| Step: 8
Training loss: 1.7298813763780803
Validation loss: 2.6022915678198735

Epoch: 5| Step: 9
Training loss: 1.496821054908121
Validation loss: 2.594352421913762

Epoch: 5| Step: 10
Training loss: 1.9425116909072964
Validation loss: 2.6056338843650693

Epoch: 439| Step: 0
Training loss: 1.9316122980615398
Validation loss: 2.58402301805724

Epoch: 5| Step: 1
Training loss: 2.3092781511164118
Validation loss: 2.6988018745600972

Epoch: 5| Step: 2
Training loss: 2.0450323998605726
Validation loss: 2.6821370598861467

Epoch: 5| Step: 3
Training loss: 2.042704752974523
Validation loss: 2.609462079064031

Epoch: 5| Step: 4
Training loss: 1.7328412259114045
Validation loss: 2.6292377345764555

Epoch: 5| Step: 5
Training loss: 1.2532329712583465
Validation loss: 2.629347155437412

Epoch: 5| Step: 6
Training loss: 1.6125588635486843
Validation loss: 2.5488662731330303

Epoch: 5| Step: 7
Training loss: 1.6274600115198128
Validation loss: 2.586769306547092

Epoch: 5| Step: 8
Training loss: 1.9142371895929275
Validation loss: 2.6015163344736596

Epoch: 5| Step: 9
Training loss: 1.7308695654029955
Validation loss: 2.6328480086633106

Epoch: 5| Step: 10
Training loss: 2.0905059050663866
Validation loss: 2.6541592993022043

Epoch: 440| Step: 0
Training loss: 1.929274480071448
Validation loss: 2.631272948237128

Epoch: 5| Step: 1
Training loss: 1.6189933682282913
Validation loss: 2.646318580275522

Epoch: 5| Step: 2
Training loss: 1.6993955322910845
Validation loss: 2.612866648538643

Epoch: 5| Step: 3
Training loss: 1.9939403526774315
Validation loss: 2.63803031407947

Epoch: 5| Step: 4
Training loss: 2.304701465629032
Validation loss: 2.6044020866712176

Epoch: 5| Step: 5
Training loss: 1.354560701800538
Validation loss: 2.640630844487402

Epoch: 5| Step: 6
Training loss: 1.9269611079315307
Validation loss: 2.677605401659592

Epoch: 5| Step: 7
Training loss: 1.3332046307595236
Validation loss: 2.6633670524537605

Epoch: 5| Step: 8
Training loss: 2.2218591101999725
Validation loss: 2.631170363995917

Epoch: 5| Step: 9
Training loss: 1.8206645314108527
Validation loss: 2.6582722483819414

Epoch: 5| Step: 10
Training loss: 2.081098451337696
Validation loss: 2.7524564516768453

Epoch: 441| Step: 0
Training loss: 1.9681054528562798
Validation loss: 2.6679835208532046

Epoch: 5| Step: 1
Training loss: 1.7250729863302896
Validation loss: 2.6084174740756856

Epoch: 5| Step: 2
Training loss: 1.6062045673520597
Validation loss: 2.613583073917244

Epoch: 5| Step: 3
Training loss: 2.2902185430732636
Validation loss: 2.705470766671053

Epoch: 5| Step: 4
Training loss: 1.9374366872964144
Validation loss: 2.6560402398285787

Epoch: 5| Step: 5
Training loss: 1.7795673252756128
Validation loss: 2.6651837515996037

Epoch: 5| Step: 6
Training loss: 1.9251132139131601
Validation loss: 2.6095800949803585

Epoch: 5| Step: 7
Training loss: 2.0420594389033244
Validation loss: 2.61411897988744

Epoch: 5| Step: 8
Training loss: 1.8102868478789194
Validation loss: 2.633198367526115

Epoch: 5| Step: 9
Training loss: 1.5635761369856995
Validation loss: 2.6334349018689722

Epoch: 5| Step: 10
Training loss: 1.802030845568615
Validation loss: 2.658468280748376

Epoch: 442| Step: 0
Training loss: 2.311245139629067
Validation loss: 2.638807227017701

Epoch: 5| Step: 1
Training loss: 2.0011772029105095
Validation loss: 2.631833511044887

Epoch: 5| Step: 2
Training loss: 2.0407235698640402
Validation loss: 2.5850455653031683

Epoch: 5| Step: 3
Training loss: 1.6043930719633557
Validation loss: 2.5958072022325513

Epoch: 5| Step: 4
Training loss: 1.520103366499308
Validation loss: 2.680452596636839

Epoch: 5| Step: 5
Training loss: 1.7902943730314729
Validation loss: 2.607795223852084

Epoch: 5| Step: 6
Training loss: 1.7910370570640384
Validation loss: 2.64461530444997

Epoch: 5| Step: 7
Training loss: 1.8980372128551792
Validation loss: 2.6515494665192865

Epoch: 5| Step: 8
Training loss: 1.4700765098071902
Validation loss: 2.6592353090513687

Epoch: 5| Step: 9
Training loss: 1.6916747551835842
Validation loss: 2.6382970653266407

Epoch: 5| Step: 10
Training loss: 1.661204933605772
Validation loss: 2.6401942528530444

Epoch: 443| Step: 0
Training loss: 2.4111178812126277
Validation loss: 2.663051361492835

Epoch: 5| Step: 1
Training loss: 1.6949970285845342
Validation loss: 2.6124552127504095

Epoch: 5| Step: 2
Training loss: 1.7180974241661593
Validation loss: 2.5953367114117705

Epoch: 5| Step: 3
Training loss: 2.1381040333129926
Validation loss: 2.6204173494137537

Epoch: 5| Step: 4
Training loss: 1.5076583230052498
Validation loss: 2.569945281384585

Epoch: 5| Step: 5
Training loss: 1.936699117212473
Validation loss: 2.6622215080477973

Epoch: 5| Step: 6
Training loss: 1.8592518998116219
Validation loss: 2.655355651584627

Epoch: 5| Step: 7
Training loss: 1.7982139574413998
Validation loss: 2.611298905361764

Epoch: 5| Step: 8
Training loss: 1.6246617038422992
Validation loss: 2.6523975827959374

Epoch: 5| Step: 9
Training loss: 1.846806594950216
Validation loss: 2.6135965699644084

Epoch: 5| Step: 10
Training loss: 1.2072257468543748
Validation loss: 2.6407913123596303

Epoch: 444| Step: 0
Training loss: 2.1571971637454666
Validation loss: 2.6177331548164218

Epoch: 5| Step: 1
Training loss: 1.4758458896291655
Validation loss: 2.634006035330648

Epoch: 5| Step: 2
Training loss: 1.8226303602359177
Validation loss: 2.6998519614185508

Epoch: 5| Step: 3
Training loss: 1.831215683026399
Validation loss: 2.6572571863893173

Epoch: 5| Step: 4
Training loss: 2.0206848037511542
Validation loss: 2.772732913388081

Epoch: 5| Step: 5
Training loss: 2.2895790532783393
Validation loss: 2.645346694569349

Epoch: 5| Step: 6
Training loss: 2.190816272868924
Validation loss: 2.695302227583861

Epoch: 5| Step: 7
Training loss: 1.7792651176759104
Validation loss: 2.6458336466223122

Epoch: 5| Step: 8
Training loss: 1.568924931351422
Validation loss: 2.6859023717694765

Epoch: 5| Step: 9
Training loss: 1.2943529631296622
Validation loss: 2.6646544230995475

Epoch: 5| Step: 10
Training loss: 1.3776188965594638
Validation loss: 2.666407536662757

Epoch: 445| Step: 0
Training loss: 1.605261499249356
Validation loss: 2.6120757726333306

Epoch: 5| Step: 1
Training loss: 1.760943256900181
Validation loss: 2.6461166757866756

Epoch: 5| Step: 2
Training loss: 2.2952982362598733
Validation loss: 2.681299119181936

Epoch: 5| Step: 3
Training loss: 1.4426040428099685
Validation loss: 2.6071944468750257

Epoch: 5| Step: 4
Training loss: 2.319476044287941
Validation loss: 2.7037980536708854

Epoch: 5| Step: 5
Training loss: 2.0223233605805366
Validation loss: 2.671606208038842

Epoch: 5| Step: 6
Training loss: 1.829423296688048
Validation loss: 2.569878693276936

Epoch: 5| Step: 7
Training loss: 1.4964082153345646
Validation loss: 2.631896110143738

Epoch: 5| Step: 8
Training loss: 1.543435714173814
Validation loss: 2.6257115667789357

Epoch: 5| Step: 9
Training loss: 1.6890306947944327
Validation loss: 2.6569597769002566

Epoch: 5| Step: 10
Training loss: 1.6528709778923205
Validation loss: 2.618478174727759

Epoch: 446| Step: 0
Training loss: 1.5673345160247958
Validation loss: 2.647371824570439

Epoch: 5| Step: 1
Training loss: 1.8188026944946103
Validation loss: 2.5718767498190176

Epoch: 5| Step: 2
Training loss: 1.8833103392331028
Validation loss: 2.653977859281879

Epoch: 5| Step: 3
Training loss: 1.3872849718787714
Validation loss: 2.66204069409489

Epoch: 5| Step: 4
Training loss: 1.5909348851131664
Validation loss: 2.6256978454630593

Epoch: 5| Step: 5
Training loss: 2.239555382369336
Validation loss: 2.6680465276362333

Epoch: 5| Step: 6
Training loss: 1.460924362694734
Validation loss: 2.617261905803253

Epoch: 5| Step: 7
Training loss: 1.781185952089169
Validation loss: 2.622394501197093

Epoch: 5| Step: 8
Training loss: 1.7081621906183289
Validation loss: 2.655551906011447

Epoch: 5| Step: 9
Training loss: 1.6134133642749449
Validation loss: 2.621067214542233

Epoch: 5| Step: 10
Training loss: 2.784582049445481
Validation loss: 2.6341439161459386

Epoch: 447| Step: 0
Training loss: 1.9006671135905335
Validation loss: 2.5899215902091264

Epoch: 5| Step: 1
Training loss: 1.3843184638265418
Validation loss: 2.6162536081360415

Epoch: 5| Step: 2
Training loss: 2.3088754653091708
Validation loss: 2.674712553921493

Epoch: 5| Step: 3
Training loss: 1.4744649854288217
Validation loss: 2.668407514309532

Epoch: 5| Step: 4
Training loss: 2.0267471876377816
Validation loss: 2.678314149809065

Epoch: 5| Step: 5
Training loss: 2.229849654291385
Validation loss: 2.7146464274580295

Epoch: 5| Step: 6
Training loss: 1.8858655181017316
Validation loss: 2.580035576955452

Epoch: 5| Step: 7
Training loss: 1.4538611731492852
Validation loss: 2.62276875664176

Epoch: 5| Step: 8
Training loss: 1.6840840840403188
Validation loss: 2.613113008200616

Epoch: 5| Step: 9
Training loss: 1.9972169705662177
Validation loss: 2.6355044828452785

Epoch: 5| Step: 10
Training loss: 1.724889505689854
Validation loss: 2.6594219872774105

Epoch: 448| Step: 0
Training loss: 1.6664686403251072
Validation loss: 2.7197032563753423

Epoch: 5| Step: 1
Training loss: 1.915983582830475
Validation loss: 2.6421225802801165

Epoch: 5| Step: 2
Training loss: 1.802883220574255
Validation loss: 2.642905247641239

Epoch: 5| Step: 3
Training loss: 1.806856841474749
Validation loss: 2.6522243524290663

Epoch: 5| Step: 4
Training loss: 2.2362598925180333
Validation loss: 2.640034289572404

Epoch: 5| Step: 5
Training loss: 2.0390945373590696
Validation loss: 2.7112164806712187

Epoch: 5| Step: 6
Training loss: 1.58121527833474
Validation loss: 2.6037578007481548

Epoch: 5| Step: 7
Training loss: 2.0834221121627587
Validation loss: 2.6271805230204794

Epoch: 5| Step: 8
Training loss: 1.8807421179295296
Validation loss: 2.6484856954004363

Epoch: 5| Step: 9
Training loss: 1.6020527159200448
Validation loss: 2.652039154544184

Epoch: 5| Step: 10
Training loss: 1.8225968725259052
Validation loss: 2.6493439261393883

Epoch: 449| Step: 0
Training loss: 1.563396578094419
Validation loss: 2.666028624838759

Epoch: 5| Step: 1
Training loss: 1.9362278730533113
Validation loss: 2.6390353628661596

Epoch: 5| Step: 2
Training loss: 2.051505638432779
Validation loss: 2.657965922482208

Epoch: 5| Step: 3
Training loss: 1.253501945746684
Validation loss: 2.6178095105815613

Epoch: 5| Step: 4
Training loss: 2.165851720966968
Validation loss: 2.6517615483297443

Epoch: 5| Step: 5
Training loss: 1.8167472929372024
Validation loss: 2.601810319232373

Epoch: 5| Step: 6
Training loss: 1.7541218308663662
Validation loss: 2.6387506249789348

Epoch: 5| Step: 7
Training loss: 2.0700395512142538
Validation loss: 2.6641558602318822

Epoch: 5| Step: 8
Training loss: 1.7288500790923957
Validation loss: 2.6344570728243597

Epoch: 5| Step: 9
Training loss: 1.709772976534201
Validation loss: 2.677898837395532

Epoch: 5| Step: 10
Training loss: 2.407541498161278
Validation loss: 2.61516053105938

Epoch: 450| Step: 0
Training loss: 1.8002540991828782
Validation loss: 2.617546736444568

Epoch: 5| Step: 1
Training loss: 1.37619499817305
Validation loss: 2.6124440541974208

Epoch: 5| Step: 2
Training loss: 1.826088316938632
Validation loss: 2.640177487435233

Epoch: 5| Step: 3
Training loss: 1.6757229170172194
Validation loss: 2.5866103501926676

Epoch: 5| Step: 4
Training loss: 1.9445918943114395
Validation loss: 2.6217675764875272

Epoch: 5| Step: 5
Training loss: 1.5297698827736586
Validation loss: 2.640722497367189

Epoch: 5| Step: 6
Training loss: 2.6861435771752236
Validation loss: 2.63274549747894

Epoch: 5| Step: 7
Training loss: 2.2309394513458427
Validation loss: 2.6082336875246654

Epoch: 5| Step: 8
Training loss: 1.7880691369192971
Validation loss: 2.567844612811443

Epoch: 5| Step: 9
Training loss: 1.637999768467888
Validation loss: 2.613001785137435

Epoch: 5| Step: 10
Training loss: 1.3141428792458028
Validation loss: 2.675004785100448

Epoch: 451| Step: 0
Training loss: 1.9059001413947443
Validation loss: 2.635732160486847

Epoch: 5| Step: 1
Training loss: 1.9420562208741565
Validation loss: 2.6734569255973466

Epoch: 5| Step: 2
Training loss: 1.3252959694581385
Validation loss: 2.639470837889719

Epoch: 5| Step: 3
Training loss: 2.0949339294940335
Validation loss: 2.638909928720647

Epoch: 5| Step: 4
Training loss: 1.4713922636338161
Validation loss: 2.68521137952807

Epoch: 5| Step: 5
Training loss: 1.9591923581408512
Validation loss: 2.575534837730471

Epoch: 5| Step: 6
Training loss: 1.9733423229712985
Validation loss: 2.638167315520275

Epoch: 5| Step: 7
Training loss: 1.9846636344473043
Validation loss: 2.6173030577365157

Epoch: 5| Step: 8
Training loss: 1.469519393362007
Validation loss: 2.657171748889679

Epoch: 5| Step: 9
Training loss: 1.8919306888707865
Validation loss: 2.636528426228516

Epoch: 5| Step: 10
Training loss: 1.9067964864875715
Validation loss: 2.6471230051970256

Epoch: 452| Step: 0
Training loss: 1.6397006382678474
Validation loss: 2.656567613793644

Epoch: 5| Step: 1
Training loss: 1.7199765770448403
Validation loss: 2.663231870509283

Epoch: 5| Step: 2
Training loss: 1.721208928878004
Validation loss: 2.687568965102353

Epoch: 5| Step: 3
Training loss: 1.714459838993105
Validation loss: 2.628854894892978

Epoch: 5| Step: 4
Training loss: 1.5580954460220962
Validation loss: 2.6571034266286118

Epoch: 5| Step: 5
Training loss: 2.0025225466865018
Validation loss: 2.6838324328825

Epoch: 5| Step: 6
Training loss: 1.8219353641304996
Validation loss: 2.65440947087772

Epoch: 5| Step: 7
Training loss: 1.4473105152082089
Validation loss: 2.71622492637969

Epoch: 5| Step: 8
Training loss: 1.948398945173817
Validation loss: 2.734894720748809

Epoch: 5| Step: 9
Training loss: 1.8512726890930233
Validation loss: 2.61939286585477

Epoch: 5| Step: 10
Training loss: 2.4647360897582895
Validation loss: 2.603965202824395

Epoch: 453| Step: 0
Training loss: 1.6434788179254038
Validation loss: 2.6952944205214115

Epoch: 5| Step: 1
Training loss: 1.8352952198921393
Validation loss: 2.6798661556701537

Epoch: 5| Step: 2
Training loss: 1.7073822708092368
Validation loss: 2.6243114808780574

Epoch: 5| Step: 3
Training loss: 2.290317438770642
Validation loss: 2.649313054985628

Epoch: 5| Step: 4
Training loss: 2.4755585858942672
Validation loss: 2.6640110003072643

Epoch: 5| Step: 5
Training loss: 1.6569784469860327
Validation loss: 2.617173154592954

Epoch: 5| Step: 6
Training loss: 1.29478539025199
Validation loss: 2.642159898566138

Epoch: 5| Step: 7
Training loss: 1.0546434746489877
Validation loss: 2.65023885228244

Epoch: 5| Step: 8
Training loss: 1.7358520679070277
Validation loss: 2.6818867743497568

Epoch: 5| Step: 9
Training loss: 1.5380340082999646
Validation loss: 2.6368867787335772

Epoch: 5| Step: 10
Training loss: 2.477337351982928
Validation loss: 2.6199471301922435

Epoch: 454| Step: 0
Training loss: 1.8056866410753714
Validation loss: 2.65166238305438

Epoch: 5| Step: 1
Training loss: 2.3747667900830796
Validation loss: 2.640692979714635

Epoch: 5| Step: 2
Training loss: 1.9951686917835032
Validation loss: 2.6117498751351507

Epoch: 5| Step: 3
Training loss: 1.9315602716872182
Validation loss: 2.655470071620001

Epoch: 5| Step: 4
Training loss: 1.5593001598065725
Validation loss: 2.688460530142075

Epoch: 5| Step: 5
Training loss: 1.760630201522299
Validation loss: 2.5696261852643607

Epoch: 5| Step: 6
Training loss: 1.5124506792586465
Validation loss: 2.6029912002883253

Epoch: 5| Step: 7
Training loss: 1.6396501823993097
Validation loss: 2.6035313149103687

Epoch: 5| Step: 8
Training loss: 2.3202140607406663
Validation loss: 2.6589939737569783

Epoch: 5| Step: 9
Training loss: 1.6430184480603083
Validation loss: 2.6767860254849407

Epoch: 5| Step: 10
Training loss: 1.5178307282529584
Validation loss: 2.6346058098881824

Epoch: 455| Step: 0
Training loss: 2.26408691814305
Validation loss: 2.6434380603595713

Epoch: 5| Step: 1
Training loss: 1.7666605385488114
Validation loss: 2.6589561107722584

Epoch: 5| Step: 2
Training loss: 1.1020422898397664
Validation loss: 2.6135920676931748

Epoch: 5| Step: 3
Training loss: 2.222178644176868
Validation loss: 2.675846555526837

Epoch: 5| Step: 4
Training loss: 1.606279822640447
Validation loss: 2.6608853463951587

Epoch: 5| Step: 5
Training loss: 1.9112355434152903
Validation loss: 2.674938423000792

Epoch: 5| Step: 6
Training loss: 1.3145740107685866
Validation loss: 2.6815613812303156

Epoch: 5| Step: 7
Training loss: 2.4556535457700517
Validation loss: 2.7114285350039884

Epoch: 5| Step: 8
Training loss: 0.8213943250696478
Validation loss: 2.651542330217576

Epoch: 5| Step: 9
Training loss: 2.2295850081970086
Validation loss: 2.656599392674174

Epoch: 5| Step: 10
Training loss: 1.4823798976578928
Validation loss: 2.6385465294801915

Epoch: 456| Step: 0
Training loss: 2.2717927311794845
Validation loss: 2.6003224185968112

Epoch: 5| Step: 1
Training loss: 2.0862507674191244
Validation loss: 2.6223650666139067

Epoch: 5| Step: 2
Training loss: 1.6357780429838895
Validation loss: 2.665390919524798

Epoch: 5| Step: 3
Training loss: 1.7242909674305404
Validation loss: 2.636626305518641

Epoch: 5| Step: 4
Training loss: 1.373307530282645
Validation loss: 2.6454971412528834

Epoch: 5| Step: 5
Training loss: 1.5202168386537789
Validation loss: 2.6665409261017334

Epoch: 5| Step: 6
Training loss: 2.488973141088129
Validation loss: 2.5875865591871645

Epoch: 5| Step: 7
Training loss: 1.386396730670387
Validation loss: 2.7139136428463426

Epoch: 5| Step: 8
Training loss: 1.6231286938331122
Validation loss: 2.6794399325418743

Epoch: 5| Step: 9
Training loss: 1.5117655902082006
Validation loss: 2.625206134005777

Epoch: 5| Step: 10
Training loss: 1.8231254094816158
Validation loss: 2.6462933062437304

Epoch: 457| Step: 0
Training loss: 1.6503082074234303
Validation loss: 2.652659360314307

Epoch: 5| Step: 1
Training loss: 1.1723399956363565
Validation loss: 2.6364376145205015

Epoch: 5| Step: 2
Training loss: 2.382788986340182
Validation loss: 2.6499627238612375

Epoch: 5| Step: 3
Training loss: 1.8032365390915628
Validation loss: 2.6813615071234467

Epoch: 5| Step: 4
Training loss: 2.2760421671455817
Validation loss: 2.692764686900358

Epoch: 5| Step: 5
Training loss: 1.1288577798647865
Validation loss: 2.6916062582720883

Epoch: 5| Step: 6
Training loss: 1.7310693529539272
Validation loss: 2.611933273916491

Epoch: 5| Step: 7
Training loss: 1.7515348107278736
Validation loss: 2.7364871444755283

Epoch: 5| Step: 8
Training loss: 1.8558262530795449
Validation loss: 2.6932512593117828

Epoch: 5| Step: 9
Training loss: 1.8902076701961892
Validation loss: 2.6717681815438676

Epoch: 5| Step: 10
Training loss: 1.9174028793268776
Validation loss: 2.651026765959704

Epoch: 458| Step: 0
Training loss: 1.3155443216626763
Validation loss: 2.699065216994333

Epoch: 5| Step: 1
Training loss: 1.5258921874422005
Validation loss: 2.6831346827218083

Epoch: 5| Step: 2
Training loss: 2.1278668307246336
Validation loss: 2.6374046541340133

Epoch: 5| Step: 3
Training loss: 1.5361416592740325
Validation loss: 2.619575525985079

Epoch: 5| Step: 4
Training loss: 2.3347602863324126
Validation loss: 2.617308505693462

Epoch: 5| Step: 5
Training loss: 1.7481719414495067
Validation loss: 2.660391789614409

Epoch: 5| Step: 6
Training loss: 1.9291057250227188
Validation loss: 2.573271933918756

Epoch: 5| Step: 7
Training loss: 1.16235395149875
Validation loss: 2.6390216287396195

Epoch: 5| Step: 8
Training loss: 2.107043751194028
Validation loss: 2.6041268629088026

Epoch: 5| Step: 9
Training loss: 1.4680053771333674
Validation loss: 2.612018276273463

Epoch: 5| Step: 10
Training loss: 2.0342871627947883
Validation loss: 2.67462637715503

Epoch: 459| Step: 0
Training loss: 1.472933553394743
Validation loss: 2.644800461430152

Epoch: 5| Step: 1
Training loss: 1.5921016471559561
Validation loss: 2.73259669640229

Epoch: 5| Step: 2
Training loss: 2.18353893777639
Validation loss: 2.6686530085772944

Epoch: 5| Step: 3
Training loss: 1.8615757716411656
Validation loss: 2.6585258872679414

Epoch: 5| Step: 4
Training loss: 1.5121176338807896
Validation loss: 2.561061294181256

Epoch: 5| Step: 5
Training loss: 1.8421304993227363
Validation loss: 2.618186250510094

Epoch: 5| Step: 6
Training loss: 2.1619138551712456
Validation loss: 2.654902047285276

Epoch: 5| Step: 7
Training loss: 1.5279459436900866
Validation loss: 2.6806389267570814

Epoch: 5| Step: 8
Training loss: 2.033488873749819
Validation loss: 2.6699373100599098

Epoch: 5| Step: 9
Training loss: 1.4131996515018261
Validation loss: 2.622685497586789

Epoch: 5| Step: 10
Training loss: 1.8456350485543973
Validation loss: 2.6415348163961476

Epoch: 460| Step: 0
Training loss: 2.009500113429104
Validation loss: 2.6080907115229173

Epoch: 5| Step: 1
Training loss: 1.5102902940522227
Validation loss: 2.660213557841198

Epoch: 5| Step: 2
Training loss: 2.3664604052357054
Validation loss: 2.661155362838508

Epoch: 5| Step: 3
Training loss: 1.8320763425828848
Validation loss: 2.678695844894766

Epoch: 5| Step: 4
Training loss: 1.7260574361586873
Validation loss: 2.6125430772074383

Epoch: 5| Step: 5
Training loss: 1.5521129204236306
Validation loss: 2.6800243517908484

Epoch: 5| Step: 6
Training loss: 1.8908664139394882
Validation loss: 2.6701390628119537

Epoch: 5| Step: 7
Training loss: 1.850641142089693
Validation loss: 2.650640111585542

Epoch: 5| Step: 8
Training loss: 1.7011472084893688
Validation loss: 2.645501922581605

Epoch: 5| Step: 9
Training loss: 1.1275912218767776
Validation loss: 2.6376116605496196

Epoch: 5| Step: 10
Training loss: 2.004727022609478
Validation loss: 2.6941054161931834

Epoch: 461| Step: 0
Training loss: 1.7628676903464997
Validation loss: 2.5767669471850065

Epoch: 5| Step: 1
Training loss: 1.2922816453285122
Validation loss: 2.6533043435655643

Epoch: 5| Step: 2
Training loss: 1.5746390489201503
Validation loss: 2.720481452285505

Epoch: 5| Step: 3
Training loss: 1.9314565850537542
Validation loss: 2.6665536186138894

Epoch: 5| Step: 4
Training loss: 1.6316629405980854
Validation loss: 2.6681788474144974

Epoch: 5| Step: 5
Training loss: 1.7042051617192664
Validation loss: 2.611014850230887

Epoch: 5| Step: 6
Training loss: 2.001614157660017
Validation loss: 2.632537014322032

Epoch: 5| Step: 7
Training loss: 1.7473607597488514
Validation loss: 2.634630784435965

Epoch: 5| Step: 8
Training loss: 2.2724000851328143
Validation loss: 2.6648582160525724

Epoch: 5| Step: 9
Training loss: 1.665142085224623
Validation loss: 2.5796647272825126

Epoch: 5| Step: 10
Training loss: 2.224393088901473
Validation loss: 2.643282334836453

Epoch: 462| Step: 0
Training loss: 1.3942601557500778
Validation loss: 2.598789699287734

Epoch: 5| Step: 1
Training loss: 2.1346260157774446
Validation loss: 2.6503329296791978

Epoch: 5| Step: 2
Training loss: 1.8810701024419327
Validation loss: 2.600891785598131

Epoch: 5| Step: 3
Training loss: 2.502764699010045
Validation loss: 2.6359507590102527

Epoch: 5| Step: 4
Training loss: 1.4563659294382256
Validation loss: 2.701430586869597

Epoch: 5| Step: 5
Training loss: 1.670039943514331
Validation loss: 2.6202949903682913

Epoch: 5| Step: 6
Training loss: 1.454229611817026
Validation loss: 2.6864493954815156

Epoch: 5| Step: 7
Training loss: 1.8172127194675916
Validation loss: 2.6132115614549685

Epoch: 5| Step: 8
Training loss: 2.332091262019655
Validation loss: 2.688576090093371

Epoch: 5| Step: 9
Training loss: 1.2836825376649004
Validation loss: 2.7136128327911457

Epoch: 5| Step: 10
Training loss: 1.6352993220449472
Validation loss: 2.664937637122128

Epoch: 463| Step: 0
Training loss: 1.6254953949744835
Validation loss: 2.6590632453004885

Epoch: 5| Step: 1
Training loss: 1.6194239093633802
Validation loss: 2.6504991348819558

Epoch: 5| Step: 2
Training loss: 1.850880944081774
Validation loss: 2.664068213198595

Epoch: 5| Step: 3
Training loss: 2.153880047007487
Validation loss: 2.6732200523722227

Epoch: 5| Step: 4
Training loss: 2.2537765597842894
Validation loss: 2.6345071967419793

Epoch: 5| Step: 5
Training loss: 1.515905138062326
Validation loss: 2.706453246001096

Epoch: 5| Step: 6
Training loss: 1.3911211650246067
Validation loss: 2.66108444731377

Epoch: 5| Step: 7
Training loss: 1.4062969199936166
Validation loss: 2.642491004074719

Epoch: 5| Step: 8
Training loss: 1.6394028243955134
Validation loss: 2.607908311603112

Epoch: 5| Step: 9
Training loss: 2.2596177009033718
Validation loss: 2.642237492832321

Epoch: 5| Step: 10
Training loss: 2.0631518634294146
Validation loss: 2.695905836800611

Epoch: 464| Step: 0
Training loss: 1.7430684552300062
Validation loss: 2.5920768151576636

Epoch: 5| Step: 1
Training loss: 1.7736658293825978
Validation loss: 2.6663448603585502

Epoch: 5| Step: 2
Training loss: 1.6094619579340375
Validation loss: 2.6700089093272785

Epoch: 5| Step: 3
Training loss: 1.7859592760148526
Validation loss: 2.6532511953802373

Epoch: 5| Step: 4
Training loss: 1.6284924903300602
Validation loss: 2.6304323188558523

Epoch: 5| Step: 5
Training loss: 1.4913133387452344
Validation loss: 2.599896810568744

Epoch: 5| Step: 6
Training loss: 1.6914105492376437
Validation loss: 2.6823438808776277

Epoch: 5| Step: 7
Training loss: 1.6898926620706027
Validation loss: 2.6265392663795115

Epoch: 5| Step: 8
Training loss: 1.9901777115262371
Validation loss: 2.6626822134320527

Epoch: 5| Step: 9
Training loss: 1.5442359066938125
Validation loss: 2.583471628616311

Epoch: 5| Step: 10
Training loss: 2.629785897855715
Validation loss: 2.6768452011064516

Epoch: 465| Step: 0
Training loss: 1.9737889427706392
Validation loss: 2.652472902028712

Epoch: 5| Step: 1
Training loss: 2.409296658401284
Validation loss: 2.685530150241177

Epoch: 5| Step: 2
Training loss: 1.8797259852400807
Validation loss: 2.6881082623411405

Epoch: 5| Step: 3
Training loss: 1.360362297284121
Validation loss: 2.6365483146952062

Epoch: 5| Step: 4
Training loss: 2.0359073944090924
Validation loss: 2.641769274356391

Epoch: 5| Step: 5
Training loss: 1.7255813779916418
Validation loss: 2.6596463615101427

Epoch: 5| Step: 6
Training loss: 1.7390255138374795
Validation loss: 2.606268382563998

Epoch: 5| Step: 7
Training loss: 1.8244023690126139
Validation loss: 2.603169200891117

Epoch: 5| Step: 8
Training loss: 1.246007934294003
Validation loss: 2.667492539305751

Epoch: 5| Step: 9
Training loss: 1.6385207714665144
Validation loss: 2.633002066139018

Epoch: 5| Step: 10
Training loss: 1.7738359986655314
Validation loss: 2.6673034742717325

Epoch: 466| Step: 0
Training loss: 1.438310063211824
Validation loss: 2.6361509243271035

Epoch: 5| Step: 1
Training loss: 1.8522183829961076
Validation loss: 2.620471156195242

Epoch: 5| Step: 2
Training loss: 1.0946260486095494
Validation loss: 2.647806842519875

Epoch: 5| Step: 3
Training loss: 1.5004950342296381
Validation loss: 2.6343481376678852

Epoch: 5| Step: 4
Training loss: 1.3768650324352891
Validation loss: 2.5987602459417305

Epoch: 5| Step: 5
Training loss: 1.7322852802292696
Validation loss: 2.6861272216670167

Epoch: 5| Step: 6
Training loss: 1.4016374174612583
Validation loss: 2.6720995633238673

Epoch: 5| Step: 7
Training loss: 1.8591860506878777
Validation loss: 2.668692408372065

Epoch: 5| Step: 8
Training loss: 2.04393924688541
Validation loss: 2.721076415055204

Epoch: 5| Step: 9
Training loss: 2.428328253488283
Validation loss: 2.646265782472007

Epoch: 5| Step: 10
Training loss: 2.344461968684376
Validation loss: 2.612778423090683

Epoch: 467| Step: 0
Training loss: 1.4265698068187223
Validation loss: 2.671643010854981

Epoch: 5| Step: 1
Training loss: 1.9233931461181568
Validation loss: 2.63806082408298

Epoch: 5| Step: 2
Training loss: 1.7693719855376842
Validation loss: 2.681524892362845

Epoch: 5| Step: 3
Training loss: 1.5428486065022904
Validation loss: 2.632835146845326

Epoch: 5| Step: 4
Training loss: 1.306998803921118
Validation loss: 2.6909925065790556

Epoch: 5| Step: 5
Training loss: 1.6845992552993725
Validation loss: 2.641823239660181

Epoch: 5| Step: 6
Training loss: 1.9864812771279479
Validation loss: 2.695269440242632

Epoch: 5| Step: 7
Training loss: 1.5579235959398434
Validation loss: 2.6572344104961956

Epoch: 5| Step: 8
Training loss: 1.4551190056914545
Validation loss: 2.5914521894789893

Epoch: 5| Step: 9
Training loss: 1.9885135057818948
Validation loss: 2.6458813768953084

Epoch: 5| Step: 10
Training loss: 2.5486720011751167
Validation loss: 2.6880664023489373

Epoch: 468| Step: 0
Training loss: 1.892013040275879
Validation loss: 2.6520060213178676

Epoch: 5| Step: 1
Training loss: 1.7601905165857317
Validation loss: 2.5711074793088633

Epoch: 5| Step: 2
Training loss: 1.1619513909157622
Validation loss: 2.630290219106368

Epoch: 5| Step: 3
Training loss: 2.2800984023425905
Validation loss: 2.6574819469478292

Epoch: 5| Step: 4
Training loss: 1.2601157478119247
Validation loss: 2.6185467411413814

Epoch: 5| Step: 5
Training loss: 1.8278533864189004
Validation loss: 2.654525376477918

Epoch: 5| Step: 6
Training loss: 1.6928212367820523
Validation loss: 2.6237540826099006

Epoch: 5| Step: 7
Training loss: 1.6262763952624542
Validation loss: 2.7111132193257714

Epoch: 5| Step: 8
Training loss: 0.8768961320806343
Validation loss: 2.7068714755899395

Epoch: 5| Step: 9
Training loss: 2.3492089340162194
Validation loss: 2.689520755112041

Epoch: 5| Step: 10
Training loss: 1.993048866901701
Validation loss: 2.619037705037648

Epoch: 469| Step: 0
Training loss: 2.129476208466372
Validation loss: 2.6403277664869815

Epoch: 5| Step: 1
Training loss: 1.7466046910659658
Validation loss: 2.5902617079578425

Epoch: 5| Step: 2
Training loss: 1.6205578757087722
Validation loss: 2.6461552960266017

Epoch: 5| Step: 3
Training loss: 1.9757897596677534
Validation loss: 2.680012180320281

Epoch: 5| Step: 4
Training loss: 1.8705307784537255
Validation loss: 2.613047732049284

Epoch: 5| Step: 5
Training loss: 1.5169881609188787
Validation loss: 2.6674680165923137

Epoch: 5| Step: 6
Training loss: 1.8776167729378261
Validation loss: 2.7607277365019436

Epoch: 5| Step: 7
Training loss: 2.0742047268093526
Validation loss: 2.6351853713033666

Epoch: 5| Step: 8
Training loss: 1.5631514907660442
Validation loss: 2.6546419810274187

Epoch: 5| Step: 9
Training loss: 1.8826298288711836
Validation loss: 2.692520609822371

Epoch: 5| Step: 10
Training loss: 1.5676446523648964
Validation loss: 2.6588921114511073

Epoch: 470| Step: 0
Training loss: 2.143749768671407
Validation loss: 2.6686344545250433

Epoch: 5| Step: 1
Training loss: 1.4737949977278926
Validation loss: 2.6755429105372754

Epoch: 5| Step: 2
Training loss: 1.595046693961452
Validation loss: 2.6580702739053472

Epoch: 5| Step: 3
Training loss: 1.797794869527266
Validation loss: 2.6435558628612568

Epoch: 5| Step: 4
Training loss: 1.7224617846143313
Validation loss: 2.662017910495137

Epoch: 5| Step: 5
Training loss: 2.1272339018144115
Validation loss: 2.6774388415562367

Epoch: 5| Step: 6
Training loss: 1.2550666644715576
Validation loss: 2.6773216212053277

Epoch: 5| Step: 7
Training loss: 1.8415454033446899
Validation loss: 2.657580825616392

Epoch: 5| Step: 8
Training loss: 1.8635926056480396
Validation loss: 2.6660024087367873

Epoch: 5| Step: 9
Training loss: 1.5303356009530031
Validation loss: 2.6237761227085956

Epoch: 5| Step: 10
Training loss: 2.1980173410316466
Validation loss: 2.6307030301008725

Epoch: 471| Step: 0
Training loss: 1.2171019635488136
Validation loss: 2.6274363671519914

Epoch: 5| Step: 1
Training loss: 1.5248026673264605
Validation loss: 2.607084040201785

Epoch: 5| Step: 2
Training loss: 2.047375101045806
Validation loss: 2.6441678069644676

Epoch: 5| Step: 3
Training loss: 2.062851962489487
Validation loss: 2.6593770218567445

Epoch: 5| Step: 4
Training loss: 1.5817264216115556
Validation loss: 2.636731945811514

Epoch: 5| Step: 5
Training loss: 1.9364900109988599
Validation loss: 2.625717340479453

Epoch: 5| Step: 6
Training loss: 1.6667765660609835
Validation loss: 2.6796386254123146

Epoch: 5| Step: 7
Training loss: 1.7464471583111443
Validation loss: 2.6545520598743417

Epoch: 5| Step: 8
Training loss: 1.7047654397211873
Validation loss: 2.7070918166457245

Epoch: 5| Step: 9
Training loss: 2.1849915427037727
Validation loss: 2.6004770720768593

Epoch: 5| Step: 10
Training loss: 1.6635521477751485
Validation loss: 2.69658164684392

Epoch: 472| Step: 0
Training loss: 1.7540728313631793
Validation loss: 2.6707571142962157

Epoch: 5| Step: 1
Training loss: 1.969679476809241
Validation loss: 2.6619694111525942

Epoch: 5| Step: 2
Training loss: 1.4627713204438642
Validation loss: 2.6686420379354985

Epoch: 5| Step: 3
Training loss: 2.0008205876175476
Validation loss: 2.6662672763448563

Epoch: 5| Step: 4
Training loss: 1.8242321463180826
Validation loss: 2.6704172464502576

Epoch: 5| Step: 5
Training loss: 1.1713423472082802
Validation loss: 2.6659888462286006

Epoch: 5| Step: 6
Training loss: 1.5320904040940726
Validation loss: 2.6826078909296838

Epoch: 5| Step: 7
Training loss: 1.586483715686726
Validation loss: 2.672276911203163

Epoch: 5| Step: 8
Training loss: 1.7480207558497325
Validation loss: 2.6440327797818766

Epoch: 5| Step: 9
Training loss: 2.3941622227239034
Validation loss: 2.6664177531029782

Epoch: 5| Step: 10
Training loss: 1.4668059774184945
Validation loss: 2.6046011547929795

Epoch: 473| Step: 0
Training loss: 1.6404115083842834
Validation loss: 2.6536452085999502

Epoch: 5| Step: 1
Training loss: 1.2963962820386434
Validation loss: 2.6522268423900575

Epoch: 5| Step: 2
Training loss: 2.0039992877859953
Validation loss: 2.6293844278680965

Epoch: 5| Step: 3
Training loss: 2.0916898470299587
Validation loss: 2.632157355328241

Epoch: 5| Step: 4
Training loss: 1.9493331111163332
Validation loss: 2.6610491882654093

Epoch: 5| Step: 5
Training loss: 1.2986338993641113
Validation loss: 2.692768209474831

Epoch: 5| Step: 6
Training loss: 1.5767878542424079
Validation loss: 2.6303525849590192

Epoch: 5| Step: 7
Training loss: 1.5673475980516531
Validation loss: 2.6380999218128087

Epoch: 5| Step: 8
Training loss: 2.3221089508361192
Validation loss: 2.688580171202934

Epoch: 5| Step: 9
Training loss: 1.7110785160565694
Validation loss: 2.62542573295996

Epoch: 5| Step: 10
Training loss: 1.6395685336629753
Validation loss: 2.7030691311433173

Epoch: 474| Step: 0
Training loss: 1.7274217495675184
Validation loss: 2.6776380194520253

Epoch: 5| Step: 1
Training loss: 1.6087415615236904
Validation loss: 2.5792150942931134

Epoch: 5| Step: 2
Training loss: 1.4637074042946434
Validation loss: 2.65826013354793

Epoch: 5| Step: 3
Training loss: 1.626439117530517
Validation loss: 2.5652085023137277

Epoch: 5| Step: 4
Training loss: 1.630045028485826
Validation loss: 2.656147603927183

Epoch: 5| Step: 5
Training loss: 1.737183299120459
Validation loss: 2.69608935597788

Epoch: 5| Step: 6
Training loss: 1.519178727158414
Validation loss: 2.6769100181147403

Epoch: 5| Step: 7
Training loss: 2.1197976776962597
Validation loss: 2.681108749160461

Epoch: 5| Step: 8
Training loss: 1.619291181202335
Validation loss: 2.679174955810662

Epoch: 5| Step: 9
Training loss: 2.37841581353513
Validation loss: 2.6736574433624445

Epoch: 5| Step: 10
Training loss: 1.9977037838146654
Validation loss: 2.6910456767373767

Epoch: 475| Step: 0
Training loss: 1.497702189632898
Validation loss: 2.6327066342713663

Epoch: 5| Step: 1
Training loss: 1.5119393752018924
Validation loss: 2.655955480839625

Epoch: 5| Step: 2
Training loss: 1.069757415064685
Validation loss: 2.6432572509657355

Epoch: 5| Step: 3
Training loss: 2.2157440239663138
Validation loss: 2.663720536446821

Epoch: 5| Step: 4
Training loss: 1.6786750758558615
Validation loss: 2.6354619050308896

Epoch: 5| Step: 5
Training loss: 2.060913400458509
Validation loss: 2.701143109990704

Epoch: 5| Step: 6
Training loss: 1.792972606247555
Validation loss: 2.6390359865247572

Epoch: 5| Step: 7
Training loss: 1.9133873819344445
Validation loss: 2.681036720558148

Epoch: 5| Step: 8
Training loss: 1.903643530249779
Validation loss: 2.694017897560384

Epoch: 5| Step: 9
Training loss: 1.8944281795819007
Validation loss: 2.680496678665772

Epoch: 5| Step: 10
Training loss: 1.488008809622456
Validation loss: 2.7546013421424402

Epoch: 476| Step: 0
Training loss: 1.8833692685077583
Validation loss: 2.649834829102487

Epoch: 5| Step: 1
Training loss: 1.8862127095373198
Validation loss: 2.66855948769311

Epoch: 5| Step: 2
Training loss: 1.3351694319572633
Validation loss: 2.6880183291222948

Epoch: 5| Step: 3
Training loss: 1.5198943579503228
Validation loss: 2.6129633126109795

Epoch: 5| Step: 4
Training loss: 1.4188707073470368
Validation loss: 2.671783564678015

Epoch: 5| Step: 5
Training loss: 1.6857224038184921
Validation loss: 2.6857269535787656

Epoch: 5| Step: 6
Training loss: 1.2563737495164888
Validation loss: 2.6831592227664802

Epoch: 5| Step: 7
Training loss: 1.4846705092363401
Validation loss: 2.615230687214705

Epoch: 5| Step: 8
Training loss: 1.9772269598428427
Validation loss: 2.6772531811675866

Epoch: 5| Step: 9
Training loss: 1.8188677117182885
Validation loss: 2.6918477697112833

Epoch: 5| Step: 10
Training loss: 2.5637033939821654
Validation loss: 2.660859034336275

Epoch: 477| Step: 0
Training loss: 1.5500491934322396
Validation loss: 2.6528404488791844

Epoch: 5| Step: 1
Training loss: 2.040053671149525
Validation loss: 2.684442559559999

Epoch: 5| Step: 2
Training loss: 1.966719109703462
Validation loss: 2.6956344671377894

Epoch: 5| Step: 3
Training loss: 1.947431520915692
Validation loss: 2.6690406333089975

Epoch: 5| Step: 4
Training loss: 1.857316488491294
Validation loss: 2.638187527855041

Epoch: 5| Step: 5
Training loss: 2.0560133684814677
Validation loss: 2.673995503464945

Epoch: 5| Step: 6
Training loss: 1.5494226611009516
Validation loss: 2.7281076016660837

Epoch: 5| Step: 7
Training loss: 1.170194208866825
Validation loss: 2.690047496875413

Epoch: 5| Step: 8
Training loss: 2.0663763667868174
Validation loss: 2.729480014019334

Epoch: 5| Step: 9
Training loss: 1.7797752432422835
Validation loss: 2.6748667352476043

Epoch: 5| Step: 10
Training loss: 1.558659219920369
Validation loss: 2.54837436404798

Epoch: 478| Step: 0
Training loss: 1.67896954473487
Validation loss: 2.6481731647205367

Epoch: 5| Step: 1
Training loss: 1.3578689826832708
Validation loss: 2.60359852030228

Epoch: 5| Step: 2
Training loss: 1.415709405871116
Validation loss: 2.6539901742974386

Epoch: 5| Step: 3
Training loss: 1.622654689591548
Validation loss: 2.631280806415689

Epoch: 5| Step: 4
Training loss: 2.057855289046224
Validation loss: 2.615440395520948

Epoch: 5| Step: 5
Training loss: 1.9914028642101096
Validation loss: 2.6910356643048727

Epoch: 5| Step: 6
Training loss: 1.158771857721122
Validation loss: 2.660370861356197

Epoch: 5| Step: 7
Training loss: 2.2841279153228546
Validation loss: 2.648795755059851

Epoch: 5| Step: 8
Training loss: 1.7544665556726224
Validation loss: 2.6393795417232417

Epoch: 5| Step: 9
Training loss: 2.2803462080197767
Validation loss: 2.6176361958067176

Epoch: 5| Step: 10
Training loss: 1.6262571900287228
Validation loss: 2.6263301407240625

Epoch: 479| Step: 0
Training loss: 1.6219067109229086
Validation loss: 2.6496293900985632

Epoch: 5| Step: 1
Training loss: 2.050435936329565
Validation loss: 2.5782984640732978

Epoch: 5| Step: 2
Training loss: 1.7482652921985633
Validation loss: 2.610157433289695

Epoch: 5| Step: 3
Training loss: 1.3443888542848266
Validation loss: 2.6028099386531367

Epoch: 5| Step: 4
Training loss: 1.5507544219725624
Validation loss: 2.6181212369546287

Epoch: 5| Step: 5
Training loss: 1.4852971475178158
Validation loss: 2.6540622008767243

Epoch: 5| Step: 6
Training loss: 1.228128830221867
Validation loss: 2.6827298427814763

Epoch: 5| Step: 7
Training loss: 1.6420417118419846
Validation loss: 2.6313185366477585

Epoch: 5| Step: 8
Training loss: 2.5201648004322834
Validation loss: 2.59492380421917

Epoch: 5| Step: 9
Training loss: 2.116117312512745
Validation loss: 2.620020241373066

Epoch: 5| Step: 10
Training loss: 1.6837786862790716
Validation loss: 2.63532748921222

Epoch: 480| Step: 0
Training loss: 1.1942374188018188
Validation loss: 2.679558343213423

Epoch: 5| Step: 1
Training loss: 1.8305620431021288
Validation loss: 2.5684697344925285

Epoch: 5| Step: 2
Training loss: 2.0706468995856517
Validation loss: 2.6391989059709666

Epoch: 5| Step: 3
Training loss: 1.2727334820453475
Validation loss: 2.665478235488122

Epoch: 5| Step: 4
Training loss: 1.5187824826632599
Validation loss: 2.6938981830039124

Epoch: 5| Step: 5
Training loss: 1.3796759340313405
Validation loss: 2.6817746734736634

Epoch: 5| Step: 6
Training loss: 1.8262514474433527
Validation loss: 2.6638391906549383

Epoch: 5| Step: 7
Training loss: 1.393443049000387
Validation loss: 2.6444570831166163

Epoch: 5| Step: 8
Training loss: 1.8673543815575075
Validation loss: 2.6618671965687835

Epoch: 5| Step: 9
Training loss: 1.8750258126071533
Validation loss: 2.6672101530891057

Epoch: 5| Step: 10
Training loss: 2.3173509186464116
Validation loss: 2.699303814930546

Epoch: 481| Step: 0
Training loss: 2.06897493735723
Validation loss: 2.717095727618562

Epoch: 5| Step: 1
Training loss: 1.6641779040226385
Validation loss: 2.67320831887801

Epoch: 5| Step: 2
Training loss: 1.8813753460158968
Validation loss: 2.6002640678429465

Epoch: 5| Step: 3
Training loss: 1.6642706655761013
Validation loss: 2.7034698594491626

Epoch: 5| Step: 4
Training loss: 1.8325301997674397
Validation loss: 2.6895746616228084

Epoch: 5| Step: 5
Training loss: 1.8781324288067383
Validation loss: 2.638895639224901

Epoch: 5| Step: 6
Training loss: 1.3949481330308058
Validation loss: 2.67277394579184

Epoch: 5| Step: 7
Training loss: 1.3240280239072495
Validation loss: 2.6553446646229477

Epoch: 5| Step: 8
Training loss: 2.1281973402188985
Validation loss: 2.624649763791852

Epoch: 5| Step: 9
Training loss: 1.5044896170960533
Validation loss: 2.58351818604942

Epoch: 5| Step: 10
Training loss: 1.53539097668271
Validation loss: 2.6345340395863444

Epoch: 482| Step: 0
Training loss: 1.7955151263465337
Validation loss: 2.6488836335398376

Epoch: 5| Step: 1
Training loss: 1.7101317298075835
Validation loss: 2.618802966693005

Epoch: 5| Step: 2
Training loss: 1.804958372719201
Validation loss: 2.6468059743828007

Epoch: 5| Step: 3
Training loss: 1.6435459111795907
Validation loss: 2.55154219501628

Epoch: 5| Step: 4
Training loss: 1.7662299816079752
Validation loss: 2.620652030217942

Epoch: 5| Step: 5
Training loss: 2.037934557671698
Validation loss: 2.642964567847198

Epoch: 5| Step: 6
Training loss: 1.4145675515973872
Validation loss: 2.6575006545917677

Epoch: 5| Step: 7
Training loss: 1.5313716762233576
Validation loss: 2.6306962489795715

Epoch: 5| Step: 8
Training loss: 2.0282033520156912
Validation loss: 2.6183537502102068

Epoch: 5| Step: 9
Training loss: 1.934662925972051
Validation loss: 2.6059440608120115

Epoch: 5| Step: 10
Training loss: 1.6297720750933704
Validation loss: 2.6420650178207086

Epoch: 483| Step: 0
Training loss: 2.2890292741362623
Validation loss: 2.6657243673739095

Epoch: 5| Step: 1
Training loss: 1.1752713133683432
Validation loss: 2.6512497746235613

Epoch: 5| Step: 2
Training loss: 2.073180202684155
Validation loss: 2.699752225638838

Epoch: 5| Step: 3
Training loss: 1.6488555811927905
Validation loss: 2.706757176919295

Epoch: 5| Step: 4
Training loss: 1.6747994203178838
Validation loss: 2.645514855577041

Epoch: 5| Step: 5
Training loss: 2.056717134883843
Validation loss: 2.670984635684332

Epoch: 5| Step: 6
Training loss: 1.331886037479172
Validation loss: 2.638865109242792

Epoch: 5| Step: 7
Training loss: 1.6545639092790934
Validation loss: 2.6508731302938293

Epoch: 5| Step: 8
Training loss: 1.989365916996917
Validation loss: 2.6422207161227793

Epoch: 5| Step: 9
Training loss: 1.2836410727342085
Validation loss: 2.578384944157593

Epoch: 5| Step: 10
Training loss: 1.603753280220037
Validation loss: 2.6201486384482244

Epoch: 484| Step: 0
Training loss: 1.582642839683581
Validation loss: 2.6707621527689884

Epoch: 5| Step: 1
Training loss: 1.8467845836523917
Validation loss: 2.6243703167983083

Epoch: 5| Step: 2
Training loss: 1.7789014760096995
Validation loss: 2.6306208802465187

Epoch: 5| Step: 3
Training loss: 1.51888365294819
Validation loss: 2.597708697564053

Epoch: 5| Step: 4
Training loss: 1.6380209465410913
Validation loss: 2.700801017511124

Epoch: 5| Step: 5
Training loss: 2.3041567433737375
Validation loss: 2.702539378992377

Epoch: 5| Step: 6
Training loss: 1.363347267804056
Validation loss: 2.643585197265125

Epoch: 5| Step: 7
Training loss: 1.4677661278822478
Validation loss: 2.677121445879419

Epoch: 5| Step: 8
Training loss: 1.6118035372289954
Validation loss: 2.6506950476902635

Epoch: 5| Step: 9
Training loss: 1.7228252302059628
Validation loss: 2.6190891371383245

Epoch: 5| Step: 10
Training loss: 1.911923267943636
Validation loss: 2.651690346776772

Epoch: 485| Step: 0
Training loss: 1.3851143165261057
Validation loss: 2.640467096859774

Epoch: 5| Step: 1
Training loss: 1.3945074426665076
Validation loss: 2.671223735037288

Epoch: 5| Step: 2
Training loss: 1.6614710728586415
Validation loss: 2.6672521404802834

Epoch: 5| Step: 3
Training loss: 1.7589210913971436
Validation loss: 2.6712325817691944

Epoch: 5| Step: 4
Training loss: 1.447446165780279
Validation loss: 2.6184538283922922

Epoch: 5| Step: 5
Training loss: 2.473952304765818
Validation loss: 2.6199161347724536

Epoch: 5| Step: 6
Training loss: 1.5468222869214467
Validation loss: 2.561688247311574

Epoch: 5| Step: 7
Training loss: 1.5162499309391972
Validation loss: 2.574345983849356

Epoch: 5| Step: 8
Training loss: 2.1669141799205773
Validation loss: 2.651240139861137

Epoch: 5| Step: 9
Training loss: 1.5054457674118202
Validation loss: 2.6735861642631904

Epoch: 5| Step: 10
Training loss: 1.7151287424238388
Validation loss: 2.6682081974334646

Epoch: 486| Step: 0
Training loss: 1.671359044970649
Validation loss: 2.627659657634693

Epoch: 5| Step: 1
Training loss: 1.1155997244058011
Validation loss: 2.6322154539077793

Epoch: 5| Step: 2
Training loss: 2.1719140797124825
Validation loss: 2.665693678226812

Epoch: 5| Step: 3
Training loss: 1.4714437091778858
Validation loss: 2.6382745528202096

Epoch: 5| Step: 4
Training loss: 1.5182817906921184
Validation loss: 2.634071732275215

Epoch: 5| Step: 5
Training loss: 1.7034129328085494
Validation loss: 2.7167039092461858

Epoch: 5| Step: 6
Training loss: 2.0839484514681414
Validation loss: 2.7034158175015772

Epoch: 5| Step: 7
Training loss: 1.2953768430036159
Validation loss: 2.6868234771626494

Epoch: 5| Step: 8
Training loss: 2.2240758026569947
Validation loss: 2.6189891772041705

Epoch: 5| Step: 9
Training loss: 1.564099980380637
Validation loss: 2.579068493719509

Epoch: 5| Step: 10
Training loss: 1.8863382844380783
Validation loss: 2.6474243533861284

Epoch: 487| Step: 0
Training loss: 1.3272286924863848
Validation loss: 2.7059102245609323

Epoch: 5| Step: 1
Training loss: 1.2894275495182128
Validation loss: 2.6884311818970055

Epoch: 5| Step: 2
Training loss: 1.695461917041147
Validation loss: 2.711933925599833

Epoch: 5| Step: 3
Training loss: 1.5881862388672787
Validation loss: 2.648532240541529

Epoch: 5| Step: 4
Training loss: 2.0717931670861978
Validation loss: 2.6837078181950194

Epoch: 5| Step: 5
Training loss: 1.540307175852884
Validation loss: 2.619076925238134

Epoch: 5| Step: 6
Training loss: 1.5612428566957859
Validation loss: 2.6171452452288664

Epoch: 5| Step: 7
Training loss: 2.273796341619368
Validation loss: 2.621237919010316

Epoch: 5| Step: 8
Training loss: 1.4683428260822562
Validation loss: 2.6458967390368744

Epoch: 5| Step: 9
Training loss: 1.642033000033636
Validation loss: 2.6631240084213053

Epoch: 5| Step: 10
Training loss: 1.939029643528132
Validation loss: 2.6522411538208273

Epoch: 488| Step: 0
Training loss: 2.2025257134208513
Validation loss: 2.672945055019864

Epoch: 5| Step: 1
Training loss: 1.4685491871011003
Validation loss: 2.621942220726669

Epoch: 5| Step: 2
Training loss: 2.269101231818016
Validation loss: 2.6533720974675563

Epoch: 5| Step: 3
Training loss: 1.5878091676283286
Validation loss: 2.64583238603767

Epoch: 5| Step: 4
Training loss: 1.0372932687718808
Validation loss: 2.660162934340105

Epoch: 5| Step: 5
Training loss: 1.6513248846499913
Validation loss: 2.717890949666912

Epoch: 5| Step: 6
Training loss: 1.813253311934708
Validation loss: 2.603787289129228

Epoch: 5| Step: 7
Training loss: 1.7104104680434182
Validation loss: 2.6629111246451345

Epoch: 5| Step: 8
Training loss: 1.6112592462787831
Validation loss: 2.6958752040448792

Epoch: 5| Step: 9
Training loss: 1.524232314698098
Validation loss: 2.6802233805898674

Epoch: 5| Step: 10
Training loss: 1.8111877294857701
Validation loss: 2.70484732402945

Epoch: 489| Step: 0
Training loss: 1.7320386942358066
Validation loss: 2.6505719449751814

Epoch: 5| Step: 1
Training loss: 1.624922897270318
Validation loss: 2.699333743965961

Epoch: 5| Step: 2
Training loss: 1.3262616269018148
Validation loss: 2.7268880784948957

Epoch: 5| Step: 3
Training loss: 1.8394138619572005
Validation loss: 2.721395534729484

Epoch: 5| Step: 4
Training loss: 1.090809220109923
Validation loss: 2.6758784925040984

Epoch: 5| Step: 5
Training loss: 1.6282115891288174
Validation loss: 2.6953767711460257

Epoch: 5| Step: 6
Training loss: 1.6705158448870812
Validation loss: 2.700118998309699

Epoch: 5| Step: 7
Training loss: 1.2309614860093927
Validation loss: 2.6775582321132676

Epoch: 5| Step: 8
Training loss: 2.490132312553089
Validation loss: 2.707110586301387

Epoch: 5| Step: 9
Training loss: 1.79575757650917
Validation loss: 2.6512681824921147

Epoch: 5| Step: 10
Training loss: 1.8159725861055662
Validation loss: 2.6799973781917545

Epoch: 490| Step: 0
Training loss: 1.7132858116273562
Validation loss: 2.6831581889628664

Epoch: 5| Step: 1
Training loss: 1.909890622507322
Validation loss: 2.6855084775862657

Epoch: 5| Step: 2
Training loss: 1.962786771389757
Validation loss: 2.5907496269327694

Epoch: 5| Step: 3
Training loss: 1.822409212234664
Validation loss: 2.6824380546564304

Epoch: 5| Step: 4
Training loss: 1.5813991461214458
Validation loss: 2.6064691975835066

Epoch: 5| Step: 5
Training loss: 1.9787745706426791
Validation loss: 2.6652394623499016

Epoch: 5| Step: 6
Training loss: 1.932046783915451
Validation loss: 2.662099018759464

Epoch: 5| Step: 7
Training loss: 1.773930350900734
Validation loss: 2.7089585556776656

Epoch: 5| Step: 8
Training loss: 1.2498276591704809
Validation loss: 2.666490341966139

Epoch: 5| Step: 9
Training loss: 1.2659391790306842
Validation loss: 2.710993221833626

Epoch: 5| Step: 10
Training loss: 1.0739438346725252
Validation loss: 2.6643764979726043

Epoch: 491| Step: 0
Training loss: 1.3720707903552327
Validation loss: 2.643631139200305

Epoch: 5| Step: 1
Training loss: 1.9193744053493462
Validation loss: 2.6452697710527326

Epoch: 5| Step: 2
Training loss: 1.466419481269598
Validation loss: 2.6814288537225917

Epoch: 5| Step: 3
Training loss: 1.6921027249475435
Validation loss: 2.7089917773201604

Epoch: 5| Step: 4
Training loss: 1.7208884374310447
Validation loss: 2.6692306884500026

Epoch: 5| Step: 5
Training loss: 1.8076886740490343
Validation loss: 2.6373802740110412

Epoch: 5| Step: 6
Training loss: 1.6778670270745006
Validation loss: 2.622437384043513

Epoch: 5| Step: 7
Training loss: 2.2232601907338476
Validation loss: 2.6633336448040374

Epoch: 5| Step: 8
Training loss: 1.5585073193747527
Validation loss: 2.7351127208287895

Epoch: 5| Step: 9
Training loss: 1.6688101654064977
Validation loss: 2.65589293384854

Epoch: 5| Step: 10
Training loss: 1.849808518062698
Validation loss: 2.7079815701596277

Epoch: 492| Step: 0
Training loss: 1.4788789693227609
Validation loss: 2.660388924732724

Epoch: 5| Step: 1
Training loss: 1.4496423148604403
Validation loss: 2.7132128438203553

Epoch: 5| Step: 2
Training loss: 2.2338220939251965
Validation loss: 2.6497905127158083

Epoch: 5| Step: 3
Training loss: 1.775521553675747
Validation loss: 2.698533291812911

Epoch: 5| Step: 4
Training loss: 1.4322634145088848
Validation loss: 2.6293682409262447

Epoch: 5| Step: 5
Training loss: 1.782060806718321
Validation loss: 2.725921382008363

Epoch: 5| Step: 6
Training loss: 1.8529265968165893
Validation loss: 2.597664838035439

Epoch: 5| Step: 7
Training loss: 1.623719958349749
Validation loss: 2.651171436530764

Epoch: 5| Step: 8
Training loss: 2.0775112306954617
Validation loss: 2.7155850510080444

Epoch: 5| Step: 9
Training loss: 1.508894300031315
Validation loss: 2.679930506447909

Epoch: 5| Step: 10
Training loss: 1.25164686435387
Validation loss: 2.6266307218975027

Epoch: 493| Step: 0
Training loss: 2.0950374914925214
Validation loss: 2.65642147391421

Epoch: 5| Step: 1
Training loss: 1.6463573764317991
Validation loss: 2.6781828237554874

Epoch: 5| Step: 2
Training loss: 1.4574720109768016
Validation loss: 2.6966901899008167

Epoch: 5| Step: 3
Training loss: 1.6235299430132466
Validation loss: 2.5974448482634576

Epoch: 5| Step: 4
Training loss: 1.862933304326381
Validation loss: 2.658360431754318

Epoch: 5| Step: 5
Training loss: 1.640604800145364
Validation loss: 2.686986759263644

Epoch: 5| Step: 6
Training loss: 1.9765480252063863
Validation loss: 2.604474683368163

Epoch: 5| Step: 7
Training loss: 1.6863148377482444
Validation loss: 2.5958458480437163

Epoch: 5| Step: 8
Training loss: 1.6717325310299955
Validation loss: 2.633470217178146

Epoch: 5| Step: 9
Training loss: 1.2721899743877159
Validation loss: 2.6533350934011297

Epoch: 5| Step: 10
Training loss: 1.203090369977087
Validation loss: 2.646493895333876

Epoch: 494| Step: 0
Training loss: 1.4347172214601034
Validation loss: 2.6040140510057

Epoch: 5| Step: 1
Training loss: 1.6674836858268747
Validation loss: 2.651495381555792

Epoch: 5| Step: 2
Training loss: 1.9726839875641182
Validation loss: 2.6829122202831353

Epoch: 5| Step: 3
Training loss: 1.8449878739782961
Validation loss: 2.684932637631041

Epoch: 5| Step: 4
Training loss: 2.4728504363791766
Validation loss: 2.692889158558161

Epoch: 5| Step: 5
Training loss: 1.7063602900928376
Validation loss: 2.7081225487505325

Epoch: 5| Step: 6
Training loss: 1.2907693832954694
Validation loss: 2.643945550679154

Epoch: 5| Step: 7
Training loss: 1.2952408663794515
Validation loss: 2.6836009453198506

Epoch: 5| Step: 8
Training loss: 1.6525663041102439
Validation loss: 2.684135255681351

Epoch: 5| Step: 9
Training loss: 1.578542295370807
Validation loss: 2.6611642468949626

Epoch: 5| Step: 10
Training loss: 1.721384560859649
Validation loss: 2.673114001195504

Epoch: 495| Step: 0
Training loss: 1.3419116552754002
Validation loss: 2.6592964861120136

Epoch: 5| Step: 1
Training loss: 1.471770002179619
Validation loss: 2.6989733378720215

Epoch: 5| Step: 2
Training loss: 1.6151333354082105
Validation loss: 2.7174818782291035

Epoch: 5| Step: 3
Training loss: 1.6390603733685336
Validation loss: 2.7163667314208584

Epoch: 5| Step: 4
Training loss: 1.7334002943431956
Validation loss: 2.6456111165132397

Epoch: 5| Step: 5
Training loss: 1.6814654499398525
Validation loss: 2.701634157330128

Epoch: 5| Step: 6
Training loss: 1.5802392677023553
Validation loss: 2.6073091004561184

Epoch: 5| Step: 7
Training loss: 1.3934735900763366
Validation loss: 2.6153060554163257

Epoch: 5| Step: 8
Training loss: 2.0010957100629945
Validation loss: 2.7147749074011354

Epoch: 5| Step: 9
Training loss: 2.1672600764943417
Validation loss: 2.704502473391862

Epoch: 5| Step: 10
Training loss: 1.3642753758320512
Validation loss: 2.6805750109227415

Epoch: 496| Step: 0
Training loss: 1.693071915141799
Validation loss: 2.6306159325112355

Epoch: 5| Step: 1
Training loss: 1.2583060865841784
Validation loss: 2.628248022763313

Epoch: 5| Step: 2
Training loss: 1.4369095958180371
Validation loss: 2.618990054268362

Epoch: 5| Step: 3
Training loss: 1.1779449932487303
Validation loss: 2.646031203140907

Epoch: 5| Step: 4
Training loss: 2.0664675150047893
Validation loss: 2.5839538708835694

Epoch: 5| Step: 5
Training loss: 2.565473180779013
Validation loss: 2.634649956468705

Epoch: 5| Step: 6
Training loss: 1.4476413419298655
Validation loss: 2.62033852687748

Epoch: 5| Step: 7
Training loss: 1.4367846491989773
Validation loss: 2.6987849887638737

Epoch: 5| Step: 8
Training loss: 1.67540745690025
Validation loss: 2.6385377635918603

Epoch: 5| Step: 9
Training loss: 1.6287669023879547
Validation loss: 2.7268343981862144

Epoch: 5| Step: 10
Training loss: 1.817079940066121
Validation loss: 2.7404358048025763

Epoch: 497| Step: 0
Training loss: 1.404391522991528
Validation loss: 2.764949168402785

Epoch: 5| Step: 1
Training loss: 1.9138825001061708
Validation loss: 2.6232382003532515

Epoch: 5| Step: 2
Training loss: 1.6759171152946815
Validation loss: 2.6939383669584442

Epoch: 5| Step: 3
Training loss: 1.60433177180914
Validation loss: 2.6125512659901466

Epoch: 5| Step: 4
Training loss: 2.2171907990789297
Validation loss: 2.632467764437844

Epoch: 5| Step: 5
Training loss: 2.2990214380805383
Validation loss: 2.6527765619765202

Epoch: 5| Step: 6
Training loss: 1.3072415325790072
Validation loss: 2.7353198297423864

Epoch: 5| Step: 7
Training loss: 1.9417946501807186
Validation loss: 2.7212749030232612

Epoch: 5| Step: 8
Training loss: 1.319355589680037
Validation loss: 2.7220864149771584

Epoch: 5| Step: 9
Training loss: 1.6843733608825295
Validation loss: 2.6904655420058834

Epoch: 5| Step: 10
Training loss: 1.4115895941065666
Validation loss: 2.603103312964974

Epoch: 498| Step: 0
Training loss: 2.5107433270125767
Validation loss: 2.6958546216196804

Epoch: 5| Step: 1
Training loss: 1.624695969530362
Validation loss: 2.698786204666322

Epoch: 5| Step: 2
Training loss: 1.5842043421701806
Validation loss: 2.667584458070958

Epoch: 5| Step: 3
Training loss: 1.4856944594396562
Validation loss: 2.665736277102874

Epoch: 5| Step: 4
Training loss: 1.3475405436062389
Validation loss: 2.7188895640785935

Epoch: 5| Step: 5
Training loss: 1.3250386448388844
Validation loss: 2.658921514807567

Epoch: 5| Step: 6
Training loss: 1.322299658197888
Validation loss: 2.641085981594131

Epoch: 5| Step: 7
Training loss: 1.6212535365763894
Validation loss: 2.6150395887099633

Epoch: 5| Step: 8
Training loss: 1.577402157054039
Validation loss: 2.661073161270682

Epoch: 5| Step: 9
Training loss: 1.936724599911748
Validation loss: 2.647045712006571

Epoch: 5| Step: 10
Training loss: 1.8440671098499894
Validation loss: 2.672282159785031

Epoch: 499| Step: 0
Training loss: 1.3790201026662878
Validation loss: 2.6032987885149232

Epoch: 5| Step: 1
Training loss: 2.0563904409943623
Validation loss: 2.6557625262339886

Epoch: 5| Step: 2
Training loss: 2.0201649953478937
Validation loss: 2.662327539093693

Epoch: 5| Step: 3
Training loss: 1.417107354603322
Validation loss: 2.659800352094976

Epoch: 5| Step: 4
Training loss: 1.6718352838950494
Validation loss: 2.6636694541004515

Epoch: 5| Step: 5
Training loss: 1.922771647871954
Validation loss: 2.651688387082838

Epoch: 5| Step: 6
Training loss: 1.6015385323568645
Validation loss: 2.7220422445494097

Epoch: 5| Step: 7
Training loss: 1.7143180580153368
Validation loss: 2.7057081147080937

Epoch: 5| Step: 8
Training loss: 1.5584751934956986
Validation loss: 2.6940428228322584

Epoch: 5| Step: 9
Training loss: 1.7428774301500634
Validation loss: 2.7061771344646974

Epoch: 5| Step: 10
Training loss: 1.8925385682624383
Validation loss: 2.647290418098598

Epoch: 500| Step: 0
Training loss: 1.9406574731834199
Validation loss: 2.7064895740204093

Epoch: 5| Step: 1
Training loss: 1.48600871881158
Validation loss: 2.6810052954087014

Epoch: 5| Step: 2
Training loss: 1.5356426681725581
Validation loss: 2.6017576380537273

Epoch: 5| Step: 3
Training loss: 1.372883207678519
Validation loss: 2.720949172021577

Epoch: 5| Step: 4
Training loss: 1.0221667372001035
Validation loss: 2.629691435370354

Epoch: 5| Step: 5
Training loss: 1.9997532811577279
Validation loss: 2.632647241655666

Epoch: 5| Step: 6
Training loss: 1.57172872723527
Validation loss: 2.59011498336038

Epoch: 5| Step: 7
Training loss: 1.3030934904025935
Validation loss: 2.6357138493447

Epoch: 5| Step: 8
Training loss: 1.9039519794843816
Validation loss: 2.6765481308445644

Epoch: 5| Step: 9
Training loss: 1.9150597290604647
Validation loss: 2.694985331896225

Epoch: 5| Step: 10
Training loss: 2.151196625849247
Validation loss: 2.635985205188903

Testing loss: 2.660572827883332
