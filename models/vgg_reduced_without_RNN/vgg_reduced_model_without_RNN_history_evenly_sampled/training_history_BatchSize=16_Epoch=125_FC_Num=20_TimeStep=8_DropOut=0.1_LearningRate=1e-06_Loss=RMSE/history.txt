Epoch: 1| Step: 0
Training loss: 3.937929039241696
Validation loss: 3.596668519648724

Epoch: 6| Step: 1
Training loss: 4.7553704670413
Validation loss: 3.593967441509674

Epoch: 6| Step: 2
Training loss: 2.6526335387991513
Validation loss: 3.5916906590461357

Epoch: 6| Step: 3
Training loss: 3.4889950080763708
Validation loss: 3.5923014685081402

Epoch: 6| Step: 4
Training loss: 3.7734766734994314
Validation loss: 3.59093839100124

Epoch: 6| Step: 5
Training loss: 3.1305821724991554
Validation loss: 3.5881734632007

Epoch: 6| Step: 6
Training loss: 4.240201088077543
Validation loss: 3.586725142630071

Epoch: 6| Step: 7
Training loss: 3.8153801966811973
Validation loss: 3.5848574181435238

Epoch: 6| Step: 8
Training loss: 4.598345268172266
Validation loss: 3.5820323807973833

Epoch: 6| Step: 9
Training loss: 3.622754947386516
Validation loss: 3.581013152762908

Epoch: 6| Step: 10
Training loss: 3.158814398800109
Validation loss: 3.5789292241290918

Epoch: 6| Step: 11
Training loss: 3.3696706161493486
Validation loss: 3.576322198910991

Epoch: 6| Step: 12
Training loss: 4.073375757332585
Validation loss: 3.574929488760495

Epoch: 6| Step: 13
Training loss: 3.913345118888858
Validation loss: 3.5733730417297327

Epoch: 2| Step: 0
Training loss: 3.006003730187859
Validation loss: 3.5705151980014107

Epoch: 6| Step: 1
Training loss: 3.8207274915594676
Validation loss: 3.570442160552892

Epoch: 6| Step: 2
Training loss: 3.941129918614761
Validation loss: 3.5674419167375135

Epoch: 6| Step: 3
Training loss: 3.697033213360204
Validation loss: 3.566538118405969

Epoch: 6| Step: 4
Training loss: 3.9701124841239297
Validation loss: 3.563179122651578

Epoch: 6| Step: 5
Training loss: 3.515288069792154
Validation loss: 3.5610413917834753

Epoch: 6| Step: 6
Training loss: 3.5726222740908504
Validation loss: 3.56000508435135

Epoch: 6| Step: 7
Training loss: 4.128565778742576
Validation loss: 3.555495012369896

Epoch: 6| Step: 8
Training loss: 3.6406957267472735
Validation loss: 3.553347635786585

Epoch: 6| Step: 9
Training loss: 3.8475238912830863
Validation loss: 3.553224543325748

Epoch: 6| Step: 10
Training loss: 3.990030142495781
Validation loss: 3.552247831231908

Epoch: 6| Step: 11
Training loss: 4.568760378469637
Validation loss: 3.547511878546234

Epoch: 6| Step: 12
Training loss: 3.2103679365304583
Validation loss: 3.5431980714093454

Epoch: 6| Step: 13
Training loss: 3.3405511118155125
Validation loss: 3.5433041912292715

Epoch: 3| Step: 0
Training loss: 4.205677717935442
Validation loss: 3.544558080365328

Epoch: 6| Step: 1
Training loss: 3.4544855949928612
Validation loss: 3.5376038867157273

Epoch: 6| Step: 2
Training loss: 2.7947287396145164
Validation loss: 3.5370904363407614

Epoch: 6| Step: 3
Training loss: 4.281719098530484
Validation loss: 3.5346708898329657

Epoch: 6| Step: 4
Training loss: 4.579216003614993
Validation loss: 3.532289181310622

Epoch: 6| Step: 5
Training loss: 4.166604130593535
Validation loss: 3.5296000245760006

Epoch: 6| Step: 6
Training loss: 3.6621510414296323
Validation loss: 3.527330884327554

Epoch: 6| Step: 7
Training loss: 4.305421410115014
Validation loss: 3.5226293052167352

Epoch: 6| Step: 8
Training loss: 3.2676516728124474
Validation loss: 3.5202550955085714

Epoch: 6| Step: 9
Training loss: 3.4105031469554556
Validation loss: 3.518225917752573

Epoch: 6| Step: 10
Training loss: 2.6950099609417393
Validation loss: 3.5168550173108226

Epoch: 6| Step: 11
Training loss: 3.465489685333845
Validation loss: 3.513705043308643

Epoch: 6| Step: 12
Training loss: 3.3244230070913248
Validation loss: 3.5131468225975526

Epoch: 6| Step: 13
Training loss: 4.375788154453578
Validation loss: 3.5105352845734523

Epoch: 4| Step: 0
Training loss: 3.2826552515438294
Validation loss: 3.507355347483546

Epoch: 6| Step: 1
Training loss: 3.8099252730523046
Validation loss: 3.505652809873089

Epoch: 6| Step: 2
Training loss: 2.758683107755161
Validation loss: 3.5031207713927404

Epoch: 6| Step: 3
Training loss: 4.203869608329675
Validation loss: 3.501812076113563

Epoch: 6| Step: 4
Training loss: 3.508003212686979
Validation loss: 3.499251331002503

Epoch: 6| Step: 5
Training loss: 2.855778668202039
Validation loss: 3.4980522675101438

Epoch: 6| Step: 6
Training loss: 3.6652486544536935
Validation loss: 3.491205813462008

Epoch: 6| Step: 7
Training loss: 3.2108696329411526
Validation loss: 3.489082151790149

Epoch: 6| Step: 8
Training loss: 4.42049815171342
Validation loss: 3.4873769373151147

Epoch: 6| Step: 9
Training loss: 3.6001445105476213
Validation loss: 3.483824769017225

Epoch: 6| Step: 10
Training loss: 4.166298557551331
Validation loss: 3.4802428367960005

Epoch: 6| Step: 11
Training loss: 4.350053124815915
Validation loss: 3.4790870569464483

Epoch: 6| Step: 12
Training loss: 3.966513777171917
Validation loss: 3.4761158727149715

Epoch: 6| Step: 13
Training loss: 3.4488951033304645
Validation loss: 3.472926708549704

Epoch: 5| Step: 0
Training loss: 2.962542659919148
Validation loss: 3.47037605974706

Epoch: 6| Step: 1
Training loss: 3.4633962194358783
Validation loss: 3.468507216675475

Epoch: 6| Step: 2
Training loss: 4.114961836905593
Validation loss: 3.4641944617339626

Epoch: 6| Step: 3
Training loss: 3.547996175744577
Validation loss: 3.4595031869859802

Epoch: 6| Step: 4
Training loss: 3.1428117872656296
Validation loss: 3.4565430306800824

Epoch: 6| Step: 5
Training loss: 4.344318819194514
Validation loss: 3.455072629802219

Epoch: 6| Step: 6
Training loss: 4.3538634758967865
Validation loss: 3.450820298514319

Epoch: 6| Step: 7
Training loss: 3.389031523602097
Validation loss: 3.4488199779008357

Epoch: 6| Step: 8
Training loss: 3.6672478273075697
Validation loss: 3.4425825845954727

Epoch: 6| Step: 9
Training loss: 3.8674146180939886
Validation loss: 3.4403763670407805

Epoch: 6| Step: 10
Training loss: 3.068716629375187
Validation loss: 3.4357827275792396

Epoch: 6| Step: 11
Training loss: 3.4860583973040473
Validation loss: 3.4298624384688488

Epoch: 6| Step: 12
Training loss: 3.540653233360857
Validation loss: 3.430152033580334

Epoch: 6| Step: 13
Training loss: 4.345157532464571
Validation loss: 3.428166757027312

Epoch: 6| Step: 0
Training loss: 4.052948742448038
Validation loss: 3.4209320331905633

Epoch: 6| Step: 1
Training loss: 2.843799800227149
Validation loss: 3.4181262594516015

Epoch: 6| Step: 2
Training loss: 4.112454844867505
Validation loss: 3.414591762230478

Epoch: 6| Step: 3
Training loss: 4.125864111818208
Validation loss: 3.413627772733645

Epoch: 6| Step: 4
Training loss: 3.917669708918958
Validation loss: 3.403039188708631

Epoch: 6| Step: 5
Training loss: 3.1515085089942536
Validation loss: 3.404787973419668

Epoch: 6| Step: 6
Training loss: 3.362463662330519
Validation loss: 3.4005211465722742

Epoch: 6| Step: 7
Training loss: 2.9738946608337278
Validation loss: 3.3950825056261547

Epoch: 6| Step: 8
Training loss: 3.282817066739595
Validation loss: 3.3928872701655197

Epoch: 6| Step: 9
Training loss: 3.6509034279824633
Validation loss: 3.3880494881014123

Epoch: 6| Step: 10
Training loss: 4.2786714905588505
Validation loss: 3.387640673148813

Epoch: 6| Step: 11
Training loss: 3.6603007252452575
Validation loss: 3.3814011080390767

Epoch: 6| Step: 12
Training loss: 4.060511410454194
Validation loss: 3.3756343111788554

Epoch: 6| Step: 13
Training loss: 1.8803428820145731
Validation loss: 3.3726069208958673

Epoch: 7| Step: 0
Training loss: 3.4034595783916113
Validation loss: 3.365215302483296

Epoch: 6| Step: 1
Training loss: 3.7116304091995245
Validation loss: 3.364729006685748

Epoch: 6| Step: 2
Training loss: 3.2905516526614513
Validation loss: 3.361936988329919

Epoch: 6| Step: 3
Training loss: 3.2247857843269783
Validation loss: 3.356072927379938

Epoch: 6| Step: 4
Training loss: 3.640212661902729
Validation loss: 3.348607857616557

Epoch: 6| Step: 5
Training loss: 2.6728098165355223
Validation loss: 3.352458722067057

Epoch: 6| Step: 6
Training loss: 4.653508960466457
Validation loss: 3.3454210860870113

Epoch: 6| Step: 7
Training loss: 3.961953418471338
Validation loss: 3.3378816957302178

Epoch: 6| Step: 8
Training loss: 3.8558528751306524
Validation loss: 3.335006368355838

Epoch: 6| Step: 9
Training loss: 3.5218472497450977
Validation loss: 3.3293345728521877

Epoch: 6| Step: 10
Training loss: 2.9327288900741886
Validation loss: 3.323435137533082

Epoch: 6| Step: 11
Training loss: 2.975675836299925
Validation loss: 3.320951267015042

Epoch: 6| Step: 12
Training loss: 3.428817743013928
Validation loss: 3.3157302250724516

Epoch: 6| Step: 13
Training loss: 4.724722411059963
Validation loss: 3.312267548385623

Epoch: 8| Step: 0
Training loss: 4.093264252476327
Validation loss: 3.308372474565539

Epoch: 6| Step: 1
Training loss: 3.286304468259974
Validation loss: 3.303062872591934

Epoch: 6| Step: 2
Training loss: 3.465472210611
Validation loss: 3.296387480519151

Epoch: 6| Step: 3
Training loss: 3.811519809479762
Validation loss: 3.2929381851795916

Epoch: 6| Step: 4
Training loss: 3.445335336207269
Validation loss: 3.288101611282815

Epoch: 6| Step: 5
Training loss: 4.227757085904652
Validation loss: 3.2805567574051158

Epoch: 6| Step: 6
Training loss: 3.8975413177238107
Validation loss: 3.2743833166509755

Epoch: 6| Step: 7
Training loss: 3.27707922939877
Validation loss: 3.2678312046187514

Epoch: 6| Step: 8
Training loss: 3.7980204294789224
Validation loss: 3.262577497609867

Epoch: 6| Step: 9
Training loss: 3.8348567395762947
Validation loss: 3.258524820799069

Epoch: 6| Step: 10
Training loss: 2.8139304867734936
Validation loss: 3.2539036878602245

Epoch: 6| Step: 11
Training loss: 2.129671235837566
Validation loss: 3.245399723226427

Epoch: 6| Step: 12
Training loss: 3.6458535039434588
Validation loss: 3.2434649966605833

Epoch: 6| Step: 13
Training loss: 2.47331665283638
Validation loss: 3.2428514872344523

Epoch: 9| Step: 0
Training loss: 3.3270258991504957
Validation loss: 3.2330389510643633

Epoch: 6| Step: 1
Training loss: 3.678418760795588
Validation loss: 3.227492469998743

Epoch: 6| Step: 2
Training loss: 3.966422051546105
Validation loss: 3.2217019197873547

Epoch: 6| Step: 3
Training loss: 2.4445344217193887
Validation loss: 3.2210117966942473

Epoch: 6| Step: 4
Training loss: 3.3497427599626755
Validation loss: 3.210688306955624

Epoch: 6| Step: 5
Training loss: 3.778747991876198
Validation loss: 3.2088585977477972

Epoch: 6| Step: 6
Training loss: 3.3131491546815384
Validation loss: 3.2015845843899453

Epoch: 6| Step: 7
Training loss: 3.227391466698964
Validation loss: 3.194038881633607

Epoch: 6| Step: 8
Training loss: 3.4631143789192196
Validation loss: 3.1888573652049943

Epoch: 6| Step: 9
Training loss: 4.1246536571872365
Validation loss: 3.185090531457139

Epoch: 6| Step: 10
Training loss: 2.8851675942861865
Validation loss: 3.17729076163595

Epoch: 6| Step: 11
Training loss: 3.809427743222722
Validation loss: 3.1711272611047576

Epoch: 6| Step: 12
Training loss: 3.3597187664772385
Validation loss: 3.1668082504053885

Epoch: 6| Step: 13
Training loss: 3.144185036501861
Validation loss: 3.1599625843832024

Epoch: 10| Step: 0
Training loss: 3.95565702746344
Validation loss: 3.1564031105101

Epoch: 6| Step: 1
Training loss: 3.4983670648842016
Validation loss: 3.1485443321030324

Epoch: 6| Step: 2
Training loss: 2.768215883976149
Validation loss: 3.146044205707768

Epoch: 6| Step: 3
Training loss: 3.9593786900479797
Validation loss: 3.13863535767138

Epoch: 6| Step: 4
Training loss: 3.8782199894094305
Validation loss: 3.1363065486538813

Epoch: 6| Step: 5
Training loss: 3.9511701854451404
Validation loss: 3.129134519859851

Epoch: 6| Step: 6
Training loss: 3.579331906596957
Validation loss: 3.1206574504226623

Epoch: 6| Step: 7
Training loss: 2.9607597035998947
Validation loss: 3.111205014873799

Epoch: 6| Step: 8
Training loss: 3.04649436725025
Validation loss: 3.10597786868333

Epoch: 6| Step: 9
Training loss: 3.133861946264096
Validation loss: 3.102777220632136

Epoch: 6| Step: 10
Training loss: 3.192665850723342
Validation loss: 3.091924961640555

Epoch: 6| Step: 11
Training loss: 2.96216390771583
Validation loss: 3.082455942313314

Epoch: 6| Step: 12
Training loss: 3.242317803763318
Validation loss: 3.0756273436243835

Epoch: 6| Step: 13
Training loss: 2.5324988404522695
Validation loss: 3.07505972779476

Epoch: 11| Step: 0
Training loss: 3.123242608879576
Validation loss: 3.0670134480941313

Epoch: 6| Step: 1
Training loss: 3.5964413060766334
Validation loss: 3.0600474550920103

Epoch: 6| Step: 2
Training loss: 3.7827378805711493
Validation loss: 3.054370653148151

Epoch: 6| Step: 3
Training loss: 3.1618608514906934
Validation loss: 3.048922551386058

Epoch: 6| Step: 4
Training loss: 3.175264999264118
Validation loss: 3.0423471013093977

Epoch: 6| Step: 5
Training loss: 3.7753808997789253
Validation loss: 3.0329309269828832

Epoch: 6| Step: 6
Training loss: 2.7992156054015704
Validation loss: 3.0284680124820764

Epoch: 6| Step: 7
Training loss: 3.2038793652477846
Validation loss: 3.0231171421528593

Epoch: 6| Step: 8
Training loss: 3.217290454790086
Validation loss: 3.0187842157866758

Epoch: 6| Step: 9
Training loss: 3.595210831658175
Validation loss: 3.006885265357945

Epoch: 6| Step: 10
Training loss: 3.0884412435037834
Validation loss: 2.996744733779516

Epoch: 6| Step: 11
Training loss: 2.832389019696787
Validation loss: 2.9979442898880406

Epoch: 6| Step: 12
Training loss: 3.0188736094565214
Validation loss: 2.9931638380973755

Epoch: 6| Step: 13
Training loss: 4.025064854069779
Validation loss: 2.9766636017024313

Epoch: 12| Step: 0
Training loss: 3.3778781627773906
Validation loss: 2.9695952770263045

Epoch: 6| Step: 1
Training loss: 2.9935541841500686
Validation loss: 2.9716474037106715

Epoch: 6| Step: 2
Training loss: 3.270686848917836
Validation loss: 2.9564704893790337

Epoch: 6| Step: 3
Training loss: 3.307270023945959
Validation loss: 2.9559380087508003

Epoch: 6| Step: 4
Training loss: 3.071666622758666
Validation loss: 2.94547510273541

Epoch: 6| Step: 5
Training loss: 3.990445886235231
Validation loss: 2.9435452090797005

Epoch: 6| Step: 6
Training loss: 3.0611703282709577
Validation loss: 2.9341653534849756

Epoch: 6| Step: 7
Training loss: 2.977410623664734
Validation loss: 2.9226744718792474

Epoch: 6| Step: 8
Training loss: 2.8339194271287966
Validation loss: 2.9188899691476884

Epoch: 6| Step: 9
Training loss: 3.187004350011111
Validation loss: 2.9079207073838496

Epoch: 6| Step: 10
Training loss: 3.300497370142843
Validation loss: 2.8953976702195825

Epoch: 6| Step: 11
Training loss: 3.3785192720056334
Validation loss: 2.8910805602365355

Epoch: 6| Step: 12
Training loss: 2.9318344997519126
Validation loss: 2.8877890615250923

Epoch: 6| Step: 13
Training loss: 3.457830063076725
Validation loss: 2.8745646367804873

Epoch: 13| Step: 0
Training loss: 3.7748538058437657
Validation loss: 2.8679320363505862

Epoch: 6| Step: 1
Training loss: 3.0139256566427663
Validation loss: 2.864146597375951

Epoch: 6| Step: 2
Training loss: 3.598032249327361
Validation loss: 2.8539405687092017

Epoch: 6| Step: 3
Training loss: 2.9861481676587025
Validation loss: 2.837974334645955

Epoch: 6| Step: 4
Training loss: 2.7803621053542016
Validation loss: 2.833631759166927

Epoch: 6| Step: 5
Training loss: 3.335234449572948
Validation loss: 2.8353542775774043

Epoch: 6| Step: 6
Training loss: 2.895575001855353
Validation loss: 2.819572603694181

Epoch: 6| Step: 7
Training loss: 3.736975622230825
Validation loss: 2.811872518494512

Epoch: 6| Step: 8
Training loss: 2.7191019816941453
Validation loss: 2.8025285670773012

Epoch: 6| Step: 9
Training loss: 2.8293481363142368
Validation loss: 2.7987116186080327

Epoch: 6| Step: 10
Training loss: 2.64478241081366
Validation loss: 2.7890025819187256

Epoch: 6| Step: 11
Training loss: 3.015926840109856
Validation loss: 2.779614759501469

Epoch: 6| Step: 12
Training loss: 3.524962101725849
Validation loss: 2.7731667432237055

Epoch: 6| Step: 13
Training loss: 2.697131618344719
Validation loss: 2.7646769766659665

Epoch: 14| Step: 0
Training loss: 3.173542955938753
Validation loss: 2.7593005780846784

Epoch: 6| Step: 1
Training loss: 3.3617694217055334
Validation loss: 2.7495109732972884

Epoch: 6| Step: 2
Training loss: 3.639104304517824
Validation loss: 2.745060218615085

Epoch: 6| Step: 3
Training loss: 3.3623659525532257
Validation loss: 2.7320616055791747

Epoch: 6| Step: 4
Training loss: 2.622989065935016
Validation loss: 2.729389340026747

Epoch: 6| Step: 5
Training loss: 2.7605694614564364
Validation loss: 2.7277985066156463

Epoch: 6| Step: 6
Training loss: 3.1804667649699807
Validation loss: 2.7192754071605667

Epoch: 6| Step: 7
Training loss: 3.3735430363043912
Validation loss: 2.696720361839596

Epoch: 6| Step: 8
Training loss: 2.2765942447624794
Validation loss: 2.69255018580088

Epoch: 6| Step: 9
Training loss: 2.7522662101778983
Validation loss: 2.686060108353659

Epoch: 6| Step: 10
Training loss: 3.3534940120153856
Validation loss: 2.6756751604503464

Epoch: 6| Step: 11
Training loss: 2.7992063214906895
Validation loss: 2.6780616738120986

Epoch: 6| Step: 12
Training loss: 2.923250415224858
Validation loss: 2.6662083476765583

Epoch: 6| Step: 13
Training loss: 3.2607144025845267
Validation loss: 2.6669832055845117

Epoch: 15| Step: 0
Training loss: 3.0629225458856655
Validation loss: 2.654702305968097

Epoch: 6| Step: 1
Training loss: 3.2031958595439662
Validation loss: 2.653768862367934

Epoch: 6| Step: 2
Training loss: 2.9791988202118302
Validation loss: 2.648358341096052

Epoch: 6| Step: 3
Training loss: 2.6976269501377272
Validation loss: 2.6483273122820696

Epoch: 6| Step: 4
Training loss: 3.532484530815276
Validation loss: 2.6458751651582477

Epoch: 6| Step: 5
Training loss: 2.867460565270914
Validation loss: 2.630299791232168

Epoch: 6| Step: 6
Training loss: 2.6674307284884042
Validation loss: 2.6188555585253432

Epoch: 6| Step: 7
Training loss: 3.172941883477044
Validation loss: 2.6186028155686816

Epoch: 6| Step: 8
Training loss: 2.8252771697331625
Validation loss: 2.6160076936839345

Epoch: 6| Step: 9
Training loss: 3.5259881440481013
Validation loss: 2.614018065907779

Epoch: 6| Step: 10
Training loss: 3.3727884464189084
Validation loss: 2.6102794307646917

Epoch: 6| Step: 11
Training loss: 2.4874715640489047
Validation loss: 2.601366586504188

Epoch: 6| Step: 12
Training loss: 2.420449114022895
Validation loss: 2.602624797695973

Epoch: 6| Step: 13
Training loss: 3.150696958913106
Validation loss: 2.5981911715959316

Epoch: 16| Step: 0
Training loss: 2.82092920888889
Validation loss: 2.582238602146488

Epoch: 6| Step: 1
Training loss: 2.3417402678990267
Validation loss: 2.5819184437486635

Epoch: 6| Step: 2
Training loss: 2.570181428761734
Validation loss: 2.582123786507065

Epoch: 6| Step: 3
Training loss: 2.994805925860528
Validation loss: 2.5802383685461656

Epoch: 6| Step: 4
Training loss: 2.793177286112368
Validation loss: 2.5764085710875246

Epoch: 6| Step: 5
Training loss: 3.2195482467872902
Validation loss: 2.568331324477454

Epoch: 6| Step: 6
Training loss: 3.319887668134017
Validation loss: 2.567099751560553

Epoch: 6| Step: 7
Training loss: 3.0489821752500745
Validation loss: 2.5656337799489197

Epoch: 6| Step: 8
Training loss: 3.3552632563131377
Validation loss: 2.554916925970323

Epoch: 6| Step: 9
Training loss: 3.348511487576843
Validation loss: 2.5593990318338724

Epoch: 6| Step: 10
Training loss: 2.9779914369684186
Validation loss: 2.5634061930305667

Epoch: 6| Step: 11
Training loss: 2.930646652886893
Validation loss: 2.5478672088155334

Epoch: 6| Step: 12
Training loss: 2.7903454818938096
Validation loss: 2.5496860947126527

Epoch: 6| Step: 13
Training loss: 2.911280063000571
Validation loss: 2.5523161858281087

Epoch: 17| Step: 0
Training loss: 3.0520827951962426
Validation loss: 2.546039040717549

Epoch: 6| Step: 1
Training loss: 2.9760898805602043
Validation loss: 2.5361493620226963

Epoch: 6| Step: 2
Training loss: 3.3213087315188687
Validation loss: 2.5347305750225773

Epoch: 6| Step: 3
Training loss: 2.6048465197373796
Validation loss: 2.5253375424485793

Epoch: 6| Step: 4
Training loss: 2.4984551424950694
Validation loss: 2.5315939637781892

Epoch: 6| Step: 5
Training loss: 3.233819001548762
Validation loss: 2.526797401395521

Epoch: 6| Step: 6
Training loss: 2.387470233192423
Validation loss: 2.527821947887047

Epoch: 6| Step: 7
Training loss: 3.5258255877793294
Validation loss: 2.5246814925303025

Epoch: 6| Step: 8
Training loss: 2.692652708520654
Validation loss: 2.5361947129434586

Epoch: 6| Step: 9
Training loss: 2.991492606565612
Validation loss: 2.525701507578002

Epoch: 6| Step: 10
Training loss: 3.1175573602827775
Validation loss: 2.522777012114317

Epoch: 6| Step: 11
Training loss: 2.9103566350368517
Validation loss: 2.516301728447955

Epoch: 6| Step: 12
Training loss: 2.8120419447145926
Validation loss: 2.5148770410121064

Epoch: 6| Step: 13
Training loss: 2.974837636924821
Validation loss: 2.5213626606516146

Epoch: 18| Step: 0
Training loss: 3.1369627291186286
Validation loss: 2.519386874850479

Epoch: 6| Step: 1
Training loss: 3.055021067794854
Validation loss: 2.513635389081357

Epoch: 6| Step: 2
Training loss: 2.4668227773531206
Validation loss: 2.5118303712558303

Epoch: 6| Step: 3
Training loss: 2.8873397716637457
Validation loss: 2.515800580517747

Epoch: 6| Step: 4
Training loss: 2.8719167347263346
Validation loss: 2.5053202838779316

Epoch: 6| Step: 5
Training loss: 2.705355919851614
Validation loss: 2.5159816077728534

Epoch: 6| Step: 6
Training loss: 2.703426189952347
Validation loss: 2.5175103401720973

Epoch: 6| Step: 7
Training loss: 2.993372271765249
Validation loss: 2.500505347090659

Epoch: 6| Step: 8
Training loss: 3.0386284760969167
Validation loss: 2.5086528188141486

Epoch: 6| Step: 9
Training loss: 2.723871602901693
Validation loss: 2.5044569126337954

Epoch: 6| Step: 10
Training loss: 3.2904038401129845
Validation loss: 2.505010889791214

Epoch: 6| Step: 11
Training loss: 2.5155959986561016
Validation loss: 2.4965592333099647

Epoch: 6| Step: 12
Training loss: 3.476287213688366
Validation loss: 2.502064225955337

Epoch: 6| Step: 13
Training loss: 3.2474747163582705
Validation loss: 2.496667293587552

Epoch: 19| Step: 0
Training loss: 2.5244766788353665
Validation loss: 2.4924557073774727

Epoch: 6| Step: 1
Training loss: 2.5579948830989574
Validation loss: 2.4991412154161283

Epoch: 6| Step: 2
Training loss: 2.802446495450588
Validation loss: 2.495373037333124

Epoch: 6| Step: 3
Training loss: 3.132707170727787
Validation loss: 2.5055017107444244

Epoch: 6| Step: 4
Training loss: 2.6629090259123847
Validation loss: 2.5083427401495633

Epoch: 6| Step: 5
Training loss: 2.517279607980778
Validation loss: 2.5059547283727084

Epoch: 6| Step: 6
Training loss: 2.744001956571988
Validation loss: 2.5093338457814074

Epoch: 6| Step: 7
Training loss: 3.1961236124781274
Validation loss: 2.505222195587443

Epoch: 6| Step: 8
Training loss: 3.5089329754528946
Validation loss: 2.5062933172914192

Epoch: 6| Step: 9
Training loss: 2.6374924718378754
Validation loss: 2.504669480113787

Epoch: 6| Step: 10
Training loss: 2.586117556662152
Validation loss: 2.4992278690981684

Epoch: 6| Step: 11
Training loss: 3.6027798198640895
Validation loss: 2.5038508577279557

Epoch: 6| Step: 12
Training loss: 3.0279170324128404
Validation loss: 2.491322709933308

Epoch: 6| Step: 13
Training loss: 3.5155745439087616
Validation loss: 2.5022178779372046

Epoch: 20| Step: 0
Training loss: 2.0522232653418944
Validation loss: 2.4974817482802645

Epoch: 6| Step: 1
Training loss: 3.3130165992825304
Validation loss: 2.4973756100137336

Epoch: 6| Step: 2
Training loss: 3.081781065326824
Validation loss: 2.499000779294173

Epoch: 6| Step: 3
Training loss: 3.125066527612165
Validation loss: 2.500429017161981

Epoch: 6| Step: 4
Training loss: 3.025567145027898
Validation loss: 2.4947614472512036

Epoch: 6| Step: 5
Training loss: 3.258146932071855
Validation loss: 2.5017440116899348

Epoch: 6| Step: 6
Training loss: 3.2822621555549287
Validation loss: 2.4921516495343283

Epoch: 6| Step: 7
Training loss: 2.5796126264107264
Validation loss: 2.492780854149091

Epoch: 6| Step: 8
Training loss: 3.22532678175733
Validation loss: 2.4916282682402353

Epoch: 6| Step: 9
Training loss: 3.191318394024798
Validation loss: 2.493958390156784

Epoch: 6| Step: 10
Training loss: 1.8389703252699623
Validation loss: 2.494978248027402

Epoch: 6| Step: 11
Training loss: 2.822923123022675
Validation loss: 2.4757283873411224

Epoch: 6| Step: 12
Training loss: 2.988202741003008
Validation loss: 2.4934668330300624

Epoch: 6| Step: 13
Training loss: 2.5905068585706847
Validation loss: 2.4925831427232303

Epoch: 21| Step: 0
Training loss: 3.2330319477158236
Validation loss: 2.49324994298617

Epoch: 6| Step: 1
Training loss: 2.557615323118832
Validation loss: 2.484200605949392

Epoch: 6| Step: 2
Training loss: 3.109331600327224
Validation loss: 2.487997810497863

Epoch: 6| Step: 3
Training loss: 3.0030584639562803
Validation loss: 2.4882130199382675

Epoch: 6| Step: 4
Training loss: 2.952576439987993
Validation loss: 2.4904012415596775

Epoch: 6| Step: 5
Training loss: 2.564092559917203
Validation loss: 2.4949039428226594

Epoch: 6| Step: 6
Training loss: 3.0626567878292565
Validation loss: 2.488685850488296

Epoch: 6| Step: 7
Training loss: 3.1305299277405103
Validation loss: 2.4834735876040015

Epoch: 6| Step: 8
Training loss: 2.5404968905085465
Validation loss: 2.5027870230163134

Epoch: 6| Step: 9
Training loss: 2.5483208981051106
Validation loss: 2.491614941354938

Epoch: 6| Step: 10
Training loss: 3.096214160796472
Validation loss: 2.4871473909519852

Epoch: 6| Step: 11
Training loss: 3.2141848290975092
Validation loss: 2.4819898082742085

Epoch: 6| Step: 12
Training loss: 2.8683786854177717
Validation loss: 2.48393241235399

Epoch: 6| Step: 13
Training loss: 2.8354416090526655
Validation loss: 2.4911750801842536

Epoch: 22| Step: 0
Training loss: 2.489594357092378
Validation loss: 2.4783875211446595

Epoch: 6| Step: 1
Training loss: 3.110375938140356
Validation loss: 2.486357984817951

Epoch: 6| Step: 2
Training loss: 3.109021344032776
Validation loss: 2.4903124431844983

Epoch: 6| Step: 3
Training loss: 2.3351427850625406
Validation loss: 2.4838661905428405

Epoch: 6| Step: 4
Training loss: 3.1187941920755873
Validation loss: 2.4876490677683814

Epoch: 6| Step: 5
Training loss: 2.7273151047622024
Validation loss: 2.4976160865772363

Epoch: 6| Step: 6
Training loss: 3.1871198539687855
Validation loss: 2.489034107031042

Epoch: 6| Step: 7
Training loss: 2.3099284952829846
Validation loss: 2.492623780783132

Epoch: 6| Step: 8
Training loss: 2.7528338136518005
Validation loss: 2.488295462750896

Epoch: 6| Step: 9
Training loss: 2.7725608622248874
Validation loss: 2.4900952320607055

Epoch: 6| Step: 10
Training loss: 3.0956606118926278
Validation loss: 2.4847584296520955

Epoch: 6| Step: 11
Training loss: 3.575913324598557
Validation loss: 2.493788773191591

Epoch: 6| Step: 12
Training loss: 3.0007823877548447
Validation loss: 2.484826129866955

Epoch: 6| Step: 13
Training loss: 2.932604992638231
Validation loss: 2.4793080115274946

Epoch: 23| Step: 0
Training loss: 3.140057260999544
Validation loss: 2.483417915076007

Epoch: 6| Step: 1
Training loss: 3.020049964794615
Validation loss: 2.4903562693769534

Epoch: 6| Step: 2
Training loss: 2.8739980527357543
Validation loss: 2.4861402327905995

Epoch: 6| Step: 3
Training loss: 2.483965378106907
Validation loss: 2.483391373382718

Epoch: 6| Step: 4
Training loss: 2.9737697525939817
Validation loss: 2.4836516464601255

Epoch: 6| Step: 5
Training loss: 3.115243252828259
Validation loss: 2.494054965345269

Epoch: 6| Step: 6
Training loss: 2.8128822914554203
Validation loss: 2.4871064953947672

Epoch: 6| Step: 7
Training loss: 2.9647641378577556
Validation loss: 2.47541544793731

Epoch: 6| Step: 8
Training loss: 2.9267563461895727
Validation loss: 2.48194388523426

Epoch: 6| Step: 9
Training loss: 2.6133452950742315
Validation loss: 2.473211724790656

Epoch: 6| Step: 10
Training loss: 2.992489154639864
Validation loss: 2.4792087782642844

Epoch: 6| Step: 11
Training loss: 2.21669469925596
Validation loss: 2.4754972684030108

Epoch: 6| Step: 12
Training loss: 3.226336085616859
Validation loss: 2.4704624310243997

Epoch: 6| Step: 13
Training loss: 3.586107569964534
Validation loss: 2.478663369561856

Epoch: 24| Step: 0
Training loss: 2.812644954760648
Validation loss: 2.4875038964833682

Epoch: 6| Step: 1
Training loss: 3.402171922236169
Validation loss: 2.479023393017377

Epoch: 6| Step: 2
Training loss: 2.602534481996438
Validation loss: 2.485134360326775

Epoch: 6| Step: 3
Training loss: 3.182660336946677
Validation loss: 2.4879995292096257

Epoch: 6| Step: 4
Training loss: 2.427858700871804
Validation loss: 2.4814164437489463

Epoch: 6| Step: 5
Training loss: 3.5639313616410013
Validation loss: 2.4914538200762593

Epoch: 6| Step: 6
Training loss: 2.997863167468091
Validation loss: 2.4766285165057167

Epoch: 6| Step: 7
Training loss: 3.0618895876043095
Validation loss: 2.480133534735441

Epoch: 6| Step: 8
Training loss: 2.510741237905791
Validation loss: 2.4797975856393477

Epoch: 6| Step: 9
Training loss: 2.669347091453886
Validation loss: 2.473040115774016

Epoch: 6| Step: 10
Training loss: 2.313285178838535
Validation loss: 2.4876646320792384

Epoch: 6| Step: 11
Training loss: 3.351114025210264
Validation loss: 2.4812132020792657

Epoch: 6| Step: 12
Training loss: 2.6443920465116926
Validation loss: 2.4799328477760842

Epoch: 6| Step: 13
Training loss: 2.909782805579649
Validation loss: 2.482869250271477

Epoch: 25| Step: 0
Training loss: 2.7204063894512323
Validation loss: 2.47309895138279

Epoch: 6| Step: 1
Training loss: 2.5608384863266482
Validation loss: 2.480640637771967

Epoch: 6| Step: 2
Training loss: 2.9740862621221087
Validation loss: 2.4773955412252873

Epoch: 6| Step: 3
Training loss: 3.163880745647766
Validation loss: 2.479177403773607

Epoch: 6| Step: 4
Training loss: 3.273778055543474
Validation loss: 2.472346373666807

Epoch: 6| Step: 5
Training loss: 2.5557950386766386
Validation loss: 2.4746961868717294

Epoch: 6| Step: 6
Training loss: 3.311389233033309
Validation loss: 2.476180768977876

Epoch: 6| Step: 7
Training loss: 3.267843998354727
Validation loss: 2.488109452168026

Epoch: 6| Step: 8
Training loss: 2.7434182733369785
Validation loss: 2.4764796671108584

Epoch: 6| Step: 9
Training loss: 2.5582487616296024
Validation loss: 2.473699718660483

Epoch: 6| Step: 10
Training loss: 2.895681052469245
Validation loss: 2.4891962989761436

Epoch: 6| Step: 11
Training loss: 2.906063607094064
Validation loss: 2.477209284992751

Epoch: 6| Step: 12
Training loss: 2.5162645557662877
Validation loss: 2.481054253560909

Epoch: 6| Step: 13
Training loss: 3.2615345428897253
Validation loss: 2.484833657272402

Epoch: 26| Step: 0
Training loss: 2.8625274123832436
Validation loss: 2.4792094038680665

Epoch: 6| Step: 1
Training loss: 3.0380506228359763
Validation loss: 2.4668466944906275

Epoch: 6| Step: 2
Training loss: 3.0643594507472174
Validation loss: 2.4747582156852785

Epoch: 6| Step: 3
Training loss: 2.87101353124541
Validation loss: 2.477071160501196

Epoch: 6| Step: 4
Training loss: 2.688672719187994
Validation loss: 2.465941586041847

Epoch: 6| Step: 5
Training loss: 2.7148671979371852
Validation loss: 2.4766425456275223

Epoch: 6| Step: 6
Training loss: 3.138448236043135
Validation loss: 2.485766372508414

Epoch: 6| Step: 7
Training loss: 2.8477533687571293
Validation loss: 2.4690351527912586

Epoch: 6| Step: 8
Training loss: 2.5090496303595553
Validation loss: 2.474263387027485

Epoch: 6| Step: 9
Training loss: 2.5463916343283093
Validation loss: 2.473472622317889

Epoch: 6| Step: 10
Training loss: 2.5325712358523598
Validation loss: 2.4719566484705973

Epoch: 6| Step: 11
Training loss: 3.517357429049741
Validation loss: 2.4670918406143145

Epoch: 6| Step: 12
Training loss: 3.1897871002615705
Validation loss: 2.4800584084999087

Epoch: 6| Step: 13
Training loss: 2.6899239011019405
Validation loss: 2.4709077468167

Epoch: 27| Step: 0
Training loss: 2.6395654301888034
Validation loss: 2.472144579600488

Epoch: 6| Step: 1
Training loss: 2.970982725891207
Validation loss: 2.4749769727444244

Epoch: 6| Step: 2
Training loss: 2.5353748009849997
Validation loss: 2.471254612287753

Epoch: 6| Step: 3
Training loss: 2.4363923123534157
Validation loss: 2.468579934554005

Epoch: 6| Step: 4
Training loss: 2.533006976672601
Validation loss: 2.470175721223979

Epoch: 6| Step: 5
Training loss: 3.381700575276107
Validation loss: 2.470149196034458

Epoch: 6| Step: 6
Training loss: 2.76469034899572
Validation loss: 2.472624664838443

Epoch: 6| Step: 7
Training loss: 3.361705167061654
Validation loss: 2.462691636096132

Epoch: 6| Step: 8
Training loss: 3.1401427548753404
Validation loss: 2.462908975085035

Epoch: 6| Step: 9
Training loss: 3.1056439428275713
Validation loss: 2.4710603907614925

Epoch: 6| Step: 10
Training loss: 2.948413299315675
Validation loss: 2.4647384799709164

Epoch: 6| Step: 11
Training loss: 2.71174376533068
Validation loss: 2.4607295101915967

Epoch: 6| Step: 12
Training loss: 2.428861716896853
Validation loss: 2.4729913799593324

Epoch: 6| Step: 13
Training loss: 3.605304354704505
Validation loss: 2.47664113060792

Epoch: 28| Step: 0
Training loss: 2.3865863869483004
Validation loss: 2.4660927347884574

Epoch: 6| Step: 1
Training loss: 2.886046541691264
Validation loss: 2.4720631324673588

Epoch: 6| Step: 2
Training loss: 2.5615867289883814
Validation loss: 2.4635720709751454

Epoch: 6| Step: 3
Training loss: 2.6264035242046004
Validation loss: 2.4688905214105215

Epoch: 6| Step: 4
Training loss: 3.244100057128951
Validation loss: 2.4667469090040064

Epoch: 6| Step: 5
Training loss: 2.575907267761344
Validation loss: 2.466748207064338

Epoch: 6| Step: 6
Training loss: 2.8492967775338607
Validation loss: 2.465507532744925

Epoch: 6| Step: 7
Training loss: 2.5594346855758996
Validation loss: 2.4708728233138992

Epoch: 6| Step: 8
Training loss: 3.521561692119536
Validation loss: 2.4639124486017048

Epoch: 6| Step: 9
Training loss: 2.4657726441865244
Validation loss: 2.457730184000271

Epoch: 6| Step: 10
Training loss: 3.4183661878306726
Validation loss: 2.4667781713864607

Epoch: 6| Step: 11
Training loss: 3.405619711701167
Validation loss: 2.465493196947638

Epoch: 6| Step: 12
Training loss: 2.5200468260335187
Validation loss: 2.461919451325699

Epoch: 6| Step: 13
Training loss: 3.2729175673656976
Validation loss: 2.462279547061955

Epoch: 29| Step: 0
Training loss: 2.4000836914093315
Validation loss: 2.4636719507123916

Epoch: 6| Step: 1
Training loss: 2.541098567655728
Validation loss: 2.4659597845117482

Epoch: 6| Step: 2
Training loss: 3.1310658901400394
Validation loss: 2.4639620080342044

Epoch: 6| Step: 3
Training loss: 3.0559182577934623
Validation loss: 2.4598320997592564

Epoch: 6| Step: 4
Training loss: 2.606399850173721
Validation loss: 2.460456340921052

Epoch: 6| Step: 5
Training loss: 3.1472286809765393
Validation loss: 2.463655833160832

Epoch: 6| Step: 6
Training loss: 3.3847540730291907
Validation loss: 2.456324617179884

Epoch: 6| Step: 7
Training loss: 2.763969399979793
Validation loss: 2.455590016988407

Epoch: 6| Step: 8
Training loss: 2.2205455123542333
Validation loss: 2.457061917113136

Epoch: 6| Step: 9
Training loss: 2.3422680047611824
Validation loss: 2.4640846079937675

Epoch: 6| Step: 10
Training loss: 3.210652805153759
Validation loss: 2.4606630046245344

Epoch: 6| Step: 11
Training loss: 2.8216999054550986
Validation loss: 2.4672973219748666

Epoch: 6| Step: 12
Training loss: 3.1342567672565154
Validation loss: 2.4659241089387023

Epoch: 6| Step: 13
Training loss: 3.457091663931859
Validation loss: 2.4713983532572823

Epoch: 30| Step: 0
Training loss: 3.0600262986094013
Validation loss: 2.4609573053545186

Epoch: 6| Step: 1
Training loss: 2.776520554757557
Validation loss: 2.4628521829554186

Epoch: 6| Step: 2
Training loss: 3.0321320499058753
Validation loss: 2.451763119127198

Epoch: 6| Step: 3
Training loss: 2.724556783626616
Validation loss: 2.455511673836341

Epoch: 6| Step: 4
Training loss: 2.4758709925874642
Validation loss: 2.4590432435315956

Epoch: 6| Step: 5
Training loss: 3.0280998614737147
Validation loss: 2.4635426087854504

Epoch: 6| Step: 6
Training loss: 2.8086805051687076
Validation loss: 2.4579347478881854

Epoch: 6| Step: 7
Training loss: 2.88376425975619
Validation loss: 2.4707258305237305

Epoch: 6| Step: 8
Training loss: 2.3739856762474014
Validation loss: 2.456598592357011

Epoch: 6| Step: 9
Training loss: 2.9454582036656056
Validation loss: 2.456820506539087

Epoch: 6| Step: 10
Training loss: 2.5098279418333482
Validation loss: 2.4564105864811685

Epoch: 6| Step: 11
Training loss: 3.2854575655142653
Validation loss: 2.4660899976369124

Epoch: 6| Step: 12
Training loss: 3.447429119263895
Validation loss: 2.463697483220606

Epoch: 6| Step: 13
Training loss: 2.674157756942341
Validation loss: 2.4508534339859613

Epoch: 31| Step: 0
Training loss: 1.9785474979887354
Validation loss: 2.4537904880581314

Epoch: 6| Step: 1
Training loss: 2.8945526657650738
Validation loss: 2.4619839819875913

Epoch: 6| Step: 2
Training loss: 2.6689160118909383
Validation loss: 2.4579969863959237

Epoch: 6| Step: 3
Training loss: 3.2012615458955382
Validation loss: 2.46010541129133

Epoch: 6| Step: 4
Training loss: 2.910624339714082
Validation loss: 2.4598235203417764

Epoch: 6| Step: 5
Training loss: 3.1123405385054688
Validation loss: 2.466719098754718

Epoch: 6| Step: 6
Training loss: 3.058805767715462
Validation loss: 2.4612483106824734

Epoch: 6| Step: 7
Training loss: 3.1272510813111127
Validation loss: 2.4638174159760386

Epoch: 6| Step: 8
Training loss: 2.7515346406547647
Validation loss: 2.4630693339589267

Epoch: 6| Step: 9
Training loss: 3.6135672131351333
Validation loss: 2.4542736120488686

Epoch: 6| Step: 10
Training loss: 3.208155556909849
Validation loss: 2.451209746155118

Epoch: 6| Step: 11
Training loss: 2.7409879228840093
Validation loss: 2.460787669183331

Epoch: 6| Step: 12
Training loss: 2.4409095197799613
Validation loss: 2.4552282969337225

Epoch: 6| Step: 13
Training loss: 1.5273626380006173
Validation loss: 2.451300893905758

Epoch: 32| Step: 0
Training loss: 3.470429434903768
Validation loss: 2.4620979990998997

Epoch: 6| Step: 1
Training loss: 2.9651729516572463
Validation loss: 2.4587472372893835

Epoch: 6| Step: 2
Training loss: 3.3067156112289005
Validation loss: 2.4597696367053596

Epoch: 6| Step: 3
Training loss: 2.4745880824545177
Validation loss: 2.4581518264375086

Epoch: 6| Step: 4
Training loss: 2.713988771903103
Validation loss: 2.468076270018894

Epoch: 6| Step: 5
Training loss: 2.9529674023754797
Validation loss: 2.4539917741181947

Epoch: 6| Step: 6
Training loss: 2.9185899841751564
Validation loss: 2.4601201077818637

Epoch: 6| Step: 7
Training loss: 2.4322600161816412
Validation loss: 2.4616961753677806

Epoch: 6| Step: 8
Training loss: 2.2984930035640443
Validation loss: 2.4529126333175606

Epoch: 6| Step: 9
Training loss: 2.734455390838341
Validation loss: 2.4519199609199194

Epoch: 6| Step: 10
Training loss: 2.8755913831092736
Validation loss: 2.4611804660566894

Epoch: 6| Step: 11
Training loss: 2.83053149270397
Validation loss: 2.4565558806187555

Epoch: 6| Step: 12
Training loss: 3.112514731743814
Validation loss: 2.4550319867687747

Epoch: 6| Step: 13
Training loss: 3.011092817322111
Validation loss: 2.4562574569186912

Epoch: 33| Step: 0
Training loss: 3.01375604933484
Validation loss: 2.4591601152736184

Epoch: 6| Step: 1
Training loss: 3.0207510750631403
Validation loss: 2.4586955363843557

Epoch: 6| Step: 2
Training loss: 3.0647585578647742
Validation loss: 2.4467132025789984

Epoch: 6| Step: 3
Training loss: 2.928605106040496
Validation loss: 2.4571900539686413

Epoch: 6| Step: 4
Training loss: 3.0941992539479943
Validation loss: 2.4483781374802636

Epoch: 6| Step: 5
Training loss: 2.531382616124783
Validation loss: 2.452465547955191

Epoch: 6| Step: 6
Training loss: 3.0890751206984848
Validation loss: 2.462422707327788

Epoch: 6| Step: 7
Training loss: 2.9949442860511266
Validation loss: 2.4559150371172453

Epoch: 6| Step: 8
Training loss: 2.995649043654651
Validation loss: 2.4603908386761466

Epoch: 6| Step: 9
Training loss: 2.8505088218093433
Validation loss: 2.471710506842536

Epoch: 6| Step: 10
Training loss: 2.417671444167834
Validation loss: 2.4624459832026546

Epoch: 6| Step: 11
Training loss: 2.7950383981104125
Validation loss: 2.460408573374021

Epoch: 6| Step: 12
Training loss: 2.662889686686152
Validation loss: 2.4498831121082634

Epoch: 6| Step: 13
Training loss: 2.3967596391870187
Validation loss: 2.4616166299709628

Epoch: 34| Step: 0
Training loss: 2.49157458574308
Validation loss: 2.458144067146066

Epoch: 6| Step: 1
Training loss: 2.6622518611847363
Validation loss: 2.460645666103295

Epoch: 6| Step: 2
Training loss: 2.899923185449288
Validation loss: 2.468523034031041

Epoch: 6| Step: 3
Training loss: 2.1176780892417386
Validation loss: 2.452043021826986

Epoch: 6| Step: 4
Training loss: 3.2551142727295814
Validation loss: 2.449845013248135

Epoch: 6| Step: 5
Training loss: 2.8019498677476102
Validation loss: 2.454807496404354

Epoch: 6| Step: 6
Training loss: 2.8816434976305665
Validation loss: 2.4711090017806936

Epoch: 6| Step: 7
Training loss: 3.3031136302337285
Validation loss: 2.4651351087476505

Epoch: 6| Step: 8
Training loss: 3.0646172814441406
Validation loss: 2.457498610663487

Epoch: 6| Step: 9
Training loss: 2.911244684249722
Validation loss: 2.4503297835383395

Epoch: 6| Step: 10
Training loss: 2.3275821744218876
Validation loss: 2.455270207941888

Epoch: 6| Step: 11
Training loss: 3.0189724857963043
Validation loss: 2.45995473984465

Epoch: 6| Step: 12
Training loss: 3.172420811788353
Validation loss: 2.4360700114334355

Epoch: 6| Step: 13
Training loss: 2.9833982776697994
Validation loss: 2.4529862530207747

Epoch: 35| Step: 0
Training loss: 2.57121339911938
Validation loss: 2.44369183982473

Epoch: 6| Step: 1
Training loss: 2.316930393146456
Validation loss: 2.452247028297507

Epoch: 6| Step: 2
Training loss: 3.2811610618527034
Validation loss: 2.444547740471249

Epoch: 6| Step: 3
Training loss: 2.930448143443445
Validation loss: 2.451640923590361

Epoch: 6| Step: 4
Training loss: 3.1403441042566733
Validation loss: 2.447242995653808

Epoch: 6| Step: 5
Training loss: 2.694263021734449
Validation loss: 2.445479379087775

Epoch: 6| Step: 6
Training loss: 2.6392874857264057
Validation loss: 2.459203381200332

Epoch: 6| Step: 7
Training loss: 2.410084035524192
Validation loss: 2.4443154762067207

Epoch: 6| Step: 8
Training loss: 3.3137647985173264
Validation loss: 2.451924418157623

Epoch: 6| Step: 9
Training loss: 2.4595471526680495
Validation loss: 2.4555002990464287

Epoch: 6| Step: 10
Training loss: 3.7295140507754683
Validation loss: 2.454028184144164

Epoch: 6| Step: 11
Training loss: 2.5486258824815735
Validation loss: 2.4563249355052137

Epoch: 6| Step: 12
Training loss: 2.784566466387757
Validation loss: 2.457899647357382

Epoch: 6| Step: 13
Training loss: 2.6716708278167487
Validation loss: 2.4522392409134484

Epoch: 36| Step: 0
Training loss: 3.16130205466785
Validation loss: 2.4464763015995525

Epoch: 6| Step: 1
Training loss: 2.864994384866641
Validation loss: 2.4551702693829593

Epoch: 6| Step: 2
Training loss: 3.1356716284688475
Validation loss: 2.4524433491850703

Epoch: 6| Step: 3
Training loss: 3.070645146877443
Validation loss: 2.4511580734802405

Epoch: 6| Step: 4
Training loss: 3.3397105407919496
Validation loss: 2.440213047423303

Epoch: 6| Step: 5
Training loss: 2.6084794203663195
Validation loss: 2.4439992907960972

Epoch: 6| Step: 6
Training loss: 2.3349207065359945
Validation loss: 2.456204310212479

Epoch: 6| Step: 7
Training loss: 2.6185681701026247
Validation loss: 2.4523873370609754

Epoch: 6| Step: 8
Training loss: 3.0892492366183837
Validation loss: 2.4385633513018647

Epoch: 6| Step: 9
Training loss: 2.7915109524547024
Validation loss: 2.4505307701041623

Epoch: 6| Step: 10
Training loss: 2.712312816718393
Validation loss: 2.4414075667839192

Epoch: 6| Step: 11
Training loss: 2.686565325350472
Validation loss: 2.441856175989557

Epoch: 6| Step: 12
Training loss: 2.728480235739315
Validation loss: 2.442634996149001

Epoch: 6| Step: 13
Training loss: 2.3262335755487356
Validation loss: 2.446267637681704

Epoch: 37| Step: 0
Training loss: 2.90896332119622
Validation loss: 2.450132470884755

Epoch: 6| Step: 1
Training loss: 3.510206870913925
Validation loss: 2.4441443357269184

Epoch: 6| Step: 2
Training loss: 2.8550428915726864
Validation loss: 2.4545501609362965

Epoch: 6| Step: 3
Training loss: 2.265453568911596
Validation loss: 2.4384875982734293

Epoch: 6| Step: 4
Training loss: 2.585586754560064
Validation loss: 2.4473082076621053

Epoch: 6| Step: 5
Training loss: 3.047442574089068
Validation loss: 2.453895584197506

Epoch: 6| Step: 6
Training loss: 3.2394067812256133
Validation loss: 2.4356881278894376

Epoch: 6| Step: 7
Training loss: 2.918413202429907
Validation loss: 2.4463117258215266

Epoch: 6| Step: 8
Training loss: 3.26460578746819
Validation loss: 2.4399864445132784

Epoch: 6| Step: 9
Training loss: 2.671481990352971
Validation loss: 2.446946708112402

Epoch: 6| Step: 10
Training loss: 2.4661012757628864
Validation loss: 2.4426444220403685

Epoch: 6| Step: 11
Training loss: 2.7152387372847455
Validation loss: 2.4421727501391093

Epoch: 6| Step: 12
Training loss: 2.5618488135654873
Validation loss: 2.4384920474727116

Epoch: 6| Step: 13
Training loss: 2.3026718377057303
Validation loss: 2.445255281361503

Epoch: 38| Step: 0
Training loss: 3.070284544839337
Validation loss: 2.4580918247844155

Epoch: 6| Step: 1
Training loss: 2.82038477754836
Validation loss: 2.4474614833991333

Epoch: 6| Step: 2
Training loss: 2.6666973430140666
Validation loss: 2.451571860446162

Epoch: 6| Step: 3
Training loss: 3.0620521685082402
Validation loss: 2.446577521590084

Epoch: 6| Step: 4
Training loss: 2.8984509902187745
Validation loss: 2.4396160397146813

Epoch: 6| Step: 5
Training loss: 2.7863126817706054
Validation loss: 2.440924497789853

Epoch: 6| Step: 6
Training loss: 3.023382930608158
Validation loss: 2.451974834671124

Epoch: 6| Step: 7
Training loss: 3.0320873873555403
Validation loss: 2.4361549907225717

Epoch: 6| Step: 8
Training loss: 2.5958178446773497
Validation loss: 2.4341484273471026

Epoch: 6| Step: 9
Training loss: 2.2201950310619445
Validation loss: 2.443555581118694

Epoch: 6| Step: 10
Training loss: 3.286939647188962
Validation loss: 2.4438635451523045

Epoch: 6| Step: 11
Training loss: 2.970328624025394
Validation loss: 2.433540464405269

Epoch: 6| Step: 12
Training loss: 2.6525066252687712
Validation loss: 2.4480569359870405

Epoch: 6| Step: 13
Training loss: 2.263615104746773
Validation loss: 2.4387206961606442

Epoch: 39| Step: 0
Training loss: 3.1575807089016013
Validation loss: 2.4423031671097695

Epoch: 6| Step: 1
Training loss: 2.593403620743962
Validation loss: 2.4317138239143845

Epoch: 6| Step: 2
Training loss: 3.072192211207655
Validation loss: 2.4376150986994922

Epoch: 6| Step: 3
Training loss: 2.67856104894171
Validation loss: 2.451546002963735

Epoch: 6| Step: 4
Training loss: 3.2375631790182515
Validation loss: 2.4408678532058015

Epoch: 6| Step: 5
Training loss: 2.6668955486141592
Validation loss: 2.4358749020728925

Epoch: 6| Step: 6
Training loss: 2.290303697729197
Validation loss: 2.4288859212859784

Epoch: 6| Step: 7
Training loss: 3.0595430384496924
Validation loss: 2.434239204489691

Epoch: 6| Step: 8
Training loss: 2.897244518954571
Validation loss: 2.436011330721109

Epoch: 6| Step: 9
Training loss: 2.993365581256616
Validation loss: 2.440175967422453

Epoch: 6| Step: 10
Training loss: 2.6706733008975383
Validation loss: 2.433803771233365

Epoch: 6| Step: 11
Training loss: 2.809643630104365
Validation loss: 2.4414604202659667

Epoch: 6| Step: 12
Training loss: 2.825417249805424
Validation loss: 2.443881823057992

Epoch: 6| Step: 13
Training loss: 2.5781885312662234
Validation loss: 2.4354663165874486

Epoch: 40| Step: 0
Training loss: 2.9129413974261253
Validation loss: 2.449939157418172

Epoch: 6| Step: 1
Training loss: 3.0868320375748084
Validation loss: 2.42786398261102

Epoch: 6| Step: 2
Training loss: 3.2608678016104973
Validation loss: 2.433626552791237

Epoch: 6| Step: 3
Training loss: 3.2395573622141915
Validation loss: 2.4411118627115878

Epoch: 6| Step: 4
Training loss: 2.765774480368442
Validation loss: 2.441854126635189

Epoch: 6| Step: 5
Training loss: 2.602490050693516
Validation loss: 2.449162092608598

Epoch: 6| Step: 6
Training loss: 3.1697443679120494
Validation loss: 2.4406376089670268

Epoch: 6| Step: 7
Training loss: 2.654001159138775
Validation loss: 2.4452349347002826

Epoch: 6| Step: 8
Training loss: 2.4322107098739085
Validation loss: 2.445577046851108

Epoch: 6| Step: 9
Training loss: 2.6353443321785313
Validation loss: 2.4403267249570115

Epoch: 6| Step: 10
Training loss: 3.143026771550336
Validation loss: 2.4438163622636178

Epoch: 6| Step: 11
Training loss: 2.550043674169786
Validation loss: 2.4397342203708523

Epoch: 6| Step: 12
Training loss: 2.882228719844012
Validation loss: 2.4527943026852514

Epoch: 6| Step: 13
Training loss: 1.5867763612131234
Validation loss: 2.443552046551437

Epoch: 41| Step: 0
Training loss: 3.193446577555537
Validation loss: 2.4546252292139736

Epoch: 6| Step: 1
Training loss: 3.1714161508088665
Validation loss: 2.4423831872240735

Epoch: 6| Step: 2
Training loss: 2.620329016199532
Validation loss: 2.440374764249265

Epoch: 6| Step: 3
Training loss: 2.97086780701084
Validation loss: 2.450507013849215

Epoch: 6| Step: 4
Training loss: 2.441219328781882
Validation loss: 2.4478585551600758

Epoch: 6| Step: 5
Training loss: 2.726624758646281
Validation loss: 2.4433451421831403

Epoch: 6| Step: 6
Training loss: 2.9074601145900743
Validation loss: 2.4528132843411448

Epoch: 6| Step: 7
Training loss: 3.004688572796627
Validation loss: 2.444327472550858

Epoch: 6| Step: 8
Training loss: 2.895406531481192
Validation loss: 2.436869713063105

Epoch: 6| Step: 9
Training loss: 2.954147888324779
Validation loss: 2.449936467096793

Epoch: 6| Step: 10
Training loss: 2.8997395102482777
Validation loss: 2.442140905090733

Epoch: 6| Step: 11
Training loss: 2.1111386308493696
Validation loss: 2.439445498549226

Epoch: 6| Step: 12
Training loss: 2.1827401828459903
Validation loss: 2.440757226399772

Epoch: 6| Step: 13
Training loss: 3.6194854094486173
Validation loss: 2.42945277036381

Epoch: 42| Step: 0
Training loss: 2.6017049114667286
Validation loss: 2.4355478318072383

Epoch: 6| Step: 1
Training loss: 2.515771897096439
Validation loss: 2.439269652695769

Epoch: 6| Step: 2
Training loss: 2.604826474844398
Validation loss: 2.4441598424800883

Epoch: 6| Step: 3
Training loss: 2.677990078281658
Validation loss: 2.444015046020895

Epoch: 6| Step: 4
Training loss: 2.107204196212634
Validation loss: 2.435289071751743

Epoch: 6| Step: 5
Training loss: 2.749102359268982
Validation loss: 2.4423232757769227

Epoch: 6| Step: 6
Training loss: 2.6745392304497693
Validation loss: 2.4363528871491837

Epoch: 6| Step: 7
Training loss: 3.0182594295604974
Validation loss: 2.4296326821172736

Epoch: 6| Step: 8
Training loss: 3.587732335452584
Validation loss: 2.4330917317543923

Epoch: 6| Step: 9
Training loss: 2.8884569440197745
Validation loss: 2.4285747310553583

Epoch: 6| Step: 10
Training loss: 3.091917477808099
Validation loss: 2.4283279821675996

Epoch: 6| Step: 11
Training loss: 3.431020560176022
Validation loss: 2.433765930490722

Epoch: 6| Step: 12
Training loss: 2.902298733142639
Validation loss: 2.4329848897882593

Epoch: 6| Step: 13
Training loss: 2.146409398748839
Validation loss: 2.4308698557803483

Epoch: 43| Step: 0
Training loss: 3.0860819722411925
Validation loss: 2.425147053748911

Epoch: 6| Step: 1
Training loss: 2.7532243033089503
Validation loss: 2.4441051719265037

Epoch: 6| Step: 2
Training loss: 2.769574981473318
Validation loss: 2.433868987304445

Epoch: 6| Step: 3
Training loss: 2.5598520693655153
Validation loss: 2.4331818766397237

Epoch: 6| Step: 4
Training loss: 2.761162298492601
Validation loss: 2.4291633478728536

Epoch: 6| Step: 5
Training loss: 3.3437628344708417
Validation loss: 2.426893894858841

Epoch: 6| Step: 6
Training loss: 2.600015816273633
Validation loss: 2.4265663028985673

Epoch: 6| Step: 7
Training loss: 2.9369285514643098
Validation loss: 2.4298863588902844

Epoch: 6| Step: 8
Training loss: 2.3205971077687035
Validation loss: 2.427612640605227

Epoch: 6| Step: 9
Training loss: 2.6581390844026216
Validation loss: 2.432504210966172

Epoch: 6| Step: 10
Training loss: 3.067873230902586
Validation loss: 2.429432192162672

Epoch: 6| Step: 11
Training loss: 2.8962892864066943
Validation loss: 2.4328382443191137

Epoch: 6| Step: 12
Training loss: 2.6357603690844287
Validation loss: 2.4372304320853733

Epoch: 6| Step: 13
Training loss: 3.1023430983024687
Validation loss: 2.436407992607216

Epoch: 44| Step: 0
Training loss: 2.7612476945334707
Validation loss: 2.4354013380316712

Epoch: 6| Step: 1
Training loss: 3.041213189030459
Validation loss: 2.443468462879908

Epoch: 6| Step: 2
Training loss: 2.157378744384586
Validation loss: 2.426783147087771

Epoch: 6| Step: 3
Training loss: 3.117397062289263
Validation loss: 2.4318480761150223

Epoch: 6| Step: 4
Training loss: 2.602850517831608
Validation loss: 2.425134888527679

Epoch: 6| Step: 5
Training loss: 3.1914657157671287
Validation loss: 2.4343099646798394

Epoch: 6| Step: 6
Training loss: 2.755770697407212
Validation loss: 2.436393220426161

Epoch: 6| Step: 7
Training loss: 3.2762328528254243
Validation loss: 2.4291607041958474

Epoch: 6| Step: 8
Training loss: 2.606595780741323
Validation loss: 2.4366176702658975

Epoch: 6| Step: 9
Training loss: 3.017467351071543
Validation loss: 2.430132338735417

Epoch: 6| Step: 10
Training loss: 2.8156525639106715
Validation loss: 2.435397009504994

Epoch: 6| Step: 11
Training loss: 2.473747121260839
Validation loss: 2.4217389330845935

Epoch: 6| Step: 12
Training loss: 2.2630086590461755
Validation loss: 2.423880684905199

Epoch: 6| Step: 13
Training loss: 3.1977337382098967
Validation loss: 2.434902526800644

Epoch: 45| Step: 0
Training loss: 3.118445885762913
Validation loss: 2.428399341102027

Epoch: 6| Step: 1
Training loss: 2.9710880107959623
Validation loss: 2.4277392092748142

Epoch: 6| Step: 2
Training loss: 2.7857718409367016
Validation loss: 2.436202571389572

Epoch: 6| Step: 3
Training loss: 2.635051737210463
Validation loss: 2.433192721490456

Epoch: 6| Step: 4
Training loss: 2.2786238721969987
Validation loss: 2.4357860209068627

Epoch: 6| Step: 5
Training loss: 2.6879301392298363
Validation loss: 2.433670140979461

Epoch: 6| Step: 6
Training loss: 2.92943944262346
Validation loss: 2.443264149424159

Epoch: 6| Step: 7
Training loss: 2.926788930692512
Validation loss: 2.431975656646291

Epoch: 6| Step: 8
Training loss: 2.800346564234823
Validation loss: 2.4241756958047898

Epoch: 6| Step: 9
Training loss: 2.4642922438856854
Validation loss: 2.420113678403533

Epoch: 6| Step: 10
Training loss: 3.190063791862913
Validation loss: 2.4304552276890505

Epoch: 6| Step: 11
Training loss: 2.591267512290359
Validation loss: 2.4287694789911

Epoch: 6| Step: 12
Training loss: 2.977332628800405
Validation loss: 2.429892807319741

Epoch: 6| Step: 13
Training loss: 3.0389454483202245
Validation loss: 2.4170643971034296

Epoch: 46| Step: 0
Training loss: 3.108575152552201
Validation loss: 2.4298513627794858

Epoch: 6| Step: 1
Training loss: 2.8049928291759527
Validation loss: 2.430816487273388

Epoch: 6| Step: 2
Training loss: 2.725369342656889
Validation loss: 2.4353326007085814

Epoch: 6| Step: 3
Training loss: 3.3815434919034058
Validation loss: 2.438195324238826

Epoch: 6| Step: 4
Training loss: 2.7052450521036264
Validation loss: 2.4231576963688606

Epoch: 6| Step: 5
Training loss: 2.380888415340221
Validation loss: 2.4238686169793104

Epoch: 6| Step: 6
Training loss: 2.8665198606411564
Validation loss: 2.432308885136106

Epoch: 6| Step: 7
Training loss: 2.7506302198114776
Validation loss: 2.4249739568233943

Epoch: 6| Step: 8
Training loss: 2.6880517437586695
Validation loss: 2.4271010487516533

Epoch: 6| Step: 9
Training loss: 2.3848218106736088
Validation loss: 2.415750016401119

Epoch: 6| Step: 10
Training loss: 3.1281908148397615
Validation loss: 2.4371859135400036

Epoch: 6| Step: 11
Training loss: 2.8889103933495797
Validation loss: 2.4243119252188916

Epoch: 6| Step: 12
Training loss: 2.2984422799066544
Validation loss: 2.432944212342692

Epoch: 6| Step: 13
Training loss: 3.10206426986531
Validation loss: 2.4398063568724275

Epoch: 47| Step: 0
Training loss: 2.6635380113974683
Validation loss: 2.440443247153679

Epoch: 6| Step: 1
Training loss: 2.5077784645884518
Validation loss: 2.438980698241688

Epoch: 6| Step: 2
Training loss: 2.5700600914664973
Validation loss: 2.433311339487002

Epoch: 6| Step: 3
Training loss: 3.2221207237335148
Validation loss: 2.423886387798964

Epoch: 6| Step: 4
Training loss: 3.1275172966616775
Validation loss: 2.4209570228318755

Epoch: 6| Step: 5
Training loss: 2.6152491437339713
Validation loss: 2.4286637747957087

Epoch: 6| Step: 6
Training loss: 3.319405609144875
Validation loss: 2.4348438137398802

Epoch: 6| Step: 7
Training loss: 2.7461084227081782
Validation loss: 2.431599270345041

Epoch: 6| Step: 8
Training loss: 2.736327079429672
Validation loss: 2.4299057964430597

Epoch: 6| Step: 9
Training loss: 2.947604878430646
Validation loss: 2.4341593026469686

Epoch: 6| Step: 10
Training loss: 2.4140672405900054
Validation loss: 2.422227040141756

Epoch: 6| Step: 11
Training loss: 2.4930093301108065
Validation loss: 2.424070235474833

Epoch: 6| Step: 12
Training loss: 3.3681908194700467
Validation loss: 2.431444839678706

Epoch: 6| Step: 13
Training loss: 1.9083436193841414
Validation loss: 2.4343517040077542

Epoch: 48| Step: 0
Training loss: 3.151604283235043
Validation loss: 2.4403133133069344

Epoch: 6| Step: 1
Training loss: 2.639299590514728
Validation loss: 2.437074746688296

Epoch: 6| Step: 2
Training loss: 3.3628533386864565
Validation loss: 2.427356823039564

Epoch: 6| Step: 3
Training loss: 2.3850339446461257
Validation loss: 2.4244602511435676

Epoch: 6| Step: 4
Training loss: 2.970822062923531
Validation loss: 2.435081092604542

Epoch: 6| Step: 5
Training loss: 2.829961191187598
Validation loss: 2.424940416411526

Epoch: 6| Step: 6
Training loss: 2.8265769473118376
Validation loss: 2.430664690051131

Epoch: 6| Step: 7
Training loss: 2.481286005868715
Validation loss: 2.4178927101131613

Epoch: 6| Step: 8
Training loss: 2.4888986154018053
Validation loss: 2.4290990745731564

Epoch: 6| Step: 9
Training loss: 2.491191796648341
Validation loss: 2.427953458933566

Epoch: 6| Step: 10
Training loss: 2.55667177185716
Validation loss: 2.429703639242978

Epoch: 6| Step: 11
Training loss: 3.2532178647494394
Validation loss: 2.426220647899736

Epoch: 6| Step: 12
Training loss: 2.415707222352236
Validation loss: 2.424855128156685

Epoch: 6| Step: 13
Training loss: 3.3455248249063914
Validation loss: 2.4253744797190557

Epoch: 49| Step: 0
Training loss: 2.0936630003205225
Validation loss: 2.4300273125716867

Epoch: 6| Step: 1
Training loss: 3.1372987963840755
Validation loss: 2.439174832909857

Epoch: 6| Step: 2
Training loss: 2.8527516850961367
Validation loss: 2.4274721988519614

Epoch: 6| Step: 3
Training loss: 2.1686188144198737
Validation loss: 2.424600375694198

Epoch: 6| Step: 4
Training loss: 2.4841128037005062
Validation loss: 2.4166601737518274

Epoch: 6| Step: 5
Training loss: 2.6086338840994863
Validation loss: 2.4220115186498115

Epoch: 6| Step: 6
Training loss: 2.6419717638584617
Validation loss: 2.4331666286535856

Epoch: 6| Step: 7
Training loss: 3.377959472666096
Validation loss: 2.426631448306033

Epoch: 6| Step: 8
Training loss: 2.9413939294645686
Validation loss: 2.415802824220681

Epoch: 6| Step: 9
Training loss: 2.762301241943955
Validation loss: 2.425898327131599

Epoch: 6| Step: 10
Training loss: 2.9836570315506084
Validation loss: 2.4250440797984885

Epoch: 6| Step: 11
Training loss: 3.0910495570593457
Validation loss: 2.4263979265160165

Epoch: 6| Step: 12
Training loss: 2.9396748709445393
Validation loss: 2.4147034858154472

Epoch: 6| Step: 13
Training loss: 2.864888862731115
Validation loss: 2.4342771142281387

Epoch: 50| Step: 0
Training loss: 2.8763008491832363
Validation loss: 2.4168776277564494

Epoch: 6| Step: 1
Training loss: 2.9577319827962207
Validation loss: 2.4238679252664

Epoch: 6| Step: 2
Training loss: 2.6148602059162505
Validation loss: 2.424201058434997

Epoch: 6| Step: 3
Training loss: 2.7779583257703484
Validation loss: 2.4234551690850306

Epoch: 6| Step: 4
Training loss: 2.3817514527349366
Validation loss: 2.4185199512513034

Epoch: 6| Step: 5
Training loss: 2.333678515197087
Validation loss: 2.426611643813886

Epoch: 6| Step: 6
Training loss: 2.9159551206675096
Validation loss: 2.4379225186688283

Epoch: 6| Step: 7
Training loss: 2.7635823265638026
Validation loss: 2.4164810450606478

Epoch: 6| Step: 8
Training loss: 2.8021605432548937
Validation loss: 2.4117884603417985

Epoch: 6| Step: 9
Training loss: 2.8277297613151338
Validation loss: 2.428322519852927

Epoch: 6| Step: 10
Training loss: 3.004476069065114
Validation loss: 2.4176190939011697

Epoch: 6| Step: 11
Training loss: 2.6700856424376465
Validation loss: 2.4129950524931965

Epoch: 6| Step: 12
Training loss: 2.9818424044130603
Validation loss: 2.420204209227483

Epoch: 6| Step: 13
Training loss: 3.3767005027238075
Validation loss: 2.4262202210173296

Epoch: 51| Step: 0
Training loss: 2.306230655578699
Validation loss: 2.4158559248308116

Epoch: 6| Step: 1
Training loss: 2.6621528112572013
Validation loss: 2.4235167549974297

Epoch: 6| Step: 2
Training loss: 3.3367658743526105
Validation loss: 2.4333211618114277

Epoch: 6| Step: 3
Training loss: 2.7090187868161784
Validation loss: 2.427667268611255

Epoch: 6| Step: 4
Training loss: 3.0817078782154668
Validation loss: 2.4234898386585675

Epoch: 6| Step: 5
Training loss: 2.936906795260594
Validation loss: 2.4186067014765147

Epoch: 6| Step: 6
Training loss: 2.990081922754819
Validation loss: 2.4324612916816

Epoch: 6| Step: 7
Training loss: 2.7260124285632212
Validation loss: 2.4181300185744137

Epoch: 6| Step: 8
Training loss: 2.2723539201810117
Validation loss: 2.424487811236464

Epoch: 6| Step: 9
Training loss: 2.730419589624733
Validation loss: 2.427062622373468

Epoch: 6| Step: 10
Training loss: 2.608563873860249
Validation loss: 2.427632633351946

Epoch: 6| Step: 11
Training loss: 3.107592968213712
Validation loss: 2.424546455225057

Epoch: 6| Step: 12
Training loss: 3.1233323797538657
Validation loss: 2.4149342366187887

Epoch: 6| Step: 13
Training loss: 1.8840016135879054
Validation loss: 2.420040283283115

Epoch: 52| Step: 0
Training loss: 2.4562230077138856
Validation loss: 2.4260099680771643

Epoch: 6| Step: 1
Training loss: 2.8642261814226835
Validation loss: 2.423970664681796

Epoch: 6| Step: 2
Training loss: 2.5269560007930187
Validation loss: 2.42843458880314

Epoch: 6| Step: 3
Training loss: 3.7222456970866364
Validation loss: 2.4417994627272335

Epoch: 6| Step: 4
Training loss: 2.964227544505973
Validation loss: 2.425341840144212

Epoch: 6| Step: 5
Training loss: 2.7990541120656687
Validation loss: 2.4242560953710783

Epoch: 6| Step: 6
Training loss: 1.9318877120943425
Validation loss: 2.4137863424415493

Epoch: 6| Step: 7
Training loss: 2.7698284038179475
Validation loss: 2.4146054897686033

Epoch: 6| Step: 8
Training loss: 3.1769574416602757
Validation loss: 2.419494959386609

Epoch: 6| Step: 9
Training loss: 2.8509425495290732
Validation loss: 2.42684660916416

Epoch: 6| Step: 10
Training loss: 2.9156597760938503
Validation loss: 2.417421870747878

Epoch: 6| Step: 11
Training loss: 2.7254139577034397
Validation loss: 2.4372941743515653

Epoch: 6| Step: 12
Training loss: 2.3976649925890423
Validation loss: 2.4147211149353827

Epoch: 6| Step: 13
Training loss: 2.271169783372878
Validation loss: 2.425913878655026

Epoch: 53| Step: 0
Training loss: 2.668924945037543
Validation loss: 2.4269931291801297

Epoch: 6| Step: 1
Training loss: 3.0255816444296086
Validation loss: 2.4156429603445027

Epoch: 6| Step: 2
Training loss: 2.4493238800702577
Validation loss: 2.422322567785185

Epoch: 6| Step: 3
Training loss: 3.124411870926202
Validation loss: 2.4179584730179307

Epoch: 6| Step: 4
Training loss: 2.894238661831575
Validation loss: 2.410248863041808

Epoch: 6| Step: 5
Training loss: 2.8252169162888134
Validation loss: 2.4195771133356834

Epoch: 6| Step: 6
Training loss: 2.6977365401731777
Validation loss: 2.434694937924235

Epoch: 6| Step: 7
Training loss: 2.49690550975278
Validation loss: 2.4073976098146876

Epoch: 6| Step: 8
Training loss: 3.08625548450698
Validation loss: 2.4258969099893144

Epoch: 6| Step: 9
Training loss: 2.471154116756421
Validation loss: 2.416455513877707

Epoch: 6| Step: 10
Training loss: 3.11238833920371
Validation loss: 2.416840149957745

Epoch: 6| Step: 11
Training loss: 2.9270181524184986
Validation loss: 2.416443859758635

Epoch: 6| Step: 12
Training loss: 2.56693943935714
Validation loss: 2.424530581418661

Epoch: 6| Step: 13
Training loss: 2.5195350351231256
Validation loss: 2.406682314829397

Epoch: 54| Step: 0
Training loss: 3.3091795491685327
Validation loss: 2.4110986404171424

Epoch: 6| Step: 1
Training loss: 3.0217127254431353
Validation loss: 2.427128577273874

Epoch: 6| Step: 2
Training loss: 2.6835118354833463
Validation loss: 2.4290950451005973

Epoch: 6| Step: 3
Training loss: 2.105606782312978
Validation loss: 2.415273309965513

Epoch: 6| Step: 4
Training loss: 2.746246897956579
Validation loss: 2.424373104457411

Epoch: 6| Step: 5
Training loss: 2.974721264002855
Validation loss: 2.4301062045986264

Epoch: 6| Step: 6
Training loss: 3.3536927893468986
Validation loss: 2.4161203641744344

Epoch: 6| Step: 7
Training loss: 2.14869361044505
Validation loss: 2.4246070105290096

Epoch: 6| Step: 8
Training loss: 2.724569822181546
Validation loss: 2.412041236579633

Epoch: 6| Step: 9
Training loss: 2.5390134836013902
Validation loss: 2.4269076759148827

Epoch: 6| Step: 10
Training loss: 2.9799645873660254
Validation loss: 2.4291037446580557

Epoch: 6| Step: 11
Training loss: 2.237756051698134
Validation loss: 2.423001454850976

Epoch: 6| Step: 12
Training loss: 2.9643432033827337
Validation loss: 2.406707147056653

Epoch: 6| Step: 13
Training loss: 2.8939992644883112
Validation loss: 2.405317811276552

Epoch: 55| Step: 0
Training loss: 2.648364400839467
Validation loss: 2.420573748416905

Epoch: 6| Step: 1
Training loss: 3.6766386258487533
Validation loss: 2.414055475116643

Epoch: 6| Step: 2
Training loss: 2.652145985125256
Validation loss: 2.425459606491974

Epoch: 6| Step: 3
Training loss: 2.2133762671814456
Validation loss: 2.425389039962865

Epoch: 6| Step: 4
Training loss: 2.6824756941889616
Validation loss: 2.4268873940943725

Epoch: 6| Step: 5
Training loss: 2.8112954845285416
Validation loss: 2.4232810065833195

Epoch: 6| Step: 6
Training loss: 2.573055948253321
Validation loss: 2.4446581899794975

Epoch: 6| Step: 7
Training loss: 2.4935612733792367
Validation loss: 2.4310794964871048

Epoch: 6| Step: 8
Training loss: 2.4847779337100317
Validation loss: 2.4059823138601906

Epoch: 6| Step: 9
Training loss: 2.4898148007441026
Validation loss: 2.4154683831472195

Epoch: 6| Step: 10
Training loss: 2.981072161026641
Validation loss: 2.4257493377235626

Epoch: 6| Step: 11
Training loss: 2.815849683055016
Validation loss: 2.4305606989261648

Epoch: 6| Step: 12
Training loss: 3.325822490412249
Validation loss: 2.444828991444443

Epoch: 6| Step: 13
Training loss: 2.7502619878644454
Validation loss: 2.4151319097125543

Epoch: 56| Step: 0
Training loss: 2.8596818269463453
Validation loss: 2.430719928681757

Epoch: 6| Step: 1
Training loss: 2.555027183791223
Validation loss: 2.426939953237635

Epoch: 6| Step: 2
Training loss: 2.8033656668716667
Validation loss: 2.427387173287074

Epoch: 6| Step: 3
Training loss: 2.506030248582711
Validation loss: 2.4158506996102136

Epoch: 6| Step: 4
Training loss: 2.9284411411346216
Validation loss: 2.422715972640339

Epoch: 6| Step: 5
Training loss: 2.464923452306871
Validation loss: 2.424849083410575

Epoch: 6| Step: 6
Training loss: 2.5113879233613483
Validation loss: 2.430222779056602

Epoch: 6| Step: 7
Training loss: 2.9704151503049423
Validation loss: 2.4147873952403773

Epoch: 6| Step: 8
Training loss: 2.805643837759945
Validation loss: 2.427653812895998

Epoch: 6| Step: 9
Training loss: 3.4648202166354833
Validation loss: 2.4129139270891193

Epoch: 6| Step: 10
Training loss: 2.589147505806444
Validation loss: 2.421683581697223

Epoch: 6| Step: 11
Training loss: 2.4407551866261556
Validation loss: 2.4131045940751625

Epoch: 6| Step: 12
Training loss: 3.2196091181283415
Validation loss: 2.4071349817985177

Epoch: 6| Step: 13
Training loss: 2.3675148111301034
Validation loss: 2.42457968123702

Epoch: 57| Step: 0
Training loss: 3.071656687556957
Validation loss: 2.4148557725346476

Epoch: 6| Step: 1
Training loss: 2.438623413992705
Validation loss: 2.42735964400107

Epoch: 6| Step: 2
Training loss: 2.8798760239090044
Validation loss: 2.4205901157630607

Epoch: 6| Step: 3
Training loss: 2.4448597644304084
Validation loss: 2.4093747975794493

Epoch: 6| Step: 4
Training loss: 2.6664366225517084
Validation loss: 2.4212564684808946

Epoch: 6| Step: 5
Training loss: 3.129144133289001
Validation loss: 2.4239802192049567

Epoch: 6| Step: 6
Training loss: 2.541771016297887
Validation loss: 2.4117329805031247

Epoch: 6| Step: 7
Training loss: 2.620517718582212
Validation loss: 2.433880993005675

Epoch: 6| Step: 8
Training loss: 2.813133168474571
Validation loss: 2.4160040096116786

Epoch: 6| Step: 9
Training loss: 2.5517402470214408
Validation loss: 2.4045023458616

Epoch: 6| Step: 10
Training loss: 2.9667642477324576
Validation loss: 2.40885136057328

Epoch: 6| Step: 11
Training loss: 3.4752027274077166
Validation loss: 2.4195191324501084

Epoch: 6| Step: 12
Training loss: 2.3793698314854104
Validation loss: 2.4166937611906505

Epoch: 6| Step: 13
Training loss: 2.4196704305908647
Validation loss: 2.415929162684953

Epoch: 58| Step: 0
Training loss: 2.7021395259554444
Validation loss: 2.4235900416642844

Epoch: 6| Step: 1
Training loss: 2.717776946525762
Validation loss: 2.415802357294333

Epoch: 6| Step: 2
Training loss: 2.833952574285311
Validation loss: 2.409800510821777

Epoch: 6| Step: 3
Training loss: 2.312459584475799
Validation loss: 2.4237846009735917

Epoch: 6| Step: 4
Training loss: 2.728273046437612
Validation loss: 2.401804008181351

Epoch: 6| Step: 5
Training loss: 2.470335921792379
Validation loss: 2.4110031369836316

Epoch: 6| Step: 6
Training loss: 2.822637471448831
Validation loss: 2.416019564871009

Epoch: 6| Step: 7
Training loss: 2.9932002253627017
Validation loss: 2.422312089139124

Epoch: 6| Step: 8
Training loss: 2.748583949244356
Validation loss: 2.4087657841523953

Epoch: 6| Step: 9
Training loss: 2.084460246160206
Validation loss: 2.4097149095949066

Epoch: 6| Step: 10
Training loss: 2.6442898030126907
Validation loss: 2.395677702897331

Epoch: 6| Step: 11
Training loss: 2.8545364548718557
Validation loss: 2.4125234102982187

Epoch: 6| Step: 12
Training loss: 3.6077661933421843
Validation loss: 2.413874537237049

Epoch: 6| Step: 13
Training loss: 3.1523370943625526
Validation loss: 2.4215346717481276

Epoch: 59| Step: 0
Training loss: 3.2342685552947756
Validation loss: 2.412572350687781

Epoch: 6| Step: 1
Training loss: 2.411220816222554
Validation loss: 2.4117186822235523

Epoch: 6| Step: 2
Training loss: 2.9198905203166037
Validation loss: 2.418529100127856

Epoch: 6| Step: 3
Training loss: 2.4607303592758822
Validation loss: 2.4102631221771302

Epoch: 6| Step: 4
Training loss: 2.5118643568676724
Validation loss: 2.4179678286464314

Epoch: 6| Step: 5
Training loss: 2.1262267442583043
Validation loss: 2.4195206561057905

Epoch: 6| Step: 6
Training loss: 1.787839579838044
Validation loss: 2.412223432133585

Epoch: 6| Step: 7
Training loss: 2.728810779770109
Validation loss: 2.4167688766805764

Epoch: 6| Step: 8
Training loss: 2.7808352386160196
Validation loss: 2.428743400910771

Epoch: 6| Step: 9
Training loss: 2.8519163147364206
Validation loss: 2.4292875277967254

Epoch: 6| Step: 10
Training loss: 3.7348383532248404
Validation loss: 2.4329534134035242

Epoch: 6| Step: 11
Training loss: 2.7771789244339864
Validation loss: 2.4192965264283233

Epoch: 6| Step: 12
Training loss: 3.1719670023987705
Validation loss: 2.4146214856246737

Epoch: 6| Step: 13
Training loss: 2.6983758739332715
Validation loss: 2.427913250484182

Epoch: 60| Step: 0
Training loss: 2.9536156625181547
Validation loss: 2.4154215190892296

Epoch: 6| Step: 1
Training loss: 2.434841760589153
Validation loss: 2.417197133897712

Epoch: 6| Step: 2
Training loss: 3.213794634407811
Validation loss: 2.4143962237173113

Epoch: 6| Step: 3
Training loss: 2.2121524774931767
Validation loss: 2.416803607165462

Epoch: 6| Step: 4
Training loss: 2.334663171101467
Validation loss: 2.4053295256976064

Epoch: 6| Step: 5
Training loss: 2.6179155390428024
Validation loss: 2.4021516952760096

Epoch: 6| Step: 6
Training loss: 3.1017654314122316
Validation loss: 2.411712150121299

Epoch: 6| Step: 7
Training loss: 2.7344886102235164
Validation loss: 2.4124615054890524

Epoch: 6| Step: 8
Training loss: 3.014893121801944
Validation loss: 2.417440631192314

Epoch: 6| Step: 9
Training loss: 2.0812059094223594
Validation loss: 2.419935854667881

Epoch: 6| Step: 10
Training loss: 2.9650441379703447
Validation loss: 2.4087220560755873

Epoch: 6| Step: 11
Training loss: 2.796291695404572
Validation loss: 2.418406812796315

Epoch: 6| Step: 12
Training loss: 3.2646515047753315
Validation loss: 2.4023915905427913

Epoch: 6| Step: 13
Training loss: 2.7060554804503076
Validation loss: 2.4228369192876316

Epoch: 61| Step: 0
Training loss: 2.8217051441192647
Validation loss: 2.4163390497296624

Epoch: 6| Step: 1
Training loss: 2.801811422511239
Validation loss: 2.41252578848236

Epoch: 6| Step: 2
Training loss: 2.9436642514838316
Validation loss: 2.4059616222901465

Epoch: 6| Step: 3
Training loss: 2.870956562942691
Validation loss: 2.4145721535798694

Epoch: 6| Step: 4
Training loss: 2.6390246897327048
Validation loss: 2.4028294007459263

Epoch: 6| Step: 5
Training loss: 2.721916371851193
Validation loss: 2.4157152113397315

Epoch: 6| Step: 6
Training loss: 2.911357370626621
Validation loss: 2.409888811062501

Epoch: 6| Step: 7
Training loss: 2.636693974131282
Validation loss: 2.4124387760205233

Epoch: 6| Step: 8
Training loss: 2.463234450128292
Validation loss: 2.411315619973589

Epoch: 6| Step: 9
Training loss: 2.683683479952293
Validation loss: 2.415127974762443

Epoch: 6| Step: 10
Training loss: 2.9698460212121223
Validation loss: 2.4194154405523878

Epoch: 6| Step: 11
Training loss: 2.8744376918046743
Validation loss: 2.4181009144792207

Epoch: 6| Step: 12
Training loss: 2.2914008477684145
Validation loss: 2.4114797658496525

Epoch: 6| Step: 13
Training loss: 3.2006655298999225
Validation loss: 2.41692737414966

Epoch: 62| Step: 0
Training loss: 2.8595829455529977
Validation loss: 2.4102152325912933

Epoch: 6| Step: 1
Training loss: 2.7999558343128883
Validation loss: 2.4221090319474263

Epoch: 6| Step: 2
Training loss: 3.3383984388712076
Validation loss: 2.4108332653062727

Epoch: 6| Step: 3
Training loss: 2.7232462217794473
Validation loss: 2.409200646188381

Epoch: 6| Step: 4
Training loss: 2.0808843205501537
Validation loss: 2.412198461141535

Epoch: 6| Step: 5
Training loss: 2.4738059120741047
Validation loss: 2.421047935090344

Epoch: 6| Step: 6
Training loss: 2.3784286445530007
Validation loss: 2.417719391771736

Epoch: 6| Step: 7
Training loss: 2.8366747021439895
Validation loss: 2.399634741689627

Epoch: 6| Step: 8
Training loss: 2.782889065339794
Validation loss: 2.4339718880831085

Epoch: 6| Step: 9
Training loss: 2.558685534046709
Validation loss: 2.4135502458494678

Epoch: 6| Step: 10
Training loss: 3.088053998781376
Validation loss: 2.421415334976783

Epoch: 6| Step: 11
Training loss: 2.735804157068583
Validation loss: 2.4174124196833855

Epoch: 6| Step: 12
Training loss: 2.958148538611484
Validation loss: 2.4265504481161706

Epoch: 6| Step: 13
Training loss: 3.110047234179591
Validation loss: 2.4118794567168798

Epoch: 63| Step: 0
Training loss: 2.730559559022856
Validation loss: 2.4057632889484175

Epoch: 6| Step: 1
Training loss: 3.027320280907013
Validation loss: 2.4054905417798946

Epoch: 6| Step: 2
Training loss: 2.844047446991225
Validation loss: 2.403414616157126

Epoch: 6| Step: 3
Training loss: 2.269824535965779
Validation loss: 2.418765268237604

Epoch: 6| Step: 4
Training loss: 2.8127849858327028
Validation loss: 2.4194554188374746

Epoch: 6| Step: 5
Training loss: 2.897970239037602
Validation loss: 2.4162032662932043

Epoch: 6| Step: 6
Training loss: 2.645437606493923
Validation loss: 2.406837038587624

Epoch: 6| Step: 7
Training loss: 3.028785254083961
Validation loss: 2.3982581641778205

Epoch: 6| Step: 8
Training loss: 2.4635438710714292
Validation loss: 2.412284231422277

Epoch: 6| Step: 9
Training loss: 2.665084329670063
Validation loss: 2.4013011586525272

Epoch: 6| Step: 10
Training loss: 2.8579304699458525
Validation loss: 2.4034185318847925

Epoch: 6| Step: 11
Training loss: 2.60962086507173
Validation loss: 2.409657781374347

Epoch: 6| Step: 12
Training loss: 2.853317932758779
Validation loss: 2.4167919504818993

Epoch: 6| Step: 13
Training loss: 2.9481255734742127
Validation loss: 2.3939915094426456

Epoch: 64| Step: 0
Training loss: 3.299533007553058
Validation loss: 2.413571126222563

Epoch: 6| Step: 1
Training loss: 2.854881549789777
Validation loss: 2.407110566683353

Epoch: 6| Step: 2
Training loss: 2.906296432288273
Validation loss: 2.407098828978936

Epoch: 6| Step: 3
Training loss: 2.974166105709805
Validation loss: 2.418039748831792

Epoch: 6| Step: 4
Training loss: 2.5308225294311084
Validation loss: 2.414681834893018

Epoch: 6| Step: 5
Training loss: 2.585509757538994
Validation loss: 2.413100111878281

Epoch: 6| Step: 6
Training loss: 2.8751801144115507
Validation loss: 2.4157138561427307

Epoch: 6| Step: 7
Training loss: 2.0616052015923576
Validation loss: 2.41625683661264

Epoch: 6| Step: 8
Training loss: 2.7553163638265765
Validation loss: 2.418738098700318

Epoch: 6| Step: 9
Training loss: 2.489139331079638
Validation loss: 2.404441687786973

Epoch: 6| Step: 10
Training loss: 2.7742093583734655
Validation loss: 2.416017802381702

Epoch: 6| Step: 11
Training loss: 2.509134294834651
Validation loss: 2.4043766939236937

Epoch: 6| Step: 12
Training loss: 2.630560118060221
Validation loss: 2.4120842248028023

Epoch: 6| Step: 13
Training loss: 3.314794501469902
Validation loss: 2.4012200230538765

Epoch: 65| Step: 0
Training loss: 2.805862223249198
Validation loss: 2.4217469095845012

Epoch: 6| Step: 1
Training loss: 2.675276971899039
Validation loss: 2.4239549536809935

Epoch: 6| Step: 2
Training loss: 2.7911274422416166
Validation loss: 2.414716992461353

Epoch: 6| Step: 3
Training loss: 2.5682051811782123
Validation loss: 2.4176593017724284

Epoch: 6| Step: 4
Training loss: 2.9336720950132738
Validation loss: 2.412166167237425

Epoch: 6| Step: 5
Training loss: 2.7471660403412725
Validation loss: 2.4043957640689277

Epoch: 6| Step: 6
Training loss: 2.6864705442812
Validation loss: 2.406498274388851

Epoch: 6| Step: 7
Training loss: 2.579824084265362
Validation loss: 2.411901627049839

Epoch: 6| Step: 8
Training loss: 2.978608156861863
Validation loss: 2.4023855975881774

Epoch: 6| Step: 9
Training loss: 2.893873379344914
Validation loss: 2.412765148481323

Epoch: 6| Step: 10
Training loss: 2.68895744016538
Validation loss: 2.412551101440048

Epoch: 6| Step: 11
Training loss: 2.619230014262731
Validation loss: 2.4179200630336393

Epoch: 6| Step: 12
Training loss: 2.4736759921468163
Validation loss: 2.411217244888393

Epoch: 6| Step: 13
Training loss: 3.2396032858149297
Validation loss: 2.4260576061125882

Epoch: 66| Step: 0
Training loss: 2.6963843826527536
Validation loss: 2.423393060076506

Epoch: 6| Step: 1
Training loss: 3.191302705203283
Validation loss: 2.4164626272655028

Epoch: 6| Step: 2
Training loss: 2.671386495627504
Validation loss: 2.407644227238849

Epoch: 6| Step: 3
Training loss: 2.41374643966594
Validation loss: 2.4091616964658367

Epoch: 6| Step: 4
Training loss: 2.7453238871842487
Validation loss: 2.3987396467849265

Epoch: 6| Step: 5
Training loss: 2.7351554410792147
Validation loss: 2.4217886981810652

Epoch: 6| Step: 6
Training loss: 2.946959179417212
Validation loss: 2.401688124069721

Epoch: 6| Step: 7
Training loss: 2.99052394907485
Validation loss: 2.413207737547262

Epoch: 6| Step: 8
Training loss: 2.721922766072563
Validation loss: 2.4163564897377996

Epoch: 6| Step: 9
Training loss: 2.5574866775359606
Validation loss: 2.4088587901507004

Epoch: 6| Step: 10
Training loss: 2.462577152495862
Validation loss: 2.4051010165096067

Epoch: 6| Step: 11
Training loss: 3.0759267945526236
Validation loss: 2.4088895746016132

Epoch: 6| Step: 12
Training loss: 2.3450295579426097
Validation loss: 2.400358669935029

Epoch: 6| Step: 13
Training loss: 2.6313916455922475
Validation loss: 2.412504039380382

Epoch: 67| Step: 0
Training loss: 2.2857882155655753
Validation loss: 2.4071472023096336

Epoch: 6| Step: 1
Training loss: 2.3565398101260637
Validation loss: 2.4088995475895487

Epoch: 6| Step: 2
Training loss: 3.1791393360514704
Validation loss: 2.4139409353060897

Epoch: 6| Step: 3
Training loss: 3.1549117773329107
Validation loss: 2.423687237593935

Epoch: 6| Step: 4
Training loss: 2.73445818093346
Validation loss: 2.413867987603667

Epoch: 6| Step: 5
Training loss: 2.656152521476542
Validation loss: 2.4067465343507806

Epoch: 6| Step: 6
Training loss: 2.7566048460751107
Validation loss: 2.3952837948230714

Epoch: 6| Step: 7
Training loss: 2.6777844135664752
Validation loss: 2.418960272837928

Epoch: 6| Step: 8
Training loss: 3.0050602198198377
Validation loss: 2.4167932997705615

Epoch: 6| Step: 9
Training loss: 3.246714765543599
Validation loss: 2.423048281282162

Epoch: 6| Step: 10
Training loss: 2.808450708473889
Validation loss: 2.4128929220315407

Epoch: 6| Step: 11
Training loss: 2.379739850195427
Validation loss: 2.4226793999601632

Epoch: 6| Step: 12
Training loss: 2.513243975969178
Validation loss: 2.4206349829483984

Epoch: 6| Step: 13
Training loss: 1.9639737760886886
Validation loss: 2.434943887472073

Epoch: 68| Step: 0
Training loss: 2.7591262584305447
Validation loss: 2.408777342915187

Epoch: 6| Step: 1
Training loss: 2.799089631177733
Validation loss: 2.4263345488537778

Epoch: 6| Step: 2
Training loss: 2.740665284994908
Validation loss: 2.416211012789758

Epoch: 6| Step: 3
Training loss: 2.6328092399599625
Validation loss: 2.3997780613929183

Epoch: 6| Step: 4
Training loss: 2.95751626636614
Validation loss: 2.4092878075186412

Epoch: 6| Step: 5
Training loss: 2.9339183317960513
Validation loss: 2.4187339120588294

Epoch: 6| Step: 6
Training loss: 2.740247773989426
Validation loss: 2.420640151242269

Epoch: 6| Step: 7
Training loss: 2.5261068958368202
Validation loss: 2.42889293810722

Epoch: 6| Step: 8
Training loss: 2.3571740804808874
Validation loss: 2.421038828558164

Epoch: 6| Step: 9
Training loss: 3.701200733726542
Validation loss: 2.41306503699254

Epoch: 6| Step: 10
Training loss: 2.2290002160600615
Validation loss: 2.417803259088965

Epoch: 6| Step: 11
Training loss: 2.5162523328577966
Validation loss: 2.4153990605296727

Epoch: 6| Step: 12
Training loss: 2.68022822048866
Validation loss: 2.4197855615894848

Epoch: 6| Step: 13
Training loss: 2.3664490205684685
Validation loss: 2.420903234595323

Epoch: 69| Step: 0
Training loss: 2.9099147209964213
Validation loss: 2.420489139313261

Epoch: 6| Step: 1
Training loss: 2.0400154547012437
Validation loss: 2.427650495948295

Epoch: 6| Step: 2
Training loss: 3.2773230896436094
Validation loss: 2.405990471525905

Epoch: 6| Step: 3
Training loss: 2.9916343077996688
Validation loss: 2.4046681242118653

Epoch: 6| Step: 4
Training loss: 2.4320941548065607
Validation loss: 2.41466368631664

Epoch: 6| Step: 5
Training loss: 3.0887364309484493
Validation loss: 2.4206410874648143

Epoch: 6| Step: 6
Training loss: 2.6965582138842654
Validation loss: 2.3953122278935286

Epoch: 6| Step: 7
Training loss: 3.298979029075108
Validation loss: 2.4089587631509204

Epoch: 6| Step: 8
Training loss: 2.3466602821516114
Validation loss: 2.4011703302630116

Epoch: 6| Step: 9
Training loss: 2.39473346397775
Validation loss: 2.415257053598117

Epoch: 6| Step: 10
Training loss: 2.1924862299870576
Validation loss: 2.425433719018377

Epoch: 6| Step: 11
Training loss: 3.0765159777780187
Validation loss: 2.3917625166503327

Epoch: 6| Step: 12
Training loss: 2.27333294080729
Validation loss: 2.401941884268116

Epoch: 6| Step: 13
Training loss: 3.0723756647986544
Validation loss: 2.396073645425512

Epoch: 70| Step: 0
Training loss: 2.2452886846947786
Validation loss: 2.394187468563978

Epoch: 6| Step: 1
Training loss: 2.795886840156702
Validation loss: 2.405960447002775

Epoch: 6| Step: 2
Training loss: 3.5070922383974916
Validation loss: 2.404111360590661

Epoch: 6| Step: 3
Training loss: 3.0939363365700556
Validation loss: 2.4056175220005303

Epoch: 6| Step: 4
Training loss: 2.8344453611546463
Validation loss: 2.4073063748042416

Epoch: 6| Step: 5
Training loss: 2.551294622708552
Validation loss: 2.402134127591631

Epoch: 6| Step: 6
Training loss: 2.1625097329686924
Validation loss: 2.4083430064108184

Epoch: 6| Step: 7
Training loss: 3.3239923886465617
Validation loss: 2.400768065221908

Epoch: 6| Step: 8
Training loss: 2.7973737218751533
Validation loss: 2.393353947447201

Epoch: 6| Step: 9
Training loss: 2.643282484196452
Validation loss: 2.3937710189871106

Epoch: 6| Step: 10
Training loss: 2.6290103613996427
Validation loss: 2.4000850265918983

Epoch: 6| Step: 11
Training loss: 2.368050194588488
Validation loss: 2.402598708581636

Epoch: 6| Step: 12
Training loss: 2.4714464358653543
Validation loss: 2.404930778039185

Epoch: 6| Step: 13
Training loss: 2.4888999565007106
Validation loss: 2.4148853202095384

Epoch: 71| Step: 0
Training loss: 2.764163390755593
Validation loss: 2.4119017142086707

Epoch: 6| Step: 1
Training loss: 2.6208040216582744
Validation loss: 2.40919650149878

Epoch: 6| Step: 2
Training loss: 2.88697642413913
Validation loss: 2.403713005445508

Epoch: 6| Step: 3
Training loss: 2.7472256624332902
Validation loss: 2.395574867320663

Epoch: 6| Step: 4
Training loss: 2.8207293173368035
Validation loss: 2.4185402025414606

Epoch: 6| Step: 5
Training loss: 2.6476652656822655
Validation loss: 2.412095864380886

Epoch: 6| Step: 6
Training loss: 2.012442508610834
Validation loss: 2.422668755663686

Epoch: 6| Step: 7
Training loss: 2.5164751784208796
Validation loss: 2.4075727317742435

Epoch: 6| Step: 8
Training loss: 2.7595508489166036
Validation loss: 2.4237489170350286

Epoch: 6| Step: 9
Training loss: 3.0924991429419473
Validation loss: 2.4126824119313035

Epoch: 6| Step: 10
Training loss: 2.8338396704527993
Validation loss: 2.4233468718694398

Epoch: 6| Step: 11
Training loss: 2.9219517009276026
Validation loss: 2.424212159194995

Epoch: 6| Step: 12
Training loss: 2.9086672666789357
Validation loss: 2.418157883519598

Epoch: 6| Step: 13
Training loss: 2.712973322201816
Validation loss: 2.4078490706891156

Epoch: 72| Step: 0
Training loss: 2.2404306154512725
Validation loss: 2.4053083030597144

Epoch: 6| Step: 1
Training loss: 2.8900337233110274
Validation loss: 2.400797989167852

Epoch: 6| Step: 2
Training loss: 1.9595920764950565
Validation loss: 2.4154621127242075

Epoch: 6| Step: 3
Training loss: 2.867042641787293
Validation loss: 2.424382357081404

Epoch: 6| Step: 4
Training loss: 2.3379299890300302
Validation loss: 2.4236847138154345

Epoch: 6| Step: 5
Training loss: 2.5514849733347114
Validation loss: 2.431829559119802

Epoch: 6| Step: 6
Training loss: 2.9687862996341634
Validation loss: 2.413530293654636

Epoch: 6| Step: 7
Training loss: 2.5203722592557294
Validation loss: 2.4104439599636307

Epoch: 6| Step: 8
Training loss: 2.328507769564526
Validation loss: 2.4184349173017514

Epoch: 6| Step: 9
Training loss: 3.2631876487541205
Validation loss: 2.4158666320408004

Epoch: 6| Step: 10
Training loss: 2.461333712214437
Validation loss: 2.4080191262683135

Epoch: 6| Step: 11
Training loss: 3.1516784192744836
Validation loss: 2.399134475967969

Epoch: 6| Step: 12
Training loss: 3.0495815677970413
Validation loss: 2.415593274525885

Epoch: 6| Step: 13
Training loss: 3.6297845506440516
Validation loss: 2.4116461201509787

Epoch: 73| Step: 0
Training loss: 2.1606411656930002
Validation loss: 2.4208786390563444

Epoch: 6| Step: 1
Training loss: 3.136051928946618
Validation loss: 2.407297568786275

Epoch: 6| Step: 2
Training loss: 2.186420828425065
Validation loss: 2.405033334023452

Epoch: 6| Step: 3
Training loss: 3.039485637165867
Validation loss: 2.4085031653544693

Epoch: 6| Step: 4
Training loss: 2.0546849471972024
Validation loss: 2.42093694954148

Epoch: 6| Step: 5
Training loss: 3.0757130114112488
Validation loss: 2.4091106489549827

Epoch: 6| Step: 6
Training loss: 3.0274067533766624
Validation loss: 2.4019048447762286

Epoch: 6| Step: 7
Training loss: 2.687049295646868
Validation loss: 2.4008236286622555

Epoch: 6| Step: 8
Training loss: 2.290697574896929
Validation loss: 2.4101015154764127

Epoch: 6| Step: 9
Training loss: 3.0362923752900723
Validation loss: 2.4118894513552442

Epoch: 6| Step: 10
Training loss: 2.337796903307578
Validation loss: 2.405962140140973

Epoch: 6| Step: 11
Training loss: 3.069758163768116
Validation loss: 2.396492960803061

Epoch: 6| Step: 12
Training loss: 2.8359939947885224
Validation loss: 2.4157159202443594

Epoch: 6| Step: 13
Training loss: 2.8523289316754226
Validation loss: 2.4133847387622698

Epoch: 74| Step: 0
Training loss: 2.7284811969351757
Validation loss: 2.4232309388818134

Epoch: 6| Step: 1
Training loss: 2.781293204325595
Validation loss: 2.425049372953677

Epoch: 6| Step: 2
Training loss: 2.483380580512382
Validation loss: 2.412710043870192

Epoch: 6| Step: 3
Training loss: 2.2724477179863665
Validation loss: 2.418494265099847

Epoch: 6| Step: 4
Training loss: 2.4840827626064055
Validation loss: 2.4133071702717293

Epoch: 6| Step: 5
Training loss: 3.2239988917119318
Validation loss: 2.4059917554820047

Epoch: 6| Step: 6
Training loss: 2.6841217809755618
Validation loss: 2.4121168896645777

Epoch: 6| Step: 7
Training loss: 2.5398777987903447
Validation loss: 2.4023072188019485

Epoch: 6| Step: 8
Training loss: 2.498564594178129
Validation loss: 2.398498972609058

Epoch: 6| Step: 9
Training loss: 2.799457998269652
Validation loss: 2.4017176875060935

Epoch: 6| Step: 10
Training loss: 3.423844837380775
Validation loss: 2.420270187904283

Epoch: 6| Step: 11
Training loss: 2.7020378793282047
Validation loss: 2.4126533462540296

Epoch: 6| Step: 12
Training loss: 2.641798853249481
Validation loss: 2.4092387525241468

Epoch: 6| Step: 13
Training loss: 2.583144509172364
Validation loss: 2.4108883543293396

Epoch: 75| Step: 0
Training loss: 3.1671031517235475
Validation loss: 2.405788605925372

Epoch: 6| Step: 1
Training loss: 3.144947474636913
Validation loss: 2.408598747691411

Epoch: 6| Step: 2
Training loss: 2.500643265935635
Validation loss: 2.4163578339648604

Epoch: 6| Step: 3
Training loss: 2.5257468979042517
Validation loss: 2.414387816256392

Epoch: 6| Step: 4
Training loss: 2.262163767410197
Validation loss: 2.4000936166046967

Epoch: 6| Step: 5
Training loss: 2.650344387204911
Validation loss: 2.3973081211185736

Epoch: 6| Step: 6
Training loss: 2.165802844563035
Validation loss: 2.4026551921238104

Epoch: 6| Step: 7
Training loss: 2.803865700186986
Validation loss: 2.4283975226726717

Epoch: 6| Step: 8
Training loss: 2.8297332069079997
Validation loss: 2.4094962660057124

Epoch: 6| Step: 9
Training loss: 2.193148595205221
Validation loss: 2.408104122407527

Epoch: 6| Step: 10
Training loss: 3.2870748498818196
Validation loss: 2.42584844660665

Epoch: 6| Step: 11
Training loss: 2.252222658753359
Validation loss: 2.413878013304106

Epoch: 6| Step: 12
Training loss: 3.0832350088027405
Validation loss: 2.413824370011882

Epoch: 6| Step: 13
Training loss: 2.9080622775349863
Validation loss: 2.4374071550001246

Epoch: 76| Step: 0
Training loss: 2.5721683005862053
Validation loss: 2.423411168668612

Epoch: 6| Step: 1
Training loss: 2.6382860287031975
Validation loss: 2.413597989600977

Epoch: 6| Step: 2
Training loss: 2.750679972419355
Validation loss: 2.40322936113459

Epoch: 6| Step: 3
Training loss: 2.7596672240341675
Validation loss: 2.4140574259442

Epoch: 6| Step: 4
Training loss: 2.7957290773998023
Validation loss: 2.411361682476721

Epoch: 6| Step: 5
Training loss: 2.844569832137581
Validation loss: 2.421947114832079

Epoch: 6| Step: 6
Training loss: 2.4815844332065957
Validation loss: 2.41417827860208

Epoch: 6| Step: 7
Training loss: 2.6778803923992003
Validation loss: 2.404974033535409

Epoch: 6| Step: 8
Training loss: 3.372207192504952
Validation loss: 2.404201074718222

Epoch: 6| Step: 9
Training loss: 2.604903724633948
Validation loss: 2.414509956224342

Epoch: 6| Step: 10
Training loss: 3.1333686163789283
Validation loss: 2.399670394808016

Epoch: 6| Step: 11
Training loss: 2.4614545975208926
Validation loss: 2.407267716049821

Epoch: 6| Step: 12
Training loss: 2.1107510069967033
Validation loss: 2.4165922978435996

Epoch: 6| Step: 13
Training loss: 2.5854290695774114
Validation loss: 2.423383632299328

Epoch: 77| Step: 0
Training loss: 3.067442350832953
Validation loss: 2.3940500860876495

Epoch: 6| Step: 1
Training loss: 2.7747762538301317
Validation loss: 2.4117520057681454

Epoch: 6| Step: 2
Training loss: 2.6898967789766717
Validation loss: 2.405207470589164

Epoch: 6| Step: 3
Training loss: 3.2111479233153677
Validation loss: 2.3911618594986184

Epoch: 6| Step: 4
Training loss: 2.2356017686395617
Validation loss: 2.418733314799383

Epoch: 6| Step: 5
Training loss: 2.808398328834583
Validation loss: 2.3980708185166226

Epoch: 6| Step: 6
Training loss: 2.7563024606707636
Validation loss: 2.393876206680084

Epoch: 6| Step: 7
Training loss: 3.1325462779944457
Validation loss: 2.406366954571993

Epoch: 6| Step: 8
Training loss: 2.1065664172564085
Validation loss: 2.40482989456007

Epoch: 6| Step: 9
Training loss: 1.5125876598334458
Validation loss: 2.4087308004772816

Epoch: 6| Step: 10
Training loss: 2.636206818792671
Validation loss: 2.393741483782177

Epoch: 6| Step: 11
Training loss: 3.2075480371150156
Validation loss: 2.408446529965793

Epoch: 6| Step: 12
Training loss: 2.8171241046460453
Validation loss: 2.4037682080564307

Epoch: 6| Step: 13
Training loss: 2.41175055055008
Validation loss: 2.41910145037685

Epoch: 78| Step: 0
Training loss: 2.255274418544647
Validation loss: 2.4163194696216377

Epoch: 6| Step: 1
Training loss: 2.857147683412018
Validation loss: 2.4167810086989245

Epoch: 6| Step: 2
Training loss: 3.175610977619387
Validation loss: 2.4045166444054953

Epoch: 6| Step: 3
Training loss: 2.5700149131965624
Validation loss: 2.419389880996473

Epoch: 6| Step: 4
Training loss: 2.049510162261315
Validation loss: 2.4176908797203573

Epoch: 6| Step: 5
Training loss: 2.899004693071265
Validation loss: 2.4059874156010794

Epoch: 6| Step: 6
Training loss: 2.520038973491775
Validation loss: 2.40379377427629

Epoch: 6| Step: 7
Training loss: 2.8567980217603393
Validation loss: 2.392370276598733

Epoch: 6| Step: 8
Training loss: 2.9742393739434667
Validation loss: 2.3942891184695485

Epoch: 6| Step: 9
Training loss: 2.9780417143472953
Validation loss: 2.4081628784748

Epoch: 6| Step: 10
Training loss: 2.852299007251873
Validation loss: 2.414466633725978

Epoch: 6| Step: 11
Training loss: 2.564709896762833
Validation loss: 2.41883062692686

Epoch: 6| Step: 12
Training loss: 2.1791745474425483
Validation loss: 2.4313178997985254

Epoch: 6| Step: 13
Training loss: 3.0929397909259353
Validation loss: 2.399588233992564

Epoch: 79| Step: 0
Training loss: 3.1032925256107777
Validation loss: 2.398225986145749

Epoch: 6| Step: 1
Training loss: 2.7520350815621746
Validation loss: 2.3960902207855517

Epoch: 6| Step: 2
Training loss: 3.013930402978646
Validation loss: 2.392313509503938

Epoch: 6| Step: 3
Training loss: 3.296657175398208
Validation loss: 2.4119522785551437

Epoch: 6| Step: 4
Training loss: 2.638754006892803
Validation loss: 2.419790457830457

Epoch: 6| Step: 5
Training loss: 2.3785307890154446
Validation loss: 2.402350427628454

Epoch: 6| Step: 6
Training loss: 1.5670825896514504
Validation loss: 2.4029235241617735

Epoch: 6| Step: 7
Training loss: 2.6313758801864755
Validation loss: 2.408002026179014

Epoch: 6| Step: 8
Training loss: 2.5697186836318466
Validation loss: 2.3995238063302864

Epoch: 6| Step: 9
Training loss: 2.0354055299587643
Validation loss: 2.420526360438811

Epoch: 6| Step: 10
Training loss: 3.1373234186217123
Validation loss: 2.419027230768361

Epoch: 6| Step: 11
Training loss: 2.809722206801685
Validation loss: 2.424194084081837

Epoch: 6| Step: 12
Training loss: 2.784792069732149
Validation loss: 2.3940121909603267

Epoch: 6| Step: 13
Training loss: 2.551825830872075
Validation loss: 2.418009616819824

Epoch: 80| Step: 0
Training loss: 1.8928653274729343
Validation loss: 2.4105326322622393

Epoch: 6| Step: 1
Training loss: 3.043963953915088
Validation loss: 2.4120734152443135

Epoch: 6| Step: 2
Training loss: 2.8579309704868434
Validation loss: 2.406218782245596

Epoch: 6| Step: 3
Training loss: 2.5399520489529372
Validation loss: 2.400007914842865

Epoch: 6| Step: 4
Training loss: 2.9159407302630873
Validation loss: 2.3959328572350485

Epoch: 6| Step: 5
Training loss: 3.3899497489243013
Validation loss: 2.4122440296065912

Epoch: 6| Step: 6
Training loss: 2.991135853152879
Validation loss: 2.390925389140483

Epoch: 6| Step: 7
Training loss: 2.9581230697770615
Validation loss: 2.4040911637069438

Epoch: 6| Step: 8
Training loss: 2.670684549251163
Validation loss: 2.4320774221601873

Epoch: 6| Step: 9
Training loss: 1.9632054925670752
Validation loss: 2.4099357194156696

Epoch: 6| Step: 10
Training loss: 2.2314553558991705
Validation loss: 2.4164464239879275

Epoch: 6| Step: 11
Training loss: 2.4467472827460135
Validation loss: 2.408752323958831

Epoch: 6| Step: 12
Training loss: 2.7597775469155974
Validation loss: 2.4132211070253735

Epoch: 6| Step: 13
Training loss: 2.685300237254072
Validation loss: 2.4042168849493715

Epoch: 81| Step: 0
Training loss: 2.8747329587894916
Validation loss: 2.3987347647535

Epoch: 6| Step: 1
Training loss: 2.45319886308983
Validation loss: 2.4135358861066316

Epoch: 6| Step: 2
Training loss: 3.258250255127224
Validation loss: 2.4101433581355813

Epoch: 6| Step: 3
Training loss: 3.245180224099988
Validation loss: 2.4064478319440745

Epoch: 6| Step: 4
Training loss: 2.906094454632892
Validation loss: 2.420264015190621

Epoch: 6| Step: 5
Training loss: 2.440587264976921
Validation loss: 2.429258775826589

Epoch: 6| Step: 6
Training loss: 2.4446324386939935
Validation loss: 2.4111674710608035

Epoch: 6| Step: 7
Training loss: 2.701972583470712
Validation loss: 2.4109284149960644

Epoch: 6| Step: 8
Training loss: 2.7035263733745936
Validation loss: 2.43277296426072

Epoch: 6| Step: 9
Training loss: 2.6930814050495453
Validation loss: 2.410412911391533

Epoch: 6| Step: 10
Training loss: 2.0310185227181026
Validation loss: 2.4309286574400732

Epoch: 6| Step: 11
Training loss: 2.350959370977997
Validation loss: 2.42143678382319

Epoch: 6| Step: 12
Training loss: 2.8065262826286608
Validation loss: 2.4156336371014513

Epoch: 6| Step: 13
Training loss: 2.619834813596271
Validation loss: 2.422164733471435

Epoch: 82| Step: 0
Training loss: 2.9686947466075315
Validation loss: 2.4323418317328054

Epoch: 6| Step: 1
Training loss: 2.901321005028356
Validation loss: 2.4279781696940876

Epoch: 6| Step: 2
Training loss: 2.6777260054687764
Validation loss: 2.416639139727976

Epoch: 6| Step: 3
Training loss: 2.162926330877956
Validation loss: 2.4156879215371094

Epoch: 6| Step: 4
Training loss: 2.5580198619867764
Validation loss: 2.4085054974809093

Epoch: 6| Step: 5
Training loss: 2.740254734477556
Validation loss: 2.4080584894415926

Epoch: 6| Step: 6
Training loss: 3.0303307151974748
Validation loss: 2.403004764937336

Epoch: 6| Step: 7
Training loss: 2.470483678186725
Validation loss: 2.411762821550578

Epoch: 6| Step: 8
Training loss: 3.0762239578924238
Validation loss: 2.4045172958396286

Epoch: 6| Step: 9
Training loss: 2.7438978637615814
Validation loss: 2.4152867115282795

Epoch: 6| Step: 10
Training loss: 2.8321521391224276
Validation loss: 2.4143910792211467

Epoch: 6| Step: 11
Training loss: 2.5136402901752537
Validation loss: 2.3842520107172334

Epoch: 6| Step: 12
Training loss: 2.2456339755304926
Validation loss: 2.404742866953396

Epoch: 6| Step: 13
Training loss: 2.472936629418578
Validation loss: 2.4164542163850276

Epoch: 83| Step: 0
Training loss: 2.825687179708175
Validation loss: 2.4086467077333498

Epoch: 6| Step: 1
Training loss: 2.323090300178976
Validation loss: 2.392664006098004

Epoch: 6| Step: 2
Training loss: 2.970766366540026
Validation loss: 2.406480378894058

Epoch: 6| Step: 3
Training loss: 3.1662129194194493
Validation loss: 2.4013338527592563

Epoch: 6| Step: 4
Training loss: 2.289331413851811
Validation loss: 2.405381376060608

Epoch: 6| Step: 5
Training loss: 2.4281208838547
Validation loss: 2.3893183086697642

Epoch: 6| Step: 6
Training loss: 2.5813678114193706
Validation loss: 2.4028890016816566

Epoch: 6| Step: 7
Training loss: 2.472532055283469
Validation loss: 2.40524569667912

Epoch: 6| Step: 8
Training loss: 3.245210933794871
Validation loss: 2.4097830664527167

Epoch: 6| Step: 9
Training loss: 2.564371030703547
Validation loss: 2.3926649543387546

Epoch: 6| Step: 10
Training loss: 2.197080178806243
Validation loss: 2.4058369501894856

Epoch: 6| Step: 11
Training loss: 3.186757319077397
Validation loss: 2.41250251129324

Epoch: 6| Step: 12
Training loss: 2.9293307074406414
Validation loss: 2.3806263007879687

Epoch: 6| Step: 13
Training loss: 1.928846909764005
Validation loss: 2.409646771023518

Epoch: 84| Step: 0
Training loss: 2.0185270487494598
Validation loss: 2.398343030570798

Epoch: 6| Step: 1
Training loss: 2.7017512717188863
Validation loss: 2.415173201357048

Epoch: 6| Step: 2
Training loss: 2.4056667264994993
Validation loss: 2.4056541899553943

Epoch: 6| Step: 3
Training loss: 3.0373495810355764
Validation loss: 2.4169392529265035

Epoch: 6| Step: 4
Training loss: 2.295402002634556
Validation loss: 2.417438040975402

Epoch: 6| Step: 5
Training loss: 2.515470322302136
Validation loss: 2.4091075033432734

Epoch: 6| Step: 6
Training loss: 3.2150595535766415
Validation loss: 2.4042345675039645

Epoch: 6| Step: 7
Training loss: 2.3376303570143753
Validation loss: 2.4121240790845055

Epoch: 6| Step: 8
Training loss: 2.5333359212192903
Validation loss: 2.410514573688601

Epoch: 6| Step: 9
Training loss: 2.8054546698968763
Validation loss: 2.4056867471098675

Epoch: 6| Step: 10
Training loss: 3.0623818199554815
Validation loss: 2.4194589663558492

Epoch: 6| Step: 11
Training loss: 2.84407561397767
Validation loss: 2.4245548956596417

Epoch: 6| Step: 12
Training loss: 2.871476377565043
Validation loss: 2.4196848757697005

Epoch: 6| Step: 13
Training loss: 2.9346388823103724
Validation loss: 2.4242769744782136

Epoch: 85| Step: 0
Training loss: 2.3643693421003955
Validation loss: 2.424595122795369

Epoch: 6| Step: 1
Training loss: 2.1683535122744897
Validation loss: 2.419423239810906

Epoch: 6| Step: 2
Training loss: 3.0476165651555394
Validation loss: 2.427048552776777

Epoch: 6| Step: 3
Training loss: 3.0939842674876252
Validation loss: 2.417137171976256

Epoch: 6| Step: 4
Training loss: 2.8331742709520995
Validation loss: 2.398218528973247

Epoch: 6| Step: 5
Training loss: 2.5044730224923257
Validation loss: 2.4148411445342064

Epoch: 6| Step: 6
Training loss: 2.67116622000851
Validation loss: 2.4228311864125525

Epoch: 6| Step: 7
Training loss: 2.6581345100151985
Validation loss: 2.4364348588281644

Epoch: 6| Step: 8
Training loss: 2.46984800234004
Validation loss: 2.4242625164770635

Epoch: 6| Step: 9
Training loss: 2.9687540154680905
Validation loss: 2.4252714160618627

Epoch: 6| Step: 10
Training loss: 1.861485157413825
Validation loss: 2.4040002073804154

Epoch: 6| Step: 11
Training loss: 2.7855307392813313
Validation loss: 2.44571822044516

Epoch: 6| Step: 12
Training loss: 3.0343209667482522
Validation loss: 2.4195202799600053

Epoch: 6| Step: 13
Training loss: 3.0932524309869445
Validation loss: 2.432004647407088

Epoch: 86| Step: 0
Training loss: 2.7373623469333035
Validation loss: 2.426542804356188

Epoch: 6| Step: 1
Training loss: 1.8570167910053494
Validation loss: 2.3985040464445544

Epoch: 6| Step: 2
Training loss: 2.5953177803991756
Validation loss: 2.39260887355605

Epoch: 6| Step: 3
Training loss: 2.506225273790415
Validation loss: 2.4009798249411847

Epoch: 6| Step: 4
Training loss: 2.9970607664193034
Validation loss: 2.4129811324826873

Epoch: 6| Step: 5
Training loss: 2.9702681022909876
Validation loss: 2.3983514365554175

Epoch: 6| Step: 6
Training loss: 3.0751886449495043
Validation loss: 2.409863007382313

Epoch: 6| Step: 7
Training loss: 2.4808194610887844
Validation loss: 2.3951266244712524

Epoch: 6| Step: 8
Training loss: 2.513296625424099
Validation loss: 2.396571822308107

Epoch: 6| Step: 9
Training loss: 2.9313397033890563
Validation loss: 2.3986006621099127

Epoch: 6| Step: 10
Training loss: 2.2751727740736496
Validation loss: 2.398154695226475

Epoch: 6| Step: 11
Training loss: 3.089283811661554
Validation loss: 2.4121412339136095

Epoch: 6| Step: 12
Training loss: 2.7342074097637385
Validation loss: 2.417269119965665

Epoch: 6| Step: 13
Training loss: 2.304853737218369
Validation loss: 2.4078641697067926

Epoch: 87| Step: 0
Training loss: 2.813146389750888
Validation loss: 2.393386690130743

Epoch: 6| Step: 1
Training loss: 2.566219421739676
Validation loss: 2.414762777751408

Epoch: 6| Step: 2
Training loss: 2.9884762370004236
Validation loss: 2.4140110325652473

Epoch: 6| Step: 3
Training loss: 2.970711953214611
Validation loss: 2.4318507843389408

Epoch: 6| Step: 4
Training loss: 2.3435725844308926
Validation loss: 2.4179387628888316

Epoch: 6| Step: 5
Training loss: 2.8281386570047498
Validation loss: 2.398858067203308

Epoch: 6| Step: 6
Training loss: 3.038527728495486
Validation loss: 2.4163976267787515

Epoch: 6| Step: 7
Training loss: 2.5574524641793177
Validation loss: 2.391464216926441

Epoch: 6| Step: 8
Training loss: 3.087835650404058
Validation loss: 2.4103552833393462

Epoch: 6| Step: 9
Training loss: 2.447181450567561
Validation loss: 2.41140165448193

Epoch: 6| Step: 10
Training loss: 2.807283098329244
Validation loss: 2.4119088697254383

Epoch: 6| Step: 11
Training loss: 2.141799047908345
Validation loss: 2.412329788702633

Epoch: 6| Step: 12
Training loss: 2.5748619005521993
Validation loss: 2.4170538161131216

Epoch: 6| Step: 13
Training loss: 2.059959928252455
Validation loss: 2.4081816775160463

Epoch: 88| Step: 0
Training loss: 2.7567534317821347
Validation loss: 2.415241097509677

Epoch: 6| Step: 1
Training loss: 2.5125195782406315
Validation loss: 2.415122413595957

Epoch: 6| Step: 2
Training loss: 2.5239337633936216
Validation loss: 2.410454391292201

Epoch: 6| Step: 3
Training loss: 2.488989425324061
Validation loss: 2.417630930044753

Epoch: 6| Step: 4
Training loss: 2.543927505635855
Validation loss: 2.402916836923623

Epoch: 6| Step: 5
Training loss: 2.873947282534613
Validation loss: 2.3891754806794743

Epoch: 6| Step: 6
Training loss: 2.9785799813744025
Validation loss: 2.4155371497700537

Epoch: 6| Step: 7
Training loss: 3.1035763138634307
Validation loss: 2.4127633942400406

Epoch: 6| Step: 8
Training loss: 2.960125089528194
Validation loss: 2.3994817715404926

Epoch: 6| Step: 9
Training loss: 2.2584735470232453
Validation loss: 2.418342045309591

Epoch: 6| Step: 10
Training loss: 2.8603245560350197
Validation loss: 2.4107414669664573

Epoch: 6| Step: 11
Training loss: 2.536342819267653
Validation loss: 2.387821990406696

Epoch: 6| Step: 12
Training loss: 2.6340851467044706
Validation loss: 2.3999730993971435

Epoch: 6| Step: 13
Training loss: 2.1432319971732587
Validation loss: 2.4107525127275404

Epoch: 89| Step: 0
Training loss: 2.990768534405764
Validation loss: 2.4081957987900524

Epoch: 6| Step: 1
Training loss: 2.578475835799751
Validation loss: 2.4221367066424415

Epoch: 6| Step: 2
Training loss: 2.650264503666019
Validation loss: 2.410151912299521

Epoch: 6| Step: 3
Training loss: 2.026863644003779
Validation loss: 2.4214293250795986

Epoch: 6| Step: 4
Training loss: 2.8372658385062355
Validation loss: 2.408388326356033

Epoch: 6| Step: 5
Training loss: 3.2111252036073257
Validation loss: 2.3993076014017447

Epoch: 6| Step: 6
Training loss: 2.5177338095530675
Validation loss: 2.393798574711267

Epoch: 6| Step: 7
Training loss: 2.80486039927766
Validation loss: 2.414322069709336

Epoch: 6| Step: 8
Training loss: 2.8884968939987843
Validation loss: 2.4078818664675867

Epoch: 6| Step: 9
Training loss: 2.6678363102537053
Validation loss: 2.408551176261677

Epoch: 6| Step: 10
Training loss: 2.609391994763613
Validation loss: 2.4006101347589976

Epoch: 6| Step: 11
Training loss: 2.2385235666922236
Validation loss: 2.40126793295998

Epoch: 6| Step: 12
Training loss: 2.901393976283682
Validation loss: 2.4124359216712694

Epoch: 6| Step: 13
Training loss: 2.323358354073446
Validation loss: 2.432355227786898

Epoch: 90| Step: 0
Training loss: 2.4316782753109303
Validation loss: 2.4231029815080976

Epoch: 6| Step: 1
Training loss: 2.833130343028428
Validation loss: 2.4009262805351494

Epoch: 6| Step: 2
Training loss: 2.901850498021256
Validation loss: 2.4221774703302734

Epoch: 6| Step: 3
Training loss: 2.2959829661305675
Validation loss: 2.4082691014027273

Epoch: 6| Step: 4
Training loss: 2.4561050682891867
Validation loss: 2.410044561830318

Epoch: 6| Step: 5
Training loss: 2.385115714155116
Validation loss: 2.386635426314377

Epoch: 6| Step: 6
Training loss: 2.376843389581272
Validation loss: 2.410157208377596

Epoch: 6| Step: 7
Training loss: 2.4725767969561034
Validation loss: 2.4146316833788366

Epoch: 6| Step: 8
Training loss: 2.7542192862866104
Validation loss: 2.414240788201003

Epoch: 6| Step: 9
Training loss: 3.0622273537854716
Validation loss: 2.4200053979719724

Epoch: 6| Step: 10
Training loss: 3.4439176819784967
Validation loss: 2.4127664883340416

Epoch: 6| Step: 11
Training loss: 2.1202119852640386
Validation loss: 2.4066392594094554

Epoch: 6| Step: 12
Training loss: 2.7616610811031617
Validation loss: 2.416925789459774

Epoch: 6| Step: 13
Training loss: 3.038833727230388
Validation loss: 2.4157372170007645

Epoch: 91| Step: 0
Training loss: 2.5835552940586535
Validation loss: 2.4176837529804374

Epoch: 6| Step: 1
Training loss: 2.127773270409936
Validation loss: 2.4172777167883637

Epoch: 6| Step: 2
Training loss: 2.55257680883862
Validation loss: 2.4160806272752575

Epoch: 6| Step: 3
Training loss: 2.569916854136825
Validation loss: 2.399799700423387

Epoch: 6| Step: 4
Training loss: 2.740301021273908
Validation loss: 2.410366128788118

Epoch: 6| Step: 5
Training loss: 2.4365784296775113
Validation loss: 2.388330541207104

Epoch: 6| Step: 6
Training loss: 2.1995500277800075
Validation loss: 2.4131665142578815

Epoch: 6| Step: 7
Training loss: 2.561197833921156
Validation loss: 2.404727077237734

Epoch: 6| Step: 8
Training loss: 2.768581383524289
Validation loss: 2.4369770169482314

Epoch: 6| Step: 9
Training loss: 2.987163259769231
Validation loss: 2.4132762785776474

Epoch: 6| Step: 10
Training loss: 2.8770359957090332
Validation loss: 2.3947624795220177

Epoch: 6| Step: 11
Training loss: 3.3464086782960765
Validation loss: 2.420392592398281

Epoch: 6| Step: 12
Training loss: 2.592119646707671
Validation loss: 2.4003404472406027

Epoch: 6| Step: 13
Training loss: 2.978986418991146
Validation loss: 2.4086350222176938

Epoch: 92| Step: 0
Training loss: 2.407107906241438
Validation loss: 2.4192634488007454

Epoch: 6| Step: 1
Training loss: 2.302063977834768
Validation loss: 2.4114913833625913

Epoch: 6| Step: 2
Training loss: 3.3544869279889626
Validation loss: 2.396811396845674

Epoch: 6| Step: 3
Training loss: 2.5841022905706197
Validation loss: 2.416112234344527

Epoch: 6| Step: 4
Training loss: 3.3204943079819937
Validation loss: 2.4086037119087234

Epoch: 6| Step: 5
Training loss: 2.885579422493102
Validation loss: 2.419524806420329

Epoch: 6| Step: 6
Training loss: 2.6935919093498537
Validation loss: 2.426702584041196

Epoch: 6| Step: 7
Training loss: 2.3717166893036126
Validation loss: 2.407731472596007

Epoch: 6| Step: 8
Training loss: 2.54163950504319
Validation loss: 2.430670538397997

Epoch: 6| Step: 9
Training loss: 2.566689950251143
Validation loss: 2.4123560250887737

Epoch: 6| Step: 10
Training loss: 2.7728576053909024
Validation loss: 2.408366567566398

Epoch: 6| Step: 11
Training loss: 2.761636562824108
Validation loss: 2.4206077178974192

Epoch: 6| Step: 12
Training loss: 2.1849878327404095
Validation loss: 2.4236373200250028

Epoch: 6| Step: 13
Training loss: 2.137304807975129
Validation loss: 2.426436526656978

Epoch: 93| Step: 0
Training loss: 2.6938736322978385
Validation loss: 2.3949484686906297

Epoch: 6| Step: 1
Training loss: 2.549381263315597
Validation loss: 2.4170931180644453

Epoch: 6| Step: 2
Training loss: 2.4462015406623925
Validation loss: 2.3989733998182885

Epoch: 6| Step: 3
Training loss: 3.0622278209328124
Validation loss: 2.4218844209475217

Epoch: 6| Step: 4
Training loss: 2.688509108474226
Validation loss: 2.410219568582332

Epoch: 6| Step: 5
Training loss: 2.551383024912808
Validation loss: 2.413777328529126

Epoch: 6| Step: 6
Training loss: 2.384556066754994
Validation loss: 2.3912279544376287

Epoch: 6| Step: 7
Training loss: 3.224971646916153
Validation loss: 2.411005955813374

Epoch: 6| Step: 8
Training loss: 2.8723560283228093
Validation loss: 2.4030210140430692

Epoch: 6| Step: 9
Training loss: 2.387194197478414
Validation loss: 2.394241183484602

Epoch: 6| Step: 10
Training loss: 3.0739308553251994
Validation loss: 2.4002875352794235

Epoch: 6| Step: 11
Training loss: 2.2035624834017336
Validation loss: 2.4152120456414097

Epoch: 6| Step: 12
Training loss: 2.5997760126026908
Validation loss: 2.4076318181193366

Epoch: 6| Step: 13
Training loss: 2.199526831287851
Validation loss: 2.4233424657429055

Epoch: 94| Step: 0
Training loss: 2.9943966989322193
Validation loss: 2.4032368859647306

Epoch: 6| Step: 1
Training loss: 2.2916581471602706
Validation loss: 2.403801656748186

Epoch: 6| Step: 2
Training loss: 2.316436921764158
Validation loss: 2.3962970907206294

Epoch: 6| Step: 3
Training loss: 3.1674593552388077
Validation loss: 2.421628944687483

Epoch: 6| Step: 4
Training loss: 2.4314045128841557
Validation loss: 2.3847985748234333

Epoch: 6| Step: 5
Training loss: 2.6230805054736313
Validation loss: 2.3892931508671307

Epoch: 6| Step: 6
Training loss: 3.111316783858018
Validation loss: 2.398484168961952

Epoch: 6| Step: 7
Training loss: 2.543726185680142
Validation loss: 2.3923267664246146

Epoch: 6| Step: 8
Training loss: 2.662883866984099
Validation loss: 2.399397469500336

Epoch: 6| Step: 9
Training loss: 2.9046590408646518
Validation loss: 2.409020473833287

Epoch: 6| Step: 10
Training loss: 2.4906161625225502
Validation loss: 2.395964200448073

Epoch: 6| Step: 11
Training loss: 2.327514158670893
Validation loss: 2.4108942772335564

Epoch: 6| Step: 12
Training loss: 2.7406751151814945
Validation loss: 2.409880138414289

Epoch: 6| Step: 13
Training loss: 2.6537638978958067
Validation loss: 2.405590576963652

Epoch: 95| Step: 0
Training loss: 2.338279953028061
Validation loss: 2.414835047650033

Epoch: 6| Step: 1
Training loss: 2.59448048060366
Validation loss: 2.398779156887766

Epoch: 6| Step: 2
Training loss: 2.894864659019998
Validation loss: 2.413649756870384

Epoch: 6| Step: 3
Training loss: 3.204943926673307
Validation loss: 2.410526246902192

Epoch: 6| Step: 4
Training loss: 2.44531571750612
Validation loss: 2.397339177939521

Epoch: 6| Step: 5
Training loss: 2.6675926825913368
Validation loss: 2.3964464306452706

Epoch: 6| Step: 6
Training loss: 2.4025215889459894
Validation loss: 2.4297178897171205

Epoch: 6| Step: 7
Training loss: 1.7440022139185232
Validation loss: 2.4016218942895815

Epoch: 6| Step: 8
Training loss: 2.3214560622379583
Validation loss: 2.420008624759886

Epoch: 6| Step: 9
Training loss: 2.443580282030153
Validation loss: 2.409085358375998

Epoch: 6| Step: 10
Training loss: 3.1023375650160268
Validation loss: 2.4081418404926973

Epoch: 6| Step: 11
Training loss: 3.164820300118706
Validation loss: 2.4166979736433225

Epoch: 6| Step: 12
Training loss: 2.644937819271005
Validation loss: 2.4013943848979324

Epoch: 6| Step: 13
Training loss: 2.9314647929344733
Validation loss: 2.4009035940209724

Epoch: 96| Step: 0
Training loss: 2.614141074742292
Validation loss: 2.3981827051458464

Epoch: 6| Step: 1
Training loss: 3.0275388987000795
Validation loss: 2.4077995019335776

Epoch: 6| Step: 2
Training loss: 1.840591052119557
Validation loss: 2.39630619713223

Epoch: 6| Step: 3
Training loss: 2.57319548997002
Validation loss: 2.3980730464010374

Epoch: 6| Step: 4
Training loss: 3.1173496443183337
Validation loss: 2.4089776230260624

Epoch: 6| Step: 5
Training loss: 2.8966322055371947
Validation loss: 2.420194103806366

Epoch: 6| Step: 6
Training loss: 2.392806111586663
Validation loss: 2.405002527127522

Epoch: 6| Step: 7
Training loss: 2.911900104087797
Validation loss: 2.418989472573563

Epoch: 6| Step: 8
Training loss: 2.23383821028275
Validation loss: 2.400939238975

Epoch: 6| Step: 9
Training loss: 2.531362083685039
Validation loss: 2.400301882427934

Epoch: 6| Step: 10
Training loss: 2.352401431670951
Validation loss: 2.4034773160996084

Epoch: 6| Step: 11
Training loss: 3.1947811962777424
Validation loss: 2.400549262996943

Epoch: 6| Step: 12
Training loss: 2.360198123665232
Validation loss: 2.399473715148944

Epoch: 6| Step: 13
Training loss: 3.066318855741073
Validation loss: 2.4193562515145284

Epoch: 97| Step: 0
Training loss: 2.7593247371256124
Validation loss: 2.399393925442973

Epoch: 6| Step: 1
Training loss: 2.3312964631633006
Validation loss: 2.4133947643457057

Epoch: 6| Step: 2
Training loss: 3.2826728279072475
Validation loss: 2.4176351090527595

Epoch: 6| Step: 3
Training loss: 2.828933347389466
Validation loss: 2.4247550197217995

Epoch: 6| Step: 4
Training loss: 2.9248293052490686
Validation loss: 2.3983054876130185

Epoch: 6| Step: 5
Training loss: 1.887828808369735
Validation loss: 2.396899353101283

Epoch: 6| Step: 6
Training loss: 2.6393516224054605
Validation loss: 2.3965104232859264

Epoch: 6| Step: 7
Training loss: 2.3033072783804025
Validation loss: 2.432882598478875

Epoch: 6| Step: 8
Training loss: 2.4370617594823587
Validation loss: 2.4252565718199435

Epoch: 6| Step: 9
Training loss: 2.5221236738575907
Validation loss: 2.393893275951375

Epoch: 6| Step: 10
Training loss: 2.647522354679989
Validation loss: 2.4092180974347994

Epoch: 6| Step: 11
Training loss: 2.827720739650826
Validation loss: 2.412826740561124

Epoch: 6| Step: 12
Training loss: 3.0046501677083906
Validation loss: 2.409276698646611

Epoch: 6| Step: 13
Training loss: 2.4662635933549275
Validation loss: 2.409188185495444

Epoch: 98| Step: 0
Training loss: 2.648388167290353
Validation loss: 2.417232126553337

Epoch: 6| Step: 1
Training loss: 2.133008116530058
Validation loss: 2.4163161180174786

Epoch: 6| Step: 2
Training loss: 2.7615350341121703
Validation loss: 2.415346219470316

Epoch: 6| Step: 3
Training loss: 2.9931205709014006
Validation loss: 2.416658668448254

Epoch: 6| Step: 4
Training loss: 2.9319811984678457
Validation loss: 2.4251389087235458

Epoch: 6| Step: 5
Training loss: 2.0174956401792024
Validation loss: 2.409531046522659

Epoch: 6| Step: 6
Training loss: 3.048805290493445
Validation loss: 2.4329081996334025

Epoch: 6| Step: 7
Training loss: 2.6129503254422497
Validation loss: 2.4147821984953395

Epoch: 6| Step: 8
Training loss: 2.2026054906100696
Validation loss: 2.422628469027755

Epoch: 6| Step: 9
Training loss: 2.529618667693388
Validation loss: 2.4097840654049008

Epoch: 6| Step: 10
Training loss: 2.745648669534417
Validation loss: 2.412241528926947

Epoch: 6| Step: 11
Training loss: 2.825397503998867
Validation loss: 2.415024967440329

Epoch: 6| Step: 12
Training loss: 2.606236563448952
Validation loss: 2.413560592586581

Epoch: 6| Step: 13
Training loss: 2.9558499797491757
Validation loss: 2.4071961572180363

Epoch: 99| Step: 0
Training loss: 3.0371988657434406
Validation loss: 2.410785002093621

Epoch: 6| Step: 1
Training loss: 2.505523682941602
Validation loss: 2.424054631935332

Epoch: 6| Step: 2
Training loss: 3.0703365722955023
Validation loss: 2.3969776557753897

Epoch: 6| Step: 3
Training loss: 2.951885467840272
Validation loss: 2.4198200676141055

Epoch: 6| Step: 4
Training loss: 2.195298598710435
Validation loss: 2.4055452565297926

Epoch: 6| Step: 5
Training loss: 2.681000146139469
Validation loss: 2.4099135937606486

Epoch: 6| Step: 6
Training loss: 2.8672111156852718
Validation loss: 2.4075083729663067

Epoch: 6| Step: 7
Training loss: 2.4917625136636743
Validation loss: 2.4106701303572513

Epoch: 6| Step: 8
Training loss: 2.487464663000565
Validation loss: 2.413207833688787

Epoch: 6| Step: 9
Training loss: 2.658057103010808
Validation loss: 2.397044351302283

Epoch: 6| Step: 10
Training loss: 2.2930709582136957
Validation loss: 2.4197925841403936

Epoch: 6| Step: 11
Training loss: 2.2541481562598924
Validation loss: 2.4161941690883064

Epoch: 6| Step: 12
Training loss: 2.5766795412295487
Validation loss: 2.423879242257098

Epoch: 6| Step: 13
Training loss: 2.8364960091608364
Validation loss: 2.405159962122501

Epoch: 100| Step: 0
Training loss: 2.3316216548404247
Validation loss: 2.402971991679166

Epoch: 6| Step: 1
Training loss: 2.8154586488819993
Validation loss: 2.4231381385612476

Epoch: 6| Step: 2
Training loss: 2.338713256612549
Validation loss: 2.395864310115604

Epoch: 6| Step: 3
Training loss: 2.4459237501684683
Validation loss: 2.4110192726393125

Epoch: 6| Step: 4
Training loss: 2.6106637296390605
Validation loss: 2.412042793124539

Epoch: 6| Step: 5
Training loss: 2.532860420239684
Validation loss: 2.400323845692314

Epoch: 6| Step: 6
Training loss: 2.5556816010097476
Validation loss: 2.416115297623508

Epoch: 6| Step: 7
Training loss: 3.0174235776564533
Validation loss: 2.4012219971210342

Epoch: 6| Step: 8
Training loss: 2.651158378345268
Validation loss: 2.409392626355445

Epoch: 6| Step: 9
Training loss: 2.7580846376661965
Validation loss: 2.411353963990964

Epoch: 6| Step: 10
Training loss: 2.375318405491319
Validation loss: 2.399281334522633

Epoch: 6| Step: 11
Training loss: 3.0763364911311375
Validation loss: 2.4101466087640024

Epoch: 6| Step: 12
Training loss: 2.555317279054983
Validation loss: 2.409188754794092

Epoch: 6| Step: 13
Training loss: 3.067359027934291
Validation loss: 2.4151460497919417

Epoch: 101| Step: 0
Training loss: 1.9229707153042463
Validation loss: 2.4072289405922

Epoch: 6| Step: 1
Training loss: 2.483486280489022
Validation loss: 2.4177873553249962

Epoch: 6| Step: 2
Training loss: 2.9741026158025767
Validation loss: 2.4094244073430215

Epoch: 6| Step: 3
Training loss: 3.586512434336509
Validation loss: 2.4042872619823252

Epoch: 6| Step: 4
Training loss: 2.446856611433638
Validation loss: 2.4384137721303962

Epoch: 6| Step: 5
Training loss: 2.5483798396488906
Validation loss: 2.3937337705977213

Epoch: 6| Step: 6
Training loss: 2.5306702880123315
Validation loss: 2.4073197003812528

Epoch: 6| Step: 7
Training loss: 2.257455764624379
Validation loss: 2.4064324134964816

Epoch: 6| Step: 8
Training loss: 2.323332494172757
Validation loss: 2.398840749519866

Epoch: 6| Step: 9
Training loss: 2.2344209893035343
Validation loss: 2.408396853755268

Epoch: 6| Step: 10
Training loss: 2.1959025720131407
Validation loss: 2.401086116869849

Epoch: 6| Step: 11
Training loss: 2.9103214089040064
Validation loss: 2.4038430726289524

Epoch: 6| Step: 12
Training loss: 3.1644958952794098
Validation loss: 2.397780608185972

Epoch: 6| Step: 13
Training loss: 3.022456520089664
Validation loss: 2.408075528447658

Epoch: 102| Step: 0
Training loss: 2.5400908749761704
Validation loss: 2.4179849695822027

Epoch: 6| Step: 1
Training loss: 2.9845724789456995
Validation loss: 2.393218522429394

Epoch: 6| Step: 2
Training loss: 2.500744708722897
Validation loss: 2.417827154300312

Epoch: 6| Step: 3
Training loss: 2.7990898867092806
Validation loss: 2.418013618115636

Epoch: 6| Step: 4
Training loss: 2.931164666664189
Validation loss: 2.4199814776568815

Epoch: 6| Step: 5
Training loss: 2.8036244537504014
Validation loss: 2.409988522732681

Epoch: 6| Step: 6
Training loss: 2.4867159772420626
Validation loss: 2.412495919679548

Epoch: 6| Step: 7
Training loss: 2.653995319945888
Validation loss: 2.418866672231393

Epoch: 6| Step: 8
Training loss: 2.302623587572959
Validation loss: 2.4140747741159925

Epoch: 6| Step: 9
Training loss: 1.91635897143051
Validation loss: 2.4270036024038695

Epoch: 6| Step: 10
Training loss: 2.6163922824071038
Validation loss: 2.412712681133877

Epoch: 6| Step: 11
Training loss: 3.0122092078960567
Validation loss: 2.420078519786186

Epoch: 6| Step: 12
Training loss: 2.570296452712776
Validation loss: 2.4037567942490896

Epoch: 6| Step: 13
Training loss: 2.902302183364443
Validation loss: 2.4061745135161474

Epoch: 103| Step: 0
Training loss: 2.530794455897778
Validation loss: 2.4245650717236047

Epoch: 6| Step: 1
Training loss: 2.5688700701271023
Validation loss: 2.4167727315227707

Epoch: 6| Step: 2
Training loss: 2.36279513821519
Validation loss: 2.429397641159831

Epoch: 6| Step: 3
Training loss: 2.7162325373727705
Validation loss: 2.4085315168762964

Epoch: 6| Step: 4
Training loss: 2.355678871613657
Validation loss: 2.4274275974489004

Epoch: 6| Step: 5
Training loss: 2.663893171282011
Validation loss: 2.395804204848436

Epoch: 6| Step: 6
Training loss: 2.9978898892632753
Validation loss: 2.4170324121639237

Epoch: 6| Step: 7
Training loss: 2.634793857567419
Validation loss: 2.419897353179249

Epoch: 6| Step: 8
Training loss: 2.296395076515064
Validation loss: 2.406750821201266

Epoch: 6| Step: 9
Training loss: 2.591684369172929
Validation loss: 2.4165130908726966

Epoch: 6| Step: 10
Training loss: 3.0432061432091513
Validation loss: 2.4161356741126645

Epoch: 6| Step: 11
Training loss: 2.6650787831411518
Validation loss: 2.41446322115166

Epoch: 6| Step: 12
Training loss: 2.242615130646929
Validation loss: 2.4234805212726376

Epoch: 6| Step: 13
Training loss: 3.4131814967845875
Validation loss: 2.4197032007015844

Epoch: 104| Step: 0
Training loss: 2.886944381299677
Validation loss: 2.4296456087946714

Epoch: 6| Step: 1
Training loss: 2.7292637601475667
Validation loss: 2.4407136786483608

Epoch: 6| Step: 2
Training loss: 2.5049208848227504
Validation loss: 2.413227577677454

Epoch: 6| Step: 3
Training loss: 2.6223527184395365
Validation loss: 2.40280807387184

Epoch: 6| Step: 4
Training loss: 2.40001395539359
Validation loss: 2.4216516937609844

Epoch: 6| Step: 5
Training loss: 2.810119469163053
Validation loss: 2.4200818555865458

Epoch: 6| Step: 6
Training loss: 2.8223940282209194
Validation loss: 2.429549625176323

Epoch: 6| Step: 7
Training loss: 3.215625172013555
Validation loss: 2.4247000406318246

Epoch: 6| Step: 8
Training loss: 2.0591787704962154
Validation loss: 2.425365892569497

Epoch: 6| Step: 9
Training loss: 2.8182331567154537
Validation loss: 2.4017910042400192

Epoch: 6| Step: 10
Training loss: 3.1534931493454605
Validation loss: 2.421653040341911

Epoch: 6| Step: 11
Training loss: 2.280936650742345
Validation loss: 2.4090495290691925

Epoch: 6| Step: 12
Training loss: 2.139678745934357
Validation loss: 2.4087835514501594

Epoch: 6| Step: 13
Training loss: 1.9696191352746757
Validation loss: 2.4202438657124303

Epoch: 105| Step: 0
Training loss: 3.201069092977016
Validation loss: 2.4213000750092335

Epoch: 6| Step: 1
Training loss: 2.0771198566660276
Validation loss: 2.4239088872339214

Epoch: 6| Step: 2
Training loss: 2.408135109193851
Validation loss: 2.4060749980615057

Epoch: 6| Step: 3
Training loss: 2.472684983603291
Validation loss: 2.423774470287345

Epoch: 6| Step: 4
Training loss: 2.2462849145891948
Validation loss: 2.4022944176777057

Epoch: 6| Step: 5
Training loss: 2.6670422488207097
Validation loss: 2.4217762726168535

Epoch: 6| Step: 6
Training loss: 2.6778036452222787
Validation loss: 2.42410775483943

Epoch: 6| Step: 7
Training loss: 2.9144236159355006
Validation loss: 2.4138095966295228

Epoch: 6| Step: 8
Training loss: 2.8013100011919994
Validation loss: 2.4297357612509196

Epoch: 6| Step: 9
Training loss: 2.7984985242672415
Validation loss: 2.428065892288265

Epoch: 6| Step: 10
Training loss: 2.801429407518826
Validation loss: 2.4268157968563395

Epoch: 6| Step: 11
Training loss: 2.107824589360253
Validation loss: 2.418048767529027

Epoch: 6| Step: 12
Training loss: 2.8348071995861877
Validation loss: 2.4075569584882985

Epoch: 6| Step: 13
Training loss: 2.410436085386754
Validation loss: 2.407932701543437

Epoch: 106| Step: 0
Training loss: 3.0519806168666896
Validation loss: 2.442866798923085

Epoch: 6| Step: 1
Training loss: 2.1070462405612465
Validation loss: 2.3901659633181356

Epoch: 6| Step: 2
Training loss: 2.516434628061037
Validation loss: 2.4008205117019825

Epoch: 6| Step: 3
Training loss: 2.9685267314275943
Validation loss: 2.4009937120273377

Epoch: 6| Step: 4
Training loss: 2.8259949645249307
Validation loss: 2.4066802152843656

Epoch: 6| Step: 5
Training loss: 2.6128987715245255
Validation loss: 2.3974111111864556

Epoch: 6| Step: 6
Training loss: 1.8393946785996986
Validation loss: 2.409112247298736

Epoch: 6| Step: 7
Training loss: 2.8384141432554926
Validation loss: 2.420520424034392

Epoch: 6| Step: 8
Training loss: 2.518725078450006
Validation loss: 2.4054259652638987

Epoch: 6| Step: 9
Training loss: 3.112709289622804
Validation loss: 2.4026892933021795

Epoch: 6| Step: 10
Training loss: 2.4366676670112417
Validation loss: 2.403101115909019

Epoch: 6| Step: 11
Training loss: 2.3327488394225275
Validation loss: 2.417870276628016

Epoch: 6| Step: 12
Training loss: 2.8504445850209734
Validation loss: 2.396295100828149

Epoch: 6| Step: 13
Training loss: 2.6261009450716197
Validation loss: 2.411638338793851

Epoch: 107| Step: 0
Training loss: 2.5944515336634377
Validation loss: 2.4213849712842346

Epoch: 6| Step: 1
Training loss: 2.3573994228554893
Validation loss: 2.418180647224568

Epoch: 6| Step: 2
Training loss: 3.263569161917912
Validation loss: 2.41656085989577

Epoch: 6| Step: 3
Training loss: 2.3492661730461384
Validation loss: 2.402817996349187

Epoch: 6| Step: 4
Training loss: 3.0363451422417285
Validation loss: 2.408444163188004

Epoch: 6| Step: 5
Training loss: 2.348488455477841
Validation loss: 2.4198751967742953

Epoch: 6| Step: 6
Training loss: 2.4852113095863495
Validation loss: 2.420339144334169

Epoch: 6| Step: 7
Training loss: 2.938446054905608
Validation loss: 2.432370090891338

Epoch: 6| Step: 8
Training loss: 3.035884499786664
Validation loss: 2.398184952168177

Epoch: 6| Step: 9
Training loss: 2.2699141318931457
Validation loss: 2.4077258496259377

Epoch: 6| Step: 10
Training loss: 2.3122084150259035
Validation loss: 2.4158059536860748

Epoch: 6| Step: 11
Training loss: 2.462457580975609
Validation loss: 2.4033080613291546

Epoch: 6| Step: 12
Training loss: 2.530432298238148
Validation loss: 2.42075797264042

Epoch: 6| Step: 13
Training loss: 2.660808466472449
Validation loss: 2.398693389993224

Epoch: 108| Step: 0
Training loss: 3.339176936814886
Validation loss: 2.407331808669452

Epoch: 6| Step: 1
Training loss: 2.7526825912019888
Validation loss: 2.403515863027167

Epoch: 6| Step: 2
Training loss: 2.090032437086499
Validation loss: 2.4302620832367996

Epoch: 6| Step: 3
Training loss: 2.7707340442583894
Validation loss: 2.396949140319184

Epoch: 6| Step: 4
Training loss: 2.7585190686466903
Validation loss: 2.3925447583461708

Epoch: 6| Step: 5
Training loss: 2.7319162704013986
Validation loss: 2.406517252618888

Epoch: 6| Step: 6
Training loss: 2.561248194413226
Validation loss: 2.406838287474781

Epoch: 6| Step: 7
Training loss: 2.1524658168510835
Validation loss: 2.4035439885933156

Epoch: 6| Step: 8
Training loss: 2.5320668727366296
Validation loss: 2.4156088711669046

Epoch: 6| Step: 9
Training loss: 2.5077218012585294
Validation loss: 2.418063546817901

Epoch: 6| Step: 10
Training loss: 2.0092666050935697
Validation loss: 2.4145456142555437

Epoch: 6| Step: 11
Training loss: 2.3086058330703776
Validation loss: 2.4005287317782162

Epoch: 6| Step: 12
Training loss: 2.9782151167565525
Validation loss: 2.4096652318711578

Epoch: 6| Step: 13
Training loss: 3.1993463325445726
Validation loss: 2.4044933206016563

Epoch: 109| Step: 0
Training loss: 2.042649895199946
Validation loss: 2.400277635451297

Epoch: 6| Step: 1
Training loss: 2.313256320477637
Validation loss: 2.4066303401654374

Epoch: 6| Step: 2
Training loss: 2.640253887395071
Validation loss: 2.4046802767685804

Epoch: 6| Step: 3
Training loss: 3.102376451514487
Validation loss: 2.4056115733160075

Epoch: 6| Step: 4
Training loss: 2.444039595437722
Validation loss: 2.401017055946342

Epoch: 6| Step: 5
Training loss: 2.5531047619469267
Validation loss: 2.385184254178649

Epoch: 6| Step: 6
Training loss: 2.8245150462118014
Validation loss: 2.4055677356825425

Epoch: 6| Step: 7
Training loss: 2.4210607328868603
Validation loss: 2.3966648479703903

Epoch: 6| Step: 8
Training loss: 2.716787484959734
Validation loss: 2.395287838363201

Epoch: 6| Step: 9
Training loss: 2.671617194336597
Validation loss: 2.3995233736300365

Epoch: 6| Step: 10
Training loss: 3.2389476352756335
Validation loss: 2.432825202357345

Epoch: 6| Step: 11
Training loss: 2.605151018389007
Validation loss: 2.416763546295646

Epoch: 6| Step: 12
Training loss: 2.3606636620694275
Validation loss: 2.418749739645387

Epoch: 6| Step: 13
Training loss: 2.370658922624044
Validation loss: 2.4180960725975464

Epoch: 110| Step: 0
Training loss: 2.938756308863207
Validation loss: 2.4064064651543355

Epoch: 6| Step: 1
Training loss: 2.969308097983352
Validation loss: 2.413786669031947

Epoch: 6| Step: 2
Training loss: 2.89851745330678
Validation loss: 2.4057700620490863

Epoch: 6| Step: 3
Training loss: 2.1891982979214264
Validation loss: 2.396987313616065

Epoch: 6| Step: 4
Training loss: 2.840497514908638
Validation loss: 2.435475149175039

Epoch: 6| Step: 5
Training loss: 2.572087935651572
Validation loss: 2.421531288190877

Epoch: 6| Step: 6
Training loss: 2.5336205955398206
Validation loss: 2.405462550878153

Epoch: 6| Step: 7
Training loss: 2.228421475881509
Validation loss: 2.429027182100461

Epoch: 6| Step: 8
Training loss: 2.397417379632317
Validation loss: 2.3923216334085105

Epoch: 6| Step: 9
Training loss: 2.748154801429874
Validation loss: 2.4010509759228977

Epoch: 6| Step: 10
Training loss: 2.2449154093211003
Validation loss: 2.4311369180050404

Epoch: 6| Step: 11
Training loss: 2.5391703890840067
Validation loss: 2.448922188545246

Epoch: 6| Step: 12
Training loss: 2.712990458926203
Validation loss: 2.4191363826349095

Epoch: 6| Step: 13
Training loss: 2.8322671305323315
Validation loss: 2.4110652461720137

Epoch: 111| Step: 0
Training loss: 2.633900131921813
Validation loss: 2.406302923614801

Epoch: 6| Step: 1
Training loss: 3.7293757090592643
Validation loss: 2.4031435642442562

Epoch: 6| Step: 2
Training loss: 2.773188620132654
Validation loss: 2.4164784474497614

Epoch: 6| Step: 3
Training loss: 2.286151584448773
Validation loss: 2.390451556750414

Epoch: 6| Step: 4
Training loss: 2.3896805636760603
Validation loss: 2.42705105510065

Epoch: 6| Step: 5
Training loss: 2.5499735512951283
Validation loss: 2.397800236505515

Epoch: 6| Step: 6
Training loss: 2.5448129181215906
Validation loss: 2.4156313882682876

Epoch: 6| Step: 7
Training loss: 2.647176346632097
Validation loss: 2.400736593580338

Epoch: 6| Step: 8
Training loss: 2.632769123025692
Validation loss: 2.4119772350898323

Epoch: 6| Step: 9
Training loss: 2.730823150032186
Validation loss: 2.378790909003242

Epoch: 6| Step: 10
Training loss: 3.031397393172738
Validation loss: 2.3962876569038833

Epoch: 6| Step: 11
Training loss: 1.9209708591417396
Validation loss: 2.3962177558505613

Epoch: 6| Step: 12
Training loss: 1.9993938481168976
Validation loss: 2.3917394286198808

Epoch: 6| Step: 13
Training loss: 2.1192476166467293
Validation loss: 2.4210118709043313

Epoch: 112| Step: 0
Training loss: 2.984320994582529
Validation loss: 2.3918158621178907

Epoch: 6| Step: 1
Training loss: 2.6947771950593546
Validation loss: 2.3945570850683247

Epoch: 6| Step: 2
Training loss: 3.0161390113566777
Validation loss: 2.4136894530677897

Epoch: 6| Step: 3
Training loss: 2.1277687883754353
Validation loss: 2.408134811112809

Epoch: 6| Step: 4
Training loss: 2.8625782185491477
Validation loss: 2.4152854399433057

Epoch: 6| Step: 5
Training loss: 2.698563712944997
Validation loss: 2.4182459363745754

Epoch: 6| Step: 6
Training loss: 3.1100177963091102
Validation loss: 2.4085494647200467

Epoch: 6| Step: 7
Training loss: 2.9883982118143972
Validation loss: 2.4143196975419827

Epoch: 6| Step: 8
Training loss: 2.638491428849274
Validation loss: 2.4152848105191103

Epoch: 6| Step: 9
Training loss: 1.720029112214629
Validation loss: 2.4086646725464833

Epoch: 6| Step: 10
Training loss: 2.631333113782532
Validation loss: 2.4207003748204095

Epoch: 6| Step: 11
Training loss: 2.3368991671197876
Validation loss: 2.4209803849842277

Epoch: 6| Step: 12
Training loss: 1.9913720949221345
Validation loss: 2.402874950576565

Epoch: 6| Step: 13
Training loss: 2.13890251414045
Validation loss: 2.4026671724052036

Epoch: 113| Step: 0
Training loss: 2.7379976525697196
Validation loss: 2.414261982225684

Epoch: 6| Step: 1
Training loss: 2.588941414026913
Validation loss: 2.408504765165776

Epoch: 6| Step: 2
Training loss: 2.4080322403000975
Validation loss: 2.4318435699568637

Epoch: 6| Step: 3
Training loss: 2.3673510605107078
Validation loss: 2.417377688400771

Epoch: 6| Step: 4
Training loss: 2.2712918673127405
Validation loss: 2.404816412336618

Epoch: 6| Step: 5
Training loss: 2.9006334402252936
Validation loss: 2.41054993560959

Epoch: 6| Step: 6
Training loss: 2.8685174918436847
Validation loss: 2.419478604764008

Epoch: 6| Step: 7
Training loss: 2.21219084567935
Validation loss: 2.400641541848719

Epoch: 6| Step: 8
Training loss: 2.6316150692920126
Validation loss: 2.3961227773605316

Epoch: 6| Step: 9
Training loss: 2.8704748615492406
Validation loss: 2.4119354423143284

Epoch: 6| Step: 10
Training loss: 2.885544224385797
Validation loss: 2.4013186219344904

Epoch: 6| Step: 11
Training loss: 2.4358943639316313
Validation loss: 2.420527123008885

Epoch: 6| Step: 12
Training loss: 2.724283134590109
Validation loss: 2.4375157740955244

Epoch: 6| Step: 13
Training loss: 2.725128408783768
Validation loss: 2.4287086965533744

Epoch: 114| Step: 0
Training loss: 2.496393654347371
Validation loss: 2.404125338355715

Epoch: 6| Step: 1
Training loss: 3.226402740587451
Validation loss: 2.393602227096164

Epoch: 6| Step: 2
Training loss: 2.426103506013977
Validation loss: 2.3950835400723154

Epoch: 6| Step: 3
Training loss: 2.26903755740626
Validation loss: 2.404201361024337

Epoch: 6| Step: 4
Training loss: 1.9273560064735569
Validation loss: 2.391724183323286

Epoch: 6| Step: 5
Training loss: 2.853900776379315
Validation loss: 2.3935715191484035

Epoch: 6| Step: 6
Training loss: 2.798605782940517
Validation loss: 2.3943881708568786

Epoch: 6| Step: 7
Training loss: 2.502065091750843
Validation loss: 2.4026475224929955

Epoch: 6| Step: 8
Training loss: 2.6955598137215553
Validation loss: 2.4153419643269842

Epoch: 6| Step: 9
Training loss: 3.000039100392166
Validation loss: 2.42157996818911

Epoch: 6| Step: 10
Training loss: 2.610112617080024
Validation loss: 2.3921279124021706

Epoch: 6| Step: 11
Training loss: 2.4011461699962164
Validation loss: 2.418320877501527

Epoch: 6| Step: 12
Training loss: 2.694711634790954
Validation loss: 2.4079226276661982

Epoch: 6| Step: 13
Training loss: 1.8231069047753683
Validation loss: 2.387103871033154

Epoch: 115| Step: 0
Training loss: 2.4850942662126303
Validation loss: 2.4039326506672025

Epoch: 6| Step: 1
Training loss: 3.2601241365446736
Validation loss: 2.403750774835687

Epoch: 6| Step: 2
Training loss: 3.0418065879375713
Validation loss: 2.4028497634716417

Epoch: 6| Step: 3
Training loss: 2.0331501216374206
Validation loss: 2.381690774954879

Epoch: 6| Step: 4
Training loss: 3.1196469043565376
Validation loss: 2.3925723860543964

Epoch: 6| Step: 5
Training loss: 2.1803023588850396
Validation loss: 2.39820788407588

Epoch: 6| Step: 6
Training loss: 2.3965874411160213
Validation loss: 2.40168361896544

Epoch: 6| Step: 7
Training loss: 2.753969968234494
Validation loss: 2.4063945061524463

Epoch: 6| Step: 8
Training loss: 2.6971413420067933
Validation loss: 2.4050630588675808

Epoch: 6| Step: 9
Training loss: 2.582603864326029
Validation loss: 2.411886886532823

Epoch: 6| Step: 10
Training loss: 2.81092705716732
Validation loss: 2.41073826499429

Epoch: 6| Step: 11
Training loss: 1.926467247160544
Validation loss: 2.3999817603112064

Epoch: 6| Step: 12
Training loss: 2.5336546602082186
Validation loss: 2.4252698738209197

Epoch: 6| Step: 13
Training loss: 2.2761599046619234
Validation loss: 2.415345290747979

Epoch: 116| Step: 0
Training loss: 3.0415568571431266
Validation loss: 2.4055715082974634

Epoch: 6| Step: 1
Training loss: 2.14206240766636
Validation loss: 2.4178350164687767

Epoch: 6| Step: 2
Training loss: 2.997077153839129
Validation loss: 2.4214757213737617

Epoch: 6| Step: 3
Training loss: 2.779769846493608
Validation loss: 2.4006496140771816

Epoch: 6| Step: 4
Training loss: 2.5084099459010996
Validation loss: 2.4147915006079677

Epoch: 6| Step: 5
Training loss: 1.86716847429997
Validation loss: 2.3973956699090624

Epoch: 6| Step: 6
Training loss: 2.4851706328421033
Validation loss: 2.44210477343281

Epoch: 6| Step: 7
Training loss: 2.7504457632659256
Validation loss: 2.391650504392461

Epoch: 6| Step: 8
Training loss: 2.8226028399319993
Validation loss: 2.4108403655083332

Epoch: 6| Step: 9
Training loss: 2.3033230120606585
Validation loss: 2.395434664121245

Epoch: 6| Step: 10
Training loss: 2.6072731918633454
Validation loss: 2.4136927615858332

Epoch: 6| Step: 11
Training loss: 3.0664867997979317
Validation loss: 2.415344985065577

Epoch: 6| Step: 12
Training loss: 2.1567322564899154
Validation loss: 2.4029912084625757

Epoch: 6| Step: 13
Training loss: 2.729712385600242
Validation loss: 2.414460456262148

Epoch: 117| Step: 0
Training loss: 2.470055536734594
Validation loss: 2.391536333849741

Epoch: 6| Step: 1
Training loss: 2.7307281589209103
Validation loss: 2.4309193675115353

Epoch: 6| Step: 2
Training loss: 2.6650394203462566
Validation loss: 2.3959196063572836

Epoch: 6| Step: 3
Training loss: 2.673081332035788
Validation loss: 2.4070135672855892

Epoch: 6| Step: 4
Training loss: 2.497136192362765
Validation loss: 2.418024491767895

Epoch: 6| Step: 5
Training loss: 2.5268754245135914
Validation loss: 2.416604819547766

Epoch: 6| Step: 6
Training loss: 2.6220014793979596
Validation loss: 2.414789470750337

Epoch: 6| Step: 7
Training loss: 2.896686858124005
Validation loss: 2.4001011341758494

Epoch: 6| Step: 8
Training loss: 2.4598192368750564
Validation loss: 2.403684044084955

Epoch: 6| Step: 9
Training loss: 2.8302678373051178
Validation loss: 2.399777519773687

Epoch: 6| Step: 10
Training loss: 2.3478474721610345
Validation loss: 2.4209979334529805

Epoch: 6| Step: 11
Training loss: 2.4381096884357434
Validation loss: 2.3989601187147906

Epoch: 6| Step: 12
Training loss: 2.49656918673659
Validation loss: 2.408536743073992

Epoch: 6| Step: 13
Training loss: 3.024977811621636
Validation loss: 2.395643076001111

Epoch: 118| Step: 0
Training loss: 3.0872512531850997
Validation loss: 2.4192120453865518

Epoch: 6| Step: 1
Training loss: 3.002781373369917
Validation loss: 2.4315519380381647

Epoch: 6| Step: 2
Training loss: 2.6153839729489534
Validation loss: 2.4169419640669596

Epoch: 6| Step: 3
Training loss: 2.4158466745696625
Validation loss: 2.412528384504642

Epoch: 6| Step: 4
Training loss: 2.402357644141732
Validation loss: 2.410151982502681

Epoch: 6| Step: 5
Training loss: 2.3387064263318034
Validation loss: 2.419276343989885

Epoch: 6| Step: 6
Training loss: 2.5219934069360503
Validation loss: 2.437127737263652

Epoch: 6| Step: 7
Training loss: 2.363592155750045
Validation loss: 2.406477283642286

Epoch: 6| Step: 8
Training loss: 2.8937595177776116
Validation loss: 2.4055375950477114

Epoch: 6| Step: 9
Training loss: 2.2251522483599517
Validation loss: 2.421483899894938

Epoch: 6| Step: 10
Training loss: 1.795610596665089
Validation loss: 2.3950663123039577

Epoch: 6| Step: 11
Training loss: 2.970191525278863
Validation loss: 2.389212701417085

Epoch: 6| Step: 12
Training loss: 2.817180299670369
Validation loss: 2.4175906580769517

Epoch: 6| Step: 13
Training loss: 2.442340934360832
Validation loss: 2.410520104008209

Epoch: 119| Step: 0
Training loss: 3.3990548110318017
Validation loss: 2.3992349022513566

Epoch: 6| Step: 1
Training loss: 2.679834656525644
Validation loss: 2.414308363349414

Epoch: 6| Step: 2
Training loss: 2.5495596935632787
Validation loss: 2.4051028573494104

Epoch: 6| Step: 3
Training loss: 2.606487389600417
Validation loss: 2.399942691949387

Epoch: 6| Step: 4
Training loss: 2.4207801559131594
Validation loss: 2.4171831723294495

Epoch: 6| Step: 5
Training loss: 2.966065488044746
Validation loss: 2.410845932298828

Epoch: 6| Step: 6
Training loss: 3.1002686537956685
Validation loss: 2.395303267542016

Epoch: 6| Step: 7
Training loss: 2.095498223433473
Validation loss: 2.4160885969898596

Epoch: 6| Step: 8
Training loss: 2.453045691890778
Validation loss: 2.410071799588575

Epoch: 6| Step: 9
Training loss: 2.544002855935083
Validation loss: 2.423430075807001

Epoch: 6| Step: 10
Training loss: 2.3739764367005156
Validation loss: 2.4039139650339094

Epoch: 6| Step: 11
Training loss: 2.060268466455192
Validation loss: 2.402848156161036

Epoch: 6| Step: 12
Training loss: 2.3410834847628554
Validation loss: 2.4035010169494497

Epoch: 6| Step: 13
Training loss: 2.3665936924425033
Validation loss: 2.40511704573214

Epoch: 120| Step: 0
Training loss: 2.753644608858771
Validation loss: 2.396470600851489

Epoch: 6| Step: 1
Training loss: 2.761785223132563
Validation loss: 2.3897609158461046

Epoch: 6| Step: 2
Training loss: 2.683603167343829
Validation loss: 2.406792926625456

Epoch: 6| Step: 3
Training loss: 2.197717401472127
Validation loss: 2.3984979732321476

Epoch: 6| Step: 4
Training loss: 2.330523388407852
Validation loss: 2.405539042301308

Epoch: 6| Step: 5
Training loss: 2.441573431775892
Validation loss: 2.4067962265160103

Epoch: 6| Step: 6
Training loss: 2.649343150083071
Validation loss: 2.3930817948486274

Epoch: 6| Step: 7
Training loss: 2.66516448467007
Validation loss: 2.4005517224596375

Epoch: 6| Step: 8
Training loss: 2.436916183589383
Validation loss: 2.42127707963823

Epoch: 6| Step: 9
Training loss: 2.509140851223641
Validation loss: 2.411081180453209

Epoch: 6| Step: 10
Training loss: 2.171523470525804
Validation loss: 2.410748256388224

Epoch: 6| Step: 11
Training loss: 2.9088092323505026
Validation loss: 2.3925263925584503

Epoch: 6| Step: 12
Training loss: 2.5185428543670736
Validation loss: 2.4085207834440823

Epoch: 6| Step: 13
Training loss: 3.564337407154179
Validation loss: 2.3824173816068575

Epoch: 121| Step: 0
Training loss: 2.73267499120815
Validation loss: 2.4016525814973857

Epoch: 6| Step: 1
Training loss: 2.8125567112609193
Validation loss: 2.4012379102423966

Epoch: 6| Step: 2
Training loss: 2.4600417671689683
Validation loss: 2.4117904337308294

Epoch: 6| Step: 3
Training loss: 2.3665630662656234
Validation loss: 2.40134243990617

Epoch: 6| Step: 4
Training loss: 2.654203816088521
Validation loss: 2.3937046858212288

Epoch: 6| Step: 5
Training loss: 3.1998795605882586
Validation loss: 2.4015022821693637

Epoch: 6| Step: 6
Training loss: 2.2992490579135096
Validation loss: 2.3975161156510554

Epoch: 6| Step: 7
Training loss: 2.870083793453653
Validation loss: 2.4261993010458016

Epoch: 6| Step: 8
Training loss: 2.8484615657624692
Validation loss: 2.407012905876333

Epoch: 6| Step: 9
Training loss: 2.322685287196562
Validation loss: 2.43192948386116

Epoch: 6| Step: 10
Training loss: 2.2014357130310205
Validation loss: 2.4117822005476484

Epoch: 6| Step: 11
Training loss: 2.1293866376723964
Validation loss: 2.4222834057171223

Epoch: 6| Step: 12
Training loss: 2.549615240053772
Validation loss: 2.4191719581674684

Epoch: 6| Step: 13
Training loss: 2.651499730515327
Validation loss: 2.414636054438413

Epoch: 122| Step: 0
Training loss: 2.7491353149414817
Validation loss: 2.422216272142981

Epoch: 6| Step: 1
Training loss: 2.401270681011178
Validation loss: 2.399213631045142

Epoch: 6| Step: 2
Training loss: 2.4683735234476414
Validation loss: 2.431911509327643

Epoch: 6| Step: 3
Training loss: 2.3895744059716586
Validation loss: 2.4170556319399314

Epoch: 6| Step: 4
Training loss: 2.442100877744922
Validation loss: 2.3978815605179795

Epoch: 6| Step: 5
Training loss: 2.902790266270723
Validation loss: 2.433075456936154

Epoch: 6| Step: 6
Training loss: 3.122630327130016
Validation loss: 2.416913361700154

Epoch: 6| Step: 7
Training loss: 2.545511547757033
Validation loss: 2.413955624517017

Epoch: 6| Step: 8
Training loss: 2.4926093530723836
Validation loss: 2.4313039708138353

Epoch: 6| Step: 9
Training loss: 1.9825833860854334
Validation loss: 2.4134869195803015

Epoch: 6| Step: 10
Training loss: 2.8623370061720292
Validation loss: 2.443396227800099

Epoch: 6| Step: 11
Training loss: 2.4338149556493165
Validation loss: 2.4237882246562608

Epoch: 6| Step: 12
Training loss: 2.5882309254441136
Validation loss: 2.405874371358721

Epoch: 6| Step: 13
Training loss: 2.7811442151472074
Validation loss: 2.421151214533811

Epoch: 123| Step: 0
Training loss: 2.9676224022730966
Validation loss: 2.4133409775270858

Epoch: 6| Step: 1
Training loss: 3.073917980095118
Validation loss: 2.427135363633777

Epoch: 6| Step: 2
Training loss: 2.6981972115268484
Validation loss: 2.407360362476805

Epoch: 6| Step: 3
Training loss: 2.853670527270177
Validation loss: 2.4139275485743186

Epoch: 6| Step: 4
Training loss: 2.8100406490385983
Validation loss: 2.3912148361597154

Epoch: 6| Step: 5
Training loss: 2.1175417445368008
Validation loss: 2.4134096071890627

Epoch: 6| Step: 6
Training loss: 1.8871258598528327
Validation loss: 2.386286706416456

Epoch: 6| Step: 7
Training loss: 2.7620241678825486
Validation loss: 2.4047104915814628

Epoch: 6| Step: 8
Training loss: 2.56412938116184
Validation loss: 2.385242084097659

Epoch: 6| Step: 9
Training loss: 1.9195027791366073
Validation loss: 2.414930660691236

Epoch: 6| Step: 10
Training loss: 2.0311519892595187
Validation loss: 2.409488977774907

Epoch: 6| Step: 11
Training loss: 2.3941355342502777
Validation loss: 2.3800919431325323

Epoch: 6| Step: 12
Training loss: 2.7711405093837813
Validation loss: 2.4100681818754652

Epoch: 6| Step: 13
Training loss: 3.1796123673843844
Validation loss: 2.4183626892564414

Epoch: 124| Step: 0
Training loss: 2.43820141212711
Validation loss: 2.405939341279829

Epoch: 6| Step: 1
Training loss: 2.4150615711142747
Validation loss: 2.402472676438311

Epoch: 6| Step: 2
Training loss: 2.6598333087118555
Validation loss: 2.400304709552645

Epoch: 6| Step: 3
Training loss: 2.354316492854997
Validation loss: 2.4040362772318535

Epoch: 6| Step: 4
Training loss: 2.352047284111605
Validation loss: 2.4235167571130662

Epoch: 6| Step: 5
Training loss: 2.4400791314848203
Validation loss: 2.419503153079838

Epoch: 6| Step: 6
Training loss: 2.289874248633414
Validation loss: 2.434635139492264

Epoch: 6| Step: 7
Training loss: 3.201880385338303
Validation loss: 2.4188886147773667

Epoch: 6| Step: 8
Training loss: 2.1190418413755987
Validation loss: 2.422464832007587

Epoch: 6| Step: 9
Training loss: 2.932851644182615
Validation loss: 2.4257198811657372

Epoch: 6| Step: 10
Training loss: 2.411239405362044
Validation loss: 2.4261071737840854

Epoch: 6| Step: 11
Training loss: 2.8291688120351157
Validation loss: 2.3954508564859545

Epoch: 6| Step: 12
Training loss: 2.5590168610375477
Validation loss: 2.404570034764484

Epoch: 6| Step: 13
Training loss: 3.4772904566167226
Validation loss: 2.4266496679579928

Epoch: 125| Step: 0
Training loss: 2.266275141598111
Validation loss: 2.4035476427915254

Epoch: 6| Step: 1
Training loss: 2.3859466452632523
Validation loss: 2.4047624762905246

Epoch: 6| Step: 2
Training loss: 2.8412365547798526
Validation loss: 2.4212113682235255

Epoch: 6| Step: 3
Training loss: 2.8584770084969144
Validation loss: 2.422798635318155

Epoch: 6| Step: 4
Training loss: 2.739785732049852
Validation loss: 2.4184183042791108

Epoch: 6| Step: 5
Training loss: 2.9228603721049997
Validation loss: 2.4193240817654673

Epoch: 6| Step: 6
Training loss: 2.611459778667507
Validation loss: 2.4091839684248173

Epoch: 6| Step: 7
Training loss: 2.4112755944459368
Validation loss: 2.408503005692604

Epoch: 6| Step: 8
Training loss: 2.7848693785520577
Validation loss: 2.4178721143727806

Epoch: 6| Step: 9
Training loss: 2.3069986425692597
Validation loss: 2.3871671057029054

Epoch: 6| Step: 10
Training loss: 2.5321512383947375
Validation loss: 2.4114000209775477

Epoch: 6| Step: 11
Training loss: 2.1608361386615487
Validation loss: 2.4068917866357378

Epoch: 6| Step: 12
Training loss: 2.5469037387841276
Validation loss: 2.3948045623558696

Epoch: 6| Step: 13
Training loss: 2.6896068387785954
Validation loss: 2.397506968924706

Testing loss: 2.4343276156774856
