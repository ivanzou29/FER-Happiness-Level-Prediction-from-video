Epoch: 1| Step: 0
Training loss: 5.734767141628435
Validation loss: 5.498611517313685

Epoch: 5| Step: 1
Training loss: 5.832193136044369
Validation loss: 5.495298973762258

Epoch: 5| Step: 2
Training loss: 6.040496221709951
Validation loss: 5.489735882366971

Epoch: 5| Step: 3
Training loss: 6.421943014485478
Validation loss: 5.48986380009034

Epoch: 5| Step: 4
Training loss: 5.22261096418287
Validation loss: 5.485735924666367

Epoch: 5| Step: 5
Training loss: 4.82849475222513
Validation loss: 5.483975118484108

Epoch: 5| Step: 6
Training loss: 4.413762175209109
Validation loss: 5.479779110711122

Epoch: 5| Step: 7
Training loss: 5.673065985279903
Validation loss: 5.477711072189714

Epoch: 5| Step: 8
Training loss: 6.0060972386839815
Validation loss: 5.474078838708399

Epoch: 5| Step: 9
Training loss: 4.878083256622925
Validation loss: 5.46817709457723

Epoch: 5| Step: 10
Training loss: 5.498398807841538
Validation loss: 5.4704533750042215

Epoch: 2| Step: 0
Training loss: 5.1469305724506285
Validation loss: 5.46445495235233

Epoch: 5| Step: 1
Training loss: 5.091048196960466
Validation loss: 5.464485878531419

Epoch: 5| Step: 2
Training loss: 6.568235960500544
Validation loss: 5.4602149695354765

Epoch: 5| Step: 3
Training loss: 4.934834014049087
Validation loss: 5.459005485254785

Epoch: 5| Step: 4
Training loss: 5.600570867596334
Validation loss: 5.453977644701476

Epoch: 5| Step: 5
Training loss: 5.400863875059603
Validation loss: 5.4498595412399204

Epoch: 5| Step: 6
Training loss: 4.918116705913291
Validation loss: 5.446341493117997

Epoch: 5| Step: 7
Training loss: 5.84468242529805
Validation loss: 5.446109065354001

Epoch: 5| Step: 8
Training loss: 5.7650907108683915
Validation loss: 5.440603315254777

Epoch: 5| Step: 9
Training loss: 5.835460638252623
Validation loss: 5.439673317939261

Epoch: 5| Step: 10
Training loss: 5.144270418893256
Validation loss: 5.435729601733299

Epoch: 3| Step: 0
Training loss: 5.12238282158548
Validation loss: 5.4322687372984495

Epoch: 5| Step: 1
Training loss: 5.968395282530737
Validation loss: 5.430345206397956

Epoch: 5| Step: 2
Training loss: 5.297479915679837
Validation loss: 5.429022026343617

Epoch: 5| Step: 3
Training loss: 6.5483227861060085
Validation loss: 5.425190815887857

Epoch: 5| Step: 4
Training loss: 6.300904757004024
Validation loss: 5.41976612036142

Epoch: 5| Step: 5
Training loss: 5.802319214259084
Validation loss: 5.4184108163149585

Epoch: 5| Step: 6
Training loss: 4.976476072701732
Validation loss: 5.417178980577277

Epoch: 5| Step: 7
Training loss: 4.568621565530812
Validation loss: 5.412022968293066

Epoch: 5| Step: 8
Training loss: 5.20554879585152
Validation loss: 5.41123767702041

Epoch: 5| Step: 9
Training loss: 5.128443607751832
Validation loss: 5.405978041686833

Epoch: 5| Step: 10
Training loss: 4.823657292732805
Validation loss: 5.4029646130634195

Epoch: 4| Step: 0
Training loss: 6.304759501408873
Validation loss: 5.401901667285628

Epoch: 5| Step: 1
Training loss: 6.167626417926391
Validation loss: 5.397874926815181

Epoch: 5| Step: 2
Training loss: 4.709571045539434
Validation loss: 5.3964350752026995

Epoch: 5| Step: 3
Training loss: 5.310960793507226
Validation loss: 5.393569115210162

Epoch: 5| Step: 4
Training loss: 6.345135917921265
Validation loss: 5.38862215357468

Epoch: 5| Step: 5
Training loss: 4.9823068375954325
Validation loss: 5.389474395421314

Epoch: 5| Step: 6
Training loss: 4.534270654341367
Validation loss: 5.383853849904342

Epoch: 5| Step: 7
Training loss: 5.701796118188432
Validation loss: 5.37958806987059

Epoch: 5| Step: 8
Training loss: 5.055292155259122
Validation loss: 5.377655441737733

Epoch: 5| Step: 9
Training loss: 5.7747779704426865
Validation loss: 5.374078284769973

Epoch: 5| Step: 10
Training loss: 4.339738928681794
Validation loss: 5.373262829138004

Epoch: 5| Step: 0
Training loss: 5.3214877226807165
Validation loss: 5.365718125689226

Epoch: 5| Step: 1
Training loss: 5.872260895818957
Validation loss: 5.365946366593565

Epoch: 5| Step: 2
Training loss: 5.201738602420833
Validation loss: 5.363522769578899

Epoch: 5| Step: 3
Training loss: 4.194209403104457
Validation loss: 5.359042274500397

Epoch: 5| Step: 4
Training loss: 5.532536416328233
Validation loss: 5.356987922799268

Epoch: 5| Step: 5
Training loss: 4.339415438965105
Validation loss: 5.35517296141372

Epoch: 5| Step: 6
Training loss: 5.8077461737662475
Validation loss: 5.350066554495367

Epoch: 5| Step: 7
Training loss: 5.571243443749473
Validation loss: 5.348932889975754

Epoch: 5| Step: 8
Training loss: 5.089676240168556
Validation loss: 5.345396536484814

Epoch: 5| Step: 9
Training loss: 6.123510997162743
Validation loss: 5.340874909379448

Epoch: 5| Step: 10
Training loss: 6.158818207864988
Validation loss: 5.341008949738655

Epoch: 6| Step: 0
Training loss: 5.333285430852025
Validation loss: 5.3379548389320375

Epoch: 5| Step: 1
Training loss: 5.399963251624634
Validation loss: 5.332827106928611

Epoch: 5| Step: 2
Training loss: 5.54933374203325
Validation loss: 5.330142484996527

Epoch: 5| Step: 3
Training loss: 5.0888609094604815
Validation loss: 5.326091923738528

Epoch: 5| Step: 4
Training loss: 6.05916983781897
Validation loss: 5.323115764726751

Epoch: 5| Step: 5
Training loss: 6.064770774692193
Validation loss: 5.320614314445328

Epoch: 5| Step: 6
Training loss: 5.183309678067673
Validation loss: 5.31603911500316

Epoch: 5| Step: 7
Training loss: 5.473923856975705
Validation loss: 5.315509200123846

Epoch: 5| Step: 8
Training loss: 4.514859989399112
Validation loss: 5.309835517856692

Epoch: 5| Step: 9
Training loss: 5.189402771326087
Validation loss: 5.307846758911572

Epoch: 5| Step: 10
Training loss: 5.041091108440575
Validation loss: 5.305549639117077

Epoch: 7| Step: 0
Training loss: 4.917547933619291
Validation loss: 5.299462005651143

Epoch: 5| Step: 1
Training loss: 5.899660986519427
Validation loss: 5.29518447824971

Epoch: 5| Step: 2
Training loss: 4.703597441101805
Validation loss: 5.292714453262407

Epoch: 5| Step: 3
Training loss: 6.415604771853005
Validation loss: 5.29026734396808

Epoch: 5| Step: 4
Training loss: 5.960618796771833
Validation loss: 5.28595085171335

Epoch: 5| Step: 5
Training loss: 5.1701640730598095
Validation loss: 5.2834534368466075

Epoch: 5| Step: 6
Training loss: 4.712533455889303
Validation loss: 5.27942353613748

Epoch: 5| Step: 7
Training loss: 5.330001008568645
Validation loss: 5.275825440259733

Epoch: 5| Step: 8
Training loss: 5.274652637778032
Validation loss: 5.273068487639757

Epoch: 5| Step: 9
Training loss: 4.368287741199862
Validation loss: 5.268379447930274

Epoch: 5| Step: 10
Training loss: 5.638039796957378
Validation loss: 5.264474501541738

Epoch: 8| Step: 0
Training loss: 4.986704888698815
Validation loss: 5.262106695383089

Epoch: 5| Step: 1
Training loss: 5.30526366215897
Validation loss: 5.256170013627997

Epoch: 5| Step: 2
Training loss: 5.0473674144213145
Validation loss: 5.252131504528894

Epoch: 5| Step: 3
Training loss: 5.521933948523864
Validation loss: 5.248765785710442

Epoch: 5| Step: 4
Training loss: 5.322781655029552
Validation loss: 5.24287131753497

Epoch: 5| Step: 5
Training loss: 5.342935600462397
Validation loss: 5.241271079768738

Epoch: 5| Step: 6
Training loss: 5.660422456429724
Validation loss: 5.238330722731306

Epoch: 5| Step: 7
Training loss: 4.4308533656454445
Validation loss: 5.232552455636051

Epoch: 5| Step: 8
Training loss: 5.882356623480149
Validation loss: 5.229706656632381

Epoch: 5| Step: 9
Training loss: 5.421114733598062
Validation loss: 5.225852059277088

Epoch: 5| Step: 10
Training loss: 5.1770415992001295
Validation loss: 5.219826058611773

Epoch: 9| Step: 0
Training loss: 5.329831026415528
Validation loss: 5.218080541183272

Epoch: 5| Step: 1
Training loss: 4.7665576459959595
Validation loss: 5.211533552223275

Epoch: 5| Step: 2
Training loss: 5.011892290448258
Validation loss: 5.2089361905909906

Epoch: 5| Step: 3
Training loss: 4.62268214525555
Validation loss: 5.20046623165536

Epoch: 5| Step: 4
Training loss: 5.666803620123338
Validation loss: 5.19858231588514

Epoch: 5| Step: 5
Training loss: 3.9783927737460543
Validation loss: 5.192657676164409

Epoch: 5| Step: 6
Training loss: 6.0251269315273035
Validation loss: 5.187995880024875

Epoch: 5| Step: 7
Training loss: 5.487947957517803
Validation loss: 5.184999043205914

Epoch: 5| Step: 8
Training loss: 4.404435237225215
Validation loss: 5.182342248394499

Epoch: 5| Step: 9
Training loss: 5.742083531690575
Validation loss: 5.169003307904132

Epoch: 5| Step: 10
Training loss: 6.362849005999163
Validation loss: 5.168702471067026

Epoch: 10| Step: 0
Training loss: 6.3754445837240805
Validation loss: 5.164579439606215

Epoch: 5| Step: 1
Training loss: 3.98314800443161
Validation loss: 5.155168048781963

Epoch: 5| Step: 2
Training loss: 5.108391810088179
Validation loss: 5.156076079686121

Epoch: 5| Step: 3
Training loss: 4.817196622599211
Validation loss: 5.150074296975486

Epoch: 5| Step: 4
Training loss: 4.9926184526430495
Validation loss: 5.142026604756366

Epoch: 5| Step: 5
Training loss: 5.930717690380992
Validation loss: 5.135108473077863

Epoch: 5| Step: 6
Training loss: 5.200934238140576
Validation loss: 5.1325673665861355

Epoch: 5| Step: 7
Training loss: 5.110218969979915
Validation loss: 5.122941941266072

Epoch: 5| Step: 8
Training loss: 4.775828959624382
Validation loss: 5.119663284193142

Epoch: 5| Step: 9
Training loss: 5.3801759150791035
Validation loss: 5.112173268947455

Epoch: 5| Step: 10
Training loss: 5.099248434301526
Validation loss: 5.1092074240272565

Epoch: 11| Step: 0
Training loss: 5.810763848364933
Validation loss: 5.098412097514149

Epoch: 5| Step: 1
Training loss: 4.757054360907278
Validation loss: 5.095944613604702

Epoch: 5| Step: 2
Training loss: 4.258570836281457
Validation loss: 5.089478699540513

Epoch: 5| Step: 3
Training loss: 5.028509495403318
Validation loss: 5.084240463119301

Epoch: 5| Step: 4
Training loss: 5.166663918443175
Validation loss: 5.075634267878736

Epoch: 5| Step: 5
Training loss: 5.842966282152006
Validation loss: 5.07133042705259

Epoch: 5| Step: 6
Training loss: 5.310095388701542
Validation loss: 5.062486930859669

Epoch: 5| Step: 7
Training loss: 5.341718856548632
Validation loss: 5.054274761700069

Epoch: 5| Step: 8
Training loss: 5.322482077020559
Validation loss: 5.047289227198336

Epoch: 5| Step: 9
Training loss: 5.868405801025336
Validation loss: 5.041265759367306

Epoch: 5| Step: 10
Training loss: 2.4882933228587616
Validation loss: 5.0349247533307055

Epoch: 12| Step: 0
Training loss: 5.529753574171679
Validation loss: 5.026746869259455

Epoch: 5| Step: 1
Training loss: 5.689767238904431
Validation loss: 5.0220636919634165

Epoch: 5| Step: 2
Training loss: 6.034737799004557
Validation loss: 5.012617810885867

Epoch: 5| Step: 3
Training loss: 4.780208499143953
Validation loss: 5.009825916507578

Epoch: 5| Step: 4
Training loss: 4.827648744272028
Validation loss: 4.997731955709972

Epoch: 5| Step: 5
Training loss: 5.3506300510649565
Validation loss: 4.994014368941305

Epoch: 5| Step: 6
Training loss: 4.782731767812386
Validation loss: 4.980076116454701

Epoch: 5| Step: 7
Training loss: 4.6809569405879685
Validation loss: 4.979005564968709

Epoch: 5| Step: 8
Training loss: 4.6124726829650315
Validation loss: 4.9709127472082395

Epoch: 5| Step: 9
Training loss: 4.252869478800276
Validation loss: 4.959965102413359

Epoch: 5| Step: 10
Training loss: 4.765626600921863
Validation loss: 4.952510707788344

Epoch: 13| Step: 0
Training loss: 4.424999844825871
Validation loss: 4.941403319772071

Epoch: 5| Step: 1
Training loss: 5.511631024782476
Validation loss: 4.935460188635454

Epoch: 5| Step: 2
Training loss: 5.088715294251317
Validation loss: 4.927328879630743

Epoch: 5| Step: 3
Training loss: 5.495011234567003
Validation loss: 4.92408096561075

Epoch: 5| Step: 4
Training loss: 5.081907207784325
Validation loss: 4.9125247957514535

Epoch: 5| Step: 5
Training loss: 5.435998994458059
Validation loss: 4.902782821586833

Epoch: 5| Step: 6
Training loss: 5.54736790146059
Validation loss: 4.8956907601979855

Epoch: 5| Step: 7
Training loss: 4.547981887794737
Validation loss: 4.886097009387904

Epoch: 5| Step: 8
Training loss: 4.903552243039705
Validation loss: 4.87615326102384

Epoch: 5| Step: 9
Training loss: 4.056481466169417
Validation loss: 4.867233530818209

Epoch: 5| Step: 10
Training loss: 4.1262235271872365
Validation loss: 4.857016683948216

Epoch: 14| Step: 0
Training loss: 5.513934430186001
Validation loss: 4.848750019944238

Epoch: 5| Step: 1
Training loss: 5.2475205879116515
Validation loss: 4.843264522827732

Epoch: 5| Step: 2
Training loss: 4.7316729700454765
Validation loss: 4.82990176420345

Epoch: 5| Step: 3
Training loss: 4.0117351527932685
Validation loss: 4.817304386763359

Epoch: 5| Step: 4
Training loss: 4.321836895888493
Validation loss: 4.811603477018748

Epoch: 5| Step: 5
Training loss: 5.290670987068483
Validation loss: 4.803741398745099

Epoch: 5| Step: 6
Training loss: 5.569793034925472
Validation loss: 4.797023922528931

Epoch: 5| Step: 7
Training loss: 4.809585084844065
Validation loss: 4.780454013470741

Epoch: 5| Step: 8
Training loss: 4.396708228141618
Validation loss: 4.76934202129799

Epoch: 5| Step: 9
Training loss: 4.10398807556621
Validation loss: 4.760659403789825

Epoch: 5| Step: 10
Training loss: 5.375678263607602
Validation loss: 4.750453568949393

Epoch: 15| Step: 0
Training loss: 4.937574555039373
Validation loss: 4.737325503721571

Epoch: 5| Step: 1
Training loss: 5.044926033801034
Validation loss: 4.731751044480753

Epoch: 5| Step: 2
Training loss: 4.373730502547126
Validation loss: 4.716613137923299

Epoch: 5| Step: 3
Training loss: 4.291296316419711
Validation loss: 4.714815116659648

Epoch: 5| Step: 4
Training loss: 4.970347213743814
Validation loss: 4.699164788630687

Epoch: 5| Step: 5
Training loss: 4.606724691582209
Validation loss: 4.683092055493551

Epoch: 5| Step: 6
Training loss: 4.8491041555580345
Validation loss: 4.670426257710137

Epoch: 5| Step: 7
Training loss: 5.228442665021394
Validation loss: 4.666603355300537

Epoch: 5| Step: 8
Training loss: 4.631795890646242
Validation loss: 4.654792744254362

Epoch: 5| Step: 9
Training loss: 4.7203594772390325
Validation loss: 4.633689929120412

Epoch: 5| Step: 10
Training loss: 4.581345606869239
Validation loss: 4.623836234559802

Epoch: 16| Step: 0
Training loss: 3.7846969152570784
Validation loss: 4.617633830280586

Epoch: 5| Step: 1
Training loss: 4.908582388102599
Validation loss: 4.598542117597794

Epoch: 5| Step: 2
Training loss: 4.992812330994846
Validation loss: 4.589173061055701

Epoch: 5| Step: 3
Training loss: 4.44482633751357
Validation loss: 4.57586015845466

Epoch: 5| Step: 4
Training loss: 5.300965476717573
Validation loss: 4.571195523458709

Epoch: 5| Step: 5
Training loss: 5.244827265336094
Validation loss: 4.552233236518871

Epoch: 5| Step: 6
Training loss: 4.164479762601235
Validation loss: 4.533581083671058

Epoch: 5| Step: 7
Training loss: 5.020993031010505
Validation loss: 4.522392408248153

Epoch: 5| Step: 8
Training loss: 4.227101741103314
Validation loss: 4.509744480353348

Epoch: 5| Step: 9
Training loss: 4.187498178054641
Validation loss: 4.495359963644781

Epoch: 5| Step: 10
Training loss: 4.331682966866279
Validation loss: 4.4780689074291695

Epoch: 17| Step: 0
Training loss: 4.534551010028316
Validation loss: 4.475109744609621

Epoch: 5| Step: 1
Training loss: 4.28958721460232
Validation loss: 4.453676469899558

Epoch: 5| Step: 2
Training loss: 3.5117641017476164
Validation loss: 4.442676395726121

Epoch: 5| Step: 3
Training loss: 5.116958449966789
Validation loss: 4.425128679656449

Epoch: 5| Step: 4
Training loss: 4.53321553713025
Validation loss: 4.41128887966785

Epoch: 5| Step: 5
Training loss: 4.1525708887341
Validation loss: 4.4066475041867825

Epoch: 5| Step: 6
Training loss: 4.952956332153824
Validation loss: 4.385330326005049

Epoch: 5| Step: 7
Training loss: 4.155813552771634
Validation loss: 4.372315614874194

Epoch: 5| Step: 8
Training loss: 4.972754058715029
Validation loss: 4.349562800710188

Epoch: 5| Step: 9
Training loss: 3.6528565398710784
Validation loss: 4.335217366073015

Epoch: 5| Step: 10
Training loss: 5.20179543676904
Validation loss: 4.316965331815882

Epoch: 18| Step: 0
Training loss: 4.7770037775725465
Validation loss: 4.305470682887288

Epoch: 5| Step: 1
Training loss: 4.253423994487251
Validation loss: 4.294507731496185

Epoch: 5| Step: 2
Training loss: 4.358456531969139
Validation loss: 4.275432742609146

Epoch: 5| Step: 3
Training loss: 4.260654781685695
Validation loss: 4.258267658129272

Epoch: 5| Step: 4
Training loss: 4.571317748020711
Validation loss: 4.2288744684220285

Epoch: 5| Step: 5
Training loss: 4.318892454235229
Validation loss: 4.220642154091102

Epoch: 5| Step: 6
Training loss: 3.879248105569298
Validation loss: 4.193982300542168

Epoch: 5| Step: 7
Training loss: 4.522638385399378
Validation loss: 4.176910679551711

Epoch: 5| Step: 8
Training loss: 3.758684402162357
Validation loss: 4.157557382173624

Epoch: 5| Step: 9
Training loss: 4.741620553076801
Validation loss: 4.152750379233956

Epoch: 5| Step: 10
Training loss: 3.8121752991533073
Validation loss: 4.130825785125038

Epoch: 19| Step: 0
Training loss: 4.210625631641795
Validation loss: 4.117103557280058

Epoch: 5| Step: 1
Training loss: 4.141522695289222
Validation loss: 4.099690242884438

Epoch: 5| Step: 2
Training loss: 3.5380796031805706
Validation loss: 4.071153963281733

Epoch: 5| Step: 3
Training loss: 5.136724691061203
Validation loss: 4.051864051637591

Epoch: 5| Step: 4
Training loss: 3.7986946925875307
Validation loss: 4.032142308286142

Epoch: 5| Step: 5
Training loss: 3.4160616889582887
Validation loss: 4.019665158125445

Epoch: 5| Step: 6
Training loss: 5.238409781817029
Validation loss: 4.006601689911851

Epoch: 5| Step: 7
Training loss: 3.6184812666706034
Validation loss: 3.9794655801253613

Epoch: 5| Step: 8
Training loss: 5.026683749229755
Validation loss: 3.971260393697512

Epoch: 5| Step: 9
Training loss: 3.1800547394749556
Validation loss: 3.9510518330544673

Epoch: 5| Step: 10
Training loss: 3.31725258244526
Validation loss: 3.921227772082117

Epoch: 20| Step: 0
Training loss: 3.8515127306463697
Validation loss: 3.880569793763684

Epoch: 5| Step: 1
Training loss: 4.654393997491695
Validation loss: 3.881423992108997

Epoch: 5| Step: 2
Training loss: 4.406818109777295
Validation loss: 3.8630272997817836

Epoch: 5| Step: 3
Training loss: 4.163084219409392
Validation loss: 3.8395030171837385

Epoch: 5| Step: 4
Training loss: 3.6893775168850866
Validation loss: 3.812528987016496

Epoch: 5| Step: 5
Training loss: 3.232370833717109
Validation loss: 3.8031703220584725

Epoch: 5| Step: 6
Training loss: 4.074679852412727
Validation loss: 3.7654663741497605

Epoch: 5| Step: 7
Training loss: 3.8346026986436694
Validation loss: 3.7467028530615347

Epoch: 5| Step: 8
Training loss: 4.006212655070432
Validation loss: 3.725398810274224

Epoch: 5| Step: 9
Training loss: 3.5978876592412536
Validation loss: 3.7140431227417046

Epoch: 5| Step: 10
Training loss: 3.3562847739465855
Validation loss: 3.6935722698509412

Epoch: 21| Step: 0
Training loss: 3.2707232964992903
Validation loss: 3.659228927109492

Epoch: 5| Step: 1
Training loss: 3.8441433588977043
Validation loss: 3.6391047300178165

Epoch: 5| Step: 2
Training loss: 4.231668543435204
Validation loss: 3.6259948163155404

Epoch: 5| Step: 3
Training loss: 4.300993010723907
Validation loss: 3.5801653617216673

Epoch: 5| Step: 4
Training loss: 3.5783791264406832
Validation loss: 3.573754580114104

Epoch: 5| Step: 5
Training loss: 3.2374559554119684
Validation loss: 3.5617762954751426

Epoch: 5| Step: 6
Training loss: 2.7566546638285887
Validation loss: 3.5227863326784585

Epoch: 5| Step: 7
Training loss: 3.759933539269885
Validation loss: 3.519643335022534

Epoch: 5| Step: 8
Training loss: 3.9075652082765804
Validation loss: 3.492504740374657

Epoch: 5| Step: 9
Training loss: 3.698656694035286
Validation loss: 3.4616810819222317

Epoch: 5| Step: 10
Training loss: 3.82116415130146
Validation loss: 3.450894053592929

Epoch: 22| Step: 0
Training loss: 3.6775313294487577
Validation loss: 3.4207839668685485

Epoch: 5| Step: 1
Training loss: 3.9963774967229355
Validation loss: 3.390527170251032

Epoch: 5| Step: 2
Training loss: 4.035046586118733
Validation loss: 3.3691580241120977

Epoch: 5| Step: 3
Training loss: 3.2702102229587244
Validation loss: 3.361658828038603

Epoch: 5| Step: 4
Training loss: 3.561712211373618
Validation loss: 3.3201204070394503

Epoch: 5| Step: 5
Training loss: 3.289934273848813
Validation loss: 3.286540294445761

Epoch: 5| Step: 6
Training loss: 3.6505113217405927
Validation loss: 3.264850123956988

Epoch: 5| Step: 7
Training loss: 3.573980738318422
Validation loss: 3.242188271736046

Epoch: 5| Step: 8
Training loss: 2.4551276518348693
Validation loss: 3.229842676436786

Epoch: 5| Step: 9
Training loss: 3.572207158915347
Validation loss: 3.204986314792815

Epoch: 5| Step: 10
Training loss: 2.880694844348301
Validation loss: 3.195267993785433

Epoch: 23| Step: 0
Training loss: 3.1049392728656695
Validation loss: 3.1606284869837755

Epoch: 5| Step: 1
Training loss: 3.7279867653427634
Validation loss: 3.137476147028785

Epoch: 5| Step: 2
Training loss: 3.481568168195194
Validation loss: 3.122075398604915

Epoch: 5| Step: 3
Training loss: 3.143758851905328
Validation loss: 3.0902870654324945

Epoch: 5| Step: 4
Training loss: 3.8433229782966367
Validation loss: 3.0788448581587224

Epoch: 5| Step: 5
Training loss: 3.167802874529898
Validation loss: 3.061595338625833

Epoch: 5| Step: 6
Training loss: 2.9974368590003437
Validation loss: 3.0262028673437276

Epoch: 5| Step: 7
Training loss: 3.3887729069052703
Validation loss: 3.022471765556477

Epoch: 5| Step: 8
Training loss: 3.320432701179032
Validation loss: 2.984886735034987

Epoch: 5| Step: 9
Training loss: 2.473221797056237
Validation loss: 2.9824235288381966

Epoch: 5| Step: 10
Training loss: 3.2719643129766967
Validation loss: 2.9537308624805636

Epoch: 24| Step: 0
Training loss: 3.2286937408330827
Validation loss: 2.9328847868236045

Epoch: 5| Step: 1
Training loss: 2.5959883993092387
Validation loss: 2.899042674259868

Epoch: 5| Step: 2
Training loss: 3.2114242593147715
Validation loss: 2.917589133743773

Epoch: 5| Step: 3
Training loss: 2.871600089545859
Validation loss: 2.895696659069047

Epoch: 5| Step: 4
Training loss: 3.412150460810882
Validation loss: 2.8731536536430493

Epoch: 5| Step: 5
Training loss: 3.144999631508713
Validation loss: 2.8766640568458075

Epoch: 5| Step: 6
Training loss: 2.5752060520727897
Validation loss: 2.8718502541142

Epoch: 5| Step: 7
Training loss: 3.462140634114354
Validation loss: 2.842552619017245

Epoch: 5| Step: 8
Training loss: 3.1638065941073252
Validation loss: 2.8190417869467117

Epoch: 5| Step: 9
Training loss: 3.0304507745503235
Validation loss: 2.8106249375464527

Epoch: 5| Step: 10
Training loss: 3.496107116332689
Validation loss: 2.7693803746337853

Epoch: 25| Step: 0
Training loss: 3.2596082243679514
Validation loss: 2.7818111228334184

Epoch: 5| Step: 1
Training loss: 2.8421156661826656
Validation loss: 2.764904468082248

Epoch: 5| Step: 2
Training loss: 2.1957098441775305
Validation loss: 2.7895373677258197

Epoch: 5| Step: 3
Training loss: 2.631489588324585
Validation loss: 2.7370591394558237

Epoch: 5| Step: 4
Training loss: 2.8365471134775
Validation loss: 2.727871995820335

Epoch: 5| Step: 5
Training loss: 3.087763224512504
Validation loss: 2.7236013950158706

Epoch: 5| Step: 6
Training loss: 2.441452733932477
Validation loss: 2.692781222967432

Epoch: 5| Step: 7
Training loss: 3.1948577631898045
Validation loss: 2.6826873751838174

Epoch: 5| Step: 8
Training loss: 3.5503877562323374
Validation loss: 2.670939147930512

Epoch: 5| Step: 9
Training loss: 3.271414994600124
Validation loss: 2.7082324051016338

Epoch: 5| Step: 10
Training loss: 3.555524455040441
Validation loss: 2.6857627620490008

Epoch: 26| Step: 0
Training loss: 3.274245861089589
Validation loss: 2.685179440895279

Epoch: 5| Step: 1
Training loss: 2.3065400517540247
Validation loss: 2.651179122109281

Epoch: 5| Step: 2
Training loss: 1.9889093092835604
Validation loss: 2.6608073603950673

Epoch: 5| Step: 3
Training loss: 3.036977332087415
Validation loss: 2.656271835131238

Epoch: 5| Step: 4
Training loss: 2.952815771312034
Validation loss: 2.668533667282126

Epoch: 5| Step: 5
Training loss: 3.4558902215211593
Validation loss: 2.605463625604031

Epoch: 5| Step: 6
Training loss: 3.198740121066665
Validation loss: 2.614643929823594

Epoch: 5| Step: 7
Training loss: 3.4967130485442843
Validation loss: 2.641055865207005

Epoch: 5| Step: 8
Training loss: 2.9666962597117514
Validation loss: 2.62371955108863

Epoch: 5| Step: 9
Training loss: 2.845292563790158
Validation loss: 2.6199834600053493

Epoch: 5| Step: 10
Training loss: 2.683127017017089
Validation loss: 2.599806905964227

Epoch: 27| Step: 0
Training loss: 3.0427111221574075
Validation loss: 2.6208822726440846

Epoch: 5| Step: 1
Training loss: 3.134257680079792
Validation loss: 2.5683971042763525

Epoch: 5| Step: 2
Training loss: 2.585951698471689
Validation loss: 2.600106158822517

Epoch: 5| Step: 3
Training loss: 2.9871342071941713
Validation loss: 2.5840575244795794

Epoch: 5| Step: 4
Training loss: 2.705619851413903
Validation loss: 2.574369295398114

Epoch: 5| Step: 5
Training loss: 2.54440637316626
Validation loss: 2.6162754243150843

Epoch: 5| Step: 6
Training loss: 3.151038673756757
Validation loss: 2.5700385822362146

Epoch: 5| Step: 7
Training loss: 3.0571371339456643
Validation loss: 2.5694515161288556

Epoch: 5| Step: 8
Training loss: 2.351200519469036
Validation loss: 2.585749144770826

Epoch: 5| Step: 9
Training loss: 3.6303342836587924
Validation loss: 2.5613609701773115

Epoch: 5| Step: 10
Training loss: 2.9384311255418636
Validation loss: 2.5476217991261643

Epoch: 28| Step: 0
Training loss: 3.091507223975638
Validation loss: 2.5996147318361915

Epoch: 5| Step: 1
Training loss: 2.5711002707942034
Validation loss: 2.602762266088547

Epoch: 5| Step: 2
Training loss: 3.0861066940860478
Validation loss: 2.5592139719685787

Epoch: 5| Step: 3
Training loss: 2.804213459896038
Validation loss: 2.5477350225995883

Epoch: 5| Step: 4
Training loss: 2.659764287586635
Validation loss: 2.5614109921703347

Epoch: 5| Step: 5
Training loss: 3.213804130202195
Validation loss: 2.5873015356318327

Epoch: 5| Step: 6
Training loss: 3.0819359439478387
Validation loss: 2.5835730540355706

Epoch: 5| Step: 7
Training loss: 2.9244807247022973
Validation loss: 2.5593609365212373

Epoch: 5| Step: 8
Training loss: 2.931407372778588
Validation loss: 2.5540286624490607

Epoch: 5| Step: 9
Training loss: 3.107601867872019
Validation loss: 2.556046547039022

Epoch: 5| Step: 10
Training loss: 2.555330248128792
Validation loss: 2.5541902532159106

Epoch: 29| Step: 0
Training loss: 2.3914544156447834
Validation loss: 2.5810820733298905

Epoch: 5| Step: 1
Training loss: 2.941410951243338
Validation loss: 2.5677913176533527

Epoch: 5| Step: 2
Training loss: 2.053840723802603
Validation loss: 2.53922040096538

Epoch: 5| Step: 3
Training loss: 3.581323385235719
Validation loss: 2.5574088936375468

Epoch: 5| Step: 4
Training loss: 2.9313891542504598
Validation loss: 2.5336921302073883

Epoch: 5| Step: 5
Training loss: 2.8215518669243242
Validation loss: 2.550607611135947

Epoch: 5| Step: 6
Training loss: 3.4010173958364613
Validation loss: 2.589168007741044

Epoch: 5| Step: 7
Training loss: 2.9277785121652196
Validation loss: 2.5787999318441357

Epoch: 5| Step: 8
Training loss: 2.6743086055065843
Validation loss: 2.5838553208592803

Epoch: 5| Step: 9
Training loss: 2.7412267670210033
Validation loss: 2.5677488270958917

Epoch: 5| Step: 10
Training loss: 3.480968914635085
Validation loss: 2.5488124916239365

Epoch: 30| Step: 0
Training loss: 2.6954997564311087
Validation loss: 2.556576208301161

Epoch: 5| Step: 1
Training loss: 3.2066270989443986
Validation loss: 2.560236623820579

Epoch: 5| Step: 2
Training loss: 3.5800229831575834
Validation loss: 2.558469087553534

Epoch: 5| Step: 3
Training loss: 3.013599881927269
Validation loss: 2.5695639677738416

Epoch: 5| Step: 4
Training loss: 3.1438154270651966
Validation loss: 2.559749049051428

Epoch: 5| Step: 5
Training loss: 2.7507011213389845
Validation loss: 2.545750603119518

Epoch: 5| Step: 6
Training loss: 3.0758475771518805
Validation loss: 2.5587838912684644

Epoch: 5| Step: 7
Training loss: 2.748271312102489
Validation loss: 2.5798727376701986

Epoch: 5| Step: 8
Training loss: 2.198573178657381
Validation loss: 2.558270603474538

Epoch: 5| Step: 9
Training loss: 2.9785486038133273
Validation loss: 2.5437594639710754

Epoch: 5| Step: 10
Training loss: 2.969768148806572
Validation loss: 2.592333862078788

Epoch: 31| Step: 0
Training loss: 2.6306231986719637
Validation loss: 2.590259172287218

Epoch: 5| Step: 1
Training loss: 2.372467196270918
Validation loss: 2.575856297141341

Epoch: 5| Step: 2
Training loss: 2.828935538632558
Validation loss: 2.591107180084431

Epoch: 5| Step: 3
Training loss: 3.5090339420184855
Validation loss: 2.556238555621833

Epoch: 5| Step: 4
Training loss: 3.742467817984858
Validation loss: 2.5435798779819314

Epoch: 5| Step: 5
Training loss: 2.3168010407408595
Validation loss: 2.5562133928450703

Epoch: 5| Step: 6
Training loss: 3.077769612356189
Validation loss: 2.5604129008214036

Epoch: 5| Step: 7
Training loss: 2.721211776780362
Validation loss: 2.561308801256352

Epoch: 5| Step: 8
Training loss: 3.165683660688601
Validation loss: 2.5476010473754447

Epoch: 5| Step: 9
Training loss: 2.2444057855749406
Validation loss: 2.6048382594925603

Epoch: 5| Step: 10
Training loss: 3.3010422823467906
Validation loss: 2.5757665969902765

Epoch: 32| Step: 0
Training loss: 3.3966439962582027
Validation loss: 2.5504021594290007

Epoch: 5| Step: 1
Training loss: 2.743680281394177
Validation loss: 2.552180792174227

Epoch: 5| Step: 2
Training loss: 2.931334335317723
Validation loss: 2.5435463887060887

Epoch: 5| Step: 3
Training loss: 2.3860213888893167
Validation loss: 2.548724952803249

Epoch: 5| Step: 4
Training loss: 3.126234039790593
Validation loss: 2.575084405971823

Epoch: 5| Step: 5
Training loss: 2.6063431354960747
Validation loss: 2.5450977884195876

Epoch: 5| Step: 6
Training loss: 3.181780601874038
Validation loss: 2.5681846132168276

Epoch: 5| Step: 7
Training loss: 3.323871455446426
Validation loss: 2.5859048309260197

Epoch: 5| Step: 8
Training loss: 2.6519591736678882
Validation loss: 2.5542653348910163

Epoch: 5| Step: 9
Training loss: 2.6621767232860143
Validation loss: 2.5771840714971024

Epoch: 5| Step: 10
Training loss: 3.1074336907086013
Validation loss: 2.549955365278729

Epoch: 33| Step: 0
Training loss: 2.7525274626343244
Validation loss: 2.5338571769744447

Epoch: 5| Step: 1
Training loss: 2.903952890534193
Validation loss: 2.555896771996035

Epoch: 5| Step: 2
Training loss: 3.1446202615022205
Validation loss: 2.556451737284273

Epoch: 5| Step: 3
Training loss: 2.5908541772428677
Validation loss: 2.581452337540937

Epoch: 5| Step: 4
Training loss: 3.3121052632765786
Validation loss: 2.558938585665337

Epoch: 5| Step: 5
Training loss: 3.3246335623606114
Validation loss: 2.5799041038781354

Epoch: 5| Step: 6
Training loss: 2.928165294650876
Validation loss: 2.5334987963875104

Epoch: 5| Step: 7
Training loss: 2.882707464687552
Validation loss: 2.5776085747464648

Epoch: 5| Step: 8
Training loss: 2.24608090604344
Validation loss: 2.5581613623207247

Epoch: 5| Step: 9
Training loss: 2.8595766090233594
Validation loss: 2.5349516272888537

Epoch: 5| Step: 10
Training loss: 3.0668860965121434
Validation loss: 2.547721403063632

Epoch: 34| Step: 0
Training loss: 2.4692227840408734
Validation loss: 2.5658197266380487

Epoch: 5| Step: 1
Training loss: 3.6761561333308435
Validation loss: 2.5273969669105534

Epoch: 5| Step: 2
Training loss: 2.605196136441991
Validation loss: 2.5731902963218216

Epoch: 5| Step: 3
Training loss: 2.4310664835806346
Validation loss: 2.589569018327051

Epoch: 5| Step: 4
Training loss: 3.681013447491105
Validation loss: 2.538397903233028

Epoch: 5| Step: 5
Training loss: 3.0297388459016124
Validation loss: 2.5429658385216762

Epoch: 5| Step: 6
Training loss: 2.6225596392225854
Validation loss: 2.5548348523716062

Epoch: 5| Step: 7
Training loss: 2.6626576945568066
Validation loss: 2.5314514969191877

Epoch: 5| Step: 8
Training loss: 2.415940625099033
Validation loss: 2.5625075773601815

Epoch: 5| Step: 9
Training loss: 2.8448085282025204
Validation loss: 2.537125527108189

Epoch: 5| Step: 10
Training loss: 3.435071746432264
Validation loss: 2.5632111807797413

Epoch: 35| Step: 0
Training loss: 2.6882845598381704
Validation loss: 2.561579466159348

Epoch: 5| Step: 1
Training loss: 3.2223863523343903
Validation loss: 2.5739684346328016

Epoch: 5| Step: 2
Training loss: 3.561833771097024
Validation loss: 2.583489467561426

Epoch: 5| Step: 3
Training loss: 2.9471860234031664
Validation loss: 2.586997034911179

Epoch: 5| Step: 4
Training loss: 2.725062791293386
Validation loss: 2.5719859815671073

Epoch: 5| Step: 5
Training loss: 2.8282327368010547
Validation loss: 2.5627189160549717

Epoch: 5| Step: 6
Training loss: 2.445949678616113
Validation loss: 2.5409417459272436

Epoch: 5| Step: 7
Training loss: 2.8048335385355836
Validation loss: 2.560213693270757

Epoch: 5| Step: 8
Training loss: 2.7434911862178417
Validation loss: 2.568761357579059

Epoch: 5| Step: 9
Training loss: 2.8240461072480807
Validation loss: 2.5636897482798986

Epoch: 5| Step: 10
Training loss: 3.364886495594593
Validation loss: 2.579953499044497

Epoch: 36| Step: 0
Training loss: 1.961202413590697
Validation loss: 2.5668856310311354

Epoch: 5| Step: 1
Training loss: 3.171611154791789
Validation loss: 2.556813530286376

Epoch: 5| Step: 2
Training loss: 3.270619346924308
Validation loss: 2.5320203047834107

Epoch: 5| Step: 3
Training loss: 3.29676594486027
Validation loss: 2.537833373468388

Epoch: 5| Step: 4
Training loss: 2.576924732439843
Validation loss: 2.5500526748917483

Epoch: 5| Step: 5
Training loss: 3.6281132976333397
Validation loss: 2.5608746736252326

Epoch: 5| Step: 6
Training loss: 3.0000079472754435
Validation loss: 2.564772548865885

Epoch: 5| Step: 7
Training loss: 2.4951481468235843
Validation loss: 2.5915145798800068

Epoch: 5| Step: 8
Training loss: 2.619324406740754
Validation loss: 2.5643750365591274

Epoch: 5| Step: 9
Training loss: 2.849972467122181
Validation loss: 2.5378552748482677

Epoch: 5| Step: 10
Training loss: 2.7991550464924586
Validation loss: 2.5440417727469145

Epoch: 37| Step: 0
Training loss: 3.048871603930047
Validation loss: 2.547185904392689

Epoch: 5| Step: 1
Training loss: 2.7561917391823827
Validation loss: 2.567135438659619

Epoch: 5| Step: 2
Training loss: 2.503798269719759
Validation loss: 2.5570405317527145

Epoch: 5| Step: 3
Training loss: 2.9786865985764703
Validation loss: 2.546407921864366

Epoch: 5| Step: 4
Training loss: 2.3182731940200267
Validation loss: 2.543234273293402

Epoch: 5| Step: 5
Training loss: 3.4241615215778727
Validation loss: 2.564849770607464

Epoch: 5| Step: 6
Training loss: 2.740562370393724
Validation loss: 2.561082905834173

Epoch: 5| Step: 7
Training loss: 3.3459525296525765
Validation loss: 2.5701401846588903

Epoch: 5| Step: 8
Training loss: 2.739101140238805
Validation loss: 2.5712135716098525

Epoch: 5| Step: 9
Training loss: 2.8388673554674013
Validation loss: 2.546233922340055

Epoch: 5| Step: 10
Training loss: 3.157996572559084
Validation loss: 2.5739003081796112

Epoch: 38| Step: 0
Training loss: 2.8515767136311
Validation loss: 2.5480075544850376

Epoch: 5| Step: 1
Training loss: 3.281170508012183
Validation loss: 2.5468451395454133

Epoch: 5| Step: 2
Training loss: 3.1965708598185056
Validation loss: 2.5750872791447295

Epoch: 5| Step: 3
Training loss: 2.815902601437932
Validation loss: 2.5552121224871147

Epoch: 5| Step: 4
Training loss: 3.019225979828762
Validation loss: 2.590545145053367

Epoch: 5| Step: 5
Training loss: 3.456824207032755
Validation loss: 2.5661855595782535

Epoch: 5| Step: 6
Training loss: 2.934698676477077
Validation loss: 2.5644472788461443

Epoch: 5| Step: 7
Training loss: 2.05344599939032
Validation loss: 2.5743064924548564

Epoch: 5| Step: 8
Training loss: 2.5132076424588896
Validation loss: 2.5518700954880202

Epoch: 5| Step: 9
Training loss: 3.3142108457781374
Validation loss: 2.551438719602492

Epoch: 5| Step: 10
Training loss: 2.2793627731878123
Validation loss: 2.5655407725719033

Epoch: 39| Step: 0
Training loss: 2.456899472631252
Validation loss: 2.5303056951481517

Epoch: 5| Step: 1
Training loss: 3.4075067284140483
Validation loss: 2.5595568105272

Epoch: 5| Step: 2
Training loss: 2.5532212088678006
Validation loss: 2.549047670113397

Epoch: 5| Step: 3
Training loss: 2.6466864364455778
Validation loss: 2.541284848856712

Epoch: 5| Step: 4
Training loss: 2.6956424234783714
Validation loss: 2.5583718204946906

Epoch: 5| Step: 5
Training loss: 3.3787575044029974
Validation loss: 2.53670508914513

Epoch: 5| Step: 6
Training loss: 2.459300050478032
Validation loss: 2.563721632470806

Epoch: 5| Step: 7
Training loss: 3.403907740507047
Validation loss: 2.574662594185107

Epoch: 5| Step: 8
Training loss: 3.1390853827835383
Validation loss: 2.5890943273524254

Epoch: 5| Step: 9
Training loss: 2.3917799011256173
Validation loss: 2.539402396119793

Epoch: 5| Step: 10
Training loss: 3.168526672077652
Validation loss: 2.5479215616585282

Epoch: 40| Step: 0
Training loss: 2.4129950376191633
Validation loss: 2.5628922635188363

Epoch: 5| Step: 1
Training loss: 2.7808232355053537
Validation loss: 2.540738231903142

Epoch: 5| Step: 2
Training loss: 2.7217467881148094
Validation loss: 2.5686390300027186

Epoch: 5| Step: 3
Training loss: 3.088005666984537
Validation loss: 2.5433048218834906

Epoch: 5| Step: 4
Training loss: 2.643431396765946
Validation loss: 2.542399778970591

Epoch: 5| Step: 5
Training loss: 2.7653990400000774
Validation loss: 2.5438171224674324

Epoch: 5| Step: 6
Training loss: 2.741919175629733
Validation loss: 2.559050262061947

Epoch: 5| Step: 7
Training loss: 3.0160224929294617
Validation loss: 2.5549684658351715

Epoch: 5| Step: 8
Training loss: 3.233081798666733
Validation loss: 2.5434835685413826

Epoch: 5| Step: 9
Training loss: 3.398235446579684
Validation loss: 2.546017357753683

Epoch: 5| Step: 10
Training loss: 3.269381028601693
Validation loss: 2.5708943118167076

Epoch: 41| Step: 0
Training loss: 2.792342706688321
Validation loss: 2.5769551725267723

Epoch: 5| Step: 1
Training loss: 2.3239643374413514
Validation loss: 2.534616232031847

Epoch: 5| Step: 2
Training loss: 2.422440788876036
Validation loss: 2.5532232531756835

Epoch: 5| Step: 3
Training loss: 3.26161100472303
Validation loss: 2.549267580473165

Epoch: 5| Step: 4
Training loss: 2.8933135854981775
Validation loss: 2.5521774030219877

Epoch: 5| Step: 5
Training loss: 3.8258549401740773
Validation loss: 2.5723494316750046

Epoch: 5| Step: 6
Training loss: 2.304784947291022
Validation loss: 2.5316779117920056

Epoch: 5| Step: 7
Training loss: 2.633775393486267
Validation loss: 2.5601577218400364

Epoch: 5| Step: 8
Training loss: 2.9611639172790007
Validation loss: 2.5419046145014392

Epoch: 5| Step: 9
Training loss: 3.258090878675126
Validation loss: 2.570512799895504

Epoch: 5| Step: 10
Training loss: 2.9438037195183875
Validation loss: 2.5765409284790977

Epoch: 42| Step: 0
Training loss: 2.7805776747836717
Validation loss: 2.5585827924050224

Epoch: 5| Step: 1
Training loss: 3.2976909188276218
Validation loss: 2.5722073165071984

Epoch: 5| Step: 2
Training loss: 2.4174348552964258
Validation loss: 2.549262284777369

Epoch: 5| Step: 3
Training loss: 2.461387472038099
Validation loss: 2.5776239419724165

Epoch: 5| Step: 4
Training loss: 3.4547601341089536
Validation loss: 2.5477838566156916

Epoch: 5| Step: 5
Training loss: 3.0736742712917673
Validation loss: 2.542421158520134

Epoch: 5| Step: 6
Training loss: 2.9021242451482574
Validation loss: 2.568698732903284

Epoch: 5| Step: 7
Training loss: 3.1357037147768336
Validation loss: 2.601371754448686

Epoch: 5| Step: 8
Training loss: 3.2001054627205927
Validation loss: 2.5432737361103497

Epoch: 5| Step: 9
Training loss: 2.5291701826378037
Validation loss: 2.578357331319058

Epoch: 5| Step: 10
Training loss: 2.6125829473587694
Validation loss: 2.5680403224074486

Epoch: 43| Step: 0
Training loss: 3.08868023634966
Validation loss: 2.5793092038377283

Epoch: 5| Step: 1
Training loss: 3.2813530315390222
Validation loss: 2.5750249387363957

Epoch: 5| Step: 2
Training loss: 2.6388648673408683
Validation loss: 2.5819501584385005

Epoch: 5| Step: 3
Training loss: 2.568590323504315
Validation loss: 2.5664677429249148

Epoch: 5| Step: 4
Training loss: 2.6355978158404203
Validation loss: 2.549467525669072

Epoch: 5| Step: 5
Training loss: 3.1915818052904172
Validation loss: 2.5416756086294736

Epoch: 5| Step: 6
Training loss: 3.287667819189015
Validation loss: 2.572742084746016

Epoch: 5| Step: 7
Training loss: 3.130547444301937
Validation loss: 2.5598657936105655

Epoch: 5| Step: 8
Training loss: 2.974969552789886
Validation loss: 2.5418981063130106

Epoch: 5| Step: 9
Training loss: 2.3163500516870683
Validation loss: 2.527158488308752

Epoch: 5| Step: 10
Training loss: 2.3407834415770563
Validation loss: 2.564871998027595

Epoch: 44| Step: 0
Training loss: 3.2337269894047016
Validation loss: 2.5734222348497986

Epoch: 5| Step: 1
Training loss: 2.749875412633027
Validation loss: 2.592666799103782

Epoch: 5| Step: 2
Training loss: 2.4052758164574106
Validation loss: 2.5655761011434013

Epoch: 5| Step: 3
Training loss: 2.4595745853934337
Validation loss: 2.5115542041418153

Epoch: 5| Step: 4
Training loss: 2.3775150634737687
Validation loss: 2.5744976799031

Epoch: 5| Step: 5
Training loss: 3.412818804370851
Validation loss: 2.5468392610260024

Epoch: 5| Step: 6
Training loss: 3.0074597436711015
Validation loss: 2.5565201381798803

Epoch: 5| Step: 7
Training loss: 3.0749199151256015
Validation loss: 2.536254077301357

Epoch: 5| Step: 8
Training loss: 2.2459636086617936
Validation loss: 2.5476978542261595

Epoch: 5| Step: 9
Training loss: 3.4197683599450346
Validation loss: 2.5561821280758075

Epoch: 5| Step: 10
Training loss: 3.2392952025276505
Validation loss: 2.537636134344501

Epoch: 45| Step: 0
Training loss: 3.330466436304322
Validation loss: 2.552283921101091

Epoch: 5| Step: 1
Training loss: 2.8783069333572304
Validation loss: 2.53913775942246

Epoch: 5| Step: 2
Training loss: 2.805260219913337
Validation loss: 2.574965969919738

Epoch: 5| Step: 3
Training loss: 2.758873754231003
Validation loss: 2.5578073572634348

Epoch: 5| Step: 4
Training loss: 2.693770523170124
Validation loss: 2.569906031609328

Epoch: 5| Step: 5
Training loss: 2.8142271884340357
Validation loss: 2.526422996311584

Epoch: 5| Step: 6
Training loss: 3.2739382704483075
Validation loss: 2.5377917339600486

Epoch: 5| Step: 7
Training loss: 2.8612672975083133
Validation loss: 2.539806563508266

Epoch: 5| Step: 8
Training loss: 2.9351329600486693
Validation loss: 2.584751938106619

Epoch: 5| Step: 9
Training loss: 2.642157747449695
Validation loss: 2.556132292602988

Epoch: 5| Step: 10
Training loss: 2.960428078343309
Validation loss: 2.524116773406544

Epoch: 46| Step: 0
Training loss: 3.470022432106353
Validation loss: 2.566959370632787

Epoch: 5| Step: 1
Training loss: 2.954764097966839
Validation loss: 2.5517361258878766

Epoch: 5| Step: 2
Training loss: 2.3117311591420915
Validation loss: 2.56246934617799

Epoch: 5| Step: 3
Training loss: 3.168616514385162
Validation loss: 2.5642229536150163

Epoch: 5| Step: 4
Training loss: 2.4413560541714814
Validation loss: 2.532295502340909

Epoch: 5| Step: 5
Training loss: 2.870069339193704
Validation loss: 2.523721648279778

Epoch: 5| Step: 6
Training loss: 3.6687753133859076
Validation loss: 2.5484634027198125

Epoch: 5| Step: 7
Training loss: 3.035368019679422
Validation loss: 2.571722532628425

Epoch: 5| Step: 8
Training loss: 2.547451117947848
Validation loss: 2.5573499476730057

Epoch: 5| Step: 9
Training loss: 2.4721856656270846
Validation loss: 2.548900747578828

Epoch: 5| Step: 10
Training loss: 2.4766686834923535
Validation loss: 2.546769571352406

Epoch: 47| Step: 0
Training loss: 2.3998836171223847
Validation loss: 2.562883317891842

Epoch: 5| Step: 1
Training loss: 2.949849082836481
Validation loss: 2.550037967898683

Epoch: 5| Step: 2
Training loss: 3.3635931457442436
Validation loss: 2.517341831988234

Epoch: 5| Step: 3
Training loss: 2.908990203945835
Validation loss: 2.5346409881905774

Epoch: 5| Step: 4
Training loss: 2.6313153546478363
Validation loss: 2.5629487053738904

Epoch: 5| Step: 5
Training loss: 2.7349555570907316
Validation loss: 2.5482766845134104

Epoch: 5| Step: 6
Training loss: 3.1456175639615847
Validation loss: 2.543265041017246

Epoch: 5| Step: 7
Training loss: 3.245297918530299
Validation loss: 2.56842894799711

Epoch: 5| Step: 8
Training loss: 1.998073305494022
Validation loss: 2.5291909315414993

Epoch: 5| Step: 9
Training loss: 2.574732357300649
Validation loss: 2.5756025088720143

Epoch: 5| Step: 10
Training loss: 3.4343073497214944
Validation loss: 2.5646806667876403

Epoch: 48| Step: 0
Training loss: 2.9084377463178654
Validation loss: 2.549523249131118

Epoch: 5| Step: 1
Training loss: 2.893536395434504
Validation loss: 2.5272195094500423

Epoch: 5| Step: 2
Training loss: 2.7473642549312025
Validation loss: 2.571400797711522

Epoch: 5| Step: 3
Training loss: 3.5917959456989688
Validation loss: 2.560334167483708

Epoch: 5| Step: 4
Training loss: 3.035418446334565
Validation loss: 2.5701097476445884

Epoch: 5| Step: 5
Training loss: 2.8171467859052326
Validation loss: 2.55968623493055

Epoch: 5| Step: 6
Training loss: 3.360642021239673
Validation loss: 2.5309035123440577

Epoch: 5| Step: 7
Training loss: 2.76751937211587
Validation loss: 2.5715162655888957

Epoch: 5| Step: 8
Training loss: 2.5021530416933286
Validation loss: 2.560178570079288

Epoch: 5| Step: 9
Training loss: 2.031292137295814
Validation loss: 2.5195844019690226

Epoch: 5| Step: 10
Training loss: 2.8056376343440723
Validation loss: 2.522384858312973

Epoch: 49| Step: 0
Training loss: 3.369236723040729
Validation loss: 2.5244115013096393

Epoch: 5| Step: 1
Training loss: 3.422562482220324
Validation loss: 2.572330226842702

Epoch: 5| Step: 2
Training loss: 2.526090378963439
Validation loss: 2.5479173830337034

Epoch: 5| Step: 3
Training loss: 2.950183998447355
Validation loss: 2.545517742556807

Epoch: 5| Step: 4
Training loss: 2.5295082976006653
Validation loss: 2.550835169898626

Epoch: 5| Step: 5
Training loss: 3.5471690051863867
Validation loss: 2.588336560027085

Epoch: 5| Step: 6
Training loss: 1.9325488417203758
Validation loss: 2.5327536227568603

Epoch: 5| Step: 7
Training loss: 3.00516367614111
Validation loss: 2.5384131432476105

Epoch: 5| Step: 8
Training loss: 2.4955391185570575
Validation loss: 2.549933182265012

Epoch: 5| Step: 9
Training loss: 2.9854306256397605
Validation loss: 2.5767701050143943

Epoch: 5| Step: 10
Training loss: 2.8111342610933443
Validation loss: 2.556296718898686

Epoch: 50| Step: 0
Training loss: 2.664931527523122
Validation loss: 2.5409832571381505

Epoch: 5| Step: 1
Training loss: 2.070025499712022
Validation loss: 2.5602459041262065

Epoch: 5| Step: 2
Training loss: 3.2991527625749106
Validation loss: 2.550375844404843

Epoch: 5| Step: 3
Training loss: 3.049086330704233
Validation loss: 2.547026782127934

Epoch: 5| Step: 4
Training loss: 2.638459530975269
Validation loss: 2.533604519237113

Epoch: 5| Step: 5
Training loss: 2.523019761977665
Validation loss: 2.5530757364958165

Epoch: 5| Step: 6
Training loss: 3.369985316439824
Validation loss: 2.5485777420804556

Epoch: 5| Step: 7
Training loss: 2.8929341758415372
Validation loss: 2.5402662974156645

Epoch: 5| Step: 8
Training loss: 3.0486839206567953
Validation loss: 2.5362941121685196

Epoch: 5| Step: 9
Training loss: 3.1577151080123014
Validation loss: 2.5551259176209498

Epoch: 5| Step: 10
Training loss: 2.812194129418025
Validation loss: 2.5317400588703762

Epoch: 51| Step: 0
Training loss: 2.6258614352784715
Validation loss: 2.5696139837232996

Epoch: 5| Step: 1
Training loss: 2.872879075285519
Validation loss: 2.555649549302207

Epoch: 5| Step: 2
Training loss: 2.6396369665689066
Validation loss: 2.529703573063009

Epoch: 5| Step: 3
Training loss: 3.263845150341124
Validation loss: 2.5565922725177557

Epoch: 5| Step: 4
Training loss: 2.5613469576786865
Validation loss: 2.5360923014975114

Epoch: 5| Step: 5
Training loss: 2.830881198332036
Validation loss: 2.5614046256253333

Epoch: 5| Step: 6
Training loss: 2.995649043654651
Validation loss: 2.544335361401807

Epoch: 5| Step: 7
Training loss: 2.936217007571436
Validation loss: 2.554518890611988

Epoch: 5| Step: 8
Training loss: 2.710153779737722
Validation loss: 2.555976415333638

Epoch: 5| Step: 9
Training loss: 2.573508551056246
Validation loss: 2.5315325270551066

Epoch: 5| Step: 10
Training loss: 3.7729900086869903
Validation loss: 2.5601973043104564

Epoch: 52| Step: 0
Training loss: 2.545499465285938
Validation loss: 2.5598266406606833

Epoch: 5| Step: 1
Training loss: 3.115867239546637
Validation loss: 2.523235850796921

Epoch: 5| Step: 2
Training loss: 2.950170259896525
Validation loss: 2.56038387911755

Epoch: 5| Step: 3
Training loss: 3.290691054098727
Validation loss: 2.526661579844941

Epoch: 5| Step: 4
Training loss: 2.4180236711566083
Validation loss: 2.5412142108973823

Epoch: 5| Step: 5
Training loss: 2.8000016450877125
Validation loss: 2.5380860021443827

Epoch: 5| Step: 6
Training loss: 2.54197277247796
Validation loss: 2.5623156528507427

Epoch: 5| Step: 7
Training loss: 3.142073567666178
Validation loss: 2.5462685200193507

Epoch: 5| Step: 8
Training loss: 2.945664281099562
Validation loss: 2.575581802404174

Epoch: 5| Step: 9
Training loss: 2.475247391946241
Validation loss: 2.5619023624334845

Epoch: 5| Step: 10
Training loss: 3.343157849509694
Validation loss: 2.533176682922989

Epoch: 53| Step: 0
Training loss: 3.6114138174747246
Validation loss: 2.529948342597776

Epoch: 5| Step: 1
Training loss: 2.837111217062771
Validation loss: 2.5356906762588696

Epoch: 5| Step: 2
Training loss: 3.157783513452826
Validation loss: 2.5311488216530433

Epoch: 5| Step: 3
Training loss: 2.4581752230559344
Validation loss: 2.5530847245201853

Epoch: 5| Step: 4
Training loss: 2.367184478455683
Validation loss: 2.554207147437637

Epoch: 5| Step: 5
Training loss: 2.159803475517262
Validation loss: 2.5597532053572984

Epoch: 5| Step: 6
Training loss: 2.6790359639213293
Validation loss: 2.563333017294364

Epoch: 5| Step: 7
Training loss: 2.5700584216472455
Validation loss: 2.5560252889796624

Epoch: 5| Step: 8
Training loss: 3.214640985261579
Validation loss: 2.524719193182494

Epoch: 5| Step: 9
Training loss: 2.906436709077297
Validation loss: 2.5536728336298693

Epoch: 5| Step: 10
Training loss: 3.3947808598622116
Validation loss: 2.5286227291808947

Epoch: 54| Step: 0
Training loss: 2.744048006388508
Validation loss: 2.5430038276078917

Epoch: 5| Step: 1
Training loss: 3.136739728389531
Validation loss: 2.508048725371923

Epoch: 5| Step: 2
Training loss: 2.140218320209506
Validation loss: 2.5509942525858387

Epoch: 5| Step: 3
Training loss: 2.8266384369712085
Validation loss: 2.564342387704083

Epoch: 5| Step: 4
Training loss: 2.930555047330968
Validation loss: 2.5504073683220994

Epoch: 5| Step: 5
Training loss: 2.3858477162753595
Validation loss: 2.545498024087133

Epoch: 5| Step: 6
Training loss: 2.626953578792944
Validation loss: 2.5419701916636464

Epoch: 5| Step: 7
Training loss: 3.0637413156138074
Validation loss: 2.540875853659628

Epoch: 5| Step: 8
Training loss: 2.691797590663905
Validation loss: 2.511685720841609

Epoch: 5| Step: 9
Training loss: 3.6545420512938818
Validation loss: 2.516929103985318

Epoch: 5| Step: 10
Training loss: 3.306982663755422
Validation loss: 2.530102199524316

Epoch: 55| Step: 0
Training loss: 3.217204639598513
Validation loss: 2.540308230402362

Epoch: 5| Step: 1
Training loss: 3.1309611112993325
Validation loss: 2.5442723017610755

Epoch: 5| Step: 2
Training loss: 3.579662409161234
Validation loss: 2.53419989969564

Epoch: 5| Step: 3
Training loss: 2.5096328165858193
Validation loss: 2.534963202801144

Epoch: 5| Step: 4
Training loss: 2.376111222357999
Validation loss: 2.5359583000444275

Epoch: 5| Step: 5
Training loss: 2.553759111639303
Validation loss: 2.518323843322235

Epoch: 5| Step: 6
Training loss: 3.160915288314431
Validation loss: 2.5410580369492175

Epoch: 5| Step: 7
Training loss: 2.9437773166693026
Validation loss: 2.5408412289631888

Epoch: 5| Step: 8
Training loss: 2.906489044531048
Validation loss: 2.545356169271075

Epoch: 5| Step: 9
Training loss: 2.9363922302953944
Validation loss: 2.527739166951424

Epoch: 5| Step: 10
Training loss: 2.2546813795571055
Validation loss: 2.5229213091018527

Epoch: 56| Step: 0
Training loss: 3.3436514581438304
Validation loss: 2.5434271805610207

Epoch: 5| Step: 1
Training loss: 3.0827363613372363
Validation loss: 2.531636874826645

Epoch: 5| Step: 2
Training loss: 2.178431432724032
Validation loss: 2.521301617234599

Epoch: 5| Step: 3
Training loss: 3.1542025430941063
Validation loss: 2.5367694768423754

Epoch: 5| Step: 4
Training loss: 2.828991161927286
Validation loss: 2.5472462802039706

Epoch: 5| Step: 5
Training loss: 2.9058670283833545
Validation loss: 2.529097662513824

Epoch: 5| Step: 6
Training loss: 2.6940287753340497
Validation loss: 2.5462632482908756

Epoch: 5| Step: 7
Training loss: 3.1802820498064004
Validation loss: 2.5562880901659213

Epoch: 5| Step: 8
Training loss: 2.017103968515209
Validation loss: 2.5046932067861354

Epoch: 5| Step: 9
Training loss: 3.199185810222288
Validation loss: 2.5571042745664037

Epoch: 5| Step: 10
Training loss: 2.806539704931403
Validation loss: 2.534259335565559

Epoch: 57| Step: 0
Training loss: 2.9438178117396836
Validation loss: 2.5321411707128507

Epoch: 5| Step: 1
Training loss: 2.352955149160298
Validation loss: 2.5285914172866013

Epoch: 5| Step: 2
Training loss: 3.019692479575298
Validation loss: 2.5758394384171637

Epoch: 5| Step: 3
Training loss: 2.6442879997409
Validation loss: 2.548697446620192

Epoch: 5| Step: 4
Training loss: 2.9889212128767575
Validation loss: 2.514541531759512

Epoch: 5| Step: 5
Training loss: 3.348632242909692
Validation loss: 2.5228603989175182

Epoch: 5| Step: 6
Training loss: 3.1232740595135224
Validation loss: 2.553441931450677

Epoch: 5| Step: 7
Training loss: 2.411042432300096
Validation loss: 2.5460452090611043

Epoch: 5| Step: 8
Training loss: 3.0836090961206843
Validation loss: 2.553899946617713

Epoch: 5| Step: 9
Training loss: 2.850452112844492
Validation loss: 2.5640383888942635

Epoch: 5| Step: 10
Training loss: 2.8132205463990707
Validation loss: 2.5162972049146584

Epoch: 58| Step: 0
Training loss: 2.9787839274649373
Validation loss: 2.5450196973968087

Epoch: 5| Step: 1
Training loss: 3.3314330088317825
Validation loss: 2.5226514567264595

Epoch: 5| Step: 2
Training loss: 3.0373411034988984
Validation loss: 2.5427109810238746

Epoch: 5| Step: 3
Training loss: 2.7373572952490193
Validation loss: 2.5695190182363987

Epoch: 5| Step: 4
Training loss: 3.1681308540234463
Validation loss: 2.55173905549009

Epoch: 5| Step: 5
Training loss: 2.392981969265693
Validation loss: 2.5121783996625955

Epoch: 5| Step: 6
Training loss: 2.8453870819053817
Validation loss: 2.5293768014876616

Epoch: 5| Step: 7
Training loss: 2.303755335685193
Validation loss: 2.550162583580309

Epoch: 5| Step: 8
Training loss: 3.3140983324213553
Validation loss: 2.5592853221767906

Epoch: 5| Step: 9
Training loss: 2.3959989297001507
Validation loss: 2.5520481759303975

Epoch: 5| Step: 10
Training loss: 2.9582702379258974
Validation loss: 2.5563042394313005

Epoch: 59| Step: 0
Training loss: 3.169810106865461
Validation loss: 2.543366646555815

Epoch: 5| Step: 1
Training loss: 2.689820197382045
Validation loss: 2.5325196066250077

Epoch: 5| Step: 2
Training loss: 3.065100052711148
Validation loss: 2.565604330675594

Epoch: 5| Step: 3
Training loss: 2.6626283247563256
Validation loss: 2.558029150334622

Epoch: 5| Step: 4
Training loss: 2.1585307567350056
Validation loss: 2.527564856971865

Epoch: 5| Step: 5
Training loss: 2.8638294314520847
Validation loss: 2.495585385183688

Epoch: 5| Step: 6
Training loss: 3.0905935195229866
Validation loss: 2.5496367918707983

Epoch: 5| Step: 7
Training loss: 3.350478061328102
Validation loss: 2.530258168722969

Epoch: 5| Step: 8
Training loss: 3.1047704907303313
Validation loss: 2.537258482788612

Epoch: 5| Step: 9
Training loss: 2.3298560753768065
Validation loss: 2.558587894465874

Epoch: 5| Step: 10
Training loss: 3.112321080959728
Validation loss: 2.5504764620461926

Epoch: 60| Step: 0
Training loss: 2.958048273957755
Validation loss: 2.539406423191045

Epoch: 5| Step: 1
Training loss: 3.2196268905656016
Validation loss: 2.5303710014927336

Epoch: 5| Step: 2
Training loss: 2.5339428741410885
Validation loss: 2.5397947708451913

Epoch: 5| Step: 3
Training loss: 2.617977831490935
Validation loss: 2.5115524545950314

Epoch: 5| Step: 4
Training loss: 3.4866484337275874
Validation loss: 2.5279210688698983

Epoch: 5| Step: 5
Training loss: 3.208509432100661
Validation loss: 2.5131367070061

Epoch: 5| Step: 6
Training loss: 2.425521566401666
Validation loss: 2.543737392712262

Epoch: 5| Step: 7
Training loss: 2.5777160320158283
Validation loss: 2.546300699879242

Epoch: 5| Step: 8
Training loss: 2.4011356448457324
Validation loss: 2.5376549935753028

Epoch: 5| Step: 9
Training loss: 3.1834562494271226
Validation loss: 2.554090131179613

Epoch: 5| Step: 10
Training loss: 2.7926145529068593
Validation loss: 2.5437180766762926

Epoch: 61| Step: 0
Training loss: 3.445643817774804
Validation loss: 2.5385042531955855

Epoch: 5| Step: 1
Training loss: 2.959481638806798
Validation loss: 2.5425376939453295

Epoch: 5| Step: 2
Training loss: 3.4215317645440164
Validation loss: 2.5301480879418152

Epoch: 5| Step: 3
Training loss: 2.7748206759411267
Validation loss: 2.5624655824556384

Epoch: 5| Step: 4
Training loss: 2.6720825471633507
Validation loss: 2.5546553174050484

Epoch: 5| Step: 5
Training loss: 2.299791003144001
Validation loss: 2.5435969182673235

Epoch: 5| Step: 6
Training loss: 3.169619655716101
Validation loss: 2.5552634115979043

Epoch: 5| Step: 7
Training loss: 2.9289686618116964
Validation loss: 2.51633238637867

Epoch: 5| Step: 8
Training loss: 2.612614066084155
Validation loss: 2.5362088047695424

Epoch: 5| Step: 9
Training loss: 3.0948774036783475
Validation loss: 2.5577058893765496

Epoch: 5| Step: 10
Training loss: 1.7136096728278953
Validation loss: 2.543159982871528

Epoch: 62| Step: 0
Training loss: 3.3911955041440267
Validation loss: 2.5496722724372685

Epoch: 5| Step: 1
Training loss: 3.0480105118157255
Validation loss: 2.541222990686907

Epoch: 5| Step: 2
Training loss: 2.846695600566586
Validation loss: 2.536036181833355

Epoch: 5| Step: 3
Training loss: 2.698052382032077
Validation loss: 2.542676744789419

Epoch: 5| Step: 4
Training loss: 2.0682567826746245
Validation loss: 2.5296382900254417

Epoch: 5| Step: 5
Training loss: 2.717913882717929
Validation loss: 2.56290644962076

Epoch: 5| Step: 6
Training loss: 2.8220539158808045
Validation loss: 2.542777738666483

Epoch: 5| Step: 7
Training loss: 2.952429634050328
Validation loss: 2.5580643270907557

Epoch: 5| Step: 8
Training loss: 2.9156213431217854
Validation loss: 2.5349073716540387

Epoch: 5| Step: 9
Training loss: 3.221961632053189
Validation loss: 2.5424952744124742

Epoch: 5| Step: 10
Training loss: 2.7189818535522243
Validation loss: 2.54804338875196

Epoch: 63| Step: 0
Training loss: 2.786588966421051
Validation loss: 2.5300740617619333

Epoch: 5| Step: 1
Training loss: 2.2935911825220128
Validation loss: 2.540034461134448

Epoch: 5| Step: 2
Training loss: 2.100084430268891
Validation loss: 2.544608099726251

Epoch: 5| Step: 3
Training loss: 3.6456110132643307
Validation loss: 2.523704619057621

Epoch: 5| Step: 4
Training loss: 3.1205362101261533
Validation loss: 2.5305981998913167

Epoch: 5| Step: 5
Training loss: 2.705733523519837
Validation loss: 2.5496420691926476

Epoch: 5| Step: 6
Training loss: 3.3034633957567157
Validation loss: 2.54454589214075

Epoch: 5| Step: 7
Training loss: 2.0636513704129333
Validation loss: 2.5342632180589897

Epoch: 5| Step: 8
Training loss: 3.318669170537576
Validation loss: 2.5398211500775627

Epoch: 5| Step: 9
Training loss: 2.7692970854814853
Validation loss: 2.537086452673077

Epoch: 5| Step: 10
Training loss: 2.965640879388549
Validation loss: 2.532908277387297

Epoch: 64| Step: 0
Training loss: 3.387021025969412
Validation loss: 2.4996345396460864

Epoch: 5| Step: 1
Training loss: 2.6866435083411915
Validation loss: 2.5140719252981065

Epoch: 5| Step: 2
Training loss: 2.7945808079916064
Validation loss: 2.520756769064213

Epoch: 5| Step: 3
Training loss: 2.7748432733765305
Validation loss: 2.556189244770829

Epoch: 5| Step: 4
Training loss: 2.59208515464164
Validation loss: 2.547493969700651

Epoch: 5| Step: 5
Training loss: 3.3632594162146985
Validation loss: 2.5348172611121345

Epoch: 5| Step: 6
Training loss: 2.6363948368749472
Validation loss: 2.5514939277771207

Epoch: 5| Step: 7
Training loss: 3.625180733220172
Validation loss: 2.577194093532186

Epoch: 5| Step: 8
Training loss: 2.140373270868299
Validation loss: 2.530246143103059

Epoch: 5| Step: 9
Training loss: 2.670037424060987
Validation loss: 2.529381383726578

Epoch: 5| Step: 10
Training loss: 2.5361911912382324
Validation loss: 2.5335366764803986

Epoch: 65| Step: 0
Training loss: 3.1220118159498793
Validation loss: 2.534264742022021

Epoch: 5| Step: 1
Training loss: 2.385797950445838
Validation loss: 2.5206334360166616

Epoch: 5| Step: 2
Training loss: 3.0131963724333026
Validation loss: 2.5399483457317085

Epoch: 5| Step: 3
Training loss: 2.575785552262198
Validation loss: 2.519744238786323

Epoch: 5| Step: 4
Training loss: 3.5299628958764777
Validation loss: 2.549120322642608

Epoch: 5| Step: 5
Training loss: 2.3722001688416277
Validation loss: 2.523348943726765

Epoch: 5| Step: 6
Training loss: 2.4109516531528232
Validation loss: 2.499888330447181

Epoch: 5| Step: 7
Training loss: 3.3662984785179355
Validation loss: 2.5543295709993696

Epoch: 5| Step: 8
Training loss: 2.688900161444555
Validation loss: 2.5132324799519514

Epoch: 5| Step: 9
Training loss: 2.892504766488331
Validation loss: 2.526557345200549

Epoch: 5| Step: 10
Training loss: 2.823789698510421
Validation loss: 2.5439696554002182

Epoch: 66| Step: 0
Training loss: 3.3365942422461465
Validation loss: 2.5200766123666214

Epoch: 5| Step: 1
Training loss: 2.876450048566283
Validation loss: 2.5429613301594673

Epoch: 5| Step: 2
Training loss: 2.709818144464332
Validation loss: 2.5725298823256573

Epoch: 5| Step: 3
Training loss: 4.057752681815666
Validation loss: 2.571352185400506

Epoch: 5| Step: 4
Training loss: 2.66928903464958
Validation loss: 2.536757177899783

Epoch: 5| Step: 5
Training loss: 2.7517172913387444
Validation loss: 2.5349072887245647

Epoch: 5| Step: 6
Training loss: 2.7150571451091956
Validation loss: 2.5626129217550946

Epoch: 5| Step: 7
Training loss: 2.845839016090926
Validation loss: 2.5225292925746383

Epoch: 5| Step: 8
Training loss: 1.9195691674368545
Validation loss: 2.535401695372347

Epoch: 5| Step: 9
Training loss: 2.8232437920211195
Validation loss: 2.5317080787270627

Epoch: 5| Step: 10
Training loss: 2.0815330610726264
Validation loss: 2.5585964553243823

Epoch: 67| Step: 0
Training loss: 2.7706647740389125
Validation loss: 2.512904372469004

Epoch: 5| Step: 1
Training loss: 2.4073101532139747
Validation loss: 2.519602384943859

Epoch: 5| Step: 2
Training loss: 2.5875154503992217
Validation loss: 2.5260351473782623

Epoch: 5| Step: 3
Training loss: 2.9575099784315135
Validation loss: 2.5336663023557637

Epoch: 5| Step: 4
Training loss: 3.4865849760951226
Validation loss: 2.5105570200468663

Epoch: 5| Step: 5
Training loss: 3.1950108915092597
Validation loss: 2.5307713406334456

Epoch: 5| Step: 6
Training loss: 3.504098536085728
Validation loss: 2.5539398107737528

Epoch: 5| Step: 7
Training loss: 2.664720560277883
Validation loss: 2.5463120294853225

Epoch: 5| Step: 8
Training loss: 2.385541809886192
Validation loss: 2.5254893074619833

Epoch: 5| Step: 9
Training loss: 2.3752254579844254
Validation loss: 2.535289859036603

Epoch: 5| Step: 10
Training loss: 2.8463779924284918
Validation loss: 2.5508141327309968

Epoch: 68| Step: 0
Training loss: 2.4979164978315747
Validation loss: 2.5316367988785293

Epoch: 5| Step: 1
Training loss: 2.953584342634416
Validation loss: 2.521301792122907

Epoch: 5| Step: 2
Training loss: 3.2872510982612844
Validation loss: 2.506408960052051

Epoch: 5| Step: 3
Training loss: 2.67433071498306
Validation loss: 2.508566062500239

Epoch: 5| Step: 4
Training loss: 2.8789895613687477
Validation loss: 2.5415346792867854

Epoch: 5| Step: 5
Training loss: 2.209602303257763
Validation loss: 2.5195458481303645

Epoch: 5| Step: 6
Training loss: 3.0761776103617167
Validation loss: 2.5564921352489587

Epoch: 5| Step: 7
Training loss: 3.218639927435641
Validation loss: 2.5311483496710574

Epoch: 5| Step: 8
Training loss: 2.4296657156504327
Validation loss: 2.5657463329719854

Epoch: 5| Step: 9
Training loss: 2.69770145417052
Validation loss: 2.5223879846216652

Epoch: 5| Step: 10
Training loss: 3.132518117110948
Validation loss: 2.528666855542714

Epoch: 69| Step: 0
Training loss: 3.077872638717134
Validation loss: 2.541155997996901

Epoch: 5| Step: 1
Training loss: 3.3963870823741322
Validation loss: 2.5287153009889844

Epoch: 5| Step: 2
Training loss: 2.2431071983772566
Validation loss: 2.5338479295242022

Epoch: 5| Step: 3
Training loss: 2.4496176362905864
Validation loss: 2.5166258143718268

Epoch: 5| Step: 4
Training loss: 2.962431920552966
Validation loss: 2.5507891013709565

Epoch: 5| Step: 5
Training loss: 2.4461675252056736
Validation loss: 2.5442671044903684

Epoch: 5| Step: 6
Training loss: 3.061305844789409
Validation loss: 2.53633198892254

Epoch: 5| Step: 7
Training loss: 2.3416353986107348
Validation loss: 2.5409335796083266

Epoch: 5| Step: 8
Training loss: 2.8941267917594393
Validation loss: 2.5354567370752434

Epoch: 5| Step: 9
Training loss: 3.357641438155909
Validation loss: 2.53720302952524

Epoch: 5| Step: 10
Training loss: 2.971497880211192
Validation loss: 2.5082252757436097

Epoch: 70| Step: 0
Training loss: 3.130918467743955
Validation loss: 2.5320020637306158

Epoch: 5| Step: 1
Training loss: 2.2717780385059174
Validation loss: 2.5098088510323784

Epoch: 5| Step: 2
Training loss: 2.85257717526319
Validation loss: 2.5086931393364957

Epoch: 5| Step: 3
Training loss: 2.7176191236115645
Validation loss: 2.5699472764773668

Epoch: 5| Step: 4
Training loss: 3.114244032189643
Validation loss: 2.509317933658131

Epoch: 5| Step: 5
Training loss: 3.145047693906762
Validation loss: 2.5242894304607018

Epoch: 5| Step: 6
Training loss: 2.9672891335259055
Validation loss: 2.551145440936553

Epoch: 5| Step: 7
Training loss: 2.668856248371012
Validation loss: 2.5305872943074483

Epoch: 5| Step: 8
Training loss: 1.9339898830729103
Validation loss: 2.5313419136466866

Epoch: 5| Step: 9
Training loss: 3.5657240349859882
Validation loss: 2.529293129825104

Epoch: 5| Step: 10
Training loss: 2.748355286947937
Validation loss: 2.554722961599125

Epoch: 71| Step: 0
Training loss: 3.1522551078576506
Validation loss: 2.519672467871316

Epoch: 5| Step: 1
Training loss: 2.2777438458445487
Validation loss: 2.5070910393086905

Epoch: 5| Step: 2
Training loss: 2.706152482951825
Validation loss: 2.5633360256535798

Epoch: 5| Step: 3
Training loss: 3.442648621164901
Validation loss: 2.5453975812965526

Epoch: 5| Step: 4
Training loss: 2.8231760635470313
Validation loss: 2.554885469736184

Epoch: 5| Step: 5
Training loss: 2.7726214860557046
Validation loss: 2.5329377768506296

Epoch: 5| Step: 6
Training loss: 3.079718782294113
Validation loss: 2.5391987935505687

Epoch: 5| Step: 7
Training loss: 2.5683658730312287
Validation loss: 2.544768581121377

Epoch: 5| Step: 8
Training loss: 2.5139417999862808
Validation loss: 2.5415072768525326

Epoch: 5| Step: 9
Training loss: 3.075590842944348
Validation loss: 2.5006403390094323

Epoch: 5| Step: 10
Training loss: 2.8105760563547624
Validation loss: 2.545433448277712

Epoch: 72| Step: 0
Training loss: 2.2899480675551596
Validation loss: 2.519920284109431

Epoch: 5| Step: 1
Training loss: 2.472887941325936
Validation loss: 2.555030542072349

Epoch: 5| Step: 2
Training loss: 2.964921269264088
Validation loss: 2.5223597526737223

Epoch: 5| Step: 3
Training loss: 3.230694284373257
Validation loss: 2.527905109455449

Epoch: 5| Step: 4
Training loss: 2.9633437874448334
Validation loss: 2.5258764292634655

Epoch: 5| Step: 5
Training loss: 3.192670630045186
Validation loss: 2.5479726755560552

Epoch: 5| Step: 6
Training loss: 2.937367213068393
Validation loss: 2.544506030932951

Epoch: 5| Step: 7
Training loss: 2.4942990150434117
Validation loss: 2.556187754438647

Epoch: 5| Step: 8
Training loss: 2.6330334488612683
Validation loss: 2.557112623339175

Epoch: 5| Step: 9
Training loss: 2.495945790282915
Validation loss: 2.5426575114386507

Epoch: 5| Step: 10
Training loss: 3.4825998753933596
Validation loss: 2.547666593632026

Epoch: 73| Step: 0
Training loss: 2.6297134588527675
Validation loss: 2.546516674590139

Epoch: 5| Step: 1
Training loss: 2.8256789109036493
Validation loss: 2.5543867972044905

Epoch: 5| Step: 2
Training loss: 2.4964672877718215
Validation loss: 2.53903794345387

Epoch: 5| Step: 3
Training loss: 3.296401292658218
Validation loss: 2.546260551006176

Epoch: 5| Step: 4
Training loss: 2.9250883496627105
Validation loss: 2.5501175670155525

Epoch: 5| Step: 5
Training loss: 2.9314156686779853
Validation loss: 2.545482273574047

Epoch: 5| Step: 6
Training loss: 2.297290790318187
Validation loss: 2.521750952718497

Epoch: 5| Step: 7
Training loss: 2.9058880324193512
Validation loss: 2.5437711727465224

Epoch: 5| Step: 8
Training loss: 3.136690018499718
Validation loss: 2.5464632803849434

Epoch: 5| Step: 9
Training loss: 2.7334215518237146
Validation loss: 2.5459304689802846

Epoch: 5| Step: 10
Training loss: 2.9620159671206263
Validation loss: 2.548875330816819

Epoch: 74| Step: 0
Training loss: 3.19654042869479
Validation loss: 2.5346900820655214

Epoch: 5| Step: 1
Training loss: 2.575840903445568
Validation loss: 2.5439583526485587

Epoch: 5| Step: 2
Training loss: 2.113881700993383
Validation loss: 2.5340350006995207

Epoch: 5| Step: 3
Training loss: 2.630688815404371
Validation loss: 2.5553783074691623

Epoch: 5| Step: 4
Training loss: 3.4117711668746464
Validation loss: 2.5072184506216093

Epoch: 5| Step: 5
Training loss: 3.10627676570421
Validation loss: 2.505390969943238

Epoch: 5| Step: 6
Training loss: 2.352850171741512
Validation loss: 2.5666030960882935

Epoch: 5| Step: 7
Training loss: 2.635172886687079
Validation loss: 2.5388235823154455

Epoch: 5| Step: 8
Training loss: 3.5587171581321932
Validation loss: 2.5218908548914567

Epoch: 5| Step: 9
Training loss: 3.013875186808936
Validation loss: 2.537219447281174

Epoch: 5| Step: 10
Training loss: 2.4363096215990576
Validation loss: 2.518088952458228

Epoch: 75| Step: 0
Training loss: 3.0912144607000362
Validation loss: 2.5596354070249365

Epoch: 5| Step: 1
Training loss: 2.7754980035636208
Validation loss: 2.5407736157623164

Epoch: 5| Step: 2
Training loss: 3.2395062861628126
Validation loss: 2.5320957583284476

Epoch: 5| Step: 3
Training loss: 2.6813089786614097
Validation loss: 2.5356947587649294

Epoch: 5| Step: 4
Training loss: 2.634566540616045
Validation loss: 2.4946772938599406

Epoch: 5| Step: 5
Training loss: 2.716246932511193
Validation loss: 2.5200856204250046

Epoch: 5| Step: 6
Training loss: 2.972026582817214
Validation loss: 2.5429201677976665

Epoch: 5| Step: 7
Training loss: 2.6651674367613194
Validation loss: 2.522751910885763

Epoch: 5| Step: 8
Training loss: 3.2450315204141615
Validation loss: 2.4969338965431924

Epoch: 5| Step: 9
Training loss: 3.13004582258814
Validation loss: 2.5597179105943866

Epoch: 5| Step: 10
Training loss: 1.6827743908490633
Validation loss: 2.512982299516056

Epoch: 76| Step: 0
Training loss: 3.283640109090494
Validation loss: 2.5113106634682834

Epoch: 5| Step: 1
Training loss: 2.9010009945404547
Validation loss: 2.540459783247256

Epoch: 5| Step: 2
Training loss: 3.136900862066351
Validation loss: 2.535939811335643

Epoch: 5| Step: 3
Training loss: 3.0493071410112442
Validation loss: 2.5426518228720307

Epoch: 5| Step: 4
Training loss: 2.9226765068798133
Validation loss: 2.535523816650438

Epoch: 5| Step: 5
Training loss: 2.6926719225273144
Validation loss: 2.4983528012288283

Epoch: 5| Step: 6
Training loss: 3.008320079432603
Validation loss: 2.5034806222830523

Epoch: 5| Step: 7
Training loss: 2.289333496717308
Validation loss: 2.5252109539777905

Epoch: 5| Step: 8
Training loss: 2.7583057513591487
Validation loss: 2.532723656545651

Epoch: 5| Step: 9
Training loss: 2.5244287958951097
Validation loss: 2.5552603430690173

Epoch: 5| Step: 10
Training loss: 2.483292733784372
Validation loss: 2.51823167034815

Epoch: 77| Step: 0
Training loss: 3.1742402076230647
Validation loss: 2.5022342250486638

Epoch: 5| Step: 1
Training loss: 3.002736115458225
Validation loss: 2.5400220488108944

Epoch: 5| Step: 2
Training loss: 2.877375077784757
Validation loss: 2.533745967571335

Epoch: 5| Step: 3
Training loss: 2.6288796773533987
Validation loss: 2.5701681785337134

Epoch: 5| Step: 4
Training loss: 3.570085313776695
Validation loss: 2.570945063714717

Epoch: 5| Step: 5
Training loss: 3.011013477833716
Validation loss: 2.5336747177353804

Epoch: 5| Step: 6
Training loss: 2.009728018925071
Validation loss: 2.5377626343871595

Epoch: 5| Step: 7
Training loss: 2.411372096014427
Validation loss: 2.4996925821284415

Epoch: 5| Step: 8
Training loss: 2.929209433650821
Validation loss: 2.5303444852410735

Epoch: 5| Step: 9
Training loss: 2.4128042355363637
Validation loss: 2.5172667046028625

Epoch: 5| Step: 10
Training loss: 2.9111454249034905
Validation loss: 2.5089324626749274

Epoch: 78| Step: 0
Training loss: 2.546134232523748
Validation loss: 2.546390495666774

Epoch: 5| Step: 1
Training loss: 3.103965308978704
Validation loss: 2.557477788181867

Epoch: 5| Step: 2
Training loss: 3.323613220361541
Validation loss: 2.543446231702154

Epoch: 5| Step: 3
Training loss: 2.932943015428443
Validation loss: 2.5785137461409984

Epoch: 5| Step: 4
Training loss: 2.475587767350162
Validation loss: 2.5350320186665263

Epoch: 5| Step: 5
Training loss: 2.7654768909515783
Validation loss: 2.5481109710332683

Epoch: 5| Step: 6
Training loss: 3.2156285826252518
Validation loss: 2.561298664015686

Epoch: 5| Step: 7
Training loss: 2.9251597499424036
Validation loss: 2.5411333976791917

Epoch: 5| Step: 8
Training loss: 2.2515526818320155
Validation loss: 2.541720998120463

Epoch: 5| Step: 9
Training loss: 3.279472232785384
Validation loss: 2.526593773885909

Epoch: 5| Step: 10
Training loss: 1.8339466095144872
Validation loss: 2.48512254136798

Epoch: 79| Step: 0
Training loss: 2.491455161857697
Validation loss: 2.5347798967470028

Epoch: 5| Step: 1
Training loss: 3.184847157881738
Validation loss: 2.529146535572696

Epoch: 5| Step: 2
Training loss: 3.1447304988310716
Validation loss: 2.5496173415499648

Epoch: 5| Step: 3
Training loss: 2.9061295679222146
Validation loss: 2.4864411263257757

Epoch: 5| Step: 4
Training loss: 2.6347668918524567
Validation loss: 2.526417305691725

Epoch: 5| Step: 5
Training loss: 3.117204479658877
Validation loss: 2.5206195785079992

Epoch: 5| Step: 6
Training loss: 2.4837209932335402
Validation loss: 2.509454753167558

Epoch: 5| Step: 7
Training loss: 2.7794382430666604
Validation loss: 2.503784513576954

Epoch: 5| Step: 8
Training loss: 2.242553893667534
Validation loss: 2.5472980135139545

Epoch: 5| Step: 9
Training loss: 2.509915334785811
Validation loss: 2.5394974934649324

Epoch: 5| Step: 10
Training loss: 3.5723506527350013
Validation loss: 2.5167996535287678

Epoch: 80| Step: 0
Training loss: 3.0734915157937643
Validation loss: 2.530581204787266

Epoch: 5| Step: 1
Training loss: 2.1925388611989143
Validation loss: 2.5221092593813625

Epoch: 5| Step: 2
Training loss: 2.5574728803790885
Validation loss: 2.512074726951935

Epoch: 5| Step: 3
Training loss: 2.7509791625054274
Validation loss: 2.5246163456786483

Epoch: 5| Step: 4
Training loss: 2.513131273969073
Validation loss: 2.5157695064568917

Epoch: 5| Step: 5
Training loss: 2.583208009284614
Validation loss: 2.5568995719758862

Epoch: 5| Step: 6
Training loss: 3.2332629074869033
Validation loss: 2.532795697330496

Epoch: 5| Step: 7
Training loss: 2.999329651006657
Validation loss: 2.558026173817675

Epoch: 5| Step: 8
Training loss: 3.5071485269082805
Validation loss: 2.5769874128803805

Epoch: 5| Step: 9
Training loss: 2.713758776003486
Validation loss: 2.5305241656038713

Epoch: 5| Step: 10
Training loss: 2.9816962397988607
Validation loss: 2.5499119139579163

Epoch: 81| Step: 0
Training loss: 2.437706767384552
Validation loss: 2.55045106048453

Epoch: 5| Step: 1
Training loss: 2.8813057453447626
Validation loss: 2.5122966716123054

Epoch: 5| Step: 2
Training loss: 2.6892132288500603
Validation loss: 2.523151106770637

Epoch: 5| Step: 3
Training loss: 3.543157570380194
Validation loss: 2.543450506371169

Epoch: 5| Step: 4
Training loss: 2.4546597290410697
Validation loss: 2.54271104706302

Epoch: 5| Step: 5
Training loss: 2.1957337324896478
Validation loss: 2.5375089510958766

Epoch: 5| Step: 6
Training loss: 3.1637481156505216
Validation loss: 2.52567005085936

Epoch: 5| Step: 7
Training loss: 2.773493634582664
Validation loss: 2.542091678714649

Epoch: 5| Step: 8
Training loss: 3.261958203691739
Validation loss: 2.5488981707618863

Epoch: 5| Step: 9
Training loss: 2.5961549938231974
Validation loss: 2.53389663002224

Epoch: 5| Step: 10
Training loss: 3.1113235272447195
Validation loss: 2.5180160256310393

Epoch: 82| Step: 0
Training loss: 3.7750599534282285
Validation loss: 2.5387526547272294

Epoch: 5| Step: 1
Training loss: 2.722966399513299
Validation loss: 2.5458561031670714

Epoch: 5| Step: 2
Training loss: 2.5507242333668803
Validation loss: 2.524114066675212

Epoch: 5| Step: 3
Training loss: 2.7098223676565425
Validation loss: 2.55295907206095

Epoch: 5| Step: 4
Training loss: 2.454957896879631
Validation loss: 2.540171892931901

Epoch: 5| Step: 5
Training loss: 2.355213461432652
Validation loss: 2.52348623886187

Epoch: 5| Step: 6
Training loss: 2.321010292013968
Validation loss: 2.5284012827819233

Epoch: 5| Step: 7
Training loss: 3.257002402745392
Validation loss: 2.5546238499213683

Epoch: 5| Step: 8
Training loss: 3.001958366791536
Validation loss: 2.520241440497273

Epoch: 5| Step: 9
Training loss: 2.9370728851823773
Validation loss: 2.532004614205436

Epoch: 5| Step: 10
Training loss: 2.7241529950716536
Validation loss: 2.519468995101261

Epoch: 83| Step: 0
Training loss: 4.0922450436992
Validation loss: 2.537221442341732

Epoch: 5| Step: 1
Training loss: 2.5135206815810847
Validation loss: 2.5595617158365607

Epoch: 5| Step: 2
Training loss: 2.782842630162196
Validation loss: 2.539612415166757

Epoch: 5| Step: 3
Training loss: 2.6486260001018502
Validation loss: 2.5464562693991186

Epoch: 5| Step: 4
Training loss: 2.004557780635056
Validation loss: 2.5290485624603343

Epoch: 5| Step: 5
Training loss: 2.7028234236407496
Validation loss: 2.526332963175059

Epoch: 5| Step: 6
Training loss: 3.2119511770050857
Validation loss: 2.526926138299186

Epoch: 5| Step: 7
Training loss: 2.5253011240665764
Validation loss: 2.5290256339759813

Epoch: 5| Step: 8
Training loss: 2.582054426634588
Validation loss: 2.5295212956235247

Epoch: 5| Step: 9
Training loss: 2.9801697187289853
Validation loss: 2.528596012101218

Epoch: 5| Step: 10
Training loss: 2.5754808217724845
Validation loss: 2.5417593830317244

Epoch: 84| Step: 0
Training loss: 2.808188970309646
Validation loss: 2.4929930469386083

Epoch: 5| Step: 1
Training loss: 2.9507916632870765
Validation loss: 2.524062811909723

Epoch: 5| Step: 2
Training loss: 2.8751351697907825
Validation loss: 2.504909042550169

Epoch: 5| Step: 3
Training loss: 2.787337509688021
Validation loss: 2.5434528427705794

Epoch: 5| Step: 4
Training loss: 3.3158409975903957
Validation loss: 2.528728764369775

Epoch: 5| Step: 5
Training loss: 2.4047279002543043
Validation loss: 2.5055612114262362

Epoch: 5| Step: 6
Training loss: 2.4714901360483372
Validation loss: 2.5084619538244697

Epoch: 5| Step: 7
Training loss: 2.9490824484749205
Validation loss: 2.5568515221792056

Epoch: 5| Step: 8
Training loss: 2.8148571732979444
Validation loss: 2.5260030391891357

Epoch: 5| Step: 9
Training loss: 2.656146148446647
Validation loss: 2.5288783054714385

Epoch: 5| Step: 10
Training loss: 2.9333825981453647
Validation loss: 2.527040044039449

Epoch: 85| Step: 0
Training loss: 2.4972161051677975
Validation loss: 2.53786549057878

Epoch: 5| Step: 1
Training loss: 3.1982447220886905
Validation loss: 2.5334857712117596

Epoch: 5| Step: 2
Training loss: 2.4578774455148107
Validation loss: 2.533916877862836

Epoch: 5| Step: 3
Training loss: 2.1623434682653344
Validation loss: 2.555184328959329

Epoch: 5| Step: 4
Training loss: 2.4179128415449265
Validation loss: 2.539574175472593

Epoch: 5| Step: 5
Training loss: 3.099860120509252
Validation loss: 2.516818961232416

Epoch: 5| Step: 6
Training loss: 2.5695988090357984
Validation loss: 2.5232608029388475

Epoch: 5| Step: 7
Training loss: 3.291171668453791
Validation loss: 2.5339983567632682

Epoch: 5| Step: 8
Training loss: 3.2419336426407823
Validation loss: 2.5223435024539462

Epoch: 5| Step: 9
Training loss: 2.9163043932495993
Validation loss: 2.5254815865500704

Epoch: 5| Step: 10
Training loss: 2.852529367066714
Validation loss: 2.524292032398437

Epoch: 86| Step: 0
Training loss: 2.816497843571736
Validation loss: 2.5243115600485035

Epoch: 5| Step: 1
Training loss: 2.9348673284591142
Validation loss: 2.542672942695392

Epoch: 5| Step: 2
Training loss: 2.8868789731626223
Validation loss: 2.4909664638082334

Epoch: 5| Step: 3
Training loss: 3.4882912288578574
Validation loss: 2.5409899356539722

Epoch: 5| Step: 4
Training loss: 2.6807065755394834
Validation loss: 2.5335712355630013

Epoch: 5| Step: 5
Training loss: 2.668555177103492
Validation loss: 2.538932663948017

Epoch: 5| Step: 6
Training loss: 2.8533456740008485
Validation loss: 2.527586834142357

Epoch: 5| Step: 7
Training loss: 3.171103848828693
Validation loss: 2.5290581351094654

Epoch: 5| Step: 8
Training loss: 2.2611015676827613
Validation loss: 2.537650140377598

Epoch: 5| Step: 9
Training loss: 2.4925109270749717
Validation loss: 2.532185296506944

Epoch: 5| Step: 10
Training loss: 2.9229479772876026
Validation loss: 2.511042118770303

Epoch: 87| Step: 0
Training loss: 2.7615129321291265
Validation loss: 2.552550791424027

Epoch: 5| Step: 1
Training loss: 3.0599345146602057
Validation loss: 2.524636917748586

Epoch: 5| Step: 2
Training loss: 1.9953500216905977
Validation loss: 2.498454398579477

Epoch: 5| Step: 3
Training loss: 2.597856419243778
Validation loss: 2.5405418262808097

Epoch: 5| Step: 4
Training loss: 3.4185370621278337
Validation loss: 2.5164962326875093

Epoch: 5| Step: 5
Training loss: 2.684338240099776
Validation loss: 2.533421294998465

Epoch: 5| Step: 6
Training loss: 2.859821722436322
Validation loss: 2.5304275704925336

Epoch: 5| Step: 7
Training loss: 2.948194474967933
Validation loss: 2.53494405756697

Epoch: 5| Step: 8
Training loss: 2.9528149638840393
Validation loss: 2.5196732675868523

Epoch: 5| Step: 9
Training loss: 2.148132302541254
Validation loss: 2.5373711012596876

Epoch: 5| Step: 10
Training loss: 3.492106801579135
Validation loss: 2.555270904070152

Epoch: 88| Step: 0
Training loss: 3.486229920273021
Validation loss: 2.53244380127366

Epoch: 5| Step: 1
Training loss: 2.5575536113351593
Validation loss: 2.5014299148847994

Epoch: 5| Step: 2
Training loss: 2.5354075255865243
Validation loss: 2.535336080776672

Epoch: 5| Step: 3
Training loss: 2.4657215906908614
Validation loss: 2.521865284338573

Epoch: 5| Step: 4
Training loss: 2.3175959756312587
Validation loss: 2.5092377094789304

Epoch: 5| Step: 5
Training loss: 3.000984983869977
Validation loss: 2.5202350609923827

Epoch: 5| Step: 6
Training loss: 2.9505726921100894
Validation loss: 2.532877103491983

Epoch: 5| Step: 7
Training loss: 2.7679754926280156
Validation loss: 2.54500503384655

Epoch: 5| Step: 8
Training loss: 3.028670009386436
Validation loss: 2.5183373653111683

Epoch: 5| Step: 9
Training loss: 2.705734757144404
Validation loss: 2.5239545563605517

Epoch: 5| Step: 10
Training loss: 3.09932091565953
Validation loss: 2.5314401246028644

Epoch: 89| Step: 0
Training loss: 2.608740449603685
Validation loss: 2.5312070001018365

Epoch: 5| Step: 1
Training loss: 2.8667939874925845
Validation loss: 2.54416274471541

Epoch: 5| Step: 2
Training loss: 2.1536057332805707
Validation loss: 2.505039019966129

Epoch: 5| Step: 3
Training loss: 2.933538322077482
Validation loss: 2.5508510250465593

Epoch: 5| Step: 4
Training loss: 3.4444612242860786
Validation loss: 2.525439596191856

Epoch: 5| Step: 5
Training loss: 2.7645942793176435
Validation loss: 2.51804714119989

Epoch: 5| Step: 6
Training loss: 2.976818163847976
Validation loss: 2.532228277514695

Epoch: 5| Step: 7
Training loss: 3.2692087759598634
Validation loss: 2.5486879170556613

Epoch: 5| Step: 8
Training loss: 2.296793099325052
Validation loss: 2.545664099002359

Epoch: 5| Step: 9
Training loss: 2.433922612241225
Validation loss: 2.5108432212508474

Epoch: 5| Step: 10
Training loss: 3.153831990945589
Validation loss: 2.5466371786707898

Epoch: 90| Step: 0
Training loss: 2.5383341991834696
Validation loss: 2.518417541894628

Epoch: 5| Step: 1
Training loss: 1.997948249776758
Validation loss: 2.521548300385907

Epoch: 5| Step: 2
Training loss: 2.4379799199204455
Validation loss: 2.4953476193474957

Epoch: 5| Step: 3
Training loss: 3.0197951187968495
Validation loss: 2.5156534384799802

Epoch: 5| Step: 4
Training loss: 2.6338743338184636
Validation loss: 2.528810350113004

Epoch: 5| Step: 5
Training loss: 2.735937315256231
Validation loss: 2.5493759839454744

Epoch: 5| Step: 6
Training loss: 2.802142505422774
Validation loss: 2.535077772846093

Epoch: 5| Step: 7
Training loss: 3.6109388522282195
Validation loss: 2.5178495118094864

Epoch: 5| Step: 8
Training loss: 2.474968237624919
Validation loss: 2.5436231159590257

Epoch: 5| Step: 9
Training loss: 3.098408284244351
Validation loss: 2.5287427132893723

Epoch: 5| Step: 10
Training loss: 3.2487419334390735
Validation loss: 2.5533178186996164

Epoch: 91| Step: 0
Training loss: 3.2031063916666036
Validation loss: 2.5151972151237274

Epoch: 5| Step: 1
Training loss: 2.2233652817557763
Validation loss: 2.5170191465497784

Epoch: 5| Step: 2
Training loss: 2.9255377511532563
Validation loss: 2.52576042176779

Epoch: 5| Step: 3
Training loss: 2.8969839723701325
Validation loss: 2.5416716335684506

Epoch: 5| Step: 4
Training loss: 2.9059320091280187
Validation loss: 2.5499754634885536

Epoch: 5| Step: 5
Training loss: 2.6337430763968346
Validation loss: 2.5274017221334764

Epoch: 5| Step: 6
Training loss: 2.3778479716773133
Validation loss: 2.5021733158790114

Epoch: 5| Step: 7
Training loss: 2.9285331384634548
Validation loss: 2.5428187601711194

Epoch: 5| Step: 8
Training loss: 2.6716422710229013
Validation loss: 2.55545319071586

Epoch: 5| Step: 9
Training loss: 3.2917869320560054
Validation loss: 2.5320141640351395

Epoch: 5| Step: 10
Training loss: 2.8647242470963685
Validation loss: 2.537631272523608

Epoch: 92| Step: 0
Training loss: 2.959544959016659
Validation loss: 2.5227063396432907

Epoch: 5| Step: 1
Training loss: 2.9212580554803753
Validation loss: 2.5558797655691476

Epoch: 5| Step: 2
Training loss: 2.8380168091247295
Validation loss: 2.502941860752413

Epoch: 5| Step: 3
Training loss: 2.0881380625056183
Validation loss: 2.5495162867815875

Epoch: 5| Step: 4
Training loss: 2.838122154289857
Validation loss: 2.540260548997242

Epoch: 5| Step: 5
Training loss: 2.781761036760204
Validation loss: 2.5566491783405936

Epoch: 5| Step: 6
Training loss: 2.4492385109038843
Validation loss: 2.520388162618707

Epoch: 5| Step: 7
Training loss: 3.1536992407428475
Validation loss: 2.5591044334872404

Epoch: 5| Step: 8
Training loss: 3.461024022796859
Validation loss: 2.5379935206108475

Epoch: 5| Step: 9
Training loss: 3.014329859462622
Validation loss: 2.546584948721353

Epoch: 5| Step: 10
Training loss: 1.9258144290688968
Validation loss: 2.520464822845845

Epoch: 93| Step: 0
Training loss: 2.7210083274783976
Validation loss: 2.5204704282435886

Epoch: 5| Step: 1
Training loss: 2.886463696022701
Validation loss: 2.5162478866671383

Epoch: 5| Step: 2
Training loss: 2.756896907120039
Validation loss: 2.503953772871324

Epoch: 5| Step: 3
Training loss: 2.5831045439118085
Validation loss: 2.496365559229018

Epoch: 5| Step: 4
Training loss: 3.261224437421901
Validation loss: 2.5383966317127657

Epoch: 5| Step: 5
Training loss: 2.8469349558574923
Validation loss: 2.5679713518460643

Epoch: 5| Step: 6
Training loss: 2.3344395149845054
Validation loss: 2.5200682919642694

Epoch: 5| Step: 7
Training loss: 2.830742736241098
Validation loss: 2.5177665618353036

Epoch: 5| Step: 8
Training loss: 2.6660084706863714
Validation loss: 2.5210195350744464

Epoch: 5| Step: 9
Training loss: 3.1626573244549765
Validation loss: 2.534777691924792

Epoch: 5| Step: 10
Training loss: 2.8199485480572486
Validation loss: 2.536633882000122

Epoch: 94| Step: 0
Training loss: 2.624595974301628
Validation loss: 2.4965956951273887

Epoch: 5| Step: 1
Training loss: 2.6823715247454327
Validation loss: 2.531597462511557

Epoch: 5| Step: 2
Training loss: 3.022917315857439
Validation loss: 2.5184225522737433

Epoch: 5| Step: 3
Training loss: 2.2797235058561545
Validation loss: 2.5316056265414963

Epoch: 5| Step: 4
Training loss: 3.469510381713587
Validation loss: 2.548603078823489

Epoch: 5| Step: 5
Training loss: 2.9909502862990394
Validation loss: 2.5403670248325985

Epoch: 5| Step: 6
Training loss: 3.212039210896091
Validation loss: 2.544451011687691

Epoch: 5| Step: 7
Training loss: 2.399480040174496
Validation loss: 2.508212752001252

Epoch: 5| Step: 8
Training loss: 2.8440501295733815
Validation loss: 2.5482616493633583

Epoch: 5| Step: 9
Training loss: 2.759092817210163
Validation loss: 2.530704636530007

Epoch: 5| Step: 10
Training loss: 2.366844530093299
Validation loss: 2.5083528277192513

Epoch: 95| Step: 0
Training loss: 2.6864328261652646
Validation loss: 2.5452400282965377

Epoch: 5| Step: 1
Training loss: 2.2776513129175116
Validation loss: 2.534810689214941

Epoch: 5| Step: 2
Training loss: 2.8445379821312122
Validation loss: 2.55069374658391

Epoch: 5| Step: 3
Training loss: 2.576907245990289
Validation loss: 2.524873261635213

Epoch: 5| Step: 4
Training loss: 3.3555831445594175
Validation loss: 2.549062167596165

Epoch: 5| Step: 5
Training loss: 2.5487695679935407
Validation loss: 2.5117819124628906

Epoch: 5| Step: 6
Training loss: 3.0135797868504937
Validation loss: 2.5291932983450525

Epoch: 5| Step: 7
Training loss: 2.755229226353444
Validation loss: 2.533354576676984

Epoch: 5| Step: 8
Training loss: 2.3334948165963496
Validation loss: 2.52132991237819

Epoch: 5| Step: 9
Training loss: 3.0496703798376603
Validation loss: 2.5177400676077135

Epoch: 5| Step: 10
Training loss: 3.156940649026302
Validation loss: 2.5264723990394122

Epoch: 96| Step: 0
Training loss: 2.0965480043504603
Validation loss: 2.513432444500835

Epoch: 5| Step: 1
Training loss: 2.7391596322645806
Validation loss: 2.5354028955926986

Epoch: 5| Step: 2
Training loss: 2.3345308182888758
Validation loss: 2.5185652329376325

Epoch: 5| Step: 3
Training loss: 2.95235049470816
Validation loss: 2.517291498990925

Epoch: 5| Step: 4
Training loss: 2.6815292213010027
Validation loss: 2.516890589430791

Epoch: 5| Step: 5
Training loss: 2.4375608387714967
Validation loss: 2.536398307509647

Epoch: 5| Step: 6
Training loss: 3.1375047356923145
Validation loss: 2.5411219491422936

Epoch: 5| Step: 7
Training loss: 3.4533800402051615
Validation loss: 2.549595279775585

Epoch: 5| Step: 8
Training loss: 2.5909520880311825
Validation loss: 2.5131283238434086

Epoch: 5| Step: 9
Training loss: 3.1292686300177994
Validation loss: 2.5334769474064216

Epoch: 5| Step: 10
Training loss: 2.9887800211816606
Validation loss: 2.508738175212171

Epoch: 97| Step: 0
Training loss: 2.671558740648674
Validation loss: 2.5334494750202805

Epoch: 5| Step: 1
Training loss: 2.6431110123908947
Validation loss: 2.528799638053815

Epoch: 5| Step: 2
Training loss: 2.3879270601043623
Validation loss: 2.50278187480715

Epoch: 5| Step: 3
Training loss: 2.966444706560788
Validation loss: 2.5757191151386354

Epoch: 5| Step: 4
Training loss: 2.68815941815847
Validation loss: 2.5296937196055884

Epoch: 5| Step: 5
Training loss: 3.3902424539381215
Validation loss: 2.5188079581817275

Epoch: 5| Step: 6
Training loss: 3.027880181808016
Validation loss: 2.536670736985216

Epoch: 5| Step: 7
Training loss: 2.50486863041185
Validation loss: 2.518024711191544

Epoch: 5| Step: 8
Training loss: 3.3696560407385414
Validation loss: 2.511505669587977

Epoch: 5| Step: 9
Training loss: 2.448232741274906
Validation loss: 2.5130063435203027

Epoch: 5| Step: 10
Training loss: 2.7014253598071845
Validation loss: 2.5304894012914487

Epoch: 98| Step: 0
Training loss: 3.2690881499515
Validation loss: 2.5691728386470167

Epoch: 5| Step: 1
Training loss: 2.952136323319091
Validation loss: 2.5084269420063032

Epoch: 5| Step: 2
Training loss: 2.8195998541015985
Validation loss: 2.5327402475763847

Epoch: 5| Step: 3
Training loss: 2.1739891246253413
Validation loss: 2.5201099771177353

Epoch: 5| Step: 4
Training loss: 3.0590745102286836
Validation loss: 2.484465973201568

Epoch: 5| Step: 5
Training loss: 3.0549093102512654
Validation loss: 2.539238392280456

Epoch: 5| Step: 6
Training loss: 2.5139528012332715
Validation loss: 2.549094696871642

Epoch: 5| Step: 7
Training loss: 2.8002088911609726
Validation loss: 2.5445933028310077

Epoch: 5| Step: 8
Training loss: 2.6643958456506716
Validation loss: 2.5209843112281187

Epoch: 5| Step: 9
Training loss: 2.242559422074618
Validation loss: 2.5206881960772844

Epoch: 5| Step: 10
Training loss: 3.132724827326843
Validation loss: 2.5429947354012756

Epoch: 99| Step: 0
Training loss: 2.8856151159099457
Validation loss: 2.49909335585606

Epoch: 5| Step: 1
Training loss: 2.5817261485304477
Validation loss: 2.5270916746394274

Epoch: 5| Step: 2
Training loss: 2.8701176859156594
Validation loss: 2.537978090195806

Epoch: 5| Step: 3
Training loss: 2.9600553381103016
Validation loss: 2.535295604568828

Epoch: 5| Step: 4
Training loss: 2.5387006765933817
Validation loss: 2.536857296835766

Epoch: 5| Step: 5
Training loss: 2.5317738308889135
Validation loss: 2.548154627115281

Epoch: 5| Step: 6
Training loss: 2.540078203544302
Validation loss: 2.5201919364788616

Epoch: 5| Step: 7
Training loss: 3.2279696963564732
Validation loss: 2.546504282788555

Epoch: 5| Step: 8
Training loss: 3.686502871424422
Validation loss: 2.5107118370660912

Epoch: 5| Step: 9
Training loss: 1.782169372477104
Validation loss: 2.508343800010616

Epoch: 5| Step: 10
Training loss: 2.8519046107921664
Validation loss: 2.552093683305103

Epoch: 100| Step: 0
Training loss: 2.79387781247652
Validation loss: 2.523262269030802

Epoch: 5| Step: 1
Training loss: 2.469658986076281
Validation loss: 2.503236463061504

Epoch: 5| Step: 2
Training loss: 2.842998363385717
Validation loss: 2.5158112842373335

Epoch: 5| Step: 3
Training loss: 2.3351974080384035
Validation loss: 2.533358401863705

Epoch: 5| Step: 4
Training loss: 2.790156729476451
Validation loss: 2.5303955955439443

Epoch: 5| Step: 5
Training loss: 3.174029741192359
Validation loss: 2.4980656487805115

Epoch: 5| Step: 6
Training loss: 2.650561445967876
Validation loss: 2.5427012394750106

Epoch: 5| Step: 7
Training loss: 3.164683791962918
Validation loss: 2.5338891310057914

Epoch: 5| Step: 8
Training loss: 3.0649259651041856
Validation loss: 2.538486333430457

Epoch: 5| Step: 9
Training loss: 3.0293463008741863
Validation loss: 2.5051193381818155

Epoch: 5| Step: 10
Training loss: 2.427845934685387
Validation loss: 2.553125473984162

Epoch: 101| Step: 0
Training loss: 2.9751097971425713
Validation loss: 2.533300712779675

Epoch: 5| Step: 1
Training loss: 2.6135445363796914
Validation loss: 2.5255478723378926

Epoch: 5| Step: 2
Training loss: 2.5435732168492136
Validation loss: 2.5235093659987395

Epoch: 5| Step: 3
Training loss: 2.435464057646186
Validation loss: 2.512729656768037

Epoch: 5| Step: 4
Training loss: 2.611410112598954
Validation loss: 2.526297198962822

Epoch: 5| Step: 5
Training loss: 2.930373943018681
Validation loss: 2.5088671766375175

Epoch: 5| Step: 6
Training loss: 2.811660302167592
Validation loss: 2.505830018165502

Epoch: 5| Step: 7
Training loss: 2.9032046862486887
Validation loss: 2.515147049689906

Epoch: 5| Step: 8
Training loss: 3.060715447355833
Validation loss: 2.4949163489268487

Epoch: 5| Step: 9
Training loss: 3.4606674467862546
Validation loss: 2.511647763310717

Epoch: 5| Step: 10
Training loss: 2.054315685672815
Validation loss: 2.5017088361696973

Epoch: 102| Step: 0
Training loss: 3.3398458915837432
Validation loss: 2.541377563683865

Epoch: 5| Step: 1
Training loss: 2.591779212920227
Validation loss: 2.528912140036461

Epoch: 5| Step: 2
Training loss: 2.7013337479177135
Validation loss: 2.5385418202637666

Epoch: 5| Step: 3
Training loss: 2.7322482312252836
Validation loss: 2.514074272684404

Epoch: 5| Step: 4
Training loss: 2.807993096438233
Validation loss: 2.5194274133079166

Epoch: 5| Step: 5
Training loss: 3.053479358174196
Validation loss: 2.536030461229358

Epoch: 5| Step: 6
Training loss: 2.888897023637844
Validation loss: 2.54786748853657

Epoch: 5| Step: 7
Training loss: 2.821077533634116
Validation loss: 2.517191590761278

Epoch: 5| Step: 8
Training loss: 2.224707757852505
Validation loss: 2.496869368696138

Epoch: 5| Step: 9
Training loss: 3.0235974173429714
Validation loss: 2.525984174156379

Epoch: 5| Step: 10
Training loss: 2.4088719932652594
Validation loss: 2.5280523111273983

Epoch: 103| Step: 0
Training loss: 2.73208356484866
Validation loss: 2.4941354034387415

Epoch: 5| Step: 1
Training loss: 2.739669556705287
Validation loss: 2.550607747830872

Epoch: 5| Step: 2
Training loss: 2.3030385470889194
Validation loss: 2.5263296443757053

Epoch: 5| Step: 3
Training loss: 2.5785974243115692
Validation loss: 2.5515810460694137

Epoch: 5| Step: 4
Training loss: 3.308509870634651
Validation loss: 2.5114520230546624

Epoch: 5| Step: 5
Training loss: 2.8080914171504414
Validation loss: 2.5401886745031774

Epoch: 5| Step: 6
Training loss: 2.9446858920862438
Validation loss: 2.5281581451248236

Epoch: 5| Step: 7
Training loss: 2.9312458420583685
Validation loss: 2.540783557420088

Epoch: 5| Step: 8
Training loss: 2.907675608795432
Validation loss: 2.533849911557134

Epoch: 5| Step: 9
Training loss: 2.951995633657064
Validation loss: 2.5009869565446365

Epoch: 5| Step: 10
Training loss: 2.4554809142784517
Validation loss: 2.4989710956770406

Epoch: 104| Step: 0
Training loss: 3.2067264314449915
Validation loss: 2.5240440745717434

Epoch: 5| Step: 1
Training loss: 2.3070945454617195
Validation loss: 2.5068544373496633

Epoch: 5| Step: 2
Training loss: 2.806030461956922
Validation loss: 2.5163653392643295

Epoch: 5| Step: 3
Training loss: 2.431711807128313
Validation loss: 2.5386571598787975

Epoch: 5| Step: 4
Training loss: 3.3476922868994565
Validation loss: 2.536542257137764

Epoch: 5| Step: 5
Training loss: 2.884818188311745
Validation loss: 2.5638766528860586

Epoch: 5| Step: 6
Training loss: 2.838583644358233
Validation loss: 2.4906202962676063

Epoch: 5| Step: 7
Training loss: 2.917295079426203
Validation loss: 2.545667733485185

Epoch: 5| Step: 8
Training loss: 2.441980889404151
Validation loss: 2.529443667297464

Epoch: 5| Step: 9
Training loss: 2.9918088349659757
Validation loss: 2.513969782299767

Epoch: 5| Step: 10
Training loss: 2.3240656954594727
Validation loss: 2.5178885436902867

Epoch: 105| Step: 0
Training loss: 1.8427194851253392
Validation loss: 2.534347328522637

Epoch: 5| Step: 1
Training loss: 3.191297176743038
Validation loss: 2.5693728352635796

Epoch: 5| Step: 2
Training loss: 2.862180740343465
Validation loss: 2.5576084830334866

Epoch: 5| Step: 3
Training loss: 2.954187111364586
Validation loss: 2.5282344673389003

Epoch: 5| Step: 4
Training loss: 2.373220781147029
Validation loss: 2.49959158381329

Epoch: 5| Step: 5
Training loss: 3.2108748306878496
Validation loss: 2.5683525086293213

Epoch: 5| Step: 6
Training loss: 2.752773187092241
Validation loss: 2.5098726008702417

Epoch: 5| Step: 7
Training loss: 3.0322437034036454
Validation loss: 2.5190684799211143

Epoch: 5| Step: 8
Training loss: 2.4571737906102538
Validation loss: 2.526556229562502

Epoch: 5| Step: 9
Training loss: 3.2634486196829493
Validation loss: 2.5245827317802796

Epoch: 5| Step: 10
Training loss: 2.1066325126164958
Validation loss: 2.493202908103021

Epoch: 106| Step: 0
Training loss: 2.418145144041728
Validation loss: 2.552866942542322

Epoch: 5| Step: 1
Training loss: 2.8922424739845574
Validation loss: 2.506744819913288

Epoch: 5| Step: 2
Training loss: 2.542007287970179
Validation loss: 2.5059009670965575

Epoch: 5| Step: 3
Training loss: 2.6683156359067994
Validation loss: 2.5311053807105455

Epoch: 5| Step: 4
Training loss: 2.919107360527803
Validation loss: 2.5360302792696623

Epoch: 5| Step: 5
Training loss: 2.7854372714718316
Validation loss: 2.512985827222199

Epoch: 5| Step: 6
Training loss: 2.4806371436442967
Validation loss: 2.524808826436366

Epoch: 5| Step: 7
Training loss: 2.9672259785757085
Validation loss: 2.5334943521305946

Epoch: 5| Step: 8
Training loss: 3.0873130340183406
Validation loss: 2.502602973594448

Epoch: 5| Step: 9
Training loss: 2.7672226596108542
Validation loss: 2.500844806551976

Epoch: 5| Step: 10
Training loss: 3.0145188907114275
Validation loss: 2.504714295608168

Epoch: 107| Step: 0
Training loss: 2.983455496334477
Validation loss: 2.5210029594473427

Epoch: 5| Step: 1
Training loss: 2.73161464325866
Validation loss: 2.5400777867131716

Epoch: 5| Step: 2
Training loss: 2.664201123163247
Validation loss: 2.5255719773981493

Epoch: 5| Step: 3
Training loss: 2.7407545383161436
Validation loss: 2.515854239281481

Epoch: 5| Step: 4
Training loss: 3.0390348849966435
Validation loss: 2.5310009482270903

Epoch: 5| Step: 5
Training loss: 3.153364618911014
Validation loss: 2.506191868425355

Epoch: 5| Step: 6
Training loss: 2.6184099217833814
Validation loss: 2.51624101869312

Epoch: 5| Step: 7
Training loss: 2.834396405964596
Validation loss: 2.5135281944489267

Epoch: 5| Step: 8
Training loss: 2.6073075744493135
Validation loss: 2.520192343374923

Epoch: 5| Step: 9
Training loss: 2.8037688469561584
Validation loss: 2.5078184142880127

Epoch: 5| Step: 10
Training loss: 2.7256174280472134
Validation loss: 2.5185209183908035

Epoch: 108| Step: 0
Training loss: 2.608982627743557
Validation loss: 2.5297753735407196

Epoch: 5| Step: 1
Training loss: 2.4704501900854257
Validation loss: 2.502308390958184

Epoch: 5| Step: 2
Training loss: 2.72242181937178
Validation loss: 2.4972055979005043

Epoch: 5| Step: 3
Training loss: 3.241149589139583
Validation loss: 2.50855596352452

Epoch: 5| Step: 4
Training loss: 2.764460604103561
Validation loss: 2.515594982614483

Epoch: 5| Step: 5
Training loss: 3.006703516641989
Validation loss: 2.5371775981372977

Epoch: 5| Step: 6
Training loss: 2.953686534637259
Validation loss: 2.5005148613833854

Epoch: 5| Step: 7
Training loss: 3.0801186858259886
Validation loss: 2.5017723784202657

Epoch: 5| Step: 8
Training loss: 2.917628665496026
Validation loss: 2.520732010795235

Epoch: 5| Step: 9
Training loss: 2.2074613709056217
Validation loss: 2.5409740860681067

Epoch: 5| Step: 10
Training loss: 2.5911075966216663
Validation loss: 2.501106050352155

Epoch: 109| Step: 0
Training loss: 2.3508999420252983
Validation loss: 2.5101552309803274

Epoch: 5| Step: 1
Training loss: 2.4076528051890023
Validation loss: 2.535113655381085

Epoch: 5| Step: 2
Training loss: 2.6495816170409485
Validation loss: 2.5392546509888727

Epoch: 5| Step: 3
Training loss: 2.9963124181733463
Validation loss: 2.526768434941926

Epoch: 5| Step: 4
Training loss: 3.216302181670111
Validation loss: 2.5302145189657095

Epoch: 5| Step: 5
Training loss: 2.8279165960420265
Validation loss: 2.5312952523470016

Epoch: 5| Step: 6
Training loss: 2.0338782106770057
Validation loss: 2.5318568646785686

Epoch: 5| Step: 7
Training loss: 3.2379387282099086
Validation loss: 2.564830711525789

Epoch: 5| Step: 8
Training loss: 3.625293325198057
Validation loss: 2.5341712404135173

Epoch: 5| Step: 9
Training loss: 2.3271028463785806
Validation loss: 2.5319782831376902

Epoch: 5| Step: 10
Training loss: 2.692825275491329
Validation loss: 2.5032992542709707

Epoch: 110| Step: 0
Training loss: 3.200554835379713
Validation loss: 2.5398699369050903

Epoch: 5| Step: 1
Training loss: 2.959294731558102
Validation loss: 2.504347061272492

Epoch: 5| Step: 2
Training loss: 2.7554546359084404
Validation loss: 2.5309274038216083

Epoch: 5| Step: 3
Training loss: 2.369656524717348
Validation loss: 2.548413922309005

Epoch: 5| Step: 4
Training loss: 2.6639018527729723
Validation loss: 2.5344178867819576

Epoch: 5| Step: 5
Training loss: 2.9572195902702467
Validation loss: 2.5215489714032313

Epoch: 5| Step: 6
Training loss: 3.197938171380684
Validation loss: 2.542833296191387

Epoch: 5| Step: 7
Training loss: 2.9271777987367766
Validation loss: 2.5412075919873973

Epoch: 5| Step: 8
Training loss: 2.5675638917812553
Validation loss: 2.5469606255419186

Epoch: 5| Step: 9
Training loss: 2.136561637276775
Validation loss: 2.4966062758141954

Epoch: 5| Step: 10
Training loss: 2.6675571107336915
Validation loss: 2.5361836312810193

Epoch: 111| Step: 0
Training loss: 2.025426998565926
Validation loss: 2.5465373667207127

Epoch: 5| Step: 1
Training loss: 2.1984271018752297
Validation loss: 2.4980485447212377

Epoch: 5| Step: 2
Training loss: 2.699590853314456
Validation loss: 2.487862628243814

Epoch: 5| Step: 3
Training loss: 2.574091860432495
Validation loss: 2.5624729078027695

Epoch: 5| Step: 4
Training loss: 3.0884875613915166
Validation loss: 2.521286604248283

Epoch: 5| Step: 5
Training loss: 2.826833018890046
Validation loss: 2.5504620690986846

Epoch: 5| Step: 6
Training loss: 2.738142458980428
Validation loss: 2.498056096424403

Epoch: 5| Step: 7
Training loss: 2.7805183391216635
Validation loss: 2.494613486615961

Epoch: 5| Step: 8
Training loss: 3.241105600032045
Validation loss: 2.533205163198245

Epoch: 5| Step: 9
Training loss: 2.957178633732118
Validation loss: 2.5106880723099563

Epoch: 5| Step: 10
Training loss: 3.180339474581917
Validation loss: 2.531222563199524

Epoch: 112| Step: 0
Training loss: 2.471374179342349
Validation loss: 2.5514774516591827

Epoch: 5| Step: 1
Training loss: 2.685558682502452
Validation loss: 2.520757874556339

Epoch: 5| Step: 2
Training loss: 2.7972988894311497
Validation loss: 2.510419984887732

Epoch: 5| Step: 3
Training loss: 2.899595291574228
Validation loss: 2.5351036682293318

Epoch: 5| Step: 4
Training loss: 2.5900816196851517
Validation loss: 2.5371478195768193

Epoch: 5| Step: 5
Training loss: 3.4230740332034877
Validation loss: 2.518326325192391

Epoch: 5| Step: 6
Training loss: 2.1759222728016203
Validation loss: 2.5036905008348387

Epoch: 5| Step: 7
Training loss: 2.4974109594837044
Validation loss: 2.517116478752137

Epoch: 5| Step: 8
Training loss: 3.3321053786266215
Validation loss: 2.4807644895857477

Epoch: 5| Step: 9
Training loss: 2.628532122309232
Validation loss: 2.510605008257956

Epoch: 5| Step: 10
Training loss: 3.0489371339516906
Validation loss: 2.5173917820898075

Epoch: 113| Step: 0
Training loss: 2.7917119112666
Validation loss: 2.5225283220101793

Epoch: 5| Step: 1
Training loss: 2.9184037258417206
Validation loss: 2.531910696515334

Epoch: 5| Step: 2
Training loss: 2.32010040855169
Validation loss: 2.5211218581769486

Epoch: 5| Step: 3
Training loss: 2.34779507294809
Validation loss: 2.5101520822869965

Epoch: 5| Step: 4
Training loss: 2.189771617146411
Validation loss: 2.4814266345814304

Epoch: 5| Step: 5
Training loss: 3.2630847742991134
Validation loss: 2.5206010820478215

Epoch: 5| Step: 6
Training loss: 2.9194306129380374
Validation loss: 2.5485640968705243

Epoch: 5| Step: 7
Training loss: 3.09383245801373
Validation loss: 2.5652954516628954

Epoch: 5| Step: 8
Training loss: 2.6544328644914503
Validation loss: 2.5206818914386546

Epoch: 5| Step: 9
Training loss: 2.5303730328539085
Validation loss: 2.5183375739989775

Epoch: 5| Step: 10
Training loss: 3.3030387065951294
Validation loss: 2.500778934175926

Epoch: 114| Step: 0
Training loss: 2.181145949191013
Validation loss: 2.533900975435134

Epoch: 5| Step: 1
Training loss: 2.5714866484032655
Validation loss: 2.551608004743626

Epoch: 5| Step: 2
Training loss: 2.817865805653178
Validation loss: 2.4943792551299495

Epoch: 5| Step: 3
Training loss: 2.8623495004061934
Validation loss: 2.538411823257919

Epoch: 5| Step: 4
Training loss: 2.1606835382248732
Validation loss: 2.5223342026281945

Epoch: 5| Step: 5
Training loss: 2.7099276813837814
Validation loss: 2.5309850892653576

Epoch: 5| Step: 6
Training loss: 2.5362923402669164
Validation loss: 2.5419825480826272

Epoch: 5| Step: 7
Training loss: 2.8150422368514416
Validation loss: 2.5069025854062414

Epoch: 5| Step: 8
Training loss: 3.490333833221972
Validation loss: 2.5000134949678823

Epoch: 5| Step: 9
Training loss: 2.984758442317297
Validation loss: 2.5322295551695158

Epoch: 5| Step: 10
Training loss: 3.345756997979137
Validation loss: 2.5279116100615373

Epoch: 115| Step: 0
Training loss: 1.95824037155381
Validation loss: 2.5169859078670225

Epoch: 5| Step: 1
Training loss: 2.7115098860171973
Validation loss: 2.5320336179555176

Epoch: 5| Step: 2
Training loss: 2.6649859217975065
Validation loss: 2.5127464828598085

Epoch: 5| Step: 3
Training loss: 2.832660052768129
Validation loss: 2.5431650815996547

Epoch: 5| Step: 4
Training loss: 2.6853890223494585
Validation loss: 2.542738790913981

Epoch: 5| Step: 5
Training loss: 3.0012549318704433
Validation loss: 2.5376902173696743

Epoch: 5| Step: 6
Training loss: 2.312531342165138
Validation loss: 2.523102283197861

Epoch: 5| Step: 7
Training loss: 2.95578125671106
Validation loss: 2.511089538242643

Epoch: 5| Step: 8
Training loss: 3.0178804017796663
Validation loss: 2.5315196294881357

Epoch: 5| Step: 9
Training loss: 3.1888172195509403
Validation loss: 2.5350751627644783

Epoch: 5| Step: 10
Training loss: 3.0756393698325817
Validation loss: 2.5317162687281516

Epoch: 116| Step: 0
Training loss: 2.4923330999910576
Validation loss: 2.51777764870095

Epoch: 5| Step: 1
Training loss: 3.134991199779175
Validation loss: 2.534899491319197

Epoch: 5| Step: 2
Training loss: 2.9530048648679186
Validation loss: 2.5110026506953513

Epoch: 5| Step: 3
Training loss: 2.4072392399514047
Validation loss: 2.549920178200991

Epoch: 5| Step: 4
Training loss: 2.7747622482589014
Validation loss: 2.529385718652767

Epoch: 5| Step: 5
Training loss: 2.2442749089501848
Validation loss: 2.5334565553937543

Epoch: 5| Step: 6
Training loss: 2.0841841168482125
Validation loss: 2.5470873841472943

Epoch: 5| Step: 7
Training loss: 2.656848077200175
Validation loss: 2.5197749901475888

Epoch: 5| Step: 8
Training loss: 2.992989455041685
Validation loss: 2.51503588448921

Epoch: 5| Step: 9
Training loss: 3.758363425619998
Validation loss: 2.533698372117923

Epoch: 5| Step: 10
Training loss: 2.707119058172967
Validation loss: 2.517100016955698

Epoch: 117| Step: 0
Training loss: 2.4739171289057684
Validation loss: 2.5058361299808958

Epoch: 5| Step: 1
Training loss: 2.239294225677008
Validation loss: 2.508912391271977

Epoch: 5| Step: 2
Training loss: 2.2109398723899596
Validation loss: 2.523764742953796

Epoch: 5| Step: 3
Training loss: 3.099375994236566
Validation loss: 2.542562807548213

Epoch: 5| Step: 4
Training loss: 3.695374050797182
Validation loss: 2.534673562460523

Epoch: 5| Step: 5
Training loss: 2.7432996445445585
Validation loss: 2.5242719937525497

Epoch: 5| Step: 6
Training loss: 2.9574071123719348
Validation loss: 2.5162581116713114

Epoch: 5| Step: 7
Training loss: 2.569041764148162
Validation loss: 2.5203702106796433

Epoch: 5| Step: 8
Training loss: 2.7760816407799744
Validation loss: 2.5258008254520306

Epoch: 5| Step: 9
Training loss: 3.0118651991488994
Validation loss: 2.5123231273242896

Epoch: 5| Step: 10
Training loss: 2.2748001052733
Validation loss: 2.557502269917682

Epoch: 118| Step: 0
Training loss: 2.0294040214735576
Validation loss: 2.530226608567897

Epoch: 5| Step: 1
Training loss: 2.7460831578187435
Validation loss: 2.503509794695357

Epoch: 5| Step: 2
Training loss: 2.457436338669236
Validation loss: 2.514849039230899

Epoch: 5| Step: 3
Training loss: 3.6699469516256746
Validation loss: 2.5460394777178945

Epoch: 5| Step: 4
Training loss: 3.361855660003673
Validation loss: 2.5353294101188255

Epoch: 5| Step: 5
Training loss: 2.318218377958922
Validation loss: 2.5207796985192075

Epoch: 5| Step: 6
Training loss: 2.2959894043016678
Validation loss: 2.503729316229897

Epoch: 5| Step: 7
Training loss: 3.034764405710754
Validation loss: 2.5347667679126946

Epoch: 5| Step: 8
Training loss: 3.0977598464017517
Validation loss: 2.5459177430352042

Epoch: 5| Step: 9
Training loss: 2.3698452674477055
Validation loss: 2.5156680152928463

Epoch: 5| Step: 10
Training loss: 2.7297432171572864
Validation loss: 2.5761496057567648

Epoch: 119| Step: 0
Training loss: 2.2859129606482544
Validation loss: 2.5222933144957107

Epoch: 5| Step: 1
Training loss: 2.3743354469935065
Validation loss: 2.495200094168448

Epoch: 5| Step: 2
Training loss: 2.8654592018877367
Validation loss: 2.5236490711385193

Epoch: 5| Step: 3
Training loss: 2.784789330066819
Validation loss: 2.529826787190849

Epoch: 5| Step: 4
Training loss: 2.7512659280221454
Validation loss: 2.5346095645367512

Epoch: 5| Step: 5
Training loss: 1.9845361118543927
Validation loss: 2.528891406078948

Epoch: 5| Step: 6
Training loss: 3.0018422510225973
Validation loss: 2.514137077200521

Epoch: 5| Step: 7
Training loss: 2.715365704096305
Validation loss: 2.5322774262645282

Epoch: 5| Step: 8
Training loss: 3.129533150076343
Validation loss: 2.5281147400016213

Epoch: 5| Step: 9
Training loss: 3.039422099748479
Validation loss: 2.5260754020492526

Epoch: 5| Step: 10
Training loss: 3.578035445112915
Validation loss: 2.545105110368889

Epoch: 120| Step: 0
Training loss: 3.079658861960962
Validation loss: 2.52296735505456

Epoch: 5| Step: 1
Training loss: 2.7687044402565504
Validation loss: 2.5196130460584496

Epoch: 5| Step: 2
Training loss: 2.8046322447877934
Validation loss: 2.550373967693676

Epoch: 5| Step: 3
Training loss: 2.676157146697858
Validation loss: 2.4970029709505193

Epoch: 5| Step: 4
Training loss: 2.7037703785544975
Validation loss: 2.4849009334776593

Epoch: 5| Step: 5
Training loss: 2.3221534079476154
Validation loss: 2.4913169339928767

Epoch: 5| Step: 6
Training loss: 3.1632627630317716
Validation loss: 2.520022310030263

Epoch: 5| Step: 7
Training loss: 2.795837295082192
Validation loss: 2.5528395432504536

Epoch: 5| Step: 8
Training loss: 3.1634528432231113
Validation loss: 2.5420032670362716

Epoch: 5| Step: 9
Training loss: 2.61262008902045
Validation loss: 2.535117352518414

Epoch: 5| Step: 10
Training loss: 2.1589868839885007
Validation loss: 2.5106468127526753

Epoch: 121| Step: 0
Training loss: 2.468391295822936
Validation loss: 2.4843384279621556

Epoch: 5| Step: 1
Training loss: 3.233452117022705
Validation loss: 2.538744453092133

Epoch: 5| Step: 2
Training loss: 2.5274056334193458
Validation loss: 2.5134715006063293

Epoch: 5| Step: 3
Training loss: 3.0125883160700173
Validation loss: 2.513919626535014

Epoch: 5| Step: 4
Training loss: 2.3259675955577532
Validation loss: 2.541504256776732

Epoch: 5| Step: 5
Training loss: 2.9020115288703265
Validation loss: 2.47951617060464

Epoch: 5| Step: 6
Training loss: 2.9265345990123386
Validation loss: 2.515556661138351

Epoch: 5| Step: 7
Training loss: 2.585572185239749
Validation loss: 2.5709514415348416

Epoch: 5| Step: 8
Training loss: 2.842287463023566
Validation loss: 2.54493437624904

Epoch: 5| Step: 9
Training loss: 2.9104822987442667
Validation loss: 2.512825538068289

Epoch: 5| Step: 10
Training loss: 2.368852791279553
Validation loss: 2.512475586635174

Epoch: 122| Step: 0
Training loss: 2.774576990002207
Validation loss: 2.5366064266235706

Epoch: 5| Step: 1
Training loss: 3.215191698306705
Validation loss: 2.5554057577915286

Epoch: 5| Step: 2
Training loss: 2.5879137491596587
Validation loss: 2.507234403676651

Epoch: 5| Step: 3
Training loss: 2.317214181634515
Validation loss: 2.4871682440773206

Epoch: 5| Step: 4
Training loss: 2.9401779953928444
Validation loss: 2.509990744000704

Epoch: 5| Step: 5
Training loss: 2.1855478567985394
Validation loss: 2.535314947360476

Epoch: 5| Step: 6
Training loss: 2.71044099421998
Validation loss: 2.5474029815119525

Epoch: 5| Step: 7
Training loss: 2.5966927254397203
Validation loss: 2.5401156746677103

Epoch: 5| Step: 8
Training loss: 3.0408958259559644
Validation loss: 2.526292593878427

Epoch: 5| Step: 9
Training loss: 2.9977869772324146
Validation loss: 2.515929313570936

Epoch: 5| Step: 10
Training loss: 2.9443035471891688
Validation loss: 2.5332297115176976

Epoch: 123| Step: 0
Training loss: 3.0698990482792716
Validation loss: 2.557637216481213

Epoch: 5| Step: 1
Training loss: 3.053163270115028
Validation loss: 2.53383370619186

Epoch: 5| Step: 2
Training loss: 2.697740782278598
Validation loss: 2.531188623800087

Epoch: 5| Step: 3
Training loss: 1.8520891430495132
Validation loss: 2.540138532316461

Epoch: 5| Step: 4
Training loss: 2.9264630693366707
Validation loss: 2.5221179908171076

Epoch: 5| Step: 5
Training loss: 2.928841023546846
Validation loss: 2.5188460022093913

Epoch: 5| Step: 6
Training loss: 2.327588115462377
Validation loss: 2.5072622870254464

Epoch: 5| Step: 7
Training loss: 2.8660931486657257
Validation loss: 2.522059087091528

Epoch: 5| Step: 8
Training loss: 2.917717244902873
Validation loss: 2.5095549714526073

Epoch: 5| Step: 9
Training loss: 2.5302058762629644
Validation loss: 2.5142256020756135

Epoch: 5| Step: 10
Training loss: 2.967621116833922
Validation loss: 2.5254080529694107

Epoch: 124| Step: 0
Training loss: 2.367893428479258
Validation loss: 2.519985064048668

Epoch: 5| Step: 1
Training loss: 3.062612414729694
Validation loss: 2.5192579368707557

Epoch: 5| Step: 2
Training loss: 2.9029656997846147
Validation loss: 2.5234575046356054

Epoch: 5| Step: 3
Training loss: 2.2112636797337886
Validation loss: 2.4951248528760703

Epoch: 5| Step: 4
Training loss: 3.0452878290452214
Validation loss: 2.5044411128339163

Epoch: 5| Step: 5
Training loss: 2.8935825373596473
Validation loss: 2.5014737779140703

Epoch: 5| Step: 6
Training loss: 2.7506285729327633
Validation loss: 2.524517726580643

Epoch: 5| Step: 7
Training loss: 2.3749258130181854
Validation loss: 2.5268456462906785

Epoch: 5| Step: 8
Training loss: 2.620815211133865
Validation loss: 2.536160248743643

Epoch: 5| Step: 9
Training loss: 2.506567435008262
Validation loss: 2.5119008843302186

Epoch: 5| Step: 10
Training loss: 3.4709773430289506
Validation loss: 2.5275154390826415

Epoch: 125| Step: 0
Training loss: 2.798755375940868
Validation loss: 2.509480000682329

Epoch: 5| Step: 1
Training loss: 2.665393575123351
Validation loss: 2.517349355347459

Epoch: 5| Step: 2
Training loss: 2.2986467236400894
Validation loss: 2.4946975763909345

Epoch: 5| Step: 3
Training loss: 3.24589367191381
Validation loss: 2.494374202622356

Epoch: 5| Step: 4
Training loss: 2.480534686316055
Validation loss: 2.4983071297126624

Epoch: 5| Step: 5
Training loss: 3.3365670889808317
Validation loss: 2.514600600876687

Epoch: 5| Step: 6
Training loss: 2.0527342588531723
Validation loss: 2.5131333784307346

Epoch: 5| Step: 7
Training loss: 2.047132053687098
Validation loss: 2.5428918054034693

Epoch: 5| Step: 8
Training loss: 2.7384438024315796
Validation loss: 2.5073666356872235

Epoch: 5| Step: 9
Training loss: 2.755511482930575
Validation loss: 2.5206074601177986

Epoch: 5| Step: 10
Training loss: 3.610663906348041
Validation loss: 2.5214737502658755

Epoch: 126| Step: 0
Training loss: 2.3872935700175253
Validation loss: 2.480595535139996

Epoch: 5| Step: 1
Training loss: 2.731640129247506
Validation loss: 2.522261171886616

Epoch: 5| Step: 2
Training loss: 1.8305554006779396
Validation loss: 2.531131447391199

Epoch: 5| Step: 3
Training loss: 2.96708552228985
Validation loss: 2.507704313756688

Epoch: 5| Step: 4
Training loss: 2.5462583953913778
Validation loss: 2.5346437059319564

Epoch: 5| Step: 5
Training loss: 3.0620037377432467
Validation loss: 2.5011005153310597

Epoch: 5| Step: 6
Training loss: 2.2796656711466685
Validation loss: 2.536251845963715

Epoch: 5| Step: 7
Training loss: 3.457064629517524
Validation loss: 2.513563828758428

Epoch: 5| Step: 8
Training loss: 2.572219095120636
Validation loss: 2.5286330288479326

Epoch: 5| Step: 9
Training loss: 2.7872460698674777
Validation loss: 2.5270526165032043

Epoch: 5| Step: 10
Training loss: 3.30360297405249
Validation loss: 2.526063584356406

Epoch: 127| Step: 0
Training loss: 2.6061118731956947
Validation loss: 2.5163121702395976

Epoch: 5| Step: 1
Training loss: 1.9544403529791519
Validation loss: 2.481614186363623

Epoch: 5| Step: 2
Training loss: 2.5971145868239054
Validation loss: 2.491662575703326

Epoch: 5| Step: 3
Training loss: 2.301063507331014
Validation loss: 2.5165925816996593

Epoch: 5| Step: 4
Training loss: 3.0361433351076097
Validation loss: 2.5065523133161025

Epoch: 5| Step: 5
Training loss: 2.8459075456347454
Validation loss: 2.5182880035414628

Epoch: 5| Step: 6
Training loss: 3.339414548902089
Validation loss: 2.5011419897661473

Epoch: 5| Step: 7
Training loss: 3.014393767587735
Validation loss: 2.5181065582233004

Epoch: 5| Step: 8
Training loss: 3.1885508880598206
Validation loss: 2.511443516368004

Epoch: 5| Step: 9
Training loss: 2.725838201555993
Validation loss: 2.540317600162023

Epoch: 5| Step: 10
Training loss: 2.5067429207640703
Validation loss: 2.5402580764466935

Epoch: 128| Step: 0
Training loss: 2.5494441080978696
Validation loss: 2.532683439217486

Epoch: 5| Step: 1
Training loss: 2.8364543181152913
Validation loss: 2.526685321190392

Epoch: 5| Step: 2
Training loss: 2.681572609724444
Validation loss: 2.5227752032814537

Epoch: 5| Step: 3
Training loss: 2.9788064983482982
Validation loss: 2.5250925939967046

Epoch: 5| Step: 4
Training loss: 2.6360360625177885
Validation loss: 2.5249338349086505

Epoch: 5| Step: 5
Training loss: 3.561935781672144
Validation loss: 2.511467758332993

Epoch: 5| Step: 6
Training loss: 3.075264778212719
Validation loss: 2.537767653041746

Epoch: 5| Step: 7
Training loss: 2.192356930178514
Validation loss: 2.5128440443224487

Epoch: 5| Step: 8
Training loss: 2.3125868085084305
Validation loss: 2.502403651695265

Epoch: 5| Step: 9
Training loss: 2.9094102965937583
Validation loss: 2.514969494932144

Epoch: 5| Step: 10
Training loss: 2.5207136351695696
Validation loss: 2.5262526202160474

Epoch: 129| Step: 0
Training loss: 2.598999043504481
Validation loss: 2.5048296126238694

Epoch: 5| Step: 1
Training loss: 2.8989362673114414
Validation loss: 2.522262281293195

Epoch: 5| Step: 2
Training loss: 2.3057014950238623
Validation loss: 2.5309610833668397

Epoch: 5| Step: 3
Training loss: 2.897568071041362
Validation loss: 2.5379612536029237

Epoch: 5| Step: 4
Training loss: 3.071646907561389
Validation loss: 2.499176522474087

Epoch: 5| Step: 5
Training loss: 2.662948420198043
Validation loss: 2.521103682666017

Epoch: 5| Step: 6
Training loss: 3.0458110810252803
Validation loss: 2.505957475178649

Epoch: 5| Step: 7
Training loss: 2.220773660551139
Validation loss: 2.4608961615904996

Epoch: 5| Step: 8
Training loss: 2.437780119621352
Validation loss: 2.530560199831788

Epoch: 5| Step: 9
Training loss: 2.645624157504194
Validation loss: 2.5149001433427234

Epoch: 5| Step: 10
Training loss: 3.1604931702445738
Validation loss: 2.5196531942431304

Epoch: 130| Step: 0
Training loss: 3.0667587563605903
Validation loss: 2.5092358316284447

Epoch: 5| Step: 1
Training loss: 2.2591901226038504
Validation loss: 2.5073738674194352

Epoch: 5| Step: 2
Training loss: 2.910369414644764
Validation loss: 2.5232376968920174

Epoch: 5| Step: 3
Training loss: 2.751751255404211
Validation loss: 2.5494310195849423

Epoch: 5| Step: 4
Training loss: 2.2355025854127764
Validation loss: 2.5315081648164752

Epoch: 5| Step: 5
Training loss: 3.0953717845648487
Validation loss: 2.513970567513255

Epoch: 5| Step: 6
Training loss: 2.7530616709670617
Validation loss: 2.5208290053957345

Epoch: 5| Step: 7
Training loss: 2.71653262511725
Validation loss: 2.5331128657843753

Epoch: 5| Step: 8
Training loss: 2.678639109528467
Validation loss: 2.5077896881267154

Epoch: 5| Step: 9
Training loss: 3.0375511510490254
Validation loss: 2.540383421635978

Epoch: 5| Step: 10
Training loss: 2.677741052798703
Validation loss: 2.5409979610486997

Epoch: 131| Step: 0
Training loss: 2.5081879046622473
Validation loss: 2.533219117829267

Epoch: 5| Step: 1
Training loss: 3.642477718329631
Validation loss: 2.521751367495893

Epoch: 5| Step: 2
Training loss: 2.334790206404499
Validation loss: 2.5217011758857897

Epoch: 5| Step: 3
Training loss: 3.0859612958932225
Validation loss: 2.48551445579957

Epoch: 5| Step: 4
Training loss: 2.450835988409616
Validation loss: 2.513626294163763

Epoch: 5| Step: 5
Training loss: 2.39400587183488
Validation loss: 2.546323034851084

Epoch: 5| Step: 6
Training loss: 2.408786081262598
Validation loss: 2.526956397469261

Epoch: 5| Step: 7
Training loss: 3.015737106532221
Validation loss: 2.509732248371549

Epoch: 5| Step: 8
Training loss: 2.851423202665764
Validation loss: 2.484309386443779

Epoch: 5| Step: 9
Training loss: 2.753965293305447
Validation loss: 2.544384962438285

Epoch: 5| Step: 10
Training loss: 2.6959004078872844
Validation loss: 2.5143360287077323

Epoch: 132| Step: 0
Training loss: 2.7798119588417802
Validation loss: 2.5025843142670383

Epoch: 5| Step: 1
Training loss: 3.0300835006841256
Validation loss: 2.523842914676231

Epoch: 5| Step: 2
Training loss: 3.3440701340343226
Validation loss: 2.554704718073754

Epoch: 5| Step: 3
Training loss: 1.7753614836631328
Validation loss: 2.5331724708673247

Epoch: 5| Step: 4
Training loss: 2.71857978024849
Validation loss: 2.4843754953146697

Epoch: 5| Step: 5
Training loss: 2.6594991222422455
Validation loss: 2.5155914402234445

Epoch: 5| Step: 6
Training loss: 2.2307953870944845
Validation loss: 2.4851140461664896

Epoch: 5| Step: 7
Training loss: 2.3466970607385926
Validation loss: 2.5067720746426017

Epoch: 5| Step: 8
Training loss: 2.849463288482529
Validation loss: 2.512803541979353

Epoch: 5| Step: 9
Training loss: 3.306970407497172
Validation loss: 2.510142265446755

Epoch: 5| Step: 10
Training loss: 2.893003897333668
Validation loss: 2.5141840192147766

Epoch: 133| Step: 0
Training loss: 2.8375461524201255
Validation loss: 2.5553715346321164

Epoch: 5| Step: 1
Training loss: 2.000708097038867
Validation loss: 2.547908726929703

Epoch: 5| Step: 2
Training loss: 2.4059866228500724
Validation loss: 2.532134160569602

Epoch: 5| Step: 3
Training loss: 2.5324773756185897
Validation loss: 2.5242272792019564

Epoch: 5| Step: 4
Training loss: 1.8979798067423579
Validation loss: 2.5023195744872577

Epoch: 5| Step: 5
Training loss: 3.0743780422021154
Validation loss: 2.512961820767831

Epoch: 5| Step: 6
Training loss: 2.4180951555332513
Validation loss: 2.5247550543798725

Epoch: 5| Step: 7
Training loss: 2.7613336059844014
Validation loss: 2.499290107104033

Epoch: 5| Step: 8
Training loss: 3.328948156437266
Validation loss: 2.554250206521538

Epoch: 5| Step: 9
Training loss: 3.2632484366803993
Validation loss: 2.5348685431706612

Epoch: 5| Step: 10
Training loss: 3.426478246513193
Validation loss: 2.503089941041271

Epoch: 134| Step: 0
Training loss: 2.852594559863253
Validation loss: 2.5021065747875277

Epoch: 5| Step: 1
Training loss: 2.6157203319682365
Validation loss: 2.5000113517749614

Epoch: 5| Step: 2
Training loss: 2.4921300038369125
Validation loss: 2.516954874922356

Epoch: 5| Step: 3
Training loss: 2.253084611464571
Validation loss: 2.5194277735202073

Epoch: 5| Step: 4
Training loss: 2.8093141950194696
Validation loss: 2.5125582633611883

Epoch: 5| Step: 5
Training loss: 3.1702305331475156
Validation loss: 2.508567924500835

Epoch: 5| Step: 6
Training loss: 2.555477475157548
Validation loss: 2.498146095759748

Epoch: 5| Step: 7
Training loss: 2.8832709715462626
Validation loss: 2.5322280284630465

Epoch: 5| Step: 8
Training loss: 2.812631731127246
Validation loss: 2.5096727924392317

Epoch: 5| Step: 9
Training loss: 2.963240802065433
Validation loss: 2.525782141099442

Epoch: 5| Step: 10
Training loss: 3.0012369784605326
Validation loss: 2.5251101509304554

Epoch: 135| Step: 0
Training loss: 3.138103022890643
Validation loss: 2.515441402236559

Epoch: 5| Step: 1
Training loss: 2.1961354515325944
Validation loss: 2.515833625965312

Epoch: 5| Step: 2
Training loss: 2.7909315669199897
Validation loss: 2.531634903212821

Epoch: 5| Step: 3
Training loss: 2.3336040362503985
Validation loss: 2.4845065294056865

Epoch: 5| Step: 4
Training loss: 2.8886071662799675
Validation loss: 2.5087035760084575

Epoch: 5| Step: 5
Training loss: 3.3785156024179095
Validation loss: 2.5041513748388637

Epoch: 5| Step: 6
Training loss: 2.50312514477752
Validation loss: 2.532351634037688

Epoch: 5| Step: 7
Training loss: 2.0834606767517942
Validation loss: 2.539492942098297

Epoch: 5| Step: 8
Training loss: 2.967113485512997
Validation loss: 2.513898646039

Epoch: 5| Step: 9
Training loss: 2.6513837332586863
Validation loss: 2.5160464407215586

Epoch: 5| Step: 10
Training loss: 2.98839374405292
Validation loss: 2.53703250228745

Epoch: 136| Step: 0
Training loss: 3.340922506018831
Validation loss: 2.5479118591488086

Epoch: 5| Step: 1
Training loss: 2.5387880147607484
Validation loss: 2.517571033574176

Epoch: 5| Step: 2
Training loss: 2.239651937690755
Validation loss: 2.5398928815507396

Epoch: 5| Step: 3
Training loss: 2.681031004314152
Validation loss: 2.5325819790290853

Epoch: 5| Step: 4
Training loss: 2.821428833559655
Validation loss: 2.5285333649577275

Epoch: 5| Step: 5
Training loss: 2.9751633286721235
Validation loss: 2.550809551807456

Epoch: 5| Step: 6
Training loss: 2.744928712457686
Validation loss: 2.5064612478103587

Epoch: 5| Step: 7
Training loss: 2.8127765095737804
Validation loss: 2.521478701702564

Epoch: 5| Step: 8
Training loss: 2.588554602321384
Validation loss: 2.5337396913768147

Epoch: 5| Step: 9
Training loss: 2.753948065257672
Validation loss: 2.5527957292796875

Epoch: 5| Step: 10
Training loss: 2.442067390949164
Validation loss: 2.5623988099806803

Epoch: 137| Step: 0
Training loss: 2.277858564706796
Validation loss: 2.509008825114528

Epoch: 5| Step: 1
Training loss: 2.99187354290801
Validation loss: 2.520260728445291

Epoch: 5| Step: 2
Training loss: 2.24650811395256
Validation loss: 2.533210690816014

Epoch: 5| Step: 3
Training loss: 3.3452209374602395
Validation loss: 2.512378055252043

Epoch: 5| Step: 4
Training loss: 2.304286495171782
Validation loss: 2.496223201524572

Epoch: 5| Step: 5
Training loss: 2.806811195451889
Validation loss: 2.494155648234177

Epoch: 5| Step: 6
Training loss: 3.231896376752119
Validation loss: 2.508807098330611

Epoch: 5| Step: 7
Training loss: 2.7984377794462625
Validation loss: 2.560040777294083

Epoch: 5| Step: 8
Training loss: 3.1414981975632212
Validation loss: 2.519003090203712

Epoch: 5| Step: 9
Training loss: 2.3929655298603048
Validation loss: 2.5223328732076795

Epoch: 5| Step: 10
Training loss: 2.2668904946646684
Validation loss: 2.5250361562524355

Epoch: 138| Step: 0
Training loss: 2.5643336550796145
Validation loss: 2.4959646759022323

Epoch: 5| Step: 1
Training loss: 2.7260011461273717
Validation loss: 2.5356013599364156

Epoch: 5| Step: 2
Training loss: 2.554141951706395
Validation loss: 2.5380452859579203

Epoch: 5| Step: 3
Training loss: 2.4885821916536086
Validation loss: 2.5116456892460337

Epoch: 5| Step: 4
Training loss: 2.8113448419851736
Validation loss: 2.49987526244026

Epoch: 5| Step: 5
Training loss: 3.1612058200366047
Validation loss: 2.5451130034247744

Epoch: 5| Step: 6
Training loss: 3.249245189165694
Validation loss: 2.4888624600506013

Epoch: 5| Step: 7
Training loss: 2.630259195471764
Validation loss: 2.5244855848747463

Epoch: 5| Step: 8
Training loss: 2.4958667920586572
Validation loss: 2.501597790398279

Epoch: 5| Step: 9
Training loss: 2.3869584832546313
Validation loss: 2.5166422100002053

Epoch: 5| Step: 10
Training loss: 3.1053053710953944
Validation loss: 2.5070309746804793

Epoch: 139| Step: 0
Training loss: 3.097841735905069
Validation loss: 2.499635666787026

Epoch: 5| Step: 1
Training loss: 3.0486044645900776
Validation loss: 2.5114455176136743

Epoch: 5| Step: 2
Training loss: 2.299585105958442
Validation loss: 2.539950838770306

Epoch: 5| Step: 3
Training loss: 2.6723223752265053
Validation loss: 2.5153697913742703

Epoch: 5| Step: 4
Training loss: 2.5730928265476085
Validation loss: 2.4746852654337035

Epoch: 5| Step: 5
Training loss: 2.2254425980195665
Validation loss: 2.5151776605391056

Epoch: 5| Step: 6
Training loss: 2.8031841701356726
Validation loss: 2.508033707672864

Epoch: 5| Step: 7
Training loss: 3.310082615169973
Validation loss: 2.5230283612181674

Epoch: 5| Step: 8
Training loss: 2.286799747868848
Validation loss: 2.522998111839918

Epoch: 5| Step: 9
Training loss: 2.773111071651576
Validation loss: 2.5172850188250937

Epoch: 5| Step: 10
Training loss: 2.859915260179951
Validation loss: 2.482231800189038

Epoch: 140| Step: 0
Training loss: 3.0121272066162628
Validation loss: 2.538089953529147

Epoch: 5| Step: 1
Training loss: 2.7127498318284804
Validation loss: 2.545242966383058

Epoch: 5| Step: 2
Training loss: 2.579290138292448
Validation loss: 2.50386118762318

Epoch: 5| Step: 3
Training loss: 2.4314337339821916
Validation loss: 2.537479300692117

Epoch: 5| Step: 4
Training loss: 3.2128541150091228
Validation loss: 2.5104375280195033

Epoch: 5| Step: 5
Training loss: 1.9502149952452532
Validation loss: 2.491811975987333

Epoch: 5| Step: 6
Training loss: 2.898384032051898
Validation loss: 2.5413333221010257

Epoch: 5| Step: 7
Training loss: 2.8208557620112416
Validation loss: 2.5302492120783038

Epoch: 5| Step: 8
Training loss: 2.9915067929307595
Validation loss: 2.5131834840917264

Epoch: 5| Step: 9
Training loss: 2.7367029362209934
Validation loss: 2.5396077807253645

Epoch: 5| Step: 10
Training loss: 2.4919453566057257
Validation loss: 2.5349195713592096

Epoch: 141| Step: 0
Training loss: 2.642375839622332
Validation loss: 2.4906943463719786

Epoch: 5| Step: 1
Training loss: 2.462908630547288
Validation loss: 2.532736561139926

Epoch: 5| Step: 2
Training loss: 3.037259152757753
Validation loss: 2.528146029406601

Epoch: 5| Step: 3
Training loss: 2.7556619445026946
Validation loss: 2.5218252821783786

Epoch: 5| Step: 4
Training loss: 2.8386286637626386
Validation loss: 2.52395038782676

Epoch: 5| Step: 5
Training loss: 2.530121916898013
Validation loss: 2.5153460583956564

Epoch: 5| Step: 6
Training loss: 2.548867505233377
Validation loss: 2.500689805139737

Epoch: 5| Step: 7
Training loss: 3.3428203680882502
Validation loss: 2.524514587676904

Epoch: 5| Step: 8
Training loss: 2.680389223445012
Validation loss: 2.5549651927610726

Epoch: 5| Step: 9
Training loss: 2.5881795239687326
Validation loss: 2.517209742578752

Epoch: 5| Step: 10
Training loss: 2.3480125829629186
Validation loss: 2.5091801585466826

Epoch: 142| Step: 0
Training loss: 2.231641471137486
Validation loss: 2.5299102405639147

Epoch: 5| Step: 1
Training loss: 3.1293661515354794
Validation loss: 2.511465962791133

Epoch: 5| Step: 2
Training loss: 2.46533778539943
Validation loss: 2.495207828641061

Epoch: 5| Step: 3
Training loss: 3.6289440929135552
Validation loss: 2.5336800935668364

Epoch: 5| Step: 4
Training loss: 2.8552833841381404
Validation loss: 2.5404051224124413

Epoch: 5| Step: 5
Training loss: 3.1373567039320727
Validation loss: 2.4992709552986603

Epoch: 5| Step: 6
Training loss: 2.1858381225595522
Validation loss: 2.525837958270375

Epoch: 5| Step: 7
Training loss: 2.660850759135156
Validation loss: 2.5311295412185673

Epoch: 5| Step: 8
Training loss: 2.359405517380761
Validation loss: 2.5148899179142656

Epoch: 5| Step: 9
Training loss: 2.7080722585191186
Validation loss: 2.523962689247669

Epoch: 5| Step: 10
Training loss: 2.3685926037837266
Validation loss: 2.5376363000250906

Epoch: 143| Step: 0
Training loss: 2.6272802893681875
Validation loss: 2.5287974204141626

Epoch: 5| Step: 1
Training loss: 3.023118586317526
Validation loss: 2.518310103408625

Epoch: 5| Step: 2
Training loss: 2.54885525159176
Validation loss: 2.4845182728745696

Epoch: 5| Step: 3
Training loss: 2.7190011445604605
Validation loss: 2.5232746520382205

Epoch: 5| Step: 4
Training loss: 2.2059102950476848
Validation loss: 2.5340951344353604

Epoch: 5| Step: 5
Training loss: 2.169932203156676
Validation loss: 2.5268921381496283

Epoch: 5| Step: 6
Training loss: 3.050521937252811
Validation loss: 2.497803020087483

Epoch: 5| Step: 7
Training loss: 2.609200294722219
Validation loss: 2.538848877053707

Epoch: 5| Step: 8
Training loss: 2.607238808823962
Validation loss: 2.532895057880686

Epoch: 5| Step: 9
Training loss: 2.69009965648193
Validation loss: 2.51010700539311

Epoch: 5| Step: 10
Training loss: 3.552932876317903
Validation loss: 2.5184468955301225

Epoch: 144| Step: 0
Training loss: 2.3245502652226895
Validation loss: 2.4914595041208933

Epoch: 5| Step: 1
Training loss: 3.30569983594011
Validation loss: 2.4876854983878305

Epoch: 5| Step: 2
Training loss: 2.9375824612345327
Validation loss: 2.4789743311800003

Epoch: 5| Step: 3
Training loss: 2.9300805400415824
Validation loss: 2.526698838001887

Epoch: 5| Step: 4
Training loss: 2.218013265014553
Validation loss: 2.5105873371233067

Epoch: 5| Step: 5
Training loss: 2.457752698011938
Validation loss: 2.481578470342174

Epoch: 5| Step: 6
Training loss: 2.6484464121980857
Validation loss: 2.500796469080245

Epoch: 5| Step: 7
Training loss: 2.9874979825192587
Validation loss: 2.5103170305087734

Epoch: 5| Step: 8
Training loss: 2.992104631277409
Validation loss: 2.5048224646359762

Epoch: 5| Step: 9
Training loss: 2.7449306233295023
Validation loss: 2.540549241583137

Epoch: 5| Step: 10
Training loss: 2.354312442103368
Validation loss: 2.5226360158002374

Epoch: 145| Step: 0
Training loss: 2.090204910016464
Validation loss: 2.511848788393469

Epoch: 5| Step: 1
Training loss: 2.2723578022698945
Validation loss: 2.5280215321707766

Epoch: 5| Step: 2
Training loss: 2.9780991960430345
Validation loss: 2.486166627585285

Epoch: 5| Step: 3
Training loss: 3.2478571943637653
Validation loss: 2.540707724179441

Epoch: 5| Step: 4
Training loss: 2.583669722610587
Validation loss: 2.5284003012903247

Epoch: 5| Step: 5
Training loss: 2.8020631205646347
Validation loss: 2.535753023235422

Epoch: 5| Step: 6
Training loss: 2.5128368778135024
Validation loss: 2.501746957819696

Epoch: 5| Step: 7
Training loss: 2.723501678953709
Validation loss: 2.5106177794313473

Epoch: 5| Step: 8
Training loss: 2.3199045355656738
Validation loss: 2.5149290314060933

Epoch: 5| Step: 9
Training loss: 3.3551867969433253
Validation loss: 2.516509635118218

Epoch: 5| Step: 10
Training loss: 3.035141482127039
Validation loss: 2.536105066131763

Epoch: 146| Step: 0
Training loss: 2.5408344365467124
Validation loss: 2.509692510452248

Epoch: 5| Step: 1
Training loss: 2.7157592108148116
Validation loss: 2.5340384009644707

Epoch: 5| Step: 2
Training loss: 3.1682327480359675
Validation loss: 2.496163827444975

Epoch: 5| Step: 3
Training loss: 2.330624051982577
Validation loss: 2.50943289813994

Epoch: 5| Step: 4
Training loss: 3.0285834155398152
Validation loss: 2.4769028830554762

Epoch: 5| Step: 5
Training loss: 3.070198503469769
Validation loss: 2.5264139185085552

Epoch: 5| Step: 6
Training loss: 2.816327690478551
Validation loss: 2.531902465629218

Epoch: 5| Step: 7
Training loss: 2.3571293735531347
Validation loss: 2.525094576810407

Epoch: 5| Step: 8
Training loss: 3.09461207853682
Validation loss: 2.524925994519548

Epoch: 5| Step: 9
Training loss: 2.3282582289702796
Validation loss: 2.5385424999176935

Epoch: 5| Step: 10
Training loss: 2.091016208784712
Validation loss: 2.4917356688614842

Epoch: 147| Step: 0
Training loss: 3.55086316642652
Validation loss: 2.5332109306629422

Epoch: 5| Step: 1
Training loss: 2.681582834353166
Validation loss: 2.50465083311093

Epoch: 5| Step: 2
Training loss: 2.5250305249474714
Validation loss: 2.540155505864796

Epoch: 5| Step: 3
Training loss: 3.2221297510259093
Validation loss: 2.5111525133724655

Epoch: 5| Step: 4
Training loss: 2.263734857770808
Validation loss: 2.5367231033527204

Epoch: 5| Step: 5
Training loss: 2.826109531561207
Validation loss: 2.538321083178044

Epoch: 5| Step: 6
Training loss: 2.7925988439212084
Validation loss: 2.510670231747116

Epoch: 5| Step: 7
Training loss: 2.613657104651136
Validation loss: 2.543410123011158

Epoch: 5| Step: 8
Training loss: 2.311833775408788
Validation loss: 2.497762597668676

Epoch: 5| Step: 9
Training loss: 2.841166234256403
Validation loss: 2.54910360590547

Epoch: 5| Step: 10
Training loss: 1.7650676286400744
Validation loss: 2.5236469277010265

Epoch: 148| Step: 0
Training loss: 2.4270643198035313
Validation loss: 2.52422712127397

Epoch: 5| Step: 1
Training loss: 2.7462330941542414
Validation loss: 2.535414097958959

Epoch: 5| Step: 2
Training loss: 2.3988861757779127
Validation loss: 2.4979689223034307

Epoch: 5| Step: 3
Training loss: 2.904190810626321
Validation loss: 2.5117748148792676

Epoch: 5| Step: 4
Training loss: 3.058373298349249
Validation loss: 2.507587821350956

Epoch: 5| Step: 5
Training loss: 3.22608984932881
Validation loss: 2.501340723977436

Epoch: 5| Step: 6
Training loss: 2.605676462567002
Validation loss: 2.541757117695567

Epoch: 5| Step: 7
Training loss: 2.2317676403211246
Validation loss: 2.504304823521946

Epoch: 5| Step: 8
Training loss: 3.152074639274136
Validation loss: 2.522825534079963

Epoch: 5| Step: 9
Training loss: 2.5136087049536275
Validation loss: 2.5204972843439246

Epoch: 5| Step: 10
Training loss: 2.657951707462971
Validation loss: 2.5225730539725966

Epoch: 149| Step: 0
Training loss: 2.7977945531659136
Validation loss: 2.5441226527936736

Epoch: 5| Step: 1
Training loss: 2.614690243990956
Validation loss: 2.5329042855306936

Epoch: 5| Step: 2
Training loss: 3.1434231719052557
Validation loss: 2.5276274038744284

Epoch: 5| Step: 3
Training loss: 2.4902451937571364
Validation loss: 2.506940257890331

Epoch: 5| Step: 4
Training loss: 2.669789532142011
Validation loss: 2.5044425275009807

Epoch: 5| Step: 5
Training loss: 2.727185022504461
Validation loss: 2.5371043136144413

Epoch: 5| Step: 6
Training loss: 2.211966015877167
Validation loss: 2.5133712008289684

Epoch: 5| Step: 7
Training loss: 2.8919475107560757
Validation loss: 2.5195715500766918

Epoch: 5| Step: 8
Training loss: 2.993043622678811
Validation loss: 2.5262364432407556

Epoch: 5| Step: 9
Training loss: 2.262760113680142
Validation loss: 2.5222537775242992

Epoch: 5| Step: 10
Training loss: 2.9791928981524265
Validation loss: 2.5225181498624045

Epoch: 150| Step: 0
Training loss: 2.305667164665956
Validation loss: 2.5278795541026513

Epoch: 5| Step: 1
Training loss: 3.076771394952325
Validation loss: 2.5069479714812326

Epoch: 5| Step: 2
Training loss: 2.1316326077593417
Validation loss: 2.524341583465028

Epoch: 5| Step: 3
Training loss: 2.527285638580374
Validation loss: 2.5260425205227155

Epoch: 5| Step: 4
Training loss: 2.986202619072142
Validation loss: 2.5246782654875366

Epoch: 5| Step: 5
Training loss: 2.889415591064349
Validation loss: 2.5549225601364087

Epoch: 5| Step: 6
Training loss: 2.721166742371518
Validation loss: 2.5045298012913855

Epoch: 5| Step: 7
Training loss: 2.7568089547696526
Validation loss: 2.485754712285906

Epoch: 5| Step: 8
Training loss: 2.605543418626459
Validation loss: 2.510166558277454

Epoch: 5| Step: 9
Training loss: 3.379871667084701
Validation loss: 2.541633489914376

Epoch: 5| Step: 10
Training loss: 2.254988861563974
Validation loss: 2.5263555675278226

Epoch: 151| Step: 0
Training loss: 3.038080758041631
Validation loss: 2.559998102515072

Epoch: 5| Step: 1
Training loss: 2.2286207891419423
Validation loss: 2.510294927675598

Epoch: 5| Step: 2
Training loss: 2.749868216391384
Validation loss: 2.5264393334336104

Epoch: 5| Step: 3
Training loss: 2.3978544141530755
Validation loss: 2.5110585426891707

Epoch: 5| Step: 4
Training loss: 2.978808099113673
Validation loss: 2.5542531623468063

Epoch: 5| Step: 5
Training loss: 2.9912146039909784
Validation loss: 2.5294645477412785

Epoch: 5| Step: 6
Training loss: 2.7107533329126374
Validation loss: 2.529613774754734

Epoch: 5| Step: 7
Training loss: 2.8302986685655087
Validation loss: 2.541175096430265

Epoch: 5| Step: 8
Training loss: 2.2859707415987005
Validation loss: 2.498396611565465

Epoch: 5| Step: 9
Training loss: 2.66316910695326
Validation loss: 2.5207465511209417

Epoch: 5| Step: 10
Training loss: 3.0144042078952618
Validation loss: 2.4927326945512855

Epoch: 152| Step: 0
Training loss: 2.7426240144299014
Validation loss: 2.5402957871224188

Epoch: 5| Step: 1
Training loss: 2.8710404371644604
Validation loss: 2.5366398518830926

Epoch: 5| Step: 2
Training loss: 2.4943442265297633
Validation loss: 2.5334501934812605

Epoch: 5| Step: 3
Training loss: 2.876487347202863
Validation loss: 2.4749366726463986

Epoch: 5| Step: 4
Training loss: 2.210989799824499
Validation loss: 2.504369686463007

Epoch: 5| Step: 5
Training loss: 2.5882377420505636
Validation loss: 2.5187193032608968

Epoch: 5| Step: 6
Training loss: 2.8648971848072664
Validation loss: 2.5191352000675713

Epoch: 5| Step: 7
Training loss: 2.8630219429286456
Validation loss: 2.51427455009788

Epoch: 5| Step: 8
Training loss: 2.8015102570955497
Validation loss: 2.5213885758988486

Epoch: 5| Step: 9
Training loss: 2.852463504113131
Validation loss: 2.5429229643995037

Epoch: 5| Step: 10
Training loss: 2.8810313441787017
Validation loss: 2.5370182442631712

Epoch: 153| Step: 0
Training loss: 3.111066808460812
Validation loss: 2.4851672812517007

Epoch: 5| Step: 1
Training loss: 2.8126446156939013
Validation loss: 2.552907995739569

Epoch: 5| Step: 2
Training loss: 3.2118767991054447
Validation loss: 2.5337582467294517

Epoch: 5| Step: 3
Training loss: 2.496776791814705
Validation loss: 2.538846867620641

Epoch: 5| Step: 4
Training loss: 2.3470515076845078
Validation loss: 2.5206641775470326

Epoch: 5| Step: 5
Training loss: 2.8383015848991135
Validation loss: 2.5421177164453654

Epoch: 5| Step: 6
Training loss: 2.357880580113871
Validation loss: 2.5347487175508587

Epoch: 5| Step: 7
Training loss: 3.1720347998443112
Validation loss: 2.5474401607290527

Epoch: 5| Step: 8
Training loss: 1.8284936516901666
Validation loss: 2.5274794841768

Epoch: 5| Step: 9
Training loss: 2.6985668935494598
Validation loss: 2.5109794379747723

Epoch: 5| Step: 10
Training loss: 2.86066995283282
Validation loss: 2.544976088272139

Epoch: 154| Step: 0
Training loss: 2.7243753749762267
Validation loss: 2.55833375898783

Epoch: 5| Step: 1
Training loss: 2.8353353234104777
Validation loss: 2.4932045754129244

Epoch: 5| Step: 2
Training loss: 2.87470492631698
Validation loss: 2.5892761714227426

Epoch: 5| Step: 3
Training loss: 2.5974804811597916
Validation loss: 2.5282254264603465

Epoch: 5| Step: 4
Training loss: 2.792802968473668
Validation loss: 2.5237380252365043

Epoch: 5| Step: 5
Training loss: 1.7460630273356306
Validation loss: 2.558166047329721

Epoch: 5| Step: 6
Training loss: 2.836830187819914
Validation loss: 2.531352055400259

Epoch: 5| Step: 7
Training loss: 3.12840040215969
Validation loss: 2.4924184649930434

Epoch: 5| Step: 8
Training loss: 2.941960458610356
Validation loss: 2.5367602743688424

Epoch: 5| Step: 9
Training loss: 2.711786318645771
Validation loss: 2.519714801573355

Epoch: 5| Step: 10
Training loss: 2.717207460072381
Validation loss: 2.519482713431996

Epoch: 155| Step: 0
Training loss: 3.2158071156823813
Validation loss: 2.5404256503851843

Epoch: 5| Step: 1
Training loss: 2.4131138984051343
Validation loss: 2.508309026727172

Epoch: 5| Step: 2
Training loss: 2.9819524229413097
Validation loss: 2.5281175266158806

Epoch: 5| Step: 3
Training loss: 3.5963978176612246
Validation loss: 2.5355018324436145

Epoch: 5| Step: 4
Training loss: 2.672848708095845
Validation loss: 2.542379165092943

Epoch: 5| Step: 5
Training loss: 2.026377423731676
Validation loss: 2.507098199234603

Epoch: 5| Step: 6
Training loss: 2.5526344378988863
Validation loss: 2.5506835088609563

Epoch: 5| Step: 7
Training loss: 2.319632587936628
Validation loss: 2.5392135910881173

Epoch: 5| Step: 8
Training loss: 2.3021294314456817
Validation loss: 2.5640857341113845

Epoch: 5| Step: 9
Training loss: 3.052014207979381
Validation loss: 2.528654641892167

Epoch: 5| Step: 10
Training loss: 2.3179043690503067
Validation loss: 2.512071491878567

Epoch: 156| Step: 0
Training loss: 2.6390797986581047
Validation loss: 2.5414233256800403

Epoch: 5| Step: 1
Training loss: 2.990937213285889
Validation loss: 2.5190302036537457

Epoch: 5| Step: 2
Training loss: 2.0025645741160605
Validation loss: 2.5481280544619587

Epoch: 5| Step: 3
Training loss: 2.820940872313763
Validation loss: 2.494111925807465

Epoch: 5| Step: 4
Training loss: 2.5784725070602414
Validation loss: 2.5170022634641844

Epoch: 5| Step: 5
Training loss: 2.464042424499356
Validation loss: 2.5401446937942302

Epoch: 5| Step: 6
Training loss: 2.5224839998461794
Validation loss: 2.5170011929896283

Epoch: 5| Step: 7
Training loss: 3.2086180688583363
Validation loss: 2.5077527307137317

Epoch: 5| Step: 8
Training loss: 3.1374512383672712
Validation loss: 2.531300799327095

Epoch: 5| Step: 9
Training loss: 2.2723090133734676
Validation loss: 2.525302114884165

Epoch: 5| Step: 10
Training loss: 2.999575743876042
Validation loss: 2.5252684096097497

Epoch: 157| Step: 0
Training loss: 2.864523666222813
Validation loss: 2.4792342003999406

Epoch: 5| Step: 1
Training loss: 2.443723607225654
Validation loss: 2.5474821537526298

Epoch: 5| Step: 2
Training loss: 2.3179854209513837
Validation loss: 2.5125385688584956

Epoch: 5| Step: 3
Training loss: 2.735232845346392
Validation loss: 2.5442551017571535

Epoch: 5| Step: 4
Training loss: 2.4833032947575417
Validation loss: 2.4949707933569605

Epoch: 5| Step: 5
Training loss: 2.345211336417974
Validation loss: 2.537016899295866

Epoch: 5| Step: 6
Training loss: 3.088050756096636
Validation loss: 2.498555898941504

Epoch: 5| Step: 7
Training loss: 2.9011448146122527
Validation loss: 2.5268717274918786

Epoch: 5| Step: 8
Training loss: 2.2826316516424803
Validation loss: 2.5190302977918604

Epoch: 5| Step: 9
Training loss: 2.6601644059334864
Validation loss: 2.5177469691670264

Epoch: 5| Step: 10
Training loss: 3.488158904148201
Validation loss: 2.5150999085388905

Epoch: 158| Step: 0
Training loss: 2.878945669993855
Validation loss: 2.544121657213747

Epoch: 5| Step: 1
Training loss: 2.81152437030529
Validation loss: 2.5040733449688446

Epoch: 5| Step: 2
Training loss: 2.9737894752964253
Validation loss: 2.5049341342647167

Epoch: 5| Step: 3
Training loss: 2.7913015231183187
Validation loss: 2.5252816040686703

Epoch: 5| Step: 4
Training loss: 2.561668726370717
Validation loss: 2.494831655629133

Epoch: 5| Step: 5
Training loss: 2.488065461723483
Validation loss: 2.4907273718727625

Epoch: 5| Step: 6
Training loss: 1.784886045478259
Validation loss: 2.495172402751644

Epoch: 5| Step: 7
Training loss: 2.446498205568243
Validation loss: 2.51202575137327

Epoch: 5| Step: 8
Training loss: 2.9201292646876698
Validation loss: 2.521943953063801

Epoch: 5| Step: 9
Training loss: 2.5650709327571595
Validation loss: 2.482683073737234

Epoch: 5| Step: 10
Training loss: 3.5025008667339637
Validation loss: 2.5216313704650615

Epoch: 159| Step: 0
Training loss: 2.812361395917377
Validation loss: 2.50578345268147

Epoch: 5| Step: 1
Training loss: 2.7800216533997686
Validation loss: 2.5022866241183985

Epoch: 5| Step: 2
Training loss: 2.194115689220677
Validation loss: 2.4987323428609156

Epoch: 5| Step: 3
Training loss: 2.54036080839006
Validation loss: 2.5429126248209246

Epoch: 5| Step: 4
Training loss: 2.9737439365012466
Validation loss: 2.5235662254468574

Epoch: 5| Step: 5
Training loss: 2.8291374628266714
Validation loss: 2.5285853320845777

Epoch: 5| Step: 6
Training loss: 3.102838594832328
Validation loss: 2.5151518953452894

Epoch: 5| Step: 7
Training loss: 2.681357705680648
Validation loss: 2.532734413246687

Epoch: 5| Step: 8
Training loss: 2.722263915419538
Validation loss: 2.5248366578514774

Epoch: 5| Step: 9
Training loss: 2.455342159473231
Validation loss: 2.5175974552455527

Epoch: 5| Step: 10
Training loss: 2.6288492953293674
Validation loss: 2.507340819879231

Epoch: 160| Step: 0
Training loss: 2.555898023776922
Validation loss: 2.4974067733343506

Epoch: 5| Step: 1
Training loss: 2.9358376202284475
Validation loss: 2.5220029885751853

Epoch: 5| Step: 2
Training loss: 2.752382979924173
Validation loss: 2.5213302946878597

Epoch: 5| Step: 3
Training loss: 2.565749736174438
Validation loss: 2.50558891285399

Epoch: 5| Step: 4
Training loss: 3.0021326114405413
Validation loss: 2.529762467015198

Epoch: 5| Step: 5
Training loss: 2.6276391704081594
Validation loss: 2.531741901802174

Epoch: 5| Step: 6
Training loss: 2.947239900328837
Validation loss: 2.523954287193739

Epoch: 5| Step: 7
Training loss: 2.4695861945455637
Validation loss: 2.5549305332378336

Epoch: 5| Step: 8
Training loss: 2.5854700132691852
Validation loss: 2.499554330827779

Epoch: 5| Step: 9
Training loss: 2.4992684247588497
Validation loss: 2.5151796588136404

Epoch: 5| Step: 10
Training loss: 2.6125246329720495
Validation loss: 2.5425608917965046

Epoch: 161| Step: 0
Training loss: 2.7773032312884727
Validation loss: 2.514313303041044

Epoch: 5| Step: 1
Training loss: 2.838939244602797
Validation loss: 2.523188474678116

Epoch: 5| Step: 2
Training loss: 2.2211029041811443
Validation loss: 2.5166974648751603

Epoch: 5| Step: 3
Training loss: 2.932647755730629
Validation loss: 2.5376417442428316

Epoch: 5| Step: 4
Training loss: 2.2606109910635843
Validation loss: 2.50705439268392

Epoch: 5| Step: 5
Training loss: 3.1756286959822764
Validation loss: 2.5030795316607093

Epoch: 5| Step: 6
Training loss: 3.025770130329103
Validation loss: 2.533908311527396

Epoch: 5| Step: 7
Training loss: 2.6993258906298183
Validation loss: 2.5197162585367883

Epoch: 5| Step: 8
Training loss: 2.4987576258716175
Validation loss: 2.5039213497898145

Epoch: 5| Step: 9
Training loss: 2.394034951881463
Validation loss: 2.5308262682909004

Epoch: 5| Step: 10
Training loss: 2.856835243150425
Validation loss: 2.5081489139792614

Epoch: 162| Step: 0
Training loss: 3.103094918680513
Validation loss: 2.5196588899651013

Epoch: 5| Step: 1
Training loss: 3.147978869938007
Validation loss: 2.5209640845981585

Epoch: 5| Step: 2
Training loss: 2.25679198964674
Validation loss: 2.5289418949401865

Epoch: 5| Step: 3
Training loss: 2.4350887011404483
Validation loss: 2.5249992111498853

Epoch: 5| Step: 4
Training loss: 2.5310448457444275
Validation loss: 2.529683545867996

Epoch: 5| Step: 5
Training loss: 2.483484072451957
Validation loss: 2.5299022919701613

Epoch: 5| Step: 6
Training loss: 2.311146520481932
Validation loss: 2.515685802069637

Epoch: 5| Step: 7
Training loss: 2.73059492133494
Validation loss: 2.5067294313429236

Epoch: 5| Step: 8
Training loss: 2.9197386413034487
Validation loss: 2.515577218634985

Epoch: 5| Step: 9
Training loss: 2.528544828923106
Validation loss: 2.5436424337239742

Epoch: 5| Step: 10
Training loss: 3.045942114797853
Validation loss: 2.5248648890107126

Epoch: 163| Step: 0
Training loss: 2.4713111822787033
Validation loss: 2.5316605593885746

Epoch: 5| Step: 1
Training loss: 2.8161732739978356
Validation loss: 2.5297216199006223

Epoch: 5| Step: 2
Training loss: 3.1081623415580295
Validation loss: 2.5356973075475744

Epoch: 5| Step: 3
Training loss: 2.3325380832061313
Validation loss: 2.526484576562955

Epoch: 5| Step: 4
Training loss: 2.6361761594499606
Validation loss: 2.5298758772072163

Epoch: 5| Step: 5
Training loss: 3.2343754422837105
Validation loss: 2.5375246005661865

Epoch: 5| Step: 6
Training loss: 2.6426161983930387
Validation loss: 2.513291031567509

Epoch: 5| Step: 7
Training loss: 2.5262379887902644
Validation loss: 2.55320645385642

Epoch: 5| Step: 8
Training loss: 2.831892170615119
Validation loss: 2.5388093787802726

Epoch: 5| Step: 9
Training loss: 2.8560190988110423
Validation loss: 2.5222617481885825

Epoch: 5| Step: 10
Training loss: 2.357808685805242
Validation loss: 2.527870604242433

Epoch: 164| Step: 0
Training loss: 2.6361227986816176
Validation loss: 2.5083982274129646

Epoch: 5| Step: 1
Training loss: 2.7529076030342003
Validation loss: 2.5510853624096104

Epoch: 5| Step: 2
Training loss: 2.009320119817295
Validation loss: 2.5406113593417654

Epoch: 5| Step: 3
Training loss: 2.5369186035980222
Validation loss: 2.528254778777557

Epoch: 5| Step: 4
Training loss: 2.418271836126137
Validation loss: 2.5279667387885243

Epoch: 5| Step: 5
Training loss: 3.175053699670066
Validation loss: 2.520999403300139

Epoch: 5| Step: 6
Training loss: 2.507094996596748
Validation loss: 2.53433517057161

Epoch: 5| Step: 7
Training loss: 3.3524606919455504
Validation loss: 2.515376752434776

Epoch: 5| Step: 8
Training loss: 2.538068747086119
Validation loss: 2.509451647523854

Epoch: 5| Step: 9
Training loss: 3.1063786930926343
Validation loss: 2.517707433097134

Epoch: 5| Step: 10
Training loss: 2.5018579254978133
Validation loss: 2.5135481341399712

Epoch: 165| Step: 0
Training loss: 2.982324984612303
Validation loss: 2.5387983499318394

Epoch: 5| Step: 1
Training loss: 3.09097628086928
Validation loss: 2.554541632429267

Epoch: 5| Step: 2
Training loss: 2.920273285710161
Validation loss: 2.4909741692302174

Epoch: 5| Step: 3
Training loss: 2.290540198698872
Validation loss: 2.5153443889455462

Epoch: 5| Step: 4
Training loss: 2.405878013492809
Validation loss: 2.5522582452305467

Epoch: 5| Step: 5
Training loss: 2.8701710158911133
Validation loss: 2.5200839327516955

Epoch: 5| Step: 6
Training loss: 2.8061120286086316
Validation loss: 2.5414894569412327

Epoch: 5| Step: 7
Training loss: 2.3779196611698277
Validation loss: 2.566306481687135

Epoch: 5| Step: 8
Training loss: 2.493712816463121
Validation loss: 2.544578071620944

Epoch: 5| Step: 9
Training loss: 2.3378928685635643
Validation loss: 2.518460081956213

Epoch: 5| Step: 10
Training loss: 3.214885576979574
Validation loss: 2.497523293074146

Epoch: 166| Step: 0
Training loss: 2.6432934883196504
Validation loss: 2.5303588568570157

Epoch: 5| Step: 1
Training loss: 2.8089511946298136
Validation loss: 2.532650716870541

Epoch: 5| Step: 2
Training loss: 3.2155556244034735
Validation loss: 2.548432905992079

Epoch: 5| Step: 3
Training loss: 3.1527754288345826
Validation loss: 2.5342307103385564

Epoch: 5| Step: 4
Training loss: 2.82454129773899
Validation loss: 2.540900365201623

Epoch: 5| Step: 5
Training loss: 2.757156942544757
Validation loss: 2.5242194025950706

Epoch: 5| Step: 6
Training loss: 1.7707794704847382
Validation loss: 2.508152721390403

Epoch: 5| Step: 7
Training loss: 2.6383626602801677
Validation loss: 2.540028436653546

Epoch: 5| Step: 8
Training loss: 2.6377331852091785
Validation loss: 2.5255007152031714

Epoch: 5| Step: 9
Training loss: 2.597216667899201
Validation loss: 2.530360857833375

Epoch: 5| Step: 10
Training loss: 2.5069982805280415
Validation loss: 2.5365895223077506

Epoch: 167| Step: 0
Training loss: 2.8433336225586268
Validation loss: 2.525015072171958

Epoch: 5| Step: 1
Training loss: 2.8601034935319
Validation loss: 2.499654880410724

Epoch: 5| Step: 2
Training loss: 2.0781525344745435
Validation loss: 2.5211329582511004

Epoch: 5| Step: 3
Training loss: 2.0631396139945295
Validation loss: 2.537802238858238

Epoch: 5| Step: 4
Training loss: 3.383968446498787
Validation loss: 2.5320900571709686

Epoch: 5| Step: 5
Training loss: 2.639749235034409
Validation loss: 2.53125477938123

Epoch: 5| Step: 6
Training loss: 2.892917363315392
Validation loss: 2.5222796266974212

Epoch: 5| Step: 7
Training loss: 2.2264031604170085
Validation loss: 2.5122072083021414

Epoch: 5| Step: 8
Training loss: 2.295161535857006
Validation loss: 2.4921788262322937

Epoch: 5| Step: 9
Training loss: 2.955480534295334
Validation loss: 2.538194556931335

Epoch: 5| Step: 10
Training loss: 3.262105258723903
Validation loss: 2.5526584569045347

Epoch: 168| Step: 0
Training loss: 3.095391502700858
Validation loss: 2.5122768689326267

Epoch: 5| Step: 1
Training loss: 2.873247026827462
Validation loss: 2.536607776861803

Epoch: 5| Step: 2
Training loss: 2.329793038078868
Validation loss: 2.5372987922925194

Epoch: 5| Step: 3
Training loss: 2.5962396645558337
Validation loss: 2.5297694958912196

Epoch: 5| Step: 4
Training loss: 3.305306883860647
Validation loss: 2.5184598936373517

Epoch: 5| Step: 5
Training loss: 1.9752974853524339
Validation loss: 2.5168278419114762

Epoch: 5| Step: 6
Training loss: 3.0269950025937504
Validation loss: 2.50781811016586

Epoch: 5| Step: 7
Training loss: 2.3430950012484533
Validation loss: 2.55761022914142

Epoch: 5| Step: 8
Training loss: 2.350716067849694
Validation loss: 2.512732516558621

Epoch: 5| Step: 9
Training loss: 2.4094801190868753
Validation loss: 2.5096144179179203

Epoch: 5| Step: 10
Training loss: 3.1365700730447768
Validation loss: 2.5191882067283196

Epoch: 169| Step: 0
Training loss: 2.7758434766456013
Validation loss: 2.5182533645184155

Epoch: 5| Step: 1
Training loss: 2.577162314345455
Validation loss: 2.5232966533672823

Epoch: 5| Step: 2
Training loss: 2.9132820291024535
Validation loss: 2.5160363381465345

Epoch: 5| Step: 3
Training loss: 2.7388152773106076
Validation loss: 2.5145944716224906

Epoch: 5| Step: 4
Training loss: 2.2569204501971414
Validation loss: 2.533760130688624

Epoch: 5| Step: 5
Training loss: 2.6959068638139887
Validation loss: 2.542409050774678

Epoch: 5| Step: 6
Training loss: 3.51337927405224
Validation loss: 2.568797195743925

Epoch: 5| Step: 7
Training loss: 1.63934552391973
Validation loss: 2.505188003207516

Epoch: 5| Step: 8
Training loss: 2.9396719512090286
Validation loss: 2.5298460451263916

Epoch: 5| Step: 9
Training loss: 2.1789753068257447
Validation loss: 2.534754642315388

Epoch: 5| Step: 10
Training loss: 2.869128160339245
Validation loss: 2.5127090504676

Epoch: 170| Step: 0
Training loss: 2.34570099054727
Validation loss: 2.54180545232966

Epoch: 5| Step: 1
Training loss: 2.522619628640434
Validation loss: 2.533919632803109

Epoch: 5| Step: 2
Training loss: 3.1177145911469486
Validation loss: 2.506184575998582

Epoch: 5| Step: 3
Training loss: 2.822078923052474
Validation loss: 2.493661293567547

Epoch: 5| Step: 4
Training loss: 2.7954979602067356
Validation loss: 2.5233991716464

Epoch: 5| Step: 5
Training loss: 2.299512114816211
Validation loss: 2.5387550822930383

Epoch: 5| Step: 6
Training loss: 2.8128894960061874
Validation loss: 2.5130413915112157

Epoch: 5| Step: 7
Training loss: 2.7260077056887804
Validation loss: 2.5155937423705472

Epoch: 5| Step: 8
Training loss: 2.85800838643813
Validation loss: 2.49276012613694

Epoch: 5| Step: 9
Training loss: 2.2002219695039615
Validation loss: 2.5402999692015698

Epoch: 5| Step: 10
Training loss: 2.730367022844595
Validation loss: 2.5193341878215554

Epoch: 171| Step: 0
Training loss: 2.7631677605875895
Validation loss: 2.507048960781905

Epoch: 5| Step: 1
Training loss: 2.3666602828606846
Validation loss: 2.5191488856155395

Epoch: 5| Step: 2
Training loss: 2.614171354098906
Validation loss: 2.4771779922901915

Epoch: 5| Step: 3
Training loss: 2.4209079903817674
Validation loss: 2.516305686532919

Epoch: 5| Step: 4
Training loss: 2.7406986030951694
Validation loss: 2.5374450721697945

Epoch: 5| Step: 5
Training loss: 3.2216403169009933
Validation loss: 2.4997379760430034

Epoch: 5| Step: 6
Training loss: 2.0167136394400216
Validation loss: 2.515880940861277

Epoch: 5| Step: 7
Training loss: 3.0008945720779745
Validation loss: 2.5266141908476594

Epoch: 5| Step: 8
Training loss: 2.720133374674721
Validation loss: 2.533487509659692

Epoch: 5| Step: 9
Training loss: 2.626635813781992
Validation loss: 2.5078038864082375

Epoch: 5| Step: 10
Training loss: 2.8641963812986937
Validation loss: 2.484174143825866

Epoch: 172| Step: 0
Training loss: 2.9770046116053517
Validation loss: 2.5237315585759275

Epoch: 5| Step: 1
Training loss: 2.382418240308139
Validation loss: 2.5384233365343305

Epoch: 5| Step: 2
Training loss: 3.059855974086578
Validation loss: 2.5211197400462164

Epoch: 5| Step: 3
Training loss: 2.317873408121738
Validation loss: 2.5510770225521036

Epoch: 5| Step: 4
Training loss: 2.5987785037607356
Validation loss: 2.5658934439185908

Epoch: 5| Step: 5
Training loss: 2.511106615240673
Validation loss: 2.509620993483088

Epoch: 5| Step: 6
Training loss: 3.1653418697712348
Validation loss: 2.5308163837506275

Epoch: 5| Step: 7
Training loss: 2.4900656729007946
Validation loss: 2.4876121481286755

Epoch: 5| Step: 8
Training loss: 2.532442824385767
Validation loss: 2.4808494951971

Epoch: 5| Step: 9
Training loss: 2.7100006155597507
Validation loss: 2.513447737463658

Epoch: 5| Step: 10
Training loss: 2.8097195762998535
Validation loss: 2.5057437564960536

Epoch: 173| Step: 0
Training loss: 2.045992362477058
Validation loss: 2.527854710429562

Epoch: 5| Step: 1
Training loss: 2.8001968859524244
Validation loss: 2.518272740481608

Epoch: 5| Step: 2
Training loss: 3.1817656153510545
Validation loss: 2.5018591192668906

Epoch: 5| Step: 3
Training loss: 2.384586761790314
Validation loss: 2.4953504744019157

Epoch: 5| Step: 4
Training loss: 2.685399676363644
Validation loss: 2.543727880847702

Epoch: 5| Step: 5
Training loss: 2.1071559961015556
Validation loss: 2.5136827774806436

Epoch: 5| Step: 6
Training loss: 2.933277422921217
Validation loss: 2.5163179580849504

Epoch: 5| Step: 7
Training loss: 2.604133870236192
Validation loss: 2.5224903863673074

Epoch: 5| Step: 8
Training loss: 2.91947144571391
Validation loss: 2.52160552633832

Epoch: 5| Step: 9
Training loss: 2.967730216502075
Validation loss: 2.4918479928632546

Epoch: 5| Step: 10
Training loss: 2.680559822654512
Validation loss: 2.523371651515224

Epoch: 174| Step: 0
Training loss: 2.856574683234877
Validation loss: 2.531556872856514

Epoch: 5| Step: 1
Training loss: 2.924260109464474
Validation loss: 2.5052038259267193

Epoch: 5| Step: 2
Training loss: 2.752913319030577
Validation loss: 2.5279190690047146

Epoch: 5| Step: 3
Training loss: 2.358865442892693
Validation loss: 2.539384944057835

Epoch: 5| Step: 4
Training loss: 2.885871236274827
Validation loss: 2.5241850216875603

Epoch: 5| Step: 5
Training loss: 2.149677487513763
Validation loss: 2.555905115184318

Epoch: 5| Step: 6
Training loss: 2.7958539239056033
Validation loss: 2.538296193739052

Epoch: 5| Step: 7
Training loss: 2.7042977319429795
Validation loss: 2.5349616281866862

Epoch: 5| Step: 8
Training loss: 2.477284323257146
Validation loss: 2.532417822001363

Epoch: 5| Step: 9
Training loss: 2.794252754051023
Validation loss: 2.5216746162501953

Epoch: 5| Step: 10
Training loss: 2.5773551022550456
Validation loss: 2.4838980177322814

Epoch: 175| Step: 0
Training loss: 2.6945346760361666
Validation loss: 2.519398663316782

Epoch: 5| Step: 1
Training loss: 3.097325272454249
Validation loss: 2.539865599180989

Epoch: 5| Step: 2
Training loss: 2.5198553305682863
Validation loss: 2.523403797758299

Epoch: 5| Step: 3
Training loss: 1.93204770943078
Validation loss: 2.5488331500292927

Epoch: 5| Step: 4
Training loss: 2.8685989439843667
Validation loss: 2.5530319396325103

Epoch: 5| Step: 5
Training loss: 3.0366859067215928
Validation loss: 2.5291929121558447

Epoch: 5| Step: 6
Training loss: 2.6666581829253984
Validation loss: 2.5314061835630426

Epoch: 5| Step: 7
Training loss: 2.5926442374530083
Validation loss: 2.532609371747122

Epoch: 5| Step: 8
Training loss: 2.6031831842447937
Validation loss: 2.5261556958432974

Epoch: 5| Step: 9
Training loss: 2.249741751367356
Validation loss: 2.489401388262528

Epoch: 5| Step: 10
Training loss: 3.0822073108972785
Validation loss: 2.570927463800688

Epoch: 176| Step: 0
Training loss: 2.698097625515794
Validation loss: 2.5421065264761067

Epoch: 5| Step: 1
Training loss: 3.0896934347326246
Validation loss: 2.5274902713108394

Epoch: 5| Step: 2
Training loss: 2.7381890426979334
Validation loss: 2.550824733748486

Epoch: 5| Step: 3
Training loss: 2.3313485173330992
Validation loss: 2.5507731463387087

Epoch: 5| Step: 4
Training loss: 2.602025079698668
Validation loss: 2.5458084833759593

Epoch: 5| Step: 5
Training loss: 3.0819040714610955
Validation loss: 2.4953531537735136

Epoch: 5| Step: 6
Training loss: 2.781574187511871
Validation loss: 2.5356981274846437

Epoch: 5| Step: 7
Training loss: 2.5562509774576943
Validation loss: 2.5416059266539883

Epoch: 5| Step: 8
Training loss: 2.861352122339643
Validation loss: 2.5428147213647745

Epoch: 5| Step: 9
Training loss: 2.227327342593462
Validation loss: 2.546821802548641

Epoch: 5| Step: 10
Training loss: 2.481612583063814
Validation loss: 2.5329032146918222

Epoch: 177| Step: 0
Training loss: 1.8604023763770619
Validation loss: 2.489642503258112

Epoch: 5| Step: 1
Training loss: 2.3227035584364906
Validation loss: 2.490360130755619

Epoch: 5| Step: 2
Training loss: 2.5218342036808234
Validation loss: 2.5341949114054834

Epoch: 5| Step: 3
Training loss: 2.2039225331935137
Validation loss: 2.555880763590247

Epoch: 5| Step: 4
Training loss: 2.4997025312831855
Validation loss: 2.5280955601431496

Epoch: 5| Step: 5
Training loss: 2.535667802779908
Validation loss: 2.5324099015249217

Epoch: 5| Step: 6
Training loss: 3.071071851172401
Validation loss: 2.532946439583239

Epoch: 5| Step: 7
Training loss: 3.258118978670792
Validation loss: 2.5437427019257104

Epoch: 5| Step: 8
Training loss: 2.740816735549579
Validation loss: 2.5423643895095416

Epoch: 5| Step: 9
Training loss: 3.461276138994977
Validation loss: 2.532707055284098

Epoch: 5| Step: 10
Training loss: 2.5522703348792595
Validation loss: 2.5488908722808725

Epoch: 178| Step: 0
Training loss: 2.7942438802755345
Validation loss: 2.494278771411612

Epoch: 5| Step: 1
Training loss: 3.384435673924475
Validation loss: 2.5479216149855044

Epoch: 5| Step: 2
Training loss: 2.661221239213175
Validation loss: 2.5380082933574575

Epoch: 5| Step: 3
Training loss: 2.338715805219657
Validation loss: 2.5241464802269613

Epoch: 5| Step: 4
Training loss: 2.8192256619193694
Validation loss: 2.516065128085872

Epoch: 5| Step: 5
Training loss: 3.086321302280144
Validation loss: 2.512007520253436

Epoch: 5| Step: 6
Training loss: 2.6478045672186763
Validation loss: 2.5094167966256435

Epoch: 5| Step: 7
Training loss: 2.2502825877433543
Validation loss: 2.55343117162323

Epoch: 5| Step: 8
Training loss: 2.59507625636843
Validation loss: 2.5390006139389936

Epoch: 5| Step: 9
Training loss: 2.349044516280041
Validation loss: 2.5238421152661377

Epoch: 5| Step: 10
Training loss: 1.9984018974324207
Validation loss: 2.5092942834080203

Epoch: 179| Step: 0
Training loss: 2.835776248267274
Validation loss: 2.5333112990430897

Epoch: 5| Step: 1
Training loss: 2.9239249968295975
Validation loss: 2.5130256084481997

Epoch: 5| Step: 2
Training loss: 2.041201116720586
Validation loss: 2.4969205687142293

Epoch: 5| Step: 3
Training loss: 2.7330858952088573
Validation loss: 2.5487972564581924

Epoch: 5| Step: 4
Training loss: 2.172843662204739
Validation loss: 2.49876602390308

Epoch: 5| Step: 5
Training loss: 2.757346311075056
Validation loss: 2.567183645489919

Epoch: 5| Step: 6
Training loss: 3.0882460831739524
Validation loss: 2.5455843435072496

Epoch: 5| Step: 7
Training loss: 2.9565245422242676
Validation loss: 2.5107893001957393

Epoch: 5| Step: 8
Training loss: 3.0641230739148138
Validation loss: 2.5544319919431815

Epoch: 5| Step: 9
Training loss: 2.376942091503254
Validation loss: 2.5311908418767954

Epoch: 5| Step: 10
Training loss: 2.5604870030483537
Validation loss: 2.5047970494027108

Epoch: 180| Step: 0
Training loss: 2.992090925844418
Validation loss: 2.5117218773366163

Epoch: 5| Step: 1
Training loss: 2.6948947748650993
Validation loss: 2.5125273512284805

Epoch: 5| Step: 2
Training loss: 2.8764081077439134
Validation loss: 2.550984582867092

Epoch: 5| Step: 3
Training loss: 2.529646942774887
Validation loss: 2.535343000668232

Epoch: 5| Step: 4
Training loss: 2.7462602676109373
Validation loss: 2.526246542572778

Epoch: 5| Step: 5
Training loss: 2.8194293808391118
Validation loss: 2.5519899258692003

Epoch: 5| Step: 6
Training loss: 2.645568193582341
Validation loss: 2.478826849227093

Epoch: 5| Step: 7
Training loss: 2.5154458687071752
Validation loss: 2.5332879729762445

Epoch: 5| Step: 8
Training loss: 2.3547356067140224
Validation loss: 2.514631615978814

Epoch: 5| Step: 9
Training loss: 2.60504531279123
Validation loss: 2.5045346009545457

Epoch: 5| Step: 10
Training loss: 2.4571244990813135
Validation loss: 2.5208211756302634

Epoch: 181| Step: 0
Training loss: 3.044116213972443
Validation loss: 2.5293160467624456

Epoch: 5| Step: 1
Training loss: 2.580727852757822
Validation loss: 2.538907185261774

Epoch: 5| Step: 2
Training loss: 2.5535703310359157
Validation loss: 2.5179804940359762

Epoch: 5| Step: 3
Training loss: 2.2308885810555363
Validation loss: 2.5329988495464155

Epoch: 5| Step: 4
Training loss: 2.4809962875602896
Validation loss: 2.545797402274167

Epoch: 5| Step: 5
Training loss: 3.3229465941672895
Validation loss: 2.5267382100466618

Epoch: 5| Step: 6
Training loss: 2.6185773660573
Validation loss: 2.524396022402835

Epoch: 5| Step: 7
Training loss: 2.0184486187813047
Validation loss: 2.535418941280973

Epoch: 5| Step: 8
Training loss: 2.6650541814624735
Validation loss: 2.5259179779680387

Epoch: 5| Step: 9
Training loss: 2.6047353098233845
Validation loss: 2.5394577973182653

Epoch: 5| Step: 10
Training loss: 3.262252307127155
Validation loss: 2.534720430604357

Epoch: 182| Step: 0
Training loss: 2.663421106177273
Validation loss: 2.523054808042852

Epoch: 5| Step: 1
Training loss: 2.738228834143035
Validation loss: 2.516822657232549

Epoch: 5| Step: 2
Training loss: 2.698163280237597
Validation loss: 2.5173213372761807

Epoch: 5| Step: 3
Training loss: 2.4468679142991876
Validation loss: 2.5165995516021638

Epoch: 5| Step: 4
Training loss: 2.3636159612535366
Validation loss: 2.5051971272246565

Epoch: 5| Step: 5
Training loss: 2.5317615886855065
Validation loss: 2.5618918923128526

Epoch: 5| Step: 6
Training loss: 2.8314708497266157
Validation loss: 2.515006099616795

Epoch: 5| Step: 7
Training loss: 2.443497346661561
Validation loss: 2.5311471079326227

Epoch: 5| Step: 8
Training loss: 2.8574479076479897
Validation loss: 2.5308164809957288

Epoch: 5| Step: 9
Training loss: 2.2115065849839213
Validation loss: 2.5496676814183337

Epoch: 5| Step: 10
Training loss: 3.5725782287873926
Validation loss: 2.5467552163433287

Epoch: 183| Step: 0
Training loss: 2.0147660665338907
Validation loss: 2.56589793097165

Epoch: 5| Step: 1
Training loss: 2.789131142335241
Validation loss: 2.552389478538589

Epoch: 5| Step: 2
Training loss: 2.959962387361489
Validation loss: 2.5009247822931804

Epoch: 5| Step: 3
Training loss: 2.4375353101471395
Validation loss: 2.532341872885123

Epoch: 5| Step: 4
Training loss: 2.2512677118175475
Validation loss: 2.542080396858975

Epoch: 5| Step: 5
Training loss: 2.858930542802986
Validation loss: 2.5367668159504833

Epoch: 5| Step: 6
Training loss: 2.7087557145407426
Validation loss: 2.5283176366320794

Epoch: 5| Step: 7
Training loss: 2.809588642080459
Validation loss: 2.4937282164794685

Epoch: 5| Step: 8
Training loss: 2.5887797890224316
Validation loss: 2.557930223888441

Epoch: 5| Step: 9
Training loss: 3.1967969957606774
Validation loss: 2.558484295186285

Epoch: 5| Step: 10
Training loss: 2.710642158184847
Validation loss: 2.5383772073689186

Epoch: 184| Step: 0
Training loss: 2.3677419888048012
Validation loss: 2.523335079795539

Epoch: 5| Step: 1
Training loss: 2.335673237527814
Validation loss: 2.5470407058236115

Epoch: 5| Step: 2
Training loss: 2.940870907562297
Validation loss: 2.5211277336162032

Epoch: 5| Step: 3
Training loss: 2.8330408020097506
Validation loss: 2.5051096361920786

Epoch: 5| Step: 4
Training loss: 2.513508350474546
Validation loss: 2.5112654695552123

Epoch: 5| Step: 5
Training loss: 2.2159576037238313
Validation loss: 2.5089425621787678

Epoch: 5| Step: 6
Training loss: 2.9674229918645714
Validation loss: 2.533240391181873

Epoch: 5| Step: 7
Training loss: 2.49739157975
Validation loss: 2.5121219228308918

Epoch: 5| Step: 8
Training loss: 2.3584905318134233
Validation loss: 2.4928300854438508

Epoch: 5| Step: 9
Training loss: 2.936938292995826
Validation loss: 2.545879969622769

Epoch: 5| Step: 10
Training loss: 3.372171700392599
Validation loss: 2.525479186829805

Epoch: 185| Step: 0
Training loss: 2.993272549777413
Validation loss: 2.5657774302410155

Epoch: 5| Step: 1
Training loss: 2.5245374992488276
Validation loss: 2.514717482038997

Epoch: 5| Step: 2
Training loss: 2.1150258420262777
Validation loss: 2.5151545230442838

Epoch: 5| Step: 3
Training loss: 2.120803504039585
Validation loss: 2.495099433903352

Epoch: 5| Step: 4
Training loss: 2.845104858933181
Validation loss: 2.5165248212614024

Epoch: 5| Step: 5
Training loss: 2.564176708702216
Validation loss: 2.5175541328051896

Epoch: 5| Step: 6
Training loss: 2.5275653346943736
Validation loss: 2.511263705515278

Epoch: 5| Step: 7
Training loss: 2.892788299198877
Validation loss: 2.519377627200153

Epoch: 5| Step: 8
Training loss: 2.9457138152384426
Validation loss: 2.507187254344893

Epoch: 5| Step: 9
Training loss: 2.320736419279664
Validation loss: 2.5279137204731175

Epoch: 5| Step: 10
Training loss: 3.343964186608948
Validation loss: 2.511673283250372

Epoch: 186| Step: 0
Training loss: 2.676091041173793
Validation loss: 2.5137071564393305

Epoch: 5| Step: 1
Training loss: 3.0809471244595907
Validation loss: 2.524348425337645

Epoch: 5| Step: 2
Training loss: 3.118481666167316
Validation loss: 2.537202814305775

Epoch: 5| Step: 3
Training loss: 2.6041292925377992
Validation loss: 2.584442405388568

Epoch: 5| Step: 4
Training loss: 3.0511866653038977
Validation loss: 2.476004574977803

Epoch: 5| Step: 5
Training loss: 2.170182590977066
Validation loss: 2.5469721031941464

Epoch: 5| Step: 6
Training loss: 1.9033550104664974
Validation loss: 2.541927350166681

Epoch: 5| Step: 7
Training loss: 2.44227738364514
Validation loss: 2.5247078286193987

Epoch: 5| Step: 8
Training loss: 2.659784545920777
Validation loss: 2.552769743219792

Epoch: 5| Step: 9
Training loss: 2.2269207582528834
Validation loss: 2.5681376475319206

Epoch: 5| Step: 10
Training loss: 3.2549273478988896
Validation loss: 2.5392552910774744

Epoch: 187| Step: 0
Training loss: 2.6867170745942
Validation loss: 2.544370657452689

Epoch: 5| Step: 1
Training loss: 2.4574631158305764
Validation loss: 2.5155186356452908

Epoch: 5| Step: 2
Training loss: 2.7001461307399373
Validation loss: 2.560202147811386

Epoch: 5| Step: 3
Training loss: 2.418259808057765
Validation loss: 2.5128283569409064

Epoch: 5| Step: 4
Training loss: 3.05733911498042
Validation loss: 2.562700098220231

Epoch: 5| Step: 5
Training loss: 3.2064984677059925
Validation loss: 2.555889409746678

Epoch: 5| Step: 6
Training loss: 2.0295414708372292
Validation loss: 2.5061812576253835

Epoch: 5| Step: 7
Training loss: 2.09972303925619
Validation loss: 2.499467825904192

Epoch: 5| Step: 8
Training loss: 2.85489524582322
Validation loss: 2.522447966108026

Epoch: 5| Step: 9
Training loss: 2.8603658991617493
Validation loss: 2.5088014290647975

Epoch: 5| Step: 10
Training loss: 2.4890033147352253
Validation loss: 2.551613890361438

Epoch: 188| Step: 0
Training loss: 2.3332654284632652
Validation loss: 2.5004261268951193

Epoch: 5| Step: 1
Training loss: 2.4507599138687626
Validation loss: 2.5153505031228125

Epoch: 5| Step: 2
Training loss: 2.956752265055221
Validation loss: 2.522701927184655

Epoch: 5| Step: 3
Training loss: 2.2935160255113423
Validation loss: 2.515093247406392

Epoch: 5| Step: 4
Training loss: 2.889982409836191
Validation loss: 2.5470286039336267

Epoch: 5| Step: 5
Training loss: 2.2490610706727105
Validation loss: 2.543852227680351

Epoch: 5| Step: 6
Training loss: 2.293095079935365
Validation loss: 2.5187765079911975

Epoch: 5| Step: 7
Training loss: 2.9352250725457947
Validation loss: 2.526860774373845

Epoch: 5| Step: 8
Training loss: 2.9043169052982782
Validation loss: 2.5411357180496115

Epoch: 5| Step: 9
Training loss: 2.923307832485604
Validation loss: 2.5163085748612604

Epoch: 5| Step: 10
Training loss: 2.781972127027491
Validation loss: 2.530806836491996

Epoch: 189| Step: 0
Training loss: 2.173877698362197
Validation loss: 2.5040486521005305

Epoch: 5| Step: 1
Training loss: 3.3246981031992955
Validation loss: 2.515135454326884

Epoch: 5| Step: 2
Training loss: 3.1539748650458233
Validation loss: 2.514487039539894

Epoch: 5| Step: 3
Training loss: 2.769127476021028
Validation loss: 2.5088832316097216

Epoch: 5| Step: 4
Training loss: 2.586197670010299
Validation loss: 2.551201956772008

Epoch: 5| Step: 5
Training loss: 2.2868314422687828
Validation loss: 2.540086135434064

Epoch: 5| Step: 6
Training loss: 2.9528823026201776
Validation loss: 2.515969126714989

Epoch: 5| Step: 7
Training loss: 2.6540750911930058
Validation loss: 2.5556311197896036

Epoch: 5| Step: 8
Training loss: 2.2830462764907207
Validation loss: 2.5488373744257564

Epoch: 5| Step: 9
Training loss: 2.3721374527344588
Validation loss: 2.4875505609310955

Epoch: 5| Step: 10
Training loss: 2.4893271555170937
Validation loss: 2.5274749015327216

Epoch: 190| Step: 0
Training loss: 3.010390249662198
Validation loss: 2.5304346537493814

Epoch: 5| Step: 1
Training loss: 2.347273657371273
Validation loss: 2.533055593143428

Epoch: 5| Step: 2
Training loss: 2.289568535916311
Validation loss: 2.4941730719272295

Epoch: 5| Step: 3
Training loss: 2.6826682014739016
Validation loss: 2.543305696823714

Epoch: 5| Step: 4
Training loss: 2.3791387535190323
Validation loss: 2.4984377799604442

Epoch: 5| Step: 5
Training loss: 2.50420379061059
Validation loss: 2.5350454222065624

Epoch: 5| Step: 6
Training loss: 2.5742197687960333
Validation loss: 2.548380639409568

Epoch: 5| Step: 7
Training loss: 2.6972193952240704
Validation loss: 2.495260055224803

Epoch: 5| Step: 8
Training loss: 3.2835176897009557
Validation loss: 2.504924767757773

Epoch: 5| Step: 9
Training loss: 3.114225964579236
Validation loss: 2.489262519054126

Epoch: 5| Step: 10
Training loss: 2.1498011474912935
Validation loss: 2.55510626627687

Epoch: 191| Step: 0
Training loss: 2.3472305902135036
Validation loss: 2.5210413379595877

Epoch: 5| Step: 1
Training loss: 2.101419436892539
Validation loss: 2.545729981128698

Epoch: 5| Step: 2
Training loss: 2.8584746730844124
Validation loss: 2.532614919898009

Epoch: 5| Step: 3
Training loss: 2.8388534141392743
Validation loss: 2.562128980075132

Epoch: 5| Step: 4
Training loss: 3.0461634660967585
Validation loss: 2.5125096951446952

Epoch: 5| Step: 5
Training loss: 2.757292787681114
Validation loss: 2.573351842466304

Epoch: 5| Step: 6
Training loss: 2.6213709859436656
Validation loss: 2.546263890644929

Epoch: 5| Step: 7
Training loss: 2.7284413507137493
Validation loss: 2.513967743802827

Epoch: 5| Step: 8
Training loss: 2.5575483909346968
Validation loss: 2.5320139109124673

Epoch: 5| Step: 9
Training loss: 2.650410595160118
Validation loss: 2.4977967551891154

Epoch: 5| Step: 10
Training loss: 3.0512463633927016
Validation loss: 2.5140858137985345

Epoch: 192| Step: 0
Training loss: 2.2690098174997835
Validation loss: 2.5443626265748476

Epoch: 5| Step: 1
Training loss: 2.2846212690080505
Validation loss: 2.51622981527664

Epoch: 5| Step: 2
Training loss: 3.0546859389981624
Validation loss: 2.518890063211052

Epoch: 5| Step: 3
Training loss: 2.7827679210178657
Validation loss: 2.5127808621368732

Epoch: 5| Step: 4
Training loss: 2.853579959757735
Validation loss: 2.5122922316867236

Epoch: 5| Step: 5
Training loss: 2.700069574943152
Validation loss: 2.519448687113304

Epoch: 5| Step: 6
Training loss: 2.5311070154566457
Validation loss: 2.493804117226666

Epoch: 5| Step: 7
Training loss: 3.156467543554919
Validation loss: 2.541617052255335

Epoch: 5| Step: 8
Training loss: 2.432886501551429
Validation loss: 2.5519144668278395

Epoch: 5| Step: 9
Training loss: 3.04630982463512
Validation loss: 2.559425376286027

Epoch: 5| Step: 10
Training loss: 2.0614849251421012
Validation loss: 2.5549486587561483

Epoch: 193| Step: 0
Training loss: 2.288564582285158
Validation loss: 2.557309265523938

Epoch: 5| Step: 1
Training loss: 2.803344745166728
Validation loss: 2.5524053019345563

Epoch: 5| Step: 2
Training loss: 2.9745911004650405
Validation loss: 2.5529488544683727

Epoch: 5| Step: 3
Training loss: 2.8247095211878612
Validation loss: 2.5424351770141023

Epoch: 5| Step: 4
Training loss: 2.478848145696918
Validation loss: 2.508912285003367

Epoch: 5| Step: 5
Training loss: 2.4630877108148206
Validation loss: 2.5172863784086523

Epoch: 5| Step: 6
Training loss: 3.2264664383967463
Validation loss: 2.5574800426003703

Epoch: 5| Step: 7
Training loss: 2.5205916191631883
Validation loss: 2.5306034698091966

Epoch: 5| Step: 8
Training loss: 2.586387387697033
Validation loss: 2.550438416401297

Epoch: 5| Step: 9
Training loss: 2.564238168113972
Validation loss: 2.5223368131893

Epoch: 5| Step: 10
Training loss: 2.3002169423828587
Validation loss: 2.4950580275330045

Epoch: 194| Step: 0
Training loss: 2.082283505730208
Validation loss: 2.5374987339299704

Epoch: 5| Step: 1
Training loss: 3.0556019538670403
Validation loss: 2.5228324847301584

Epoch: 5| Step: 2
Training loss: 2.2179746750674867
Validation loss: 2.5054274106708867

Epoch: 5| Step: 3
Training loss: 3.0124398443143714
Validation loss: 2.5443323048831354

Epoch: 5| Step: 4
Training loss: 2.871490492624163
Validation loss: 2.5431036764269828

Epoch: 5| Step: 5
Training loss: 2.470274828551807
Validation loss: 2.5492560839923506

Epoch: 5| Step: 6
Training loss: 2.660502003789963
Validation loss: 2.533567618636876

Epoch: 5| Step: 7
Training loss: 3.016148497054915
Validation loss: 2.5293835790630514

Epoch: 5| Step: 8
Training loss: 2.081802212425608
Validation loss: 2.5278746801090497

Epoch: 5| Step: 9
Training loss: 2.669217935673773
Validation loss: 2.511742461115942

Epoch: 5| Step: 10
Training loss: 2.506876072489876
Validation loss: 2.5116302939574475

Epoch: 195| Step: 0
Training loss: 2.6540657487384727
Validation loss: 2.4964639811279277

Epoch: 5| Step: 1
Training loss: 2.7054111757687345
Validation loss: 2.5284066383936246

Epoch: 5| Step: 2
Training loss: 2.6448728264737027
Validation loss: 2.4998176928672313

Epoch: 5| Step: 3
Training loss: 2.3968019158512295
Validation loss: 2.549094049699546

Epoch: 5| Step: 4
Training loss: 2.514897306404672
Validation loss: 2.5520897013668717

Epoch: 5| Step: 5
Training loss: 3.1647089545049214
Validation loss: 2.5075630373402507

Epoch: 5| Step: 6
Training loss: 2.3049897593769306
Validation loss: 2.5313401514444984

Epoch: 5| Step: 7
Training loss: 2.5841440856432505
Validation loss: 2.5691537657344212

Epoch: 5| Step: 8
Training loss: 2.660847085434759
Validation loss: 2.4948557471402224

Epoch: 5| Step: 9
Training loss: 2.712649198023826
Validation loss: 2.540416625645994

Epoch: 5| Step: 10
Training loss: 2.923106214631381
Validation loss: 2.5086130300721723

Epoch: 196| Step: 0
Training loss: 2.7331475690969285
Validation loss: 2.509266610626233

Epoch: 5| Step: 1
Training loss: 2.6233679829805037
Validation loss: 2.5379337115729776

Epoch: 5| Step: 2
Training loss: 2.916714440817349
Validation loss: 2.5332177688208644

Epoch: 5| Step: 3
Training loss: 2.3858818922076703
Validation loss: 2.519562935985649

Epoch: 5| Step: 4
Training loss: 2.5697309305667537
Validation loss: 2.559357814307164

Epoch: 5| Step: 5
Training loss: 2.5453755463999204
Validation loss: 2.489726333606196

Epoch: 5| Step: 6
Training loss: 2.9961582062513332
Validation loss: 2.5223169495819584

Epoch: 5| Step: 7
Training loss: 3.1147221733116015
Validation loss: 2.5161580167107482

Epoch: 5| Step: 8
Training loss: 2.5325607861889883
Validation loss: 2.529655818450349

Epoch: 5| Step: 9
Training loss: 2.392662825350239
Validation loss: 2.5331039334022267

Epoch: 5| Step: 10
Training loss: 2.0862429963046316
Validation loss: 2.545473129791992

Epoch: 197| Step: 0
Training loss: 2.654699254360749
Validation loss: 2.5456170194428998

Epoch: 5| Step: 1
Training loss: 2.507600864500188
Validation loss: 2.5225475106608335

Epoch: 5| Step: 2
Training loss: 2.9706682934245796
Validation loss: 2.511951340650143

Epoch: 5| Step: 3
Training loss: 2.708703167435236
Validation loss: 2.5183227846073963

Epoch: 5| Step: 4
Training loss: 2.5629301873089583
Validation loss: 2.5132588452295255

Epoch: 5| Step: 5
Training loss: 3.017518392916092
Validation loss: 2.530358471858851

Epoch: 5| Step: 6
Training loss: 2.247759975549953
Validation loss: 2.538663958120767

Epoch: 5| Step: 7
Training loss: 2.5749566231935104
Validation loss: 2.5435493398358417

Epoch: 5| Step: 8
Training loss: 1.9122891054248152
Validation loss: 2.5607533518580956

Epoch: 5| Step: 9
Training loss: 2.5490541087558802
Validation loss: 2.5288002397307974

Epoch: 5| Step: 10
Training loss: 3.32592987595874
Validation loss: 2.534433608949566

Epoch: 198| Step: 0
Training loss: 2.419747482555462
Validation loss: 2.5432958537288473

Epoch: 5| Step: 1
Training loss: 2.7106622121911603
Validation loss: 2.5046432987325438

Epoch: 5| Step: 2
Training loss: 2.540609692366727
Validation loss: 2.5570455215942265

Epoch: 5| Step: 3
Training loss: 2.4097076938373188
Validation loss: 2.5066890976429548

Epoch: 5| Step: 4
Training loss: 2.9926905595088082
Validation loss: 2.5118355203112355

Epoch: 5| Step: 5
Training loss: 2.557560789368397
Validation loss: 2.5511034680167786

Epoch: 5| Step: 6
Training loss: 3.1753680158578175
Validation loss: 2.550306131749734

Epoch: 5| Step: 7
Training loss: 2.703466669440531
Validation loss: 2.4946946404336168

Epoch: 5| Step: 8
Training loss: 1.836797180188736
Validation loss: 2.5400996596577445

Epoch: 5| Step: 9
Training loss: 2.8284358912770946
Validation loss: 2.5045271726811755

Epoch: 5| Step: 10
Training loss: 2.7619342207316304
Validation loss: 2.5354037358477206

Epoch: 199| Step: 0
Training loss: 2.907527027742515
Validation loss: 2.533890803413838

Epoch: 5| Step: 1
Training loss: 2.770502563084338
Validation loss: 2.5024716700282834

Epoch: 5| Step: 2
Training loss: 2.7834153907542785
Validation loss: 2.5315905733946136

Epoch: 5| Step: 3
Training loss: 2.3126825827612354
Validation loss: 2.5583240699126044

Epoch: 5| Step: 4
Training loss: 2.5922657959962914
Validation loss: 2.569224634351342

Epoch: 5| Step: 5
Training loss: 2.2088251705795527
Validation loss: 2.535742887962587

Epoch: 5| Step: 6
Training loss: 2.537267995666981
Validation loss: 2.5050595430151903

Epoch: 5| Step: 7
Training loss: 2.879543197750289
Validation loss: 2.5258139369465873

Epoch: 5| Step: 8
Training loss: 2.446491773662072
Validation loss: 2.5601918039167506

Epoch: 5| Step: 9
Training loss: 2.651164403646049
Validation loss: 2.536428967128367

Epoch: 5| Step: 10
Training loss: 2.5227870043682206
Validation loss: 2.5138175798402562

Epoch: 200| Step: 0
Training loss: 3.4428826930935825
Validation loss: 2.532321854407034

Epoch: 5| Step: 1
Training loss: 1.9154086614672035
Validation loss: 2.5182709558998373

Epoch: 5| Step: 2
Training loss: 2.3843254914149683
Validation loss: 2.545859204681072

Epoch: 5| Step: 3
Training loss: 2.4993821334260113
Validation loss: 2.5477852180360667

Epoch: 5| Step: 4
Training loss: 2.5945324923895137
Validation loss: 2.504851924367816

Epoch: 5| Step: 5
Training loss: 2.527341391608009
Validation loss: 2.565717508485508

Epoch: 5| Step: 6
Training loss: 3.2177089748379872
Validation loss: 2.560552328575487

Epoch: 5| Step: 7
Training loss: 2.8337376997873833
Validation loss: 2.51095661301266

Epoch: 5| Step: 8
Training loss: 2.0449645466984063
Validation loss: 2.5446989425361597

Epoch: 5| Step: 9
Training loss: 2.766555629554938
Validation loss: 2.5414959813068174

Epoch: 5| Step: 10
Training loss: 2.504001181196964
Validation loss: 2.5130154605744073

Epoch: 201| Step: 0
Training loss: 2.3812000259401978
Validation loss: 2.5357668920648164

Epoch: 5| Step: 1
Training loss: 2.3517215712978166
Validation loss: 2.537763119281756

Epoch: 5| Step: 2
Training loss: 3.111757218920196
Validation loss: 2.541883342053121

Epoch: 5| Step: 3
Training loss: 2.8602030237869958
Validation loss: 2.515334626003576

Epoch: 5| Step: 4
Training loss: 2.3844901760776436
Validation loss: 2.5426340412300714

Epoch: 5| Step: 5
Training loss: 2.8077865947532454
Validation loss: 2.550988304235858

Epoch: 5| Step: 6
Training loss: 2.65658630037343
Validation loss: 2.51387346227803

Epoch: 5| Step: 7
Training loss: 1.8757851546190099
Validation loss: 2.5465360761101095

Epoch: 5| Step: 8
Training loss: 2.9599762415576816
Validation loss: 2.545038386073413

Epoch: 5| Step: 9
Training loss: 2.8003035687326623
Validation loss: 2.5426994604435564

Epoch: 5| Step: 10
Training loss: 2.653851581916659
Validation loss: 2.5146176326213707

Epoch: 202| Step: 0
Training loss: 3.226037229773665
Validation loss: 2.5311645529851057

Epoch: 5| Step: 1
Training loss: 2.809124340718116
Validation loss: 2.4944224004146527

Epoch: 5| Step: 2
Training loss: 2.5370713158411253
Validation loss: 2.567074923440867

Epoch: 5| Step: 3
Training loss: 2.8841483476555396
Validation loss: 2.505916112156869

Epoch: 5| Step: 4
Training loss: 2.6086254756582856
Validation loss: 2.5389317097514406

Epoch: 5| Step: 5
Training loss: 2.433533693800249
Validation loss: 2.5565302241738306

Epoch: 5| Step: 6
Training loss: 2.7914823404826623
Validation loss: 2.5360681791706576

Epoch: 5| Step: 7
Training loss: 2.872460446131052
Validation loss: 2.5308086355325567

Epoch: 5| Step: 8
Training loss: 2.581929307272743
Validation loss: 2.5351446106497817

Epoch: 5| Step: 9
Training loss: 2.2627855068072393
Validation loss: 2.5374810894452877

Epoch: 5| Step: 10
Training loss: 1.8056134247268525
Validation loss: 2.518787559368271

Epoch: 203| Step: 0
Training loss: 3.183359186623396
Validation loss: 2.590327126808005

Epoch: 5| Step: 1
Training loss: 2.497279307988627
Validation loss: 2.5317537036220767

Epoch: 5| Step: 2
Training loss: 2.7576162468347785
Validation loss: 2.5091303438280574

Epoch: 5| Step: 3
Training loss: 2.8194586393837304
Validation loss: 2.510283724018991

Epoch: 5| Step: 4
Training loss: 2.6509416382710205
Validation loss: 2.5380627351106155

Epoch: 5| Step: 5
Training loss: 2.2128478514938807
Validation loss: 2.5044148922139535

Epoch: 5| Step: 6
Training loss: 2.4884086827774037
Validation loss: 2.536703413539402

Epoch: 5| Step: 7
Training loss: 2.276341945879734
Validation loss: 2.5554221363501033

Epoch: 5| Step: 8
Training loss: 2.7809601536282598
Validation loss: 2.539960602979699

Epoch: 5| Step: 9
Training loss: 2.7289809729226273
Validation loss: 2.5265768360635263

Epoch: 5| Step: 10
Training loss: 2.522314713537872
Validation loss: 2.492996546886107

Epoch: 204| Step: 0
Training loss: 2.530973913889534
Validation loss: 2.5412517984331426

Epoch: 5| Step: 1
Training loss: 2.27506263562846
Validation loss: 2.5317809898671157

Epoch: 5| Step: 2
Training loss: 2.8188786547073286
Validation loss: 2.500139143363326

Epoch: 5| Step: 3
Training loss: 2.6811450075164838
Validation loss: 2.513471734177181

Epoch: 5| Step: 4
Training loss: 2.798750605444696
Validation loss: 2.5237095011047845

Epoch: 5| Step: 5
Training loss: 2.7600256492970914
Validation loss: 2.53875632333972

Epoch: 5| Step: 6
Training loss: 2.6404709629975303
Validation loss: 2.532949071088622

Epoch: 5| Step: 7
Training loss: 1.8906523647377194
Validation loss: 2.509529664930704

Epoch: 5| Step: 8
Training loss: 2.9821185624150313
Validation loss: 2.5250444892205572

Epoch: 5| Step: 9
Training loss: 2.91366288050378
Validation loss: 2.4905433782530033

Epoch: 5| Step: 10
Training loss: 2.553547736180898
Validation loss: 2.5521321362133387

Epoch: 205| Step: 0
Training loss: 2.3835410083198245
Validation loss: 2.5301750434590327

Epoch: 5| Step: 1
Training loss: 2.960115585390143
Validation loss: 2.5194859074459144

Epoch: 5| Step: 2
Training loss: 2.9421110284057597
Validation loss: 2.565063405945442

Epoch: 5| Step: 3
Training loss: 2.4444610770940858
Validation loss: 2.523141230772455

Epoch: 5| Step: 4
Training loss: 2.82879546421818
Validation loss: 2.522499147989415

Epoch: 5| Step: 5
Training loss: 2.4955994977825506
Validation loss: 2.5296682188052517

Epoch: 5| Step: 6
Training loss: 2.3644063494038665
Validation loss: 2.4842086409179287

Epoch: 5| Step: 7
Training loss: 2.7571092092464213
Validation loss: 2.4960746342667814

Epoch: 5| Step: 8
Training loss: 2.6415710560276375
Validation loss: 2.5349118366942864

Epoch: 5| Step: 9
Training loss: 2.7967713406069907
Validation loss: 2.545746494444371

Epoch: 5| Step: 10
Training loss: 2.229517959532657
Validation loss: 2.530405154485539

Epoch: 206| Step: 0
Training loss: 3.2005134170649088
Validation loss: 2.528687559912927

Epoch: 5| Step: 1
Training loss: 1.9666283089189183
Validation loss: 2.5403637521196973

Epoch: 5| Step: 2
Training loss: 1.902883402204629
Validation loss: 2.548840916878537

Epoch: 5| Step: 3
Training loss: 3.267936654951244
Validation loss: 2.5008329798317135

Epoch: 5| Step: 4
Training loss: 3.081779053864962
Validation loss: 2.54248968228149

Epoch: 5| Step: 5
Training loss: 2.5536747129361927
Validation loss: 2.565290007171504

Epoch: 5| Step: 6
Training loss: 2.6135086850127287
Validation loss: 2.513921200562298

Epoch: 5| Step: 7
Training loss: 2.042225456322863
Validation loss: 2.5281305733650763

Epoch: 5| Step: 8
Training loss: 2.7118086500770233
Validation loss: 2.490287377092828

Epoch: 5| Step: 9
Training loss: 2.7519334585273594
Validation loss: 2.549929752423803

Epoch: 5| Step: 10
Training loss: 2.191616653432581
Validation loss: 2.5127410091890328

Epoch: 207| Step: 0
Training loss: 2.9929669911163588
Validation loss: 2.5531804388416472

Epoch: 5| Step: 1
Training loss: 2.952695946582768
Validation loss: 2.5405565847141567

Epoch: 5| Step: 2
Training loss: 2.373452535736093
Validation loss: 2.555453490673812

Epoch: 5| Step: 3
Training loss: 2.283409664056954
Validation loss: 2.5409141020145185

Epoch: 5| Step: 4
Training loss: 2.919534653724685
Validation loss: 2.5061028388097952

Epoch: 5| Step: 5
Training loss: 2.684200834546145
Validation loss: 2.52662040661391

Epoch: 5| Step: 6
Training loss: 1.9058643638887998
Validation loss: 2.5714439287905537

Epoch: 5| Step: 7
Training loss: 2.878835690175852
Validation loss: 2.552750628092515

Epoch: 5| Step: 8
Training loss: 2.698219390342077
Validation loss: 2.5581452458242526

Epoch: 5| Step: 9
Training loss: 2.448037283881503
Validation loss: 2.505681746317437

Epoch: 5| Step: 10
Training loss: 2.5235807301408224
Validation loss: 2.529597879732951

Epoch: 208| Step: 0
Training loss: 2.444735230383791
Validation loss: 2.52352402848357

Epoch: 5| Step: 1
Training loss: 2.433952782661134
Validation loss: 2.536499092512556

Epoch: 5| Step: 2
Training loss: 2.384162495394003
Validation loss: 2.5331923389166446

Epoch: 5| Step: 3
Training loss: 2.398837674334213
Validation loss: 2.5178620028917194

Epoch: 5| Step: 4
Training loss: 2.8714846805493988
Validation loss: 2.5409755247882146

Epoch: 5| Step: 5
Training loss: 2.52056362085881
Validation loss: 2.5305333735330664

Epoch: 5| Step: 6
Training loss: 2.4557914092238526
Validation loss: 2.538441402173676

Epoch: 5| Step: 7
Training loss: 3.0519379634326778
Validation loss: 2.572340330575671

Epoch: 5| Step: 8
Training loss: 2.8338448866753168
Validation loss: 2.560149460603166

Epoch: 5| Step: 9
Training loss: 2.7508950944184702
Validation loss: 2.5760032805567334

Epoch: 5| Step: 10
Training loss: 2.641988097730765
Validation loss: 2.537641845267359

Epoch: 209| Step: 0
Training loss: 2.993159123925371
Validation loss: 2.5302375623136304

Epoch: 5| Step: 1
Training loss: 2.715978678859795
Validation loss: 2.539454060061979

Epoch: 5| Step: 2
Training loss: 2.6940471830420467
Validation loss: 2.5235039583414873

Epoch: 5| Step: 3
Training loss: 2.366859539214176
Validation loss: 2.540578290065984

Epoch: 5| Step: 4
Training loss: 2.1517472730096108
Validation loss: 2.5495095838430615

Epoch: 5| Step: 5
Training loss: 2.553227932184619
Validation loss: 2.5379289346680807

Epoch: 5| Step: 6
Training loss: 2.542851552298877
Validation loss: 2.5529183852138813

Epoch: 5| Step: 7
Training loss: 2.3560141569337225
Validation loss: 2.5294552381170683

Epoch: 5| Step: 8
Training loss: 1.8078803020875098
Validation loss: 2.5369546349161896

Epoch: 5| Step: 9
Training loss: 2.974247550374004
Validation loss: 2.520419798162717

Epoch: 5| Step: 10
Training loss: 3.360285010284365
Validation loss: 2.5603236879462545

Epoch: 210| Step: 0
Training loss: 2.699817905643418
Validation loss: 2.5071992775777336

Epoch: 5| Step: 1
Training loss: 2.738632462598396
Validation loss: 2.5614087532221044

Epoch: 5| Step: 2
Training loss: 3.01952824956392
Validation loss: 2.5068848324391833

Epoch: 5| Step: 3
Training loss: 1.8278601038801328
Validation loss: 2.5314538028717513

Epoch: 5| Step: 4
Training loss: 3.097545722827168
Validation loss: 2.5618264198158727

Epoch: 5| Step: 5
Training loss: 2.8664102358308177
Validation loss: 2.530395508414051

Epoch: 5| Step: 6
Training loss: 2.241987372316024
Validation loss: 2.547155998265735

Epoch: 5| Step: 7
Training loss: 2.4943833199450456
Validation loss: 2.5246779222712914

Epoch: 5| Step: 8
Training loss: 2.8922609391000234
Validation loss: 2.5082161147032513

Epoch: 5| Step: 9
Training loss: 1.9934065735267756
Validation loss: 2.533822586885832

Epoch: 5| Step: 10
Training loss: 2.825098599764028
Validation loss: 2.558421695513079

Epoch: 211| Step: 0
Training loss: 2.6567260315634935
Validation loss: 2.5661793607243566

Epoch: 5| Step: 1
Training loss: 2.808896362810144
Validation loss: 2.566039987954084

Epoch: 5| Step: 2
Training loss: 2.8178505758788837
Validation loss: 2.5294016241296204

Epoch: 5| Step: 3
Training loss: 2.498767644410575
Validation loss: 2.5594969079037466

Epoch: 5| Step: 4
Training loss: 2.2167084663675833
Validation loss: 2.5258431640276275

Epoch: 5| Step: 5
Training loss: 2.758471963938764
Validation loss: 2.5331314753187093

Epoch: 5| Step: 6
Training loss: 2.4874189430717237
Validation loss: 2.535946013342487

Epoch: 5| Step: 7
Training loss: 2.3436691270226753
Validation loss: 2.5693339598926266

Epoch: 5| Step: 8
Training loss: 2.445204369832469
Validation loss: 2.5678607243403797

Epoch: 5| Step: 9
Training loss: 3.07946810006158
Validation loss: 2.5320856499274873

Epoch: 5| Step: 10
Training loss: 2.845629563490277
Validation loss: 2.576037164932169

Epoch: 212| Step: 0
Training loss: 2.449320083785141
Validation loss: 2.519969321931912

Epoch: 5| Step: 1
Training loss: 2.8488005339294467
Validation loss: 2.5018039327250987

Epoch: 5| Step: 2
Training loss: 2.4893341471781913
Validation loss: 2.5062235450734422

Epoch: 5| Step: 3
Training loss: 2.593142059042042
Validation loss: 2.5651845098747112

Epoch: 5| Step: 4
Training loss: 2.2187461315712316
Validation loss: 2.540013661525885

Epoch: 5| Step: 5
Training loss: 2.2859040952107375
Validation loss: 2.5244154314460423

Epoch: 5| Step: 6
Training loss: 3.0519031215405645
Validation loss: 2.539611712581544

Epoch: 5| Step: 7
Training loss: 2.4312644820774896
Validation loss: 2.58438875812927

Epoch: 5| Step: 8
Training loss: 2.534700279198922
Validation loss: 2.513304874401791

Epoch: 5| Step: 9
Training loss: 3.382300216966322
Validation loss: 2.552279491223274

Epoch: 5| Step: 10
Training loss: 2.0587839114761004
Validation loss: 2.534989780972483

Epoch: 213| Step: 0
Training loss: 2.298757080432303
Validation loss: 2.4486109241085217

Epoch: 5| Step: 1
Training loss: 2.6093951926906285
Validation loss: 2.5379478280875576

Epoch: 5| Step: 2
Training loss: 2.850753042217941
Validation loss: 2.538660402981794

Epoch: 5| Step: 3
Training loss: 2.0145992064089024
Validation loss: 2.5172585714689553

Epoch: 5| Step: 4
Training loss: 1.78846504196884
Validation loss: 2.489074435339768

Epoch: 5| Step: 5
Training loss: 2.5361135406408226
Validation loss: 2.5343473042452325

Epoch: 5| Step: 6
Training loss: 2.687491217310549
Validation loss: 2.5444207298400774

Epoch: 5| Step: 7
Training loss: 2.7871000507629153
Validation loss: 2.5747577891423457

Epoch: 5| Step: 8
Training loss: 3.2570562788563686
Validation loss: 2.526022316127316

Epoch: 5| Step: 9
Training loss: 2.1559213581357324
Validation loss: 2.511694458913065

Epoch: 5| Step: 10
Training loss: 3.458712101305808
Validation loss: 2.5173106063700574

Epoch: 214| Step: 0
Training loss: 2.716312938510479
Validation loss: 2.519835199666617

Epoch: 5| Step: 1
Training loss: 2.7739223002778064
Validation loss: 2.573282652627412

Epoch: 5| Step: 2
Training loss: 2.9866092966166846
Validation loss: 2.588926507101238

Epoch: 5| Step: 3
Training loss: 2.286632510932019
Validation loss: 2.506880010687077

Epoch: 5| Step: 4
Training loss: 2.3924194781585975
Validation loss: 2.5183149215998015

Epoch: 5| Step: 5
Training loss: 2.5751705002122818
Validation loss: 2.5364487470048256

Epoch: 5| Step: 6
Training loss: 2.8989030407589835
Validation loss: 2.539451703831121

Epoch: 5| Step: 7
Training loss: 2.5851742635164467
Validation loss: 2.5314544226531095

Epoch: 5| Step: 8
Training loss: 2.1339485021596434
Validation loss: 2.5542113659571504

Epoch: 5| Step: 9
Training loss: 2.740686772171219
Validation loss: 2.531287599783396

Epoch: 5| Step: 10
Training loss: 2.8155910883649073
Validation loss: 2.5651325396454254

Epoch: 215| Step: 0
Training loss: 2.430013555010128
Validation loss: 2.5609616925347685

Epoch: 5| Step: 1
Training loss: 2.7555229906325036
Validation loss: 2.539718265080441

Epoch: 5| Step: 2
Training loss: 1.8631186744252406
Validation loss: 2.533357563966155

Epoch: 5| Step: 3
Training loss: 2.772561722146649
Validation loss: 2.5309851328201565

Epoch: 5| Step: 4
Training loss: 2.5724218924984625
Validation loss: 2.5372138167460196

Epoch: 5| Step: 5
Training loss: 3.3024681340426567
Validation loss: 2.547523305801372

Epoch: 5| Step: 6
Training loss: 2.2531283141811507
Validation loss: 2.5659974688957554

Epoch: 5| Step: 7
Training loss: 2.61793102122242
Validation loss: 2.525506320589776

Epoch: 5| Step: 8
Training loss: 2.4975981618780376
Validation loss: 2.5372145215108617

Epoch: 5| Step: 9
Training loss: 2.867393216021417
Validation loss: 2.518163223048788

Epoch: 5| Step: 10
Training loss: 2.8768114105562668
Validation loss: 2.5462840240330276

Epoch: 216| Step: 0
Training loss: 2.6073785328209493
Validation loss: 2.5346908224261218

Epoch: 5| Step: 1
Training loss: 3.1651217724363443
Validation loss: 2.5147653653718574

Epoch: 5| Step: 2
Training loss: 2.310096419497833
Validation loss: 2.5367763983821208

Epoch: 5| Step: 3
Training loss: 2.1197040986540623
Validation loss: 2.544149200776221

Epoch: 5| Step: 4
Training loss: 2.425248092073359
Validation loss: 2.517608370765888

Epoch: 5| Step: 5
Training loss: 2.4128154014804144
Validation loss: 2.5389523859497563

Epoch: 5| Step: 6
Training loss: 2.1238729068426307
Validation loss: 2.5250691544419737

Epoch: 5| Step: 7
Training loss: 2.2405517140511177
Validation loss: 2.543009513370871

Epoch: 5| Step: 8
Training loss: 3.7084569731828143
Validation loss: 2.512224618538518

Epoch: 5| Step: 9
Training loss: 2.301011078888682
Validation loss: 2.5109888503014384

Epoch: 5| Step: 10
Training loss: 2.935178772974704
Validation loss: 2.5661950990906384

Epoch: 217| Step: 0
Training loss: 2.298593306560524
Validation loss: 2.5384194725229987

Epoch: 5| Step: 1
Training loss: 2.285269240495832
Validation loss: 2.5215458486294215

Epoch: 5| Step: 2
Training loss: 3.0863949979801886
Validation loss: 2.513037707802244

Epoch: 5| Step: 3
Training loss: 1.869514196806691
Validation loss: 2.515718371090885

Epoch: 5| Step: 4
Training loss: 2.5833578928938783
Validation loss: 2.5264991720608774

Epoch: 5| Step: 5
Training loss: 3.361165549798078
Validation loss: 2.5140833807672185

Epoch: 5| Step: 6
Training loss: 2.859566937451051
Validation loss: 2.481818869242231

Epoch: 5| Step: 7
Training loss: 2.4978645741362957
Validation loss: 2.5031591635755364

Epoch: 5| Step: 8
Training loss: 2.9102312936003862
Validation loss: 2.5535936675986686

Epoch: 5| Step: 9
Training loss: 2.11406350597462
Validation loss: 2.565997611264867

Epoch: 5| Step: 10
Training loss: 2.6091268272936294
Validation loss: 2.5023528543087

Epoch: 218| Step: 0
Training loss: 3.264617910650351
Validation loss: 2.565437754357803

Epoch: 5| Step: 1
Training loss: 2.922287039849769
Validation loss: 2.518834356700323

Epoch: 5| Step: 2
Training loss: 2.4983421550829954
Validation loss: 2.5508231608850984

Epoch: 5| Step: 3
Training loss: 2.3595198024752206
Validation loss: 2.55696495005315

Epoch: 5| Step: 4
Training loss: 1.953136718714844
Validation loss: 2.513046595212749

Epoch: 5| Step: 5
Training loss: 2.269231517125172
Validation loss: 2.502031389030783

Epoch: 5| Step: 6
Training loss: 2.3708288808377453
Validation loss: 2.521973773915668

Epoch: 5| Step: 7
Training loss: 2.5719903264197512
Validation loss: 2.555496431448202

Epoch: 5| Step: 8
Training loss: 2.709101514202026
Validation loss: 2.5257750793048537

Epoch: 5| Step: 9
Training loss: 2.7644238638478056
Validation loss: 2.5426226175988376

Epoch: 5| Step: 10
Training loss: 2.8352717519291866
Validation loss: 2.557147733502691

Epoch: 219| Step: 0
Training loss: 2.7449410462432655
Validation loss: 2.561108142888819

Epoch: 5| Step: 1
Training loss: 2.7883522988734866
Validation loss: 2.513767083471623

Epoch: 5| Step: 2
Training loss: 2.5618553281104632
Validation loss: 2.5519486589958187

Epoch: 5| Step: 3
Training loss: 2.713695519320845
Validation loss: 2.534267700419594

Epoch: 5| Step: 4
Training loss: 2.6908213473994524
Validation loss: 2.5548569722551955

Epoch: 5| Step: 5
Training loss: 2.5519786787308347
Validation loss: 2.5728836333118967

Epoch: 5| Step: 6
Training loss: 2.3052579529379655
Validation loss: 2.5461407369323297

Epoch: 5| Step: 7
Training loss: 2.931097642399896
Validation loss: 2.5817255298946145

Epoch: 5| Step: 8
Training loss: 1.9979132256131842
Validation loss: 2.531567446158763

Epoch: 5| Step: 9
Training loss: 2.5721239935856333
Validation loss: 2.505374670545257

Epoch: 5| Step: 10
Training loss: 2.5142318943536623
Validation loss: 2.5490591564712526

Epoch: 220| Step: 0
Training loss: 2.6103357613567306
Validation loss: 2.536410069470225

Epoch: 5| Step: 1
Training loss: 2.6881161360515806
Validation loss: 2.512389008244782

Epoch: 5| Step: 2
Training loss: 2.142465955359162
Validation loss: 2.568284246184259

Epoch: 5| Step: 3
Training loss: 2.3011656668324636
Validation loss: 2.5083044867355335

Epoch: 5| Step: 4
Training loss: 3.2334329458668973
Validation loss: 2.53147554981514

Epoch: 5| Step: 5
Training loss: 2.392537766719565
Validation loss: 2.5524465925610835

Epoch: 5| Step: 6
Training loss: 2.288470611603597
Validation loss: 2.497030392584597

Epoch: 5| Step: 7
Training loss: 3.0528649554205893
Validation loss: 2.497808260667003

Epoch: 5| Step: 8
Training loss: 2.481732480585708
Validation loss: 2.5270369326163875

Epoch: 5| Step: 9
Training loss: 3.0733000607734033
Validation loss: 2.4745084583345602

Epoch: 5| Step: 10
Training loss: 2.2571721736425125
Validation loss: 2.5487877946572746

Epoch: 221| Step: 0
Training loss: 2.745147411786654
Validation loss: 2.547287518589734

Epoch: 5| Step: 1
Training loss: 2.130015680855354
Validation loss: 2.5317839840758984

Epoch: 5| Step: 2
Training loss: 3.037675634259222
Validation loss: 2.5501374779674477

Epoch: 5| Step: 3
Training loss: 2.521437191687946
Validation loss: 2.539599907909547

Epoch: 5| Step: 4
Training loss: 1.9411892990378596
Validation loss: 2.5571386033626364

Epoch: 5| Step: 5
Training loss: 3.2480044473984058
Validation loss: 2.487315814806812

Epoch: 5| Step: 6
Training loss: 2.696695431845471
Validation loss: 2.495911695764996

Epoch: 5| Step: 7
Training loss: 1.9399306524801048
Validation loss: 2.56944949670539

Epoch: 5| Step: 8
Training loss: 2.3770154131436567
Validation loss: 2.530835749633694

Epoch: 5| Step: 9
Training loss: 2.849645016965672
Validation loss: 2.5485473795026903

Epoch: 5| Step: 10
Training loss: 2.8008891022371816
Validation loss: 2.5226087454749835

Epoch: 222| Step: 0
Training loss: 2.831632009843857
Validation loss: 2.536909824069838

Epoch: 5| Step: 1
Training loss: 2.694716854897759
Validation loss: 2.541616608442615

Epoch: 5| Step: 2
Training loss: 2.4934891796194734
Validation loss: 2.4993446690964287

Epoch: 5| Step: 3
Training loss: 1.997866147874068
Validation loss: 2.5524933437722512

Epoch: 5| Step: 4
Training loss: 2.3487180825217298
Validation loss: 2.557161185537205

Epoch: 5| Step: 5
Training loss: 3.146508319178758
Validation loss: 2.532338600936744

Epoch: 5| Step: 6
Training loss: 2.2278430134308556
Validation loss: 2.554359186390506

Epoch: 5| Step: 7
Training loss: 2.495992118187222
Validation loss: 2.52108192811346

Epoch: 5| Step: 8
Training loss: 2.7497547213668794
Validation loss: 2.508248135781628

Epoch: 5| Step: 9
Training loss: 2.9046944998276674
Validation loss: 2.5497513963341145

Epoch: 5| Step: 10
Training loss: 2.228377716584919
Validation loss: 2.5406525419558905

Epoch: 223| Step: 0
Training loss: 2.4466098841523416
Validation loss: 2.557456230267216

Epoch: 5| Step: 1
Training loss: 2.5313693359878253
Validation loss: 2.542580019000139

Epoch: 5| Step: 2
Training loss: 3.2208822650490685
Validation loss: 2.5247139617530845

Epoch: 5| Step: 3
Training loss: 2.673305909102544
Validation loss: 2.529588384629249

Epoch: 5| Step: 4
Training loss: 2.700867520588437
Validation loss: 2.56133567706115

Epoch: 5| Step: 5
Training loss: 2.4934360163075038
Validation loss: 2.5141854620488853

Epoch: 5| Step: 6
Training loss: 2.415032744254776
Validation loss: 2.5047949021148255

Epoch: 5| Step: 7
Training loss: 2.5155387531920543
Validation loss: 2.524589110961252

Epoch: 5| Step: 8
Training loss: 3.146114732564823
Validation loss: 2.525653355527155

Epoch: 5| Step: 9
Training loss: 2.397030893202319
Validation loss: 2.5538347505728733

Epoch: 5| Step: 10
Training loss: 1.9349891636665772
Validation loss: 2.547907914946801

Epoch: 224| Step: 0
Training loss: 2.587689224179569
Validation loss: 2.544669247963119

Epoch: 5| Step: 1
Training loss: 2.6086171585865223
Validation loss: 2.5011719674118162

Epoch: 5| Step: 2
Training loss: 2.012383271617205
Validation loss: 2.534556186519972

Epoch: 5| Step: 3
Training loss: 2.8415146310655466
Validation loss: 2.5359803641994634

Epoch: 5| Step: 4
Training loss: 2.5198983804710045
Validation loss: 2.527095941466594

Epoch: 5| Step: 5
Training loss: 2.425751862524537
Validation loss: 2.5038090892543807

Epoch: 5| Step: 6
Training loss: 2.74156699265134
Validation loss: 2.543751320807469

Epoch: 5| Step: 7
Training loss: 2.027534020229016
Validation loss: 2.5085751210894878

Epoch: 5| Step: 8
Training loss: 3.178836193048696
Validation loss: 2.508414112665869

Epoch: 5| Step: 9
Training loss: 2.3929286653285495
Validation loss: 2.518317873793517

Epoch: 5| Step: 10
Training loss: 3.079538398435149
Validation loss: 2.558693487406927

Epoch: 225| Step: 0
Training loss: 2.6557073599850307
Validation loss: 2.5480969098166306

Epoch: 5| Step: 1
Training loss: 2.506894142536203
Validation loss: 2.511972811974897

Epoch: 5| Step: 2
Training loss: 3.3128150934029827
Validation loss: 2.5173223821546027

Epoch: 5| Step: 3
Training loss: 2.347666202466945
Validation loss: 2.5379266447001214

Epoch: 5| Step: 4
Training loss: 2.183281236371596
Validation loss: 2.5425077563351928

Epoch: 5| Step: 5
Training loss: 2.449496750819521
Validation loss: 2.5130925976691163

Epoch: 5| Step: 6
Training loss: 2.203250637936064
Validation loss: 2.515935977584691

Epoch: 5| Step: 7
Training loss: 2.1347157017907383
Validation loss: 2.5829347583510667

Epoch: 5| Step: 8
Training loss: 3.0331249927054627
Validation loss: 2.5247127066958144

Epoch: 5| Step: 9
Training loss: 2.6808908502086433
Validation loss: 2.5222113268585

Epoch: 5| Step: 10
Training loss: 2.6070422864205356
Validation loss: 2.528849763287631

Epoch: 226| Step: 0
Training loss: 2.33120963544903
Validation loss: 2.555420070727314

Epoch: 5| Step: 1
Training loss: 1.940828847698413
Validation loss: 2.5280551434439023

Epoch: 5| Step: 2
Training loss: 2.2304386063391095
Validation loss: 2.5124857137313987

Epoch: 5| Step: 3
Training loss: 2.814231085506415
Validation loss: 2.5093470790742383

Epoch: 5| Step: 4
Training loss: 2.622262162732334
Validation loss: 2.515264384499012

Epoch: 5| Step: 5
Training loss: 3.26014768488271
Validation loss: 2.5194519462928566

Epoch: 5| Step: 6
Training loss: 2.538450947986199
Validation loss: 2.52889373261323

Epoch: 5| Step: 7
Training loss: 2.451755992092848
Validation loss: 2.537436746079362

Epoch: 5| Step: 8
Training loss: 2.1381018031249406
Validation loss: 2.547179174186013

Epoch: 5| Step: 9
Training loss: 2.765073645854354
Validation loss: 2.520072383501907

Epoch: 5| Step: 10
Training loss: 3.036790954971912
Validation loss: 2.5177398313781425

Epoch: 227| Step: 0
Training loss: 2.1445211330376686
Validation loss: 2.5386564984327142

Epoch: 5| Step: 1
Training loss: 2.825881489649288
Validation loss: 2.5227802314271273

Epoch: 5| Step: 2
Training loss: 2.3121463402101874
Validation loss: 2.5435107158480306

Epoch: 5| Step: 3
Training loss: 2.037588119941589
Validation loss: 2.5100252815430735

Epoch: 5| Step: 4
Training loss: 2.5657766838630125
Validation loss: 2.5122610825972407

Epoch: 5| Step: 5
Training loss: 2.590426418299792
Validation loss: 2.5520407222148

Epoch: 5| Step: 6
Training loss: 2.6239718285537017
Validation loss: 2.491063969035471

Epoch: 5| Step: 7
Training loss: 2.957316658225257
Validation loss: 2.568473151054515

Epoch: 5| Step: 8
Training loss: 2.779167338480337
Validation loss: 2.5587294235022133

Epoch: 5| Step: 9
Training loss: 2.876277473912
Validation loss: 2.522299029665663

Epoch: 5| Step: 10
Training loss: 2.630991773098792
Validation loss: 2.5558628377679877

Epoch: 228| Step: 0
Training loss: 2.7829259901770618
Validation loss: 2.534616497032048

Epoch: 5| Step: 1
Training loss: 2.8409769140297154
Validation loss: 2.5268939450499985

Epoch: 5| Step: 2
Training loss: 3.030283665739667
Validation loss: 2.49570265251902

Epoch: 5| Step: 3
Training loss: 2.377117016548359
Validation loss: 2.5402302353613995

Epoch: 5| Step: 4
Training loss: 2.581519094854262
Validation loss: 2.4887795729995483

Epoch: 5| Step: 5
Training loss: 2.7848601324274505
Validation loss: 2.548173127804371

Epoch: 5| Step: 6
Training loss: 2.73229037793956
Validation loss: 2.514543533598146

Epoch: 5| Step: 7
Training loss: 2.2989175239493447
Validation loss: 2.5020579860711742

Epoch: 5| Step: 8
Training loss: 2.7803809704902767
Validation loss: 2.55624140785559

Epoch: 5| Step: 9
Training loss: 1.9225642511274192
Validation loss: 2.477165577554463

Epoch: 5| Step: 10
Training loss: 2.3650745996238447
Validation loss: 2.5293726388493596

Epoch: 229| Step: 0
Training loss: 2.8437570425093086
Validation loss: 2.531878391981624

Epoch: 5| Step: 1
Training loss: 2.118812303555403
Validation loss: 2.5324861629207556

Epoch: 5| Step: 2
Training loss: 2.6601270318352257
Validation loss: 2.5316810225744466

Epoch: 5| Step: 3
Training loss: 2.636211612109005
Validation loss: 2.5200694771070085

Epoch: 5| Step: 4
Training loss: 2.448732464714416
Validation loss: 2.554475101430782

Epoch: 5| Step: 5
Training loss: 2.2120449136930542
Validation loss: 2.5557751397019

Epoch: 5| Step: 6
Training loss: 2.901353546490568
Validation loss: 2.5286172361431674

Epoch: 5| Step: 7
Training loss: 3.1663936363437695
Validation loss: 2.5283663909271885

Epoch: 5| Step: 8
Training loss: 2.7328062952755285
Validation loss: 2.519147834371072

Epoch: 5| Step: 9
Training loss: 1.7736601164654502
Validation loss: 2.498280265958311

Epoch: 5| Step: 10
Training loss: 2.782596219465026
Validation loss: 2.574284331558016

Epoch: 230| Step: 0
Training loss: 2.159131543447879
Validation loss: 2.5065765376399756

Epoch: 5| Step: 1
Training loss: 2.8161182441486465
Validation loss: 2.5263231082410678

Epoch: 5| Step: 2
Training loss: 2.4258022829578296
Validation loss: 2.552491897985233

Epoch: 5| Step: 3
Training loss: 2.1978829427967304
Validation loss: 2.558450219422039

Epoch: 5| Step: 4
Training loss: 2.5541090004049765
Validation loss: 2.55647140135035

Epoch: 5| Step: 5
Training loss: 3.3484176428664885
Validation loss: 2.5589241301112184

Epoch: 5| Step: 6
Training loss: 2.6440003621480583
Validation loss: 2.528623074903247

Epoch: 5| Step: 7
Training loss: 2.6928263379525332
Validation loss: 2.5250393853760293

Epoch: 5| Step: 8
Training loss: 2.8262089935796726
Validation loss: 2.5280788473647093

Epoch: 5| Step: 9
Training loss: 2.6018205577717595
Validation loss: 2.5616732118169225

Epoch: 5| Step: 10
Training loss: 1.9959746024746294
Validation loss: 2.553539608168516

Epoch: 231| Step: 0
Training loss: 2.509176768528893
Validation loss: 2.4967792704605505

Epoch: 5| Step: 1
Training loss: 2.6137942963782166
Validation loss: 2.546661107266558

Epoch: 5| Step: 2
Training loss: 2.629667038818106
Validation loss: 2.549968242990406

Epoch: 5| Step: 3
Training loss: 3.8234898746396815
Validation loss: 2.57018037046163

Epoch: 5| Step: 4
Training loss: 2.4052222893465447
Validation loss: 2.5119228138204415

Epoch: 5| Step: 5
Training loss: 2.28957707476838
Validation loss: 2.525493769866256

Epoch: 5| Step: 6
Training loss: 2.300903731552574
Validation loss: 2.565252838315417

Epoch: 5| Step: 7
Training loss: 2.6993518581224225
Validation loss: 2.490905793197802

Epoch: 5| Step: 8
Training loss: 2.3117305403367165
Validation loss: 2.545020313370846

Epoch: 5| Step: 9
Training loss: 2.25736134387395
Validation loss: 2.523218904657807

Epoch: 5| Step: 10
Training loss: 1.9117275398404638
Validation loss: 2.4861201341167813

Epoch: 232| Step: 0
Training loss: 2.9024283600869483
Validation loss: 2.5554416789250514

Epoch: 5| Step: 1
Training loss: 2.3394616122242318
Validation loss: 2.5285006842093676

Epoch: 5| Step: 2
Training loss: 2.185070978054988
Validation loss: 2.536434115773298

Epoch: 5| Step: 3
Training loss: 2.3305115212771774
Validation loss: 2.5360724672865964

Epoch: 5| Step: 4
Training loss: 3.4382889275789084
Validation loss: 2.5453803455880517

Epoch: 5| Step: 5
Training loss: 2.8436485523950696
Validation loss: 2.5246082230209352

Epoch: 5| Step: 6
Training loss: 2.4552756437176866
Validation loss: 2.528588206386259

Epoch: 5| Step: 7
Training loss: 2.2441579421315643
Validation loss: 2.5009596561968594

Epoch: 5| Step: 8
Training loss: 2.180676963757739
Validation loss: 2.563733667062332

Epoch: 5| Step: 9
Training loss: 2.2267070522567227
Validation loss: 2.554678685200463

Epoch: 5| Step: 10
Training loss: 3.1963791687383143
Validation loss: 2.5326646239449566

Epoch: 233| Step: 0
Training loss: 2.338652598943704
Validation loss: 2.5278708243130303

Epoch: 5| Step: 1
Training loss: 2.703243804261299
Validation loss: 2.5370276721507086

Epoch: 5| Step: 2
Training loss: 2.2322688279709526
Validation loss: 2.5738885880566746

Epoch: 5| Step: 3
Training loss: 2.563079489336694
Validation loss: 2.469614506078255

Epoch: 5| Step: 4
Training loss: 3.1985551194711217
Validation loss: 2.555267648439155

Epoch: 5| Step: 5
Training loss: 2.8377982096316976
Validation loss: 2.552607458931079

Epoch: 5| Step: 6
Training loss: 2.6744950147615483
Validation loss: 2.5257484133032504

Epoch: 5| Step: 7
Training loss: 2.0814186325718653
Validation loss: 2.5646437035166225

Epoch: 5| Step: 8
Training loss: 2.0654726280997284
Validation loss: 2.530109397176393

Epoch: 5| Step: 9
Training loss: 2.609408167097173
Validation loss: 2.5502956954451648

Epoch: 5| Step: 10
Training loss: 3.130512715719463
Validation loss: 2.5588100907687976

Epoch: 234| Step: 0
Training loss: 2.603855989361966
Validation loss: 2.555686214328025

Epoch: 5| Step: 1
Training loss: 2.588489299119093
Validation loss: 2.501778276757872

Epoch: 5| Step: 2
Training loss: 2.238836569078778
Validation loss: 2.492190750597768

Epoch: 5| Step: 3
Training loss: 2.33769563070482
Validation loss: 2.5292404727884534

Epoch: 5| Step: 4
Training loss: 2.580125622019756
Validation loss: 2.5025848326120226

Epoch: 5| Step: 5
Training loss: 3.0574562422708325
Validation loss: 2.554633392466457

Epoch: 5| Step: 6
Training loss: 2.096499445523262
Validation loss: 2.556392032165401

Epoch: 5| Step: 7
Training loss: 2.7898257624319487
Validation loss: 2.5194664370242053

Epoch: 5| Step: 8
Training loss: 2.958421589425897
Validation loss: 2.5348237591623977

Epoch: 5| Step: 9
Training loss: 2.2966489096713136
Validation loss: 2.5047444935423133

Epoch: 5| Step: 10
Training loss: 2.666542129787497
Validation loss: 2.5536705587839332

Epoch: 235| Step: 0
Training loss: 2.0837048644341767
Validation loss: 2.525665090891504

Epoch: 5| Step: 1
Training loss: 2.66778483392214
Validation loss: 2.555996804206819

Epoch: 5| Step: 2
Training loss: 2.501824285568308
Validation loss: 2.5344486887057522

Epoch: 5| Step: 3
Training loss: 2.67997620031123
Validation loss: 2.5306708694905127

Epoch: 5| Step: 4
Training loss: 2.1656864834599476
Validation loss: 2.5652342864150692

Epoch: 5| Step: 5
Training loss: 2.1771402549299
Validation loss: 2.505242143058787

Epoch: 5| Step: 6
Training loss: 2.991855851959417
Validation loss: 2.4894528036609604

Epoch: 5| Step: 7
Training loss: 2.4029940089525335
Validation loss: 2.5729910044455324

Epoch: 5| Step: 8
Training loss: 3.359390613608338
Validation loss: 2.5758697281080525

Epoch: 5| Step: 9
Training loss: 2.6462704955664615
Validation loss: 2.507391770800206

Epoch: 5| Step: 10
Training loss: 2.129838036123787
Validation loss: 2.5463618784484643

Epoch: 236| Step: 0
Training loss: 3.046496402008972
Validation loss: 2.548143873131875

Epoch: 5| Step: 1
Training loss: 2.4052703646765288
Validation loss: 2.5236797292063566

Epoch: 5| Step: 2
Training loss: 2.5110040718753543
Validation loss: 2.529824485835451

Epoch: 5| Step: 3
Training loss: 2.5703929204447347
Validation loss: 2.5161894466495194

Epoch: 5| Step: 4
Training loss: 2.2475180181984005
Validation loss: 2.523164177168058

Epoch: 5| Step: 5
Training loss: 1.5074925849188132
Validation loss: 2.5419756497954014

Epoch: 5| Step: 6
Training loss: 2.585982676684778
Validation loss: 2.532625133484627

Epoch: 5| Step: 7
Training loss: 2.5128316593945983
Validation loss: 2.524527959724999

Epoch: 5| Step: 8
Training loss: 2.9665364897666753
Validation loss: 2.5733100982557278

Epoch: 5| Step: 9
Training loss: 2.900715141251977
Validation loss: 2.521915320200802

Epoch: 5| Step: 10
Training loss: 2.7141756182405756
Validation loss: 2.5091283289859927

Epoch: 237| Step: 0
Training loss: 2.477758365558862
Validation loss: 2.4850876618558537

Epoch: 5| Step: 1
Training loss: 2.3336744286224143
Validation loss: 2.5539405104211257

Epoch: 5| Step: 2
Training loss: 2.452965312060909
Validation loss: 2.4882397837451777

Epoch: 5| Step: 3
Training loss: 2.921874510413144
Validation loss: 2.5344215485192128

Epoch: 5| Step: 4
Training loss: 1.598335252402025
Validation loss: 2.510268401567869

Epoch: 5| Step: 5
Training loss: 2.6668715894957558
Validation loss: 2.5332992049343313

Epoch: 5| Step: 6
Training loss: 2.7174312857298846
Validation loss: 2.540891423873739

Epoch: 5| Step: 7
Training loss: 2.9364415960702077
Validation loss: 2.5584731497448403

Epoch: 5| Step: 8
Training loss: 3.2192462427499953
Validation loss: 2.5114541575052676

Epoch: 5| Step: 9
Training loss: 2.4771849996131396
Validation loss: 2.5186385581347532

Epoch: 5| Step: 10
Training loss: 2.014535890616928
Validation loss: 2.531008847790355

Epoch: 238| Step: 0
Training loss: 2.3366846018967675
Validation loss: 2.513614505653339

Epoch: 5| Step: 1
Training loss: 2.0496538242110014
Validation loss: 2.5347817657874487

Epoch: 5| Step: 2
Training loss: 2.602692046687925
Validation loss: 2.5577706835541867

Epoch: 5| Step: 3
Training loss: 2.4413294909808294
Validation loss: 2.50122300299661

Epoch: 5| Step: 4
Training loss: 2.0143079372869086
Validation loss: 2.5211375773358973

Epoch: 5| Step: 5
Training loss: 2.895896764559104
Validation loss: 2.5268111296537454

Epoch: 5| Step: 6
Training loss: 2.5045627917526905
Validation loss: 2.5709282286266517

Epoch: 5| Step: 7
Training loss: 3.577786358796038
Validation loss: 2.53794256230851

Epoch: 5| Step: 8
Training loss: 2.833235533279246
Validation loss: 2.5636822444126715

Epoch: 5| Step: 9
Training loss: 2.3381849213656016
Validation loss: 2.537820262450894

Epoch: 5| Step: 10
Training loss: 2.284576081533389
Validation loss: 2.5192417485616256

Epoch: 239| Step: 0
Training loss: 2.3887834624257778
Validation loss: 2.5449931736047144

Epoch: 5| Step: 1
Training loss: 2.4485466870060875
Validation loss: 2.5590622034159445

Epoch: 5| Step: 2
Training loss: 2.8069033569452855
Validation loss: 2.5281598071275067

Epoch: 5| Step: 3
Training loss: 2.2996487639552776
Validation loss: 2.5736091946852135

Epoch: 5| Step: 4
Training loss: 2.550346489347822
Validation loss: 2.554334545060181

Epoch: 5| Step: 5
Training loss: 2.64255403562676
Validation loss: 2.5194699729494414

Epoch: 5| Step: 6
Training loss: 2.5158008964126366
Validation loss: 2.5686655930744147

Epoch: 5| Step: 7
Training loss: 2.8830701924755857
Validation loss: 2.520198632962426

Epoch: 5| Step: 8
Training loss: 2.5636543837134718
Validation loss: 2.538387730043145

Epoch: 5| Step: 9
Training loss: 2.342232479913067
Validation loss: 2.5960835608047255

Epoch: 5| Step: 10
Training loss: 2.504541658663898
Validation loss: 2.5192638125865967

Epoch: 240| Step: 0
Training loss: 2.666309382425235
Validation loss: 2.498262902208321

Epoch: 5| Step: 1
Training loss: 2.4212762892462245
Validation loss: 2.556294246314421

Epoch: 5| Step: 2
Training loss: 2.8132651241977
Validation loss: 2.5374793572694747

Epoch: 5| Step: 3
Training loss: 1.8737421266926058
Validation loss: 2.5125224035785867

Epoch: 5| Step: 4
Training loss: 2.0667828106802704
Validation loss: 2.5130720504513886

Epoch: 5| Step: 5
Training loss: 2.9657974820079454
Validation loss: 2.531175959456388

Epoch: 5| Step: 6
Training loss: 2.7731945522442465
Validation loss: 2.5208122749503303

Epoch: 5| Step: 7
Training loss: 2.731785447209158
Validation loss: 2.5264262160521285

Epoch: 5| Step: 8
Training loss: 2.776721224651465
Validation loss: 2.509128487353455

Epoch: 5| Step: 9
Training loss: 2.711971558458296
Validation loss: 2.5682427430244132

Epoch: 5| Step: 10
Training loss: 2.241198916600388
Validation loss: 2.548063182098712

Epoch: 241| Step: 0
Training loss: 2.340835895892278
Validation loss: 2.5260790012866425

Epoch: 5| Step: 1
Training loss: 2.131831911356711
Validation loss: 2.5154914012855105

Epoch: 5| Step: 2
Training loss: 2.4325490702338275
Validation loss: 2.5185909367479358

Epoch: 5| Step: 3
Training loss: 2.355879562764555
Validation loss: 2.5359502895339707

Epoch: 5| Step: 4
Training loss: 2.6202640499396717
Validation loss: 2.50526544526588

Epoch: 5| Step: 5
Training loss: 2.622204700059412
Validation loss: 2.5017663586379855

Epoch: 5| Step: 6
Training loss: 2.2507354805823465
Validation loss: 2.5156818440284328

Epoch: 5| Step: 7
Training loss: 3.1856124375342416
Validation loss: 2.5316976953715704

Epoch: 5| Step: 8
Training loss: 2.6456991346873515
Validation loss: 2.5601017211469093

Epoch: 5| Step: 9
Training loss: 2.9814400346436254
Validation loss: 2.544753522222156

Epoch: 5| Step: 10
Training loss: 2.5611186142115305
Validation loss: 2.5295500683971843

Epoch: 242| Step: 0
Training loss: 2.4305443923936045
Validation loss: 2.5001201898129803

Epoch: 5| Step: 1
Training loss: 2.5288634175517166
Validation loss: 2.544121064702432

Epoch: 5| Step: 2
Training loss: 2.357051589569548
Validation loss: 2.5441623466912926

Epoch: 5| Step: 3
Training loss: 2.1059072742028038
Validation loss: 2.530083642183583

Epoch: 5| Step: 4
Training loss: 2.6125133167274237
Validation loss: 2.545528671794497

Epoch: 5| Step: 5
Training loss: 2.8782078634753074
Validation loss: 2.516675883097466

Epoch: 5| Step: 6
Training loss: 2.0176718321731535
Validation loss: 2.531271996827272

Epoch: 5| Step: 7
Training loss: 2.4136138795452955
Validation loss: 2.5468525158601643

Epoch: 5| Step: 8
Training loss: 3.073663101488222
Validation loss: 2.5120060169761746

Epoch: 5| Step: 9
Training loss: 2.3263207939645567
Validation loss: 2.5157715271894454

Epoch: 5| Step: 10
Training loss: 3.0758920693678284
Validation loss: 2.5645585014375487

Epoch: 243| Step: 0
Training loss: 2.77710844134928
Validation loss: 2.497343162094023

Epoch: 5| Step: 1
Training loss: 2.8566698295845794
Validation loss: 2.527238492569108

Epoch: 5| Step: 2
Training loss: 2.3436008660234946
Validation loss: 2.530628086927281

Epoch: 5| Step: 3
Training loss: 2.6393051912188974
Validation loss: 2.5387034525977836

Epoch: 5| Step: 4
Training loss: 2.8109089907716034
Validation loss: 2.5355926476326376

Epoch: 5| Step: 5
Training loss: 2.3833100346669114
Validation loss: 2.5041699242097613

Epoch: 5| Step: 6
Training loss: 2.501661797386817
Validation loss: 2.5314949390111527

Epoch: 5| Step: 7
Training loss: 2.656816758670807
Validation loss: 2.537950919063456

Epoch: 5| Step: 8
Training loss: 2.3983196018330464
Validation loss: 2.539341939815769

Epoch: 5| Step: 9
Training loss: 2.2210492323185482
Validation loss: 2.5507314346389673

Epoch: 5| Step: 10
Training loss: 2.5281539632413663
Validation loss: 2.540887456666501

Epoch: 244| Step: 0
Training loss: 2.75832035910637
Validation loss: 2.5380454990857766

Epoch: 5| Step: 1
Training loss: 2.671527862306435
Validation loss: 2.524619826664603

Epoch: 5| Step: 2
Training loss: 1.4857787070481758
Validation loss: 2.5081586323208653

Epoch: 5| Step: 3
Training loss: 2.6602262468133455
Validation loss: 2.533950035084993

Epoch: 5| Step: 4
Training loss: 2.964154028798995
Validation loss: 2.540731679357293

Epoch: 5| Step: 5
Training loss: 2.4606191277815417
Validation loss: 2.4987970636975745

Epoch: 5| Step: 6
Training loss: 2.3980736472025264
Validation loss: 2.5232469984678407

Epoch: 5| Step: 7
Training loss: 2.3848224105135167
Validation loss: 2.530330947377748

Epoch: 5| Step: 8
Training loss: 2.631652938906826
Validation loss: 2.5514776445744616

Epoch: 5| Step: 9
Training loss: 3.1575897696956337
Validation loss: 2.5296024149524223

Epoch: 5| Step: 10
Training loss: 1.6236316348213504
Validation loss: 2.5303719538517915

Epoch: 245| Step: 0
Training loss: 2.5219483129724214
Validation loss: 2.487846855987137

Epoch: 5| Step: 1
Training loss: 2.1435871651867617
Validation loss: 2.541012465615397

Epoch: 5| Step: 2
Training loss: 2.9295904931856382
Validation loss: 2.548800636023516

Epoch: 5| Step: 3
Training loss: 2.2541842231372353
Validation loss: 2.550032155049135

Epoch: 5| Step: 4
Training loss: 2.151747937823398
Validation loss: 2.5637675306098084

Epoch: 5| Step: 5
Training loss: 2.814092397239763
Validation loss: 2.500018845764007

Epoch: 5| Step: 6
Training loss: 1.8197501300277694
Validation loss: 2.5318897846053003

Epoch: 5| Step: 7
Training loss: 3.215818533156963
Validation loss: 2.5275906376299444

Epoch: 5| Step: 8
Training loss: 2.367165644075826
Validation loss: 2.519042054342601

Epoch: 5| Step: 9
Training loss: 3.032201715880488
Validation loss: 2.518994529125817

Epoch: 5| Step: 10
Training loss: 1.9563890572261573
Validation loss: 2.525544751970915

Epoch: 246| Step: 0
Training loss: 2.328418789958517
Validation loss: 2.570463729964072

Epoch: 5| Step: 1
Training loss: 2.500138660400264
Validation loss: 2.5530526231402595

Epoch: 5| Step: 2
Training loss: 2.484253406548043
Validation loss: 2.5298907693022126

Epoch: 5| Step: 3
Training loss: 2.0986389472484785
Validation loss: 2.5555327159604952

Epoch: 5| Step: 4
Training loss: 2.1131828694175074
Validation loss: 2.5201632267442053

Epoch: 5| Step: 5
Training loss: 3.1287555253471204
Validation loss: 2.518416636930738

Epoch: 5| Step: 6
Training loss: 2.6735577554594445
Validation loss: 2.5684999613763146

Epoch: 5| Step: 7
Training loss: 2.6668917044417486
Validation loss: 2.561067695613901

Epoch: 5| Step: 8
Training loss: 2.864213362412934
Validation loss: 2.5308845891289518

Epoch: 5| Step: 9
Training loss: 2.7918622152438415
Validation loss: 2.5465390429027743

Epoch: 5| Step: 10
Training loss: 1.9049755901865364
Validation loss: 2.5571461053786435

Epoch: 247| Step: 0
Training loss: 2.3646292885055167
Validation loss: 2.5696845333700797

Epoch: 5| Step: 1
Training loss: 3.0640883705801647
Validation loss: 2.5215816182137725

Epoch: 5| Step: 2
Training loss: 2.235006923280784
Validation loss: 2.4955798892817715

Epoch: 5| Step: 3
Training loss: 2.3174066811613176
Validation loss: 2.559620878285219

Epoch: 5| Step: 4
Training loss: 2.4723190391051526
Validation loss: 2.4957390713815926

Epoch: 5| Step: 5
Training loss: 1.7962008331089616
Validation loss: 2.5357199118314857

Epoch: 5| Step: 6
Training loss: 2.086030536534168
Validation loss: 2.523551823273998

Epoch: 5| Step: 7
Training loss: 3.048388608914866
Validation loss: 2.5696644646045437

Epoch: 5| Step: 8
Training loss: 2.6290323077016313
Validation loss: 2.524378019752225

Epoch: 5| Step: 9
Training loss: 2.646977024746787
Validation loss: 2.537358481918691

Epoch: 5| Step: 10
Training loss: 2.7286387410987643
Validation loss: 2.546624095865136

Epoch: 248| Step: 0
Training loss: 2.984147307812421
Validation loss: 2.5714380098001373

Epoch: 5| Step: 1
Training loss: 2.8330340694879395
Validation loss: 2.5468840260122088

Epoch: 5| Step: 2
Training loss: 2.3745960092772394
Validation loss: 2.5529099007140053

Epoch: 5| Step: 3
Training loss: 2.629449433981703
Validation loss: 2.5502337924640295

Epoch: 5| Step: 4
Training loss: 2.5194747563615545
Validation loss: 2.56275604713601

Epoch: 5| Step: 5
Training loss: 1.5673342878489398
Validation loss: 2.522212626866748

Epoch: 5| Step: 6
Training loss: 2.5568508122991807
Validation loss: 2.5313720430632634

Epoch: 5| Step: 7
Training loss: 2.4055940799207693
Validation loss: 2.537152959689903

Epoch: 5| Step: 8
Training loss: 2.223633777482498
Validation loss: 2.5492663053237203

Epoch: 5| Step: 9
Training loss: 2.8233181901305717
Validation loss: 2.5828887298512844

Epoch: 5| Step: 10
Training loss: 2.780961182417693
Validation loss: 2.5172522714801517

Epoch: 249| Step: 0
Training loss: 2.844619282756581
Validation loss: 2.536544129933035

Epoch: 5| Step: 1
Training loss: 2.6309306949953846
Validation loss: 2.543672646224723

Epoch: 5| Step: 2
Training loss: 1.9955525420403801
Validation loss: 2.5103557434437067

Epoch: 5| Step: 3
Training loss: 1.6777798487725575
Validation loss: 2.5170406474679363

Epoch: 5| Step: 4
Training loss: 2.74534281940251
Validation loss: 2.5658671688732335

Epoch: 5| Step: 5
Training loss: 2.21099918131164
Validation loss: 2.5185694317603065

Epoch: 5| Step: 6
Training loss: 2.458058444241637
Validation loss: 2.5981582150440623

Epoch: 5| Step: 7
Training loss: 2.3568257081333077
Validation loss: 2.5011928419810134

Epoch: 5| Step: 8
Training loss: 3.421796823941114
Validation loss: 2.512427467830183

Epoch: 5| Step: 9
Training loss: 3.0930142539257384
Validation loss: 2.527948781848956

Epoch: 5| Step: 10
Training loss: 2.266519725000945
Validation loss: 2.550756019317123

Epoch: 250| Step: 0
Training loss: 2.850152490116791
Validation loss: 2.5273681746967114

Epoch: 5| Step: 1
Training loss: 2.5341632232425186
Validation loss: 2.5209016525406227

Epoch: 5| Step: 2
Training loss: 2.1503379600513366
Validation loss: 2.5397137176424196

Epoch: 5| Step: 3
Training loss: 2.174224899562921
Validation loss: 2.57369646385902

Epoch: 5| Step: 4
Training loss: 3.3955979684968107
Validation loss: 2.5688102085366964

Epoch: 5| Step: 5
Training loss: 2.9269683018861996
Validation loss: 2.5634740993411747

Epoch: 5| Step: 6
Training loss: 2.905903949439262
Validation loss: 2.493629340140148

Epoch: 5| Step: 7
Training loss: 2.4604011072177716
Validation loss: 2.504441172204909

Epoch: 5| Step: 8
Training loss: 1.860029986765337
Validation loss: 2.5448365747498625

Epoch: 5| Step: 9
Training loss: 2.0166506264839468
Validation loss: 2.5239008493948383

Epoch: 5| Step: 10
Training loss: 2.40320940005906
Validation loss: 2.528616512253585

Epoch: 251| Step: 0
Training loss: 2.5675997346786694
Validation loss: 2.4901034528855237

Epoch: 5| Step: 1
Training loss: 2.50876530405498
Validation loss: 2.5460488883108208

Epoch: 5| Step: 2
Training loss: 2.1600491874887027
Validation loss: 2.5187635227138485

Epoch: 5| Step: 3
Training loss: 2.063847188526886
Validation loss: 2.4944986047985838

Epoch: 5| Step: 4
Training loss: 2.573277395394811
Validation loss: 2.573355679926927

Epoch: 5| Step: 5
Training loss: 2.099326039203576
Validation loss: 2.5312857970321176

Epoch: 5| Step: 6
Training loss: 2.7239853886171823
Validation loss: 2.573492978948804

Epoch: 5| Step: 7
Training loss: 2.856165183913615
Validation loss: 2.5003813637296846

Epoch: 5| Step: 8
Training loss: 2.14488097849887
Validation loss: 2.554478124236141

Epoch: 5| Step: 9
Training loss: 2.813301989334049
Validation loss: 2.543465771547674

Epoch: 5| Step: 10
Training loss: 3.3496486650392483
Validation loss: 2.57099597215886

Epoch: 252| Step: 0
Training loss: 2.6785244656033464
Validation loss: 2.5344299624026183

Epoch: 5| Step: 1
Training loss: 2.4378121005056617
Validation loss: 2.528960536180617

Epoch: 5| Step: 2
Training loss: 2.4717545394385065
Validation loss: 2.5203988727930833

Epoch: 5| Step: 3
Training loss: 3.3025839312830407
Validation loss: 2.5222460670362588

Epoch: 5| Step: 4
Training loss: 2.136917132943823
Validation loss: 2.585447406664553

Epoch: 5| Step: 5
Training loss: 2.3975513324671875
Validation loss: 2.55070989408109

Epoch: 5| Step: 6
Training loss: 2.2944991091645224
Validation loss: 2.523887344008089

Epoch: 5| Step: 7
Training loss: 2.8736964048454525
Validation loss: 2.548411295706988

Epoch: 5| Step: 8
Training loss: 2.0476361672159964
Validation loss: 2.5325674560410985

Epoch: 5| Step: 9
Training loss: 2.072780879443901
Validation loss: 2.5894473321597378

Epoch: 5| Step: 10
Training loss: 2.3564315523582913
Validation loss: 2.534413550347598

Epoch: 253| Step: 0
Training loss: 3.0149276006049712
Validation loss: 2.5295873863693976

Epoch: 5| Step: 1
Training loss: 2.0745935478605113
Validation loss: 2.495915702619128

Epoch: 5| Step: 2
Training loss: 2.1646276073560164
Validation loss: 2.4861370629628343

Epoch: 5| Step: 3
Training loss: 2.0958276944498557
Validation loss: 2.563153858536407

Epoch: 5| Step: 4
Training loss: 3.0403425565761704
Validation loss: 2.533057886502905

Epoch: 5| Step: 5
Training loss: 2.786117409263415
Validation loss: 2.5553578665087326

Epoch: 5| Step: 6
Training loss: 2.2154759710683725
Validation loss: 2.552545170101041

Epoch: 5| Step: 7
Training loss: 2.143032641263258
Validation loss: 2.52348609765006

Epoch: 5| Step: 8
Training loss: 2.9057797287318907
Validation loss: 2.5499096478213774

Epoch: 5| Step: 9
Training loss: 2.434790646054051
Validation loss: 2.538607612545823

Epoch: 5| Step: 10
Training loss: 2.642699109879455
Validation loss: 2.5364898274051106

Epoch: 254| Step: 0
Training loss: 3.124631783726606
Validation loss: 2.549746518904638

Epoch: 5| Step: 1
Training loss: 1.940039969455296
Validation loss: 2.4976469584727496

Epoch: 5| Step: 2
Training loss: 2.3170712627701744
Validation loss: 2.5528812134761623

Epoch: 5| Step: 3
Training loss: 2.7864424850631133
Validation loss: 2.5753162306537885

Epoch: 5| Step: 4
Training loss: 2.320340756844726
Validation loss: 2.5696575468499736

Epoch: 5| Step: 5
Training loss: 2.527818213711149
Validation loss: 2.5212077289319823

Epoch: 5| Step: 6
Training loss: 2.309450045593548
Validation loss: 2.4936502706528807

Epoch: 5| Step: 7
Training loss: 2.6179727315801284
Validation loss: 2.5082424264131316

Epoch: 5| Step: 8
Training loss: 2.795986780389142
Validation loss: 2.4837676926280423

Epoch: 5| Step: 9
Training loss: 2.1951977031192498
Validation loss: 2.5380892222406106

Epoch: 5| Step: 10
Training loss: 3.2038192368853644
Validation loss: 2.528751638773252

Epoch: 255| Step: 0
Training loss: 2.41581460028556
Validation loss: 2.528112389427234

Epoch: 5| Step: 1
Training loss: 3.372780387878944
Validation loss: 2.5741025259301455

Epoch: 5| Step: 2
Training loss: 2.8396289854421792
Validation loss: 2.5277374813454836

Epoch: 5| Step: 3
Training loss: 2.6162291636869788
Validation loss: 2.561657892014219

Epoch: 5| Step: 4
Training loss: 2.234038854536031
Validation loss: 2.5367816857830268

Epoch: 5| Step: 5
Training loss: 2.6803189526258206
Validation loss: 2.5699833833988732

Epoch: 5| Step: 6
Training loss: 2.530707689754039
Validation loss: 2.5183241914764403

Epoch: 5| Step: 7
Training loss: 2.1076878334771143
Validation loss: 2.552093145884438

Epoch: 5| Step: 8
Training loss: 2.321944462390473
Validation loss: 2.5260337813397764

Epoch: 5| Step: 9
Training loss: 2.1421946318860354
Validation loss: 2.529335070399369

Epoch: 5| Step: 10
Training loss: 2.295133696175256
Validation loss: 2.528295707387246

Epoch: 256| Step: 0
Training loss: 2.203806886593287
Validation loss: 2.5092879562719097

Epoch: 5| Step: 1
Training loss: 2.591445266572519
Validation loss: 2.5674221987049313

Epoch: 5| Step: 2
Training loss: 2.8420168447404697
Validation loss: 2.5236030955288014

Epoch: 5| Step: 3
Training loss: 2.902032560811265
Validation loss: 2.563565974663163

Epoch: 5| Step: 4
Training loss: 1.9445701316296544
Validation loss: 2.500365724782175

Epoch: 5| Step: 5
Training loss: 2.409220855571446
Validation loss: 2.5176405773593156

Epoch: 5| Step: 6
Training loss: 2.5198138884286903
Validation loss: 2.527583019492124

Epoch: 5| Step: 7
Training loss: 2.6837825347818782
Validation loss: 2.520807510348124

Epoch: 5| Step: 8
Training loss: 2.1752968596521036
Validation loss: 2.582539575067051

Epoch: 5| Step: 9
Training loss: 2.6956726718139303
Validation loss: 2.561608767049844

Epoch: 5| Step: 10
Training loss: 3.0935944797459713
Validation loss: 2.5795037613502214

Epoch: 257| Step: 0
Training loss: 2.7901327179546977
Validation loss: 2.4867642925365874

Epoch: 5| Step: 1
Training loss: 2.025912858518065
Validation loss: 2.562836340583996

Epoch: 5| Step: 2
Training loss: 2.127390582703546
Validation loss: 2.4994864120843183

Epoch: 5| Step: 3
Training loss: 2.366245900839244
Validation loss: 2.5612330242112034

Epoch: 5| Step: 4
Training loss: 2.8074558377550347
Validation loss: 2.508874478637995

Epoch: 5| Step: 5
Training loss: 2.121783009306164
Validation loss: 2.567574697222424

Epoch: 5| Step: 6
Training loss: 2.857219613270396
Validation loss: 2.5313433467010094

Epoch: 5| Step: 7
Training loss: 3.014464950785489
Validation loss: 2.528291516605489

Epoch: 5| Step: 8
Training loss: 2.658781931783577
Validation loss: 2.5893634991873817

Epoch: 5| Step: 9
Training loss: 2.7908152140586084
Validation loss: 2.560678266193773

Epoch: 5| Step: 10
Training loss: 1.739518931523501
Validation loss: 2.5435596385261685

Epoch: 258| Step: 0
Training loss: 2.5812825604987553
Validation loss: 2.5643218682388116

Epoch: 5| Step: 1
Training loss: 2.2509275220051106
Validation loss: 2.5189769560280006

Epoch: 5| Step: 2
Training loss: 2.0969108521627056
Validation loss: 2.5181787148164365

Epoch: 5| Step: 3
Training loss: 2.4970868303679823
Validation loss: 2.5778843523452606

Epoch: 5| Step: 4
Training loss: 2.3167520557648427
Validation loss: 2.5697934762176433

Epoch: 5| Step: 5
Training loss: 2.3194864260388792
Validation loss: 2.5798567806549406

Epoch: 5| Step: 6
Training loss: 2.796016113704151
Validation loss: 2.5411440209229337

Epoch: 5| Step: 7
Training loss: 2.326773949129021
Validation loss: 2.567707954268097

Epoch: 5| Step: 8
Training loss: 2.7160483782003237
Validation loss: 2.552833854275437

Epoch: 5| Step: 9
Training loss: 2.861905505152531
Validation loss: 2.510292626796552

Epoch: 5| Step: 10
Training loss: 3.3095723295951363
Validation loss: 2.590732681069299

Epoch: 259| Step: 0
Training loss: 2.618853684878698
Validation loss: 2.5012841515676802

Epoch: 5| Step: 1
Training loss: 2.2188983921341414
Validation loss: 2.5351465436350584

Epoch: 5| Step: 2
Training loss: 2.107785226293387
Validation loss: 2.526275720505515

Epoch: 5| Step: 3
Training loss: 2.7671809587880585
Validation loss: 2.543507308087748

Epoch: 5| Step: 4
Training loss: 2.910085300886395
Validation loss: 2.5473305396543138

Epoch: 5| Step: 5
Training loss: 2.5340249192563897
Validation loss: 2.5193519181875645

Epoch: 5| Step: 6
Training loss: 2.6794796521068576
Validation loss: 2.5784033800605908

Epoch: 5| Step: 7
Training loss: 1.808507929634004
Validation loss: 2.5584303932046795

Epoch: 5| Step: 8
Training loss: 3.164724172472159
Validation loss: 2.542002990703986

Epoch: 5| Step: 9
Training loss: 2.3997953963486007
Validation loss: 2.5180024728999166

Epoch: 5| Step: 10
Training loss: 2.129292472312741
Validation loss: 2.5746575448887685

Epoch: 260| Step: 0
Training loss: 3.3686517421568714
Validation loss: 2.5425794815851535

Epoch: 5| Step: 1
Training loss: 2.390442485948049
Validation loss: 2.5410679855652867

Epoch: 5| Step: 2
Training loss: 2.6090952100769687
Validation loss: 2.554475750752155

Epoch: 5| Step: 3
Training loss: 2.185133607738207
Validation loss: 2.5068101561108813

Epoch: 5| Step: 4
Training loss: 2.552619306893947
Validation loss: 2.5023564359303854

Epoch: 5| Step: 5
Training loss: 2.3586769334466497
Validation loss: 2.565563620535476

Epoch: 5| Step: 6
Training loss: 2.3414578228152965
Validation loss: 2.52035972975588

Epoch: 5| Step: 7
Training loss: 2.2263661080464967
Validation loss: 2.5632340075019924

Epoch: 5| Step: 8
Training loss: 2.7501836195245355
Validation loss: 2.4787406903563496

Epoch: 5| Step: 9
Training loss: 2.6846546813429546
Validation loss: 2.54181041509399

Epoch: 5| Step: 10
Training loss: 2.19773714558775
Validation loss: 2.5399647987319116

Epoch: 261| Step: 0
Training loss: 2.8690490500298265
Validation loss: 2.5163603033944804

Epoch: 5| Step: 1
Training loss: 2.4418908698701554
Validation loss: 2.527111564119896

Epoch: 5| Step: 2
Training loss: 2.638305819382608
Validation loss: 2.508518503348031

Epoch: 5| Step: 3
Training loss: 2.2305648435613317
Validation loss: 2.5152447703013747

Epoch: 5| Step: 4
Training loss: 2.2022398124058187
Validation loss: 2.5630013925528266

Epoch: 5| Step: 5
Training loss: 2.021879325284267
Validation loss: 2.5111441725892334

Epoch: 5| Step: 6
Training loss: 2.682050102738775
Validation loss: 2.519167882229666

Epoch: 5| Step: 7
Training loss: 2.0014234484123383
Validation loss: 2.518737184522519

Epoch: 5| Step: 8
Training loss: 2.735243305214493
Validation loss: 2.579735612234583

Epoch: 5| Step: 9
Training loss: 3.2447924340963095
Validation loss: 2.5447850049717498

Epoch: 5| Step: 10
Training loss: 2.6242650229260343
Validation loss: 2.5538638371636178

Epoch: 262| Step: 0
Training loss: 2.4878115128264944
Validation loss: 2.5589471533652945

Epoch: 5| Step: 1
Training loss: 2.538074195426619
Validation loss: 2.545652175364742

Epoch: 5| Step: 2
Training loss: 2.2549552393697927
Validation loss: 2.546159031750963

Epoch: 5| Step: 3
Training loss: 3.352098115390944
Validation loss: 2.5549356370732994

Epoch: 5| Step: 4
Training loss: 2.354002842787174
Validation loss: 2.553685617302747

Epoch: 5| Step: 5
Training loss: 2.4434285569554834
Validation loss: 2.5516217331420883

Epoch: 5| Step: 6
Training loss: 2.719879792586541
Validation loss: 2.5499205300842256

Epoch: 5| Step: 7
Training loss: 2.0835993660506777
Validation loss: 2.5155448149218165

Epoch: 5| Step: 8
Training loss: 2.5663741064744094
Validation loss: 2.576244168604908

Epoch: 5| Step: 9
Training loss: 2.71517656879689
Validation loss: 2.525106928496548

Epoch: 5| Step: 10
Training loss: 2.1254150882793112
Validation loss: 2.4991300648514048

Epoch: 263| Step: 0
Training loss: 2.945306671703451
Validation loss: 2.538768909477815

Epoch: 5| Step: 1
Training loss: 2.8461627157077065
Validation loss: 2.5708859454751467

Epoch: 5| Step: 2
Training loss: 2.3451211606021665
Validation loss: 2.5669581552059175

Epoch: 5| Step: 3
Training loss: 2.7469724114931324
Validation loss: 2.4887114086201856

Epoch: 5| Step: 4
Training loss: 2.425916290210141
Validation loss: 2.5406974280553336

Epoch: 5| Step: 5
Training loss: 2.3551035229390163
Validation loss: 2.514843018639014

Epoch: 5| Step: 6
Training loss: 2.135848012638835
Validation loss: 2.541230780795338

Epoch: 5| Step: 7
Training loss: 2.465753015789596
Validation loss: 2.552627870696223

Epoch: 5| Step: 8
Training loss: 1.974187396471913
Validation loss: 2.5251730916311583

Epoch: 5| Step: 9
Training loss: 2.7942553137887156
Validation loss: 2.4861414846342833

Epoch: 5| Step: 10
Training loss: 2.906229654876704
Validation loss: 2.5384699718392048

Epoch: 264| Step: 0
Training loss: 2.5957811973891864
Validation loss: 2.5485703687471917

Epoch: 5| Step: 1
Training loss: 2.1406069566843353
Validation loss: 2.5465151977249207

Epoch: 5| Step: 2
Training loss: 2.7185295278669086
Validation loss: 2.482569132024048

Epoch: 5| Step: 3
Training loss: 1.9599487121839387
Validation loss: 2.5414631192345594

Epoch: 5| Step: 4
Training loss: 2.3028579950517
Validation loss: 2.4991290482703064

Epoch: 5| Step: 5
Training loss: 2.308828687251173
Validation loss: 2.576185795915876

Epoch: 5| Step: 6
Training loss: 2.0539172219048303
Validation loss: 2.5486671800207343

Epoch: 5| Step: 7
Training loss: 3.001368846136963
Validation loss: 2.520178871011427

Epoch: 5| Step: 8
Training loss: 2.5676260129617288
Validation loss: 2.5812356022163563

Epoch: 5| Step: 9
Training loss: 3.1386524287667656
Validation loss: 2.548773735162909

Epoch: 5| Step: 10
Training loss: 2.483646885920555
Validation loss: 2.596901463754245

Epoch: 265| Step: 0
Training loss: 2.836537867698955
Validation loss: 2.5501342238252285

Epoch: 5| Step: 1
Training loss: 2.5190169881540867
Validation loss: 2.5830990228235775

Epoch: 5| Step: 2
Training loss: 2.5127264347810256
Validation loss: 2.5120916615235296

Epoch: 5| Step: 3
Training loss: 2.0876551496218614
Validation loss: 2.4918613467943054

Epoch: 5| Step: 4
Training loss: 2.1168214826461136
Validation loss: 2.491814792910985

Epoch: 5| Step: 5
Training loss: 2.996594403349989
Validation loss: 2.519291847723755

Epoch: 5| Step: 6
Training loss: 2.422777561470661
Validation loss: 2.544401034103238

Epoch: 5| Step: 7
Training loss: 2.873066625261398
Validation loss: 2.554335730362589

Epoch: 5| Step: 8
Training loss: 2.5459662378294574
Validation loss: 2.5401092456646235

Epoch: 5| Step: 9
Training loss: 2.0591479718995966
Validation loss: 2.5627030603052368

Epoch: 5| Step: 10
Training loss: 2.0580960274657407
Validation loss: 2.502835606798182

Epoch: 266| Step: 0
Training loss: 2.4805054669403566
Validation loss: 2.509001906671475

Epoch: 5| Step: 1
Training loss: 3.43529550783266
Validation loss: 2.561557259208759

Epoch: 5| Step: 2
Training loss: 2.6519818290789883
Validation loss: 2.5234041081296184

Epoch: 5| Step: 3
Training loss: 2.4417545649967307
Validation loss: 2.5592140541104125

Epoch: 5| Step: 4
Training loss: 2.655170355897235
Validation loss: 2.5737942225386794

Epoch: 5| Step: 5
Training loss: 2.6540832658137457
Validation loss: 2.503555470629057

Epoch: 5| Step: 6
Training loss: 2.0707737822640144
Validation loss: 2.5188930824120477

Epoch: 5| Step: 7
Training loss: 2.3145176101907934
Validation loss: 2.5015819907307413

Epoch: 5| Step: 8
Training loss: 2.3687669375979103
Validation loss: 2.5398206176303955

Epoch: 5| Step: 9
Training loss: 2.679013092322288
Validation loss: 2.531741259813997

Epoch: 5| Step: 10
Training loss: 1.7736987623108997
Validation loss: 2.5062577550354472

Epoch: 267| Step: 0
Training loss: 2.8261639450584153
Validation loss: 2.5343950736350913

Epoch: 5| Step: 1
Training loss: 2.5640090592770313
Validation loss: 2.5335642501199724

Epoch: 5| Step: 2
Training loss: 2.38819033244104
Validation loss: 2.5408022681743985

Epoch: 5| Step: 3
Training loss: 2.2934634245340155
Validation loss: 2.4967087584942855

Epoch: 5| Step: 4
Training loss: 2.6231673064602425
Validation loss: 2.5254339348250703

Epoch: 5| Step: 5
Training loss: 2.1953852631263255
Validation loss: 2.569386511647243

Epoch: 5| Step: 6
Training loss: 2.881326100964217
Validation loss: 2.533170178623613

Epoch: 5| Step: 7
Training loss: 2.396316236397395
Validation loss: 2.5722590127374514

Epoch: 5| Step: 8
Training loss: 3.066091494594161
Validation loss: 2.5804761063413384

Epoch: 5| Step: 9
Training loss: 2.086892812903631
Validation loss: 2.5316642403034195

Epoch: 5| Step: 10
Training loss: 1.9465607464510384
Validation loss: 2.523042111000407

Epoch: 268| Step: 0
Training loss: 2.4594665975611547
Validation loss: 2.50068287854616

Epoch: 5| Step: 1
Training loss: 2.352380249186231
Validation loss: 2.568907030467233

Epoch: 5| Step: 2
Training loss: 2.542577757419988
Validation loss: 2.574504666306092

Epoch: 5| Step: 3
Training loss: 2.7824781470798743
Validation loss: 2.5542755065689287

Epoch: 5| Step: 4
Training loss: 1.9127838846579999
Validation loss: 2.5816381637201067

Epoch: 5| Step: 5
Training loss: 3.2373995437649086
Validation loss: 2.525013616235409

Epoch: 5| Step: 6
Training loss: 2.625075747895657
Validation loss: 2.5516564305763674

Epoch: 5| Step: 7
Training loss: 2.7471862616615947
Validation loss: 2.535346741456572

Epoch: 5| Step: 8
Training loss: 2.004718697618095
Validation loss: 2.523833200861463

Epoch: 5| Step: 9
Training loss: 2.5763875944734687
Validation loss: 2.53096657334346

Epoch: 5| Step: 10
Training loss: 2.373226105628686
Validation loss: 2.5440305589939913

Epoch: 269| Step: 0
Training loss: 2.820400585373485
Validation loss: 2.5498050997247406

Epoch: 5| Step: 1
Training loss: 2.429450118559868
Validation loss: 2.5404921739243624

Epoch: 5| Step: 2
Training loss: 3.0171650329101043
Validation loss: 2.5355328385829248

Epoch: 5| Step: 3
Training loss: 2.2542845939020113
Validation loss: 2.523088937124247

Epoch: 5| Step: 4
Training loss: 2.151902169070765
Validation loss: 2.5484166253623335

Epoch: 5| Step: 5
Training loss: 2.6196294978301986
Validation loss: 2.486825453862462

Epoch: 5| Step: 6
Training loss: 2.2855786577074144
Validation loss: 2.5215454648273923

Epoch: 5| Step: 7
Training loss: 2.457135754714409
Validation loss: 2.545283035622159

Epoch: 5| Step: 8
Training loss: 2.9466730916340143
Validation loss: 2.528491547962086

Epoch: 5| Step: 9
Training loss: 1.8611945857912302
Validation loss: 2.54512530328734

Epoch: 5| Step: 10
Training loss: 2.190429469808839
Validation loss: 2.5609955952381083

Epoch: 270| Step: 0
Training loss: 1.7238919417244671
Validation loss: 2.5259235458911258

Epoch: 5| Step: 1
Training loss: 2.9133440620114244
Validation loss: 2.5534199378611895

Epoch: 5| Step: 2
Training loss: 2.6193761072541037
Validation loss: 2.564735424988239

Epoch: 5| Step: 3
Training loss: 2.5178582366353512
Validation loss: 2.5387652843048354

Epoch: 5| Step: 4
Training loss: 2.728758880978233
Validation loss: 2.546234292855771

Epoch: 5| Step: 5
Training loss: 2.5012489060338043
Validation loss: 2.514202627122739

Epoch: 5| Step: 6
Training loss: 2.5364369124513915
Validation loss: 2.5222165543309107

Epoch: 5| Step: 7
Training loss: 2.5498451746893327
Validation loss: 2.4970734037694515

Epoch: 5| Step: 8
Training loss: 2.5991914041982285
Validation loss: 2.54417616967973

Epoch: 5| Step: 9
Training loss: 2.5699304917134955
Validation loss: 2.5280718695619497

Epoch: 5| Step: 10
Training loss: 2.0955476018786836
Validation loss: 2.515363633418596

Epoch: 271| Step: 0
Training loss: 2.653651054359718
Validation loss: 2.569549333544691

Epoch: 5| Step: 1
Training loss: 2.7301136053293003
Validation loss: 2.5314471103374

Epoch: 5| Step: 2
Training loss: 2.3493580164476895
Validation loss: 2.549838679730438

Epoch: 5| Step: 3
Training loss: 1.9397948425985854
Validation loss: 2.5326146283698576

Epoch: 5| Step: 4
Training loss: 2.0134294957865233
Validation loss: 2.5581935980154573

Epoch: 5| Step: 5
Training loss: 2.2759530219675286
Validation loss: 2.4851442934904457

Epoch: 5| Step: 6
Training loss: 2.97493348888772
Validation loss: 2.513367467623268

Epoch: 5| Step: 7
Training loss: 2.6801446018778723
Validation loss: 2.5169354307562104

Epoch: 5| Step: 8
Training loss: 1.8553689066475807
Validation loss: 2.5627790189595543

Epoch: 5| Step: 9
Training loss: 2.624555550142712
Validation loss: 2.543013119388074

Epoch: 5| Step: 10
Training loss: 3.1380569814707826
Validation loss: 2.5286063392511715

Epoch: 272| Step: 0
Training loss: 2.764125438984969
Validation loss: 2.5201186117188574

Epoch: 5| Step: 1
Training loss: 2.105327537769428
Validation loss: 2.5227393444265243

Epoch: 5| Step: 2
Training loss: 3.3480262863421615
Validation loss: 2.5152324038197253

Epoch: 5| Step: 3
Training loss: 2.209215767611061
Validation loss: 2.5707656037579807

Epoch: 5| Step: 4
Training loss: 2.7008548089852495
Validation loss: 2.5331835535581044

Epoch: 5| Step: 5
Training loss: 2.8405139662189933
Validation loss: 2.4982181618534054

Epoch: 5| Step: 6
Training loss: 2.14423172323384
Validation loss: 2.5292495647729507

Epoch: 5| Step: 7
Training loss: 1.762287124331502
Validation loss: 2.5598570407073793

Epoch: 5| Step: 8
Training loss: 2.3613495301190706
Validation loss: 2.5799939304540196

Epoch: 5| Step: 9
Training loss: 2.2780728097387377
Validation loss: 2.529688846067106

Epoch: 5| Step: 10
Training loss: 2.4273553676713955
Validation loss: 2.5392719212093144

Epoch: 273| Step: 0
Training loss: 1.820602852254161
Validation loss: 2.5353040064509225

Epoch: 5| Step: 1
Training loss: 2.2929660465672947
Validation loss: 2.5741671852483075

Epoch: 5| Step: 2
Training loss: 2.421914180315637
Validation loss: 2.506386685694162

Epoch: 5| Step: 3
Training loss: 2.762783077460003
Validation loss: 2.513579784377439

Epoch: 5| Step: 4
Training loss: 2.2314420003052553
Validation loss: 2.5293333919383576

Epoch: 5| Step: 5
Training loss: 2.672777168596131
Validation loss: 2.5634287949978614

Epoch: 5| Step: 6
Training loss: 2.8155038686897473
Validation loss: 2.569506977816594

Epoch: 5| Step: 7
Training loss: 2.826248389357083
Validation loss: 2.514838032220177

Epoch: 5| Step: 8
Training loss: 2.534419018684177
Validation loss: 2.505582448464582

Epoch: 5| Step: 9
Training loss: 2.6822581958842866
Validation loss: 2.528798457509428

Epoch: 5| Step: 10
Training loss: 2.307274972641415
Validation loss: 2.510640250085312

Epoch: 274| Step: 0
Training loss: 2.6955240802372127
Validation loss: 2.578133895724435

Epoch: 5| Step: 1
Training loss: 2.354936479493392
Validation loss: 2.5222809165064892

Epoch: 5| Step: 2
Training loss: 2.5756174550898234
Validation loss: 2.5665009485916337

Epoch: 5| Step: 3
Training loss: 2.4891053276903383
Validation loss: 2.536323727910524

Epoch: 5| Step: 4
Training loss: 2.7751237927567325
Validation loss: 2.558767109420804

Epoch: 5| Step: 5
Training loss: 2.647101681493234
Validation loss: 2.5630792462834813

Epoch: 5| Step: 6
Training loss: 2.4725907785627697
Validation loss: 2.5138370868753754

Epoch: 5| Step: 7
Training loss: 2.270750785050534
Validation loss: 2.5687345729398863

Epoch: 5| Step: 8
Training loss: 2.4974826536444907
Validation loss: 2.5157824429894746

Epoch: 5| Step: 9
Training loss: 2.140093660889722
Validation loss: 2.5125889409505335

Epoch: 5| Step: 10
Training loss: 2.715949271170763
Validation loss: 2.538040566837954

Epoch: 275| Step: 0
Training loss: 3.1176165522100003
Validation loss: 2.5300277631410872

Epoch: 5| Step: 1
Training loss: 2.268657259976621
Validation loss: 2.4886288379424344

Epoch: 5| Step: 2
Training loss: 2.19709092187418
Validation loss: 2.5341526127179677

Epoch: 5| Step: 3
Training loss: 2.5542611515891593
Validation loss: 2.5567845068311508

Epoch: 5| Step: 4
Training loss: 2.8894324239659968
Validation loss: 2.564518690382074

Epoch: 5| Step: 5
Training loss: 2.5173678787549716
Validation loss: 2.4775094663218677

Epoch: 5| Step: 6
Training loss: 2.6314042397278428
Validation loss: 2.5406475804615085

Epoch: 5| Step: 7
Training loss: 2.17550893069034
Validation loss: 2.5607328526890827

Epoch: 5| Step: 8
Training loss: 2.1176962153333068
Validation loss: 2.539102313389779

Epoch: 5| Step: 9
Training loss: 2.2287517292146504
Validation loss: 2.543925937577784

Epoch: 5| Step: 10
Training loss: 2.508662284834407
Validation loss: 2.545505009512728

Epoch: 276| Step: 0
Training loss: 2.154926612648816
Validation loss: 2.5327807241338585

Epoch: 5| Step: 1
Training loss: 2.16194065335079
Validation loss: 2.515346731067549

Epoch: 5| Step: 2
Training loss: 2.618510626365802
Validation loss: 2.5412001195895635

Epoch: 5| Step: 3
Training loss: 2.8803147657893944
Validation loss: 2.5445910893845918

Epoch: 5| Step: 4
Training loss: 2.3357138638310615
Validation loss: 2.576616842354925

Epoch: 5| Step: 5
Training loss: 2.0717370080808655
Validation loss: 2.5265156253801613

Epoch: 5| Step: 6
Training loss: 2.4995146280231895
Validation loss: 2.511031632602927

Epoch: 5| Step: 7
Training loss: 2.2001982382845062
Validation loss: 2.5357240761822313

Epoch: 5| Step: 8
Training loss: 2.306631115692719
Validation loss: 2.517062445605903

Epoch: 5| Step: 9
Training loss: 2.5120812328045328
Validation loss: 2.511052736595485

Epoch: 5| Step: 10
Training loss: 3.2426026595547386
Validation loss: 2.5558152384150064

Epoch: 277| Step: 0
Training loss: 2.4055185568677917
Validation loss: 2.525890403069241

Epoch: 5| Step: 1
Training loss: 2.438787853703871
Validation loss: 2.53783368055975

Epoch: 5| Step: 2
Training loss: 2.2791705125105617
Validation loss: 2.500049633640916

Epoch: 5| Step: 3
Training loss: 2.2836816447801587
Validation loss: 2.4785158980671067

Epoch: 5| Step: 4
Training loss: 2.2183336753854506
Validation loss: 2.5050398550550814

Epoch: 5| Step: 5
Training loss: 2.8424433126978768
Validation loss: 2.548671321204803

Epoch: 5| Step: 6
Training loss: 2.255580022780451
Validation loss: 2.5558183950485445

Epoch: 5| Step: 7
Training loss: 2.5678375294173366
Validation loss: 2.5043569504774847

Epoch: 5| Step: 8
Training loss: 2.4788628613762107
Validation loss: 2.551948138622503

Epoch: 5| Step: 9
Training loss: 2.574441023218681
Validation loss: 2.566188199955793

Epoch: 5| Step: 10
Training loss: 2.594211858969882
Validation loss: 2.5823307013571437

Epoch: 278| Step: 0
Training loss: 2.2567557531528366
Validation loss: 2.530007026166821

Epoch: 5| Step: 1
Training loss: 2.3652335685898707
Validation loss: 2.562572996438919

Epoch: 5| Step: 2
Training loss: 2.4224133293150474
Validation loss: 2.5215631918450567

Epoch: 5| Step: 3
Training loss: 2.662238875644643
Validation loss: 2.5209616724422164

Epoch: 5| Step: 4
Training loss: 2.556652561564954
Validation loss: 2.534513218690775

Epoch: 5| Step: 5
Training loss: 2.622208882511641
Validation loss: 2.5043669097646957

Epoch: 5| Step: 6
Training loss: 2.545035979610545
Validation loss: 2.593999681391339

Epoch: 5| Step: 7
Training loss: 2.452524488289897
Validation loss: 2.5517785595815936

Epoch: 5| Step: 8
Training loss: 2.3618072705173994
Validation loss: 2.5624343839658725

Epoch: 5| Step: 9
Training loss: 2.685716081317197
Validation loss: 2.5162864991867933

Epoch: 5| Step: 10
Training loss: 2.0071487220131576
Validation loss: 2.550323127092867

Epoch: 279| Step: 0
Training loss: 2.178735887631679
Validation loss: 2.541482494775069

Epoch: 5| Step: 1
Training loss: 2.4505506480582544
Validation loss: 2.50822335420718

Epoch: 5| Step: 2
Training loss: 2.2089432527878268
Validation loss: 2.525599144673346

Epoch: 5| Step: 3
Training loss: 2.676200889482458
Validation loss: 2.5204740125995384

Epoch: 5| Step: 4
Training loss: 2.785009179639498
Validation loss: 2.532804594867493

Epoch: 5| Step: 5
Training loss: 2.042900711589609
Validation loss: 2.564546784105953

Epoch: 5| Step: 6
Training loss: 2.2680059090256455
Validation loss: 2.5439949574193848

Epoch: 5| Step: 7
Training loss: 2.6012460327118183
Validation loss: 2.5267750693544335

Epoch: 5| Step: 8
Training loss: 2.7165546542363406
Validation loss: 2.550937052782346

Epoch: 5| Step: 9
Training loss: 2.853722660770869
Validation loss: 2.5471519129934976

Epoch: 5| Step: 10
Training loss: 2.4272990860772565
Validation loss: 2.517515987789424

Epoch: 280| Step: 0
Training loss: 2.425180455995105
Validation loss: 2.5487576156328866

Epoch: 5| Step: 1
Training loss: 2.251952489768449
Validation loss: 2.534997797552012

Epoch: 5| Step: 2
Training loss: 2.5516435412906526
Validation loss: 2.549220292416475

Epoch: 5| Step: 3
Training loss: 2.429210750993355
Validation loss: 2.516987680118953

Epoch: 5| Step: 4
Training loss: 2.395564741476011
Validation loss: 2.480995025887297

Epoch: 5| Step: 5
Training loss: 2.2557120403049797
Validation loss: 2.4928871715898713

Epoch: 5| Step: 6
Training loss: 2.630642593843369
Validation loss: 2.559537229760678

Epoch: 5| Step: 7
Training loss: 2.2552706127656164
Validation loss: 2.50539224286558

Epoch: 5| Step: 8
Training loss: 2.2916423333928
Validation loss: 2.5391479003275874

Epoch: 5| Step: 9
Training loss: 2.9403706585531313
Validation loss: 2.542113169265709

Epoch: 5| Step: 10
Training loss: 2.525559705132356
Validation loss: 2.551600635143287

Epoch: 281| Step: 0
Training loss: 2.5526950544205307
Validation loss: 2.5538400252429767

Epoch: 5| Step: 1
Training loss: 2.660393837333198
Validation loss: 2.534639056336913

Epoch: 5| Step: 2
Training loss: 2.3575388856433643
Validation loss: 2.5274249554478914

Epoch: 5| Step: 3
Training loss: 2.9198590019882293
Validation loss: 2.5144766661257387

Epoch: 5| Step: 4
Training loss: 2.444085346442423
Validation loss: 2.5404247865627156

Epoch: 5| Step: 5
Training loss: 2.6815875465602357
Validation loss: 2.551340075196285

Epoch: 5| Step: 6
Training loss: 2.554745174771844
Validation loss: 2.519598025045768

Epoch: 5| Step: 7
Training loss: 2.3102119054659767
Validation loss: 2.541488110305249

Epoch: 5| Step: 8
Training loss: 1.9045875053663284
Validation loss: 2.4979990221827872

Epoch: 5| Step: 9
Training loss: 1.7441921589618596
Validation loss: 2.5522362213514174

Epoch: 5| Step: 10
Training loss: 2.912682746098336
Validation loss: 2.5569263271887963

Epoch: 282| Step: 0
Training loss: 2.5544709746734684
Validation loss: 2.534441306636157

Epoch: 5| Step: 1
Training loss: 2.438362360286312
Validation loss: 2.5802309247287334

Epoch: 5| Step: 2
Training loss: 2.473232883031292
Validation loss: 2.5356219156780693

Epoch: 5| Step: 3
Training loss: 2.6140251526384954
Validation loss: 2.527712844189817

Epoch: 5| Step: 4
Training loss: 1.8671345723204247
Validation loss: 2.538485232124264

Epoch: 5| Step: 5
Training loss: 3.022350026993721
Validation loss: 2.5318195143405755

Epoch: 5| Step: 6
Training loss: 2.5006753962862818
Validation loss: 2.5254130819638534

Epoch: 5| Step: 7
Training loss: 2.2229168945236113
Validation loss: 2.5597248021301273

Epoch: 5| Step: 8
Training loss: 2.6970395070068878
Validation loss: 2.5977829004130992

Epoch: 5| Step: 9
Training loss: 2.2217525528916395
Validation loss: 2.517130947281705

Epoch: 5| Step: 10
Training loss: 2.1404975797500954
Validation loss: 2.5122669195731433

Epoch: 283| Step: 0
Training loss: 2.6560426518910707
Validation loss: 2.509841616845389

Epoch: 5| Step: 1
Training loss: 2.4921908483213695
Validation loss: 2.525756882468859

Epoch: 5| Step: 2
Training loss: 2.367070865590435
Validation loss: 2.558568730623769

Epoch: 5| Step: 3
Training loss: 2.179033844536607
Validation loss: 2.5245726217304276

Epoch: 5| Step: 4
Training loss: 3.033914555070037
Validation loss: 2.4803540275049536

Epoch: 5| Step: 5
Training loss: 2.1953648462536934
Validation loss: 2.5848698067614024

Epoch: 5| Step: 6
Training loss: 2.059894997411302
Validation loss: 2.531670903910201

Epoch: 5| Step: 7
Training loss: 2.6937344119158624
Validation loss: 2.5184994005902146

Epoch: 5| Step: 8
Training loss: 1.7866199594532133
Validation loss: 2.497594643231034

Epoch: 5| Step: 9
Training loss: 2.570471761575467
Validation loss: 2.5448581045787084

Epoch: 5| Step: 10
Training loss: 3.00146337421928
Validation loss: 2.55042976885363

Epoch: 284| Step: 0
Training loss: 2.500227917772319
Validation loss: 2.4835835673991613

Epoch: 5| Step: 1
Training loss: 2.4239251104312203
Validation loss: 2.5757138917431113

Epoch: 5| Step: 2
Training loss: 2.4805169048290767
Validation loss: 2.521625511957551

Epoch: 5| Step: 3
Training loss: 2.4088811979409566
Validation loss: 2.534932347461024

Epoch: 5| Step: 4
Training loss: 2.358468292023185
Validation loss: 2.574916481067796

Epoch: 5| Step: 5
Training loss: 2.624701800892745
Validation loss: 2.5443607101631405

Epoch: 5| Step: 6
Training loss: 3.0701147894258716
Validation loss: 2.5478541715675225

Epoch: 5| Step: 7
Training loss: 2.4635567426052205
Validation loss: 2.5649107836047915

Epoch: 5| Step: 8
Training loss: 2.3580002979799297
Validation loss: 2.5363586598907233

Epoch: 5| Step: 9
Training loss: 2.167863832976517
Validation loss: 2.5573674786307095

Epoch: 5| Step: 10
Training loss: 2.194605051539997
Validation loss: 2.566895715246941

Epoch: 285| Step: 0
Training loss: 2.2614760721624667
Validation loss: 2.5197372745301374

Epoch: 5| Step: 1
Training loss: 2.0679249942244717
Validation loss: 2.5163780536956577

Epoch: 5| Step: 2
Training loss: 2.1686935725278103
Validation loss: 2.5542876293254033

Epoch: 5| Step: 3
Training loss: 2.416829125654837
Validation loss: 2.519706899159944

Epoch: 5| Step: 4
Training loss: 2.392262714382098
Validation loss: 2.5087325047687172

Epoch: 5| Step: 5
Training loss: 2.7383935663150476
Validation loss: 2.521726687105482

Epoch: 5| Step: 6
Training loss: 2.8090032244535132
Validation loss: 2.588867527157702

Epoch: 5| Step: 7
Training loss: 2.513371660849287
Validation loss: 2.5561818612996503

Epoch: 5| Step: 8
Training loss: 2.7149169911995474
Validation loss: 2.5583832790187344

Epoch: 5| Step: 9
Training loss: 2.8037742041581795
Validation loss: 2.5061007008244216

Epoch: 5| Step: 10
Training loss: 2.445432324870938
Validation loss: 2.533757986698457

Epoch: 286| Step: 0
Training loss: 2.3489392625890257
Validation loss: 2.5525927907615067

Epoch: 5| Step: 1
Training loss: 2.2324145059138547
Validation loss: 2.541255613750307

Epoch: 5| Step: 2
Training loss: 2.63799448304543
Validation loss: 2.519299296571623

Epoch: 5| Step: 3
Training loss: 2.4724038041921643
Validation loss: 2.556949235083416

Epoch: 5| Step: 4
Training loss: 2.339043532952701
Validation loss: 2.570914201462922

Epoch: 5| Step: 5
Training loss: 2.7427684027360684
Validation loss: 2.510842213496244

Epoch: 5| Step: 6
Training loss: 2.268941096725284
Validation loss: 2.5574740822703865

Epoch: 5| Step: 7
Training loss: 2.443415189085736
Validation loss: 2.5814898963143817

Epoch: 5| Step: 8
Training loss: 2.8037997145035685
Validation loss: 2.500482336295965

Epoch: 5| Step: 9
Training loss: 2.3769505170872094
Validation loss: 2.563471487170155

Epoch: 5| Step: 10
Training loss: 2.3152104551091104
Validation loss: 2.551192942016938

Epoch: 287| Step: 0
Training loss: 3.189718035729951
Validation loss: 2.529682630746452

Epoch: 5| Step: 1
Training loss: 2.2339457919955685
Validation loss: 2.5474316881742367

Epoch: 5| Step: 2
Training loss: 2.32812233739099
Validation loss: 2.4956415731523025

Epoch: 5| Step: 3
Training loss: 2.476128765837622
Validation loss: 2.574096389962902

Epoch: 5| Step: 4
Training loss: 2.9196076597239484
Validation loss: 2.5326187796060986

Epoch: 5| Step: 5
Training loss: 2.571587058133283
Validation loss: 2.5400024209056604

Epoch: 5| Step: 6
Training loss: 2.161016420590611
Validation loss: 2.527975496641956

Epoch: 5| Step: 7
Training loss: 2.492036151176779
Validation loss: 2.50941069148795

Epoch: 5| Step: 8
Training loss: 2.325621417277856
Validation loss: 2.5504694550560534

Epoch: 5| Step: 9
Training loss: 2.4128164884279606
Validation loss: 2.564557554776309

Epoch: 5| Step: 10
Training loss: 1.7658292939141544
Validation loss: 2.4826780480246353

Epoch: 288| Step: 0
Training loss: 1.9968743934690125
Validation loss: 2.552767190393486

Epoch: 5| Step: 1
Training loss: 1.7880330018021053
Validation loss: 2.509966366736238

Epoch: 5| Step: 2
Training loss: 2.537040774127882
Validation loss: 2.516384881563276

Epoch: 5| Step: 3
Training loss: 2.6624057126252163
Validation loss: 2.492690032709015

Epoch: 5| Step: 4
Training loss: 2.4884604205386514
Validation loss: 2.500342491746987

Epoch: 5| Step: 5
Training loss: 2.455203688148719
Validation loss: 2.526529020322182

Epoch: 5| Step: 6
Training loss: 2.125848712853049
Validation loss: 2.5348949069190865

Epoch: 5| Step: 7
Training loss: 3.2153137530920297
Validation loss: 2.559917296929464

Epoch: 5| Step: 8
Training loss: 2.5174317121288383
Validation loss: 2.53395872470845

Epoch: 5| Step: 9
Training loss: 2.091073560277344
Validation loss: 2.5600162176899044

Epoch: 5| Step: 10
Training loss: 2.8037914661839505
Validation loss: 2.5173523473722628

Epoch: 289| Step: 0
Training loss: 2.473125009563254
Validation loss: 2.5133602898567275

Epoch: 5| Step: 1
Training loss: 2.1602509462318955
Validation loss: 2.4883445293442037

Epoch: 5| Step: 2
Training loss: 2.0014223762914995
Validation loss: 2.5434238714677835

Epoch: 5| Step: 3
Training loss: 2.4609894277755537
Validation loss: 2.541358738130581

Epoch: 5| Step: 4
Training loss: 2.7474279513297164
Validation loss: 2.5205334924319227

Epoch: 5| Step: 5
Training loss: 2.7309993288422763
Validation loss: 2.5148065950759664

Epoch: 5| Step: 6
Training loss: 2.4878872210586698
Validation loss: 2.5417293207672387

Epoch: 5| Step: 7
Training loss: 2.180955524842901
Validation loss: 2.5416301789901614

Epoch: 5| Step: 8
Training loss: 2.791593882812322
Validation loss: 2.542927956739477

Epoch: 5| Step: 9
Training loss: 2.2650263554469166
Validation loss: 2.530708158779169

Epoch: 5| Step: 10
Training loss: 2.593960948776615
Validation loss: 2.5357359919099016

Epoch: 290| Step: 0
Training loss: 2.8068771103396792
Validation loss: 2.552833284373005

Epoch: 5| Step: 1
Training loss: 2.5780446357917315
Validation loss: 2.551905089920437

Epoch: 5| Step: 2
Training loss: 2.4307024145414964
Validation loss: 2.523819858652975

Epoch: 5| Step: 3
Training loss: 2.266655312771504
Validation loss: 2.4998524181325514

Epoch: 5| Step: 4
Training loss: 2.0219514906032696
Validation loss: 2.537768285423846

Epoch: 5| Step: 5
Training loss: 2.7728117760801667
Validation loss: 2.501369181372421

Epoch: 5| Step: 6
Training loss: 1.7604518488090204
Validation loss: 2.5555397486929796

Epoch: 5| Step: 7
Training loss: 2.398768896015558
Validation loss: 2.5137396195358903

Epoch: 5| Step: 8
Training loss: 2.6785412886604143
Validation loss: 2.532475616231116

Epoch: 5| Step: 9
Training loss: 2.617348099520995
Validation loss: 2.527699156326587

Epoch: 5| Step: 10
Training loss: 2.4226828919649246
Validation loss: 2.5126768576949647

Epoch: 291| Step: 0
Training loss: 1.8845446205028578
Validation loss: 2.587622558677817

Epoch: 5| Step: 1
Training loss: 2.721927145667573
Validation loss: 2.4889727826483403

Epoch: 5| Step: 2
Training loss: 1.8244646384528043
Validation loss: 2.479956655017678

Epoch: 5| Step: 3
Training loss: 2.7612490760452846
Validation loss: 2.5835551987986425

Epoch: 5| Step: 4
Training loss: 3.0212769982769507
Validation loss: 2.510588125436954

Epoch: 5| Step: 5
Training loss: 2.370028864688784
Validation loss: 2.5128300974375852

Epoch: 5| Step: 6
Training loss: 2.950642829296542
Validation loss: 2.5166645158289787

Epoch: 5| Step: 7
Training loss: 2.8808676509415023
Validation loss: 2.499011898634054

Epoch: 5| Step: 8
Training loss: 2.063301624224945
Validation loss: 2.5379963650656996

Epoch: 5| Step: 9
Training loss: 2.341318725945881
Validation loss: 2.599385253700453

Epoch: 5| Step: 10
Training loss: 1.896402092041426
Validation loss: 2.540207189812754

Epoch: 292| Step: 0
Training loss: 2.8836299905331555
Validation loss: 2.611852219990327

Epoch: 5| Step: 1
Training loss: 2.777336367397449
Validation loss: 2.526597780786007

Epoch: 5| Step: 2
Training loss: 1.9046474036360994
Validation loss: 2.5331787656716163

Epoch: 5| Step: 3
Training loss: 1.8326787068866657
Validation loss: 2.585131866286829

Epoch: 5| Step: 4
Training loss: 2.067674561296014
Validation loss: 2.514485486257792

Epoch: 5| Step: 5
Training loss: 2.812400137929814
Validation loss: 2.522675973601206

Epoch: 5| Step: 6
Training loss: 2.302075163077331
Validation loss: 2.5283851367911327

Epoch: 5| Step: 7
Training loss: 1.954766400129987
Validation loss: 2.56464969116686

Epoch: 5| Step: 8
Training loss: 2.5410876839321466
Validation loss: 2.553851863472327

Epoch: 5| Step: 9
Training loss: 2.3326693225826216
Validation loss: 2.501415043975976

Epoch: 5| Step: 10
Training loss: 2.9051628130199187
Validation loss: 2.5665465348247167

Epoch: 293| Step: 0
Training loss: 2.427859682883364
Validation loss: 2.5761610717840484

Epoch: 5| Step: 1
Training loss: 2.659422203209851
Validation loss: 2.515766176269798

Epoch: 5| Step: 2
Training loss: 2.637245317791073
Validation loss: 2.528359698839109

Epoch: 5| Step: 3
Training loss: 2.4511448345744555
Validation loss: 2.551027918437695

Epoch: 5| Step: 4
Training loss: 2.4289702801195614
Validation loss: 2.5395611754000122

Epoch: 5| Step: 5
Training loss: 1.8844684583980231
Validation loss: 2.5988281922371295

Epoch: 5| Step: 6
Training loss: 2.545990866507594
Validation loss: 2.566307990118123

Epoch: 5| Step: 7
Training loss: 2.7421399408547176
Validation loss: 2.5385554567326434

Epoch: 5| Step: 8
Training loss: 2.2684752326808906
Validation loss: 2.5048699578431504

Epoch: 5| Step: 9
Training loss: 2.2445419656489123
Validation loss: 2.543797800990079

Epoch: 5| Step: 10
Training loss: 2.64909494167532
Validation loss: 2.530374271932767

Epoch: 294| Step: 0
Training loss: 2.2183760206938437
Validation loss: 2.575985234516643

Epoch: 5| Step: 1
Training loss: 2.787875310153702
Validation loss: 2.555073090620325

Epoch: 5| Step: 2
Training loss: 1.9600523512524528
Validation loss: 2.5211825378500774

Epoch: 5| Step: 3
Training loss: 2.507839404761003
Validation loss: 2.5247481080071212

Epoch: 5| Step: 4
Training loss: 1.9370706143956211
Validation loss: 2.523038067970678

Epoch: 5| Step: 5
Training loss: 2.99466405624294
Validation loss: 2.5080752463352423

Epoch: 5| Step: 6
Training loss: 2.8274095167662727
Validation loss: 2.5544421805204895

Epoch: 5| Step: 7
Training loss: 2.1317965704393127
Validation loss: 2.5365459921147653

Epoch: 5| Step: 8
Training loss: 2.9709929977534775
Validation loss: 2.580790292324274

Epoch: 5| Step: 9
Training loss: 2.2245332807030707
Validation loss: 2.509445421922565

Epoch: 5| Step: 10
Training loss: 1.8458308745885221
Validation loss: 2.48687287326663

Epoch: 295| Step: 0
Training loss: 2.022479209651585
Validation loss: 2.614143067486997

Epoch: 5| Step: 1
Training loss: 2.2775357461546477
Validation loss: 2.517413228907178

Epoch: 5| Step: 2
Training loss: 2.290564242984469
Validation loss: 2.516045694874744

Epoch: 5| Step: 3
Training loss: 2.7247381801991115
Validation loss: 2.4939811861733285

Epoch: 5| Step: 4
Training loss: 2.8664839294504776
Validation loss: 2.518994994225542

Epoch: 5| Step: 5
Training loss: 2.84156128211579
Validation loss: 2.555435854290267

Epoch: 5| Step: 6
Training loss: 1.8976890438633767
Validation loss: 2.521782625046149

Epoch: 5| Step: 7
Training loss: 2.3418855499200983
Validation loss: 2.5179071445842345

Epoch: 5| Step: 8
Training loss: 2.448489529288745
Validation loss: 2.529963338637294

Epoch: 5| Step: 9
Training loss: 2.003003011669803
Validation loss: 2.5225358598816148

Epoch: 5| Step: 10
Training loss: 2.9466276192415375
Validation loss: 2.5706850733064637

Epoch: 296| Step: 0
Training loss: 3.006222946457663
Validation loss: 2.545556011804203

Epoch: 5| Step: 1
Training loss: 2.6178629900209605
Validation loss: 2.5180584492854843

Epoch: 5| Step: 2
Training loss: 2.644615634039593
Validation loss: 2.54875041079563

Epoch: 5| Step: 3
Training loss: 2.8387393614260144
Validation loss: 2.506607098717082

Epoch: 5| Step: 4
Training loss: 2.292618836928461
Validation loss: 2.5733018563291306

Epoch: 5| Step: 5
Training loss: 2.4094543918932705
Validation loss: 2.5108683440237654

Epoch: 5| Step: 6
Training loss: 2.317426331469531
Validation loss: 2.5162414068701664

Epoch: 5| Step: 7
Training loss: 2.26204762019617
Validation loss: 2.5176694125951444

Epoch: 5| Step: 8
Training loss: 2.113189187574191
Validation loss: 2.472215218730152

Epoch: 5| Step: 9
Training loss: 2.2265237369844004
Validation loss: 2.5605171369401054

Epoch: 5| Step: 10
Training loss: 2.0962582268095686
Validation loss: 2.619609560182732

Epoch: 297| Step: 0
Training loss: 3.2946448715623227
Validation loss: 2.538693311936947

Epoch: 5| Step: 1
Training loss: 2.4617532014025043
Validation loss: 2.5210110581293175

Epoch: 5| Step: 2
Training loss: 2.4962113282594505
Validation loss: 2.5631398718424983

Epoch: 5| Step: 3
Training loss: 2.1620775063637683
Validation loss: 2.4834285023566065

Epoch: 5| Step: 4
Training loss: 2.2503723260327226
Validation loss: 2.525731237882182

Epoch: 5| Step: 5
Training loss: 2.439603435934124
Validation loss: 2.530872449996576

Epoch: 5| Step: 6
Training loss: 2.2884007040813867
Validation loss: 2.554009351974704

Epoch: 5| Step: 7
Training loss: 2.4213470868057545
Validation loss: 2.5619405090149145

Epoch: 5| Step: 8
Training loss: 2.348833801171318
Validation loss: 2.5498953974561007

Epoch: 5| Step: 9
Training loss: 1.9770337172601153
Validation loss: 2.5387696208795374

Epoch: 5| Step: 10
Training loss: 2.2891811301051392
Validation loss: 2.52861889480255

Epoch: 298| Step: 0
Training loss: 2.7919788660490172
Validation loss: 2.5362778375140516

Epoch: 5| Step: 1
Training loss: 1.6862113412055095
Validation loss: 2.548947798671649

Epoch: 5| Step: 2
Training loss: 2.5475187833653203
Validation loss: 2.535912584497783

Epoch: 5| Step: 3
Training loss: 1.9760990730383465
Validation loss: 2.4952945490546563

Epoch: 5| Step: 4
Training loss: 2.371093448343525
Validation loss: 2.50002925404486

Epoch: 5| Step: 5
Training loss: 2.9173851399828368
Validation loss: 2.526064683466587

Epoch: 5| Step: 6
Training loss: 2.364465035547659
Validation loss: 2.5470353325251254

Epoch: 5| Step: 7
Training loss: 2.314900569881458
Validation loss: 2.4927919241019443

Epoch: 5| Step: 8
Training loss: 2.1971666644381713
Validation loss: 2.5412631939271697

Epoch: 5| Step: 9
Training loss: 2.53633464117372
Validation loss: 2.5239684504077493

Epoch: 5| Step: 10
Training loss: 2.8171947714002457
Validation loss: 2.5508483999490057

Epoch: 299| Step: 0
Training loss: 1.7157705665633038
Validation loss: 2.512941013356256

Epoch: 5| Step: 1
Training loss: 3.058072685201193
Validation loss: 2.5647386925907436

Epoch: 5| Step: 2
Training loss: 2.9308072404420327
Validation loss: 2.5556858903226862

Epoch: 5| Step: 3
Training loss: 2.2039909013882295
Validation loss: 2.4647728236796245

Epoch: 5| Step: 4
Training loss: 2.2381587502609435
Validation loss: 2.507520251323146

Epoch: 5| Step: 5
Training loss: 2.3545839283117234
Validation loss: 2.5375110767623243

Epoch: 5| Step: 6
Training loss: 2.637126885368562
Validation loss: 2.575908784503514

Epoch: 5| Step: 7
Training loss: 2.1962156779647537
Validation loss: 2.5340907630522227

Epoch: 5| Step: 8
Training loss: 2.6126114196380588
Validation loss: 2.533658128270541

Epoch: 5| Step: 9
Training loss: 2.181405979470976
Validation loss: 2.559885787973367

Epoch: 5| Step: 10
Training loss: 2.3984864071509944
Validation loss: 2.5689406631561913

Epoch: 300| Step: 0
Training loss: 2.645602979669776
Validation loss: 2.539820214383604

Epoch: 5| Step: 1
Training loss: 2.6647441808506573
Validation loss: 2.494209375907533

Epoch: 5| Step: 2
Training loss: 2.529914126691623
Validation loss: 2.503089052043864

Epoch: 5| Step: 3
Training loss: 2.306480201872728
Validation loss: 2.490984797465825

Epoch: 5| Step: 4
Training loss: 2.3743841477047436
Validation loss: 2.551801249468269

Epoch: 5| Step: 5
Training loss: 2.360729611810583
Validation loss: 2.5689602725410814

Epoch: 5| Step: 6
Training loss: 3.0789257886218726
Validation loss: 2.5132166210741795

Epoch: 5| Step: 7
Training loss: 2.2950110105695036
Validation loss: 2.5956381409079845

Epoch: 5| Step: 8
Training loss: 2.1613828959954797
Validation loss: 2.5660935602551573

Epoch: 5| Step: 9
Training loss: 2.126005047251182
Validation loss: 2.531644654939557

Epoch: 5| Step: 10
Training loss: 1.8889959583915743
Validation loss: 2.548102641562632

Epoch: 301| Step: 0
Training loss: 2.4394720854072007
Validation loss: 2.520244607101931

Epoch: 5| Step: 1
Training loss: 2.4753873425642983
Validation loss: 2.6154416550707467

Epoch: 5| Step: 2
Training loss: 2.4112572033400292
Validation loss: 2.5253439989057163

Epoch: 5| Step: 3
Training loss: 1.9100676908032128
Validation loss: 2.5520621852404526

Epoch: 5| Step: 4
Training loss: 2.011707609571702
Validation loss: 2.5202042389522257

Epoch: 5| Step: 5
Training loss: 2.1497885045554708
Validation loss: 2.556092167270648

Epoch: 5| Step: 6
Training loss: 2.6122886243665016
Validation loss: 2.542485847641469

Epoch: 5| Step: 7
Training loss: 2.2362951817647265
Validation loss: 2.56576996844956

Epoch: 5| Step: 8
Training loss: 3.1910897778559777
Validation loss: 2.5278292438139345

Epoch: 5| Step: 9
Training loss: 2.237167853737922
Validation loss: 2.5390568013596617

Epoch: 5| Step: 10
Training loss: 2.7358805843862197
Validation loss: 2.5289632073134443

Epoch: 302| Step: 0
Training loss: 2.480594854077974
Validation loss: 2.511894403525527

Epoch: 5| Step: 1
Training loss: 2.3683515148104766
Validation loss: 2.5243725692713395

Epoch: 5| Step: 2
Training loss: 2.49990367703842
Validation loss: 2.5409079091072555

Epoch: 5| Step: 3
Training loss: 1.9305040739896282
Validation loss: 2.5441204903290866

Epoch: 5| Step: 4
Training loss: 2.2276119502884955
Validation loss: 2.4826377799999277

Epoch: 5| Step: 5
Training loss: 2.013313564978216
Validation loss: 2.5398264462805606

Epoch: 5| Step: 6
Training loss: 2.641286011074409
Validation loss: 2.5578397317234893

Epoch: 5| Step: 7
Training loss: 2.378424534625124
Validation loss: 2.5144996130861457

Epoch: 5| Step: 8
Training loss: 2.651243001091409
Validation loss: 2.536936665805273

Epoch: 5| Step: 9
Training loss: 2.69085953561976
Validation loss: 2.5687621959044162

Epoch: 5| Step: 10
Training loss: 2.4330711232179807
Validation loss: 2.517162192951699

Epoch: 303| Step: 0
Training loss: 1.9508502378169947
Validation loss: 2.58819232540284

Epoch: 5| Step: 1
Training loss: 2.450643657291278
Validation loss: 2.49023980754764

Epoch: 5| Step: 2
Training loss: 2.437934054339474
Validation loss: 2.5283933182910627

Epoch: 5| Step: 3
Training loss: 2.724401891321431
Validation loss: 2.5262018472425942

Epoch: 5| Step: 4
Training loss: 2.536878286032042
Validation loss: 2.4932561678979868

Epoch: 5| Step: 5
Training loss: 2.772833358082587
Validation loss: 2.527593457278382

Epoch: 5| Step: 6
Training loss: 2.421972457401533
Validation loss: 2.5090462279042987

Epoch: 5| Step: 7
Training loss: 1.9356169625381163
Validation loss: 2.5476583512605693

Epoch: 5| Step: 8
Training loss: 2.187770499807203
Validation loss: 2.5313399499052047

Epoch: 5| Step: 9
Training loss: 2.4620017036475477
Validation loss: 2.532438267932697

Epoch: 5| Step: 10
Training loss: 2.80153859644754
Validation loss: 2.4941599323473196

Epoch: 304| Step: 0
Training loss: 2.6451896625440825
Validation loss: 2.5198484764960543

Epoch: 5| Step: 1
Training loss: 1.9794372039069124
Validation loss: 2.5527130110241854

Epoch: 5| Step: 2
Training loss: 2.118606486003335
Validation loss: 2.5284254427669803

Epoch: 5| Step: 3
Training loss: 2.4515236651503565
Validation loss: 2.4852171770836784

Epoch: 5| Step: 4
Training loss: 2.207320958930727
Validation loss: 2.515840574533441

Epoch: 5| Step: 5
Training loss: 2.831234397592564
Validation loss: 2.4934830385684124

Epoch: 5| Step: 6
Training loss: 1.8507200489416122
Validation loss: 2.527305940400166

Epoch: 5| Step: 7
Training loss: 2.6329984967103948
Validation loss: 2.4957010716238828

Epoch: 5| Step: 8
Training loss: 2.5018991885896846
Validation loss: 2.5892643585205377

Epoch: 5| Step: 9
Training loss: 2.6466429265236324
Validation loss: 2.538064450222014

Epoch: 5| Step: 10
Training loss: 2.513322617721313
Validation loss: 2.557958576886875

Epoch: 305| Step: 0
Training loss: 2.127097160849865
Validation loss: 2.5200974859877197

Epoch: 5| Step: 1
Training loss: 1.7240882509571902
Validation loss: 2.5118753957902595

Epoch: 5| Step: 2
Training loss: 2.2328837293257666
Validation loss: 2.5561619332425893

Epoch: 5| Step: 3
Training loss: 2.5046661699687327
Validation loss: 2.5766422247528986

Epoch: 5| Step: 4
Training loss: 2.636953114584259
Validation loss: 2.606396302345837

Epoch: 5| Step: 5
Training loss: 2.788635050184092
Validation loss: 2.5185543627893954

Epoch: 5| Step: 6
Training loss: 2.714847526273228
Validation loss: 2.519527045657647

Epoch: 5| Step: 7
Training loss: 2.5123341519860274
Validation loss: 2.5467249986363116

Epoch: 5| Step: 8
Training loss: 2.8973936273041963
Validation loss: 2.5240809915042512

Epoch: 5| Step: 9
Training loss: 2.5849310538506867
Validation loss: 2.5257244723287906

Epoch: 5| Step: 10
Training loss: 1.390982035547637
Validation loss: 2.5440422645063356

Epoch: 306| Step: 0
Training loss: 3.0007968480092853
Validation loss: 2.5699322912976097

Epoch: 5| Step: 1
Training loss: 2.4007439970135875
Validation loss: 2.563882746317835

Epoch: 5| Step: 2
Training loss: 2.2402052141601434
Validation loss: 2.57549206780795

Epoch: 5| Step: 3
Training loss: 2.3033814948641416
Validation loss: 2.488456184305204

Epoch: 5| Step: 4
Training loss: 2.046759565752954
Validation loss: 2.5383006982673715

Epoch: 5| Step: 5
Training loss: 2.8023768180297797
Validation loss: 2.5348872712905255

Epoch: 5| Step: 6
Training loss: 2.8787601594335697
Validation loss: 2.529215832028469

Epoch: 5| Step: 7
Training loss: 1.9319746540571041
Validation loss: 2.528089405805394

Epoch: 5| Step: 8
Training loss: 2.1465149201292886
Validation loss: 2.525359956232658

Epoch: 5| Step: 9
Training loss: 2.185191653158861
Validation loss: 2.573069048108882

Epoch: 5| Step: 10
Training loss: 2.4879248826502387
Validation loss: 2.5480644165996145

Epoch: 307| Step: 0
Training loss: 3.21332455751268
Validation loss: 2.5530581961511203

Epoch: 5| Step: 1
Training loss: 2.000787818239536
Validation loss: 2.5494283251489445

Epoch: 5| Step: 2
Training loss: 2.923599468660065
Validation loss: 2.5151587693511304

Epoch: 5| Step: 3
Training loss: 2.3474027525367664
Validation loss: 2.505947745231648

Epoch: 5| Step: 4
Training loss: 2.1722568752563287
Validation loss: 2.556026821531681

Epoch: 5| Step: 5
Training loss: 2.6907377035570117
Validation loss: 2.5010726391386253

Epoch: 5| Step: 6
Training loss: 1.5463994383702884
Validation loss: 2.5278345823826247

Epoch: 5| Step: 7
Training loss: 2.4135343597349794
Validation loss: 2.510239828549197

Epoch: 5| Step: 8
Training loss: 3.010975470152547
Validation loss: 2.5475134447872847

Epoch: 5| Step: 9
Training loss: 1.9983268534173755
Validation loss: 2.5035943669643768

Epoch: 5| Step: 10
Training loss: 2.1396612517801468
Validation loss: 2.511407892294967

Epoch: 308| Step: 0
Training loss: 2.1537499792770944
Validation loss: 2.5077304739142097

Epoch: 5| Step: 1
Training loss: 2.672183638029996
Validation loss: 2.5289134974240253

Epoch: 5| Step: 2
Training loss: 2.183891808327729
Validation loss: 2.4979817457646174

Epoch: 5| Step: 3
Training loss: 2.3648665226374526
Validation loss: 2.4839721567717254

Epoch: 5| Step: 4
Training loss: 2.00175613550642
Validation loss: 2.572228304288359

Epoch: 5| Step: 5
Training loss: 2.352620137275659
Validation loss: 2.5411286045942805

Epoch: 5| Step: 6
Training loss: 2.1901067188685026
Validation loss: 2.530351768828787

Epoch: 5| Step: 7
Training loss: 2.8319844419623146
Validation loss: 2.4978313094386144

Epoch: 5| Step: 8
Training loss: 2.5459993881620404
Validation loss: 2.5160836237579716

Epoch: 5| Step: 9
Training loss: 3.1004421411045415
Validation loss: 2.5269617860714266

Epoch: 5| Step: 10
Training loss: 1.744237403704954
Validation loss: 2.5052923318437315

Epoch: 309| Step: 0
Training loss: 2.351254262398117
Validation loss: 2.5820721383559104

Epoch: 5| Step: 1
Training loss: 2.3149367201459374
Validation loss: 2.5365777692646367

Epoch: 5| Step: 2
Training loss: 2.08840259523404
Validation loss: 2.5100963182022213

Epoch: 5| Step: 3
Training loss: 1.8966356054130322
Validation loss: 2.5263715133916307

Epoch: 5| Step: 4
Training loss: 3.025308350539615
Validation loss: 2.549320007871371

Epoch: 5| Step: 5
Training loss: 2.4993364407158913
Validation loss: 2.535401683238693

Epoch: 5| Step: 6
Training loss: 2.2545266710684713
Validation loss: 2.564182134561893

Epoch: 5| Step: 7
Training loss: 1.944404175507897
Validation loss: 2.5253936003916886

Epoch: 5| Step: 8
Training loss: 1.9772511967370683
Validation loss: 2.5449597452348076

Epoch: 5| Step: 9
Training loss: 2.6782048964628795
Validation loss: 2.4641527034998356

Epoch: 5| Step: 10
Training loss: 2.7913899260800856
Validation loss: 2.526731710480158

Epoch: 310| Step: 0
Training loss: 2.182140651627738
Validation loss: 2.5100927466031493

Epoch: 5| Step: 1
Training loss: 2.5104155059009785
Validation loss: 2.5536043032580054

Epoch: 5| Step: 2
Training loss: 2.6508813795835993
Validation loss: 2.5422144446978407

Epoch: 5| Step: 3
Training loss: 1.610424551342032
Validation loss: 2.5005818725563866

Epoch: 5| Step: 4
Training loss: 3.0241401900639717
Validation loss: 2.550481405425445

Epoch: 5| Step: 5
Training loss: 2.338689299569974
Validation loss: 2.520134851362123

Epoch: 5| Step: 6
Training loss: 2.460269025808317
Validation loss: 2.564463734615562

Epoch: 5| Step: 7
Training loss: 2.225626645086249
Validation loss: 2.5412461147903405

Epoch: 5| Step: 8
Training loss: 2.194998830738495
Validation loss: 2.521675136770909

Epoch: 5| Step: 9
Training loss: 2.3582993638610437
Validation loss: 2.5864553517624214

Epoch: 5| Step: 10
Training loss: 2.5223172656771213
Validation loss: 2.601227269870539

Epoch: 311| Step: 0
Training loss: 2.612824039349341
Validation loss: 2.5354558210040676

Epoch: 5| Step: 1
Training loss: 2.4226606509830835
Validation loss: 2.544107427834995

Epoch: 5| Step: 2
Training loss: 1.977174385260034
Validation loss: 2.5137189949983068

Epoch: 5| Step: 3
Training loss: 2.5855413865329266
Validation loss: 2.5378456106263156

Epoch: 5| Step: 4
Training loss: 2.275063054814382
Validation loss: 2.5886121821030503

Epoch: 5| Step: 5
Training loss: 2.629793422694057
Validation loss: 2.560657263838846

Epoch: 5| Step: 6
Training loss: 2.5146151583052747
Validation loss: 2.576440718777858

Epoch: 5| Step: 7
Training loss: 2.1445693827367363
Validation loss: 2.5453403957220213

Epoch: 5| Step: 8
Training loss: 2.241832213215497
Validation loss: 2.5451003247637445

Epoch: 5| Step: 9
Training loss: 2.4391372268441462
Validation loss: 2.5086703886104815

Epoch: 5| Step: 10
Training loss: 2.3169084747505875
Validation loss: 2.5435737248254506

Epoch: 312| Step: 0
Training loss: 2.9283268324624774
Validation loss: 2.531999721827496

Epoch: 5| Step: 1
Training loss: 1.7997783259480846
Validation loss: 2.584656514136724

Epoch: 5| Step: 2
Training loss: 2.4483010064733337
Validation loss: 2.5831267829699245

Epoch: 5| Step: 3
Training loss: 2.4286111980676104
Validation loss: 2.5258403657695063

Epoch: 5| Step: 4
Training loss: 2.068776377714317
Validation loss: 2.523052068673543

Epoch: 5| Step: 5
Training loss: 1.9706895750277482
Validation loss: 2.5384999732271125

Epoch: 5| Step: 6
Training loss: 2.2443119843532386
Validation loss: 2.5303045533004878

Epoch: 5| Step: 7
Training loss: 2.5832549872874924
Validation loss: 2.473399320094271

Epoch: 5| Step: 8
Training loss: 2.4628856879721037
Validation loss: 2.539652531854332

Epoch: 5| Step: 9
Training loss: 2.5278868762310145
Validation loss: 2.492655690534557

Epoch: 5| Step: 10
Training loss: 2.4882108238230707
Validation loss: 2.5438965091004255

Epoch: 313| Step: 0
Training loss: 2.4264414406452035
Validation loss: 2.5786448044486066

Epoch: 5| Step: 1
Training loss: 1.7693909848433367
Validation loss: 2.5264764091761367

Epoch: 5| Step: 2
Training loss: 2.6394704969736886
Validation loss: 2.529861186681672

Epoch: 5| Step: 3
Training loss: 2.1477694495804305
Validation loss: 2.5504814154770403

Epoch: 5| Step: 4
Training loss: 2.47867232023514
Validation loss: 2.57734179242285

Epoch: 5| Step: 5
Training loss: 2.0984840961659854
Validation loss: 2.5059965777063162

Epoch: 5| Step: 6
Training loss: 2.8913276436981143
Validation loss: 2.5208058404469904

Epoch: 5| Step: 7
Training loss: 2.335656598913221
Validation loss: 2.526634244401

Epoch: 5| Step: 8
Training loss: 2.071533649109594
Validation loss: 2.5369643550789758

Epoch: 5| Step: 9
Training loss: 2.81226670039323
Validation loss: 2.5458584534705606

Epoch: 5| Step: 10
Training loss: 2.5397347367311776
Validation loss: 2.5571564555781503

Epoch: 314| Step: 0
Training loss: 2.544609606915219
Validation loss: 2.597716318281483

Epoch: 5| Step: 1
Training loss: 3.46092826893697
Validation loss: 2.518379153427571

Epoch: 5| Step: 2
Training loss: 2.2833468063216884
Validation loss: 2.4820744124850953

Epoch: 5| Step: 3
Training loss: 2.232581425769925
Validation loss: 2.5389823846664474

Epoch: 5| Step: 4
Training loss: 2.0488783954747922
Validation loss: 2.5038948933581864

Epoch: 5| Step: 5
Training loss: 2.66441069981503
Validation loss: 2.5357123302489235

Epoch: 5| Step: 6
Training loss: 2.645143514103739
Validation loss: 2.5348010245103065

Epoch: 5| Step: 7
Training loss: 2.0700154793202015
Validation loss: 2.5350041656935627

Epoch: 5| Step: 8
Training loss: 2.0554023920451923
Validation loss: 2.508070583261649

Epoch: 5| Step: 9
Training loss: 2.273657824140571
Validation loss: 2.5179369796465156

Epoch: 5| Step: 10
Training loss: 2.215175166555496
Validation loss: 2.587697528268455

Epoch: 315| Step: 0
Training loss: 2.864791991986265
Validation loss: 2.4939235057267104

Epoch: 5| Step: 1
Training loss: 2.661518750683846
Validation loss: 2.586331794364543

Epoch: 5| Step: 2
Training loss: 2.4658997898701482
Validation loss: 2.541988504395689

Epoch: 5| Step: 3
Training loss: 2.2614543542837184
Validation loss: 2.533718068082997

Epoch: 5| Step: 4
Training loss: 1.610705742135165
Validation loss: 2.569649426894797

Epoch: 5| Step: 5
Training loss: 2.6875141941849
Validation loss: 2.54365806561608

Epoch: 5| Step: 6
Training loss: 2.405673961304683
Validation loss: 2.4521438384856995

Epoch: 5| Step: 7
Training loss: 2.6297551636538636
Validation loss: 2.501004384410906

Epoch: 5| Step: 8
Training loss: 2.097808775515626
Validation loss: 2.562111797886043

Epoch: 5| Step: 9
Training loss: 1.7389118550902918
Validation loss: 2.507778961414325

Epoch: 5| Step: 10
Training loss: 2.550539621589441
Validation loss: 2.524368680706049

Epoch: 316| Step: 0
Training loss: 2.857242476906428
Validation loss: 2.4631900487427365

Epoch: 5| Step: 1
Training loss: 2.060291147860573
Validation loss: 2.499433983542012

Epoch: 5| Step: 2
Training loss: 2.644518447912606
Validation loss: 2.4718992168903333

Epoch: 5| Step: 3
Training loss: 2.229056263504064
Validation loss: 2.5153255367204803

Epoch: 5| Step: 4
Training loss: 1.9946541867469236
Validation loss: 2.4810262988620604

Epoch: 5| Step: 5
Training loss: 2.6350295696010924
Validation loss: 2.5210491797524677

Epoch: 5| Step: 6
Training loss: 2.769187572337962
Validation loss: 2.5507186904339036

Epoch: 5| Step: 7
Training loss: 2.1029950899582888
Validation loss: 2.5756179278809936

Epoch: 5| Step: 8
Training loss: 2.1977284668774564
Validation loss: 2.5541153229042797

Epoch: 5| Step: 9
Training loss: 2.5106683079975345
Validation loss: 2.516512515062657

Epoch: 5| Step: 10
Training loss: 2.488636129275541
Validation loss: 2.5375440960947397

Epoch: 317| Step: 0
Training loss: 1.9469482408098522
Validation loss: 2.5242252606682682

Epoch: 5| Step: 1
Training loss: 2.5152729806960186
Validation loss: 2.514595618564906

Epoch: 5| Step: 2
Training loss: 2.973455133751657
Validation loss: 2.572113723549698

Epoch: 5| Step: 3
Training loss: 2.3037421922556582
Validation loss: 2.5627404377024283

Epoch: 5| Step: 4
Training loss: 1.8782845021590913
Validation loss: 2.548233404771702

Epoch: 5| Step: 5
Training loss: 2.069891199394679
Validation loss: 2.563084758484624

Epoch: 5| Step: 6
Training loss: 2.80060988664114
Validation loss: 2.5381031156767113

Epoch: 5| Step: 7
Training loss: 2.1304482571295065
Validation loss: 2.5359963344600405

Epoch: 5| Step: 8
Training loss: 2.873905802946399
Validation loss: 2.5465860862892447

Epoch: 5| Step: 9
Training loss: 1.9544466353592054
Validation loss: 2.535225605666548

Epoch: 5| Step: 10
Training loss: 2.596697867144428
Validation loss: 2.4817926141438007

Epoch: 318| Step: 0
Training loss: 2.301517595421532
Validation loss: 2.4946738820788856

Epoch: 5| Step: 1
Training loss: 2.5936544010055522
Validation loss: 2.5739051273886395

Epoch: 5| Step: 2
Training loss: 1.8358330879551807
Validation loss: 2.524494996604907

Epoch: 5| Step: 3
Training loss: 2.3269676045391057
Validation loss: 2.5290464823924284

Epoch: 5| Step: 4
Training loss: 2.597851371607391
Validation loss: 2.5046828291454006

Epoch: 5| Step: 5
Training loss: 2.058228201504336
Validation loss: 2.525584342990596

Epoch: 5| Step: 6
Training loss: 2.343123492110432
Validation loss: 2.540036819852597

Epoch: 5| Step: 7
Training loss: 2.6173410854538965
Validation loss: 2.545698230106296

Epoch: 5| Step: 8
Training loss: 2.7721257075970964
Validation loss: 2.49126312747501

Epoch: 5| Step: 9
Training loss: 2.284695988136984
Validation loss: 2.4982471001776525

Epoch: 5| Step: 10
Training loss: 2.103941751174206
Validation loss: 2.5394729209348257

Epoch: 319| Step: 0
Training loss: 2.37455715266977
Validation loss: 2.5078082300093008

Epoch: 5| Step: 1
Training loss: 1.8924805544177956
Validation loss: 2.5411474611091562

Epoch: 5| Step: 2
Training loss: 3.034262821469323
Validation loss: 2.553718620245914

Epoch: 5| Step: 3
Training loss: 2.013784233384786
Validation loss: 2.506676236908163

Epoch: 5| Step: 4
Training loss: 2.4292897576563512
Validation loss: 2.544562921927003

Epoch: 5| Step: 5
Training loss: 2.4257686694520797
Validation loss: 2.5426804561358622

Epoch: 5| Step: 6
Training loss: 2.7000754910971083
Validation loss: 2.6031239772912262

Epoch: 5| Step: 7
Training loss: 2.6632037526652836
Validation loss: 2.527747249629276

Epoch: 5| Step: 8
Training loss: 1.7964632308853683
Validation loss: 2.54505647123892

Epoch: 5| Step: 9
Training loss: 2.3729587617064736
Validation loss: 2.5364687409980933

Epoch: 5| Step: 10
Training loss: 2.422102394503678
Validation loss: 2.582884277774101

Epoch: 320| Step: 0
Training loss: 2.365530107376317
Validation loss: 2.535678105172429

Epoch: 5| Step: 1
Training loss: 2.6846878064901047
Validation loss: 2.5686005307765467

Epoch: 5| Step: 2
Training loss: 2.748497032054279
Validation loss: 2.563550968182209

Epoch: 5| Step: 3
Training loss: 2.5767223819797054
Validation loss: 2.5409398410605375

Epoch: 5| Step: 4
Training loss: 2.083072824085105
Validation loss: 2.551852404200301

Epoch: 5| Step: 5
Training loss: 2.764329941115197
Validation loss: 2.535502323584383

Epoch: 5| Step: 6
Training loss: 1.9092673513281624
Validation loss: 2.4896545592186956

Epoch: 5| Step: 7
Training loss: 2.459107217909293
Validation loss: 2.5168057988034027

Epoch: 5| Step: 8
Training loss: 2.516470251776518
Validation loss: 2.5090195312423815

Epoch: 5| Step: 9
Training loss: 2.0140199406686947
Validation loss: 2.51485664191506

Epoch: 5| Step: 10
Training loss: 2.382507704955508
Validation loss: 2.5362388682831343

Epoch: 321| Step: 0
Training loss: 2.5263154710593776
Validation loss: 2.535817234934377

Epoch: 5| Step: 1
Training loss: 1.9028759472374839
Validation loss: 2.568038383733842

Epoch: 5| Step: 2
Training loss: 2.404857777694706
Validation loss: 2.553140313809007

Epoch: 5| Step: 3
Training loss: 2.483290525575214
Validation loss: 2.533574704751386

Epoch: 5| Step: 4
Training loss: 2.2494623813472487
Validation loss: 2.540391973201067

Epoch: 5| Step: 5
Training loss: 1.9287308394938365
Validation loss: 2.5364287063604425

Epoch: 5| Step: 6
Training loss: 2.169885726064501
Validation loss: 2.516826352208654

Epoch: 5| Step: 7
Training loss: 2.4649348657757857
Validation loss: 2.5018591407854696

Epoch: 5| Step: 8
Training loss: 1.7543848145213454
Validation loss: 2.5314727679100586

Epoch: 5| Step: 9
Training loss: 2.783712432840799
Validation loss: 2.565512021720442

Epoch: 5| Step: 10
Training loss: 3.272014299431406
Validation loss: 2.5517111186423813

Epoch: 322| Step: 0
Training loss: 2.635492517236701
Validation loss: 2.559152364850718

Epoch: 5| Step: 1
Training loss: 2.7750341842882777
Validation loss: 2.5206590841572076

Epoch: 5| Step: 2
Training loss: 2.2962225162395944
Validation loss: 2.487066091882333

Epoch: 5| Step: 3
Training loss: 2.1724165646034774
Validation loss: 2.510016284362448

Epoch: 5| Step: 4
Training loss: 2.118904459226589
Validation loss: 2.502644975267257

Epoch: 5| Step: 5
Training loss: 2.9234626251070748
Validation loss: 2.5158351035184343

Epoch: 5| Step: 6
Training loss: 2.373415970845925
Validation loss: 2.4694591711858123

Epoch: 5| Step: 7
Training loss: 2.4404164008992058
Validation loss: 2.531631447062232

Epoch: 5| Step: 8
Training loss: 2.1819814554085526
Validation loss: 2.5170979076624858

Epoch: 5| Step: 9
Training loss: 1.970270084708073
Validation loss: 2.562718218804191

Epoch: 5| Step: 10
Training loss: 2.3024496302029243
Validation loss: 2.529673318377828

Epoch: 323| Step: 0
Training loss: 3.307291939001998
Validation loss: 2.5405567643314972

Epoch: 5| Step: 1
Training loss: 1.8838481666385722
Validation loss: 2.5241768052191484

Epoch: 5| Step: 2
Training loss: 2.2589346133323094
Validation loss: 2.459765197852568

Epoch: 5| Step: 3
Training loss: 2.9431630191222684
Validation loss: 2.5368042692881803

Epoch: 5| Step: 4
Training loss: 2.0836445639514136
Validation loss: 2.5099688282715733

Epoch: 5| Step: 5
Training loss: 2.2930501634223868
Validation loss: 2.5484415904945603

Epoch: 5| Step: 6
Training loss: 2.4809715902723033
Validation loss: 2.544398280436047

Epoch: 5| Step: 7
Training loss: 2.2613985826589924
Validation loss: 2.5408621282430444

Epoch: 5| Step: 8
Training loss: 2.1073121333075124
Validation loss: 2.5501293340590783

Epoch: 5| Step: 9
Training loss: 1.9095234515080277
Validation loss: 2.568268091395086

Epoch: 5| Step: 10
Training loss: 2.2245030566121846
Validation loss: 2.5344560353508165

Epoch: 324| Step: 0
Training loss: 2.1902483432651607
Validation loss: 2.540576244664872

Epoch: 5| Step: 1
Training loss: 2.176037757861503
Validation loss: 2.526601036324242

Epoch: 5| Step: 2
Training loss: 2.6367909061307477
Validation loss: 2.546520387387257

Epoch: 5| Step: 3
Training loss: 2.6208435939796186
Validation loss: 2.5656687150500193

Epoch: 5| Step: 4
Training loss: 2.402186343610993
Validation loss: 2.561765105692389

Epoch: 5| Step: 5
Training loss: 2.440295548127959
Validation loss: 2.4924998548455832

Epoch: 5| Step: 6
Training loss: 2.2123215727331367
Validation loss: 2.517913855798651

Epoch: 5| Step: 7
Training loss: 2.189437661979852
Validation loss: 2.5458786263161124

Epoch: 5| Step: 8
Training loss: 3.0202326385628044
Validation loss: 2.506897787208879

Epoch: 5| Step: 9
Training loss: 2.1123168775653807
Validation loss: 2.525889774818012

Epoch: 5| Step: 10
Training loss: 1.847343047292815
Validation loss: 2.5065559329164637

Epoch: 325| Step: 0
Training loss: 2.310643043354752
Validation loss: 2.577705869790306

Epoch: 5| Step: 1
Training loss: 2.8784129575470585
Validation loss: 2.550258396012956

Epoch: 5| Step: 2
Training loss: 2.7603500838016983
Validation loss: 2.4912627678211234

Epoch: 5| Step: 3
Training loss: 2.2996106108397605
Validation loss: 2.5344168803090503

Epoch: 5| Step: 4
Training loss: 2.4734991243051274
Validation loss: 2.535542001023699

Epoch: 5| Step: 5
Training loss: 2.048814509867476
Validation loss: 2.577313005112527

Epoch: 5| Step: 6
Training loss: 2.168837584560145
Validation loss: 2.557855398124929

Epoch: 5| Step: 7
Training loss: 1.9837078264509258
Validation loss: 2.476150154880015

Epoch: 5| Step: 8
Training loss: 2.39660813339268
Validation loss: 2.533152198859936

Epoch: 5| Step: 9
Training loss: 2.324089803244208
Validation loss: 2.4918377808643033

Epoch: 5| Step: 10
Training loss: 2.4548403822835883
Validation loss: 2.482249144915026

Epoch: 326| Step: 0
Training loss: 2.519861007520633
Validation loss: 2.5437019049516123

Epoch: 5| Step: 1
Training loss: 2.7013121242343323
Validation loss: 2.522305688030686

Epoch: 5| Step: 2
Training loss: 2.350203314569191
Validation loss: 2.553392782454455

Epoch: 5| Step: 3
Training loss: 2.211314785850898
Validation loss: 2.494982224527542

Epoch: 5| Step: 4
Training loss: 2.060271359505486
Validation loss: 2.5417473966976316

Epoch: 5| Step: 5
Training loss: 2.6365134830401384
Validation loss: 2.5248223431400594

Epoch: 5| Step: 6
Training loss: 2.179083846532135
Validation loss: 2.502808707656933

Epoch: 5| Step: 7
Training loss: 2.6623015638737084
Validation loss: 2.523831349615204

Epoch: 5| Step: 8
Training loss: 2.214667957467827
Validation loss: 2.5189382493897687

Epoch: 5| Step: 9
Training loss: 2.232828098293355
Validation loss: 2.5648559616799838

Epoch: 5| Step: 10
Training loss: 2.1570210943981207
Validation loss: 2.520648871920286

Epoch: 327| Step: 0
Training loss: 2.4488419968526585
Validation loss: 2.510905839081665

Epoch: 5| Step: 1
Training loss: 2.6480817077569627
Validation loss: 2.566082952382961

Epoch: 5| Step: 2
Training loss: 2.4731631851622518
Validation loss: 2.471830207416066

Epoch: 5| Step: 3
Training loss: 2.7135944812831
Validation loss: 2.5752604580524174

Epoch: 5| Step: 4
Training loss: 2.7490533586571027
Validation loss: 2.538308120621822

Epoch: 5| Step: 5
Training loss: 2.1325187061558197
Validation loss: 2.5087830723274616

Epoch: 5| Step: 6
Training loss: 2.227108751181092
Validation loss: 2.5426834339808226

Epoch: 5| Step: 7
Training loss: 2.615158524385475
Validation loss: 2.498439224705236

Epoch: 5| Step: 8
Training loss: 1.9335396190734264
Validation loss: 2.5111177442721804

Epoch: 5| Step: 9
Training loss: 1.793795326537476
Validation loss: 2.512542715512033

Epoch: 5| Step: 10
Training loss: 2.417757237663082
Validation loss: 2.5294983410193037

Epoch: 328| Step: 0
Training loss: 2.770363234793906
Validation loss: 2.5341076501461437

Epoch: 5| Step: 1
Training loss: 3.0639511095932224
Validation loss: 2.5227409012644317

Epoch: 5| Step: 2
Training loss: 1.940292499455743
Validation loss: 2.505812446868977

Epoch: 5| Step: 3
Training loss: 2.6195357534550183
Validation loss: 2.472457599123493

Epoch: 5| Step: 4
Training loss: 2.387470832366928
Validation loss: 2.5345870899322707

Epoch: 5| Step: 5
Training loss: 2.113274480840591
Validation loss: 2.5385950831703887

Epoch: 5| Step: 6
Training loss: 2.373616970326103
Validation loss: 2.550143647455832

Epoch: 5| Step: 7
Training loss: 2.3022728636268397
Validation loss: 2.4943494949317264

Epoch: 5| Step: 8
Training loss: 2.3398386552401753
Validation loss: 2.523753392377258

Epoch: 5| Step: 9
Training loss: 2.2003239349817925
Validation loss: 2.596217344281318

Epoch: 5| Step: 10
Training loss: 2.0557933775760153
Validation loss: 2.504686990851642

Epoch: 329| Step: 0
Training loss: 2.642210896104743
Validation loss: 2.535700944183827

Epoch: 5| Step: 1
Training loss: 2.529956911195063
Validation loss: 2.5492041229128795

Epoch: 5| Step: 2
Training loss: 2.3146156736827628
Validation loss: 2.4832176019520484

Epoch: 5| Step: 3
Training loss: 2.880527655690067
Validation loss: 2.4908038858887713

Epoch: 5| Step: 4
Training loss: 2.472648921913509
Validation loss: 2.524524493844789

Epoch: 5| Step: 5
Training loss: 2.3918656265318337
Validation loss: 2.5404533611697513

Epoch: 5| Step: 6
Training loss: 2.138711115507586
Validation loss: 2.5390234099377347

Epoch: 5| Step: 7
Training loss: 1.965483483585977
Validation loss: 2.5156909065476705

Epoch: 5| Step: 8
Training loss: 2.4691431239543498
Validation loss: 2.5143673789521395

Epoch: 5| Step: 9
Training loss: 2.16882439301611
Validation loss: 2.5310944479390405

Epoch: 5| Step: 10
Training loss: 1.9152884158081152
Validation loss: 2.502123562480168

Epoch: 330| Step: 0
Training loss: 2.2985499496492814
Validation loss: 2.4478267699425627

Epoch: 5| Step: 1
Training loss: 2.6685239066271222
Validation loss: 2.5190694197612595

Epoch: 5| Step: 2
Training loss: 1.9545909415591471
Validation loss: 2.552506240316918

Epoch: 5| Step: 3
Training loss: 2.309150125294469
Validation loss: 2.5315609438008324

Epoch: 5| Step: 4
Training loss: 2.2131265647471126
Validation loss: 2.4946458847450854

Epoch: 5| Step: 5
Training loss: 2.9463251533358785
Validation loss: 2.5019469084058907

Epoch: 5| Step: 6
Training loss: 2.6989291928739023
Validation loss: 2.5222083426306208

Epoch: 5| Step: 7
Training loss: 2.494329984522054
Validation loss: 2.5040915335231895

Epoch: 5| Step: 8
Training loss: 1.8553827205590618
Validation loss: 2.474078322362902

Epoch: 5| Step: 9
Training loss: 2.1177392219608735
Validation loss: 2.550892933026516

Epoch: 5| Step: 10
Training loss: 1.9953899897238354
Validation loss: 2.4968733083020624

Epoch: 331| Step: 0
Training loss: 1.607652501633833
Validation loss: 2.5106269521305724

Epoch: 5| Step: 1
Training loss: 2.238724536506
Validation loss: 2.497234199943831

Epoch: 5| Step: 2
Training loss: 1.9793321707608509
Validation loss: 2.5154331811581585

Epoch: 5| Step: 3
Training loss: 2.801869966875568
Validation loss: 2.520755029972583

Epoch: 5| Step: 4
Training loss: 2.345991156663024
Validation loss: 2.484195950691795

Epoch: 5| Step: 5
Training loss: 2.424391687920399
Validation loss: 2.508420920819607

Epoch: 5| Step: 6
Training loss: 3.004215298989589
Validation loss: 2.5713465792579133

Epoch: 5| Step: 7
Training loss: 2.2458626537025044
Validation loss: 2.5081482250672056

Epoch: 5| Step: 8
Training loss: 2.2461584994063903
Validation loss: 2.4822577568146014

Epoch: 5| Step: 9
Training loss: 2.274136465321031
Validation loss: 2.5695120970971064

Epoch: 5| Step: 10
Training loss: 2.723508944862822
Validation loss: 2.577020039811053

Epoch: 332| Step: 0
Training loss: 2.2937769334755362
Validation loss: 2.5912904618732164

Epoch: 5| Step: 1
Training loss: 2.7789870925224704
Validation loss: 2.540703352065197

Epoch: 5| Step: 2
Training loss: 2.1869880077101294
Validation loss: 2.5080176421515774

Epoch: 5| Step: 3
Training loss: 2.0983520717657798
Validation loss: 2.4826415470230585

Epoch: 5| Step: 4
Training loss: 2.4341989318875403
Validation loss: 2.4953707247499315

Epoch: 5| Step: 5
Training loss: 2.3425550339136243
Validation loss: 2.492059443647866

Epoch: 5| Step: 6
Training loss: 2.4232670874725684
Validation loss: 2.524288583459315

Epoch: 5| Step: 7
Training loss: 2.227224579469385
Validation loss: 2.4882745201645857

Epoch: 5| Step: 8
Training loss: 2.6115513480052086
Validation loss: 2.4945347781476723

Epoch: 5| Step: 9
Training loss: 2.250429960071628
Validation loss: 2.582838137207176

Epoch: 5| Step: 10
Training loss: 2.188931351081462
Validation loss: 2.525795796214623

Epoch: 333| Step: 0
Training loss: 1.8680828294177183
Validation loss: 2.5278405405932958

Epoch: 5| Step: 1
Training loss: 2.4919661181428947
Validation loss: 2.4996422429622465

Epoch: 5| Step: 2
Training loss: 2.616607601770714
Validation loss: 2.4865587187159437

Epoch: 5| Step: 3
Training loss: 2.479949560421564
Validation loss: 2.4770377878503425

Epoch: 5| Step: 4
Training loss: 2.042492433531624
Validation loss: 2.557507185683248

Epoch: 5| Step: 5
Training loss: 2.42459809817062
Validation loss: 2.5710740768789684

Epoch: 5| Step: 6
Training loss: 2.6058041929984945
Validation loss: 2.5723716461153607

Epoch: 5| Step: 7
Training loss: 2.318978693704245
Validation loss: 2.5161319304192666

Epoch: 5| Step: 8
Training loss: 2.8859619470045175
Validation loss: 2.523930667440169

Epoch: 5| Step: 9
Training loss: 2.126908286947038
Validation loss: 2.534697874046576

Epoch: 5| Step: 10
Training loss: 1.5100501657199084
Validation loss: 2.5314378262332498

Epoch: 334| Step: 0
Training loss: 2.3192097005119505
Validation loss: 2.5323539027258173

Epoch: 5| Step: 1
Training loss: 1.960903820949265
Validation loss: 2.5401165062989466

Epoch: 5| Step: 2
Training loss: 1.9354061379640757
Validation loss: 2.5779440986953195

Epoch: 5| Step: 3
Training loss: 2.067194134044887
Validation loss: 2.5118794720961173

Epoch: 5| Step: 4
Training loss: 2.146594224363003
Validation loss: 2.5041055295903116

Epoch: 5| Step: 5
Training loss: 2.1721892644079004
Validation loss: 2.5478843180270543

Epoch: 5| Step: 6
Training loss: 2.8150110691049424
Validation loss: 2.481794808191068

Epoch: 5| Step: 7
Training loss: 1.9818106474784887
Validation loss: 2.5669029170925706

Epoch: 5| Step: 8
Training loss: 2.562412725683668
Validation loss: 2.5561069703144814

Epoch: 5| Step: 9
Training loss: 2.2021364199020756
Validation loss: 2.5899836863831758

Epoch: 5| Step: 10
Training loss: 3.2092332609946137
Validation loss: 2.563994347349086

Epoch: 335| Step: 0
Training loss: 1.9382814861698767
Validation loss: 2.5332266299611974

Epoch: 5| Step: 1
Training loss: 2.4098082156660316
Validation loss: 2.4921496888587114

Epoch: 5| Step: 2
Training loss: 2.2270238565675373
Validation loss: 2.5240862679194005

Epoch: 5| Step: 3
Training loss: 2.0646928631790966
Validation loss: 2.4765792902526793

Epoch: 5| Step: 4
Training loss: 2.8931329518322415
Validation loss: 2.5055127551894993

Epoch: 5| Step: 5
Training loss: 2.3105239673552718
Validation loss: 2.557556201483815

Epoch: 5| Step: 6
Training loss: 2.536575836864684
Validation loss: 2.5328544019746397

Epoch: 5| Step: 7
Training loss: 2.373678140702613
Validation loss: 2.5476817746801714

Epoch: 5| Step: 8
Training loss: 2.502532058190366
Validation loss: 2.530356029145447

Epoch: 5| Step: 9
Training loss: 1.8847040195971345
Validation loss: 2.485799591363587

Epoch: 5| Step: 10
Training loss: 2.174437952317284
Validation loss: 2.467512090107514

Epoch: 336| Step: 0
Training loss: 2.123249454887641
Validation loss: 2.5027735491492273

Epoch: 5| Step: 1
Training loss: 2.054177340569404
Validation loss: 2.509266349078881

Epoch: 5| Step: 2
Training loss: 2.782000408306956
Validation loss: 2.5383291008512923

Epoch: 5| Step: 3
Training loss: 2.2460390830643595
Validation loss: 2.488229077844836

Epoch: 5| Step: 4
Training loss: 2.267489277941537
Validation loss: 2.5320308002141543

Epoch: 5| Step: 5
Training loss: 2.2546171921562435
Validation loss: 2.4821298182057463

Epoch: 5| Step: 6
Training loss: 2.565598452171665
Validation loss: 2.5218253065763316

Epoch: 5| Step: 7
Training loss: 2.3009005193446876
Validation loss: 2.5579513969632224

Epoch: 5| Step: 8
Training loss: 2.50142771961216
Validation loss: 2.534064069226147

Epoch: 5| Step: 9
Training loss: 1.9706410000312153
Validation loss: 2.4747879369612114

Epoch: 5| Step: 10
Training loss: 2.5210008696902997
Validation loss: 2.5264815030147214

Epoch: 337| Step: 0
Training loss: 2.6114471796439447
Validation loss: 2.4645513842157656

Epoch: 5| Step: 1
Training loss: 2.1394378265953855
Validation loss: 2.540593313168828

Epoch: 5| Step: 2
Training loss: 2.590721476452976
Validation loss: 2.4906347169729135

Epoch: 5| Step: 3
Training loss: 1.9636824040522376
Validation loss: 2.4646968110975322

Epoch: 5| Step: 4
Training loss: 2.224593727652938
Validation loss: 2.5445435391136377

Epoch: 5| Step: 5
Training loss: 2.687372426398415
Validation loss: 2.52381150488105

Epoch: 5| Step: 6
Training loss: 2.209061544539277
Validation loss: 2.5517194363340177

Epoch: 5| Step: 7
Training loss: 2.264923513270498
Validation loss: 2.4863587988575877

Epoch: 5| Step: 8
Training loss: 2.1471388342378868
Validation loss: 2.5627895919912524

Epoch: 5| Step: 9
Training loss: 2.596149300030589
Validation loss: 2.5085741277530036

Epoch: 5| Step: 10
Training loss: 2.320316610107892
Validation loss: 2.505798390766126

Epoch: 338| Step: 0
Training loss: 1.9135079962506265
Validation loss: 2.5359155136777938

Epoch: 5| Step: 1
Training loss: 2.1518400125487287
Validation loss: 2.5298589552789377

Epoch: 5| Step: 2
Training loss: 2.425834520034561
Validation loss: 2.5684637407758135

Epoch: 5| Step: 3
Training loss: 2.5436306749704514
Validation loss: 2.5720844850192237

Epoch: 5| Step: 4
Training loss: 2.052794189743121
Validation loss: 2.5478370329736824

Epoch: 5| Step: 5
Training loss: 2.658021582935617
Validation loss: 2.5203123789135122

Epoch: 5| Step: 6
Training loss: 2.157028057865598
Validation loss: 2.5397577567894167

Epoch: 5| Step: 7
Training loss: 1.6215204987055107
Validation loss: 2.5197409637060817

Epoch: 5| Step: 8
Training loss: 2.440596740793504
Validation loss: 2.5238364066377814

Epoch: 5| Step: 9
Training loss: 2.629739569762175
Validation loss: 2.5327456208363905

Epoch: 5| Step: 10
Training loss: 2.9350333713278465
Validation loss: 2.5164900566041823

Epoch: 339| Step: 0
Training loss: 2.7135462452757726
Validation loss: 2.5510791007357994

Epoch: 5| Step: 1
Training loss: 2.463123525305933
Validation loss: 2.5464877965351334

Epoch: 5| Step: 2
Training loss: 1.646974465770389
Validation loss: 2.5723884249167597

Epoch: 5| Step: 3
Training loss: 2.4450242722755537
Validation loss: 2.5055015797742444

Epoch: 5| Step: 4
Training loss: 2.635450360430817
Validation loss: 2.5753646123523577

Epoch: 5| Step: 5
Training loss: 2.0647885890005413
Validation loss: 2.567798305330377

Epoch: 5| Step: 6
Training loss: 1.9863198429261335
Validation loss: 2.582197693591774

Epoch: 5| Step: 7
Training loss: 2.293093000486595
Validation loss: 2.5534736042561357

Epoch: 5| Step: 8
Training loss: 2.568135368528623
Validation loss: 2.5206528292814214

Epoch: 5| Step: 9
Training loss: 2.1130554868360645
Validation loss: 2.554903497239063

Epoch: 5| Step: 10
Training loss: 1.713702054232991
Validation loss: 2.506485306297469

Epoch: 340| Step: 0
Training loss: 1.9331755831366162
Validation loss: 2.567831466335938

Epoch: 5| Step: 1
Training loss: 2.812566629256336
Validation loss: 2.526021058675425

Epoch: 5| Step: 2
Training loss: 2.5612602025913764
Validation loss: 2.547270385241168

Epoch: 5| Step: 3
Training loss: 2.3568897421048804
Validation loss: 2.522581752298433

Epoch: 5| Step: 4
Training loss: 2.404003531366125
Validation loss: 2.5516445891943236

Epoch: 5| Step: 5
Training loss: 2.0556612789470465
Validation loss: 2.5195444694160165

Epoch: 5| Step: 6
Training loss: 2.291334775531142
Validation loss: 2.556700660222985

Epoch: 5| Step: 7
Training loss: 2.5028351919588934
Validation loss: 2.447733089149957

Epoch: 5| Step: 8
Training loss: 2.495689299624701
Validation loss: 2.4958475492733605

Epoch: 5| Step: 9
Training loss: 2.091558761650334
Validation loss: 2.51844565465476

Epoch: 5| Step: 10
Training loss: 2.0982107214622023
Validation loss: 2.526117539648602

Epoch: 341| Step: 0
Training loss: 1.9143466037956949
Validation loss: 2.5776615475778732

Epoch: 5| Step: 1
Training loss: 3.0751056870076985
Validation loss: 2.5001907214356107

Epoch: 5| Step: 2
Training loss: 2.708217784666394
Validation loss: 2.5009666583908463

Epoch: 5| Step: 3
Training loss: 1.787427663339796
Validation loss: 2.5099759074703214

Epoch: 5| Step: 4
Training loss: 2.3017403072295206
Validation loss: 2.520671236878812

Epoch: 5| Step: 5
Training loss: 2.2946356412255664
Validation loss: 2.537589535239101

Epoch: 5| Step: 6
Training loss: 2.3686690022251
Validation loss: 2.51056290795718

Epoch: 5| Step: 7
Training loss: 1.876397057449678
Validation loss: 2.4816597410295866

Epoch: 5| Step: 8
Training loss: 2.7359010634073853
Validation loss: 2.574961165141192

Epoch: 5| Step: 9
Training loss: 2.1709105181990673
Validation loss: 2.514106309903499

Epoch: 5| Step: 10
Training loss: 2.0127873517665487
Validation loss: 2.5330982173088383

Epoch: 342| Step: 0
Training loss: 2.23333225060432
Validation loss: 2.5152376447773377

Epoch: 5| Step: 1
Training loss: 2.1693335284041724
Validation loss: 2.5753294643493776

Epoch: 5| Step: 2
Training loss: 1.8830249080904733
Validation loss: 2.516726339947911

Epoch: 5| Step: 3
Training loss: 2.2080115917634067
Validation loss: 2.4875491479940623

Epoch: 5| Step: 4
Training loss: 2.5333195455912114
Validation loss: 2.5320045585182402

Epoch: 5| Step: 5
Training loss: 2.2511093795550456
Validation loss: 2.5142357414962984

Epoch: 5| Step: 6
Training loss: 2.238341964776995
Validation loss: 2.5419481421846686

Epoch: 5| Step: 7
Training loss: 2.006996553031269
Validation loss: 2.5426711651565097

Epoch: 5| Step: 8
Training loss: 2.957726985059956
Validation loss: 2.5867674146150397

Epoch: 5| Step: 9
Training loss: 2.528313428649136
Validation loss: 2.5307204324166928

Epoch: 5| Step: 10
Training loss: 2.1627162229894243
Validation loss: 2.545159832433996

Epoch: 343| Step: 0
Training loss: 2.401546587919238
Validation loss: 2.5015756102694926

Epoch: 5| Step: 1
Training loss: 1.8602366013938343
Validation loss: 2.5099959509626957

Epoch: 5| Step: 2
Training loss: 2.578188623741452
Validation loss: 2.5486334829850024

Epoch: 5| Step: 3
Training loss: 2.302201096872707
Validation loss: 2.5132736929810546

Epoch: 5| Step: 4
Training loss: 2.669437657547323
Validation loss: 2.5619172404783503

Epoch: 5| Step: 5
Training loss: 2.491661087931466
Validation loss: 2.5804435737768134

Epoch: 5| Step: 6
Training loss: 2.37726615405554
Validation loss: 2.5275211049157034

Epoch: 5| Step: 7
Training loss: 2.308967882748314
Validation loss: 2.4915101969113884

Epoch: 5| Step: 8
Training loss: 2.5305310393884906
Validation loss: 2.517761980349589

Epoch: 5| Step: 9
Training loss: 1.975322952906696
Validation loss: 2.5854593916898376

Epoch: 5| Step: 10
Training loss: 2.151266780524054
Validation loss: 2.5155146600158202

Epoch: 344| Step: 0
Training loss: 2.442501316909669
Validation loss: 2.5479745630912305

Epoch: 5| Step: 1
Training loss: 2.264618959354287
Validation loss: 2.563364615891228

Epoch: 5| Step: 2
Training loss: 2.570052206199386
Validation loss: 2.5269051262952535

Epoch: 5| Step: 3
Training loss: 2.0342406338385493
Validation loss: 2.5333823870695302

Epoch: 5| Step: 4
Training loss: 2.5140156781262326
Validation loss: 2.527639662551224

Epoch: 5| Step: 5
Training loss: 2.5450637086939563
Validation loss: 2.5161105215871022

Epoch: 5| Step: 6
Training loss: 2.372475537253382
Validation loss: 2.480780518717734

Epoch: 5| Step: 7
Training loss: 1.756613089065926
Validation loss: 2.586578229288409

Epoch: 5| Step: 8
Training loss: 2.327086453846951
Validation loss: 2.519546390458385

Epoch: 5| Step: 9
Training loss: 2.172725483526144
Validation loss: 2.490831040239457

Epoch: 5| Step: 10
Training loss: 2.291324994597117
Validation loss: 2.515911902477995

Epoch: 345| Step: 0
Training loss: 2.800287051473151
Validation loss: 2.506424825182076

Epoch: 5| Step: 1
Training loss: 1.9325072655781792
Validation loss: 2.4640204548788445

Epoch: 5| Step: 2
Training loss: 1.9735295241790523
Validation loss: 2.5612404131397755

Epoch: 5| Step: 3
Training loss: 1.7863322251483669
Validation loss: 2.5668337162180266

Epoch: 5| Step: 4
Training loss: 2.030324519672135
Validation loss: 2.5717978141973656

Epoch: 5| Step: 5
Training loss: 2.8630875629941155
Validation loss: 2.4620552604172636

Epoch: 5| Step: 6
Training loss: 2.2321851977011087
Validation loss: 2.5140619035043263

Epoch: 5| Step: 7
Training loss: 2.7365448979535536
Validation loss: 2.5371081190012914

Epoch: 5| Step: 8
Training loss: 2.399266699184803
Validation loss: 2.515898144297325

Epoch: 5| Step: 9
Training loss: 2.304276458810164
Validation loss: 2.497556657334996

Epoch: 5| Step: 10
Training loss: 2.1649249730313938
Validation loss: 2.518084937108922

Epoch: 346| Step: 0
Training loss: 1.7728718262981364
Validation loss: 2.5357151105358664

Epoch: 5| Step: 1
Training loss: 2.129318673318469
Validation loss: 2.507797792677991

Epoch: 5| Step: 2
Training loss: 2.3347432327409345
Validation loss: 2.485198413009603

Epoch: 5| Step: 3
Training loss: 2.485572670205168
Validation loss: 2.615769896596499

Epoch: 5| Step: 4
Training loss: 2.6736858990490417
Validation loss: 2.5351618087568313

Epoch: 5| Step: 5
Training loss: 2.0331814313128818
Validation loss: 2.5485830874822555

Epoch: 5| Step: 6
Training loss: 2.051119531251637
Validation loss: 2.5278298543423077

Epoch: 5| Step: 7
Training loss: 2.7082138230780877
Validation loss: 2.581033951271201

Epoch: 5| Step: 8
Training loss: 2.902459739123257
Validation loss: 2.455891119994964

Epoch: 5| Step: 9
Training loss: 2.244009095430216
Validation loss: 2.5306368720400036

Epoch: 5| Step: 10
Training loss: 1.4274009388291322
Validation loss: 2.5923304542185712

Epoch: 347| Step: 0
Training loss: 2.500728024336689
Validation loss: 2.4843897273139937

Epoch: 5| Step: 1
Training loss: 2.5734517600261406
Validation loss: 2.51485743908442

Epoch: 5| Step: 2
Training loss: 2.6325163632252937
Validation loss: 2.5528251555922146

Epoch: 5| Step: 3
Training loss: 1.8908001526966682
Validation loss: 2.4849836218357684

Epoch: 5| Step: 4
Training loss: 2.3946952328064888
Validation loss: 2.5023887092250114

Epoch: 5| Step: 5
Training loss: 2.5080720285905156
Validation loss: 2.524552025780437

Epoch: 5| Step: 6
Training loss: 1.86950577982774
Validation loss: 2.5319823260668706

Epoch: 5| Step: 7
Training loss: 2.177889940666986
Validation loss: 2.521505634501045

Epoch: 5| Step: 8
Training loss: 2.059350122698043
Validation loss: 2.4499422600216176

Epoch: 5| Step: 9
Training loss: 2.4516517443000727
Validation loss: 2.549434447583183

Epoch: 5| Step: 10
Training loss: 1.8463587005373048
Validation loss: 2.50996487806795

Epoch: 348| Step: 0
Training loss: 2.4490877204658514
Validation loss: 2.503278668144865

Epoch: 5| Step: 1
Training loss: 2.606229062076323
Validation loss: 2.51343704509813

Epoch: 5| Step: 2
Training loss: 2.5999213646954975
Validation loss: 2.5135330146669985

Epoch: 5| Step: 3
Training loss: 2.8415851107739956
Validation loss: 2.5663330798905517

Epoch: 5| Step: 4
Training loss: 1.8663766289360832
Validation loss: 2.518557039869306

Epoch: 5| Step: 5
Training loss: 1.931380729818384
Validation loss: 2.52006105698638

Epoch: 5| Step: 6
Training loss: 2.7024492069520947
Validation loss: 2.51533224514049

Epoch: 5| Step: 7
Training loss: 1.687256053670089
Validation loss: 2.4675184256633105

Epoch: 5| Step: 8
Training loss: 2.0869122345862374
Validation loss: 2.5005091712665477

Epoch: 5| Step: 9
Training loss: 1.781317860163988
Validation loss: 2.518991704940743

Epoch: 5| Step: 10
Training loss: 2.2914681666554233
Validation loss: 2.533687619509348

Epoch: 349| Step: 0
Training loss: 2.7959853307696645
Validation loss: 2.511789681609663

Epoch: 5| Step: 1
Training loss: 1.7348026057808912
Validation loss: 2.5801815855464785

Epoch: 5| Step: 2
Training loss: 2.5410754866003242
Validation loss: 2.4998240193602044

Epoch: 5| Step: 3
Training loss: 2.441450683189412
Validation loss: 2.5537477829479593

Epoch: 5| Step: 4
Training loss: 2.229946629864916
Validation loss: 2.546561479474993

Epoch: 5| Step: 5
Training loss: 2.0985231792486814
Validation loss: 2.4871289073772425

Epoch: 5| Step: 6
Training loss: 2.2703864214861427
Validation loss: 2.47173428956175

Epoch: 5| Step: 7
Training loss: 2.410814390172903
Validation loss: 2.540222236303918

Epoch: 5| Step: 8
Training loss: 2.513724420645919
Validation loss: 2.5109660131731513

Epoch: 5| Step: 9
Training loss: 2.434440355317298
Validation loss: 2.571702673158637

Epoch: 5| Step: 10
Training loss: 1.849572701981834
Validation loss: 2.529893007770263

Epoch: 350| Step: 0
Training loss: 2.237608483950557
Validation loss: 2.5158183393535754

Epoch: 5| Step: 1
Training loss: 2.2618791856012885
Validation loss: 2.5070643064883003

Epoch: 5| Step: 2
Training loss: 2.684627505984067
Validation loss: 2.4988852117595206

Epoch: 5| Step: 3
Training loss: 2.2818734349182996
Validation loss: 2.4870414414694717

Epoch: 5| Step: 4
Training loss: 2.2734514478537453
Validation loss: 2.53209824897393

Epoch: 5| Step: 5
Training loss: 2.751099800055113
Validation loss: 2.520955122389923

Epoch: 5| Step: 6
Training loss: 2.4311250316206605
Validation loss: 2.5674464068817477

Epoch: 5| Step: 7
Training loss: 1.8594257764534858
Validation loss: 2.540807865028243

Epoch: 5| Step: 8
Training loss: 1.7800716049279182
Validation loss: 2.5119180976745343

Epoch: 5| Step: 9
Training loss: 2.2372348862761036
Validation loss: 2.5347083482762023

Epoch: 5| Step: 10
Training loss: 2.7187428967613294
Validation loss: 2.470036755563565

Epoch: 351| Step: 0
Training loss: 2.7241509821049243
Validation loss: 2.545811445981517

Epoch: 5| Step: 1
Training loss: 2.050608019097224
Validation loss: 2.4627321579116637

Epoch: 5| Step: 2
Training loss: 2.3828279088256905
Validation loss: 2.5001998042176985

Epoch: 5| Step: 3
Training loss: 2.2449758384780765
Validation loss: 2.5876359107393805

Epoch: 5| Step: 4
Training loss: 2.0705102214326025
Validation loss: 2.5627529190547524

Epoch: 5| Step: 5
Training loss: 2.6410759535140644
Validation loss: 2.5314677074072467

Epoch: 5| Step: 6
Training loss: 2.3107056744550443
Validation loss: 2.525937342839049

Epoch: 5| Step: 7
Training loss: 2.2136028924590176
Validation loss: 2.4784729806509693

Epoch: 5| Step: 8
Training loss: 2.1812147033808644
Validation loss: 2.5125783964482835

Epoch: 5| Step: 9
Training loss: 2.2172072513875354
Validation loss: 2.506408416927068

Epoch: 5| Step: 10
Training loss: 2.2790367154507
Validation loss: 2.52266352159922

Epoch: 352| Step: 0
Training loss: 2.180312637869289
Validation loss: 2.5136105652586065

Epoch: 5| Step: 1
Training loss: 2.2603561697978622
Validation loss: 2.489962878707678

Epoch: 5| Step: 2
Training loss: 2.076026373113206
Validation loss: 2.4850925846926546

Epoch: 5| Step: 3
Training loss: 2.112000477436763
Validation loss: 2.503290429032805

Epoch: 5| Step: 4
Training loss: 2.0846680625314717
Validation loss: 2.4820995925029554

Epoch: 5| Step: 5
Training loss: 2.7787306444023367
Validation loss: 2.5720117007152887

Epoch: 5| Step: 6
Training loss: 2.32789631174817
Validation loss: 2.5011390726484732

Epoch: 5| Step: 7
Training loss: 2.490475057302796
Validation loss: 2.498789448059749

Epoch: 5| Step: 8
Training loss: 2.455747623852933
Validation loss: 2.5639569132406574

Epoch: 5| Step: 9
Training loss: 2.318846987934864
Validation loss: 2.5301750024233556

Epoch: 5| Step: 10
Training loss: 2.14263320615588
Validation loss: 2.5256106148520003

Epoch: 353| Step: 0
Training loss: 2.4046901254224418
Validation loss: 2.5456728780469757

Epoch: 5| Step: 1
Training loss: 1.8164525836244414
Validation loss: 2.50423522163188

Epoch: 5| Step: 2
Training loss: 1.636898640873021
Validation loss: 2.5147551903673415

Epoch: 5| Step: 3
Training loss: 1.3516152873232243
Validation loss: 2.5295346482987067

Epoch: 5| Step: 4
Training loss: 1.880568310487592
Validation loss: 2.484773933657307

Epoch: 5| Step: 5
Training loss: 2.301718140601319
Validation loss: 2.548031796196383

Epoch: 5| Step: 6
Training loss: 2.7909700084292663
Validation loss: 2.5211271906114883

Epoch: 5| Step: 7
Training loss: 2.580316894941455
Validation loss: 2.5255626782946954

Epoch: 5| Step: 8
Training loss: 2.456297748285998
Validation loss: 2.5234118526690335

Epoch: 5| Step: 9
Training loss: 2.7382918723603704
Validation loss: 2.5144350609081125

Epoch: 5| Step: 10
Training loss: 2.699933676434889
Validation loss: 2.5525060384401193

Epoch: 354| Step: 0
Training loss: 1.8259058467870617
Validation loss: 2.491714554560844

Epoch: 5| Step: 1
Training loss: 2.49295300054641
Validation loss: 2.521568718549788

Epoch: 5| Step: 2
Training loss: 1.9208707589277478
Validation loss: 2.4951858539635507

Epoch: 5| Step: 3
Training loss: 1.914240365619784
Validation loss: 2.4904621993069895

Epoch: 5| Step: 4
Training loss: 2.72478665557882
Validation loss: 2.5444553924754665

Epoch: 5| Step: 5
Training loss: 1.42123432187682
Validation loss: 2.583744741409732

Epoch: 5| Step: 6
Training loss: 2.205960120157954
Validation loss: 2.4442570899416234

Epoch: 5| Step: 7
Training loss: 2.6572153469018636
Validation loss: 2.6026238289274297

Epoch: 5| Step: 8
Training loss: 2.615403754608757
Validation loss: 2.527763547259663

Epoch: 5| Step: 9
Training loss: 2.675857520582698
Validation loss: 2.5506433264565445

Epoch: 5| Step: 10
Training loss: 2.5966550805058226
Validation loss: 2.56403309770974

Epoch: 355| Step: 0
Training loss: 2.3030235361345097
Validation loss: 2.5276354148983002

Epoch: 5| Step: 1
Training loss: 2.13007511633292
Validation loss: 2.465994022845677

Epoch: 5| Step: 2
Training loss: 1.7675897924554498
Validation loss: 2.5351067940219445

Epoch: 5| Step: 3
Training loss: 2.1402881663595195
Validation loss: 2.4814399113220005

Epoch: 5| Step: 4
Training loss: 2.2614153459195094
Validation loss: 2.5240581235255397

Epoch: 5| Step: 5
Training loss: 2.1181381737554603
Validation loss: 2.5001093676445354

Epoch: 5| Step: 6
Training loss: 2.449851214503764
Validation loss: 2.5335261599669923

Epoch: 5| Step: 7
Training loss: 2.5930795377514406
Validation loss: 2.4930176863205644

Epoch: 5| Step: 8
Training loss: 2.4155156474758517
Validation loss: 2.554320956698017

Epoch: 5| Step: 9
Training loss: 1.7052703084928986
Validation loss: 2.539374380590628

Epoch: 5| Step: 10
Training loss: 2.967139680707105
Validation loss: 2.487366214822865

Epoch: 356| Step: 0
Training loss: 1.9614372072653878
Validation loss: 2.5328093272857055

Epoch: 5| Step: 1
Training loss: 2.556602763339303
Validation loss: 2.567978449845703

Epoch: 5| Step: 2
Training loss: 2.2986676752430473
Validation loss: 2.5510953593495205

Epoch: 5| Step: 3
Training loss: 2.179183409452093
Validation loss: 2.545328527978092

Epoch: 5| Step: 4
Training loss: 1.7571321654354466
Validation loss: 2.497493151534291

Epoch: 5| Step: 5
Training loss: 2.6683092025755406
Validation loss: 2.5587459130384804

Epoch: 5| Step: 6
Training loss: 2.484056848271705
Validation loss: 2.5429096225446193

Epoch: 5| Step: 7
Training loss: 2.444565338940667
Validation loss: 2.518506812082946

Epoch: 5| Step: 8
Training loss: 1.731276416232742
Validation loss: 2.539611126084256

Epoch: 5| Step: 9
Training loss: 2.33307812067039
Validation loss: 2.4983098941622246

Epoch: 5| Step: 10
Training loss: 2.4074907943216837
Validation loss: 2.5356243260202156

Epoch: 357| Step: 0
Training loss: 2.150732084322721
Validation loss: 2.4869751859604174

Epoch: 5| Step: 1
Training loss: 2.049244797395992
Validation loss: 2.518523542574731

Epoch: 5| Step: 2
Training loss: 2.535043957872756
Validation loss: 2.496832049425971

Epoch: 5| Step: 3
Training loss: 2.4895693620318995
Validation loss: 2.481510175307678

Epoch: 5| Step: 4
Training loss: 1.569520513365856
Validation loss: 2.513993065815011

Epoch: 5| Step: 5
Training loss: 2.564536146343923
Validation loss: 2.5286526821467805

Epoch: 5| Step: 6
Training loss: 2.2992368219762604
Validation loss: 2.504677177668266

Epoch: 5| Step: 7
Training loss: 2.744128374500013
Validation loss: 2.495430030376514

Epoch: 5| Step: 8
Training loss: 2.2065669018569563
Validation loss: 2.5194501004764187

Epoch: 5| Step: 9
Training loss: 2.2300960944302526
Validation loss: 2.554463070389143

Epoch: 5| Step: 10
Training loss: 2.269054789601633
Validation loss: 2.531985181324761

Epoch: 358| Step: 0
Training loss: 2.4203898152167516
Validation loss: 2.4951038628102733

Epoch: 5| Step: 1
Training loss: 2.100120304839655
Validation loss: 2.545691290528192

Epoch: 5| Step: 2
Training loss: 2.0900654042427598
Validation loss: 2.5205311347874835

Epoch: 5| Step: 3
Training loss: 1.8738962739596055
Validation loss: 2.5221113482200224

Epoch: 5| Step: 4
Training loss: 2.6067107527469036
Validation loss: 2.510601055481363

Epoch: 5| Step: 5
Training loss: 1.9926565777414849
Validation loss: 2.515701082862869

Epoch: 5| Step: 6
Training loss: 2.7488281180612297
Validation loss: 2.49671737853293

Epoch: 5| Step: 7
Training loss: 2.1876480052469227
Validation loss: 2.523879287059737

Epoch: 5| Step: 8
Training loss: 2.1544249177510935
Validation loss: 2.5384985432030036

Epoch: 5| Step: 9
Training loss: 1.8934417423365089
Validation loss: 2.506244076834929

Epoch: 5| Step: 10
Training loss: 2.522109872310842
Validation loss: 2.4811596868735175

Epoch: 359| Step: 0
Training loss: 2.381866667589534
Validation loss: 2.4725012109281255

Epoch: 5| Step: 1
Training loss: 2.4799521561591424
Validation loss: 2.561620133533397

Epoch: 5| Step: 2
Training loss: 1.9478011547525071
Validation loss: 2.539862696762506

Epoch: 5| Step: 3
Training loss: 2.209387353757342
Validation loss: 2.5690242619623676

Epoch: 5| Step: 4
Training loss: 1.6108797316456185
Validation loss: 2.477627286027724

Epoch: 5| Step: 5
Training loss: 2.1437777948384897
Validation loss: 2.556799048680221

Epoch: 5| Step: 6
Training loss: 2.3253622367634526
Validation loss: 2.5477947781449046

Epoch: 5| Step: 7
Training loss: 2.7724530259221387
Validation loss: 2.5243553494522817

Epoch: 5| Step: 8
Training loss: 2.2048525699106287
Validation loss: 2.5170927276138078

Epoch: 5| Step: 9
Training loss: 2.5292519112497085
Validation loss: 2.5281616212341302

Epoch: 5| Step: 10
Training loss: 2.2811806028078867
Validation loss: 2.458007449544682

Epoch: 360| Step: 0
Training loss: 1.881192852178804
Validation loss: 2.5227269974077906

Epoch: 5| Step: 1
Training loss: 2.386790772395567
Validation loss: 2.5314199070817374

Epoch: 5| Step: 2
Training loss: 2.620761628577552
Validation loss: 2.507489945471853

Epoch: 5| Step: 3
Training loss: 2.266309647866643
Validation loss: 2.5312562124848834

Epoch: 5| Step: 4
Training loss: 2.233835648750248
Validation loss: 2.477355034181589

Epoch: 5| Step: 5
Training loss: 2.426400564750709
Validation loss: 2.5204561863793753

Epoch: 5| Step: 6
Training loss: 2.0438011326357524
Validation loss: 2.5454759185533224

Epoch: 5| Step: 7
Training loss: 2.1188299698493016
Validation loss: 2.54695587160662

Epoch: 5| Step: 8
Training loss: 2.490254672098655
Validation loss: 2.5321850727616257

Epoch: 5| Step: 9
Training loss: 1.904730707293427
Validation loss: 2.4925638046488516

Epoch: 5| Step: 10
Training loss: 2.560620525822677
Validation loss: 2.545039779181685

Epoch: 361| Step: 0
Training loss: 2.3493299056442027
Validation loss: 2.5642087528013287

Epoch: 5| Step: 1
Training loss: 2.4510693532469188
Validation loss: 2.5037738536661958

Epoch: 5| Step: 2
Training loss: 2.7460223822185097
Validation loss: 2.5133201247899333

Epoch: 5| Step: 3
Training loss: 2.443908385780776
Validation loss: 2.519396154011269

Epoch: 5| Step: 4
Training loss: 2.1280036342704545
Validation loss: 2.5607887544856287

Epoch: 5| Step: 5
Training loss: 1.8922559150908767
Validation loss: 2.490889203465213

Epoch: 5| Step: 6
Training loss: 2.2031625514516393
Validation loss: 2.533757223805813

Epoch: 5| Step: 7
Training loss: 1.8575619104267065
Validation loss: 2.5134026554168125

Epoch: 5| Step: 8
Training loss: 2.4472958257688595
Validation loss: 2.5035116348561335

Epoch: 5| Step: 9
Training loss: 1.9818385576731041
Validation loss: 2.5474039053633

Epoch: 5| Step: 10
Training loss: 2.1276662592579956
Validation loss: 2.520717676842362

Epoch: 362| Step: 0
Training loss: 1.7140772329443172
Validation loss: 2.5322821834589435

Epoch: 5| Step: 1
Training loss: 2.6131605454011546
Validation loss: 2.5498342403260277

Epoch: 5| Step: 2
Training loss: 2.4436554092871563
Validation loss: 2.50511592783002

Epoch: 5| Step: 3
Training loss: 2.491425496383209
Validation loss: 2.5072151786070047

Epoch: 5| Step: 4
Training loss: 1.8215057653209705
Validation loss: 2.526449252856374

Epoch: 5| Step: 5
Training loss: 2.4161352252884942
Validation loss: 2.5478071782600007

Epoch: 5| Step: 6
Training loss: 2.2761998125269782
Validation loss: 2.5133602867967118

Epoch: 5| Step: 7
Training loss: 2.5190696115964815
Validation loss: 2.497895879146772

Epoch: 5| Step: 8
Training loss: 1.917089256747847
Validation loss: 2.505221948967632

Epoch: 5| Step: 9
Training loss: 2.40300452596339
Validation loss: 2.4895291292709674

Epoch: 5| Step: 10
Training loss: 2.3038365749043894
Validation loss: 2.580265396417623

Epoch: 363| Step: 0
Training loss: 2.5973015794059737
Validation loss: 2.4959598320272027

Epoch: 5| Step: 1
Training loss: 2.5509392074584856
Validation loss: 2.5483445040602857

Epoch: 5| Step: 2
Training loss: 2.277266695737595
Validation loss: 2.4749281476610925

Epoch: 5| Step: 3
Training loss: 1.7810775941098789
Validation loss: 2.5371667471051595

Epoch: 5| Step: 4
Training loss: 2.051852166440664
Validation loss: 2.555499904479015

Epoch: 5| Step: 5
Training loss: 3.064101909596046
Validation loss: 2.5617227723722977

Epoch: 5| Step: 6
Training loss: 2.499003974865595
Validation loss: 2.5616168789662837

Epoch: 5| Step: 7
Training loss: 1.1905400864165838
Validation loss: 2.563839303052534

Epoch: 5| Step: 8
Training loss: 2.1625109457279206
Validation loss: 2.514326933265679

Epoch: 5| Step: 9
Training loss: 1.7524505215352235
Validation loss: 2.569441021395281

Epoch: 5| Step: 10
Training loss: 2.503339634907288
Validation loss: 2.4950206801422006

Epoch: 364| Step: 0
Training loss: 2.718040198263937
Validation loss: 2.553138686141788

Epoch: 5| Step: 1
Training loss: 1.9413064052151694
Validation loss: 2.495396165615543

Epoch: 5| Step: 2
Training loss: 2.456864149661136
Validation loss: 2.492100485271029

Epoch: 5| Step: 3
Training loss: 2.0556858668677336
Validation loss: 2.512679393096103

Epoch: 5| Step: 4
Training loss: 1.625266346744655
Validation loss: 2.5304278830417233

Epoch: 5| Step: 5
Training loss: 2.848724541611044
Validation loss: 2.4358345696856665

Epoch: 5| Step: 6
Training loss: 1.9550127595841207
Validation loss: 2.5707151953593477

Epoch: 5| Step: 7
Training loss: 1.7269963888717033
Validation loss: 2.557179989995394

Epoch: 5| Step: 8
Training loss: 2.3496865936046203
Validation loss: 2.533533510299054

Epoch: 5| Step: 9
Training loss: 2.468072822504198
Validation loss: 2.537728438982515

Epoch: 5| Step: 10
Training loss: 2.4727863199214117
Validation loss: 2.570302723424856

Epoch: 365| Step: 0
Training loss: 2.720519268453516
Validation loss: 2.50386256627036

Epoch: 5| Step: 1
Training loss: 2.7842026371379647
Validation loss: 2.527942898938378

Epoch: 5| Step: 2
Training loss: 2.0521029037342764
Validation loss: 2.4932147915819467

Epoch: 5| Step: 3
Training loss: 2.152503144442469
Validation loss: 2.5399770442933653

Epoch: 5| Step: 4
Training loss: 2.15382901711511
Validation loss: 2.5970277245301143

Epoch: 5| Step: 5
Training loss: 2.309531807124842
Validation loss: 2.5386079175238043

Epoch: 5| Step: 6
Training loss: 2.1680169177503794
Validation loss: 2.5521428161345776

Epoch: 5| Step: 7
Training loss: 1.9992340528551686
Validation loss: 2.5550685343896062

Epoch: 5| Step: 8
Training loss: 1.9179962218389601
Validation loss: 2.481868425409728

Epoch: 5| Step: 9
Training loss: 1.842283150322755
Validation loss: 2.51425945334673

Epoch: 5| Step: 10
Training loss: 2.6095686058356913
Validation loss: 2.5349279937028557

Epoch: 366| Step: 0
Training loss: 2.06744047362905
Validation loss: 2.4589522545355496

Epoch: 5| Step: 1
Training loss: 2.2742451809415556
Validation loss: 2.51494553901314

Epoch: 5| Step: 2
Training loss: 2.3337302097488757
Validation loss: 2.5445331310607426

Epoch: 5| Step: 3
Training loss: 2.0910504146356326
Validation loss: 2.564023043229242

Epoch: 5| Step: 4
Training loss: 1.8053995024253064
Validation loss: 2.479274449255049

Epoch: 5| Step: 5
Training loss: 2.024654066890483
Validation loss: 2.521016704005731

Epoch: 5| Step: 6
Training loss: 1.523301886366805
Validation loss: 2.5390036531480638

Epoch: 5| Step: 7
Training loss: 2.099164764879957
Validation loss: 2.493996401561938

Epoch: 5| Step: 8
Training loss: 3.0148983410956185
Validation loss: 2.491806627630284

Epoch: 5| Step: 9
Training loss: 2.929977687451289
Validation loss: 2.552176038922098

Epoch: 5| Step: 10
Training loss: 2.0229148631639493
Validation loss: 2.5154532993883514

Epoch: 367| Step: 0
Training loss: 1.8515655903850792
Validation loss: 2.5486503456409024

Epoch: 5| Step: 1
Training loss: 2.6202780624064714
Validation loss: 2.577681732603657

Epoch: 5| Step: 2
Training loss: 2.2756284663114523
Validation loss: 2.4804925634668464

Epoch: 5| Step: 3
Training loss: 2.1097559832087933
Validation loss: 2.531335296267297

Epoch: 5| Step: 4
Training loss: 1.773684379433751
Validation loss: 2.540262360517443

Epoch: 5| Step: 5
Training loss: 1.7177079943519136
Validation loss: 2.4777291175812493

Epoch: 5| Step: 6
Training loss: 2.388297549944888
Validation loss: 2.5056795199834223

Epoch: 5| Step: 7
Training loss: 2.5643026942621834
Validation loss: 2.503582851213553

Epoch: 5| Step: 8
Training loss: 1.9037638226293447
Validation loss: 2.5464117093207337

Epoch: 5| Step: 9
Training loss: 2.467631605787688
Validation loss: 2.55841585962601

Epoch: 5| Step: 10
Training loss: 2.696340259921164
Validation loss: 2.488994749350004

Epoch: 368| Step: 0
Training loss: 2.0943845100608116
Validation loss: 2.561978194729914

Epoch: 5| Step: 1
Training loss: 1.6787877001473825
Validation loss: 2.5770435430421177

Epoch: 5| Step: 2
Training loss: 2.542606638544701
Validation loss: 2.4300069697519935

Epoch: 5| Step: 3
Training loss: 2.3384360535242608
Validation loss: 2.5165643514615663

Epoch: 5| Step: 4
Training loss: 2.3286983116912716
Validation loss: 2.5566507105186296

Epoch: 5| Step: 5
Training loss: 2.539704884182939
Validation loss: 2.5156004444702926

Epoch: 5| Step: 6
Training loss: 2.0681130295859824
Validation loss: 2.5336422368667955

Epoch: 5| Step: 7
Training loss: 2.2594634359313157
Validation loss: 2.4975641422660977

Epoch: 5| Step: 8
Training loss: 2.0349890700663007
Validation loss: 2.5268510031704023

Epoch: 5| Step: 9
Training loss: 2.206578138982406
Validation loss: 2.5347665322585495

Epoch: 5| Step: 10
Training loss: 2.4272072450717026
Validation loss: 2.564611464428003

Epoch: 369| Step: 0
Training loss: 2.4473745408599625
Validation loss: 2.5289744412461244

Epoch: 5| Step: 1
Training loss: 2.6213846286878613
Validation loss: 2.5106001221717986

Epoch: 5| Step: 2
Training loss: 2.0276619545708696
Validation loss: 2.5228955295046127

Epoch: 5| Step: 3
Training loss: 2.7775635022063963
Validation loss: 2.506790096350018

Epoch: 5| Step: 4
Training loss: 2.0329516985512908
Validation loss: 2.528616830095885

Epoch: 5| Step: 5
Training loss: 2.2746664704027943
Validation loss: 2.5052058715548977

Epoch: 5| Step: 6
Training loss: 2.2763590180435775
Validation loss: 2.51372486071438

Epoch: 5| Step: 7
Training loss: 2.3508364548291136
Validation loss: 2.5492618543633268

Epoch: 5| Step: 8
Training loss: 1.8288383070405514
Validation loss: 2.500572031472936

Epoch: 5| Step: 9
Training loss: 1.898705357622582
Validation loss: 2.474090492505187

Epoch: 5| Step: 10
Training loss: 2.4072519173360454
Validation loss: 2.554788327141119

Epoch: 370| Step: 0
Training loss: 2.302247906033884
Validation loss: 2.5652026423908314

Epoch: 5| Step: 1
Training loss: 2.4414340818726092
Validation loss: 2.5053493161701867

Epoch: 5| Step: 2
Training loss: 1.6373782775133197
Validation loss: 2.4865618617157366

Epoch: 5| Step: 3
Training loss: 1.7986933256953845
Validation loss: 2.5216521168429957

Epoch: 5| Step: 4
Training loss: 2.4050200650652998
Validation loss: 2.5071105945907046

Epoch: 5| Step: 5
Training loss: 1.9778852296362293
Validation loss: 2.5231073950250975

Epoch: 5| Step: 6
Training loss: 2.869767776823677
Validation loss: 2.496314262589012

Epoch: 5| Step: 7
Training loss: 2.521793172234359
Validation loss: 2.5094466662267814

Epoch: 5| Step: 8
Training loss: 2.4502381267433133
Validation loss: 2.5671589974356044

Epoch: 5| Step: 9
Training loss: 2.175094961965315
Validation loss: 2.5176381783114654

Epoch: 5| Step: 10
Training loss: 1.9903212239162145
Validation loss: 2.5280897318264635

Epoch: 371| Step: 0
Training loss: 2.4491558644862446
Validation loss: 2.462776382782935

Epoch: 5| Step: 1
Training loss: 1.637300883992585
Validation loss: 2.5202553168691515

Epoch: 5| Step: 2
Training loss: 1.8764541073764218
Validation loss: 2.500332916817155

Epoch: 5| Step: 3
Training loss: 1.9220822230325576
Validation loss: 2.5096704399145646

Epoch: 5| Step: 4
Training loss: 2.150367119961229
Validation loss: 2.5489890497596055

Epoch: 5| Step: 5
Training loss: 2.2862108193654183
Validation loss: 2.5326826183044338

Epoch: 5| Step: 6
Training loss: 2.6727795770643006
Validation loss: 2.5199219067819905

Epoch: 5| Step: 7
Training loss: 2.3553733996170405
Validation loss: 2.5423683352531428

Epoch: 5| Step: 8
Training loss: 2.214823620147997
Validation loss: 2.5191436538127396

Epoch: 5| Step: 9
Training loss: 2.789695261921708
Validation loss: 2.506466870205989

Epoch: 5| Step: 10
Training loss: 2.4281962930432184
Validation loss: 2.4869368048905645

Epoch: 372| Step: 0
Training loss: 2.472744185343956
Validation loss: 2.5023535775999908

Epoch: 5| Step: 1
Training loss: 1.8747383570906626
Validation loss: 2.4635501804103663

Epoch: 5| Step: 2
Training loss: 2.489908066856382
Validation loss: 2.4938711092922468

Epoch: 5| Step: 3
Training loss: 2.490875568493393
Validation loss: 2.5384254210377395

Epoch: 5| Step: 4
Training loss: 2.087219758553374
Validation loss: 2.5185146551510074

Epoch: 5| Step: 5
Training loss: 2.6687674492794873
Validation loss: 2.5355717473843833

Epoch: 5| Step: 6
Training loss: 1.8839337820860462
Validation loss: 2.511254866921532

Epoch: 5| Step: 7
Training loss: 1.810335840397092
Validation loss: 2.5240770588157573

Epoch: 5| Step: 8
Training loss: 2.1850798161504303
Validation loss: 2.565212122097391

Epoch: 5| Step: 9
Training loss: 2.276584191045536
Validation loss: 2.4763310437723294

Epoch: 5| Step: 10
Training loss: 2.5324225829813525
Validation loss: 2.509649600106707

Epoch: 373| Step: 0
Training loss: 2.2169874470673263
Validation loss: 2.479204163268199

Epoch: 5| Step: 1
Training loss: 1.8883432538321026
Validation loss: 2.4996592576584544

Epoch: 5| Step: 2
Training loss: 2.0115171461102337
Validation loss: 2.5486967621302816

Epoch: 5| Step: 3
Training loss: 2.940242866553518
Validation loss: 2.493713219455415

Epoch: 5| Step: 4
Training loss: 2.076916565572416
Validation loss: 2.545469855586907

Epoch: 5| Step: 5
Training loss: 2.2320935532710537
Validation loss: 2.5379976933522963

Epoch: 5| Step: 6
Training loss: 2.398567718052483
Validation loss: 2.5145724910072067

Epoch: 5| Step: 7
Training loss: 2.5934087689696645
Validation loss: 2.4836783969720218

Epoch: 5| Step: 8
Training loss: 2.376646775977893
Validation loss: 2.492711008647419

Epoch: 5| Step: 9
Training loss: 2.1238236256590883
Validation loss: 2.4563961798508998

Epoch: 5| Step: 10
Training loss: 1.9299776422856016
Validation loss: 2.528692844964698

Epoch: 374| Step: 0
Training loss: 2.132959940638342
Validation loss: 2.543441631460837

Epoch: 5| Step: 1
Training loss: 2.340195159761832
Validation loss: 2.4825205987692147

Epoch: 5| Step: 2
Training loss: 2.0292581035005277
Validation loss: 2.518463812702647

Epoch: 5| Step: 3
Training loss: 2.3800331791400247
Validation loss: 2.4970041105728944

Epoch: 5| Step: 4
Training loss: 1.7433056172829375
Validation loss: 2.538141558332199

Epoch: 5| Step: 5
Training loss: 2.361338221778455
Validation loss: 2.5525291416797473

Epoch: 5| Step: 6
Training loss: 2.0661281694241027
Validation loss: 2.5101865604170084

Epoch: 5| Step: 7
Training loss: 2.471999432196444
Validation loss: 2.459727285408521

Epoch: 5| Step: 8
Training loss: 2.0944875300681165
Validation loss: 2.4699373683002483

Epoch: 5| Step: 9
Training loss: 2.577787619970248
Validation loss: 2.473774698088108

Epoch: 5| Step: 10
Training loss: 2.299251339182744
Validation loss: 2.4884111450329525

Epoch: 375| Step: 0
Training loss: 1.8171269781476236
Validation loss: 2.492473716372213

Epoch: 5| Step: 1
Training loss: 1.8737736188075615
Validation loss: 2.514386035463001

Epoch: 5| Step: 2
Training loss: 2.196795631157906
Validation loss: 2.5381985303676258

Epoch: 5| Step: 3
Training loss: 2.897830539706045
Validation loss: 2.4937163405874028

Epoch: 5| Step: 4
Training loss: 1.965732926891421
Validation loss: 2.5228027919064555

Epoch: 5| Step: 5
Training loss: 2.6121238802790483
Validation loss: 2.5283912417398633

Epoch: 5| Step: 6
Training loss: 2.140123628806506
Validation loss: 2.526160033260301

Epoch: 5| Step: 7
Training loss: 2.352889589487489
Validation loss: 2.519441133391379

Epoch: 5| Step: 8
Training loss: 2.801515022892512
Validation loss: 2.481800876932234

Epoch: 5| Step: 9
Training loss: 1.7535063493720826
Validation loss: 2.526282794092886

Epoch: 5| Step: 10
Training loss: 2.106859982509725
Validation loss: 2.5074415305974993

Epoch: 376| Step: 0
Training loss: 2.3224559606476824
Validation loss: 2.5057279371863066

Epoch: 5| Step: 1
Training loss: 1.8935607941535428
Validation loss: 2.5573552065719523

Epoch: 5| Step: 2
Training loss: 2.049898084572745
Validation loss: 2.5976027739876613

Epoch: 5| Step: 3
Training loss: 2.7114653059793676
Validation loss: 2.4662408774145206

Epoch: 5| Step: 4
Training loss: 2.510061996119864
Validation loss: 2.5534203464902756

Epoch: 5| Step: 5
Training loss: 2.0170103531639363
Validation loss: 2.5604932006647876

Epoch: 5| Step: 6
Training loss: 1.7019083419486878
Validation loss: 2.5652049304956854

Epoch: 5| Step: 7
Training loss: 2.3229373765601005
Validation loss: 2.5513309865722027

Epoch: 5| Step: 8
Training loss: 2.9535857956260596
Validation loss: 2.473972176392733

Epoch: 5| Step: 9
Training loss: 1.6815313110975412
Validation loss: 2.5323494939168136

Epoch: 5| Step: 10
Training loss: 1.562143514021179
Validation loss: 2.4710868044994903

Epoch: 377| Step: 0
Training loss: 2.3477188076627735
Validation loss: 2.5373779211336216

Epoch: 5| Step: 1
Training loss: 1.894476695110943
Validation loss: 2.5169288630961177

Epoch: 5| Step: 2
Training loss: 2.166704348701081
Validation loss: 2.44456263955909

Epoch: 5| Step: 3
Training loss: 1.8598723187255812
Validation loss: 2.521091451695679

Epoch: 5| Step: 4
Training loss: 1.7094243992671019
Validation loss: 2.545273366364751

Epoch: 5| Step: 5
Training loss: 2.8802386116151673
Validation loss: 2.541199955150158

Epoch: 5| Step: 6
Training loss: 2.0522743820357348
Validation loss: 2.4913774762555043

Epoch: 5| Step: 7
Training loss: 1.899052587009035
Validation loss: 2.472705307599748

Epoch: 5| Step: 8
Training loss: 2.75592512434856
Validation loss: 2.5695314596782026

Epoch: 5| Step: 9
Training loss: 2.454617283312786
Validation loss: 2.5530977611660415

Epoch: 5| Step: 10
Training loss: 1.9516774420871037
Validation loss: 2.4475711645886857

Epoch: 378| Step: 0
Training loss: 2.4712165389547645
Validation loss: 2.474120002131642

Epoch: 5| Step: 1
Training loss: 1.575286805817946
Validation loss: 2.4967701362174557

Epoch: 5| Step: 2
Training loss: 2.2966507782776384
Validation loss: 2.479306199933286

Epoch: 5| Step: 3
Training loss: 2.380582172131742
Validation loss: 2.5494910863160514

Epoch: 5| Step: 4
Training loss: 2.1508242025357682
Validation loss: 2.5324511010944772

Epoch: 5| Step: 5
Training loss: 2.6418023729415196
Validation loss: 2.50526544577753

Epoch: 5| Step: 6
Training loss: 2.014511037145371
Validation loss: 2.515136269755004

Epoch: 5| Step: 7
Training loss: 2.6769148381466485
Validation loss: 2.4728326172610626

Epoch: 5| Step: 8
Training loss: 2.393570923643168
Validation loss: 2.4509864537298633

Epoch: 5| Step: 9
Training loss: 1.637843362466132
Validation loss: 2.536672894683631

Epoch: 5| Step: 10
Training loss: 2.381684983941397
Validation loss: 2.523699453585452

Epoch: 379| Step: 0
Training loss: 2.1494507775643803
Validation loss: 2.4922752204203285

Epoch: 5| Step: 1
Training loss: 1.4562307823124638
Validation loss: 2.52736561497847

Epoch: 5| Step: 2
Training loss: 2.0055410398108844
Validation loss: 2.4999345750348967

Epoch: 5| Step: 3
Training loss: 2.3112989863831044
Validation loss: 2.528719038909198

Epoch: 5| Step: 4
Training loss: 2.1723183378379383
Validation loss: 2.528887433225263

Epoch: 5| Step: 5
Training loss: 2.356002924180604
Validation loss: 2.5146711555503702

Epoch: 5| Step: 6
Training loss: 2.1392031214478
Validation loss: 2.4845896023437386

Epoch: 5| Step: 7
Training loss: 3.1000205562279173
Validation loss: 2.486644930425218

Epoch: 5| Step: 8
Training loss: 1.939184994328861
Validation loss: 2.4564578906481684

Epoch: 5| Step: 9
Training loss: 2.181967250651636
Validation loss: 2.519575442993126

Epoch: 5| Step: 10
Training loss: 1.8922562300833645
Validation loss: 2.4841158275013897

Epoch: 380| Step: 0
Training loss: 2.5180569852542156
Validation loss: 2.506938915193374

Epoch: 5| Step: 1
Training loss: 1.8821202821998626
Validation loss: 2.506590125046154

Epoch: 5| Step: 2
Training loss: 2.234533557734609
Validation loss: 2.506627472902399

Epoch: 5| Step: 3
Training loss: 2.2469075461883525
Validation loss: 2.512338006116357

Epoch: 5| Step: 4
Training loss: 2.2268748281833735
Validation loss: 2.5035408371152403

Epoch: 5| Step: 5
Training loss: 2.477439364125282
Validation loss: 2.478784274354732

Epoch: 5| Step: 6
Training loss: 2.075569474540961
Validation loss: 2.4809331628244995

Epoch: 5| Step: 7
Training loss: 2.3095503888873727
Validation loss: 2.550428050246787

Epoch: 5| Step: 8
Training loss: 1.8110994650005405
Validation loss: 2.511114434459872

Epoch: 5| Step: 9
Training loss: 1.7141786297776487
Validation loss: 2.558241846075414

Epoch: 5| Step: 10
Training loss: 2.5004109998461965
Validation loss: 2.467968963736367

Epoch: 381| Step: 0
Training loss: 1.9424457798758679
Validation loss: 2.521867833882953

Epoch: 5| Step: 1
Training loss: 2.325816501277245
Validation loss: 2.495405298210215

Epoch: 5| Step: 2
Training loss: 2.4528607268640115
Validation loss: 2.527112945807052

Epoch: 5| Step: 3
Training loss: 2.4079693683120738
Validation loss: 2.5209328077461843

Epoch: 5| Step: 4
Training loss: 1.9647842307205043
Validation loss: 2.5312815104287676

Epoch: 5| Step: 5
Training loss: 2.519032131703405
Validation loss: 2.4999298588337124

Epoch: 5| Step: 6
Training loss: 1.9505073400895692
Validation loss: 2.5106289667910695

Epoch: 5| Step: 7
Training loss: 1.9426203717183428
Validation loss: 2.5317700468494007

Epoch: 5| Step: 8
Training loss: 2.298101084950175
Validation loss: 2.468330923024997

Epoch: 5| Step: 9
Training loss: 2.1451895281949893
Validation loss: 2.4888901856207117

Epoch: 5| Step: 10
Training loss: 2.626607856608493
Validation loss: 2.5049149529472943

Epoch: 382| Step: 0
Training loss: 2.5302983131496237
Validation loss: 2.5585346359441603

Epoch: 5| Step: 1
Training loss: 1.785788726617427
Validation loss: 2.5120867599595567

Epoch: 5| Step: 2
Training loss: 2.1511969583412536
Validation loss: 2.456359494953745

Epoch: 5| Step: 3
Training loss: 2.509579140232499
Validation loss: 2.5613226938551286

Epoch: 5| Step: 4
Training loss: 2.077581807900249
Validation loss: 2.5256752072261346

Epoch: 5| Step: 5
Training loss: 1.7277741474401038
Validation loss: 2.6020121354750674

Epoch: 5| Step: 6
Training loss: 2.2674865441306857
Validation loss: 2.603673204163177

Epoch: 5| Step: 7
Training loss: 2.5008711250836866
Validation loss: 2.494011587562045

Epoch: 5| Step: 8
Training loss: 2.049905644548132
Validation loss: 2.537217982686467

Epoch: 5| Step: 9
Training loss: 2.2941939088104877
Validation loss: 2.515432046827622

Epoch: 5| Step: 10
Training loss: 2.032046587342397
Validation loss: 2.536774192263385

Epoch: 383| Step: 0
Training loss: 2.382810098615593
Validation loss: 2.460477842240186

Epoch: 5| Step: 1
Training loss: 1.8443340087802977
Validation loss: 2.550105650126899

Epoch: 5| Step: 2
Training loss: 2.079848299179851
Validation loss: 2.5196389843883154

Epoch: 5| Step: 3
Training loss: 2.4936188321525643
Validation loss: 2.576543065723548

Epoch: 5| Step: 4
Training loss: 2.2420681911718803
Validation loss: 2.4802838496316477

Epoch: 5| Step: 5
Training loss: 2.0393954768834837
Validation loss: 2.465598398361939

Epoch: 5| Step: 6
Training loss: 2.486834765864021
Validation loss: 2.5517076291521876

Epoch: 5| Step: 7
Training loss: 2.040743080449877
Validation loss: 2.5335400409864395

Epoch: 5| Step: 8
Training loss: 2.2592102792719446
Validation loss: 2.4952542904532344

Epoch: 5| Step: 9
Training loss: 2.329028575081496
Validation loss: 2.5820543045117534

Epoch: 5| Step: 10
Training loss: 1.5616762660222436
Validation loss: 2.556877204062134

Epoch: 384| Step: 0
Training loss: 2.4779273282618135
Validation loss: 2.5653289997882545

Epoch: 5| Step: 1
Training loss: 2.0153473655463707
Validation loss: 2.5194287534194837

Epoch: 5| Step: 2
Training loss: 2.0063456955187853
Validation loss: 2.56212864287628

Epoch: 5| Step: 3
Training loss: 2.4618651564150222
Validation loss: 2.4417704617445306

Epoch: 5| Step: 4
Training loss: 2.1976908225748315
Validation loss: 2.528794559529417

Epoch: 5| Step: 5
Training loss: 2.1722949603109347
Validation loss: 2.4907217937167028

Epoch: 5| Step: 6
Training loss: 2.3978072838867597
Validation loss: 2.570970092280144

Epoch: 5| Step: 7
Training loss: 2.0219065644572964
Validation loss: 2.484575506658064

Epoch: 5| Step: 8
Training loss: 2.0218281476637183
Validation loss: 2.5424567317157667

Epoch: 5| Step: 9
Training loss: 1.6542069411799865
Validation loss: 2.5260859957578328

Epoch: 5| Step: 10
Training loss: 2.4873006616207114
Validation loss: 2.4813583901254104

Epoch: 385| Step: 0
Training loss: 1.5769248402354847
Validation loss: 2.495964646115922

Epoch: 5| Step: 1
Training loss: 2.555959868813019
Validation loss: 2.52430001592289

Epoch: 5| Step: 2
Training loss: 2.2378630189130115
Validation loss: 2.5364896186947083

Epoch: 5| Step: 3
Training loss: 2.388396577106426
Validation loss: 2.541703027404279

Epoch: 5| Step: 4
Training loss: 2.221906431595485
Validation loss: 2.53960104860626

Epoch: 5| Step: 5
Training loss: 1.6067102834049436
Validation loss: 2.4909348617574465

Epoch: 5| Step: 6
Training loss: 3.0601737081552205
Validation loss: 2.553330619210503

Epoch: 5| Step: 7
Training loss: 1.8313109846668985
Validation loss: 2.544483189345228

Epoch: 5| Step: 8
Training loss: 2.4367778392988853
Validation loss: 2.5525959493713875

Epoch: 5| Step: 9
Training loss: 2.124880843468167
Validation loss: 2.4555291352630713

Epoch: 5| Step: 10
Training loss: 2.19339339789535
Validation loss: 2.463960024406688

Epoch: 386| Step: 0
Training loss: 2.4292685586052194
Validation loss: 2.5675153795627152

Epoch: 5| Step: 1
Training loss: 2.31252495004752
Validation loss: 2.4900901193837677

Epoch: 5| Step: 2
Training loss: 1.9771941008924137
Validation loss: 2.532380938528858

Epoch: 5| Step: 3
Training loss: 1.9868731655845562
Validation loss: 2.4995142516076356

Epoch: 5| Step: 4
Training loss: 2.231418494265814
Validation loss: 2.508078250445795

Epoch: 5| Step: 5
Training loss: 2.6367322229111805
Validation loss: 2.52891033863302

Epoch: 5| Step: 6
Training loss: 2.5102373325562817
Validation loss: 2.526866336161277

Epoch: 5| Step: 7
Training loss: 1.8521137302280053
Validation loss: 2.44073709222604

Epoch: 5| Step: 8
Training loss: 1.801298451986417
Validation loss: 2.5451083397155396

Epoch: 5| Step: 9
Training loss: 1.9873132054101852
Validation loss: 2.4929971803416295

Epoch: 5| Step: 10
Training loss: 2.30595616482099
Validation loss: 2.4977684048906545

Epoch: 387| Step: 0
Training loss: 1.9910968861977663
Validation loss: 2.4857345125175

Epoch: 5| Step: 1
Training loss: 2.4183629320131126
Validation loss: 2.501659826743587

Epoch: 5| Step: 2
Training loss: 1.7823769200274073
Validation loss: 2.483947582991661

Epoch: 5| Step: 3
Training loss: 2.2094627826954802
Validation loss: 2.505757625678083

Epoch: 5| Step: 4
Training loss: 2.7155042544651016
Validation loss: 2.4769042140890805

Epoch: 5| Step: 5
Training loss: 1.8118356605304062
Validation loss: 2.5492107170375924

Epoch: 5| Step: 6
Training loss: 1.5005345981350098
Validation loss: 2.5013259068587264

Epoch: 5| Step: 7
Training loss: 2.087188459893897
Validation loss: 2.465285886822153

Epoch: 5| Step: 8
Training loss: 2.4688112275462255
Validation loss: 2.5470580384964867

Epoch: 5| Step: 9
Training loss: 3.0044608329699667
Validation loss: 2.5162116872102156

Epoch: 5| Step: 10
Training loss: 1.9811862947348466
Validation loss: 2.508828076444242

Epoch: 388| Step: 0
Training loss: 2.285776324792612
Validation loss: 2.5503365809471643

Epoch: 5| Step: 1
Training loss: 2.533019401105517
Validation loss: 2.506995111508177

Epoch: 5| Step: 2
Training loss: 2.4422070952133943
Validation loss: 2.463408234067375

Epoch: 5| Step: 3
Training loss: 1.8549203805210912
Validation loss: 2.529620106791191

Epoch: 5| Step: 4
Training loss: 2.342393202652475
Validation loss: 2.511677697221831

Epoch: 5| Step: 5
Training loss: 2.760647189513405
Validation loss: 2.504167350504276

Epoch: 5| Step: 6
Training loss: 1.1799941516989918
Validation loss: 2.508218824281431

Epoch: 5| Step: 7
Training loss: 2.225847417210112
Validation loss: 2.6062673792467765

Epoch: 5| Step: 8
Training loss: 1.8238773394048011
Validation loss: 2.48989950870202

Epoch: 5| Step: 9
Training loss: 1.849241580669096
Validation loss: 2.5236090180161344

Epoch: 5| Step: 10
Training loss: 1.9924206167223901
Validation loss: 2.5081828574844933

Epoch: 389| Step: 0
Training loss: 2.477899713846855
Validation loss: 2.597641714818559

Epoch: 5| Step: 1
Training loss: 2.2205763271504377
Validation loss: 2.526298238099259

Epoch: 5| Step: 2
Training loss: 2.6758234842127666
Validation loss: 2.4863096817343413

Epoch: 5| Step: 3
Training loss: 2.0459603165985274
Validation loss: 2.4933754119570914

Epoch: 5| Step: 4
Training loss: 2.276943583852136
Validation loss: 2.5171186796931893

Epoch: 5| Step: 5
Training loss: 2.504848832463235
Validation loss: 2.5219818613479816

Epoch: 5| Step: 6
Training loss: 1.2376772011937758
Validation loss: 2.514121925579977

Epoch: 5| Step: 7
Training loss: 1.7229848535307024
Validation loss: 2.4822126644593374

Epoch: 5| Step: 8
Training loss: 2.5851358052630102
Validation loss: 2.559137504791536

Epoch: 5| Step: 9
Training loss: 2.0694430846935927
Validation loss: 2.5303447405570636

Epoch: 5| Step: 10
Training loss: 1.6104203319960217
Validation loss: 2.5324194326166882

Epoch: 390| Step: 0
Training loss: 2.642564862338531
Validation loss: 2.542094484295727

Epoch: 5| Step: 1
Training loss: 2.049879475283778
Validation loss: 2.4883164597653167

Epoch: 5| Step: 2
Training loss: 2.1615527641779737
Validation loss: 2.5156562124017996

Epoch: 5| Step: 3
Training loss: 2.201586896600098
Validation loss: 2.5304300642996624

Epoch: 5| Step: 4
Training loss: 2.2825467330309928
Validation loss: 2.4527174495690804

Epoch: 5| Step: 5
Training loss: 2.3673935602222826
Validation loss: 2.5398343961159027

Epoch: 5| Step: 6
Training loss: 2.2927510094790677
Validation loss: 2.463434829238936

Epoch: 5| Step: 7
Training loss: 2.1468549969003647
Validation loss: 2.553786208942344

Epoch: 5| Step: 8
Training loss: 2.0778045407213206
Validation loss: 2.52948823845451

Epoch: 5| Step: 9
Training loss: 1.698835518251402
Validation loss: 2.4608672299161927

Epoch: 5| Step: 10
Training loss: 2.2997222691242962
Validation loss: 2.465939739157346

Epoch: 391| Step: 0
Training loss: 1.9874076198005308
Validation loss: 2.439146064006393

Epoch: 5| Step: 1
Training loss: 1.8228481461498978
Validation loss: 2.4570225908951864

Epoch: 5| Step: 2
Training loss: 2.3304838992734855
Validation loss: 2.5217200688932375

Epoch: 5| Step: 3
Training loss: 2.3586122404057943
Validation loss: 2.5104684985625814

Epoch: 5| Step: 4
Training loss: 2.1655289401593607
Validation loss: 2.5022368473590384

Epoch: 5| Step: 5
Training loss: 2.2602390858264654
Validation loss: 2.4977625083740653

Epoch: 5| Step: 6
Training loss: 1.9163115697675384
Validation loss: 2.485989722351021

Epoch: 5| Step: 7
Training loss: 2.2865602532845344
Validation loss: 2.4828169468389856

Epoch: 5| Step: 8
Training loss: 1.645096634110633
Validation loss: 2.4256507373816465

Epoch: 5| Step: 9
Training loss: 2.102561287910863
Validation loss: 2.4243737389241837

Epoch: 5| Step: 10
Training loss: 2.5736313006322873
Validation loss: 2.513988657948294

Epoch: 392| Step: 0
Training loss: 2.3750989792928605
Validation loss: 2.479272742073277

Epoch: 5| Step: 1
Training loss: 2.1343500093977013
Validation loss: 2.5080139234649983

Epoch: 5| Step: 2
Training loss: 2.0449873978429367
Validation loss: 2.44492947539273

Epoch: 5| Step: 3
Training loss: 2.044092514781162
Validation loss: 2.463879482994641

Epoch: 5| Step: 4
Training loss: 1.8125689263227753
Validation loss: 2.5223490355799054

Epoch: 5| Step: 5
Training loss: 2.431670235449735
Validation loss: 2.5029765488197366

Epoch: 5| Step: 6
Training loss: 2.4091531653890748
Validation loss: 2.545468487892487

Epoch: 5| Step: 7
Training loss: 2.327778323175229
Validation loss: 2.551347998199267

Epoch: 5| Step: 8
Training loss: 2.04577956844416
Validation loss: 2.5133237570839717

Epoch: 5| Step: 9
Training loss: 2.1152440684652083
Validation loss: 2.5314792279608858

Epoch: 5| Step: 10
Training loss: 2.285939556754511
Validation loss: 2.550152312058362

Epoch: 393| Step: 0
Training loss: 2.170963452833234
Validation loss: 2.5037842693752994

Epoch: 5| Step: 1
Training loss: 2.1190137130776048
Validation loss: 2.493261711079422

Epoch: 5| Step: 2
Training loss: 2.2880208115664895
Validation loss: 2.5252311465911204

Epoch: 5| Step: 3
Training loss: 2.978805217735379
Validation loss: 2.519446485155079

Epoch: 5| Step: 4
Training loss: 1.9698675102373748
Validation loss: 2.493903929278688

Epoch: 5| Step: 5
Training loss: 2.221344948168488
Validation loss: 2.506557662426969

Epoch: 5| Step: 6
Training loss: 1.9295969335639211
Validation loss: 2.505124879162103

Epoch: 5| Step: 7
Training loss: 2.062449252342357
Validation loss: 2.515638007592337

Epoch: 5| Step: 8
Training loss: 1.810439023259192
Validation loss: 2.46400410030646

Epoch: 5| Step: 9
Training loss: 1.9022783898751674
Validation loss: 2.5355310317723885

Epoch: 5| Step: 10
Training loss: 2.3091972065831885
Validation loss: 2.5033278665698244

Epoch: 394| Step: 0
Training loss: 2.2525899603658486
Validation loss: 2.532237000381376

Epoch: 5| Step: 1
Training loss: 2.110958832831349
Validation loss: 2.484170924017792

Epoch: 5| Step: 2
Training loss: 2.3844722782954455
Validation loss: 2.535861635432101

Epoch: 5| Step: 3
Training loss: 2.172911801306842
Validation loss: 2.4955018769874524

Epoch: 5| Step: 4
Training loss: 2.4217675954321876
Validation loss: 2.5229147814116355

Epoch: 5| Step: 5
Training loss: 2.272865459402604
Validation loss: 2.493446367758342

Epoch: 5| Step: 6
Training loss: 1.9042207516836325
Validation loss: 2.4855702866191156

Epoch: 5| Step: 7
Training loss: 2.0438829057974637
Validation loss: 2.4163641381357785

Epoch: 5| Step: 8
Training loss: 1.968378728342574
Validation loss: 2.5577252400998245

Epoch: 5| Step: 9
Training loss: 2.418793717809852
Validation loss: 2.483017385207393

Epoch: 5| Step: 10
Training loss: 2.371458324075021
Validation loss: 2.5114126941250707

Epoch: 395| Step: 0
Training loss: 2.1152683019338845
Validation loss: 2.490576728967221

Epoch: 5| Step: 1
Training loss: 2.3319590699544603
Validation loss: 2.503274317708367

Epoch: 5| Step: 2
Training loss: 1.9159164480814534
Validation loss: 2.5360302802805497

Epoch: 5| Step: 3
Training loss: 2.382219584755758
Validation loss: 2.525264871651631

Epoch: 5| Step: 4
Training loss: 1.9765724513591203
Validation loss: 2.51016260276782

Epoch: 5| Step: 5
Training loss: 2.187139644914101
Validation loss: 2.5391947525200536

Epoch: 5| Step: 6
Training loss: 1.558371468279689
Validation loss: 2.5388903507911706

Epoch: 5| Step: 7
Training loss: 2.568810392166401
Validation loss: 2.4671495955621356

Epoch: 5| Step: 8
Training loss: 2.2451895046326595
Validation loss: 2.496747485286106

Epoch: 5| Step: 9
Training loss: 2.449450614211767
Validation loss: 2.5490984577076348

Epoch: 5| Step: 10
Training loss: 1.979596248652291
Validation loss: 2.4473163679449796

Epoch: 396| Step: 0
Training loss: 1.862624334499178
Validation loss: 2.518586541508613

Epoch: 5| Step: 1
Training loss: 2.436767957263302
Validation loss: 2.6037284715389135

Epoch: 5| Step: 2
Training loss: 2.5263267015443174
Validation loss: 2.551373878162866

Epoch: 5| Step: 3
Training loss: 2.3752685194306333
Validation loss: 2.449984729192714

Epoch: 5| Step: 4
Training loss: 1.5325329135764323
Validation loss: 2.499222561742686

Epoch: 5| Step: 5
Training loss: 2.2027936104516423
Validation loss: 2.5511157048301967

Epoch: 5| Step: 6
Training loss: 2.027966706809612
Validation loss: 2.492563311989854

Epoch: 5| Step: 7
Training loss: 1.9606166136309648
Validation loss: 2.521371605143028

Epoch: 5| Step: 8
Training loss: 2.2949378739468917
Validation loss: 2.5463430837043197

Epoch: 5| Step: 9
Training loss: 2.241629501185947
Validation loss: 2.4920837769596944

Epoch: 5| Step: 10
Training loss: 2.2595490110298226
Validation loss: 2.5009510938328754

Epoch: 397| Step: 0
Training loss: 1.5871858240859649
Validation loss: 2.587176642282007

Epoch: 5| Step: 1
Training loss: 1.9071956227689155
Validation loss: 2.526645891501522

Epoch: 5| Step: 2
Training loss: 2.2367198884130333
Validation loss: 2.4925307613107135

Epoch: 5| Step: 3
Training loss: 2.141126587847049
Validation loss: 2.491021387189778

Epoch: 5| Step: 4
Training loss: 2.8902044866743393
Validation loss: 2.499027427054609

Epoch: 5| Step: 5
Training loss: 2.0065108655516073
Validation loss: 2.4794415498803937

Epoch: 5| Step: 6
Training loss: 1.9011897477955226
Validation loss: 2.4686667107784435

Epoch: 5| Step: 7
Training loss: 2.5741671613464505
Validation loss: 2.4730991462655787

Epoch: 5| Step: 8
Training loss: 2.1932379535277695
Validation loss: 2.4581755035970794

Epoch: 5| Step: 9
Training loss: 1.8862412126764942
Validation loss: 2.495426966864023

Epoch: 5| Step: 10
Training loss: 2.090183465744381
Validation loss: 2.4603373800915804

Epoch: 398| Step: 0
Training loss: 2.256880518342135
Validation loss: 2.566881423353661

Epoch: 5| Step: 1
Training loss: 2.277167337955753
Validation loss: 2.5009036492151213

Epoch: 5| Step: 2
Training loss: 1.540354539758395
Validation loss: 2.4850418517715296

Epoch: 5| Step: 3
Training loss: 2.5463075532246946
Validation loss: 2.47312282855653

Epoch: 5| Step: 4
Training loss: 1.7015753178950035
Validation loss: 2.5090403466524394

Epoch: 5| Step: 5
Training loss: 2.2902229153943217
Validation loss: 2.4783123916340446

Epoch: 5| Step: 6
Training loss: 1.7002108779711806
Validation loss: 2.5381802387727626

Epoch: 5| Step: 7
Training loss: 2.8616963953493166
Validation loss: 2.5044976947987636

Epoch: 5| Step: 8
Training loss: 2.0803584666572443
Validation loss: 2.4132264686061573

Epoch: 5| Step: 9
Training loss: 2.0969723629128527
Validation loss: 2.534961405697731

Epoch: 5| Step: 10
Training loss: 1.8230147053831165
Validation loss: 2.55461277996243

Epoch: 399| Step: 0
Training loss: 2.4465081457536106
Validation loss: 2.5205806438405234

Epoch: 5| Step: 1
Training loss: 1.7459849893376957
Validation loss: 2.4605560460254834

Epoch: 5| Step: 2
Training loss: 2.4331898851657567
Validation loss: 2.479561547211587

Epoch: 5| Step: 3
Training loss: 1.3903826384495312
Validation loss: 2.506155735465184

Epoch: 5| Step: 4
Training loss: 2.937750947662712
Validation loss: 2.53280183112307

Epoch: 5| Step: 5
Training loss: 1.6811473091841185
Validation loss: 2.536533304490214

Epoch: 5| Step: 6
Training loss: 2.5548019150243735
Validation loss: 2.5105888172534545

Epoch: 5| Step: 7
Training loss: 1.9738084506366589
Validation loss: 2.521376218198438

Epoch: 5| Step: 8
Training loss: 2.028425629939103
Validation loss: 2.497941231818273

Epoch: 5| Step: 9
Training loss: 2.1518503166952447
Validation loss: 2.5353307013783537

Epoch: 5| Step: 10
Training loss: 2.027681473255211
Validation loss: 2.566492996951131

Epoch: 400| Step: 0
Training loss: 1.8937341015843967
Validation loss: 2.5528926394045297

Epoch: 5| Step: 1
Training loss: 2.533922644719327
Validation loss: 2.511675914078323

Epoch: 5| Step: 2
Training loss: 2.0531848591014183
Validation loss: 2.5229324205655814

Epoch: 5| Step: 3
Training loss: 2.4169535192613902
Validation loss: 2.4571894561450174

Epoch: 5| Step: 4
Training loss: 1.8590022122111913
Validation loss: 2.5236391483282343

Epoch: 5| Step: 5
Training loss: 2.141461842263106
Validation loss: 2.4489105894811174

Epoch: 5| Step: 6
Training loss: 1.929344610105265
Validation loss: 2.426541067999061

Epoch: 5| Step: 7
Training loss: 2.3014408325439706
Validation loss: 2.475809817445303

Epoch: 5| Step: 8
Training loss: 1.9444828332411503
Validation loss: 2.5072066856641713

Epoch: 5| Step: 9
Training loss: 2.3487240716092823
Validation loss: 2.5028566856650225

Epoch: 5| Step: 10
Training loss: 2.216906144058088
Validation loss: 2.4985823998495373

Epoch: 401| Step: 0
Training loss: 2.1346921358433733
Validation loss: 2.443205175613543

Epoch: 5| Step: 1
Training loss: 2.1592909889054015
Validation loss: 2.504475255528778

Epoch: 5| Step: 2
Training loss: 2.0528903542591133
Validation loss: 2.524645872979537

Epoch: 5| Step: 3
Training loss: 2.059890599169795
Validation loss: 2.5270302654132832

Epoch: 5| Step: 4
Training loss: 1.9049317851831786
Validation loss: 2.530624465288101

Epoch: 5| Step: 5
Training loss: 2.078005220790322
Validation loss: 2.4890797447645054

Epoch: 5| Step: 6
Training loss: 2.524625232947159
Validation loss: 2.496694173670236

Epoch: 5| Step: 7
Training loss: 2.2560196988821675
Validation loss: 2.513848465909291

Epoch: 5| Step: 8
Training loss: 2.2182904694407184
Validation loss: 2.499731321151016

Epoch: 5| Step: 9
Training loss: 1.860380718172945
Validation loss: 2.5331009458139486

Epoch: 5| Step: 10
Training loss: 2.183703916223921
Validation loss: 2.4673679855863226

Epoch: 402| Step: 0
Training loss: 2.522469255091784
Validation loss: 2.445438985479956

Epoch: 5| Step: 1
Training loss: 2.126804819532569
Validation loss: 2.4599243766311862

Epoch: 5| Step: 2
Training loss: 1.5364760144611846
Validation loss: 2.54893244965683

Epoch: 5| Step: 3
Training loss: 2.0030249131739253
Validation loss: 2.4944343058330163

Epoch: 5| Step: 4
Training loss: 2.418688640752621
Validation loss: 2.497878398802435

Epoch: 5| Step: 5
Training loss: 2.2552536981144464
Validation loss: 2.5413451580633803

Epoch: 5| Step: 6
Training loss: 1.8823150357468932
Validation loss: 2.4691861277420966

Epoch: 5| Step: 7
Training loss: 2.103125689252766
Validation loss: 2.4682340174893396

Epoch: 5| Step: 8
Training loss: 2.457838547478245
Validation loss: 2.542448524383712

Epoch: 5| Step: 9
Training loss: 1.7714253576640673
Validation loss: 2.534791788594466

Epoch: 5| Step: 10
Training loss: 2.4449402157079896
Validation loss: 2.5398277685631774

Epoch: 403| Step: 0
Training loss: 2.105090841657347
Validation loss: 2.5017175199352604

Epoch: 5| Step: 1
Training loss: 2.2084664598560426
Validation loss: 2.512127087616805

Epoch: 5| Step: 2
Training loss: 1.6206742444778552
Validation loss: 2.4319778998532664

Epoch: 5| Step: 3
Training loss: 1.5189524825639245
Validation loss: 2.5013837625103386

Epoch: 5| Step: 4
Training loss: 2.76305593359845
Validation loss: 2.549151822864524

Epoch: 5| Step: 5
Training loss: 2.643224937297776
Validation loss: 2.5359337892584115

Epoch: 5| Step: 6
Training loss: 2.0748537172896393
Validation loss: 2.4475021316768917

Epoch: 5| Step: 7
Training loss: 1.8790136611912862
Validation loss: 2.505768178932396

Epoch: 5| Step: 8
Training loss: 1.8994834749929361
Validation loss: 2.567496556942547

Epoch: 5| Step: 9
Training loss: 2.4137067316603322
Validation loss: 2.5306883198519414

Epoch: 5| Step: 10
Training loss: 2.646247971452414
Validation loss: 2.4665809504174

Epoch: 404| Step: 0
Training loss: 2.0974674530595907
Validation loss: 2.548976180175725

Epoch: 5| Step: 1
Training loss: 2.297546807477499
Validation loss: 2.466107670039253

Epoch: 5| Step: 2
Training loss: 2.3017358532045433
Validation loss: 2.492325694496914

Epoch: 5| Step: 3
Training loss: 2.2156793541959883
Validation loss: 2.5149703817687294

Epoch: 5| Step: 4
Training loss: 2.4630300193502928
Validation loss: 2.5337519331288876

Epoch: 5| Step: 5
Training loss: 2.241123917496357
Validation loss: 2.502191861983987

Epoch: 5| Step: 6
Training loss: 2.101907921521059
Validation loss: 2.498064362375422

Epoch: 5| Step: 7
Training loss: 2.1266941722099624
Validation loss: 2.5054763597013774

Epoch: 5| Step: 8
Training loss: 1.9734340833814075
Validation loss: 2.5262821659392385

Epoch: 5| Step: 9
Training loss: 1.7835412263760155
Validation loss: 2.534225202648767

Epoch: 5| Step: 10
Training loss: 1.760780575249692
Validation loss: 2.4549373549444757

Epoch: 405| Step: 0
Training loss: 1.4562883298356402
Validation loss: 2.495710187694524

Epoch: 5| Step: 1
Training loss: 2.6482338616055787
Validation loss: 2.4962362978933608

Epoch: 5| Step: 2
Training loss: 2.162267718767052
Validation loss: 2.4983907308971576

Epoch: 5| Step: 3
Training loss: 1.9624852611206962
Validation loss: 2.4860422127105726

Epoch: 5| Step: 4
Training loss: 2.4809892724023195
Validation loss: 2.5363904863871665

Epoch: 5| Step: 5
Training loss: 1.6757034248118088
Validation loss: 2.4882809965497006

Epoch: 5| Step: 6
Training loss: 2.0286965386285614
Validation loss: 2.467945909270588

Epoch: 5| Step: 7
Training loss: 2.256921929141166
Validation loss: 2.455811821877981

Epoch: 5| Step: 8
Training loss: 2.2848196450139557
Validation loss: 2.502247956416814

Epoch: 5| Step: 9
Training loss: 2.0797743597886473
Validation loss: 2.5603044569922964

Epoch: 5| Step: 10
Training loss: 2.5892146340371363
Validation loss: 2.462588558100649

Epoch: 406| Step: 0
Training loss: 1.9874559649501589
Validation loss: 2.4819661713392542

Epoch: 5| Step: 1
Training loss: 2.7259108849594624
Validation loss: 2.5468443050783303

Epoch: 5| Step: 2
Training loss: 2.116520062072821
Validation loss: 2.4733022545038077

Epoch: 5| Step: 3
Training loss: 1.839758091449115
Validation loss: 2.4806881888362255

Epoch: 5| Step: 4
Training loss: 2.3885092754028197
Validation loss: 2.5269579648977913

Epoch: 5| Step: 5
Training loss: 1.760322575810352
Validation loss: 2.486643800488756

Epoch: 5| Step: 6
Training loss: 2.065080127038975
Validation loss: 2.494536758530382

Epoch: 5| Step: 7
Training loss: 2.133744368095988
Validation loss: 2.486716454564568

Epoch: 5| Step: 8
Training loss: 2.443682825282331
Validation loss: 2.5388329732057704

Epoch: 5| Step: 9
Training loss: 2.117432527334106
Validation loss: 2.4606755286660613

Epoch: 5| Step: 10
Training loss: 2.2757799593145585
Validation loss: 2.4924502580598

Epoch: 407| Step: 0
Training loss: 2.4769341704361203
Validation loss: 2.562915107085502

Epoch: 5| Step: 1
Training loss: 1.9405134823219452
Validation loss: 2.4628385582704593

Epoch: 5| Step: 2
Training loss: 2.2868988956642746
Validation loss: 2.433770286145639

Epoch: 5| Step: 3
Training loss: 2.0070782814440093
Validation loss: 2.4913137573742863

Epoch: 5| Step: 4
Training loss: 2.083932548815214
Validation loss: 2.4774005404009167

Epoch: 5| Step: 5
Training loss: 1.741981323085129
Validation loss: 2.4946624094170393

Epoch: 5| Step: 6
Training loss: 1.8496177536191563
Validation loss: 2.471040701657174

Epoch: 5| Step: 7
Training loss: 2.3345700347193006
Validation loss: 2.4655423326058603

Epoch: 5| Step: 8
Training loss: 2.252269236337357
Validation loss: 2.5356111277512094

Epoch: 5| Step: 9
Training loss: 1.9843796256905055
Validation loss: 2.5195863474005784

Epoch: 5| Step: 10
Training loss: 2.594186401422833
Validation loss: 2.506054196633839

Epoch: 408| Step: 0
Training loss: 1.792583482359817
Validation loss: 2.42488041654679

Epoch: 5| Step: 1
Training loss: 1.9822675673088488
Validation loss: 2.51053061107774

Epoch: 5| Step: 2
Training loss: 2.389116596734653
Validation loss: 2.460243600477155

Epoch: 5| Step: 3
Training loss: 1.9476572023734446
Validation loss: 2.5067163795685454

Epoch: 5| Step: 4
Training loss: 2.2817640378621977
Validation loss: 2.5105418294604083

Epoch: 5| Step: 5
Training loss: 1.9663752811434836
Validation loss: 2.5096990122652945

Epoch: 5| Step: 6
Training loss: 1.8946328047442946
Validation loss: 2.4682237472592226

Epoch: 5| Step: 7
Training loss: 2.4420503056723812
Validation loss: 2.4814203190390205

Epoch: 5| Step: 8
Training loss: 2.0309534883493465
Validation loss: 2.465419824892718

Epoch: 5| Step: 9
Training loss: 2.691465778550672
Validation loss: 2.515908450202729

Epoch: 5| Step: 10
Training loss: 1.8916195231989665
Validation loss: 2.490473824107453

Epoch: 409| Step: 0
Training loss: 1.6292825899890362
Validation loss: 2.4898480335423483

Epoch: 5| Step: 1
Training loss: 2.8938503107930194
Validation loss: 2.4940100395163127

Epoch: 5| Step: 2
Training loss: 1.9620199673343357
Validation loss: 2.4887526846910277

Epoch: 5| Step: 3
Training loss: 2.284898427128905
Validation loss: 2.488769321627982

Epoch: 5| Step: 4
Training loss: 1.5234645743287303
Validation loss: 2.518557334042552

Epoch: 5| Step: 5
Training loss: 2.478641443688875
Validation loss: 2.477906376676429

Epoch: 5| Step: 6
Training loss: 2.1257493436943116
Validation loss: 2.431204842852637

Epoch: 5| Step: 7
Training loss: 1.7655602502343672
Validation loss: 2.486780010835806

Epoch: 5| Step: 8
Training loss: 2.069769100635104
Validation loss: 2.452689067375851

Epoch: 5| Step: 9
Training loss: 2.1298684841620292
Validation loss: 2.511746072216279

Epoch: 5| Step: 10
Training loss: 2.305360340244093
Validation loss: 2.4986653118398876

Epoch: 410| Step: 0
Training loss: 2.0018212847212746
Validation loss: 2.544432876879034

Epoch: 5| Step: 1
Training loss: 2.4449402157079896
Validation loss: 2.5008112206525523

Epoch: 5| Step: 2
Training loss: 1.606161149235606
Validation loss: 2.4756590289687357

Epoch: 5| Step: 3
Training loss: 2.2153895544899798
Validation loss: 2.4816298308790445

Epoch: 5| Step: 4
Training loss: 2.5325029827676513
Validation loss: 2.472913884584142

Epoch: 5| Step: 5
Training loss: 1.7983058374168992
Validation loss: 2.4426680794925977

Epoch: 5| Step: 6
Training loss: 1.6959118464835048
Validation loss: 2.483199278054261

Epoch: 5| Step: 7
Training loss: 2.521127121464812
Validation loss: 2.5438124301797274

Epoch: 5| Step: 8
Training loss: 1.8281919679031897
Validation loss: 2.4845678412377095

Epoch: 5| Step: 9
Training loss: 2.2784746610744757
Validation loss: 2.490563239995252

Epoch: 5| Step: 10
Training loss: 2.041055341270278
Validation loss: 2.5645548507420157

Epoch: 411| Step: 0
Training loss: 1.727684036477177
Validation loss: 2.4670004761251705

Epoch: 5| Step: 1
Training loss: 2.0558812839877985
Validation loss: 2.4318609583365305

Epoch: 5| Step: 2
Training loss: 1.6896768587178428
Validation loss: 2.489483637767325

Epoch: 5| Step: 3
Training loss: 2.4268698100413495
Validation loss: 2.456000785894249

Epoch: 5| Step: 4
Training loss: 2.426123160378498
Validation loss: 2.5379838316625847

Epoch: 5| Step: 5
Training loss: 2.250967877220229
Validation loss: 2.5158591859834942

Epoch: 5| Step: 6
Training loss: 2.5280838933556935
Validation loss: 2.5308419621224822

Epoch: 5| Step: 7
Training loss: 2.3427489113646898
Validation loss: 2.463723035234772

Epoch: 5| Step: 8
Training loss: 1.8034016706007325
Validation loss: 2.445128243796075

Epoch: 5| Step: 9
Training loss: 1.7820174588376778
Validation loss: 2.5312965821244213

Epoch: 5| Step: 10
Training loss: 2.3200343315280905
Validation loss: 2.5240195039499005

Epoch: 412| Step: 0
Training loss: 1.9261029885823169
Validation loss: 2.4750120100212865

Epoch: 5| Step: 1
Training loss: 2.539929802292522
Validation loss: 2.4966204077999756

Epoch: 5| Step: 2
Training loss: 1.927537469363639
Validation loss: 2.46138834433012

Epoch: 5| Step: 3
Training loss: 2.0425772939225455
Validation loss: 2.508720256403613

Epoch: 5| Step: 4
Training loss: 2.632900338448022
Validation loss: 2.4749122929748504

Epoch: 5| Step: 5
Training loss: 1.6281712472391545
Validation loss: 2.490050223464606

Epoch: 5| Step: 6
Training loss: 1.464334221279038
Validation loss: 2.483467855861523

Epoch: 5| Step: 7
Training loss: 2.680480839594476
Validation loss: 2.48974818966184

Epoch: 5| Step: 8
Training loss: 1.669053308018448
Validation loss: 2.501879205242806

Epoch: 5| Step: 9
Training loss: 2.0446917122889756
Validation loss: 2.4691467319447544

Epoch: 5| Step: 10
Training loss: 2.2755360569135084
Validation loss: 2.520247287981113

Epoch: 413| Step: 0
Training loss: 2.072682647019347
Validation loss: 2.5203647622118552

Epoch: 5| Step: 1
Training loss: 2.0087953529389235
Validation loss: 2.4853039222066364

Epoch: 5| Step: 2
Training loss: 2.16539175475677
Validation loss: 2.5635417868446364

Epoch: 5| Step: 3
Training loss: 2.6065215081418387
Validation loss: 2.542219895750417

Epoch: 5| Step: 4
Training loss: 2.138052738399246
Validation loss: 2.470070075424838

Epoch: 5| Step: 5
Training loss: 1.9536936428071492
Validation loss: 2.437129895257406

Epoch: 5| Step: 6
Training loss: 2.4875796779734225
Validation loss: 2.581413551724235

Epoch: 5| Step: 7
Training loss: 2.2607496751698357
Validation loss: 2.433876281528123

Epoch: 5| Step: 8
Training loss: 1.6264119982830856
Validation loss: 2.503472197569552

Epoch: 5| Step: 9
Training loss: 2.195174134804959
Validation loss: 2.5063861282445434

Epoch: 5| Step: 10
Training loss: 2.1149131129388654
Validation loss: 2.4772449713861575

Epoch: 414| Step: 0
Training loss: 2.812946453687353
Validation loss: 2.5002926767957825

Epoch: 5| Step: 1
Training loss: 1.8359163972981019
Validation loss: 2.5310524960033667

Epoch: 5| Step: 2
Training loss: 2.307351748083934
Validation loss: 2.442577981377738

Epoch: 5| Step: 3
Training loss: 1.5795491657001417
Validation loss: 2.483965558720171

Epoch: 5| Step: 4
Training loss: 2.301158932319368
Validation loss: 2.462005606893955

Epoch: 5| Step: 5
Training loss: 2.0692045882098395
Validation loss: 2.415989795500685

Epoch: 5| Step: 6
Training loss: 2.5282207305852538
Validation loss: 2.514677098054453

Epoch: 5| Step: 7
Training loss: 1.7218056998872036
Validation loss: 2.536166420897268

Epoch: 5| Step: 8
Training loss: 2.2387779976155344
Validation loss: 2.4790816533344833

Epoch: 5| Step: 9
Training loss: 1.6006826821881366
Validation loss: 2.5310073431376554

Epoch: 5| Step: 10
Training loss: 2.2900974681051527
Validation loss: 2.5370626732556505

Epoch: 415| Step: 0
Training loss: 2.5688800936610314
Validation loss: 2.520275269455573

Epoch: 5| Step: 1
Training loss: 2.149949530075662
Validation loss: 2.4344168169412654

Epoch: 5| Step: 2
Training loss: 2.2992557980206216
Validation loss: 2.5343454348843784

Epoch: 5| Step: 3
Training loss: 2.345610223688533
Validation loss: 2.500547687465869

Epoch: 5| Step: 4
Training loss: 2.2901200595350804
Validation loss: 2.473750270693077

Epoch: 5| Step: 5
Training loss: 1.826350598080937
Validation loss: 2.4761350596749345

Epoch: 5| Step: 6
Training loss: 2.0414803737843354
Validation loss: 2.5123920480132287

Epoch: 5| Step: 7
Training loss: 2.350222183437863
Validation loss: 2.51550794010745

Epoch: 5| Step: 8
Training loss: 1.6781678888675944
Validation loss: 2.4666331135375392

Epoch: 5| Step: 9
Training loss: 1.6318045977831015
Validation loss: 2.492583543841151

Epoch: 5| Step: 10
Training loss: 1.8450083560289174
Validation loss: 2.5074106801200435

Epoch: 416| Step: 0
Training loss: 2.2152224154780984
Validation loss: 2.5245856786754985

Epoch: 5| Step: 1
Training loss: 2.140221884980495
Validation loss: 2.522845364468071

Epoch: 5| Step: 2
Training loss: 2.0906469780147314
Validation loss: 2.4902773244372334

Epoch: 5| Step: 3
Training loss: 2.278737605108805
Validation loss: 2.453200779654834

Epoch: 5| Step: 4
Training loss: 2.289690888377479
Validation loss: 2.4932115659690135

Epoch: 5| Step: 5
Training loss: 1.8095308516719093
Validation loss: 2.4930859746109406

Epoch: 5| Step: 6
Training loss: 1.8757707283331848
Validation loss: 2.427946420391215

Epoch: 5| Step: 7
Training loss: 1.9908067892718
Validation loss: 2.485750883975204

Epoch: 5| Step: 8
Training loss: 2.09043268479563
Validation loss: 2.4706128756786114

Epoch: 5| Step: 9
Training loss: 2.366483678146098
Validation loss: 2.5146953174662725

Epoch: 5| Step: 10
Training loss: 1.8679324782745612
Validation loss: 2.476217407145246

Epoch: 417| Step: 0
Training loss: 1.9666307335604334
Validation loss: 2.4903116952923186

Epoch: 5| Step: 1
Training loss: 1.8444231388605448
Validation loss: 2.506849798594214

Epoch: 5| Step: 2
Training loss: 1.8493017244922039
Validation loss: 2.5193442344337313

Epoch: 5| Step: 3
Training loss: 1.7884755066987983
Validation loss: 2.5049754157646964

Epoch: 5| Step: 4
Training loss: 2.7088769122689893
Validation loss: 2.494165494077276

Epoch: 5| Step: 5
Training loss: 2.4935556321655117
Validation loss: 2.5369526937086184

Epoch: 5| Step: 6
Training loss: 2.1728729589887537
Validation loss: 2.506134208676377

Epoch: 5| Step: 7
Training loss: 2.4338289640103943
Validation loss: 2.4735638078615145

Epoch: 5| Step: 8
Training loss: 1.795637816062412
Validation loss: 2.561141453578375

Epoch: 5| Step: 9
Training loss: 2.1857637326785286
Validation loss: 2.527976387028783

Epoch: 5| Step: 10
Training loss: 2.503505252144654
Validation loss: 2.4992759096922486

Epoch: 418| Step: 0
Training loss: 2.0517158631108434
Validation loss: 2.489121560594528

Epoch: 5| Step: 1
Training loss: 2.0029264735545276
Validation loss: 2.4933081197025877

Epoch: 5| Step: 2
Training loss: 1.9426878109036319
Validation loss: 2.500213927683478

Epoch: 5| Step: 3
Training loss: 1.704964930042243
Validation loss: 2.5187574819619956

Epoch: 5| Step: 4
Training loss: 2.27511126068026
Validation loss: 2.4332604477699284

Epoch: 5| Step: 5
Training loss: 2.194649810141484
Validation loss: 2.5357848876627296

Epoch: 5| Step: 6
Training loss: 1.366880894749842
Validation loss: 2.5077910037891282

Epoch: 5| Step: 7
Training loss: 1.9595431655680895
Validation loss: 2.4562838774593567

Epoch: 5| Step: 8
Training loss: 3.0555048870933375
Validation loss: 2.502951373977369

Epoch: 5| Step: 9
Training loss: 2.323687221752298
Validation loss: 2.4428459821547137

Epoch: 5| Step: 10
Training loss: 2.261464369836239
Validation loss: 2.515068554684035

Epoch: 419| Step: 0
Training loss: 2.032195942037154
Validation loss: 2.531981628451953

Epoch: 5| Step: 1
Training loss: 1.9823251785222626
Validation loss: 2.49657862463908

Epoch: 5| Step: 2
Training loss: 1.8786784646634154
Validation loss: 2.545936166332456

Epoch: 5| Step: 3
Training loss: 2.069995092856078
Validation loss: 2.492456706109186

Epoch: 5| Step: 4
Training loss: 2.3014079925822655
Validation loss: 2.5083211053952152

Epoch: 5| Step: 5
Training loss: 1.96568180359969
Validation loss: 2.4932050592050743

Epoch: 5| Step: 6
Training loss: 2.102560494150235
Validation loss: 2.4671891100138517

Epoch: 5| Step: 7
Training loss: 2.312024454244887
Validation loss: 2.516395676015386

Epoch: 5| Step: 8
Training loss: 2.174642871169072
Validation loss: 2.579426161343949

Epoch: 5| Step: 9
Training loss: 2.4387045598257173
Validation loss: 2.4837247255841537

Epoch: 5| Step: 10
Training loss: 1.8172619188573578
Validation loss: 2.407476331349787

Epoch: 420| Step: 0
Training loss: 1.922004013073212
Validation loss: 2.458059558115713

Epoch: 5| Step: 1
Training loss: 1.8847830183580532
Validation loss: 2.4869147292962963

Epoch: 5| Step: 2
Training loss: 1.802277776852537
Validation loss: 2.5235472842918556

Epoch: 5| Step: 3
Training loss: 2.480918735327957
Validation loss: 2.4997413593755025

Epoch: 5| Step: 4
Training loss: 2.0528307746007584
Validation loss: 2.534010390374519

Epoch: 5| Step: 5
Training loss: 2.079436727145928
Validation loss: 2.5510368835288877

Epoch: 5| Step: 6
Training loss: 1.703867199365887
Validation loss: 2.55411860108239

Epoch: 5| Step: 7
Training loss: 1.9568003748624354
Validation loss: 2.470821265112125

Epoch: 5| Step: 8
Training loss: 2.521294501710474
Validation loss: 2.533251408301759

Epoch: 5| Step: 9
Training loss: 1.513472375335986
Validation loss: 2.4718672497268996

Epoch: 5| Step: 10
Training loss: 3.0056145898643054
Validation loss: 2.5264691357250726

Epoch: 421| Step: 0
Training loss: 1.6626466270550455
Validation loss: 2.5122856825015463

Epoch: 5| Step: 1
Training loss: 2.2091210118136186
Validation loss: 2.50119255499018

Epoch: 5| Step: 2
Training loss: 2.1007520963746207
Validation loss: 2.4594373175968807

Epoch: 5| Step: 3
Training loss: 2.2475036972405866
Validation loss: 2.5127980041581623

Epoch: 5| Step: 4
Training loss: 2.763580773675152
Validation loss: 2.5655887025987396

Epoch: 5| Step: 5
Training loss: 2.1535753994317446
Validation loss: 2.4399394682374647

Epoch: 5| Step: 6
Training loss: 1.8904635778196046
Validation loss: 2.473134363821229

Epoch: 5| Step: 7
Training loss: 1.47268862903728
Validation loss: 2.4640883180675184

Epoch: 5| Step: 8
Training loss: 2.162447771092152
Validation loss: 2.508623876871799

Epoch: 5| Step: 9
Training loss: 2.2438265561615367
Validation loss: 2.451963244819872

Epoch: 5| Step: 10
Training loss: 1.9182150501978505
Validation loss: 2.4464519558255087

Epoch: 422| Step: 0
Training loss: 2.1285141330040993
Validation loss: 2.4635254872119083

Epoch: 5| Step: 1
Training loss: 2.2408614540629084
Validation loss: 2.47244757662579

Epoch: 5| Step: 2
Training loss: 1.9075031226496304
Validation loss: 2.5214595333865355

Epoch: 5| Step: 3
Training loss: 2.104520283310135
Validation loss: 2.5061790767439343

Epoch: 5| Step: 4
Training loss: 1.9290512209707296
Validation loss: 2.4666660080465133

Epoch: 5| Step: 5
Training loss: 2.1681563562548845
Validation loss: 2.5764000007568066

Epoch: 5| Step: 6
Training loss: 1.9775909040272728
Validation loss: 2.527411196036437

Epoch: 5| Step: 7
Training loss: 2.2581196612335366
Validation loss: 2.5207399140630407

Epoch: 5| Step: 8
Training loss: 2.0540368968320317
Validation loss: 2.4486196087717933

Epoch: 5| Step: 9
Training loss: 1.8150929943673118
Validation loss: 2.4727436451922795

Epoch: 5| Step: 10
Training loss: 2.4388635196201496
Validation loss: 2.499846415775554

Epoch: 423| Step: 0
Training loss: 2.496409794674255
Validation loss: 2.5284671675760917

Epoch: 5| Step: 1
Training loss: 2.3980495872302017
Validation loss: 2.4764300465872933

Epoch: 5| Step: 2
Training loss: 2.084813418742022
Validation loss: 2.4862021178668425

Epoch: 5| Step: 3
Training loss: 1.3106179139942136
Validation loss: 2.479409258099984

Epoch: 5| Step: 4
Training loss: 2.240518726504726
Validation loss: 2.5096713546720304

Epoch: 5| Step: 5
Training loss: 2.0335991993089926
Validation loss: 2.5307126636446236

Epoch: 5| Step: 6
Training loss: 2.3386710512750137
Validation loss: 2.5067912795889016

Epoch: 5| Step: 7
Training loss: 1.5047757892315865
Validation loss: 2.490114207351254

Epoch: 5| Step: 8
Training loss: 2.0712798539693935
Validation loss: 2.481822613750103

Epoch: 5| Step: 9
Training loss: 2.210366219086613
Validation loss: 2.4428608874238664

Epoch: 5| Step: 10
Training loss: 1.8458668469672421
Validation loss: 2.5191390173334085

Epoch: 424| Step: 0
Training loss: 2.9244732243836187
Validation loss: 2.4952964219859

Epoch: 5| Step: 1
Training loss: 2.0091873389812505
Validation loss: 2.4934906385409827

Epoch: 5| Step: 2
Training loss: 2.075607955297493
Validation loss: 2.447239370036398

Epoch: 5| Step: 3
Training loss: 1.6107830813496749
Validation loss: 2.486706044170863

Epoch: 5| Step: 4
Training loss: 2.1215145473480437
Validation loss: 2.519650528502451

Epoch: 5| Step: 5
Training loss: 2.3723882067181257
Validation loss: 2.458462549244231

Epoch: 5| Step: 6
Training loss: 2.384958670236055
Validation loss: 2.56025312968399

Epoch: 5| Step: 7
Training loss: 1.6704050893073912
Validation loss: 2.5569146475726683

Epoch: 5| Step: 8
Training loss: 1.6270853746753868
Validation loss: 2.5254439592017457

Epoch: 5| Step: 9
Training loss: 1.844091674698021
Validation loss: 2.4875532208782123

Epoch: 5| Step: 10
Training loss: 1.865802842039139
Validation loss: 2.516530000441623

Epoch: 425| Step: 0
Training loss: 2.3412175038491383
Validation loss: 2.434816223461011

Epoch: 5| Step: 1
Training loss: 2.107036509381761
Validation loss: 2.492020736588965

Epoch: 5| Step: 2
Training loss: 2.3202856813672663
Validation loss: 2.514344678549151

Epoch: 5| Step: 3
Training loss: 1.8263546449313999
Validation loss: 2.489410560356415

Epoch: 5| Step: 4
Training loss: 2.111824817089465
Validation loss: 2.519881720149241

Epoch: 5| Step: 5
Training loss: 1.8995202512894127
Validation loss: 2.4877536785110537

Epoch: 5| Step: 6
Training loss: 1.9276328325824283
Validation loss: 2.4856107649840498

Epoch: 5| Step: 7
Training loss: 2.8084348333865443
Validation loss: 2.510928134609893

Epoch: 5| Step: 8
Training loss: 1.9361263450900128
Validation loss: 2.4879689858348084

Epoch: 5| Step: 9
Training loss: 2.163676093132341
Validation loss: 2.4836064230302366

Epoch: 5| Step: 10
Training loss: 1.5852055105317155
Validation loss: 2.451090774792721

Epoch: 426| Step: 0
Training loss: 1.8736733511630357
Validation loss: 2.43955210906069

Epoch: 5| Step: 1
Training loss: 2.054799588123152
Validation loss: 2.4894256219188935

Epoch: 5| Step: 2
Training loss: 1.7765085123224849
Validation loss: 2.4259592386329802

Epoch: 5| Step: 3
Training loss: 1.9259921997165879
Validation loss: 2.5235187732426185

Epoch: 5| Step: 4
Training loss: 1.7688009679345666
Validation loss: 2.5212631455791428

Epoch: 5| Step: 5
Training loss: 2.0327292118119096
Validation loss: 2.4723754115765115

Epoch: 5| Step: 6
Training loss: 2.664561026457191
Validation loss: 2.4982269090616573

Epoch: 5| Step: 7
Training loss: 2.1977315044299575
Validation loss: 2.4277688884277477

Epoch: 5| Step: 8
Training loss: 1.6147367917217708
Validation loss: 2.4987544484525617

Epoch: 5| Step: 9
Training loss: 2.3402113585915396
Validation loss: 2.517966007988935

Epoch: 5| Step: 10
Training loss: 2.2353701209501566
Validation loss: 2.5256666383131976

Epoch: 427| Step: 0
Training loss: 2.0154881393927773
Validation loss: 2.525778525199182

Epoch: 5| Step: 1
Training loss: 2.2449377120113034
Validation loss: 2.4726749215924992

Epoch: 5| Step: 2
Training loss: 2.2830132763644087
Validation loss: 2.4241939772720267

Epoch: 5| Step: 3
Training loss: 2.4276811466535086
Validation loss: 2.5150604358474404

Epoch: 5| Step: 4
Training loss: 2.2564472439847725
Validation loss: 2.4879364327502365

Epoch: 5| Step: 5
Training loss: 1.8605869734994414
Validation loss: 2.47840313741145

Epoch: 5| Step: 6
Training loss: 2.0284613613993097
Validation loss: 2.4957458242312516

Epoch: 5| Step: 7
Training loss: 1.527128472730078
Validation loss: 2.5410789208260574

Epoch: 5| Step: 8
Training loss: 2.0707249644404575
Validation loss: 2.4960939595204428

Epoch: 5| Step: 9
Training loss: 2.260960163458943
Validation loss: 2.5680319248055508

Epoch: 5| Step: 10
Training loss: 1.6638142575208517
Validation loss: 2.499090451734516

Epoch: 428| Step: 0
Training loss: 1.9347779010003554
Validation loss: 2.4439984086263795

Epoch: 5| Step: 1
Training loss: 2.272056028769949
Validation loss: 2.4430717857135584

Epoch: 5| Step: 2
Training loss: 1.551012997162678
Validation loss: 2.483919427601677

Epoch: 5| Step: 3
Training loss: 1.8711414689447747
Validation loss: 2.505883470980079

Epoch: 5| Step: 4
Training loss: 2.5500573245318305
Validation loss: 2.544581122303207

Epoch: 5| Step: 5
Training loss: 2.452008521776186
Validation loss: 2.4820149695255274

Epoch: 5| Step: 6
Training loss: 2.7231796834207986
Validation loss: 2.596178137194032

Epoch: 5| Step: 7
Training loss: 1.6718888326767858
Validation loss: 2.4804126513855986

Epoch: 5| Step: 8
Training loss: 1.8965215865942493
Validation loss: 2.449727926807552

Epoch: 5| Step: 9
Training loss: 1.534235165938741
Validation loss: 2.4794564160967627

Epoch: 5| Step: 10
Training loss: 1.6942682522053314
Validation loss: 2.5002676241178032

Epoch: 429| Step: 0
Training loss: 2.0233713971390666
Validation loss: 2.422085735191239

Epoch: 5| Step: 1
Training loss: 2.4574713623613547
Validation loss: 2.4999220651353684

Epoch: 5| Step: 2
Training loss: 2.144678996682211
Validation loss: 2.5086786957202225

Epoch: 5| Step: 3
Training loss: 1.5505038765247134
Validation loss: 2.523941829817499

Epoch: 5| Step: 4
Training loss: 1.7540227430776496
Validation loss: 2.4843052153674208

Epoch: 5| Step: 5
Training loss: 2.716894283783484
Validation loss: 2.49501615912596

Epoch: 5| Step: 6
Training loss: 1.970567137125489
Validation loss: 2.5366472043097996

Epoch: 5| Step: 7
Training loss: 1.7619575287921136
Validation loss: 2.5164546557661622

Epoch: 5| Step: 8
Training loss: 1.8760549756272942
Validation loss: 2.472252288455175

Epoch: 5| Step: 9
Training loss: 2.1788159887549026
Validation loss: 2.5133468043314298

Epoch: 5| Step: 10
Training loss: 2.501346130353948
Validation loss: 2.4781102133577457

Epoch: 430| Step: 0
Training loss: 2.2461478848775176
Validation loss: 2.442920060539654

Epoch: 5| Step: 1
Training loss: 1.6404013345027872
Validation loss: 2.536489676810197

Epoch: 5| Step: 2
Training loss: 2.4251375926201897
Validation loss: 2.4983381654602255

Epoch: 5| Step: 3
Training loss: 2.1629587381477453
Validation loss: 2.4538776305707213

Epoch: 5| Step: 4
Training loss: 2.0415394672032874
Validation loss: 2.4558201480709183

Epoch: 5| Step: 5
Training loss: 1.668018921001525
Validation loss: 2.4231065712961914

Epoch: 5| Step: 6
Training loss: 2.4045144299545935
Validation loss: 2.560111983292495

Epoch: 5| Step: 7
Training loss: 1.7921074022055818
Validation loss: 2.513432448070751

Epoch: 5| Step: 8
Training loss: 2.3771980554399748
Validation loss: 2.51973765097691

Epoch: 5| Step: 9
Training loss: 1.79828919860637
Validation loss: 2.427603803699567

Epoch: 5| Step: 10
Training loss: 2.3431599192079107
Validation loss: 2.4942056232718914

Epoch: 431| Step: 0
Training loss: 1.7037892577363645
Validation loss: 2.4970970424603083

Epoch: 5| Step: 1
Training loss: 1.957332016909795
Validation loss: 2.4529773925615954

Epoch: 5| Step: 2
Training loss: 1.76766647202382
Validation loss: 2.457588750108593

Epoch: 5| Step: 3
Training loss: 1.5525877301526496
Validation loss: 2.480848979544372

Epoch: 5| Step: 4
Training loss: 2.1052174603998774
Validation loss: 2.4438949444833002

Epoch: 5| Step: 5
Training loss: 1.7669847367020914
Validation loss: 2.5323858332073423

Epoch: 5| Step: 6
Training loss: 2.4268776693238565
Validation loss: 2.5198501353317817

Epoch: 5| Step: 7
Training loss: 2.1942351063004146
Validation loss: 2.4468254779925633

Epoch: 5| Step: 8
Training loss: 2.461415756014473
Validation loss: 2.5416291582260606

Epoch: 5| Step: 9
Training loss: 1.798392277206184
Validation loss: 2.407950105552275

Epoch: 5| Step: 10
Training loss: 2.695987428941481
Validation loss: 2.4720805277984716

Epoch: 432| Step: 0
Training loss: 2.0030866884087963
Validation loss: 2.463251546665153

Epoch: 5| Step: 1
Training loss: 2.3482774874145407
Validation loss: 2.4431794724961224

Epoch: 5| Step: 2
Training loss: 1.9040830208445625
Validation loss: 2.575435741081503

Epoch: 5| Step: 3
Training loss: 2.410684635847913
Validation loss: 2.4812135058461084

Epoch: 5| Step: 4
Training loss: 1.854222571855327
Validation loss: 2.4897782200595056

Epoch: 5| Step: 5
Training loss: 1.5835867310920317
Validation loss: 2.540945370012924

Epoch: 5| Step: 6
Training loss: 2.181524125064801
Validation loss: 2.5294245086646447

Epoch: 5| Step: 7
Training loss: 1.9017173785514296
Validation loss: 2.507580422569349

Epoch: 5| Step: 8
Training loss: 2.207890328171422
Validation loss: 2.485418648304646

Epoch: 5| Step: 9
Training loss: 2.314782742878587
Validation loss: 2.498413637822994

Epoch: 5| Step: 10
Training loss: 1.8802168432943094
Validation loss: 2.4282551805599595

Epoch: 433| Step: 0
Training loss: 2.076717387580611
Validation loss: 2.478569134200443

Epoch: 5| Step: 1
Training loss: 1.9309101632870709
Validation loss: 2.581702537985172

Epoch: 5| Step: 2
Training loss: 2.041789952921952
Validation loss: 2.4964899227612696

Epoch: 5| Step: 3
Training loss: 2.3470865532706076
Validation loss: 2.4406850917425094

Epoch: 5| Step: 4
Training loss: 1.9452313019378802
Validation loss: 2.443813502601751

Epoch: 5| Step: 5
Training loss: 2.460518356233065
Validation loss: 2.4629788881871373

Epoch: 5| Step: 6
Training loss: 2.173391128582873
Validation loss: 2.404770956847543

Epoch: 5| Step: 7
Training loss: 1.9091687604586596
Validation loss: 2.5079984322855213

Epoch: 5| Step: 8
Training loss: 1.9563940537523976
Validation loss: 2.4925363086767063

Epoch: 5| Step: 9
Training loss: 1.9854424076339692
Validation loss: 2.4733133484103993

Epoch: 5| Step: 10
Training loss: 1.5787177908202492
Validation loss: 2.424298932032424

Epoch: 434| Step: 0
Training loss: 1.6810913606696367
Validation loss: 2.460643358389207

Epoch: 5| Step: 1
Training loss: 1.3426933125952207
Validation loss: 2.460789921546908

Epoch: 5| Step: 2
Training loss: 1.9459748270459045
Validation loss: 2.485570390791466

Epoch: 5| Step: 3
Training loss: 1.9408145363556557
Validation loss: 2.4774408107675745

Epoch: 5| Step: 4
Training loss: 1.96870186156503
Validation loss: 2.554613768443172

Epoch: 5| Step: 5
Training loss: 1.8838390543441124
Validation loss: 2.516495537910727

Epoch: 5| Step: 6
Training loss: 2.5031568622823386
Validation loss: 2.490365108538451

Epoch: 5| Step: 7
Training loss: 2.244000489430366
Validation loss: 2.5110343238287185

Epoch: 5| Step: 8
Training loss: 2.5452510594492326
Validation loss: 2.417136876065958

Epoch: 5| Step: 9
Training loss: 2.162922142147785
Validation loss: 2.470323581637881

Epoch: 5| Step: 10
Training loss: 2.3496741129771217
Validation loss: 2.486922774051078

Epoch: 435| Step: 0
Training loss: 2.310369902384886
Validation loss: 2.4639765483445073

Epoch: 5| Step: 1
Training loss: 2.124989677852917
Validation loss: 2.512080609263939

Epoch: 5| Step: 2
Training loss: 1.8906359711636092
Validation loss: 2.4834900503542188

Epoch: 5| Step: 3
Training loss: 2.1058806687008893
Validation loss: 2.4699031763262154

Epoch: 5| Step: 4
Training loss: 2.3898124560589014
Validation loss: 2.4930022778017222

Epoch: 5| Step: 5
Training loss: 2.3189118650137215
Validation loss: 2.4840160308402375

Epoch: 5| Step: 6
Training loss: 1.8763508063473164
Validation loss: 2.504370291450138

Epoch: 5| Step: 7
Training loss: 1.6745612409617767
Validation loss: 2.444467924405513

Epoch: 5| Step: 8
Training loss: 1.5633092691864485
Validation loss: 2.503599017895496

Epoch: 5| Step: 9
Training loss: 2.041699337860073
Validation loss: 2.517474932805417

Epoch: 5| Step: 10
Training loss: 2.31873964374214
Validation loss: 2.4948822110553537

Epoch: 436| Step: 0
Training loss: 1.8811746018213837
Validation loss: 2.438759555380915

Epoch: 5| Step: 1
Training loss: 2.6208201235714723
Validation loss: 2.506775499615582

Epoch: 5| Step: 2
Training loss: 1.8623216505233284
Validation loss: 2.5163973636153645

Epoch: 5| Step: 3
Training loss: 1.9889395772464422
Validation loss: 2.4178383527136567

Epoch: 5| Step: 4
Training loss: 2.1924324013044396
Validation loss: 2.4879371251981

Epoch: 5| Step: 5
Training loss: 2.2227637293461
Validation loss: 2.497904954878529

Epoch: 5| Step: 6
Training loss: 2.004417309649042
Validation loss: 2.479372355351925

Epoch: 5| Step: 7
Training loss: 2.061436118657906
Validation loss: 2.4244431567814253

Epoch: 5| Step: 8
Training loss: 1.6645048028264149
Validation loss: 2.459632158829618

Epoch: 5| Step: 9
Training loss: 1.789502618617753
Validation loss: 2.467551727063593

Epoch: 5| Step: 10
Training loss: 2.5223490254162027
Validation loss: 2.4835861841122338

Epoch: 437| Step: 0
Training loss: 2.58964397413636
Validation loss: 2.4442411422398913

Epoch: 5| Step: 1
Training loss: 1.2329412414862195
Validation loss: 2.474230741691994

Epoch: 5| Step: 2
Training loss: 1.7950054892240872
Validation loss: 2.503947398453758

Epoch: 5| Step: 3
Training loss: 1.7049653495556514
Validation loss: 2.423075191945881

Epoch: 5| Step: 4
Training loss: 1.9724247862735105
Validation loss: 2.4446759030067318

Epoch: 5| Step: 5
Training loss: 2.3492255781332636
Validation loss: 2.4550593864082204

Epoch: 5| Step: 6
Training loss: 2.0543395933622945
Validation loss: 2.5591697642535203

Epoch: 5| Step: 7
Training loss: 2.3714288666408176
Validation loss: 2.5238669882795994

Epoch: 5| Step: 8
Training loss: 2.018881244940042
Validation loss: 2.5173502769892426

Epoch: 5| Step: 9
Training loss: 2.1750989080279983
Validation loss: 2.4964179443854597

Epoch: 5| Step: 10
Training loss: 2.1376706640810013
Validation loss: 2.4686067144210697

Epoch: 438| Step: 0
Training loss: 1.853622127966251
Validation loss: 2.5043472915996405

Epoch: 5| Step: 1
Training loss: 2.549288583138608
Validation loss: 2.46001774948157

Epoch: 5| Step: 2
Training loss: 2.117748341055013
Validation loss: 2.5457238311550605

Epoch: 5| Step: 3
Training loss: 1.5345631781207456
Validation loss: 2.479154174854563

Epoch: 5| Step: 4
Training loss: 2.394350626917783
Validation loss: 2.5058105623592914

Epoch: 5| Step: 5
Training loss: 1.7532416700956448
Validation loss: 2.5088857667572815

Epoch: 5| Step: 6
Training loss: 1.670385963244673
Validation loss: 2.5374510381236286

Epoch: 5| Step: 7
Training loss: 2.614897679940153
Validation loss: 2.4841486406643556

Epoch: 5| Step: 8
Training loss: 1.7137977694720041
Validation loss: 2.4156527420168294

Epoch: 5| Step: 9
Training loss: 2.116204177711862
Validation loss: 2.482288501109162

Epoch: 5| Step: 10
Training loss: 2.490468260309521
Validation loss: 2.4829788035735674

Epoch: 439| Step: 0
Training loss: 1.638044962581454
Validation loss: 2.500136418876212

Epoch: 5| Step: 1
Training loss: 1.7169230374620736
Validation loss: 2.539170357785256

Epoch: 5| Step: 2
Training loss: 2.5273379011838233
Validation loss: 2.4989908447853617

Epoch: 5| Step: 3
Training loss: 1.8506316730413743
Validation loss: 2.4542189056448644

Epoch: 5| Step: 4
Training loss: 2.238140321459148
Validation loss: 2.517105788730648

Epoch: 5| Step: 5
Training loss: 1.6843895679756873
Validation loss: 2.543730225054964

Epoch: 5| Step: 6
Training loss: 2.7945007817391327
Validation loss: 2.4431691688231476

Epoch: 5| Step: 7
Training loss: 1.692244253853538
Validation loss: 2.435076632961818

Epoch: 5| Step: 8
Training loss: 2.139589156527025
Validation loss: 2.4983583382328627

Epoch: 5| Step: 9
Training loss: 1.9674654206044928
Validation loss: 2.511861224605377

Epoch: 5| Step: 10
Training loss: 1.826228992568492
Validation loss: 2.432578193272747

Epoch: 440| Step: 0
Training loss: 2.0118261216036775
Validation loss: 2.4314008647033587

Epoch: 5| Step: 1
Training loss: 2.205752490091848
Validation loss: 2.508250110447407

Epoch: 5| Step: 2
Training loss: 2.2520271282493134
Validation loss: 2.4590194537919103

Epoch: 5| Step: 3
Training loss: 1.7062982517448322
Validation loss: 2.5642733856635784

Epoch: 5| Step: 4
Training loss: 2.4167173533769484
Validation loss: 2.4797477159313943

Epoch: 5| Step: 5
Training loss: 1.689378258253562
Validation loss: 2.5086723414837526

Epoch: 5| Step: 6
Training loss: 1.7441750722732101
Validation loss: 2.4828250647591377

Epoch: 5| Step: 7
Training loss: 2.087820967251835
Validation loss: 2.4610151724953626

Epoch: 5| Step: 8
Training loss: 2.2801924043752226
Validation loss: 2.5768179614748865

Epoch: 5| Step: 9
Training loss: 2.1861653207178264
Validation loss: 2.474909109802355

Epoch: 5| Step: 10
Training loss: 1.7847057750783524
Validation loss: 2.4353477693408587

Epoch: 441| Step: 0
Training loss: 2.016324417245056
Validation loss: 2.5217002538009274

Epoch: 5| Step: 1
Training loss: 1.910287552203723
Validation loss: 2.473493530616406

Epoch: 5| Step: 2
Training loss: 2.141263212306853
Validation loss: 2.4736545817109867

Epoch: 5| Step: 3
Training loss: 1.8420711567955235
Validation loss: 2.4517165954055

Epoch: 5| Step: 4
Training loss: 2.382472780118201
Validation loss: 2.509232996459788

Epoch: 5| Step: 5
Training loss: 2.3080424055438353
Validation loss: 2.4291403103209137

Epoch: 5| Step: 6
Training loss: 1.5898070834943723
Validation loss: 2.56912517206588

Epoch: 5| Step: 7
Training loss: 2.0769111702243515
Validation loss: 2.4748427211291686

Epoch: 5| Step: 8
Training loss: 2.131511584922239
Validation loss: 2.4725507309243526

Epoch: 5| Step: 9
Training loss: 2.00303717315049
Validation loss: 2.554419339464025

Epoch: 5| Step: 10
Training loss: 2.316462035255231
Validation loss: 2.517278977580505

Epoch: 442| Step: 0
Training loss: 1.8270759506975371
Validation loss: 2.455698924851195

Epoch: 5| Step: 1
Training loss: 1.9232713542364133
Validation loss: 2.5718566523067823

Epoch: 5| Step: 2
Training loss: 1.8735307022849064
Validation loss: 2.409930397320081

Epoch: 5| Step: 3
Training loss: 1.3675974639946051
Validation loss: 2.4561715177453274

Epoch: 5| Step: 4
Training loss: 2.0698043487523785
Validation loss: 2.4407996474226805

Epoch: 5| Step: 5
Training loss: 1.8472294707701815
Validation loss: 2.5122169900308893

Epoch: 5| Step: 6
Training loss: 1.9792512239830875
Validation loss: 2.503669928677219

Epoch: 5| Step: 7
Training loss: 2.3941881142423616
Validation loss: 2.4824400094539314

Epoch: 5| Step: 8
Training loss: 2.762832007156437
Validation loss: 2.476215816916024

Epoch: 5| Step: 9
Training loss: 2.164595885939514
Validation loss: 2.460692492436488

Epoch: 5| Step: 10
Training loss: 2.2647917168789506
Validation loss: 2.490486530210667

Epoch: 443| Step: 0
Training loss: 1.543518663748899
Validation loss: 2.4665743492375882

Epoch: 5| Step: 1
Training loss: 2.293051099192048
Validation loss: 2.471099707289989

Epoch: 5| Step: 2
Training loss: 1.4968292579749727
Validation loss: 2.493479725910782

Epoch: 5| Step: 3
Training loss: 2.215088630608034
Validation loss: 2.4505841988669506

Epoch: 5| Step: 4
Training loss: 1.9413974078646732
Validation loss: 2.5005687476857688

Epoch: 5| Step: 5
Training loss: 2.2235564703353092
Validation loss: 2.4893851262881865

Epoch: 5| Step: 6
Training loss: 2.3404169415439875
Validation loss: 2.425842065629909

Epoch: 5| Step: 7
Training loss: 1.825224115380179
Validation loss: 2.493324940108923

Epoch: 5| Step: 8
Training loss: 2.643504001003273
Validation loss: 2.499994632756204

Epoch: 5| Step: 9
Training loss: 1.741668418567026
Validation loss: 2.493934846098267

Epoch: 5| Step: 10
Training loss: 2.005955293585094
Validation loss: 2.491406555775666

Epoch: 444| Step: 0
Training loss: 2.045097336259722
Validation loss: 2.4025029686336254

Epoch: 5| Step: 1
Training loss: 2.1303840197901747
Validation loss: 2.389782072731076

Epoch: 5| Step: 2
Training loss: 1.9115039774947877
Validation loss: 2.4754431832717128

Epoch: 5| Step: 3
Training loss: 2.003589984408626
Validation loss: 2.4759051249262063

Epoch: 5| Step: 4
Training loss: 1.90680223814391
Validation loss: 2.483760178506608

Epoch: 5| Step: 5
Training loss: 1.7326124703587433
Validation loss: 2.4459673539917945

Epoch: 5| Step: 6
Training loss: 1.7210522577840097
Validation loss: 2.531392463008166

Epoch: 5| Step: 7
Training loss: 1.9693935492927384
Validation loss: 2.4776782338858307

Epoch: 5| Step: 8
Training loss: 2.063211722829292
Validation loss: 2.5144610827293037

Epoch: 5| Step: 9
Training loss: 2.4072118050701303
Validation loss: 2.4643796699026552

Epoch: 5| Step: 10
Training loss: 2.504235970484395
Validation loss: 2.4615076850251114

Epoch: 445| Step: 0
Training loss: 1.9767147804674505
Validation loss: 2.4741278543125755

Epoch: 5| Step: 1
Training loss: 2.35085704271796
Validation loss: 2.4537861627167312

Epoch: 5| Step: 2
Training loss: 2.117832212363416
Validation loss: 2.4519576014782425

Epoch: 5| Step: 3
Training loss: 2.173142097851315
Validation loss: 2.5456364670954055

Epoch: 5| Step: 4
Training loss: 2.1051250453242476
Validation loss: 2.492187798314529

Epoch: 5| Step: 5
Training loss: 2.2819440648063187
Validation loss: 2.52622528034689

Epoch: 5| Step: 6
Training loss: 2.153039947734488
Validation loss: 2.52735972208844

Epoch: 5| Step: 7
Training loss: 1.8578834000414057
Validation loss: 2.4471206927877667

Epoch: 5| Step: 8
Training loss: 1.9934960350033548
Validation loss: 2.499748831611653

Epoch: 5| Step: 9
Training loss: 1.935557406769247
Validation loss: 2.5215110433937977

Epoch: 5| Step: 10
Training loss: 1.9459199378313237
Validation loss: 2.497615146362574

Epoch: 446| Step: 0
Training loss: 2.7198219378474375
Validation loss: 2.457851661670694

Epoch: 5| Step: 1
Training loss: 1.5803628294860155
Validation loss: 2.495494978627319

Epoch: 5| Step: 2
Training loss: 1.9146385727289417
Validation loss: 2.513815794135365

Epoch: 5| Step: 3
Training loss: 1.7357102486565146
Validation loss: 2.43578271292828

Epoch: 5| Step: 4
Training loss: 2.097206451098473
Validation loss: 2.5229086987760043

Epoch: 5| Step: 5
Training loss: 2.059523312867596
Validation loss: 2.504179951807931

Epoch: 5| Step: 6
Training loss: 1.7778843990115833
Validation loss: 2.548657948083135

Epoch: 5| Step: 7
Training loss: 2.1165146550338707
Validation loss: 2.4934472211239456

Epoch: 5| Step: 8
Training loss: 2.019210819523112
Validation loss: 2.4700916233126606

Epoch: 5| Step: 9
Training loss: 1.6907953652445846
Validation loss: 2.4768418917615787

Epoch: 5| Step: 10
Training loss: 2.0308972565936463
Validation loss: 2.4041548003775084

Epoch: 447| Step: 0
Training loss: 1.688357523863785
Validation loss: 2.5587658430130276

Epoch: 5| Step: 1
Training loss: 1.6568469285403669
Validation loss: 2.4569102733116157

Epoch: 5| Step: 2
Training loss: 1.6479770686304132
Validation loss: 2.503087006734115

Epoch: 5| Step: 3
Training loss: 1.7230873865914185
Validation loss: 2.4821959701497907

Epoch: 5| Step: 4
Training loss: 2.2793817054894663
Validation loss: 2.450817965298002

Epoch: 5| Step: 5
Training loss: 1.6649042427318248
Validation loss: 2.5073147420545028

Epoch: 5| Step: 6
Training loss: 2.628622008512303
Validation loss: 2.5257356496161476

Epoch: 5| Step: 7
Training loss: 2.1509522303229676
Validation loss: 2.4539864786202474

Epoch: 5| Step: 8
Training loss: 2.67120031572119
Validation loss: 2.493477286138707

Epoch: 5| Step: 9
Training loss: 2.159235559755963
Validation loss: 2.4981457930256386

Epoch: 5| Step: 10
Training loss: 1.9716101563783168
Validation loss: 2.505084614289843

Epoch: 448| Step: 0
Training loss: 2.247223518516859
Validation loss: 2.4944287796458027

Epoch: 5| Step: 1
Training loss: 1.3539281879635388
Validation loss: 2.4731324336791407

Epoch: 5| Step: 2
Training loss: 2.21028229942923
Validation loss: 2.485782436422527

Epoch: 5| Step: 3
Training loss: 2.290292246798349
Validation loss: 2.432227845296769

Epoch: 5| Step: 4
Training loss: 1.6620817619208559
Validation loss: 2.495528969945422

Epoch: 5| Step: 5
Training loss: 2.516701225228746
Validation loss: 2.491194525772309

Epoch: 5| Step: 6
Training loss: 2.366363684194901
Validation loss: 2.5158569294244764

Epoch: 5| Step: 7
Training loss: 1.7365408081654956
Validation loss: 2.466214605123305

Epoch: 5| Step: 8
Training loss: 2.08203479988411
Validation loss: 2.4638582142577685

Epoch: 5| Step: 9
Training loss: 1.9726207767734096
Validation loss: 2.473746438313339

Epoch: 5| Step: 10
Training loss: 1.8780740334296528
Validation loss: 2.4700293320031026

Epoch: 449| Step: 0
Training loss: 2.5927810697568927
Validation loss: 2.449207279517141

Epoch: 5| Step: 1
Training loss: 2.0721815201844636
Validation loss: 2.449585876514875

Epoch: 5| Step: 2
Training loss: 2.2336829120656434
Validation loss: 2.447707074333802

Epoch: 5| Step: 3
Training loss: 1.8188582083376794
Validation loss: 2.445665184340296

Epoch: 5| Step: 4
Training loss: 1.9771147548267556
Validation loss: 2.509922642929551

Epoch: 5| Step: 5
Training loss: 1.620830468548725
Validation loss: 2.482410664825689

Epoch: 5| Step: 6
Training loss: 1.7588119039370829
Validation loss: 2.5130436189742675

Epoch: 5| Step: 7
Training loss: 2.122849442076179
Validation loss: 2.4728943605582616

Epoch: 5| Step: 8
Training loss: 2.149247339378131
Validation loss: 2.508351300788816

Epoch: 5| Step: 9
Training loss: 1.8498688367793414
Validation loss: 2.5087165510212426

Epoch: 5| Step: 10
Training loss: 2.04026332296409
Validation loss: 2.4011336418802403

Epoch: 450| Step: 0
Training loss: 2.692879194868254
Validation loss: 2.485939798712208

Epoch: 5| Step: 1
Training loss: 2.355994221290017
Validation loss: 2.51287999898463

Epoch: 5| Step: 2
Training loss: 2.0164800205503672
Validation loss: 2.5180373093244084

Epoch: 5| Step: 3
Training loss: 1.593515790297929
Validation loss: 2.494905965041888

Epoch: 5| Step: 4
Training loss: 1.9747473180868325
Validation loss: 2.4909150580403927

Epoch: 5| Step: 5
Training loss: 1.414933415925529
Validation loss: 2.466416491460134

Epoch: 5| Step: 6
Training loss: 2.390390621489137
Validation loss: 2.4730648684273824

Epoch: 5| Step: 7
Training loss: 1.851732270388822
Validation loss: 2.513631942348587

Epoch: 5| Step: 8
Training loss: 1.9670317281385636
Validation loss: 2.5260129374900253

Epoch: 5| Step: 9
Training loss: 1.8261903486490398
Validation loss: 2.4489987001650397

Epoch: 5| Step: 10
Training loss: 1.896330618002741
Validation loss: 2.4685754866191494

Testing loss: 2.756575732447622
