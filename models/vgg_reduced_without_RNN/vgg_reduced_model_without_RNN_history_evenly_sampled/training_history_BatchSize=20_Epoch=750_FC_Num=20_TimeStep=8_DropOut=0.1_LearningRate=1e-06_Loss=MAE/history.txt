Epoch: 1| Step: 0
Training loss: 3.7333388328552246
Validation loss: 2.87030372311992

Epoch: 5| Step: 1
Training loss: 2.1682708263397217
Validation loss: 2.8704649479158464

Epoch: 5| Step: 2
Training loss: 2.5950236320495605
Validation loss: 2.868766156576013

Epoch: 5| Step: 3
Training loss: 3.509507417678833
Validation loss: 2.867127941500756

Epoch: 5| Step: 4
Training loss: 3.1330599784851074
Validation loss: 2.866463533011816

Epoch: 5| Step: 5
Training loss: 3.2942936420440674
Validation loss: 2.8646377696785876

Epoch: 5| Step: 6
Training loss: 2.7203564643859863
Validation loss: 2.862687326246692

Epoch: 5| Step: 7
Training loss: 3.2531421184539795
Validation loss: 2.862546838739867

Epoch: 5| Step: 8
Training loss: 2.718749523162842
Validation loss: 2.8620937357666674

Epoch: 5| Step: 9
Training loss: 2.944709300994873
Validation loss: 2.8610028066942768

Epoch: 5| Step: 10
Training loss: 2.6533563137054443
Validation loss: 2.860672773853425

Epoch: 2| Step: 0
Training loss: 3.1519999504089355
Validation loss: 2.859461130634431

Epoch: 5| Step: 1
Training loss: 3.03300142288208
Validation loss: 2.8586535838342484

Epoch: 5| Step: 2
Training loss: 2.2800331115722656
Validation loss: 2.856805096390427

Epoch: 5| Step: 3
Training loss: 2.935120105743408
Validation loss: 2.8556223197649886

Epoch: 5| Step: 4
Training loss: 4.232138156890869
Validation loss: 2.8545907210278254

Epoch: 5| Step: 5
Training loss: 2.980691432952881
Validation loss: 2.8538195933065107

Epoch: 5| Step: 6
Training loss: 3.1171202659606934
Validation loss: 2.850722587236794

Epoch: 5| Step: 7
Training loss: 3.088759183883667
Validation loss: 2.8512461916092904

Epoch: 5| Step: 8
Training loss: 2.3700053691864014
Validation loss: 2.8510307009502123

Epoch: 5| Step: 9
Training loss: 2.67333984375
Validation loss: 2.8486936400013585

Epoch: 5| Step: 10
Training loss: 2.7855911254882812
Validation loss: 2.8463427994840886

Epoch: 3| Step: 0
Training loss: 3.42716908454895
Validation loss: 2.8468643593531784

Epoch: 5| Step: 1
Training loss: 2.637960910797119
Validation loss: 2.8469190059169645

Epoch: 5| Step: 2
Training loss: 2.4053008556365967
Validation loss: 2.844063756286457

Epoch: 5| Step: 3
Training loss: 2.3097946643829346
Validation loss: 2.8431452294831634

Epoch: 5| Step: 4
Training loss: 2.5269360542297363
Validation loss: 2.843743619098458

Epoch: 5| Step: 5
Training loss: 2.844452381134033
Validation loss: 2.841327444199593

Epoch: 5| Step: 6
Training loss: 3.613507032394409
Validation loss: 2.838205729761431

Epoch: 5| Step: 7
Training loss: 3.6654891967773438
Validation loss: 2.838206632162935

Epoch: 5| Step: 8
Training loss: 2.8476428985595703
Validation loss: 2.8377258649436374

Epoch: 5| Step: 9
Training loss: 3.205282688140869
Validation loss: 2.835666436021046

Epoch: 5| Step: 10
Training loss: 3.1460461616516113
Validation loss: 2.8343569796572448

Epoch: 4| Step: 0
Training loss: 2.6076340675354004
Validation loss: 2.8352225852268997

Epoch: 5| Step: 1
Training loss: 3.888425827026367
Validation loss: 2.8346351859390095

Epoch: 5| Step: 2
Training loss: 2.224522352218628
Validation loss: 2.8331562601109987

Epoch: 5| Step: 3
Training loss: 3.3653512001037598
Validation loss: 2.832018918888543

Epoch: 5| Step: 4
Training loss: 3.3038501739501953
Validation loss: 2.8322530151695333

Epoch: 5| Step: 5
Training loss: 3.0963332653045654
Validation loss: 2.830014318548223

Epoch: 5| Step: 6
Training loss: 3.1325385570526123
Validation loss: 2.8277698511718423

Epoch: 5| Step: 7
Training loss: 3.2482199668884277
Validation loss: 2.8288517639201176

Epoch: 5| Step: 8
Training loss: 2.9531495571136475
Validation loss: 2.8245596731862714

Epoch: 5| Step: 9
Training loss: 2.5045013427734375
Validation loss: 2.82434190985977

Epoch: 5| Step: 10
Training loss: 2.031421184539795
Validation loss: 2.8252868985617035

Epoch: 5| Step: 0
Training loss: 2.78360652923584
Validation loss: 2.8233303587923766

Epoch: 5| Step: 1
Training loss: 3.3714141845703125
Validation loss: 2.8216922795900734

Epoch: 5| Step: 2
Training loss: 3.342212200164795
Validation loss: 2.8195532906439995

Epoch: 5| Step: 3
Training loss: 2.976919174194336
Validation loss: 2.8201408565685315

Epoch: 5| Step: 4
Training loss: 2.3116230964660645
Validation loss: 2.8191019001827446

Epoch: 5| Step: 5
Training loss: 2.475132465362549
Validation loss: 2.81755559162427

Epoch: 5| Step: 6
Training loss: 2.9443743228912354
Validation loss: 2.815953193172332

Epoch: 5| Step: 7
Training loss: 3.255840301513672
Validation loss: 2.8165170351664224

Epoch: 5| Step: 8
Training loss: 3.2349400520324707
Validation loss: 2.813716052680887

Epoch: 5| Step: 9
Training loss: 2.7186450958251953
Validation loss: 2.8136645388859574

Epoch: 5| Step: 10
Training loss: 3.0059401988983154
Validation loss: 2.813114017568609

Epoch: 6| Step: 0
Training loss: 2.7168471813201904
Validation loss: 2.810249759304908

Epoch: 5| Step: 1
Training loss: 2.0737144947052
Validation loss: 2.8094593542878346

Epoch: 5| Step: 2
Training loss: 2.642927646636963
Validation loss: 2.808230753867857

Epoch: 5| Step: 3
Training loss: 3.9160308837890625
Validation loss: 2.808828235954367

Epoch: 5| Step: 4
Training loss: 2.861908435821533
Validation loss: 2.8048818777966242

Epoch: 5| Step: 5
Training loss: 3.1284618377685547
Validation loss: 2.8044406829341764

Epoch: 5| Step: 6
Training loss: 2.762842893600464
Validation loss: 2.805379693226148

Epoch: 5| Step: 7
Training loss: 2.602792263031006
Validation loss: 2.802079103326285

Epoch: 5| Step: 8
Training loss: 3.1703007221221924
Validation loss: 2.7992337903668805

Epoch: 5| Step: 9
Training loss: 3.495889186859131
Validation loss: 2.799494533128636

Epoch: 5| Step: 10
Training loss: 2.957113742828369
Validation loss: 2.7995525585707797

Epoch: 7| Step: 0
Training loss: 2.818701982498169
Validation loss: 2.798803044903663

Epoch: 5| Step: 1
Training loss: 2.6452627182006836
Validation loss: 2.797533171151274

Epoch: 5| Step: 2
Training loss: 3.6844959259033203
Validation loss: 2.7964340486834125

Epoch: 5| Step: 3
Training loss: 3.4831435680389404
Validation loss: 2.793599887560773

Epoch: 5| Step: 4
Training loss: 2.4327473640441895
Validation loss: 2.7914678794081493

Epoch: 5| Step: 5
Training loss: 2.5804474353790283
Validation loss: 2.789420074032199

Epoch: 5| Step: 6
Training loss: 3.1735012531280518
Validation loss: 2.790753000526018

Epoch: 5| Step: 7
Training loss: 3.321755886077881
Validation loss: 2.7884121325708207

Epoch: 5| Step: 8
Training loss: 2.9158549308776855
Validation loss: 2.788200086162936

Epoch: 5| Step: 9
Training loss: 2.3443527221679688
Validation loss: 2.78617980916013

Epoch: 5| Step: 10
Training loss: 2.7759664058685303
Validation loss: 2.7841737859992572

Epoch: 8| Step: 0
Training loss: 2.995497226715088
Validation loss: 2.781080138298773

Epoch: 5| Step: 1
Training loss: 2.9684207439422607
Validation loss: 2.7797522006496305

Epoch: 5| Step: 2
Training loss: 3.2236030101776123
Validation loss: 2.7791690262415076

Epoch: 5| Step: 3
Training loss: 2.4787392616271973
Validation loss: 2.775860881292692

Epoch: 5| Step: 4
Training loss: 3.6942226886749268
Validation loss: 2.7751999491004535

Epoch: 5| Step: 5
Training loss: 2.967183828353882
Validation loss: 2.772384294899561

Epoch: 5| Step: 6
Training loss: 2.3979358673095703
Validation loss: 2.7716678009238294

Epoch: 5| Step: 7
Training loss: 2.42682147026062
Validation loss: 2.7685023712855514

Epoch: 5| Step: 8
Training loss: 2.614269971847534
Validation loss: 2.765904462465676

Epoch: 5| Step: 9
Training loss: 3.3839099407196045
Validation loss: 2.7639965036863923

Epoch: 5| Step: 10
Training loss: 2.916273355484009
Validation loss: 2.762259673046809

Epoch: 9| Step: 0
Training loss: 1.9832340478897095
Validation loss: 2.760850401334865

Epoch: 5| Step: 1
Training loss: 3.0422561168670654
Validation loss: 2.7595227559407554

Epoch: 5| Step: 2
Training loss: 3.209334135055542
Validation loss: 2.7552528612075315

Epoch: 5| Step: 3
Training loss: 3.053546190261841
Validation loss: 2.753268962265343

Epoch: 5| Step: 4
Training loss: 3.1545825004577637
Validation loss: 2.751420949095039

Epoch: 5| Step: 5
Training loss: 3.154244899749756
Validation loss: 2.750673637595228

Epoch: 5| Step: 6
Training loss: 3.548231601715088
Validation loss: 2.748906022758894

Epoch: 5| Step: 7
Training loss: 2.7246227264404297
Validation loss: 2.743429655669838

Epoch: 5| Step: 8
Training loss: 2.4844768047332764
Validation loss: 2.74267509419431

Epoch: 5| Step: 9
Training loss: 3.1087090969085693
Validation loss: 2.742177194164645

Epoch: 5| Step: 10
Training loss: 2.332724094390869
Validation loss: 2.7379953861236572

Epoch: 10| Step: 0
Training loss: 2.601465940475464
Validation loss: 2.7367320112002793

Epoch: 5| Step: 1
Training loss: 2.954836368560791
Validation loss: 2.7338613720350367

Epoch: 5| Step: 2
Training loss: 2.3691351413726807
Validation loss: 2.7323686333112818

Epoch: 5| Step: 3
Training loss: 2.9388062953948975
Validation loss: 2.7299543375610025

Epoch: 5| Step: 4
Training loss: 3.234905242919922
Validation loss: 2.7276906915890273

Epoch: 5| Step: 5
Training loss: 2.7402515411376953
Validation loss: 2.7261368741271315

Epoch: 5| Step: 6
Training loss: 2.644184112548828
Validation loss: 2.7222653127485708

Epoch: 5| Step: 7
Training loss: 3.160259246826172
Validation loss: 2.71875883430563

Epoch: 5| Step: 8
Training loss: 2.6620547771453857
Validation loss: 2.7195280982602026

Epoch: 5| Step: 9
Training loss: 2.913693904876709
Validation loss: 2.7123976535694574

Epoch: 5| Step: 10
Training loss: 3.525362968444824
Validation loss: 2.71056245475687

Epoch: 11| Step: 0
Training loss: 2.5987048149108887
Validation loss: 2.7088571671516664

Epoch: 5| Step: 1
Training loss: 2.7141525745391846
Validation loss: 2.7074655614873415

Epoch: 5| Step: 2
Training loss: 2.993931770324707
Validation loss: 2.7012032667795816

Epoch: 5| Step: 3
Training loss: 2.490762710571289
Validation loss: 2.703850312899518

Epoch: 5| Step: 4
Training loss: 2.830284833908081
Validation loss: 2.697333602495091

Epoch: 5| Step: 5
Training loss: 2.8858399391174316
Validation loss: 2.6978809038798013

Epoch: 5| Step: 6
Training loss: 3.481179714202881
Validation loss: 2.6954261897712626

Epoch: 5| Step: 7
Training loss: 3.1936306953430176
Validation loss: 2.692155186847974

Epoch: 5| Step: 8
Training loss: 2.963756799697876
Validation loss: 2.6883336702982583

Epoch: 5| Step: 9
Training loss: 2.8048434257507324
Validation loss: 2.6857306393243934

Epoch: 5| Step: 10
Training loss: 2.423210859298706
Validation loss: 2.6804011790983138

Epoch: 12| Step: 0
Training loss: 2.966034412384033
Validation loss: 2.677514486415412

Epoch: 5| Step: 1
Training loss: 2.9720451831817627
Validation loss: 2.678042539986231

Epoch: 5| Step: 2
Training loss: 2.821000337600708
Validation loss: 2.6740955281001266

Epoch: 5| Step: 3
Training loss: 3.0641798973083496
Validation loss: 2.6718617741779616

Epoch: 5| Step: 4
Training loss: 2.5691239833831787
Validation loss: 2.6647818011622273

Epoch: 5| Step: 5
Training loss: 3.3262887001037598
Validation loss: 2.6649810626942623

Epoch: 5| Step: 6
Training loss: 3.0578246116638184
Validation loss: 2.6604992599897486

Epoch: 5| Step: 7
Training loss: 2.0975046157836914
Validation loss: 2.6560426168544318

Epoch: 5| Step: 8
Training loss: 2.7474026679992676
Validation loss: 2.652026463580388

Epoch: 5| Step: 9
Training loss: 3.1217780113220215
Validation loss: 2.6522410941380326

Epoch: 5| Step: 10
Training loss: 2.4003591537475586
Validation loss: 2.6483336033359652

Epoch: 13| Step: 0
Training loss: 3.0181198120117188
Validation loss: 2.645350222946495

Epoch: 5| Step: 1
Training loss: 2.2848010063171387
Validation loss: 2.64098879086074

Epoch: 5| Step: 2
Training loss: 3.031226396560669
Validation loss: 2.6414467391147407

Epoch: 5| Step: 3
Training loss: 3.2765796184539795
Validation loss: 2.6365241491666405

Epoch: 5| Step: 4
Training loss: 2.6964457035064697
Validation loss: 2.628244028296522

Epoch: 5| Step: 5
Training loss: 2.318754196166992
Validation loss: 2.630532121145597

Epoch: 5| Step: 6
Training loss: 2.648136854171753
Validation loss: 2.6276403832179245

Epoch: 5| Step: 7
Training loss: 3.730910062789917
Validation loss: 2.6244606869195097

Epoch: 5| Step: 8
Training loss: 2.228158473968506
Validation loss: 2.615933854092834

Epoch: 5| Step: 9
Training loss: 2.7570252418518066
Validation loss: 2.6148225850956415

Epoch: 5| Step: 10
Training loss: 2.979982614517212
Validation loss: 2.608630282904512

Epoch: 14| Step: 0
Training loss: 2.8509631156921387
Validation loss: 2.6104437381990495

Epoch: 5| Step: 1
Training loss: 2.810814142227173
Validation loss: 2.603564977645874

Epoch: 5| Step: 2
Training loss: 2.9449315071105957
Validation loss: 2.60098070995782

Epoch: 5| Step: 3
Training loss: 2.860612154006958
Validation loss: 2.596743150423932

Epoch: 5| Step: 4
Training loss: 2.6893935203552246
Validation loss: 2.5942463080088296

Epoch: 5| Step: 5
Training loss: 3.2761950492858887
Validation loss: 2.5913605292638144

Epoch: 5| Step: 6
Training loss: 2.7198729515075684
Validation loss: 2.586334072133546

Epoch: 5| Step: 7
Training loss: 2.3259124755859375
Validation loss: 2.586518579913724

Epoch: 5| Step: 8
Training loss: 2.257340431213379
Validation loss: 2.5772237521345898

Epoch: 5| Step: 9
Training loss: 2.906728506088257
Validation loss: 2.570452518360589

Epoch: 5| Step: 10
Training loss: 3.125281810760498
Validation loss: 2.569785887195218

Epoch: 15| Step: 0
Training loss: 3.3871607780456543
Validation loss: 2.5661208834699405

Epoch: 5| Step: 1
Training loss: 2.716538906097412
Validation loss: 2.561972451466386

Epoch: 5| Step: 2
Training loss: 2.216519832611084
Validation loss: 2.557931907715336

Epoch: 5| Step: 3
Training loss: 3.3816699981689453
Validation loss: 2.557569588384321

Epoch: 5| Step: 4
Training loss: 2.5176000595092773
Validation loss: 2.5511503040149646

Epoch: 5| Step: 5
Training loss: 2.031782627105713
Validation loss: 2.546850730014104

Epoch: 5| Step: 6
Training loss: 2.5421133041381836
Validation loss: 2.5428938993843655

Epoch: 5| Step: 7
Training loss: 3.1598682403564453
Validation loss: 2.5389784228417183

Epoch: 5| Step: 8
Training loss: 3.3901162147521973
Validation loss: 2.5375888988535893

Epoch: 5| Step: 9
Training loss: 2.0536131858825684
Validation loss: 2.5271053993573753

Epoch: 5| Step: 10
Training loss: 3.1116392612457275
Validation loss: 2.526085297266642

Epoch: 16| Step: 0
Training loss: 2.417518138885498
Validation loss: 2.5223746504834903

Epoch: 5| Step: 1
Training loss: 2.969555616378784
Validation loss: 2.518234896403487

Epoch: 5| Step: 2
Training loss: 2.524468183517456
Validation loss: 2.508992329720528

Epoch: 5| Step: 3
Training loss: 2.7806661128997803
Validation loss: 2.5001042530100834

Epoch: 5| Step: 4
Training loss: 2.140695571899414
Validation loss: 2.5017870574869137

Epoch: 5| Step: 5
Training loss: 2.377596139907837
Validation loss: 2.5004297943525415

Epoch: 5| Step: 6
Training loss: 2.91043758392334
Validation loss: 2.49462692968307

Epoch: 5| Step: 7
Training loss: 3.6800332069396973
Validation loss: 2.4897102463629937

Epoch: 5| Step: 8
Training loss: 3.302067279815674
Validation loss: 2.4810189611168316

Epoch: 5| Step: 9
Training loss: 2.3882291316986084
Validation loss: 2.4734174897593837

Epoch: 5| Step: 10
Training loss: 2.6008543968200684
Validation loss: 2.474994139004779

Epoch: 17| Step: 0
Training loss: 2.550262212753296
Validation loss: 2.464468535556588

Epoch: 5| Step: 1
Training loss: 2.924586772918701
Validation loss: 2.460437177329935

Epoch: 5| Step: 2
Training loss: 2.417707920074463
Validation loss: 2.457276354553879

Epoch: 5| Step: 3
Training loss: 2.9047470092773438
Validation loss: 2.4514743230676137

Epoch: 5| Step: 4
Training loss: 3.0021965503692627
Validation loss: 2.4458052368574243

Epoch: 5| Step: 5
Training loss: 3.1754848957061768
Validation loss: 2.444535375923239

Epoch: 5| Step: 6
Training loss: 2.526991367340088
Validation loss: 2.434540210231658

Epoch: 5| Step: 7
Training loss: 2.235183000564575
Validation loss: 2.4225354322823147

Epoch: 5| Step: 8
Training loss: 2.5510611534118652
Validation loss: 2.422723465068366

Epoch: 5| Step: 9
Training loss: 2.9877548217773438
Validation loss: 2.4159292815833964

Epoch: 5| Step: 10
Training loss: 2.4448983669281006
Validation loss: 2.4146424057663127

Epoch: 18| Step: 0
Training loss: 2.2429723739624023
Validation loss: 2.398498381337812

Epoch: 5| Step: 1
Training loss: 2.3789916038513184
Validation loss: 2.4030559755140737

Epoch: 5| Step: 2
Training loss: 2.865830898284912
Validation loss: 2.3847492689727456

Epoch: 5| Step: 3
Training loss: 2.885667085647583
Validation loss: 2.386923333649994

Epoch: 5| Step: 4
Training loss: 2.6844515800476074
Validation loss: 2.37721646729336

Epoch: 5| Step: 5
Training loss: 2.2426838874816895
Validation loss: 2.3766452009959886

Epoch: 5| Step: 6
Training loss: 3.1999917030334473
Validation loss: 2.3715617425980104

Epoch: 5| Step: 7
Training loss: 2.573922634124756
Validation loss: 2.3597313870665846

Epoch: 5| Step: 8
Training loss: 3.029932737350464
Validation loss: 2.3570014174266527

Epoch: 5| Step: 9
Training loss: 2.744211196899414
Validation loss: 2.3462292225130144

Epoch: 5| Step: 10
Training loss: 2.5195491313934326
Validation loss: 2.334845971035701

Epoch: 19| Step: 0
Training loss: 2.930018186569214
Validation loss: 2.3300981444697224

Epoch: 5| Step: 1
Training loss: 2.8916776180267334
Validation loss: 2.329307679207094

Epoch: 5| Step: 2
Training loss: 2.4694302082061768
Validation loss: 2.3177895751050723

Epoch: 5| Step: 3
Training loss: 2.5063910484313965
Validation loss: 2.3185104195789625

Epoch: 5| Step: 4
Training loss: 2.326267719268799
Validation loss: 2.311930041159353

Epoch: 5| Step: 5
Training loss: 2.7706682682037354
Validation loss: 2.3026141787088044

Epoch: 5| Step: 6
Training loss: 2.5923755168914795
Validation loss: 2.3003914945869037

Epoch: 5| Step: 7
Training loss: 2.464085340499878
Validation loss: 2.300523963025821

Epoch: 5| Step: 8
Training loss: 2.6299524307250977
Validation loss: 2.2874662773583525

Epoch: 5| Step: 9
Training loss: 2.583747148513794
Validation loss: 2.287449070202407

Epoch: 5| Step: 10
Training loss: 2.809539556503296
Validation loss: 2.280994453737813

Epoch: 20| Step: 0
Training loss: 2.6351988315582275
Validation loss: 2.2733628801120225

Epoch: 5| Step: 1
Training loss: 2.172309637069702
Validation loss: 2.2662599009852253

Epoch: 5| Step: 2
Training loss: 2.4747090339660645
Validation loss: 2.254034388449884

Epoch: 5| Step: 3
Training loss: 2.6498465538024902
Validation loss: 2.260429882234143

Epoch: 5| Step: 4
Training loss: 3.119307279586792
Validation loss: 2.246342423141644

Epoch: 5| Step: 5
Training loss: 2.077136754989624
Validation loss: 2.246847075800742

Epoch: 5| Step: 6
Training loss: 2.7643067836761475
Validation loss: 2.245016667150682

Epoch: 5| Step: 7
Training loss: 2.5082075595855713
Validation loss: 2.241020348764235

Epoch: 5| Step: 8
Training loss: 2.7275469303131104
Validation loss: 2.221649064812609

Epoch: 5| Step: 9
Training loss: 3.1702616214752197
Validation loss: 2.2298643665928997

Epoch: 5| Step: 10
Training loss: 2.2262699604034424
Validation loss: 2.2168615261713662

Epoch: 21| Step: 0
Training loss: 2.986450672149658
Validation loss: 2.2192127371347077

Epoch: 5| Step: 1
Training loss: 1.9148521423339844
Validation loss: 2.2083070508895384

Epoch: 5| Step: 2
Training loss: 2.6181042194366455
Validation loss: 2.2057946369212162

Epoch: 5| Step: 3
Training loss: 1.9601656198501587
Validation loss: 2.204702810574603

Epoch: 5| Step: 4
Training loss: 2.764869451522827
Validation loss: 2.194868249277915

Epoch: 5| Step: 5
Training loss: 2.931689739227295
Validation loss: 2.1986800573205434

Epoch: 5| Step: 6
Training loss: 2.7075953483581543
Validation loss: 2.1885303835715018

Epoch: 5| Step: 7
Training loss: 2.2591114044189453
Validation loss: 2.1852968354378977

Epoch: 5| Step: 8
Training loss: 2.9272048473358154
Validation loss: 2.1801824313338085

Epoch: 5| Step: 9
Training loss: 2.4177191257476807
Validation loss: 2.1797637503634215

Epoch: 5| Step: 10
Training loss: 2.7052459716796875
Validation loss: 2.1700101180743148

Epoch: 22| Step: 0
Training loss: 2.4602901935577393
Validation loss: 2.167269934890091

Epoch: 5| Step: 1
Training loss: 2.613356590270996
Validation loss: 2.161835560234644

Epoch: 5| Step: 2
Training loss: 3.2429604530334473
Validation loss: 2.1577348439924178

Epoch: 5| Step: 3
Training loss: 2.8885016441345215
Validation loss: 2.1469960084525486

Epoch: 5| Step: 4
Training loss: 2.2833316326141357
Validation loss: 2.149790007580993

Epoch: 5| Step: 5
Training loss: 2.5728907585144043
Validation loss: 2.140052513409686

Epoch: 5| Step: 6
Training loss: 2.315605640411377
Validation loss: 2.1515670873785533

Epoch: 5| Step: 7
Training loss: 2.4394257068634033
Validation loss: 2.1352929171695503

Epoch: 5| Step: 8
Training loss: 2.234046697616577
Validation loss: 2.1384133190237065

Epoch: 5| Step: 9
Training loss: 1.9491939544677734
Validation loss: 2.1408034191336682

Epoch: 5| Step: 10
Training loss: 2.8819994926452637
Validation loss: 2.125706398358909

Epoch: 23| Step: 0
Training loss: 2.140444278717041
Validation loss: 2.128777934658912

Epoch: 5| Step: 1
Training loss: 2.4941015243530273
Validation loss: 2.122479038853799

Epoch: 5| Step: 2
Training loss: 2.793126344680786
Validation loss: 2.109650513177277

Epoch: 5| Step: 3
Training loss: 2.30216908454895
Validation loss: 2.1146811105871715

Epoch: 5| Step: 4
Training loss: 2.95442271232605
Validation loss: 2.1076666180805494

Epoch: 5| Step: 5
Training loss: 2.880532741546631
Validation loss: 2.1160065051048034

Epoch: 5| Step: 6
Training loss: 2.0478057861328125
Validation loss: 2.1082554324980705

Epoch: 5| Step: 7
Training loss: 2.1012420654296875
Validation loss: 2.104328432390767

Epoch: 5| Step: 8
Training loss: 2.4638853073120117
Validation loss: 2.0936570449541976

Epoch: 5| Step: 9
Training loss: 2.947075366973877
Validation loss: 2.08609055190958

Epoch: 5| Step: 10
Training loss: 2.4538660049438477
Validation loss: 2.076923317806695

Epoch: 24| Step: 0
Training loss: 2.785663604736328
Validation loss: 2.093950952253034

Epoch: 5| Step: 1
Training loss: 1.9869111776351929
Validation loss: 2.0738506663230156

Epoch: 5| Step: 2
Training loss: 2.180220365524292
Validation loss: 2.0881659958952214

Epoch: 5| Step: 3
Training loss: 2.1910154819488525
Validation loss: 2.0841791783609698

Epoch: 5| Step: 4
Training loss: 2.719956159591675
Validation loss: 2.070205630794648

Epoch: 5| Step: 5
Training loss: 2.2009661197662354
Validation loss: 2.0665745453167985

Epoch: 5| Step: 6
Training loss: 2.9153823852539062
Validation loss: 2.0592680438872306

Epoch: 5| Step: 7
Training loss: 2.7207207679748535
Validation loss: 2.068698670274468

Epoch: 5| Step: 8
Training loss: 2.770355701446533
Validation loss: 2.0715356052562757

Epoch: 5| Step: 9
Training loss: 2.6226038932800293
Validation loss: 2.0552357217316986

Epoch: 5| Step: 10
Training loss: 2.3059566020965576
Validation loss: 2.0614445414594424

Epoch: 25| Step: 0
Training loss: 2.4959120750427246
Validation loss: 2.060423542094487

Epoch: 5| Step: 1
Training loss: 2.1781551837921143
Validation loss: 2.0730192840740247

Epoch: 5| Step: 2
Training loss: 2.5765280723571777
Validation loss: 2.0457569527369674

Epoch: 5| Step: 3
Training loss: 2.647995710372925
Validation loss: 2.063437492616715

Epoch: 5| Step: 4
Training loss: 2.006190538406372
Validation loss: 2.0367111647000877

Epoch: 5| Step: 5
Training loss: 2.611595869064331
Validation loss: 2.0497061103902836

Epoch: 5| Step: 6
Training loss: 2.805025577545166
Validation loss: 2.049614567910471

Epoch: 5| Step: 7
Training loss: 2.6533026695251465
Validation loss: 2.0502969526475474

Epoch: 5| Step: 8
Training loss: 2.0938429832458496
Validation loss: 2.0412104001609226

Epoch: 5| Step: 9
Training loss: 2.5384087562561035
Validation loss: 2.0317773447241834

Epoch: 5| Step: 10
Training loss: 2.7768044471740723
Validation loss: 2.031533618127146

Epoch: 26| Step: 0
Training loss: 2.5970585346221924
Validation loss: 2.0358341009386125

Epoch: 5| Step: 1
Training loss: 2.9462568759918213
Validation loss: 2.0359549086580992

Epoch: 5| Step: 2
Training loss: 2.2193546295166016
Validation loss: 2.031954050064087

Epoch: 5| Step: 3
Training loss: 2.828007221221924
Validation loss: 2.03475530685917

Epoch: 5| Step: 4
Training loss: 2.5412514209747314
Validation loss: 2.026410331008255

Epoch: 5| Step: 5
Training loss: 2.6187174320220947
Validation loss: 2.0371053859751713

Epoch: 5| Step: 6
Training loss: 2.340506076812744
Validation loss: 2.0255722973936345

Epoch: 5| Step: 7
Training loss: 1.733587622642517
Validation loss: 2.038658780436362

Epoch: 5| Step: 8
Training loss: 2.2937076091766357
Validation loss: 2.0342985532617055

Epoch: 5| Step: 9
Training loss: 2.361408233642578
Validation loss: 2.0275118120255007

Epoch: 5| Step: 10
Training loss: 2.7663068771362305
Validation loss: 2.0241611106421358

Epoch: 27| Step: 0
Training loss: 2.6013741493225098
Validation loss: 2.053233068476441

Epoch: 5| Step: 1
Training loss: 2.706939458847046
Validation loss: 2.0174515298617783

Epoch: 5| Step: 2
Training loss: 2.22991681098938
Validation loss: 2.0313280038936163

Epoch: 5| Step: 3
Training loss: 2.1523025035858154
Validation loss: 2.037247045065767

Epoch: 5| Step: 4
Training loss: 1.9840366840362549
Validation loss: 2.0200586190787693

Epoch: 5| Step: 5
Training loss: 2.4817214012145996
Validation loss: 2.0401657781293316

Epoch: 5| Step: 6
Training loss: 2.82232666015625
Validation loss: 2.0327607534265004

Epoch: 5| Step: 7
Training loss: 2.432619571685791
Validation loss: 2.029486304970198

Epoch: 5| Step: 8
Training loss: 2.1996567249298096
Validation loss: 2.020331641679169

Epoch: 5| Step: 9
Training loss: 2.6224231719970703
Validation loss: 2.0248253114761843

Epoch: 5| Step: 10
Training loss: 3.067375659942627
Validation loss: 2.0227644879330873

Epoch: 28| Step: 0
Training loss: 2.3005423545837402
Validation loss: 2.030800880924348

Epoch: 5| Step: 1
Training loss: 2.7234129905700684
Validation loss: 2.019704245751904

Epoch: 5| Step: 2
Training loss: 2.1279749870300293
Validation loss: 2.0263204446402927

Epoch: 5| Step: 3
Training loss: 2.736354351043701
Validation loss: 2.0260328720974665

Epoch: 5| Step: 4
Training loss: 2.61260986328125
Validation loss: 2.017461835697133

Epoch: 5| Step: 5
Training loss: 1.5751770734786987
Validation loss: 2.0368362434448732

Epoch: 5| Step: 6
Training loss: 2.905329704284668
Validation loss: 2.032730563994377

Epoch: 5| Step: 7
Training loss: 2.6628243923187256
Validation loss: 2.019340656136954

Epoch: 5| Step: 8
Training loss: 2.17203950881958
Validation loss: 2.0351246223654798

Epoch: 5| Step: 9
Training loss: 2.662446975708008
Validation loss: 2.013323780029051

Epoch: 5| Step: 10
Training loss: 2.6141865253448486
Validation loss: 2.034617913666592

Epoch: 29| Step: 0
Training loss: 2.117051601409912
Validation loss: 2.026191429425311

Epoch: 5| Step: 1
Training loss: 2.2189176082611084
Validation loss: 2.0285394755742883

Epoch: 5| Step: 2
Training loss: 1.9535661935806274
Validation loss: 2.0178760046600015

Epoch: 5| Step: 3
Training loss: 3.044691562652588
Validation loss: 2.030008368594672

Epoch: 5| Step: 4
Training loss: 2.5529608726501465
Validation loss: 2.0257172161532986

Epoch: 5| Step: 5
Training loss: 2.868952989578247
Validation loss: 2.0386296843969696

Epoch: 5| Step: 6
Training loss: 2.0421454906463623
Validation loss: 2.025583782503682

Epoch: 5| Step: 7
Training loss: 2.2835323810577393
Validation loss: 2.044983063974688

Epoch: 5| Step: 8
Training loss: 2.5573534965515137
Validation loss: 2.0138707263495332

Epoch: 5| Step: 9
Training loss: 2.9083924293518066
Validation loss: 2.031849463780721

Epoch: 5| Step: 10
Training loss: 2.53485107421875
Validation loss: 2.0176213992539274

Epoch: 30| Step: 0
Training loss: 2.4619686603546143
Validation loss: 2.0149736353146133

Epoch: 5| Step: 1
Training loss: 2.5335497856140137
Validation loss: 2.022454397652739

Epoch: 5| Step: 2
Training loss: 2.4777066707611084
Validation loss: 2.0265927007121425

Epoch: 5| Step: 3
Training loss: 2.8124277591705322
Validation loss: 2.0301765575203845

Epoch: 5| Step: 4
Training loss: 2.2374682426452637
Validation loss: 2.03464146583311

Epoch: 5| Step: 5
Training loss: 2.233807325363159
Validation loss: 2.024857146765596

Epoch: 5| Step: 6
Training loss: 2.72249698638916
Validation loss: 2.036156610776019

Epoch: 5| Step: 7
Training loss: 1.995111107826233
Validation loss: 2.034486565538632

Epoch: 5| Step: 8
Training loss: 2.395240068435669
Validation loss: 2.019726541734511

Epoch: 5| Step: 9
Training loss: 2.1653714179992676
Validation loss: 2.0196312114756596

Epoch: 5| Step: 10
Training loss: 3.067840099334717
Validation loss: 2.034236641340358

Epoch: 31| Step: 0
Training loss: 3.180229902267456
Validation loss: 2.0281255629754837

Epoch: 5| Step: 1
Training loss: 1.809403657913208
Validation loss: 2.020161618468582

Epoch: 5| Step: 2
Training loss: 2.318294048309326
Validation loss: 2.0235164319315264

Epoch: 5| Step: 3
Training loss: 2.5130579471588135
Validation loss: 2.022092637195382

Epoch: 5| Step: 4
Training loss: 1.8301947116851807
Validation loss: 2.017941282641503

Epoch: 5| Step: 5
Training loss: 2.5888803005218506
Validation loss: 2.0251846390385784

Epoch: 5| Step: 6
Training loss: 2.7142574787139893
Validation loss: 2.000231494185745

Epoch: 5| Step: 7
Training loss: 2.452277421951294
Validation loss: 2.0073013382573284

Epoch: 5| Step: 8
Training loss: 2.3487789630889893
Validation loss: 2.015621590357955

Epoch: 5| Step: 9
Training loss: 2.7326340675354004
Validation loss: 2.0019359383531796

Epoch: 5| Step: 10
Training loss: 2.385788679122925
Validation loss: 2.0389167724117154

Epoch: 32| Step: 0
Training loss: 2.728945255279541
Validation loss: 2.0284249692834835

Epoch: 5| Step: 1
Training loss: 2.17535662651062
Validation loss: 2.021962999015726

Epoch: 5| Step: 2
Training loss: 2.519681930541992
Validation loss: 2.025712877191523

Epoch: 5| Step: 3
Training loss: 2.6025190353393555
Validation loss: 2.0150219394314672

Epoch: 5| Step: 4
Training loss: 2.3609824180603027
Validation loss: 2.011204133751572

Epoch: 5| Step: 5
Training loss: 1.726056694984436
Validation loss: 2.018962908816594

Epoch: 5| Step: 6
Training loss: 2.2791519165039062
Validation loss: 2.017218946128763

Epoch: 5| Step: 7
Training loss: 2.962012767791748
Validation loss: 2.0223988474056287

Epoch: 5| Step: 8
Training loss: 2.415356159210205
Validation loss: 2.007119663300053

Epoch: 5| Step: 9
Training loss: 2.3451333045959473
Validation loss: 2.0158258202255412

Epoch: 5| Step: 10
Training loss: 2.8470170497894287
Validation loss: 2.0136924597524826

Epoch: 33| Step: 0
Training loss: 3.163508415222168
Validation loss: 2.0130942970193844

Epoch: 5| Step: 1
Training loss: 2.0056490898132324
Validation loss: 2.030623303946628

Epoch: 5| Step: 2
Training loss: 2.808868885040283
Validation loss: 2.0274156883198726

Epoch: 5| Step: 3
Training loss: 2.396829843521118
Validation loss: 2.0195750959457888

Epoch: 5| Step: 4
Training loss: 2.0669984817504883
Validation loss: 2.025102093655576

Epoch: 5| Step: 5
Training loss: 2.3818955421447754
Validation loss: 2.013609460605088

Epoch: 5| Step: 6
Training loss: 1.987322211265564
Validation loss: 2.021861007136683

Epoch: 5| Step: 7
Training loss: 2.321216344833374
Validation loss: 2.0314896439993255

Epoch: 5| Step: 8
Training loss: 3.084362030029297
Validation loss: 2.0269301117107434

Epoch: 5| Step: 9
Training loss: 2.3740577697753906
Validation loss: 2.0250049919210453

Epoch: 5| Step: 10
Training loss: 2.249296188354492
Validation loss: 2.013165545719926

Epoch: 34| Step: 0
Training loss: 2.280088424682617
Validation loss: 2.018694946842809

Epoch: 5| Step: 1
Training loss: 2.306957244873047
Validation loss: 2.0264339370112263

Epoch: 5| Step: 2
Training loss: 2.4061174392700195
Validation loss: 2.016722984211419

Epoch: 5| Step: 3
Training loss: 2.4951961040496826
Validation loss: 2.019029117399646

Epoch: 5| Step: 4
Training loss: 2.4307827949523926
Validation loss: 2.0195699712281585

Epoch: 5| Step: 5
Training loss: 2.5813839435577393
Validation loss: 2.0159042471198627

Epoch: 5| Step: 6
Training loss: 2.219719648361206
Validation loss: 2.01994466012524

Epoch: 5| Step: 7
Training loss: 2.670132637023926
Validation loss: 2.0279996830929994

Epoch: 5| Step: 8
Training loss: 2.191880941390991
Validation loss: 2.0236335159629903

Epoch: 5| Step: 9
Training loss: 2.4616951942443848
Validation loss: 2.018664798428935

Epoch: 5| Step: 10
Training loss: 2.7892932891845703
Validation loss: 2.012140404793524

Epoch: 35| Step: 0
Training loss: 2.268045663833618
Validation loss: 2.0161375922541462

Epoch: 5| Step: 1
Training loss: 2.7313826084136963
Validation loss: 2.020033171100001

Epoch: 5| Step: 2
Training loss: 2.0189805030822754
Validation loss: 2.00984094219823

Epoch: 5| Step: 3
Training loss: 2.168283700942993
Validation loss: 2.013699713573661

Epoch: 5| Step: 4
Training loss: 2.169151782989502
Validation loss: 2.0295927780930714

Epoch: 5| Step: 5
Training loss: 2.6075210571289062
Validation loss: 2.0127376728160407

Epoch: 5| Step: 6
Training loss: 2.6579315662384033
Validation loss: 2.016768645214778

Epoch: 5| Step: 7
Training loss: 2.409907817840576
Validation loss: 2.017459613020702

Epoch: 5| Step: 8
Training loss: 2.4985885620117188
Validation loss: 2.0086747523277038

Epoch: 5| Step: 9
Training loss: 2.327436685562134
Validation loss: 2.0111337105433145

Epoch: 5| Step: 10
Training loss: 2.9636070728302
Validation loss: 2.022964623666579

Epoch: 36| Step: 0
Training loss: 2.7813000679016113
Validation loss: 2.026041248793243

Epoch: 5| Step: 1
Training loss: 2.8067047595977783
Validation loss: 2.002500900658228

Epoch: 5| Step: 2
Training loss: 2.1192023754119873
Validation loss: 2.007640302822154

Epoch: 5| Step: 3
Training loss: 2.615584373474121
Validation loss: 2.004117319660802

Epoch: 5| Step: 4
Training loss: 2.196654796600342
Validation loss: 2.0132135280998806

Epoch: 5| Step: 5
Training loss: 2.7119312286376953
Validation loss: 2.027797355446764

Epoch: 5| Step: 6
Training loss: 2.379504680633545
Validation loss: 2.01001803592969

Epoch: 5| Step: 7
Training loss: 2.4683780670166016
Validation loss: 2.0254453612912084

Epoch: 5| Step: 8
Training loss: 1.947951316833496
Validation loss: 2.015216878665391

Epoch: 5| Step: 9
Training loss: 2.031414031982422
Validation loss: 1.999592564439261

Epoch: 5| Step: 10
Training loss: 2.6992058753967285
Validation loss: 2.024309117306945

Epoch: 37| Step: 0
Training loss: 2.340038299560547
Validation loss: 2.01724378396106

Epoch: 5| Step: 1
Training loss: 2.6473400592803955
Validation loss: 2.016716508455174

Epoch: 5| Step: 2
Training loss: 2.656830310821533
Validation loss: 2.0233463318117204

Epoch: 5| Step: 3
Training loss: 2.6068150997161865
Validation loss: 2.010587065450607

Epoch: 5| Step: 4
Training loss: 1.498389720916748
Validation loss: 2.009855338322219

Epoch: 5| Step: 5
Training loss: 2.71018648147583
Validation loss: 2.0166114632801344

Epoch: 5| Step: 6
Training loss: 2.609889030456543
Validation loss: 2.007741935791508

Epoch: 5| Step: 7
Training loss: 1.6829811334609985
Validation loss: 2.0131468747251775

Epoch: 5| Step: 8
Training loss: 2.4205384254455566
Validation loss: 2.0162498438230125

Epoch: 5| Step: 9
Training loss: 2.9126052856445312
Validation loss: 2.021239883156233

Epoch: 5| Step: 10
Training loss: 2.670088291168213
Validation loss: 2.0271452601237963

Epoch: 38| Step: 0
Training loss: 2.5355536937713623
Validation loss: 2.0223395465522684

Epoch: 5| Step: 1
Training loss: 2.69004225730896
Validation loss: 2.0167118785201863

Epoch: 5| Step: 2
Training loss: 2.6787238121032715
Validation loss: 2.01260547484121

Epoch: 5| Step: 3
Training loss: 2.599025011062622
Validation loss: 2.0171328693307857

Epoch: 5| Step: 4
Training loss: 2.4924890995025635
Validation loss: 2.014928251184443

Epoch: 5| Step: 5
Training loss: 2.155646324157715
Validation loss: 2.008639940651514

Epoch: 5| Step: 6
Training loss: 2.4713492393493652
Validation loss: 2.004984886415543

Epoch: 5| Step: 7
Training loss: 2.4951870441436768
Validation loss: 2.002279785371596

Epoch: 5| Step: 8
Training loss: 2.1483242511749268
Validation loss: 1.9919526359086395

Epoch: 5| Step: 9
Training loss: 2.336637496948242
Validation loss: 2.0082666899568293

Epoch: 5| Step: 10
Training loss: 1.9431101083755493
Validation loss: 2.003601485683072

Epoch: 39| Step: 0
Training loss: 2.812016010284424
Validation loss: 2.0152433277458273

Epoch: 5| Step: 1
Training loss: 2.8729898929595947
Validation loss: 2.005082864915171

Epoch: 5| Step: 2
Training loss: 3.1242847442626953
Validation loss: 2.0030083887038694

Epoch: 5| Step: 3
Training loss: 2.2596933841705322
Validation loss: 2.0148900978026854

Epoch: 5| Step: 4
Training loss: 1.9815305471420288
Validation loss: 2.003153534345729

Epoch: 5| Step: 5
Training loss: 2.245328903198242
Validation loss: 2.00497624181932

Epoch: 5| Step: 6
Training loss: 2.202582597732544
Validation loss: 2.00697410491205

Epoch: 5| Step: 7
Training loss: 2.5408833026885986
Validation loss: 2.0146541121185466

Epoch: 5| Step: 8
Training loss: 2.5762155055999756
Validation loss: 2.0158510554221367

Epoch: 5| Step: 9
Training loss: 2.409775972366333
Validation loss: 2.013541025500144

Epoch: 5| Step: 10
Training loss: 1.552428126335144
Validation loss: 1.9992462191530453

Epoch: 40| Step: 0
Training loss: 2.846257209777832
Validation loss: 2.012711332690331

Epoch: 5| Step: 1
Training loss: 2.21409273147583
Validation loss: 1.9986632908544233

Epoch: 5| Step: 2
Training loss: 2.2201321125030518
Validation loss: 2.001518585348642

Epoch: 5| Step: 3
Training loss: 2.959352970123291
Validation loss: 2.0012169884097193

Epoch: 5| Step: 4
Training loss: 1.536456823348999
Validation loss: 2.0066522654666694

Epoch: 5| Step: 5
Training loss: 2.2722010612487793
Validation loss: 2.0002479642950077

Epoch: 5| Step: 6
Training loss: 2.7395825386047363
Validation loss: 1.9917399037268855

Epoch: 5| Step: 7
Training loss: 1.815757393836975
Validation loss: 1.9903982326548586

Epoch: 5| Step: 8
Training loss: 2.919085741043091
Validation loss: 1.9997616275664298

Epoch: 5| Step: 9
Training loss: 2.3630447387695312
Validation loss: 2.014036584925908

Epoch: 5| Step: 10
Training loss: 2.606384515762329
Validation loss: 1.9905514076191893

Epoch: 41| Step: 0
Training loss: 2.5397045612335205
Validation loss: 1.9854864817793652

Epoch: 5| Step: 1
Training loss: 2.571357488632202
Validation loss: 1.991829474767049

Epoch: 5| Step: 2
Training loss: 2.4397172927856445
Validation loss: 1.9818759336266467

Epoch: 5| Step: 3
Training loss: 2.2352612018585205
Validation loss: 1.9994798642332836

Epoch: 5| Step: 4
Training loss: 2.2002296447753906
Validation loss: 1.9977799795007194

Epoch: 5| Step: 5
Training loss: 2.601297378540039
Validation loss: 2.000769163972588

Epoch: 5| Step: 6
Training loss: 2.983194351196289
Validation loss: 2.004451108235185

Epoch: 5| Step: 7
Training loss: 1.7871034145355225
Validation loss: 2.012443350207421

Epoch: 5| Step: 8
Training loss: 2.158430814743042
Validation loss: 1.98782136876096

Epoch: 5| Step: 9
Training loss: 2.8242807388305664
Validation loss: 2.0093134090464604

Epoch: 5| Step: 10
Training loss: 2.144418239593506
Validation loss: 1.9943218513201642

Epoch: 42| Step: 0
Training loss: 2.8062191009521484
Validation loss: 2.0123257547296505

Epoch: 5| Step: 1
Training loss: 2.4345641136169434
Validation loss: 1.9987046090505456

Epoch: 5| Step: 2
Training loss: 2.5088186264038086
Validation loss: 2.001576826136599

Epoch: 5| Step: 3
Training loss: 2.7864105701446533
Validation loss: 1.9879976857093073

Epoch: 5| Step: 4
Training loss: 1.9380801916122437
Validation loss: 1.990666732993177

Epoch: 5| Step: 5
Training loss: 2.1628167629241943
Validation loss: 2.0076488282090876

Epoch: 5| Step: 6
Training loss: 1.9567044973373413
Validation loss: 1.9940390817580684

Epoch: 5| Step: 7
Training loss: 2.038327693939209
Validation loss: 2.000913658449727

Epoch: 5| Step: 8
Training loss: 2.802727460861206
Validation loss: 1.9886109675130537

Epoch: 5| Step: 9
Training loss: 2.6042392253875732
Validation loss: 1.9943754365367274

Epoch: 5| Step: 10
Training loss: 2.4215776920318604
Validation loss: 1.9832569476096862

Epoch: 43| Step: 0
Training loss: 1.8454958200454712
Validation loss: 2.005344829251689

Epoch: 5| Step: 1
Training loss: 2.464407444000244
Validation loss: 2.0022883081948883

Epoch: 5| Step: 2
Training loss: 2.816922903060913
Validation loss: 1.982813222433931

Epoch: 5| Step: 3
Training loss: 2.7595419883728027
Validation loss: 1.9939009271642214

Epoch: 5| Step: 4
Training loss: 2.668640613555908
Validation loss: 1.9982390557565997

Epoch: 5| Step: 5
Training loss: 3.1752796173095703
Validation loss: 1.9823936057347122

Epoch: 5| Step: 6
Training loss: 2.3190174102783203
Validation loss: 1.9784954555573002

Epoch: 5| Step: 7
Training loss: 1.6356210708618164
Validation loss: 2.0076534837804814

Epoch: 5| Step: 8
Training loss: 2.23926043510437
Validation loss: 1.9926265926771267

Epoch: 5| Step: 9
Training loss: 2.617487668991089
Validation loss: 1.9862127098985898

Epoch: 5| Step: 10
Training loss: 1.7236028909683228
Validation loss: 1.990552395902654

Epoch: 44| Step: 0
Training loss: 2.5412025451660156
Validation loss: 1.9975005529260124

Epoch: 5| Step: 1
Training loss: 1.8795284032821655
Validation loss: 1.9985728520219044

Epoch: 5| Step: 2
Training loss: 2.5131423473358154
Validation loss: 1.9775892457654398

Epoch: 5| Step: 3
Training loss: 2.004202365875244
Validation loss: 2.0074819980129117

Epoch: 5| Step: 4
Training loss: 2.4181599617004395
Validation loss: 1.9871681300542687

Epoch: 5| Step: 5
Training loss: 1.9275119304656982
Validation loss: 1.9900206929893904

Epoch: 5| Step: 6
Training loss: 2.1781508922576904
Validation loss: 1.9843616947051017

Epoch: 5| Step: 7
Training loss: 3.1218841075897217
Validation loss: 1.9910460390070432

Epoch: 5| Step: 8
Training loss: 2.846010446548462
Validation loss: 1.9817969888769171

Epoch: 5| Step: 9
Training loss: 2.2442736625671387
Validation loss: 1.9803201178068757

Epoch: 5| Step: 10
Training loss: 2.6622307300567627
Validation loss: 1.9845105089167112

Epoch: 45| Step: 0
Training loss: 2.126025438308716
Validation loss: 2.0007238311152302

Epoch: 5| Step: 1
Training loss: 2.059142589569092
Validation loss: 1.997086819782052

Epoch: 5| Step: 2
Training loss: 2.8186590671539307
Validation loss: 1.9923097907855947

Epoch: 5| Step: 3
Training loss: 2.097879648208618
Validation loss: 1.9897348778222197

Epoch: 5| Step: 4
Training loss: 3.006408214569092
Validation loss: 1.9786513210624777

Epoch: 5| Step: 5
Training loss: 2.5967202186584473
Validation loss: 2.0009117177737656

Epoch: 5| Step: 6
Training loss: 2.496668815612793
Validation loss: 2.0005201498667398

Epoch: 5| Step: 7
Training loss: 2.229201555252075
Validation loss: 1.9951531323053504

Epoch: 5| Step: 8
Training loss: 2.2172787189483643
Validation loss: 1.9833691940512708

Epoch: 5| Step: 9
Training loss: 2.513018846511841
Validation loss: 1.975775061115142

Epoch: 5| Step: 10
Training loss: 2.232800245285034
Validation loss: 1.9895672516156269

Epoch: 46| Step: 0
Training loss: 2.4210617542266846
Validation loss: 1.9981990283535374

Epoch: 5| Step: 1
Training loss: 2.1716809272766113
Validation loss: 1.980523883655507

Epoch: 5| Step: 2
Training loss: 2.2964446544647217
Validation loss: 1.984443974751298

Epoch: 5| Step: 3
Training loss: 2.744978666305542
Validation loss: 1.9855651599104687

Epoch: 5| Step: 4
Training loss: 2.230686902999878
Validation loss: 1.9963082369937692

Epoch: 5| Step: 5
Training loss: 2.228139877319336
Validation loss: 1.9965590559026247

Epoch: 5| Step: 6
Training loss: 2.446708917617798
Validation loss: 1.9833747020331762

Epoch: 5| Step: 7
Training loss: 2.562211036682129
Validation loss: 1.988757989739859

Epoch: 5| Step: 8
Training loss: 2.258437156677246
Validation loss: 2.0004077675522014

Epoch: 5| Step: 9
Training loss: 2.270580530166626
Validation loss: 1.9966063294359433

Epoch: 5| Step: 10
Training loss: 2.572134494781494
Validation loss: 1.9977291835251676

Epoch: 47| Step: 0
Training loss: 2.4109251499176025
Validation loss: 1.9978080590565999

Epoch: 5| Step: 1
Training loss: 2.285266876220703
Validation loss: 2.004535189238928

Epoch: 5| Step: 2
Training loss: 2.0477237701416016
Validation loss: 1.9988314272255026

Epoch: 5| Step: 3
Training loss: 2.0102057456970215
Validation loss: 1.992993547070411

Epoch: 5| Step: 4
Training loss: 3.0390994548797607
Validation loss: 2.014890081139021

Epoch: 5| Step: 5
Training loss: 2.2883431911468506
Validation loss: 2.011363785753968

Epoch: 5| Step: 6
Training loss: 2.650893449783325
Validation loss: 2.0007837562150854

Epoch: 5| Step: 7
Training loss: 2.492920398712158
Validation loss: 1.9947895183358142

Epoch: 5| Step: 8
Training loss: 2.784996509552002
Validation loss: 2.006382985781598

Epoch: 5| Step: 9
Training loss: 2.264580249786377
Validation loss: 2.0072760876788887

Epoch: 5| Step: 10
Training loss: 1.8343677520751953
Validation loss: 1.9903378871179396

Epoch: 48| Step: 0
Training loss: 2.5391316413879395
Validation loss: 2.005718413219657

Epoch: 5| Step: 1
Training loss: 2.5696918964385986
Validation loss: 1.9966167865260955

Epoch: 5| Step: 2
Training loss: 2.7842249870300293
Validation loss: 1.987300956121055

Epoch: 5| Step: 3
Training loss: 1.775010347366333
Validation loss: 2.002799149482481

Epoch: 5| Step: 4
Training loss: 2.383650302886963
Validation loss: 1.9911192412017493

Epoch: 5| Step: 5
Training loss: 2.4345381259918213
Validation loss: 1.9854078715847385

Epoch: 5| Step: 6
Training loss: 2.490769147872925
Validation loss: 2.00814950466156

Epoch: 5| Step: 7
Training loss: 2.3019425868988037
Validation loss: 2.0108686480470883

Epoch: 5| Step: 8
Training loss: 1.9049336910247803
Validation loss: 1.9999839823733094

Epoch: 5| Step: 9
Training loss: 2.4488906860351562
Validation loss: 2.0138887320795367

Epoch: 5| Step: 10
Training loss: 2.490511178970337
Validation loss: 2.0099174284165904

Epoch: 49| Step: 0
Training loss: 2.165881633758545
Validation loss: 2.0034180918047504

Epoch: 5| Step: 1
Training loss: 2.1813580989837646
Validation loss: 1.9975209184872207

Epoch: 5| Step: 2
Training loss: 2.8230583667755127
Validation loss: 1.9998082217349802

Epoch: 5| Step: 3
Training loss: 2.307569980621338
Validation loss: 2.0211550330602996

Epoch: 5| Step: 4
Training loss: 2.5177676677703857
Validation loss: 1.97274834750801

Epoch: 5| Step: 5
Training loss: 2.7759461402893066
Validation loss: 1.9931557921953098

Epoch: 5| Step: 6
Training loss: 1.951216459274292
Validation loss: 1.9981657689617527

Epoch: 5| Step: 7
Training loss: 2.3815221786499023
Validation loss: 1.9959924169766006

Epoch: 5| Step: 8
Training loss: 2.4730029106140137
Validation loss: 1.985518185041284

Epoch: 5| Step: 9
Training loss: 2.1642963886260986
Validation loss: 1.9949305800981418

Epoch: 5| Step: 10
Training loss: 2.3930130004882812
Validation loss: 1.9963870202341387

Epoch: 50| Step: 0
Training loss: 2.730180025100708
Validation loss: 1.989540256479735

Epoch: 5| Step: 1
Training loss: 2.3007545471191406
Validation loss: 1.9791288055399412

Epoch: 5| Step: 2
Training loss: 2.2356865406036377
Validation loss: 2.005243552628384

Epoch: 5| Step: 3
Training loss: 2.6146864891052246
Validation loss: 1.9942523048770042

Epoch: 5| Step: 4
Training loss: 2.6538093090057373
Validation loss: 1.990925629933675

Epoch: 5| Step: 5
Training loss: 1.6757084131240845
Validation loss: 1.9806513042860134

Epoch: 5| Step: 6
Training loss: 1.7413642406463623
Validation loss: 1.9997281874379804

Epoch: 5| Step: 7
Training loss: 2.2434260845184326
Validation loss: 2.0086643824013333

Epoch: 5| Step: 8
Training loss: 2.4809296131134033
Validation loss: 1.9886304819455711

Epoch: 5| Step: 9
Training loss: 2.7695472240448
Validation loss: 1.99295590513496

Epoch: 5| Step: 10
Training loss: 2.6402909755706787
Validation loss: 1.9956087015008415

Epoch: 51| Step: 0
Training loss: 2.0031895637512207
Validation loss: 1.9875978910794823

Epoch: 5| Step: 1
Training loss: 2.644773483276367
Validation loss: 1.9977234525065268

Epoch: 5| Step: 2
Training loss: 2.0541915893554688
Validation loss: 1.988855391420344

Epoch: 5| Step: 3
Training loss: 2.112684726715088
Validation loss: 1.9896358802754393

Epoch: 5| Step: 4
Training loss: 2.4951255321502686
Validation loss: 1.9923305665293047

Epoch: 5| Step: 5
Training loss: 2.6948249340057373
Validation loss: 2.0034162434198524

Epoch: 5| Step: 6
Training loss: 2.4490389823913574
Validation loss: 1.9943855270262687

Epoch: 5| Step: 7
Training loss: 2.675062656402588
Validation loss: 1.9859392566065635

Epoch: 5| Step: 8
Training loss: 2.1264827251434326
Validation loss: 1.9768891219169862

Epoch: 5| Step: 9
Training loss: 2.096984386444092
Validation loss: 1.9902326496698524

Epoch: 5| Step: 10
Training loss: 2.789430618286133
Validation loss: 2.000569946022444

Epoch: 52| Step: 0
Training loss: 2.347787618637085
Validation loss: 1.9989471691910938

Epoch: 5| Step: 1
Training loss: 2.163766860961914
Validation loss: 2.001331795928299

Epoch: 5| Step: 2
Training loss: 2.362567901611328
Validation loss: 1.993890723874492

Epoch: 5| Step: 3
Training loss: 2.7840874195098877
Validation loss: 1.997829544928766

Epoch: 5| Step: 4
Training loss: 2.300093173980713
Validation loss: 2.0016962661538074

Epoch: 5| Step: 5
Training loss: 2.7148241996765137
Validation loss: 1.9859839588083246

Epoch: 5| Step: 6
Training loss: 2.7633984088897705
Validation loss: 2.0011216517417663

Epoch: 5| Step: 7
Training loss: 1.9144748449325562
Validation loss: 1.9905331621887863

Epoch: 5| Step: 8
Training loss: 1.8379528522491455
Validation loss: 2.005110486861198

Epoch: 5| Step: 9
Training loss: 2.1294736862182617
Validation loss: 1.9857708484895769

Epoch: 5| Step: 10
Training loss: 2.6735267639160156
Validation loss: 2.0036791627125075

Epoch: 53| Step: 0
Training loss: 2.05820631980896
Validation loss: 1.9984139165570658

Epoch: 5| Step: 1
Training loss: 2.218496799468994
Validation loss: 2.003957904795165

Epoch: 5| Step: 2
Training loss: 2.29417085647583
Validation loss: 1.990497882648181

Epoch: 5| Step: 3
Training loss: 1.6265408992767334
Validation loss: 2.011423151980164

Epoch: 5| Step: 4
Training loss: 2.61091947555542
Validation loss: 2.0067807038625083

Epoch: 5| Step: 5
Training loss: 2.208695888519287
Validation loss: 1.9963048542699506

Epoch: 5| Step: 6
Training loss: 2.783240795135498
Validation loss: 1.9902924645331599

Epoch: 5| Step: 7
Training loss: 2.7790074348449707
Validation loss: 1.9919720836865005

Epoch: 5| Step: 8
Training loss: 2.192758560180664
Validation loss: 1.976960132198949

Epoch: 5| Step: 9
Training loss: 2.621539354324341
Validation loss: 1.988559986955376

Epoch: 5| Step: 10
Training loss: 2.4974424839019775
Validation loss: 1.9947337976066015

Epoch: 54| Step: 0
Training loss: 2.3394315242767334
Validation loss: 1.993129869943024

Epoch: 5| Step: 1
Training loss: 2.571572780609131
Validation loss: 1.9944493232234832

Epoch: 5| Step: 2
Training loss: 2.2944726943969727
Validation loss: 1.9793645976692118

Epoch: 5| Step: 3
Training loss: 2.5285484790802
Validation loss: 1.985604727140037

Epoch: 5| Step: 4
Training loss: 2.7796406745910645
Validation loss: 1.986961014809147

Epoch: 5| Step: 5
Training loss: 2.5343642234802246
Validation loss: 1.9827247204319123

Epoch: 5| Step: 6
Training loss: 2.3930907249450684
Validation loss: 1.987926842063986

Epoch: 5| Step: 7
Training loss: 2.0695080757141113
Validation loss: 1.990875005722046

Epoch: 5| Step: 8
Training loss: 2.3137831687927246
Validation loss: 1.9730555152380338

Epoch: 5| Step: 9
Training loss: 1.6290340423583984
Validation loss: 1.980160128685736

Epoch: 5| Step: 10
Training loss: 2.499948501586914
Validation loss: 1.9791476649622763

Epoch: 55| Step: 0
Training loss: 2.3419344425201416
Validation loss: 1.9879228914937666

Epoch: 5| Step: 1
Training loss: 2.745455265045166
Validation loss: 1.9750672117356332

Epoch: 5| Step: 2
Training loss: 2.240708112716675
Validation loss: 1.9791762021280104

Epoch: 5| Step: 3
Training loss: 1.9890058040618896
Validation loss: 1.9730936916925574

Epoch: 5| Step: 4
Training loss: 2.5191988945007324
Validation loss: 1.9777250418099024

Epoch: 5| Step: 5
Training loss: 2.709676504135132
Validation loss: 1.963229452410052

Epoch: 5| Step: 6
Training loss: 2.2039637565612793
Validation loss: 1.9656984242059852

Epoch: 5| Step: 7
Training loss: 2.026664972305298
Validation loss: 1.9646398585329774

Epoch: 5| Step: 8
Training loss: 2.502126455307007
Validation loss: 1.9727905334964875

Epoch: 5| Step: 9
Training loss: 2.406491994857788
Validation loss: 1.9665080514005435

Epoch: 5| Step: 10
Training loss: 2.1337499618530273
Validation loss: 1.978518944914623

Epoch: 56| Step: 0
Training loss: 2.2820441722869873
Validation loss: 1.9641979458511516

Epoch: 5| Step: 1
Training loss: 2.42226505279541
Validation loss: 1.9669679800669353

Epoch: 5| Step: 2
Training loss: 1.948521375656128
Validation loss: 1.9688162726740683

Epoch: 5| Step: 3
Training loss: 2.045728921890259
Validation loss: 1.9833720025195871

Epoch: 5| Step: 4
Training loss: 3.0214741230010986
Validation loss: 1.9696464410392187

Epoch: 5| Step: 5
Training loss: 2.677340507507324
Validation loss: 1.992974922221194

Epoch: 5| Step: 6
Training loss: 2.9063162803649902
Validation loss: 1.9818043247345956

Epoch: 5| Step: 7
Training loss: 2.0954699516296387
Validation loss: 1.9691351152235461

Epoch: 5| Step: 8
Training loss: 2.015908718109131
Validation loss: 1.9573291270963606

Epoch: 5| Step: 9
Training loss: 2.5746212005615234
Validation loss: 1.9768427777033981

Epoch: 5| Step: 10
Training loss: 1.827372431755066
Validation loss: 1.9656355227193525

Epoch: 57| Step: 0
Training loss: 2.4367761611938477
Validation loss: 1.9681663949002501

Epoch: 5| Step: 1
Training loss: 2.470331907272339
Validation loss: 1.9751022477303781

Epoch: 5| Step: 2
Training loss: 2.1487765312194824
Validation loss: 1.9708860279411398

Epoch: 5| Step: 3
Training loss: 2.2600085735321045
Validation loss: 1.9820332270796581

Epoch: 5| Step: 4
Training loss: 2.0667104721069336
Validation loss: 1.9799593943421558

Epoch: 5| Step: 5
Training loss: 2.464536666870117
Validation loss: 1.9652103429199548

Epoch: 5| Step: 6
Training loss: 2.535872459411621
Validation loss: 1.980581691188197

Epoch: 5| Step: 7
Training loss: 2.7027499675750732
Validation loss: 1.9813569617527786

Epoch: 5| Step: 8
Training loss: 2.3756203651428223
Validation loss: 1.9661902894255936

Epoch: 5| Step: 9
Training loss: 2.007093906402588
Validation loss: 1.977904397954223

Epoch: 5| Step: 10
Training loss: 2.2598559856414795
Validation loss: 1.9834498820766326

Epoch: 58| Step: 0
Training loss: 2.399059772491455
Validation loss: 1.970555974591163

Epoch: 5| Step: 1
Training loss: 2.731015205383301
Validation loss: 1.9964632962339668

Epoch: 5| Step: 2
Training loss: 2.030048370361328
Validation loss: 1.9656766742788336

Epoch: 5| Step: 3
Training loss: 2.043851852416992
Validation loss: 1.996013250402225

Epoch: 5| Step: 4
Training loss: 1.6967592239379883
Validation loss: 1.9575749802333053

Epoch: 5| Step: 5
Training loss: 2.4498727321624756
Validation loss: 1.9656398706538702

Epoch: 5| Step: 6
Training loss: 2.766327381134033
Validation loss: 1.9658192037254252

Epoch: 5| Step: 7
Training loss: 2.4894206523895264
Validation loss: 1.9744115644885647

Epoch: 5| Step: 8
Training loss: 2.4433648586273193
Validation loss: 1.978686014811198

Epoch: 5| Step: 9
Training loss: 2.452576160430908
Validation loss: 1.9660532448881416

Epoch: 5| Step: 10
Training loss: 2.312361240386963
Validation loss: 1.955657551365514

Epoch: 59| Step: 0
Training loss: 2.0736708641052246
Validation loss: 1.9694755231180499

Epoch: 5| Step: 1
Training loss: 2.328974723815918
Validation loss: 1.9698320947667605

Epoch: 5| Step: 2
Training loss: 1.9439613819122314
Validation loss: 1.9760389379275742

Epoch: 5| Step: 3
Training loss: 2.635781764984131
Validation loss: 1.9745416410507695

Epoch: 5| Step: 4
Training loss: 2.3183770179748535
Validation loss: 1.978890852261615

Epoch: 5| Step: 5
Training loss: 2.7397613525390625
Validation loss: 1.9669244507307648

Epoch: 5| Step: 6
Training loss: 2.2045092582702637
Validation loss: 1.9693028183393582

Epoch: 5| Step: 7
Training loss: 2.5959715843200684
Validation loss: 1.9702755789602957

Epoch: 5| Step: 8
Training loss: 2.2391135692596436
Validation loss: 1.9672161353531705

Epoch: 5| Step: 9
Training loss: 2.1410207748413086
Validation loss: 1.9597883557760587

Epoch: 5| Step: 10
Training loss: 2.573559522628784
Validation loss: 1.9804669759606803

Epoch: 60| Step: 0
Training loss: 2.1321499347686768
Validation loss: 1.9797187543684436

Epoch: 5| Step: 1
Training loss: 1.7202163934707642
Validation loss: 1.9635168429343932

Epoch: 5| Step: 2
Training loss: 2.6058361530303955
Validation loss: 1.9667372267733338

Epoch: 5| Step: 3
Training loss: 2.644366979598999
Validation loss: 1.967876349726031

Epoch: 5| Step: 4
Training loss: 2.117680788040161
Validation loss: 1.9659000404419438

Epoch: 5| Step: 5
Training loss: 2.0074310302734375
Validation loss: 1.966973147084636

Epoch: 5| Step: 6
Training loss: 2.3774843215942383
Validation loss: 1.9763348346115441

Epoch: 5| Step: 7
Training loss: 2.5309722423553467
Validation loss: 1.98294775332174

Epoch: 5| Step: 8
Training loss: 2.484536647796631
Validation loss: 1.9922221591395717

Epoch: 5| Step: 9
Training loss: 2.20458984375
Validation loss: 1.9841163337871592

Epoch: 5| Step: 10
Training loss: 2.620718240737915
Validation loss: 1.974258284414968

Epoch: 61| Step: 0
Training loss: 2.6106340885162354
Validation loss: 1.980261864200715

Epoch: 5| Step: 1
Training loss: 2.4218292236328125
Validation loss: 1.9880163682404386

Epoch: 5| Step: 2
Training loss: 2.247753143310547
Validation loss: 1.9777877510234874

Epoch: 5| Step: 3
Training loss: 2.045456647872925
Validation loss: 1.9930106106624808

Epoch: 5| Step: 4
Training loss: 2.2146172523498535
Validation loss: 1.958456911066527

Epoch: 5| Step: 5
Training loss: 2.3726308345794678
Validation loss: 1.9800670428942608

Epoch: 5| Step: 6
Training loss: 2.9041495323181152
Validation loss: 1.9774520781732374

Epoch: 5| Step: 7
Training loss: 2.3757920265197754
Validation loss: 1.9711791956296532

Epoch: 5| Step: 8
Training loss: 2.1608383655548096
Validation loss: 1.9755059493485319

Epoch: 5| Step: 9
Training loss: 1.9653270244598389
Validation loss: 1.9711679027926536

Epoch: 5| Step: 10
Training loss: 2.3886451721191406
Validation loss: 1.969163446016209

Epoch: 62| Step: 0
Training loss: 2.5273406505584717
Validation loss: 1.9743139359258837

Epoch: 5| Step: 1
Training loss: 2.085045576095581
Validation loss: 1.961804997536444

Epoch: 5| Step: 2
Training loss: 2.614380359649658
Validation loss: 1.975472859157029

Epoch: 5| Step: 3
Training loss: 1.9952723979949951
Validation loss: 1.968062957127889

Epoch: 5| Step: 4
Training loss: 2.684953212738037
Validation loss: 1.9821817426271335

Epoch: 5| Step: 5
Training loss: 2.4128594398498535
Validation loss: 1.9755232923774309

Epoch: 5| Step: 6
Training loss: 1.7819843292236328
Validation loss: 1.972596565882365

Epoch: 5| Step: 7
Training loss: 1.95011305809021
Validation loss: 1.9720535265502108

Epoch: 5| Step: 8
Training loss: 2.420868396759033
Validation loss: 1.9658024464884112

Epoch: 5| Step: 9
Training loss: 2.5578579902648926
Validation loss: 1.979585245091428

Epoch: 5| Step: 10
Training loss: 2.390467405319214
Validation loss: 1.9791519539330595

Epoch: 63| Step: 0
Training loss: 2.283973455429077
Validation loss: 1.954714426430323

Epoch: 5| Step: 1
Training loss: 2.2620460987091064
Validation loss: 1.9773152835907475

Epoch: 5| Step: 2
Training loss: 2.16703724861145
Validation loss: 1.9768400615261448

Epoch: 5| Step: 3
Training loss: 1.946150541305542
Validation loss: 1.965931761649347

Epoch: 5| Step: 4
Training loss: 2.1117594242095947
Validation loss: 1.9589062531789143

Epoch: 5| Step: 5
Training loss: 2.4478068351745605
Validation loss: 1.9649339170866116

Epoch: 5| Step: 6
Training loss: 2.3998985290527344
Validation loss: 1.959724607006196

Epoch: 5| Step: 7
Training loss: 2.426893711090088
Validation loss: 1.9738160487144225

Epoch: 5| Step: 8
Training loss: 2.6397552490234375
Validation loss: 1.9712994406300206

Epoch: 5| Step: 9
Training loss: 2.58735990524292
Validation loss: 1.9700329137104813

Epoch: 5| Step: 10
Training loss: 2.1297454833984375
Validation loss: 1.9708970182685441

Epoch: 64| Step: 0
Training loss: 2.6818790435791016
Validation loss: 1.9727654995456818

Epoch: 5| Step: 1
Training loss: 1.6640453338623047
Validation loss: 1.9624057175010763

Epoch: 5| Step: 2
Training loss: 2.648954391479492
Validation loss: 1.9742002359000586

Epoch: 5| Step: 3
Training loss: 1.7907764911651611
Validation loss: 1.9504939586885515

Epoch: 5| Step: 4
Training loss: 2.7238078117370605
Validation loss: 1.9614574050390592

Epoch: 5| Step: 5
Training loss: 2.2364134788513184
Validation loss: 1.96327684515266

Epoch: 5| Step: 6
Training loss: 2.1059603691101074
Validation loss: 1.966390158540459

Epoch: 5| Step: 7
Training loss: 2.8157293796539307
Validation loss: 1.9770505889769523

Epoch: 5| Step: 8
Training loss: 2.2512457370758057
Validation loss: 1.9941470007742605

Epoch: 5| Step: 9
Training loss: 2.6918368339538574
Validation loss: 1.9575398583565988

Epoch: 5| Step: 10
Training loss: 1.6614642143249512
Validation loss: 1.9690419217591644

Epoch: 65| Step: 0
Training loss: 2.336003065109253
Validation loss: 1.9726527980578843

Epoch: 5| Step: 1
Training loss: 1.6481893062591553
Validation loss: 1.9677609346246208

Epoch: 5| Step: 2
Training loss: 2.839329242706299
Validation loss: 1.9846727963416808

Epoch: 5| Step: 3
Training loss: 2.3432018756866455
Validation loss: 1.9722629131809357

Epoch: 5| Step: 4
Training loss: 2.7882602214813232
Validation loss: 1.9680114458965998

Epoch: 5| Step: 5
Training loss: 1.8583948612213135
Validation loss: 1.9738631863747873

Epoch: 5| Step: 6
Training loss: 2.1301610469818115
Validation loss: 1.9850008205700946

Epoch: 5| Step: 7
Training loss: 2.553326368331909
Validation loss: 1.9860880733818136

Epoch: 5| Step: 8
Training loss: 2.5778913497924805
Validation loss: 1.9643885217687136

Epoch: 5| Step: 9
Training loss: 2.2325592041015625
Validation loss: 1.989923072117631

Epoch: 5| Step: 10
Training loss: 1.7933883666992188
Validation loss: 1.9697298042235836

Epoch: 66| Step: 0
Training loss: 2.8243472576141357
Validation loss: 1.974382846586166

Epoch: 5| Step: 1
Training loss: 2.050123691558838
Validation loss: 1.9698368041746077

Epoch: 5| Step: 2
Training loss: 2.2104480266571045
Validation loss: 1.9573013449227938

Epoch: 5| Step: 3
Training loss: 2.494990825653076
Validation loss: 1.9814316803409207

Epoch: 5| Step: 4
Training loss: 2.3246212005615234
Validation loss: 1.972173370340819

Epoch: 5| Step: 5
Training loss: 2.1466267108917236
Validation loss: 1.9732898922376736

Epoch: 5| Step: 6
Training loss: 2.175692558288574
Validation loss: 1.967388440203923

Epoch: 5| Step: 7
Training loss: 2.4194910526275635
Validation loss: 1.957137853868546

Epoch: 5| Step: 8
Training loss: 2.0483250617980957
Validation loss: 1.9513651965766825

Epoch: 5| Step: 9
Training loss: 2.1490001678466797
Validation loss: 1.9808090348397531

Epoch: 5| Step: 10
Training loss: 2.5831289291381836
Validation loss: 1.9708105492335495

Epoch: 67| Step: 0
Training loss: 2.6431891918182373
Validation loss: 1.9587144403047458

Epoch: 5| Step: 1
Training loss: 2.0236716270446777
Validation loss: 1.9672858022874402

Epoch: 5| Step: 2
Training loss: 2.309934139251709
Validation loss: 1.9556178738993983

Epoch: 5| Step: 3
Training loss: 1.8251796960830688
Validation loss: 1.9532347443283244

Epoch: 5| Step: 4
Training loss: 2.0020480155944824
Validation loss: 1.947970385192543

Epoch: 5| Step: 5
Training loss: 2.660998582839966
Validation loss: 1.9524216780098536

Epoch: 5| Step: 6
Training loss: 2.356722593307495
Validation loss: 1.9615606018292007

Epoch: 5| Step: 7
Training loss: 1.8845630884170532
Validation loss: 1.9639503109839656

Epoch: 5| Step: 8
Training loss: 2.5271191596984863
Validation loss: 1.926011735393155

Epoch: 5| Step: 9
Training loss: 2.9499220848083496
Validation loss: 1.9559378957235685

Epoch: 5| Step: 10
Training loss: 2.2234792709350586
Validation loss: 1.9435809966056579

Epoch: 68| Step: 0
Training loss: 1.8625084161758423
Validation loss: 1.9603690870346562

Epoch: 5| Step: 1
Training loss: 2.602891683578491
Validation loss: 1.964176857343284

Epoch: 5| Step: 2
Training loss: 2.248030185699463
Validation loss: 1.9634069294057868

Epoch: 5| Step: 3
Training loss: 2.728184461593628
Validation loss: 1.9714412407208515

Epoch: 5| Step: 4
Training loss: 2.1435837745666504
Validation loss: 1.9722812034750496

Epoch: 5| Step: 5
Training loss: 2.2715823650360107
Validation loss: 1.9589652604954217

Epoch: 5| Step: 6
Training loss: 2.446215867996216
Validation loss: 1.9749445505039667

Epoch: 5| Step: 7
Training loss: 1.905308485031128
Validation loss: 1.9316680136547293

Epoch: 5| Step: 8
Training loss: 2.2171761989593506
Validation loss: 1.9566013813018799

Epoch: 5| Step: 9
Training loss: 2.1989293098449707
Validation loss: 1.9636624910498177

Epoch: 5| Step: 10
Training loss: 2.4214768409729004
Validation loss: 1.9666373063159246

Epoch: 69| Step: 0
Training loss: 2.665976047515869
Validation loss: 1.9529775188815208

Epoch: 5| Step: 1
Training loss: 1.752856969833374
Validation loss: 1.9630375626266643

Epoch: 5| Step: 2
Training loss: 2.5324597358703613
Validation loss: 1.97037971532473

Epoch: 5| Step: 3
Training loss: 2.572744846343994
Validation loss: 1.9374040275491693

Epoch: 5| Step: 4
Training loss: 2.2826480865478516
Validation loss: 1.969723311803674

Epoch: 5| Step: 5
Training loss: 2.6268298625946045
Validation loss: 1.9710272960765387

Epoch: 5| Step: 6
Training loss: 2.392601728439331
Validation loss: 1.97394763013368

Epoch: 5| Step: 7
Training loss: 2.3924312591552734
Validation loss: 1.95716812533717

Epoch: 5| Step: 8
Training loss: 1.6527868509292603
Validation loss: 1.94564486575383

Epoch: 5| Step: 9
Training loss: 1.7860244512557983
Validation loss: 1.9678147813325286

Epoch: 5| Step: 10
Training loss: 2.622328758239746
Validation loss: 1.9758225551215551

Epoch: 70| Step: 0
Training loss: 2.4635515213012695
Validation loss: 1.978180294395775

Epoch: 5| Step: 1
Training loss: 1.983917236328125
Validation loss: 1.9674578187286214

Epoch: 5| Step: 2
Training loss: 2.8240864276885986
Validation loss: 1.9645884703564387

Epoch: 5| Step: 3
Training loss: 2.523820161819458
Validation loss: 1.9671615964622908

Epoch: 5| Step: 4
Training loss: 3.243640899658203
Validation loss: 1.9701003669410624

Epoch: 5| Step: 5
Training loss: 1.8318437337875366
Validation loss: 1.9737841672794794

Epoch: 5| Step: 6
Training loss: 1.9742679595947266
Validation loss: 1.9752198367990472

Epoch: 5| Step: 7
Training loss: 2.1261701583862305
Validation loss: 1.9483002847240818

Epoch: 5| Step: 8
Training loss: 1.8232322931289673
Validation loss: 1.9514200995045323

Epoch: 5| Step: 9
Training loss: 1.2938339710235596
Validation loss: 1.937046657326401

Epoch: 5| Step: 10
Training loss: 2.9649105072021484
Validation loss: 1.97594299111315

Epoch: 71| Step: 0
Training loss: 2.1680030822753906
Validation loss: 1.9761701706917054

Epoch: 5| Step: 1
Training loss: 1.9289573431015015
Validation loss: 1.984873821658473

Epoch: 5| Step: 2
Training loss: 2.2053232192993164
Validation loss: 1.9711511109464912

Epoch: 5| Step: 3
Training loss: 2.6569344997406006
Validation loss: 1.963374650606545

Epoch: 5| Step: 4
Training loss: 1.9339210987091064
Validation loss: 1.9650287205173123

Epoch: 5| Step: 5
Training loss: 2.8930983543395996
Validation loss: 1.9758116352942683

Epoch: 5| Step: 6
Training loss: 2.5060834884643555
Validation loss: 1.9774864758214643

Epoch: 5| Step: 7
Training loss: 2.5384292602539062
Validation loss: 1.9628798807820966

Epoch: 5| Step: 8
Training loss: 2.2773497104644775
Validation loss: 1.9722020933704991

Epoch: 5| Step: 9
Training loss: 1.8565196990966797
Validation loss: 1.9647848631746025

Epoch: 5| Step: 10
Training loss: 2.0101356506347656
Validation loss: 1.9599196628857685

Epoch: 72| Step: 0
Training loss: 2.4928081035614014
Validation loss: 1.964700255342709

Epoch: 5| Step: 1
Training loss: 2.1169350147247314
Validation loss: 1.9537847490720852

Epoch: 5| Step: 2
Training loss: 2.2266640663146973
Validation loss: 1.9456137047019055

Epoch: 5| Step: 3
Training loss: 2.365607500076294
Validation loss: 1.9737630492897444

Epoch: 5| Step: 4
Training loss: 2.428417921066284
Validation loss: 1.958379973647415

Epoch: 5| Step: 5
Training loss: 2.571502685546875
Validation loss: 1.966363904296711

Epoch: 5| Step: 6
Training loss: 2.4663567543029785
Validation loss: 1.9671621950723792

Epoch: 5| Step: 7
Training loss: 1.7570087909698486
Validation loss: 1.9719597165302565

Epoch: 5| Step: 8
Training loss: 1.9013869762420654
Validation loss: 1.9549184383884552

Epoch: 5| Step: 9
Training loss: 2.490565061569214
Validation loss: 1.9531194702271493

Epoch: 5| Step: 10
Training loss: 2.1112208366394043
Validation loss: 1.938433644592121

Epoch: 73| Step: 0
Training loss: 2.473548412322998
Validation loss: 1.949690116349087

Epoch: 5| Step: 1
Training loss: 2.9558708667755127
Validation loss: 1.9823664593440231

Epoch: 5| Step: 2
Training loss: 2.1166293621063232
Validation loss: 1.9817785857826151

Epoch: 5| Step: 3
Training loss: 1.903664231300354
Validation loss: 1.9602497572539954

Epoch: 5| Step: 4
Training loss: 2.5222601890563965
Validation loss: 1.9342773704118625

Epoch: 5| Step: 5
Training loss: 2.0157103538513184
Validation loss: 1.9725916026740946

Epoch: 5| Step: 6
Training loss: 1.9217262268066406
Validation loss: 1.9765008828973258

Epoch: 5| Step: 7
Training loss: 2.086137294769287
Validation loss: 1.9439894627499323

Epoch: 5| Step: 8
Training loss: 1.9900867938995361
Validation loss: 1.955067680728051

Epoch: 5| Step: 9
Training loss: 2.5867919921875
Validation loss: 1.958938531978156

Epoch: 5| Step: 10
Training loss: 2.177354097366333
Validation loss: 1.9689595801855928

Epoch: 74| Step: 0
Training loss: 1.8425508737564087
Validation loss: 1.9435654096705939

Epoch: 5| Step: 1
Training loss: 2.3774001598358154
Validation loss: 1.9621757281723844

Epoch: 5| Step: 2
Training loss: 2.083775520324707
Validation loss: 1.953053003998213

Epoch: 5| Step: 3
Training loss: 2.015009641647339
Validation loss: 1.9591643592362762

Epoch: 5| Step: 4
Training loss: 1.9379743337631226
Validation loss: 1.9533870361184562

Epoch: 5| Step: 5
Training loss: 2.2434513568878174
Validation loss: 1.945864829965817

Epoch: 5| Step: 6
Training loss: 2.2856674194335938
Validation loss: 1.9634369739922144

Epoch: 5| Step: 7
Training loss: 2.7265305519104004
Validation loss: 1.9499881254729403

Epoch: 5| Step: 8
Training loss: 2.0561020374298096
Validation loss: 1.956998941718891

Epoch: 5| Step: 9
Training loss: 2.26765775680542
Validation loss: 1.931649310614473

Epoch: 5| Step: 10
Training loss: 3.0515918731689453
Validation loss: 1.9391424681550713

Epoch: 75| Step: 0
Training loss: 2.356407403945923
Validation loss: 1.9376432100931804

Epoch: 5| Step: 1
Training loss: 2.309093952178955
Validation loss: 1.935345870192333

Epoch: 5| Step: 2
Training loss: 2.223905086517334
Validation loss: 1.9534887549697713

Epoch: 5| Step: 3
Training loss: 2.39810848236084
Validation loss: 1.9394551169487737

Epoch: 5| Step: 4
Training loss: 2.5728588104248047
Validation loss: 1.9472310402060067

Epoch: 5| Step: 5
Training loss: 1.8737338781356812
Validation loss: 1.9349397715701853

Epoch: 5| Step: 6
Training loss: 2.439877986907959
Validation loss: 1.980659939909494

Epoch: 5| Step: 7
Training loss: 1.4293133020401
Validation loss: 1.9753670077170096

Epoch: 5| Step: 8
Training loss: 2.6432600021362305
Validation loss: 1.94478561288567

Epoch: 5| Step: 9
Training loss: 2.5289437770843506
Validation loss: 1.9634009561231058

Epoch: 5| Step: 10
Training loss: 1.847849726676941
Validation loss: 1.977102219417531

Epoch: 76| Step: 0
Training loss: 2.2757925987243652
Validation loss: 1.9307703177134197

Epoch: 5| Step: 1
Training loss: 2.6423795223236084
Validation loss: 1.964202409149498

Epoch: 5| Step: 2
Training loss: 1.7116470336914062
Validation loss: 1.9438088388853176

Epoch: 5| Step: 3
Training loss: 2.095262050628662
Validation loss: 1.9501685327099216

Epoch: 5| Step: 4
Training loss: 2.235635995864868
Validation loss: 1.9673162967927995

Epoch: 5| Step: 5
Training loss: 2.2145514488220215
Validation loss: 1.9715807373805712

Epoch: 5| Step: 6
Training loss: 2.2613911628723145
Validation loss: 1.9622303260269987

Epoch: 5| Step: 7
Training loss: 2.491731643676758
Validation loss: 1.942797104517619

Epoch: 5| Step: 8
Training loss: 2.146059036254883
Validation loss: 1.9437315617838213

Epoch: 5| Step: 9
Training loss: 2.1268413066864014
Validation loss: 1.9607107434221493

Epoch: 5| Step: 10
Training loss: 2.4379374980926514
Validation loss: 1.9360852818335257

Epoch: 77| Step: 0
Training loss: 2.6245124340057373
Validation loss: 1.949127028065343

Epoch: 5| Step: 1
Training loss: 2.5923495292663574
Validation loss: 1.9511363275589482

Epoch: 5| Step: 2
Training loss: 2.130335569381714
Validation loss: 1.9296673369664017

Epoch: 5| Step: 3
Training loss: 1.5952427387237549
Validation loss: 1.942790267288044

Epoch: 5| Step: 4
Training loss: 1.6323158740997314
Validation loss: 1.948711492682016

Epoch: 5| Step: 5
Training loss: 2.0158424377441406
Validation loss: 1.9282379586209533

Epoch: 5| Step: 6
Training loss: 2.3624179363250732
Validation loss: 1.9247078716114003

Epoch: 5| Step: 7
Training loss: 2.4003236293792725
Validation loss: 1.9097353386622604

Epoch: 5| Step: 8
Training loss: 2.4355549812316895
Validation loss: 1.9221272237839238

Epoch: 5| Step: 9
Training loss: 2.268472194671631
Validation loss: 1.9232733800847044

Epoch: 5| Step: 10
Training loss: 2.5752878189086914
Validation loss: 1.9291628240257181

Epoch: 78| Step: 0
Training loss: 2.0664379596710205
Validation loss: 1.90566046391764

Epoch: 5| Step: 1
Training loss: 2.560157299041748
Validation loss: 1.9351380384096535

Epoch: 5| Step: 2
Training loss: 2.431037187576294
Validation loss: 1.9284176749567832

Epoch: 5| Step: 3
Training loss: 2.3877081871032715
Validation loss: 1.9402225402093702

Epoch: 5| Step: 4
Training loss: 2.9751219749450684
Validation loss: 1.9310530360027025

Epoch: 5| Step: 5
Training loss: 1.8461707830429077
Validation loss: 1.925199443294156

Epoch: 5| Step: 6
Training loss: 1.3394261598587036
Validation loss: 1.9410706438044065

Epoch: 5| Step: 7
Training loss: 2.3646397590637207
Validation loss: 1.9348458551591443

Epoch: 5| Step: 8
Training loss: 2.719714641571045
Validation loss: 1.9595560566071542

Epoch: 5| Step: 9
Training loss: 1.7109534740447998
Validation loss: 1.9488989858217136

Epoch: 5| Step: 10
Training loss: 2.2340939044952393
Validation loss: 1.9478261906613585

Epoch: 79| Step: 0
Training loss: 2.8855462074279785
Validation loss: 1.9320065667552333

Epoch: 5| Step: 1
Training loss: 2.7416751384735107
Validation loss: 1.962160715492823

Epoch: 5| Step: 2
Training loss: 2.5384507179260254
Validation loss: 1.9257427095085062

Epoch: 5| Step: 3
Training loss: 2.248648166656494
Validation loss: 1.9318886392860002

Epoch: 5| Step: 4
Training loss: 2.1675376892089844
Validation loss: 1.952729263613301

Epoch: 5| Step: 5
Training loss: 1.6047264337539673
Validation loss: 1.9276611548598095

Epoch: 5| Step: 6
Training loss: 1.363502025604248
Validation loss: 1.9408628530399774

Epoch: 5| Step: 7
Training loss: 2.9678685665130615
Validation loss: 1.9288922779021724

Epoch: 5| Step: 8
Training loss: 2.470515489578247
Validation loss: 1.9563921049077024

Epoch: 5| Step: 9
Training loss: 1.412443995475769
Validation loss: 1.9498637132747199

Epoch: 5| Step: 10
Training loss: 1.9705350399017334
Validation loss: 1.9190878509193339

Epoch: 80| Step: 0
Training loss: 2.284053325653076
Validation loss: 1.937830312277681

Epoch: 5| Step: 1
Training loss: 2.377114772796631
Validation loss: 1.921875141000235

Epoch: 5| Step: 2
Training loss: 2.8946990966796875
Validation loss: 1.921817846195672

Epoch: 5| Step: 3
Training loss: 2.520282030105591
Validation loss: 1.9465087229205715

Epoch: 5| Step: 4
Training loss: 2.2129364013671875
Validation loss: 1.9146944284439087

Epoch: 5| Step: 5
Training loss: 1.99314284324646
Validation loss: 1.962330343902752

Epoch: 5| Step: 6
Training loss: 1.8672107458114624
Validation loss: 1.9447560438545801

Epoch: 5| Step: 7
Training loss: 2.52607798576355
Validation loss: 1.945584665062607

Epoch: 5| Step: 8
Training loss: 2.132530689239502
Validation loss: 1.952738090228009

Epoch: 5| Step: 9
Training loss: 1.8257068395614624
Validation loss: 1.959504327466411

Epoch: 5| Step: 10
Training loss: 1.7015345096588135
Validation loss: 1.949147116753363

Epoch: 81| Step: 0
Training loss: 1.9642693996429443
Validation loss: 1.9611755289057249

Epoch: 5| Step: 1
Training loss: 2.7011146545410156
Validation loss: 1.9615157740090483

Epoch: 5| Step: 2
Training loss: 1.9572250843048096
Validation loss: 1.9455187013072353

Epoch: 5| Step: 3
Training loss: 2.34096622467041
Validation loss: 1.9576347540783625

Epoch: 5| Step: 4
Training loss: 2.587462902069092
Validation loss: 1.9718637517703477

Epoch: 5| Step: 5
Training loss: 3.0720160007476807
Validation loss: 1.9543659751133253

Epoch: 5| Step: 6
Training loss: 2.1707561016082764
Validation loss: 1.945122636774535

Epoch: 5| Step: 7
Training loss: 1.8544044494628906
Validation loss: 1.953682553383612

Epoch: 5| Step: 8
Training loss: 2.0115976333618164
Validation loss: 1.9512913867991457

Epoch: 5| Step: 9
Training loss: 1.7210943698883057
Validation loss: 1.9550386654433383

Epoch: 5| Step: 10
Training loss: 2.0695884227752686
Validation loss: 1.9467369074462562

Epoch: 82| Step: 0
Training loss: 2.534156084060669
Validation loss: 1.9567153825554797

Epoch: 5| Step: 1
Training loss: 1.8597545623779297
Validation loss: 1.9453138548840758

Epoch: 5| Step: 2
Training loss: 1.573248028755188
Validation loss: 1.95589368830445

Epoch: 5| Step: 3
Training loss: 2.538628101348877
Validation loss: 1.9411204168873448

Epoch: 5| Step: 4
Training loss: 1.8875001668930054
Validation loss: 1.9415465362610356

Epoch: 5| Step: 5
Training loss: 2.0565624237060547
Validation loss: 1.958268118161027

Epoch: 5| Step: 6
Training loss: 2.220778465270996
Validation loss: 1.945850015968405

Epoch: 5| Step: 7
Training loss: 1.9957759380340576
Validation loss: 1.9386549213881135

Epoch: 5| Step: 8
Training loss: 2.9971792697906494
Validation loss: 1.9552405572706653

Epoch: 5| Step: 9
Training loss: 2.4873340129852295
Validation loss: 1.9471494600337038

Epoch: 5| Step: 10
Training loss: 2.1311564445495605
Validation loss: 1.9363086915785266

Epoch: 83| Step: 0
Training loss: 2.837003231048584
Validation loss: 1.9205571656586022

Epoch: 5| Step: 1
Training loss: 2.305989980697632
Validation loss: 1.9284127091848722

Epoch: 5| Step: 2
Training loss: 1.957655668258667
Validation loss: 1.952166356066222

Epoch: 5| Step: 3
Training loss: 2.2426912784576416
Validation loss: 1.935603121275543

Epoch: 5| Step: 4
Training loss: 2.4913723468780518
Validation loss: 1.9170898660536735

Epoch: 5| Step: 5
Training loss: 1.7350971698760986
Validation loss: 1.9084249299059632

Epoch: 5| Step: 6
Training loss: 2.744051933288574
Validation loss: 1.9229619195384364

Epoch: 5| Step: 7
Training loss: 2.1769816875457764
Validation loss: 1.9392486644047562

Epoch: 5| Step: 8
Training loss: 2.1638259887695312
Validation loss: 1.949050352137576

Epoch: 5| Step: 9
Training loss: 1.8887627124786377
Validation loss: 1.9253580249765867

Epoch: 5| Step: 10
Training loss: 1.7130924463272095
Validation loss: 1.9222233936350832

Epoch: 84| Step: 0
Training loss: 2.667180061340332
Validation loss: 1.9348325126914567

Epoch: 5| Step: 1
Training loss: 2.184121608734131
Validation loss: 1.9327077288781442

Epoch: 5| Step: 2
Training loss: 2.3486506938934326
Validation loss: 1.9383009287618822

Epoch: 5| Step: 3
Training loss: 2.705733060836792
Validation loss: 1.9062182249561432

Epoch: 5| Step: 4
Training loss: 1.395880103111267
Validation loss: 1.9159579456493419

Epoch: 5| Step: 5
Training loss: 2.4376158714294434
Validation loss: 1.941618820672394

Epoch: 5| Step: 6
Training loss: 1.468689203262329
Validation loss: 1.9127208097006685

Epoch: 5| Step: 7
Training loss: 1.5377390384674072
Validation loss: 1.9058119712337371

Epoch: 5| Step: 8
Training loss: 2.5433874130249023
Validation loss: 1.9266476336345877

Epoch: 5| Step: 9
Training loss: 2.630441665649414
Validation loss: 1.9114458343034149

Epoch: 5| Step: 10
Training loss: 2.349552631378174
Validation loss: 1.930714694402551

Epoch: 85| Step: 0
Training loss: 2.9334499835968018
Validation loss: 1.9219714082697386

Epoch: 5| Step: 1
Training loss: 2.0989186763763428
Validation loss: 1.9064268745401853

Epoch: 5| Step: 2
Training loss: 2.1182198524475098
Validation loss: 1.937966158313136

Epoch: 5| Step: 3
Training loss: 2.086092472076416
Validation loss: 1.9255617023796163

Epoch: 5| Step: 4
Training loss: 1.6352927684783936
Validation loss: 1.9250373942877657

Epoch: 5| Step: 5
Training loss: 2.10807466506958
Validation loss: 1.925050857246563

Epoch: 5| Step: 6
Training loss: 2.442239761352539
Validation loss: 1.9297451152596423

Epoch: 5| Step: 7
Training loss: 2.1049087047576904
Validation loss: 1.9222365425479027

Epoch: 5| Step: 8
Training loss: 2.596912384033203
Validation loss: 1.919056378385072

Epoch: 5| Step: 9
Training loss: 2.039520740509033
Validation loss: 1.957674619972065

Epoch: 5| Step: 10
Training loss: 2.0649633407592773
Validation loss: 1.9410858385024532

Epoch: 86| Step: 0
Training loss: 2.4140372276306152
Validation loss: 1.9470818068391533

Epoch: 5| Step: 1
Training loss: 2.439941883087158
Validation loss: 1.9415485641007781

Epoch: 5| Step: 2
Training loss: 1.8762344121932983
Validation loss: 1.9537387381317795

Epoch: 5| Step: 3
Training loss: 2.275351047515869
Validation loss: 1.938997225094867

Epoch: 5| Step: 4
Training loss: 2.3595173358917236
Validation loss: 1.9501872421592794

Epoch: 5| Step: 5
Training loss: 2.2306087017059326
Validation loss: 1.9753867067316526

Epoch: 5| Step: 6
Training loss: 2.63666033744812
Validation loss: 1.9512330280837191

Epoch: 5| Step: 7
Training loss: 2.347747325897217
Validation loss: 1.9403868490649807

Epoch: 5| Step: 8
Training loss: 1.9258229732513428
Validation loss: 1.9638722481266144

Epoch: 5| Step: 9
Training loss: 2.144235849380493
Validation loss: 1.9521685864335747

Epoch: 5| Step: 10
Training loss: 1.3747798204421997
Validation loss: 1.9675847535492272

Epoch: 87| Step: 0
Training loss: 2.1638665199279785
Validation loss: 1.9744637563664427

Epoch: 5| Step: 1
Training loss: 2.300053119659424
Validation loss: 1.9539727575035506

Epoch: 5| Step: 2
Training loss: 1.8949050903320312
Validation loss: 1.9560805264339651

Epoch: 5| Step: 3
Training loss: 2.2244343757629395
Validation loss: 1.9461384678399691

Epoch: 5| Step: 4
Training loss: 2.372271776199341
Validation loss: 1.962932373887749

Epoch: 5| Step: 5
Training loss: 1.9156932830810547
Validation loss: 1.9409427155730545

Epoch: 5| Step: 6
Training loss: 2.4013774394989014
Validation loss: 1.9536810767266057

Epoch: 5| Step: 7
Training loss: 1.651961088180542
Validation loss: 1.9676195934254637

Epoch: 5| Step: 8
Training loss: 2.290728807449341
Validation loss: 1.9671964363385273

Epoch: 5| Step: 9
Training loss: 2.456808090209961
Validation loss: 1.94780380751497

Epoch: 5| Step: 10
Training loss: 2.3029654026031494
Validation loss: 1.9289072534089446

Epoch: 88| Step: 0
Training loss: 2.131300449371338
Validation loss: 1.9510876453051003

Epoch: 5| Step: 1
Training loss: 2.0842368602752686
Validation loss: 1.9478409879951066

Epoch: 5| Step: 2
Training loss: 2.8061320781707764
Validation loss: 1.9418136355697468

Epoch: 5| Step: 3
Training loss: 2.07114839553833
Validation loss: 1.9675609745005125

Epoch: 5| Step: 4
Training loss: 2.23828387260437
Validation loss: 1.9250059281626055

Epoch: 5| Step: 5
Training loss: 1.9862123727798462
Validation loss: 1.9398242799184655

Epoch: 5| Step: 6
Training loss: 2.3559787273406982
Validation loss: 1.9578425602246357

Epoch: 5| Step: 7
Training loss: 2.0597805976867676
Validation loss: 1.9305505996109338

Epoch: 5| Step: 8
Training loss: 1.7375917434692383
Validation loss: 1.9294810423287012

Epoch: 5| Step: 9
Training loss: 2.478259325027466
Validation loss: 1.9400483549282115

Epoch: 5| Step: 10
Training loss: 2.1063902378082275
Validation loss: 1.9372753584256737

Epoch: 89| Step: 0
Training loss: 2.7250404357910156
Validation loss: 1.944054384385386

Epoch: 5| Step: 1
Training loss: 1.9470428228378296
Validation loss: 1.9517557928639073

Epoch: 5| Step: 2
Training loss: 2.1567435264587402
Validation loss: 1.9404851903197586

Epoch: 5| Step: 3
Training loss: 1.9607436656951904
Validation loss: 1.9434787650262155

Epoch: 5| Step: 4
Training loss: 2.4170212745666504
Validation loss: 1.9602915292145104

Epoch: 5| Step: 5
Training loss: 1.9676538705825806
Validation loss: 1.9419931852689354

Epoch: 5| Step: 6
Training loss: 1.9758737087249756
Validation loss: 1.9648366435881583

Epoch: 5| Step: 7
Training loss: 2.4624600410461426
Validation loss: 1.9291286135232577

Epoch: 5| Step: 8
Training loss: 2.7612662315368652
Validation loss: 1.9456103642781575

Epoch: 5| Step: 9
Training loss: 1.5145174264907837
Validation loss: 1.9273676064706617

Epoch: 5| Step: 10
Training loss: 2.072554111480713
Validation loss: 1.9250867494972803

Epoch: 90| Step: 0
Training loss: 2.772862195968628
Validation loss: 1.919997617762576

Epoch: 5| Step: 1
Training loss: 2.166290283203125
Validation loss: 1.95549383342907

Epoch: 5| Step: 2
Training loss: 2.3349204063415527
Validation loss: 1.9338219293984034

Epoch: 5| Step: 3
Training loss: 1.7940952777862549
Validation loss: 1.9572995901107788

Epoch: 5| Step: 4
Training loss: 2.4423768520355225
Validation loss: 1.9348506389125701

Epoch: 5| Step: 5
Training loss: 2.294940710067749
Validation loss: 1.9388184111605409

Epoch: 5| Step: 6
Training loss: 1.665546178817749
Validation loss: 1.96215953365449

Epoch: 5| Step: 7
Training loss: 1.7206573486328125
Validation loss: 1.9544500253533805

Epoch: 5| Step: 8
Training loss: 2.405194044113159
Validation loss: 1.9351649053635136

Epoch: 5| Step: 9
Training loss: 2.0613694190979004
Validation loss: 1.9467835772422053

Epoch: 5| Step: 10
Training loss: 2.1054744720458984
Validation loss: 1.9320654151260213

Epoch: 91| Step: 0
Training loss: 1.8735191822052002
Validation loss: 1.9320383251354258

Epoch: 5| Step: 1
Training loss: 2.337672472000122
Validation loss: 1.9689062641512962

Epoch: 5| Step: 2
Training loss: 2.3573899269104004
Validation loss: 1.9690752439601447

Epoch: 5| Step: 3
Training loss: 2.2367842197418213
Validation loss: 1.9687347258290937

Epoch: 5| Step: 4
Training loss: 2.6332714557647705
Validation loss: 1.9524457762318272

Epoch: 5| Step: 5
Training loss: 2.149733543395996
Validation loss: 1.9446817905672136

Epoch: 5| Step: 6
Training loss: 2.3567252159118652
Validation loss: 1.939431808328116

Epoch: 5| Step: 7
Training loss: 1.6863998174667358
Validation loss: 1.9696529180772844

Epoch: 5| Step: 8
Training loss: 2.1425623893737793
Validation loss: 1.9330484610731884

Epoch: 5| Step: 9
Training loss: 2.25590443611145
Validation loss: 1.9624075146131619

Epoch: 5| Step: 10
Training loss: 1.9115402698516846
Validation loss: 1.949984327439339

Epoch: 92| Step: 0
Training loss: 2.3921360969543457
Validation loss: 1.9487955954767042

Epoch: 5| Step: 1
Training loss: 2.0201029777526855
Validation loss: 1.9530158299271778

Epoch: 5| Step: 2
Training loss: 1.9663190841674805
Validation loss: 1.9084672966311056

Epoch: 5| Step: 3
Training loss: 1.9882967472076416
Validation loss: 1.956246232473722

Epoch: 5| Step: 4
Training loss: 1.954806923866272
Validation loss: 1.9168347069012222

Epoch: 5| Step: 5
Training loss: 2.203568935394287
Validation loss: 1.9555397597692346

Epoch: 5| Step: 6
Training loss: 2.481137752532959
Validation loss: 1.9485202476542482

Epoch: 5| Step: 7
Training loss: 1.972877860069275
Validation loss: 1.9389693531938779

Epoch: 5| Step: 8
Training loss: 2.0153021812438965
Validation loss: 1.9339491410921978

Epoch: 5| Step: 9
Training loss: 2.441140651702881
Validation loss: 1.9298065682893157

Epoch: 5| Step: 10
Training loss: 2.3806591033935547
Validation loss: 1.9185279825682282

Epoch: 93| Step: 0
Training loss: 2.564502239227295
Validation loss: 1.924212739031802

Epoch: 5| Step: 1
Training loss: 1.588945746421814
Validation loss: 1.9237682140001686

Epoch: 5| Step: 2
Training loss: 2.2290444374084473
Validation loss: 1.9343922843215287

Epoch: 5| Step: 3
Training loss: 2.0907204151153564
Validation loss: 1.948195683058872

Epoch: 5| Step: 4
Training loss: 2.4510440826416016
Validation loss: 1.9392249456015966

Epoch: 5| Step: 5
Training loss: 1.5616954565048218
Validation loss: 1.9603803708989134

Epoch: 5| Step: 6
Training loss: 1.9762370586395264
Validation loss: 1.9711312401679255

Epoch: 5| Step: 7
Training loss: 2.6351044178009033
Validation loss: 1.9606077735142042

Epoch: 5| Step: 8
Training loss: 2.180579900741577
Validation loss: 1.9204631736201625

Epoch: 5| Step: 9
Training loss: 2.4744083881378174
Validation loss: 1.9724506844756424

Epoch: 5| Step: 10
Training loss: 2.027353286743164
Validation loss: 1.9786600323133572

Epoch: 94| Step: 0
Training loss: 2.303070545196533
Validation loss: 1.956355171818887

Epoch: 5| Step: 1
Training loss: 2.1134819984436035
Validation loss: 1.9990805938679685

Epoch: 5| Step: 2
Training loss: 1.9096349477767944
Validation loss: 1.9549755434836111

Epoch: 5| Step: 3
Training loss: 2.375999927520752
Validation loss: 1.9746326695206344

Epoch: 5| Step: 4
Training loss: 1.8811981678009033
Validation loss: 1.9454417087698495

Epoch: 5| Step: 5
Training loss: 2.2098000049591064
Validation loss: 1.9417501957185808

Epoch: 5| Step: 6
Training loss: 2.1519880294799805
Validation loss: 1.954848797090592

Epoch: 5| Step: 7
Training loss: 2.389155864715576
Validation loss: 1.9605264535514257

Epoch: 5| Step: 8
Training loss: 2.690138339996338
Validation loss: 1.9606456474591327

Epoch: 5| Step: 9
Training loss: 2.101919412612915
Validation loss: 1.9408313228238014

Epoch: 5| Step: 10
Training loss: 1.7552040815353394
Validation loss: 1.9727348999310566

Epoch: 95| Step: 0
Training loss: 3.056305408477783
Validation loss: 1.9701462945630472

Epoch: 5| Step: 1
Training loss: 1.8602066040039062
Validation loss: 1.9676025221424718

Epoch: 5| Step: 2
Training loss: 2.1420083045959473
Validation loss: 1.9674845075094571

Epoch: 5| Step: 3
Training loss: 2.4556937217712402
Validation loss: 1.9667917592551118

Epoch: 5| Step: 4
Training loss: 1.7654378414154053
Validation loss: 1.987639327203074

Epoch: 5| Step: 5
Training loss: 2.1453139781951904
Validation loss: 1.9840130626514394

Epoch: 5| Step: 6
Training loss: 2.0943076610565186
Validation loss: 1.9612369524535311

Epoch: 5| Step: 7
Training loss: 2.120042085647583
Validation loss: 1.990937981554257

Epoch: 5| Step: 8
Training loss: 2.080803155899048
Validation loss: 1.9710698704565726

Epoch: 5| Step: 9
Training loss: 2.182847023010254
Validation loss: 1.985884069114603

Epoch: 5| Step: 10
Training loss: 1.9932982921600342
Validation loss: 1.989218665707496

Epoch: 96| Step: 0
Training loss: 2.0713629722595215
Validation loss: 1.969044199553869

Epoch: 5| Step: 1
Training loss: 2.598809242248535
Validation loss: 1.9618008893023255

Epoch: 5| Step: 2
Training loss: 2.303610324859619
Validation loss: 1.9669650216256418

Epoch: 5| Step: 3
Training loss: 2.604328155517578
Validation loss: 1.9672198987776233

Epoch: 5| Step: 4
Training loss: 2.023193359375
Validation loss: 1.9623254242763724

Epoch: 5| Step: 5
Training loss: 1.6961199045181274
Validation loss: 1.931623758808259

Epoch: 5| Step: 6
Training loss: 1.783637285232544
Validation loss: 1.9460899188954344

Epoch: 5| Step: 7
Training loss: 1.6449989080429077
Validation loss: 1.9505163751622683

Epoch: 5| Step: 8
Training loss: 2.7467494010925293
Validation loss: 1.9268194936936902

Epoch: 5| Step: 9
Training loss: 2.1107285022735596
Validation loss: 1.9340986667140838

Epoch: 5| Step: 10
Training loss: 2.1565639972686768
Validation loss: 1.9369394625386884

Epoch: 97| Step: 0
Training loss: 2.045027256011963
Validation loss: 1.9223207273790914

Epoch: 5| Step: 1
Training loss: 1.5033321380615234
Validation loss: 1.9486860075304586

Epoch: 5| Step: 2
Training loss: 1.7085702419281006
Validation loss: 1.9468439689246557

Epoch: 5| Step: 3
Training loss: 2.462214469909668
Validation loss: 1.925753148653174

Epoch: 5| Step: 4
Training loss: 2.3385751247406006
Validation loss: 1.921476541026946

Epoch: 5| Step: 5
Training loss: 2.9653916358947754
Validation loss: 1.9310100552856282

Epoch: 5| Step: 6
Training loss: 2.414409875869751
Validation loss: 1.9029343640932472

Epoch: 5| Step: 7
Training loss: 1.9000091552734375
Validation loss: 1.9284355845502628

Epoch: 5| Step: 8
Training loss: 1.618973970413208
Validation loss: 1.9598448122701337

Epoch: 5| Step: 9
Training loss: 2.552607297897339
Validation loss: 1.925506050868701

Epoch: 5| Step: 10
Training loss: 2.2135941982269287
Validation loss: 1.9249095301474295

Epoch: 98| Step: 0
Training loss: 1.625702142715454
Validation loss: 1.9231972232941659

Epoch: 5| Step: 1
Training loss: 1.7395015954971313
Validation loss: 1.919320491052443

Epoch: 5| Step: 2
Training loss: 1.730907678604126
Validation loss: 1.930727453641994

Epoch: 5| Step: 3
Training loss: 3.0529847145080566
Validation loss: 1.9218421571998185

Epoch: 5| Step: 4
Training loss: 2.3911619186401367
Validation loss: 1.9322581355289747

Epoch: 5| Step: 5
Training loss: 2.2414276599884033
Validation loss: 1.906108025581606

Epoch: 5| Step: 6
Training loss: 1.8806575536727905
Validation loss: 1.900942712701777

Epoch: 5| Step: 7
Training loss: 2.125978946685791
Validation loss: 1.918937115259068

Epoch: 5| Step: 8
Training loss: 2.8314340114593506
Validation loss: 1.9405775365009104

Epoch: 5| Step: 9
Training loss: 2.1474499702453613
Validation loss: 1.9080108878433064

Epoch: 5| Step: 10
Training loss: 2.109705686569214
Validation loss: 1.924467154728469

Epoch: 99| Step: 0
Training loss: 2.6105990409851074
Validation loss: 1.9719262174380723

Epoch: 5| Step: 1
Training loss: 1.6289584636688232
Validation loss: 1.9071401191014115

Epoch: 5| Step: 2
Training loss: 2.141139507293701
Validation loss: 1.9384573800589449

Epoch: 5| Step: 3
Training loss: 2.675161361694336
Validation loss: 1.9527735581962011

Epoch: 5| Step: 4
Training loss: 1.9862686395645142
Validation loss: 1.9233857572719615

Epoch: 5| Step: 5
Training loss: 1.9964383840560913
Validation loss: 1.9301964647026473

Epoch: 5| Step: 6
Training loss: 2.0760512351989746
Validation loss: 1.9361116911775322

Epoch: 5| Step: 7
Training loss: 2.2030856609344482
Validation loss: 1.9480190110462967

Epoch: 5| Step: 8
Training loss: 1.9221216440200806
Validation loss: 1.9365716185621036

Epoch: 5| Step: 9
Training loss: 1.864950180053711
Validation loss: 1.9374038660398094

Epoch: 5| Step: 10
Training loss: 2.6521012783050537
Validation loss: 1.9769667886918592

Epoch: 100| Step: 0
Training loss: 1.2856329679489136
Validation loss: 1.9612576756426083

Epoch: 5| Step: 1
Training loss: 2.2330591678619385
Validation loss: 1.9661908636810959

Epoch: 5| Step: 2
Training loss: 2.492316484451294
Validation loss: 1.95882490886155

Epoch: 5| Step: 3
Training loss: 1.578550100326538
Validation loss: 1.982633036951865

Epoch: 5| Step: 4
Training loss: 2.221839189529419
Validation loss: 1.9679303169250488

Epoch: 5| Step: 5
Training loss: 2.267298936843872
Validation loss: 1.9481888637747815

Epoch: 5| Step: 6
Training loss: 2.4927399158477783
Validation loss: 1.9755645593007405

Epoch: 5| Step: 7
Training loss: 1.9813683032989502
Validation loss: 1.9608866809516825

Epoch: 5| Step: 8
Training loss: 2.2890453338623047
Validation loss: 1.976168401779667

Epoch: 5| Step: 9
Training loss: 2.8361854553222656
Validation loss: 1.9550155875503377

Epoch: 5| Step: 10
Training loss: 1.9999521970748901
Validation loss: 1.9706527135705436

Epoch: 101| Step: 0
Training loss: 2.5991358757019043
Validation loss: 1.965042761577073

Epoch: 5| Step: 1
Training loss: 2.353200674057007
Validation loss: 1.969436740362516

Epoch: 5| Step: 2
Training loss: 1.3473949432373047
Validation loss: 1.9867229269396873

Epoch: 5| Step: 3
Training loss: 2.020120620727539
Validation loss: 1.944113762147965

Epoch: 5| Step: 4
Training loss: 2.0394062995910645
Validation loss: 1.9408670163923694

Epoch: 5| Step: 5
Training loss: 1.857154130935669
Validation loss: 1.9474068598080707

Epoch: 5| Step: 6
Training loss: 2.5910675525665283
Validation loss: 1.9629767658889934

Epoch: 5| Step: 7
Training loss: 2.6230368614196777
Validation loss: 1.946107779779742

Epoch: 5| Step: 8
Training loss: 2.0247139930725098
Validation loss: 1.9579155945008802

Epoch: 5| Step: 9
Training loss: 1.6926023960113525
Validation loss: 1.961676118194416

Epoch: 5| Step: 10
Training loss: 2.247189521789551
Validation loss: 1.9423943693919847

Epoch: 102| Step: 0
Training loss: 2.1041982173919678
Validation loss: 1.9467238790245467

Epoch: 5| Step: 1
Training loss: 2.6578705310821533
Validation loss: 1.9639050088902956

Epoch: 5| Step: 2
Training loss: 2.121412754058838
Validation loss: 1.9549721953689412

Epoch: 5| Step: 3
Training loss: 2.049567461013794
Validation loss: 1.9566774470831758

Epoch: 5| Step: 4
Training loss: 2.0419209003448486
Validation loss: 1.9496140813314786

Epoch: 5| Step: 5
Training loss: 1.9049161672592163
Validation loss: 1.9442048175360567

Epoch: 5| Step: 6
Training loss: 2.0310168266296387
Validation loss: 1.9254737002875215

Epoch: 5| Step: 7
Training loss: 2.232820749282837
Validation loss: 1.9382165747304116

Epoch: 5| Step: 8
Training loss: 2.0048582553863525
Validation loss: 1.9350155168964016

Epoch: 5| Step: 9
Training loss: 2.238725423812866
Validation loss: 1.9587602205173944

Epoch: 5| Step: 10
Training loss: 2.0331926345825195
Validation loss: 1.9490237864114905

Epoch: 103| Step: 0
Training loss: 2.0437114238739014
Validation loss: 1.929710038246647

Epoch: 5| Step: 1
Training loss: 1.9495004415512085
Validation loss: 1.9423872988711122

Epoch: 5| Step: 2
Training loss: 1.8881887197494507
Validation loss: 1.94913435751392

Epoch: 5| Step: 3
Training loss: 1.9522581100463867
Validation loss: 1.9622507044064101

Epoch: 5| Step: 4
Training loss: 2.7298712730407715
Validation loss: 1.933392241436948

Epoch: 5| Step: 5
Training loss: 2.094625473022461
Validation loss: 1.9249126500980829

Epoch: 5| Step: 6
Training loss: 2.449380397796631
Validation loss: 1.9048326784564602

Epoch: 5| Step: 7
Training loss: 1.7621104717254639
Validation loss: 1.8987881086205924

Epoch: 5| Step: 8
Training loss: 2.330634593963623
Validation loss: 1.9190306637876777

Epoch: 5| Step: 9
Training loss: 1.8779951333999634
Validation loss: 1.9404720542251424

Epoch: 5| Step: 10
Training loss: 2.5319838523864746
Validation loss: 1.9250085507669756

Epoch: 104| Step: 0
Training loss: 2.1847150325775146
Validation loss: 1.955569508255169

Epoch: 5| Step: 1
Training loss: 2.4699482917785645
Validation loss: 1.941782824454769

Epoch: 5| Step: 2
Training loss: 2.274235486984253
Validation loss: 1.9008348731584446

Epoch: 5| Step: 3
Training loss: 2.5069949626922607
Validation loss: 1.9308169054728683

Epoch: 5| Step: 4
Training loss: 1.9088777303695679
Validation loss: 1.9382428584560272

Epoch: 5| Step: 5
Training loss: 1.6318979263305664
Validation loss: 1.9363013621299499

Epoch: 5| Step: 6
Training loss: 2.4235637187957764
Validation loss: 1.9278412211325862

Epoch: 5| Step: 7
Training loss: 2.3105978965759277
Validation loss: 1.9482847157345022

Epoch: 5| Step: 8
Training loss: 1.7062435150146484
Validation loss: 1.959867622262688

Epoch: 5| Step: 9
Training loss: 2.0005695819854736
Validation loss: 1.9554609150014899

Epoch: 5| Step: 10
Training loss: 1.9879099130630493
Validation loss: 1.9571319369859592

Epoch: 105| Step: 0
Training loss: 2.2381327152252197
Validation loss: 1.9622751359016664

Epoch: 5| Step: 1
Training loss: 1.9281394481658936
Validation loss: 1.9685211630277737

Epoch: 5| Step: 2
Training loss: 2.289926528930664
Validation loss: 1.9235783161655549

Epoch: 5| Step: 3
Training loss: 1.7298349142074585
Validation loss: 1.944126727760479

Epoch: 5| Step: 4
Training loss: 1.9518769979476929
Validation loss: 1.9515055046286633

Epoch: 5| Step: 5
Training loss: 2.2524471282958984
Validation loss: 1.9045078498060986

Epoch: 5| Step: 6
Training loss: 2.0504167079925537
Validation loss: 1.923563108649305

Epoch: 5| Step: 7
Training loss: 2.3436903953552246
Validation loss: 1.9492518722370107

Epoch: 5| Step: 8
Training loss: 2.4829611778259277
Validation loss: 1.9211748133423507

Epoch: 5| Step: 9
Training loss: 2.131880283355713
Validation loss: 1.9349984507406912

Epoch: 5| Step: 10
Training loss: 1.974122166633606
Validation loss: 1.9279618596517911

Epoch: 106| Step: 0
Training loss: 1.803506851196289
Validation loss: 1.9244293282108922

Epoch: 5| Step: 1
Training loss: 2.002488374710083
Validation loss: 1.9388258482820244

Epoch: 5| Step: 2
Training loss: 2.0215811729431152
Validation loss: 1.9143271394955215

Epoch: 5| Step: 3
Training loss: 2.6213088035583496
Validation loss: 1.9021170703313683

Epoch: 5| Step: 4
Training loss: 1.9632413387298584
Validation loss: 1.9409374344733454

Epoch: 5| Step: 5
Training loss: 2.305717945098877
Validation loss: 1.9502477261327928

Epoch: 5| Step: 6
Training loss: 2.068594455718994
Validation loss: 1.9372906377238612

Epoch: 5| Step: 7
Training loss: 1.967139482498169
Validation loss: 1.9294492224211335

Epoch: 5| Step: 8
Training loss: 2.510932445526123
Validation loss: 1.9441647760329708

Epoch: 5| Step: 9
Training loss: 1.9410960674285889
Validation loss: 1.951867885487054

Epoch: 5| Step: 10
Training loss: 2.2265968322753906
Validation loss: 1.9375964569789108

Epoch: 107| Step: 0
Training loss: 2.2875359058380127
Validation loss: 1.9670378508106354

Epoch: 5| Step: 1
Training loss: 2.340355396270752
Validation loss: 1.9526794187484249

Epoch: 5| Step: 2
Training loss: 2.1873481273651123
Validation loss: 1.944924077680034

Epoch: 5| Step: 3
Training loss: 2.510425567626953
Validation loss: 1.936585710894677

Epoch: 5| Step: 4
Training loss: 2.090479850769043
Validation loss: 1.918341762276106

Epoch: 5| Step: 5
Training loss: 2.109539747238159
Validation loss: 1.9299289000931608

Epoch: 5| Step: 6
Training loss: 2.3543529510498047
Validation loss: 1.9245894455140637

Epoch: 5| Step: 7
Training loss: 2.2215688228607178
Validation loss: 1.9519370768659858

Epoch: 5| Step: 8
Training loss: 1.0648549795150757
Validation loss: 1.9643930107034662

Epoch: 5| Step: 9
Training loss: 2.250664710998535
Validation loss: 1.9634912244735225

Epoch: 5| Step: 10
Training loss: 1.747770071029663
Validation loss: 1.962439493466449

Epoch: 108| Step: 0
Training loss: 2.4922194480895996
Validation loss: 1.9311269560167867

Epoch: 5| Step: 1
Training loss: 1.5941722393035889
Validation loss: 1.9533670435669601

Epoch: 5| Step: 2
Training loss: 2.492975950241089
Validation loss: 1.9502255480776551

Epoch: 5| Step: 3
Training loss: 1.8961775302886963
Validation loss: 1.966692170789165

Epoch: 5| Step: 4
Training loss: 2.688455104827881
Validation loss: 1.943329208640642

Epoch: 5| Step: 5
Training loss: 2.4109864234924316
Validation loss: 1.921445720939226

Epoch: 5| Step: 6
Training loss: 1.875658392906189
Validation loss: 1.9529966859407322

Epoch: 5| Step: 7
Training loss: 2.1739304065704346
Validation loss: 1.9628631350814656

Epoch: 5| Step: 8
Training loss: 1.6720943450927734
Validation loss: 1.9456435762425905

Epoch: 5| Step: 9
Training loss: 2.257267713546753
Validation loss: 1.950081661183347

Epoch: 5| Step: 10
Training loss: 1.6196001768112183
Validation loss: 1.9201951116643927

Epoch: 109| Step: 0
Training loss: 1.963697075843811
Validation loss: 1.9451233776666785

Epoch: 5| Step: 1
Training loss: 1.8521915674209595
Validation loss: 1.9498035343744422

Epoch: 5| Step: 2
Training loss: 2.290935516357422
Validation loss: 1.9308280252641248

Epoch: 5| Step: 3
Training loss: 1.7695796489715576
Validation loss: 1.9610342171884352

Epoch: 5| Step: 4
Training loss: 2.2223851680755615
Validation loss: 1.95762546600834

Epoch: 5| Step: 5
Training loss: 1.7689697742462158
Validation loss: 1.92868499858405

Epoch: 5| Step: 6
Training loss: 2.0080432891845703
Validation loss: 1.944041952010124

Epoch: 5| Step: 7
Training loss: 2.406553030014038
Validation loss: 1.9726254952851163

Epoch: 5| Step: 8
Training loss: 2.4440689086914062
Validation loss: 1.9422108255406862

Epoch: 5| Step: 9
Training loss: 2.3806495666503906
Validation loss: 1.9450996639908

Epoch: 5| Step: 10
Training loss: 2.1481552124023438
Validation loss: 1.936231490104429

Epoch: 110| Step: 0
Training loss: 2.2369017601013184
Validation loss: 1.928845924715842

Epoch: 5| Step: 1
Training loss: 2.1094794273376465
Validation loss: 1.9592194852008615

Epoch: 5| Step: 2
Training loss: 2.4128851890563965
Validation loss: 1.9430636129071635

Epoch: 5| Step: 3
Training loss: 2.331582546234131
Validation loss: 1.9575476774605371

Epoch: 5| Step: 4
Training loss: 2.08388090133667
Validation loss: 1.943905468909971

Epoch: 5| Step: 5
Training loss: 1.6273151636123657
Validation loss: 1.9425682765181347

Epoch: 5| Step: 6
Training loss: 2.072695255279541
Validation loss: 1.9571129301542878

Epoch: 5| Step: 7
Training loss: 2.152111768722534
Validation loss: 1.9469453506572272

Epoch: 5| Step: 8
Training loss: 2.067269802093506
Validation loss: 1.958609724557528

Epoch: 5| Step: 9
Training loss: 2.1669750213623047
Validation loss: 1.9602662158268753

Epoch: 5| Step: 10
Training loss: 2.0993850231170654
Validation loss: 1.9499243997758435

Epoch: 111| Step: 0
Training loss: 1.5619268417358398
Validation loss: 1.9685195902342438

Epoch: 5| Step: 1
Training loss: 2.2097790241241455
Validation loss: 1.9391301575527395

Epoch: 5| Step: 2
Training loss: 1.780304193496704
Validation loss: 1.9358842360076083

Epoch: 5| Step: 3
Training loss: 3.0665602684020996
Validation loss: 1.947247261642128

Epoch: 5| Step: 4
Training loss: 1.8909759521484375
Validation loss: 1.9561677389247443

Epoch: 5| Step: 5
Training loss: 1.911842703819275
Validation loss: 1.9590146695413897

Epoch: 5| Step: 6
Training loss: 2.1698126792907715
Validation loss: 1.9164796977914789

Epoch: 5| Step: 7
Training loss: 2.1021032333374023
Validation loss: 1.948563568053707

Epoch: 5| Step: 8
Training loss: 2.519808530807495
Validation loss: 1.9329086785675378

Epoch: 5| Step: 9
Training loss: 2.237316608428955
Validation loss: 1.9324833193132955

Epoch: 5| Step: 10
Training loss: 1.596117615699768
Validation loss: 1.9200855455090922

Epoch: 112| Step: 0
Training loss: 1.972495675086975
Validation loss: 1.938017898990262

Epoch: 5| Step: 1
Training loss: 2.2175471782684326
Validation loss: 1.9393714974003453

Epoch: 5| Step: 2
Training loss: 2.111201047897339
Validation loss: 1.9454673977308377

Epoch: 5| Step: 3
Training loss: 2.1136879920959473
Validation loss: 1.9436349099682224

Epoch: 5| Step: 4
Training loss: 2.0570154190063477
Validation loss: 1.946453143191594

Epoch: 5| Step: 5
Training loss: 1.94667649269104
Validation loss: 1.9256568390835997

Epoch: 5| Step: 6
Training loss: 2.647151231765747
Validation loss: 1.9489189783732097

Epoch: 5| Step: 7
Training loss: 1.9759374856948853
Validation loss: 1.9175366945164178

Epoch: 5| Step: 8
Training loss: 2.202853202819824
Validation loss: 1.9415787919875114

Epoch: 5| Step: 9
Training loss: 1.881103277206421
Validation loss: 1.9310084927466609

Epoch: 5| Step: 10
Training loss: 2.22705340385437
Validation loss: 1.9548736041592014

Epoch: 113| Step: 0
Training loss: 1.9732310771942139
Validation loss: 1.9403409598976054

Epoch: 5| Step: 1
Training loss: 1.6879510879516602
Validation loss: 1.9289468142294115

Epoch: 5| Step: 2
Training loss: 2.39031982421875
Validation loss: 1.9383284353440808

Epoch: 5| Step: 3
Training loss: 2.3339037895202637
Validation loss: 1.9436233940944876

Epoch: 5| Step: 4
Training loss: 2.703181505203247
Validation loss: 1.9478943809386222

Epoch: 5| Step: 5
Training loss: 2.2826311588287354
Validation loss: 1.9409230652675833

Epoch: 5| Step: 6
Training loss: 2.1423466205596924
Validation loss: 1.938454056298861

Epoch: 5| Step: 7
Training loss: 1.3738059997558594
Validation loss: 1.9359787574378393

Epoch: 5| Step: 8
Training loss: 1.867248296737671
Validation loss: 1.945565467239708

Epoch: 5| Step: 9
Training loss: 1.823097586631775
Validation loss: 1.9795218436948714

Epoch: 5| Step: 10
Training loss: 2.438661813735962
Validation loss: 1.9565254360116937

Epoch: 114| Step: 0
Training loss: 2.38856840133667
Validation loss: 1.9705236752827961

Epoch: 5| Step: 1
Training loss: 2.080090045928955
Validation loss: 1.9580625795548963

Epoch: 5| Step: 2
Training loss: 1.562334418296814
Validation loss: 1.9603451657038864

Epoch: 5| Step: 3
Training loss: 1.9000844955444336
Validation loss: 1.9574531944849158

Epoch: 5| Step: 4
Training loss: 1.5211045742034912
Validation loss: 1.978391085901568

Epoch: 5| Step: 5
Training loss: 2.7419910430908203
Validation loss: 1.9774349530537922

Epoch: 5| Step: 6
Training loss: 2.827448606491089
Validation loss: 1.9858407922970351

Epoch: 5| Step: 7
Training loss: 1.9316236972808838
Validation loss: 1.9728732775616389

Epoch: 5| Step: 8
Training loss: 2.1822092533111572
Validation loss: 1.9390061247733332

Epoch: 5| Step: 9
Training loss: 1.8827136754989624
Validation loss: 1.9146888256072998

Epoch: 5| Step: 10
Training loss: 2.05722713470459
Validation loss: 1.9507682426001436

Epoch: 115| Step: 0
Training loss: 2.362703323364258
Validation loss: 1.922625792923794

Epoch: 5| Step: 1
Training loss: 2.0845425128936768
Validation loss: 1.9506822619386899

Epoch: 5| Step: 2
Training loss: 2.578137159347534
Validation loss: 1.934981353821293

Epoch: 5| Step: 3
Training loss: 2.3620200157165527
Validation loss: 1.9497682689338602

Epoch: 5| Step: 4
Training loss: 2.080911636352539
Validation loss: 1.943979614524431

Epoch: 5| Step: 5
Training loss: 2.2282555103302
Validation loss: 1.937052930555036

Epoch: 5| Step: 6
Training loss: 1.6890604496002197
Validation loss: 1.9428562733434862

Epoch: 5| Step: 7
Training loss: 2.1438794136047363
Validation loss: 1.9046538465766496

Epoch: 5| Step: 8
Training loss: 1.6464027166366577
Validation loss: 1.9604682076361872

Epoch: 5| Step: 9
Training loss: 2.302682399749756
Validation loss: 1.9274058444525606

Epoch: 5| Step: 10
Training loss: 1.7064611911773682
Validation loss: 1.9196254540515203

Epoch: 116| Step: 0
Training loss: 1.7813247442245483
Validation loss: 1.9318763594473563

Epoch: 5| Step: 1
Training loss: 1.9253299236297607
Validation loss: 1.9131200685296008

Epoch: 5| Step: 2
Training loss: 2.316848039627075
Validation loss: 1.9326231043825868

Epoch: 5| Step: 3
Training loss: 2.3849010467529297
Validation loss: 1.9343574893090032

Epoch: 5| Step: 4
Training loss: 1.9469959735870361
Validation loss: 1.9595084113459433

Epoch: 5| Step: 5
Training loss: 2.15372896194458
Validation loss: 1.9389404712184783

Epoch: 5| Step: 6
Training loss: 2.558037757873535
Validation loss: 1.9616136294539257

Epoch: 5| Step: 7
Training loss: 2.0372190475463867
Validation loss: 1.9318508640412362

Epoch: 5| Step: 8
Training loss: 2.170870542526245
Validation loss: 1.9415028428518644

Epoch: 5| Step: 9
Training loss: 1.5240041017532349
Validation loss: 1.9525624744353756

Epoch: 5| Step: 10
Training loss: 2.161619186401367
Validation loss: 1.9631563989065026

Epoch: 117| Step: 0
Training loss: 2.479592800140381
Validation loss: 1.946394787039808

Epoch: 5| Step: 1
Training loss: 2.53395938873291
Validation loss: 1.9520757429061397

Epoch: 5| Step: 2
Training loss: 1.7746092081069946
Validation loss: 1.9276568633253857

Epoch: 5| Step: 3
Training loss: 2.3943064212799072
Validation loss: 1.97494843698317

Epoch: 5| Step: 4
Training loss: 2.527017593383789
Validation loss: 1.9412563449593

Epoch: 5| Step: 5
Training loss: 1.744070291519165
Validation loss: 1.9508314517236525

Epoch: 5| Step: 6
Training loss: 1.9402246475219727
Validation loss: 1.965021365432329

Epoch: 5| Step: 7
Training loss: 2.0196545124053955
Validation loss: 1.9566771753372685

Epoch: 5| Step: 8
Training loss: 1.899696707725525
Validation loss: 1.9726303123658704

Epoch: 5| Step: 9
Training loss: 1.3683249950408936
Validation loss: 1.9330203071717293

Epoch: 5| Step: 10
Training loss: 2.244344472885132
Validation loss: 1.9399196306864421

Epoch: 118| Step: 0
Training loss: 2.0118050575256348
Validation loss: 1.948640984873618

Epoch: 5| Step: 1
Training loss: 1.4606761932373047
Validation loss: 1.9374856820670507

Epoch: 5| Step: 2
Training loss: 1.7098814249038696
Validation loss: 1.9569003684546358

Epoch: 5| Step: 3
Training loss: 2.449460029602051
Validation loss: 1.924504210872035

Epoch: 5| Step: 4
Training loss: 1.616675615310669
Validation loss: 1.9623371183231313

Epoch: 5| Step: 5
Training loss: 2.6507973670959473
Validation loss: 1.9691659724840553

Epoch: 5| Step: 6
Training loss: 2.5478737354278564
Validation loss: 1.9479283286679177

Epoch: 5| Step: 7
Training loss: 2.0557634830474854
Validation loss: 1.9512916200904435

Epoch: 5| Step: 8
Training loss: 2.055607795715332
Validation loss: 1.9488709434386222

Epoch: 5| Step: 9
Training loss: 2.7143936157226562
Validation loss: 1.966395870331795

Epoch: 5| Step: 10
Training loss: 1.4957822561264038
Validation loss: 1.9570576067893737

Epoch: 119| Step: 0
Training loss: 1.7329641580581665
Validation loss: 1.9552008336590183

Epoch: 5| Step: 1
Training loss: 1.988837480545044
Validation loss: 1.965569834555349

Epoch: 5| Step: 2
Training loss: 2.542888879776001
Validation loss: 1.969295979827963

Epoch: 5| Step: 3
Training loss: 2.1645538806915283
Validation loss: 1.934561098775556

Epoch: 5| Step: 4
Training loss: 1.8207437992095947
Validation loss: 1.955250229886783

Epoch: 5| Step: 5
Training loss: 2.396653890609741
Validation loss: 1.9336844080237932

Epoch: 5| Step: 6
Training loss: 1.601662039756775
Validation loss: 1.9471104939778645

Epoch: 5| Step: 7
Training loss: 1.8730344772338867
Validation loss: 1.9728912935462048

Epoch: 5| Step: 8
Training loss: 2.115619659423828
Validation loss: 1.9325237812534455

Epoch: 5| Step: 9
Training loss: 2.4549624919891357
Validation loss: 1.930668712944113

Epoch: 5| Step: 10
Training loss: 2.3120486736297607
Validation loss: 1.9204920004772883

Epoch: 120| Step: 0
Training loss: 1.7873647212982178
Validation loss: 1.919158850946734

Epoch: 5| Step: 1
Training loss: 2.10009765625
Validation loss: 1.9527565997133973

Epoch: 5| Step: 2
Training loss: 1.9869680404663086
Validation loss: 1.9285649714931365

Epoch: 5| Step: 3
Training loss: 2.595691204071045
Validation loss: 1.9371801499397523

Epoch: 5| Step: 4
Training loss: 1.5824272632598877
Validation loss: 1.9386092796120593

Epoch: 5| Step: 5
Training loss: 1.9297363758087158
Validation loss: 1.9539535789079563

Epoch: 5| Step: 6
Training loss: 2.4549689292907715
Validation loss: 1.9359976168601745

Epoch: 5| Step: 7
Training loss: 1.7093864679336548
Validation loss: 1.9472295225307505

Epoch: 5| Step: 8
Training loss: 2.074038505554199
Validation loss: 1.9602421022230578

Epoch: 5| Step: 9
Training loss: 2.3753662109375
Validation loss: 1.931072788853799

Epoch: 5| Step: 10
Training loss: 1.9984939098358154
Validation loss: 1.9560749171882548

Epoch: 121| Step: 0
Training loss: 1.5503747463226318
Validation loss: 1.9443062774596676

Epoch: 5| Step: 1
Training loss: 2.262514114379883
Validation loss: 1.9554106868723387

Epoch: 5| Step: 2
Training loss: 2.2253832817077637
Validation loss: 1.932109252099068

Epoch: 5| Step: 3
Training loss: 2.471571683883667
Validation loss: 1.9275750575527069

Epoch: 5| Step: 4
Training loss: 2.179986000061035
Validation loss: 1.916063880407682

Epoch: 5| Step: 5
Training loss: 2.2071375846862793
Validation loss: 1.932549709914833

Epoch: 5| Step: 6
Training loss: 2.286250591278076
Validation loss: 1.9371934475437287

Epoch: 5| Step: 7
Training loss: 2.1179733276367188
Validation loss: 1.9298344850540161

Epoch: 5| Step: 8
Training loss: 2.681983232498169
Validation loss: 1.9051556766674083

Epoch: 5| Step: 9
Training loss: 1.3200304508209229
Validation loss: 1.9310017298626643

Epoch: 5| Step: 10
Training loss: 1.6344308853149414
Validation loss: 1.9226688396546148

Epoch: 122| Step: 0
Training loss: 2.3461594581604004
Validation loss: 1.926987382673448

Epoch: 5| Step: 1
Training loss: 1.9298464059829712
Validation loss: 1.9499616699834024

Epoch: 5| Step: 2
Training loss: 1.6165399551391602
Validation loss: 1.9283305880843953

Epoch: 5| Step: 3
Training loss: 2.3164355754852295
Validation loss: 1.9516703044214556

Epoch: 5| Step: 4
Training loss: 1.9052852392196655
Validation loss: 1.9437336511509393

Epoch: 5| Step: 5
Training loss: 1.999123215675354
Validation loss: 1.9264091625008533

Epoch: 5| Step: 6
Training loss: 1.9054574966430664
Validation loss: 1.917869366625304

Epoch: 5| Step: 7
Training loss: 2.227926731109619
Validation loss: 1.9787704508791688

Epoch: 5| Step: 8
Training loss: 2.3280067443847656
Validation loss: 2.0042459644297117

Epoch: 5| Step: 9
Training loss: 2.149883985519409
Validation loss: 1.984269795879241

Epoch: 5| Step: 10
Training loss: 1.850498914718628
Validation loss: 1.9636857048157723

Epoch: 123| Step: 0
Training loss: 2.3421413898468018
Validation loss: 1.9654078329763105

Epoch: 5| Step: 1
Training loss: 2.0922322273254395
Validation loss: 1.9358995550422258

Epoch: 5| Step: 2
Training loss: 2.090372085571289
Validation loss: 1.9602429636063115

Epoch: 5| Step: 3
Training loss: 1.5321767330169678
Validation loss: 1.9564562100236134

Epoch: 5| Step: 4
Training loss: 2.235551357269287
Validation loss: 1.9465248418110672

Epoch: 5| Step: 5
Training loss: 2.2689967155456543
Validation loss: 1.9433661096839494

Epoch: 5| Step: 6
Training loss: 1.1979460716247559
Validation loss: 1.9754238961845316

Epoch: 5| Step: 7
Training loss: 2.923886775970459
Validation loss: 1.9478339918198124

Epoch: 5| Step: 8
Training loss: 2.0930662155151367
Validation loss: 1.948900277896594

Epoch: 5| Step: 9
Training loss: 2.0982394218444824
Validation loss: 1.9724939433477258

Epoch: 5| Step: 10
Training loss: 1.9115102291107178
Validation loss: 1.9556774195804392

Epoch: 124| Step: 0
Training loss: 1.9761693477630615
Validation loss: 1.9301366318938553

Epoch: 5| Step: 1
Training loss: 1.591675043106079
Validation loss: 1.9390107739356257

Epoch: 5| Step: 2
Training loss: 1.9809547662734985
Validation loss: 1.9297354375162432

Epoch: 5| Step: 3
Training loss: 1.711163878440857
Validation loss: 1.9367545343214465

Epoch: 5| Step: 4
Training loss: 1.9003469944000244
Validation loss: 1.9262839030194026

Epoch: 5| Step: 5
Training loss: 2.3732693195343018
Validation loss: 1.9481304896775113

Epoch: 5| Step: 6
Training loss: 2.0287537574768066
Validation loss: 1.91563545632106

Epoch: 5| Step: 7
Training loss: 1.9822132587432861
Validation loss: 1.9339912347896124

Epoch: 5| Step: 8
Training loss: 2.109246015548706
Validation loss: 1.919778008614817

Epoch: 5| Step: 9
Training loss: 2.6962292194366455
Validation loss: 1.90698794908421

Epoch: 5| Step: 10
Training loss: 2.445157289505005
Validation loss: 1.9041496733183503

Epoch: 125| Step: 0
Training loss: 2.129302978515625
Validation loss: 1.8876752045846754

Epoch: 5| Step: 1
Training loss: 2.8265397548675537
Validation loss: 1.9134804664119598

Epoch: 5| Step: 2
Training loss: 1.6610714197158813
Validation loss: 1.923273213448063

Epoch: 5| Step: 3
Training loss: 2.107454538345337
Validation loss: 1.9309868761288222

Epoch: 5| Step: 4
Training loss: 1.9038429260253906
Validation loss: 1.9262585819408458

Epoch: 5| Step: 5
Training loss: 2.4722900390625
Validation loss: 1.9137707448774768

Epoch: 5| Step: 6
Training loss: 1.627342939376831
Validation loss: 1.9474326154237152

Epoch: 5| Step: 7
Training loss: 2.1526896953582764
Validation loss: 1.9295222810519639

Epoch: 5| Step: 8
Training loss: 1.9960025548934937
Validation loss: 1.9237740885826848

Epoch: 5| Step: 9
Training loss: 2.033766508102417
Validation loss: 1.9450415744576404

Epoch: 5| Step: 10
Training loss: 1.6671152114868164
Validation loss: 1.9045900324339509

Epoch: 126| Step: 0
Training loss: 2.1623306274414062
Validation loss: 1.9540492860219811

Epoch: 5| Step: 1
Training loss: 2.1564462184906006
Validation loss: 1.9563340410109489

Epoch: 5| Step: 2
Training loss: 1.7521158456802368
Validation loss: 1.9598071767437844

Epoch: 5| Step: 3
Training loss: 2.1945667266845703
Validation loss: 1.9337164189225884

Epoch: 5| Step: 4
Training loss: 1.7391259670257568
Validation loss: 1.9245216256828719

Epoch: 5| Step: 5
Training loss: 2.4406590461730957
Validation loss: 1.9445327379370247

Epoch: 5| Step: 6
Training loss: 2.3073337078094482
Validation loss: 1.9508555217455792

Epoch: 5| Step: 7
Training loss: 2.1441378593444824
Validation loss: 1.9301968928306334

Epoch: 5| Step: 8
Training loss: 1.8656291961669922
Validation loss: 1.9267341475332938

Epoch: 5| Step: 9
Training loss: 2.0717854499816895
Validation loss: 1.9484988874004734

Epoch: 5| Step: 10
Training loss: 1.8741605281829834
Validation loss: 1.936595251483302

Epoch: 127| Step: 0
Training loss: 2.305509328842163
Validation loss: 1.9543595134571035

Epoch: 5| Step: 1
Training loss: 1.635620355606079
Validation loss: 1.9550533974042503

Epoch: 5| Step: 2
Training loss: 2.3618712425231934
Validation loss: 1.9428021574533114

Epoch: 5| Step: 3
Training loss: 1.8443896770477295
Validation loss: 1.9627035548610072

Epoch: 5| Step: 4
Training loss: 1.8731439113616943
Validation loss: 1.9289729877184796

Epoch: 5| Step: 5
Training loss: 2.33536958694458
Validation loss: 1.970296993050524

Epoch: 5| Step: 6
Training loss: 1.907152533531189
Validation loss: 1.9257436670282835

Epoch: 5| Step: 7
Training loss: 2.002225875854492
Validation loss: 1.9288503636596024

Epoch: 5| Step: 8
Training loss: 1.9856998920440674
Validation loss: 1.9649512434518466

Epoch: 5| Step: 9
Training loss: 2.1991569995880127
Validation loss: 1.9426645322512555

Epoch: 5| Step: 10
Training loss: 2.1654794216156006
Validation loss: 1.9554924452176659

Epoch: 128| Step: 0
Training loss: 2.380645275115967
Validation loss: 1.9535881037353187

Epoch: 5| Step: 1
Training loss: 2.0435781478881836
Validation loss: 1.9183050253057992

Epoch: 5| Step: 2
Training loss: 2.1796958446502686
Validation loss: 1.9467577754810292

Epoch: 5| Step: 3
Training loss: 2.6201748847961426
Validation loss: 1.9682612316582793

Epoch: 5| Step: 4
Training loss: 1.8772547245025635
Validation loss: 1.9389688225202664

Epoch: 5| Step: 5
Training loss: 2.0073304176330566
Validation loss: 1.9653918768769951

Epoch: 5| Step: 6
Training loss: 2.0083210468292236
Validation loss: 1.9542860266982869

Epoch: 5| Step: 7
Training loss: 1.213993787765503
Validation loss: 1.974365565084642

Epoch: 5| Step: 8
Training loss: 1.779140830039978
Validation loss: 1.9706853858886226

Epoch: 5| Step: 9
Training loss: 2.491683006286621
Validation loss: 1.9662170743429532

Epoch: 5| Step: 10
Training loss: 2.1726462841033936
Validation loss: 1.973658828325169

Epoch: 129| Step: 0
Training loss: 1.9075191020965576
Validation loss: 1.9703339658757693

Epoch: 5| Step: 1
Training loss: 2.2623705863952637
Validation loss: 1.9701546417769564

Epoch: 5| Step: 2
Training loss: 1.7873375415802002
Validation loss: 1.9415330938113633

Epoch: 5| Step: 3
Training loss: 2.042649745941162
Validation loss: 1.938667143544843

Epoch: 5| Step: 4
Training loss: 2.5494492053985596
Validation loss: 1.9686851539919454

Epoch: 5| Step: 5
Training loss: 2.1740169525146484
Validation loss: 1.9755594589376961

Epoch: 5| Step: 6
Training loss: 2.155834913253784
Validation loss: 1.9403694701451126

Epoch: 5| Step: 7
Training loss: 2.4910616874694824
Validation loss: 1.9360853651518464

Epoch: 5| Step: 8
Training loss: 1.5845154523849487
Validation loss: 1.942478584986861

Epoch: 5| Step: 9
Training loss: 1.732714056968689
Validation loss: 1.9521275361378987

Epoch: 5| Step: 10
Training loss: 1.69806706905365
Validation loss: 1.9260621634862756

Epoch: 130| Step: 0
Training loss: 2.067809581756592
Validation loss: 1.9063341245856336

Epoch: 5| Step: 1
Training loss: 1.9419679641723633
Validation loss: 1.9025460673916725

Epoch: 5| Step: 2
Training loss: 2.508770704269409
Validation loss: 1.9300264953285136

Epoch: 5| Step: 3
Training loss: 1.9097545146942139
Validation loss: 1.9269056986736994

Epoch: 5| Step: 4
Training loss: 2.1048107147216797
Validation loss: 1.955927829588613

Epoch: 5| Step: 5
Training loss: 2.302131414413452
Validation loss: 1.9429660817628265

Epoch: 5| Step: 6
Training loss: 1.078748106956482
Validation loss: 1.936203158029946

Epoch: 5| Step: 7
Training loss: 1.8466465473175049
Validation loss: 1.9478540856351134

Epoch: 5| Step: 8
Training loss: 2.0411038398742676
Validation loss: 1.8942789800705448

Epoch: 5| Step: 9
Training loss: 2.0109620094299316
Validation loss: 1.960655886639831

Epoch: 5| Step: 10
Training loss: 2.6398894786834717
Validation loss: 1.9293363940331243

Epoch: 131| Step: 0
Training loss: 1.7510532140731812
Validation loss: 1.9931419716086438

Epoch: 5| Step: 1
Training loss: 2.0448720455169678
Validation loss: 1.9294487712203816

Epoch: 5| Step: 2
Training loss: 2.167598247528076
Validation loss: 1.9557383727001887

Epoch: 5| Step: 3
Training loss: 1.9126148223876953
Validation loss: 1.941511918139714

Epoch: 5| Step: 4
Training loss: 1.9281034469604492
Validation loss: 1.9568388872249152

Epoch: 5| Step: 5
Training loss: 2.29801344871521
Validation loss: 1.928867720788525

Epoch: 5| Step: 6
Training loss: 2.6105074882507324
Validation loss: 1.9470417909724738

Epoch: 5| Step: 7
Training loss: 1.7845993041992188
Validation loss: 1.9517644131055443

Epoch: 5| Step: 8
Training loss: 1.7169862985610962
Validation loss: 1.9689950789174726

Epoch: 5| Step: 9
Training loss: 1.7206255197525024
Validation loss: 1.9629144514760664

Epoch: 5| Step: 10
Training loss: 2.448833465576172
Validation loss: 1.9181722928118963

Epoch: 132| Step: 0
Training loss: 1.6936298608779907
Validation loss: 1.9651332029732325

Epoch: 5| Step: 1
Training loss: 2.047154188156128
Validation loss: 1.96896626487855

Epoch: 5| Step: 2
Training loss: 1.9581600427627563
Validation loss: 1.9673561665319628

Epoch: 5| Step: 3
Training loss: 1.7740793228149414
Validation loss: 1.9205173189922045

Epoch: 5| Step: 4
Training loss: 2.672375440597534
Validation loss: 1.9410500936610724

Epoch: 5| Step: 5
Training loss: 2.622739315032959
Validation loss: 1.9455428072201308

Epoch: 5| Step: 6
Training loss: 1.5189471244812012
Validation loss: 1.9580925459502845

Epoch: 5| Step: 7
Training loss: 1.7403091192245483
Validation loss: 1.936354503836683

Epoch: 5| Step: 8
Training loss: 1.7411531209945679
Validation loss: 1.9383364210846603

Epoch: 5| Step: 9
Training loss: 2.4093539714813232
Validation loss: 1.9350315870777253

Epoch: 5| Step: 10
Training loss: 2.4017555713653564
Validation loss: 1.9281738304322766

Epoch: 133| Step: 0
Training loss: 1.7883533239364624
Validation loss: 1.9517435412253104

Epoch: 5| Step: 1
Training loss: 2.451349973678589
Validation loss: 1.9352415069457023

Epoch: 5| Step: 2
Training loss: 1.8635765314102173
Validation loss: 1.9295494120608094

Epoch: 5| Step: 3
Training loss: 1.7922687530517578
Validation loss: 1.9566627048677014

Epoch: 5| Step: 4
Training loss: 1.697918176651001
Validation loss: 1.9259464228025047

Epoch: 5| Step: 5
Training loss: 1.9117281436920166
Validation loss: 1.9509791071696947

Epoch: 5| Step: 6
Training loss: 2.027130603790283
Validation loss: 1.952533898815032

Epoch: 5| Step: 7
Training loss: 2.261749744415283
Validation loss: 1.9908088791754939

Epoch: 5| Step: 8
Training loss: 2.5656533241271973
Validation loss: 1.9116106930599417

Epoch: 5| Step: 9
Training loss: 2.311039924621582
Validation loss: 1.9705400582282775

Epoch: 5| Step: 10
Training loss: 1.6424815654754639
Validation loss: 1.9449516291259437

Epoch: 134| Step: 0
Training loss: 2.476454496383667
Validation loss: 1.9555421849732757

Epoch: 5| Step: 1
Training loss: 2.25537371635437
Validation loss: 1.9440256164919945

Epoch: 5| Step: 2
Training loss: 2.1430153846740723
Validation loss: 1.939349946155343

Epoch: 5| Step: 3
Training loss: 1.8581244945526123
Validation loss: 1.9125649070227018

Epoch: 5| Step: 4
Training loss: 2.1513195037841797
Validation loss: 1.9254065405937932

Epoch: 5| Step: 5
Training loss: 1.8041365146636963
Validation loss: 1.9632821185614473

Epoch: 5| Step: 6
Training loss: 1.6669893264770508
Validation loss: 1.9374056657155354

Epoch: 5| Step: 7
Training loss: 2.172814130783081
Validation loss: 1.960278147010393

Epoch: 5| Step: 8
Training loss: 1.9152415990829468
Validation loss: 1.9661014233866045

Epoch: 5| Step: 9
Training loss: 1.68703293800354
Validation loss: 1.9512965730441514

Epoch: 5| Step: 10
Training loss: 2.2412095069885254
Validation loss: 1.933492750249883

Epoch: 135| Step: 0
Training loss: 1.683772325515747
Validation loss: 1.9543317094925912

Epoch: 5| Step: 1
Training loss: 2.401444435119629
Validation loss: 1.9614729804377402

Epoch: 5| Step: 2
Training loss: 2.22514009475708
Validation loss: 1.9565765139877156

Epoch: 5| Step: 3
Training loss: 2.5905842781066895
Validation loss: 1.9736273480999855

Epoch: 5| Step: 4
Training loss: 1.8143562078475952
Validation loss: 1.984392927538964

Epoch: 5| Step: 5
Training loss: 2.0190956592559814
Validation loss: 1.9595260902117657

Epoch: 5| Step: 6
Training loss: 2.321221113204956
Validation loss: 1.9953340253522318

Epoch: 5| Step: 7
Training loss: 1.6181873083114624
Validation loss: 1.9830528100331624

Epoch: 5| Step: 8
Training loss: 2.025139570236206
Validation loss: 1.960419806100989

Epoch: 5| Step: 9
Training loss: 1.8384395837783813
Validation loss: 1.9563212061441073

Epoch: 5| Step: 10
Training loss: 2.0309040546417236
Validation loss: 1.9763720035552979

Epoch: 136| Step: 0
Training loss: 1.6091201305389404
Validation loss: 1.9604893768987348

Epoch: 5| Step: 1
Training loss: 2.3902745246887207
Validation loss: 1.9834484156741892

Epoch: 5| Step: 2
Training loss: 2.1855015754699707
Validation loss: 1.923877772464547

Epoch: 5| Step: 3
Training loss: 1.7706836462020874
Validation loss: 1.9530543486277263

Epoch: 5| Step: 4
Training loss: 2.0445096492767334
Validation loss: 1.9491268793741863

Epoch: 5| Step: 5
Training loss: 2.0162360668182373
Validation loss: 1.9417906012586368

Epoch: 5| Step: 6
Training loss: 2.057678699493408
Validation loss: 1.9222569183636737

Epoch: 5| Step: 7
Training loss: 1.6443971395492554
Validation loss: 1.9464601688487555

Epoch: 5| Step: 8
Training loss: 2.4613566398620605
Validation loss: 1.9170688121549544

Epoch: 5| Step: 9
Training loss: 1.952649712562561
Validation loss: 1.9585110384930846

Epoch: 5| Step: 10
Training loss: 2.1610701084136963
Validation loss: 1.9306921369285994

Epoch: 137| Step: 0
Training loss: 2.0168724060058594
Validation loss: 1.9016277123523015

Epoch: 5| Step: 1
Training loss: 2.3807318210601807
Validation loss: 1.9372519088047806

Epoch: 5| Step: 2
Training loss: 2.245194673538208
Validation loss: 1.913368889080581

Epoch: 5| Step: 3
Training loss: 1.804140329360962
Validation loss: 1.945764862081056

Epoch: 5| Step: 4
Training loss: 1.4098846912384033
Validation loss: 1.9210029340559436

Epoch: 5| Step: 5
Training loss: 1.8170626163482666
Validation loss: 1.94115424284371

Epoch: 5| Step: 6
Training loss: 1.9638677835464478
Validation loss: 1.9286705140144593

Epoch: 5| Step: 7
Training loss: 2.4706578254699707
Validation loss: 1.9192088868028374

Epoch: 5| Step: 8
Training loss: 2.4368021488189697
Validation loss: 1.9014522849872548

Epoch: 5| Step: 9
Training loss: 1.5958640575408936
Validation loss: 1.9239859196447557

Epoch: 5| Step: 10
Training loss: 2.3257625102996826
Validation loss: 1.9235605834632792

Epoch: 138| Step: 0
Training loss: 2.2695393562316895
Validation loss: 1.9529421765317199

Epoch: 5| Step: 1
Training loss: 2.002495288848877
Validation loss: 1.9656668875807075

Epoch: 5| Step: 2
Training loss: 1.579196810722351
Validation loss: 1.923517962937714

Epoch: 5| Step: 3
Training loss: 2.1219403743743896
Validation loss: 1.9438603052528955

Epoch: 5| Step: 4
Training loss: 2.1277997493743896
Validation loss: 1.94149528139381

Epoch: 5| Step: 5
Training loss: 2.2567083835601807
Validation loss: 1.9701437206678494

Epoch: 5| Step: 6
Training loss: 1.9885469675064087
Validation loss: 1.9698457935804963

Epoch: 5| Step: 7
Training loss: 1.8701015710830688
Validation loss: 1.9566462091220322

Epoch: 5| Step: 8
Training loss: 2.4671597480773926
Validation loss: 1.9599748862686979

Epoch: 5| Step: 9
Training loss: 1.998706579208374
Validation loss: 1.9309289775868899

Epoch: 5| Step: 10
Training loss: 1.4361475706100464
Validation loss: 1.9259529934134534

Epoch: 139| Step: 0
Training loss: 1.7432677745819092
Validation loss: 1.9928131295788674

Epoch: 5| Step: 1
Training loss: 2.0261664390563965
Validation loss: 1.9769418342139131

Epoch: 5| Step: 2
Training loss: 1.7833633422851562
Validation loss: 1.9537892931251115

Epoch: 5| Step: 3
Training loss: 2.7593843936920166
Validation loss: 1.9816176532417216

Epoch: 5| Step: 4
Training loss: 1.652737021446228
Validation loss: 1.998647641110164

Epoch: 5| Step: 5
Training loss: 1.7720741033554077
Validation loss: 1.963633644965387

Epoch: 5| Step: 6
Training loss: 1.9502636194229126
Validation loss: 1.96354627865617

Epoch: 5| Step: 7
Training loss: 2.124361991882324
Validation loss: 1.9454671593122586

Epoch: 5| Step: 8
Training loss: 2.7612829208374023
Validation loss: 1.9601795724643174

Epoch: 5| Step: 9
Training loss: 1.822351098060608
Validation loss: 1.9769684858219598

Epoch: 5| Step: 10
Training loss: 1.8913127183914185
Validation loss: 1.95583398495951

Epoch: 140| Step: 0
Training loss: 2.3586349487304688
Validation loss: 1.9554834878572853

Epoch: 5| Step: 1
Training loss: 2.1789145469665527
Validation loss: 1.9564789264432845

Epoch: 5| Step: 2
Training loss: 1.7588956356048584
Validation loss: 1.914423599038073

Epoch: 5| Step: 3
Training loss: 2.110187292098999
Validation loss: 1.8904850495758878

Epoch: 5| Step: 4
Training loss: 2.2131412029266357
Validation loss: 1.9343085494092715

Epoch: 5| Step: 5
Training loss: 1.8328603506088257
Validation loss: 1.9311218248900546

Epoch: 5| Step: 6
Training loss: 1.6044152975082397
Validation loss: 1.9337770015962663

Epoch: 5| Step: 7
Training loss: 1.8983901739120483
Validation loss: 1.9095852349394111

Epoch: 5| Step: 8
Training loss: 2.232992649078369
Validation loss: 1.9153630836035616

Epoch: 5| Step: 9
Training loss: 2.2238831520080566
Validation loss: 1.9571126507174583

Epoch: 5| Step: 10
Training loss: 1.9439181089401245
Validation loss: 1.945791204770406

Epoch: 141| Step: 0
Training loss: 2.0202198028564453
Validation loss: 1.9295232936900149

Epoch: 5| Step: 1
Training loss: 2.439643621444702
Validation loss: 1.9362617641366937

Epoch: 5| Step: 2
Training loss: 1.8165504932403564
Validation loss: 1.9059816970620105

Epoch: 5| Step: 3
Training loss: 2.4546749591827393
Validation loss: 1.9877480588933474

Epoch: 5| Step: 4
Training loss: 1.8885209560394287
Validation loss: 1.9522189235174527

Epoch: 5| Step: 5
Training loss: 2.3819308280944824
Validation loss: 1.9718005772559875

Epoch: 5| Step: 6
Training loss: 1.3038866519927979
Validation loss: 1.990488879142269

Epoch: 5| Step: 7
Training loss: 1.649645209312439
Validation loss: 1.967461516780238

Epoch: 5| Step: 8
Training loss: 2.415923833847046
Validation loss: 1.9583954554732128

Epoch: 5| Step: 9
Training loss: 1.8644206523895264
Validation loss: 1.9479269866020448

Epoch: 5| Step: 10
Training loss: 2.1759984493255615
Validation loss: 1.9856566805993356

Epoch: 142| Step: 0
Training loss: 1.5481784343719482
Validation loss: 1.9601839255261164

Epoch: 5| Step: 1
Training loss: 2.2573275566101074
Validation loss: 1.9570489006657754

Epoch: 5| Step: 2
Training loss: 1.8542811870574951
Validation loss: 1.966164626101012

Epoch: 5| Step: 3
Training loss: 2.1394734382629395
Validation loss: 1.982866584613759

Epoch: 5| Step: 4
Training loss: 2.0098443031311035
Validation loss: 1.998877913721146

Epoch: 5| Step: 5
Training loss: 2.3972980976104736
Validation loss: 1.9920169076611918

Epoch: 5| Step: 6
Training loss: 2.3712921142578125
Validation loss: 1.9521184275227208

Epoch: 5| Step: 7
Training loss: 2.073052406311035
Validation loss: 1.9313221759693597

Epoch: 5| Step: 8
Training loss: 1.713515043258667
Validation loss: 1.9759715859607985

Epoch: 5| Step: 9
Training loss: 2.0598669052124023
Validation loss: 1.9113293206819923

Epoch: 5| Step: 10
Training loss: 1.6814106702804565
Validation loss: 1.9674368186663556

Epoch: 143| Step: 0
Training loss: 1.8638874292373657
Validation loss: 1.967764494239643

Epoch: 5| Step: 1
Training loss: 2.0088813304901123
Validation loss: 1.9148266200096375

Epoch: 5| Step: 2
Training loss: 2.285710096359253
Validation loss: 1.9243194467277938

Epoch: 5| Step: 3
Training loss: 1.746642827987671
Validation loss: 1.9467501486501386

Epoch: 5| Step: 4
Training loss: 2.170799970626831
Validation loss: 1.9230210396551317

Epoch: 5| Step: 5
Training loss: 1.9506895542144775
Validation loss: 1.9571878448609383

Epoch: 5| Step: 6
Training loss: 1.7653179168701172
Validation loss: 1.9388839583243094

Epoch: 5| Step: 7
Training loss: 1.7821391820907593
Validation loss: 1.9262526509582356

Epoch: 5| Step: 8
Training loss: 1.4516613483428955
Validation loss: 1.9031831320895944

Epoch: 5| Step: 9
Training loss: 2.5058741569519043
Validation loss: 1.9353443640534596

Epoch: 5| Step: 10
Training loss: 2.6078343391418457
Validation loss: 1.9189570860196186

Epoch: 144| Step: 0
Training loss: 2.844167709350586
Validation loss: 1.936624784623423

Epoch: 5| Step: 1
Training loss: 2.112682580947876
Validation loss: 1.950202807303398

Epoch: 5| Step: 2
Training loss: 1.3807246685028076
Validation loss: 1.9545494330826627

Epoch: 5| Step: 3
Training loss: 2.0133025646209717
Validation loss: 1.9456333550073768

Epoch: 5| Step: 4
Training loss: 2.107793092727661
Validation loss: 1.9551423762434272

Epoch: 5| Step: 5
Training loss: 2.5593531131744385
Validation loss: 1.9311724324380197

Epoch: 5| Step: 6
Training loss: 1.33962082862854
Validation loss: 1.9560606018189461

Epoch: 5| Step: 7
Training loss: 1.6943376064300537
Validation loss: 1.9462160884693105

Epoch: 5| Step: 8
Training loss: 2.1430859565734863
Validation loss: 1.9411159253889514

Epoch: 5| Step: 9
Training loss: 1.7988412380218506
Validation loss: 1.9507427753940705

Epoch: 5| Step: 10
Training loss: 1.9549206495285034
Validation loss: 1.9549503275143203

Epoch: 145| Step: 0
Training loss: 2.6691524982452393
Validation loss: 1.9064938893882177

Epoch: 5| Step: 1
Training loss: 1.794562578201294
Validation loss: 1.912916503926759

Epoch: 5| Step: 2
Training loss: 2.5147156715393066
Validation loss: 1.9491498226760535

Epoch: 5| Step: 3
Training loss: 2.194064140319824
Validation loss: 1.9438515042745939

Epoch: 5| Step: 4
Training loss: 1.5402942895889282
Validation loss: 1.9561390440951112

Epoch: 5| Step: 5
Training loss: 1.7331196069717407
Validation loss: 1.9340046913393083

Epoch: 5| Step: 6
Training loss: 1.9447567462921143
Validation loss: 1.931825719853883

Epoch: 5| Step: 7
Training loss: 1.960034966468811
Validation loss: 1.963759046728893

Epoch: 5| Step: 8
Training loss: 2.1208879947662354
Validation loss: 1.9945999089107718

Epoch: 5| Step: 9
Training loss: 1.8348281383514404
Validation loss: 1.9598106927769159

Epoch: 5| Step: 10
Training loss: 1.6886094808578491
Validation loss: 1.9658305157897293

Epoch: 146| Step: 0
Training loss: 2.3243277072906494
Validation loss: 1.9756008271248109

Epoch: 5| Step: 1
Training loss: 2.2752883434295654
Validation loss: 1.94178177977121

Epoch: 5| Step: 2
Training loss: 1.9548406600952148
Validation loss: 1.9365884360446726

Epoch: 5| Step: 3
Training loss: 1.7939090728759766
Validation loss: 1.967072429195527

Epoch: 5| Step: 4
Training loss: 2.05104660987854
Validation loss: 1.957441960611651

Epoch: 5| Step: 5
Training loss: 2.074462890625
Validation loss: 1.9451001216006536

Epoch: 5| Step: 6
Training loss: 1.3875476121902466
Validation loss: 1.9505828888185563

Epoch: 5| Step: 7
Training loss: 2.3817317485809326
Validation loss: 1.9181639430343465

Epoch: 5| Step: 8
Training loss: 1.847409963607788
Validation loss: 1.9681475495779386

Epoch: 5| Step: 9
Training loss: 1.7784866094589233
Validation loss: 1.9612047467180478

Epoch: 5| Step: 10
Training loss: 2.0658280849456787
Validation loss: 1.9461199365636355

Epoch: 147| Step: 0
Training loss: 2.551398515701294
Validation loss: 1.9476137648346603

Epoch: 5| Step: 1
Training loss: 2.2969393730163574
Validation loss: 1.9556909863666823

Epoch: 5| Step: 2
Training loss: 1.9526193141937256
Validation loss: 1.9281301549685899

Epoch: 5| Step: 3
Training loss: 1.5980544090270996
Validation loss: 1.9574779182352045

Epoch: 5| Step: 4
Training loss: 1.7400802373886108
Validation loss: 1.9464960995540823

Epoch: 5| Step: 5
Training loss: 1.4783437252044678
Validation loss: 1.960259037633096

Epoch: 5| Step: 6
Training loss: 1.9844402074813843
Validation loss: 1.9739913953247892

Epoch: 5| Step: 7
Training loss: 1.8800420761108398
Validation loss: 1.957269214814709

Epoch: 5| Step: 8
Training loss: 2.265137195587158
Validation loss: 1.9563452377114245

Epoch: 5| Step: 9
Training loss: 1.8995037078857422
Validation loss: 1.9368331855343235

Epoch: 5| Step: 10
Training loss: 2.304269313812256
Validation loss: 1.9329717261816866

Epoch: 148| Step: 0
Training loss: 2.2318546772003174
Validation loss: 1.958434909902593

Epoch: 5| Step: 1
Training loss: 2.2294344902038574
Validation loss: 1.921974866620956

Epoch: 5| Step: 2
Training loss: 2.224879503250122
Validation loss: 1.9443209658386886

Epoch: 5| Step: 3
Training loss: 1.5871531963348389
Validation loss: 1.9770641006449217

Epoch: 5| Step: 4
Training loss: 2.3016648292541504
Validation loss: 1.9398341178894043

Epoch: 5| Step: 5
Training loss: 2.2978098392486572
Validation loss: 1.9273025284531295

Epoch: 5| Step: 6
Training loss: 1.9445559978485107
Validation loss: 1.9548631534781507

Epoch: 5| Step: 7
Training loss: 1.7760159969329834
Validation loss: 1.9310199727294266

Epoch: 5| Step: 8
Training loss: 2.016022205352783
Validation loss: 1.9488005663758965

Epoch: 5| Step: 9
Training loss: 1.4778386354446411
Validation loss: 1.9165599410251906

Epoch: 5| Step: 10
Training loss: 1.980981707572937
Validation loss: 1.9702370769234114

Epoch: 149| Step: 0
Training loss: 2.443610429763794
Validation loss: 1.9421424109448668

Epoch: 5| Step: 1
Training loss: 1.7917520999908447
Validation loss: 1.954954303720946

Epoch: 5| Step: 2
Training loss: 2.09541916847229
Validation loss: 1.939542757567539

Epoch: 5| Step: 3
Training loss: 2.060006618499756
Validation loss: 1.9718618598035587

Epoch: 5| Step: 4
Training loss: 1.7434622049331665
Validation loss: 1.9594066450672765

Epoch: 5| Step: 5
Training loss: 1.5631769895553589
Validation loss: 1.9424396702038345

Epoch: 5| Step: 6
Training loss: 1.9506433010101318
Validation loss: 1.9435624832748084

Epoch: 5| Step: 7
Training loss: 2.35244083404541
Validation loss: 1.9411716691909298

Epoch: 5| Step: 8
Training loss: 1.6378271579742432
Validation loss: 1.9483267440590808

Epoch: 5| Step: 9
Training loss: 2.318819284439087
Validation loss: 1.949591927630927

Epoch: 5| Step: 10
Training loss: 2.047304391860962
Validation loss: 1.973462603425467

Epoch: 150| Step: 0
Training loss: 2.1000161170959473
Validation loss: 1.9400183975055654

Epoch: 5| Step: 1
Training loss: 2.197556734085083
Validation loss: 1.969737378499841

Epoch: 5| Step: 2
Training loss: 2.245579957962036
Validation loss: 1.9705612967091222

Epoch: 5| Step: 3
Training loss: 2.36291766166687
Validation loss: 1.9721138528598252

Epoch: 5| Step: 4
Training loss: 1.4081426858901978
Validation loss: 1.998510342772289

Epoch: 5| Step: 5
Training loss: 1.4738719463348389
Validation loss: 1.9805212277238087

Epoch: 5| Step: 6
Training loss: 2.3019232749938965
Validation loss: 1.954956623815721

Epoch: 5| Step: 7
Training loss: 2.192754030227661
Validation loss: 1.9858725186317199

Epoch: 5| Step: 8
Training loss: 1.9531543254852295
Validation loss: 1.9418741528705885

Epoch: 5| Step: 9
Training loss: 1.6008154153823853
Validation loss: 1.9492137970462922

Epoch: 5| Step: 10
Training loss: 2.0107784271240234
Validation loss: 1.9372144411968928

Epoch: 151| Step: 0
Training loss: 2.010280132293701
Validation loss: 1.937580539334205

Epoch: 5| Step: 1
Training loss: 1.476244330406189
Validation loss: 1.9434169697505173

Epoch: 5| Step: 2
Training loss: 1.8164880275726318
Validation loss: 1.9595667123794556

Epoch: 5| Step: 3
Training loss: 2.8219480514526367
Validation loss: 1.9783344755890548

Epoch: 5| Step: 4
Training loss: 1.4891350269317627
Validation loss: 1.94485261876096

Epoch: 5| Step: 5
Training loss: 2.727384328842163
Validation loss: 1.9304594660318026

Epoch: 5| Step: 6
Training loss: 2.0386319160461426
Validation loss: 1.952237536830287

Epoch: 5| Step: 7
Training loss: 1.6460981369018555
Validation loss: 1.904729684193929

Epoch: 5| Step: 8
Training loss: 2.1796412467956543
Validation loss: 1.927184538174701

Epoch: 5| Step: 9
Training loss: 1.8255913257598877
Validation loss: 1.9355773618144374

Epoch: 5| Step: 10
Training loss: 1.9273439645767212
Validation loss: 1.942144501593805

Epoch: 152| Step: 0
Training loss: 2.282093048095703
Validation loss: 1.936816212951496

Epoch: 5| Step: 1
Training loss: 2.6113884449005127
Validation loss: 1.9434592121390886

Epoch: 5| Step: 2
Training loss: 1.7204681634902954
Validation loss: 1.929265268387333

Epoch: 5| Step: 3
Training loss: 2.124455213546753
Validation loss: 1.9316563644716818

Epoch: 5| Step: 4
Training loss: 1.6570861339569092
Validation loss: 1.9652843013886483

Epoch: 5| Step: 5
Training loss: 1.8610576391220093
Validation loss: 1.9569105896898495

Epoch: 5| Step: 6
Training loss: 1.702857255935669
Validation loss: 1.9385109357936408

Epoch: 5| Step: 7
Training loss: 2.1056602001190186
Validation loss: 1.9461782491335304

Epoch: 5| Step: 8
Training loss: 2.5246613025665283
Validation loss: 1.9140306980379167

Epoch: 5| Step: 9
Training loss: 1.5890300273895264
Validation loss: 1.9516283055787444

Epoch: 5| Step: 10
Training loss: 1.868821144104004
Validation loss: 1.9393650203622796

Epoch: 153| Step: 0
Training loss: 1.6265480518341064
Validation loss: 1.943651553123228

Epoch: 5| Step: 1
Training loss: 1.7696014642715454
Validation loss: 1.9394370150822464

Epoch: 5| Step: 2
Training loss: 1.6509361267089844
Validation loss: 1.9078678597686112

Epoch: 5| Step: 3
Training loss: 2.5727906227111816
Validation loss: 1.9442942488578059

Epoch: 5| Step: 4
Training loss: 2.4778854846954346
Validation loss: 1.937724728738108

Epoch: 5| Step: 5
Training loss: 1.8149611949920654
Validation loss: 1.9226506121696965

Epoch: 5| Step: 6
Training loss: 2.1124215126037598
Validation loss: 1.9416103132309452

Epoch: 5| Step: 7
Training loss: 1.2854537963867188
Validation loss: 1.9522013330972323

Epoch: 5| Step: 8
Training loss: 2.0635123252868652
Validation loss: 1.9259151784322595

Epoch: 5| Step: 9
Training loss: 2.3897016048431396
Validation loss: 1.990020554552796

Epoch: 5| Step: 10
Training loss: 1.9001853466033936
Validation loss: 1.9483914413759786

Epoch: 154| Step: 0
Training loss: 2.0969831943511963
Validation loss: 1.983385746197034

Epoch: 5| Step: 1
Training loss: 2.1518502235412598
Validation loss: 1.9528313221470002

Epoch: 5| Step: 2
Training loss: 1.8053417205810547
Validation loss: 1.963466795541907

Epoch: 5| Step: 3
Training loss: 1.7531874179840088
Validation loss: 1.9457233734028314

Epoch: 5| Step: 4
Training loss: 2.28273344039917
Validation loss: 1.933706888588526

Epoch: 5| Step: 5
Training loss: 2.134730577468872
Validation loss: 1.9251722687034196

Epoch: 5| Step: 6
Training loss: 1.2867830991744995
Validation loss: 1.9507431432765017

Epoch: 5| Step: 7
Training loss: 1.978647232055664
Validation loss: 1.9489421895755235

Epoch: 5| Step: 8
Training loss: 1.8751760721206665
Validation loss: 1.9448872843096334

Epoch: 5| Step: 9
Training loss: 2.3463306427001953
Validation loss: 1.9447976850694226

Epoch: 5| Step: 10
Training loss: 1.9968557357788086
Validation loss: 1.936803820312664

Epoch: 155| Step: 0
Training loss: 2.5388779640197754
Validation loss: 1.959416292046988

Epoch: 5| Step: 1
Training loss: 2.03644061088562
Validation loss: 1.9277738255839194

Epoch: 5| Step: 2
Training loss: 1.558223009109497
Validation loss: 1.9738493068243868

Epoch: 5| Step: 3
Training loss: 2.126391887664795
Validation loss: 1.9228430358312463

Epoch: 5| Step: 4
Training loss: 2.135695695877075
Validation loss: 1.944205484082622

Epoch: 5| Step: 5
Training loss: 1.6458278894424438
Validation loss: 1.9508276088263399

Epoch: 5| Step: 6
Training loss: 1.8366142511367798
Validation loss: 1.9300567949971845

Epoch: 5| Step: 7
Training loss: 1.9105333089828491
Validation loss: 1.9603967512807539

Epoch: 5| Step: 8
Training loss: 2.1522393226623535
Validation loss: 1.925545879589614

Epoch: 5| Step: 9
Training loss: 2.3696129322052
Validation loss: 1.9348131841228855

Epoch: 5| Step: 10
Training loss: 1.5960444211959839
Validation loss: 1.9639234273664412

Epoch: 156| Step: 0
Training loss: 2.3814797401428223
Validation loss: 1.9520817238797423

Epoch: 5| Step: 1
Training loss: 1.8647387027740479
Validation loss: 1.9590594307068856

Epoch: 5| Step: 2
Training loss: 1.5781404972076416
Validation loss: 1.9377662238254343

Epoch: 5| Step: 3
Training loss: 1.9543802738189697
Validation loss: 1.982004786050448

Epoch: 5| Step: 4
Training loss: 1.159483551979065
Validation loss: 1.9529873235251314

Epoch: 5| Step: 5
Training loss: 1.5790573358535767
Validation loss: 1.9735545060967887

Epoch: 5| Step: 6
Training loss: 2.3748464584350586
Validation loss: 1.9400138931889688

Epoch: 5| Step: 7
Training loss: 1.895729422569275
Validation loss: 1.9349685625363422

Epoch: 5| Step: 8
Training loss: 2.0745697021484375
Validation loss: 1.9775369205782491

Epoch: 5| Step: 9
Training loss: 2.479346513748169
Validation loss: 1.990186499011132

Epoch: 5| Step: 10
Training loss: 2.562826156616211
Validation loss: 1.9679441195662304

Epoch: 157| Step: 0
Training loss: 2.0546021461486816
Validation loss: 1.9752694765726726

Epoch: 5| Step: 1
Training loss: 2.2816224098205566
Validation loss: 1.9691460824781848

Epoch: 5| Step: 2
Training loss: 1.759935975074768
Validation loss: 1.9735674678638417

Epoch: 5| Step: 3
Training loss: 2.65114164352417
Validation loss: 1.9388202300635717

Epoch: 5| Step: 4
Training loss: 1.8650709390640259
Validation loss: 1.9789522911912651

Epoch: 5| Step: 5
Training loss: 1.6186336278915405
Validation loss: 1.9592877703328286

Epoch: 5| Step: 6
Training loss: 1.6825987100601196
Validation loss: 1.9441542266517557

Epoch: 5| Step: 7
Training loss: 1.9354496002197266
Validation loss: 1.9869374382880427

Epoch: 5| Step: 8
Training loss: 2.225496768951416
Validation loss: 1.9641076262279222

Epoch: 5| Step: 9
Training loss: 1.6330986022949219
Validation loss: 1.9495045113307174

Epoch: 5| Step: 10
Training loss: 2.023787498474121
Validation loss: 1.9485638449268956

Epoch: 158| Step: 0
Training loss: 1.6307792663574219
Validation loss: 1.966293243951695

Epoch: 5| Step: 1
Training loss: 2.3535022735595703
Validation loss: 1.954181868542907

Epoch: 5| Step: 2
Training loss: 2.0799055099487305
Validation loss: 2.0134909460621495

Epoch: 5| Step: 3
Training loss: 1.4596595764160156
Validation loss: 1.9506160290010515

Epoch: 5| Step: 4
Training loss: 1.8393945693969727
Validation loss: 1.9505854396409885

Epoch: 5| Step: 5
Training loss: 2.288198471069336
Validation loss: 1.9576635360717773

Epoch: 5| Step: 6
Training loss: 1.4220234155654907
Validation loss: 1.9771041895753594

Epoch: 5| Step: 7
Training loss: 2.179068088531494
Validation loss: 1.963099152811112

Epoch: 5| Step: 8
Training loss: 2.631114959716797
Validation loss: 1.9438253256582445

Epoch: 5| Step: 9
Training loss: 1.8298934698104858
Validation loss: 1.9601461733541181

Epoch: 5| Step: 10
Training loss: 1.9860377311706543
Validation loss: 1.931905133749849

Epoch: 159| Step: 0
Training loss: 2.5469868183135986
Validation loss: 1.9500825276938818

Epoch: 5| Step: 1
Training loss: 2.067247152328491
Validation loss: 1.9648391341650358

Epoch: 5| Step: 2
Training loss: 1.6200233697891235
Validation loss: 1.933331020416752

Epoch: 5| Step: 3
Training loss: 2.284029245376587
Validation loss: 1.938774852342503

Epoch: 5| Step: 4
Training loss: 2.197070360183716
Validation loss: 1.9306960721169748

Epoch: 5| Step: 5
Training loss: 1.844977617263794
Validation loss: 1.9870320443184144

Epoch: 5| Step: 6
Training loss: 2.001722812652588
Validation loss: 1.940832345716415

Epoch: 5| Step: 7
Training loss: 2.3700907230377197
Validation loss: 1.9670632898166616

Epoch: 5| Step: 8
Training loss: 2.001553535461426
Validation loss: 1.9681837597200948

Epoch: 5| Step: 9
Training loss: 1.643113136291504
Validation loss: 1.9300578358352825

Epoch: 5| Step: 10
Training loss: 1.0316565036773682
Validation loss: 1.9226139283949328

Epoch: 160| Step: 0
Training loss: 1.465656042098999
Validation loss: 1.9611389188356296

Epoch: 5| Step: 1
Training loss: 1.961731195449829
Validation loss: 1.9481006386459514

Epoch: 5| Step: 2
Training loss: 2.682349443435669
Validation loss: 1.959915494406095

Epoch: 5| Step: 3
Training loss: 1.7454828023910522
Validation loss: 1.9187638067430066

Epoch: 5| Step: 4
Training loss: 2.1035823822021484
Validation loss: 1.9869859308324835

Epoch: 5| Step: 5
Training loss: 1.975644826889038
Validation loss: 1.9462372244045298

Epoch: 5| Step: 6
Training loss: 2.1946487426757812
Validation loss: 1.9438552561626639

Epoch: 5| Step: 7
Training loss: 1.536694049835205
Validation loss: 1.9811818138245614

Epoch: 5| Step: 8
Training loss: 2.1645898818969727
Validation loss: 1.950946738643031

Epoch: 5| Step: 9
Training loss: 1.9947046041488647
Validation loss: 1.936396914143716

Epoch: 5| Step: 10
Training loss: 2.019486427307129
Validation loss: 1.9518782887407529

Epoch: 161| Step: 0
Training loss: 2.809706211090088
Validation loss: 1.9348528077525478

Epoch: 5| Step: 1
Training loss: 1.4795124530792236
Validation loss: 1.9102063512289396

Epoch: 5| Step: 2
Training loss: 1.8191044330596924
Validation loss: 1.9927503755015712

Epoch: 5| Step: 3
Training loss: 1.8002439737319946
Validation loss: 1.9101288536543488

Epoch: 5| Step: 4
Training loss: 2.016526460647583
Validation loss: 1.9717851197847756

Epoch: 5| Step: 5
Training loss: 2.4052321910858154
Validation loss: 1.9296734640675206

Epoch: 5| Step: 6
Training loss: 2.1500325202941895
Validation loss: 1.9326706983709847

Epoch: 5| Step: 7
Training loss: 1.8054172992706299
Validation loss: 1.9491700331370037

Epoch: 5| Step: 8
Training loss: 1.9810463190078735
Validation loss: 1.9416349190537647

Epoch: 5| Step: 9
Training loss: 1.8805177211761475
Validation loss: 1.9647416055843394

Epoch: 5| Step: 10
Training loss: 1.6574640274047852
Validation loss: 1.9191059591949626

Epoch: 162| Step: 0
Training loss: 2.2672829627990723
Validation loss: 1.9329447592458417

Epoch: 5| Step: 1
Training loss: 2.0806756019592285
Validation loss: 1.9568176410531486

Epoch: 5| Step: 2
Training loss: 1.9280288219451904
Validation loss: 1.9683962432287072

Epoch: 5| Step: 3
Training loss: 2.2367942333221436
Validation loss: 1.9519235023888208

Epoch: 5| Step: 4
Training loss: 1.6450977325439453
Validation loss: 1.9478353569584508

Epoch: 5| Step: 5
Training loss: 1.5582542419433594
Validation loss: 1.9427016576131184

Epoch: 5| Step: 6
Training loss: 1.9245026111602783
Validation loss: 1.946601576702569

Epoch: 5| Step: 7
Training loss: 1.9656717777252197
Validation loss: 1.9331276750051847

Epoch: 5| Step: 8
Training loss: 1.3646401166915894
Validation loss: 1.972788518474948

Epoch: 5| Step: 9
Training loss: 2.4943490028381348
Validation loss: 1.9564365930454706

Epoch: 5| Step: 10
Training loss: 2.041221857070923
Validation loss: 1.9777257570656397

Epoch: 163| Step: 0
Training loss: 1.8877360820770264
Validation loss: 1.9287671427572928

Epoch: 5| Step: 1
Training loss: 1.8859058618545532
Validation loss: 1.938208641544465

Epoch: 5| Step: 2
Training loss: 2.0566458702087402
Validation loss: 1.9344317259327057

Epoch: 5| Step: 3
Training loss: 1.9501597881317139
Validation loss: 1.9289929482244677

Epoch: 5| Step: 4
Training loss: 1.8842785358428955
Validation loss: 1.9355175469511299

Epoch: 5| Step: 5
Training loss: 1.8751081228256226
Validation loss: 1.9470966221183859

Epoch: 5| Step: 6
Training loss: 1.4041749238967896
Validation loss: 1.9423470599676973

Epoch: 5| Step: 7
Training loss: 1.922898530960083
Validation loss: 1.98488696159855

Epoch: 5| Step: 8
Training loss: 1.7736326456069946
Validation loss: 1.9566587607065837

Epoch: 5| Step: 9
Training loss: 2.567624568939209
Validation loss: 1.9394718216311546

Epoch: 5| Step: 10
Training loss: 2.014721155166626
Validation loss: 1.9439283160753147

Epoch: 164| Step: 0
Training loss: 2.1179585456848145
Validation loss: 1.97551388894358

Epoch: 5| Step: 1
Training loss: 2.6157007217407227
Validation loss: 1.9984696501044816

Epoch: 5| Step: 2
Training loss: 1.8789541721343994
Validation loss: 1.9496165424264886

Epoch: 5| Step: 3
Training loss: 2.0845377445220947
Validation loss: 1.923062930824936

Epoch: 5| Step: 4
Training loss: 1.449840784072876
Validation loss: 1.9365385745161323

Epoch: 5| Step: 5
Training loss: 1.754703164100647
Validation loss: 1.9549294594795472

Epoch: 5| Step: 6
Training loss: 2.0064613819122314
Validation loss: 1.9991551394103675

Epoch: 5| Step: 7
Training loss: 2.397632122039795
Validation loss: 1.9356019227735457

Epoch: 5| Step: 8
Training loss: 1.4329532384872437
Validation loss: 1.958638503987302

Epoch: 5| Step: 9
Training loss: 1.7811920642852783
Validation loss: 1.9668450022256503

Epoch: 5| Step: 10
Training loss: 1.8511749505996704
Validation loss: 1.9426457343562957

Epoch: 165| Step: 0
Training loss: 2.0709807872772217
Validation loss: 2.0008175578168643

Epoch: 5| Step: 1
Training loss: 1.3401155471801758
Validation loss: 1.9572882203645603

Epoch: 5| Step: 2
Training loss: 1.799146056175232
Validation loss: 1.987918858887047

Epoch: 5| Step: 3
Training loss: 1.7557423114776611
Validation loss: 1.9403971190093665

Epoch: 5| Step: 4
Training loss: 2.341902732849121
Validation loss: 1.9656443262612948

Epoch: 5| Step: 5
Training loss: 2.0121207237243652
Validation loss: 1.9624375450995661

Epoch: 5| Step: 6
Training loss: 2.034749746322632
Validation loss: 1.9720768364526893

Epoch: 5| Step: 7
Training loss: 2.1250433921813965
Validation loss: 1.92680492965124

Epoch: 5| Step: 8
Training loss: 1.9680912494659424
Validation loss: 1.9753761009503437

Epoch: 5| Step: 9
Training loss: 2.2621192932128906
Validation loss: 1.969482228320132

Epoch: 5| Step: 10
Training loss: 1.8562395572662354
Validation loss: 1.9581374634978592

Epoch: 166| Step: 0
Training loss: 1.8479557037353516
Validation loss: 1.955892389820468

Epoch: 5| Step: 1
Training loss: 2.051426410675049
Validation loss: 1.957204100906208

Epoch: 5| Step: 2
Training loss: 1.8974835872650146
Validation loss: 1.9917307156388477

Epoch: 5| Step: 3
Training loss: 2.0455269813537598
Validation loss: 1.9365885001356884

Epoch: 5| Step: 4
Training loss: 1.9874910116195679
Validation loss: 1.9775379883345736

Epoch: 5| Step: 5
Training loss: 1.913998007774353
Validation loss: 1.9376835848695488

Epoch: 5| Step: 6
Training loss: 2.212531566619873
Validation loss: 1.9539259249164211

Epoch: 5| Step: 7
Training loss: 1.7508862018585205
Validation loss: 1.9338511267016012

Epoch: 5| Step: 8
Training loss: 1.609816312789917
Validation loss: 1.9519250572368663

Epoch: 5| Step: 9
Training loss: 2.307877540588379
Validation loss: 1.9567499058220976

Epoch: 5| Step: 10
Training loss: 2.0982563495635986
Validation loss: 1.9558185210791967

Epoch: 167| Step: 0
Training loss: 2.412644863128662
Validation loss: 1.952739413066577

Epoch: 5| Step: 1
Training loss: 1.65264892578125
Validation loss: 1.960597235669372

Epoch: 5| Step: 2
Training loss: 1.998752236366272
Validation loss: 1.9401917649853615

Epoch: 5| Step: 3
Training loss: 1.84931218624115
Validation loss: 1.9736815998631139

Epoch: 5| Step: 4
Training loss: 1.8402036428451538
Validation loss: 1.9598401041441067

Epoch: 5| Step: 5
Training loss: 1.7307722568511963
Validation loss: 1.9574320662406184

Epoch: 5| Step: 6
Training loss: 2.1183981895446777
Validation loss: 1.9484004179636638

Epoch: 5| Step: 7
Training loss: 2.008579969406128
Validation loss: 1.945132746491381

Epoch: 5| Step: 8
Training loss: 2.1130988597869873
Validation loss: 1.9585143212349183

Epoch: 5| Step: 9
Training loss: 1.4262300729751587
Validation loss: 1.9706619785678001

Epoch: 5| Step: 10
Training loss: 2.0262808799743652
Validation loss: 1.9762651920318604

Epoch: 168| Step: 0
Training loss: 1.7888526916503906
Validation loss: 1.984781669032189

Epoch: 5| Step: 1
Training loss: 1.4244554042816162
Validation loss: 1.963871148324782

Epoch: 5| Step: 2
Training loss: 2.125619649887085
Validation loss: 1.982014024129478

Epoch: 5| Step: 3
Training loss: 2.6178159713745117
Validation loss: 1.9819085367264286

Epoch: 5| Step: 4
Training loss: 2.470588207244873
Validation loss: 2.008133554971346

Epoch: 5| Step: 5
Training loss: 2.0205883979797363
Validation loss: 1.9882408880418347

Epoch: 5| Step: 6
Training loss: 1.28746497631073
Validation loss: 1.9932050628046836

Epoch: 5| Step: 7
Training loss: 2.112743377685547
Validation loss: 1.9888328390736734

Epoch: 5| Step: 8
Training loss: 1.9200623035430908
Validation loss: 2.00717092329456

Epoch: 5| Step: 9
Training loss: 2.1531224250793457
Validation loss: 1.9612715180202196

Epoch: 5| Step: 10
Training loss: 1.4613323211669922
Validation loss: 1.9924934730734876

Epoch: 169| Step: 0
Training loss: 2.0584895610809326
Validation loss: 1.9565153942313245

Epoch: 5| Step: 1
Training loss: 1.7420517206192017
Validation loss: 1.972919165447194

Epoch: 5| Step: 2
Training loss: 1.9404151439666748
Validation loss: 1.9735600127968738

Epoch: 5| Step: 3
Training loss: 1.8739938735961914
Validation loss: 1.9802474808949295

Epoch: 5| Step: 4
Training loss: 2.2823803424835205
Validation loss: 1.9707468645547026

Epoch: 5| Step: 5
Training loss: 2.057232618331909
Validation loss: 1.9546566188976329

Epoch: 5| Step: 6
Training loss: 1.8384824991226196
Validation loss: 2.0051229333364837

Epoch: 5| Step: 7
Training loss: 2.3866074085235596
Validation loss: 1.9692141189370105

Epoch: 5| Step: 8
Training loss: 1.8537229299545288
Validation loss: 1.964817713665706

Epoch: 5| Step: 9
Training loss: 1.5970497131347656
Validation loss: 1.982877342931686

Epoch: 5| Step: 10
Training loss: 1.578068494796753
Validation loss: 1.9529906485670356

Epoch: 170| Step: 0
Training loss: 2.0778989791870117
Validation loss: 1.9633546196004397

Epoch: 5| Step: 1
Training loss: 1.630502462387085
Validation loss: 1.964312550842121

Epoch: 5| Step: 2
Training loss: 2.056861162185669
Validation loss: 1.9633557335022958

Epoch: 5| Step: 3
Training loss: 1.787559151649475
Validation loss: 1.9277884947356356

Epoch: 5| Step: 4
Training loss: 2.371948719024658
Validation loss: 1.9356997795002435

Epoch: 5| Step: 5
Training loss: 1.5893045663833618
Validation loss: 1.968360206132294

Epoch: 5| Step: 6
Training loss: 2.33552622795105
Validation loss: 1.9462287605449717

Epoch: 5| Step: 7
Training loss: 1.6663490533828735
Validation loss: 1.9765147393749607

Epoch: 5| Step: 8
Training loss: 1.9127113819122314
Validation loss: 1.9346762498219807

Epoch: 5| Step: 9
Training loss: 1.9778728485107422
Validation loss: 1.9542592289627239

Epoch: 5| Step: 10
Training loss: 2.0757219791412354
Validation loss: 1.9624238232130646

Epoch: 171| Step: 0
Training loss: 1.6378765106201172
Validation loss: 1.91830869900283

Epoch: 5| Step: 1
Training loss: 2.2911791801452637
Validation loss: 1.9296234807660502

Epoch: 5| Step: 2
Training loss: 2.2698864936828613
Validation loss: 1.9391806984460482

Epoch: 5| Step: 3
Training loss: 1.8489042520523071
Validation loss: 1.997711702059674

Epoch: 5| Step: 4
Training loss: 1.9278614521026611
Validation loss: 1.9625430055843887

Epoch: 5| Step: 5
Training loss: 1.8692127466201782
Validation loss: 1.9260775030300181

Epoch: 5| Step: 6
Training loss: 1.5576331615447998
Validation loss: 1.9640308913364206

Epoch: 5| Step: 7
Training loss: 1.4866331815719604
Validation loss: 1.974998342093601

Epoch: 5| Step: 8
Training loss: 1.8584716320037842
Validation loss: 1.9619945505613923

Epoch: 5| Step: 9
Training loss: 1.8418251276016235
Validation loss: 1.9609763814556984

Epoch: 5| Step: 10
Training loss: 2.688066244125366
Validation loss: 1.9584848380857898

Epoch: 172| Step: 0
Training loss: 1.5811420679092407
Validation loss: 1.9466797664601316

Epoch: 5| Step: 1
Training loss: 2.056248664855957
Validation loss: 1.9560144011692335

Epoch: 5| Step: 2
Training loss: 2.245598316192627
Validation loss: 1.9676747475900958

Epoch: 5| Step: 3
Training loss: 1.2301499843597412
Validation loss: 1.9443148900103826

Epoch: 5| Step: 4
Training loss: 2.8062124252319336
Validation loss: 1.9814954060380177

Epoch: 5| Step: 5
Training loss: 1.70176100730896
Validation loss: 1.9805862237048406

Epoch: 5| Step: 6
Training loss: 1.6859363317489624
Validation loss: 1.9884409955752793

Epoch: 5| Step: 7
Training loss: 2.169734239578247
Validation loss: 1.9575818918084587

Epoch: 5| Step: 8
Training loss: 1.5418589115142822
Validation loss: 1.9588486866284442

Epoch: 5| Step: 9
Training loss: 1.8735195398330688
Validation loss: 1.9339944367767663

Epoch: 5| Step: 10
Training loss: 2.530337333679199
Validation loss: 1.9610438116135136

Epoch: 173| Step: 0
Training loss: 1.9699760675430298
Validation loss: 1.9754197815413117

Epoch: 5| Step: 1
Training loss: 1.6421149969100952
Validation loss: 1.946120023727417

Epoch: 5| Step: 2
Training loss: 1.7181965112686157
Validation loss: 1.9562890555268975

Epoch: 5| Step: 3
Training loss: 1.4178388118743896
Validation loss: 1.9489273896781347

Epoch: 5| Step: 4
Training loss: 1.7836487293243408
Validation loss: 1.9659338933165356

Epoch: 5| Step: 5
Training loss: 1.8069441318511963
Validation loss: 1.9287522108324113

Epoch: 5| Step: 6
Training loss: 3.3226921558380127
Validation loss: 1.9440437363040062

Epoch: 5| Step: 7
Training loss: 1.9737231731414795
Validation loss: 1.9180101489508024

Epoch: 5| Step: 8
Training loss: 1.6775181293487549
Validation loss: 1.9537144655822425

Epoch: 5| Step: 9
Training loss: 2.39052152633667
Validation loss: 1.9622737412811608

Epoch: 5| Step: 10
Training loss: 1.4286810159683228
Validation loss: 1.9407580257743917

Epoch: 174| Step: 0
Training loss: 2.340674877166748
Validation loss: 1.9607500773604198

Epoch: 5| Step: 1
Training loss: 2.19783091545105
Validation loss: 1.9394365202996038

Epoch: 5| Step: 2
Training loss: 2.38326358795166
Validation loss: 1.964000073812341

Epoch: 5| Step: 3
Training loss: 1.7206100225448608
Validation loss: 1.967214274150069

Epoch: 5| Step: 4
Training loss: 2.0992507934570312
Validation loss: 1.955879936936081

Epoch: 5| Step: 5
Training loss: 1.7763986587524414
Validation loss: 1.945321326614708

Epoch: 5| Step: 6
Training loss: 1.4407879114151
Validation loss: 1.955139011465093

Epoch: 5| Step: 7
Training loss: 1.7495815753936768
Validation loss: 1.9389910313390917

Epoch: 5| Step: 8
Training loss: 1.531578779220581
Validation loss: 1.9715954424232565

Epoch: 5| Step: 9
Training loss: 1.9124622344970703
Validation loss: 1.9594729408141105

Epoch: 5| Step: 10
Training loss: 1.7567700147628784
Validation loss: 1.9581743209592757

Epoch: 175| Step: 0
Training loss: 1.9625526666641235
Validation loss: 1.9651984014818746

Epoch: 5| Step: 1
Training loss: 2.098932981491089
Validation loss: 1.9591170959575201

Epoch: 5| Step: 2
Training loss: 1.8926112651824951
Validation loss: 1.9661968856729486

Epoch: 5| Step: 3
Training loss: 1.9691498279571533
Validation loss: 1.9510227986561355

Epoch: 5| Step: 4
Training loss: 2.0145938396453857
Validation loss: 1.9442937886843117

Epoch: 5| Step: 5
Training loss: 1.500213623046875
Validation loss: 1.9707529596103135

Epoch: 5| Step: 6
Training loss: 1.7863500118255615
Validation loss: 1.9487788420851513

Epoch: 5| Step: 7
Training loss: 2.0539400577545166
Validation loss: 1.9863631315128778

Epoch: 5| Step: 8
Training loss: 1.883557677268982
Validation loss: 1.9494834638410998

Epoch: 5| Step: 9
Training loss: 2.173182725906372
Validation loss: 1.963225185230214

Epoch: 5| Step: 10
Training loss: 1.8617279529571533
Validation loss: 1.9511486291885376

Epoch: 176| Step: 0
Training loss: 1.2447280883789062
Validation loss: 1.9380896014551963

Epoch: 5| Step: 1
Training loss: 1.7908216714859009
Validation loss: 1.9519090383283553

Epoch: 5| Step: 2
Training loss: 1.5885870456695557
Validation loss: 1.9646170370040401

Epoch: 5| Step: 3
Training loss: 2.5270094871520996
Validation loss: 1.9754562839385001

Epoch: 5| Step: 4
Training loss: 2.4777398109436035
Validation loss: 1.9704281309599518

Epoch: 5| Step: 5
Training loss: 1.712181806564331
Validation loss: 1.9484459687304754

Epoch: 5| Step: 6
Training loss: 1.7158000469207764
Validation loss: 1.9755632556894773

Epoch: 5| Step: 7
Training loss: 1.7888743877410889
Validation loss: 1.9440515105442335

Epoch: 5| Step: 8
Training loss: 2.1359715461730957
Validation loss: 1.9573982659206595

Epoch: 5| Step: 9
Training loss: 1.9252843856811523
Validation loss: 1.9578979874169955

Epoch: 5| Step: 10
Training loss: 2.389692544937134
Validation loss: 1.9709394170391945

Epoch: 177| Step: 0
Training loss: 2.004150152206421
Validation loss: 1.9489046886403074

Epoch: 5| Step: 1
Training loss: 2.0748372077941895
Validation loss: 1.9658118191585745

Epoch: 5| Step: 2
Training loss: 1.9065399169921875
Validation loss: 1.9496405957847514

Epoch: 5| Step: 3
Training loss: 1.2113109827041626
Validation loss: 1.9737368373460666

Epoch: 5| Step: 4
Training loss: 1.4527171850204468
Validation loss: 1.9604125202343028

Epoch: 5| Step: 5
Training loss: 2.182551622390747
Validation loss: 1.9714799978399788

Epoch: 5| Step: 6
Training loss: 2.5123190879821777
Validation loss: 1.972402455986187

Epoch: 5| Step: 7
Training loss: 2.2330589294433594
Validation loss: 1.95898776413292

Epoch: 5| Step: 8
Training loss: 1.4822900295257568
Validation loss: 1.966931099532753

Epoch: 5| Step: 9
Training loss: 2.028475522994995
Validation loss: 1.9496664808642479

Epoch: 5| Step: 10
Training loss: 2.2265517711639404
Validation loss: 1.9558161971389607

Epoch: 178| Step: 0
Training loss: 2.113018035888672
Validation loss: 1.9403791786521993

Epoch: 5| Step: 1
Training loss: 2.1444666385650635
Validation loss: 1.958902842255049

Epoch: 5| Step: 2
Training loss: 2.308526039123535
Validation loss: 1.9502147461778374

Epoch: 5| Step: 3
Training loss: 2.0435333251953125
Validation loss: 1.9517393804365588

Epoch: 5| Step: 4
Training loss: 1.5042320489883423
Validation loss: 1.95210434544471

Epoch: 5| Step: 5
Training loss: 1.3015317916870117
Validation loss: 1.9954600282894668

Epoch: 5| Step: 6
Training loss: 2.107944965362549
Validation loss: 1.9928799380538285

Epoch: 5| Step: 7
Training loss: 1.7755424976348877
Validation loss: 1.9575264364160516

Epoch: 5| Step: 8
Training loss: 1.642183542251587
Validation loss: 1.9841961565838064

Epoch: 5| Step: 9
Training loss: 2.146392345428467
Validation loss: 1.98450606612749

Epoch: 5| Step: 10
Training loss: 2.1180288791656494
Validation loss: 1.9518457202501194

Epoch: 179| Step: 0
Training loss: 2.2400283813476562
Validation loss: 1.9955338060214955

Epoch: 5| Step: 1
Training loss: 2.01332688331604
Validation loss: 1.9786548665774766

Epoch: 5| Step: 2
Training loss: 1.442915916442871
Validation loss: 1.9736081118224769

Epoch: 5| Step: 3
Training loss: 1.6837600469589233
Validation loss: 1.9766691718050229

Epoch: 5| Step: 4
Training loss: 2.071917772293091
Validation loss: 1.9764392004218152

Epoch: 5| Step: 5
Training loss: 1.709256887435913
Validation loss: 1.9475687626869447

Epoch: 5| Step: 6
Training loss: 2.0572288036346436
Validation loss: 1.9530819436555267

Epoch: 5| Step: 7
Training loss: 2.3302512168884277
Validation loss: 1.9593418695593392

Epoch: 5| Step: 8
Training loss: 2.1686553955078125
Validation loss: 1.9859470103376655

Epoch: 5| Step: 9
Training loss: 1.4967353343963623
Validation loss: 1.9859497085694344

Epoch: 5| Step: 10
Training loss: 1.721595287322998
Validation loss: 1.9689620848624938

Epoch: 180| Step: 0
Training loss: 1.6783491373062134
Validation loss: 1.9792305372094596

Epoch: 5| Step: 1
Training loss: 2.1767148971557617
Validation loss: 1.9581494126268613

Epoch: 5| Step: 2
Training loss: 1.4898507595062256
Validation loss: 1.980978870904574

Epoch: 5| Step: 3
Training loss: 1.6888210773468018
Validation loss: 1.9468197630297752

Epoch: 5| Step: 4
Training loss: 2.211019515991211
Validation loss: 1.9348215877368886

Epoch: 5| Step: 5
Training loss: 1.629699468612671
Validation loss: 1.9633877303010674

Epoch: 5| Step: 6
Training loss: 1.9616645574569702
Validation loss: 1.9734005671675487

Epoch: 5| Step: 7
Training loss: 1.5890920162200928
Validation loss: 1.9602141431582871

Epoch: 5| Step: 8
Training loss: 1.8980610370635986
Validation loss: 1.967379113679291

Epoch: 5| Step: 9
Training loss: 2.6799774169921875
Validation loss: 1.9639777316842029

Epoch: 5| Step: 10
Training loss: 2.0663795471191406
Validation loss: 1.9638878312162174

Epoch: 181| Step: 0
Training loss: 1.8090318441390991
Validation loss: 1.9436510006586711

Epoch: 5| Step: 1
Training loss: 1.4187955856323242
Validation loss: 1.981856248712027

Epoch: 5| Step: 2
Training loss: 1.421933889389038
Validation loss: 1.9387095987155873

Epoch: 5| Step: 3
Training loss: 1.8244892358779907
Validation loss: 1.9492809900673487

Epoch: 5| Step: 4
Training loss: 2.2156333923339844
Validation loss: 1.9690211460154543

Epoch: 5| Step: 5
Training loss: 2.0960609912872314
Validation loss: 1.9797566270315519

Epoch: 5| Step: 6
Training loss: 1.8212846517562866
Validation loss: 1.9288269332660142

Epoch: 5| Step: 7
Training loss: 1.86477792263031
Validation loss: 1.944718490364731

Epoch: 5| Step: 8
Training loss: 2.164433240890503
Validation loss: 1.9566071084750596

Epoch: 5| Step: 9
Training loss: 2.4358956813812256
Validation loss: 1.980922713074633

Epoch: 5| Step: 10
Training loss: 1.842903733253479
Validation loss: 1.984219802323208

Epoch: 182| Step: 0
Training loss: 1.5178784132003784
Validation loss: 1.9241015462465183

Epoch: 5| Step: 1
Training loss: 2.4751932621002197
Validation loss: 1.957052546162759

Epoch: 5| Step: 2
Training loss: 2.13525390625
Validation loss: 1.9770004454479422

Epoch: 5| Step: 3
Training loss: 1.6709827184677124
Validation loss: 1.9484064271373134

Epoch: 5| Step: 4
Training loss: 2.3396878242492676
Validation loss: 1.9287244709589149

Epoch: 5| Step: 5
Training loss: 1.5807428359985352
Validation loss: 1.9945587086421188

Epoch: 5| Step: 6
Training loss: 2.198079824447632
Validation loss: 1.9720930694251932

Epoch: 5| Step: 7
Training loss: 1.6646640300750732
Validation loss: 1.9632443920258553

Epoch: 5| Step: 8
Training loss: 1.4019278287887573
Validation loss: 1.9557664202105614

Epoch: 5| Step: 9
Training loss: 1.680720329284668
Validation loss: 1.9969111437438636

Epoch: 5| Step: 10
Training loss: 2.6055288314819336
Validation loss: 1.9846170204941944

Epoch: 183| Step: 0
Training loss: 2.3925893306732178
Validation loss: 1.9915604001732283

Epoch: 5| Step: 1
Training loss: 1.6686149835586548
Validation loss: 1.982585032780965

Epoch: 5| Step: 2
Training loss: 1.6955463886260986
Validation loss: 1.981339636669364

Epoch: 5| Step: 3
Training loss: 1.557905673980713
Validation loss: 1.965398003978114

Epoch: 5| Step: 4
Training loss: 1.9587711095809937
Validation loss: 1.9811263494594122

Epoch: 5| Step: 5
Training loss: 2.479153871536255
Validation loss: 1.9719738357810563

Epoch: 5| Step: 6
Training loss: 2.2539515495300293
Validation loss: 1.9549505249146493

Epoch: 5| Step: 7
Training loss: 1.885695219039917
Validation loss: 1.9709362752975956

Epoch: 5| Step: 8
Training loss: 1.561464548110962
Validation loss: 1.9518760904189079

Epoch: 5| Step: 9
Training loss: 1.9517309665679932
Validation loss: 1.961163374685472

Epoch: 5| Step: 10
Training loss: 1.453624963760376
Validation loss: 1.9685653191740795

Epoch: 184| Step: 0
Training loss: 2.2406630516052246
Validation loss: 1.9536895636589295

Epoch: 5| Step: 1
Training loss: 1.7796728610992432
Validation loss: 1.9670393672040714

Epoch: 5| Step: 2
Training loss: 1.434168815612793
Validation loss: 1.9437705470669655

Epoch: 5| Step: 3
Training loss: 1.738001823425293
Validation loss: 1.9651696989613194

Epoch: 5| Step: 4
Training loss: 1.9139522314071655
Validation loss: 1.965916177277924

Epoch: 5| Step: 5
Training loss: 2.2239270210266113
Validation loss: 1.94762300163187

Epoch: 5| Step: 6
Training loss: 2.0981435775756836
Validation loss: 1.9635462619925057

Epoch: 5| Step: 7
Training loss: 1.4763264656066895
Validation loss: 1.947364104691372

Epoch: 5| Step: 8
Training loss: 1.6125338077545166
Validation loss: 1.9611369717505671

Epoch: 5| Step: 9
Training loss: 1.557761549949646
Validation loss: 1.9810402649705128

Epoch: 5| Step: 10
Training loss: 2.861809492111206
Validation loss: 1.996983725537536

Epoch: 185| Step: 0
Training loss: 1.9743667840957642
Validation loss: 1.9408007885820122

Epoch: 5| Step: 1
Training loss: 1.4453632831573486
Validation loss: 1.9701180240159393

Epoch: 5| Step: 2
Training loss: 2.02842378616333
Validation loss: 1.9214106105989026

Epoch: 5| Step: 3
Training loss: 2.570669412612915
Validation loss: 1.9747374365406651

Epoch: 5| Step: 4
Training loss: 1.643471121788025
Validation loss: 1.9560759439263293

Epoch: 5| Step: 5
Training loss: 1.613288164138794
Validation loss: 1.9811040944950555

Epoch: 5| Step: 6
Training loss: 2.2823116779327393
Validation loss: 1.9723141385662941

Epoch: 5| Step: 7
Training loss: 1.7276391983032227
Validation loss: 1.9648444588466356

Epoch: 5| Step: 8
Training loss: 1.4118691682815552
Validation loss: 1.9698521398728894

Epoch: 5| Step: 9
Training loss: 2.01653790473938
Validation loss: 1.9973555380298245

Epoch: 5| Step: 10
Training loss: 1.9079620838165283
Validation loss: 1.9577860140031385

Epoch: 186| Step: 0
Training loss: 2.863534450531006
Validation loss: 1.9813764890034993

Epoch: 5| Step: 1
Training loss: 1.475003957748413
Validation loss: 1.9600408384876866

Epoch: 5| Step: 2
Training loss: 1.835384726524353
Validation loss: 1.9488532620091592

Epoch: 5| Step: 3
Training loss: 1.8425846099853516
Validation loss: 1.9870480311814176

Epoch: 5| Step: 4
Training loss: 2.5974068641662598
Validation loss: 2.006606830063687

Epoch: 5| Step: 5
Training loss: 2.290560245513916
Validation loss: 1.9755939950225174

Epoch: 5| Step: 6
Training loss: 1.980053186416626
Validation loss: 1.9685424091995403

Epoch: 5| Step: 7
Training loss: 1.499729871749878
Validation loss: 1.9929315787489696

Epoch: 5| Step: 8
Training loss: 1.4021289348602295
Validation loss: 2.009854183402113

Epoch: 5| Step: 9
Training loss: 1.6418994665145874
Validation loss: 1.9937552687942341

Epoch: 5| Step: 10
Training loss: 1.522035002708435
Validation loss: 1.9782969746538388

Epoch: 187| Step: 0
Training loss: 1.5182243585586548
Validation loss: 2.0011843045552573

Epoch: 5| Step: 1
Training loss: 2.290727138519287
Validation loss: 1.9555979595389417

Epoch: 5| Step: 2
Training loss: 1.8596556186676025
Validation loss: 1.9668605455788233

Epoch: 5| Step: 3
Training loss: 1.860870361328125
Validation loss: 2.005163949023011

Epoch: 5| Step: 4
Training loss: 1.7844489812850952
Validation loss: 1.9330085567248765

Epoch: 5| Step: 5
Training loss: 2.2581965923309326
Validation loss: 1.9528793801543534

Epoch: 5| Step: 6
Training loss: 1.562049150466919
Validation loss: 1.9529811669421453

Epoch: 5| Step: 7
Training loss: 1.912337064743042
Validation loss: 1.9400786251150153

Epoch: 5| Step: 8
Training loss: 2.0943071842193604
Validation loss: 1.9455424419013403

Epoch: 5| Step: 9
Training loss: 1.9773683547973633
Validation loss: 1.989676703688919

Epoch: 5| Step: 10
Training loss: 1.97139310836792
Validation loss: 1.9317325468986266

Epoch: 188| Step: 0
Training loss: 1.735905647277832
Validation loss: 1.9571623020274664

Epoch: 5| Step: 1
Training loss: 1.8627287149429321
Validation loss: 1.984637641137646

Epoch: 5| Step: 2
Training loss: 2.071669578552246
Validation loss: 1.9342810248815885

Epoch: 5| Step: 3
Training loss: 1.7891385555267334
Validation loss: 1.9715669411484913

Epoch: 5| Step: 4
Training loss: 1.6992571353912354
Validation loss: 1.9394801188540716

Epoch: 5| Step: 5
Training loss: 1.7246471643447876
Validation loss: 1.970415041010867

Epoch: 5| Step: 6
Training loss: 1.9874337911605835
Validation loss: 1.9906932013009184

Epoch: 5| Step: 7
Training loss: 1.708325982093811
Validation loss: 1.9565379696507608

Epoch: 5| Step: 8
Training loss: 2.1666321754455566
Validation loss: 1.9812031676692348

Epoch: 5| Step: 9
Training loss: 1.9787298440933228
Validation loss: 1.9770873874746344

Epoch: 5| Step: 10
Training loss: 1.9508213996887207
Validation loss: 1.98186328077829

Epoch: 189| Step: 0
Training loss: 2.175833225250244
Validation loss: 1.997980188297969

Epoch: 5| Step: 1
Training loss: 2.3901588916778564
Validation loss: 1.9659146134571364

Epoch: 5| Step: 2
Training loss: 1.5071264505386353
Validation loss: 2.0119693279266357

Epoch: 5| Step: 3
Training loss: 1.6246826648712158
Validation loss: 2.0098376222836074

Epoch: 5| Step: 4
Training loss: 1.6933265924453735
Validation loss: 1.9723088408029208

Epoch: 5| Step: 5
Training loss: 1.8126041889190674
Validation loss: 1.9972037192313903

Epoch: 5| Step: 6
Training loss: 2.356232166290283
Validation loss: 1.9622761639215613

Epoch: 5| Step: 7
Training loss: 1.8944852352142334
Validation loss: 1.9685405082600091

Epoch: 5| Step: 8
Training loss: 1.9248653650283813
Validation loss: 1.9813662844319497

Epoch: 5| Step: 9
Training loss: 1.7469608783721924
Validation loss: 1.9462748150671683

Epoch: 5| Step: 10
Training loss: 1.8025468587875366
Validation loss: 1.9794495913290209

Epoch: 190| Step: 0
Training loss: 1.9745413064956665
Validation loss: 1.997825361067249

Epoch: 5| Step: 1
Training loss: 1.584266185760498
Validation loss: 1.9651977913354033

Epoch: 5| Step: 2
Training loss: 2.10406756401062
Validation loss: 1.9471366918215187

Epoch: 5| Step: 3
Training loss: 2.394549608230591
Validation loss: 2.0039103569522982

Epoch: 5| Step: 4
Training loss: 1.8608360290527344
Validation loss: 1.9849525343987249

Epoch: 5| Step: 5
Training loss: 1.6326961517333984
Validation loss: 1.9592956086640716

Epoch: 5| Step: 6
Training loss: 1.5296785831451416
Validation loss: 2.0071286693696053

Epoch: 5| Step: 7
Training loss: 1.6698306798934937
Validation loss: 1.9921603907821

Epoch: 5| Step: 8
Training loss: 1.6932117938995361
Validation loss: 1.9552598922483382

Epoch: 5| Step: 9
Training loss: 2.155893087387085
Validation loss: 1.9747410897285707

Epoch: 5| Step: 10
Training loss: 2.1445064544677734
Validation loss: 1.9479765520300916

Epoch: 191| Step: 0
Training loss: 2.0783658027648926
Validation loss: 1.948353018811954

Epoch: 5| Step: 1
Training loss: 1.3125909566879272
Validation loss: 1.9463401122759747

Epoch: 5| Step: 2
Training loss: 1.7389955520629883
Validation loss: 1.9597024122873943

Epoch: 5| Step: 3
Training loss: 2.0241196155548096
Validation loss: 1.9799852601943477

Epoch: 5| Step: 4
Training loss: 2.1826796531677246
Validation loss: 1.9755106408108947

Epoch: 5| Step: 5
Training loss: 1.4344011545181274
Validation loss: 2.0094951480947514

Epoch: 5| Step: 6
Training loss: 2.179431915283203
Validation loss: 1.9544119232444352

Epoch: 5| Step: 7
Training loss: 1.681702971458435
Validation loss: 1.9642770008374286

Epoch: 5| Step: 8
Training loss: 2.231417417526245
Validation loss: 1.9839240466394732

Epoch: 5| Step: 9
Training loss: 1.7519702911376953
Validation loss: 1.9623187562470794

Epoch: 5| Step: 10
Training loss: 2.023214340209961
Validation loss: 2.000273496873917

Epoch: 192| Step: 0
Training loss: 1.7901853322982788
Validation loss: 1.9575243611489572

Epoch: 5| Step: 1
Training loss: 2.1975979804992676
Validation loss: 1.9906831018386348

Epoch: 5| Step: 2
Training loss: 1.2953962087631226
Validation loss: 1.9800800046613138

Epoch: 5| Step: 3
Training loss: 2.1635003089904785
Validation loss: 1.9738760917417464

Epoch: 5| Step: 4
Training loss: 2.1180930137634277
Validation loss: 1.9699026474388697

Epoch: 5| Step: 5
Training loss: 2.112555742263794
Validation loss: 1.9902072234820294

Epoch: 5| Step: 6
Training loss: 1.7377958297729492
Validation loss: 1.974728717598864

Epoch: 5| Step: 7
Training loss: 2.0104973316192627
Validation loss: 1.9774920966035576

Epoch: 5| Step: 8
Training loss: 1.8087637424468994
Validation loss: 1.9971963385100007

Epoch: 5| Step: 9
Training loss: 1.0419964790344238
Validation loss: 1.956774204008041

Epoch: 5| Step: 10
Training loss: 2.332202911376953
Validation loss: 1.9650969941128966

Epoch: 193| Step: 0
Training loss: 1.9262183904647827
Validation loss: 2.041343806892313

Epoch: 5| Step: 1
Training loss: 1.540501356124878
Validation loss: 1.9796883008813346

Epoch: 5| Step: 2
Training loss: 2.270414352416992
Validation loss: 1.9758462559792302

Epoch: 5| Step: 3
Training loss: 1.7462294101715088
Validation loss: 1.9699429888879099

Epoch: 5| Step: 4
Training loss: 2.4157471656799316
Validation loss: 1.9913696345462595

Epoch: 5| Step: 5
Training loss: 1.3263294696807861
Validation loss: 1.9481776311833372

Epoch: 5| Step: 6
Training loss: 1.8520218133926392
Validation loss: 1.978558495480527

Epoch: 5| Step: 7
Training loss: 1.797363042831421
Validation loss: 1.9551104473811325

Epoch: 5| Step: 8
Training loss: 1.8265749216079712
Validation loss: 1.9838439008241058

Epoch: 5| Step: 9
Training loss: 1.5091322660446167
Validation loss: 1.9737265289470713

Epoch: 5| Step: 10
Training loss: 2.370056390762329
Validation loss: 1.956417017085578

Epoch: 194| Step: 0
Training loss: 1.5119624137878418
Validation loss: 1.987898729180777

Epoch: 5| Step: 1
Training loss: 2.3802330493927
Validation loss: 1.9520556490908387

Epoch: 5| Step: 2
Training loss: 1.7599811553955078
Validation loss: 1.8975904167339366

Epoch: 5| Step: 3
Training loss: 2.3702361583709717
Validation loss: 1.9657024311762985

Epoch: 5| Step: 4
Training loss: 1.5513887405395508
Validation loss: 1.9513969395750312

Epoch: 5| Step: 5
Training loss: 2.0091888904571533
Validation loss: 1.9693635971315446

Epoch: 5| Step: 6
Training loss: 1.5481526851654053
Validation loss: 1.9851129029386787

Epoch: 5| Step: 7
Training loss: 1.770125389099121
Validation loss: 1.9923203350395284

Epoch: 5| Step: 8
Training loss: 2.1276230812072754
Validation loss: 1.9843855878358245

Epoch: 5| Step: 9
Training loss: 1.1758041381835938
Validation loss: 1.990807843464677

Epoch: 5| Step: 10
Training loss: 2.4606010913848877
Validation loss: 1.9274140160570863

Epoch: 195| Step: 0
Training loss: 2.2945353984832764
Validation loss: 1.9716576683905818

Epoch: 5| Step: 1
Training loss: 1.5247600078582764
Validation loss: 1.943820881587203

Epoch: 5| Step: 2
Training loss: 2.0080790519714355
Validation loss: 1.978169838587443

Epoch: 5| Step: 3
Training loss: 1.7522398233413696
Validation loss: 1.9798826094596618

Epoch: 5| Step: 4
Training loss: 1.1992709636688232
Validation loss: 2.0058204845715593

Epoch: 5| Step: 5
Training loss: 1.891266107559204
Validation loss: 1.981599179647302

Epoch: 5| Step: 6
Training loss: 2.065225124359131
Validation loss: 1.9806895512406544

Epoch: 5| Step: 7
Training loss: 2.2043681144714355
Validation loss: 1.9800140332150202

Epoch: 5| Step: 8
Training loss: 1.9536155462265015
Validation loss: 1.9863675102110832

Epoch: 5| Step: 9
Training loss: 1.7081050872802734
Validation loss: 2.008395037343425

Epoch: 5| Step: 10
Training loss: 2.2838473320007324
Validation loss: 1.992617275125237

Epoch: 196| Step: 0
Training loss: 1.9553394317626953
Validation loss: 1.989146355659731

Epoch: 5| Step: 1
Training loss: 1.9148916006088257
Validation loss: 1.9944106378862936

Epoch: 5| Step: 2
Training loss: 1.6697804927825928
Validation loss: 1.9629459406739922

Epoch: 5| Step: 3
Training loss: 1.9041566848754883
Validation loss: 1.9968210343391664

Epoch: 5| Step: 4
Training loss: 1.571223258972168
Validation loss: 1.971013012752738

Epoch: 5| Step: 5
Training loss: 1.785776138305664
Validation loss: 1.9835581164206229

Epoch: 5| Step: 6
Training loss: 1.7951667308807373
Validation loss: 1.9943464520157024

Epoch: 5| Step: 7
Training loss: 1.9837658405303955
Validation loss: 2.0119911316902406

Epoch: 5| Step: 8
Training loss: 1.9495468139648438
Validation loss: 1.9736290349755237

Epoch: 5| Step: 9
Training loss: 2.1694836616516113
Validation loss: 1.953532911116077

Epoch: 5| Step: 10
Training loss: 2.075349807739258
Validation loss: 1.9324066113400202

Epoch: 197| Step: 0
Training loss: 2.6887900829315186
Validation loss: 1.9692156186667822

Epoch: 5| Step: 1
Training loss: 1.873785376548767
Validation loss: 1.9600355253424695

Epoch: 5| Step: 2
Training loss: 2.03424334526062
Validation loss: 1.9612955995785293

Epoch: 5| Step: 3
Training loss: 1.6018117666244507
Validation loss: 2.0023374057585195

Epoch: 5| Step: 4
Training loss: 2.0138230323791504
Validation loss: 1.9768085518190939

Epoch: 5| Step: 5
Training loss: 1.458341360092163
Validation loss: 1.9548881464107062

Epoch: 5| Step: 6
Training loss: 1.5969734191894531
Validation loss: 1.9757064645008375

Epoch: 5| Step: 7
Training loss: 1.4563407897949219
Validation loss: 1.9734589130647722

Epoch: 5| Step: 8
Training loss: 2.0179429054260254
Validation loss: 1.9557869588175127

Epoch: 5| Step: 9
Training loss: 1.9321982860565186
Validation loss: 1.9829243818918865

Epoch: 5| Step: 10
Training loss: 2.0005602836608887
Validation loss: 1.9806074750038885

Epoch: 198| Step: 0
Training loss: 1.2030705213546753
Validation loss: 2.0020716267247356

Epoch: 5| Step: 1
Training loss: 2.1872153282165527
Validation loss: 1.9539644436169696

Epoch: 5| Step: 2
Training loss: 1.9933586120605469
Validation loss: 1.990916649500529

Epoch: 5| Step: 3
Training loss: 1.9302787780761719
Validation loss: 1.973841667175293

Epoch: 5| Step: 4
Training loss: 1.712906837463379
Validation loss: 1.9643239359701834

Epoch: 5| Step: 5
Training loss: 1.2428189516067505
Validation loss: 1.9714826781262633

Epoch: 5| Step: 6
Training loss: 2.065300464630127
Validation loss: 1.9426959714581888

Epoch: 5| Step: 7
Training loss: 1.6532407999038696
Validation loss: 1.962577086622997

Epoch: 5| Step: 8
Training loss: 2.4036476612091064
Validation loss: 1.943411168231759

Epoch: 5| Step: 9
Training loss: 2.1433935165405273
Validation loss: 2.014668753070216

Epoch: 5| Step: 10
Training loss: 2.0335733890533447
Validation loss: 1.9433356638877624

Epoch: 199| Step: 0
Training loss: 1.6685606241226196
Validation loss: 1.992943392005018

Epoch: 5| Step: 1
Training loss: 1.6647361516952515
Validation loss: 1.9852966877721971

Epoch: 5| Step: 2
Training loss: 1.4204299449920654
Validation loss: 1.9651329299455047

Epoch: 5| Step: 3
Training loss: 1.5209182500839233
Validation loss: 2.0141266802305817

Epoch: 5| Step: 4
Training loss: 2.148764133453369
Validation loss: 1.9448021829769175

Epoch: 5| Step: 5
Training loss: 2.0899147987365723
Validation loss: 1.9810717131501885

Epoch: 5| Step: 6
Training loss: 2.528644561767578
Validation loss: 2.005524681460473

Epoch: 5| Step: 7
Training loss: 1.530881404876709
Validation loss: 2.0070960470425185

Epoch: 5| Step: 8
Training loss: 1.712765097618103
Validation loss: 2.021886497415522

Epoch: 5| Step: 9
Training loss: 1.9226150512695312
Validation loss: 1.9648143809328797

Epoch: 5| Step: 10
Training loss: 2.089435577392578
Validation loss: 1.9642984456913446

Epoch: 200| Step: 0
Training loss: 1.4637340307235718
Validation loss: 1.9941482390126875

Epoch: 5| Step: 1
Training loss: 2.3550000190734863
Validation loss: 2.024357752133441

Epoch: 5| Step: 2
Training loss: 1.304377555847168
Validation loss: 1.991922438785594

Epoch: 5| Step: 3
Training loss: 2.1447668075561523
Validation loss: 2.002913692946075

Epoch: 5| Step: 4
Training loss: 1.6229091882705688
Validation loss: 2.009344370134415

Epoch: 5| Step: 5
Training loss: 2.0266852378845215
Validation loss: 1.9469879186281593

Epoch: 5| Step: 6
Training loss: 1.9770839214324951
Validation loss: 1.9905913465766496

Epoch: 5| Step: 7
Training loss: 1.6583001613616943
Validation loss: 1.9524825349930794

Epoch: 5| Step: 8
Training loss: 2.0406603813171387
Validation loss: 1.9676513223237888

Epoch: 5| Step: 9
Training loss: 1.8250467777252197
Validation loss: 1.9704642629110685

Epoch: 5| Step: 10
Training loss: 2.066620111465454
Validation loss: 1.9802677605741767

Epoch: 201| Step: 0
Training loss: 1.7690073251724243
Validation loss: 1.9380747182394868

Epoch: 5| Step: 1
Training loss: 1.7854678630828857
Validation loss: 1.9841306876110774

Epoch: 5| Step: 2
Training loss: 1.9981905221939087
Validation loss: 1.9740420438910042

Epoch: 5| Step: 3
Training loss: 1.896139144897461
Validation loss: 1.9946202155082458

Epoch: 5| Step: 4
Training loss: 1.9914661645889282
Validation loss: 1.9836128578391126

Epoch: 5| Step: 5
Training loss: 2.1637473106384277
Validation loss: 1.9859729889900453

Epoch: 5| Step: 6
Training loss: 1.9298908710479736
Validation loss: 1.9578009292643557

Epoch: 5| Step: 7
Training loss: 1.9246286153793335
Validation loss: 1.92794386289453

Epoch: 5| Step: 8
Training loss: 1.887860894203186
Validation loss: 1.9874071741616854

Epoch: 5| Step: 9
Training loss: 1.5921621322631836
Validation loss: 1.99633200066064

Epoch: 5| Step: 10
Training loss: 1.3326083421707153
Validation loss: 1.958516005546816

Epoch: 202| Step: 0
Training loss: 2.0568618774414062
Validation loss: 1.9638390284712597

Epoch: 5| Step: 1
Training loss: 1.2280418872833252
Validation loss: 2.0117828397340674

Epoch: 5| Step: 2
Training loss: 2.005542516708374
Validation loss: 2.0025482972462973

Epoch: 5| Step: 3
Training loss: 2.2504611015319824
Validation loss: 1.9767557728675105

Epoch: 5| Step: 4
Training loss: 1.8918927907943726
Validation loss: 1.9856633922105194

Epoch: 5| Step: 5
Training loss: 1.1625707149505615
Validation loss: 1.9702824751536052

Epoch: 5| Step: 6
Training loss: 2.2351784706115723
Validation loss: 1.9869221589898551

Epoch: 5| Step: 7
Training loss: 2.0640764236450195
Validation loss: 1.9755050674561532

Epoch: 5| Step: 8
Training loss: 1.6813119649887085
Validation loss: 1.9887466276845625

Epoch: 5| Step: 9
Training loss: 1.9951149225234985
Validation loss: 2.025443584688248

Epoch: 5| Step: 10
Training loss: 1.609597086906433
Validation loss: 1.9888645795083815

Epoch: 203| Step: 0
Training loss: 1.9459623098373413
Validation loss: 1.9988443877107354

Epoch: 5| Step: 1
Training loss: 1.4296073913574219
Validation loss: 1.9931540386651152

Epoch: 5| Step: 2
Training loss: 1.2355382442474365
Validation loss: 1.9567072981147355

Epoch: 5| Step: 3
Training loss: 1.7562488317489624
Validation loss: 1.9818620451035038

Epoch: 5| Step: 4
Training loss: 2.1918692588806152
Validation loss: 1.9533071441035117

Epoch: 5| Step: 5
Training loss: 2.2086403369903564
Validation loss: 1.9654518429951002

Epoch: 5| Step: 6
Training loss: 2.4270148277282715
Validation loss: 1.9705385995167557

Epoch: 5| Step: 7
Training loss: 1.8128118515014648
Validation loss: 1.9816423449465024

Epoch: 5| Step: 8
Training loss: 1.469222068786621
Validation loss: 1.9478167974820702

Epoch: 5| Step: 9
Training loss: 1.6508285999298096
Validation loss: 1.9538153756049372

Epoch: 5| Step: 10
Training loss: 2.2479214668273926
Validation loss: 2.0206413486952424

Epoch: 204| Step: 0
Training loss: 2.472834587097168
Validation loss: 1.9667792512524513

Epoch: 5| Step: 1
Training loss: 1.8999965190887451
Validation loss: 1.9541105275513024

Epoch: 5| Step: 2
Training loss: 1.924835205078125
Validation loss: 1.9515965805258801

Epoch: 5| Step: 3
Training loss: 2.0760598182678223
Validation loss: 1.986749933611962

Epoch: 5| Step: 4
Training loss: 1.7883310317993164
Validation loss: 1.9321236123320877

Epoch: 5| Step: 5
Training loss: 1.749868631362915
Validation loss: 2.042498911580732

Epoch: 5| Step: 6
Training loss: 1.6796894073486328
Validation loss: 1.981231809944235

Epoch: 5| Step: 7
Training loss: 1.537526249885559
Validation loss: 1.9864548713930192

Epoch: 5| Step: 8
Training loss: 1.817257285118103
Validation loss: 1.9765679836273193

Epoch: 5| Step: 9
Training loss: 1.6103980541229248
Validation loss: 1.9667299755157963

Epoch: 5| Step: 10
Training loss: 2.0735068321228027
Validation loss: 1.9768481241759432

Epoch: 205| Step: 0
Training loss: 1.9494901895523071
Validation loss: 2.0058182176723274

Epoch: 5| Step: 1
Training loss: 1.7537577152252197
Validation loss: 2.0015461470491145

Epoch: 5| Step: 2
Training loss: 2.285257339477539
Validation loss: 1.9768119601793186

Epoch: 5| Step: 3
Training loss: 2.7272605895996094
Validation loss: 1.9720637875218545

Epoch: 5| Step: 4
Training loss: 1.8681800365447998
Validation loss: 1.968249245356488

Epoch: 5| Step: 5
Training loss: 1.8487555980682373
Validation loss: 1.9874260669113488

Epoch: 5| Step: 6
Training loss: 1.6257684230804443
Validation loss: 1.9907647320019302

Epoch: 5| Step: 7
Training loss: 1.852708101272583
Validation loss: 1.980678444267601

Epoch: 5| Step: 8
Training loss: 1.714673399925232
Validation loss: 1.972561405551049

Epoch: 5| Step: 9
Training loss: 1.157195806503296
Validation loss: 2.005976721804629

Epoch: 5| Step: 10
Training loss: 1.382399320602417
Validation loss: 1.978251172650245

Epoch: 206| Step: 0
Training loss: 1.726639747619629
Validation loss: 1.9830968149246708

Epoch: 5| Step: 1
Training loss: 2.120779275894165
Validation loss: 1.9622221377588087

Epoch: 5| Step: 2
Training loss: 1.0150963068008423
Validation loss: 1.9893089212397093

Epoch: 5| Step: 3
Training loss: 1.5690839290618896
Validation loss: 1.9588435375562279

Epoch: 5| Step: 4
Training loss: 1.9969861507415771
Validation loss: 1.9856392004156624

Epoch: 5| Step: 5
Training loss: 2.371227741241455
Validation loss: 2.0028447028129333

Epoch: 5| Step: 6
Training loss: 1.378613829612732
Validation loss: 1.9666332583273611

Epoch: 5| Step: 7
Training loss: 1.8061370849609375
Validation loss: 1.995955572333387

Epoch: 5| Step: 8
Training loss: 2.550118923187256
Validation loss: 2.005261330194371

Epoch: 5| Step: 9
Training loss: 1.6796869039535522
Validation loss: 1.9932723147894746

Epoch: 5| Step: 10
Training loss: 2.124937057495117
Validation loss: 2.0021260746063723

Epoch: 207| Step: 0
Training loss: 1.5896514654159546
Validation loss: 2.0185221138820855

Epoch: 5| Step: 1
Training loss: 1.897249460220337
Validation loss: 1.9845683959222609

Epoch: 5| Step: 2
Training loss: 1.610907793045044
Validation loss: 1.996019999186198

Epoch: 5| Step: 3
Training loss: 1.858381986618042
Validation loss: 2.0064611396481915

Epoch: 5| Step: 4
Training loss: 2.2345497608184814
Validation loss: 2.009772358402129

Epoch: 5| Step: 5
Training loss: 1.2101503610610962
Validation loss: 1.9917383809243479

Epoch: 5| Step: 6
Training loss: 2.0623066425323486
Validation loss: 1.9837537375829553

Epoch: 5| Step: 7
Training loss: 2.158412218093872
Validation loss: 2.0152723148304927

Epoch: 5| Step: 8
Training loss: 1.8960908651351929
Validation loss: 1.9988466462781351

Epoch: 5| Step: 9
Training loss: 2.2740135192871094
Validation loss: 1.9872238430925595

Epoch: 5| Step: 10
Training loss: 1.6545387506484985
Validation loss: 2.0051443499903523

Epoch: 208| Step: 0
Training loss: 1.9320013523101807
Validation loss: 1.9704968083289363

Epoch: 5| Step: 1
Training loss: 1.7519851922988892
Validation loss: 1.997251114537639

Epoch: 5| Step: 2
Training loss: 2.1216487884521484
Validation loss: 1.9844040319483767

Epoch: 5| Step: 3
Training loss: 1.4569820165634155
Validation loss: 1.9780860870115218

Epoch: 5| Step: 4
Training loss: 1.6560542583465576
Validation loss: 1.986719553188611

Epoch: 5| Step: 5
Training loss: 2.007986307144165
Validation loss: 1.9733955680683095

Epoch: 5| Step: 6
Training loss: 1.8357837200164795
Validation loss: 1.9959852592919463

Epoch: 5| Step: 7
Training loss: 2.1116082668304443
Validation loss: 2.001179184964908

Epoch: 5| Step: 8
Training loss: 1.797106146812439
Validation loss: 2.00624293281186

Epoch: 5| Step: 9
Training loss: 1.874169945716858
Validation loss: 1.9915213789991153

Epoch: 5| Step: 10
Training loss: 1.6886118650436401
Validation loss: 1.9874612259608444

Epoch: 209| Step: 0
Training loss: 1.9040457010269165
Validation loss: 2.0116286880226544

Epoch: 5| Step: 1
Training loss: 1.5707229375839233
Validation loss: 2.001668009706723

Epoch: 5| Step: 2
Training loss: 2.207380771636963
Validation loss: 2.0170665248747794

Epoch: 5| Step: 3
Training loss: 1.5301072597503662
Validation loss: 1.9955797990163167

Epoch: 5| Step: 4
Training loss: 1.5798842906951904
Validation loss: 1.9538524586667296

Epoch: 5| Step: 5
Training loss: 1.7774670124053955
Validation loss: 1.967995415451706

Epoch: 5| Step: 6
Training loss: 1.7968336343765259
Validation loss: 1.9794007001384613

Epoch: 5| Step: 7
Training loss: 1.2951215505599976
Validation loss: 1.9792203390470116

Epoch: 5| Step: 8
Training loss: 2.705388069152832
Validation loss: 1.9794591639631538

Epoch: 5| Step: 9
Training loss: 1.6333000659942627
Validation loss: 1.9910688143904491

Epoch: 5| Step: 10
Training loss: 1.924980640411377
Validation loss: 1.9826924518872333

Epoch: 210| Step: 0
Training loss: 1.5821740627288818
Validation loss: 2.013444867185367

Epoch: 5| Step: 1
Training loss: 1.4612407684326172
Validation loss: 2.016060536907565

Epoch: 5| Step: 2
Training loss: 2.329620599746704
Validation loss: 2.0093249518384217

Epoch: 5| Step: 3
Training loss: 1.9760777950286865
Validation loss: 2.0337659338469147

Epoch: 5| Step: 4
Training loss: 2.1192095279693604
Validation loss: 2.024240488647133

Epoch: 5| Step: 5
Training loss: 1.7483152151107788
Validation loss: 2.0225306146888324

Epoch: 5| Step: 6
Training loss: 1.6486599445343018
Validation loss: 2.0226434674314273

Epoch: 5| Step: 7
Training loss: 1.7162582874298096
Validation loss: 2.0014281183160763

Epoch: 5| Step: 8
Training loss: 1.9770495891571045
Validation loss: 2.0004811979109243

Epoch: 5| Step: 9
Training loss: 1.7181365489959717
Validation loss: 2.0157577183938797

Epoch: 5| Step: 10
Training loss: 1.7946501970291138
Validation loss: 1.99206454266784

Epoch: 211| Step: 0
Training loss: 1.4574071168899536
Validation loss: 1.9882386653654036

Epoch: 5| Step: 1
Training loss: 1.582230806350708
Validation loss: 1.9992173089775989

Epoch: 5| Step: 2
Training loss: 2.222543478012085
Validation loss: 1.9951715392451133

Epoch: 5| Step: 3
Training loss: 1.809699296951294
Validation loss: 1.9698726630979968

Epoch: 5| Step: 4
Training loss: 1.5091140270233154
Validation loss: 1.9752738885982062

Epoch: 5| Step: 5
Training loss: 2.3057141304016113
Validation loss: 1.9645112509368567

Epoch: 5| Step: 6
Training loss: 1.5503485202789307
Validation loss: 1.9884850402032175

Epoch: 5| Step: 7
Training loss: 2.276097297668457
Validation loss: 1.999296106317992

Epoch: 5| Step: 8
Training loss: 2.3762247562408447
Validation loss: 1.983444554831392

Epoch: 5| Step: 9
Training loss: 1.4338538646697998
Validation loss: 1.971265959483321

Epoch: 5| Step: 10
Training loss: 1.8770164251327515
Validation loss: 1.9798148075739543

Epoch: 212| Step: 0
Training loss: 1.7815303802490234
Validation loss: 1.9625783158886818

Epoch: 5| Step: 1
Training loss: 1.7197039127349854
Validation loss: 1.9732441427887126

Epoch: 5| Step: 2
Training loss: 1.6323696374893188
Validation loss: 1.9735223529159382

Epoch: 5| Step: 3
Training loss: 1.4966784715652466
Validation loss: 1.9781834989465692

Epoch: 5| Step: 4
Training loss: 2.260502338409424
Validation loss: 1.9706201027798396

Epoch: 5| Step: 5
Training loss: 1.5597769021987915
Validation loss: 1.9539706271181825

Epoch: 5| Step: 6
Training loss: 2.138833522796631
Validation loss: 1.965230154734786

Epoch: 5| Step: 7
Training loss: 2.2441658973693848
Validation loss: 2.0065733027714554

Epoch: 5| Step: 8
Training loss: 1.7126176357269287
Validation loss: 1.999971059060866

Epoch: 5| Step: 9
Training loss: 2.170672655105591
Validation loss: 2.0086888190238708

Epoch: 5| Step: 10
Training loss: 1.4645452499389648
Validation loss: 2.0028185434238885

Epoch: 213| Step: 0
Training loss: 1.9451987743377686
Validation loss: 2.0309835890287995

Epoch: 5| Step: 1
Training loss: 1.8871402740478516
Validation loss: 2.0193306399929907

Epoch: 5| Step: 2
Training loss: 1.9024864435195923
Validation loss: 2.00899669431871

Epoch: 5| Step: 3
Training loss: 1.3477833271026611
Validation loss: 2.0269220875155542

Epoch: 5| Step: 4
Training loss: 2.085556983947754
Validation loss: 1.9862755383214643

Epoch: 5| Step: 5
Training loss: 1.9030914306640625
Validation loss: 2.000228222980294

Epoch: 5| Step: 6
Training loss: 2.116240978240967
Validation loss: 2.0167348051583893

Epoch: 5| Step: 7
Training loss: 1.5965553522109985
Validation loss: 2.0115936366460656

Epoch: 5| Step: 8
Training loss: 1.6552503108978271
Validation loss: 1.9835275334696616

Epoch: 5| Step: 9
Training loss: 2.0997097492218018
Validation loss: 1.960876887844455

Epoch: 5| Step: 10
Training loss: 1.4707448482513428
Validation loss: 1.9891328401463007

Epoch: 214| Step: 0
Training loss: 1.2888917922973633
Validation loss: 1.9828576669898084

Epoch: 5| Step: 1
Training loss: 1.7912242412567139
Validation loss: 1.9676666618675314

Epoch: 5| Step: 2
Training loss: 2.1478748321533203
Validation loss: 1.9542592751082553

Epoch: 5| Step: 3
Training loss: 2.302715301513672
Validation loss: 1.9999256005851171

Epoch: 5| Step: 4
Training loss: 1.9468024969100952
Validation loss: 1.9791261098718131

Epoch: 5| Step: 5
Training loss: 1.6448662281036377
Validation loss: 1.9281849284325876

Epoch: 5| Step: 6
Training loss: 2.217249631881714
Validation loss: 1.9750770855975408

Epoch: 5| Step: 7
Training loss: 2.1912591457366943
Validation loss: 1.9515555840666576

Epoch: 5| Step: 8
Training loss: 1.589432954788208
Validation loss: 1.9849175278858473

Epoch: 5| Step: 9
Training loss: 1.5769201517105103
Validation loss: 1.972608227883616

Epoch: 5| Step: 10
Training loss: 1.5267900228500366
Validation loss: 2.0443471913696616

Epoch: 215| Step: 0
Training loss: 2.446533441543579
Validation loss: 2.015137723697129

Epoch: 5| Step: 1
Training loss: 1.8401024341583252
Validation loss: 2.0017541634139193

Epoch: 5| Step: 2
Training loss: 1.7767794132232666
Validation loss: 1.9787229927637244

Epoch: 5| Step: 3
Training loss: 1.9438908100128174
Validation loss: 2.018295108631093

Epoch: 5| Step: 4
Training loss: 2.236483097076416
Validation loss: 1.966157651716663

Epoch: 5| Step: 5
Training loss: 1.421144962310791
Validation loss: 1.9935709712325886

Epoch: 5| Step: 6
Training loss: 1.713836431503296
Validation loss: 1.9820041220675233

Epoch: 5| Step: 7
Training loss: 1.5375112295150757
Validation loss: 1.9839772409008396

Epoch: 5| Step: 8
Training loss: 1.8734657764434814
Validation loss: 1.969538837350825

Epoch: 5| Step: 9
Training loss: 1.5761439800262451
Validation loss: 1.9611171727539392

Epoch: 5| Step: 10
Training loss: 1.8037997484207153
Validation loss: 1.9366434594636321

Epoch: 216| Step: 0
Training loss: 1.403043508529663
Validation loss: 1.9724369895073675

Epoch: 5| Step: 1
Training loss: 1.9117103815078735
Validation loss: 1.99355108891764

Epoch: 5| Step: 2
Training loss: 1.9338865280151367
Validation loss: 2.0225158917006625

Epoch: 5| Step: 3
Training loss: 1.3620786666870117
Validation loss: 1.9677380515683083

Epoch: 5| Step: 4
Training loss: 2.5662472248077393
Validation loss: 1.9919826394768172

Epoch: 5| Step: 5
Training loss: 2.0602896213531494
Validation loss: 1.9546940403599893

Epoch: 5| Step: 6
Training loss: 1.7761024236679077
Validation loss: 1.9421696637266426

Epoch: 5| Step: 7
Training loss: 1.8275001049041748
Validation loss: 2.00115297173941

Epoch: 5| Step: 8
Training loss: 2.0605597496032715
Validation loss: 2.002517507922265

Epoch: 5| Step: 9
Training loss: 1.3772008419036865
Validation loss: 1.939079321840758

Epoch: 5| Step: 10
Training loss: 1.7928802967071533
Validation loss: 2.023362946766679

Epoch: 217| Step: 0
Training loss: 1.877849817276001
Validation loss: 1.9831090460541427

Epoch: 5| Step: 1
Training loss: 1.6586300134658813
Validation loss: 2.0088560427388837

Epoch: 5| Step: 2
Training loss: 1.588997483253479
Validation loss: 1.9701271185310938

Epoch: 5| Step: 3
Training loss: 1.9941402673721313
Validation loss: 1.9924980004628499

Epoch: 5| Step: 4
Training loss: 2.435600996017456
Validation loss: 1.9671772308247064

Epoch: 5| Step: 5
Training loss: 1.6557791233062744
Validation loss: 1.9803434879549089

Epoch: 5| Step: 6
Training loss: 1.9936538934707642
Validation loss: 1.9814295102191228

Epoch: 5| Step: 7
Training loss: 1.653699517250061
Validation loss: 1.980158305937244

Epoch: 5| Step: 8
Training loss: 1.8037605285644531
Validation loss: 2.0071681468717513

Epoch: 5| Step: 9
Training loss: 1.419003963470459
Validation loss: 1.9967335552297614

Epoch: 5| Step: 10
Training loss: 2.0685038566589355
Validation loss: 1.9759385701148742

Epoch: 218| Step: 0
Training loss: 1.7299549579620361
Validation loss: 1.9845551777911443

Epoch: 5| Step: 1
Training loss: 1.4093589782714844
Validation loss: 2.02238013539263

Epoch: 5| Step: 2
Training loss: 2.0205416679382324
Validation loss: 1.9867616391951037

Epoch: 5| Step: 3
Training loss: 2.235238552093506
Validation loss: 2.0516618169764036

Epoch: 5| Step: 4
Training loss: 1.5373647212982178
Validation loss: 1.979329591156334

Epoch: 5| Step: 5
Training loss: 2.051835060119629
Validation loss: 1.9932053922325053

Epoch: 5| Step: 6
Training loss: 1.89993417263031
Validation loss: 2.008005693394651

Epoch: 5| Step: 7
Training loss: 1.7329086065292358
Validation loss: 1.982102955541303

Epoch: 5| Step: 8
Training loss: 2.0174942016601562
Validation loss: 2.0080260333194526

Epoch: 5| Step: 9
Training loss: 1.5451934337615967
Validation loss: 2.021538088398595

Epoch: 5| Step: 10
Training loss: 1.7007062435150146
Validation loss: 1.9813500014684533

Epoch: 219| Step: 0
Training loss: 1.6453012228012085
Validation loss: 2.0048677126566568

Epoch: 5| Step: 1
Training loss: 1.9792089462280273
Validation loss: 2.0118713648088518

Epoch: 5| Step: 2
Training loss: 1.7956655025482178
Validation loss: 1.9752448758771342

Epoch: 5| Step: 3
Training loss: 1.8646148443222046
Validation loss: 1.9624626098140594

Epoch: 5| Step: 4
Training loss: 1.6776554584503174
Validation loss: 1.9864991864850443

Epoch: 5| Step: 5
Training loss: 1.3394964933395386
Validation loss: 2.000849671261285

Epoch: 5| Step: 6
Training loss: 1.9018081426620483
Validation loss: 1.9943887854135165

Epoch: 5| Step: 7
Training loss: 1.8109651803970337
Validation loss: 1.9499587371785154

Epoch: 5| Step: 8
Training loss: 2.2979538440704346
Validation loss: 1.9708502907906809

Epoch: 5| Step: 9
Training loss: 1.9499038457870483
Validation loss: 1.9736339507564422

Epoch: 5| Step: 10
Training loss: 2.1569442749023438
Validation loss: 1.9785277869111748

Epoch: 220| Step: 0
Training loss: 1.9251201152801514
Validation loss: 1.9939049905346287

Epoch: 5| Step: 1
Training loss: 1.6052913665771484
Validation loss: 2.035419024446959

Epoch: 5| Step: 2
Training loss: 1.5322418212890625
Validation loss: 1.9910269911571215

Epoch: 5| Step: 3
Training loss: 1.3160899877548218
Validation loss: 1.9626677779741184

Epoch: 5| Step: 4
Training loss: 2.200490951538086
Validation loss: 1.9814128363004295

Epoch: 5| Step: 5
Training loss: 1.6748592853546143
Validation loss: 1.9658455733330018

Epoch: 5| Step: 6
Training loss: 1.7400833368301392
Validation loss: 1.9688300496788436

Epoch: 5| Step: 7
Training loss: 1.9342257976531982
Validation loss: 1.9726828195715462

Epoch: 5| Step: 8
Training loss: 1.8001916408538818
Validation loss: 2.0114513904817644

Epoch: 5| Step: 9
Training loss: 2.66384220123291
Validation loss: 2.0020875546240036

Epoch: 5| Step: 10
Training loss: 1.7509918212890625
Validation loss: 2.002100193372337

Epoch: 221| Step: 0
Training loss: 1.6667829751968384
Validation loss: 2.0063952566474996

Epoch: 5| Step: 1
Training loss: 2.4982237815856934
Validation loss: 1.988511461083607

Epoch: 5| Step: 2
Training loss: 1.4934184551239014
Validation loss: 2.0449936236104658

Epoch: 5| Step: 3
Training loss: 2.3373427391052246
Validation loss: 2.013597757585587

Epoch: 5| Step: 4
Training loss: 1.2934577465057373
Validation loss: 2.0354361495664044

Epoch: 5| Step: 5
Training loss: 1.8377106189727783
Validation loss: 2.021480829485001

Epoch: 5| Step: 6
Training loss: 1.6742279529571533
Validation loss: 2.029460022526403

Epoch: 5| Step: 7
Training loss: 1.6432965993881226
Validation loss: 2.0579312386051303

Epoch: 5| Step: 8
Training loss: 1.8365463018417358
Validation loss: 2.0650059946121706

Epoch: 5| Step: 9
Training loss: 2.1604857444763184
Validation loss: 2.031724464508795

Epoch: 5| Step: 10
Training loss: 1.9623486995697021
Validation loss: 2.0086761507936703

Epoch: 222| Step: 0
Training loss: 2.5131726264953613
Validation loss: 1.995130003139537

Epoch: 5| Step: 1
Training loss: 1.3420435190200806
Validation loss: 1.9877530938835555

Epoch: 5| Step: 2
Training loss: 1.382309079170227
Validation loss: 2.0207285740042247

Epoch: 5| Step: 3
Training loss: 2.085625410079956
Validation loss: 1.982986263049546

Epoch: 5| Step: 4
Training loss: 2.13040828704834
Validation loss: 1.9967105183550107

Epoch: 5| Step: 5
Training loss: 1.6778032779693604
Validation loss: 2.017696221669515

Epoch: 5| Step: 6
Training loss: 1.867164969444275
Validation loss: 1.9814480171408704

Epoch: 5| Step: 7
Training loss: 1.63296377658844
Validation loss: 1.9764414128436838

Epoch: 5| Step: 8
Training loss: 1.855965256690979
Validation loss: 1.9682277966571111

Epoch: 5| Step: 9
Training loss: 1.8617092370986938
Validation loss: 2.009591482018912

Epoch: 5| Step: 10
Training loss: 1.4329562187194824
Validation loss: 1.9982354769142725

Epoch: 223| Step: 0
Training loss: 1.624383568763733
Validation loss: 1.9854872944534465

Epoch: 5| Step: 1
Training loss: 1.7333112955093384
Validation loss: 1.9903951537224553

Epoch: 5| Step: 2
Training loss: 2.024968147277832
Validation loss: 1.976473891606895

Epoch: 5| Step: 3
Training loss: 1.5775226354599
Validation loss: 1.9983907591912053

Epoch: 5| Step: 4
Training loss: 1.9048070907592773
Validation loss: 2.017656510876071

Epoch: 5| Step: 5
Training loss: 2.3147189617156982
Validation loss: 2.032817648303124

Epoch: 5| Step: 6
Training loss: 1.741816520690918
Validation loss: 2.044497884729857

Epoch: 5| Step: 7
Training loss: 1.1812422275543213
Validation loss: 2.0279371123160086

Epoch: 5| Step: 8
Training loss: 2.1884806156158447
Validation loss: 2.014068413806218

Epoch: 5| Step: 9
Training loss: 1.809727430343628
Validation loss: 2.0268906034449095

Epoch: 5| Step: 10
Training loss: 1.8171151876449585
Validation loss: 2.0025666759860132

Epoch: 224| Step: 0
Training loss: 1.2374216318130493
Validation loss: 2.0188622961762133

Epoch: 5| Step: 1
Training loss: 2.0079500675201416
Validation loss: 2.012232006237071

Epoch: 5| Step: 2
Training loss: 2.101588249206543
Validation loss: 1.992620668103618

Epoch: 5| Step: 3
Training loss: 1.9804519414901733
Validation loss: 1.9593318149607668

Epoch: 5| Step: 4
Training loss: 1.8049752712249756
Validation loss: 2.0012222284911783

Epoch: 5| Step: 5
Training loss: 1.8518619537353516
Validation loss: 1.9743553246221235

Epoch: 5| Step: 6
Training loss: 1.1443341970443726
Validation loss: 2.0133817759893273

Epoch: 5| Step: 7
Training loss: 1.5961031913757324
Validation loss: 1.964958365245532

Epoch: 5| Step: 8
Training loss: 1.86819589138031
Validation loss: 1.9831504667958906

Epoch: 5| Step: 9
Training loss: 2.68906831741333
Validation loss: 2.004242625287784

Epoch: 5| Step: 10
Training loss: 1.2471445798873901
Validation loss: 1.9289808504043087

Epoch: 225| Step: 0
Training loss: 1.7698581218719482
Validation loss: 2.022519423115638

Epoch: 5| Step: 1
Training loss: 1.708788514137268
Validation loss: 1.9915677501309303

Epoch: 5| Step: 2
Training loss: 1.8933486938476562
Validation loss: 2.0026663631521244

Epoch: 5| Step: 3
Training loss: 1.5640636682510376
Validation loss: 1.9798663611053138

Epoch: 5| Step: 4
Training loss: 1.8810720443725586
Validation loss: 1.993804673994741

Epoch: 5| Step: 5
Training loss: 1.5537563562393188
Validation loss: 1.993662275293822

Epoch: 5| Step: 6
Training loss: 1.5360475778579712
Validation loss: 1.966169559827415

Epoch: 5| Step: 7
Training loss: 2.0548059940338135
Validation loss: 1.9896143790214293

Epoch: 5| Step: 8
Training loss: 1.950132966041565
Validation loss: 1.9774424722117763

Epoch: 5| Step: 9
Training loss: 2.341015577316284
Validation loss: 1.998041086299445

Epoch: 5| Step: 10
Training loss: 1.3838934898376465
Validation loss: 1.9816979413391442

Epoch: 226| Step: 0
Training loss: 1.6275842189788818
Validation loss: 2.0073238662494126

Epoch: 5| Step: 1
Training loss: 1.8041702508926392
Validation loss: 2.0251808961232505

Epoch: 5| Step: 2
Training loss: 2.5666744709014893
Validation loss: 1.9899789248743365

Epoch: 5| Step: 3
Training loss: 1.4931243658065796
Validation loss: 1.957712124752742

Epoch: 5| Step: 4
Training loss: 2.0771071910858154
Validation loss: 1.989958038894079

Epoch: 5| Step: 5
Training loss: 2.1528308391571045
Validation loss: 1.9426735319117063

Epoch: 5| Step: 6
Training loss: 1.6330970525741577
Validation loss: 2.0155942363123738

Epoch: 5| Step: 7
Training loss: 1.295572280883789
Validation loss: 2.0119639442813013

Epoch: 5| Step: 8
Training loss: 1.7570472955703735
Validation loss: 1.9401516465730564

Epoch: 5| Step: 9
Training loss: 1.755831003189087
Validation loss: 1.9605933696992937

Epoch: 5| Step: 10
Training loss: 1.2977627515792847
Validation loss: 1.988228451821112

Epoch: 227| Step: 0
Training loss: 1.8536598682403564
Validation loss: 1.9546833320330548

Epoch: 5| Step: 1
Training loss: 1.3362998962402344
Validation loss: 2.012791697696973

Epoch: 5| Step: 2
Training loss: 1.5118887424468994
Validation loss: 1.9697270854826896

Epoch: 5| Step: 3
Training loss: 2.0389208793640137
Validation loss: 1.9617197411034697

Epoch: 5| Step: 4
Training loss: 1.6180965900421143
Validation loss: 1.9945504127010223

Epoch: 5| Step: 5
Training loss: 1.7001800537109375
Validation loss: 1.9921476456426805

Epoch: 5| Step: 6
Training loss: 2.2573046684265137
Validation loss: 2.000523829972872

Epoch: 5| Step: 7
Training loss: 2.448634386062622
Validation loss: 2.0389805916816957

Epoch: 5| Step: 8
Training loss: 1.787631630897522
Validation loss: 1.9939837468567716

Epoch: 5| Step: 9
Training loss: 1.3604565858840942
Validation loss: 2.052477159807759

Epoch: 5| Step: 10
Training loss: 2.0998010635375977
Validation loss: 2.0426203563649166

Epoch: 228| Step: 0
Training loss: 1.6727216243743896
Validation loss: 2.0081683128110823

Epoch: 5| Step: 1
Training loss: 2.2029764652252197
Validation loss: 2.0172866070142357

Epoch: 5| Step: 2
Training loss: 1.4864223003387451
Validation loss: 2.0242084328846266

Epoch: 5| Step: 3
Training loss: 1.6430532932281494
Validation loss: 1.9782152675813245

Epoch: 5| Step: 4
Training loss: 1.4717038869857788
Validation loss: 1.9893038093402822

Epoch: 5| Step: 5
Training loss: 2.289095640182495
Validation loss: 2.0172645391956454

Epoch: 5| Step: 6
Training loss: 1.821373701095581
Validation loss: 2.0063502032269716

Epoch: 5| Step: 7
Training loss: 2.1220877170562744
Validation loss: 2.0468830626497985

Epoch: 5| Step: 8
Training loss: 1.6149877309799194
Validation loss: 2.0042607040815454

Epoch: 5| Step: 9
Training loss: 1.8082849979400635
Validation loss: 1.9679341675132833

Epoch: 5| Step: 10
Training loss: 1.6870628595352173
Validation loss: 2.0058601466558312

Epoch: 229| Step: 0
Training loss: 1.9531011581420898
Validation loss: 1.9560299124768985

Epoch: 5| Step: 1
Training loss: 1.9337093830108643
Validation loss: 1.9947881083334646

Epoch: 5| Step: 2
Training loss: 1.4815597534179688
Validation loss: 2.0341671359154487

Epoch: 5| Step: 3
Training loss: 1.6693512201309204
Validation loss: 1.9888837042675223

Epoch: 5| Step: 4
Training loss: 1.80908203125
Validation loss: 1.9879862005992601

Epoch: 5| Step: 5
Training loss: 2.1180293560028076
Validation loss: 1.9641321987234137

Epoch: 5| Step: 6
Training loss: 1.5338870286941528
Validation loss: 1.974881951526929

Epoch: 5| Step: 7
Training loss: 1.7087135314941406
Validation loss: 1.973369224097139

Epoch: 5| Step: 8
Training loss: 1.4083484411239624
Validation loss: 1.9771762945318734

Epoch: 5| Step: 9
Training loss: 2.099374294281006
Validation loss: 1.9713053126488962

Epoch: 5| Step: 10
Training loss: 2.452388286590576
Validation loss: 1.9907175174323462

Epoch: 230| Step: 0
Training loss: 1.8111951351165771
Validation loss: 2.030042048423521

Epoch: 5| Step: 1
Training loss: 1.8494724035263062
Validation loss: 1.999075210222634

Epoch: 5| Step: 2
Training loss: 1.9936641454696655
Validation loss: 2.000607926358459

Epoch: 5| Step: 3
Training loss: 1.2871595621109009
Validation loss: 1.9650163778694727

Epoch: 5| Step: 4
Training loss: 1.6316179037094116
Validation loss: 2.0044826807514315

Epoch: 5| Step: 5
Training loss: 1.890631914138794
Validation loss: 2.003530135718725

Epoch: 5| Step: 6
Training loss: 1.9069324731826782
Validation loss: 2.0031338481492895

Epoch: 5| Step: 7
Training loss: 1.9548451900482178
Validation loss: 2.0366990053525535

Epoch: 5| Step: 8
Training loss: 2.044826030731201
Validation loss: 2.010164132682226

Epoch: 5| Step: 9
Training loss: 1.3910012245178223
Validation loss: 1.9952232196766844

Epoch: 5| Step: 10
Training loss: 1.6753424406051636
Validation loss: 2.0017473902753604

Epoch: 231| Step: 0
Training loss: 2.5502402782440186
Validation loss: 2.023935047529077

Epoch: 5| Step: 1
Training loss: 1.884500503540039
Validation loss: 2.035801162001907

Epoch: 5| Step: 2
Training loss: 1.883418321609497
Validation loss: 2.0370506048202515

Epoch: 5| Step: 3
Training loss: 1.6531766653060913
Validation loss: 2.0271238716699744

Epoch: 5| Step: 4
Training loss: 1.4577680826187134
Validation loss: 2.030900063053254

Epoch: 5| Step: 5
Training loss: 1.6988922357559204
Validation loss: 1.9944356192824662

Epoch: 5| Step: 6
Training loss: 2.1476197242736816
Validation loss: 2.0074536569656862

Epoch: 5| Step: 7
Training loss: 1.8380142450332642
Validation loss: 2.020770900992937

Epoch: 5| Step: 8
Training loss: 1.3019683361053467
Validation loss: 2.0410794211972143

Epoch: 5| Step: 9
Training loss: 1.572311282157898
Validation loss: 2.013627234325614

Epoch: 5| Step: 10
Training loss: 1.9302589893341064
Validation loss: 1.9922584333727438

Epoch: 232| Step: 0
Training loss: 2.1959662437438965
Validation loss: 1.9979533149350075

Epoch: 5| Step: 1
Training loss: 1.5412932634353638
Validation loss: 2.008652615290816

Epoch: 5| Step: 2
Training loss: 1.2137285470962524
Validation loss: 1.9931102465557795

Epoch: 5| Step: 3
Training loss: 1.7557604312896729
Validation loss: 1.9588984904750701

Epoch: 5| Step: 4
Training loss: 1.587611436843872
Validation loss: 1.9358086047634002

Epoch: 5| Step: 5
Training loss: 1.6966361999511719
Validation loss: 1.9560636679331462

Epoch: 5| Step: 6
Training loss: 1.8238487243652344
Validation loss: 1.9677645160305886

Epoch: 5| Step: 7
Training loss: 1.821157455444336
Validation loss: 1.9803019441584104

Epoch: 5| Step: 8
Training loss: 2.0478711128234863
Validation loss: 1.9368127456275366

Epoch: 5| Step: 9
Training loss: 2.1507980823516846
Validation loss: 2.0023031568014495

Epoch: 5| Step: 10
Training loss: 1.8550825119018555
Validation loss: 1.9982512048495713

Epoch: 233| Step: 0
Training loss: 1.7099376916885376
Validation loss: 1.999104675426278

Epoch: 5| Step: 1
Training loss: 2.123882293701172
Validation loss: 2.01391593615214

Epoch: 5| Step: 2
Training loss: 1.8086011409759521
Validation loss: 1.9736261918980589

Epoch: 5| Step: 3
Training loss: 1.3000117540359497
Validation loss: 2.0414506222612117

Epoch: 5| Step: 4
Training loss: 1.5759961605072021
Validation loss: 1.9696804195322015

Epoch: 5| Step: 5
Training loss: 1.528120756149292
Validation loss: 2.0017749032666607

Epoch: 5| Step: 6
Training loss: 1.8144588470458984
Validation loss: 1.9990090131759644

Epoch: 5| Step: 7
Training loss: 1.6090370416641235
Validation loss: 1.9950556460247244

Epoch: 5| Step: 8
Training loss: 2.0671353340148926
Validation loss: 2.0484796903466664

Epoch: 5| Step: 9
Training loss: 2.4083023071289062
Validation loss: 2.049359493358161

Epoch: 5| Step: 10
Training loss: 1.4463001489639282
Validation loss: 2.0101708071206206

Epoch: 234| Step: 0
Training loss: 2.013636589050293
Validation loss: 2.015965425839988

Epoch: 5| Step: 1
Training loss: 1.5166791677474976
Validation loss: 2.008869318551915

Epoch: 5| Step: 2
Training loss: 1.8698126077651978
Validation loss: 1.9933198805778258

Epoch: 5| Step: 3
Training loss: 1.8344109058380127
Validation loss: 2.0185993230471047

Epoch: 5| Step: 4
Training loss: 1.653692603111267
Validation loss: 2.017812636590773

Epoch: 5| Step: 5
Training loss: 1.4367191791534424
Validation loss: 1.975802735615802

Epoch: 5| Step: 6
Training loss: 1.9182636737823486
Validation loss: 1.9992978188299364

Epoch: 5| Step: 7
Training loss: 1.992611289024353
Validation loss: 1.9957546982713925

Epoch: 5| Step: 8
Training loss: 1.6855300664901733
Validation loss: 1.9788596617278231

Epoch: 5| Step: 9
Training loss: 2.006899356842041
Validation loss: 2.003771274320541

Epoch: 5| Step: 10
Training loss: 1.7723467350006104
Validation loss: 2.00074238674615

Epoch: 235| Step: 0
Training loss: 1.8820775747299194
Validation loss: 2.01457445211308

Epoch: 5| Step: 1
Training loss: 1.8945550918579102
Validation loss: 2.000969386869861

Epoch: 5| Step: 2
Training loss: 1.7134430408477783
Validation loss: 2.0197865860436552

Epoch: 5| Step: 3
Training loss: 1.7601826190948486
Validation loss: 2.000343281735656

Epoch: 5| Step: 4
Training loss: 1.5442405939102173
Validation loss: 1.9796917053960985

Epoch: 5| Step: 5
Training loss: 1.95440673828125
Validation loss: 1.9742536660163634

Epoch: 5| Step: 6
Training loss: 1.7924665212631226
Validation loss: 1.9805651121242072

Epoch: 5| Step: 7
Training loss: 1.575268030166626
Validation loss: 2.006117283657033

Epoch: 5| Step: 8
Training loss: 1.4098308086395264
Validation loss: 1.9979825007018222

Epoch: 5| Step: 9
Training loss: 1.7403104305267334
Validation loss: 2.0115019172750492

Epoch: 5| Step: 10
Training loss: 2.3601202964782715
Validation loss: 2.0231507414130756

Epoch: 236| Step: 0
Training loss: 1.6059659719467163
Validation loss: 1.9951499021181496

Epoch: 5| Step: 1
Training loss: 1.0858781337738037
Validation loss: 1.981932690066676

Epoch: 5| Step: 2
Training loss: 2.433342933654785
Validation loss: 2.0069387061621553

Epoch: 5| Step: 3
Training loss: 2.160557985305786
Validation loss: 1.9858351510058168

Epoch: 5| Step: 4
Training loss: 1.6099884510040283
Validation loss: 1.998709641477113

Epoch: 5| Step: 5
Training loss: 1.588693380355835
Validation loss: 2.0123326009319675

Epoch: 5| Step: 6
Training loss: 2.412097930908203
Validation loss: 2.005528570503317

Epoch: 5| Step: 7
Training loss: 1.7294479608535767
Validation loss: 2.023747421080066

Epoch: 5| Step: 8
Training loss: 1.7802879810333252
Validation loss: 2.0204916692549184

Epoch: 5| Step: 9
Training loss: 1.2712708711624146
Validation loss: 1.9865738384185299

Epoch: 5| Step: 10
Training loss: 1.512007236480713
Validation loss: 2.0128598584923694

Epoch: 237| Step: 0
Training loss: 2.022993564605713
Validation loss: 2.0050014962432203

Epoch: 5| Step: 1
Training loss: 1.9654757976531982
Validation loss: 1.9999376394415413

Epoch: 5| Step: 2
Training loss: 1.9028079509735107
Validation loss: 1.9869177969553138

Epoch: 5| Step: 3
Training loss: 1.7641828060150146
Validation loss: 2.0043059446478404

Epoch: 5| Step: 4
Training loss: 1.6521936655044556
Validation loss: 1.9722114070769279

Epoch: 5| Step: 5
Training loss: 1.5068939924240112
Validation loss: 1.9946716485484954

Epoch: 5| Step: 6
Training loss: 1.9883873462677002
Validation loss: 1.9751218570175992

Epoch: 5| Step: 7
Training loss: 1.5812733173370361
Validation loss: 1.9663692956329675

Epoch: 5| Step: 8
Training loss: 1.4250218868255615
Validation loss: 2.0050484108668503

Epoch: 5| Step: 9
Training loss: 1.6080951690673828
Validation loss: 2.000936313342023

Epoch: 5| Step: 10
Training loss: 1.8145214319229126
Validation loss: 1.9906487875087286

Epoch: 238| Step: 0
Training loss: 1.597165822982788
Validation loss: 1.9887518357205134

Epoch: 5| Step: 1
Training loss: 1.661515474319458
Validation loss: 2.0188623436035646

Epoch: 5| Step: 2
Training loss: 1.7687124013900757
Validation loss: 1.9586915098210818

Epoch: 5| Step: 3
Training loss: 2.20465350151062
Validation loss: 2.026222454604282

Epoch: 5| Step: 4
Training loss: 2.5547118186950684
Validation loss: 2.011210492862168

Epoch: 5| Step: 5
Training loss: 1.4096487760543823
Validation loss: 2.031741883165093

Epoch: 5| Step: 6
Training loss: 1.9537937641143799
Validation loss: 2.010559985714574

Epoch: 5| Step: 7
Training loss: 2.112025737762451
Validation loss: 2.013820380292913

Epoch: 5| Step: 8
Training loss: 1.5918680429458618
Validation loss: 1.9644544304058116

Epoch: 5| Step: 9
Training loss: 1.269696831703186
Validation loss: 2.0278906719658965

Epoch: 5| Step: 10
Training loss: 1.4829719066619873
Validation loss: 2.0235495669867403

Epoch: 239| Step: 0
Training loss: 1.5888097286224365
Validation loss: 2.0116036399718253

Epoch: 5| Step: 1
Training loss: 2.0783324241638184
Validation loss: 2.001612227450135

Epoch: 5| Step: 2
Training loss: 1.8465780019760132
Validation loss: 1.9835391890618108

Epoch: 5| Step: 3
Training loss: 1.16256844997406
Validation loss: 2.0090649089505597

Epoch: 5| Step: 4
Training loss: 1.2389179468154907
Validation loss: 2.0326561979068223

Epoch: 5| Step: 5
Training loss: 1.6185293197631836
Validation loss: 1.9861498353301839

Epoch: 5| Step: 6
Training loss: 1.6700875759124756
Validation loss: 1.9779457802413611

Epoch: 5| Step: 7
Training loss: 1.6077773571014404
Validation loss: 1.9995282516684583

Epoch: 5| Step: 8
Training loss: 2.2172250747680664
Validation loss: 2.04691622718688

Epoch: 5| Step: 9
Training loss: 1.5806734561920166
Validation loss: 2.045667040732599

Epoch: 5| Step: 10
Training loss: 2.7700037956237793
Validation loss: 1.9804072533884356

Epoch: 240| Step: 0
Training loss: 1.2223281860351562
Validation loss: 1.9697338009393344

Epoch: 5| Step: 1
Training loss: 1.3829233646392822
Validation loss: 1.9977558966605895

Epoch: 5| Step: 2
Training loss: 1.6968984603881836
Validation loss: 2.035832835781959

Epoch: 5| Step: 3
Training loss: 2.3009798526763916
Validation loss: 2.0170763756639216

Epoch: 5| Step: 4
Training loss: 1.4884111881256104
Validation loss: 1.9888050133182156

Epoch: 5| Step: 5
Training loss: 1.9710842370986938
Validation loss: 2.0113745017718245

Epoch: 5| Step: 6
Training loss: 1.8064666986465454
Validation loss: 2.0231080933283736

Epoch: 5| Step: 7
Training loss: 1.8533756732940674
Validation loss: 2.016390041638446

Epoch: 5| Step: 8
Training loss: 1.6931473016738892
Validation loss: 1.977126354812294

Epoch: 5| Step: 9
Training loss: 1.8626251220703125
Validation loss: 2.0702701768567486

Epoch: 5| Step: 10
Training loss: 2.3563530445098877
Validation loss: 2.0330170880081835

Epoch: 241| Step: 0
Training loss: 1.9700639247894287
Validation loss: 1.9893378134696715

Epoch: 5| Step: 1
Training loss: 1.7440862655639648
Validation loss: 2.0206705370256977

Epoch: 5| Step: 2
Training loss: 1.8183616399765015
Validation loss: 2.0211867491404214

Epoch: 5| Step: 3
Training loss: 1.776336669921875
Validation loss: 2.0321476510775986

Epoch: 5| Step: 4
Training loss: 1.945023775100708
Validation loss: 1.9985963016427972

Epoch: 5| Step: 5
Training loss: 1.0831884145736694
Validation loss: 2.0438783091883503

Epoch: 5| Step: 6
Training loss: 1.2939034700393677
Validation loss: 2.0073259107528196

Epoch: 5| Step: 7
Training loss: 2.315647840499878
Validation loss: 1.9979091587887015

Epoch: 5| Step: 8
Training loss: 2.081789016723633
Validation loss: 2.038824681312807

Epoch: 5| Step: 9
Training loss: 1.5751837491989136
Validation loss: 2.016060854799004

Epoch: 5| Step: 10
Training loss: 1.6679859161376953
Validation loss: 1.9774569337086012

Epoch: 242| Step: 0
Training loss: 2.3704144954681396
Validation loss: 1.9834873778845674

Epoch: 5| Step: 1
Training loss: 1.3895570039749146
Validation loss: 2.005255359475331

Epoch: 5| Step: 2
Training loss: 0.9713752865791321
Validation loss: 1.9830472802603116

Epoch: 5| Step: 3
Training loss: 2.090273380279541
Validation loss: 2.0168368457466044

Epoch: 5| Step: 4
Training loss: 1.5299352407455444
Validation loss: 2.0274883239499983

Epoch: 5| Step: 5
Training loss: 2.2425856590270996
Validation loss: 1.9968496625141432

Epoch: 5| Step: 6
Training loss: 1.1731535196304321
Validation loss: 1.9530014991760254

Epoch: 5| Step: 7
Training loss: 1.4227626323699951
Validation loss: 1.9902377974602483

Epoch: 5| Step: 8
Training loss: 1.7531715631484985
Validation loss: 1.968851876515214

Epoch: 5| Step: 9
Training loss: 2.1635525226593018
Validation loss: 2.0497627745392504

Epoch: 5| Step: 10
Training loss: 2.3829991817474365
Validation loss: 2.0103698468977407

Epoch: 243| Step: 0
Training loss: 2.4325039386749268
Validation loss: 2.042869911398939

Epoch: 5| Step: 1
Training loss: 1.7223793268203735
Validation loss: 1.996946834748791

Epoch: 5| Step: 2
Training loss: 1.7608665227890015
Validation loss: 2.014877865391393

Epoch: 5| Step: 3
Training loss: 1.6707462072372437
Validation loss: 1.9974097103200934

Epoch: 5| Step: 4
Training loss: 1.267112374305725
Validation loss: 2.0311129016260945

Epoch: 5| Step: 5
Training loss: 1.7510379552841187
Validation loss: 2.0044234978255404

Epoch: 5| Step: 6
Training loss: 1.7517296075820923
Validation loss: 2.028270629144484

Epoch: 5| Step: 7
Training loss: 1.5274752378463745
Validation loss: 2.0162604239679154

Epoch: 5| Step: 8
Training loss: 2.1289544105529785
Validation loss: 2.0085384102277857

Epoch: 5| Step: 9
Training loss: 1.890344262123108
Validation loss: 2.0331472927524197

Epoch: 5| Step: 10
Training loss: 1.0412794351577759
Validation loss: 2.001534579902567

Epoch: 244| Step: 0
Training loss: 2.073169708251953
Validation loss: 2.0578595053765083

Epoch: 5| Step: 1
Training loss: 1.4984891414642334
Validation loss: 2.001453721395103

Epoch: 5| Step: 2
Training loss: 1.7529802322387695
Validation loss: 1.9970812413000292

Epoch: 5| Step: 3
Training loss: 1.6800884008407593
Validation loss: 2.0191196818505563

Epoch: 5| Step: 4
Training loss: 1.8376039266586304
Validation loss: 2.0032723975437943

Epoch: 5| Step: 5
Training loss: 2.12247896194458
Validation loss: 2.0325379756189164

Epoch: 5| Step: 6
Training loss: 1.5834647417068481
Validation loss: 1.994117541979718

Epoch: 5| Step: 7
Training loss: 1.762998342514038
Validation loss: 1.998834676640008

Epoch: 5| Step: 8
Training loss: 1.5218135118484497
Validation loss: 1.9667621517694125

Epoch: 5| Step: 9
Training loss: 1.3897031545639038
Validation loss: 2.0127466878583355

Epoch: 5| Step: 10
Training loss: 1.8744206428527832
Validation loss: 2.0143529125439223

Epoch: 245| Step: 0
Training loss: 1.9547655582427979
Validation loss: 2.011349506275628

Epoch: 5| Step: 1
Training loss: 1.556512713432312
Validation loss: 2.012467795802701

Epoch: 5| Step: 2
Training loss: 1.4440381526947021
Validation loss: 2.0475076808724353

Epoch: 5| Step: 3
Training loss: 1.817760705947876
Validation loss: 2.002089786273177

Epoch: 5| Step: 4
Training loss: 1.6856555938720703
Validation loss: 1.986362059911092

Epoch: 5| Step: 5
Training loss: 1.9300044775009155
Validation loss: 1.9981370151683848

Epoch: 5| Step: 6
Training loss: 1.6829535961151123
Validation loss: 2.0466439723968506

Epoch: 5| Step: 7
Training loss: 1.9599641561508179
Validation loss: 2.0241511893528763

Epoch: 5| Step: 8
Training loss: 1.613146185874939
Validation loss: 1.9963079383296352

Epoch: 5| Step: 9
Training loss: 1.8924033641815186
Validation loss: 2.0280344614418606

Epoch: 5| Step: 10
Training loss: 1.959111213684082
Validation loss: 2.04120046605346

Epoch: 246| Step: 0
Training loss: 1.9454166889190674
Validation loss: 2.0393549985783075

Epoch: 5| Step: 1
Training loss: 1.3237673044204712
Validation loss: 2.0127552196543705

Epoch: 5| Step: 2
Training loss: 1.638321876525879
Validation loss: 2.036307409245481

Epoch: 5| Step: 3
Training loss: 1.978697419166565
Validation loss: 2.017183590960759

Epoch: 5| Step: 4
Training loss: 1.8823035955429077
Validation loss: 1.9775781593015116

Epoch: 5| Step: 5
Training loss: 1.8667418956756592
Validation loss: 2.0078701947325017

Epoch: 5| Step: 6
Training loss: 2.3239402770996094
Validation loss: 2.052539954903305

Epoch: 5| Step: 7
Training loss: 1.6536791324615479
Validation loss: 1.9941787335180468

Epoch: 5| Step: 8
Training loss: 1.5954434871673584
Validation loss: 2.0085534049618627

Epoch: 5| Step: 9
Training loss: 1.449498176574707
Validation loss: 2.031368596579439

Epoch: 5| Step: 10
Training loss: 1.1489918231964111
Validation loss: 2.0436182816823325

Epoch: 247| Step: 0
Training loss: 1.756696105003357
Validation loss: 1.979223676907119

Epoch: 5| Step: 1
Training loss: 1.5612040758132935
Validation loss: 1.983355527283043

Epoch: 5| Step: 2
Training loss: 1.6351425647735596
Validation loss: 2.0015551326095418

Epoch: 5| Step: 3
Training loss: 1.571279525756836
Validation loss: 2.010852979075524

Epoch: 5| Step: 4
Training loss: 2.0418176651000977
Validation loss: 2.02064650161292

Epoch: 5| Step: 5
Training loss: 1.8029747009277344
Validation loss: 2.013050215218657

Epoch: 5| Step: 6
Training loss: 1.642324686050415
Validation loss: 2.0419683764057774

Epoch: 5| Step: 7
Training loss: 2.194950819015503
Validation loss: 2.058835978149086

Epoch: 5| Step: 8
Training loss: 1.3312649726867676
Validation loss: 2.029661367016454

Epoch: 5| Step: 9
Training loss: 1.593343734741211
Validation loss: 2.025700584534676

Epoch: 5| Step: 10
Training loss: 1.939246654510498
Validation loss: 1.9923185046001146

Epoch: 248| Step: 0
Training loss: 1.743320107460022
Validation loss: 2.0528216131271853

Epoch: 5| Step: 1
Training loss: 1.7413784265518188
Validation loss: 2.0244028414449384

Epoch: 5| Step: 2
Training loss: 2.546452045440674
Validation loss: 2.008964266828311

Epoch: 5| Step: 3
Training loss: 1.9263776540756226
Validation loss: 2.0156241052894184

Epoch: 5| Step: 4
Training loss: 1.449844479560852
Validation loss: 2.030203701347433

Epoch: 5| Step: 5
Training loss: 1.7638027667999268
Validation loss: 2.0465579750717326

Epoch: 5| Step: 6
Training loss: 1.8290729522705078
Validation loss: 1.997484346871735

Epoch: 5| Step: 7
Training loss: 1.7828481197357178
Validation loss: 2.0041099030484437

Epoch: 5| Step: 8
Training loss: 1.458744764328003
Validation loss: 2.0242249555485223

Epoch: 5| Step: 9
Training loss: 1.3986024856567383
Validation loss: 2.0238560591974566

Epoch: 5| Step: 10
Training loss: 1.6274741888046265
Validation loss: 2.0331165431648173

Epoch: 249| Step: 0
Training loss: 2.1486668586730957
Validation loss: 2.001608633225964

Epoch: 5| Step: 1
Training loss: 1.8591935634613037
Validation loss: 2.0350942355330273

Epoch: 5| Step: 2
Training loss: 1.6748199462890625
Validation loss: 2.0836938299158567

Epoch: 5| Step: 3
Training loss: 1.9072624444961548
Validation loss: 2.0305731937449467

Epoch: 5| Step: 4
Training loss: 1.6882215738296509
Validation loss: 2.0086658077855266

Epoch: 5| Step: 5
Training loss: 1.5543607473373413
Validation loss: 2.0028138186341975

Epoch: 5| Step: 6
Training loss: 2.024466037750244
Validation loss: 1.996932452724826

Epoch: 5| Step: 7
Training loss: 1.577890396118164
Validation loss: 2.0115914126878143

Epoch: 5| Step: 8
Training loss: 1.8893640041351318
Validation loss: 1.9845367054785452

Epoch: 5| Step: 9
Training loss: 1.6191068887710571
Validation loss: 2.0188888939478065

Epoch: 5| Step: 10
Training loss: 1.367690086364746
Validation loss: 2.043770162008142

Epoch: 250| Step: 0
Training loss: 1.878278136253357
Validation loss: 2.008940678770824

Epoch: 5| Step: 1
Training loss: 1.487802505493164
Validation loss: 1.959196500880744

Epoch: 5| Step: 2
Training loss: 0.9729822278022766
Validation loss: 1.9965744736374065

Epoch: 5| Step: 3
Training loss: 2.3941969871520996
Validation loss: 2.0340246000597553

Epoch: 5| Step: 4
Training loss: 2.026073932647705
Validation loss: 1.9986122064693

Epoch: 5| Step: 5
Training loss: 1.503710150718689
Validation loss: 2.030641245585616

Epoch: 5| Step: 6
Training loss: 1.9184995889663696
Validation loss: 2.0173912009885235

Epoch: 5| Step: 7
Training loss: 1.9911746978759766
Validation loss: 2.009372485581265

Epoch: 5| Step: 8
Training loss: 1.457344651222229
Validation loss: 2.0083662886773386

Epoch: 5| Step: 9
Training loss: 2.044010877609253
Validation loss: 2.0178676856461393

Epoch: 5| Step: 10
Training loss: 1.3093411922454834
Validation loss: 2.015366477351035

Epoch: 251| Step: 0
Training loss: 1.9351251125335693
Validation loss: 2.0233613637185868

Epoch: 5| Step: 1
Training loss: 1.5135924816131592
Validation loss: 1.9904697043921358

Epoch: 5| Step: 2
Training loss: 1.7870533466339111
Validation loss: 1.9738088525751585

Epoch: 5| Step: 3
Training loss: 1.0979312658309937
Validation loss: 2.030213886691678

Epoch: 5| Step: 4
Training loss: 1.2903740406036377
Validation loss: 2.052214759652333

Epoch: 5| Step: 5
Training loss: 1.7645448446273804
Validation loss: 2.027988373592336

Epoch: 5| Step: 6
Training loss: 2.383884906768799
Validation loss: 2.0081873734792075

Epoch: 5| Step: 7
Training loss: 1.3750555515289307
Validation loss: 2.0209367903329993

Epoch: 5| Step: 8
Training loss: 1.9967283010482788
Validation loss: 1.9674088108924128

Epoch: 5| Step: 9
Training loss: 1.5891187191009521
Validation loss: 2.05492445858576

Epoch: 5| Step: 10
Training loss: 2.136075973510742
Validation loss: 1.995590256106469

Epoch: 252| Step: 0
Training loss: 1.3640276193618774
Validation loss: 1.9807114370407597

Epoch: 5| Step: 1
Training loss: 1.6636492013931274
Validation loss: 1.9999489156148766

Epoch: 5| Step: 2
Training loss: 1.2988837957382202
Validation loss: 2.033591366583301

Epoch: 5| Step: 3
Training loss: 1.566069483757019
Validation loss: 1.976967688529722

Epoch: 5| Step: 4
Training loss: 1.816588044166565
Validation loss: 2.014124337063041

Epoch: 5| Step: 5
Training loss: 1.7176223993301392
Validation loss: 2.0316967784717517

Epoch: 5| Step: 6
Training loss: 1.4426853656768799
Validation loss: 2.03231095498608

Epoch: 5| Step: 7
Training loss: 1.5458201169967651
Validation loss: 2.0583032408068256

Epoch: 5| Step: 8
Training loss: 1.9317668676376343
Validation loss: 2.0088207670437392

Epoch: 5| Step: 9
Training loss: 2.476574659347534
Validation loss: 2.0232955076361216

Epoch: 5| Step: 10
Training loss: 2.2624878883361816
Validation loss: 1.9828634108266523

Epoch: 253| Step: 0
Training loss: 2.0593934059143066
Validation loss: 2.036131574261573

Epoch: 5| Step: 1
Training loss: 2.1346354484558105
Validation loss: 2.026125000369164

Epoch: 5| Step: 2
Training loss: 1.9673268795013428
Validation loss: 2.0540619691212973

Epoch: 5| Step: 3
Training loss: 1.9462066888809204
Validation loss: 1.9892662571322532

Epoch: 5| Step: 4
Training loss: 1.2297556400299072
Validation loss: 2.063899811877999

Epoch: 5| Step: 5
Training loss: 1.3440709114074707
Validation loss: 2.000502960656279

Epoch: 5| Step: 6
Training loss: 1.5554845333099365
Validation loss: 2.023732211000176

Epoch: 5| Step: 7
Training loss: 1.465138554573059
Validation loss: 1.9878614077004053

Epoch: 5| Step: 8
Training loss: 1.663458228111267
Validation loss: 2.012967783917663

Epoch: 5| Step: 9
Training loss: 1.9183499813079834
Validation loss: 1.995306876397902

Epoch: 5| Step: 10
Training loss: 1.820412278175354
Validation loss: 1.9843457232239425

Epoch: 254| Step: 0
Training loss: 1.5466545820236206
Validation loss: 1.9883562480249712

Epoch: 5| Step: 1
Training loss: 1.5436980724334717
Validation loss: 1.9999953585286294

Epoch: 5| Step: 2
Training loss: 1.846181869506836
Validation loss: 1.9760883610735658

Epoch: 5| Step: 3
Training loss: 1.247071385383606
Validation loss: 2.0091787730493853

Epoch: 5| Step: 4
Training loss: 1.1132678985595703
Validation loss: 2.0416928722012426

Epoch: 5| Step: 5
Training loss: 2.002742290496826
Validation loss: 2.026954416305788

Epoch: 5| Step: 6
Training loss: 2.2634644508361816
Validation loss: 1.9836744005962084

Epoch: 5| Step: 7
Training loss: 1.951711893081665
Validation loss: 2.0309353618211645

Epoch: 5| Step: 8
Training loss: 1.8294776678085327
Validation loss: 1.9978522216120074

Epoch: 5| Step: 9
Training loss: 1.5014970302581787
Validation loss: 2.0152313029894264

Epoch: 5| Step: 10
Training loss: 2.2340238094329834
Validation loss: 2.01491141575639

Epoch: 255| Step: 0
Training loss: 1.7198781967163086
Validation loss: 1.9873249415428407

Epoch: 5| Step: 1
Training loss: 1.8039487600326538
Validation loss: 2.0336372365233717

Epoch: 5| Step: 2
Training loss: 1.286380410194397
Validation loss: 2.0410983844469954

Epoch: 5| Step: 3
Training loss: 2.109346866607666
Validation loss: 2.021328867122691

Epoch: 5| Step: 4
Training loss: 1.5403521060943604
Validation loss: 2.048371661093927

Epoch: 5| Step: 5
Training loss: 1.5887171030044556
Validation loss: 2.0116781342414116

Epoch: 5| Step: 6
Training loss: 1.5183242559432983
Validation loss: 2.0568286988043014

Epoch: 5| Step: 7
Training loss: 1.7145349979400635
Validation loss: 2.062779998266569

Epoch: 5| Step: 8
Training loss: 1.7065309286117554
Validation loss: 2.0464425561248616

Epoch: 5| Step: 9
Training loss: 1.7775859832763672
Validation loss: 2.011890608777282

Epoch: 5| Step: 10
Training loss: 2.1102466583251953
Validation loss: 2.0580974804457797

Epoch: 256| Step: 0
Training loss: 1.2284371852874756
Validation loss: 2.0430012851633053

Epoch: 5| Step: 1
Training loss: 2.369234561920166
Validation loss: 2.05228284353851

Epoch: 5| Step: 2
Training loss: 1.580068588256836
Validation loss: 2.048112045052231

Epoch: 5| Step: 3
Training loss: 1.3241159915924072
Validation loss: 1.9975509041099138

Epoch: 5| Step: 4
Training loss: 1.7655376195907593
Validation loss: 2.0022668274500037

Epoch: 5| Step: 5
Training loss: 2.0491442680358887
Validation loss: 1.9773339840673632

Epoch: 5| Step: 6
Training loss: 1.568250298500061
Validation loss: 2.0031075503236506

Epoch: 5| Step: 7
Training loss: 1.9283342361450195
Validation loss: 2.0265910856185423

Epoch: 5| Step: 8
Training loss: 2.0626747608184814
Validation loss: 2.01580564437374

Epoch: 5| Step: 9
Training loss: 1.859250783920288
Validation loss: 1.989687164624532

Epoch: 5| Step: 10
Training loss: 1.3486990928649902
Validation loss: 1.9802437264432189

Epoch: 257| Step: 0
Training loss: 1.7940499782562256
Validation loss: 2.0364158512443624

Epoch: 5| Step: 1
Training loss: 1.9641567468643188
Validation loss: 2.0455106817265993

Epoch: 5| Step: 2
Training loss: 1.2026208639144897
Validation loss: 2.0095810685106503

Epoch: 5| Step: 3
Training loss: 1.682903528213501
Validation loss: 2.023422682157127

Epoch: 5| Step: 4
Training loss: 1.2289443016052246
Validation loss: 1.9577411182465092

Epoch: 5| Step: 5
Training loss: 2.560640573501587
Validation loss: 2.0331862331718527

Epoch: 5| Step: 6
Training loss: 1.4029136896133423
Validation loss: 2.012109823124383

Epoch: 5| Step: 7
Training loss: 1.7582933902740479
Validation loss: 2.0253894611071517

Epoch: 5| Step: 8
Training loss: 1.674633264541626
Validation loss: 2.0543992339923816

Epoch: 5| Step: 9
Training loss: 1.9011341333389282
Validation loss: 2.0266528283396075

Epoch: 5| Step: 10
Training loss: 1.6157327890396118
Validation loss: 1.9981579716487596

Epoch: 258| Step: 0
Training loss: 1.6187427043914795
Validation loss: 2.020672736629363

Epoch: 5| Step: 1
Training loss: 1.8435474634170532
Validation loss: 2.052756013408784

Epoch: 5| Step: 2
Training loss: 1.4810335636138916
Validation loss: 2.027585011656566

Epoch: 5| Step: 3
Training loss: 1.5099767446517944
Validation loss: 2.046887928439725

Epoch: 5| Step: 4
Training loss: 1.5492208003997803
Validation loss: 2.0146931166289956

Epoch: 5| Step: 5
Training loss: 2.2511277198791504
Validation loss: 2.0115211894435268

Epoch: 5| Step: 6
Training loss: 1.9058749675750732
Validation loss: 2.054899823281073

Epoch: 5| Step: 7
Training loss: 1.6900116205215454
Validation loss: 2.06286270131347

Epoch: 5| Step: 8
Training loss: 1.5435453653335571
Validation loss: 2.0328804190440843

Epoch: 5| Step: 9
Training loss: 1.6730926036834717
Validation loss: 1.9959782733712146

Epoch: 5| Step: 10
Training loss: 1.7424955368041992
Validation loss: 2.0042584685869116

Epoch: 259| Step: 0
Training loss: 1.3010749816894531
Validation loss: 2.005522971512169

Epoch: 5| Step: 1
Training loss: 1.6006721258163452
Validation loss: 2.0148497499445432

Epoch: 5| Step: 2
Training loss: 2.0759499073028564
Validation loss: 2.004910656200942

Epoch: 5| Step: 3
Training loss: 1.5926628112792969
Validation loss: 2.0414845687086864

Epoch: 5| Step: 4
Training loss: 2.191683530807495
Validation loss: 2.029969928085163

Epoch: 5| Step: 5
Training loss: 1.799033522605896
Validation loss: 2.063632103704637

Epoch: 5| Step: 6
Training loss: 2.1220247745513916
Validation loss: 2.0322763766011884

Epoch: 5| Step: 7
Training loss: 2.112443685531616
Validation loss: 2.0145081730299097

Epoch: 5| Step: 8
Training loss: 1.5081137418746948
Validation loss: 2.0034238279506726

Epoch: 5| Step: 9
Training loss: 1.356722116470337
Validation loss: 2.0081732708920716

Epoch: 5| Step: 10
Training loss: 1.2449620962142944
Validation loss: 2.0162717244958364

Epoch: 260| Step: 0
Training loss: 1.897099256515503
Validation loss: 2.001656183632471

Epoch: 5| Step: 1
Training loss: 1.6807212829589844
Validation loss: 2.0152742811428603

Epoch: 5| Step: 2
Training loss: 1.563159704208374
Validation loss: 2.0870030592846613

Epoch: 5| Step: 3
Training loss: 1.9817546606063843
Validation loss: 2.0325881204297467

Epoch: 5| Step: 4
Training loss: 1.939501166343689
Validation loss: 2.0509773095448813

Epoch: 5| Step: 5
Training loss: 1.5837581157684326
Validation loss: 2.0582624955843856

Epoch: 5| Step: 6
Training loss: 1.6623356342315674
Validation loss: 2.0592362444887877

Epoch: 5| Step: 7
Training loss: 2.0751521587371826
Validation loss: 2.0194355313495924

Epoch: 5| Step: 8
Training loss: 1.7198076248168945
Validation loss: 2.0229822102413384

Epoch: 5| Step: 9
Training loss: 1.42281174659729
Validation loss: 1.9869393046184252

Epoch: 5| Step: 10
Training loss: 1.3448328971862793
Validation loss: 1.992638296978448

Epoch: 261| Step: 0
Training loss: 1.9699236154556274
Validation loss: 2.013367365765315

Epoch: 5| Step: 1
Training loss: 1.435443639755249
Validation loss: 2.00408515878903

Epoch: 5| Step: 2
Training loss: 1.4012527465820312
Validation loss: 2.0098675553516676

Epoch: 5| Step: 3
Training loss: 1.8812118768692017
Validation loss: 2.0394379605529127

Epoch: 5| Step: 4
Training loss: 1.146071434020996
Validation loss: 2.066031967439959

Epoch: 5| Step: 5
Training loss: 2.2606582641601562
Validation loss: 2.023311822645126

Epoch: 5| Step: 6
Training loss: 1.8969119787216187
Validation loss: 1.9731112718582153

Epoch: 5| Step: 7
Training loss: 1.6090484857559204
Validation loss: 2.0372418972753708

Epoch: 5| Step: 8
Training loss: 1.7415498495101929
Validation loss: 1.9857809979428527

Epoch: 5| Step: 9
Training loss: 1.94316828250885
Validation loss: 2.0062517325083413

Epoch: 5| Step: 10
Training loss: 1.5711604356765747
Validation loss: 2.018498969334428

Epoch: 262| Step: 0
Training loss: 1.8121435642242432
Validation loss: 2.0543463537769933

Epoch: 5| Step: 1
Training loss: 1.570449709892273
Validation loss: 2.040461132603307

Epoch: 5| Step: 2
Training loss: 1.5965068340301514
Validation loss: 2.019250677477929

Epoch: 5| Step: 3
Training loss: 1.880842924118042
Validation loss: 2.0378874937693277

Epoch: 5| Step: 4
Training loss: 2.072974681854248
Validation loss: 2.0370511739484725

Epoch: 5| Step: 5
Training loss: 1.8813127279281616
Validation loss: 2.01861979756304

Epoch: 5| Step: 6
Training loss: 1.6089576482772827
Validation loss: 2.036444551201277

Epoch: 5| Step: 7
Training loss: 1.6057888269424438
Validation loss: 1.9703793435968378

Epoch: 5| Step: 8
Training loss: 1.515720248222351
Validation loss: 1.992250124613444

Epoch: 5| Step: 9
Training loss: 1.3094784021377563
Validation loss: 2.033374395421756

Epoch: 5| Step: 10
Training loss: 1.862989068031311
Validation loss: 2.0452970612433647

Epoch: 263| Step: 0
Training loss: 1.291475534439087
Validation loss: 2.001291392951883

Epoch: 5| Step: 1
Training loss: 2.1023192405700684
Validation loss: 2.030843452740741

Epoch: 5| Step: 2
Training loss: 1.826590895652771
Validation loss: 1.9901934695500199

Epoch: 5| Step: 3
Training loss: 1.7055158615112305
Validation loss: 2.0539142239478325

Epoch: 5| Step: 4
Training loss: 1.4420764446258545
Validation loss: 1.9867578347524006

Epoch: 5| Step: 5
Training loss: 2.02943754196167
Validation loss: 1.996133054456403

Epoch: 5| Step: 6
Training loss: 1.6838394403457642
Validation loss: 2.01686030690388

Epoch: 5| Step: 7
Training loss: 1.7003366947174072
Validation loss: 2.022233857903429

Epoch: 5| Step: 8
Training loss: 1.6339563131332397
Validation loss: 1.999886017973705

Epoch: 5| Step: 9
Training loss: 1.839870810508728
Validation loss: 2.0291472891325593

Epoch: 5| Step: 10
Training loss: 1.7375147342681885
Validation loss: 2.0197135838129188

Epoch: 264| Step: 0
Training loss: 1.4283955097198486
Validation loss: 2.0138209366029307

Epoch: 5| Step: 1
Training loss: 1.5857617855072021
Validation loss: 2.044633880738289

Epoch: 5| Step: 2
Training loss: 1.5884473323822021
Validation loss: 2.0101961051264117

Epoch: 5| Step: 3
Training loss: 2.034682035446167
Validation loss: 2.0225627473605576

Epoch: 5| Step: 4
Training loss: 1.9537971019744873
Validation loss: 2.003961160618772

Epoch: 5| Step: 5
Training loss: 2.10176420211792
Validation loss: 2.036094154081037

Epoch: 5| Step: 6
Training loss: 2.096452236175537
Validation loss: 2.0124031651404595

Epoch: 5| Step: 7
Training loss: 1.3349632024765015
Validation loss: 2.058303383088881

Epoch: 5| Step: 8
Training loss: 1.479187250137329
Validation loss: 2.0167553347925984

Epoch: 5| Step: 9
Training loss: 1.487504243850708
Validation loss: 1.9686832966343049

Epoch: 5| Step: 10
Training loss: 1.8757898807525635
Validation loss: 2.022666851679484

Epoch: 265| Step: 0
Training loss: 1.9361648559570312
Validation loss: 2.0017646102495092

Epoch: 5| Step: 1
Training loss: 1.6063144207000732
Validation loss: 2.026499404702135

Epoch: 5| Step: 2
Training loss: 1.7973148822784424
Validation loss: 1.9899063289806407

Epoch: 5| Step: 3
Training loss: 1.48281729221344
Validation loss: 2.035912113804971

Epoch: 5| Step: 4
Training loss: 1.6526298522949219
Validation loss: 1.9921386331640265

Epoch: 5| Step: 5
Training loss: 1.8055784702301025
Validation loss: 1.988125439613096

Epoch: 5| Step: 6
Training loss: 1.5805587768554688
Validation loss: 1.9943877445754183

Epoch: 5| Step: 7
Training loss: 1.4328234195709229
Validation loss: 2.0325316780356952

Epoch: 5| Step: 8
Training loss: 1.2612757682800293
Validation loss: 2.0475929911418627

Epoch: 5| Step: 9
Training loss: 2.4974143505096436
Validation loss: 2.044009400952247

Epoch: 5| Step: 10
Training loss: 1.6172035932540894
Validation loss: 2.036184985150573

Epoch: 266| Step: 0
Training loss: 1.3806469440460205
Validation loss: 2.0186492807121685

Epoch: 5| Step: 1
Training loss: 1.6004797220230103
Validation loss: 2.0767092422772477

Epoch: 5| Step: 2
Training loss: 1.633345365524292
Validation loss: 2.009056406636392

Epoch: 5| Step: 3
Training loss: 1.6304149627685547
Validation loss: 2.0627364138121247

Epoch: 5| Step: 4
Training loss: 1.5935850143432617
Validation loss: 2.0451988571433612

Epoch: 5| Step: 5
Training loss: 2.3361377716064453
Validation loss: 2.0543919558166177

Epoch: 5| Step: 6
Training loss: 1.6287590265274048
Validation loss: 2.025004222828855

Epoch: 5| Step: 7
Training loss: 1.5673387050628662
Validation loss: 2.0374326270113707

Epoch: 5| Step: 8
Training loss: 1.8527904748916626
Validation loss: 2.010040972822456

Epoch: 5| Step: 9
Training loss: 1.8251928091049194
Validation loss: 2.0477408670609996

Epoch: 5| Step: 10
Training loss: 1.9965380430221558
Validation loss: 2.0217604867873655

Epoch: 267| Step: 0
Training loss: 1.6342090368270874
Validation loss: 2.0161172882203133

Epoch: 5| Step: 1
Training loss: 2.0158543586730957
Validation loss: 2.0367439934002456

Epoch: 5| Step: 2
Training loss: 1.17854642868042
Validation loss: 2.0241425242475284

Epoch: 5| Step: 3
Training loss: 1.9222662448883057
Validation loss: 2.011057510170885

Epoch: 5| Step: 4
Training loss: 2.0253591537475586
Validation loss: 2.003762550251458

Epoch: 5| Step: 5
Training loss: 1.5465971231460571
Validation loss: 2.030507577362881

Epoch: 5| Step: 6
Training loss: 1.335950255393982
Validation loss: 2.019788924083915

Epoch: 5| Step: 7
Training loss: 1.0763318538665771
Validation loss: 2.051114709146561

Epoch: 5| Step: 8
Training loss: 2.158142328262329
Validation loss: 2.026915278486026

Epoch: 5| Step: 9
Training loss: 1.960873007774353
Validation loss: 1.997792746431084

Epoch: 5| Step: 10
Training loss: 1.855955719947815
Validation loss: 2.0271819458212903

Epoch: 268| Step: 0
Training loss: 1.9322516918182373
Validation loss: 2.051437895785096

Epoch: 5| Step: 1
Training loss: 1.8448889255523682
Validation loss: 2.0376421495150496

Epoch: 5| Step: 2
Training loss: 0.9577609896659851
Validation loss: 2.0380653642839

Epoch: 5| Step: 3
Training loss: 1.9544627666473389
Validation loss: 2.0114126795081684

Epoch: 5| Step: 4
Training loss: 1.7837746143341064
Validation loss: 2.0204626321792603

Epoch: 5| Step: 5
Training loss: 1.561509370803833
Validation loss: 2.02388959546243

Epoch: 5| Step: 6
Training loss: 1.1995899677276611
Validation loss: 1.9845652067533104

Epoch: 5| Step: 7
Training loss: 1.3454395532608032
Validation loss: 2.0546391266648487

Epoch: 5| Step: 8
Training loss: 1.5913499593734741
Validation loss: 2.029789932312504

Epoch: 5| Step: 9
Training loss: 2.2583911418914795
Validation loss: 2.009410362089834

Epoch: 5| Step: 10
Training loss: 2.0114893913269043
Validation loss: 2.009256451360641

Epoch: 269| Step: 0
Training loss: 1.4390206336975098
Validation loss: 2.0101545010843584

Epoch: 5| Step: 1
Training loss: 1.5604685544967651
Validation loss: 1.999373346246699

Epoch: 5| Step: 2
Training loss: 1.6836700439453125
Validation loss: 1.9934759691197386

Epoch: 5| Step: 3
Training loss: 1.8080097436904907
Validation loss: 2.028027052520424

Epoch: 5| Step: 4
Training loss: 1.2597978115081787
Validation loss: 2.0521307529941684

Epoch: 5| Step: 5
Training loss: 1.5450537204742432
Validation loss: 1.9715056163008495

Epoch: 5| Step: 6
Training loss: 1.9084522724151611
Validation loss: 2.052338856522755

Epoch: 5| Step: 7
Training loss: 1.6583503484725952
Validation loss: 2.012692666822864

Epoch: 5| Step: 8
Training loss: 1.8885990381240845
Validation loss: 2.021011775539767

Epoch: 5| Step: 9
Training loss: 1.588762879371643
Validation loss: 2.042166445844917

Epoch: 5| Step: 10
Training loss: 2.386569023132324
Validation loss: 2.0288215414170296

Epoch: 270| Step: 0
Training loss: 2.042675733566284
Validation loss: 2.0681048234303794

Epoch: 5| Step: 1
Training loss: 2.086056709289551
Validation loss: 2.0112297637488252

Epoch: 5| Step: 2
Training loss: 1.7997411489486694
Validation loss: 2.0347417041819584

Epoch: 5| Step: 3
Training loss: 1.7261037826538086
Validation loss: 2.027859668577871

Epoch: 5| Step: 4
Training loss: 1.7551209926605225
Validation loss: 2.012302743491306

Epoch: 5| Step: 5
Training loss: 1.9764001369476318
Validation loss: 2.0527404354464625

Epoch: 5| Step: 6
Training loss: 1.5906505584716797
Validation loss: 2.052082009212945

Epoch: 5| Step: 7
Training loss: 1.2224396467208862
Validation loss: 2.049701467637093

Epoch: 5| Step: 8
Training loss: 1.6670116186141968
Validation loss: 2.037946956132048

Epoch: 5| Step: 9
Training loss: 1.2483787536621094
Validation loss: 2.0233517103297736

Epoch: 5| Step: 10
Training loss: 1.3398773670196533
Validation loss: 2.048567359165479

Epoch: 271| Step: 0
Training loss: 1.5600335597991943
Validation loss: 2.011344531530975

Epoch: 5| Step: 1
Training loss: 0.9028812646865845
Validation loss: 1.994407420517296

Epoch: 5| Step: 2
Training loss: 1.4546854496002197
Validation loss: 2.0110443561307845

Epoch: 5| Step: 3
Training loss: 2.0005555152893066
Validation loss: 2.020571252351166

Epoch: 5| Step: 4
Training loss: 1.974900245666504
Validation loss: 2.0107737433525825

Epoch: 5| Step: 5
Training loss: 1.9401719570159912
Validation loss: 2.0207231583133822

Epoch: 5| Step: 6
Training loss: 1.814632773399353
Validation loss: 2.0211387218967563

Epoch: 5| Step: 7
Training loss: 1.6792991161346436
Validation loss: 2.0338484253934634

Epoch: 5| Step: 8
Training loss: 1.7481329441070557
Validation loss: 2.040236824302263

Epoch: 5| Step: 9
Training loss: 1.7186870574951172
Validation loss: 2.0549548338818293

Epoch: 5| Step: 10
Training loss: 1.6879746913909912
Validation loss: 2.0126308920562908

Epoch: 272| Step: 0
Training loss: 1.1069715023040771
Validation loss: 2.0405236380074614

Epoch: 5| Step: 1
Training loss: 2.2790160179138184
Validation loss: 2.0329331249319096

Epoch: 5| Step: 2
Training loss: 2.2088675498962402
Validation loss: 2.0518799174216484

Epoch: 5| Step: 3
Training loss: 1.3234174251556396
Validation loss: 2.0485568277297483

Epoch: 5| Step: 4
Training loss: 1.8346933126449585
Validation loss: 2.0248461308017855

Epoch: 5| Step: 5
Training loss: 2.019080400466919
Validation loss: 2.0041417434651363

Epoch: 5| Step: 6
Training loss: 2.135230302810669
Validation loss: 2.030290357528194

Epoch: 5| Step: 7
Training loss: 1.5471457242965698
Validation loss: 2.030198863757554

Epoch: 5| Step: 8
Training loss: 1.5459821224212646
Validation loss: 2.0050469393371255

Epoch: 5| Step: 9
Training loss: 1.0641956329345703
Validation loss: 2.059239697712724

Epoch: 5| Step: 10
Training loss: 1.2509580850601196
Validation loss: 2.0023685604013424

Epoch: 273| Step: 0
Training loss: 2.094191551208496
Validation loss: 2.039594848950704

Epoch: 5| Step: 1
Training loss: 1.5659167766571045
Validation loss: 2.0000225472193893

Epoch: 5| Step: 2
Training loss: 1.5575988292694092
Validation loss: 2.01661991816695

Epoch: 5| Step: 3
Training loss: 1.6841007471084595
Validation loss: 1.9612732753958753

Epoch: 5| Step: 4
Training loss: 1.7944059371948242
Validation loss: 2.0276819582908385

Epoch: 5| Step: 5
Training loss: 1.9915895462036133
Validation loss: 2.0511029958724976

Epoch: 5| Step: 6
Training loss: 1.5031765699386597
Validation loss: 2.0366203733669814

Epoch: 5| Step: 7
Training loss: 0.9930065274238586
Validation loss: 1.9821049423627957

Epoch: 5| Step: 8
Training loss: 1.7889213562011719
Validation loss: 2.0038812365583194

Epoch: 5| Step: 9
Training loss: 1.3143423795700073
Validation loss: 2.032386804139742

Epoch: 5| Step: 10
Training loss: 2.2365851402282715
Validation loss: 2.0316962119071715

Epoch: 274| Step: 0
Training loss: 1.5069422721862793
Validation loss: 1.9974134839991087

Epoch: 5| Step: 1
Training loss: 2.0688509941101074
Validation loss: 2.04223136491673

Epoch: 5| Step: 2
Training loss: 1.2837815284729004
Validation loss: 1.9920466048743135

Epoch: 5| Step: 3
Training loss: 2.150167942047119
Validation loss: 1.983459113746561

Epoch: 5| Step: 4
Training loss: 2.109093189239502
Validation loss: 2.0763887359249975

Epoch: 5| Step: 5
Training loss: 1.2060775756835938
Validation loss: 2.010174168053494

Epoch: 5| Step: 6
Training loss: 1.3461189270019531
Validation loss: 2.026010622260391

Epoch: 5| Step: 7
Training loss: 1.4845422506332397
Validation loss: 1.998779349429633

Epoch: 5| Step: 8
Training loss: 2.0197298526763916
Validation loss: 2.029435912768046

Epoch: 5| Step: 9
Training loss: 1.280562400817871
Validation loss: 2.0255759351996967

Epoch: 5| Step: 10
Training loss: 2.089109420776367
Validation loss: 2.0028362761261644

Epoch: 275| Step: 0
Training loss: 1.4895321130752563
Validation loss: 2.0092682530803065

Epoch: 5| Step: 1
Training loss: 2.155097484588623
Validation loss: 2.0417334495052213

Epoch: 5| Step: 2
Training loss: 1.4675970077514648
Validation loss: 2.050987667934869

Epoch: 5| Step: 3
Training loss: 1.382836937904358
Validation loss: 2.0736441509698027

Epoch: 5| Step: 4
Training loss: 2.267343044281006
Validation loss: 2.036021347968809

Epoch: 5| Step: 5
Training loss: 1.5991443395614624
Validation loss: 2.0919471120321624

Epoch: 5| Step: 6
Training loss: 1.9682581424713135
Validation loss: 2.0760281624332553

Epoch: 5| Step: 7
Training loss: 1.80405592918396
Validation loss: 2.0291946421387377

Epoch: 5| Step: 8
Training loss: 1.393121600151062
Validation loss: 2.0753843092149302

Epoch: 5| Step: 9
Training loss: 1.5542163848876953
Validation loss: 2.106996856709962

Epoch: 5| Step: 10
Training loss: 1.183693289756775
Validation loss: 2.0513360731063353

Epoch: 276| Step: 0
Training loss: 1.7794392108917236
Validation loss: 2.0472588539123535

Epoch: 5| Step: 1
Training loss: 1.8849174976348877
Validation loss: 2.031192289885654

Epoch: 5| Step: 2
Training loss: 1.4818090200424194
Validation loss: 2.0337457349223476

Epoch: 5| Step: 3
Training loss: 1.2521085739135742
Validation loss: 2.0435468971088366

Epoch: 5| Step: 4
Training loss: 1.280809998512268
Validation loss: 2.0386185774239163

Epoch: 5| Step: 5
Training loss: 1.9738467931747437
Validation loss: 2.0052286578762915

Epoch: 5| Step: 6
Training loss: 2.209005832672119
Validation loss: 2.031094789505005

Epoch: 5| Step: 7
Training loss: 1.4839448928833008
Validation loss: 2.0143857694441274

Epoch: 5| Step: 8
Training loss: 1.6419875621795654
Validation loss: 2.0109389046187043

Epoch: 5| Step: 9
Training loss: 1.706634283065796
Validation loss: 2.026510025865288

Epoch: 5| Step: 10
Training loss: 2.077723741531372
Validation loss: 2.0116030118798696

Epoch: 277| Step: 0
Training loss: 2.076056957244873
Validation loss: 2.0072466224752445

Epoch: 5| Step: 1
Training loss: 2.0772032737731934
Validation loss: 1.9917814757234307

Epoch: 5| Step: 2
Training loss: 1.8453747034072876
Validation loss: 2.0516175749481365

Epoch: 5| Step: 3
Training loss: 1.1803163290023804
Validation loss: 2.0551414105199997

Epoch: 5| Step: 4
Training loss: 1.2913440465927124
Validation loss: 2.0172451490996988

Epoch: 5| Step: 5
Training loss: 1.2850967645645142
Validation loss: 2.0650928174295733

Epoch: 5| Step: 6
Training loss: 1.536049246788025
Validation loss: 2.0526196008087485

Epoch: 5| Step: 7
Training loss: 1.9161598682403564
Validation loss: 2.082118845755054

Epoch: 5| Step: 8
Training loss: 1.912793517112732
Validation loss: 2.033402050695112

Epoch: 5| Step: 9
Training loss: 1.7529007196426392
Validation loss: 2.0328792628421577

Epoch: 5| Step: 10
Training loss: 1.385985016822815
Validation loss: 2.006071857226792

Epoch: 278| Step: 0
Training loss: 1.4095666408538818
Validation loss: 2.0604461662230955

Epoch: 5| Step: 1
Training loss: 1.8023955821990967
Validation loss: 2.070288404341667

Epoch: 5| Step: 2
Training loss: 1.9199340343475342
Validation loss: 2.0416643388809694

Epoch: 5| Step: 3
Training loss: 1.9901268482208252
Validation loss: 2.038992372892236

Epoch: 5| Step: 4
Training loss: 1.6731719970703125
Validation loss: 2.030502526990829

Epoch: 5| Step: 5
Training loss: 1.6580979824066162
Validation loss: 2.023642360523183

Epoch: 5| Step: 6
Training loss: 1.0738611221313477
Validation loss: 1.9950240350538684

Epoch: 5| Step: 7
Training loss: 1.7005455493927002
Validation loss: 2.0381234807352864

Epoch: 5| Step: 8
Training loss: 1.636549949645996
Validation loss: 2.0110781038961103

Epoch: 5| Step: 9
Training loss: 2.403196096420288
Validation loss: 2.040304950488511

Epoch: 5| Step: 10
Training loss: 1.2666951417922974
Validation loss: 1.9879451464581233

Epoch: 279| Step: 0
Training loss: 1.866166353225708
Validation loss: 2.024750676206363

Epoch: 5| Step: 1
Training loss: 1.9770504236221313
Validation loss: 1.9877207292023527

Epoch: 5| Step: 2
Training loss: 1.1181267499923706
Validation loss: 2.0086837237881077

Epoch: 5| Step: 3
Training loss: 1.161067247390747
Validation loss: 2.0219141693525415

Epoch: 5| Step: 4
Training loss: 1.560935616493225
Validation loss: 2.0189405718157367

Epoch: 5| Step: 5
Training loss: 1.7003421783447266
Validation loss: 2.047547532666114

Epoch: 5| Step: 6
Training loss: 1.6477463245391846
Validation loss: 2.0241851806640625

Epoch: 5| Step: 7
Training loss: 2.03023099899292
Validation loss: 2.0429987702318417

Epoch: 5| Step: 8
Training loss: 1.4592864513397217
Validation loss: 2.01755460616081

Epoch: 5| Step: 9
Training loss: 1.9772498607635498
Validation loss: 2.0220649357764953

Epoch: 5| Step: 10
Training loss: 2.0437371730804443
Validation loss: 2.0549809983981553

Epoch: 280| Step: 0
Training loss: 2.3206028938293457
Validation loss: 2.0491022192021853

Epoch: 5| Step: 1
Training loss: 1.3077455759048462
Validation loss: 2.0443027891138548

Epoch: 5| Step: 2
Training loss: 1.9774055480957031
Validation loss: 2.078486201583698

Epoch: 5| Step: 3
Training loss: 1.700988531112671
Validation loss: 2.0212806527332594

Epoch: 5| Step: 4
Training loss: 1.5288490056991577
Validation loss: 2.040970858707223

Epoch: 5| Step: 5
Training loss: 1.503273844718933
Validation loss: 2.030509121956364

Epoch: 5| Step: 6
Training loss: 1.3590494394302368
Validation loss: 1.9996535060226277

Epoch: 5| Step: 7
Training loss: 1.6475169658660889
Validation loss: 2.0213620790871243

Epoch: 5| Step: 8
Training loss: 1.2464029788970947
Validation loss: 2.0451798900481193

Epoch: 5| Step: 9
Training loss: 1.5851991176605225
Validation loss: 2.0407735557966333

Epoch: 5| Step: 10
Training loss: 2.3789658546447754
Validation loss: 2.045891320833596

Epoch: 281| Step: 0
Training loss: 2.2040181159973145
Validation loss: 2.023542042701475

Epoch: 5| Step: 1
Training loss: 1.8923298120498657
Validation loss: 2.0153251540276313

Epoch: 5| Step: 2
Training loss: 1.4300940036773682
Validation loss: 2.0356550447402464

Epoch: 5| Step: 3
Training loss: 1.1227421760559082
Validation loss: 2.0445011610625894

Epoch: 5| Step: 4
Training loss: 1.431989073753357
Validation loss: 1.9941850246921662

Epoch: 5| Step: 5
Training loss: 1.626612901687622
Validation loss: 2.026136088114913

Epoch: 5| Step: 6
Training loss: 1.838083267211914
Validation loss: 2.005619950191949

Epoch: 5| Step: 7
Training loss: 1.599538803100586
Validation loss: 2.0170061844651417

Epoch: 5| Step: 8
Training loss: 1.44121253490448
Validation loss: 2.0301116948486655

Epoch: 5| Step: 9
Training loss: 1.8307600021362305
Validation loss: 2.0018617183931413

Epoch: 5| Step: 10
Training loss: 1.8452138900756836
Validation loss: 2.053209768828525

Epoch: 282| Step: 0
Training loss: 1.742100477218628
Validation loss: 2.0321757408880416

Epoch: 5| Step: 1
Training loss: 1.789002776145935
Validation loss: 2.020324150721232

Epoch: 5| Step: 2
Training loss: 1.8108603954315186
Validation loss: 1.986967190619438

Epoch: 5| Step: 3
Training loss: 1.6452308893203735
Validation loss: 2.0572973015487834

Epoch: 5| Step: 4
Training loss: 1.9891782999038696
Validation loss: 2.042416718698317

Epoch: 5| Step: 5
Training loss: 1.495871901512146
Validation loss: 2.010702507470244

Epoch: 5| Step: 6
Training loss: 1.798078179359436
Validation loss: 2.0574133370512273

Epoch: 5| Step: 7
Training loss: 1.5050904750823975
Validation loss: 2.0007978588022213

Epoch: 5| Step: 8
Training loss: 1.1793911457061768
Validation loss: 2.021246938295262

Epoch: 5| Step: 9
Training loss: 1.9167892932891846
Validation loss: 2.048828955619566

Epoch: 5| Step: 10
Training loss: 1.6162176132202148
Validation loss: 2.0780780443581204

Epoch: 283| Step: 0
Training loss: 1.7558162212371826
Validation loss: 2.0334158802545197

Epoch: 5| Step: 1
Training loss: 1.2946985960006714
Validation loss: 1.9922536214192708

Epoch: 5| Step: 2
Training loss: 1.6473886966705322
Validation loss: 2.053609417330834

Epoch: 5| Step: 3
Training loss: 2.1997063159942627
Validation loss: 1.9983262964474258

Epoch: 5| Step: 4
Training loss: 2.1018996238708496
Validation loss: 2.0039386082721014

Epoch: 5| Step: 5
Training loss: 1.324576735496521
Validation loss: 2.0051969584598335

Epoch: 5| Step: 6
Training loss: 2.0151314735412598
Validation loss: 2.031884237002301

Epoch: 5| Step: 7
Training loss: 1.2964054346084595
Validation loss: 2.029158261514479

Epoch: 5| Step: 8
Training loss: 1.8581796884536743
Validation loss: 2.0136931519354544

Epoch: 5| Step: 9
Training loss: 1.5632669925689697
Validation loss: 2.0548002412242274

Epoch: 5| Step: 10
Training loss: 1.2916828393936157
Validation loss: 2.056206517322089

Epoch: 284| Step: 0
Training loss: 1.329047679901123
Validation loss: 1.9794484402543755

Epoch: 5| Step: 1
Training loss: 2.127316951751709
Validation loss: 2.0645360562109176

Epoch: 5| Step: 2
Training loss: 1.5223512649536133
Validation loss: 2.0353466336445143

Epoch: 5| Step: 3
Training loss: 1.6307413578033447
Validation loss: 2.0245175335996892

Epoch: 5| Step: 4
Training loss: 1.62076735496521
Validation loss: 2.029109001159668

Epoch: 5| Step: 5
Training loss: 1.8227922916412354
Validation loss: 2.0563380410594325

Epoch: 5| Step: 6
Training loss: 1.8793283700942993
Validation loss: 2.0312331927719938

Epoch: 5| Step: 7
Training loss: 1.8563597202301025
Validation loss: 2.026081564605877

Epoch: 5| Step: 8
Training loss: 1.2206847667694092
Validation loss: 2.0227464014484036

Epoch: 5| Step: 9
Training loss: 1.6384223699569702
Validation loss: 2.0392228044489378

Epoch: 5| Step: 10
Training loss: 1.4107091426849365
Validation loss: 2.0171264756110405

Epoch: 285| Step: 0
Training loss: 1.502948522567749
Validation loss: 2.0537066587837796

Epoch: 5| Step: 1
Training loss: 1.9456079006195068
Validation loss: 1.9828793976896553

Epoch: 5| Step: 2
Training loss: 2.025171995162964
Validation loss: 2.0387166828237553

Epoch: 5| Step: 3
Training loss: 1.7891632318496704
Validation loss: 2.0533468595115085

Epoch: 5| Step: 4
Training loss: 1.552839994430542
Validation loss: 2.01153144785153

Epoch: 5| Step: 5
Training loss: 1.6762536764144897
Validation loss: 2.0346312651070217

Epoch: 5| Step: 6
Training loss: 1.5321180820465088
Validation loss: 2.0339105270242177

Epoch: 5| Step: 7
Training loss: 1.7661300897598267
Validation loss: 2.025687019030253

Epoch: 5| Step: 8
Training loss: 1.474945306777954
Validation loss: 2.0612568560466973

Epoch: 5| Step: 9
Training loss: 1.2436959743499756
Validation loss: 2.0534926614453717

Epoch: 5| Step: 10
Training loss: 1.6019647121429443
Validation loss: 2.0642898441642843

Epoch: 286| Step: 0
Training loss: 1.4912288188934326
Validation loss: 2.0234444731025287

Epoch: 5| Step: 1
Training loss: 2.306654930114746
Validation loss: 2.066542697209184

Epoch: 5| Step: 2
Training loss: 1.46518075466156
Validation loss: 2.0392936083578292

Epoch: 5| Step: 3
Training loss: 1.7975847721099854
Validation loss: 2.029291582363908

Epoch: 5| Step: 4
Training loss: 1.3515074253082275
Validation loss: 2.0353570663800804

Epoch: 5| Step: 5
Training loss: 1.5771512985229492
Validation loss: 2.037543789032967

Epoch: 5| Step: 6
Training loss: 1.2069919109344482
Validation loss: 1.9958145541529502

Epoch: 5| Step: 7
Training loss: 1.8260176181793213
Validation loss: 2.0410702279818955

Epoch: 5| Step: 8
Training loss: 1.6906465291976929
Validation loss: 2.075821504797987

Epoch: 5| Step: 9
Training loss: 1.8866045475006104
Validation loss: 2.040135209278394

Epoch: 5| Step: 10
Training loss: 1.894671082496643
Validation loss: 2.017903415105676

Epoch: 287| Step: 0
Training loss: 1.7361215353012085
Validation loss: 1.9940333776576544

Epoch: 5| Step: 1
Training loss: 1.7938724756240845
Validation loss: 2.0610727161489506

Epoch: 5| Step: 2
Training loss: 1.5345871448516846
Validation loss: 2.02276300743062

Epoch: 5| Step: 3
Training loss: 1.001741647720337
Validation loss: 2.0118352725941646

Epoch: 5| Step: 4
Training loss: 2.343247890472412
Validation loss: 2.0222034864528204

Epoch: 5| Step: 5
Training loss: 1.401439905166626
Validation loss: 2.0137244450148715

Epoch: 5| Step: 6
Training loss: 2.4529106616973877
Validation loss: 2.017581429532779

Epoch: 5| Step: 7
Training loss: 1.8441085815429688
Validation loss: 2.0348897826287056

Epoch: 5| Step: 8
Training loss: 1.504492998123169
Validation loss: 1.9953904126280098

Epoch: 5| Step: 9
Training loss: 1.2995145320892334
Validation loss: 2.0065998236338296

Epoch: 5| Step: 10
Training loss: 1.286728858947754
Validation loss: 2.0556421510634886

Epoch: 288| Step: 0
Training loss: 1.3457084894180298
Validation loss: 2.0361660552281204

Epoch: 5| Step: 1
Training loss: 1.9154605865478516
Validation loss: 2.040633260562856

Epoch: 5| Step: 2
Training loss: 1.890144944190979
Validation loss: 2.0258161252544773

Epoch: 5| Step: 3
Training loss: 1.693955421447754
Validation loss: 1.9864181498045563

Epoch: 5| Step: 4
Training loss: 1.2745596170425415
Validation loss: 2.01983150359123

Epoch: 5| Step: 5
Training loss: 2.5224692821502686
Validation loss: 2.0236465213119343

Epoch: 5| Step: 6
Training loss: 2.063991069793701
Validation loss: 2.0670291249470045

Epoch: 5| Step: 7
Training loss: 1.0083173513412476
Validation loss: 2.0432778045695317

Epoch: 5| Step: 8
Training loss: 1.3223730325698853
Validation loss: 2.075283460719611

Epoch: 5| Step: 9
Training loss: 1.580484390258789
Validation loss: 2.0585445883453533

Epoch: 5| Step: 10
Training loss: 1.5393282175064087
Validation loss: 2.0753529264080908

Epoch: 289| Step: 0
Training loss: 1.732373833656311
Validation loss: 2.0729925055657663

Epoch: 5| Step: 1
Training loss: 1.6199359893798828
Validation loss: 2.045089820379852

Epoch: 5| Step: 2
Training loss: 1.0334149599075317
Validation loss: 2.0168669915968374

Epoch: 5| Step: 3
Training loss: 1.459525465965271
Validation loss: 1.9968195000002462

Epoch: 5| Step: 4
Training loss: 2.3621134757995605
Validation loss: 2.0238184505893337

Epoch: 5| Step: 5
Training loss: 1.888869285583496
Validation loss: 2.0317696935387066

Epoch: 5| Step: 6
Training loss: 1.24349045753479
Validation loss: 1.991452763157506

Epoch: 5| Step: 7
Training loss: 2.173095226287842
Validation loss: 2.0454574144014748

Epoch: 5| Step: 8
Training loss: 1.9077469110488892
Validation loss: 2.0269924068963654

Epoch: 5| Step: 9
Training loss: 1.0567128658294678
Validation loss: 1.9900060904923307

Epoch: 5| Step: 10
Training loss: 1.3771742582321167
Validation loss: 2.0287452936172485

Epoch: 290| Step: 0
Training loss: 1.8923088312149048
Validation loss: 2.0409897476114254

Epoch: 5| Step: 1
Training loss: 1.710494041442871
Validation loss: 2.036359833132836

Epoch: 5| Step: 2
Training loss: 1.752142310142517
Validation loss: 2.0211533513120425

Epoch: 5| Step: 3
Training loss: 1.570497989654541
Validation loss: 2.014373025586528

Epoch: 5| Step: 4
Training loss: 2.4878103733062744
Validation loss: 2.0062396628882295

Epoch: 5| Step: 5
Training loss: 1.2678568363189697
Validation loss: 2.0082367415069253

Epoch: 5| Step: 6
Training loss: 1.6499710083007812
Validation loss: 2.0103008875282864

Epoch: 5| Step: 7
Training loss: 1.6721168756484985
Validation loss: 2.0421554670538953

Epoch: 5| Step: 8
Training loss: 1.4390255212783813
Validation loss: 2.0267265945352535

Epoch: 5| Step: 9
Training loss: 0.9597463607788086
Validation loss: 2.0181493041335896

Epoch: 5| Step: 10
Training loss: 2.016178846359253
Validation loss: 2.036355059633973

Epoch: 291| Step: 0
Training loss: 2.1332345008850098
Validation loss: 2.050485211033975

Epoch: 5| Step: 1
Training loss: 1.5996646881103516
Validation loss: 2.061743269684494

Epoch: 5| Step: 2
Training loss: 1.7980735301971436
Validation loss: 2.035330726254371

Epoch: 5| Step: 3
Training loss: 1.8073585033416748
Validation loss: 2.0278502382257932

Epoch: 5| Step: 4
Training loss: 1.7427641153335571
Validation loss: 2.0535912885460803

Epoch: 5| Step: 5
Training loss: 1.3668667078018188
Validation loss: 2.0250013489877023

Epoch: 5| Step: 6
Training loss: 1.6802330017089844
Validation loss: 2.047311290617912

Epoch: 5| Step: 7
Training loss: 1.2384940385818481
Validation loss: 2.003267549699353

Epoch: 5| Step: 8
Training loss: 1.6012229919433594
Validation loss: 2.065938159983645

Epoch: 5| Step: 9
Training loss: 1.364789605140686
Validation loss: 2.04895354342717

Epoch: 5| Step: 10
Training loss: 1.9950467348098755
Validation loss: 2.0194835457750546

Epoch: 292| Step: 0
Training loss: 1.604278564453125
Validation loss: 2.071104165046446

Epoch: 5| Step: 1
Training loss: 1.8582311868667603
Validation loss: 2.0791693977130357

Epoch: 5| Step: 2
Training loss: 1.8831201791763306
Validation loss: 2.0523414355452343

Epoch: 5| Step: 3
Training loss: 1.4568769931793213
Validation loss: 2.0340339381207704

Epoch: 5| Step: 4
Training loss: 2.0113139152526855
Validation loss: 2.0400886266462264

Epoch: 5| Step: 5
Training loss: 1.6776517629623413
Validation loss: 2.0487302785278647

Epoch: 5| Step: 6
Training loss: 1.2239649295806885
Validation loss: 1.9993969932679208

Epoch: 5| Step: 7
Training loss: 1.11737859249115
Validation loss: 2.0539715110614734

Epoch: 5| Step: 8
Training loss: 1.532612919807434
Validation loss: 2.020937160779071

Epoch: 5| Step: 9
Training loss: 1.7925689220428467
Validation loss: 2.03342798192014

Epoch: 5| Step: 10
Training loss: 2.3370044231414795
Validation loss: 1.9847579258744434

Epoch: 293| Step: 0
Training loss: 2.0092670917510986
Validation loss: 2.0317362931466874

Epoch: 5| Step: 1
Training loss: 1.1584784984588623
Validation loss: 2.0060218841798845

Epoch: 5| Step: 2
Training loss: 1.4922091960906982
Validation loss: 2.030721859265399

Epoch: 5| Step: 3
Training loss: 1.6935081481933594
Validation loss: 1.9995485044294787

Epoch: 5| Step: 4
Training loss: 1.382655143737793
Validation loss: 2.0037173225033666

Epoch: 5| Step: 5
Training loss: 1.9866383075714111
Validation loss: 2.0386182441506335

Epoch: 5| Step: 6
Training loss: 1.3542791604995728
Validation loss: 2.0188674157665623

Epoch: 5| Step: 7
Training loss: 2.0587587356567383
Validation loss: 2.072489833319059

Epoch: 5| Step: 8
Training loss: 1.8587383031845093
Validation loss: 2.0531533354072162

Epoch: 5| Step: 9
Training loss: 1.4193048477172852
Validation loss: 2.033876593394946

Epoch: 5| Step: 10
Training loss: 1.6493157148361206
Validation loss: 2.012321905423236

Epoch: 294| Step: 0
Training loss: 1.7040512561798096
Validation loss: 2.0122911673720165

Epoch: 5| Step: 1
Training loss: 1.2905542850494385
Validation loss: 2.020748033318468

Epoch: 5| Step: 2
Training loss: 1.875591516494751
Validation loss: 2.0289827059674006

Epoch: 5| Step: 3
Training loss: 1.1104198694229126
Validation loss: 2.0145703002970707

Epoch: 5| Step: 4
Training loss: 2.0553059577941895
Validation loss: 2.0663064654155443

Epoch: 5| Step: 5
Training loss: 1.4493125677108765
Validation loss: 2.005347572347169

Epoch: 5| Step: 6
Training loss: 1.8125817775726318
Validation loss: 2.0305678895724717

Epoch: 5| Step: 7
Training loss: 1.9261630773544312
Validation loss: 1.9959177637612948

Epoch: 5| Step: 8
Training loss: 1.2228747606277466
Validation loss: 2.0226483524486585

Epoch: 5| Step: 9
Training loss: 1.6429002285003662
Validation loss: 2.0251559954817577

Epoch: 5| Step: 10
Training loss: 1.8397467136383057
Validation loss: 2.053968829493369

Epoch: 295| Step: 0
Training loss: 1.5691007375717163
Validation loss: 2.0724570751190186

Epoch: 5| Step: 1
Training loss: 1.9260272979736328
Validation loss: 2.0295337195037515

Epoch: 5| Step: 2
Training loss: 1.4788997173309326
Validation loss: 2.053523285414583

Epoch: 5| Step: 3
Training loss: 1.7901960611343384
Validation loss: 2.0389278704120266

Epoch: 5| Step: 4
Training loss: 2.5864415168762207
Validation loss: 2.097331121403684

Epoch: 5| Step: 5
Training loss: 1.3926734924316406
Validation loss: 2.049404946706628

Epoch: 5| Step: 6
Training loss: 1.531506896018982
Validation loss: 2.0657702927948325

Epoch: 5| Step: 7
Training loss: 1.7889982461929321
Validation loss: 2.0686366019710416

Epoch: 5| Step: 8
Training loss: 1.5512645244598389
Validation loss: 2.0287886845168246

Epoch: 5| Step: 9
Training loss: 1.0443143844604492
Validation loss: 2.0859226129388295

Epoch: 5| Step: 10
Training loss: 1.488247036933899
Validation loss: 2.0449126471755323

Epoch: 296| Step: 0
Training loss: 1.8900924921035767
Validation loss: 2.0183805804098807

Epoch: 5| Step: 1
Training loss: 1.6661297082901
Validation loss: 2.0307923645101567

Epoch: 5| Step: 2
Training loss: 1.7948843240737915
Validation loss: 2.0422507152762464

Epoch: 5| Step: 3
Training loss: 1.6532291173934937
Validation loss: 2.0753099021091255

Epoch: 5| Step: 4
Training loss: 1.4775073528289795
Validation loss: 2.013330216048866

Epoch: 5| Step: 5
Training loss: 1.3150007724761963
Validation loss: 2.0533569320555656

Epoch: 5| Step: 6
Training loss: 1.8668636083602905
Validation loss: 2.006271828887283

Epoch: 5| Step: 7
Training loss: 1.6859772205352783
Validation loss: 2.019416828309336

Epoch: 5| Step: 8
Training loss: 1.3254283666610718
Validation loss: 2.0284120882711103

Epoch: 5| Step: 9
Training loss: 1.7045360803604126
Validation loss: 2.008424106464591

Epoch: 5| Step: 10
Training loss: 1.6254959106445312
Validation loss: 2.019051246745612

Epoch: 297| Step: 0
Training loss: 1.8354324102401733
Validation loss: 2.0040048630006853

Epoch: 5| Step: 1
Training loss: 1.2110283374786377
Validation loss: 2.0211526283653836

Epoch: 5| Step: 2
Training loss: 1.1885888576507568
Validation loss: 2.019670594123102

Epoch: 5| Step: 3
Training loss: 1.360579013824463
Validation loss: 2.0374511646968063

Epoch: 5| Step: 4
Training loss: 2.724274158477783
Validation loss: 2.066472581637803

Epoch: 5| Step: 5
Training loss: 1.8092409372329712
Validation loss: 2.0243420293254237

Epoch: 5| Step: 6
Training loss: 1.6333715915679932
Validation loss: 2.0306663974638908

Epoch: 5| Step: 7
Training loss: 1.9171407222747803
Validation loss: 2.0328043724900935

Epoch: 5| Step: 8
Training loss: 1.4988062381744385
Validation loss: 2.0589728560498965

Epoch: 5| Step: 9
Training loss: 1.4564863443374634
Validation loss: 2.022947165273851

Epoch: 5| Step: 10
Training loss: 1.3055766820907593
Validation loss: 2.04979879881746

Epoch: 298| Step: 0
Training loss: 2.560612678527832
Validation loss: 2.058960353174517

Epoch: 5| Step: 1
Training loss: 1.710741639137268
Validation loss: 2.037120956246571

Epoch: 5| Step: 2
Training loss: 1.6116039752960205
Validation loss: 2.0148138000119116

Epoch: 5| Step: 3
Training loss: 1.822218656539917
Validation loss: 2.0278754311223186

Epoch: 5| Step: 4
Training loss: 2.161120891571045
Validation loss: 2.0086209850926555

Epoch: 5| Step: 5
Training loss: 1.218039870262146
Validation loss: 2.046114872860652

Epoch: 5| Step: 6
Training loss: 1.1112558841705322
Validation loss: 2.052403316702894

Epoch: 5| Step: 7
Training loss: 1.681708574295044
Validation loss: 2.03630978574035

Epoch: 5| Step: 8
Training loss: 1.8838398456573486
Validation loss: 2.0615332664981967

Epoch: 5| Step: 9
Training loss: 1.0470855236053467
Validation loss: 2.0328130709227694

Epoch: 5| Step: 10
Training loss: 1.1573001146316528
Validation loss: 1.9843470204261042

Epoch: 299| Step: 0
Training loss: 1.8224586248397827
Validation loss: 2.034929165276148

Epoch: 5| Step: 1
Training loss: 1.1014001369476318
Validation loss: 2.061162133370676

Epoch: 5| Step: 2
Training loss: 2.168518304824829
Validation loss: 2.0387628642461633

Epoch: 5| Step: 3
Training loss: 1.7207176685333252
Validation loss: 1.9995697454739643

Epoch: 5| Step: 4
Training loss: 1.8595664501190186
Validation loss: 2.0790832145239717

Epoch: 5| Step: 5
Training loss: 1.8366096019744873
Validation loss: 2.0467725774293304

Epoch: 5| Step: 6
Training loss: 1.3139146566390991
Validation loss: 2.006008783976237

Epoch: 5| Step: 7
Training loss: 1.322008490562439
Validation loss: 2.057633320490519

Epoch: 5| Step: 8
Training loss: 1.7104160785675049
Validation loss: 2.0136067713460615

Epoch: 5| Step: 9
Training loss: 1.3023958206176758
Validation loss: 2.0512456188919725

Epoch: 5| Step: 10
Training loss: 1.9866249561309814
Validation loss: 2.0613469769877772

Epoch: 300| Step: 0
Training loss: 0.8978229761123657
Validation loss: 2.047194855187529

Epoch: 5| Step: 1
Training loss: 1.1885647773742676
Validation loss: 2.006358395340622

Epoch: 5| Step: 2
Training loss: 1.6893106698989868
Validation loss: 1.997522343871414

Epoch: 5| Step: 3
Training loss: 2.410013198852539
Validation loss: 2.0250112497678368

Epoch: 5| Step: 4
Training loss: 1.7468630075454712
Validation loss: 2.043976823488871

Epoch: 5| Step: 5
Training loss: 1.8188050985336304
Validation loss: 2.0542817449056976

Epoch: 5| Step: 6
Training loss: 1.3827183246612549
Validation loss: 2.012718685211674

Epoch: 5| Step: 7
Training loss: 2.0664782524108887
Validation loss: 2.0469193843103226

Epoch: 5| Step: 8
Training loss: 1.3648656606674194
Validation loss: 2.0230194445579284

Epoch: 5| Step: 9
Training loss: 1.6748149394989014
Validation loss: 2.0901382200179563

Epoch: 5| Step: 10
Training loss: 1.923438310623169
Validation loss: 2.00742741041286

Epoch: 301| Step: 0
Training loss: 2.0783028602600098
Validation loss: 2.0011486891777284

Epoch: 5| Step: 1
Training loss: 1.5956586599349976
Validation loss: 2.033503317063855

Epoch: 5| Step: 2
Training loss: 2.026451349258423
Validation loss: 2.0161357361783265

Epoch: 5| Step: 3
Training loss: 1.5730466842651367
Validation loss: 2.0400597741526942

Epoch: 5| Step: 4
Training loss: 1.5097730159759521
Validation loss: 1.9925624657702703

Epoch: 5| Step: 5
Training loss: 1.551680088043213
Validation loss: 2.0447210419562554

Epoch: 5| Step: 6
Training loss: 1.415984869003296
Validation loss: 1.963480636637698

Epoch: 5| Step: 7
Training loss: 1.9303098917007446
Validation loss: 1.9787553741085915

Epoch: 5| Step: 8
Training loss: 1.5922918319702148
Validation loss: 2.045169779049453

Epoch: 5| Step: 9
Training loss: 1.3723342418670654
Validation loss: 2.0262927034849763

Epoch: 5| Step: 10
Training loss: 1.417255163192749
Validation loss: 2.052239369320613

Epoch: 302| Step: 0
Training loss: 0.9591602087020874
Validation loss: 2.037187659612266

Epoch: 5| Step: 1
Training loss: 1.4792401790618896
Validation loss: 2.054587424442332

Epoch: 5| Step: 2
Training loss: 1.466493844985962
Validation loss: 2.032133492090369

Epoch: 5| Step: 3
Training loss: 1.2322828769683838
Validation loss: 2.061324491295763

Epoch: 5| Step: 4
Training loss: 2.0180208683013916
Validation loss: 2.0542799657390964

Epoch: 5| Step: 5
Training loss: 1.9144351482391357
Validation loss: 2.028869746833719

Epoch: 5| Step: 6
Training loss: 1.7992547750473022
Validation loss: 2.0315003830899476

Epoch: 5| Step: 7
Training loss: 1.4921801090240479
Validation loss: 2.0586565694501324

Epoch: 5| Step: 8
Training loss: 2.309842586517334
Validation loss: 2.0442779448724564

Epoch: 5| Step: 9
Training loss: 1.991700530052185
Validation loss: 2.0669821513596403

Epoch: 5| Step: 10
Training loss: 1.2623987197875977
Validation loss: 2.0484306607195126

Epoch: 303| Step: 0
Training loss: 1.723224401473999
Validation loss: 2.027625371051091

Epoch: 5| Step: 1
Training loss: 1.8509693145751953
Validation loss: 1.9935924545411141

Epoch: 5| Step: 2
Training loss: 1.5949478149414062
Validation loss: 2.092757649319146

Epoch: 5| Step: 3
Training loss: 1.3699133396148682
Validation loss: 2.023466202520555

Epoch: 5| Step: 4
Training loss: 1.619053602218628
Validation loss: 2.0252494273647184

Epoch: 5| Step: 5
Training loss: 1.399774193763733
Validation loss: 2.0877319471810454

Epoch: 5| Step: 6
Training loss: 2.0890631675720215
Validation loss: 2.023391810796594

Epoch: 5| Step: 7
Training loss: 1.7120475769042969
Validation loss: 2.0740224135819303

Epoch: 5| Step: 8
Training loss: 1.538435935974121
Validation loss: 2.0527607433257566

Epoch: 5| Step: 9
Training loss: 1.5010337829589844
Validation loss: 2.010531417785152

Epoch: 5| Step: 10
Training loss: 1.600805401802063
Validation loss: 2.0219825185755247

Epoch: 304| Step: 0
Training loss: 2.2189555168151855
Validation loss: 2.0538040976370535

Epoch: 5| Step: 1
Training loss: 1.5175977945327759
Validation loss: 1.9634996921785417

Epoch: 5| Step: 2
Training loss: 1.9607661962509155
Validation loss: 2.049560651984266

Epoch: 5| Step: 3
Training loss: 2.601524829864502
Validation loss: 2.058305908274907

Epoch: 5| Step: 4
Training loss: 0.9720614552497864
Validation loss: 1.9781834758738035

Epoch: 5| Step: 5
Training loss: 1.7174094915390015
Validation loss: 1.957922358666697

Epoch: 5| Step: 6
Training loss: 1.590694785118103
Validation loss: 2.043485624815828

Epoch: 5| Step: 7
Training loss: 0.9995293617248535
Validation loss: 2.0435035536366124

Epoch: 5| Step: 8
Training loss: 1.5934921503067017
Validation loss: 2.068531761887253

Epoch: 5| Step: 9
Training loss: 1.1647449731826782
Validation loss: 2.028528828774729

Epoch: 5| Step: 10
Training loss: 1.4464329481124878
Validation loss: 2.0144515383628105

Epoch: 305| Step: 0
Training loss: 1.5228617191314697
Validation loss: 2.0578338920429187

Epoch: 5| Step: 1
Training loss: 1.7385947704315186
Validation loss: 2.0400861001783803

Epoch: 5| Step: 2
Training loss: 1.7426550388336182
Validation loss: 1.9891130411496727

Epoch: 5| Step: 3
Training loss: 2.149015188217163
Validation loss: 2.058400002858972

Epoch: 5| Step: 4
Training loss: 1.636714220046997
Validation loss: 2.010449145429878

Epoch: 5| Step: 5
Training loss: 1.4903523921966553
Validation loss: 2.0356528464184014

Epoch: 5| Step: 6
Training loss: 1.823339819908142
Validation loss: 2.0245192794389624

Epoch: 5| Step: 7
Training loss: 1.2468605041503906
Validation loss: 2.0413672706132293

Epoch: 5| Step: 8
Training loss: 1.7690436840057373
Validation loss: 2.0533318288864626

Epoch: 5| Step: 9
Training loss: 1.5111463069915771
Validation loss: 2.034217276880818

Epoch: 5| Step: 10
Training loss: 1.0059548616409302
Validation loss: 2.0630292328455115

Epoch: 306| Step: 0
Training loss: 2.175931453704834
Validation loss: 2.032273413032614

Epoch: 5| Step: 1
Training loss: 1.4870129823684692
Validation loss: 2.050929041318996

Epoch: 5| Step: 2
Training loss: 1.8436813354492188
Validation loss: 2.043387952671256

Epoch: 5| Step: 3
Training loss: 1.9868724346160889
Validation loss: 2.0642599533962946

Epoch: 5| Step: 4
Training loss: 1.4464149475097656
Validation loss: 2.025351761489786

Epoch: 5| Step: 5
Training loss: 2.121152400970459
Validation loss: 2.003025882987566

Epoch: 5| Step: 6
Training loss: 1.055437684059143
Validation loss: 2.069954684985581

Epoch: 5| Step: 7
Training loss: 1.135051965713501
Validation loss: 2.031345744286814

Epoch: 5| Step: 8
Training loss: 1.3043239116668701
Validation loss: 2.0503800453678256

Epoch: 5| Step: 9
Training loss: 2.0947186946868896
Validation loss: 2.0172925841423774

Epoch: 5| Step: 10
Training loss: 1.1829912662506104
Validation loss: 2.002876825230096

Epoch: 307| Step: 0
Training loss: 1.6025947332382202
Validation loss: 2.025947473382437

Epoch: 5| Step: 1
Training loss: 1.4920473098754883
Validation loss: 2.059218329768027

Epoch: 5| Step: 2
Training loss: 1.1184847354888916
Validation loss: 2.012084836600929

Epoch: 5| Step: 3
Training loss: 1.8705337047576904
Validation loss: 2.0339664015718686

Epoch: 5| Step: 4
Training loss: 1.4169601202011108
Validation loss: 1.9884850799396474

Epoch: 5| Step: 5
Training loss: 2.148240089416504
Validation loss: 2.020348274579612

Epoch: 5| Step: 6
Training loss: 1.3302515745162964
Validation loss: 2.018028146477156

Epoch: 5| Step: 7
Training loss: 1.7383577823638916
Validation loss: 2.0266746577396186

Epoch: 5| Step: 8
Training loss: 1.9297043085098267
Validation loss: 2.033800013603703

Epoch: 5| Step: 9
Training loss: 1.3070012331008911
Validation loss: 2.0554687002653718

Epoch: 5| Step: 10
Training loss: 1.579890251159668
Validation loss: 2.0024988087274695

Epoch: 308| Step: 0
Training loss: 1.8530899286270142
Validation loss: 2.0273968763248895

Epoch: 5| Step: 1
Training loss: 1.372389554977417
Validation loss: 2.02893659376329

Epoch: 5| Step: 2
Training loss: 1.577907681465149
Validation loss: 2.0129098943484727

Epoch: 5| Step: 3
Training loss: 1.79591965675354
Validation loss: 2.0390412179372643

Epoch: 5| Step: 4
Training loss: 1.2127388715744019
Validation loss: 1.984609817945829

Epoch: 5| Step: 5
Training loss: 2.047787666320801
Validation loss: 2.0344198211546867

Epoch: 5| Step: 6
Training loss: 2.1973190307617188
Validation loss: 1.985292750020181

Epoch: 5| Step: 7
Training loss: 1.4608690738677979
Validation loss: 2.0262079854165354

Epoch: 5| Step: 8
Training loss: 1.5396826267242432
Validation loss: 2.007842445886263

Epoch: 5| Step: 9
Training loss: 1.3671836853027344
Validation loss: 2.0060790995115876

Epoch: 5| Step: 10
Training loss: 1.4795457124710083
Validation loss: 2.018444662453026

Epoch: 309| Step: 0
Training loss: 1.8114553689956665
Validation loss: 2.0374877760487218

Epoch: 5| Step: 1
Training loss: 0.9890943765640259
Validation loss: 2.045560416354928

Epoch: 5| Step: 2
Training loss: 1.7022197246551514
Validation loss: 2.0271477904371036

Epoch: 5| Step: 3
Training loss: 1.7094061374664307
Validation loss: 1.9982200194430608

Epoch: 5| Step: 4
Training loss: 1.9831384420394897
Validation loss: 2.0405951776812152

Epoch: 5| Step: 5
Training loss: 1.6310627460479736
Validation loss: 2.053023035808276

Epoch: 5| Step: 6
Training loss: 1.5974469184875488
Validation loss: 2.0208093850843367

Epoch: 5| Step: 7
Training loss: 1.7652885913848877
Validation loss: 1.9868610520516672

Epoch: 5| Step: 8
Training loss: 1.6935333013534546
Validation loss: 2.0082620113126692

Epoch: 5| Step: 9
Training loss: 1.3671808242797852
Validation loss: 2.040623662292316

Epoch: 5| Step: 10
Training loss: 1.4110897779464722
Validation loss: 2.02941495244221

Epoch: 310| Step: 0
Training loss: 1.4738367795944214
Validation loss: 2.0371227777132423

Epoch: 5| Step: 1
Training loss: 2.0607728958129883
Validation loss: 2.0158213569271948

Epoch: 5| Step: 2
Training loss: 1.415351152420044
Validation loss: 2.01166763741483

Epoch: 5| Step: 3
Training loss: 1.741687536239624
Validation loss: 2.025148607069446

Epoch: 5| Step: 4
Training loss: 1.308711290359497
Validation loss: 2.075151938264088

Epoch: 5| Step: 5
Training loss: 1.476715326309204
Validation loss: 2.049080302638392

Epoch: 5| Step: 6
Training loss: 1.6730560064315796
Validation loss: 2.0188487947628064

Epoch: 5| Step: 7
Training loss: 1.9105802774429321
Validation loss: 2.0192251795081684

Epoch: 5| Step: 8
Training loss: 1.3648568391799927
Validation loss: 2.0357779969451246

Epoch: 5| Step: 9
Training loss: 1.697736382484436
Validation loss: 2.0455537124346663

Epoch: 5| Step: 10
Training loss: 1.6173585653305054
Validation loss: 2.0188000561088644

Epoch: 311| Step: 0
Training loss: 1.9992420673370361
Validation loss: 2.018176183905653

Epoch: 5| Step: 1
Training loss: 1.7260860204696655
Validation loss: 2.0447458759430917

Epoch: 5| Step: 2
Training loss: 1.630348801612854
Validation loss: 2.0318654121891147

Epoch: 5| Step: 3
Training loss: 1.0036734342575073
Validation loss: 2.0686687115700013

Epoch: 5| Step: 4
Training loss: 1.4988417625427246
Validation loss: 2.041884251820144

Epoch: 5| Step: 5
Training loss: 1.1492067575454712
Validation loss: 2.0289004028484388

Epoch: 5| Step: 6
Training loss: 1.6795858144760132
Validation loss: 2.0391879312453733

Epoch: 5| Step: 7
Training loss: 1.8738491535186768
Validation loss: 2.069685777028402

Epoch: 5| Step: 8
Training loss: 1.435149073600769
Validation loss: 2.0377364466267247

Epoch: 5| Step: 9
Training loss: 2.0830280780792236
Validation loss: 2.0249526500701904

Epoch: 5| Step: 10
Training loss: 1.5968594551086426
Validation loss: 2.028305338275048

Epoch: 312| Step: 0
Training loss: 0.8650134205818176
Validation loss: 2.013582702605955

Epoch: 5| Step: 1
Training loss: 2.153830051422119
Validation loss: 2.014371843748195

Epoch: 5| Step: 2
Training loss: 1.4038729667663574
Validation loss: 2.03638469788336

Epoch: 5| Step: 3
Training loss: 1.6271919012069702
Validation loss: 2.0812267629049157

Epoch: 5| Step: 4
Training loss: 2.0098609924316406
Validation loss: 2.0322589130811792

Epoch: 5| Step: 5
Training loss: 1.277197241783142
Validation loss: 2.031473152099117

Epoch: 5| Step: 6
Training loss: 1.4510844945907593
Validation loss: 2.063789103620796

Epoch: 5| Step: 7
Training loss: 1.9962291717529297
Validation loss: 2.04437848829454

Epoch: 5| Step: 8
Training loss: 1.588731288909912
Validation loss: 2.0535744159452376

Epoch: 5| Step: 9
Training loss: 1.758774757385254
Validation loss: 2.0183212346928094

Epoch: 5| Step: 10
Training loss: 1.4776055812835693
Validation loss: 2.0128117761304303

Epoch: 313| Step: 0
Training loss: 0.9999380111694336
Validation loss: 2.025155355853419

Epoch: 5| Step: 1
Training loss: 2.313650131225586
Validation loss: 2.0340346418401247

Epoch: 5| Step: 2
Training loss: 1.4715553522109985
Validation loss: 2.0271412095715924

Epoch: 5| Step: 3
Training loss: 1.5779105424880981
Validation loss: 2.0684049411486556

Epoch: 5| Step: 4
Training loss: 1.8217989206314087
Validation loss: 2.0522285840844594

Epoch: 5| Step: 5
Training loss: 1.5608059167861938
Validation loss: 2.0087852683118594

Epoch: 5| Step: 6
Training loss: 1.232498049736023
Validation loss: 2.0569986297238256

Epoch: 5| Step: 7
Training loss: 1.8425813913345337
Validation loss: 2.040151952415384

Epoch: 5| Step: 8
Training loss: 1.8203284740447998
Validation loss: 2.0395145134259294

Epoch: 5| Step: 9
Training loss: 1.4984501600265503
Validation loss: 2.0139402484381073

Epoch: 5| Step: 10
Training loss: 2.0238404273986816
Validation loss: 2.035600654540523

Epoch: 314| Step: 0
Training loss: 1.1277480125427246
Validation loss: 2.0193275482423845

Epoch: 5| Step: 1
Training loss: 1.4595013856887817
Validation loss: 1.9832689518569617

Epoch: 5| Step: 2
Training loss: 1.4871841669082642
Validation loss: 2.0112259323878954

Epoch: 5| Step: 3
Training loss: 1.5626955032348633
Validation loss: 2.042214006505987

Epoch: 5| Step: 4
Training loss: 1.2621757984161377
Validation loss: 2.0229553689238844

Epoch: 5| Step: 5
Training loss: 2.2649688720703125
Validation loss: 1.9785902820607668

Epoch: 5| Step: 6
Training loss: 1.168670415878296
Validation loss: 2.0102815294778473

Epoch: 5| Step: 7
Training loss: 2.1497838497161865
Validation loss: 1.975276359947779

Epoch: 5| Step: 8
Training loss: 1.897032380104065
Validation loss: 2.0367790242677093

Epoch: 5| Step: 9
Training loss: 1.464799165725708
Validation loss: 2.0387244160457323

Epoch: 5| Step: 10
Training loss: 1.804908037185669
Validation loss: 2.0292680289155696

Epoch: 315| Step: 0
Training loss: 1.7758452892303467
Validation loss: 2.0015167920820174

Epoch: 5| Step: 1
Training loss: 1.4867092370986938
Validation loss: 2.0164971274714314

Epoch: 5| Step: 2
Training loss: 1.4815205335617065
Validation loss: 2.0233104767337924

Epoch: 5| Step: 3
Training loss: 1.7547972202301025
Validation loss: 2.0414356134271108

Epoch: 5| Step: 4
Training loss: 0.9939530491828918
Validation loss: 2.0117241887636084

Epoch: 5| Step: 5
Training loss: 2.050246000289917
Validation loss: 2.0534629667958906

Epoch: 5| Step: 6
Training loss: 1.5915725231170654
Validation loss: 2.0335789354898597

Epoch: 5| Step: 7
Training loss: 1.0859568119049072
Validation loss: 2.0133805262145175

Epoch: 5| Step: 8
Training loss: 1.5151968002319336
Validation loss: 2.065129521072552

Epoch: 5| Step: 9
Training loss: 2.329500675201416
Validation loss: 2.064573798128354

Epoch: 5| Step: 10
Training loss: 1.4559190273284912
Validation loss: 2.0535909950092273

Epoch: 316| Step: 0
Training loss: 1.813194990158081
Validation loss: 2.0799405459434754

Epoch: 5| Step: 1
Training loss: 1.3892310857772827
Validation loss: 2.0698128592583442

Epoch: 5| Step: 2
Training loss: 1.7376229763031006
Validation loss: 2.033048463124101

Epoch: 5| Step: 3
Training loss: 2.1005148887634277
Validation loss: 2.0749232820285264

Epoch: 5| Step: 4
Training loss: 1.3574260473251343
Validation loss: 2.016886213774322

Epoch: 5| Step: 5
Training loss: 1.481449842453003
Validation loss: 2.0099487125232653

Epoch: 5| Step: 6
Training loss: 1.5605180263519287
Validation loss: 2.067024396311852

Epoch: 5| Step: 7
Training loss: 1.6879405975341797
Validation loss: 2.0349300830594954

Epoch: 5| Step: 8
Training loss: 1.8458147048950195
Validation loss: 2.0377120394860544

Epoch: 5| Step: 9
Training loss: 1.628064751625061
Validation loss: 2.0117814540863037

Epoch: 5| Step: 10
Training loss: 1.305724859237671
Validation loss: 1.9995083937080957

Epoch: 317| Step: 0
Training loss: 1.869786024093628
Validation loss: 2.01981113290274

Epoch: 5| Step: 1
Training loss: 1.5264818668365479
Validation loss: 2.0245623255288727

Epoch: 5| Step: 2
Training loss: 1.4469835758209229
Validation loss: 2.0405239174442906

Epoch: 5| Step: 3
Training loss: 2.0933737754821777
Validation loss: 2.0384818815415904

Epoch: 5| Step: 4
Training loss: 1.4657924175262451
Validation loss: 1.993886543858436

Epoch: 5| Step: 5
Training loss: 1.7788050174713135
Validation loss: 2.098695226894912

Epoch: 5| Step: 6
Training loss: 1.4818692207336426
Validation loss: 2.010965911290979

Epoch: 5| Step: 7
Training loss: 1.670127272605896
Validation loss: 2.018099590014386

Epoch: 5| Step: 8
Training loss: 1.3640673160552979
Validation loss: 2.063303566748096

Epoch: 5| Step: 9
Training loss: 1.3590290546417236
Validation loss: 2.0285696675700526

Epoch: 5| Step: 10
Training loss: 1.6189024448394775
Validation loss: 2.037377272882769

Epoch: 318| Step: 0
Training loss: 1.6609569787979126
Validation loss: 2.0125732908966723

Epoch: 5| Step: 1
Training loss: 0.9402974843978882
Validation loss: 2.0031712362843175

Epoch: 5| Step: 2
Training loss: 1.7652854919433594
Validation loss: 2.002697137094313

Epoch: 5| Step: 3
Training loss: 1.6422961950302124
Validation loss: 2.0141594268942393

Epoch: 5| Step: 4
Training loss: 1.0662481784820557
Validation loss: 2.035249585746437

Epoch: 5| Step: 5
Training loss: 2.0107295513153076
Validation loss: 2.049638743041664

Epoch: 5| Step: 6
Training loss: 1.6604942083358765
Validation loss: 1.964532054880614

Epoch: 5| Step: 7
Training loss: 1.6671514511108398
Validation loss: 2.013711414029521

Epoch: 5| Step: 8
Training loss: 1.270455241203308
Validation loss: 1.979953396704889

Epoch: 5| Step: 9
Training loss: 1.5599514245986938
Validation loss: 2.0449298889406267

Epoch: 5| Step: 10
Training loss: 2.3524270057678223
Validation loss: 2.0338009172870266

Epoch: 319| Step: 0
Training loss: 1.595605492591858
Validation loss: 2.051115246229274

Epoch: 5| Step: 1
Training loss: 1.8343502283096313
Validation loss: 2.057751670960457

Epoch: 5| Step: 2
Training loss: 1.9213285446166992
Validation loss: 2.0635487930749052

Epoch: 5| Step: 3
Training loss: 1.824954628944397
Validation loss: 2.015281169645248

Epoch: 5| Step: 4
Training loss: 1.5177462100982666
Validation loss: 2.0445771345528225

Epoch: 5| Step: 5
Training loss: 1.258780837059021
Validation loss: 2.0883346501217095

Epoch: 5| Step: 6
Training loss: 1.7355010509490967
Validation loss: 2.0456208131646596

Epoch: 5| Step: 7
Training loss: 1.438044548034668
Validation loss: 2.049857420306052

Epoch: 5| Step: 8
Training loss: 1.6784963607788086
Validation loss: 2.0353255989731

Epoch: 5| Step: 9
Training loss: 1.908789038658142
Validation loss: 2.0182783501122588

Epoch: 5| Step: 10
Training loss: 0.9570636749267578
Validation loss: 2.0536331797158844

Epoch: 320| Step: 0
Training loss: 2.124768018722534
Validation loss: 2.035054317084692

Epoch: 5| Step: 1
Training loss: 1.3194867372512817
Validation loss: 2.0453564082422564

Epoch: 5| Step: 2
Training loss: 1.5388100147247314
Validation loss: 2.051687195736875

Epoch: 5| Step: 3
Training loss: 1.395583152770996
Validation loss: 2.047714765353869

Epoch: 5| Step: 4
Training loss: 1.2410509586334229
Validation loss: 2.072307571288078

Epoch: 5| Step: 5
Training loss: 1.779476523399353
Validation loss: 2.0268606755041305

Epoch: 5| Step: 6
Training loss: 1.583038091659546
Validation loss: 2.032219257406009

Epoch: 5| Step: 7
Training loss: 1.3508989810943604
Validation loss: 1.9405025000213294

Epoch: 5| Step: 8
Training loss: 1.5380699634552002
Validation loss: 2.0120566198902745

Epoch: 5| Step: 9
Training loss: 2.3545260429382324
Validation loss: 2.034021582654727

Epoch: 5| Step: 10
Training loss: 1.1255674362182617
Validation loss: 2.0021263296886156

Epoch: 321| Step: 0
Training loss: 1.6972112655639648
Validation loss: 2.0320627689361572

Epoch: 5| Step: 1
Training loss: 2.017763137817383
Validation loss: 2.022334901235437

Epoch: 5| Step: 2
Training loss: 1.5946934223175049
Validation loss: 2.0598891089039464

Epoch: 5| Step: 3
Training loss: 1.45218026638031
Validation loss: 1.9780201463289158

Epoch: 5| Step: 4
Training loss: 1.1870843172073364
Validation loss: 2.017188024777238

Epoch: 5| Step: 5
Training loss: 1.5103085041046143
Validation loss: 1.9798088330094532

Epoch: 5| Step: 6
Training loss: 1.70268976688385
Validation loss: 2.0325706684461204

Epoch: 5| Step: 7
Training loss: 1.8533194065093994
Validation loss: 2.0214684701734975

Epoch: 5| Step: 8
Training loss: 1.257770299911499
Validation loss: 2.0243613232848463

Epoch: 5| Step: 9
Training loss: 1.6022838354110718
Validation loss: 2.016840507907252

Epoch: 5| Step: 10
Training loss: 1.7012735605239868
Validation loss: 2.0061236145675823

Epoch: 322| Step: 0
Training loss: 1.7837371826171875
Validation loss: 1.9974756445935977

Epoch: 5| Step: 1
Training loss: 1.2620749473571777
Validation loss: 2.0298032940074964

Epoch: 5| Step: 2
Training loss: 1.3236865997314453
Validation loss: 2.0101161144113027

Epoch: 5| Step: 3
Training loss: 1.6632740497589111
Validation loss: 2.0585871640072075

Epoch: 5| Step: 4
Training loss: 1.5129166841506958
Validation loss: 2.065096098889587

Epoch: 5| Step: 5
Training loss: 1.1910516023635864
Validation loss: 2.0460339874349613

Epoch: 5| Step: 6
Training loss: 2.0244555473327637
Validation loss: 2.0220241418448825

Epoch: 5| Step: 7
Training loss: 1.5818759202957153
Validation loss: 1.9847481584036222

Epoch: 5| Step: 8
Training loss: 1.5552446842193604
Validation loss: 2.0269652002601215

Epoch: 5| Step: 9
Training loss: 1.6178414821624756
Validation loss: 2.035356274215124

Epoch: 5| Step: 10
Training loss: 1.9929313659667969
Validation loss: 1.9986643765562324

Epoch: 323| Step: 0
Training loss: 1.3551299571990967
Validation loss: 2.0215579181589107

Epoch: 5| Step: 1
Training loss: 1.6191341876983643
Validation loss: 2.0172858879130375

Epoch: 5| Step: 2
Training loss: 1.374956727027893
Validation loss: 2.041766092341433

Epoch: 5| Step: 3
Training loss: 2.3673818111419678
Validation loss: 2.0373546449087

Epoch: 5| Step: 4
Training loss: 1.5600191354751587
Validation loss: 2.0293382265234507

Epoch: 5| Step: 5
Training loss: 1.7169950008392334
Validation loss: 1.994337421591564

Epoch: 5| Step: 6
Training loss: 1.2999112606048584
Validation loss: 1.9776364090622112

Epoch: 5| Step: 7
Training loss: 1.8714191913604736
Validation loss: 2.0339296710106636

Epoch: 5| Step: 8
Training loss: 1.092482566833496
Validation loss: 2.0194556738740657

Epoch: 5| Step: 9
Training loss: 1.6419655084609985
Validation loss: 1.9995979468027751

Epoch: 5| Step: 10
Training loss: 1.5930230617523193
Validation loss: 2.012238766557427

Epoch: 324| Step: 0
Training loss: 1.5443367958068848
Validation loss: 2.019784040348504

Epoch: 5| Step: 1
Training loss: 1.669870376586914
Validation loss: 2.0582621533383607

Epoch: 5| Step: 2
Training loss: 1.5818277597427368
Validation loss: 2.061953736889747

Epoch: 5| Step: 3
Training loss: 1.1504950523376465
Validation loss: 2.064881073531284

Epoch: 5| Step: 4
Training loss: 1.089268445968628
Validation loss: 2.0213811653916554

Epoch: 5| Step: 5
Training loss: 1.210463523864746
Validation loss: 2.0705250283723236

Epoch: 5| Step: 6
Training loss: 2.094128370285034
Validation loss: 2.055678144578011

Epoch: 5| Step: 7
Training loss: 1.6871503591537476
Validation loss: 2.044135655126264

Epoch: 5| Step: 8
Training loss: 1.6009963750839233
Validation loss: 2.0077367572374243

Epoch: 5| Step: 9
Training loss: 1.8666902780532837
Validation loss: 2.0380982083659016

Epoch: 5| Step: 10
Training loss: 1.944026231765747
Validation loss: 2.019267048887027

Epoch: 325| Step: 0
Training loss: 1.723554015159607
Validation loss: 1.9757881215823594

Epoch: 5| Step: 1
Training loss: 1.4222440719604492
Validation loss: 2.0323204763474

Epoch: 5| Step: 2
Training loss: 1.9781944751739502
Validation loss: 1.990903272423693

Epoch: 5| Step: 3
Training loss: 1.5877408981323242
Validation loss: 1.9693690525588168

Epoch: 5| Step: 4
Training loss: 1.0272893905639648
Validation loss: 2.0100131470669984

Epoch: 5| Step: 5
Training loss: 1.2517037391662598
Validation loss: 2.0180621313792404

Epoch: 5| Step: 6
Training loss: 1.7023597955703735
Validation loss: 2.021945088140426

Epoch: 5| Step: 7
Training loss: 1.6979362964630127
Validation loss: 1.9993583002398092

Epoch: 5| Step: 8
Training loss: 2.044158697128296
Validation loss: 2.0384623568545104

Epoch: 5| Step: 9
Training loss: 1.3911917209625244
Validation loss: 1.9631432115390737

Epoch: 5| Step: 10
Training loss: 1.6483047008514404
Validation loss: 2.000955717537993

Epoch: 326| Step: 0
Training loss: 1.2714837789535522
Validation loss: 2.0263096440222954

Epoch: 5| Step: 1
Training loss: 1.0193374156951904
Validation loss: 1.99235168580086

Epoch: 5| Step: 2
Training loss: 1.516969084739685
Validation loss: 2.050336996714274

Epoch: 5| Step: 3
Training loss: 1.2091448307037354
Validation loss: 2.03032019061427

Epoch: 5| Step: 4
Training loss: 1.7859833240509033
Validation loss: 2.03711461892692

Epoch: 5| Step: 5
Training loss: 1.199883222579956
Validation loss: 2.0114614117530083

Epoch: 5| Step: 6
Training loss: 1.4208706617355347
Validation loss: 2.0693102421299105

Epoch: 5| Step: 7
Training loss: 1.9127861261367798
Validation loss: 2.032994060106175

Epoch: 5| Step: 8
Training loss: 2.393253803253174
Validation loss: 2.011966306676147

Epoch: 5| Step: 9
Training loss: 1.9598439931869507
Validation loss: 2.0232038087742303

Epoch: 5| Step: 10
Training loss: 1.6233320236206055
Validation loss: 2.0455170805736254

Epoch: 327| Step: 0
Training loss: 1.588600754737854
Validation loss: 1.9771958833099694

Epoch: 5| Step: 1
Training loss: 1.7292331457138062
Validation loss: 2.028141834402597

Epoch: 5| Step: 2
Training loss: 2.0133769512176514
Validation loss: 2.0176810269714682

Epoch: 5| Step: 3
Training loss: 1.5505541563034058
Validation loss: 2.0344633838181854

Epoch: 5| Step: 4
Training loss: 1.882009506225586
Validation loss: 2.0033126185017247

Epoch: 5| Step: 5
Training loss: 1.538573980331421
Validation loss: 2.006022057225627

Epoch: 5| Step: 6
Training loss: 1.4296119213104248
Validation loss: 2.0331462070506108

Epoch: 5| Step: 7
Training loss: 1.5090610980987549
Validation loss: 2.039811175356629

Epoch: 5| Step: 8
Training loss: 1.2699766159057617
Validation loss: 1.9984335309715682

Epoch: 5| Step: 9
Training loss: 1.8413746356964111
Validation loss: 2.0555076214574997

Epoch: 5| Step: 10
Training loss: 1.2004228830337524
Validation loss: 2.009739648911261

Epoch: 328| Step: 0
Training loss: 1.2392323017120361
Validation loss: 2.0552749403061403

Epoch: 5| Step: 1
Training loss: 1.4621481895446777
Validation loss: 2.0029642248666413

Epoch: 5| Step: 2
Training loss: 1.4388353824615479
Validation loss: 2.039293460948493

Epoch: 5| Step: 3
Training loss: 1.930364966392517
Validation loss: 2.00268050419387

Epoch: 5| Step: 4
Training loss: 1.339282751083374
Validation loss: 2.0230955154665056

Epoch: 5| Step: 5
Training loss: 1.2400838136672974
Validation loss: 2.0328562144310243

Epoch: 5| Step: 6
Training loss: 1.955262541770935
Validation loss: 2.0212112267812095

Epoch: 5| Step: 7
Training loss: 1.660375952720642
Validation loss: 2.0008476395760812

Epoch: 5| Step: 8
Training loss: 1.0721845626831055
Validation loss: 2.03525686007674

Epoch: 5| Step: 9
Training loss: 1.9519487619400024
Validation loss: 2.0203456212115545

Epoch: 5| Step: 10
Training loss: 2.0525426864624023
Validation loss: 2.010542769585886

Epoch: 329| Step: 0
Training loss: 1.8361952304840088
Validation loss: 2.0640452959204234

Epoch: 5| Step: 1
Training loss: 1.140581488609314
Validation loss: 2.005952578718944

Epoch: 5| Step: 2
Training loss: 1.5160564184188843
Validation loss: 2.047645112519623

Epoch: 5| Step: 3
Training loss: 1.3400119543075562
Validation loss: 2.049732231324719

Epoch: 5| Step: 4
Training loss: 1.5144951343536377
Validation loss: 1.9935755011855916

Epoch: 5| Step: 5
Training loss: 1.7916641235351562
Validation loss: 2.0722789354221796

Epoch: 5| Step: 6
Training loss: 1.7564928531646729
Validation loss: 2.034547467385569

Epoch: 5| Step: 7
Training loss: 1.5903537273406982
Validation loss: 2.025120412149737

Epoch: 5| Step: 8
Training loss: 1.575011134147644
Validation loss: 2.069614343745734

Epoch: 5| Step: 9
Training loss: 1.7652645111083984
Validation loss: 2.004188414542906

Epoch: 5| Step: 10
Training loss: 1.4266940355300903
Validation loss: 2.0432890922792497

Epoch: 330| Step: 0
Training loss: 2.008816719055176
Validation loss: 1.9979789359595186

Epoch: 5| Step: 1
Training loss: 1.07883620262146
Validation loss: 1.983177060722023

Epoch: 5| Step: 2
Training loss: 0.9492552876472473
Validation loss: 2.0519316862988215

Epoch: 5| Step: 3
Training loss: 1.5913991928100586
Validation loss: 2.009261901660632

Epoch: 5| Step: 4
Training loss: 2.0211222171783447
Validation loss: 2.0609541939150904

Epoch: 5| Step: 5
Training loss: 1.3815484046936035
Validation loss: 1.9772691816411994

Epoch: 5| Step: 6
Training loss: 2.0202770233154297
Validation loss: 1.9640330653036795

Epoch: 5| Step: 7
Training loss: 1.508216142654419
Validation loss: 2.0491503387369137

Epoch: 5| Step: 8
Training loss: 1.4914238452911377
Validation loss: 2.035581919454759

Epoch: 5| Step: 9
Training loss: 1.8236068487167358
Validation loss: 2.012684714409613

Epoch: 5| Step: 10
Training loss: 1.3542183637619019
Validation loss: 1.9521509537132837

Epoch: 331| Step: 0
Training loss: 1.0957368612289429
Validation loss: 2.0324474483407955

Epoch: 5| Step: 1
Training loss: 1.5656793117523193
Validation loss: 2.005806426848135

Epoch: 5| Step: 2
Training loss: 1.4884662628173828
Validation loss: 2.0114503316981818

Epoch: 5| Step: 3
Training loss: 1.4186793565750122
Validation loss: 2.0089254481818086

Epoch: 5| Step: 4
Training loss: 1.918026328086853
Validation loss: 1.9815247930506223

Epoch: 5| Step: 5
Training loss: 1.5229442119598389
Validation loss: 2.032926897848806

Epoch: 5| Step: 6
Training loss: 1.4347577095031738
Validation loss: 2.0072357859662784

Epoch: 5| Step: 7
Training loss: 1.8228740692138672
Validation loss: 2.0526319447384087

Epoch: 5| Step: 8
Training loss: 1.4987655878067017
Validation loss: 2.0060367532955703

Epoch: 5| Step: 9
Training loss: 1.4879045486450195
Validation loss: 1.9855239775873

Epoch: 5| Step: 10
Training loss: 1.82767653465271
Validation loss: 2.0237030265151814

Epoch: 332| Step: 0
Training loss: 1.268285870552063
Validation loss: 2.0510492299192693

Epoch: 5| Step: 1
Training loss: 1.7835983037948608
Validation loss: 2.013059436634023

Epoch: 5| Step: 2
Training loss: 1.822353720664978
Validation loss: 2.027757030661388

Epoch: 5| Step: 3
Training loss: 1.1918665170669556
Validation loss: 2.0584683136273454

Epoch: 5| Step: 4
Training loss: 1.9591478109359741
Validation loss: 2.014304625090732

Epoch: 5| Step: 5
Training loss: 1.2608753442764282
Validation loss: 2.0464217380810807

Epoch: 5| Step: 6
Training loss: 1.6385711431503296
Validation loss: 1.9864771891665716

Epoch: 5| Step: 7
Training loss: 1.5381076335906982
Validation loss: 1.9702865846695439

Epoch: 5| Step: 8
Training loss: 1.831808090209961
Validation loss: 2.015229886577975

Epoch: 5| Step: 9
Training loss: 1.3645448684692383
Validation loss: 2.011010435319716

Epoch: 5| Step: 10
Training loss: 1.482686161994934
Validation loss: 1.9957477290143248

Epoch: 333| Step: 0
Training loss: 1.483917474746704
Validation loss: 2.065796490638487

Epoch: 5| Step: 1
Training loss: 1.7001243829727173
Validation loss: 2.041646966370203

Epoch: 5| Step: 2
Training loss: 2.412264108657837
Validation loss: 2.008485085220747

Epoch: 5| Step: 3
Training loss: 1.3200116157531738
Validation loss: 2.0195729565876785

Epoch: 5| Step: 4
Training loss: 1.7769666910171509
Validation loss: 2.0594399616282475

Epoch: 5| Step: 5
Training loss: 1.9388195276260376
Validation loss: 2.0382610380008654

Epoch: 5| Step: 6
Training loss: 1.6533143520355225
Validation loss: 2.059209249352896

Epoch: 5| Step: 7
Training loss: 1.0764530897140503
Validation loss: 2.0511940627969723

Epoch: 5| Step: 8
Training loss: 1.3641773462295532
Validation loss: 2.085999959258623

Epoch: 5| Step: 9
Training loss: 1.2722628116607666
Validation loss: 2.0546415416143273

Epoch: 5| Step: 10
Training loss: 1.3522007465362549
Validation loss: 2.00961814131788

Epoch: 334| Step: 0
Training loss: 1.750870704650879
Validation loss: 2.007890086020193

Epoch: 5| Step: 1
Training loss: 1.7313569784164429
Validation loss: 2.0058082534420874

Epoch: 5| Step: 2
Training loss: 1.832145094871521
Validation loss: 1.9901453077152211

Epoch: 5| Step: 3
Training loss: 0.8526708483695984
Validation loss: 2.009804492355675

Epoch: 5| Step: 4
Training loss: 1.1231313943862915
Validation loss: 2.0089040174279162

Epoch: 5| Step: 5
Training loss: 2.489434242248535
Validation loss: 2.0374849098984913

Epoch: 5| Step: 6
Training loss: 1.4963783025741577
Validation loss: 2.03899057193469

Epoch: 5| Step: 7
Training loss: 1.3104444742202759
Validation loss: 2.0490545380500054

Epoch: 5| Step: 8
Training loss: 1.2609130144119263
Validation loss: 1.998476820607339

Epoch: 5| Step: 9
Training loss: 1.938146948814392
Validation loss: 2.0157864837236303

Epoch: 5| Step: 10
Training loss: 1.3334399461746216
Validation loss: 1.9940588858819777

Epoch: 335| Step: 0
Training loss: 1.6355394124984741
Validation loss: 2.041250859537432

Epoch: 5| Step: 1
Training loss: 1.4733238220214844
Validation loss: 2.0285785095666045

Epoch: 5| Step: 2
Training loss: 1.3936069011688232
Validation loss: 2.032372002960533

Epoch: 5| Step: 3
Training loss: 1.3809034824371338
Validation loss: 2.031412519434447

Epoch: 5| Step: 4
Training loss: 2.1909148693084717
Validation loss: 2.02471024374808

Epoch: 5| Step: 5
Training loss: 1.4087737798690796
Validation loss: 2.0075268873604397

Epoch: 5| Step: 6
Training loss: 1.763540267944336
Validation loss: 2.058739346842612

Epoch: 5| Step: 7
Training loss: 1.5615612268447876
Validation loss: 2.0387711678781817

Epoch: 5| Step: 8
Training loss: 1.0075987577438354
Validation loss: 2.026352687548566

Epoch: 5| Step: 9
Training loss: 1.6169407367706299
Validation loss: 2.0414371900661017

Epoch: 5| Step: 10
Training loss: 1.8803788423538208
Validation loss: 2.0422935306384997

Epoch: 336| Step: 0
Training loss: 1.2055647373199463
Validation loss: 2.037442482927794

Epoch: 5| Step: 1
Training loss: 1.1481462717056274
Validation loss: 2.0358182717395086

Epoch: 5| Step: 2
Training loss: 2.493873119354248
Validation loss: 2.0587219525409

Epoch: 5| Step: 3
Training loss: 1.5596867799758911
Validation loss: 2.0443475220793035

Epoch: 5| Step: 4
Training loss: 1.743233323097229
Validation loss: 2.0035753865395822

Epoch: 5| Step: 5
Training loss: 1.9800794124603271
Validation loss: 2.013499806004186

Epoch: 5| Step: 6
Training loss: 1.3521393537521362
Validation loss: 1.9814509832730858

Epoch: 5| Step: 7
Training loss: 1.5640740394592285
Validation loss: 2.0072812957148396

Epoch: 5| Step: 8
Training loss: 1.6083511114120483
Validation loss: 2.0287916839763684

Epoch: 5| Step: 9
Training loss: 1.5583851337432861
Validation loss: 2.013501883834921

Epoch: 5| Step: 10
Training loss: 1.0684173107147217
Validation loss: 2.0248057944800264

Epoch: 337| Step: 0
Training loss: 1.4261467456817627
Validation loss: 2.0523650441118466

Epoch: 5| Step: 1
Training loss: 1.9489243030548096
Validation loss: 1.998340980980986

Epoch: 5| Step: 2
Training loss: 0.8891363143920898
Validation loss: 2.0593425189295123

Epoch: 5| Step: 3
Training loss: 1.4970355033874512
Validation loss: 1.981100131106633

Epoch: 5| Step: 4
Training loss: 1.05635666847229
Validation loss: 2.015435626429896

Epoch: 5| Step: 5
Training loss: 2.143688678741455
Validation loss: 1.9810725232606292

Epoch: 5| Step: 6
Training loss: 1.6806552410125732
Validation loss: 2.0038272949957077

Epoch: 5| Step: 7
Training loss: 1.6344566345214844
Validation loss: 2.0225143906890706

Epoch: 5| Step: 8
Training loss: 1.6365373134613037
Validation loss: 2.0463446404344294

Epoch: 5| Step: 9
Training loss: 1.9943832159042358
Validation loss: 2.0344154860383723

Epoch: 5| Step: 10
Training loss: 1.3223339319229126
Validation loss: 2.0459005730126494

Epoch: 338| Step: 0
Training loss: 2.549656867980957
Validation loss: 2.09598861458481

Epoch: 5| Step: 1
Training loss: 1.413325548171997
Validation loss: 2.026114753497544

Epoch: 5| Step: 2
Training loss: 1.4705698490142822
Validation loss: 2.003141257070726

Epoch: 5| Step: 3
Training loss: 1.3526830673217773
Validation loss: 2.057401441758679

Epoch: 5| Step: 4
Training loss: 1.1514774560928345
Validation loss: 2.0242030800029798

Epoch: 5| Step: 5
Training loss: 1.3943746089935303
Validation loss: 2.018656007705196

Epoch: 5| Step: 6
Training loss: 2.0922648906707764
Validation loss: 2.0188351113309144

Epoch: 5| Step: 7
Training loss: 1.4622366428375244
Validation loss: 2.057175119717916

Epoch: 5| Step: 8
Training loss: 1.7121479511260986
Validation loss: 1.9862215647133448

Epoch: 5| Step: 9
Training loss: 0.8935545682907104
Validation loss: 2.068809160622217

Epoch: 5| Step: 10
Training loss: 1.9795827865600586
Validation loss: 2.0166533506044777

Epoch: 339| Step: 0
Training loss: 1.6461397409439087
Validation loss: 1.9821856714064074

Epoch: 5| Step: 1
Training loss: 1.8824872970581055
Validation loss: 1.9976857657073646

Epoch: 5| Step: 2
Training loss: 1.5733919143676758
Validation loss: 2.049486106441867

Epoch: 5| Step: 3
Training loss: 1.6359508037567139
Validation loss: 1.985812843486827

Epoch: 5| Step: 4
Training loss: 1.8781505823135376
Validation loss: 2.019068658992808

Epoch: 5| Step: 5
Training loss: 0.9820653200149536
Validation loss: 2.053639995154514

Epoch: 5| Step: 6
Training loss: 1.9791762828826904
Validation loss: 2.005383828634857

Epoch: 5| Step: 7
Training loss: 1.6171939373016357
Validation loss: 2.0097563574391026

Epoch: 5| Step: 8
Training loss: 1.403808355331421
Validation loss: 2.021693439893825

Epoch: 5| Step: 9
Training loss: 1.5783138275146484
Validation loss: 2.0207836358777937

Epoch: 5| Step: 10
Training loss: 1.1400171518325806
Validation loss: 1.967133298996956

Epoch: 340| Step: 0
Training loss: 1.4415727853775024
Validation loss: 2.0134671772679975

Epoch: 5| Step: 1
Training loss: 1.5872299671173096
Validation loss: 2.04195463016469

Epoch: 5| Step: 2
Training loss: 1.7014150619506836
Validation loss: 2.0598599885099675

Epoch: 5| Step: 3
Training loss: 1.499084711074829
Validation loss: 2.0583132877144763

Epoch: 5| Step: 4
Training loss: 1.4151856899261475
Validation loss: 2.0343564582127396

Epoch: 5| Step: 5
Training loss: 1.6597709655761719
Validation loss: 2.047951529102941

Epoch: 5| Step: 6
Training loss: 1.5776491165161133
Validation loss: 2.0192515004065728

Epoch: 5| Step: 7
Training loss: 2.0451622009277344
Validation loss: 2.122999296393446

Epoch: 5| Step: 8
Training loss: 1.4249403476715088
Validation loss: 2.053678289536507

Epoch: 5| Step: 9
Training loss: 1.4525270462036133
Validation loss: 2.0572872161865234

Epoch: 5| Step: 10
Training loss: 1.353423833847046
Validation loss: 2.023523529370626

Epoch: 341| Step: 0
Training loss: 1.956203818321228
Validation loss: 2.040015753879342

Epoch: 5| Step: 1
Training loss: 1.8727060556411743
Validation loss: 2.0458405094762004

Epoch: 5| Step: 2
Training loss: 1.3138939142227173
Validation loss: 2.0277070986327304

Epoch: 5| Step: 3
Training loss: 1.6069622039794922
Validation loss: 2.0089047942110287

Epoch: 5| Step: 4
Training loss: 1.519242286682129
Validation loss: 2.0160850735120874

Epoch: 5| Step: 5
Training loss: 1.2016410827636719
Validation loss: 2.0196707940870717

Epoch: 5| Step: 6
Training loss: 1.0795141458511353
Validation loss: 1.9995578617177985

Epoch: 5| Step: 7
Training loss: 1.2737963199615479
Validation loss: 1.9906176520932106

Epoch: 5| Step: 8
Training loss: 1.446650743484497
Validation loss: 2.0219634399619153

Epoch: 5| Step: 9
Training loss: 2.0220773220062256
Validation loss: 2.000969280478775

Epoch: 5| Step: 10
Training loss: 1.809989094734192
Validation loss: 2.0500815171067432

Epoch: 342| Step: 0
Training loss: 1.388441801071167
Validation loss: 2.0256833901969333

Epoch: 5| Step: 1
Training loss: 0.8217192888259888
Validation loss: 1.9567830075499832

Epoch: 5| Step: 2
Training loss: 1.5547358989715576
Validation loss: 2.0218462469757243

Epoch: 5| Step: 3
Training loss: 1.5393658876419067
Validation loss: 2.017438014348348

Epoch: 5| Step: 4
Training loss: 1.8043140172958374
Validation loss: 2.0360488968510784

Epoch: 5| Step: 5
Training loss: 1.5860435962677002
Validation loss: 1.980372223802792

Epoch: 5| Step: 6
Training loss: 2.0910582542419434
Validation loss: 2.0404434281010784

Epoch: 5| Step: 7
Training loss: 1.3141485452651978
Validation loss: 1.9868747957291142

Epoch: 5| Step: 8
Training loss: 1.1492332220077515
Validation loss: 1.985930581246653

Epoch: 5| Step: 9
Training loss: 2.0905063152313232
Validation loss: 2.0112942021380187

Epoch: 5| Step: 10
Training loss: 1.700520634651184
Validation loss: 2.0150209601207445

Epoch: 343| Step: 0
Training loss: 1.8223623037338257
Validation loss: 2.0084337342169976

Epoch: 5| Step: 1
Training loss: 1.9784549474716187
Validation loss: 2.052546362723074

Epoch: 5| Step: 2
Training loss: 1.614712119102478
Validation loss: 2.0276405606218564

Epoch: 5| Step: 3
Training loss: 1.6317201852798462
Validation loss: 2.019921105395081

Epoch: 5| Step: 4
Training loss: 1.8033130168914795
Validation loss: 2.0204127270688295

Epoch: 5| Step: 5
Training loss: 1.2503238916397095
Validation loss: 2.054723575551023

Epoch: 5| Step: 6
Training loss: 1.6835514307022095
Validation loss: 2.0110663624219995

Epoch: 5| Step: 7
Training loss: 1.5356943607330322
Validation loss: 2.0456660896219234

Epoch: 5| Step: 8
Training loss: 1.447385311126709
Validation loss: 2.0483260910998107

Epoch: 5| Step: 9
Training loss: 1.2484018802642822
Validation loss: 2.045396552290968

Epoch: 5| Step: 10
Training loss: 0.9281892776489258
Validation loss: 2.044919844596617

Epoch: 344| Step: 0
Training loss: 1.422402024269104
Validation loss: 2.0464600004175657

Epoch: 5| Step: 1
Training loss: 1.9098421335220337
Validation loss: 2.037793328685145

Epoch: 5| Step: 2
Training loss: 1.8784030675888062
Validation loss: 2.0059835744160477

Epoch: 5| Step: 3
Training loss: 0.9712467193603516
Validation loss: 2.042880421043724

Epoch: 5| Step: 4
Training loss: 1.5532310009002686
Validation loss: 2.0781939670603764

Epoch: 5| Step: 5
Training loss: 1.6358671188354492
Validation loss: 2.0300569406119724

Epoch: 5| Step: 6
Training loss: 1.0592153072357178
Validation loss: 2.005016875523393

Epoch: 5| Step: 7
Training loss: 1.4031469821929932
Validation loss: 2.052564109525373

Epoch: 5| Step: 8
Training loss: 1.3989111185073853
Validation loss: 1.989966848845123

Epoch: 5| Step: 9
Training loss: 1.9519239664077759
Validation loss: 1.9956651938858854

Epoch: 5| Step: 10
Training loss: 1.7427233457565308
Validation loss: 1.961301444679178

Epoch: 345| Step: 0
Training loss: 2.0152950286865234
Validation loss: 2.0339948772102274

Epoch: 5| Step: 1
Training loss: 1.1860849857330322
Validation loss: 2.0094472041694065

Epoch: 5| Step: 2
Training loss: 1.3525974750518799
Validation loss: 2.0053222256322063

Epoch: 5| Step: 3
Training loss: 1.942215919494629
Validation loss: 2.0011582169481503

Epoch: 5| Step: 4
Training loss: 1.534764051437378
Validation loss: 2.068966696339269

Epoch: 5| Step: 5
Training loss: 1.7471609115600586
Validation loss: 2.011996590962974

Epoch: 5| Step: 6
Training loss: 1.1833820343017578
Validation loss: 2.0023340230347006

Epoch: 5| Step: 7
Training loss: 1.601620078086853
Validation loss: 1.9761443881578342

Epoch: 5| Step: 8
Training loss: 1.6654939651489258
Validation loss: 1.9986400078701716

Epoch: 5| Step: 9
Training loss: 1.551234245300293
Validation loss: 2.0045139969036145

Epoch: 5| Step: 10
Training loss: 1.108956217765808
Validation loss: 2.012689730172516

Epoch: 346| Step: 0
Training loss: 1.2603511810302734
Validation loss: 2.0462689309991817

Epoch: 5| Step: 1
Training loss: 1.919759750366211
Validation loss: 2.0134000867925663

Epoch: 5| Step: 2
Training loss: 1.7657734155654907
Validation loss: 2.0351587085313696

Epoch: 5| Step: 3
Training loss: 1.471278190612793
Validation loss: 1.9957235641376947

Epoch: 5| Step: 4
Training loss: 1.0112625360488892
Validation loss: 1.958708264494455

Epoch: 5| Step: 5
Training loss: 1.6389859914779663
Validation loss: 2.017696715170337

Epoch: 5| Step: 6
Training loss: 1.666467308998108
Validation loss: 1.9962178468704224

Epoch: 5| Step: 7
Training loss: 1.735297441482544
Validation loss: 2.0459697374733548

Epoch: 5| Step: 8
Training loss: 1.4331998825073242
Validation loss: 2.0077501753325104

Epoch: 5| Step: 9
Training loss: 1.7421010732650757
Validation loss: 2.0491187431479014

Epoch: 5| Step: 10
Training loss: 1.3334475755691528
Validation loss: 1.9818717818106375

Epoch: 347| Step: 0
Training loss: 1.5547066926956177
Validation loss: 2.050244423650926

Epoch: 5| Step: 1
Training loss: 2.2202749252319336
Validation loss: 2.0249737565235426

Epoch: 5| Step: 2
Training loss: 0.9672366380691528
Validation loss: 2.035703444993624

Epoch: 5| Step: 3
Training loss: 1.139245867729187
Validation loss: 1.9839803518787507

Epoch: 5| Step: 4
Training loss: 0.9170500040054321
Validation loss: 2.0058483769816737

Epoch: 5| Step: 5
Training loss: 2.1503970623016357
Validation loss: 2.0022990139581824

Epoch: 5| Step: 6
Training loss: 2.276632308959961
Validation loss: 2.0089824571404407

Epoch: 5| Step: 7
Training loss: 1.2550805807113647
Validation loss: 1.999420314706782

Epoch: 5| Step: 8
Training loss: 1.3637378215789795
Validation loss: 2.0071191813356135

Epoch: 5| Step: 9
Training loss: 1.4874345064163208
Validation loss: 1.9944107917047316

Epoch: 5| Step: 10
Training loss: 1.8473484516143799
Validation loss: 1.9887540391696397

Epoch: 348| Step: 0
Training loss: 1.5685193538665771
Validation loss: 1.964902295861193

Epoch: 5| Step: 1
Training loss: 1.8081283569335938
Validation loss: 1.98356548688745

Epoch: 5| Step: 2
Training loss: 1.8212192058563232
Validation loss: 2.0151052398066365

Epoch: 5| Step: 3
Training loss: 1.4112904071807861
Validation loss: 2.0337762563459334

Epoch: 5| Step: 4
Training loss: 1.247064232826233
Validation loss: 2.0252185790769515

Epoch: 5| Step: 5
Training loss: 1.2626264095306396
Validation loss: 2.0259576638539634

Epoch: 5| Step: 6
Training loss: 1.5849764347076416
Validation loss: 2.0372179426172727

Epoch: 5| Step: 7
Training loss: 1.511107087135315
Validation loss: 2.0416798219885877

Epoch: 5| Step: 8
Training loss: 1.6584179401397705
Validation loss: 2.0298856099446616

Epoch: 5| Step: 9
Training loss: 1.753800630569458
Validation loss: 1.9999710846972722

Epoch: 5| Step: 10
Training loss: 1.5984615087509155
Validation loss: 2.0668098644543718

Epoch: 349| Step: 0
Training loss: 1.4361240863800049
Validation loss: 2.0798112705189693

Epoch: 5| Step: 1
Training loss: 1.769691824913025
Validation loss: 2.0070180098215737

Epoch: 5| Step: 2
Training loss: 1.2080976963043213
Validation loss: 2.065828110582085

Epoch: 5| Step: 3
Training loss: 1.5258697271347046
Validation loss: 2.0090128426910727

Epoch: 5| Step: 4
Training loss: 1.5679311752319336
Validation loss: 2.012064923522293

Epoch: 5| Step: 5
Training loss: 0.8291603326797485
Validation loss: 2.042005915795603

Epoch: 5| Step: 6
Training loss: 2.2067456245422363
Validation loss: 1.9960403750019688

Epoch: 5| Step: 7
Training loss: 0.9114181399345398
Validation loss: 2.018698687194496

Epoch: 5| Step: 8
Training loss: 2.3696727752685547
Validation loss: 1.959114287489204

Epoch: 5| Step: 9
Training loss: 1.4447404146194458
Validation loss: 2.0209552677728797

Epoch: 5| Step: 10
Training loss: 1.397734522819519
Validation loss: 2.0270896970584826

Epoch: 350| Step: 0
Training loss: 1.7219091653823853
Validation loss: 2.0313917231816117

Epoch: 5| Step: 1
Training loss: 1.0935614109039307
Validation loss: 2.049265282128447

Epoch: 5| Step: 2
Training loss: 1.252210021018982
Validation loss: 2.0240322569365143

Epoch: 5| Step: 3
Training loss: 1.53301203250885
Validation loss: 2.008174750112718

Epoch: 5| Step: 4
Training loss: 2.3015174865722656
Validation loss: 2.0042150462827375

Epoch: 5| Step: 5
Training loss: 1.3680988550186157
Validation loss: 2.0256729420795234

Epoch: 5| Step: 6
Training loss: 1.5833587646484375
Validation loss: 1.995311088459466

Epoch: 5| Step: 7
Training loss: 1.5179390907287598
Validation loss: 2.044030330514395

Epoch: 5| Step: 8
Training loss: 1.457678198814392
Validation loss: 2.0081437531337945

Epoch: 5| Step: 9
Training loss: 1.7567838430404663
Validation loss: 1.9866417005497923

Epoch: 5| Step: 10
Training loss: 1.5959415435791016
Validation loss: 2.0562589963277182

Epoch: 351| Step: 0
Training loss: 1.6740663051605225
Validation loss: 2.0117492547599216

Epoch: 5| Step: 1
Training loss: 1.5450456142425537
Validation loss: 2.0290223603607505

Epoch: 5| Step: 2
Training loss: 1.7738593816757202
Validation loss: 1.993227848442652

Epoch: 5| Step: 3
Training loss: 1.5208910703659058
Validation loss: 1.9838252811021702

Epoch: 5| Step: 4
Training loss: 1.1754074096679688
Validation loss: 2.032404386869041

Epoch: 5| Step: 5
Training loss: 1.073449969291687
Validation loss: 1.996775757881903

Epoch: 5| Step: 6
Training loss: 1.905168890953064
Validation loss: 2.0594610757725214

Epoch: 5| Step: 7
Training loss: 1.8502929210662842
Validation loss: 2.043265035075526

Epoch: 5| Step: 8
Training loss: 1.5611252784729004
Validation loss: 2.048792208394697

Epoch: 5| Step: 9
Training loss: 1.629608154296875
Validation loss: 1.993421531492664

Epoch: 5| Step: 10
Training loss: 1.3912705183029175
Validation loss: 2.0316179439585698

Epoch: 352| Step: 0
Training loss: 1.061340570449829
Validation loss: 2.0168717804775445

Epoch: 5| Step: 1
Training loss: 1.4425548315048218
Validation loss: 2.044636849434145

Epoch: 5| Step: 2
Training loss: 1.338463544845581
Validation loss: 2.044963195759763

Epoch: 5| Step: 3
Training loss: 1.8524948358535767
Validation loss: 2.020681683735181

Epoch: 5| Step: 4
Training loss: 1.484776258468628
Validation loss: 2.033122460047404

Epoch: 5| Step: 5
Training loss: 1.830148458480835
Validation loss: 2.025881594227206

Epoch: 5| Step: 6
Training loss: 1.5448834896087646
Validation loss: 2.038990056642922

Epoch: 5| Step: 7
Training loss: 1.1535322666168213
Validation loss: 2.030957624476443

Epoch: 5| Step: 8
Training loss: 1.840490698814392
Validation loss: 1.993130527516847

Epoch: 5| Step: 9
Training loss: 1.7878621816635132
Validation loss: 2.01755686472821

Epoch: 5| Step: 10
Training loss: 1.6946519613265991
Validation loss: 2.0248678948289607

Epoch: 353| Step: 0
Training loss: 1.5734620094299316
Validation loss: 2.041792251730478

Epoch: 5| Step: 1
Training loss: 1.1594051122665405
Validation loss: 2.0056482758573306

Epoch: 5| Step: 2
Training loss: 1.5134881734848022
Validation loss: 2.021065222319736

Epoch: 5| Step: 3
Training loss: 1.6816387176513672
Validation loss: 2.0231895767232424

Epoch: 5| Step: 4
Training loss: 1.3239490985870361
Validation loss: 2.017646348604592

Epoch: 5| Step: 5
Training loss: 0.8724210858345032
Validation loss: 2.005969120610145

Epoch: 5| Step: 6
Training loss: 1.6425864696502686
Validation loss: 1.9977347491889872

Epoch: 5| Step: 7
Training loss: 1.8865535259246826
Validation loss: 2.0227879670358475

Epoch: 5| Step: 8
Training loss: 2.2927873134613037
Validation loss: 2.033752411924383

Epoch: 5| Step: 9
Training loss: 1.2680284976959229
Validation loss: 1.982734892957954

Epoch: 5| Step: 10
Training loss: 1.6452324390411377
Validation loss: 2.021212634219918

Epoch: 354| Step: 0
Training loss: 1.5215212106704712
Validation loss: 2.0154505570729575

Epoch: 5| Step: 1
Training loss: 0.7619211673736572
Validation loss: 2.0306620033838416

Epoch: 5| Step: 2
Training loss: 1.475232720375061
Validation loss: 1.9768990470517067

Epoch: 5| Step: 3
Training loss: 1.9235973358154297
Validation loss: 2.016320223449379

Epoch: 5| Step: 4
Training loss: 1.390939712524414
Validation loss: 2.0489031563522997

Epoch: 5| Step: 5
Training loss: 1.3905165195465088
Validation loss: 2.0578547100866995

Epoch: 5| Step: 6
Training loss: 1.9996894598007202
Validation loss: 2.0096913089034376

Epoch: 5| Step: 7
Training loss: 1.8869876861572266
Validation loss: 2.0062606232140654

Epoch: 5| Step: 8
Training loss: 1.4802258014678955
Validation loss: 2.0155536769538798

Epoch: 5| Step: 9
Training loss: 1.620933175086975
Validation loss: 2.006853513820197

Epoch: 5| Step: 10
Training loss: 1.6102731227874756
Validation loss: 2.0614819013944237

Epoch: 355| Step: 0
Training loss: 1.4601224660873413
Validation loss: 2.047590591574228

Epoch: 5| Step: 1
Training loss: 1.8561210632324219
Validation loss: 2.0260503304901945

Epoch: 5| Step: 2
Training loss: 1.2456893920898438
Validation loss: 2.010740340396922

Epoch: 5| Step: 3
Training loss: 1.0776326656341553
Validation loss: 2.056511145766063

Epoch: 5| Step: 4
Training loss: 1.2983978986740112
Validation loss: 2.04555183072244

Epoch: 5| Step: 5
Training loss: 1.4517778158187866
Validation loss: 2.0260704537873626

Epoch: 5| Step: 6
Training loss: 1.2506365776062012
Validation loss: 2.0036472094956266

Epoch: 5| Step: 7
Training loss: 1.8821985721588135
Validation loss: 2.0365474377909014

Epoch: 5| Step: 8
Training loss: 1.8365939855575562
Validation loss: 1.9804806196561424

Epoch: 5| Step: 9
Training loss: 1.961343765258789
Validation loss: 1.9910620668882966

Epoch: 5| Step: 10
Training loss: 1.332567811012268
Validation loss: 1.9930422639334073

Epoch: 356| Step: 0
Training loss: 1.3269315958023071
Validation loss: 2.016733697665635

Epoch: 5| Step: 1
Training loss: 1.950634241104126
Validation loss: 2.0275082895832677

Epoch: 5| Step: 2
Training loss: 1.701163649559021
Validation loss: 2.0161646002082416

Epoch: 5| Step: 3
Training loss: 2.4702351093292236
Validation loss: 1.9927272360811952

Epoch: 5| Step: 4
Training loss: 1.6387560367584229
Validation loss: 1.9944607237333893

Epoch: 5| Step: 5
Training loss: 0.9777928590774536
Validation loss: 1.99335015332827

Epoch: 5| Step: 6
Training loss: 1.4687985181808472
Validation loss: 2.0113996997956307

Epoch: 5| Step: 7
Training loss: 1.7336174249649048
Validation loss: 2.031330088133453

Epoch: 5| Step: 8
Training loss: 1.3095520734786987
Validation loss: 2.0659869012012275

Epoch: 5| Step: 9
Training loss: 1.0205347537994385
Validation loss: 2.015533052464967

Epoch: 5| Step: 10
Training loss: 1.5447090864181519
Validation loss: 2.0575514096085743

Epoch: 357| Step: 0
Training loss: 0.7248010635375977
Validation loss: 2.0533126695181734

Epoch: 5| Step: 1
Training loss: 1.7005646228790283
Validation loss: 2.044309252051897

Epoch: 5| Step: 2
Training loss: 1.8964000940322876
Validation loss: 2.0411170580053843

Epoch: 5| Step: 3
Training loss: 1.4440383911132812
Validation loss: 2.084749560202322

Epoch: 5| Step: 4
Training loss: 1.4221960306167603
Validation loss: 2.0351091008032522

Epoch: 5| Step: 5
Training loss: 1.3080499172210693
Validation loss: 1.9999056810973792

Epoch: 5| Step: 6
Training loss: 1.8383601903915405
Validation loss: 2.0476063618095974

Epoch: 5| Step: 7
Training loss: 1.538590431213379
Validation loss: 2.032968198099444

Epoch: 5| Step: 8
Training loss: 1.2860662937164307
Validation loss: 2.0305466587825487

Epoch: 5| Step: 9
Training loss: 1.616990327835083
Validation loss: 2.0360953936012844

Epoch: 5| Step: 10
Training loss: 2.032838821411133
Validation loss: 2.0467861365246516

Epoch: 358| Step: 0
Training loss: 1.8879919052124023
Validation loss: 1.9984610516537902

Epoch: 5| Step: 1
Training loss: 1.2843654155731201
Validation loss: 2.0102128328815585

Epoch: 5| Step: 2
Training loss: 1.4429738521575928
Validation loss: 2.0015085422864525

Epoch: 5| Step: 3
Training loss: 1.0295336246490479
Validation loss: 2.0143805780718402

Epoch: 5| Step: 4
Training loss: 1.9759891033172607
Validation loss: 2.014261108572765

Epoch: 5| Step: 5
Training loss: 1.6115381717681885
Validation loss: 2.0098881208768455

Epoch: 5| Step: 6
Training loss: 1.4245952367782593
Validation loss: 1.9823856315305155

Epoch: 5| Step: 7
Training loss: 1.4814035892486572
Validation loss: 2.0074228932780604

Epoch: 5| Step: 8
Training loss: 1.1971315145492554
Validation loss: 2.0155097899898404

Epoch: 5| Step: 9
Training loss: 1.502274751663208
Validation loss: 1.986110964129048

Epoch: 5| Step: 10
Training loss: 2.0156617164611816
Validation loss: 1.9900172320745324

Epoch: 359| Step: 0
Training loss: 1.0707043409347534
Validation loss: 1.9868263993211972

Epoch: 5| Step: 1
Training loss: 1.284607172012329
Validation loss: 1.9797731240590413

Epoch: 5| Step: 2
Training loss: 1.6617252826690674
Validation loss: 1.98022214827999

Epoch: 5| Step: 3
Training loss: 1.5913852453231812
Validation loss: 1.9970668336396575

Epoch: 5| Step: 4
Training loss: 1.9799683094024658
Validation loss: 2.02939163484881

Epoch: 5| Step: 5
Training loss: 1.8956884145736694
Validation loss: 2.061094186639273

Epoch: 5| Step: 6
Training loss: 1.5426552295684814
Validation loss: 2.008493758017017

Epoch: 5| Step: 7
Training loss: 0.9463922381401062
Validation loss: 2.016352225375432

Epoch: 5| Step: 8
Training loss: 1.0137158632278442
Validation loss: 2.045915294718999

Epoch: 5| Step: 9
Training loss: 1.885765790939331
Validation loss: 2.100003478347614

Epoch: 5| Step: 10
Training loss: 1.6785268783569336
Validation loss: 2.097715154770882

Epoch: 360| Step: 0
Training loss: 2.087716579437256
Validation loss: 2.046683910072491

Epoch: 5| Step: 1
Training loss: 1.5903618335723877
Validation loss: 2.1077252690510084

Epoch: 5| Step: 2
Training loss: 1.4584753513336182
Validation loss: 2.098094742785218

Epoch: 5| Step: 3
Training loss: 2.005021810531616
Validation loss: 2.0498195361065608

Epoch: 5| Step: 4
Training loss: 1.0798096656799316
Validation loss: 2.078999102756541

Epoch: 5| Step: 5
Training loss: 1.4106236696243286
Validation loss: 2.0537347960215744

Epoch: 5| Step: 6
Training loss: 1.5825153589248657
Validation loss: 2.0101642403551327

Epoch: 5| Step: 7
Training loss: 1.5816913843154907
Validation loss: 2.0084873271244827

Epoch: 5| Step: 8
Training loss: 1.511730432510376
Validation loss: 1.9927407874855945

Epoch: 5| Step: 9
Training loss: 1.4783437252044678
Validation loss: 1.9993593590233916

Epoch: 5| Step: 10
Training loss: 1.2157912254333496
Validation loss: 1.98610431660888

Epoch: 361| Step: 0
Training loss: 2.0620334148406982
Validation loss: 2.023437291063288

Epoch: 5| Step: 1
Training loss: 1.2494055032730103
Validation loss: 1.9965429959758636

Epoch: 5| Step: 2
Training loss: 2.058065414428711
Validation loss: 1.9963234393827376

Epoch: 5| Step: 3
Training loss: 1.5266525745391846
Validation loss: 1.9688891979955858

Epoch: 5| Step: 4
Training loss: 2.040097951889038
Validation loss: 2.004300816084749

Epoch: 5| Step: 5
Training loss: 0.5271850824356079
Validation loss: 1.9991671321212605

Epoch: 5| Step: 6
Training loss: 1.0781667232513428
Validation loss: 2.0132015135980423

Epoch: 5| Step: 7
Training loss: 2.4528510570526123
Validation loss: 2.0360378937054704

Epoch: 5| Step: 8
Training loss: 1.1106469631195068
Validation loss: 2.0058667326486237

Epoch: 5| Step: 9
Training loss: 1.0821210145950317
Validation loss: 2.0197487467078754

Epoch: 5| Step: 10
Training loss: 1.5266172885894775
Validation loss: 2.025889786340857

Epoch: 362| Step: 0
Training loss: 1.2564568519592285
Validation loss: 2.0282896693034838

Epoch: 5| Step: 1
Training loss: 1.1096404790878296
Validation loss: 1.9858369417088007

Epoch: 5| Step: 2
Training loss: 1.4528768062591553
Validation loss: 2.0526763316123717

Epoch: 5| Step: 3
Training loss: 1.9423799514770508
Validation loss: 2.0148685016939716

Epoch: 5| Step: 4
Training loss: 1.6782255172729492
Validation loss: 2.0468995212226786

Epoch: 5| Step: 5
Training loss: 1.9659115076065063
Validation loss: 2.041552360339831

Epoch: 5| Step: 6
Training loss: 1.3866394758224487
Validation loss: 2.020530185391826

Epoch: 5| Step: 7
Training loss: 1.9619171619415283
Validation loss: 2.0643487361169632

Epoch: 5| Step: 8
Training loss: 1.796983003616333
Validation loss: 2.0743342548288326

Epoch: 5| Step: 9
Training loss: 1.105848789215088
Validation loss: 2.0327949216288905

Epoch: 5| Step: 10
Training loss: 1.315033197402954
Validation loss: 2.0597789800295265

Epoch: 363| Step: 0
Training loss: 1.2115120887756348
Validation loss: 2.0359669295690392

Epoch: 5| Step: 1
Training loss: 1.3652769327163696
Validation loss: 2.0234589743357834

Epoch: 5| Step: 2
Training loss: 1.5467455387115479
Validation loss: 2.0598166655468684

Epoch: 5| Step: 3
Training loss: 1.202643871307373
Validation loss: 1.9950216277953117

Epoch: 5| Step: 4
Training loss: 2.009244680404663
Validation loss: 2.023166641112297

Epoch: 5| Step: 5
Training loss: 2.0333704948425293
Validation loss: 2.0317813837400047

Epoch: 5| Step: 6
Training loss: 1.3718645572662354
Validation loss: 2.013865929777904

Epoch: 5| Step: 7
Training loss: 1.2570706605911255
Validation loss: 1.992048978805542

Epoch: 5| Step: 8
Training loss: 1.1684844493865967
Validation loss: 2.008879538505308

Epoch: 5| Step: 9
Training loss: 1.3130090236663818
Validation loss: 1.99748456862665

Epoch: 5| Step: 10
Training loss: 2.091078281402588
Validation loss: 2.0307446692579534

Epoch: 364| Step: 0
Training loss: 0.9419065713882446
Validation loss: 1.9735374912138908

Epoch: 5| Step: 1
Training loss: 1.7836021184921265
Validation loss: 2.02150539172593

Epoch: 5| Step: 2
Training loss: 1.5184416770935059
Validation loss: 2.0013210235103482

Epoch: 5| Step: 3
Training loss: 1.4901114702224731
Validation loss: 2.0121833611560125

Epoch: 5| Step: 4
Training loss: 1.6057630777359009
Validation loss: 2.0043708534650904

Epoch: 5| Step: 5
Training loss: 1.5627222061157227
Validation loss: 1.992488391937748

Epoch: 5| Step: 6
Training loss: 1.0508239269256592
Validation loss: 2.011758671011976

Epoch: 5| Step: 7
Training loss: 1.0125287771224976
Validation loss: 1.932416105783114

Epoch: 5| Step: 8
Training loss: 1.8870666027069092
Validation loss: 2.014014110770277

Epoch: 5| Step: 9
Training loss: 1.763831377029419
Validation loss: 1.9751125433111703

Epoch: 5| Step: 10
Training loss: 2.0988709926605225
Validation loss: 2.0035962430379723

Epoch: 365| Step: 0
Training loss: 0.892219066619873
Validation loss: 1.9753006530064408

Epoch: 5| Step: 1
Training loss: 1.341573715209961
Validation loss: 2.0322791684058403

Epoch: 5| Step: 2
Training loss: 1.8789825439453125
Validation loss: 2.022291244999055

Epoch: 5| Step: 3
Training loss: 1.2625279426574707
Validation loss: 2.056739023936692

Epoch: 5| Step: 4
Training loss: 1.640419602394104
Validation loss: 1.9965737506907473

Epoch: 5| Step: 5
Training loss: 1.6348997354507446
Validation loss: 2.0126698427302863

Epoch: 5| Step: 6
Training loss: 2.2398409843444824
Validation loss: 1.979929736865464

Epoch: 5| Step: 7
Training loss: 1.1709620952606201
Validation loss: 2.030618370220225

Epoch: 5| Step: 8
Training loss: 1.5858752727508545
Validation loss: 2.0421490412886425

Epoch: 5| Step: 9
Training loss: 1.6409690380096436
Validation loss: 2.071986690644295

Epoch: 5| Step: 10
Training loss: 1.2784242630004883
Validation loss: 2.0173552574649936

Epoch: 366| Step: 0
Training loss: 2.016550064086914
Validation loss: 2.0587910118923394

Epoch: 5| Step: 1
Training loss: 1.7902181148529053
Validation loss: 2.03143395147016

Epoch: 5| Step: 2
Training loss: 1.8964507579803467
Validation loss: 2.039346925673946

Epoch: 5| Step: 3
Training loss: 0.9448257684707642
Validation loss: 2.0136306260221746

Epoch: 5| Step: 4
Training loss: 1.4984791278839111
Validation loss: 2.010911423672912

Epoch: 5| Step: 5
Training loss: 0.9019230008125305
Validation loss: 2.013094130382743

Epoch: 5| Step: 6
Training loss: 1.8157069683074951
Validation loss: 2.0213105191466627

Epoch: 5| Step: 7
Training loss: 1.2113884687423706
Validation loss: 2.014364539936025

Epoch: 5| Step: 8
Training loss: 2.117170572280884
Validation loss: 2.000721759693597

Epoch: 5| Step: 9
Training loss: 0.6973459720611572
Validation loss: 1.998270506499916

Epoch: 5| Step: 10
Training loss: 1.7985682487487793
Validation loss: 2.03889726567012

Epoch: 367| Step: 0
Training loss: 1.3060781955718994
Validation loss: 2.0297242723485476

Epoch: 5| Step: 1
Training loss: 1.2167363166809082
Validation loss: 2.0023852791837466

Epoch: 5| Step: 2
Training loss: 1.037243127822876
Validation loss: 2.000610928381643

Epoch: 5| Step: 3
Training loss: 1.5767720937728882
Validation loss: 2.0269971380951586

Epoch: 5| Step: 4
Training loss: 1.9418895244598389
Validation loss: 1.999438044845417

Epoch: 5| Step: 5
Training loss: 1.6040436029434204
Validation loss: 2.0177866874202603

Epoch: 5| Step: 6
Training loss: 1.4485008716583252
Validation loss: 2.0025030643709245

Epoch: 5| Step: 7
Training loss: 1.781719446182251
Validation loss: 2.0121615317560013

Epoch: 5| Step: 8
Training loss: 1.499376654624939
Validation loss: 2.00391125166288

Epoch: 5| Step: 9
Training loss: 1.8286529779434204
Validation loss: 2.039412085727979

Epoch: 5| Step: 10
Training loss: 1.6357213258743286
Validation loss: 1.9990293005461335

Epoch: 368| Step: 0
Training loss: 1.9017938375473022
Validation loss: 2.0115344255201277

Epoch: 5| Step: 1
Training loss: 1.0856539011001587
Validation loss: 2.008654540584933

Epoch: 5| Step: 2
Training loss: 1.737898588180542
Validation loss: 1.9905221410976943

Epoch: 5| Step: 3
Training loss: 1.7545969486236572
Validation loss: 2.0231868015822543

Epoch: 5| Step: 4
Training loss: 1.4195524454116821
Validation loss: 2.0465578520169823

Epoch: 5| Step: 5
Training loss: 1.4149389266967773
Validation loss: 2.008202488704394

Epoch: 5| Step: 6
Training loss: 1.2919270992279053
Validation loss: 2.015308354490547

Epoch: 5| Step: 7
Training loss: 1.291496992111206
Validation loss: 1.9927840809668265

Epoch: 5| Step: 8
Training loss: 1.3091298341751099
Validation loss: 1.9964600865558912

Epoch: 5| Step: 9
Training loss: 1.7420943975448608
Validation loss: 2.0098463130253617

Epoch: 5| Step: 10
Training loss: 1.3514281511306763
Validation loss: 2.0401518293606338

Epoch: 369| Step: 0
Training loss: 2.0268871784210205
Validation loss: 2.025368421308456

Epoch: 5| Step: 1
Training loss: 1.497287631034851
Validation loss: 1.9962849424731346

Epoch: 5| Step: 2
Training loss: 0.6322132349014282
Validation loss: 2.0153206766292615

Epoch: 5| Step: 3
Training loss: 1.3375070095062256
Validation loss: 1.989640478164919

Epoch: 5| Step: 4
Training loss: 1.916077971458435
Validation loss: 2.0030635351775796

Epoch: 5| Step: 5
Training loss: 1.3065532445907593
Validation loss: 2.0241884634058964

Epoch: 5| Step: 6
Training loss: 1.705167531967163
Validation loss: 2.0301230697221655

Epoch: 5| Step: 7
Training loss: 1.7676594257354736
Validation loss: 1.9859828654155935

Epoch: 5| Step: 8
Training loss: 1.6369956731796265
Validation loss: 2.0116709483567106

Epoch: 5| Step: 9
Training loss: 1.190085530281067
Validation loss: 2.0091247943139847

Epoch: 5| Step: 10
Training loss: 1.699537754058838
Validation loss: 1.9950784919082478

Epoch: 370| Step: 0
Training loss: 1.652817964553833
Validation loss: 2.024505780589196

Epoch: 5| Step: 1
Training loss: 1.2225170135498047
Validation loss: 2.0033900917217298

Epoch: 5| Step: 2
Training loss: 1.842529058456421
Validation loss: 1.9870792024879045

Epoch: 5| Step: 3
Training loss: 1.0489883422851562
Validation loss: 2.0397915635057675

Epoch: 5| Step: 4
Training loss: 1.6296851634979248
Validation loss: 2.0102723965080838

Epoch: 5| Step: 5
Training loss: 1.2580962181091309
Validation loss: 1.997888034389865

Epoch: 5| Step: 6
Training loss: 1.6880381107330322
Validation loss: 2.0185981565906155

Epoch: 5| Step: 7
Training loss: 1.8088080883026123
Validation loss: 2.007560327488889

Epoch: 5| Step: 8
Training loss: 1.8490641117095947
Validation loss: 2.0153284470240274

Epoch: 5| Step: 9
Training loss: 1.3746790885925293
Validation loss: 2.0301072007866314

Epoch: 5| Step: 10
Training loss: 1.332594871520996
Validation loss: 2.056293918240455

Epoch: 371| Step: 0
Training loss: 1.3333396911621094
Validation loss: 2.0441107134665213

Epoch: 5| Step: 1
Training loss: 1.660516381263733
Validation loss: 1.9948790727123138

Epoch: 5| Step: 2
Training loss: 1.485480785369873
Validation loss: 2.0312499538544686

Epoch: 5| Step: 3
Training loss: 1.56509530544281
Validation loss: 2.0264079006769324

Epoch: 5| Step: 4
Training loss: 1.6191431283950806
Validation loss: 2.0655824676636727

Epoch: 5| Step: 5
Training loss: 2.0807368755340576
Validation loss: 2.0603342581820745

Epoch: 5| Step: 6
Training loss: 1.3177924156188965
Validation loss: 2.0552866740893294

Epoch: 5| Step: 7
Training loss: 1.2263953685760498
Validation loss: 2.087751418031672

Epoch: 5| Step: 8
Training loss: 1.262574553489685
Validation loss: 2.0675751547659598

Epoch: 5| Step: 9
Training loss: 1.3614394664764404
Validation loss: 2.0727873463784494

Epoch: 5| Step: 10
Training loss: 1.4728931188583374
Validation loss: 2.0336791238477154

Epoch: 372| Step: 0
Training loss: 1.4136537313461304
Validation loss: 2.0254105547423005

Epoch: 5| Step: 1
Training loss: 1.0165073871612549
Validation loss: 2.0238115915688137

Epoch: 5| Step: 2
Training loss: 1.5212482213974
Validation loss: 1.9904815817392

Epoch: 5| Step: 3
Training loss: 1.6421371698379517
Validation loss: 1.9989612730600501

Epoch: 5| Step: 4
Training loss: 1.9094388484954834
Validation loss: 1.9755350107787757

Epoch: 5| Step: 5
Training loss: 1.9112460613250732
Validation loss: 2.0010946412240305

Epoch: 5| Step: 6
Training loss: 1.3263853788375854
Validation loss: 1.9884379345883605

Epoch: 5| Step: 7
Training loss: 1.9111353158950806
Validation loss: 2.0375704842229045

Epoch: 5| Step: 8
Training loss: 1.359188199043274
Validation loss: 1.9961605430931173

Epoch: 5| Step: 9
Training loss: 1.3978679180145264
Validation loss: 1.9823112680066017

Epoch: 5| Step: 10
Training loss: 1.2552759647369385
Validation loss: 1.9678355724580827

Epoch: 373| Step: 0
Training loss: 1.2363290786743164
Validation loss: 2.005020946584722

Epoch: 5| Step: 1
Training loss: 1.5886976718902588
Validation loss: 2.018596333842124

Epoch: 5| Step: 2
Training loss: 1.3228651285171509
Validation loss: 1.9938466215646395

Epoch: 5| Step: 3
Training loss: 1.188693881034851
Validation loss: 1.9978842196925994

Epoch: 5| Step: 4
Training loss: 1.6942237615585327
Validation loss: 2.017490863800049

Epoch: 5| Step: 5
Training loss: 1.4402333498001099
Validation loss: 2.0703049834056566

Epoch: 5| Step: 6
Training loss: 1.9075673818588257
Validation loss: 2.0510622916683072

Epoch: 5| Step: 7
Training loss: 1.7338991165161133
Validation loss: 2.057974277004119

Epoch: 5| Step: 8
Training loss: 1.45485520362854
Validation loss: 2.018184677247078

Epoch: 5| Step: 9
Training loss: 1.551329493522644
Validation loss: 2.0737810980889106

Epoch: 5| Step: 10
Training loss: 1.3133413791656494
Validation loss: 2.0927572673366917

Epoch: 374| Step: 0
Training loss: 1.2972110509872437
Validation loss: 2.007527420597692

Epoch: 5| Step: 1
Training loss: 0.7001495361328125
Validation loss: 1.9724546222276584

Epoch: 5| Step: 2
Training loss: 1.6545661687850952
Validation loss: 2.004226889661563

Epoch: 5| Step: 3
Training loss: 1.5305105447769165
Validation loss: 2.050451153068132

Epoch: 5| Step: 4
Training loss: 1.3688790798187256
Validation loss: 2.000531731113311

Epoch: 5| Step: 5
Training loss: 1.5854613780975342
Validation loss: 2.0015874485815726

Epoch: 5| Step: 6
Training loss: 1.6456615924835205
Validation loss: 2.0227315041326706

Epoch: 5| Step: 7
Training loss: 1.4940531253814697
Validation loss: 1.9847543008865849

Epoch: 5| Step: 8
Training loss: 1.9557178020477295
Validation loss: 1.9855515213422879

Epoch: 5| Step: 9
Training loss: 1.6905710697174072
Validation loss: 2.014568340393805

Epoch: 5| Step: 10
Training loss: 1.9185028076171875
Validation loss: 1.9834409990618307

Epoch: 375| Step: 0
Training loss: 1.5887130498886108
Validation loss: 2.0122655591657086

Epoch: 5| Step: 1
Training loss: 0.8361028432846069
Validation loss: 2.0388854049867198

Epoch: 5| Step: 2
Training loss: 1.8699805736541748
Validation loss: 1.9547167599842112

Epoch: 5| Step: 3
Training loss: 1.6335468292236328
Validation loss: 2.0537400220030095

Epoch: 5| Step: 4
Training loss: 0.9892524480819702
Validation loss: 2.048276843563203

Epoch: 5| Step: 5
Training loss: 1.1255465745925903
Validation loss: 2.0769617583162043

Epoch: 5| Step: 6
Training loss: 1.574191689491272
Validation loss: 2.034231208985852

Epoch: 5| Step: 7
Training loss: 1.6444717645645142
Validation loss: 1.9895143406365507

Epoch: 5| Step: 8
Training loss: 1.6668663024902344
Validation loss: 2.018713399928103

Epoch: 5| Step: 9
Training loss: 1.850581407546997
Validation loss: 2.043119768942556

Epoch: 5| Step: 10
Training loss: 1.5537314414978027
Validation loss: 2.0046236258681103

Epoch: 376| Step: 0
Training loss: 2.215604782104492
Validation loss: 2.0349046632807744

Epoch: 5| Step: 1
Training loss: 1.301214337348938
Validation loss: 2.017835627319992

Epoch: 5| Step: 2
Training loss: 1.4919283390045166
Validation loss: 1.9883016847795056

Epoch: 5| Step: 3
Training loss: 1.111070156097412
Validation loss: 2.0188042925250147

Epoch: 5| Step: 4
Training loss: 1.3738956451416016
Validation loss: 1.9967825861387356

Epoch: 5| Step: 5
Training loss: 1.9660724401474
Validation loss: 1.9621183526131414

Epoch: 5| Step: 6
Training loss: 1.2268354892730713
Validation loss: 2.0117717801883654

Epoch: 5| Step: 7
Training loss: 1.2024155855178833
Validation loss: 2.014794183033769

Epoch: 5| Step: 8
Training loss: 0.9439457058906555
Validation loss: 1.9724829478930401

Epoch: 5| Step: 9
Training loss: 1.833727240562439
Validation loss: 2.054485208244734

Epoch: 5| Step: 10
Training loss: 1.6777241230010986
Validation loss: 1.9729260808678084

Epoch: 377| Step: 0
Training loss: 1.512685775756836
Validation loss: 2.027558941994944

Epoch: 5| Step: 1
Training loss: 1.7461109161376953
Validation loss: 2.0021023673395955

Epoch: 5| Step: 2
Training loss: 1.047938346862793
Validation loss: 2.01294481882485

Epoch: 5| Step: 3
Training loss: 1.6369571685791016
Validation loss: 2.0377275623301023

Epoch: 5| Step: 4
Training loss: 1.5759459733963013
Validation loss: 2.012029799081946

Epoch: 5| Step: 5
Training loss: 1.7026550769805908
Validation loss: 1.990935738368701

Epoch: 5| Step: 6
Training loss: 1.1095749139785767
Validation loss: 1.9580217330686507

Epoch: 5| Step: 7
Training loss: 1.2141106128692627
Validation loss: 2.038666646967652

Epoch: 5| Step: 8
Training loss: 1.6339740753173828
Validation loss: 2.045273311676518

Epoch: 5| Step: 9
Training loss: 2.0813581943511963
Validation loss: 2.0430225454350954

Epoch: 5| Step: 10
Training loss: 1.5222829580307007
Validation loss: 1.9880599027038903

Epoch: 378| Step: 0
Training loss: 1.875288724899292
Validation loss: 1.9938826881429201

Epoch: 5| Step: 1
Training loss: 1.3617732524871826
Validation loss: 1.9940517333246046

Epoch: 5| Step: 2
Training loss: 1.4812240600585938
Validation loss: 1.9798491706130326

Epoch: 5| Step: 3
Training loss: 1.0789071321487427
Validation loss: 2.041539115290488

Epoch: 5| Step: 4
Training loss: 1.7772886753082275
Validation loss: 1.964693275831079

Epoch: 5| Step: 5
Training loss: 1.4500906467437744
Validation loss: 1.9692693256562757

Epoch: 5| Step: 6
Training loss: 1.442878007888794
Validation loss: 1.9808509298550185

Epoch: 5| Step: 7
Training loss: 1.3716692924499512
Validation loss: 1.9962342451977473

Epoch: 5| Step: 8
Training loss: 1.5968596935272217
Validation loss: 1.9780053220769411

Epoch: 5| Step: 9
Training loss: 1.926034688949585
Validation loss: 2.0434537882445962

Epoch: 5| Step: 10
Training loss: 1.1333829164505005
Validation loss: 2.0020851858200563

Epoch: 379| Step: 0
Training loss: 1.0869169235229492
Validation loss: 1.9937817499201784

Epoch: 5| Step: 1
Training loss: 2.268819808959961
Validation loss: 1.9992600922943444

Epoch: 5| Step: 2
Training loss: 1.547472596168518
Validation loss: 2.033204693948069

Epoch: 5| Step: 3
Training loss: 1.43704092502594
Validation loss: 2.0123162243955877

Epoch: 5| Step: 4
Training loss: 2.3255183696746826
Validation loss: 2.050647178003865

Epoch: 5| Step: 5
Training loss: 0.7727454900741577
Validation loss: 2.03224060099612

Epoch: 5| Step: 6
Training loss: 1.5803797245025635
Validation loss: 1.9784210856242845

Epoch: 5| Step: 7
Training loss: 1.112282395362854
Validation loss: 2.024608873551892

Epoch: 5| Step: 8
Training loss: 0.9378336071968079
Validation loss: 2.0350933010860155

Epoch: 5| Step: 9
Training loss: 1.794866919517517
Validation loss: 1.9982251685152772

Epoch: 5| Step: 10
Training loss: 1.4075289964675903
Validation loss: 1.9782548040472052

Epoch: 380| Step: 0
Training loss: 1.9110100269317627
Validation loss: 1.9887756057964858

Epoch: 5| Step: 1
Training loss: 1.405586838722229
Validation loss: 2.0620956164534374

Epoch: 5| Step: 2
Training loss: 1.0763355493545532
Validation loss: 1.9940538419190275

Epoch: 5| Step: 3
Training loss: 1.8555381298065186
Validation loss: 1.9935268740500174

Epoch: 5| Step: 4
Training loss: 1.4869506359100342
Validation loss: 1.9751660464912333

Epoch: 5| Step: 5
Training loss: 1.6336265802383423
Validation loss: 1.9846930696118263

Epoch: 5| Step: 6
Training loss: 1.490092396736145
Validation loss: 2.028880253273954

Epoch: 5| Step: 7
Training loss: 1.0023376941680908
Validation loss: 2.005798473153063

Epoch: 5| Step: 8
Training loss: 1.7390391826629639
Validation loss: 1.999455410947082

Epoch: 5| Step: 9
Training loss: 1.3674331903457642
Validation loss: 2.010897892777638

Epoch: 5| Step: 10
Training loss: 1.5995306968688965
Validation loss: 2.0527979199604323

Epoch: 381| Step: 0
Training loss: 1.8466224670410156
Validation loss: 2.024403674628145

Epoch: 5| Step: 1
Training loss: 1.5999648571014404
Validation loss: 2.0081319501323085

Epoch: 5| Step: 2
Training loss: 1.3594765663146973
Validation loss: 2.0187368751854025

Epoch: 5| Step: 3
Training loss: 1.5268502235412598
Validation loss: 2.062194969064446

Epoch: 5| Step: 4
Training loss: 1.6202201843261719
Validation loss: 1.9959459996992541

Epoch: 5| Step: 5
Training loss: 1.5729625225067139
Validation loss: 2.011743240458991

Epoch: 5| Step: 6
Training loss: 1.4017645120620728
Validation loss: 2.044983693348464

Epoch: 5| Step: 7
Training loss: 1.0241602659225464
Validation loss: 2.0972414478178947

Epoch: 5| Step: 8
Training loss: 1.646715521812439
Validation loss: 1.9981234919640325

Epoch: 5| Step: 9
Training loss: 1.4583876132965088
Validation loss: 2.043080360658707

Epoch: 5| Step: 10
Training loss: 1.4329023361206055
Validation loss: 2.025897015807449

Epoch: 382| Step: 0
Training loss: 1.8734028339385986
Validation loss: 2.041794482097831

Epoch: 5| Step: 1
Training loss: 1.8447309732437134
Validation loss: 1.9967494754381077

Epoch: 5| Step: 2
Training loss: 1.93533456325531
Validation loss: 1.983802951792235

Epoch: 5| Step: 3
Training loss: 1.6538947820663452
Validation loss: 1.9879163952283962

Epoch: 5| Step: 4
Training loss: 1.7530510425567627
Validation loss: 1.9958793552972938

Epoch: 5| Step: 5
Training loss: 1.1209728717803955
Validation loss: 1.996294311297837

Epoch: 5| Step: 6
Training loss: 1.3559478521347046
Validation loss: 2.011740207672119

Epoch: 5| Step: 7
Training loss: 1.2426687479019165
Validation loss: 2.0139292414470384

Epoch: 5| Step: 8
Training loss: 1.051460862159729
Validation loss: 1.973936273205665

Epoch: 5| Step: 9
Training loss: 1.4622248411178589
Validation loss: 1.9891741173241728

Epoch: 5| Step: 10
Training loss: 0.849323034286499
Validation loss: 2.0061618621631334

Epoch: 383| Step: 0
Training loss: 1.6794627904891968
Validation loss: 1.9899791491928922

Epoch: 5| Step: 1
Training loss: 1.222711205482483
Validation loss: 1.9842451618563743

Epoch: 5| Step: 2
Training loss: 1.4369876384735107
Validation loss: 2.003528884662095

Epoch: 5| Step: 3
Training loss: 1.412940502166748
Validation loss: 1.957326114818614

Epoch: 5| Step: 4
Training loss: 1.882076621055603
Validation loss: 2.0214405175178283

Epoch: 5| Step: 5
Training loss: 2.0195705890655518
Validation loss: 2.0088452908300583

Epoch: 5| Step: 6
Training loss: 1.0520057678222656
Validation loss: 2.002739817865433

Epoch: 5| Step: 7
Training loss: 1.514331579208374
Validation loss: 1.968695427781792

Epoch: 5| Step: 8
Training loss: 1.3848460912704468
Validation loss: 2.0672638377835675

Epoch: 5| Step: 9
Training loss: 1.6762239933013916
Validation loss: 2.035971350567315

Epoch: 5| Step: 10
Training loss: 0.7264259457588196
Validation loss: 1.9933220135268344

Epoch: 384| Step: 0
Training loss: 1.318838119506836
Validation loss: 2.0545935861526

Epoch: 5| Step: 1
Training loss: 1.5336602926254272
Validation loss: 1.9977883677328787

Epoch: 5| Step: 2
Training loss: 1.235446572303772
Validation loss: 2.0639448652985277

Epoch: 5| Step: 3
Training loss: 1.9072790145874023
Validation loss: 2.0478936164609847

Epoch: 5| Step: 4
Training loss: 1.2803679704666138
Validation loss: 2.0119006197939635

Epoch: 5| Step: 5
Training loss: 1.4696508646011353
Validation loss: 1.9867819163107103

Epoch: 5| Step: 6
Training loss: 1.5417232513427734
Validation loss: 2.021816199825656

Epoch: 5| Step: 7
Training loss: 1.0853443145751953
Validation loss: 2.00601658128923

Epoch: 5| Step: 8
Training loss: 1.781914472579956
Validation loss: 1.9911922741961736

Epoch: 5| Step: 9
Training loss: 1.6823209524154663
Validation loss: 1.969824380772088

Epoch: 5| Step: 10
Training loss: 1.3993514776229858
Validation loss: 1.99625531319649

Epoch: 385| Step: 0
Training loss: 0.7717400789260864
Validation loss: 2.044833824198733

Epoch: 5| Step: 1
Training loss: 1.5305931568145752
Validation loss: 1.9787583479317286

Epoch: 5| Step: 2
Training loss: 1.5621198415756226
Validation loss: 1.9863550380993915

Epoch: 5| Step: 3
Training loss: 1.5183049440383911
Validation loss: 1.9603543153373144

Epoch: 5| Step: 4
Training loss: 1.6022937297821045
Validation loss: 1.9575781809386386

Epoch: 5| Step: 5
Training loss: 1.8767955303192139
Validation loss: 2.004332119418729

Epoch: 5| Step: 6
Training loss: 1.4607652425765991
Validation loss: 1.9395432062046503

Epoch: 5| Step: 7
Training loss: 1.8944288492202759
Validation loss: 1.9978485184331094

Epoch: 5| Step: 8
Training loss: 1.8453848361968994
Validation loss: 1.9782796367522208

Epoch: 5| Step: 9
Training loss: 1.307839035987854
Validation loss: 2.004979310497161

Epoch: 5| Step: 10
Training loss: 0.8852051496505737
Validation loss: 2.029427202798987

Epoch: 386| Step: 0
Training loss: 1.934547781944275
Validation loss: 1.9960112187170214

Epoch: 5| Step: 1
Training loss: 1.3568401336669922
Validation loss: 1.988479842421829

Epoch: 5| Step: 2
Training loss: 1.8235286474227905
Validation loss: 2.012155339282046

Epoch: 5| Step: 3
Training loss: 0.9957953691482544
Validation loss: 1.9701406583991101

Epoch: 5| Step: 4
Training loss: 1.2024672031402588
Validation loss: 1.9953264395395915

Epoch: 5| Step: 5
Training loss: 1.3266671895980835
Validation loss: 1.9904163370850265

Epoch: 5| Step: 6
Training loss: 1.440303087234497
Validation loss: 2.0106186841123845

Epoch: 5| Step: 7
Training loss: 1.7796510457992554
Validation loss: 2.00553455404056

Epoch: 5| Step: 8
Training loss: 1.3403347730636597
Validation loss: 2.008674672854844

Epoch: 5| Step: 9
Training loss: 1.690167784690857
Validation loss: 2.013633742127367

Epoch: 5| Step: 10
Training loss: 1.3132404088974
Validation loss: 1.9938390818975305

Epoch: 387| Step: 0
Training loss: 1.2758452892303467
Validation loss: 1.9779597738737702

Epoch: 5| Step: 1
Training loss: 1.0185071229934692
Validation loss: 2.0254191608839136

Epoch: 5| Step: 2
Training loss: 1.578800916671753
Validation loss: 2.0699982937946113

Epoch: 5| Step: 3
Training loss: 2.046994924545288
Validation loss: 2.015483572918882

Epoch: 5| Step: 4
Training loss: 1.6896371841430664
Validation loss: 2.078025899907594

Epoch: 5| Step: 5
Training loss: 1.703113317489624
Validation loss: 2.0033494310994304

Epoch: 5| Step: 6
Training loss: 1.5815964937210083
Validation loss: 1.9930880351733136

Epoch: 5| Step: 7
Training loss: 1.6616649627685547
Validation loss: 2.053344172816123

Epoch: 5| Step: 8
Training loss: 1.0659797191619873
Validation loss: 1.9849048942647955

Epoch: 5| Step: 9
Training loss: 1.1280267238616943
Validation loss: 2.033683588427882

Epoch: 5| Step: 10
Training loss: 1.4519360065460205
Validation loss: 1.9660541319078015

Epoch: 388| Step: 0
Training loss: 1.5289950370788574
Validation loss: 2.028511865164644

Epoch: 5| Step: 1
Training loss: 1.3791594505310059
Validation loss: 2.0145354463208105

Epoch: 5| Step: 2
Training loss: 1.4141560792922974
Validation loss: 2.005600595986971

Epoch: 5| Step: 3
Training loss: 1.8824249505996704
Validation loss: 2.000337991663205

Epoch: 5| Step: 4
Training loss: 1.6599737405776978
Validation loss: 2.018943053419872

Epoch: 5| Step: 5
Training loss: 1.4065107107162476
Validation loss: 1.9925085152349165

Epoch: 5| Step: 6
Training loss: 1.2719405889511108
Validation loss: 2.034649841247066

Epoch: 5| Step: 7
Training loss: 1.1312648057937622
Validation loss: 1.9867675714595343

Epoch: 5| Step: 8
Training loss: 1.6315476894378662
Validation loss: 2.0122397856045793

Epoch: 5| Step: 9
Training loss: 1.1590718030929565
Validation loss: 1.9372294628491966

Epoch: 5| Step: 10
Training loss: 1.416513204574585
Validation loss: 1.9795426758386756

Epoch: 389| Step: 0
Training loss: 1.8420584201812744
Validation loss: 1.943120014282965

Epoch: 5| Step: 1
Training loss: 1.5916318893432617
Validation loss: 2.0211807771395613

Epoch: 5| Step: 2
Training loss: 1.318922758102417
Validation loss: 2.0019651010472286

Epoch: 5| Step: 3
Training loss: 1.5562422275543213
Validation loss: 1.9693480871056999

Epoch: 5| Step: 4
Training loss: 1.2040153741836548
Validation loss: 1.992716694390902

Epoch: 5| Step: 5
Training loss: 2.0192253589630127
Validation loss: 2.033736523761544

Epoch: 5| Step: 6
Training loss: 1.4257543087005615
Validation loss: 1.9924318277707664

Epoch: 5| Step: 7
Training loss: 1.0931968688964844
Validation loss: 2.0028203097722863

Epoch: 5| Step: 8
Training loss: 1.593234658241272
Validation loss: 2.0341967562193513

Epoch: 5| Step: 9
Training loss: 1.4212570190429688
Validation loss: 2.022907535235087

Epoch: 5| Step: 10
Training loss: 1.0898569822311401
Validation loss: 1.985426921998301

Epoch: 390| Step: 0
Training loss: 1.6931183338165283
Validation loss: 2.0218817828803934

Epoch: 5| Step: 1
Training loss: 1.612921953201294
Validation loss: 2.0425060308107765

Epoch: 5| Step: 2
Training loss: 2.378678798675537
Validation loss: 2.01916052064588

Epoch: 5| Step: 3
Training loss: 1.3805325031280518
Validation loss: 2.052628247968612

Epoch: 5| Step: 4
Training loss: 1.5288913249969482
Validation loss: 2.0434991980111725

Epoch: 5| Step: 5
Training loss: 1.1467199325561523
Validation loss: 2.036588235567975

Epoch: 5| Step: 6
Training loss: 1.1567511558532715
Validation loss: 2.019589021641721

Epoch: 5| Step: 7
Training loss: 0.951053261756897
Validation loss: 1.9847709722416376

Epoch: 5| Step: 8
Training loss: 1.7598364353179932
Validation loss: 1.9998139181444723

Epoch: 5| Step: 9
Training loss: 1.4383172988891602
Validation loss: 2.029190663368471

Epoch: 5| Step: 10
Training loss: 1.1236437559127808
Validation loss: 2.045865588290717

Epoch: 391| Step: 0
Training loss: 1.715386986732483
Validation loss: 1.9822974794654435

Epoch: 5| Step: 1
Training loss: 1.4745160341262817
Validation loss: 2.02463617632466

Epoch: 5| Step: 2
Training loss: 1.7269392013549805
Validation loss: 1.9811372308320896

Epoch: 5| Step: 3
Training loss: 1.794000267982483
Validation loss: 1.9915061496919202

Epoch: 5| Step: 4
Training loss: 1.0956647396087646
Validation loss: 2.006024545238864

Epoch: 5| Step: 5
Training loss: 1.743753433227539
Validation loss: 2.000403801600138

Epoch: 5| Step: 6
Training loss: 1.1110622882843018
Validation loss: 1.9758962585080055

Epoch: 5| Step: 7
Training loss: 1.7551714181900024
Validation loss: 1.9805214071786532

Epoch: 5| Step: 8
Training loss: 1.649911642074585
Validation loss: 2.0078206036680486

Epoch: 5| Step: 9
Training loss: 0.6966276168823242
Validation loss: 1.9658513979245258

Epoch: 5| Step: 10
Training loss: 1.4258453845977783
Validation loss: 2.007284679720479

Epoch: 392| Step: 0
Training loss: 1.5214588642120361
Validation loss: 1.9941504975800872

Epoch: 5| Step: 1
Training loss: 1.1963486671447754
Validation loss: 2.0232432580763295

Epoch: 5| Step: 2
Training loss: 1.7074024677276611
Validation loss: 2.0270713503642748

Epoch: 5| Step: 3
Training loss: 1.892486572265625
Validation loss: 2.0002964158211984

Epoch: 5| Step: 4
Training loss: 1.2847583293914795
Validation loss: 2.0094791150862172

Epoch: 5| Step: 5
Training loss: 1.0334880352020264
Validation loss: 2.007356113003146

Epoch: 5| Step: 6
Training loss: 1.6758720874786377
Validation loss: 1.9912476847248692

Epoch: 5| Step: 7
Training loss: 0.9150896072387695
Validation loss: 2.0066987647805163

Epoch: 5| Step: 8
Training loss: 1.738699197769165
Validation loss: 2.027689015993508

Epoch: 5| Step: 9
Training loss: 1.5922483205795288
Validation loss: 2.0423194554544266

Epoch: 5| Step: 10
Training loss: 1.609117031097412
Validation loss: 2.010190402307818

Epoch: 393| Step: 0
Training loss: 1.2226505279541016
Validation loss: 2.030289003925939

Epoch: 5| Step: 1
Training loss: 1.1736328601837158
Validation loss: 2.0094498729193084

Epoch: 5| Step: 2
Training loss: 2.2717301845550537
Validation loss: 1.969444182611281

Epoch: 5| Step: 3
Training loss: 1.7539325952529907
Validation loss: 2.0594189897660287

Epoch: 5| Step: 4
Training loss: 1.4934113025665283
Validation loss: 2.014373935678954

Epoch: 5| Step: 5
Training loss: 0.8628643155097961
Validation loss: 2.038359821483653

Epoch: 5| Step: 6
Training loss: 1.4275565147399902
Validation loss: 2.019230822081207

Epoch: 5| Step: 7
Training loss: 1.4936320781707764
Validation loss: 2.036201828269548

Epoch: 5| Step: 8
Training loss: 1.4984734058380127
Validation loss: 1.97851873085063

Epoch: 5| Step: 9
Training loss: 1.5683075189590454
Validation loss: 1.9957262751876668

Epoch: 5| Step: 10
Training loss: 1.2293022871017456
Validation loss: 2.0109369242063133

Epoch: 394| Step: 0
Training loss: 1.3716349601745605
Validation loss: 2.005812088648478

Epoch: 5| Step: 1
Training loss: 1.44400954246521
Validation loss: 1.9419929878686064

Epoch: 5| Step: 2
Training loss: 1.9474092721939087
Validation loss: 1.9849920490736603

Epoch: 5| Step: 3
Training loss: 2.1411972045898438
Validation loss: 1.9768352687999766

Epoch: 5| Step: 4
Training loss: 1.5259501934051514
Validation loss: 1.9836711293907576

Epoch: 5| Step: 5
Training loss: 1.627584457397461
Validation loss: 1.9504746878018944

Epoch: 5| Step: 6
Training loss: 1.033243179321289
Validation loss: 2.0010940887594737

Epoch: 5| Step: 7
Training loss: 1.165229082107544
Validation loss: 2.0132758758401357

Epoch: 5| Step: 8
Training loss: 0.9210759997367859
Validation loss: 1.9762537043581727

Epoch: 5| Step: 9
Training loss: 1.147930383682251
Validation loss: 2.016579574154269

Epoch: 5| Step: 10
Training loss: 2.2427170276641846
Validation loss: 1.9829106471871818

Epoch: 395| Step: 0
Training loss: 1.7036291360855103
Validation loss: 1.9994214837269118

Epoch: 5| Step: 1
Training loss: 1.9641168117523193
Validation loss: 1.9703756404179398

Epoch: 5| Step: 2
Training loss: 1.9857419729232788
Validation loss: 1.9762711153235486

Epoch: 5| Step: 3
Training loss: 1.163323163986206
Validation loss: 2.014701932989141

Epoch: 5| Step: 4
Training loss: 1.2233271598815918
Validation loss: 2.019282933204405

Epoch: 5| Step: 5
Training loss: 1.3961538076400757
Validation loss: 2.0377548317755423

Epoch: 5| Step: 6
Training loss: 1.4081575870513916
Validation loss: 2.051988838821329

Epoch: 5| Step: 7
Training loss: 1.283043622970581
Validation loss: 2.003101777004939

Epoch: 5| Step: 8
Training loss: 1.3882954120635986
Validation loss: 1.9855196783619542

Epoch: 5| Step: 9
Training loss: 1.168955683708191
Validation loss: 1.9702362142583376

Epoch: 5| Step: 10
Training loss: 1.3187718391418457
Validation loss: 1.9840656198481077

Epoch: 396| Step: 0
Training loss: 1.892584204673767
Validation loss: 2.05287766456604

Epoch: 5| Step: 1
Training loss: 1.1693964004516602
Validation loss: 2.0195682638434955

Epoch: 5| Step: 2
Training loss: 1.2579333782196045
Validation loss: 1.9826733527644989

Epoch: 5| Step: 3
Training loss: 1.3616588115692139
Validation loss: 2.007498921886567

Epoch: 5| Step: 4
Training loss: 2.0591673851013184
Validation loss: 2.021652090934015

Epoch: 5| Step: 5
Training loss: 1.2138841152191162
Validation loss: 2.0095298085161435

Epoch: 5| Step: 6
Training loss: 1.4884860515594482
Validation loss: 1.964341760963522

Epoch: 5| Step: 7
Training loss: 1.4404906034469604
Validation loss: 2.0349044825441096

Epoch: 5| Step: 8
Training loss: 1.050936222076416
Validation loss: 1.971550710739628

Epoch: 5| Step: 9
Training loss: 1.461125373840332
Validation loss: 2.0112483065615416

Epoch: 5| Step: 10
Training loss: 1.687087059020996
Validation loss: 1.9547441223616242

Epoch: 397| Step: 0
Training loss: 1.39582097530365
Validation loss: 1.9914259167127712

Epoch: 5| Step: 1
Training loss: 2.105471134185791
Validation loss: 2.0662800752988426

Epoch: 5| Step: 2
Training loss: 1.3652263879776
Validation loss: 2.0178737537835234

Epoch: 5| Step: 3
Training loss: 1.4020366668701172
Validation loss: 2.0142923978067215

Epoch: 5| Step: 4
Training loss: 1.3185526132583618
Validation loss: 2.034194646343108

Epoch: 5| Step: 5
Training loss: 1.8435968160629272
Validation loss: 2.0078266359144643

Epoch: 5| Step: 6
Training loss: 1.2317039966583252
Validation loss: 2.0205878621788433

Epoch: 5| Step: 7
Training loss: 1.5686718225479126
Validation loss: 2.0167189926229496

Epoch: 5| Step: 8
Training loss: 1.2419686317443848
Validation loss: 1.9782872558921896

Epoch: 5| Step: 9
Training loss: 1.104615569114685
Validation loss: 1.9962255480468913

Epoch: 5| Step: 10
Training loss: 1.4162988662719727
Validation loss: 2.0103968740791403

Epoch: 398| Step: 0
Training loss: 0.9476518630981445
Validation loss: 2.0234770928659747

Epoch: 5| Step: 1
Training loss: 1.0499173402786255
Validation loss: 1.9914910972759288

Epoch: 5| Step: 2
Training loss: 1.1979773044586182
Validation loss: 1.992449006726665

Epoch: 5| Step: 3
Training loss: 1.2556098699569702
Validation loss: 1.9888821032739454

Epoch: 5| Step: 4
Training loss: 1.5700418949127197
Validation loss: 1.9900562865759737

Epoch: 5| Step: 5
Training loss: 1.738081693649292
Validation loss: 2.0111978195046865

Epoch: 5| Step: 6
Training loss: 1.4484755992889404
Validation loss: 2.031308417679161

Epoch: 5| Step: 7
Training loss: 1.9492084980010986
Validation loss: 2.0208061228516283

Epoch: 5| Step: 8
Training loss: 1.1413928270339966
Validation loss: 2.0398891279774327

Epoch: 5| Step: 9
Training loss: 1.9869663715362549
Validation loss: 2.0039958236038045

Epoch: 5| Step: 10
Training loss: 1.9162664413452148
Validation loss: 2.0564532356877483

Epoch: 399| Step: 0
Training loss: 1.2990150451660156
Validation loss: 2.0273010756379817

Epoch: 5| Step: 1
Training loss: 1.6677480936050415
Validation loss: 2.0136117460907146

Epoch: 5| Step: 2
Training loss: 1.5217866897583008
Validation loss: 2.0204494614754953

Epoch: 5| Step: 3
Training loss: 1.1203891038894653
Validation loss: 1.9967707510917418

Epoch: 5| Step: 4
Training loss: 1.1255719661712646
Validation loss: 1.9704998911068003

Epoch: 5| Step: 5
Training loss: 1.2765882015228271
Validation loss: 1.9693637458227014

Epoch: 5| Step: 6
Training loss: 2.031128406524658
Validation loss: 1.9472128729666434

Epoch: 5| Step: 7
Training loss: 1.6801116466522217
Validation loss: 2.0351592302322388

Epoch: 5| Step: 8
Training loss: 1.2758722305297852
Validation loss: 2.036271209357887

Epoch: 5| Step: 9
Training loss: 1.6004174947738647
Validation loss: 1.9918954474951631

Epoch: 5| Step: 10
Training loss: 1.3170700073242188
Validation loss: 1.9943704271829257

Epoch: 400| Step: 0
Training loss: 1.5899697542190552
Validation loss: 1.9856035888835948

Epoch: 5| Step: 1
Training loss: 1.5958764553070068
Validation loss: 2.0149882557571575

Epoch: 5| Step: 2
Training loss: 1.541410207748413
Validation loss: 2.022284858970232

Epoch: 5| Step: 3
Training loss: 1.0885045528411865
Validation loss: 1.9992067070417507

Epoch: 5| Step: 4
Training loss: 1.8446862697601318
Validation loss: 1.9945108429078133

Epoch: 5| Step: 5
Training loss: 1.049014687538147
Validation loss: 2.017216588861199

Epoch: 5| Step: 6
Training loss: 1.828031301498413
Validation loss: 1.972253159810138

Epoch: 5| Step: 7
Training loss: 1.2586328983306885
Validation loss: 1.9542022033404278

Epoch: 5| Step: 8
Training loss: 1.5456684827804565
Validation loss: 2.000640812740531

Epoch: 5| Step: 9
Training loss: 1.3716384172439575
Validation loss: 1.9714293146646151

Epoch: 5| Step: 10
Training loss: 1.4034206867218018
Validation loss: 2.0074803777920303

Epoch: 401| Step: 0
Training loss: 1.177114725112915
Validation loss: 1.984226026842671

Epoch: 5| Step: 1
Training loss: 1.476237416267395
Validation loss: 1.990123684688281

Epoch: 5| Step: 2
Training loss: 1.484233021736145
Validation loss: 2.0227781162467053

Epoch: 5| Step: 3
Training loss: 1.8569189310073853
Validation loss: 2.0121686330405613

Epoch: 5| Step: 4
Training loss: 1.0933820009231567
Validation loss: 2.047141532744131

Epoch: 5| Step: 5
Training loss: 1.7506444454193115
Validation loss: 2.0413046985544185

Epoch: 5| Step: 6
Training loss: 1.3949276208877563
Validation loss: 2.0379643568428616

Epoch: 5| Step: 7
Training loss: 1.0992801189422607
Validation loss: 2.0424001011797177

Epoch: 5| Step: 8
Training loss: 1.7647720575332642
Validation loss: 1.9928831079954743

Epoch: 5| Step: 9
Training loss: 1.788423776626587
Validation loss: 2.0002013419264104

Epoch: 5| Step: 10
Training loss: 1.1852971315383911
Validation loss: 2.0199563810902257

Epoch: 402| Step: 0
Training loss: 1.400730848312378
Validation loss: 2.0144427284117667

Epoch: 5| Step: 1
Training loss: 1.242574691772461
Validation loss: 2.0259623681345293

Epoch: 5| Step: 2
Training loss: 1.468876600265503
Validation loss: 1.9929465119556715

Epoch: 5| Step: 3
Training loss: 1.8855164051055908
Validation loss: 2.0210792018521215

Epoch: 5| Step: 4
Training loss: 1.3984317779541016
Validation loss: 2.0003001395092217

Epoch: 5| Step: 5
Training loss: 1.0992350578308105
Validation loss: 1.985674794002246

Epoch: 5| Step: 6
Training loss: 2.0000693798065186
Validation loss: 2.0092339592595256

Epoch: 5| Step: 7
Training loss: 1.2783458232879639
Validation loss: 2.0114597453865954

Epoch: 5| Step: 8
Training loss: 0.8037411570549011
Validation loss: 2.0332444893416537

Epoch: 5| Step: 9
Training loss: 1.9416582584381104
Validation loss: 2.0509110676345004

Epoch: 5| Step: 10
Training loss: 1.610809564590454
Validation loss: 2.0341398972336964

Epoch: 403| Step: 0
Training loss: 1.105648159980774
Validation loss: 1.9984979642334806

Epoch: 5| Step: 1
Training loss: 1.8996260166168213
Validation loss: 2.0264501366564023

Epoch: 5| Step: 2
Training loss: 1.330216407775879
Validation loss: 2.0327737997936945

Epoch: 5| Step: 3
Training loss: 1.2995015382766724
Validation loss: 1.9951141239494405

Epoch: 5| Step: 4
Training loss: 2.0774810314178467
Validation loss: 2.024343411127726

Epoch: 5| Step: 5
Training loss: 1.1270071268081665
Validation loss: 2.0157094950317056

Epoch: 5| Step: 6
Training loss: 0.813052773475647
Validation loss: 1.9978758199240572

Epoch: 5| Step: 7
Training loss: 1.679722547531128
Validation loss: 2.0176640710523053

Epoch: 5| Step: 8
Training loss: 1.883811354637146
Validation loss: 2.021183841971941

Epoch: 5| Step: 9
Training loss: 1.3369255065917969
Validation loss: 1.9767845010244718

Epoch: 5| Step: 10
Training loss: 1.1298754215240479
Validation loss: 1.9995526818818943

Epoch: 404| Step: 0
Training loss: 0.9676958918571472
Validation loss: 2.0071982376037107

Epoch: 5| Step: 1
Training loss: 1.350234031677246
Validation loss: 2.0145985413623113

Epoch: 5| Step: 2
Training loss: 1.8371398448944092
Validation loss: 2.003061371464883

Epoch: 5| Step: 3
Training loss: 1.1461104154586792
Validation loss: 2.0335953517626693

Epoch: 5| Step: 4
Training loss: 1.4678027629852295
Validation loss: 2.0044624984905286

Epoch: 5| Step: 5
Training loss: 1.1926870346069336
Validation loss: 2.0012614457837996

Epoch: 5| Step: 6
Training loss: 1.5206491947174072
Validation loss: 2.012887208692489

Epoch: 5| Step: 7
Training loss: 1.3714444637298584
Validation loss: 2.0060190129023727

Epoch: 5| Step: 8
Training loss: 1.504089593887329
Validation loss: 1.9894887490939068

Epoch: 5| Step: 9
Training loss: 1.4585001468658447
Validation loss: 1.9990956129566315

Epoch: 5| Step: 10
Training loss: 1.9554582834243774
Validation loss: 2.0194123688564507

Epoch: 405| Step: 0
Training loss: 1.2961801290512085
Validation loss: 1.9704165151042323

Epoch: 5| Step: 1
Training loss: 1.6201235055923462
Validation loss: 2.018017194604361

Epoch: 5| Step: 2
Training loss: 1.4237929582595825
Validation loss: 2.025175097168133

Epoch: 5| Step: 3
Training loss: 1.3623464107513428
Validation loss: 1.9862129560080908

Epoch: 5| Step: 4
Training loss: 1.2523645162582397
Validation loss: 1.966872292180215

Epoch: 5| Step: 5
Training loss: 1.8683547973632812
Validation loss: 2.0358718082469

Epoch: 5| Step: 6
Training loss: 1.5399696826934814
Validation loss: 1.999058259430752

Epoch: 5| Step: 7
Training loss: 1.3321380615234375
Validation loss: 2.0049180433314335

Epoch: 5| Step: 8
Training loss: 1.3604176044464111
Validation loss: 1.9922819663119573

Epoch: 5| Step: 9
Training loss: 1.1789348125457764
Validation loss: 1.9919615099506993

Epoch: 5| Step: 10
Training loss: 1.691237449645996
Validation loss: 1.9866021025565364

Epoch: 406| Step: 0
Training loss: 1.3915700912475586
Validation loss: 2.049293610357469

Epoch: 5| Step: 1
Training loss: 1.3908114433288574
Validation loss: 1.9950080289635608

Epoch: 5| Step: 2
Training loss: 2.0588202476501465
Validation loss: 2.0208917381942912

Epoch: 5| Step: 3
Training loss: 1.1108530759811401
Validation loss: 2.0097229352561374

Epoch: 5| Step: 4
Training loss: 2.0510096549987793
Validation loss: 2.0026259063392557

Epoch: 5| Step: 5
Training loss: 2.026369571685791
Validation loss: 1.9442535190172092

Epoch: 5| Step: 6
Training loss: 0.8221893310546875
Validation loss: 1.9539406530318721

Epoch: 5| Step: 7
Training loss: 1.1347070932388306
Validation loss: 2.0141064889969362

Epoch: 5| Step: 8
Training loss: 1.6661545038223267
Validation loss: 1.9762724740530855

Epoch: 5| Step: 9
Training loss: 1.3374558687210083
Validation loss: 1.9857141561405633

Epoch: 5| Step: 10
Training loss: 0.9517843723297119
Validation loss: 1.9865557762884325

Epoch: 407| Step: 0
Training loss: 1.1725443601608276
Validation loss: 1.990050354311543

Epoch: 5| Step: 1
Training loss: 1.4372072219848633
Validation loss: 1.9726363279486214

Epoch: 5| Step: 2
Training loss: 1.56699538230896
Validation loss: 1.9958016872406006

Epoch: 5| Step: 3
Training loss: 1.3091386556625366
Validation loss: 1.9708161969338693

Epoch: 5| Step: 4
Training loss: 1.4024488925933838
Validation loss: 1.986221098130749

Epoch: 5| Step: 5
Training loss: 1.728112816810608
Validation loss: 2.015211861620667

Epoch: 5| Step: 6
Training loss: 1.4248950481414795
Validation loss: 1.9804414908091228

Epoch: 5| Step: 7
Training loss: 1.40570867061615
Validation loss: 1.9985771679109143

Epoch: 5| Step: 8
Training loss: 0.8811705708503723
Validation loss: 2.036774842969833

Epoch: 5| Step: 9
Training loss: 1.513542652130127
Validation loss: 2.0402910786290325

Epoch: 5| Step: 10
Training loss: 2.2315685749053955
Validation loss: 2.046184212930741

Epoch: 408| Step: 0
Training loss: 1.7165333032608032
Validation loss: 1.9690750645053001

Epoch: 5| Step: 1
Training loss: 1.6737091541290283
Validation loss: 2.017402983480884

Epoch: 5| Step: 2
Training loss: 0.9019507169723511
Validation loss: 2.004305947211481

Epoch: 5| Step: 3
Training loss: 1.2090470790863037
Validation loss: 1.973822065578994

Epoch: 5| Step: 4
Training loss: 1.2582805156707764
Validation loss: 1.9859435058409167

Epoch: 5| Step: 5
Training loss: 1.4426720142364502
Validation loss: 1.9836496691549979

Epoch: 5| Step: 6
Training loss: 1.2702757120132446
Validation loss: 1.9831273683937647

Epoch: 5| Step: 7
Training loss: 1.23415207862854
Validation loss: 2.006996226567094

Epoch: 5| Step: 8
Training loss: 1.5794527530670166
Validation loss: 1.969887512986378

Epoch: 5| Step: 9
Training loss: 1.5837161540985107
Validation loss: 1.958059089158171

Epoch: 5| Step: 10
Training loss: 2.0936660766601562
Validation loss: 1.9411850129404375

Epoch: 409| Step: 0
Training loss: 1.5857264995574951
Validation loss: 2.002163787041941

Epoch: 5| Step: 1
Training loss: 1.4283002614974976
Validation loss: 1.9887274715208239

Epoch: 5| Step: 2
Training loss: 1.2349731922149658
Validation loss: 1.9378089020329137

Epoch: 5| Step: 3
Training loss: 2.0924174785614014
Validation loss: 2.0169358048387753

Epoch: 5| Step: 4
Training loss: 1.5897562503814697
Validation loss: 1.999642466986051

Epoch: 5| Step: 5
Training loss: 1.2761034965515137
Validation loss: 2.010032751226938

Epoch: 5| Step: 6
Training loss: 1.0000542402267456
Validation loss: 2.023696932741391

Epoch: 5| Step: 7
Training loss: 1.5493991374969482
Validation loss: 2.0104322330926054

Epoch: 5| Step: 8
Training loss: 1.5559914112091064
Validation loss: 2.004454549922738

Epoch: 5| Step: 9
Training loss: 1.5087041854858398
Validation loss: 1.979239841943146

Epoch: 5| Step: 10
Training loss: 1.1469956636428833
Validation loss: 1.9896086415936869

Epoch: 410| Step: 0
Training loss: 1.781511664390564
Validation loss: 1.9795201158010831

Epoch: 5| Step: 1
Training loss: 1.1977488994598389
Validation loss: 2.0878143900184223

Epoch: 5| Step: 2
Training loss: 1.9316803216934204
Validation loss: 1.9943168701664094

Epoch: 5| Step: 3
Training loss: 1.4897960424423218
Validation loss: 2.0214277826329714

Epoch: 5| Step: 4
Training loss: 0.9880795478820801
Validation loss: 2.034996009642078

Epoch: 5| Step: 5
Training loss: 0.9819339513778687
Validation loss: 2.010406131385475

Epoch: 5| Step: 6
Training loss: 1.3403528928756714
Validation loss: 2.042320247619383

Epoch: 5| Step: 7
Training loss: 1.8920692205429077
Validation loss: 2.0032036868474816

Epoch: 5| Step: 8
Training loss: 1.1239407062530518
Validation loss: 2.0401282900123188

Epoch: 5| Step: 9
Training loss: 1.3543617725372314
Validation loss: 2.021184277790849

Epoch: 5| Step: 10
Training loss: 1.6172690391540527
Validation loss: 1.9866040714325444

Epoch: 411| Step: 0
Training loss: 1.2810696363449097
Validation loss: 1.9774578232919016

Epoch: 5| Step: 1
Training loss: 1.2737483978271484
Validation loss: 2.0244581173825007

Epoch: 5| Step: 2
Training loss: 1.6443350315093994
Validation loss: 1.9999027611106954

Epoch: 5| Step: 3
Training loss: 1.4083812236785889
Validation loss: 1.976097358170376

Epoch: 5| Step: 4
Training loss: 1.748496651649475
Validation loss: 1.960734446843465

Epoch: 5| Step: 5
Training loss: 0.9878771901130676
Validation loss: 1.9658805452367312

Epoch: 5| Step: 6
Training loss: 1.5031757354736328
Validation loss: 1.9773711824929843

Epoch: 5| Step: 7
Training loss: 1.2910088300704956
Validation loss: 1.9856275589235368

Epoch: 5| Step: 8
Training loss: 1.008547306060791
Validation loss: 1.987727512595474

Epoch: 5| Step: 9
Training loss: 1.4929426908493042
Validation loss: 1.9916462282980643

Epoch: 5| Step: 10
Training loss: 2.152872085571289
Validation loss: 2.0104068286957277

Epoch: 412| Step: 0
Training loss: 1.7404342889785767
Validation loss: 1.975336883657722

Epoch: 5| Step: 1
Training loss: 1.196035623550415
Validation loss: 1.9932857918482956

Epoch: 5| Step: 2
Training loss: 1.1131799221038818
Validation loss: 1.9741136745740009

Epoch: 5| Step: 3
Training loss: 1.723760962486267
Validation loss: 1.986314856877891

Epoch: 5| Step: 4
Training loss: 1.2129356861114502
Validation loss: 1.9990661374984249

Epoch: 5| Step: 5
Training loss: 1.157670021057129
Validation loss: 1.9667386137029177

Epoch: 5| Step: 6
Training loss: 1.7397702932357788
Validation loss: 1.9570633839535456

Epoch: 5| Step: 7
Training loss: 2.019874095916748
Validation loss: 1.9758177777772308

Epoch: 5| Step: 8
Training loss: 1.2918237447738647
Validation loss: 1.9622876618498115

Epoch: 5| Step: 9
Training loss: 1.2833597660064697
Validation loss: 1.919220321921892

Epoch: 5| Step: 10
Training loss: 1.3621004819869995
Validation loss: 2.0391628370490125

Epoch: 413| Step: 0
Training loss: 1.1549098491668701
Validation loss: 2.00252507322578

Epoch: 5| Step: 1
Training loss: 1.8356879949569702
Validation loss: 2.027897939887098

Epoch: 5| Step: 2
Training loss: 1.428924322128296
Validation loss: 2.0169502124991467

Epoch: 5| Step: 3
Training loss: 1.204195499420166
Validation loss: 1.9837226329311248

Epoch: 5| Step: 4
Training loss: 1.8018162250518799
Validation loss: 2.0431078531408824

Epoch: 5| Step: 5
Training loss: 1.1806156635284424
Validation loss: 2.038446557137274

Epoch: 5| Step: 6
Training loss: 1.0687973499298096
Validation loss: 2.03680597325807

Epoch: 5| Step: 7
Training loss: 0.8764845132827759
Validation loss: 2.011242115369407

Epoch: 5| Step: 8
Training loss: 1.7655317783355713
Validation loss: 2.0019393249224593

Epoch: 5| Step: 9
Training loss: 1.6412299871444702
Validation loss: 2.009551412315779

Epoch: 5| Step: 10
Training loss: 1.8517590761184692
Validation loss: 1.9784874928894864

Epoch: 414| Step: 0
Training loss: 0.8716452717781067
Validation loss: 1.9741230228895783

Epoch: 5| Step: 1
Training loss: 2.078526020050049
Validation loss: 1.95465975423013

Epoch: 5| Step: 2
Training loss: 1.211917519569397
Validation loss: 1.9974625802809192

Epoch: 5| Step: 3
Training loss: 1.3041584491729736
Validation loss: 2.0346279400651173

Epoch: 5| Step: 4
Training loss: 1.3028497695922852
Validation loss: 1.9821858662430958

Epoch: 5| Step: 5
Training loss: 1.8037351369857788
Validation loss: 2.004502888648741

Epoch: 5| Step: 6
Training loss: 1.9793879985809326
Validation loss: 1.9892425780655236

Epoch: 5| Step: 7
Training loss: 1.4385652542114258
Validation loss: 1.9789252204279746

Epoch: 5| Step: 8
Training loss: 1.3601022958755493
Validation loss: 1.9945784794386996

Epoch: 5| Step: 9
Training loss: 1.4915105104446411
Validation loss: 2.0115465630767164

Epoch: 5| Step: 10
Training loss: 1.1922916173934937
Validation loss: 1.9788393589758104

Epoch: 415| Step: 0
Training loss: 1.3460323810577393
Validation loss: 1.9985368559437413

Epoch: 5| Step: 1
Training loss: 1.488695740699768
Validation loss: 2.0509426862962785

Epoch: 5| Step: 2
Training loss: 1.6020675897598267
Validation loss: 2.0284326230326006

Epoch: 5| Step: 3
Training loss: 1.3555549383163452
Validation loss: 2.0322767508927213

Epoch: 5| Step: 4
Training loss: 1.3639633655548096
Validation loss: 2.002756039301554

Epoch: 5| Step: 5
Training loss: 0.7668861150741577
Validation loss: 1.9995631671720935

Epoch: 5| Step: 6
Training loss: 1.8130865097045898
Validation loss: 2.0336071137459046

Epoch: 5| Step: 7
Training loss: 1.6430810689926147
Validation loss: 1.9969198755038682

Epoch: 5| Step: 8
Training loss: 1.4795382022857666
Validation loss: 1.98287635080276

Epoch: 5| Step: 9
Training loss: 1.4137060642242432
Validation loss: 2.012106062263571

Epoch: 5| Step: 10
Training loss: 1.5378581285476685
Validation loss: 2.0288706466715825

Epoch: 416| Step: 0
Training loss: 1.2646052837371826
Validation loss: 2.010088118173743

Epoch: 5| Step: 1
Training loss: 1.3055999279022217
Validation loss: 1.971954652058181

Epoch: 5| Step: 2
Training loss: 0.8981240391731262
Validation loss: 2.0214338892249653

Epoch: 5| Step: 3
Training loss: 1.317203402519226
Validation loss: 1.9742563770663353

Epoch: 5| Step: 4
Training loss: 1.9631019830703735
Validation loss: 1.9810210017747776

Epoch: 5| Step: 5
Training loss: 1.264905333518982
Validation loss: 1.9860219186352146

Epoch: 5| Step: 6
Training loss: 1.7436269521713257
Validation loss: 1.9789605166322441

Epoch: 5| Step: 7
Training loss: 1.4374778270721436
Validation loss: 2.012137548897856

Epoch: 5| Step: 8
Training loss: 1.6374189853668213
Validation loss: 1.9844525475655832

Epoch: 5| Step: 9
Training loss: 1.5800895690917969
Validation loss: 2.023049792935771

Epoch: 5| Step: 10
Training loss: 1.3214224576950073
Validation loss: 2.0323673935346704

Epoch: 417| Step: 0
Training loss: 1.599790096282959
Validation loss: 2.0314403092989357

Epoch: 5| Step: 1
Training loss: 1.3075692653656006
Validation loss: 1.9990215442513908

Epoch: 5| Step: 2
Training loss: 1.5135509967803955
Validation loss: 2.0027942913834766

Epoch: 5| Step: 3
Training loss: 1.0411725044250488
Validation loss: 2.000143479275447

Epoch: 5| Step: 4
Training loss: 0.9381109476089478
Validation loss: 1.9853706616227345

Epoch: 5| Step: 5
Training loss: 1.342925786972046
Validation loss: 1.9676118358489005

Epoch: 5| Step: 6
Training loss: 1.4470045566558838
Validation loss: 1.9749979011474117

Epoch: 5| Step: 7
Training loss: 2.419858455657959
Validation loss: 2.0044647391124437

Epoch: 5| Step: 8
Training loss: 1.5682481527328491
Validation loss: 1.9706710436010872

Epoch: 5| Step: 9
Training loss: 1.1394562721252441
Validation loss: 2.020042129742202

Epoch: 5| Step: 10
Training loss: 1.5599679946899414
Validation loss: 1.9832396520081388

Epoch: 418| Step: 0
Training loss: 1.6005195379257202
Validation loss: 1.985510048045907

Epoch: 5| Step: 1
Training loss: 1.993147611618042
Validation loss: 1.9894021762314664

Epoch: 5| Step: 2
Training loss: 1.475555181503296
Validation loss: 2.0171332884860296

Epoch: 5| Step: 3
Training loss: 1.0511271953582764
Validation loss: 2.0136681372119534

Epoch: 5| Step: 4
Training loss: 1.6309858560562134
Validation loss: 2.0125885599402973

Epoch: 5| Step: 5
Training loss: 0.9622041583061218
Validation loss: 2.0362882139862224

Epoch: 5| Step: 6
Training loss: 1.057673454284668
Validation loss: 1.9723077063919396

Epoch: 5| Step: 7
Training loss: 1.7287051677703857
Validation loss: 1.9898123741149902

Epoch: 5| Step: 8
Training loss: 1.267389178276062
Validation loss: 1.968481468897994

Epoch: 5| Step: 9
Training loss: 1.8128654956817627
Validation loss: 2.007448031056312

Epoch: 5| Step: 10
Training loss: 1.1868985891342163
Validation loss: 2.0129099943304576

Epoch: 419| Step: 0
Training loss: 2.148712635040283
Validation loss: 1.9848306717411164

Epoch: 5| Step: 1
Training loss: 1.2627779245376587
Validation loss: 1.9998753301558956

Epoch: 5| Step: 2
Training loss: 1.2833267450332642
Validation loss: 2.006648088014254

Epoch: 5| Step: 3
Training loss: 1.83168625831604
Validation loss: 1.978500021401272

Epoch: 5| Step: 4
Training loss: 1.17324697971344
Validation loss: 2.011977964831937

Epoch: 5| Step: 5
Training loss: 1.2316769361495972
Validation loss: 1.9964640166169854

Epoch: 5| Step: 6
Training loss: 1.053698182106018
Validation loss: 2.0367905939778974

Epoch: 5| Step: 7
Training loss: 1.9005409479141235
Validation loss: 1.970384318341491

Epoch: 5| Step: 8
Training loss: 1.238764762878418
Validation loss: 2.033090461966812

Epoch: 5| Step: 9
Training loss: 1.3452913761138916
Validation loss: 2.0222005741570586

Epoch: 5| Step: 10
Training loss: 1.4516186714172363
Validation loss: 2.005411322398852

Epoch: 420| Step: 0
Training loss: 0.9619304537773132
Validation loss: 2.061876398260875

Epoch: 5| Step: 1
Training loss: 1.2270177602767944
Validation loss: 2.0013599729025238

Epoch: 5| Step: 2
Training loss: 1.3118503093719482
Validation loss: 2.0541096297643517

Epoch: 5| Step: 3
Training loss: 1.4329396486282349
Validation loss: 2.002795575767435

Epoch: 5| Step: 4
Training loss: 1.4253828525543213
Validation loss: 1.9764001061839442

Epoch: 5| Step: 5
Training loss: 1.6435922384262085
Validation loss: 2.012029665772633

Epoch: 5| Step: 6
Training loss: 1.7554117441177368
Validation loss: 1.9827108511360743

Epoch: 5| Step: 7
Training loss: 1.6132876873016357
Validation loss: 1.9553741614023845

Epoch: 5| Step: 8
Training loss: 1.5341898202896118
Validation loss: 1.9686975991854103

Epoch: 5| Step: 9
Training loss: 1.535859227180481
Validation loss: 1.930362227142498

Epoch: 5| Step: 10
Training loss: 1.261397123336792
Validation loss: 1.9856791009185135

Epoch: 421| Step: 0
Training loss: 1.697077989578247
Validation loss: 2.022089681317729

Epoch: 5| Step: 1
Training loss: 1.980525016784668
Validation loss: 1.9808966395675496

Epoch: 5| Step: 2
Training loss: 0.8204442858695984
Validation loss: 1.9709707383186585

Epoch: 5| Step: 3
Training loss: 2.1045327186584473
Validation loss: 1.956793942759114

Epoch: 5| Step: 4
Training loss: 1.540892481803894
Validation loss: 1.9948055308352235

Epoch: 5| Step: 5
Training loss: 1.5627233982086182
Validation loss: 2.030676664844636

Epoch: 5| Step: 6
Training loss: 0.8326019048690796
Validation loss: 1.9924278656641643

Epoch: 5| Step: 7
Training loss: 1.2298921346664429
Validation loss: 2.0363472636028

Epoch: 5| Step: 8
Training loss: 1.316733956336975
Validation loss: 1.9825344534330471

Epoch: 5| Step: 9
Training loss: 1.1162153482437134
Validation loss: 2.022972047969859

Epoch: 5| Step: 10
Training loss: 1.4674615859985352
Validation loss: 1.9954594130157142

Epoch: 422| Step: 0
Training loss: 1.256181001663208
Validation loss: 2.0513443972474787

Epoch: 5| Step: 1
Training loss: 1.4228460788726807
Validation loss: 1.9902797206755607

Epoch: 5| Step: 2
Training loss: 2.1685187816619873
Validation loss: 2.031199724443497

Epoch: 5| Step: 3
Training loss: 1.1211591958999634
Validation loss: 1.9871245250906995

Epoch: 5| Step: 4
Training loss: 1.709140419960022
Validation loss: 2.0267521053232174

Epoch: 5| Step: 5
Training loss: 1.4126896858215332
Validation loss: 2.0261397618119434

Epoch: 5| Step: 6
Training loss: 1.2147166728973389
Validation loss: 2.0261242223042313

Epoch: 5| Step: 7
Training loss: 1.721783995628357
Validation loss: 1.979530962564612

Epoch: 5| Step: 8
Training loss: 1.167965292930603
Validation loss: 1.9791844493599349

Epoch: 5| Step: 9
Training loss: 1.2613935470581055
Validation loss: 1.9644270917420745

Epoch: 5| Step: 10
Training loss: 1.1250944137573242
Validation loss: 1.9751843688308552

Epoch: 423| Step: 0
Training loss: 1.3880622386932373
Validation loss: 2.0038828337064354

Epoch: 5| Step: 1
Training loss: 1.5029067993164062
Validation loss: 1.9809530153069446

Epoch: 5| Step: 2
Training loss: 1.7143278121948242
Validation loss: 1.9358825529775312

Epoch: 5| Step: 3
Training loss: 1.530500888824463
Validation loss: 2.013237948058754

Epoch: 5| Step: 4
Training loss: 1.468080759048462
Validation loss: 1.9962573641089982

Epoch: 5| Step: 5
Training loss: 1.6011478900909424
Validation loss: 1.9702317919782413

Epoch: 5| Step: 6
Training loss: 1.2839972972869873
Validation loss: 2.008180272194647

Epoch: 5| Step: 7
Training loss: 1.2502678632736206
Validation loss: 1.9883869207033547

Epoch: 5| Step: 8
Training loss: 1.1209228038787842
Validation loss: 1.9929384467422322

Epoch: 5| Step: 9
Training loss: 1.4659627676010132
Validation loss: 1.9635341372541202

Epoch: 5| Step: 10
Training loss: 1.5461872816085815
Validation loss: 2.0087256816125687

Epoch: 424| Step: 0
Training loss: 1.2260911464691162
Validation loss: 1.9906538583899056

Epoch: 5| Step: 1
Training loss: 1.2404370307922363
Validation loss: 1.934921068529929

Epoch: 5| Step: 2
Training loss: 1.3981751203536987
Validation loss: 2.0165299600170505

Epoch: 5| Step: 3
Training loss: 1.7443405389785767
Validation loss: 1.9743209346648185

Epoch: 5| Step: 4
Training loss: 1.638484001159668
Validation loss: 1.990596822513047

Epoch: 5| Step: 5
Training loss: 1.4373655319213867
Validation loss: 1.9964693874441168

Epoch: 5| Step: 6
Training loss: 1.4672540426254272
Validation loss: 1.9792062441507976

Epoch: 5| Step: 7
Training loss: 1.5027650594711304
Validation loss: 1.9613033789460377

Epoch: 5| Step: 8
Training loss: 1.2696551084518433
Validation loss: 1.9414492742989653

Epoch: 5| Step: 9
Training loss: 1.2921823263168335
Validation loss: 2.0215641426783737

Epoch: 5| Step: 10
Training loss: 1.4047383069992065
Validation loss: 1.940947526244707

Epoch: 425| Step: 0
Training loss: 1.4804790019989014
Validation loss: 1.983571111515004

Epoch: 5| Step: 1
Training loss: 1.1813735961914062
Validation loss: 1.9844069532168809

Epoch: 5| Step: 2
Training loss: 1.1875967979431152
Validation loss: 1.9748960797504713

Epoch: 5| Step: 3
Training loss: 1.693495512008667
Validation loss: 2.000395882514215

Epoch: 5| Step: 4
Training loss: 1.3215174674987793
Validation loss: 2.022594118631014

Epoch: 5| Step: 5
Training loss: 1.511940598487854
Validation loss: 1.9970573097146966

Epoch: 5| Step: 6
Training loss: 1.418491005897522
Validation loss: 2.0121958832586966

Epoch: 5| Step: 7
Training loss: 1.4001874923706055
Validation loss: 2.011523787693311

Epoch: 5| Step: 8
Training loss: 1.3344612121582031
Validation loss: 2.051368882579188

Epoch: 5| Step: 9
Training loss: 1.6734638214111328
Validation loss: 2.078616084591035

Epoch: 5| Step: 10
Training loss: 1.5139403343200684
Validation loss: 2.0125091588625343

Epoch: 426| Step: 0
Training loss: 1.4276487827301025
Validation loss: 2.0212163617534022

Epoch: 5| Step: 1
Training loss: 1.2346553802490234
Validation loss: 1.9630612711752615

Epoch: 5| Step: 2
Training loss: 1.6731908321380615
Validation loss: 2.0129397402527514

Epoch: 5| Step: 3
Training loss: 1.3875272274017334
Validation loss: 1.9802193795481036

Epoch: 5| Step: 4
Training loss: 1.2710202932357788
Validation loss: 2.032083924098681

Epoch: 5| Step: 5
Training loss: 1.4957554340362549
Validation loss: 2.030102099141767

Epoch: 5| Step: 6
Training loss: 1.5481764078140259
Validation loss: 2.019974139428908

Epoch: 5| Step: 7
Training loss: 1.5626413822174072
Validation loss: 1.9742053042175949

Epoch: 5| Step: 8
Training loss: 1.457741141319275
Validation loss: 2.0202692939389135

Epoch: 5| Step: 9
Training loss: 1.0232346057891846
Validation loss: 2.00602335955507

Epoch: 5| Step: 10
Training loss: 1.023007869720459
Validation loss: 1.971065080294045

Epoch: 427| Step: 0
Training loss: 1.3390172719955444
Validation loss: 2.0027344816474506

Epoch: 5| Step: 1
Training loss: 1.9703490734100342
Validation loss: 2.005313470799436

Epoch: 5| Step: 2
Training loss: 1.4123594760894775
Validation loss: 2.0083742257087462

Epoch: 5| Step: 3
Training loss: 0.967361330986023
Validation loss: 2.0083913034008396

Epoch: 5| Step: 4
Training loss: 1.8146533966064453
Validation loss: 1.9880489380128923

Epoch: 5| Step: 5
Training loss: 1.1432236433029175
Validation loss: 2.0106264724526355

Epoch: 5| Step: 6
Training loss: 1.3457142114639282
Validation loss: 1.9815652293543662

Epoch: 5| Step: 7
Training loss: 1.5334771871566772
Validation loss: 2.035172490663426

Epoch: 5| Step: 8
Training loss: 0.9600595235824585
Validation loss: 2.037037612289511

Epoch: 5| Step: 9
Training loss: 1.5412399768829346
Validation loss: 2.0050423324749036

Epoch: 5| Step: 10
Training loss: 1.5665470361709595
Validation loss: 1.9942596650892688

Epoch: 428| Step: 0
Training loss: 1.4399278163909912
Validation loss: 1.9753138672920965

Epoch: 5| Step: 1
Training loss: 1.573148488998413
Validation loss: 2.0070641117711223

Epoch: 5| Step: 2
Training loss: 1.0171236991882324
Validation loss: 1.9979306805518366

Epoch: 5| Step: 3
Training loss: 1.1435723304748535
Validation loss: 1.9800388223381453

Epoch: 5| Step: 4
Training loss: 1.9747358560562134
Validation loss: 1.9906334697559316

Epoch: 5| Step: 5
Training loss: 1.4183439016342163
Validation loss: 2.004758568220241

Epoch: 5| Step: 6
Training loss: 1.2017850875854492
Validation loss: 1.976730159533921

Epoch: 5| Step: 7
Training loss: 1.3617279529571533
Validation loss: 2.026898628921919

Epoch: 5| Step: 8
Training loss: 1.2162028551101685
Validation loss: 2.059068856700774

Epoch: 5| Step: 9
Training loss: 1.7091655731201172
Validation loss: 1.952386479223928

Epoch: 5| Step: 10
Training loss: 1.6552163362503052
Validation loss: 2.0117440223693848

Epoch: 429| Step: 0
Training loss: 1.3039867877960205
Validation loss: 1.986968586521764

Epoch: 5| Step: 1
Training loss: 1.59134042263031
Validation loss: 1.937822796965158

Epoch: 5| Step: 2
Training loss: 1.0237451791763306
Validation loss: 1.9684976711068103

Epoch: 5| Step: 3
Training loss: 1.574737548828125
Validation loss: 2.004271709790794

Epoch: 5| Step: 4
Training loss: 0.8558141589164734
Validation loss: 1.9580337911523797

Epoch: 5| Step: 5
Training loss: 1.446782112121582
Validation loss: 2.010918988976427

Epoch: 5| Step: 6
Training loss: 1.5101001262664795
Validation loss: 1.9567149198183449

Epoch: 5| Step: 7
Training loss: 1.3538081645965576
Validation loss: 2.013470181854822

Epoch: 5| Step: 8
Training loss: 1.2316080331802368
Validation loss: 2.038512240173996

Epoch: 5| Step: 9
Training loss: 1.5476229190826416
Validation loss: 1.993331229814919

Epoch: 5| Step: 10
Training loss: 1.8147785663604736
Validation loss: 1.9829121212805472

Epoch: 430| Step: 0
Training loss: 1.4625718593597412
Validation loss: 2.0593117847237536

Epoch: 5| Step: 1
Training loss: 0.9930389523506165
Validation loss: 1.9459855236032957

Epoch: 5| Step: 2
Training loss: 1.5484097003936768
Validation loss: 2.0254183764098794

Epoch: 5| Step: 3
Training loss: 1.0391819477081299
Validation loss: 2.037760421793948

Epoch: 5| Step: 4
Training loss: 1.5905489921569824
Validation loss: 1.9703843721779444

Epoch: 5| Step: 5
Training loss: 1.880788803100586
Validation loss: 2.0006150161066363

Epoch: 5| Step: 6
Training loss: 1.0530297756195068
Validation loss: 1.988810993009998

Epoch: 5| Step: 7
Training loss: 1.505836844444275
Validation loss: 1.982918421427409

Epoch: 5| Step: 8
Training loss: 1.3781148195266724
Validation loss: 1.9770061175028484

Epoch: 5| Step: 9
Training loss: 1.7183237075805664
Validation loss: 1.9708992973450692

Epoch: 5| Step: 10
Training loss: 1.2883868217468262
Validation loss: 1.9669448791011688

Epoch: 431| Step: 0
Training loss: 1.3615138530731201
Validation loss: 1.979643984507489

Epoch: 5| Step: 1
Training loss: 0.8330065608024597
Validation loss: 1.99701855515921

Epoch: 5| Step: 2
Training loss: 1.2783300876617432
Validation loss: 1.985248686164938

Epoch: 5| Step: 3
Training loss: 1.5183818340301514
Validation loss: 1.9813048249931746

Epoch: 5| Step: 4
Training loss: 2.096555709838867
Validation loss: 1.9882985981561805

Epoch: 5| Step: 5
Training loss: 1.5271220207214355
Validation loss: 2.0233349236108924

Epoch: 5| Step: 6
Training loss: 1.4873361587524414
Validation loss: 1.9760866088251914

Epoch: 5| Step: 7
Training loss: 1.2892065048217773
Validation loss: 2.0141644580389864

Epoch: 5| Step: 8
Training loss: 1.6932954788208008
Validation loss: 1.973661861112041

Epoch: 5| Step: 9
Training loss: 1.2518951892852783
Validation loss: 2.0192224171853836

Epoch: 5| Step: 10
Training loss: 1.1236076354980469
Validation loss: 1.9652359216443953

Epoch: 432| Step: 0
Training loss: 1.6347814798355103
Validation loss: 2.041838624144113

Epoch: 5| Step: 1
Training loss: 1.7525259256362915
Validation loss: 2.025957215216852

Epoch: 5| Step: 2
Training loss: 0.9157366752624512
Validation loss: 1.9670152677002775

Epoch: 5| Step: 3
Training loss: 1.7383983135223389
Validation loss: 1.9793590422599547

Epoch: 5| Step: 4
Training loss: 1.731637716293335
Validation loss: 1.94354800767796

Epoch: 5| Step: 5
Training loss: 1.2524645328521729
Validation loss: 1.9533415007334884

Epoch: 5| Step: 6
Training loss: 0.8877272605895996
Validation loss: 2.007505219469788

Epoch: 5| Step: 7
Training loss: 1.6399562358856201
Validation loss: 2.0049566991867556

Epoch: 5| Step: 8
Training loss: 1.2226483821868896
Validation loss: 1.9868799473649712

Epoch: 5| Step: 9
Training loss: 1.6228148937225342
Validation loss: 2.01144931649649

Epoch: 5| Step: 10
Training loss: 1.304847240447998
Validation loss: 2.013823832235029

Epoch: 433| Step: 0
Training loss: 1.546849012374878
Validation loss: 1.9527822156106271

Epoch: 5| Step: 1
Training loss: 1.3213766813278198
Validation loss: 2.008110664224112

Epoch: 5| Step: 2
Training loss: 1.713830590248108
Validation loss: 2.04326137932398

Epoch: 5| Step: 3
Training loss: 1.1852214336395264
Validation loss: 1.9662261368125997

Epoch: 5| Step: 4
Training loss: 1.8275740146636963
Validation loss: 2.008918164878763

Epoch: 5| Step: 5
Training loss: 1.8308296203613281
Validation loss: 2.0030772314276746

Epoch: 5| Step: 6
Training loss: 0.9876478314399719
Validation loss: 2.0190658812881797

Epoch: 5| Step: 7
Training loss: 0.9103606939315796
Validation loss: 1.9919064506407707

Epoch: 5| Step: 8
Training loss: 1.5447368621826172
Validation loss: 1.9785867480821506

Epoch: 5| Step: 9
Training loss: 1.1960856914520264
Validation loss: 1.9907395852509366

Epoch: 5| Step: 10
Training loss: 1.273964524269104
Validation loss: 1.9821378953995243

Epoch: 434| Step: 0
Training loss: 2.1175694465637207
Validation loss: 1.9997763787546465

Epoch: 5| Step: 1
Training loss: 1.4752285480499268
Validation loss: 2.032348603330633

Epoch: 5| Step: 2
Training loss: 0.9361907243728638
Validation loss: 2.040473840569937

Epoch: 5| Step: 3
Training loss: 1.4849227666854858
Validation loss: 2.02414951016826

Epoch: 5| Step: 4
Training loss: 1.5482938289642334
Validation loss: 2.009579966145177

Epoch: 5| Step: 5
Training loss: 1.0997447967529297
Validation loss: 2.054629901404022

Epoch: 5| Step: 6
Training loss: 1.1968291997909546
Validation loss: 1.98242199549111

Epoch: 5| Step: 7
Training loss: 1.5287694931030273
Validation loss: 1.972348887433288

Epoch: 5| Step: 8
Training loss: 1.305189847946167
Validation loss: 1.9922741805353472

Epoch: 5| Step: 9
Training loss: 1.3309484720230103
Validation loss: 2.040528061569378

Epoch: 5| Step: 10
Training loss: 1.313396692276001
Validation loss: 2.009982644870717

Epoch: 435| Step: 0
Training loss: 1.483660340309143
Validation loss: 1.9902588846862956

Epoch: 5| Step: 1
Training loss: 1.6062450408935547
Validation loss: 1.9984106581698182

Epoch: 5| Step: 2
Training loss: 1.711114525794983
Validation loss: 1.9704506576702159

Epoch: 5| Step: 3
Training loss: 1.5347967147827148
Validation loss: 2.0286745845630603

Epoch: 5| Step: 4
Training loss: 0.9639965295791626
Validation loss: 1.9284615388480566

Epoch: 5| Step: 5
Training loss: 1.3563640117645264
Validation loss: 1.992071637543299

Epoch: 5| Step: 6
Training loss: 1.505855917930603
Validation loss: 1.965542721491988

Epoch: 5| Step: 7
Training loss: 1.0098748207092285
Validation loss: 1.9476912431819464

Epoch: 5| Step: 8
Training loss: 1.7202465534210205
Validation loss: 1.9341236558011783

Epoch: 5| Step: 9
Training loss: 1.2408298254013062
Validation loss: 1.995373927136903

Epoch: 5| Step: 10
Training loss: 1.0307244062423706
Validation loss: 1.9746196936535578

Epoch: 436| Step: 0
Training loss: 1.1580663919448853
Validation loss: 1.9752746679449593

Epoch: 5| Step: 1
Training loss: 1.7052072286605835
Validation loss: 1.9481044392431937

Epoch: 5| Step: 2
Training loss: 1.440469741821289
Validation loss: 2.0359129392972557

Epoch: 5| Step: 3
Training loss: 1.2329577207565308
Validation loss: 1.9409363141623877

Epoch: 5| Step: 4
Training loss: 1.3853089809417725
Validation loss: 1.9208103149167952

Epoch: 5| Step: 5
Training loss: 1.2015377283096313
Validation loss: 1.9707748197740125

Epoch: 5| Step: 6
Training loss: 1.7237889766693115
Validation loss: 1.9901869758482902

Epoch: 5| Step: 7
Training loss: 1.1263235807418823
Validation loss: 1.9921371257433327

Epoch: 5| Step: 8
Training loss: 1.4462182521820068
Validation loss: 2.0065919519752584

Epoch: 5| Step: 9
Training loss: 1.6040637493133545
Validation loss: 1.978243984201903

Epoch: 5| Step: 10
Training loss: 1.3058665990829468
Validation loss: 2.0004557114775463

Epoch: 437| Step: 0
Training loss: 2.1196205615997314
Validation loss: 2.0100186870944117

Epoch: 5| Step: 1
Training loss: 1.9648544788360596
Validation loss: 1.9777610366062452

Epoch: 5| Step: 2
Training loss: 0.7493734359741211
Validation loss: 2.008983791515391

Epoch: 5| Step: 3
Training loss: 0.8184949159622192
Validation loss: 1.9802797814851165

Epoch: 5| Step: 4
Training loss: 1.2176477909088135
Validation loss: 2.0059092531922045

Epoch: 5| Step: 5
Training loss: 1.235897421836853
Validation loss: 2.0600408097749114

Epoch: 5| Step: 6
Training loss: 1.6901746988296509
Validation loss: 2.0190519299558414

Epoch: 5| Step: 7
Training loss: 1.5076892375946045
Validation loss: 2.0337396103848695

Epoch: 5| Step: 8
Training loss: 1.2172778844833374
Validation loss: 1.9800131231225946

Epoch: 5| Step: 9
Training loss: 1.449500560760498
Validation loss: 2.022319955210532

Epoch: 5| Step: 10
Training loss: 1.4047640562057495
Validation loss: 2.0006606783918155

Epoch: 438| Step: 0
Training loss: 1.570803165435791
Validation loss: 1.9904971020196074

Epoch: 5| Step: 1
Training loss: 2.0273044109344482
Validation loss: 1.99743265105832

Epoch: 5| Step: 2
Training loss: 1.5111687183380127
Validation loss: 1.9974384948771486

Epoch: 5| Step: 3
Training loss: 0.9206110239028931
Validation loss: 2.008995315080048

Epoch: 5| Step: 4
Training loss: 0.8041342496871948
Validation loss: 1.9555364565182758

Epoch: 5| Step: 5
Training loss: 1.2511087656021118
Validation loss: 2.0104174267861152

Epoch: 5| Step: 6
Training loss: 1.404205560684204
Validation loss: 1.9672262014881257

Epoch: 5| Step: 7
Training loss: 1.3367934226989746
Validation loss: 1.991641600926717

Epoch: 5| Step: 8
Training loss: 1.4411097764968872
Validation loss: 1.9959110624046736

Epoch: 5| Step: 9
Training loss: 1.7181403636932373
Validation loss: 1.996941642094684

Epoch: 5| Step: 10
Training loss: 1.1516203880310059
Validation loss: 2.0238081062993696

Epoch: 439| Step: 0
Training loss: 1.0172760486602783
Validation loss: 2.0147171879327423

Epoch: 5| Step: 1
Training loss: 1.1617553234100342
Validation loss: 2.0076294342676797

Epoch: 5| Step: 2
Training loss: 1.4420627355575562
Validation loss: 1.990927057881509

Epoch: 5| Step: 3
Training loss: 1.5027166604995728
Validation loss: 1.9597306277162285

Epoch: 5| Step: 4
Training loss: 1.5834836959838867
Validation loss: 1.9903780439848542

Epoch: 5| Step: 5
Training loss: 1.4223763942718506
Validation loss: 1.9544861983227473

Epoch: 5| Step: 6
Training loss: 1.311281681060791
Validation loss: 2.007670884491295

Epoch: 5| Step: 7
Training loss: 1.4968655109405518
Validation loss: 1.9899269534695534

Epoch: 5| Step: 8
Training loss: 1.6233516931533813
Validation loss: 2.032444166880782

Epoch: 5| Step: 9
Training loss: 1.4020487070083618
Validation loss: 1.9741487528688164

Epoch: 5| Step: 10
Training loss: 1.2731117010116577
Validation loss: 1.9725789100893083

Epoch: 440| Step: 0
Training loss: 1.2355544567108154
Validation loss: 1.9620090171854982

Epoch: 5| Step: 1
Training loss: 0.8434179425239563
Validation loss: 1.9475962090235885

Epoch: 5| Step: 2
Training loss: 1.7391246557235718
Validation loss: 1.9619026158445625

Epoch: 5| Step: 3
Training loss: 1.6395095586776733
Validation loss: 1.977243754171556

Epoch: 5| Step: 4
Training loss: 1.1636383533477783
Validation loss: 1.9826177153536069

Epoch: 5| Step: 5
Training loss: 1.4878369569778442
Validation loss: 1.9936913867150583

Epoch: 5| Step: 6
Training loss: 1.511278748512268
Validation loss: 1.9874092353287565

Epoch: 5| Step: 7
Training loss: 1.2372387647628784
Validation loss: 1.9579734725336875

Epoch: 5| Step: 8
Training loss: 1.518437385559082
Validation loss: 1.9894391490567116

Epoch: 5| Step: 9
Training loss: 1.3155391216278076
Validation loss: 1.9307458759636007

Epoch: 5| Step: 10
Training loss: 1.691603660583496
Validation loss: 1.934724941048571

Epoch: 441| Step: 0
Training loss: 0.8444925546646118
Validation loss: 1.9841211790679603

Epoch: 5| Step: 1
Training loss: 1.227595567703247
Validation loss: 2.0028177153679634

Epoch: 5| Step: 2
Training loss: 1.2643581628799438
Validation loss: 1.9824886937295236

Epoch: 5| Step: 3
Training loss: 2.032930850982666
Validation loss: 1.9709105158364901

Epoch: 5| Step: 4
Training loss: 1.4774246215820312
Validation loss: 1.9778575128124607

Epoch: 5| Step: 5
Training loss: 1.3361732959747314
Validation loss: 1.9824972357801212

Epoch: 5| Step: 6
Training loss: 1.8473713397979736
Validation loss: 1.9457026232955277

Epoch: 5| Step: 7
Training loss: 1.1380207538604736
Validation loss: 1.9961880189116283

Epoch: 5| Step: 8
Training loss: 1.1227391958236694
Validation loss: 1.9647120814169607

Epoch: 5| Step: 9
Training loss: 1.4320982694625854
Validation loss: 1.9964563487678446

Epoch: 5| Step: 10
Training loss: 1.3712236881256104
Validation loss: 1.9812284079931115

Epoch: 442| Step: 0
Training loss: 1.491538643836975
Validation loss: 1.9520632425944011

Epoch: 5| Step: 1
Training loss: 1.7798084020614624
Validation loss: 1.9680626802547003

Epoch: 5| Step: 2
Training loss: 1.2307586669921875
Validation loss: 2.030923637010718

Epoch: 5| Step: 3
Training loss: 1.5119829177856445
Validation loss: 2.0178066120352796

Epoch: 5| Step: 4
Training loss: 1.4565098285675049
Validation loss: 1.9639189550953526

Epoch: 5| Step: 5
Training loss: 1.5358017683029175
Validation loss: 2.0386672737777873

Epoch: 5| Step: 6
Training loss: 1.3235692977905273
Validation loss: 2.0269640248308898

Epoch: 5| Step: 7
Training loss: 1.1877880096435547
Validation loss: 2.021929112813806

Epoch: 5| Step: 8
Training loss: 1.4198386669158936
Validation loss: 2.003592218122175

Epoch: 5| Step: 9
Training loss: 0.8711401224136353
Validation loss: 1.9995675189520723

Epoch: 5| Step: 10
Training loss: 1.605669379234314
Validation loss: 2.0076696654801727

Epoch: 443| Step: 0
Training loss: 1.152600884437561
Validation loss: 1.9781372521513252

Epoch: 5| Step: 1
Training loss: 1.461258888244629
Validation loss: 1.9956636608287852

Epoch: 5| Step: 2
Training loss: 1.3693420886993408
Validation loss: 2.0215845108032227

Epoch: 5| Step: 3
Training loss: 1.6092453002929688
Validation loss: 1.9644714542614516

Epoch: 5| Step: 4
Training loss: 1.5185657739639282
Validation loss: 1.9939434861624112

Epoch: 5| Step: 5
Training loss: 1.08749258518219
Validation loss: 1.98977751885691

Epoch: 5| Step: 6
Training loss: 1.4901241064071655
Validation loss: 1.9735094885672293

Epoch: 5| Step: 7
Training loss: 1.0081422328948975
Validation loss: 1.9816125874878259

Epoch: 5| Step: 8
Training loss: 1.904104471206665
Validation loss: 1.9820567266915434

Epoch: 5| Step: 9
Training loss: 1.4476947784423828
Validation loss: 1.9947400426351896

Epoch: 5| Step: 10
Training loss: 1.507636547088623
Validation loss: 1.9909149728795534

Epoch: 444| Step: 0
Training loss: 1.480916976928711
Validation loss: 1.9801549424407303

Epoch: 5| Step: 1
Training loss: 1.3184055089950562
Validation loss: 1.9970034809522732

Epoch: 5| Step: 2
Training loss: 1.0234863758087158
Validation loss: 1.9715701277538011

Epoch: 5| Step: 3
Training loss: 1.153043508529663
Validation loss: 1.9643240820976995

Epoch: 5| Step: 4
Training loss: 1.5404112339019775
Validation loss: 1.9929303302559802

Epoch: 5| Step: 5
Training loss: 1.2330071926116943
Validation loss: 2.0086418492819673

Epoch: 5| Step: 6
Training loss: 1.5275304317474365
Validation loss: 1.9998018305788758

Epoch: 5| Step: 7
Training loss: 1.7266218662261963
Validation loss: 1.9691607695753857

Epoch: 5| Step: 8
Training loss: 1.558578610420227
Validation loss: 1.9806428340173536

Epoch: 5| Step: 9
Training loss: 1.3745390176773071
Validation loss: 2.0170237889853855

Epoch: 5| Step: 10
Training loss: 1.3817994594573975
Validation loss: 1.9614681454115017

Epoch: 445| Step: 0
Training loss: 0.9227533340454102
Validation loss: 1.9665135952734178

Epoch: 5| Step: 1
Training loss: 1.0623506307601929
Validation loss: 2.0026252244108464

Epoch: 5| Step: 2
Training loss: 1.3323065042495728
Validation loss: 1.9717227130807855

Epoch: 5| Step: 3
Training loss: 2.0079498291015625
Validation loss: 1.9627323086543749

Epoch: 5| Step: 4
Training loss: 1.3732316493988037
Validation loss: 1.974380709791696

Epoch: 5| Step: 5
Training loss: 1.3917592763900757
Validation loss: 1.9803756847176501

Epoch: 5| Step: 6
Training loss: 1.2257962226867676
Validation loss: 2.0121762047531786

Epoch: 5| Step: 7
Training loss: 1.2131437063217163
Validation loss: 2.000689773149388

Epoch: 5| Step: 8
Training loss: 1.9741398096084595
Validation loss: 2.0138504043702157

Epoch: 5| Step: 9
Training loss: 1.0192173719406128
Validation loss: 1.9904612905235701

Epoch: 5| Step: 10
Training loss: 1.9133119583129883
Validation loss: 2.006919809567031

Epoch: 446| Step: 0
Training loss: 1.1109564304351807
Validation loss: 1.9691691078165525

Epoch: 5| Step: 1
Training loss: 1.5363967418670654
Validation loss: 1.9895347952842712

Epoch: 5| Step: 2
Training loss: 1.4142764806747437
Validation loss: 2.0012659436912945

Epoch: 5| Step: 3
Training loss: 1.9177461862564087
Validation loss: 1.9862219056775492

Epoch: 5| Step: 4
Training loss: 1.3232086896896362
Validation loss: 1.9919984750850226

Epoch: 5| Step: 5
Training loss: 1.3766664266586304
Validation loss: 2.032155800891179

Epoch: 5| Step: 6
Training loss: 1.030788540840149
Validation loss: 1.9629509628459971

Epoch: 5| Step: 7
Training loss: 1.3788734674453735
Validation loss: 1.9979267312634377

Epoch: 5| Step: 8
Training loss: 1.7467639446258545
Validation loss: 2.000039545438623

Epoch: 5| Step: 9
Training loss: 1.070209264755249
Validation loss: 1.9970400397495558

Epoch: 5| Step: 10
Training loss: 1.4039138555526733
Validation loss: 1.9883748536468835

Epoch: 447| Step: 0
Training loss: 1.133034586906433
Validation loss: 2.0189382235209146

Epoch: 5| Step: 1
Training loss: 1.0354788303375244
Validation loss: 2.023609153686031

Epoch: 5| Step: 2
Training loss: 1.7479581832885742
Validation loss: 2.0272945127179547

Epoch: 5| Step: 3
Training loss: 1.6563720703125
Validation loss: 2.0220039941931285

Epoch: 5| Step: 4
Training loss: 1.0834846496582031
Validation loss: 1.9836342001474032

Epoch: 5| Step: 5
Training loss: 1.7284774780273438
Validation loss: 1.9782775896851734

Epoch: 5| Step: 6
Training loss: 1.2456369400024414
Validation loss: 2.0075841539649555

Epoch: 5| Step: 7
Training loss: 1.41202712059021
Validation loss: 2.0087564658093195

Epoch: 5| Step: 8
Training loss: 1.1162703037261963
Validation loss: 1.9627902507781982

Epoch: 5| Step: 9
Training loss: 1.8182048797607422
Validation loss: 1.9746372533100907

Epoch: 5| Step: 10
Training loss: 1.1832265853881836
Validation loss: 2.0099924136233587

Epoch: 448| Step: 0
Training loss: 1.5695369243621826
Validation loss: 1.973834219799247

Epoch: 5| Step: 1
Training loss: 1.139629602432251
Validation loss: 1.9684802768050984

Epoch: 5| Step: 2
Training loss: 1.2978298664093018
Validation loss: 2.0233584629592074

Epoch: 5| Step: 3
Training loss: 1.1603012084960938
Validation loss: 1.978667857826397

Epoch: 5| Step: 4
Training loss: 1.490752100944519
Validation loss: 1.965689830882575

Epoch: 5| Step: 5
Training loss: 1.336617112159729
Validation loss: 1.9974072107704737

Epoch: 5| Step: 6
Training loss: 1.2026950120925903
Validation loss: 1.989160801774712

Epoch: 5| Step: 7
Training loss: 1.4974608421325684
Validation loss: 1.9678153684062343

Epoch: 5| Step: 8
Training loss: 2.129704236984253
Validation loss: 2.011942849364332

Epoch: 5| Step: 9
Training loss: 1.2999389171600342
Validation loss: 1.9919115215219476

Epoch: 5| Step: 10
Training loss: 1.0294872522354126
Validation loss: 2.005525271097819

Epoch: 449| Step: 0
Training loss: 1.894697904586792
Validation loss: 1.9642105307630313

Epoch: 5| Step: 1
Training loss: 1.4807193279266357
Validation loss: 2.0353556307413245

Epoch: 5| Step: 2
Training loss: 1.4640560150146484
Validation loss: 2.0231123252581527

Epoch: 5| Step: 3
Training loss: 1.8020668029785156
Validation loss: 1.9895826757595103

Epoch: 5| Step: 4
Training loss: 1.4576953649520874
Validation loss: 1.992214556663267

Epoch: 5| Step: 5
Training loss: 1.6175537109375
Validation loss: 2.036982177406229

Epoch: 5| Step: 6
Training loss: 0.9361895322799683
Validation loss: 1.984786033630371

Epoch: 5| Step: 7
Training loss: 0.9476312398910522
Validation loss: 1.982200216221553

Epoch: 5| Step: 8
Training loss: 1.1071536540985107
Validation loss: 2.0368583368998703

Epoch: 5| Step: 9
Training loss: 1.1560232639312744
Validation loss: 1.948783996284649

Epoch: 5| Step: 10
Training loss: 1.2850940227508545
Validation loss: 1.9844494506876955

Epoch: 450| Step: 0
Training loss: 1.7308337688446045
Validation loss: 2.0158868066726194

Epoch: 5| Step: 1
Training loss: 1.739231824874878
Validation loss: 1.9882172525569957

Epoch: 5| Step: 2
Training loss: 2.1733930110931396
Validation loss: 1.9980629977359567

Epoch: 5| Step: 3
Training loss: 0.926460862159729
Validation loss: 1.9756864399038336

Epoch: 5| Step: 4
Training loss: 1.2010438442230225
Validation loss: 1.99183738488023

Epoch: 5| Step: 5
Training loss: 1.214929223060608
Validation loss: 1.9724315545892204

Epoch: 5| Step: 6
Training loss: 1.326280951499939
Validation loss: 1.997073652923748

Epoch: 5| Step: 7
Training loss: 1.5607507228851318
Validation loss: 1.965175247961475

Epoch: 5| Step: 8
Training loss: 1.1772518157958984
Validation loss: 2.045768468610702

Epoch: 5| Step: 9
Training loss: 1.0714417695999146
Validation loss: 2.0300138227401243

Epoch: 5| Step: 10
Training loss: 1.2470134496688843
Validation loss: 1.999809750305709

Epoch: 451| Step: 0
Training loss: 1.5666711330413818
Validation loss: 1.9614211820787

Epoch: 5| Step: 1
Training loss: 1.0556527376174927
Validation loss: 2.0149011381210817

Epoch: 5| Step: 2
Training loss: 1.4362446069717407
Validation loss: 1.9417552371178903

Epoch: 5| Step: 3
Training loss: 1.2119667530059814
Validation loss: 1.989854645985429

Epoch: 5| Step: 4
Training loss: 1.8104887008666992
Validation loss: 1.9824134483132312

Epoch: 5| Step: 5
Training loss: 1.1648443937301636
Validation loss: 1.9221775890678487

Epoch: 5| Step: 6
Training loss: 1.6931568384170532
Validation loss: 1.927724697256601

Epoch: 5| Step: 7
Training loss: 0.9954363107681274
Validation loss: 1.949264634040094

Epoch: 5| Step: 8
Training loss: 1.3374577760696411
Validation loss: 1.9635393388809697

Epoch: 5| Step: 9
Training loss: 1.4119479656219482
Validation loss: 1.9481997874475294

Epoch: 5| Step: 10
Training loss: 1.5633562803268433
Validation loss: 1.9878127728739092

Epoch: 452| Step: 0
Training loss: 1.3476734161376953
Validation loss: 1.9835929524513982

Epoch: 5| Step: 1
Training loss: 1.8145389556884766
Validation loss: 1.9564849599715202

Epoch: 5| Step: 2
Training loss: 1.6746711730957031
Validation loss: 1.9835841232730496

Epoch: 5| Step: 3
Training loss: 0.9146890640258789
Validation loss: 1.9537568617892522

Epoch: 5| Step: 4
Training loss: 1.2538005113601685
Validation loss: 2.0043787725510134

Epoch: 5| Step: 5
Training loss: 1.373919129371643
Validation loss: 1.9799891594917542

Epoch: 5| Step: 6
Training loss: 1.2908246517181396
Validation loss: 2.0129866471854587

Epoch: 5| Step: 7
Training loss: 1.7212387323379517
Validation loss: 2.032142537255441

Epoch: 5| Step: 8
Training loss: 1.0829532146453857
Validation loss: 2.0700353550654587

Epoch: 5| Step: 9
Training loss: 1.49130380153656
Validation loss: 2.0165698259107527

Epoch: 5| Step: 10
Training loss: 1.1928285360336304
Validation loss: 2.045737233213199

Epoch: 453| Step: 0
Training loss: 1.408495306968689
Validation loss: 2.0767127852286063

Epoch: 5| Step: 1
Training loss: 1.575953722000122
Validation loss: 2.050737093853694

Epoch: 5| Step: 2
Training loss: 1.1545683145523071
Validation loss: 2.072391745864704

Epoch: 5| Step: 3
Training loss: 1.2023183107376099
Validation loss: 2.0038075831628617

Epoch: 5| Step: 4
Training loss: 0.8892999887466431
Validation loss: 2.010692545162734

Epoch: 5| Step: 5
Training loss: 1.444539189338684
Validation loss: 1.9806158209359774

Epoch: 5| Step: 6
Training loss: 1.6384403705596924
Validation loss: 2.0008488855054303

Epoch: 5| Step: 7
Training loss: 1.5096442699432373
Validation loss: 1.9980466827269523

Epoch: 5| Step: 8
Training loss: 1.2098242044448853
Validation loss: 1.9945336400821645

Epoch: 5| Step: 9
Training loss: 1.7367041110992432
Validation loss: 1.938076198741954

Epoch: 5| Step: 10
Training loss: 1.4132938385009766
Validation loss: 1.9777253981559508

Epoch: 454| Step: 0
Training loss: 1.360833764076233
Validation loss: 1.9845547599177207

Epoch: 5| Step: 1
Training loss: 0.7277463674545288
Validation loss: 2.005573172723093

Epoch: 5| Step: 2
Training loss: 1.2793654203414917
Validation loss: 1.9320538056794034

Epoch: 5| Step: 3
Training loss: 1.35968816280365
Validation loss: 1.9789934786417152

Epoch: 5| Step: 4
Training loss: 1.5571717023849487
Validation loss: 1.9843060431941864

Epoch: 5| Step: 5
Training loss: 1.0539278984069824
Validation loss: 1.959377840001096

Epoch: 5| Step: 6
Training loss: 1.7507693767547607
Validation loss: 1.9575483978435557

Epoch: 5| Step: 7
Training loss: 1.7656663656234741
Validation loss: 2.0290814548410396

Epoch: 5| Step: 8
Training loss: 1.728935956954956
Validation loss: 1.9880058355228876

Epoch: 5| Step: 9
Training loss: 1.5020822286605835
Validation loss: 1.9637646726382676

Epoch: 5| Step: 10
Training loss: 1.0028046369552612
Validation loss: 1.9479268391927083

Epoch: 455| Step: 0
Training loss: 1.0437877178192139
Validation loss: 1.9439037884435346

Epoch: 5| Step: 1
Training loss: 1.6527187824249268
Validation loss: 2.0131230174854235

Epoch: 5| Step: 2
Training loss: 1.3698360919952393
Validation loss: 1.9707534364474717

Epoch: 5| Step: 3
Training loss: 1.593285322189331
Validation loss: 1.9812655013094667

Epoch: 5| Step: 4
Training loss: 1.4600942134857178
Validation loss: 2.0118012120646815

Epoch: 5| Step: 5
Training loss: 1.7201305627822876
Validation loss: 1.9632554490079162

Epoch: 5| Step: 6
Training loss: 1.4247785806655884
Validation loss: 1.9947775179339993

Epoch: 5| Step: 7
Training loss: 0.6593241691589355
Validation loss: 1.9663405405577792

Epoch: 5| Step: 8
Training loss: 1.3206514120101929
Validation loss: 2.0213676165508967

Epoch: 5| Step: 9
Training loss: 1.5159982442855835
Validation loss: 2.0046558610854612

Epoch: 5| Step: 10
Training loss: 1.0949475765228271
Validation loss: 1.952972609509704

Epoch: 456| Step: 0
Training loss: 1.2209398746490479
Validation loss: 1.9834895877427952

Epoch: 5| Step: 1
Training loss: 1.7991163730621338
Validation loss: 1.9805876593435965

Epoch: 5| Step: 2
Training loss: 1.5992131233215332
Validation loss: 1.9406048123554518

Epoch: 5| Step: 3
Training loss: 1.6399810314178467
Validation loss: 1.9820198166754939

Epoch: 5| Step: 4
Training loss: 0.9317631721496582
Validation loss: 1.9665568028726885

Epoch: 5| Step: 5
Training loss: 1.6477463245391846
Validation loss: 1.9835900311828942

Epoch: 5| Step: 6
Training loss: 1.1000168323516846
Validation loss: 1.9292606961342595

Epoch: 5| Step: 7
Training loss: 1.5009760856628418
Validation loss: 2.0346068028480775

Epoch: 5| Step: 8
Training loss: 0.7449530363082886
Validation loss: 1.971853712553619

Epoch: 5| Step: 9
Training loss: 1.426598310470581
Validation loss: 1.9715345636490853

Epoch: 5| Step: 10
Training loss: 1.320798635482788
Validation loss: 1.9787345317102247

Epoch: 457| Step: 0
Training loss: 1.5423197746276855
Validation loss: 2.009214529427149

Epoch: 5| Step: 1
Training loss: 1.2306760549545288
Validation loss: 2.0024920432798323

Epoch: 5| Step: 2
Training loss: 1.4360512495040894
Validation loss: 1.981440685128653

Epoch: 5| Step: 3
Training loss: 1.2768535614013672
Validation loss: 1.974504663098243

Epoch: 5| Step: 4
Training loss: 1.5937691926956177
Validation loss: 1.9868792718456638

Epoch: 5| Step: 5
Training loss: 1.216823935508728
Validation loss: 1.9774426670484646

Epoch: 5| Step: 6
Training loss: 1.7038723230361938
Validation loss: 1.962847791692262

Epoch: 5| Step: 7
Training loss: 0.9246098399162292
Validation loss: 2.0000182146667154

Epoch: 5| Step: 8
Training loss: 1.9048725366592407
Validation loss: 1.9797101559177521

Epoch: 5| Step: 9
Training loss: 1.4480794668197632
Validation loss: 1.952881472085112

Epoch: 5| Step: 10
Training loss: 0.8216143250465393
Validation loss: 1.9608596768430484

Epoch: 458| Step: 0
Training loss: 1.272913932800293
Validation loss: 1.9878066714091966

Epoch: 5| Step: 1
Training loss: 1.1488656997680664
Validation loss: 2.0032939692979217

Epoch: 5| Step: 2
Training loss: 1.1146432161331177
Validation loss: 1.9892140857635006

Epoch: 5| Step: 3
Training loss: 0.8748608827590942
Validation loss: 1.9830993798471266

Epoch: 5| Step: 4
Training loss: 1.3104158639907837
Validation loss: 1.9874991370785622

Epoch: 5| Step: 5
Training loss: 1.6899608373641968
Validation loss: 1.982453546216411

Epoch: 5| Step: 6
Training loss: 1.4257352352142334
Validation loss: 2.003319073748845

Epoch: 5| Step: 7
Training loss: 1.4948636293411255
Validation loss: 1.9872964402680755

Epoch: 5| Step: 8
Training loss: 1.1835665702819824
Validation loss: 1.975334261053352

Epoch: 5| Step: 9
Training loss: 1.3513723611831665
Validation loss: 1.9660016964840632

Epoch: 5| Step: 10
Training loss: 2.050931930541992
Validation loss: 1.98171652132465

Epoch: 459| Step: 0
Training loss: 1.4744267463684082
Validation loss: 1.9667761505291026

Epoch: 5| Step: 1
Training loss: 1.2847175598144531
Validation loss: 1.967554207771055

Epoch: 5| Step: 2
Training loss: 1.0241508483886719
Validation loss: 2.003461507058913

Epoch: 5| Step: 3
Training loss: 1.0577012300491333
Validation loss: 1.9605169321901055

Epoch: 5| Step: 4
Training loss: 1.2070415019989014
Validation loss: 1.9546433687210083

Epoch: 5| Step: 5
Training loss: 1.3229097127914429
Validation loss: 1.9658459437790738

Epoch: 5| Step: 6
Training loss: 1.2937359809875488
Validation loss: 1.9805221788344844

Epoch: 5| Step: 7
Training loss: 1.8775602579116821
Validation loss: 2.0130741006584576

Epoch: 5| Step: 8
Training loss: 1.7408796548843384
Validation loss: 1.9651475696153538

Epoch: 5| Step: 9
Training loss: 1.2349700927734375
Validation loss: 1.973440529197775

Epoch: 5| Step: 10
Training loss: 1.373934030532837
Validation loss: 1.9487322094619914

Epoch: 460| Step: 0
Training loss: 1.5845812559127808
Validation loss: 1.9979826058110883

Epoch: 5| Step: 1
Training loss: 1.39498770236969
Validation loss: 1.9665368167302941

Epoch: 5| Step: 2
Training loss: 1.3995418548583984
Validation loss: 1.9647729909548195

Epoch: 5| Step: 3
Training loss: 1.0571577548980713
Validation loss: 2.0171895847525647

Epoch: 5| Step: 4
Training loss: 1.4487876892089844
Validation loss: 1.949323546501898

Epoch: 5| Step: 5
Training loss: 1.58841073513031
Validation loss: 1.9813782604791785

Epoch: 5| Step: 6
Training loss: 1.03860342502594
Validation loss: 1.9833612736835275

Epoch: 5| Step: 7
Training loss: 1.4152803421020508
Validation loss: 1.9667244213883595

Epoch: 5| Step: 8
Training loss: 1.0861146450042725
Validation loss: 2.009406843493062

Epoch: 5| Step: 9
Training loss: 1.461040735244751
Validation loss: 1.9660250794502996

Epoch: 5| Step: 10
Training loss: 1.259855031967163
Validation loss: 1.9592536944215015

Epoch: 461| Step: 0
Training loss: 1.8330215215682983
Validation loss: 1.9260953921143726

Epoch: 5| Step: 1
Training loss: 1.0856813192367554
Validation loss: 1.976821425140545

Epoch: 5| Step: 2
Training loss: 1.2244937419891357
Validation loss: 1.9992750665192962

Epoch: 5| Step: 3
Training loss: 1.553972601890564
Validation loss: 1.9586194305009739

Epoch: 5| Step: 4
Training loss: 1.2110869884490967
Validation loss: 1.9462614264539493

Epoch: 5| Step: 5
Training loss: 1.3346222639083862
Validation loss: 1.9584472833141204

Epoch: 5| Step: 6
Training loss: 0.9897686243057251
Validation loss: 1.9323092173504572

Epoch: 5| Step: 7
Training loss: 1.1036208868026733
Validation loss: 1.9833316969615158

Epoch: 5| Step: 8
Training loss: 1.3440929651260376
Validation loss: 1.9626697160864388

Epoch: 5| Step: 9
Training loss: 1.5949857234954834
Validation loss: 1.997317160329511

Epoch: 5| Step: 10
Training loss: 1.7279285192489624
Validation loss: 1.953996660888836

Epoch: 462| Step: 0
Training loss: 1.375511884689331
Validation loss: 1.9473289417964157

Epoch: 5| Step: 1
Training loss: 1.3641945123672485
Validation loss: 1.9677044935123895

Epoch: 5| Step: 2
Training loss: 1.4977657794952393
Validation loss: 2.0101531487639233

Epoch: 5| Step: 3
Training loss: 1.2616163492202759
Validation loss: 2.022862390805316

Epoch: 5| Step: 4
Training loss: 0.9330781698226929
Validation loss: 1.9779312149170907

Epoch: 5| Step: 5
Training loss: 1.3004156351089478
Validation loss: 2.0159134531533844

Epoch: 5| Step: 6
Training loss: 1.5165725946426392
Validation loss: 2.0128112531477407

Epoch: 5| Step: 7
Training loss: 1.3271207809448242
Validation loss: 1.9921415493052492

Epoch: 5| Step: 8
Training loss: 1.340527057647705
Validation loss: 1.9829623673551826

Epoch: 5| Step: 9
Training loss: 1.398199200630188
Validation loss: 1.952888342642015

Epoch: 5| Step: 10
Training loss: 1.603934407234192
Validation loss: 1.9860343061467653

Epoch: 463| Step: 0
Training loss: 1.2675676345825195
Validation loss: 1.9664661807398642

Epoch: 5| Step: 1
Training loss: 1.286679983139038
Validation loss: 1.9959560017431937

Epoch: 5| Step: 2
Training loss: 0.8876433372497559
Validation loss: 1.988090815082673

Epoch: 5| Step: 3
Training loss: 1.3844671249389648
Validation loss: 1.9408988721909062

Epoch: 5| Step: 4
Training loss: 1.0224788188934326
Validation loss: 1.9188568720253565

Epoch: 5| Step: 5
Training loss: 1.1793209314346313
Validation loss: 2.0192178000685987

Epoch: 5| Step: 6
Training loss: 0.9365173578262329
Validation loss: 1.996326337578476

Epoch: 5| Step: 7
Training loss: 1.959212064743042
Validation loss: 1.9807174987690424

Epoch: 5| Step: 8
Training loss: 1.1538808345794678
Validation loss: 1.9796299934387207

Epoch: 5| Step: 9
Training loss: 1.7447115182876587
Validation loss: 2.008088896351476

Epoch: 5| Step: 10
Training loss: 1.81135892868042
Validation loss: 1.9940242639151953

Epoch: 464| Step: 0
Training loss: 1.3920644521713257
Validation loss: 1.9904773299412062

Epoch: 5| Step: 1
Training loss: 1.3070039749145508
Validation loss: 1.9962525316464004

Epoch: 5| Step: 2
Training loss: 0.8647270202636719
Validation loss: 1.9991989430560861

Epoch: 5| Step: 3
Training loss: 1.5555765628814697
Validation loss: 2.0330731304742957

Epoch: 5| Step: 4
Training loss: 1.6846777200698853
Validation loss: 2.023365360434337

Epoch: 5| Step: 5
Training loss: 1.0159646272659302
Validation loss: 2.0208944992352555

Epoch: 5| Step: 6
Training loss: 1.6804977655410767
Validation loss: 2.0124533522513604

Epoch: 5| Step: 7
Training loss: 1.6899230480194092
Validation loss: 2.024879824730658

Epoch: 5| Step: 8
Training loss: 1.2404098510742188
Validation loss: 1.9907872728122178

Epoch: 5| Step: 9
Training loss: 1.3014800548553467
Validation loss: 1.9797570846414054

Epoch: 5| Step: 10
Training loss: 1.3976364135742188
Validation loss: 2.010042535361423

Epoch: 465| Step: 0
Training loss: 1.099347710609436
Validation loss: 1.9698512413168465

Epoch: 5| Step: 1
Training loss: 1.4186961650848389
Validation loss: 1.9240659257417083

Epoch: 5| Step: 2
Training loss: 1.3823531866073608
Validation loss: 1.9776959983251428

Epoch: 5| Step: 3
Training loss: 1.0194859504699707
Validation loss: 1.9626847774751726

Epoch: 5| Step: 4
Training loss: 1.4293510913848877
Validation loss: 1.9863035601954306

Epoch: 5| Step: 5
Training loss: 1.3842030763626099
Validation loss: 2.0048892805653233

Epoch: 5| Step: 6
Training loss: 1.2036569118499756
Validation loss: 1.976806620115875

Epoch: 5| Step: 7
Training loss: 1.5973347425460815
Validation loss: 1.9792603754228162

Epoch: 5| Step: 8
Training loss: 1.6447257995605469
Validation loss: 1.9776634323981501

Epoch: 5| Step: 9
Training loss: 1.2447655200958252
Validation loss: 1.9707682594176261

Epoch: 5| Step: 10
Training loss: 1.156246542930603
Validation loss: 1.9633609197473014

Epoch: 466| Step: 0
Training loss: 2.1837515830993652
Validation loss: 2.010894457499186

Epoch: 5| Step: 1
Training loss: 0.9917629361152649
Validation loss: 1.9756542867229832

Epoch: 5| Step: 2
Training loss: 0.8450709581375122
Validation loss: 1.9652013560777069

Epoch: 5| Step: 3
Training loss: 1.4653756618499756
Validation loss: 1.9797441651744228

Epoch: 5| Step: 4
Training loss: 1.5281550884246826
Validation loss: 2.0190918163586686

Epoch: 5| Step: 5
Training loss: 1.123408555984497
Validation loss: 1.9660612255014398

Epoch: 5| Step: 6
Training loss: 1.175321340560913
Validation loss: 1.9958626993240849

Epoch: 5| Step: 7
Training loss: 1.6339021921157837
Validation loss: 1.9787730273380075

Epoch: 5| Step: 8
Training loss: 1.1552906036376953
Validation loss: 1.9617241736381286

Epoch: 5| Step: 9
Training loss: 1.6918865442276
Validation loss: 2.0090716974709624

Epoch: 5| Step: 10
Training loss: 1.0898228883743286
Validation loss: 1.9979549505377328

Epoch: 467| Step: 0
Training loss: 1.2434183359146118
Validation loss: 2.0006229800562703

Epoch: 5| Step: 1
Training loss: 1.3277605772018433
Validation loss: 1.9951003469446653

Epoch: 5| Step: 2
Training loss: 1.5800845623016357
Validation loss: 1.9807720312508204

Epoch: 5| Step: 3
Training loss: 1.611637830734253
Validation loss: 1.9556918682590607

Epoch: 5| Step: 4
Training loss: 1.3820054531097412
Validation loss: 2.014983941149968

Epoch: 5| Step: 5
Training loss: 1.295473337173462
Validation loss: 1.9588293003779587

Epoch: 5| Step: 6
Training loss: 1.1787296533584595
Validation loss: 1.9635115695256058

Epoch: 5| Step: 7
Training loss: 1.4981132745742798
Validation loss: 1.9677849777283207

Epoch: 5| Step: 8
Training loss: 1.0320028066635132
Validation loss: 1.9466360615145775

Epoch: 5| Step: 9
Training loss: 1.2235932350158691
Validation loss: 1.9731322539749967

Epoch: 5| Step: 10
Training loss: 1.432471752166748
Validation loss: 1.9843936876584125

Epoch: 468| Step: 0
Training loss: 1.4834661483764648
Validation loss: 1.980976745646487

Epoch: 5| Step: 1
Training loss: 0.7544332146644592
Validation loss: 2.0286973240554973

Epoch: 5| Step: 2
Training loss: 1.0301371812820435
Validation loss: 2.0154880259626653

Epoch: 5| Step: 3
Training loss: 1.2688798904418945
Validation loss: 2.001022882359002

Epoch: 5| Step: 4
Training loss: 1.2810782194137573
Validation loss: 2.0055988501476985

Epoch: 5| Step: 5
Training loss: 1.1981794834136963
Validation loss: 1.9995292873792752

Epoch: 5| Step: 6
Training loss: 2.008197784423828
Validation loss: 2.0020556014071227

Epoch: 5| Step: 7
Training loss: 1.6716158390045166
Validation loss: 1.9873242455144082

Epoch: 5| Step: 8
Training loss: 0.9966022372245789
Validation loss: 1.9988748078705163

Epoch: 5| Step: 9
Training loss: 1.4979604482650757
Validation loss: 2.0184325223327964

Epoch: 5| Step: 10
Training loss: 1.4615665674209595
Validation loss: 1.971874390878985

Epoch: 469| Step: 0
Training loss: 1.7371305227279663
Validation loss: 2.0018840515485374

Epoch: 5| Step: 1
Training loss: 1.286550521850586
Validation loss: 2.0355003495370187

Epoch: 5| Step: 2
Training loss: 0.7197589874267578
Validation loss: 2.0020914026485976

Epoch: 5| Step: 3
Training loss: 1.2528115510940552
Validation loss: 2.006995952257546

Epoch: 5| Step: 4
Training loss: 1.4019958972930908
Validation loss: 2.038625358253397

Epoch: 5| Step: 5
Training loss: 1.0558645725250244
Validation loss: 2.000332591354206

Epoch: 5| Step: 6
Training loss: 1.0878134965896606
Validation loss: 1.9917178794901857

Epoch: 5| Step: 7
Training loss: 1.3313488960266113
Validation loss: 1.9501396686800065

Epoch: 5| Step: 8
Training loss: 1.739039421081543
Validation loss: 1.954419474447927

Epoch: 5| Step: 9
Training loss: 1.3428866863250732
Validation loss: 1.96169711056576

Epoch: 5| Step: 10
Training loss: 1.8485103845596313
Validation loss: 1.9655376647108345

Epoch: 470| Step: 0
Training loss: 1.357227087020874
Validation loss: 1.983405913076093

Epoch: 5| Step: 1
Training loss: 2.0891237258911133
Validation loss: 1.9325341332343318

Epoch: 5| Step: 2
Training loss: 1.1750248670578003
Validation loss: 1.9615440419925156

Epoch: 5| Step: 3
Training loss: 1.1728136539459229
Validation loss: 1.9629117981080086

Epoch: 5| Step: 4
Training loss: 1.2116472721099854
Validation loss: 1.9755983557752383

Epoch: 5| Step: 5
Training loss: 1.5059093236923218
Validation loss: 1.9749982075024677

Epoch: 5| Step: 6
Training loss: 1.3528165817260742
Validation loss: 1.9756613239165275

Epoch: 5| Step: 7
Training loss: 1.22736394405365
Validation loss: 1.9326215149253927

Epoch: 5| Step: 8
Training loss: 1.1292088031768799
Validation loss: 1.9532948014556721

Epoch: 5| Step: 9
Training loss: 1.2513304948806763
Validation loss: 2.0148648420969644

Epoch: 5| Step: 10
Training loss: 1.268410563468933
Validation loss: 2.0690074069525606

Epoch: 471| Step: 0
Training loss: 1.5115406513214111
Validation loss: 1.943479743055118

Epoch: 5| Step: 1
Training loss: 1.999103307723999
Validation loss: 1.9822790648347588

Epoch: 5| Step: 2
Training loss: 0.8427433967590332
Validation loss: 1.9464970070828673

Epoch: 5| Step: 3
Training loss: 1.4417333602905273
Validation loss: 1.972692105077928

Epoch: 5| Step: 4
Training loss: 1.0416896343231201
Validation loss: 1.9481147540512906

Epoch: 5| Step: 5
Training loss: 1.0333385467529297
Validation loss: 1.942861718516196

Epoch: 5| Step: 6
Training loss: 0.9933493733406067
Validation loss: 1.9536049532633957

Epoch: 5| Step: 7
Training loss: 1.4543365240097046
Validation loss: 1.9642331472007177

Epoch: 5| Step: 8
Training loss: 1.8823299407958984
Validation loss: 1.9867657820383708

Epoch: 5| Step: 9
Training loss: 1.1850061416625977
Validation loss: 2.017844253970731

Epoch: 5| Step: 10
Training loss: 1.1280560493469238
Validation loss: 1.9342746375709452

Epoch: 472| Step: 0
Training loss: 1.0273094177246094
Validation loss: 2.035054506794099

Epoch: 5| Step: 1
Training loss: 0.6393769383430481
Validation loss: 1.9869274400895642

Epoch: 5| Step: 2
Training loss: 1.079185128211975
Validation loss: 2.009791548534106

Epoch: 5| Step: 3
Training loss: 1.2647958993911743
Validation loss: 2.010044244027907

Epoch: 5| Step: 4
Training loss: 1.2972291707992554
Validation loss: 1.9580835988444667

Epoch: 5| Step: 5
Training loss: 1.633363962173462
Validation loss: 2.0333892696647236

Epoch: 5| Step: 6
Training loss: 1.5468471050262451
Validation loss: 1.9868888842162264

Epoch: 5| Step: 7
Training loss: 1.6524879932403564
Validation loss: 2.02498189608256

Epoch: 5| Step: 8
Training loss: 2.322342872619629
Validation loss: 2.001468386701358

Epoch: 5| Step: 9
Training loss: 0.9728436470031738
Validation loss: 1.9810427529837495

Epoch: 5| Step: 10
Training loss: 1.1918811798095703
Validation loss: 1.9499400187564153

Epoch: 473| Step: 0
Training loss: 1.4356660842895508
Validation loss: 2.017476840685773

Epoch: 5| Step: 1
Training loss: 1.412988543510437
Validation loss: 1.961831590180756

Epoch: 5| Step: 2
Training loss: 0.954926609992981
Validation loss: 2.001929469006036

Epoch: 5| Step: 3
Training loss: 1.6012614965438843
Validation loss: 2.0398258816811348

Epoch: 5| Step: 4
Training loss: 1.6604549884796143
Validation loss: 1.9854176711010676

Epoch: 5| Step: 5
Training loss: 1.216977596282959
Validation loss: 1.9507246773730043

Epoch: 5| Step: 6
Training loss: 1.045810580253601
Validation loss: 1.9507340705522926

Epoch: 5| Step: 7
Training loss: 1.7089416980743408
Validation loss: 2.0141418915922924

Epoch: 5| Step: 8
Training loss: 1.285640001296997
Validation loss: 1.9724861896166237

Epoch: 5| Step: 9
Training loss: 1.4362061023712158
Validation loss: 1.9898523534497907

Epoch: 5| Step: 10
Training loss: 1.002901554107666
Validation loss: 1.973069792152733

Epoch: 474| Step: 0
Training loss: 1.7567203044891357
Validation loss: 1.9714317860141877

Epoch: 5| Step: 1
Training loss: 0.9767599105834961
Validation loss: 2.003366529300649

Epoch: 5| Step: 2
Training loss: 1.3002687692642212
Validation loss: 1.9863113293083765

Epoch: 5| Step: 3
Training loss: 1.4384111166000366
Validation loss: 1.9867264481001004

Epoch: 5| Step: 4
Training loss: 1.4994940757751465
Validation loss: 1.9619255655555314

Epoch: 5| Step: 5
Training loss: 1.0927456617355347
Validation loss: 1.9759564797083538

Epoch: 5| Step: 6
Training loss: 1.419921875
Validation loss: 2.0506127752283567

Epoch: 5| Step: 7
Training loss: 1.4374275207519531
Validation loss: 2.0057868329427575

Epoch: 5| Step: 8
Training loss: 1.1806774139404297
Validation loss: 1.991416774770265

Epoch: 5| Step: 9
Training loss: 1.5535449981689453
Validation loss: 1.986670112097135

Epoch: 5| Step: 10
Training loss: 1.2058484554290771
Validation loss: 1.9911088808890312

Epoch: 475| Step: 0
Training loss: 1.345474123954773
Validation loss: 1.9501795691828574

Epoch: 5| Step: 1
Training loss: 1.5643675327301025
Validation loss: 1.9645918928166872

Epoch: 5| Step: 2
Training loss: 1.627547025680542
Validation loss: 1.9721301319778606

Epoch: 5| Step: 3
Training loss: 1.1440759897232056
Validation loss: 1.9941913722663798

Epoch: 5| Step: 4
Training loss: 1.1292654275894165
Validation loss: 2.0051251637038363

Epoch: 5| Step: 5
Training loss: 1.4713315963745117
Validation loss: 1.9650562168449484

Epoch: 5| Step: 6
Training loss: 1.0544078350067139
Validation loss: 1.9780223625962452

Epoch: 5| Step: 7
Training loss: 1.2024376392364502
Validation loss: 1.9838414217836113

Epoch: 5| Step: 8
Training loss: 1.5234137773513794
Validation loss: 1.9387199237782469

Epoch: 5| Step: 9
Training loss: 1.108485460281372
Validation loss: 1.9968820361680881

Epoch: 5| Step: 10
Training loss: 1.5104588270187378
Validation loss: 1.9911104043324788

Epoch: 476| Step: 0
Training loss: 1.6531988382339478
Validation loss: 2.021913666878977

Epoch: 5| Step: 1
Training loss: 1.1215448379516602
Validation loss: 2.020079863968716

Epoch: 5| Step: 2
Training loss: 1.4312677383422852
Validation loss: 2.0027667566012313

Epoch: 5| Step: 3
Training loss: 1.2000105381011963
Validation loss: 2.021056987906015

Epoch: 5| Step: 4
Training loss: 1.6660089492797852
Validation loss: 2.0391589697971138

Epoch: 5| Step: 5
Training loss: 1.2476627826690674
Validation loss: 2.0222877687023533

Epoch: 5| Step: 6
Training loss: 1.1726901531219482
Validation loss: 1.9939195622680008

Epoch: 5| Step: 7
Training loss: 1.7273880243301392
Validation loss: 2.0225237377228273

Epoch: 5| Step: 8
Training loss: 1.429672122001648
Validation loss: 2.0180565964791084

Epoch: 5| Step: 9
Training loss: 1.308025598526001
Validation loss: 2.0351776205083376

Epoch: 5| Step: 10
Training loss: 0.947552502155304
Validation loss: 1.9626053661428473

Epoch: 477| Step: 0
Training loss: 1.459583044052124
Validation loss: 1.9839023454214937

Epoch: 5| Step: 1
Training loss: 1.4790712594985962
Validation loss: 2.0104123366776334

Epoch: 5| Step: 2
Training loss: 1.3545596599578857
Validation loss: 2.0220119850609892

Epoch: 5| Step: 3
Training loss: 0.7790427803993225
Validation loss: 1.9639753013528802

Epoch: 5| Step: 4
Training loss: 1.3136082887649536
Validation loss: 1.9854454096927439

Epoch: 5| Step: 5
Training loss: 1.129361867904663
Validation loss: 1.993356357338608

Epoch: 5| Step: 6
Training loss: 1.5820176601409912
Validation loss: 1.9642296119402813

Epoch: 5| Step: 7
Training loss: 2.0791192054748535
Validation loss: 1.9814809624866774

Epoch: 5| Step: 8
Training loss: 1.4321675300598145
Validation loss: 1.966557159218737

Epoch: 5| Step: 9
Training loss: 0.9671331644058228
Validation loss: 1.966674832887547

Epoch: 5| Step: 10
Training loss: 1.493297815322876
Validation loss: 1.9614340438637683

Epoch: 478| Step: 0
Training loss: 1.6754804849624634
Validation loss: 1.9473150135368429

Epoch: 5| Step: 1
Training loss: 1.4552905559539795
Validation loss: 1.9674878761332522

Epoch: 5| Step: 2
Training loss: 1.7239071130752563
Validation loss: 1.9771815858861452

Epoch: 5| Step: 3
Training loss: 1.3993083238601685
Validation loss: 2.0125975519098263

Epoch: 5| Step: 4
Training loss: 1.3418328762054443
Validation loss: 1.9926386264062697

Epoch: 5| Step: 5
Training loss: 1.1752839088439941
Validation loss: 1.9607412084456413

Epoch: 5| Step: 6
Training loss: 1.120076298713684
Validation loss: 1.9954723440190798

Epoch: 5| Step: 7
Training loss: 0.8681814074516296
Validation loss: 2.035742264921947

Epoch: 5| Step: 8
Training loss: 1.2032825946807861
Validation loss: 1.959075629070241

Epoch: 5| Step: 9
Training loss: 1.3235782384872437
Validation loss: 1.9944158472040647

Epoch: 5| Step: 10
Training loss: 1.2695224285125732
Validation loss: 1.9840459336516678

Epoch: 479| Step: 0
Training loss: 1.0928677320480347
Validation loss: 2.0171578199632707

Epoch: 5| Step: 1
Training loss: 1.6243536472320557
Validation loss: 1.9951752001239407

Epoch: 5| Step: 2
Training loss: 1.8398761749267578
Validation loss: 2.015425976886544

Epoch: 5| Step: 3
Training loss: 1.0784666538238525
Validation loss: 2.006069391004501

Epoch: 5| Step: 4
Training loss: 1.1903915405273438
Validation loss: 1.9890465710752754

Epoch: 5| Step: 5
Training loss: 1.2938671112060547
Validation loss: 1.9884889561642882

Epoch: 5| Step: 6
Training loss: 1.4018633365631104
Validation loss: 1.9836461697855303

Epoch: 5| Step: 7
Training loss: 1.274030089378357
Validation loss: 1.9829383973152406

Epoch: 5| Step: 8
Training loss: 1.3744217157363892
Validation loss: 1.9841469013562767

Epoch: 5| Step: 9
Training loss: 1.2921617031097412
Validation loss: 1.9792202454741283

Epoch: 5| Step: 10
Training loss: 1.1689637899398804
Validation loss: 1.9806995238027265

Epoch: 480| Step: 0
Training loss: 1.6752427816390991
Validation loss: 2.023847908102056

Epoch: 5| Step: 1
Training loss: 0.9904031753540039
Validation loss: 1.9554503963839622

Epoch: 5| Step: 2
Training loss: 1.5039842128753662
Validation loss: 1.9784706305432063

Epoch: 5| Step: 3
Training loss: 2.504383087158203
Validation loss: 1.980974333260649

Epoch: 5| Step: 4
Training loss: 0.8626413345336914
Validation loss: 1.9843071506869407

Epoch: 5| Step: 5
Training loss: 1.3835316896438599
Validation loss: 1.956477116512996

Epoch: 5| Step: 6
Training loss: 1.7397544384002686
Validation loss: 1.9403156413826892

Epoch: 5| Step: 7
Training loss: 0.8239218592643738
Validation loss: 2.0203975938981578

Epoch: 5| Step: 8
Training loss: 0.8350108861923218
Validation loss: 1.9819728277062858

Epoch: 5| Step: 9
Training loss: 1.0125588178634644
Validation loss: 1.9522440510411416

Epoch: 5| Step: 10
Training loss: 1.352862000465393
Validation loss: 1.9805397192637126

Epoch: 481| Step: 0
Training loss: 1.5298689603805542
Validation loss: 1.976217754425541

Epoch: 5| Step: 1
Training loss: 1.080026626586914
Validation loss: 1.9909312725067139

Epoch: 5| Step: 2
Training loss: 1.6240618228912354
Validation loss: 1.964932152020034

Epoch: 5| Step: 3
Training loss: 1.686478853225708
Validation loss: 1.98234567206393

Epoch: 5| Step: 4
Training loss: 1.3564815521240234
Validation loss: 1.9950142445102814

Epoch: 5| Step: 5
Training loss: 1.2218245267868042
Validation loss: 1.9963110287984211

Epoch: 5| Step: 6
Training loss: 1.1642205715179443
Validation loss: 1.9974245614902948

Epoch: 5| Step: 7
Training loss: 0.9296577572822571
Validation loss: 2.0181195735931396

Epoch: 5| Step: 8
Training loss: 1.1397813558578491
Validation loss: 2.021639108657837

Epoch: 5| Step: 9
Training loss: 1.3834192752838135
Validation loss: 1.9770279430573987

Epoch: 5| Step: 10
Training loss: 1.3580430746078491
Validation loss: 1.9586433108134935

Epoch: 482| Step: 0
Training loss: 1.5990946292877197
Validation loss: 2.056756577184123

Epoch: 5| Step: 1
Training loss: 1.3651386499404907
Validation loss: 2.021072764550486

Epoch: 5| Step: 2
Training loss: 1.2379651069641113
Validation loss: 2.0271386126036286

Epoch: 5| Step: 3
Training loss: 1.3954651355743408
Validation loss: 1.956173930116879

Epoch: 5| Step: 4
Training loss: 0.978860080242157
Validation loss: 1.9904134722166165

Epoch: 5| Step: 5
Training loss: 1.3341314792633057
Validation loss: 1.970697766991072

Epoch: 5| Step: 6
Training loss: 1.3017284870147705
Validation loss: 1.9471515096643919

Epoch: 5| Step: 7
Training loss: 0.8241939544677734
Validation loss: 1.9808480944684757

Epoch: 5| Step: 8
Training loss: 1.9502906799316406
Validation loss: 1.9618526991977487

Epoch: 5| Step: 9
Training loss: 1.64335036277771
Validation loss: 2.027214712994073

Epoch: 5| Step: 10
Training loss: 1.1662429571151733
Validation loss: 1.9994593230626916

Epoch: 483| Step: 0
Training loss: 1.2465993165969849
Validation loss: 1.982249003584667

Epoch: 5| Step: 1
Training loss: 1.4451984167099
Validation loss: 1.9432999036645378

Epoch: 5| Step: 2
Training loss: 0.9978747367858887
Validation loss: 1.97596743799025

Epoch: 5| Step: 3
Training loss: 1.772632360458374
Validation loss: 2.0128686966434604

Epoch: 5| Step: 4
Training loss: 0.8030537366867065
Validation loss: 1.9896049294420468

Epoch: 5| Step: 5
Training loss: 1.2212932109832764
Validation loss: 1.9822773305318688

Epoch: 5| Step: 6
Training loss: 1.3195273876190186
Validation loss: 1.99765694397752

Epoch: 5| Step: 7
Training loss: 2.1091442108154297
Validation loss: 2.0237204182532524

Epoch: 5| Step: 8
Training loss: 1.1514744758605957
Validation loss: 2.015510125826764

Epoch: 5| Step: 9
Training loss: 0.8797907829284668
Validation loss: 1.9554275466549782

Epoch: 5| Step: 10
Training loss: 1.3070567846298218
Validation loss: 1.9768808221304288

Epoch: 484| Step: 0
Training loss: 1.7842915058135986
Validation loss: 1.9631171636683966

Epoch: 5| Step: 1
Training loss: 1.2720059156417847
Validation loss: 1.9967464170148295

Epoch: 5| Step: 2
Training loss: 1.0751999616622925
Validation loss: 1.9723651268148934

Epoch: 5| Step: 3
Training loss: 0.8893140554428101
Validation loss: 2.0119870913925992

Epoch: 5| Step: 4
Training loss: 1.113518476486206
Validation loss: 1.9956409392818328

Epoch: 5| Step: 5
Training loss: 1.15035080909729
Validation loss: 1.9926830337893577

Epoch: 5| Step: 6
Training loss: 1.1286089420318604
Validation loss: 2.02499770989982

Epoch: 5| Step: 7
Training loss: 1.2087520360946655
Validation loss: 1.9943042724363265

Epoch: 5| Step: 8
Training loss: 2.019279956817627
Validation loss: 2.044509228839669

Epoch: 5| Step: 9
Training loss: 1.6868321895599365
Validation loss: 1.9500087691891579

Epoch: 5| Step: 10
Training loss: 1.0766346454620361
Validation loss: 2.0117030477011077

Epoch: 485| Step: 0
Training loss: 1.0366485118865967
Validation loss: 2.0165858640465686

Epoch: 5| Step: 1
Training loss: 1.595004677772522
Validation loss: 1.9895554511777815

Epoch: 5| Step: 2
Training loss: 1.5629454851150513
Validation loss: 1.987495732563798

Epoch: 5| Step: 3
Training loss: 1.2561700344085693
Validation loss: 2.0373976448530793

Epoch: 5| Step: 4
Training loss: 0.8232196569442749
Validation loss: 1.9726690310303883

Epoch: 5| Step: 5
Training loss: 1.9664161205291748
Validation loss: 1.9730293917399582

Epoch: 5| Step: 6
Training loss: 1.01303231716156
Validation loss: 2.020286830522681

Epoch: 5| Step: 7
Training loss: 1.0483918190002441
Validation loss: 2.0212326036986483

Epoch: 5| Step: 8
Training loss: 1.1753658056259155
Validation loss: 1.9962013434338313

Epoch: 5| Step: 9
Training loss: 1.4568732976913452
Validation loss: 2.015886829745385

Epoch: 5| Step: 10
Training loss: 1.6967235803604126
Validation loss: 2.0149407335506972

Epoch: 486| Step: 0
Training loss: 1.6646926403045654
Validation loss: 2.010837890768564

Epoch: 5| Step: 1
Training loss: 1.3978036642074585
Validation loss: 2.0339448990360385

Epoch: 5| Step: 2
Training loss: 1.488660216331482
Validation loss: 1.973056326630295

Epoch: 5| Step: 3
Training loss: 0.828375518321991
Validation loss: 2.012046082045442

Epoch: 5| Step: 4
Training loss: 1.2140785455703735
Validation loss: 2.054357965787252

Epoch: 5| Step: 5
Training loss: 1.4190467596054077
Validation loss: 1.9956652502859793

Epoch: 5| Step: 6
Training loss: 1.4837634563446045
Validation loss: 1.989903981967639

Epoch: 5| Step: 7
Training loss: 1.6488285064697266
Validation loss: 2.0001058040126676

Epoch: 5| Step: 8
Training loss: 0.8654916882514954
Validation loss: 2.0221802137231313

Epoch: 5| Step: 9
Training loss: 1.5426764488220215
Validation loss: 1.9637611963415658

Epoch: 5| Step: 10
Training loss: 1.2255040407180786
Validation loss: 2.0089793717989357

Epoch: 487| Step: 0
Training loss: 1.6554515361785889
Validation loss: 1.9653886877080446

Epoch: 5| Step: 1
Training loss: 1.309081792831421
Validation loss: 1.9458993929688648

Epoch: 5| Step: 2
Training loss: 1.4725513458251953
Validation loss: 2.0067014002030894

Epoch: 5| Step: 3
Training loss: 1.1040247678756714
Validation loss: 1.9665866641588108

Epoch: 5| Step: 4
Training loss: 0.9044864773750305
Validation loss: 2.0051964457317064

Epoch: 5| Step: 5
Training loss: 1.484798789024353
Validation loss: 1.9942405211028231

Epoch: 5| Step: 6
Training loss: 1.370520830154419
Validation loss: 1.9668163984052596

Epoch: 5| Step: 7
Training loss: 1.3604681491851807
Validation loss: 1.963818976956029

Epoch: 5| Step: 8
Training loss: 1.4384593963623047
Validation loss: 1.9597052092193274

Epoch: 5| Step: 9
Training loss: 1.7207053899765015
Validation loss: 1.9662714312153478

Epoch: 5| Step: 10
Training loss: 0.6388344168663025
Validation loss: 1.9787525861494002

Epoch: 488| Step: 0
Training loss: 1.439348816871643
Validation loss: 1.9369785272946922

Epoch: 5| Step: 1
Training loss: 0.9804986715316772
Validation loss: 1.96559993169641

Epoch: 5| Step: 2
Training loss: 1.3651511669158936
Validation loss: 2.003410893101846

Epoch: 5| Step: 3
Training loss: 1.1754683256149292
Validation loss: 1.9794740933243946

Epoch: 5| Step: 4
Training loss: 1.0043121576309204
Validation loss: 2.0149027416782994

Epoch: 5| Step: 5
Training loss: 1.5724034309387207
Validation loss: 2.006022704544888

Epoch: 5| Step: 6
Training loss: 1.2331280708312988
Validation loss: 2.007982718047275

Epoch: 5| Step: 7
Training loss: 1.1234480142593384
Validation loss: 1.9627634504789948

Epoch: 5| Step: 8
Training loss: 1.5985416173934937
Validation loss: 1.978657227690502

Epoch: 5| Step: 9
Training loss: 1.3817487955093384
Validation loss: 1.947379058407199

Epoch: 5| Step: 10
Training loss: 1.2523910999298096
Validation loss: 1.9711061152078773

Epoch: 489| Step: 0
Training loss: 1.1720536947250366
Validation loss: 1.9902919505232124

Epoch: 5| Step: 1
Training loss: 1.4246138334274292
Validation loss: 1.9848614841379144

Epoch: 5| Step: 2
Training loss: 1.6307504177093506
Validation loss: 1.9906447190110401

Epoch: 5| Step: 3
Training loss: 1.3415815830230713
Validation loss: 1.9619343806338567

Epoch: 5| Step: 4
Training loss: 1.3474299907684326
Validation loss: 2.001075129355154

Epoch: 5| Step: 5
Training loss: 1.2755906581878662
Validation loss: 2.0072604097345823

Epoch: 5| Step: 6
Training loss: 1.5100016593933105
Validation loss: 1.9796226562992219

Epoch: 5| Step: 7
Training loss: 0.9465705752372742
Validation loss: 1.9674411268644436

Epoch: 5| Step: 8
Training loss: 0.73529052734375
Validation loss: 1.976400754785025

Epoch: 5| Step: 9
Training loss: 1.4065792560577393
Validation loss: 2.008135095719368

Epoch: 5| Step: 10
Training loss: 1.4852901697158813
Validation loss: 2.011890499822555

Epoch: 490| Step: 0
Training loss: 1.4143359661102295
Validation loss: 1.9788593707546112

Epoch: 5| Step: 1
Training loss: 1.433153748512268
Validation loss: 1.9948267654706073

Epoch: 5| Step: 2
Training loss: 1.0605818033218384
Validation loss: 2.01329077828315

Epoch: 5| Step: 3
Training loss: 0.9870537519454956
Validation loss: 2.043082202634504

Epoch: 5| Step: 4
Training loss: 0.7961845397949219
Validation loss: 2.047553693094561

Epoch: 5| Step: 5
Training loss: 0.9569045305252075
Validation loss: 2.02722264618002

Epoch: 5| Step: 6
Training loss: 1.025517463684082
Validation loss: 1.961825442570512

Epoch: 5| Step: 7
Training loss: 1.544802188873291
Validation loss: 1.9534714337318175

Epoch: 5| Step: 8
Training loss: 1.9502613544464111
Validation loss: 1.963989584676681

Epoch: 5| Step: 9
Training loss: 1.7503963708877563
Validation loss: 1.9976596473365702

Epoch: 5| Step: 10
Training loss: 1.2122344970703125
Validation loss: 1.949973257639075

Epoch: 491| Step: 0
Training loss: 1.3878898620605469
Validation loss: 1.9564258898458173

Epoch: 5| Step: 1
Training loss: 1.5386545658111572
Validation loss: 1.9600690808347476

Epoch: 5| Step: 2
Training loss: 1.1828052997589111
Validation loss: 1.9507740313006985

Epoch: 5| Step: 3
Training loss: 1.3164873123168945
Validation loss: 1.9622458821983748

Epoch: 5| Step: 4
Training loss: 1.1020342111587524
Validation loss: 2.0064864581631077

Epoch: 5| Step: 5
Training loss: 1.719931960105896
Validation loss: 1.9615579881975729

Epoch: 5| Step: 6
Training loss: 1.2367289066314697
Validation loss: 1.9418390976485385

Epoch: 5| Step: 7
Training loss: 1.0092843770980835
Validation loss: 1.982712273956627

Epoch: 5| Step: 8
Training loss: 1.1518357992172241
Validation loss: 2.0091691529879006

Epoch: 5| Step: 9
Training loss: 1.3455893993377686
Validation loss: 1.9999491450607136

Epoch: 5| Step: 10
Training loss: 1.5005518198013306
Validation loss: 2.0014130377000376

Epoch: 492| Step: 0
Training loss: 1.406930685043335
Validation loss: 2.017613408386066

Epoch: 5| Step: 1
Training loss: 1.128170371055603
Validation loss: 2.063565013229206

Epoch: 5| Step: 2
Training loss: 1.349138617515564
Validation loss: 2.0471316358094573

Epoch: 5| Step: 3
Training loss: 1.3458027839660645
Validation loss: 2.0255945562034525

Epoch: 5| Step: 4
Training loss: 1.800666093826294
Validation loss: 2.0800427236864643

Epoch: 5| Step: 5
Training loss: 1.5991065502166748
Validation loss: 2.042340168388941

Epoch: 5| Step: 6
Training loss: 1.5211185216903687
Validation loss: 2.0992274809909124

Epoch: 5| Step: 7
Training loss: 1.3624608516693115
Validation loss: 2.0066504427181777

Epoch: 5| Step: 8
Training loss: 0.6984395384788513
Validation loss: 2.056635361845775

Epoch: 5| Step: 9
Training loss: 1.4613800048828125
Validation loss: 2.0353294072612638

Epoch: 5| Step: 10
Training loss: 1.057731032371521
Validation loss: 1.9926545107236473

Epoch: 493| Step: 0
Training loss: 1.1969305276870728
Validation loss: 1.9846327561204151

Epoch: 5| Step: 1
Training loss: 1.55861234664917
Validation loss: 2.0106297321217035

Epoch: 5| Step: 2
Training loss: 1.1364505290985107
Validation loss: 1.9771496929148191

Epoch: 5| Step: 3
Training loss: 1.312504529953003
Validation loss: 2.0183897787524807

Epoch: 5| Step: 4
Training loss: 1.1262094974517822
Validation loss: 1.9538411094296364

Epoch: 5| Step: 5
Training loss: 1.337598443031311
Validation loss: 1.9748783842209847

Epoch: 5| Step: 6
Training loss: 1.6696126461029053
Validation loss: 1.9333466957974177

Epoch: 5| Step: 7
Training loss: 1.354001760482788
Validation loss: 1.9769766663992276

Epoch: 5| Step: 8
Training loss: 1.2307466268539429
Validation loss: 1.9471479744039557

Epoch: 5| Step: 9
Training loss: 1.6269413232803345
Validation loss: 1.9778452804011684

Epoch: 5| Step: 10
Training loss: 1.128652572631836
Validation loss: 2.0129348539536998

Epoch: 494| Step: 0
Training loss: 0.9344791173934937
Validation loss: 1.9830610636741883

Epoch: 5| Step: 1
Training loss: 1.672455072402954
Validation loss: 2.009105347817944

Epoch: 5| Step: 2
Training loss: 1.1878297328948975
Validation loss: 1.9520768657807381

Epoch: 5| Step: 3
Training loss: 1.7017825841903687
Validation loss: 1.9963481208329559

Epoch: 5| Step: 4
Training loss: 1.0788158178329468
Validation loss: 1.9923937025890555

Epoch: 5| Step: 5
Training loss: 1.3233882188796997
Validation loss: 2.0238887135700514

Epoch: 5| Step: 6
Training loss: 1.3339698314666748
Validation loss: 2.018336069199347

Epoch: 5| Step: 7
Training loss: 1.0590451955795288
Validation loss: 1.9779851692979054

Epoch: 5| Step: 8
Training loss: 1.2107007503509521
Validation loss: 1.9770064238579041

Epoch: 5| Step: 9
Training loss: 1.3494492769241333
Validation loss: 1.964804724339516

Epoch: 5| Step: 10
Training loss: 1.5722737312316895
Validation loss: 1.9876093249167166

Epoch: 495| Step: 0
Training loss: 1.1008566617965698
Validation loss: 1.9852599738746561

Epoch: 5| Step: 1
Training loss: 1.1064913272857666
Validation loss: 2.0065314500562605

Epoch: 5| Step: 2
Training loss: 0.9075406193733215
Validation loss: 1.9414579112042663

Epoch: 5| Step: 3
Training loss: 1.2336862087249756
Validation loss: 1.9495802220477854

Epoch: 5| Step: 4
Training loss: 1.7910125255584717
Validation loss: 1.9453468938027658

Epoch: 5| Step: 5
Training loss: 1.175086259841919
Validation loss: 1.9550452129815215

Epoch: 5| Step: 6
Training loss: 1.503849744796753
Validation loss: 2.004756413480287

Epoch: 5| Step: 7
Training loss: 1.0515093803405762
Validation loss: 2.022786755715647

Epoch: 5| Step: 8
Training loss: 1.584895133972168
Validation loss: 1.9616393081603511

Epoch: 5| Step: 9
Training loss: 1.3524459600448608
Validation loss: 1.9388610739861765

Epoch: 5| Step: 10
Training loss: 1.6557310819625854
Validation loss: 1.962374851267825

Epoch: 496| Step: 0
Training loss: 1.2004588842391968
Validation loss: 2.01760967059802

Epoch: 5| Step: 1
Training loss: 1.1056928634643555
Validation loss: 2.0018334004186813

Epoch: 5| Step: 2
Training loss: 1.3174022436141968
Validation loss: 2.01174856001331

Epoch: 5| Step: 3
Training loss: 1.4116320610046387
Validation loss: 1.9685644975272558

Epoch: 5| Step: 4
Training loss: 1.5854475498199463
Validation loss: 1.9580836680627638

Epoch: 5| Step: 5
Training loss: 1.0296398401260376
Validation loss: 1.9628210811204807

Epoch: 5| Step: 6
Training loss: 1.563712477684021
Validation loss: 2.012375183002923

Epoch: 5| Step: 7
Training loss: 1.4626848697662354
Validation loss: 1.9816743609725789

Epoch: 5| Step: 8
Training loss: 1.3023470640182495
Validation loss: 2.014404421211571

Epoch: 5| Step: 9
Training loss: 1.375533103942871
Validation loss: 2.0060481371418124

Epoch: 5| Step: 10
Training loss: 1.0694842338562012
Validation loss: 1.9551242654041578

Epoch: 497| Step: 0
Training loss: 1.2433221340179443
Validation loss: 2.0078381415336364

Epoch: 5| Step: 1
Training loss: 1.229694128036499
Validation loss: 1.9814393328082176

Epoch: 5| Step: 2
Training loss: 1.273940086364746
Validation loss: 2.0009468499050347

Epoch: 5| Step: 3
Training loss: 0.8741594552993774
Validation loss: 1.9541352666834348

Epoch: 5| Step: 4
Training loss: 1.6456571817398071
Validation loss: 2.01509343424151

Epoch: 5| Step: 5
Training loss: 1.0618133544921875
Validation loss: 1.9788716480296145

Epoch: 5| Step: 6
Training loss: 1.5432960987091064
Validation loss: 2.037839912599133

Epoch: 5| Step: 7
Training loss: 1.2679798603057861
Validation loss: 1.9666180841384395

Epoch: 5| Step: 8
Training loss: 1.6285794973373413
Validation loss: 2.0210823730755876

Epoch: 5| Step: 9
Training loss: 1.3970656394958496
Validation loss: 1.9527422125621507

Epoch: 5| Step: 10
Training loss: 1.0428060293197632
Validation loss: 1.9714375131873674

Epoch: 498| Step: 0
Training loss: 0.8081261515617371
Validation loss: 1.9738197595842424

Epoch: 5| Step: 1
Training loss: 1.8811414241790771
Validation loss: 1.9629535816049064

Epoch: 5| Step: 2
Training loss: 1.4141836166381836
Validation loss: 1.991559902826945

Epoch: 5| Step: 3
Training loss: 0.8348276019096375
Validation loss: 1.9889965685465003

Epoch: 5| Step: 4
Training loss: 1.5052490234375
Validation loss: 1.996957412330053

Epoch: 5| Step: 5
Training loss: 1.008702278137207
Validation loss: 1.9558439998216526

Epoch: 5| Step: 6
Training loss: 1.613181710243225
Validation loss: 1.9528837588525587

Epoch: 5| Step: 7
Training loss: 1.4174578189849854
Validation loss: 2.0084432094327864

Epoch: 5| Step: 8
Training loss: 1.1646593809127808
Validation loss: 1.9625519398720033

Epoch: 5| Step: 9
Training loss: 1.5389477014541626
Validation loss: 1.957967944042657

Epoch: 5| Step: 10
Training loss: 1.103442907333374
Validation loss: 2.004720272556428

Epoch: 499| Step: 0
Training loss: 0.9772824048995972
Validation loss: 2.0281127909178376

Epoch: 5| Step: 1
Training loss: 1.0890052318572998
Validation loss: 2.0114572971097884

Epoch: 5| Step: 2
Training loss: 1.0434834957122803
Validation loss: 1.9880796670913696

Epoch: 5| Step: 3
Training loss: 2.1172797679901123
Validation loss: 2.0207906833259006

Epoch: 5| Step: 4
Training loss: 1.0692334175109863
Validation loss: 2.013223922380837

Epoch: 5| Step: 5
Training loss: 1.3571093082427979
Validation loss: 2.009186969008497

Epoch: 5| Step: 6
Training loss: 0.9631935358047485
Validation loss: 2.016302526638072

Epoch: 5| Step: 7
Training loss: 1.3942618370056152
Validation loss: 1.982287629958122

Epoch: 5| Step: 8
Training loss: 1.8161287307739258
Validation loss: 1.9337856000469578

Epoch: 5| Step: 9
Training loss: 1.4347195625305176
Validation loss: 1.9995988210042317

Epoch: 5| Step: 10
Training loss: 0.9721847772598267
Validation loss: 1.9725431652479275

Epoch: 500| Step: 0
Training loss: 1.322326421737671
Validation loss: 1.9723724460089078

Epoch: 5| Step: 1
Training loss: 1.1142709255218506
Validation loss: 1.963137435656722

Epoch: 5| Step: 2
Training loss: 1.1880707740783691
Validation loss: 1.9681946898019442

Epoch: 5| Step: 3
Training loss: 1.0380760431289673
Validation loss: 2.032130218321277

Epoch: 5| Step: 4
Training loss: 1.2158663272857666
Validation loss: 1.9645154706893428

Epoch: 5| Step: 5
Training loss: 1.5139421224594116
Validation loss: 1.971130399293797

Epoch: 5| Step: 6
Training loss: 1.5093307495117188
Validation loss: 2.0081655261337117

Epoch: 5| Step: 7
Training loss: 1.0870119333267212
Validation loss: 1.9894234211214128

Epoch: 5| Step: 8
Training loss: 1.5202163457870483
Validation loss: 2.0019931331757577

Epoch: 5| Step: 9
Training loss: 1.6233747005462646
Validation loss: 1.9836997293656873

Epoch: 5| Step: 10
Training loss: 1.3542563915252686
Validation loss: 1.9728753464196318

Epoch: 501| Step: 0
Training loss: 1.6014044284820557
Validation loss: 2.0223665134881132

Epoch: 5| Step: 1
Training loss: 1.4478278160095215
Validation loss: 2.03334145135777

Epoch: 5| Step: 2
Training loss: 1.1129395961761475
Validation loss: 2.0038628860186507

Epoch: 5| Step: 3
Training loss: 0.9225664138793945
Validation loss: 2.0075986257163425

Epoch: 5| Step: 4
Training loss: 1.6188952922821045
Validation loss: 2.017103772009573

Epoch: 5| Step: 5
Training loss: 1.5467125177383423
Validation loss: 1.977916238128498

Epoch: 5| Step: 6
Training loss: 0.9193698167800903
Validation loss: 1.992595782843969

Epoch: 5| Step: 7
Training loss: 1.3660649061203003
Validation loss: 1.946981353144492

Epoch: 5| Step: 8
Training loss: 1.5311927795410156
Validation loss: 1.9639639149429977

Epoch: 5| Step: 9
Training loss: 1.0733709335327148
Validation loss: 1.9947575625552927

Epoch: 5| Step: 10
Training loss: 1.3729722499847412
Validation loss: 1.934282382329305

Epoch: 502| Step: 0
Training loss: 0.6654545068740845
Validation loss: 2.005135736157817

Epoch: 5| Step: 1
Training loss: 1.485648512840271
Validation loss: 2.004307467450378

Epoch: 5| Step: 2
Training loss: 1.0792927742004395
Validation loss: 2.012457469458221

Epoch: 5| Step: 3
Training loss: 1.9609559774398804
Validation loss: 2.0507913533077446

Epoch: 5| Step: 4
Training loss: 1.3618181943893433
Validation loss: 1.9940414121074062

Epoch: 5| Step: 5
Training loss: 1.0814173221588135
Validation loss: 1.9975016642642278

Epoch: 5| Step: 6
Training loss: 1.6435264348983765
Validation loss: 1.9766902718492734

Epoch: 5| Step: 7
Training loss: 0.7737886309623718
Validation loss: 1.9925920437741023

Epoch: 5| Step: 8
Training loss: 1.398943305015564
Validation loss: 2.017266831090373

Epoch: 5| Step: 9
Training loss: 1.6927292346954346
Validation loss: 2.0111827645250546

Epoch: 5| Step: 10
Training loss: 1.0567725896835327
Validation loss: 2.0064284032390964

Epoch: 503| Step: 0
Training loss: 0.9545404314994812
Validation loss: 2.007304778663061

Epoch: 5| Step: 1
Training loss: 1.2931363582611084
Validation loss: 2.0120371721124135

Epoch: 5| Step: 2
Training loss: 1.2582290172576904
Validation loss: 1.9724786281585693

Epoch: 5| Step: 3
Training loss: 1.5460805892944336
Validation loss: 1.9588701648096885

Epoch: 5| Step: 4
Training loss: 1.4059849977493286
Validation loss: 1.9902935899713987

Epoch: 5| Step: 5
Training loss: 1.6887496709823608
Validation loss: 1.9840351009881625

Epoch: 5| Step: 6
Training loss: 1.0450875759124756
Validation loss: 1.9977383152131112

Epoch: 5| Step: 7
Training loss: 0.9575481414794922
Validation loss: 2.0303408074122604

Epoch: 5| Step: 8
Training loss: 1.3442381620407104
Validation loss: 1.9820947518912695

Epoch: 5| Step: 9
Training loss: 1.117880940437317
Validation loss: 2.0096007136888403

Epoch: 5| Step: 10
Training loss: 1.6677526235580444
Validation loss: 1.9509479871360205

Epoch: 504| Step: 0
Training loss: 0.9545716047286987
Validation loss: 1.9486593315678258

Epoch: 5| Step: 1
Training loss: 1.5497150421142578
Validation loss: 1.9515256907350274

Epoch: 5| Step: 2
Training loss: 1.0445104837417603
Validation loss: 2.026466561901954

Epoch: 5| Step: 3
Training loss: 1.2836275100708008
Validation loss: 1.9264688158548007

Epoch: 5| Step: 4
Training loss: 1.5393949747085571
Validation loss: 2.014445235652308

Epoch: 5| Step: 5
Training loss: 1.0202696323394775
Validation loss: 1.9802197461487145

Epoch: 5| Step: 6
Training loss: 1.3744537830352783
Validation loss: 2.0103139595318864

Epoch: 5| Step: 7
Training loss: 2.0233829021453857
Validation loss: 1.9407848235099547

Epoch: 5| Step: 8
Training loss: 1.5682578086853027
Validation loss: 1.9848620942843858

Epoch: 5| Step: 9
Training loss: 1.0075702667236328
Validation loss: 2.026298174294092

Epoch: 5| Step: 10
Training loss: 0.943117618560791
Validation loss: 2.006663922340639

Epoch: 505| Step: 0
Training loss: 0.9885795712471008
Validation loss: 2.022082628742341

Epoch: 5| Step: 1
Training loss: 1.169228434562683
Validation loss: 1.977193683706304

Epoch: 5| Step: 2
Training loss: 0.8514412641525269
Validation loss: 1.983339794220463

Epoch: 5| Step: 3
Training loss: 0.8336650133132935
Validation loss: 2.0116952606426772

Epoch: 5| Step: 4
Training loss: 1.5941253900527954
Validation loss: 2.0339158094057472

Epoch: 5| Step: 5
Training loss: 1.8464221954345703
Validation loss: 2.069466334517284

Epoch: 5| Step: 6
Training loss: 1.3542051315307617
Validation loss: 2.0307878448117163

Epoch: 5| Step: 7
Training loss: 1.3957430124282837
Validation loss: 1.9809618688398791

Epoch: 5| Step: 8
Training loss: 1.7257198095321655
Validation loss: 1.968964481866488

Epoch: 5| Step: 9
Training loss: 1.346696376800537
Validation loss: 1.990568862166456

Epoch: 5| Step: 10
Training loss: 1.1034233570098877
Validation loss: 1.9769629047762962

Epoch: 506| Step: 0
Training loss: 1.3378413915634155
Validation loss: 2.025802493095398

Epoch: 5| Step: 1
Training loss: 1.9881410598754883
Validation loss: 2.011526139833594

Epoch: 5| Step: 2
Training loss: 1.2196820974349976
Validation loss: 2.0154377491243425

Epoch: 5| Step: 3
Training loss: 1.1391819715499878
Validation loss: 1.9779843745693084

Epoch: 5| Step: 4
Training loss: 1.3280770778656006
Validation loss: 1.9686248802369641

Epoch: 5| Step: 5
Training loss: 1.555421233177185
Validation loss: 1.9945132565754715

Epoch: 5| Step: 6
Training loss: 1.3298969268798828
Validation loss: 2.0121955333217496

Epoch: 5| Step: 7
Training loss: 0.8832756280899048
Validation loss: 1.9666446960100563

Epoch: 5| Step: 8
Training loss: 1.3967918157577515
Validation loss: 1.9676405986150105

Epoch: 5| Step: 9
Training loss: 1.3482471704483032
Validation loss: 1.9848845927946028

Epoch: 5| Step: 10
Training loss: 0.5514224171638489
Validation loss: 1.9746640215637863

Epoch: 507| Step: 0
Training loss: 1.3462048768997192
Validation loss: 1.9784547000802972

Epoch: 5| Step: 1
Training loss: 1.0940325260162354
Validation loss: 2.016425055842246

Epoch: 5| Step: 2
Training loss: 1.308002233505249
Validation loss: 1.9518590178540958

Epoch: 5| Step: 3
Training loss: 1.9991782903671265
Validation loss: 1.9467172135588944

Epoch: 5| Step: 4
Training loss: 0.7954277992248535
Validation loss: 1.9959885074246315

Epoch: 5| Step: 5
Training loss: 1.1397050619125366
Validation loss: 2.018403967221578

Epoch: 5| Step: 6
Training loss: 1.326262354850769
Validation loss: 1.9679050548102266

Epoch: 5| Step: 7
Training loss: 1.085080862045288
Validation loss: 1.9603945914135184

Epoch: 5| Step: 8
Training loss: 1.3668038845062256
Validation loss: 1.9825130662610453

Epoch: 5| Step: 9
Training loss: 1.42153000831604
Validation loss: 1.9950239055900163

Epoch: 5| Step: 10
Training loss: 1.2304645776748657
Validation loss: 1.9826364696666758

Epoch: 508| Step: 0
Training loss: 1.1325277090072632
Validation loss: 2.016251525571269

Epoch: 5| Step: 1
Training loss: 1.0039786100387573
Validation loss: 1.9933685538589314

Epoch: 5| Step: 2
Training loss: 1.3384755849838257
Validation loss: 1.994823960847752

Epoch: 5| Step: 3
Training loss: 1.9072033166885376
Validation loss: 1.988358292528378

Epoch: 5| Step: 4
Training loss: 1.0272268056869507
Validation loss: 1.9800820427556192

Epoch: 5| Step: 5
Training loss: 1.2542321681976318
Validation loss: 2.0109902992043445

Epoch: 5| Step: 6
Training loss: 1.0189313888549805
Validation loss: 1.970205630025556

Epoch: 5| Step: 7
Training loss: 1.4507529735565186
Validation loss: 1.953998516964656

Epoch: 5| Step: 8
Training loss: 1.2970898151397705
Validation loss: 1.975252305307696

Epoch: 5| Step: 9
Training loss: 1.3935153484344482
Validation loss: 2.004868294603081

Epoch: 5| Step: 10
Training loss: 1.1822606325149536
Validation loss: 2.005657337045157

Epoch: 509| Step: 0
Training loss: 1.1705267429351807
Validation loss: 1.966250983617639

Epoch: 5| Step: 1
Training loss: 1.3021128177642822
Validation loss: 1.9917224504614388

Epoch: 5| Step: 2
Training loss: 1.0992377996444702
Validation loss: 2.0335093070101995

Epoch: 5| Step: 3
Training loss: 1.1474722623825073
Validation loss: 2.014906066720204

Epoch: 5| Step: 4
Training loss: 1.5844062566757202
Validation loss: 2.0066960268123175

Epoch: 5| Step: 5
Training loss: 1.1798758506774902
Validation loss: 1.9937126944142003

Epoch: 5| Step: 6
Training loss: 1.1866610050201416
Validation loss: 1.9140446442429737

Epoch: 5| Step: 7
Training loss: 1.2340114116668701
Validation loss: 1.9943585511176818

Epoch: 5| Step: 8
Training loss: 1.2911145687103271
Validation loss: 1.9831280939040645

Epoch: 5| Step: 9
Training loss: 1.2661221027374268
Validation loss: 2.011527863881921

Epoch: 5| Step: 10
Training loss: 1.7084704637527466
Validation loss: 1.987485880492836

Epoch: 510| Step: 0
Training loss: 1.3108844757080078
Validation loss: 1.9531785339437506

Epoch: 5| Step: 1
Training loss: 1.2321903705596924
Validation loss: 1.9927757683620657

Epoch: 5| Step: 2
Training loss: 1.6528651714324951
Validation loss: 2.019493970819699

Epoch: 5| Step: 3
Training loss: 1.050905466079712
Validation loss: 1.9879637636164182

Epoch: 5| Step: 4
Training loss: 0.7271216511726379
Validation loss: 1.9724751159708986

Epoch: 5| Step: 5
Training loss: 1.3945324420928955
Validation loss: 2.022311956651749

Epoch: 5| Step: 6
Training loss: 1.247376799583435
Validation loss: 1.987472298324749

Epoch: 5| Step: 7
Training loss: 1.3004868030548096
Validation loss: 2.0433055175248014

Epoch: 5| Step: 8
Training loss: 1.0394561290740967
Validation loss: 2.01321772093414

Epoch: 5| Step: 9
Training loss: 1.3421435356140137
Validation loss: 2.0288539099436935

Epoch: 5| Step: 10
Training loss: 2.0898520946502686
Validation loss: 2.0098542885113786

Epoch: 511| Step: 0
Training loss: 1.556675672531128
Validation loss: 1.9864423274993896

Epoch: 5| Step: 1
Training loss: 1.2654380798339844
Validation loss: 1.977689414895991

Epoch: 5| Step: 2
Training loss: 1.2179042100906372
Validation loss: 1.969901410482263

Epoch: 5| Step: 3
Training loss: 1.1141111850738525
Validation loss: 1.9703787783140778

Epoch: 5| Step: 4
Training loss: 1.6328823566436768
Validation loss: 1.9785005200293757

Epoch: 5| Step: 5
Training loss: 1.082188367843628
Validation loss: 1.9807311540008874

Epoch: 5| Step: 6
Training loss: 1.5219981670379639
Validation loss: 1.9737674138879264

Epoch: 5| Step: 7
Training loss: 1.4662129878997803
Validation loss: 1.977427149331698

Epoch: 5| Step: 8
Training loss: 1.3332716226577759
Validation loss: 1.994858467450706

Epoch: 5| Step: 9
Training loss: 1.0568413734436035
Validation loss: 1.9797797972156155

Epoch: 5| Step: 10
Training loss: 0.6369680166244507
Validation loss: 1.9446057094040738

Epoch: 512| Step: 0
Training loss: 1.029705286026001
Validation loss: 1.9785082622240948

Epoch: 5| Step: 1
Training loss: 0.7057554125785828
Validation loss: 1.9992391576049149

Epoch: 5| Step: 2
Training loss: 1.11154305934906
Validation loss: 1.9979611225025629

Epoch: 5| Step: 3
Training loss: 1.1980005502700806
Validation loss: 1.9669957827496272

Epoch: 5| Step: 4
Training loss: 1.57871413230896
Validation loss: 1.9990083017656881

Epoch: 5| Step: 5
Training loss: 1.4058680534362793
Validation loss: 1.9907122337689964

Epoch: 5| Step: 6
Training loss: 1.4509142637252808
Validation loss: 2.023839504488053

Epoch: 5| Step: 7
Training loss: 0.9324042201042175
Validation loss: 1.9922758558745026

Epoch: 5| Step: 8
Training loss: 1.2965110540390015
Validation loss: 1.9525002946135819

Epoch: 5| Step: 9
Training loss: 1.2855037450790405
Validation loss: 2.0425763232733614

Epoch: 5| Step: 10
Training loss: 1.6821197271347046
Validation loss: 1.9628820137311054

Epoch: 513| Step: 0
Training loss: 1.309039831161499
Validation loss: 1.9402261369971818

Epoch: 5| Step: 1
Training loss: 1.4243519306182861
Validation loss: 2.004667984542026

Epoch: 5| Step: 2
Training loss: 1.886804223060608
Validation loss: 1.9859808747486403

Epoch: 5| Step: 3
Training loss: 1.350486397743225
Validation loss: 2.0267077748493483

Epoch: 5| Step: 4
Training loss: 1.2983806133270264
Validation loss: 1.9886434642217492

Epoch: 5| Step: 5
Training loss: 0.7331900596618652
Validation loss: 1.9645393433109406

Epoch: 5| Step: 6
Training loss: 1.6258872747421265
Validation loss: 1.9779826236027542

Epoch: 5| Step: 7
Training loss: 1.5518752336502075
Validation loss: 1.9707446123964043

Epoch: 5| Step: 8
Training loss: 1.0032936334609985
Validation loss: 1.9585446747400428

Epoch: 5| Step: 9
Training loss: 1.141054391860962
Validation loss: 1.9630485978177799

Epoch: 5| Step: 10
Training loss: 1.2616883516311646
Validation loss: 1.9773349531235234

Epoch: 514| Step: 0
Training loss: 1.3391600847244263
Validation loss: 2.0023338897253877

Epoch: 5| Step: 1
Training loss: 0.8146511316299438
Validation loss: 1.9822584365003852

Epoch: 5| Step: 2
Training loss: 1.267161250114441
Validation loss: 2.025908303517167

Epoch: 5| Step: 3
Training loss: 1.015743374824524
Validation loss: 2.0334803724801667

Epoch: 5| Step: 4
Training loss: 1.8557751178741455
Validation loss: 1.9883291362434306

Epoch: 5| Step: 5
Training loss: 0.9345191717147827
Validation loss: 2.031819442267059

Epoch: 5| Step: 6
Training loss: 1.0198476314544678
Validation loss: 2.061012714139877

Epoch: 5| Step: 7
Training loss: 1.996355414390564
Validation loss: 2.0584758456035326

Epoch: 5| Step: 8
Training loss: 0.9523938894271851
Validation loss: 2.017873590992343

Epoch: 5| Step: 9
Training loss: 1.1133005619049072
Validation loss: 2.0229299734997492

Epoch: 5| Step: 10
Training loss: 2.0688540935516357
Validation loss: 2.0151526261401433

Epoch: 515| Step: 0
Training loss: 1.2575807571411133
Validation loss: 1.9987977115056847

Epoch: 5| Step: 1
Training loss: 1.003189206123352
Validation loss: 2.030026520452192

Epoch: 5| Step: 2
Training loss: 0.8509138226509094
Validation loss: 1.9966995972459034

Epoch: 5| Step: 3
Training loss: 1.1927993297576904
Validation loss: 1.9786195998550744

Epoch: 5| Step: 4
Training loss: 1.840935468673706
Validation loss: 2.0261338526202786

Epoch: 5| Step: 5
Training loss: 1.15459144115448
Validation loss: 1.9449121131691882

Epoch: 5| Step: 6
Training loss: 1.412401795387268
Validation loss: 1.9878336306541198

Epoch: 5| Step: 7
Training loss: 1.418865442276001
Validation loss: 1.9867138760064238

Epoch: 5| Step: 8
Training loss: 1.023415207862854
Validation loss: 1.924042986285302

Epoch: 5| Step: 9
Training loss: 1.5135464668273926
Validation loss: 1.968497194269652

Epoch: 5| Step: 10
Training loss: 1.3485051393508911
Validation loss: 1.9767803889448925

Epoch: 516| Step: 0
Training loss: 1.5557359457015991
Validation loss: 2.0076318479353383

Epoch: 5| Step: 1
Training loss: 1.0386773347854614
Validation loss: 2.01018201920294

Epoch: 5| Step: 2
Training loss: 0.9218740463256836
Validation loss: 1.943501813437349

Epoch: 5| Step: 3
Training loss: 0.8063153028488159
Validation loss: 1.9773076324052707

Epoch: 5| Step: 4
Training loss: 1.7841520309448242
Validation loss: 1.952463553797814

Epoch: 5| Step: 5
Training loss: 1.4855458736419678
Validation loss: 1.9942598445441133

Epoch: 5| Step: 6
Training loss: 1.179465889930725
Validation loss: 1.9185819472036054

Epoch: 5| Step: 7
Training loss: 1.0500545501708984
Validation loss: 1.970509498350082

Epoch: 5| Step: 8
Training loss: 1.0347788333892822
Validation loss: 1.9687587753418954

Epoch: 5| Step: 9
Training loss: 2.105689764022827
Validation loss: 1.9934947644510577

Epoch: 5| Step: 10
Training loss: 1.1898525953292847
Validation loss: 1.995548403391274

Epoch: 517| Step: 0
Training loss: 1.1338586807250977
Validation loss: 1.987930849034299

Epoch: 5| Step: 1
Training loss: 1.6392672061920166
Validation loss: 1.991956785161008

Epoch: 5| Step: 2
Training loss: 1.2110965251922607
Validation loss: 1.9665144464021087

Epoch: 5| Step: 3
Training loss: 0.9192697405815125
Validation loss: 1.9939259713695896

Epoch: 5| Step: 4
Training loss: 1.5351505279541016
Validation loss: 2.013869753447912

Epoch: 5| Step: 5
Training loss: 1.1478667259216309
Validation loss: 1.9618135908598542

Epoch: 5| Step: 6
Training loss: 1.7589805126190186
Validation loss: 2.0063850456668484

Epoch: 5| Step: 7
Training loss: 1.2198655605316162
Validation loss: 2.007294867628364

Epoch: 5| Step: 8
Training loss: 0.8049729466438293
Validation loss: 1.9952882566759664

Epoch: 5| Step: 9
Training loss: 1.4688847064971924
Validation loss: 1.9776215502010879

Epoch: 5| Step: 10
Training loss: 1.456986665725708
Validation loss: 2.014462478699223

Epoch: 518| Step: 0
Training loss: 1.1040481328964233
Validation loss: 1.9918186536399267

Epoch: 5| Step: 1
Training loss: 1.0058534145355225
Validation loss: 1.9706571563597648

Epoch: 5| Step: 2
Training loss: 1.4299819469451904
Validation loss: 2.013470667664723

Epoch: 5| Step: 3
Training loss: 1.0149867534637451
Validation loss: 1.9647828814803914

Epoch: 5| Step: 4
Training loss: 1.2846693992614746
Validation loss: 2.0090326006694506

Epoch: 5| Step: 5
Training loss: 1.4915002584457397
Validation loss: 1.9973058290379022

Epoch: 5| Step: 6
Training loss: 0.7367444038391113
Validation loss: 1.9722555542504916

Epoch: 5| Step: 7
Training loss: 1.2202876806259155
Validation loss: 1.9831819393301522

Epoch: 5| Step: 8
Training loss: 1.4949649572372437
Validation loss: 2.0154473948222336

Epoch: 5| Step: 9
Training loss: 1.491249680519104
Validation loss: 1.9940941449134582

Epoch: 5| Step: 10
Training loss: 1.392155647277832
Validation loss: 1.9770778250950638

Epoch: 519| Step: 0
Training loss: 1.0684829950332642
Validation loss: 1.9806008595292286

Epoch: 5| Step: 1
Training loss: 0.8571977615356445
Validation loss: 1.9835398966266262

Epoch: 5| Step: 2
Training loss: 1.3322608470916748
Validation loss: 1.985332973541752

Epoch: 5| Step: 3
Training loss: 1.7236543893814087
Validation loss: 1.9608574144301876

Epoch: 5| Step: 4
Training loss: 1.0128090381622314
Validation loss: 2.010258533621347

Epoch: 5| Step: 5
Training loss: 1.3348817825317383
Validation loss: 1.997938773965323

Epoch: 5| Step: 6
Training loss: 0.9806909561157227
Validation loss: 2.033639000308129

Epoch: 5| Step: 7
Training loss: 1.4879374504089355
Validation loss: 1.984758723166681

Epoch: 5| Step: 8
Training loss: 0.9769684672355652
Validation loss: 1.981284067194949

Epoch: 5| Step: 9
Training loss: 1.3403067588806152
Validation loss: 2.039280027471563

Epoch: 5| Step: 10
Training loss: 1.4300390481948853
Validation loss: 2.0332021790166057

Epoch: 520| Step: 0
Training loss: 1.1100172996520996
Validation loss: 2.045924776343889

Epoch: 5| Step: 1
Training loss: 0.7708829641342163
Validation loss: 2.0279126282661193

Epoch: 5| Step: 2
Training loss: 1.8959791660308838
Validation loss: 1.9574383663874801

Epoch: 5| Step: 3
Training loss: 1.2674230337142944
Validation loss: 1.9874392299241916

Epoch: 5| Step: 4
Training loss: 1.6972744464874268
Validation loss: 2.020156180986794

Epoch: 5| Step: 5
Training loss: 0.8626655340194702
Validation loss: 1.9661469972261818

Epoch: 5| Step: 6
Training loss: 1.1303659677505493
Validation loss: 1.994060859885267

Epoch: 5| Step: 7
Training loss: 0.8619939684867859
Validation loss: 1.9476935914767686

Epoch: 5| Step: 8
Training loss: 1.2084304094314575
Validation loss: 1.9757031932953866

Epoch: 5| Step: 9
Training loss: 1.5830504894256592
Validation loss: 2.0012486121987783

Epoch: 5| Step: 10
Training loss: 1.2860039472579956
Validation loss: 1.9665933937154791

Epoch: 521| Step: 0
Training loss: 1.3673787117004395
Validation loss: 1.9740381868936683

Epoch: 5| Step: 1
Training loss: 1.2603495121002197
Validation loss: 2.0244773011053763

Epoch: 5| Step: 2
Training loss: 1.3366096019744873
Validation loss: 2.0113291791690293

Epoch: 5| Step: 3
Training loss: 1.0418694019317627
Validation loss: 1.951923381897711

Epoch: 5| Step: 4
Training loss: 0.9936975240707397
Validation loss: 2.0177990595499673

Epoch: 5| Step: 5
Training loss: 1.3510279655456543
Validation loss: 2.0299829795796382

Epoch: 5| Step: 6
Training loss: 1.1450923681259155
Validation loss: 2.026502909198884

Epoch: 5| Step: 7
Training loss: 1.499024748802185
Validation loss: 2.0683074971681

Epoch: 5| Step: 8
Training loss: 0.9986240267753601
Validation loss: 2.065787349977801

Epoch: 5| Step: 9
Training loss: 1.3252842426300049
Validation loss: 2.068657454623971

Epoch: 5| Step: 10
Training loss: 1.4468622207641602
Validation loss: 2.0207192590159755

Epoch: 522| Step: 0
Training loss: 1.7104495763778687
Validation loss: 2.06440076264002

Epoch: 5| Step: 1
Training loss: 1.1400705575942993
Validation loss: 2.075906102375318

Epoch: 5| Step: 2
Training loss: 1.5914231538772583
Validation loss: 2.001156578781784

Epoch: 5| Step: 3
Training loss: 1.4471104145050049
Validation loss: 2.0243627281599146

Epoch: 5| Step: 4
Training loss: 1.2160084247589111
Validation loss: 2.008000096967143

Epoch: 5| Step: 5
Training loss: 1.006567120552063
Validation loss: 2.019597068909676

Epoch: 5| Step: 6
Training loss: 1.053871989250183
Validation loss: 1.984778424744965

Epoch: 5| Step: 7
Training loss: 1.4988090991973877
Validation loss: 1.9641697483678018

Epoch: 5| Step: 8
Training loss: 1.1835486888885498
Validation loss: 1.9788587670172415

Epoch: 5| Step: 9
Training loss: 1.2288225889205933
Validation loss: 1.9967500753300165

Epoch: 5| Step: 10
Training loss: 0.9787450432777405
Validation loss: 1.9545513378676547

Epoch: 523| Step: 0
Training loss: 1.3396809101104736
Validation loss: 1.9791206980264315

Epoch: 5| Step: 1
Training loss: 1.0512984991073608
Validation loss: 2.015157797003305

Epoch: 5| Step: 2
Training loss: 1.3204419612884521
Validation loss: 1.986630985813756

Epoch: 5| Step: 3
Training loss: 1.1753456592559814
Validation loss: 1.9887496322713873

Epoch: 5| Step: 4
Training loss: 1.3395090103149414
Validation loss: 1.9753439708422589

Epoch: 5| Step: 5
Training loss: 1.7140785455703735
Validation loss: 1.975143995336307

Epoch: 5| Step: 6
Training loss: 0.999075710773468
Validation loss: 1.994301752377582

Epoch: 5| Step: 7
Training loss: 1.186091423034668
Validation loss: 2.032924423935593

Epoch: 5| Step: 8
Training loss: 1.0796020030975342
Validation loss: 2.0408877198414137

Epoch: 5| Step: 9
Training loss: 1.6790835857391357
Validation loss: 2.018398989913284

Epoch: 5| Step: 10
Training loss: 1.2604091167449951
Validation loss: 2.038408148673273

Epoch: 524| Step: 0
Training loss: 1.1008894443511963
Validation loss: 2.024389925823417

Epoch: 5| Step: 1
Training loss: 1.034002661705017
Validation loss: 2.0326313408472205

Epoch: 5| Step: 2
Training loss: 1.1197131872177124
Validation loss: 1.9807403395252843

Epoch: 5| Step: 3
Training loss: 1.644152283668518
Validation loss: 2.0162543981306014

Epoch: 5| Step: 4
Training loss: 1.0443713665008545
Validation loss: 1.950648841037545

Epoch: 5| Step: 5
Training loss: 1.0005998611450195
Validation loss: 1.9709735173051075

Epoch: 5| Step: 6
Training loss: 1.3649464845657349
Validation loss: 1.9715276507921116

Epoch: 5| Step: 7
Training loss: 1.3371905088424683
Validation loss: 1.9816775975688812

Epoch: 5| Step: 8
Training loss: 1.1472887992858887
Validation loss: 1.9505129475747385

Epoch: 5| Step: 9
Training loss: 1.5356981754302979
Validation loss: 1.9738458766732165

Epoch: 5| Step: 10
Training loss: 1.7057920694351196
Validation loss: 1.9824861505980134

Epoch: 525| Step: 0
Training loss: 1.4203529357910156
Validation loss: 1.9990843598560621

Epoch: 5| Step: 1
Training loss: 1.085903286933899
Validation loss: 2.0037374804096837

Epoch: 5| Step: 2
Training loss: 1.2628635168075562
Validation loss: 1.976846351418444

Epoch: 5| Step: 3
Training loss: 1.1460883617401123
Validation loss: 1.9708329336617583

Epoch: 5| Step: 4
Training loss: 1.592305064201355
Validation loss: 2.037437273610023

Epoch: 5| Step: 5
Training loss: 1.8423783779144287
Validation loss: 1.987037456163796

Epoch: 5| Step: 6
Training loss: 0.42041659355163574
Validation loss: 1.9844433825503114

Epoch: 5| Step: 7
Training loss: 1.2451092004776
Validation loss: 1.9914809862772624

Epoch: 5| Step: 8
Training loss: 1.236266851425171
Validation loss: 2.000516149305528

Epoch: 5| Step: 9
Training loss: 1.364542007446289
Validation loss: 1.9766007623364847

Epoch: 5| Step: 10
Training loss: 1.2740378379821777
Validation loss: 1.966181903757075

Epoch: 526| Step: 0
Training loss: 1.2027418613433838
Validation loss: 2.0022243658701577

Epoch: 5| Step: 1
Training loss: 1.5866098403930664
Validation loss: 1.970973745469124

Epoch: 5| Step: 2
Training loss: 0.826664924621582
Validation loss: 2.003513205435968

Epoch: 5| Step: 3
Training loss: 1.7581819295883179
Validation loss: 1.9897916124713035

Epoch: 5| Step: 4
Training loss: 0.9050835371017456
Validation loss: 1.9788745526344544

Epoch: 5| Step: 5
Training loss: 0.9759224057197571
Validation loss: 2.0102804937670307

Epoch: 5| Step: 6
Training loss: 1.506888747215271
Validation loss: 1.9891619913039669

Epoch: 5| Step: 7
Training loss: 1.162821888923645
Validation loss: 2.0053181289344706

Epoch: 5| Step: 8
Training loss: 1.4846500158309937
Validation loss: 1.9840755437010078

Epoch: 5| Step: 9
Training loss: 1.1170278787612915
Validation loss: 1.9829603061881116

Epoch: 5| Step: 10
Training loss: 0.9880799651145935
Validation loss: 1.9682144631621659

Epoch: 527| Step: 0
Training loss: 1.4240964651107788
Validation loss: 1.9598719471244401

Epoch: 5| Step: 1
Training loss: 1.5713720321655273
Validation loss: 1.9841865480587046

Epoch: 5| Step: 2
Training loss: 1.4322559833526611
Validation loss: 1.962266238786841

Epoch: 5| Step: 3
Training loss: 0.9231996536254883
Validation loss: 1.9876528042618946

Epoch: 5| Step: 4
Training loss: 1.2691410779953003
Validation loss: 1.938931554876348

Epoch: 5| Step: 5
Training loss: 1.1490590572357178
Validation loss: 1.9749947709421958

Epoch: 5| Step: 6
Training loss: 1.1915082931518555
Validation loss: 1.9625867662891265

Epoch: 5| Step: 7
Training loss: 1.230992078781128
Validation loss: 1.9977873102311166

Epoch: 5| Step: 8
Training loss: 1.34688401222229
Validation loss: 2.007633424574329

Epoch: 5| Step: 9
Training loss: 1.0129878520965576
Validation loss: 2.0058331233198925

Epoch: 5| Step: 10
Training loss: 1.4357192516326904
Validation loss: 1.9793428951694119

Epoch: 528| Step: 0
Training loss: 0.8989123106002808
Validation loss: 2.00029819755144

Epoch: 5| Step: 1
Training loss: 1.4361040592193604
Validation loss: 2.0039727764744915

Epoch: 5| Step: 2
Training loss: 1.0897823572158813
Validation loss: 1.9392129887816727

Epoch: 5| Step: 3
Training loss: 1.283926248550415
Validation loss: 2.0174818295304493

Epoch: 5| Step: 4
Training loss: 1.402758002281189
Validation loss: 1.963093194910275

Epoch: 5| Step: 5
Training loss: 1.0375455617904663
Validation loss: 1.979719018423429

Epoch: 5| Step: 6
Training loss: 1.3953269720077515
Validation loss: 2.01359296870488

Epoch: 5| Step: 7
Training loss: 1.593920350074768
Validation loss: 1.9776506872587307

Epoch: 5| Step: 8
Training loss: 1.0242440700531006
Validation loss: 1.9860856199777255

Epoch: 5| Step: 9
Training loss: 1.0960693359375
Validation loss: 2.0338142213001045

Epoch: 5| Step: 10
Training loss: 1.4210662841796875
Validation loss: 2.0245694844953475

Epoch: 529| Step: 0
Training loss: 0.8939769864082336
Validation loss: 1.9427828186301774

Epoch: 5| Step: 1
Training loss: 1.6585384607315063
Validation loss: 1.9556850259022047

Epoch: 5| Step: 2
Training loss: 1.2752392292022705
Validation loss: 1.9681271481257614

Epoch: 5| Step: 3
Training loss: 1.4416471719741821
Validation loss: 1.9999934037526448

Epoch: 5| Step: 4
Training loss: 1.6815121173858643
Validation loss: 1.9765976039312219

Epoch: 5| Step: 5
Training loss: 1.181555986404419
Validation loss: 2.0231467549518873

Epoch: 5| Step: 6
Training loss: 0.7982178330421448
Validation loss: 1.9710774960056427

Epoch: 5| Step: 7
Training loss: 0.6477616429328918
Validation loss: 1.9797345925402898

Epoch: 5| Step: 8
Training loss: 1.5254913568496704
Validation loss: 1.9201889704632502

Epoch: 5| Step: 9
Training loss: 1.1313765048980713
Validation loss: 1.960011548893426

Epoch: 5| Step: 10
Training loss: 1.641930341720581
Validation loss: 1.9543281703866937

Epoch: 530| Step: 0
Training loss: 0.8929557800292969
Validation loss: 1.9888626426778815

Epoch: 5| Step: 1
Training loss: 1.4738390445709229
Validation loss: 1.9768754282305319

Epoch: 5| Step: 2
Training loss: 1.4910027980804443
Validation loss: 2.0202942637987036

Epoch: 5| Step: 3
Training loss: 1.2203214168548584
Validation loss: 1.962055895918159

Epoch: 5| Step: 4
Training loss: 1.174735426902771
Validation loss: 1.9979213027543918

Epoch: 5| Step: 5
Training loss: 1.3601162433624268
Validation loss: 1.9703839017498879

Epoch: 5| Step: 6
Training loss: 1.7308979034423828
Validation loss: 2.025686776766213

Epoch: 5| Step: 7
Training loss: 1.025853157043457
Validation loss: 1.979232454812655

Epoch: 5| Step: 8
Training loss: 1.1384199857711792
Validation loss: 1.9808111331796134

Epoch: 5| Step: 9
Training loss: 0.895868182182312
Validation loss: 1.992957381791966

Epoch: 5| Step: 10
Training loss: 1.3460239171981812
Validation loss: 1.9715711775646414

Epoch: 531| Step: 0
Training loss: 0.7438490390777588
Validation loss: 2.0162463277898808

Epoch: 5| Step: 1
Training loss: 1.1345123052597046
Validation loss: 1.994780699412028

Epoch: 5| Step: 2
Training loss: 1.1736208200454712
Validation loss: 2.0134203562172512

Epoch: 5| Step: 3
Training loss: 1.4603326320648193
Validation loss: 1.9999445587076166

Epoch: 5| Step: 4
Training loss: 1.121825933456421
Validation loss: 1.9748280676462318

Epoch: 5| Step: 5
Training loss: 1.692731499671936
Validation loss: 1.95090740214112

Epoch: 5| Step: 6
Training loss: 1.8173967599868774
Validation loss: 1.9767628100610548

Epoch: 5| Step: 7
Training loss: 1.6317415237426758
Validation loss: 2.03174183189228

Epoch: 5| Step: 8
Training loss: 1.1474969387054443
Validation loss: 1.955769549133957

Epoch: 5| Step: 9
Training loss: 1.1823378801345825
Validation loss: 1.9934821667209748

Epoch: 5| Step: 10
Training loss: 1.0666934251785278
Validation loss: 1.9930781382386402

Epoch: 532| Step: 0
Training loss: 1.0986286401748657
Validation loss: 1.9584709495626471

Epoch: 5| Step: 1
Training loss: 1.019618272781372
Validation loss: 1.9963337400908112

Epoch: 5| Step: 2
Training loss: 1.4935420751571655
Validation loss: 1.989073581593011

Epoch: 5| Step: 3
Training loss: 1.7654310464859009
Validation loss: 1.9903135504773868

Epoch: 5| Step: 4
Training loss: 1.126761794090271
Validation loss: 1.9637702947021813

Epoch: 5| Step: 5
Training loss: 1.4690630435943604
Validation loss: 1.9647011731260566

Epoch: 5| Step: 6
Training loss: 1.2891987562179565
Validation loss: 1.9928149484818982

Epoch: 5| Step: 7
Training loss: 1.1030311584472656
Validation loss: 1.978200166456161

Epoch: 5| Step: 8
Training loss: 1.4246509075164795
Validation loss: 1.9977264968297814

Epoch: 5| Step: 9
Training loss: 1.063509225845337
Validation loss: 1.996442751217914

Epoch: 5| Step: 10
Training loss: 0.8707171678543091
Validation loss: 1.960505380425402

Epoch: 533| Step: 0
Training loss: 1.2260912656784058
Validation loss: 1.9966662596630793

Epoch: 5| Step: 1
Training loss: 0.9172215461730957
Validation loss: 1.9827718388649724

Epoch: 5| Step: 2
Training loss: 1.326859712600708
Validation loss: 1.992885205053514

Epoch: 5| Step: 3
Training loss: 1.6558189392089844
Validation loss: 2.0027444644640853

Epoch: 5| Step: 4
Training loss: 1.0467052459716797
Validation loss: 1.982154179644841

Epoch: 5| Step: 5
Training loss: 1.2672092914581299
Validation loss: 2.032318308789243

Epoch: 5| Step: 6
Training loss: 1.122524619102478
Validation loss: 1.9736073004302157

Epoch: 5| Step: 7
Training loss: 1.2615693807601929
Validation loss: 1.9979217898461126

Epoch: 5| Step: 8
Training loss: 1.5252501964569092
Validation loss: 2.022288251948613

Epoch: 5| Step: 9
Training loss: 1.3950797319412231
Validation loss: 1.9864389934847433

Epoch: 5| Step: 10
Training loss: 1.0451059341430664
Validation loss: 2.0826473518084456

Epoch: 534| Step: 0
Training loss: 1.5385725498199463
Validation loss: 1.938935133718675

Epoch: 5| Step: 1
Training loss: 0.980366051197052
Validation loss: 2.0133773549910514

Epoch: 5| Step: 2
Training loss: 1.6029306650161743
Validation loss: 1.9824193113593644

Epoch: 5| Step: 3
Training loss: 1.1073763370513916
Validation loss: 2.0022355228342037

Epoch: 5| Step: 4
Training loss: 1.2036287784576416
Validation loss: 1.9825792863804808

Epoch: 5| Step: 5
Training loss: 1.368221640586853
Validation loss: 2.0149051553459576

Epoch: 5| Step: 6
Training loss: 0.7398965954780579
Validation loss: 1.9841798018383723

Epoch: 5| Step: 7
Training loss: 1.8294131755828857
Validation loss: 1.9771627995275682

Epoch: 5| Step: 8
Training loss: 1.138432502746582
Validation loss: 2.0064863363901773

Epoch: 5| Step: 9
Training loss: 1.3026692867279053
Validation loss: 1.9938209723400813

Epoch: 5| Step: 10
Training loss: 0.8856140971183777
Validation loss: 1.963666860775281

Epoch: 535| Step: 0
Training loss: 1.4763447046279907
Validation loss: 1.9980161587397258

Epoch: 5| Step: 1
Training loss: 1.0552341938018799
Validation loss: 1.9717464370112265

Epoch: 5| Step: 2
Training loss: 1.2442516088485718
Validation loss: 1.9694379529645365

Epoch: 5| Step: 3
Training loss: 1.1776546239852905
Validation loss: 2.0011007247432584

Epoch: 5| Step: 4
Training loss: 1.2321778535842896
Validation loss: 2.015097020774759

Epoch: 5| Step: 5
Training loss: 1.5998669862747192
Validation loss: 2.034590721130371

Epoch: 5| Step: 6
Training loss: 1.1568933725357056
Validation loss: 2.0213414956164617

Epoch: 5| Step: 7
Training loss: 1.1496115922927856
Validation loss: 1.9965197245279949

Epoch: 5| Step: 8
Training loss: 0.8867740631103516
Validation loss: 1.9605505722825245

Epoch: 5| Step: 9
Training loss: 1.4000544548034668
Validation loss: 1.989938292452084

Epoch: 5| Step: 10
Training loss: 1.5687743425369263
Validation loss: 1.9930467938864103

Epoch: 536| Step: 0
Training loss: 0.9077996015548706
Validation loss: 2.0187814158778035

Epoch: 5| Step: 1
Training loss: 1.2178409099578857
Validation loss: 1.9830739703229678

Epoch: 5| Step: 2
Training loss: 1.180328369140625
Validation loss: 2.0110767951575657

Epoch: 5| Step: 3
Training loss: 1.657727837562561
Validation loss: 1.9977724244517665

Epoch: 5| Step: 4
Training loss: 1.4300918579101562
Validation loss: 1.9954946156471007

Epoch: 5| Step: 5
Training loss: 0.9328726530075073
Validation loss: 1.9518785707412227

Epoch: 5| Step: 6
Training loss: 1.041902780532837
Validation loss: 1.9981238021645495

Epoch: 5| Step: 7
Training loss: 0.9405537843704224
Validation loss: 2.0311616992437713

Epoch: 5| Step: 8
Training loss: 1.1813275814056396
Validation loss: 1.9667848361435758

Epoch: 5| Step: 9
Training loss: 1.721723198890686
Validation loss: 1.9914290238452215

Epoch: 5| Step: 10
Training loss: 1.4237531423568726
Validation loss: 2.0054651127066663

Epoch: 537| Step: 0
Training loss: 1.3208777904510498
Validation loss: 1.993510470595411

Epoch: 5| Step: 1
Training loss: 1.3468472957611084
Validation loss: 1.9725703923932967

Epoch: 5| Step: 2
Training loss: 1.3576854467391968
Validation loss: 1.9718538586811354

Epoch: 5| Step: 3
Training loss: 1.0749846696853638
Validation loss: 2.002294240459319

Epoch: 5| Step: 4
Training loss: 1.9213240146636963
Validation loss: 1.9760823442089943

Epoch: 5| Step: 5
Training loss: 1.0585530996322632
Validation loss: 1.961917805415328

Epoch: 5| Step: 6
Training loss: 0.9176651239395142
Validation loss: 2.010086182625063

Epoch: 5| Step: 7
Training loss: 1.431647539138794
Validation loss: 1.984393577421865

Epoch: 5| Step: 8
Training loss: 1.143726110458374
Validation loss: 1.9691955671515515

Epoch: 5| Step: 9
Training loss: 1.0008715391159058
Validation loss: 1.9926424500762776

Epoch: 5| Step: 10
Training loss: 1.3156803846359253
Validation loss: 2.010022122372863

Epoch: 538| Step: 0
Training loss: 1.540233850479126
Validation loss: 1.9995712644310408

Epoch: 5| Step: 1
Training loss: 1.1811450719833374
Validation loss: 1.9764546040565736

Epoch: 5| Step: 2
Training loss: 1.224637746810913
Validation loss: 1.9914610334621963

Epoch: 5| Step: 3
Training loss: 1.0290453433990479
Validation loss: 1.9988045794989473

Epoch: 5| Step: 4
Training loss: 1.4728240966796875
Validation loss: 2.020588158279337

Epoch: 5| Step: 5
Training loss: 1.0852606296539307
Validation loss: 2.0678992322696153

Epoch: 5| Step: 6
Training loss: 0.6885142922401428
Validation loss: 2.024178099888627

Epoch: 5| Step: 7
Training loss: 1.6240253448486328
Validation loss: 1.987558223867929

Epoch: 5| Step: 8
Training loss: 0.9937429428100586
Validation loss: 2.048231832442745

Epoch: 5| Step: 9
Training loss: 1.4816033840179443
Validation loss: 1.9750673181267195

Epoch: 5| Step: 10
Training loss: 1.3207987546920776
Validation loss: 2.0060518326297885

Epoch: 539| Step: 0
Training loss: 0.8939620852470398
Validation loss: 2.002699589216581

Epoch: 5| Step: 1
Training loss: 1.5498749017715454
Validation loss: 2.0042011814732708

Epoch: 5| Step: 2
Training loss: 0.9303730726242065
Validation loss: 2.017735540225942

Epoch: 5| Step: 3
Training loss: 1.5133365392684937
Validation loss: 2.034490439199632

Epoch: 5| Step: 4
Training loss: 1.5804446935653687
Validation loss: 1.9909916077890704

Epoch: 5| Step: 5
Training loss: 1.230452537536621
Validation loss: 1.9938945975354923

Epoch: 5| Step: 6
Training loss: 1.3431532382965088
Validation loss: 1.9927412438136276

Epoch: 5| Step: 7
Training loss: 1.170623540878296
Validation loss: 2.005855990994361

Epoch: 5| Step: 8
Training loss: 1.381204605102539
Validation loss: 1.9809902329598703

Epoch: 5| Step: 9
Training loss: 0.9734594225883484
Validation loss: 1.988771246325585

Epoch: 5| Step: 10
Training loss: 1.0009117126464844
Validation loss: 2.0272219911698373

Epoch: 540| Step: 0
Training loss: 1.1528736352920532
Validation loss: 1.9939475572237404

Epoch: 5| Step: 1
Training loss: 1.4749130010604858
Validation loss: 2.0018458058757167

Epoch: 5| Step: 2
Training loss: 1.1732500791549683
Validation loss: 2.050910952270672

Epoch: 5| Step: 3
Training loss: 1.030098557472229
Validation loss: 1.9956823561781196

Epoch: 5| Step: 4
Training loss: 1.3085614442825317
Validation loss: 1.966927473263074

Epoch: 5| Step: 5
Training loss: 0.9872429966926575
Validation loss: 2.032420548059607

Epoch: 5| Step: 6
Training loss: 1.154553771018982
Validation loss: 1.9846287030045704

Epoch: 5| Step: 7
Training loss: 1.1079574823379517
Validation loss: 1.96565830579368

Epoch: 5| Step: 8
Training loss: 1.3369909524917603
Validation loss: 2.027809222539266

Epoch: 5| Step: 9
Training loss: 1.3425613641738892
Validation loss: 1.9985511969494563

Epoch: 5| Step: 10
Training loss: 1.4285684823989868
Validation loss: 2.0253189609896753

Epoch: 541| Step: 0
Training loss: 1.6820615530014038
Validation loss: 1.960959449250211

Epoch: 5| Step: 1
Training loss: 0.7203758955001831
Validation loss: 2.0189606117945846

Epoch: 5| Step: 2
Training loss: 1.1571681499481201
Validation loss: 2.055203204513878

Epoch: 5| Step: 3
Training loss: 1.2284501791000366
Validation loss: 2.002761674183671

Epoch: 5| Step: 4
Training loss: 1.635310173034668
Validation loss: 1.9898710430309337

Epoch: 5| Step: 5
Training loss: 0.9018285870552063
Validation loss: 1.9668608506520588

Epoch: 5| Step: 6
Training loss: 1.2556463479995728
Validation loss: 1.931786749952583

Epoch: 5| Step: 7
Training loss: 1.371816873550415
Validation loss: 1.9723009294079197

Epoch: 5| Step: 8
Training loss: 1.3675695657730103
Validation loss: 1.9917941413899904

Epoch: 5| Step: 9
Training loss: 1.3663122653961182
Validation loss: 2.0195725605052006

Epoch: 5| Step: 10
Training loss: 1.1104847192764282
Validation loss: 1.9715189292866697

Epoch: 542| Step: 0
Training loss: 0.7975822687149048
Validation loss: 2.014185436310307

Epoch: 5| Step: 1
Training loss: 1.1982219219207764
Validation loss: 1.993445554087239

Epoch: 5| Step: 2
Training loss: 0.9994527697563171
Validation loss: 1.9706564154676212

Epoch: 5| Step: 3
Training loss: 1.7079317569732666
Validation loss: 2.0011819139603646

Epoch: 5| Step: 4
Training loss: 1.083176612854004
Validation loss: 1.9814967186220231

Epoch: 5| Step: 5
Training loss: 1.2057209014892578
Validation loss: 1.9570798873901367

Epoch: 5| Step: 6
Training loss: 1.644372582435608
Validation loss: 2.009696316975419

Epoch: 5| Step: 7
Training loss: 1.0010640621185303
Validation loss: 1.999570487647928

Epoch: 5| Step: 8
Training loss: 1.114892601966858
Validation loss: 1.9663046252342962

Epoch: 5| Step: 9
Training loss: 1.867378830909729
Validation loss: 2.017200949371502

Epoch: 5| Step: 10
Training loss: 0.9747521877288818
Validation loss: 1.9600234236768497

Epoch: 543| Step: 0
Training loss: 1.2323569059371948
Validation loss: 2.00675723373249

Epoch: 5| Step: 1
Training loss: 0.929449737071991
Validation loss: 2.006305049824458

Epoch: 5| Step: 2
Training loss: 1.3577827215194702
Validation loss: 2.062044782023276

Epoch: 5| Step: 3
Training loss: 1.4016636610031128
Validation loss: 1.987591148704611

Epoch: 5| Step: 4
Training loss: 1.5199248790740967
Validation loss: 2.0100696676520893

Epoch: 5| Step: 5
Training loss: 1.3936774730682373
Validation loss: 2.001997060673211

Epoch: 5| Step: 6
Training loss: 0.9973416328430176
Validation loss: 2.0100474895969516

Epoch: 5| Step: 7
Training loss: 1.4836589097976685
Validation loss: 1.9876792148877216

Epoch: 5| Step: 8
Training loss: 1.2993682622909546
Validation loss: 1.9632348168280818

Epoch: 5| Step: 9
Training loss: 1.0487663745880127
Validation loss: 2.006569000982469

Epoch: 5| Step: 10
Training loss: 0.7598088383674622
Validation loss: 2.028226738334984

Epoch: 544| Step: 0
Training loss: 1.26160728931427
Validation loss: 1.9640070366603073

Epoch: 5| Step: 1
Training loss: 1.0036981105804443
Validation loss: 2.030978011828597

Epoch: 5| Step: 2
Training loss: 1.307315468788147
Validation loss: 1.9676934672940163

Epoch: 5| Step: 3
Training loss: 1.6960432529449463
Validation loss: 2.019723294883646

Epoch: 5| Step: 4
Training loss: 1.7850784063339233
Validation loss: 1.9772662578090545

Epoch: 5| Step: 5
Training loss: 0.7793105840682983
Validation loss: 1.9814301985566334

Epoch: 5| Step: 6
Training loss: 1.2607074975967407
Validation loss: 1.9767982190655125

Epoch: 5| Step: 7
Training loss: 1.7261457443237305
Validation loss: 1.9901804020327907

Epoch: 5| Step: 8
Training loss: 1.1641013622283936
Validation loss: 2.001521236153059

Epoch: 5| Step: 9
Training loss: 0.7149608135223389
Validation loss: 2.0073861845078005

Epoch: 5| Step: 10
Training loss: 0.8125998377799988
Validation loss: 1.9963199707769579

Epoch: 545| Step: 0
Training loss: 1.7103586196899414
Validation loss: 1.9819695667553974

Epoch: 5| Step: 1
Training loss: 1.3474186658859253
Validation loss: 1.9930670081928212

Epoch: 5| Step: 2
Training loss: 1.1925005912780762
Validation loss: 1.9967978231368526

Epoch: 5| Step: 3
Training loss: 1.328756332397461
Validation loss: 2.0229743091008996

Epoch: 5| Step: 4
Training loss: 1.3122270107269287
Validation loss: 1.9847598703958655

Epoch: 5| Step: 5
Training loss: 0.802578330039978
Validation loss: 1.9839944096021755

Epoch: 5| Step: 6
Training loss: 0.9726993441581726
Validation loss: 1.976326278460923

Epoch: 5| Step: 7
Training loss: 1.3205759525299072
Validation loss: 1.9528144508279779

Epoch: 5| Step: 8
Training loss: 1.4346699714660645
Validation loss: 1.971047220691558

Epoch: 5| Step: 9
Training loss: 1.293947458267212
Validation loss: 1.9687163227347917

Epoch: 5| Step: 10
Training loss: 1.3492166996002197
Validation loss: 1.991214757324547

Epoch: 546| Step: 0
Training loss: 1.1129839420318604
Validation loss: 2.0531446600473053

Epoch: 5| Step: 1
Training loss: 0.8397239446640015
Validation loss: 2.017193786559566

Epoch: 5| Step: 2
Training loss: 1.2922372817993164
Validation loss: 2.050475299999278

Epoch: 5| Step: 3
Training loss: 0.9849527478218079
Validation loss: 1.9557220012910905

Epoch: 5| Step: 4
Training loss: 2.039062261581421
Validation loss: 1.9792031652183943

Epoch: 5| Step: 5
Training loss: 1.3772181272506714
Validation loss: 1.9770692548444193

Epoch: 5| Step: 6
Training loss: 1.1579480171203613
Validation loss: 1.970663457788447

Epoch: 5| Step: 7
Training loss: 1.190667748451233
Validation loss: 1.9961140078883017

Epoch: 5| Step: 8
Training loss: 1.8565146923065186
Validation loss: 2.003933378445205

Epoch: 5| Step: 9
Training loss: 0.8088697195053101
Validation loss: 1.9616427293387793

Epoch: 5| Step: 10
Training loss: 1.3049182891845703
Validation loss: 1.9994434361816735

Epoch: 547| Step: 0
Training loss: 0.6321049928665161
Validation loss: 1.9599853766861783

Epoch: 5| Step: 1
Training loss: 0.791419267654419
Validation loss: 2.005715315059949

Epoch: 5| Step: 2
Training loss: 1.1664139032363892
Validation loss: 1.9730931687098678

Epoch: 5| Step: 3
Training loss: 1.4229717254638672
Validation loss: 1.9965507407342233

Epoch: 5| Step: 4
Training loss: 0.9619842767715454
Validation loss: 1.9735478278129333

Epoch: 5| Step: 5
Training loss: 1.237189531326294
Validation loss: 2.000186539465381

Epoch: 5| Step: 6
Training loss: 1.1706621646881104
Validation loss: 1.9589359247556297

Epoch: 5| Step: 7
Training loss: 1.7393373250961304
Validation loss: 2.0011029551106114

Epoch: 5| Step: 8
Training loss: 1.1783013343811035
Validation loss: 2.0473883946736655

Epoch: 5| Step: 9
Training loss: 1.7058699131011963
Validation loss: 2.008635826008294

Epoch: 5| Step: 10
Training loss: 1.3544787168502808
Validation loss: 2.001832926145164

Epoch: 548| Step: 0
Training loss: 1.3634116649627686
Validation loss: 2.0027863235883814

Epoch: 5| Step: 1
Training loss: 1.2416812181472778
Validation loss: 2.0285500967374412

Epoch: 5| Step: 2
Training loss: 1.227136254310608
Validation loss: 2.011289350448116

Epoch: 5| Step: 3
Training loss: 1.364320158958435
Validation loss: 2.013278753526749

Epoch: 5| Step: 4
Training loss: 1.535529375076294
Validation loss: 2.011843283971151

Epoch: 5| Step: 5
Training loss: 1.2649239301681519
Validation loss: 2.0073543261456233

Epoch: 5| Step: 6
Training loss: 0.9936956167221069
Validation loss: 1.9918600346452446

Epoch: 5| Step: 7
Training loss: 1.1294101476669312
Validation loss: 1.958385084265022

Epoch: 5| Step: 8
Training loss: 1.2984778881072998
Validation loss: 2.006964547659761

Epoch: 5| Step: 9
Training loss: 1.1137471199035645
Validation loss: 2.004809207813714

Epoch: 5| Step: 10
Training loss: 0.907235860824585
Validation loss: 1.973749162048422

Epoch: 549| Step: 0
Training loss: 1.4498342275619507
Validation loss: 1.9522785230349469

Epoch: 5| Step: 1
Training loss: 0.9226366877555847
Validation loss: 1.9413853768379457

Epoch: 5| Step: 2
Training loss: 1.2595405578613281
Validation loss: 1.9681961690225909

Epoch: 5| Step: 3
Training loss: 1.797563910484314
Validation loss: 1.9709638523799118

Epoch: 5| Step: 4
Training loss: 0.7352050542831421
Validation loss: 1.9877762756040018

Epoch: 5| Step: 5
Training loss: 1.1089800596237183
Validation loss: 1.9747278933883996

Epoch: 5| Step: 6
Training loss: 1.196187138557434
Validation loss: 1.962333135707404

Epoch: 5| Step: 7
Training loss: 1.3469817638397217
Validation loss: 1.9815015498028006

Epoch: 5| Step: 8
Training loss: 1.534253716468811
Validation loss: 2.0308526203196537

Epoch: 5| Step: 9
Training loss: 1.1539372205734253
Validation loss: 1.9984587725772653

Epoch: 5| Step: 10
Training loss: 1.5076286792755127
Validation loss: 2.039192932908253

Epoch: 550| Step: 0
Training loss: 1.4460372924804688
Validation loss: 1.9751527604236399

Epoch: 5| Step: 1
Training loss: 1.015707015991211
Validation loss: 2.0451062289617394

Epoch: 5| Step: 2
Training loss: 0.8694556355476379
Validation loss: 2.001398996640277

Epoch: 5| Step: 3
Training loss: 1.1019704341888428
Validation loss: 1.969723847604567

Epoch: 5| Step: 4
Training loss: 1.4473575353622437
Validation loss: 2.023539855916013

Epoch: 5| Step: 5
Training loss: 1.7241207361221313
Validation loss: 1.9585408369700115

Epoch: 5| Step: 6
Training loss: 1.1371034383773804
Validation loss: 1.9871976824216946

Epoch: 5| Step: 7
Training loss: 0.8582412600517273
Validation loss: 2.0303363902594453

Epoch: 5| Step: 8
Training loss: 1.4382940530776978
Validation loss: 1.9847681317278134

Epoch: 5| Step: 9
Training loss: 1.418399691581726
Validation loss: 1.9313853376655168

Epoch: 5| Step: 10
Training loss: 0.9660903811454773
Validation loss: 1.9870044467269734

Epoch: 551| Step: 0
Training loss: 1.2415555715560913
Validation loss: 1.9923192108831098

Epoch: 5| Step: 1
Training loss: 1.350208044052124
Validation loss: 1.967114915129959

Epoch: 5| Step: 2
Training loss: 0.9889556765556335
Validation loss: 1.9814177431086057

Epoch: 5| Step: 3
Training loss: 0.9197450876235962
Validation loss: 1.9682431349190332

Epoch: 5| Step: 4
Training loss: 1.985889196395874
Validation loss: 1.9915667400565198

Epoch: 5| Step: 5
Training loss: 0.8988248109817505
Validation loss: 1.996624488984385

Epoch: 5| Step: 6
Training loss: 1.4789543151855469
Validation loss: 1.9615377328729118

Epoch: 5| Step: 7
Training loss: 1.5118216276168823
Validation loss: 1.9688070204950148

Epoch: 5| Step: 8
Training loss: 1.0502302646636963
Validation loss: 1.9184492941825622

Epoch: 5| Step: 9
Training loss: 1.259137511253357
Validation loss: 1.9256161233430267

Epoch: 5| Step: 10
Training loss: 0.9737706780433655
Validation loss: 1.9100978682118077

Epoch: 552| Step: 0
Training loss: 0.9786809682846069
Validation loss: 2.001089039669242

Epoch: 5| Step: 1
Training loss: 1.5118860006332397
Validation loss: 2.0284391090434086

Epoch: 5| Step: 2
Training loss: 0.7790396213531494
Validation loss: 1.965152080341052

Epoch: 5| Step: 3
Training loss: 1.4399945735931396
Validation loss: 1.9967822156926638

Epoch: 5| Step: 4
Training loss: 1.5486011505126953
Validation loss: 2.0051751957144788

Epoch: 5| Step: 5
Training loss: 1.8103199005126953
Validation loss: 2.021760153514083

Epoch: 5| Step: 6
Training loss: 1.2614349126815796
Validation loss: 1.9867077501871253

Epoch: 5| Step: 7
Training loss: 1.113389253616333
Validation loss: 2.026117337647305

Epoch: 5| Step: 8
Training loss: 0.806647777557373
Validation loss: 2.030231757830548

Epoch: 5| Step: 9
Training loss: 1.2594560384750366
Validation loss: 2.01088608080341

Epoch: 5| Step: 10
Training loss: 1.2356977462768555
Validation loss: 1.955973607237621

Epoch: 553| Step: 0
Training loss: 1.4349870681762695
Validation loss: 1.9903860579254806

Epoch: 5| Step: 1
Training loss: 1.0754194259643555
Validation loss: 1.9917161362145537

Epoch: 5| Step: 2
Training loss: 1.403658151626587
Validation loss: 1.982989393254762

Epoch: 5| Step: 3
Training loss: 1.109736442565918
Validation loss: 1.9685627260515768

Epoch: 5| Step: 4
Training loss: 2.033790349960327
Validation loss: 1.9987586800770094

Epoch: 5| Step: 5
Training loss: 0.8562440872192383
Validation loss: 1.9504807931120678

Epoch: 5| Step: 6
Training loss: 1.2404677867889404
Validation loss: 1.9491810875554239

Epoch: 5| Step: 7
Training loss: 1.1062690019607544
Validation loss: 1.9878558740820935

Epoch: 5| Step: 8
Training loss: 0.7112176418304443
Validation loss: 1.9770168360843454

Epoch: 5| Step: 9
Training loss: 1.1322804689407349
Validation loss: 1.961637858421572

Epoch: 5| Step: 10
Training loss: 1.4542690515518188
Validation loss: 1.9841266216770295

Epoch: 554| Step: 0
Training loss: 1.3491395711898804
Validation loss: 1.9752470036988616

Epoch: 5| Step: 1
Training loss: 1.127424955368042
Validation loss: 1.9797875394103348

Epoch: 5| Step: 2
Training loss: 1.1098525524139404
Validation loss: 1.9898662977321173

Epoch: 5| Step: 3
Training loss: 1.1757434606552124
Validation loss: 1.9961762941011818

Epoch: 5| Step: 4
Training loss: 1.307943344116211
Validation loss: 2.0087103997507403

Epoch: 5| Step: 5
Training loss: 1.5703747272491455
Validation loss: 2.022648129411923

Epoch: 5| Step: 6
Training loss: 1.4747370481491089
Validation loss: 2.003639708283127

Epoch: 5| Step: 7
Training loss: 1.2413649559020996
Validation loss: 2.048024969716226

Epoch: 5| Step: 8
Training loss: 1.2382738590240479
Validation loss: 1.9665038547208231

Epoch: 5| Step: 9
Training loss: 0.8843488693237305
Validation loss: 1.9946417013804119

Epoch: 5| Step: 10
Training loss: 1.4201958179473877
Validation loss: 1.966453504818742

Epoch: 555| Step: 0
Training loss: 1.2120202779769897
Validation loss: 2.0252433823001

Epoch: 5| Step: 1
Training loss: 1.385345458984375
Validation loss: 1.958114138213537

Epoch: 5| Step: 2
Training loss: 0.9530481100082397
Validation loss: 2.0247840317346717

Epoch: 5| Step: 3
Training loss: 1.3025271892547607
Validation loss: 1.9815316405347598

Epoch: 5| Step: 4
Training loss: 1.4996150732040405
Validation loss: 1.9770241475874377

Epoch: 5| Step: 5
Training loss: 1.2785683870315552
Validation loss: 2.0142751086142754

Epoch: 5| Step: 6
Training loss: 1.1290342807769775
Validation loss: 1.9865782017348914

Epoch: 5| Step: 7
Training loss: 1.2148959636688232
Validation loss: 1.960811952108978

Epoch: 5| Step: 8
Training loss: 1.536834478378296
Validation loss: 2.0050387959326468

Epoch: 5| Step: 9
Training loss: 1.187211036682129
Validation loss: 1.9973629751513082

Epoch: 5| Step: 10
Training loss: 0.8131680488586426
Validation loss: 2.026534931634062

Epoch: 556| Step: 0
Training loss: 0.9958575963973999
Validation loss: 1.9917825370706537

Epoch: 5| Step: 1
Training loss: 1.5822001695632935
Validation loss: 1.986308983577195

Epoch: 5| Step: 2
Training loss: 1.1831979751586914
Validation loss: 1.9857530234962382

Epoch: 5| Step: 3
Training loss: 0.6905338764190674
Validation loss: 1.9520386636898082

Epoch: 5| Step: 4
Training loss: 1.1224963665008545
Validation loss: 1.9603732529506888

Epoch: 5| Step: 5
Training loss: 1.4734798669815063
Validation loss: 1.9963195182943856

Epoch: 5| Step: 6
Training loss: 1.2981135845184326
Validation loss: 1.9158933829235774

Epoch: 5| Step: 7
Training loss: 1.13240385055542
Validation loss: 2.0008709520422

Epoch: 5| Step: 8
Training loss: 1.8326091766357422
Validation loss: 1.9598071177800496

Epoch: 5| Step: 9
Training loss: 1.1505929231643677
Validation loss: 1.969534109997493

Epoch: 5| Step: 10
Training loss: 0.6987765431404114
Validation loss: 1.9944010075702463

Epoch: 557| Step: 0
Training loss: 1.183938980102539
Validation loss: 2.0116822642664753

Epoch: 5| Step: 1
Training loss: 1.5383014678955078
Validation loss: 2.0303825806545954

Epoch: 5| Step: 2
Training loss: 1.385488748550415
Validation loss: 1.9553217990424043

Epoch: 5| Step: 3
Training loss: 1.126368761062622
Validation loss: 1.9788156247908069

Epoch: 5| Step: 4
Training loss: 0.836504340171814
Validation loss: 2.033886840266566

Epoch: 5| Step: 5
Training loss: 1.2172924280166626
Validation loss: 1.9984616336002146

Epoch: 5| Step: 6
Training loss: 1.7579606771469116
Validation loss: 1.9766249105494509

Epoch: 5| Step: 7
Training loss: 1.156665325164795
Validation loss: 1.9728977064932547

Epoch: 5| Step: 8
Training loss: 1.2178109884262085
Validation loss: 2.0200814354804253

Epoch: 5| Step: 9
Training loss: 1.0392533540725708
Validation loss: 2.0127197696316625

Epoch: 5| Step: 10
Training loss: 0.9723499417304993
Validation loss: 1.9969524132308138

Epoch: 558| Step: 0
Training loss: 1.4209949970245361
Validation loss: 2.0001095264188704

Epoch: 5| Step: 1
Training loss: 0.7224429249763489
Validation loss: 1.9828087488810222

Epoch: 5| Step: 2
Training loss: 1.2705880403518677
Validation loss: 1.9419556202427033

Epoch: 5| Step: 3
Training loss: 1.1278923749923706
Validation loss: 1.9801326477399437

Epoch: 5| Step: 4
Training loss: 1.0366023778915405
Validation loss: 2.0076891760672293

Epoch: 5| Step: 5
Training loss: 1.0437413454055786
Validation loss: 1.9655782971330868

Epoch: 5| Step: 6
Training loss: 1.6505143642425537
Validation loss: 1.9987293930463894

Epoch: 5| Step: 7
Training loss: 0.9669046401977539
Validation loss: 1.9979246508690618

Epoch: 5| Step: 8
Training loss: 1.634521722793579
Validation loss: 2.0276204283519457

Epoch: 5| Step: 9
Training loss: 1.164074182510376
Validation loss: 2.0194964229419665

Epoch: 5| Step: 10
Training loss: 1.2313843965530396
Validation loss: 1.985881140155177

Epoch: 559| Step: 0
Training loss: 0.6760722994804382
Validation loss: 2.0122095025995725

Epoch: 5| Step: 1
Training loss: 1.1786737442016602
Validation loss: 2.0237591933178645

Epoch: 5| Step: 2
Training loss: 0.8397167921066284
Validation loss: 1.966401643650506

Epoch: 5| Step: 3
Training loss: 1.4641528129577637
Validation loss: 1.9818309148152669

Epoch: 5| Step: 4
Training loss: 1.269390344619751
Validation loss: 2.010651860185849

Epoch: 5| Step: 5
Training loss: 1.6716156005859375
Validation loss: 1.9978133170835433

Epoch: 5| Step: 6
Training loss: 1.2045457363128662
Validation loss: 1.9673936020943426

Epoch: 5| Step: 7
Training loss: 1.18921959400177
Validation loss: 1.9928937022404005

Epoch: 5| Step: 8
Training loss: 1.736058235168457
Validation loss: 2.0310252058890557

Epoch: 5| Step: 9
Training loss: 1.1084963083267212
Validation loss: 1.9947652175862303

Epoch: 5| Step: 10
Training loss: 0.9675939083099365
Validation loss: 1.9808528307945497

Epoch: 560| Step: 0
Training loss: 1.3432972431182861
Validation loss: 2.0145010153452554

Epoch: 5| Step: 1
Training loss: 1.033722162246704
Validation loss: 1.9548544922182638

Epoch: 5| Step: 2
Training loss: 1.0204271078109741
Validation loss: 2.014385977099019

Epoch: 5| Step: 3
Training loss: 1.0343178510665894
Validation loss: 1.9835492526331255

Epoch: 5| Step: 4
Training loss: 1.0472805500030518
Validation loss: 2.012131790960989

Epoch: 5| Step: 5
Training loss: 0.8750563859939575
Validation loss: 1.9828968945369925

Epoch: 5| Step: 6
Training loss: 1.6862128973007202
Validation loss: 1.980913754432432

Epoch: 5| Step: 7
Training loss: 1.2898942232131958
Validation loss: 2.007949993174563

Epoch: 5| Step: 8
Training loss: 1.1160621643066406
Validation loss: 1.9702044661327074

Epoch: 5| Step: 9
Training loss: 1.3380869626998901
Validation loss: 1.9685946741411764

Epoch: 5| Step: 10
Training loss: 1.3770965337753296
Validation loss: 1.998376666858632

Epoch: 561| Step: 0
Training loss: 1.386141061782837
Validation loss: 2.013529368626174

Epoch: 5| Step: 1
Training loss: 0.8541054725646973
Validation loss: 1.9381028606045632

Epoch: 5| Step: 2
Training loss: 0.9754274487495422
Validation loss: 2.0135854316014115

Epoch: 5| Step: 3
Training loss: 0.9186911582946777
Validation loss: 2.0295980053563274

Epoch: 5| Step: 4
Training loss: 1.830685019493103
Validation loss: 1.9740543801297423

Epoch: 5| Step: 5
Training loss: 0.9047812223434448
Validation loss: 1.9549648184930124

Epoch: 5| Step: 6
Training loss: 1.5576152801513672
Validation loss: 1.990760967295657

Epoch: 5| Step: 7
Training loss: 1.2199337482452393
Validation loss: 2.0154688768489386

Epoch: 5| Step: 8
Training loss: 0.9052322506904602
Validation loss: 1.9837212844561505

Epoch: 5| Step: 9
Training loss: 1.2830431461334229
Validation loss: 1.970438377831572

Epoch: 5| Step: 10
Training loss: 1.540844440460205
Validation loss: 1.9716067967876312

Epoch: 562| Step: 0
Training loss: 0.9754132032394409
Validation loss: 1.9975073670828214

Epoch: 5| Step: 1
Training loss: 1.0296056270599365
Validation loss: 1.978212615495087

Epoch: 5| Step: 2
Training loss: 0.7969154119491577
Validation loss: 1.9661125649688065

Epoch: 5| Step: 3
Training loss: 1.5057244300842285
Validation loss: 1.9721753545986709

Epoch: 5| Step: 4
Training loss: 1.5284801721572876
Validation loss: 1.979216428213222

Epoch: 5| Step: 5
Training loss: 1.4489858150482178
Validation loss: 2.041248252314906

Epoch: 5| Step: 6
Training loss: 1.360445261001587
Validation loss: 2.003117912559099

Epoch: 5| Step: 7
Training loss: 0.7682819366455078
Validation loss: 2.000015375434711

Epoch: 5| Step: 8
Training loss: 1.034252405166626
Validation loss: 2.0060669696459206

Epoch: 5| Step: 9
Training loss: 1.2811219692230225
Validation loss: 1.9998768106583626

Epoch: 5| Step: 10
Training loss: 1.6501054763793945
Validation loss: 1.9740394110320716

Epoch: 563| Step: 0
Training loss: 1.5673515796661377
Validation loss: 1.9750858942667644

Epoch: 5| Step: 1
Training loss: 1.2442259788513184
Validation loss: 2.008559873027186

Epoch: 5| Step: 2
Training loss: 1.2146341800689697
Validation loss: 2.045385153062882

Epoch: 5| Step: 3
Training loss: 0.9463093876838684
Validation loss: 2.0148078049382856

Epoch: 5| Step: 4
Training loss: 1.4380221366882324
Validation loss: 2.005023979371594

Epoch: 5| Step: 5
Training loss: 1.238494634628296
Validation loss: 2.0314692899745

Epoch: 5| Step: 6
Training loss: 1.2646081447601318
Validation loss: 2.01114272686743

Epoch: 5| Step: 7
Training loss: 1.2946761846542358
Validation loss: 1.9811985492706299

Epoch: 5| Step: 8
Training loss: 1.1254905462265015
Validation loss: 2.0103403906668387

Epoch: 5| Step: 9
Training loss: 1.0290724039077759
Validation loss: 1.9812623787951726

Epoch: 5| Step: 10
Training loss: 1.2903763055801392
Validation loss: 1.9833503339880256

Epoch: 564| Step: 0
Training loss: 1.0423691272735596
Validation loss: 1.993287847888085

Epoch: 5| Step: 1
Training loss: 1.775730848312378
Validation loss: 2.0158713812469156

Epoch: 5| Step: 2
Training loss: 1.1657613515853882
Validation loss: 2.0255518997869184

Epoch: 5| Step: 3
Training loss: 1.5738017559051514
Validation loss: 1.9608283081362325

Epoch: 5| Step: 4
Training loss: 0.9435495138168335
Validation loss: 1.9949372558183567

Epoch: 5| Step: 5
Training loss: 1.0317366123199463
Validation loss: 2.0130619015744937

Epoch: 5| Step: 6
Training loss: 1.2455977201461792
Validation loss: 2.0199207836581814

Epoch: 5| Step: 7
Training loss: 1.0692387819290161
Validation loss: 1.9944828146247453

Epoch: 5| Step: 8
Training loss: 0.7393469214439392
Validation loss: 2.0196663397614674

Epoch: 5| Step: 9
Training loss: 1.058143138885498
Validation loss: 2.024756662307247

Epoch: 5| Step: 10
Training loss: 1.669142484664917
Validation loss: 1.9861030142794374

Epoch: 565| Step: 0
Training loss: 0.9049724340438843
Validation loss: 1.9923419952392578

Epoch: 5| Step: 1
Training loss: 1.13327157497406
Validation loss: 1.9853020560356878

Epoch: 5| Step: 2
Training loss: 1.704563856124878
Validation loss: 1.998693996860135

Epoch: 5| Step: 3
Training loss: 1.4076025485992432
Validation loss: 2.042502200731667

Epoch: 5| Step: 4
Training loss: 1.3017544746398926
Validation loss: 1.9880805861565374

Epoch: 5| Step: 5
Training loss: 1.224287748336792
Validation loss: 1.9435751425322665

Epoch: 5| Step: 6
Training loss: 1.4122180938720703
Validation loss: 2.022466513418382

Epoch: 5| Step: 7
Training loss: 0.6601963639259338
Validation loss: 2.01918125665316

Epoch: 5| Step: 8
Training loss: 1.1546659469604492
Validation loss: 1.9902787157284316

Epoch: 5| Step: 9
Training loss: 1.424213171005249
Validation loss: 2.0005293251365743

Epoch: 5| Step: 10
Training loss: 0.8396007418632507
Validation loss: 1.9610277439958306

Epoch: 566| Step: 0
Training loss: 0.8975080251693726
Validation loss: 1.964125511466816

Epoch: 5| Step: 1
Training loss: 1.0767210721969604
Validation loss: 2.022549186983416

Epoch: 5| Step: 2
Training loss: 1.414719820022583
Validation loss: 1.9958828931213708

Epoch: 5| Step: 3
Training loss: 1.39158034324646
Validation loss: 2.002359499213516

Epoch: 5| Step: 4
Training loss: 0.9133883714675903
Validation loss: 1.9975559967820362

Epoch: 5| Step: 5
Training loss: 1.552838683128357
Validation loss: 1.9865193969459944

Epoch: 5| Step: 6
Training loss: 1.5179566144943237
Validation loss: 2.008137354286768

Epoch: 5| Step: 7
Training loss: 1.149366021156311
Validation loss: 2.0325319228633756

Epoch: 5| Step: 8
Training loss: 1.3201634883880615
Validation loss: 2.032942215601603

Epoch: 5| Step: 9
Training loss: 1.1769688129425049
Validation loss: 2.002024399336948

Epoch: 5| Step: 10
Training loss: 0.7724593281745911
Validation loss: 1.967949874939457

Epoch: 567| Step: 0
Training loss: 1.4160864353179932
Validation loss: 2.0238779770430697

Epoch: 5| Step: 1
Training loss: 0.952563464641571
Validation loss: 2.0110028251524894

Epoch: 5| Step: 2
Training loss: 1.0992143154144287
Validation loss: 1.978985850529004

Epoch: 5| Step: 3
Training loss: 1.3692190647125244
Validation loss: 1.9736373270711591

Epoch: 5| Step: 4
Training loss: 1.1199798583984375
Validation loss: 1.9706391429388395

Epoch: 5| Step: 5
Training loss: 1.1959298849105835
Validation loss: 1.9447480350412347

Epoch: 5| Step: 6
Training loss: 0.9518281817436218
Validation loss: 1.9971004314320062

Epoch: 5| Step: 7
Training loss: 1.8297321796417236
Validation loss: 1.9939144388321908

Epoch: 5| Step: 8
Training loss: 1.0118658542633057
Validation loss: 1.979657990958101

Epoch: 5| Step: 9
Training loss: 0.8803785443305969
Validation loss: 2.0113100492826073

Epoch: 5| Step: 10
Training loss: 1.1356010437011719
Validation loss: 2.031405984714467

Epoch: 568| Step: 0
Training loss: 1.259178876876831
Validation loss: 2.0002726790725545

Epoch: 5| Step: 1
Training loss: 1.3709335327148438
Validation loss: 1.9625004132588704

Epoch: 5| Step: 2
Training loss: 1.4663867950439453
Validation loss: 2.005411035271101

Epoch: 5| Step: 3
Training loss: 1.1489818096160889
Validation loss: 1.9618184207588114

Epoch: 5| Step: 4
Training loss: 0.9679082036018372
Validation loss: 1.9976031113696355

Epoch: 5| Step: 5
Training loss: 0.7478253841400146
Validation loss: 1.9898843380712694

Epoch: 5| Step: 6
Training loss: 1.0158822536468506
Validation loss: 1.9828794361442648

Epoch: 5| Step: 7
Training loss: 0.9999181628227234
Validation loss: 2.0051469161946285

Epoch: 5| Step: 8
Training loss: 1.4572676420211792
Validation loss: 2.0270703607989895

Epoch: 5| Step: 9
Training loss: 1.3395575284957886
Validation loss: 1.9936775776647753

Epoch: 5| Step: 10
Training loss: 1.3714193105697632
Validation loss: 2.0092431447839223

Epoch: 569| Step: 0
Training loss: 1.0430974960327148
Validation loss: 1.9841551011608494

Epoch: 5| Step: 1
Training loss: 1.2776447534561157
Validation loss: 1.9979221846467705

Epoch: 5| Step: 2
Training loss: 0.47909241914749146
Validation loss: 1.957957201106574

Epoch: 5| Step: 3
Training loss: 1.558915615081787
Validation loss: 1.9519989695600284

Epoch: 5| Step: 4
Training loss: 1.4565598964691162
Validation loss: 1.9986454004882483

Epoch: 5| Step: 5
Training loss: 1.8749420642852783
Validation loss: 1.9552699263377855

Epoch: 5| Step: 6
Training loss: 1.1470372676849365
Validation loss: 2.0249383539281864

Epoch: 5| Step: 7
Training loss: 1.4345996379852295
Validation loss: 2.029664226757583

Epoch: 5| Step: 8
Training loss: 0.9134600758552551
Validation loss: 1.9510245284726542

Epoch: 5| Step: 9
Training loss: 1.055124044418335
Validation loss: 2.007891936968732

Epoch: 5| Step: 10
Training loss: 0.7901543974876404
Validation loss: 1.9855817030834895

Epoch: 570| Step: 0
Training loss: 0.9900909662246704
Validation loss: 1.9897543127818773

Epoch: 5| Step: 1
Training loss: 1.0639021396636963
Validation loss: 1.9903599741638347

Epoch: 5| Step: 2
Training loss: 0.6015905141830444
Validation loss: 1.9819516994619881

Epoch: 5| Step: 3
Training loss: 1.3689934015274048
Validation loss: 1.9570350147062732

Epoch: 5| Step: 4
Training loss: 1.2853385210037231
Validation loss: 1.9774349581810735

Epoch: 5| Step: 5
Training loss: 1.4311881065368652
Validation loss: 2.0209257730873684

Epoch: 5| Step: 6
Training loss: 1.1211121082305908
Validation loss: 1.99448900581688

Epoch: 5| Step: 7
Training loss: 1.3265619277954102
Validation loss: 1.9844707532595562

Epoch: 5| Step: 8
Training loss: 1.3445535898208618
Validation loss: 2.002460161844889

Epoch: 5| Step: 9
Training loss: 1.3370964527130127
Validation loss: 2.022131904478996

Epoch: 5| Step: 10
Training loss: 1.3615213632583618
Validation loss: 2.037027491036282

Epoch: 571| Step: 0
Training loss: 1.1973726749420166
Validation loss: 1.9748908691508795

Epoch: 5| Step: 1
Training loss: 1.6396806240081787
Validation loss: 2.018846716932071

Epoch: 5| Step: 2
Training loss: 0.6381629109382629
Validation loss: 2.0067395740939724

Epoch: 5| Step: 3
Training loss: 1.1059865951538086
Validation loss: 2.0089147885640464

Epoch: 5| Step: 4
Training loss: 1.5665559768676758
Validation loss: 2.0196827021978234

Epoch: 5| Step: 5
Training loss: 1.3024988174438477
Validation loss: 2.0200199542507047

Epoch: 5| Step: 6
Training loss: 0.8481721878051758
Validation loss: 2.0118979689895466

Epoch: 5| Step: 7
Training loss: 1.0048788785934448
Validation loss: 1.983221842396644

Epoch: 5| Step: 8
Training loss: 1.2406915426254272
Validation loss: 2.0002527826575824

Epoch: 5| Step: 9
Training loss: 1.271398901939392
Validation loss: 1.9526190732115059

Epoch: 5| Step: 10
Training loss: 1.2342568635940552
Validation loss: 1.9774897611269386

Epoch: 572| Step: 0
Training loss: 0.8768180012702942
Validation loss: 1.9585458591420164

Epoch: 5| Step: 1
Training loss: 0.9818630218505859
Validation loss: 1.9416148483112294

Epoch: 5| Step: 2
Training loss: 1.0721615552902222
Validation loss: 1.9730574853958622

Epoch: 5| Step: 3
Training loss: 1.2562370300292969
Validation loss: 2.0037567436054187

Epoch: 5| Step: 4
Training loss: 1.138323426246643
Validation loss: 2.0405316532299085

Epoch: 5| Step: 5
Training loss: 1.4118787050247192
Validation loss: 2.011345781305785

Epoch: 5| Step: 6
Training loss: 1.4214766025543213
Validation loss: 2.0024857623602754

Epoch: 5| Step: 7
Training loss: 1.4050439596176147
Validation loss: 2.016605084942233

Epoch: 5| Step: 8
Training loss: 0.8939844369888306
Validation loss: 2.0005273536969255

Epoch: 5| Step: 9
Training loss: 1.3982932567596436
Validation loss: 1.9883306949369368

Epoch: 5| Step: 10
Training loss: 1.245875597000122
Validation loss: 1.9867638695624568

Epoch: 573| Step: 0
Training loss: 1.520878553390503
Validation loss: 1.99554943653845

Epoch: 5| Step: 1
Training loss: 1.3260376453399658
Validation loss: 2.011226163115553

Epoch: 5| Step: 2
Training loss: 1.3145177364349365
Validation loss: 1.9924193556590746

Epoch: 5| Step: 3
Training loss: 1.7890983819961548
Validation loss: 2.0230720658456125

Epoch: 5| Step: 4
Training loss: 0.7851211428642273
Validation loss: 2.0099708598147155

Epoch: 5| Step: 5
Training loss: 0.5371170043945312
Validation loss: 1.982120511352375

Epoch: 5| Step: 6
Training loss: 1.4303001165390015
Validation loss: 1.981676810531206

Epoch: 5| Step: 7
Training loss: 1.200262427330017
Validation loss: 1.9794318188903153

Epoch: 5| Step: 8
Training loss: 0.6915940642356873
Validation loss: 1.965233620776925

Epoch: 5| Step: 9
Training loss: 1.1280015707015991
Validation loss: 1.9997014050842614

Epoch: 5| Step: 10
Training loss: 1.4866762161254883
Validation loss: 1.9827007657738143

Epoch: 574| Step: 0
Training loss: 1.850698471069336
Validation loss: 1.9955085323702904

Epoch: 5| Step: 1
Training loss: 1.0256578922271729
Validation loss: 2.0227644135875087

Epoch: 5| Step: 2
Training loss: 1.4080743789672852
Validation loss: 1.9825142365629955

Epoch: 5| Step: 3
Training loss: 0.6880064010620117
Validation loss: 1.9988778380937473

Epoch: 5| Step: 4
Training loss: 1.0504283905029297
Validation loss: 2.0300069137286116

Epoch: 5| Step: 5
Training loss: 1.4108870029449463
Validation loss: 1.9654602607091267

Epoch: 5| Step: 6
Training loss: 1.289191484451294
Validation loss: 2.022904726766771

Epoch: 5| Step: 7
Training loss: 1.1226547956466675
Validation loss: 2.0376241258395615

Epoch: 5| Step: 8
Training loss: 0.8434454202651978
Validation loss: 1.959567883963226

Epoch: 5| Step: 9
Training loss: 1.4453357458114624
Validation loss: 2.011886776134532

Epoch: 5| Step: 10
Training loss: 0.9871822595596313
Validation loss: 1.9756312575391544

Epoch: 575| Step: 0
Training loss: 1.4793064594268799
Validation loss: 1.9722165574309647

Epoch: 5| Step: 1
Training loss: 1.117669939994812
Validation loss: 1.9678307348682034

Epoch: 5| Step: 2
Training loss: 0.7799220085144043
Validation loss: 1.9562362932389783

Epoch: 5| Step: 3
Training loss: 1.208209753036499
Validation loss: 2.006135179150489

Epoch: 5| Step: 4
Training loss: 1.0063810348510742
Validation loss: 1.957475580194945

Epoch: 5| Step: 5
Training loss: 1.7032161951065063
Validation loss: 1.9886252931369248

Epoch: 5| Step: 6
Training loss: 1.1768027544021606
Validation loss: 1.9856913192297823

Epoch: 5| Step: 7
Training loss: 1.0142639875411987
Validation loss: 2.0354776369628085

Epoch: 5| Step: 8
Training loss: 1.4355462789535522
Validation loss: 1.9679499646668792

Epoch: 5| Step: 9
Training loss: 1.1245307922363281
Validation loss: 1.9946601595929874

Epoch: 5| Step: 10
Training loss: 1.1379797458648682
Validation loss: 1.987656360031456

Epoch: 576| Step: 0
Training loss: 1.2735393047332764
Validation loss: 2.0075314326952864

Epoch: 5| Step: 1
Training loss: 1.1835066080093384
Validation loss: 2.017105089720859

Epoch: 5| Step: 2
Training loss: 0.8663898706436157
Validation loss: 1.9760838747024536

Epoch: 5| Step: 3
Training loss: 1.1422059535980225
Validation loss: 2.0278914743854153

Epoch: 5| Step: 4
Training loss: 0.9875566363334656
Validation loss: 1.9796944613097816

Epoch: 5| Step: 5
Training loss: 1.768479347229004
Validation loss: 1.9867530086989045

Epoch: 5| Step: 6
Training loss: 1.2314246892929077
Validation loss: 2.0159551725592664

Epoch: 5| Step: 7
Training loss: 1.4427025318145752
Validation loss: 1.9693738683577506

Epoch: 5| Step: 8
Training loss: 1.3446083068847656
Validation loss: 1.9877344280160882

Epoch: 5| Step: 9
Training loss: 1.0697057247161865
Validation loss: 2.0236274093709965

Epoch: 5| Step: 10
Training loss: 0.9071266055107117
Validation loss: 1.9899325614334435

Epoch: 577| Step: 0
Training loss: 1.8967434167861938
Validation loss: 1.9682123071403914

Epoch: 5| Step: 1
Training loss: 1.212935447692871
Validation loss: 1.977931152107895

Epoch: 5| Step: 2
Training loss: 0.7082893252372742
Validation loss: 1.9423797733040267

Epoch: 5| Step: 3
Training loss: 1.1479326486587524
Validation loss: 1.9897229158750145

Epoch: 5| Step: 4
Training loss: 0.9890824556350708
Validation loss: 1.9831364308634112

Epoch: 5| Step: 5
Training loss: 1.4420934915542603
Validation loss: 2.0042100439789476

Epoch: 5| Step: 6
Training loss: 0.6993998885154724
Validation loss: 1.985621412595113

Epoch: 5| Step: 7
Training loss: 1.2110050916671753
Validation loss: 2.0184373701772382

Epoch: 5| Step: 8
Training loss: 1.2369657754898071
Validation loss: 1.973704602128716

Epoch: 5| Step: 9
Training loss: 1.3684581518173218
Validation loss: 1.9233887759588097

Epoch: 5| Step: 10
Training loss: 1.032576322555542
Validation loss: 2.0072990873808503

Epoch: 578| Step: 0
Training loss: 0.837306022644043
Validation loss: 1.9677670040438253

Epoch: 5| Step: 1
Training loss: 0.8728514909744263
Validation loss: 2.0198978301017516

Epoch: 5| Step: 2
Training loss: 1.2865859270095825
Validation loss: 1.9785075982411702

Epoch: 5| Step: 3
Training loss: 1.165963888168335
Validation loss: 2.0159404482892764

Epoch: 5| Step: 4
Training loss: 1.0229394435882568
Validation loss: 1.9683669049252746

Epoch: 5| Step: 5
Training loss: 1.058137059211731
Validation loss: 2.024708737609207

Epoch: 5| Step: 6
Training loss: 1.5327855348587036
Validation loss: 1.9615286088758899

Epoch: 5| Step: 7
Training loss: 1.4224833250045776
Validation loss: 2.0099011275076095

Epoch: 5| Step: 8
Training loss: 1.0635970830917358
Validation loss: 1.9859694934660388

Epoch: 5| Step: 9
Training loss: 1.855506181716919
Validation loss: 1.9953801990837179

Epoch: 5| Step: 10
Training loss: 1.1144670248031616
Validation loss: 1.992182731628418

Epoch: 579| Step: 0
Training loss: 0.8814002275466919
Validation loss: 2.0375331217242825

Epoch: 5| Step: 1
Training loss: 1.1198551654815674
Validation loss: 2.0019979348746677

Epoch: 5| Step: 2
Training loss: 1.6885149478912354
Validation loss: 1.9920286811808103

Epoch: 5| Step: 3
Training loss: 1.2766335010528564
Validation loss: 2.0286106627474547

Epoch: 5| Step: 4
Training loss: 1.6760727167129517
Validation loss: 1.9558093573457451

Epoch: 5| Step: 5
Training loss: 1.1923048496246338
Validation loss: 2.011972237658757

Epoch: 5| Step: 6
Training loss: 0.8647848963737488
Validation loss: 2.0162136862354894

Epoch: 5| Step: 7
Training loss: 1.1685218811035156
Validation loss: 1.994022819303697

Epoch: 5| Step: 8
Training loss: 1.369078278541565
Validation loss: 1.9780632603553034

Epoch: 5| Step: 9
Training loss: 1.1358251571655273
Validation loss: 1.9777092536290486

Epoch: 5| Step: 10
Training loss: 0.7785875797271729
Validation loss: 2.002897726592197

Epoch: 580| Step: 0
Training loss: 1.0326110124588013
Validation loss: 1.9810054327851983

Epoch: 5| Step: 1
Training loss: 1.0826079845428467
Validation loss: 2.0435146516369236

Epoch: 5| Step: 2
Training loss: 1.5577532052993774
Validation loss: 2.0254615263272355

Epoch: 5| Step: 3
Training loss: 0.7685225605964661
Validation loss: 2.0395775930855864

Epoch: 5| Step: 4
Training loss: 1.0230662822723389
Validation loss: 2.0126172470790085

Epoch: 5| Step: 5
Training loss: 0.9557607769966125
Validation loss: 2.049323720316733

Epoch: 5| Step: 6
Training loss: 0.9008573293685913
Validation loss: 2.00354669555541

Epoch: 5| Step: 7
Training loss: 1.4352365732192993
Validation loss: 1.9691431189096102

Epoch: 5| Step: 8
Training loss: 1.7466537952423096
Validation loss: 1.999556306869753

Epoch: 5| Step: 9
Training loss: 1.546800136566162
Validation loss: 1.9894202447706653

Epoch: 5| Step: 10
Training loss: 0.9051611423492432
Validation loss: 2.0045849007944905

Epoch: 581| Step: 0
Training loss: 1.1848509311676025
Validation loss: 1.9820408410923456

Epoch: 5| Step: 1
Training loss: 0.9229142069816589
Validation loss: 2.0380316588186447

Epoch: 5| Step: 2
Training loss: 0.9697009325027466
Validation loss: 2.028837473161759

Epoch: 5| Step: 3
Training loss: 1.1368603706359863
Validation loss: 1.9972924737520115

Epoch: 5| Step: 4
Training loss: 1.376866102218628
Validation loss: 2.0041947698080413

Epoch: 5| Step: 5
Training loss: 1.545547604560852
Validation loss: 1.9865504605795747

Epoch: 5| Step: 6
Training loss: 1.1288667917251587
Validation loss: 1.9713559099422988

Epoch: 5| Step: 7
Training loss: 1.4354666471481323
Validation loss: 1.9594087613526212

Epoch: 5| Step: 8
Training loss: 1.0678608417510986
Validation loss: 1.9732526579210836

Epoch: 5| Step: 9
Training loss: 1.242879867553711
Validation loss: 1.9634122951056368

Epoch: 5| Step: 10
Training loss: 1.1996792554855347
Validation loss: 2.011165779124024

Epoch: 582| Step: 0
Training loss: 1.0280883312225342
Validation loss: 1.9840397257958688

Epoch: 5| Step: 1
Training loss: 1.393147349357605
Validation loss: 1.9715118613294376

Epoch: 5| Step: 2
Training loss: 1.0405540466308594
Validation loss: 1.976021525680378

Epoch: 5| Step: 3
Training loss: 0.854042649269104
Validation loss: 1.9508875262352727

Epoch: 5| Step: 4
Training loss: 1.1380946636199951
Validation loss: 1.9999631117748957

Epoch: 5| Step: 5
Training loss: 1.0277246236801147
Validation loss: 2.041353802527151

Epoch: 5| Step: 6
Training loss: 0.9324284791946411
Validation loss: 1.9623772739082255

Epoch: 5| Step: 7
Training loss: 1.4030864238739014
Validation loss: 1.9581267461981824

Epoch: 5| Step: 8
Training loss: 1.6209449768066406
Validation loss: 2.0215002029172835

Epoch: 5| Step: 9
Training loss: 1.200297474861145
Validation loss: 1.9685768799115253

Epoch: 5| Step: 10
Training loss: 1.2762863636016846
Validation loss: 1.9772753664242324

Epoch: 583| Step: 0
Training loss: 1.1637160778045654
Validation loss: 1.958378799500004

Epoch: 5| Step: 1
Training loss: 1.1084673404693604
Validation loss: 1.9704193351089314

Epoch: 5| Step: 2
Training loss: 0.6126412153244019
Validation loss: 2.005839531139661

Epoch: 5| Step: 3
Training loss: 1.561222791671753
Validation loss: 2.0028449540497153

Epoch: 5| Step: 4
Training loss: 1.1637423038482666
Validation loss: 2.014216120525073

Epoch: 5| Step: 5
Training loss: 1.0396922826766968
Validation loss: 2.0130816351982856

Epoch: 5| Step: 6
Training loss: 0.9804250597953796
Validation loss: 1.9962966493380967

Epoch: 5| Step: 7
Training loss: 1.0690085887908936
Validation loss: 2.019120086905777

Epoch: 5| Step: 8
Training loss: 1.3150972127914429
Validation loss: 2.0043019761321363

Epoch: 5| Step: 9
Training loss: 1.4862701892852783
Validation loss: 1.9882671102400749

Epoch: 5| Step: 10
Training loss: 1.608494520187378
Validation loss: 2.0336119949176745

Epoch: 584| Step: 0
Training loss: 1.0218960046768188
Validation loss: 2.004417147687686

Epoch: 5| Step: 1
Training loss: 1.2393524646759033
Validation loss: 2.0058379122005996

Epoch: 5| Step: 2
Training loss: 1.0094892978668213
Validation loss: 2.062521434599353

Epoch: 5| Step: 3
Training loss: 0.9121004939079285
Validation loss: 1.995120112613965

Epoch: 5| Step: 4
Training loss: 1.5618364810943604
Validation loss: 1.9638207497135285

Epoch: 5| Step: 5
Training loss: 1.519997000694275
Validation loss: 1.9580445892067366

Epoch: 5| Step: 6
Training loss: 1.0466108322143555
Validation loss: 1.964444286079817

Epoch: 5| Step: 7
Training loss: 1.6781021356582642
Validation loss: 2.022291341135579

Epoch: 5| Step: 8
Training loss: 0.9905835390090942
Validation loss: 2.01877664237894

Epoch: 5| Step: 9
Training loss: 0.8598217964172363
Validation loss: 1.9559772347891202

Epoch: 5| Step: 10
Training loss: 1.40020751953125
Validation loss: 1.9446863846112323

Epoch: 585| Step: 0
Training loss: 1.3626196384429932
Validation loss: 1.9947970067301104

Epoch: 5| Step: 1
Training loss: 1.3415648937225342
Validation loss: 2.0153096670745523

Epoch: 5| Step: 2
Training loss: 1.0901892185211182
Validation loss: 2.004381666901291

Epoch: 5| Step: 3
Training loss: 0.9595292210578918
Validation loss: 2.0446322489810247

Epoch: 5| Step: 4
Training loss: 0.7369484901428223
Validation loss: 2.018551475258284

Epoch: 5| Step: 5
Training loss: 1.611994981765747
Validation loss: 2.034459819075882

Epoch: 5| Step: 6
Training loss: 0.9459085464477539
Validation loss: 2.018706557571247

Epoch: 5| Step: 7
Training loss: 1.3461799621582031
Validation loss: 2.026187842892062

Epoch: 5| Step: 8
Training loss: 1.545110821723938
Validation loss: 1.9770889641136251

Epoch: 5| Step: 9
Training loss: 1.2389720678329468
Validation loss: 1.979186370808591

Epoch: 5| Step: 10
Training loss: 0.9284628033638
Validation loss: 2.031528701064407

Epoch: 586| Step: 0
Training loss: 1.4227616786956787
Validation loss: 2.006011627053702

Epoch: 5| Step: 1
Training loss: 1.1076393127441406
Validation loss: 1.9682748240809287

Epoch: 5| Step: 2
Training loss: 1.4783852100372314
Validation loss: 2.0414429736393753

Epoch: 5| Step: 3
Training loss: 1.2513971328735352
Validation loss: 1.9760193978586504

Epoch: 5| Step: 4
Training loss: 1.0734283924102783
Validation loss: 1.985456097510553

Epoch: 5| Step: 5
Training loss: 1.2642565965652466
Validation loss: 1.9907693209186677

Epoch: 5| Step: 6
Training loss: 1.1677942276000977
Validation loss: 1.9955263214726602

Epoch: 5| Step: 7
Training loss: 0.9652306437492371
Validation loss: 1.9673958157980314

Epoch: 5| Step: 8
Training loss: 1.2325495481491089
Validation loss: 1.9619394797150806

Epoch: 5| Step: 9
Training loss: 0.7722806930541992
Validation loss: 2.019778484939247

Epoch: 5| Step: 10
Training loss: 1.0570882558822632
Validation loss: 1.9951772894910587

Epoch: 587| Step: 0
Training loss: 1.4496943950653076
Validation loss: 2.05349547888643

Epoch: 5| Step: 1
Training loss: 1.5373272895812988
Validation loss: 2.0216968738904564

Epoch: 5| Step: 2
Training loss: 1.1814100742340088
Validation loss: 2.034621943709671

Epoch: 5| Step: 3
Training loss: 1.207790732383728
Validation loss: 2.0256293819796656

Epoch: 5| Step: 4
Training loss: 0.8983041644096375
Validation loss: 2.002113487130852

Epoch: 5| Step: 5
Training loss: 0.8696133494377136
Validation loss: 2.0366465199378228

Epoch: 5| Step: 6
Training loss: 1.431125283241272
Validation loss: 1.9719810934476956

Epoch: 5| Step: 7
Training loss: 1.2506425380706787
Validation loss: 2.003661115964254

Epoch: 5| Step: 8
Training loss: 0.9228509664535522
Validation loss: 1.960177743306724

Epoch: 5| Step: 9
Training loss: 0.9897434115409851
Validation loss: 1.9709488858458817

Epoch: 5| Step: 10
Training loss: 1.4269355535507202
Validation loss: 1.998370716648717

Epoch: 588| Step: 0
Training loss: 0.9675003886222839
Validation loss: 1.9795293141436834

Epoch: 5| Step: 1
Training loss: 1.527273416519165
Validation loss: 1.9626422825679983

Epoch: 5| Step: 2
Training loss: 1.0080586671829224
Validation loss: 1.9760402633297829

Epoch: 5| Step: 3
Training loss: 1.2921226024627686
Validation loss: 1.9865264636214062

Epoch: 5| Step: 4
Training loss: 1.1232233047485352
Validation loss: 2.0220868510584675

Epoch: 5| Step: 5
Training loss: 1.014399528503418
Validation loss: 2.0141800013921594

Epoch: 5| Step: 6
Training loss: 1.228972315788269
Validation loss: 1.9757355566947692

Epoch: 5| Step: 7
Training loss: 1.429337739944458
Validation loss: 1.9934531283634964

Epoch: 5| Step: 8
Training loss: 1.351625680923462
Validation loss: 1.9641978202327606

Epoch: 5| Step: 9
Training loss: 0.9523800611495972
Validation loss: 2.002511743576296

Epoch: 5| Step: 10
Training loss: 1.387272834777832
Validation loss: 1.989685336748759

Epoch: 589| Step: 0
Training loss: 1.164635419845581
Validation loss: 2.0179464317137197

Epoch: 5| Step: 1
Training loss: 1.0755176544189453
Validation loss: 2.0154428802510744

Epoch: 5| Step: 2
Training loss: 1.2190674543380737
Validation loss: 2.0161836365217805

Epoch: 5| Step: 3
Training loss: 1.4359136819839478
Validation loss: 2.0056259785929034

Epoch: 5| Step: 4
Training loss: 1.4325469732284546
Validation loss: 2.011182112078513

Epoch: 5| Step: 5
Training loss: 1.464473009109497
Validation loss: 1.9381531964066208

Epoch: 5| Step: 6
Training loss: 1.1190950870513916
Validation loss: 1.9795772529417468

Epoch: 5| Step: 7
Training loss: 1.1799176931381226
Validation loss: 1.9906241022130495

Epoch: 5| Step: 8
Training loss: 0.9981386065483093
Validation loss: 1.9729690833758282

Epoch: 5| Step: 9
Training loss: 1.1221110820770264
Validation loss: 1.9805257525495303

Epoch: 5| Step: 10
Training loss: 0.9705584049224854
Validation loss: 1.967566373527691

Epoch: 590| Step: 0
Training loss: 1.1810775995254517
Validation loss: 1.9456671848092029

Epoch: 5| Step: 1
Training loss: 0.9609717130661011
Validation loss: 2.0147513651078746

Epoch: 5| Step: 2
Training loss: 0.9425421953201294
Validation loss: 2.008120613713418

Epoch: 5| Step: 3
Training loss: 1.1709105968475342
Validation loss: 2.0010159823202316

Epoch: 5| Step: 4
Training loss: 1.0821006298065186
Validation loss: 1.9684730358021234

Epoch: 5| Step: 5
Training loss: 1.7963024377822876
Validation loss: 1.963619964097136

Epoch: 5| Step: 6
Training loss: 1.248908281326294
Validation loss: 2.005866548066498

Epoch: 5| Step: 7
Training loss: 1.4669212102890015
Validation loss: 2.0127092766505417

Epoch: 5| Step: 8
Training loss: 1.0539393424987793
Validation loss: 2.0675335507239065

Epoch: 5| Step: 9
Training loss: 1.0366142988204956
Validation loss: 2.0255765312461445

Epoch: 5| Step: 10
Training loss: 1.0409687757492065
Validation loss: 2.0591952288022606

Epoch: 591| Step: 0
Training loss: 0.7464665174484253
Validation loss: 2.0473058697997883

Epoch: 5| Step: 1
Training loss: 1.2068536281585693
Validation loss: 2.026871949113825

Epoch: 5| Step: 2
Training loss: 1.4918699264526367
Validation loss: 1.9922259212822042

Epoch: 5| Step: 3
Training loss: 0.8163224458694458
Validation loss: 2.0207500098853983

Epoch: 5| Step: 4
Training loss: 1.6016509532928467
Validation loss: 1.9935880502065022

Epoch: 5| Step: 5
Training loss: 1.4199633598327637
Validation loss: 1.9998239522339196

Epoch: 5| Step: 6
Training loss: 1.2742410898208618
Validation loss: 1.9847321036041423

Epoch: 5| Step: 7
Training loss: 0.8769955635070801
Validation loss: 1.9160107694646364

Epoch: 5| Step: 8
Training loss: 1.1859638690948486
Validation loss: 1.9532965870313748

Epoch: 5| Step: 9
Training loss: 0.9194464683532715
Validation loss: 1.9845417571324173

Epoch: 5| Step: 10
Training loss: 1.621525764465332
Validation loss: 1.988767941792806

Epoch: 592| Step: 0
Training loss: 0.9093397855758667
Validation loss: 1.9628896995257306

Epoch: 5| Step: 1
Training loss: 1.6242902278900146
Validation loss: 1.9825984021668792

Epoch: 5| Step: 2
Training loss: 1.1396821737289429
Validation loss: 2.0322705238096175

Epoch: 5| Step: 3
Training loss: 1.3263171911239624
Validation loss: 1.9710026223172423

Epoch: 5| Step: 4
Training loss: 0.5917443633079529
Validation loss: 1.984460110305458

Epoch: 5| Step: 5
Training loss: 0.9874156713485718
Validation loss: 1.9940596037013556

Epoch: 5| Step: 6
Training loss: 1.4517148733139038
Validation loss: 1.9976932951199111

Epoch: 5| Step: 7
Training loss: 1.5198993682861328
Validation loss: 2.01352273520603

Epoch: 5| Step: 8
Training loss: 0.9109264612197876
Validation loss: 2.0045114550539243

Epoch: 5| Step: 9
Training loss: 1.2823148965835571
Validation loss: 1.9512556022213352

Epoch: 5| Step: 10
Training loss: 1.2005119323730469
Validation loss: 2.0125741356162616

Epoch: 593| Step: 0
Training loss: 1.1558783054351807
Validation loss: 2.023764543635871

Epoch: 5| Step: 1
Training loss: 1.2848995923995972
Validation loss: 2.024203892677061

Epoch: 5| Step: 2
Training loss: 1.4351292848587036
Validation loss: 2.035241675633256

Epoch: 5| Step: 3
Training loss: 0.7596724033355713
Validation loss: 1.9869490592710433

Epoch: 5| Step: 4
Training loss: 1.7181766033172607
Validation loss: 1.9969280342901907

Epoch: 5| Step: 5
Training loss: 0.9995779991149902
Validation loss: 1.976535354891131

Epoch: 5| Step: 6
Training loss: 1.4932405948638916
Validation loss: 1.9441442899806525

Epoch: 5| Step: 7
Training loss: 1.6500227451324463
Validation loss: 2.0031538214734805

Epoch: 5| Step: 8
Training loss: 0.8648525476455688
Validation loss: 2.013336043204031

Epoch: 5| Step: 9
Training loss: 0.8508924245834351
Validation loss: 2.0197595511713335

Epoch: 5| Step: 10
Training loss: 0.8491087555885315
Validation loss: 1.9870774361395067

Epoch: 594| Step: 0
Training loss: 1.020777702331543
Validation loss: 1.9723684095567273

Epoch: 5| Step: 1
Training loss: 0.8945213556289673
Validation loss: 1.9340475682289369

Epoch: 5| Step: 2
Training loss: 1.552551031112671
Validation loss: 1.9113357900291361

Epoch: 5| Step: 3
Training loss: 1.3057482242584229
Validation loss: 1.952628363845169

Epoch: 5| Step: 4
Training loss: 1.0793068408966064
Validation loss: 1.9598265040305354

Epoch: 5| Step: 5
Training loss: 1.1890054941177368
Validation loss: 1.995156413765364

Epoch: 5| Step: 6
Training loss: 1.5080254077911377
Validation loss: 2.022864931373186

Epoch: 5| Step: 7
Training loss: 0.7805719971656799
Validation loss: 1.9599014046371623

Epoch: 5| Step: 8
Training loss: 0.9300686717033386
Validation loss: 1.982347511476086

Epoch: 5| Step: 9
Training loss: 1.2144100666046143
Validation loss: 1.9728262052741101

Epoch: 5| Step: 10
Training loss: 1.5412591695785522
Validation loss: 1.9615119990482126

Epoch: 595| Step: 0
Training loss: 1.0998278856277466
Validation loss: 2.0060961707945792

Epoch: 5| Step: 1
Training loss: 0.776942789554596
Validation loss: 1.9746661775855607

Epoch: 5| Step: 2
Training loss: 0.8342421650886536
Validation loss: 1.958908175909391

Epoch: 5| Step: 3
Training loss: 0.591545045375824
Validation loss: 2.0009696099065963

Epoch: 5| Step: 4
Training loss: 1.4802961349487305
Validation loss: 2.018097380156158

Epoch: 5| Step: 5
Training loss: 1.4408749341964722
Validation loss: 1.9753183780177948

Epoch: 5| Step: 6
Training loss: 1.5966733694076538
Validation loss: 2.004848590461157

Epoch: 5| Step: 7
Training loss: 1.1277682781219482
Validation loss: 1.992872154840859

Epoch: 5| Step: 8
Training loss: 1.4146032333374023
Validation loss: 1.9932537360857892

Epoch: 5| Step: 9
Training loss: 1.0058443546295166
Validation loss: 1.962934281236382

Epoch: 5| Step: 10
Training loss: 1.3894904851913452
Validation loss: 1.990196556173345

Epoch: 596| Step: 0
Training loss: 0.9607017636299133
Validation loss: 2.0091752711162774

Epoch: 5| Step: 1
Training loss: 0.9679716229438782
Validation loss: 2.001836084550427

Epoch: 5| Step: 2
Training loss: 1.174757719039917
Validation loss: 1.9861473844897362

Epoch: 5| Step: 3
Training loss: 1.5714080333709717
Validation loss: 1.9605160477340862

Epoch: 5| Step: 4
Training loss: 1.0571094751358032
Validation loss: 1.9593820546263008

Epoch: 5| Step: 5
Training loss: 0.9697991609573364
Validation loss: 1.9605128790742608

Epoch: 5| Step: 6
Training loss: 0.7410987615585327
Validation loss: 1.9865014014705535

Epoch: 5| Step: 7
Training loss: 1.5215275287628174
Validation loss: 1.9492742066742272

Epoch: 5| Step: 8
Training loss: 1.0178582668304443
Validation loss: 1.955033484325614

Epoch: 5| Step: 9
Training loss: 1.3997541666030884
Validation loss: 2.025624144461847

Epoch: 5| Step: 10
Training loss: 1.407360553741455
Validation loss: 2.00526757906842

Epoch: 597| Step: 0
Training loss: 1.082613229751587
Validation loss: 2.0118292159931634

Epoch: 5| Step: 1
Training loss: 1.213956594467163
Validation loss: 1.9413213704221992

Epoch: 5| Step: 2
Training loss: 1.1440768241882324
Validation loss: 2.001310061382991

Epoch: 5| Step: 3
Training loss: 1.6209790706634521
Validation loss: 2.0253993593236452

Epoch: 5| Step: 4
Training loss: 1.2740126848220825
Validation loss: 1.9949050372646702

Epoch: 5| Step: 5
Training loss: 0.9913355112075806
Validation loss: 2.045032949857814

Epoch: 5| Step: 6
Training loss: 0.5795502066612244
Validation loss: 2.0020247915739655

Epoch: 5| Step: 7
Training loss: 1.1406641006469727
Validation loss: 2.040221425794786

Epoch: 5| Step: 8
Training loss: 1.4347347021102905
Validation loss: 2.013800876114958

Epoch: 5| Step: 9
Training loss: 1.396239995956421
Validation loss: 2.0104851427898613

Epoch: 5| Step: 10
Training loss: 1.1645281314849854
Validation loss: 1.9920322587413173

Epoch: 598| Step: 0
Training loss: 0.9084428548812866
Validation loss: 1.9988308939882504

Epoch: 5| Step: 1
Training loss: 1.0100748538970947
Validation loss: 2.008866851047803

Epoch: 5| Step: 2
Training loss: 1.2892805337905884
Validation loss: 2.0193608332705755

Epoch: 5| Step: 3
Training loss: 1.196305513381958
Validation loss: 1.9842893462027273

Epoch: 5| Step: 4
Training loss: 1.3454278707504272
Validation loss: 1.9538862423230243

Epoch: 5| Step: 5
Training loss: 1.2209056615829468
Validation loss: 1.973265427415089

Epoch: 5| Step: 6
Training loss: 0.857525646686554
Validation loss: 1.9521204104987524

Epoch: 5| Step: 7
Training loss: 1.2726398706436157
Validation loss: 1.9777726024709723

Epoch: 5| Step: 8
Training loss: 1.420064091682434
Validation loss: 1.9314609432733187

Epoch: 5| Step: 9
Training loss: 1.0305615663528442
Validation loss: 2.0250819703584075

Epoch: 5| Step: 10
Training loss: 1.2769775390625
Validation loss: 1.9847252856018722

Epoch: 599| Step: 0
Training loss: 1.7427679300308228
Validation loss: 1.9304196898655226

Epoch: 5| Step: 1
Training loss: 1.1870203018188477
Validation loss: 1.9327518350334578

Epoch: 5| Step: 2
Training loss: 0.8981917500495911
Validation loss: 2.0480776897040744

Epoch: 5| Step: 3
Training loss: 1.0519100427627563
Validation loss: 1.9864894651597547

Epoch: 5| Step: 4
Training loss: 0.8118684887886047
Validation loss: 2.000823095280637

Epoch: 5| Step: 5
Training loss: 1.3745578527450562
Validation loss: 2.025184137846834

Epoch: 5| Step: 6
Training loss: 1.5405333042144775
Validation loss: 2.0163358129480833

Epoch: 5| Step: 7
Training loss: 0.9842839241027832
Validation loss: 1.9749343856688468

Epoch: 5| Step: 8
Training loss: 1.138974905014038
Validation loss: 1.982159040307486

Epoch: 5| Step: 9
Training loss: 1.2837622165679932
Validation loss: 1.960278162392237

Epoch: 5| Step: 10
Training loss: 0.9044077396392822
Validation loss: 2.0150043144020984

Epoch: 600| Step: 0
Training loss: 1.0616859197616577
Validation loss: 2.0031761636016188

Epoch: 5| Step: 1
Training loss: 1.0211007595062256
Validation loss: 1.9902128711823495

Epoch: 5| Step: 2
Training loss: 1.307464361190796
Validation loss: 1.9865701544669367

Epoch: 5| Step: 3
Training loss: 1.5354429483413696
Validation loss: 1.9552742473540767

Epoch: 5| Step: 4
Training loss: 1.5005966424942017
Validation loss: 1.9813462072803127

Epoch: 5| Step: 5
Training loss: 1.6081798076629639
Validation loss: 1.9845223657546505

Epoch: 5| Step: 6
Training loss: 0.823708176612854
Validation loss: 1.9953221941506991

Epoch: 5| Step: 7
Training loss: 0.7519300580024719
Validation loss: 1.9691727392135128

Epoch: 5| Step: 8
Training loss: 0.9715582728385925
Validation loss: 2.0008490726511967

Epoch: 5| Step: 9
Training loss: 1.1281793117523193
Validation loss: 1.9562793060015606

Epoch: 5| Step: 10
Training loss: 0.9658279418945312
Validation loss: 1.9450838591462822

Epoch: 601| Step: 0
Training loss: 0.8606975674629211
Validation loss: 2.034408406544757

Epoch: 5| Step: 1
Training loss: 1.1115177869796753
Validation loss: 1.9776831339764338

Epoch: 5| Step: 2
Training loss: 1.2702056169509888
Validation loss: 1.994456143789394

Epoch: 5| Step: 3
Training loss: 1.0737355947494507
Validation loss: 1.9958831828127626

Epoch: 5| Step: 4
Training loss: 1.5931575298309326
Validation loss: 1.9978427553689608

Epoch: 5| Step: 5
Training loss: 1.5092742443084717
Validation loss: 2.040049563172043

Epoch: 5| Step: 6
Training loss: 1.086517333984375
Validation loss: 2.05955187736019

Epoch: 5| Step: 7
Training loss: 1.2554774284362793
Validation loss: 2.0129751197753416

Epoch: 5| Step: 8
Training loss: 0.9581063985824585
Validation loss: 2.0541997160962833

Epoch: 5| Step: 9
Training loss: 0.7856042981147766
Validation loss: 2.010657689904654

Epoch: 5| Step: 10
Training loss: 1.4812203645706177
Validation loss: 2.0559646327008485

Epoch: 602| Step: 0
Training loss: 1.1398112773895264
Validation loss: 2.0023424497214695

Epoch: 5| Step: 1
Training loss: 0.8810606002807617
Validation loss: 1.9940247163977673

Epoch: 5| Step: 2
Training loss: 0.8955496549606323
Validation loss: 1.9948599415440713

Epoch: 5| Step: 3
Training loss: 1.0996017456054688
Validation loss: 1.9757917324701946

Epoch: 5| Step: 4
Training loss: 1.0006825923919678
Validation loss: 1.9459758112507481

Epoch: 5| Step: 5
Training loss: 0.9985811114311218
Validation loss: 1.9824526797058761

Epoch: 5| Step: 6
Training loss: 1.515591025352478
Validation loss: 1.9893302738025624

Epoch: 5| Step: 7
Training loss: 1.2892671823501587
Validation loss: 1.991427763815849

Epoch: 5| Step: 8
Training loss: 0.9895991086959839
Validation loss: 1.978424613193799

Epoch: 5| Step: 9
Training loss: 1.4278762340545654
Validation loss: 1.9967366418530863

Epoch: 5| Step: 10
Training loss: 1.5167016983032227
Validation loss: 1.9643290632514543

Epoch: 603| Step: 0
Training loss: 1.1273523569107056
Validation loss: 1.9453393284992506

Epoch: 5| Step: 1
Training loss: 0.5785461068153381
Validation loss: 2.009633192452051

Epoch: 5| Step: 2
Training loss: 1.5545332431793213
Validation loss: 2.012878079568186

Epoch: 5| Step: 3
Training loss: 1.3849598169326782
Validation loss: 1.970515399850825

Epoch: 5| Step: 4
Training loss: 1.2165296077728271
Validation loss: 1.9656267243046914

Epoch: 5| Step: 5
Training loss: 1.3689481019973755
Validation loss: 1.9564068983959895

Epoch: 5| Step: 6
Training loss: 1.0582984685897827
Validation loss: 2.0129920103216685

Epoch: 5| Step: 7
Training loss: 1.297934651374817
Validation loss: 1.9900003299918225

Epoch: 5| Step: 8
Training loss: 0.7728393077850342
Validation loss: 1.9606341162035543

Epoch: 5| Step: 9
Training loss: 1.0583562850952148
Validation loss: 1.9898190831625333

Epoch: 5| Step: 10
Training loss: 1.3545162677764893
Validation loss: 2.0228129535593014

Epoch: 604| Step: 0
Training loss: 1.4774234294891357
Validation loss: 2.003329873085022

Epoch: 5| Step: 1
Training loss: 1.3016808032989502
Validation loss: 2.033021705124968

Epoch: 5| Step: 2
Training loss: 0.915518581867218
Validation loss: 2.0053840529534126

Epoch: 5| Step: 3
Training loss: 1.4817434549331665
Validation loss: 2.00744959615892

Epoch: 5| Step: 4
Training loss: 0.8686444163322449
Validation loss: 1.9919642786825857

Epoch: 5| Step: 5
Training loss: 1.355647325515747
Validation loss: 1.9988841754133984

Epoch: 5| Step: 6
Training loss: 1.0873472690582275
Validation loss: 1.9961628862606582

Epoch: 5| Step: 7
Training loss: 0.6170604825019836
Validation loss: 1.9673710292385471

Epoch: 5| Step: 8
Training loss: 1.1769853830337524
Validation loss: 1.9831850233898367

Epoch: 5| Step: 9
Training loss: 1.0501453876495361
Validation loss: 2.000805019050516

Epoch: 5| Step: 10
Training loss: 1.4527689218521118
Validation loss: 1.99473701882106

Epoch: 605| Step: 0
Training loss: 1.2261316776275635
Validation loss: 1.9799728983192033

Epoch: 5| Step: 1
Training loss: 1.156123399734497
Validation loss: 1.9874698154387935

Epoch: 5| Step: 2
Training loss: 0.7676726579666138
Validation loss: 1.9918356813410276

Epoch: 5| Step: 3
Training loss: 1.5845606327056885
Validation loss: 1.9952128779503606

Epoch: 5| Step: 4
Training loss: 1.2494221925735474
Validation loss: 2.0209681231488466

Epoch: 5| Step: 5
Training loss: 1.2289409637451172
Validation loss: 2.0107732101153304

Epoch: 5| Step: 6
Training loss: 0.9930955767631531
Validation loss: 2.002056332044704

Epoch: 5| Step: 7
Training loss: 0.9316774606704712
Validation loss: 2.012917084078635

Epoch: 5| Step: 8
Training loss: 1.555699348449707
Validation loss: 2.015835118550126

Epoch: 5| Step: 9
Training loss: 1.2440531253814697
Validation loss: 2.0086321523112636

Epoch: 5| Step: 10
Training loss: 0.955533504486084
Validation loss: 1.990578596309949

Epoch: 606| Step: 0
Training loss: 1.0645678043365479
Validation loss: 2.0195871732568227

Epoch: 5| Step: 1
Training loss: 0.987450122833252
Validation loss: 2.0226165325410905

Epoch: 5| Step: 2
Training loss: 0.9332587122917175
Validation loss: 2.043821228447781

Epoch: 5| Step: 3
Training loss: 1.4855681657791138
Validation loss: 1.9624635122155631

Epoch: 5| Step: 4
Training loss: 1.1333616971969604
Validation loss: 1.997243321070107

Epoch: 5| Step: 5
Training loss: 1.2408883571624756
Validation loss: 1.968842529481457

Epoch: 5| Step: 6
Training loss: 1.3938930034637451
Validation loss: 1.9995637081002677

Epoch: 5| Step: 7
Training loss: 0.8221957087516785
Validation loss: 1.9877319156482656

Epoch: 5| Step: 8
Training loss: 1.0596950054168701
Validation loss: 1.9803590005443943

Epoch: 5| Step: 9
Training loss: 1.510985016822815
Validation loss: 1.9762649023404686

Epoch: 5| Step: 10
Training loss: 1.0947535037994385
Validation loss: 2.0078981717427573

Epoch: 607| Step: 0
Training loss: 0.9751375913619995
Validation loss: 1.974977949614166

Epoch: 5| Step: 1
Training loss: 0.9805248975753784
Validation loss: 2.0008701816681893

Epoch: 5| Step: 2
Training loss: 1.5922340154647827
Validation loss: 1.9855382122019285

Epoch: 5| Step: 3
Training loss: 1.616967797279358
Validation loss: 1.9800610350024315

Epoch: 5| Step: 4
Training loss: 1.1556512117385864
Validation loss: 1.9709459645773775

Epoch: 5| Step: 5
Training loss: 0.6777431964874268
Validation loss: 2.0444902771262714

Epoch: 5| Step: 6
Training loss: 1.0236353874206543
Validation loss: 1.9727908552333873

Epoch: 5| Step: 7
Training loss: 1.3205697536468506
Validation loss: 2.011288078882361

Epoch: 5| Step: 8
Training loss: 0.9191425442695618
Validation loss: 1.9579879519759968

Epoch: 5| Step: 9
Training loss: 1.1560535430908203
Validation loss: 1.9287349395854498

Epoch: 5| Step: 10
Training loss: 1.4301525354385376
Validation loss: 1.9897018799217798

Epoch: 608| Step: 0
Training loss: 1.595099925994873
Validation loss: 1.977294377101365

Epoch: 5| Step: 1
Training loss: 1.415403962135315
Validation loss: 2.0133046937245194

Epoch: 5| Step: 2
Training loss: 1.0626890659332275
Validation loss: 1.9556402442275838

Epoch: 5| Step: 3
Training loss: 1.2915313243865967
Validation loss: 2.04049172452701

Epoch: 5| Step: 4
Training loss: 1.5049923658370972
Validation loss: 1.9701822880775697

Epoch: 5| Step: 5
Training loss: 0.7530125379562378
Validation loss: 2.011963834044754

Epoch: 5| Step: 6
Training loss: 0.6191708445549011
Validation loss: 1.9716015746516566

Epoch: 5| Step: 7
Training loss: 0.6494313478469849
Validation loss: 1.9915075712306525

Epoch: 5| Step: 8
Training loss: 1.230075478553772
Validation loss: 1.9646648283927672

Epoch: 5| Step: 9
Training loss: 1.3735532760620117
Validation loss: 1.9947208563486736

Epoch: 5| Step: 10
Training loss: 1.3271747827529907
Validation loss: 1.970837939170099

Epoch: 609| Step: 0
Training loss: 1.1697657108306885
Validation loss: 1.955392788815242

Epoch: 5| Step: 1
Training loss: 0.625860333442688
Validation loss: 1.9726532864314255

Epoch: 5| Step: 2
Training loss: 1.4051754474639893
Validation loss: 1.9681444309091056

Epoch: 5| Step: 3
Training loss: 1.2064005136489868
Validation loss: 1.9767247476885397

Epoch: 5| Step: 4
Training loss: 1.1543654203414917
Validation loss: 1.9660790863857474

Epoch: 5| Step: 5
Training loss: 1.0425727367401123
Validation loss: 1.988776635098201

Epoch: 5| Step: 6
Training loss: 0.7874467372894287
Validation loss: 1.9880946118344542

Epoch: 5| Step: 7
Training loss: 1.5660358667373657
Validation loss: 1.9930020006754066

Epoch: 5| Step: 8
Training loss: 1.4536892175674438
Validation loss: 2.0095648175926617

Epoch: 5| Step: 9
Training loss: 0.9543322324752808
Validation loss: 2.0008733990371868

Epoch: 5| Step: 10
Training loss: 1.4891282320022583
Validation loss: 1.9950386196054437

Epoch: 610| Step: 0
Training loss: 1.1348552703857422
Validation loss: 2.014903414633966

Epoch: 5| Step: 1
Training loss: 1.0502102375030518
Validation loss: 2.019095295219011

Epoch: 5| Step: 2
Training loss: 0.8937823176383972
Validation loss: 2.037942260824224

Epoch: 5| Step: 3
Training loss: 1.0381524562835693
Validation loss: 2.029510418574015

Epoch: 5| Step: 4
Training loss: 1.2474561929702759
Validation loss: 2.0259591110291018

Epoch: 5| Step: 5
Training loss: 1.1847727298736572
Validation loss: 2.0156628700994674

Epoch: 5| Step: 6
Training loss: 1.459466576576233
Validation loss: 1.9805368069679505

Epoch: 5| Step: 7
Training loss: 1.213533639907837
Validation loss: 2.019274083516931

Epoch: 5| Step: 8
Training loss: 1.1967999935150146
Validation loss: 2.03551596595395

Epoch: 5| Step: 9
Training loss: 1.2822643518447876
Validation loss: 1.9799164341342064

Epoch: 5| Step: 10
Training loss: 0.9564825892448425
Validation loss: 1.9915633893782092

Epoch: 611| Step: 0
Training loss: 1.4517492055892944
Validation loss: 1.989851213270618

Epoch: 5| Step: 1
Training loss: 1.2858879566192627
Validation loss: 2.019576698221186

Epoch: 5| Step: 2
Training loss: 0.9427854418754578
Validation loss: 2.0130367573871406

Epoch: 5| Step: 3
Training loss: 1.0298689603805542
Validation loss: 1.927018227115754

Epoch: 5| Step: 4
Training loss: 0.7121810913085938
Validation loss: 1.9816376086204284

Epoch: 5| Step: 5
Training loss: 1.0688579082489014
Validation loss: 1.9694929930471605

Epoch: 5| Step: 6
Training loss: 1.049745798110962
Validation loss: 1.9307263910129506

Epoch: 5| Step: 7
Training loss: 1.245627999305725
Validation loss: 2.0210645891004995

Epoch: 5| Step: 8
Training loss: 1.5092546939849854
Validation loss: 1.9840198575809438

Epoch: 5| Step: 9
Training loss: 1.3263119459152222
Validation loss: 1.9846379449290614

Epoch: 5| Step: 10
Training loss: 1.071312427520752
Validation loss: 2.012864749918702

Epoch: 612| Step: 0
Training loss: 0.671291708946228
Validation loss: 2.0102106345597135

Epoch: 5| Step: 1
Training loss: 0.9529227018356323
Validation loss: 2.002072416326051

Epoch: 5| Step: 2
Training loss: 1.1878708600997925
Validation loss: 1.929609424324446

Epoch: 5| Step: 3
Training loss: 1.3074967861175537
Validation loss: 1.968110087097332

Epoch: 5| Step: 4
Training loss: 0.8930424451828003
Validation loss: 1.9818944123483473

Epoch: 5| Step: 5
Training loss: 0.6140533685684204
Validation loss: 2.0036712641357095

Epoch: 5| Step: 6
Training loss: 1.6379470825195312
Validation loss: 1.9415454992683985

Epoch: 5| Step: 7
Training loss: 1.6205135583877563
Validation loss: 2.0128257723264795

Epoch: 5| Step: 8
Training loss: 1.7230926752090454
Validation loss: 2.010593847561908

Epoch: 5| Step: 9
Training loss: 1.1871092319488525
Validation loss: 1.9748375749075284

Epoch: 5| Step: 10
Training loss: 0.9004783630371094
Validation loss: 2.0217439564325477

Epoch: 613| Step: 0
Training loss: 0.9524675607681274
Validation loss: 1.9714032039847424

Epoch: 5| Step: 1
Training loss: 0.6944606304168701
Validation loss: 1.9600380530921362

Epoch: 5| Step: 2
Training loss: 1.9589471817016602
Validation loss: 1.998242303889285

Epoch: 5| Step: 3
Training loss: 1.5320643186569214
Validation loss: 1.999879966499985

Epoch: 5| Step: 4
Training loss: 0.9289448857307434
Validation loss: 1.983843158650142

Epoch: 5| Step: 5
Training loss: 1.6341698169708252
Validation loss: 1.9506724290950324

Epoch: 5| Step: 6
Training loss: 0.9704238772392273
Validation loss: 1.9678020413203905

Epoch: 5| Step: 7
Training loss: 1.003803014755249
Validation loss: 1.9480520832923152

Epoch: 5| Step: 8
Training loss: 1.2568203210830688
Validation loss: 1.9731548729763235

Epoch: 5| Step: 9
Training loss: 0.8105537295341492
Validation loss: 1.9514034999314176

Epoch: 5| Step: 10
Training loss: 1.1579172611236572
Validation loss: 1.9702812907516316

Epoch: 614| Step: 0
Training loss: 1.0022984743118286
Validation loss: 2.0173703816629227

Epoch: 5| Step: 1
Training loss: 0.861493706703186
Validation loss: 1.9778928500349804

Epoch: 5| Step: 2
Training loss: 1.3202364444732666
Validation loss: 1.9983510150704333

Epoch: 5| Step: 3
Training loss: 0.8172971606254578
Validation loss: 2.0173169669284614

Epoch: 5| Step: 4
Training loss: 1.7825851440429688
Validation loss: 2.0224359291856007

Epoch: 5| Step: 5
Training loss: 1.455878496170044
Validation loss: 1.9933762960536505

Epoch: 5| Step: 6
Training loss: 0.8806877136230469
Validation loss: 2.042139011044656

Epoch: 5| Step: 7
Training loss: 1.106053113937378
Validation loss: 2.029827804975612

Epoch: 5| Step: 8
Training loss: 1.0325672626495361
Validation loss: 2.0626384673580045

Epoch: 5| Step: 9
Training loss: 1.2275313138961792
Validation loss: 2.0488929953626407

Epoch: 5| Step: 10
Training loss: 1.4328908920288086
Validation loss: 2.019477190509919

Epoch: 615| Step: 0
Training loss: 1.2842352390289307
Validation loss: 1.9753917058308919

Epoch: 5| Step: 1
Training loss: 1.9013917446136475
Validation loss: 2.0151444263355707

Epoch: 5| Step: 2
Training loss: 0.7408219575881958
Validation loss: 2.020729834033597

Epoch: 5| Step: 3
Training loss: 0.5285568833351135
Validation loss: 1.9949116617120721

Epoch: 5| Step: 4
Training loss: 0.849923312664032
Validation loss: 1.9266929190645936

Epoch: 5| Step: 5
Training loss: 0.8390421867370605
Validation loss: 1.9778693004321026

Epoch: 5| Step: 6
Training loss: 1.1893031597137451
Validation loss: 2.0068506809972946

Epoch: 5| Step: 7
Training loss: 1.6536544561386108
Validation loss: 1.9852470710713377

Epoch: 5| Step: 8
Training loss: 1.0952951908111572
Validation loss: 2.0008294018366004

Epoch: 5| Step: 9
Training loss: 1.2225369215011597
Validation loss: 1.9783216420040335

Epoch: 5| Step: 10
Training loss: 1.0637857913970947
Validation loss: 1.9777685365369242

Epoch: 616| Step: 0
Training loss: 1.0818907022476196
Validation loss: 1.9687252211314377

Epoch: 5| Step: 1
Training loss: 0.6494532823562622
Validation loss: 1.9820950441463019

Epoch: 5| Step: 2
Training loss: 1.682125449180603
Validation loss: 1.972957484183773

Epoch: 5| Step: 3
Training loss: 1.390570878982544
Validation loss: 1.9985232865938576

Epoch: 5| Step: 4
Training loss: 1.0658602714538574
Validation loss: 1.9778852731950822

Epoch: 5| Step: 5
Training loss: 1.399857759475708
Validation loss: 1.9797975504270164

Epoch: 5| Step: 6
Training loss: 1.0114078521728516
Validation loss: 2.0395993776218866

Epoch: 5| Step: 7
Training loss: 1.01594078540802
Validation loss: 1.9721296961589525

Epoch: 5| Step: 8
Training loss: 1.0226649045944214
Validation loss: 1.9628452895790018

Epoch: 5| Step: 9
Training loss: 1.3297427892684937
Validation loss: 2.039643297913254

Epoch: 5| Step: 10
Training loss: 0.9659265875816345
Validation loss: 1.9774841993085799

Epoch: 617| Step: 0
Training loss: 1.02242112159729
Validation loss: 1.994357999934945

Epoch: 5| Step: 1
Training loss: 1.1160460710525513
Validation loss: 1.9912199204967869

Epoch: 5| Step: 2
Training loss: 1.3046303987503052
Validation loss: 2.0049246716242966

Epoch: 5| Step: 3
Training loss: 1.060587763786316
Validation loss: 2.0135828525789323

Epoch: 5| Step: 4
Training loss: 1.421764612197876
Validation loss: 1.9722803472190775

Epoch: 5| Step: 5
Training loss: 1.2704156637191772
Validation loss: 2.0385938946918776

Epoch: 5| Step: 6
Training loss: 1.3832792043685913
Validation loss: 1.9965080471449002

Epoch: 5| Step: 7
Training loss: 0.67100590467453
Validation loss: 1.9775542418162029

Epoch: 5| Step: 8
Training loss: 0.9474149942398071
Validation loss: 1.9939801282780145

Epoch: 5| Step: 9
Training loss: 1.0263751745224
Validation loss: 2.0453125328146

Epoch: 5| Step: 10
Training loss: 1.582617998123169
Validation loss: 1.9346461167899511

Epoch: 618| Step: 0
Training loss: 0.6513602137565613
Validation loss: 1.9407784810630224

Epoch: 5| Step: 1
Training loss: 0.8440107107162476
Validation loss: 2.001260308809178

Epoch: 5| Step: 2
Training loss: 1.4180724620819092
Validation loss: 2.0139618714650473

Epoch: 5| Step: 3
Training loss: 0.8882309794425964
Validation loss: 1.9674887285437634

Epoch: 5| Step: 4
Training loss: 1.3809577226638794
Validation loss: 1.957039693350433

Epoch: 5| Step: 5
Training loss: 1.235389232635498
Validation loss: 1.9695156646031204

Epoch: 5| Step: 6
Training loss: 1.3794353008270264
Validation loss: 1.99970853969615

Epoch: 5| Step: 7
Training loss: 1.5500410795211792
Validation loss: 1.9480988992157804

Epoch: 5| Step: 8
Training loss: 1.0563228130340576
Validation loss: 1.9540948406342538

Epoch: 5| Step: 9
Training loss: 1.1140872240066528
Validation loss: 1.9685805279721496

Epoch: 5| Step: 10
Training loss: 1.0550726652145386
Validation loss: 1.9485941369046447

Epoch: 619| Step: 0
Training loss: 1.0822453498840332
Validation loss: 2.0081634047210857

Epoch: 5| Step: 1
Training loss: 1.6297695636749268
Validation loss: 1.9628523831726403

Epoch: 5| Step: 2
Training loss: 1.2186317443847656
Validation loss: 2.0059452338885237

Epoch: 5| Step: 3
Training loss: 1.3621242046356201
Validation loss: 2.0224561152919645

Epoch: 5| Step: 4
Training loss: 1.0470402240753174
Validation loss: 2.004272699356079

Epoch: 5| Step: 5
Training loss: 0.909710705280304
Validation loss: 2.0021307237686647

Epoch: 5| Step: 6
Training loss: 0.8282085657119751
Validation loss: 2.044897828050839

Epoch: 5| Step: 7
Training loss: 1.486069679260254
Validation loss: 1.9678869952437699

Epoch: 5| Step: 8
Training loss: 0.979080080986023
Validation loss: 2.018004050818823

Epoch: 5| Step: 9
Training loss: 0.8408336639404297
Validation loss: 2.005124809921429

Epoch: 5| Step: 10
Training loss: 1.364721655845642
Validation loss: 1.9607844583449825

Epoch: 620| Step: 0
Training loss: 1.464054822921753
Validation loss: 1.9526422075046006

Epoch: 5| Step: 1
Training loss: 1.2427195310592651
Validation loss: 1.9754370079245618

Epoch: 5| Step: 2
Training loss: 1.1236125230789185
Validation loss: 2.039922132286974

Epoch: 5| Step: 3
Training loss: 0.9277284741401672
Validation loss: 2.048801306755312

Epoch: 5| Step: 4
Training loss: 1.188357949256897
Validation loss: 1.9882620457679994

Epoch: 5| Step: 5
Training loss: 1.1779340505599976
Validation loss: 1.9900535396350327

Epoch: 5| Step: 6
Training loss: 0.9285300374031067
Validation loss: 1.9848026075670797

Epoch: 5| Step: 7
Training loss: 1.2377736568450928
Validation loss: 2.029713323039393

Epoch: 5| Step: 8
Training loss: 1.0611789226531982
Validation loss: 1.9777392738608903

Epoch: 5| Step: 9
Training loss: 1.0439027547836304
Validation loss: 2.0296448174343316

Epoch: 5| Step: 10
Training loss: 1.251230001449585
Validation loss: 1.9936390487096642

Epoch: 621| Step: 0
Training loss: 0.7728044390678406
Validation loss: 1.986731235698987

Epoch: 5| Step: 1
Training loss: 1.1503853797912598
Validation loss: 1.9743126438510032

Epoch: 5| Step: 2
Training loss: 0.7476307153701782
Validation loss: 2.0286710505844443

Epoch: 5| Step: 3
Training loss: 0.9641302824020386
Validation loss: 1.9405845262671029

Epoch: 5| Step: 4
Training loss: 1.8475735187530518
Validation loss: 2.014384344059934

Epoch: 5| Step: 5
Training loss: 0.7465023398399353
Validation loss: 1.9678694612236434

Epoch: 5| Step: 6
Training loss: 1.5867583751678467
Validation loss: 1.9450980283880746

Epoch: 5| Step: 7
Training loss: 0.9163026809692383
Validation loss: 1.9733100027166388

Epoch: 5| Step: 8
Training loss: 1.5618566274642944
Validation loss: 1.9689694514838598

Epoch: 5| Step: 9
Training loss: 1.4783598184585571
Validation loss: 2.0176460563495593

Epoch: 5| Step: 10
Training loss: 1.056105613708496
Validation loss: 1.9758211592192292

Epoch: 622| Step: 0
Training loss: 0.8125196695327759
Validation loss: 2.044630076295586

Epoch: 5| Step: 1
Training loss: 0.6411426067352295
Validation loss: 1.9949867648463095

Epoch: 5| Step: 2
Training loss: 1.01212477684021
Validation loss: 1.9845837764842535

Epoch: 5| Step: 3
Training loss: 1.737813949584961
Validation loss: 1.9712303248784875

Epoch: 5| Step: 4
Training loss: 1.114857792854309
Validation loss: 1.9968405923535746

Epoch: 5| Step: 5
Training loss: 1.2654130458831787
Validation loss: 2.0042291943744948

Epoch: 5| Step: 6
Training loss: 1.0734926462173462
Validation loss: 1.953617283093032

Epoch: 5| Step: 7
Training loss: 1.4150892496109009
Validation loss: 2.0091016984754995

Epoch: 5| Step: 8
Training loss: 1.3090344667434692
Validation loss: 1.9697018848952426

Epoch: 5| Step: 9
Training loss: 1.4086415767669678
Validation loss: 1.9697319358907721

Epoch: 5| Step: 10
Training loss: 0.9280851483345032
Validation loss: 1.9941147911933161

Epoch: 623| Step: 0
Training loss: 1.4155542850494385
Validation loss: 2.0021751657609017

Epoch: 5| Step: 1
Training loss: 1.1216716766357422
Validation loss: 1.959341000485164

Epoch: 5| Step: 2
Training loss: 0.7043663859367371
Validation loss: 2.0661397685286818

Epoch: 5| Step: 3
Training loss: 0.7829118967056274
Validation loss: 1.9912902257775749

Epoch: 5| Step: 4
Training loss: 1.178580641746521
Validation loss: 2.018954982039749

Epoch: 5| Step: 5
Training loss: 1.2681536674499512
Validation loss: 2.0144570668538413

Epoch: 5| Step: 6
Training loss: 1.5621992349624634
Validation loss: 1.9896076353647376

Epoch: 5| Step: 7
Training loss: 1.0455641746520996
Validation loss: 2.0321045947331253

Epoch: 5| Step: 8
Training loss: 1.0197080373764038
Validation loss: 1.9655854240540536

Epoch: 5| Step: 9
Training loss: 1.3273303508758545
Validation loss: 2.0010445246132473

Epoch: 5| Step: 10
Training loss: 1.0841432809829712
Validation loss: 2.022105751499053

Epoch: 624| Step: 0
Training loss: 1.2671111822128296
Validation loss: 1.9463718757834485

Epoch: 5| Step: 1
Training loss: 0.7665272951126099
Validation loss: 2.000766264495029

Epoch: 5| Step: 2
Training loss: 1.0436618328094482
Validation loss: 2.0213661398938907

Epoch: 5| Step: 3
Training loss: 1.392235517501831
Validation loss: 2.0158566082677534

Epoch: 5| Step: 4
Training loss: 1.1967999935150146
Validation loss: 1.963545972301114

Epoch: 5| Step: 5
Training loss: 0.8447378277778625
Validation loss: 1.991133818062403

Epoch: 5| Step: 6
Training loss: 1.0161288976669312
Validation loss: 2.021214477477535

Epoch: 5| Step: 7
Training loss: 1.611585021018982
Validation loss: 1.9553751253312635

Epoch: 5| Step: 8
Training loss: 1.3126810789108276
Validation loss: 2.01969660482099

Epoch: 5| Step: 9
Training loss: 1.1528675556182861
Validation loss: 1.9995176587053525

Epoch: 5| Step: 10
Training loss: 0.9838830232620239
Validation loss: 2.006884877399732

Epoch: 625| Step: 0
Training loss: 0.8440658450126648
Validation loss: 1.98810016211643

Epoch: 5| Step: 1
Training loss: 0.9983389973640442
Validation loss: 1.948108318031475

Epoch: 5| Step: 2
Training loss: 1.1453678607940674
Validation loss: 1.997082971757458

Epoch: 5| Step: 3
Training loss: 0.8279131054878235
Validation loss: 2.02549389613572

Epoch: 5| Step: 4
Training loss: 1.1666028499603271
Validation loss: 1.9855050809921757

Epoch: 5| Step: 5
Training loss: 1.6687953472137451
Validation loss: 1.9804002700313446

Epoch: 5| Step: 6
Training loss: 1.139269471168518
Validation loss: 2.016942454922584

Epoch: 5| Step: 7
Training loss: 1.2048677206039429
Validation loss: 1.949723059131253

Epoch: 5| Step: 8
Training loss: 0.904251217842102
Validation loss: 1.996252041991039

Epoch: 5| Step: 9
Training loss: 1.4660584926605225
Validation loss: 1.9735303604474632

Epoch: 5| Step: 10
Training loss: 1.0482090711593628
Validation loss: 2.017965280881492

Epoch: 626| Step: 0
Training loss: 0.9446995854377747
Validation loss: 2.0361114701917096

Epoch: 5| Step: 1
Training loss: 1.4043794870376587
Validation loss: 1.9646164845394831

Epoch: 5| Step: 2
Training loss: 1.267260193824768
Validation loss: 1.923886381169801

Epoch: 5| Step: 3
Training loss: 0.8315935134887695
Validation loss: 1.9747106439323836

Epoch: 5| Step: 4
Training loss: 1.302219033241272
Validation loss: 1.9762106198136524

Epoch: 5| Step: 5
Training loss: 1.1889359951019287
Validation loss: 2.0308481903486353

Epoch: 5| Step: 6
Training loss: 1.2475417852401733
Validation loss: 1.9373189326255553

Epoch: 5| Step: 7
Training loss: 0.9644536972045898
Validation loss: 1.989755953511884

Epoch: 5| Step: 8
Training loss: 1.6631542444229126
Validation loss: 2.0317435520951466

Epoch: 5| Step: 9
Training loss: 0.7759783864021301
Validation loss: 2.014481270185081

Epoch: 5| Step: 10
Training loss: 0.8884298205375671
Validation loss: 2.028959074328023

Epoch: 627| Step: 0
Training loss: 1.6891896724700928
Validation loss: 2.0301257115538403

Epoch: 5| Step: 1
Training loss: 1.276045322418213
Validation loss: 1.9658685576531194

Epoch: 5| Step: 2
Training loss: 1.130652666091919
Validation loss: 2.0649062318186604

Epoch: 5| Step: 3
Training loss: 1.1593730449676514
Validation loss: 1.9991494506917975

Epoch: 5| Step: 4
Training loss: 1.3245056867599487
Validation loss: 1.9861223082388602

Epoch: 5| Step: 5
Training loss: 0.9639335870742798
Validation loss: 1.9748633318049933

Epoch: 5| Step: 6
Training loss: 1.5839767456054688
Validation loss: 1.9536752739260275

Epoch: 5| Step: 7
Training loss: 1.0232921838760376
Validation loss: 2.0246505083576327

Epoch: 5| Step: 8
Training loss: 0.7255414128303528
Validation loss: 1.9870822352747763

Epoch: 5| Step: 9
Training loss: 0.8544421195983887
Validation loss: 1.9658049357834684

Epoch: 5| Step: 10
Training loss: 0.5600087642669678
Validation loss: 1.987441127018262

Epoch: 628| Step: 0
Training loss: 1.0646499395370483
Validation loss: 2.034076931656048

Epoch: 5| Step: 1
Training loss: 0.36416035890579224
Validation loss: 1.9348887935761483

Epoch: 5| Step: 2
Training loss: 1.87651789188385
Validation loss: 1.9766779010013869

Epoch: 5| Step: 3
Training loss: 0.7595481872558594
Validation loss: 1.9492031605012956

Epoch: 5| Step: 4
Training loss: 1.2077925205230713
Validation loss: 2.0270667793930217

Epoch: 5| Step: 5
Training loss: 0.5937124490737915
Validation loss: 1.9475270445628832

Epoch: 5| Step: 6
Training loss: 1.399531364440918
Validation loss: 1.9709218766099663

Epoch: 5| Step: 7
Training loss: 1.457094430923462
Validation loss: 1.9657029195498394

Epoch: 5| Step: 8
Training loss: 1.0999879837036133
Validation loss: 1.9961480248358943

Epoch: 5| Step: 9
Training loss: 1.104781985282898
Validation loss: 1.9812949806131341

Epoch: 5| Step: 10
Training loss: 1.6334624290466309
Validation loss: 2.0458050632989533

Epoch: 629| Step: 0
Training loss: 0.8865134119987488
Validation loss: 1.9973328677556847

Epoch: 5| Step: 1
Training loss: 1.3495639562606812
Validation loss: 1.9906576589871479

Epoch: 5| Step: 2
Training loss: 1.2630959749221802
Validation loss: 2.0001244596255723

Epoch: 5| Step: 3
Training loss: 0.7200309634208679
Validation loss: 1.9826421160851755

Epoch: 5| Step: 4
Training loss: 1.5698895454406738
Validation loss: 1.9950120372156943

Epoch: 5| Step: 5
Training loss: 0.7370578050613403
Validation loss: 2.014992710082762

Epoch: 5| Step: 6
Training loss: 1.249138355255127
Validation loss: 1.9508950761569444

Epoch: 5| Step: 7
Training loss: 1.092899203300476
Validation loss: 1.9748826706281273

Epoch: 5| Step: 8
Training loss: 0.9648971557617188
Validation loss: 1.964235677514025

Epoch: 5| Step: 9
Training loss: 1.2017464637756348
Validation loss: 1.9531725427155853

Epoch: 5| Step: 10
Training loss: 1.5254501104354858
Validation loss: 1.9528488523216658

Epoch: 630| Step: 0
Training loss: 1.216530203819275
Validation loss: 1.9563789367675781

Epoch: 5| Step: 1
Training loss: 0.7358397245407104
Validation loss: 1.973550634999429

Epoch: 5| Step: 2
Training loss: 0.8691953420639038
Validation loss: 1.9179361622820619

Epoch: 5| Step: 3
Training loss: 0.7623893022537231
Validation loss: 1.9621051767820954

Epoch: 5| Step: 4
Training loss: 1.3422482013702393
Validation loss: 1.9680991313790763

Epoch: 5| Step: 5
Training loss: 1.253513216972351
Validation loss: 1.999273351443711

Epoch: 5| Step: 6
Training loss: 0.9682580828666687
Validation loss: 1.9453495151253157

Epoch: 5| Step: 7
Training loss: 1.1227009296417236
Validation loss: 2.005443713998282

Epoch: 5| Step: 8
Training loss: 1.1178771257400513
Validation loss: 1.9541619772552161

Epoch: 5| Step: 9
Training loss: 1.3700008392333984
Validation loss: 1.9489990549702798

Epoch: 5| Step: 10
Training loss: 1.5752626657485962
Validation loss: 1.9736590282891386

Epoch: 631| Step: 0
Training loss: 0.6195067167282104
Validation loss: 2.0348990783896497

Epoch: 5| Step: 1
Training loss: 0.788378894329071
Validation loss: 1.9984023865833078

Epoch: 5| Step: 2
Training loss: 0.7478307485580444
Validation loss: 2.024233401462596

Epoch: 5| Step: 3
Training loss: 1.0657002925872803
Validation loss: 1.9933001764359013

Epoch: 5| Step: 4
Training loss: 1.2175390720367432
Validation loss: 1.9877159377580047

Epoch: 5| Step: 5
Training loss: 1.250789999961853
Validation loss: 1.9690917768786032

Epoch: 5| Step: 6
Training loss: 1.3596569299697876
Validation loss: 2.0254686750391477

Epoch: 5| Step: 7
Training loss: 1.2880452871322632
Validation loss: 1.9884136569115423

Epoch: 5| Step: 8
Training loss: 1.0905243158340454
Validation loss: 2.0258996589209444

Epoch: 5| Step: 9
Training loss: 1.1410001516342163
Validation loss: 2.006687471943517

Epoch: 5| Step: 10
Training loss: 1.9475418329238892
Validation loss: 1.994230701077369

Epoch: 632| Step: 0
Training loss: 0.974260151386261
Validation loss: 1.9899288608181862

Epoch: 5| Step: 1
Training loss: 0.719570517539978
Validation loss: 1.994836627796132

Epoch: 5| Step: 2
Training loss: 0.7964452505111694
Validation loss: 1.979451960132968

Epoch: 5| Step: 3
Training loss: 1.0594911575317383
Validation loss: 2.0395139814704977

Epoch: 5| Step: 4
Training loss: 1.4084113836288452
Validation loss: 1.9634995857874553

Epoch: 5| Step: 5
Training loss: 0.8557449579238892
Validation loss: 1.906434343707177

Epoch: 5| Step: 6
Training loss: 1.2283799648284912
Validation loss: 1.9870425244813323

Epoch: 5| Step: 7
Training loss: 0.9919881820678711
Validation loss: 2.0142858182230303

Epoch: 5| Step: 8
Training loss: 1.2957440614700317
Validation loss: 1.9817472273303616

Epoch: 5| Step: 9
Training loss: 1.6467692852020264
Validation loss: 1.981963716527467

Epoch: 5| Step: 10
Training loss: 1.1272995471954346
Validation loss: 1.9578887147288169

Epoch: 633| Step: 0
Training loss: 1.3323709964752197
Validation loss: 1.9423906585221649

Epoch: 5| Step: 1
Training loss: 1.3414642810821533
Validation loss: 1.9629106560061056

Epoch: 5| Step: 2
Training loss: 0.9545073509216309
Validation loss: 1.9594934422482726

Epoch: 5| Step: 3
Training loss: 1.2712366580963135
Validation loss: 2.000994274693151

Epoch: 5| Step: 4
Training loss: 0.6607916951179504
Validation loss: 2.0133464131304013

Epoch: 5| Step: 5
Training loss: 1.1057121753692627
Validation loss: 1.9630555927112538

Epoch: 5| Step: 6
Training loss: 1.3632606267929077
Validation loss: 2.0245122217362925

Epoch: 5| Step: 7
Training loss: 1.392894983291626
Validation loss: 1.9884536099690262

Epoch: 5| Step: 8
Training loss: 0.7780840992927551
Validation loss: 1.9405695469148698

Epoch: 5| Step: 9
Training loss: 0.90742027759552
Validation loss: 1.9572479929975284

Epoch: 5| Step: 10
Training loss: 1.288082242012024
Validation loss: 1.9564962207630117

Epoch: 634| Step: 0
Training loss: 0.6728469133377075
Validation loss: 2.0127763466168473

Epoch: 5| Step: 1
Training loss: 1.4466876983642578
Validation loss: 2.0346554812564643

Epoch: 5| Step: 2
Training loss: 1.033064842224121
Validation loss: 2.0258570230135353

Epoch: 5| Step: 3
Training loss: 1.3583686351776123
Validation loss: 2.04436820296831

Epoch: 5| Step: 4
Training loss: 1.2434369325637817
Validation loss: 1.99506672223409

Epoch: 5| Step: 5
Training loss: 1.4318063259124756
Validation loss: 2.0061098067991194

Epoch: 5| Step: 6
Training loss: 1.3831052780151367
Validation loss: 2.0375329063784693

Epoch: 5| Step: 7
Training loss: 0.9950639605522156
Validation loss: 2.0247738194722

Epoch: 5| Step: 8
Training loss: 1.4381719827651978
Validation loss: 1.9916523656537455

Epoch: 5| Step: 9
Training loss: 0.8604964017868042
Validation loss: 1.9727820491278043

Epoch: 5| Step: 10
Training loss: 0.5282998085021973
Validation loss: 2.0029473279112127

Epoch: 635| Step: 0
Training loss: 1.353806972503662
Validation loss: 1.994960924630524

Epoch: 5| Step: 1
Training loss: 0.9051082730293274
Validation loss: 2.010516417923794

Epoch: 5| Step: 2
Training loss: 1.5308011770248413
Validation loss: 1.9968921356303717

Epoch: 5| Step: 3
Training loss: 1.3255221843719482
Validation loss: 1.959403778917046

Epoch: 5| Step: 4
Training loss: 1.085135579109192
Validation loss: 1.984828802847093

Epoch: 5| Step: 5
Training loss: 1.2049009799957275
Validation loss: 1.934235554869457

Epoch: 5| Step: 6
Training loss: 1.171156644821167
Validation loss: 1.9742174943288167

Epoch: 5| Step: 7
Training loss: 1.038356065750122
Validation loss: 2.0204549117754866

Epoch: 5| Step: 8
Training loss: 0.7467161417007446
Validation loss: 2.0293598098139607

Epoch: 5| Step: 9
Training loss: 1.2367115020751953
Validation loss: 1.9657331384638304

Epoch: 5| Step: 10
Training loss: 0.8361988663673401
Validation loss: 1.9622828768145653

Epoch: 636| Step: 0
Training loss: 0.7640239000320435
Validation loss: 1.9827452398115588

Epoch: 5| Step: 1
Training loss: 1.2818934917449951
Validation loss: 1.946353623943944

Epoch: 5| Step: 2
Training loss: 1.2986637353897095
Validation loss: 1.9825542947297454

Epoch: 5| Step: 3
Training loss: 1.2979323863983154
Validation loss: 1.972216308757823

Epoch: 5| Step: 4
Training loss: 1.6768169403076172
Validation loss: 1.9653555603437527

Epoch: 5| Step: 5
Training loss: 0.7295737862586975
Validation loss: 1.9723272156971756

Epoch: 5| Step: 6
Training loss: 0.9832382202148438
Validation loss: 1.9660275572089738

Epoch: 5| Step: 7
Training loss: 0.7485781908035278
Validation loss: 2.029654359304777

Epoch: 5| Step: 8
Training loss: 1.4551687240600586
Validation loss: 1.9660003826182375

Epoch: 5| Step: 9
Training loss: 1.2921169996261597
Validation loss: 1.9494010889402

Epoch: 5| Step: 10
Training loss: 1.0567142963409424
Validation loss: 1.9762435446503341

Epoch: 637| Step: 0
Training loss: 1.3632243871688843
Validation loss: 1.964569753216159

Epoch: 5| Step: 1
Training loss: 1.620910882949829
Validation loss: 1.9729897335011473

Epoch: 5| Step: 2
Training loss: 1.2334177494049072
Validation loss: 1.960320403498988

Epoch: 5| Step: 3
Training loss: 1.0727335214614868
Validation loss: 1.9747112976607455

Epoch: 5| Step: 4
Training loss: 1.2526555061340332
Validation loss: 1.9918663527375908

Epoch: 5| Step: 5
Training loss: 0.7870742082595825
Validation loss: 2.010701894760132

Epoch: 5| Step: 6
Training loss: 0.9650735855102539
Validation loss: 1.978679177581623

Epoch: 5| Step: 7
Training loss: 0.8610952496528625
Validation loss: 1.990749728295111

Epoch: 5| Step: 8
Training loss: 1.1177613735198975
Validation loss: 1.9495140070556312

Epoch: 5| Step: 9
Training loss: 1.2242388725280762
Validation loss: 1.978385507419545

Epoch: 5| Step: 10
Training loss: 0.8143686652183533
Validation loss: 2.0018680121309016

Epoch: 638| Step: 0
Training loss: 0.6626213788986206
Validation loss: 1.9494721235767487

Epoch: 5| Step: 1
Training loss: 0.8778494596481323
Validation loss: 1.9499350734936294

Epoch: 5| Step: 2
Training loss: 1.5978047847747803
Validation loss: 1.9816316225195443

Epoch: 5| Step: 3
Training loss: 0.5072389245033264
Validation loss: 1.9630162741548272

Epoch: 5| Step: 4
Training loss: 1.4177526235580444
Validation loss: 2.033931770632344

Epoch: 5| Step: 5
Training loss: 1.477494478225708
Validation loss: 2.0075365048582836

Epoch: 5| Step: 6
Training loss: 1.3882824182510376
Validation loss: 1.9542101660082418

Epoch: 5| Step: 7
Training loss: 0.7770599126815796
Validation loss: 1.9777777810250559

Epoch: 5| Step: 8
Training loss: 0.8070837259292603
Validation loss: 1.9802866546056603

Epoch: 5| Step: 9
Training loss: 1.6836309432983398
Validation loss: 2.025119412329889

Epoch: 5| Step: 10
Training loss: 1.0497467517852783
Validation loss: 1.9635360010208622

Epoch: 639| Step: 0
Training loss: 0.7334402799606323
Validation loss: 1.9888912939256238

Epoch: 5| Step: 1
Training loss: 1.101717233657837
Validation loss: 2.013680737505677

Epoch: 5| Step: 2
Training loss: 0.894615650177002
Validation loss: 2.0269701506501887

Epoch: 5| Step: 3
Training loss: 1.606858253479004
Validation loss: 1.9722214052754063

Epoch: 5| Step: 4
Training loss: 0.8130912780761719
Validation loss: 1.9850534367304977

Epoch: 5| Step: 5
Training loss: 1.6501067876815796
Validation loss: 2.01714204460062

Epoch: 5| Step: 6
Training loss: 1.267393708229065
Validation loss: 1.9864502414580314

Epoch: 5| Step: 7
Training loss: 0.6767438650131226
Validation loss: 2.0063742437670307

Epoch: 5| Step: 8
Training loss: 1.2599213123321533
Validation loss: 2.0287430183861845

Epoch: 5| Step: 9
Training loss: 1.2428150177001953
Validation loss: 1.9972181653463712

Epoch: 5| Step: 10
Training loss: 1.3817181587219238
Validation loss: 2.0169062960532402

Epoch: 640| Step: 0
Training loss: 1.1090977191925049
Validation loss: 2.0129589278210878

Epoch: 5| Step: 1
Training loss: 1.4427616596221924
Validation loss: 1.9845534191336682

Epoch: 5| Step: 2
Training loss: 0.6483303904533386
Validation loss: 2.0160413198573615

Epoch: 5| Step: 3
Training loss: 0.8495600819587708
Validation loss: 1.937453221249324

Epoch: 5| Step: 4
Training loss: 1.3151085376739502
Validation loss: 1.9268652213517057

Epoch: 5| Step: 5
Training loss: 0.9120186567306519
Validation loss: 2.006978437464724

Epoch: 5| Step: 6
Training loss: 1.3659100532531738
Validation loss: 1.9470988563311997

Epoch: 5| Step: 7
Training loss: 1.1179206371307373
Validation loss: 1.9826692329939974

Epoch: 5| Step: 8
Training loss: 1.26523756980896
Validation loss: 1.9400590440278411

Epoch: 5| Step: 9
Training loss: 0.9993036985397339
Validation loss: 1.9724789691227738

Epoch: 5| Step: 10
Training loss: 1.3777637481689453
Validation loss: 1.9595797549011886

Epoch: 641| Step: 0
Training loss: 1.5280430316925049
Validation loss: 1.97131694516828

Epoch: 5| Step: 1
Training loss: 1.1422570943832397
Validation loss: 1.973617938257033

Epoch: 5| Step: 2
Training loss: 0.7393507361412048
Validation loss: 1.996671994527181

Epoch: 5| Step: 3
Training loss: 1.1347051858901978
Validation loss: 2.019175855062341

Epoch: 5| Step: 4
Training loss: 1.1789982318878174
Validation loss: 2.0264838600671418

Epoch: 5| Step: 5
Training loss: 1.0530226230621338
Validation loss: 2.0326198506098923

Epoch: 5| Step: 6
Training loss: 0.9991241693496704
Validation loss: 1.9830839800578293

Epoch: 5| Step: 7
Training loss: 1.2112832069396973
Validation loss: 1.967069492545179

Epoch: 5| Step: 8
Training loss: 1.3405733108520508
Validation loss: 2.0017533045943066

Epoch: 5| Step: 9
Training loss: 0.6994246244430542
Validation loss: 1.9868073835167834

Epoch: 5| Step: 10
Training loss: 1.1571791172027588
Validation loss: 1.9503038185898975

Epoch: 642| Step: 0
Training loss: 0.8018792271614075
Validation loss: 1.973752075626004

Epoch: 5| Step: 1
Training loss: 1.5373378992080688
Validation loss: 1.9853699963579896

Epoch: 5| Step: 2
Training loss: 0.5120375752449036
Validation loss: 1.9643072325696227

Epoch: 5| Step: 3
Training loss: 1.3949329853057861
Validation loss: 2.0207852125167847

Epoch: 5| Step: 4
Training loss: 1.4219509363174438
Validation loss: 1.9803108271732126

Epoch: 5| Step: 5
Training loss: 0.9039977788925171
Validation loss: 1.9579515380244101

Epoch: 5| Step: 6
Training loss: 1.2548786401748657
Validation loss: 1.9604798260555472

Epoch: 5| Step: 7
Training loss: 1.032874345779419
Validation loss: 2.000746867989981

Epoch: 5| Step: 8
Training loss: 1.3145980834960938
Validation loss: 1.9891537773993708

Epoch: 5| Step: 9
Training loss: 1.300666332244873
Validation loss: 2.000883610017838

Epoch: 5| Step: 10
Training loss: 0.5537868738174438
Validation loss: 2.008671422158518

Epoch: 643| Step: 0
Training loss: 1.026202917098999
Validation loss: 1.9665091781206028

Epoch: 5| Step: 1
Training loss: 1.3150838613510132
Validation loss: 1.989261939961423

Epoch: 5| Step: 2
Training loss: 1.1954336166381836
Validation loss: 2.0610518468323575

Epoch: 5| Step: 3
Training loss: 0.8346464037895203
Validation loss: 1.9682814459646902

Epoch: 5| Step: 4
Training loss: 0.9474593997001648
Validation loss: 1.963293542144119

Epoch: 5| Step: 5
Training loss: 1.6487009525299072
Validation loss: 2.023371160671275

Epoch: 5| Step: 6
Training loss: 0.8912685513496399
Validation loss: 2.0135259013022146

Epoch: 5| Step: 7
Training loss: 0.9283130764961243
Validation loss: 1.9986786175799627

Epoch: 5| Step: 8
Training loss: 0.9532815217971802
Validation loss: 2.000689042511807

Epoch: 5| Step: 9
Training loss: 1.6511443853378296
Validation loss: 1.983119059634465

Epoch: 5| Step: 10
Training loss: 0.924004077911377
Validation loss: 1.9500221360114314

Epoch: 644| Step: 0
Training loss: 1.0460487604141235
Validation loss: 2.0310602444474415

Epoch: 5| Step: 1
Training loss: 1.4600632190704346
Validation loss: 2.004951129677475

Epoch: 5| Step: 2
Training loss: 0.988190770149231
Validation loss: 2.0297371700245845

Epoch: 5| Step: 3
Training loss: 0.9225335121154785
Validation loss: 1.9778547453623947

Epoch: 5| Step: 4
Training loss: 1.673431396484375
Validation loss: 1.9539629938781902

Epoch: 5| Step: 5
Training loss: 0.816756546497345
Validation loss: 1.9620311721678703

Epoch: 5| Step: 6
Training loss: 1.0004146099090576
Validation loss: 1.9668959853469685

Epoch: 5| Step: 7
Training loss: 1.1784723997116089
Validation loss: 1.9808724259817472

Epoch: 5| Step: 8
Training loss: 0.8930557370185852
Validation loss: 1.9970616704674178

Epoch: 5| Step: 9
Training loss: 0.9999831318855286
Validation loss: 2.006313439338438

Epoch: 5| Step: 10
Training loss: 0.9625086188316345
Validation loss: 2.029744335400161

Epoch: 645| Step: 0
Training loss: 1.1683473587036133
Validation loss: 1.9507960683556014

Epoch: 5| Step: 1
Training loss: 1.434464693069458
Validation loss: 2.027118754643266

Epoch: 5| Step: 2
Training loss: 1.0700629949569702
Validation loss: 1.9581911333145634

Epoch: 5| Step: 3
Training loss: 1.225773572921753
Validation loss: 1.9578666969012188

Epoch: 5| Step: 4
Training loss: 0.8064374923706055
Validation loss: 1.9642277315098753

Epoch: 5| Step: 5
Training loss: 1.219980001449585
Validation loss: 1.9344990984086068

Epoch: 5| Step: 6
Training loss: 0.8834024667739868
Validation loss: 1.9455771279591385

Epoch: 5| Step: 7
Training loss: 0.9888864755630493
Validation loss: 1.9624926351731824

Epoch: 5| Step: 8
Training loss: 1.317986249923706
Validation loss: 1.9846009259582849

Epoch: 5| Step: 9
Training loss: 1.1481455564498901
Validation loss: 1.9962739201002224

Epoch: 5| Step: 10
Training loss: 0.5956551432609558
Validation loss: 1.9784420754319878

Epoch: 646| Step: 0
Training loss: 0.8409572839736938
Validation loss: 2.0117059112876974

Epoch: 5| Step: 1
Training loss: 1.1176412105560303
Validation loss: 1.966971420472668

Epoch: 5| Step: 2
Training loss: 1.0185327529907227
Validation loss: 1.9914313747036843

Epoch: 5| Step: 3
Training loss: 1.1236083507537842
Validation loss: 1.9507913063931208

Epoch: 5| Step: 4
Training loss: 1.2353605031967163
Validation loss: 1.9889854564461658

Epoch: 5| Step: 5
Training loss: 1.3848260641098022
Validation loss: 1.9415783856504707

Epoch: 5| Step: 6
Training loss: 0.9344609975814819
Validation loss: 1.9771016336256457

Epoch: 5| Step: 7
Training loss: 1.6496843099594116
Validation loss: 1.9846801014356716

Epoch: 5| Step: 8
Training loss: 0.8656803369522095
Validation loss: 1.957445861190878

Epoch: 5| Step: 9
Training loss: 0.7810815572738647
Validation loss: 1.99825087670357

Epoch: 5| Step: 10
Training loss: 1.1233354806900024
Validation loss: 2.0181057991520053

Epoch: 647| Step: 0
Training loss: 0.947215735912323
Validation loss: 2.0030504477921354

Epoch: 5| Step: 1
Training loss: 0.8418958783149719
Validation loss: 2.024407015051893

Epoch: 5| Step: 2
Training loss: 0.8512622714042664
Validation loss: 1.9688925448284353

Epoch: 5| Step: 3
Training loss: 1.3583402633666992
Validation loss: 2.0033404724572295

Epoch: 5| Step: 4
Training loss: 0.7966620326042175
Validation loss: 2.025907249860866

Epoch: 5| Step: 5
Training loss: 0.855236828327179
Validation loss: 1.987492463921988

Epoch: 5| Step: 6
Training loss: 0.9692312479019165
Validation loss: 2.001633128812236

Epoch: 5| Step: 7
Training loss: 1.437929391860962
Validation loss: 1.997989257176717

Epoch: 5| Step: 8
Training loss: 1.7407903671264648
Validation loss: 2.0122795643345004

Epoch: 5| Step: 9
Training loss: 1.033315658569336
Validation loss: 1.9853410772098008

Epoch: 5| Step: 10
Training loss: 1.332016110420227
Validation loss: 2.0004263360013246

Epoch: 648| Step: 0
Training loss: 0.7582241892814636
Validation loss: 1.9699954262343786

Epoch: 5| Step: 1
Training loss: 1.0359480381011963
Validation loss: 1.9748915549247497

Epoch: 5| Step: 2
Training loss: 1.2026863098144531
Validation loss: 1.9537373640203988

Epoch: 5| Step: 3
Training loss: 1.413201928138733
Validation loss: 1.9886266339209773

Epoch: 5| Step: 4
Training loss: 1.0912480354309082
Validation loss: 1.995231964254892

Epoch: 5| Step: 5
Training loss: 1.9528894424438477
Validation loss: 1.9963948213925926

Epoch: 5| Step: 6
Training loss: 0.8711436986923218
Validation loss: 1.940756231225947

Epoch: 5| Step: 7
Training loss: 1.0731806755065918
Validation loss: 1.9535289502912951

Epoch: 5| Step: 8
Training loss: 1.1378047466278076
Validation loss: 1.9464275990763018

Epoch: 5| Step: 9
Training loss: 0.9960868954658508
Validation loss: 1.9511358212399226

Epoch: 5| Step: 10
Training loss: 1.075778603553772
Validation loss: 1.9318462251335062

Epoch: 649| Step: 0
Training loss: 1.235541582107544
Validation loss: 2.0293040262755526

Epoch: 5| Step: 1
Training loss: 0.6788325309753418
Validation loss: 1.984273632367452

Epoch: 5| Step: 2
Training loss: 1.163161277770996
Validation loss: 2.055342646055324

Epoch: 5| Step: 3
Training loss: 1.2793843746185303
Validation loss: 2.009546608053228

Epoch: 5| Step: 4
Training loss: 1.2213575839996338
Validation loss: 2.0518343833185013

Epoch: 5| Step: 5
Training loss: 1.5365850925445557
Validation loss: 2.0104507207870483

Epoch: 5| Step: 6
Training loss: 1.192690134048462
Validation loss: 2.048901939904818

Epoch: 5| Step: 7
Training loss: 0.9690842628479004
Validation loss: 2.0082914777981338

Epoch: 5| Step: 8
Training loss: 1.1419718265533447
Validation loss: 2.0288875295269873

Epoch: 5| Step: 9
Training loss: 1.208946943283081
Validation loss: 2.0593599427130913

Epoch: 5| Step: 10
Training loss: 0.7215374708175659
Validation loss: 1.9902317549592705

Epoch: 650| Step: 0
Training loss: 1.0464613437652588
Validation loss: 1.9838326720781223

Epoch: 5| Step: 1
Training loss: 1.7169151306152344
Validation loss: 1.989694180027131

Epoch: 5| Step: 2
Training loss: 1.008305549621582
Validation loss: 1.9499845966216056

Epoch: 5| Step: 3
Training loss: 1.2658499479293823
Validation loss: 1.9620718879084433

Epoch: 5| Step: 4
Training loss: 0.7873302698135376
Validation loss: 1.956168524680599

Epoch: 5| Step: 5
Training loss: 1.1495583057403564
Validation loss: 1.9547715263981973

Epoch: 5| Step: 6
Training loss: 1.2273749113082886
Validation loss: 1.9315418504899549

Epoch: 5| Step: 7
Training loss: 1.0322167873382568
Validation loss: 1.9762507510441605

Epoch: 5| Step: 8
Training loss: 0.8958826065063477
Validation loss: 1.966181044937462

Epoch: 5| Step: 9
Training loss: 1.1175353527069092
Validation loss: 1.9620591799418132

Epoch: 5| Step: 10
Training loss: 1.4155018329620361
Validation loss: 1.9866542200888357

Epoch: 651| Step: 0
Training loss: 1.190341591835022
Validation loss: 2.005727726926086

Epoch: 5| Step: 1
Training loss: 1.265606164932251
Validation loss: 1.9969280048083233

Epoch: 5| Step: 2
Training loss: 1.2782670259475708
Validation loss: 1.9963906247128722

Epoch: 5| Step: 3
Training loss: 0.7448371052742004
Validation loss: 2.0293704335407545

Epoch: 5| Step: 4
Training loss: 0.8297445178031921
Validation loss: 2.008089097597266

Epoch: 5| Step: 5
Training loss: 1.4188203811645508
Validation loss: 2.017283288381433

Epoch: 5| Step: 6
Training loss: 0.8364663124084473
Validation loss: 2.011928908286556

Epoch: 5| Step: 7
Training loss: 0.8647485971450806
Validation loss: 2.0534208307984056

Epoch: 5| Step: 8
Training loss: 1.5642839670181274
Validation loss: 2.028880621797295

Epoch: 5| Step: 9
Training loss: 1.1039412021636963
Validation loss: 1.9987348484736618

Epoch: 5| Step: 10
Training loss: 1.2597914934158325
Validation loss: 1.9825973690197032

Epoch: 652| Step: 0
Training loss: 1.0055389404296875
Validation loss: 1.9373752212011686

Epoch: 5| Step: 1
Training loss: 1.218475103378296
Validation loss: 2.0055870945735643

Epoch: 5| Step: 2
Training loss: 1.7011821269989014
Validation loss: 2.0140756330182477

Epoch: 5| Step: 3
Training loss: 1.0868704319000244
Validation loss: 1.948807301059846

Epoch: 5| Step: 4
Training loss: 0.615652859210968
Validation loss: 1.9992925787484774

Epoch: 5| Step: 5
Training loss: 0.9095464944839478
Validation loss: 1.9740358706443542

Epoch: 5| Step: 6
Training loss: 0.9261040687561035
Validation loss: 1.925072290564096

Epoch: 5| Step: 7
Training loss: 1.3054845333099365
Validation loss: 2.0009142916689635

Epoch: 5| Step: 8
Training loss: 1.127868890762329
Validation loss: 1.9825923109567294

Epoch: 5| Step: 9
Training loss: 0.7700712084770203
Validation loss: 1.955913515501125

Epoch: 5| Step: 10
Training loss: 1.4319857358932495
Validation loss: 1.9422433889040382

Epoch: 653| Step: 0
Training loss: 0.7751253843307495
Validation loss: 1.9701317202660344

Epoch: 5| Step: 1
Training loss: 1.1446114778518677
Validation loss: 1.9871194670277257

Epoch: 5| Step: 2
Training loss: 0.9828580617904663
Validation loss: 2.0067430798725416

Epoch: 5| Step: 3
Training loss: 1.1934571266174316
Validation loss: 1.9944200131200975

Epoch: 5| Step: 4
Training loss: 0.6550993323326111
Validation loss: 1.977349683802615

Epoch: 5| Step: 5
Training loss: 0.8586847186088562
Validation loss: 2.02823624303264

Epoch: 5| Step: 6
Training loss: 1.4049098491668701
Validation loss: 2.010588304970854

Epoch: 5| Step: 7
Training loss: 1.0776803493499756
Validation loss: 2.017164590538189

Epoch: 5| Step: 8
Training loss: 1.3345755338668823
Validation loss: 2.014819973258562

Epoch: 5| Step: 9
Training loss: 1.0842574834823608
Validation loss: 2.009267291715068

Epoch: 5| Step: 10
Training loss: 1.562214970588684
Validation loss: 2.059199669027841

Epoch: 654| Step: 0
Training loss: 0.6545770764350891
Validation loss: 2.043583188005673

Epoch: 5| Step: 1
Training loss: 1.5774726867675781
Validation loss: 2.02406063900199

Epoch: 5| Step: 2
Training loss: 1.0412862300872803
Validation loss: 2.024778301997851

Epoch: 5| Step: 3
Training loss: 0.9374436140060425
Validation loss: 1.9775138029488184

Epoch: 5| Step: 4
Training loss: 1.512846827507019
Validation loss: 1.9732506454631846

Epoch: 5| Step: 5
Training loss: 1.3991382122039795
Validation loss: 1.9438466769392773

Epoch: 5| Step: 6
Training loss: 0.7641106843948364
Validation loss: 1.9189398314363213

Epoch: 5| Step: 7
Training loss: 0.723065197467804
Validation loss: 1.930554715535974

Epoch: 5| Step: 8
Training loss: 1.4209773540496826
Validation loss: 1.9728322054750176

Epoch: 5| Step: 9
Training loss: 0.981395423412323
Validation loss: 1.9536368744347685

Epoch: 5| Step: 10
Training loss: 1.2225247621536255
Validation loss: 1.987577305045179

Epoch: 655| Step: 0
Training loss: 1.0250540971755981
Validation loss: 2.011266190518615

Epoch: 5| Step: 1
Training loss: 1.0042073726654053
Validation loss: 1.9990953117288568

Epoch: 5| Step: 2
Training loss: 1.6601550579071045
Validation loss: 1.9994667781296598

Epoch: 5| Step: 3
Training loss: 1.0918015241622925
Validation loss: 2.0378203904756935

Epoch: 5| Step: 4
Training loss: 0.9270962476730347
Validation loss: 1.9864481392727102

Epoch: 5| Step: 5
Training loss: 1.1546958684921265
Validation loss: 2.0432056842311734

Epoch: 5| Step: 6
Training loss: 1.0227503776550293
Validation loss: 2.004724737136595

Epoch: 5| Step: 7
Training loss: 0.731730580329895
Validation loss: 2.0031557403584963

Epoch: 5| Step: 8
Training loss: 0.9044400453567505
Validation loss: 1.9787580454221336

Epoch: 5| Step: 9
Training loss: 1.554604172706604
Validation loss: 1.9832409812558083

Epoch: 5| Step: 10
Training loss: 0.931723415851593
Validation loss: 1.992813002678656

Epoch: 656| Step: 0
Training loss: 0.9131115078926086
Validation loss: 2.021915017917592

Epoch: 5| Step: 1
Training loss: 1.3163866996765137
Validation loss: 1.9796746776949974

Epoch: 5| Step: 2
Training loss: 1.6552202701568604
Validation loss: 1.9952666977400422

Epoch: 5| Step: 3
Training loss: 0.7225175499916077
Validation loss: 1.9429636014405118

Epoch: 5| Step: 4
Training loss: 1.1583783626556396
Validation loss: 1.9942608302639377

Epoch: 5| Step: 5
Training loss: 1.0481812953948975
Validation loss: 1.9557000052544378

Epoch: 5| Step: 6
Training loss: 1.1696078777313232
Validation loss: 1.9172568680137716

Epoch: 5| Step: 7
Training loss: 0.9830310940742493
Validation loss: 1.9800264053447272

Epoch: 5| Step: 8
Training loss: 0.7874331474304199
Validation loss: 1.9459573645745554

Epoch: 5| Step: 9
Training loss: 0.9649320840835571
Validation loss: 1.9915821244639735

Epoch: 5| Step: 10
Training loss: 1.4287443161010742
Validation loss: 1.936926213643884

Epoch: 657| Step: 0
Training loss: 1.1925327777862549
Validation loss: 1.9285487423660934

Epoch: 5| Step: 1
Training loss: 1.5600236654281616
Validation loss: 2.0063919944147908

Epoch: 5| Step: 2
Training loss: 1.2967497110366821
Validation loss: 1.9364039077553699

Epoch: 5| Step: 3
Training loss: 1.2743332386016846
Validation loss: 1.974455827025957

Epoch: 5| Step: 4
Training loss: 0.9655536413192749
Validation loss: 1.956643622408631

Epoch: 5| Step: 5
Training loss: 0.8442764282226562
Validation loss: 2.007461917015814

Epoch: 5| Step: 6
Training loss: 0.8634379506111145
Validation loss: 1.9545333770013624

Epoch: 5| Step: 7
Training loss: 0.2897455096244812
Validation loss: 1.9990202790947371

Epoch: 5| Step: 8
Training loss: 1.6496490240097046
Validation loss: 1.9399637560690604

Epoch: 5| Step: 9
Training loss: 1.1656712293624878
Validation loss: 1.9875485461245301

Epoch: 5| Step: 10
Training loss: 1.1306297779083252
Validation loss: 1.9892910270280735

Epoch: 658| Step: 0
Training loss: 1.6547672748565674
Validation loss: 2.0002686618476786

Epoch: 5| Step: 1
Training loss: 1.1041479110717773
Validation loss: 2.0013370590825237

Epoch: 5| Step: 2
Training loss: 1.5435817241668701
Validation loss: 2.001769224802653

Epoch: 5| Step: 3
Training loss: 1.2094471454620361
Validation loss: 1.9984810518962082

Epoch: 5| Step: 4
Training loss: 0.8645762205123901
Validation loss: 2.0208961040742937

Epoch: 5| Step: 5
Training loss: 0.720095694065094
Validation loss: 1.9889724536608624

Epoch: 5| Step: 6
Training loss: 0.9412376284599304
Validation loss: 2.029440341457244

Epoch: 5| Step: 7
Training loss: 1.0659897327423096
Validation loss: 1.9398981589142994

Epoch: 5| Step: 8
Training loss: 0.7356563806533813
Validation loss: 1.969256462589387

Epoch: 5| Step: 9
Training loss: 0.7295522689819336
Validation loss: 1.9917966140213834

Epoch: 5| Step: 10
Training loss: 1.4048177003860474
Validation loss: 1.9927282589738087

Epoch: 659| Step: 0
Training loss: 1.1675056219100952
Validation loss: 1.962761708485183

Epoch: 5| Step: 1
Training loss: 1.1781946420669556
Validation loss: 1.954347091336404

Epoch: 5| Step: 2
Training loss: 0.5586389303207397
Validation loss: 1.9759831607982676

Epoch: 5| Step: 3
Training loss: 1.20075523853302
Validation loss: 1.9656432815777358

Epoch: 5| Step: 4
Training loss: 1.0052372217178345
Validation loss: 1.9853467710556523

Epoch: 5| Step: 5
Training loss: 0.8540992736816406
Validation loss: 2.0050775453608525

Epoch: 5| Step: 6
Training loss: 1.0199000835418701
Validation loss: 1.977687563947452

Epoch: 5| Step: 7
Training loss: 1.6066316366195679
Validation loss: 1.9881827933813936

Epoch: 5| Step: 8
Training loss: 1.225847840309143
Validation loss: 1.997942022098008

Epoch: 5| Step: 9
Training loss: 0.9921227693557739
Validation loss: 1.9779373292000062

Epoch: 5| Step: 10
Training loss: 1.181390643119812
Validation loss: 2.001385206817299

Epoch: 660| Step: 0
Training loss: 1.1717755794525146
Validation loss: 2.0040228354033602

Epoch: 5| Step: 1
Training loss: 1.0402358770370483
Validation loss: 1.9795520561997608

Epoch: 5| Step: 2
Training loss: 1.5682480335235596
Validation loss: 1.9699302642576155

Epoch: 5| Step: 3
Training loss: 0.9203532934188843
Validation loss: 2.0239929127436813

Epoch: 5| Step: 4
Training loss: 1.1580325365066528
Validation loss: 2.012745193255845

Epoch: 5| Step: 5
Training loss: 0.3885040879249573
Validation loss: 2.0018580728961575

Epoch: 5| Step: 6
Training loss: 0.9227825999259949
Validation loss: 2.003301275673733

Epoch: 5| Step: 7
Training loss: 1.3367257118225098
Validation loss: 2.015916601304085

Epoch: 5| Step: 8
Training loss: 0.858300507068634
Validation loss: 1.960074100443112

Epoch: 5| Step: 9
Training loss: 0.9166242480278015
Validation loss: 1.9936067532467585

Epoch: 5| Step: 10
Training loss: 1.579384684562683
Validation loss: 1.9942434192985616

Epoch: 661| Step: 0
Training loss: 1.0274784564971924
Validation loss: 2.0371705011654924

Epoch: 5| Step: 1
Training loss: 0.7780001759529114
Validation loss: 2.0367853256963913

Epoch: 5| Step: 2
Training loss: 1.1396653652191162
Validation loss: 2.024231928651051

Epoch: 5| Step: 3
Training loss: 1.821831464767456
Validation loss: 2.0040208216636413

Epoch: 5| Step: 4
Training loss: 0.914650559425354
Validation loss: 2.0151261437323784

Epoch: 5| Step: 5
Training loss: 1.128391146659851
Validation loss: 1.9961805997356292

Epoch: 5| Step: 6
Training loss: 1.234304666519165
Validation loss: 2.0596791095631097

Epoch: 5| Step: 7
Training loss: 1.4893683195114136
Validation loss: 2.0089385368490733

Epoch: 5| Step: 8
Training loss: 0.8993039131164551
Validation loss: 2.0025108668111984

Epoch: 5| Step: 9
Training loss: 0.7562642693519592
Validation loss: 2.018572791930168

Epoch: 5| Step: 10
Training loss: 0.7327464818954468
Validation loss: 2.0053354309451197

Epoch: 662| Step: 0
Training loss: 1.0663772821426392
Validation loss: 2.0102438708787322

Epoch: 5| Step: 1
Training loss: 0.9510642290115356
Validation loss: 2.008889444412724

Epoch: 5| Step: 2
Training loss: 1.1628618240356445
Validation loss: 2.0075110504704137

Epoch: 5| Step: 3
Training loss: 0.7385380864143372
Validation loss: 1.9818227329561788

Epoch: 5| Step: 4
Training loss: 1.4469443559646606
Validation loss: 1.9522382495223836

Epoch: 5| Step: 5
Training loss: 0.7863327264785767
Validation loss: 1.9585677205875356

Epoch: 5| Step: 6
Training loss: 0.9263609647750854
Validation loss: 1.942450959195373

Epoch: 5| Step: 7
Training loss: 1.216921329498291
Validation loss: 1.9973333753565305

Epoch: 5| Step: 8
Training loss: 1.1821366548538208
Validation loss: 1.9446681763536187

Epoch: 5| Step: 9
Training loss: 1.4837908744812012
Validation loss: 2.0012491287723666

Epoch: 5| Step: 10
Training loss: 1.070554494857788
Validation loss: 2.0233906469037457

Epoch: 663| Step: 0
Training loss: 0.8257415890693665
Validation loss: 1.9704547902589202

Epoch: 5| Step: 1
Training loss: 1.246167778968811
Validation loss: 2.0244048026300248

Epoch: 5| Step: 2
Training loss: 1.6165155172348022
Validation loss: 2.004559939907443

Epoch: 5| Step: 3
Training loss: 0.7587296366691589
Validation loss: 2.0258165456915416

Epoch: 5| Step: 4
Training loss: 0.6937437653541565
Validation loss: 2.0573751708512664

Epoch: 5| Step: 5
Training loss: 0.8115872144699097
Validation loss: 2.019374388520436

Epoch: 5| Step: 6
Training loss: 1.1092965602874756
Validation loss: 2.0281179053809053

Epoch: 5| Step: 7
Training loss: 1.3043477535247803
Validation loss: 2.039470450852507

Epoch: 5| Step: 8
Training loss: 1.2259353399276733
Validation loss: 2.001916934085149

Epoch: 5| Step: 9
Training loss: 0.8732658624649048
Validation loss: 2.0467013684652184

Epoch: 5| Step: 10
Training loss: 1.6109678745269775
Validation loss: 2.015607382661553

Epoch: 664| Step: 0
Training loss: 0.9765148162841797
Validation loss: 2.006444747729968

Epoch: 5| Step: 1
Training loss: 0.9164150357246399
Validation loss: 1.9577496179970362

Epoch: 5| Step: 2
Training loss: 1.1850618124008179
Validation loss: 1.9764949993420673

Epoch: 5| Step: 3
Training loss: 0.8964473605155945
Validation loss: 2.0119596091649865

Epoch: 5| Step: 4
Training loss: 0.9823141098022461
Validation loss: 1.9763502331190212

Epoch: 5| Step: 5
Training loss: 1.3396369218826294
Validation loss: 1.9969554562722482

Epoch: 5| Step: 6
Training loss: 1.3021550178527832
Validation loss: 1.9885295924320017

Epoch: 5| Step: 7
Training loss: 1.0436044931411743
Validation loss: 1.9662640684394426

Epoch: 5| Step: 8
Training loss: 1.2741608619689941
Validation loss: 1.9498398252712783

Epoch: 5| Step: 9
Training loss: 0.9473921060562134
Validation loss: 1.9963301202302337

Epoch: 5| Step: 10
Training loss: 0.9675129055976868
Validation loss: 2.02947360597631

Epoch: 665| Step: 0
Training loss: 1.2040272951126099
Validation loss: 2.0136635072769655

Epoch: 5| Step: 1
Training loss: 1.233178734779358
Validation loss: 1.974118474991091

Epoch: 5| Step: 2
Training loss: 0.901863694190979
Validation loss: 1.9714988521350327

Epoch: 5| Step: 3
Training loss: 1.266693115234375
Validation loss: 2.071474095826508

Epoch: 5| Step: 4
Training loss: 0.8895944356918335
Validation loss: 2.0356670912875923

Epoch: 5| Step: 5
Training loss: 1.113157033920288
Validation loss: 2.0003671530754334

Epoch: 5| Step: 6
Training loss: 1.16100013256073
Validation loss: 2.003609500905519

Epoch: 5| Step: 7
Training loss: 0.8304195404052734
Validation loss: 1.99747174016891

Epoch: 5| Step: 8
Training loss: 1.2381690740585327
Validation loss: 1.9572689661415674

Epoch: 5| Step: 9
Training loss: 1.2018228769302368
Validation loss: 1.9636455428215764

Epoch: 5| Step: 10
Training loss: 0.8283569812774658
Validation loss: 2.0046583875533073

Epoch: 666| Step: 0
Training loss: 0.5988425016403198
Validation loss: 2.0288921812529206

Epoch: 5| Step: 1
Training loss: 0.8999952077865601
Validation loss: 1.971606252013996

Epoch: 5| Step: 2
Training loss: 0.7209833860397339
Validation loss: 1.9711937186538533

Epoch: 5| Step: 3
Training loss: 1.1936928033828735
Validation loss: 2.003839108251756

Epoch: 5| Step: 4
Training loss: 1.275451898574829
Validation loss: 1.9750590132128807

Epoch: 5| Step: 5
Training loss: 1.1327838897705078
Validation loss: 1.9779433358100154

Epoch: 5| Step: 6
Training loss: 1.3652626276016235
Validation loss: 1.9645721950838644

Epoch: 5| Step: 7
Training loss: 1.2667322158813477
Validation loss: 1.9974197008276497

Epoch: 5| Step: 8
Training loss: 1.2458999156951904
Validation loss: 1.976489754133327

Epoch: 5| Step: 9
Training loss: 1.1043683290481567
Validation loss: 1.9640450631418536

Epoch: 5| Step: 10
Training loss: 1.3386896848678589
Validation loss: 1.9907273092577535

Epoch: 667| Step: 0
Training loss: 1.3676481246948242
Validation loss: 2.0033520908765894

Epoch: 5| Step: 1
Training loss: 1.3347327709197998
Validation loss: 2.0250834418881323

Epoch: 5| Step: 2
Training loss: 0.9741031527519226
Validation loss: 1.9622498866050475

Epoch: 5| Step: 3
Training loss: 1.5259556770324707
Validation loss: 1.9980109212219075

Epoch: 5| Step: 4
Training loss: 0.99189692735672
Validation loss: 1.98980652388706

Epoch: 5| Step: 5
Training loss: 0.7680104970932007
Validation loss: 2.0357749539036907

Epoch: 5| Step: 6
Training loss: 0.9037233591079712
Validation loss: 2.003798679638934

Epoch: 5| Step: 7
Training loss: 1.0532904863357544
Validation loss: 1.9766324617529427

Epoch: 5| Step: 8
Training loss: 0.7777717709541321
Validation loss: 1.994083043067686

Epoch: 5| Step: 9
Training loss: 1.1126431226730347
Validation loss: 2.007380529116559

Epoch: 5| Step: 10
Training loss: 1.2267186641693115
Validation loss: 2.0325457716500885

Epoch: 668| Step: 0
Training loss: 1.1966383457183838
Validation loss: 1.9930902104223929

Epoch: 5| Step: 1
Training loss: 0.9364555478096008
Validation loss: 1.9715325140183972

Epoch: 5| Step: 2
Training loss: 1.1509284973144531
Validation loss: 2.0184704924142487

Epoch: 5| Step: 3
Training loss: 0.8973686099052429
Validation loss: 2.0010823895854335

Epoch: 5| Step: 4
Training loss: 0.797629177570343
Validation loss: 2.0137516913875455

Epoch: 5| Step: 5
Training loss: 1.2695519924163818
Validation loss: 2.014215833397322

Epoch: 5| Step: 6
Training loss: 0.9254857897758484
Validation loss: 2.0050672305527555

Epoch: 5| Step: 7
Training loss: 1.1622223854064941
Validation loss: 1.9914666683443132

Epoch: 5| Step: 8
Training loss: 1.0677027702331543
Validation loss: 1.9684470340769777

Epoch: 5| Step: 9
Training loss: 1.0790953636169434
Validation loss: 1.9965989076963035

Epoch: 5| Step: 10
Training loss: 1.5330203771591187
Validation loss: 1.953684869632926

Epoch: 669| Step: 0
Training loss: 1.1283926963806152
Validation loss: 2.026700864556015

Epoch: 5| Step: 1
Training loss: 1.3014976978302002
Validation loss: 2.003885171746695

Epoch: 5| Step: 2
Training loss: 1.001785159111023
Validation loss: 2.042903737355304

Epoch: 5| Step: 3
Training loss: 0.8367297053337097
Validation loss: 1.9935586760121007

Epoch: 5| Step: 4
Training loss: 1.1242364645004272
Validation loss: 2.0104486762836413

Epoch: 5| Step: 5
Training loss: 1.4194340705871582
Validation loss: 1.9719359374815417

Epoch: 5| Step: 6
Training loss: 1.0070245265960693
Validation loss: 2.0389824708302817

Epoch: 5| Step: 7
Training loss: 1.313592553138733
Validation loss: 1.9440175589694773

Epoch: 5| Step: 8
Training loss: 0.6493385434150696
Validation loss: 1.9842605898457188

Epoch: 5| Step: 9
Training loss: 0.9767192602157593
Validation loss: 1.9654514123034734

Epoch: 5| Step: 10
Training loss: 1.07249915599823
Validation loss: 2.000792654611731

Epoch: 670| Step: 0
Training loss: 0.8579033017158508
Validation loss: 1.940641648025923

Epoch: 5| Step: 1
Training loss: 1.4708495140075684
Validation loss: 1.9609580885979436

Epoch: 5| Step: 2
Training loss: 1.1850998401641846
Validation loss: 1.9842170656368296

Epoch: 5| Step: 3
Training loss: 0.7970669269561768
Validation loss: 1.9826425378040602

Epoch: 5| Step: 4
Training loss: 1.131519079208374
Validation loss: 1.9905683507201493

Epoch: 5| Step: 5
Training loss: 1.2001867294311523
Validation loss: 1.9827171089828655

Epoch: 5| Step: 6
Training loss: 0.857735812664032
Validation loss: 1.9716762752943142

Epoch: 5| Step: 7
Training loss: 1.0516016483306885
Validation loss: 1.9892638460282357

Epoch: 5| Step: 8
Training loss: 1.5492093563079834
Validation loss: 1.9680738808006368

Epoch: 5| Step: 9
Training loss: 1.062514066696167
Validation loss: 2.014132051057713

Epoch: 5| Step: 10
Training loss: 1.024543285369873
Validation loss: 1.9855588174635364

Epoch: 671| Step: 0
Training loss: 0.6834564805030823
Validation loss: 1.984726680222378

Epoch: 5| Step: 1
Training loss: 0.7652062177658081
Validation loss: 1.9880825140142953

Epoch: 5| Step: 2
Training loss: 0.8427312970161438
Validation loss: 2.049790636185677

Epoch: 5| Step: 3
Training loss: 1.7853240966796875
Validation loss: 2.0028276443481445

Epoch: 5| Step: 4
Training loss: 1.1488028764724731
Validation loss: 1.9897888578394407

Epoch: 5| Step: 5
Training loss: 0.818956196308136
Validation loss: 2.0047312833929576

Epoch: 5| Step: 6
Training loss: 1.7511634826660156
Validation loss: 2.0098472641360376

Epoch: 5| Step: 7
Training loss: 0.8353202939033508
Validation loss: 1.9750232504260155

Epoch: 5| Step: 8
Training loss: 1.2625017166137695
Validation loss: 2.04036061609945

Epoch: 5| Step: 9
Training loss: 1.0067412853240967
Validation loss: 2.021466093678628

Epoch: 5| Step: 10
Training loss: 0.8894623517990112
Validation loss: 1.9824982266272269

Epoch: 672| Step: 0
Training loss: 1.4290740489959717
Validation loss: 1.9965167071229668

Epoch: 5| Step: 1
Training loss: 1.3765312433242798
Validation loss: 2.0042325347982426

Epoch: 5| Step: 2
Training loss: 0.7491573095321655
Validation loss: 1.987543067624492

Epoch: 5| Step: 3
Training loss: 0.9334672093391418
Validation loss: 2.0087534278951664

Epoch: 5| Step: 4
Training loss: 0.9105426669120789
Validation loss: 1.9918519873772897

Epoch: 5| Step: 5
Training loss: 1.1998536586761475
Validation loss: 2.057651940212455

Epoch: 5| Step: 6
Training loss: 0.9394599795341492
Validation loss: 2.0455190135586645

Epoch: 5| Step: 7
Training loss: 1.0411109924316406
Validation loss: 1.9804668170149609

Epoch: 5| Step: 8
Training loss: 0.7032127380371094
Validation loss: 1.9972470678308958

Epoch: 5| Step: 9
Training loss: 1.413306474685669
Validation loss: 1.9739421426608998

Epoch: 5| Step: 10
Training loss: 1.3339976072311401
Validation loss: 1.9752990712401688

Epoch: 673| Step: 0
Training loss: 1.2863333225250244
Validation loss: 1.9864411533519786

Epoch: 5| Step: 1
Training loss: 1.1748427152633667
Validation loss: 1.9385693304000362

Epoch: 5| Step: 2
Training loss: 0.7590551972389221
Validation loss: 1.943198670623123

Epoch: 5| Step: 3
Training loss: 1.0971283912658691
Validation loss: 1.9796314406138595

Epoch: 5| Step: 4
Training loss: 1.3882147073745728
Validation loss: 1.9830891163118425

Epoch: 5| Step: 5
Training loss: 1.0647871494293213
Validation loss: 1.9917674500455138

Epoch: 5| Step: 6
Training loss: 1.2148125171661377
Validation loss: 2.001119952048025

Epoch: 5| Step: 7
Training loss: 0.8917396664619446
Validation loss: 1.9674253873927618

Epoch: 5| Step: 8
Training loss: 0.5096437335014343
Validation loss: 1.9427431962823356

Epoch: 5| Step: 9
Training loss: 1.1746997833251953
Validation loss: 1.975547646963468

Epoch: 5| Step: 10
Training loss: 1.3464151620864868
Validation loss: 1.9740772811315392

Epoch: 674| Step: 0
Training loss: 1.5997097492218018
Validation loss: 1.9788408753692464

Epoch: 5| Step: 1
Training loss: 0.623104453086853
Validation loss: 1.9815176161386634

Epoch: 5| Step: 2
Training loss: 1.1345477104187012
Validation loss: 1.9802458875922746

Epoch: 5| Step: 3
Training loss: 0.985924243927002
Validation loss: 2.009342634549705

Epoch: 5| Step: 4
Training loss: 0.9828292727470398
Validation loss: 1.9800520379056212

Epoch: 5| Step: 5
Training loss: 0.9215997457504272
Validation loss: 1.9999804650583575

Epoch: 5| Step: 6
Training loss: 1.2305721044540405
Validation loss: 1.9733052202450332

Epoch: 5| Step: 7
Training loss: 1.2718894481658936
Validation loss: 2.0185403644397693

Epoch: 5| Step: 8
Training loss: 1.1228206157684326
Validation loss: 1.9763609017095258

Epoch: 5| Step: 9
Training loss: 1.1453545093536377
Validation loss: 2.028820296769501

Epoch: 5| Step: 10
Training loss: 0.8142738342285156
Validation loss: 1.9881418174312961

Epoch: 675| Step: 0
Training loss: 0.9159026145935059
Validation loss: 1.9891591712992678

Epoch: 5| Step: 1
Training loss: 1.291975736618042
Validation loss: 2.002205289820189

Epoch: 5| Step: 2
Training loss: 0.9908787608146667
Validation loss: 2.0241909809010004

Epoch: 5| Step: 3
Training loss: 1.2365888357162476
Validation loss: 2.0185343039933072

Epoch: 5| Step: 4
Training loss: 1.1396400928497314
Validation loss: 2.0327327366798156

Epoch: 5| Step: 5
Training loss: 0.7972701191902161
Validation loss: 1.973431343673378

Epoch: 5| Step: 6
Training loss: 1.078917384147644
Validation loss: 2.0084797951482956

Epoch: 5| Step: 7
Training loss: 0.9856112599372864
Validation loss: 1.959090627649779

Epoch: 5| Step: 8
Training loss: 0.8583475947380066
Validation loss: 1.9894466976965628

Epoch: 5| Step: 9
Training loss: 1.3188632726669312
Validation loss: 1.9958613008581183

Epoch: 5| Step: 10
Training loss: 1.3178434371948242
Validation loss: 1.9916022541702434

Epoch: 676| Step: 0
Training loss: 1.5905976295471191
Validation loss: 1.9528691589191396

Epoch: 5| Step: 1
Training loss: 1.486672043800354
Validation loss: 1.9441747588496054

Epoch: 5| Step: 2
Training loss: 1.1072115898132324
Validation loss: 1.9773178074949531

Epoch: 5| Step: 3
Training loss: 0.5902349948883057
Validation loss: 2.0066669333365654

Epoch: 5| Step: 4
Training loss: 0.9040815234184265
Validation loss: 1.9851914631423129

Epoch: 5| Step: 5
Training loss: 0.8635364770889282
Validation loss: 1.9995607432498728

Epoch: 5| Step: 6
Training loss: 1.0165919065475464
Validation loss: 2.0038026045727473

Epoch: 5| Step: 7
Training loss: 1.2474658489227295
Validation loss: 2.007084643968972

Epoch: 5| Step: 8
Training loss: 0.8826867938041687
Validation loss: 2.0142399047010686

Epoch: 5| Step: 9
Training loss: 1.1293576955795288
Validation loss: 1.9993633762482674

Epoch: 5| Step: 10
Training loss: 1.005171537399292
Validation loss: 2.011503154231656

Epoch: 677| Step: 0
Training loss: 1.2850654125213623
Validation loss: 1.9589124751347367

Epoch: 5| Step: 1
Training loss: 0.6941828727722168
Validation loss: 1.954020441219371

Epoch: 5| Step: 2
Training loss: 0.6818774938583374
Validation loss: 1.957945490396151

Epoch: 5| Step: 3
Training loss: 1.286859154701233
Validation loss: 1.987486288111697

Epoch: 5| Step: 4
Training loss: 0.6871989965438843
Validation loss: 1.9842346534934094

Epoch: 5| Step: 5
Training loss: 1.4919264316558838
Validation loss: 1.9987810965507262

Epoch: 5| Step: 6
Training loss: 1.2023029327392578
Validation loss: 1.9692828142514793

Epoch: 5| Step: 7
Training loss: 1.0640335083007812
Validation loss: 1.9808145056488693

Epoch: 5| Step: 8
Training loss: 0.7760502099990845
Validation loss: 1.9765012494979366

Epoch: 5| Step: 9
Training loss: 1.9214541912078857
Validation loss: 1.9415770217936525

Epoch: 5| Step: 10
Training loss: 0.7045540809631348
Validation loss: 1.9865027448182464

Epoch: 678| Step: 0
Training loss: 1.3021962642669678
Validation loss: 2.00209701958523

Epoch: 5| Step: 1
Training loss: 1.1345798969268799
Validation loss: 1.996008696094636

Epoch: 5| Step: 2
Training loss: 0.9085807800292969
Validation loss: 1.9760557579737839

Epoch: 5| Step: 3
Training loss: 0.6614282727241516
Validation loss: 1.985717970837829

Epoch: 5| Step: 4
Training loss: 1.0009984970092773
Validation loss: 1.9701253214190084

Epoch: 5| Step: 5
Training loss: 1.2481662034988403
Validation loss: 1.9757343569109518

Epoch: 5| Step: 6
Training loss: 1.1540095806121826
Validation loss: 1.985145939293728

Epoch: 5| Step: 7
Training loss: 1.1715037822723389
Validation loss: 1.9747168146153933

Epoch: 5| Step: 8
Training loss: 1.137589454650879
Validation loss: 1.9706719844572005

Epoch: 5| Step: 9
Training loss: 0.7002264857292175
Validation loss: 1.9557750891613703

Epoch: 5| Step: 10
Training loss: 1.3128132820129395
Validation loss: 2.0036399441380657

Epoch: 679| Step: 0
Training loss: 1.6039249897003174
Validation loss: 1.950954096291655

Epoch: 5| Step: 1
Training loss: 0.7923218011856079
Validation loss: 2.0108625094095864

Epoch: 5| Step: 2
Training loss: 0.8513252139091492
Validation loss: 2.0300901525764057

Epoch: 5| Step: 3
Training loss: 1.143376350402832
Validation loss: 1.9698743204916678

Epoch: 5| Step: 4
Training loss: 1.2091950178146362
Validation loss: 1.9336839337502756

Epoch: 5| Step: 5
Training loss: 0.7096443176269531
Validation loss: 1.9566750141882128

Epoch: 5| Step: 6
Training loss: 1.1148054599761963
Validation loss: 1.9286506752814017

Epoch: 5| Step: 7
Training loss: 1.1781255006790161
Validation loss: 2.007968242450427

Epoch: 5| Step: 8
Training loss: 1.5627079010009766
Validation loss: 2.0088027882319626

Epoch: 5| Step: 9
Training loss: 0.3924897611141205
Validation loss: 1.9977725808338453

Epoch: 5| Step: 10
Training loss: 1.0000925064086914
Validation loss: 1.9544961631938975

Epoch: 680| Step: 0
Training loss: 0.9853167533874512
Validation loss: 2.0093711012153217

Epoch: 5| Step: 1
Training loss: 1.0049827098846436
Validation loss: 2.0092546632212978

Epoch: 5| Step: 2
Training loss: 0.8398746252059937
Validation loss: 1.944548463308683

Epoch: 5| Step: 3
Training loss: 0.9301789402961731
Validation loss: 1.9905676687917402

Epoch: 5| Step: 4
Training loss: 0.9842443466186523
Validation loss: 1.9702275952985209

Epoch: 5| Step: 5
Training loss: 1.0579164028167725
Validation loss: 1.9824157786625687

Epoch: 5| Step: 6
Training loss: 1.2355891466140747
Validation loss: 1.9548115179102907

Epoch: 5| Step: 7
Training loss: 1.0397546291351318
Validation loss: 2.004684570015118

Epoch: 5| Step: 8
Training loss: 0.988775908946991
Validation loss: 1.9460374373261646

Epoch: 5| Step: 9
Training loss: 1.1599652767181396
Validation loss: 1.9856507816622335

Epoch: 5| Step: 10
Training loss: 1.2609766721725464
Validation loss: 1.9686384944505588

Epoch: 681| Step: 0
Training loss: 0.6026484370231628
Validation loss: 1.98126059321947

Epoch: 5| Step: 1
Training loss: 0.7349902987480164
Validation loss: 1.9982165931373514

Epoch: 5| Step: 2
Training loss: 1.2224782705307007
Validation loss: 2.0249899612959994

Epoch: 5| Step: 3
Training loss: 1.5106837749481201
Validation loss: 1.9884312870681926

Epoch: 5| Step: 4
Training loss: 1.5937623977661133
Validation loss: 1.966457643816548

Epoch: 5| Step: 5
Training loss: 0.9838703274726868
Validation loss: 1.9825193189805554

Epoch: 5| Step: 6
Training loss: 1.1627752780914307
Validation loss: 1.987465331631322

Epoch: 5| Step: 7
Training loss: 0.9408107995986938
Validation loss: 1.9696965012499081

Epoch: 5| Step: 8
Training loss: 0.8309431076049805
Validation loss: 1.9995117815591956

Epoch: 5| Step: 9
Training loss: 1.450063943862915
Validation loss: 2.0226230313701015

Epoch: 5| Step: 10
Training loss: 0.6821784973144531
Validation loss: 1.9676867544010122

Epoch: 682| Step: 0
Training loss: 0.6744732856750488
Validation loss: 1.9939992940554054

Epoch: 5| Step: 1
Training loss: 0.8614702224731445
Validation loss: 1.9614266413514332

Epoch: 5| Step: 2
Training loss: 1.005720853805542
Validation loss: 1.9873704679550663

Epoch: 5| Step: 3
Training loss: 1.0052717924118042
Validation loss: 1.9858383401747672

Epoch: 5| Step: 4
Training loss: 0.9523237347602844
Validation loss: 2.0104311486726165

Epoch: 5| Step: 5
Training loss: 0.9824168086051941
Validation loss: 1.973870886269436

Epoch: 5| Step: 6
Training loss: 1.473218321800232
Validation loss: 1.9769782353472967

Epoch: 5| Step: 7
Training loss: 1.0939197540283203
Validation loss: 1.9838582072206723

Epoch: 5| Step: 8
Training loss: 1.4784132242202759
Validation loss: 1.957990837353532

Epoch: 5| Step: 9
Training loss: 1.3356901407241821
Validation loss: 1.9632747596310032

Epoch: 5| Step: 10
Training loss: 0.59135901927948
Validation loss: 1.9585824717757523

Epoch: 683| Step: 0
Training loss: 0.61002117395401
Validation loss: 1.9719704684390817

Epoch: 5| Step: 1
Training loss: 1.0119260549545288
Validation loss: 1.9599110593077957

Epoch: 5| Step: 2
Training loss: 0.9823516607284546
Validation loss: 1.9734516143798828

Epoch: 5| Step: 3
Training loss: 1.0310840606689453
Validation loss: 2.0001903400626233

Epoch: 5| Step: 4
Training loss: 0.8998529314994812
Validation loss: 1.9681718759639288

Epoch: 5| Step: 5
Training loss: 1.4334558248519897
Validation loss: 2.065009936209648

Epoch: 5| Step: 6
Training loss: 1.03444504737854
Validation loss: 1.9758080615792224

Epoch: 5| Step: 7
Training loss: 1.055752158164978
Validation loss: 1.9855518110336796

Epoch: 5| Step: 8
Training loss: 1.2783105373382568
Validation loss: 1.9981006576168923

Epoch: 5| Step: 9
Training loss: 1.339830756187439
Validation loss: 2.0395945092683196

Epoch: 5| Step: 10
Training loss: 1.1122102737426758
Validation loss: 2.011664384154863

Epoch: 684| Step: 0
Training loss: 0.5324388742446899
Validation loss: 2.0069227769810665

Epoch: 5| Step: 1
Training loss: 1.406150460243225
Validation loss: 2.043430959024737

Epoch: 5| Step: 2
Training loss: 0.5145341157913208
Validation loss: 1.9801167134315736

Epoch: 5| Step: 3
Training loss: 1.3232767581939697
Validation loss: 1.9653611926622288

Epoch: 5| Step: 4
Training loss: 1.0649417638778687
Validation loss: 2.012735720603697

Epoch: 5| Step: 5
Training loss: 1.1685543060302734
Validation loss: 1.9814517459561747

Epoch: 5| Step: 6
Training loss: 1.0605026483535767
Validation loss: 1.9701175369242185

Epoch: 5| Step: 7
Training loss: 1.3791577816009521
Validation loss: 2.0223222612052836

Epoch: 5| Step: 8
Training loss: 1.1891173124313354
Validation loss: 1.9630801267521356

Epoch: 5| Step: 9
Training loss: 1.0454808473587036
Validation loss: 1.9397438892754175

Epoch: 5| Step: 10
Training loss: 1.1388664245605469
Validation loss: 2.0150645356024466

Epoch: 685| Step: 0
Training loss: 1.2646028995513916
Validation loss: 1.9419257858748078

Epoch: 5| Step: 1
Training loss: 0.763441264629364
Validation loss: 1.9684160242798507

Epoch: 5| Step: 2
Training loss: 1.2768930196762085
Validation loss: 1.9260821047649588

Epoch: 5| Step: 3
Training loss: 0.5134676098823547
Validation loss: 2.0047959127733783

Epoch: 5| Step: 4
Training loss: 1.1990336179733276
Validation loss: 1.96032073420863

Epoch: 5| Step: 5
Training loss: 0.8089815378189087
Validation loss: 1.9923163819056686

Epoch: 5| Step: 6
Training loss: 1.1459619998931885
Validation loss: 1.9536136786142986

Epoch: 5| Step: 7
Training loss: 0.8696044683456421
Validation loss: 1.9472534528342627

Epoch: 5| Step: 8
Training loss: 1.204538106918335
Validation loss: 1.969162223159626

Epoch: 5| Step: 9
Training loss: 1.2334113121032715
Validation loss: 1.977986628009427

Epoch: 5| Step: 10
Training loss: 1.1216423511505127
Validation loss: 1.98946596986504

Epoch: 686| Step: 0
Training loss: 1.2823870182037354
Validation loss: 1.9856962978198964

Epoch: 5| Step: 1
Training loss: 0.6502389907836914
Validation loss: 2.0234742395339476

Epoch: 5| Step: 2
Training loss: 1.0300400257110596
Validation loss: 2.0220608275423766

Epoch: 5| Step: 3
Training loss: 0.7197590470314026
Validation loss: 1.9851534725517355

Epoch: 5| Step: 4
Training loss: 0.9842950105667114
Validation loss: 1.9999847283927343

Epoch: 5| Step: 5
Training loss: 0.9017923474311829
Validation loss: 2.0279649457623883

Epoch: 5| Step: 6
Training loss: 0.8813012838363647
Validation loss: 2.0170363867154686

Epoch: 5| Step: 7
Training loss: 1.029536485671997
Validation loss: 2.033203025018015

Epoch: 5| Step: 8
Training loss: 1.4373037815093994
Validation loss: 1.9880334843871414

Epoch: 5| Step: 9
Training loss: 0.8426361083984375
Validation loss: 1.9679575786795667

Epoch: 5| Step: 10
Training loss: 1.9771578311920166
Validation loss: 2.0436420671401487

Epoch: 687| Step: 0
Training loss: 0.7943322658538818
Validation loss: 1.9678082171306814

Epoch: 5| Step: 1
Training loss: 1.012722373008728
Validation loss: 1.9354344170580629

Epoch: 5| Step: 2
Training loss: 1.1783634424209595
Validation loss: 1.9883644375749814

Epoch: 5| Step: 3
Training loss: 0.801916241645813
Validation loss: 1.9529309170220488

Epoch: 5| Step: 4
Training loss: 0.709283173084259
Validation loss: 1.9980658356861403

Epoch: 5| Step: 5
Training loss: 1.3937543630599976
Validation loss: 1.9709437252372823

Epoch: 5| Step: 6
Training loss: 1.3360182046890259
Validation loss: 1.9677654850867488

Epoch: 5| Step: 7
Training loss: 1.3449172973632812
Validation loss: 1.9772386730358165

Epoch: 5| Step: 8
Training loss: 1.1475985050201416
Validation loss: 1.9737768468036447

Epoch: 5| Step: 9
Training loss: 1.1574926376342773
Validation loss: 1.9614522944214523

Epoch: 5| Step: 10
Training loss: 0.7013285756111145
Validation loss: 1.9704533174473753

Epoch: 688| Step: 0
Training loss: 1.197657585144043
Validation loss: 2.00629432483386

Epoch: 5| Step: 1
Training loss: 1.1511863470077515
Validation loss: 2.0214934977152015

Epoch: 5| Step: 2
Training loss: 1.0790729522705078
Validation loss: 1.9660680524764522

Epoch: 5| Step: 3
Training loss: 1.1092833280563354
Validation loss: 1.946233921153571

Epoch: 5| Step: 4
Training loss: 0.615231990814209
Validation loss: 2.0203674249751593

Epoch: 5| Step: 5
Training loss: 0.4402080178260803
Validation loss: 1.9239956986519597

Epoch: 5| Step: 6
Training loss: 1.3196604251861572
Validation loss: 1.9845724413471837

Epoch: 5| Step: 7
Training loss: 1.2299290895462036
Validation loss: 1.9752614857048116

Epoch: 5| Step: 8
Training loss: 1.022639274597168
Validation loss: 1.9980570282987369

Epoch: 5| Step: 9
Training loss: 1.2485620975494385
Validation loss: 1.996364624269547

Epoch: 5| Step: 10
Training loss: 1.2496191263198853
Validation loss: 2.031682152901926

Epoch: 689| Step: 0
Training loss: 1.4756009578704834
Validation loss: 2.0369655534785283

Epoch: 5| Step: 1
Training loss: 1.0738229751586914
Validation loss: 2.042988088823134

Epoch: 5| Step: 2
Training loss: 0.9898731112480164
Validation loss: 1.9892919909569524

Epoch: 5| Step: 3
Training loss: 1.1189539432525635
Validation loss: 2.013060180089807

Epoch: 5| Step: 4
Training loss: 1.0608240365982056
Validation loss: 1.9490095325695571

Epoch: 5| Step: 5
Training loss: 0.9244035482406616
Validation loss: 2.0147359666003974

Epoch: 5| Step: 6
Training loss: 0.8532825708389282
Validation loss: 1.990906451338081

Epoch: 5| Step: 7
Training loss: 0.7402076721191406
Validation loss: 1.947502359267204

Epoch: 5| Step: 8
Training loss: 1.2448675632476807
Validation loss: 1.9922520088893112

Epoch: 5| Step: 9
Training loss: 1.0374892950057983
Validation loss: 1.9862130611173567

Epoch: 5| Step: 10
Training loss: 1.0252255201339722
Validation loss: 1.9563010443923294

Epoch: 690| Step: 0
Training loss: 1.6420962810516357
Validation loss: 1.9309949221149567

Epoch: 5| Step: 1
Training loss: 0.7083377242088318
Validation loss: 1.9705058425985358

Epoch: 5| Step: 2
Training loss: 0.853307843208313
Validation loss: 2.025014977301321

Epoch: 5| Step: 3
Training loss: 0.9344123601913452
Validation loss: 1.9856009098791307

Epoch: 5| Step: 4
Training loss: 1.1798746585845947
Validation loss: 1.9493537359340216

Epoch: 5| Step: 5
Training loss: 0.5364785194396973
Validation loss: 2.011915324836649

Epoch: 5| Step: 6
Training loss: 0.9752386212348938
Validation loss: 1.9613286064517113

Epoch: 5| Step: 7
Training loss: 1.1202131509780884
Validation loss: 1.9884843710930116

Epoch: 5| Step: 8
Training loss: 1.44447922706604
Validation loss: 1.9823475858216644

Epoch: 5| Step: 9
Training loss: 1.5102870464324951
Validation loss: 1.982318679491679

Epoch: 5| Step: 10
Training loss: 0.670653760433197
Validation loss: 2.022248932110366

Epoch: 691| Step: 0
Training loss: 1.274744987487793
Validation loss: 1.9891463441233481

Epoch: 5| Step: 1
Training loss: 0.9070655703544617
Validation loss: 1.9815945856032833

Epoch: 5| Step: 2
Training loss: 1.1009008884429932
Validation loss: 2.0177468176810973

Epoch: 5| Step: 3
Training loss: 1.0162925720214844
Validation loss: 1.9787995892186319

Epoch: 5| Step: 4
Training loss: 0.7154207229614258
Validation loss: 1.9903126583304456

Epoch: 5| Step: 5
Training loss: 1.1158567667007446
Validation loss: 1.995727486507867

Epoch: 5| Step: 6
Training loss: 1.5160341262817383
Validation loss: 1.9810901559809202

Epoch: 5| Step: 7
Training loss: 0.9856780767440796
Validation loss: 2.005296322607225

Epoch: 5| Step: 8
Training loss: 0.8656066060066223
Validation loss: 1.988435927257743

Epoch: 5| Step: 9
Training loss: 1.0588066577911377
Validation loss: 1.9821623422766244

Epoch: 5| Step: 10
Training loss: 0.8746077418327332
Validation loss: 1.9885345171856623

Epoch: 692| Step: 0
Training loss: 0.9249634742736816
Validation loss: 1.9561537055559055

Epoch: 5| Step: 1
Training loss: 1.0964223146438599
Validation loss: 1.9508063895727998

Epoch: 5| Step: 2
Training loss: 1.1804180145263672
Validation loss: 1.9665637529024513

Epoch: 5| Step: 3
Training loss: 1.0776607990264893
Validation loss: 1.9845429876799225

Epoch: 5| Step: 4
Training loss: 1.0786645412445068
Validation loss: 1.9372161511451966

Epoch: 5| Step: 5
Training loss: 1.3620851039886475
Validation loss: 1.9782444892391082

Epoch: 5| Step: 6
Training loss: 0.6921864748001099
Validation loss: 2.0005725096630793

Epoch: 5| Step: 7
Training loss: 1.367951512336731
Validation loss: 1.9851230882829236

Epoch: 5| Step: 8
Training loss: 0.8488796353340149
Validation loss: 2.015861536866875

Epoch: 5| Step: 9
Training loss: 0.9460325241088867
Validation loss: 1.9897581056881977

Epoch: 5| Step: 10
Training loss: 1.2316815853118896
Validation loss: 2.032035284144904

Epoch: 693| Step: 0
Training loss: 0.7421345710754395
Validation loss: 1.9858056332475396

Epoch: 5| Step: 1
Training loss: 1.2489464282989502
Validation loss: 1.984477279006794

Epoch: 5| Step: 2
Training loss: 0.8940653800964355
Validation loss: 1.9468709704696492

Epoch: 5| Step: 3
Training loss: 0.9313400387763977
Validation loss: 1.9820716086254324

Epoch: 5| Step: 4
Training loss: 1.2910735607147217
Validation loss: 1.9746867866926296

Epoch: 5| Step: 5
Training loss: 0.865809440612793
Validation loss: 1.935222441150296

Epoch: 5| Step: 6
Training loss: 0.9090361595153809
Validation loss: 1.954756970046669

Epoch: 5| Step: 7
Training loss: 0.9136018753051758
Validation loss: 1.9823886322718796

Epoch: 5| Step: 8
Training loss: 1.4099853038787842
Validation loss: 1.9445945742309734

Epoch: 5| Step: 9
Training loss: 1.2954713106155396
Validation loss: 1.9891495640559862

Epoch: 5| Step: 10
Training loss: 0.9343392848968506
Validation loss: 1.9610692390831568

Epoch: 694| Step: 0
Training loss: 1.3743833303451538
Validation loss: 1.9904093537279355

Epoch: 5| Step: 1
Training loss: 1.1161149740219116
Validation loss: 1.9981272925612747

Epoch: 5| Step: 2
Training loss: 1.199756383895874
Validation loss: 2.0215081771214805

Epoch: 5| Step: 3
Training loss: 0.5312879681587219
Validation loss: 2.0369350064185356

Epoch: 5| Step: 4
Training loss: 1.253204345703125
Validation loss: 2.0674037882076797

Epoch: 5| Step: 5
Training loss: 0.7116556763648987
Validation loss: 1.988142305804837

Epoch: 5| Step: 6
Training loss: 1.1427390575408936
Validation loss: 2.005625456892034

Epoch: 5| Step: 7
Training loss: 0.8794978857040405
Validation loss: 2.0352727687487038

Epoch: 5| Step: 8
Training loss: 1.3100954294204712
Validation loss: 2.0178229090987996

Epoch: 5| Step: 9
Training loss: 0.6940613985061646
Validation loss: 1.9959833519433134

Epoch: 5| Step: 10
Training loss: 1.591495156288147
Validation loss: 1.9921938603924167

Epoch: 695| Step: 0
Training loss: 1.3132219314575195
Validation loss: 1.9915534065615745

Epoch: 5| Step: 1
Training loss: 1.2040385007858276
Validation loss: 1.944568512260273

Epoch: 5| Step: 2
Training loss: 1.1538585424423218
Validation loss: 1.970307247613066

Epoch: 5| Step: 3
Training loss: 1.2320899963378906
Validation loss: 1.9990723030541533

Epoch: 5| Step: 4
Training loss: 0.6748937368392944
Validation loss: 1.9901300220079319

Epoch: 5| Step: 5
Training loss: 0.8636575937271118
Validation loss: 1.934955732796782

Epoch: 5| Step: 6
Training loss: 1.2289762496948242
Validation loss: 2.0015318393707275

Epoch: 5| Step: 7
Training loss: 1.5405906438827515
Validation loss: 1.9943322981557539

Epoch: 5| Step: 8
Training loss: 1.096716284751892
Validation loss: 1.9871740238640898

Epoch: 5| Step: 9
Training loss: 0.793122410774231
Validation loss: 1.987968696061001

Epoch: 5| Step: 10
Training loss: 0.643012523651123
Validation loss: 2.0229459219081427

Epoch: 696| Step: 0
Training loss: 1.055274248123169
Validation loss: 1.9661314436184463

Epoch: 5| Step: 1
Training loss: 1.2184622287750244
Validation loss: 1.9752024194245696

Epoch: 5| Step: 2
Training loss: 1.098853588104248
Validation loss: 2.0289627890433035

Epoch: 5| Step: 3
Training loss: 0.9307432174682617
Validation loss: 2.008497720123619

Epoch: 5| Step: 4
Training loss: 0.9688326120376587
Validation loss: 1.997849154215987

Epoch: 5| Step: 5
Training loss: 1.394849181175232
Validation loss: 1.9584993393190446

Epoch: 5| Step: 6
Training loss: 1.13178288936615
Validation loss: 2.0555933188366633

Epoch: 5| Step: 7
Training loss: 1.1273729801177979
Validation loss: 2.038308358961536

Epoch: 5| Step: 8
Training loss: 0.6976377964019775
Validation loss: 1.9927918975071242

Epoch: 5| Step: 9
Training loss: 1.144296646118164
Validation loss: 1.9692705087764288

Epoch: 5| Step: 10
Training loss: 1.0824859142303467
Validation loss: 1.995700410617295

Epoch: 697| Step: 0
Training loss: 1.3868263959884644
Validation loss: 1.9987350061375608

Epoch: 5| Step: 1
Training loss: 1.591137409210205
Validation loss: 1.9637811542839132

Epoch: 5| Step: 2
Training loss: 1.21920645236969
Validation loss: 2.0060672067826792

Epoch: 5| Step: 3
Training loss: 0.9750547409057617
Validation loss: 1.90624862845226

Epoch: 5| Step: 4
Training loss: 1.3306316137313843
Validation loss: 1.9153578999221965

Epoch: 5| Step: 5
Training loss: 1.229339361190796
Validation loss: 1.9681289375469249

Epoch: 5| Step: 6
Training loss: 0.6844135522842407
Validation loss: 2.0209773073914232

Epoch: 5| Step: 7
Training loss: 0.7135530114173889
Validation loss: 1.947394750451529

Epoch: 5| Step: 8
Training loss: 0.8795474767684937
Validation loss: 1.9861227696941746

Epoch: 5| Step: 9
Training loss: 0.8903506994247437
Validation loss: 1.9535369475682576

Epoch: 5| Step: 10
Training loss: 0.7796693444252014
Validation loss: 1.9914318387226393

Epoch: 698| Step: 0
Training loss: 0.7310599088668823
Validation loss: 1.9562110708605858

Epoch: 5| Step: 1
Training loss: 0.8428186178207397
Validation loss: 2.0220225793059154

Epoch: 5| Step: 2
Training loss: 0.966635525226593
Validation loss: 1.968992346076555

Epoch: 5| Step: 3
Training loss: 1.7535473108291626
Validation loss: 2.0811733225340485

Epoch: 5| Step: 4
Training loss: 1.517277479171753
Validation loss: 1.9862729169989144

Epoch: 5| Step: 5
Training loss: 0.9371434450149536
Validation loss: 2.0083317128560876

Epoch: 5| Step: 6
Training loss: 0.783771276473999
Validation loss: 2.003763275761758

Epoch: 5| Step: 7
Training loss: 0.7777178883552551
Validation loss: 2.014254104706549

Epoch: 5| Step: 8
Training loss: 1.3380277156829834
Validation loss: 1.9936279686548377

Epoch: 5| Step: 9
Training loss: 1.0120906829833984
Validation loss: 1.9826245718104865

Epoch: 5| Step: 10
Training loss: 1.2168891429901123
Validation loss: 2.0160001118977866

Epoch: 699| Step: 0
Training loss: 1.4657942056655884
Validation loss: 2.0005534771950013

Epoch: 5| Step: 1
Training loss: 1.0995612144470215
Validation loss: 2.030523838535432

Epoch: 5| Step: 2
Training loss: 0.8728778958320618
Validation loss: 1.95185883327197

Epoch: 5| Step: 3
Training loss: 1.1222059726715088
Validation loss: 2.004020885754657

Epoch: 5| Step: 4
Training loss: 1.38697350025177
Validation loss: 2.0350808276925036

Epoch: 5| Step: 5
Training loss: 1.0796241760253906
Validation loss: 1.9718184035311463

Epoch: 5| Step: 6
Training loss: 1.1343806982040405
Validation loss: 1.937602311052302

Epoch: 5| Step: 7
Training loss: 0.8660427927970886
Validation loss: 1.9811541162511355

Epoch: 5| Step: 8
Training loss: 0.7132488489151001
Validation loss: 2.003564500039624

Epoch: 5| Step: 9
Training loss: 0.8912101984024048
Validation loss: 1.9413773513609363

Epoch: 5| Step: 10
Training loss: 1.067077398300171
Validation loss: 1.9661866862286803

Epoch: 700| Step: 0
Training loss: 0.8248752355575562
Validation loss: 1.9610108483222224

Epoch: 5| Step: 1
Training loss: 0.990757942199707
Validation loss: 2.000991282924529

Epoch: 5| Step: 2
Training loss: 1.0688350200653076
Validation loss: 1.9984671531185028

Epoch: 5| Step: 3
Training loss: 1.0833607912063599
Validation loss: 2.0042620423019573

Epoch: 5| Step: 4
Training loss: 1.3946428298950195
Validation loss: 1.9749714277123893

Epoch: 5| Step: 5
Training loss: 0.9321543574333191
Validation loss: 2.0195643107096353

Epoch: 5| Step: 6
Training loss: 0.8568384051322937
Validation loss: 1.9430137731695687

Epoch: 5| Step: 7
Training loss: 1.0240168571472168
Validation loss: 2.0338911433373728

Epoch: 5| Step: 8
Training loss: 0.8184138536453247
Validation loss: 1.9907602469126384

Epoch: 5| Step: 9
Training loss: 0.9954065084457397
Validation loss: 1.9721174522112774

Epoch: 5| Step: 10
Training loss: 1.4845300912857056
Validation loss: 1.9602938095728557

Epoch: 701| Step: 0
Training loss: 0.9640949368476868
Validation loss: 1.9978457484194028

Epoch: 5| Step: 1
Training loss: 1.2225258350372314
Validation loss: 1.9673667133495372

Epoch: 5| Step: 2
Training loss: 1.228054404258728
Validation loss: 1.955395919020458

Epoch: 5| Step: 3
Training loss: 0.8603700399398804
Validation loss: 1.979260035740432

Epoch: 5| Step: 4
Training loss: 1.1231759786605835
Validation loss: 1.9829437655787314

Epoch: 5| Step: 5
Training loss: 0.7318605184555054
Validation loss: 1.990355066073838

Epoch: 5| Step: 6
Training loss: 0.9363502264022827
Validation loss: 2.04275450142481

Epoch: 5| Step: 7
Training loss: 1.1010403633117676
Validation loss: 2.01268938279921

Epoch: 5| Step: 8
Training loss: 0.7754713892936707
Validation loss: 1.978630886282972

Epoch: 5| Step: 9
Training loss: 1.0958976745605469
Validation loss: 1.9939723989014984

Epoch: 5| Step: 10
Training loss: 1.2307606935501099
Validation loss: 1.9301163458055066

Epoch: 702| Step: 0
Training loss: 0.8260283470153809
Validation loss: 1.986286832440284

Epoch: 5| Step: 1
Training loss: 1.4283243417739868
Validation loss: 1.9707048887847571

Epoch: 5| Step: 2
Training loss: 1.0986759662628174
Validation loss: 1.9826508004178283

Epoch: 5| Step: 3
Training loss: 0.8055265545845032
Validation loss: 1.9510841613174768

Epoch: 5| Step: 4
Training loss: 0.9811269640922546
Validation loss: 1.9713849252270115

Epoch: 5| Step: 5
Training loss: 1.198933720588684
Validation loss: 1.9969835730009182

Epoch: 5| Step: 6
Training loss: 1.242226481437683
Validation loss: 1.9734335330224806

Epoch: 5| Step: 7
Training loss: 0.7589080929756165
Validation loss: 1.9982619285583496

Epoch: 5| Step: 8
Training loss: 0.6221094131469727
Validation loss: 2.0223834937618625

Epoch: 5| Step: 9
Training loss: 1.3256733417510986
Validation loss: 2.0378668231348835

Epoch: 5| Step: 10
Training loss: 1.2272199392318726
Validation loss: 1.9839650994987899

Epoch: 703| Step: 0
Training loss: 1.210335612297058
Validation loss: 1.9800719484206168

Epoch: 5| Step: 1
Training loss: 0.9089673161506653
Validation loss: 1.9833800356875184

Epoch: 5| Step: 2
Training loss: 0.6665264368057251
Validation loss: 1.9445032932425057

Epoch: 5| Step: 3
Training loss: 0.6839156150817871
Validation loss: 1.9751735271946076

Epoch: 5| Step: 4
Training loss: 0.7497867345809937
Validation loss: 1.9703720436301282

Epoch: 5| Step: 5
Training loss: 1.7389198541641235
Validation loss: 1.9400959360984065

Epoch: 5| Step: 6
Training loss: 1.0768253803253174
Validation loss: 1.982738071872342

Epoch: 5| Step: 7
Training loss: 0.8810437917709351
Validation loss: 1.983213686173962

Epoch: 5| Step: 8
Training loss: 1.3938546180725098
Validation loss: 1.9790591129692652

Epoch: 5| Step: 9
Training loss: 0.858814537525177
Validation loss: 1.9840323373835573

Epoch: 5| Step: 10
Training loss: 1.0850324630737305
Validation loss: 1.978345517189272

Epoch: 704| Step: 0
Training loss: 0.8172609210014343
Validation loss: 1.9658622395607732

Epoch: 5| Step: 1
Training loss: 1.3764899969100952
Validation loss: 2.0123637530111496

Epoch: 5| Step: 2
Training loss: 1.260280966758728
Validation loss: 1.9776035406256234

Epoch: 5| Step: 3
Training loss: 0.8723090887069702
Validation loss: 1.951308374763817

Epoch: 5| Step: 4
Training loss: 0.5721606016159058
Validation loss: 1.986391878897144

Epoch: 5| Step: 5
Training loss: 0.9864441752433777
Validation loss: 1.9938416211835799

Epoch: 5| Step: 6
Training loss: 1.1406831741333008
Validation loss: 1.9665911736026886

Epoch: 5| Step: 7
Training loss: 1.2969896793365479
Validation loss: 1.9853556027976416

Epoch: 5| Step: 8
Training loss: 0.8637905120849609
Validation loss: 1.9834653921024774

Epoch: 5| Step: 9
Training loss: 0.8882774114608765
Validation loss: 1.9240733859359578

Epoch: 5| Step: 10
Training loss: 1.3620785474777222
Validation loss: 1.985982676988007

Epoch: 705| Step: 0
Training loss: 1.333373785018921
Validation loss: 1.9876693115439465

Epoch: 5| Step: 1
Training loss: 1.3704084157943726
Validation loss: 2.0345091896672405

Epoch: 5| Step: 2
Training loss: 0.9300443530082703
Validation loss: 1.982855967296067

Epoch: 5| Step: 3
Training loss: 0.8890851140022278
Validation loss: 1.943136868938323

Epoch: 5| Step: 4
Training loss: 0.9325836896896362
Validation loss: 1.9740506038870862

Epoch: 5| Step: 5
Training loss: 0.8312625885009766
Validation loss: 1.9979043852898382

Epoch: 5| Step: 6
Training loss: 1.4203604459762573
Validation loss: 1.9784262718692902

Epoch: 5| Step: 7
Training loss: 0.8461034893989563
Validation loss: 1.9429123683642315

Epoch: 5| Step: 8
Training loss: 0.5785814523696899
Validation loss: 2.000093420346578

Epoch: 5| Step: 9
Training loss: 1.3307911157608032
Validation loss: 1.952240151743735

Epoch: 5| Step: 10
Training loss: 1.0003710985183716
Validation loss: 1.9583347689720891

Epoch: 706| Step: 0
Training loss: 0.7840051054954529
Validation loss: 1.9859509621897051

Epoch: 5| Step: 1
Training loss: 1.2414162158966064
Validation loss: 2.0017344695265575

Epoch: 5| Step: 2
Training loss: 1.4484697580337524
Validation loss: 2.0193478804762646

Epoch: 5| Step: 3
Training loss: 1.0780725479125977
Validation loss: 1.9980018600340812

Epoch: 5| Step: 4
Training loss: 0.6025798916816711
Validation loss: 1.9522229522787116

Epoch: 5| Step: 5
Training loss: 0.9257606267929077
Validation loss: 2.0123414044739096

Epoch: 5| Step: 6
Training loss: 0.8659269213676453
Validation loss: 2.0066600871342484

Epoch: 5| Step: 7
Training loss: 1.1796954870224
Validation loss: 1.9798141243637248

Epoch: 5| Step: 8
Training loss: 0.8851132392883301
Validation loss: 1.959620468078121

Epoch: 5| Step: 9
Training loss: 1.1781537532806396
Validation loss: 1.9342607464841617

Epoch: 5| Step: 10
Training loss: 1.546417474746704
Validation loss: 1.9659262998129732

Epoch: 707| Step: 0
Training loss: 1.1485854387283325
Validation loss: 2.006698314861585

Epoch: 5| Step: 1
Training loss: 0.9629266858100891
Validation loss: 1.9752390397492277

Epoch: 5| Step: 2
Training loss: 0.93968665599823
Validation loss: 1.9742064206830916

Epoch: 5| Step: 3
Training loss: 0.7729495763778687
Validation loss: 1.9824279610828688

Epoch: 5| Step: 4
Training loss: 0.7427772879600525
Validation loss: 2.0069220783889934

Epoch: 5| Step: 5
Training loss: 1.058682918548584
Validation loss: 1.9644535895316833

Epoch: 5| Step: 6
Training loss: 1.4418061971664429
Validation loss: 1.9678265715158114

Epoch: 5| Step: 7
Training loss: 0.8816709518432617
Validation loss: 1.9941196569832422

Epoch: 5| Step: 8
Training loss: 1.2200965881347656
Validation loss: 1.9761272284292406

Epoch: 5| Step: 9
Training loss: 1.067840576171875
Validation loss: 2.0136468218218897

Epoch: 5| Step: 10
Training loss: 1.2310667037963867
Validation loss: 2.0057900157026065

Epoch: 708| Step: 0
Training loss: 1.019540786743164
Validation loss: 1.95752469442224

Epoch: 5| Step: 1
Training loss: 1.1964366436004639
Validation loss: 2.012758763887549

Epoch: 5| Step: 2
Training loss: 0.6998797655105591
Validation loss: 1.9866199698499454

Epoch: 5| Step: 3
Training loss: 0.6379257440567017
Validation loss: 1.9186901046383766

Epoch: 5| Step: 4
Training loss: 0.7170535922050476
Validation loss: 1.9658944376053349

Epoch: 5| Step: 5
Training loss: 1.1882522106170654
Validation loss: 1.9729606900163876

Epoch: 5| Step: 6
Training loss: 0.7422105073928833
Validation loss: 1.931679202664283

Epoch: 5| Step: 7
Training loss: 1.4859163761138916
Validation loss: 1.9227468557255243

Epoch: 5| Step: 8
Training loss: 0.6744732856750488
Validation loss: 1.956753065509181

Epoch: 5| Step: 9
Training loss: 1.6959726810455322
Validation loss: 1.9602125960011636

Epoch: 5| Step: 10
Training loss: 1.283913016319275
Validation loss: 1.9892359113180509

Epoch: 709| Step: 0
Training loss: 1.0563178062438965
Validation loss: 2.0021338334647556

Epoch: 5| Step: 1
Training loss: 1.1581385135650635
Validation loss: 1.9982654535642235

Epoch: 5| Step: 2
Training loss: 0.8912665247917175
Validation loss: 1.973841154447166

Epoch: 5| Step: 3
Training loss: 1.0798317193984985
Validation loss: 1.9525310557375672

Epoch: 5| Step: 4
Training loss: 0.8805333971977234
Validation loss: 1.9607575388364895

Epoch: 5| Step: 5
Training loss: 1.0504124164581299
Validation loss: 2.000004586353097

Epoch: 5| Step: 6
Training loss: 1.0989896059036255
Validation loss: 1.9722411004445886

Epoch: 5| Step: 7
Training loss: 0.7946761846542358
Validation loss: 1.9718244588503273

Epoch: 5| Step: 8
Training loss: 0.9799479246139526
Validation loss: 1.9793088333581084

Epoch: 5| Step: 9
Training loss: 1.0524492263793945
Validation loss: 2.0002008689347135

Epoch: 5| Step: 10
Training loss: 1.3712584972381592
Validation loss: 1.9592747572929627

Epoch: 710| Step: 0
Training loss: 0.932148277759552
Validation loss: 1.9844776840620144

Epoch: 5| Step: 1
Training loss: 1.021676778793335
Validation loss: 1.96065568154858

Epoch: 5| Step: 2
Training loss: 1.3607161045074463
Validation loss: 1.9508425586967058

Epoch: 5| Step: 3
Training loss: 0.977939784526825
Validation loss: 1.9840687256987377

Epoch: 5| Step: 4
Training loss: 1.1560206413269043
Validation loss: 2.0070812420178483

Epoch: 5| Step: 5
Training loss: 1.1324470043182373
Validation loss: 1.9650841079732424

Epoch: 5| Step: 6
Training loss: 1.0069668292999268
Validation loss: 1.982466192655666

Epoch: 5| Step: 7
Training loss: 0.7773814797401428
Validation loss: 1.9775887445736957

Epoch: 5| Step: 8
Training loss: 1.3142807483673096
Validation loss: 1.9899949796738163

Epoch: 5| Step: 9
Training loss: 0.5949205160140991
Validation loss: 1.9734600602939565

Epoch: 5| Step: 10
Training loss: 1.1929597854614258
Validation loss: 1.9491190500156854

Epoch: 711| Step: 0
Training loss: 0.705396294593811
Validation loss: 1.9567409382071546

Epoch: 5| Step: 1
Training loss: 1.1735329627990723
Validation loss: 1.9603053421102545

Epoch: 5| Step: 2
Training loss: 0.9327311515808105
Validation loss: 1.955498383891198

Epoch: 5| Step: 3
Training loss: 1.1253458261489868
Validation loss: 2.0033748354963077

Epoch: 5| Step: 4
Training loss: 0.8922799229621887
Validation loss: 1.9521242598051667

Epoch: 5| Step: 5
Training loss: 0.8432369232177734
Validation loss: 2.008787924243558

Epoch: 5| Step: 6
Training loss: 1.077290415763855
Validation loss: 1.983301849775417

Epoch: 5| Step: 7
Training loss: 1.0085593461990356
Validation loss: 1.9635833258269935

Epoch: 5| Step: 8
Training loss: 0.5485161542892456
Validation loss: 1.9600953594330819

Epoch: 5| Step: 9
Training loss: 1.6263278722763062
Validation loss: 1.9783462170631654

Epoch: 5| Step: 10
Training loss: 1.4866293668746948
Validation loss: 1.9620544090065906

Epoch: 712| Step: 0
Training loss: 0.6903634071350098
Validation loss: 1.9711146354675293

Epoch: 5| Step: 1
Training loss: 1.0631129741668701
Validation loss: 1.9924385637365363

Epoch: 5| Step: 2
Training loss: 1.2739839553833008
Validation loss: 1.9847382755689724

Epoch: 5| Step: 3
Training loss: 1.3520625829696655
Validation loss: 1.9588738333794378

Epoch: 5| Step: 4
Training loss: 0.7359455823898315
Validation loss: 1.9995646963837326

Epoch: 5| Step: 5
Training loss: 0.4198463559150696
Validation loss: 1.9573287502411874

Epoch: 5| Step: 6
Training loss: 0.8998125195503235
Validation loss: 1.981167475382487

Epoch: 5| Step: 7
Training loss: 1.3362432718276978
Validation loss: 1.944279920670294

Epoch: 5| Step: 8
Training loss: 1.242498755455017
Validation loss: 1.9415738556974678

Epoch: 5| Step: 9
Training loss: 1.039027214050293
Validation loss: 1.9636575239960865

Epoch: 5| Step: 10
Training loss: 1.564846396446228
Validation loss: 2.000091830889384

Epoch: 713| Step: 0
Training loss: 1.1060707569122314
Validation loss: 1.9941531112117152

Epoch: 5| Step: 1
Training loss: 0.6265934109687805
Validation loss: 1.964138848807222

Epoch: 5| Step: 2
Training loss: 1.1457197666168213
Validation loss: 1.9503847463156587

Epoch: 5| Step: 3
Training loss: 0.7939544916152954
Validation loss: 2.0329564412434897

Epoch: 5| Step: 4
Training loss: 1.050398826599121
Validation loss: 1.9442827137567664

Epoch: 5| Step: 5
Training loss: 0.9850400686264038
Validation loss: 1.985757061230239

Epoch: 5| Step: 6
Training loss: 1.129392385482788
Validation loss: 2.0059662454871723

Epoch: 5| Step: 7
Training loss: 0.8929670453071594
Validation loss: 1.9937064865584015

Epoch: 5| Step: 8
Training loss: 1.0731583833694458
Validation loss: 2.0204575343798568

Epoch: 5| Step: 9
Training loss: 1.572313904762268
Validation loss: 1.962696607394885

Epoch: 5| Step: 10
Training loss: 0.7645109295845032
Validation loss: 1.9292486431778118

Epoch: 714| Step: 0
Training loss: 0.7743992209434509
Validation loss: 1.9831385868851856

Epoch: 5| Step: 1
Training loss: 0.8504476547241211
Validation loss: 1.9643474650639359

Epoch: 5| Step: 2
Training loss: 1.441009759902954
Validation loss: 1.973953334234094

Epoch: 5| Step: 3
Training loss: 0.9603205919265747
Validation loss: 1.9616895106530958

Epoch: 5| Step: 4
Training loss: 0.9060007333755493
Validation loss: 1.961050328388009

Epoch: 5| Step: 5
Training loss: 0.6001249551773071
Validation loss: 1.942719110878565

Epoch: 5| Step: 6
Training loss: 1.0207220315933228
Validation loss: 1.990308815433133

Epoch: 5| Step: 7
Training loss: 1.397134780883789
Validation loss: 1.964055343340802

Epoch: 5| Step: 8
Training loss: 1.3563352823257446
Validation loss: 1.9444508937097364

Epoch: 5| Step: 9
Training loss: 1.2319265604019165
Validation loss: 1.9756459728364022

Epoch: 5| Step: 10
Training loss: 0.7093800902366638
Validation loss: 1.95601442808746

Epoch: 715| Step: 0
Training loss: 1.2626802921295166
Validation loss: 1.967414632920296

Epoch: 5| Step: 1
Training loss: 1.0108129978179932
Validation loss: 1.9238203533234135

Epoch: 5| Step: 2
Training loss: 0.9470149278640747
Validation loss: 1.9810955473171767

Epoch: 5| Step: 3
Training loss: 0.9477938413619995
Validation loss: 1.9685404095598447

Epoch: 5| Step: 4
Training loss: 1.0783995389938354
Validation loss: 1.9589233026709607

Epoch: 5| Step: 5
Training loss: 1.3721942901611328
Validation loss: 1.951587853893157

Epoch: 5| Step: 6
Training loss: 1.281829595565796
Validation loss: 1.936836342657766

Epoch: 5| Step: 7
Training loss: 0.8352382779121399
Validation loss: 1.97470869300186

Epoch: 5| Step: 8
Training loss: 0.7792508006095886
Validation loss: 1.9410584562568254

Epoch: 5| Step: 9
Training loss: 0.880179226398468
Validation loss: 1.9827469779599098

Epoch: 5| Step: 10
Training loss: 0.8075729608535767
Validation loss: 1.972223622824556

Epoch: 716| Step: 0
Training loss: 1.574432373046875
Validation loss: 1.9575436845902474

Epoch: 5| Step: 1
Training loss: 0.6074910759925842
Validation loss: 1.938999152952625

Epoch: 5| Step: 2
Training loss: 0.9175140261650085
Validation loss: 2.006577630196848

Epoch: 5| Step: 3
Training loss: 1.413317322731018
Validation loss: 1.940502994803972

Epoch: 5| Step: 4
Training loss: 1.047865629196167
Validation loss: 1.991508674877946

Epoch: 5| Step: 5
Training loss: 0.7271496057510376
Validation loss: 2.0057271680524273

Epoch: 5| Step: 6
Training loss: 1.0557764768600464
Validation loss: 1.9677762293046521

Epoch: 5| Step: 7
Training loss: 1.250779390335083
Validation loss: 1.987974815471198

Epoch: 5| Step: 8
Training loss: 0.6307052373886108
Validation loss: 1.9837320645650227

Epoch: 5| Step: 9
Training loss: 0.9982650876045227
Validation loss: 1.9776595997554

Epoch: 5| Step: 10
Training loss: 0.8601717352867126
Validation loss: 1.9468486680779407

Epoch: 717| Step: 0
Training loss: 1.0159265995025635
Validation loss: 1.9676204445541545

Epoch: 5| Step: 1
Training loss: 1.2840527296066284
Validation loss: 1.98681503470226

Epoch: 5| Step: 2
Training loss: 0.9261495471000671
Validation loss: 1.9420112794445408

Epoch: 5| Step: 3
Training loss: 0.9236084818840027
Validation loss: 1.9765830629615373

Epoch: 5| Step: 4
Training loss: 1.120820164680481
Validation loss: 1.9554574528048116

Epoch: 5| Step: 5
Training loss: 1.2410014867782593
Validation loss: 1.9880463666813348

Epoch: 5| Step: 6
Training loss: 1.1468650102615356
Validation loss: 1.9913406218251875

Epoch: 5| Step: 7
Training loss: 0.6204670667648315
Validation loss: 1.9648427809438398

Epoch: 5| Step: 8
Training loss: 1.2484365701675415
Validation loss: 1.9956713863598403

Epoch: 5| Step: 9
Training loss: 1.0034544467926025
Validation loss: 1.984618015186761

Epoch: 5| Step: 10
Training loss: 0.7894763946533203
Validation loss: 1.966163848036079

Epoch: 718| Step: 0
Training loss: 0.9657840728759766
Validation loss: 1.9789703533213625

Epoch: 5| Step: 1
Training loss: 0.8504711985588074
Validation loss: 1.9332049251884542

Epoch: 5| Step: 2
Training loss: 0.4673158526420593
Validation loss: 1.9626451384636663

Epoch: 5| Step: 3
Training loss: 0.8115890622138977
Validation loss: 1.9610195595731017

Epoch: 5| Step: 4
Training loss: 1.4188929796218872
Validation loss: 1.999305571279218

Epoch: 5| Step: 5
Training loss: 0.9083574414253235
Validation loss: 1.9902860503042898

Epoch: 5| Step: 6
Training loss: 1.6380780935287476
Validation loss: 1.978889182049741

Epoch: 5| Step: 7
Training loss: 1.2945852279663086
Validation loss: 1.939090044267716

Epoch: 5| Step: 8
Training loss: 0.8369255065917969
Validation loss: 1.9878886835549467

Epoch: 5| Step: 9
Training loss: 0.9676109552383423
Validation loss: 1.9688482720364806

Epoch: 5| Step: 10
Training loss: 0.9257935881614685
Validation loss: 1.9786999943435832

Epoch: 719| Step: 0
Training loss: 0.8727277517318726
Validation loss: 1.987910755218998

Epoch: 5| Step: 1
Training loss: 1.002484917640686
Validation loss: 2.0425265309631184

Epoch: 5| Step: 2
Training loss: 1.1269376277923584
Validation loss: 1.9579433830835486

Epoch: 5| Step: 3
Training loss: 0.8799114227294922
Validation loss: 2.040055323672551

Epoch: 5| Step: 4
Training loss: 0.6183739900588989
Validation loss: 2.0067416519247074

Epoch: 5| Step: 5
Training loss: 1.1673334836959839
Validation loss: 1.958397037239485

Epoch: 5| Step: 6
Training loss: 0.9513952136039734
Validation loss: 1.9963142487310594

Epoch: 5| Step: 7
Training loss: 0.8685430288314819
Validation loss: 1.9942301832219607

Epoch: 5| Step: 8
Training loss: 1.0818169116973877
Validation loss: 1.9792944051886117

Epoch: 5| Step: 9
Training loss: 1.2632945775985718
Validation loss: 2.0256873638399187

Epoch: 5| Step: 10
Training loss: 1.5371934175491333
Validation loss: 2.0067976085088586

Epoch: 720| Step: 0
Training loss: 0.8556613922119141
Validation loss: 1.9764949301237702

Epoch: 5| Step: 1
Training loss: 1.0048776865005493
Validation loss: 2.0299159839589107

Epoch: 5| Step: 2
Training loss: 0.7417712211608887
Validation loss: 2.009631610685779

Epoch: 5| Step: 3
Training loss: 1.064978003501892
Validation loss: 2.0267061546284664

Epoch: 5| Step: 4
Training loss: 0.6487163305282593
Validation loss: 2.0101245321253294

Epoch: 5| Step: 5
Training loss: 0.8801830410957336
Validation loss: 2.0237878112382788

Epoch: 5| Step: 6
Training loss: 1.3811336755752563
Validation loss: 1.9727200090244252

Epoch: 5| Step: 7
Training loss: 1.1298840045928955
Validation loss: 1.9541830683267245

Epoch: 5| Step: 8
Training loss: 1.201995849609375
Validation loss: 2.0105623596458027

Epoch: 5| Step: 9
Training loss: 0.965437114238739
Validation loss: 1.962139388566376

Epoch: 5| Step: 10
Training loss: 1.479477047920227
Validation loss: 1.973830714020678

Epoch: 721| Step: 0
Training loss: 1.0838886499404907
Validation loss: 2.031679114987773

Epoch: 5| Step: 1
Training loss: 1.2018362283706665
Validation loss: 1.9411518919852473

Epoch: 5| Step: 2
Training loss: 0.8504354357719421
Validation loss: 2.0369545900693504

Epoch: 5| Step: 3
Training loss: 1.1721620559692383
Validation loss: 1.9786781431526266

Epoch: 5| Step: 4
Training loss: 0.6564912796020508
Validation loss: 1.987998862420359

Epoch: 5| Step: 5
Training loss: 1.0583778619766235
Validation loss: 1.9902983121974493

Epoch: 5| Step: 6
Training loss: 0.9678839445114136
Validation loss: 1.9915134176131217

Epoch: 5| Step: 7
Training loss: 0.9324329495429993
Validation loss: 1.9739185533215922

Epoch: 5| Step: 8
Training loss: 1.1220808029174805
Validation loss: 2.0329131362258748

Epoch: 5| Step: 9
Training loss: 1.0970712900161743
Validation loss: 1.9790267931517733

Epoch: 5| Step: 10
Training loss: 0.9642477631568909
Validation loss: 2.039697595821914

Epoch: 722| Step: 0
Training loss: 0.58916836977005
Validation loss: 1.9725676531432776

Epoch: 5| Step: 1
Training loss: 0.9263842701911926
Validation loss: 1.969797795818698

Epoch: 5| Step: 2
Training loss: 1.2351020574569702
Validation loss: 1.984766811452886

Epoch: 5| Step: 3
Training loss: 1.2494579553604126
Validation loss: 1.9530009556842107

Epoch: 5| Step: 4
Training loss: 1.0058956146240234
Validation loss: 1.9715955436870616

Epoch: 5| Step: 5
Training loss: 1.2380083799362183
Validation loss: 1.9939326727262108

Epoch: 5| Step: 6
Training loss: 1.552211046218872
Validation loss: 2.033158850926225

Epoch: 5| Step: 7
Training loss: 0.7478238344192505
Validation loss: 1.9649964596635552

Epoch: 5| Step: 8
Training loss: 0.8942205309867859
Validation loss: 1.9390082718223653

Epoch: 5| Step: 9
Training loss: 0.5160018801689148
Validation loss: 1.9624843212866014

Epoch: 5| Step: 10
Training loss: 1.3626346588134766
Validation loss: 1.973762724989204

Epoch: 723| Step: 0
Training loss: 1.037471890449524
Validation loss: 1.9890460762926327

Epoch: 5| Step: 1
Training loss: 1.0466210842132568
Validation loss: 2.013629908202797

Epoch: 5| Step: 2
Training loss: 1.0587533712387085
Validation loss: 1.9628558133238105

Epoch: 5| Step: 3
Training loss: 1.1036195755004883
Validation loss: 2.0392974089550715

Epoch: 5| Step: 4
Training loss: 0.9079314470291138
Validation loss: 2.0183365627001693

Epoch: 5| Step: 5
Training loss: 0.5816875696182251
Validation loss: 2.0236499835086126

Epoch: 5| Step: 6
Training loss: 0.8753658533096313
Validation loss: 2.0441450854783416

Epoch: 5| Step: 7
Training loss: 1.2272270917892456
Validation loss: 1.9827370899979786

Epoch: 5| Step: 8
Training loss: 1.5321099758148193
Validation loss: 1.985083444144136

Epoch: 5| Step: 9
Training loss: 0.9980592727661133
Validation loss: 1.9837250427533222

Epoch: 5| Step: 10
Training loss: 1.0054515600204468
Validation loss: 1.9787339254092144

Epoch: 724| Step: 0
Training loss: 1.5934092998504639
Validation loss: 1.984380801518758

Epoch: 5| Step: 1
Training loss: 0.5464574098587036
Validation loss: 1.9935331395877305

Epoch: 5| Step: 2
Training loss: 1.1915796995162964
Validation loss: 1.9940054006473993

Epoch: 5| Step: 3
Training loss: 1.0984398126602173
Validation loss: 1.9854637166505218

Epoch: 5| Step: 4
Training loss: 1.2377125024795532
Validation loss: 1.9746517058341735

Epoch: 5| Step: 5
Training loss: 1.111140489578247
Validation loss: 1.9939252650865944

Epoch: 5| Step: 6
Training loss: 0.7043009996414185
Validation loss: 1.9842931762818368

Epoch: 5| Step: 7
Training loss: 1.053737998008728
Validation loss: 1.9497567517783052

Epoch: 5| Step: 8
Training loss: 1.3115520477294922
Validation loss: 2.006494532349289

Epoch: 5| Step: 9
Training loss: 0.6708064675331116
Validation loss: 1.9974654977039625

Epoch: 5| Step: 10
Training loss: 0.7718021273612976
Validation loss: 1.9729337307714647

Epoch: 725| Step: 0
Training loss: 1.1009790897369385
Validation loss: 1.9668559438438826

Epoch: 5| Step: 1
Training loss: 1.3447401523590088
Validation loss: 1.984528394155605

Epoch: 5| Step: 2
Training loss: 0.6237096786499023
Validation loss: 1.9543964170640515

Epoch: 5| Step: 3
Training loss: 0.8032573461532593
Validation loss: 2.0427287188909387

Epoch: 5| Step: 4
Training loss: 0.9198796153068542
Validation loss: 2.0212489533168014

Epoch: 5| Step: 5
Training loss: 1.1262357234954834
Validation loss: 1.9825128778334586

Epoch: 5| Step: 6
Training loss: 1.0633448362350464
Validation loss: 2.0300749553147184

Epoch: 5| Step: 7
Training loss: 0.7783513069152832
Validation loss: 1.9649407863616943

Epoch: 5| Step: 8
Training loss: 0.9580197334289551
Validation loss: 1.9518228320665256

Epoch: 5| Step: 9
Training loss: 0.9450401067733765
Validation loss: 1.9905587037404378

Epoch: 5| Step: 10
Training loss: 1.523178219795227
Validation loss: 1.9788377079912411

Epoch: 726| Step: 0
Training loss: 1.4623467922210693
Validation loss: 2.0251086834938294

Epoch: 5| Step: 1
Training loss: 0.8935969471931458
Validation loss: 1.992998835861042

Epoch: 5| Step: 2
Training loss: 0.9811286926269531
Validation loss: 1.997043216100303

Epoch: 5| Step: 3
Training loss: 1.1851779222488403
Validation loss: 1.9728933508678148

Epoch: 5| Step: 4
Training loss: 1.1122419834136963
Validation loss: 2.0032776914617068

Epoch: 5| Step: 5
Training loss: 0.8819138407707214
Validation loss: 1.9644037087758381

Epoch: 5| Step: 6
Training loss: 1.3139731884002686
Validation loss: 1.9522722895427416

Epoch: 5| Step: 7
Training loss: 0.44339004158973694
Validation loss: 2.0059810992210143

Epoch: 5| Step: 8
Training loss: 0.795434832572937
Validation loss: 1.98775303235618

Epoch: 5| Step: 9
Training loss: 0.8317155838012695
Validation loss: 1.9810768506860221

Epoch: 5| Step: 10
Training loss: 1.2570791244506836
Validation loss: 1.9737932976856027

Epoch: 727| Step: 0
Training loss: 1.2371915578842163
Validation loss: 1.9875857612138152

Epoch: 5| Step: 1
Training loss: 1.6447786092758179
Validation loss: 1.9505450469191357

Epoch: 5| Step: 2
Training loss: 0.8695276379585266
Validation loss: 1.9002262046260219

Epoch: 5| Step: 3
Training loss: 0.7516738176345825
Validation loss: 1.947121185641135

Epoch: 5| Step: 4
Training loss: 0.8522844314575195
Validation loss: 1.964705563360645

Epoch: 5| Step: 5
Training loss: 0.6791206002235413
Validation loss: 2.0300803697237404

Epoch: 5| Step: 6
Training loss: 0.6595045924186707
Validation loss: 1.9978610059266448

Epoch: 5| Step: 7
Training loss: 1.1082640886306763
Validation loss: 1.977427415950324

Epoch: 5| Step: 8
Training loss: 0.9516305923461914
Validation loss: 1.9581078355030348

Epoch: 5| Step: 9
Training loss: 1.111070990562439
Validation loss: 1.981199319644641

Epoch: 5| Step: 10
Training loss: 1.0286343097686768
Validation loss: 2.005962723044939

Epoch: 728| Step: 0
Training loss: 0.9612960815429688
Validation loss: 2.0291262108792543

Epoch: 5| Step: 1
Training loss: 1.0717452764511108
Validation loss: 1.998778579055622

Epoch: 5| Step: 2
Training loss: 0.9777032732963562
Validation loss: 2.006068847512686

Epoch: 5| Step: 3
Training loss: 1.2979447841644287
Validation loss: 2.008560690828549

Epoch: 5| Step: 4
Training loss: 1.0945613384246826
Validation loss: 1.9991958090054092

Epoch: 5| Step: 5
Training loss: 1.2835642099380493
Validation loss: 1.9706354371963009

Epoch: 5| Step: 6
Training loss: 0.7496373057365417
Validation loss: 1.9642152273526756

Epoch: 5| Step: 7
Training loss: 1.244370460510254
Validation loss: 1.9621664119023148

Epoch: 5| Step: 8
Training loss: 0.7805760502815247
Validation loss: 1.9686867357582174

Epoch: 5| Step: 9
Training loss: 0.9475696682929993
Validation loss: 1.9784693692320137

Epoch: 5| Step: 10
Training loss: 0.6123066544532776
Validation loss: 2.0089746265001196

Epoch: 729| Step: 0
Training loss: 0.9333903193473816
Validation loss: 1.938176626800209

Epoch: 5| Step: 1
Training loss: 1.0952014923095703
Validation loss: 1.9881164027798561

Epoch: 5| Step: 2
Training loss: 1.3125627040863037
Validation loss: 2.0054928589892644

Epoch: 5| Step: 3
Training loss: 1.00178861618042
Validation loss: 2.011485849657366

Epoch: 5| Step: 4
Training loss: 0.8324151039123535
Validation loss: 1.9775906070586173

Epoch: 5| Step: 5
Training loss: 1.1743847131729126
Validation loss: 1.974131356003464

Epoch: 5| Step: 6
Training loss: 1.1562795639038086
Validation loss: 2.00357126292362

Epoch: 5| Step: 7
Training loss: 0.9854949712753296
Validation loss: 1.9400810182735484

Epoch: 5| Step: 8
Training loss: 0.64304518699646
Validation loss: 1.9954092502593994

Epoch: 5| Step: 9
Training loss: 0.9771268963813782
Validation loss: 1.973837109022243

Epoch: 5| Step: 10
Training loss: 0.9554508328437805
Validation loss: 1.9627599562368085

Epoch: 730| Step: 0
Training loss: 0.5982514023780823
Validation loss: 2.027630630359855

Epoch: 5| Step: 1
Training loss: 0.6605969071388245
Validation loss: 2.0111716344792354

Epoch: 5| Step: 2
Training loss: 0.8579599261283875
Validation loss: 2.007678311358216

Epoch: 5| Step: 3
Training loss: 0.8925271034240723
Validation loss: 1.9930308083052277

Epoch: 5| Step: 4
Training loss: 1.1279079914093018
Validation loss: 2.021867923839118

Epoch: 5| Step: 5
Training loss: 1.1554641723632812
Validation loss: 1.9833078948400353

Epoch: 5| Step: 6
Training loss: 1.0199010372161865
Validation loss: 1.9312476291451404

Epoch: 5| Step: 7
Training loss: 1.137708067893982
Validation loss: 2.00924087596196

Epoch: 5| Step: 8
Training loss: 1.1740341186523438
Validation loss: 2.0165006511954853

Epoch: 5| Step: 9
Training loss: 1.3949339389801025
Validation loss: 1.9829419505211614

Epoch: 5| Step: 10
Training loss: 0.7735815644264221
Validation loss: 1.9840239542786793

Epoch: 731| Step: 0
Training loss: 1.452632188796997
Validation loss: 1.9604658644686463

Epoch: 5| Step: 1
Training loss: 1.1129963397979736
Validation loss: 2.041355147156664

Epoch: 5| Step: 2
Training loss: 1.5417582988739014
Validation loss: 1.9757246099492556

Epoch: 5| Step: 3
Training loss: 0.9921366572380066
Validation loss: 1.994906363948699

Epoch: 5| Step: 4
Training loss: 0.7552273869514465
Validation loss: 2.007852905540056

Epoch: 5| Step: 5
Training loss: 0.9918030500411987
Validation loss: 1.9788382450739543

Epoch: 5| Step: 6
Training loss: 1.1234207153320312
Validation loss: 1.934375898812407

Epoch: 5| Step: 7
Training loss: 0.4951413571834564
Validation loss: 1.9531988046502555

Epoch: 5| Step: 8
Training loss: 0.723404049873352
Validation loss: 1.9460669986663326

Epoch: 5| Step: 9
Training loss: 0.8701778650283813
Validation loss: 1.9805374542872112

Epoch: 5| Step: 10
Training loss: 0.9625421166419983
Validation loss: 1.9511151467600176

Epoch: 732| Step: 0
Training loss: 0.7468295693397522
Validation loss: 2.014752359800441

Epoch: 5| Step: 1
Training loss: 0.9723618626594543
Validation loss: 1.9859744656470515

Epoch: 5| Step: 2
Training loss: 1.1012036800384521
Validation loss: 1.9946943457408617

Epoch: 5| Step: 3
Training loss: 0.955889105796814
Validation loss: 1.9724634898606168

Epoch: 5| Step: 4
Training loss: 1.1499465703964233
Validation loss: 1.9919583746182021

Epoch: 5| Step: 5
Training loss: 1.3842188119888306
Validation loss: 2.0047907931830293

Epoch: 5| Step: 6
Training loss: 0.6669928431510925
Validation loss: 1.9547912459219656

Epoch: 5| Step: 7
Training loss: 0.7538623213768005
Validation loss: 1.9625486814847557

Epoch: 5| Step: 8
Training loss: 0.6796536445617676
Validation loss: 1.9595850283099758

Epoch: 5| Step: 9
Training loss: 0.7410603165626526
Validation loss: 1.9967082828603766

Epoch: 5| Step: 10
Training loss: 1.8694275617599487
Validation loss: 1.997573652575093

Epoch: 733| Step: 0
Training loss: 1.0968888998031616
Validation loss: 2.0051253162404543

Epoch: 5| Step: 1
Training loss: 1.2058660984039307
Validation loss: 1.979500247586158

Epoch: 5| Step: 2
Training loss: 0.68910813331604
Validation loss: 1.9827316653343938

Epoch: 5| Step: 3
Training loss: 0.7855821251869202
Validation loss: 1.9539650870907692

Epoch: 5| Step: 4
Training loss: 1.0325322151184082
Validation loss: 1.9797647140359367

Epoch: 5| Step: 5
Training loss: 0.9952610731124878
Validation loss: 1.955806073322091

Epoch: 5| Step: 6
Training loss: 0.9809786081314087
Validation loss: 1.9616129398345947

Epoch: 5| Step: 7
Training loss: 1.425830602645874
Validation loss: 1.9521004025654127

Epoch: 5| Step: 8
Training loss: 0.8884681463241577
Validation loss: 2.008623721779034

Epoch: 5| Step: 9
Training loss: 1.295066475868225
Validation loss: 2.015939517687726

Epoch: 5| Step: 10
Training loss: 0.6426684260368347
Validation loss: 2.0023603003512145

Epoch: 734| Step: 0
Training loss: 0.8574861288070679
Validation loss: 2.0029989698881745

Epoch: 5| Step: 1
Training loss: 1.1461988687515259
Validation loss: 2.0090021241095757

Epoch: 5| Step: 2
Training loss: 1.2975423336029053
Validation loss: 1.9846319408826931

Epoch: 5| Step: 3
Training loss: 0.7794540524482727
Validation loss: 1.9966987461172125

Epoch: 5| Step: 4
Training loss: 0.8177655935287476
Validation loss: 2.004800042798442

Epoch: 5| Step: 5
Training loss: 1.1207239627838135
Validation loss: 2.000404868074643

Epoch: 5| Step: 6
Training loss: 1.5312635898590088
Validation loss: 1.9646853298269293

Epoch: 5| Step: 7
Training loss: 0.9385733604431152
Validation loss: 2.0023554512249526

Epoch: 5| Step: 8
Training loss: 0.8053137063980103
Validation loss: 1.982589384560944

Epoch: 5| Step: 9
Training loss: 0.8146550059318542
Validation loss: 1.9602116794996365

Epoch: 5| Step: 10
Training loss: 1.032982587814331
Validation loss: 1.952277974415851

Epoch: 735| Step: 0
Training loss: 1.2045397758483887
Validation loss: 1.9697295901595906

Epoch: 5| Step: 1
Training loss: 0.959595799446106
Validation loss: 1.9396205563699045

Epoch: 5| Step: 2
Training loss: 1.1902682781219482
Validation loss: 1.983478525633453

Epoch: 5| Step: 3
Training loss: 0.8303014636039734
Validation loss: 1.992760528800308

Epoch: 5| Step: 4
Training loss: 1.3139934539794922
Validation loss: 2.0344151450741674

Epoch: 5| Step: 5
Training loss: 1.2890907526016235
Validation loss: 1.9381150237975582

Epoch: 5| Step: 6
Training loss: 0.9017652273178101
Validation loss: 2.009252481563117

Epoch: 5| Step: 7
Training loss: 0.9783528447151184
Validation loss: 2.000515789114019

Epoch: 5| Step: 8
Training loss: 0.9043084979057312
Validation loss: 1.9724079383316862

Epoch: 5| Step: 9
Training loss: 0.7686708569526672
Validation loss: 2.005497701706425

Epoch: 5| Step: 10
Training loss: 0.7108442783355713
Validation loss: 1.9910556859867548

Epoch: 736| Step: 0
Training loss: 1.1521285772323608
Validation loss: 1.9899576684480071

Epoch: 5| Step: 1
Training loss: 0.8650429844856262
Validation loss: 1.9725634846636044

Epoch: 5| Step: 2
Training loss: 0.7181984186172485
Validation loss: 1.9783952338721162

Epoch: 5| Step: 3
Training loss: 1.3952726125717163
Validation loss: 1.9924934846098705

Epoch: 5| Step: 4
Training loss: 0.8762367367744446
Validation loss: 2.0274081665982484

Epoch: 5| Step: 5
Training loss: 1.2414661645889282
Validation loss: 1.9488309596174507

Epoch: 5| Step: 6
Training loss: 1.0964105129241943
Validation loss: 2.018172320499215

Epoch: 5| Step: 7
Training loss: 0.833676815032959
Validation loss: 1.986557008117758

Epoch: 5| Step: 8
Training loss: 0.9317981004714966
Validation loss: 2.0286104653471257

Epoch: 5| Step: 9
Training loss: 0.6846882104873657
Validation loss: 1.949308491522266

Epoch: 5| Step: 10
Training loss: 1.0202274322509766
Validation loss: 1.9723978298966602

Epoch: 737| Step: 0
Training loss: 1.110642671585083
Validation loss: 1.9795495233228129

Epoch: 5| Step: 1
Training loss: 1.0175141096115112
Validation loss: 1.9707118939327937

Epoch: 5| Step: 2
Training loss: 0.7918219566345215
Validation loss: 1.971327909859278

Epoch: 5| Step: 3
Training loss: 0.7625464200973511
Validation loss: 2.018803222205049

Epoch: 5| Step: 4
Training loss: 1.0204126834869385
Validation loss: 1.9280295897555608

Epoch: 5| Step: 5
Training loss: 1.0188226699829102
Validation loss: 1.9737593550835886

Epoch: 5| Step: 6
Training loss: 1.6037628650665283
Validation loss: 1.9786629292272753

Epoch: 5| Step: 7
Training loss: 0.9784963726997375
Validation loss: 1.9576602610208655

Epoch: 5| Step: 8
Training loss: 1.2064602375030518
Validation loss: 1.9608752048143776

Epoch: 5| Step: 9
Training loss: 0.8822551965713501
Validation loss: 1.9523416142309866

Epoch: 5| Step: 10
Training loss: 0.8396111130714417
Validation loss: 1.9280415529845862

Epoch: 738| Step: 0
Training loss: 0.6775801181793213
Validation loss: 1.978792973743972

Epoch: 5| Step: 1
Training loss: 1.0528967380523682
Validation loss: 1.983406659095518

Epoch: 5| Step: 2
Training loss: 0.7128778696060181
Validation loss: 1.9476498532038864

Epoch: 5| Step: 3
Training loss: 1.5404819250106812
Validation loss: 1.9698949911261117

Epoch: 5| Step: 4
Training loss: 1.172974705696106
Validation loss: 1.9433031415426603

Epoch: 5| Step: 5
Training loss: 0.7989236116409302
Validation loss: 1.9458590553652855

Epoch: 5| Step: 6
Training loss: 0.9511321783065796
Validation loss: 1.963481117320317

Epoch: 5| Step: 7
Training loss: 0.7631274461746216
Validation loss: 1.9841061420338129

Epoch: 5| Step: 8
Training loss: 1.0040340423583984
Validation loss: 1.9630533802893855

Epoch: 5| Step: 9
Training loss: 1.3190758228302002
Validation loss: 1.9456318693776284

Epoch: 5| Step: 10
Training loss: 0.7172330617904663
Validation loss: 2.013533907551919

Epoch: 739| Step: 0
Training loss: 0.7297830581665039
Validation loss: 1.9416437764321604

Epoch: 5| Step: 1
Training loss: 1.021226167678833
Validation loss: 1.9891634820609965

Epoch: 5| Step: 2
Training loss: 1.2466152906417847
Validation loss: 1.957815029287851

Epoch: 5| Step: 3
Training loss: 1.03127121925354
Validation loss: 1.9635380237333235

Epoch: 5| Step: 4
Training loss: 0.4638383388519287
Validation loss: 1.9409691390170847

Epoch: 5| Step: 5
Training loss: 1.042181134223938
Validation loss: 1.9631524085998535

Epoch: 5| Step: 6
Training loss: 1.289809226989746
Validation loss: 1.977995612288034

Epoch: 5| Step: 7
Training loss: 1.21816086769104
Validation loss: 1.9882542369186238

Epoch: 5| Step: 8
Training loss: 1.2040092945098877
Validation loss: 1.9877812708577802

Epoch: 5| Step: 9
Training loss: 1.056623935699463
Validation loss: 1.9466667406020626

Epoch: 5| Step: 10
Training loss: 0.6748743653297424
Validation loss: 2.0079148251523256

Epoch: 740| Step: 0
Training loss: 1.2098157405853271
Validation loss: 1.9983359382998558

Epoch: 5| Step: 1
Training loss: 1.263331413269043
Validation loss: 1.9524635602069158

Epoch: 5| Step: 2
Training loss: 1.0315954685211182
Validation loss: 1.9803842177955053

Epoch: 5| Step: 3
Training loss: 1.26397705078125
Validation loss: 1.999942410376764

Epoch: 5| Step: 4
Training loss: 0.7825578451156616
Validation loss: 2.0197377589441117

Epoch: 5| Step: 5
Training loss: 1.2691491842269897
Validation loss: 2.0324641171322075

Epoch: 5| Step: 6
Training loss: 0.9285899996757507
Validation loss: 2.030416642465899

Epoch: 5| Step: 7
Training loss: 0.9651477932929993
Validation loss: 1.9821653148179412

Epoch: 5| Step: 8
Training loss: 0.45948705077171326
Validation loss: 2.0315878698902745

Epoch: 5| Step: 9
Training loss: 0.784746527671814
Validation loss: 1.9549003993311236

Epoch: 5| Step: 10
Training loss: 1.189132809638977
Validation loss: 1.9394414527441866

Epoch: 741| Step: 0
Training loss: 0.9295850992202759
Validation loss: 1.9734272879938926

Epoch: 5| Step: 1
Training loss: 1.3511487245559692
Validation loss: 1.9856757130674136

Epoch: 5| Step: 2
Training loss: 0.7107331156730652
Validation loss: 1.9554285605748494

Epoch: 5| Step: 3
Training loss: 1.488298773765564
Validation loss: 1.9456953669107089

Epoch: 5| Step: 4
Training loss: 1.0025887489318848
Validation loss: 1.9596307277679443

Epoch: 5| Step: 5
Training loss: 0.9877722859382629
Validation loss: 1.9079138694270965

Epoch: 5| Step: 6
Training loss: 0.985081672668457
Validation loss: 2.01259377566717

Epoch: 5| Step: 7
Training loss: 0.7421639561653137
Validation loss: 1.9840027670706473

Epoch: 5| Step: 8
Training loss: 1.1040549278259277
Validation loss: 1.990993938138408

Epoch: 5| Step: 9
Training loss: 0.9134361147880554
Validation loss: 1.9528465206905077

Epoch: 5| Step: 10
Training loss: 0.898756206035614
Validation loss: 1.997390975234329

Epoch: 742| Step: 0
Training loss: 1.1312233209609985
Validation loss: 2.009905925361059

Epoch: 5| Step: 1
Training loss: 0.7449697256088257
Validation loss: 1.985615312412221

Epoch: 5| Step: 2
Training loss: 0.8722702264785767
Validation loss: 1.943953078280213

Epoch: 5| Step: 3
Training loss: 1.312646746635437
Validation loss: 1.9444424772775302

Epoch: 5| Step: 4
Training loss: 0.7223466634750366
Validation loss: 1.9668534878761537

Epoch: 5| Step: 5
Training loss: 1.1663075685501099
Validation loss: 1.9926085241379277

Epoch: 5| Step: 6
Training loss: 1.2063671350479126
Validation loss: 1.9717089770942606

Epoch: 5| Step: 7
Training loss: 0.6606029272079468
Validation loss: 1.9768090158380487

Epoch: 5| Step: 8
Training loss: 0.7018010020256042
Validation loss: 1.9539632156331053

Epoch: 5| Step: 9
Training loss: 0.7244272232055664
Validation loss: 1.9738728679636472

Epoch: 5| Step: 10
Training loss: 1.8361444473266602
Validation loss: 1.9235209111244447

Epoch: 743| Step: 0
Training loss: 1.2254700660705566
Validation loss: 1.932990772749788

Epoch: 5| Step: 1
Training loss: 1.169809341430664
Validation loss: 1.968644203678254

Epoch: 5| Step: 2
Training loss: 1.3576209545135498
Validation loss: 1.8887888475130963

Epoch: 5| Step: 3
Training loss: 0.927276611328125
Validation loss: 1.9976016539399342

Epoch: 5| Step: 4
Training loss: 0.8921182751655579
Validation loss: 1.9081083164420178

Epoch: 5| Step: 5
Training loss: 1.125255823135376
Validation loss: 1.934325187436996

Epoch: 5| Step: 6
Training loss: 0.8207061886787415
Validation loss: 1.9506965337261077

Epoch: 5| Step: 7
Training loss: 1.157265067100525
Validation loss: 1.9930778562381704

Epoch: 5| Step: 8
Training loss: 0.5787144899368286
Validation loss: 1.9757560478743685

Epoch: 5| Step: 9
Training loss: 1.1792247295379639
Validation loss: 1.9759896070726457

Epoch: 5| Step: 10
Training loss: 0.3393610417842865
Validation loss: 2.006985900222614

Epoch: 744| Step: 0
Training loss: 0.9416923522949219
Validation loss: 2.0114286503484173

Epoch: 5| Step: 1
Training loss: 1.0195093154907227
Validation loss: 1.9868067361975228

Epoch: 5| Step: 2
Training loss: 0.8958223462104797
Validation loss: 1.9944104738132928

Epoch: 5| Step: 3
Training loss: 0.7358454465866089
Validation loss: 1.9924530700970722

Epoch: 5| Step: 4
Training loss: 0.45349693298339844
Validation loss: 1.9769126446016374

Epoch: 5| Step: 5
Training loss: 1.1748673915863037
Validation loss: 1.9274025809380315

Epoch: 5| Step: 6
Training loss: 0.7806483507156372
Validation loss: 1.9456297197649557

Epoch: 5| Step: 7
Training loss: 1.3385686874389648
Validation loss: 1.9423780184920116

Epoch: 5| Step: 8
Training loss: 1.362985372543335
Validation loss: 1.9447249135663431

Epoch: 5| Step: 9
Training loss: 1.045202374458313
Validation loss: 1.9842334396095687

Epoch: 5| Step: 10
Training loss: 1.170683741569519
Validation loss: 1.9824196010507562

Epoch: 745| Step: 0
Training loss: 0.6377793550491333
Validation loss: 1.9895436110035065

Epoch: 5| Step: 1
Training loss: 1.1579875946044922
Validation loss: 2.0333130257104033

Epoch: 5| Step: 2
Training loss: 0.879162609577179
Validation loss: 1.9758413972393158

Epoch: 5| Step: 3
Training loss: 1.2709873914718628
Validation loss: 1.9619485588483914

Epoch: 5| Step: 4
Training loss: 0.6026034951210022
Validation loss: 1.9898850046178347

Epoch: 5| Step: 5
Training loss: 1.1419264078140259
Validation loss: 2.007876193651589

Epoch: 5| Step: 6
Training loss: 1.3487789630889893
Validation loss: 2.023576141685568

Epoch: 5| Step: 7
Training loss: 0.945397675037384
Validation loss: 2.0065900266811414

Epoch: 5| Step: 8
Training loss: 1.0875816345214844
Validation loss: 1.973184706062399

Epoch: 5| Step: 9
Training loss: 0.6299898624420166
Validation loss: 1.9749399154416976

Epoch: 5| Step: 10
Training loss: 1.1009809970855713
Validation loss: 1.9716987789318126

Epoch: 746| Step: 0
Training loss: 0.5581635236740112
Validation loss: 1.9980500205870597

Epoch: 5| Step: 1
Training loss: 0.7442429661750793
Validation loss: 1.977322563048332

Epoch: 5| Step: 2
Training loss: 0.6902303695678711
Validation loss: 1.976857417373247

Epoch: 5| Step: 3
Training loss: 1.3461694717407227
Validation loss: 1.9927224356641051

Epoch: 5| Step: 4
Training loss: 1.205909252166748
Validation loss: 1.9282215051753546

Epoch: 5| Step: 5
Training loss: 1.184661865234375
Validation loss: 1.9774963868561612

Epoch: 5| Step: 6
Training loss: 1.315230131149292
Validation loss: 1.9741366473577355

Epoch: 5| Step: 7
Training loss: 1.1451137065887451
Validation loss: 1.9435273062798284

Epoch: 5| Step: 8
Training loss: 0.8097759485244751
Validation loss: 1.9425307884011218

Epoch: 5| Step: 9
Training loss: 0.7794421911239624
Validation loss: 1.9743132809157014

Epoch: 5| Step: 10
Training loss: 1.1285121440887451
Validation loss: 1.9060917464635705

Epoch: 747| Step: 0
Training loss: 0.9169563055038452
Validation loss: 1.9630112084009315

Epoch: 5| Step: 1
Training loss: 0.7882182598114014
Validation loss: 2.0106702876347367

Epoch: 5| Step: 2
Training loss: 0.695970892906189
Validation loss: 2.0209071251653854

Epoch: 5| Step: 3
Training loss: 1.34568190574646
Validation loss: 2.006783554630895

Epoch: 5| Step: 4
Training loss: 0.8849145770072937
Validation loss: 2.0030386678634153

Epoch: 5| Step: 5
Training loss: 0.6097312569618225
Validation loss: 1.976989569202546

Epoch: 5| Step: 6
Training loss: 1.306003451347351
Validation loss: 2.028516661736273

Epoch: 5| Step: 7
Training loss: 0.8728793859481812
Validation loss: 1.9570643389096825

Epoch: 5| Step: 8
Training loss: 0.8812753558158875
Validation loss: 1.9835456981453845

Epoch: 5| Step: 9
Training loss: 1.033403754234314
Validation loss: 2.00353592441928

Epoch: 5| Step: 10
Training loss: 1.5832737684249878
Validation loss: 1.9202866426078222

Epoch: 748| Step: 0
Training loss: 0.9802452325820923
Validation loss: 1.9931130332331504

Epoch: 5| Step: 1
Training loss: 1.184698224067688
Validation loss: 1.9452472040730138

Epoch: 5| Step: 2
Training loss: 1.3179562091827393
Validation loss: 1.951688208887654

Epoch: 5| Step: 3
Training loss: 0.8806289434432983
Validation loss: 1.9436981524190595

Epoch: 5| Step: 4
Training loss: 1.2978655099868774
Validation loss: 1.9854245416579708

Epoch: 5| Step: 5
Training loss: 1.270244836807251
Validation loss: 1.9849714181756462

Epoch: 5| Step: 6
Training loss: 0.6750758290290833
Validation loss: 1.9478423467246435

Epoch: 5| Step: 7
Training loss: 0.8935272097587585
Validation loss: 1.9754582784509147

Epoch: 5| Step: 8
Training loss: 0.8726959228515625
Validation loss: 1.915545573798559

Epoch: 5| Step: 9
Training loss: 0.8891421556472778
Validation loss: 1.9709858650802283

Epoch: 5| Step: 10
Training loss: 0.4590994417667389
Validation loss: 2.012957424245855

Epoch: 749| Step: 0
Training loss: 1.0930840969085693
Validation loss: 1.9712369903441398

Epoch: 5| Step: 1
Training loss: 0.7162286639213562
Validation loss: 1.9713300633174118

Epoch: 5| Step: 2
Training loss: 0.8716486096382141
Validation loss: 2.0013960151262182

Epoch: 5| Step: 3
Training loss: 0.942238986492157
Validation loss: 1.999568421353576

Epoch: 5| Step: 4
Training loss: 1.2140123844146729
Validation loss: 2.0178898175557456

Epoch: 5| Step: 5
Training loss: 1.7335662841796875
Validation loss: 1.9763140537405526

Epoch: 5| Step: 6
Training loss: 0.7516665458679199
Validation loss: 1.9888637053069247

Epoch: 5| Step: 7
Training loss: 0.6521441340446472
Validation loss: 1.9499222950268817

Epoch: 5| Step: 8
Training loss: 1.1614034175872803
Validation loss: 1.968617864834365

Epoch: 5| Step: 9
Training loss: 0.7679585218429565
Validation loss: 2.000606084382662

Epoch: 5| Step: 10
Training loss: 1.225829839706421
Validation loss: 1.9306525671353905

Epoch: 750| Step: 0
Training loss: 1.2368614673614502
Validation loss: 1.9477683151921918

Epoch: 5| Step: 1
Training loss: 1.2772681713104248
Validation loss: 1.960239948764924

Epoch: 5| Step: 2
Training loss: 1.0036025047302246
Validation loss: 1.9647517691376388

Epoch: 5| Step: 3
Training loss: 0.929305911064148
Validation loss: 1.9859088800286735

Epoch: 5| Step: 4
Training loss: 1.0254923105239868
Validation loss: 1.874030165774848

Epoch: 5| Step: 5
Training loss: 0.9051458239555359
Validation loss: 2.0007275458305114

Epoch: 5| Step: 6
Training loss: 0.9876019358634949
Validation loss: 1.9730418958971578

Epoch: 5| Step: 7
Training loss: 0.9274746179580688
Validation loss: 1.9427232601309334

Epoch: 5| Step: 8
Training loss: 0.818032443523407
Validation loss: 2.0213375617099065

Epoch: 5| Step: 9
Training loss: 0.8402740359306335
Validation loss: 1.9654459312397947

Epoch: 5| Step: 10
Training loss: 0.6403489112854004
Validation loss: 1.964442095448894

Testing loss: 2.1562109655804105
