Epoch: 1| Step: 0
Training loss: 3.424164056777954
Validation loss: 4.2773022395308296

Epoch: 6| Step: 1
Training loss: 3.653782367706299
Validation loss: 4.277575080112745

Epoch: 6| Step: 2
Training loss: 4.162854194641113
Validation loss: 4.272799750810028

Epoch: 6| Step: 3
Training loss: 5.198106288909912
Validation loss: 4.2737284014301915

Epoch: 6| Step: 4
Training loss: 3.4776220321655273
Validation loss: 4.272378419035224

Epoch: 6| Step: 5
Training loss: 4.533456802368164
Validation loss: 4.2690416894933225

Epoch: 6| Step: 6
Training loss: 4.567584991455078
Validation loss: 4.269069733158235

Epoch: 6| Step: 7
Training loss: 3.7712602615356445
Validation loss: 4.268111157160933

Epoch: 6| Step: 8
Training loss: 3.6754567623138428
Validation loss: 4.262819946453136

Epoch: 6| Step: 9
Training loss: 5.282042980194092
Validation loss: 4.2628488950831915

Epoch: 6| Step: 10
Training loss: 2.779543161392212
Validation loss: 4.260906824501612

Epoch: 6| Step: 11
Training loss: 4.099140167236328
Validation loss: 4.259042668086226

Epoch: 6| Step: 12
Training loss: 4.539957046508789
Validation loss: 4.25952850362306

Epoch: 6| Step: 13
Training loss: 4.08186674118042
Validation loss: 4.255711570862801

Epoch: 2| Step: 0
Training loss: 3.5583291053771973
Validation loss: 4.255730013693532

Epoch: 6| Step: 1
Training loss: 5.5913238525390625
Validation loss: 4.253506588679488

Epoch: 6| Step: 2
Training loss: 3.934540271759033
Validation loss: 4.250951259366928

Epoch: 6| Step: 3
Training loss: 4.224489212036133
Validation loss: 4.251422502661264

Epoch: 6| Step: 4
Training loss: 3.8875374794006348
Validation loss: 4.248289841477589

Epoch: 6| Step: 5
Training loss: 3.4451513290405273
Validation loss: 4.247192457158079

Epoch: 6| Step: 6
Training loss: 4.775040149688721
Validation loss: 4.245498226534936

Epoch: 6| Step: 7
Training loss: 3.918754816055298
Validation loss: 4.244296079040856

Epoch: 6| Step: 8
Training loss: 3.9536962509155273
Validation loss: 4.24433090866253

Epoch: 6| Step: 9
Training loss: 3.607689619064331
Validation loss: 4.239924538520075

Epoch: 6| Step: 10
Training loss: 4.324347496032715
Validation loss: 4.239995125801332

Epoch: 6| Step: 11
Training loss: 4.740464210510254
Validation loss: 4.2401583425460325

Epoch: 6| Step: 12
Training loss: 3.206770181655884
Validation loss: 4.23824950443801

Epoch: 6| Step: 13
Training loss: 3.5704188346862793
Validation loss: 4.235099269497779

Epoch: 3| Step: 0
Training loss: 3.9040427207946777
Validation loss: 4.232752574387417

Epoch: 6| Step: 1
Training loss: 3.791816234588623
Validation loss: 4.234369793245869

Epoch: 6| Step: 2
Training loss: 3.4828128814697266
Validation loss: 4.229787321500881

Epoch: 6| Step: 3
Training loss: 2.888584852218628
Validation loss: 4.230263345985002

Epoch: 6| Step: 4
Training loss: 3.0560803413391113
Validation loss: 4.226797044918102

Epoch: 6| Step: 5
Training loss: 6.9625701904296875
Validation loss: 4.224449332042407

Epoch: 6| Step: 6
Training loss: 3.098764181137085
Validation loss: 4.22616187731425

Epoch: 6| Step: 7
Training loss: 4.028528213500977
Validation loss: 4.2235283646532285

Epoch: 6| Step: 8
Training loss: 4.440742492675781
Validation loss: 4.219218115652761

Epoch: 6| Step: 9
Training loss: 3.9990477561950684
Validation loss: 4.218482171335528

Epoch: 6| Step: 10
Training loss: 4.300142288208008
Validation loss: 4.220600922902425

Epoch: 6| Step: 11
Training loss: 3.4401440620422363
Validation loss: 4.2165566157269225

Epoch: 6| Step: 12
Training loss: 4.990007400512695
Validation loss: 4.213800732807447

Epoch: 6| Step: 13
Training loss: 4.447168350219727
Validation loss: 4.21458629895282

Epoch: 4| Step: 0
Training loss: 4.05161190032959
Validation loss: 4.212067027245799

Epoch: 6| Step: 1
Training loss: 4.156144618988037
Validation loss: 4.209951282829366

Epoch: 6| Step: 2
Training loss: 3.815870523452759
Validation loss: 4.209330430594823

Epoch: 6| Step: 3
Training loss: 3.867197036743164
Validation loss: 4.206818765209567

Epoch: 6| Step: 4
Training loss: 5.029213905334473
Validation loss: 4.204632328402612

Epoch: 6| Step: 5
Training loss: 3.7507238388061523
Validation loss: 4.2016056942683395

Epoch: 6| Step: 6
Training loss: 3.6507797241210938
Validation loss: 4.200734671726022

Epoch: 6| Step: 7
Training loss: 3.131483554840088
Validation loss: 4.199360842345863

Epoch: 6| Step: 8
Training loss: 2.625141143798828
Validation loss: 4.196377400429018

Epoch: 6| Step: 9
Training loss: 5.44810152053833
Validation loss: 4.194764778178225

Epoch: 6| Step: 10
Training loss: 3.6040165424346924
Validation loss: 4.193789751298966

Epoch: 6| Step: 11
Training loss: 4.106904029846191
Validation loss: 4.191828594412855

Epoch: 6| Step: 12
Training loss: 4.385364055633545
Validation loss: 4.188492303253502

Epoch: 6| Step: 13
Training loss: 5.32160758972168
Validation loss: 4.186816212951496

Epoch: 5| Step: 0
Training loss: 4.393405914306641
Validation loss: 4.184411443689818

Epoch: 6| Step: 1
Training loss: 4.525864601135254
Validation loss: 4.183519922276979

Epoch: 6| Step: 2
Training loss: 4.279110431671143
Validation loss: 4.180612776869086

Epoch: 6| Step: 3
Training loss: 4.095745086669922
Validation loss: 4.17812934998543

Epoch: 6| Step: 4
Training loss: 4.2275896072387695
Validation loss: 4.1768570100107505

Epoch: 6| Step: 5
Training loss: 3.4201693534851074
Validation loss: 4.173158527702413

Epoch: 6| Step: 6
Training loss: 3.6472973823547363
Validation loss: 4.171253506855298

Epoch: 6| Step: 7
Training loss: 2.9851574897766113
Validation loss: 4.17319082444714

Epoch: 6| Step: 8
Training loss: 4.9004316329956055
Validation loss: 4.167239043020433

Epoch: 6| Step: 9
Training loss: 3.9992458820343018
Validation loss: 4.163431054802351

Epoch: 6| Step: 10
Training loss: 4.713894844055176
Validation loss: 4.159408994900283

Epoch: 6| Step: 11
Training loss: 2.7352633476257324
Validation loss: 4.158946142401747

Epoch: 6| Step: 12
Training loss: 3.967989444732666
Validation loss: 4.154849436975295

Epoch: 6| Step: 13
Training loss: 4.157413005828857
Validation loss: 4.150254769991803

Epoch: 6| Step: 0
Training loss: 2.4282758235931396
Validation loss: 4.148621528379379

Epoch: 6| Step: 1
Training loss: 4.673565864562988
Validation loss: 4.146068132051858

Epoch: 6| Step: 2
Training loss: 4.711824417114258
Validation loss: 4.144650282398347

Epoch: 6| Step: 3
Training loss: 3.1032519340515137
Validation loss: 4.137906153996785

Epoch: 6| Step: 4
Training loss: 4.008363246917725
Validation loss: 4.13799984224381

Epoch: 6| Step: 5
Training loss: 4.463535785675049
Validation loss: 4.133158801704325

Epoch: 6| Step: 6
Training loss: 4.272782325744629
Validation loss: 4.132226913206039

Epoch: 6| Step: 7
Training loss: 3.946413993835449
Validation loss: 4.1286236393836235

Epoch: 6| Step: 8
Training loss: 3.554330825805664
Validation loss: 4.124369200839792

Epoch: 6| Step: 9
Training loss: 4.829278469085693
Validation loss: 4.11965274810791

Epoch: 6| Step: 10
Training loss: 2.939177989959717
Validation loss: 4.117226372482956

Epoch: 6| Step: 11
Training loss: 3.7803149223327637
Validation loss: 4.1157737496078655

Epoch: 6| Step: 12
Training loss: 4.40079927444458
Validation loss: 4.1128400371920675

Epoch: 6| Step: 13
Training loss: 4.665213108062744
Validation loss: 4.106032566357684

Epoch: 7| Step: 0
Training loss: 3.900440216064453
Validation loss: 4.105079081750685

Epoch: 6| Step: 1
Training loss: 4.209338188171387
Validation loss: 4.101932048797607

Epoch: 6| Step: 2
Training loss: 3.829380750656128
Validation loss: 4.097216775340419

Epoch: 6| Step: 3
Training loss: 4.419232368469238
Validation loss: 4.094886851567094

Epoch: 6| Step: 4
Training loss: 3.1790518760681152
Validation loss: 4.092954163910241

Epoch: 6| Step: 5
Training loss: 4.181751251220703
Validation loss: 4.0858272121798604

Epoch: 6| Step: 6
Training loss: 4.473007678985596
Validation loss: 4.083978181244225

Epoch: 6| Step: 7
Training loss: 3.832345485687256
Validation loss: 4.0791615157999015

Epoch: 6| Step: 8
Training loss: 3.6250624656677246
Validation loss: 4.078699129883961

Epoch: 6| Step: 9
Training loss: 4.132425785064697
Validation loss: 4.075235171984601

Epoch: 6| Step: 10
Training loss: 4.066628456115723
Validation loss: 4.070402237676805

Epoch: 6| Step: 11
Training loss: 3.7866761684417725
Validation loss: 4.070480854280533

Epoch: 6| Step: 12
Training loss: 4.095258712768555
Validation loss: 4.064185316844653

Epoch: 6| Step: 13
Training loss: 2.572110891342163
Validation loss: 4.0604641283712075

Epoch: 8| Step: 0
Training loss: 3.793349027633667
Validation loss: 4.057058980388026

Epoch: 6| Step: 1
Training loss: 4.470656394958496
Validation loss: 4.054842100348524

Epoch: 6| Step: 2
Training loss: 3.995912551879883
Validation loss: 4.05009647082257

Epoch: 6| Step: 3
Training loss: 2.880216360092163
Validation loss: 4.045645370278307

Epoch: 6| Step: 4
Training loss: 4.582255840301514
Validation loss: 4.0433158746329685

Epoch: 6| Step: 5
Training loss: 2.9472522735595703
Validation loss: 4.037196774636546

Epoch: 6| Step: 6
Training loss: 3.304290533065796
Validation loss: 4.033349111515989

Epoch: 6| Step: 7
Training loss: 2.864671230316162
Validation loss: 4.028542436579222

Epoch: 6| Step: 8
Training loss: 4.237334251403809
Validation loss: 4.02494344916395

Epoch: 6| Step: 9
Training loss: 4.449782371520996
Validation loss: 4.021950126976095

Epoch: 6| Step: 10
Training loss: 4.589291572570801
Validation loss: 4.016568065971456

Epoch: 6| Step: 11
Training loss: 3.7965338230133057
Validation loss: 4.013430641543481

Epoch: 6| Step: 12
Training loss: 4.408267498016357
Validation loss: 4.006447507489112

Epoch: 6| Step: 13
Training loss: 3.9695515632629395
Validation loss: 4.005358257601338

Epoch: 9| Step: 0
Training loss: 5.0140790939331055
Validation loss: 4.000121316602153

Epoch: 6| Step: 1
Training loss: 4.183266639709473
Validation loss: 3.9925763043024207

Epoch: 6| Step: 2
Training loss: 4.444983959197998
Validation loss: 3.9926775706711637

Epoch: 6| Step: 3
Training loss: 3.9411017894744873
Validation loss: 3.988936142254901

Epoch: 6| Step: 4
Training loss: 3.9392948150634766
Validation loss: 3.9838547732240412

Epoch: 6| Step: 5
Training loss: 3.310392141342163
Validation loss: 3.9790435760251937

Epoch: 6| Step: 6
Training loss: 4.439947605133057
Validation loss: 3.9725158470933155

Epoch: 6| Step: 7
Training loss: 2.778491497039795
Validation loss: 3.9701259033654326

Epoch: 6| Step: 8
Training loss: 2.5259132385253906
Validation loss: 3.962033789644959

Epoch: 6| Step: 9
Training loss: 4.877731800079346
Validation loss: 3.963012772221719

Epoch: 6| Step: 10
Training loss: 3.1389148235321045
Validation loss: 3.954804056434221

Epoch: 6| Step: 11
Training loss: 3.370208978652954
Validation loss: 3.9514305078855125

Epoch: 6| Step: 12
Training loss: 4.472931861877441
Validation loss: 3.948061430326072

Epoch: 6| Step: 13
Training loss: 2.5321035385131836
Validation loss: 3.9408313715329735

Epoch: 10| Step: 0
Training loss: 3.664010524749756
Validation loss: 3.936177404977942

Epoch: 6| Step: 1
Training loss: 4.550602912902832
Validation loss: 3.935302770265969

Epoch: 6| Step: 2
Training loss: 5.515313148498535
Validation loss: 3.9263303869514057

Epoch: 6| Step: 3
Training loss: 2.978616714477539
Validation loss: 3.919361888721425

Epoch: 6| Step: 4
Training loss: 2.9329752922058105
Validation loss: 3.922163386498728

Epoch: 6| Step: 5
Training loss: 4.599917411804199
Validation loss: 3.918537155274422

Epoch: 6| Step: 6
Training loss: 4.506182670593262
Validation loss: 3.9061194466006373

Epoch: 6| Step: 7
Training loss: 2.8098063468933105
Validation loss: 3.8960066687676216

Epoch: 6| Step: 8
Training loss: 3.4249603748321533
Validation loss: 3.8982786722080682

Epoch: 6| Step: 9
Training loss: 3.0201632976531982
Validation loss: 3.892295140092091

Epoch: 6| Step: 10
Training loss: 2.8875279426574707
Validation loss: 3.884173482976934

Epoch: 6| Step: 11
Training loss: 3.770280599594116
Validation loss: 3.8781493094659623

Epoch: 6| Step: 12
Training loss: 5.074850082397461
Validation loss: 3.8695754979246404

Epoch: 6| Step: 13
Training loss: 2.3949923515319824
Validation loss: 3.868933549491308

Epoch: 11| Step: 0
Training loss: 2.4883012771606445
Validation loss: 3.863990012035575

Epoch: 6| Step: 1
Training loss: 2.6377437114715576
Validation loss: 3.859556721102807

Epoch: 6| Step: 2
Training loss: 5.029328346252441
Validation loss: 3.8525276235354844

Epoch: 6| Step: 3
Training loss: 5.289557456970215
Validation loss: 3.8555590055322133

Epoch: 6| Step: 4
Training loss: 2.9200384616851807
Validation loss: 3.840975089739728

Epoch: 6| Step: 5
Training loss: 3.455897808074951
Validation loss: 3.8377882280657367

Epoch: 6| Step: 6
Training loss: 1.718973159790039
Validation loss: 3.8277447608209427

Epoch: 6| Step: 7
Training loss: 4.599275588989258
Validation loss: 3.826012175570252

Epoch: 6| Step: 8
Training loss: 4.972081661224365
Validation loss: 3.8172857120472896

Epoch: 6| Step: 9
Training loss: 4.064725875854492
Validation loss: 3.811135635581068

Epoch: 6| Step: 10
Training loss: 3.477570056915283
Validation loss: 3.8056140715076077

Epoch: 6| Step: 11
Training loss: 3.958073139190674
Validation loss: 3.8066902468281407

Epoch: 6| Step: 12
Training loss: 4.111114501953125
Validation loss: 3.7955774184196227

Epoch: 6| Step: 13
Training loss: 2.6487674713134766
Validation loss: 3.786902860928607

Epoch: 12| Step: 0
Training loss: 3.4379796981811523
Validation loss: 3.783987065797211

Epoch: 6| Step: 1
Training loss: 3.980225086212158
Validation loss: 3.7758439484462945

Epoch: 6| Step: 2
Training loss: 3.9231297969818115
Validation loss: 3.774494012196859

Epoch: 6| Step: 3
Training loss: 3.6340644359588623
Validation loss: 3.7631102736278246

Epoch: 6| Step: 4
Training loss: 3.8617565631866455
Validation loss: 3.761320291026946

Epoch: 6| Step: 5
Training loss: 3.664848804473877
Validation loss: 3.7516221871940036

Epoch: 6| Step: 6
Training loss: 4.135821342468262
Validation loss: 3.743110238864858

Epoch: 6| Step: 7
Training loss: 2.8702149391174316
Validation loss: 3.737401500824959

Epoch: 6| Step: 8
Training loss: 4.310465335845947
Validation loss: 3.731020035282258

Epoch: 6| Step: 9
Training loss: 4.2826995849609375
Validation loss: 3.7292928388041835

Epoch: 6| Step: 10
Training loss: 2.7908029556274414
Validation loss: 3.716591755549113

Epoch: 6| Step: 11
Training loss: 3.488034725189209
Validation loss: 3.7108240691564416

Epoch: 6| Step: 12
Training loss: 3.027832508087158
Validation loss: 3.699393051926808

Epoch: 6| Step: 13
Training loss: 3.3032445907592773
Validation loss: 3.6978871745447957

Epoch: 13| Step: 0
Training loss: 2.8782639503479004
Validation loss: 3.6872463175045547

Epoch: 6| Step: 1
Training loss: 3.0497069358825684
Validation loss: 3.686915200243714

Epoch: 6| Step: 2
Training loss: 3.4681527614593506
Validation loss: 3.672943410053048

Epoch: 6| Step: 3
Training loss: 4.375407695770264
Validation loss: 3.668537555202361

Epoch: 6| Step: 4
Training loss: 3.4202537536621094
Validation loss: 3.6623271306355796

Epoch: 6| Step: 5
Training loss: 4.42251443862915
Validation loss: 3.658581354284799

Epoch: 6| Step: 6
Training loss: 2.727451801300049
Validation loss: 3.6443549843244654

Epoch: 6| Step: 7
Training loss: 2.7971136569976807
Validation loss: 3.6295843483299337

Epoch: 6| Step: 8
Training loss: 4.2042036056518555
Validation loss: 3.635481806211574

Epoch: 6| Step: 9
Training loss: 2.581395149230957
Validation loss: 3.6205627277333248

Epoch: 6| Step: 10
Training loss: 3.1812286376953125
Validation loss: 3.6094498224155878

Epoch: 6| Step: 11
Training loss: 3.8245949745178223
Validation loss: 3.610305445168608

Epoch: 6| Step: 12
Training loss: 4.553160190582275
Validation loss: 3.596379044235394

Epoch: 6| Step: 13
Training loss: 4.391757011413574
Validation loss: 3.5912546239873415

Epoch: 14| Step: 0
Training loss: 4.42399787902832
Validation loss: 3.5766987569870485

Epoch: 6| Step: 1
Training loss: 3.541077136993408
Validation loss: 3.5752683352398615

Epoch: 6| Step: 2
Training loss: 3.6144232749938965
Validation loss: 3.5642505461169827

Epoch: 6| Step: 3
Training loss: 3.8170223236083984
Validation loss: 3.5492446217485654

Epoch: 6| Step: 4
Training loss: 3.1371889114379883
Validation loss: 3.5533337413623767

Epoch: 6| Step: 5
Training loss: 3.818929672241211
Validation loss: 3.5385975299342984

Epoch: 6| Step: 6
Training loss: 2.2256436347961426
Validation loss: 3.5282031207956295

Epoch: 6| Step: 7
Training loss: 3.903949022293091
Validation loss: 3.512967909536054

Epoch: 6| Step: 8
Training loss: 3.124105930328369
Validation loss: 3.504293875027728

Epoch: 6| Step: 9
Training loss: 4.132267951965332
Validation loss: 3.492473881731751

Epoch: 6| Step: 10
Training loss: 3.4853463172912598
Validation loss: 3.487460982414984

Epoch: 6| Step: 11
Training loss: 4.008106231689453
Validation loss: 3.471733829026581

Epoch: 6| Step: 12
Training loss: 1.8867101669311523
Validation loss: 3.4541254017942693

Epoch: 6| Step: 13
Training loss: 2.561790943145752
Validation loss: 3.4464614596418155

Epoch: 15| Step: 0
Training loss: 2.4873478412628174
Validation loss: 3.44305020506664

Epoch: 6| Step: 1
Training loss: 3.281114101409912
Validation loss: 3.4316367949208906

Epoch: 6| Step: 2
Training loss: 3.5702104568481445
Validation loss: 3.4099432088995494

Epoch: 6| Step: 3
Training loss: 3.1771836280822754
Validation loss: 3.407282962593981

Epoch: 6| Step: 4
Training loss: 3.2203807830810547
Validation loss: 3.3936331707944154

Epoch: 6| Step: 5
Training loss: 3.7781965732574463
Validation loss: 3.390952892200921

Epoch: 6| Step: 6
Training loss: 4.363490104675293
Validation loss: 3.374513969626478

Epoch: 6| Step: 7
Training loss: 3.169544219970703
Validation loss: 3.36162321541899

Epoch: 6| Step: 8
Training loss: 3.608649730682373
Validation loss: 3.346849064673147

Epoch: 6| Step: 9
Training loss: 3.1002655029296875
Validation loss: 3.3228745896329164

Epoch: 6| Step: 10
Training loss: 3.227297306060791
Validation loss: 3.306932210922241

Epoch: 6| Step: 11
Training loss: 3.0173697471618652
Validation loss: 3.2949165323729157

Epoch: 6| Step: 12
Training loss: 2.739480972290039
Validation loss: 3.2814324337949037

Epoch: 6| Step: 13
Training loss: 3.9063873291015625
Validation loss: 3.2916463369964273

Epoch: 16| Step: 0
Training loss: 4.057941913604736
Validation loss: 3.2669507585546023

Epoch: 6| Step: 1
Training loss: 3.191333770751953
Validation loss: 3.2493393190445437

Epoch: 6| Step: 2
Training loss: 2.310077667236328
Validation loss: 3.2380513785987772

Epoch: 6| Step: 3
Training loss: 4.301692962646484
Validation loss: 3.227818412165488

Epoch: 6| Step: 4
Training loss: 2.482459545135498
Validation loss: 3.2243747967545704

Epoch: 6| Step: 5
Training loss: 3.2236926555633545
Validation loss: 3.207737535558721

Epoch: 6| Step: 6
Training loss: 3.5859084129333496
Validation loss: 3.200309835454469

Epoch: 6| Step: 7
Training loss: 2.721048355102539
Validation loss: 3.1834313997658352

Epoch: 6| Step: 8
Training loss: 3.8510398864746094
Validation loss: 3.1563117709211124

Epoch: 6| Step: 9
Training loss: 3.7359726428985596
Validation loss: 3.150160635671308

Epoch: 6| Step: 10
Training loss: 2.7129714488983154
Validation loss: 3.1391371809026247

Epoch: 6| Step: 11
Training loss: 3.2426908016204834
Validation loss: 3.1070351651919785

Epoch: 6| Step: 12
Training loss: 2.510596752166748
Validation loss: 3.100295602634389

Epoch: 6| Step: 13
Training loss: 1.704277753829956
Validation loss: 3.0983218787818827

Epoch: 17| Step: 0
Training loss: 2.6086676120758057
Validation loss: 3.086058283364901

Epoch: 6| Step: 1
Training loss: 2.9702389240264893
Validation loss: 3.0724348227183023

Epoch: 6| Step: 2
Training loss: 3.328014850616455
Validation loss: 3.070534401042487

Epoch: 6| Step: 3
Training loss: 2.8119869232177734
Validation loss: 3.0194336522010063

Epoch: 6| Step: 4
Training loss: 3.1457419395446777
Validation loss: 3.029128287428169

Epoch: 6| Step: 5
Training loss: 3.0246870517730713
Validation loss: 2.997139302633142

Epoch: 6| Step: 6
Training loss: 2.5786991119384766
Validation loss: 2.990071476146739

Epoch: 6| Step: 7
Training loss: 2.7712955474853516
Validation loss: 2.9783048322123866

Epoch: 6| Step: 8
Training loss: 3.703237771987915
Validation loss: 2.96056104219088

Epoch: 6| Step: 9
Training loss: 2.917180061340332
Validation loss: 2.936937152698476

Epoch: 6| Step: 10
Training loss: 2.5373642444610596
Validation loss: 2.9315295809058735

Epoch: 6| Step: 11
Training loss: 3.5678091049194336
Validation loss: 2.9125925315323697

Epoch: 6| Step: 12
Training loss: 3.793571949005127
Validation loss: 2.899175464466054

Epoch: 6| Step: 13
Training loss: 2.76867413520813
Validation loss: 2.8843134654465543

Epoch: 18| Step: 0
Training loss: 3.457771062850952
Validation loss: 2.863672528215634

Epoch: 6| Step: 1
Training loss: 2.6790244579315186
Validation loss: 2.85357153672044

Epoch: 6| Step: 2
Training loss: 3.6567001342773438
Validation loss: 2.8529679647056003

Epoch: 6| Step: 3
Training loss: 2.718874454498291
Validation loss: 2.84282273374578

Epoch: 6| Step: 4
Training loss: 2.5615830421447754
Validation loss: 2.834066173081757

Epoch: 6| Step: 5
Training loss: 2.91141414642334
Validation loss: 2.8032270785300963

Epoch: 6| Step: 6
Training loss: 3.057575225830078
Validation loss: 2.7910319938454577

Epoch: 6| Step: 7
Training loss: 2.200178623199463
Validation loss: 2.791098117828369

Epoch: 6| Step: 8
Training loss: 2.727749824523926
Validation loss: 2.762046698601015

Epoch: 6| Step: 9
Training loss: 2.688293933868408
Validation loss: 2.7504606734039965

Epoch: 6| Step: 10
Training loss: 2.1503353118896484
Validation loss: 2.742933896280104

Epoch: 6| Step: 11
Training loss: 3.3839735984802246
Validation loss: 2.7391319274902344

Epoch: 6| Step: 12
Training loss: 3.665043354034424
Validation loss: 2.732885758082072

Epoch: 6| Step: 13
Training loss: 3.1174659729003906
Validation loss: 2.7042232098117953

Epoch: 19| Step: 0
Training loss: 2.8176279067993164
Validation loss: 2.6893554708009124

Epoch: 6| Step: 1
Training loss: 3.245208978652954
Validation loss: 2.7105214390703427

Epoch: 6| Step: 2
Training loss: 2.942582130432129
Validation loss: 2.672349881100398

Epoch: 6| Step: 3
Training loss: 3.7009079456329346
Validation loss: 2.6466853413530576

Epoch: 6| Step: 4
Training loss: 2.260134696960449
Validation loss: 2.6297421993747836

Epoch: 6| Step: 5
Training loss: 2.7368528842926025
Validation loss: 2.6189535920337965

Epoch: 6| Step: 6
Training loss: 2.8493802547454834
Validation loss: 2.6070898297012493

Epoch: 6| Step: 7
Training loss: 3.8446364402770996
Validation loss: 2.5947423083807832

Epoch: 6| Step: 8
Training loss: 2.326122760772705
Validation loss: 2.6096986621938725

Epoch: 6| Step: 9
Training loss: 2.4935340881347656
Validation loss: 2.581612471611269

Epoch: 6| Step: 10
Training loss: 2.4913527965545654
Validation loss: 2.564496906854773

Epoch: 6| Step: 11
Training loss: 3.0437231063842773
Validation loss: 2.5370563409661733

Epoch: 6| Step: 12
Training loss: 2.228522539138794
Validation loss: 2.5549328122087704

Epoch: 6| Step: 13
Training loss: 2.0259783267974854
Validation loss: 2.5292700926462808

Epoch: 20| Step: 0
Training loss: 1.872133493423462
Validation loss: 2.5019137346616356

Epoch: 6| Step: 1
Training loss: 2.8758010864257812
Validation loss: 2.49896421740132

Epoch: 6| Step: 2
Training loss: 2.4651052951812744
Validation loss: 2.4669112313178276

Epoch: 6| Step: 3
Training loss: 3.1572232246398926
Validation loss: 2.4452247337628434

Epoch: 6| Step: 4
Training loss: 2.8013417720794678
Validation loss: 2.50143999438132

Epoch: 6| Step: 5
Training loss: 2.4009337425231934
Validation loss: 2.4460053520817913

Epoch: 6| Step: 6
Training loss: 1.7677836418151855
Validation loss: 2.452953887242143

Epoch: 6| Step: 7
Training loss: 2.5958735942840576
Validation loss: 2.432981075779084

Epoch: 6| Step: 8
Training loss: 3.0535552501678467
Validation loss: 2.4272670925304456

Epoch: 6| Step: 9
Training loss: 3.335287094116211
Validation loss: 2.4206476826821604

Epoch: 6| Step: 10
Training loss: 3.151343822479248
Validation loss: 2.438075852650468

Epoch: 6| Step: 11
Training loss: 3.086000442504883
Validation loss: 2.416235903257965

Epoch: 6| Step: 12
Training loss: 2.1492433547973633
Validation loss: 2.3883177285553305

Epoch: 6| Step: 13
Training loss: 3.1338207721710205
Validation loss: 2.3971029302125335

Epoch: 21| Step: 0
Training loss: 2.8196492195129395
Validation loss: 2.3493367959094305

Epoch: 6| Step: 1
Training loss: 2.33711576461792
Validation loss: 2.3651447860143517

Epoch: 6| Step: 2
Training loss: 2.8882904052734375
Validation loss: 2.3693364025444112

Epoch: 6| Step: 3
Training loss: 3.128997802734375
Validation loss: 2.33402168878945

Epoch: 6| Step: 4
Training loss: 2.7067325115203857
Validation loss: 2.365218388136997

Epoch: 6| Step: 5
Training loss: 3.136683225631714
Validation loss: 2.321357996233048

Epoch: 6| Step: 6
Training loss: 2.4604368209838867
Validation loss: 2.322761825335923

Epoch: 6| Step: 7
Training loss: 3.1362452507019043
Validation loss: 2.3295948556674424

Epoch: 6| Step: 8
Training loss: 1.811483383178711
Validation loss: 2.3104711912011586

Epoch: 6| Step: 9
Training loss: 2.4667930603027344
Validation loss: 2.27632713061507

Epoch: 6| Step: 10
Training loss: 2.7869608402252197
Validation loss: 2.3013742918609292

Epoch: 6| Step: 11
Training loss: 2.2947397232055664
Validation loss: 2.2800316297879784

Epoch: 6| Step: 12
Training loss: 2.39102840423584
Validation loss: 2.295060693576772

Epoch: 6| Step: 13
Training loss: 2.8096399307250977
Validation loss: 2.3116127419215378

Epoch: 22| Step: 0
Training loss: 2.9484245777130127
Validation loss: 2.2568807781383557

Epoch: 6| Step: 1
Training loss: 2.4329071044921875
Validation loss: 2.270511434924218

Epoch: 6| Step: 2
Training loss: 2.723651647567749
Validation loss: 2.263020623114801

Epoch: 6| Step: 3
Training loss: 2.9885711669921875
Validation loss: 2.2452948298505557

Epoch: 6| Step: 4
Training loss: 2.5492000579833984
Validation loss: 2.250000238418579

Epoch: 6| Step: 5
Training loss: 2.575826644897461
Validation loss: 2.244381932802098

Epoch: 6| Step: 6
Training loss: 1.986877202987671
Validation loss: 2.223239847408828

Epoch: 6| Step: 7
Training loss: 3.007340908050537
Validation loss: 2.206960722964297

Epoch: 6| Step: 8
Training loss: 2.149693250656128
Validation loss: 2.2023972913783085

Epoch: 6| Step: 9
Training loss: 2.4684267044067383
Validation loss: 2.243640479221139

Epoch: 6| Step: 10
Training loss: 2.9544808864593506
Validation loss: 2.2380337740785334

Epoch: 6| Step: 11
Training loss: 2.6339974403381348
Validation loss: 2.2226721138082524

Epoch: 6| Step: 12
Training loss: 2.1056103706359863
Validation loss: 2.2267334358666533

Epoch: 6| Step: 13
Training loss: 2.923933982849121
Validation loss: 2.2164383011479534

Epoch: 23| Step: 0
Training loss: 2.802302837371826
Validation loss: 2.2255228873222106

Epoch: 6| Step: 1
Training loss: 2.909109592437744
Validation loss: 2.212515413120229

Epoch: 6| Step: 2
Training loss: 2.528517007827759
Validation loss: 2.2192621807898245

Epoch: 6| Step: 3
Training loss: 2.626467227935791
Validation loss: 2.2170048324010705

Epoch: 6| Step: 4
Training loss: 2.440502166748047
Validation loss: 2.2155855163451164

Epoch: 6| Step: 5
Training loss: 3.0431909561157227
Validation loss: 2.170797066021991

Epoch: 6| Step: 6
Training loss: 2.318389415740967
Validation loss: 2.194435816939159

Epoch: 6| Step: 7
Training loss: 2.2507543563842773
Validation loss: 2.1992836844536567

Epoch: 6| Step: 8
Training loss: 1.9942127466201782
Validation loss: 2.196780389355075

Epoch: 6| Step: 9
Training loss: 3.135455846786499
Validation loss: 2.1851117405840146

Epoch: 6| Step: 10
Training loss: 3.0530335903167725
Validation loss: 2.192597878876553

Epoch: 6| Step: 11
Training loss: 2.792910575866699
Validation loss: 2.2194267408822173

Epoch: 6| Step: 12
Training loss: 1.793344259262085
Validation loss: 2.1771336268353205

Epoch: 6| Step: 13
Training loss: 2.2219491004943848
Validation loss: 2.1966396788115143

Epoch: 24| Step: 0
Training loss: 2.1697778701782227
Validation loss: 2.1929713987535044

Epoch: 6| Step: 1
Training loss: 2.1828622817993164
Validation loss: 2.170269376488142

Epoch: 6| Step: 2
Training loss: 3.0847020149230957
Validation loss: 2.1959839687552503

Epoch: 6| Step: 3
Training loss: 2.398104667663574
Validation loss: 2.21016191410762

Epoch: 6| Step: 4
Training loss: 2.5335710048675537
Validation loss: 2.176575045431814

Epoch: 6| Step: 5
Training loss: 2.7114038467407227
Validation loss: 2.1553185601388254

Epoch: 6| Step: 6
Training loss: 3.4218814373016357
Validation loss: 2.1820608082637993

Epoch: 6| Step: 7
Training loss: 2.6568024158477783
Validation loss: 2.1733578994709957

Epoch: 6| Step: 8
Training loss: 2.3397839069366455
Validation loss: 2.2053741485841813

Epoch: 6| Step: 9
Training loss: 3.229440689086914
Validation loss: 2.194240995632705

Epoch: 6| Step: 10
Training loss: 2.24273419380188
Validation loss: 2.1701721324715564

Epoch: 6| Step: 11
Training loss: 2.5689401626586914
Validation loss: 2.1622381235963557

Epoch: 6| Step: 12
Training loss: 1.4442709684371948
Validation loss: 2.173050381804025

Epoch: 6| Step: 13
Training loss: 3.3114213943481445
Validation loss: 2.154289077687007

Epoch: 25| Step: 0
Training loss: 2.879500150680542
Validation loss: 2.180288727565478

Epoch: 6| Step: 1
Training loss: 3.035409450531006
Validation loss: 2.1801632091563237

Epoch: 6| Step: 2
Training loss: 2.076542615890503
Validation loss: 2.1712846730345037

Epoch: 6| Step: 3
Training loss: 2.989043712615967
Validation loss: 2.190562848121889

Epoch: 6| Step: 4
Training loss: 2.190403461456299
Validation loss: 2.1700305746447657

Epoch: 6| Step: 5
Training loss: 2.430644989013672
Validation loss: 2.1604940224719305

Epoch: 6| Step: 6
Training loss: 2.1401431560516357
Validation loss: 2.1792560290264826

Epoch: 6| Step: 7
Training loss: 2.738642692565918
Validation loss: 2.2108137735756497

Epoch: 6| Step: 8
Training loss: 2.3355798721313477
Validation loss: 2.193699621385144

Epoch: 6| Step: 9
Training loss: 2.3177130222320557
Validation loss: 2.158833775469052

Epoch: 6| Step: 10
Training loss: 2.9698705673217773
Validation loss: 2.2041700578504995

Epoch: 6| Step: 11
Training loss: 2.062904119491577
Validation loss: 2.166831124213434

Epoch: 6| Step: 12
Training loss: 2.8950371742248535
Validation loss: 2.1789673400181595

Epoch: 6| Step: 13
Training loss: 2.7309253215789795
Validation loss: 2.1954747297430552

Epoch: 26| Step: 0
Training loss: 2.447737216949463
Validation loss: 2.1836526701527257

Epoch: 6| Step: 1
Training loss: 3.0005393028259277
Validation loss: 2.1806705997836207

Epoch: 6| Step: 2
Training loss: 2.7878310680389404
Validation loss: 2.1823172030910367

Epoch: 6| Step: 3
Training loss: 2.076561212539673
Validation loss: 2.1683840264556227

Epoch: 6| Step: 4
Training loss: 2.5831551551818848
Validation loss: 2.159855238852962

Epoch: 6| Step: 5
Training loss: 2.1883275508880615
Validation loss: 2.167498565489246

Epoch: 6| Step: 6
Training loss: 2.7716007232666016
Validation loss: 2.1656413437217794

Epoch: 6| Step: 7
Training loss: 2.2504723072052
Validation loss: 2.2076305984168925

Epoch: 6| Step: 8
Training loss: 2.5834193229675293
Validation loss: 2.214308939954286

Epoch: 6| Step: 9
Training loss: 2.510169267654419
Validation loss: 2.17487185488465

Epoch: 6| Step: 10
Training loss: 2.245762825012207
Validation loss: 2.146109841203177

Epoch: 6| Step: 11
Training loss: 3.3164103031158447
Validation loss: 2.2112627234510196

Epoch: 6| Step: 12
Training loss: 2.443758010864258
Validation loss: 2.185314319467032

Epoch: 6| Step: 13
Training loss: 2.4969873428344727
Validation loss: 2.208965988569362

Epoch: 27| Step: 0
Training loss: 2.110485076904297
Validation loss: 2.181796009822558

Epoch: 6| Step: 1
Training loss: 1.7352458238601685
Validation loss: 2.190009911855062

Epoch: 6| Step: 2
Training loss: 2.6278131008148193
Validation loss: 2.179881198431856

Epoch: 6| Step: 3
Training loss: 2.715822219848633
Validation loss: 2.202459950600901

Epoch: 6| Step: 4
Training loss: 2.861456871032715
Validation loss: 2.166803793240619

Epoch: 6| Step: 5
Training loss: 2.325172185897827
Validation loss: 2.1810921699770036

Epoch: 6| Step: 6
Training loss: 2.1912662982940674
Validation loss: 2.1885860120096514

Epoch: 6| Step: 7
Training loss: 1.7861077785491943
Validation loss: 2.1731529056384997

Epoch: 6| Step: 8
Training loss: 2.9687931537628174
Validation loss: 2.159396322824622

Epoch: 6| Step: 9
Training loss: 3.2379534244537354
Validation loss: 2.146252412949839

Epoch: 6| Step: 10
Training loss: 2.451303720474243
Validation loss: 2.16727440972482

Epoch: 6| Step: 11
Training loss: 2.760547399520874
Validation loss: 2.173677973849799

Epoch: 6| Step: 12
Training loss: 2.8348915576934814
Validation loss: 2.1475156020092707

Epoch: 6| Step: 13
Training loss: 3.3806354999542236
Validation loss: 2.1744927090983235

Epoch: 28| Step: 0
Training loss: 2.04121994972229
Validation loss: 2.1655919269848893

Epoch: 6| Step: 1
Training loss: 2.931252956390381
Validation loss: 2.170562971022821

Epoch: 6| Step: 2
Training loss: 2.515045642852783
Validation loss: 2.181914652547529

Epoch: 6| Step: 3
Training loss: 3.263662338256836
Validation loss: 2.1941090117218676

Epoch: 6| Step: 4
Training loss: 2.1843395233154297
Validation loss: 2.160772413335821

Epoch: 6| Step: 5
Training loss: 2.1881637573242188
Validation loss: 2.144697919968636

Epoch: 6| Step: 6
Training loss: 2.6716575622558594
Validation loss: 2.17486297956077

Epoch: 6| Step: 7
Training loss: 3.0615553855895996
Validation loss: 2.173498643341885

Epoch: 6| Step: 8
Training loss: 2.1129744052886963
Validation loss: 2.1186899715854275

Epoch: 6| Step: 9
Training loss: 2.7123749256134033
Validation loss: 2.1751572047510455

Epoch: 6| Step: 10
Training loss: 1.9151020050048828
Validation loss: 2.1828396422888643

Epoch: 6| Step: 11
Training loss: 2.93607234954834
Validation loss: 2.1378932563207482

Epoch: 6| Step: 12
Training loss: 3.10121750831604
Validation loss: 2.1609514708160074

Epoch: 6| Step: 13
Training loss: 1.7316076755523682
Validation loss: 2.143724336419054

Epoch: 29| Step: 0
Training loss: 2.206094264984131
Validation loss: 2.183300719466261

Epoch: 6| Step: 1
Training loss: 2.2922184467315674
Validation loss: 2.1762845195749754

Epoch: 6| Step: 2
Training loss: 3.159654140472412
Validation loss: 2.10866968606108

Epoch: 6| Step: 3
Training loss: 2.4565443992614746
Validation loss: 2.176137770375898

Epoch: 6| Step: 4
Training loss: 2.590057373046875
Validation loss: 2.1677502509086364

Epoch: 6| Step: 5
Training loss: 2.753401756286621
Validation loss: 2.1718849417983845

Epoch: 6| Step: 6
Training loss: 2.8527421951293945
Validation loss: 2.176466275286931

Epoch: 6| Step: 7
Training loss: 1.8775438070297241
Validation loss: 2.1805901847859865

Epoch: 6| Step: 8
Training loss: 2.2673163414001465
Validation loss: 2.1570732132081063

Epoch: 6| Step: 9
Training loss: 2.0181636810302734
Validation loss: 2.182186679173541

Epoch: 6| Step: 10
Training loss: 2.9151997566223145
Validation loss: 2.1776826509865383

Epoch: 6| Step: 11
Training loss: 2.611626625061035
Validation loss: 2.15246481280173

Epoch: 6| Step: 12
Training loss: 3.0669827461242676
Validation loss: 2.1355665627346245

Epoch: 6| Step: 13
Training loss: 2.67423939704895
Validation loss: 2.188091201166953

Epoch: 30| Step: 0
Training loss: 2.225870132446289
Validation loss: 2.162048967935706

Epoch: 6| Step: 1
Training loss: 2.202113628387451
Validation loss: 2.157856325949392

Epoch: 6| Step: 2
Training loss: 2.945523262023926
Validation loss: 2.150973017497729

Epoch: 6| Step: 3
Training loss: 2.5578808784484863
Validation loss: 2.1477572520573935

Epoch: 6| Step: 4
Training loss: 3.070716381072998
Validation loss: 2.1629488980898293

Epoch: 6| Step: 5
Training loss: 3.13584566116333
Validation loss: 2.1665914109958115

Epoch: 6| Step: 6
Training loss: 2.5198895931243896
Validation loss: 2.1429444436104066

Epoch: 6| Step: 7
Training loss: 2.2943947315216064
Validation loss: 2.153825016431911

Epoch: 6| Step: 8
Training loss: 2.0645127296447754
Validation loss: 2.1539873846115603

Epoch: 6| Step: 9
Training loss: 2.073350667953491
Validation loss: 2.137754140361663

Epoch: 6| Step: 10
Training loss: 2.5705933570861816
Validation loss: 2.126910627529185

Epoch: 6| Step: 11
Training loss: 3.1474673748016357
Validation loss: 2.164422763291226

Epoch: 6| Step: 12
Training loss: 2.3311660289764404
Validation loss: 2.153249438090991

Epoch: 6| Step: 13
Training loss: 2.6112780570983887
Validation loss: 2.179695631868096

Epoch: 31| Step: 0
Training loss: 2.8882534503936768
Validation loss: 2.1586087493486303

Epoch: 6| Step: 1
Training loss: 2.7857794761657715
Validation loss: 2.161869110599641

Epoch: 6| Step: 2
Training loss: 2.1673083305358887
Validation loss: 2.160892863427439

Epoch: 6| Step: 3
Training loss: 2.379477024078369
Validation loss: 2.149522501935241

Epoch: 6| Step: 4
Training loss: 2.4993090629577637
Validation loss: 2.1590056573190997

Epoch: 6| Step: 5
Training loss: 3.1048953533172607
Validation loss: 2.1488790691539807

Epoch: 6| Step: 6
Training loss: 2.9180614948272705
Validation loss: 2.1722540573407243

Epoch: 6| Step: 7
Training loss: 2.91321063041687
Validation loss: 2.1169023103611444

Epoch: 6| Step: 8
Training loss: 2.6589417457580566
Validation loss: 2.136690261543438

Epoch: 6| Step: 9
Training loss: 2.3442764282226562
Validation loss: 2.1485260686566754

Epoch: 6| Step: 10
Training loss: 1.8680915832519531
Validation loss: 2.116453396376743

Epoch: 6| Step: 11
Training loss: 2.3080801963806152
Validation loss: 2.1623969924065376

Epoch: 6| Step: 12
Training loss: 2.434657573699951
Validation loss: 2.157665962814003

Epoch: 6| Step: 13
Training loss: 2.186323881149292
Validation loss: 2.152659582835372

Epoch: 32| Step: 0
Training loss: 2.429476737976074
Validation loss: 2.1620107440538305

Epoch: 6| Step: 1
Training loss: 2.9863088130950928
Validation loss: 2.1483560377551663

Epoch: 6| Step: 2
Training loss: 2.667935371398926
Validation loss: 2.178655755135321

Epoch: 6| Step: 3
Training loss: 2.3057639598846436
Validation loss: 2.14919138211076

Epoch: 6| Step: 4
Training loss: 2.689854860305786
Validation loss: 2.192003829504854

Epoch: 6| Step: 5
Training loss: 1.840120553970337
Validation loss: 2.1406008940871044

Epoch: 6| Step: 6
Training loss: 2.222458839416504
Validation loss: 2.180576314208328

Epoch: 6| Step: 7
Training loss: 2.901705741882324
Validation loss: 2.1480128726651593

Epoch: 6| Step: 8
Training loss: 2.7635064125061035
Validation loss: 2.1506645833292315

Epoch: 6| Step: 9
Training loss: 2.8428378105163574
Validation loss: 2.163507907621322

Epoch: 6| Step: 10
Training loss: 2.6201906204223633
Validation loss: 2.1710235713630595

Epoch: 6| Step: 11
Training loss: 1.7237377166748047
Validation loss: 2.169775068119008

Epoch: 6| Step: 12
Training loss: 1.932665228843689
Validation loss: 2.174203867553383

Epoch: 6| Step: 13
Training loss: 4.189730644226074
Validation loss: 2.163808020212317

Epoch: 33| Step: 0
Training loss: 3.1665987968444824
Validation loss: 2.1728098738578057

Epoch: 6| Step: 1
Training loss: 2.8435933589935303
Validation loss: 2.1802267900077243

Epoch: 6| Step: 2
Training loss: 2.914444923400879
Validation loss: 2.1594488492576023

Epoch: 6| Step: 3
Training loss: 2.451500177383423
Validation loss: 2.1597837273792555

Epoch: 6| Step: 4
Training loss: 1.886293649673462
Validation loss: 2.168382247289022

Epoch: 6| Step: 5
Training loss: 2.3273134231567383
Validation loss: 2.1853310164584907

Epoch: 6| Step: 6
Training loss: 2.2451510429382324
Validation loss: 2.1590000583279516

Epoch: 6| Step: 7
Training loss: 2.4245474338531494
Validation loss: 2.1627774751314552

Epoch: 6| Step: 8
Training loss: 3.3998613357543945
Validation loss: 2.150185763194997

Epoch: 6| Step: 9
Training loss: 2.9086477756500244
Validation loss: 2.1440439480607227

Epoch: 6| Step: 10
Training loss: 1.9713042974472046
Validation loss: 2.164481270697809

Epoch: 6| Step: 11
Training loss: 2.4553380012512207
Validation loss: 2.144960282951273

Epoch: 6| Step: 12
Training loss: 2.026702404022217
Validation loss: 2.157842836072368

Epoch: 6| Step: 13
Training loss: 2.3987913131713867
Validation loss: 2.144834280014038

Epoch: 34| Step: 0
Training loss: 1.873436689376831
Validation loss: 2.151437364598756

Epoch: 6| Step: 1
Training loss: 2.037954330444336
Validation loss: 2.13736899693807

Epoch: 6| Step: 2
Training loss: 3.471503734588623
Validation loss: 2.1455007137790805

Epoch: 6| Step: 3
Training loss: 2.3067140579223633
Validation loss: 2.141434864331317

Epoch: 6| Step: 4
Training loss: 2.1557235717773438
Validation loss: 2.149414003536265

Epoch: 6| Step: 5
Training loss: 2.994729995727539
Validation loss: 2.1901005826970583

Epoch: 6| Step: 6
Training loss: 2.250382423400879
Validation loss: 2.142497506192935

Epoch: 6| Step: 7
Training loss: 2.612637519836426
Validation loss: 2.164824152505526

Epoch: 6| Step: 8
Training loss: 2.1034345626831055
Validation loss: 2.1588659747954337

Epoch: 6| Step: 9
Training loss: 2.4636595249176025
Validation loss: 2.122685468325051

Epoch: 6| Step: 10
Training loss: 2.7748525142669678
Validation loss: 2.158531435074345

Epoch: 6| Step: 11
Training loss: 2.601877450942993
Validation loss: 2.1730782421686317

Epoch: 6| Step: 12
Training loss: 2.309199094772339
Validation loss: 2.1212450663248696

Epoch: 6| Step: 13
Training loss: 3.9094057083129883
Validation loss: 2.1645792197155695

Epoch: 35| Step: 0
Training loss: 2.519805431365967
Validation loss: 2.143790844948061

Epoch: 6| Step: 1
Training loss: 2.304533004760742
Validation loss: 2.125891588067496

Epoch: 6| Step: 2
Training loss: 2.5290112495422363
Validation loss: 2.1350443158098447

Epoch: 6| Step: 3
Training loss: 2.601254940032959
Validation loss: 2.1354663782222296

Epoch: 6| Step: 4
Training loss: 2.7917532920837402
Validation loss: 2.176065452637211

Epoch: 6| Step: 5
Training loss: 2.180670738220215
Validation loss: 2.1564676146353445

Epoch: 6| Step: 6
Training loss: 2.3755221366882324
Validation loss: 2.139889238983072

Epoch: 6| Step: 7
Training loss: 2.802835464477539
Validation loss: 2.130226214726766

Epoch: 6| Step: 8
Training loss: 2.011296510696411
Validation loss: 2.1412083128447175

Epoch: 6| Step: 9
Training loss: 2.0994274616241455
Validation loss: 2.1329244131683023

Epoch: 6| Step: 10
Training loss: 2.544793128967285
Validation loss: 2.1342046747925463

Epoch: 6| Step: 11
Training loss: 3.277644634246826
Validation loss: 2.1646553906061317

Epoch: 6| Step: 12
Training loss: 2.353057384490967
Validation loss: 2.1287740122887397

Epoch: 6| Step: 13
Training loss: 3.1777966022491455
Validation loss: 2.152091059633481

Epoch: 36| Step: 0
Training loss: 2.431394577026367
Validation loss: 2.119637973846928

Epoch: 6| Step: 1
Training loss: 2.4003705978393555
Validation loss: 2.1631423722031298

Epoch: 6| Step: 2
Training loss: 2.592109203338623
Validation loss: 2.1406781224794287

Epoch: 6| Step: 3
Training loss: 2.2335104942321777
Validation loss: 2.130794873801611

Epoch: 6| Step: 4
Training loss: 2.9207258224487305
Validation loss: 2.170888444428803

Epoch: 6| Step: 5
Training loss: 2.085333824157715
Validation loss: 2.1654578870342625

Epoch: 6| Step: 6
Training loss: 2.4602742195129395
Validation loss: 2.143652385280978

Epoch: 6| Step: 7
Training loss: 2.432415008544922
Validation loss: 2.1722411289009997

Epoch: 6| Step: 8
Training loss: 2.542052984237671
Validation loss: 2.1717178103744343

Epoch: 6| Step: 9
Training loss: 3.2724952697753906
Validation loss: 2.1358327019599175

Epoch: 6| Step: 10
Training loss: 1.693848729133606
Validation loss: 2.1554955436337377

Epoch: 6| Step: 11
Training loss: 2.405214309692383
Validation loss: 2.161433837747061

Epoch: 6| Step: 12
Training loss: 2.6552176475524902
Validation loss: 2.1742630620156564

Epoch: 6| Step: 13
Training loss: 3.2259321212768555
Validation loss: 2.133950007859097

Epoch: 37| Step: 0
Training loss: 2.2775001525878906
Validation loss: 2.1580270695429977

Epoch: 6| Step: 1
Training loss: 2.751152992248535
Validation loss: 2.1549824591605895

Epoch: 6| Step: 2
Training loss: 2.721436023712158
Validation loss: 2.158346168456539

Epoch: 6| Step: 3
Training loss: 3.420578718185425
Validation loss: 2.163490342837508

Epoch: 6| Step: 4
Training loss: 2.1202633380889893
Validation loss: 2.15489028346154

Epoch: 6| Step: 5
Training loss: 2.245035409927368
Validation loss: 2.1855577371453725

Epoch: 6| Step: 6
Training loss: 2.309032678604126
Validation loss: 2.1458986292603197

Epoch: 6| Step: 7
Training loss: 2.7225592136383057
Validation loss: 2.1748546400377826

Epoch: 6| Step: 8
Training loss: 2.177715301513672
Validation loss: 2.179123288841658

Epoch: 6| Step: 9
Training loss: 1.8946725130081177
Validation loss: 2.1635722550012733

Epoch: 6| Step: 10
Training loss: 2.8313612937927246
Validation loss: 2.1581862716264624

Epoch: 6| Step: 11
Training loss: 2.835033655166626
Validation loss: 2.1332780673939693

Epoch: 6| Step: 12
Training loss: 2.720916509628296
Validation loss: 2.1411143143971763

Epoch: 6| Step: 13
Training loss: 1.6672834157943726
Validation loss: 2.1548676106237594

Epoch: 38| Step: 0
Training loss: 2.1767029762268066
Validation loss: 2.1607438184881724

Epoch: 6| Step: 1
Training loss: 2.1449027061462402
Validation loss: 2.1595837852006317

Epoch: 6| Step: 2
Training loss: 2.1300411224365234
Validation loss: 2.1687614712663876

Epoch: 6| Step: 3
Training loss: 2.1377124786376953
Validation loss: 2.134076249214911

Epoch: 6| Step: 4
Training loss: 2.3780388832092285
Validation loss: 2.1571995276276783

Epoch: 6| Step: 5
Training loss: 3.5117650032043457
Validation loss: 2.142897013695009

Epoch: 6| Step: 6
Training loss: 1.8186572790145874
Validation loss: 2.1350641917156916

Epoch: 6| Step: 7
Training loss: 2.792313575744629
Validation loss: 2.13573351470373

Epoch: 6| Step: 8
Training loss: 2.609083652496338
Validation loss: 2.169605983200894

Epoch: 6| Step: 9
Training loss: 2.549720287322998
Validation loss: 2.1780956663111204

Epoch: 6| Step: 10
Training loss: 2.5959625244140625
Validation loss: 2.128047485505381

Epoch: 6| Step: 11
Training loss: 3.1942384243011475
Validation loss: 2.169739870614903

Epoch: 6| Step: 12
Training loss: 2.2594850063323975
Validation loss: 2.158189768432289

Epoch: 6| Step: 13
Training loss: 3.0057575702667236
Validation loss: 2.1660681501511605

Epoch: 39| Step: 0
Training loss: 2.675051689147949
Validation loss: 2.154873533915448

Epoch: 6| Step: 1
Training loss: 2.4669110774993896
Validation loss: 2.143182131551927

Epoch: 6| Step: 2
Training loss: 2.3432860374450684
Validation loss: 2.123707681573847

Epoch: 6| Step: 3
Training loss: 2.7531845569610596
Validation loss: 2.1372245383518997

Epoch: 6| Step: 4
Training loss: 3.1853561401367188
Validation loss: 2.1501693879404375

Epoch: 6| Step: 5
Training loss: 2.48264479637146
Validation loss: 2.1495547448435137

Epoch: 6| Step: 6
Training loss: 2.570415496826172
Validation loss: 2.144345445017661

Epoch: 6| Step: 7
Training loss: 2.323169708251953
Validation loss: 2.138904453605734

Epoch: 6| Step: 8
Training loss: 2.772217273712158
Validation loss: 2.143756845945953

Epoch: 6| Step: 9
Training loss: 2.6735827922821045
Validation loss: 2.1444087951414046

Epoch: 6| Step: 10
Training loss: 2.1453497409820557
Validation loss: 2.170227678873206

Epoch: 6| Step: 11
Training loss: 2.9973721504211426
Validation loss: 2.138226896203974

Epoch: 6| Step: 12
Training loss: 1.4815568923950195
Validation loss: 2.1190828149036696

Epoch: 6| Step: 13
Training loss: 1.7714080810546875
Validation loss: 2.132934908713064

Epoch: 40| Step: 0
Training loss: 1.9258136749267578
Validation loss: 2.1391522064003894

Epoch: 6| Step: 1
Training loss: 3.4032654762268066
Validation loss: 2.120418071746826

Epoch: 6| Step: 2
Training loss: 2.575904130935669
Validation loss: 2.155599494134226

Epoch: 6| Step: 3
Training loss: 2.9687671661376953
Validation loss: 2.113620417092436

Epoch: 6| Step: 4
Training loss: 2.843480110168457
Validation loss: 2.1033956427727976

Epoch: 6| Step: 5
Training loss: 3.2632246017456055
Validation loss: 2.134386980405418

Epoch: 6| Step: 6
Training loss: 2.258159637451172
Validation loss: 2.1485085769366195

Epoch: 6| Step: 7
Training loss: 2.623047351837158
Validation loss: 2.117843912493798

Epoch: 6| Step: 8
Training loss: 2.3236751556396484
Validation loss: 2.1257765511030793

Epoch: 6| Step: 9
Training loss: 2.586698293685913
Validation loss: 2.1305050580732283

Epoch: 6| Step: 10
Training loss: 1.8685894012451172
Validation loss: 2.1371740192495365

Epoch: 6| Step: 11
Training loss: 1.9534807205200195
Validation loss: 2.1415767400495467

Epoch: 6| Step: 12
Training loss: 2.149524688720703
Validation loss: 2.126040591988512

Epoch: 6| Step: 13
Training loss: 1.8967291116714478
Validation loss: 2.1744576897672427

Epoch: 41| Step: 0
Training loss: 2.456678628921509
Validation loss: 2.1697899756893033

Epoch: 6| Step: 1
Training loss: 3.0517330169677734
Validation loss: 2.1352781416267477

Epoch: 6| Step: 2
Training loss: 2.197169780731201
Validation loss: 2.1156968173160347

Epoch: 6| Step: 3
Training loss: 2.4623842239379883
Validation loss: 2.1281158296010827

Epoch: 6| Step: 4
Training loss: 1.7688050270080566
Validation loss: 2.1176400107722126

Epoch: 6| Step: 5
Training loss: 2.877319812774658
Validation loss: 2.1397477862655476

Epoch: 6| Step: 6
Training loss: 3.115985631942749
Validation loss: 2.129510279624693

Epoch: 6| Step: 7
Training loss: 2.377697467803955
Validation loss: 2.1456064434461695

Epoch: 6| Step: 8
Training loss: 2.6363558769226074
Validation loss: 2.1155082884655205

Epoch: 6| Step: 9
Training loss: 1.925047516822815
Validation loss: 2.1138252314700874

Epoch: 6| Step: 10
Training loss: 2.2697596549987793
Validation loss: 2.158006698854508

Epoch: 6| Step: 11
Training loss: 2.574256658554077
Validation loss: 2.1428311409488803

Epoch: 6| Step: 12
Training loss: 2.9255967140197754
Validation loss: 2.17004225074604

Epoch: 6| Step: 13
Training loss: 2.124330520629883
Validation loss: 2.1430094395914385

Epoch: 42| Step: 0
Training loss: 2.9924540519714355
Validation loss: 2.154064856549745

Epoch: 6| Step: 1
Training loss: 2.533719062805176
Validation loss: 2.132413902590352

Epoch: 6| Step: 2
Training loss: 3.020111083984375
Validation loss: 2.1438646803620043

Epoch: 6| Step: 3
Training loss: 2.884394645690918
Validation loss: 2.139623806040774

Epoch: 6| Step: 4
Training loss: 2.4486007690429688
Validation loss: 2.1449481415492233

Epoch: 6| Step: 5
Training loss: 2.270291805267334
Validation loss: 2.124535133761744

Epoch: 6| Step: 6
Training loss: 2.4291763305664062
Validation loss: 2.1363814697470715

Epoch: 6| Step: 7
Training loss: 2.152757406234741
Validation loss: 2.153326580601354

Epoch: 6| Step: 8
Training loss: 2.243297576904297
Validation loss: 2.1349302722561743

Epoch: 6| Step: 9
Training loss: 1.845531702041626
Validation loss: 2.1524166907033613

Epoch: 6| Step: 10
Training loss: 2.804290771484375
Validation loss: 2.1113303374218684

Epoch: 6| Step: 11
Training loss: 2.529541492462158
Validation loss: 2.144075406494961

Epoch: 6| Step: 12
Training loss: 2.605224370956421
Validation loss: 2.1524753852557112

Epoch: 6| Step: 13
Training loss: 1.6450917720794678
Validation loss: 2.1491117297962146

Epoch: 43| Step: 0
Training loss: 2.4490389823913574
Validation loss: 2.1258630470563005

Epoch: 6| Step: 1
Training loss: 2.0689971446990967
Validation loss: 2.178069991450156

Epoch: 6| Step: 2
Training loss: 2.516238212585449
Validation loss: 2.1541169740820445

Epoch: 6| Step: 3
Training loss: 3.3570218086242676
Validation loss: 2.1431678648917907

Epoch: 6| Step: 4
Training loss: 2.242490768432617
Validation loss: 2.134560359421597

Epoch: 6| Step: 5
Training loss: 2.9031410217285156
Validation loss: 2.1054322924665225

Epoch: 6| Step: 6
Training loss: 2.3187994956970215
Validation loss: 2.09089587068045

Epoch: 6| Step: 7
Training loss: 2.300490379333496
Validation loss: 2.139528161735945

Epoch: 6| Step: 8
Training loss: 2.505657196044922
Validation loss: 2.156796460510582

Epoch: 6| Step: 9
Training loss: 2.649106502532959
Validation loss: 2.1207289259920836

Epoch: 6| Step: 10
Training loss: 2.5173258781433105
Validation loss: 2.147067044370918

Epoch: 6| Step: 11
Training loss: 1.9312973022460938
Validation loss: 2.1304962045402935

Epoch: 6| Step: 12
Training loss: 2.4070863723754883
Validation loss: 2.1462956602855394

Epoch: 6| Step: 13
Training loss: 2.6457347869873047
Validation loss: 2.170505310899468

Epoch: 44| Step: 0
Training loss: 2.49326753616333
Validation loss: 2.154924584973243

Epoch: 6| Step: 1
Training loss: 2.799971580505371
Validation loss: 2.1343686760112806

Epoch: 6| Step: 2
Training loss: 1.9935321807861328
Validation loss: 2.1432147846427014

Epoch: 6| Step: 3
Training loss: 2.3561017513275146
Validation loss: 2.117810623620146

Epoch: 6| Step: 4
Training loss: 2.3340978622436523
Validation loss: 2.141647260676148

Epoch: 6| Step: 5
Training loss: 2.432114601135254
Validation loss: 2.141972259808612

Epoch: 6| Step: 6
Training loss: 2.3586606979370117
Validation loss: 2.1386075532564552

Epoch: 6| Step: 7
Training loss: 1.92924165725708
Validation loss: 2.136941179152458

Epoch: 6| Step: 8
Training loss: 2.3314414024353027
Validation loss: 2.1355197762930267

Epoch: 6| Step: 9
Training loss: 2.601736068725586
Validation loss: 2.10845511703081

Epoch: 6| Step: 10
Training loss: 3.3099751472473145
Validation loss: 2.1636287807136454

Epoch: 6| Step: 11
Training loss: 2.5666377544403076
Validation loss: 2.1215851063369424

Epoch: 6| Step: 12
Training loss: 2.5900628566741943
Validation loss: 2.137312827571746

Epoch: 6| Step: 13
Training loss: 2.4217910766601562
Validation loss: 2.1420699524623092

Epoch: 45| Step: 0
Training loss: 2.1914291381835938
Validation loss: 2.135482732967664

Epoch: 6| Step: 1
Training loss: 3.656647205352783
Validation loss: 2.1119638617320726

Epoch: 6| Step: 2
Training loss: 3.089674711227417
Validation loss: 2.133904259691956

Epoch: 6| Step: 3
Training loss: 2.0461771488189697
Validation loss: 2.1505566771312425

Epoch: 6| Step: 4
Training loss: 1.7625079154968262
Validation loss: 2.1608656324366087

Epoch: 6| Step: 5
Training loss: 2.5972886085510254
Validation loss: 2.1433350065703034

Epoch: 6| Step: 6
Training loss: 2.24910306930542
Validation loss: 2.1628399587446645

Epoch: 6| Step: 7
Training loss: 1.5300065279006958
Validation loss: 2.1523482978984876

Epoch: 6| Step: 8
Training loss: 2.1333866119384766
Validation loss: 2.141830890409408

Epoch: 6| Step: 9
Training loss: 2.607593536376953
Validation loss: 2.1319694108860467

Epoch: 6| Step: 10
Training loss: 3.4961764812469482
Validation loss: 2.127657410919025

Epoch: 6| Step: 11
Training loss: 2.540882110595703
Validation loss: 2.1401836487554733

Epoch: 6| Step: 12
Training loss: 2.669729232788086
Validation loss: 2.13475122246691

Epoch: 6| Step: 13
Training loss: 1.9127349853515625
Validation loss: 2.1075961641086045

Epoch: 46| Step: 0
Training loss: 2.8386850357055664
Validation loss: 2.09777166510141

Epoch: 6| Step: 1
Training loss: 2.2402234077453613
Validation loss: 2.103520393371582

Epoch: 6| Step: 2
Training loss: 3.022766590118408
Validation loss: 2.1310224289535196

Epoch: 6| Step: 3
Training loss: 2.403977870941162
Validation loss: 2.1109747861021306

Epoch: 6| Step: 4
Training loss: 2.451556921005249
Validation loss: 2.1053958682603735

Epoch: 6| Step: 5
Training loss: 2.748666286468506
Validation loss: 2.1351275982395297

Epoch: 6| Step: 6
Training loss: 1.961709976196289
Validation loss: 2.1322030046934723

Epoch: 6| Step: 7
Training loss: 2.94677996635437
Validation loss: 2.118441989344935

Epoch: 6| Step: 8
Training loss: 2.1253514289855957
Validation loss: 2.118598376550982

Epoch: 6| Step: 9
Training loss: 2.0391314029693604
Validation loss: 2.106168580311601

Epoch: 6| Step: 10
Training loss: 2.182685136795044
Validation loss: 2.110468400421963

Epoch: 6| Step: 11
Training loss: 2.532646656036377
Validation loss: 2.1257478191006567

Epoch: 6| Step: 12
Training loss: 2.587160587310791
Validation loss: 2.1453873085719284

Epoch: 6| Step: 13
Training loss: 2.496803045272827
Validation loss: 2.1182121576801425

Epoch: 47| Step: 0
Training loss: 2.6473121643066406
Validation loss: 2.1266071719508015

Epoch: 6| Step: 1
Training loss: 2.0006659030914307
Validation loss: 2.116428993081534

Epoch: 6| Step: 2
Training loss: 2.5871498584747314
Validation loss: 2.1147406255045245

Epoch: 6| Step: 3
Training loss: 1.7562859058380127
Validation loss: 2.0809805008672897

Epoch: 6| Step: 4
Training loss: 2.840308427810669
Validation loss: 2.096009095509847

Epoch: 6| Step: 5
Training loss: 2.106846809387207
Validation loss: 2.123831764344246

Epoch: 6| Step: 6
Training loss: 2.7111809253692627
Validation loss: 2.143022103976178

Epoch: 6| Step: 7
Training loss: 2.41798996925354
Validation loss: 2.1261900830012497

Epoch: 6| Step: 8
Training loss: 1.7306969165802002
Validation loss: 2.139615028135238

Epoch: 6| Step: 9
Training loss: 2.1874139308929443
Validation loss: 2.078595220401723

Epoch: 6| Step: 10
Training loss: 3.1482064723968506
Validation loss: 2.1206154310575096

Epoch: 6| Step: 11
Training loss: 3.087773561477661
Validation loss: 2.1077183318394486

Epoch: 6| Step: 12
Training loss: 2.9338765144348145
Validation loss: 2.136677101094236

Epoch: 6| Step: 13
Training loss: 2.510653495788574
Validation loss: 2.0835779187499837

Epoch: 48| Step: 0
Training loss: 2.7486348152160645
Validation loss: 2.0977112477825535

Epoch: 6| Step: 1
Training loss: 2.253561019897461
Validation loss: 2.105089613186416

Epoch: 6| Step: 2
Training loss: 2.238247871398926
Validation loss: 2.1338331878826184

Epoch: 6| Step: 3
Training loss: 2.5438895225524902
Validation loss: 2.097010512505808

Epoch: 6| Step: 4
Training loss: 2.52907133102417
Validation loss: 2.0897254943847656

Epoch: 6| Step: 5
Training loss: 2.7346973419189453
Validation loss: 2.089256460948657

Epoch: 6| Step: 6
Training loss: 2.249732732772827
Validation loss: 2.128499125921598

Epoch: 6| Step: 7
Training loss: 2.46168851852417
Validation loss: 2.0823594139468287

Epoch: 6| Step: 8
Training loss: 2.129767417907715
Validation loss: 2.130755486026887

Epoch: 6| Step: 9
Training loss: 2.4599404335021973
Validation loss: 2.112582806617983

Epoch: 6| Step: 10
Training loss: 1.8616359233856201
Validation loss: 2.086184501647949

Epoch: 6| Step: 11
Training loss: 2.268073558807373
Validation loss: 2.1002048343740483

Epoch: 6| Step: 12
Training loss: 3.1266486644744873
Validation loss: 2.1163012391777447

Epoch: 6| Step: 13
Training loss: 3.3268377780914307
Validation loss: 2.1205519758244997

Epoch: 49| Step: 0
Training loss: 2.2452611923217773
Validation loss: 2.1374687533224783

Epoch: 6| Step: 1
Training loss: 2.6091907024383545
Validation loss: 2.110770025560933

Epoch: 6| Step: 2
Training loss: 2.499427080154419
Validation loss: 2.09162216032705

Epoch: 6| Step: 3
Training loss: 2.3044652938842773
Validation loss: 2.102764050165812

Epoch: 6| Step: 4
Training loss: 2.8680777549743652
Validation loss: 2.0863551401322886

Epoch: 6| Step: 5
Training loss: 2.3777294158935547
Validation loss: 2.1281304590163694

Epoch: 6| Step: 6
Training loss: 2.7771568298339844
Validation loss: 2.13833313603555

Epoch: 6| Step: 7
Training loss: 2.2786641120910645
Validation loss: 2.119196209856259

Epoch: 6| Step: 8
Training loss: 2.477537155151367
Validation loss: 2.1046869216426725

Epoch: 6| Step: 9
Training loss: 2.896287441253662
Validation loss: 2.122430078444942

Epoch: 6| Step: 10
Training loss: 2.506101131439209
Validation loss: 2.1111593759188088

Epoch: 6| Step: 11
Training loss: 1.9662036895751953
Validation loss: 2.122387150282501

Epoch: 6| Step: 12
Training loss: 2.3934242725372314
Validation loss: 2.0982096784858295

Epoch: 6| Step: 13
Training loss: 2.389711856842041
Validation loss: 2.1303534994843187

Epoch: 50| Step: 0
Training loss: 2.286229133605957
Validation loss: 2.0983186614128853

Epoch: 6| Step: 1
Training loss: 2.309309244155884
Validation loss: 2.117232591875138

Epoch: 6| Step: 2
Training loss: 2.5436742305755615
Validation loss: 2.1129105193640596

Epoch: 6| Step: 3
Training loss: 2.5545308589935303
Validation loss: 2.121652364730835

Epoch: 6| Step: 4
Training loss: 2.2530407905578613
Validation loss: 2.087234785479884

Epoch: 6| Step: 5
Training loss: 2.8201348781585693
Validation loss: 2.124889550670501

Epoch: 6| Step: 6
Training loss: 2.5332329273223877
Validation loss: 2.093238139665255

Epoch: 6| Step: 7
Training loss: 1.7924182415008545
Validation loss: 2.109927285102106

Epoch: 6| Step: 8
Training loss: 2.5982370376586914
Validation loss: 2.130701748273706

Epoch: 6| Step: 9
Training loss: 2.64727783203125
Validation loss: 2.141323435691095

Epoch: 6| Step: 10
Training loss: 2.5797085762023926
Validation loss: 2.1302079654509023

Epoch: 6| Step: 11
Training loss: 2.606368064880371
Validation loss: 2.1282652616500854

Epoch: 6| Step: 12
Training loss: 2.151533603668213
Validation loss: 2.1074277559916177

Epoch: 6| Step: 13
Training loss: 2.653245687484741
Validation loss: 2.1004347544844433

Epoch: 51| Step: 0
Training loss: 2.7887988090515137
Validation loss: 2.1143871456064205

Epoch: 6| Step: 1
Training loss: 1.8998796939849854
Validation loss: 2.103237126463203

Epoch: 6| Step: 2
Training loss: 1.9174163341522217
Validation loss: 2.0849241825842086

Epoch: 6| Step: 3
Training loss: 2.119521379470825
Validation loss: 2.1002298811430573

Epoch: 6| Step: 4
Training loss: 2.4339327812194824
Validation loss: 2.074432235892101

Epoch: 6| Step: 5
Training loss: 1.9169011116027832
Validation loss: 2.09766580981593

Epoch: 6| Step: 6
Training loss: 3.3445587158203125
Validation loss: 2.094750319757769

Epoch: 6| Step: 7
Training loss: 2.536267042160034
Validation loss: 2.1168628264498968

Epoch: 6| Step: 8
Training loss: 3.097273349761963
Validation loss: 2.076778463138047

Epoch: 6| Step: 9
Training loss: 2.28763484954834
Validation loss: 2.1046008320264917

Epoch: 6| Step: 10
Training loss: 3.4660305976867676
Validation loss: 2.0993181915693384

Epoch: 6| Step: 11
Training loss: 1.8489727973937988
Validation loss: 2.0825647666890132

Epoch: 6| Step: 12
Training loss: 2.1067750453948975
Validation loss: 2.1183564816751788

Epoch: 6| Step: 13
Training loss: 3.1319706439971924
Validation loss: 2.1333569288253784

Epoch: 52| Step: 0
Training loss: 1.8578176498413086
Validation loss: 2.1049332003439627

Epoch: 6| Step: 1
Training loss: 1.6494123935699463
Validation loss: 2.1271188528307023

Epoch: 6| Step: 2
Training loss: 2.8803329467773438
Validation loss: 2.121225433964883

Epoch: 6| Step: 3
Training loss: 2.8670265674591064
Validation loss: 2.144502538506703

Epoch: 6| Step: 4
Training loss: 2.602288246154785
Validation loss: 2.1067663161985335

Epoch: 6| Step: 5
Training loss: 2.6945390701293945
Validation loss: 2.1147975178175074

Epoch: 6| Step: 6
Training loss: 2.6863303184509277
Validation loss: 2.099536011295934

Epoch: 6| Step: 7
Training loss: 2.613279104232788
Validation loss: 2.112401203442645

Epoch: 6| Step: 8
Training loss: 2.676112174987793
Validation loss: 2.0790732291436966

Epoch: 6| Step: 9
Training loss: 2.372535228729248
Validation loss: 2.0909252679476173

Epoch: 6| Step: 10
Training loss: 2.425919771194458
Validation loss: 2.0899005346400763

Epoch: 6| Step: 11
Training loss: 2.0487945079803467
Validation loss: 2.0988195583384526

Epoch: 6| Step: 12
Training loss: 2.5177459716796875
Validation loss: 2.099508922587159

Epoch: 6| Step: 13
Training loss: 2.5573480129241943
Validation loss: 2.0850739299610095

Epoch: 53| Step: 0
Training loss: 2.8479535579681396
Validation loss: 2.0854171578602125

Epoch: 6| Step: 1
Training loss: 2.4733405113220215
Validation loss: 2.113120073913246

Epoch: 6| Step: 2
Training loss: 2.2442736625671387
Validation loss: 2.091021796708466

Epoch: 6| Step: 3
Training loss: 2.334761619567871
Validation loss: 2.129336944190405

Epoch: 6| Step: 4
Training loss: 2.248504161834717
Validation loss: 2.104280028291928

Epoch: 6| Step: 5
Training loss: 2.1161797046661377
Validation loss: 2.083535004687566

Epoch: 6| Step: 6
Training loss: 2.644528865814209
Validation loss: 2.078549092815768

Epoch: 6| Step: 7
Training loss: 2.5082528591156006
Validation loss: 2.0927869748043757

Epoch: 6| Step: 8
Training loss: 2.8430604934692383
Validation loss: 2.1012558014162126

Epoch: 6| Step: 9
Training loss: 2.0716965198516846
Validation loss: 2.1036486343670915

Epoch: 6| Step: 10
Training loss: 1.7441493272781372
Validation loss: 2.100410501162211

Epoch: 6| Step: 11
Training loss: 2.0827975273132324
Validation loss: 2.1067214729965373

Epoch: 6| Step: 12
Training loss: 3.0865814685821533
Validation loss: 2.0980505071660525

Epoch: 6| Step: 13
Training loss: 2.930697441101074
Validation loss: 2.09041827853008

Epoch: 54| Step: 0
Training loss: 2.9236817359924316
Validation loss: 2.124381758833444

Epoch: 6| Step: 1
Training loss: 2.579190731048584
Validation loss: 2.057646066911759

Epoch: 6| Step: 2
Training loss: 2.24503231048584
Validation loss: 2.1146944081911476

Epoch: 6| Step: 3
Training loss: 2.5134191513061523
Validation loss: 2.069759620133267

Epoch: 6| Step: 4
Training loss: 2.67121958732605
Validation loss: 2.084928753555462

Epoch: 6| Step: 5
Training loss: 2.5363411903381348
Validation loss: 2.1018540115766626

Epoch: 6| Step: 6
Training loss: 2.5611753463745117
Validation loss: 2.114719401123703

Epoch: 6| Step: 7
Training loss: 2.7838759422302246
Validation loss: 2.12730683049848

Epoch: 6| Step: 8
Training loss: 1.8507648706436157
Validation loss: 2.120254349964921

Epoch: 6| Step: 9
Training loss: 2.965761661529541
Validation loss: 2.108104495592015

Epoch: 6| Step: 10
Training loss: 1.7829906940460205
Validation loss: 2.108336517887731

Epoch: 6| Step: 11
Training loss: 2.3921709060668945
Validation loss: 2.120069249983757

Epoch: 6| Step: 12
Training loss: 1.8411494493484497
Validation loss: 2.096652284745247

Epoch: 6| Step: 13
Training loss: 2.448064088821411
Validation loss: 2.1295870132343744

Epoch: 55| Step: 0
Training loss: 1.9077658653259277
Validation loss: 2.113266396266158

Epoch: 6| Step: 1
Training loss: 2.5477218627929688
Validation loss: 2.087570463457415

Epoch: 6| Step: 2
Training loss: 2.7078351974487305
Validation loss: 2.092118932354835

Epoch: 6| Step: 3
Training loss: 2.047320604324341
Validation loss: 2.0952272671525196

Epoch: 6| Step: 4
Training loss: 2.9248046875
Validation loss: 2.0934191647396294

Epoch: 6| Step: 5
Training loss: 1.988252878189087
Validation loss: 2.066331366057037

Epoch: 6| Step: 6
Training loss: 2.098482131958008
Validation loss: 2.1008795410074215

Epoch: 6| Step: 7
Training loss: 3.3212451934814453
Validation loss: 2.08676411772287

Epoch: 6| Step: 8
Training loss: 2.430663585662842
Validation loss: 2.0910739642317577

Epoch: 6| Step: 9
Training loss: 1.5185649394989014
Validation loss: 2.124225216527139

Epoch: 6| Step: 10
Training loss: 3.1549599170684814
Validation loss: 2.1052081687476045

Epoch: 6| Step: 11
Training loss: 1.8512330055236816
Validation loss: 2.1020516990333475

Epoch: 6| Step: 12
Training loss: 2.8862624168395996
Validation loss: 2.094107168976979

Epoch: 6| Step: 13
Training loss: 3.3980653285980225
Validation loss: 2.0775147971286567

Epoch: 56| Step: 0
Training loss: 1.8727500438690186
Validation loss: 2.0904454390207925

Epoch: 6| Step: 1
Training loss: 2.5591025352478027
Validation loss: 2.077230256090882

Epoch: 6| Step: 2
Training loss: 2.443601369857788
Validation loss: 2.131531415447112

Epoch: 6| Step: 3
Training loss: 2.196838855743408
Validation loss: 2.0995125437295563

Epoch: 6| Step: 4
Training loss: 3.0134315490722656
Validation loss: 2.146075353827528

Epoch: 6| Step: 5
Training loss: 2.0151658058166504
Validation loss: 2.096914527236774

Epoch: 6| Step: 6
Training loss: 2.573955535888672
Validation loss: 2.108057011840164

Epoch: 6| Step: 7
Training loss: 1.8095476627349854
Validation loss: 2.1014259963907223

Epoch: 6| Step: 8
Training loss: 2.581843852996826
Validation loss: 2.0986294823308147

Epoch: 6| Step: 9
Training loss: 3.042398452758789
Validation loss: 2.1127433225672734

Epoch: 6| Step: 10
Training loss: 2.779451608657837
Validation loss: 2.110147342886976

Epoch: 6| Step: 11
Training loss: 2.1971170902252197
Validation loss: 2.090982807579861

Epoch: 6| Step: 12
Training loss: 2.339125633239746
Validation loss: 2.1040122970458

Epoch: 6| Step: 13
Training loss: 2.60929012298584
Validation loss: 2.104497186599239

Epoch: 57| Step: 0
Training loss: 2.8648595809936523
Validation loss: 2.1071167325460785

Epoch: 6| Step: 1
Training loss: 2.656419277191162
Validation loss: 2.103241318015642

Epoch: 6| Step: 2
Training loss: 2.4776830673217773
Validation loss: 2.102447860984392

Epoch: 6| Step: 3
Training loss: 2.880934715270996
Validation loss: 2.112749391986478

Epoch: 6| Step: 4
Training loss: 2.4028100967407227
Validation loss: 2.1259973613164758

Epoch: 6| Step: 5
Training loss: 2.2545766830444336
Validation loss: 2.106173333301339

Epoch: 6| Step: 6
Training loss: 2.6461451053619385
Validation loss: 2.1189154835157495

Epoch: 6| Step: 7
Training loss: 2.3653054237365723
Validation loss: 2.1032805135173183

Epoch: 6| Step: 8
Training loss: 1.74640691280365
Validation loss: 2.1032499164663334

Epoch: 6| Step: 9
Training loss: 2.2139639854431152
Validation loss: 2.1011868446103987

Epoch: 6| Step: 10
Training loss: 2.831397533416748
Validation loss: 2.141327916934926

Epoch: 6| Step: 11
Training loss: 2.442716121673584
Validation loss: 2.0947535563540716

Epoch: 6| Step: 12
Training loss: 1.898012638092041
Validation loss: 2.106030028353455

Epoch: 6| Step: 13
Training loss: 2.5560920238494873
Validation loss: 2.1288686542100805

Epoch: 58| Step: 0
Training loss: 2.5987730026245117
Validation loss: 2.087855600541638

Epoch: 6| Step: 1
Training loss: 2.9074249267578125
Validation loss: 2.1087819145571802

Epoch: 6| Step: 2
Training loss: 2.7914810180664062
Validation loss: 2.0760407755451817

Epoch: 6| Step: 3
Training loss: 2.447383403778076
Validation loss: 2.102876422225788

Epoch: 6| Step: 4
Training loss: 1.827278971672058
Validation loss: 2.1523412017412085

Epoch: 6| Step: 5
Training loss: 2.0061168670654297
Validation loss: 2.0979037195123653

Epoch: 6| Step: 6
Training loss: 2.081038475036621
Validation loss: 2.1087329631210654

Epoch: 6| Step: 7
Training loss: 2.9151644706726074
Validation loss: 2.1034228199271747

Epoch: 6| Step: 8
Training loss: 2.6805953979492188
Validation loss: 2.0983555342561457

Epoch: 6| Step: 9
Training loss: 1.962660551071167
Validation loss: 2.0922356933675785

Epoch: 6| Step: 10
Training loss: 3.260389804840088
Validation loss: 2.0852070098282187

Epoch: 6| Step: 11
Training loss: 2.90594744682312
Validation loss: 2.117869741173201

Epoch: 6| Step: 12
Training loss: 1.5560588836669922
Validation loss: 2.098504807359429

Epoch: 6| Step: 13
Training loss: 1.8577853441238403
Validation loss: 2.1169032358354136

Epoch: 59| Step: 0
Training loss: 2.6723976135253906
Validation loss: 2.103186591978996

Epoch: 6| Step: 1
Training loss: 2.5100367069244385
Validation loss: 2.1099669061681277

Epoch: 6| Step: 2
Training loss: 2.344512462615967
Validation loss: 2.097151256376697

Epoch: 6| Step: 3
Training loss: 2.8747079372406006
Validation loss: 2.085028035666353

Epoch: 6| Step: 4
Training loss: 2.4761815071105957
Validation loss: 2.0996564306238645

Epoch: 6| Step: 5
Training loss: 1.8885650634765625
Validation loss: 2.079588192765431

Epoch: 6| Step: 6
Training loss: 2.0150718688964844
Validation loss: 2.114201045805408

Epoch: 6| Step: 7
Training loss: 3.079514503479004
Validation loss: 2.1155270837968394

Epoch: 6| Step: 8
Training loss: 2.037464141845703
Validation loss: 2.077658168731197

Epoch: 6| Step: 9
Training loss: 2.5627846717834473
Validation loss: 2.101473735224816

Epoch: 6| Step: 10
Training loss: 2.998406410217285
Validation loss: 2.099020246536501

Epoch: 6| Step: 11
Training loss: 1.6812744140625
Validation loss: 2.089650228459348

Epoch: 6| Step: 12
Training loss: 2.722928762435913
Validation loss: 2.074735305642569

Epoch: 6| Step: 13
Training loss: 1.730937123298645
Validation loss: 2.1152299117016535

Epoch: 60| Step: 0
Training loss: 2.2680583000183105
Validation loss: 2.078912470930366

Epoch: 6| Step: 1
Training loss: 2.000311851501465
Validation loss: 2.122927341409909

Epoch: 6| Step: 2
Training loss: 2.4551467895507812
Validation loss: 2.0727552675431773

Epoch: 6| Step: 3
Training loss: 2.553162097930908
Validation loss: 2.1086480386795534

Epoch: 6| Step: 4
Training loss: 2.9758520126342773
Validation loss: 2.0643346719844367

Epoch: 6| Step: 5
Training loss: 2.310847043991089
Validation loss: 2.06194745597019

Epoch: 6| Step: 6
Training loss: 2.700075149536133
Validation loss: 2.0648925637686126

Epoch: 6| Step: 7
Training loss: 2.3336994647979736
Validation loss: 2.078623176902853

Epoch: 6| Step: 8
Training loss: 2.305941104888916
Validation loss: 2.0867231661273586

Epoch: 6| Step: 9
Training loss: 2.4148426055908203
Validation loss: 2.098681962618264

Epoch: 6| Step: 10
Training loss: 2.2557802200317383
Validation loss: 2.064233745298078

Epoch: 6| Step: 11
Training loss: 2.5576789379119873
Validation loss: 2.0861061003900345

Epoch: 6| Step: 12
Training loss: 2.1809864044189453
Validation loss: 2.0686459643866426

Epoch: 6| Step: 13
Training loss: 2.615734100341797
Validation loss: 2.092252549304757

Epoch: 61| Step: 0
Training loss: 2.7166497707366943
Validation loss: 2.064716633930001

Epoch: 6| Step: 1
Training loss: 2.283186435699463
Validation loss: 2.1155754366228656

Epoch: 6| Step: 2
Training loss: 2.609959125518799
Validation loss: 2.0859595396185435

Epoch: 6| Step: 3
Training loss: 1.9837180376052856
Validation loss: 2.0744876579571794

Epoch: 6| Step: 4
Training loss: 1.9896320104599
Validation loss: 2.1057359864634853

Epoch: 6| Step: 5
Training loss: 2.617938756942749
Validation loss: 2.1169540843655987

Epoch: 6| Step: 6
Training loss: 2.410857915878296
Validation loss: 2.074608010630454

Epoch: 6| Step: 7
Training loss: 2.6721088886260986
Validation loss: 2.111969655559909

Epoch: 6| Step: 8
Training loss: 2.9039034843444824
Validation loss: 2.1230210181205504

Epoch: 6| Step: 9
Training loss: 2.1529006958007812
Validation loss: 2.1032824234295915

Epoch: 6| Step: 10
Training loss: 2.158440113067627
Validation loss: 2.0817612576228317

Epoch: 6| Step: 11
Training loss: 2.111335039138794
Validation loss: 2.1075097360918598

Epoch: 6| Step: 12
Training loss: 2.7451395988464355
Validation loss: 2.0897842748190767

Epoch: 6| Step: 13
Training loss: 2.560155153274536
Validation loss: 2.1115968150477253

Epoch: 62| Step: 0
Training loss: 2.467625856399536
Validation loss: 2.0681512817259757

Epoch: 6| Step: 1
Training loss: 2.3697423934936523
Validation loss: 2.081287463506063

Epoch: 6| Step: 2
Training loss: 1.9501948356628418
Validation loss: 2.0950660244111092

Epoch: 6| Step: 3
Training loss: 2.289853572845459
Validation loss: 2.0537039079973773

Epoch: 6| Step: 4
Training loss: 2.5402026176452637
Validation loss: 2.0853836203134186

Epoch: 6| Step: 5
Training loss: 1.8823553323745728
Validation loss: 2.076187845199339

Epoch: 6| Step: 6
Training loss: 2.5797367095947266
Validation loss: 2.076723188482305

Epoch: 6| Step: 7
Training loss: 1.987917184829712
Validation loss: 2.08320624597611

Epoch: 6| Step: 8
Training loss: 2.1966233253479004
Validation loss: 2.1010422437421736

Epoch: 6| Step: 9
Training loss: 2.127042770385742
Validation loss: 2.0955455226282917

Epoch: 6| Step: 10
Training loss: 2.536849021911621
Validation loss: 2.1224091283736692

Epoch: 6| Step: 11
Training loss: 2.8773326873779297
Validation loss: 2.108019627550597

Epoch: 6| Step: 12
Training loss: 3.458195209503174
Validation loss: 2.0971605918740712

Epoch: 6| Step: 13
Training loss: 2.2997803688049316
Validation loss: 2.0661094996236984

Epoch: 63| Step: 0
Training loss: 2.9195327758789062
Validation loss: 2.065151491472798

Epoch: 6| Step: 1
Training loss: 2.802201509475708
Validation loss: 2.082200191354239

Epoch: 6| Step: 2
Training loss: 2.5956335067749023
Validation loss: 2.076739932901116

Epoch: 6| Step: 3
Training loss: 2.658367395401001
Validation loss: 2.099402532782606

Epoch: 6| Step: 4
Training loss: 2.294813632965088
Validation loss: 2.1048790536901003

Epoch: 6| Step: 5
Training loss: 1.7323017120361328
Validation loss: 2.081744376049247

Epoch: 6| Step: 6
Training loss: 1.7800612449645996
Validation loss: 2.098739636841641

Epoch: 6| Step: 7
Training loss: 2.4236702919006348
Validation loss: 2.09023573834409

Epoch: 6| Step: 8
Training loss: 2.2281484603881836
Validation loss: 2.116307868752428

Epoch: 6| Step: 9
Training loss: 2.5782692432403564
Validation loss: 2.121888073541785

Epoch: 6| Step: 10
Training loss: 2.7282867431640625
Validation loss: 2.1018277445147113

Epoch: 6| Step: 11
Training loss: 2.5091841220855713
Validation loss: 2.1098987133272233

Epoch: 6| Step: 12
Training loss: 1.6194438934326172
Validation loss: 2.1180983756178167

Epoch: 6| Step: 13
Training loss: 2.9345147609710693
Validation loss: 2.0972820046127483

Epoch: 64| Step: 0
Training loss: 2.9599082469940186
Validation loss: 2.0832285291405133

Epoch: 6| Step: 1
Training loss: 1.5672297477722168
Validation loss: 2.0924844780275897

Epoch: 6| Step: 2
Training loss: 2.6073007583618164
Validation loss: 2.1111347982960362

Epoch: 6| Step: 3
Training loss: 1.708343744277954
Validation loss: 2.1047625823687484

Epoch: 6| Step: 4
Training loss: 2.648669481277466
Validation loss: 2.114351184137406

Epoch: 6| Step: 5
Training loss: 2.2148630619049072
Validation loss: 2.080492313190173

Epoch: 6| Step: 6
Training loss: 2.0411548614501953
Validation loss: 2.0750143335711573

Epoch: 6| Step: 7
Training loss: 2.7362959384918213
Validation loss: 2.051417484078356

Epoch: 6| Step: 8
Training loss: 2.909282684326172
Validation loss: 2.1064818623245403

Epoch: 6| Step: 9
Training loss: 2.611588954925537
Validation loss: 2.0864636423767253

Epoch: 6| Step: 10
Training loss: 2.698544502258301
Validation loss: 2.078110615412394

Epoch: 6| Step: 11
Training loss: 2.1519222259521484
Validation loss: 2.068694342849075

Epoch: 6| Step: 12
Training loss: 2.1839218139648438
Validation loss: 2.079015451092874

Epoch: 6| Step: 13
Training loss: 2.5934383869171143
Validation loss: 2.0692316024534163

Epoch: 65| Step: 0
Training loss: 2.098639965057373
Validation loss: 2.1011379508561987

Epoch: 6| Step: 1
Training loss: 2.164689064025879
Validation loss: 2.0761875490988455

Epoch: 6| Step: 2
Training loss: 2.9172022342681885
Validation loss: 2.0667195050947127

Epoch: 6| Step: 3
Training loss: 2.649111270904541
Validation loss: 2.1020845367062475

Epoch: 6| Step: 4
Training loss: 1.6600576639175415
Validation loss: 2.099723110916794

Epoch: 6| Step: 5
Training loss: 2.2162911891937256
Validation loss: 2.0856946642680834

Epoch: 6| Step: 6
Training loss: 2.536306619644165
Validation loss: 2.1036159300035044

Epoch: 6| Step: 7
Training loss: 3.4332668781280518
Validation loss: 2.0706712584341727

Epoch: 6| Step: 8
Training loss: 2.5635974407196045
Validation loss: 2.065873348584739

Epoch: 6| Step: 9
Training loss: 2.3381776809692383
Validation loss: 2.0665461158239715

Epoch: 6| Step: 10
Training loss: 2.426462411880493
Validation loss: 2.0704200498519407

Epoch: 6| Step: 11
Training loss: 1.9116861820220947
Validation loss: 2.0780300273690173

Epoch: 6| Step: 12
Training loss: 1.9762789011001587
Validation loss: 2.0525376771086004

Epoch: 6| Step: 13
Training loss: 2.718653678894043
Validation loss: 2.039251124987038

Epoch: 66| Step: 0
Training loss: 2.3120269775390625
Validation loss: 2.0578481869031022

Epoch: 6| Step: 1
Training loss: 2.19390869140625
Validation loss: 2.06170815549871

Epoch: 6| Step: 2
Training loss: 2.356879711151123
Validation loss: 2.051199238787415

Epoch: 6| Step: 3
Training loss: 1.5599747896194458
Validation loss: 2.0461134679855837

Epoch: 6| Step: 4
Training loss: 2.7065513134002686
Validation loss: 2.0753862473272506

Epoch: 6| Step: 5
Training loss: 2.1834146976470947
Validation loss: 2.073368917229355

Epoch: 6| Step: 6
Training loss: 2.4369542598724365
Validation loss: 2.089968263462026

Epoch: 6| Step: 7
Training loss: 2.606433391571045
Validation loss: 2.098736656609402

Epoch: 6| Step: 8
Training loss: 2.807445526123047
Validation loss: 2.049955955115698

Epoch: 6| Step: 9
Training loss: 2.0843615531921387
Validation loss: 2.1285322712313746

Epoch: 6| Step: 10
Training loss: 2.605703830718994
Validation loss: 2.060025320258192

Epoch: 6| Step: 11
Training loss: 2.465470314025879
Validation loss: 2.0739888632169334

Epoch: 6| Step: 12
Training loss: 2.646944761276245
Validation loss: 2.1009121094980547

Epoch: 6| Step: 13
Training loss: 3.115856170654297
Validation loss: 2.0476884406100035

Epoch: 67| Step: 0
Training loss: 3.1144776344299316
Validation loss: 2.059939081950854

Epoch: 6| Step: 1
Training loss: 2.4705898761749268
Validation loss: 2.0773107736341414

Epoch: 6| Step: 2
Training loss: 2.8743996620178223
Validation loss: 2.0661824518634426

Epoch: 6| Step: 3
Training loss: 1.8950297832489014
Validation loss: 2.079407581719019

Epoch: 6| Step: 4
Training loss: 1.7830084562301636
Validation loss: 2.0765902842244794

Epoch: 6| Step: 5
Training loss: 2.390880584716797
Validation loss: 2.072796562666534

Epoch: 6| Step: 6
Training loss: 2.3797802925109863
Validation loss: 2.068524832366615

Epoch: 6| Step: 7
Training loss: 2.528719902038574
Validation loss: 2.056606387579313

Epoch: 6| Step: 8
Training loss: 2.299966335296631
Validation loss: 2.10784270686488

Epoch: 6| Step: 9
Training loss: 2.467949867248535
Validation loss: 2.079441293593376

Epoch: 6| Step: 10
Training loss: 1.7568186521530151
Validation loss: 2.074557794037686

Epoch: 6| Step: 11
Training loss: 2.327110767364502
Validation loss: 2.097116547246133

Epoch: 6| Step: 12
Training loss: 2.4521889686584473
Validation loss: 2.0706743565938805

Epoch: 6| Step: 13
Training loss: 2.7088403701782227
Validation loss: 2.0481853382561797

Epoch: 68| Step: 0
Training loss: 2.4710750579833984
Validation loss: 2.078663723443144

Epoch: 6| Step: 1
Training loss: 2.9890804290771484
Validation loss: 2.040484123332526

Epoch: 6| Step: 2
Training loss: 2.6971912384033203
Validation loss: 2.1002223312213855

Epoch: 6| Step: 3
Training loss: 2.1501851081848145
Validation loss: 2.016605782252486

Epoch: 6| Step: 4
Training loss: 2.2257158756256104
Validation loss: 2.0487121920431814

Epoch: 6| Step: 5
Training loss: 2.2584352493286133
Validation loss: 2.060258509010397

Epoch: 6| Step: 6
Training loss: 1.9051671028137207
Validation loss: 2.062623864860945

Epoch: 6| Step: 7
Training loss: 2.370182514190674
Validation loss: 2.0423534813747612

Epoch: 6| Step: 8
Training loss: 2.4731805324554443
Validation loss: 2.0511498323050876

Epoch: 6| Step: 9
Training loss: 2.433539390563965
Validation loss: 2.045583435284194

Epoch: 6| Step: 10
Training loss: 1.938549280166626
Validation loss: 2.014692121936429

Epoch: 6| Step: 11
Training loss: 1.9619619846343994
Validation loss: 2.063685699175763

Epoch: 6| Step: 12
Training loss: 3.006185531616211
Validation loss: 2.0546094961063837

Epoch: 6| Step: 13
Training loss: 2.560443162918091
Validation loss: 2.050429690268732

Epoch: 69| Step: 0
Training loss: 2.4142112731933594
Validation loss: 2.055585894533383

Epoch: 6| Step: 1
Training loss: 2.1517257690429688
Validation loss: 2.0633760190779165

Epoch: 6| Step: 2
Training loss: 2.8828821182250977
Validation loss: 2.0693339352966635

Epoch: 6| Step: 3
Training loss: 1.9615296125411987
Validation loss: 2.069523534467143

Epoch: 6| Step: 4
Training loss: 2.7218024730682373
Validation loss: 2.042063661800918

Epoch: 6| Step: 5
Training loss: 1.8157488107681274
Validation loss: 2.05009106410447

Epoch: 6| Step: 6
Training loss: 2.4303157329559326
Validation loss: 2.031303583934743

Epoch: 6| Step: 7
Training loss: 2.504957437515259
Validation loss: 2.0177828881048385

Epoch: 6| Step: 8
Training loss: 2.2754170894622803
Validation loss: 2.033480341716479

Epoch: 6| Step: 9
Training loss: 2.616650104522705
Validation loss: 2.0344226770503546

Epoch: 6| Step: 10
Training loss: 2.4204118251800537
Validation loss: 2.0730404059092202

Epoch: 6| Step: 11
Training loss: 2.51826810836792
Validation loss: 2.0574139959068707

Epoch: 6| Step: 12
Training loss: 2.4420976638793945
Validation loss: 2.064932273280236

Epoch: 6| Step: 13
Training loss: 2.1570053100585938
Validation loss: 2.034579168083847

Epoch: 70| Step: 0
Training loss: 3.0211238861083984
Validation loss: 2.0971545788549606

Epoch: 6| Step: 1
Training loss: 1.874938726425171
Validation loss: 2.0184150549673263

Epoch: 6| Step: 2
Training loss: 2.3927571773529053
Validation loss: 2.083067076180571

Epoch: 6| Step: 3
Training loss: 2.258579969406128
Validation loss: 2.0403942856737363

Epoch: 6| Step: 4
Training loss: 2.091948986053467
Validation loss: 2.0657784938812256

Epoch: 6| Step: 5
Training loss: 2.999790668487549
Validation loss: 2.1029341272128526

Epoch: 6| Step: 6
Training loss: 2.3688805103302
Validation loss: 2.0517267642482633

Epoch: 6| Step: 7
Training loss: 2.3529062271118164
Validation loss: 2.0468851122804868

Epoch: 6| Step: 8
Training loss: 1.7792391777038574
Validation loss: 2.043760181755148

Epoch: 6| Step: 9
Training loss: 2.4115169048309326
Validation loss: 2.036087078432883

Epoch: 6| Step: 10
Training loss: 2.965095043182373
Validation loss: 2.0298087045710576

Epoch: 6| Step: 11
Training loss: 2.0708327293395996
Validation loss: 2.038624971143661

Epoch: 6| Step: 12
Training loss: 2.517176389694214
Validation loss: 2.055488048061248

Epoch: 6| Step: 13
Training loss: 2.78353214263916
Validation loss: 2.085470768713182

Epoch: 71| Step: 0
Training loss: 2.8880369663238525
Validation loss: 2.0467012082376788

Epoch: 6| Step: 1
Training loss: 3.021880626678467
Validation loss: 2.0446042681253083

Epoch: 6| Step: 2
Training loss: 2.469090461730957
Validation loss: 2.044698417827647

Epoch: 6| Step: 3
Training loss: 2.7153921127319336
Validation loss: 2.0595523952155985

Epoch: 6| Step: 4
Training loss: 2.5727343559265137
Validation loss: 2.04217105783442

Epoch: 6| Step: 5
Training loss: 1.9319065809249878
Validation loss: 2.046650431489432

Epoch: 6| Step: 6
Training loss: 2.2176225185394287
Validation loss: 2.024711473013765

Epoch: 6| Step: 7
Training loss: 2.4662907123565674
Validation loss: 2.05293966621481

Epoch: 6| Step: 8
Training loss: 2.511155128479004
Validation loss: 2.039302554181827

Epoch: 6| Step: 9
Training loss: 2.2486846446990967
Validation loss: 2.002979650292345

Epoch: 6| Step: 10
Training loss: 2.003567695617676
Validation loss: 2.0477122158132572

Epoch: 6| Step: 11
Training loss: 1.7914236783981323
Validation loss: 2.002210651674578

Epoch: 6| Step: 12
Training loss: 1.662316083908081
Validation loss: 2.0338814514939503

Epoch: 6| Step: 13
Training loss: 3.169879913330078
Validation loss: 2.0305798912561066

Epoch: 72| Step: 0
Training loss: 2.3166146278381348
Validation loss: 2.0806740778748707

Epoch: 6| Step: 1
Training loss: 2.6716465950012207
Validation loss: 2.0563900316915205

Epoch: 6| Step: 2
Training loss: 2.2694485187530518
Validation loss: 2.0577237836776243

Epoch: 6| Step: 3
Training loss: 2.0305051803588867
Validation loss: 2.0637545072904198

Epoch: 6| Step: 4
Training loss: 2.6888015270233154
Validation loss: 2.0846014176645586

Epoch: 6| Step: 5
Training loss: 1.8167099952697754
Validation loss: 2.0762110499925512

Epoch: 6| Step: 6
Training loss: 2.3259153366088867
Validation loss: 2.063026069312967

Epoch: 6| Step: 7
Training loss: 2.376272439956665
Validation loss: 2.0718363972120386

Epoch: 6| Step: 8
Training loss: 3.1830034255981445
Validation loss: 2.057065017761723

Epoch: 6| Step: 9
Training loss: 2.5627284049987793
Validation loss: 2.0632864736741587

Epoch: 6| Step: 10
Training loss: 2.3369815349578857
Validation loss: 2.0406097417236655

Epoch: 6| Step: 11
Training loss: 1.9043731689453125
Validation loss: 2.0760065817063853

Epoch: 6| Step: 12
Training loss: 1.8597571849822998
Validation loss: 2.041495318053871

Epoch: 6| Step: 13
Training loss: 2.3861300945281982
Validation loss: 2.056820488745166

Epoch: 73| Step: 0
Training loss: 2.7554688453674316
Validation loss: 2.0572796919012584

Epoch: 6| Step: 1
Training loss: 1.9377533197402954
Validation loss: 2.0206375698889456

Epoch: 6| Step: 2
Training loss: 2.4898064136505127
Validation loss: 2.0647628640615814

Epoch: 6| Step: 3
Training loss: 1.6373810768127441
Validation loss: 2.0343105818635676

Epoch: 6| Step: 4
Training loss: 1.9988726377487183
Validation loss: 2.0253919145112396

Epoch: 6| Step: 5
Training loss: 2.4825329780578613
Validation loss: 2.0508522628456034

Epoch: 6| Step: 6
Training loss: 2.307203769683838
Validation loss: 2.0196305500563754

Epoch: 6| Step: 7
Training loss: 2.8818583488464355
Validation loss: 2.0584179816707486

Epoch: 6| Step: 8
Training loss: 2.2886366844177246
Validation loss: 2.044866984890353

Epoch: 6| Step: 9
Training loss: 2.533573865890503
Validation loss: 2.0561854262505808

Epoch: 6| Step: 10
Training loss: 1.5486007928848267
Validation loss: 2.034506167134931

Epoch: 6| Step: 11
Training loss: 2.8625688552856445
Validation loss: 2.0464233352291967

Epoch: 6| Step: 12
Training loss: 2.594198703765869
Validation loss: 2.039625347301524

Epoch: 6| Step: 13
Training loss: 2.916045904159546
Validation loss: 2.032821637327953

Epoch: 74| Step: 0
Training loss: 2.5394363403320312
Validation loss: 2.0457974403135237

Epoch: 6| Step: 1
Training loss: 2.2307839393615723
Validation loss: 2.0393637213655698

Epoch: 6| Step: 2
Training loss: 1.7021920680999756
Validation loss: 2.046335102409445

Epoch: 6| Step: 3
Training loss: 2.191743850708008
Validation loss: 2.0535971887650026

Epoch: 6| Step: 4
Training loss: 2.36592698097229
Validation loss: 2.030105911275392

Epoch: 6| Step: 5
Training loss: 2.3319787979125977
Validation loss: 2.0641402108694917

Epoch: 6| Step: 6
Training loss: 2.311166286468506
Validation loss: 2.070053326186313

Epoch: 6| Step: 7
Training loss: 2.3609681129455566
Validation loss: 2.06230305728092

Epoch: 6| Step: 8
Training loss: 2.060981273651123
Validation loss: 2.0149753093719482

Epoch: 6| Step: 9
Training loss: 2.023022174835205
Validation loss: 2.040933470572195

Epoch: 6| Step: 10
Training loss: 2.3381850719451904
Validation loss: 2.0157103948695685

Epoch: 6| Step: 11
Training loss: 2.3325679302215576
Validation loss: 2.0253348606888966

Epoch: 6| Step: 12
Training loss: 3.381211042404175
Validation loss: 2.07015388114478

Epoch: 6| Step: 13
Training loss: 2.7079107761383057
Validation loss: 2.033357640748383

Epoch: 75| Step: 0
Training loss: 2.5021347999572754
Validation loss: 2.051910226063062

Epoch: 6| Step: 1
Training loss: 2.022909164428711
Validation loss: 2.0214209300215527

Epoch: 6| Step: 2
Training loss: 3.0362799167633057
Validation loss: 2.041774739501297

Epoch: 6| Step: 3
Training loss: 2.5523202419281006
Validation loss: 2.0177095397826164

Epoch: 6| Step: 4
Training loss: 2.5260043144226074
Validation loss: 2.062203512396864

Epoch: 6| Step: 5
Training loss: 2.1078102588653564
Validation loss: 2.0838882000215593

Epoch: 6| Step: 6
Training loss: 2.3780722618103027
Validation loss: 2.0234221437925934

Epoch: 6| Step: 7
Training loss: 1.726443886756897
Validation loss: 2.0699735687625025

Epoch: 6| Step: 8
Training loss: 2.162177801132202
Validation loss: 2.03914999833671

Epoch: 6| Step: 9
Training loss: 2.6187000274658203
Validation loss: 2.008976359521189

Epoch: 6| Step: 10
Training loss: 1.9006307125091553
Validation loss: 2.004991308335335

Epoch: 6| Step: 11
Training loss: 2.318556308746338
Validation loss: 2.05252746869159

Epoch: 6| Step: 12
Training loss: 2.6238625049591064
Validation loss: 2.0358147531427364

Epoch: 6| Step: 13
Training loss: 2.4410078525543213
Validation loss: 2.0041017352893786

Epoch: 76| Step: 0
Training loss: 2.866471290588379
Validation loss: 2.0027131342118785

Epoch: 6| Step: 1
Training loss: 2.534590482711792
Validation loss: 2.0589610735575357

Epoch: 6| Step: 2
Training loss: 2.6787564754486084
Validation loss: 2.0169068010904456

Epoch: 6| Step: 3
Training loss: 2.154017686843872
Validation loss: 2.0174470486179477

Epoch: 6| Step: 4
Training loss: 2.6205058097839355
Validation loss: 2.0060740837486843

Epoch: 6| Step: 5
Training loss: 1.8216403722763062
Validation loss: 2.0117416304926716

Epoch: 6| Step: 6
Training loss: 1.4151028394699097
Validation loss: 2.003657479440012

Epoch: 6| Step: 7
Training loss: 2.0950636863708496
Validation loss: 2.0638728769876624

Epoch: 6| Step: 8
Training loss: 2.5777714252471924
Validation loss: 2.07621681562034

Epoch: 6| Step: 9
Training loss: 2.3762693405151367
Validation loss: 2.03557566929889

Epoch: 6| Step: 10
Training loss: 2.312105178833008
Validation loss: 2.0436844287380094

Epoch: 6| Step: 11
Training loss: 2.486051082611084
Validation loss: 2.0209127831202682

Epoch: 6| Step: 12
Training loss: 1.8269107341766357
Validation loss: 2.0366180327630814

Epoch: 6| Step: 13
Training loss: 3.5180647373199463
Validation loss: 2.036199664556852

Epoch: 77| Step: 0
Training loss: 2.1087889671325684
Validation loss: 2.031403230082604

Epoch: 6| Step: 1
Training loss: 2.7481603622436523
Validation loss: 2.0259389902955744

Epoch: 6| Step: 2
Training loss: 1.8636976480484009
Validation loss: 2.0492775286397626

Epoch: 6| Step: 3
Training loss: 2.602437973022461
Validation loss: 2.042982002740265

Epoch: 6| Step: 4
Training loss: 1.8862032890319824
Validation loss: 2.0287754048583326

Epoch: 6| Step: 5
Training loss: 2.0035667419433594
Validation loss: 2.0294447252827306

Epoch: 6| Step: 6
Training loss: 2.005613327026367
Validation loss: 2.028989394505819

Epoch: 6| Step: 7
Training loss: 2.674727201461792
Validation loss: 2.035509072324281

Epoch: 6| Step: 8
Training loss: 2.9467267990112305
Validation loss: 2.0325563517949914

Epoch: 6| Step: 9
Training loss: 2.1368894577026367
Validation loss: 2.0498468324702275

Epoch: 6| Step: 10
Training loss: 2.4508285522460938
Validation loss: 2.0124190174123293

Epoch: 6| Step: 11
Training loss: 2.2415719032287598
Validation loss: 2.0419455318040747

Epoch: 6| Step: 12
Training loss: 2.7217650413513184
Validation loss: 2.0442644678136355

Epoch: 6| Step: 13
Training loss: 2.1020727157592773
Validation loss: 2.004456720044536

Epoch: 78| Step: 0
Training loss: 2.302858829498291
Validation loss: 2.0378010465252783

Epoch: 6| Step: 1
Training loss: 2.369213104248047
Validation loss: 2.057644167254048

Epoch: 6| Step: 2
Training loss: 2.634788990020752
Validation loss: 2.0200184365754486

Epoch: 6| Step: 3
Training loss: 1.6799635887145996
Validation loss: 2.058780654784172

Epoch: 6| Step: 4
Training loss: 1.980799913406372
Validation loss: 2.0182140334959953

Epoch: 6| Step: 5
Training loss: 3.0450406074523926
Validation loss: 2.0115003085905507

Epoch: 6| Step: 6
Training loss: 2.701331853866577
Validation loss: 2.0393390194062264

Epoch: 6| Step: 7
Training loss: 2.241701602935791
Validation loss: 2.010990633759447

Epoch: 6| Step: 8
Training loss: 2.7621259689331055
Validation loss: 2.0317050987674343

Epoch: 6| Step: 9
Training loss: 1.6514358520507812
Validation loss: 2.046659367058867

Epoch: 6| Step: 10
Training loss: 2.4462947845458984
Validation loss: 2.005636538228681

Epoch: 6| Step: 11
Training loss: 2.460716724395752
Validation loss: 2.0348987579345703

Epoch: 6| Step: 12
Training loss: 2.348980665206909
Validation loss: 2.0403003487535702

Epoch: 6| Step: 13
Training loss: 1.8102917671203613
Validation loss: 2.0217132529904767

Epoch: 79| Step: 0
Training loss: 2.893993377685547
Validation loss: 2.0566195698194605

Epoch: 6| Step: 1
Training loss: 1.9249169826507568
Validation loss: 2.0234817920192594

Epoch: 6| Step: 2
Training loss: 2.0557847023010254
Validation loss: 2.0543833458295433

Epoch: 6| Step: 3
Training loss: 2.1322638988494873
Validation loss: 2.011241735950593

Epoch: 6| Step: 4
Training loss: 3.0819926261901855
Validation loss: 2.0599227695054907

Epoch: 6| Step: 5
Training loss: 1.5667645931243896
Validation loss: 2.056761100728025

Epoch: 6| Step: 6
Training loss: 2.5852670669555664
Validation loss: 2.04270903782178

Epoch: 6| Step: 7
Training loss: 2.8423943519592285
Validation loss: 2.0447805235462804

Epoch: 6| Step: 8
Training loss: 2.8603434562683105
Validation loss: 1.9824937107742473

Epoch: 6| Step: 9
Training loss: 2.262556552886963
Validation loss: 2.040671856172623

Epoch: 6| Step: 10
Training loss: 1.8142015933990479
Validation loss: 2.082664046236264

Epoch: 6| Step: 11
Training loss: 2.689487934112549
Validation loss: 2.030722213047807

Epoch: 6| Step: 12
Training loss: 1.596773624420166
Validation loss: 2.041774942028907

Epoch: 6| Step: 13
Training loss: 2.154547929763794
Validation loss: 2.030757487461131

Epoch: 80| Step: 0
Training loss: 2.3091228008270264
Validation loss: 2.0198684456527873

Epoch: 6| Step: 1
Training loss: 2.0972299575805664
Validation loss: 2.0180874832214846

Epoch: 6| Step: 2
Training loss: 2.547079563140869
Validation loss: 2.0362634043539725

Epoch: 6| Step: 3
Training loss: 2.019943952560425
Validation loss: 1.9953137136274768

Epoch: 6| Step: 4
Training loss: 2.3477158546447754
Validation loss: 2.0408549590777327

Epoch: 6| Step: 5
Training loss: 1.9576148986816406
Validation loss: 2.0715670303631852

Epoch: 6| Step: 6
Training loss: 2.1328885555267334
Validation loss: 2.0284618895540953

Epoch: 6| Step: 7
Training loss: 1.6987489461898804
Validation loss: 1.9699328304618917

Epoch: 6| Step: 8
Training loss: 2.8776814937591553
Validation loss: 2.02761996176935

Epoch: 6| Step: 9
Training loss: 1.977193832397461
Validation loss: 2.046925175574518

Epoch: 6| Step: 10
Training loss: 2.758746385574341
Validation loss: 2.046114766469566

Epoch: 6| Step: 11
Training loss: 2.591780662536621
Validation loss: 2.043815279519686

Epoch: 6| Step: 12
Training loss: 2.8720459938049316
Validation loss: 2.032156834038355

Epoch: 6| Step: 13
Training loss: 2.092299461364746
Validation loss: 2.0196916416127193

Epoch: 81| Step: 0
Training loss: 2.6868438720703125
Validation loss: 2.0161124070485434

Epoch: 6| Step: 1
Training loss: 2.408051013946533
Validation loss: 2.017675248525476

Epoch: 6| Step: 2
Training loss: 2.536250591278076
Validation loss: 2.03607702127067

Epoch: 6| Step: 3
Training loss: 1.951196551322937
Validation loss: 1.9944366485841813

Epoch: 6| Step: 4
Training loss: 1.8837552070617676
Validation loss: 2.019720754315776

Epoch: 6| Step: 5
Training loss: 2.37003493309021
Validation loss: 2.03153920173645

Epoch: 6| Step: 6
Training loss: 2.0551347732543945
Validation loss: 2.031908219860446

Epoch: 6| Step: 7
Training loss: 2.750692367553711
Validation loss: 2.015693913223923

Epoch: 6| Step: 8
Training loss: 2.588151454925537
Validation loss: 2.006954795570784

Epoch: 6| Step: 9
Training loss: 2.004634141921997
Validation loss: 2.0173219814095447

Epoch: 6| Step: 10
Training loss: 1.9539262056350708
Validation loss: 2.00557223186698

Epoch: 6| Step: 11
Training loss: 2.5529887676239014
Validation loss: 2.0020391236069384

Epoch: 6| Step: 12
Training loss: 2.236002206802368
Validation loss: 1.9903809255169285

Epoch: 6| Step: 13
Training loss: 2.6530895233154297
Validation loss: 1.9902881935078611

Epoch: 82| Step: 0
Training loss: 2.422938823699951
Validation loss: 1.9918715723099247

Epoch: 6| Step: 1
Training loss: 1.8960565328598022
Validation loss: 2.0205961876018073

Epoch: 6| Step: 2
Training loss: 2.021301746368408
Validation loss: 2.0047772238331456

Epoch: 6| Step: 3
Training loss: 2.2486228942871094
Validation loss: 2.006663719813029

Epoch: 6| Step: 4
Training loss: 1.9117881059646606
Validation loss: 2.049252083224635

Epoch: 6| Step: 5
Training loss: 2.531604528427124
Validation loss: 2.0443950878676547

Epoch: 6| Step: 6
Training loss: 2.454146146774292
Validation loss: 1.9910276307854602

Epoch: 6| Step: 7
Training loss: 2.343775987625122
Validation loss: 1.973444209303907

Epoch: 6| Step: 8
Training loss: 2.1478922367095947
Validation loss: 2.0393537885399273

Epoch: 6| Step: 9
Training loss: 1.9493942260742188
Validation loss: 2.0702150996013353

Epoch: 6| Step: 10
Training loss: 2.4212539196014404
Validation loss: 2.0159103614027782

Epoch: 6| Step: 11
Training loss: 2.116955280303955
Validation loss: 2.0122242589150705

Epoch: 6| Step: 12
Training loss: 3.3501036167144775
Validation loss: 2.043106186774469

Epoch: 6| Step: 13
Training loss: 2.575390577316284
Validation loss: 2.020324207121326

Epoch: 83| Step: 0
Training loss: 2.7252490520477295
Validation loss: 2.0346344312032065

Epoch: 6| Step: 1
Training loss: 1.983108401298523
Validation loss: 2.052235008567892

Epoch: 6| Step: 2
Training loss: 2.066701650619507
Validation loss: 2.030411961258099

Epoch: 6| Step: 3
Training loss: 2.1598610877990723
Validation loss: 2.0050341160066667

Epoch: 6| Step: 4
Training loss: 2.387782573699951
Validation loss: 2.0643203899424565

Epoch: 6| Step: 5
Training loss: 1.6950619220733643
Validation loss: 2.0081095259676696

Epoch: 6| Step: 6
Training loss: 2.092021942138672
Validation loss: 2.036543848694012

Epoch: 6| Step: 7
Training loss: 2.1994495391845703
Validation loss: 2.0363483172591015

Epoch: 6| Step: 8
Training loss: 2.709163188934326
Validation loss: 2.0468829319041264

Epoch: 6| Step: 9
Training loss: 2.6021432876586914
Validation loss: 2.0399703210399998

Epoch: 6| Step: 10
Training loss: 1.970871925354004
Validation loss: 2.0410804389625468

Epoch: 6| Step: 11
Training loss: 2.73799729347229
Validation loss: 2.0293276732967747

Epoch: 6| Step: 12
Training loss: 2.306971549987793
Validation loss: 2.0538370327282975

Epoch: 6| Step: 13
Training loss: 2.9710798263549805
Validation loss: 2.0143813689549765

Epoch: 84| Step: 0
Training loss: 1.542541742324829
Validation loss: 2.004278858502706

Epoch: 6| Step: 1
Training loss: 2.324066162109375
Validation loss: 2.0098184565062165

Epoch: 6| Step: 2
Training loss: 2.1496267318725586
Validation loss: 2.0535690528090282

Epoch: 6| Step: 3
Training loss: 1.981064796447754
Validation loss: 2.0301727094957904

Epoch: 6| Step: 4
Training loss: 2.431400775909424
Validation loss: 2.0193959282290552

Epoch: 6| Step: 5
Training loss: 2.159639835357666
Validation loss: 2.0563011528343282

Epoch: 6| Step: 6
Training loss: 1.5553642511367798
Validation loss: 2.0441538826111825

Epoch: 6| Step: 7
Training loss: 3.1046667098999023
Validation loss: 2.0549901685407086

Epoch: 6| Step: 8
Training loss: 2.344111919403076
Validation loss: 2.0339217801247873

Epoch: 6| Step: 9
Training loss: 2.121410369873047
Validation loss: 2.0342376655147922

Epoch: 6| Step: 10
Training loss: 3.096973180770874
Validation loss: 2.0042991202364684

Epoch: 6| Step: 11
Training loss: 3.219452381134033
Validation loss: 2.0241359536365797

Epoch: 6| Step: 12
Training loss: 1.9961695671081543
Validation loss: 2.0154753833688717

Epoch: 6| Step: 13
Training loss: 2.3421270847320557
Validation loss: 1.9865012668794202

Epoch: 85| Step: 0
Training loss: 2.359426736831665
Validation loss: 2.017808352747271

Epoch: 6| Step: 1
Training loss: 2.36630916595459
Validation loss: 2.0382200517962055

Epoch: 6| Step: 2
Training loss: 2.570896625518799
Validation loss: 2.0450086337263866

Epoch: 6| Step: 3
Training loss: 2.3799397945404053
Validation loss: 2.0343105023907078

Epoch: 6| Step: 4
Training loss: 2.152864456176758
Validation loss: 2.024889494783135

Epoch: 6| Step: 5
Training loss: 1.7322200536727905
Validation loss: 2.0318857226320493

Epoch: 6| Step: 6
Training loss: 2.3512134552001953
Validation loss: 2.0155341381667764

Epoch: 6| Step: 7
Training loss: 2.639111280441284
Validation loss: 2.0281174016255203

Epoch: 6| Step: 8
Training loss: 1.867302417755127
Validation loss: 2.0343685175782893

Epoch: 6| Step: 9
Training loss: 3.370108127593994
Validation loss: 1.9989253885002547

Epoch: 6| Step: 10
Training loss: 2.364126682281494
Validation loss: 2.038236202732209

Epoch: 6| Step: 11
Training loss: 1.7266044616699219
Validation loss: 2.0374627920889083

Epoch: 6| Step: 12
Training loss: 2.4288864135742188
Validation loss: 2.025161220181373

Epoch: 6| Step: 13
Training loss: 1.8701996803283691
Validation loss: 2.048537709379709

Epoch: 86| Step: 0
Training loss: 2.456310987472534
Validation loss: 2.0156678281804568

Epoch: 6| Step: 1
Training loss: 2.0553908348083496
Validation loss: 1.9983395863604803

Epoch: 6| Step: 2
Training loss: 1.3081591129302979
Validation loss: 2.010826631258893

Epoch: 6| Step: 3
Training loss: 2.1242003440856934
Validation loss: 1.9767844343698153

Epoch: 6| Step: 4
Training loss: 2.1754391193389893
Validation loss: 2.0026159107044177

Epoch: 6| Step: 5
Training loss: 2.965066432952881
Validation loss: 2.0099292775636077

Epoch: 6| Step: 6
Training loss: 2.3355278968811035
Validation loss: 1.9731543935755247

Epoch: 6| Step: 7
Training loss: 2.2836785316467285
Validation loss: 1.9821858944431427

Epoch: 6| Step: 8
Training loss: 2.450392723083496
Validation loss: 2.0069392060720794

Epoch: 6| Step: 9
Training loss: 2.0399370193481445
Validation loss: 1.9769795069130518

Epoch: 6| Step: 10
Training loss: 2.704899311065674
Validation loss: 2.0129968325297036

Epoch: 6| Step: 11
Training loss: 2.5021378993988037
Validation loss: 1.97067637981907

Epoch: 6| Step: 12
Training loss: 2.3220348358154297
Validation loss: 1.977012368940538

Epoch: 6| Step: 13
Training loss: 2.374436616897583
Validation loss: 1.9852176532950452

Epoch: 87| Step: 0
Training loss: 2.1077661514282227
Validation loss: 2.0184687440113356

Epoch: 6| Step: 1
Training loss: 2.249361753463745
Validation loss: 1.963721453502614

Epoch: 6| Step: 2
Training loss: 2.351917028427124
Validation loss: 2.021154354977351

Epoch: 6| Step: 3
Training loss: 1.511112928390503
Validation loss: 1.9807055291309152

Epoch: 6| Step: 4
Training loss: 2.930452823638916
Validation loss: 1.9738014487810032

Epoch: 6| Step: 5
Training loss: 2.118940830230713
Validation loss: 1.9714681794566493

Epoch: 6| Step: 6
Training loss: 2.291080951690674
Validation loss: 2.0304906368255615

Epoch: 6| Step: 7
Training loss: 2.127542018890381
Validation loss: 1.9862152350846158

Epoch: 6| Step: 8
Training loss: 2.533414840698242
Validation loss: 2.005734009127463

Epoch: 6| Step: 9
Training loss: 3.0302562713623047
Validation loss: 2.0100871696267077

Epoch: 6| Step: 10
Training loss: 2.1807544231414795
Validation loss: 1.9892718689416045

Epoch: 6| Step: 11
Training loss: 1.5691310167312622
Validation loss: 1.9838088673930014

Epoch: 6| Step: 12
Training loss: 2.265023946762085
Validation loss: 2.0250664295688754

Epoch: 6| Step: 13
Training loss: 2.5859382152557373
Validation loss: 2.033340986056994

Epoch: 88| Step: 0
Training loss: 2.422865390777588
Validation loss: 1.9967306480612805

Epoch: 6| Step: 1
Training loss: 2.6371383666992188
Validation loss: 2.0056458993624617

Epoch: 6| Step: 2
Training loss: 2.061758518218994
Validation loss: 2.0212501031096264

Epoch: 6| Step: 3
Training loss: 2.162458896636963
Validation loss: 1.985832316901094

Epoch: 6| Step: 4
Training loss: 1.9370760917663574
Validation loss: 1.9734788889526038

Epoch: 6| Step: 5
Training loss: 3.0475778579711914
Validation loss: 1.9936697688153995

Epoch: 6| Step: 6
Training loss: 2.427943706512451
Validation loss: 2.0017217577144666

Epoch: 6| Step: 7
Training loss: 1.9515422582626343
Validation loss: 1.9954215031798168

Epoch: 6| Step: 8
Training loss: 1.943542718887329
Validation loss: 1.9781290203012445

Epoch: 6| Step: 9
Training loss: 2.445889472961426
Validation loss: 1.979717521257298

Epoch: 6| Step: 10
Training loss: 1.803978443145752
Validation loss: 2.0237627465237855

Epoch: 6| Step: 11
Training loss: 2.2346794605255127
Validation loss: 2.003796064725486

Epoch: 6| Step: 12
Training loss: 2.688976287841797
Validation loss: 2.00083742859543

Epoch: 6| Step: 13
Training loss: 2.0164108276367188
Validation loss: 2.0165491693763324

Epoch: 89| Step: 0
Training loss: 2.547929286956787
Validation loss: 1.9951008686455347

Epoch: 6| Step: 1
Training loss: 1.7027091979980469
Validation loss: 2.0213728386868715

Epoch: 6| Step: 2
Training loss: 2.7499375343322754
Validation loss: 1.995764793888215

Epoch: 6| Step: 3
Training loss: 2.0082287788391113
Validation loss: 1.998324001989057

Epoch: 6| Step: 4
Training loss: 1.828908085823059
Validation loss: 2.0245974474055792

Epoch: 6| Step: 5
Training loss: 2.1093342304229736
Validation loss: 2.0095787817432034

Epoch: 6| Step: 6
Training loss: 1.8030240535736084
Validation loss: 1.9867440244202972

Epoch: 6| Step: 7
Training loss: 1.9116133451461792
Validation loss: 1.9880822038137784

Epoch: 6| Step: 8
Training loss: 2.6209003925323486
Validation loss: 2.0060255027586416

Epoch: 6| Step: 9
Training loss: 2.8470029830932617
Validation loss: 1.9949382312836186

Epoch: 6| Step: 10
Training loss: 1.9272851943969727
Validation loss: 1.9835535531402917

Epoch: 6| Step: 11
Training loss: 2.5380187034606934
Validation loss: 1.9857425535878828

Epoch: 6| Step: 12
Training loss: 2.6883318424224854
Validation loss: 1.9724865190444454

Epoch: 6| Step: 13
Training loss: 3.157406806945801
Validation loss: 1.9644249536657845

Epoch: 90| Step: 0
Training loss: 1.2785755395889282
Validation loss: 1.9717255664128128

Epoch: 6| Step: 1
Training loss: 2.3104095458984375
Validation loss: 1.9879045742814259

Epoch: 6| Step: 2
Training loss: 2.3986940383911133
Validation loss: 1.9753049227499193

Epoch: 6| Step: 3
Training loss: 1.7718772888183594
Validation loss: 1.9850555389158187

Epoch: 6| Step: 4
Training loss: 2.336317777633667
Validation loss: 2.018228448847289

Epoch: 6| Step: 5
Training loss: 2.5481905937194824
Validation loss: 2.013343631580312

Epoch: 6| Step: 6
Training loss: 2.0891432762145996
Validation loss: 2.0152338807300856

Epoch: 6| Step: 7
Training loss: 2.2498583793640137
Validation loss: 2.0086020090246715

Epoch: 6| Step: 8
Training loss: 2.905308246612549
Validation loss: 1.9760928602628811

Epoch: 6| Step: 9
Training loss: 2.9201889038085938
Validation loss: 1.9830025921585739

Epoch: 6| Step: 10
Training loss: 2.4396376609802246
Validation loss: 1.970027740283679

Epoch: 6| Step: 11
Training loss: 2.239647388458252
Validation loss: 1.9285858728552376

Epoch: 6| Step: 12
Training loss: 1.974654197692871
Validation loss: 1.9755658975211523

Epoch: 6| Step: 13
Training loss: 2.354785919189453
Validation loss: 1.9814982362972793

Epoch: 91| Step: 0
Training loss: 1.9257375001907349
Validation loss: 1.9901994030962709

Epoch: 6| Step: 1
Training loss: 1.8964078426361084
Validation loss: 1.986953091877763

Epoch: 6| Step: 2
Training loss: 2.19486141204834
Validation loss: 1.9503827761578303

Epoch: 6| Step: 3
Training loss: 2.2181787490844727
Validation loss: 2.0155038320890037

Epoch: 6| Step: 4
Training loss: 2.2088398933410645
Validation loss: 2.0161230987118137

Epoch: 6| Step: 5
Training loss: 2.5418968200683594
Validation loss: 1.9626306564577165

Epoch: 6| Step: 6
Training loss: 2.5175375938415527
Validation loss: 1.9308936262643466

Epoch: 6| Step: 7
Training loss: 2.1509785652160645
Validation loss: 1.9483421617938625

Epoch: 6| Step: 8
Training loss: 3.151883363723755
Validation loss: 1.9606321396366242

Epoch: 6| Step: 9
Training loss: 2.1661267280578613
Validation loss: 1.9526373096691665

Epoch: 6| Step: 10
Training loss: 2.1094911098480225
Validation loss: 2.0045221672263196

Epoch: 6| Step: 11
Training loss: 1.7056787014007568
Validation loss: 1.9924631810957385

Epoch: 6| Step: 12
Training loss: 2.235440492630005
Validation loss: 2.005508768943048

Epoch: 6| Step: 13
Training loss: 2.7674577236175537
Validation loss: 2.001420263321169

Epoch: 92| Step: 0
Training loss: 2.226477861404419
Validation loss: 1.9962818391861454

Epoch: 6| Step: 1
Training loss: 2.6978399753570557
Validation loss: 2.0057210383876676

Epoch: 6| Step: 2
Training loss: 2.0447962284088135
Validation loss: 2.037167323532925

Epoch: 6| Step: 3
Training loss: 1.8018289804458618
Validation loss: 2.030185450789749

Epoch: 6| Step: 4
Training loss: 2.332301616668701
Validation loss: 2.004997561054845

Epoch: 6| Step: 5
Training loss: 2.2619433403015137
Validation loss: 1.990018670276929

Epoch: 6| Step: 6
Training loss: 2.63832426071167
Validation loss: 1.9984424550046203

Epoch: 6| Step: 7
Training loss: 2.1607019901275635
Validation loss: 2.0200924975897676

Epoch: 6| Step: 8
Training loss: 2.291564464569092
Validation loss: 2.0131577419978317

Epoch: 6| Step: 9
Training loss: 2.6120872497558594
Validation loss: 1.9876689346887733

Epoch: 6| Step: 10
Training loss: 1.9792934656143188
Validation loss: 2.0403333710085962

Epoch: 6| Step: 11
Training loss: 1.9922083616256714
Validation loss: 2.0384055132506997

Epoch: 6| Step: 12
Training loss: 2.2852559089660645
Validation loss: 2.039885110752557

Epoch: 6| Step: 13
Training loss: 1.7862387895584106
Validation loss: 2.0147176711790022

Epoch: 93| Step: 0
Training loss: 1.815966248512268
Validation loss: 2.008387105439299

Epoch: 6| Step: 1
Training loss: 1.2985000610351562
Validation loss: 2.0546644964525775

Epoch: 6| Step: 2
Training loss: 2.085739850997925
Validation loss: 2.0303319987430366

Epoch: 6| Step: 3
Training loss: 2.134157180786133
Validation loss: 2.0322507414766537

Epoch: 6| Step: 4
Training loss: 3.2304043769836426
Validation loss: 2.043801341005551

Epoch: 6| Step: 5
Training loss: 3.0115487575531006
Validation loss: 2.0177231911690003

Epoch: 6| Step: 6
Training loss: 2.2957472801208496
Validation loss: 2.0336307735853296

Epoch: 6| Step: 7
Training loss: 1.4134812355041504
Validation loss: 2.0359228913502028

Epoch: 6| Step: 8
Training loss: 2.8342180252075195
Validation loss: 2.0568445523579917

Epoch: 6| Step: 9
Training loss: 1.9109495878219604
Validation loss: 2.0215733512755363

Epoch: 6| Step: 10
Training loss: 2.2840383052825928
Validation loss: 2.001783022316553

Epoch: 6| Step: 11
Training loss: 1.841965675354004
Validation loss: 2.058140649590441

Epoch: 6| Step: 12
Training loss: 3.0640006065368652
Validation loss: 2.037251349418394

Epoch: 6| Step: 13
Training loss: 2.7750771045684814
Validation loss: 1.9938692046749977

Epoch: 94| Step: 0
Training loss: 2.2115695476531982
Validation loss: 2.044095200877036

Epoch: 6| Step: 1
Training loss: 2.0986266136169434
Validation loss: 2.0146874612377537

Epoch: 6| Step: 2
Training loss: 1.8864915370941162
Validation loss: 2.0388267488889795

Epoch: 6| Step: 3
Training loss: 3.1053919792175293
Validation loss: 1.9993284799719369

Epoch: 6| Step: 4
Training loss: 1.9769928455352783
Validation loss: 2.0258256581521805

Epoch: 6| Step: 5
Training loss: 2.275207996368408
Validation loss: 2.0053975582122803

Epoch: 6| Step: 6
Training loss: 2.052155017852783
Validation loss: 2.0280946339330366

Epoch: 6| Step: 7
Training loss: 2.37089204788208
Validation loss: 2.0223369239478983

Epoch: 6| Step: 8
Training loss: 1.895702838897705
Validation loss: 2.009648953714678

Epoch: 6| Step: 9
Training loss: 2.231994152069092
Validation loss: 2.045887363854275

Epoch: 6| Step: 10
Training loss: 3.041048288345337
Validation loss: 1.9986780920336324

Epoch: 6| Step: 11
Training loss: 1.999882698059082
Validation loss: 2.0500026954117643

Epoch: 6| Step: 12
Training loss: 2.073472261428833
Validation loss: 2.01550389618002

Epoch: 6| Step: 13
Training loss: 2.4699485301971436
Validation loss: 2.0090162677149617

Epoch: 95| Step: 0
Training loss: 2.4124317169189453
Validation loss: 2.0129685632644163

Epoch: 6| Step: 1
Training loss: 2.6349611282348633
Validation loss: 2.0048679485115954

Epoch: 6| Step: 2
Training loss: 2.453218936920166
Validation loss: 2.0274251994266304

Epoch: 6| Step: 3
Training loss: 2.188352584838867
Validation loss: 2.019444224654987

Epoch: 6| Step: 4
Training loss: 1.4983153343200684
Validation loss: 1.997849336234472

Epoch: 6| Step: 5
Training loss: 1.9179961681365967
Validation loss: 2.037416358147898

Epoch: 6| Step: 6
Training loss: 1.8585145473480225
Validation loss: 2.0209945222382903

Epoch: 6| Step: 7
Training loss: 2.6017532348632812
Validation loss: 2.017808655256866

Epoch: 6| Step: 8
Training loss: 2.7397148609161377
Validation loss: 2.020642352360551

Epoch: 6| Step: 9
Training loss: 2.089616537094116
Validation loss: 2.051845504391578

Epoch: 6| Step: 10
Training loss: 2.507519245147705
Validation loss: 2.0001520469624507

Epoch: 6| Step: 11
Training loss: 1.8145697116851807
Validation loss: 2.0139439849443335

Epoch: 6| Step: 12
Training loss: 2.445651054382324
Validation loss: 2.0257807598319104

Epoch: 6| Step: 13
Training loss: 2.5714540481567383
Validation loss: 1.965254186302103

Epoch: 96| Step: 0
Training loss: 3.227789878845215
Validation loss: 2.0475876933784893

Epoch: 6| Step: 1
Training loss: 2.549255847930908
Validation loss: 2.015690179281337

Epoch: 6| Step: 2
Training loss: 1.85239839553833
Validation loss: 1.9962778027339647

Epoch: 6| Step: 3
Training loss: 2.5797204971313477
Validation loss: 2.0366466993926675

Epoch: 6| Step: 4
Training loss: 1.6418812274932861
Validation loss: 2.01386825243632

Epoch: 6| Step: 5
Training loss: 2.0091795921325684
Validation loss: 2.0121066736918625

Epoch: 6| Step: 6
Training loss: 1.6196787357330322
Validation loss: 1.9889190145718154

Epoch: 6| Step: 7
Training loss: 2.5083203315734863
Validation loss: 2.0172229082353654

Epoch: 6| Step: 8
Training loss: 2.771656036376953
Validation loss: 1.9888592535449612

Epoch: 6| Step: 9
Training loss: 2.2210729122161865
Validation loss: 2.023351287329069

Epoch: 6| Step: 10
Training loss: 2.1853630542755127
Validation loss: 1.9974806052382275

Epoch: 6| Step: 11
Training loss: 2.479257583618164
Validation loss: 2.000961445992993

Epoch: 6| Step: 12
Training loss: 1.9253580570220947
Validation loss: 2.0222397030040784

Epoch: 6| Step: 13
Training loss: 1.4214398860931396
Validation loss: 1.9902560762179795

Epoch: 97| Step: 0
Training loss: 1.2915624380111694
Validation loss: 2.004895629421357

Epoch: 6| Step: 1
Training loss: 1.9784204959869385
Validation loss: 2.0342639992314

Epoch: 6| Step: 2
Training loss: 2.295506238937378
Validation loss: 2.0092696092462026

Epoch: 6| Step: 3
Training loss: 2.533338785171509
Validation loss: 2.01769357855602

Epoch: 6| Step: 4
Training loss: 2.3502631187438965
Validation loss: 2.0218493964082453

Epoch: 6| Step: 5
Training loss: 2.4381253719329834
Validation loss: 2.0251212402056624

Epoch: 6| Step: 6
Training loss: 1.7178541421890259
Validation loss: 1.9674628626915716

Epoch: 6| Step: 7
Training loss: 2.3959717750549316
Validation loss: 1.9913624384069954

Epoch: 6| Step: 8
Training loss: 2.6884758472442627
Validation loss: 2.0405969158295663

Epoch: 6| Step: 9
Training loss: 2.6458446979522705
Validation loss: 1.999695748411199

Epoch: 6| Step: 10
Training loss: 1.93110191822052
Validation loss: 1.9972953770750312

Epoch: 6| Step: 11
Training loss: 2.117004871368408
Validation loss: 2.0315106902071225

Epoch: 6| Step: 12
Training loss: 2.0026960372924805
Validation loss: 2.0137691087620233

Epoch: 6| Step: 13
Training loss: 3.417771339416504
Validation loss: 2.0245144751764115

Epoch: 98| Step: 0
Training loss: 1.8689396381378174
Validation loss: 2.032455422544992

Epoch: 6| Step: 1
Training loss: 2.36616849899292
Validation loss: 2.0031636555989585

Epoch: 6| Step: 2
Training loss: 1.3252649307250977
Validation loss: 1.980804499759469

Epoch: 6| Step: 3
Training loss: 2.1846070289611816
Validation loss: 1.9752157349740305

Epoch: 6| Step: 4
Training loss: 2.9814608097076416
Validation loss: 2.012154717599192

Epoch: 6| Step: 5
Training loss: 2.21116304397583
Validation loss: 1.9970606155292963

Epoch: 6| Step: 6
Training loss: 2.2198638916015625
Validation loss: 1.9999329710519442

Epoch: 6| Step: 7
Training loss: 2.532620429992676
Validation loss: 2.0035019548990394

Epoch: 6| Step: 8
Training loss: 2.3188469409942627
Validation loss: 1.9895282612052014

Epoch: 6| Step: 9
Training loss: 2.141531229019165
Validation loss: 1.986507349116828

Epoch: 6| Step: 10
Training loss: 2.3950552940368652
Validation loss: 2.0034288834500056

Epoch: 6| Step: 11
Training loss: 2.023284435272217
Validation loss: 1.9800192732964792

Epoch: 6| Step: 12
Training loss: 2.3670401573181152
Validation loss: 1.9693633176947152

Epoch: 6| Step: 13
Training loss: 2.4038631916046143
Validation loss: 1.974281317444258

Epoch: 99| Step: 0
Training loss: 2.6589560508728027
Validation loss: 1.991059777557209

Epoch: 6| Step: 1
Training loss: 2.3855769634246826
Validation loss: 1.9592324508133756

Epoch: 6| Step: 2
Training loss: 2.695014476776123
Validation loss: 1.9532750204045286

Epoch: 6| Step: 3
Training loss: 2.102688789367676
Validation loss: 2.0093358114201534

Epoch: 6| Step: 4
Training loss: 1.6603429317474365
Validation loss: 2.0150257233650453

Epoch: 6| Step: 5
Training loss: 2.1800003051757812
Validation loss: 1.9863647068700483

Epoch: 6| Step: 6
Training loss: 1.782848834991455
Validation loss: 1.996971430317048

Epoch: 6| Step: 7
Training loss: 2.523792266845703
Validation loss: 2.002866265594318

Epoch: 6| Step: 8
Training loss: 1.908478021621704
Validation loss: 1.9882516707143476

Epoch: 6| Step: 9
Training loss: 1.767101764678955
Validation loss: 1.9802689488216112

Epoch: 6| Step: 10
Training loss: 2.230273723602295
Validation loss: 1.9815029572415095

Epoch: 6| Step: 11
Training loss: 2.2810964584350586
Validation loss: 2.033732530891254

Epoch: 6| Step: 12
Training loss: 2.6937975883483887
Validation loss: 2.009693823834901

Epoch: 6| Step: 13
Training loss: 2.4071836471557617
Validation loss: 2.030941945250316

Epoch: 100| Step: 0
Training loss: 2.7396602630615234
Validation loss: 2.0261726353758123

Epoch: 6| Step: 1
Training loss: 2.6635117530822754
Validation loss: 1.9800788112865981

Epoch: 6| Step: 2
Training loss: 1.746890902519226
Validation loss: 2.023045304001019

Epoch: 6| Step: 3
Training loss: 2.174600124359131
Validation loss: 2.02019416645009

Epoch: 6| Step: 4
Training loss: 1.9952009916305542
Validation loss: 2.0195048239923294

Epoch: 6| Step: 5
Training loss: 1.8825335502624512
Validation loss: 2.006284334326303

Epoch: 6| Step: 6
Training loss: 2.0213794708251953
Validation loss: 1.9860731273569086

Epoch: 6| Step: 7
Training loss: 2.8096559047698975
Validation loss: 1.9794694198075162

Epoch: 6| Step: 8
Training loss: 2.2040791511535645
Validation loss: 2.0343295656224734

Epoch: 6| Step: 9
Training loss: 1.5298408269882202
Validation loss: 2.025526059571133

Epoch: 6| Step: 10
Training loss: 2.69873309135437
Validation loss: 2.022079062718217

Epoch: 6| Step: 11
Training loss: 2.6831276416778564
Validation loss: 2.0400231140916065

Epoch: 6| Step: 12
Training loss: 1.776942253112793
Validation loss: 1.999475606026188

Epoch: 6| Step: 13
Training loss: 2.6747195720672607
Validation loss: 2.024010876173614

Epoch: 101| Step: 0
Training loss: 1.9631731510162354
Validation loss: 2.0058235353039158

Epoch: 6| Step: 1
Training loss: 2.6595654487609863
Validation loss: 1.9857736749033774

Epoch: 6| Step: 2
Training loss: 2.379486322402954
Validation loss: 1.9978686096847698

Epoch: 6| Step: 3
Training loss: 1.7599639892578125
Validation loss: 2.0225216381011473

Epoch: 6| Step: 4
Training loss: 2.203765392303467
Validation loss: 2.0179024691222818

Epoch: 6| Step: 5
Training loss: 1.8332949876785278
Validation loss: 2.0077979962031045

Epoch: 6| Step: 6
Training loss: 2.146256685256958
Validation loss: 2.0002179132994784

Epoch: 6| Step: 7
Training loss: 2.6103875637054443
Validation loss: 2.0050713054595457

Epoch: 6| Step: 8
Training loss: 2.44096040725708
Validation loss: 1.9844422776211974

Epoch: 6| Step: 9
Training loss: 2.559962749481201
Validation loss: 2.0284821846151866

Epoch: 6| Step: 10
Training loss: 2.3930530548095703
Validation loss: 1.9862514670177172

Epoch: 6| Step: 11
Training loss: 2.4703054428100586
Validation loss: 2.000389874622386

Epoch: 6| Step: 12
Training loss: 1.947946548461914
Validation loss: 2.0039289356559835

Epoch: 6| Step: 13
Training loss: 1.8319517374038696
Validation loss: 1.9641076621188913

Epoch: 102| Step: 0
Training loss: 2.267916202545166
Validation loss: 2.001963887163388

Epoch: 6| Step: 1
Training loss: 2.0411477088928223
Validation loss: 2.00852144405406

Epoch: 6| Step: 2
Training loss: 2.4040372371673584
Validation loss: 1.9846459293878207

Epoch: 6| Step: 3
Training loss: 3.233611583709717
Validation loss: 1.9631333748499553

Epoch: 6| Step: 4
Training loss: 1.7460227012634277
Validation loss: 2.0103304975776264

Epoch: 6| Step: 5
Training loss: 2.180387496948242
Validation loss: 2.0018004832729215

Epoch: 6| Step: 6
Training loss: 2.119157552719116
Validation loss: 1.9885469867337136

Epoch: 6| Step: 7
Training loss: 2.368741989135742
Validation loss: 2.0046247205426617

Epoch: 6| Step: 8
Training loss: 2.0775249004364014
Validation loss: 2.0084732271009877

Epoch: 6| Step: 9
Training loss: 2.3329854011535645
Validation loss: 1.9811556659718996

Epoch: 6| Step: 10
Training loss: 2.1180193424224854
Validation loss: 2.008237482399069

Epoch: 6| Step: 11
Training loss: 2.0097713470458984
Validation loss: 1.9908873111970964

Epoch: 6| Step: 12
Training loss: 2.270611524581909
Validation loss: 1.998356052624282

Epoch: 6| Step: 13
Training loss: 2.322456121444702
Validation loss: 1.9796967519226896

Epoch: 103| Step: 0
Training loss: 2.3292603492736816
Validation loss: 1.98846939814988

Epoch: 6| Step: 1
Training loss: 1.7335395812988281
Validation loss: 2.009887067220544

Epoch: 6| Step: 2
Training loss: 2.459920883178711
Validation loss: 1.9969268703973422

Epoch: 6| Step: 3
Training loss: 2.7546937465667725
Validation loss: 1.9781124848191456

Epoch: 6| Step: 4
Training loss: 2.4834465980529785
Validation loss: 1.9872226856088127

Epoch: 6| Step: 5
Training loss: 1.4507880210876465
Validation loss: 1.9736262111253635

Epoch: 6| Step: 6
Training loss: 2.432952404022217
Validation loss: 2.009165302399666

Epoch: 6| Step: 7
Training loss: 2.09145188331604
Validation loss: 1.98380906351151

Epoch: 6| Step: 8
Training loss: 2.297048568725586
Validation loss: 1.965500154802876

Epoch: 6| Step: 9
Training loss: 1.7876684665679932
Validation loss: 1.9796863755872172

Epoch: 6| Step: 10
Training loss: 2.763967990875244
Validation loss: 1.982415376170989

Epoch: 6| Step: 11
Training loss: 1.9985510110855103
Validation loss: 2.0089984606671076

Epoch: 6| Step: 12
Training loss: 1.8382620811462402
Validation loss: 1.9768385989691621

Epoch: 6| Step: 13
Training loss: 3.2750887870788574
Validation loss: 1.9668536929674045

Epoch: 104| Step: 0
Training loss: 2.306091547012329
Validation loss: 2.0317006623873146

Epoch: 6| Step: 1
Training loss: 1.585985779762268
Validation loss: 2.0034449510676886

Epoch: 6| Step: 2
Training loss: 2.3424415588378906
Validation loss: 1.9973201918345627

Epoch: 6| Step: 3
Training loss: 1.9301612377166748
Validation loss: 2.0197882165190992

Epoch: 6| Step: 4
Training loss: 2.739434242248535
Validation loss: 2.0103704954988215

Epoch: 6| Step: 5
Training loss: 2.1557767391204834
Validation loss: 1.9776158550734162

Epoch: 6| Step: 6
Training loss: 2.068516731262207
Validation loss: 1.9427345721952376

Epoch: 6| Step: 7
Training loss: 2.5055317878723145
Validation loss: 1.9828171781314317

Epoch: 6| Step: 8
Training loss: 3.214970827102661
Validation loss: 2.0128176955766577

Epoch: 6| Step: 9
Training loss: 1.9108021259307861
Validation loss: 1.9682599575288835

Epoch: 6| Step: 10
Training loss: 2.3010292053222656
Validation loss: 1.9803232557030135

Epoch: 6| Step: 11
Training loss: 1.701355218887329
Validation loss: 1.9887792474480086

Epoch: 6| Step: 12
Training loss: 2.1059458255767822
Validation loss: 1.9751749089969102

Epoch: 6| Step: 13
Training loss: 2.570399284362793
Validation loss: 2.0100725671296478

Epoch: 105| Step: 0
Training loss: 2.252448797225952
Validation loss: 1.9641291659365419

Epoch: 6| Step: 1
Training loss: 2.669543743133545
Validation loss: 2.011914017379925

Epoch: 6| Step: 2
Training loss: 2.2019591331481934
Validation loss: 1.99106764793396

Epoch: 6| Step: 3
Training loss: 2.336007595062256
Validation loss: 2.0181806484858194

Epoch: 6| Step: 4
Training loss: 1.3211560249328613
Validation loss: 2.0011269379687566

Epoch: 6| Step: 5
Training loss: 2.404266595840454
Validation loss: 1.993897916168295

Epoch: 6| Step: 6
Training loss: 2.634232521057129
Validation loss: 2.009130170268397

Epoch: 6| Step: 7
Training loss: 2.0963358879089355
Validation loss: 1.9826533743130264

Epoch: 6| Step: 8
Training loss: 1.4022150039672852
Validation loss: 1.9991598924001057

Epoch: 6| Step: 9
Training loss: 1.9138692617416382
Validation loss: 1.9931264180009083

Epoch: 6| Step: 10
Training loss: 2.611024856567383
Validation loss: 2.005382804460423

Epoch: 6| Step: 11
Training loss: 2.8501882553100586
Validation loss: 2.030110346373691

Epoch: 6| Step: 12
Training loss: 2.472529411315918
Validation loss: 1.9899659925891506

Epoch: 6| Step: 13
Training loss: 1.6123144626617432
Validation loss: 2.009955834316951

Epoch: 106| Step: 0
Training loss: 2.62868070602417
Validation loss: 2.015084662745076

Epoch: 6| Step: 1
Training loss: 1.6362955570220947
Validation loss: 1.9981640436316048

Epoch: 6| Step: 2
Training loss: 2.129729986190796
Validation loss: 1.957608558798349

Epoch: 6| Step: 3
Training loss: 2.524508476257324
Validation loss: 1.985604392584934

Epoch: 6| Step: 4
Training loss: 1.9982147216796875
Validation loss: 2.0159666653602355

Epoch: 6| Step: 5
Training loss: 1.819728136062622
Validation loss: 1.9686310060562626

Epoch: 6| Step: 6
Training loss: 3.207639217376709
Validation loss: 2.0070370166532454

Epoch: 6| Step: 7
Training loss: 2.272629976272583
Validation loss: 1.982031371003838

Epoch: 6| Step: 8
Training loss: 1.7584816217422485
Validation loss: 1.9905657229884979

Epoch: 6| Step: 9
Training loss: 2.1941375732421875
Validation loss: 1.988911049340361

Epoch: 6| Step: 10
Training loss: 2.7079689502716064
Validation loss: 2.0156399972977175

Epoch: 6| Step: 11
Training loss: 1.8360874652862549
Validation loss: 1.9780880584511706

Epoch: 6| Step: 12
Training loss: 1.925216555595398
Validation loss: 1.9772930798992034

Epoch: 6| Step: 13
Training loss: 2.39788818359375
Validation loss: 2.0296029403645504

Epoch: 107| Step: 0
Training loss: 2.4971108436584473
Validation loss: 1.9798884814785374

Epoch: 6| Step: 1
Training loss: 2.259906053543091
Validation loss: 1.966999884574644

Epoch: 6| Step: 2
Training loss: 2.3187222480773926
Validation loss: 2.0379844711672876

Epoch: 6| Step: 3
Training loss: 2.2224721908569336
Validation loss: 1.9704768952503

Epoch: 6| Step: 4
Training loss: 2.348935604095459
Validation loss: 2.006219499854631

Epoch: 6| Step: 5
Training loss: 2.1874008178710938
Validation loss: 1.9886151898291804

Epoch: 6| Step: 6
Training loss: 2.2689566612243652
Validation loss: 1.9557916131070865

Epoch: 6| Step: 7
Training loss: 1.561318039894104
Validation loss: 1.9874384505774385

Epoch: 6| Step: 8
Training loss: 2.1193528175354004
Validation loss: 1.9906169035101449

Epoch: 6| Step: 9
Training loss: 2.804258346557617
Validation loss: 1.9917160336689284

Epoch: 6| Step: 10
Training loss: 2.2161102294921875
Validation loss: 1.9986143830001994

Epoch: 6| Step: 11
Training loss: 1.6889433860778809
Validation loss: 1.9763027724399362

Epoch: 6| Step: 12
Training loss: 2.4004931449890137
Validation loss: 1.967835771140232

Epoch: 6| Step: 13
Training loss: 2.0347564220428467
Validation loss: 1.9947833181709371

Epoch: 108| Step: 0
Training loss: 2.0319085121154785
Validation loss: 1.994271828282264

Epoch: 6| Step: 1
Training loss: 1.884074091911316
Validation loss: 1.977020586690595

Epoch: 6| Step: 2
Training loss: 2.7101964950561523
Validation loss: 1.9740408953799997

Epoch: 6| Step: 3
Training loss: 2.146953821182251
Validation loss: 1.9626989441533242

Epoch: 6| Step: 4
Training loss: 1.7671579122543335
Validation loss: 1.9676841228238997

Epoch: 6| Step: 5
Training loss: 2.5633890628814697
Validation loss: 1.9720927156427854

Epoch: 6| Step: 6
Training loss: 2.0773513317108154
Validation loss: 1.9753473061387257

Epoch: 6| Step: 7
Training loss: 1.7498345375061035
Validation loss: 2.030569604648057

Epoch: 6| Step: 8
Training loss: 2.154524564743042
Validation loss: 1.985453450551597

Epoch: 6| Step: 9
Training loss: 2.4273664951324463
Validation loss: 2.0119332062300814

Epoch: 6| Step: 10
Training loss: 2.126904010772705
Validation loss: 2.001842248824335

Epoch: 6| Step: 11
Training loss: 2.3320372104644775
Validation loss: 2.0168026083259174

Epoch: 6| Step: 12
Training loss: 2.638807773590088
Validation loss: 2.015387217203776

Epoch: 6| Step: 13
Training loss: 2.283506155014038
Validation loss: 2.0043133433147142

Epoch: 109| Step: 0
Training loss: 1.9238362312316895
Validation loss: 2.009034813091319

Epoch: 6| Step: 1
Training loss: 2.845590591430664
Validation loss: 1.9977431117847402

Epoch: 6| Step: 2
Training loss: 2.7600302696228027
Validation loss: 1.9935768637605893

Epoch: 6| Step: 3
Training loss: 2.0386860370635986
Validation loss: 1.9733491636091662

Epoch: 6| Step: 4
Training loss: 1.9105339050292969
Validation loss: 2.009140295367087

Epoch: 6| Step: 5
Training loss: 1.9620554447174072
Validation loss: 1.9853874457779752

Epoch: 6| Step: 6
Training loss: 1.856292724609375
Validation loss: 1.9966918537693639

Epoch: 6| Step: 7
Training loss: 2.5452256202697754
Validation loss: 1.9866556480366697

Epoch: 6| Step: 8
Training loss: 2.566091775894165
Validation loss: 1.9902952653105541

Epoch: 6| Step: 9
Training loss: 1.9783097505569458
Validation loss: 1.982280017227255

Epoch: 6| Step: 10
Training loss: 1.9652869701385498
Validation loss: 1.9912607208375008

Epoch: 6| Step: 11
Training loss: 2.2716336250305176
Validation loss: 1.9419071084709578

Epoch: 6| Step: 12
Training loss: 2.0023818016052246
Validation loss: 1.9705737470298685

Epoch: 6| Step: 13
Training loss: 2.366077423095703
Validation loss: 1.992983692435808

Epoch: 110| Step: 0
Training loss: 1.9952561855316162
Validation loss: 1.9755950973879906

Epoch: 6| Step: 1
Training loss: 2.2276692390441895
Validation loss: 1.9636624205497004

Epoch: 6| Step: 2
Training loss: 2.0371413230895996
Validation loss: 2.000743655748265

Epoch: 6| Step: 3
Training loss: 2.1989083290100098
Validation loss: 1.9571601959966844

Epoch: 6| Step: 4
Training loss: 2.3202948570251465
Validation loss: 1.9564358457442252

Epoch: 6| Step: 5
Training loss: 1.8248142004013062
Validation loss: 2.013321071542719

Epoch: 6| Step: 6
Training loss: 2.1975882053375244
Validation loss: 1.974862184575809

Epoch: 6| Step: 7
Training loss: 2.7448179721832275
Validation loss: 1.9878920073150306

Epoch: 6| Step: 8
Training loss: 1.771780014038086
Validation loss: 1.9928212178650724

Epoch: 6| Step: 9
Training loss: 1.8962808847427368
Validation loss: 2.0021653867536977

Epoch: 6| Step: 10
Training loss: 2.321983814239502
Validation loss: 2.0106411287861485

Epoch: 6| Step: 11
Training loss: 2.5250775814056396
Validation loss: 1.9833727152116838

Epoch: 6| Step: 12
Training loss: 2.6137304306030273
Validation loss: 1.9719796193543302

Epoch: 6| Step: 13
Training loss: 2.31939435005188
Validation loss: 1.971389239834201

Epoch: 111| Step: 0
Training loss: 1.1455103158950806
Validation loss: 1.9951766178172121

Epoch: 6| Step: 1
Training loss: 2.327674388885498
Validation loss: 1.9808092283946213

Epoch: 6| Step: 2
Training loss: 2.1880698204040527
Validation loss: 1.988135294247699

Epoch: 6| Step: 3
Training loss: 2.8671185970306396
Validation loss: 2.0085398612483853

Epoch: 6| Step: 4
Training loss: 1.9664663076400757
Validation loss: 2.0000269848813295

Epoch: 6| Step: 5
Training loss: 2.2390716075897217
Validation loss: 2.023224505045081

Epoch: 6| Step: 6
Training loss: 2.408952474594116
Validation loss: 1.9926137552466443

Epoch: 6| Step: 7
Training loss: 1.881345510482788
Validation loss: 1.9682004144114833

Epoch: 6| Step: 8
Training loss: 2.041764736175537
Validation loss: 2.0045745321499404

Epoch: 6| Step: 9
Training loss: 2.318922519683838
Validation loss: 2.0154704368242653

Epoch: 6| Step: 10
Training loss: 2.545257568359375
Validation loss: 1.9890329376343758

Epoch: 6| Step: 11
Training loss: 1.8834125995635986
Validation loss: 2.015491739396126

Epoch: 6| Step: 12
Training loss: 2.583470106124878
Validation loss: 2.0237568937322146

Epoch: 6| Step: 13
Training loss: 2.093142509460449
Validation loss: 2.003196608635687

Epoch: 112| Step: 0
Training loss: 2.9712905883789062
Validation loss: 2.0015694979698426

Epoch: 6| Step: 1
Training loss: 2.6377482414245605
Validation loss: 2.00948832368338

Epoch: 6| Step: 2
Training loss: 2.3790555000305176
Validation loss: 2.0463383159329815

Epoch: 6| Step: 3
Training loss: 1.7290499210357666
Validation loss: 2.0341581401004585

Epoch: 6| Step: 4
Training loss: 2.3944690227508545
Validation loss: 1.9949115848028531

Epoch: 6| Step: 5
Training loss: 2.072518825531006
Validation loss: 1.9970045448631368

Epoch: 6| Step: 6
Training loss: 1.2793068885803223
Validation loss: 2.0172849932024555

Epoch: 6| Step: 7
Training loss: 2.6084492206573486
Validation loss: 2.017848168649981

Epoch: 6| Step: 8
Training loss: 2.368466854095459
Validation loss: 1.9812794270053986

Epoch: 6| Step: 9
Training loss: 2.0776095390319824
Validation loss: 2.008094446633452

Epoch: 6| Step: 10
Training loss: 2.386396884918213
Validation loss: 2.009180630407026

Epoch: 6| Step: 11
Training loss: 2.098879337310791
Validation loss: 2.0320816116948284

Epoch: 6| Step: 12
Training loss: 1.672776460647583
Validation loss: 2.0000823505463137

Epoch: 6| Step: 13
Training loss: 2.3233609199523926
Validation loss: 2.011368969435333

Epoch: 113| Step: 0
Training loss: 2.7728469371795654
Validation loss: 2.02650729046073

Epoch: 6| Step: 1
Training loss: 2.207808017730713
Validation loss: 2.022095931473599

Epoch: 6| Step: 2
Training loss: 2.157804012298584
Validation loss: 1.996572841880142

Epoch: 6| Step: 3
Training loss: 3.3276824951171875
Validation loss: 1.9836854473237069

Epoch: 6| Step: 4
Training loss: 2.063199996948242
Validation loss: 2.0026323846591416

Epoch: 6| Step: 5
Training loss: 2.0437211990356445
Validation loss: 1.9778107366254252

Epoch: 6| Step: 6
Training loss: 2.2708702087402344
Validation loss: 2.0116975768919914

Epoch: 6| Step: 7
Training loss: 2.064223051071167
Validation loss: 1.991851137530419

Epoch: 6| Step: 8
Training loss: 2.1843762397766113
Validation loss: 1.986196223125663

Epoch: 6| Step: 9
Training loss: 1.5938372611999512
Validation loss: 2.0139400805196455

Epoch: 6| Step: 10
Training loss: 2.868030071258545
Validation loss: 1.9976561505307433

Epoch: 6| Step: 11
Training loss: 1.7289718389511108
Validation loss: 2.007133715896196

Epoch: 6| Step: 12
Training loss: 1.7590973377227783
Validation loss: 1.9956020642352361

Epoch: 6| Step: 13
Training loss: 1.4596630334854126
Validation loss: 2.0014148078938967

Epoch: 114| Step: 0
Training loss: 1.8694233894348145
Validation loss: 2.0008859224216913

Epoch: 6| Step: 1
Training loss: 2.633078098297119
Validation loss: 1.9652886031776347

Epoch: 6| Step: 2
Training loss: 2.1821913719177246
Validation loss: 1.992476232590214

Epoch: 6| Step: 3
Training loss: 2.106045961380005
Validation loss: 2.001231872907249

Epoch: 6| Step: 4
Training loss: 2.378358840942383
Validation loss: 1.975328233934218

Epoch: 6| Step: 5
Training loss: 1.9374221563339233
Validation loss: 2.014730158672538

Epoch: 6| Step: 6
Training loss: 2.74428653717041
Validation loss: 1.987577769064134

Epoch: 6| Step: 7
Training loss: 2.598723888397217
Validation loss: 2.0131966708808817

Epoch: 6| Step: 8
Training loss: 2.5346803665161133
Validation loss: 2.000321119062362

Epoch: 6| Step: 9
Training loss: 2.1375722885131836
Validation loss: 2.006785541452387

Epoch: 6| Step: 10
Training loss: 1.8220365047454834
Validation loss: 2.0158587296803794

Epoch: 6| Step: 11
Training loss: 2.1455600261688232
Validation loss: 2.0082959962147537

Epoch: 6| Step: 12
Training loss: 1.1965527534484863
Validation loss: 2.0223286869705364

Epoch: 6| Step: 13
Training loss: 2.519596815109253
Validation loss: 2.0241205961473527

Epoch: 115| Step: 0
Training loss: 2.0357604026794434
Validation loss: 2.0097878210006224

Epoch: 6| Step: 1
Training loss: 2.2846481800079346
Validation loss: 2.048145373662313

Epoch: 6| Step: 2
Training loss: 2.8942971229553223
Validation loss: 2.023490974980016

Epoch: 6| Step: 3
Training loss: 1.9161338806152344
Validation loss: 2.0177252164451023

Epoch: 6| Step: 4
Training loss: 1.845373511314392
Validation loss: 2.0028924198560816

Epoch: 6| Step: 5
Training loss: 1.6829819679260254
Validation loss: 2.028764719604164

Epoch: 6| Step: 6
Training loss: 1.6953656673431396
Validation loss: 2.001681343201668

Epoch: 6| Step: 7
Training loss: 1.9891337156295776
Validation loss: 2.017371323800856

Epoch: 6| Step: 8
Training loss: 2.192434072494507
Validation loss: 1.9739532445066719

Epoch: 6| Step: 9
Training loss: 2.5832200050354004
Validation loss: 2.005132791816547

Epoch: 6| Step: 10
Training loss: 2.5113096237182617
Validation loss: 2.017461556260304

Epoch: 6| Step: 11
Training loss: 1.9787566661834717
Validation loss: 2.038342391290972

Epoch: 6| Step: 12
Training loss: 2.0692806243896484
Validation loss: 2.039138727290656

Epoch: 6| Step: 13
Training loss: 3.48343825340271
Validation loss: 2.0033319996249292

Epoch: 116| Step: 0
Training loss: 2.9288747310638428
Validation loss: 2.0202347386267876

Epoch: 6| Step: 1
Training loss: 2.2785425186157227
Validation loss: 2.0038276513417563

Epoch: 6| Step: 2
Training loss: 1.8793370723724365
Validation loss: 2.022578500932263

Epoch: 6| Step: 3
Training loss: 2.5720620155334473
Validation loss: 2.0387554912156958

Epoch: 6| Step: 4
Training loss: 1.8483060598373413
Validation loss: 2.003484402933428

Epoch: 6| Step: 5
Training loss: 1.6008909940719604
Validation loss: 1.9754463498310377

Epoch: 6| Step: 6
Training loss: 1.5549100637435913
Validation loss: 2.0258160496270783

Epoch: 6| Step: 7
Training loss: 2.446417808532715
Validation loss: 2.0175377066417406

Epoch: 6| Step: 8
Training loss: 2.4528353214263916
Validation loss: 2.0441371176832464

Epoch: 6| Step: 9
Training loss: 1.6814773082733154
Validation loss: 2.040861811689151

Epoch: 6| Step: 10
Training loss: 2.0010151863098145
Validation loss: 2.0240068281850507

Epoch: 6| Step: 11
Training loss: 2.618765354156494
Validation loss: 2.0070913837802027

Epoch: 6| Step: 12
Training loss: 2.808037281036377
Validation loss: 2.003860673596782

Epoch: 6| Step: 13
Training loss: 2.1573705673217773
Validation loss: 2.0230393294365174

Epoch: 117| Step: 0
Training loss: 2.2025146484375
Validation loss: 2.009312052880564

Epoch: 6| Step: 1
Training loss: 1.8655872344970703
Validation loss: 1.9946983552748156

Epoch: 6| Step: 2
Training loss: 1.900618553161621
Validation loss: 1.993188060739989

Epoch: 6| Step: 3
Training loss: 1.5367703437805176
Validation loss: 2.009296417236328

Epoch: 6| Step: 4
Training loss: 2.3107988834381104
Validation loss: 2.004660144928963

Epoch: 6| Step: 5
Training loss: 2.0763754844665527
Validation loss: 1.9768439979963406

Epoch: 6| Step: 6
Training loss: 1.8874280452728271
Validation loss: 1.9930177837289789

Epoch: 6| Step: 7
Training loss: 2.320950984954834
Validation loss: 1.9833604071729927

Epoch: 6| Step: 8
Training loss: 2.5372061729431152
Validation loss: 1.9894025518048195

Epoch: 6| Step: 9
Training loss: 2.758612632751465
Validation loss: 1.9844993955345565

Epoch: 6| Step: 10
Training loss: 2.4479377269744873
Validation loss: 1.9572305474230038

Epoch: 6| Step: 11
Training loss: 2.746345281600952
Validation loss: 1.985264834537301

Epoch: 6| Step: 12
Training loss: 2.0460052490234375
Validation loss: 1.984902802334037

Epoch: 6| Step: 13
Training loss: 2.001068592071533
Validation loss: 2.012799101491128

Epoch: 118| Step: 0
Training loss: 1.7976458072662354
Validation loss: 2.0016660023761053

Epoch: 6| Step: 1
Training loss: 2.2911014556884766
Validation loss: 1.9950105015949537

Epoch: 6| Step: 2
Training loss: 2.0894205570220947
Validation loss: 2.0057127629556963

Epoch: 6| Step: 3
Training loss: 2.438497304916382
Validation loss: 1.9586230836888796

Epoch: 6| Step: 4
Training loss: 2.5608160495758057
Validation loss: 2.0043017505317606

Epoch: 6| Step: 5
Training loss: 1.8892854452133179
Validation loss: 1.9936792568493915

Epoch: 6| Step: 6
Training loss: 1.4912152290344238
Validation loss: 1.9962467839640956

Epoch: 6| Step: 7
Training loss: 2.0980310440063477
Validation loss: 2.0004881787043747

Epoch: 6| Step: 8
Training loss: 1.7813694477081299
Validation loss: 2.032622306577621

Epoch: 6| Step: 9
Training loss: 1.5576438903808594
Validation loss: 1.9949680579605924

Epoch: 6| Step: 10
Training loss: 2.6938743591308594
Validation loss: 2.02388410927147

Epoch: 6| Step: 11
Training loss: 3.0150418281555176
Validation loss: 2.005135259320659

Epoch: 6| Step: 12
Training loss: 2.138263702392578
Validation loss: 1.998014917937658

Epoch: 6| Step: 13
Training loss: 2.633216381072998
Validation loss: 2.001924219951835

Epoch: 119| Step: 0
Training loss: 1.808285117149353
Validation loss: 2.015220859999298

Epoch: 6| Step: 1
Training loss: 2.7160825729370117
Validation loss: 2.02274755508669

Epoch: 6| Step: 2
Training loss: 2.3552141189575195
Validation loss: 2.0042954644849225

Epoch: 6| Step: 3
Training loss: 2.0237433910369873
Validation loss: 2.014484518317766

Epoch: 6| Step: 4
Training loss: 2.255998134613037
Validation loss: 1.9791671012037544

Epoch: 6| Step: 5
Training loss: 2.440891981124878
Validation loss: 1.991929026060207

Epoch: 6| Step: 6
Training loss: 3.1783628463745117
Validation loss: 1.9941489465775029

Epoch: 6| Step: 7
Training loss: 1.652694582939148
Validation loss: 2.021411334314654

Epoch: 6| Step: 8
Training loss: 1.6886714696884155
Validation loss: 2.012234846750895

Epoch: 6| Step: 9
Training loss: 2.3270082473754883
Validation loss: 2.0428681476141817

Epoch: 6| Step: 10
Training loss: 2.4208335876464844
Validation loss: 2.065860418863194

Epoch: 6| Step: 11
Training loss: 1.4164572954177856
Validation loss: 2.0075440637526976

Epoch: 6| Step: 12
Training loss: 2.19968318939209
Validation loss: 2.007171029685646

Epoch: 6| Step: 13
Training loss: 1.9109880924224854
Validation loss: 2.016592994812996

Epoch: 120| Step: 0
Training loss: 2.6192848682403564
Validation loss: 1.9826930299881966

Epoch: 6| Step: 1
Training loss: 1.8509190082550049
Validation loss: 2.0238838093255156

Epoch: 6| Step: 2
Training loss: 2.5869107246398926
Validation loss: 2.020126309446109

Epoch: 6| Step: 3
Training loss: 2.788527011871338
Validation loss: 2.0072380547882407

Epoch: 6| Step: 4
Training loss: 2.0306594371795654
Validation loss: 2.0132038106200514

Epoch: 6| Step: 5
Training loss: 1.8405250310897827
Validation loss: 1.9720323419058194

Epoch: 6| Step: 6
Training loss: 1.6379857063293457
Validation loss: 2.00210081120973

Epoch: 6| Step: 7
Training loss: 2.5048749446868896
Validation loss: 2.033840323007235

Epoch: 6| Step: 8
Training loss: 2.164377212524414
Validation loss: 2.0411231902337845

Epoch: 6| Step: 9
Training loss: 1.7779244184494019
Validation loss: 2.041608352814951

Epoch: 6| Step: 10
Training loss: 1.7396962642669678
Validation loss: 2.027627347618021

Epoch: 6| Step: 11
Training loss: 2.251857280731201
Validation loss: 2.0164985182464763

Epoch: 6| Step: 12
Training loss: 2.256819248199463
Validation loss: 2.0179207158345047

Epoch: 6| Step: 13
Training loss: 2.812310218811035
Validation loss: 2.027461010922668

Epoch: 121| Step: 0
Training loss: 2.739928722381592
Validation loss: 2.0397508875016244

Epoch: 6| Step: 1
Training loss: 2.3239264488220215
Validation loss: 1.9840353432522024

Epoch: 6| Step: 2
Training loss: 2.1514716148376465
Validation loss: 1.9823897743737826

Epoch: 6| Step: 3
Training loss: 3.1492607593536377
Validation loss: 2.011251805931009

Epoch: 6| Step: 4
Training loss: 2.334054470062256
Validation loss: 1.9670215460561937

Epoch: 6| Step: 5
Training loss: 2.2760632038116455
Validation loss: 2.0188708305358887

Epoch: 6| Step: 6
Training loss: 2.4418516159057617
Validation loss: 1.970627264309955

Epoch: 6| Step: 7
Training loss: 2.3097283840179443
Validation loss: 2.0010982713391705

Epoch: 6| Step: 8
Training loss: 1.4697439670562744
Validation loss: 1.983612081056

Epoch: 6| Step: 9
Training loss: 1.619410514831543
Validation loss: 2.02399645697686

Epoch: 6| Step: 10
Training loss: 1.6310595273971558
Validation loss: 2.012152241122338

Epoch: 6| Step: 11
Training loss: 2.1490583419799805
Validation loss: 2.040089948202974

Epoch: 6| Step: 12
Training loss: 2.1633248329162598
Validation loss: 1.9805157607601536

Epoch: 6| Step: 13
Training loss: 1.2836834192276
Validation loss: 2.0252892663401942

Epoch: 122| Step: 0
Training loss: 2.0302953720092773
Validation loss: 2.01515402460611

Epoch: 6| Step: 1
Training loss: 2.732579231262207
Validation loss: 2.0086709760850474

Epoch: 6| Step: 2
Training loss: 1.4132392406463623
Validation loss: 2.0245700087598575

Epoch: 6| Step: 3
Training loss: 1.788468599319458
Validation loss: 2.0069575489208265

Epoch: 6| Step: 4
Training loss: 2.0148401260375977
Validation loss: 2.0074419411279822

Epoch: 6| Step: 5
Training loss: 1.8261343240737915
Validation loss: 2.0306034882863364

Epoch: 6| Step: 6
Training loss: 2.846750259399414
Validation loss: 1.9744519187558083

Epoch: 6| Step: 7
Training loss: 2.4494333267211914
Validation loss: 2.013357318857665

Epoch: 6| Step: 8
Training loss: 2.605306625366211
Validation loss: 2.0510502425573205

Epoch: 6| Step: 9
Training loss: 2.37605619430542
Validation loss: 1.9878804247866395

Epoch: 6| Step: 10
Training loss: 2.1954424381256104
Validation loss: 2.0171064215321697

Epoch: 6| Step: 11
Training loss: 1.3730173110961914
Validation loss: 2.001766238161313

Epoch: 6| Step: 12
Training loss: 2.7932991981506348
Validation loss: 1.9829598472964378

Epoch: 6| Step: 13
Training loss: 1.67816960811615
Validation loss: 1.982893959168465

Epoch: 123| Step: 0
Training loss: 1.731682300567627
Validation loss: 1.9989663067684378

Epoch: 6| Step: 1
Training loss: 2.695159912109375
Validation loss: 2.0179793655231433

Epoch: 6| Step: 2
Training loss: 2.520838499069214
Validation loss: 1.985739020891087

Epoch: 6| Step: 3
Training loss: 2.9205095767974854
Validation loss: 2.020805897251252

Epoch: 6| Step: 4
Training loss: 2.476958751678467
Validation loss: 1.9659963871843071

Epoch: 6| Step: 5
Training loss: 1.6275635957717896
Validation loss: 2.016669201594527

Epoch: 6| Step: 6
Training loss: 1.6641039848327637
Validation loss: 1.978273509651102

Epoch: 6| Step: 7
Training loss: 1.8777382373809814
Validation loss: 1.996468650397434

Epoch: 6| Step: 8
Training loss: 2.074352741241455
Validation loss: 1.9800350307136454

Epoch: 6| Step: 9
Training loss: 1.6670150756835938
Validation loss: 1.9595712231051536

Epoch: 6| Step: 10
Training loss: 2.165703773498535
Validation loss: 1.9662071863810222

Epoch: 6| Step: 11
Training loss: 2.4301156997680664
Validation loss: 1.978246868297618

Epoch: 6| Step: 12
Training loss: 2.7890992164611816
Validation loss: 1.9721494951555807

Epoch: 6| Step: 13
Training loss: 2.05332088470459
Validation loss: 1.9841568880183722

Epoch: 124| Step: 0
Training loss: 2.856659173965454
Validation loss: 2.0125022934329126

Epoch: 6| Step: 1
Training loss: 1.944325566291809
Validation loss: 1.9779697284903577

Epoch: 6| Step: 2
Training loss: 2.3522303104400635
Validation loss: 1.9632545030245216

Epoch: 6| Step: 3
Training loss: 2.0158133506774902
Validation loss: 2.003290744238002

Epoch: 6| Step: 4
Training loss: 2.236703395843506
Validation loss: 1.9810467304721955

Epoch: 6| Step: 5
Training loss: 2.048612594604492
Validation loss: 2.025929641979997

Epoch: 6| Step: 6
Training loss: 2.34403133392334
Validation loss: 2.0013125878508373

Epoch: 6| Step: 7
Training loss: 1.931896448135376
Validation loss: 2.0127552440089564

Epoch: 6| Step: 8
Training loss: 1.9274241924285889
Validation loss: 1.9945152639060892

Epoch: 6| Step: 9
Training loss: 2.300321102142334
Validation loss: 2.0095028928531113

Epoch: 6| Step: 10
Training loss: 1.750398874282837
Validation loss: 2.0468144634718537

Epoch: 6| Step: 11
Training loss: 2.2521464824676514
Validation loss: 1.9963525367039505

Epoch: 6| Step: 12
Training loss: 2.607267379760742
Validation loss: 1.9577349116725307

Epoch: 6| Step: 13
Training loss: 1.8235280513763428
Validation loss: 1.9687142243949316

Epoch: 125| Step: 0
Training loss: 2.0083816051483154
Validation loss: 2.010491125045284

Epoch: 6| Step: 1
Training loss: 2.095066547393799
Validation loss: 1.9892683234266055

Epoch: 6| Step: 2
Training loss: 2.8343887329101562
Validation loss: 2.00354600978154

Epoch: 6| Step: 3
Training loss: 1.703187108039856
Validation loss: 2.021901592131584

Epoch: 6| Step: 4
Training loss: 1.8380868434906006
Validation loss: 1.9908143269118441

Epoch: 6| Step: 5
Training loss: 2.2947237491607666
Validation loss: 2.052281375854246

Epoch: 6| Step: 6
Training loss: 2.110041379928589
Validation loss: 2.0393154134032545

Epoch: 6| Step: 7
Training loss: 1.8493205308914185
Validation loss: 2.0348947343005928

Epoch: 6| Step: 8
Training loss: 2.405217409133911
Validation loss: 2.0179249919870847

Epoch: 6| Step: 9
Training loss: 1.4471616744995117
Validation loss: 2.0532925513482865

Epoch: 6| Step: 10
Training loss: 3.08449649810791
Validation loss: 2.0324156284332275

Epoch: 6| Step: 11
Training loss: 2.0131468772888184
Validation loss: 1.9925412875349804

Epoch: 6| Step: 12
Training loss: 2.1942594051361084
Validation loss: 2.0420944485613095

Epoch: 6| Step: 13
Training loss: 2.14634370803833
Validation loss: 2.006891191646617

Epoch: 126| Step: 0
Training loss: 2.2851362228393555
Validation loss: 2.013254557886431

Epoch: 6| Step: 1
Training loss: 3.274244546890259
Validation loss: 2.0219253647711968

Epoch: 6| Step: 2
Training loss: 1.5065332651138306
Validation loss: 2.0148758196061656

Epoch: 6| Step: 3
Training loss: 2.4406073093414307
Validation loss: 2.012607541135562

Epoch: 6| Step: 4
Training loss: 1.8891611099243164
Validation loss: 2.027777136013072

Epoch: 6| Step: 5
Training loss: 1.8022971153259277
Validation loss: 2.0269541355871383

Epoch: 6| Step: 6
Training loss: 2.040034294128418
Validation loss: 2.0148878168034297

Epoch: 6| Step: 7
Training loss: 2.171874523162842
Validation loss: 1.9978137990479827

Epoch: 6| Step: 8
Training loss: 1.4472105503082275
Validation loss: 2.0101986700488674

Epoch: 6| Step: 9
Training loss: 1.6090525388717651
Validation loss: 1.9933012852104761

Epoch: 6| Step: 10
Training loss: 2.0005576610565186
Validation loss: 2.003298673578488

Epoch: 6| Step: 11
Training loss: 2.816922426223755
Validation loss: 1.984774197301557

Epoch: 6| Step: 12
Training loss: 2.6760430335998535
Validation loss: 2.0003209139711116

Epoch: 6| Step: 13
Training loss: 2.381495475769043
Validation loss: 2.0060772229266424

Epoch: 127| Step: 0
Training loss: 1.9703707695007324
Validation loss: 1.9706008395841044

Epoch: 6| Step: 1
Training loss: 2.294210910797119
Validation loss: 2.0020242378275883

Epoch: 6| Step: 2
Training loss: 2.324690341949463
Validation loss: 2.006211285950035

Epoch: 6| Step: 3
Training loss: 1.9973368644714355
Validation loss: 1.9813617480698453

Epoch: 6| Step: 4
Training loss: 1.4573723077774048
Validation loss: 2.003947037522511

Epoch: 6| Step: 5
Training loss: 2.2578980922698975
Validation loss: 2.0090247995109967

Epoch: 6| Step: 6
Training loss: 2.158176898956299
Validation loss: 2.015093018931727

Epoch: 6| Step: 7
Training loss: 2.703126907348633
Validation loss: 1.9869829044547132

Epoch: 6| Step: 8
Training loss: 2.4218196868896484
Validation loss: 1.9835399273903138

Epoch: 6| Step: 9
Training loss: 1.9146255254745483
Validation loss: 2.015132957889188

Epoch: 6| Step: 10
Training loss: 2.5335516929626465
Validation loss: 1.9866049135884931

Epoch: 6| Step: 11
Training loss: 2.2052576541900635
Validation loss: 1.9972795683850524

Epoch: 6| Step: 12
Training loss: 1.8910720348358154
Validation loss: 1.9950691077017015

Epoch: 6| Step: 13
Training loss: 2.300001859664917
Validation loss: 2.001954327347458

Epoch: 128| Step: 0
Training loss: 2.916234254837036
Validation loss: 2.005232849428731

Epoch: 6| Step: 1
Training loss: 2.3602235317230225
Validation loss: 1.9816874432307419

Epoch: 6| Step: 2
Training loss: 2.3978042602539062
Validation loss: 1.975008632547112

Epoch: 6| Step: 3
Training loss: 2.2965598106384277
Validation loss: 2.00273790795316

Epoch: 6| Step: 4
Training loss: 1.879868984222412
Validation loss: 1.983842106275661

Epoch: 6| Step: 5
Training loss: 3.2360544204711914
Validation loss: 2.0103332137548797

Epoch: 6| Step: 6
Training loss: 2.489680767059326
Validation loss: 1.9977994811150335

Epoch: 6| Step: 7
Training loss: 2.0849833488464355
Validation loss: 1.9948545604623773

Epoch: 6| Step: 8
Training loss: 1.921938180923462
Validation loss: 2.007969275597603

Epoch: 6| Step: 9
Training loss: 1.4714492559432983
Validation loss: 2.0023331026877127

Epoch: 6| Step: 10
Training loss: 1.9678330421447754
Validation loss: 2.03760144915632

Epoch: 6| Step: 11
Training loss: 1.9330244064331055
Validation loss: 1.9890035967673025

Epoch: 6| Step: 12
Training loss: 2.010105848312378
Validation loss: 2.0182101572713544

Epoch: 6| Step: 13
Training loss: 1.3463003635406494
Validation loss: 2.0305696405390257

Epoch: 129| Step: 0
Training loss: 1.8698525428771973
Validation loss: 2.0390607349334227

Epoch: 6| Step: 1
Training loss: 2.2941694259643555
Validation loss: 2.0406260541690293

Epoch: 6| Step: 2
Training loss: 2.036079168319702
Validation loss: 2.0203383148357434

Epoch: 6| Step: 3
Training loss: 2.4244091510772705
Validation loss: 2.0171365455914567

Epoch: 6| Step: 4
Training loss: 2.221405029296875
Validation loss: 1.9962689004918581

Epoch: 6| Step: 5
Training loss: 2.194636344909668
Validation loss: 2.019430350231868

Epoch: 6| Step: 6
Training loss: 2.2245712280273438
Validation loss: 2.02197423032535

Epoch: 6| Step: 7
Training loss: 1.6962966918945312
Validation loss: 1.9935921545951598

Epoch: 6| Step: 8
Training loss: 2.3823087215423584
Validation loss: 2.031886718606436

Epoch: 6| Step: 9
Training loss: 2.229218006134033
Validation loss: 2.013478572650622

Epoch: 6| Step: 10
Training loss: 1.8152642250061035
Validation loss: 1.9852040800997006

Epoch: 6| Step: 11
Training loss: 1.8545539379119873
Validation loss: 1.9624835778308172

Epoch: 6| Step: 12
Training loss: 2.141073226928711
Validation loss: 2.01304304727944

Epoch: 6| Step: 13
Training loss: 3.6052310466766357
Validation loss: 2.012302057717436

Epoch: 130| Step: 0
Training loss: 2.0793116092681885
Validation loss: 2.0172465155201573

Epoch: 6| Step: 1
Training loss: 2.113323211669922
Validation loss: 2.012894090785775

Epoch: 6| Step: 2
Training loss: 2.2257890701293945
Validation loss: 1.9961560003219112

Epoch: 6| Step: 3
Training loss: 2.477808952331543
Validation loss: 1.9938076247451126

Epoch: 6| Step: 4
Training loss: 2.653979539871216
Validation loss: 2.0207763179655998

Epoch: 6| Step: 5
Training loss: 1.8702658414840698
Validation loss: 2.0429249425088205

Epoch: 6| Step: 6
Training loss: 2.1285324096679688
Validation loss: 2.0390502714341685

Epoch: 6| Step: 7
Training loss: 2.1701762676239014
Validation loss: 2.029042882304038

Epoch: 6| Step: 8
Training loss: 2.3923869132995605
Validation loss: 2.0371553603038994

Epoch: 6| Step: 9
Training loss: 2.196990489959717
Validation loss: 2.0504461770416587

Epoch: 6| Step: 10
Training loss: 1.8537952899932861
Validation loss: 2.0147617965616207

Epoch: 6| Step: 11
Training loss: 2.062347173690796
Validation loss: 2.002892648020098

Epoch: 6| Step: 12
Training loss: 2.179091453552246
Validation loss: 2.0163255301854943

Epoch: 6| Step: 13
Training loss: 1.7559332847595215
Validation loss: 2.0489459537690684

Epoch: 131| Step: 0
Training loss: 2.341080665588379
Validation loss: 2.057236990621013

Epoch: 6| Step: 1
Training loss: 2.2413032054901123
Validation loss: 2.071711859395427

Epoch: 6| Step: 2
Training loss: 2.1432762145996094
Validation loss: 2.0623797831996793

Epoch: 6| Step: 3
Training loss: 2.9969849586486816
Validation loss: 2.0422659971380748

Epoch: 6| Step: 4
Training loss: 2.203683376312256
Validation loss: 2.010844079397058

Epoch: 6| Step: 5
Training loss: 2.1192739009857178
Validation loss: 2.0324671191553914

Epoch: 6| Step: 6
Training loss: 1.9430538415908813
Validation loss: 2.0118781033382622

Epoch: 6| Step: 7
Training loss: 1.7109460830688477
Validation loss: 2.0008072109632593

Epoch: 6| Step: 8
Training loss: 2.675964117050171
Validation loss: 2.0272212143867248

Epoch: 6| Step: 9
Training loss: 2.458171844482422
Validation loss: 2.0560805079757527

Epoch: 6| Step: 10
Training loss: 1.6977508068084717
Validation loss: 2.0075263554050076

Epoch: 6| Step: 11
Training loss: 1.2008228302001953
Validation loss: 2.010107463405978

Epoch: 6| Step: 12
Training loss: 2.2832837104797363
Validation loss: 1.999408677060117

Epoch: 6| Step: 13
Training loss: 2.2969141006469727
Validation loss: 2.0024603361724527

Epoch: 132| Step: 0
Training loss: 1.521937608718872
Validation loss: 2.0193318167040424

Epoch: 6| Step: 1
Training loss: 2.86362886428833
Validation loss: 2.0320603693685224

Epoch: 6| Step: 2
Training loss: 2.3099074363708496
Validation loss: 2.031664066417243

Epoch: 6| Step: 3
Training loss: 2.507108688354492
Validation loss: 2.0269766853701685

Epoch: 6| Step: 4
Training loss: 1.9349114894866943
Validation loss: 2.0227974883971678

Epoch: 6| Step: 5
Training loss: 2.1637182235717773
Validation loss: 2.006538814113986

Epoch: 6| Step: 6
Training loss: 2.0812108516693115
Validation loss: 2.061017462002334

Epoch: 6| Step: 7
Training loss: 1.8508033752441406
Validation loss: 2.0491730346474597

Epoch: 6| Step: 8
Training loss: 2.3856005668640137
Validation loss: 2.0089115788859706

Epoch: 6| Step: 9
Training loss: 2.68332576751709
Validation loss: 2.040178829623807

Epoch: 6| Step: 10
Training loss: 1.6754767894744873
Validation loss: 2.026190111714025

Epoch: 6| Step: 11
Training loss: 2.367412567138672
Validation loss: 2.017014640633778

Epoch: 6| Step: 12
Training loss: 1.9768283367156982
Validation loss: 2.0333669083092802

Epoch: 6| Step: 13
Training loss: 1.935701847076416
Validation loss: 2.0325120341393257

Epoch: 133| Step: 0
Training loss: 1.8886793851852417
Validation loss: 2.027267094581358

Epoch: 6| Step: 1
Training loss: 2.5043134689331055
Validation loss: 2.040269209492591

Epoch: 6| Step: 2
Training loss: 2.572848320007324
Validation loss: 2.0362922812020905

Epoch: 6| Step: 3
Training loss: 2.0780744552612305
Validation loss: 2.0210151210907967

Epoch: 6| Step: 4
Training loss: 2.048532485961914
Validation loss: 2.0284116614249443

Epoch: 6| Step: 5
Training loss: 1.9344496726989746
Validation loss: 2.061602736032137

Epoch: 6| Step: 6
Training loss: 2.335970878601074
Validation loss: 2.0617142774725474

Epoch: 6| Step: 7
Training loss: 2.5890181064605713
Validation loss: 1.9743926281570106

Epoch: 6| Step: 8
Training loss: 1.4261552095413208
Validation loss: 2.049327784968961

Epoch: 6| Step: 9
Training loss: 2.343393325805664
Validation loss: 1.995326408775904

Epoch: 6| Step: 10
Training loss: 1.5779097080230713
Validation loss: 2.01946989182503

Epoch: 6| Step: 11
Training loss: 2.170729875564575
Validation loss: 2.0148087086216098

Epoch: 6| Step: 12
Training loss: 2.2222864627838135
Validation loss: 2.0205096826758435

Epoch: 6| Step: 13
Training loss: 2.8615357875823975
Validation loss: 1.9876091428982314

Epoch: 134| Step: 0
Training loss: 2.2350125312805176
Validation loss: 2.0272441115430606

Epoch: 6| Step: 1
Training loss: 1.628603458404541
Validation loss: 2.0024754360157955

Epoch: 6| Step: 2
Training loss: 2.824619770050049
Validation loss: 1.9951383964989775

Epoch: 6| Step: 3
Training loss: 1.8886208534240723
Validation loss: 2.0373810632254488

Epoch: 6| Step: 4
Training loss: 2.3333258628845215
Validation loss: 2.0119056458114297

Epoch: 6| Step: 5
Training loss: 2.3547263145446777
Validation loss: 2.023013525111701

Epoch: 6| Step: 6
Training loss: 1.9780945777893066
Validation loss: 2.0340704276997554

Epoch: 6| Step: 7
Training loss: 1.9198811054229736
Validation loss: 2.040178846287471

Epoch: 6| Step: 8
Training loss: 2.175065279006958
Validation loss: 1.9999979055056007

Epoch: 6| Step: 9
Training loss: 2.3477797508239746
Validation loss: 1.9963708257162442

Epoch: 6| Step: 10
Training loss: 2.0713179111480713
Validation loss: 2.033896744892161

Epoch: 6| Step: 11
Training loss: 2.353376626968384
Validation loss: 2.026759719335905

Epoch: 6| Step: 12
Training loss: 1.8325213193893433
Validation loss: 2.046985560847867

Epoch: 6| Step: 13
Training loss: 2.4714863300323486
Validation loss: 2.006880783265637

Epoch: 135| Step: 0
Training loss: 2.2437891960144043
Validation loss: 2.054793328367254

Epoch: 6| Step: 1
Training loss: 1.8998172283172607
Validation loss: 2.032335122426351

Epoch: 6| Step: 2
Training loss: 1.2634284496307373
Validation loss: 2.0142001413529917

Epoch: 6| Step: 3
Training loss: 2.27211856842041
Validation loss: 2.0030653066532587

Epoch: 6| Step: 4
Training loss: 1.8540480136871338
Validation loss: 2.0171411498900382

Epoch: 6| Step: 5
Training loss: 2.3949742317199707
Validation loss: 1.9848829277100102

Epoch: 6| Step: 6
Training loss: 2.942378520965576
Validation loss: 2.022550554685695

Epoch: 6| Step: 7
Training loss: 2.3502235412597656
Validation loss: 1.9802515570835402

Epoch: 6| Step: 8
Training loss: 1.6011836528778076
Validation loss: 1.9627648707359069

Epoch: 6| Step: 9
Training loss: 2.488020181655884
Validation loss: 1.9926599764054822

Epoch: 6| Step: 10
Training loss: 1.9826422929763794
Validation loss: 2.010467884361103

Epoch: 6| Step: 11
Training loss: 1.9876054525375366
Validation loss: 2.015750713245843

Epoch: 6| Step: 12
Training loss: 2.3913426399230957
Validation loss: 2.013474638744067

Epoch: 6| Step: 13
Training loss: 2.794271230697632
Validation loss: 2.016954077187405

Epoch: 136| Step: 0
Training loss: 1.5349241495132446
Validation loss: 2.0347989169500207

Epoch: 6| Step: 1
Training loss: 1.991572618484497
Validation loss: 1.9991655888095978

Epoch: 6| Step: 2
Training loss: 2.338646173477173
Validation loss: 2.0133106964890675

Epoch: 6| Step: 3
Training loss: 1.8140573501586914
Validation loss: 2.0188967361245105

Epoch: 6| Step: 4
Training loss: 2.521535873413086
Validation loss: 2.0423727573886996

Epoch: 6| Step: 5
Training loss: 2.006021022796631
Validation loss: 2.0890957540081394

Epoch: 6| Step: 6
Training loss: 2.1329188346862793
Validation loss: 2.0293450381166194

Epoch: 6| Step: 7
Training loss: 2.202812671661377
Validation loss: 2.013158869999711

Epoch: 6| Step: 8
Training loss: 1.8866909742355347
Validation loss: 2.022096610838367

Epoch: 6| Step: 9
Training loss: 2.1282541751861572
Validation loss: 2.005073731945407

Epoch: 6| Step: 10
Training loss: 2.465163230895996
Validation loss: 2.0317473770469747

Epoch: 6| Step: 11
Training loss: 2.1823654174804688
Validation loss: 2.036537572901736

Epoch: 6| Step: 12
Training loss: 2.4213380813598633
Validation loss: 2.045328458150228

Epoch: 6| Step: 13
Training loss: 2.5090904235839844
Validation loss: 2.0098159338838313

Epoch: 137| Step: 0
Training loss: 2.544137477874756
Validation loss: 2.014115072065784

Epoch: 6| Step: 1
Training loss: 1.7358814477920532
Validation loss: 2.004548938043656

Epoch: 6| Step: 2
Training loss: 2.486314058303833
Validation loss: 2.0142082719392675

Epoch: 6| Step: 3
Training loss: 2.450430154800415
Validation loss: 2.02858224222737

Epoch: 6| Step: 4
Training loss: 2.3398287296295166
Validation loss: 2.0409572752573157

Epoch: 6| Step: 5
Training loss: 1.989090919494629
Validation loss: 2.040991431923323

Epoch: 6| Step: 6
Training loss: 2.802997589111328
Validation loss: 2.0284299914554884

Epoch: 6| Step: 7
Training loss: 2.0719146728515625
Validation loss: 2.022748249833302

Epoch: 6| Step: 8
Training loss: 1.982664942741394
Validation loss: 2.0531518177319596

Epoch: 6| Step: 9
Training loss: 2.200648784637451
Validation loss: 2.046625047601679

Epoch: 6| Step: 10
Training loss: 1.9181206226348877
Validation loss: 2.0507854159160326

Epoch: 6| Step: 11
Training loss: 1.3417450189590454
Validation loss: 2.0656616790320284

Epoch: 6| Step: 12
Training loss: 1.927351951599121
Validation loss: 2.012038105277605

Epoch: 6| Step: 13
Training loss: 2.1748971939086914
Validation loss: 1.9984193271206272

Epoch: 138| Step: 0
Training loss: 2.0609114170074463
Validation loss: 2.014997773273017

Epoch: 6| Step: 1
Training loss: 2.8368918895721436
Validation loss: 2.0562890127140987

Epoch: 6| Step: 2
Training loss: 1.8619784116744995
Validation loss: 2.0426451493335027

Epoch: 6| Step: 3
Training loss: 2.4541139602661133
Validation loss: 2.047960860754854

Epoch: 6| Step: 4
Training loss: 1.5532803535461426
Validation loss: 2.0224913474052184

Epoch: 6| Step: 5
Training loss: 2.545778751373291
Validation loss: 2.031480536665968

Epoch: 6| Step: 6
Training loss: 2.8750548362731934
Validation loss: 1.9749106361019997

Epoch: 6| Step: 7
Training loss: 1.9113179445266724
Validation loss: 2.0267278250827583

Epoch: 6| Step: 8
Training loss: 2.273057460784912
Validation loss: 2.077471876657137

Epoch: 6| Step: 9
Training loss: 2.093747615814209
Validation loss: 2.0386775616676576

Epoch: 6| Step: 10
Training loss: 1.637192964553833
Validation loss: 2.0023960580107985

Epoch: 6| Step: 11
Training loss: 2.357330083847046
Validation loss: 2.066749431753671

Epoch: 6| Step: 12
Training loss: 1.6646039485931396
Validation loss: 2.0212149030418805

Epoch: 6| Step: 13
Training loss: 1.701316237449646
Validation loss: 2.0373392566557853

Epoch: 139| Step: 0
Training loss: 1.8372628688812256
Validation loss: 1.9986899539988527

Epoch: 6| Step: 1
Training loss: 2.0941710472106934
Validation loss: 1.9900698328530917

Epoch: 6| Step: 2
Training loss: 1.840246558189392
Validation loss: 1.9928532723457582

Epoch: 6| Step: 3
Training loss: 3.0908093452453613
Validation loss: 1.9842848393224901

Epoch: 6| Step: 4
Training loss: 2.409824848175049
Validation loss: 2.03357159578672

Epoch: 6| Step: 5
Training loss: 1.9444689750671387
Validation loss: 1.9662347070632442

Epoch: 6| Step: 6
Training loss: 2.9041624069213867
Validation loss: 2.0248236220370055

Epoch: 6| Step: 7
Training loss: 1.7980766296386719
Validation loss: 1.9773567184325187

Epoch: 6| Step: 8
Training loss: 1.9572442770004272
Validation loss: 1.9932590530764671

Epoch: 6| Step: 9
Training loss: 1.7058324813842773
Validation loss: 1.9500176906585693

Epoch: 6| Step: 10
Training loss: 1.844010591506958
Validation loss: 2.0183579652540145

Epoch: 6| Step: 11
Training loss: 2.355940103530884
Validation loss: 1.9593840491387151

Epoch: 6| Step: 12
Training loss: 2.0188558101654053
Validation loss: 1.9741541031868226

Epoch: 6| Step: 13
Training loss: 2.361203193664551
Validation loss: 2.0046037679077475

Epoch: 140| Step: 0
Training loss: 1.7292745113372803
Validation loss: 2.001410174113448

Epoch: 6| Step: 1
Training loss: 2.5685253143310547
Validation loss: 1.9696725337736067

Epoch: 6| Step: 2
Training loss: 2.1232314109802246
Validation loss: 2.0257675288825907

Epoch: 6| Step: 3
Training loss: 1.51261568069458
Validation loss: 2.0268677665341284

Epoch: 6| Step: 4
Training loss: 2.755389928817749
Validation loss: 2.006112306348739

Epoch: 6| Step: 5
Training loss: 2.26826810836792
Validation loss: 2.0442038274580434

Epoch: 6| Step: 6
Training loss: 1.5828156471252441
Validation loss: 2.0264365032155025

Epoch: 6| Step: 7
Training loss: 2.6326375007629395
Validation loss: 2.0192939850591842

Epoch: 6| Step: 8
Training loss: 2.352090835571289
Validation loss: 2.029560773603378

Epoch: 6| Step: 9
Training loss: 2.4444921016693115
Validation loss: 2.0314581753105245

Epoch: 6| Step: 10
Training loss: 1.8982386589050293
Validation loss: 2.019083285844454

Epoch: 6| Step: 11
Training loss: 2.0870730876922607
Validation loss: 2.0205838757176555

Epoch: 6| Step: 12
Training loss: 2.4463272094726562
Validation loss: 2.0271368065188007

Epoch: 6| Step: 13
Training loss: 1.6165539026260376
Validation loss: 2.03471480390077

Epoch: 141| Step: 0
Training loss: 2.1752114295959473
Validation loss: 2.0365592792469966

Epoch: 6| Step: 1
Training loss: 1.1140310764312744
Validation loss: 2.03019263539263

Epoch: 6| Step: 2
Training loss: 2.37957501411438
Validation loss: 2.0299678361544045

Epoch: 6| Step: 3
Training loss: 1.9172229766845703
Validation loss: 1.999513885026337

Epoch: 6| Step: 4
Training loss: 2.259678363800049
Validation loss: 2.0183802727730042

Epoch: 6| Step: 5
Training loss: 1.5287253856658936
Validation loss: 2.0311133374450026

Epoch: 6| Step: 6
Training loss: 2.985779047012329
Validation loss: 2.0434011413205053

Epoch: 6| Step: 7
Training loss: 2.638779401779175
Validation loss: 2.030763383834593

Epoch: 6| Step: 8
Training loss: 2.0376110076904297
Validation loss: 2.0543365209333357

Epoch: 6| Step: 9
Training loss: 1.867767095565796
Validation loss: 2.026416378636514

Epoch: 6| Step: 10
Training loss: 2.5098469257354736
Validation loss: 2.027239978954356

Epoch: 6| Step: 11
Training loss: 2.4516077041625977
Validation loss: 1.9771250576101325

Epoch: 6| Step: 12
Training loss: 2.14909291267395
Validation loss: 2.0033258571419665

Epoch: 6| Step: 13
Training loss: 1.5456016063690186
Validation loss: 2.020381176343528

Epoch: 142| Step: 0
Training loss: 1.7311457395553589
Validation loss: 2.0711621084520893

Epoch: 6| Step: 1
Training loss: 2.030254602432251
Validation loss: 2.025154539333877

Epoch: 6| Step: 2
Training loss: 1.7267054319381714
Validation loss: 2.002398089696002

Epoch: 6| Step: 3
Training loss: 2.43147349357605
Validation loss: 2.0343589923715077

Epoch: 6| Step: 4
Training loss: 2.2213480472564697
Validation loss: 2.043424898578275

Epoch: 6| Step: 5
Training loss: 1.3518420457839966
Validation loss: 2.0471306770078597

Epoch: 6| Step: 6
Training loss: 1.5644078254699707
Validation loss: 2.026843763166858

Epoch: 6| Step: 7
Training loss: 2.5916500091552734
Validation loss: 2.0291975493072183

Epoch: 6| Step: 8
Training loss: 2.4723122119903564
Validation loss: 2.041881463860953

Epoch: 6| Step: 9
Training loss: 2.288381814956665
Validation loss: 2.0366560156627367

Epoch: 6| Step: 10
Training loss: 2.53507661819458
Validation loss: 2.019730906332693

Epoch: 6| Step: 11
Training loss: 2.1280386447906494
Validation loss: 2.0158159937909854

Epoch: 6| Step: 12
Training loss: 2.1436350345611572
Validation loss: 2.014318750750634

Epoch: 6| Step: 13
Training loss: 2.579092264175415
Validation loss: 2.0229591426029

Epoch: 143| Step: 0
Training loss: 1.4438681602478027
Validation loss: 2.045994209986861

Epoch: 6| Step: 1
Training loss: 2.0197126865386963
Validation loss: 2.006881824103735

Epoch: 6| Step: 2
Training loss: 2.388458251953125
Validation loss: 1.9969605617625739

Epoch: 6| Step: 3
Training loss: 1.8843272924423218
Validation loss: 2.0537734954587874

Epoch: 6| Step: 4
Training loss: 2.25709867477417
Validation loss: 2.0126020703264462

Epoch: 6| Step: 5
Training loss: 2.0877621173858643
Validation loss: 2.016282618686717

Epoch: 6| Step: 6
Training loss: 2.714710235595703
Validation loss: 2.010223320735398

Epoch: 6| Step: 7
Training loss: 2.454683780670166
Validation loss: 2.0198833673231062

Epoch: 6| Step: 8
Training loss: 2.1128029823303223
Validation loss: 2.025549319482619

Epoch: 6| Step: 9
Training loss: 2.575882911682129
Validation loss: 2.0721069971720376

Epoch: 6| Step: 10
Training loss: 2.5611162185668945
Validation loss: 1.9836027429949852

Epoch: 6| Step: 11
Training loss: 1.6324372291564941
Validation loss: 2.012280229599245

Epoch: 6| Step: 12
Training loss: 1.9648592472076416
Validation loss: 2.039841221224877

Epoch: 6| Step: 13
Training loss: 1.9039865732192993
Validation loss: 1.9839791251767067

Epoch: 144| Step: 0
Training loss: 2.245023727416992
Validation loss: 2.018473571346652

Epoch: 6| Step: 1
Training loss: 1.9618167877197266
Validation loss: 2.0140272571194555

Epoch: 6| Step: 2
Training loss: 2.289482593536377
Validation loss: 1.980722245349679

Epoch: 6| Step: 3
Training loss: 1.7610633373260498
Validation loss: 2.037688680874404

Epoch: 6| Step: 4
Training loss: 2.0845837593078613
Validation loss: 2.0373394873834427

Epoch: 6| Step: 5
Training loss: 2.5153791904449463
Validation loss: 2.0333128744556057

Epoch: 6| Step: 6
Training loss: 2.7681281566619873
Validation loss: 2.0358976497445056

Epoch: 6| Step: 7
Training loss: 2.117537260055542
Validation loss: 2.0258592533808883

Epoch: 6| Step: 8
Training loss: 2.072329521179199
Validation loss: 1.9804405012438375

Epoch: 6| Step: 9
Training loss: 1.8837900161743164
Validation loss: 2.0056276987957697

Epoch: 6| Step: 10
Training loss: 1.8270320892333984
Validation loss: 2.0339863415687316

Epoch: 6| Step: 11
Training loss: 2.1302170753479004
Validation loss: 1.9973639390801872

Epoch: 6| Step: 12
Training loss: 2.5028345584869385
Validation loss: 2.0203080920762915

Epoch: 6| Step: 13
Training loss: 1.644119143486023
Validation loss: 1.9887864717873194

Epoch: 145| Step: 0
Training loss: 2.1222431659698486
Validation loss: 2.033979413329914

Epoch: 6| Step: 1
Training loss: 2.8328933715820312
Validation loss: 2.0030925735350578

Epoch: 6| Step: 2
Training loss: 2.088421583175659
Validation loss: 2.019645123071568

Epoch: 6| Step: 3
Training loss: 3.021310806274414
Validation loss: 2.0173305849875174

Epoch: 6| Step: 4
Training loss: 1.7639358043670654
Validation loss: 2.030146063015025

Epoch: 6| Step: 5
Training loss: 1.58774995803833
Validation loss: 2.004748449530653

Epoch: 6| Step: 6
Training loss: 2.069514751434326
Validation loss: 2.062680043200011

Epoch: 6| Step: 7
Training loss: 2.4216060638427734
Validation loss: 2.0295975349282704

Epoch: 6| Step: 8
Training loss: 2.3310422897338867
Validation loss: 2.0431221415919643

Epoch: 6| Step: 9
Training loss: 1.8413761854171753
Validation loss: 2.0445558153172976

Epoch: 6| Step: 10
Training loss: 1.7889374494552612
Validation loss: 2.0281265153679797

Epoch: 6| Step: 11
Training loss: 2.479771852493286
Validation loss: 2.0303562533470894

Epoch: 6| Step: 12
Training loss: 1.789630651473999
Validation loss: 2.0669365236836095

Epoch: 6| Step: 13
Training loss: 2.245584726333618
Validation loss: 2.0648672465355165

Epoch: 146| Step: 0
Training loss: 1.7631962299346924
Validation loss: 2.0430979190334195

Epoch: 6| Step: 1
Training loss: 1.5098869800567627
Validation loss: 2.0296494935148504

Epoch: 6| Step: 2
Training loss: 2.35145902633667
Validation loss: 2.0576553351135662

Epoch: 6| Step: 3
Training loss: 2.4740095138549805
Validation loss: 2.024449743250365

Epoch: 6| Step: 4
Training loss: 2.610401153564453
Validation loss: 2.0230689471767795

Epoch: 6| Step: 5
Training loss: 2.3714065551757812
Validation loss: 2.0164529251795944

Epoch: 6| Step: 6
Training loss: 1.9736316204071045
Validation loss: 2.012912914317141

Epoch: 6| Step: 7
Training loss: 2.785604476928711
Validation loss: 2.034791686201608

Epoch: 6| Step: 8
Training loss: 1.8410286903381348
Validation loss: 2.019897271228093

Epoch: 6| Step: 9
Training loss: 2.097510814666748
Validation loss: 1.9878798377129339

Epoch: 6| Step: 10
Training loss: 1.7086334228515625
Validation loss: 1.9954033205586095

Epoch: 6| Step: 11
Training loss: 2.080066204071045
Validation loss: 2.0235044135842273

Epoch: 6| Step: 12
Training loss: 1.7152891159057617
Validation loss: 1.9960397840828024

Epoch: 6| Step: 13
Training loss: 2.3792803287506104
Validation loss: 2.0174473831730504

Epoch: 147| Step: 0
Training loss: 2.3096632957458496
Validation loss: 2.0513553247656873

Epoch: 6| Step: 1
Training loss: 3.138526201248169
Validation loss: 2.0212959781769784

Epoch: 6| Step: 2
Training loss: 1.8139946460723877
Validation loss: 2.0601919004994054

Epoch: 6| Step: 3
Training loss: 2.500319004058838
Validation loss: 2.071901798248291

Epoch: 6| Step: 4
Training loss: 2.059330940246582
Validation loss: 2.0565374974281556

Epoch: 6| Step: 5
Training loss: 1.6427001953125
Validation loss: 2.001267916412764

Epoch: 6| Step: 6
Training loss: 1.2639460563659668
Validation loss: 2.050411258974383

Epoch: 6| Step: 7
Training loss: 2.324594497680664
Validation loss: 2.054098065181445

Epoch: 6| Step: 8
Training loss: 2.2916650772094727
Validation loss: 2.073405400399239

Epoch: 6| Step: 9
Training loss: 2.376689910888672
Validation loss: 2.0856259279353644

Epoch: 6| Step: 10
Training loss: 1.909382700920105
Validation loss: 2.037986327243108

Epoch: 6| Step: 11
Training loss: 2.152020215988159
Validation loss: 2.0938390993302867

Epoch: 6| Step: 12
Training loss: 1.6068669557571411
Validation loss: 2.0404055951744

Epoch: 6| Step: 13
Training loss: 2.8078441619873047
Validation loss: 2.03515810607582

Epoch: 148| Step: 0
Training loss: 2.711090564727783
Validation loss: 2.04739047122258

Epoch: 6| Step: 1
Training loss: 2.7575325965881348
Validation loss: 2.071346882850893

Epoch: 6| Step: 2
Training loss: 2.8884427547454834
Validation loss: 2.0433210454961306

Epoch: 6| Step: 3
Training loss: 2.1954822540283203
Validation loss: 2.023492541364444

Epoch: 6| Step: 4
Training loss: 2.6945133209228516
Validation loss: 2.0498819492196523

Epoch: 6| Step: 5
Training loss: 1.9183087348937988
Validation loss: 2.023826027429232

Epoch: 6| Step: 6
Training loss: 1.6571969985961914
Validation loss: 2.0109333607458297

Epoch: 6| Step: 7
Training loss: 1.8778003454208374
Validation loss: 2.0582659449628604

Epoch: 6| Step: 8
Training loss: 1.614290475845337
Validation loss: 2.036515433301208

Epoch: 6| Step: 9
Training loss: 1.8271605968475342
Validation loss: 2.045461940509017

Epoch: 6| Step: 10
Training loss: 1.6624164581298828
Validation loss: 2.004907754159743

Epoch: 6| Step: 11
Training loss: 1.5483441352844238
Validation loss: 2.020133859367781

Epoch: 6| Step: 12
Training loss: 2.3592607975006104
Validation loss: 2.049303203500727

Epoch: 6| Step: 13
Training loss: 2.624246835708618
Validation loss: 2.002648695822685

Epoch: 149| Step: 0
Training loss: 1.562711238861084
Validation loss: 2.0188907102871965

Epoch: 6| Step: 1
Training loss: 1.3987767696380615
Validation loss: 2.0311392661063903

Epoch: 6| Step: 2
Training loss: 2.4237120151519775
Validation loss: 2.0380562889960503

Epoch: 6| Step: 3
Training loss: 1.7650184631347656
Validation loss: 2.01639860932545

Epoch: 6| Step: 4
Training loss: 2.761364698410034
Validation loss: 1.9926410336648264

Epoch: 6| Step: 5
Training loss: 1.816663384437561
Validation loss: 1.992769286196719

Epoch: 6| Step: 6
Training loss: 2.697786808013916
Validation loss: 1.9768736900821808

Epoch: 6| Step: 7
Training loss: 2.5202417373657227
Validation loss: 1.998969534391998

Epoch: 6| Step: 8
Training loss: 1.7098565101623535
Validation loss: 1.9983662636049333

Epoch: 6| Step: 9
Training loss: 2.429485559463501
Validation loss: 2.0025672143505466

Epoch: 6| Step: 10
Training loss: 2.1567177772521973
Validation loss: 2.0054443190174718

Epoch: 6| Step: 11
Training loss: 2.530925750732422
Validation loss: 2.0269658898794525

Epoch: 6| Step: 12
Training loss: 1.7517220973968506
Validation loss: 2.054472246477681

Epoch: 6| Step: 13
Training loss: 1.888418436050415
Validation loss: 2.0376712801635906

Epoch: 150| Step: 0
Training loss: 1.7691833972930908
Validation loss: 2.008826668544482

Epoch: 6| Step: 1
Training loss: 2.7029709815979004
Validation loss: 2.0194219696906304

Epoch: 6| Step: 2
Training loss: 2.4563040733337402
Validation loss: 2.0270260226341987

Epoch: 6| Step: 3
Training loss: 2.3058910369873047
Validation loss: 2.0325193238514725

Epoch: 6| Step: 4
Training loss: 1.919219970703125
Validation loss: 2.029641928211335

Epoch: 6| Step: 5
Training loss: 2.121508836746216
Validation loss: 2.0184970581403343

Epoch: 6| Step: 6
Training loss: 2.476109504699707
Validation loss: 2.0498549938201904

Epoch: 6| Step: 7
Training loss: 1.9037301540374756
Validation loss: 2.0826906260623725

Epoch: 6| Step: 8
Training loss: 1.937074899673462
Validation loss: 2.061709137373073

Epoch: 6| Step: 9
Training loss: 2.1956610679626465
Validation loss: 2.0565308319625033

Epoch: 6| Step: 10
Training loss: 2.0296688079833984
Validation loss: 2.0467966961604294

Epoch: 6| Step: 11
Training loss: 1.8488285541534424
Validation loss: 2.0776503624454623

Epoch: 6| Step: 12
Training loss: 2.479971170425415
Validation loss: 2.0656273467566377

Epoch: 6| Step: 13
Training loss: 1.425132155418396
Validation loss: 2.0446915447071032

Testing loss: 2.0691916068394978
