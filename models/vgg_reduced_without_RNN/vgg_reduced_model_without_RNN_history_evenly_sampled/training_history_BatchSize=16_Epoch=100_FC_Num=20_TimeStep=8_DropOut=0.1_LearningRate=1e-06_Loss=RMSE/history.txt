Epoch: 1| Step: 0
Training loss: 7.4956744117988015
Validation loss: 8.152894410392934

Epoch: 6| Step: 1
Training loss: 8.441729354500113
Validation loss: 8.14574383374735

Epoch: 6| Step: 2
Training loss: 7.887293831961582
Validation loss: 8.143344562425343

Epoch: 6| Step: 3
Training loss: 6.303747775962266
Validation loss: 8.134009649896292

Epoch: 6| Step: 4
Training loss: 9.506095536862494
Validation loss: 8.128710221635657

Epoch: 6| Step: 5
Training loss: 8.253752808559552
Validation loss: 8.120404504924567

Epoch: 6| Step: 6
Training loss: 7.420734904209602
Validation loss: 8.119456424612403

Epoch: 6| Step: 7
Training loss: 9.737046464536311
Validation loss: 8.114171417504917

Epoch: 6| Step: 8
Training loss: 8.49186227240619
Validation loss: 8.107631187549197

Epoch: 6| Step: 9
Training loss: 7.584155642461594
Validation loss: 8.104939159770165

Epoch: 6| Step: 10
Training loss: 7.280179579479661
Validation loss: 8.097369517817548

Epoch: 6| Step: 11
Training loss: 7.200720263588437
Validation loss: 8.093884004088636

Epoch: 6| Step: 12
Training loss: 8.693946258062901
Validation loss: 8.087409687021381

Epoch: 6| Step: 13
Training loss: 8.161020571895548
Validation loss: 8.079820665334765

Epoch: 2| Step: 0
Training loss: 8.25586006808904
Validation loss: 8.077004673755372

Epoch: 6| Step: 1
Training loss: 7.968891456694839
Validation loss: 8.07189311313079

Epoch: 6| Step: 2
Training loss: 8.753330141964186
Validation loss: 8.065564764120301

Epoch: 6| Step: 3
Training loss: 7.849689074147524
Validation loss: 8.061373347726713

Epoch: 6| Step: 4
Training loss: 7.287081106719494
Validation loss: 8.054899267559012

Epoch: 6| Step: 5
Training loss: 8.233890873902801
Validation loss: 8.046114725623285

Epoch: 6| Step: 6
Training loss: 8.779457859689208
Validation loss: 8.043441036880465

Epoch: 6| Step: 7
Training loss: 7.996644031428488
Validation loss: 8.037847723335318

Epoch: 6| Step: 8
Training loss: 8.01825110414004
Validation loss: 8.031723599032102

Epoch: 6| Step: 9
Training loss: 7.6100043755216715
Validation loss: 8.026553935416734

Epoch: 6| Step: 10
Training loss: 8.48980864867479
Validation loss: 8.020728631062687

Epoch: 6| Step: 11
Training loss: 7.540492800689229
Validation loss: 8.015071075527379

Epoch: 6| Step: 12
Training loss: 8.335109165440167
Validation loss: 8.012972988074457

Epoch: 6| Step: 13
Training loss: 5.453673064663873
Validation loss: 8.006178951285195

Epoch: 3| Step: 0
Training loss: 6.695790793428752
Validation loss: 7.99933134637861

Epoch: 6| Step: 1
Training loss: 7.882901299905558
Validation loss: 7.995428322374041

Epoch: 6| Step: 2
Training loss: 8.296888333469747
Validation loss: 7.985747747252964

Epoch: 6| Step: 3
Training loss: 8.487013376749733
Validation loss: 7.980597285825602

Epoch: 6| Step: 4
Training loss: 8.911082673232231
Validation loss: 7.97758165830008

Epoch: 6| Step: 5
Training loss: 7.705999182512214
Validation loss: 7.971234949185821

Epoch: 6| Step: 6
Training loss: 7.376163972715939
Validation loss: 7.964101520294592

Epoch: 6| Step: 7
Training loss: 8.69672414557676
Validation loss: 7.962198191860428

Epoch: 6| Step: 8
Training loss: 6.5870830946853145
Validation loss: 7.953904631528706

Epoch: 6| Step: 9
Training loss: 7.511158081650197
Validation loss: 7.949978616615679

Epoch: 6| Step: 10
Training loss: 8.442681424103734
Validation loss: 7.944372154086882

Epoch: 6| Step: 11
Training loss: 7.444781673757927
Validation loss: 7.936990633882869

Epoch: 6| Step: 12
Training loss: 8.273250300349105
Validation loss: 7.930804041132133

Epoch: 6| Step: 13
Training loss: 8.473553523402378
Validation loss: 7.927600868657457

Epoch: 4| Step: 0
Training loss: 7.600016202407431
Validation loss: 7.921265981623122

Epoch: 6| Step: 1
Training loss: 7.734757970711075
Validation loss: 7.913675717522495

Epoch: 6| Step: 2
Training loss: 8.00127972857604
Validation loss: 7.907185459077117

Epoch: 6| Step: 3
Training loss: 7.652022210415454
Validation loss: 7.903491577474691

Epoch: 6| Step: 4
Training loss: 8.277792615542957
Validation loss: 7.8967657739716515

Epoch: 6| Step: 5
Training loss: 7.482047401961265
Validation loss: 7.891287315088636

Epoch: 6| Step: 6
Training loss: 8.079373467959359
Validation loss: 7.882201683775309

Epoch: 6| Step: 7
Training loss: 7.216649662317883
Validation loss: 7.875454612328141

Epoch: 6| Step: 8
Training loss: 8.179989697139753
Validation loss: 7.870360695998329

Epoch: 6| Step: 9
Training loss: 8.415285607770633
Validation loss: 7.868558197966645

Epoch: 6| Step: 10
Training loss: 7.9640503432533025
Validation loss: 7.859891457437453

Epoch: 6| Step: 11
Training loss: 6.854874996545285
Validation loss: 7.853596190673103

Epoch: 6| Step: 12
Training loss: 6.950856590998898
Validation loss: 7.84801517504247

Epoch: 6| Step: 13
Training loss: 9.986717558231565
Validation loss: 7.844295683896759

Epoch: 5| Step: 0
Training loss: 7.661462122961404
Validation loss: 7.834705031956206

Epoch: 6| Step: 1
Training loss: 7.705301406777486
Validation loss: 7.8314897841614926

Epoch: 6| Step: 2
Training loss: 6.996895782998667
Validation loss: 7.823665576221615

Epoch: 6| Step: 3
Training loss: 8.473897910689109
Validation loss: 7.814767280631083

Epoch: 6| Step: 4
Training loss: 8.007673398182092
Validation loss: 7.80763263246945

Epoch: 6| Step: 5
Training loss: 6.794233277932172
Validation loss: 7.802416722547706

Epoch: 6| Step: 6
Training loss: 8.408805373684183
Validation loss: 7.791818138792391

Epoch: 6| Step: 7
Training loss: 7.846663826699122
Validation loss: 7.786073194979517

Epoch: 6| Step: 8
Training loss: 7.562551955367759
Validation loss: 7.778680329564037

Epoch: 6| Step: 9
Training loss: 6.034207740492526
Validation loss: 7.774393714700822

Epoch: 6| Step: 10
Training loss: 8.660399836588946
Validation loss: 7.769048996025181

Epoch: 6| Step: 11
Training loss: 8.525601595685748
Validation loss: 7.7621507214643986

Epoch: 6| Step: 12
Training loss: 7.551195254671271
Validation loss: 7.754956351897525

Epoch: 6| Step: 13
Training loss: 8.002313756137044
Validation loss: 7.745118402273149

Epoch: 6| Step: 0
Training loss: 7.454221248977719
Validation loss: 7.742255187184451

Epoch: 6| Step: 1
Training loss: 6.389223276131898
Validation loss: 7.732555120192304

Epoch: 6| Step: 2
Training loss: 7.258435833364535
Validation loss: 7.726509253233822

Epoch: 6| Step: 3
Training loss: 7.889654662645304
Validation loss: 7.716387912022157

Epoch: 6| Step: 4
Training loss: 8.050818208612402
Validation loss: 7.710793313892199

Epoch: 6| Step: 5
Training loss: 7.079601007630734
Validation loss: 7.701521398568423

Epoch: 6| Step: 6
Training loss: 9.671023822854877
Validation loss: 7.692232094985635

Epoch: 6| Step: 7
Training loss: 7.605358904734491
Validation loss: 7.68347787338278

Epoch: 6| Step: 8
Training loss: 7.7557297721952905
Validation loss: 7.677452197977963

Epoch: 6| Step: 9
Training loss: 6.930825261550917
Validation loss: 7.670325577379074

Epoch: 6| Step: 10
Training loss: 7.530890111911443
Validation loss: 7.661726707892753

Epoch: 6| Step: 11
Training loss: 9.0342239710331
Validation loss: 7.656465566118875

Epoch: 6| Step: 12
Training loss: 6.680926648586187
Validation loss: 7.644245542676509

Epoch: 6| Step: 13
Training loss: 6.712380019950194
Validation loss: 7.637333543629545

Epoch: 7| Step: 0
Training loss: 7.424348631779166
Validation loss: 7.629845983450963

Epoch: 6| Step: 1
Training loss: 7.4670998254654934
Validation loss: 7.6236112806980465

Epoch: 6| Step: 2
Training loss: 7.21171828451683
Validation loss: 7.613384545417646

Epoch: 6| Step: 3
Training loss: 7.6221638392123845
Validation loss: 7.604888003449911

Epoch: 6| Step: 4
Training loss: 7.699677041947472
Validation loss: 7.591645309374796

Epoch: 6| Step: 5
Training loss: 7.920147769589825
Validation loss: 7.587763988811593

Epoch: 6| Step: 6
Training loss: 7.205550639747989
Validation loss: 7.578916097742712

Epoch: 6| Step: 7
Training loss: 7.480088059422093
Validation loss: 7.564789892736521

Epoch: 6| Step: 8
Training loss: 7.916261388209404
Validation loss: 7.557465668434158

Epoch: 6| Step: 9
Training loss: 7.103499514519812
Validation loss: 7.550436648432278

Epoch: 6| Step: 10
Training loss: 8.367420923448051
Validation loss: 7.542728780540219

Epoch: 6| Step: 11
Training loss: 7.365457341742422
Validation loss: 7.536381898285425

Epoch: 6| Step: 12
Training loss: 6.510752367647096
Validation loss: 7.5239979402288375

Epoch: 6| Step: 13
Training loss: 8.424853532463162
Validation loss: 7.517878524428236

Epoch: 8| Step: 0
Training loss: 7.692048750700576
Validation loss: 7.504071984961182

Epoch: 6| Step: 1
Training loss: 7.776510365475987
Validation loss: 7.4951123079353055

Epoch: 6| Step: 2
Training loss: 6.92351545265442
Validation loss: 7.482277766895314

Epoch: 6| Step: 3
Training loss: 8.015973832717794
Validation loss: 7.476446017891747

Epoch: 6| Step: 4
Training loss: 8.419087530788252
Validation loss: 7.4671082025861795

Epoch: 6| Step: 5
Training loss: 6.335855015454147
Validation loss: 7.454080744781988

Epoch: 6| Step: 6
Training loss: 7.026219446088334
Validation loss: 7.44319544863919

Epoch: 6| Step: 7
Training loss: 6.607379440726139
Validation loss: 7.435266548386661

Epoch: 6| Step: 8
Training loss: 7.885663517893192
Validation loss: 7.426300465499841

Epoch: 6| Step: 9
Training loss: 6.361078657412673
Validation loss: 7.418555675087822

Epoch: 6| Step: 10
Training loss: 7.776772555227034
Validation loss: 7.404779560563353

Epoch: 6| Step: 11
Training loss: 6.737239502805586
Validation loss: 7.395821078225473

Epoch: 6| Step: 12
Training loss: 8.498422364075738
Validation loss: 7.385191424557129

Epoch: 6| Step: 13
Training loss: 6.984400124045975
Validation loss: 7.376069289121381

Epoch: 9| Step: 0
Training loss: 7.4798220999874685
Validation loss: 7.3658948017407395

Epoch: 6| Step: 1
Training loss: 8.490925151979814
Validation loss: 7.351003426756247

Epoch: 6| Step: 2
Training loss: 7.910374466511649
Validation loss: 7.346171312738132

Epoch: 6| Step: 3
Training loss: 7.488106516121238
Validation loss: 7.332807050299098

Epoch: 6| Step: 4
Training loss: 7.135250815438708
Validation loss: 7.322932069441012

Epoch: 6| Step: 5
Training loss: 6.876861320301024
Validation loss: 7.308400770243328

Epoch: 6| Step: 6
Training loss: 6.257222084643691
Validation loss: 7.298358572219369

Epoch: 6| Step: 7
Training loss: 7.931154372869015
Validation loss: 7.2847346090715375

Epoch: 6| Step: 8
Training loss: 6.963979687796412
Validation loss: 7.268411067558601

Epoch: 6| Step: 9
Training loss: 6.8591389191826755
Validation loss: 7.267022719536124

Epoch: 6| Step: 10
Training loss: 6.590559779749306
Validation loss: 7.2560245488325394

Epoch: 6| Step: 11
Training loss: 7.276053870775004
Validation loss: 7.238488339217525

Epoch: 6| Step: 12
Training loss: 7.033119326163511
Validation loss: 7.224471811763905

Epoch: 6| Step: 13
Training loss: 6.860751281171024
Validation loss: 7.215124206867848

Epoch: 10| Step: 0
Training loss: 8.176895379176145
Validation loss: 7.199726362395119

Epoch: 6| Step: 1
Training loss: 6.861917428614188
Validation loss: 7.1949001144778375

Epoch: 6| Step: 2
Training loss: 7.216720758225114
Validation loss: 7.183876017821659

Epoch: 6| Step: 3
Training loss: 7.960535939639307
Validation loss: 7.164783852409494

Epoch: 6| Step: 4
Training loss: 7.434616427452047
Validation loss: 7.156771085476312

Epoch: 6| Step: 5
Training loss: 6.631107034679133
Validation loss: 7.138833227278824

Epoch: 6| Step: 6
Training loss: 5.720935508147152
Validation loss: 7.126285712588381

Epoch: 6| Step: 7
Training loss: 6.603901212955018
Validation loss: 7.116828793882152

Epoch: 6| Step: 8
Training loss: 7.4987840302527085
Validation loss: 7.113247251037714

Epoch: 6| Step: 9
Training loss: 6.658753403393689
Validation loss: 7.090759225108725

Epoch: 6| Step: 10
Training loss: 7.287758991749533
Validation loss: 7.084468738490082

Epoch: 6| Step: 11
Training loss: 6.54903753067006
Validation loss: 7.063992807803769

Epoch: 6| Step: 12
Training loss: 7.274341105088735
Validation loss: 7.052925268876537

Epoch: 6| Step: 13
Training loss: 7.0227069411133565
Validation loss: 7.046639967873531

Epoch: 11| Step: 0
Training loss: 6.96365046695537
Validation loss: 7.034793404817348

Epoch: 6| Step: 1
Training loss: 7.128315204522686
Validation loss: 7.016050299406743

Epoch: 6| Step: 2
Training loss: 6.6564007236089475
Validation loss: 6.9985509403914135

Epoch: 6| Step: 3
Training loss: 5.86412958136758
Validation loss: 6.984580905277229

Epoch: 6| Step: 4
Training loss: 7.141345632571474
Validation loss: 6.971331115750985

Epoch: 6| Step: 5
Training loss: 6.973368529795607
Validation loss: 6.949985513519324

Epoch: 6| Step: 6
Training loss: 7.863480635046665
Validation loss: 6.9410865807908735

Epoch: 6| Step: 7
Training loss: 7.233514392655205
Validation loss: 6.926686096521042

Epoch: 6| Step: 8
Training loss: 6.380048062134523
Validation loss: 6.911781389601676

Epoch: 6| Step: 9
Training loss: 6.6031808528532885
Validation loss: 6.906202942812196

Epoch: 6| Step: 10
Training loss: 6.027769042837413
Validation loss: 6.882671457604311

Epoch: 6| Step: 11
Training loss: 7.887302295848912
Validation loss: 6.865644540207748

Epoch: 6| Step: 12
Training loss: 6.0774050877078825
Validation loss: 6.854400338543012

Epoch: 6| Step: 13
Training loss: 7.816657829144111
Validation loss: 6.84788564660649

Epoch: 12| Step: 0
Training loss: 6.280565518714321
Validation loss: 6.822772587508411

Epoch: 6| Step: 1
Training loss: 7.547352651324637
Validation loss: 6.813329629016697

Epoch: 6| Step: 2
Training loss: 6.073457548767398
Validation loss: 6.8015415231082486

Epoch: 6| Step: 3
Training loss: 5.47224184001541
Validation loss: 6.780708622170302

Epoch: 6| Step: 4
Training loss: 6.770422663827938
Validation loss: 6.762491676004425

Epoch: 6| Step: 5
Training loss: 7.502275248958333
Validation loss: 6.758275375622458

Epoch: 6| Step: 6
Training loss: 6.174192355694564
Validation loss: 6.737630000328908

Epoch: 6| Step: 7
Training loss: 6.39481281832747
Validation loss: 6.711989544536299

Epoch: 6| Step: 8
Training loss: 7.815050364970865
Validation loss: 6.7073019380414385

Epoch: 6| Step: 9
Training loss: 7.128116929761707
Validation loss: 6.691638330443452

Epoch: 6| Step: 10
Training loss: 5.971971211838625
Validation loss: 6.674151526800144

Epoch: 6| Step: 11
Training loss: 7.5587602937078495
Validation loss: 6.656379279025539

Epoch: 6| Step: 12
Training loss: 6.031661419844666
Validation loss: 6.635828858816522

Epoch: 6| Step: 13
Training loss: 6.337677553236582
Validation loss: 6.62076000607026

Epoch: 13| Step: 0
Training loss: 5.88632506615323
Validation loss: 6.603974504885124

Epoch: 6| Step: 1
Training loss: 6.04511592226914
Validation loss: 6.582914817573763

Epoch: 6| Step: 2
Training loss: 6.206162792257701
Validation loss: 6.573118604925867

Epoch: 6| Step: 3
Training loss: 6.440436128811221
Validation loss: 6.554756570653765

Epoch: 6| Step: 4
Training loss: 6.831183056446635
Validation loss: 6.5351762062676535

Epoch: 6| Step: 5
Training loss: 6.395603171648411
Validation loss: 6.524791364579971

Epoch: 6| Step: 6
Training loss: 6.537270139661222
Validation loss: 6.4926804094963515

Epoch: 6| Step: 7
Training loss: 5.527492475362182
Validation loss: 6.493966722068253

Epoch: 6| Step: 8
Training loss: 8.508137117888785
Validation loss: 6.471230222688241

Epoch: 6| Step: 9
Training loss: 5.476858873823507
Validation loss: 6.450365723994138

Epoch: 6| Step: 10
Training loss: 5.448866091018979
Validation loss: 6.42876243652618

Epoch: 6| Step: 11
Training loss: 6.711920243272471
Validation loss: 6.423640125419396

Epoch: 6| Step: 12
Training loss: 6.680063837168949
Validation loss: 6.400495182256672

Epoch: 6| Step: 13
Training loss: 7.5983839927011525
Validation loss: 6.3806814846433015

Epoch: 14| Step: 0
Training loss: 6.562315729369747
Validation loss: 6.3741941897829655

Epoch: 6| Step: 1
Training loss: 5.813657583823898
Validation loss: 6.348428606599095

Epoch: 6| Step: 2
Training loss: 7.068640276177867
Validation loss: 6.316075567583379

Epoch: 6| Step: 3
Training loss: 6.353521929273693
Validation loss: 6.307654347804104

Epoch: 6| Step: 4
Training loss: 6.019360143171625
Validation loss: 6.279105492027998

Epoch: 6| Step: 5
Training loss: 5.790190510885091
Validation loss: 6.263093666313386

Epoch: 6| Step: 6
Training loss: 6.200425644076752
Validation loss: 6.256049328388214

Epoch: 6| Step: 7
Training loss: 5.445729134381705
Validation loss: 6.225129895964194

Epoch: 6| Step: 8
Training loss: 5.613133438489683
Validation loss: 6.215280756633912

Epoch: 6| Step: 9
Training loss: 6.619939634848868
Validation loss: 6.189398686281265

Epoch: 6| Step: 10
Training loss: 7.061467998351904
Validation loss: 6.171270495554445

Epoch: 6| Step: 11
Training loss: 6.429338336794434
Validation loss: 6.1443774796524

Epoch: 6| Step: 12
Training loss: 5.781800279976736
Validation loss: 6.130078953785542

Epoch: 6| Step: 13
Training loss: 5.669138350637764
Validation loss: 6.113688628953266

Epoch: 15| Step: 0
Training loss: 6.036034460273999
Validation loss: 6.102281323447542

Epoch: 6| Step: 1
Training loss: 4.889430281014383
Validation loss: 6.066187571084634

Epoch: 6| Step: 2
Training loss: 5.474053476113527
Validation loss: 6.0365418907882455

Epoch: 6| Step: 3
Training loss: 6.224195080541319
Validation loss: 6.024136445330981

Epoch: 6| Step: 4
Training loss: 5.519959732129931
Validation loss: 6.023643456401597

Epoch: 6| Step: 5
Training loss: 5.831061147757475
Validation loss: 5.976110024012556

Epoch: 6| Step: 6
Training loss: 5.118810311918133
Validation loss: 5.967283106766955

Epoch: 6| Step: 7
Training loss: 7.273595363653395
Validation loss: 5.948121161325667

Epoch: 6| Step: 8
Training loss: 7.088080875873926
Validation loss: 5.930874154350701

Epoch: 6| Step: 9
Training loss: 6.125715875635571
Validation loss: 5.904593498508269

Epoch: 6| Step: 10
Training loss: 6.231450745496965
Validation loss: 5.884455287629746

Epoch: 6| Step: 11
Training loss: 6.338114824135468
Validation loss: 5.860046213515105

Epoch: 6| Step: 12
Training loss: 5.04693735751434
Validation loss: 5.827116767337781

Epoch: 6| Step: 13
Training loss: 4.712254177329858
Validation loss: 5.812714084859924

Epoch: 16| Step: 0
Training loss: 5.582267868333892
Validation loss: 5.800925970083198

Epoch: 6| Step: 1
Training loss: 6.345603634473228
Validation loss: 5.772939794293672

Epoch: 6| Step: 2
Training loss: 4.98960750098803
Validation loss: 5.7387866646169705

Epoch: 6| Step: 3
Training loss: 6.020671837916663
Validation loss: 5.737224666458941

Epoch: 6| Step: 4
Training loss: 6.461395653344756
Validation loss: 5.713782049943703

Epoch: 6| Step: 5
Training loss: 6.217778575685996
Validation loss: 5.678145504591178

Epoch: 6| Step: 6
Training loss: 5.2947522076053195
Validation loss: 5.652593344084918

Epoch: 6| Step: 7
Training loss: 4.839882765051583
Validation loss: 5.64218796556564

Epoch: 6| Step: 8
Training loss: 6.15687333257705
Validation loss: 5.623034536058528

Epoch: 6| Step: 9
Training loss: 5.163416096315636
Validation loss: 5.585769927321442

Epoch: 6| Step: 10
Training loss: 5.058319437844779
Validation loss: 5.556388691741869

Epoch: 6| Step: 11
Training loss: 6.130973549928418
Validation loss: 5.543360772326938

Epoch: 6| Step: 12
Training loss: 4.291289427143054
Validation loss: 5.520907565651213

Epoch: 6| Step: 13
Training loss: 6.034080987343176
Validation loss: 5.492167465786536

Epoch: 17| Step: 0
Training loss: 5.887434117946804
Validation loss: 5.487171590475044

Epoch: 6| Step: 1
Training loss: 5.8903394068285
Validation loss: 5.444880686054171

Epoch: 6| Step: 2
Training loss: 5.658558748424814
Validation loss: 5.426458780759827

Epoch: 6| Step: 3
Training loss: 4.86151900018253
Validation loss: 5.406399340407104

Epoch: 6| Step: 4
Training loss: 4.943750601863704
Validation loss: 5.37412488929195

Epoch: 6| Step: 5
Training loss: 5.849692520798903
Validation loss: 5.350821921436583

Epoch: 6| Step: 6
Training loss: 5.999510745128156
Validation loss: 5.3286260409512805

Epoch: 6| Step: 7
Training loss: 6.092115603636898
Validation loss: 5.306246947275037

Epoch: 6| Step: 8
Training loss: 4.468884446049
Validation loss: 5.26443913766863

Epoch: 6| Step: 9
Training loss: 5.155804239136211
Validation loss: 5.25412645696948

Epoch: 6| Step: 10
Training loss: 5.264924769719938
Validation loss: 5.212999907169365

Epoch: 6| Step: 11
Training loss: 4.25156732718051
Validation loss: 5.217368912072896

Epoch: 6| Step: 12
Training loss: 4.396472227604276
Validation loss: 5.171159986859992

Epoch: 6| Step: 13
Training loss: 5.2175660760604305
Validation loss: 5.149112576054329

Epoch: 18| Step: 0
Training loss: 4.9935090848367025
Validation loss: 5.1384051246650735

Epoch: 6| Step: 1
Training loss: 5.746621839580074
Validation loss: 5.088373145286443

Epoch: 6| Step: 2
Training loss: 4.983178261137704
Validation loss: 5.062771914325062

Epoch: 6| Step: 3
Training loss: 4.555981303430364
Validation loss: 5.046541608905818

Epoch: 6| Step: 4
Training loss: 4.406435049513502
Validation loss: 5.010752582765702

Epoch: 6| Step: 5
Training loss: 5.310895251077724
Validation loss: 4.993223821296538

Epoch: 6| Step: 6
Training loss: 4.595461156905682
Validation loss: 4.9570128593089775

Epoch: 6| Step: 7
Training loss: 6.072486124976912
Validation loss: 4.943765731402136

Epoch: 6| Step: 8
Training loss: 5.832539458977311
Validation loss: 4.909776122653229

Epoch: 6| Step: 9
Training loss: 5.365707171104749
Validation loss: 4.894533339867943

Epoch: 6| Step: 10
Training loss: 4.627143157109656
Validation loss: 4.846517294626237

Epoch: 6| Step: 11
Training loss: 3.654975342882641
Validation loss: 4.827949771103304

Epoch: 6| Step: 12
Training loss: 3.9267666770836898
Validation loss: 4.791186620662501

Epoch: 6| Step: 13
Training loss: 4.910258411203521
Validation loss: 4.772703163399664

Epoch: 19| Step: 0
Training loss: 1.941137345110123
Validation loss: 4.741124155302129

Epoch: 6| Step: 1
Training loss: 5.132096192704961
Validation loss: 4.712138707325646

Epoch: 6| Step: 2
Training loss: 4.9656838607420415
Validation loss: 4.684838177051216

Epoch: 6| Step: 3
Training loss: 4.625187638059224
Validation loss: 4.686581347287305

Epoch: 6| Step: 4
Training loss: 3.9914588337882395
Validation loss: 4.634924484214581

Epoch: 6| Step: 5
Training loss: 4.745266412907474
Validation loss: 4.598623648653163

Epoch: 6| Step: 6
Training loss: 5.059298786534136
Validation loss: 4.594931548677028

Epoch: 6| Step: 7
Training loss: 4.099229479703534
Validation loss: 4.56525046839487

Epoch: 6| Step: 8
Training loss: 4.640737204688336
Validation loss: 4.534799710583403

Epoch: 6| Step: 9
Training loss: 5.676527232893474
Validation loss: 4.518853453174133

Epoch: 6| Step: 10
Training loss: 4.670793184804881
Validation loss: 4.492705116786189

Epoch: 6| Step: 11
Training loss: 4.771560724547774
Validation loss: 4.463258765216227

Epoch: 6| Step: 12
Training loss: 4.486456517535887
Validation loss: 4.409280593966229

Epoch: 6| Step: 13
Training loss: 4.11865740890508
Validation loss: 4.394358164014074

Epoch: 20| Step: 0
Training loss: 4.27374344590101
Validation loss: 4.367171512979324

Epoch: 6| Step: 1
Training loss: 4.2021657990795775
Validation loss: 4.344820185993011

Epoch: 6| Step: 2
Training loss: 4.001995780870157
Validation loss: 4.304949408522821

Epoch: 6| Step: 3
Training loss: 4.308634919482593
Validation loss: 4.2811561923299655

Epoch: 6| Step: 4
Training loss: 3.8774583463319194
Validation loss: 4.235067907744091

Epoch: 6| Step: 5
Training loss: 2.456949836097764
Validation loss: 4.229481506186423

Epoch: 6| Step: 6
Training loss: 4.31805725283034
Validation loss: 4.176132704441562

Epoch: 6| Step: 7
Training loss: 4.759745789159017
Validation loss: 4.176644402720192

Epoch: 6| Step: 8
Training loss: 4.9025678484636055
Validation loss: 4.1256698755574694

Epoch: 6| Step: 9
Training loss: 4.183901478965938
Validation loss: 4.113162996073879

Epoch: 6| Step: 10
Training loss: 4.105472931283551
Validation loss: 4.076672216157788

Epoch: 6| Step: 11
Training loss: 4.056666014605187
Validation loss: 4.065498080023952

Epoch: 6| Step: 12
Training loss: 4.934240110074416
Validation loss: 4.025201124423399

Epoch: 6| Step: 13
Training loss: 4.248725026689417
Validation loss: 3.994213756761574

Epoch: 21| Step: 0
Training loss: 3.885649168747154
Validation loss: 3.974144502154875

Epoch: 6| Step: 1
Training loss: 3.561701768825019
Validation loss: 3.946799395684282

Epoch: 6| Step: 2
Training loss: 3.6934763437486717
Validation loss: 3.9056929048730167

Epoch: 6| Step: 3
Training loss: 4.304449999119734
Validation loss: 3.875445433918526

Epoch: 6| Step: 4
Training loss: 3.6923457489130946
Validation loss: 3.8673873112247747

Epoch: 6| Step: 5
Training loss: 2.7816785846483083
Validation loss: 3.8421856924875946

Epoch: 6| Step: 6
Training loss: 3.778089100656897
Validation loss: 3.7910726019432692

Epoch: 6| Step: 7
Training loss: 3.470145829624084
Validation loss: 3.779915402152587

Epoch: 6| Step: 8
Training loss: 4.398326919818889
Validation loss: 3.74510789569432

Epoch: 6| Step: 9
Training loss: 3.476089548237111
Validation loss: 3.7147104368283967

Epoch: 6| Step: 10
Training loss: 4.915228725012647
Validation loss: 3.7074793520977356

Epoch: 6| Step: 11
Training loss: 3.749480529409038
Validation loss: 3.680491478557558

Epoch: 6| Step: 12
Training loss: 3.594175097989769
Validation loss: 3.643174220209863

Epoch: 6| Step: 13
Training loss: 4.682168598983449
Validation loss: 3.629919070289144

Epoch: 22| Step: 0
Training loss: 3.807621069703394
Validation loss: 3.625501554145878

Epoch: 6| Step: 1
Training loss: 3.4620570316035644
Validation loss: 3.5566369344818263

Epoch: 6| Step: 2
Training loss: 3.3589531212204555
Validation loss: 3.5709692701280558

Epoch: 6| Step: 3
Training loss: 3.77324440661492
Validation loss: 3.517043924695114

Epoch: 6| Step: 4
Training loss: 3.9583021196171995
Validation loss: 3.504650345395246

Epoch: 6| Step: 5
Training loss: 4.012206288458691
Validation loss: 3.5022147491637106

Epoch: 6| Step: 6
Training loss: 3.564135259799561
Validation loss: 3.456126469040061

Epoch: 6| Step: 7
Training loss: 3.151807623632305
Validation loss: 3.4553520338781354

Epoch: 6| Step: 8
Training loss: 3.028795644783802
Validation loss: 3.415144153182283

Epoch: 6| Step: 9
Training loss: 4.378758587078765
Validation loss: 3.4063694505763236

Epoch: 6| Step: 10
Training loss: 3.7184548140623725
Validation loss: 3.3884380650829224

Epoch: 6| Step: 11
Training loss: 3.362663327472833
Validation loss: 3.3580536976131383

Epoch: 6| Step: 12
Training loss: 3.1804948011552825
Validation loss: 3.3224194306662582

Epoch: 6| Step: 13
Training loss: 3.4906536377745487
Validation loss: 3.3227473246135872

Epoch: 23| Step: 0
Training loss: 2.98865589461157
Validation loss: 3.3041053534036813

Epoch: 6| Step: 1
Training loss: 3.009484240172343
Validation loss: 3.300701433830656

Epoch: 6| Step: 2
Training loss: 3.4785466050873386
Validation loss: 3.2636419312945417

Epoch: 6| Step: 3
Training loss: 2.8677003490162716
Validation loss: 3.256143337450048

Epoch: 6| Step: 4
Training loss: 2.989160984169676
Validation loss: 3.2417572649299347

Epoch: 6| Step: 5
Training loss: 4.519868012248204
Validation loss: 3.2326939784701487

Epoch: 6| Step: 6
Training loss: 2.981757169245211
Validation loss: 3.2081910735607555

Epoch: 6| Step: 7
Training loss: 3.431884340111328
Validation loss: 3.2094792888561323

Epoch: 6| Step: 8
Training loss: 3.7681143355871156
Validation loss: 3.1984178501018103

Epoch: 6| Step: 9
Training loss: 3.2256081118674684
Validation loss: 3.1724881243817418

Epoch: 6| Step: 10
Training loss: 3.5942134392502636
Validation loss: 3.173354544899168

Epoch: 6| Step: 11
Training loss: 3.8220779926480786
Validation loss: 3.130131345840264

Epoch: 6| Step: 12
Training loss: 3.2491905965133383
Validation loss: 3.1306606436381132

Epoch: 6| Step: 13
Training loss: 3.162152955083029
Validation loss: 3.1413134776996197

Epoch: 24| Step: 0
Training loss: 3.465708868664722
Validation loss: 3.1090344367059344

Epoch: 6| Step: 1
Training loss: 3.7007206704687885
Validation loss: 3.098198721773844

Epoch: 6| Step: 2
Training loss: 3.477392753302073
Validation loss: 3.101538926298427

Epoch: 6| Step: 3
Training loss: 3.6351665130214568
Validation loss: 3.082302478808928

Epoch: 6| Step: 4
Training loss: 3.319249600092594
Validation loss: 3.1035591539123266

Epoch: 6| Step: 5
Training loss: 2.840636172970326
Validation loss: 3.0574385283201932

Epoch: 6| Step: 6
Training loss: 3.10985971631184
Validation loss: 3.048281393569465

Epoch: 6| Step: 7
Training loss: 3.538150358232179
Validation loss: 3.0505942270966777

Epoch: 6| Step: 8
Training loss: 2.408251932829861
Validation loss: 3.0215976538821634

Epoch: 6| Step: 9
Training loss: 2.861204468851054
Validation loss: 3.0474032440286964

Epoch: 6| Step: 10
Training loss: 4.390962526644971
Validation loss: 3.0191432868831862

Epoch: 6| Step: 11
Training loss: 2.8997901577501044
Validation loss: 2.9953877978280814

Epoch: 6| Step: 12
Training loss: 2.6839336418783435
Validation loss: 2.9870417849645223

Epoch: 6| Step: 13
Training loss: 2.8636589269588604
Validation loss: 3.0041795827567945

Epoch: 25| Step: 0
Training loss: 3.1434996245468785
Validation loss: 2.999718372566282

Epoch: 6| Step: 1
Training loss: 3.545959892360253
Validation loss: 2.978049251921027

Epoch: 6| Step: 2
Training loss: 2.706708528292048
Validation loss: 2.9899134331306834

Epoch: 6| Step: 3
Training loss: 3.253871519125498
Validation loss: 2.9710638022250833

Epoch: 6| Step: 4
Training loss: 3.4780518502685864
Validation loss: 2.953060247750167

Epoch: 6| Step: 5
Training loss: 3.2884315012299177
Validation loss: 2.9693288691019606

Epoch: 6| Step: 6
Training loss: 2.9544648859736298
Validation loss: 2.9627989417085687

Epoch: 6| Step: 7
Training loss: 3.56723430668002
Validation loss: 2.9644586994900823

Epoch: 6| Step: 8
Training loss: 3.319628261298679
Validation loss: 2.9594171114009415

Epoch: 6| Step: 9
Training loss: 3.0107421875
Validation loss: 2.964985228999421

Epoch: 6| Step: 10
Training loss: 3.213885288425174
Validation loss: 2.9336198599936014

Epoch: 6| Step: 11
Training loss: 2.699093143615573
Validation loss: 2.9528375474749575

Epoch: 6| Step: 12
Training loss: 2.8451011717494747
Validation loss: 2.940939356621665

Epoch: 6| Step: 13
Training loss: 4.119914995446162
Validation loss: 2.95612456627024

Epoch: 26| Step: 0
Training loss: 3.5352881644069
Validation loss: 2.95707530446459

Epoch: 6| Step: 1
Training loss: 3.266439381951227
Validation loss: 2.918960956316429

Epoch: 6| Step: 2
Training loss: 2.706337315514132
Validation loss: 2.9355025594540796

Epoch: 6| Step: 3
Training loss: 2.88586479223474
Validation loss: 2.940257493756193

Epoch: 6| Step: 4
Training loss: 4.19206217017919
Validation loss: 2.9561065720550945

Epoch: 6| Step: 5
Training loss: 3.8488502470058448
Validation loss: 2.9490218488721696

Epoch: 6| Step: 6
Training loss: 2.4889539830270997
Validation loss: 2.947609154053989

Epoch: 6| Step: 7
Training loss: 3.387385495210733
Validation loss: 2.9013089772835445

Epoch: 6| Step: 8
Training loss: 3.926885072002156
Validation loss: 2.9333749545361663

Epoch: 6| Step: 9
Training loss: 2.745599694121284
Validation loss: 2.9247880476565005

Epoch: 6| Step: 10
Training loss: 2.103287113284395
Validation loss: 2.9132400799784968

Epoch: 6| Step: 11
Training loss: 2.99496434695209
Validation loss: 2.9153256886127727

Epoch: 6| Step: 12
Training loss: 3.2498336162525607
Validation loss: 2.9057410327406386

Epoch: 6| Step: 13
Training loss: 2.929196085088026
Validation loss: 2.9186703314227254

Epoch: 27| Step: 0
Training loss: 3.128949378165234
Validation loss: 2.939432692225942

Epoch: 6| Step: 1
Training loss: 3.180880386075147
Validation loss: 2.9414239776747784

Epoch: 6| Step: 2
Training loss: 3.119929205017917
Validation loss: 2.92022277925612

Epoch: 6| Step: 3
Training loss: 3.1384035671138983
Validation loss: 2.9077326441420484

Epoch: 6| Step: 4
Training loss: 2.721547934221288
Validation loss: 2.9242888929220907

Epoch: 6| Step: 5
Training loss: 2.4265905925158706
Validation loss: 2.92117208286786

Epoch: 6| Step: 6
Training loss: 2.8930528497177104
Validation loss: 2.942265058332814

Epoch: 6| Step: 7
Training loss: 3.7688778325759413
Validation loss: 2.9121850901291366

Epoch: 6| Step: 8
Training loss: 3.0649709270150125
Validation loss: 2.932266642367309

Epoch: 6| Step: 9
Training loss: 4.477198157857943
Validation loss: 2.932049272740753

Epoch: 6| Step: 10
Training loss: 2.1314974912431355
Validation loss: 2.9207750906174

Epoch: 6| Step: 11
Training loss: 2.825326451707098
Validation loss: 2.9270508426116484

Epoch: 6| Step: 12
Training loss: 3.836445139685234
Validation loss: 2.9449955304642192

Epoch: 6| Step: 13
Training loss: 3.5288072086984448
Validation loss: 2.9398708441483787

Epoch: 28| Step: 0
Training loss: 3.4525952515386544
Validation loss: 2.913649020779786

Epoch: 6| Step: 1
Training loss: 4.059900479153986
Validation loss: 2.947620156188879

Epoch: 6| Step: 2
Training loss: 3.142484048273331
Validation loss: 2.886204443007453

Epoch: 6| Step: 3
Training loss: 3.0574252063152607
Validation loss: 2.9094366024680527

Epoch: 6| Step: 4
Training loss: 3.031969437316815
Validation loss: 2.9398627552340995

Epoch: 6| Step: 5
Training loss: 3.421046465895189
Validation loss: 2.9199974525211294

Epoch: 6| Step: 6
Training loss: 3.3297987476741304
Validation loss: 2.9143096054557396

Epoch: 6| Step: 7
Training loss: 3.8311673278352214
Validation loss: 2.882289569259127

Epoch: 6| Step: 8
Training loss: 2.6238340785788306
Validation loss: 2.8931727362278328

Epoch: 6| Step: 9
Training loss: 3.68954152636946
Validation loss: 2.9270763768633943

Epoch: 6| Step: 10
Training loss: 2.693369023760137
Validation loss: 2.9389459031388423

Epoch: 6| Step: 11
Training loss: 1.7735261600867591
Validation loss: 2.908633194979631

Epoch: 6| Step: 12
Training loss: 3.2150236614774492
Validation loss: 2.92189165994254

Epoch: 6| Step: 13
Training loss: 2.1389783108446694
Validation loss: 2.9216319354809

Epoch: 29| Step: 0
Training loss: 2.9302940452851307
Validation loss: 2.934541022292906

Epoch: 6| Step: 1
Training loss: 2.785798885472146
Validation loss: 2.957978844508837

Epoch: 6| Step: 2
Training loss: 3.327033351904158
Validation loss: 2.9369280853364543

Epoch: 6| Step: 3
Training loss: 3.0949337938958617
Validation loss: 2.9114826653457113

Epoch: 6| Step: 4
Training loss: 3.8727632034920836
Validation loss: 2.9265084608450636

Epoch: 6| Step: 5
Training loss: 3.307419821992099
Validation loss: 2.927702861430951

Epoch: 6| Step: 6
Training loss: 3.091028577106615
Validation loss: 2.881087486839761

Epoch: 6| Step: 7
Training loss: 3.673579043797456
Validation loss: 2.9276319426198576

Epoch: 6| Step: 8
Training loss: 2.457198338975303
Validation loss: 2.892470915653973

Epoch: 6| Step: 9
Training loss: 2.825945778576976
Validation loss: 2.9175780605394537

Epoch: 6| Step: 10
Training loss: 3.87263970632215
Validation loss: 2.9103992581756146

Epoch: 6| Step: 11
Training loss: 3.011656685077091
Validation loss: 2.91633854498484

Epoch: 6| Step: 12
Training loss: 3.26689174486521
Validation loss: 2.9245447799362396

Epoch: 6| Step: 13
Training loss: 2.3012056590734264
Validation loss: 2.9113732665502474

Epoch: 30| Step: 0
Training loss: 2.9850527008874055
Validation loss: 2.9086682467731317

Epoch: 6| Step: 1
Training loss: 3.9776988626060104
Validation loss: 2.907530103199328

Epoch: 6| Step: 2
Training loss: 2.6877195579090003
Validation loss: 2.8968232248948578

Epoch: 6| Step: 3
Training loss: 3.010618649650847
Validation loss: 2.888836493548117

Epoch: 6| Step: 4
Training loss: 3.1018007893152455
Validation loss: 2.9123685561109576

Epoch: 6| Step: 5
Training loss: 3.8953610438242006
Validation loss: 2.9174237166788908

Epoch: 6| Step: 6
Training loss: 3.013023558900876
Validation loss: 2.913710604188708

Epoch: 6| Step: 7
Training loss: 3.113692310339414
Validation loss: 2.8826320176067264

Epoch: 6| Step: 8
Training loss: 2.8840405502748885
Validation loss: 2.936816134820552

Epoch: 6| Step: 9
Training loss: 3.2118248374749663
Validation loss: 2.8685847637565627

Epoch: 6| Step: 10
Training loss: 3.4631694545897713
Validation loss: 2.93204502164241

Epoch: 6| Step: 11
Training loss: 3.0989788834774687
Validation loss: 2.874849544688353

Epoch: 6| Step: 12
Training loss: 2.606065124248381
Validation loss: 2.9259725121228266

Epoch: 6| Step: 13
Training loss: 3.564067027462463
Validation loss: 2.910682086191827

Epoch: 31| Step: 0
Training loss: 3.205537064614856
Validation loss: 2.908229179102811

Epoch: 6| Step: 1
Training loss: 3.407351114626605
Validation loss: 2.9051553122445974

Epoch: 6| Step: 2
Training loss: 2.9491370991905033
Validation loss: 2.909334153255104

Epoch: 6| Step: 3
Training loss: 3.2147737405044103
Validation loss: 2.9360130533261444

Epoch: 6| Step: 4
Training loss: 4.021203111369858
Validation loss: 2.8830097810285387

Epoch: 6| Step: 5
Training loss: 3.1762472751550197
Validation loss: 2.9025076894087785

Epoch: 6| Step: 6
Training loss: 2.905658456630675
Validation loss: 2.876002171367913

Epoch: 6| Step: 7
Training loss: 2.884364922238286
Validation loss: 2.9325063557601356

Epoch: 6| Step: 8
Training loss: 2.2579026781704643
Validation loss: 2.9083413406018788

Epoch: 6| Step: 9
Training loss: 3.007174813185237
Validation loss: 2.8904910104478274

Epoch: 6| Step: 10
Training loss: 3.0353336159666675
Validation loss: 2.9046318929654653

Epoch: 6| Step: 11
Training loss: 3.4900343570275094
Validation loss: 2.892446143927297

Epoch: 6| Step: 12
Training loss: 3.0593843765816473
Validation loss: 2.947188793907478

Epoch: 6| Step: 13
Training loss: 3.8175075976103177
Validation loss: 2.897701254719763

Epoch: 32| Step: 0
Training loss: 3.717648383067187
Validation loss: 2.9350513034515426

Epoch: 6| Step: 1
Training loss: 2.8826110273220817
Validation loss: 2.9097791457292033

Epoch: 6| Step: 2
Training loss: 3.362960817887488
Validation loss: 2.8904548521775677

Epoch: 6| Step: 3
Training loss: 3.2832893936650955
Validation loss: 2.8773207961179237

Epoch: 6| Step: 4
Training loss: 3.8690403054416267
Validation loss: 2.9061795253811655

Epoch: 6| Step: 5
Training loss: 3.0919467795703266
Validation loss: 2.928978349292481

Epoch: 6| Step: 6
Training loss: 2.6982306122229547
Validation loss: 2.9225960373164726

Epoch: 6| Step: 7
Training loss: 3.1316938805188634
Validation loss: 2.8904522437055813

Epoch: 6| Step: 8
Training loss: 2.8686529670876983
Validation loss: 2.875970781776177

Epoch: 6| Step: 9
Training loss: 3.4255789998290544
Validation loss: 2.895783118887284

Epoch: 6| Step: 10
Training loss: 2.6099973381876618
Validation loss: 2.900694968536586

Epoch: 6| Step: 11
Training loss: 2.7949716069070805
Validation loss: 2.868343344162788

Epoch: 6| Step: 12
Training loss: 3.371471821435976
Validation loss: 2.8978169068194495

Epoch: 6| Step: 13
Training loss: 3.137480570820382
Validation loss: 2.908465470412939

Epoch: 33| Step: 0
Training loss: 3.4695204145592595
Validation loss: 2.9118234932001226

Epoch: 6| Step: 1
Training loss: 3.510141937342148
Validation loss: 2.927842269343561

Epoch: 6| Step: 2
Training loss: 2.3615334849829677
Validation loss: 2.872705490076403

Epoch: 6| Step: 3
Training loss: 2.260454473457651
Validation loss: 2.901271960640554

Epoch: 6| Step: 4
Training loss: 3.091663157691575
Validation loss: 2.899500246130371

Epoch: 6| Step: 5
Training loss: 2.8315163190271377
Validation loss: 2.892049070698649

Epoch: 6| Step: 6
Training loss: 2.7091762307016913
Validation loss: 2.9012919959174432

Epoch: 6| Step: 7
Training loss: 3.473533425184157
Validation loss: 2.9064396198614317

Epoch: 6| Step: 8
Training loss: 3.8881608750847167
Validation loss: 2.8955409469774076

Epoch: 6| Step: 9
Training loss: 3.032803638726348
Validation loss: 2.898765429324489

Epoch: 6| Step: 10
Training loss: 2.6001045792894923
Validation loss: 2.9205432721897564

Epoch: 6| Step: 11
Training loss: 4.11664150606155
Validation loss: 2.9257756850941616

Epoch: 6| Step: 12
Training loss: 3.124292217210245
Validation loss: 2.904534846352261

Epoch: 6| Step: 13
Training loss: 3.723048826894948
Validation loss: 2.885517215602013

Epoch: 34| Step: 0
Training loss: 2.758250431378505
Validation loss: 2.9290671386203084

Epoch: 6| Step: 1
Training loss: 2.894634208958762
Validation loss: 2.869428905878506

Epoch: 6| Step: 2
Training loss: 2.757757602393798
Validation loss: 2.8987979181121886

Epoch: 6| Step: 3
Training loss: 2.2421263576770785
Validation loss: 2.8725826396171623

Epoch: 6| Step: 4
Training loss: 3.66839512630992
Validation loss: 2.887032000092965

Epoch: 6| Step: 5
Training loss: 2.392364068868427
Validation loss: 2.9056509959557992

Epoch: 6| Step: 6
Training loss: 3.596019525816526
Validation loss: 2.9093796348911556

Epoch: 6| Step: 7
Training loss: 2.7965458511093964
Validation loss: 2.877749442291771

Epoch: 6| Step: 8
Training loss: 3.9979227155779147
Validation loss: 2.894714120299861

Epoch: 6| Step: 9
Training loss: 2.62110430151099
Validation loss: 2.8694403082863285

Epoch: 6| Step: 10
Training loss: 3.5152422209150966
Validation loss: 2.9185428576534678

Epoch: 6| Step: 11
Training loss: 3.6622479140461732
Validation loss: 2.903018338015352

Epoch: 6| Step: 12
Training loss: 4.088108514409315
Validation loss: 2.9040088019277617

Epoch: 6| Step: 13
Training loss: 2.292822032179196
Validation loss: 2.8545475714515525

Epoch: 35| Step: 0
Training loss: 2.6909388342532767
Validation loss: 2.8619306030351286

Epoch: 6| Step: 1
Training loss: 2.6522930516831726
Validation loss: 2.883179495047814

Epoch: 6| Step: 2
Training loss: 2.8913772841298537
Validation loss: 2.8843663932117183

Epoch: 6| Step: 3
Training loss: 2.851428721177004
Validation loss: 2.890740757835766

Epoch: 6| Step: 4
Training loss: 3.2125358965460107
Validation loss: 2.8727876462564157

Epoch: 6| Step: 5
Training loss: 3.275718895436754
Validation loss: 2.88931830398607

Epoch: 6| Step: 6
Training loss: 3.090347114004215
Validation loss: 2.8922774797794815

Epoch: 6| Step: 7
Training loss: 3.1209347031499526
Validation loss: 2.8694896367471268

Epoch: 6| Step: 8
Training loss: 3.9141103775842345
Validation loss: 2.8856320420543473

Epoch: 6| Step: 9
Training loss: 3.3777138430696083
Validation loss: 2.8985190391541926

Epoch: 6| Step: 10
Training loss: 2.1565540486352432
Validation loss: 2.886084872842362

Epoch: 6| Step: 11
Training loss: 3.5087294028030613
Validation loss: 2.8707668479689685

Epoch: 6| Step: 12
Training loss: 3.723900185866871
Validation loss: 2.8775593893858202

Epoch: 6| Step: 13
Training loss: 3.3837157842895285
Validation loss: 2.8891067246914144

Epoch: 36| Step: 0
Training loss: 3.4931616053947185
Validation loss: 2.8698384184556205

Epoch: 6| Step: 1
Training loss: 3.836101831462838
Validation loss: 2.8806654406372303

Epoch: 6| Step: 2
Training loss: 2.4929711715127008
Validation loss: 2.864130143071127

Epoch: 6| Step: 3
Training loss: 2.737249465695659
Validation loss: 2.8574736063114567

Epoch: 6| Step: 4
Training loss: 4.279189010507305
Validation loss: 2.899022771117923

Epoch: 6| Step: 5
Training loss: 3.1574315040872905
Validation loss: 2.87009598956965

Epoch: 6| Step: 6
Training loss: 2.698158243525478
Validation loss: 2.8991483150590223

Epoch: 6| Step: 7
Training loss: 2.432621107860149
Validation loss: 2.858350332034929

Epoch: 6| Step: 8
Training loss: 2.9244001767957424
Validation loss: 2.879045792820114

Epoch: 6| Step: 9
Training loss: 3.147606827647805
Validation loss: 2.892710550261818

Epoch: 6| Step: 10
Training loss: 2.8933664879312966
Validation loss: 2.8725998710187053

Epoch: 6| Step: 11
Training loss: 3.114749270370402
Validation loss: 2.8640545476489954

Epoch: 6| Step: 12
Training loss: 3.0901665790186756
Validation loss: 2.8650428055944994

Epoch: 6| Step: 13
Training loss: 3.521642663395169
Validation loss: 2.8805920795614153

Epoch: 37| Step: 0
Training loss: 2.9179319816019307
Validation loss: 2.855614055277827

Epoch: 6| Step: 1
Training loss: 3.284371480749334
Validation loss: 2.8608505850086754

Epoch: 6| Step: 2
Training loss: 2.330493106644426
Validation loss: 2.8918149016175803

Epoch: 6| Step: 3
Training loss: 3.5018339801695926
Validation loss: 2.881876537914786

Epoch: 6| Step: 4
Training loss: 3.87343861286352
Validation loss: 2.8848867818687447

Epoch: 6| Step: 5
Training loss: 2.585846683255877
Validation loss: 2.882225526664055

Epoch: 6| Step: 6
Training loss: 2.7674232283422184
Validation loss: 2.878464522688885

Epoch: 6| Step: 7
Training loss: 2.9273359703284334
Validation loss: 2.8585574445352857

Epoch: 6| Step: 8
Training loss: 3.6997702810784707
Validation loss: 2.8692602937099623

Epoch: 6| Step: 9
Training loss: 2.8864656783943974
Validation loss: 2.8761928254258766

Epoch: 6| Step: 10
Training loss: 3.2890123377075944
Validation loss: 2.875313799239607

Epoch: 6| Step: 11
Training loss: 3.2931436693607496
Validation loss: 2.8653731905933015

Epoch: 6| Step: 12
Training loss: 3.295514445223871
Validation loss: 2.9050083072583037

Epoch: 6| Step: 13
Training loss: 3.0198314364550303
Validation loss: 2.8848643817035846

Epoch: 38| Step: 0
Training loss: 3.278327585075341
Validation loss: 2.8887517400621596

Epoch: 6| Step: 1
Training loss: 2.8938793112285355
Validation loss: 2.86969409963849

Epoch: 6| Step: 2
Training loss: 2.468634494059173
Validation loss: 2.876443503207271

Epoch: 6| Step: 3
Training loss: 3.767039053297024
Validation loss: 2.85377180905473

Epoch: 6| Step: 4
Training loss: 2.714593977381541
Validation loss: 2.8931790966473208

Epoch: 6| Step: 5
Training loss: 3.169996033915737
Validation loss: 2.877672105747314

Epoch: 6| Step: 6
Training loss: 3.9515407840709766
Validation loss: 2.861394621614549

Epoch: 6| Step: 7
Training loss: 3.214652110213058
Validation loss: 2.8770608439814045

Epoch: 6| Step: 8
Training loss: 2.073699368898684
Validation loss: 2.8829875672456153

Epoch: 6| Step: 9
Training loss: 2.9628468499567826
Validation loss: 2.890143594562005

Epoch: 6| Step: 10
Training loss: 2.5110474634215714
Validation loss: 2.8716324241239755

Epoch: 6| Step: 11
Training loss: 3.5773781076028097
Validation loss: 2.8959818285757972

Epoch: 6| Step: 12
Training loss: 3.4897241972015753
Validation loss: 2.9011989960364137

Epoch: 6| Step: 13
Training loss: 2.8336690442031505
Validation loss: 2.881117962910957

Epoch: 39| Step: 0
Training loss: 4.05308168692523
Validation loss: 2.8389456976310523

Epoch: 6| Step: 1
Training loss: 3.1114625297103458
Validation loss: 2.885427057740558

Epoch: 6| Step: 2
Training loss: 3.2771505269321817
Validation loss: 2.883432021103856

Epoch: 6| Step: 3
Training loss: 3.568327838359547
Validation loss: 2.8929545347121985

Epoch: 6| Step: 4
Training loss: 3.180834214294754
Validation loss: 2.9123065719654457

Epoch: 6| Step: 5
Training loss: 2.8652287166568193
Validation loss: 2.8362667089615012

Epoch: 6| Step: 6
Training loss: 2.9660896025773695
Validation loss: 2.8892543834709636

Epoch: 6| Step: 7
Training loss: 3.1172125870309424
Validation loss: 2.8825588817847425

Epoch: 6| Step: 8
Training loss: 2.914203221091206
Validation loss: 2.8361222591639503

Epoch: 6| Step: 9
Training loss: 3.12335955478188
Validation loss: 2.8793836704148723

Epoch: 6| Step: 10
Training loss: 2.3245536498805737
Validation loss: 2.8585562140839906

Epoch: 6| Step: 11
Training loss: 3.2943069074060336
Validation loss: 2.8856865254059128

Epoch: 6| Step: 12
Training loss: 3.1079651976788463
Validation loss: 2.8416344130516435

Epoch: 6| Step: 13
Training loss: 2.7098192002630017
Validation loss: 2.870879084486881

Epoch: 40| Step: 0
Training loss: 2.7389068541884387
Validation loss: 2.8705374712259646

Epoch: 6| Step: 1
Training loss: 2.8440206210304946
Validation loss: 2.8533944190835996

Epoch: 6| Step: 2
Training loss: 3.1417005225127266
Validation loss: 2.8537630772335585

Epoch: 6| Step: 3
Training loss: 3.127729520845178
Validation loss: 2.8790628777956453

Epoch: 6| Step: 4
Training loss: 3.1849612429190537
Validation loss: 2.8346541370553706

Epoch: 6| Step: 5
Training loss: 2.8046120126070497
Validation loss: 2.859115641721304

Epoch: 6| Step: 6
Training loss: 3.3661920974686734
Validation loss: 2.862939253988675

Epoch: 6| Step: 7
Training loss: 2.496766956269094
Validation loss: 2.855418354230122

Epoch: 6| Step: 8
Training loss: 3.21705508744705
Validation loss: 2.883653284867324

Epoch: 6| Step: 9
Training loss: 3.205122757344629
Validation loss: 2.8500730509841703

Epoch: 6| Step: 10
Training loss: 3.8250790058029867
Validation loss: 2.8679055509045694

Epoch: 6| Step: 11
Training loss: 3.771680339856437
Validation loss: 2.86843889021188

Epoch: 6| Step: 12
Training loss: 2.537452163621221
Validation loss: 2.8619586083503497

Epoch: 6| Step: 13
Training loss: 3.0771946154500824
Validation loss: 2.8329982094906425

Epoch: 41| Step: 0
Training loss: 3.152614199016714
Validation loss: 2.852737325445758

Epoch: 6| Step: 1
Training loss: 2.6974756378685854
Validation loss: 2.840614119682989

Epoch: 6| Step: 2
Training loss: 3.3862217029108783
Validation loss: 2.832545135233724

Epoch: 6| Step: 3
Training loss: 2.2572683978909525
Validation loss: 2.8433645285330145

Epoch: 6| Step: 4
Training loss: 3.223665502475495
Validation loss: 2.8589467158757578

Epoch: 6| Step: 5
Training loss: 2.867309900316519
Validation loss: 2.870811421621951

Epoch: 6| Step: 6
Training loss: 3.531642925716124
Validation loss: 2.8790455203430056

Epoch: 6| Step: 7
Training loss: 2.6924024711945522
Validation loss: 2.8712949718987177

Epoch: 6| Step: 8
Training loss: 3.8886314094924965
Validation loss: 2.8354313904261983

Epoch: 6| Step: 9
Training loss: 3.6717459148686324
Validation loss: 2.8414764908179553

Epoch: 6| Step: 10
Training loss: 2.574490291183755
Validation loss: 2.850458981403994

Epoch: 6| Step: 11
Training loss: 2.7820416298993735
Validation loss: 2.8997123207116107

Epoch: 6| Step: 12
Training loss: 3.6246206150811817
Validation loss: 2.852096593457107

Epoch: 6| Step: 13
Training loss: 3.419519597940723
Validation loss: 2.8224427229061795

Epoch: 42| Step: 0
Training loss: 3.099569838427354
Validation loss: 2.861598196348683

Epoch: 6| Step: 1
Training loss: 3.3770634030305646
Validation loss: 2.849780004012941

Epoch: 6| Step: 2
Training loss: 2.6426198072169984
Validation loss: 2.84678624301152

Epoch: 6| Step: 3
Training loss: 2.9334242120305496
Validation loss: 2.842451830364976

Epoch: 6| Step: 4
Training loss: 3.1526325003771185
Validation loss: 2.8271156331376743

Epoch: 6| Step: 5
Training loss: 2.742361036064366
Validation loss: 2.8763944285827656

Epoch: 6| Step: 6
Training loss: 3.2759148230000226
Validation loss: 2.8151373416980108

Epoch: 6| Step: 7
Training loss: 3.679887187099332
Validation loss: 2.8863537912768065

Epoch: 6| Step: 8
Training loss: 3.0565473353375667
Validation loss: 2.8656523689634814

Epoch: 6| Step: 9
Training loss: 3.323551384427754
Validation loss: 2.830369806173772

Epoch: 6| Step: 10
Training loss: 3.310230413294386
Validation loss: 2.84448086842673

Epoch: 6| Step: 11
Training loss: 3.105149968897751
Validation loss: 2.826233706373479

Epoch: 6| Step: 12
Training loss: 2.387100114337809
Validation loss: 2.8630857667987093

Epoch: 6| Step: 13
Training loss: 2.727413449124837
Validation loss: 2.8217245523494374

Epoch: 43| Step: 0
Training loss: 3.80763021165059
Validation loss: 2.8660224800185707

Epoch: 6| Step: 1
Training loss: 3.945924133631003
Validation loss: 2.8681656463598677

Epoch: 6| Step: 2
Training loss: 3.1350502146421255
Validation loss: 2.8445179932311553

Epoch: 6| Step: 3
Training loss: 3.417635028350997
Validation loss: 2.850797274127264

Epoch: 6| Step: 4
Training loss: 2.4685432250913264
Validation loss: 2.844182288681891

Epoch: 6| Step: 5
Training loss: 3.4587814469694944
Validation loss: 2.838153427741894

Epoch: 6| Step: 6
Training loss: 3.3416513292019308
Validation loss: 2.848330699668599

Epoch: 6| Step: 7
Training loss: 2.9511647656681412
Validation loss: 2.8719708560959725

Epoch: 6| Step: 8
Training loss: 2.655555903684344
Validation loss: 2.8366455823126473

Epoch: 6| Step: 9
Training loss: 2.3452131663309896
Validation loss: 2.788143940696461

Epoch: 6| Step: 10
Training loss: 3.0865635490357763
Validation loss: 2.8389929597913803

Epoch: 6| Step: 11
Training loss: 2.687021612128002
Validation loss: 2.819850223476219

Epoch: 6| Step: 12
Training loss: 2.59900307983122
Validation loss: 2.8359144736394497

Epoch: 6| Step: 13
Training loss: 2.467874395843696
Validation loss: 2.816191363972467

Epoch: 44| Step: 0
Training loss: 2.662001721674637
Validation loss: 2.8274997982583843

Epoch: 6| Step: 1
Training loss: 3.536514543958346
Validation loss: 2.873614220226708

Epoch: 6| Step: 2
Training loss: 3.4416373583367013
Validation loss: 2.8360001905610646

Epoch: 6| Step: 3
Training loss: 3.3750856176748676
Validation loss: 2.8467136865998524

Epoch: 6| Step: 4
Training loss: 3.241110307924926
Validation loss: 2.8248988498703786

Epoch: 6| Step: 5
Training loss: 2.709605392639227
Validation loss: 2.8512155809250173

Epoch: 6| Step: 6
Training loss: 3.3464108156784995
Validation loss: 2.813910389777143

Epoch: 6| Step: 7
Training loss: 3.698124209028852
Validation loss: 2.860345924970789

Epoch: 6| Step: 8
Training loss: 2.795373694835901
Validation loss: 2.829735258919094

Epoch: 6| Step: 9
Training loss: 2.6431669381369214
Validation loss: 2.847140204682876

Epoch: 6| Step: 10
Training loss: 2.421095199559908
Validation loss: 2.847203275262509

Epoch: 6| Step: 11
Training loss: 3.215984749202722
Validation loss: 2.840927154558166

Epoch: 6| Step: 12
Training loss: 2.717221937789422
Validation loss: 2.8213290985269563

Epoch: 6| Step: 13
Training loss: 3.2999630608080683
Validation loss: 2.805275947556478

Epoch: 45| Step: 0
Training loss: 3.138706209461396
Validation loss: 2.832998591367437

Epoch: 6| Step: 1
Training loss: 3.167349758423831
Validation loss: 2.833671061699369

Epoch: 6| Step: 2
Training loss: 3.034397025377066
Validation loss: 2.8207165360466186

Epoch: 6| Step: 3
Training loss: 2.9760709742214675
Validation loss: 2.8586971762330715

Epoch: 6| Step: 4
Training loss: 3.1894372774981368
Validation loss: 2.8094116172049945

Epoch: 6| Step: 5
Training loss: 2.419195156877958
Validation loss: 2.8636709302115095

Epoch: 6| Step: 6
Training loss: 3.175543707002473
Validation loss: 2.830491139413656

Epoch: 6| Step: 7
Training loss: 2.8946379977785814
Validation loss: 2.806853789864398

Epoch: 6| Step: 8
Training loss: 3.014557802785989
Validation loss: 2.7970063671417202

Epoch: 6| Step: 9
Training loss: 3.2201163345551427
Validation loss: 2.8523236396034255

Epoch: 6| Step: 10
Training loss: 3.2136857275098003
Validation loss: 2.8019895240922974

Epoch: 6| Step: 11
Training loss: 3.112852672527927
Validation loss: 2.835413701681548

Epoch: 6| Step: 12
Training loss: 3.3509805525326684
Validation loss: 2.832767991758409

Epoch: 6| Step: 13
Training loss: 3.3190529262992605
Validation loss: 2.8803893862043886

Epoch: 46| Step: 0
Training loss: 2.7933865748166626
Validation loss: 2.8337019672096657

Epoch: 6| Step: 1
Training loss: 3.076478314349794
Validation loss: 2.779653071608471

Epoch: 6| Step: 2
Training loss: 2.645905491202905
Validation loss: 2.842389913450642

Epoch: 6| Step: 3
Training loss: 3.9413218040228855
Validation loss: 2.853227756584698

Epoch: 6| Step: 4
Training loss: 3.235012268090312
Validation loss: 2.810888483643785

Epoch: 6| Step: 5
Training loss: 3.7090931374752265
Validation loss: 2.7632085830654476

Epoch: 6| Step: 6
Training loss: 2.4102556650193887
Validation loss: 2.8308167878399875

Epoch: 6| Step: 7
Training loss: 3.8097390355324685
Validation loss: 2.8703323458514345

Epoch: 6| Step: 8
Training loss: 2.9630692590967396
Validation loss: 2.792187082206022

Epoch: 6| Step: 9
Training loss: 2.9957768597185437
Validation loss: 2.771057230578674

Epoch: 6| Step: 10
Training loss: 2.3270935231403773
Validation loss: 2.7871620625161992

Epoch: 6| Step: 11
Training loss: 2.742009866291885
Validation loss: 2.8063132582353694

Epoch: 6| Step: 12
Training loss: 3.244202798687411
Validation loss: 2.8207170450090073

Epoch: 6| Step: 13
Training loss: 2.0709819359168837
Validation loss: 2.7951415613752264

Epoch: 47| Step: 0
Training loss: 3.048709884198202
Validation loss: 2.7969107750182176

Epoch: 6| Step: 1
Training loss: 3.6931990210926102
Validation loss: 2.803603333721038

Epoch: 6| Step: 2
Training loss: 2.7755247187048875
Validation loss: 2.8237950386106303

Epoch: 6| Step: 3
Training loss: 3.1352727271885836
Validation loss: 2.8157137431199324

Epoch: 6| Step: 4
Training loss: 4.017254806660965
Validation loss: 2.8205752663498136

Epoch: 6| Step: 5
Training loss: 3.0667071346708847
Validation loss: 2.7998869061520004

Epoch: 6| Step: 6
Training loss: 2.7945284243284916
Validation loss: 2.8299763358579906

Epoch: 6| Step: 7
Training loss: 3.241561792502845
Validation loss: 2.7797906246913873

Epoch: 6| Step: 8
Training loss: 2.6536064906225216
Validation loss: 2.797847758065448

Epoch: 6| Step: 9
Training loss: 2.489682843335751
Validation loss: 2.7821752215169173

Epoch: 6| Step: 10
Training loss: 3.207550415689433
Validation loss: 2.76788726758302

Epoch: 6| Step: 11
Training loss: 2.081151264586524
Validation loss: 2.78485931772862

Epoch: 6| Step: 12
Training loss: 2.8179872178545193
Validation loss: 2.8207721305561324

Epoch: 6| Step: 13
Training loss: 3.539074895639164
Validation loss: 2.7711272643929306

Epoch: 48| Step: 0
Training loss: 3.0057381747413823
Validation loss: 2.8215825117630087

Epoch: 6| Step: 1
Training loss: 2.8057901664142273
Validation loss: 2.8015896594495664

Epoch: 6| Step: 2
Training loss: 3.693809800543381
Validation loss: 2.795335202915438

Epoch: 6| Step: 3
Training loss: 3.276514177962035
Validation loss: 2.794501637661723

Epoch: 6| Step: 4
Training loss: 2.9314020048311735
Validation loss: 2.7688839723266674

Epoch: 6| Step: 5
Training loss: 2.8029432903409206
Validation loss: 2.830146771676832

Epoch: 6| Step: 6
Training loss: 3.001882280495381
Validation loss: 2.7838959504819076

Epoch: 6| Step: 7
Training loss: 3.167252503129345
Validation loss: 2.7947250364200147

Epoch: 6| Step: 8
Training loss: 2.992053633999643
Validation loss: 2.768180479003286

Epoch: 6| Step: 9
Training loss: 2.674430116217884
Validation loss: 2.799277762026531

Epoch: 6| Step: 10
Training loss: 3.13317077566753
Validation loss: 2.794387422429176

Epoch: 6| Step: 11
Training loss: 2.826947551962691
Validation loss: 2.775522207272727

Epoch: 6| Step: 12
Training loss: 3.3190024989280476
Validation loss: 2.7865550608153393

Epoch: 6| Step: 13
Training loss: 2.932308072755133
Validation loss: 2.779009748328931

Epoch: 49| Step: 0
Training loss: 3.0234130542959567
Validation loss: 2.808771782959764

Epoch: 6| Step: 1
Training loss: 3.683130552713949
Validation loss: 2.796942221458794

Epoch: 6| Step: 2
Training loss: 3.2570249488350536
Validation loss: 2.818186503385304

Epoch: 6| Step: 3
Training loss: 3.7081136459827437
Validation loss: 2.802249169023541

Epoch: 6| Step: 4
Training loss: 2.43783821302667
Validation loss: 2.7868534047655986

Epoch: 6| Step: 5
Training loss: 2.7560566183400685
Validation loss: 2.8045886019983635

Epoch: 6| Step: 6
Training loss: 2.648764711044814
Validation loss: 2.770729149645365

Epoch: 6| Step: 7
Training loss: 2.6491178915792153
Validation loss: 2.7734394374472635

Epoch: 6| Step: 8
Training loss: 3.3952894340816546
Validation loss: 2.7983794188742097

Epoch: 6| Step: 9
Training loss: 2.9370381418309544
Validation loss: 2.806902999831618

Epoch: 6| Step: 10
Training loss: 2.9481624505302957
Validation loss: 2.820727440545705

Epoch: 6| Step: 11
Training loss: 3.2942630491302958
Validation loss: 2.7619625614637657

Epoch: 6| Step: 12
Training loss: 3.0444254100356125
Validation loss: 2.780426189128664

Epoch: 6| Step: 13
Training loss: 2.7679521500415127
Validation loss: 2.817216474760716

Epoch: 50| Step: 0
Training loss: 2.4854771310678516
Validation loss: 2.778742819850653

Epoch: 6| Step: 1
Training loss: 3.0052882315572207
Validation loss: 2.763763530803806

Epoch: 6| Step: 2
Training loss: 2.6293550422841356
Validation loss: 2.80896010682136

Epoch: 6| Step: 3
Training loss: 2.8357221032934334
Validation loss: 2.8248078245586026

Epoch: 6| Step: 4
Training loss: 2.282508085138347
Validation loss: 2.7697720477856387

Epoch: 6| Step: 5
Training loss: 3.116830293844604
Validation loss: 2.7817255682561877

Epoch: 6| Step: 6
Training loss: 2.545881112540543
Validation loss: 2.750893691864026

Epoch: 6| Step: 7
Training loss: 3.584908930048735
Validation loss: 2.7862193993723117

Epoch: 6| Step: 8
Training loss: 3.122205476576432
Validation loss: 2.8114042291845363

Epoch: 6| Step: 9
Training loss: 4.355123655050595
Validation loss: 2.7875524265695786

Epoch: 6| Step: 10
Training loss: 2.7883703404091498
Validation loss: 2.76739580413307

Epoch: 6| Step: 11
Training loss: 3.0708583511582583
Validation loss: 2.767904815936198

Epoch: 6| Step: 12
Training loss: 3.5137857330687483
Validation loss: 2.7833695943601233

Epoch: 6| Step: 13
Training loss: 3.151300458553282
Validation loss: 2.8017930695015147

Epoch: 51| Step: 0
Training loss: 2.911251399693822
Validation loss: 2.7500602458272474

Epoch: 6| Step: 1
Training loss: 3.3238606960517783
Validation loss: 2.8236771745673845

Epoch: 6| Step: 2
Training loss: 3.1302807249985367
Validation loss: 2.8535018028550088

Epoch: 6| Step: 3
Training loss: 3.2377720192001522
Validation loss: 2.7947055975496666

Epoch: 6| Step: 4
Training loss: 3.212406759727262
Validation loss: 2.762364079770336

Epoch: 6| Step: 5
Training loss: 3.446841776351385
Validation loss: 2.8059778260887223

Epoch: 6| Step: 6
Training loss: 2.756568866026563
Validation loss: 2.7687500690365843

Epoch: 6| Step: 7
Training loss: 2.931912729138052
Validation loss: 2.8058698377898867

Epoch: 6| Step: 8
Training loss: 3.333476746970828
Validation loss: 2.7821519971463733

Epoch: 6| Step: 9
Training loss: 2.7702948159278975
Validation loss: 2.761014409666016

Epoch: 6| Step: 10
Training loss: 2.7055843389165
Validation loss: 2.8131867467019576

Epoch: 6| Step: 11
Training loss: 2.99530376976305
Validation loss: 2.7801037608997023

Epoch: 6| Step: 12
Training loss: 2.6471138406159764
Validation loss: 2.7529170114201023

Epoch: 6| Step: 13
Training loss: 2.8863801047770767
Validation loss: 2.8085292427837816

Epoch: 52| Step: 0
Training loss: 2.5307989778302273
Validation loss: 2.764844590216828

Epoch: 6| Step: 1
Training loss: 3.241253306912737
Validation loss: 2.771279678336412

Epoch: 6| Step: 2
Training loss: 3.174452612841199
Validation loss: 2.7978192017339225

Epoch: 6| Step: 3
Training loss: 2.865986835095449
Validation loss: 2.818309286240104

Epoch: 6| Step: 4
Training loss: 2.5890942808144874
Validation loss: 2.7949654706105127

Epoch: 6| Step: 5
Training loss: 3.8591584056045614
Validation loss: 2.8359059074095514

Epoch: 6| Step: 6
Training loss: 3.1751537195674953
Validation loss: 2.78764347836725

Epoch: 6| Step: 7
Training loss: 3.042864541851338
Validation loss: 2.785604620587745

Epoch: 6| Step: 8
Training loss: 3.3015803165559854
Validation loss: 2.799199958188619

Epoch: 6| Step: 9
Training loss: 3.79520734419088
Validation loss: 2.8254821109325228

Epoch: 6| Step: 10
Training loss: 2.6388404730209105
Validation loss: 2.815248071554031

Epoch: 6| Step: 11
Training loss: 3.0630111267804367
Validation loss: 2.828038066261455

Epoch: 6| Step: 12
Training loss: 2.2905917218589567
Validation loss: 2.7921846013693625

Epoch: 6| Step: 13
Training loss: 1.5302902639470566
Validation loss: 2.761188003835706

Epoch: 53| Step: 0
Training loss: 3.286611046646079
Validation loss: 2.822984773092561

Epoch: 6| Step: 1
Training loss: 2.8644727280967026
Validation loss: 2.720788540558046

Epoch: 6| Step: 2
Training loss: 3.3080238472979593
Validation loss: 2.784103815335454

Epoch: 6| Step: 3
Training loss: 3.312895841159229
Validation loss: 2.7924477643540375

Epoch: 6| Step: 4
Training loss: 2.885222629307226
Validation loss: 2.751451188649645

Epoch: 6| Step: 5
Training loss: 2.8316658573549884
Validation loss: 2.81569203819172

Epoch: 6| Step: 6
Training loss: 2.6813818910255995
Validation loss: 2.785470661475664

Epoch: 6| Step: 7
Training loss: 3.405611030772587
Validation loss: 2.7738890780993146

Epoch: 6| Step: 8
Training loss: 2.585422891081132
Validation loss: 2.767802909545446

Epoch: 6| Step: 9
Training loss: 3.108468695208198
Validation loss: 2.774993038750775

Epoch: 6| Step: 10
Training loss: 2.80834942897029
Validation loss: 2.7916680178197444

Epoch: 6| Step: 11
Training loss: 2.8590844845799537
Validation loss: 2.781307345687814

Epoch: 6| Step: 12
Training loss: 3.518288243623903
Validation loss: 2.760939774698973

Epoch: 6| Step: 13
Training loss: 3.1237276157219793
Validation loss: 2.7729184908471924

Epoch: 54| Step: 0
Training loss: 2.5484309212174625
Validation loss: 2.744415065585492

Epoch: 6| Step: 1
Training loss: 1.6658836750758672
Validation loss: 2.7538869800822896

Epoch: 6| Step: 2
Training loss: 2.6449189796369934
Validation loss: 2.8017784697236072

Epoch: 6| Step: 3
Training loss: 3.7657265550523924
Validation loss: 2.739978489629308

Epoch: 6| Step: 4
Training loss: 3.2331682248252305
Validation loss: 2.795221744458256

Epoch: 6| Step: 5
Training loss: 3.3998585503269756
Validation loss: 2.7801420321493038

Epoch: 6| Step: 6
Training loss: 2.7318817979199608
Validation loss: 2.777021299913015

Epoch: 6| Step: 7
Training loss: 2.897410249282784
Validation loss: 2.7541101519112314

Epoch: 6| Step: 8
Training loss: 3.100212360614705
Validation loss: 2.788295691108187

Epoch: 6| Step: 9
Training loss: 3.475578117308215
Validation loss: 2.734579495753904

Epoch: 6| Step: 10
Training loss: 3.1813270784344807
Validation loss: 2.8044117944487

Epoch: 6| Step: 11
Training loss: 2.7816134440376112
Validation loss: 2.766628760144741

Epoch: 6| Step: 12
Training loss: 3.1542037524953677
Validation loss: 2.7852355175321457

Epoch: 6| Step: 13
Training loss: 2.808101860339905
Validation loss: 2.7507600768686076

Epoch: 55| Step: 0
Training loss: 2.951214530631507
Validation loss: 2.7205109589304373

Epoch: 6| Step: 1
Training loss: 2.6781056353337425
Validation loss: 2.745571894125813

Epoch: 6| Step: 2
Training loss: 2.3089479539373987
Validation loss: 2.7818264632869822

Epoch: 6| Step: 3
Training loss: 2.7339268780399
Validation loss: 2.7592119330416893

Epoch: 6| Step: 4
Training loss: 3.1379939203440483
Validation loss: 2.776496539802028

Epoch: 6| Step: 5
Training loss: 3.180376357833428
Validation loss: 2.7123425880298266

Epoch: 6| Step: 6
Training loss: 3.5526213625339005
Validation loss: 2.7303442742018125

Epoch: 6| Step: 7
Training loss: 3.2433518123067615
Validation loss: 2.7176258184920283

Epoch: 6| Step: 8
Training loss: 2.4512411282547575
Validation loss: 2.7737768977429593

Epoch: 6| Step: 9
Training loss: 3.198439432133332
Validation loss: 2.76484086275875

Epoch: 6| Step: 10
Training loss: 3.1250750723404503
Validation loss: 2.7788395176050407

Epoch: 6| Step: 11
Training loss: 2.906543347720404
Validation loss: 2.791068785523743

Epoch: 6| Step: 12
Training loss: 3.676693356216225
Validation loss: 2.742438865144221

Epoch: 6| Step: 13
Training loss: 2.3065034597831096
Validation loss: 2.778943000854488

Epoch: 56| Step: 0
Training loss: 2.5469386555024403
Validation loss: 2.7775802164340093

Epoch: 6| Step: 1
Training loss: 2.452987667054292
Validation loss: 2.787882597719759

Epoch: 6| Step: 2
Training loss: 3.201894830943523
Validation loss: 2.802582497140622

Epoch: 6| Step: 3
Training loss: 3.147304435150742
Validation loss: 2.773291045959309

Epoch: 6| Step: 4
Training loss: 2.8922329116462873
Validation loss: 2.753163027947988

Epoch: 6| Step: 5
Training loss: 2.476512824201122
Validation loss: 2.752112542047606

Epoch: 6| Step: 6
Training loss: 3.148603789905244
Validation loss: 2.78071236745827

Epoch: 6| Step: 7
Training loss: 2.7104122301593647
Validation loss: 2.7521576215299812

Epoch: 6| Step: 8
Training loss: 2.686947521820229
Validation loss: 2.782540217843451

Epoch: 6| Step: 9
Training loss: 3.685138010574695
Validation loss: 2.779684607222716

Epoch: 6| Step: 10
Training loss: 3.559547673324783
Validation loss: 2.7558989047978013

Epoch: 6| Step: 11
Training loss: 2.866408073235486
Validation loss: 2.7930068908606756

Epoch: 6| Step: 12
Training loss: 3.00487043485426
Validation loss: 2.749491484229234

Epoch: 6| Step: 13
Training loss: 3.453119338363218
Validation loss: 2.7278119713890328

Epoch: 57| Step: 0
Training loss: 3.0222880226183935
Validation loss: 2.7908085817644714

Epoch: 6| Step: 1
Training loss: 4.174979322919068
Validation loss: 2.7734996251992667

Epoch: 6| Step: 2
Training loss: 2.8925365828802896
Validation loss: 2.7627871575195786

Epoch: 6| Step: 3
Training loss: 3.0932277662525944
Validation loss: 2.7552700092037417

Epoch: 6| Step: 4
Training loss: 3.11507747817086
Validation loss: 2.7629452127380763

Epoch: 6| Step: 5
Training loss: 1.9484987936038187
Validation loss: 2.792686425530036

Epoch: 6| Step: 6
Training loss: 2.6205850440121936
Validation loss: 2.7864401095168825

Epoch: 6| Step: 7
Training loss: 3.630045569267821
Validation loss: 2.7677689998121062

Epoch: 6| Step: 8
Training loss: 2.660843411729289
Validation loss: 2.7213357527464552

Epoch: 6| Step: 9
Training loss: 3.0762166725408755
Validation loss: 2.7436238236905353

Epoch: 6| Step: 10
Training loss: 3.401216760463843
Validation loss: 2.748911426806149

Epoch: 6| Step: 11
Training loss: 2.6788763926241965
Validation loss: 2.817680917541705

Epoch: 6| Step: 12
Training loss: 2.556909370722852
Validation loss: 2.7404352070266524

Epoch: 6| Step: 13
Training loss: 2.7136125805473204
Validation loss: 2.751479660186312

Epoch: 58| Step: 0
Training loss: 2.326927747679313
Validation loss: 2.799644384676608

Epoch: 6| Step: 1
Training loss: 2.4180101628369983
Validation loss: 2.7639025072579306

Epoch: 6| Step: 2
Training loss: 2.751709406763592
Validation loss: 2.704651321462337

Epoch: 6| Step: 3
Training loss: 2.853789330109953
Validation loss: 2.7903014787502807

Epoch: 6| Step: 4
Training loss: 3.1887443955752395
Validation loss: 2.754244810698595

Epoch: 6| Step: 5
Training loss: 2.707394442063622
Validation loss: 2.758105997501525

Epoch: 6| Step: 6
Training loss: 2.502483469539774
Validation loss: 2.722626308984435

Epoch: 6| Step: 7
Training loss: 3.359596848370581
Validation loss: 2.7665022935999897

Epoch: 6| Step: 8
Training loss: 3.3532417554339475
Validation loss: 2.8051264847767827

Epoch: 6| Step: 9
Training loss: 3.172511445634304
Validation loss: 2.7660708097371183

Epoch: 6| Step: 10
Training loss: 3.180919211826281
Validation loss: 2.7329408546431506

Epoch: 6| Step: 11
Training loss: 3.8332135693182257
Validation loss: 2.7616482886820197

Epoch: 6| Step: 12
Training loss: 3.499515091138758
Validation loss: 2.793897796646718

Epoch: 6| Step: 13
Training loss: 2.2715292981101634
Validation loss: 2.718809970849165

Epoch: 59| Step: 0
Training loss: 2.9497377052726614
Validation loss: 2.765878727720106

Epoch: 6| Step: 1
Training loss: 3.609172072217533
Validation loss: 2.767375497963343

Epoch: 6| Step: 2
Training loss: 3.049375163627756
Validation loss: 2.7859371869085763

Epoch: 6| Step: 3
Training loss: 2.9653123728997035
Validation loss: 2.7796661985023916

Epoch: 6| Step: 4
Training loss: 2.8048025973619706
Validation loss: 2.7213122512659678

Epoch: 6| Step: 5
Training loss: 3.3475038366886913
Validation loss: 2.7268253839875314

Epoch: 6| Step: 6
Training loss: 2.6752262625860777
Validation loss: 2.733246340469042

Epoch: 6| Step: 7
Training loss: 2.5157029986876833
Validation loss: 2.7575446631517218

Epoch: 6| Step: 8
Training loss: 3.1905960305866845
Validation loss: 2.7470657079533165

Epoch: 6| Step: 9
Training loss: 3.012842822057328
Validation loss: 2.7034340939645

Epoch: 6| Step: 10
Training loss: 2.7968656230748015
Validation loss: 2.6664820650126706

Epoch: 6| Step: 11
Training loss: 3.0875224618442174
Validation loss: 2.7206287161110905

Epoch: 6| Step: 12
Training loss: 2.935445188587277
Validation loss: 2.716130151495838

Epoch: 6| Step: 13
Training loss: 3.0785204638193955
Validation loss: 2.7574763185653053

Epoch: 60| Step: 0
Training loss: 3.589584191769265
Validation loss: 2.75256391834952

Epoch: 6| Step: 1
Training loss: 2.968156454080694
Validation loss: 2.7934466916205194

Epoch: 6| Step: 2
Training loss: 2.4969259435925695
Validation loss: 2.7474768111081476

Epoch: 6| Step: 3
Training loss: 2.7992816991432727
Validation loss: 2.683743103383157

Epoch: 6| Step: 4
Training loss: 2.5424526646051473
Validation loss: 2.708487491306389

Epoch: 6| Step: 5
Training loss: 2.6470851990376802
Validation loss: 2.701934058933701

Epoch: 6| Step: 6
Training loss: 2.883093843455058
Validation loss: 2.7043310042060296

Epoch: 6| Step: 7
Training loss: 3.8979758560740385
Validation loss: 2.7035243109125573

Epoch: 6| Step: 8
Training loss: 2.638629497919103
Validation loss: 2.7250353039158086

Epoch: 6| Step: 9
Training loss: 3.083060553229198
Validation loss: 2.7369571121067366

Epoch: 6| Step: 10
Training loss: 3.0052580848599693
Validation loss: 2.7396757466721042

Epoch: 6| Step: 11
Training loss: 3.556989724938816
Validation loss: 2.753258429423151

Epoch: 6| Step: 12
Training loss: 2.6430519282608502
Validation loss: 2.7474804744134698

Epoch: 6| Step: 13
Training loss: 2.836155738525116
Validation loss: 2.7605550021248426

Epoch: 61| Step: 0
Training loss: 3.4279207792976525
Validation loss: 2.7579112395022536

Epoch: 6| Step: 1
Training loss: 2.9164410821779736
Validation loss: 2.7225520294001995

Epoch: 6| Step: 2
Training loss: 3.413102562772456
Validation loss: 2.7413559734942896

Epoch: 6| Step: 3
Training loss: 2.646715802986517
Validation loss: 2.7152192873610552

Epoch: 6| Step: 4
Training loss: 3.5205252849341035
Validation loss: 2.688839908687267

Epoch: 6| Step: 5
Training loss: 2.241153066382474
Validation loss: 2.7374901203526583

Epoch: 6| Step: 6
Training loss: 3.344281876232952
Validation loss: 2.7263637152575124

Epoch: 6| Step: 7
Training loss: 2.9589553680508915
Validation loss: 2.7325422838685505

Epoch: 6| Step: 8
Training loss: 2.3935174336018643
Validation loss: 2.75108787314951

Epoch: 6| Step: 9
Training loss: 3.0361623385304424
Validation loss: 2.7779169845223417

Epoch: 6| Step: 10
Training loss: 3.0313472142312468
Validation loss: 2.760447436064667

Epoch: 6| Step: 11
Training loss: 2.3679562569908197
Validation loss: 2.7497795833282885

Epoch: 6| Step: 12
Training loss: 3.283475865660653
Validation loss: 2.778136923928981

Epoch: 6| Step: 13
Training loss: 2.738367794916676
Validation loss: 2.7553118214429637

Epoch: 62| Step: 0
Training loss: 2.872696658740642
Validation loss: 2.7261351339105317

Epoch: 6| Step: 1
Training loss: 3.484687141156394
Validation loss: 2.7166417271037853

Epoch: 6| Step: 2
Training loss: 3.138574490701025
Validation loss: 2.7454290315287673

Epoch: 6| Step: 3
Training loss: 3.1147503420006495
Validation loss: 2.727493030030165

Epoch: 6| Step: 4
Training loss: 3.5148756796935468
Validation loss: 2.7605575615342044

Epoch: 6| Step: 5
Training loss: 3.739845132120266
Validation loss: 2.726891945263958

Epoch: 6| Step: 6
Training loss: 2.4616076329030787
Validation loss: 2.7536903717389594

Epoch: 6| Step: 7
Training loss: 2.565787091170426
Validation loss: 2.721758897283391

Epoch: 6| Step: 8
Training loss: 3.4403474978207824
Validation loss: 2.750356602597238

Epoch: 6| Step: 9
Training loss: 2.628153586940895
Validation loss: 2.73052759782099

Epoch: 6| Step: 10
Training loss: 2.4434032847897993
Validation loss: 2.7846128580889746

Epoch: 6| Step: 11
Training loss: 2.447007831656048
Validation loss: 2.7896218308183762

Epoch: 6| Step: 12
Training loss: 2.529436945626804
Validation loss: 2.7094520195785474

Epoch: 6| Step: 13
Training loss: 2.259570219646791
Validation loss: 2.6985985416896385

Epoch: 63| Step: 0
Training loss: 3.433895648968228
Validation loss: 2.758640650558576

Epoch: 6| Step: 1
Training loss: 2.774004467246179
Validation loss: 2.771973940394773

Epoch: 6| Step: 2
Training loss: 2.5589758667726534
Validation loss: 2.752202131135454

Epoch: 6| Step: 3
Training loss: 2.719613562929694
Validation loss: 2.811710540375006

Epoch: 6| Step: 4
Training loss: 2.871130287820229
Validation loss: 2.7136544602589754

Epoch: 6| Step: 5
Training loss: 2.898731802833491
Validation loss: 2.767737121875682

Epoch: 6| Step: 6
Training loss: 3.0054329314947106
Validation loss: 2.738780125039089

Epoch: 6| Step: 7
Training loss: 2.9333853615857275
Validation loss: 2.7743584020964405

Epoch: 6| Step: 8
Training loss: 3.36967967268353
Validation loss: 2.7247375253493686

Epoch: 6| Step: 9
Training loss: 3.6620024723980076
Validation loss: 2.6793430852897044

Epoch: 6| Step: 10
Training loss: 3.057730249576441
Validation loss: 2.768131907792929

Epoch: 6| Step: 11
Training loss: 2.3870565671702475
Validation loss: 2.7200944560927445

Epoch: 6| Step: 12
Training loss: 2.2505937428675504
Validation loss: 2.727766654037276

Epoch: 6| Step: 13
Training loss: 2.3690392833397844
Validation loss: 2.743293147824145

Epoch: 64| Step: 0
Training loss: 3.4959229837833843
Validation loss: 2.759603477561157

Epoch: 6| Step: 1
Training loss: 3.0755396795812455
Validation loss: 2.8039184141054205

Epoch: 6| Step: 2
Training loss: 2.9872987815097716
Validation loss: 2.7249290546636074

Epoch: 6| Step: 3
Training loss: 3.1358798034560627
Validation loss: 2.7027536459941004

Epoch: 6| Step: 4
Training loss: 3.412457191282614
Validation loss: 2.7191649589276645

Epoch: 6| Step: 5
Training loss: 2.7091087307265247
Validation loss: 2.7380589049709583

Epoch: 6| Step: 6
Training loss: 3.0952291324332006
Validation loss: 2.7168986488381437

Epoch: 6| Step: 7
Training loss: 2.6531228001454
Validation loss: 2.712343589916013

Epoch: 6| Step: 8
Training loss: 2.332463465626299
Validation loss: 2.747071571423155

Epoch: 6| Step: 9
Training loss: 3.553772257259844
Validation loss: 2.7433573069364927

Epoch: 6| Step: 10
Training loss: 2.6647796113172455
Validation loss: 2.7344248392980353

Epoch: 6| Step: 11
Training loss: 3.2397004297483614
Validation loss: 2.7009352094374295

Epoch: 6| Step: 12
Training loss: 2.6373821865001776
Validation loss: 2.752622673790566

Epoch: 6| Step: 13
Training loss: 2.3945203970683395
Validation loss: 2.6417434788613345

Epoch: 65| Step: 0
Training loss: 3.298083621675097
Validation loss: 2.7253714572553847

Epoch: 6| Step: 1
Training loss: 3.056234685005244
Validation loss: 2.7136908279137546

Epoch: 6| Step: 2
Training loss: 3.1159054980950693
Validation loss: 2.714650020797502

Epoch: 6| Step: 3
Training loss: 2.5915282511980866
Validation loss: 2.7393576274306723

Epoch: 6| Step: 4
Training loss: 2.698574933394027
Validation loss: 2.7509402218085133

Epoch: 6| Step: 5
Training loss: 3.1921356002763663
Validation loss: 2.7010745854325773

Epoch: 6| Step: 6
Training loss: 2.7492000109810886
Validation loss: 2.7993850425852163

Epoch: 6| Step: 7
Training loss: 2.8631739993129646
Validation loss: 2.7297650100655377

Epoch: 6| Step: 8
Training loss: 3.335706787707752
Validation loss: 2.7569018997529056

Epoch: 6| Step: 9
Training loss: 3.3110380005356643
Validation loss: 2.7280577757006395

Epoch: 6| Step: 10
Training loss: 2.2516524286994137
Validation loss: 2.7801430003812024

Epoch: 6| Step: 11
Training loss: 2.8243015641223157
Validation loss: 2.7445082266643586

Epoch: 6| Step: 12
Training loss: 3.1236474734207778
Validation loss: 2.712462600019953

Epoch: 6| Step: 13
Training loss: 2.1581591571454597
Validation loss: 2.733042893096816

Epoch: 66| Step: 0
Training loss: 3.131916631522014
Validation loss: 2.7414468613999343

Epoch: 6| Step: 1
Training loss: 2.874213733134722
Validation loss: 2.7063146054926888

Epoch: 6| Step: 2
Training loss: 2.7972004450691443
Validation loss: 2.6896711480907745

Epoch: 6| Step: 3
Training loss: 3.5731842711895596
Validation loss: 2.7362647351713796

Epoch: 6| Step: 4
Training loss: 2.717778086958159
Validation loss: 2.774345331405147

Epoch: 6| Step: 5
Training loss: 1.9522349046008012
Validation loss: 2.682683020401383

Epoch: 6| Step: 6
Training loss: 2.171345598205902
Validation loss: 2.698790605183688

Epoch: 6| Step: 7
Training loss: 3.4001098727256513
Validation loss: 2.6955224596080414

Epoch: 6| Step: 8
Training loss: 3.170960242747295
Validation loss: 2.730423288021002

Epoch: 6| Step: 9
Training loss: 3.481173288811667
Validation loss: 2.7246901555854257

Epoch: 6| Step: 10
Training loss: 2.431253008607704
Validation loss: 2.7347702345451617

Epoch: 6| Step: 11
Training loss: 2.827143040258233
Validation loss: 2.7718799294366647

Epoch: 6| Step: 12
Training loss: 3.5974981250453197
Validation loss: 2.7094610887387276

Epoch: 6| Step: 13
Training loss: 3.8477758398689748
Validation loss: 2.699376964922953

Epoch: 67| Step: 0
Training loss: 3.3981074731994663
Validation loss: 2.7480316146526107

Epoch: 6| Step: 1
Training loss: 2.4591615111623266
Validation loss: 2.7198478039127174

Epoch: 6| Step: 2
Training loss: 3.3052354723544224
Validation loss: 2.718022274679269

Epoch: 6| Step: 3
Training loss: 2.661835396788454
Validation loss: 2.7825785394222864

Epoch: 6| Step: 4
Training loss: 3.138728693772425
Validation loss: 2.734959301845304

Epoch: 6| Step: 5
Training loss: 2.9147969565499063
Validation loss: 2.7290748637738402

Epoch: 6| Step: 6
Training loss: 2.83059803443441
Validation loss: 2.7080470524659868

Epoch: 6| Step: 7
Training loss: 2.969893064789401
Validation loss: 2.69929863313639

Epoch: 6| Step: 8
Training loss: 2.8270832482499344
Validation loss: 2.7320996321059314

Epoch: 6| Step: 9
Training loss: 3.3034755206822815
Validation loss: 2.7743012694616804

Epoch: 6| Step: 10
Training loss: 4.001352320003069
Validation loss: 2.7423412699532546

Epoch: 6| Step: 11
Training loss: 2.1894839418200895
Validation loss: 2.715838951978481

Epoch: 6| Step: 12
Training loss: 2.3786457589382435
Validation loss: 2.7363964178654716

Epoch: 6| Step: 13
Training loss: 1.9177373369694213
Validation loss: 2.6924826051223243

Epoch: 68| Step: 0
Training loss: 2.3223840989675257
Validation loss: 2.723994616439754

Epoch: 6| Step: 1
Training loss: 3.192979179871178
Validation loss: 2.7351015780990138

Epoch: 6| Step: 2
Training loss: 3.19073740791981
Validation loss: 2.7560732769606067

Epoch: 6| Step: 3
Training loss: 2.239273037964756
Validation loss: 2.7602597588870714

Epoch: 6| Step: 4
Training loss: 2.9514710977112752
Validation loss: 2.7636150928674663

Epoch: 6| Step: 5
Training loss: 2.0200328093404245
Validation loss: 2.7125003436837685

Epoch: 6| Step: 6
Training loss: 2.4791253244067737
Validation loss: 2.7557228275310766

Epoch: 6| Step: 7
Training loss: 3.5495760543634574
Validation loss: 2.6967792939691657

Epoch: 6| Step: 8
Training loss: 3.6652307010499277
Validation loss: 2.72616748890834

Epoch: 6| Step: 9
Training loss: 3.468760722375742
Validation loss: 2.7695403177375653

Epoch: 6| Step: 10
Training loss: 3.1186119400687318
Validation loss: 2.709923086569976

Epoch: 6| Step: 11
Training loss: 2.488115577632002
Validation loss: 2.7734799063070783

Epoch: 6| Step: 12
Training loss: 3.297655058505619
Validation loss: 2.725413144047417

Epoch: 6| Step: 13
Training loss: 2.94485445786632
Validation loss: 2.6901069754424936

Epoch: 69| Step: 0
Training loss: 3.3198491749342356
Validation loss: 2.731984163073396

Epoch: 6| Step: 1
Training loss: 2.2440481938781427
Validation loss: 2.784770205728451

Epoch: 6| Step: 2
Training loss: 3.131777927871316
Validation loss: 2.6970671703950546

Epoch: 6| Step: 3
Training loss: 2.3907951344305713
Validation loss: 2.7681670179563924

Epoch: 6| Step: 4
Training loss: 2.79891450140397
Validation loss: 2.7113224626341457

Epoch: 6| Step: 5
Training loss: 3.222916508193568
Validation loss: 2.7134953347010558

Epoch: 6| Step: 6
Training loss: 3.5192063464246908
Validation loss: 2.7120875392462875

Epoch: 6| Step: 7
Training loss: 2.1207113184676634
Validation loss: 2.712475522806394

Epoch: 6| Step: 8
Training loss: 2.646016862966906
Validation loss: 2.6712620585076023

Epoch: 6| Step: 9
Training loss: 3.0146088938935494
Validation loss: 2.738901571350259

Epoch: 6| Step: 10
Training loss: 3.578104610468312
Validation loss: 2.736302236711057

Epoch: 6| Step: 11
Training loss: 2.6108864615455394
Validation loss: 2.6917900953455494

Epoch: 6| Step: 12
Training loss: 2.8509430512969356
Validation loss: 2.758063785641275

Epoch: 6| Step: 13
Training loss: 3.826950453581797
Validation loss: 2.727743229579961

Epoch: 70| Step: 0
Training loss: 2.855832432914735
Validation loss: 2.7614258351514938

Epoch: 6| Step: 1
Training loss: 2.062847917284789
Validation loss: 2.7381595795600937

Epoch: 6| Step: 2
Training loss: 3.7592926599834926
Validation loss: 2.7420863151083137

Epoch: 6| Step: 3
Training loss: 2.093726086835806
Validation loss: 2.728817280906867

Epoch: 6| Step: 4
Training loss: 2.949251086329349
Validation loss: 2.6827163151471405

Epoch: 6| Step: 5
Training loss: 3.0150787965716805
Validation loss: 2.744351128308116

Epoch: 6| Step: 6
Training loss: 3.0757167322021135
Validation loss: 2.751406133931464

Epoch: 6| Step: 7
Training loss: 2.4859816436396764
Validation loss: 2.6999611164697663

Epoch: 6| Step: 8
Training loss: 2.744429929422904
Validation loss: 2.7086688046109617

Epoch: 6| Step: 9
Training loss: 2.945163227214499
Validation loss: 2.7120959256218096

Epoch: 6| Step: 10
Training loss: 3.9502419071726615
Validation loss: 2.7413311707378503

Epoch: 6| Step: 11
Training loss: 3.0275056660329023
Validation loss: 2.719670324881337

Epoch: 6| Step: 12
Training loss: 2.927850335428695
Validation loss: 2.7181566444520713

Epoch: 6| Step: 13
Training loss: 3.3139033673689515
Validation loss: 2.7290463510679746

Epoch: 71| Step: 0
Training loss: 3.031605807786314
Validation loss: 2.690089356535991

Epoch: 6| Step: 1
Training loss: 2.428095550554902
Validation loss: 2.7316539898992374

Epoch: 6| Step: 2
Training loss: 3.0010850851371114
Validation loss: 2.7038302910126744

Epoch: 6| Step: 3
Training loss: 2.6648043050002292
Validation loss: 2.732472538959385

Epoch: 6| Step: 4
Training loss: 2.9501490862399615
Validation loss: 2.717955308487796

Epoch: 6| Step: 5
Training loss: 3.8606140371731743
Validation loss: 2.7194817877951585

Epoch: 6| Step: 6
Training loss: 2.956419061258313
Validation loss: 2.750425276962169

Epoch: 6| Step: 7
Training loss: 3.173122517718339
Validation loss: 2.6911354059039545

Epoch: 6| Step: 8
Training loss: 2.7924700098297097
Validation loss: 2.7343581088668

Epoch: 6| Step: 9
Training loss: 2.7383834667418827
Validation loss: 2.6660499779388136

Epoch: 6| Step: 10
Training loss: 2.3044755223953004
Validation loss: 2.7348431595748584

Epoch: 6| Step: 11
Training loss: 2.8368543923909684
Validation loss: 2.7222566527794823

Epoch: 6| Step: 12
Training loss: 2.9971998179905195
Validation loss: 2.656841529258296

Epoch: 6| Step: 13
Training loss: 3.087012149709031
Validation loss: 2.6867492172722245

Epoch: 72| Step: 0
Training loss: 2.566216541635178
Validation loss: 2.715717795913553

Epoch: 6| Step: 1
Training loss: 3.243463839512113
Validation loss: 2.7414231274068026

Epoch: 6| Step: 2
Training loss: 3.8764805580221386
Validation loss: 2.740471092996248

Epoch: 6| Step: 3
Training loss: 3.0313585399583336
Validation loss: 2.702562063821813

Epoch: 6| Step: 4
Training loss: 2.7938298531882135
Validation loss: 2.7243437863221063

Epoch: 6| Step: 5
Training loss: 2.577288497697961
Validation loss: 2.6772195742987677

Epoch: 6| Step: 6
Training loss: 3.240212153564927
Validation loss: 2.6909184327154185

Epoch: 6| Step: 7
Training loss: 2.8585740932425763
Validation loss: 2.696493245490106

Epoch: 6| Step: 8
Training loss: 3.0578323917199994
Validation loss: 2.756944498102239

Epoch: 6| Step: 9
Training loss: 2.550406692835212
Validation loss: 2.724615956730486

Epoch: 6| Step: 10
Training loss: 2.9957297450917433
Validation loss: 2.696254251463544

Epoch: 6| Step: 11
Training loss: 2.8433960075969136
Validation loss: 2.6721919702358705

Epoch: 6| Step: 12
Training loss: 2.692384052241735
Validation loss: 2.70648528405833

Epoch: 6| Step: 13
Training loss: 2.589200361376566
Validation loss: 2.6866969506354845

Epoch: 73| Step: 0
Training loss: 3.8107448352442623
Validation loss: 2.6757800523865884

Epoch: 6| Step: 1
Training loss: 3.2430371745258246
Validation loss: 2.6518163548599474

Epoch: 6| Step: 2
Training loss: 2.7717231717507995
Validation loss: 2.7043906757870912

Epoch: 6| Step: 3
Training loss: 2.542434378408214
Validation loss: 2.7206096519598773

Epoch: 6| Step: 4
Training loss: 3.3927900723589803
Validation loss: 2.7385135778115437

Epoch: 6| Step: 5
Training loss: 2.1901719260119106
Validation loss: 2.736186858833025

Epoch: 6| Step: 6
Training loss: 3.2425889835191937
Validation loss: 2.712934538092203

Epoch: 6| Step: 7
Training loss: 3.121086722164334
Validation loss: 2.7233311650269347

Epoch: 6| Step: 8
Training loss: 2.437837821829917
Validation loss: 2.69843071842779

Epoch: 6| Step: 9
Training loss: 2.6061794792898443
Validation loss: 2.7002823888208476

Epoch: 6| Step: 10
Training loss: 2.780146090421893
Validation loss: 2.691166581302004

Epoch: 6| Step: 11
Training loss: 2.6658618030258117
Validation loss: 2.7227561213105216

Epoch: 6| Step: 12
Training loss: 3.600436417299927
Validation loss: 2.7044814428500743

Epoch: 6| Step: 13
Training loss: 1.7510465489882423
Validation loss: 2.739227588741198

Epoch: 74| Step: 0
Training loss: 2.911968552723532
Validation loss: 2.6666715218771553

Epoch: 6| Step: 1
Training loss: 2.322316341632378
Validation loss: 2.681894231388206

Epoch: 6| Step: 2
Training loss: 3.27945420306415
Validation loss: 2.7310513671664074

Epoch: 6| Step: 3
Training loss: 3.08622643771936
Validation loss: 2.738209486665485

Epoch: 6| Step: 4
Training loss: 2.484246976420814
Validation loss: 2.7195125816806858

Epoch: 6| Step: 5
Training loss: 2.4287623763149466
Validation loss: 2.722875741167333

Epoch: 6| Step: 6
Training loss: 2.9793971223772084
Validation loss: 2.683653308554811

Epoch: 6| Step: 7
Training loss: 3.0225589076912738
Validation loss: 2.70082808518829

Epoch: 6| Step: 8
Training loss: 3.42320065534371
Validation loss: 2.7171858513819123

Epoch: 6| Step: 9
Training loss: 3.1706869973005967
Validation loss: 2.7504908309193645

Epoch: 6| Step: 10
Training loss: 3.2203473321991902
Validation loss: 2.753767410487005

Epoch: 6| Step: 11
Training loss: 3.326144780011119
Validation loss: 2.716320813518602

Epoch: 6| Step: 12
Training loss: 2.6223234427397175
Validation loss: 2.7164598172444294

Epoch: 6| Step: 13
Training loss: 2.4018105512196826
Validation loss: 2.709723562723255

Epoch: 75| Step: 0
Training loss: 3.4409747508108475
Validation loss: 2.7139997065998562

Epoch: 6| Step: 1
Training loss: 3.1162620451778937
Validation loss: 2.7760410288443467

Epoch: 6| Step: 2
Training loss: 3.2168259286408056
Validation loss: 2.708458933666883

Epoch: 6| Step: 3
Training loss: 3.0825058797639455
Validation loss: 2.6862259306135403

Epoch: 6| Step: 4
Training loss: 2.9680753242414677
Validation loss: 2.7212470080876208

Epoch: 6| Step: 5
Training loss: 2.954324791410811
Validation loss: 2.701367246490833

Epoch: 6| Step: 6
Training loss: 1.5906555952266137
Validation loss: 2.7082564025125246

Epoch: 6| Step: 7
Training loss: 2.6255183843384193
Validation loss: 2.703159724452378

Epoch: 6| Step: 8
Training loss: 2.9196524097024708
Validation loss: 2.6518256511014067

Epoch: 6| Step: 9
Training loss: 3.1662666837822724
Validation loss: 2.69338301378225

Epoch: 6| Step: 10
Training loss: 2.8846710747453783
Validation loss: 2.7479101576255296

Epoch: 6| Step: 11
Training loss: 2.492494187573052
Validation loss: 2.70493574427076

Epoch: 6| Step: 12
Training loss: 2.444540956306633
Validation loss: 2.700320411912432

Epoch: 6| Step: 13
Training loss: 3.4914556841659365
Validation loss: 2.6478306807813907

Epoch: 76| Step: 0
Training loss: 3.3128661906966506
Validation loss: 2.712960687164649

Epoch: 6| Step: 1
Training loss: 3.3327063606626623
Validation loss: 2.7236250489945815

Epoch: 6| Step: 2
Training loss: 1.7960098173981884
Validation loss: 2.7556339948311614

Epoch: 6| Step: 3
Training loss: 3.3491962322655384
Validation loss: 2.6763160601644027

Epoch: 6| Step: 4
Training loss: 2.3041078000082456
Validation loss: 2.710588591205308

Epoch: 6| Step: 5
Training loss: 2.826072074219421
Validation loss: 2.692688693374437

Epoch: 6| Step: 6
Training loss: 3.318649198506311
Validation loss: 2.723571358026031

Epoch: 6| Step: 7
Training loss: 3.1641598533441146
Validation loss: 2.651820718761047

Epoch: 6| Step: 8
Training loss: 2.3633589298313065
Validation loss: 2.7151248475033682

Epoch: 6| Step: 9
Training loss: 2.882771313380835
Validation loss: 2.738948046685418

Epoch: 6| Step: 10
Training loss: 2.579338204426659
Validation loss: 2.739857079825176

Epoch: 6| Step: 11
Training loss: 3.502288751215012
Validation loss: 2.693699658278466

Epoch: 6| Step: 12
Training loss: 2.5391872903528605
Validation loss: 2.7176017160904933

Epoch: 6| Step: 13
Training loss: 3.141563920449809
Validation loss: 2.7784867943754747

Epoch: 77| Step: 0
Training loss: 3.505600263535852
Validation loss: 2.7151953259965262

Epoch: 6| Step: 1
Training loss: 2.655328298986159
Validation loss: 2.7037921485067433

Epoch: 6| Step: 2
Training loss: 2.9021431403057516
Validation loss: 2.676367540996292

Epoch: 6| Step: 3
Training loss: 2.5346214541490255
Validation loss: 2.6792348125767123

Epoch: 6| Step: 4
Training loss: 2.6277351661795487
Validation loss: 2.688599514433762

Epoch: 6| Step: 5
Training loss: 2.5593605348506636
Validation loss: 2.659711248728843

Epoch: 6| Step: 6
Training loss: 2.968481111897857
Validation loss: 2.677953342588983

Epoch: 6| Step: 7
Training loss: 2.394376516398938
Validation loss: 2.738126126637868

Epoch: 6| Step: 8
Training loss: 3.2777614395539016
Validation loss: 2.7000214495731676

Epoch: 6| Step: 9
Training loss: 3.2251620821181404
Validation loss: 2.7054539585061264

Epoch: 6| Step: 10
Training loss: 2.4616271975001935
Validation loss: 2.7138981867880285

Epoch: 6| Step: 11
Training loss: 3.4240854866194175
Validation loss: 2.6579647554221553

Epoch: 6| Step: 12
Training loss: 3.1192610878037637
Validation loss: 2.7055515956378717

Epoch: 6| Step: 13
Training loss: 2.927765319945702
Validation loss: 2.70990250583317

Epoch: 78| Step: 0
Training loss: 4.07774193378694
Validation loss: 2.713908534289686

Epoch: 6| Step: 1
Training loss: 1.9956139512298314
Validation loss: 2.6881893415714826

Epoch: 6| Step: 2
Training loss: 2.9533723596386783
Validation loss: 2.649287734042541

Epoch: 6| Step: 3
Training loss: 3.342006335669675
Validation loss: 2.6621018211309275

Epoch: 6| Step: 4
Training loss: 3.512002120927592
Validation loss: 2.731592250379623

Epoch: 6| Step: 5
Training loss: 2.599691915598899
Validation loss: 2.691383110130393

Epoch: 6| Step: 6
Training loss: 2.9661047142512214
Validation loss: 2.691075229867518

Epoch: 6| Step: 7
Training loss: 3.0929647662933744
Validation loss: 2.6362569872382444

Epoch: 6| Step: 8
Training loss: 2.6376329433689807
Validation loss: 2.6853230944459865

Epoch: 6| Step: 9
Training loss: 2.4059727496651635
Validation loss: 2.7218553957111826

Epoch: 6| Step: 10
Training loss: 2.6411799462809182
Validation loss: 2.681330307597497

Epoch: 6| Step: 11
Training loss: 3.0536948540010576
Validation loss: 2.6777197819174186

Epoch: 6| Step: 12
Training loss: 2.9764276108502683
Validation loss: 2.7050547988126956

Epoch: 6| Step: 13
Training loss: 2.338156880169284
Validation loss: 2.7376786121328998

Epoch: 79| Step: 0
Training loss: 2.8409326032185755
Validation loss: 2.6753211708306415

Epoch: 6| Step: 1
Training loss: 2.6758707964316133
Validation loss: 2.6706639905884653

Epoch: 6| Step: 2
Training loss: 3.4793933786928153
Validation loss: 2.703213542963083

Epoch: 6| Step: 3
Training loss: 2.8772499568421144
Validation loss: 2.687585846964756

Epoch: 6| Step: 4
Training loss: 2.66029193997042
Validation loss: 2.6856048280610065

Epoch: 6| Step: 5
Training loss: 3.6522680264543217
Validation loss: 2.7175080693925273

Epoch: 6| Step: 6
Training loss: 3.1678305712196955
Validation loss: 2.7423036630938338

Epoch: 6| Step: 7
Training loss: 3.1032740869271844
Validation loss: 2.7054178693516913

Epoch: 6| Step: 8
Training loss: 2.6711383718784005
Validation loss: 2.7089327465192636

Epoch: 6| Step: 9
Training loss: 2.4685601270066266
Validation loss: 2.665455870801368

Epoch: 6| Step: 10
Training loss: 3.7554721325168092
Validation loss: 2.7366562222876047

Epoch: 6| Step: 11
Training loss: 2.426345734945513
Validation loss: 2.6922582898176315

Epoch: 6| Step: 12
Training loss: 2.4005154731631606
Validation loss: 2.6731162587900195

Epoch: 6| Step: 13
Training loss: 2.6371327619118787
Validation loss: 2.7133718319397233

Epoch: 80| Step: 0
Training loss: 2.8593935106022257
Validation loss: 2.675020433297452

Epoch: 6| Step: 1
Training loss: 2.538842951746006
Validation loss: 2.66158428961285

Epoch: 6| Step: 2
Training loss: 2.320387713821993
Validation loss: 2.6675703846449474

Epoch: 6| Step: 3
Training loss: 3.288211232113081
Validation loss: 2.639927220865562

Epoch: 6| Step: 4
Training loss: 3.7635753324248626
Validation loss: 2.6951199503647327

Epoch: 6| Step: 5
Training loss: 2.569451741617741
Validation loss: 2.6584278692295347

Epoch: 6| Step: 6
Training loss: 2.573286382596047
Validation loss: 2.6762208174399547

Epoch: 6| Step: 7
Training loss: 3.410848610628872
Validation loss: 2.6495710396066894

Epoch: 6| Step: 8
Training loss: 2.6391926328511714
Validation loss: 2.6690997443704636

Epoch: 6| Step: 9
Training loss: 2.3733300813195455
Validation loss: 2.741207694148362

Epoch: 6| Step: 10
Training loss: 2.820096501667459
Validation loss: 2.6118653142082566

Epoch: 6| Step: 11
Training loss: 3.538752460162225
Validation loss: 2.6989032289136845

Epoch: 6| Step: 12
Training loss: 2.376470010476328
Validation loss: 2.666594171371812

Epoch: 6| Step: 13
Training loss: 2.6945091045351113
Validation loss: 2.650053355538326

Epoch: 81| Step: 0
Training loss: 3.0688414022037507
Validation loss: 2.7053759561863795

Epoch: 6| Step: 1
Training loss: 3.0287032292777707
Validation loss: 2.654860662192809

Epoch: 6| Step: 2
Training loss: 3.360328858267531
Validation loss: 2.635668483345676

Epoch: 6| Step: 3
Training loss: 2.2035595620841164
Validation loss: 2.6670007502825337

Epoch: 6| Step: 4
Training loss: 2.9298194957244132
Validation loss: 2.7116598649362604

Epoch: 6| Step: 5
Training loss: 2.6825338211131684
Validation loss: 2.698746852845468

Epoch: 6| Step: 6
Training loss: 1.9244249996121128
Validation loss: 2.6659604910936823

Epoch: 6| Step: 7
Training loss: 2.8078299851422392
Validation loss: 2.6661208700430765

Epoch: 6| Step: 8
Training loss: 2.6870327033156376
Validation loss: 2.734818668965624

Epoch: 6| Step: 9
Training loss: 3.7801858965257886
Validation loss: 2.6737523008654978

Epoch: 6| Step: 10
Training loss: 2.480162978662152
Validation loss: 2.663523935840989

Epoch: 6| Step: 11
Training loss: 3.5694929054490054
Validation loss: 2.7085458919768888

Epoch: 6| Step: 12
Training loss: 2.4887576043986583
Validation loss: 2.71298621798679

Epoch: 6| Step: 13
Training loss: 2.5201169301712647
Validation loss: 2.723642619447387

Epoch: 82| Step: 0
Training loss: 3.1269464153191597
Validation loss: 2.680806095149997

Epoch: 6| Step: 1
Training loss: 2.8136995088850636
Validation loss: 2.7033720854914938

Epoch: 6| Step: 2
Training loss: 2.626825515313652
Validation loss: 2.7127021998101504

Epoch: 6| Step: 3
Training loss: 2.755724324378517
Validation loss: 2.708219221628175

Epoch: 6| Step: 4
Training loss: 3.514168263731182
Validation loss: 2.6932117485622085

Epoch: 6| Step: 5
Training loss: 3.517513056380408
Validation loss: 2.6823116739404806

Epoch: 6| Step: 6
Training loss: 2.753622789877565
Validation loss: 2.7473180190167255

Epoch: 6| Step: 7
Training loss: 3.0380678878341194
Validation loss: 2.6967208038924

Epoch: 6| Step: 8
Training loss: 3.25248417914235
Validation loss: 2.690459910589396

Epoch: 6| Step: 9
Training loss: 2.6022015494091844
Validation loss: 2.706808703882559

Epoch: 6| Step: 10
Training loss: 2.4191800782448096
Validation loss: 2.659715484011146

Epoch: 6| Step: 11
Training loss: 2.781074689847699
Validation loss: 2.7038770724009615

Epoch: 6| Step: 12
Training loss: 3.143037239710971
Validation loss: 2.70141854031658

Epoch: 6| Step: 13
Training loss: 2.3309675439304027
Validation loss: 2.6835574960702497

Epoch: 83| Step: 0
Training loss: 3.8958972918858294
Validation loss: 2.7353151191894236

Epoch: 6| Step: 1
Training loss: 2.606288249149082
Validation loss: 2.697881312504296

Epoch: 6| Step: 2
Training loss: 2.8057593207647638
Validation loss: 2.6655131589566587

Epoch: 6| Step: 3
Training loss: 2.984574076618512
Validation loss: 2.6628208853452238

Epoch: 6| Step: 4
Training loss: 3.32573861544422
Validation loss: 2.686447174857433

Epoch: 6| Step: 5
Training loss: 2.782775974622996
Validation loss: 2.6863799931925647

Epoch: 6| Step: 6
Training loss: 2.7168600594737433
Validation loss: 2.7314873777481576

Epoch: 6| Step: 7
Training loss: 2.7500596473467342
Validation loss: 2.718483348967096

Epoch: 6| Step: 8
Training loss: 2.621409731151668
Validation loss: 2.660072678911493

Epoch: 6| Step: 9
Training loss: 2.8840256699518827
Validation loss: 2.6523045983651463

Epoch: 6| Step: 10
Training loss: 2.9599844573875846
Validation loss: 2.6509591228014857

Epoch: 6| Step: 11
Training loss: 2.4527484580515226
Validation loss: 2.691311028823463

Epoch: 6| Step: 12
Training loss: 2.5964411367366074
Validation loss: 2.62150844092462

Epoch: 6| Step: 13
Training loss: 2.74339785043057
Validation loss: 2.6881590710193657

Epoch: 84| Step: 0
Training loss: 3.1234400097988133
Validation loss: 2.6711865339114627

Epoch: 6| Step: 1
Training loss: 3.2122016144750525
Validation loss: 2.6453678405367964

Epoch: 6| Step: 2
Training loss: 2.3158767378030434
Validation loss: 2.6618165775499842

Epoch: 6| Step: 3
Training loss: 3.225640929651572
Validation loss: 2.698939719348696

Epoch: 6| Step: 4
Training loss: 2.674704497941063
Validation loss: 2.651081464869116

Epoch: 6| Step: 5
Training loss: 2.300623319998835
Validation loss: 2.6978195203980366

Epoch: 6| Step: 6
Training loss: 2.5498047810046423
Validation loss: 2.658349186222552

Epoch: 6| Step: 7
Training loss: 2.8196015452529672
Validation loss: 2.7176208923747387

Epoch: 6| Step: 8
Training loss: 3.2960351534144694
Validation loss: 2.6792601365953788

Epoch: 6| Step: 9
Training loss: 2.615231275378578
Validation loss: 2.7281219886479655

Epoch: 6| Step: 10
Training loss: 3.282466699179991
Validation loss: 2.7307235240016423

Epoch: 6| Step: 11
Training loss: 2.908984138956953
Validation loss: 2.713158343962864

Epoch: 6| Step: 12
Training loss: 2.991818716564907
Validation loss: 2.6568558660071653

Epoch: 6| Step: 13
Training loss: 3.243459135035392
Validation loss: 2.679176165302795

Epoch: 85| Step: 0
Training loss: 2.5963868675098456
Validation loss: 2.7174437273380616

Epoch: 6| Step: 1
Training loss: 3.1956501901231738
Validation loss: 2.703827708246866

Epoch: 6| Step: 2
Training loss: 2.5292020448559684
Validation loss: 2.6408024918962067

Epoch: 6| Step: 3
Training loss: 3.212742207818188
Validation loss: 2.7222990266960423

Epoch: 6| Step: 4
Training loss: 2.7466048176138127
Validation loss: 2.7049325304012335

Epoch: 6| Step: 5
Training loss: 2.5426319561439277
Validation loss: 2.6526356369636876

Epoch: 6| Step: 6
Training loss: 2.7930769892706437
Validation loss: 2.6783624843157052

Epoch: 6| Step: 7
Training loss: 3.318292699079992
Validation loss: 2.652383357264931

Epoch: 6| Step: 8
Training loss: 3.005897923272558
Validation loss: 2.7060528837029745

Epoch: 6| Step: 9
Training loss: 3.1532161219334607
Validation loss: 2.720284083029847

Epoch: 6| Step: 10
Training loss: 3.2741185756642603
Validation loss: 2.7375225396791625

Epoch: 6| Step: 11
Training loss: 2.4607317157264883
Validation loss: 2.6661611813039316

Epoch: 6| Step: 12
Training loss: 2.355400122406658
Validation loss: 2.631494564617876

Epoch: 6| Step: 13
Training loss: 2.7564444890680235
Validation loss: 2.6678254169730855

Epoch: 86| Step: 0
Training loss: 2.085815540420209
Validation loss: 2.6644033882050295

Epoch: 6| Step: 1
Training loss: 2.8078967252144826
Validation loss: 2.673466939616559

Epoch: 6| Step: 2
Training loss: 2.282343040827115
Validation loss: 2.6663238490256282

Epoch: 6| Step: 3
Training loss: 2.7924355164598564
Validation loss: 2.6378608940758443

Epoch: 6| Step: 4
Training loss: 3.076906534297196
Validation loss: 2.670849087724852

Epoch: 6| Step: 5
Training loss: 2.224562218277628
Validation loss: 2.6873197874300803

Epoch: 6| Step: 6
Training loss: 3.2790633408692513
Validation loss: 2.6750193637641186

Epoch: 6| Step: 7
Training loss: 3.1226648379721476
Validation loss: 2.7084734202867495

Epoch: 6| Step: 8
Training loss: 2.942079586049537
Validation loss: 2.678005305056526

Epoch: 6| Step: 9
Training loss: 3.1989981513535266
Validation loss: 2.673100576428842

Epoch: 6| Step: 10
Training loss: 3.4584347047464448
Validation loss: 2.694853671937187

Epoch: 6| Step: 11
Training loss: 2.376997158172411
Validation loss: 2.6114527409315134

Epoch: 6| Step: 12
Training loss: 3.183331774832725
Validation loss: 2.6555321695251077

Epoch: 6| Step: 13
Training loss: 3.161273546595006
Validation loss: 2.599735269565744

Epoch: 87| Step: 0
Training loss: 3.558104899189007
Validation loss: 2.6785993076324877

Epoch: 6| Step: 1
Training loss: 2.807132940576441
Validation loss: 2.6333832865590714

Epoch: 6| Step: 2
Training loss: 2.566304151109567
Validation loss: 2.635195415476193

Epoch: 6| Step: 3
Training loss: 2.7819410172880072
Validation loss: 2.6861300438272315

Epoch: 6| Step: 4
Training loss: 2.4587464281840674
Validation loss: 2.73823538969092

Epoch: 6| Step: 5
Training loss: 3.2678546503490797
Validation loss: 2.687355698691451

Epoch: 6| Step: 6
Training loss: 2.4311951501145836
Validation loss: 2.695914817448787

Epoch: 6| Step: 7
Training loss: 2.314641012943223
Validation loss: 2.6743617028360567

Epoch: 6| Step: 8
Training loss: 3.1495274628324395
Validation loss: 2.681604185967322

Epoch: 6| Step: 9
Training loss: 2.480346292191276
Validation loss: 2.7355730892181156

Epoch: 6| Step: 10
Training loss: 3.701738186391082
Validation loss: 2.729741723907042

Epoch: 6| Step: 11
Training loss: 2.3703395894765156
Validation loss: 2.7003380409639175

Epoch: 6| Step: 12
Training loss: 3.5360284393254338
Validation loss: 2.634648061943742

Epoch: 6| Step: 13
Training loss: 1.9681964883331673
Validation loss: 2.7630275020190473

Epoch: 88| Step: 0
Training loss: 2.7565690390086894
Validation loss: 2.674119185447843

Epoch: 6| Step: 1
Training loss: 2.851624705015012
Validation loss: 2.714761722647816

Epoch: 6| Step: 2
Training loss: 3.0731262825200383
Validation loss: 2.670496125878465

Epoch: 6| Step: 3
Training loss: 3.514558079208034
Validation loss: 2.670714438079411

Epoch: 6| Step: 4
Training loss: 2.566956900828857
Validation loss: 2.671268338851586

Epoch: 6| Step: 5
Training loss: 3.339806057901346
Validation loss: 2.665354578628702

Epoch: 6| Step: 6
Training loss: 3.318294567173579
Validation loss: 2.6612455410885953

Epoch: 6| Step: 7
Training loss: 3.2154885962854536
Validation loss: 2.6757177795829823

Epoch: 6| Step: 8
Training loss: 2.548740569616872
Validation loss: 2.6678862903919973

Epoch: 6| Step: 9
Training loss: 1.9880246219760478
Validation loss: 2.670186314454864

Epoch: 6| Step: 10
Training loss: 3.0780089690515866
Validation loss: 2.703859754658732

Epoch: 6| Step: 11
Training loss: 3.266987639507431
Validation loss: 2.65327630361366

Epoch: 6| Step: 12
Training loss: 2.2038663874729356
Validation loss: 2.646541772562128

Epoch: 6| Step: 13
Training loss: 1.884683905692793
Validation loss: 2.656398597725367

Epoch: 89| Step: 0
Training loss: 3.4673456321849754
Validation loss: 2.6143882801926246

Epoch: 6| Step: 1
Training loss: 2.912522632691032
Validation loss: 2.670656059665498

Epoch: 6| Step: 2
Training loss: 2.8454509301319137
Validation loss: 2.646223347290306

Epoch: 6| Step: 3
Training loss: 2.1695251926314207
Validation loss: 2.658798229880209

Epoch: 6| Step: 4
Training loss: 3.267551273798821
Validation loss: 2.6540113373670264

Epoch: 6| Step: 5
Training loss: 1.9676906823867195
Validation loss: 2.660612810802701

Epoch: 6| Step: 6
Training loss: 3.5981224992222236
Validation loss: 2.661027913535611

Epoch: 6| Step: 7
Training loss: 2.330682974984546
Validation loss: 2.6862959171218104

Epoch: 6| Step: 8
Training loss: 2.311602237778092
Validation loss: 2.6531567847115536

Epoch: 6| Step: 9
Training loss: 3.453059821570958
Validation loss: 2.692285341494357

Epoch: 6| Step: 10
Training loss: 2.561608508344789
Validation loss: 2.6922225877395545

Epoch: 6| Step: 11
Training loss: 2.9595599429902317
Validation loss: 2.614478857599371

Epoch: 6| Step: 12
Training loss: 2.9025431958515586
Validation loss: 2.673769688965262

Epoch: 6| Step: 13
Training loss: 2.5701169574411895
Validation loss: 2.7053978070313787

Epoch: 90| Step: 0
Training loss: 3.159258022840618
Validation loss: 2.6293483985752877

Epoch: 6| Step: 1
Training loss: 2.8899439653818333
Validation loss: 2.6900345940497767

Epoch: 6| Step: 2
Training loss: 3.002311610680909
Validation loss: 2.6586438370086922

Epoch: 6| Step: 3
Training loss: 2.490351272532011
Validation loss: 2.6474296822259125

Epoch: 6| Step: 4
Training loss: 3.059680185497238
Validation loss: 2.6277739755971443

Epoch: 6| Step: 5
Training loss: 3.0928955439465073
Validation loss: 2.659634896825258

Epoch: 6| Step: 6
Training loss: 1.7650265650060346
Validation loss: 2.626682406457907

Epoch: 6| Step: 7
Training loss: 3.2337698992399675
Validation loss: 2.6629622600462826

Epoch: 6| Step: 8
Training loss: 3.3772101053536963
Validation loss: 2.7310527639531306

Epoch: 6| Step: 9
Training loss: 2.2370559507491596
Validation loss: 2.666194941984678

Epoch: 6| Step: 10
Training loss: 2.432338139636635
Validation loss: 2.6417439815466763

Epoch: 6| Step: 11
Training loss: 2.72625783185433
Validation loss: 2.6994482448923613

Epoch: 6| Step: 12
Training loss: 3.231721093314766
Validation loss: 2.6826728611261372

Epoch: 6| Step: 13
Training loss: 3.2155504342230024
Validation loss: 2.7131354047315615

Epoch: 91| Step: 0
Training loss: 2.4434941267610752
Validation loss: 2.644031767524632

Epoch: 6| Step: 1
Training loss: 3.773129657959223
Validation loss: 2.657985867555751

Epoch: 6| Step: 2
Training loss: 2.8974926994699133
Validation loss: 2.670017275204181

Epoch: 6| Step: 3
Training loss: 2.6678573115967583
Validation loss: 2.6874509111992713

Epoch: 6| Step: 4
Training loss: 2.377715415622056
Validation loss: 2.6325623425161533

Epoch: 6| Step: 5
Training loss: 2.786159767959116
Validation loss: 2.710871086975024

Epoch: 6| Step: 6
Training loss: 3.2095567096502498
Validation loss: 2.692944389442585

Epoch: 6| Step: 7
Training loss: 2.3533869664651887
Validation loss: 2.736082323470259

Epoch: 6| Step: 8
Training loss: 2.294668162504806
Validation loss: 2.6694098182748665

Epoch: 6| Step: 9
Training loss: 2.2226995856111498
Validation loss: 2.6472150744030007

Epoch: 6| Step: 10
Training loss: 3.3679000206829786
Validation loss: 2.6313941455237027

Epoch: 6| Step: 11
Training loss: 3.0258446704256743
Validation loss: 2.7218090542498135

Epoch: 6| Step: 12
Training loss: 3.278292967472342
Validation loss: 2.6887810571173136

Epoch: 6| Step: 13
Training loss: 3.7765334797802823
Validation loss: 2.682970007138866

Epoch: 92| Step: 0
Training loss: 3.9332097007157762
Validation loss: 2.6660886334806353

Epoch: 6| Step: 1
Training loss: 2.9611859783499694
Validation loss: 2.6651125796576207

Epoch: 6| Step: 2
Training loss: 2.517434458632344
Validation loss: 2.713590364104044

Epoch: 6| Step: 3
Training loss: 2.3995718494618954
Validation loss: 2.6677012673321676

Epoch: 6| Step: 4
Training loss: 2.7267936892718048
Validation loss: 2.7295430138485663

Epoch: 6| Step: 5
Training loss: 2.97241659113176
Validation loss: 2.684673172423633

Epoch: 6| Step: 6
Training loss: 2.4311028678718647
Validation loss: 2.692846447522238

Epoch: 6| Step: 7
Training loss: 2.9306941629889565
Validation loss: 2.620289433171753

Epoch: 6| Step: 8
Training loss: 2.9444115674884457
Validation loss: 2.6289386353241633

Epoch: 6| Step: 9
Training loss: 3.592434849795388
Validation loss: 2.6288336375521415

Epoch: 6| Step: 10
Training loss: 2.2016445082368348
Validation loss: 2.7156938351714737

Epoch: 6| Step: 11
Training loss: 2.936415938961876
Validation loss: 2.6544286671387276

Epoch: 6| Step: 12
Training loss: 3.34438111240696
Validation loss: 2.677687659622441

Epoch: 6| Step: 13
Training loss: 2.124254432482347
Validation loss: 2.714116723799808

Epoch: 93| Step: 0
Training loss: 2.750216042095283
Validation loss: 2.660467830714631

Epoch: 6| Step: 1
Training loss: 2.8589827471729894
Validation loss: 2.6780080812100966

Epoch: 6| Step: 2
Training loss: 3.5257006226239764
Validation loss: 2.7490263582892864

Epoch: 6| Step: 3
Training loss: 2.460789461073116
Validation loss: 2.73833299172244

Epoch: 6| Step: 4
Training loss: 2.564394552894035
Validation loss: 2.645696541684386

Epoch: 6| Step: 5
Training loss: 2.920348722458775
Validation loss: 2.642519322910642

Epoch: 6| Step: 6
Training loss: 2.4496832350878566
Validation loss: 2.6494996650107803

Epoch: 6| Step: 7
Training loss: 3.182730453549847
Validation loss: 2.68106051484265

Epoch: 6| Step: 8
Training loss: 2.7141685030303107
Validation loss: 2.7157834787170354

Epoch: 6| Step: 9
Training loss: 2.7563887857455076
Validation loss: 2.63792393810562

Epoch: 6| Step: 10
Training loss: 3.376206076547087
Validation loss: 2.733422201779353

Epoch: 6| Step: 11
Training loss: 2.725832691182833
Validation loss: 2.667680516542633

Epoch: 6| Step: 12
Training loss: 3.3501861520545346
Validation loss: 2.706690217110206

Epoch: 6| Step: 13
Training loss: 2.364304401453919
Validation loss: 2.6514225890857017

Epoch: 94| Step: 0
Training loss: 3.6051420681666677
Validation loss: 2.6723534880555024

Epoch: 6| Step: 1
Training loss: 2.618251026477902
Validation loss: 2.65010486479658

Epoch: 6| Step: 2
Training loss: 2.109879044957456
Validation loss: 2.675264869865808

Epoch: 6| Step: 3
Training loss: 2.9328742433855988
Validation loss: 2.7451167056121264

Epoch: 6| Step: 4
Training loss: 2.5366541312363724
Validation loss: 2.693887846192305

Epoch: 6| Step: 5
Training loss: 2.642867992261025
Validation loss: 2.6776962437323206

Epoch: 6| Step: 6
Training loss: 2.8365249235583625
Validation loss: 2.6452096797224693

Epoch: 6| Step: 7
Training loss: 2.6813490807070686
Validation loss: 2.6536032971877566

Epoch: 6| Step: 8
Training loss: 3.095193391344356
Validation loss: 2.6286821708533537

Epoch: 6| Step: 9
Training loss: 2.9989916378361303
Validation loss: 2.6559639127005448

Epoch: 6| Step: 10
Training loss: 3.7569260533122226
Validation loss: 2.7035347493249366

Epoch: 6| Step: 11
Training loss: 2.465153065662657
Validation loss: 2.6606638627069508

Epoch: 6| Step: 12
Training loss: 2.9892377133022423
Validation loss: 2.6506014328904497

Epoch: 6| Step: 13
Training loss: 2.579336448179829
Validation loss: 2.7025867680048603

Epoch: 95| Step: 0
Training loss: 2.7505605299765614
Validation loss: 2.66237420237409

Epoch: 6| Step: 1
Training loss: 2.287326818695768
Validation loss: 2.638024888994517

Epoch: 6| Step: 2
Training loss: 2.598018397277112
Validation loss: 2.6100684174211786

Epoch: 6| Step: 3
Training loss: 2.9230088262695526
Validation loss: 2.6614714694155994

Epoch: 6| Step: 4
Training loss: 3.1073344066688677
Validation loss: 2.685877762293714

Epoch: 6| Step: 5
Training loss: 3.3399432608073747
Validation loss: 2.6574996662758044

Epoch: 6| Step: 6
Training loss: 2.837258779884768
Validation loss: 2.681656619739622

Epoch: 6| Step: 7
Training loss: 3.0768516733981137
Validation loss: 2.696243279979878

Epoch: 6| Step: 8
Training loss: 2.763626583523534
Validation loss: 2.650466284666943

Epoch: 6| Step: 9
Training loss: 2.817940514964808
Validation loss: 2.6909909908730882

Epoch: 6| Step: 10
Training loss: 2.4839576994508445
Validation loss: 2.6698670090009524

Epoch: 6| Step: 11
Training loss: 3.46581302060553
Validation loss: 2.647025620579145

Epoch: 6| Step: 12
Training loss: 2.882825732523831
Validation loss: 2.7076039798598943

Epoch: 6| Step: 13
Training loss: 2.03939395709847
Validation loss: 2.720643401301105

Epoch: 96| Step: 0
Training loss: 3.5876513937663117
Validation loss: 2.629996140696065

Epoch: 6| Step: 1
Training loss: 2.3944782792621857
Validation loss: 2.7181294503533224

Epoch: 6| Step: 2
Training loss: 3.191880600601102
Validation loss: 2.6673814534365077

Epoch: 6| Step: 3
Training loss: 2.0971053836885285
Validation loss: 2.653353201776869

Epoch: 6| Step: 4
Training loss: 2.817033970225474
Validation loss: 2.6277721366017306

Epoch: 6| Step: 5
Training loss: 2.4020608875012273
Validation loss: 2.642711283437965

Epoch: 6| Step: 6
Training loss: 2.9886830178241173
Validation loss: 2.640015139161918

Epoch: 6| Step: 7
Training loss: 2.4477645718555037
Validation loss: 2.6183614694547797

Epoch: 6| Step: 8
Training loss: 2.6261269103250324
Validation loss: 2.6158467879292657

Epoch: 6| Step: 9
Training loss: 2.735960930985921
Validation loss: 2.6696718683724185

Epoch: 6| Step: 10
Training loss: 3.148922714821057
Validation loss: 2.654959155683658

Epoch: 6| Step: 11
Training loss: 3.711392087699398
Validation loss: 2.629510029768332

Epoch: 6| Step: 12
Training loss: 2.739986046804277
Validation loss: 2.6515564558415536

Epoch: 6| Step: 13
Training loss: 2.521391898660027
Validation loss: 2.645887391927998

Epoch: 97| Step: 0
Training loss: 3.381442102979257
Validation loss: 2.6352652021821945

Epoch: 6| Step: 1
Training loss: 2.899159631971871
Validation loss: 2.6351627251989274

Epoch: 6| Step: 2
Training loss: 3.0283004725648066
Validation loss: 2.689320866279262

Epoch: 6| Step: 3
Training loss: 2.6191362555891966
Validation loss: 2.633741308732783

Epoch: 6| Step: 4
Training loss: 2.6987786603627564
Validation loss: 2.677571356869727

Epoch: 6| Step: 5
Training loss: 2.8764470646544633
Validation loss: 2.6901495088827403

Epoch: 6| Step: 6
Training loss: 2.4436477990987244
Validation loss: 2.6114392416585064

Epoch: 6| Step: 7
Training loss: 3.6268177079088724
Validation loss: 2.6332416644119245

Epoch: 6| Step: 8
Training loss: 3.2329295886201397
Validation loss: 2.6379109222171624

Epoch: 6| Step: 9
Training loss: 2.4706333557651536
Validation loss: 2.6456062152236037

Epoch: 6| Step: 10
Training loss: 3.051581713669191
Validation loss: 2.6483983351463625

Epoch: 6| Step: 11
Training loss: 1.96715687068155
Validation loss: 2.6105886280752633

Epoch: 6| Step: 12
Training loss: 3.11275539958946
Validation loss: 2.6770125441546537

Epoch: 6| Step: 13
Training loss: 2.9392445030826146
Validation loss: 2.718553991704967

Epoch: 98| Step: 0
Training loss: 2.915023849677641
Validation loss: 2.61984159787802

Epoch: 6| Step: 1
Training loss: 3.140959157295015
Validation loss: 2.6454336167886168

Epoch: 6| Step: 2
Training loss: 2.805179138447186
Validation loss: 2.7146077210824533

Epoch: 6| Step: 3
Training loss: 3.34470760145173
Validation loss: 2.7137697503587996

Epoch: 6| Step: 4
Training loss: 2.061888864313918
Validation loss: 2.6464299453110574

Epoch: 6| Step: 5
Training loss: 2.6136270017795487
Validation loss: 2.6745627930641387

Epoch: 6| Step: 6
Training loss: 2.429265319845006
Validation loss: 2.6634997423419895

Epoch: 6| Step: 7
Training loss: 2.852050237879271
Validation loss: 2.653572230194969

Epoch: 6| Step: 8
Training loss: 2.0551158618054446
Validation loss: 2.7001807767204613

Epoch: 6| Step: 9
Training loss: 3.1483501109828436
Validation loss: 2.7160089716086775

Epoch: 6| Step: 10
Training loss: 2.2978108893287272
Validation loss: 2.6895108866549404

Epoch: 6| Step: 11
Training loss: 2.5093597677678257
Validation loss: 2.68781807484569

Epoch: 6| Step: 12
Training loss: 3.5914564692214355
Validation loss: 2.616817696429991

Epoch: 6| Step: 13
Training loss: 3.4605085740045896
Validation loss: 2.7291455540845915

Epoch: 99| Step: 0
Training loss: 2.691056138784519
Validation loss: 2.654959618208196

Epoch: 6| Step: 1
Training loss: 3.3330770552981783
Validation loss: 2.6465877193565337

Epoch: 6| Step: 2
Training loss: 3.728337726775167
Validation loss: 2.624320277678818

Epoch: 6| Step: 3
Training loss: 2.0306844070588066
Validation loss: 2.6680190370600054

Epoch: 6| Step: 4
Training loss: 3.1620446823505124
Validation loss: 2.6361452498192177

Epoch: 6| Step: 5
Training loss: 2.5887829203149506
Validation loss: 2.634871299028839

Epoch: 6| Step: 6
Training loss: 3.2784749239773725
Validation loss: 2.6412859838975193

Epoch: 6| Step: 7
Training loss: 2.698047875315391
Validation loss: 2.594540345744595

Epoch: 6| Step: 8
Training loss: 2.948284723784323
Validation loss: 2.661787173427415

Epoch: 6| Step: 9
Training loss: 2.133242832688143
Validation loss: 2.6596039552312867

Epoch: 6| Step: 10
Training loss: 2.5577977463769197
Validation loss: 2.667491610914294

Epoch: 6| Step: 11
Training loss: 3.1469992862163614
Validation loss: 2.7000936116709635

Epoch: 6| Step: 12
Training loss: 2.7828480276488357
Validation loss: 2.640143177519619

Epoch: 6| Step: 13
Training loss: 1.9210732501201693
Validation loss: 2.7024622326417695

Epoch: 100| Step: 0
Training loss: 2.8306778824461682
Validation loss: 2.6297774264158833

Epoch: 6| Step: 1
Training loss: 3.0437859942366083
Validation loss: 2.676002785847493

Epoch: 6| Step: 2
Training loss: 2.7680565441398004
Validation loss: 2.657803159435946

Epoch: 6| Step: 3
Training loss: 2.96578236876864
Validation loss: 2.654943514775117

Epoch: 6| Step: 4
Training loss: 3.0862398796178265
Validation loss: 2.614776396984409

Epoch: 6| Step: 5
Training loss: 2.3312584189091656
Validation loss: 2.642155033566867

Epoch: 6| Step: 6
Training loss: 2.5560386887489295
Validation loss: 2.671168198043929

Epoch: 6| Step: 7
Training loss: 2.877494393350689
Validation loss: 2.6139074521631587

Epoch: 6| Step: 8
Training loss: 2.918786686211326
Validation loss: 2.660666443532063

Epoch: 6| Step: 9
Training loss: 2.79785752753509
Validation loss: 2.6643777978931134

Epoch: 6| Step: 10
Training loss: 3.1439628513849636
Validation loss: 2.6928828905580335

Epoch: 6| Step: 11
Training loss: 2.0425770604737616
Validation loss: 2.643090972528884

Epoch: 6| Step: 12
Training loss: 2.908765627003894
Validation loss: 2.6604311305938606

Epoch: 6| Step: 13
Training loss: 3.4395381087332386
Validation loss: 2.6668338508522575

Testing loss: 2.5780514053475545
