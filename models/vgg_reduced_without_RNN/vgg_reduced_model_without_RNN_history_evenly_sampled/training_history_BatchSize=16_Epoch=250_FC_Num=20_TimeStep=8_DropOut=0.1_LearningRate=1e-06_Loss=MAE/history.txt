Epoch: 1| Step: 0
Training loss: 3.794325351715088
Validation loss: 3.6109047730763755

Epoch: 6| Step: 1
Training loss: 3.9716014862060547
Validation loss: 3.6079037881666616

Epoch: 6| Step: 2
Training loss: 3.2111144065856934
Validation loss: 3.6088626102734636

Epoch: 6| Step: 3
Training loss: 3.935380458831787
Validation loss: 3.605065717492052

Epoch: 6| Step: 4
Training loss: 2.9251461029052734
Validation loss: 3.6016520377128356

Epoch: 6| Step: 5
Training loss: 2.619210958480835
Validation loss: 3.600952302255938

Epoch: 6| Step: 6
Training loss: 4.283250331878662
Validation loss: 3.5978805865010908

Epoch: 6| Step: 7
Training loss: 2.524488925933838
Validation loss: 3.593580722808838

Epoch: 6| Step: 8
Training loss: 3.8851089477539062
Validation loss: 3.5949741204579673

Epoch: 6| Step: 9
Training loss: 3.248544692993164
Validation loss: 3.5918233010076706

Epoch: 6| Step: 10
Training loss: 4.08446741104126
Validation loss: 3.5888765550428823

Epoch: 6| Step: 11
Training loss: 2.9868788719177246
Validation loss: 3.5883396312754643

Epoch: 6| Step: 12
Training loss: 3.9039177894592285
Validation loss: 3.586730803212812

Epoch: 6| Step: 13
Training loss: 4.133418560028076
Validation loss: 3.5820017066053165

Epoch: 2| Step: 0
Training loss: 3.8903520107269287
Validation loss: 3.5790882572051017

Epoch: 6| Step: 1
Training loss: 3.520339012145996
Validation loss: 3.5772837182526946

Epoch: 6| Step: 2
Training loss: 2.9368653297424316
Validation loss: 3.5756016931226178

Epoch: 6| Step: 3
Training loss: 3.524163246154785
Validation loss: 3.574548828986383

Epoch: 6| Step: 4
Training loss: 3.8923499584198
Validation loss: 3.571461146877658

Epoch: 6| Step: 5
Training loss: 4.156026840209961
Validation loss: 3.570690647248299

Epoch: 6| Step: 6
Training loss: 3.5762343406677246
Validation loss: 3.5678205490112305

Epoch: 6| Step: 7
Training loss: 3.0794880390167236
Validation loss: 3.565325778017762

Epoch: 6| Step: 8
Training loss: 2.798703670501709
Validation loss: 3.5627482732137046

Epoch: 6| Step: 9
Training loss: 3.4897499084472656
Validation loss: 3.560765089527253

Epoch: 6| Step: 10
Training loss: 3.5377817153930664
Validation loss: 3.5597962974220194

Epoch: 6| Step: 11
Training loss: 3.7603652477264404
Validation loss: 3.5584879998237855

Epoch: 6| Step: 12
Training loss: 3.638896942138672
Validation loss: 3.5548145668480986

Epoch: 6| Step: 13
Training loss: 2.772054433822632
Validation loss: 3.553086406441145

Epoch: 3| Step: 0
Training loss: 3.693603992462158
Validation loss: 3.550975827760594

Epoch: 6| Step: 1
Training loss: 4.4747724533081055
Validation loss: 3.5491091743592293

Epoch: 6| Step: 2
Training loss: 3.750147819519043
Validation loss: 3.5465068150592107

Epoch: 6| Step: 3
Training loss: 3.6174874305725098
Validation loss: 3.547971584463632

Epoch: 6| Step: 4
Training loss: 2.3263368606567383
Validation loss: 3.5440976978630148

Epoch: 6| Step: 5
Training loss: 3.322888135910034
Validation loss: 3.542204080089446

Epoch: 6| Step: 6
Training loss: 3.280937671661377
Validation loss: 3.539965537286574

Epoch: 6| Step: 7
Training loss: 3.175889492034912
Validation loss: 3.540201182006508

Epoch: 6| Step: 8
Training loss: 3.03381085395813
Validation loss: 3.53740293236189

Epoch: 6| Step: 9
Training loss: 3.128929615020752
Validation loss: 3.534126727811752

Epoch: 6| Step: 10
Training loss: 3.3459160327911377
Validation loss: 3.533240361880231

Epoch: 6| Step: 11
Training loss: 3.2412757873535156
Validation loss: 3.5308491619684363

Epoch: 6| Step: 12
Training loss: 4.564342498779297
Validation loss: 3.5289887151410504

Epoch: 6| Step: 13
Training loss: 3.677781105041504
Validation loss: 3.526938171796901

Epoch: 4| Step: 0
Training loss: 3.0780751705169678
Validation loss: 3.526100622710361

Epoch: 6| Step: 1
Training loss: 2.4125733375549316
Validation loss: 3.5237169009383007

Epoch: 6| Step: 2
Training loss: 3.0549421310424805
Validation loss: 3.521497300876084

Epoch: 6| Step: 3
Training loss: 3.73156476020813
Validation loss: 3.5205034902018886

Epoch: 6| Step: 4
Training loss: 3.4313876628875732
Validation loss: 3.51697051653298

Epoch: 6| Step: 5
Training loss: 4.17563533782959
Validation loss: 3.516645300772882

Epoch: 6| Step: 6
Training loss: 4.750456809997559
Validation loss: 3.514849167998119

Epoch: 6| Step: 7
Training loss: 4.073741436004639
Validation loss: 3.5116753988368536

Epoch: 6| Step: 8
Training loss: 4.2840352058410645
Validation loss: 3.509627757533904

Epoch: 6| Step: 9
Training loss: 1.8407392501831055
Validation loss: 3.5048823536083265

Epoch: 6| Step: 10
Training loss: 3.2012996673583984
Validation loss: 3.504475611512379

Epoch: 6| Step: 11
Training loss: 2.7130119800567627
Validation loss: 3.5020756413859706

Epoch: 6| Step: 12
Training loss: 3.603144407272339
Validation loss: 3.499806022131315

Epoch: 6| Step: 13
Training loss: 4.152633190155029
Validation loss: 3.4977393329784436

Epoch: 5| Step: 0
Training loss: 4.2153706550598145
Validation loss: 3.493559178485665

Epoch: 6| Step: 1
Training loss: 3.1904044151306152
Validation loss: 3.4897690588428127

Epoch: 6| Step: 2
Training loss: 3.0718843936920166
Validation loss: 3.489821567330309

Epoch: 6| Step: 3
Training loss: 2.698927879333496
Validation loss: 3.4869159447249545

Epoch: 6| Step: 4
Training loss: 3.696492910385132
Validation loss: 3.4859097234664427

Epoch: 6| Step: 5
Training loss: 3.694948673248291
Validation loss: 3.482055248752717

Epoch: 6| Step: 6
Training loss: 2.307528018951416
Validation loss: 3.47926503099421

Epoch: 6| Step: 7
Training loss: 3.846086263656616
Validation loss: 3.477239342146022

Epoch: 6| Step: 8
Training loss: 3.0617034435272217
Validation loss: 3.4755334443943475

Epoch: 6| Step: 9
Training loss: 4.347777843475342
Validation loss: 3.474535257585587

Epoch: 6| Step: 10
Training loss: 2.098921537399292
Validation loss: 3.4714730247374503

Epoch: 6| Step: 11
Training loss: 4.509668350219727
Validation loss: 3.4685053133195445

Epoch: 6| Step: 12
Training loss: 3.392246961593628
Validation loss: 3.465677671535041

Epoch: 6| Step: 13
Training loss: 3.854593515396118
Validation loss: 3.4627807678714877

Epoch: 6| Step: 0
Training loss: 3.4643406867980957
Validation loss: 3.46035950158232

Epoch: 6| Step: 1
Training loss: 3.117133140563965
Validation loss: 3.4576939895588863

Epoch: 6| Step: 2
Training loss: 3.4048068523406982
Validation loss: 3.454745105517808

Epoch: 6| Step: 3
Training loss: 4.107330322265625
Validation loss: 3.4503992475489134

Epoch: 6| Step: 4
Training loss: 3.4037845134735107
Validation loss: 3.4490409307582404

Epoch: 6| Step: 5
Training loss: 3.34429931640625
Validation loss: 3.445939005062144

Epoch: 6| Step: 6
Training loss: 2.97348690032959
Validation loss: 3.4427129991592897

Epoch: 6| Step: 7
Training loss: 3.2015552520751953
Validation loss: 3.438792377389887

Epoch: 6| Step: 8
Training loss: 2.7130467891693115
Validation loss: 3.4364281495412192

Epoch: 6| Step: 9
Training loss: 3.8270387649536133
Validation loss: 3.4316752828577513

Epoch: 6| Step: 10
Training loss: 3.8922312259674072
Validation loss: 3.4303520212891283

Epoch: 6| Step: 11
Training loss: 3.4902501106262207
Validation loss: 3.427997583984047

Epoch: 6| Step: 12
Training loss: 3.0017919540405273
Validation loss: 3.4242392868124027

Epoch: 6| Step: 13
Training loss: 3.467705726623535
Validation loss: 3.422036393996208

Epoch: 7| Step: 0
Training loss: 3.5549917221069336
Validation loss: 3.4188336556957615

Epoch: 6| Step: 1
Training loss: 3.5203161239624023
Validation loss: 3.41432370421707

Epoch: 6| Step: 2
Training loss: 3.7220277786254883
Validation loss: 3.413666102194017

Epoch: 6| Step: 3
Training loss: 3.5132851600646973
Validation loss: 3.41078810281651

Epoch: 6| Step: 4
Training loss: 3.310640335083008
Validation loss: 3.404711002944618

Epoch: 6| Step: 5
Training loss: 3.4142208099365234
Validation loss: 3.4026680684858754

Epoch: 6| Step: 6
Training loss: 2.7380523681640625
Validation loss: 3.400040647035004

Epoch: 6| Step: 7
Training loss: 4.837560653686523
Validation loss: 3.3974593018972747

Epoch: 6| Step: 8
Training loss: 3.8363523483276367
Validation loss: 3.3932499706104235

Epoch: 6| Step: 9
Training loss: 3.892918586730957
Validation loss: 3.386181290431689

Epoch: 6| Step: 10
Training loss: 2.0659666061401367
Validation loss: 3.383710768914992

Epoch: 6| Step: 11
Training loss: 2.1798205375671387
Validation loss: 3.381003313167121

Epoch: 6| Step: 12
Training loss: 3.7054829597473145
Validation loss: 3.3768079973036245

Epoch: 6| Step: 13
Training loss: 1.982215404510498
Validation loss: 3.3773504944257837

Epoch: 8| Step: 0
Training loss: 2.7343358993530273
Validation loss: 3.3718614039882535

Epoch: 6| Step: 1
Training loss: 4.632769584655762
Validation loss: 3.366546436022687

Epoch: 6| Step: 2
Training loss: 3.858844757080078
Validation loss: 3.3644647495720976

Epoch: 6| Step: 3
Training loss: 3.210564613342285
Validation loss: 3.3590357893256733

Epoch: 6| Step: 4
Training loss: 1.9634201526641846
Validation loss: 3.354309220467844

Epoch: 6| Step: 5
Training loss: 3.682281017303467
Validation loss: 3.3515421498206353

Epoch: 6| Step: 6
Training loss: 3.438480854034424
Validation loss: 3.347212335114838

Epoch: 6| Step: 7
Training loss: 2.6860995292663574
Validation loss: 3.341755062021235

Epoch: 6| Step: 8
Training loss: 2.5178472995758057
Validation loss: 3.338941269023444

Epoch: 6| Step: 9
Training loss: 2.7685790061950684
Validation loss: 3.33867403768724

Epoch: 6| Step: 10
Training loss: 3.0397610664367676
Validation loss: 3.331020837189049

Epoch: 6| Step: 11
Training loss: 5.121639728546143
Validation loss: 3.327607931629304

Epoch: 6| Step: 12
Training loss: 2.920288562774658
Validation loss: 3.3264782505650676

Epoch: 6| Step: 13
Training loss: 4.013925552368164
Validation loss: 3.3202738274810133

Epoch: 9| Step: 0
Training loss: 3.3768744468688965
Validation loss: 3.3127322914779826

Epoch: 6| Step: 1
Training loss: 3.1649298667907715
Validation loss: 3.3106131938196

Epoch: 6| Step: 2
Training loss: 3.90093731880188
Validation loss: 3.30590069934886

Epoch: 6| Step: 3
Training loss: 3.2963149547576904
Validation loss: 3.3013497578200472

Epoch: 6| Step: 4
Training loss: 3.85217547416687
Validation loss: 3.297420773454892

Epoch: 6| Step: 5
Training loss: 2.734936237335205
Validation loss: 3.291346121859807

Epoch: 6| Step: 6
Training loss: 3.3899643421173096
Validation loss: 3.283432073490594

Epoch: 6| Step: 7
Training loss: 3.61281156539917
Validation loss: 3.2804495621752996

Epoch: 6| Step: 8
Training loss: 1.911052942276001
Validation loss: 3.2732704993217223

Epoch: 6| Step: 9
Training loss: 4.43237829208374
Validation loss: 3.2676052842088925

Epoch: 6| Step: 10
Training loss: 3.1451456546783447
Validation loss: 3.2634359790432836

Epoch: 6| Step: 11
Training loss: 3.788689613342285
Validation loss: 3.255227847765851

Epoch: 6| Step: 12
Training loss: 1.9915821552276611
Validation loss: 3.2495774402413318

Epoch: 6| Step: 13
Training loss: 2.7754993438720703
Validation loss: 3.2474405560442197

Epoch: 10| Step: 0
Training loss: 4.138345241546631
Validation loss: 3.2387037328494492

Epoch: 6| Step: 1
Training loss: 3.6576361656188965
Validation loss: 3.2361596527919976

Epoch: 6| Step: 2
Training loss: 3.5572762489318848
Validation loss: 3.236746552169964

Epoch: 6| Step: 3
Training loss: 3.3484716415405273
Validation loss: 3.2228328463851765

Epoch: 6| Step: 4
Training loss: 3.131213665008545
Validation loss: 3.2177041704936693

Epoch: 6| Step: 5
Training loss: 3.0785226821899414
Validation loss: 3.2124315564350416

Epoch: 6| Step: 6
Training loss: 2.7082438468933105
Validation loss: 3.207697535073885

Epoch: 6| Step: 7
Training loss: 3.388753652572632
Validation loss: 3.2010195870553293

Epoch: 6| Step: 8
Training loss: 3.305354118347168
Validation loss: 3.188868922571982

Epoch: 6| Step: 9
Training loss: 3.4553909301757812
Validation loss: 3.183991124553065

Epoch: 6| Step: 10
Training loss: 2.929530620574951
Validation loss: 3.183338695956815

Epoch: 6| Step: 11
Training loss: 2.5976815223693848
Validation loss: 3.1755667681335122

Epoch: 6| Step: 12
Training loss: 2.470928192138672
Validation loss: 3.1689273875246764

Epoch: 6| Step: 13
Training loss: 2.8424839973449707
Validation loss: 3.1628440016059467

Epoch: 11| Step: 0
Training loss: 3.5792083740234375
Validation loss: 3.1532904922321277

Epoch: 6| Step: 1
Training loss: 3.163262367248535
Validation loss: 3.149238342879921

Epoch: 6| Step: 2
Training loss: 2.954658031463623
Validation loss: 3.141642080840244

Epoch: 6| Step: 3
Training loss: 2.7344250679016113
Validation loss: 3.133703495866509

Epoch: 6| Step: 4
Training loss: 2.6345558166503906
Validation loss: 3.1246587819950555

Epoch: 6| Step: 5
Training loss: 2.8065097332000732
Validation loss: 3.117745678911927

Epoch: 6| Step: 6
Training loss: 3.1905150413513184
Validation loss: 3.104725940253145

Epoch: 6| Step: 7
Training loss: 3.085810661315918
Validation loss: 3.1012403067722114

Epoch: 6| Step: 8
Training loss: 2.8486876487731934
Validation loss: 3.0895322548445834

Epoch: 6| Step: 9
Training loss: 3.6300740242004395
Validation loss: 3.0823775747770905

Epoch: 6| Step: 10
Training loss: 2.875149965286255
Validation loss: 3.079575769362911

Epoch: 6| Step: 11
Training loss: 3.397928237915039
Validation loss: 3.06453767899544

Epoch: 6| Step: 12
Training loss: 3.149176836013794
Validation loss: 3.060926306632257

Epoch: 6| Step: 13
Training loss: 4.124441623687744
Validation loss: 3.0482354394851194

Epoch: 12| Step: 0
Training loss: 2.8391666412353516
Validation loss: 3.041756958089849

Epoch: 6| Step: 1
Training loss: 3.8778085708618164
Validation loss: 3.0368017817056305

Epoch: 6| Step: 2
Training loss: 3.1686792373657227
Validation loss: 3.0269875962247133

Epoch: 6| Step: 3
Training loss: 3.2073726654052734
Validation loss: 3.022770722707113

Epoch: 6| Step: 4
Training loss: 3.5333402156829834
Validation loss: 3.011705472905149

Epoch: 6| Step: 5
Training loss: 2.7450342178344727
Validation loss: 3.0045699996332966

Epoch: 6| Step: 6
Training loss: 3.443160057067871
Validation loss: 2.99491407281609

Epoch: 6| Step: 7
Training loss: 2.5860652923583984
Validation loss: 2.9817426076499363

Epoch: 6| Step: 8
Training loss: 3.3365421295166016
Validation loss: 2.9814641373131865

Epoch: 6| Step: 9
Training loss: 3.5818123817443848
Validation loss: 2.966905040125693

Epoch: 6| Step: 10
Training loss: 2.52298641204834
Validation loss: 2.9578370689063944

Epoch: 6| Step: 11
Training loss: 3.040292978286743
Validation loss: 2.952799525312198

Epoch: 6| Step: 12
Training loss: 2.5151546001434326
Validation loss: 2.944829720322804

Epoch: 6| Step: 13
Training loss: 1.5541715621948242
Validation loss: 2.933300333638345

Epoch: 13| Step: 0
Training loss: 2.782707691192627
Validation loss: 2.924037407803279

Epoch: 6| Step: 1
Training loss: 2.8198354244232178
Validation loss: 2.918138891138056

Epoch: 6| Step: 2
Training loss: 3.294543743133545
Validation loss: 2.90665856740808

Epoch: 6| Step: 3
Training loss: 3.43759822845459
Validation loss: 2.892470157274636

Epoch: 6| Step: 4
Training loss: 2.3845596313476562
Validation loss: 2.884622509761523

Epoch: 6| Step: 5
Training loss: 3.5028493404388428
Validation loss: 2.8721803388287945

Epoch: 6| Step: 6
Training loss: 3.180075168609619
Validation loss: 2.865369366061303

Epoch: 6| Step: 7
Training loss: 3.075916290283203
Validation loss: 2.856000441376881

Epoch: 6| Step: 8
Training loss: 3.1290531158447266
Validation loss: 2.849725943739696

Epoch: 6| Step: 9
Training loss: 2.579763412475586
Validation loss: 2.8415306332290813

Epoch: 6| Step: 10
Training loss: 3.146343946456909
Validation loss: 2.8285450653363298

Epoch: 6| Step: 11
Training loss: 2.501641273498535
Validation loss: 2.82144001735154

Epoch: 6| Step: 12
Training loss: 2.305880069732666
Validation loss: 2.8110942045847573

Epoch: 6| Step: 13
Training loss: 3.543006420135498
Validation loss: 2.7939136592290734

Epoch: 14| Step: 0
Training loss: 3.545048236846924
Validation loss: 2.7895252678983953

Epoch: 6| Step: 1
Training loss: 3.067723035812378
Validation loss: 2.7808904776009182

Epoch: 6| Step: 2
Training loss: 2.6641852855682373
Validation loss: 2.7723425690845778

Epoch: 6| Step: 3
Training loss: 2.6636672019958496
Validation loss: 2.758874306114771

Epoch: 6| Step: 4
Training loss: 2.4522652626037598
Validation loss: 2.7489040231191986

Epoch: 6| Step: 5
Training loss: 3.4290683269500732
Validation loss: 2.740284591592768

Epoch: 6| Step: 6
Training loss: 3.139115571975708
Validation loss: 2.735431783942766

Epoch: 6| Step: 7
Training loss: 2.6439194679260254
Validation loss: 2.7185123146221204

Epoch: 6| Step: 8
Training loss: 2.6320900917053223
Validation loss: 2.70842493221324

Epoch: 6| Step: 9
Training loss: 2.498898983001709
Validation loss: 2.698866141739712

Epoch: 6| Step: 10
Training loss: 2.469627857208252
Validation loss: 2.6925731320534982

Epoch: 6| Step: 11
Training loss: 2.921983242034912
Validation loss: 2.6760594844818115

Epoch: 6| Step: 12
Training loss: 3.213416814804077
Validation loss: 2.6663061547022995

Epoch: 6| Step: 13
Training loss: 2.7325072288513184
Validation loss: 2.65192199009721

Epoch: 15| Step: 0
Training loss: 2.428434371948242
Validation loss: 2.6451608263036257

Epoch: 6| Step: 1
Training loss: 2.8529653549194336
Validation loss: 2.627931025720412

Epoch: 6| Step: 2
Training loss: 2.3997843265533447
Validation loss: 2.6182466168557443

Epoch: 6| Step: 3
Training loss: 3.9282522201538086
Validation loss: 2.6067962672120784

Epoch: 6| Step: 4
Training loss: 2.8863306045532227
Validation loss: 2.5915617071172243

Epoch: 6| Step: 5
Training loss: 2.9461770057678223
Validation loss: 2.5724916893948793

Epoch: 6| Step: 6
Training loss: 3.527449607849121
Validation loss: 2.555076135102139

Epoch: 6| Step: 7
Training loss: 3.029808759689331
Validation loss: 2.543454803446288

Epoch: 6| Step: 8
Training loss: 2.49116849899292
Validation loss: 2.5245446389721287

Epoch: 6| Step: 9
Training loss: 2.942840099334717
Validation loss: 2.5240706910369215

Epoch: 6| Step: 10
Training loss: 2.8761870861053467
Validation loss: 2.501764899940901

Epoch: 6| Step: 11
Training loss: 1.7990407943725586
Validation loss: 2.4981808918778614

Epoch: 6| Step: 12
Training loss: 2.289608955383301
Validation loss: 2.489539046441355

Epoch: 6| Step: 13
Training loss: 2.5832743644714355
Validation loss: 2.4725149985282653

Epoch: 16| Step: 0
Training loss: 2.014866828918457
Validation loss: 2.465847740891159

Epoch: 6| Step: 1
Training loss: 2.010399341583252
Validation loss: 2.4659511940453642

Epoch: 6| Step: 2
Training loss: 3.064621686935425
Validation loss: 2.4535661666624007

Epoch: 6| Step: 3
Training loss: 2.8052804470062256
Validation loss: 2.4514387012809835

Epoch: 6| Step: 4
Training loss: 2.4176149368286133
Validation loss: 2.450112247979769

Epoch: 6| Step: 5
Training loss: 3.2341346740722656
Validation loss: 2.437661750342256

Epoch: 6| Step: 6
Training loss: 2.730398654937744
Validation loss: 2.4351255329706336

Epoch: 6| Step: 7
Training loss: 2.6847331523895264
Validation loss: 2.423350247003699

Epoch: 6| Step: 8
Training loss: 2.6311607360839844
Validation loss: 2.413412086425289

Epoch: 6| Step: 9
Training loss: 2.257305860519409
Validation loss: 2.4055801642838346

Epoch: 6| Step: 10
Training loss: 3.5826680660247803
Validation loss: 2.4013886426084783

Epoch: 6| Step: 11
Training loss: 2.244680881500244
Validation loss: 2.3907152965504634

Epoch: 6| Step: 12
Training loss: 2.969738245010376
Validation loss: 2.37672927559063

Epoch: 6| Step: 13
Training loss: 3.227778434753418
Validation loss: 2.3726220874376196

Epoch: 17| Step: 0
Training loss: 2.646240711212158
Validation loss: 2.366712418935632

Epoch: 6| Step: 1
Training loss: 2.6369266510009766
Validation loss: 2.351324332657681

Epoch: 6| Step: 2
Training loss: 3.001469612121582
Validation loss: 2.3530466812913136

Epoch: 6| Step: 3
Training loss: 2.322848320007324
Validation loss: 2.337321409615137

Epoch: 6| Step: 4
Training loss: 2.8869080543518066
Validation loss: 2.344210837476997

Epoch: 6| Step: 5
Training loss: 2.319115400314331
Validation loss: 2.3211618802880727

Epoch: 6| Step: 6
Training loss: 2.509861707687378
Validation loss: 2.32265841960907

Epoch: 6| Step: 7
Training loss: 3.2993574142456055
Validation loss: 2.314213283600346

Epoch: 6| Step: 8
Training loss: 1.8681890964508057
Validation loss: 2.313490847105621

Epoch: 6| Step: 9
Training loss: 2.945570707321167
Validation loss: 2.2982129743022304

Epoch: 6| Step: 10
Training loss: 3.07072377204895
Validation loss: 2.2967844496491137

Epoch: 6| Step: 11
Training loss: 2.6384682655334473
Validation loss: 2.2858485150080856

Epoch: 6| Step: 12
Training loss: 2.4300537109375
Validation loss: 2.2746491714190413

Epoch: 6| Step: 13
Training loss: 1.9223692417144775
Validation loss: 2.2663145501126527

Epoch: 18| Step: 0
Training loss: 2.983954668045044
Validation loss: 2.2653883375147337

Epoch: 6| Step: 1
Training loss: 3.5046072006225586
Validation loss: 2.259314460139121

Epoch: 6| Step: 2
Training loss: 2.3009231090545654
Validation loss: 2.2546328729198826

Epoch: 6| Step: 3
Training loss: 3.1504883766174316
Validation loss: 2.2464067500124694

Epoch: 6| Step: 4
Training loss: 2.794167995452881
Validation loss: 2.2454312770597395

Epoch: 6| Step: 5
Training loss: 2.1512696743011475
Validation loss: 2.2448054436714417

Epoch: 6| Step: 6
Training loss: 2.090597629547119
Validation loss: 2.230752388636271

Epoch: 6| Step: 7
Training loss: 2.3083090782165527
Validation loss: 2.2204278643413256

Epoch: 6| Step: 8
Training loss: 1.7345757484436035
Validation loss: 2.2087438106536865

Epoch: 6| Step: 9
Training loss: 2.512977123260498
Validation loss: 2.218098130277408

Epoch: 6| Step: 10
Training loss: 2.5035901069641113
Validation loss: 2.2122819372402724

Epoch: 6| Step: 11
Training loss: 2.7003207206726074
Validation loss: 2.195622503116567

Epoch: 6| Step: 12
Training loss: 2.5750677585601807
Validation loss: 2.1974534244947534

Epoch: 6| Step: 13
Training loss: 2.5581588745117188
Validation loss: 2.2002506666286017

Epoch: 19| Step: 0
Training loss: 2.9843499660491943
Validation loss: 2.1813413802013604

Epoch: 6| Step: 1
Training loss: 2.649257183074951
Validation loss: 2.179078435385099

Epoch: 6| Step: 2
Training loss: 2.8269824981689453
Validation loss: 2.176491452801612

Epoch: 6| Step: 3
Training loss: 1.9646031856536865
Validation loss: 2.16406084645179

Epoch: 6| Step: 4
Training loss: 2.4617044925689697
Validation loss: 2.1592719042172996

Epoch: 6| Step: 5
Training loss: 1.8144899606704712
Validation loss: 2.166272201845723

Epoch: 6| Step: 6
Training loss: 2.6783742904663086
Validation loss: 2.1630805705183294

Epoch: 6| Step: 7
Training loss: 2.7701315879821777
Validation loss: 2.1643032015010877

Epoch: 6| Step: 8
Training loss: 2.722886085510254
Validation loss: 2.144163898242417

Epoch: 6| Step: 9
Training loss: 2.8538339138031006
Validation loss: 2.151761169074684

Epoch: 6| Step: 10
Training loss: 2.467017412185669
Validation loss: 2.137159014260897

Epoch: 6| Step: 11
Training loss: 2.0867068767547607
Validation loss: 2.1283577667769564

Epoch: 6| Step: 12
Training loss: 2.4945626258850098
Validation loss: 2.1227933617048365

Epoch: 6| Step: 13
Training loss: 2.6340885162353516
Validation loss: 2.132970130571755

Epoch: 20| Step: 0
Training loss: 3.2678322792053223
Validation loss: 2.1097543470321165

Epoch: 6| Step: 1
Training loss: 2.035957098007202
Validation loss: 2.121220906575521

Epoch: 6| Step: 2
Training loss: 1.8306772708892822
Validation loss: 2.1046346156827864

Epoch: 6| Step: 3
Training loss: 2.6877503395080566
Validation loss: 2.102962609260313

Epoch: 6| Step: 4
Training loss: 2.8471426963806152
Validation loss: 2.1142030736451507

Epoch: 6| Step: 5
Training loss: 2.2973175048828125
Validation loss: 2.110161953074958

Epoch: 6| Step: 6
Training loss: 2.123067855834961
Validation loss: 2.117581836638912

Epoch: 6| Step: 7
Training loss: 2.5976626873016357
Validation loss: 2.110011185369184

Epoch: 6| Step: 8
Training loss: 2.368669033050537
Validation loss: 2.1001280841007026

Epoch: 6| Step: 9
Training loss: 2.7035269737243652
Validation loss: 2.105746248716949

Epoch: 6| Step: 10
Training loss: 2.8225715160369873
Validation loss: 2.0969795655178767

Epoch: 6| Step: 11
Training loss: 2.4481163024902344
Validation loss: 2.092572437819614

Epoch: 6| Step: 12
Training loss: 2.5296103954315186
Validation loss: 2.098474059053647

Epoch: 6| Step: 13
Training loss: 2.0930755138397217
Validation loss: 2.09103310749095

Epoch: 21| Step: 0
Training loss: 2.2239956855773926
Validation loss: 2.096589831895726

Epoch: 6| Step: 1
Training loss: 2.5966176986694336
Validation loss: 2.075805720462594

Epoch: 6| Step: 2
Training loss: 2.4239542484283447
Validation loss: 2.091436291253695

Epoch: 6| Step: 3
Training loss: 2.38985538482666
Validation loss: 2.085103331073638

Epoch: 6| Step: 4
Training loss: 2.4157352447509766
Validation loss: 2.0845169726238457

Epoch: 6| Step: 5
Training loss: 2.776946544647217
Validation loss: 2.064797427064629

Epoch: 6| Step: 6
Training loss: 3.1965301036834717
Validation loss: 2.0679454957285235

Epoch: 6| Step: 7
Training loss: 1.897507905960083
Validation loss: 2.07214883835085

Epoch: 6| Step: 8
Training loss: 2.176365852355957
Validation loss: 2.0615738732840425

Epoch: 6| Step: 9
Training loss: 2.373863697052002
Validation loss: 2.0702066011326288

Epoch: 6| Step: 10
Training loss: 1.8866688013076782
Validation loss: 2.070125315778999

Epoch: 6| Step: 11
Training loss: 2.8109450340270996
Validation loss: 2.0673715965722197

Epoch: 6| Step: 12
Training loss: 2.729388475418091
Validation loss: 2.064412634859803

Epoch: 6| Step: 13
Training loss: 3.251694917678833
Validation loss: 2.0707089080605456

Epoch: 22| Step: 0
Training loss: 1.8804163932800293
Validation loss: 2.0729881102038967

Epoch: 6| Step: 1
Training loss: 2.880786895751953
Validation loss: 2.062043156675113

Epoch: 6| Step: 2
Training loss: 2.1715378761291504
Validation loss: 2.0605310765645837

Epoch: 6| Step: 3
Training loss: 2.355836868286133
Validation loss: 2.083764230051348

Epoch: 6| Step: 4
Training loss: 2.75913143157959
Validation loss: 2.0773921935789046

Epoch: 6| Step: 5
Training loss: 3.0177547931671143
Validation loss: 2.0934990836728002

Epoch: 6| Step: 6
Training loss: 2.928462028503418
Validation loss: 2.0813398322751446

Epoch: 6| Step: 7
Training loss: 2.538008213043213
Validation loss: 2.071133641786473

Epoch: 6| Step: 8
Training loss: 2.2134785652160645
Validation loss: 2.0741352112062517

Epoch: 6| Step: 9
Training loss: 2.142193078994751
Validation loss: 2.078290384302857

Epoch: 6| Step: 10
Training loss: 2.655855178833008
Validation loss: 2.075825002885634

Epoch: 6| Step: 11
Training loss: 2.689312219619751
Validation loss: 2.0794490857790877

Epoch: 6| Step: 12
Training loss: 2.6030290126800537
Validation loss: 2.0759470667890323

Epoch: 6| Step: 13
Training loss: 1.546752691268921
Validation loss: 2.0829124912138908

Epoch: 23| Step: 0
Training loss: 2.725466728210449
Validation loss: 2.0945047922031854

Epoch: 6| Step: 1
Training loss: 2.0905895233154297
Validation loss: 2.095506960345853

Epoch: 6| Step: 2
Training loss: 2.986276149749756
Validation loss: 2.07965358098348

Epoch: 6| Step: 3
Training loss: 2.133331298828125
Validation loss: 2.1045057286498365

Epoch: 6| Step: 4
Training loss: 2.231475591659546
Validation loss: 2.063103509205644

Epoch: 6| Step: 5
Training loss: 2.7894561290740967
Validation loss: 2.0861738856120775

Epoch: 6| Step: 6
Training loss: 1.9196151494979858
Validation loss: 2.0793405168799945

Epoch: 6| Step: 7
Training loss: 2.2603018283843994
Validation loss: 2.1061253214395173

Epoch: 6| Step: 8
Training loss: 2.0484910011291504
Validation loss: 2.086699260178433

Epoch: 6| Step: 9
Training loss: 2.8450145721435547
Validation loss: 2.081948582844068

Epoch: 6| Step: 10
Training loss: 2.0967135429382324
Validation loss: 2.1003022334908925

Epoch: 6| Step: 11
Training loss: 2.300248622894287
Validation loss: 2.089915734465404

Epoch: 6| Step: 12
Training loss: 3.30369234085083
Validation loss: 2.0830678798819102

Epoch: 6| Step: 13
Training loss: 3.1602535247802734
Validation loss: 2.089773185791508

Epoch: 24| Step: 0
Training loss: 2.2274723052978516
Validation loss: 2.08574576147141

Epoch: 6| Step: 1
Training loss: 2.188692808151245
Validation loss: 2.0907993778105705

Epoch: 6| Step: 2
Training loss: 2.9575531482696533
Validation loss: 2.1051270807943037

Epoch: 6| Step: 3
Training loss: 2.5323781967163086
Validation loss: 2.0732353041248937

Epoch: 6| Step: 4
Training loss: 1.9172186851501465
Validation loss: 2.0762497622479676

Epoch: 6| Step: 5
Training loss: 2.426568031311035
Validation loss: 2.078471327340731

Epoch: 6| Step: 6
Training loss: 3.185072898864746
Validation loss: 2.0820907713264547

Epoch: 6| Step: 7
Training loss: 2.746238946914673
Validation loss: 2.0765136390604

Epoch: 6| Step: 8
Training loss: 2.052152395248413
Validation loss: 2.0768643207447504

Epoch: 6| Step: 9
Training loss: 2.746138095855713
Validation loss: 2.0891150992403746

Epoch: 6| Step: 10
Training loss: 2.3027238845825195
Validation loss: 2.0961997509002686

Epoch: 6| Step: 11
Training loss: 2.763279438018799
Validation loss: 2.0879578500665645

Epoch: 6| Step: 12
Training loss: 2.053040027618408
Validation loss: 2.077893387886786

Epoch: 6| Step: 13
Training loss: 2.395094871520996
Validation loss: 2.086817131247572

Epoch: 25| Step: 0
Training loss: 2.4689083099365234
Validation loss: 2.079759479850851

Epoch: 6| Step: 1
Training loss: 1.760225772857666
Validation loss: 2.0729849274440477

Epoch: 6| Step: 2
Training loss: 2.763209104537964
Validation loss: 2.0865664610298733

Epoch: 6| Step: 3
Training loss: 2.3435328006744385
Validation loss: 2.0716767452096425

Epoch: 6| Step: 4
Training loss: 2.619234085083008
Validation loss: 2.1022008619000836

Epoch: 6| Step: 5
Training loss: 2.9403858184814453
Validation loss: 2.0741607912125124

Epoch: 6| Step: 6
Training loss: 2.3151638507843018
Validation loss: 2.0787463829081547

Epoch: 6| Step: 7
Training loss: 2.2197563648223877
Validation loss: 2.0895947499941756

Epoch: 6| Step: 8
Training loss: 2.3613319396972656
Validation loss: 2.070691736795569

Epoch: 6| Step: 9
Training loss: 2.8567843437194824
Validation loss: 2.0651374093947874

Epoch: 6| Step: 10
Training loss: 2.999317169189453
Validation loss: 2.08856104266259

Epoch: 6| Step: 11
Training loss: 2.85168719291687
Validation loss: 2.0702964951915126

Epoch: 6| Step: 12
Training loss: 1.6865798234939575
Validation loss: 2.0718514983372023

Epoch: 6| Step: 13
Training loss: 2.3807032108306885
Validation loss: 2.0719700397983676

Epoch: 26| Step: 0
Training loss: 2.95822811126709
Validation loss: 2.0631648096986996

Epoch: 6| Step: 1
Training loss: 2.3537516593933105
Validation loss: 2.0809836054360993

Epoch: 6| Step: 2
Training loss: 3.0994439125061035
Validation loss: 2.0803526678392963

Epoch: 6| Step: 3
Training loss: 3.1747477054595947
Validation loss: 2.0839770109422746

Epoch: 6| Step: 4
Training loss: 2.475597858428955
Validation loss: 2.082002055260443

Epoch: 6| Step: 5
Training loss: 2.773700475692749
Validation loss: 2.086203687934465

Epoch: 6| Step: 6
Training loss: 2.158623218536377
Validation loss: 2.1000559458168606

Epoch: 6| Step: 7
Training loss: 2.5248281955718994
Validation loss: 2.0827621131814937

Epoch: 6| Step: 8
Training loss: 2.279393196105957
Validation loss: 2.0886132588950534

Epoch: 6| Step: 9
Training loss: 2.2203569412231445
Validation loss: 2.094011168326101

Epoch: 6| Step: 10
Training loss: 2.4667716026306152
Validation loss: 2.0942067689793085

Epoch: 6| Step: 11
Training loss: 1.444856882095337
Validation loss: 2.070918380573232

Epoch: 6| Step: 12
Training loss: 2.6089298725128174
Validation loss: 2.095588981464345

Epoch: 6| Step: 13
Training loss: 1.595536708831787
Validation loss: 2.0869502636694137

Epoch: 27| Step: 0
Training loss: 3.040774345397949
Validation loss: 2.097921630387665

Epoch: 6| Step: 1
Training loss: 2.4435343742370605
Validation loss: 2.092006561576679

Epoch: 6| Step: 2
Training loss: 1.7459410429000854
Validation loss: 2.0899585857186267

Epoch: 6| Step: 3
Training loss: 2.3829517364501953
Validation loss: 2.0940280524633264

Epoch: 6| Step: 4
Training loss: 2.4649195671081543
Validation loss: 2.0760914382114204

Epoch: 6| Step: 5
Training loss: 2.5696496963500977
Validation loss: 2.0804411672776744

Epoch: 6| Step: 6
Training loss: 2.442178249359131
Validation loss: 2.076479879758691

Epoch: 6| Step: 7
Training loss: 2.3982155323028564
Validation loss: 2.0841456779869656

Epoch: 6| Step: 8
Training loss: 2.2611162662506104
Validation loss: 2.083891120008243

Epoch: 6| Step: 9
Training loss: 2.333528995513916
Validation loss: 2.08588400963814

Epoch: 6| Step: 10
Training loss: 2.6168651580810547
Validation loss: 2.0801918224621843

Epoch: 6| Step: 11
Training loss: 2.327291488647461
Validation loss: 2.089474839548911

Epoch: 6| Step: 12
Training loss: 2.691707134246826
Validation loss: 2.072377230531426

Epoch: 6| Step: 13
Training loss: 2.719148874282837
Validation loss: 2.071126917357086

Epoch: 28| Step: 0
Training loss: 2.6193461418151855
Validation loss: 2.082313923425572

Epoch: 6| Step: 1
Training loss: 2.143801212310791
Validation loss: 2.0741459169695453

Epoch: 6| Step: 2
Training loss: 2.051680564880371
Validation loss: 2.082171106851229

Epoch: 6| Step: 3
Training loss: 2.3895626068115234
Validation loss: 2.09365112678979

Epoch: 6| Step: 4
Training loss: 2.5838258266448975
Validation loss: 2.071641342614287

Epoch: 6| Step: 5
Training loss: 2.2213845252990723
Validation loss: 2.0774264566359983

Epoch: 6| Step: 6
Training loss: 2.3700194358825684
Validation loss: 2.0896018217968684

Epoch: 6| Step: 7
Training loss: 2.2338550090789795
Validation loss: 2.0827723549258326

Epoch: 6| Step: 8
Training loss: 2.4488425254821777
Validation loss: 2.0896004105126984

Epoch: 6| Step: 9
Training loss: 2.5955827236175537
Validation loss: 2.0941475411897064

Epoch: 6| Step: 10
Training loss: 2.097015619277954
Validation loss: 2.082951863606771

Epoch: 6| Step: 11
Training loss: 3.061802387237549
Validation loss: 2.0819283634103756

Epoch: 6| Step: 12
Training loss: 2.5601205825805664
Validation loss: 2.0875053277579685

Epoch: 6| Step: 13
Training loss: 3.552605390548706
Validation loss: 2.0694719078720256

Epoch: 29| Step: 0
Training loss: 2.3970274925231934
Validation loss: 2.0747456781325804

Epoch: 6| Step: 1
Training loss: 2.1085565090179443
Validation loss: 2.0775443277051373

Epoch: 6| Step: 2
Training loss: 2.4648258686065674
Validation loss: 2.08043066147835

Epoch: 6| Step: 3
Training loss: 2.7994003295898438
Validation loss: 2.096834623685447

Epoch: 6| Step: 4
Training loss: 2.401123046875
Validation loss: 2.0836865568673737

Epoch: 6| Step: 5
Training loss: 3.1028261184692383
Validation loss: 2.0949243704477944

Epoch: 6| Step: 6
Training loss: 2.1615748405456543
Validation loss: 2.084808334227531

Epoch: 6| Step: 7
Training loss: 1.7466305494308472
Validation loss: 2.079329731643841

Epoch: 6| Step: 8
Training loss: 2.0213804244995117
Validation loss: 2.097165096190668

Epoch: 6| Step: 9
Training loss: 2.4398155212402344
Validation loss: 2.089832228998984

Epoch: 6| Step: 10
Training loss: 3.0636470317840576
Validation loss: 2.0958497601170696

Epoch: 6| Step: 11
Training loss: 2.316654920578003
Validation loss: 2.0916511704844813

Epoch: 6| Step: 12
Training loss: 2.3152265548706055
Validation loss: 2.094428305984825

Epoch: 6| Step: 13
Training loss: 3.123612642288208
Validation loss: 2.087523934661701

Epoch: 30| Step: 0
Training loss: 2.308485507965088
Validation loss: 2.0869099619568034

Epoch: 6| Step: 1
Training loss: 2.0739684104919434
Validation loss: 2.0775441328684487

Epoch: 6| Step: 2
Training loss: 2.7356910705566406
Validation loss: 2.087222883778234

Epoch: 6| Step: 3
Training loss: 2.6689934730529785
Validation loss: 2.087235176435081

Epoch: 6| Step: 4
Training loss: 2.7131028175354004
Validation loss: 2.082718095471782

Epoch: 6| Step: 5
Training loss: 2.973759412765503
Validation loss: 2.072525082095977

Epoch: 6| Step: 6
Training loss: 1.6864912509918213
Validation loss: 2.0818968895942933

Epoch: 6| Step: 7
Training loss: 2.5342414379119873
Validation loss: 2.0890454258970035

Epoch: 6| Step: 8
Training loss: 2.421710252761841
Validation loss: 2.08282204597227

Epoch: 6| Step: 9
Training loss: 2.346182107925415
Validation loss: 2.0928354083850818

Epoch: 6| Step: 10
Training loss: 2.296107292175293
Validation loss: 2.0903928664422806

Epoch: 6| Step: 11
Training loss: 2.664653778076172
Validation loss: 2.0914831161499023

Epoch: 6| Step: 12
Training loss: 2.3828492164611816
Validation loss: 2.0723637278361986

Epoch: 6| Step: 13
Training loss: 2.1687803268432617
Validation loss: 2.092862844467163

Epoch: 31| Step: 0
Training loss: 2.1665241718292236
Validation loss: 2.0954273721223236

Epoch: 6| Step: 1
Training loss: 2.263139247894287
Validation loss: 2.081255997380903

Epoch: 6| Step: 2
Training loss: 3.002714157104492
Validation loss: 2.093526671009679

Epoch: 6| Step: 3
Training loss: 2.249943494796753
Validation loss: 2.0712962535119828

Epoch: 6| Step: 4
Training loss: 2.532688617706299
Validation loss: 2.0761096631326983

Epoch: 6| Step: 5
Training loss: 2.4761486053466797
Validation loss: 2.0842909607835995

Epoch: 6| Step: 6
Training loss: 2.9290080070495605
Validation loss: 2.0796467706721318

Epoch: 6| Step: 7
Training loss: 2.0150790214538574
Validation loss: 2.0563020039630193

Epoch: 6| Step: 8
Training loss: 2.666102409362793
Validation loss: 2.075020226099158

Epoch: 6| Step: 9
Training loss: 2.4908242225646973
Validation loss: 2.0728068505564043

Epoch: 6| Step: 10
Training loss: 2.1156833171844482
Validation loss: 2.0917751737820205

Epoch: 6| Step: 11
Training loss: 1.956263780593872
Validation loss: 2.0675592191757692

Epoch: 6| Step: 12
Training loss: 2.743241548538208
Validation loss: 2.0666382005137782

Epoch: 6| Step: 13
Training loss: 2.416700601577759
Validation loss: 2.0784095179650093

Epoch: 32| Step: 0
Training loss: 2.319650650024414
Validation loss: 2.0742422252572994

Epoch: 6| Step: 1
Training loss: 2.1086838245391846
Validation loss: 2.082931641609438

Epoch: 6| Step: 2
Training loss: 2.2397587299346924
Validation loss: 2.0572099275486444

Epoch: 6| Step: 3
Training loss: 2.5187177658081055
Validation loss: 2.062615663774552

Epoch: 6| Step: 4
Training loss: 2.7929165363311768
Validation loss: 2.068473046825778

Epoch: 6| Step: 5
Training loss: 2.2282636165618896
Validation loss: 2.0721511892093125

Epoch: 6| Step: 6
Training loss: 2.274967908859253
Validation loss: 2.0712496516525105

Epoch: 6| Step: 7
Training loss: 2.6752214431762695
Validation loss: 2.078345021893901

Epoch: 6| Step: 8
Training loss: 2.7481417655944824
Validation loss: 2.0571799585896153

Epoch: 6| Step: 9
Training loss: 2.4366748332977295
Validation loss: 2.044994361938969

Epoch: 6| Step: 10
Training loss: 2.606072425842285
Validation loss: 2.0745560071801625

Epoch: 6| Step: 11
Training loss: 2.589122772216797
Validation loss: 2.0648200640114407

Epoch: 6| Step: 12
Training loss: 2.8510661125183105
Validation loss: 2.0577240554235314

Epoch: 6| Step: 13
Training loss: 0.9933876395225525
Validation loss: 2.052287249154942

Epoch: 33| Step: 0
Training loss: 2.504686117172241
Validation loss: 2.064853224703061

Epoch: 6| Step: 1
Training loss: 3.367814302444458
Validation loss: 2.042295394405242

Epoch: 6| Step: 2
Training loss: 2.3960089683532715
Validation loss: 2.0604362385247343

Epoch: 6| Step: 3
Training loss: 1.5083141326904297
Validation loss: 2.0637412583956154

Epoch: 6| Step: 4
Training loss: 2.2397525310516357
Validation loss: 2.0395853352803055

Epoch: 6| Step: 5
Training loss: 2.314540386199951
Validation loss: 2.065101445362132

Epoch: 6| Step: 6
Training loss: 2.9232842922210693
Validation loss: 2.0493463239362164

Epoch: 6| Step: 7
Training loss: 2.11838698387146
Validation loss: 2.0408135293632426

Epoch: 6| Step: 8
Training loss: 2.145073413848877
Validation loss: 2.0482530734872304

Epoch: 6| Step: 9
Training loss: 2.1994543075561523
Validation loss: 2.033689498901367

Epoch: 6| Step: 10
Training loss: 2.5343663692474365
Validation loss: 2.0251796425029798

Epoch: 6| Step: 11
Training loss: 3.078514814376831
Validation loss: 2.046846987098776

Epoch: 6| Step: 12
Training loss: 1.921724557876587
Validation loss: 2.047614585968756

Epoch: 6| Step: 13
Training loss: 2.7858710289001465
Validation loss: 2.0493247893548783

Epoch: 34| Step: 0
Training loss: 2.693702220916748
Validation loss: 2.049941893546812

Epoch: 6| Step: 1
Training loss: 2.304776191711426
Validation loss: 2.0588339721002886

Epoch: 6| Step: 2
Training loss: 1.9693219661712646
Validation loss: 2.0641774772315897

Epoch: 6| Step: 3
Training loss: 2.427356004714966
Validation loss: 2.052083161569411

Epoch: 6| Step: 4
Training loss: 2.636997699737549
Validation loss: 2.0727854915844497

Epoch: 6| Step: 5
Training loss: 2.3610355854034424
Validation loss: 2.0553657508665517

Epoch: 6| Step: 6
Training loss: 1.8207241296768188
Validation loss: 2.0592551667203187

Epoch: 6| Step: 7
Training loss: 2.271115303039551
Validation loss: 2.0542306669296755

Epoch: 6| Step: 8
Training loss: 2.4247164726257324
Validation loss: 2.05143823418566

Epoch: 6| Step: 9
Training loss: 2.7775509357452393
Validation loss: 2.059865538791944

Epoch: 6| Step: 10
Training loss: 2.3360023498535156
Validation loss: 2.052468842075717

Epoch: 6| Step: 11
Training loss: 2.684183120727539
Validation loss: 2.042060372649982

Epoch: 6| Step: 12
Training loss: 2.687735080718994
Validation loss: 2.059462519102199

Epoch: 6| Step: 13
Training loss: 2.511714220046997
Validation loss: 2.0403222037899877

Epoch: 35| Step: 0
Training loss: 2.825495719909668
Validation loss: 2.0483904269433792

Epoch: 6| Step: 1
Training loss: 1.892113208770752
Validation loss: 2.0366737842559814

Epoch: 6| Step: 2
Training loss: 2.7247445583343506
Validation loss: 2.052173340192405

Epoch: 6| Step: 3
Training loss: 2.012505054473877
Validation loss: 2.0530839684189006

Epoch: 6| Step: 4
Training loss: 2.0469770431518555
Validation loss: 2.0577267164825113

Epoch: 6| Step: 5
Training loss: 2.8738861083984375
Validation loss: 2.065056893133348

Epoch: 6| Step: 6
Training loss: 2.520547866821289
Validation loss: 2.059811007591986

Epoch: 6| Step: 7
Training loss: 2.065657615661621
Validation loss: 2.057617223390969

Epoch: 6| Step: 8
Training loss: 2.5368621349334717
Validation loss: 2.058829838229764

Epoch: 6| Step: 9
Training loss: 2.004531145095825
Validation loss: 2.067137413127448

Epoch: 6| Step: 10
Training loss: 2.6407346725463867
Validation loss: 2.0429548499404744

Epoch: 6| Step: 11
Training loss: 2.9261717796325684
Validation loss: 2.055768979493008

Epoch: 6| Step: 12
Training loss: 2.1405177116394043
Validation loss: 2.0541531360277565

Epoch: 6| Step: 13
Training loss: 2.550966262817383
Validation loss: 2.0616824870468466

Epoch: 36| Step: 0
Training loss: 3.0481488704681396
Validation loss: 2.055108365192208

Epoch: 6| Step: 1
Training loss: 1.99110746383667
Validation loss: 2.053771218945903

Epoch: 6| Step: 2
Training loss: 3.0061094760894775
Validation loss: 2.052681733203191

Epoch: 6| Step: 3
Training loss: 2.139068603515625
Validation loss: 2.078688624084637

Epoch: 6| Step: 4
Training loss: 2.0158658027648926
Validation loss: 2.058909809717568

Epoch: 6| Step: 5
Training loss: 2.103759527206421
Validation loss: 2.064281566168672

Epoch: 6| Step: 6
Training loss: 1.6823275089263916
Validation loss: 2.05481654982413

Epoch: 6| Step: 7
Training loss: 2.089667797088623
Validation loss: 2.0642340952350247

Epoch: 6| Step: 8
Training loss: 2.3111655712127686
Validation loss: 2.0706788545013755

Epoch: 6| Step: 9
Training loss: 2.510883331298828
Validation loss: 2.0507757868818057

Epoch: 6| Step: 10
Training loss: 2.4834237098693848
Validation loss: 2.0604005090651976

Epoch: 6| Step: 11
Training loss: 3.15895938873291
Validation loss: 2.0686185565046085

Epoch: 6| Step: 12
Training loss: 2.813356399536133
Validation loss: 2.069853109698142

Epoch: 6| Step: 13
Training loss: 2.2924082279205322
Validation loss: 2.0673385371444044

Epoch: 37| Step: 0
Training loss: 2.6264894008636475
Validation loss: 2.0677582961256786

Epoch: 6| Step: 1
Training loss: 2.0518500804901123
Validation loss: 2.043751570486253

Epoch: 6| Step: 2
Training loss: 2.5057387351989746
Validation loss: 2.0599222772864887

Epoch: 6| Step: 3
Training loss: 2.035588264465332
Validation loss: 2.0679019369104856

Epoch: 6| Step: 4
Training loss: 1.9721918106079102
Validation loss: 2.062053580437937

Epoch: 6| Step: 5
Training loss: 2.4422554969787598
Validation loss: 2.067241993001712

Epoch: 6| Step: 6
Training loss: 2.4629812240600586
Validation loss: 2.0550625708795365

Epoch: 6| Step: 7
Training loss: 2.663513660430908
Validation loss: 2.051069821080854

Epoch: 6| Step: 8
Training loss: 1.7691422700881958
Validation loss: 2.060188784394213

Epoch: 6| Step: 9
Training loss: 2.5754356384277344
Validation loss: 2.077067308528449

Epoch: 6| Step: 10
Training loss: 2.737126350402832
Validation loss: 2.080691886204545

Epoch: 6| Step: 11
Training loss: 3.062865734100342
Validation loss: 2.061267714346609

Epoch: 6| Step: 12
Training loss: 2.5723814964294434
Validation loss: 2.0764602871351343

Epoch: 6| Step: 13
Training loss: 1.9511208534240723
Validation loss: 2.072894911612234

Epoch: 38| Step: 0
Training loss: 1.5606472492218018
Validation loss: 2.0578432852222073

Epoch: 6| Step: 1
Training loss: 3.1559252738952637
Validation loss: 2.067199940322548

Epoch: 6| Step: 2
Training loss: 2.289700746536255
Validation loss: 2.066559591600972

Epoch: 6| Step: 3
Training loss: 2.8681061267852783
Validation loss: 2.0536456390093734

Epoch: 6| Step: 4
Training loss: 2.779911994934082
Validation loss: 2.067411063819803

Epoch: 6| Step: 5
Training loss: 2.5785675048828125
Validation loss: 2.0651253487474177

Epoch: 6| Step: 6
Training loss: 2.0669760704040527
Validation loss: 2.080815884374803

Epoch: 6| Step: 7
Training loss: 2.263338565826416
Validation loss: 2.056918713354295

Epoch: 6| Step: 8
Training loss: 2.023833990097046
Validation loss: 2.0646530505149596

Epoch: 6| Step: 9
Training loss: 2.863974094390869
Validation loss: 2.0712301038926646

Epoch: 6| Step: 10
Training loss: 1.6835731267929077
Validation loss: 2.064158556281879

Epoch: 6| Step: 11
Training loss: 2.241302013397217
Validation loss: 2.079535730423466

Epoch: 6| Step: 12
Training loss: 2.496570110321045
Validation loss: 2.0475445203883673

Epoch: 6| Step: 13
Training loss: 2.825471878051758
Validation loss: 2.067077471363929

Epoch: 39| Step: 0
Training loss: 2.028914451599121
Validation loss: 2.071831900586364

Epoch: 6| Step: 1
Training loss: 2.4400477409362793
Validation loss: 2.0564221989723945

Epoch: 6| Step: 2
Training loss: 2.6437625885009766
Validation loss: 2.0548933564975695

Epoch: 6| Step: 3
Training loss: 2.045246124267578
Validation loss: 2.058755461887647

Epoch: 6| Step: 4
Training loss: 2.966773509979248
Validation loss: 2.0668556767125286

Epoch: 6| Step: 5
Training loss: 1.7369052171707153
Validation loss: 2.043888748333018

Epoch: 6| Step: 6
Training loss: 2.9097607135772705
Validation loss: 2.0496380790587394

Epoch: 6| Step: 7
Training loss: 2.5946130752563477
Validation loss: 2.0738389697126163

Epoch: 6| Step: 8
Training loss: 2.284217596054077
Validation loss: 2.0623178507692073

Epoch: 6| Step: 9
Training loss: 2.4273171424865723
Validation loss: 2.075760433750768

Epoch: 6| Step: 10
Training loss: 2.513211727142334
Validation loss: 2.0593313568381855

Epoch: 6| Step: 11
Training loss: 1.7109239101409912
Validation loss: 2.0592617129766815

Epoch: 6| Step: 12
Training loss: 2.5416979789733887
Validation loss: 2.0649173631463

Epoch: 6| Step: 13
Training loss: 2.9820704460144043
Validation loss: 2.0456141964081795

Epoch: 40| Step: 0
Training loss: 1.9937527179718018
Validation loss: 2.063233881868342

Epoch: 6| Step: 1
Training loss: 2.5108625888824463
Validation loss: 2.0631194499231156

Epoch: 6| Step: 2
Training loss: 1.8911638259887695
Validation loss: 2.0575652276315997

Epoch: 6| Step: 3
Training loss: 2.5395474433898926
Validation loss: 2.0504680859145297

Epoch: 6| Step: 4
Training loss: 2.6865386962890625
Validation loss: 2.059200417610907

Epoch: 6| Step: 5
Training loss: 2.711202621459961
Validation loss: 2.04205729756304

Epoch: 6| Step: 6
Training loss: 2.7400126457214355
Validation loss: 2.0559245117249025

Epoch: 6| Step: 7
Training loss: 1.3902208805084229
Validation loss: 2.049788696791536

Epoch: 6| Step: 8
Training loss: 2.3674609661102295
Validation loss: 2.0497601339893956

Epoch: 6| Step: 9
Training loss: 2.7317769527435303
Validation loss: 2.056990505546652

Epoch: 6| Step: 10
Training loss: 1.7451679706573486
Validation loss: 2.053375010849327

Epoch: 6| Step: 11
Training loss: 3.0457139015197754
Validation loss: 2.065511186917623

Epoch: 6| Step: 12
Training loss: 2.890981674194336
Validation loss: 2.0484469706012356

Epoch: 6| Step: 13
Training loss: 1.8032381534576416
Validation loss: 2.0687731696713354

Epoch: 41| Step: 0
Training loss: 2.1522817611694336
Validation loss: 2.048611412766159

Epoch: 6| Step: 1
Training loss: 2.214505672454834
Validation loss: 2.050625647267988

Epoch: 6| Step: 2
Training loss: 2.969568967819214
Validation loss: 2.047994209874061

Epoch: 6| Step: 3
Training loss: 2.1981592178344727
Validation loss: 2.054530917957265

Epoch: 6| Step: 4
Training loss: 2.402583360671997
Validation loss: 2.0396540626402824

Epoch: 6| Step: 5
Training loss: 2.1476051807403564
Validation loss: 2.0555442687003844

Epoch: 6| Step: 6
Training loss: 2.8119044303894043
Validation loss: 2.0493153756664646

Epoch: 6| Step: 7
Training loss: 2.343719482421875
Validation loss: 2.0465054024932203

Epoch: 6| Step: 8
Training loss: 2.0725479125976562
Validation loss: 2.0423019855253157

Epoch: 6| Step: 9
Training loss: 2.5324673652648926
Validation loss: 2.0532979785755114

Epoch: 6| Step: 10
Training loss: 1.9973050355911255
Validation loss: 2.0468367748363043

Epoch: 6| Step: 11
Training loss: 3.005430221557617
Validation loss: 2.0431737310142926

Epoch: 6| Step: 12
Training loss: 2.487109422683716
Validation loss: 2.0582109599985103

Epoch: 6| Step: 13
Training loss: 1.6593633890151978
Validation loss: 2.0592695923261743

Epoch: 42| Step: 0
Training loss: 2.3356971740722656
Validation loss: 2.0654228220703783

Epoch: 6| Step: 1
Training loss: 2.251760482788086
Validation loss: 2.0633826127616306

Epoch: 6| Step: 2
Training loss: 2.2893357276916504
Validation loss: 2.0463260117397515

Epoch: 6| Step: 3
Training loss: 2.784501552581787
Validation loss: 2.0597565174102783

Epoch: 6| Step: 4
Training loss: 2.1735360622406006
Validation loss: 2.0563723964075886

Epoch: 6| Step: 5
Training loss: 2.714221477508545
Validation loss: 2.069371497759255

Epoch: 6| Step: 6
Training loss: 2.8186357021331787
Validation loss: 2.0595324077913837

Epoch: 6| Step: 7
Training loss: 2.4422991275787354
Validation loss: 2.0488675602020754

Epoch: 6| Step: 8
Training loss: 2.6064932346343994
Validation loss: 2.0628597223630516

Epoch: 6| Step: 9
Training loss: 2.116909980773926
Validation loss: 2.0812413461746706

Epoch: 6| Step: 10
Training loss: 1.9201066493988037
Validation loss: 2.0599697136109874

Epoch: 6| Step: 11
Training loss: 2.331115245819092
Validation loss: 2.075365995848051

Epoch: 6| Step: 12
Training loss: 2.1325602531433105
Validation loss: 2.0678771836783296

Epoch: 6| Step: 13
Training loss: 2.144291400909424
Validation loss: 2.0803213478416525

Epoch: 43| Step: 0
Training loss: 3.1732940673828125
Validation loss: 2.067873813772714

Epoch: 6| Step: 1
Training loss: 2.3828234672546387
Validation loss: 2.0696190262353547

Epoch: 6| Step: 2
Training loss: 2.2349648475646973
Validation loss: 2.0410650891642415

Epoch: 6| Step: 3
Training loss: 2.8470282554626465
Validation loss: 2.0663929395778204

Epoch: 6| Step: 4
Training loss: 2.642164707183838
Validation loss: 2.0548742612202964

Epoch: 6| Step: 5
Training loss: 1.9978070259094238
Validation loss: 2.051712597570112

Epoch: 6| Step: 6
Training loss: 2.0213053226470947
Validation loss: 2.0550430179924093

Epoch: 6| Step: 7
Training loss: 2.220808506011963
Validation loss: 2.038614208980273

Epoch: 6| Step: 8
Training loss: 2.5784945487976074
Validation loss: 2.0369158765321136

Epoch: 6| Step: 9
Training loss: 2.3425304889678955
Validation loss: 2.0285764689086587

Epoch: 6| Step: 10
Training loss: 2.3239758014678955
Validation loss: 2.0371292701331516

Epoch: 6| Step: 11
Training loss: 1.9658293724060059
Validation loss: 2.0231035563253585

Epoch: 6| Step: 12
Training loss: 2.2474517822265625
Validation loss: 2.035083524642452

Epoch: 6| Step: 13
Training loss: 2.286531925201416
Validation loss: 2.030721329873608

Epoch: 44| Step: 0
Training loss: 2.7041420936584473
Validation loss: 2.0441788499073317

Epoch: 6| Step: 1
Training loss: 2.6975812911987305
Validation loss: 2.0272053390420894

Epoch: 6| Step: 2
Training loss: 3.25056529045105
Validation loss: 2.018651149606192

Epoch: 6| Step: 3
Training loss: 2.698423147201538
Validation loss: 2.0307178779314925

Epoch: 6| Step: 4
Training loss: 2.683748245239258
Validation loss: 2.0188581635875087

Epoch: 6| Step: 5
Training loss: 2.705599784851074
Validation loss: 2.0132501035608272

Epoch: 6| Step: 6
Training loss: 2.150620222091675
Validation loss: 2.036306140243366

Epoch: 6| Step: 7
Training loss: 1.6613192558288574
Validation loss: 2.041256429046713

Epoch: 6| Step: 8
Training loss: 1.8202595710754395
Validation loss: 2.028278484139391

Epoch: 6| Step: 9
Training loss: 2.039130210876465
Validation loss: 2.024839529427149

Epoch: 6| Step: 10
Training loss: 2.0066990852355957
Validation loss: 2.02293760033064

Epoch: 6| Step: 11
Training loss: 2.108798027038574
Validation loss: 2.045538079354071

Epoch: 6| Step: 12
Training loss: 1.8105840682983398
Validation loss: 2.034197791930168

Epoch: 6| Step: 13
Training loss: 3.074061393737793
Validation loss: 2.0280407423614175

Epoch: 45| Step: 0
Training loss: 1.5953927040100098
Validation loss: 2.0332222177136328

Epoch: 6| Step: 1
Training loss: 2.031975746154785
Validation loss: 2.028787975670189

Epoch: 6| Step: 2
Training loss: 1.9897222518920898
Validation loss: 2.0460574614104403

Epoch: 6| Step: 3
Training loss: 2.1847493648529053
Validation loss: 2.054858843485514

Epoch: 6| Step: 4
Training loss: 3.117560863494873
Validation loss: 2.0306586475782495

Epoch: 6| Step: 5
Training loss: 2.861694574356079
Validation loss: 2.041045452958794

Epoch: 6| Step: 6
Training loss: 2.7413902282714844
Validation loss: 2.028974239544202

Epoch: 6| Step: 7
Training loss: 1.3769114017486572
Validation loss: 2.038484937401228

Epoch: 6| Step: 8
Training loss: 2.141881227493286
Validation loss: 2.0547578052807878

Epoch: 6| Step: 9
Training loss: 2.8117876052856445
Validation loss: 2.0252751688803396

Epoch: 6| Step: 10
Training loss: 2.3145053386688232
Validation loss: 2.0481743017832437

Epoch: 6| Step: 11
Training loss: 2.3593344688415527
Validation loss: 2.049716200879825

Epoch: 6| Step: 12
Training loss: 2.6554956436157227
Validation loss: 2.038296348305159

Epoch: 6| Step: 13
Training loss: 3.171217203140259
Validation loss: 2.0229830229154198

Epoch: 46| Step: 0
Training loss: 2.2347235679626465
Validation loss: 2.030290634401383

Epoch: 6| Step: 1
Training loss: 2.468310832977295
Validation loss: 2.0459209090919903

Epoch: 6| Step: 2
Training loss: 2.1920876502990723
Validation loss: 2.0409271358161845

Epoch: 6| Step: 3
Training loss: 2.233074426651001
Validation loss: 2.0350418295911563

Epoch: 6| Step: 4
Training loss: 1.7940441370010376
Validation loss: 2.0325551020201815

Epoch: 6| Step: 5
Training loss: 1.963761806488037
Validation loss: 2.0372057268696446

Epoch: 6| Step: 6
Training loss: 2.750582456588745
Validation loss: 2.0462334784128333

Epoch: 6| Step: 7
Training loss: 2.528085231781006
Validation loss: 2.046387610896941

Epoch: 6| Step: 8
Training loss: 2.625387191772461
Validation loss: 2.050715986118522

Epoch: 6| Step: 9
Training loss: 2.2507503032684326
Validation loss: 2.048273827439995

Epoch: 6| Step: 10
Training loss: 2.2447316646575928
Validation loss: 2.054254510069406

Epoch: 6| Step: 11
Training loss: 2.318354606628418
Validation loss: 2.056476413562734

Epoch: 6| Step: 12
Training loss: 2.5660977363586426
Validation loss: 2.060919451457198

Epoch: 6| Step: 13
Training loss: 2.871958017349243
Validation loss: 2.054111747331517

Epoch: 47| Step: 0
Training loss: 2.3368144035339355
Validation loss: 2.050336523722577

Epoch: 6| Step: 1
Training loss: 2.7195987701416016
Validation loss: 2.0512884688633743

Epoch: 6| Step: 2
Training loss: 2.288787841796875
Validation loss: 2.0583389497572377

Epoch: 6| Step: 3
Training loss: 2.6211018562316895
Validation loss: 2.0385469826318885

Epoch: 6| Step: 4
Training loss: 2.1510143280029297
Validation loss: 2.079029103761078

Epoch: 6| Step: 5
Training loss: 2.542417526245117
Validation loss: 2.037117736313933

Epoch: 6| Step: 6
Training loss: 2.744810104370117
Validation loss: 2.053712705130218

Epoch: 6| Step: 7
Training loss: 2.5058600902557373
Validation loss: 2.0564197391592045

Epoch: 6| Step: 8
Training loss: 2.468332290649414
Validation loss: 2.0464971937159055

Epoch: 6| Step: 9
Training loss: 2.1945271492004395
Validation loss: 2.0431699855353243

Epoch: 6| Step: 10
Training loss: 2.1397299766540527
Validation loss: 2.0356837395698792

Epoch: 6| Step: 11
Training loss: 1.845062255859375
Validation loss: 2.03468830098388

Epoch: 6| Step: 12
Training loss: 1.5009682178497314
Validation loss: 2.0495692786350044

Epoch: 6| Step: 13
Training loss: 2.715648651123047
Validation loss: 2.0273247713683755

Epoch: 48| Step: 0
Training loss: 2.5528039932250977
Validation loss: 2.0473157180252897

Epoch: 6| Step: 1
Training loss: 1.9483492374420166
Validation loss: 2.031240878566619

Epoch: 6| Step: 2
Training loss: 2.2692012786865234
Validation loss: 2.036023869309374

Epoch: 6| Step: 3
Training loss: 2.670598030090332
Validation loss: 2.0254203606677312

Epoch: 6| Step: 4
Training loss: 2.270082473754883
Validation loss: 2.0226616590253768

Epoch: 6| Step: 5
Training loss: 2.6463890075683594
Validation loss: 2.031529567574942

Epoch: 6| Step: 6
Training loss: 2.794229030609131
Validation loss: 2.0173817129545313

Epoch: 6| Step: 7
Training loss: 1.9296512603759766
Validation loss: 2.023383976310812

Epoch: 6| Step: 8
Training loss: 2.502720594406128
Validation loss: 2.0308983966868412

Epoch: 6| Step: 9
Training loss: 1.8017160892486572
Validation loss: 2.0247618370158698

Epoch: 6| Step: 10
Training loss: 2.656649112701416
Validation loss: 2.009028757772138

Epoch: 6| Step: 11
Training loss: 2.0145084857940674
Validation loss: 2.0200537584161244

Epoch: 6| Step: 12
Training loss: 2.254142999649048
Validation loss: 2.00473585180057

Epoch: 6| Step: 13
Training loss: 2.6153266429901123
Validation loss: 1.9986643996289981

Epoch: 49| Step: 0
Training loss: 2.709400177001953
Validation loss: 2.0142619174013854

Epoch: 6| Step: 1
Training loss: 1.9281830787658691
Validation loss: 2.010918382675417

Epoch: 6| Step: 2
Training loss: 2.77810001373291
Validation loss: 2.02263444085275

Epoch: 6| Step: 3
Training loss: 1.8828356266021729
Validation loss: 2.0140122649490193

Epoch: 6| Step: 4
Training loss: 2.500666618347168
Validation loss: 2.024976381691553

Epoch: 6| Step: 5
Training loss: 2.851475477218628
Validation loss: 2.0151059448078112

Epoch: 6| Step: 6
Training loss: 2.2860522270202637
Validation loss: 2.0334167813742035

Epoch: 6| Step: 7
Training loss: 1.939414143562317
Validation loss: 2.0047596539220502

Epoch: 6| Step: 8
Training loss: 1.969374179840088
Validation loss: 1.9980803920376686

Epoch: 6| Step: 9
Training loss: 2.378565788269043
Validation loss: 1.9980968198468607

Epoch: 6| Step: 10
Training loss: 2.276812791824341
Validation loss: 2.0288899137127783

Epoch: 6| Step: 11
Training loss: 2.5671348571777344
Validation loss: 1.9909336528470438

Epoch: 6| Step: 12
Training loss: 2.4165782928466797
Validation loss: 2.0064436248553696

Epoch: 6| Step: 13
Training loss: 1.9416033029556274
Validation loss: 2.0196526819659817

Epoch: 50| Step: 0
Training loss: 2.0424013137817383
Validation loss: 2.000803957703293

Epoch: 6| Step: 1
Training loss: 1.6897220611572266
Validation loss: 2.0145251827855266

Epoch: 6| Step: 2
Training loss: 2.001918315887451
Validation loss: 2.012070463549706

Epoch: 6| Step: 3
Training loss: 2.4517087936401367
Validation loss: 2.0075231726451586

Epoch: 6| Step: 4
Training loss: 2.789478302001953
Validation loss: 2.017054480891074

Epoch: 6| Step: 5
Training loss: 2.859976291656494
Validation loss: 1.9895870736850205

Epoch: 6| Step: 6
Training loss: 2.489485025405884
Validation loss: 1.9817514675919727

Epoch: 6| Step: 7
Training loss: 2.4157309532165527
Validation loss: 1.9840423291729343

Epoch: 6| Step: 8
Training loss: 2.402897357940674
Validation loss: 1.9981652203426565

Epoch: 6| Step: 9
Training loss: 1.8391051292419434
Validation loss: 1.9888196529880646

Epoch: 6| Step: 10
Training loss: 2.6208481788635254
Validation loss: 2.0039481257879608

Epoch: 6| Step: 11
Training loss: 2.5916876792907715
Validation loss: 1.9963568641293434

Epoch: 6| Step: 12
Training loss: 2.1655120849609375
Validation loss: 1.9968012763607887

Epoch: 6| Step: 13
Training loss: 2.2449402809143066
Validation loss: 2.002110524844098

Epoch: 51| Step: 0
Training loss: 2.649717330932617
Validation loss: 2.0172626844016452

Epoch: 6| Step: 1
Training loss: 2.133756399154663
Validation loss: 2.012143401689427

Epoch: 6| Step: 2
Training loss: 1.6700859069824219
Validation loss: 2.0241724368064635

Epoch: 6| Step: 3
Training loss: 2.6197948455810547
Validation loss: 2.0067519013599684

Epoch: 6| Step: 4
Training loss: 2.013326406478882
Validation loss: 2.018511149191087

Epoch: 6| Step: 5
Training loss: 2.477548122406006
Validation loss: 2.0097658172730477

Epoch: 6| Step: 6
Training loss: 2.4718990325927734
Validation loss: 2.0121804847512195

Epoch: 6| Step: 7
Training loss: 1.939866065979004
Validation loss: 2.0089116199042207

Epoch: 6| Step: 8
Training loss: 1.931541085243225
Validation loss: 2.0297624680303756

Epoch: 6| Step: 9
Training loss: 2.3377366065979004
Validation loss: 2.015183771810224

Epoch: 6| Step: 10
Training loss: 2.922964572906494
Validation loss: 2.005761246527395

Epoch: 6| Step: 11
Training loss: 2.425412178039551
Validation loss: 2.0223923498584377

Epoch: 6| Step: 12
Training loss: 2.7255942821502686
Validation loss: 2.021323944932671

Epoch: 6| Step: 13
Training loss: 1.993897557258606
Validation loss: 2.0177828060683383

Epoch: 52| Step: 0
Training loss: 2.6146044731140137
Validation loss: 2.0267954487954416

Epoch: 6| Step: 1
Training loss: 1.7642818689346313
Validation loss: 2.0429808144928305

Epoch: 6| Step: 2
Training loss: 2.008124351501465
Validation loss: 2.021786005266251

Epoch: 6| Step: 3
Training loss: 2.8062825202941895
Validation loss: 2.0308174676792596

Epoch: 6| Step: 4
Training loss: 2.704503059387207
Validation loss: 2.0100145801421134

Epoch: 6| Step: 5
Training loss: 2.5592050552368164
Validation loss: 2.004037936528524

Epoch: 6| Step: 6
Training loss: 2.0087132453918457
Validation loss: 2.014744189477736

Epoch: 6| Step: 7
Training loss: 2.4237866401672363
Validation loss: 2.0029916699214647

Epoch: 6| Step: 8
Training loss: 2.433438301086426
Validation loss: 2.025405717152421

Epoch: 6| Step: 9
Training loss: 2.7235946655273438
Validation loss: 2.029230672826049

Epoch: 6| Step: 10
Training loss: 2.5698471069335938
Validation loss: 2.0107344811962498

Epoch: 6| Step: 11
Training loss: 1.7485135793685913
Validation loss: 2.0133588224328975

Epoch: 6| Step: 12
Training loss: 1.5353927612304688
Validation loss: 2.0251084681480163

Epoch: 6| Step: 13
Training loss: 2.5695364475250244
Validation loss: 2.0163216257608063

Epoch: 53| Step: 0
Training loss: 2.2956488132476807
Validation loss: 2.035637891420754

Epoch: 6| Step: 1
Training loss: 1.8250541687011719
Validation loss: 2.013285477956136

Epoch: 6| Step: 2
Training loss: 1.769175410270691
Validation loss: 2.013348276897143

Epoch: 6| Step: 3
Training loss: 2.8045148849487305
Validation loss: 2.0271205889281405

Epoch: 6| Step: 4
Training loss: 2.4052786827087402
Validation loss: 2.033963208557457

Epoch: 6| Step: 5
Training loss: 1.9292179346084595
Validation loss: 2.011437972386678

Epoch: 6| Step: 6
Training loss: 2.3043782711029053
Validation loss: 2.0164019228309713

Epoch: 6| Step: 7
Training loss: 2.2064714431762695
Validation loss: 2.030253364193824

Epoch: 6| Step: 8
Training loss: 2.372041702270508
Validation loss: 2.026344688989783

Epoch: 6| Step: 9
Training loss: 2.1521966457366943
Validation loss: 2.027136020762946

Epoch: 6| Step: 10
Training loss: 2.2844278812408447
Validation loss: 2.024865860580116

Epoch: 6| Step: 11
Training loss: 2.9112188816070557
Validation loss: 2.0210753205001994

Epoch: 6| Step: 12
Training loss: 2.6434264183044434
Validation loss: 2.013737961810122

Epoch: 6| Step: 13
Training loss: 2.4373581409454346
Validation loss: 2.0249332548469625

Epoch: 54| Step: 0
Training loss: 2.733915090560913
Validation loss: 1.996013738775766

Epoch: 6| Step: 1
Training loss: 2.4292192459106445
Validation loss: 2.025374581736903

Epoch: 6| Step: 2
Training loss: 2.0444602966308594
Validation loss: 1.9968971744660409

Epoch: 6| Step: 3
Training loss: 2.7105302810668945
Validation loss: 2.011350615050203

Epoch: 6| Step: 4
Training loss: 2.1529123783111572
Validation loss: 2.0151416717037076

Epoch: 6| Step: 5
Training loss: 2.497180700302124
Validation loss: 2.0216182739503923

Epoch: 6| Step: 6
Training loss: 1.9847044944763184
Validation loss: 2.0301874709385697

Epoch: 6| Step: 7
Training loss: 2.480130195617676
Validation loss: 2.026861268986938

Epoch: 6| Step: 8
Training loss: 1.942172884941101
Validation loss: 2.021642028644521

Epoch: 6| Step: 9
Training loss: 2.5254321098327637
Validation loss: 2.0229199650467082

Epoch: 6| Step: 10
Training loss: 2.6576333045959473
Validation loss: 2.019534534023654

Epoch: 6| Step: 11
Training loss: 1.9121601581573486
Validation loss: 2.0245092914950464

Epoch: 6| Step: 12
Training loss: 2.359419107437134
Validation loss: 2.0263710944883284

Epoch: 6| Step: 13
Training loss: 1.445636510848999
Validation loss: 2.0115106362168507

Epoch: 55| Step: 0
Training loss: 2.6255648136138916
Validation loss: 2.0147106211672545

Epoch: 6| Step: 1
Training loss: 1.9985867738723755
Validation loss: 2.0057022263926845

Epoch: 6| Step: 2
Training loss: 2.5132153034210205
Validation loss: 2.0254084781933854

Epoch: 6| Step: 3
Training loss: 2.2818379402160645
Validation loss: 2.016373958638919

Epoch: 6| Step: 4
Training loss: 2.1242833137512207
Validation loss: 2.00052220847017

Epoch: 6| Step: 5
Training loss: 2.3267807960510254
Validation loss: 2.0175635686484714

Epoch: 6| Step: 6
Training loss: 2.288513660430908
Validation loss: 2.019070271522768

Epoch: 6| Step: 7
Training loss: 2.359795093536377
Validation loss: 2.009811824367892

Epoch: 6| Step: 8
Training loss: 1.9245306253433228
Validation loss: 1.9990446875172276

Epoch: 6| Step: 9
Training loss: 2.2244791984558105
Validation loss: 2.007804725759773

Epoch: 6| Step: 10
Training loss: 2.6075336933135986
Validation loss: 1.9943980478471326

Epoch: 6| Step: 11
Training loss: 2.601940870285034
Validation loss: 2.0043019722866755

Epoch: 6| Step: 12
Training loss: 1.7303528785705566
Validation loss: 2.020013456703514

Epoch: 6| Step: 13
Training loss: 2.6511244773864746
Validation loss: 1.9980710578221146

Epoch: 56| Step: 0
Training loss: 1.650928020477295
Validation loss: 2.0027827575642574

Epoch: 6| Step: 1
Training loss: 2.341853141784668
Validation loss: 2.0055304740064885

Epoch: 6| Step: 2
Training loss: 2.4443180561065674
Validation loss: 2.0147275232499644

Epoch: 6| Step: 3
Training loss: 1.393620252609253
Validation loss: 2.017789876589211

Epoch: 6| Step: 4
Training loss: 1.9703314304351807
Validation loss: 2.02773662664557

Epoch: 6| Step: 5
Training loss: 2.5422120094299316
Validation loss: 2.017794601378902

Epoch: 6| Step: 6
Training loss: 2.67783522605896
Validation loss: 2.02033479239351

Epoch: 6| Step: 7
Training loss: 2.43857741355896
Validation loss: 2.011739259125084

Epoch: 6| Step: 8
Training loss: 2.9442763328552246
Validation loss: 2.0141692148741854

Epoch: 6| Step: 9
Training loss: 2.477755069732666
Validation loss: 2.023164726072742

Epoch: 6| Step: 10
Training loss: 1.9999518394470215
Validation loss: 2.0191509621117705

Epoch: 6| Step: 11
Training loss: 2.5623440742492676
Validation loss: 2.0001463364529353

Epoch: 6| Step: 12
Training loss: 2.3534460067749023
Validation loss: 2.0036383687808947

Epoch: 6| Step: 13
Training loss: 2.125654935836792
Validation loss: 2.005497160778251

Epoch: 57| Step: 0
Training loss: 2.436500310897827
Validation loss: 2.002101716174874

Epoch: 6| Step: 1
Training loss: 2.316594123840332
Validation loss: 2.0032615456529843

Epoch: 6| Step: 2
Training loss: 1.7674343585968018
Validation loss: 2.0212994929282897

Epoch: 6| Step: 3
Training loss: 2.4971108436584473
Validation loss: 2.0021287087471253

Epoch: 6| Step: 4
Training loss: 2.7569894790649414
Validation loss: 2.0100762536448817

Epoch: 6| Step: 5
Training loss: 1.825907588005066
Validation loss: 2.0086109574123094

Epoch: 6| Step: 6
Training loss: 2.279595136642456
Validation loss: 2.026071556152836

Epoch: 6| Step: 7
Training loss: 1.7816252708435059
Validation loss: 2.0060792174390567

Epoch: 6| Step: 8
Training loss: 2.052290916442871
Validation loss: 2.041853525305307

Epoch: 6| Step: 9
Training loss: 2.8861114978790283
Validation loss: 1.9977448435239895

Epoch: 6| Step: 10
Training loss: 2.4596712589263916
Validation loss: 2.006265937641103

Epoch: 6| Step: 11
Training loss: 1.7174944877624512
Validation loss: 2.0049105844190045

Epoch: 6| Step: 12
Training loss: 2.7071926593780518
Validation loss: 1.9952200510168587

Epoch: 6| Step: 13
Training loss: 2.565171957015991
Validation loss: 1.988836355106805

Epoch: 58| Step: 0
Training loss: 2.377592086791992
Validation loss: 1.9991745538609003

Epoch: 6| Step: 1
Training loss: 2.0623035430908203
Validation loss: 2.004769584184052

Epoch: 6| Step: 2
Training loss: 2.200829029083252
Validation loss: 1.9987346139005435

Epoch: 6| Step: 3
Training loss: 2.4275107383728027
Validation loss: 2.005673731527021

Epoch: 6| Step: 4
Training loss: 2.0850844383239746
Validation loss: 1.9802876762164536

Epoch: 6| Step: 5
Training loss: 2.110888957977295
Validation loss: 1.9744316095946937

Epoch: 6| Step: 6
Training loss: 2.059692621231079
Validation loss: 1.9938695623028664

Epoch: 6| Step: 7
Training loss: 2.284712314605713
Validation loss: 1.9835610748619161

Epoch: 6| Step: 8
Training loss: 3.0160393714904785
Validation loss: 1.9993991915897658

Epoch: 6| Step: 9
Training loss: 2.306152820587158
Validation loss: 1.9992540587661087

Epoch: 6| Step: 10
Training loss: 2.201846122741699
Validation loss: 1.986013530403055

Epoch: 6| Step: 11
Training loss: 2.0436058044433594
Validation loss: 1.979653968605944

Epoch: 6| Step: 12
Training loss: 2.110697031021118
Validation loss: 1.9952844932515135

Epoch: 6| Step: 13
Training loss: 2.7031545639038086
Validation loss: 1.967241802523213

Epoch: 59| Step: 0
Training loss: 2.524848461151123
Validation loss: 1.9741350143186507

Epoch: 6| Step: 1
Training loss: 3.1006665229797363
Validation loss: 1.9901890139425955

Epoch: 6| Step: 2
Training loss: 2.73040771484375
Validation loss: 1.9861473857715566

Epoch: 6| Step: 3
Training loss: 2.197310209274292
Validation loss: 1.9860547434899114

Epoch: 6| Step: 4
Training loss: 2.52195405960083
Validation loss: 1.9807701597931564

Epoch: 6| Step: 5
Training loss: 1.7037556171417236
Validation loss: 2.0133256540503552

Epoch: 6| Step: 6
Training loss: 1.7594877481460571
Validation loss: 2.0011466882562123

Epoch: 6| Step: 7
Training loss: 2.3442747592926025
Validation loss: 2.0020369432305776

Epoch: 6| Step: 8
Training loss: 2.2529711723327637
Validation loss: 1.9875233968098958

Epoch: 6| Step: 9
Training loss: 1.8786721229553223
Validation loss: 2.00675747599653

Epoch: 6| Step: 10
Training loss: 2.6729750633239746
Validation loss: 1.9858811311824347

Epoch: 6| Step: 11
Training loss: 1.7445861101150513
Validation loss: 2.0033405519300893

Epoch: 6| Step: 12
Training loss: 2.034315824508667
Validation loss: 1.9813898019893195

Epoch: 6| Step: 13
Training loss: 2.152266502380371
Validation loss: 1.9939179510198615

Epoch: 60| Step: 0
Training loss: 2.891178607940674
Validation loss: 1.997994549812809

Epoch: 6| Step: 1
Training loss: 1.8479505777359009
Validation loss: 1.9972710570981425

Epoch: 6| Step: 2
Training loss: 2.4248785972595215
Validation loss: 1.9867219463471444

Epoch: 6| Step: 3
Training loss: 2.669339656829834
Validation loss: 2.0042521005035727

Epoch: 6| Step: 4
Training loss: 1.9261809587478638
Validation loss: 2.0028691842991817

Epoch: 6| Step: 5
Training loss: 2.1112449169158936
Validation loss: 2.0118597245985463

Epoch: 6| Step: 6
Training loss: 2.440096855163574
Validation loss: 1.9963485220427155

Epoch: 6| Step: 7
Training loss: 2.086843490600586
Validation loss: 1.995424759003424

Epoch: 6| Step: 8
Training loss: 2.1603972911834717
Validation loss: 1.9964957826880998

Epoch: 6| Step: 9
Training loss: 2.229419708251953
Validation loss: 1.9908693939126947

Epoch: 6| Step: 10
Training loss: 2.1798477172851562
Validation loss: 1.9966699359237507

Epoch: 6| Step: 11
Training loss: 1.8626325130462646
Validation loss: 1.999707442457958

Epoch: 6| Step: 12
Training loss: 2.2763171195983887
Validation loss: 2.0012336918102798

Epoch: 6| Step: 13
Training loss: 2.7312545776367188
Validation loss: 1.992599154031405

Epoch: 61| Step: 0
Training loss: 3.027647018432617
Validation loss: 2.0030630839768278

Epoch: 6| Step: 1
Training loss: 2.279917001724243
Validation loss: 2.0055794254426034

Epoch: 6| Step: 2
Training loss: 2.1843421459198
Validation loss: 1.9956299284453034

Epoch: 6| Step: 3
Training loss: 2.0839505195617676
Validation loss: 2.0015324110625894

Epoch: 6| Step: 4
Training loss: 1.7919762134552002
Validation loss: 1.9881868618790821

Epoch: 6| Step: 5
Training loss: 2.1568427085876465
Validation loss: 1.9976189867142709

Epoch: 6| Step: 6
Training loss: 1.9189801216125488
Validation loss: 1.9889729753617318

Epoch: 6| Step: 7
Training loss: 2.236586570739746
Validation loss: 1.9830159474444646

Epoch: 6| Step: 8
Training loss: 2.719608783721924
Validation loss: 1.9771162156135804

Epoch: 6| Step: 9
Training loss: 1.8691105842590332
Validation loss: 1.9973106563732188

Epoch: 6| Step: 10
Training loss: 2.3524410724639893
Validation loss: 1.9897948721403718

Epoch: 6| Step: 11
Training loss: 2.502429723739624
Validation loss: 1.9769290993290562

Epoch: 6| Step: 12
Training loss: 2.1921963691711426
Validation loss: 1.9888788205321117

Epoch: 6| Step: 13
Training loss: 1.915021300315857
Validation loss: 1.9981501999721731

Epoch: 62| Step: 0
Training loss: 2.3912734985351562
Validation loss: 1.9774777837978896

Epoch: 6| Step: 1
Training loss: 2.3295440673828125
Validation loss: 1.9670694861360776

Epoch: 6| Step: 2
Training loss: 2.2677993774414062
Validation loss: 1.9943307868895992

Epoch: 6| Step: 3
Training loss: 2.502995491027832
Validation loss: 1.961607579262026

Epoch: 6| Step: 4
Training loss: 1.748584270477295
Validation loss: 1.9581261975790865

Epoch: 6| Step: 5
Training loss: 1.7964131832122803
Validation loss: 1.9638720943081764

Epoch: 6| Step: 6
Training loss: 2.0975165367126465
Validation loss: 1.9711799019126481

Epoch: 6| Step: 7
Training loss: 2.396989583969116
Validation loss: 1.9778741777584117

Epoch: 6| Step: 8
Training loss: 2.178504705429077
Validation loss: 1.9566588247975996

Epoch: 6| Step: 9
Training loss: 2.4574713706970215
Validation loss: 1.9666315124880882

Epoch: 6| Step: 10
Training loss: 1.9192622900009155
Validation loss: 1.9634021571887437

Epoch: 6| Step: 11
Training loss: 2.065819263458252
Validation loss: 1.9560483655621927

Epoch: 6| Step: 12
Training loss: 3.0412211418151855
Validation loss: 1.9555659806856545

Epoch: 6| Step: 13
Training loss: 2.0823144912719727
Validation loss: 1.9637867353295768

Epoch: 63| Step: 0
Training loss: 2.265963077545166
Validation loss: 1.9641443529436666

Epoch: 6| Step: 1
Training loss: 2.1236190795898438
Validation loss: 1.9665896238819245

Epoch: 6| Step: 2
Training loss: 2.1651811599731445
Validation loss: 1.9826252614298174

Epoch: 6| Step: 3
Training loss: 2.5447754859924316
Validation loss: 1.9705904991396013

Epoch: 6| Step: 4
Training loss: 2.8260788917541504
Validation loss: 1.9558988668585335

Epoch: 6| Step: 5
Training loss: 2.6376795768737793
Validation loss: 1.953103930719437

Epoch: 6| Step: 6
Training loss: 3.0441386699676514
Validation loss: 1.9572319061525407

Epoch: 6| Step: 7
Training loss: 1.7191768884658813
Validation loss: 1.949660910073147

Epoch: 6| Step: 8
Training loss: 1.8488106727600098
Validation loss: 1.9600521608065533

Epoch: 6| Step: 9
Training loss: 2.3686776161193848
Validation loss: 1.9672383903175272

Epoch: 6| Step: 10
Training loss: 1.9796502590179443
Validation loss: 1.9734709878121652

Epoch: 6| Step: 11
Training loss: 1.9748599529266357
Validation loss: 1.9539940780208958

Epoch: 6| Step: 12
Training loss: 1.571852207183838
Validation loss: 1.9676237144777853

Epoch: 6| Step: 13
Training loss: 2.3291006088256836
Validation loss: 1.9655533862370316

Epoch: 64| Step: 0
Training loss: 2.7770698070526123
Validation loss: 1.9823410959653958

Epoch: 6| Step: 1
Training loss: 2.1276662349700928
Validation loss: 1.992479367922711

Epoch: 6| Step: 2
Training loss: 2.9104461669921875
Validation loss: 1.9920605433884488

Epoch: 6| Step: 3
Training loss: 2.359483242034912
Validation loss: 1.9855399657321233

Epoch: 6| Step: 4
Training loss: 2.648621082305908
Validation loss: 1.9889535980839883

Epoch: 6| Step: 5
Training loss: 2.214468479156494
Validation loss: 1.9929294842545704

Epoch: 6| Step: 6
Training loss: 1.5785826444625854
Validation loss: 1.9982488129728584

Epoch: 6| Step: 7
Training loss: 1.906789779663086
Validation loss: 1.99610395585337

Epoch: 6| Step: 8
Training loss: 2.1613070964813232
Validation loss: 1.9936144646777902

Epoch: 6| Step: 9
Training loss: 1.6722732782363892
Validation loss: 1.9804527874915832

Epoch: 6| Step: 10
Training loss: 2.4555013179779053
Validation loss: 1.9811908711669266

Epoch: 6| Step: 11
Training loss: 2.309108257293701
Validation loss: 1.9820382671971475

Epoch: 6| Step: 12
Training loss: 1.6438488960266113
Validation loss: 1.9978805524046703

Epoch: 6| Step: 13
Training loss: 2.667741298675537
Validation loss: 1.9774020333443918

Epoch: 65| Step: 0
Training loss: 2.252413272857666
Validation loss: 1.9910168647766113

Epoch: 6| Step: 1
Training loss: 2.3867006301879883
Validation loss: 1.9911749580855012

Epoch: 6| Step: 2
Training loss: 2.067448616027832
Validation loss: 1.9747792033738987

Epoch: 6| Step: 3
Training loss: 2.1315884590148926
Validation loss: 1.9716831817421863

Epoch: 6| Step: 4
Training loss: 2.3091135025024414
Validation loss: 1.979775651808708

Epoch: 6| Step: 5
Training loss: 1.7154093980789185
Validation loss: 1.9650392058075115

Epoch: 6| Step: 6
Training loss: 2.1496989727020264
Validation loss: 1.9693434058978994

Epoch: 6| Step: 7
Training loss: 2.3085906505584717
Validation loss: 1.9940593806646203

Epoch: 6| Step: 8
Training loss: 1.6772780418395996
Validation loss: 1.9711712509073236

Epoch: 6| Step: 9
Training loss: 2.555109977722168
Validation loss: 1.9903094153250418

Epoch: 6| Step: 10
Training loss: 2.2752015590667725
Validation loss: 1.9515950038868894

Epoch: 6| Step: 11
Training loss: 2.780683994293213
Validation loss: 1.9598761835405905

Epoch: 6| Step: 12
Training loss: 2.31746768951416
Validation loss: 1.966876773424046

Epoch: 6| Step: 13
Training loss: 2.473936080932617
Validation loss: 1.9673249413890224

Epoch: 66| Step: 0
Training loss: 2.2790329456329346
Validation loss: 1.9503014344041065

Epoch: 6| Step: 1
Training loss: 2.411151885986328
Validation loss: 1.98238459966516

Epoch: 6| Step: 2
Training loss: 2.171910524368286
Validation loss: 1.9572715887459375

Epoch: 6| Step: 3
Training loss: 2.8185620307922363
Validation loss: 1.960815437378422

Epoch: 6| Step: 4
Training loss: 1.583014726638794
Validation loss: 1.9678733118118779

Epoch: 6| Step: 5
Training loss: 1.5004817247390747
Validation loss: 1.952999061153781

Epoch: 6| Step: 6
Training loss: 2.2297072410583496
Validation loss: 1.9846275301389797

Epoch: 6| Step: 7
Training loss: 2.719151496887207
Validation loss: 1.9562058525700723

Epoch: 6| Step: 8
Training loss: 2.3700647354125977
Validation loss: 1.968687052367836

Epoch: 6| Step: 9
Training loss: 2.1347436904907227
Validation loss: 1.9637782522427139

Epoch: 6| Step: 10
Training loss: 2.4135384559631348
Validation loss: 1.9850433770046438

Epoch: 6| Step: 11
Training loss: 1.9834843873977661
Validation loss: 1.956599045825261

Epoch: 6| Step: 12
Training loss: 2.687711238861084
Validation loss: 1.9574810535677019

Epoch: 6| Step: 13
Training loss: 1.7310651540756226
Validation loss: 1.9608126250646447

Epoch: 67| Step: 0
Training loss: 2.007028341293335
Validation loss: 1.9691533952630975

Epoch: 6| Step: 1
Training loss: 2.2189064025878906
Validation loss: 1.9619828475418912

Epoch: 6| Step: 2
Training loss: 2.031862497329712
Validation loss: 1.9511415573858446

Epoch: 6| Step: 3
Training loss: 1.8368020057678223
Validation loss: 1.975449997891662

Epoch: 6| Step: 4
Training loss: 2.1979780197143555
Validation loss: 1.967029361314671

Epoch: 6| Step: 5
Training loss: 1.979770302772522
Validation loss: 1.9817120259807957

Epoch: 6| Step: 6
Training loss: 2.5234975814819336
Validation loss: 1.9938136262278403

Epoch: 6| Step: 7
Training loss: 2.2677183151245117
Validation loss: 1.9832994937896729

Epoch: 6| Step: 8
Training loss: 2.9833202362060547
Validation loss: 1.9683565785807948

Epoch: 6| Step: 9
Training loss: 2.117222547531128
Validation loss: 1.9854036402958695

Epoch: 6| Step: 10
Training loss: 2.1641080379486084
Validation loss: 1.9759185749997374

Epoch: 6| Step: 11
Training loss: 1.9978615045547485
Validation loss: 1.9721911991796186

Epoch: 6| Step: 12
Training loss: 2.495335102081299
Validation loss: 1.9953787877995481

Epoch: 6| Step: 13
Training loss: 2.111697196960449
Validation loss: 1.9849274696842316

Epoch: 68| Step: 0
Training loss: 2.26362681388855
Validation loss: 1.9928960056715115

Epoch: 6| Step: 1
Training loss: 2.0086379051208496
Validation loss: 1.9950896283631683

Epoch: 6| Step: 2
Training loss: 2.1603665351867676
Validation loss: 1.9884844518476916

Epoch: 6| Step: 3
Training loss: 1.766251564025879
Validation loss: 2.0030858747420774

Epoch: 6| Step: 4
Training loss: 2.142364501953125
Validation loss: 1.9798041710289576

Epoch: 6| Step: 5
Training loss: 2.2670702934265137
Validation loss: 1.9851077013118292

Epoch: 6| Step: 6
Training loss: 2.166926383972168
Validation loss: 1.9854454404564315

Epoch: 6| Step: 7
Training loss: 2.6034250259399414
Validation loss: 2.000231789004418

Epoch: 6| Step: 8
Training loss: 1.5416592359542847
Validation loss: 1.9859488010406494

Epoch: 6| Step: 9
Training loss: 2.833273410797119
Validation loss: 1.979595120235156

Epoch: 6| Step: 10
Training loss: 2.346733808517456
Validation loss: 1.977915043471962

Epoch: 6| Step: 11
Training loss: 2.3689956665039062
Validation loss: 1.9954707289254794

Epoch: 6| Step: 12
Training loss: 2.635336399078369
Validation loss: 1.9766479820333502

Epoch: 6| Step: 13
Training loss: 1.6201733350753784
Validation loss: 2.008520726234682

Epoch: 69| Step: 0
Training loss: 2.6193363666534424
Validation loss: 1.9861994020400509

Epoch: 6| Step: 1
Training loss: 2.766003131866455
Validation loss: 1.976260454423966

Epoch: 6| Step: 2
Training loss: 2.576662540435791
Validation loss: 1.9981417297035136

Epoch: 6| Step: 3
Training loss: 2.2606120109558105
Validation loss: 1.983308284513412

Epoch: 6| Step: 4
Training loss: 2.039083480834961
Validation loss: 1.9695731350170669

Epoch: 6| Step: 5
Training loss: 2.4563326835632324
Validation loss: 1.973902574149511

Epoch: 6| Step: 6
Training loss: 1.518170952796936
Validation loss: 1.9834491642572547

Epoch: 6| Step: 7
Training loss: 1.6390628814697266
Validation loss: 1.9872301201666556

Epoch: 6| Step: 8
Training loss: 2.6947712898254395
Validation loss: 1.9785206446083643

Epoch: 6| Step: 9
Training loss: 2.1761162281036377
Validation loss: 1.976459615974016

Epoch: 6| Step: 10
Training loss: 1.7768044471740723
Validation loss: 1.9656897552551762

Epoch: 6| Step: 11
Training loss: 1.9419163465499878
Validation loss: 1.9661634660536242

Epoch: 6| Step: 12
Training loss: 2.2959868907928467
Validation loss: 1.9811920350597751

Epoch: 6| Step: 13
Training loss: 2.224642753601074
Validation loss: 1.9592131337811869

Epoch: 70| Step: 0
Training loss: 2.0373904705047607
Validation loss: 1.9760927128535446

Epoch: 6| Step: 1
Training loss: 2.91318941116333
Validation loss: 1.9908689145118958

Epoch: 6| Step: 2
Training loss: 2.0415759086608887
Validation loss: 1.9890124951639483

Epoch: 6| Step: 3
Training loss: 1.892198085784912
Validation loss: 1.9829691571574057

Epoch: 6| Step: 4
Training loss: 2.026428699493408
Validation loss: 1.981196283012308

Epoch: 6| Step: 5
Training loss: 2.6871256828308105
Validation loss: 1.9954242398661952

Epoch: 6| Step: 6
Training loss: 2.9579319953918457
Validation loss: 1.998465532897621

Epoch: 6| Step: 7
Training loss: 2.1688666343688965
Validation loss: 2.020112309404599

Epoch: 6| Step: 8
Training loss: 2.1879210472106934
Validation loss: 2.001306769668415

Epoch: 6| Step: 9
Training loss: 1.8849539756774902
Validation loss: 2.002397503904117

Epoch: 6| Step: 10
Training loss: 2.096484661102295
Validation loss: 2.003037086097143

Epoch: 6| Step: 11
Training loss: 1.5752513408660889
Validation loss: 2.0092007472950923

Epoch: 6| Step: 12
Training loss: 2.265937566757202
Validation loss: 1.9917537371317546

Epoch: 6| Step: 13
Training loss: 2.070997476577759
Validation loss: 2.019361626717352

Epoch: 71| Step: 0
Training loss: 2.365734338760376
Validation loss: 2.000944156800547

Epoch: 6| Step: 1
Training loss: 2.1045475006103516
Validation loss: 1.9782734378691642

Epoch: 6| Step: 2
Training loss: 2.4380455017089844
Validation loss: 1.986472366958536

Epoch: 6| Step: 3
Training loss: 1.736818790435791
Validation loss: 1.9961240676141554

Epoch: 6| Step: 4
Training loss: 2.6743674278259277
Validation loss: 1.9931664082311815

Epoch: 6| Step: 5
Training loss: 1.457770824432373
Validation loss: 1.9852622606421029

Epoch: 6| Step: 6
Training loss: 1.6855336427688599
Validation loss: 1.9880504531245078

Epoch: 6| Step: 7
Training loss: 1.7850863933563232
Validation loss: 1.9614133732293242

Epoch: 6| Step: 8
Training loss: 2.810373306274414
Validation loss: 1.9738343043993878

Epoch: 6| Step: 9
Training loss: 2.831716775894165
Validation loss: 1.974250530683866

Epoch: 6| Step: 10
Training loss: 1.9553462266921997
Validation loss: 1.9599526684771302

Epoch: 6| Step: 11
Training loss: 2.022984027862549
Validation loss: 1.958720786597139

Epoch: 6| Step: 12
Training loss: 2.5883569717407227
Validation loss: 1.9652692284635318

Epoch: 6| Step: 13
Training loss: 1.999441146850586
Validation loss: 1.9667836812234694

Epoch: 72| Step: 0
Training loss: 2.1997365951538086
Validation loss: 1.945954002359862

Epoch: 6| Step: 1
Training loss: 2.0024373531341553
Validation loss: 1.9602933827266897

Epoch: 6| Step: 2
Training loss: 2.354300022125244
Validation loss: 1.9575656831905406

Epoch: 6| Step: 3
Training loss: 1.6839995384216309
Validation loss: 1.9596133180843887

Epoch: 6| Step: 4
Training loss: 2.3340604305267334
Validation loss: 1.9633875585371448

Epoch: 6| Step: 5
Training loss: 2.3497047424316406
Validation loss: 1.9657484921075965

Epoch: 6| Step: 6
Training loss: 2.2262825965881348
Validation loss: 1.9779296741690686

Epoch: 6| Step: 7
Training loss: 1.8930318355560303
Validation loss: 1.9783540387307443

Epoch: 6| Step: 8
Training loss: 2.1367883682250977
Validation loss: 1.9781244467663508

Epoch: 6| Step: 9
Training loss: 2.295814037322998
Validation loss: 1.966159188619224

Epoch: 6| Step: 10
Training loss: 2.4521095752716064
Validation loss: 1.9707061475323093

Epoch: 6| Step: 11
Training loss: 1.762783169746399
Validation loss: 1.9527175311119325

Epoch: 6| Step: 12
Training loss: 2.7641243934631348
Validation loss: 1.9681021039203932

Epoch: 6| Step: 13
Training loss: 2.5664148330688477
Validation loss: 1.953251782283988

Epoch: 73| Step: 0
Training loss: 2.0913009643554688
Validation loss: 1.9633039171977709

Epoch: 6| Step: 1
Training loss: 1.8462324142456055
Validation loss: 1.9532619727555143

Epoch: 6| Step: 2
Training loss: 2.142568826675415
Validation loss: 1.9501252174377441

Epoch: 6| Step: 3
Training loss: 2.254452705383301
Validation loss: 1.9553803013217064

Epoch: 6| Step: 4
Training loss: 1.8105080127716064
Validation loss: 1.9772440374538462

Epoch: 6| Step: 5
Training loss: 2.621746063232422
Validation loss: 1.9733879809738488

Epoch: 6| Step: 6
Training loss: 1.9080369472503662
Validation loss: 1.9756693788754043

Epoch: 6| Step: 7
Training loss: 2.422834873199463
Validation loss: 1.976471056220352

Epoch: 6| Step: 8
Training loss: 2.8003549575805664
Validation loss: 1.94701079399355

Epoch: 6| Step: 9
Training loss: 2.2091565132141113
Validation loss: 1.972613093673542

Epoch: 6| Step: 10
Training loss: 2.2167458534240723
Validation loss: 1.9813169715225056

Epoch: 6| Step: 11
Training loss: 1.6628358364105225
Validation loss: 1.9903314933981946

Epoch: 6| Step: 12
Training loss: 2.0193545818328857
Validation loss: 1.9851566476206626

Epoch: 6| Step: 13
Training loss: 2.9244637489318848
Validation loss: 1.9711373441962785

Epoch: 74| Step: 0
Training loss: 2.7322826385498047
Validation loss: 1.9620296314198484

Epoch: 6| Step: 1
Training loss: 2.6906986236572266
Validation loss: 1.9707976925757624

Epoch: 6| Step: 2
Training loss: 2.3300461769104004
Validation loss: 1.9840332949033348

Epoch: 6| Step: 3
Training loss: 1.3446964025497437
Validation loss: 1.9583084224372782

Epoch: 6| Step: 4
Training loss: 2.468899726867676
Validation loss: 1.9825461346616027

Epoch: 6| Step: 5
Training loss: 1.8738435506820679
Validation loss: 1.9826863529861614

Epoch: 6| Step: 6
Training loss: 2.625364303588867
Validation loss: 1.9770135161697224

Epoch: 6| Step: 7
Training loss: 1.8943581581115723
Validation loss: 1.9917698124403596

Epoch: 6| Step: 8
Training loss: 2.086014747619629
Validation loss: 1.9741162792328866

Epoch: 6| Step: 9
Training loss: 2.591463565826416
Validation loss: 1.9850845054913593

Epoch: 6| Step: 10
Training loss: 2.458265781402588
Validation loss: 1.9895104721028318

Epoch: 6| Step: 11
Training loss: 1.2357237339019775
Validation loss: 2.000543563596664

Epoch: 6| Step: 12
Training loss: 1.7834739685058594
Validation loss: 1.9984287997727752

Epoch: 6| Step: 13
Training loss: 2.6141583919525146
Validation loss: 1.983311628782621

Epoch: 75| Step: 0
Training loss: 2.6373887062072754
Validation loss: 1.980974111505734

Epoch: 6| Step: 1
Training loss: 2.265469789505005
Validation loss: 1.9878241592837917

Epoch: 6| Step: 2
Training loss: 2.6585397720336914
Validation loss: 1.9408474532506799

Epoch: 6| Step: 3
Training loss: 1.9951798915863037
Validation loss: 1.9759683698736212

Epoch: 6| Step: 4
Training loss: 1.9284236431121826
Validation loss: 1.9936801387417702

Epoch: 6| Step: 5
Training loss: 2.189049243927002
Validation loss: 1.9806620869585263

Epoch: 6| Step: 6
Training loss: 1.6666654348373413
Validation loss: 1.9769046101518857

Epoch: 6| Step: 7
Training loss: 2.4009923934936523
Validation loss: 1.9917082799378263

Epoch: 6| Step: 8
Training loss: 2.451784610748291
Validation loss: 1.9939076054480769

Epoch: 6| Step: 9
Training loss: 1.477250099182129
Validation loss: 1.9821755257985925

Epoch: 6| Step: 10
Training loss: 2.1598238945007324
Validation loss: 1.9762428319582375

Epoch: 6| Step: 11
Training loss: 2.373663902282715
Validation loss: 2.015997131665548

Epoch: 6| Step: 12
Training loss: 2.174940347671509
Validation loss: 1.9803095530438166

Epoch: 6| Step: 13
Training loss: 2.2962117195129395
Validation loss: 1.9729209433319748

Epoch: 76| Step: 0
Training loss: 1.8734389543533325
Validation loss: 1.961381055975473

Epoch: 6| Step: 1
Training loss: 2.001068115234375
Validation loss: 1.9830710246998777

Epoch: 6| Step: 2
Training loss: 2.2971677780151367
Validation loss: 1.9867265301366006

Epoch: 6| Step: 3
Training loss: 1.7082817554473877
Validation loss: 1.9695272394405898

Epoch: 6| Step: 4
Training loss: 2.0785322189331055
Validation loss: 1.985499705037763

Epoch: 6| Step: 5
Training loss: 2.0165224075317383
Validation loss: 1.9651797638144544

Epoch: 6| Step: 6
Training loss: 2.3560853004455566
Validation loss: 1.9771901561367897

Epoch: 6| Step: 7
Training loss: 2.8064839839935303
Validation loss: 1.9780819134045673

Epoch: 6| Step: 8
Training loss: 2.2331736087799072
Validation loss: 1.9802352138744888

Epoch: 6| Step: 9
Training loss: 1.9701805114746094
Validation loss: 1.9740633477446854

Epoch: 6| Step: 10
Training loss: 2.3098058700561523
Validation loss: 1.9636801109519055

Epoch: 6| Step: 11
Training loss: 2.369786024093628
Validation loss: 1.976248602713308

Epoch: 6| Step: 12
Training loss: 2.7431724071502686
Validation loss: 1.9894728083764353

Epoch: 6| Step: 13
Training loss: 1.6504954099655151
Validation loss: 1.997138866814234

Epoch: 77| Step: 0
Training loss: 2.1553518772125244
Validation loss: 1.9843006057123984

Epoch: 6| Step: 1
Training loss: 2.5609965324401855
Validation loss: 1.9936538998798659

Epoch: 6| Step: 2
Training loss: 1.826660394668579
Validation loss: 1.9729242555556759

Epoch: 6| Step: 3
Training loss: 2.0130422115325928
Validation loss: 1.975283286904776

Epoch: 6| Step: 4
Training loss: 2.5445010662078857
Validation loss: 1.969767334640667

Epoch: 6| Step: 5
Training loss: 1.326951503753662
Validation loss: 1.9865475803293207

Epoch: 6| Step: 6
Training loss: 2.1150810718536377
Validation loss: 1.983138031856988

Epoch: 6| Step: 7
Training loss: 1.5281884670257568
Validation loss: 1.9484306227776311

Epoch: 6| Step: 8
Training loss: 2.604722261428833
Validation loss: 1.9785485293275566

Epoch: 6| Step: 9
Training loss: 2.259782552719116
Validation loss: 1.9861774072852185

Epoch: 6| Step: 10
Training loss: 2.3713271617889404
Validation loss: 1.9794396585033787

Epoch: 6| Step: 11
Training loss: 2.083984851837158
Validation loss: 1.9800498844474874

Epoch: 6| Step: 12
Training loss: 2.5682358741760254
Validation loss: 1.9774281106969362

Epoch: 6| Step: 13
Training loss: 2.9692330360412598
Validation loss: 1.977855238863217

Epoch: 78| Step: 0
Training loss: 1.879838228225708
Validation loss: 1.9686289205346057

Epoch: 6| Step: 1
Training loss: 2.1894516944885254
Validation loss: 1.9831445217132568

Epoch: 6| Step: 2
Training loss: 2.210800886154175
Validation loss: 1.9808736052564395

Epoch: 6| Step: 3
Training loss: 2.3267955780029297
Validation loss: 1.983844892953032

Epoch: 6| Step: 4
Training loss: 1.9562180042266846
Validation loss: 1.9773238448686496

Epoch: 6| Step: 5
Training loss: 2.4590559005737305
Validation loss: 1.9907373420653804

Epoch: 6| Step: 6
Training loss: 1.9599506855010986
Validation loss: 1.9941450549710182

Epoch: 6| Step: 7
Training loss: 2.2189087867736816
Validation loss: 1.9839477949245001

Epoch: 6| Step: 8
Training loss: 2.2966179847717285
Validation loss: 1.9838117399523336

Epoch: 6| Step: 9
Training loss: 1.9681960344314575
Validation loss: 2.0007313541186753

Epoch: 6| Step: 10
Training loss: 2.0430150032043457
Validation loss: 2.007392075753981

Epoch: 6| Step: 11
Training loss: 2.3960373401641846
Validation loss: 1.999363019902219

Epoch: 6| Step: 12
Training loss: 2.529096841812134
Validation loss: 2.016121499000057

Epoch: 6| Step: 13
Training loss: 1.9261860847473145
Validation loss: 2.011268493949726

Epoch: 79| Step: 0
Training loss: 2.2227368354797363
Validation loss: 2.009791843352779

Epoch: 6| Step: 1
Training loss: 1.4109745025634766
Validation loss: 2.0187583392666233

Epoch: 6| Step: 2
Training loss: 2.5786538124084473
Validation loss: 2.020360440336248

Epoch: 6| Step: 3
Training loss: 1.6853227615356445
Validation loss: 2.0242795969850276

Epoch: 6| Step: 4
Training loss: 2.1702375411987305
Validation loss: 2.034887780425369

Epoch: 6| Step: 5
Training loss: 2.3614397048950195
Validation loss: 2.0093734097737137

Epoch: 6| Step: 6
Training loss: 1.8105381727218628
Validation loss: 2.023862995127196

Epoch: 6| Step: 7
Training loss: 2.116295576095581
Validation loss: 2.046223666078301

Epoch: 6| Step: 8
Training loss: 2.4877891540527344
Validation loss: 2.026027753788938

Epoch: 6| Step: 9
Training loss: 2.302685260772705
Validation loss: 2.045389431779103

Epoch: 6| Step: 10
Training loss: 2.647890090942383
Validation loss: 2.016039116408235

Epoch: 6| Step: 11
Training loss: 1.5071852207183838
Validation loss: 2.0234949511866414

Epoch: 6| Step: 12
Training loss: 2.80045223236084
Validation loss: 2.000551244264008

Epoch: 6| Step: 13
Training loss: 2.3848211765289307
Validation loss: 2.032261235739595

Epoch: 80| Step: 0
Training loss: 2.390669584274292
Validation loss: 2.0164341029300483

Epoch: 6| Step: 1
Training loss: 2.5457603931427
Validation loss: 1.9998717872045373

Epoch: 6| Step: 2
Training loss: 2.432736396789551
Validation loss: 2.00978446263139

Epoch: 6| Step: 3
Training loss: 1.8630708456039429
Validation loss: 2.008764907877932

Epoch: 6| Step: 4
Training loss: 1.2068687677383423
Validation loss: 2.0188370186795472

Epoch: 6| Step: 5
Training loss: 1.6926417350769043
Validation loss: 2.0191732145124868

Epoch: 6| Step: 6
Training loss: 1.816542387008667
Validation loss: 2.022929665862873

Epoch: 6| Step: 7
Training loss: 1.9032604694366455
Validation loss: 2.01559224308178

Epoch: 6| Step: 8
Training loss: 2.820380210876465
Validation loss: 2.009567778597596

Epoch: 6| Step: 9
Training loss: 2.4249701499938965
Validation loss: 2.006202245271334

Epoch: 6| Step: 10
Training loss: 2.6179864406585693
Validation loss: 2.0147893210893035

Epoch: 6| Step: 11
Training loss: 2.4310531616210938
Validation loss: 2.006353291132117

Epoch: 6| Step: 12
Training loss: 2.1912550926208496
Validation loss: 2.0070209246809765

Epoch: 6| Step: 13
Training loss: 1.7417340278625488
Validation loss: 2.0077081111169632

Epoch: 81| Step: 0
Training loss: 1.7416431903839111
Validation loss: 2.0114658853059173

Epoch: 6| Step: 1
Training loss: 2.0013771057128906
Validation loss: 2.0211509735353532

Epoch: 6| Step: 2
Training loss: 1.8375550508499146
Validation loss: 1.9896441582710511

Epoch: 6| Step: 3
Training loss: 2.6867153644561768
Validation loss: 2.018019635190246

Epoch: 6| Step: 4
Training loss: 2.0050528049468994
Validation loss: 1.9936788466668898

Epoch: 6| Step: 5
Training loss: 1.7863913774490356
Validation loss: 1.9976300424145115

Epoch: 6| Step: 6
Training loss: 2.0885071754455566
Validation loss: 2.00461854216873

Epoch: 6| Step: 7
Training loss: 2.3065857887268066
Validation loss: 2.004663849389681

Epoch: 6| Step: 8
Training loss: 2.8977127075195312
Validation loss: 2.0015648616257535

Epoch: 6| Step: 9
Training loss: 2.2633941173553467
Validation loss: 1.9839044258158693

Epoch: 6| Step: 10
Training loss: 2.3182730674743652
Validation loss: 2.0013057877940517

Epoch: 6| Step: 11
Training loss: 2.0155582427978516
Validation loss: 2.0003739838959067

Epoch: 6| Step: 12
Training loss: 1.9812867641448975
Validation loss: 1.9839559126925725

Epoch: 6| Step: 13
Training loss: 2.3612537384033203
Validation loss: 1.9711544821339269

Epoch: 82| Step: 0
Training loss: 2.1684322357177734
Validation loss: 1.9827453782481532

Epoch: 6| Step: 1
Training loss: 2.3275303840637207
Validation loss: 1.9747537925679197

Epoch: 6| Step: 2
Training loss: 2.8097434043884277
Validation loss: 1.97733982147709

Epoch: 6| Step: 3
Training loss: 2.1704354286193848
Validation loss: 1.9639360468874696

Epoch: 6| Step: 4
Training loss: 1.7601046562194824
Validation loss: 1.9905758352689846

Epoch: 6| Step: 5
Training loss: 2.41579270362854
Validation loss: 1.9823558689445577

Epoch: 6| Step: 6
Training loss: 1.9976446628570557
Validation loss: 2.001806746246994

Epoch: 6| Step: 7
Training loss: 2.328084707260132
Validation loss: 1.996667859374836

Epoch: 6| Step: 8
Training loss: 1.6646806001663208
Validation loss: 2.004096499053381

Epoch: 6| Step: 9
Training loss: 2.285527229309082
Validation loss: 2.01065121927569

Epoch: 6| Step: 10
Training loss: 2.1500964164733887
Validation loss: 1.9833790204858268

Epoch: 6| Step: 11
Training loss: 2.159050464630127
Validation loss: 1.9808149696678243

Epoch: 6| Step: 12
Training loss: 2.001284122467041
Validation loss: 1.9922085064713673

Epoch: 6| Step: 13
Training loss: 2.344101905822754
Validation loss: 1.972934910046157

Epoch: 83| Step: 0
Training loss: 3.0046985149383545
Validation loss: 1.964107055817881

Epoch: 6| Step: 1
Training loss: 2.193716049194336
Validation loss: 1.9774627313818982

Epoch: 6| Step: 2
Training loss: 2.0334107875823975
Validation loss: 2.004215508378962

Epoch: 6| Step: 3
Training loss: 2.0936837196350098
Validation loss: 1.9890005793622745

Epoch: 6| Step: 4
Training loss: 2.6575021743774414
Validation loss: 1.975402170611966

Epoch: 6| Step: 5
Training loss: 2.3993759155273438
Validation loss: 1.9743735636434248

Epoch: 6| Step: 6
Training loss: 1.3447980880737305
Validation loss: 1.973387125999697

Epoch: 6| Step: 7
Training loss: 2.3160810470581055
Validation loss: 1.9913592248834588

Epoch: 6| Step: 8
Training loss: 1.8822007179260254
Validation loss: 1.975289813933834

Epoch: 6| Step: 9
Training loss: 1.9406481981277466
Validation loss: 2.0144548646865355

Epoch: 6| Step: 10
Training loss: 1.5539765357971191
Validation loss: 1.9968505546610842

Epoch: 6| Step: 11
Training loss: 2.05619215965271
Validation loss: 1.9924758711168844

Epoch: 6| Step: 12
Training loss: 2.473689556121826
Validation loss: 1.99671418692476

Epoch: 6| Step: 13
Training loss: 2.5084211826324463
Validation loss: 2.0006139034866006

Epoch: 84| Step: 0
Training loss: 1.543627381324768
Validation loss: 1.9908784051095285

Epoch: 6| Step: 1
Training loss: 1.4698692560195923
Validation loss: 1.9968802749469716

Epoch: 6| Step: 2
Training loss: 1.6347131729125977
Validation loss: 2.0034319969915573

Epoch: 6| Step: 3
Training loss: 2.037601947784424
Validation loss: 1.990522135970413

Epoch: 6| Step: 4
Training loss: 2.323967218399048
Validation loss: 1.991266345465055

Epoch: 6| Step: 5
Training loss: 2.5530107021331787
Validation loss: 1.9954472626409223

Epoch: 6| Step: 6
Training loss: 2.1734280586242676
Validation loss: 2.021629168141273

Epoch: 6| Step: 7
Training loss: 2.9440979957580566
Validation loss: 1.9888363217794767

Epoch: 6| Step: 8
Training loss: 2.7879412174224854
Validation loss: 1.9886932142319218

Epoch: 6| Step: 9
Training loss: 2.914794683456421
Validation loss: 2.0124502899826213

Epoch: 6| Step: 10
Training loss: 2.3160481452941895
Validation loss: 2.003816012413271

Epoch: 6| Step: 11
Training loss: 2.10577392578125
Validation loss: 1.9957809486696798

Epoch: 6| Step: 12
Training loss: 1.70950186252594
Validation loss: 2.0094814838901645

Epoch: 6| Step: 13
Training loss: 1.6367403268814087
Validation loss: 1.9965387211051038

Epoch: 85| Step: 0
Training loss: 2.467592716217041
Validation loss: 2.005159117842233

Epoch: 6| Step: 1
Training loss: 2.4285545349121094
Validation loss: 1.9997212809901084

Epoch: 6| Step: 2
Training loss: 2.177522659301758
Validation loss: 1.9911681093195432

Epoch: 6| Step: 3
Training loss: 1.5773837566375732
Validation loss: 1.99567368466367

Epoch: 6| Step: 4
Training loss: 1.8321384191513062
Validation loss: 1.9896206560955252

Epoch: 6| Step: 5
Training loss: 2.20434308052063
Validation loss: 2.0016230383226947

Epoch: 6| Step: 6
Training loss: 2.270699977874756
Validation loss: 2.017935550341042

Epoch: 6| Step: 7
Training loss: 2.2995376586914062
Validation loss: 2.00609387505439

Epoch: 6| Step: 8
Training loss: 2.3352582454681396
Validation loss: 2.010577565880232

Epoch: 6| Step: 9
Training loss: 2.823697328567505
Validation loss: 2.004599819901169

Epoch: 6| Step: 10
Training loss: 1.7640247344970703
Validation loss: 1.9884234525824105

Epoch: 6| Step: 11
Training loss: 2.342782974243164
Validation loss: 2.0164336542929373

Epoch: 6| Step: 12
Training loss: 1.5197036266326904
Validation loss: 1.992346470073987

Epoch: 6| Step: 13
Training loss: 2.320573568344116
Validation loss: 2.010280728340149

Epoch: 86| Step: 0
Training loss: 2.029170036315918
Validation loss: 1.9963283692636797

Epoch: 6| Step: 1
Training loss: 2.4659817218780518
Validation loss: 1.9901649746843564

Epoch: 6| Step: 2
Training loss: 2.1531753540039062
Validation loss: 1.9887307536217473

Epoch: 6| Step: 3
Training loss: 1.8934093713760376
Validation loss: 2.0000694080065657

Epoch: 6| Step: 4
Training loss: 1.9525997638702393
Validation loss: 2.005427739953482

Epoch: 6| Step: 5
Training loss: 1.9718077182769775
Validation loss: 2.0073912143707275

Epoch: 6| Step: 6
Training loss: 2.06699800491333
Validation loss: 2.012857570443102

Epoch: 6| Step: 7
Training loss: 2.033484935760498
Validation loss: 1.9996753469590218

Epoch: 6| Step: 8
Training loss: 2.669027328491211
Validation loss: 2.001619908117479

Epoch: 6| Step: 9
Training loss: 2.915902614593506
Validation loss: 2.0134087570251955

Epoch: 6| Step: 10
Training loss: 1.5459598302841187
Validation loss: 2.007962199949449

Epoch: 6| Step: 11
Training loss: 1.8507591485977173
Validation loss: 2.0158617419581257

Epoch: 6| Step: 12
Training loss: 1.9921982288360596
Validation loss: 2.020348882162443

Epoch: 6| Step: 13
Training loss: 2.913196563720703
Validation loss: 2.0110647652738836

Epoch: 87| Step: 0
Training loss: 1.842286467552185
Validation loss: 1.9958775504942863

Epoch: 6| Step: 1
Training loss: 2.711378335952759
Validation loss: 2.024794952843779

Epoch: 6| Step: 2
Training loss: 2.3210396766662598
Validation loss: 2.0144088870735577

Epoch: 6| Step: 3
Training loss: 2.4444828033447266
Validation loss: 1.9824869043083602

Epoch: 6| Step: 4
Training loss: 2.172130584716797
Validation loss: 1.999744817774783

Epoch: 6| Step: 5
Training loss: 2.692197561264038
Validation loss: 1.991325936009807

Epoch: 6| Step: 6
Training loss: 2.402944326400757
Validation loss: 2.019851287206014

Epoch: 6| Step: 7
Training loss: 1.7066718339920044
Validation loss: 2.00986623507674

Epoch: 6| Step: 8
Training loss: 2.0501580238342285
Validation loss: 1.9921116085462673

Epoch: 6| Step: 9
Training loss: 1.4393386840820312
Validation loss: 1.9837658636031612

Epoch: 6| Step: 10
Training loss: 2.3504087924957275
Validation loss: 1.9992137160352481

Epoch: 6| Step: 11
Training loss: 2.087977409362793
Validation loss: 1.9968497676234092

Epoch: 6| Step: 12
Training loss: 1.598881483078003
Validation loss: 1.9979108918097712

Epoch: 6| Step: 13
Training loss: 2.45052433013916
Validation loss: 2.0032978211679766

Epoch: 88| Step: 0
Training loss: 2.8760621547698975
Validation loss: 2.006958951232254

Epoch: 6| Step: 1
Training loss: 1.9711993932724
Validation loss: 1.9898227389140795

Epoch: 6| Step: 2
Training loss: 2.095459461212158
Validation loss: 1.9957849774309384

Epoch: 6| Step: 3
Training loss: 2.7008986473083496
Validation loss: 2.0163237766552995

Epoch: 6| Step: 4
Training loss: 2.2680819034576416
Validation loss: 2.006447833071473

Epoch: 6| Step: 5
Training loss: 2.413755416870117
Validation loss: 1.9975466318027948

Epoch: 6| Step: 6
Training loss: 1.990317702293396
Validation loss: 2.020318967039867

Epoch: 6| Step: 7
Training loss: 1.5788309574127197
Validation loss: 2.0070898737958682

Epoch: 6| Step: 8
Training loss: 2.2889223098754883
Validation loss: 2.0092065039501397

Epoch: 6| Step: 9
Training loss: 1.209883689880371
Validation loss: 2.0142531984595844

Epoch: 6| Step: 10
Training loss: 1.8991615772247314
Validation loss: 1.993485035434846

Epoch: 6| Step: 11
Training loss: 2.7941501140594482
Validation loss: 2.0203475131783435

Epoch: 6| Step: 12
Training loss: 2.0647759437561035
Validation loss: 2.027695917314099

Epoch: 6| Step: 13
Training loss: 1.8204443454742432
Validation loss: 2.0295257132540465

Epoch: 89| Step: 0
Training loss: 2.0783615112304688
Validation loss: 2.00599737962087

Epoch: 6| Step: 1
Training loss: 2.6038479804992676
Validation loss: 1.9950203998114473

Epoch: 6| Step: 2
Training loss: 2.097701072692871
Validation loss: 2.033180139398062

Epoch: 6| Step: 3
Training loss: 1.7486099004745483
Validation loss: 1.993865994996922

Epoch: 6| Step: 4
Training loss: 1.726889729499817
Validation loss: 1.989169233588762

Epoch: 6| Step: 5
Training loss: 2.293870449066162
Validation loss: 2.0020292484632103

Epoch: 6| Step: 6
Training loss: 2.4942073822021484
Validation loss: 1.9954298555210073

Epoch: 6| Step: 7
Training loss: 2.889970541000366
Validation loss: 2.000558644212702

Epoch: 6| Step: 8
Training loss: 1.6142467260360718
Validation loss: 1.9878784251469437

Epoch: 6| Step: 9
Training loss: 2.086367607116699
Validation loss: 1.9688326927923387

Epoch: 6| Step: 10
Training loss: 1.948347568511963
Validation loss: 2.0016145565176524

Epoch: 6| Step: 11
Training loss: 2.382200241088867
Validation loss: 1.9966899361661685

Epoch: 6| Step: 12
Training loss: 2.005791187286377
Validation loss: 1.987399806258499

Epoch: 6| Step: 13
Training loss: 2.0363574028015137
Validation loss: 1.9988545704913396

Epoch: 90| Step: 0
Training loss: 1.8185728788375854
Validation loss: 1.9978130722558627

Epoch: 6| Step: 1
Training loss: 2.469050884246826
Validation loss: 2.0086728231881255

Epoch: 6| Step: 2
Training loss: 1.4435632228851318
Validation loss: 2.0185869483537573

Epoch: 6| Step: 3
Training loss: 2.317305564880371
Validation loss: 2.0006486190262662

Epoch: 6| Step: 4
Training loss: 2.386206865310669
Validation loss: 1.9925234727962042

Epoch: 6| Step: 5
Training loss: 2.825249671936035
Validation loss: 2.0046488636283466

Epoch: 6| Step: 6
Training loss: 1.9185107946395874
Validation loss: 2.0087842633647304

Epoch: 6| Step: 7
Training loss: 2.3375728130340576
Validation loss: 2.0320975831759873

Epoch: 6| Step: 8
Training loss: 2.4992566108703613
Validation loss: 1.9972772008629256

Epoch: 6| Step: 9
Training loss: 2.527216672897339
Validation loss: 2.017792485093558

Epoch: 6| Step: 10
Training loss: 1.5703366994857788
Validation loss: 2.0247687934547343

Epoch: 6| Step: 11
Training loss: 2.248746633529663
Validation loss: 2.0053094830564273

Epoch: 6| Step: 12
Training loss: 1.6308794021606445
Validation loss: 2.021806720764406

Epoch: 6| Step: 13
Training loss: 1.8931342363357544
Validation loss: 2.026772822103193

Epoch: 91| Step: 0
Training loss: 2.666133403778076
Validation loss: 2.011705331904914

Epoch: 6| Step: 1
Training loss: 2.5680599212646484
Validation loss: 2.025684792508361

Epoch: 6| Step: 2
Training loss: 2.4524331092834473
Validation loss: 2.012611540414954

Epoch: 6| Step: 3
Training loss: 1.640152931213379
Validation loss: 2.008707623327932

Epoch: 6| Step: 4
Training loss: 2.4219069480895996
Validation loss: 2.0013867514107817

Epoch: 6| Step: 5
Training loss: 1.6982629299163818
Validation loss: 1.9938742678652528

Epoch: 6| Step: 6
Training loss: 2.2326154708862305
Validation loss: 1.9991265368717972

Epoch: 6| Step: 7
Training loss: 2.01491641998291
Validation loss: 2.009336271593648

Epoch: 6| Step: 8
Training loss: 1.6659886837005615
Validation loss: 2.0118117242731075

Epoch: 6| Step: 9
Training loss: 2.238023281097412
Validation loss: 2.0152036143887426

Epoch: 6| Step: 10
Training loss: 2.7443175315856934
Validation loss: 2.0074745057731547

Epoch: 6| Step: 11
Training loss: 2.0226964950561523
Validation loss: 2.0326170690598024

Epoch: 6| Step: 12
Training loss: 1.6293246746063232
Validation loss: 2.0324621892744497

Epoch: 6| Step: 13
Training loss: 1.7592504024505615
Validation loss: 2.0290151232032367

Epoch: 92| Step: 0
Training loss: 2.270585060119629
Validation loss: 2.0065204738288798

Epoch: 6| Step: 1
Training loss: 2.7888457775115967
Validation loss: 2.016187019245599

Epoch: 6| Step: 2
Training loss: 1.9881088733673096
Validation loss: 2.021591550560408

Epoch: 6| Step: 3
Training loss: 1.703460931777954
Validation loss: 1.999456851713119

Epoch: 6| Step: 4
Training loss: 2.2278711795806885
Validation loss: 2.0150457735984557

Epoch: 6| Step: 5
Training loss: 2.288498878479004
Validation loss: 2.01353185407577

Epoch: 6| Step: 6
Training loss: 2.5703554153442383
Validation loss: 2.014725713319676

Epoch: 6| Step: 7
Training loss: 1.785956859588623
Validation loss: 2.002134769193588

Epoch: 6| Step: 8
Training loss: 2.6360421180725098
Validation loss: 2.0191617191478772

Epoch: 6| Step: 9
Training loss: 1.7632052898406982
Validation loss: 2.027102037142682

Epoch: 6| Step: 10
Training loss: 1.7793910503387451
Validation loss: 2.0090245341741912

Epoch: 6| Step: 11
Training loss: 2.3791728019714355
Validation loss: 2.012956178316506

Epoch: 6| Step: 12
Training loss: 1.8419594764709473
Validation loss: 2.004212961401991

Epoch: 6| Step: 13
Training loss: 1.862729549407959
Validation loss: 1.9926225626340477

Epoch: 93| Step: 0
Training loss: 2.3332114219665527
Validation loss: 2.020469278417608

Epoch: 6| Step: 1
Training loss: 2.510991096496582
Validation loss: 1.9980213847211612

Epoch: 6| Step: 2
Training loss: 2.2875351905822754
Validation loss: 2.0010645620284544

Epoch: 6| Step: 3
Training loss: 2.170388698577881
Validation loss: 2.029744117490707

Epoch: 6| Step: 4
Training loss: 2.3741087913513184
Validation loss: 1.9742184505667737

Epoch: 6| Step: 5
Training loss: 1.8860664367675781
Validation loss: 1.9977231051332207

Epoch: 6| Step: 6
Training loss: 2.558211326599121
Validation loss: 2.0202855089659333

Epoch: 6| Step: 7
Training loss: 2.2667789459228516
Validation loss: 2.016606224480496

Epoch: 6| Step: 8
Training loss: 1.5985357761383057
Validation loss: 2.0160302833844255

Epoch: 6| Step: 9
Training loss: 2.402106761932373
Validation loss: 2.0364775683290217

Epoch: 6| Step: 10
Training loss: 2.009042739868164
Validation loss: 2.017578378800423

Epoch: 6| Step: 11
Training loss: 2.1446175575256348
Validation loss: 2.001321243983443

Epoch: 6| Step: 12
Training loss: 1.446955919265747
Validation loss: 2.0155665964208622

Epoch: 6| Step: 13
Training loss: 2.031463384628296
Validation loss: 2.0325433515733287

Epoch: 94| Step: 0
Training loss: 2.3009872436523438
Validation loss: 2.0076859574164114

Epoch: 6| Step: 1
Training loss: 2.0529232025146484
Validation loss: 2.0092880751497004

Epoch: 6| Step: 2
Training loss: 1.884073257446289
Validation loss: 2.012300657969649

Epoch: 6| Step: 3
Training loss: 2.2013700008392334
Validation loss: 2.0148409515298824

Epoch: 6| Step: 4
Training loss: 2.041390895843506
Validation loss: 1.9970751500898791

Epoch: 6| Step: 5
Training loss: 2.3615357875823975
Validation loss: 1.9979779669033584

Epoch: 6| Step: 6
Training loss: 2.0687060356140137
Validation loss: 1.9876266987093034

Epoch: 6| Step: 7
Training loss: 1.9001126289367676
Validation loss: 2.0090546454152753

Epoch: 6| Step: 8
Training loss: 1.7634341716766357
Validation loss: 2.0010954551799323

Epoch: 6| Step: 9
Training loss: 2.241793155670166
Validation loss: 2.0023352638367684

Epoch: 6| Step: 10
Training loss: 2.833428382873535
Validation loss: 2.0004483551107426

Epoch: 6| Step: 11
Training loss: 2.003275156021118
Validation loss: 1.9814170650256577

Epoch: 6| Step: 12
Training loss: 2.2962851524353027
Validation loss: 2.002271718876336

Epoch: 6| Step: 13
Training loss: 2.0887250900268555
Validation loss: 2.0026668015346734

Epoch: 95| Step: 0
Training loss: 2.401207447052002
Validation loss: 1.9959273722863966

Epoch: 6| Step: 1
Training loss: 2.020164966583252
Validation loss: 1.9928875764211018

Epoch: 6| Step: 2
Training loss: 2.092254400253296
Validation loss: 2.023357570812266

Epoch: 6| Step: 3
Training loss: 2.1198763847351074
Validation loss: 1.995472792656191

Epoch: 6| Step: 4
Training loss: 2.3660824298858643
Validation loss: 2.0064770278110298

Epoch: 6| Step: 5
Training loss: 1.625380277633667
Validation loss: 1.9810832187693606

Epoch: 6| Step: 6
Training loss: 1.283785343170166
Validation loss: 1.9930571945764686

Epoch: 6| Step: 7
Training loss: 2.8711647987365723
Validation loss: 1.9869668124824442

Epoch: 6| Step: 8
Training loss: 2.36674165725708
Validation loss: 1.995019192336708

Epoch: 6| Step: 9
Training loss: 2.2805447578430176
Validation loss: 2.0000342553661716

Epoch: 6| Step: 10
Training loss: 1.867129921913147
Validation loss: 2.0015111277180333

Epoch: 6| Step: 11
Training loss: 2.0169265270233154
Validation loss: 1.9866904981674687

Epoch: 6| Step: 12
Training loss: 2.3197224140167236
Validation loss: 1.9878870799977293

Epoch: 6| Step: 13
Training loss: 2.608288049697876
Validation loss: 1.9853892249445761

Epoch: 96| Step: 0
Training loss: 2.109854221343994
Validation loss: 2.0101020566878782

Epoch: 6| Step: 1
Training loss: 2.127739667892456
Validation loss: 2.010122896522604

Epoch: 6| Step: 2
Training loss: 2.0407400131225586
Validation loss: 2.016354460870066

Epoch: 6| Step: 3
Training loss: 2.068026065826416
Validation loss: 2.038039218994879

Epoch: 6| Step: 4
Training loss: 1.9053336381912231
Validation loss: 2.023819641400409

Epoch: 6| Step: 5
Training loss: 2.0286922454833984
Validation loss: 2.021239680628623

Epoch: 6| Step: 6
Training loss: 1.99330735206604
Validation loss: 2.0057361331037296

Epoch: 6| Step: 7
Training loss: 2.8441708087921143
Validation loss: 1.9951285546825779

Epoch: 6| Step: 8
Training loss: 1.9701122045516968
Validation loss: 1.9853488706773328

Epoch: 6| Step: 9
Training loss: 2.616569995880127
Validation loss: 1.9982589906261814

Epoch: 6| Step: 10
Training loss: 1.2636100053787231
Validation loss: 2.0184218652786745

Epoch: 6| Step: 11
Training loss: 2.028374671936035
Validation loss: 2.032738249789002

Epoch: 6| Step: 12
Training loss: 2.9035706520080566
Validation loss: 2.042597451517659

Epoch: 6| Step: 13
Training loss: 1.8254503011703491
Validation loss: 2.0101913675185172

Epoch: 97| Step: 0
Training loss: 2.0680277347564697
Validation loss: 2.019925199529176

Epoch: 6| Step: 1
Training loss: 2.3600950241088867
Validation loss: 2.031049641229773

Epoch: 6| Step: 2
Training loss: 2.19264554977417
Validation loss: 2.0073792857508503

Epoch: 6| Step: 3
Training loss: 2.322171926498413
Validation loss: 2.0028099090822282

Epoch: 6| Step: 4
Training loss: 1.659927248954773
Validation loss: 1.997618268894893

Epoch: 6| Step: 5
Training loss: 1.6008304357528687
Validation loss: 2.0067205993078088

Epoch: 6| Step: 6
Training loss: 1.8261834383010864
Validation loss: 2.0078192295566684

Epoch: 6| Step: 7
Training loss: 2.300243377685547
Validation loss: 2.0040593903551818

Epoch: 6| Step: 8
Training loss: 1.9258710145950317
Validation loss: 2.0002967260217153

Epoch: 6| Step: 9
Training loss: 2.7046070098876953
Validation loss: 2.0214663436335902

Epoch: 6| Step: 10
Training loss: 2.4712657928466797
Validation loss: 2.0101948886789303

Epoch: 6| Step: 11
Training loss: 2.232722759246826
Validation loss: 2.0230187254567302

Epoch: 6| Step: 12
Training loss: 1.626070499420166
Validation loss: 2.022667069588938

Epoch: 6| Step: 13
Training loss: 2.7574572563171387
Validation loss: 2.022691347265756

Epoch: 98| Step: 0
Training loss: 2.150023937225342
Validation loss: 2.0186157085562266

Epoch: 6| Step: 1
Training loss: 1.9934197664260864
Validation loss: 2.0086902546626266

Epoch: 6| Step: 2
Training loss: 2.2682878971099854
Validation loss: 2.017318835822485

Epoch: 6| Step: 3
Training loss: 2.125117301940918
Validation loss: 2.009369473303518

Epoch: 6| Step: 4
Training loss: 2.0631320476531982
Validation loss: 1.9893421511496268

Epoch: 6| Step: 5
Training loss: 1.7857950925827026
Validation loss: 2.002565832548244

Epoch: 6| Step: 6
Training loss: 2.6106925010681152
Validation loss: 2.006686670805818

Epoch: 6| Step: 7
Training loss: 2.9439125061035156
Validation loss: 1.981044764159828

Epoch: 6| Step: 8
Training loss: 2.0230095386505127
Validation loss: 1.9855463402245634

Epoch: 6| Step: 9
Training loss: 1.7118041515350342
Validation loss: 1.9950384862961308

Epoch: 6| Step: 10
Training loss: 1.4147775173187256
Validation loss: 1.9951701420609669

Epoch: 6| Step: 11
Training loss: 2.3439764976501465
Validation loss: 1.98061841277666

Epoch: 6| Step: 12
Training loss: 1.892061710357666
Validation loss: 1.9938713735149753

Epoch: 6| Step: 13
Training loss: 2.7950141429901123
Validation loss: 1.9933181578113186

Epoch: 99| Step: 0
Training loss: 1.6866226196289062
Validation loss: 2.0056233764976583

Epoch: 6| Step: 1
Training loss: 2.4293460845947266
Validation loss: 1.9988286161935458

Epoch: 6| Step: 2
Training loss: 2.1458487510681152
Validation loss: 1.9999398313542849

Epoch: 6| Step: 3
Training loss: 2.658540725708008
Validation loss: 2.0298691398353985

Epoch: 6| Step: 4
Training loss: 2.386387825012207
Validation loss: 2.023003162876252

Epoch: 6| Step: 5
Training loss: 2.1925241947174072
Validation loss: 2.036580378009427

Epoch: 6| Step: 6
Training loss: 2.1308186054229736
Validation loss: 2.040512097779141

Epoch: 6| Step: 7
Training loss: 1.9344329833984375
Validation loss: 2.0511537110933693

Epoch: 6| Step: 8
Training loss: 1.825149416923523
Validation loss: 2.039428190518451

Epoch: 6| Step: 9
Training loss: 2.3538618087768555
Validation loss: 2.0412577018942883

Epoch: 6| Step: 10
Training loss: 2.343426465988159
Validation loss: 2.0474929219932965

Epoch: 6| Step: 11
Training loss: 1.8938401937484741
Validation loss: 2.042853501535231

Epoch: 6| Step: 12
Training loss: 1.6590980291366577
Validation loss: 2.0596075442529496

Epoch: 6| Step: 13
Training loss: 2.2327141761779785
Validation loss: 2.0199728140266995

Epoch: 100| Step: 0
Training loss: 1.4458203315734863
Validation loss: 2.0272377165414954

Epoch: 6| Step: 1
Training loss: 2.184079170227051
Validation loss: 2.0245651955245645

Epoch: 6| Step: 2
Training loss: 2.3462636470794678
Validation loss: 2.0212454078018025

Epoch: 6| Step: 3
Training loss: 1.9451409578323364
Validation loss: 1.9997215758087814

Epoch: 6| Step: 4
Training loss: 2.514709949493408
Validation loss: 2.0290419875934558

Epoch: 6| Step: 5
Training loss: 1.6199681758880615
Validation loss: 1.9889384751678796

Epoch: 6| Step: 6
Training loss: 2.335205554962158
Validation loss: 2.0071549364315566

Epoch: 6| Step: 7
Training loss: 2.5508344173431396
Validation loss: 1.9972309425312986

Epoch: 6| Step: 8
Training loss: 2.2221274375915527
Validation loss: 2.0014666203529603

Epoch: 6| Step: 9
Training loss: 2.388613224029541
Validation loss: 1.9927544068264704

Epoch: 6| Step: 10
Training loss: 2.498812675476074
Validation loss: 1.9945097764333088

Epoch: 6| Step: 11
Training loss: 2.1627511978149414
Validation loss: 1.9977922285756757

Epoch: 6| Step: 12
Training loss: 1.953153371810913
Validation loss: 1.966769036426339

Epoch: 6| Step: 13
Training loss: 1.3118444681167603
Validation loss: 2.0061167773380073

Epoch: 101| Step: 0
Training loss: 1.462644338607788
Validation loss: 2.010684505585701

Epoch: 6| Step: 1
Training loss: 2.1691136360168457
Validation loss: 2.007448019519929

Epoch: 6| Step: 2
Training loss: 2.0021774768829346
Validation loss: 1.9895615090606034

Epoch: 6| Step: 3
Training loss: 2.0200486183166504
Validation loss: 2.0005279176978656

Epoch: 6| Step: 4
Training loss: 2.32338285446167
Validation loss: 2.0009275174910024

Epoch: 6| Step: 5
Training loss: 2.2136824131011963
Validation loss: 2.016841806391234

Epoch: 6| Step: 6
Training loss: 2.260913848876953
Validation loss: 2.0249580362791657

Epoch: 6| Step: 7
Training loss: 2.132153034210205
Validation loss: 2.022097537594457

Epoch: 6| Step: 8
Training loss: 2.140632390975952
Validation loss: 2.016958200803367

Epoch: 6| Step: 9
Training loss: 1.9456175565719604
Validation loss: 2.0533217435242026

Epoch: 6| Step: 10
Training loss: 2.2035884857177734
Validation loss: 2.0370401131209506

Epoch: 6| Step: 11
Training loss: 2.0166945457458496
Validation loss: 2.0451145018300703

Epoch: 6| Step: 12
Training loss: 2.7470297813415527
Validation loss: 2.0634517310768046

Epoch: 6| Step: 13
Training loss: 2.309333562850952
Validation loss: 2.0380936322673673

Epoch: 102| Step: 0
Training loss: 2.20535945892334
Validation loss: 2.0426270346487723

Epoch: 6| Step: 1
Training loss: 1.7453041076660156
Validation loss: 2.044131922465499

Epoch: 6| Step: 2
Training loss: 1.5332952737808228
Validation loss: 2.029876293674592

Epoch: 6| Step: 3
Training loss: 2.4820947647094727
Validation loss: 2.046629657027542

Epoch: 6| Step: 4
Training loss: 2.0419821739196777
Validation loss: 2.0230783185651227

Epoch: 6| Step: 5
Training loss: 1.6172164678573608
Validation loss: 2.0416656053194435

Epoch: 6| Step: 6
Training loss: 2.381776809692383
Validation loss: 2.0332525673732964

Epoch: 6| Step: 7
Training loss: 2.6574759483337402
Validation loss: 2.0266314732131137

Epoch: 6| Step: 8
Training loss: 2.2954354286193848
Validation loss: 2.024380681335285

Epoch: 6| Step: 9
Training loss: 2.48960280418396
Validation loss: 2.0261326528364614

Epoch: 6| Step: 10
Training loss: 2.08774733543396
Validation loss: 2.011423421162431

Epoch: 6| Step: 11
Training loss: 2.1108038425445557
Validation loss: 1.9832373306315432

Epoch: 6| Step: 12
Training loss: 1.9096612930297852
Validation loss: 1.9888408619870421

Epoch: 6| Step: 13
Training loss: 2.490017890930176
Validation loss: 1.9898451797423824

Epoch: 103| Step: 0
Training loss: 2.320021390914917
Validation loss: 2.0075645856959845

Epoch: 6| Step: 1
Training loss: 2.764725923538208
Validation loss: 2.013427770265969

Epoch: 6| Step: 2
Training loss: 1.9972326755523682
Validation loss: 2.0197539073164745

Epoch: 6| Step: 3
Training loss: 1.7010585069656372
Validation loss: 2.006864993802963

Epoch: 6| Step: 4
Training loss: 1.6872668266296387
Validation loss: 2.0128413425978793

Epoch: 6| Step: 5
Training loss: 1.9977960586547852
Validation loss: 2.016537627866191

Epoch: 6| Step: 6
Training loss: 1.8453761339187622
Validation loss: 1.9921289567024476

Epoch: 6| Step: 7
Training loss: 2.7354607582092285
Validation loss: 2.015746719093733

Epoch: 6| Step: 8
Training loss: 1.7079013586044312
Validation loss: 2.0026106026864823

Epoch: 6| Step: 9
Training loss: 2.4408864974975586
Validation loss: 2.0234464894058886

Epoch: 6| Step: 10
Training loss: 1.883133053779602
Validation loss: 1.9838724918262933

Epoch: 6| Step: 11
Training loss: 2.232064723968506
Validation loss: 2.0050411070546796

Epoch: 6| Step: 12
Training loss: 1.5532636642456055
Validation loss: 2.0233058647442888

Epoch: 6| Step: 13
Training loss: 2.948474407196045
Validation loss: 2.0374764627025974

Epoch: 104| Step: 0
Training loss: 1.6785681247711182
Validation loss: 2.030037165969931

Epoch: 6| Step: 1
Training loss: 2.6384291648864746
Validation loss: 2.0002329605881886

Epoch: 6| Step: 2
Training loss: 1.9988377094268799
Validation loss: 2.00086098717105

Epoch: 6| Step: 3
Training loss: 2.598851442337036
Validation loss: 1.9948805327056556

Epoch: 6| Step: 4
Training loss: 2.1973116397857666
Validation loss: 2.0262247362444477

Epoch: 6| Step: 5
Training loss: 1.9806451797485352
Validation loss: 2.0100286519655617

Epoch: 6| Step: 6
Training loss: 2.777462959289551
Validation loss: 2.016795542932326

Epoch: 6| Step: 7
Training loss: 2.209200382232666
Validation loss: 2.0364030625230525

Epoch: 6| Step: 8
Training loss: 2.153428077697754
Validation loss: 2.01672770771929

Epoch: 6| Step: 9
Training loss: 1.8406543731689453
Validation loss: 2.0249354326596825

Epoch: 6| Step: 10
Training loss: 1.291532278060913
Validation loss: 2.037079640614089

Epoch: 6| Step: 11
Training loss: 2.6880178451538086
Validation loss: 2.0457316713948406

Epoch: 6| Step: 12
Training loss: 1.449307918548584
Validation loss: 2.021695711279428

Epoch: 6| Step: 13
Training loss: 2.314213514328003
Validation loss: 2.032788076708394

Epoch: 105| Step: 0
Training loss: 2.3440799713134766
Validation loss: 2.0044501135426183

Epoch: 6| Step: 1
Training loss: 1.8158714771270752
Validation loss: 2.01055662093624

Epoch: 6| Step: 2
Training loss: 2.0999298095703125
Validation loss: 1.9873457416411369

Epoch: 6| Step: 3
Training loss: 2.273622512817383
Validation loss: 1.9864518386061474

Epoch: 6| Step: 4
Training loss: 1.7071338891983032
Validation loss: 1.98841643077071

Epoch: 6| Step: 5
Training loss: 3.1119847297668457
Validation loss: 1.9859110206686041

Epoch: 6| Step: 6
Training loss: 2.262691020965576
Validation loss: 1.9911640703037221

Epoch: 6| Step: 7
Training loss: 1.8170818090438843
Validation loss: 1.9940135453336982

Epoch: 6| Step: 8
Training loss: 2.0623409748077393
Validation loss: 2.00686655506011

Epoch: 6| Step: 9
Training loss: 2.035428047180176
Validation loss: 1.997286331269049

Epoch: 6| Step: 10
Training loss: 2.0482537746429443
Validation loss: 1.9904951613436463

Epoch: 6| Step: 11
Training loss: 2.487354278564453
Validation loss: 1.9740633913265762

Epoch: 6| Step: 12
Training loss: 1.9711593389511108
Validation loss: 1.9649450548233525

Epoch: 6| Step: 13
Training loss: 1.6396158933639526
Validation loss: 1.9986631895906182

Epoch: 106| Step: 0
Training loss: 2.2814087867736816
Validation loss: 1.979922180534691

Epoch: 6| Step: 1
Training loss: 2.5293121337890625
Validation loss: 1.9696670142553185

Epoch: 6| Step: 2
Training loss: 1.9696768522262573
Validation loss: 1.9748653006810013

Epoch: 6| Step: 3
Training loss: 1.945232629776001
Validation loss: 1.9940454729141728

Epoch: 6| Step: 4
Training loss: 2.1646604537963867
Validation loss: 1.9975625866202897

Epoch: 6| Step: 5
Training loss: 2.1754355430603027
Validation loss: 1.9780690208558114

Epoch: 6| Step: 6
Training loss: 2.1102709770202637
Validation loss: 1.9939218169899398

Epoch: 6| Step: 7
Training loss: 2.1794705390930176
Validation loss: 1.9735685599747526

Epoch: 6| Step: 8
Training loss: 1.8566988706588745
Validation loss: 1.975309548839446

Epoch: 6| Step: 9
Training loss: 2.531557321548462
Validation loss: 1.991765796497304

Epoch: 6| Step: 10
Training loss: 1.6321485042572021
Validation loss: 2.028101036625524

Epoch: 6| Step: 11
Training loss: 2.298413038253784
Validation loss: 1.9999257787581413

Epoch: 6| Step: 12
Training loss: 2.259021282196045
Validation loss: 1.9890540133240402

Epoch: 6| Step: 13
Training loss: 1.6734470129013062
Validation loss: 2.015824285886621

Epoch: 107| Step: 0
Training loss: 2.1939282417297363
Validation loss: 2.0102677691367363

Epoch: 6| Step: 1
Training loss: 1.440801978111267
Validation loss: 1.9993952474286478

Epoch: 6| Step: 2
Training loss: 2.744586944580078
Validation loss: 2.013303966932399

Epoch: 6| Step: 3
Training loss: 1.5639824867248535
Validation loss: 2.0234954780147922

Epoch: 6| Step: 4
Training loss: 2.316100597381592
Validation loss: 2.0272041700219594

Epoch: 6| Step: 5
Training loss: 1.4782516956329346
Validation loss: 2.0200641642334642

Epoch: 6| Step: 6
Training loss: 2.3169801235198975
Validation loss: 2.0230670103462796

Epoch: 6| Step: 7
Training loss: 2.3126583099365234
Validation loss: 2.0279531504518244

Epoch: 6| Step: 8
Training loss: 1.8537964820861816
Validation loss: 2.035469783249722

Epoch: 6| Step: 9
Training loss: 1.974900484085083
Validation loss: 2.038713406491023

Epoch: 6| Step: 10
Training loss: 2.5923590660095215
Validation loss: 2.0419332699109147

Epoch: 6| Step: 11
Training loss: 2.4578168392181396
Validation loss: 2.0326419004829983

Epoch: 6| Step: 12
Training loss: 2.1630797386169434
Validation loss: 1.9973542869731944

Epoch: 6| Step: 13
Training loss: 2.1330785751342773
Validation loss: 2.0295858921543246

Epoch: 108| Step: 0
Training loss: 2.14764404296875
Validation loss: 2.060272098869406

Epoch: 6| Step: 1
Training loss: 2.5628764629364014
Validation loss: 2.0345276812071442

Epoch: 6| Step: 2
Training loss: 2.5240139961242676
Validation loss: 2.022089676190448

Epoch: 6| Step: 3
Training loss: 2.3273842334747314
Validation loss: 2.020579754665334

Epoch: 6| Step: 4
Training loss: 2.03882098197937
Validation loss: 2.040066667782363

Epoch: 6| Step: 5
Training loss: 1.9442362785339355
Validation loss: 2.037343478971912

Epoch: 6| Step: 6
Training loss: 2.6663873195648193
Validation loss: 2.0410639547532603

Epoch: 6| Step: 7
Training loss: 2.133924722671509
Validation loss: 2.0512651474245134

Epoch: 6| Step: 8
Training loss: 1.758683443069458
Validation loss: 2.0475200914567515

Epoch: 6| Step: 9
Training loss: 1.660078763961792
Validation loss: 2.0372539489499983

Epoch: 6| Step: 10
Training loss: 1.9763485193252563
Validation loss: 2.0339347534282233

Epoch: 6| Step: 11
Training loss: 1.681838035583496
Validation loss: 2.0389678311604325

Epoch: 6| Step: 12
Training loss: 1.9318382740020752
Validation loss: 2.03119497658104

Epoch: 6| Step: 13
Training loss: 2.147179126739502
Validation loss: 2.022727640726233

Epoch: 109| Step: 0
Training loss: 1.564063549041748
Validation loss: 2.026032668288036

Epoch: 6| Step: 1
Training loss: 1.7329331636428833
Validation loss: 2.0271972225558375

Epoch: 6| Step: 2
Training loss: 1.9256259202957153
Validation loss: 2.0240637615162838

Epoch: 6| Step: 3
Training loss: 2.927755355834961
Validation loss: 2.0265587299100813

Epoch: 6| Step: 4
Training loss: 2.7501182556152344
Validation loss: 2.0294532416969218

Epoch: 6| Step: 5
Training loss: 1.6881787776947021
Validation loss: 2.0040011687945296

Epoch: 6| Step: 6
Training loss: 2.318547248840332
Validation loss: 2.0323349263078425

Epoch: 6| Step: 7
Training loss: 1.9611386060714722
Validation loss: 2.0187858932761737

Epoch: 6| Step: 8
Training loss: 2.1775918006896973
Validation loss: 2.038219427549711

Epoch: 6| Step: 9
Training loss: 1.958465337753296
Validation loss: 2.019844014157531

Epoch: 6| Step: 10
Training loss: 2.182180404663086
Validation loss: 1.9944106404499342

Epoch: 6| Step: 11
Training loss: 2.305480480194092
Validation loss: 1.9836329183270853

Epoch: 6| Step: 12
Training loss: 2.072843551635742
Validation loss: 2.01042878243231

Epoch: 6| Step: 13
Training loss: 1.9467016458511353
Validation loss: 2.014740918272285

Epoch: 110| Step: 0
Training loss: 2.027803421020508
Validation loss: 2.0159743626912436

Epoch: 6| Step: 1
Training loss: 2.32619571685791
Validation loss: 1.9919482097830823

Epoch: 6| Step: 2
Training loss: 1.6030136346817017
Validation loss: 2.0038491859230945

Epoch: 6| Step: 3
Training loss: 2.4991962909698486
Validation loss: 1.9876431021639096

Epoch: 6| Step: 4
Training loss: 2.044304370880127
Validation loss: 2.0320132124808525

Epoch: 6| Step: 5
Training loss: 2.4443469047546387
Validation loss: 1.9875472950679

Epoch: 6| Step: 6
Training loss: 1.9317145347595215
Validation loss: 1.9861913675902991

Epoch: 6| Step: 7
Training loss: 1.906578540802002
Validation loss: 1.9889144077095935

Epoch: 6| Step: 8
Training loss: 2.9114036560058594
Validation loss: 2.02870576612411

Epoch: 6| Step: 9
Training loss: 1.9300082921981812
Validation loss: 2.0072453919277398

Epoch: 6| Step: 10
Training loss: 2.091912269592285
Validation loss: 2.003764985710062

Epoch: 6| Step: 11
Training loss: 2.1980643272399902
Validation loss: 2.008662280216012

Epoch: 6| Step: 12
Training loss: 1.0848604440689087
Validation loss: 2.001620251645324

Epoch: 6| Step: 13
Training loss: 2.9460196495056152
Validation loss: 2.0366082422194944

Epoch: 111| Step: 0
Training loss: 2.739046573638916
Validation loss: 2.0311755826396327

Epoch: 6| Step: 1
Training loss: 2.333005905151367
Validation loss: 2.0049227719665854

Epoch: 6| Step: 2
Training loss: 1.9104782342910767
Validation loss: 2.0226582211832844

Epoch: 6| Step: 3
Training loss: 2.09525203704834
Validation loss: 2.0022426113005607

Epoch: 6| Step: 4
Training loss: 2.7425291538238525
Validation loss: 2.04289347382002

Epoch: 6| Step: 5
Training loss: 1.7205631732940674
Validation loss: 2.003199049221572

Epoch: 6| Step: 6
Training loss: 1.6489689350128174
Validation loss: 2.023271128695498

Epoch: 6| Step: 7
Training loss: 1.9823064804077148
Validation loss: 2.005946559290732

Epoch: 6| Step: 8
Training loss: 2.0454905033111572
Validation loss: 2.009892148356284

Epoch: 6| Step: 9
Training loss: 2.4273898601531982
Validation loss: 2.020721153546405

Epoch: 6| Step: 10
Training loss: 2.0577850341796875
Validation loss: 2.025220150588661

Epoch: 6| Step: 11
Training loss: 2.4307947158813477
Validation loss: 2.0182807330162293

Epoch: 6| Step: 12
Training loss: 1.811077356338501
Validation loss: 2.0136957988944104

Epoch: 6| Step: 13
Training loss: 1.0820392370224
Validation loss: 2.0033695838784658

Epoch: 112| Step: 0
Training loss: 2.3148467540740967
Validation loss: 1.9810397868515344

Epoch: 6| Step: 1
Training loss: 2.1388516426086426
Validation loss: 2.02698024242155

Epoch: 6| Step: 2
Training loss: 2.999135732650757
Validation loss: 2.008474611466931

Epoch: 6| Step: 3
Training loss: 1.6208158731460571
Validation loss: 2.0142603894715667

Epoch: 6| Step: 4
Training loss: 2.357085704803467
Validation loss: 2.020464276754728

Epoch: 6| Step: 5
Training loss: 1.9013280868530273
Validation loss: 2.0229130624442972

Epoch: 6| Step: 6
Training loss: 1.8210573196411133
Validation loss: 2.0151993818180536

Epoch: 6| Step: 7
Training loss: 2.2586865425109863
Validation loss: 2.015793570908167

Epoch: 6| Step: 8
Training loss: 2.140310049057007
Validation loss: 2.01955420483825

Epoch: 6| Step: 9
Training loss: 2.3225555419921875
Validation loss: 2.014612482440087

Epoch: 6| Step: 10
Training loss: 2.1968111991882324
Validation loss: 2.0053929898046676

Epoch: 6| Step: 11
Training loss: 2.286757469177246
Validation loss: 2.0236781412555325

Epoch: 6| Step: 12
Training loss: 1.3111581802368164
Validation loss: 2.0296726918989614

Epoch: 6| Step: 13
Training loss: 1.4161642789840698
Validation loss: 2.0260105068965624

Epoch: 113| Step: 0
Training loss: 2.0528717041015625
Validation loss: 2.0269483135592554

Epoch: 6| Step: 1
Training loss: 2.2393534183502197
Validation loss: 2.0091804612067437

Epoch: 6| Step: 2
Training loss: 2.296233654022217
Validation loss: 2.029910913077734

Epoch: 6| Step: 3
Training loss: 2.4471187591552734
Validation loss: 1.9969596452610467

Epoch: 6| Step: 4
Training loss: 1.8967301845550537
Validation loss: 2.0491277684447584

Epoch: 6| Step: 5
Training loss: 1.6200242042541504
Validation loss: 2.030587109186316

Epoch: 6| Step: 6
Training loss: 2.5205109119415283
Validation loss: 1.999034539345772

Epoch: 6| Step: 7
Training loss: 2.1520092487335205
Validation loss: 2.0156176244058917

Epoch: 6| Step: 8
Training loss: 1.699999213218689
Validation loss: 2.0284839112271547

Epoch: 6| Step: 9
Training loss: 1.9594354629516602
Validation loss: 2.0078589788047214

Epoch: 6| Step: 10
Training loss: 1.9367892742156982
Validation loss: 2.0110231522590882

Epoch: 6| Step: 11
Training loss: 2.5822904109954834
Validation loss: 2.0026701496493433

Epoch: 6| Step: 12
Training loss: 1.7098684310913086
Validation loss: 2.0135995418794694

Epoch: 6| Step: 13
Training loss: 2.75990629196167
Validation loss: 2.0037676031871507

Epoch: 114| Step: 0
Training loss: 1.94740629196167
Validation loss: 2.0061320130543043

Epoch: 6| Step: 1
Training loss: 1.7188408374786377
Validation loss: 2.0001749146369194

Epoch: 6| Step: 2
Training loss: 2.039463996887207
Validation loss: 1.9881278968626452

Epoch: 6| Step: 3
Training loss: 2.2929203510284424
Validation loss: 1.9888289461853683

Epoch: 6| Step: 4
Training loss: 2.637812614440918
Validation loss: 1.9964781602223713

Epoch: 6| Step: 5
Training loss: 2.5249946117401123
Validation loss: 2.0030638223053305

Epoch: 6| Step: 6
Training loss: 1.7299202680587769
Validation loss: 2.027120961937853

Epoch: 6| Step: 7
Training loss: 1.8254179954528809
Validation loss: 1.9895896014346872

Epoch: 6| Step: 8
Training loss: 2.6511173248291016
Validation loss: 1.9852574717613958

Epoch: 6| Step: 9
Training loss: 2.4277095794677734
Validation loss: 2.0075556026991976

Epoch: 6| Step: 10
Training loss: 2.087129592895508
Validation loss: 2.0097974795167164

Epoch: 6| Step: 11
Training loss: 1.593796968460083
Validation loss: 2.0059506277884207

Epoch: 6| Step: 12
Training loss: 2.185368299484253
Validation loss: 2.0009224427643644

Epoch: 6| Step: 13
Training loss: 1.671257495880127
Validation loss: 1.9969227570359425

Epoch: 115| Step: 0
Training loss: 1.947589635848999
Validation loss: 1.9970464937148555

Epoch: 6| Step: 1
Training loss: 2.171844959259033
Validation loss: 2.0204051630471342

Epoch: 6| Step: 2
Training loss: 1.6487531661987305
Validation loss: 2.0049240473778016

Epoch: 6| Step: 3
Training loss: 2.2033612728118896
Validation loss: 2.0118938082007953

Epoch: 6| Step: 4
Training loss: 2.3093483448028564
Validation loss: 2.017369585652505

Epoch: 6| Step: 5
Training loss: 1.7866395711898804
Validation loss: 2.0042588813330537

Epoch: 6| Step: 6
Training loss: 1.7702001333236694
Validation loss: 2.0058355357057307

Epoch: 6| Step: 7
Training loss: 1.9230542182922363
Validation loss: 2.036901838035994

Epoch: 6| Step: 8
Training loss: 2.773824691772461
Validation loss: 2.0412040372048654

Epoch: 6| Step: 9
Training loss: 2.086270809173584
Validation loss: 2.035254249008753

Epoch: 6| Step: 10
Training loss: 2.331632137298584
Validation loss: 2.0328633554520144

Epoch: 6| Step: 11
Training loss: 2.919928789138794
Validation loss: 2.0569963403927383

Epoch: 6| Step: 12
Training loss: 1.463329792022705
Validation loss: 2.0408318196573565

Epoch: 6| Step: 13
Training loss: 2.1184630393981934
Validation loss: 2.0459903517077045

Epoch: 116| Step: 0
Training loss: 2.0844616889953613
Validation loss: 2.0451488494873047

Epoch: 6| Step: 1
Training loss: 0.9289616346359253
Validation loss: 2.032086564648536

Epoch: 6| Step: 2
Training loss: 2.088762044906616
Validation loss: 2.0513721845483266

Epoch: 6| Step: 3
Training loss: 2.3512439727783203
Validation loss: 2.0498165545925016

Epoch: 6| Step: 4
Training loss: 2.2035343647003174
Validation loss: 2.011495937583267

Epoch: 6| Step: 5
Training loss: 2.509730339050293
Validation loss: 2.0101440414305656

Epoch: 6| Step: 6
Training loss: 2.488466262817383
Validation loss: 2.0025922739377586

Epoch: 6| Step: 7
Training loss: 1.7965848445892334
Validation loss: 2.0339196382030362

Epoch: 6| Step: 8
Training loss: 2.127241849899292
Validation loss: 2.0028976676284627

Epoch: 6| Step: 9
Training loss: 2.374696969985962
Validation loss: 2.027777479540917

Epoch: 6| Step: 10
Training loss: 1.9248011112213135
Validation loss: 2.016500452513336

Epoch: 6| Step: 11
Training loss: 1.907921552658081
Validation loss: 2.019783007201328

Epoch: 6| Step: 12
Training loss: 2.402184247970581
Validation loss: 2.017936989825259

Epoch: 6| Step: 13
Training loss: 2.0104119777679443
Validation loss: 2.0231326164737826

Epoch: 117| Step: 0
Training loss: 1.5939035415649414
Validation loss: 2.0352343231119137

Epoch: 6| Step: 1
Training loss: 1.321883201599121
Validation loss: 2.0041136562183337

Epoch: 6| Step: 2
Training loss: 2.767986297607422
Validation loss: 2.000892754523985

Epoch: 6| Step: 3
Training loss: 2.323197364807129
Validation loss: 2.0314776359065885

Epoch: 6| Step: 4
Training loss: 2.0621275901794434
Validation loss: 2.021236732441892

Epoch: 6| Step: 5
Training loss: 2.174762725830078
Validation loss: 2.0394206252149356

Epoch: 6| Step: 6
Training loss: 2.2821197509765625
Validation loss: 2.0408517429905553

Epoch: 6| Step: 7
Training loss: 1.9538016319274902
Validation loss: 2.062687917422223

Epoch: 6| Step: 8
Training loss: 1.4378042221069336
Validation loss: 2.02786684548983

Epoch: 6| Step: 9
Training loss: 2.9972376823425293
Validation loss: 2.020079082058322

Epoch: 6| Step: 10
Training loss: 1.618130087852478
Validation loss: 2.0340772572384087

Epoch: 6| Step: 11
Training loss: 2.228477954864502
Validation loss: 2.030819308373236

Epoch: 6| Step: 12
Training loss: 2.7191805839538574
Validation loss: 2.0429116295230005

Epoch: 6| Step: 13
Training loss: 1.5848982334136963
Validation loss: 2.0373506007655973

Epoch: 118| Step: 0
Training loss: 1.9906654357910156
Validation loss: 2.029900389332925

Epoch: 6| Step: 1
Training loss: 2.076704978942871
Validation loss: 2.0326575950909684

Epoch: 6| Step: 2
Training loss: 1.780221700668335
Validation loss: 2.010606622183195

Epoch: 6| Step: 3
Training loss: 1.6929833889007568
Validation loss: 2.012802500878611

Epoch: 6| Step: 4
Training loss: 2.4810702800750732
Validation loss: 2.0279678119126188

Epoch: 6| Step: 5
Training loss: 2.3402485847473145
Validation loss: 2.017170759939378

Epoch: 6| Step: 6
Training loss: 2.471585750579834
Validation loss: 2.014904788745347

Epoch: 6| Step: 7
Training loss: 2.55484676361084
Validation loss: 1.9820732352554158

Epoch: 6| Step: 8
Training loss: 2.1917500495910645
Validation loss: 1.9993741871208273

Epoch: 6| Step: 9
Training loss: 1.9176071882247925
Validation loss: 1.9960120493365872

Epoch: 6| Step: 10
Training loss: 1.2887330055236816
Validation loss: 1.9979773849569342

Epoch: 6| Step: 11
Training loss: 2.184311866760254
Validation loss: 2.0061091133343276

Epoch: 6| Step: 12
Training loss: 2.2879598140716553
Validation loss: 2.005131272859471

Epoch: 6| Step: 13
Training loss: 2.010014533996582
Validation loss: 1.9860948747204197

Epoch: 119| Step: 0
Training loss: 1.6816270351409912
Validation loss: 1.996172558876776

Epoch: 6| Step: 1
Training loss: 2.1967530250549316
Validation loss: 2.0251708235791934

Epoch: 6| Step: 2
Training loss: 2.94663143157959
Validation loss: 2.011929440241988

Epoch: 6| Step: 3
Training loss: 1.9991272687911987
Validation loss: 2.0093258221944175

Epoch: 6| Step: 4
Training loss: 2.122788906097412
Validation loss: 2.0021710139448925

Epoch: 6| Step: 5
Training loss: 1.9361814260482788
Validation loss: 2.003543649950335

Epoch: 6| Step: 6
Training loss: 2.0108251571655273
Validation loss: 2.006615813060473

Epoch: 6| Step: 7
Training loss: 2.077977180480957
Validation loss: 2.0017720986438055

Epoch: 6| Step: 8
Training loss: 1.4914064407348633
Validation loss: 2.0037374240095898

Epoch: 6| Step: 9
Training loss: 2.344957113265991
Validation loss: 2.0096137075014013

Epoch: 6| Step: 10
Training loss: 2.26694393157959
Validation loss: 2.02498568642524

Epoch: 6| Step: 11
Training loss: 1.891703724861145
Validation loss: 2.0081837702822942

Epoch: 6| Step: 12
Training loss: 2.296630382537842
Validation loss: 2.010069575361026

Epoch: 6| Step: 13
Training loss: 1.709981918334961
Validation loss: 2.019649523560719

Epoch: 120| Step: 0
Training loss: 2.270264148712158
Validation loss: 2.0050867603671167

Epoch: 6| Step: 1
Training loss: 2.3762173652648926
Validation loss: 2.036011281833854

Epoch: 6| Step: 2
Training loss: 2.632567882537842
Validation loss: 2.030317726955619

Epoch: 6| Step: 3
Training loss: 2.3973162174224854
Validation loss: 2.0235148424743326

Epoch: 6| Step: 4
Training loss: 1.5638149976730347
Validation loss: 2.0260941982269287

Epoch: 6| Step: 5
Training loss: 2.216330051422119
Validation loss: 2.0464120218830724

Epoch: 6| Step: 6
Training loss: 2.6495580673217773
Validation loss: 2.031461597770773

Epoch: 6| Step: 7
Training loss: 1.6926438808441162
Validation loss: 2.008139423144761

Epoch: 6| Step: 8
Training loss: 1.9699338674545288
Validation loss: 2.030496261453116

Epoch: 6| Step: 9
Training loss: 1.8569203615188599
Validation loss: 2.05365171740132

Epoch: 6| Step: 10
Training loss: 2.2914276123046875
Validation loss: 2.044124722480774

Epoch: 6| Step: 11
Training loss: 2.0376830101013184
Validation loss: 2.0205824323879775

Epoch: 6| Step: 12
Training loss: 1.5946669578552246
Validation loss: 2.0468175052314677

Epoch: 6| Step: 13
Training loss: 1.37454354763031
Validation loss: 2.0145965417226157

Epoch: 121| Step: 0
Training loss: 2.003391742706299
Validation loss: 2.05630842075553

Epoch: 6| Step: 1
Training loss: 2.2877092361450195
Validation loss: 2.033443009981545

Epoch: 6| Step: 2
Training loss: 2.177884578704834
Validation loss: 2.015526208826291

Epoch: 6| Step: 3
Training loss: 1.76847505569458
Validation loss: 2.022242687081778

Epoch: 6| Step: 4
Training loss: 1.8981847763061523
Validation loss: 2.0189170440038047

Epoch: 6| Step: 5
Training loss: 2.4880266189575195
Validation loss: 2.0115297455941477

Epoch: 6| Step: 6
Training loss: 1.9063775539398193
Validation loss: 2.0388815505530244

Epoch: 6| Step: 7
Training loss: 2.6910667419433594
Validation loss: 2.004218118165129

Epoch: 6| Step: 8
Training loss: 1.833647608757019
Validation loss: 2.015282159210533

Epoch: 6| Step: 9
Training loss: 1.7912864685058594
Validation loss: 2.0235714720141504

Epoch: 6| Step: 10
Training loss: 2.419011116027832
Validation loss: 2.0036174507551294

Epoch: 6| Step: 11
Training loss: 2.373317003250122
Validation loss: 2.0140610330848285

Epoch: 6| Step: 12
Training loss: 1.5038435459136963
Validation loss: 2.0175579504300187

Epoch: 6| Step: 13
Training loss: 2.1135828495025635
Validation loss: 2.0124972020426104

Epoch: 122| Step: 0
Training loss: 2.9441211223602295
Validation loss: 2.0110116030580256

Epoch: 6| Step: 1
Training loss: 1.7787014245986938
Validation loss: 2.012805420865295

Epoch: 6| Step: 2
Training loss: 1.509199857711792
Validation loss: 2.0248122189634588

Epoch: 6| Step: 3
Training loss: 1.6487374305725098
Validation loss: 2.0174981035212034

Epoch: 6| Step: 4
Training loss: 1.732113242149353
Validation loss: 2.02114357999576

Epoch: 6| Step: 5
Training loss: 2.4952616691589355
Validation loss: 2.016995136455823

Epoch: 6| Step: 6
Training loss: 1.69866144657135
Validation loss: 2.019359516841109

Epoch: 6| Step: 7
Training loss: 1.596567988395691
Validation loss: 2.028001775023758

Epoch: 6| Step: 8
Training loss: 2.7539069652557373
Validation loss: 2.0276730598941928

Epoch: 6| Step: 9
Training loss: 2.029815435409546
Validation loss: 2.0427833628910843

Epoch: 6| Step: 10
Training loss: 2.007373809814453
Validation loss: 1.9972896370836484

Epoch: 6| Step: 11
Training loss: 2.38432240486145
Validation loss: 1.9920272904057656

Epoch: 6| Step: 12
Training loss: 2.1415205001831055
Validation loss: 2.02828634682522

Epoch: 6| Step: 13
Training loss: 2.4571332931518555
Validation loss: 2.0061570098323207

Epoch: 123| Step: 0
Training loss: 2.8481926918029785
Validation loss: 2.0251891049005653

Epoch: 6| Step: 1
Training loss: 1.4705770015716553
Validation loss: 2.0026960424197617

Epoch: 6| Step: 2
Training loss: 2.3537535667419434
Validation loss: 2.0019658457848335

Epoch: 6| Step: 3
Training loss: 2.9660587310791016
Validation loss: 1.9969102259605163

Epoch: 6| Step: 4
Training loss: 2.044273853302002
Validation loss: 2.013152321179708

Epoch: 6| Step: 5
Training loss: 2.2569925785064697
Validation loss: 2.0170549154281616

Epoch: 6| Step: 6
Training loss: 1.6677947044372559
Validation loss: 2.0421739316755727

Epoch: 6| Step: 7
Training loss: 2.536949634552002
Validation loss: 2.0107128850875364

Epoch: 6| Step: 8
Training loss: 1.5508146286010742
Validation loss: 2.0055106250188683

Epoch: 6| Step: 9
Training loss: 1.5942811965942383
Validation loss: 2.02138098337317

Epoch: 6| Step: 10
Training loss: 1.8895364999771118
Validation loss: 2.029143075789175

Epoch: 6| Step: 11
Training loss: 1.7883577346801758
Validation loss: 2.012700742290866

Epoch: 6| Step: 12
Training loss: 2.088010787963867
Validation loss: 2.038896891378587

Epoch: 6| Step: 13
Training loss: 2.2076377868652344
Validation loss: 2.0130788305754304

Epoch: 124| Step: 0
Training loss: 1.5436360836029053
Validation loss: 2.0153997328973587

Epoch: 6| Step: 1
Training loss: 1.8753867149353027
Validation loss: 2.020351085611569

Epoch: 6| Step: 2
Training loss: 2.443544864654541
Validation loss: 2.012155189309069

Epoch: 6| Step: 3
Training loss: 2.6022963523864746
Validation loss: 2.0443045669986355

Epoch: 6| Step: 4
Training loss: 2.502405881881714
Validation loss: 2.021829492302351

Epoch: 6| Step: 5
Training loss: 1.8976863622665405
Validation loss: 2.045888436737881

Epoch: 6| Step: 6
Training loss: 2.569624423980713
Validation loss: 2.0421235907462334

Epoch: 6| Step: 7
Training loss: 1.545046091079712
Validation loss: 2.0386170700032222

Epoch: 6| Step: 8
Training loss: 1.8851439952850342
Validation loss: 2.00180955343349

Epoch: 6| Step: 9
Training loss: 2.171945571899414
Validation loss: 2.026729924704439

Epoch: 6| Step: 10
Training loss: 1.2543647289276123
Validation loss: 2.0330867318696875

Epoch: 6| Step: 11
Training loss: 2.820768356323242
Validation loss: 2.023164972182243

Epoch: 6| Step: 12
Training loss: 2.29356050491333
Validation loss: 2.031337530382218

Epoch: 6| Step: 13
Training loss: 1.6581919193267822
Validation loss: 2.02800936852732

Epoch: 125| Step: 0
Training loss: 2.728080987930298
Validation loss: 2.013256340898493

Epoch: 6| Step: 1
Training loss: 1.9047694206237793
Validation loss: 2.0244919664116314

Epoch: 6| Step: 2
Training loss: 2.0993151664733887
Validation loss: 2.032480469314001

Epoch: 6| Step: 3
Training loss: 1.7659673690795898
Validation loss: 2.0090583203941264

Epoch: 6| Step: 4
Training loss: 1.6950525045394897
Validation loss: 2.024843087760351

Epoch: 6| Step: 5
Training loss: 1.8720917701721191
Validation loss: 2.024630482478808

Epoch: 6| Step: 6
Training loss: 2.486086845397949
Validation loss: 2.0177592154472106

Epoch: 6| Step: 7
Training loss: 2.0754709243774414
Validation loss: 2.012020023920203

Epoch: 6| Step: 8
Training loss: 2.496100425720215
Validation loss: 2.032767706019904

Epoch: 6| Step: 9
Training loss: 2.4198808670043945
Validation loss: 2.0321979830341954

Epoch: 6| Step: 10
Training loss: 2.098604917526245
Validation loss: 2.0197556531557472

Epoch: 6| Step: 11
Training loss: 1.8550639152526855
Validation loss: 2.0193978099412817

Epoch: 6| Step: 12
Training loss: 1.3942558765411377
Validation loss: 2.0126508922987085

Epoch: 6| Step: 13
Training loss: 2.4628348350524902
Validation loss: 1.9981643051229498

Epoch: 126| Step: 0
Training loss: 1.964678168296814
Validation loss: 2.0097951043036675

Epoch: 6| Step: 1
Training loss: 1.9225801229476929
Validation loss: 2.006044431399274

Epoch: 6| Step: 2
Training loss: 2.31545352935791
Validation loss: 1.992212689051064

Epoch: 6| Step: 3
Training loss: 1.7301125526428223
Validation loss: 1.997155185668699

Epoch: 6| Step: 4
Training loss: 2.2031984329223633
Validation loss: 2.002207686824183

Epoch: 6| Step: 5
Training loss: 1.9947768449783325
Validation loss: 2.011369976946103

Epoch: 6| Step: 6
Training loss: 2.655869483947754
Validation loss: 2.0011483418044222

Epoch: 6| Step: 7
Training loss: 2.23530912399292
Validation loss: 2.0265728401881393

Epoch: 6| Step: 8
Training loss: 2.6005096435546875
Validation loss: 2.0077819516581874

Epoch: 6| Step: 9
Training loss: 2.3487987518310547
Validation loss: 2.003679726713447

Epoch: 6| Step: 10
Training loss: 1.5975418090820312
Validation loss: 2.014378865559896

Epoch: 6| Step: 11
Training loss: 1.8089181184768677
Validation loss: 2.035536854497848

Epoch: 6| Step: 12
Training loss: 1.7387796640396118
Validation loss: 2.0106050609260477

Epoch: 6| Step: 13
Training loss: 1.9149829149246216
Validation loss: 2.0287363221568446

Epoch: 127| Step: 0
Training loss: 2.0955796241760254
Validation loss: 2.040878257443828

Epoch: 6| Step: 1
Training loss: 1.883819818496704
Validation loss: 2.018235204040363

Epoch: 6| Step: 2
Training loss: 1.8197133541107178
Validation loss: 2.0481125308621313

Epoch: 6| Step: 3
Training loss: 2.248349666595459
Validation loss: 2.049138387044271

Epoch: 6| Step: 4
Training loss: 2.0069072246551514
Validation loss: 2.0346445293836695

Epoch: 6| Step: 5
Training loss: 1.8891746997833252
Validation loss: 2.048974214061614

Epoch: 6| Step: 6
Training loss: 2.309591293334961
Validation loss: 2.0223839257353093

Epoch: 6| Step: 7
Training loss: 1.4345273971557617
Validation loss: 2.033336688113469

Epoch: 6| Step: 8
Training loss: 2.540694236755371
Validation loss: 2.020819297400854

Epoch: 6| Step: 9
Training loss: 1.5663976669311523
Validation loss: 2.0508913737471386

Epoch: 6| Step: 10
Training loss: 2.7272183895111084
Validation loss: 2.038184645355389

Epoch: 6| Step: 11
Training loss: 2.179224729537964
Validation loss: 2.00984352378435

Epoch: 6| Step: 12
Training loss: 2.129154920578003
Validation loss: 2.016778507540303

Epoch: 6| Step: 13
Training loss: 2.3227574825286865
Validation loss: 2.020040342884679

Epoch: 128| Step: 0
Training loss: 2.4007203578948975
Validation loss: 2.029714740732665

Epoch: 6| Step: 1
Training loss: 2.353726387023926
Validation loss: 2.02660810050144

Epoch: 6| Step: 2
Training loss: 2.4164257049560547
Validation loss: 2.032296722935092

Epoch: 6| Step: 3
Training loss: 1.8660293817520142
Validation loss: 2.0531497193920996

Epoch: 6| Step: 4
Training loss: 1.9649066925048828
Validation loss: 2.04405237526022

Epoch: 6| Step: 5
Training loss: 1.9795228242874146
Validation loss: 2.0381703966407367

Epoch: 6| Step: 6
Training loss: 1.8941223621368408
Validation loss: 2.0429595029482277

Epoch: 6| Step: 7
Training loss: 2.1100428104400635
Validation loss: 2.0613333922560497

Epoch: 6| Step: 8
Training loss: 2.3502113819122314
Validation loss: 2.0538194282080537

Epoch: 6| Step: 9
Training loss: 1.3782157897949219
Validation loss: 2.0703726789002777

Epoch: 6| Step: 10
Training loss: 1.5392885208129883
Validation loss: 2.0358942606115855

Epoch: 6| Step: 11
Training loss: 2.233323335647583
Validation loss: 2.0293885943710164

Epoch: 6| Step: 12
Training loss: 2.297529697418213
Validation loss: 2.0573054064986525

Epoch: 6| Step: 13
Training loss: 2.0698130130767822
Validation loss: 2.0457629414014917

Epoch: 129| Step: 0
Training loss: 2.464980363845825
Validation loss: 2.03878281962487

Epoch: 6| Step: 1
Training loss: 1.7944949865341187
Validation loss: 2.038118439335977

Epoch: 6| Step: 2
Training loss: 1.8508193492889404
Validation loss: 1.995859206363719

Epoch: 6| Step: 3
Training loss: 2.3093791007995605
Validation loss: 2.0237345400676934

Epoch: 6| Step: 4
Training loss: 1.7722495794296265
Validation loss: 2.007324536641439

Epoch: 6| Step: 5
Training loss: 2.6893296241760254
Validation loss: 2.022388965852799

Epoch: 6| Step: 6
Training loss: 1.9179655313491821
Validation loss: 2.0032587794847387

Epoch: 6| Step: 7
Training loss: 2.2861061096191406
Validation loss: 1.99641542537238

Epoch: 6| Step: 8
Training loss: 2.260376453399658
Validation loss: 1.9971625907446748

Epoch: 6| Step: 9
Training loss: 2.1177077293395996
Validation loss: 2.0033435808715

Epoch: 6| Step: 10
Training loss: 2.428314685821533
Validation loss: 1.9971125959068217

Epoch: 6| Step: 11
Training loss: 1.7525595426559448
Validation loss: 1.9879835177493352

Epoch: 6| Step: 12
Training loss: 1.494406819343567
Validation loss: 1.9938646388310257

Epoch: 6| Step: 13
Training loss: 2.3677568435668945
Validation loss: 2.0061763563463764

Epoch: 130| Step: 0
Training loss: 1.9560879468917847
Validation loss: 2.001836330659928

Epoch: 6| Step: 1
Training loss: 2.2930078506469727
Validation loss: 1.9978018601735432

Epoch: 6| Step: 2
Training loss: 1.5396333932876587
Validation loss: 2.0173181538940756

Epoch: 6| Step: 3
Training loss: 1.7699978351593018
Validation loss: 2.001715724186231

Epoch: 6| Step: 4
Training loss: 2.280349016189575
Validation loss: 2.0367431332988124

Epoch: 6| Step: 5
Training loss: 2.3271303176879883
Validation loss: 2.025381022884

Epoch: 6| Step: 6
Training loss: 2.045792818069458
Validation loss: 2.028006387013261

Epoch: 6| Step: 7
Training loss: 2.4782752990722656
Validation loss: 2.008051815853324

Epoch: 6| Step: 8
Training loss: 1.7956936359405518
Validation loss: 2.022842755881689

Epoch: 6| Step: 9
Training loss: 2.063100814819336
Validation loss: 2.0179520473685315

Epoch: 6| Step: 10
Training loss: 2.3150858879089355
Validation loss: 2.049251546141922

Epoch: 6| Step: 11
Training loss: 2.359360694885254
Validation loss: 2.0577869415283203

Epoch: 6| Step: 12
Training loss: 1.966649055480957
Validation loss: 2.0627850717113865

Epoch: 6| Step: 13
Training loss: 1.6302320957183838
Validation loss: 2.029682177369313

Epoch: 131| Step: 0
Training loss: 2.1744489669799805
Validation loss: 2.0684376814032115

Epoch: 6| Step: 1
Training loss: 2.4123682975769043
Validation loss: 2.0322258869806924

Epoch: 6| Step: 2
Training loss: 2.472444534301758
Validation loss: 2.0418261763870076

Epoch: 6| Step: 3
Training loss: 1.9711387157440186
Validation loss: 2.0631426739436325

Epoch: 6| Step: 4
Training loss: 2.0266950130462646
Validation loss: 2.0393781828623947

Epoch: 6| Step: 5
Training loss: 1.6088638305664062
Validation loss: 2.0365989567131124

Epoch: 6| Step: 6
Training loss: 1.9693982601165771
Validation loss: 2.0276796689597507

Epoch: 6| Step: 7
Training loss: 1.5451679229736328
Validation loss: 2.055354413165841

Epoch: 6| Step: 8
Training loss: 1.8496180772781372
Validation loss: 2.032482906054425

Epoch: 6| Step: 9
Training loss: 2.833533525466919
Validation loss: 2.039986897540349

Epoch: 6| Step: 10
Training loss: 2.103891611099243
Validation loss: 2.058646725070092

Epoch: 6| Step: 11
Training loss: 1.672581434249878
Validation loss: 2.031802681184584

Epoch: 6| Step: 12
Training loss: 2.3145859241485596
Validation loss: 2.0368832042140346

Epoch: 6| Step: 13
Training loss: 1.78806471824646
Validation loss: 2.027042519661688

Epoch: 132| Step: 0
Training loss: 2.567302703857422
Validation loss: 2.0413514824323755

Epoch: 6| Step: 1
Training loss: 2.242297410964966
Validation loss: 2.0126695299661286

Epoch: 6| Step: 2
Training loss: 2.0746514797210693
Validation loss: 2.0242703922333254

Epoch: 6| Step: 3
Training loss: 1.874383807182312
Validation loss: 2.0102133468915055

Epoch: 6| Step: 4
Training loss: 1.9747800827026367
Validation loss: 2.0193193266468663

Epoch: 6| Step: 5
Training loss: 1.9387691020965576
Validation loss: 2.036824180233863

Epoch: 6| Step: 6
Training loss: 2.411184549331665
Validation loss: 2.061887236051662

Epoch: 6| Step: 7
Training loss: 2.2448835372924805
Validation loss: 2.0369353602009435

Epoch: 6| Step: 8
Training loss: 1.845529556274414
Validation loss: 2.0174722004962224

Epoch: 6| Step: 9
Training loss: 2.5576975345611572
Validation loss: 2.04560544413905

Epoch: 6| Step: 10
Training loss: 1.6452957391738892
Validation loss: 2.0205082021733767

Epoch: 6| Step: 11
Training loss: 1.6390612125396729
Validation loss: 2.03439325158314

Epoch: 6| Step: 12
Training loss: 1.5274627208709717
Validation loss: 2.042583842431345

Epoch: 6| Step: 13
Training loss: 2.2436349391937256
Validation loss: 2.0235384023317726

Epoch: 133| Step: 0
Training loss: 1.961669683456421
Validation loss: 2.0151952466657086

Epoch: 6| Step: 1
Training loss: 1.3035190105438232
Validation loss: 2.026901360481016

Epoch: 6| Step: 2
Training loss: 1.9725978374481201
Validation loss: 2.028917279294742

Epoch: 6| Step: 3
Training loss: 2.3859004974365234
Validation loss: 1.9942231268011115

Epoch: 6| Step: 4
Training loss: 1.8064234256744385
Validation loss: 2.0068589384837816

Epoch: 6| Step: 5
Training loss: 2.206035614013672
Validation loss: 2.018249870628439

Epoch: 6| Step: 6
Training loss: 2.5557780265808105
Validation loss: 2.0208812388040687

Epoch: 6| Step: 7
Training loss: 2.5027589797973633
Validation loss: 2.01277087068045

Epoch: 6| Step: 8
Training loss: 2.0649683475494385
Validation loss: 1.994608267661064

Epoch: 6| Step: 9
Training loss: 1.9989051818847656
Validation loss: 1.9947616925803564

Epoch: 6| Step: 10
Training loss: 1.6861462593078613
Validation loss: 2.011380753209514

Epoch: 6| Step: 11
Training loss: 2.2600326538085938
Validation loss: 2.0096922356595277

Epoch: 6| Step: 12
Training loss: 1.974743366241455
Validation loss: 2.0543081760406494

Epoch: 6| Step: 13
Training loss: 2.382817029953003
Validation loss: 2.02954218592695

Epoch: 134| Step: 0
Training loss: 2.4791789054870605
Validation loss: 1.9948984243536507

Epoch: 6| Step: 1
Training loss: 1.6008845567703247
Validation loss: 2.0051433937523955

Epoch: 6| Step: 2
Training loss: 2.5662379264831543
Validation loss: 2.044584922893073

Epoch: 6| Step: 3
Training loss: 1.4833464622497559
Validation loss: 2.0273465879501833

Epoch: 6| Step: 4
Training loss: 2.295471668243408
Validation loss: 2.0361300668408795

Epoch: 6| Step: 5
Training loss: 2.1189613342285156
Validation loss: 2.0481774512157647

Epoch: 6| Step: 6
Training loss: 1.8522130250930786
Validation loss: 2.052633423959055

Epoch: 6| Step: 7
Training loss: 2.5094051361083984
Validation loss: 2.059934687870805

Epoch: 6| Step: 8
Training loss: 2.0268664360046387
Validation loss: 2.0669388258329002

Epoch: 6| Step: 9
Training loss: 1.8160241842269897
Validation loss: 2.0433375168872137

Epoch: 6| Step: 10
Training loss: 1.9040350914001465
Validation loss: 2.0527413468207083

Epoch: 6| Step: 11
Training loss: 2.240774631500244
Validation loss: 2.0628974283895185

Epoch: 6| Step: 12
Training loss: 1.799453854560852
Validation loss: 2.066098023486394

Epoch: 6| Step: 13
Training loss: 2.5424013137817383
Validation loss: 2.053899106159005

Epoch: 135| Step: 0
Training loss: 2.4540042877197266
Validation loss: 2.0529600792033698

Epoch: 6| Step: 1
Training loss: 1.6720564365386963
Validation loss: 2.046528248376744

Epoch: 6| Step: 2
Training loss: 2.331294059753418
Validation loss: 2.0423405939532864

Epoch: 6| Step: 3
Training loss: 1.3304858207702637
Validation loss: 2.051533781072145

Epoch: 6| Step: 4
Training loss: 1.7500190734863281
Validation loss: 2.0450657439488236

Epoch: 6| Step: 5
Training loss: 1.9316935539245605
Validation loss: 2.0458687672051052

Epoch: 6| Step: 6
Training loss: 2.6056082248687744
Validation loss: 2.0797137547564764

Epoch: 6| Step: 7
Training loss: 1.5760949850082397
Validation loss: 2.0393813284494544

Epoch: 6| Step: 8
Training loss: 2.199159622192383
Validation loss: 2.049296675189849

Epoch: 6| Step: 9
Training loss: 2.314176559448242
Validation loss: 2.0505229401332077

Epoch: 6| Step: 10
Training loss: 2.3905622959136963
Validation loss: 2.0312527405318392

Epoch: 6| Step: 11
Training loss: 1.992598533630371
Validation loss: 2.0563853517655404

Epoch: 6| Step: 12
Training loss: 2.1044745445251465
Validation loss: 2.0303021502751175

Epoch: 6| Step: 13
Training loss: 2.129305839538574
Validation loss: 2.0390612463797293

Epoch: 136| Step: 0
Training loss: 2.013963222503662
Validation loss: 2.054804704522574

Epoch: 6| Step: 1
Training loss: 2.2767300605773926
Validation loss: 2.0540334768192743

Epoch: 6| Step: 2
Training loss: 1.983500361442566
Validation loss: 2.0610232814665763

Epoch: 6| Step: 3
Training loss: 2.605719566345215
Validation loss: 2.0332462082627

Epoch: 6| Step: 4
Training loss: 2.2750468254089355
Validation loss: 2.047435245206279

Epoch: 6| Step: 5
Training loss: 1.7895406484603882
Validation loss: 2.033880381173985

Epoch: 6| Step: 6
Training loss: 1.8787707090377808
Validation loss: 2.0418669126367055

Epoch: 6| Step: 7
Training loss: 1.9816737174987793
Validation loss: 2.0365562131327968

Epoch: 6| Step: 8
Training loss: 2.0467796325683594
Validation loss: 2.0246297210775395

Epoch: 6| Step: 9
Training loss: 1.7905261516571045
Validation loss: 2.0454180086812666

Epoch: 6| Step: 10
Training loss: 2.289544105529785
Validation loss: 2.026715611898771

Epoch: 6| Step: 11
Training loss: 2.3676323890686035
Validation loss: 2.0215650860981276

Epoch: 6| Step: 12
Training loss: 1.546459674835205
Validation loss: 2.039000421442011

Epoch: 6| Step: 13
Training loss: 1.881857991218567
Validation loss: 2.042608323917594

Epoch: 137| Step: 0
Training loss: 1.802198886871338
Validation loss: 2.0249175025570776

Epoch: 6| Step: 1
Training loss: 1.4980156421661377
Validation loss: 2.0677305985522527

Epoch: 6| Step: 2
Training loss: 1.9753880500793457
Validation loss: 2.0703623499921573

Epoch: 6| Step: 3
Training loss: 1.6520936489105225
Validation loss: 2.0432702931024695

Epoch: 6| Step: 4
Training loss: 2.052751302719116
Validation loss: 2.0447985408126668

Epoch: 6| Step: 5
Training loss: 2.28159236907959
Validation loss: 2.060206154341339

Epoch: 6| Step: 6
Training loss: 2.4242441654205322
Validation loss: 2.025874650606545

Epoch: 6| Step: 7
Training loss: 2.3207030296325684
Validation loss: 2.042037945921703

Epoch: 6| Step: 8
Training loss: 2.091917037963867
Validation loss: 2.0335184579254477

Epoch: 6| Step: 9
Training loss: 1.856679916381836
Validation loss: 2.0435864886929913

Epoch: 6| Step: 10
Training loss: 2.386587381362915
Validation loss: 2.0268840315521404

Epoch: 6| Step: 11
Training loss: 1.8231091499328613
Validation loss: 2.041140853717763

Epoch: 6| Step: 12
Training loss: 2.4519128799438477
Validation loss: 2.033843313494036

Epoch: 6| Step: 13
Training loss: 1.9539151191711426
Validation loss: 2.0403657869626115

Epoch: 138| Step: 0
Training loss: 1.628081202507019
Validation loss: 2.0505413701457362

Epoch: 6| Step: 1
Training loss: 2.7010488510131836
Validation loss: 2.0254466687479327

Epoch: 6| Step: 2
Training loss: 2.289199113845825
Validation loss: 2.042353742866106

Epoch: 6| Step: 3
Training loss: 2.5419373512268066
Validation loss: 2.017220443294894

Epoch: 6| Step: 4
Training loss: 1.7683262825012207
Validation loss: 2.0267986994917675

Epoch: 6| Step: 5
Training loss: 1.176146149635315
Validation loss: 2.0220151050116426

Epoch: 6| Step: 6
Training loss: 2.038119316101074
Validation loss: 2.0180897815253145

Epoch: 6| Step: 7
Training loss: 2.08186936378479
Validation loss: 2.0297601274264756

Epoch: 6| Step: 8
Training loss: 1.8767690658569336
Validation loss: 2.031237071560275

Epoch: 6| Step: 9
Training loss: 2.235325813293457
Validation loss: 2.024558300613075

Epoch: 6| Step: 10
Training loss: 2.652514696121216
Validation loss: 2.00393097887757

Epoch: 6| Step: 11
Training loss: 1.658193588256836
Validation loss: 2.046072147225821

Epoch: 6| Step: 12
Training loss: 1.527916669845581
Validation loss: 2.0338805567833687

Epoch: 6| Step: 13
Training loss: 2.465160369873047
Validation loss: 2.013230335327887

Epoch: 139| Step: 0
Training loss: 2.535090208053589
Validation loss: 2.0118307695593884

Epoch: 6| Step: 1
Training loss: 2.145451545715332
Validation loss: 2.031899462464035

Epoch: 6| Step: 2
Training loss: 1.6865854263305664
Validation loss: 2.0144156717484996

Epoch: 6| Step: 3
Training loss: 2.3669393062591553
Validation loss: 2.021222451681732

Epoch: 6| Step: 4
Training loss: 1.5894945859909058
Validation loss: 2.038122873152456

Epoch: 6| Step: 5
Training loss: 2.0217137336730957
Validation loss: 2.0092454328331897

Epoch: 6| Step: 6
Training loss: 2.1333603858947754
Validation loss: 2.014765147239931

Epoch: 6| Step: 7
Training loss: 1.904402256011963
Validation loss: 2.014570710479572

Epoch: 6| Step: 8
Training loss: 2.2052464485168457
Validation loss: 2.0323731040441864

Epoch: 6| Step: 9
Training loss: 1.3383132219314575
Validation loss: 2.017769626391831

Epoch: 6| Step: 10
Training loss: 2.4816184043884277
Validation loss: 2.023450461767053

Epoch: 6| Step: 11
Training loss: 2.0960140228271484
Validation loss: 2.0258043107166084

Epoch: 6| Step: 12
Training loss: 2.0861730575561523
Validation loss: 2.051145471552367

Epoch: 6| Step: 13
Training loss: 2.1702747344970703
Validation loss: 2.0476081986581125

Epoch: 140| Step: 0
Training loss: 2.4328184127807617
Validation loss: 2.062607124287595

Epoch: 6| Step: 1
Training loss: 2.322275161743164
Validation loss: 2.047760053347516

Epoch: 6| Step: 2
Training loss: 2.4319894313812256
Validation loss: 2.051552084184462

Epoch: 6| Step: 3
Training loss: 1.6714396476745605
Validation loss: 2.0531179879301336

Epoch: 6| Step: 4
Training loss: 1.2546696662902832
Validation loss: 2.042942217601243

Epoch: 6| Step: 5
Training loss: 1.572962760925293
Validation loss: 2.016888474905363

Epoch: 6| Step: 6
Training loss: 2.921443223953247
Validation loss: 2.0539461489646667

Epoch: 6| Step: 7
Training loss: 1.9790493249893188
Validation loss: 2.031936926226462

Epoch: 6| Step: 8
Training loss: 1.8710582256317139
Validation loss: 2.0139801066408873

Epoch: 6| Step: 9
Training loss: 2.198855400085449
Validation loss: 2.0390808095214186

Epoch: 6| Step: 10
Training loss: 2.5091233253479004
Validation loss: 2.051620626962313

Epoch: 6| Step: 11
Training loss: 1.7003037929534912
Validation loss: 2.05561480727247

Epoch: 6| Step: 12
Training loss: 1.7018764019012451
Validation loss: 2.0338921777663694

Epoch: 6| Step: 13
Training loss: 1.9755033254623413
Validation loss: 2.048880902669763

Epoch: 141| Step: 0
Training loss: 2.2432570457458496
Validation loss: 2.0400389932817027

Epoch: 6| Step: 1
Training loss: 1.9177498817443848
Validation loss: 2.0476633656409478

Epoch: 6| Step: 2
Training loss: 1.9936559200286865
Validation loss: 2.051846719557239

Epoch: 6| Step: 3
Training loss: 1.9980260133743286
Validation loss: 2.052626232947073

Epoch: 6| Step: 4
Training loss: 1.9706778526306152
Validation loss: 2.0487781647712953

Epoch: 6| Step: 5
Training loss: 2.2499427795410156
Validation loss: 2.0314744441739974

Epoch: 6| Step: 6
Training loss: 1.8042433261871338
Validation loss: 2.0475762838958413

Epoch: 6| Step: 7
Training loss: 1.807661771774292
Validation loss: 2.0556186527334233

Epoch: 6| Step: 8
Training loss: 2.030529022216797
Validation loss: 2.0459244174342

Epoch: 6| Step: 9
Training loss: 2.5309762954711914
Validation loss: 2.060242965657224

Epoch: 6| Step: 10
Training loss: 2.0055737495422363
Validation loss: 2.058411461050792

Epoch: 6| Step: 11
Training loss: 1.867842674255371
Validation loss: 2.060716559810023

Epoch: 6| Step: 12
Training loss: 1.9692816734313965
Validation loss: 2.062191117194391

Epoch: 6| Step: 13
Training loss: 2.326873779296875
Validation loss: 2.038758990585163

Epoch: 142| Step: 0
Training loss: 2.3040971755981445
Validation loss: 2.0426320055479645

Epoch: 6| Step: 1
Training loss: 1.5587234497070312
Validation loss: 2.0253631440542077

Epoch: 6| Step: 2
Training loss: 1.667739987373352
Validation loss: 2.03293627308261

Epoch: 6| Step: 3
Training loss: 2.3392364978790283
Validation loss: 2.05117033373925

Epoch: 6| Step: 4
Training loss: 1.8975027799606323
Validation loss: 2.0284727606722104

Epoch: 6| Step: 5
Training loss: 2.5176467895507812
Validation loss: 2.033399802382274

Epoch: 6| Step: 6
Training loss: 2.3853116035461426
Validation loss: 2.012491705597088

Epoch: 6| Step: 7
Training loss: 2.5713963508605957
Validation loss: 2.036104868817073

Epoch: 6| Step: 8
Training loss: 1.528796672821045
Validation loss: 2.0137567276595743

Epoch: 6| Step: 9
Training loss: 1.999563217163086
Validation loss: 2.0189390285040743

Epoch: 6| Step: 10
Training loss: 1.7913784980773926
Validation loss: 2.01340179674087

Epoch: 6| Step: 11
Training loss: 1.8675891160964966
Validation loss: 2.0245770203169955

Epoch: 6| Step: 12
Training loss: 2.0172390937805176
Validation loss: 2.0527458139645156

Epoch: 6| Step: 13
Training loss: 2.071582317352295
Validation loss: 2.027048049434539

Epoch: 143| Step: 0
Training loss: 2.185800075531006
Validation loss: 2.024735426390043

Epoch: 6| Step: 1
Training loss: 2.2352781295776367
Validation loss: 2.0558863891068326

Epoch: 6| Step: 2
Training loss: 1.3358277082443237
Validation loss: 2.022313033380816

Epoch: 6| Step: 3
Training loss: 1.5814945697784424
Validation loss: 2.0378848621922154

Epoch: 6| Step: 4
Training loss: 2.4683446884155273
Validation loss: 2.0498060603295603

Epoch: 6| Step: 5
Training loss: 2.2086870670318604
Validation loss: 2.016245038278641

Epoch: 6| Step: 6
Training loss: 1.7592861652374268
Validation loss: 2.044682505310223

Epoch: 6| Step: 7
Training loss: 2.310206890106201
Validation loss: 2.021469901966792

Epoch: 6| Step: 8
Training loss: 2.6275925636291504
Validation loss: 2.0185639999246083

Epoch: 6| Step: 9
Training loss: 1.8762309551239014
Validation loss: 2.035357153543862

Epoch: 6| Step: 10
Training loss: 2.2298614978790283
Validation loss: 2.0208004033693703

Epoch: 6| Step: 11
Training loss: 2.4164199829101562
Validation loss: 2.0371646599103044

Epoch: 6| Step: 12
Training loss: 1.6184649467468262
Validation loss: 2.014341961952948

Epoch: 6| Step: 13
Training loss: 1.6850134134292603
Validation loss: 2.0011585963669645

Epoch: 144| Step: 0
Training loss: 1.8398919105529785
Validation loss: 2.019082256542739

Epoch: 6| Step: 1
Training loss: 2.6456451416015625
Validation loss: 2.055038013765889

Epoch: 6| Step: 2
Training loss: 1.693828821182251
Validation loss: 2.0060069343095184

Epoch: 6| Step: 3
Training loss: 2.343109130859375
Validation loss: 2.0551101417951685

Epoch: 6| Step: 4
Training loss: 2.551849126815796
Validation loss: 2.039999613197901

Epoch: 6| Step: 5
Training loss: 1.7876417636871338
Validation loss: 2.043337757869433

Epoch: 6| Step: 6
Training loss: 1.7557387351989746
Validation loss: 2.0374219263753583

Epoch: 6| Step: 7
Training loss: 1.7287263870239258
Validation loss: 2.03101029703694

Epoch: 6| Step: 8
Training loss: 2.028759479522705
Validation loss: 2.024988111629281

Epoch: 6| Step: 9
Training loss: 1.6781911849975586
Validation loss: 2.0546237602028796

Epoch: 6| Step: 10
Training loss: 2.5332260131835938
Validation loss: 2.034948164416898

Epoch: 6| Step: 11
Training loss: 1.6817903518676758
Validation loss: 2.0292353988975607

Epoch: 6| Step: 12
Training loss: 2.0208945274353027
Validation loss: 2.0490907315284974

Epoch: 6| Step: 13
Training loss: 2.0817975997924805
Validation loss: 2.0259368932375343

Epoch: 145| Step: 0
Training loss: 1.8874821662902832
Validation loss: 2.0667166145898963

Epoch: 6| Step: 1
Training loss: 1.6268479824066162
Validation loss: 2.05938272963288

Epoch: 6| Step: 2
Training loss: 1.489434003829956
Validation loss: 2.04867999528044

Epoch: 6| Step: 3
Training loss: 1.3867568969726562
Validation loss: 2.0572487192769207

Epoch: 6| Step: 4
Training loss: 2.7530651092529297
Validation loss: 2.0419539431089997

Epoch: 6| Step: 5
Training loss: 2.841916561126709
Validation loss: 2.071610773763349

Epoch: 6| Step: 6
Training loss: 1.5205329656600952
Validation loss: 2.0621093203944545

Epoch: 6| Step: 7
Training loss: 2.6697921752929688
Validation loss: 2.053893535367904

Epoch: 6| Step: 8
Training loss: 2.451660394668579
Validation loss: 2.053173311295048

Epoch: 6| Step: 9
Training loss: 2.05224347114563
Validation loss: 2.0627765988790863

Epoch: 6| Step: 10
Training loss: 1.6043033599853516
Validation loss: 2.0445535695681007

Epoch: 6| Step: 11
Training loss: 2.4903054237365723
Validation loss: 2.0609293894101213

Epoch: 6| Step: 12
Training loss: 1.5788359642028809
Validation loss: 2.050457134041735

Epoch: 6| Step: 13
Training loss: 2.742727041244507
Validation loss: 2.048729968327348

Epoch: 146| Step: 0
Training loss: 2.1614019870758057
Validation loss: 2.051444306168505

Epoch: 6| Step: 1
Training loss: 2.094536781311035
Validation loss: 2.031876342270964

Epoch: 6| Step: 2
Training loss: 1.9652538299560547
Validation loss: 2.0478297279727076

Epoch: 6| Step: 3
Training loss: 2.163194179534912
Validation loss: 2.0485822616084928

Epoch: 6| Step: 4
Training loss: 2.1066606044769287
Validation loss: 2.043284302116722

Epoch: 6| Step: 5
Training loss: 2.6970887184143066
Validation loss: 2.0333160764427594

Epoch: 6| Step: 6
Training loss: 2.19526743888855
Validation loss: 2.043547789255778

Epoch: 6| Step: 7
Training loss: 1.8687388896942139
Validation loss: 2.0401261801360757

Epoch: 6| Step: 8
Training loss: 2.332642078399658
Validation loss: 2.042998226740027

Epoch: 6| Step: 9
Training loss: 1.2083868980407715
Validation loss: 2.05075736968748

Epoch: 6| Step: 10
Training loss: 2.293261766433716
Validation loss: 2.0483337666398738

Epoch: 6| Step: 11
Training loss: 1.6775200366973877
Validation loss: 2.0670576736491215

Epoch: 6| Step: 12
Training loss: 1.4704365730285645
Validation loss: 2.0316379044645574

Epoch: 6| Step: 13
Training loss: 2.53519344329834
Validation loss: 2.0359420840458204

Epoch: 147| Step: 0
Training loss: 1.9131981134414673
Validation loss: 2.015309954202303

Epoch: 6| Step: 1
Training loss: 2.1469523906707764
Validation loss: 2.0383892225962814

Epoch: 6| Step: 2
Training loss: 1.8005356788635254
Validation loss: 2.047132792011384

Epoch: 6| Step: 3
Training loss: 1.9500069618225098
Validation loss: 2.0401258366082304

Epoch: 6| Step: 4
Training loss: 2.1646671295166016
Validation loss: 2.050885405591739

Epoch: 6| Step: 5
Training loss: 2.20947003364563
Validation loss: 2.0462242377701627

Epoch: 6| Step: 6
Training loss: 1.6580183506011963
Validation loss: 2.033551441725864

Epoch: 6| Step: 7
Training loss: 2.4086661338806152
Validation loss: 2.054819796674995

Epoch: 6| Step: 8
Training loss: 2.0064451694488525
Validation loss: 2.044685653460923

Epoch: 6| Step: 9
Training loss: 2.192108631134033
Validation loss: 2.052809779362012

Epoch: 6| Step: 10
Training loss: 1.69746732711792
Validation loss: 2.0156479830382974

Epoch: 6| Step: 11
Training loss: 2.034834384918213
Validation loss: 2.039527254719888

Epoch: 6| Step: 12
Training loss: 2.605185031890869
Validation loss: 2.0448285738627114

Epoch: 6| Step: 13
Training loss: 1.2342768907546997
Validation loss: 2.0488159579615437

Epoch: 148| Step: 0
Training loss: 2.204556465148926
Validation loss: 2.0544396331233363

Epoch: 6| Step: 1
Training loss: 2.8885178565979004
Validation loss: 2.053226590156555

Epoch: 6| Step: 2
Training loss: 1.988770604133606
Validation loss: 2.0565928361749135

Epoch: 6| Step: 3
Training loss: 2.322648763656616
Validation loss: 2.0622506769754554

Epoch: 6| Step: 4
Training loss: 1.831209421157837
Validation loss: 2.0476017434109925

Epoch: 6| Step: 5
Training loss: 2.1297287940979004
Validation loss: 2.037934584002341

Epoch: 6| Step: 6
Training loss: 2.2441039085388184
Validation loss: 2.0567193031311035

Epoch: 6| Step: 7
Training loss: 1.4924253225326538
Validation loss: 2.0372866930500155

Epoch: 6| Step: 8
Training loss: 1.885266900062561
Validation loss: 2.033529104725007

Epoch: 6| Step: 9
Training loss: 1.1600230932235718
Validation loss: 2.045628788650677

Epoch: 6| Step: 10
Training loss: 1.9776558876037598
Validation loss: 2.0452420762790147

Epoch: 6| Step: 11
Training loss: 1.4664145708084106
Validation loss: 2.018112867109237

Epoch: 6| Step: 12
Training loss: 2.485529661178589
Validation loss: 2.0541331306580575

Epoch: 6| Step: 13
Training loss: 2.546299695968628
Validation loss: 2.035191179603659

Epoch: 149| Step: 0
Training loss: 2.8993988037109375
Validation loss: 2.0445151931496075

Epoch: 6| Step: 1
Training loss: 2.3472936153411865
Validation loss: 2.0327110649437032

Epoch: 6| Step: 2
Training loss: 2.0737884044647217
Validation loss: 2.008973034479285

Epoch: 6| Step: 3
Training loss: 2.351170301437378
Validation loss: 2.0249794324239097

Epoch: 6| Step: 4
Training loss: 1.193724274635315
Validation loss: 2.0286787850882417

Epoch: 6| Step: 5
Training loss: 2.536259174346924
Validation loss: 1.992728405101325

Epoch: 6| Step: 6
Training loss: 1.6342394351959229
Validation loss: 2.0392191435701106

Epoch: 6| Step: 7
Training loss: 1.7693812847137451
Validation loss: 2.019516030947367

Epoch: 6| Step: 8
Training loss: 2.065713882446289
Validation loss: 1.998788591354124

Epoch: 6| Step: 9
Training loss: 1.8260756731033325
Validation loss: 2.0139873848166516

Epoch: 6| Step: 10
Training loss: 2.0807013511657715
Validation loss: 2.0457185968275993

Epoch: 6| Step: 11
Training loss: 1.5813329219818115
Validation loss: 2.0572937021973314

Epoch: 6| Step: 12
Training loss: 1.9491112232208252
Validation loss: 2.02929780303791

Epoch: 6| Step: 13
Training loss: 2.201327323913574
Validation loss: 2.0477240290693057

Epoch: 150| Step: 0
Training loss: 2.3079886436462402
Validation loss: 2.0571572024335145

Epoch: 6| Step: 1
Training loss: 1.6748430728912354
Validation loss: 2.0568523535164456

Epoch: 6| Step: 2
Training loss: 3.1422853469848633
Validation loss: 2.037048550062282

Epoch: 6| Step: 3
Training loss: 2.100813388824463
Validation loss: 2.057406597239997

Epoch: 6| Step: 4
Training loss: 2.5225727558135986
Validation loss: 2.05355498098558

Epoch: 6| Step: 5
Training loss: 1.7822136878967285
Validation loss: 2.042708340511527

Epoch: 6| Step: 6
Training loss: 1.4748860597610474
Validation loss: 2.056013919973886

Epoch: 6| Step: 7
Training loss: 1.483373761177063
Validation loss: 2.084615149805623

Epoch: 6| Step: 8
Training loss: 2.727550983428955
Validation loss: 2.0820174550497406

Epoch: 6| Step: 9
Training loss: 2.2500312328338623
Validation loss: 2.0773259503867036

Epoch: 6| Step: 10
Training loss: 1.798173427581787
Validation loss: 2.079558881380225

Epoch: 6| Step: 11
Training loss: 1.4823404550552368
Validation loss: 2.0639230974258913

Epoch: 6| Step: 12
Training loss: 2.0581276416778564
Validation loss: 2.0826527585265455

Epoch: 6| Step: 13
Training loss: 1.3161729574203491
Validation loss: 2.05269500388894

Epoch: 151| Step: 0
Training loss: 2.555372714996338
Validation loss: 2.040881351758075

Epoch: 6| Step: 1
Training loss: 2.316521406173706
Validation loss: 2.038631804527775

Epoch: 6| Step: 2
Training loss: 2.1622698307037354
Validation loss: 2.0768441102838002

Epoch: 6| Step: 3
Training loss: 1.9069504737854004
Validation loss: 2.0405922884582193

Epoch: 6| Step: 4
Training loss: 1.837691307067871
Validation loss: 2.0390554576791744

Epoch: 6| Step: 5
Training loss: 1.7312434911727905
Validation loss: 2.054208791384133

Epoch: 6| Step: 6
Training loss: 1.516696572303772
Validation loss: 2.037879305501138

Epoch: 6| Step: 7
Training loss: 1.5113511085510254
Validation loss: 2.0231015938584522

Epoch: 6| Step: 8
Training loss: 1.6437866687774658
Validation loss: 2.046770006097773

Epoch: 6| Step: 9
Training loss: 1.8061842918395996
Validation loss: 2.0194975394074635

Epoch: 6| Step: 10
Training loss: 1.9146133661270142
Validation loss: 2.0321478036142167

Epoch: 6| Step: 11
Training loss: 2.3791213035583496
Validation loss: 2.0196053981781006

Epoch: 6| Step: 12
Training loss: 2.486525535583496
Validation loss: 2.0098634125084005

Epoch: 6| Step: 13
Training loss: 2.802382469177246
Validation loss: 2.0509008130719586

Epoch: 152| Step: 0
Training loss: 1.5015292167663574
Validation loss: 2.041285120030885

Epoch: 6| Step: 1
Training loss: 1.5897585153579712
Validation loss: 2.0643741135956137

Epoch: 6| Step: 2
Training loss: 2.6073365211486816
Validation loss: 2.042524286495742

Epoch: 6| Step: 3
Training loss: 2.3730483055114746
Validation loss: 2.009913718828591

Epoch: 6| Step: 4
Training loss: 2.0834474563598633
Validation loss: 2.0069962534853207

Epoch: 6| Step: 5
Training loss: 2.301908016204834
Validation loss: 2.0209953682397

Epoch: 6| Step: 6
Training loss: 1.8025516271591187
Validation loss: 2.036663777084761

Epoch: 6| Step: 7
Training loss: 2.211576461791992
Validation loss: 2.047356945212169

Epoch: 6| Step: 8
Training loss: 1.6098268032073975
Validation loss: 2.036221532411473

Epoch: 6| Step: 9
Training loss: 2.477667808532715
Validation loss: 2.0151072676463793

Epoch: 6| Step: 10
Training loss: 2.0956766605377197
Validation loss: 2.0399891279077016

Epoch: 6| Step: 11
Training loss: 2.042314291000366
Validation loss: 2.01821558449858

Epoch: 6| Step: 12
Training loss: 1.4328675270080566
Validation loss: 2.032535392750976

Epoch: 6| Step: 13
Training loss: 2.2988977432250977
Validation loss: 2.066460863236458

Epoch: 153| Step: 0
Training loss: 1.5478405952453613
Validation loss: 2.0708528872459167

Epoch: 6| Step: 1
Training loss: 1.5542569160461426
Validation loss: 2.0449452977026663

Epoch: 6| Step: 2
Training loss: 2.130841016769409
Validation loss: 2.0437281541926886

Epoch: 6| Step: 3
Training loss: 1.4185230731964111
Validation loss: 2.0442680722923687

Epoch: 6| Step: 4
Training loss: 2.6984312534332275
Validation loss: 2.0392052422287645

Epoch: 6| Step: 5
Training loss: 2.6277217864990234
Validation loss: 2.041469268901374

Epoch: 6| Step: 6
Training loss: 2.262263774871826
Validation loss: 2.0673258227686726

Epoch: 6| Step: 7
Training loss: 1.772010087966919
Validation loss: 2.063158136542125

Epoch: 6| Step: 8
Training loss: 1.7436928749084473
Validation loss: 2.054335331404081

Epoch: 6| Step: 9
Training loss: 2.60929536819458
Validation loss: 2.0441897735800794

Epoch: 6| Step: 10
Training loss: 1.4299583435058594
Validation loss: 2.0488141249584895

Epoch: 6| Step: 11
Training loss: 2.2335052490234375
Validation loss: 2.055766564543529

Epoch: 6| Step: 12
Training loss: 2.637911319732666
Validation loss: 2.037722635012801

Epoch: 6| Step: 13
Training loss: 1.2773106098175049
Validation loss: 2.0456048698835474

Epoch: 154| Step: 0
Training loss: 1.8961189985275269
Validation loss: 2.0390160981044976

Epoch: 6| Step: 1
Training loss: 2.1205573081970215
Validation loss: 2.066214212807276

Epoch: 6| Step: 2
Training loss: 2.321894407272339
Validation loss: 2.0607104532180296

Epoch: 6| Step: 3
Training loss: 2.6024131774902344
Validation loss: 2.037432698793309

Epoch: 6| Step: 4
Training loss: 1.5340842008590698
Validation loss: 2.052270867491281

Epoch: 6| Step: 5
Training loss: 2.28225040435791
Validation loss: 2.0538890054149013

Epoch: 6| Step: 6
Training loss: 2.2305498123168945
Validation loss: 2.04352932078864

Epoch: 6| Step: 7
Training loss: 1.4557631015777588
Validation loss: 2.0551855666663057

Epoch: 6| Step: 8
Training loss: 1.8701001405715942
Validation loss: 2.0410958438791256

Epoch: 6| Step: 9
Training loss: 2.0518665313720703
Validation loss: 2.0612076713192846

Epoch: 6| Step: 10
Training loss: 1.796905755996704
Validation loss: 2.0657814651407223

Epoch: 6| Step: 11
Training loss: 2.3948051929473877
Validation loss: 2.061676521455088

Epoch: 6| Step: 12
Training loss: 1.910963535308838
Validation loss: 2.0825904761591265

Epoch: 6| Step: 13
Training loss: 1.5841197967529297
Validation loss: 2.042422030561714

Epoch: 155| Step: 0
Training loss: 2.8927531242370605
Validation loss: 2.025096917665133

Epoch: 6| Step: 1
Training loss: 2.3762636184692383
Validation loss: 2.0465715674943823

Epoch: 6| Step: 2
Training loss: 0.762946367263794
Validation loss: 2.027764763883365

Epoch: 6| Step: 3
Training loss: 1.7156929969787598
Validation loss: 2.060190805824854

Epoch: 6| Step: 4
Training loss: 1.8176618814468384
Validation loss: 2.0344727987884195

Epoch: 6| Step: 5
Training loss: 2.5849015712738037
Validation loss: 2.0286905765533447

Epoch: 6| Step: 6
Training loss: 2.5640182495117188
Validation loss: 2.028826403361495

Epoch: 6| Step: 7
Training loss: 2.323202610015869
Validation loss: 2.0115925791443034

Epoch: 6| Step: 8
Training loss: 1.9633734226226807
Validation loss: 2.0340499211383123

Epoch: 6| Step: 9
Training loss: 1.6415518522262573
Validation loss: 2.0055234816766556

Epoch: 6| Step: 10
Training loss: 2.2116217613220215
Validation loss: 2.0476231446830173

Epoch: 6| Step: 11
Training loss: 1.5526190996170044
Validation loss: 2.0444521198990526

Epoch: 6| Step: 12
Training loss: 2.1073548793792725
Validation loss: 2.023938544334904

Epoch: 6| Step: 13
Training loss: 1.6311696767807007
Validation loss: 2.0366049428139963

Epoch: 156| Step: 0
Training loss: 1.7705703973770142
Validation loss: 2.031516654517061

Epoch: 6| Step: 1
Training loss: 2.8210437297821045
Validation loss: 2.015167192746234

Epoch: 6| Step: 2
Training loss: 2.02767014503479
Validation loss: 2.042200517910783

Epoch: 6| Step: 3
Training loss: 1.3922204971313477
Validation loss: 2.0297164301718436

Epoch: 6| Step: 4
Training loss: 1.9906282424926758
Validation loss: 2.0132728545896468

Epoch: 6| Step: 5
Training loss: 2.415339469909668
Validation loss: 2.0524767316797727

Epoch: 6| Step: 6
Training loss: 1.9449824094772339
Validation loss: 2.0305438016050603

Epoch: 6| Step: 7
Training loss: 1.8732104301452637
Validation loss: 2.038461349343741

Epoch: 6| Step: 8
Training loss: 1.9450857639312744
Validation loss: 2.0187574407105804

Epoch: 6| Step: 9
Training loss: 2.1165385246276855
Validation loss: 2.0369148792759066

Epoch: 6| Step: 10
Training loss: 2.0945725440979004
Validation loss: 2.057654365416496

Epoch: 6| Step: 11
Training loss: 2.093356132507324
Validation loss: 2.065497565013106

Epoch: 6| Step: 12
Training loss: 1.5549733638763428
Validation loss: 2.046422371300318

Epoch: 6| Step: 13
Training loss: 2.189363718032837
Validation loss: 2.065780572993781

Epoch: 157| Step: 0
Training loss: 2.228156566619873
Validation loss: 2.088138808486282

Epoch: 6| Step: 1
Training loss: 2.1200013160705566
Validation loss: 2.0728149901154223

Epoch: 6| Step: 2
Training loss: 1.284153938293457
Validation loss: 2.0531524137784074

Epoch: 6| Step: 3
Training loss: 1.7918553352355957
Validation loss: 2.0389935713942333

Epoch: 6| Step: 4
Training loss: 1.895336627960205
Validation loss: 2.0391895296753093

Epoch: 6| Step: 5
Training loss: 1.7482255697250366
Validation loss: 2.0685210561239593

Epoch: 6| Step: 6
Training loss: 2.71604061126709
Validation loss: 2.0662709692473054

Epoch: 6| Step: 7
Training loss: 1.7024197578430176
Validation loss: 2.0364130312396633

Epoch: 6| Step: 8
Training loss: 1.9905173778533936
Validation loss: 2.07321955568047

Epoch: 6| Step: 9
Training loss: 2.625490427017212
Validation loss: 2.031635647178978

Epoch: 6| Step: 10
Training loss: 2.1874823570251465
Validation loss: 2.03505507592232

Epoch: 6| Step: 11
Training loss: 1.998083233833313
Validation loss: 2.021700918033559

Epoch: 6| Step: 12
Training loss: 1.7751858234405518
Validation loss: 2.05863756005482

Epoch: 6| Step: 13
Training loss: 2.1418371200561523
Validation loss: 2.064417185321931

Epoch: 158| Step: 0
Training loss: 1.3116161823272705
Validation loss: 2.048691354772096

Epoch: 6| Step: 1
Training loss: 2.3902788162231445
Validation loss: 2.0331932639562957

Epoch: 6| Step: 2
Training loss: 1.819305181503296
Validation loss: 2.0450409317529328

Epoch: 6| Step: 3
Training loss: 2.7215375900268555
Validation loss: 2.0379048470527894

Epoch: 6| Step: 4
Training loss: 1.490607738494873
Validation loss: 2.0529650667662263

Epoch: 6| Step: 5
Training loss: 1.5070252418518066
Validation loss: 2.0625330889096825

Epoch: 6| Step: 6
Training loss: 2.127983331680298
Validation loss: 2.067282138332244

Epoch: 6| Step: 7
Training loss: 2.3935532569885254
Validation loss: 2.0347622338161675

Epoch: 6| Step: 8
Training loss: 1.6715744733810425
Validation loss: 2.06404274125253

Epoch: 6| Step: 9
Training loss: 2.3121867179870605
Validation loss: 2.0270236717757357

Epoch: 6| Step: 10
Training loss: 2.2268195152282715
Validation loss: 2.0514428602751864

Epoch: 6| Step: 11
Training loss: 2.370720148086548
Validation loss: 2.0642510588451097

Epoch: 6| Step: 12
Training loss: 1.7823832035064697
Validation loss: 2.0389539734009774

Epoch: 6| Step: 13
Training loss: 1.772557258605957
Validation loss: 2.0557553434884674

Epoch: 159| Step: 0
Training loss: 1.533356785774231
Validation loss: 2.051659281535815

Epoch: 6| Step: 1
Training loss: 1.9436163902282715
Validation loss: 2.077161435158022

Epoch: 6| Step: 2
Training loss: 1.6584628820419312
Validation loss: 2.0407341436673234

Epoch: 6| Step: 3
Training loss: 1.9153451919555664
Validation loss: 2.036694224162768

Epoch: 6| Step: 4
Training loss: 1.7080209255218506
Validation loss: 2.0384851937652915

Epoch: 6| Step: 5
Training loss: 2.3520851135253906
Validation loss: 2.063049239497031

Epoch: 6| Step: 6
Training loss: 2.2913317680358887
Validation loss: 2.034517188226023

Epoch: 6| Step: 7
Training loss: 2.175203323364258
Validation loss: 2.039212078176519

Epoch: 6| Step: 8
Training loss: 1.9032440185546875
Validation loss: 2.051740889908165

Epoch: 6| Step: 9
Training loss: 2.4273595809936523
Validation loss: 2.06627816795021

Epoch: 6| Step: 10
Training loss: 2.2479472160339355
Validation loss: 2.0404832004218973

Epoch: 6| Step: 11
Training loss: 2.2068309783935547
Validation loss: 2.047646250776065

Epoch: 6| Step: 12
Training loss: 1.9685406684875488
Validation loss: 2.0477076973966373

Epoch: 6| Step: 13
Training loss: 1.8641338348388672
Validation loss: 2.033610422124145

Epoch: 160| Step: 0
Training loss: 1.1085937023162842
Validation loss: 2.0645380802051996

Epoch: 6| Step: 1
Training loss: 1.3440836668014526
Validation loss: 2.037582330806281

Epoch: 6| Step: 2
Training loss: 2.5191030502319336
Validation loss: 2.0520334679593324

Epoch: 6| Step: 3
Training loss: 1.539803385734558
Validation loss: 2.039494845174974

Epoch: 6| Step: 4
Training loss: 1.2345786094665527
Validation loss: 2.042550939385609

Epoch: 6| Step: 5
Training loss: 2.27447509765625
Validation loss: 2.027255488980201

Epoch: 6| Step: 6
Training loss: 2.135162115097046
Validation loss: 2.0389683849068096

Epoch: 6| Step: 7
Training loss: 1.7483090162277222
Validation loss: 2.023036574804655

Epoch: 6| Step: 8
Training loss: 1.59883451461792
Validation loss: 2.0387551246150846

Epoch: 6| Step: 9
Training loss: 2.309734344482422
Validation loss: 2.02293328315981

Epoch: 6| Step: 10
Training loss: 2.134845733642578
Validation loss: 2.050082428480989

Epoch: 6| Step: 11
Training loss: 2.8872077465057373
Validation loss: 2.0597202470225673

Epoch: 6| Step: 12
Training loss: 2.523021697998047
Validation loss: 2.021829466665945

Epoch: 6| Step: 13
Training loss: 2.8110592365264893
Validation loss: 2.0476360103135467

Epoch: 161| Step: 0
Training loss: 2.1165213584899902
Validation loss: 2.0597948335832164

Epoch: 6| Step: 1
Training loss: 2.429267168045044
Validation loss: 2.0563008836520615

Epoch: 6| Step: 2
Training loss: 2.156093120574951
Validation loss: 2.064796070898733

Epoch: 6| Step: 3
Training loss: 1.2977406978607178
Validation loss: 2.03849527143663

Epoch: 6| Step: 4
Training loss: 1.9039273262023926
Validation loss: 2.039406248318252

Epoch: 6| Step: 5
Training loss: 2.411306381225586
Validation loss: 2.0772347168255876

Epoch: 6| Step: 6
Training loss: 2.008906841278076
Validation loss: 2.0433919711779525

Epoch: 6| Step: 7
Training loss: 2.1431424617767334
Validation loss: 2.056375689403985

Epoch: 6| Step: 8
Training loss: 1.7289726734161377
Validation loss: 2.0758247593397736

Epoch: 6| Step: 9
Training loss: 2.056793212890625
Validation loss: 2.052491677704678

Epoch: 6| Step: 10
Training loss: 2.14715313911438
Validation loss: 2.06483365643409

Epoch: 6| Step: 11
Training loss: 1.4743539094924927
Validation loss: 2.0278517994829404

Epoch: 6| Step: 12
Training loss: 1.7059109210968018
Validation loss: 2.0605637309371785

Epoch: 6| Step: 13
Training loss: 2.5134949684143066
Validation loss: 2.069529438531527

Epoch: 162| Step: 0
Training loss: 1.7252981662750244
Validation loss: 2.0543120009924776

Epoch: 6| Step: 1
Training loss: 1.9951459169387817
Validation loss: 2.050424591187508

Epoch: 6| Step: 2
Training loss: 1.372080683708191
Validation loss: 2.0460612581622217

Epoch: 6| Step: 3
Training loss: 2.0906803607940674
Validation loss: 2.0613875004553024

Epoch: 6| Step: 4
Training loss: 2.09529972076416
Validation loss: 2.0440552016740203

Epoch: 6| Step: 5
Training loss: 1.9604579210281372
Validation loss: 2.051979112368758

Epoch: 6| Step: 6
Training loss: 2.3215198516845703
Validation loss: 2.0415599243615263

Epoch: 6| Step: 7
Training loss: 1.2423095703125
Validation loss: 2.0389444058941257

Epoch: 6| Step: 8
Training loss: 2.849553108215332
Validation loss: 2.0199736895099765

Epoch: 6| Step: 9
Training loss: 2.0892868041992188
Validation loss: 2.0450807656011274

Epoch: 6| Step: 10
Training loss: 2.3687829971313477
Validation loss: 2.059756353337278

Epoch: 6| Step: 11
Training loss: 1.9982836246490479
Validation loss: 2.062981568356996

Epoch: 6| Step: 12
Training loss: 2.3392245769500732
Validation loss: 2.01892501308072

Epoch: 6| Step: 13
Training loss: 1.4536868333816528
Validation loss: 2.040568749109904

Epoch: 163| Step: 0
Training loss: 2.3698408603668213
Validation loss: 2.028119551238193

Epoch: 6| Step: 1
Training loss: 1.9418467283248901
Validation loss: 2.037906062218451

Epoch: 6| Step: 2
Training loss: 1.5301599502563477
Validation loss: 2.0686046282450357

Epoch: 6| Step: 3
Training loss: 2.2800493240356445
Validation loss: 2.0192620523514284

Epoch: 6| Step: 4
Training loss: 2.3981313705444336
Validation loss: 2.013979369594205

Epoch: 6| Step: 5
Training loss: 2.300666332244873
Validation loss: 2.0707794876508814

Epoch: 6| Step: 6
Training loss: 1.5311449766159058
Validation loss: 2.0377544305657826

Epoch: 6| Step: 7
Training loss: 1.941415786743164
Validation loss: 2.0489937002940843

Epoch: 6| Step: 8
Training loss: 1.7098573446273804
Validation loss: 2.0544582515634517

Epoch: 6| Step: 9
Training loss: 2.5613369941711426
Validation loss: 2.0776012533454487

Epoch: 6| Step: 10
Training loss: 1.5041285753250122
Validation loss: 2.042576692437613

Epoch: 6| Step: 11
Training loss: 1.6895461082458496
Validation loss: 2.063122467328143

Epoch: 6| Step: 12
Training loss: 1.8450136184692383
Validation loss: 2.076343696604493

Epoch: 6| Step: 13
Training loss: 2.359323501586914
Validation loss: 2.0582597371070617

Epoch: 164| Step: 0
Training loss: 2.3032283782958984
Validation loss: 2.0678419297741306

Epoch: 6| Step: 1
Training loss: 2.4204626083374023
Validation loss: 2.041678842677865

Epoch: 6| Step: 2
Training loss: 2.225923538208008
Validation loss: 2.070318168209445

Epoch: 6| Step: 3
Training loss: 1.597292423248291
Validation loss: 2.0471777082771383

Epoch: 6| Step: 4
Training loss: 2.17110276222229
Validation loss: 2.0247708110399145

Epoch: 6| Step: 5
Training loss: 2.534524440765381
Validation loss: 2.056624129254331

Epoch: 6| Step: 6
Training loss: 1.7764551639556885
Validation loss: 2.0382945999022453

Epoch: 6| Step: 7
Training loss: 1.3629029989242554
Validation loss: 2.0433621765464864

Epoch: 6| Step: 8
Training loss: 2.227045774459839
Validation loss: 2.0707132406132196

Epoch: 6| Step: 9
Training loss: 1.7409427165985107
Validation loss: 2.0318213816612

Epoch: 6| Step: 10
Training loss: 2.139758348464966
Validation loss: 2.0773371637508435

Epoch: 6| Step: 11
Training loss: 2.0348682403564453
Validation loss: 2.0608895491528254

Epoch: 6| Step: 12
Training loss: 2.014341354370117
Validation loss: 2.036137186070924

Epoch: 6| Step: 13
Training loss: 1.3727580308914185
Validation loss: 2.0722777612747683

Epoch: 165| Step: 0
Training loss: 2.600783109664917
Validation loss: 2.0756938008851904

Epoch: 6| Step: 1
Training loss: 1.8157392740249634
Validation loss: 2.0530721833628993

Epoch: 6| Step: 2
Training loss: 2.2521510124206543
Validation loss: 2.050110632373441

Epoch: 6| Step: 3
Training loss: 1.6684527397155762
Validation loss: 2.0508582130555184

Epoch: 6| Step: 4
Training loss: 2.4061946868896484
Validation loss: 2.0581436772500314

Epoch: 6| Step: 5
Training loss: 2.201775550842285
Validation loss: 2.0663778294799147

Epoch: 6| Step: 6
Training loss: 1.5910260677337646
Validation loss: 2.036272862906097

Epoch: 6| Step: 7
Training loss: 1.896209716796875
Validation loss: 2.042575296535287

Epoch: 6| Step: 8
Training loss: 1.760797381401062
Validation loss: 2.035329004769684

Epoch: 6| Step: 9
Training loss: 2.185607671737671
Validation loss: 2.041321510909706

Epoch: 6| Step: 10
Training loss: 1.66178560256958
Validation loss: 2.04994833982119

Epoch: 6| Step: 11
Training loss: 1.6954073905944824
Validation loss: 2.037403516871955

Epoch: 6| Step: 12
Training loss: 1.9185611009597778
Validation loss: 2.0529155051836403

Epoch: 6| Step: 13
Training loss: 2.237309455871582
Validation loss: 2.065241482950026

Epoch: 166| Step: 0
Training loss: 1.8910030126571655
Validation loss: 2.081177701232254

Epoch: 6| Step: 1
Training loss: 2.115206718444824
Validation loss: 2.0290885253619124

Epoch: 6| Step: 2
Training loss: 1.9713801145553589
Validation loss: 2.039634322607389

Epoch: 6| Step: 3
Training loss: 2.5405659675598145
Validation loss: 2.0596513773805354

Epoch: 6| Step: 4
Training loss: 2.117370843887329
Validation loss: 2.039541394479813

Epoch: 6| Step: 5
Training loss: 2.5393898487091064
Validation loss: 2.0965439683647564

Epoch: 6| Step: 6
Training loss: 1.8359609842300415
Validation loss: 2.0781338253328876

Epoch: 6| Step: 7
Training loss: 1.15704345703125
Validation loss: 2.071270769642245

Epoch: 6| Step: 8
Training loss: 1.9255096912384033
Validation loss: 2.0695310254250803

Epoch: 6| Step: 9
Training loss: 1.8068315982818604
Validation loss: 2.093262426314815

Epoch: 6| Step: 10
Training loss: 2.177854537963867
Validation loss: 2.062326160810327

Epoch: 6| Step: 11
Training loss: 1.79701828956604
Validation loss: 2.096397861357658

Epoch: 6| Step: 12
Training loss: 1.4083620309829712
Validation loss: 2.0959356779693277

Epoch: 6| Step: 13
Training loss: 3.450070381164551
Validation loss: 2.0687850367638374

Epoch: 167| Step: 0
Training loss: 2.3077926635742188
Validation loss: 2.078798665795275

Epoch: 6| Step: 1
Training loss: 1.9895203113555908
Validation loss: 2.0504943632310435

Epoch: 6| Step: 2
Training loss: 2.004328966140747
Validation loss: 2.0606962224488616

Epoch: 6| Step: 3
Training loss: 2.0051944255828857
Validation loss: 2.037676034435149

Epoch: 6| Step: 4
Training loss: 1.2762051820755005
Validation loss: 2.0699641268740416

Epoch: 6| Step: 5
Training loss: 2.138972759246826
Validation loss: 2.0402322392309866

Epoch: 6| Step: 6
Training loss: 1.9149062633514404
Validation loss: 2.066218460759809

Epoch: 6| Step: 7
Training loss: 1.5724170207977295
Validation loss: 2.0375974203950618

Epoch: 6| Step: 8
Training loss: 1.9472501277923584
Validation loss: 2.0372672542448966

Epoch: 6| Step: 9
Training loss: 1.7605960369110107
Validation loss: 2.0489683869064494

Epoch: 6| Step: 10
Training loss: 2.543922185897827
Validation loss: 2.0638175946409985

Epoch: 6| Step: 11
Training loss: 2.664600133895874
Validation loss: 2.04834246635437

Epoch: 6| Step: 12
Training loss: 2.009246826171875
Validation loss: 2.0535224753041423

Epoch: 6| Step: 13
Training loss: 1.3384380340576172
Validation loss: 2.070080034194454

Epoch: 168| Step: 0
Training loss: 1.6141669750213623
Validation loss: 2.0618185227917087

Epoch: 6| Step: 1
Training loss: 2.126234769821167
Validation loss: 2.0470236450113277

Epoch: 6| Step: 2
Training loss: 2.0865368843078613
Validation loss: 2.0644853025354366

Epoch: 6| Step: 3
Training loss: 1.729694128036499
Validation loss: 2.0620827444138063

Epoch: 6| Step: 4
Training loss: 1.6906602382659912
Validation loss: 2.0566730601813203

Epoch: 6| Step: 5
Training loss: 1.9866998195648193
Validation loss: 2.027416508684876

Epoch: 6| Step: 6
Training loss: 2.336385488510132
Validation loss: 2.0693909147734284

Epoch: 6| Step: 7
Training loss: 1.926480770111084
Validation loss: 2.052855742874966

Epoch: 6| Step: 8
Training loss: 2.1382503509521484
Validation loss: 2.0462767270303543

Epoch: 6| Step: 9
Training loss: 1.5853731632232666
Validation loss: 2.0524753960230018

Epoch: 6| Step: 10
Training loss: 2.268519401550293
Validation loss: 2.060370542669809

Epoch: 6| Step: 11
Training loss: 2.244772434234619
Validation loss: 2.0423932408773773

Epoch: 6| Step: 12
Training loss: 1.9335010051727295
Validation loss: 2.07485863213898

Epoch: 6| Step: 13
Training loss: 2.2419261932373047
Validation loss: 2.0394268202525314

Epoch: 169| Step: 0
Training loss: 1.7249619960784912
Validation loss: 2.076431391059711

Epoch: 6| Step: 1
Training loss: 2.2395148277282715
Validation loss: 2.056109928315686

Epoch: 6| Step: 2
Training loss: 1.9564372301101685
Validation loss: 2.085067064531388

Epoch: 6| Step: 3
Training loss: 1.8778862953186035
Validation loss: 2.088295131601313

Epoch: 6| Step: 4
Training loss: 2.1915886402130127
Validation loss: 2.073787207244545

Epoch: 6| Step: 5
Training loss: 2.1818904876708984
Validation loss: 2.079588883666582

Epoch: 6| Step: 6
Training loss: 2.526101589202881
Validation loss: 2.07177944208986

Epoch: 6| Step: 7
Training loss: 2.647644519805908
Validation loss: 2.0585116468450075

Epoch: 6| Step: 8
Training loss: 2.0028257369995117
Validation loss: 2.068282950309015

Epoch: 6| Step: 9
Training loss: 1.5236449241638184
Validation loss: 2.056470686389554

Epoch: 6| Step: 10
Training loss: 2.2144742012023926
Validation loss: 2.0773893248650337

Epoch: 6| Step: 11
Training loss: 1.8291065692901611
Validation loss: 2.012721792344124

Epoch: 6| Step: 12
Training loss: 1.0687980651855469
Validation loss: 2.02988374874156

Epoch: 6| Step: 13
Training loss: 1.6979695558547974
Validation loss: 2.048571889118482

Epoch: 170| Step: 0
Training loss: 2.8780033588409424
Validation loss: 2.0351781819456365

Epoch: 6| Step: 1
Training loss: 2.030397415161133
Validation loss: 2.0513287282759145

Epoch: 6| Step: 2
Training loss: 2.4844698905944824
Validation loss: 2.0002515367282334

Epoch: 6| Step: 3
Training loss: 2.0129849910736084
Validation loss: 2.0676724885099675

Epoch: 6| Step: 4
Training loss: 0.7249677181243896
Validation loss: 2.0472314229575534

Epoch: 6| Step: 5
Training loss: 1.6919046640396118
Validation loss: 2.0532585010733655

Epoch: 6| Step: 6
Training loss: 1.959823727607727
Validation loss: 2.064536202338434

Epoch: 6| Step: 7
Training loss: 2.3528904914855957
Validation loss: 2.0573663993548323

Epoch: 6| Step: 8
Training loss: 1.8334237337112427
Validation loss: 2.047041562295729

Epoch: 6| Step: 9
Training loss: 1.7451294660568237
Validation loss: 2.033960048870374

Epoch: 6| Step: 10
Training loss: 1.8622102737426758
Validation loss: 2.0489723067129813

Epoch: 6| Step: 11
Training loss: 2.0563371181488037
Validation loss: 2.0413516952145483

Epoch: 6| Step: 12
Training loss: 1.5996291637420654
Validation loss: 2.039513216223768

Epoch: 6| Step: 13
Training loss: 2.6364595890045166
Validation loss: 2.0366703720502954

Epoch: 171| Step: 0
Training loss: 1.9236342906951904
Validation loss: 2.0586768747657858

Epoch: 6| Step: 1
Training loss: 1.6376343965530396
Validation loss: 2.058887290698226

Epoch: 6| Step: 2
Training loss: 2.2885427474975586
Validation loss: 2.059283107839605

Epoch: 6| Step: 3
Training loss: 2.5566539764404297
Validation loss: 2.050976235379455

Epoch: 6| Step: 4
Training loss: 2.1691250801086426
Validation loss: 2.069941113072057

Epoch: 6| Step: 5
Training loss: 1.8282065391540527
Validation loss: 2.048902798724431

Epoch: 6| Step: 6
Training loss: 1.678115963935852
Validation loss: 2.067559001266315

Epoch: 6| Step: 7
Training loss: 2.3119113445281982
Validation loss: 2.066813912442935

Epoch: 6| Step: 8
Training loss: 1.317216157913208
Validation loss: 2.08093076111168

Epoch: 6| Step: 9
Training loss: 1.6915810108184814
Validation loss: 2.0741544500474007

Epoch: 6| Step: 10
Training loss: 1.9743810892105103
Validation loss: 2.095904541271989

Epoch: 6| Step: 11
Training loss: 1.8591583967208862
Validation loss: 2.049654749131972

Epoch: 6| Step: 12
Training loss: 2.3832356929779053
Validation loss: 2.0679235304555585

Epoch: 6| Step: 13
Training loss: 2.0698208808898926
Validation loss: 2.0533255838578746

Epoch: 172| Step: 0
Training loss: 1.8425238132476807
Validation loss: 2.0814708099570325

Epoch: 6| Step: 1
Training loss: 2.0903069972991943
Validation loss: 2.047759408591896

Epoch: 6| Step: 2
Training loss: 2.010608673095703
Validation loss: 2.059274260715772

Epoch: 6| Step: 3
Training loss: 2.1384174823760986
Validation loss: 2.0524170437166767

Epoch: 6| Step: 4
Training loss: 2.6386327743530273
Validation loss: 2.0308773953427552

Epoch: 6| Step: 5
Training loss: 1.7314634323120117
Validation loss: 2.0699487681029947

Epoch: 6| Step: 6
Training loss: 1.4923005104064941
Validation loss: 2.0493642335296958

Epoch: 6| Step: 7
Training loss: 1.8808960914611816
Validation loss: 2.048831509005639

Epoch: 6| Step: 8
Training loss: 2.3288445472717285
Validation loss: 2.0481955389822684

Epoch: 6| Step: 9
Training loss: 2.173614740371704
Validation loss: 2.0604752173987766

Epoch: 6| Step: 10
Training loss: 1.2543944120407104
Validation loss: 2.04566950439125

Epoch: 6| Step: 11
Training loss: 1.7953699827194214
Validation loss: 2.042658828919934

Epoch: 6| Step: 12
Training loss: 2.1837573051452637
Validation loss: 2.0718360818842405

Epoch: 6| Step: 13
Training loss: 2.1190154552459717
Validation loss: 2.089260193609422

Epoch: 173| Step: 0
Training loss: 2.013303279876709
Validation loss: 2.014971270356127

Epoch: 6| Step: 1
Training loss: 1.895249605178833
Validation loss: 2.031090167260939

Epoch: 6| Step: 2
Training loss: 2.0376229286193848
Validation loss: 2.0415045586965417

Epoch: 6| Step: 3
Training loss: 2.395472288131714
Validation loss: 2.0765579554342453

Epoch: 6| Step: 4
Training loss: 1.95758855342865
Validation loss: 2.0675598729041313

Epoch: 6| Step: 5
Training loss: 1.8016806840896606
Validation loss: 2.070857358235185

Epoch: 6| Step: 6
Training loss: 2.0486996173858643
Validation loss: 2.0624902344519094

Epoch: 6| Step: 7
Training loss: 2.2269086837768555
Validation loss: 2.0793313928829726

Epoch: 6| Step: 8
Training loss: 1.8467587232589722
Validation loss: 2.067145014321932

Epoch: 6| Step: 9
Training loss: 1.4914937019348145
Validation loss: 2.0654823485241143

Epoch: 6| Step: 10
Training loss: 2.5834810733795166
Validation loss: 2.088210150759707

Epoch: 6| Step: 11
Training loss: 1.5670099258422852
Validation loss: 2.049970906267884

Epoch: 6| Step: 12
Training loss: 2.190067768096924
Validation loss: 2.0379365541601695

Epoch: 6| Step: 13
Training loss: 1.3541532754898071
Validation loss: 2.0457854014570995

Epoch: 174| Step: 0
Training loss: 2.4620985984802246
Validation loss: 2.0495281886028986

Epoch: 6| Step: 1
Training loss: 2.093579053878784
Validation loss: 2.0609033915304367

Epoch: 6| Step: 2
Training loss: 2.2996578216552734
Validation loss: 2.0536216817876345

Epoch: 6| Step: 3
Training loss: 2.4744908809661865
Validation loss: 2.071761251777731

Epoch: 6| Step: 4
Training loss: 2.845893383026123
Validation loss: 2.070508062198598

Epoch: 6| Step: 5
Training loss: 1.7773633003234863
Validation loss: 2.061020771662394

Epoch: 6| Step: 6
Training loss: 2.3365492820739746
Validation loss: 2.0875600281582085

Epoch: 6| Step: 7
Training loss: 0.9770656228065491
Validation loss: 2.079838711728332

Epoch: 6| Step: 8
Training loss: 1.5635106563568115
Validation loss: 2.068913621287192

Epoch: 6| Step: 9
Training loss: 1.510657787322998
Validation loss: 2.0686818425373366

Epoch: 6| Step: 10
Training loss: 2.0313899517059326
Validation loss: 2.0572524455285843

Epoch: 6| Step: 11
Training loss: 1.9503378868103027
Validation loss: 2.0687961680914766

Epoch: 6| Step: 12
Training loss: 1.2999464273452759
Validation loss: 2.0507119701754664

Epoch: 6| Step: 13
Training loss: 2.1003222465515137
Validation loss: 2.0572756157126477

Epoch: 175| Step: 0
Training loss: 1.7758631706237793
Validation loss: 2.04804063868779

Epoch: 6| Step: 1
Training loss: 1.9226402044296265
Validation loss: 2.0408545027496996

Epoch: 6| Step: 2
Training loss: 1.464772343635559
Validation loss: 2.065922701230613

Epoch: 6| Step: 3
Training loss: 1.9897496700286865
Validation loss: 2.073972982745017

Epoch: 6| Step: 4
Training loss: 2.02695369720459
Validation loss: 2.067747715980776

Epoch: 6| Step: 5
Training loss: 1.6850025653839111
Validation loss: 2.091635199003322

Epoch: 6| Step: 6
Training loss: 2.415736198425293
Validation loss: 2.0753788358421734

Epoch: 6| Step: 7
Training loss: 1.5277819633483887
Validation loss: 2.0784223874409995

Epoch: 6| Step: 8
Training loss: 2.4037299156188965
Validation loss: 2.0660036404927573

Epoch: 6| Step: 9
Training loss: 2.038160562515259
Validation loss: 2.066879339115594

Epoch: 6| Step: 10
Training loss: 2.130671262741089
Validation loss: 2.0390088609469834

Epoch: 6| Step: 11
Training loss: 2.010178565979004
Validation loss: 2.0898256712062384

Epoch: 6| Step: 12
Training loss: 1.9036228656768799
Validation loss: 2.0497601980804117

Epoch: 6| Step: 13
Training loss: 2.4088122844696045
Validation loss: 2.0615113653162473

Epoch: 176| Step: 0
Training loss: 2.2301816940307617
Validation loss: 2.061223970946445

Epoch: 6| Step: 1
Training loss: 1.7463669776916504
Validation loss: 2.0378672204991823

Epoch: 6| Step: 2
Training loss: 1.5477274656295776
Validation loss: 2.05560141481379

Epoch: 6| Step: 3
Training loss: 3.198996067047119
Validation loss: 2.039456476447403

Epoch: 6| Step: 4
Training loss: 1.9401261806488037
Validation loss: 2.071236748849192

Epoch: 6| Step: 5
Training loss: 2.5687718391418457
Validation loss: 2.0696426053201

Epoch: 6| Step: 6
Training loss: 2.1129188537597656
Validation loss: 2.0418640913501864

Epoch: 6| Step: 7
Training loss: 1.7279375791549683
Validation loss: 2.0466265293859665

Epoch: 6| Step: 8
Training loss: 1.4769530296325684
Validation loss: 2.0293368818939372

Epoch: 6| Step: 9
Training loss: 1.558411955833435
Validation loss: 2.076857569397137

Epoch: 6| Step: 10
Training loss: 1.133544921875
Validation loss: 2.0483008751305203

Epoch: 6| Step: 11
Training loss: 1.6292668581008911
Validation loss: 2.0638822483760055

Epoch: 6| Step: 12
Training loss: 2.5471854209899902
Validation loss: 2.063204783265309

Epoch: 6| Step: 13
Training loss: 2.370237350463867
Validation loss: 2.06022931555266

Epoch: 177| Step: 0
Training loss: 1.9971885681152344
Validation loss: 2.0484645674305577

Epoch: 6| Step: 1
Training loss: 1.8741589784622192
Validation loss: 2.06725755558219

Epoch: 6| Step: 2
Training loss: 1.5714097023010254
Validation loss: 2.088599679290607

Epoch: 6| Step: 3
Training loss: 1.9682174921035767
Validation loss: 2.0486796132979856

Epoch: 6| Step: 4
Training loss: 1.7732223272323608
Validation loss: 2.079364388219772

Epoch: 6| Step: 5
Training loss: 1.8253306150436401
Validation loss: 2.074206103560745

Epoch: 6| Step: 6
Training loss: 1.9317615032196045
Validation loss: 2.073787295690147

Epoch: 6| Step: 7
Training loss: 2.0709400177001953
Validation loss: 2.0814851919809976

Epoch: 6| Step: 8
Training loss: 1.7827842235565186
Validation loss: 2.052959753621009

Epoch: 6| Step: 9
Training loss: 2.699395179748535
Validation loss: 2.0689307438429965

Epoch: 6| Step: 10
Training loss: 2.120039701461792
Validation loss: 2.0586819443651425

Epoch: 6| Step: 11
Training loss: 1.8411591053009033
Validation loss: 2.0891266843324066

Epoch: 6| Step: 12
Training loss: 2.0593206882476807
Validation loss: 2.042780392913408

Epoch: 6| Step: 13
Training loss: 2.0800282955169678
Validation loss: 2.0458174751650904

Epoch: 178| Step: 0
Training loss: 2.0244741439819336
Validation loss: 2.0608768745135237

Epoch: 6| Step: 1
Training loss: 2.4860095977783203
Validation loss: 2.039853565154537

Epoch: 6| Step: 2
Training loss: 2.03610897064209
Validation loss: 2.0744943182955504

Epoch: 6| Step: 3
Training loss: 1.7953681945800781
Validation loss: 2.068852932222428

Epoch: 6| Step: 4
Training loss: 1.6081955432891846
Validation loss: 2.082903039070868

Epoch: 6| Step: 5
Training loss: 2.0187666416168213
Validation loss: 2.059865874628867

Epoch: 6| Step: 6
Training loss: 1.7169959545135498
Validation loss: 2.0676572194663425

Epoch: 6| Step: 7
Training loss: 2.1650466918945312
Validation loss: 2.048267851593674

Epoch: 6| Step: 8
Training loss: 2.615114688873291
Validation loss: 2.065185582765969

Epoch: 6| Step: 9
Training loss: 1.9280246496200562
Validation loss: 2.062158852495173

Epoch: 6| Step: 10
Training loss: 1.912128210067749
Validation loss: 2.0278461569099018

Epoch: 6| Step: 11
Training loss: 1.8246302604675293
Validation loss: 2.0708465101898357

Epoch: 6| Step: 12
Training loss: 1.9046998023986816
Validation loss: 2.054966652265159

Epoch: 6| Step: 13
Training loss: 0.8965516686439514
Validation loss: 2.0808023355340444

Epoch: 179| Step: 0
Training loss: 1.7400274276733398
Validation loss: 2.038199709307763

Epoch: 6| Step: 1
Training loss: 1.7038675546646118
Validation loss: 2.051348847727622

Epoch: 6| Step: 2
Training loss: 1.727548599243164
Validation loss: 2.0503892962650587

Epoch: 6| Step: 3
Training loss: 2.02001953125
Validation loss: 2.057208835437734

Epoch: 6| Step: 4
Training loss: 1.862077236175537
Validation loss: 2.028705261086905

Epoch: 6| Step: 5
Training loss: 2.074869155883789
Validation loss: 2.06268826864099

Epoch: 6| Step: 6
Training loss: 2.505091428756714
Validation loss: 2.0614582748823267

Epoch: 6| Step: 7
Training loss: 2.1897997856140137
Validation loss: 2.0330024739747405

Epoch: 6| Step: 8
Training loss: 1.876112461090088
Validation loss: 2.0513339952756

Epoch: 6| Step: 9
Training loss: 2.4193005561828613
Validation loss: 2.0373282048010055

Epoch: 6| Step: 10
Training loss: 2.2485580444335938
Validation loss: 2.0734388623186337

Epoch: 6| Step: 11
Training loss: 0.9557117223739624
Validation loss: 2.0518930137798352

Epoch: 6| Step: 12
Training loss: 2.249545097351074
Validation loss: 2.0511079321625414

Epoch: 6| Step: 13
Training loss: 1.3980413675308228
Validation loss: 2.0541774124227543

Epoch: 180| Step: 0
Training loss: 2.231194496154785
Validation loss: 2.0815900718012164

Epoch: 6| Step: 1
Training loss: 1.596913456916809
Validation loss: 2.0691144351036317

Epoch: 6| Step: 2
Training loss: 1.8129353523254395
Validation loss: 2.051005635210263

Epoch: 6| Step: 3
Training loss: 2.2757115364074707
Validation loss: 2.0854187729538127

Epoch: 6| Step: 4
Training loss: 1.2667551040649414
Validation loss: 2.0397520719035978

Epoch: 6| Step: 5
Training loss: 1.9648942947387695
Validation loss: 2.052464077549596

Epoch: 6| Step: 6
Training loss: 2.4837393760681152
Validation loss: 2.0549258506426247

Epoch: 6| Step: 7
Training loss: 2.012584686279297
Validation loss: 2.077414466488746

Epoch: 6| Step: 8
Training loss: 1.9245882034301758
Validation loss: 2.079033019722149

Epoch: 6| Step: 9
Training loss: 1.92331862449646
Validation loss: 2.0479232700922156

Epoch: 6| Step: 10
Training loss: 2.642430543899536
Validation loss: 2.0657121750616256

Epoch: 6| Step: 11
Training loss: 1.975165843963623
Validation loss: 2.0656506861409833

Epoch: 6| Step: 12
Training loss: 1.441622018814087
Validation loss: 2.0832563484868696

Epoch: 6| Step: 13
Training loss: 2.2062113285064697
Validation loss: 2.0854580120373796

Epoch: 181| Step: 0
Training loss: 1.7788069248199463
Validation loss: 2.0610881133746077

Epoch: 6| Step: 1
Training loss: 2.536073684692383
Validation loss: 2.066283805395967

Epoch: 6| Step: 2
Training loss: 1.3316794633865356
Validation loss: 2.064428767850322

Epoch: 6| Step: 3
Training loss: 2.3514418601989746
Validation loss: 2.072263066486646

Epoch: 6| Step: 4
Training loss: 1.361829400062561
Validation loss: 2.0839413622374177

Epoch: 6| Step: 5
Training loss: 2.071820020675659
Validation loss: 2.048066641694756

Epoch: 6| Step: 6
Training loss: 1.9496588706970215
Validation loss: 2.0603873601523777

Epoch: 6| Step: 7
Training loss: 2.9741835594177246
Validation loss: 2.0436006899802917

Epoch: 6| Step: 8
Training loss: 2.3382644653320312
Validation loss: 2.0579700405879686

Epoch: 6| Step: 9
Training loss: 2.2477359771728516
Validation loss: 2.0720635972997195

Epoch: 6| Step: 10
Training loss: 1.5913230180740356
Validation loss: 2.0688858378318047

Epoch: 6| Step: 11
Training loss: 1.9670615196228027
Validation loss: 2.04388169575763

Epoch: 6| Step: 12
Training loss: 1.3482677936553955
Validation loss: 2.0486813040189844

Epoch: 6| Step: 13
Training loss: 1.4896721839904785
Validation loss: 2.0634499775466097

Epoch: 182| Step: 0
Training loss: 2.1028800010681152
Validation loss: 2.0513897224139144

Epoch: 6| Step: 1
Training loss: 1.867913842201233
Validation loss: 2.101777684304022

Epoch: 6| Step: 2
Training loss: 2.4304134845733643
Validation loss: 2.060246290699128

Epoch: 6| Step: 3
Training loss: 1.9650441408157349
Validation loss: 2.0770282642815703

Epoch: 6| Step: 4
Training loss: 1.835880160331726
Validation loss: 2.0733244931826027

Epoch: 6| Step: 5
Training loss: 2.095240592956543
Validation loss: 2.0569667995616956

Epoch: 6| Step: 6
Training loss: 2.1894218921661377
Validation loss: 2.0442058860614734

Epoch: 6| Step: 7
Training loss: 1.8165464401245117
Validation loss: 2.073420827106763

Epoch: 6| Step: 8
Training loss: 2.2905473709106445
Validation loss: 2.0402120697882866

Epoch: 6| Step: 9
Training loss: 1.335709810256958
Validation loss: 2.0551255915754583

Epoch: 6| Step: 10
Training loss: 1.9358924627304077
Validation loss: 2.062393666595541

Epoch: 6| Step: 11
Training loss: 1.6959197521209717
Validation loss: 2.042889582213535

Epoch: 6| Step: 12
Training loss: 1.77693772315979
Validation loss: 2.0565310934538483

Epoch: 6| Step: 13
Training loss: 2.059382438659668
Validation loss: 2.0521976870875203

Epoch: 183| Step: 0
Training loss: 2.9431278705596924
Validation loss: 2.0573836872654576

Epoch: 6| Step: 1
Training loss: 1.399674415588379
Validation loss: 2.0717170405131515

Epoch: 6| Step: 2
Training loss: 2.205418586730957
Validation loss: 2.052838974101569

Epoch: 6| Step: 3
Training loss: 1.5219416618347168
Validation loss: 2.0576898154392036

Epoch: 6| Step: 4
Training loss: 2.40799617767334
Validation loss: 2.0750295705692743

Epoch: 6| Step: 5
Training loss: 1.3066729307174683
Validation loss: 2.097341839985181

Epoch: 6| Step: 6
Training loss: 2.3770699501037598
Validation loss: 2.075871129189768

Epoch: 6| Step: 7
Training loss: 1.8153595924377441
Validation loss: 2.0751848989917385

Epoch: 6| Step: 8
Training loss: 1.8289835453033447
Validation loss: 2.0996247132619223

Epoch: 6| Step: 9
Training loss: 2.0228331089019775
Validation loss: 2.081124246761363

Epoch: 6| Step: 10
Training loss: 2.090395212173462
Validation loss: 2.0914990004672798

Epoch: 6| Step: 11
Training loss: 1.465240478515625
Validation loss: 2.102341187897549

Epoch: 6| Step: 12
Training loss: 1.8431413173675537
Validation loss: 2.0885819978611444

Epoch: 6| Step: 13
Training loss: 2.3272111415863037
Validation loss: 2.082980925037015

Epoch: 184| Step: 0
Training loss: 2.638747215270996
Validation loss: 2.0810520546410674

Epoch: 6| Step: 1
Training loss: 2.2838802337646484
Validation loss: 2.0637790285130984

Epoch: 6| Step: 2
Training loss: 1.7732570171356201
Validation loss: 2.085952229397271

Epoch: 6| Step: 3
Training loss: 2.2319157123565674
Validation loss: 2.0548817060327016

Epoch: 6| Step: 4
Training loss: 1.8694294691085815
Validation loss: 2.0726451937870314

Epoch: 6| Step: 5
Training loss: 2.1781554222106934
Validation loss: 2.0624304663750435

Epoch: 6| Step: 6
Training loss: 1.6616039276123047
Validation loss: 2.0873709109521683

Epoch: 6| Step: 7
Training loss: 1.736591100692749
Validation loss: 2.0449415996510494

Epoch: 6| Step: 8
Training loss: 2.655681610107422
Validation loss: 2.030546162718086

Epoch: 6| Step: 9
Training loss: 1.7442842721939087
Validation loss: 2.062953923338203

Epoch: 6| Step: 10
Training loss: 2.408071517944336
Validation loss: 2.0601951896503405

Epoch: 6| Step: 11
Training loss: 1.347987174987793
Validation loss: 2.0466389015156734

Epoch: 6| Step: 12
Training loss: 1.5683852434158325
Validation loss: 2.050002996639539

Epoch: 6| Step: 13
Training loss: 0.8754090070724487
Validation loss: 2.0527576887479393

Epoch: 185| Step: 0
Training loss: 2.1206603050231934
Validation loss: 2.0369241724732103

Epoch: 6| Step: 1
Training loss: 1.7605983018875122
Validation loss: 2.04769709802443

Epoch: 6| Step: 2
Training loss: 1.7629197835922241
Validation loss: 2.055801204455796

Epoch: 6| Step: 3
Training loss: 1.3532447814941406
Validation loss: 2.053300767816523

Epoch: 6| Step: 4
Training loss: 1.8654191493988037
Validation loss: 2.0727463127464376

Epoch: 6| Step: 5
Training loss: 2.058534860610962
Validation loss: 2.0553700629101006

Epoch: 6| Step: 6
Training loss: 1.1403363943099976
Validation loss: 2.056406359518728

Epoch: 6| Step: 7
Training loss: 2.265547513961792
Validation loss: 2.0538217906028993

Epoch: 6| Step: 8
Training loss: 2.4426097869873047
Validation loss: 2.0523165182400773

Epoch: 6| Step: 9
Training loss: 2.527942180633545
Validation loss: 2.067653927751767

Epoch: 6| Step: 10
Training loss: 2.6519856452941895
Validation loss: 2.0528495055372997

Epoch: 6| Step: 11
Training loss: 2.0395872592926025
Validation loss: 2.055260726200637

Epoch: 6| Step: 12
Training loss: 1.5829644203186035
Validation loss: 2.082167171662854

Epoch: 6| Step: 13
Training loss: 1.9047932624816895
Validation loss: 2.0706590067955757

Epoch: 186| Step: 0
Training loss: 1.162523627281189
Validation loss: 2.079072121650942

Epoch: 6| Step: 1
Training loss: 2.2976107597351074
Validation loss: 2.0836972087942143

Epoch: 6| Step: 2
Training loss: 1.7609424591064453
Validation loss: 2.0445867200051584

Epoch: 6| Step: 3
Training loss: 1.7666741609573364
Validation loss: 2.054267064217598

Epoch: 6| Step: 4
Training loss: 2.573962688446045
Validation loss: 2.032417994673534

Epoch: 6| Step: 5
Training loss: 1.6367559432983398
Validation loss: 2.0668399205771824

Epoch: 6| Step: 6
Training loss: 2.357799530029297
Validation loss: 2.0556888093230543

Epoch: 6| Step: 7
Training loss: 1.5086374282836914
Validation loss: 2.0607210589993383

Epoch: 6| Step: 8
Training loss: 1.7536451816558838
Validation loss: 2.0653920558191117

Epoch: 6| Step: 9
Training loss: 2.3459665775299072
Validation loss: 2.0612395835179154

Epoch: 6| Step: 10
Training loss: 1.8826128244400024
Validation loss: 2.0674806282084477

Epoch: 6| Step: 11
Training loss: 2.4444527626037598
Validation loss: 2.069696726337556

Epoch: 6| Step: 12
Training loss: 1.6702780723571777
Validation loss: 2.041539866437194

Epoch: 6| Step: 13
Training loss: 2.4589171409606934
Validation loss: 2.049657621691304

Epoch: 187| Step: 0
Training loss: 1.7111060619354248
Validation loss: 2.086646859363843

Epoch: 6| Step: 1
Training loss: 2.7115840911865234
Validation loss: 2.0700813134511313

Epoch: 6| Step: 2
Training loss: 2.401066780090332
Validation loss: 2.1051097659654516

Epoch: 6| Step: 3
Training loss: 2.2268476486206055
Validation loss: 2.0907074943665536

Epoch: 6| Step: 4
Training loss: 2.4554193019866943
Validation loss: 2.106876023354069

Epoch: 6| Step: 5
Training loss: 1.7755513191223145
Validation loss: 2.091543520650556

Epoch: 6| Step: 6
Training loss: 1.9498462677001953
Validation loss: 2.091613669549265

Epoch: 6| Step: 7
Training loss: 2.2441673278808594
Validation loss: 2.1122959429217922

Epoch: 6| Step: 8
Training loss: 1.4176645278930664
Validation loss: 2.0916405365031254

Epoch: 6| Step: 9
Training loss: 1.6226139068603516
Validation loss: 2.097163983570632

Epoch: 6| Step: 10
Training loss: 1.559748649597168
Validation loss: 2.0834344151199504

Epoch: 6| Step: 11
Training loss: 1.5133910179138184
Validation loss: 2.0414337368421656

Epoch: 6| Step: 12
Training loss: 1.6636160612106323
Validation loss: 2.0683112887926

Epoch: 6| Step: 13
Training loss: 2.1133320331573486
Validation loss: 2.0496510818440425

Epoch: 188| Step: 0
Training loss: 2.201310396194458
Validation loss: 2.076898500483523

Epoch: 6| Step: 1
Training loss: 2.287316083908081
Validation loss: 2.07779691039875

Epoch: 6| Step: 2
Training loss: 1.9301083087921143
Validation loss: 2.0957148331467823

Epoch: 6| Step: 3
Training loss: 2.063011646270752
Validation loss: 2.0668285790310112

Epoch: 6| Step: 4
Training loss: 2.0872397422790527
Validation loss: 2.090737501780192

Epoch: 6| Step: 5
Training loss: 2.3512306213378906
Validation loss: 2.0591274205074517

Epoch: 6| Step: 6
Training loss: 2.254580497741699
Validation loss: 2.043134525258054

Epoch: 6| Step: 7
Training loss: 1.7231030464172363
Validation loss: 2.051659103362791

Epoch: 6| Step: 8
Training loss: 1.3617157936096191
Validation loss: 2.06540149001665

Epoch: 6| Step: 9
Training loss: 2.006000518798828
Validation loss: 2.055824036239296

Epoch: 6| Step: 10
Training loss: 1.4837559461593628
Validation loss: 2.0602250227364163

Epoch: 6| Step: 11
Training loss: 2.125929594039917
Validation loss: 2.0530383138246435

Epoch: 6| Step: 12
Training loss: 1.7136969566345215
Validation loss: 2.0534979322905182

Epoch: 6| Step: 13
Training loss: 1.376671314239502
Validation loss: 2.0410127319315428

Epoch: 189| Step: 0
Training loss: 1.7900216579437256
Validation loss: 2.055907159723261

Epoch: 6| Step: 1
Training loss: 1.5407030582427979
Validation loss: 2.0427226430626324

Epoch: 6| Step: 2
Training loss: 1.8168812990188599
Validation loss: 2.0518478219227125

Epoch: 6| Step: 3
Training loss: 2.0498671531677246
Validation loss: 2.074764859291815

Epoch: 6| Step: 4
Training loss: 1.9476276636123657
Validation loss: 2.048964117162971

Epoch: 6| Step: 5
Training loss: 2.3672685623168945
Validation loss: 2.0648837063902166

Epoch: 6| Step: 6
Training loss: 2.023350238800049
Validation loss: 2.07625832608951

Epoch: 6| Step: 7
Training loss: 2.180452346801758
Validation loss: 2.0516561436396774

Epoch: 6| Step: 8
Training loss: 1.5526361465454102
Validation loss: 2.068033533711587

Epoch: 6| Step: 9
Training loss: 1.4973351955413818
Validation loss: 2.04135194388769

Epoch: 6| Step: 10
Training loss: 2.1035943031311035
Validation loss: 2.0712390663803264

Epoch: 6| Step: 11
Training loss: 2.34281325340271
Validation loss: 2.0562132840515464

Epoch: 6| Step: 12
Training loss: 2.0878548622131348
Validation loss: 2.0998386644547984

Epoch: 6| Step: 13
Training loss: 1.4204506874084473
Validation loss: 2.065704018838944

Epoch: 190| Step: 0
Training loss: 1.3066726922988892
Validation loss: 2.0755948866567304

Epoch: 6| Step: 1
Training loss: 1.776715636253357
Validation loss: 2.076274282188826

Epoch: 6| Step: 2
Training loss: 1.852216362953186
Validation loss: 2.0623849463719193

Epoch: 6| Step: 3
Training loss: 1.2376644611358643
Validation loss: 2.0432983662492488

Epoch: 6| Step: 4
Training loss: 2.04886794090271
Validation loss: 2.0429831627876527

Epoch: 6| Step: 5
Training loss: 2.143021583557129
Validation loss: 2.063186002034013

Epoch: 6| Step: 6
Training loss: 1.9587123394012451
Validation loss: 2.058290784076978

Epoch: 6| Step: 7
Training loss: 1.7129851579666138
Validation loss: 2.074342817388555

Epoch: 6| Step: 8
Training loss: 2.142714023590088
Validation loss: 2.058161981644169

Epoch: 6| Step: 9
Training loss: 1.4441407918930054
Validation loss: 2.061562579165223

Epoch: 6| Step: 10
Training loss: 2.5901410579681396
Validation loss: 2.0351356742202595

Epoch: 6| Step: 11
Training loss: 2.366901159286499
Validation loss: 2.0406414437037643

Epoch: 6| Step: 12
Training loss: 2.744110584259033
Validation loss: 2.0611894117888583

Epoch: 6| Step: 13
Training loss: 1.7296475172042847
Validation loss: 2.0402681622453915

Epoch: 191| Step: 0
Training loss: 2.1106603145599365
Validation loss: 2.07857802350034

Epoch: 6| Step: 1
Training loss: 1.7464911937713623
Validation loss: 2.0700617618458246

Epoch: 6| Step: 2
Training loss: 2.5318126678466797
Validation loss: 2.0786058569467194

Epoch: 6| Step: 3
Training loss: 1.701789140701294
Validation loss: 2.0731444281916462

Epoch: 6| Step: 4
Training loss: 1.821948766708374
Validation loss: 2.0614768664042153

Epoch: 6| Step: 5
Training loss: 2.063896417617798
Validation loss: 2.0762612691489597

Epoch: 6| Step: 6
Training loss: 1.721740961074829
Validation loss: 2.0866469003820933

Epoch: 6| Step: 7
Training loss: 2.4801177978515625
Validation loss: 2.031736819974838

Epoch: 6| Step: 8
Training loss: 1.5414748191833496
Validation loss: 2.0671300362515193

Epoch: 6| Step: 9
Training loss: 2.98246431350708
Validation loss: 2.0572318953852498

Epoch: 6| Step: 10
Training loss: 1.446291446685791
Validation loss: 2.093897760555308

Epoch: 6| Step: 11
Training loss: 1.9348986148834229
Validation loss: 2.075552225112915

Epoch: 6| Step: 12
Training loss: 1.2439069747924805
Validation loss: 2.1026941294311197

Epoch: 6| Step: 13
Training loss: 1.76431405544281
Validation loss: 2.0842324097951255

Epoch: 192| Step: 0
Training loss: 2.067455768585205
Validation loss: 2.081188101922312

Epoch: 6| Step: 1
Training loss: 2.0701866149902344
Validation loss: 2.0629312146094536

Epoch: 6| Step: 2
Training loss: 1.5890285968780518
Validation loss: 2.0552573063040294

Epoch: 6| Step: 3
Training loss: 1.4515563249588013
Validation loss: 2.082658810000266

Epoch: 6| Step: 4
Training loss: 1.551694393157959
Validation loss: 2.1003861529852754

Epoch: 6| Step: 5
Training loss: 1.978621006011963
Validation loss: 2.085251969675864

Epoch: 6| Step: 6
Training loss: 1.8972084522247314
Validation loss: 2.07235074299638

Epoch: 6| Step: 7
Training loss: 2.2669105529785156
Validation loss: 2.038880140550675

Epoch: 6| Step: 8
Training loss: 2.577908992767334
Validation loss: 2.074492657056419

Epoch: 6| Step: 9
Training loss: 2.280625343322754
Validation loss: 2.0623933269131567

Epoch: 6| Step: 10
Training loss: 2.1688361167907715
Validation loss: 2.073160345836352

Epoch: 6| Step: 11
Training loss: 1.6263726949691772
Validation loss: 2.0711075939157957

Epoch: 6| Step: 12
Training loss: 1.7568893432617188
Validation loss: 2.086654716922391

Epoch: 6| Step: 13
Training loss: 1.7091407775878906
Validation loss: 2.0501962220796974

Epoch: 193| Step: 0
Training loss: 2.1152045726776123
Validation loss: 2.061770507084426

Epoch: 6| Step: 1
Training loss: 1.8399088382720947
Validation loss: 2.0584506616797498

Epoch: 6| Step: 2
Training loss: 1.5297536849975586
Validation loss: 2.0646332310092066

Epoch: 6| Step: 3
Training loss: 1.9121049642562866
Validation loss: 2.0564842160030077

Epoch: 6| Step: 4
Training loss: 2.132103204727173
Validation loss: 2.087723219266502

Epoch: 6| Step: 5
Training loss: 2.36407470703125
Validation loss: 2.0873548779436337

Epoch: 6| Step: 6
Training loss: 1.944432258605957
Validation loss: 2.058258404013931

Epoch: 6| Step: 7
Training loss: 1.2409690618515015
Validation loss: 2.0741390797399704

Epoch: 6| Step: 8
Training loss: 2.2311811447143555
Validation loss: 2.0659428617005706

Epoch: 6| Step: 9
Training loss: 2.3262715339660645
Validation loss: 2.0876412289116972

Epoch: 6| Step: 10
Training loss: 2.1040902137756348
Validation loss: 2.0733561925990607

Epoch: 6| Step: 11
Training loss: 1.5523052215576172
Validation loss: 2.0767812882700274

Epoch: 6| Step: 12
Training loss: 1.994419813156128
Validation loss: 2.090276671994117

Epoch: 6| Step: 13
Training loss: 1.7290889024734497
Validation loss: 2.085912027666646

Epoch: 194| Step: 0
Training loss: 2.0904335975646973
Validation loss: 2.0951511731711765

Epoch: 6| Step: 1
Training loss: 1.843475580215454
Validation loss: 2.097075964814873

Epoch: 6| Step: 2
Training loss: 2.446309804916382
Validation loss: 2.083282679639837

Epoch: 6| Step: 3
Training loss: 1.7021336555480957
Validation loss: 2.1089926842720277

Epoch: 6| Step: 4
Training loss: 2.074570894241333
Validation loss: 2.120273365769335

Epoch: 6| Step: 5
Training loss: 1.97831392288208
Validation loss: 2.1061990235441472

Epoch: 6| Step: 6
Training loss: 1.8708072900772095
Validation loss: 2.1297905957827004

Epoch: 6| Step: 7
Training loss: 1.5995442867279053
Validation loss: 2.0799651543299356

Epoch: 6| Step: 8
Training loss: 2.291895866394043
Validation loss: 2.064477907714023

Epoch: 6| Step: 9
Training loss: 2.0085763931274414
Validation loss: 2.0662234137135167

Epoch: 6| Step: 10
Training loss: 1.9759011268615723
Validation loss: 2.067598719750681

Epoch: 6| Step: 11
Training loss: 2.078770637512207
Validation loss: 2.081375583525627

Epoch: 6| Step: 12
Training loss: 1.2883508205413818
Validation loss: 2.085498043285903

Epoch: 6| Step: 13
Training loss: 1.9897689819335938
Validation loss: 2.0828878751365085

Epoch: 195| Step: 0
Training loss: 1.8963203430175781
Validation loss: 2.075367740405503

Epoch: 6| Step: 1
Training loss: 2.150289535522461
Validation loss: 2.0804703286899033

Epoch: 6| Step: 2
Training loss: 1.3904004096984863
Validation loss: 2.0451571505556823

Epoch: 6| Step: 3
Training loss: 1.904065728187561
Validation loss: 2.0715598867785547

Epoch: 6| Step: 4
Training loss: 2.2830429077148438
Validation loss: 2.0521384105887464

Epoch: 6| Step: 5
Training loss: 1.8921518325805664
Validation loss: 2.0750814612193773

Epoch: 6| Step: 6
Training loss: 2.3988795280456543
Validation loss: 2.0401210041456324

Epoch: 6| Step: 7
Training loss: 1.9668850898742676
Validation loss: 2.037614522441741

Epoch: 6| Step: 8
Training loss: 1.639418363571167
Validation loss: 2.060860995323427

Epoch: 6| Step: 9
Training loss: 2.048645496368408
Validation loss: 2.044415784138505

Epoch: 6| Step: 10
Training loss: 1.7245510816574097
Validation loss: 2.0719198193601382

Epoch: 6| Step: 11
Training loss: 1.0554611682891846
Validation loss: 2.0539615538812455

Epoch: 6| Step: 12
Training loss: 2.4687187671661377
Validation loss: 2.0462546015298493

Epoch: 6| Step: 13
Training loss: 2.585843324661255
Validation loss: 2.0476048825889506

Epoch: 196| Step: 0
Training loss: 2.3339943885803223
Validation loss: 2.0544028820530063

Epoch: 6| Step: 1
Training loss: 1.977276086807251
Validation loss: 2.049198963308847

Epoch: 6| Step: 2
Training loss: 1.4988739490509033
Validation loss: 2.0797536757684525

Epoch: 6| Step: 3
Training loss: 1.9301739931106567
Validation loss: 2.069629312843405

Epoch: 6| Step: 4
Training loss: 1.7390143871307373
Validation loss: 2.063079091810411

Epoch: 6| Step: 5
Training loss: 1.9030810594558716
Validation loss: 2.079144867517615

Epoch: 6| Step: 6
Training loss: 1.8980530500411987
Validation loss: 2.068509106994957

Epoch: 6| Step: 7
Training loss: 2.2492051124572754
Validation loss: 2.104080080986023

Epoch: 6| Step: 8
Training loss: 1.4956220388412476
Validation loss: 2.087064850714899

Epoch: 6| Step: 9
Training loss: 1.9410715103149414
Validation loss: 2.072863345505089

Epoch: 6| Step: 10
Training loss: 1.3576726913452148
Validation loss: 2.099865936463879

Epoch: 6| Step: 11
Training loss: 2.439154863357544
Validation loss: 2.0834032438134633

Epoch: 6| Step: 12
Training loss: 2.0550222396850586
Validation loss: 2.084602521311852

Epoch: 6| Step: 13
Training loss: 2.0091397762298584
Validation loss: 2.1126934302750455

Epoch: 197| Step: 0
Training loss: 1.8129934072494507
Validation loss: 2.088118996671451

Epoch: 6| Step: 1
Training loss: 1.9054970741271973
Validation loss: 2.0888153635045534

Epoch: 6| Step: 2
Training loss: 1.377530574798584
Validation loss: 2.1008710797115038

Epoch: 6| Step: 3
Training loss: 2.3560597896575928
Validation loss: 2.0961924855427077

Epoch: 6| Step: 4
Training loss: 1.7946391105651855
Validation loss: 2.0865361177793114

Epoch: 6| Step: 5
Training loss: 2.0812911987304688
Validation loss: 2.090197137607041

Epoch: 6| Step: 6
Training loss: 2.0753180980682373
Validation loss: 2.108929549494097

Epoch: 6| Step: 7
Training loss: 1.990065336227417
Validation loss: 2.0747633134165118

Epoch: 6| Step: 8
Training loss: 2.3993101119995117
Validation loss: 2.097643998361403

Epoch: 6| Step: 9
Training loss: 1.8902149200439453
Validation loss: 2.0946343573190833

Epoch: 6| Step: 10
Training loss: 1.9021813869476318
Validation loss: 2.074426031881763

Epoch: 6| Step: 11
Training loss: 2.1497621536254883
Validation loss: 2.070538733595161

Epoch: 6| Step: 12
Training loss: 1.9960527420043945
Validation loss: 2.0698742148696736

Epoch: 6| Step: 13
Training loss: 0.8167282938957214
Validation loss: 2.0822449679015786

Epoch: 198| Step: 0
Training loss: 1.8175501823425293
Validation loss: 2.0503841805201706

Epoch: 6| Step: 1
Training loss: 1.4419245719909668
Validation loss: 2.059387381358813

Epoch: 6| Step: 2
Training loss: 1.5515820980072021
Validation loss: 2.0668016941316667

Epoch: 6| Step: 3
Training loss: 2.8893775939941406
Validation loss: 2.0702105863119966

Epoch: 6| Step: 4
Training loss: 1.7592768669128418
Validation loss: 2.086209694544474

Epoch: 6| Step: 5
Training loss: 1.9128884077072144
Validation loss: 2.1053996483484902

Epoch: 6| Step: 6
Training loss: 1.9040133953094482
Validation loss: 2.0953324712732786

Epoch: 6| Step: 7
Training loss: 1.4486513137817383
Validation loss: 2.094437341536245

Epoch: 6| Step: 8
Training loss: 2.2943172454833984
Validation loss: 2.1217491319102626

Epoch: 6| Step: 9
Training loss: 1.1461502313613892
Validation loss: 2.131800950214427

Epoch: 6| Step: 10
Training loss: 2.6415646076202393
Validation loss: 2.0952806985506447

Epoch: 6| Step: 11
Training loss: 2.2512714862823486
Validation loss: 2.11934599825131

Epoch: 6| Step: 12
Training loss: 1.8444232940673828
Validation loss: 2.0788574526386876

Epoch: 6| Step: 13
Training loss: 2.285562753677368
Validation loss: 2.093124771630892

Epoch: 199| Step: 0
Training loss: 1.6125688552856445
Validation loss: 2.06219902089847

Epoch: 6| Step: 1
Training loss: 1.051928162574768
Validation loss: 2.0901336362285

Epoch: 6| Step: 2
Training loss: 1.8922768831253052
Validation loss: 2.062935108779579

Epoch: 6| Step: 3
Training loss: 1.5837621688842773
Validation loss: 2.0563149272754626

Epoch: 6| Step: 4
Training loss: 2.1519861221313477
Validation loss: 2.0796334922954602

Epoch: 6| Step: 5
Training loss: 2.1627559661865234
Validation loss: 2.024126277175001

Epoch: 6| Step: 6
Training loss: 1.8289819955825806
Validation loss: 2.0912549162423737

Epoch: 6| Step: 7
Training loss: 1.9348064661026
Validation loss: 2.044168136453116

Epoch: 6| Step: 8
Training loss: 1.4306328296661377
Validation loss: 2.0337200446795394

Epoch: 6| Step: 9
Training loss: 2.0481600761413574
Validation loss: 2.0373445262191114

Epoch: 6| Step: 10
Training loss: 2.6310341358184814
Validation loss: 2.0114541745954946

Epoch: 6| Step: 11
Training loss: 1.6177735328674316
Validation loss: 2.0446276203278573

Epoch: 6| Step: 12
Training loss: 2.6366662979125977
Validation loss: 2.0440976876084522

Epoch: 6| Step: 13
Training loss: 2.782546281814575
Validation loss: 2.056997101794007

Epoch: 200| Step: 0
Training loss: 1.6159522533416748
Validation loss: 2.0563804872574343

Epoch: 6| Step: 1
Training loss: 1.5975406169891357
Validation loss: 2.0543997082658993

Epoch: 6| Step: 2
Training loss: 1.8988142013549805
Validation loss: 2.035120394922072

Epoch: 6| Step: 3
Training loss: 3.026948928833008
Validation loss: 2.0578276470143306

Epoch: 6| Step: 4
Training loss: 2.9378280639648438
Validation loss: 2.090847763963925

Epoch: 6| Step: 5
Training loss: 1.6725995540618896
Validation loss: 2.0803186983190556

Epoch: 6| Step: 6
Training loss: 1.987139105796814
Validation loss: 2.069197670105965

Epoch: 6| Step: 7
Training loss: 1.8176960945129395
Validation loss: 2.0678840529534126

Epoch: 6| Step: 8
Training loss: 1.816130518913269
Validation loss: 2.0646328951722834

Epoch: 6| Step: 9
Training loss: 1.440202236175537
Validation loss: 2.0702427100109797

Epoch: 6| Step: 10
Training loss: 2.425835371017456
Validation loss: 2.067348062351186

Epoch: 6| Step: 11
Training loss: 1.500536561012268
Validation loss: 2.0793826503138386

Epoch: 6| Step: 12
Training loss: 1.5262162685394287
Validation loss: 2.0883815070634246

Epoch: 6| Step: 13
Training loss: 1.5322998762130737
Validation loss: 2.089773185791508

Epoch: 201| Step: 0
Training loss: 1.5625150203704834
Validation loss: 2.0938466774520053

Epoch: 6| Step: 1
Training loss: 2.1759848594665527
Validation loss: 2.076736655286563

Epoch: 6| Step: 2
Training loss: 1.8136125802993774
Validation loss: 2.0863862140204317

Epoch: 6| Step: 3
Training loss: 2.1386711597442627
Validation loss: 2.1092893577391103

Epoch: 6| Step: 4
Training loss: 2.018986701965332
Validation loss: 2.074402088760048

Epoch: 6| Step: 5
Training loss: 1.7598623037338257
Validation loss: 2.0832708843292727

Epoch: 6| Step: 6
Training loss: 1.788513422012329
Validation loss: 2.0954127760343653

Epoch: 6| Step: 7
Training loss: 1.2634671926498413
Validation loss: 2.07069391845375

Epoch: 6| Step: 8
Training loss: 1.6256272792816162
Validation loss: 2.0634531308245916

Epoch: 6| Step: 9
Training loss: 2.1128811836242676
Validation loss: 2.077645500500997

Epoch: 6| Step: 10
Training loss: 2.1772139072418213
Validation loss: 2.0692699545173237

Epoch: 6| Step: 11
Training loss: 2.3421974182128906
Validation loss: 2.094995719130321

Epoch: 6| Step: 12
Training loss: 2.0616703033447266
Validation loss: 2.0658608764730473

Epoch: 6| Step: 13
Training loss: 2.21956467628479
Validation loss: 2.0887385465765513

Epoch: 202| Step: 0
Training loss: 2.579035520553589
Validation loss: 2.0635494262941423

Epoch: 6| Step: 1
Training loss: 2.3471503257751465
Validation loss: 2.060246411190238

Epoch: 6| Step: 2
Training loss: 2.1718697547912598
Validation loss: 2.0620907596362534

Epoch: 6| Step: 3
Training loss: 2.5591087341308594
Validation loss: 2.06389965293228

Epoch: 6| Step: 4
Training loss: 1.0907491445541382
Validation loss: 2.0676567246837

Epoch: 6| Step: 5
Training loss: 1.9004089832305908
Validation loss: 2.078029276222311

Epoch: 6| Step: 6
Training loss: 1.4641550779342651
Validation loss: 2.062543697254632

Epoch: 6| Step: 7
Training loss: 2.204378604888916
Validation loss: 2.0701240672860095

Epoch: 6| Step: 8
Training loss: 1.5827867984771729
Validation loss: 2.0599049752758396

Epoch: 6| Step: 9
Training loss: 1.5858995914459229
Validation loss: 2.0549086011866087

Epoch: 6| Step: 10
Training loss: 2.0408105850219727
Validation loss: 2.089151563182954

Epoch: 6| Step: 11
Training loss: 1.7538423538208008
Validation loss: 2.0989386830278622

Epoch: 6| Step: 12
Training loss: 1.8061103820800781
Validation loss: 2.064229380699896

Epoch: 6| Step: 13
Training loss: 1.1689977645874023
Validation loss: 2.0711150182190763

Epoch: 203| Step: 0
Training loss: 2.224606990814209
Validation loss: 2.0467516965763544

Epoch: 6| Step: 1
Training loss: 1.989654779434204
Validation loss: 2.0712109534971175

Epoch: 6| Step: 2
Training loss: 2.1141412258148193
Validation loss: 2.075045790723575

Epoch: 6| Step: 3
Training loss: 1.7084722518920898
Validation loss: 2.0758560998465425

Epoch: 6| Step: 4
Training loss: 2.0465822219848633
Validation loss: 2.081069984743672

Epoch: 6| Step: 5
Training loss: 1.964594841003418
Validation loss: 2.0724651621234034

Epoch: 6| Step: 6
Training loss: 1.6198804378509521
Validation loss: 2.0762372196361585

Epoch: 6| Step: 7
Training loss: 2.0127100944519043
Validation loss: 2.0833160287590435

Epoch: 6| Step: 8
Training loss: 1.3848035335540771
Validation loss: 2.072005664148638

Epoch: 6| Step: 9
Training loss: 2.174137592315674
Validation loss: 2.058467049752512

Epoch: 6| Step: 10
Training loss: 2.1194138526916504
Validation loss: 2.0717742955812843

Epoch: 6| Step: 11
Training loss: 2.0590109825134277
Validation loss: 2.0970244510199434

Epoch: 6| Step: 12
Training loss: 1.6157234907150269
Validation loss: 2.055123888036256

Epoch: 6| Step: 13
Training loss: 1.3891263008117676
Validation loss: 2.053194974058418

Epoch: 204| Step: 0
Training loss: 2.504267692565918
Validation loss: 2.0399642503389748

Epoch: 6| Step: 1
Training loss: 1.7650823593139648
Validation loss: 2.073010083167784

Epoch: 6| Step: 2
Training loss: 1.532853364944458
Validation loss: 2.0433800502489974

Epoch: 6| Step: 3
Training loss: 2.6171960830688477
Validation loss: 2.0488403663840344

Epoch: 6| Step: 4
Training loss: 1.5977108478546143
Validation loss: 2.055280000932755

Epoch: 6| Step: 5
Training loss: 2.0503196716308594
Validation loss: 2.0391302903493247

Epoch: 6| Step: 6
Training loss: 2.0587944984436035
Validation loss: 2.0585174919456564

Epoch: 6| Step: 7
Training loss: 1.3577077388763428
Validation loss: 2.0642705181593537

Epoch: 6| Step: 8
Training loss: 1.9049983024597168
Validation loss: 2.054535787592652

Epoch: 6| Step: 9
Training loss: 2.1212081909179688
Validation loss: 2.0786227192929996

Epoch: 6| Step: 10
Training loss: 1.4418447017669678
Validation loss: 2.0392874799748903

Epoch: 6| Step: 11
Training loss: 2.3981730937957764
Validation loss: 2.047423788296279

Epoch: 6| Step: 12
Training loss: 1.4490725994110107
Validation loss: 2.0583315715994885

Epoch: 6| Step: 13
Training loss: 1.9113878011703491
Validation loss: 2.101641721622918

Epoch: 205| Step: 0
Training loss: 2.2366585731506348
Validation loss: 2.0785145221217984

Epoch: 6| Step: 1
Training loss: 1.3645727634429932
Validation loss: 2.0824476262574554

Epoch: 6| Step: 2
Training loss: 1.5236396789550781
Validation loss: 2.0771026457509687

Epoch: 6| Step: 3
Training loss: 2.0170669555664062
Validation loss: 2.0659312176448044

Epoch: 6| Step: 4
Training loss: 2.2302303314208984
Validation loss: 2.1060155386565835

Epoch: 6| Step: 5
Training loss: 2.156785011291504
Validation loss: 2.071356693903605

Epoch: 6| Step: 6
Training loss: 1.6610811948776245
Validation loss: 2.0584883228425057

Epoch: 6| Step: 7
Training loss: 1.4020484685897827
Validation loss: 2.097963236993359

Epoch: 6| Step: 8
Training loss: 2.6677260398864746
Validation loss: 2.089423052726253

Epoch: 6| Step: 9
Training loss: 1.6507214307785034
Validation loss: 2.076527160982932

Epoch: 6| Step: 10
Training loss: 1.8483915328979492
Validation loss: 2.09864705352373

Epoch: 6| Step: 11
Training loss: 1.7827832698822021
Validation loss: 2.0719053540178525

Epoch: 6| Step: 12
Training loss: 1.8392281532287598
Validation loss: 2.0726605717853834

Epoch: 6| Step: 13
Training loss: 2.3284382820129395
Validation loss: 2.0699080318532963

Epoch: 206| Step: 0
Training loss: 1.5138167142868042
Validation loss: 2.0645882801343034

Epoch: 6| Step: 1
Training loss: 1.8640717267990112
Validation loss: 2.056050741544334

Epoch: 6| Step: 2
Training loss: 2.0155274868011475
Validation loss: 2.043895131798201

Epoch: 6| Step: 3
Training loss: 1.400882601737976
Validation loss: 2.0593943377976776

Epoch: 6| Step: 4
Training loss: 1.7472416162490845
Validation loss: 2.054301408029372

Epoch: 6| Step: 5
Training loss: 1.7077951431274414
Validation loss: 2.0803778094630085

Epoch: 6| Step: 6
Training loss: 2.1419291496276855
Validation loss: 2.0790979580212663

Epoch: 6| Step: 7
Training loss: 1.2451790571212769
Validation loss: 2.0784952999443136

Epoch: 6| Step: 8
Training loss: 1.9386305809020996
Validation loss: 2.0738701089735954

Epoch: 6| Step: 9
Training loss: 1.9192997217178345
Validation loss: 2.058728305242395

Epoch: 6| Step: 10
Training loss: 2.668114185333252
Validation loss: 2.070481692591021

Epoch: 6| Step: 11
Training loss: 1.5494506359100342
Validation loss: 2.0584542520584597

Epoch: 6| Step: 12
Training loss: 2.143486261367798
Validation loss: 2.0857510079619703

Epoch: 6| Step: 13
Training loss: 3.5740575790405273
Validation loss: 2.08324626440643

Epoch: 207| Step: 0
Training loss: 2.674657106399536
Validation loss: 2.0736000614781536

Epoch: 6| Step: 1
Training loss: 1.8073796033859253
Validation loss: 2.064611550300352

Epoch: 6| Step: 2
Training loss: 1.6451377868652344
Validation loss: 2.042819220532653

Epoch: 6| Step: 3
Training loss: 1.8241944313049316
Validation loss: 2.0651344688989783

Epoch: 6| Step: 4
Training loss: 1.6831068992614746
Validation loss: 2.0547635042539207

Epoch: 6| Step: 5
Training loss: 2.32914400100708
Validation loss: 2.068631408035114

Epoch: 6| Step: 6
Training loss: 2.3100287914276123
Validation loss: 2.080039467862857

Epoch: 6| Step: 7
Training loss: 1.6335750818252563
Validation loss: 2.0633225287160566

Epoch: 6| Step: 8
Training loss: 1.7127145528793335
Validation loss: 2.089458978304299

Epoch: 6| Step: 9
Training loss: 1.5790925025939941
Validation loss: 2.051522301089379

Epoch: 6| Step: 10
Training loss: 1.3015245199203491
Validation loss: 2.0622221859552528

Epoch: 6| Step: 11
Training loss: 2.527395248413086
Validation loss: 2.0661949649933846

Epoch: 6| Step: 12
Training loss: 1.870263934135437
Validation loss: 2.04567059522034

Epoch: 6| Step: 13
Training loss: 2.041304588317871
Validation loss: 2.04700832469489

Epoch: 208| Step: 0
Training loss: 1.959089994430542
Validation loss: 2.0612652404333955

Epoch: 6| Step: 1
Training loss: 1.7748489379882812
Validation loss: 2.0640512845849477

Epoch: 6| Step: 2
Training loss: 1.9533319473266602
Validation loss: 2.0545185189093313

Epoch: 6| Step: 3
Training loss: 2.585397720336914
Validation loss: 2.066307266553243

Epoch: 6| Step: 4
Training loss: 1.4356000423431396
Validation loss: 2.0541937710136495

Epoch: 6| Step: 5
Training loss: 1.2403229475021362
Validation loss: 2.065128227715851

Epoch: 6| Step: 6
Training loss: 2.0888261795043945
Validation loss: 2.0622319303533083

Epoch: 6| Step: 7
Training loss: 2.4540770053863525
Validation loss: 2.0562587873910063

Epoch: 6| Step: 8
Training loss: 1.4919027090072632
Validation loss: 2.0724062586343415

Epoch: 6| Step: 9
Training loss: 2.081552505493164
Validation loss: 2.054919186458793

Epoch: 6| Step: 10
Training loss: 1.753913164138794
Validation loss: 2.0632528028180523

Epoch: 6| Step: 11
Training loss: 1.9398362636566162
Validation loss: 2.051587890553218

Epoch: 6| Step: 12
Training loss: 2.1154556274414062
Validation loss: 2.062234442721131

Epoch: 6| Step: 13
Training loss: 1.6917814016342163
Validation loss: 2.038924901716171

Epoch: 209| Step: 0
Training loss: 1.4931087493896484
Validation loss: 2.0778288764338337

Epoch: 6| Step: 1
Training loss: 2.104006290435791
Validation loss: 2.045070722538938

Epoch: 6| Step: 2
Training loss: 1.9298412799835205
Validation loss: 2.0598720530027985

Epoch: 6| Step: 3
Training loss: 2.2073023319244385
Validation loss: 2.0625535006164224

Epoch: 6| Step: 4
Training loss: 1.7445859909057617
Validation loss: 2.067044855445944

Epoch: 6| Step: 5
Training loss: 2.260768175125122
Validation loss: 2.0734487041350333

Epoch: 6| Step: 6
Training loss: 2.1481428146362305
Validation loss: 2.0835914586179998

Epoch: 6| Step: 7
Training loss: 1.8734872341156006
Validation loss: 2.089119501011346

Epoch: 6| Step: 8
Training loss: 1.6343951225280762
Validation loss: 2.0531948843309955

Epoch: 6| Step: 9
Training loss: 1.7630605697631836
Validation loss: 2.086371406432121

Epoch: 6| Step: 10
Training loss: 1.866875171661377
Validation loss: 2.095136529655867

Epoch: 6| Step: 11
Training loss: 1.0436122417449951
Validation loss: 2.0705204574010705

Epoch: 6| Step: 12
Training loss: 2.03283429145813
Validation loss: 2.084057697685816

Epoch: 6| Step: 13
Training loss: 2.9274964332580566
Validation loss: 2.0982791249470045

Epoch: 210| Step: 0
Training loss: 1.780726671218872
Validation loss: 2.104393656535815

Epoch: 6| Step: 1
Training loss: 2.483823537826538
Validation loss: 2.0752260351693756

Epoch: 6| Step: 2
Training loss: 1.245237112045288
Validation loss: 2.064944662073607

Epoch: 6| Step: 3
Training loss: 2.0289359092712402
Validation loss: 2.0700356011749594

Epoch: 6| Step: 4
Training loss: 2.495857000350952
Validation loss: 2.0854819577227355

Epoch: 6| Step: 5
Training loss: 2.2159106731414795
Validation loss: 2.0817692125997236

Epoch: 6| Step: 6
Training loss: 1.3660728931427002
Validation loss: 2.0830632755833287

Epoch: 6| Step: 7
Training loss: 2.1538281440734863
Validation loss: 2.0868904975152787

Epoch: 6| Step: 8
Training loss: 2.5268945693969727
Validation loss: 2.078935738532774

Epoch: 6| Step: 9
Training loss: 1.5518341064453125
Validation loss: 2.08572014557418

Epoch: 6| Step: 10
Training loss: 2.0915231704711914
Validation loss: 2.09904077488889

Epoch: 6| Step: 11
Training loss: 1.4477084875106812
Validation loss: 2.0899101598288423

Epoch: 6| Step: 12
Training loss: 1.8699817657470703
Validation loss: 2.1033457120259604

Epoch: 6| Step: 13
Training loss: 0.9900402426719666
Validation loss: 2.0812390786345287

Epoch: 211| Step: 0
Training loss: 2.2133007049560547
Validation loss: 2.073278163069038

Epoch: 6| Step: 1
Training loss: 1.1881847381591797
Validation loss: 2.085694666831724

Epoch: 6| Step: 2
Training loss: 2.4196834564208984
Validation loss: 2.0707484624719106

Epoch: 6| Step: 3
Training loss: 1.5681507587432861
Validation loss: 2.0927661759879

Epoch: 6| Step: 4
Training loss: 2.139395236968994
Validation loss: 2.0660065348430345

Epoch: 6| Step: 5
Training loss: 2.0357625484466553
Validation loss: 2.0343893984312653

Epoch: 6| Step: 6
Training loss: 2.214200496673584
Validation loss: 2.0604837248402257

Epoch: 6| Step: 7
Training loss: 1.867049217224121
Validation loss: 2.051214723176854

Epoch: 6| Step: 8
Training loss: 1.564847469329834
Validation loss: 2.059919875155213

Epoch: 6| Step: 9
Training loss: 2.2334768772125244
Validation loss: 2.0723498700767435

Epoch: 6| Step: 10
Training loss: 1.134279489517212
Validation loss: 2.057249023068336

Epoch: 6| Step: 11
Training loss: 1.726743459701538
Validation loss: 2.070534671506574

Epoch: 6| Step: 12
Training loss: 2.6141140460968018
Validation loss: 2.021647878872451

Epoch: 6| Step: 13
Training loss: 1.723610758781433
Validation loss: 2.0669964564743863

Epoch: 212| Step: 0
Training loss: 1.6194353103637695
Validation loss: 2.067530573055308

Epoch: 6| Step: 1
Training loss: 1.9286119937896729
Validation loss: 2.0743268279619116

Epoch: 6| Step: 2
Training loss: 1.9169702529907227
Validation loss: 2.0618218388608707

Epoch: 6| Step: 3
Training loss: 2.5645618438720703
Validation loss: 2.072231250424539

Epoch: 6| Step: 4
Training loss: 2.045185089111328
Validation loss: 2.0848739813732844

Epoch: 6| Step: 5
Training loss: 1.8780667781829834
Validation loss: 2.0852142803130613

Epoch: 6| Step: 6
Training loss: 1.923452377319336
Validation loss: 2.1049872444521998

Epoch: 6| Step: 7
Training loss: 2.448932647705078
Validation loss: 2.119856128128626

Epoch: 6| Step: 8
Training loss: 1.9470629692077637
Validation loss: 2.1104048144432808

Epoch: 6| Step: 9
Training loss: 1.9293336868286133
Validation loss: 2.0683043438901185

Epoch: 6| Step: 10
Training loss: 2.0103225708007812
Validation loss: 2.105224940084642

Epoch: 6| Step: 11
Training loss: 1.4657776355743408
Validation loss: 2.085128764952383

Epoch: 6| Step: 12
Training loss: 1.326249361038208
Validation loss: 2.0704701292899346

Epoch: 6| Step: 13
Training loss: 1.399248480796814
Validation loss: 2.084999067808992

Epoch: 213| Step: 0
Training loss: 1.5232787132263184
Validation loss: 2.091279773301976

Epoch: 6| Step: 1
Training loss: 1.817207932472229
Validation loss: 2.055579311104231

Epoch: 6| Step: 2
Training loss: 1.603288173675537
Validation loss: 2.0534171160831245

Epoch: 6| Step: 3
Training loss: 2.219919443130493
Validation loss: 2.0838349442328177

Epoch: 6| Step: 4
Training loss: 2.0684432983398438
Validation loss: 2.061682503710511

Epoch: 6| Step: 5
Training loss: 1.9501464366912842
Validation loss: 2.0686772010659658

Epoch: 6| Step: 6
Training loss: 1.6669563055038452
Validation loss: 2.0572261297574608

Epoch: 6| Step: 7
Training loss: 1.869433879852295
Validation loss: 2.067040357538449

Epoch: 6| Step: 8
Training loss: 2.2251389026641846
Validation loss: 2.077219142708727

Epoch: 6| Step: 9
Training loss: 2.0291848182678223
Validation loss: 2.067397872606913

Epoch: 6| Step: 10
Training loss: 1.6788063049316406
Validation loss: 2.0537489883361326

Epoch: 6| Step: 11
Training loss: 1.9166524410247803
Validation loss: 2.0802016732513264

Epoch: 6| Step: 12
Training loss: 1.995466709136963
Validation loss: 2.077139328884822

Epoch: 6| Step: 13
Training loss: 1.9832861423492432
Validation loss: 2.0588228561544932

Epoch: 214| Step: 0
Training loss: 1.5799391269683838
Validation loss: 2.086009443447154

Epoch: 6| Step: 1
Training loss: 2.298570156097412
Validation loss: 2.063975300840152

Epoch: 6| Step: 2
Training loss: 1.6482818126678467
Validation loss: 2.0729406495248117

Epoch: 6| Step: 3
Training loss: 2.94632625579834
Validation loss: 2.076287184992144

Epoch: 6| Step: 4
Training loss: 1.6101199388504028
Validation loss: 2.061889945819814

Epoch: 6| Step: 5
Training loss: 1.7204355001449585
Validation loss: 2.0765686778612036

Epoch: 6| Step: 6
Training loss: 2.153743028640747
Validation loss: 2.0757412500278924

Epoch: 6| Step: 7
Training loss: 1.8615248203277588
Validation loss: 2.0650847381161106

Epoch: 6| Step: 8
Training loss: 1.9215195178985596
Validation loss: 2.0791740161116405

Epoch: 6| Step: 9
Training loss: 1.6834912300109863
Validation loss: 2.062433783726026

Epoch: 6| Step: 10
Training loss: 1.2668434381484985
Validation loss: 2.046640544809321

Epoch: 6| Step: 11
Training loss: 1.6379221677780151
Validation loss: 2.0552968568699335

Epoch: 6| Step: 12
Training loss: 2.764360189437866
Validation loss: 2.0874276827740412

Epoch: 6| Step: 13
Training loss: 1.2719670534133911
Validation loss: 2.033621226587603

Epoch: 215| Step: 0
Training loss: 1.9768131971359253
Validation loss: 2.071312778739519

Epoch: 6| Step: 1
Training loss: 1.8739668130874634
Validation loss: 2.071176871176689

Epoch: 6| Step: 2
Training loss: 1.8469951152801514
Validation loss: 2.0798102296808714

Epoch: 6| Step: 3
Training loss: 1.916456699371338
Validation loss: 2.0857614573612007

Epoch: 6| Step: 4
Training loss: 1.7383861541748047
Validation loss: 2.1073285174626175

Epoch: 6| Step: 5
Training loss: 2.043200969696045
Validation loss: 2.0998815797990367

Epoch: 6| Step: 6
Training loss: 1.4696791172027588
Validation loss: 2.1024540265401206

Epoch: 6| Step: 7
Training loss: 1.7465137243270874
Validation loss: 2.0675707529949885

Epoch: 6| Step: 8
Training loss: 1.687517762184143
Validation loss: 2.086576738665181

Epoch: 6| Step: 9
Training loss: 2.6806464195251465
Validation loss: 2.06855079179169

Epoch: 6| Step: 10
Training loss: 1.6812982559204102
Validation loss: 2.0988208350314888

Epoch: 6| Step: 11
Training loss: 2.145064115524292
Validation loss: 2.0511569220532655

Epoch: 6| Step: 12
Training loss: 1.4945379495620728
Validation loss: 2.0721722495171333

Epoch: 6| Step: 13
Training loss: 2.2149863243103027
Validation loss: 2.0711744139271397

Epoch: 216| Step: 0
Training loss: 2.1114139556884766
Validation loss: 2.046834535496209

Epoch: 6| Step: 1
Training loss: 2.1864013671875
Validation loss: 2.0765751946356987

Epoch: 6| Step: 2
Training loss: 2.4545493125915527
Validation loss: 2.0621970725315872

Epoch: 6| Step: 3
Training loss: 1.6548320055007935
Validation loss: 2.0818693586575088

Epoch: 6| Step: 4
Training loss: 1.6335909366607666
Validation loss: 2.0554889248263453

Epoch: 6| Step: 5
Training loss: 1.7176706790924072
Validation loss: 2.073360607188235

Epoch: 6| Step: 6
Training loss: 1.9458054304122925
Validation loss: 2.0990588062552997

Epoch: 6| Step: 7
Training loss: 1.7006044387817383
Validation loss: 2.0465009161221084

Epoch: 6| Step: 8
Training loss: 1.7712116241455078
Validation loss: 2.092262755158127

Epoch: 6| Step: 9
Training loss: 1.7996494770050049
Validation loss: 2.0809876085609518

Epoch: 6| Step: 10
Training loss: 1.5110000371932983
Validation loss: 2.060737666263375

Epoch: 6| Step: 11
Training loss: 2.519155740737915
Validation loss: 2.03890121880398

Epoch: 6| Step: 12
Training loss: 1.767297625541687
Validation loss: 2.0540359507324877

Epoch: 6| Step: 13
Training loss: 1.4209586381912231
Validation loss: 2.0646929522996307

Epoch: 217| Step: 0
Training loss: 2.152592182159424
Validation loss: 2.0802810961200344

Epoch: 6| Step: 1
Training loss: 2.00577449798584
Validation loss: 2.0856873104649205

Epoch: 6| Step: 2
Training loss: 1.1274869441986084
Validation loss: 2.059166951846051

Epoch: 6| Step: 3
Training loss: 2.3892693519592285
Validation loss: 2.028342282900246

Epoch: 6| Step: 4
Training loss: 1.3393903970718384
Validation loss: 2.077065388361613

Epoch: 6| Step: 5
Training loss: 2.086704969406128
Validation loss: 2.04658660581035

Epoch: 6| Step: 6
Training loss: 2.5576837062835693
Validation loss: 2.039666873152538

Epoch: 6| Step: 7
Training loss: 1.7526066303253174
Validation loss: 2.073893298384964

Epoch: 6| Step: 8
Training loss: 2.166764974594116
Validation loss: 2.055947699854451

Epoch: 6| Step: 9
Training loss: 2.6059532165527344
Validation loss: 2.0755370188784856

Epoch: 6| Step: 10
Training loss: 1.5398337841033936
Validation loss: 2.070365874998031

Epoch: 6| Step: 11
Training loss: 1.5888607501983643
Validation loss: 2.083152817141625

Epoch: 6| Step: 12
Training loss: 1.4548273086547852
Validation loss: 2.0615207251682075

Epoch: 6| Step: 13
Training loss: 1.9387531280517578
Validation loss: 2.055009829100742

Epoch: 218| Step: 0
Training loss: 1.5662851333618164
Validation loss: 2.021483452089371

Epoch: 6| Step: 1
Training loss: 1.9951131343841553
Validation loss: 2.039771032589738

Epoch: 6| Step: 2
Training loss: 1.6773583889007568
Validation loss: 2.075103057328091

Epoch: 6| Step: 3
Training loss: 2.061069965362549
Validation loss: 2.061936632279427

Epoch: 6| Step: 4
Training loss: 2.1267075538635254
Validation loss: 2.083260743848739

Epoch: 6| Step: 5
Training loss: 1.529528021812439
Validation loss: 2.088605203936177

Epoch: 6| Step: 6
Training loss: 2.646801471710205
Validation loss: 2.1093379259109497

Epoch: 6| Step: 7
Training loss: 1.340627670288086
Validation loss: 2.120664806776149

Epoch: 6| Step: 8
Training loss: 2.523526191711426
Validation loss: 2.1291825771331787

Epoch: 6| Step: 9
Training loss: 1.724692702293396
Validation loss: 2.104338397261917

Epoch: 6| Step: 10
Training loss: 1.890428900718689
Validation loss: 2.1025973237970823

Epoch: 6| Step: 11
Training loss: 1.8218783140182495
Validation loss: 2.098053882198949

Epoch: 6| Step: 12
Training loss: 1.544864296913147
Validation loss: 2.106555638774749

Epoch: 6| Step: 13
Training loss: 2.4326601028442383
Validation loss: 2.0867421165589364

Epoch: 219| Step: 0
Training loss: 1.5714094638824463
Validation loss: 2.0910426275704497

Epoch: 6| Step: 1
Training loss: 1.9906582832336426
Validation loss: 2.0892292709760767

Epoch: 6| Step: 2
Training loss: 1.7979183197021484
Validation loss: 2.1169459307065575

Epoch: 6| Step: 3
Training loss: 1.8959821462631226
Validation loss: 2.099214350023577

Epoch: 6| Step: 4
Training loss: 1.7639600038528442
Validation loss: 2.071611406982586

Epoch: 6| Step: 5
Training loss: 2.1726815700531006
Validation loss: 2.1035958079881567

Epoch: 6| Step: 6
Training loss: 1.5898200273513794
Validation loss: 2.0733139745650755

Epoch: 6| Step: 7
Training loss: 2.1077890396118164
Validation loss: 2.096290211523733

Epoch: 6| Step: 8
Training loss: 1.609506607055664
Validation loss: 2.0943363148679017

Epoch: 6| Step: 9
Training loss: 1.589461088180542
Validation loss: 2.098871818152807

Epoch: 6| Step: 10
Training loss: 2.217129945755005
Validation loss: 2.0668912549172678

Epoch: 6| Step: 11
Training loss: 1.6775747537612915
Validation loss: 2.093403482949862

Epoch: 6| Step: 12
Training loss: 2.162952184677124
Validation loss: 2.0789258454435613

Epoch: 6| Step: 13
Training loss: 2.422964096069336
Validation loss: 2.0438780553879274

Epoch: 220| Step: 0
Training loss: 2.20522403717041
Validation loss: 2.076402715457383

Epoch: 6| Step: 1
Training loss: 1.5869319438934326
Validation loss: 2.0618637761762066

Epoch: 6| Step: 2
Training loss: 1.819553256034851
Validation loss: 2.053519013107464

Epoch: 6| Step: 3
Training loss: 2.1722252368927
Validation loss: 2.053409921225681

Epoch: 6| Step: 4
Training loss: 1.9106167554855347
Validation loss: 2.0656330764934583

Epoch: 6| Step: 5
Training loss: 1.4650123119354248
Validation loss: 2.054991300388049

Epoch: 6| Step: 6
Training loss: 1.8091516494750977
Validation loss: 2.103057889528172

Epoch: 6| Step: 7
Training loss: 2.391026735305786
Validation loss: 2.0454614752082416

Epoch: 6| Step: 8
Training loss: 2.355311870574951
Validation loss: 2.0755770155178603

Epoch: 6| Step: 9
Training loss: 1.9524908065795898
Validation loss: 2.04184796989605

Epoch: 6| Step: 10
Training loss: 2.116608142852783
Validation loss: 2.066165480562436

Epoch: 6| Step: 11
Training loss: 1.252028465270996
Validation loss: 2.05389202666539

Epoch: 6| Step: 12
Training loss: 2.1608352661132812
Validation loss: 2.0344743356909802

Epoch: 6| Step: 13
Training loss: 1.4875435829162598
Validation loss: 2.086047713474561

Epoch: 221| Step: 0
Training loss: 1.9640905857086182
Validation loss: 2.106821629308885

Epoch: 6| Step: 1
Training loss: 1.4362514019012451
Validation loss: 2.076142364932645

Epoch: 6| Step: 2
Training loss: 1.712526798248291
Validation loss: 2.089327355866791

Epoch: 6| Step: 3
Training loss: 1.974644422531128
Validation loss: 2.081676998446065

Epoch: 6| Step: 4
Training loss: 1.8858792781829834
Validation loss: 2.082588898238315

Epoch: 6| Step: 5
Training loss: 2.150628089904785
Validation loss: 2.0875499197231826

Epoch: 6| Step: 6
Training loss: 2.2017719745635986
Validation loss: 2.108738436493822

Epoch: 6| Step: 7
Training loss: 1.8856356143951416
Validation loss: 2.0928171091182257

Epoch: 6| Step: 8
Training loss: 1.5793042182922363
Validation loss: 2.1147178680666032

Epoch: 6| Step: 9
Training loss: 1.6236679553985596
Validation loss: 2.091037332370717

Epoch: 6| Step: 10
Training loss: 1.509864330291748
Validation loss: 2.119563228340559

Epoch: 6| Step: 11
Training loss: 2.7174324989318848
Validation loss: 2.1025449229824926

Epoch: 6| Step: 12
Training loss: 2.1041243076324463
Validation loss: 2.1221047216846096

Epoch: 6| Step: 13
Training loss: 1.5408107042312622
Validation loss: 2.0892000224000666

Epoch: 222| Step: 0
Training loss: 1.997113823890686
Validation loss: 2.097167379112654

Epoch: 6| Step: 1
Training loss: 1.740780234336853
Validation loss: 2.0581083464366134

Epoch: 6| Step: 2
Training loss: 2.2997419834136963
Validation loss: 2.0976647125777377

Epoch: 6| Step: 3
Training loss: 1.6559728384017944
Validation loss: 2.0456953638343403

Epoch: 6| Step: 4
Training loss: 2.6992621421813965
Validation loss: 2.0782056867435412

Epoch: 6| Step: 5
Training loss: 1.656484603881836
Validation loss: 2.077197549163654

Epoch: 6| Step: 6
Training loss: 1.3908522129058838
Validation loss: 2.057536713538631

Epoch: 6| Step: 7
Training loss: 1.5068457126617432
Validation loss: 2.076488317981843

Epoch: 6| Step: 8
Training loss: 1.8105899095535278
Validation loss: 2.089701980672857

Epoch: 6| Step: 9
Training loss: 1.764221429824829
Validation loss: 2.049290032796962

Epoch: 6| Step: 10
Training loss: 2.588684558868408
Validation loss: 2.0607214832818634

Epoch: 6| Step: 11
Training loss: 1.0420947074890137
Validation loss: 2.0659267825465046

Epoch: 6| Step: 12
Training loss: 2.023218870162964
Validation loss: 2.0797535834773893

Epoch: 6| Step: 13
Training loss: 2.2806787490844727
Validation loss: 2.0593225930326726

Epoch: 223| Step: 0
Training loss: 0.966941237449646
Validation loss: 2.066919861301299

Epoch: 6| Step: 1
Training loss: 2.534208297729492
Validation loss: 2.0901904541959047

Epoch: 6| Step: 2
Training loss: 2.2758634090423584
Validation loss: 2.0657008168517903

Epoch: 6| Step: 3
Training loss: 1.3217847347259521
Validation loss: 2.0653064930310814

Epoch: 6| Step: 4
Training loss: 2.1255557537078857
Validation loss: 2.0847238327867244

Epoch: 6| Step: 5
Training loss: 2.4595868587493896
Validation loss: 2.054100703167659

Epoch: 6| Step: 6
Training loss: 2.415555953979492
Validation loss: 2.08882886363614

Epoch: 6| Step: 7
Training loss: 1.8194043636322021
Validation loss: 2.0904776101471274

Epoch: 6| Step: 8
Training loss: 1.5266226530075073
Validation loss: 2.087011993572276

Epoch: 6| Step: 9
Training loss: 2.2594990730285645
Validation loss: 2.0873556419085433

Epoch: 6| Step: 10
Training loss: 1.567046880722046
Validation loss: 2.0617062378955144

Epoch: 6| Step: 11
Training loss: 1.9029200077056885
Validation loss: 2.0634539255531887

Epoch: 6| Step: 12
Training loss: 1.6735550165176392
Validation loss: 2.081178985616212

Epoch: 6| Step: 13
Training loss: 0.873972475528717
Validation loss: 2.0822582039781796

Epoch: 224| Step: 0
Training loss: 1.1885710954666138
Validation loss: 2.0931694430689656

Epoch: 6| Step: 1
Training loss: 1.1690587997436523
Validation loss: 2.074756622314453

Epoch: 6| Step: 2
Training loss: 2.062612533569336
Validation loss: 2.112966340075257

Epoch: 6| Step: 3
Training loss: 2.270911455154419
Validation loss: 2.071533956835347

Epoch: 6| Step: 4
Training loss: 1.891388177871704
Validation loss: 2.090092582087363

Epoch: 6| Step: 5
Training loss: 2.108668327331543
Validation loss: 2.0730089705477477

Epoch: 6| Step: 6
Training loss: 1.6170355081558228
Validation loss: 2.055978972424743

Epoch: 6| Step: 7
Training loss: 2.2124741077423096
Validation loss: 2.062909572355209

Epoch: 6| Step: 8
Training loss: 1.9274853467941284
Validation loss: 2.0999371877280613

Epoch: 6| Step: 9
Training loss: 2.082794189453125
Validation loss: 2.06752945018071

Epoch: 6| Step: 10
Training loss: 1.8842122554779053
Validation loss: 2.0810521571866927

Epoch: 6| Step: 11
Training loss: 2.2221429347991943
Validation loss: 2.0996143715355986

Epoch: 6| Step: 12
Training loss: 1.8106536865234375
Validation loss: 2.071129746334527

Epoch: 6| Step: 13
Training loss: 1.3808798789978027
Validation loss: 2.0710344596575667

Epoch: 225| Step: 0
Training loss: 2.305253505706787
Validation loss: 2.0935844529059624

Epoch: 6| Step: 1
Training loss: 1.8019472360610962
Validation loss: 2.0668446684396393

Epoch: 6| Step: 2
Training loss: 1.6977055072784424
Validation loss: 2.066563480643816

Epoch: 6| Step: 3
Training loss: 2.2507431507110596
Validation loss: 2.0895041701614216

Epoch: 6| Step: 4
Training loss: 1.5484566688537598
Validation loss: 2.0712669908359485

Epoch: 6| Step: 5
Training loss: 1.2316584587097168
Validation loss: 2.074942147859963

Epoch: 6| Step: 6
Training loss: 2.0028090476989746
Validation loss: 2.078116334894652

Epoch: 6| Step: 7
Training loss: 1.5922555923461914
Validation loss: 2.0637395330654678

Epoch: 6| Step: 8
Training loss: 1.5383777618408203
Validation loss: 2.0751176777706353

Epoch: 6| Step: 9
Training loss: 1.5057073831558228
Validation loss: 2.0525898138682046

Epoch: 6| Step: 10
Training loss: 1.8672983646392822
Validation loss: 2.0650898051518265

Epoch: 6| Step: 11
Training loss: 2.414992094039917
Validation loss: 2.0938441368841354

Epoch: 6| Step: 12
Training loss: 2.48759126663208
Validation loss: 2.094253452875281

Epoch: 6| Step: 13
Training loss: 1.7576631307601929
Validation loss: 2.070356156236382

Epoch: 226| Step: 0
Training loss: 1.4921737909317017
Validation loss: 2.087876472421872

Epoch: 6| Step: 1
Training loss: 1.6394572257995605
Validation loss: 2.0765671255767986

Epoch: 6| Step: 2
Training loss: 1.9443672895431519
Validation loss: 2.1310631254667878

Epoch: 6| Step: 3
Training loss: 1.635597586631775
Validation loss: 2.094866111714353

Epoch: 6| Step: 4
Training loss: 2.606079578399658
Validation loss: 2.0830220278873237

Epoch: 6| Step: 5
Training loss: 1.6161558628082275
Validation loss: 2.1096019052690074

Epoch: 6| Step: 6
Training loss: 2.5160999298095703
Validation loss: 2.1055650659786758

Epoch: 6| Step: 7
Training loss: 1.6382976770401
Validation loss: 2.1062409749595066

Epoch: 6| Step: 8
Training loss: 1.4207148551940918
Validation loss: 2.122224405247678

Epoch: 6| Step: 9
Training loss: 2.2454631328582764
Validation loss: 2.0812535080858456

Epoch: 6| Step: 10
Training loss: 1.4893043041229248
Validation loss: 2.079341342372279

Epoch: 6| Step: 11
Training loss: 2.321223258972168
Validation loss: 2.060585524446221

Epoch: 6| Step: 12
Training loss: 1.612441062927246
Validation loss: 2.081393687955795

Epoch: 6| Step: 13
Training loss: 1.6025534868240356
Validation loss: 2.054087551691199

Epoch: 227| Step: 0
Training loss: 1.9926931858062744
Validation loss: 2.0552260901338313

Epoch: 6| Step: 1
Training loss: 2.0902323722839355
Validation loss: 2.0980024953042307

Epoch: 6| Step: 2
Training loss: 1.4809023141860962
Validation loss: 2.079414462530485

Epoch: 6| Step: 3
Training loss: 2.0468361377716064
Validation loss: 2.07513036394632

Epoch: 6| Step: 4
Training loss: 1.9570472240447998
Validation loss: 2.0755832041463544

Epoch: 6| Step: 5
Training loss: 1.3866188526153564
Validation loss: 2.0583922709188154

Epoch: 6| Step: 6
Training loss: 2.2948546409606934
Validation loss: 2.0122896458512995

Epoch: 6| Step: 7
Training loss: 2.6238837242126465
Validation loss: 2.0959996818214335

Epoch: 6| Step: 8
Training loss: 1.9071192741394043
Validation loss: 2.0687132112441526

Epoch: 6| Step: 9
Training loss: 1.3280589580535889
Validation loss: 2.0509266955878145

Epoch: 6| Step: 10
Training loss: 2.144289016723633
Validation loss: 2.0560608051156484

Epoch: 6| Step: 11
Training loss: 1.9955832958221436
Validation loss: 2.0568785282873336

Epoch: 6| Step: 12
Training loss: 1.4271386861801147
Validation loss: 2.058312931368428

Epoch: 6| Step: 13
Training loss: 1.3536359071731567
Validation loss: 2.1035627806058494

Epoch: 228| Step: 0
Training loss: 1.322587251663208
Validation loss: 2.0804082142409457

Epoch: 6| Step: 1
Training loss: 2.250269889831543
Validation loss: 2.104849671804777

Epoch: 6| Step: 2
Training loss: 1.8354792594909668
Validation loss: 2.0813797289325344

Epoch: 6| Step: 3
Training loss: 1.500356674194336
Validation loss: 2.0839508438623078

Epoch: 6| Step: 4
Training loss: 1.0758674144744873
Validation loss: 2.1019145160593014

Epoch: 6| Step: 5
Training loss: 2.2289786338806152
Validation loss: 2.0804021025216706

Epoch: 6| Step: 6
Training loss: 1.6504096984863281
Validation loss: 2.081432789884588

Epoch: 6| Step: 7
Training loss: 2.241372585296631
Validation loss: 2.1134946410373976

Epoch: 6| Step: 8
Training loss: 2.006303310394287
Validation loss: 2.0875449693331154

Epoch: 6| Step: 9
Training loss: 2.0888724327087402
Validation loss: 2.09278271531546

Epoch: 6| Step: 10
Training loss: 1.59109628200531
Validation loss: 2.0623864345653082

Epoch: 6| Step: 11
Training loss: 1.7359082698822021
Validation loss: 2.0890650800479356

Epoch: 6| Step: 12
Training loss: 2.6881937980651855
Validation loss: 2.089370664729867

Epoch: 6| Step: 13
Training loss: 1.7012852430343628
Validation loss: 2.090617387525497

Epoch: 229| Step: 0
Training loss: 2.4167184829711914
Validation loss: 2.105903676761094

Epoch: 6| Step: 1
Training loss: 2.00321888923645
Validation loss: 2.081350795684322

Epoch: 6| Step: 2
Training loss: 1.3121274709701538
Validation loss: 2.0832320759373326

Epoch: 6| Step: 3
Training loss: 1.6944348812103271
Validation loss: 2.094822624678253

Epoch: 6| Step: 4
Training loss: 1.2351057529449463
Validation loss: 2.0855447194909535

Epoch: 6| Step: 5
Training loss: 1.740868091583252
Validation loss: 2.0836269394043954

Epoch: 6| Step: 6
Training loss: 2.224639892578125
Validation loss: 2.095440641526253

Epoch: 6| Step: 7
Training loss: 1.6218173503875732
Validation loss: 2.108292602723645

Epoch: 6| Step: 8
Training loss: 2.344209909439087
Validation loss: 2.06440911369939

Epoch: 6| Step: 9
Training loss: 2.0890626907348633
Validation loss: 2.0813086648141184

Epoch: 6| Step: 10
Training loss: 1.7122858762741089
Validation loss: 2.091794954833164

Epoch: 6| Step: 11
Training loss: 2.077305793762207
Validation loss: 2.106842940853488

Epoch: 6| Step: 12
Training loss: 2.2998223304748535
Validation loss: 2.061255552435434

Epoch: 6| Step: 13
Training loss: 0.7347779870033264
Validation loss: 2.109612464904785

Epoch: 230| Step: 0
Training loss: 1.5272120237350464
Validation loss: 2.1010696618787703

Epoch: 6| Step: 1
Training loss: 1.321603775024414
Validation loss: 2.06141520315601

Epoch: 6| Step: 2
Training loss: 2.153381824493408
Validation loss: 2.080504141828065

Epoch: 6| Step: 3
Training loss: 1.9992492198944092
Validation loss: 2.10563741448105

Epoch: 6| Step: 4
Training loss: 1.3795069456100464
Validation loss: 2.0944316156448854

Epoch: 6| Step: 5
Training loss: 2.2760064601898193
Validation loss: 2.1064626965471493

Epoch: 6| Step: 6
Training loss: 2.6039392948150635
Validation loss: 2.068846005265431

Epoch: 6| Step: 7
Training loss: 1.6950680017471313
Validation loss: 2.118991031441637

Epoch: 6| Step: 8
Training loss: 2.054711103439331
Validation loss: 2.0938785883688156

Epoch: 6| Step: 9
Training loss: 1.9434161186218262
Validation loss: 2.108108061616139

Epoch: 6| Step: 10
Training loss: 1.6929214000701904
Validation loss: 2.106270710627238

Epoch: 6| Step: 11
Training loss: 2.515881299972534
Validation loss: 2.070036821467902

Epoch: 6| Step: 12
Training loss: 1.6197967529296875
Validation loss: 2.0927338497613066

Epoch: 6| Step: 13
Training loss: 1.1353492736816406
Validation loss: 2.102209125795672

Epoch: 231| Step: 0
Training loss: 1.9020483493804932
Validation loss: 2.0775130974349154

Epoch: 6| Step: 1
Training loss: 2.2884562015533447
Validation loss: 2.0901739622956965

Epoch: 6| Step: 2
Training loss: 2.006253242492676
Validation loss: 2.101790855007787

Epoch: 6| Step: 3
Training loss: 2.1006577014923096
Validation loss: 2.079779173738213

Epoch: 6| Step: 4
Training loss: 1.371773600578308
Validation loss: 2.0911729951058664

Epoch: 6| Step: 5
Training loss: 1.5126994848251343
Validation loss: 2.0618468279479654

Epoch: 6| Step: 6
Training loss: 1.7017946243286133
Validation loss: 2.0690237552888933

Epoch: 6| Step: 7
Training loss: 1.184013843536377
Validation loss: 2.087505034221116

Epoch: 6| Step: 8
Training loss: 2.2258734703063965
Validation loss: 2.0705370467196227

Epoch: 6| Step: 9
Training loss: 1.7858736515045166
Validation loss: 2.0890843432436705

Epoch: 6| Step: 10
Training loss: 2.4607346057891846
Validation loss: 2.1001693407694497

Epoch: 6| Step: 11
Training loss: 2.552938938140869
Validation loss: 2.056858447290236

Epoch: 6| Step: 12
Training loss: 1.679809808731079
Validation loss: 2.0874095296347015

Epoch: 6| Step: 13
Training loss: 1.1457160711288452
Validation loss: 2.048575283378683

Epoch: 232| Step: 0
Training loss: 1.7071014642715454
Validation loss: 2.0790823787771244

Epoch: 6| Step: 1
Training loss: 1.4922237396240234
Validation loss: 2.106584092622162

Epoch: 6| Step: 2
Training loss: 1.6844463348388672
Validation loss: 2.0958553667991393

Epoch: 6| Step: 3
Training loss: 1.9983351230621338
Validation loss: 2.0574310005352063

Epoch: 6| Step: 4
Training loss: 2.112945079803467
Validation loss: 2.040080488369029

Epoch: 6| Step: 5
Training loss: 2.3496594429016113
Validation loss: 2.0674778825493267

Epoch: 6| Step: 6
Training loss: 2.323728322982788
Validation loss: 2.081556540663524

Epoch: 6| Step: 7
Training loss: 1.8234193325042725
Validation loss: 2.0429606232591855

Epoch: 6| Step: 8
Training loss: 2.300259828567505
Validation loss: 2.073750626656317

Epoch: 6| Step: 9
Training loss: 1.7894809246063232
Validation loss: 2.068556982983825

Epoch: 6| Step: 10
Training loss: 1.1854026317596436
Validation loss: 2.070299845869823

Epoch: 6| Step: 11
Training loss: 1.5753226280212402
Validation loss: 2.071594899700534

Epoch: 6| Step: 12
Training loss: 2.1236157417297363
Validation loss: 2.0894512514914236

Epoch: 6| Step: 13
Training loss: 1.2329134941101074
Validation loss: 2.1142924870214155

Epoch: 233| Step: 0
Training loss: 1.503583550453186
Validation loss: 2.088178680789086

Epoch: 6| Step: 1
Training loss: 1.685508131980896
Validation loss: 2.107537566974599

Epoch: 6| Step: 2
Training loss: 2.478593111038208
Validation loss: 2.1124815017946306

Epoch: 6| Step: 3
Training loss: 1.5713801383972168
Validation loss: 2.1196084791614163

Epoch: 6| Step: 4
Training loss: 1.4940392971038818
Validation loss: 2.135940353075663

Epoch: 6| Step: 5
Training loss: 2.5151174068450928
Validation loss: 2.1549545206049436

Epoch: 6| Step: 6
Training loss: 2.03840970993042
Validation loss: 2.145259339322326

Epoch: 6| Step: 7
Training loss: 2.071345329284668
Validation loss: 2.117788037946147

Epoch: 6| Step: 8
Training loss: 2.110651969909668
Validation loss: 2.147700148244058

Epoch: 6| Step: 9
Training loss: 2.224071741104126
Validation loss: 2.162861203634611

Epoch: 6| Step: 10
Training loss: 1.8054661750793457
Validation loss: 2.155711712375764

Epoch: 6| Step: 11
Training loss: 1.6194400787353516
Validation loss: 2.176338782874487

Epoch: 6| Step: 12
Training loss: 1.7784831523895264
Validation loss: 2.1448784233421407

Epoch: 6| Step: 13
Training loss: 1.2732136249542236
Validation loss: 2.1066695182554183

Epoch: 234| Step: 0
Training loss: 2.0863261222839355
Validation loss: 2.1194189851002028

Epoch: 6| Step: 1
Training loss: 1.9012181758880615
Validation loss: 2.1127017364707044

Epoch: 6| Step: 2
Training loss: 2.3503878116607666
Validation loss: 2.1098249971225695

Epoch: 6| Step: 3
Training loss: 2.306194305419922
Validation loss: 2.0817809156192246

Epoch: 6| Step: 4
Training loss: 2.0057756900787354
Validation loss: 2.089496627930672

Epoch: 6| Step: 5
Training loss: 1.6329385042190552
Validation loss: 2.0737680401853336

Epoch: 6| Step: 6
Training loss: 1.7139434814453125
Validation loss: 2.093774510968116

Epoch: 6| Step: 7
Training loss: 1.3614877462387085
Validation loss: 2.097061335399587

Epoch: 6| Step: 8
Training loss: 1.2414772510528564
Validation loss: 2.058658907490392

Epoch: 6| Step: 9
Training loss: 1.8200294971466064
Validation loss: 2.0548130760910692

Epoch: 6| Step: 10
Training loss: 1.8144559860229492
Validation loss: 2.0607294395405757

Epoch: 6| Step: 11
Training loss: 1.9928385019302368
Validation loss: 2.082797893913843

Epoch: 6| Step: 12
Training loss: 1.799912929534912
Validation loss: 2.0953240984229633

Epoch: 6| Step: 13
Training loss: 2.2007970809936523
Validation loss: 2.0623291961608397

Epoch: 235| Step: 0
Training loss: 1.1066792011260986
Validation loss: 2.0483927816473027

Epoch: 6| Step: 1
Training loss: 2.0813615322113037
Validation loss: 2.087451757923249

Epoch: 6| Step: 2
Training loss: 1.5483415126800537
Validation loss: 2.083516768229905

Epoch: 6| Step: 3
Training loss: 1.6077895164489746
Validation loss: 2.06638406425394

Epoch: 6| Step: 4
Training loss: 2.122112274169922
Validation loss: 2.0949249344487346

Epoch: 6| Step: 5
Training loss: 1.8900737762451172
Validation loss: 2.0703764038701213

Epoch: 6| Step: 6
Training loss: 2.033780336380005
Validation loss: 2.0729367310001003

Epoch: 6| Step: 7
Training loss: 2.3441238403320312
Validation loss: 2.063169264024304

Epoch: 6| Step: 8
Training loss: 1.3462786674499512
Validation loss: 2.036630056237662

Epoch: 6| Step: 9
Training loss: 1.990744709968567
Validation loss: 2.117032886833273

Epoch: 6| Step: 10
Training loss: 1.6678447723388672
Validation loss: 2.0816908036508868

Epoch: 6| Step: 11
Training loss: 1.5907695293426514
Validation loss: 2.104595450944798

Epoch: 6| Step: 12
Training loss: 2.2531919479370117
Validation loss: 2.0786005399560414

Epoch: 6| Step: 13
Training loss: 2.2341740131378174
Validation loss: 2.073141549223213

Epoch: 236| Step: 0
Training loss: 1.6762797832489014
Validation loss: 2.124291914765553

Epoch: 6| Step: 1
Training loss: 1.570678949356079
Validation loss: 2.102033561275851

Epoch: 6| Step: 2
Training loss: 1.9573438167572021
Validation loss: 2.0989056505182737

Epoch: 6| Step: 3
Training loss: 1.652970790863037
Validation loss: 2.1361021405907086

Epoch: 6| Step: 4
Training loss: 1.786729097366333
Validation loss: 2.136526028315226

Epoch: 6| Step: 5
Training loss: 1.9213656187057495
Validation loss: 2.115818353109462

Epoch: 6| Step: 6
Training loss: 1.8463841676712036
Validation loss: 2.1306670609340874

Epoch: 6| Step: 7
Training loss: 2.4898672103881836
Validation loss: 2.1205178460767193

Epoch: 6| Step: 8
Training loss: 1.7509205341339111
Validation loss: 2.1282428362036265

Epoch: 6| Step: 9
Training loss: 1.932311773300171
Validation loss: 2.1169335752405147

Epoch: 6| Step: 10
Training loss: 1.902199625968933
Validation loss: 2.085447552383587

Epoch: 6| Step: 11
Training loss: 2.1742472648620605
Validation loss: 2.085602557787331

Epoch: 6| Step: 12
Training loss: 1.2656404972076416
Validation loss: 2.1303934820236696

Epoch: 6| Step: 13
Training loss: 2.3904294967651367
Validation loss: 2.107239261750252

Epoch: 237| Step: 0
Training loss: 1.7471857070922852
Validation loss: 2.1095305181318715

Epoch: 6| Step: 1
Training loss: 1.998328685760498
Validation loss: 2.077639769482356

Epoch: 6| Step: 2
Training loss: 1.674129605293274
Validation loss: 2.0871312566982803

Epoch: 6| Step: 3
Training loss: 1.3226559162139893
Validation loss: 2.0971504462662565

Epoch: 6| Step: 4
Training loss: 1.5246728658676147
Validation loss: 2.1118276631960304

Epoch: 6| Step: 5
Training loss: 2.2843897342681885
Validation loss: 2.0373340934835453

Epoch: 6| Step: 6
Training loss: 1.8019652366638184
Validation loss: 2.0849783664108603

Epoch: 6| Step: 7
Training loss: 1.642706036567688
Validation loss: 2.077446642742362

Epoch: 6| Step: 8
Training loss: 1.709749460220337
Validation loss: 2.09732198843392

Epoch: 6| Step: 9
Training loss: 2.2450804710388184
Validation loss: 2.0659529675719557

Epoch: 6| Step: 10
Training loss: 2.4476380348205566
Validation loss: 2.085393847957734

Epoch: 6| Step: 11
Training loss: 2.103400468826294
Validation loss: 2.0948741384731826

Epoch: 6| Step: 12
Training loss: 1.534965991973877
Validation loss: 2.0809601865788943

Epoch: 6| Step: 13
Training loss: 1.5588351488113403
Validation loss: 2.0699877303133727

Epoch: 238| Step: 0
Training loss: 1.2972707748413086
Validation loss: 2.06645970190725

Epoch: 6| Step: 1
Training loss: 2.503955841064453
Validation loss: 2.0709744961031022

Epoch: 6| Step: 2
Training loss: 2.16233491897583
Validation loss: 2.096763100675357

Epoch: 6| Step: 3
Training loss: 1.8123779296875
Validation loss: 2.0708530846462456

Epoch: 6| Step: 4
Training loss: 1.3735806941986084
Validation loss: 2.0494195838128366

Epoch: 6| Step: 5
Training loss: 1.9623875617980957
Validation loss: 2.041147570456228

Epoch: 6| Step: 6
Training loss: 1.958849310874939
Validation loss: 2.090136843342935

Epoch: 6| Step: 7
Training loss: 2.072906732559204
Validation loss: 2.0337131997590423

Epoch: 6| Step: 8
Training loss: 1.7952888011932373
Validation loss: 2.0580105986646426

Epoch: 6| Step: 9
Training loss: 1.9957952499389648
Validation loss: 2.0622980427998368

Epoch: 6| Step: 10
Training loss: 1.8640689849853516
Validation loss: 2.075907732850762

Epoch: 6| Step: 11
Training loss: 1.5154584646224976
Validation loss: 2.080077450762513

Epoch: 6| Step: 12
Training loss: 1.5786957740783691
Validation loss: 2.0937876983355452

Epoch: 6| Step: 13
Training loss: 2.2672197818756104
Validation loss: 2.083242348445359

Epoch: 239| Step: 0
Training loss: 1.6083014011383057
Validation loss: 2.1036907806191394

Epoch: 6| Step: 1
Training loss: 2.033646583557129
Validation loss: 2.039095599164245

Epoch: 6| Step: 2
Training loss: 1.3762747049331665
Validation loss: 2.1052553320443756

Epoch: 6| Step: 3
Training loss: 1.4912569522857666
Validation loss: 2.0928255960505497

Epoch: 6| Step: 4
Training loss: 2.2623393535614014
Validation loss: 2.1088181464902815

Epoch: 6| Step: 5
Training loss: 2.0030977725982666
Validation loss: 2.1239788045165358

Epoch: 6| Step: 6
Training loss: 1.9491955041885376
Validation loss: 2.097391774577479

Epoch: 6| Step: 7
Training loss: 2.2124977111816406
Validation loss: 2.118539708916859

Epoch: 6| Step: 8
Training loss: 1.7436373233795166
Validation loss: 2.078160975569038

Epoch: 6| Step: 9
Training loss: 1.9100475311279297
Validation loss: 2.104211991833102

Epoch: 6| Step: 10
Training loss: 1.5759665966033936
Validation loss: 2.0866650073759017

Epoch: 6| Step: 11
Training loss: 2.0984883308410645
Validation loss: 2.112645895250382

Epoch: 6| Step: 12
Training loss: 1.852893590927124
Validation loss: 2.09835034801114

Epoch: 6| Step: 13
Training loss: 1.6492563486099243
Validation loss: 2.114370184559976

Epoch: 240| Step: 0
Training loss: 1.6132168769836426
Validation loss: 2.09209620055332

Epoch: 6| Step: 1
Training loss: 1.8792481422424316
Validation loss: 2.1109072508350497

Epoch: 6| Step: 2
Training loss: 1.4748458862304688
Validation loss: 2.074513054663135

Epoch: 6| Step: 3
Training loss: 1.7597417831420898
Validation loss: 2.086528896003641

Epoch: 6| Step: 4
Training loss: 2.344816207885742
Validation loss: 2.1167345867362073

Epoch: 6| Step: 5
Training loss: 1.7055590152740479
Validation loss: 2.097964817477811

Epoch: 6| Step: 6
Training loss: 1.5072804689407349
Validation loss: 2.1033145971195673

Epoch: 6| Step: 7
Training loss: 2.3047804832458496
Validation loss: 2.0646628474676483

Epoch: 6| Step: 8
Training loss: 1.9980342388153076
Validation loss: 2.0830371969489643

Epoch: 6| Step: 9
Training loss: 1.7252802848815918
Validation loss: 2.0865907720340195

Epoch: 6| Step: 10
Training loss: 2.044849395751953
Validation loss: 2.1440987689520723

Epoch: 6| Step: 11
Training loss: 2.101458787918091
Validation loss: 2.1127428803392636

Epoch: 6| Step: 12
Training loss: 1.8257330656051636
Validation loss: 2.0874635634883756

Epoch: 6| Step: 13
Training loss: 1.435712218284607
Validation loss: 2.111889619981089

Epoch: 241| Step: 0
Training loss: 1.7254507541656494
Validation loss: 2.0734735150491037

Epoch: 6| Step: 1
Training loss: 2.0578665733337402
Validation loss: 2.080495680532148

Epoch: 6| Step: 2
Training loss: 1.8401610851287842
Validation loss: 2.1025638503413044

Epoch: 6| Step: 3
Training loss: 2.2594542503356934
Validation loss: 2.087936561594727

Epoch: 6| Step: 4
Training loss: 2.7684719562530518
Validation loss: 2.0895673100666334

Epoch: 6| Step: 5
Training loss: 1.7193135023117065
Validation loss: 2.0906254142843266

Epoch: 6| Step: 6
Training loss: 1.6269413232803345
Validation loss: 2.0959494062649306

Epoch: 6| Step: 7
Training loss: 1.6862058639526367
Validation loss: 2.126548474834811

Epoch: 6| Step: 8
Training loss: 1.9999749660491943
Validation loss: 2.093382021432282

Epoch: 6| Step: 9
Training loss: 1.6386308670043945
Validation loss: 2.08472720525598

Epoch: 6| Step: 10
Training loss: 1.7833311557769775
Validation loss: 2.0695430245450748

Epoch: 6| Step: 11
Training loss: 1.3209636211395264
Validation loss: 2.0753238354959795

Epoch: 6| Step: 12
Training loss: 1.0761957168579102
Validation loss: 2.084377375982141

Epoch: 6| Step: 13
Training loss: 2.430405616760254
Validation loss: 2.0853087978978313

Epoch: 242| Step: 0
Training loss: 1.6344258785247803
Validation loss: 2.0901055361634944

Epoch: 6| Step: 1
Training loss: 2.323643922805786
Validation loss: 2.0793743184817735

Epoch: 6| Step: 2
Training loss: 1.8638410568237305
Validation loss: 2.074111851312781

Epoch: 6| Step: 3
Training loss: 1.6006121635437012
Validation loss: 2.0382944025019163

Epoch: 6| Step: 4
Training loss: 2.027604103088379
Validation loss: 2.0520204421012633

Epoch: 6| Step: 5
Training loss: 2.335922956466675
Validation loss: 2.0782082939660675

Epoch: 6| Step: 6
Training loss: 1.758365511894226
Validation loss: 2.0552335913463304

Epoch: 6| Step: 7
Training loss: 1.4170145988464355
Validation loss: 2.0509648784514396

Epoch: 6| Step: 8
Training loss: 0.9029775857925415
Validation loss: 2.0499804699292747

Epoch: 6| Step: 9
Training loss: 1.7268438339233398
Validation loss: 2.0644249531530563

Epoch: 6| Step: 10
Training loss: 2.155668258666992
Validation loss: 2.067458252752981

Epoch: 6| Step: 11
Training loss: 2.2711739540100098
Validation loss: 2.0578854750561457

Epoch: 6| Step: 12
Training loss: 1.724877119064331
Validation loss: 2.0898283297015774

Epoch: 6| Step: 13
Training loss: 2.177880048751831
Validation loss: 2.0720833962963474

Epoch: 243| Step: 0
Training loss: 2.090362071990967
Validation loss: 2.100840817215622

Epoch: 6| Step: 1
Training loss: 1.6134538650512695
Validation loss: 2.0724013928444154

Epoch: 6| Step: 2
Training loss: 2.017242908477783
Validation loss: 2.0941024852055374

Epoch: 6| Step: 3
Training loss: 1.424546241760254
Validation loss: 2.113454977671305

Epoch: 6| Step: 4
Training loss: 1.4620497226715088
Validation loss: 2.132672417548395

Epoch: 6| Step: 5
Training loss: 2.1885223388671875
Validation loss: 2.0948898228265906

Epoch: 6| Step: 6
Training loss: 1.5665066242218018
Validation loss: 2.0949477405958277

Epoch: 6| Step: 7
Training loss: 1.6823009252548218
Validation loss: 2.0983752255798667

Epoch: 6| Step: 8
Training loss: 2.0391957759857178
Validation loss: 2.066264949819093

Epoch: 6| Step: 9
Training loss: 1.8900378942489624
Validation loss: 2.058820273286553

Epoch: 6| Step: 10
Training loss: 1.5537985563278198
Validation loss: 2.0649204190059374

Epoch: 6| Step: 11
Training loss: 1.7677968740463257
Validation loss: 2.1125144881586873

Epoch: 6| Step: 12
Training loss: 1.7986524105072021
Validation loss: 2.0923674324507355

Epoch: 6| Step: 13
Training loss: 2.5750274658203125
Validation loss: 2.1109293968446794

Epoch: 244| Step: 0
Training loss: 2.468419075012207
Validation loss: 2.0844400877593667

Epoch: 6| Step: 1
Training loss: 1.3128225803375244
Validation loss: 2.100056343181159

Epoch: 6| Step: 2
Training loss: 1.4882514476776123
Validation loss: 2.111424805015646

Epoch: 6| Step: 3
Training loss: 2.001361846923828
Validation loss: 2.1226501669935

Epoch: 6| Step: 4
Training loss: 2.3384177684783936
Validation loss: 2.129369687008601

Epoch: 6| Step: 5
Training loss: 1.446487545967102
Validation loss: 2.1102055747021913

Epoch: 6| Step: 6
Training loss: 1.6876248121261597
Validation loss: 2.106472399926955

Epoch: 6| Step: 7
Training loss: 2.337268352508545
Validation loss: 2.1240943785636657

Epoch: 6| Step: 8
Training loss: 1.9718730449676514
Validation loss: 2.113044341405233

Epoch: 6| Step: 9
Training loss: 1.544143795967102
Validation loss: 2.119584027157035

Epoch: 6| Step: 10
Training loss: 1.8133080005645752
Validation loss: 2.1334250844934934

Epoch: 6| Step: 11
Training loss: 1.4951682090759277
Validation loss: 2.104145332049298

Epoch: 6| Step: 12
Training loss: 1.3136181831359863
Validation loss: 2.099691947301229

Epoch: 6| Step: 13
Training loss: 2.701491355895996
Validation loss: 2.0840055224716023

Epoch: 245| Step: 0
Training loss: 1.60965895652771
Validation loss: 2.1170684214561217

Epoch: 6| Step: 1
Training loss: 2.259265422821045
Validation loss: 2.104878717853177

Epoch: 6| Step: 2
Training loss: 1.7177040576934814
Validation loss: 2.106800074218422

Epoch: 6| Step: 3
Training loss: 2.107308864593506
Validation loss: 2.0918880098609516

Epoch: 6| Step: 4
Training loss: 2.240032434463501
Validation loss: 2.0742941633347542

Epoch: 6| Step: 5
Training loss: 1.9387526512145996
Validation loss: 2.0676802409592496

Epoch: 6| Step: 6
Training loss: 2.1708102226257324
Validation loss: 2.0808974337834183

Epoch: 6| Step: 7
Training loss: 1.6319161653518677
Validation loss: 2.063652975584871

Epoch: 6| Step: 8
Training loss: 1.0606224536895752
Validation loss: 2.07993733754722

Epoch: 6| Step: 9
Training loss: 1.7457361221313477
Validation loss: 2.091628133609731

Epoch: 6| Step: 10
Training loss: 1.2367528676986694
Validation loss: 2.072051391806654

Epoch: 6| Step: 11
Training loss: 2.0625853538513184
Validation loss: 2.0796510301610476

Epoch: 6| Step: 12
Training loss: 1.5798938274383545
Validation loss: 2.09079255852648

Epoch: 6| Step: 13
Training loss: 2.153198480606079
Validation loss: 2.05180642297191

Epoch: 246| Step: 0
Training loss: 2.5042781829833984
Validation loss: 2.0726070557871172

Epoch: 6| Step: 1
Training loss: 2.2590487003326416
Validation loss: 2.0526647619021836

Epoch: 6| Step: 2
Training loss: 2.2814126014709473
Validation loss: 2.0782674563828336

Epoch: 6| Step: 3
Training loss: 2.059091091156006
Validation loss: 2.0684629768453617

Epoch: 6| Step: 4
Training loss: 1.6194041967391968
Validation loss: 2.079546010622414

Epoch: 6| Step: 5
Training loss: 1.882408618927002
Validation loss: 2.080767153411783

Epoch: 6| Step: 6
Training loss: 1.5556724071502686
Validation loss: 2.1064780707000406

Epoch: 6| Step: 7
Training loss: 1.224277377128601
Validation loss: 2.0743235721383044

Epoch: 6| Step: 8
Training loss: 1.8545724153518677
Validation loss: 2.0854372606482556

Epoch: 6| Step: 9
Training loss: 1.2410717010498047
Validation loss: 2.1105037004716936

Epoch: 6| Step: 10
Training loss: 1.2425692081451416
Validation loss: 2.0826724626684703

Epoch: 6| Step: 11
Training loss: 1.6332143545150757
Validation loss: 2.1000337023888864

Epoch: 6| Step: 12
Training loss: 2.0194411277770996
Validation loss: 2.090175464589109

Epoch: 6| Step: 13
Training loss: 2.2299153804779053
Validation loss: 2.1242556469414824

Epoch: 247| Step: 0
Training loss: 1.650436520576477
Validation loss: 2.1249748942672566

Epoch: 6| Step: 1
Training loss: 1.9717597961425781
Validation loss: 2.0933170933877268

Epoch: 6| Step: 2
Training loss: 2.926797866821289
Validation loss: 2.117901473916987

Epoch: 6| Step: 3
Training loss: 1.324474811553955
Validation loss: 2.0919852154229277

Epoch: 6| Step: 4
Training loss: 2.247974157333374
Validation loss: 2.0762821679474204

Epoch: 6| Step: 5
Training loss: 1.142838716506958
Validation loss: 2.0763288941434634

Epoch: 6| Step: 6
Training loss: 1.9132466316223145
Validation loss: 2.127290100179693

Epoch: 6| Step: 7
Training loss: 1.3598741292953491
Validation loss: 2.0888265537959274

Epoch: 6| Step: 8
Training loss: 2.295227527618408
Validation loss: 2.106890623287488

Epoch: 6| Step: 9
Training loss: 2.2165253162384033
Validation loss: 2.0809331875975414

Epoch: 6| Step: 10
Training loss: 1.4637210369110107
Validation loss: 2.0509891535646174

Epoch: 6| Step: 11
Training loss: 1.737065315246582
Validation loss: 2.1109022889085995

Epoch: 6| Step: 12
Training loss: 1.6073081493377686
Validation loss: 2.058526764633835

Epoch: 6| Step: 13
Training loss: 1.2610151767730713
Validation loss: 2.1070696205221195

Epoch: 248| Step: 0
Training loss: 1.1913628578186035
Validation loss: 2.0882449944814048

Epoch: 6| Step: 1
Training loss: 2.4865260124206543
Validation loss: 2.093523356222337

Epoch: 6| Step: 2
Training loss: 1.3301680088043213
Validation loss: 2.070728107165265

Epoch: 6| Step: 3
Training loss: 1.7686079740524292
Validation loss: 2.098745133287163

Epoch: 6| Step: 4
Training loss: 2.2423653602600098
Validation loss: 2.090642131784911

Epoch: 6| Step: 5
Training loss: 1.6646816730499268
Validation loss: 2.080913935938189

Epoch: 6| Step: 6
Training loss: 1.3617955446243286
Validation loss: 2.1145934891957108

Epoch: 6| Step: 7
Training loss: 1.4667022228240967
Validation loss: 2.10777723404669

Epoch: 6| Step: 8
Training loss: 1.6698474884033203
Validation loss: 2.1109743451559417

Epoch: 6| Step: 9
Training loss: 2.0913920402526855
Validation loss: 2.1307474156861663

Epoch: 6| Step: 10
Training loss: 1.970743179321289
Validation loss: 2.1156628080593642

Epoch: 6| Step: 11
Training loss: 2.3351197242736816
Validation loss: 2.1247659703736663

Epoch: 6| Step: 12
Training loss: 1.7726409435272217
Validation loss: 2.1182642982852076

Epoch: 6| Step: 13
Training loss: 2.2045416831970215
Validation loss: 2.1125875160258305

Epoch: 249| Step: 0
Training loss: 1.5074996948242188
Validation loss: 2.090203777436287

Epoch: 6| Step: 1
Training loss: 1.2801802158355713
Validation loss: 2.0924163018503497

Epoch: 6| Step: 2
Training loss: 2.1739296913146973
Validation loss: 2.1029677660234514

Epoch: 6| Step: 3
Training loss: 1.9335541725158691
Validation loss: 2.0879407416107836

Epoch: 6| Step: 4
Training loss: 1.4102736711502075
Validation loss: 2.065318194768762

Epoch: 6| Step: 5
Training loss: 2.0429787635803223
Validation loss: 2.0878452280516266

Epoch: 6| Step: 6
Training loss: 1.9489927291870117
Validation loss: 2.0865277244198706

Epoch: 6| Step: 7
Training loss: 1.8156938552856445
Validation loss: 2.075651091914023

Epoch: 6| Step: 8
Training loss: 2.4109809398651123
Validation loss: 2.042325712019397

Epoch: 6| Step: 9
Training loss: 2.001183271408081
Validation loss: 2.079236390770123

Epoch: 6| Step: 10
Training loss: 1.9430556297302246
Validation loss: 2.0570304047676826

Epoch: 6| Step: 11
Training loss: 0.7554145455360413
Validation loss: 2.0728613843200026

Epoch: 6| Step: 12
Training loss: 2.0670325756073
Validation loss: 2.038121609277623

Epoch: 6| Step: 13
Training loss: 2.7262589931488037
Validation loss: 2.0820884781499065

Epoch: 250| Step: 0
Training loss: 1.511918306350708
Validation loss: 2.084654346589119

Epoch: 6| Step: 1
Training loss: 1.7207075357437134
Validation loss: 2.0917600995750836

Epoch: 6| Step: 2
Training loss: 1.8181945085525513
Validation loss: 2.090470528089872

Epoch: 6| Step: 3
Training loss: 1.4102165699005127
Validation loss: 2.0929846661065215

Epoch: 6| Step: 4
Training loss: 1.9152610301971436
Validation loss: 2.131869549392372

Epoch: 6| Step: 5
Training loss: 1.7744591236114502
Validation loss: 2.1353633903688

Epoch: 6| Step: 6
Training loss: 1.6546992063522339
Validation loss: 2.103940802235757

Epoch: 6| Step: 7
Training loss: 1.7618329524993896
Validation loss: 2.1199480179817445

Epoch: 6| Step: 8
Training loss: 1.8135044574737549
Validation loss: 2.130623431615932

Epoch: 6| Step: 9
Training loss: 2.547736644744873
Validation loss: 2.115143278593658

Epoch: 6| Step: 10
Training loss: 2.8432486057281494
Validation loss: 2.1322381752793507

Epoch: 6| Step: 11
Training loss: 1.6126821041107178
Validation loss: 2.115985398651451

Epoch: 6| Step: 12
Training loss: 1.9108564853668213
Validation loss: 2.1060601434400006

Epoch: 6| Step: 13
Training loss: 0.8706076145172119
Validation loss: 2.1264680329189507

Testing loss: 2.0387445317374335
