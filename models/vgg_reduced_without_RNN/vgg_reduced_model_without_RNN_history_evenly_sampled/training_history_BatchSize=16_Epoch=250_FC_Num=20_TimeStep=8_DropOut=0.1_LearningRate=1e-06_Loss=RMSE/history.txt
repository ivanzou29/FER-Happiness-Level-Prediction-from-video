Epoch: 1| Step: 0
Training loss: 4.83979488221899
Validation loss: 5.989283387822638

Epoch: 6| Step: 1
Training loss: 6.32257122707105
Validation loss: 5.983876759383382

Epoch: 6| Step: 2
Training loss: 5.983033669847701
Validation loss: 5.982184694982021

Epoch: 6| Step: 3
Training loss: 5.868854311340023
Validation loss: 5.977449130197902

Epoch: 6| Step: 4
Training loss: 6.266557352992918
Validation loss: 5.977271349410988

Epoch: 6| Step: 5
Training loss: 5.790245851557978
Validation loss: 5.975067024062704

Epoch: 6| Step: 6
Training loss: 3.199956154522924
Validation loss: 5.968805004575764

Epoch: 6| Step: 7
Training loss: 6.62960194953493
Validation loss: 5.965324863550733

Epoch: 6| Step: 8
Training loss: 4.818759562956626
Validation loss: 5.96262585979279

Epoch: 6| Step: 9
Training loss: 6.700570426685235
Validation loss: 5.959843213703953

Epoch: 6| Step: 10
Training loss: 6.697730679300371
Validation loss: 5.957073923889764

Epoch: 6| Step: 11
Training loss: 6.938417666116148
Validation loss: 5.951568154481018

Epoch: 6| Step: 12
Training loss: 5.417607367577813
Validation loss: 5.947953349943314

Epoch: 6| Step: 13
Training loss: 7.994557198100541
Validation loss: 5.946825001168201

Epoch: 2| Step: 0
Training loss: 5.412763431472679
Validation loss: 5.945298052934314

Epoch: 6| Step: 1
Training loss: 6.144020597721382
Validation loss: 5.943123219062454

Epoch: 6| Step: 2
Training loss: 6.2820777157916545
Validation loss: 5.939730942597003

Epoch: 6| Step: 3
Training loss: 5.487942049126459
Validation loss: 5.936555769428565

Epoch: 6| Step: 4
Training loss: 6.197105273394285
Validation loss: 5.932513848751794

Epoch: 6| Step: 5
Training loss: 5.819489245468626
Validation loss: 5.929989026948038

Epoch: 6| Step: 6
Training loss: 6.014369922847085
Validation loss: 5.925974945124259

Epoch: 6| Step: 7
Training loss: 4.636324447153419
Validation loss: 5.921764592993198

Epoch: 6| Step: 8
Training loss: 5.922923616755654
Validation loss: 5.920439096247927

Epoch: 6| Step: 9
Training loss: 5.7202279937762315
Validation loss: 5.917485040859893

Epoch: 6| Step: 10
Training loss: 5.899187659251272
Validation loss: 5.91240950898918

Epoch: 6| Step: 11
Training loss: 6.7926393838171615
Validation loss: 5.910542711372072

Epoch: 6| Step: 12
Training loss: 6.0558013088432405
Validation loss: 5.904343792636044

Epoch: 6| Step: 13
Training loss: 7.098368615788788
Validation loss: 5.9052441225446355

Epoch: 3| Step: 0
Training loss: 6.387364980685257
Validation loss: 5.90212868036509

Epoch: 6| Step: 1
Training loss: 6.227527959968345
Validation loss: 5.895555007935555

Epoch: 6| Step: 2
Training loss: 5.092924835207682
Validation loss: 5.89143417509326

Epoch: 6| Step: 3
Training loss: 6.773265163248793
Validation loss: 5.8922031813029445

Epoch: 6| Step: 4
Training loss: 5.281716591352398
Validation loss: 5.885928446473606

Epoch: 6| Step: 5
Training loss: 5.255398109520418
Validation loss: 5.8840663181521995

Epoch: 6| Step: 6
Training loss: 6.268811107881528
Validation loss: 5.881195322392204

Epoch: 6| Step: 7
Training loss: 5.757149273836007
Validation loss: 5.877186162712156

Epoch: 6| Step: 8
Training loss: 6.069299090420129
Validation loss: 5.8712768906013

Epoch: 6| Step: 9
Training loss: 5.380020281104678
Validation loss: 5.8707473887745465

Epoch: 6| Step: 10
Training loss: 6.077165621083894
Validation loss: 5.869233115798005

Epoch: 6| Step: 11
Training loss: 5.567687969212154
Validation loss: 5.861988234043609

Epoch: 6| Step: 12
Training loss: 6.505236643680474
Validation loss: 5.86290229886163

Epoch: 6| Step: 13
Training loss: 5.625913249160972
Validation loss: 5.859202425914039

Epoch: 4| Step: 0
Training loss: 6.099253199154987
Validation loss: 5.856728435957782

Epoch: 6| Step: 1
Training loss: 5.819273580725022
Validation loss: 5.849685193217476

Epoch: 6| Step: 2
Training loss: 6.515945243741202
Validation loss: 5.84751047507597

Epoch: 6| Step: 3
Training loss: 5.559552901425178
Validation loss: 5.8441082437322205

Epoch: 6| Step: 4
Training loss: 5.181355341633068
Validation loss: 5.839232262799093

Epoch: 6| Step: 5
Training loss: 5.400211556140576
Validation loss: 5.839405704533947

Epoch: 6| Step: 6
Training loss: 6.241748092520899
Validation loss: 5.831771811517227

Epoch: 6| Step: 7
Training loss: 6.021385862699677
Validation loss: 5.832932704874079

Epoch: 6| Step: 8
Training loss: 6.262893499929173
Validation loss: 5.824373976175935

Epoch: 6| Step: 9
Training loss: 6.36501352840643
Validation loss: 5.8229255465607235

Epoch: 6| Step: 10
Training loss: 4.624734613176152
Validation loss: 5.820625601885907

Epoch: 6| Step: 11
Training loss: 5.9209701933894126
Validation loss: 5.817398584639624

Epoch: 6| Step: 12
Training loss: 5.12638389697171
Validation loss: 5.811609279992298

Epoch: 6| Step: 13
Training loss: 6.949630990969559
Validation loss: 5.80557387524539

Epoch: 5| Step: 0
Training loss: 5.833732627644981
Validation loss: 5.800783716066395

Epoch: 6| Step: 1
Training loss: 5.497398801724783
Validation loss: 5.798300043413559

Epoch: 6| Step: 2
Training loss: 5.313030261334988
Validation loss: 5.79036251188827

Epoch: 6| Step: 3
Training loss: 6.119753712205
Validation loss: 5.7906515111611245

Epoch: 6| Step: 4
Training loss: 6.636546311768056
Validation loss: 5.785413060533598

Epoch: 6| Step: 5
Training loss: 4.227157240676332
Validation loss: 5.781912540251744

Epoch: 6| Step: 6
Training loss: 5.793484336251763
Validation loss: 5.778280434831361

Epoch: 6| Step: 7
Training loss: 5.247659433967882
Validation loss: 5.775397265597035

Epoch: 6| Step: 8
Training loss: 5.7318578699330365
Validation loss: 5.769773064318897

Epoch: 6| Step: 9
Training loss: 6.193509045022174
Validation loss: 5.764182666827157

Epoch: 6| Step: 10
Training loss: 6.531434563032219
Validation loss: 5.764757149471867

Epoch: 6| Step: 11
Training loss: 5.66872787387151
Validation loss: 5.756046527640779

Epoch: 6| Step: 12
Training loss: 6.56070125088167
Validation loss: 5.757013941178607

Epoch: 6| Step: 13
Training loss: 5.132005323233337
Validation loss: 5.749875222912537

Epoch: 6| Step: 0
Training loss: 6.686028719763617
Validation loss: 5.743285236763006

Epoch: 6| Step: 1
Training loss: 5.889538247316301
Validation loss: 5.740105242792511

Epoch: 6| Step: 2
Training loss: 5.780729363169915
Validation loss: 5.735046935689177

Epoch: 6| Step: 3
Training loss: 6.183753526639193
Validation loss: 5.7286207685924895

Epoch: 6| Step: 4
Training loss: 5.684170932892143
Validation loss: 5.726382169964911

Epoch: 6| Step: 5
Training loss: 5.832579028088388
Validation loss: 5.7186908634812434

Epoch: 6| Step: 6
Training loss: 5.707635470239214
Validation loss: 5.713410888967574

Epoch: 6| Step: 7
Training loss: 5.217320046422001
Validation loss: 5.712239467244298

Epoch: 6| Step: 8
Training loss: 5.953585389124414
Validation loss: 5.7069934122373525

Epoch: 6| Step: 9
Training loss: 4.760341830120985
Validation loss: 5.697035167125738

Epoch: 6| Step: 10
Training loss: 5.785728246009306
Validation loss: 5.693569937498492

Epoch: 6| Step: 11
Training loss: 4.385735555306998
Validation loss: 5.688972452924285

Epoch: 6| Step: 12
Training loss: 6.5010853374790845
Validation loss: 5.68443130271983

Epoch: 6| Step: 13
Training loss: 5.536171313286701
Validation loss: 5.677852353719186

Epoch: 7| Step: 0
Training loss: 5.732655113973081
Validation loss: 5.67476266568239

Epoch: 6| Step: 1
Training loss: 5.718587904336953
Validation loss: 5.67319928966862

Epoch: 6| Step: 2
Training loss: 5.804785418294237
Validation loss: 5.662098430601504

Epoch: 6| Step: 3
Training loss: 5.903014573477479
Validation loss: 5.659199006347955

Epoch: 6| Step: 4
Training loss: 4.922165441269278
Validation loss: 5.648833029619905

Epoch: 6| Step: 5
Training loss: 5.339060192202549
Validation loss: 5.65022442482952

Epoch: 6| Step: 6
Training loss: 5.297529242067158
Validation loss: 5.644868854677211

Epoch: 6| Step: 7
Training loss: 5.884939997001715
Validation loss: 5.634374913659199

Epoch: 6| Step: 8
Training loss: 5.512631909096194
Validation loss: 5.632549034015802

Epoch: 6| Step: 9
Training loss: 6.302959824659327
Validation loss: 5.625623854812993

Epoch: 6| Step: 10
Training loss: 5.987302696465376
Validation loss: 5.622164395509026

Epoch: 6| Step: 11
Training loss: 5.894651943864594
Validation loss: 5.612698498218172

Epoch: 6| Step: 12
Training loss: 5.322137147245166
Validation loss: 5.606854072976624

Epoch: 6| Step: 13
Training loss: 5.566185234099089
Validation loss: 5.599562017391469

Epoch: 8| Step: 0
Training loss: 5.937293119339902
Validation loss: 5.59142405387064

Epoch: 6| Step: 1
Training loss: 5.701546897459125
Validation loss: 5.58911781180346

Epoch: 6| Step: 2
Training loss: 5.71407239379527
Validation loss: 5.583755320490764

Epoch: 6| Step: 3
Training loss: 5.677798538186643
Validation loss: 5.575296633224183

Epoch: 6| Step: 4
Training loss: 4.478401911307115
Validation loss: 5.564810460720927

Epoch: 6| Step: 5
Training loss: 6.117884648572756
Validation loss: 5.562344825334315

Epoch: 6| Step: 6
Training loss: 6.149232534267838
Validation loss: 5.557055417436808

Epoch: 6| Step: 7
Training loss: 5.121722033708601
Validation loss: 5.549820200128704

Epoch: 6| Step: 8
Training loss: 5.339175580853163
Validation loss: 5.538696945325535

Epoch: 6| Step: 9
Training loss: 5.125023446378342
Validation loss: 5.531992227579603

Epoch: 6| Step: 10
Training loss: 5.975341991389489
Validation loss: 5.523603610856233

Epoch: 6| Step: 11
Training loss: 5.549551820271957
Validation loss: 5.520803325228672

Epoch: 6| Step: 12
Training loss: 4.974620110657831
Validation loss: 5.509485163188207

Epoch: 6| Step: 13
Training loss: 6.35971750747644
Validation loss: 5.499719929579324

Epoch: 9| Step: 0
Training loss: 5.873386892073803
Validation loss: 5.498551369045531

Epoch: 6| Step: 1
Training loss: 5.425079893587434
Validation loss: 5.489160849958624

Epoch: 6| Step: 2
Training loss: 5.61475575405862
Validation loss: 5.479013016073741

Epoch: 6| Step: 3
Training loss: 5.667812605533577
Validation loss: 5.4732240869164945

Epoch: 6| Step: 4
Training loss: 4.565047924379314
Validation loss: 5.464750053779255

Epoch: 6| Step: 5
Training loss: 5.153914228881008
Validation loss: 5.456554281039442

Epoch: 6| Step: 6
Training loss: 6.07147747629168
Validation loss: 5.444278786232951

Epoch: 6| Step: 7
Training loss: 5.1915138985500064
Validation loss: 5.445777232832402

Epoch: 6| Step: 8
Training loss: 5.729619936496593
Validation loss: 5.4389116215606395

Epoch: 6| Step: 9
Training loss: 5.287215796513913
Validation loss: 5.425531681312046

Epoch: 6| Step: 10
Training loss: 5.697250559737538
Validation loss: 5.412610901905603

Epoch: 6| Step: 11
Training loss: 5.248885626824643
Validation loss: 5.407000222480921

Epoch: 6| Step: 12
Training loss: 5.268585188019916
Validation loss: 5.399994771234008

Epoch: 6| Step: 13
Training loss: 5.983727004224373
Validation loss: 5.390427703599703

Epoch: 10| Step: 0
Training loss: 5.364188032184265
Validation loss: 5.380801523799622

Epoch: 6| Step: 1
Training loss: 5.983973078764062
Validation loss: 5.375171957201028

Epoch: 6| Step: 2
Training loss: 5.0431204137002394
Validation loss: 5.3694966696309905

Epoch: 6| Step: 3
Training loss: 4.888247756148238
Validation loss: 5.354381816313194

Epoch: 6| Step: 4
Training loss: 5.144445420043795
Validation loss: 5.341960586990996

Epoch: 6| Step: 5
Training loss: 5.712161077883527
Validation loss: 5.341349064956838

Epoch: 6| Step: 6
Training loss: 5.87495454811208
Validation loss: 5.3244835829970745

Epoch: 6| Step: 7
Training loss: 5.5881210220983215
Validation loss: 5.31593143794024

Epoch: 6| Step: 8
Training loss: 5.09742875450227
Validation loss: 5.300199500578226

Epoch: 6| Step: 9
Training loss: 5.008574952926434
Validation loss: 5.291461035922387

Epoch: 6| Step: 10
Training loss: 4.540449813540212
Validation loss: 5.275147799631758

Epoch: 6| Step: 11
Training loss: 5.7617088188473735
Validation loss: 5.276962983916232

Epoch: 6| Step: 12
Training loss: 5.552818359426867
Validation loss: 5.259204834652227

Epoch: 6| Step: 13
Training loss: 5.260920293387272
Validation loss: 5.253620463900348

Epoch: 11| Step: 0
Training loss: 3.6921210348803646
Validation loss: 5.23698954918933

Epoch: 6| Step: 1
Training loss: 5.896321019288214
Validation loss: 5.229684854124886

Epoch: 6| Step: 2
Training loss: 5.216459399768544
Validation loss: 5.220991844249267

Epoch: 6| Step: 3
Training loss: 5.013980774229764
Validation loss: 5.208414301417221

Epoch: 6| Step: 4
Training loss: 5.317445136371443
Validation loss: 5.186960171739639

Epoch: 6| Step: 5
Training loss: 5.346960341521043
Validation loss: 5.177645235370502

Epoch: 6| Step: 6
Training loss: 4.256337993681314
Validation loss: 5.171632981208776

Epoch: 6| Step: 7
Training loss: 6.208708203495502
Validation loss: 5.159850403894745

Epoch: 6| Step: 8
Training loss: 6.629566562115028
Validation loss: 5.1455592185034185

Epoch: 6| Step: 9
Training loss: 3.892688617583214
Validation loss: 5.138436586311174

Epoch: 6| Step: 10
Training loss: 4.611765303159494
Validation loss: 5.1265549260526475

Epoch: 6| Step: 11
Training loss: 5.3990985117878925
Validation loss: 5.112973123403046

Epoch: 6| Step: 12
Training loss: 5.171083510763771
Validation loss: 5.097742572035162

Epoch: 6| Step: 13
Training loss: 5.512895724739457
Validation loss: 5.0863126835613075

Epoch: 12| Step: 0
Training loss: 4.7447713885692275
Validation loss: 5.073504237686622

Epoch: 6| Step: 1
Training loss: 6.620049696444766
Validation loss: 5.053186969414005

Epoch: 6| Step: 2
Training loss: 4.109467596018916
Validation loss: 5.045237820287223

Epoch: 6| Step: 3
Training loss: 4.702993194659511
Validation loss: 5.029678876980344

Epoch: 6| Step: 4
Training loss: 5.421690660140785
Validation loss: 5.016209450200995

Epoch: 6| Step: 5
Training loss: 4.830827765131179
Validation loss: 5.001907267891657

Epoch: 6| Step: 6
Training loss: 4.886569257930233
Validation loss: 4.982761278831597

Epoch: 6| Step: 7
Training loss: 4.830879882216217
Validation loss: 4.96845054020736

Epoch: 6| Step: 8
Training loss: 5.696892664343672
Validation loss: 4.956981079868576

Epoch: 6| Step: 9
Training loss: 4.5208718200076685
Validation loss: 4.939665764222033

Epoch: 6| Step: 10
Training loss: 5.074401805180579
Validation loss: 4.918320299351329

Epoch: 6| Step: 11
Training loss: 4.697628421215696
Validation loss: 4.906504354630134

Epoch: 6| Step: 12
Training loss: 4.751988847867165
Validation loss: 4.883354203822401

Epoch: 6| Step: 13
Training loss: 5.259100519589494
Validation loss: 4.876012755298888

Epoch: 13| Step: 0
Training loss: 4.778165732510121
Validation loss: 4.865493453531226

Epoch: 6| Step: 1
Training loss: 4.523054195628414
Validation loss: 4.8477858376454535

Epoch: 6| Step: 2
Training loss: 4.78317700616848
Validation loss: 4.824565784728886

Epoch: 6| Step: 3
Training loss: 4.90020807564029
Validation loss: 4.811624729449944

Epoch: 6| Step: 4
Training loss: 4.899017251003998
Validation loss: 4.794247278060709

Epoch: 6| Step: 5
Training loss: 4.8353864759526894
Validation loss: 4.786556511181978

Epoch: 6| Step: 6
Training loss: 5.479910138917903
Validation loss: 4.760343755944253

Epoch: 6| Step: 7
Training loss: 5.2462840780696975
Validation loss: 4.7384758200819554

Epoch: 6| Step: 8
Training loss: 5.018687231448042
Validation loss: 4.7322099976381065

Epoch: 6| Step: 9
Training loss: 3.509356662230167
Validation loss: 4.723369952980187

Epoch: 6| Step: 10
Training loss: 4.643391513464533
Validation loss: 4.693506803780482

Epoch: 6| Step: 11
Training loss: 4.532292108076187
Validation loss: 4.687034808083652

Epoch: 6| Step: 12
Training loss: 5.1025314929668735
Validation loss: 4.6610963856077445

Epoch: 6| Step: 13
Training loss: 5.036544004840553
Validation loss: 4.637895319566585

Epoch: 14| Step: 0
Training loss: 5.360551799440279
Validation loss: 4.62549698145819

Epoch: 6| Step: 1
Training loss: 4.280441319182274
Validation loss: 4.605310949983831

Epoch: 6| Step: 2
Training loss: 3.9273231628740426
Validation loss: 4.585551733895158

Epoch: 6| Step: 3
Training loss: 4.722059895337137
Validation loss: 4.5693245896235055

Epoch: 6| Step: 4
Training loss: 4.878946516422108
Validation loss: 4.547361701300547

Epoch: 6| Step: 5
Training loss: 4.555985489900038
Validation loss: 4.525692020960283

Epoch: 6| Step: 6
Training loss: 4.306562676448776
Validation loss: 4.518962898288945

Epoch: 6| Step: 7
Training loss: 5.38197477380007
Validation loss: 4.493473061708053

Epoch: 6| Step: 8
Training loss: 4.425742247662987
Validation loss: 4.47317416910093

Epoch: 6| Step: 9
Training loss: 4.9589805287499855
Validation loss: 4.443057739303915

Epoch: 6| Step: 10
Training loss: 4.00059123438141
Validation loss: 4.423729315586023

Epoch: 6| Step: 11
Training loss: 4.665714348399329
Validation loss: 4.40942494405019

Epoch: 6| Step: 12
Training loss: 3.1386145994210137
Validation loss: 4.39605793886755

Epoch: 6| Step: 13
Training loss: 5.334802464954808
Validation loss: 4.374449134754056

Epoch: 15| Step: 0
Training loss: 3.6162672417048682
Validation loss: 4.344066746134003

Epoch: 6| Step: 1
Training loss: 3.997740345708323
Validation loss: 4.324268049283362

Epoch: 6| Step: 2
Training loss: 4.415054074881853
Validation loss: 4.295909595792275

Epoch: 6| Step: 3
Training loss: 4.282452936398229
Validation loss: 4.287555721220681

Epoch: 6| Step: 4
Training loss: 4.553587059186507
Validation loss: 4.272833530700432

Epoch: 6| Step: 5
Training loss: 4.80426112818537
Validation loss: 4.245074072202845

Epoch: 6| Step: 6
Training loss: 5.079116865273284
Validation loss: 4.215739196034819

Epoch: 6| Step: 7
Training loss: 4.663749237019587
Validation loss: 4.209569078075249

Epoch: 6| Step: 8
Training loss: 3.886765246855987
Validation loss: 4.185182481408071

Epoch: 6| Step: 9
Training loss: 4.954963030171981
Validation loss: 4.149834158319474

Epoch: 6| Step: 10
Training loss: 4.164736694952185
Validation loss: 4.1271371684064775

Epoch: 6| Step: 11
Training loss: 3.923278557441751
Validation loss: 4.104917754952547

Epoch: 6| Step: 12
Training loss: 3.862348762193211
Validation loss: 4.078099711305994

Epoch: 6| Step: 13
Training loss: 3.3540736752210787
Validation loss: 4.057331962290042

Epoch: 16| Step: 0
Training loss: 3.845163721138334
Validation loss: 4.043280108300809

Epoch: 6| Step: 1
Training loss: 4.510844620745086
Validation loss: 4.014624780905337

Epoch: 6| Step: 2
Training loss: 3.4641745694158796
Validation loss: 4.008384570530935

Epoch: 6| Step: 3
Training loss: 3.5070525367789314
Validation loss: 3.9721590373601146

Epoch: 6| Step: 4
Training loss: 4.286967226074457
Validation loss: 3.962383858836236

Epoch: 6| Step: 5
Training loss: 4.100281608028492
Validation loss: 3.919653639575293

Epoch: 6| Step: 6
Training loss: 4.6897972072850855
Validation loss: 3.914879627935028

Epoch: 6| Step: 7
Training loss: 3.9845269866079254
Validation loss: 3.888111467389379

Epoch: 6| Step: 8
Training loss: 3.597997394503572
Validation loss: 3.8486336611332597

Epoch: 6| Step: 9
Training loss: 5.194376971690006
Validation loss: 3.850451134793664

Epoch: 6| Step: 10
Training loss: 3.35073835292546
Validation loss: 3.8042388824698583

Epoch: 6| Step: 11
Training loss: 3.893551135916677
Validation loss: 3.7862464723757583

Epoch: 6| Step: 12
Training loss: 3.113393669061111
Validation loss: 3.7722226682861018

Epoch: 6| Step: 13
Training loss: 4.091942074914797
Validation loss: 3.7248626118201904

Epoch: 17| Step: 0
Training loss: 3.133807321639701
Validation loss: 3.7116613706000825

Epoch: 6| Step: 1
Training loss: 3.220228725863273
Validation loss: 3.695306812594103

Epoch: 6| Step: 2
Training loss: 4.262641506139507
Validation loss: 3.6683322646379852

Epoch: 6| Step: 3
Training loss: 4.405351046582773
Validation loss: 3.6393458297559698

Epoch: 6| Step: 4
Training loss: 3.8933044766528093
Validation loss: 3.615515333644901

Epoch: 6| Step: 5
Training loss: 3.7088095255652895
Validation loss: 3.6129056100830144

Epoch: 6| Step: 6
Training loss: 3.245567673930404
Validation loss: 3.5811712854421605

Epoch: 6| Step: 7
Training loss: 3.280666771781045
Validation loss: 3.5464129490079057

Epoch: 6| Step: 8
Training loss: 4.1223052499457715
Validation loss: 3.525746262787768

Epoch: 6| Step: 9
Training loss: 4.145177792554231
Validation loss: 3.5221497973173768

Epoch: 6| Step: 10
Training loss: 3.3103155454760076
Validation loss: 3.5129267590126605

Epoch: 6| Step: 11
Training loss: 4.160715328850256
Validation loss: 3.466290720447762

Epoch: 6| Step: 12
Training loss: 3.4527738228616105
Validation loss: 3.4497115254306663

Epoch: 6| Step: 13
Training loss: 3.227855210972216
Validation loss: 3.424450260250746

Epoch: 18| Step: 0
Training loss: 3.0571953120907294
Validation loss: 3.4004174525732336

Epoch: 6| Step: 1
Training loss: 3.3764769536681785
Validation loss: 3.384849252155241

Epoch: 6| Step: 2
Training loss: 2.781434728081162
Validation loss: 3.3497231737175053

Epoch: 6| Step: 3
Training loss: 3.7935635918410275
Validation loss: 3.3353670028241136

Epoch: 6| Step: 4
Training loss: 4.110749105604539
Validation loss: 3.3016589366791314

Epoch: 6| Step: 5
Training loss: 3.5062936327934198
Validation loss: 3.297796917818626

Epoch: 6| Step: 6
Training loss: 3.9877964065067983
Validation loss: 3.265790189857318

Epoch: 6| Step: 7
Training loss: 3.0451661624264625
Validation loss: 3.2356898159013365

Epoch: 6| Step: 8
Training loss: 3.139075053348001
Validation loss: 3.2202222718324487

Epoch: 6| Step: 9
Training loss: 3.608487106699808
Validation loss: 3.2132437250051247

Epoch: 6| Step: 10
Training loss: 3.1951377466443818
Validation loss: 3.21411953353428

Epoch: 6| Step: 11
Training loss: 3.3299426635754847
Validation loss: 3.1734077455651715

Epoch: 6| Step: 12
Training loss: 3.683097797877883
Validation loss: 3.1582324400518065

Epoch: 6| Step: 13
Training loss: 3.470738296459381
Validation loss: 3.162165944513484

Epoch: 19| Step: 0
Training loss: 2.2325532328889954
Validation loss: 3.1226535733060907

Epoch: 6| Step: 1
Training loss: 3.2090247924265407
Validation loss: 3.1145741213615206

Epoch: 6| Step: 2
Training loss: 3.7908933640447597
Validation loss: 3.0760910137621766

Epoch: 6| Step: 3
Training loss: 3.922124603961045
Validation loss: 3.060770939211457

Epoch: 6| Step: 4
Training loss: 3.4538232433989826
Validation loss: 3.045819228611424

Epoch: 6| Step: 5
Training loss: 3.4723629393144115
Validation loss: 3.018663125119374

Epoch: 6| Step: 6
Training loss: 2.609584046173445
Validation loss: 3.0193425597290973

Epoch: 6| Step: 7
Training loss: 2.6193711010870455
Validation loss: 3.0042092470406137

Epoch: 6| Step: 8
Training loss: 3.6013489368199085
Validation loss: 2.968045355822602

Epoch: 6| Step: 9
Training loss: 3.462705965492102
Validation loss: 2.9846938317866587

Epoch: 6| Step: 10
Training loss: 3.317913598019228
Validation loss: 2.9304246174510604

Epoch: 6| Step: 11
Training loss: 2.522536361931305
Validation loss: 2.9326778821899855

Epoch: 6| Step: 12
Training loss: 3.2990426264261217
Validation loss: 2.9177811938164724

Epoch: 6| Step: 13
Training loss: 3.709040299366101
Validation loss: 2.8959535733291046

Epoch: 20| Step: 0
Training loss: 3.365616504938284
Validation loss: 2.891868912996613

Epoch: 6| Step: 1
Training loss: 3.3701684064131645
Validation loss: 2.855235188479451

Epoch: 6| Step: 2
Training loss: 3.382836180993902
Validation loss: 2.8494583761574632

Epoch: 6| Step: 3
Training loss: 3.3967133456371026
Validation loss: 2.853277019415198

Epoch: 6| Step: 4
Training loss: 2.1376626337654683
Validation loss: 2.831759023287645

Epoch: 6| Step: 5
Training loss: 3.157915336976705
Validation loss: 2.828632888599528

Epoch: 6| Step: 6
Training loss: 2.6801920157295482
Validation loss: 2.8168379551031304

Epoch: 6| Step: 7
Training loss: 3.6680995280034137
Validation loss: 2.782927289994629

Epoch: 6| Step: 8
Training loss: 2.633625934939422
Validation loss: 2.826835621677401

Epoch: 6| Step: 9
Training loss: 3.3774792077746674
Validation loss: 2.7631607576164656

Epoch: 6| Step: 10
Training loss: 2.903069673633112
Validation loss: 2.7746001576624146

Epoch: 6| Step: 11
Training loss: 2.3570205359488843
Validation loss: 2.7698872798749212

Epoch: 6| Step: 12
Training loss: 3.038886763877831
Validation loss: 2.7533323731624724

Epoch: 6| Step: 13
Training loss: 3.5676284818228994
Validation loss: 2.7859981297524388

Epoch: 21| Step: 0
Training loss: 3.2034928273465573
Validation loss: 2.7411014189515557

Epoch: 6| Step: 1
Training loss: 2.2463114491985605
Validation loss: 2.755246252855119

Epoch: 6| Step: 2
Training loss: 3.677970858368751
Validation loss: 2.736151296138906

Epoch: 6| Step: 3
Training loss: 2.1507722133193057
Validation loss: 2.7214115944371007

Epoch: 6| Step: 4
Training loss: 2.6201880719481094
Validation loss: 2.7289181104276836

Epoch: 6| Step: 5
Training loss: 2.7667951102105057
Validation loss: 2.6994389863427806

Epoch: 6| Step: 6
Training loss: 2.4517527830384864
Validation loss: 2.7234904303581615

Epoch: 6| Step: 7
Training loss: 3.022025318213893
Validation loss: 2.701295853923685

Epoch: 6| Step: 8
Training loss: 2.919997647428218
Validation loss: 2.701978042879665

Epoch: 6| Step: 9
Training loss: 2.5806212391436745
Validation loss: 2.6787633685688927

Epoch: 6| Step: 10
Training loss: 3.2074029407399967
Validation loss: 2.6986869225277856

Epoch: 6| Step: 11
Training loss: 3.837498489031665
Validation loss: 2.684559091769338

Epoch: 6| Step: 12
Training loss: 3.671918113942364
Validation loss: 2.6798692838487637

Epoch: 6| Step: 13
Training loss: 3.6787502123683256
Validation loss: 2.671014387742343

Epoch: 22| Step: 0
Training loss: 3.3169220971386
Validation loss: 2.680969112618324

Epoch: 6| Step: 1
Training loss: 3.3325305130885905
Validation loss: 2.641295818030863

Epoch: 6| Step: 2
Training loss: 3.612146411737639
Validation loss: 2.6657032597874983

Epoch: 6| Step: 3
Training loss: 2.799921773771457
Validation loss: 2.656616161571603

Epoch: 6| Step: 4
Training loss: 2.486015497946518
Validation loss: 2.6618827168578703

Epoch: 6| Step: 5
Training loss: 3.069443596733824
Validation loss: 2.6628156392951947

Epoch: 6| Step: 6
Training loss: 3.517154886305506
Validation loss: 2.638510198754342

Epoch: 6| Step: 7
Training loss: 3.2310118950896696
Validation loss: 2.6334570098901007

Epoch: 6| Step: 8
Training loss: 2.5845106170017047
Validation loss: 2.6663765236716426

Epoch: 6| Step: 9
Training loss: 2.5388068906794823
Validation loss: 2.637978360597721

Epoch: 6| Step: 10
Training loss: 2.6993636935633876
Validation loss: 2.6455331376430107

Epoch: 6| Step: 11
Training loss: 2.936868640335059
Validation loss: 2.6405865542122773

Epoch: 6| Step: 12
Training loss: 2.9908715285013496
Validation loss: 2.653627376586203

Epoch: 6| Step: 13
Training loss: 2.4582819098142745
Validation loss: 2.6142307575373485

Epoch: 23| Step: 0
Training loss: 3.0615435293898132
Validation loss: 2.6266648989210752

Epoch: 6| Step: 1
Training loss: 3.5290555633987495
Validation loss: 2.6309520143202585

Epoch: 6| Step: 2
Training loss: 2.6285392879215204
Validation loss: 2.6382713908704356

Epoch: 6| Step: 3
Training loss: 3.2232100317277452
Validation loss: 2.632210141990735

Epoch: 6| Step: 4
Training loss: 3.1948056740086295
Validation loss: 2.628138696606724

Epoch: 6| Step: 5
Training loss: 2.553132683545134
Validation loss: 2.62108575907029

Epoch: 6| Step: 6
Training loss: 2.929538733202047
Validation loss: 2.6486261704546057

Epoch: 6| Step: 7
Training loss: 1.9675342499637136
Validation loss: 2.6312425202870933

Epoch: 6| Step: 8
Training loss: 3.751693343264416
Validation loss: 2.6513346603568744

Epoch: 6| Step: 9
Training loss: 2.933711429272508
Validation loss: 2.6265185622689025

Epoch: 6| Step: 10
Training loss: 2.9691942384524426
Validation loss: 2.6230633834040713

Epoch: 6| Step: 11
Training loss: 3.211164851620774
Validation loss: 2.627325952424675

Epoch: 6| Step: 12
Training loss: 3.0353686480541113
Validation loss: 2.661036742140411

Epoch: 6| Step: 13
Training loss: 1.974237695685335
Validation loss: 2.6340586379822932

Epoch: 24| Step: 0
Training loss: 2.1834159874255543
Validation loss: 2.6447395626427967

Epoch: 6| Step: 1
Training loss: 3.1216702841842827
Validation loss: 2.624810678322294

Epoch: 6| Step: 2
Training loss: 3.129343447578554
Validation loss: 2.664704410966489

Epoch: 6| Step: 3
Training loss: 2.2834458952212087
Validation loss: 2.642170474135467

Epoch: 6| Step: 4
Training loss: 3.308450202575206
Validation loss: 2.6210454402036842

Epoch: 6| Step: 5
Training loss: 2.6761323795903746
Validation loss: 2.6002963396145815

Epoch: 6| Step: 6
Training loss: 3.1560202033359586
Validation loss: 2.622359622318717

Epoch: 6| Step: 7
Training loss: 2.646932979160408
Validation loss: 2.596079808290129

Epoch: 6| Step: 8
Training loss: 3.2776354545111417
Validation loss: 2.616521330750776

Epoch: 6| Step: 9
Training loss: 3.7108177406662484
Validation loss: 2.596165942933513

Epoch: 6| Step: 10
Training loss: 2.6646491604553555
Validation loss: 2.6346934260524604

Epoch: 6| Step: 11
Training loss: 3.0825838432449433
Validation loss: 2.6113539701125843

Epoch: 6| Step: 12
Training loss: 2.8682865873876158
Validation loss: 2.6131995874579426

Epoch: 6| Step: 13
Training loss: 3.7141321826475457
Validation loss: 2.589105667731795

Epoch: 25| Step: 0
Training loss: 3.1503576287600925
Validation loss: 2.6344201699413734

Epoch: 6| Step: 1
Training loss: 2.3669605712894373
Validation loss: 2.612435822881809

Epoch: 6| Step: 2
Training loss: 2.7645278737288983
Validation loss: 2.604491035851237

Epoch: 6| Step: 3
Training loss: 3.3933940778090554
Validation loss: 2.6237486692882874

Epoch: 6| Step: 4
Training loss: 3.3728994261073444
Validation loss: 2.610138819957682

Epoch: 6| Step: 5
Training loss: 3.3259227074721838
Validation loss: 2.609960532949457

Epoch: 6| Step: 6
Training loss: 3.2502059871245446
Validation loss: 2.6347686636934653

Epoch: 6| Step: 7
Training loss: 3.189052727182937
Validation loss: 2.613437655694149

Epoch: 6| Step: 8
Training loss: 2.768346880290741
Validation loss: 2.6252554297020545

Epoch: 6| Step: 9
Training loss: 3.0637400705027984
Validation loss: 2.6225197125289763

Epoch: 6| Step: 10
Training loss: 2.3221687059254106
Validation loss: 2.6099196763220487

Epoch: 6| Step: 11
Training loss: 2.9423113439814412
Validation loss: 2.5912644621580614

Epoch: 6| Step: 12
Training loss: 2.79183454625574
Validation loss: 2.5884128658265717

Epoch: 6| Step: 13
Training loss: 2.517689491572891
Validation loss: 2.635692109439903

Epoch: 26| Step: 0
Training loss: 3.336887340533553
Validation loss: 2.623308180551766

Epoch: 6| Step: 1
Training loss: 2.7783459707459763
Validation loss: 2.6386635457620735

Epoch: 6| Step: 2
Training loss: 2.4137474274189463
Validation loss: 2.6070663125528872

Epoch: 6| Step: 3
Training loss: 2.585589336456367
Validation loss: 2.6134635682293688

Epoch: 6| Step: 4
Training loss: 2.747849056712643
Validation loss: 2.614858506861496

Epoch: 6| Step: 5
Training loss: 2.2723216041567014
Validation loss: 2.6218398067504984

Epoch: 6| Step: 6
Training loss: 2.436028256294723
Validation loss: 2.613384555578771

Epoch: 6| Step: 7
Training loss: 2.7551010678232655
Validation loss: 2.616713662277743

Epoch: 6| Step: 8
Training loss: 2.9615820834808586
Validation loss: 2.6062323278221093

Epoch: 6| Step: 9
Training loss: 3.6613126737544714
Validation loss: 2.6020113127885627

Epoch: 6| Step: 10
Training loss: 3.446626097060993
Validation loss: 2.633770247268668

Epoch: 6| Step: 11
Training loss: 2.8480832129119573
Validation loss: 2.6301432049677365

Epoch: 6| Step: 12
Training loss: 3.661332078966378
Validation loss: 2.622823603070333

Epoch: 6| Step: 13
Training loss: 3.5042567933626274
Validation loss: 2.633317408884149

Epoch: 27| Step: 0
Training loss: 3.2909866467566924
Validation loss: 2.6026670907156557

Epoch: 6| Step: 1
Training loss: 2.6110218812923423
Validation loss: 2.5849461172088684

Epoch: 6| Step: 2
Training loss: 3.1451988506677444
Validation loss: 2.594045618979436

Epoch: 6| Step: 3
Training loss: 3.444215907100146
Validation loss: 2.65448603778909

Epoch: 6| Step: 4
Training loss: 2.579640076245838
Validation loss: 2.6245937540903324

Epoch: 6| Step: 5
Training loss: 2.6790147832253997
Validation loss: 2.600475380383897

Epoch: 6| Step: 6
Training loss: 2.282912184401102
Validation loss: 2.6162731343303482

Epoch: 6| Step: 7
Training loss: 2.4478333371095036
Validation loss: 2.6033089296174197

Epoch: 6| Step: 8
Training loss: 3.38515865027393
Validation loss: 2.593064473691408

Epoch: 6| Step: 9
Training loss: 3.052080607928382
Validation loss: 2.590852858243957

Epoch: 6| Step: 10
Training loss: 3.1963141254173197
Validation loss: 2.5939151648566297

Epoch: 6| Step: 11
Training loss: 2.9882538039997777
Validation loss: 2.6146970426016507

Epoch: 6| Step: 12
Training loss: 3.1928791209970395
Validation loss: 2.5785859204018533

Epoch: 6| Step: 13
Training loss: 3.14926386512005
Validation loss: 2.6157800863764966

Epoch: 28| Step: 0
Training loss: 3.1412093344870935
Validation loss: 2.589620622884777

Epoch: 6| Step: 1
Training loss: 2.687391766874899
Validation loss: 2.6269198232152373

Epoch: 6| Step: 2
Training loss: 3.082030631139038
Validation loss: 2.593866578165869

Epoch: 6| Step: 3
Training loss: 2.8229500650117
Validation loss: 2.6012889537545822

Epoch: 6| Step: 4
Training loss: 2.0398349979465635
Validation loss: 2.614267675738716

Epoch: 6| Step: 5
Training loss: 3.1912541440764257
Validation loss: 2.612915784576995

Epoch: 6| Step: 6
Training loss: 2.7147076250157856
Validation loss: 2.6302788486894917

Epoch: 6| Step: 7
Training loss: 3.2624788597854355
Validation loss: 2.6064069605688793

Epoch: 6| Step: 8
Training loss: 2.6121772749301724
Validation loss: 2.6291415391695714

Epoch: 6| Step: 9
Training loss: 3.213302595168285
Validation loss: 2.5886614685468876

Epoch: 6| Step: 10
Training loss: 3.102920042954499
Validation loss: 2.6059962510731642

Epoch: 6| Step: 11
Training loss: 3.754698543714902
Validation loss: 2.601784660138591

Epoch: 6| Step: 12
Training loss: 3.3461645802427724
Validation loss: 2.6270921644664305

Epoch: 6| Step: 13
Training loss: 1.6119515987210233
Validation loss: 2.6371640633981457

Epoch: 29| Step: 0
Training loss: 2.8086560577993853
Validation loss: 2.5932739943842007

Epoch: 6| Step: 1
Training loss: 3.7906570068416987
Validation loss: 2.6324513568857304

Epoch: 6| Step: 2
Training loss: 1.842396125919246
Validation loss: 2.6199372217960533

Epoch: 6| Step: 3
Training loss: 3.4596099029431038
Validation loss: 2.6194687298951647

Epoch: 6| Step: 4
Training loss: 3.196022309274357
Validation loss: 2.6243081497109384

Epoch: 6| Step: 5
Training loss: 3.0545160972332157
Validation loss: 2.626288736851545

Epoch: 6| Step: 6
Training loss: 2.038674971780437
Validation loss: 2.580280648465392

Epoch: 6| Step: 7
Training loss: 3.194151277957043
Validation loss: 2.6053509591580193

Epoch: 6| Step: 8
Training loss: 2.9913218867156117
Validation loss: 2.612111990116709

Epoch: 6| Step: 9
Training loss: 2.95837774825447
Validation loss: 2.614701399821361

Epoch: 6| Step: 10
Training loss: 2.5101257303367075
Validation loss: 2.6221240511428188

Epoch: 6| Step: 11
Training loss: 3.154644548370307
Validation loss: 2.6128021492177034

Epoch: 6| Step: 12
Training loss: 3.6050825480455586
Validation loss: 2.601110294231801

Epoch: 6| Step: 13
Training loss: 1.8296136256419062
Validation loss: 2.6089683865812203

Epoch: 30| Step: 0
Training loss: 3.215656460533054
Validation loss: 2.622192839965164

Epoch: 6| Step: 1
Training loss: 2.34552484068263
Validation loss: 2.6027519455609345

Epoch: 6| Step: 2
Training loss: 3.1032104726277847
Validation loss: 2.621335718876419

Epoch: 6| Step: 3
Training loss: 3.275472295353663
Validation loss: 2.599560316340081

Epoch: 6| Step: 4
Training loss: 2.5307878613984727
Validation loss: 2.594623000173506

Epoch: 6| Step: 5
Training loss: 3.452930427696623
Validation loss: 2.617878538123231

Epoch: 6| Step: 6
Training loss: 2.888421285720577
Validation loss: 2.615341892927303

Epoch: 6| Step: 7
Training loss: 2.559267563946214
Validation loss: 2.5867103889135876

Epoch: 6| Step: 8
Training loss: 2.5471668661248477
Validation loss: 2.633164508966623

Epoch: 6| Step: 9
Training loss: 2.6848447235501713
Validation loss: 2.6184606847865775

Epoch: 6| Step: 10
Training loss: 2.9384374543031475
Validation loss: 2.607789086549901

Epoch: 6| Step: 11
Training loss: 2.858572425147639
Validation loss: 2.5971018876085616

Epoch: 6| Step: 12
Training loss: 3.622961852523273
Validation loss: 2.6320192175238804

Epoch: 6| Step: 13
Training loss: 3.5636090342600797
Validation loss: 2.592011940928801

Epoch: 31| Step: 0
Training loss: 3.0731625905743205
Validation loss: 2.586340781799684

Epoch: 6| Step: 1
Training loss: 2.613238917351446
Validation loss: 2.5873734766490135

Epoch: 6| Step: 2
Training loss: 2.589787501303997
Validation loss: 2.6251615415011855

Epoch: 6| Step: 3
Training loss: 2.965523341600129
Validation loss: 2.6122046975983517

Epoch: 6| Step: 4
Training loss: 2.838329136909374
Validation loss: 2.61243911325226

Epoch: 6| Step: 5
Training loss: 3.011282526824719
Validation loss: 2.6005302642178525

Epoch: 6| Step: 6
Training loss: 2.9086398891300846
Validation loss: 2.616902763490415

Epoch: 6| Step: 7
Training loss: 3.440559690099873
Validation loss: 2.6195247307594167

Epoch: 6| Step: 8
Training loss: 3.1222057820253455
Validation loss: 2.624374217394724

Epoch: 6| Step: 9
Training loss: 2.5209273854094496
Validation loss: 2.571325412793952

Epoch: 6| Step: 10
Training loss: 2.9845656089428614
Validation loss: 2.5973167215429744

Epoch: 6| Step: 11
Training loss: 3.039703850626195
Validation loss: 2.6082220617224374

Epoch: 6| Step: 12
Training loss: 3.6094475280608673
Validation loss: 2.594393096321658

Epoch: 6| Step: 13
Training loss: 2.2398407780734337
Validation loss: 2.592424926237241

Epoch: 32| Step: 0
Training loss: 2.4606962539863235
Validation loss: 2.595757828263223

Epoch: 6| Step: 1
Training loss: 3.830964946254872
Validation loss: 2.5919323336904125

Epoch: 6| Step: 2
Training loss: 2.830181238416571
Validation loss: 2.5914657265864736

Epoch: 6| Step: 3
Training loss: 3.1314889295109145
Validation loss: 2.596262940475619

Epoch: 6| Step: 4
Training loss: 2.40786857168372
Validation loss: 2.613514852043951

Epoch: 6| Step: 5
Training loss: 2.6191764903048673
Validation loss: 2.6179372845753335

Epoch: 6| Step: 6
Training loss: 2.5811804958342597
Validation loss: 2.610988030696101

Epoch: 6| Step: 7
Training loss: 2.589928166781491
Validation loss: 2.6066085654941955

Epoch: 6| Step: 8
Training loss: 3.1058842219127807
Validation loss: 2.6166736414842333

Epoch: 6| Step: 9
Training loss: 2.7411474445465607
Validation loss: 2.599719714524876

Epoch: 6| Step: 10
Training loss: 3.3089788183535567
Validation loss: 2.612256303488088

Epoch: 6| Step: 11
Training loss: 2.9794334523361004
Validation loss: 2.616216322567546

Epoch: 6| Step: 12
Training loss: 2.954938059511041
Validation loss: 2.5995022241235404

Epoch: 6| Step: 13
Training loss: 4.023264701613968
Validation loss: 2.6003180895354148

Epoch: 33| Step: 0
Training loss: 2.7735017151181696
Validation loss: 2.624166073939468

Epoch: 6| Step: 1
Training loss: 2.253737630106683
Validation loss: 2.6217111091822694

Epoch: 6| Step: 2
Training loss: 2.9681897086413422
Validation loss: 2.5900674072307632

Epoch: 6| Step: 3
Training loss: 2.8960856229443226
Validation loss: 2.616966349637784

Epoch: 6| Step: 4
Training loss: 3.0664580322558512
Validation loss: 2.621536415319663

Epoch: 6| Step: 5
Training loss: 4.075010784111497
Validation loss: 2.6120106953199973

Epoch: 6| Step: 6
Training loss: 2.9842657099180325
Validation loss: 2.601035540724241

Epoch: 6| Step: 7
Training loss: 2.8462072801629947
Validation loss: 2.6013792806683345

Epoch: 6| Step: 8
Training loss: 3.3923422688056677
Validation loss: 2.5995685238301607

Epoch: 6| Step: 9
Training loss: 2.4812582366576037
Validation loss: 2.605893639336497

Epoch: 6| Step: 10
Training loss: 2.674477542231635
Validation loss: 2.639624149485333

Epoch: 6| Step: 11
Training loss: 3.308145503966692
Validation loss: 2.6031010301045248

Epoch: 6| Step: 12
Training loss: 2.219580266640203
Validation loss: 2.611389505497585

Epoch: 6| Step: 13
Training loss: 2.9844659122380732
Validation loss: 2.6118323520479936

Epoch: 34| Step: 0
Training loss: 2.9680439962843197
Validation loss: 2.6011707952471608

Epoch: 6| Step: 1
Training loss: 2.864007584481879
Validation loss: 2.607742174001585

Epoch: 6| Step: 2
Training loss: 2.6668697120930553
Validation loss: 2.6082960519724674

Epoch: 6| Step: 3
Training loss: 2.632836769060066
Validation loss: 2.578165524718287

Epoch: 6| Step: 4
Training loss: 1.9914975635878562
Validation loss: 2.5893560424949342

Epoch: 6| Step: 5
Training loss: 4.108337967710738
Validation loss: 2.6017962053333727

Epoch: 6| Step: 6
Training loss: 3.418917836980788
Validation loss: 2.6167039699127956

Epoch: 6| Step: 7
Training loss: 3.2590262441312934
Validation loss: 2.6174977451251324

Epoch: 6| Step: 8
Training loss: 2.4392367313575787
Validation loss: 2.584928499066283

Epoch: 6| Step: 9
Training loss: 3.0491699965476964
Validation loss: 2.5941909689961498

Epoch: 6| Step: 10
Training loss: 2.8956563515862745
Validation loss: 2.591776100084888

Epoch: 6| Step: 11
Training loss: 2.34602713272782
Validation loss: 2.6089080880115922

Epoch: 6| Step: 12
Training loss: 3.5108699939792736
Validation loss: 2.6164333118226795

Epoch: 6| Step: 13
Training loss: 2.2404844615068007
Validation loss: 2.595448917672032

Epoch: 35| Step: 0
Training loss: 2.998914522250939
Validation loss: 2.6052019698778923

Epoch: 6| Step: 1
Training loss: 3.0834604872869957
Validation loss: 2.586250564058966

Epoch: 6| Step: 2
Training loss: 3.6624227730482564
Validation loss: 2.585107445888918

Epoch: 6| Step: 3
Training loss: 2.2634892361205723
Validation loss: 2.5890722276788303

Epoch: 6| Step: 4
Training loss: 3.0756846402328946
Validation loss: 2.59232937430372

Epoch: 6| Step: 5
Training loss: 2.5066339213011304
Validation loss: 2.606520216742179

Epoch: 6| Step: 6
Training loss: 2.8379669074185023
Validation loss: 2.5910495775837203

Epoch: 6| Step: 7
Training loss: 3.347312669248705
Validation loss: 2.5649610547052353

Epoch: 6| Step: 8
Training loss: 3.003197237827045
Validation loss: 2.600941660403813

Epoch: 6| Step: 9
Training loss: 2.1493547180940413
Validation loss: 2.6097094733056183

Epoch: 6| Step: 10
Training loss: 3.2732999859242295
Validation loss: 2.5843120468234835

Epoch: 6| Step: 11
Training loss: 3.0166312796974255
Validation loss: 2.592411061867455

Epoch: 6| Step: 12
Training loss: 2.350096793920603
Validation loss: 2.587498819228962

Epoch: 6| Step: 13
Training loss: 3.4203135093523667
Validation loss: 2.594899772852511

Epoch: 36| Step: 0
Training loss: 2.578366262533458
Validation loss: 2.5896401944712064

Epoch: 6| Step: 1
Training loss: 2.7625989145374974
Validation loss: 2.603614219559573

Epoch: 6| Step: 2
Training loss: 2.3822056732425323
Validation loss: 2.580158920683001

Epoch: 6| Step: 3
Training loss: 3.36476887446259
Validation loss: 2.5621162305256338

Epoch: 6| Step: 4
Training loss: 2.677180326809963
Validation loss: 2.573384462691624

Epoch: 6| Step: 5
Training loss: 3.837742522587691
Validation loss: 2.6108199631939906

Epoch: 6| Step: 6
Training loss: 2.8083226015997096
Validation loss: 2.616062044394924

Epoch: 6| Step: 7
Training loss: 3.527677366040856
Validation loss: 2.590108813072628

Epoch: 6| Step: 8
Training loss: 2.4571707826909504
Validation loss: 2.6021284636838646

Epoch: 6| Step: 9
Training loss: 2.622486546048254
Validation loss: 2.581947332618948

Epoch: 6| Step: 10
Training loss: 3.266045940227908
Validation loss: 2.5947438093123822

Epoch: 6| Step: 11
Training loss: 3.0599080230253652
Validation loss: 2.594958793024811

Epoch: 6| Step: 12
Training loss: 3.0831780953033507
Validation loss: 2.6003913345879037

Epoch: 6| Step: 13
Training loss: 2.268613751316238
Validation loss: 2.616106852760389

Epoch: 37| Step: 0
Training loss: 3.7483008031817313
Validation loss: 2.5776899789251715

Epoch: 6| Step: 1
Training loss: 2.37260939093658
Validation loss: 2.596866479404603

Epoch: 6| Step: 2
Training loss: 3.5234649724798572
Validation loss: 2.605003913092464

Epoch: 6| Step: 3
Training loss: 2.9854814166128096
Validation loss: 2.5773263698013342

Epoch: 6| Step: 4
Training loss: 2.9890608026287326
Validation loss: 2.619982552940356

Epoch: 6| Step: 5
Training loss: 2.8618693494105742
Validation loss: 2.558046668620079

Epoch: 6| Step: 6
Training loss: 2.4377997776457963
Validation loss: 2.5801988148230013

Epoch: 6| Step: 7
Training loss: 3.1218897791484976
Validation loss: 2.584414625647103

Epoch: 6| Step: 8
Training loss: 3.3808146649538613
Validation loss: 2.5967704057586243

Epoch: 6| Step: 9
Training loss: 2.7656682760010134
Validation loss: 2.6122673431140746

Epoch: 6| Step: 10
Training loss: 3.2826729731660573
Validation loss: 2.575696038758123

Epoch: 6| Step: 11
Training loss: 2.6622048442735458
Validation loss: 2.6019726935222973

Epoch: 6| Step: 12
Training loss: 1.9485817520106254
Validation loss: 2.5845851957889594

Epoch: 6| Step: 13
Training loss: 2.2676966173753956
Validation loss: 2.58823110571496

Epoch: 38| Step: 0
Training loss: 2.19833415858803
Validation loss: 2.604694529204632

Epoch: 6| Step: 1
Training loss: 2.8719296853853944
Validation loss: 2.605517531619662

Epoch: 6| Step: 2
Training loss: 3.2335395655455095
Validation loss: 2.606230950700891

Epoch: 6| Step: 3
Training loss: 2.9285941970418614
Validation loss: 2.603430121499676

Epoch: 6| Step: 4
Training loss: 3.251028045035812
Validation loss: 2.5783774333436584

Epoch: 6| Step: 5
Training loss: 2.9307605456772876
Validation loss: 2.6008856487624827

Epoch: 6| Step: 6
Training loss: 2.9883144401751593
Validation loss: 2.5963097326189684

Epoch: 6| Step: 7
Training loss: 2.9833126074499017
Validation loss: 2.5753314005207417

Epoch: 6| Step: 8
Training loss: 2.947890390519397
Validation loss: 2.5708431640262597

Epoch: 6| Step: 9
Training loss: 2.5474311829800316
Validation loss: 2.5998700848960894

Epoch: 6| Step: 10
Training loss: 3.229969064428563
Validation loss: 2.611616482901346

Epoch: 6| Step: 11
Training loss: 3.355644674429978
Validation loss: 2.583559479541916

Epoch: 6| Step: 12
Training loss: 2.8593653277457656
Validation loss: 2.572863491851174

Epoch: 6| Step: 13
Training loss: 2.398196130591936
Validation loss: 2.5970595508485212

Epoch: 39| Step: 0
Training loss: 2.4867329473926123
Validation loss: 2.589541899460882

Epoch: 6| Step: 1
Training loss: 3.1386794711521335
Validation loss: 2.596010877582071

Epoch: 6| Step: 2
Training loss: 3.5612721251218535
Validation loss: 2.5872131003126517

Epoch: 6| Step: 3
Training loss: 3.5609324168578653
Validation loss: 2.5879412001011346

Epoch: 6| Step: 4
Training loss: 2.811484344200032
Validation loss: 2.573299955491836

Epoch: 6| Step: 5
Training loss: 2.4744827731895835
Validation loss: 2.5669599588712213

Epoch: 6| Step: 6
Training loss: 2.5964387492817873
Validation loss: 2.596104183738127

Epoch: 6| Step: 7
Training loss: 3.0497333910374347
Validation loss: 2.5924416059053987

Epoch: 6| Step: 8
Training loss: 2.4532186891195633
Validation loss: 2.5890302448096687

Epoch: 6| Step: 9
Training loss: 2.8041966255783106
Validation loss: 2.603721073216349

Epoch: 6| Step: 10
Training loss: 3.131567500724945
Validation loss: 2.5794041199681828

Epoch: 6| Step: 11
Training loss: 2.7497121486866156
Validation loss: 2.5876249067117407

Epoch: 6| Step: 12
Training loss: 3.1666299081643188
Validation loss: 2.5822745362104804

Epoch: 6| Step: 13
Training loss: 2.4987792849482475
Validation loss: 2.5885513964744344

Epoch: 40| Step: 0
Training loss: 3.372930669411866
Validation loss: 2.5959367801154385

Epoch: 6| Step: 1
Training loss: 3.1997339674515723
Validation loss: 2.5824584716714543

Epoch: 6| Step: 2
Training loss: 2.949152297730234
Validation loss: 2.570536130249368

Epoch: 6| Step: 3
Training loss: 3.2864977334991305
Validation loss: 2.5779368531107743

Epoch: 6| Step: 4
Training loss: 2.184522837164338
Validation loss: 2.589445990663459

Epoch: 6| Step: 5
Training loss: 2.78027618161526
Validation loss: 2.572865268459101

Epoch: 6| Step: 6
Training loss: 2.9782018277324633
Validation loss: 2.596252090518273

Epoch: 6| Step: 7
Training loss: 3.21918506830025
Validation loss: 2.5939014132155434

Epoch: 6| Step: 8
Training loss: 3.170381542072571
Validation loss: 2.589073755522006

Epoch: 6| Step: 9
Training loss: 3.180472312256203
Validation loss: 2.574850453630756

Epoch: 6| Step: 10
Training loss: 2.853253759213388
Validation loss: 2.5840713671984963

Epoch: 6| Step: 11
Training loss: 2.8747060874307357
Validation loss: 2.617899582313481

Epoch: 6| Step: 12
Training loss: 2.459461944477989
Validation loss: 2.5785648889230357

Epoch: 6| Step: 13
Training loss: 2.1658360894442383
Validation loss: 2.5851331911797892

Epoch: 41| Step: 0
Training loss: 2.5862728950147145
Validation loss: 2.5837164997258557

Epoch: 6| Step: 1
Training loss: 3.08021760865407
Validation loss: 2.5884601465214487

Epoch: 6| Step: 2
Training loss: 2.2595139794454306
Validation loss: 2.5788441649040124

Epoch: 6| Step: 3
Training loss: 2.6278618244210468
Validation loss: 2.6043176783594753

Epoch: 6| Step: 4
Training loss: 3.21144578906313
Validation loss: 2.590084596976115

Epoch: 6| Step: 5
Training loss: 2.935270884034162
Validation loss: 2.5957576761686534

Epoch: 6| Step: 6
Training loss: 3.5304239032595706
Validation loss: 2.5670042221783262

Epoch: 6| Step: 7
Training loss: 3.429362149111094
Validation loss: 2.599767223473359

Epoch: 6| Step: 8
Training loss: 2.9026871037859645
Validation loss: 2.586564287987137

Epoch: 6| Step: 9
Training loss: 2.9056021675891603
Validation loss: 2.5905251745589197

Epoch: 6| Step: 10
Training loss: 2.6879632240118423
Validation loss: 2.576055417606065

Epoch: 6| Step: 11
Training loss: 3.2633260273161615
Validation loss: 2.588330526145249

Epoch: 6| Step: 12
Training loss: 2.557653542661146
Validation loss: 2.597986581718157

Epoch: 6| Step: 13
Training loss: 2.862665836244678
Validation loss: 2.594957929078873

Epoch: 42| Step: 0
Training loss: 3.311602488873253
Validation loss: 2.573091861107024

Epoch: 6| Step: 1
Training loss: 2.497831644027579
Validation loss: 2.6137445353919526

Epoch: 6| Step: 2
Training loss: 2.8276365079568433
Validation loss: 2.5695126937305774

Epoch: 6| Step: 3
Training loss: 1.8525523183747534
Validation loss: 2.5772240788305196

Epoch: 6| Step: 4
Training loss: 2.5045679322067858
Validation loss: 2.589998875757619

Epoch: 6| Step: 5
Training loss: 3.424738552389318
Validation loss: 2.5818231603135553

Epoch: 6| Step: 6
Training loss: 2.588699939783455
Validation loss: 2.5791381674795995

Epoch: 6| Step: 7
Training loss: 3.1000971563557833
Validation loss: 2.577642880602234

Epoch: 6| Step: 8
Training loss: 2.5938535922401815
Validation loss: 2.598452332097733

Epoch: 6| Step: 9
Training loss: 3.122932818478955
Validation loss: 2.5733969013847453

Epoch: 6| Step: 10
Training loss: 3.052912906397805
Validation loss: 2.599720817008966

Epoch: 6| Step: 11
Training loss: 3.5228348108696914
Validation loss: 2.5927657656699696

Epoch: 6| Step: 12
Training loss: 3.060174798897064
Validation loss: 2.5722668448955517

Epoch: 6| Step: 13
Training loss: 3.33024307692637
Validation loss: 2.5686008341895135

Epoch: 43| Step: 0
Training loss: 2.430027683398636
Validation loss: 2.599993992830883

Epoch: 6| Step: 1
Training loss: 2.034049115543516
Validation loss: 2.581806594750666

Epoch: 6| Step: 2
Training loss: 2.754543106353931
Validation loss: 2.5757321755717135

Epoch: 6| Step: 3
Training loss: 3.1356955031463354
Validation loss: 2.596163420929332

Epoch: 6| Step: 4
Training loss: 2.57894865808342
Validation loss: 2.5906222289262657

Epoch: 6| Step: 5
Training loss: 2.9697538585970142
Validation loss: 2.593273161017033

Epoch: 6| Step: 6
Training loss: 2.864634528425103
Validation loss: 2.586809198340659

Epoch: 6| Step: 7
Training loss: 3.51129670625058
Validation loss: 2.605344170598603

Epoch: 6| Step: 8
Training loss: 3.2931713254620103
Validation loss: 2.548673623647929

Epoch: 6| Step: 9
Training loss: 2.5951906362787978
Validation loss: 2.574831292344112

Epoch: 6| Step: 10
Training loss: 3.0153631383229835
Validation loss: 2.594707054968181

Epoch: 6| Step: 11
Training loss: 3.222354537249573
Validation loss: 2.5537725042258947

Epoch: 6| Step: 12
Training loss: 3.6191428648215545
Validation loss: 2.590782267569448

Epoch: 6| Step: 13
Training loss: 2.3535443949227024
Validation loss: 2.58283054405629

Epoch: 44| Step: 0
Training loss: 2.0727487876298696
Validation loss: 2.5976873649629155

Epoch: 6| Step: 1
Training loss: 3.14765227491062
Validation loss: 2.5713943502200265

Epoch: 6| Step: 2
Training loss: 3.300367629641233
Validation loss: 2.6029009224176387

Epoch: 6| Step: 3
Training loss: 2.480248436943356
Validation loss: 2.5859866203131574

Epoch: 6| Step: 4
Training loss: 3.095708054018158
Validation loss: 2.5731234813395387

Epoch: 6| Step: 5
Training loss: 2.7931503983762167
Validation loss: 2.6083627768403086

Epoch: 6| Step: 6
Training loss: 2.6732547164671328
Validation loss: 2.579169943194457

Epoch: 6| Step: 7
Training loss: 3.1237134192356213
Validation loss: 2.618263537929799

Epoch: 6| Step: 8
Training loss: 2.5355605168990105
Validation loss: 2.5867826392275526

Epoch: 6| Step: 9
Training loss: 3.2994215834043064
Validation loss: 2.6042658324690486

Epoch: 6| Step: 10
Training loss: 3.241492948478244
Validation loss: 2.5850416450321867

Epoch: 6| Step: 11
Training loss: 3.2288674164621285
Validation loss: 2.586907142313991

Epoch: 6| Step: 12
Training loss: 2.8662044492579883
Validation loss: 2.586521250460366

Epoch: 6| Step: 13
Training loss: 2.797839717606908
Validation loss: 2.5951134559534634

Epoch: 45| Step: 0
Training loss: 2.92636432618286
Validation loss: 2.584707968811931

Epoch: 6| Step: 1
Training loss: 2.3567872666827503
Validation loss: 2.5851112629238875

Epoch: 6| Step: 2
Training loss: 2.697359142850655
Validation loss: 2.6115740525890394

Epoch: 6| Step: 3
Training loss: 2.5694417203138418
Validation loss: 2.5508439929548867

Epoch: 6| Step: 4
Training loss: 4.000631759344635
Validation loss: 2.593853268060674

Epoch: 6| Step: 5
Training loss: 2.7248026680147612
Validation loss: 2.5920576694524087

Epoch: 6| Step: 6
Training loss: 2.827506740707066
Validation loss: 2.582489232692444

Epoch: 6| Step: 7
Training loss: 2.4198787214296966
Validation loss: 2.5906148535395186

Epoch: 6| Step: 8
Training loss: 3.2987136414415272
Validation loss: 2.572300487473324

Epoch: 6| Step: 9
Training loss: 2.47698326026333
Validation loss: 2.593797551082572

Epoch: 6| Step: 10
Training loss: 3.0719825143713817
Validation loss: 2.5832092845506365

Epoch: 6| Step: 11
Training loss: 2.9526392623009756
Validation loss: 2.594832444421473

Epoch: 6| Step: 12
Training loss: 3.3086831036857
Validation loss: 2.5963449505859333

Epoch: 6| Step: 13
Training loss: 2.5794175115899094
Validation loss: 2.5784350475077633

Epoch: 46| Step: 0
Training loss: 2.6715601685402595
Validation loss: 2.586685156352811

Epoch: 6| Step: 1
Training loss: 2.6525784418154594
Validation loss: 2.5820153758263333

Epoch: 6| Step: 2
Training loss: 3.0929820330961615
Validation loss: 2.594047689422974

Epoch: 6| Step: 3
Training loss: 2.821428664554091
Validation loss: 2.5884627354557534

Epoch: 6| Step: 4
Training loss: 2.956315189473497
Validation loss: 2.588649011099848

Epoch: 6| Step: 5
Training loss: 3.002954935107278
Validation loss: 2.5683931625865646

Epoch: 6| Step: 6
Training loss: 2.32234313681486
Validation loss: 2.573103770174892

Epoch: 6| Step: 7
Training loss: 2.7470800329769363
Validation loss: 2.595734974472778

Epoch: 6| Step: 8
Training loss: 2.881396930779423
Validation loss: 2.5944239470622454

Epoch: 6| Step: 9
Training loss: 3.1187226380273603
Validation loss: 2.583461036529316

Epoch: 6| Step: 10
Training loss: 3.8200008210585747
Validation loss: 2.5836836696082233

Epoch: 6| Step: 11
Training loss: 2.6703886839309745
Validation loss: 2.5949691554139975

Epoch: 6| Step: 12
Training loss: 2.793313257271205
Validation loss: 2.597254000679498

Epoch: 6| Step: 13
Training loss: 2.9359407547734255
Validation loss: 2.5626129887819635

Epoch: 47| Step: 0
Training loss: 2.565542601215884
Validation loss: 2.58496971449186

Epoch: 6| Step: 1
Training loss: 2.513817273894334
Validation loss: 2.57383359330402

Epoch: 6| Step: 2
Training loss: 3.2927225729081204
Validation loss: 2.579304749060754

Epoch: 6| Step: 3
Training loss: 3.020059753988913
Validation loss: 2.5816405777716023

Epoch: 6| Step: 4
Training loss: 2.5539686959124865
Validation loss: 2.5729897196313147

Epoch: 6| Step: 5
Training loss: 2.658785787681402
Validation loss: 2.5551300774337204

Epoch: 6| Step: 6
Training loss: 3.112500024512111
Validation loss: 2.5766855685668864

Epoch: 6| Step: 7
Training loss: 2.666828230096174
Validation loss: 2.56732142537256

Epoch: 6| Step: 8
Training loss: 2.8226938945710587
Validation loss: 2.568613298043825

Epoch: 6| Step: 9
Training loss: 2.7565346153517325
Validation loss: 2.576152744440023

Epoch: 6| Step: 10
Training loss: 3.2245098539968753
Validation loss: 2.554765129433963

Epoch: 6| Step: 11
Training loss: 3.470272795318227
Validation loss: 2.5708286786817998

Epoch: 6| Step: 12
Training loss: 2.782527844340252
Validation loss: 2.571094494595176

Epoch: 6| Step: 13
Training loss: 3.444331645827706
Validation loss: 2.598099271498936

Epoch: 48| Step: 0
Training loss: 3.421856745144301
Validation loss: 2.5713825777986097

Epoch: 6| Step: 1
Training loss: 2.967843007524079
Validation loss: 2.5830413350328416

Epoch: 6| Step: 2
Training loss: 2.748812332313949
Validation loss: 2.5800521891635797

Epoch: 6| Step: 3
Training loss: 2.706528389864104
Validation loss: 2.5661046546159225

Epoch: 6| Step: 4
Training loss: 3.1289803142568404
Validation loss: 2.5750995911421533

Epoch: 6| Step: 5
Training loss: 2.6059533259090437
Validation loss: 2.581169460313095

Epoch: 6| Step: 6
Training loss: 2.6722973941408417
Validation loss: 2.570951493386973

Epoch: 6| Step: 7
Training loss: 2.769085115082733
Validation loss: 2.5804893632487294

Epoch: 6| Step: 8
Training loss: 3.91543853388847
Validation loss: 2.5783985260080944

Epoch: 6| Step: 9
Training loss: 2.937541230906618
Validation loss: 2.5825429720227335

Epoch: 6| Step: 10
Training loss: 2.3829209600059635
Validation loss: 2.5907610995904933

Epoch: 6| Step: 11
Training loss: 2.8137019661964264
Validation loss: 2.5643833881530593

Epoch: 6| Step: 12
Training loss: 2.6920802984519216
Validation loss: 2.5748030405117177

Epoch: 6| Step: 13
Training loss: 2.6414462285371574
Validation loss: 2.5597433203489013

Epoch: 49| Step: 0
Training loss: 3.09549394255797
Validation loss: 2.5605348484583526

Epoch: 6| Step: 1
Training loss: 2.7168449655386047
Validation loss: 2.5589767513821253

Epoch: 6| Step: 2
Training loss: 2.2292806530862395
Validation loss: 2.5727986981318005

Epoch: 6| Step: 3
Training loss: 2.596544621610686
Validation loss: 2.5715865118265917

Epoch: 6| Step: 4
Training loss: 3.379480002316861
Validation loss: 2.559661703974329

Epoch: 6| Step: 5
Training loss: 2.739831243594701
Validation loss: 2.581261123926841

Epoch: 6| Step: 6
Training loss: 3.601402163298218
Validation loss: 2.595221076479134

Epoch: 6| Step: 7
Training loss: 2.929855952188389
Validation loss: 2.5803549133530894

Epoch: 6| Step: 8
Training loss: 3.5267203657776887
Validation loss: 2.574449514929801

Epoch: 6| Step: 9
Training loss: 2.744425672611932
Validation loss: 2.566615162116784

Epoch: 6| Step: 10
Training loss: 2.9467785978275085
Validation loss: 2.5625125135370825

Epoch: 6| Step: 11
Training loss: 2.590318547104984
Validation loss: 2.5812616801040473

Epoch: 6| Step: 12
Training loss: 2.7287114372796317
Validation loss: 2.5646694842998223

Epoch: 6| Step: 13
Training loss: 2.095637481315526
Validation loss: 2.56793424526107

Epoch: 50| Step: 0
Training loss: 4.122467188198523
Validation loss: 2.5620140397236777

Epoch: 6| Step: 1
Training loss: 2.193199579900979
Validation loss: 2.5885192149783482

Epoch: 6| Step: 2
Training loss: 3.426644680778932
Validation loss: 2.5816518337161773

Epoch: 6| Step: 3
Training loss: 2.2529080988887618
Validation loss: 2.57172098849585

Epoch: 6| Step: 4
Training loss: 2.818377816608497
Validation loss: 2.570809372739916

Epoch: 6| Step: 5
Training loss: 2.643571372344142
Validation loss: 2.553799895515888

Epoch: 6| Step: 6
Training loss: 2.8602221958838547
Validation loss: 2.563813823900409

Epoch: 6| Step: 7
Training loss: 2.810596669745435
Validation loss: 2.573658395897189

Epoch: 6| Step: 8
Training loss: 2.860418410739427
Validation loss: 2.570877145330835

Epoch: 6| Step: 9
Training loss: 2.716272562690766
Validation loss: 2.555495782386172

Epoch: 6| Step: 10
Training loss: 3.382567504750546
Validation loss: 2.550951201856064

Epoch: 6| Step: 11
Training loss: 2.3991680213188578
Validation loss: 2.5799581275881405

Epoch: 6| Step: 12
Training loss: 2.571701648381113
Validation loss: 2.5637542207340696

Epoch: 6| Step: 13
Training loss: 2.7689133400022
Validation loss: 2.575000114851098

Epoch: 51| Step: 0
Training loss: 3.645317230025328
Validation loss: 2.5523581799862662

Epoch: 6| Step: 1
Training loss: 2.4212740244778836
Validation loss: 2.600709524476538

Epoch: 6| Step: 2
Training loss: 2.774559889938443
Validation loss: 2.565053224575686

Epoch: 6| Step: 3
Training loss: 2.7373836858416403
Validation loss: 2.563157341195319

Epoch: 6| Step: 4
Training loss: 2.9714728467388443
Validation loss: 2.5453487463181452

Epoch: 6| Step: 5
Training loss: 3.2958755786244343
Validation loss: 2.565426346329479

Epoch: 6| Step: 6
Training loss: 2.7418085689596934
Validation loss: 2.5619117447780018

Epoch: 6| Step: 7
Training loss: 3.342936193954438
Validation loss: 2.5471867659222727

Epoch: 6| Step: 8
Training loss: 2.9884515053112652
Validation loss: 2.5456798634962934

Epoch: 6| Step: 9
Training loss: 2.4727905622647137
Validation loss: 2.5588678078726463

Epoch: 6| Step: 10
Training loss: 2.6828406108612066
Validation loss: 2.579707829508769

Epoch: 6| Step: 11
Training loss: 2.896728999173606
Validation loss: 2.5636654516302255

Epoch: 6| Step: 12
Training loss: 2.746430160731763
Validation loss: 2.547990617145186

Epoch: 6| Step: 13
Training loss: 2.618453718736833
Validation loss: 2.551450295673879

Epoch: 52| Step: 0
Training loss: 2.936418374772931
Validation loss: 2.595985000196652

Epoch: 6| Step: 1
Training loss: 1.6190309936073208
Validation loss: 2.5743327450980558

Epoch: 6| Step: 2
Training loss: 2.6641314097690576
Validation loss: 2.565763410887815

Epoch: 6| Step: 3
Training loss: 3.280579416689086
Validation loss: 2.573609043273962

Epoch: 6| Step: 4
Training loss: 2.9193185648672726
Validation loss: 2.580300072315976

Epoch: 6| Step: 5
Training loss: 3.4664887627166796
Validation loss: 2.587134816926716

Epoch: 6| Step: 6
Training loss: 2.698963202871221
Validation loss: 2.5730048055715242

Epoch: 6| Step: 7
Training loss: 3.1070276342365655
Validation loss: 2.566522054456453

Epoch: 6| Step: 8
Training loss: 3.7532629440329357
Validation loss: 2.573593169946343

Epoch: 6| Step: 9
Training loss: 2.640894227156923
Validation loss: 2.597661007865936

Epoch: 6| Step: 10
Training loss: 3.1533839744173724
Validation loss: 2.579130500814099

Epoch: 6| Step: 11
Training loss: 2.3422687172884404
Validation loss: 2.540209312212071

Epoch: 6| Step: 12
Training loss: 3.0698811856616843
Validation loss: 2.576307283538337

Epoch: 6| Step: 13
Training loss: 1.3560405481571929
Validation loss: 2.5874739366744226

Epoch: 53| Step: 0
Training loss: 2.615955757548598
Validation loss: 2.5749510537710605

Epoch: 6| Step: 1
Training loss: 3.3266979614600163
Validation loss: 2.5812082795933904

Epoch: 6| Step: 2
Training loss: 3.219289789955074
Validation loss: 2.6004998556037044

Epoch: 6| Step: 3
Training loss: 2.46967433574054
Validation loss: 2.5745782553988006

Epoch: 6| Step: 4
Training loss: 3.511260718834807
Validation loss: 2.560059006827138

Epoch: 6| Step: 5
Training loss: 2.6145541023555596
Validation loss: 2.568278698227461

Epoch: 6| Step: 6
Training loss: 2.7893226993691176
Validation loss: 2.5709061104061153

Epoch: 6| Step: 7
Training loss: 2.5954709146509094
Validation loss: 2.5772850490549244

Epoch: 6| Step: 8
Training loss: 2.9966828762997926
Validation loss: 2.572714887158751

Epoch: 6| Step: 9
Training loss: 2.580027485190966
Validation loss: 2.5781502790507522

Epoch: 6| Step: 10
Training loss: 3.0170455512027368
Validation loss: 2.572229047797648

Epoch: 6| Step: 11
Training loss: 3.154259384452125
Validation loss: 2.5617255364386096

Epoch: 6| Step: 12
Training loss: 2.948175551478647
Validation loss: 2.568548592735356

Epoch: 6| Step: 13
Training loss: 2.4537804572245414
Validation loss: 2.5720821536968277

Epoch: 54| Step: 0
Training loss: 2.2068457601463516
Validation loss: 2.584575058588329

Epoch: 6| Step: 1
Training loss: 2.5581173518793716
Validation loss: 2.57031218382283

Epoch: 6| Step: 2
Training loss: 3.943663601903751
Validation loss: 2.554433905817137

Epoch: 6| Step: 3
Training loss: 2.897154984425959
Validation loss: 2.589430580732003

Epoch: 6| Step: 4
Training loss: 2.9439548429260087
Validation loss: 2.5613326077997525

Epoch: 6| Step: 5
Training loss: 2.018114076019521
Validation loss: 2.5664910730909374

Epoch: 6| Step: 6
Training loss: 2.748878163484938
Validation loss: 2.5819549482253654

Epoch: 6| Step: 7
Training loss: 3.0574953876750652
Validation loss: 2.565958594839131

Epoch: 6| Step: 8
Training loss: 2.9845132046799008
Validation loss: 2.5817769516304554

Epoch: 6| Step: 9
Training loss: 3.295074839226866
Validation loss: 2.572535298539588

Epoch: 6| Step: 10
Training loss: 2.8507734487295626
Validation loss: 2.564338425785528

Epoch: 6| Step: 11
Training loss: 2.2559451924964513
Validation loss: 2.578493960850169

Epoch: 6| Step: 12
Training loss: 3.1649617742125358
Validation loss: 2.5819403603973923

Epoch: 6| Step: 13
Training loss: 2.8682129400840393
Validation loss: 2.606688548195475

Epoch: 55| Step: 0
Training loss: 2.9849038179834713
Validation loss: 2.5725999693457067

Epoch: 6| Step: 1
Training loss: 2.7244207063933437
Validation loss: 2.5564151885346353

Epoch: 6| Step: 2
Training loss: 2.772913579750397
Validation loss: 2.574203342528134

Epoch: 6| Step: 3
Training loss: 2.618408920181283
Validation loss: 2.5611617642979567

Epoch: 6| Step: 4
Training loss: 2.5888385461743186
Validation loss: 2.581564342901606

Epoch: 6| Step: 5
Training loss: 2.7204860537675795
Validation loss: 2.5636220256827906

Epoch: 6| Step: 6
Training loss: 2.977138033115881
Validation loss: 2.539470231580585

Epoch: 6| Step: 7
Training loss: 3.5291927049945597
Validation loss: 2.552062794994278

Epoch: 6| Step: 8
Training loss: 2.8382874727902814
Validation loss: 2.552446712082969

Epoch: 6| Step: 9
Training loss: 2.7547897761286326
Validation loss: 2.5578694097058605

Epoch: 6| Step: 10
Training loss: 2.742117943384217
Validation loss: 2.5825204618964612

Epoch: 6| Step: 11
Training loss: 3.3639143681280936
Validation loss: 2.571466694394781

Epoch: 6| Step: 12
Training loss: 3.0601762012788636
Validation loss: 2.5881776994323467

Epoch: 6| Step: 13
Training loss: 2.314782845876838
Validation loss: 2.594310126256466

Epoch: 56| Step: 0
Training loss: 2.800772396908951
Validation loss: 2.55740812526967

Epoch: 6| Step: 1
Training loss: 2.143772011691157
Validation loss: 2.5735768671848884

Epoch: 6| Step: 2
Training loss: 2.2885612485797657
Validation loss: 2.575685878516065

Epoch: 6| Step: 3
Training loss: 3.80612938600557
Validation loss: 2.5675948701864204

Epoch: 6| Step: 4
Training loss: 2.6646832500829634
Validation loss: 2.5733132523572424

Epoch: 6| Step: 5
Training loss: 2.9168411384351525
Validation loss: 2.557249321781313

Epoch: 6| Step: 6
Training loss: 2.796967147928809
Validation loss: 2.5620797805924664

Epoch: 6| Step: 7
Training loss: 2.853993505715117
Validation loss: 2.5620305881700354

Epoch: 6| Step: 8
Training loss: 2.7014088557752216
Validation loss: 2.569645879207592

Epoch: 6| Step: 9
Training loss: 3.0215350333604785
Validation loss: 2.5541261802221014

Epoch: 6| Step: 10
Training loss: 3.1586140758644485
Validation loss: 2.573013169008885

Epoch: 6| Step: 11
Training loss: 3.7207910402179025
Validation loss: 2.565277537164015

Epoch: 6| Step: 12
Training loss: 2.8605387669726685
Validation loss: 2.563008562830706

Epoch: 6| Step: 13
Training loss: 1.9895235688452149
Validation loss: 2.5526330961381007

Epoch: 57| Step: 0
Training loss: 2.6326766615782775
Validation loss: 2.570339751932109

Epoch: 6| Step: 1
Training loss: 3.21274873831839
Validation loss: 2.561119746325015

Epoch: 6| Step: 2
Training loss: 2.689346832191709
Validation loss: 2.5679623330654793

Epoch: 6| Step: 3
Training loss: 3.200839981460189
Validation loss: 2.565762049015127

Epoch: 6| Step: 4
Training loss: 2.4030776476814335
Validation loss: 2.5849699941650086

Epoch: 6| Step: 5
Training loss: 3.0367435345375586
Validation loss: 2.5701718561670837

Epoch: 6| Step: 6
Training loss: 3.441837833634041
Validation loss: 2.56601165131819

Epoch: 6| Step: 7
Training loss: 2.79920061485129
Validation loss: 2.5784245112891577

Epoch: 6| Step: 8
Training loss: 2.9305308031078376
Validation loss: 2.570800083199532

Epoch: 6| Step: 9
Training loss: 2.546313077569501
Validation loss: 2.569105375341658

Epoch: 6| Step: 10
Training loss: 2.165167681255117
Validation loss: 2.5705027518109795

Epoch: 6| Step: 11
Training loss: 2.9658224026066886
Validation loss: 2.5721264943092543

Epoch: 6| Step: 12
Training loss: 3.0637912752755514
Validation loss: 2.5678840937647265

Epoch: 6| Step: 13
Training loss: 3.641750701935654
Validation loss: 2.5775916976454227

Epoch: 58| Step: 0
Training loss: 3.0685632590600957
Validation loss: 2.5688964940900827

Epoch: 6| Step: 1
Training loss: 2.174355387257947
Validation loss: 2.5699570314612235

Epoch: 6| Step: 2
Training loss: 3.6403981412352393
Validation loss: 2.5501947912059575

Epoch: 6| Step: 3
Training loss: 2.726797536431244
Validation loss: 2.5719944091192857

Epoch: 6| Step: 4
Training loss: 2.347293667079021
Validation loss: 2.5676875685298364

Epoch: 6| Step: 5
Training loss: 2.9372782522062475
Validation loss: 2.5777812232613417

Epoch: 6| Step: 6
Training loss: 3.1720080418238252
Validation loss: 2.5631917664539894

Epoch: 6| Step: 7
Training loss: 2.24617771157609
Validation loss: 2.5544061158652513

Epoch: 6| Step: 8
Training loss: 3.134386994024207
Validation loss: 2.579981598091685

Epoch: 6| Step: 9
Training loss: 2.869840221144282
Validation loss: 2.5843207436833158

Epoch: 6| Step: 10
Training loss: 2.9182965402191865
Validation loss: 2.5739769702323536

Epoch: 6| Step: 11
Training loss: 2.6548311819942367
Validation loss: 2.569578486187706

Epoch: 6| Step: 12
Training loss: 3.2454526339283194
Validation loss: 2.5782595124863237

Epoch: 6| Step: 13
Training loss: 2.711276777952151
Validation loss: 2.550986524451474

Epoch: 59| Step: 0
Training loss: 2.574435651842181
Validation loss: 2.5516684467198574

Epoch: 6| Step: 1
Training loss: 2.868949660456914
Validation loss: 2.5685611536573494

Epoch: 6| Step: 2
Training loss: 2.885065784993513
Validation loss: 2.5629152501259793

Epoch: 6| Step: 3
Training loss: 3.3126091129398043
Validation loss: 2.5752102551080855

Epoch: 6| Step: 4
Training loss: 2.515430893132427
Validation loss: 2.5416776380162616

Epoch: 6| Step: 5
Training loss: 2.58633899165021
Validation loss: 2.558425354960199

Epoch: 6| Step: 6
Training loss: 2.8771609602245127
Validation loss: 2.5739345419477284

Epoch: 6| Step: 7
Training loss: 2.5471580675708774
Validation loss: 2.573347878479034

Epoch: 6| Step: 8
Training loss: 2.8209838068246156
Validation loss: 2.5537860342709156

Epoch: 6| Step: 9
Training loss: 2.763347485379132
Validation loss: 2.5601469131327454

Epoch: 6| Step: 10
Training loss: 3.329309959972233
Validation loss: 2.562470059503799

Epoch: 6| Step: 11
Training loss: 2.8115018980917714
Validation loss: 2.548567954051354

Epoch: 6| Step: 12
Training loss: 3.2479176819616025
Validation loss: 2.555357062912298

Epoch: 6| Step: 13
Training loss: 3.3270731951886146
Validation loss: 2.550104772493198

Epoch: 60| Step: 0
Training loss: 3.5664158765614875
Validation loss: 2.5349951145744525

Epoch: 6| Step: 1
Training loss: 2.9266761867684075
Validation loss: 2.5439298607443943

Epoch: 6| Step: 2
Training loss: 2.685251759353003
Validation loss: 2.559772191076389

Epoch: 6| Step: 3
Training loss: 3.0711617496466506
Validation loss: 2.55868267852586

Epoch: 6| Step: 4
Training loss: 2.7304360929399896
Validation loss: 2.5379128977780145

Epoch: 6| Step: 5
Training loss: 2.988202741003008
Validation loss: 2.568775358574658

Epoch: 6| Step: 6
Training loss: 1.976367262293549
Validation loss: 2.576850567668984

Epoch: 6| Step: 7
Training loss: 3.289063949765862
Validation loss: 2.5707705450202734

Epoch: 6| Step: 8
Training loss: 2.4033914405933814
Validation loss: 2.566895952945122

Epoch: 6| Step: 9
Training loss: 3.3959822982847943
Validation loss: 2.572965131182548

Epoch: 6| Step: 10
Training loss: 3.182220574733135
Validation loss: 2.5637272162883074

Epoch: 6| Step: 11
Training loss: 2.9754352988412185
Validation loss: 2.5538609250562394

Epoch: 6| Step: 12
Training loss: 2.4794916105626545
Validation loss: 2.5828339917465866

Epoch: 6| Step: 13
Training loss: 2.2709364094803095
Validation loss: 2.5736818511354853

Epoch: 61| Step: 0
Training loss: 2.320682586029399
Validation loss: 2.571608030041649

Epoch: 6| Step: 1
Training loss: 2.6605494092437185
Validation loss: 2.5642624813317627

Epoch: 6| Step: 2
Training loss: 3.1815279196581714
Validation loss: 2.572418987447509

Epoch: 6| Step: 3
Training loss: 2.698735901944617
Validation loss: 2.5365712271954624

Epoch: 6| Step: 4
Training loss: 3.2068844946343593
Validation loss: 2.54526010733581

Epoch: 6| Step: 5
Training loss: 2.513738837309816
Validation loss: 2.550423162803041

Epoch: 6| Step: 6
Training loss: 3.2795884057895375
Validation loss: 2.588839559216967

Epoch: 6| Step: 7
Training loss: 3.3926565526880363
Validation loss: 2.5845852057079233

Epoch: 6| Step: 8
Training loss: 1.7260622706667446
Validation loss: 2.550063700305594

Epoch: 6| Step: 9
Training loss: 2.7172781807946182
Validation loss: 2.5348204004057346

Epoch: 6| Step: 10
Training loss: 2.567308984204986
Validation loss: 2.5579096108909063

Epoch: 6| Step: 11
Training loss: 2.6642554428619145
Validation loss: 2.5477715675753516

Epoch: 6| Step: 12
Training loss: 3.6363669449617766
Validation loss: 2.573097804190115

Epoch: 6| Step: 13
Training loss: 2.971285249455254
Validation loss: 2.5458005421259733

Epoch: 62| Step: 0
Training loss: 2.993395529131298
Validation loss: 2.5688373806003195

Epoch: 6| Step: 1
Training loss: 2.773315083125783
Validation loss: 2.572454467711387

Epoch: 6| Step: 2
Training loss: 2.15965411401488
Validation loss: 2.5707679921190434

Epoch: 6| Step: 3
Training loss: 2.68100067971323
Validation loss: 2.5522701259526164

Epoch: 6| Step: 4
Training loss: 2.2919135451996078
Validation loss: 2.5511182341863794

Epoch: 6| Step: 5
Training loss: 2.9845216725042323
Validation loss: 2.5691679212537797

Epoch: 6| Step: 6
Training loss: 3.636744711155323
Validation loss: 2.550070622958331

Epoch: 6| Step: 7
Training loss: 3.032541845273526
Validation loss: 2.5478273009620738

Epoch: 6| Step: 8
Training loss: 2.494831560064134
Validation loss: 2.561286685044508

Epoch: 6| Step: 9
Training loss: 2.472139373800776
Validation loss: 2.5556110414808404

Epoch: 6| Step: 10
Training loss: 3.1499589221031914
Validation loss: 2.545702105224541

Epoch: 6| Step: 11
Training loss: 3.2444045977417266
Validation loss: 2.549109189561303

Epoch: 6| Step: 12
Training loss: 3.373353061794244
Validation loss: 2.5798783978257664

Epoch: 6| Step: 13
Training loss: 2.388137021387668
Validation loss: 2.590895787207356

Epoch: 63| Step: 0
Training loss: 2.172399224335292
Validation loss: 2.577645930939903

Epoch: 6| Step: 1
Training loss: 3.106088099107774
Validation loss: 2.5583157165755592

Epoch: 6| Step: 2
Training loss: 3.06909093264309
Validation loss: 2.5626897033855456

Epoch: 6| Step: 3
Training loss: 3.2485671185885336
Validation loss: 2.5666426256044987

Epoch: 6| Step: 4
Training loss: 2.720485440299909
Validation loss: 2.561231832091362

Epoch: 6| Step: 5
Training loss: 2.6052458294581684
Validation loss: 2.574587687141483

Epoch: 6| Step: 6
Training loss: 3.2291115212602737
Validation loss: 2.55630227982272

Epoch: 6| Step: 7
Training loss: 2.674158737663797
Validation loss: 2.5626018853070414

Epoch: 6| Step: 8
Training loss: 3.5303459698202353
Validation loss: 2.5557175684212448

Epoch: 6| Step: 9
Training loss: 2.7444066471923962
Validation loss: 2.5655837433623825

Epoch: 6| Step: 10
Training loss: 3.0721962466836663
Validation loss: 2.5539177376539683

Epoch: 6| Step: 11
Training loss: 2.5202301711975057
Validation loss: 2.5400181642700317

Epoch: 6| Step: 12
Training loss: 2.5004596287687866
Validation loss: 2.553365465111033

Epoch: 6| Step: 13
Training loss: 2.7954173631866706
Validation loss: 2.5762793991601356

Epoch: 64| Step: 0
Training loss: 3.1713337553915606
Validation loss: 2.5626182628906884

Epoch: 6| Step: 1
Training loss: 3.16130522221563
Validation loss: 2.575142464149978

Epoch: 6| Step: 2
Training loss: 1.9362906096246644
Validation loss: 2.5505038746621196

Epoch: 6| Step: 3
Training loss: 2.187887211997706
Validation loss: 2.56942224830176

Epoch: 6| Step: 4
Training loss: 2.8724468338497506
Validation loss: 2.5632328883242312

Epoch: 6| Step: 5
Training loss: 2.677620048503056
Validation loss: 2.583789987688497

Epoch: 6| Step: 6
Training loss: 3.0468394742019433
Validation loss: 2.5823456572782866

Epoch: 6| Step: 7
Training loss: 2.052458391592568
Validation loss: 2.5510806965546253

Epoch: 6| Step: 8
Training loss: 2.76576792891835
Validation loss: 2.565823328573878

Epoch: 6| Step: 9
Training loss: 3.150847693323725
Validation loss: 2.553518734338339

Epoch: 6| Step: 10
Training loss: 2.9794374534058146
Validation loss: 2.571719971700491

Epoch: 6| Step: 11
Training loss: 3.4150428324703954
Validation loss: 2.559097288835269

Epoch: 6| Step: 12
Training loss: 3.388277427736272
Validation loss: 2.5708992628033895

Epoch: 6| Step: 13
Training loss: 2.69012784008874
Validation loss: 2.5345361491177605

Epoch: 65| Step: 0
Training loss: 3.3513382701069725
Validation loss: 2.5578269638009488

Epoch: 6| Step: 1
Training loss: 3.050922541942616
Validation loss: 2.57601800252073

Epoch: 6| Step: 2
Training loss: 2.4645562586153074
Validation loss: 2.5664765442040154

Epoch: 6| Step: 3
Training loss: 2.5207182697696577
Validation loss: 2.539918879243157

Epoch: 6| Step: 4
Training loss: 2.628744179886539
Validation loss: 2.5484149172180626

Epoch: 6| Step: 5
Training loss: 2.9443095394235352
Validation loss: 2.5791930252703796

Epoch: 6| Step: 6
Training loss: 2.7710471584639538
Validation loss: 2.569433904986692

Epoch: 6| Step: 7
Training loss: 2.9782806003586457
Validation loss: 2.556834460940327

Epoch: 6| Step: 8
Training loss: 2.2463111307851062
Validation loss: 2.562728376438859

Epoch: 6| Step: 9
Training loss: 3.2870210305920162
Validation loss: 2.5587814225904357

Epoch: 6| Step: 10
Training loss: 2.8884047770996486
Validation loss: 2.5749280312398217

Epoch: 6| Step: 11
Training loss: 3.4571283531560284
Validation loss: 2.571430109815956

Epoch: 6| Step: 12
Training loss: 1.9415322460529412
Validation loss: 2.579300838948966

Epoch: 6| Step: 13
Training loss: 3.782299684211192
Validation loss: 2.5612001941690656

Epoch: 66| Step: 0
Training loss: 3.2642249797812544
Validation loss: 2.5436890529629785

Epoch: 6| Step: 1
Training loss: 3.031605335920354
Validation loss: 2.5674820946541974

Epoch: 6| Step: 2
Training loss: 2.956996418635677
Validation loss: 2.5373545132290625

Epoch: 6| Step: 3
Training loss: 2.353143205103673
Validation loss: 2.555079755886611

Epoch: 6| Step: 4
Training loss: 2.3282400013215265
Validation loss: 2.576834527271791

Epoch: 6| Step: 5
Training loss: 2.8180136147976316
Validation loss: 2.5535639359070648

Epoch: 6| Step: 6
Training loss: 2.8095154079022224
Validation loss: 2.5397862768234423

Epoch: 6| Step: 7
Training loss: 3.3613800452665004
Validation loss: 2.5168113043781615

Epoch: 6| Step: 8
Training loss: 2.737608300422646
Validation loss: 2.547361244819257

Epoch: 6| Step: 9
Training loss: 2.6589952531695453
Validation loss: 2.5351224047247114

Epoch: 6| Step: 10
Training loss: 2.4433844524654833
Validation loss: 2.543447307173672

Epoch: 6| Step: 11
Training loss: 3.177242604416883
Validation loss: 2.535069376281824

Epoch: 6| Step: 12
Training loss: 2.771506139388864
Validation loss: 2.5504290029064625

Epoch: 6| Step: 13
Training loss: 3.157518792779833
Validation loss: 2.5788487954386996

Epoch: 67| Step: 0
Training loss: 2.8352150745654146
Validation loss: 2.5674395520487083

Epoch: 6| Step: 1
Training loss: 2.697889251766077
Validation loss: 2.5426449591689377

Epoch: 6| Step: 2
Training loss: 2.5515130061005555
Validation loss: 2.5539816457360467

Epoch: 6| Step: 3
Training loss: 3.6224365378350094
Validation loss: 2.549393567725129

Epoch: 6| Step: 4
Training loss: 3.2876945060947
Validation loss: 2.5477320255029294

Epoch: 6| Step: 5
Training loss: 2.9510923787688084
Validation loss: 2.5521097506239294

Epoch: 6| Step: 6
Training loss: 2.444537250124967
Validation loss: 2.5486415109669873

Epoch: 6| Step: 7
Training loss: 2.6226938198967877
Validation loss: 2.553451096896372

Epoch: 6| Step: 8
Training loss: 3.1690142278716005
Validation loss: 2.552849729145277

Epoch: 6| Step: 9
Training loss: 2.808624649408434
Validation loss: 2.5711008580852477

Epoch: 6| Step: 10
Training loss: 2.6465267163932986
Validation loss: 2.5649827134582672

Epoch: 6| Step: 11
Training loss: 2.7704936992943314
Validation loss: 2.5665081380600965

Epoch: 6| Step: 12
Training loss: 2.673426306036161
Validation loss: 2.5496223931777457

Epoch: 6| Step: 13
Training loss: 2.8458029913413445
Validation loss: 2.5544238627300118

Epoch: 68| Step: 0
Training loss: 2.9346801534143783
Validation loss: 2.544725765580348

Epoch: 6| Step: 1
Training loss: 2.7266223102994043
Validation loss: 2.5589465487583163

Epoch: 6| Step: 2
Training loss: 2.5607249927619926
Validation loss: 2.5393208235849696

Epoch: 6| Step: 3
Training loss: 3.041492108775181
Validation loss: 2.5504580755665547

Epoch: 6| Step: 4
Training loss: 2.9671424127078967
Validation loss: 2.5398900054065603

Epoch: 6| Step: 5
Training loss: 3.049867695924937
Validation loss: 2.5734697072786807

Epoch: 6| Step: 6
Training loss: 3.2526381129175
Validation loss: 2.5597126365188965

Epoch: 6| Step: 7
Training loss: 3.249011696420775
Validation loss: 2.548194781357796

Epoch: 6| Step: 8
Training loss: 2.8551432662799754
Validation loss: 2.550635080638106

Epoch: 6| Step: 9
Training loss: 3.206811783560979
Validation loss: 2.569975161727071

Epoch: 6| Step: 10
Training loss: 2.7601493466094147
Validation loss: 2.5510582585267265

Epoch: 6| Step: 11
Training loss: 2.892393983366908
Validation loss: 2.558737003011209

Epoch: 6| Step: 12
Training loss: 2.411762808794893
Validation loss: 2.5364861100327545

Epoch: 6| Step: 13
Training loss: 1.9339571524630184
Validation loss: 2.556434448745883

Epoch: 69| Step: 0
Training loss: 2.4554106154130726
Validation loss: 2.5512202665448864

Epoch: 6| Step: 1
Training loss: 2.599298815444314
Validation loss: 2.547615013215612

Epoch: 6| Step: 2
Training loss: 3.1258311882882897
Validation loss: 2.5622353866096854

Epoch: 6| Step: 3
Training loss: 3.4701843045674123
Validation loss: 2.551081572847662

Epoch: 6| Step: 4
Training loss: 2.395160834978528
Validation loss: 2.5546692963618587

Epoch: 6| Step: 5
Training loss: 2.456969631859764
Validation loss: 2.5767512753796313

Epoch: 6| Step: 6
Training loss: 3.011734266030881
Validation loss: 2.5653911501039004

Epoch: 6| Step: 7
Training loss: 3.3683888710674363
Validation loss: 2.5563892091819604

Epoch: 6| Step: 8
Training loss: 2.407678452609162
Validation loss: 2.560751547825681

Epoch: 6| Step: 9
Training loss: 3.199051662828044
Validation loss: 2.5573978196948985

Epoch: 6| Step: 10
Training loss: 2.5807642518913525
Validation loss: 2.5806734527682957

Epoch: 6| Step: 11
Training loss: 2.677023405797108
Validation loss: 2.5758340535348805

Epoch: 6| Step: 12
Training loss: 2.8251360700127197
Validation loss: 2.552138563056174

Epoch: 6| Step: 13
Training loss: 3.3479835590610603
Validation loss: 2.558791796732953

Epoch: 70| Step: 0
Training loss: 2.882967978319161
Validation loss: 2.5605609659660273

Epoch: 6| Step: 1
Training loss: 2.6243198058467216
Validation loss: 2.5353334133245715

Epoch: 6| Step: 2
Training loss: 2.475095681546978
Validation loss: 2.550729236569657

Epoch: 6| Step: 3
Training loss: 2.1776375924402087
Validation loss: 2.5499306079994564

Epoch: 6| Step: 4
Training loss: 2.6766436224389247
Validation loss: 2.5794736475097837

Epoch: 6| Step: 5
Training loss: 2.993669187852731
Validation loss: 2.544312491076789

Epoch: 6| Step: 6
Training loss: 3.399785618474629
Validation loss: 2.550594961798095

Epoch: 6| Step: 7
Training loss: 1.8600815143976506
Validation loss: 2.56245305668381

Epoch: 6| Step: 8
Training loss: 2.940486931473262
Validation loss: 2.559428298589351

Epoch: 6| Step: 9
Training loss: 2.7729083348891126
Validation loss: 2.5524644514791905

Epoch: 6| Step: 10
Training loss: 3.585448121563311
Validation loss: 2.545154613808595

Epoch: 6| Step: 11
Training loss: 3.069078192477032
Validation loss: 2.556813198402531

Epoch: 6| Step: 12
Training loss: 3.255277603429641
Validation loss: 2.541321665142433

Epoch: 6| Step: 13
Training loss: 2.8741044017860107
Validation loss: 2.5402385331206285

Epoch: 71| Step: 0
Training loss: 2.627640440696462
Validation loss: 2.5574957462892454

Epoch: 6| Step: 1
Training loss: 3.1614460994645053
Validation loss: 2.5595332163335787

Epoch: 6| Step: 2
Training loss: 3.0514392021181798
Validation loss: 2.541445306074772

Epoch: 6| Step: 3
Training loss: 2.765831718693379
Validation loss: 2.5685638015737093

Epoch: 6| Step: 4
Training loss: 3.2193503699511172
Validation loss: 2.563817627640623

Epoch: 6| Step: 5
Training loss: 2.74671141188325
Validation loss: 2.5417981233967875

Epoch: 6| Step: 6
Training loss: 2.963846916116838
Validation loss: 2.561578426323108

Epoch: 6| Step: 7
Training loss: 2.1148447961878647
Validation loss: 2.5509493738069877

Epoch: 6| Step: 8
Training loss: 2.5058793552520866
Validation loss: 2.5576938083809657

Epoch: 6| Step: 9
Training loss: 3.3195676439336745
Validation loss: 2.56156817105319

Epoch: 6| Step: 10
Training loss: 2.779443732943628
Validation loss: 2.566876705313559

Epoch: 6| Step: 11
Training loss: 3.42832081877916
Validation loss: 2.5537488390230383

Epoch: 6| Step: 12
Training loss: 2.0571193445845015
Validation loss: 2.5533987081348197

Epoch: 6| Step: 13
Training loss: 3.1895978419403512
Validation loss: 2.5443019918984717

Epoch: 72| Step: 0
Training loss: 2.884185877393134
Validation loss: 2.555207981870615

Epoch: 6| Step: 1
Training loss: 2.938116942205783
Validation loss: 2.5543754903658575

Epoch: 6| Step: 2
Training loss: 3.1567104494736933
Validation loss: 2.537519566276487

Epoch: 6| Step: 3
Training loss: 2.922334522689009
Validation loss: 2.5708046968110048

Epoch: 6| Step: 4
Training loss: 2.827318108034714
Validation loss: 2.54187748029845

Epoch: 6| Step: 5
Training loss: 2.7430367309525288
Validation loss: 2.5578095572683566

Epoch: 6| Step: 6
Training loss: 2.9871611845946684
Validation loss: 2.5692612323740542

Epoch: 6| Step: 7
Training loss: 2.9438422704923575
Validation loss: 2.5531028982871087

Epoch: 6| Step: 8
Training loss: 2.740027900470217
Validation loss: 2.5397942500004684

Epoch: 6| Step: 9
Training loss: 2.7475093486651136
Validation loss: 2.5150269725090966

Epoch: 6| Step: 10
Training loss: 2.778455723578431
Validation loss: 2.5483958348147397

Epoch: 6| Step: 11
Training loss: 3.079992666855046
Validation loss: 2.5489042255735193

Epoch: 6| Step: 12
Training loss: 2.614889382818134
Validation loss: 2.5645512045396885

Epoch: 6| Step: 13
Training loss: 2.46735332914982
Validation loss: 2.541935623223702

Epoch: 73| Step: 0
Training loss: 2.8387116454207124
Validation loss: 2.5360205878752278

Epoch: 6| Step: 1
Training loss: 3.2634484735684475
Validation loss: 2.537776641742484

Epoch: 6| Step: 2
Training loss: 3.06068366547771
Validation loss: 2.538670865406796

Epoch: 6| Step: 3
Training loss: 2.337868495189488
Validation loss: 2.546663840366997

Epoch: 6| Step: 4
Training loss: 3.3653977454631505
Validation loss: 2.5494204670733036

Epoch: 6| Step: 5
Training loss: 2.8632690929035056
Validation loss: 2.5470782370689196

Epoch: 6| Step: 6
Training loss: 2.319082428579647
Validation loss: 2.5574679394872435

Epoch: 6| Step: 7
Training loss: 3.2335615379054388
Validation loss: 2.5598466813974765

Epoch: 6| Step: 8
Training loss: 2.801365151717433
Validation loss: 2.5278584912026822

Epoch: 6| Step: 9
Training loss: 2.852435419954711
Validation loss: 2.549935144254766

Epoch: 6| Step: 10
Training loss: 2.8596026220555357
Validation loss: 2.577126643241136

Epoch: 6| Step: 11
Training loss: 3.159484716485594
Validation loss: 2.5449470124209563

Epoch: 6| Step: 12
Training loss: 1.793153308686167
Validation loss: 2.5557058993307455

Epoch: 6| Step: 13
Training loss: 2.805464612999726
Validation loss: 2.5453984504815894

Epoch: 74| Step: 0
Training loss: 3.2087372529713236
Validation loss: 2.5416543614980447

Epoch: 6| Step: 1
Training loss: 3.1695572225565747
Validation loss: 2.56947761483932

Epoch: 6| Step: 2
Training loss: 2.1299490798093195
Validation loss: 2.5348844294149497

Epoch: 6| Step: 3
Training loss: 2.87937296134292
Validation loss: 2.5486092610793163

Epoch: 6| Step: 4
Training loss: 2.9363034022880004
Validation loss: 2.5547766427680907

Epoch: 6| Step: 5
Training loss: 2.6718473377245857
Validation loss: 2.548847358054907

Epoch: 6| Step: 6
Training loss: 3.5750311256600935
Validation loss: 2.5065833154994452

Epoch: 6| Step: 7
Training loss: 2.7735154691670174
Validation loss: 2.53978740027679

Epoch: 6| Step: 8
Training loss: 3.0298145474123372
Validation loss: 2.55786781812242

Epoch: 6| Step: 9
Training loss: 2.260814004832556
Validation loss: 2.5357644272645516

Epoch: 6| Step: 10
Training loss: 3.286668644789074
Validation loss: 2.5446463977658427

Epoch: 6| Step: 11
Training loss: 2.320211389053286
Validation loss: 2.5438084856682894

Epoch: 6| Step: 12
Training loss: 2.794196268575813
Validation loss: 2.552212893470669

Epoch: 6| Step: 13
Training loss: 1.890030948849744
Validation loss: 2.5710667441302593

Epoch: 75| Step: 0
Training loss: 2.602826427175593
Validation loss: 2.529489791138641

Epoch: 6| Step: 1
Training loss: 2.5992867995476163
Validation loss: 2.5751170719468894

Epoch: 6| Step: 2
Training loss: 3.5320318926173795
Validation loss: 2.5349265070520124

Epoch: 6| Step: 3
Training loss: 2.862344169539621
Validation loss: 2.532269095331561

Epoch: 6| Step: 4
Training loss: 3.268933240375107
Validation loss: 2.554388826528832

Epoch: 6| Step: 5
Training loss: 2.878240666255298
Validation loss: 2.552236976711543

Epoch: 6| Step: 6
Training loss: 2.688074006282329
Validation loss: 2.5540347492634012

Epoch: 6| Step: 7
Training loss: 2.7625770799749163
Validation loss: 2.552916344678671

Epoch: 6| Step: 8
Training loss: 2.1773319984559647
Validation loss: 2.5704145842935335

Epoch: 6| Step: 9
Training loss: 2.7665397726013286
Validation loss: 2.5292821314458767

Epoch: 6| Step: 10
Training loss: 3.041333602715725
Validation loss: 2.526784115422391

Epoch: 6| Step: 11
Training loss: 3.599034413013397
Validation loss: 2.536820648191341

Epoch: 6| Step: 12
Training loss: 1.8370564398985685
Validation loss: 2.5322987136023642

Epoch: 6| Step: 13
Training loss: 3.110864483806533
Validation loss: 2.553428068262502

Epoch: 76| Step: 0
Training loss: 3.0900838688699683
Validation loss: 2.577833562035662

Epoch: 6| Step: 1
Training loss: 3.1028845441301325
Validation loss: 2.5754007553095186

Epoch: 6| Step: 2
Training loss: 3.289341133257903
Validation loss: 2.5484896781405735

Epoch: 6| Step: 3
Training loss: 2.810047351804728
Validation loss: 2.5284686823586493

Epoch: 6| Step: 4
Training loss: 2.4970149338794694
Validation loss: 2.5466952904409768

Epoch: 6| Step: 5
Training loss: 2.3423355920962683
Validation loss: 2.5390680189049046

Epoch: 6| Step: 6
Training loss: 3.1875535549077876
Validation loss: 2.5229035550456222

Epoch: 6| Step: 7
Training loss: 2.9404710394904474
Validation loss: 2.5588776541849936

Epoch: 6| Step: 8
Training loss: 2.420916755363837
Validation loss: 2.540072768585815

Epoch: 6| Step: 9
Training loss: 2.8300826742005363
Validation loss: 2.5413956930581945

Epoch: 6| Step: 10
Training loss: 2.23318599195916
Validation loss: 2.5457181393699218

Epoch: 6| Step: 11
Training loss: 3.163379736808866
Validation loss: 2.5600487279460418

Epoch: 6| Step: 12
Training loss: 2.98942099384111
Validation loss: 2.535949328149705

Epoch: 6| Step: 13
Training loss: 2.704787696644089
Validation loss: 2.574392740176126

Epoch: 77| Step: 0
Training loss: 3.3819887774984543
Validation loss: 2.537666170846286

Epoch: 6| Step: 1
Training loss: 2.8526263199167086
Validation loss: 2.5855757011591898

Epoch: 6| Step: 2
Training loss: 2.1948402412686856
Validation loss: 2.5524251016316484

Epoch: 6| Step: 3
Training loss: 3.273767714130241
Validation loss: 2.5815600856625807

Epoch: 6| Step: 4
Training loss: 3.0674134367999275
Validation loss: 2.5577364569572856

Epoch: 6| Step: 5
Training loss: 2.8484729490517355
Validation loss: 2.5405212018686196

Epoch: 6| Step: 6
Training loss: 2.711468383520325
Validation loss: 2.569985143044699

Epoch: 6| Step: 7
Training loss: 3.2152680757805094
Validation loss: 2.558963880935354

Epoch: 6| Step: 8
Training loss: 2.954196311755309
Validation loss: 2.558180490131266

Epoch: 6| Step: 9
Training loss: 2.2461877952458096
Validation loss: 2.5418731222989916

Epoch: 6| Step: 10
Training loss: 2.2319562932113857
Validation loss: 2.544570473109129

Epoch: 6| Step: 11
Training loss: 3.319279193533443
Validation loss: 2.5480876697762715

Epoch: 6| Step: 12
Training loss: 2.8698405534534657
Validation loss: 2.554324048937462

Epoch: 6| Step: 13
Training loss: 1.7064333639024565
Validation loss: 2.5204867185103863

Epoch: 78| Step: 0
Training loss: 2.9680913897322525
Validation loss: 2.5393143726302867

Epoch: 6| Step: 1
Training loss: 2.3664460988308766
Validation loss: 2.5517661822814124

Epoch: 6| Step: 2
Training loss: 2.854245446967237
Validation loss: 2.547122552988858

Epoch: 6| Step: 3
Training loss: 2.9426208663139413
Validation loss: 2.554715220660432

Epoch: 6| Step: 4
Training loss: 2.9503758465843632
Validation loss: 2.552879887912521

Epoch: 6| Step: 5
Training loss: 2.3428982013334516
Validation loss: 2.5371547774706693

Epoch: 6| Step: 6
Training loss: 3.531023136379658
Validation loss: 2.5557868776882984

Epoch: 6| Step: 7
Training loss: 2.5606841189501406
Validation loss: 2.5665367758679682

Epoch: 6| Step: 8
Training loss: 3.1376924250589733
Validation loss: 2.531762947583131

Epoch: 6| Step: 9
Training loss: 2.9427009154819856
Validation loss: 2.5448026960288037

Epoch: 6| Step: 10
Training loss: 3.089403586497509
Validation loss: 2.5490797827062064

Epoch: 6| Step: 11
Training loss: 2.8621797407478042
Validation loss: 2.507109345036878

Epoch: 6| Step: 12
Training loss: 2.592016537060201
Validation loss: 2.5685936969888203

Epoch: 6| Step: 13
Training loss: 2.3836284303595967
Validation loss: 2.5559990047671337

Epoch: 79| Step: 0
Training loss: 2.905121450856414
Validation loss: 2.539561732129131

Epoch: 6| Step: 1
Training loss: 3.3087560260344575
Validation loss: 2.538809938198702

Epoch: 6| Step: 2
Training loss: 2.7459564825834266
Validation loss: 2.5566839178453926

Epoch: 6| Step: 3
Training loss: 2.6519012756268636
Validation loss: 2.538610934986097

Epoch: 6| Step: 4
Training loss: 2.8093584953391892
Validation loss: 2.5355523939132962

Epoch: 6| Step: 5
Training loss: 3.114989612494672
Validation loss: 2.54111044002184

Epoch: 6| Step: 6
Training loss: 3.219410060128083
Validation loss: 2.5509826020877147

Epoch: 6| Step: 7
Training loss: 2.650510083895925
Validation loss: 2.555151087093729

Epoch: 6| Step: 8
Training loss: 2.847478748540307
Validation loss: 2.5617570848118585

Epoch: 6| Step: 9
Training loss: 2.5772247592253588
Validation loss: 2.5344253063462823

Epoch: 6| Step: 10
Training loss: 2.515273739002715
Validation loss: 2.564918591224641

Epoch: 6| Step: 11
Training loss: 2.493426454440478
Validation loss: 2.529516474454339

Epoch: 6| Step: 12
Training loss: 2.4687984799803764
Validation loss: 2.5775628564340223

Epoch: 6| Step: 13
Training loss: 3.7398850399851447
Validation loss: 2.5762187534266436

Epoch: 80| Step: 0
Training loss: 1.8546919632225678
Validation loss: 2.5334575015333445

Epoch: 6| Step: 1
Training loss: 3.5959033651299
Validation loss: 2.548236108016515

Epoch: 6| Step: 2
Training loss: 3.1396300604536047
Validation loss: 2.548947679991462

Epoch: 6| Step: 3
Training loss: 3.012476725508185
Validation loss: 2.5524088645454714

Epoch: 6| Step: 4
Training loss: 2.918141310158692
Validation loss: 2.5561550190630866

Epoch: 6| Step: 5
Training loss: 3.2404889540776134
Validation loss: 2.5830444951165306

Epoch: 6| Step: 6
Training loss: 2.1581078970082554
Validation loss: 2.53874802477519

Epoch: 6| Step: 7
Training loss: 2.996550165895528
Validation loss: 2.5137003070201684

Epoch: 6| Step: 8
Training loss: 3.044066401335113
Validation loss: 2.5279658666523157

Epoch: 6| Step: 9
Training loss: 2.330319490426091
Validation loss: 2.5450073375918874

Epoch: 6| Step: 10
Training loss: 2.8283671912926223
Validation loss: 2.550228944104411

Epoch: 6| Step: 11
Training loss: 3.1204177831042563
Validation loss: 2.546790262434864

Epoch: 6| Step: 12
Training loss: 2.73223077897934
Validation loss: 2.5485862892860567

Epoch: 6| Step: 13
Training loss: 2.547786806862029
Validation loss: 2.5550602807785405

Epoch: 81| Step: 0
Training loss: 3.1760860357858487
Validation loss: 2.5494739371067445

Epoch: 6| Step: 1
Training loss: 2.4393270443173836
Validation loss: 2.5732768364956593

Epoch: 6| Step: 2
Training loss: 1.7685532045911094
Validation loss: 2.5404559465523713

Epoch: 6| Step: 3
Training loss: 3.0756489820965878
Validation loss: 2.5544418774329802

Epoch: 6| Step: 4
Training loss: 3.2617750334309354
Validation loss: 2.551533914424792

Epoch: 6| Step: 5
Training loss: 2.2609676504069056
Validation loss: 2.5512705376060745

Epoch: 6| Step: 6
Training loss: 2.8543401697889137
Validation loss: 2.5556432978081456

Epoch: 6| Step: 7
Training loss: 2.4665225639865502
Validation loss: 2.5646816124038434

Epoch: 6| Step: 8
Training loss: 3.3398179081145716
Validation loss: 2.5644653810864066

Epoch: 6| Step: 9
Training loss: 3.49790823963658
Validation loss: 2.5583862671448583

Epoch: 6| Step: 10
Training loss: 3.018557057029562
Validation loss: 2.543794311982437

Epoch: 6| Step: 11
Training loss: 2.624757664711528
Validation loss: 2.583195273461073

Epoch: 6| Step: 12
Training loss: 2.6522520608461586
Validation loss: 2.544775025553496

Epoch: 6| Step: 13
Training loss: 3.150098490310617
Validation loss: 2.5366246345660564

Epoch: 82| Step: 0
Training loss: 2.9247285505010905
Validation loss: 2.5690190309421346

Epoch: 6| Step: 1
Training loss: 2.7578696442213912
Validation loss: 2.565863823776283

Epoch: 6| Step: 2
Training loss: 3.1292250491070446
Validation loss: 2.561340265682653

Epoch: 6| Step: 3
Training loss: 2.8446097279582188
Validation loss: 2.5390135441833594

Epoch: 6| Step: 4
Training loss: 2.8247482626501377
Validation loss: 2.533750323360586

Epoch: 6| Step: 5
Training loss: 2.3047078794451186
Validation loss: 2.542525009500289

Epoch: 6| Step: 6
Training loss: 2.841397496635541
Validation loss: 2.572413177335759

Epoch: 6| Step: 7
Training loss: 2.727584516158142
Validation loss: 2.560010946231815

Epoch: 6| Step: 8
Training loss: 3.3079039159656287
Validation loss: 2.5579310597501546

Epoch: 6| Step: 9
Training loss: 2.9262939329894695
Validation loss: 2.53172806965494

Epoch: 6| Step: 10
Training loss: 1.9663279333269503
Validation loss: 2.540732497669686

Epoch: 6| Step: 11
Training loss: 3.1364890426573266
Validation loss: 2.5280692968662604

Epoch: 6| Step: 12
Training loss: 2.469498146750015
Validation loss: 2.5550885973962125

Epoch: 6| Step: 13
Training loss: 3.606859395653261
Validation loss: 2.550776649419064

Epoch: 83| Step: 0
Training loss: 2.3487997967210625
Validation loss: 2.569657269500902

Epoch: 6| Step: 1
Training loss: 3.3214154016142827
Validation loss: 2.5636578576924878

Epoch: 6| Step: 2
Training loss: 3.321221153240246
Validation loss: 2.541398396514908

Epoch: 6| Step: 3
Training loss: 2.7731533710919036
Validation loss: 2.5507253097900016

Epoch: 6| Step: 4
Training loss: 3.7620294270315155
Validation loss: 2.5466073114008547

Epoch: 6| Step: 5
Training loss: 2.415290001937041
Validation loss: 2.5633948489680645

Epoch: 6| Step: 6
Training loss: 2.520389381177334
Validation loss: 2.568394757629147

Epoch: 6| Step: 7
Training loss: 2.5026809622380517
Validation loss: 2.5853610527515136

Epoch: 6| Step: 8
Training loss: 2.4770049172307576
Validation loss: 2.5539897768586584

Epoch: 6| Step: 9
Training loss: 2.577634452620831
Validation loss: 2.581837064659796

Epoch: 6| Step: 10
Training loss: 3.063839989052239
Validation loss: 2.5516427646561106

Epoch: 6| Step: 11
Training loss: 2.3535163341220406
Validation loss: 2.549863404723963

Epoch: 6| Step: 12
Training loss: 2.648676948638144
Validation loss: 2.541148874509829

Epoch: 6| Step: 13
Training loss: 3.4127112187004123
Validation loss: 2.5521637760532405

Epoch: 84| Step: 0
Training loss: 2.535941497555142
Validation loss: 2.5508227659103064

Epoch: 6| Step: 1
Training loss: 2.951515687699513
Validation loss: 2.5526345694637156

Epoch: 6| Step: 2
Training loss: 2.707248871658179
Validation loss: 2.55259248544575

Epoch: 6| Step: 3
Training loss: 3.3531914156036087
Validation loss: 2.5437046130121392

Epoch: 6| Step: 4
Training loss: 2.89079539853547
Validation loss: 2.5504001138650234

Epoch: 6| Step: 5
Training loss: 2.744797206537687
Validation loss: 2.5497108372732336

Epoch: 6| Step: 6
Training loss: 2.668380147065431
Validation loss: 2.5374034293203414

Epoch: 6| Step: 7
Training loss: 3.4436515558645024
Validation loss: 2.5452294271848235

Epoch: 6| Step: 8
Training loss: 2.535001823529974
Validation loss: 2.549042971362476

Epoch: 6| Step: 9
Training loss: 2.856320944140819
Validation loss: 2.5567574964530624

Epoch: 6| Step: 10
Training loss: 2.9268104362657286
Validation loss: 2.5487392202740384

Epoch: 6| Step: 11
Training loss: 2.5269855322051935
Validation loss: 2.5429228998780826

Epoch: 6| Step: 12
Training loss: 2.5070849162367197
Validation loss: 2.5484653960197465

Epoch: 6| Step: 13
Training loss: 2.823157231026751
Validation loss: 2.5464188039905884

Epoch: 85| Step: 0
Training loss: 2.938198087814173
Validation loss: 2.5225816100197145

Epoch: 6| Step: 1
Training loss: 2.8203480049920606
Validation loss: 2.5723374234393677

Epoch: 6| Step: 2
Training loss: 3.481480512400944
Validation loss: 2.528226885617339

Epoch: 6| Step: 3
Training loss: 2.679212344557901
Validation loss: 2.5618492118438274

Epoch: 6| Step: 4
Training loss: 2.8942165847224057
Validation loss: 2.53518480005821

Epoch: 6| Step: 5
Training loss: 2.4687735640934347
Validation loss: 2.5547343531997204

Epoch: 6| Step: 6
Training loss: 2.9829241836125613
Validation loss: 2.5519064672249363

Epoch: 6| Step: 7
Training loss: 2.4158118369426975
Validation loss: 2.540859237052555

Epoch: 6| Step: 8
Training loss: 2.8497372154754244
Validation loss: 2.5446576292059624

Epoch: 6| Step: 9
Training loss: 2.4831994112331146
Validation loss: 2.5331070778553246

Epoch: 6| Step: 10
Training loss: 2.5830580246773587
Validation loss: 2.54300802237149

Epoch: 6| Step: 11
Training loss: 3.117628635178469
Validation loss: 2.5594619832155123

Epoch: 6| Step: 12
Training loss: 2.7430236063409748
Validation loss: 2.5535935762406328

Epoch: 6| Step: 13
Training loss: 2.8701499166111937
Validation loss: 2.5480753691217712

Epoch: 86| Step: 0
Training loss: 2.7656479311924507
Validation loss: 2.5425120466983877

Epoch: 6| Step: 1
Training loss: 3.5380603306070313
Validation loss: 2.5455713580146453

Epoch: 6| Step: 2
Training loss: 2.6637922133095286
Validation loss: 2.552395916786312

Epoch: 6| Step: 3
Training loss: 2.874137583211528
Validation loss: 2.5643299670739266

Epoch: 6| Step: 4
Training loss: 2.5799294370420225
Validation loss: 2.543779024590108

Epoch: 6| Step: 5
Training loss: 2.7010620712723745
Validation loss: 2.5374734408875264

Epoch: 6| Step: 6
Training loss: 2.5370896406925927
Validation loss: 2.567047844573075

Epoch: 6| Step: 7
Training loss: 2.6230536011292207
Validation loss: 2.554200395583792

Epoch: 6| Step: 8
Training loss: 2.267633113802199
Validation loss: 2.536176332095172

Epoch: 6| Step: 9
Training loss: 2.9972578868171973
Validation loss: 2.5438192771275725

Epoch: 6| Step: 10
Training loss: 2.9525665885528927
Validation loss: 2.525917571994311

Epoch: 6| Step: 11
Training loss: 3.0344774820168277
Validation loss: 2.5630982173675996

Epoch: 6| Step: 12
Training loss: 3.2842669468317824
Validation loss: 2.54439205872917

Epoch: 6| Step: 13
Training loss: 2.674902466751736
Validation loss: 2.5534220061060138

Epoch: 87| Step: 0
Training loss: 2.7183300877903926
Validation loss: 2.5440961146109173

Epoch: 6| Step: 1
Training loss: 2.380529692232505
Validation loss: 2.539752990885824

Epoch: 6| Step: 2
Training loss: 2.647835181958626
Validation loss: 2.5408800519363193

Epoch: 6| Step: 3
Training loss: 3.1326158419026506
Validation loss: 2.5594552231879706

Epoch: 6| Step: 4
Training loss: 3.8725972263254733
Validation loss: 2.535263311313314

Epoch: 6| Step: 5
Training loss: 3.4765379486931556
Validation loss: 2.5490164270788553

Epoch: 6| Step: 6
Training loss: 2.465354225752368
Validation loss: 2.553373379821279

Epoch: 6| Step: 7
Training loss: 2.551934768608403
Validation loss: 2.538612244773666

Epoch: 6| Step: 8
Training loss: 3.3771671825230887
Validation loss: 2.546290943369662

Epoch: 6| Step: 9
Training loss: 2.9355925190334533
Validation loss: 2.5279629662902026

Epoch: 6| Step: 10
Training loss: 2.538697389614437
Validation loss: 2.533655628534194

Epoch: 6| Step: 11
Training loss: 2.4604125416651383
Validation loss: 2.5857529142604574

Epoch: 6| Step: 12
Training loss: 2.1452160907373066
Validation loss: 2.544680471998366

Epoch: 6| Step: 13
Training loss: 2.225631251424115
Validation loss: 2.5558485739534955

Epoch: 88| Step: 0
Training loss: 3.353038969473893
Validation loss: 2.5363046020432423

Epoch: 6| Step: 1
Training loss: 2.4697462558526815
Validation loss: 2.5528584578714746

Epoch: 6| Step: 2
Training loss: 2.5552335849597108
Validation loss: 2.5440031360810176

Epoch: 6| Step: 3
Training loss: 3.0015709260805403
Validation loss: 2.5615317283336285

Epoch: 6| Step: 4
Training loss: 3.14660015402289
Validation loss: 2.5425009996286767

Epoch: 6| Step: 5
Training loss: 2.728817419948351
Validation loss: 2.535646615510208

Epoch: 6| Step: 6
Training loss: 2.4010805359933114
Validation loss: 2.5453152367543095

Epoch: 6| Step: 7
Training loss: 2.834334832256982
Validation loss: 2.55773599489309

Epoch: 6| Step: 8
Training loss: 2.8246061236162747
Validation loss: 2.562224426578562

Epoch: 6| Step: 9
Training loss: 2.13993768726075
Validation loss: 2.5566754849479385

Epoch: 6| Step: 10
Training loss: 3.5299261531724127
Validation loss: 2.553035764457306

Epoch: 6| Step: 11
Training loss: 2.689471209429939
Validation loss: 2.5377270650954773

Epoch: 6| Step: 12
Training loss: 3.2023056843252515
Validation loss: 2.5625360267761796

Epoch: 6| Step: 13
Training loss: 1.7875515083414393
Validation loss: 2.5718768016524938

Epoch: 89| Step: 0
Training loss: 2.681614486000156
Validation loss: 2.547255192180128

Epoch: 6| Step: 1
Training loss: 3.4959165730680777
Validation loss: 2.5551864278818788

Epoch: 6| Step: 2
Training loss: 3.4164770740536485
Validation loss: 2.550876385440242

Epoch: 6| Step: 3
Training loss: 3.1837972938670354
Validation loss: 2.5470465763292305

Epoch: 6| Step: 4
Training loss: 2.8828242438679323
Validation loss: 2.5578706204311397

Epoch: 6| Step: 5
Training loss: 3.4479407149260877
Validation loss: 2.571312196377457

Epoch: 6| Step: 6
Training loss: 2.874803951047446
Validation loss: 2.547671662209315

Epoch: 6| Step: 7
Training loss: 2.533839843542241
Validation loss: 2.539378602045522

Epoch: 6| Step: 8
Training loss: 2.411190954645273
Validation loss: 2.5449869654401223

Epoch: 6| Step: 9
Training loss: 2.340870627131869
Validation loss: 2.54397189054969

Epoch: 6| Step: 10
Training loss: 2.6491333714021117
Validation loss: 2.560148158830076

Epoch: 6| Step: 11
Training loss: 2.033699085088294
Validation loss: 2.548110833198307

Epoch: 6| Step: 12
Training loss: 2.778548911399537
Validation loss: 2.5524074995648824

Epoch: 6| Step: 13
Training loss: 2.27000498464432
Validation loss: 2.530442092084868

Epoch: 90| Step: 0
Training loss: 2.690942378271729
Validation loss: 2.548392589011374

Epoch: 6| Step: 1
Training loss: 3.299393979693808
Validation loss: 2.560209521691011

Epoch: 6| Step: 2
Training loss: 3.006093353821882
Validation loss: 2.564615804280864

Epoch: 6| Step: 3
Training loss: 3.000313106727916
Validation loss: 2.546830655614128

Epoch: 6| Step: 4
Training loss: 3.4207418995639847
Validation loss: 2.5359608930424544

Epoch: 6| Step: 5
Training loss: 2.634362735018342
Validation loss: 2.5622121887889406

Epoch: 6| Step: 6
Training loss: 2.777353278678934
Validation loss: 2.553426536158727

Epoch: 6| Step: 7
Training loss: 3.2184239194564768
Validation loss: 2.5196758478377945

Epoch: 6| Step: 8
Training loss: 2.324479904248765
Validation loss: 2.557194349141748

Epoch: 6| Step: 9
Training loss: 2.4099270357665405
Validation loss: 2.5333029775819345

Epoch: 6| Step: 10
Training loss: 2.525456898963621
Validation loss: 2.530188998083784

Epoch: 6| Step: 11
Training loss: 2.3141216056739906
Validation loss: 2.553525213411169

Epoch: 6| Step: 12
Training loss: 2.79347576527814
Validation loss: 2.5519731083853783

Epoch: 6| Step: 13
Training loss: 2.7720028887536876
Validation loss: 2.53081207254737

Epoch: 91| Step: 0
Training loss: 3.1082623661997695
Validation loss: 2.550549249774429

Epoch: 6| Step: 1
Training loss: 3.090511592253857
Validation loss: 2.529173797236788

Epoch: 6| Step: 2
Training loss: 3.207222007068502
Validation loss: 2.5498839611133968

Epoch: 6| Step: 3
Training loss: 2.6180005077597617
Validation loss: 2.544078585413001

Epoch: 6| Step: 4
Training loss: 3.2403357675610787
Validation loss: 2.5532320288205947

Epoch: 6| Step: 5
Training loss: 2.486127511176982
Validation loss: 2.531406521816113

Epoch: 6| Step: 6
Training loss: 2.6417179892896447
Validation loss: 2.548901039255835

Epoch: 6| Step: 7
Training loss: 2.863021110177034
Validation loss: 2.5480759929090495

Epoch: 6| Step: 8
Training loss: 2.923688682640559
Validation loss: 2.543646750897331

Epoch: 6| Step: 9
Training loss: 2.7797138386551214
Validation loss: 2.545441127806859

Epoch: 6| Step: 10
Training loss: 2.359268287114871
Validation loss: 2.5723403584809743

Epoch: 6| Step: 11
Training loss: 2.9582454148960355
Validation loss: 2.5506346393996298

Epoch: 6| Step: 12
Training loss: 2.5691049632201164
Validation loss: 2.5562561764384113

Epoch: 6| Step: 13
Training loss: 2.455891792249662
Validation loss: 2.5511175277355402

Epoch: 92| Step: 0
Training loss: 2.5531213842060536
Validation loss: 2.5572973360341695

Epoch: 6| Step: 1
Training loss: 2.4919530106487753
Validation loss: 2.5610756245593462

Epoch: 6| Step: 2
Training loss: 2.5606912882080572
Validation loss: 2.5449643528053887

Epoch: 6| Step: 3
Training loss: 3.0777473024342985
Validation loss: 2.5376058494684712

Epoch: 6| Step: 4
Training loss: 2.0956588697782434
Validation loss: 2.5568813580177907

Epoch: 6| Step: 5
Training loss: 2.8783003067156923
Validation loss: 2.5564971612586453

Epoch: 6| Step: 6
Training loss: 2.4899334415287906
Validation loss: 2.5679715185644243

Epoch: 6| Step: 7
Training loss: 3.2722226895423936
Validation loss: 2.563927651183731

Epoch: 6| Step: 8
Training loss: 3.069743717692011
Validation loss: 2.542305298417903

Epoch: 6| Step: 9
Training loss: 2.961590616870197
Validation loss: 2.5461628548178115

Epoch: 6| Step: 10
Training loss: 2.907549167784775
Validation loss: 2.53775443258307

Epoch: 6| Step: 11
Training loss: 3.087956871176252
Validation loss: 2.543831078344144

Epoch: 6| Step: 12
Training loss: 3.206313913760507
Validation loss: 2.542044187078708

Epoch: 6| Step: 13
Training loss: 2.78202954629419
Validation loss: 2.5592650676868662

Epoch: 93| Step: 0
Training loss: 2.533006788423149
Validation loss: 2.5533146107805256

Epoch: 6| Step: 1
Training loss: 3.187007492013533
Validation loss: 2.5353950804998613

Epoch: 6| Step: 2
Training loss: 3.3435763019830453
Validation loss: 2.5498754986894734

Epoch: 6| Step: 3
Training loss: 2.7229741046415294
Validation loss: 2.541686508999625

Epoch: 6| Step: 4
Training loss: 2.6790597252590556
Validation loss: 2.535890331212146

Epoch: 6| Step: 5
Training loss: 3.3465909208664835
Validation loss: 2.5748250943915663

Epoch: 6| Step: 6
Training loss: 3.222844158820885
Validation loss: 2.5194668765984902

Epoch: 6| Step: 7
Training loss: 2.666701455684074
Validation loss: 2.5170668170254804

Epoch: 6| Step: 8
Training loss: 2.1576757831063644
Validation loss: 2.5403887257491284

Epoch: 6| Step: 9
Training loss: 2.225713842515396
Validation loss: 2.5277689894145894

Epoch: 6| Step: 10
Training loss: 2.945051510527142
Validation loss: 2.5384793448493546

Epoch: 6| Step: 11
Training loss: 2.856886150544479
Validation loss: 2.5285596163173842

Epoch: 6| Step: 12
Training loss: 3.0523093251654063
Validation loss: 2.556281688798748

Epoch: 6| Step: 13
Training loss: 1.9124036178736563
Validation loss: 2.5339503901976776

Epoch: 94| Step: 0
Training loss: 3.166697217559676
Validation loss: 2.5191794000084484

Epoch: 6| Step: 1
Training loss: 2.4506742055788746
Validation loss: 2.517021765424396

Epoch: 6| Step: 2
Training loss: 3.270970691947289
Validation loss: 2.539446403817988

Epoch: 6| Step: 3
Training loss: 2.6945479483458925
Validation loss: 2.5396462914550324

Epoch: 6| Step: 4
Training loss: 2.8363430269199497
Validation loss: 2.5485249050876218

Epoch: 6| Step: 5
Training loss: 2.3841664954297315
Validation loss: 2.51874564672833

Epoch: 6| Step: 6
Training loss: 2.3522804152907972
Validation loss: 2.509801070646641

Epoch: 6| Step: 7
Training loss: 3.4626316031775213
Validation loss: 2.5418227904441877

Epoch: 6| Step: 8
Training loss: 3.4746058068945986
Validation loss: 2.528220714361097

Epoch: 6| Step: 9
Training loss: 1.610757326693511
Validation loss: 2.5507415405071026

Epoch: 6| Step: 10
Training loss: 3.035693814505146
Validation loss: 2.5402779607309784

Epoch: 6| Step: 11
Training loss: 2.263369891452444
Validation loss: 2.543250250420191

Epoch: 6| Step: 12
Training loss: 2.3664181910176088
Validation loss: 2.5350988870030227

Epoch: 6| Step: 13
Training loss: 3.902891744908273
Validation loss: 2.5436937177626278

Epoch: 95| Step: 0
Training loss: 3.5519617382428836
Validation loss: 2.5254547245766386

Epoch: 6| Step: 1
Training loss: 2.504984940199973
Validation loss: 2.5428057807192244

Epoch: 6| Step: 2
Training loss: 2.780285442984266
Validation loss: 2.5501011513713427

Epoch: 6| Step: 3
Training loss: 2.9442612772976076
Validation loss: 2.5742664417702277

Epoch: 6| Step: 4
Training loss: 2.3568257081333077
Validation loss: 2.525114833300309

Epoch: 6| Step: 5
Training loss: 3.1239929102329977
Validation loss: 2.5562312414930863

Epoch: 6| Step: 6
Training loss: 3.331365306354487
Validation loss: 2.5377929279991327

Epoch: 6| Step: 7
Training loss: 2.5848129916106353
Validation loss: 2.5392043641548576

Epoch: 6| Step: 8
Training loss: 1.9573877432486502
Validation loss: 2.558645855046571

Epoch: 6| Step: 9
Training loss: 2.7266950602401594
Validation loss: 2.547545334196857

Epoch: 6| Step: 10
Training loss: 2.829830266762316
Validation loss: 2.5687717148700546

Epoch: 6| Step: 11
Training loss: 3.463515309780863
Validation loss: 2.549419366970948

Epoch: 6| Step: 12
Training loss: 2.3722684109271164
Validation loss: 2.5857891757363545

Epoch: 6| Step: 13
Training loss: 2.101641458495801
Validation loss: 2.526905704581704

Epoch: 96| Step: 0
Training loss: 2.9837054555098526
Validation loss: 2.5327826240028926

Epoch: 6| Step: 1
Training loss: 2.9754179909323932
Validation loss: 2.5463215266627053

Epoch: 6| Step: 2
Training loss: 3.5795020239811373
Validation loss: 2.557828352950804

Epoch: 6| Step: 3
Training loss: 2.3569338466406276
Validation loss: 2.5417838779846647

Epoch: 6| Step: 4
Training loss: 2.8106877740318366
Validation loss: 2.551039750622919

Epoch: 6| Step: 5
Training loss: 2.007431766020218
Validation loss: 2.567644524117875

Epoch: 6| Step: 6
Training loss: 3.0120016675136454
Validation loss: 2.578538283667678

Epoch: 6| Step: 7
Training loss: 2.7430754090783096
Validation loss: 2.583283473184332

Epoch: 6| Step: 8
Training loss: 2.496875622573794
Validation loss: 2.583865813104902

Epoch: 6| Step: 9
Training loss: 4.064093644001919
Validation loss: 2.6019377271085204

Epoch: 6| Step: 10
Training loss: 2.5787707820467274
Validation loss: 2.5754376109775787

Epoch: 6| Step: 11
Training loss: 1.9637417139064284
Validation loss: 2.5550059323012912

Epoch: 6| Step: 12
Training loss: 2.7872378580997554
Validation loss: 2.571049326524742

Epoch: 6| Step: 13
Training loss: 2.6821046831949364
Validation loss: 2.596988070648267

Epoch: 97| Step: 0
Training loss: 2.8743431336058385
Validation loss: 2.5671536347897357

Epoch: 6| Step: 1
Training loss: 2.7550080388223606
Validation loss: 2.535184291412304

Epoch: 6| Step: 2
Training loss: 2.546737760813051
Validation loss: 2.5664774581927943

Epoch: 6| Step: 3
Training loss: 3.7439574832132374
Validation loss: 2.5807404706259605

Epoch: 6| Step: 4
Training loss: 2.793599432316402
Validation loss: 2.562529747062717

Epoch: 6| Step: 5
Training loss: 3.0148703465965347
Validation loss: 2.5499745264938474

Epoch: 6| Step: 6
Training loss: 3.146275386109235
Validation loss: 2.5758002426264026

Epoch: 6| Step: 7
Training loss: 3.180728676279914
Validation loss: 2.5555288281617683

Epoch: 6| Step: 8
Training loss: 2.3291635948893354
Validation loss: 2.56219097588146

Epoch: 6| Step: 9
Training loss: 2.8183665655497756
Validation loss: 2.55109930264315

Epoch: 6| Step: 10
Training loss: 2.7475920451941125
Validation loss: 2.565097951540557

Epoch: 6| Step: 11
Training loss: 2.375123472517711
Validation loss: 2.5695051300441594

Epoch: 6| Step: 12
Training loss: 2.6862935751695254
Validation loss: 2.555758474517346

Epoch: 6| Step: 13
Training loss: 2.171868193910761
Validation loss: 2.5533371585007747

Epoch: 98| Step: 0
Training loss: 3.021990920390861
Validation loss: 2.5320244873686364

Epoch: 6| Step: 1
Training loss: 3.001941688332151
Validation loss: 2.542054925518255

Epoch: 6| Step: 2
Training loss: 2.164441457681512
Validation loss: 2.533352709619463

Epoch: 6| Step: 3
Training loss: 2.543805197227022
Validation loss: 2.5280661136967835

Epoch: 6| Step: 4
Training loss: 2.7483275269523557
Validation loss: 2.553799797138255

Epoch: 6| Step: 5
Training loss: 3.362943377564595
Validation loss: 2.563973385155591

Epoch: 6| Step: 6
Training loss: 2.72350973273132
Validation loss: 2.5790767142356836

Epoch: 6| Step: 7
Training loss: 2.2861802635173243
Validation loss: 2.5365529743997346

Epoch: 6| Step: 8
Training loss: 2.6397495963089717
Validation loss: 2.5603675703476036

Epoch: 6| Step: 9
Training loss: 3.263503558271925
Validation loss: 2.525441674154928

Epoch: 6| Step: 10
Training loss: 3.3069073951935426
Validation loss: 2.541758298777137

Epoch: 6| Step: 11
Training loss: 2.908565460239639
Validation loss: 2.551162333213927

Epoch: 6| Step: 12
Training loss: 3.0773018447955236
Validation loss: 2.5294199001520963

Epoch: 6| Step: 13
Training loss: 1.497911429716602
Validation loss: 2.5406407633100456

Epoch: 99| Step: 0
Training loss: 2.613018849517655
Validation loss: 2.5728656431109806

Epoch: 6| Step: 1
Training loss: 2.650324326587653
Validation loss: 2.5646509856570185

Epoch: 6| Step: 2
Training loss: 2.9132579684893676
Validation loss: 2.5543281899831887

Epoch: 6| Step: 3
Training loss: 2.2469041506769045
Validation loss: 2.529963707482609

Epoch: 6| Step: 4
Training loss: 2.1747505308002157
Validation loss: 2.5491493508925993

Epoch: 6| Step: 5
Training loss: 2.988997310041211
Validation loss: 2.5314092521446345

Epoch: 6| Step: 6
Training loss: 2.466841527394262
Validation loss: 2.5257804942795445

Epoch: 6| Step: 7
Training loss: 2.4952031846726017
Validation loss: 2.5436659329265976

Epoch: 6| Step: 8
Training loss: 3.795844044061339
Validation loss: 2.5243600169732274

Epoch: 6| Step: 9
Training loss: 2.616081436785335
Validation loss: 2.5464121976021787

Epoch: 6| Step: 10
Training loss: 2.7060027928024284
Validation loss: 2.550532584618638

Epoch: 6| Step: 11
Training loss: 3.0529427387104278
Validation loss: 2.5446527699701424

Epoch: 6| Step: 12
Training loss: 3.15090883253503
Validation loss: 2.5587107737066317

Epoch: 6| Step: 13
Training loss: 3.193262314560883
Validation loss: 2.559374003301402

Epoch: 100| Step: 0
Training loss: 3.1811026908178883
Validation loss: 2.5473386361521237

Epoch: 6| Step: 1
Training loss: 3.1113799259066646
Validation loss: 2.5519203688169196

Epoch: 6| Step: 2
Training loss: 2.522217257696
Validation loss: 2.564841920298025

Epoch: 6| Step: 3
Training loss: 2.508561637432903
Validation loss: 2.534503331334139

Epoch: 6| Step: 4
Training loss: 3.3870901500326562
Validation loss: 2.5380052822493817

Epoch: 6| Step: 5
Training loss: 2.7448240467649243
Validation loss: 2.547494379783457

Epoch: 6| Step: 6
Training loss: 2.873631027035485
Validation loss: 2.5680928557122225

Epoch: 6| Step: 7
Training loss: 2.7300815553325672
Validation loss: 2.5521064678564143

Epoch: 6| Step: 8
Training loss: 2.3527141805152945
Validation loss: 2.55134894775219

Epoch: 6| Step: 9
Training loss: 3.228511046436938
Validation loss: 2.546664733279838

Epoch: 6| Step: 10
Training loss: 2.512310616866497
Validation loss: 2.5292977740438656

Epoch: 6| Step: 11
Training loss: 2.380882807577981
Validation loss: 2.529966134868495

Epoch: 6| Step: 12
Training loss: 3.003658448156373
Validation loss: 2.5295791985968283

Epoch: 6| Step: 13
Training loss: 2.4130045229841355
Validation loss: 2.534201636642068

Epoch: 101| Step: 0
Training loss: 2.6913483146998267
Validation loss: 2.5450804237619775

Epoch: 6| Step: 1
Training loss: 2.2505886579406233
Validation loss: 2.5487111866726777

Epoch: 6| Step: 2
Training loss: 2.8913134605610784
Validation loss: 2.5508424030180814

Epoch: 6| Step: 3
Training loss: 3.2310945395992556
Validation loss: 2.5708628526356603

Epoch: 6| Step: 4
Training loss: 2.511181716104513
Validation loss: 2.5657692475482317

Epoch: 6| Step: 5
Training loss: 2.774750390726157
Validation loss: 2.5651587822392994

Epoch: 6| Step: 6
Training loss: 2.958164013239231
Validation loss: 2.5579903340768824

Epoch: 6| Step: 7
Training loss: 2.8378565156781024
Validation loss: 2.550785085234915

Epoch: 6| Step: 8
Training loss: 2.315217560664753
Validation loss: 2.5387461677429806

Epoch: 6| Step: 9
Training loss: 2.532627343217521
Validation loss: 2.567083034562267

Epoch: 6| Step: 10
Training loss: 2.8972588376390935
Validation loss: 2.5445992500104526

Epoch: 6| Step: 11
Training loss: 3.1583527462915417
Validation loss: 2.533473128470133

Epoch: 6| Step: 12
Training loss: 2.9818424044130603
Validation loss: 2.544093302168051

Epoch: 6| Step: 13
Training loss: 3.3457755255228196
Validation loss: 2.5594424508038967

Epoch: 102| Step: 0
Training loss: 2.5322160172601484
Validation loss: 2.5571266209442314

Epoch: 6| Step: 1
Training loss: 2.5493733140884216
Validation loss: 2.5478482229299204

Epoch: 6| Step: 2
Training loss: 3.1511388506234064
Validation loss: 2.5711135261896243

Epoch: 6| Step: 3
Training loss: 2.806641984168077
Validation loss: 2.521267728328811

Epoch: 6| Step: 4
Training loss: 2.3198358836168786
Validation loss: 2.5358779127576536

Epoch: 6| Step: 5
Training loss: 2.6784845883052637
Validation loss: 2.5375169859844573

Epoch: 6| Step: 6
Training loss: 3.4334519566410147
Validation loss: 2.515708069502065

Epoch: 6| Step: 7
Training loss: 3.23037929941529
Validation loss: 2.5209258142313034

Epoch: 6| Step: 8
Training loss: 2.4645160148844782
Validation loss: 2.532608424278432

Epoch: 6| Step: 9
Training loss: 3.044096476987228
Validation loss: 2.5105287178558413

Epoch: 6| Step: 10
Training loss: 2.631087465317827
Validation loss: 2.5672858801607723

Epoch: 6| Step: 11
Training loss: 2.3132978557904065
Validation loss: 2.5618360666244953

Epoch: 6| Step: 12
Training loss: 2.7133949420723513
Validation loss: 2.547182040589954

Epoch: 6| Step: 13
Training loss: 3.6034988196169784
Validation loss: 2.550187778415513

Epoch: 103| Step: 0
Training loss: 2.6581441072503327
Validation loss: 2.507179628915608

Epoch: 6| Step: 1
Training loss: 1.7930831041623858
Validation loss: 2.543561489020422

Epoch: 6| Step: 2
Training loss: 3.6433111276557746
Validation loss: 2.544094250397971

Epoch: 6| Step: 3
Training loss: 3.191919890103583
Validation loss: 2.5683404098378864

Epoch: 6| Step: 4
Training loss: 2.9353288784035168
Validation loss: 2.5640848572634725

Epoch: 6| Step: 5
Training loss: 2.885039340433612
Validation loss: 2.570516758281492

Epoch: 6| Step: 6
Training loss: 2.554030400966774
Validation loss: 2.5602487999591856

Epoch: 6| Step: 7
Training loss: 2.77847906373123
Validation loss: 2.5536595178215182

Epoch: 6| Step: 8
Training loss: 2.792914799522638
Validation loss: 2.545062846445696

Epoch: 6| Step: 9
Training loss: 2.9102689785213585
Validation loss: 2.5327943157068518

Epoch: 6| Step: 10
Training loss: 2.846819551934983
Validation loss: 2.5569119364583335

Epoch: 6| Step: 11
Training loss: 2.2046675456095004
Validation loss: 2.546028119712206

Epoch: 6| Step: 12
Training loss: 2.866628982237108
Validation loss: 2.524165531652835

Epoch: 6| Step: 13
Training loss: 2.403683172716364
Validation loss: 2.5557816757467817

Epoch: 104| Step: 0
Training loss: 3.391244576798183
Validation loss: 2.5482300858229947

Epoch: 6| Step: 1
Training loss: 3.3353785598233228
Validation loss: 2.5374349093043684

Epoch: 6| Step: 2
Training loss: 2.4982065443559587
Validation loss: 2.567618404777949

Epoch: 6| Step: 3
Training loss: 2.4181454398286433
Validation loss: 2.53779352198791

Epoch: 6| Step: 4
Training loss: 2.692348276607934
Validation loss: 2.5499835224331027

Epoch: 6| Step: 5
Training loss: 3.2282668962340013
Validation loss: 2.5451088776038224

Epoch: 6| Step: 6
Training loss: 3.414258030370467
Validation loss: 2.562100307007658

Epoch: 6| Step: 7
Training loss: 2.1505788777867507
Validation loss: 2.5413465461347884

Epoch: 6| Step: 8
Training loss: 2.685955934755309
Validation loss: 2.5712842289160736

Epoch: 6| Step: 9
Training loss: 2.5794926570367087
Validation loss: 2.549019806353596

Epoch: 6| Step: 10
Training loss: 2.3194436652613057
Validation loss: 2.546228202496846

Epoch: 6| Step: 11
Training loss: 2.598949506256668
Validation loss: 2.5597494787036004

Epoch: 6| Step: 12
Training loss: 3.007464341660167
Validation loss: 2.5250817641311514

Epoch: 6| Step: 13
Training loss: 2.45749940035901
Validation loss: 2.528048316673487

Epoch: 105| Step: 0
Training loss: 2.613374306428937
Validation loss: 2.524496730073608

Epoch: 6| Step: 1
Training loss: 2.850743006175032
Validation loss: 2.561178026971306

Epoch: 6| Step: 2
Training loss: 2.1723395200747317
Validation loss: 2.5553534151230557

Epoch: 6| Step: 3
Training loss: 2.3187001595705894
Validation loss: 2.536600118090809

Epoch: 6| Step: 4
Training loss: 2.906336957389438
Validation loss: 2.544709711077897

Epoch: 6| Step: 5
Training loss: 2.85456552062191
Validation loss: 2.5334034758908417

Epoch: 6| Step: 6
Training loss: 3.2955953274973053
Validation loss: 2.545324533441973

Epoch: 6| Step: 7
Training loss: 3.395714100497764
Validation loss: 2.562807795469574

Epoch: 6| Step: 8
Training loss: 2.9352544764556163
Validation loss: 2.555091918472827

Epoch: 6| Step: 9
Training loss: 3.5654659305967424
Validation loss: 2.5674690711360646

Epoch: 6| Step: 10
Training loss: 2.0850178838095523
Validation loss: 2.56669686501707

Epoch: 6| Step: 11
Training loss: 2.6777512030208372
Validation loss: 2.556130628729326

Epoch: 6| Step: 12
Training loss: 2.3564679760876572
Validation loss: 2.5482542590188775

Epoch: 6| Step: 13
Training loss: 2.9307211718131874
Validation loss: 2.5607926868571167

Epoch: 106| Step: 0
Training loss: 2.5720062704410322
Validation loss: 2.5318184663319827

Epoch: 6| Step: 1
Training loss: 2.0097290866151374
Validation loss: 2.5450472010211453

Epoch: 6| Step: 2
Training loss: 2.4098244412374625
Validation loss: 2.5567005830139733

Epoch: 6| Step: 3
Training loss: 3.698339275156491
Validation loss: 2.546587780056425

Epoch: 6| Step: 4
Training loss: 2.2944303205279644
Validation loss: 2.534796921348608

Epoch: 6| Step: 5
Training loss: 2.9257937992575496
Validation loss: 2.5326444895860307

Epoch: 6| Step: 6
Training loss: 2.7966612835431794
Validation loss: 2.528885381409637

Epoch: 6| Step: 7
Training loss: 2.870208063857738
Validation loss: 2.5484426024941986

Epoch: 6| Step: 8
Training loss: 2.9780021650154027
Validation loss: 2.53234252383227

Epoch: 6| Step: 9
Training loss: 2.8742430975987814
Validation loss: 2.586507473384407

Epoch: 6| Step: 10
Training loss: 2.9807981456556303
Validation loss: 2.556665135809494

Epoch: 6| Step: 11
Training loss: 2.430125794941888
Validation loss: 2.5603305578255924

Epoch: 6| Step: 12
Training loss: 2.8506014942085782
Validation loss: 2.5421183618638636

Epoch: 6| Step: 13
Training loss: 3.341683007356514
Validation loss: 2.5502826545279658

Epoch: 107| Step: 0
Training loss: 2.917129988427798
Validation loss: 2.525313532607563

Epoch: 6| Step: 1
Training loss: 2.2558451069962744
Validation loss: 2.5205577756344746

Epoch: 6| Step: 2
Training loss: 3.3493914207971383
Validation loss: 2.550559282990017

Epoch: 6| Step: 3
Training loss: 3.4391309163742134
Validation loss: 2.5555306408969383

Epoch: 6| Step: 4
Training loss: 2.9100017327372316
Validation loss: 2.580611740044581

Epoch: 6| Step: 5
Training loss: 2.5084014866421356
Validation loss: 2.543273489148343

Epoch: 6| Step: 6
Training loss: 2.9763010465881767
Validation loss: 2.5432318036339323

Epoch: 6| Step: 7
Training loss: 2.8806643869393507
Validation loss: 2.5537105881468336

Epoch: 6| Step: 8
Training loss: 2.665331675232064
Validation loss: 2.5005222441625277

Epoch: 6| Step: 9
Training loss: 2.7599169776703087
Validation loss: 2.5400728432724167

Epoch: 6| Step: 10
Training loss: 2.811519027870804
Validation loss: 2.527954830046835

Epoch: 6| Step: 11
Training loss: 2.2089239326390455
Validation loss: 2.53594549372913

Epoch: 6| Step: 12
Training loss: 2.3429505065431577
Validation loss: 2.544172708397576

Epoch: 6| Step: 13
Training loss: 3.200933534827733
Validation loss: 2.5446824778323203

Epoch: 108| Step: 0
Training loss: 3.6954012773426834
Validation loss: 2.507518435318539

Epoch: 6| Step: 1
Training loss: 3.239377046908645
Validation loss: 2.524809168619436

Epoch: 6| Step: 2
Training loss: 2.8637178720431207
Validation loss: 2.5476897568574137

Epoch: 6| Step: 3
Training loss: 1.7037520348025266
Validation loss: 2.5676115284381216

Epoch: 6| Step: 4
Training loss: 2.9611922584788046
Validation loss: 2.5473920854751952

Epoch: 6| Step: 5
Training loss: 2.962255823558962
Validation loss: 2.5522751321517116

Epoch: 6| Step: 6
Training loss: 3.3911143710063945
Validation loss: 2.544604286413279

Epoch: 6| Step: 7
Training loss: 2.9323835251255477
Validation loss: 2.541116683887573

Epoch: 6| Step: 8
Training loss: 2.874653339218263
Validation loss: 2.516551011463692

Epoch: 6| Step: 9
Training loss: 1.9608322054493204
Validation loss: 2.539357480062214

Epoch: 6| Step: 10
Training loss: 2.4043431839252163
Validation loss: 2.551895718001591

Epoch: 6| Step: 11
Training loss: 2.459271645222198
Validation loss: 2.552126737974294

Epoch: 6| Step: 12
Training loss: 2.8156637411384233
Validation loss: 2.5252142706941396

Epoch: 6| Step: 13
Training loss: 2.155729811573754
Validation loss: 2.539609622995064

Epoch: 109| Step: 0
Training loss: 1.9767424610824469
Validation loss: 2.5859615626063084

Epoch: 6| Step: 1
Training loss: 2.676214876331969
Validation loss: 2.562232489019746

Epoch: 6| Step: 2
Training loss: 2.6415882046797203
Validation loss: 2.538036874968935

Epoch: 6| Step: 3
Training loss: 3.026822819343694
Validation loss: 2.5769873133983

Epoch: 6| Step: 4
Training loss: 3.189525035788002
Validation loss: 2.5353596109599192

Epoch: 6| Step: 5
Training loss: 2.94140625
Validation loss: 2.5708578118315177

Epoch: 6| Step: 6
Training loss: 2.633304538649855
Validation loss: 2.551522123716388

Epoch: 6| Step: 7
Training loss: 3.5537910420949097
Validation loss: 2.556444582210205

Epoch: 6| Step: 8
Training loss: 2.956205507229929
Validation loss: 2.5716924612523053

Epoch: 6| Step: 9
Training loss: 2.717297922603097
Validation loss: 2.53772108665778

Epoch: 6| Step: 10
Training loss: 2.5104568182766824
Validation loss: 2.51973693979769

Epoch: 6| Step: 11
Training loss: 2.8998225519546375
Validation loss: 2.5504867207033866

Epoch: 6| Step: 12
Training loss: 2.170155455123401
Validation loss: 2.5562246373975266

Epoch: 6| Step: 13
Training loss: 3.1342836954314244
Validation loss: 2.5485056957536356

Epoch: 110| Step: 0
Training loss: 3.7455447115823355
Validation loss: 2.5369595480543787

Epoch: 6| Step: 1
Training loss: 2.931481709706418
Validation loss: 2.5605390765771268

Epoch: 6| Step: 2
Training loss: 2.8404409418182803
Validation loss: 2.5495189906772437

Epoch: 6| Step: 3
Training loss: 2.5472981856110284
Validation loss: 2.529166234549163

Epoch: 6| Step: 4
Training loss: 2.492047631814239
Validation loss: 2.551637865724367

Epoch: 6| Step: 5
Training loss: 3.6538970418621948
Validation loss: 2.5282436896912395

Epoch: 6| Step: 6
Training loss: 2.450953014071273
Validation loss: 2.5213911218582346

Epoch: 6| Step: 7
Training loss: 3.132858770699445
Validation loss: 2.562703132331577

Epoch: 6| Step: 8
Training loss: 2.245821569785861
Validation loss: 2.5548255283277324

Epoch: 6| Step: 9
Training loss: 3.1025505894202774
Validation loss: 2.536767712346962

Epoch: 6| Step: 10
Training loss: 2.0903875196114274
Validation loss: 2.551384671786525

Epoch: 6| Step: 11
Training loss: 2.202161429423982
Validation loss: 2.538848774057679

Epoch: 6| Step: 12
Training loss: 2.451361538665709
Validation loss: 2.5431269568171597

Epoch: 6| Step: 13
Training loss: 2.767629985013848
Validation loss: 2.5583143146632743

Epoch: 111| Step: 0
Training loss: 1.5113390068555725
Validation loss: 2.5537276903336776

Epoch: 6| Step: 1
Training loss: 2.508960686823798
Validation loss: 2.547627495714809

Epoch: 6| Step: 2
Training loss: 3.09719548881485
Validation loss: 2.5614533821872167

Epoch: 6| Step: 3
Training loss: 2.898686565381171
Validation loss: 2.5545005482821317

Epoch: 6| Step: 4
Training loss: 2.919506398116397
Validation loss: 2.5813608465707536

Epoch: 6| Step: 5
Training loss: 3.340416931581211
Validation loss: 2.5101778446715293

Epoch: 6| Step: 6
Training loss: 2.291061101723888
Validation loss: 2.5614501919633885

Epoch: 6| Step: 7
Training loss: 3.032135509653447
Validation loss: 2.5497888670684428

Epoch: 6| Step: 8
Training loss: 2.309404414793588
Validation loss: 2.5612065942535964

Epoch: 6| Step: 9
Training loss: 2.9398002546277486
Validation loss: 2.574490752232496

Epoch: 6| Step: 10
Training loss: 2.8241557724976047
Validation loss: 2.567971486618392

Epoch: 6| Step: 11
Training loss: 3.0935832277295607
Validation loss: 2.5488795556462702

Epoch: 6| Step: 12
Training loss: 2.535763707437279
Validation loss: 2.5703656630920353

Epoch: 6| Step: 13
Training loss: 3.5749385588374647
Validation loss: 2.557761775141171

Epoch: 112| Step: 0
Training loss: 2.1213884517734773
Validation loss: 2.547547517905904

Epoch: 6| Step: 1
Training loss: 2.555526922130042
Validation loss: 2.560760319696109

Epoch: 6| Step: 2
Training loss: 2.278517876801669
Validation loss: 2.558650589265952

Epoch: 6| Step: 3
Training loss: 2.98371536394591
Validation loss: 2.534455764264746

Epoch: 6| Step: 4
Training loss: 3.143043308193926
Validation loss: 2.5780187948506916

Epoch: 6| Step: 5
Training loss: 2.325878108746373
Validation loss: 2.5788332704895875

Epoch: 6| Step: 6
Training loss: 2.6512381450238753
Validation loss: 2.539745000419323

Epoch: 6| Step: 7
Training loss: 2.8385468555834645
Validation loss: 2.563653343718838

Epoch: 6| Step: 8
Training loss: 2.83577523936417
Validation loss: 2.546556432345691

Epoch: 6| Step: 9
Training loss: 3.9169624839156723
Validation loss: 2.5779394834413094

Epoch: 6| Step: 10
Training loss: 2.8388611406669346
Validation loss: 2.5536723136078967

Epoch: 6| Step: 11
Training loss: 2.3448401395401732
Validation loss: 2.5301626891570392

Epoch: 6| Step: 12
Training loss: 2.898986270910192
Validation loss: 2.568120257976843

Epoch: 6| Step: 13
Training loss: 2.9962740648661548
Validation loss: 2.56709502942777

Epoch: 113| Step: 0
Training loss: 3.5412262287412535
Validation loss: 2.554868794734657

Epoch: 6| Step: 1
Training loss: 2.9685533960393435
Validation loss: 2.5460021400975292

Epoch: 6| Step: 2
Training loss: 2.9391705247251454
Validation loss: 2.569988243370127

Epoch: 6| Step: 3
Training loss: 2.2996427507345265
Validation loss: 2.5582107233449145

Epoch: 6| Step: 4
Training loss: 3.2320306362550784
Validation loss: 2.5584460209181965

Epoch: 6| Step: 5
Training loss: 2.385116813725988
Validation loss: 2.550401511080891

Epoch: 6| Step: 6
Training loss: 2.8320597048678255
Validation loss: 2.562464782088663

Epoch: 6| Step: 7
Training loss: 2.674394813601491
Validation loss: 2.5567920630280963

Epoch: 6| Step: 8
Training loss: 3.169401811303152
Validation loss: 2.5407053393449215

Epoch: 6| Step: 9
Training loss: 2.820742925625414
Validation loss: 2.584158794959086

Epoch: 6| Step: 10
Training loss: 2.3252537578621713
Validation loss: 2.554489352341061

Epoch: 6| Step: 11
Training loss: 2.5247555529420698
Validation loss: 2.5569351402555287

Epoch: 6| Step: 12
Training loss: 2.559303616190821
Validation loss: 2.5484960276579645

Epoch: 6| Step: 13
Training loss: 2.7325086927493802
Validation loss: 2.5461641274940456

Epoch: 114| Step: 0
Training loss: 2.8215121520701953
Validation loss: 2.5633152300983237

Epoch: 6| Step: 1
Training loss: 2.8284235844086996
Validation loss: 2.561307037651607

Epoch: 6| Step: 2
Training loss: 2.8815948478555238
Validation loss: 2.558694534427185

Epoch: 6| Step: 3
Training loss: 3.6188275633621463
Validation loss: 2.5450240631032885

Epoch: 6| Step: 4
Training loss: 2.645153519009745
Validation loss: 2.57527510561978

Epoch: 6| Step: 5
Training loss: 2.5368858045078664
Validation loss: 2.5351662854837342

Epoch: 6| Step: 6
Training loss: 3.280059307771736
Validation loss: 2.567691240730314

Epoch: 6| Step: 7
Training loss: 2.432798105539063
Validation loss: 2.5614301177328316

Epoch: 6| Step: 8
Training loss: 3.1061091308581372
Validation loss: 2.547732322344958

Epoch: 6| Step: 9
Training loss: 2.7726715319640403
Validation loss: 2.556644294015607

Epoch: 6| Step: 10
Training loss: 2.343852536819556
Validation loss: 2.5427681818755454

Epoch: 6| Step: 11
Training loss: 2.4350706857060156
Validation loss: 2.560583801296123

Epoch: 6| Step: 12
Training loss: 2.5503553703864075
Validation loss: 2.5360524039566097

Epoch: 6| Step: 13
Training loss: 2.3343872233406553
Validation loss: 2.564041992332651

Epoch: 115| Step: 0
Training loss: 1.7162385104156674
Validation loss: 2.566656283075397

Epoch: 6| Step: 1
Training loss: 1.7057702756009612
Validation loss: 2.547090316076886

Epoch: 6| Step: 2
Training loss: 2.770329671033044
Validation loss: 2.5478791331552206

Epoch: 6| Step: 3
Training loss: 2.481454536213672
Validation loss: 2.564858602426744

Epoch: 6| Step: 4
Training loss: 3.0919268852462367
Validation loss: 2.549425038425903

Epoch: 6| Step: 5
Training loss: 3.021821134574373
Validation loss: 2.5566942508643393

Epoch: 6| Step: 6
Training loss: 1.956090887746965
Validation loss: 2.551370924025922

Epoch: 6| Step: 7
Training loss: 2.2321510184002586
Validation loss: 2.5400297043290525

Epoch: 6| Step: 8
Training loss: 3.7379606900747944
Validation loss: 2.555726336504476

Epoch: 6| Step: 9
Training loss: 2.8902843377705283
Validation loss: 2.542908561967992

Epoch: 6| Step: 10
Training loss: 3.759731635398309
Validation loss: 2.5880591939307522

Epoch: 6| Step: 11
Training loss: 3.2306198951945064
Validation loss: 2.5722887032527573

Epoch: 6| Step: 12
Training loss: 2.6689320915332986
Validation loss: 2.5601597095397173

Epoch: 6| Step: 13
Training loss: 2.496051913345107
Validation loss: 2.5665474328066926

Epoch: 116| Step: 0
Training loss: 2.6262552802183947
Validation loss: 2.532895045735024

Epoch: 6| Step: 1
Training loss: 2.937672549110663
Validation loss: 2.5497888318783044

Epoch: 6| Step: 2
Training loss: 3.2627222036642487
Validation loss: 2.5730035611168223

Epoch: 6| Step: 3
Training loss: 2.4449246132428946
Validation loss: 2.539482555745108

Epoch: 6| Step: 4
Training loss: 2.2079103052676703
Validation loss: 2.5524814957268807

Epoch: 6| Step: 5
Training loss: 2.9400448428516386
Validation loss: 2.530994969095175

Epoch: 6| Step: 6
Training loss: 2.031504688434979
Validation loss: 2.546398641465009

Epoch: 6| Step: 7
Training loss: 3.200442498130202
Validation loss: 2.5670836916798203

Epoch: 6| Step: 8
Training loss: 3.1243080899055737
Validation loss: 2.5588344465455206

Epoch: 6| Step: 9
Training loss: 3.3449040498072575
Validation loss: 2.5739333786186345

Epoch: 6| Step: 10
Training loss: 2.1114141709599674
Validation loss: 2.546067183285983

Epoch: 6| Step: 11
Training loss: 2.965217818031927
Validation loss: 2.553603505133323

Epoch: 6| Step: 12
Training loss: 2.8616460734185347
Validation loss: 2.5583489022905708

Epoch: 6| Step: 13
Training loss: 2.198948899511945
Validation loss: 2.5558181322466633

Epoch: 117| Step: 0
Training loss: 3.1348220582439805
Validation loss: 2.561484537078718

Epoch: 6| Step: 1
Training loss: 2.666773873399412
Validation loss: 2.5794647812523452

Epoch: 6| Step: 2
Training loss: 1.9521251713338093
Validation loss: 2.5640387928315604

Epoch: 6| Step: 3
Training loss: 2.8709306527867144
Validation loss: 2.5299892965016837

Epoch: 6| Step: 4
Training loss: 4.073052887780879
Validation loss: 2.5681783328409167

Epoch: 6| Step: 5
Training loss: 2.23296765375007
Validation loss: 2.5724223030920204

Epoch: 6| Step: 6
Training loss: 2.2699033133463895
Validation loss: 2.544725003960909

Epoch: 6| Step: 7
Training loss: 2.2127901005617967
Validation loss: 2.5255297748663184

Epoch: 6| Step: 8
Training loss: 2.876978980917418
Validation loss: 2.5487355524518343

Epoch: 6| Step: 9
Training loss: 2.812095867367762
Validation loss: 2.5365789092990654

Epoch: 6| Step: 10
Training loss: 3.278781507299232
Validation loss: 2.581811959728814

Epoch: 6| Step: 11
Training loss: 2.6024461683116447
Validation loss: 2.5300634437144236

Epoch: 6| Step: 12
Training loss: 2.905775462140348
Validation loss: 2.53850132548787

Epoch: 6| Step: 13
Training loss: 2.635945705543504
Validation loss: 2.581380973372725

Epoch: 118| Step: 0
Training loss: 2.489749493234711
Validation loss: 2.548567815738151

Epoch: 6| Step: 1
Training loss: 2.5081905662318453
Validation loss: 2.550774112186333

Epoch: 6| Step: 2
Training loss: 3.154552947713314
Validation loss: 2.5425030646559432

Epoch: 6| Step: 3
Training loss: 2.292820888346405
Validation loss: 2.570023607564003

Epoch: 6| Step: 4
Training loss: 3.388317395229229
Validation loss: 2.5472175553490146

Epoch: 6| Step: 5
Training loss: 2.966722780047017
Validation loss: 2.534431648615132

Epoch: 6| Step: 6
Training loss: 2.58515185266134
Validation loss: 2.5402556987590796

Epoch: 6| Step: 7
Training loss: 2.451617707213794
Validation loss: 2.5402475605109456

Epoch: 6| Step: 8
Training loss: 2.391401376753549
Validation loss: 2.56277218065214

Epoch: 6| Step: 9
Training loss: 2.9395381268855933
Validation loss: 2.5390911161894194

Epoch: 6| Step: 10
Training loss: 2.8137205230646636
Validation loss: 2.5339923609289925

Epoch: 6| Step: 11
Training loss: 2.805282402170326
Validation loss: 2.5620962875894944

Epoch: 6| Step: 12
Training loss: 3.047750181047761
Validation loss: 2.5429682348460103

Epoch: 6| Step: 13
Training loss: 3.6029653733850293
Validation loss: 2.560223906903467

Epoch: 119| Step: 0
Training loss: 2.9482549646232736
Validation loss: 2.5521632175528954

Epoch: 6| Step: 1
Training loss: 1.7936897241121437
Validation loss: 2.560968381015345

Epoch: 6| Step: 2
Training loss: 2.1429690036641413
Validation loss: 2.5244291421918237

Epoch: 6| Step: 3
Training loss: 2.477171428922319
Validation loss: 2.5564397085253026

Epoch: 6| Step: 4
Training loss: 2.84999990630568
Validation loss: 2.558813378962474

Epoch: 6| Step: 5
Training loss: 2.8867260180473457
Validation loss: 2.593282798600335

Epoch: 6| Step: 6
Training loss: 2.755228187955818
Validation loss: 2.5243957725784725

Epoch: 6| Step: 7
Training loss: 3.046360852803818
Validation loss: 2.5370652939234897

Epoch: 6| Step: 8
Training loss: 2.593957639908636
Validation loss: 2.5724222472831912

Epoch: 6| Step: 9
Training loss: 3.216333167093864
Validation loss: 2.506605003094732

Epoch: 6| Step: 10
Training loss: 2.996854086316658
Validation loss: 2.547509720355154

Epoch: 6| Step: 11
Training loss: 3.259089158015254
Validation loss: 2.55269049946891

Epoch: 6| Step: 12
Training loss: 2.4341424167378043
Validation loss: 2.587997478029001

Epoch: 6| Step: 13
Training loss: 3.096544179174045
Validation loss: 2.565358898922908

Epoch: 120| Step: 0
Training loss: 2.155687894669554
Validation loss: 2.5367189820771303

Epoch: 6| Step: 1
Training loss: 2.805001243958223
Validation loss: 2.546404853235299

Epoch: 6| Step: 2
Training loss: 2.8040301474394
Validation loss: 2.5218590009408803

Epoch: 6| Step: 3
Training loss: 2.735324716487325
Validation loss: 2.5632721942745236

Epoch: 6| Step: 4
Training loss: 2.5555093825587303
Validation loss: 2.546021004822193

Epoch: 6| Step: 5
Training loss: 3.060190692519824
Validation loss: 2.5627852320401856

Epoch: 6| Step: 6
Training loss: 2.791949063341977
Validation loss: 2.5325453722747544

Epoch: 6| Step: 7
Training loss: 3.467500341259995
Validation loss: 2.5464533216382574

Epoch: 6| Step: 8
Training loss: 2.9731172261869214
Validation loss: 2.569259587978745

Epoch: 6| Step: 9
Training loss: 2.537310280308092
Validation loss: 2.5631754915527503

Epoch: 6| Step: 10
Training loss: 2.286203102227313
Validation loss: 2.5764688262849034

Epoch: 6| Step: 11
Training loss: 3.0756140987371263
Validation loss: 2.5212055768095456

Epoch: 6| Step: 12
Training loss: 2.3336018907311136
Validation loss: 2.568248547597789

Epoch: 6| Step: 13
Training loss: 3.3455962316002004
Validation loss: 2.5395143239107796

Epoch: 121| Step: 0
Training loss: 3.019684742015648
Validation loss: 2.5563723063153665

Epoch: 6| Step: 1
Training loss: 2.4377980172321587
Validation loss: 2.560682697310241

Epoch: 6| Step: 2
Training loss: 2.8966769812268223
Validation loss: 2.5368293881106805

Epoch: 6| Step: 3
Training loss: 2.4267533914383774
Validation loss: 2.553353751134201

Epoch: 6| Step: 4
Training loss: 2.2775488314538905
Validation loss: 2.5912031767896884

Epoch: 6| Step: 5
Training loss: 2.8493048104462306
Validation loss: 2.5726105074956394

Epoch: 6| Step: 6
Training loss: 2.798673509691489
Validation loss: 2.5579970608940603

Epoch: 6| Step: 7
Training loss: 3.2229422517503594
Validation loss: 2.5410923146656192

Epoch: 6| Step: 8
Training loss: 2.825939872830977
Validation loss: 2.5754713315853923

Epoch: 6| Step: 9
Training loss: 3.1087572260436347
Validation loss: 2.5639466634846855

Epoch: 6| Step: 10
Training loss: 2.942901839024003
Validation loss: 2.5513235187033967

Epoch: 6| Step: 11
Training loss: 3.0914189968660946
Validation loss: 2.57796108088937

Epoch: 6| Step: 12
Training loss: 2.440026172435035
Validation loss: 2.5454315316650544

Epoch: 6| Step: 13
Training loss: 2.3628239969580016
Validation loss: 2.5501982563778327

Epoch: 122| Step: 0
Training loss: 2.9872283875921224
Validation loss: 2.548541740296051

Epoch: 6| Step: 1
Training loss: 2.7115468156709817
Validation loss: 2.5492357478056347

Epoch: 6| Step: 2
Training loss: 3.1136189544434045
Validation loss: 2.556202515308175

Epoch: 6| Step: 3
Training loss: 2.030874951290586
Validation loss: 2.559221838038932

Epoch: 6| Step: 4
Training loss: 2.823338963826888
Validation loss: 2.571905680212166

Epoch: 6| Step: 5
Training loss: 2.640299398900155
Validation loss: 2.5669157746987787

Epoch: 6| Step: 6
Training loss: 2.7479340856162473
Validation loss: 2.5334988530537594

Epoch: 6| Step: 7
Training loss: 2.8332385627006116
Validation loss: 2.546145856876933

Epoch: 6| Step: 8
Training loss: 3.1548721780894717
Validation loss: 2.5643822719762013

Epoch: 6| Step: 9
Training loss: 3.441731293620313
Validation loss: 2.577311593639784

Epoch: 6| Step: 10
Training loss: 2.1386304041355917
Validation loss: 2.5434324994935187

Epoch: 6| Step: 11
Training loss: 2.4440491554199326
Validation loss: 2.560449710401999

Epoch: 6| Step: 12
Training loss: 2.7409285130438814
Validation loss: 2.559449814351772

Epoch: 6| Step: 13
Training loss: 2.9205701229622356
Validation loss: 2.512220888731315

Epoch: 123| Step: 0
Training loss: 2.347938152531969
Validation loss: 2.5676970784998705

Epoch: 6| Step: 1
Training loss: 2.501561535484228
Validation loss: 2.5635958223586632

Epoch: 6| Step: 2
Training loss: 3.362039334531718
Validation loss: 2.5501825791266626

Epoch: 6| Step: 3
Training loss: 2.641918971370591
Validation loss: 2.5369338605833556

Epoch: 6| Step: 4
Training loss: 2.405101254209325
Validation loss: 2.5301523597470297

Epoch: 6| Step: 5
Training loss: 2.1048020137001533
Validation loss: 2.552224268149458

Epoch: 6| Step: 6
Training loss: 2.768666120167063
Validation loss: 2.5731062988396163

Epoch: 6| Step: 7
Training loss: 3.6220011968078825
Validation loss: 2.542840121579365

Epoch: 6| Step: 8
Training loss: 3.1157467985689995
Validation loss: 2.5352985966491794

Epoch: 6| Step: 9
Training loss: 2.8827729674732674
Validation loss: 2.558372029925105

Epoch: 6| Step: 10
Training loss: 2.632905590551033
Validation loss: 2.523847057993356

Epoch: 6| Step: 11
Training loss: 2.9087812004170086
Validation loss: 2.5626445242291283

Epoch: 6| Step: 12
Training loss: 2.199387430392773
Validation loss: 2.5298138373526635

Epoch: 6| Step: 13
Training loss: 2.9345857489714637
Validation loss: 2.555113116070708

Epoch: 124| Step: 0
Training loss: 2.514312591347153
Validation loss: 2.580045478116631

Epoch: 6| Step: 1
Training loss: 2.576750972926381
Validation loss: 2.5416524924682045

Epoch: 6| Step: 2
Training loss: 2.202831708716367
Validation loss: 2.552796305718116

Epoch: 6| Step: 3
Training loss: 3.133590183146655
Validation loss: 2.556340766701531

Epoch: 6| Step: 4
Training loss: 2.882629057880905
Validation loss: 2.570001757872421

Epoch: 6| Step: 5
Training loss: 2.2335667782329516
Validation loss: 2.5634552450470522

Epoch: 6| Step: 6
Training loss: 1.6524372480195968
Validation loss: 2.5370525482671367

Epoch: 6| Step: 7
Training loss: 3.2291760516286674
Validation loss: 2.5655007029578365

Epoch: 6| Step: 8
Training loss: 3.1743208752107637
Validation loss: 2.5799832773870985

Epoch: 6| Step: 9
Training loss: 2.966688223199714
Validation loss: 2.553087246904983

Epoch: 6| Step: 10
Training loss: 2.54939828393043
Validation loss: 2.504103774839349

Epoch: 6| Step: 11
Training loss: 3.2348794589807737
Validation loss: 2.5349554434921107

Epoch: 6| Step: 12
Training loss: 3.494396765389884
Validation loss: 2.5278469713884073

Epoch: 6| Step: 13
Training loss: 1.669586397794471
Validation loss: 2.5486327225333243

Epoch: 125| Step: 0
Training loss: 2.5645656168801163
Validation loss: 2.577334749055844

Epoch: 6| Step: 1
Training loss: 2.8845993334983864
Validation loss: 2.5568398041202944

Epoch: 6| Step: 2
Training loss: 2.5183291857534
Validation loss: 2.5485656047377114

Epoch: 6| Step: 3
Training loss: 2.7345073558926756
Validation loss: 2.5461667624553974

Epoch: 6| Step: 4
Training loss: 2.738571869886866
Validation loss: 2.5334826636572156

Epoch: 6| Step: 5
Training loss: 3.127437556411077
Validation loss: 2.5573534462554757

Epoch: 6| Step: 6
Training loss: 2.9282177302802697
Validation loss: 2.5376536115665767

Epoch: 6| Step: 7
Training loss: 2.4441137330958265
Validation loss: 2.5620316748522756

Epoch: 6| Step: 8
Training loss: 2.584958908374251
Validation loss: 2.5198269822406605

Epoch: 6| Step: 9
Training loss: 3.071530787139008
Validation loss: 2.550245856525994

Epoch: 6| Step: 10
Training loss: 3.059922983035582
Validation loss: 2.522546459816416

Epoch: 6| Step: 11
Training loss: 2.1058986699070448
Validation loss: 2.5421352717701247

Epoch: 6| Step: 12
Training loss: 3.0433076760365436
Validation loss: 2.5288298296936227

Epoch: 6| Step: 13
Training loss: 2.90485717868825
Validation loss: 2.5435675918119185

Epoch: 126| Step: 0
Training loss: 2.220077439924994
Validation loss: 2.519550079913825

Epoch: 6| Step: 1
Training loss: 2.609536719878649
Validation loss: 2.5415091621284924

Epoch: 6| Step: 2
Training loss: 2.36311478462019
Validation loss: 2.525087987730701

Epoch: 6| Step: 3
Training loss: 2.4503813544106676
Validation loss: 2.5438487185917515

Epoch: 6| Step: 4
Training loss: 2.1182633372742017
Validation loss: 2.5957795776949077

Epoch: 6| Step: 5
Training loss: 3.258505621710472
Validation loss: 2.555241902722995

Epoch: 6| Step: 6
Training loss: 3.126587273891808
Validation loss: 2.5710591531079667

Epoch: 6| Step: 7
Training loss: 3.457252210893999
Validation loss: 2.5590695665552765

Epoch: 6| Step: 8
Training loss: 2.8096488063907
Validation loss: 2.5604386010502846

Epoch: 6| Step: 9
Training loss: 2.9573074675421505
Validation loss: 2.562868293409477

Epoch: 6| Step: 10
Training loss: 2.19368458185714
Validation loss: 2.5661620807781262

Epoch: 6| Step: 11
Training loss: 3.1629549325005084
Validation loss: 2.547253907468605

Epoch: 6| Step: 12
Training loss: 2.881996928481425
Validation loss: 2.5390399426388264

Epoch: 6| Step: 13
Training loss: 2.865792166223893
Validation loss: 2.574663362880112

Epoch: 127| Step: 0
Training loss: 2.5257304730725765
Validation loss: 2.5701072190240835

Epoch: 6| Step: 1
Training loss: 2.243966277598391
Validation loss: 2.5305143624504387

Epoch: 6| Step: 2
Training loss: 2.198692245201981
Validation loss: 2.5391300103462906

Epoch: 6| Step: 3
Training loss: 2.3236447434905827
Validation loss: 2.554616552243736

Epoch: 6| Step: 4
Training loss: 3.2277835632143974
Validation loss: 2.542077321997521

Epoch: 6| Step: 5
Training loss: 3.0886692751961204
Validation loss: 2.5312491421613883

Epoch: 6| Step: 6
Training loss: 3.1181041163396825
Validation loss: 2.575461682097715

Epoch: 6| Step: 7
Training loss: 3.5292490463520365
Validation loss: 2.556858559806811

Epoch: 6| Step: 8
Training loss: 2.5953403790634133
Validation loss: 2.5607500100922755

Epoch: 6| Step: 9
Training loss: 2.8370481896003716
Validation loss: 2.5434741192271035

Epoch: 6| Step: 10
Training loss: 2.6714855601830605
Validation loss: 2.559912658188128

Epoch: 6| Step: 11
Training loss: 3.0214272452380184
Validation loss: 2.531043356812752

Epoch: 6| Step: 12
Training loss: 2.2257348379462583
Validation loss: 2.5661067625889973

Epoch: 6| Step: 13
Training loss: 3.000581526025202
Validation loss: 2.5530262882400456

Epoch: 128| Step: 0
Training loss: 3.372354530268107
Validation loss: 2.554304066239993

Epoch: 6| Step: 1
Training loss: 2.1307668412324134
Validation loss: 2.5644471398898623

Epoch: 6| Step: 2
Training loss: 2.971624328117694
Validation loss: 2.5622663954194995

Epoch: 6| Step: 3
Training loss: 2.9983306054666046
Validation loss: 2.5471405458576015

Epoch: 6| Step: 4
Training loss: 2.1757927556992125
Validation loss: 2.5744319315051323

Epoch: 6| Step: 5
Training loss: 2.5416651136883437
Validation loss: 2.564183565259298

Epoch: 6| Step: 6
Training loss: 2.3271617560859963
Validation loss: 2.564589963979881

Epoch: 6| Step: 7
Training loss: 3.0058520777404927
Validation loss: 2.5507837404912537

Epoch: 6| Step: 8
Training loss: 3.3440379081201854
Validation loss: 2.5521616143749672

Epoch: 6| Step: 9
Training loss: 2.547856054159513
Validation loss: 2.5420701920158506

Epoch: 6| Step: 10
Training loss: 2.8515119992317577
Validation loss: 2.565481480832521

Epoch: 6| Step: 11
Training loss: 3.2291674870315656
Validation loss: 2.5593381123172887

Epoch: 6| Step: 12
Training loss: 2.5654026432303585
Validation loss: 2.5480598750016603

Epoch: 6| Step: 13
Training loss: 2.480409636506492
Validation loss: 2.543977622520063

Epoch: 129| Step: 0
Training loss: 2.6098112552549506
Validation loss: 2.5214686371601664

Epoch: 6| Step: 1
Training loss: 2.6092344691644107
Validation loss: 2.546287947593701

Epoch: 6| Step: 2
Training loss: 2.7729076470377163
Validation loss: 2.5583549663004117

Epoch: 6| Step: 3
Training loss: 2.66397210915889
Validation loss: 2.5256136590083664

Epoch: 6| Step: 4
Training loss: 2.838943275715366
Validation loss: 2.5434180797882964

Epoch: 6| Step: 5
Training loss: 3.36513348658985
Validation loss: 2.6205628362029896

Epoch: 6| Step: 6
Training loss: 3.045156140763698
Validation loss: 2.5349205513379527

Epoch: 6| Step: 7
Training loss: 2.449309668306016
Validation loss: 2.5611562299406248

Epoch: 6| Step: 8
Training loss: 2.945679335680859
Validation loss: 2.522063036140986

Epoch: 6| Step: 9
Training loss: 3.3875653925703677
Validation loss: 2.54899165162835

Epoch: 6| Step: 10
Training loss: 3.041813015138732
Validation loss: 2.51821926661469

Epoch: 6| Step: 11
Training loss: 2.14238683216957
Validation loss: 2.5694911120728547

Epoch: 6| Step: 12
Training loss: 2.1882397082198017
Validation loss: 2.5390594608613686

Epoch: 6| Step: 13
Training loss: 2.3931637915204287
Validation loss: 2.580698780366729

Epoch: 130| Step: 0
Training loss: 2.4962679663380745
Validation loss: 2.5378802590198877

Epoch: 6| Step: 1
Training loss: 2.4711938664684703
Validation loss: 2.5394791546935576

Epoch: 6| Step: 2
Training loss: 3.689666241073848
Validation loss: 2.5659972785707197

Epoch: 6| Step: 3
Training loss: 3.0489616877975405
Validation loss: 2.556831733698359

Epoch: 6| Step: 4
Training loss: 2.4719445528645103
Validation loss: 2.5353601311989284

Epoch: 6| Step: 5
Training loss: 2.4085060541679915
Validation loss: 2.536081217365841

Epoch: 6| Step: 6
Training loss: 2.79126197576623
Validation loss: 2.5507505880141528

Epoch: 6| Step: 7
Training loss: 3.344487189198939
Validation loss: 2.5522379952419967

Epoch: 6| Step: 8
Training loss: 2.6939600108123276
Validation loss: 2.5224670283296144

Epoch: 6| Step: 9
Training loss: 2.7750602165768297
Validation loss: 2.5509738769925128

Epoch: 6| Step: 10
Training loss: 2.4495170934781116
Validation loss: 2.574249875381255

Epoch: 6| Step: 11
Training loss: 2.6923193192492936
Validation loss: 2.557979810861965

Epoch: 6| Step: 12
Training loss: 2.4753813709858385
Validation loss: 2.5518868262500054

Epoch: 6| Step: 13
Training loss: 2.9108744919039684
Validation loss: 2.5469978625494565

Epoch: 131| Step: 0
Training loss: 3.1992704692381597
Validation loss: 2.548846959756528

Epoch: 6| Step: 1
Training loss: 2.5907669378218565
Validation loss: 2.5488077723230713

Epoch: 6| Step: 2
Training loss: 2.6690082005260116
Validation loss: 2.5677462821728256

Epoch: 6| Step: 3
Training loss: 2.692387417252138
Validation loss: 2.545789458975591

Epoch: 6| Step: 4
Training loss: 3.2889830518536973
Validation loss: 2.588977025328734

Epoch: 6| Step: 5
Training loss: 2.680289064731642
Validation loss: 2.5630002317631213

Epoch: 6| Step: 6
Training loss: 2.5845655968345667
Validation loss: 2.547339301382186

Epoch: 6| Step: 7
Training loss: 2.5862717887805013
Validation loss: 2.5998302367220356

Epoch: 6| Step: 8
Training loss: 3.483825640286687
Validation loss: 2.531417810733242

Epoch: 6| Step: 9
Training loss: 2.4734701109885306
Validation loss: 2.5733480777245816

Epoch: 6| Step: 10
Training loss: 2.950257700639574
Validation loss: 2.525864530965668

Epoch: 6| Step: 11
Training loss: 2.5921026306791237
Validation loss: 2.550661483445709

Epoch: 6| Step: 12
Training loss: 2.0271708684867944
Validation loss: 2.548677588794125

Epoch: 6| Step: 13
Training loss: 2.496357935146451
Validation loss: 2.5421198453173215

Epoch: 132| Step: 0
Training loss: 2.3374073928195154
Validation loss: 2.5911443822350315

Epoch: 6| Step: 1
Training loss: 2.882972113266374
Validation loss: 2.572180755127308

Epoch: 6| Step: 2
Training loss: 2.75855752969243
Validation loss: 2.560302189039907

Epoch: 6| Step: 3
Training loss: 2.3043603697256234
Validation loss: 2.528761075177423

Epoch: 6| Step: 4
Training loss: 2.412677058704627
Validation loss: 2.5311375001381378

Epoch: 6| Step: 5
Training loss: 2.1890643384600375
Validation loss: 2.5297385883506287

Epoch: 6| Step: 6
Training loss: 3.4024107408552697
Validation loss: 2.52289927807968

Epoch: 6| Step: 7
Training loss: 2.513544015663294
Validation loss: 2.5236526072984797

Epoch: 6| Step: 8
Training loss: 2.540100636628726
Validation loss: 2.541745577158299

Epoch: 6| Step: 9
Training loss: 3.2431736193306198
Validation loss: 2.5542775364835215

Epoch: 6| Step: 10
Training loss: 3.7257834205933076
Validation loss: 2.5504413922244433

Epoch: 6| Step: 11
Training loss: 2.946400084915181
Validation loss: 2.5742365723991236

Epoch: 6| Step: 12
Training loss: 1.761881548005677
Validation loss: 2.548854935770291

Epoch: 6| Step: 13
Training loss: 3.3936316875257124
Validation loss: 2.571139166321638

Epoch: 133| Step: 0
Training loss: 2.161593574674475
Validation loss: 2.532125818028372

Epoch: 6| Step: 1
Training loss: 3.189235140189407
Validation loss: 2.585202338542936

Epoch: 6| Step: 2
Training loss: 2.2967634109067334
Validation loss: 2.5768335373661935

Epoch: 6| Step: 3
Training loss: 2.7493150898518985
Validation loss: 2.5483189705859672

Epoch: 6| Step: 4
Training loss: 2.3459090397364695
Validation loss: 2.542913158132899

Epoch: 6| Step: 5
Training loss: 2.2306995172257342
Validation loss: 2.5740047241810617

Epoch: 6| Step: 6
Training loss: 3.4477840217514397
Validation loss: 2.5502713134094

Epoch: 6| Step: 7
Training loss: 3.177324996679044
Validation loss: 2.5358124924595247

Epoch: 6| Step: 8
Training loss: 2.7652423831043986
Validation loss: 2.5692796758716745

Epoch: 6| Step: 9
Training loss: 3.2058788835822742
Validation loss: 2.5577514153635215

Epoch: 6| Step: 10
Training loss: 2.7872689087192395
Validation loss: 2.594848721328713

Epoch: 6| Step: 11
Training loss: 2.647329363056332
Validation loss: 2.561940787199383

Epoch: 6| Step: 12
Training loss: 2.989367717627975
Validation loss: 2.5369600907019247

Epoch: 6| Step: 13
Training loss: 1.6989773984486825
Validation loss: 2.5570307074411582

Epoch: 134| Step: 0
Training loss: 2.1544228151226026
Validation loss: 2.5589548053630593

Epoch: 6| Step: 1
Training loss: 2.5929005162478185
Validation loss: 2.5499642054542635

Epoch: 6| Step: 2
Training loss: 3.3846513714577804
Validation loss: 2.554342597277319

Epoch: 6| Step: 3
Training loss: 2.823301216387187
Validation loss: 2.5515459125575615

Epoch: 6| Step: 4
Training loss: 2.7483621401536906
Validation loss: 2.568988104637504

Epoch: 6| Step: 5
Training loss: 2.7546519034298735
Validation loss: 2.549943815095324

Epoch: 6| Step: 6
Training loss: 3.749052436638951
Validation loss: 2.5788308528160533

Epoch: 6| Step: 7
Training loss: 2.5147496945632883
Validation loss: 2.563861935198772

Epoch: 6| Step: 8
Training loss: 2.635617174404251
Validation loss: 2.550310352701088

Epoch: 6| Step: 9
Training loss: 2.029249291692791
Validation loss: 2.5459889543422913

Epoch: 6| Step: 10
Training loss: 3.030283980454186
Validation loss: 2.5213708141002784

Epoch: 6| Step: 11
Training loss: 2.9386894577455682
Validation loss: 2.5235345338531765

Epoch: 6| Step: 12
Training loss: 1.9910959881300936
Validation loss: 2.5485332895101185

Epoch: 6| Step: 13
Training loss: 3.1528273049682904
Validation loss: 2.579559289157571

Epoch: 135| Step: 0
Training loss: 2.2881295968879343
Validation loss: 2.526771789690235

Epoch: 6| Step: 1
Training loss: 2.9661526209636633
Validation loss: 2.5517350709891367

Epoch: 6| Step: 2
Training loss: 2.91844424621018
Validation loss: 2.5670082428998455

Epoch: 6| Step: 3
Training loss: 2.7254517487009506
Validation loss: 2.5473515497361157

Epoch: 6| Step: 4
Training loss: 2.8915186145123273
Validation loss: 2.5792228819701086

Epoch: 6| Step: 5
Training loss: 2.7170065189433594
Validation loss: 2.5459765942080756

Epoch: 6| Step: 6
Training loss: 3.039765029158523
Validation loss: 2.5516810957596037

Epoch: 6| Step: 7
Training loss: 2.552204383522408
Validation loss: 2.5382817115253404

Epoch: 6| Step: 8
Training loss: 3.1386126243824064
Validation loss: 2.5429354613613366

Epoch: 6| Step: 9
Training loss: 3.3188456088732283
Validation loss: 2.561478851290495

Epoch: 6| Step: 10
Training loss: 2.4402411282322114
Validation loss: 2.570680390170627

Epoch: 6| Step: 11
Training loss: 2.336053851747986
Validation loss: 2.5741792835430233

Epoch: 6| Step: 12
Training loss: 2.5647569347123857
Validation loss: 2.578588857279025

Epoch: 6| Step: 13
Training loss: 2.5014519289968926
Validation loss: 2.5482494863701035

Epoch: 136| Step: 0
Training loss: 3.330820344338578
Validation loss: 2.5741766872147296

Epoch: 6| Step: 1
Training loss: 2.6867246174616524
Validation loss: 2.5604956126248664

Epoch: 6| Step: 2
Training loss: 3.4184369099023053
Validation loss: 2.5824653849169854

Epoch: 6| Step: 3
Training loss: 2.3892462251223656
Validation loss: 2.559055845052593

Epoch: 6| Step: 4
Training loss: 3.088593472351318
Validation loss: 2.554399044383231

Epoch: 6| Step: 5
Training loss: 2.6688164946158426
Validation loss: 2.5332472930161316

Epoch: 6| Step: 6
Training loss: 2.364715191585848
Validation loss: 2.527789301043841

Epoch: 6| Step: 7
Training loss: 2.8435538088015506
Validation loss: 2.528393368988092

Epoch: 6| Step: 8
Training loss: 2.6626739910746418
Validation loss: 2.577770137385103

Epoch: 6| Step: 9
Training loss: 3.1654381292982237
Validation loss: 2.5378790953264163

Epoch: 6| Step: 10
Training loss: 2.559372645040507
Validation loss: 2.5420250175201367

Epoch: 6| Step: 11
Training loss: 2.599598552816035
Validation loss: 2.569305860142457

Epoch: 6| Step: 12
Training loss: 2.4329321682995757
Validation loss: 2.5379489887191453

Epoch: 6| Step: 13
Training loss: 2.374152182787812
Validation loss: 2.5586141400596003

Epoch: 137| Step: 0
Training loss: 2.981084957392754
Validation loss: 2.5469218016450714

Epoch: 6| Step: 1
Training loss: 2.8250977558337853
Validation loss: 2.5483530611021608

Epoch: 6| Step: 2
Training loss: 2.61653379560558
Validation loss: 2.5394713127740176

Epoch: 6| Step: 3
Training loss: 3.015218282360865
Validation loss: 2.5684327009846144

Epoch: 6| Step: 4
Training loss: 2.7636116587410737
Validation loss: 2.5280527963633723

Epoch: 6| Step: 5
Training loss: 2.531964048290081
Validation loss: 2.5626892722255787

Epoch: 6| Step: 6
Training loss: 2.06013931655145
Validation loss: 2.558602369955097

Epoch: 6| Step: 7
Training loss: 3.0260711160738
Validation loss: 2.5471734524395693

Epoch: 6| Step: 8
Training loss: 3.1607310900422343
Validation loss: 2.5482061065668087

Epoch: 6| Step: 9
Training loss: 2.953395286180071
Validation loss: 2.546899798053781

Epoch: 6| Step: 10
Training loss: 2.3560841833401445
Validation loss: 2.5440350800731313

Epoch: 6| Step: 11
Training loss: 3.21487000316779
Validation loss: 2.5655667571807617

Epoch: 6| Step: 12
Training loss: 2.5229317834486817
Validation loss: 2.5322789580031393

Epoch: 6| Step: 13
Training loss: 1.8918059892925192
Validation loss: 2.5751185453506023

Epoch: 138| Step: 0
Training loss: 2.751387852807588
Validation loss: 2.5618644254296523

Epoch: 6| Step: 1
Training loss: 2.4474193527759573
Validation loss: 2.54748445324517

Epoch: 6| Step: 2
Training loss: 2.4136795678473764
Validation loss: 2.551534231421782

Epoch: 6| Step: 3
Training loss: 2.299781672854589
Validation loss: 2.5839953479011912

Epoch: 6| Step: 4
Training loss: 2.889212928433139
Validation loss: 2.539739450684365

Epoch: 6| Step: 5
Training loss: 2.981293690359316
Validation loss: 2.5771503812576197

Epoch: 6| Step: 6
Training loss: 3.349460182537523
Validation loss: 2.54754719990968

Epoch: 6| Step: 7
Training loss: 3.3434587868771315
Validation loss: 2.567594504750054

Epoch: 6| Step: 8
Training loss: 2.1310558420827914
Validation loss: 2.5551440698463668

Epoch: 6| Step: 9
Training loss: 2.3505520598280554
Validation loss: 2.5490548610360713

Epoch: 6| Step: 10
Training loss: 3.1170178513026445
Validation loss: 2.5579424861728848

Epoch: 6| Step: 11
Training loss: 3.1120866615957574
Validation loss: 2.5328601682137353

Epoch: 6| Step: 12
Training loss: 2.5674114145896323
Validation loss: 2.588656791193048

Epoch: 6| Step: 13
Training loss: 2.8281984267002547
Validation loss: 2.5600308893904433

Epoch: 139| Step: 0
Training loss: 2.500100229161477
Validation loss: 2.57033007420297

Epoch: 6| Step: 1
Training loss: 2.9848910379889904
Validation loss: 2.5298450307544718

Epoch: 6| Step: 2
Training loss: 1.992719870848157
Validation loss: 2.546787727773715

Epoch: 6| Step: 3
Training loss: 2.818645798476294
Validation loss: 2.551573887384339

Epoch: 6| Step: 4
Training loss: 2.031382160288934
Validation loss: 2.5757642958734737

Epoch: 6| Step: 5
Training loss: 2.3717164882521207
Validation loss: 2.539741094004747

Epoch: 6| Step: 6
Training loss: 2.65863683835473
Validation loss: 2.515455918619249

Epoch: 6| Step: 7
Training loss: 2.614428805664617
Validation loss: 2.600365870498209

Epoch: 6| Step: 8
Training loss: 3.3709375869101685
Validation loss: 2.5770737539193536

Epoch: 6| Step: 9
Training loss: 3.898194819600798
Validation loss: 2.5224914697570977

Epoch: 6| Step: 10
Training loss: 2.5454479502307614
Validation loss: 2.5523436931896604

Epoch: 6| Step: 11
Training loss: 2.7421817616459725
Validation loss: 2.5460425769946897

Epoch: 6| Step: 12
Training loss: 2.594410272228456
Validation loss: 2.5301680719438644

Epoch: 6| Step: 13
Training loss: 2.6859449278865806
Validation loss: 2.535784582345223

Epoch: 140| Step: 0
Training loss: 2.585883194736388
Validation loss: 2.540902621212128

Epoch: 6| Step: 1
Training loss: 2.787314329250281
Validation loss: 2.551281654724372

Epoch: 6| Step: 2
Training loss: 2.7389471574903848
Validation loss: 2.5357743167809144

Epoch: 6| Step: 3
Training loss: 2.8157653502647313
Validation loss: 2.53214437407052

Epoch: 6| Step: 4
Training loss: 2.2304977174604854
Validation loss: 2.545409407424869

Epoch: 6| Step: 5
Training loss: 3.400775114229619
Validation loss: 2.505514281803425

Epoch: 6| Step: 6
Training loss: 2.5190180292760167
Validation loss: 2.5528015097260512

Epoch: 6| Step: 7
Training loss: 3.051905465178073
Validation loss: 2.5502439475510705

Epoch: 6| Step: 8
Training loss: 3.3594207050851614
Validation loss: 2.544921808514547

Epoch: 6| Step: 9
Training loss: 2.7757508851443053
Validation loss: 2.5922116262735857

Epoch: 6| Step: 10
Training loss: 2.3815257115582926
Validation loss: 2.563786223616391

Epoch: 6| Step: 11
Training loss: 1.783568763641439
Validation loss: 2.520156781428416

Epoch: 6| Step: 12
Training loss: 2.8560244414835743
Validation loss: 2.5552859581743417

Epoch: 6| Step: 13
Training loss: 2.9079853742354995
Validation loss: 2.534060531408114

Epoch: 141| Step: 0
Training loss: 2.124735423054117
Validation loss: 2.52466898441644

Epoch: 6| Step: 1
Training loss: 2.7541913256981667
Validation loss: 2.5416201801241507

Epoch: 6| Step: 2
Training loss: 3.4631051536587583
Validation loss: 2.554079354008032

Epoch: 6| Step: 3
Training loss: 3.109607937009362
Validation loss: 2.5536713026768476

Epoch: 6| Step: 4
Training loss: 1.506530691245064
Validation loss: 2.562322810039847

Epoch: 6| Step: 5
Training loss: 2.662195799020154
Validation loss: 2.5567903213748093

Epoch: 6| Step: 6
Training loss: 2.7209532130549907
Validation loss: 2.561368665008235

Epoch: 6| Step: 7
Training loss: 3.130199836469766
Validation loss: 2.548141125521575

Epoch: 6| Step: 8
Training loss: 2.3285147321520476
Validation loss: 2.5616039617367865

Epoch: 6| Step: 9
Training loss: 2.7774544866834714
Validation loss: 2.555365846277846

Epoch: 6| Step: 10
Training loss: 2.488392586365623
Validation loss: 2.5583641096356744

Epoch: 6| Step: 11
Training loss: 3.196374394961597
Validation loss: 2.5573120052888147

Epoch: 6| Step: 12
Training loss: 2.752038893435899
Validation loss: 2.532091310596498

Epoch: 6| Step: 13
Training loss: 2.9116836124036958
Validation loss: 2.5607104712054176

Epoch: 142| Step: 0
Training loss: 2.8113025235315208
Validation loss: 2.558765476315722

Epoch: 6| Step: 1
Training loss: 2.4368617860641755
Validation loss: 2.558776677592211

Epoch: 6| Step: 2
Training loss: 3.2760654725552647
Validation loss: 2.524962948308285

Epoch: 6| Step: 3
Training loss: 2.6067231917370597
Validation loss: 2.5502778002298006

Epoch: 6| Step: 4
Training loss: 2.2803501810560123
Validation loss: 2.574119330298586

Epoch: 6| Step: 5
Training loss: 3.3765478470116754
Validation loss: 2.5263073558942986

Epoch: 6| Step: 6
Training loss: 3.243957183630591
Validation loss: 2.5148354097972256

Epoch: 6| Step: 7
Training loss: 2.896662001201822
Validation loss: 2.5667334436491065

Epoch: 6| Step: 8
Training loss: 2.31058649849795
Validation loss: 2.5669433343422496

Epoch: 6| Step: 9
Training loss: 2.9510574773079226
Validation loss: 2.529391212048675

Epoch: 6| Step: 10
Training loss: 2.2767362487719494
Validation loss: 2.517377165357868

Epoch: 6| Step: 11
Training loss: 1.8486561559622965
Validation loss: 2.5718123598736073

Epoch: 6| Step: 12
Training loss: 2.8474343714464823
Validation loss: 2.5646956556630562

Epoch: 6| Step: 13
Training loss: 2.9323664509444436
Validation loss: 2.5691216306398

Epoch: 143| Step: 0
Training loss: 2.6693322647593085
Validation loss: 2.5748076912575826

Epoch: 6| Step: 1
Training loss: 2.895522963177057
Validation loss: 2.554208146112289

Epoch: 6| Step: 2
Training loss: 2.8663102556791586
Validation loss: 2.5804662659445023

Epoch: 6| Step: 3
Training loss: 3.1782088157081683
Validation loss: 2.5309252361603387

Epoch: 6| Step: 4
Training loss: 2.7136145134713163
Validation loss: 2.581185490655933

Epoch: 6| Step: 5
Training loss: 3.107401619395013
Validation loss: 2.5783842889259536

Epoch: 6| Step: 6
Training loss: 1.8768405146166571
Validation loss: 2.553408973123632

Epoch: 6| Step: 7
Training loss: 2.080672344884893
Validation loss: 2.565337610103208

Epoch: 6| Step: 8
Training loss: 2.8272715592793114
Validation loss: 2.569587297763376

Epoch: 6| Step: 9
Training loss: 2.569076844001226
Validation loss: 2.5485665653864547

Epoch: 6| Step: 10
Training loss: 3.1475119922460992
Validation loss: 2.5520074007257967

Epoch: 6| Step: 11
Training loss: 2.9567590384119007
Validation loss: 2.549338982796048

Epoch: 6| Step: 12
Training loss: 2.8313127119179997
Validation loss: 2.5358259818504476

Epoch: 6| Step: 13
Training loss: 2.645982172426586
Validation loss: 2.545838231122518

Epoch: 144| Step: 0
Training loss: 3.087517210877669
Validation loss: 2.535576996349078

Epoch: 6| Step: 1
Training loss: 2.776360575171294
Validation loss: 2.5637829268014958

Epoch: 6| Step: 2
Training loss: 3.243415177251276
Validation loss: 2.572862956277876

Epoch: 6| Step: 3
Training loss: 1.7929621012778414
Validation loss: 2.5594277682178386

Epoch: 6| Step: 4
Training loss: 2.6444359541025646
Validation loss: 2.552590903628333

Epoch: 6| Step: 5
Training loss: 3.0940166319959213
Validation loss: 2.557846622305964

Epoch: 6| Step: 6
Training loss: 3.252340354432004
Validation loss: 2.5765863156879467

Epoch: 6| Step: 7
Training loss: 2.713693059308956
Validation loss: 2.579053084405661

Epoch: 6| Step: 8
Training loss: 2.3619199252594067
Validation loss: 2.570013495720606

Epoch: 6| Step: 9
Training loss: 1.7765409899426845
Validation loss: 2.552538877860431

Epoch: 6| Step: 10
Training loss: 2.6017724488001814
Validation loss: 2.557927477770096

Epoch: 6| Step: 11
Training loss: 2.6862333107097474
Validation loss: 2.551280752876521

Epoch: 6| Step: 12
Training loss: 3.1807708019585887
Validation loss: 2.552889347601619

Epoch: 6| Step: 13
Training loss: 3.070323060772232
Validation loss: 2.575321612139227

Epoch: 145| Step: 0
Training loss: 3.1061277062272534
Validation loss: 2.5551399506911157

Epoch: 6| Step: 1
Training loss: 3.057036060433779
Validation loss: 2.549618495863883

Epoch: 6| Step: 2
Training loss: 2.7133704269960415
Validation loss: 2.5610605494318373

Epoch: 6| Step: 3
Training loss: 2.8842141483707673
Validation loss: 2.569333171643047

Epoch: 6| Step: 4
Training loss: 1.6715717932014347
Validation loss: 2.5339504448303938

Epoch: 6| Step: 5
Training loss: 2.9700179755183878
Validation loss: 2.5761822831033965

Epoch: 6| Step: 6
Training loss: 3.054338127898765
Validation loss: 2.569491732656547

Epoch: 6| Step: 7
Training loss: 2.5623140965459155
Validation loss: 2.538295402920811

Epoch: 6| Step: 8
Training loss: 2.472223855731248
Validation loss: 2.5616992967026317

Epoch: 6| Step: 9
Training loss: 3.1114827588789993
Validation loss: 2.5807413477751053

Epoch: 6| Step: 10
Training loss: 3.099894423378995
Validation loss: 2.5362309415450293

Epoch: 6| Step: 11
Training loss: 1.954208500732229
Validation loss: 2.536263539869502

Epoch: 6| Step: 12
Training loss: 2.4071498030675116
Validation loss: 2.5426872516868926

Epoch: 6| Step: 13
Training loss: 3.0730190626422726
Validation loss: 2.5413765952738525

Epoch: 146| Step: 0
Training loss: 2.5458873869989365
Validation loss: 2.5163676977554426

Epoch: 6| Step: 1
Training loss: 2.581270091276512
Validation loss: 2.55650316598352

Epoch: 6| Step: 2
Training loss: 2.991923905756447
Validation loss: 2.561143547618909

Epoch: 6| Step: 3
Training loss: 3.3651068470104892
Validation loss: 2.527615514326157

Epoch: 6| Step: 4
Training loss: 2.4906417214324095
Validation loss: 2.5407259198835743

Epoch: 6| Step: 5
Training loss: 2.621853895864017
Validation loss: 2.515903682427535

Epoch: 6| Step: 6
Training loss: 2.082640596294166
Validation loss: 2.5366039116008157

Epoch: 6| Step: 7
Training loss: 2.4730813382690386
Validation loss: 2.569529461269438

Epoch: 6| Step: 8
Training loss: 2.588563904900205
Validation loss: 2.546566642868689

Epoch: 6| Step: 9
Training loss: 3.1828480601957727
Validation loss: 2.5321770169045696

Epoch: 6| Step: 10
Training loss: 3.4884466493017223
Validation loss: 2.5360492818567018

Epoch: 6| Step: 11
Training loss: 1.4814815227632163
Validation loss: 2.572388755787723

Epoch: 6| Step: 12
Training loss: 3.277849015217898
Validation loss: 2.536160214375238

Epoch: 6| Step: 13
Training loss: 2.7738807001733052
Validation loss: 2.5553231089763244

Epoch: 147| Step: 0
Training loss: 3.4361200510530803
Validation loss: 2.521150383113194

Epoch: 6| Step: 1
Training loss: 2.467666291543919
Validation loss: 2.516812392249788

Epoch: 6| Step: 2
Training loss: 2.784767070186099
Validation loss: 2.571842217527071

Epoch: 6| Step: 3
Training loss: 2.604630228109761
Validation loss: 2.5390753077585497

Epoch: 6| Step: 4
Training loss: 2.2322930726868555
Validation loss: 2.5346099903587915

Epoch: 6| Step: 5
Training loss: 1.9773385556144114
Validation loss: 2.5329517865968874

Epoch: 6| Step: 6
Training loss: 3.2210670205468395
Validation loss: 2.5759091736412887

Epoch: 6| Step: 7
Training loss: 2.32007399852075
Validation loss: 2.5700524715357758

Epoch: 6| Step: 8
Training loss: 3.054711539327564
Validation loss: 2.5339239083673553

Epoch: 6| Step: 9
Training loss: 3.018580910190208
Validation loss: 2.518641047837722

Epoch: 6| Step: 10
Training loss: 2.430010709699727
Validation loss: 2.537764101193029

Epoch: 6| Step: 11
Training loss: 3.0003897095917105
Validation loss: 2.581288405270765

Epoch: 6| Step: 12
Training loss: 3.1394806100653914
Validation loss: 2.529640254074469

Epoch: 6| Step: 13
Training loss: 2.5730790204139065
Validation loss: 2.5551094759599073

Epoch: 148| Step: 0
Training loss: 2.6184113786584766
Validation loss: 2.5480221715784044

Epoch: 6| Step: 1
Training loss: 2.8215342065582116
Validation loss: 2.51100200748862

Epoch: 6| Step: 2
Training loss: 2.962567446942862
Validation loss: 2.5702800662036576

Epoch: 6| Step: 3
Training loss: 2.762736218049501
Validation loss: 2.541630849748957

Epoch: 6| Step: 4
Training loss: 2.1209996660979575
Validation loss: 2.5377081791243734

Epoch: 6| Step: 5
Training loss: 2.463417668410963
Validation loss: 2.5698196283181587

Epoch: 6| Step: 6
Training loss: 2.523709025699858
Validation loss: 2.5304327521174725

Epoch: 6| Step: 7
Training loss: 3.311469871562493
Validation loss: 2.505943997897855

Epoch: 6| Step: 8
Training loss: 2.9081158954765605
Validation loss: 2.552930035915665

Epoch: 6| Step: 9
Training loss: 2.532369860424293
Validation loss: 2.5638199994757755

Epoch: 6| Step: 10
Training loss: 2.2400125727981854
Validation loss: 2.5556064686541844

Epoch: 6| Step: 11
Training loss: 2.783368364749434
Validation loss: 2.568760838615606

Epoch: 6| Step: 12
Training loss: 3.0188963544604523
Validation loss: 2.5524643696223346

Epoch: 6| Step: 13
Training loss: 3.7491530415618852
Validation loss: 2.568892795669747

Epoch: 149| Step: 0
Training loss: 3.1705614198114622
Validation loss: 2.5949775587092323

Epoch: 6| Step: 1
Training loss: 2.2649206710969603
Validation loss: 2.564974611686781

Epoch: 6| Step: 2
Training loss: 2.3725579405644552
Validation loss: 2.5467017340241607

Epoch: 6| Step: 3
Training loss: 2.1343588341118895
Validation loss: 2.5381196089198994

Epoch: 6| Step: 4
Training loss: 3.001741857298266
Validation loss: 2.5725954521283616

Epoch: 6| Step: 5
Training loss: 2.4138606212362146
Validation loss: 2.5741144313181317

Epoch: 6| Step: 6
Training loss: 2.8948529639977405
Validation loss: 2.5694439113549503

Epoch: 6| Step: 7
Training loss: 3.212779758013072
Validation loss: 2.5498349104347873

Epoch: 6| Step: 8
Training loss: 2.513892673140664
Validation loss: 2.588167098870309

Epoch: 6| Step: 9
Training loss: 2.5934652149168853
Validation loss: 2.5557634929420656

Epoch: 6| Step: 10
Training loss: 2.6226846383756905
Validation loss: 2.5533186440227498

Epoch: 6| Step: 11
Training loss: 2.9342721289334674
Validation loss: 2.535252366136135

Epoch: 6| Step: 12
Training loss: 3.0269816126647755
Validation loss: 2.528588392936943

Epoch: 6| Step: 13
Training loss: 3.2578587517325293
Validation loss: 2.533784301800995

Epoch: 150| Step: 0
Training loss: 2.8412009751621246
Validation loss: 2.545867376346784

Epoch: 6| Step: 1
Training loss: 2.8771105773063104
Validation loss: 2.5362240943274426

Epoch: 6| Step: 2
Training loss: 3.1963256125220796
Validation loss: 2.5577438439592375

Epoch: 6| Step: 3
Training loss: 2.9662632214251143
Validation loss: 2.573180525699151

Epoch: 6| Step: 4
Training loss: 3.0828509769658345
Validation loss: 2.580721803073136

Epoch: 6| Step: 5
Training loss: 2.798034768489096
Validation loss: 2.5275940110650796

Epoch: 6| Step: 6
Training loss: 2.666089581592107
Validation loss: 2.5716608024899656

Epoch: 6| Step: 7
Training loss: 3.2338366958917084
Validation loss: 2.590351265420891

Epoch: 6| Step: 8
Training loss: 2.4832089164681954
Validation loss: 2.566076585440683

Epoch: 6| Step: 9
Training loss: 2.278510342884007
Validation loss: 2.56746105509436

Epoch: 6| Step: 10
Training loss: 1.6559270147973224
Validation loss: 2.5360628639994416

Epoch: 6| Step: 11
Training loss: 2.4298652019710385
Validation loss: 2.5506447828397953

Epoch: 6| Step: 12
Training loss: 2.804788996738105
Validation loss: 2.515664183588475

Epoch: 6| Step: 13
Training loss: 2.1539422553494516
Validation loss: 2.5743459599491594

Epoch: 151| Step: 0
Training loss: 2.684619069133683
Validation loss: 2.57813177968635

Epoch: 6| Step: 1
Training loss: 3.242839260544155
Validation loss: 2.5459942699367537

Epoch: 6| Step: 2
Training loss: 2.562318190661119
Validation loss: 2.550493404991428

Epoch: 6| Step: 3
Training loss: 1.6660157681070424
Validation loss: 2.547780907372163

Epoch: 6| Step: 4
Training loss: 3.3711483487938048
Validation loss: 2.5487256890869627

Epoch: 6| Step: 5
Training loss: 2.5974693747395676
Validation loss: 2.5371305702633498

Epoch: 6| Step: 6
Training loss: 2.576973397807081
Validation loss: 2.5638747280625416

Epoch: 6| Step: 7
Training loss: 3.0327493950922846
Validation loss: 2.5364110165295575

Epoch: 6| Step: 8
Training loss: 2.379147973017788
Validation loss: 2.5473534030109466

Epoch: 6| Step: 9
Training loss: 3.621490358033565
Validation loss: 2.5294182612750356

Epoch: 6| Step: 10
Training loss: 2.1425920345164386
Validation loss: 2.5288160992153506

Epoch: 6| Step: 11
Training loss: 2.619541851492117
Validation loss: 2.557609839224195

Epoch: 6| Step: 12
Training loss: 2.8036794737110364
Validation loss: 2.557940352429371

Epoch: 6| Step: 13
Training loss: 2.7760403306873154
Validation loss: 2.564276864802507

Epoch: 152| Step: 0
Training loss: 2.625877142996428
Validation loss: 2.5546102239601987

Epoch: 6| Step: 1
Training loss: 3.3028016537536864
Validation loss: 2.504457036493187

Epoch: 6| Step: 2
Training loss: 2.3618093904143005
Validation loss: 2.5407233034960535

Epoch: 6| Step: 3
Training loss: 2.403129436751736
Validation loss: 2.5654311994444345

Epoch: 6| Step: 4
Training loss: 2.143136103955347
Validation loss: 2.553460611696584

Epoch: 6| Step: 5
Training loss: 2.862059120308679
Validation loss: 2.567132493672589

Epoch: 6| Step: 6
Training loss: 3.2448426921786
Validation loss: 2.5777109976515273

Epoch: 6| Step: 7
Training loss: 2.7872629210233946
Validation loss: 2.532879467863204

Epoch: 6| Step: 8
Training loss: 3.241795968923087
Validation loss: 2.5591155351068258

Epoch: 6| Step: 9
Training loss: 2.633080352832062
Validation loss: 2.569435049400311

Epoch: 6| Step: 10
Training loss: 2.940472661125282
Validation loss: 2.5629552651359866

Epoch: 6| Step: 11
Training loss: 2.943326649930054
Validation loss: 2.5713003268688643

Epoch: 6| Step: 12
Training loss: 2.4706901941978816
Validation loss: 2.5573369347086325

Epoch: 6| Step: 13
Training loss: 1.7590047904161346
Validation loss: 2.5797120421035666

Epoch: 153| Step: 0
Training loss: 2.981206520131376
Validation loss: 2.558123940064946

Epoch: 6| Step: 1
Training loss: 3.064453125
Validation loss: 2.5908147009870293

Epoch: 6| Step: 2
Training loss: 2.693930097255028
Validation loss: 2.5667949572003916

Epoch: 6| Step: 3
Training loss: 2.0355064983971656
Validation loss: 2.5882877358921808

Epoch: 6| Step: 4
Training loss: 3.058405104235901
Validation loss: 2.555331257400283

Epoch: 6| Step: 5
Training loss: 2.9394380385306373
Validation loss: 2.543364598357268

Epoch: 6| Step: 6
Training loss: 3.094261512470488
Validation loss: 2.5595325572775662

Epoch: 6| Step: 7
Training loss: 3.4479687889438977
Validation loss: 2.551619587582342

Epoch: 6| Step: 8
Training loss: 2.724538582049611
Validation loss: 2.5469241258010475

Epoch: 6| Step: 9
Training loss: 2.5753580677735073
Validation loss: 2.5403007745335886

Epoch: 6| Step: 10
Training loss: 2.2540558181932324
Validation loss: 2.5618466150279064

Epoch: 6| Step: 11
Training loss: 2.190500109455077
Validation loss: 2.5603163874902184

Epoch: 6| Step: 12
Training loss: 2.2267801814164048
Validation loss: 2.549970716179208

Epoch: 6| Step: 13
Training loss: 2.339616716734941
Validation loss: 2.5382163642931976

Epoch: 154| Step: 0
Training loss: 3.14126625916007
Validation loss: 2.545303650154874

Epoch: 6| Step: 1
Training loss: 2.350404473254918
Validation loss: 2.567846351958918

Epoch: 6| Step: 2
Training loss: 2.446340813917418
Validation loss: 2.513582390771828

Epoch: 6| Step: 3
Training loss: 2.763817406586749
Validation loss: 2.5649172159098557

Epoch: 6| Step: 4
Training loss: 2.698665225387962
Validation loss: 2.536577394306393

Epoch: 6| Step: 5
Training loss: 3.023069216355696
Validation loss: 2.543274334867116

Epoch: 6| Step: 6
Training loss: 2.6967017090465277
Validation loss: 2.5309584113037995

Epoch: 6| Step: 7
Training loss: 3.0374621416409218
Validation loss: 2.543321219906666

Epoch: 6| Step: 8
Training loss: 3.292863475343084
Validation loss: 2.561161803335703

Epoch: 6| Step: 9
Training loss: 2.4729376899406215
Validation loss: 2.511158050738835

Epoch: 6| Step: 10
Training loss: 2.4954512221365874
Validation loss: 2.5674666627315457

Epoch: 6| Step: 11
Training loss: 2.207271704614256
Validation loss: 2.5087972098065645

Epoch: 6| Step: 12
Training loss: 2.509778164487157
Validation loss: 2.565761732277208

Epoch: 6| Step: 13
Training loss: 3.047900374589106
Validation loss: 2.5507145646346303

Epoch: 155| Step: 0
Training loss: 3.5785306342469867
Validation loss: 2.5680370140830178

Epoch: 6| Step: 1
Training loss: 3.4143430825867385
Validation loss: 2.56412576184929

Epoch: 6| Step: 2
Training loss: 3.3294053458035173
Validation loss: 2.56433634635068

Epoch: 6| Step: 3
Training loss: 3.065706715092601
Validation loss: 2.558154717109291

Epoch: 6| Step: 4
Training loss: 2.4335732742354397
Validation loss: 2.573081004109898

Epoch: 6| Step: 5
Training loss: 2.352432951665943
Validation loss: 2.5614565593959866

Epoch: 6| Step: 6
Training loss: 2.1225621320169785
Validation loss: 2.5382402833933666

Epoch: 6| Step: 7
Training loss: 2.595690265793016
Validation loss: 2.5507653466785944

Epoch: 6| Step: 8
Training loss: 2.65781347598821
Validation loss: 2.542820772514572

Epoch: 6| Step: 9
Training loss: 1.940090232304109
Validation loss: 2.5505052778520456

Epoch: 6| Step: 10
Training loss: 2.8356590449555603
Validation loss: 2.5578890037407516

Epoch: 6| Step: 11
Training loss: 2.281469256171976
Validation loss: 2.5442040411425686

Epoch: 6| Step: 12
Training loss: 2.3578203144285266
Validation loss: 2.55710215466053

Epoch: 6| Step: 13
Training loss: 2.8688816813246985
Validation loss: 2.5503923964952464

Epoch: 156| Step: 0
Training loss: 2.442990306421224
Validation loss: 2.5498207682371756

Epoch: 6| Step: 1
Training loss: 2.3829087534990596
Validation loss: 2.511790924752568

Epoch: 6| Step: 2
Training loss: 2.6655019859202094
Validation loss: 2.5376451336135366

Epoch: 6| Step: 3
Training loss: 2.300540205499913
Validation loss: 2.553509383903407

Epoch: 6| Step: 4
Training loss: 3.3354154441842376
Validation loss: 2.509518509957512

Epoch: 6| Step: 5
Training loss: 2.385345313547299
Validation loss: 2.524607537584816

Epoch: 6| Step: 6
Training loss: 2.5006967527301245
Validation loss: 2.545881987602351

Epoch: 6| Step: 7
Training loss: 2.57872834515043
Validation loss: 2.5810144346099526

Epoch: 6| Step: 8
Training loss: 3.3985717746911055
Validation loss: 2.4961457978295325

Epoch: 6| Step: 9
Training loss: 2.416297051237562
Validation loss: 2.5672663508551374

Epoch: 6| Step: 10
Training loss: 2.7058236647482987
Validation loss: 2.545414736315524

Epoch: 6| Step: 11
Training loss: 2.422189802814167
Validation loss: 2.5575767010546513

Epoch: 6| Step: 12
Training loss: 3.372942544619128
Validation loss: 2.5534681114666355

Epoch: 6| Step: 13
Training loss: 2.9676302755758925
Validation loss: 2.551374688037907

Epoch: 157| Step: 0
Training loss: 3.148836550732664
Validation loss: 2.556520516229884

Epoch: 6| Step: 1
Training loss: 2.789375608163366
Validation loss: 2.5588795436948124

Epoch: 6| Step: 2
Training loss: 1.8439335489236235
Validation loss: 2.552595454238205

Epoch: 6| Step: 3
Training loss: 2.617062967098993
Validation loss: 2.5695668311563518

Epoch: 6| Step: 4
Training loss: 2.8298540256986215
Validation loss: 2.554697955492941

Epoch: 6| Step: 5
Training loss: 2.8417483820497416
Validation loss: 2.531365668822654

Epoch: 6| Step: 6
Training loss: 2.494714490191862
Validation loss: 2.535931802788637

Epoch: 6| Step: 7
Training loss: 2.291155070218106
Validation loss: 2.5771883250226586

Epoch: 6| Step: 8
Training loss: 2.1858503388375854
Validation loss: 2.5327836888196504

Epoch: 6| Step: 9
Training loss: 2.6240414277039608
Validation loss: 2.5240822103114255

Epoch: 6| Step: 10
Training loss: 3.023522821843987
Validation loss: 2.5304923656224205

Epoch: 6| Step: 11
Training loss: 3.4541570579723406
Validation loss: 2.5481332096508065

Epoch: 6| Step: 12
Training loss: 2.614170259670439
Validation loss: 2.519214596174166

Epoch: 6| Step: 13
Training loss: 2.6273563345007394
Validation loss: 2.5422522791282374

Epoch: 158| Step: 0
Training loss: 2.5840103943913912
Validation loss: 2.604887651292105

Epoch: 6| Step: 1
Training loss: 2.3568702185032753
Validation loss: 2.53247179679714

Epoch: 6| Step: 2
Training loss: 2.793588678878226
Validation loss: 2.570033366248183

Epoch: 6| Step: 3
Training loss: 2.9088585744543782
Validation loss: 2.5374665273110195

Epoch: 6| Step: 4
Training loss: 2.3230898896592467
Validation loss: 2.576653215986926

Epoch: 6| Step: 5
Training loss: 2.519067624040396
Validation loss: 2.5017280748610795

Epoch: 6| Step: 6
Training loss: 2.55626776579487
Validation loss: 2.544338787197174

Epoch: 6| Step: 7
Training loss: 2.785470995566957
Validation loss: 2.5014594596645088

Epoch: 6| Step: 8
Training loss: 2.8375814417776106
Validation loss: 2.526826166632314

Epoch: 6| Step: 9
Training loss: 2.9033339442687884
Validation loss: 2.5483709648035022

Epoch: 6| Step: 10
Training loss: 2.554241456455751
Validation loss: 2.54259255394558

Epoch: 6| Step: 11
Training loss: 2.2596664472888315
Validation loss: 2.542999275964004

Epoch: 6| Step: 12
Training loss: 3.0460077078428074
Validation loss: 2.541560889157277

Epoch: 6| Step: 13
Training loss: 4.190846031555571
Validation loss: 2.5561966863895846

Epoch: 159| Step: 0
Training loss: 3.31850062581031
Validation loss: 2.5282129206695956

Epoch: 6| Step: 1
Training loss: 2.595377400027167
Validation loss: 2.5638534509171165

Epoch: 6| Step: 2
Training loss: 1.9800770991178418
Validation loss: 2.543518842647455

Epoch: 6| Step: 3
Training loss: 2.7546568368469857
Validation loss: 2.573119199175585

Epoch: 6| Step: 4
Training loss: 2.583491525626159
Validation loss: 2.5487916670898754

Epoch: 6| Step: 5
Training loss: 3.0649699935564407
Validation loss: 2.568940856755939

Epoch: 6| Step: 6
Training loss: 3.171331500012446
Validation loss: 2.5521868150904563

Epoch: 6| Step: 7
Training loss: 2.3177313528453642
Validation loss: 2.5639828419107022

Epoch: 6| Step: 8
Training loss: 2.2324765549952628
Validation loss: 2.5512310894570667

Epoch: 6| Step: 9
Training loss: 2.8311636602108394
Validation loss: 2.534385065443869

Epoch: 6| Step: 10
Training loss: 2.749808564892234
Validation loss: 2.5568432442439537

Epoch: 6| Step: 11
Training loss: 2.919755626015543
Validation loss: 2.543210661234678

Epoch: 6| Step: 12
Training loss: 2.4214568730857278
Validation loss: 2.564448869345204

Epoch: 6| Step: 13
Training loss: 2.88218256159449
Validation loss: 2.5638790226667934

Epoch: 160| Step: 0
Training loss: 2.479192065795384
Validation loss: 2.549844596578337

Epoch: 6| Step: 1
Training loss: 2.234864721449858
Validation loss: 2.5694235408863517

Epoch: 6| Step: 2
Training loss: 2.5817961477567857
Validation loss: 2.5569630430867263

Epoch: 6| Step: 3
Training loss: 2.033951356904441
Validation loss: 2.517659648486481

Epoch: 6| Step: 4
Training loss: 3.653020492116122
Validation loss: 2.544333368392851

Epoch: 6| Step: 5
Training loss: 3.11095261926967
Validation loss: 2.552248714898807

Epoch: 6| Step: 6
Training loss: 2.8640395509556913
Validation loss: 2.54253385988187

Epoch: 6| Step: 7
Training loss: 2.492661481885406
Validation loss: 2.5732708081478983

Epoch: 6| Step: 8
Training loss: 2.2427633257223283
Validation loss: 2.5332822087228988

Epoch: 6| Step: 9
Training loss: 3.0516504668620574
Validation loss: 2.5315055642194775

Epoch: 6| Step: 10
Training loss: 2.9098318034325588
Validation loss: 2.5543510750110947

Epoch: 6| Step: 11
Training loss: 2.5566763412743474
Validation loss: 2.559051453194474

Epoch: 6| Step: 12
Training loss: 2.8424424739173344
Validation loss: 2.5380713813612212

Epoch: 6| Step: 13
Training loss: 3.0561070570643105
Validation loss: 2.530154311238188

Epoch: 161| Step: 0
Training loss: 3.065992893616366
Validation loss: 2.556676153764959

Epoch: 6| Step: 1
Training loss: 3.3994290713992856
Validation loss: 2.55931017227364

Epoch: 6| Step: 2
Training loss: 1.847290583551027
Validation loss: 2.589129846446922

Epoch: 6| Step: 3
Training loss: 2.574935882658962
Validation loss: 2.5265589930361076

Epoch: 6| Step: 4
Training loss: 2.6563318576541377
Validation loss: 2.5383250175323

Epoch: 6| Step: 5
Training loss: 2.4847118221335633
Validation loss: 2.5766436734055986

Epoch: 6| Step: 6
Training loss: 2.7304151363320974
Validation loss: 2.5308098227365505

Epoch: 6| Step: 7
Training loss: 2.6360003361564273
Validation loss: 2.526829727514934

Epoch: 6| Step: 8
Training loss: 2.4482293328342224
Validation loss: 2.515842141754397

Epoch: 6| Step: 9
Training loss: 2.7506424413542816
Validation loss: 2.555919037154621

Epoch: 6| Step: 10
Training loss: 2.9496475009123837
Validation loss: 2.5245810359430845

Epoch: 6| Step: 11
Training loss: 2.9403526577319012
Validation loss: 2.5573113967865875

Epoch: 6| Step: 12
Training loss: 3.0210310947973413
Validation loss: 2.5689176361584045

Epoch: 6| Step: 13
Training loss: 2.6185749077359457
Validation loss: 2.5556445226287097

Epoch: 162| Step: 0
Training loss: 2.4467418259277256
Validation loss: 2.5649229230615926

Epoch: 6| Step: 1
Training loss: 2.404169942323601
Validation loss: 2.569579890933678

Epoch: 6| Step: 2
Training loss: 2.2195196831524986
Validation loss: 2.5765660190997903

Epoch: 6| Step: 3
Training loss: 3.155072436339972
Validation loss: 2.5771971090877703

Epoch: 6| Step: 4
Training loss: 2.833526006393139
Validation loss: 2.518155497999513

Epoch: 6| Step: 5
Training loss: 3.102926497242569
Validation loss: 2.5351574857297874

Epoch: 6| Step: 6
Training loss: 3.0393893107838825
Validation loss: 2.542990681752612

Epoch: 6| Step: 7
Training loss: 1.9452368173852406
Validation loss: 2.543236831656479

Epoch: 6| Step: 8
Training loss: 2.0652132394343004
Validation loss: 2.5469374919215095

Epoch: 6| Step: 9
Training loss: 2.6709338755932817
Validation loss: 2.519717383816629

Epoch: 6| Step: 10
Training loss: 3.183972070600228
Validation loss: 2.553776125161276

Epoch: 6| Step: 11
Training loss: 2.886086194597113
Validation loss: 2.558860438141544

Epoch: 6| Step: 12
Training loss: 2.956437448119536
Validation loss: 2.5560208959262445

Epoch: 6| Step: 13
Training loss: 2.6334463199890124
Validation loss: 2.547479857277046

Epoch: 163| Step: 0
Training loss: 2.338071326950319
Validation loss: 2.546638112866714

Epoch: 6| Step: 1
Training loss: 2.6854797576840275
Validation loss: 2.558165940100734

Epoch: 6| Step: 2
Training loss: 2.0973327500927974
Validation loss: 2.549700283908749

Epoch: 6| Step: 3
Training loss: 3.2417474287182775
Validation loss: 2.5560698960979322

Epoch: 6| Step: 4
Training loss: 2.9067008376373176
Validation loss: 2.546395318111343

Epoch: 6| Step: 5
Training loss: 2.76691635069916
Validation loss: 2.5762705348459325

Epoch: 6| Step: 6
Training loss: 2.5033529685004274
Validation loss: 2.5599714259730777

Epoch: 6| Step: 7
Training loss: 3.2258954778814997
Validation loss: 2.541455948189325

Epoch: 6| Step: 8
Training loss: 2.7542059552674636
Validation loss: 2.5523083210748254

Epoch: 6| Step: 9
Training loss: 1.8350924231097954
Validation loss: 2.550516988828976

Epoch: 6| Step: 10
Training loss: 3.208532021715694
Validation loss: 2.535369532895413

Epoch: 6| Step: 11
Training loss: 3.2172766711571406
Validation loss: 2.550477319448771

Epoch: 6| Step: 12
Training loss: 2.3379071457358007
Validation loss: 2.55781825503694

Epoch: 6| Step: 13
Training loss: 2.781187249665185
Validation loss: 2.582207216640955

Epoch: 164| Step: 0
Training loss: 2.740265001165276
Validation loss: 2.5742794488254437

Epoch: 6| Step: 1
Training loss: 2.6425943649029815
Validation loss: 2.5195854662586474

Epoch: 6| Step: 2
Training loss: 2.4790028964106914
Validation loss: 2.522614188587973

Epoch: 6| Step: 3
Training loss: 2.964811905399635
Validation loss: 2.544226046887708

Epoch: 6| Step: 4
Training loss: 2.700464074553954
Validation loss: 2.5738822902240317

Epoch: 6| Step: 5
Training loss: 2.895331268332062
Validation loss: 2.5652119781856038

Epoch: 6| Step: 6
Training loss: 2.615081759865035
Validation loss: 2.5828245345330094

Epoch: 6| Step: 7
Training loss: 2.044418025134028
Validation loss: 2.558038364987772

Epoch: 6| Step: 8
Training loss: 2.538527775725025
Validation loss: 2.582191419995877

Epoch: 6| Step: 9
Training loss: 2.910525386875869
Validation loss: 2.5375409662324455

Epoch: 6| Step: 10
Training loss: 3.36051403518695
Validation loss: 2.5570637594472867

Epoch: 6| Step: 11
Training loss: 2.38507233068161
Validation loss: 2.5889295035447653

Epoch: 6| Step: 12
Training loss: 3.548484941011715
Validation loss: 2.571939604118794

Epoch: 6| Step: 13
Training loss: 1.730865226430952
Validation loss: 2.558448996946691

Epoch: 165| Step: 0
Training loss: 2.8069743659490323
Validation loss: 2.564375944298928

Epoch: 6| Step: 1
Training loss: 3.275779014129931
Validation loss: 2.5404866924231406

Epoch: 6| Step: 2
Training loss: 2.3533117942076514
Validation loss: 2.5482698917955133

Epoch: 6| Step: 3
Training loss: 2.0550901069284566
Validation loss: 2.558876496033004

Epoch: 6| Step: 4
Training loss: 3.2084281378936685
Validation loss: 2.5368989840188476

Epoch: 6| Step: 5
Training loss: 2.471964035649079
Validation loss: 2.559734309133974

Epoch: 6| Step: 6
Training loss: 2.4350184989398835
Validation loss: 2.538626018204345

Epoch: 6| Step: 7
Training loss: 2.9556270273628793
Validation loss: 2.547536036808216

Epoch: 6| Step: 8
Training loss: 3.137605192693122
Validation loss: 2.552867204643789

Epoch: 6| Step: 9
Training loss: 2.416495667908138
Validation loss: 2.5896067435011676

Epoch: 6| Step: 10
Training loss: 2.411149622447984
Validation loss: 2.5398371809748865

Epoch: 6| Step: 11
Training loss: 2.9335794461202545
Validation loss: 2.5401458443387916

Epoch: 6| Step: 12
Training loss: 1.81601361368765
Validation loss: 2.5680488008428477

Epoch: 6| Step: 13
Training loss: 3.0871683104724075
Validation loss: 2.552976405222016

Epoch: 166| Step: 0
Training loss: 2.4955545956496654
Validation loss: 2.5899105236333475

Epoch: 6| Step: 1
Training loss: 2.408743421053649
Validation loss: 2.5423592246398923

Epoch: 6| Step: 2
Training loss: 2.5039660465997566
Validation loss: 2.546177445247461

Epoch: 6| Step: 3
Training loss: 2.7590579065631804
Validation loss: 2.569814780996791

Epoch: 6| Step: 4
Training loss: 2.5017272704338347
Validation loss: 2.555228388914845

Epoch: 6| Step: 5
Training loss: 3.062393809443229
Validation loss: 2.5541653121540224

Epoch: 6| Step: 6
Training loss: 2.4304874979814723
Validation loss: 2.5356254877153392

Epoch: 6| Step: 7
Training loss: 3.372245229453701
Validation loss: 2.533739560854468

Epoch: 6| Step: 8
Training loss: 2.393874310086872
Validation loss: 2.537876483075065

Epoch: 6| Step: 9
Training loss: 3.5715002842923984
Validation loss: 2.582218002504118

Epoch: 6| Step: 10
Training loss: 2.5554920294601344
Validation loss: 2.5549814186185498

Epoch: 6| Step: 11
Training loss: 2.4510748004308494
Validation loss: 2.5763090119976395

Epoch: 6| Step: 12
Training loss: 2.8144815881628045
Validation loss: 2.552529511281673

Epoch: 6| Step: 13
Training loss: 2.7499915036156923
Validation loss: 2.5471894451163837

Epoch: 167| Step: 0
Training loss: 2.953119510060208
Validation loss: 2.5775642846773428

Epoch: 6| Step: 1
Training loss: 3.187630445017726
Validation loss: 2.5578793189943374

Epoch: 6| Step: 2
Training loss: 2.2093755913589312
Validation loss: 2.533808542495168

Epoch: 6| Step: 3
Training loss: 2.3758848449339287
Validation loss: 2.5391674520479754

Epoch: 6| Step: 4
Training loss: 2.825665495138708
Validation loss: 2.5678140187983787

Epoch: 6| Step: 5
Training loss: 2.6217242191866266
Validation loss: 2.552164042244909

Epoch: 6| Step: 6
Training loss: 3.1314427908444284
Validation loss: 2.5528985963720388

Epoch: 6| Step: 7
Training loss: 2.757989288801676
Validation loss: 2.5162055955025933

Epoch: 6| Step: 8
Training loss: 2.8826169823815055
Validation loss: 2.5121988077510538

Epoch: 6| Step: 9
Training loss: 3.145880103026755
Validation loss: 2.5109740702067835

Epoch: 6| Step: 10
Training loss: 2.366456173772862
Validation loss: 2.5221205919456144

Epoch: 6| Step: 11
Training loss: 2.4692228805969947
Validation loss: 2.56303677763188

Epoch: 6| Step: 12
Training loss: 2.3685129817053645
Validation loss: 2.5600419098842138

Epoch: 6| Step: 13
Training loss: 2.2917330529972184
Validation loss: 2.5551601530999637

Epoch: 168| Step: 0
Training loss: 3.1110763112649873
Validation loss: 2.5413358168072984

Epoch: 6| Step: 1
Training loss: 2.8056912551980178
Validation loss: 2.5274838345366315

Epoch: 6| Step: 2
Training loss: 2.4787872622522302
Validation loss: 2.572228671059724

Epoch: 6| Step: 3
Training loss: 1.8039258530428481
Validation loss: 2.549067007112119

Epoch: 6| Step: 4
Training loss: 2.7358814558370517
Validation loss: 2.541156355129136

Epoch: 6| Step: 5
Training loss: 3.0510569507706182
Validation loss: 2.5305436026126156

Epoch: 6| Step: 6
Training loss: 3.0493470165222014
Validation loss: 2.5491234252135135

Epoch: 6| Step: 7
Training loss: 2.4294162611110877
Validation loss: 2.5735849209571966

Epoch: 6| Step: 8
Training loss: 3.2892151568362666
Validation loss: 2.548907950985357

Epoch: 6| Step: 9
Training loss: 2.3419600709073514
Validation loss: 2.53561797055775

Epoch: 6| Step: 10
Training loss: 1.9584489206602262
Validation loss: 2.4929019339717304

Epoch: 6| Step: 11
Training loss: 3.0138210771454874
Validation loss: 2.59446624481648

Epoch: 6| Step: 12
Training loss: 3.074880991547903
Validation loss: 2.577600689695862

Epoch: 6| Step: 13
Training loss: 2.5489585170789955
Validation loss: 2.5599214659810534

Epoch: 169| Step: 0
Training loss: 2.4385481317090343
Validation loss: 2.536012488602821

Epoch: 6| Step: 1
Training loss: 2.6724199776583215
Validation loss: 2.5525125376597813

Epoch: 6| Step: 2
Training loss: 2.2231867313045335
Validation loss: 2.5717185491831724

Epoch: 6| Step: 3
Training loss: 2.8646408537667223
Validation loss: 2.5567045878523755

Epoch: 6| Step: 4
Training loss: 2.662555346562911
Validation loss: 2.5570813836004818

Epoch: 6| Step: 5
Training loss: 3.3966242019449666
Validation loss: 2.5590914815368553

Epoch: 6| Step: 6
Training loss: 3.1268750478228684
Validation loss: 2.5539193944369707

Epoch: 6| Step: 7
Training loss: 3.2344817360483082
Validation loss: 2.5612791661295686

Epoch: 6| Step: 8
Training loss: 3.0017404276165514
Validation loss: 2.5620276263081814

Epoch: 6| Step: 9
Training loss: 2.0039386114589672
Validation loss: 2.5410485897129926

Epoch: 6| Step: 10
Training loss: 2.60398408376866
Validation loss: 2.5413893147047077

Epoch: 6| Step: 11
Training loss: 2.3418920655108524
Validation loss: 2.544157308405947

Epoch: 6| Step: 12
Training loss: 2.483679716116991
Validation loss: 2.5690790702794293

Epoch: 6| Step: 13
Training loss: 2.385033344859419
Validation loss: 2.5437018182775026

Epoch: 170| Step: 0
Training loss: 2.965232290911203
Validation loss: 2.549866452099014

Epoch: 6| Step: 1
Training loss: 2.9681615949066864
Validation loss: 2.534752866303439

Epoch: 6| Step: 2
Training loss: 2.2125628532490635
Validation loss: 2.5373395305614745

Epoch: 6| Step: 3
Training loss: 3.906956112937591
Validation loss: 2.5438971147649374

Epoch: 6| Step: 4
Training loss: 2.30946067888573
Validation loss: 2.5770689540654237

Epoch: 6| Step: 5
Training loss: 2.5406903961135856
Validation loss: 2.554373178007819

Epoch: 6| Step: 6
Training loss: 2.6612718570325904
Validation loss: 2.560271157441858

Epoch: 6| Step: 7
Training loss: 3.0050956048212862
Validation loss: 2.5454801132716347

Epoch: 6| Step: 8
Training loss: 2.5080785877563847
Validation loss: 2.5398168475984435

Epoch: 6| Step: 9
Training loss: 2.825488131051153
Validation loss: 2.5361530778669654

Epoch: 6| Step: 10
Training loss: 2.3351169535654126
Validation loss: 2.5711551430406865

Epoch: 6| Step: 11
Training loss: 2.1094173850993374
Validation loss: 2.5211218500420283

Epoch: 6| Step: 12
Training loss: 2.6284937542047833
Validation loss: 2.550773591573403

Epoch: 6| Step: 13
Training loss: 2.3588180389860813
Validation loss: 2.5549887824809145

Epoch: 171| Step: 0
Training loss: 2.2642803542772953
Validation loss: 2.55193438786988

Epoch: 6| Step: 1
Training loss: 2.5370556221451666
Validation loss: 2.5347594262138213

Epoch: 6| Step: 2
Training loss: 2.6948945979241747
Validation loss: 2.5607199960743627

Epoch: 6| Step: 3
Training loss: 2.9106849548573797
Validation loss: 2.54290924751187

Epoch: 6| Step: 4
Training loss: 2.683828640670889
Validation loss: 2.5886454825188117

Epoch: 6| Step: 5
Training loss: 2.4870480725926796
Validation loss: 2.5549679641380036

Epoch: 6| Step: 6
Training loss: 3.2545328075110898
Validation loss: 2.5106920045277676

Epoch: 6| Step: 7
Training loss: 2.43961985425274
Validation loss: 2.543424703529251

Epoch: 6| Step: 8
Training loss: 2.6356586048714856
Validation loss: 2.558452668379094

Epoch: 6| Step: 9
Training loss: 2.107436129687078
Validation loss: 2.5610990288693336

Epoch: 6| Step: 10
Training loss: 2.998099996984581
Validation loss: 2.564407412080145

Epoch: 6| Step: 11
Training loss: 3.133702330133524
Validation loss: 2.534546792932713

Epoch: 6| Step: 12
Training loss: 2.5692661555755634
Validation loss: 2.5439301630688247

Epoch: 6| Step: 13
Training loss: 2.861375786185818
Validation loss: 2.5515600582549913

Epoch: 172| Step: 0
Training loss: 2.604651006798803
Validation loss: 2.5334135375444484

Epoch: 6| Step: 1
Training loss: 2.366486499089381
Validation loss: 2.581323557049483

Epoch: 6| Step: 2
Training loss: 2.2022559433639377
Validation loss: 2.5497964269043227

Epoch: 6| Step: 3
Training loss: 2.93826787124505
Validation loss: 2.5657037655821617

Epoch: 6| Step: 4
Training loss: 2.7472575992080266
Validation loss: 2.5284003327223963

Epoch: 6| Step: 5
Training loss: 2.850308746211622
Validation loss: 2.54919507695684

Epoch: 6| Step: 6
Training loss: 3.1572582787225394
Validation loss: 2.576855867355273

Epoch: 6| Step: 7
Training loss: 2.2535880407956523
Validation loss: 2.5359851235457724

Epoch: 6| Step: 8
Training loss: 2.5984663768455194
Validation loss: 2.5509918276224006

Epoch: 6| Step: 9
Training loss: 2.5198058459253696
Validation loss: 2.593798640269886

Epoch: 6| Step: 10
Training loss: 3.2569106063404427
Validation loss: 2.559730318049485

Epoch: 6| Step: 11
Training loss: 2.746152440362335
Validation loss: 2.560312625609464

Epoch: 6| Step: 12
Training loss: 2.9869102374734386
Validation loss: 2.5293965331311217

Epoch: 6| Step: 13
Training loss: 2.2568806239828954
Validation loss: 2.546125322665271

Epoch: 173| Step: 0
Training loss: 2.5800921709023426
Validation loss: 2.5769918199326804

Epoch: 6| Step: 1
Training loss: 2.981372541232353
Validation loss: 2.558256782486599

Epoch: 6| Step: 2
Training loss: 2.6241947028741084
Validation loss: 2.5554007075643104

Epoch: 6| Step: 3
Training loss: 2.4167795045313816
Validation loss: 2.5354785730403187

Epoch: 6| Step: 4
Training loss: 3.1847227376508696
Validation loss: 2.5251194648987214

Epoch: 6| Step: 5
Training loss: 2.9445304338226848
Validation loss: 2.5775255636864323

Epoch: 6| Step: 6
Training loss: 2.8599666129344254
Validation loss: 2.5383047260765075

Epoch: 6| Step: 7
Training loss: 3.085063569141967
Validation loss: 2.5520767871470538

Epoch: 6| Step: 8
Training loss: 2.94880465196107
Validation loss: 2.5285506313507926

Epoch: 6| Step: 9
Training loss: 1.4651098391136839
Validation loss: 2.530586576046722

Epoch: 6| Step: 10
Training loss: 2.2541427620438785
Validation loss: 2.5383958409258156

Epoch: 6| Step: 11
Training loss: 2.607597522320004
Validation loss: 2.512938460876077

Epoch: 6| Step: 12
Training loss: 2.899987477242628
Validation loss: 2.5242253581672913

Epoch: 6| Step: 13
Training loss: 2.7712429766809015
Validation loss: 2.571591217238085

Epoch: 174| Step: 0
Training loss: 3.1792546757973166
Validation loss: 2.531553735591973

Epoch: 6| Step: 1
Training loss: 2.326382285594267
Validation loss: 2.544798612015732

Epoch: 6| Step: 2
Training loss: 3.478704379924059
Validation loss: 2.5031767453038065

Epoch: 6| Step: 3
Training loss: 2.0245963648017975
Validation loss: 2.5324522217279832

Epoch: 6| Step: 4
Training loss: 2.502864912715281
Validation loss: 2.5313107467931775

Epoch: 6| Step: 5
Training loss: 2.2158610918942
Validation loss: 2.5649642520564258

Epoch: 6| Step: 6
Training loss: 2.0875575029139704
Validation loss: 2.5217150132180195

Epoch: 6| Step: 7
Training loss: 2.4662441622108626
Validation loss: 2.539256546014122

Epoch: 6| Step: 8
Training loss: 2.9431338562409888
Validation loss: 2.5149678007675904

Epoch: 6| Step: 9
Training loss: 3.245935098785455
Validation loss: 2.550242261741064

Epoch: 6| Step: 10
Training loss: 2.496377991445181
Validation loss: 2.5879741857206193

Epoch: 6| Step: 11
Training loss: 2.524197490558929
Validation loss: 2.56422683273096

Epoch: 6| Step: 12
Training loss: 3.1088047750729864
Validation loss: 2.536323020371232

Epoch: 6| Step: 13
Training loss: 2.853148638490521
Validation loss: 2.528574709813297

Epoch: 175| Step: 0
Training loss: 2.940182698600116
Validation loss: 2.558247087107184

Epoch: 6| Step: 1
Training loss: 2.5223350360566004
Validation loss: 2.5226048369142364

Epoch: 6| Step: 2
Training loss: 2.8257380576361877
Validation loss: 2.554326829039187

Epoch: 6| Step: 3
Training loss: 2.589369602441744
Validation loss: 2.5627057792981853

Epoch: 6| Step: 4
Training loss: 2.666219693712272
Validation loss: 2.5318803132849044

Epoch: 6| Step: 5
Training loss: 3.0799310488228353
Validation loss: 2.550903113378099

Epoch: 6| Step: 6
Training loss: 3.173147312797403
Validation loss: 2.5579307891474716

Epoch: 6| Step: 7
Training loss: 2.6746937121865018
Validation loss: 2.5173185152875543

Epoch: 6| Step: 8
Training loss: 2.2100587857743443
Validation loss: 2.502950360996802

Epoch: 6| Step: 9
Training loss: 2.3124267978938655
Validation loss: 2.538734613518587

Epoch: 6| Step: 10
Training loss: 2.198287848155557
Validation loss: 2.558300070028485

Epoch: 6| Step: 11
Training loss: 3.3301270959559077
Validation loss: 2.5428648541316345

Epoch: 6| Step: 12
Training loss: 2.582407405999116
Validation loss: 2.5618663177400354

Epoch: 6| Step: 13
Training loss: 2.5494637467746357
Validation loss: 2.525284619181175

Epoch: 176| Step: 0
Training loss: 2.6281265530938858
Validation loss: 2.5531931064970665

Epoch: 6| Step: 1
Training loss: 3.0438756019949174
Validation loss: 2.5560486221852385

Epoch: 6| Step: 2
Training loss: 2.7766715093282697
Validation loss: 2.5542106192104495

Epoch: 6| Step: 3
Training loss: 3.0182218290979796
Validation loss: 2.5696725037023374

Epoch: 6| Step: 4
Training loss: 2.964873020997636
Validation loss: 2.534621397507874

Epoch: 6| Step: 5
Training loss: 2.793492834898262
Validation loss: 2.5107009962236706

Epoch: 6| Step: 6
Training loss: 2.7718088445327327
Validation loss: 2.543425787577429

Epoch: 6| Step: 7
Training loss: 2.289887055189601
Validation loss: 2.5400798436176992

Epoch: 6| Step: 8
Training loss: 2.2935438848288343
Validation loss: 2.5855679702944894

Epoch: 6| Step: 9
Training loss: 2.2593214015486165
Validation loss: 2.528766750385063

Epoch: 6| Step: 10
Training loss: 3.2288132176725086
Validation loss: 2.5428451947362256

Epoch: 6| Step: 11
Training loss: 2.6293113362389695
Validation loss: 2.5630294694000315

Epoch: 6| Step: 12
Training loss: 2.4362155758034034
Validation loss: 2.549783759466147

Epoch: 6| Step: 13
Training loss: 2.321889630319086
Validation loss: 2.537633794610144

Epoch: 177| Step: 0
Training loss: 2.7978559084553942
Validation loss: 2.5322274645533285

Epoch: 6| Step: 1
Training loss: 2.5960226558349127
Validation loss: 2.5759952229005085

Epoch: 6| Step: 2
Training loss: 2.7468501171247923
Validation loss: 2.5456972502482795

Epoch: 6| Step: 3
Training loss: 3.8245469167801227
Validation loss: 2.5350752825997453

Epoch: 6| Step: 4
Training loss: 2.469737374556207
Validation loss: 2.544202426903485

Epoch: 6| Step: 5
Training loss: 2.117055403188513
Validation loss: 2.5705407318681375

Epoch: 6| Step: 6
Training loss: 2.2980330266280746
Validation loss: 2.5382409106076804

Epoch: 6| Step: 7
Training loss: 2.6903671229681008
Validation loss: 2.579660882312697

Epoch: 6| Step: 8
Training loss: 2.7003092129571113
Validation loss: 2.5729260022041895

Epoch: 6| Step: 9
Training loss: 2.541971365586543
Validation loss: 2.565796098612954

Epoch: 6| Step: 10
Training loss: 2.5628600449112016
Validation loss: 2.5466815203856457

Epoch: 6| Step: 11
Training loss: 2.869079298346882
Validation loss: 2.549729110497504

Epoch: 6| Step: 12
Training loss: 2.5174863575146174
Validation loss: 2.552664738807388

Epoch: 6| Step: 13
Training loss: 1.9284617743527535
Validation loss: 2.541592212745097

Epoch: 178| Step: 0
Training loss: 2.563104511691633
Validation loss: 2.521853712749684

Epoch: 6| Step: 1
Training loss: 2.9682542888976964
Validation loss: 2.566659914800774

Epoch: 6| Step: 2
Training loss: 2.495103236568141
Validation loss: 2.5312987818765484

Epoch: 6| Step: 3
Training loss: 3.3408452902548436
Validation loss: 2.5434519023650353

Epoch: 6| Step: 4
Training loss: 2.49694389467833
Validation loss: 2.5390009552191306

Epoch: 6| Step: 5
Training loss: 2.498422029314936
Validation loss: 2.555185860009122

Epoch: 6| Step: 6
Training loss: 2.0419235327411287
Validation loss: 2.5310903438328958

Epoch: 6| Step: 7
Training loss: 2.892216259912803
Validation loss: 2.5463291622347355

Epoch: 6| Step: 8
Training loss: 2.9411134612122045
Validation loss: 2.5913621605732113

Epoch: 6| Step: 9
Training loss: 2.234928302681641
Validation loss: 2.589876338701921

Epoch: 6| Step: 10
Training loss: 2.7217784982736104
Validation loss: 2.517246690487569

Epoch: 6| Step: 11
Training loss: 2.5884119278896014
Validation loss: 2.5625277481957793

Epoch: 6| Step: 12
Training loss: 3.31855364719725
Validation loss: 2.505697556710682

Epoch: 6| Step: 13
Training loss: 2.253160164779551
Validation loss: 2.5211087812588424

Epoch: 179| Step: 0
Training loss: 2.7236761429582574
Validation loss: 2.531206022989818

Epoch: 6| Step: 1
Training loss: 2.9250607997737497
Validation loss: 2.5244402490497984

Epoch: 6| Step: 2
Training loss: 2.4820100095978948
Validation loss: 2.552607344438332

Epoch: 6| Step: 3
Training loss: 2.9813002480165
Validation loss: 2.5346462638630296

Epoch: 6| Step: 4
Training loss: 2.9512329499181553
Validation loss: 2.526475176303302

Epoch: 6| Step: 5
Training loss: 2.0483142946670925
Validation loss: 2.548874721809163

Epoch: 6| Step: 6
Training loss: 2.7756136241560325
Validation loss: 2.5406816659444473

Epoch: 6| Step: 7
Training loss: 2.3014462194961043
Validation loss: 2.5580857395767476

Epoch: 6| Step: 8
Training loss: 2.631934860153887
Validation loss: 2.5282170994134985

Epoch: 6| Step: 9
Training loss: 2.5594646806107613
Validation loss: 2.5046669703814506

Epoch: 6| Step: 10
Training loss: 2.547724669847032
Validation loss: 2.5491950296905044

Epoch: 6| Step: 11
Training loss: 3.244907497504112
Validation loss: 2.5238851672531464

Epoch: 6| Step: 12
Training loss: 2.5879672748082645
Validation loss: 2.5624495920765273

Epoch: 6| Step: 13
Training loss: 3.025321905489718
Validation loss: 2.569409192711943

Epoch: 180| Step: 0
Training loss: 2.4393665307513954
Validation loss: 2.533870019137934

Epoch: 6| Step: 1
Training loss: 2.136617431470106
Validation loss: 2.5341755074602443

Epoch: 6| Step: 2
Training loss: 2.39040737782199
Validation loss: 2.539231449182554

Epoch: 6| Step: 3
Training loss: 3.1281066711071723
Validation loss: 2.5397229265744943

Epoch: 6| Step: 4
Training loss: 2.5752576199148396
Validation loss: 2.5425605797304973

Epoch: 6| Step: 5
Training loss: 2.5626618869166635
Validation loss: 2.581515487012292

Epoch: 6| Step: 6
Training loss: 3.718622029130176
Validation loss: 2.5518973926732897

Epoch: 6| Step: 7
Training loss: 2.123281794011861
Validation loss: 2.5294049718381593

Epoch: 6| Step: 8
Training loss: 2.454679154758849
Validation loss: 2.558143866867967

Epoch: 6| Step: 9
Training loss: 2.887738740637679
Validation loss: 2.5347352598488726

Epoch: 6| Step: 10
Training loss: 2.58506276067401
Validation loss: 2.5255353867864976

Epoch: 6| Step: 11
Training loss: 2.6739233541980925
Validation loss: 2.5362615536579973

Epoch: 6| Step: 12
Training loss: 2.5616485297562663
Validation loss: 2.5440442637895604

Epoch: 6| Step: 13
Training loss: 3.0708651833886065
Validation loss: 2.5632136701955535

Epoch: 181| Step: 0
Training loss: 2.42065851977774
Validation loss: 2.571540514480426

Epoch: 6| Step: 1
Training loss: 2.9244914859954982
Validation loss: 2.570836570043523

Epoch: 6| Step: 2
Training loss: 3.0321032709435385
Validation loss: 2.5488532007631166

Epoch: 6| Step: 3
Training loss: 2.7384386656786006
Validation loss: 2.5431910750752946

Epoch: 6| Step: 4
Training loss: 2.930777466514225
Validation loss: 2.553427283134732

Epoch: 6| Step: 5
Training loss: 1.9431957693577677
Validation loss: 2.5774123841793792

Epoch: 6| Step: 6
Training loss: 3.2620212072060792
Validation loss: 2.5233353134693473

Epoch: 6| Step: 7
Training loss: 1.9899087476654915
Validation loss: 2.5482114044575552

Epoch: 6| Step: 8
Training loss: 2.7325059879164075
Validation loss: 2.5635263092011287

Epoch: 6| Step: 9
Training loss: 2.4594802659420445
Validation loss: 2.552534604350582

Epoch: 6| Step: 10
Training loss: 2.034721928561395
Validation loss: 2.5412601039536242

Epoch: 6| Step: 11
Training loss: 3.218505553805668
Validation loss: 2.5750061262077573

Epoch: 6| Step: 12
Training loss: 3.235145366533402
Validation loss: 2.555080160236844

Epoch: 6| Step: 13
Training loss: 1.693680500702022
Validation loss: 2.531066359190061

Epoch: 182| Step: 0
Training loss: 1.9655902271197032
Validation loss: 2.527330259968103

Epoch: 6| Step: 1
Training loss: 2.5576889651416232
Validation loss: 2.538618654341179

Epoch: 6| Step: 2
Training loss: 3.0253408192720874
Validation loss: 2.5675547188026724

Epoch: 6| Step: 3
Training loss: 2.9526523433856684
Validation loss: 2.5577933082579953

Epoch: 6| Step: 4
Training loss: 2.343814594650238
Validation loss: 2.565506125517725

Epoch: 6| Step: 5
Training loss: 3.081050973155447
Validation loss: 2.5665552749028966

Epoch: 6| Step: 6
Training loss: 2.936270760973941
Validation loss: 2.5597938156158637

Epoch: 6| Step: 7
Training loss: 2.4478598297230336
Validation loss: 2.542006085825569

Epoch: 6| Step: 8
Training loss: 3.0323418292805466
Validation loss: 2.5806248045254305

Epoch: 6| Step: 9
Training loss: 2.825518086281187
Validation loss: 2.515514856708223

Epoch: 6| Step: 10
Training loss: 2.2349797210797453
Validation loss: 2.551118835121647

Epoch: 6| Step: 11
Training loss: 2.4908325912901597
Validation loss: 2.5540659700566897

Epoch: 6| Step: 12
Training loss: 2.5358110942820224
Validation loss: 2.549429877253029

Epoch: 6| Step: 13
Training loss: 2.652452334623786
Validation loss: 2.546568040174444

Epoch: 183| Step: 0
Training loss: 3.0792672608444525
Validation loss: 2.567411871916923

Epoch: 6| Step: 1
Training loss: 2.6893183744383626
Validation loss: 2.536384836829116

Epoch: 6| Step: 2
Training loss: 3.056294128473837
Validation loss: 2.532232996330125

Epoch: 6| Step: 3
Training loss: 3.183302864874249
Validation loss: 2.5454679228874344

Epoch: 6| Step: 4
Training loss: 2.426920305487894
Validation loss: 2.5743646886728038

Epoch: 6| Step: 5
Training loss: 2.6915557775498744
Validation loss: 2.588194297515388

Epoch: 6| Step: 6
Training loss: 2.535297689621477
Validation loss: 2.570993802383241

Epoch: 6| Step: 7
Training loss: 2.8054975014734778
Validation loss: 2.5750406688358263

Epoch: 6| Step: 8
Training loss: 3.209118107187535
Validation loss: 2.5544003892308793

Epoch: 6| Step: 9
Training loss: 1.7030240650190283
Validation loss: 2.574819981691771

Epoch: 6| Step: 10
Training loss: 2.799150276677431
Validation loss: 2.553621380054652

Epoch: 6| Step: 11
Training loss: 2.6157814006464717
Validation loss: 2.5497373642731027

Epoch: 6| Step: 12
Training loss: 1.9940636271557404
Validation loss: 2.529816822742634

Epoch: 6| Step: 13
Training loss: 2.3248650173258234
Validation loss: 2.5243570911413724

Epoch: 184| Step: 0
Training loss: 2.091185066231989
Validation loss: 2.5171586262860743

Epoch: 6| Step: 1
Training loss: 3.0896557776064117
Validation loss: 2.556839520367539

Epoch: 6| Step: 2
Training loss: 2.809105413993699
Validation loss: 2.5288672839993236

Epoch: 6| Step: 3
Training loss: 3.080881810968135
Validation loss: 2.5267391201469747

Epoch: 6| Step: 4
Training loss: 2.649633267056054
Validation loss: 2.5643605706623305

Epoch: 6| Step: 5
Training loss: 2.471397429001494
Validation loss: 2.545372797815696

Epoch: 6| Step: 6
Training loss: 2.1243404037922176
Validation loss: 2.5675580157668545

Epoch: 6| Step: 7
Training loss: 3.42465445453035
Validation loss: 2.568536089641393

Epoch: 6| Step: 8
Training loss: 2.6343909719035024
Validation loss: 2.550323975500002

Epoch: 6| Step: 9
Training loss: 2.7565190467224867
Validation loss: 2.5696350635201686

Epoch: 6| Step: 10
Training loss: 2.9444311629501634
Validation loss: 2.5246544209864346

Epoch: 6| Step: 11
Training loss: 2.0866681937231424
Validation loss: 2.5416186691451133

Epoch: 6| Step: 12
Training loss: 2.61261424859758
Validation loss: 2.556229668947658

Epoch: 6| Step: 13
Training loss: 2.2379623105963833
Validation loss: 2.524143665868834

Epoch: 185| Step: 0
Training loss: 2.9344929664307835
Validation loss: 2.5994405017858915

Epoch: 6| Step: 1
Training loss: 2.0116137430877217
Validation loss: 2.509452452539762

Epoch: 6| Step: 2
Training loss: 2.3454600898308846
Validation loss: 2.5679927326386816

Epoch: 6| Step: 3
Training loss: 2.8443307807517804
Validation loss: 2.5315910098510574

Epoch: 6| Step: 4
Training loss: 3.4275933130696536
Validation loss: 2.535089408458134

Epoch: 6| Step: 5
Training loss: 2.6888643394572065
Validation loss: 2.544332900871818

Epoch: 6| Step: 6
Training loss: 2.7830317929720745
Validation loss: 2.508788651710733

Epoch: 6| Step: 7
Training loss: 2.93963594089929
Validation loss: 2.5237309892123854

Epoch: 6| Step: 8
Training loss: 2.7610376103487795
Validation loss: 2.5345087843045997

Epoch: 6| Step: 9
Training loss: 2.667267691910135
Validation loss: 2.5311972955574245

Epoch: 6| Step: 10
Training loss: 2.368209165163284
Validation loss: 2.527181364752225

Epoch: 6| Step: 11
Training loss: 2.2302121951838743
Validation loss: 2.5182241694765835

Epoch: 6| Step: 12
Training loss: 2.443018510614847
Validation loss: 2.5582968102356256

Epoch: 6| Step: 13
Training loss: 2.9453636589970067
Validation loss: 2.5242592205688634

Epoch: 186| Step: 0
Training loss: 2.1951407911815433
Validation loss: 2.487529083377101

Epoch: 6| Step: 1
Training loss: 2.391763852190679
Validation loss: 2.5188092782668985

Epoch: 6| Step: 2
Training loss: 2.9228990361685034
Validation loss: 2.5377880548614695

Epoch: 6| Step: 3
Training loss: 3.102627741837384
Validation loss: 2.5745072453753814

Epoch: 6| Step: 4
Training loss: 2.3819813764085924
Validation loss: 2.552093952517655

Epoch: 6| Step: 5
Training loss: 2.8053759736687156
Validation loss: 2.549814965449408

Epoch: 6| Step: 6
Training loss: 2.1558545620756204
Validation loss: 2.548949559764287

Epoch: 6| Step: 7
Training loss: 2.4068627506202938
Validation loss: 2.5629801646717745

Epoch: 6| Step: 8
Training loss: 1.9534814127927997
Validation loss: 2.5232947494039264

Epoch: 6| Step: 9
Training loss: 2.5839255074667316
Validation loss: 2.521235672293047

Epoch: 6| Step: 10
Training loss: 3.3377257652931522
Validation loss: 2.5067561718252955

Epoch: 6| Step: 11
Training loss: 3.3983940034033964
Validation loss: 2.5213702355611436

Epoch: 6| Step: 12
Training loss: 2.964610214987232
Validation loss: 2.529913637759326

Epoch: 6| Step: 13
Training loss: 2.238026016888657
Validation loss: 2.546315745601247

Epoch: 187| Step: 0
Training loss: 2.470136036080435
Validation loss: 2.577160418345028

Epoch: 6| Step: 1
Training loss: 2.684102949894039
Validation loss: 2.5625966211686837

Epoch: 6| Step: 2
Training loss: 3.1099839117486523
Validation loss: 2.551380248637016

Epoch: 6| Step: 3
Training loss: 2.5699212144583243
Validation loss: 2.54854310432934

Epoch: 6| Step: 4
Training loss: 2.7584365268393105
Validation loss: 2.5637754362063077

Epoch: 6| Step: 5
Training loss: 3.022951703139122
Validation loss: 2.579722848336754

Epoch: 6| Step: 6
Training loss: 2.41169222417689
Validation loss: 2.526201421018079

Epoch: 6| Step: 7
Training loss: 2.281696432665801
Validation loss: 2.574590654468923

Epoch: 6| Step: 8
Training loss: 2.039174043958773
Validation loss: 2.5345529346252325

Epoch: 6| Step: 9
Training loss: 2.544086638348878
Validation loss: 2.530501471344646

Epoch: 6| Step: 10
Training loss: 2.200261520967595
Validation loss: 2.5690792923084134

Epoch: 6| Step: 11
Training loss: 2.888652561579706
Validation loss: 2.5369440810347283

Epoch: 6| Step: 12
Training loss: 3.3394175475042935
Validation loss: 2.5463056261950916

Epoch: 6| Step: 13
Training loss: 3.072753712272062
Validation loss: 2.5311346560781263

Epoch: 188| Step: 0
Training loss: 2.097367080277936
Validation loss: 2.606074326940815

Epoch: 6| Step: 1
Training loss: 2.278037225735602
Validation loss: 2.544016427861663

Epoch: 6| Step: 2
Training loss: 2.3044801780425908
Validation loss: 2.5694067631775908

Epoch: 6| Step: 3
Training loss: 2.662657067765667
Validation loss: 2.5236843410902323

Epoch: 6| Step: 4
Training loss: 2.158366505234166
Validation loss: 2.5432887684913585

Epoch: 6| Step: 5
Training loss: 3.057605179282153
Validation loss: 2.547166198836816

Epoch: 6| Step: 6
Training loss: 2.1955802998497638
Validation loss: 2.509162607645563

Epoch: 6| Step: 7
Training loss: 3.0917097357725862
Validation loss: 2.5506819178190345

Epoch: 6| Step: 8
Training loss: 2.839773898728284
Validation loss: 2.48487527218794

Epoch: 6| Step: 9
Training loss: 3.3042092845296103
Validation loss: 2.5580474222644507

Epoch: 6| Step: 10
Training loss: 3.0295805118865764
Validation loss: 2.548272946106334

Epoch: 6| Step: 11
Training loss: 2.2396685443606676
Validation loss: 2.534228566746506

Epoch: 6| Step: 12
Training loss: 2.9285725417450705
Validation loss: 2.5423496612338714

Epoch: 6| Step: 13
Training loss: 2.8156196247011414
Validation loss: 2.5472410356600066

Epoch: 189| Step: 0
Training loss: 2.4005309669930175
Validation loss: 2.574473484257727

Epoch: 6| Step: 1
Training loss: 2.8940648412288237
Validation loss: 2.53912155044838

Epoch: 6| Step: 2
Training loss: 2.7029918130686434
Validation loss: 2.499845635355279

Epoch: 6| Step: 3
Training loss: 1.953593571722466
Validation loss: 2.5633322372006395

Epoch: 6| Step: 4
Training loss: 2.4105841505660925
Validation loss: 2.5391425057830377

Epoch: 6| Step: 5
Training loss: 2.8599189282644213
Validation loss: 2.5623705451333967

Epoch: 6| Step: 6
Training loss: 2.5670179221668534
Validation loss: 2.5443270840566123

Epoch: 6| Step: 7
Training loss: 3.3145841843471877
Validation loss: 2.521510276795794

Epoch: 6| Step: 8
Training loss: 2.605514503088721
Validation loss: 2.5475197232759217

Epoch: 6| Step: 9
Training loss: 2.6084750330971187
Validation loss: 2.5475993950369467

Epoch: 6| Step: 10
Training loss: 3.0456640722695076
Validation loss: 2.5606462449922627

Epoch: 6| Step: 11
Training loss: 2.9080975310329604
Validation loss: 2.539622349256699

Epoch: 6| Step: 12
Training loss: 2.711698134071104
Validation loss: 2.540287873043561

Epoch: 6| Step: 13
Training loss: 2.078854196291721
Validation loss: 2.520626857650672

Epoch: 190| Step: 0
Training loss: 2.5325315080736877
Validation loss: 2.5492919892045545

Epoch: 6| Step: 1
Training loss: 3.0195631491887163
Validation loss: 2.572399217068496

Epoch: 6| Step: 2
Training loss: 2.3588514947205788
Validation loss: 2.546504761991687

Epoch: 6| Step: 3
Training loss: 3.1087431145788496
Validation loss: 2.5435176669189947

Epoch: 6| Step: 4
Training loss: 3.0533481793549386
Validation loss: 2.5601619625979426

Epoch: 6| Step: 5
Training loss: 2.8638092844773877
Validation loss: 2.5284863405601183

Epoch: 6| Step: 6
Training loss: 2.570141076397926
Validation loss: 2.5824723527429434

Epoch: 6| Step: 7
Training loss: 2.144155889850472
Validation loss: 2.570878094650968

Epoch: 6| Step: 8
Training loss: 2.422831389571148
Validation loss: 2.533307647844722

Epoch: 6| Step: 9
Training loss: 3.1109512397773087
Validation loss: 2.5613950122224893

Epoch: 6| Step: 10
Training loss: 2.275694680261611
Validation loss: 2.5480818464409407

Epoch: 6| Step: 11
Training loss: 3.0266493659288227
Validation loss: 2.545055168797018

Epoch: 6| Step: 12
Training loss: 2.745856892123383
Validation loss: 2.533180963789301

Epoch: 6| Step: 13
Training loss: 1.548105155315579
Validation loss: 2.5514013534822184

Epoch: 191| Step: 0
Training loss: 2.682659847335541
Validation loss: 2.567520637610192

Epoch: 6| Step: 1
Training loss: 2.2600997374478125
Validation loss: 2.5923568437562334

Epoch: 6| Step: 2
Training loss: 2.840211951983503
Validation loss: 2.5166339398732025

Epoch: 6| Step: 3
Training loss: 2.7751211294595066
Validation loss: 2.5676859141409016

Epoch: 6| Step: 4
Training loss: 3.134581259181225
Validation loss: 2.5474744974841705

Epoch: 6| Step: 5
Training loss: 2.3643927364304265
Validation loss: 2.557981003495164

Epoch: 6| Step: 6
Training loss: 2.720329089171668
Validation loss: 2.571343599213775

Epoch: 6| Step: 7
Training loss: 2.4298114315697545
Validation loss: 2.544232849394433

Epoch: 6| Step: 8
Training loss: 2.9964211097337285
Validation loss: 2.544662487928774

Epoch: 6| Step: 9
Training loss: 2.9577672891441202
Validation loss: 2.566189898767072

Epoch: 6| Step: 10
Training loss: 2.5381218209395877
Validation loss: 2.5332591272905227

Epoch: 6| Step: 11
Training loss: 2.389373052557836
Validation loss: 2.5536200819811743

Epoch: 6| Step: 12
Training loss: 2.528883687444
Validation loss: 2.5484883110608525

Epoch: 6| Step: 13
Training loss: 2.4367833184300576
Validation loss: 2.586607207845552

Epoch: 192| Step: 0
Training loss: 2.9926757414163196
Validation loss: 2.5367158279526674

Epoch: 6| Step: 1
Training loss: 2.781619101045868
Validation loss: 2.527693097374724

Epoch: 6| Step: 2
Training loss: 2.4553046778238343
Validation loss: 2.5480992459800644

Epoch: 6| Step: 3
Training loss: 2.6590049369625586
Validation loss: 2.563768325570336

Epoch: 6| Step: 4
Training loss: 2.4464223859627245
Validation loss: 2.565592561663397

Epoch: 6| Step: 5
Training loss: 2.309432908340006
Validation loss: 2.555140976592661

Epoch: 6| Step: 6
Training loss: 2.961551491883048
Validation loss: 2.5665223161622936

Epoch: 6| Step: 7
Training loss: 3.2075706335007625
Validation loss: 2.5291511020106126

Epoch: 6| Step: 8
Training loss: 2.4924027400807853
Validation loss: 2.506026709039296

Epoch: 6| Step: 9
Training loss: 2.6643371440462964
Validation loss: 2.535545875486597

Epoch: 6| Step: 10
Training loss: 2.507121623767931
Validation loss: 2.5408816107755743

Epoch: 6| Step: 11
Training loss: 1.878410099371026
Validation loss: 2.5556858080674543

Epoch: 6| Step: 12
Training loss: 3.2022555031754085
Validation loss: 2.5669139889794748

Epoch: 6| Step: 13
Training loss: 2.8754952045706474
Validation loss: 2.5234587339031513

Epoch: 193| Step: 0
Training loss: 2.966288781119533
Validation loss: 2.5486431938122793

Epoch: 6| Step: 1
Training loss: 3.0037900507840845
Validation loss: 2.5295991232453336

Epoch: 6| Step: 2
Training loss: 2.5167085197791685
Validation loss: 2.5407237464557966

Epoch: 6| Step: 3
Training loss: 2.5320304326824408
Validation loss: 2.5508189056063824

Epoch: 6| Step: 4
Training loss: 2.6039757518723388
Validation loss: 2.515566229587562

Epoch: 6| Step: 5
Training loss: 2.6355909408022273
Validation loss: 2.547798135393855

Epoch: 6| Step: 6
Training loss: 2.759155551569641
Validation loss: 2.517472120154018

Epoch: 6| Step: 7
Training loss: 2.9393324310769713
Validation loss: 2.5068094259240836

Epoch: 6| Step: 8
Training loss: 2.002672079362594
Validation loss: 2.50333561638188

Epoch: 6| Step: 9
Training loss: 2.2340168699278147
Validation loss: 2.5762325795535443

Epoch: 6| Step: 10
Training loss: 2.3917696338069794
Validation loss: 2.523413660029593

Epoch: 6| Step: 11
Training loss: 3.1932939715205997
Validation loss: 2.5325510794931816

Epoch: 6| Step: 12
Training loss: 2.389169686347358
Validation loss: 2.523566642973532

Epoch: 6| Step: 13
Training loss: 3.141917252265019
Validation loss: 2.5457419668378036

Epoch: 194| Step: 0
Training loss: 2.452301081407434
Validation loss: 2.534678173558062

Epoch: 6| Step: 1
Training loss: 2.2705416244122185
Validation loss: 2.5073841899576554

Epoch: 6| Step: 2
Training loss: 3.601022808160562
Validation loss: 2.5232032233578425

Epoch: 6| Step: 3
Training loss: 2.289536358736431
Validation loss: 2.5154756932149254

Epoch: 6| Step: 4
Training loss: 2.500395171404631
Validation loss: 2.516046901781125

Epoch: 6| Step: 5
Training loss: 3.081316073252813
Validation loss: 2.5521812502217247

Epoch: 6| Step: 6
Training loss: 2.819834998964783
Validation loss: 2.539156865968639

Epoch: 6| Step: 7
Training loss: 2.1427029735873377
Validation loss: 2.5268887262393425

Epoch: 6| Step: 8
Training loss: 2.436423430750725
Validation loss: 2.5310532597112516

Epoch: 6| Step: 9
Training loss: 2.0021791507314064
Validation loss: 2.5258918970683055

Epoch: 6| Step: 10
Training loss: 2.7039078477415552
Validation loss: 2.550103971262625

Epoch: 6| Step: 11
Training loss: 2.3328924330183813
Validation loss: 2.5443655344396974

Epoch: 6| Step: 12
Training loss: 3.4000086167170225
Validation loss: 2.5129722019654306

Epoch: 6| Step: 13
Training loss: 3.1546932195844946
Validation loss: 2.5464284386957785

Epoch: 195| Step: 0
Training loss: 1.575024419928263
Validation loss: 2.5638525559912506

Epoch: 6| Step: 1
Training loss: 3.223445541364409
Validation loss: 2.519900984908027

Epoch: 6| Step: 2
Training loss: 2.9511119298697617
Validation loss: 2.5653442616916307

Epoch: 6| Step: 3
Training loss: 2.9537486876017867
Validation loss: 2.592025387087551

Epoch: 6| Step: 4
Training loss: 2.136424042568972
Validation loss: 2.5073649660364863

Epoch: 6| Step: 5
Training loss: 2.9603032461976326
Validation loss: 2.5150540732706768

Epoch: 6| Step: 6
Training loss: 2.5099255937589176
Validation loss: 2.5406331762308336

Epoch: 6| Step: 7
Training loss: 2.756092345557825
Validation loss: 2.564919759641927

Epoch: 6| Step: 8
Training loss: 3.288142059635761
Validation loss: 2.5573837814714673

Epoch: 6| Step: 9
Training loss: 2.4265954068833304
Validation loss: 2.539425350037525

Epoch: 6| Step: 10
Training loss: 2.4751178366612945
Validation loss: 2.5641309068705174

Epoch: 6| Step: 11
Training loss: 2.6490973716745554
Validation loss: 2.5597011148395388

Epoch: 6| Step: 12
Training loss: 2.506116156678573
Validation loss: 2.586286002268125

Epoch: 6| Step: 13
Training loss: 2.78940851538864
Validation loss: 2.5344105076572445

Epoch: 196| Step: 0
Training loss: 2.3829514759996675
Validation loss: 2.5340073229194124

Epoch: 6| Step: 1
Training loss: 2.390266341687491
Validation loss: 2.561925405954548

Epoch: 6| Step: 2
Training loss: 2.9073544936371905
Validation loss: 2.5503497713651178

Epoch: 6| Step: 3
Training loss: 2.737432895343071
Validation loss: 2.5650026089656746

Epoch: 6| Step: 4
Training loss: 2.284803157817037
Validation loss: 2.5571974008133744

Epoch: 6| Step: 5
Training loss: 2.2908834563991296
Validation loss: 2.5619248045521035

Epoch: 6| Step: 6
Training loss: 2.6465408600694857
Validation loss: 2.5815196529620383

Epoch: 6| Step: 7
Training loss: 2.7518656211136983
Validation loss: 2.5337361126337568

Epoch: 6| Step: 8
Training loss: 3.1238909469990586
Validation loss: 2.5496308775571377

Epoch: 6| Step: 9
Training loss: 2.8502801389376384
Validation loss: 2.5093856639459498

Epoch: 6| Step: 10
Training loss: 3.065648542930114
Validation loss: 2.5149255706460334

Epoch: 6| Step: 11
Training loss: 2.684306265291837
Validation loss: 2.5409222361099233

Epoch: 6| Step: 12
Training loss: 2.3019328578831635
Validation loss: 2.552124722923447

Epoch: 6| Step: 13
Training loss: 2.5279739278161113
Validation loss: 2.5302490418612202

Epoch: 197| Step: 0
Training loss: 1.8940347237148139
Validation loss: 2.581765516502056

Epoch: 6| Step: 1
Training loss: 3.4763818586759916
Validation loss: 2.531632494135601

Epoch: 6| Step: 2
Training loss: 2.650262164697292
Validation loss: 2.548270299238374

Epoch: 6| Step: 3
Training loss: 2.0987659552344264
Validation loss: 2.5744738646503227

Epoch: 6| Step: 4
Training loss: 2.551323218259886
Validation loss: 2.5787704877834

Epoch: 6| Step: 5
Training loss: 2.6558632064143106
Validation loss: 2.5094329481984174

Epoch: 6| Step: 6
Training loss: 1.9612056351282154
Validation loss: 2.5453784390071554

Epoch: 6| Step: 7
Training loss: 2.7331602177421632
Validation loss: 2.558974434165499

Epoch: 6| Step: 8
Training loss: 2.5184170410597595
Validation loss: 2.5193680854373373

Epoch: 6| Step: 9
Training loss: 3.02870511854974
Validation loss: 2.5561652067901557

Epoch: 6| Step: 10
Training loss: 2.178050092725348
Validation loss: 2.557235900285566

Epoch: 6| Step: 11
Training loss: 3.1211342361364256
Validation loss: 2.503499099822086

Epoch: 6| Step: 12
Training loss: 2.6981827200909345
Validation loss: 2.5337034908980494

Epoch: 6| Step: 13
Training loss: 2.9390861611678814
Validation loss: 2.545705729582654

Epoch: 198| Step: 0
Training loss: 2.7629629135652656
Validation loss: 2.5648027223659398

Epoch: 6| Step: 1
Training loss: 3.327056713312262
Validation loss: 2.533092925255496

Epoch: 6| Step: 2
Training loss: 2.712476485893184
Validation loss: 2.557052784267587

Epoch: 6| Step: 3
Training loss: 2.134502146830834
Validation loss: 2.5378367009629375

Epoch: 6| Step: 4
Training loss: 2.2088029350150733
Validation loss: 2.5799727107254524

Epoch: 6| Step: 5
Training loss: 1.9407545258423686
Validation loss: 2.5152717209279363

Epoch: 6| Step: 6
Training loss: 1.718629728790887
Validation loss: 2.584685367444474

Epoch: 6| Step: 7
Training loss: 2.5328818818272634
Validation loss: 2.550426785478064

Epoch: 6| Step: 8
Training loss: 2.678892857475546
Validation loss: 2.551344800866085

Epoch: 6| Step: 9
Training loss: 2.475266174491648
Validation loss: 2.5515059607620008

Epoch: 6| Step: 10
Training loss: 2.898835599555786
Validation loss: 2.530408650810112

Epoch: 6| Step: 11
Training loss: 3.151655724753744
Validation loss: 2.5603492108418155

Epoch: 6| Step: 12
Training loss: 2.932194890559068
Validation loss: 2.5346713221457935

Epoch: 6| Step: 13
Training loss: 3.412822437074556
Validation loss: 2.55018053037072

Epoch: 199| Step: 0
Training loss: 2.5990212432239743
Validation loss: 2.559195431888199

Epoch: 6| Step: 1
Training loss: 3.9677384656885453
Validation loss: 2.5444219429344974

Epoch: 6| Step: 2
Training loss: 2.894406870693489
Validation loss: 2.5626795616035905

Epoch: 6| Step: 3
Training loss: 2.239844077848391
Validation loss: 2.5763283264812586

Epoch: 6| Step: 4
Training loss: 2.8553712256772816
Validation loss: 2.5362727118000596

Epoch: 6| Step: 5
Training loss: 2.863784808209998
Validation loss: 2.5538581183477436

Epoch: 6| Step: 6
Training loss: 2.2279904789062
Validation loss: 2.5600805538396365

Epoch: 6| Step: 7
Training loss: 2.9027733465604
Validation loss: 2.56956105051256

Epoch: 6| Step: 8
Training loss: 1.9233965549402838
Validation loss: 2.5511701301530065

Epoch: 6| Step: 9
Training loss: 2.019195469697927
Validation loss: 2.5426052430950237

Epoch: 6| Step: 10
Training loss: 2.6255685099822386
Validation loss: 2.52890258254761

Epoch: 6| Step: 11
Training loss: 1.9916748584062776
Validation loss: 2.585128489591745

Epoch: 6| Step: 12
Training loss: 2.334252607821523
Validation loss: 2.5726724888809196

Epoch: 6| Step: 13
Training loss: 3.3731818776815805
Validation loss: 2.547991451236852

Epoch: 200| Step: 0
Training loss: 2.8605692719725244
Validation loss: 2.5544601122977793

Epoch: 6| Step: 1
Training loss: 2.7381419365417194
Validation loss: 2.4907689325761715

Epoch: 6| Step: 2
Training loss: 2.0857430699633515
Validation loss: 2.557340042348081

Epoch: 6| Step: 3
Training loss: 2.6434687363370606
Validation loss: 2.4960583130614897

Epoch: 6| Step: 4
Training loss: 3.0328160595958953
Validation loss: 2.5537421692791837

Epoch: 6| Step: 5
Training loss: 2.38100457315915
Validation loss: 2.556721664998502

Epoch: 6| Step: 6
Training loss: 3.0185643235752857
Validation loss: 2.5189215074038898

Epoch: 6| Step: 7
Training loss: 1.4941672727913735
Validation loss: 2.5770925752292326

Epoch: 6| Step: 8
Training loss: 2.4476215806947597
Validation loss: 2.50698623536797

Epoch: 6| Step: 9
Training loss: 2.516164970496259
Validation loss: 2.5197283883351287

Epoch: 6| Step: 10
Training loss: 2.9039645489086743
Validation loss: 2.527307846413546

Epoch: 6| Step: 11
Training loss: 2.656377632216279
Validation loss: 2.501242285910258

Epoch: 6| Step: 12
Training loss: 3.1547031955791445
Validation loss: 2.552048890159954

Epoch: 6| Step: 13
Training loss: 2.8239262219644456
Validation loss: 2.5087217759562455

Epoch: 201| Step: 0
Training loss: 2.934854168103947
Validation loss: 2.5642857195896855

Epoch: 6| Step: 1
Training loss: 2.5948579558964875
Validation loss: 2.512129318441817

Epoch: 6| Step: 2
Training loss: 2.5305873804176766
Validation loss: 2.5623552495099404

Epoch: 6| Step: 3
Training loss: 2.2849918143294814
Validation loss: 2.5492948069740065

Epoch: 6| Step: 4
Training loss: 3.1609686902289793
Validation loss: 2.549605882844434

Epoch: 6| Step: 5
Training loss: 2.488898902780203
Validation loss: 2.50014999924091

Epoch: 6| Step: 6
Training loss: 2.2638226936923664
Validation loss: 2.550287058471155

Epoch: 6| Step: 7
Training loss: 2.5384329147325633
Validation loss: 2.500863360971366

Epoch: 6| Step: 8
Training loss: 3.3406810045677493
Validation loss: 2.5195390328988765

Epoch: 6| Step: 9
Training loss: 2.972989558658684
Validation loss: 2.4946897375724437

Epoch: 6| Step: 10
Training loss: 2.772874543987581
Validation loss: 2.5560955818222926

Epoch: 6| Step: 11
Training loss: 2.248945306902487
Validation loss: 2.5522392367637754

Epoch: 6| Step: 12
Training loss: 2.086196940429012
Validation loss: 2.5530646688616185

Epoch: 6| Step: 13
Training loss: 2.2722816281790448
Validation loss: 2.557856151825656

Epoch: 202| Step: 0
Training loss: 2.863558018150746
Validation loss: 2.504492184674817

Epoch: 6| Step: 1
Training loss: 2.624446265535569
Validation loss: 2.537189435298404

Epoch: 6| Step: 2
Training loss: 2.5720954439005914
Validation loss: 2.555495088180541

Epoch: 6| Step: 3
Training loss: 2.086689217093171
Validation loss: 2.545607843918166

Epoch: 6| Step: 4
Training loss: 2.774620126378226
Validation loss: 2.533780333077903

Epoch: 6| Step: 5
Training loss: 1.9128090627434056
Validation loss: 2.5321237455505785

Epoch: 6| Step: 6
Training loss: 2.33782841624367
Validation loss: 2.5810057613738246

Epoch: 6| Step: 7
Training loss: 2.836816068391426
Validation loss: 2.5734544068951326

Epoch: 6| Step: 8
Training loss: 2.7816252723144816
Validation loss: 2.562943571983242

Epoch: 6| Step: 9
Training loss: 2.9845350931577332
Validation loss: 2.568579727939553

Epoch: 6| Step: 10
Training loss: 2.2827296226961424
Validation loss: 2.5546740319293795

Epoch: 6| Step: 11
Training loss: 3.3701556725019355
Validation loss: 2.5330149448744903

Epoch: 6| Step: 12
Training loss: 2.631707839820903
Validation loss: 2.604980991815289

Epoch: 6| Step: 13
Training loss: 2.605518346311595
Validation loss: 2.532506768748902

Epoch: 203| Step: 0
Training loss: 2.636220836957423
Validation loss: 2.5206942810200523

Epoch: 6| Step: 1
Training loss: 2.627544441464334
Validation loss: 2.5069766162757063

Epoch: 6| Step: 2
Training loss: 2.8274897921080275
Validation loss: 2.5312942284280395

Epoch: 6| Step: 3
Training loss: 2.639976466969883
Validation loss: 2.566867807529743

Epoch: 6| Step: 4
Training loss: 3.017208019880216
Validation loss: 2.569088870470848

Epoch: 6| Step: 5
Training loss: 2.4543882385471942
Validation loss: 2.512439414456935

Epoch: 6| Step: 6
Training loss: 2.626858734363676
Validation loss: 2.5663148769434363

Epoch: 6| Step: 7
Training loss: 2.0901029336942956
Validation loss: 2.5366656504692298

Epoch: 6| Step: 8
Training loss: 3.044635282074766
Validation loss: 2.569046707728164

Epoch: 6| Step: 9
Training loss: 2.6858794183315258
Validation loss: 2.5698487270181243

Epoch: 6| Step: 10
Training loss: 2.0684209279527392
Validation loss: 2.5496630944130607

Epoch: 6| Step: 11
Training loss: 2.393727601745834
Validation loss: 2.5488190354652818

Epoch: 6| Step: 12
Training loss: 2.8176124730377268
Validation loss: 2.5386213698439466

Epoch: 6| Step: 13
Training loss: 3.4124652958596924
Validation loss: 2.5336869324821807

Epoch: 204| Step: 0
Training loss: 2.1437605565648084
Validation loss: 2.543544727686197

Epoch: 6| Step: 1
Training loss: 1.9921897738574645
Validation loss: 2.5456548768187828

Epoch: 6| Step: 2
Training loss: 2.261821000022995
Validation loss: 2.5572751640774967

Epoch: 6| Step: 3
Training loss: 1.8770290839696306
Validation loss: 2.5465871986892137

Epoch: 6| Step: 4
Training loss: 3.0035431919030966
Validation loss: 2.5313802078202094

Epoch: 6| Step: 5
Training loss: 2.7693217081233983
Validation loss: 2.5793677563055972

Epoch: 6| Step: 6
Training loss: 2.6281655615762065
Validation loss: 2.543930974305867

Epoch: 6| Step: 7
Training loss: 2.7994926606082244
Validation loss: 2.5577951284088742

Epoch: 6| Step: 8
Training loss: 2.480857133871852
Validation loss: 2.5506408820626345

Epoch: 6| Step: 9
Training loss: 2.8465818620626946
Validation loss: 2.5593750680732663

Epoch: 6| Step: 10
Training loss: 3.59913603164084
Validation loss: 2.5737253344521407

Epoch: 6| Step: 11
Training loss: 3.186608133643028
Validation loss: 2.546702258489439

Epoch: 6| Step: 12
Training loss: 2.546435920920263
Validation loss: 2.5302145280846062

Epoch: 6| Step: 13
Training loss: 2.2346510283158914
Validation loss: 2.576049966000418

Epoch: 205| Step: 0
Training loss: 3.1576145357333303
Validation loss: 2.542859485619512

Epoch: 6| Step: 1
Training loss: 2.2861926736209197
Validation loss: 2.5710060382584694

Epoch: 6| Step: 2
Training loss: 2.4868780038973184
Validation loss: 2.540494985308287

Epoch: 6| Step: 3
Training loss: 2.763909103941567
Validation loss: 2.529243659547944

Epoch: 6| Step: 4
Training loss: 3.043157412516401
Validation loss: 2.5034464747274856

Epoch: 6| Step: 5
Training loss: 3.272058164466645
Validation loss: 2.5478046647348327

Epoch: 6| Step: 6
Training loss: 2.5431528801185497
Validation loss: 2.5532274251250517

Epoch: 6| Step: 7
Training loss: 2.3536919872004436
Validation loss: 2.463523711881179

Epoch: 6| Step: 8
Training loss: 2.8489851499942387
Validation loss: 2.529086690653448

Epoch: 6| Step: 9
Training loss: 2.161287035914325
Validation loss: 2.5187362694951934

Epoch: 6| Step: 10
Training loss: 2.8190433256535132
Validation loss: 2.5908741828019273

Epoch: 6| Step: 11
Training loss: 2.1629964357894336
Validation loss: 2.5621888286663768

Epoch: 6| Step: 12
Training loss: 2.3480392879857876
Validation loss: 2.5397197216720744

Epoch: 6| Step: 13
Training loss: 2.1708436342118236
Validation loss: 2.5381741856499724

Epoch: 206| Step: 0
Training loss: 2.0184020790763726
Validation loss: 2.5498324089626316

Epoch: 6| Step: 1
Training loss: 2.936256957324
Validation loss: 2.5747740336470533

Epoch: 6| Step: 2
Training loss: 2.5472588747143057
Validation loss: 2.519124070837223

Epoch: 6| Step: 3
Training loss: 2.833410224619189
Validation loss: 2.5689108835490897

Epoch: 6| Step: 4
Training loss: 2.5153626488781082
Validation loss: 2.547822207539194

Epoch: 6| Step: 5
Training loss: 2.8132000369845014
Validation loss: 2.5548355587979947

Epoch: 6| Step: 6
Training loss: 3.7209100941040973
Validation loss: 2.531995099777153

Epoch: 6| Step: 7
Training loss: 2.2687295623783528
Validation loss: 2.5030028736149674

Epoch: 6| Step: 8
Training loss: 3.20127048305645
Validation loss: 2.539143552787995

Epoch: 6| Step: 9
Training loss: 2.4767457912259525
Validation loss: 2.4985126182832165

Epoch: 6| Step: 10
Training loss: 1.9907791245708673
Validation loss: 2.497077648997085

Epoch: 6| Step: 11
Training loss: 2.315944477647805
Validation loss: 2.5287220489092808

Epoch: 6| Step: 12
Training loss: 2.2484146466926234
Validation loss: 2.527870308110539

Epoch: 6| Step: 13
Training loss: 2.4795268996499407
Validation loss: 2.559574421019854

Epoch: 207| Step: 0
Training loss: 2.1226773752025476
Validation loss: 2.573117931860922

Epoch: 6| Step: 1
Training loss: 2.831134017353956
Validation loss: 2.5200154838796

Epoch: 6| Step: 2
Training loss: 2.82309777686485
Validation loss: 2.537351701396579

Epoch: 6| Step: 3
Training loss: 2.6502752988795475
Validation loss: 2.5540153183828247

Epoch: 6| Step: 4
Training loss: 3.0574185000121115
Validation loss: 2.544343147018901

Epoch: 6| Step: 5
Training loss: 2.2041264415548687
Validation loss: 2.5559234434223628

Epoch: 6| Step: 6
Training loss: 2.323481697734465
Validation loss: 2.55285082576093

Epoch: 6| Step: 7
Training loss: 3.1882679332108257
Validation loss: 2.555417516535776

Epoch: 6| Step: 8
Training loss: 3.1998020706953074
Validation loss: 2.5482872910567007

Epoch: 6| Step: 9
Training loss: 2.7775253043408377
Validation loss: 2.544821212019664

Epoch: 6| Step: 10
Training loss: 2.103983225867993
Validation loss: 2.5443605590265093

Epoch: 6| Step: 11
Training loss: 2.104570696222669
Validation loss: 2.544988442184849

Epoch: 6| Step: 12
Training loss: 2.8216405895790935
Validation loss: 2.52137932593092

Epoch: 6| Step: 13
Training loss: 2.403275670361997
Validation loss: 2.560841221314627

Epoch: 208| Step: 0
Training loss: 1.921429962485889
Validation loss: 2.54786271918807

Epoch: 6| Step: 1
Training loss: 3.098348263654463
Validation loss: 2.516192808879838

Epoch: 6| Step: 2
Training loss: 2.834842018421693
Validation loss: 2.5666697881536065

Epoch: 6| Step: 3
Training loss: 2.027301648241185
Validation loss: 2.533311942657334

Epoch: 6| Step: 4
Training loss: 1.9849630370650242
Validation loss: 2.5264869073429956

Epoch: 6| Step: 5
Training loss: 2.9245276827820246
Validation loss: 2.551087212469498

Epoch: 6| Step: 6
Training loss: 3.1503559638030483
Validation loss: 2.534633090844421

Epoch: 6| Step: 7
Training loss: 2.6549492736683225
Validation loss: 2.556756640153835

Epoch: 6| Step: 8
Training loss: 2.4454909189477196
Validation loss: 2.5693850778603817

Epoch: 6| Step: 9
Training loss: 2.276262239175034
Validation loss: 2.5806084557840303

Epoch: 6| Step: 10
Training loss: 2.629549534442992
Validation loss: 2.5258319471247748

Epoch: 6| Step: 11
Training loss: 3.134891115332824
Validation loss: 2.5383639214078246

Epoch: 6| Step: 12
Training loss: 2.806788855389991
Validation loss: 2.5705364733265608

Epoch: 6| Step: 13
Training loss: 2.9238289404328355
Validation loss: 2.557363752510289

Epoch: 209| Step: 0
Training loss: 2.3462723447114704
Validation loss: 2.5457297092290805

Epoch: 6| Step: 1
Training loss: 2.126178414711259
Validation loss: 2.5068610661735713

Epoch: 6| Step: 2
Training loss: 2.770077155240245
Validation loss: 2.543771735105013

Epoch: 6| Step: 3
Training loss: 2.6360152598852498
Validation loss: 2.545292374478401

Epoch: 6| Step: 4
Training loss: 3.0495083897355295
Validation loss: 2.5360599415603127

Epoch: 6| Step: 5
Training loss: 3.378833007018673
Validation loss: 2.552114712938902

Epoch: 6| Step: 6
Training loss: 1.8440640715434145
Validation loss: 2.5379736497421486

Epoch: 6| Step: 7
Training loss: 2.7083447284947826
Validation loss: 2.5502475543966447

Epoch: 6| Step: 8
Training loss: 2.731645191504656
Validation loss: 2.5334584051722167

Epoch: 6| Step: 9
Training loss: 2.4950287984283013
Validation loss: 2.5000464599148042

Epoch: 6| Step: 10
Training loss: 3.235765388660256
Validation loss: 2.516362304295623

Epoch: 6| Step: 11
Training loss: 2.4770811482498205
Validation loss: 2.546003087616524

Epoch: 6| Step: 12
Training loss: 2.649290684471762
Validation loss: 2.5165142479176277

Epoch: 6| Step: 13
Training loss: 2.3691337818068936
Validation loss: 2.615907711552544

Epoch: 210| Step: 0
Training loss: 2.745697296739884
Validation loss: 2.555031642768848

Epoch: 6| Step: 1
Training loss: 2.6861565359123816
Validation loss: 2.539758113613566

Epoch: 6| Step: 2
Training loss: 2.714931920218424
Validation loss: 2.5260130724712004

Epoch: 6| Step: 3
Training loss: 1.979235684713961
Validation loss: 2.5326092037131707

Epoch: 6| Step: 4
Training loss: 2.840410556399594
Validation loss: 2.536170555200745

Epoch: 6| Step: 5
Training loss: 3.464139331314879
Validation loss: 2.5345311412596834

Epoch: 6| Step: 6
Training loss: 2.4083477635814767
Validation loss: 2.532843191323725

Epoch: 6| Step: 7
Training loss: 2.6917989192473826
Validation loss: 2.540893043243174

Epoch: 6| Step: 8
Training loss: 2.2847742527606267
Validation loss: 2.513199466607134

Epoch: 6| Step: 9
Training loss: 3.057738670584504
Validation loss: 2.533122001556649

Epoch: 6| Step: 10
Training loss: 2.4388760326204024
Validation loss: 2.560942209601538

Epoch: 6| Step: 11
Training loss: 1.828471224351105
Validation loss: 2.5430096222470593

Epoch: 6| Step: 12
Training loss: 2.2677324687728837
Validation loss: 2.5734930207880113

Epoch: 6| Step: 13
Training loss: 3.0439595677100435
Validation loss: 2.5584885106615527

Epoch: 211| Step: 0
Training loss: 2.9092241061668562
Validation loss: 2.543747853908121

Epoch: 6| Step: 1
Training loss: 2.6354738814786334
Validation loss: 2.5215207997055975

Epoch: 6| Step: 2
Training loss: 2.884398481577208
Validation loss: 2.5401273603736474

Epoch: 6| Step: 3
Training loss: 3.0171331083668673
Validation loss: 2.5001154780635737

Epoch: 6| Step: 4
Training loss: 2.5784059313676
Validation loss: 2.5443851538761804

Epoch: 6| Step: 5
Training loss: 3.415125491516049
Validation loss: 2.544997831229208

Epoch: 6| Step: 6
Training loss: 2.6893002003261675
Validation loss: 2.561685665343928

Epoch: 6| Step: 7
Training loss: 2.6157031960232566
Validation loss: 2.545923364893925

Epoch: 6| Step: 8
Training loss: 2.5851168064902295
Validation loss: 2.5609733561964823

Epoch: 6| Step: 9
Training loss: 2.343810017135207
Validation loss: 2.515230056495029

Epoch: 6| Step: 10
Training loss: 2.447330799741931
Validation loss: 2.488482615317034

Epoch: 6| Step: 11
Training loss: 2.3413659750039613
Validation loss: 2.5255453336141085

Epoch: 6| Step: 12
Training loss: 1.6826046474385803
Validation loss: 2.4983518387164967

Epoch: 6| Step: 13
Training loss: 2.239033996869128
Validation loss: 2.535220271538276

Epoch: 212| Step: 0
Training loss: 2.343239283548699
Validation loss: 2.541298920527676

Epoch: 6| Step: 1
Training loss: 2.51044456709135
Validation loss: 2.5337038430098424

Epoch: 6| Step: 2
Training loss: 2.436824215841416
Validation loss: 2.5343257984196224

Epoch: 6| Step: 3
Training loss: 3.6071355568732346
Validation loss: 2.5513349134244794

Epoch: 6| Step: 4
Training loss: 2.7151721783131437
Validation loss: 2.5197342273440584

Epoch: 6| Step: 5
Training loss: 3.6276644418514428
Validation loss: 2.5274916071473656

Epoch: 6| Step: 6
Training loss: 2.3966485226103087
Validation loss: 2.4884261101370786

Epoch: 6| Step: 7
Training loss: 2.2932643407416715
Validation loss: 2.5445784856998936

Epoch: 6| Step: 8
Training loss: 2.6143200097079125
Validation loss: 2.5624960732498714

Epoch: 6| Step: 9
Training loss: 3.1591976489539633
Validation loss: 2.5793487398947073

Epoch: 6| Step: 10
Training loss: 1.897462696618459
Validation loss: 2.494861956228376

Epoch: 6| Step: 11
Training loss: 1.9250690621211897
Validation loss: 2.5000544090913217

Epoch: 6| Step: 12
Training loss: 2.235610513616204
Validation loss: 2.5158632125275555

Epoch: 6| Step: 13
Training loss: 2.4014377777533906
Validation loss: 2.523266261917253

Epoch: 213| Step: 0
Training loss: 2.5472049616408308
Validation loss: 2.5479462670214934

Epoch: 6| Step: 1
Training loss: 2.6171125258909003
Validation loss: 2.5497703057112084

Epoch: 6| Step: 2
Training loss: 2.0626987014770117
Validation loss: 2.523216437760268

Epoch: 6| Step: 3
Training loss: 2.9021456048824423
Validation loss: 2.5132423816267173

Epoch: 6| Step: 4
Training loss: 2.9124895611359
Validation loss: 2.478578450328644

Epoch: 6| Step: 5
Training loss: 2.0821069413788846
Validation loss: 2.5534971314536707

Epoch: 6| Step: 6
Training loss: 3.035041247217977
Validation loss: 2.5383820541267714

Epoch: 6| Step: 7
Training loss: 1.9040529691556867
Validation loss: 2.487741760701335

Epoch: 6| Step: 8
Training loss: 2.5266210356981174
Validation loss: 2.5242797234421595

Epoch: 6| Step: 9
Training loss: 2.8162063760506872
Validation loss: 2.516549918385512

Epoch: 6| Step: 10
Training loss: 3.1144230183622597
Validation loss: 2.5443858188708632

Epoch: 6| Step: 11
Training loss: 2.274964334396986
Validation loss: 2.5484454604353406

Epoch: 6| Step: 12
Training loss: 2.943535144521582
Validation loss: 2.551979889237121

Epoch: 6| Step: 13
Training loss: 3.2641160024710962
Validation loss: 2.501369010214959

Epoch: 214| Step: 0
Training loss: 2.8725170526089654
Validation loss: 2.5270108165984335

Epoch: 6| Step: 1
Training loss: 3.470251085063412
Validation loss: 2.537400876189424

Epoch: 6| Step: 2
Training loss: 2.1385969593043246
Validation loss: 2.5120052852380375

Epoch: 6| Step: 3
Training loss: 2.3605139806293423
Validation loss: 2.5827222647846715

Epoch: 6| Step: 4
Training loss: 2.1749730689475153
Validation loss: 2.5184915534029395

Epoch: 6| Step: 5
Training loss: 3.1844857118956553
Validation loss: 2.5851229767928467

Epoch: 6| Step: 6
Training loss: 2.655605731695798
Validation loss: 2.555183490192474

Epoch: 6| Step: 7
Training loss: 2.4068661185838454
Validation loss: 2.5246666834366427

Epoch: 6| Step: 8
Training loss: 1.6223393446230472
Validation loss: 2.5266022402178705

Epoch: 6| Step: 9
Training loss: 3.0217203000066317
Validation loss: 2.5529518931394892

Epoch: 6| Step: 10
Training loss: 2.1111199967158303
Validation loss: 2.5156592711515016

Epoch: 6| Step: 11
Training loss: 2.7101439268173455
Validation loss: 2.50857766983377

Epoch: 6| Step: 12
Training loss: 2.5680039076433725
Validation loss: 2.5542126536932206

Epoch: 6| Step: 13
Training loss: 3.2297439223308415
Validation loss: 2.5275220867487125

Epoch: 215| Step: 0
Training loss: 2.3974198658332755
Validation loss: 2.5188613869822065

Epoch: 6| Step: 1
Training loss: 1.9961506038564243
Validation loss: 2.579745925465601

Epoch: 6| Step: 2
Training loss: 2.1017007888617494
Validation loss: 2.5293824631512596

Epoch: 6| Step: 3
Training loss: 2.54545544339449
Validation loss: 2.5199364558514645

Epoch: 6| Step: 4
Training loss: 2.950389099322722
Validation loss: 2.5488826559957687

Epoch: 6| Step: 5
Training loss: 2.735693041709364
Validation loss: 2.5598614962793427

Epoch: 6| Step: 6
Training loss: 2.5738582561267505
Validation loss: 2.5445751282329883

Epoch: 6| Step: 7
Training loss: 2.7290355757662095
Validation loss: 2.5262999713454124

Epoch: 6| Step: 8
Training loss: 1.9372616282847706
Validation loss: 2.550114793383289

Epoch: 6| Step: 9
Training loss: 3.0054643456922823
Validation loss: 2.512691730311327

Epoch: 6| Step: 10
Training loss: 3.414547115472882
Validation loss: 2.549451835879923

Epoch: 6| Step: 11
Training loss: 2.7407434905480383
Validation loss: 2.532652395157538

Epoch: 6| Step: 12
Training loss: 2.935350646302422
Validation loss: 2.538882431826481

Epoch: 6| Step: 13
Training loss: 2.4946935603868456
Validation loss: 2.54108920430679

Epoch: 216| Step: 0
Training loss: 2.745095213887286
Validation loss: 2.5388807606870083

Epoch: 6| Step: 1
Training loss: 2.5836178612658176
Validation loss: 2.5781759555985415

Epoch: 6| Step: 2
Training loss: 2.2539455998785582
Validation loss: 2.50830392971213

Epoch: 6| Step: 3
Training loss: 2.2218534229802893
Validation loss: 2.520457195375689

Epoch: 6| Step: 4
Training loss: 3.456583078073281
Validation loss: 2.5628474490450035

Epoch: 6| Step: 5
Training loss: 1.919921937090697
Validation loss: 2.5607934156666476

Epoch: 6| Step: 6
Training loss: 2.39467681392539
Validation loss: 2.5446992679404183

Epoch: 6| Step: 7
Training loss: 3.091041689593759
Validation loss: 2.5813289935450445

Epoch: 6| Step: 8
Training loss: 3.267835243264878
Validation loss: 2.5371610543111953

Epoch: 6| Step: 9
Training loss: 2.3791690173919697
Validation loss: 2.5955338386119107

Epoch: 6| Step: 10
Training loss: 3.0389482726765698
Validation loss: 2.569723281726258

Epoch: 6| Step: 11
Training loss: 2.016669897071626
Validation loss: 2.562003437975088

Epoch: 6| Step: 12
Training loss: 2.677154055204263
Validation loss: 2.546918292759402

Epoch: 6| Step: 13
Training loss: 2.439976045928691
Validation loss: 2.562469434218213

Epoch: 217| Step: 0
Training loss: 3.0251740586827642
Validation loss: 2.550292789315764

Epoch: 6| Step: 1
Training loss: 2.744897790892457
Validation loss: 2.525045558315787

Epoch: 6| Step: 2
Training loss: 2.6593815912149332
Validation loss: 2.521451340572204

Epoch: 6| Step: 3
Training loss: 2.7667361683522618
Validation loss: 2.557328046838965

Epoch: 6| Step: 4
Training loss: 2.8236499598775957
Validation loss: 2.5157280703818747

Epoch: 6| Step: 5
Training loss: 2.408410922673877
Validation loss: 2.5511179226646963

Epoch: 6| Step: 6
Training loss: 2.7808545292210467
Validation loss: 2.568397518008698

Epoch: 6| Step: 7
Training loss: 2.5147462814702513
Validation loss: 2.5399864828986916

Epoch: 6| Step: 8
Training loss: 3.3165828087203866
Validation loss: 2.542154367888762

Epoch: 6| Step: 9
Training loss: 2.5215787389754514
Validation loss: 2.4876231205070143

Epoch: 6| Step: 10
Training loss: 1.8881394623067103
Validation loss: 2.530193111757714

Epoch: 6| Step: 11
Training loss: 2.093288313792595
Validation loss: 2.5259037607292365

Epoch: 6| Step: 12
Training loss: 2.42274489008422
Validation loss: 2.530144616588149

Epoch: 6| Step: 13
Training loss: 1.347261144244053
Validation loss: 2.557655633543312

Epoch: 218| Step: 0
Training loss: 2.182307374544142
Validation loss: 2.5594564231467483

Epoch: 6| Step: 1
Training loss: 2.862575386753794
Validation loss: 2.523227310176493

Epoch: 6| Step: 2
Training loss: 2.508590149854597
Validation loss: 2.499557406717525

Epoch: 6| Step: 3
Training loss: 2.5146626592437644
Validation loss: 2.5057683855977175

Epoch: 6| Step: 4
Training loss: 3.479777634630496
Validation loss: 2.531261238975595

Epoch: 6| Step: 5
Training loss: 2.0087032494508112
Validation loss: 2.526197645883519

Epoch: 6| Step: 6
Training loss: 2.124269921043164
Validation loss: 2.56809276886305

Epoch: 6| Step: 7
Training loss: 2.996108551187772
Validation loss: 2.53890977120913

Epoch: 6| Step: 8
Training loss: 2.4420274600297907
Validation loss: 2.550631142657389

Epoch: 6| Step: 9
Training loss: 2.5551649108340575
Validation loss: 2.5315292550733495

Epoch: 6| Step: 10
Training loss: 2.971306272494611
Validation loss: 2.5184291414873408

Epoch: 6| Step: 11
Training loss: 3.0622577182144015
Validation loss: 2.4984717384247785

Epoch: 6| Step: 12
Training loss: 2.3391668649348807
Validation loss: 2.5387266784160007

Epoch: 6| Step: 13
Training loss: 2.440232041847722
Validation loss: 2.5129544449498447

Epoch: 219| Step: 0
Training loss: 2.6502288791493918
Validation loss: 2.5571735046434183

Epoch: 6| Step: 1
Training loss: 3.0586012332283934
Validation loss: 2.5333142064375824

Epoch: 6| Step: 2
Training loss: 3.185907452241902
Validation loss: 2.531324866820953

Epoch: 6| Step: 3
Training loss: 1.843013616373946
Validation loss: 2.5201417514494797

Epoch: 6| Step: 4
Training loss: 2.9040387673220507
Validation loss: 2.5814572245820195

Epoch: 6| Step: 5
Training loss: 2.050534420599834
Validation loss: 2.560661755061458

Epoch: 6| Step: 6
Training loss: 2.9013203476213176
Validation loss: 2.5645844929999737

Epoch: 6| Step: 7
Training loss: 1.8073864856072464
Validation loss: 2.548686944382251

Epoch: 6| Step: 8
Training loss: 2.831899916135767
Validation loss: 2.5259520155882083

Epoch: 6| Step: 9
Training loss: 2.493261984587962
Validation loss: 2.530824262617681

Epoch: 6| Step: 10
Training loss: 2.2117081771592484
Validation loss: 2.5585642768084753

Epoch: 6| Step: 11
Training loss: 2.531102870856672
Validation loss: 2.5322386232605227

Epoch: 6| Step: 12
Training loss: 3.0763256409981845
Validation loss: 2.574601711716512

Epoch: 6| Step: 13
Training loss: 2.6263102031853953
Validation loss: 2.5176452644568172

Epoch: 220| Step: 0
Training loss: 2.356974713409565
Validation loss: 2.555546595067801

Epoch: 6| Step: 1
Training loss: 2.0968368322136404
Validation loss: 2.559020506610099

Epoch: 6| Step: 2
Training loss: 2.32102272133017
Validation loss: 2.5285048198940703

Epoch: 6| Step: 3
Training loss: 2.5585865748647008
Validation loss: 2.5777739792080223

Epoch: 6| Step: 4
Training loss: 3.6480861715211375
Validation loss: 2.5502581426905975

Epoch: 6| Step: 5
Training loss: 2.5204771646722524
Validation loss: 2.538106791288415

Epoch: 6| Step: 6
Training loss: 2.91931758483602
Validation loss: 2.555319541399124

Epoch: 6| Step: 7
Training loss: 2.6743560336751604
Validation loss: 2.4954131871753207

Epoch: 6| Step: 8
Training loss: 2.9514623735043473
Validation loss: 2.509032229766564

Epoch: 6| Step: 9
Training loss: 2.3395736105341216
Validation loss: 2.5449418386897853

Epoch: 6| Step: 10
Training loss: 2.5991163696269064
Validation loss: 2.551620091444931

Epoch: 6| Step: 11
Training loss: 1.7894665124471936
Validation loss: 2.526754986480807

Epoch: 6| Step: 12
Training loss: 2.4635779369391364
Validation loss: 2.517777986239419

Epoch: 6| Step: 13
Training loss: 3.0004632909989626
Validation loss: 2.5302447803512207

Epoch: 221| Step: 0
Training loss: 2.893298588059229
Validation loss: 2.565468008471072

Epoch: 6| Step: 1
Training loss: 3.0857305916098023
Validation loss: 2.4917462701853905

Epoch: 6| Step: 2
Training loss: 3.45351770161684
Validation loss: 2.488543519104411

Epoch: 6| Step: 3
Training loss: 2.595044559838541
Validation loss: 2.558819524527017

Epoch: 6| Step: 4
Training loss: 2.0123592209000982
Validation loss: 2.5766166732110634

Epoch: 6| Step: 5
Training loss: 2.2509652292624134
Validation loss: 2.54412535939867

Epoch: 6| Step: 6
Training loss: 2.7634789712932997
Validation loss: 2.543316961148209

Epoch: 6| Step: 7
Training loss: 2.128910169685325
Validation loss: 2.5531288960178693

Epoch: 6| Step: 8
Training loss: 2.0408843221820097
Validation loss: 2.518226874394435

Epoch: 6| Step: 9
Training loss: 2.9907101801397937
Validation loss: 2.544206604576313

Epoch: 6| Step: 10
Training loss: 2.3765922027878594
Validation loss: 2.5739844012604447

Epoch: 6| Step: 11
Training loss: 2.8473916683070035
Validation loss: 2.550849540640656

Epoch: 6| Step: 12
Training loss: 2.4060811565660916
Validation loss: 2.5067040876026114

Epoch: 6| Step: 13
Training loss: 1.8233047580862574
Validation loss: 2.557135100476049

Epoch: 222| Step: 0
Training loss: 2.3788746798821134
Validation loss: 2.5695984359029715

Epoch: 6| Step: 1
Training loss: 2.12434175057357
Validation loss: 2.5567467435599838

Epoch: 6| Step: 2
Training loss: 3.1192146153951206
Validation loss: 2.5511281375413417

Epoch: 6| Step: 3
Training loss: 1.7403847300849224
Validation loss: 2.5154622159729576

Epoch: 6| Step: 4
Training loss: 2.5364046711242043
Validation loss: 2.588608686153515

Epoch: 6| Step: 5
Training loss: 1.9351886991414533
Validation loss: 2.529296751343434

Epoch: 6| Step: 6
Training loss: 2.612428443330266
Validation loss: 2.5589286474180377

Epoch: 6| Step: 7
Training loss: 2.374098154804266
Validation loss: 2.5714615241727707

Epoch: 6| Step: 8
Training loss: 2.4245382124898014
Validation loss: 2.535129344918828

Epoch: 6| Step: 9
Training loss: 3.4930448909029614
Validation loss: 2.5543868403602668

Epoch: 6| Step: 10
Training loss: 2.7889267490378846
Validation loss: 2.5586001034998813

Epoch: 6| Step: 11
Training loss: 3.4084965008492043
Validation loss: 2.5469116121739814

Epoch: 6| Step: 12
Training loss: 2.016968272120855
Validation loss: 2.5448785140274355

Epoch: 6| Step: 13
Training loss: 2.7680076206631576
Validation loss: 2.5256503652158493

Epoch: 223| Step: 0
Training loss: 2.9478774500598375
Validation loss: 2.485350214328872

Epoch: 6| Step: 1
Training loss: 2.834334832256982
Validation loss: 2.517973714274967

Epoch: 6| Step: 2
Training loss: 2.068099080278111
Validation loss: 2.5305000145123393

Epoch: 6| Step: 3
Training loss: 2.078062242980095
Validation loss: 2.5047619996617243

Epoch: 6| Step: 4
Training loss: 2.405520836469712
Validation loss: 2.5325897673735036

Epoch: 6| Step: 5
Training loss: 2.5533223368886833
Validation loss: 2.5337080663239147

Epoch: 6| Step: 6
Training loss: 2.8889268990811905
Validation loss: 2.518197158824016

Epoch: 6| Step: 7
Training loss: 2.2177424762534996
Validation loss: 2.542107986741652

Epoch: 6| Step: 8
Training loss: 2.966266757999735
Validation loss: 2.525020250182173

Epoch: 6| Step: 9
Training loss: 2.4056541398687643
Validation loss: 2.539771561860301

Epoch: 6| Step: 10
Training loss: 2.0619910797162992
Validation loss: 2.5347961476434766

Epoch: 6| Step: 11
Training loss: 2.6385195311892775
Validation loss: 2.517921187053245

Epoch: 6| Step: 12
Training loss: 2.529836754639902
Validation loss: 2.5596026866964863

Epoch: 6| Step: 13
Training loss: 3.854028372818022
Validation loss: 2.5293153169914366

Epoch: 224| Step: 0
Training loss: 2.1226352548806995
Validation loss: 2.565656886879922

Epoch: 6| Step: 1
Training loss: 2.5106871104421846
Validation loss: 2.5373707920916346

Epoch: 6| Step: 2
Training loss: 2.818376040128527
Validation loss: 2.5667691428326056

Epoch: 6| Step: 3
Training loss: 2.7299587663044758
Validation loss: 2.5048127005989334

Epoch: 6| Step: 4
Training loss: 2.4020614830362135
Validation loss: 2.547385060943554

Epoch: 6| Step: 5
Training loss: 2.4948710280971196
Validation loss: 2.566262592949919

Epoch: 6| Step: 6
Training loss: 2.745451633703306
Validation loss: 2.559381810282567

Epoch: 6| Step: 7
Training loss: 3.0613631649136686
Validation loss: 2.5146009393513666

Epoch: 6| Step: 8
Training loss: 3.5455031914030233
Validation loss: 2.53950985787724

Epoch: 6| Step: 9
Training loss: 2.657743684751306
Validation loss: 2.524437550789536

Epoch: 6| Step: 10
Training loss: 2.614871876716071
Validation loss: 2.5224148507961304

Epoch: 6| Step: 11
Training loss: 2.4390297026692664
Validation loss: 2.5500778109963975

Epoch: 6| Step: 12
Training loss: 1.8955138499710649
Validation loss: 2.5762465389505675

Epoch: 6| Step: 13
Training loss: 2.0179541090708475
Validation loss: 2.5303277640139465

Epoch: 225| Step: 0
Training loss: 2.7544768912328776
Validation loss: 2.550247469955502

Epoch: 6| Step: 1
Training loss: 2.3801585942809447
Validation loss: 2.5303636521055624

Epoch: 6| Step: 2
Training loss: 2.7735745248390975
Validation loss: 2.5290749017297274

Epoch: 6| Step: 3
Training loss: 2.0157321635302474
Validation loss: 2.525654070115619

Epoch: 6| Step: 4
Training loss: 2.210759671342042
Validation loss: 2.548485820338298

Epoch: 6| Step: 5
Training loss: 2.7379291215504082
Validation loss: 2.539696468595946

Epoch: 6| Step: 6
Training loss: 2.137167484230437
Validation loss: 2.52759598126677

Epoch: 6| Step: 7
Training loss: 3.753309823725392
Validation loss: 2.5159833639196707

Epoch: 6| Step: 8
Training loss: 2.5502947917408045
Validation loss: 2.533115191477618

Epoch: 6| Step: 9
Training loss: 2.448701989568314
Validation loss: 2.5866955092697173

Epoch: 6| Step: 10
Training loss: 3.00374226810827
Validation loss: 2.5374480718187846

Epoch: 6| Step: 11
Training loss: 2.2815028011347462
Validation loss: 2.5710739467562638

Epoch: 6| Step: 12
Training loss: 2.6222128831118785
Validation loss: 2.5298347056209467

Epoch: 6| Step: 13
Training loss: 2.3461287570492204
Validation loss: 2.555169573244344

Epoch: 226| Step: 0
Training loss: 2.226688849896395
Validation loss: 2.524335458566745

Epoch: 6| Step: 1
Training loss: 2.4562410621383384
Validation loss: 2.5636403007503143

Epoch: 6| Step: 2
Training loss: 2.136845279831688
Validation loss: 2.53898605597613

Epoch: 6| Step: 3
Training loss: 2.829534864179521
Validation loss: 2.5239880486139032

Epoch: 6| Step: 4
Training loss: 3.3106727598669132
Validation loss: 2.5411340776488296

Epoch: 6| Step: 5
Training loss: 2.327795837482002
Validation loss: 2.5180160027233556

Epoch: 6| Step: 6
Training loss: 2.9281320740768004
Validation loss: 2.5563046696624614

Epoch: 6| Step: 7
Training loss: 2.6639051642620704
Validation loss: 2.510138235853538

Epoch: 6| Step: 8
Training loss: 2.33561607369342
Validation loss: 2.501315429154467

Epoch: 6| Step: 9
Training loss: 2.8720892393545014
Validation loss: 2.532753335293455

Epoch: 6| Step: 10
Training loss: 2.0310005621709752
Validation loss: 2.5332408961700903

Epoch: 6| Step: 11
Training loss: 2.7406189173562416
Validation loss: 2.5254581110160563

Epoch: 6| Step: 12
Training loss: 2.470833104751688
Validation loss: 2.520430806734394

Epoch: 6| Step: 13
Training loss: 2.549322719014522
Validation loss: 2.4935112535555723

Epoch: 227| Step: 0
Training loss: 2.4268030051123968
Validation loss: 2.5488739151629605

Epoch: 6| Step: 1
Training loss: 2.1676623428601163
Validation loss: 2.5147741192477158

Epoch: 6| Step: 2
Training loss: 2.030226581687853
Validation loss: 2.5331896175941195

Epoch: 6| Step: 3
Training loss: 2.1793023319452987
Validation loss: 2.5636346547433595

Epoch: 6| Step: 4
Training loss: 2.2173776815195962
Validation loss: 2.544359869843356

Epoch: 6| Step: 5
Training loss: 2.781589358767632
Validation loss: 2.529985139937646

Epoch: 6| Step: 6
Training loss: 1.9878087409754093
Validation loss: 2.5282329696540975

Epoch: 6| Step: 7
Training loss: 2.7910159666943457
Validation loss: 2.559074953154129

Epoch: 6| Step: 8
Training loss: 3.537414436518701
Validation loss: 2.5679666677545443

Epoch: 6| Step: 9
Training loss: 2.5092520221680394
Validation loss: 2.6021584355424205

Epoch: 6| Step: 10
Training loss: 2.54952733764236
Validation loss: 2.5526684065075496

Epoch: 6| Step: 11
Training loss: 2.688270990540035
Validation loss: 2.5329136781244532

Epoch: 6| Step: 12
Training loss: 2.8050218983167707
Validation loss: 2.541618702431043

Epoch: 6| Step: 13
Training loss: 3.9151116524044953
Validation loss: 2.5148068295422346

Epoch: 228| Step: 0
Training loss: 2.28978845327163
Validation loss: 2.53290993323672

Epoch: 6| Step: 1
Training loss: 1.8443616078949594
Validation loss: 2.5392876587544184

Epoch: 6| Step: 2
Training loss: 2.299104296382248
Validation loss: 2.558829215733712

Epoch: 6| Step: 3
Training loss: 2.9514736826565238
Validation loss: 2.526499746381443

Epoch: 6| Step: 4
Training loss: 2.245740461346004
Validation loss: 2.5363843349937154

Epoch: 6| Step: 5
Training loss: 2.897113837115324
Validation loss: 2.521367016481566

Epoch: 6| Step: 6
Training loss: 2.222960868569971
Validation loss: 2.5491569810114014

Epoch: 6| Step: 7
Training loss: 2.517929443279825
Validation loss: 2.5054439358591822

Epoch: 6| Step: 8
Training loss: 2.2104590878983625
Validation loss: 2.5653767458989667

Epoch: 6| Step: 9
Training loss: 3.0976396249947946
Validation loss: 2.529458616666814

Epoch: 6| Step: 10
Training loss: 3.2708577116687465
Validation loss: 2.5626133379218943

Epoch: 6| Step: 11
Training loss: 2.878370548339773
Validation loss: 2.5382165743766394

Epoch: 6| Step: 12
Training loss: 2.6754577886723023
Validation loss: 2.5293574832203785

Epoch: 6| Step: 13
Training loss: 2.179687937527958
Validation loss: 2.56387662288882

Epoch: 229| Step: 0
Training loss: 2.372850549684943
Validation loss: 2.5221310569120754

Epoch: 6| Step: 1
Training loss: 2.631657468728566
Validation loss: 2.5264366596323597

Epoch: 6| Step: 2
Training loss: 2.4504135600226387
Validation loss: 2.534638887426078

Epoch: 6| Step: 3
Training loss: 2.1835216858356703
Validation loss: 2.5624170197367993

Epoch: 6| Step: 4
Training loss: 2.6049223960402523
Validation loss: 2.532618041676525

Epoch: 6| Step: 5
Training loss: 2.6491092516387313
Validation loss: 2.5559713241079334

Epoch: 6| Step: 6
Training loss: 3.845639268491237
Validation loss: 2.5519472134025043

Epoch: 6| Step: 7
Training loss: 2.4099923299137114
Validation loss: 2.5664583652491877

Epoch: 6| Step: 8
Training loss: 2.607777546259252
Validation loss: 2.5712699644065737

Epoch: 6| Step: 9
Training loss: 2.249247743102363
Validation loss: 2.5087107906020965

Epoch: 6| Step: 10
Training loss: 2.22909990252282
Validation loss: 2.5335442139796043

Epoch: 6| Step: 11
Training loss: 2.4481969037183715
Validation loss: 2.586983433789978

Epoch: 6| Step: 12
Training loss: 2.614393331202169
Validation loss: 2.4946692946647144

Epoch: 6| Step: 13
Training loss: 3.1389646174055117
Validation loss: 2.57017521859863

Epoch: 230| Step: 0
Training loss: 2.6905893711119186
Validation loss: 2.5710613966148523

Epoch: 6| Step: 1
Training loss: 2.566905909283205
Validation loss: 2.5705360045873618

Epoch: 6| Step: 2
Training loss: 3.3667103723641385
Validation loss: 2.5174783371073777

Epoch: 6| Step: 3
Training loss: 2.926132445909347
Validation loss: 2.5612118592470225

Epoch: 6| Step: 4
Training loss: 2.469440122309038
Validation loss: 2.5577390078307918

Epoch: 6| Step: 5
Training loss: 2.434900805354354
Validation loss: 2.5265830549656765

Epoch: 6| Step: 6
Training loss: 2.5271295046906053
Validation loss: 2.531932339294621

Epoch: 6| Step: 7
Training loss: 2.9768827170993393
Validation loss: 2.5340660642417445

Epoch: 6| Step: 8
Training loss: 2.684534166300172
Validation loss: 2.572564271851695

Epoch: 6| Step: 9
Training loss: 1.7746853912281875
Validation loss: 2.5037462130464743

Epoch: 6| Step: 10
Training loss: 2.5385659069667015
Validation loss: 2.524160086806965

Epoch: 6| Step: 11
Training loss: 2.2622101403125896
Validation loss: 2.543695320734368

Epoch: 6| Step: 12
Training loss: 2.8017875959662173
Validation loss: 2.555256462882127

Epoch: 6| Step: 13
Training loss: 1.9594156507445817
Validation loss: 2.486368076519127

Epoch: 231| Step: 0
Training loss: 2.4677529554947406
Validation loss: 2.5602209129114333

Epoch: 6| Step: 1
Training loss: 2.8818059885452447
Validation loss: 2.512871413985423

Epoch: 6| Step: 2
Training loss: 2.6839988436063957
Validation loss: 2.5411900776691696

Epoch: 6| Step: 3
Training loss: 2.3936282971073712
Validation loss: 2.4928930004530065

Epoch: 6| Step: 4
Training loss: 2.798762276108445
Validation loss: 2.5350624268220736

Epoch: 6| Step: 5
Training loss: 2.3667100481525756
Validation loss: 2.563006956434141

Epoch: 6| Step: 6
Training loss: 2.378831483264219
Validation loss: 2.5413161728205775

Epoch: 6| Step: 7
Training loss: 1.8802829068964704
Validation loss: 2.5515470077240954

Epoch: 6| Step: 8
Training loss: 2.6810290478986367
Validation loss: 2.5369447651587853

Epoch: 6| Step: 9
Training loss: 2.5667068560868045
Validation loss: 2.543472123527438

Epoch: 6| Step: 10
Training loss: 3.0269546750988097
Validation loss: 2.570477420490368

Epoch: 6| Step: 11
Training loss: 2.5846320138647836
Validation loss: 2.5089135970116567

Epoch: 6| Step: 12
Training loss: 3.0880266674748205
Validation loss: 2.5451717795305293

Epoch: 6| Step: 13
Training loss: 2.316696277493206
Validation loss: 2.5360211185929984

Epoch: 232| Step: 0
Training loss: 2.0683267534977685
Validation loss: 2.4760377192755803

Epoch: 6| Step: 1
Training loss: 2.7458236366143205
Validation loss: 2.534588438211867

Epoch: 6| Step: 2
Training loss: 2.2795820017007564
Validation loss: 2.579869693443402

Epoch: 6| Step: 3
Training loss: 3.318643307452551
Validation loss: 2.5135004489470987

Epoch: 6| Step: 4
Training loss: 1.7332165259960215
Validation loss: 2.5455609395612155

Epoch: 6| Step: 5
Training loss: 2.137732563417443
Validation loss: 2.5303197853235484

Epoch: 6| Step: 6
Training loss: 2.2725356367986884
Validation loss: 2.550841980910798

Epoch: 6| Step: 7
Training loss: 2.1459595973325754
Validation loss: 2.4877524194922183

Epoch: 6| Step: 8
Training loss: 2.617192328149698
Validation loss: 2.5348986610104163

Epoch: 6| Step: 9
Training loss: 3.6155026427512413
Validation loss: 2.536463862789572

Epoch: 6| Step: 10
Training loss: 2.4909766433582528
Validation loss: 2.5004647633044432

Epoch: 6| Step: 11
Training loss: 2.7113497637715254
Validation loss: 2.541307951212735

Epoch: 6| Step: 12
Training loss: 2.3062132876402344
Validation loss: 2.5461317596358786

Epoch: 6| Step: 13
Training loss: 3.214400083535603
Validation loss: 2.573281194112565

Epoch: 233| Step: 0
Training loss: 2.0712339258117005
Validation loss: 2.547723039726161

Epoch: 6| Step: 1
Training loss: 3.030072799664168
Validation loss: 2.4856174205518102

Epoch: 6| Step: 2
Training loss: 2.191985844141784
Validation loss: 2.5544378780795323

Epoch: 6| Step: 3
Training loss: 2.484492461108836
Validation loss: 2.53233803806401

Epoch: 6| Step: 4
Training loss: 2.741537859440813
Validation loss: 2.5655292615778595

Epoch: 6| Step: 5
Training loss: 2.5381914258510756
Validation loss: 2.5321424534738197

Epoch: 6| Step: 6
Training loss: 2.1939617087431476
Validation loss: 2.562127152997141

Epoch: 6| Step: 7
Training loss: 3.115975280477585
Validation loss: 2.5048939087996223

Epoch: 6| Step: 8
Training loss: 2.7991959302878633
Validation loss: 2.5437440473681328

Epoch: 6| Step: 9
Training loss: 3.1639081752488094
Validation loss: 2.5500915385848275

Epoch: 6| Step: 10
Training loss: 2.4011555035816343
Validation loss: 2.5030966848137375

Epoch: 6| Step: 11
Training loss: 2.548442334907852
Validation loss: 2.565555832365547

Epoch: 6| Step: 12
Training loss: 2.2926353719131534
Validation loss: 2.5131396418205023

Epoch: 6| Step: 13
Training loss: 1.9187996923119173
Validation loss: 2.534297317587475

Epoch: 234| Step: 0
Training loss: 1.841036076131634
Validation loss: 2.5515247777608714

Epoch: 6| Step: 1
Training loss: 2.5005261821142697
Validation loss: 2.52879806619103

Epoch: 6| Step: 2
Training loss: 2.7038934750876527
Validation loss: 2.5578211185387474

Epoch: 6| Step: 3
Training loss: 2.8865874264466718
Validation loss: 2.557700515931565

Epoch: 6| Step: 4
Training loss: 2.3985718928654487
Validation loss: 2.5414202056388913

Epoch: 6| Step: 5
Training loss: 2.6664493194061323
Validation loss: 2.5447451525465707

Epoch: 6| Step: 6
Training loss: 2.641512840036165
Validation loss: 2.5332865764413497

Epoch: 6| Step: 7
Training loss: 2.4708036741521195
Validation loss: 2.538658746843774

Epoch: 6| Step: 8
Training loss: 3.1402034951134388
Validation loss: 2.5571598962783555

Epoch: 6| Step: 9
Training loss: 2.5073888307917653
Validation loss: 2.5280088768064997

Epoch: 6| Step: 10
Training loss: 3.2486860113237936
Validation loss: 2.4637608352056355

Epoch: 6| Step: 11
Training loss: 2.1965170165717716
Validation loss: 2.5730923503034853

Epoch: 6| Step: 12
Training loss: 2.508948143250964
Validation loss: 2.5653253771714803

Epoch: 6| Step: 13
Training loss: 1.9555895705166764
Validation loss: 2.52443333633887

Epoch: 235| Step: 0
Training loss: 2.7835336803428965
Validation loss: 2.530520886239767

Epoch: 6| Step: 1
Training loss: 1.7541698096361191
Validation loss: 2.5311966311491303

Epoch: 6| Step: 2
Training loss: 3.1630860882506138
Validation loss: 2.5047263117766065

Epoch: 6| Step: 3
Training loss: 2.723038809346692
Validation loss: 2.504010862398063

Epoch: 6| Step: 4
Training loss: 2.384288893278524
Validation loss: 2.542533408666921

Epoch: 6| Step: 5
Training loss: 2.668837934916911
Validation loss: 2.489247907079771

Epoch: 6| Step: 6
Training loss: 2.553108123760874
Validation loss: 2.5194945482558833

Epoch: 6| Step: 7
Training loss: 2.4130638056704625
Validation loss: 2.502648349547925

Epoch: 6| Step: 8
Training loss: 2.9113131482952026
Validation loss: 2.5005330512159762

Epoch: 6| Step: 9
Training loss: 2.5449837994013023
Validation loss: 2.5273454211603044

Epoch: 6| Step: 10
Training loss: 2.1826281109905623
Validation loss: 2.601844672520936

Epoch: 6| Step: 11
Training loss: 2.942629292644703
Validation loss: 2.5338276052501905

Epoch: 6| Step: 12
Training loss: 3.0604932788861703
Validation loss: 2.5533738115502964

Epoch: 6| Step: 13
Training loss: 2.0263390670112074
Validation loss: 2.5395565509599485

Epoch: 236| Step: 0
Training loss: 2.488648966832154
Validation loss: 2.5422747671462855

Epoch: 6| Step: 1
Training loss: 2.843378399055399
Validation loss: 2.5155391832614598

Epoch: 6| Step: 2
Training loss: 2.619194240718235
Validation loss: 2.524969455473736

Epoch: 6| Step: 3
Training loss: 2.7906428969814288
Validation loss: 2.568444978505554

Epoch: 6| Step: 4
Training loss: 2.4351918956802194
Validation loss: 2.507079494626443

Epoch: 6| Step: 5
Training loss: 1.8308704334378403
Validation loss: 2.5390212582756084

Epoch: 6| Step: 6
Training loss: 2.357160526886474
Validation loss: 2.529942359964869

Epoch: 6| Step: 7
Training loss: 2.8483363465779994
Validation loss: 2.51332852159313

Epoch: 6| Step: 8
Training loss: 2.9276164554721924
Validation loss: 2.533344628128602

Epoch: 6| Step: 9
Training loss: 1.988619372803075
Validation loss: 2.586335057480152

Epoch: 6| Step: 10
Training loss: 2.550738814791067
Validation loss: 2.5269320276349765

Epoch: 6| Step: 11
Training loss: 3.1243401402945645
Validation loss: 2.525591919449112

Epoch: 6| Step: 12
Training loss: 2.430122851653224
Validation loss: 2.5519777223802342

Epoch: 6| Step: 13
Training loss: 2.354885959172288
Validation loss: 2.567185765559058

Epoch: 237| Step: 0
Training loss: 2.640084566871515
Validation loss: 2.507316519097397

Epoch: 6| Step: 1
Training loss: 2.4789347072618577
Validation loss: 2.531851444473658

Epoch: 6| Step: 2
Training loss: 2.8800631182429797
Validation loss: 2.5201661147204746

Epoch: 6| Step: 3
Training loss: 2.725710323041816
Validation loss: 2.51993825349655

Epoch: 6| Step: 4
Training loss: 2.0489539152355363
Validation loss: 2.4718458454041095

Epoch: 6| Step: 5
Training loss: 2.4600375028403243
Validation loss: 2.540738759112941

Epoch: 6| Step: 6
Training loss: 2.804073766007446
Validation loss: 2.5007975628933536

Epoch: 6| Step: 7
Training loss: 2.6192497668756367
Validation loss: 2.5665683959518124

Epoch: 6| Step: 8
Training loss: 1.8570148009910565
Validation loss: 2.5958829457430213

Epoch: 6| Step: 9
Training loss: 2.28659810281323
Validation loss: 2.486934820517587

Epoch: 6| Step: 10
Training loss: 3.008903325432999
Validation loss: 2.5152707006784043

Epoch: 6| Step: 11
Training loss: 2.5007843694455905
Validation loss: 2.5561024550416587

Epoch: 6| Step: 12
Training loss: 3.1168038268345835
Validation loss: 2.5043471513560016

Epoch: 6| Step: 13
Training loss: 2.8215836384051465
Validation loss: 2.5425852106448685

Epoch: 238| Step: 0
Training loss: 2.544504009847092
Validation loss: 2.5463607000055717

Epoch: 6| Step: 1
Training loss: 3.0354047793799457
Validation loss: 2.5329214401457487

Epoch: 6| Step: 2
Training loss: 2.521441730401635
Validation loss: 2.5295825562050003

Epoch: 6| Step: 3
Training loss: 3.246316436217014
Validation loss: 2.5105467013639395

Epoch: 6| Step: 4
Training loss: 2.545934679060947
Validation loss: 2.5150805529820075

Epoch: 6| Step: 5
Training loss: 2.4787189709851303
Validation loss: 2.523339940206305

Epoch: 6| Step: 6
Training loss: 1.9372620590293441
Validation loss: 2.53453072958519

Epoch: 6| Step: 7
Training loss: 2.5773701805477818
Validation loss: 2.514875890120475

Epoch: 6| Step: 8
Training loss: 2.4479335594947096
Validation loss: 2.56397121243668

Epoch: 6| Step: 9
Training loss: 2.3699553268986655
Validation loss: 2.565696617324868

Epoch: 6| Step: 10
Training loss: 2.7624935374464847
Validation loss: 2.5317293607260525

Epoch: 6| Step: 11
Training loss: 2.3100603999048372
Validation loss: 2.5264332679088652

Epoch: 6| Step: 12
Training loss: 2.3175114122951292
Validation loss: 2.5261901006715988

Epoch: 6| Step: 13
Training loss: 2.8610218079424805
Validation loss: 2.5352755436861067

Epoch: 239| Step: 0
Training loss: 2.094833662945327
Validation loss: 2.5890522032451715

Epoch: 6| Step: 1
Training loss: 2.9823615986766647
Validation loss: 2.5620802308665733

Epoch: 6| Step: 2
Training loss: 2.257895075466078
Validation loss: 2.5617543638112488

Epoch: 6| Step: 3
Training loss: 2.8872491042221387
Validation loss: 2.5079478233509773

Epoch: 6| Step: 4
Training loss: 2.8342826786167836
Validation loss: 2.491259838620939

Epoch: 6| Step: 5
Training loss: 3.015278692570899
Validation loss: 2.54363062961645

Epoch: 6| Step: 6
Training loss: 2.412473186284614
Validation loss: 2.565397725605559

Epoch: 6| Step: 7
Training loss: 2.52616786576002
Validation loss: 2.517070398589474

Epoch: 6| Step: 8
Training loss: 2.3276609431919377
Validation loss: 2.5444428465562146

Epoch: 6| Step: 9
Training loss: 2.9218446454598075
Validation loss: 2.582953984581139

Epoch: 6| Step: 10
Training loss: 1.994639723712252
Validation loss: 2.5310448984141036

Epoch: 6| Step: 11
Training loss: 2.424210339211058
Validation loss: 2.522502518070501

Epoch: 6| Step: 12
Training loss: 2.9852779280766018
Validation loss: 2.550304494231836

Epoch: 6| Step: 13
Training loss: 2.1953136946379646
Validation loss: 2.5284498174717953

Epoch: 240| Step: 0
Training loss: 2.754873206099212
Validation loss: 2.558545028121182

Epoch: 6| Step: 1
Training loss: 2.6329640874039817
Validation loss: 2.559638168337505

Epoch: 6| Step: 2
Training loss: 2.8412071848444835
Validation loss: 2.555351948381249

Epoch: 6| Step: 3
Training loss: 2.635970850237768
Validation loss: 2.4991511595852387

Epoch: 6| Step: 4
Training loss: 2.4590727992441423
Validation loss: 2.5182342642925644

Epoch: 6| Step: 5
Training loss: 1.9303974899546006
Validation loss: 2.5214232023530263

Epoch: 6| Step: 6
Training loss: 2.1326566646222536
Validation loss: 2.522816333584596

Epoch: 6| Step: 7
Training loss: 2.6944480504889023
Validation loss: 2.5763998166729944

Epoch: 6| Step: 8
Training loss: 2.7553552156944376
Validation loss: 2.5735903518850374

Epoch: 6| Step: 9
Training loss: 2.82794053967244
Validation loss: 2.510248917353491

Epoch: 6| Step: 10
Training loss: 2.2202227365602227
Validation loss: 2.5745547256789663

Epoch: 6| Step: 11
Training loss: 2.970591084651658
Validation loss: 2.545173423372489

Epoch: 6| Step: 12
Training loss: 2.2838205982439557
Validation loss: 2.557001253329347

Epoch: 6| Step: 13
Training loss: 1.7099023762102425
Validation loss: 2.5325833379926483

Epoch: 241| Step: 0
Training loss: 1.9931214779870252
Validation loss: 2.5252812406306235

Epoch: 6| Step: 1
Training loss: 2.618914498418078
Validation loss: 2.5256916283571083

Epoch: 6| Step: 2
Training loss: 2.8868494068769572
Validation loss: 2.5472013816870045

Epoch: 6| Step: 3
Training loss: 2.2804240991782727
Validation loss: 2.5219159026810707

Epoch: 6| Step: 4
Training loss: 2.6234607725037025
Validation loss: 2.52922996679242

Epoch: 6| Step: 5
Training loss: 2.7399612475529724
Validation loss: 2.4835969915725205

Epoch: 6| Step: 6
Training loss: 2.5460744898612773
Validation loss: 2.533008071757847

Epoch: 6| Step: 7
Training loss: 2.643922451157442
Validation loss: 2.5176862026189957

Epoch: 6| Step: 8
Training loss: 2.6407945567211595
Validation loss: 2.5306722654428127

Epoch: 6| Step: 9
Training loss: 2.9078802643043544
Validation loss: 2.5336416095259

Epoch: 6| Step: 10
Training loss: 1.825552736476105
Validation loss: 2.5295776723176893

Epoch: 6| Step: 11
Training loss: 2.5092096447650274
Validation loss: 2.4750107486641024

Epoch: 6| Step: 12
Training loss: 2.6629453761149278
Validation loss: 2.5602588191956

Epoch: 6| Step: 13
Training loss: 2.8457376429572605
Validation loss: 2.540588415130415

Epoch: 242| Step: 0
Training loss: 2.425021090858217
Validation loss: 2.5374961283591753

Epoch: 6| Step: 1
Training loss: 2.129269294231229
Validation loss: 2.553404422959583

Epoch: 6| Step: 2
Training loss: 2.3043844767355712
Validation loss: 2.5276477668462944

Epoch: 6| Step: 3
Training loss: 2.7566486096357723
Validation loss: 2.575948407583431

Epoch: 6| Step: 4
Training loss: 2.962811765080234
Validation loss: 2.5659215930279196

Epoch: 6| Step: 5
Training loss: 2.2749162302209514
Validation loss: 2.5863739885503914

Epoch: 6| Step: 6
Training loss: 2.953551569410791
Validation loss: 2.5136755424814607

Epoch: 6| Step: 7
Training loss: 2.737028306011192
Validation loss: 2.5440937143105358

Epoch: 6| Step: 8
Training loss: 2.902005284983517
Validation loss: 2.5258961151750254

Epoch: 6| Step: 9
Training loss: 2.20773558054066
Validation loss: 2.535255887123084

Epoch: 6| Step: 10
Training loss: 2.991773133433348
Validation loss: 2.5268384855045536

Epoch: 6| Step: 11
Training loss: 2.1844967525752286
Validation loss: 2.526040808412495

Epoch: 6| Step: 12
Training loss: 2.1469146325063835
Validation loss: 2.520042916551162

Epoch: 6| Step: 13
Training loss: 2.644562263250571
Validation loss: 2.5356176773527657

Epoch: 243| Step: 0
Training loss: 2.7614122622654413
Validation loss: 2.4874076090660964

Epoch: 6| Step: 1
Training loss: 2.2059787097156005
Validation loss: 2.532829166806491

Epoch: 6| Step: 2
Training loss: 2.3608606978622633
Validation loss: 2.550191211428153

Epoch: 6| Step: 3
Training loss: 1.947867496570274
Validation loss: 2.5652809579775204

Epoch: 6| Step: 4
Training loss: 3.2744452261415926
Validation loss: 2.5020478751716477

Epoch: 6| Step: 5
Training loss: 3.175132844804028
Validation loss: 2.5258443038322778

Epoch: 6| Step: 6
Training loss: 2.3668150152357104
Validation loss: 2.5467469101209383

Epoch: 6| Step: 7
Training loss: 2.3326627812309138
Validation loss: 2.5059280437891394

Epoch: 6| Step: 8
Training loss: 2.9796607045817667
Validation loss: 2.5190235849721785

Epoch: 6| Step: 9
Training loss: 2.456460907789457
Validation loss: 2.5131842175269727

Epoch: 6| Step: 10
Training loss: 2.512437305332477
Validation loss: 2.529029647159987

Epoch: 6| Step: 11
Training loss: 2.1718249418129583
Validation loss: 2.527578937069584

Epoch: 6| Step: 12
Training loss: 2.4915368836283496
Validation loss: 2.5386839467855933

Epoch: 6| Step: 13
Training loss: 2.4593586049872442
Validation loss: 2.5159357401667672

Epoch: 244| Step: 0
Training loss: 2.505972308901712
Validation loss: 2.5178076843565034

Epoch: 6| Step: 1
Training loss: 2.3367385766486897
Validation loss: 2.530987333855874

Epoch: 6| Step: 2
Training loss: 2.9120419121545162
Validation loss: 2.5012259769013254

Epoch: 6| Step: 3
Training loss: 3.053627708381702
Validation loss: 2.592890656759241

Epoch: 6| Step: 4
Training loss: 2.10559070354282
Validation loss: 2.5266222086353505

Epoch: 6| Step: 5
Training loss: 2.2743373282998167
Validation loss: 2.5692982908581574

Epoch: 6| Step: 6
Training loss: 2.505941293021168
Validation loss: 2.541317016164369

Epoch: 6| Step: 7
Training loss: 2.5960289927834146
Validation loss: 2.5404802668817514

Epoch: 6| Step: 8
Training loss: 2.4472710806503435
Validation loss: 2.5674384017530096

Epoch: 6| Step: 9
Training loss: 3.138398705151262
Validation loss: 2.5248113039625917

Epoch: 6| Step: 10
Training loss: 2.799692791025668
Validation loss: 2.5314284595579717

Epoch: 6| Step: 11
Training loss: 2.4034784382026966
Validation loss: 2.5788391496418424

Epoch: 6| Step: 12
Training loss: 1.9791123299083206
Validation loss: 2.530277557115763

Epoch: 6| Step: 13
Training loss: 1.7611109325771195
Validation loss: 2.534952929865303

Epoch: 245| Step: 0
Training loss: 2.363194891242392
Validation loss: 2.510605853749016

Epoch: 6| Step: 1
Training loss: 2.82231833860806
Validation loss: 2.5312478285638003

Epoch: 6| Step: 2
Training loss: 2.5026345676212367
Validation loss: 2.523344008151597

Epoch: 6| Step: 3
Training loss: 2.4620325951978974
Validation loss: 2.509115911924109

Epoch: 6| Step: 4
Training loss: 2.301013151181805
Validation loss: 2.5238508909873407

Epoch: 6| Step: 5
Training loss: 2.2699696942965786
Validation loss: 2.5841337914533145

Epoch: 6| Step: 6
Training loss: 2.4396737993788205
Validation loss: 2.548848053568215

Epoch: 6| Step: 7
Training loss: 2.29140313685115
Validation loss: 2.5541154383331577

Epoch: 6| Step: 8
Training loss: 2.979237553391158
Validation loss: 2.5299871057440146

Epoch: 6| Step: 9
Training loss: 3.027912465481888
Validation loss: 2.545396871243666

Epoch: 6| Step: 10
Training loss: 2.212465007957863
Validation loss: 2.524052368664245

Epoch: 6| Step: 11
Training loss: 2.7815897873329773
Validation loss: 2.560266475283666

Epoch: 6| Step: 12
Training loss: 2.6931614350080553
Validation loss: 2.5655882819183726

Epoch: 6| Step: 13
Training loss: 2.588763764113191
Validation loss: 2.539960278986998

Epoch: 246| Step: 0
Training loss: 2.4674548844345607
Validation loss: 2.535957499398887

Epoch: 6| Step: 1
Training loss: 2.5888591753282753
Validation loss: 2.5717597450459104

Epoch: 6| Step: 2
Training loss: 2.6261767519976935
Validation loss: 2.517828570169488

Epoch: 6| Step: 3
Training loss: 2.8513538022945126
Validation loss: 2.499599515462415

Epoch: 6| Step: 4
Training loss: 2.16263001332265
Validation loss: 2.571656107174625

Epoch: 6| Step: 5
Training loss: 3.03821495025012
Validation loss: 2.5096404105555523

Epoch: 6| Step: 6
Training loss: 1.9052354583005093
Validation loss: 2.5181954332353937

Epoch: 6| Step: 7
Training loss: 2.256525326147789
Validation loss: 2.5000006050191166

Epoch: 6| Step: 8
Training loss: 2.8159053955009092
Validation loss: 2.5510711065527873

Epoch: 6| Step: 9
Training loss: 2.6704776076717387
Validation loss: 2.512040235446455

Epoch: 6| Step: 10
Training loss: 2.265630051179714
Validation loss: 2.5847266046001263

Epoch: 6| Step: 11
Training loss: 2.6481488726046067
Validation loss: 2.501788024457843

Epoch: 6| Step: 12
Training loss: 2.730455914250275
Validation loss: 2.5908365334741736

Epoch: 6| Step: 13
Training loss: 2.246790716423535
Validation loss: 2.542350674650068

Epoch: 247| Step: 0
Training loss: 2.1758670481779063
Validation loss: 2.528276719531249

Epoch: 6| Step: 1
Training loss: 2.412450159378298
Validation loss: 2.5243216782529543

Epoch: 6| Step: 2
Training loss: 2.190751520222719
Validation loss: 2.5660693423128103

Epoch: 6| Step: 3
Training loss: 2.291710893608802
Validation loss: 2.588619881098211

Epoch: 6| Step: 4
Training loss: 1.9338156832862403
Validation loss: 2.5414560631844427

Epoch: 6| Step: 5
Training loss: 2.1796654047239206
Validation loss: 2.5673689207403303

Epoch: 6| Step: 6
Training loss: 3.2462375576881035
Validation loss: 2.533504600623874

Epoch: 6| Step: 7
Training loss: 2.1699409930385305
Validation loss: 2.541794812182726

Epoch: 6| Step: 8
Training loss: 3.0030117811441284
Validation loss: 2.4769837953505416

Epoch: 6| Step: 9
Training loss: 1.9622083094854743
Validation loss: 2.52395189871791

Epoch: 6| Step: 10
Training loss: 2.8267660511587085
Validation loss: 2.498969133170763

Epoch: 6| Step: 11
Training loss: 3.218333985934265
Validation loss: 2.5192827187846722

Epoch: 6| Step: 12
Training loss: 2.775996701065434
Validation loss: 2.5525392354087573

Epoch: 6| Step: 13
Training loss: 2.921611100789318
Validation loss: 2.6021921448502887

Epoch: 248| Step: 0
Training loss: 2.617127192926916
Validation loss: 2.476455577994148

Epoch: 6| Step: 1
Training loss: 2.266427575385495
Validation loss: 2.5286642799039587

Epoch: 6| Step: 2
Training loss: 1.809840981363522
Validation loss: 2.5140572311403364

Epoch: 6| Step: 3
Training loss: 2.4018919481150522
Validation loss: 2.518018474206691

Epoch: 6| Step: 4
Training loss: 2.490935390760098
Validation loss: 2.507020807143346

Epoch: 6| Step: 5
Training loss: 2.4456396889483085
Validation loss: 2.521498245040087

Epoch: 6| Step: 6
Training loss: 2.596594663836965
Validation loss: 2.535038313909751

Epoch: 6| Step: 7
Training loss: 2.600077895684887
Validation loss: 2.5392622260333804

Epoch: 6| Step: 8
Training loss: 2.9696141641628433
Validation loss: 2.514291416832321

Epoch: 6| Step: 9
Training loss: 3.070361265615433
Validation loss: 2.485580827601151

Epoch: 6| Step: 10
Training loss: 2.4181423833621043
Validation loss: 2.5233330661359945

Epoch: 6| Step: 11
Training loss: 2.910466242927532
Validation loss: 2.5290618476879962

Epoch: 6| Step: 12
Training loss: 2.1743279745264066
Validation loss: 2.542197274637787

Epoch: 6| Step: 13
Training loss: 2.279960476884098
Validation loss: 2.5380989612897213

Epoch: 249| Step: 0
Training loss: 2.3604352981177734
Validation loss: 2.5873326354104713

Epoch: 6| Step: 1
Training loss: 2.6087632975584403
Validation loss: 2.5585111009615384

Epoch: 6| Step: 2
Training loss: 2.2554826694398598
Validation loss: 2.564035101402216

Epoch: 6| Step: 3
Training loss: 2.6296501750869754
Validation loss: 2.5174465189754507

Epoch: 6| Step: 4
Training loss: 2.734905256900354
Validation loss: 2.509077108337375

Epoch: 6| Step: 5
Training loss: 2.8782494467339887
Validation loss: 2.5573319013271787

Epoch: 6| Step: 6
Training loss: 2.2078793136951065
Validation loss: 2.546992472552735

Epoch: 6| Step: 7
Training loss: 2.3381543309529427
Validation loss: 2.507736595921086

Epoch: 6| Step: 8
Training loss: 2.4303800816242727
Validation loss: 2.5756366155045716

Epoch: 6| Step: 9
Training loss: 2.8283817743736233
Validation loss: 2.563172421993975

Epoch: 6| Step: 10
Training loss: 2.5340958597948973
Validation loss: 2.5501142344341963

Epoch: 6| Step: 11
Training loss: 2.0905852811544285
Validation loss: 2.550446123077502

Epoch: 6| Step: 12
Training loss: 3.0836401778119025
Validation loss: 2.5535831513637275

Epoch: 6| Step: 13
Training loss: 2.059568228795176
Validation loss: 2.489816746783987

Epoch: 250| Step: 0
Training loss: 2.376404999198336
Validation loss: 2.5289362535784465

Epoch: 6| Step: 1
Training loss: 2.0170136628716566
Validation loss: 2.528825658044826

Epoch: 6| Step: 2
Training loss: 2.62717601865726
Validation loss: 2.5143872712047064

Epoch: 6| Step: 3
Training loss: 2.493557066373601
Validation loss: 2.578083609518779

Epoch: 6| Step: 4
Training loss: 2.815042321545935
Validation loss: 2.529005103688016

Epoch: 6| Step: 5
Training loss: 2.4931593766786655
Validation loss: 2.517522209726048

Epoch: 6| Step: 6
Training loss: 2.944110331582573
Validation loss: 2.5470667417778277

Epoch: 6| Step: 7
Training loss: 2.667163822401951
Validation loss: 2.562923199362902

Epoch: 6| Step: 8
Training loss: 2.8970150811853284
Validation loss: 2.5155870591063394

Epoch: 6| Step: 9
Training loss: 2.230023608574538
Validation loss: 2.5244912981281633

Epoch: 6| Step: 10
Training loss: 2.489012414652239
Validation loss: 2.5712261494244197

Epoch: 6| Step: 11
Training loss: 2.6175724486605554
Validation loss: 2.5004186597588474

Epoch: 6| Step: 12
Training loss: 2.6264796854973156
Validation loss: 2.5937417647083625

Epoch: 6| Step: 13
Training loss: 2.1395130471555848
Validation loss: 2.526767182934309

Testing loss: 2.6317027745700066
