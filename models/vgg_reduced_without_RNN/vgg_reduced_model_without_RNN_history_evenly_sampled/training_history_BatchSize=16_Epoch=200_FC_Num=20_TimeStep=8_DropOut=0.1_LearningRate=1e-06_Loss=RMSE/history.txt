Epoch: 1| Step: 0
Training loss: 5.3441220873403905
Validation loss: 5.915037733662948

Epoch: 6| Step: 1
Training loss: 6.4686550557268445
Validation loss: 5.91175919652978

Epoch: 6| Step: 2
Training loss: 5.832979609346056
Validation loss: 5.908813343948263

Epoch: 6| Step: 3
Training loss: 5.8954087319040855
Validation loss: 5.9067678507195085

Epoch: 6| Step: 4
Training loss: 6.075348129030633
Validation loss: 5.903721152709729

Epoch: 6| Step: 5
Training loss: 6.032274228426901
Validation loss: 5.902901550127734

Epoch: 6| Step: 6
Training loss: 6.495529398027887
Validation loss: 5.897926630612792

Epoch: 6| Step: 7
Training loss: 6.672290655048625
Validation loss: 5.896769552304628

Epoch: 6| Step: 8
Training loss: 4.216923975475655
Validation loss: 5.89370133752181

Epoch: 6| Step: 9
Training loss: 5.712732369602919
Validation loss: 5.89065613113759

Epoch: 6| Step: 10
Training loss: 6.091257377822012
Validation loss: 5.889196239194567

Epoch: 6| Step: 11
Training loss: 5.67961361927533
Validation loss: 5.885749004134408

Epoch: 6| Step: 12
Training loss: 6.261114385213431
Validation loss: 5.883884204790873

Epoch: 6| Step: 13
Training loss: 5.728742364141281
Validation loss: 5.88152426954048

Epoch: 2| Step: 0
Training loss: 5.491812767821445
Validation loss: 5.879963708625632

Epoch: 6| Step: 1
Training loss: 6.706129134511951
Validation loss: 5.876049044961759

Epoch: 6| Step: 2
Training loss: 5.140779347986792
Validation loss: 5.872417866076821

Epoch: 6| Step: 3
Training loss: 6.100496440760413
Validation loss: 5.869412325784176

Epoch: 6| Step: 4
Training loss: 6.303552915452535
Validation loss: 5.868753156630888

Epoch: 6| Step: 5
Training loss: 6.408427840562403
Validation loss: 5.864848655813452

Epoch: 6| Step: 6
Training loss: 5.597427608401812
Validation loss: 5.861129651590062

Epoch: 6| Step: 7
Training loss: 5.762438381966182
Validation loss: 5.859276891399744

Epoch: 6| Step: 8
Training loss: 5.313270064248077
Validation loss: 5.857364371370967

Epoch: 6| Step: 9
Training loss: 6.078264641812513
Validation loss: 5.8546793951121865

Epoch: 6| Step: 10
Training loss: 4.896263114516239
Validation loss: 5.8519462210896895

Epoch: 6| Step: 11
Training loss: 6.26176870496293
Validation loss: 5.848781274408602

Epoch: 6| Step: 12
Training loss: 6.615655030266631
Validation loss: 5.847271752832354

Epoch: 6| Step: 13
Training loss: 5.1125345989073185
Validation loss: 5.844702931992512

Epoch: 3| Step: 0
Training loss: 5.32451608097694
Validation loss: 5.840478988549394

Epoch: 6| Step: 1
Training loss: 6.393223465077226
Validation loss: 5.837390709775514

Epoch: 6| Step: 2
Training loss: 6.540373202533474
Validation loss: 5.835577675718536

Epoch: 6| Step: 3
Training loss: 5.922038617050377
Validation loss: 5.832336749662172

Epoch: 6| Step: 4
Training loss: 5.945049104608066
Validation loss: 5.829505502443896

Epoch: 6| Step: 5
Training loss: 5.2721591332460305
Validation loss: 5.8286177049104255

Epoch: 6| Step: 6
Training loss: 6.3632905420243695
Validation loss: 5.82275480684216

Epoch: 6| Step: 7
Training loss: 5.050822978426329
Validation loss: 5.821689440360453

Epoch: 6| Step: 8
Training loss: 5.235772609590292
Validation loss: 5.815941507936605

Epoch: 6| Step: 9
Training loss: 5.5301762632454565
Validation loss: 5.81562975139699

Epoch: 6| Step: 10
Training loss: 5.915243093956131
Validation loss: 5.81086470664923

Epoch: 6| Step: 11
Training loss: 6.5483061835325795
Validation loss: 5.809106046511821

Epoch: 6| Step: 12
Training loss: 5.642140361934426
Validation loss: 5.804460144691554

Epoch: 6| Step: 13
Training loss: 6.080138042288287
Validation loss: 5.801755863839358

Epoch: 4| Step: 0
Training loss: 6.169627879094809
Validation loss: 5.7993637901511415

Epoch: 6| Step: 1
Training loss: 5.501052408966958
Validation loss: 5.795085509047152

Epoch: 6| Step: 2
Training loss: 6.677538145606894
Validation loss: 5.7924117663038155

Epoch: 6| Step: 3
Training loss: 5.635472192214565
Validation loss: 5.788014187187436

Epoch: 6| Step: 4
Training loss: 6.293975541165771
Validation loss: 5.784789157972866

Epoch: 6| Step: 5
Training loss: 5.219403802725767
Validation loss: 5.782013100167851

Epoch: 6| Step: 6
Training loss: 5.512110814479651
Validation loss: 5.77936653956589

Epoch: 6| Step: 7
Training loss: 6.038562196287913
Validation loss: 5.775934709608925

Epoch: 6| Step: 8
Training loss: 6.107774451667432
Validation loss: 5.771450609288452

Epoch: 6| Step: 9
Training loss: 5.856481707537611
Validation loss: 5.768225046395854

Epoch: 6| Step: 10
Training loss: 5.178741598856762
Validation loss: 5.7651887716367884

Epoch: 6| Step: 11
Training loss: 5.4804275086986225
Validation loss: 5.759060569788238

Epoch: 6| Step: 12
Training loss: 5.985353713518336
Validation loss: 5.756605355402572

Epoch: 6| Step: 13
Training loss: 5.161764813923886
Validation loss: 5.752290684067841

Epoch: 5| Step: 0
Training loss: 5.757210895470295
Validation loss: 5.748578170892894

Epoch: 6| Step: 1
Training loss: 5.499927173479138
Validation loss: 5.744590501018137

Epoch: 6| Step: 2
Training loss: 5.098966209501652
Validation loss: 5.740235148526827

Epoch: 6| Step: 3
Training loss: 5.007041931379034
Validation loss: 5.737811845756795

Epoch: 6| Step: 4
Training loss: 4.076552047511393
Validation loss: 5.7328524794021165

Epoch: 6| Step: 5
Training loss: 6.486284898512242
Validation loss: 5.730758536526386

Epoch: 6| Step: 6
Training loss: 4.937829115316802
Validation loss: 5.72436649836745

Epoch: 6| Step: 7
Training loss: 5.70503031636507
Validation loss: 5.721944460864435

Epoch: 6| Step: 8
Training loss: 5.943050961949437
Validation loss: 5.716757727843985

Epoch: 6| Step: 9
Training loss: 5.721763608922228
Validation loss: 5.715935873443315

Epoch: 6| Step: 10
Training loss: 6.149688477108293
Validation loss: 5.709064243134859

Epoch: 6| Step: 11
Training loss: 7.582479016595389
Validation loss: 5.7064608269280415

Epoch: 6| Step: 12
Training loss: 5.474748907036082
Validation loss: 5.7009021391261765

Epoch: 6| Step: 13
Training loss: 6.760470146669084
Validation loss: 5.6965530430623685

Epoch: 6| Step: 0
Training loss: 5.784466812501533
Validation loss: 5.694315821231051

Epoch: 6| Step: 1
Training loss: 4.989241469530632
Validation loss: 5.6894127641378125

Epoch: 6| Step: 2
Training loss: 6.1372837751101645
Validation loss: 5.683627615468565

Epoch: 6| Step: 3
Training loss: 5.32901360493543
Validation loss: 5.680415051033714

Epoch: 6| Step: 4
Training loss: 6.767948729480951
Validation loss: 5.673733974217333

Epoch: 6| Step: 5
Training loss: 4.677233426660019
Validation loss: 5.668658781624129

Epoch: 6| Step: 6
Training loss: 5.445423710698561
Validation loss: 5.665447718674947

Epoch: 6| Step: 7
Training loss: 4.653059922705392
Validation loss: 5.658434743989013

Epoch: 6| Step: 8
Training loss: 6.34585070475127
Validation loss: 5.65419809527646

Epoch: 6| Step: 9
Training loss: 5.52188507234597
Validation loss: 5.651213699050286

Epoch: 6| Step: 10
Training loss: 6.412076951734199
Validation loss: 5.644450723078129

Epoch: 6| Step: 11
Training loss: 6.1258544325911695
Validation loss: 5.638820199133669

Epoch: 6| Step: 12
Training loss: 5.620434243201616
Validation loss: 5.6321849297322695

Epoch: 6| Step: 13
Training loss: 5.2923959344679465
Validation loss: 5.629683357216685

Epoch: 7| Step: 0
Training loss: 5.830713101413591
Validation loss: 5.624060995647394

Epoch: 6| Step: 1
Training loss: 4.942751638733938
Validation loss: 5.618408484828917

Epoch: 6| Step: 2
Training loss: 4.6330092904557425
Validation loss: 5.6152732730069275

Epoch: 6| Step: 3
Training loss: 6.208286703391194
Validation loss: 5.610409959275531

Epoch: 6| Step: 4
Training loss: 5.947872698388094
Validation loss: 5.605282462421353

Epoch: 6| Step: 5
Training loss: 5.710291876873878
Validation loss: 5.598233335869386

Epoch: 6| Step: 6
Training loss: 5.417204942611899
Validation loss: 5.5934456427199395

Epoch: 6| Step: 7
Training loss: 5.9727035131387005
Validation loss: 5.589012315251729

Epoch: 6| Step: 8
Training loss: 6.645735051336202
Validation loss: 5.582792263540149

Epoch: 6| Step: 9
Training loss: 4.7575501117482615
Validation loss: 5.5742565820931596

Epoch: 6| Step: 10
Training loss: 5.519599671152353
Validation loss: 5.569748689942619

Epoch: 6| Step: 11
Training loss: 6.511177136575031
Validation loss: 5.562246956807043

Epoch: 6| Step: 12
Training loss: 5.67532353088137
Validation loss: 5.55907523624575

Epoch: 6| Step: 13
Training loss: 3.3016662494698314
Validation loss: 5.554506343838229

Epoch: 8| Step: 0
Training loss: 5.744224301286147
Validation loss: 5.548742318950607

Epoch: 6| Step: 1
Training loss: 6.702386277403253
Validation loss: 5.540031341085589

Epoch: 6| Step: 2
Training loss: 4.837464419685043
Validation loss: 5.5357166588747315

Epoch: 6| Step: 3
Training loss: 5.499049538069607
Validation loss: 5.528360494443378

Epoch: 6| Step: 4
Training loss: 5.483106678430204
Validation loss: 5.523873960566318

Epoch: 6| Step: 5
Training loss: 5.689037743912423
Validation loss: 5.517554722390659

Epoch: 6| Step: 6
Training loss: 5.495685098580411
Validation loss: 5.511480101991232

Epoch: 6| Step: 7
Training loss: 5.869522788098686
Validation loss: 5.501815086212485

Epoch: 6| Step: 8
Training loss: 4.786086086316748
Validation loss: 5.4979859222709475

Epoch: 6| Step: 9
Training loss: 5.492254872675319
Validation loss: 5.489900099033689

Epoch: 6| Step: 10
Training loss: 4.7628023387028895
Validation loss: 5.484141287755313

Epoch: 6| Step: 11
Training loss: 5.736108003522612
Validation loss: 5.479490801695574

Epoch: 6| Step: 12
Training loss: 5.460115777489418
Validation loss: 5.469717146383104

Epoch: 6| Step: 13
Training loss: 5.919407957217077
Validation loss: 5.464867811797922

Epoch: 9| Step: 0
Training loss: 4.647789353776179
Validation loss: 5.45773153299513

Epoch: 6| Step: 1
Training loss: 5.449027809434741
Validation loss: 5.454127746431635

Epoch: 6| Step: 2
Training loss: 4.807734520360054
Validation loss: 5.4473468549426896

Epoch: 6| Step: 3
Training loss: 5.611975446966817
Validation loss: 5.437970456148491

Epoch: 6| Step: 4
Training loss: 4.7725213852768436
Validation loss: 5.432441041203256

Epoch: 6| Step: 5
Training loss: 5.804009912715047
Validation loss: 5.420751302190082

Epoch: 6| Step: 6
Training loss: 5.303862067878746
Validation loss: 5.414452389702909

Epoch: 6| Step: 7
Training loss: 6.380270779881476
Validation loss: 5.4075937426233205

Epoch: 6| Step: 8
Training loss: 6.197198837983174
Validation loss: 5.400682801618798

Epoch: 6| Step: 9
Training loss: 5.456194431856572
Validation loss: 5.390069314601271

Epoch: 6| Step: 10
Training loss: 4.397664030918348
Validation loss: 5.380990603214121

Epoch: 6| Step: 11
Training loss: 5.645150099888271
Validation loss: 5.373218917607684

Epoch: 6| Step: 12
Training loss: 5.655357332550959
Validation loss: 5.366382827595291

Epoch: 6| Step: 13
Training loss: 5.970840487461459
Validation loss: 5.359668513299063

Epoch: 10| Step: 0
Training loss: 5.364681719522811
Validation loss: 5.347027254201442

Epoch: 6| Step: 1
Training loss: 5.784997993277661
Validation loss: 5.340760713317479

Epoch: 6| Step: 2
Training loss: 5.582152379338746
Validation loss: 5.329595214578888

Epoch: 6| Step: 3
Training loss: 5.527727460179585
Validation loss: 5.323977679774568

Epoch: 6| Step: 4
Training loss: 5.637631454119326
Validation loss: 5.318678712329153

Epoch: 6| Step: 5
Training loss: 5.433101234081267
Validation loss: 5.304898085328752

Epoch: 6| Step: 6
Training loss: 6.056434034891666
Validation loss: 5.297310074690231

Epoch: 6| Step: 7
Training loss: 5.529652165377888
Validation loss: 5.289982324255841

Epoch: 6| Step: 8
Training loss: 5.175548343816304
Validation loss: 5.278883440010788

Epoch: 6| Step: 9
Training loss: 5.000766313956956
Validation loss: 5.268320020962675

Epoch: 6| Step: 10
Training loss: 4.9821219299783195
Validation loss: 5.256647558934778

Epoch: 6| Step: 11
Training loss: 4.273985330730535
Validation loss: 5.247164316417959

Epoch: 6| Step: 12
Training loss: 3.9841090693270367
Validation loss: 5.240650428533538

Epoch: 6| Step: 13
Training loss: 6.345917730673982
Validation loss: 5.228349582693247

Epoch: 11| Step: 0
Training loss: 5.481924351757207
Validation loss: 5.221346501956036

Epoch: 6| Step: 1
Training loss: 5.851836948044939
Validation loss: 5.20457201134401

Epoch: 6| Step: 2
Training loss: 5.204461186761492
Validation loss: 5.1990882532525475

Epoch: 6| Step: 3
Training loss: 5.777003692874055
Validation loss: 5.187503649140394

Epoch: 6| Step: 4
Training loss: 4.637983501554674
Validation loss: 5.173467383221573

Epoch: 6| Step: 5
Training loss: 5.371502825331014
Validation loss: 5.168249744471958

Epoch: 6| Step: 6
Training loss: 5.149142643940967
Validation loss: 5.1501567696846395

Epoch: 6| Step: 7
Training loss: 4.171670858696297
Validation loss: 5.145774717753936

Epoch: 6| Step: 8
Training loss: 4.89072639920841
Validation loss: 5.133653743467743

Epoch: 6| Step: 9
Training loss: 4.528961656148275
Validation loss: 5.1209509576921795

Epoch: 6| Step: 10
Training loss: 5.482400131046567
Validation loss: 5.112978923585707

Epoch: 6| Step: 11
Training loss: 5.399316476018342
Validation loss: 5.102084873649627

Epoch: 6| Step: 12
Training loss: 4.898199973058901
Validation loss: 5.0886067728350985

Epoch: 6| Step: 13
Training loss: 5.894196659448504
Validation loss: 5.0824849661260885

Epoch: 12| Step: 0
Training loss: 5.50716384422851
Validation loss: 5.0710924546850755

Epoch: 6| Step: 1
Training loss: 5.535252561518743
Validation loss: 5.052703954619819

Epoch: 6| Step: 2
Training loss: 5.4542913637800705
Validation loss: 5.043371803938298

Epoch: 6| Step: 3
Training loss: 4.636078222264912
Validation loss: 5.025642953120106

Epoch: 6| Step: 4
Training loss: 4.864852124561204
Validation loss: 5.015504944150695

Epoch: 6| Step: 5
Training loss: 6.131956859598615
Validation loss: 5.005985803461424

Epoch: 6| Step: 6
Training loss: 5.469071209874821
Validation loss: 4.994507888619175

Epoch: 6| Step: 7
Training loss: 4.895513754079528
Validation loss: 4.97741652533893

Epoch: 6| Step: 8
Training loss: 4.137988132598069
Validation loss: 4.964128186276439

Epoch: 6| Step: 9
Training loss: 5.208318094867031
Validation loss: 4.9451659529047465

Epoch: 6| Step: 10
Training loss: 3.1570688828356657
Validation loss: 4.937469359791272

Epoch: 6| Step: 11
Training loss: 5.763733757821807
Validation loss: 4.920252653808451

Epoch: 6| Step: 12
Training loss: 4.110342165772402
Validation loss: 4.9073828340431405

Epoch: 6| Step: 13
Training loss: 4.641572078560628
Validation loss: 4.886457905001702

Epoch: 13| Step: 0
Training loss: 5.909386180623017
Validation loss: 4.887686155611676

Epoch: 6| Step: 1
Training loss: 5.0751550058830945
Validation loss: 4.8684131832535025

Epoch: 6| Step: 2
Training loss: 3.96804647142362
Validation loss: 4.84962488492877

Epoch: 6| Step: 3
Training loss: 3.8389925163575684
Validation loss: 4.837825863356824

Epoch: 6| Step: 4
Training loss: 5.132824205359085
Validation loss: 4.825488730524377

Epoch: 6| Step: 5
Training loss: 5.262940217586242
Validation loss: 4.81344600308262

Epoch: 6| Step: 6
Training loss: 5.582131194707515
Validation loss: 4.797227866893818

Epoch: 6| Step: 7
Training loss: 4.166761371807827
Validation loss: 4.783612779450492

Epoch: 6| Step: 8
Training loss: 4.89949357666068
Validation loss: 4.768875102065232

Epoch: 6| Step: 9
Training loss: 3.718095353149882
Validation loss: 4.750089004451281

Epoch: 6| Step: 10
Training loss: 5.3957171728329225
Validation loss: 4.7325368392775315

Epoch: 6| Step: 11
Training loss: 5.33542202739851
Validation loss: 4.709810602184818

Epoch: 6| Step: 12
Training loss: 3.8074178122493585
Validation loss: 4.702034766078564

Epoch: 6| Step: 13
Training loss: 5.177687591145675
Validation loss: 4.682756693255515

Epoch: 14| Step: 0
Training loss: 5.494604411859171
Validation loss: 4.668965318861997

Epoch: 6| Step: 1
Training loss: 4.267265032493757
Validation loss: 4.649152948822518

Epoch: 6| Step: 2
Training loss: 5.042672028148537
Validation loss: 4.638693211211188

Epoch: 6| Step: 3
Training loss: 5.186470756916838
Validation loss: 4.615344333012752

Epoch: 6| Step: 4
Training loss: 3.882756008297547
Validation loss: 4.601323817456396

Epoch: 6| Step: 5
Training loss: 4.539469242748471
Validation loss: 4.581173943899998

Epoch: 6| Step: 6
Training loss: 5.259019642258075
Validation loss: 4.568114333293112

Epoch: 6| Step: 7
Training loss: 3.2506320045423593
Validation loss: 4.538834484198341

Epoch: 6| Step: 8
Training loss: 4.299410650984711
Validation loss: 4.526670596911663

Epoch: 6| Step: 9
Training loss: 3.555647299165716
Validation loss: 4.516116145404179

Epoch: 6| Step: 10
Training loss: 3.9664489803901533
Validation loss: 4.496207159933121

Epoch: 6| Step: 11
Training loss: 4.753093314582506
Validation loss: 4.472419111943208

Epoch: 6| Step: 12
Training loss: 5.533731539695251
Validation loss: 4.456758149385159

Epoch: 6| Step: 13
Training loss: 5.187542650897707
Validation loss: 4.437485935917402

Epoch: 15| Step: 0
Training loss: 4.696968789347601
Validation loss: 4.424723400983864

Epoch: 6| Step: 1
Training loss: 3.075524640491443
Validation loss: 4.401390955486822

Epoch: 6| Step: 2
Training loss: 3.67174305780232
Validation loss: 4.387863152938577

Epoch: 6| Step: 3
Training loss: 4.915082040375628
Validation loss: 4.356033870808396

Epoch: 6| Step: 4
Training loss: 3.8335567630392973
Validation loss: 4.349579926338458

Epoch: 6| Step: 5
Training loss: 3.70471685133255
Validation loss: 4.320034237471117

Epoch: 6| Step: 6
Training loss: 4.368217005708389
Validation loss: 4.303552062759142

Epoch: 6| Step: 7
Training loss: 5.008827808785845
Validation loss: 4.285798525678177

Epoch: 6| Step: 8
Training loss: 4.80755480056134
Validation loss: 4.253644879857547

Epoch: 6| Step: 9
Training loss: 4.250585627879015
Validation loss: 4.237412007655736

Epoch: 6| Step: 10
Training loss: 5.028927663935591
Validation loss: 4.2162347062516545

Epoch: 6| Step: 11
Training loss: 4.434127600706333
Validation loss: 4.203757288566194

Epoch: 6| Step: 12
Training loss: 4.267502144632544
Validation loss: 4.183226656479987

Epoch: 6| Step: 13
Training loss: 4.755081069207069
Validation loss: 4.164441243296817

Epoch: 16| Step: 0
Training loss: 3.8886561793379877
Validation loss: 4.13305559258907

Epoch: 6| Step: 1
Training loss: 3.2264937792980666
Validation loss: 4.110760064247852

Epoch: 6| Step: 2
Training loss: 4.6245356146189325
Validation loss: 4.085745609766925

Epoch: 6| Step: 3
Training loss: 5.139379657760415
Validation loss: 4.068159359502929

Epoch: 6| Step: 4
Training loss: 4.161958144835822
Validation loss: 4.048267885770321

Epoch: 6| Step: 5
Training loss: 4.594439188841325
Validation loss: 4.022428483179843

Epoch: 6| Step: 6
Training loss: 4.654756857056599
Validation loss: 3.989330415567971

Epoch: 6| Step: 7
Training loss: 4.257641374141413
Validation loss: 3.9761046603305994

Epoch: 6| Step: 8
Training loss: 4.821872452582566
Validation loss: 3.949358229386605

Epoch: 6| Step: 9
Training loss: 3.476200110589479
Validation loss: 3.9123599034194

Epoch: 6| Step: 10
Training loss: 2.9076908600632416
Validation loss: 3.9017730561324067

Epoch: 6| Step: 11
Training loss: 3.6652451418381373
Validation loss: 3.8728900832366264

Epoch: 6| Step: 12
Training loss: 3.747590626135495
Validation loss: 3.8610137785440997

Epoch: 6| Step: 13
Training loss: 2.799355882399243
Validation loss: 3.844250623487766

Epoch: 17| Step: 0
Training loss: 4.20150124195593
Validation loss: 3.8057813128091675

Epoch: 6| Step: 1
Training loss: 2.8940598983102137
Validation loss: 3.7818922261713888

Epoch: 6| Step: 2
Training loss: 4.5006569276897475
Validation loss: 3.7682100774560423

Epoch: 6| Step: 3
Training loss: 4.575094945370563
Validation loss: 3.7396710606295986

Epoch: 6| Step: 4
Training loss: 2.7019116980738347
Validation loss: 3.7153666750950256

Epoch: 6| Step: 5
Training loss: 3.713004923691119
Validation loss: 3.6973414406834775

Epoch: 6| Step: 6
Training loss: 3.4473926034510636
Validation loss: 3.6589633061654037

Epoch: 6| Step: 7
Training loss: 3.8253829166003976
Validation loss: 3.6590305550207987

Epoch: 6| Step: 8
Training loss: 3.5112255458720356
Validation loss: 3.6233866152493013

Epoch: 6| Step: 9
Training loss: 3.7088527244276146
Validation loss: 3.5960938074879283

Epoch: 6| Step: 10
Training loss: 4.322270920410222
Validation loss: 3.574597766867454

Epoch: 6| Step: 11
Training loss: 3.991337934003831
Validation loss: 3.553078455951178

Epoch: 6| Step: 12
Training loss: 3.635620344662977
Validation loss: 3.547285849692295

Epoch: 6| Step: 13
Training loss: 3.567467689287645
Validation loss: 3.50161262723022

Epoch: 18| Step: 0
Training loss: 3.9873913884692667
Validation loss: 3.4826985196172013

Epoch: 6| Step: 1
Training loss: 3.6309755993114865
Validation loss: 3.4770047728578524

Epoch: 6| Step: 2
Training loss: 4.177115702642401
Validation loss: 3.450292674914845

Epoch: 6| Step: 3
Training loss: 3.144936103111058
Validation loss: 3.418999763494736

Epoch: 6| Step: 4
Training loss: 3.9904282009795455
Validation loss: 3.385976039718379

Epoch: 6| Step: 5
Training loss: 3.73701824030458
Validation loss: 3.3621624770903944

Epoch: 6| Step: 6
Training loss: 3.3238978516804276
Validation loss: 3.3435037587607113

Epoch: 6| Step: 7
Training loss: 3.3339426119601625
Validation loss: 3.33095327027467

Epoch: 6| Step: 8
Training loss: 2.122597626686333
Validation loss: 3.3041305637056664

Epoch: 6| Step: 9
Training loss: 3.932388742356012
Validation loss: 3.2931436973859656

Epoch: 6| Step: 10
Training loss: 3.3592182921298352
Validation loss: 3.260619205612007

Epoch: 6| Step: 11
Training loss: 3.425537100674956
Validation loss: 3.2455622489630733

Epoch: 6| Step: 12
Training loss: 3.34792302781272
Validation loss: 3.2268014608944324

Epoch: 6| Step: 13
Training loss: 3.163247990262602
Validation loss: 3.197557324468227

Epoch: 19| Step: 0
Training loss: 2.8309905145904626
Validation loss: 3.1925124180034357

Epoch: 6| Step: 1
Training loss: 3.754937545317935
Validation loss: 3.159178772139893

Epoch: 6| Step: 2
Training loss: 3.1139748445645106
Validation loss: 3.143015521950033

Epoch: 6| Step: 3
Training loss: 3.1216921274504994
Validation loss: 3.1048006199233087

Epoch: 6| Step: 4
Training loss: 3.381195034066866
Validation loss: 3.1146322637430743

Epoch: 6| Step: 5
Training loss: 3.191903457290659
Validation loss: 3.089691259154932

Epoch: 6| Step: 6
Training loss: 2.3958648900704245
Validation loss: 3.044214550019327

Epoch: 6| Step: 7
Training loss: 2.5002692077649575
Validation loss: 3.0379616533779847

Epoch: 6| Step: 8
Training loss: 3.4518040680871342
Validation loss: 3.0421813336129695

Epoch: 6| Step: 9
Training loss: 3.969223594943383
Validation loss: 3.0202663654773994

Epoch: 6| Step: 10
Training loss: 2.8771826710126502
Validation loss: 3.0026176049695446

Epoch: 6| Step: 11
Training loss: 3.266565214904282
Validation loss: 2.989353723502876

Epoch: 6| Step: 12
Training loss: 3.8765933544894513
Validation loss: 2.9874474249186846

Epoch: 6| Step: 13
Training loss: 3.6436760032821978
Validation loss: 2.9434627171837042

Epoch: 20| Step: 0
Training loss: 2.640351411088237
Validation loss: 2.9260610027782152

Epoch: 6| Step: 1
Training loss: 3.7427674801735322
Validation loss: 2.9183983335368655

Epoch: 6| Step: 2
Training loss: 3.007988783389342
Validation loss: 2.898904011773504

Epoch: 6| Step: 3
Training loss: 2.9898455745152193
Validation loss: 2.8881814017449745

Epoch: 6| Step: 4
Training loss: 3.622739547485916
Validation loss: 2.885849667250382

Epoch: 6| Step: 5
Training loss: 2.6189795891897534
Validation loss: 2.8615499054714535

Epoch: 6| Step: 6
Training loss: 2.7394988961980817
Validation loss: 2.8296812937031834

Epoch: 6| Step: 7
Training loss: 2.462897401296685
Validation loss: 2.860759044875217

Epoch: 6| Step: 8
Training loss: 2.9475853040676974
Validation loss: 2.7927381800538527

Epoch: 6| Step: 9
Training loss: 2.9612874249548624
Validation loss: 2.813044749819722

Epoch: 6| Step: 10
Training loss: 3.5029970688476846
Validation loss: 2.795580963033469

Epoch: 6| Step: 11
Training loss: 3.7874650557010736
Validation loss: 2.7751741408798734

Epoch: 6| Step: 12
Training loss: 2.5905596864057325
Validation loss: 2.7773615270565806

Epoch: 6| Step: 13
Training loss: 3.756694667094645
Validation loss: 2.7599499277489326

Epoch: 21| Step: 0
Training loss: 2.9524199436326075
Validation loss: 2.738929872417588

Epoch: 6| Step: 1
Training loss: 3.421155601372687
Validation loss: 2.7406286466837124

Epoch: 6| Step: 2
Training loss: 2.7364535034121573
Validation loss: 2.7354549439926137

Epoch: 6| Step: 3
Training loss: 2.703902028148566
Validation loss: 2.7276797727633757

Epoch: 6| Step: 4
Training loss: 2.9306186671238423
Validation loss: 2.6922270156494927

Epoch: 6| Step: 5
Training loss: 2.9053958745209068
Validation loss: 2.721739422368303

Epoch: 6| Step: 6
Training loss: 3.103973450930602
Validation loss: 2.6922655791043137

Epoch: 6| Step: 7
Training loss: 2.7251495810235147
Validation loss: 2.729054883070249

Epoch: 6| Step: 8
Training loss: 3.3976585460101605
Validation loss: 2.687766662631286

Epoch: 6| Step: 9
Training loss: 2.889767741337866
Validation loss: 2.6718761072526522

Epoch: 6| Step: 10
Training loss: 2.851338416923229
Validation loss: 2.6656973490947924

Epoch: 6| Step: 11
Training loss: 3.711108908459079
Validation loss: 2.661583956345285

Epoch: 6| Step: 12
Training loss: 3.283138930347285
Validation loss: 2.663317760453984

Epoch: 6| Step: 13
Training loss: 2.2683667660542364
Validation loss: 2.6510550613076216

Epoch: 22| Step: 0
Training loss: 3.0273469001999738
Validation loss: 2.6593461977638424

Epoch: 6| Step: 1
Training loss: 3.113837485598558
Validation loss: 2.6820777611046127

Epoch: 6| Step: 2
Training loss: 3.593733281635705
Validation loss: 2.669447903686382

Epoch: 6| Step: 3
Training loss: 3.6011168231060244
Validation loss: 2.6548858131427844

Epoch: 6| Step: 4
Training loss: 2.5459145449241127
Validation loss: 2.6448699903386546

Epoch: 6| Step: 5
Training loss: 2.718973698675766
Validation loss: 2.651083919156926

Epoch: 6| Step: 6
Training loss: 2.7813683816811245
Validation loss: 2.6459306487955967

Epoch: 6| Step: 7
Training loss: 2.466884825913794
Validation loss: 2.6316151822957385

Epoch: 6| Step: 8
Training loss: 3.485644737818421
Validation loss: 2.660057742697746

Epoch: 6| Step: 9
Training loss: 2.5780689580201552
Validation loss: 2.663647208007941

Epoch: 6| Step: 10
Training loss: 2.448524388838971
Validation loss: 2.6688082757880975

Epoch: 6| Step: 11
Training loss: 3.151675544644229
Validation loss: 2.6419145105729367

Epoch: 6| Step: 12
Training loss: 3.285256691575411
Validation loss: 2.6220539141925308

Epoch: 6| Step: 13
Training loss: 2.888115530751796
Validation loss: 2.641344069978092

Epoch: 23| Step: 0
Training loss: 3.4486650344320706
Validation loss: 2.6392465687608184

Epoch: 6| Step: 1
Training loss: 3.780650067617586
Validation loss: 2.64059315896659

Epoch: 6| Step: 2
Training loss: 1.9876289421816375
Validation loss: 2.6689189569509617

Epoch: 6| Step: 3
Training loss: 3.1688949040193375
Validation loss: 2.6652207671839134

Epoch: 6| Step: 4
Training loss: 3.53618418886145
Validation loss: 2.6266736634401076

Epoch: 6| Step: 5
Training loss: 3.0438054199186535
Validation loss: 2.6552465011506725

Epoch: 6| Step: 6
Training loss: 2.596861110976039
Validation loss: 2.636120281839407

Epoch: 6| Step: 7
Training loss: 2.754146311151381
Validation loss: 2.6490008822499838

Epoch: 6| Step: 8
Training loss: 2.929906241833943
Validation loss: 2.655175899951735

Epoch: 6| Step: 9
Training loss: 2.974255887103565
Validation loss: 2.6382730592998453

Epoch: 6| Step: 10
Training loss: 2.853140616400307
Validation loss: 2.6548321882024863

Epoch: 6| Step: 11
Training loss: 2.8284748345763204
Validation loss: 2.654795546332744

Epoch: 6| Step: 12
Training loss: 2.679005260757117
Validation loss: 2.648643470881362

Epoch: 6| Step: 13
Training loss: 3.1301910010612772
Validation loss: 2.6616077800550513

Epoch: 24| Step: 0
Training loss: 3.5520476547343653
Validation loss: 2.640004989514277

Epoch: 6| Step: 1
Training loss: 3.0224024062890753
Validation loss: 2.6434644604776385

Epoch: 6| Step: 2
Training loss: 2.379844442941874
Validation loss: 2.628001988373534

Epoch: 6| Step: 3
Training loss: 3.1955047027309758
Validation loss: 2.662234921710846

Epoch: 6| Step: 4
Training loss: 2.5560757192879
Validation loss: 2.6524925907235612

Epoch: 6| Step: 5
Training loss: 3.703438017287205
Validation loss: 2.6517326785192448

Epoch: 6| Step: 6
Training loss: 2.697812190051963
Validation loss: 2.6547584182214896

Epoch: 6| Step: 7
Training loss: 2.618002511276078
Validation loss: 2.6324462090536107

Epoch: 6| Step: 8
Training loss: 3.2142769556077577
Validation loss: 2.6478008149038548

Epoch: 6| Step: 9
Training loss: 2.5660591529456243
Validation loss: 2.6113144699673416

Epoch: 6| Step: 10
Training loss: 3.2105583468263688
Validation loss: 2.649808618225175

Epoch: 6| Step: 11
Training loss: 2.2328537250447664
Validation loss: 2.6216974202221

Epoch: 6| Step: 12
Training loss: 2.864101817958435
Validation loss: 2.634044509036801

Epoch: 6| Step: 13
Training loss: 3.832309102320049
Validation loss: 2.6290798125391026

Epoch: 25| Step: 0
Training loss: 2.904487321428998
Validation loss: 2.662607368824366

Epoch: 6| Step: 1
Training loss: 3.601020954320059
Validation loss: 2.6403585912297296

Epoch: 6| Step: 2
Training loss: 3.0622527353544067
Validation loss: 2.6415908104498773

Epoch: 6| Step: 3
Training loss: 3.0404189350680304
Validation loss: 2.6256850579737367

Epoch: 6| Step: 4
Training loss: 2.4080609529454575
Validation loss: 2.654706938417231

Epoch: 6| Step: 5
Training loss: 2.7611380348283006
Validation loss: 2.6611009740792317

Epoch: 6| Step: 6
Training loss: 2.961577736273063
Validation loss: 2.6355075693234182

Epoch: 6| Step: 7
Training loss: 3.7075585974025858
Validation loss: 2.6399298583793667

Epoch: 6| Step: 8
Training loss: 2.015897628917366
Validation loss: 2.6463516423049884

Epoch: 6| Step: 9
Training loss: 3.117215952349003
Validation loss: 2.637122856842302

Epoch: 6| Step: 10
Training loss: 3.1831881212065105
Validation loss: 2.6545024057213067

Epoch: 6| Step: 11
Training loss: 3.381260187553247
Validation loss: 2.6318220781349524

Epoch: 6| Step: 12
Training loss: 2.4475702459991506
Validation loss: 2.654662611621855

Epoch: 6| Step: 13
Training loss: 2.5132195955776933
Validation loss: 2.644432619202609

Epoch: 26| Step: 0
Training loss: 3.0250186383642617
Validation loss: 2.6438195165449114

Epoch: 6| Step: 1
Training loss: 2.3770392848175987
Validation loss: 2.6579731592076077

Epoch: 6| Step: 2
Training loss: 2.9753375398864117
Validation loss: 2.6390246945898794

Epoch: 6| Step: 3
Training loss: 3.042222133413864
Validation loss: 2.650493067445109

Epoch: 6| Step: 4
Training loss: 3.280733485667419
Validation loss: 2.6345783138691647

Epoch: 6| Step: 5
Training loss: 2.898825400993364
Validation loss: 2.6420393013837655

Epoch: 6| Step: 6
Training loss: 3.0580399402831855
Validation loss: 2.646832393211258

Epoch: 6| Step: 7
Training loss: 3.045617729380302
Validation loss: 2.6523136783173213

Epoch: 6| Step: 8
Training loss: 2.174964518641312
Validation loss: 2.634863782854458

Epoch: 6| Step: 9
Training loss: 3.3792660912979167
Validation loss: 2.6324789807834015

Epoch: 6| Step: 10
Training loss: 2.969465791843412
Validation loss: 2.6577467482965274

Epoch: 6| Step: 11
Training loss: 2.787208346859799
Validation loss: 2.6343343041707876

Epoch: 6| Step: 12
Training loss: 2.9715530814818796
Validation loss: 2.6311091458333973

Epoch: 6| Step: 13
Training loss: 3.733346709726984
Validation loss: 2.657568233019463

Epoch: 27| Step: 0
Training loss: 2.5683135169979225
Validation loss: 2.6324346161689327

Epoch: 6| Step: 1
Training loss: 3.0577143431646014
Validation loss: 2.621872480783999

Epoch: 6| Step: 2
Training loss: 2.8885672178260653
Validation loss: 2.6096475611251155

Epoch: 6| Step: 3
Training loss: 3.114024763936169
Validation loss: 2.664396781856117

Epoch: 6| Step: 4
Training loss: 3.4123690178295156
Validation loss: 2.633305505379926

Epoch: 6| Step: 5
Training loss: 3.1558864875173707
Validation loss: 2.654966809054274

Epoch: 6| Step: 6
Training loss: 2.3811968219255912
Validation loss: 2.6446672918583864

Epoch: 6| Step: 7
Training loss: 3.3257056383817347
Validation loss: 2.6331273650117395

Epoch: 6| Step: 8
Training loss: 3.4232473190877695
Validation loss: 2.616676893214922

Epoch: 6| Step: 9
Training loss: 2.031643521263377
Validation loss: 2.6436274386615395

Epoch: 6| Step: 10
Training loss: 3.384704201873435
Validation loss: 2.6604983459890943

Epoch: 6| Step: 11
Training loss: 2.7538887618571497
Validation loss: 2.6491596354108244

Epoch: 6| Step: 12
Training loss: 3.0052114362166247
Validation loss: 2.6402451184364732

Epoch: 6| Step: 13
Training loss: 2.9965219999817307
Validation loss: 2.6462632898083807

Epoch: 28| Step: 0
Training loss: 3.0544233671370593
Validation loss: 2.605110735826424

Epoch: 6| Step: 1
Training loss: 3.1794845928713276
Validation loss: 2.6555068113423435

Epoch: 6| Step: 2
Training loss: 2.9607854718556634
Validation loss: 2.644296251153533

Epoch: 6| Step: 3
Training loss: 3.2670051542065717
Validation loss: 2.636683866147802

Epoch: 6| Step: 4
Training loss: 2.4960240218522687
Validation loss: 2.6194472407711746

Epoch: 6| Step: 5
Training loss: 2.784447878173892
Validation loss: 2.629912838479751

Epoch: 6| Step: 6
Training loss: 2.9476810716139514
Validation loss: 2.6240178286032165

Epoch: 6| Step: 7
Training loss: 2.860248869891794
Validation loss: 2.652887898469741

Epoch: 6| Step: 8
Training loss: 3.015722717915647
Validation loss: 2.6555423457468352

Epoch: 6| Step: 9
Training loss: 3.3342009051134247
Validation loss: 2.6180929460166906

Epoch: 6| Step: 10
Training loss: 2.8301750045422014
Validation loss: 2.64913240270617

Epoch: 6| Step: 11
Training loss: 3.0585157986155407
Validation loss: 2.640662951074439

Epoch: 6| Step: 12
Training loss: 2.8319202901215372
Validation loss: 2.647208594634639

Epoch: 6| Step: 13
Training loss: 3.0822456778425535
Validation loss: 2.62033294042234

Epoch: 29| Step: 0
Training loss: 3.030629831956507
Validation loss: 2.6137205520119506

Epoch: 6| Step: 1
Training loss: 2.916646430535734
Validation loss: 2.646588392574354

Epoch: 6| Step: 2
Training loss: 3.0487036279433846
Validation loss: 2.6556286610519035

Epoch: 6| Step: 3
Training loss: 2.0386521668293773
Validation loss: 2.642195002171514

Epoch: 6| Step: 4
Training loss: 2.789356205539521
Validation loss: 2.6371747469782485

Epoch: 6| Step: 5
Training loss: 2.5757973075461056
Validation loss: 2.62183531961253

Epoch: 6| Step: 6
Training loss: 2.229102148625668
Validation loss: 2.628435498259472

Epoch: 6| Step: 7
Training loss: 3.020542858671563
Validation loss: 2.627868121662523

Epoch: 6| Step: 8
Training loss: 2.6570054718983465
Validation loss: 2.6208167351447647

Epoch: 6| Step: 9
Training loss: 4.2619116413439455
Validation loss: 2.6156085415248076

Epoch: 6| Step: 10
Training loss: 3.5944810206736935
Validation loss: 2.620419611318558

Epoch: 6| Step: 11
Training loss: 3.200591187703557
Validation loss: 2.6477563327937417

Epoch: 6| Step: 12
Training loss: 3.008333393917629
Validation loss: 2.6486384396958416

Epoch: 6| Step: 13
Training loss: 2.0078846959296337
Validation loss: 2.603855187933697

Epoch: 30| Step: 0
Training loss: 2.8432006305288153
Validation loss: 2.6379349976243778

Epoch: 6| Step: 1
Training loss: 2.756903393170479
Validation loss: 2.639141916976186

Epoch: 6| Step: 2
Training loss: 3.2406714146379247
Validation loss: 2.6455269163668533

Epoch: 6| Step: 3
Training loss: 2.6618953179369744
Validation loss: 2.6091515180905804

Epoch: 6| Step: 4
Training loss: 2.3994150561531318
Validation loss: 2.654542862513229

Epoch: 6| Step: 5
Training loss: 3.1695444348902337
Validation loss: 2.6309107557794293

Epoch: 6| Step: 6
Training loss: 2.9089733202967403
Validation loss: 2.6194706784607455

Epoch: 6| Step: 7
Training loss: 3.386225927414493
Validation loss: 2.627839901513178

Epoch: 6| Step: 8
Training loss: 3.4966167719371937
Validation loss: 2.632624881437658

Epoch: 6| Step: 9
Training loss: 3.0384797074351373
Validation loss: 2.6205755508595696

Epoch: 6| Step: 10
Training loss: 3.3465037192485436
Validation loss: 2.6384100408484614

Epoch: 6| Step: 11
Training loss: 2.5747266161336717
Validation loss: 2.6242362013305205

Epoch: 6| Step: 12
Training loss: 2.819175427594518
Validation loss: 2.62812892834561

Epoch: 6| Step: 13
Training loss: 2.262404053060416
Validation loss: 2.6400985100683125

Epoch: 31| Step: 0
Training loss: 3.349930514853361
Validation loss: 2.646436462828359

Epoch: 6| Step: 1
Training loss: 2.410555962505405
Validation loss: 2.6304364433940832

Epoch: 6| Step: 2
Training loss: 2.8326768862650007
Validation loss: 2.6444237739417735

Epoch: 6| Step: 3
Training loss: 3.1576536475557866
Validation loss: 2.648542833739745

Epoch: 6| Step: 4
Training loss: 2.6398967212646958
Validation loss: 2.6532248684862476

Epoch: 6| Step: 5
Training loss: 3.204552309187562
Validation loss: 2.622136280137965

Epoch: 6| Step: 6
Training loss: 2.930010724357273
Validation loss: 2.5898829896292472

Epoch: 6| Step: 7
Training loss: 2.7114413889705884
Validation loss: 2.6349545719414866

Epoch: 6| Step: 8
Training loss: 3.437994904004504
Validation loss: 2.6265398832447198

Epoch: 6| Step: 9
Training loss: 3.063439361375576
Validation loss: 2.6290153384851687

Epoch: 6| Step: 10
Training loss: 2.9174601610825652
Validation loss: 2.6140454687747647

Epoch: 6| Step: 11
Training loss: 2.5945924057339123
Validation loss: 2.612408817252617

Epoch: 6| Step: 12
Training loss: 2.936374529864791
Validation loss: 2.607480117683824

Epoch: 6| Step: 13
Training loss: 2.96879352738444
Validation loss: 2.6265306390358876

Epoch: 32| Step: 0
Training loss: 3.51131503932058
Validation loss: 2.60991284267448

Epoch: 6| Step: 1
Training loss: 1.8318694150976857
Validation loss: 2.623852926955819

Epoch: 6| Step: 2
Training loss: 2.6606031762218922
Validation loss: 2.628489007284529

Epoch: 6| Step: 3
Training loss: 3.813842787112438
Validation loss: 2.6535972315350107

Epoch: 6| Step: 4
Training loss: 1.8971572138141324
Validation loss: 2.6076223141132298

Epoch: 6| Step: 5
Training loss: 3.204484158095094
Validation loss: 2.6014923024150796

Epoch: 6| Step: 6
Training loss: 2.907441746004327
Validation loss: 2.6294416068915956

Epoch: 6| Step: 7
Training loss: 3.1800974738578853
Validation loss: 2.6132722718315002

Epoch: 6| Step: 8
Training loss: 3.312355470203391
Validation loss: 2.6071198727339673

Epoch: 6| Step: 9
Training loss: 2.6417206065771057
Validation loss: 2.5985740977492204

Epoch: 6| Step: 10
Training loss: 3.094595745351634
Validation loss: 2.615809575456516

Epoch: 6| Step: 11
Training loss: 3.08699963797075
Validation loss: 2.606682417630815

Epoch: 6| Step: 12
Training loss: 2.9330623465413637
Validation loss: 2.604972754631942

Epoch: 6| Step: 13
Training loss: 2.2927071261254723
Validation loss: 2.6260775431276637

Epoch: 33| Step: 0
Training loss: 3.163120157705059
Validation loss: 2.647875394975787

Epoch: 6| Step: 1
Training loss: 3.118702150027466
Validation loss: 2.630880857634623

Epoch: 6| Step: 2
Training loss: 2.6841466520128363
Validation loss: 2.622645473104045

Epoch: 6| Step: 3
Training loss: 2.7196449472998823
Validation loss: 2.6244990353727347

Epoch: 6| Step: 4
Training loss: 2.986159505131615
Validation loss: 2.6802607164523584

Epoch: 6| Step: 5
Training loss: 3.314521029062813
Validation loss: 2.618735311548581

Epoch: 6| Step: 6
Training loss: 2.973030136997539
Validation loss: 2.6492835130554373

Epoch: 6| Step: 7
Training loss: 3.5096418542537062
Validation loss: 2.5994922368119897

Epoch: 6| Step: 8
Training loss: 3.6345474530254047
Validation loss: 2.624783356101693

Epoch: 6| Step: 9
Training loss: 2.599735202509853
Validation loss: 2.6302529965489794

Epoch: 6| Step: 10
Training loss: 2.4703883275863143
Validation loss: 2.609833646888627

Epoch: 6| Step: 11
Training loss: 2.443976088892318
Validation loss: 2.6330354292550586

Epoch: 6| Step: 12
Training loss: 2.6653177207227436
Validation loss: 2.614218463122201

Epoch: 6| Step: 13
Training loss: 2.8947042189589576
Validation loss: 2.642710093149874

Epoch: 34| Step: 0
Training loss: 2.266029058797018
Validation loss: 2.6262219910603704

Epoch: 6| Step: 1
Training loss: 2.9245554007390915
Validation loss: 2.591405039549547

Epoch: 6| Step: 2
Training loss: 3.969510463636902
Validation loss: 2.6184250485720018

Epoch: 6| Step: 3
Training loss: 3.6148249447384746
Validation loss: 2.6098454767055346

Epoch: 6| Step: 4
Training loss: 2.9169135579563963
Validation loss: 2.625068681231534

Epoch: 6| Step: 5
Training loss: 2.5238681106930567
Validation loss: 2.649144129612847

Epoch: 6| Step: 6
Training loss: 2.197717076018186
Validation loss: 2.614087963417259

Epoch: 6| Step: 7
Training loss: 3.078192075976417
Validation loss: 2.6074280357802704

Epoch: 6| Step: 8
Training loss: 2.7048003016176367
Validation loss: 2.6168164287254085

Epoch: 6| Step: 9
Training loss: 2.634080892596633
Validation loss: 2.6271204716906347

Epoch: 6| Step: 10
Training loss: 3.420982488306939
Validation loss: 2.6003988104084605

Epoch: 6| Step: 11
Training loss: 2.6958241737206183
Validation loss: 2.6201634978723654

Epoch: 6| Step: 12
Training loss: 3.043589850565742
Validation loss: 2.638084312138202

Epoch: 6| Step: 13
Training loss: 2.1701685287146897
Validation loss: 2.6471013899835127

Epoch: 35| Step: 0
Training loss: 3.4104554699411005
Validation loss: 2.653726518184812

Epoch: 6| Step: 1
Training loss: 3.266813801027462
Validation loss: 2.607336298034554

Epoch: 6| Step: 2
Training loss: 2.927204351310488
Validation loss: 2.6285392216004397

Epoch: 6| Step: 3
Training loss: 2.9486696249958295
Validation loss: 2.6187924205936888

Epoch: 6| Step: 4
Training loss: 2.518283363450748
Validation loss: 2.623803422197338

Epoch: 6| Step: 5
Training loss: 3.085350734118709
Validation loss: 2.637785788369721

Epoch: 6| Step: 6
Training loss: 3.115195189800575
Validation loss: 2.630518593648144

Epoch: 6| Step: 7
Training loss: 2.929872552749352
Validation loss: 2.6113769660198902

Epoch: 6| Step: 8
Training loss: 2.3921872687760133
Validation loss: 2.6149926307496116

Epoch: 6| Step: 9
Training loss: 3.0735790163863856
Validation loss: 2.6292063133732535

Epoch: 6| Step: 10
Training loss: 3.256468571156743
Validation loss: 2.5946563775802725

Epoch: 6| Step: 11
Training loss: 2.75979741666048
Validation loss: 2.6491288598501646

Epoch: 6| Step: 12
Training loss: 2.381942039713435
Validation loss: 2.6367239458829728

Epoch: 6| Step: 13
Training loss: 2.7903185668701633
Validation loss: 2.6242140556811497

Epoch: 36| Step: 0
Training loss: 2.4683732336795927
Validation loss: 2.616576309112305

Epoch: 6| Step: 1
Training loss: 2.8995337867879893
Validation loss: 2.6254614440549275

Epoch: 6| Step: 2
Training loss: 2.576560545689829
Validation loss: 2.653016021943531

Epoch: 6| Step: 3
Training loss: 2.292554255751424
Validation loss: 2.6350923457245536

Epoch: 6| Step: 4
Training loss: 2.8951866653691853
Validation loss: 2.624705333744338

Epoch: 6| Step: 5
Training loss: 3.199694624873419
Validation loss: 2.6425777796341934

Epoch: 6| Step: 6
Training loss: 3.25225780995707
Validation loss: 2.606833784810204

Epoch: 6| Step: 7
Training loss: 2.257680288489533
Validation loss: 2.632514495406141

Epoch: 6| Step: 8
Training loss: 3.438478920005937
Validation loss: 2.618473945196042

Epoch: 6| Step: 9
Training loss: 3.453302715440715
Validation loss: 2.634887610756184

Epoch: 6| Step: 10
Training loss: 2.4570405653638994
Validation loss: 2.603050117266022

Epoch: 6| Step: 11
Training loss: 3.249975204373185
Validation loss: 2.6270862722941932

Epoch: 6| Step: 12
Training loss: 3.307049279329397
Validation loss: 2.642788055402363

Epoch: 6| Step: 13
Training loss: 3.3243023764359987
Validation loss: 2.6498129283514475

Epoch: 37| Step: 0
Training loss: 2.680012941756244
Validation loss: 2.6147560433874557

Epoch: 6| Step: 1
Training loss: 3.1572294320761007
Validation loss: 2.6242833465477347

Epoch: 6| Step: 2
Training loss: 2.424430237524589
Validation loss: 2.621370299403694

Epoch: 6| Step: 3
Training loss: 3.3252377589985396
Validation loss: 2.6181469875917394

Epoch: 6| Step: 4
Training loss: 3.4247243505779275
Validation loss: 2.6260673776846533

Epoch: 6| Step: 5
Training loss: 3.015554792940847
Validation loss: 2.6310386501319574

Epoch: 6| Step: 6
Training loss: 3.2975811676609283
Validation loss: 2.631567447531443

Epoch: 6| Step: 7
Training loss: 2.853869531762321
Validation loss: 2.6093655387672996

Epoch: 6| Step: 8
Training loss: 2.1446884458979727
Validation loss: 2.6276691478775662

Epoch: 6| Step: 9
Training loss: 3.5893847947316653
Validation loss: 2.6136176854149196

Epoch: 6| Step: 10
Training loss: 2.409078743578389
Validation loss: 2.628089103820849

Epoch: 6| Step: 11
Training loss: 2.969514447219628
Validation loss: 2.6376156669463278

Epoch: 6| Step: 12
Training loss: 2.5911547074413575
Validation loss: 2.6223513844891064

Epoch: 6| Step: 13
Training loss: 3.2211377814644524
Validation loss: 2.630038269906491

Epoch: 38| Step: 0
Training loss: 2.815953402149942
Validation loss: 2.617816053327171

Epoch: 6| Step: 1
Training loss: 3.2944257415818123
Validation loss: 2.611328099474806

Epoch: 6| Step: 2
Training loss: 2.4605147710154087
Validation loss: 2.6252816181524685

Epoch: 6| Step: 3
Training loss: 3.2714091642474004
Validation loss: 2.6086163979313475

Epoch: 6| Step: 4
Training loss: 2.258266733273738
Validation loss: 2.6245514251536592

Epoch: 6| Step: 5
Training loss: 3.4539136719553825
Validation loss: 2.627445933087574

Epoch: 6| Step: 6
Training loss: 3.1374212977048512
Validation loss: 2.6336647081686637

Epoch: 6| Step: 7
Training loss: 3.456094147132745
Validation loss: 2.637078898454802

Epoch: 6| Step: 8
Training loss: 3.0563766609266323
Validation loss: 2.599451868037094

Epoch: 6| Step: 9
Training loss: 3.4043615863578514
Validation loss: 2.584714292834951

Epoch: 6| Step: 10
Training loss: 2.2759076623873877
Validation loss: 2.6351273216649522

Epoch: 6| Step: 11
Training loss: 2.3687387551717656
Validation loss: 2.6468051888651303

Epoch: 6| Step: 12
Training loss: 3.1298876876912107
Validation loss: 2.640729154205118

Epoch: 6| Step: 13
Training loss: 1.9308466962413111
Validation loss: 2.580197097414913

Epoch: 39| Step: 0
Training loss: 3.307870472799583
Validation loss: 2.600676335161657

Epoch: 6| Step: 1
Training loss: 2.6028810201294164
Validation loss: 2.6191233479703997

Epoch: 6| Step: 2
Training loss: 2.852998053409997
Validation loss: 2.6148450761526583

Epoch: 6| Step: 3
Training loss: 3.5829637617812025
Validation loss: 2.622785447624557

Epoch: 6| Step: 4
Training loss: 3.1838555538441344
Validation loss: 2.6169239570852625

Epoch: 6| Step: 5
Training loss: 2.5321783553307546
Validation loss: 2.625871822162719

Epoch: 6| Step: 6
Training loss: 3.349275391057236
Validation loss: 2.614935906361843

Epoch: 6| Step: 7
Training loss: 2.7210503854288923
Validation loss: 2.6313629303090242

Epoch: 6| Step: 8
Training loss: 2.988236251193057
Validation loss: 2.6154350387517997

Epoch: 6| Step: 9
Training loss: 2.97636913562588
Validation loss: 2.617252025442467

Epoch: 6| Step: 10
Training loss: 2.9222728437995653
Validation loss: 2.6209843836493465

Epoch: 6| Step: 11
Training loss: 2.6607195780071464
Validation loss: 2.604262487473939

Epoch: 6| Step: 12
Training loss: 2.5388938495671924
Validation loss: 2.620255812859735

Epoch: 6| Step: 13
Training loss: 2.850341033608704
Validation loss: 2.5964340217593143

Epoch: 40| Step: 0
Training loss: 2.502805661370628
Validation loss: 2.6187129617657656

Epoch: 6| Step: 1
Training loss: 3.8580219816033536
Validation loss: 2.631737499164319

Epoch: 6| Step: 2
Training loss: 2.7746725421875693
Validation loss: 2.6100147335787187

Epoch: 6| Step: 3
Training loss: 2.951946043394973
Validation loss: 2.6360231724907734

Epoch: 6| Step: 4
Training loss: 2.999309460320747
Validation loss: 2.6135625584972955

Epoch: 6| Step: 5
Training loss: 2.7182079958793266
Validation loss: 2.610030093681394

Epoch: 6| Step: 6
Training loss: 2.494957224874823
Validation loss: 2.597138777842958

Epoch: 6| Step: 7
Training loss: 2.1972254770637685
Validation loss: 2.616065119512964

Epoch: 6| Step: 8
Training loss: 2.4006689172614317
Validation loss: 2.62666467736771

Epoch: 6| Step: 9
Training loss: 3.3129108102239977
Validation loss: 2.6272558274915685

Epoch: 6| Step: 10
Training loss: 2.527639946539226
Validation loss: 2.62764195294364

Epoch: 6| Step: 11
Training loss: 2.9330594202233673
Validation loss: 2.6123198300140213

Epoch: 6| Step: 12
Training loss: 3.5163660243339065
Validation loss: 2.6297095549648706

Epoch: 6| Step: 13
Training loss: 3.8319363052474062
Validation loss: 2.6216363495156982

Epoch: 41| Step: 0
Training loss: 3.1477748277588047
Validation loss: 2.635648184577913

Epoch: 6| Step: 1
Training loss: 2.7162399105019808
Validation loss: 2.610783813216307

Epoch: 6| Step: 2
Training loss: 3.5097698366610093
Validation loss: 2.6067981558522564

Epoch: 6| Step: 3
Training loss: 2.8090533011877103
Validation loss: 2.620316532220523

Epoch: 6| Step: 4
Training loss: 2.931067220686871
Validation loss: 2.6083575244615096

Epoch: 6| Step: 5
Training loss: 2.963308708451908
Validation loss: 2.6213266069259187

Epoch: 6| Step: 6
Training loss: 2.5656636875223344
Validation loss: 2.634596757456234

Epoch: 6| Step: 7
Training loss: 3.3424287841788236
Validation loss: 2.612839937298158

Epoch: 6| Step: 8
Training loss: 2.684674307819964
Validation loss: 2.615532481225118

Epoch: 6| Step: 9
Training loss: 2.4248172730492956
Validation loss: 2.6065915447146746

Epoch: 6| Step: 10
Training loss: 3.728107124279363
Validation loss: 2.629115611489526

Epoch: 6| Step: 11
Training loss: 2.981902211500269
Validation loss: 2.606333720307356

Epoch: 6| Step: 12
Training loss: 2.325066624989148
Validation loss: 2.6195740325688037

Epoch: 6| Step: 13
Training loss: 1.92882737979197
Validation loss: 2.593321371312144

Epoch: 42| Step: 0
Training loss: 3.816305793681721
Validation loss: 2.635261831356186

Epoch: 6| Step: 1
Training loss: 2.7953995377118193
Validation loss: 2.626125918499631

Epoch: 6| Step: 2
Training loss: 2.4827921881544066
Validation loss: 2.6125926039864735

Epoch: 6| Step: 3
Training loss: 3.251376667422505
Validation loss: 2.626992758882583

Epoch: 6| Step: 4
Training loss: 2.623109954507256
Validation loss: 2.6119112452866604

Epoch: 6| Step: 5
Training loss: 2.3939961120140483
Validation loss: 2.5985128185383175

Epoch: 6| Step: 6
Training loss: 3.4690092522593163
Validation loss: 2.6167369255706197

Epoch: 6| Step: 7
Training loss: 3.019177967639662
Validation loss: 2.6180795975073154

Epoch: 6| Step: 8
Training loss: 3.1527749751037
Validation loss: 2.6351128657256218

Epoch: 6| Step: 9
Training loss: 2.597953790819028
Validation loss: 2.6245920027300746

Epoch: 6| Step: 10
Training loss: 2.9500647133663556
Validation loss: 2.619459404946493

Epoch: 6| Step: 11
Training loss: 3.114694004367801
Validation loss: 2.6244878108086787

Epoch: 6| Step: 12
Training loss: 1.8383910970296329
Validation loss: 2.5955758841952403

Epoch: 6| Step: 13
Training loss: 2.7869841367710153
Validation loss: 2.5911480607676456

Epoch: 43| Step: 0
Training loss: 2.9258835982181974
Validation loss: 2.619006833937656

Epoch: 6| Step: 1
Training loss: 3.150402128195056
Validation loss: 2.612069103622983

Epoch: 6| Step: 2
Training loss: 3.040566511071901
Validation loss: 2.6240000971417192

Epoch: 6| Step: 3
Training loss: 3.2020593871042555
Validation loss: 2.618352676132896

Epoch: 6| Step: 4
Training loss: 3.209373371603013
Validation loss: 2.6107579595136152

Epoch: 6| Step: 5
Training loss: 2.648590713615358
Validation loss: 2.608872793972694

Epoch: 6| Step: 6
Training loss: 2.57069296760216
Validation loss: 2.606521031120714

Epoch: 6| Step: 7
Training loss: 2.456506815678237
Validation loss: 2.6136858280975734

Epoch: 6| Step: 8
Training loss: 2.90316871634789
Validation loss: 2.609623345581299

Epoch: 6| Step: 9
Training loss: 3.091486092886754
Validation loss: 2.621941540202857

Epoch: 6| Step: 10
Training loss: 3.1632549244281507
Validation loss: 2.612725773691108

Epoch: 6| Step: 11
Training loss: 2.595063394055151
Validation loss: 2.6238817654628828

Epoch: 6| Step: 12
Training loss: 2.6983441538257034
Validation loss: 2.5937678581974146

Epoch: 6| Step: 13
Training loss: 3.069843596161703
Validation loss: 2.639184436392526

Epoch: 44| Step: 0
Training loss: 3.2739452614656286
Validation loss: 2.6233041767356013

Epoch: 6| Step: 1
Training loss: 3.2295736897222507
Validation loss: 2.5776122079484693

Epoch: 6| Step: 2
Training loss: 2.302266028794259
Validation loss: 2.636352882174623

Epoch: 6| Step: 3
Training loss: 3.032277984920253
Validation loss: 2.625505955303801

Epoch: 6| Step: 4
Training loss: 3.8420161857125037
Validation loss: 2.612731127184045

Epoch: 6| Step: 5
Training loss: 2.8540940843992053
Validation loss: 2.61734670376134

Epoch: 6| Step: 6
Training loss: 2.8031282899086656
Validation loss: 2.617477870573809

Epoch: 6| Step: 7
Training loss: 2.9924388013045853
Validation loss: 2.641216401407967

Epoch: 6| Step: 8
Training loss: 2.7265592646101418
Validation loss: 2.6361370570141753

Epoch: 6| Step: 9
Training loss: 2.8324006359317813
Validation loss: 2.6203414609846125

Epoch: 6| Step: 10
Training loss: 2.5885100231628715
Validation loss: 2.5932218100565434

Epoch: 6| Step: 11
Training loss: 2.487801546001529
Validation loss: 2.601894536943444

Epoch: 6| Step: 12
Training loss: 3.2277179708829187
Validation loss: 2.6198704668407014

Epoch: 6| Step: 13
Training loss: 2.055025602306515
Validation loss: 2.605063061081877

Epoch: 45| Step: 0
Training loss: 2.9305104638397586
Validation loss: 2.612330744738648

Epoch: 6| Step: 1
Training loss: 2.3837174495080906
Validation loss: 2.5703272615406507

Epoch: 6| Step: 2
Training loss: 2.5506326302056945
Validation loss: 2.6033131788635187

Epoch: 6| Step: 3
Training loss: 2.743991964528633
Validation loss: 2.5984308546501977

Epoch: 6| Step: 4
Training loss: 2.369453679949148
Validation loss: 2.613582519713658

Epoch: 6| Step: 5
Training loss: 3.2993721567016303
Validation loss: 2.601095580246245

Epoch: 6| Step: 6
Training loss: 2.924943750606816
Validation loss: 2.61690877557643

Epoch: 6| Step: 7
Training loss: 2.796586005768228
Validation loss: 2.6094486667549646

Epoch: 6| Step: 8
Training loss: 2.9801834789858845
Validation loss: 2.621042412008953

Epoch: 6| Step: 9
Training loss: 3.706420462227979
Validation loss: 2.6108837426511253

Epoch: 6| Step: 10
Training loss: 2.7429915333504895
Validation loss: 2.6265820766763124

Epoch: 6| Step: 11
Training loss: 2.828941775238223
Validation loss: 2.6201592994355924

Epoch: 6| Step: 12
Training loss: 3.4354072442666768
Validation loss: 2.6005103911059138

Epoch: 6| Step: 13
Training loss: 2.779927657304447
Validation loss: 2.615047968684452

Epoch: 46| Step: 0
Training loss: 3.2719481364385876
Validation loss: 2.606285541195985

Epoch: 6| Step: 1
Training loss: 3.2637254949122387
Validation loss: 2.6182039253874643

Epoch: 6| Step: 2
Training loss: 1.890422841763292
Validation loss: 2.610283395631159

Epoch: 6| Step: 3
Training loss: 3.434964580103402
Validation loss: 2.59694097877939

Epoch: 6| Step: 4
Training loss: 2.4602628237189785
Validation loss: 2.631664092969976

Epoch: 6| Step: 5
Training loss: 2.2198850925022167
Validation loss: 2.6009564393275646

Epoch: 6| Step: 6
Training loss: 3.0224793958947673
Validation loss: 2.610614282143536

Epoch: 6| Step: 7
Training loss: 3.260754909987534
Validation loss: 2.6088934356928553

Epoch: 6| Step: 8
Training loss: 2.752489090567857
Validation loss: 2.6009460998065665

Epoch: 6| Step: 9
Training loss: 2.1884166431863026
Validation loss: 2.627239810883967

Epoch: 6| Step: 10
Training loss: 3.272406586435029
Validation loss: 2.6184018580433954

Epoch: 6| Step: 11
Training loss: 2.8946559534224585
Validation loss: 2.6122570493439223

Epoch: 6| Step: 12
Training loss: 3.5113307921042685
Validation loss: 2.598522338524065

Epoch: 6| Step: 13
Training loss: 2.595221412341758
Validation loss: 2.61572554898067

Epoch: 47| Step: 0
Training loss: 3.049826107383554
Validation loss: 2.6384607610749735

Epoch: 6| Step: 1
Training loss: 2.88518676576402
Validation loss: 2.604358860594089

Epoch: 6| Step: 2
Training loss: 2.4631976693271516
Validation loss: 2.6314814613978057

Epoch: 6| Step: 3
Training loss: 2.51173232387832
Validation loss: 2.6005801745449886

Epoch: 6| Step: 4
Training loss: 3.0585819015175995
Validation loss: 2.61055190237063

Epoch: 6| Step: 5
Training loss: 2.895324186578377
Validation loss: 2.6212715746485773

Epoch: 6| Step: 6
Training loss: 2.845232063844942
Validation loss: 2.6170857149674447

Epoch: 6| Step: 7
Training loss: 2.807487513989124
Validation loss: 2.624922611093913

Epoch: 6| Step: 8
Training loss: 2.242152941500609
Validation loss: 2.6095521073551238

Epoch: 6| Step: 9
Training loss: 3.8129293481427404
Validation loss: 2.606002479167108

Epoch: 6| Step: 10
Training loss: 3.370052243062662
Validation loss: 2.6199143470155946

Epoch: 6| Step: 11
Training loss: 3.2145398206025924
Validation loss: 2.6207440687709984

Epoch: 6| Step: 12
Training loss: 2.393717840790422
Validation loss: 2.6030157473854927

Epoch: 6| Step: 13
Training loss: 2.6089309954219355
Validation loss: 2.615695255272185

Epoch: 48| Step: 0
Training loss: 3.1221605752611192
Validation loss: 2.6014396108544653

Epoch: 6| Step: 1
Training loss: 2.602201732652923
Validation loss: 2.6056803419540424

Epoch: 6| Step: 2
Training loss: 2.5494689837295574
Validation loss: 2.6267718162476044

Epoch: 6| Step: 3
Training loss: 3.707531845974626
Validation loss: 2.5810481181154676

Epoch: 6| Step: 4
Training loss: 3.162390900791934
Validation loss: 2.6050629134669836

Epoch: 6| Step: 5
Training loss: 2.96628251178091
Validation loss: 2.6091645197464644

Epoch: 6| Step: 6
Training loss: 2.7297023412500807
Validation loss: 2.6026601661198416

Epoch: 6| Step: 7
Training loss: 3.1019798785896877
Validation loss: 2.6181321079100472

Epoch: 6| Step: 8
Training loss: 2.4259360443704474
Validation loss: 2.617355076838887

Epoch: 6| Step: 9
Training loss: 2.8691422869506757
Validation loss: 2.6108668341867727

Epoch: 6| Step: 10
Training loss: 2.883862973411542
Validation loss: 2.6187783257777304

Epoch: 6| Step: 11
Training loss: 2.7497744034219163
Validation loss: 2.587945560763026

Epoch: 6| Step: 12
Training loss: 2.9493046021754985
Validation loss: 2.5905460901348936

Epoch: 6| Step: 13
Training loss: 2.6906530824053068
Validation loss: 2.610427856251103

Epoch: 49| Step: 0
Training loss: 2.5677987186600126
Validation loss: 2.5920880406190534

Epoch: 6| Step: 1
Training loss: 2.8605881082307483
Validation loss: 2.6112178960509502

Epoch: 6| Step: 2
Training loss: 3.1920483619066577
Validation loss: 2.611315085520354

Epoch: 6| Step: 3
Training loss: 2.8213421323755616
Validation loss: 2.5971614781262646

Epoch: 6| Step: 4
Training loss: 2.756932623448454
Validation loss: 2.593453120589909

Epoch: 6| Step: 5
Training loss: 2.74826055480879
Validation loss: 2.578041727132593

Epoch: 6| Step: 6
Training loss: 3.358040904020338
Validation loss: 2.612105375178365

Epoch: 6| Step: 7
Training loss: 2.8059861940627493
Validation loss: 2.6212700372099156

Epoch: 6| Step: 8
Training loss: 2.529381521568629
Validation loss: 2.6167699640876116

Epoch: 6| Step: 9
Training loss: 2.8081509343199262
Validation loss: 2.604327906057164

Epoch: 6| Step: 10
Training loss: 2.5935825155945498
Validation loss: 2.584164791954971

Epoch: 6| Step: 11
Training loss: 2.817276776465383
Validation loss: 2.608761703612993

Epoch: 6| Step: 12
Training loss: 3.1598221610523494
Validation loss: 2.5915256742293913

Epoch: 6| Step: 13
Training loss: 3.6427249991334127
Validation loss: 2.588038970478433

Epoch: 50| Step: 0
Training loss: 3.1157498593884743
Validation loss: 2.624988036316438

Epoch: 6| Step: 1
Training loss: 3.0242664866521927
Validation loss: 2.581575650817313

Epoch: 6| Step: 2
Training loss: 2.963212319539622
Validation loss: 2.5860967777586166

Epoch: 6| Step: 3
Training loss: 2.9292826868759776
Validation loss: 2.6215714518357967

Epoch: 6| Step: 4
Training loss: 3.1507453884256575
Validation loss: 2.5945960734496167

Epoch: 6| Step: 5
Training loss: 3.0951217538676326
Validation loss: 2.6055078812397996

Epoch: 6| Step: 6
Training loss: 2.915629683937489
Validation loss: 2.5951989934162474

Epoch: 6| Step: 7
Training loss: 2.6904583107313607
Validation loss: 2.601618315262322

Epoch: 6| Step: 8
Training loss: 2.8189991775300394
Validation loss: 2.6038129806705435

Epoch: 6| Step: 9
Training loss: 3.1572378897589104
Validation loss: 2.6149557316066168

Epoch: 6| Step: 10
Training loss: 2.663287097480243
Validation loss: 2.594251073045045

Epoch: 6| Step: 11
Training loss: 2.7750763685010873
Validation loss: 2.631524236107108

Epoch: 6| Step: 12
Training loss: 2.5005411516055487
Validation loss: 2.570943111276938

Epoch: 6| Step: 13
Training loss: 2.6227912693080246
Validation loss: 2.5933258257368483

Epoch: 51| Step: 0
Training loss: 2.702030996866269
Validation loss: 2.5984317411200895

Epoch: 6| Step: 1
Training loss: 2.4161584144281725
Validation loss: 2.5939563096397347

Epoch: 6| Step: 2
Training loss: 3.3668156040094277
Validation loss: 2.592474671223081

Epoch: 6| Step: 3
Training loss: 2.8202915349376587
Validation loss: 2.575299243960054

Epoch: 6| Step: 4
Training loss: 2.5391637224414643
Validation loss: 2.596990061747586

Epoch: 6| Step: 5
Training loss: 2.8487926669773334
Validation loss: 2.6005221815115966

Epoch: 6| Step: 6
Training loss: 3.13421188645087
Validation loss: 2.6055080229258962

Epoch: 6| Step: 7
Training loss: 3.60115164773749
Validation loss: 2.5984874613368296

Epoch: 6| Step: 8
Training loss: 2.590711261339273
Validation loss: 2.602293017956365

Epoch: 6| Step: 9
Training loss: 2.5125379872653015
Validation loss: 2.606936962361055

Epoch: 6| Step: 10
Training loss: 3.458523771871899
Validation loss: 2.594622336197766

Epoch: 6| Step: 11
Training loss: 2.4858433444871983
Validation loss: 2.6194602123662207

Epoch: 6| Step: 12
Training loss: 2.9254406067343552
Validation loss: 2.577252743789054

Epoch: 6| Step: 13
Training loss: 3.327432909718355
Validation loss: 2.598930245462098

Epoch: 52| Step: 0
Training loss: 2.8963324210499555
Validation loss: 2.598675511330653

Epoch: 6| Step: 1
Training loss: 1.796372716610114
Validation loss: 2.6236730474788947

Epoch: 6| Step: 2
Training loss: 3.7247293309947187
Validation loss: 2.5800376670878284

Epoch: 6| Step: 3
Training loss: 2.4025930383869567
Validation loss: 2.5817102119077466

Epoch: 6| Step: 4
Training loss: 3.130426044901111
Validation loss: 2.5838473506928317

Epoch: 6| Step: 5
Training loss: 2.4856356894934923
Validation loss: 2.5878277559203178

Epoch: 6| Step: 6
Training loss: 3.195367267018045
Validation loss: 2.5892276848138507

Epoch: 6| Step: 7
Training loss: 2.8930452679211935
Validation loss: 2.6028374959629317

Epoch: 6| Step: 8
Training loss: 3.0322397720122902
Validation loss: 2.600783918696012

Epoch: 6| Step: 9
Training loss: 2.8789600796888264
Validation loss: 2.5869932890357537

Epoch: 6| Step: 10
Training loss: 2.9960923176231096
Validation loss: 2.58293496181974

Epoch: 6| Step: 11
Training loss: 3.0836030653084845
Validation loss: 2.5989668079037234

Epoch: 6| Step: 12
Training loss: 3.082856081206458
Validation loss: 2.5863128836760696

Epoch: 6| Step: 13
Training loss: 2.1363055232350865
Validation loss: 2.588379937795723

Epoch: 53| Step: 0
Training loss: 3.008064239668213
Validation loss: 2.601849769558495

Epoch: 6| Step: 1
Training loss: 1.9041318538274217
Validation loss: 2.5978618482790834

Epoch: 6| Step: 2
Training loss: 3.4661566860488593
Validation loss: 2.595737437635148

Epoch: 6| Step: 3
Training loss: 2.543430925082595
Validation loss: 2.5883337629700183

Epoch: 6| Step: 4
Training loss: 2.1393578113040363
Validation loss: 2.6105049746568376

Epoch: 6| Step: 5
Training loss: 2.519047653746976
Validation loss: 2.58074899475468

Epoch: 6| Step: 6
Training loss: 3.1499628579508245
Validation loss: 2.609686276548351

Epoch: 6| Step: 7
Training loss: 2.8018232506136864
Validation loss: 2.6072305355095047

Epoch: 6| Step: 8
Training loss: 2.691744358213076
Validation loss: 2.6020491945228956

Epoch: 6| Step: 9
Training loss: 3.0370643146275453
Validation loss: 2.5823880089193274

Epoch: 6| Step: 10
Training loss: 4.002303175652598
Validation loss: 2.6168227447096135

Epoch: 6| Step: 11
Training loss: 3.102695978631395
Validation loss: 2.597658873192876

Epoch: 6| Step: 12
Training loss: 2.794015882841498
Validation loss: 2.6051530824666997

Epoch: 6| Step: 13
Training loss: 2.5210644219356158
Validation loss: 2.6222485851679593

Epoch: 54| Step: 0
Training loss: 2.4019391967548276
Validation loss: 2.5772551778637434

Epoch: 6| Step: 1
Training loss: 3.0992233718672213
Validation loss: 2.597421918513026

Epoch: 6| Step: 2
Training loss: 2.5213461320183406
Validation loss: 2.595496350709459

Epoch: 6| Step: 3
Training loss: 3.4122445091210647
Validation loss: 2.6059853393301213

Epoch: 6| Step: 4
Training loss: 2.8176904044341846
Validation loss: 2.6171462179279104

Epoch: 6| Step: 5
Training loss: 1.974988710395319
Validation loss: 2.5927429265401045

Epoch: 6| Step: 6
Training loss: 2.302670388145657
Validation loss: 2.6257240968694493

Epoch: 6| Step: 7
Training loss: 3.1783270397500702
Validation loss: 2.5742009633297984

Epoch: 6| Step: 8
Training loss: 2.974423899287694
Validation loss: 2.5947065451461975

Epoch: 6| Step: 9
Training loss: 2.975531772562479
Validation loss: 2.573417867509713

Epoch: 6| Step: 10
Training loss: 2.742804911519193
Validation loss: 2.6010656444354696

Epoch: 6| Step: 11
Training loss: 3.1688311022851265
Validation loss: 2.6055853587704845

Epoch: 6| Step: 12
Training loss: 3.604076112407095
Validation loss: 2.6201895327266094

Epoch: 6| Step: 13
Training loss: 2.901888620417334
Validation loss: 2.606984235546802

Epoch: 55| Step: 0
Training loss: 2.538912442981727
Validation loss: 2.609404284410111

Epoch: 6| Step: 1
Training loss: 2.732177374414266
Validation loss: 2.628048630965938

Epoch: 6| Step: 2
Training loss: 2.8880551023430843
Validation loss: 2.610176197743388

Epoch: 6| Step: 3
Training loss: 2.8224115142602537
Validation loss: 2.609353972044413

Epoch: 6| Step: 4
Training loss: 3.2653896119187604
Validation loss: 2.621620223279214

Epoch: 6| Step: 5
Training loss: 3.1861972016381928
Validation loss: 2.6086784023933554

Epoch: 6| Step: 6
Training loss: 2.89755934910393
Validation loss: 2.602532144458933

Epoch: 6| Step: 7
Training loss: 3.1455319157043764
Validation loss: 2.5863983900513836

Epoch: 6| Step: 8
Training loss: 3.2531942662497055
Validation loss: 2.6032649546829916

Epoch: 6| Step: 9
Training loss: 2.8182284191898805
Validation loss: 2.6044376066633

Epoch: 6| Step: 10
Training loss: 2.776764070131252
Validation loss: 2.5942177131525064

Epoch: 6| Step: 11
Training loss: 2.787805952721476
Validation loss: 2.606905856998684

Epoch: 6| Step: 12
Training loss: 2.4966658293345345
Validation loss: 2.580717771928899

Epoch: 6| Step: 13
Training loss: 2.877804756365393
Validation loss: 2.583254600248688

Epoch: 56| Step: 0
Training loss: 2.8060554419958788
Validation loss: 2.620173948438157

Epoch: 6| Step: 1
Training loss: 2.9041277612372474
Validation loss: 2.588471613480124

Epoch: 6| Step: 2
Training loss: 3.6323732828405113
Validation loss: 2.610544320104951

Epoch: 6| Step: 3
Training loss: 2.5734383264018006
Validation loss: 2.6238944400994684

Epoch: 6| Step: 4
Training loss: 2.9815958074427127
Validation loss: 2.573843857473445

Epoch: 6| Step: 5
Training loss: 2.859885081670046
Validation loss: 2.596999850392143

Epoch: 6| Step: 6
Training loss: 2.9420513848874834
Validation loss: 2.6144747069062446

Epoch: 6| Step: 7
Training loss: 2.8083147910512465
Validation loss: 2.5895470642739555

Epoch: 6| Step: 8
Training loss: 3.1483701031383604
Validation loss: 2.630034460564637

Epoch: 6| Step: 9
Training loss: 2.3336948614242163
Validation loss: 2.591808992881732

Epoch: 6| Step: 10
Training loss: 2.810464928063939
Validation loss: 2.598765338177544

Epoch: 6| Step: 11
Training loss: 2.7055384275280234
Validation loss: 2.5795169646179157

Epoch: 6| Step: 12
Training loss: 2.8924736091642935
Validation loss: 2.5802661644370364

Epoch: 6| Step: 13
Training loss: 2.7599667356393875
Validation loss: 2.60504234275773

Epoch: 57| Step: 0
Training loss: 2.8009041688726173
Validation loss: 2.5825538835462356

Epoch: 6| Step: 1
Training loss: 2.3633576183748244
Validation loss: 2.584691921633256

Epoch: 6| Step: 2
Training loss: 2.651478329852839
Validation loss: 2.594761416632455

Epoch: 6| Step: 3
Training loss: 2.7901652744521326
Validation loss: 2.624872793464288

Epoch: 6| Step: 4
Training loss: 3.0699771765938473
Validation loss: 2.596479505539814

Epoch: 6| Step: 5
Training loss: 3.1292960582518283
Validation loss: 2.575218658669337

Epoch: 6| Step: 6
Training loss: 3.2574326547612884
Validation loss: 2.5983197564159726

Epoch: 6| Step: 7
Training loss: 3.5744012504636924
Validation loss: 2.5977319011085753

Epoch: 6| Step: 8
Training loss: 2.0687761472219397
Validation loss: 2.61599183703599

Epoch: 6| Step: 9
Training loss: 3.182087060788715
Validation loss: 2.5616728405319593

Epoch: 6| Step: 10
Training loss: 3.4072927576240386
Validation loss: 2.613052597280761

Epoch: 6| Step: 11
Training loss: 1.918162163268457
Validation loss: 2.5903363893716254

Epoch: 6| Step: 12
Training loss: 2.41454263498689
Validation loss: 2.606386588334934

Epoch: 6| Step: 13
Training loss: 3.33738916334495
Validation loss: 2.606884010104202

Epoch: 58| Step: 0
Training loss: 3.572229450891543
Validation loss: 2.598396418242666

Epoch: 6| Step: 1
Training loss: 2.6123809860352933
Validation loss: 2.593797518466248

Epoch: 6| Step: 2
Training loss: 3.0962169329125335
Validation loss: 2.63580011563571

Epoch: 6| Step: 3
Training loss: 2.330672336219392
Validation loss: 2.592532285569827

Epoch: 6| Step: 4
Training loss: 3.587025329874754
Validation loss: 2.6035247530063015

Epoch: 6| Step: 5
Training loss: 2.8372493683621616
Validation loss: 2.6054107929662718

Epoch: 6| Step: 6
Training loss: 2.489431166421083
Validation loss: 2.6227068741600115

Epoch: 6| Step: 7
Training loss: 3.3425031101894245
Validation loss: 2.5872044131754457

Epoch: 6| Step: 8
Training loss: 2.6149209299769924
Validation loss: 2.609370311634356

Epoch: 6| Step: 9
Training loss: 2.950209050934165
Validation loss: 2.581802893971717

Epoch: 6| Step: 10
Training loss: 2.5211172863476614
Validation loss: 2.595381500264717

Epoch: 6| Step: 11
Training loss: 2.4347030046508165
Validation loss: 2.5990583794409208

Epoch: 6| Step: 12
Training loss: 2.0004499644510525
Validation loss: 2.6046771386365264

Epoch: 6| Step: 13
Training loss: 3.9082148378760015
Validation loss: 2.5995996050569667

Epoch: 59| Step: 0
Training loss: 3.065921351489713
Validation loss: 2.60296902851772

Epoch: 6| Step: 1
Training loss: 2.847156203416889
Validation loss: 2.629253515728011

Epoch: 6| Step: 2
Training loss: 3.0844132534078263
Validation loss: 2.597069335282653

Epoch: 6| Step: 3
Training loss: 3.376401963272491
Validation loss: 2.6045324082675245

Epoch: 6| Step: 4
Training loss: 2.885476801460226
Validation loss: 2.6247913943765755

Epoch: 6| Step: 5
Training loss: 2.417681009800285
Validation loss: 2.5919828813606127

Epoch: 6| Step: 6
Training loss: 2.614073856965252
Validation loss: 2.598136296566913

Epoch: 6| Step: 7
Training loss: 3.1447705290367134
Validation loss: 2.6178863292771166

Epoch: 6| Step: 8
Training loss: 3.250717377350302
Validation loss: 2.604612273125918

Epoch: 6| Step: 9
Training loss: 2.8277462869059438
Validation loss: 2.5975750540608704

Epoch: 6| Step: 10
Training loss: 2.6265546645411275
Validation loss: 2.5699212314167785

Epoch: 6| Step: 11
Training loss: 2.8264025928145307
Validation loss: 2.602458176516705

Epoch: 6| Step: 12
Training loss: 2.6921899371542946
Validation loss: 2.597942351898222

Epoch: 6| Step: 13
Training loss: 2.2086196449901854
Validation loss: 2.5838521756577304

Epoch: 60| Step: 0
Training loss: 2.994551797742085
Validation loss: 2.5875216882989736

Epoch: 6| Step: 1
Training loss: 2.3262669874551865
Validation loss: 2.6104931330977545

Epoch: 6| Step: 2
Training loss: 2.9744099520725586
Validation loss: 2.6067786157253847

Epoch: 6| Step: 3
Training loss: 3.3201401609685943
Validation loss: 2.6009387507378627

Epoch: 6| Step: 4
Training loss: 2.8187616792085857
Validation loss: 2.5760623002665963

Epoch: 6| Step: 5
Training loss: 2.472368702733939
Validation loss: 2.5875444075618095

Epoch: 6| Step: 6
Training loss: 2.8436835983404873
Validation loss: 2.5991519480448377

Epoch: 6| Step: 7
Training loss: 3.2961488620140686
Validation loss: 2.5912614031181063

Epoch: 6| Step: 8
Training loss: 3.652427174640481
Validation loss: 2.5972137688662316

Epoch: 6| Step: 9
Training loss: 2.989289875226202
Validation loss: 2.5772639234045105

Epoch: 6| Step: 10
Training loss: 2.2056298051513146
Validation loss: 2.5805707878180915

Epoch: 6| Step: 11
Training loss: 2.47486227018357
Validation loss: 2.5999542116340812

Epoch: 6| Step: 12
Training loss: 2.835534773886305
Validation loss: 2.5987324209682674

Epoch: 6| Step: 13
Training loss: 2.6838144269937962
Validation loss: 2.580010469399823

Epoch: 61| Step: 0
Training loss: 2.713418929728325
Validation loss: 2.609782984253756

Epoch: 6| Step: 1
Training loss: 2.648356838742185
Validation loss: 2.593362549240974

Epoch: 6| Step: 2
Training loss: 2.868339120200343
Validation loss: 2.6033487383313005

Epoch: 6| Step: 3
Training loss: 2.3539062175883667
Validation loss: 2.5901072789115376

Epoch: 6| Step: 4
Training loss: 3.197256825783936
Validation loss: 2.594019809452575

Epoch: 6| Step: 5
Training loss: 2.685608575285538
Validation loss: 2.5840965702211123

Epoch: 6| Step: 6
Training loss: 2.742179240244193
Validation loss: 2.5745720379177732

Epoch: 6| Step: 7
Training loss: 2.7032567692210363
Validation loss: 2.5982693379456663

Epoch: 6| Step: 8
Training loss: 3.0521884071221423
Validation loss: 2.6144139675783413

Epoch: 6| Step: 9
Training loss: 3.3387557906797203
Validation loss: 2.6159685906371095

Epoch: 6| Step: 10
Training loss: 3.0340718771078157
Validation loss: 2.5825329131693353

Epoch: 6| Step: 11
Training loss: 3.063339429758652
Validation loss: 2.5646349529255055

Epoch: 6| Step: 12
Training loss: 2.8074407213564925
Validation loss: 2.573443409968447

Epoch: 6| Step: 13
Training loss: 2.366587547090112
Validation loss: 2.574472655758477

Epoch: 62| Step: 0
Training loss: 3.143948594602483
Validation loss: 2.5983614461279982

Epoch: 6| Step: 1
Training loss: 2.2748011533589034
Validation loss: 2.6189453138312806

Epoch: 6| Step: 2
Training loss: 2.6794640806609076
Validation loss: 2.614340771199931

Epoch: 6| Step: 3
Training loss: 3.0188393336755084
Validation loss: 2.594475628962885

Epoch: 6| Step: 4
Training loss: 2.2825373322524696
Validation loss: 2.581088511520309

Epoch: 6| Step: 5
Training loss: 3.207432971471032
Validation loss: 2.602617686325609

Epoch: 6| Step: 6
Training loss: 3.4168356101593513
Validation loss: 2.612988541107968

Epoch: 6| Step: 7
Training loss: 2.8607557954697
Validation loss: 2.5761298003184696

Epoch: 6| Step: 8
Training loss: 2.1650554706259726
Validation loss: 2.5989186904951205

Epoch: 6| Step: 9
Training loss: 2.835461621251612
Validation loss: 2.5939686872417

Epoch: 6| Step: 10
Training loss: 2.5065580183521057
Validation loss: 2.5686871167957035

Epoch: 6| Step: 11
Training loss: 2.9429335966509464
Validation loss: 2.5699106144051322

Epoch: 6| Step: 12
Training loss: 2.7725796084588263
Validation loss: 2.585877224527927

Epoch: 6| Step: 13
Training loss: 4.127758144390728
Validation loss: 2.584652879926205

Epoch: 63| Step: 0
Training loss: 2.1588667319698662
Validation loss: 2.5718525713821787

Epoch: 6| Step: 1
Training loss: 2.8454443945524983
Validation loss: 2.5891302514204075

Epoch: 6| Step: 2
Training loss: 1.8798612519055804
Validation loss: 2.5985372037204173

Epoch: 6| Step: 3
Training loss: 2.168837914347718
Validation loss: 2.5569042392441657

Epoch: 6| Step: 4
Training loss: 3.0562861715411263
Validation loss: 2.587862964497008

Epoch: 6| Step: 5
Training loss: 3.536790400529875
Validation loss: 2.585993434904683

Epoch: 6| Step: 6
Training loss: 2.8278688767936853
Validation loss: 2.5812828147490956

Epoch: 6| Step: 7
Training loss: 2.841748549846844
Validation loss: 2.6065743817041196

Epoch: 6| Step: 8
Training loss: 3.152949202961037
Validation loss: 2.588854751838341

Epoch: 6| Step: 9
Training loss: 2.827068574136445
Validation loss: 2.5994328594949936

Epoch: 6| Step: 10
Training loss: 3.3614748047782808
Validation loss: 2.5911799860164058

Epoch: 6| Step: 11
Training loss: 2.851726036085461
Validation loss: 2.5801466626358716

Epoch: 6| Step: 12
Training loss: 3.1587432984438397
Validation loss: 2.584183469358197

Epoch: 6| Step: 13
Training loss: 2.927054155052709
Validation loss: 2.5925333752887103

Epoch: 64| Step: 0
Training loss: 3.03334319214389
Validation loss: 2.5840949412188143

Epoch: 6| Step: 1
Training loss: 2.7316916241843026
Validation loss: 2.5925392708379196

Epoch: 6| Step: 2
Training loss: 2.935558895205763
Validation loss: 2.5924795404527687

Epoch: 6| Step: 3
Training loss: 2.485596362575574
Validation loss: 2.5815059782937055

Epoch: 6| Step: 4
Training loss: 2.4956686645937314
Validation loss: 2.577148566818618

Epoch: 6| Step: 5
Training loss: 2.911886348665405
Validation loss: 2.5960689526298606

Epoch: 6| Step: 6
Training loss: 3.3630602118223045
Validation loss: 2.5782712246721267

Epoch: 6| Step: 7
Training loss: 2.8438660315013
Validation loss: 2.5774775284002143

Epoch: 6| Step: 8
Training loss: 3.541693040338191
Validation loss: 2.6087178854550706

Epoch: 6| Step: 9
Training loss: 2.5243556947435093
Validation loss: 2.610896499533871

Epoch: 6| Step: 10
Training loss: 2.890309744474863
Validation loss: 2.579713129287802

Epoch: 6| Step: 11
Training loss: 2.5231358964980988
Validation loss: 2.592083924292513

Epoch: 6| Step: 12
Training loss: 2.4606408318825874
Validation loss: 2.5946368013450667

Epoch: 6| Step: 13
Training loss: 3.032774079996776
Validation loss: 2.6039056350978376

Epoch: 65| Step: 0
Training loss: 3.3365114955535424
Validation loss: 2.557026120610663

Epoch: 6| Step: 1
Training loss: 1.9844640276304402
Validation loss: 2.573798858174531

Epoch: 6| Step: 2
Training loss: 2.836296962519039
Validation loss: 2.58311008682242

Epoch: 6| Step: 3
Training loss: 2.688137156342171
Validation loss: 2.6071820062000524

Epoch: 6| Step: 4
Training loss: 3.0565498314191184
Validation loss: 2.598580446726981

Epoch: 6| Step: 5
Training loss: 3.192283332420649
Validation loss: 2.597719125960526

Epoch: 6| Step: 6
Training loss: 3.417042843338797
Validation loss: 2.584335806134858

Epoch: 6| Step: 7
Training loss: 2.4300236607408277
Validation loss: 2.6022334533289357

Epoch: 6| Step: 8
Training loss: 3.0365770860922128
Validation loss: 2.6102167129849274

Epoch: 6| Step: 9
Training loss: 2.615830345707071
Validation loss: 2.559385536469955

Epoch: 6| Step: 10
Training loss: 2.2195607168302023
Validation loss: 2.5930838937270244

Epoch: 6| Step: 11
Training loss: 2.8030905254714904
Validation loss: 2.609216348374968

Epoch: 6| Step: 12
Training loss: 3.1898169978634194
Validation loss: 2.6069213342504844

Epoch: 6| Step: 13
Training loss: 2.442949219452681
Validation loss: 2.599771708270093

Epoch: 66| Step: 0
Training loss: 2.6934647128036877
Validation loss: 2.582177847174371

Epoch: 6| Step: 1
Training loss: 3.0011692947283257
Validation loss: 2.6039321534585547

Epoch: 6| Step: 2
Training loss: 2.917638798331921
Validation loss: 2.5778315143712036

Epoch: 6| Step: 3
Training loss: 2.9687946516995685
Validation loss: 2.6031205673070716

Epoch: 6| Step: 4
Training loss: 3.2010211269035405
Validation loss: 2.557841254167964

Epoch: 6| Step: 5
Training loss: 2.7764248085550265
Validation loss: 2.594666152303913

Epoch: 6| Step: 6
Training loss: 3.2833333985252824
Validation loss: 2.5721102948795016

Epoch: 6| Step: 7
Training loss: 3.406134507207395
Validation loss: 2.6108045095448316

Epoch: 6| Step: 8
Training loss: 2.9210732731964826
Validation loss: 2.6017300599452464

Epoch: 6| Step: 9
Training loss: 2.9076475659329453
Validation loss: 2.621969871745944

Epoch: 6| Step: 10
Training loss: 2.657589114858026
Validation loss: 2.5823493185619473

Epoch: 6| Step: 11
Training loss: 1.6379865957137858
Validation loss: 2.5988182191051488

Epoch: 6| Step: 12
Training loss: 2.490671970589822
Validation loss: 2.610770959552071

Epoch: 6| Step: 13
Training loss: 2.5164693043438042
Validation loss: 2.6025683598011295

Epoch: 67| Step: 0
Training loss: 2.50160852183814
Validation loss: 2.592288774815849

Epoch: 6| Step: 1
Training loss: 2.7742769931876703
Validation loss: 2.581872595221699

Epoch: 6| Step: 2
Training loss: 2.419345445307062
Validation loss: 2.599223567971829

Epoch: 6| Step: 3
Training loss: 2.3538634743587847
Validation loss: 2.596274969379698

Epoch: 6| Step: 4
Training loss: 3.141649676883268
Validation loss: 2.593965791496932

Epoch: 6| Step: 5
Training loss: 3.1037279540134337
Validation loss: 2.6102302146518555

Epoch: 6| Step: 6
Training loss: 3.2909725922168005
Validation loss: 2.6032612765308616

Epoch: 6| Step: 7
Training loss: 2.8258125588198926
Validation loss: 2.592339950922932

Epoch: 6| Step: 8
Training loss: 2.9031920393480664
Validation loss: 2.579133885361966

Epoch: 6| Step: 9
Training loss: 1.8169993098944706
Validation loss: 2.631393858119389

Epoch: 6| Step: 10
Training loss: 2.9873133070323505
Validation loss: 2.5806958121153847

Epoch: 6| Step: 11
Training loss: 3.4403109068428956
Validation loss: 2.5712154251339148

Epoch: 6| Step: 12
Training loss: 3.262320420741637
Validation loss: 2.6125081688600664

Epoch: 6| Step: 13
Training loss: 2.350869314230966
Validation loss: 2.5851348165527854

Epoch: 68| Step: 0
Training loss: 2.5665252518607176
Validation loss: 2.5759774460085123

Epoch: 6| Step: 1
Training loss: 2.7589809114709074
Validation loss: 2.5981559194515387

Epoch: 6| Step: 2
Training loss: 2.499073142853914
Validation loss: 2.5823212472642

Epoch: 6| Step: 3
Training loss: 3.2644151700707265
Validation loss: 2.6029537488746985

Epoch: 6| Step: 4
Training loss: 3.5121325969299577
Validation loss: 2.5869554325972053

Epoch: 6| Step: 5
Training loss: 3.164480525530211
Validation loss: 2.5913961606928

Epoch: 6| Step: 6
Training loss: 2.5083949283206106
Validation loss: 2.595094364263636

Epoch: 6| Step: 7
Training loss: 2.7976884564695355
Validation loss: 2.5925180252408477

Epoch: 6| Step: 8
Training loss: 2.7762449856866986
Validation loss: 2.5965941662333067

Epoch: 6| Step: 9
Training loss: 2.617895958508045
Validation loss: 2.5893982626447305

Epoch: 6| Step: 10
Training loss: 2.878351994115099
Validation loss: 2.5922027195211452

Epoch: 6| Step: 11
Training loss: 2.905209262684076
Validation loss: 2.5977563261877794

Epoch: 6| Step: 12
Training loss: 2.9247905036696977
Validation loss: 2.5890313003556074

Epoch: 6| Step: 13
Training loss: 2.0164599204948046
Validation loss: 2.610384786917743

Epoch: 69| Step: 0
Training loss: 2.7402300246646685
Validation loss: 2.5946945593605846

Epoch: 6| Step: 1
Training loss: 2.761036056028905
Validation loss: 2.6001963256927922

Epoch: 6| Step: 2
Training loss: 2.0247579265062052
Validation loss: 2.5810654543414238

Epoch: 6| Step: 3
Training loss: 3.182953228318335
Validation loss: 2.596163435741423

Epoch: 6| Step: 4
Training loss: 2.7495844266908285
Validation loss: 2.6144183399784953

Epoch: 6| Step: 5
Training loss: 2.52628159055442
Validation loss: 2.58824609885673

Epoch: 6| Step: 6
Training loss: 2.8198193570710255
Validation loss: 2.596677308162729

Epoch: 6| Step: 7
Training loss: 3.693267708159773
Validation loss: 2.569690694836741

Epoch: 6| Step: 8
Training loss: 2.6918553391538618
Validation loss: 2.5842141870289006

Epoch: 6| Step: 9
Training loss: 2.2371367346114863
Validation loss: 2.5768293329990866

Epoch: 6| Step: 10
Training loss: 2.9440915438060933
Validation loss: 2.5871969527374237

Epoch: 6| Step: 11
Training loss: 2.9474193211871342
Validation loss: 2.5909537443848727

Epoch: 6| Step: 12
Training loss: 2.912488578806737
Validation loss: 2.6073405525160287

Epoch: 6| Step: 13
Training loss: 3.6316913802654187
Validation loss: 2.5703930451163632

Epoch: 70| Step: 0
Training loss: 3.216548722498091
Validation loss: 2.584341704512997

Epoch: 6| Step: 1
Training loss: 2.700810847562999
Validation loss: 2.573753778403202

Epoch: 6| Step: 2
Training loss: 2.5048137097558882
Validation loss: 2.5999991585735667

Epoch: 6| Step: 3
Training loss: 3.1799469263218265
Validation loss: 2.610015737419882

Epoch: 6| Step: 4
Training loss: 2.9443020896168033
Validation loss: 2.587323735642627

Epoch: 6| Step: 5
Training loss: 2.4300323928432177
Validation loss: 2.6023724668625725

Epoch: 6| Step: 6
Training loss: 3.5743526913086283
Validation loss: 2.5850402714979417

Epoch: 6| Step: 7
Training loss: 2.552508156639166
Validation loss: 2.59164505097425

Epoch: 6| Step: 8
Training loss: 3.3395517678929627
Validation loss: 2.6010750146286727

Epoch: 6| Step: 9
Training loss: 3.0783527115764557
Validation loss: 2.61185425423373

Epoch: 6| Step: 10
Training loss: 2.3640409903546824
Validation loss: 2.567346740900375

Epoch: 6| Step: 11
Training loss: 2.1815492615996854
Validation loss: 2.5856626978207653

Epoch: 6| Step: 12
Training loss: 2.523593956788658
Validation loss: 2.6143602910882864

Epoch: 6| Step: 13
Training loss: 3.0579797510907514
Validation loss: 2.622676340473814

Epoch: 71| Step: 0
Training loss: 2.975463343850114
Validation loss: 2.600730364062436

Epoch: 6| Step: 1
Training loss: 3.6522071853646394
Validation loss: 2.58940716221279

Epoch: 6| Step: 2
Training loss: 2.680236760114859
Validation loss: 2.5753501350188572

Epoch: 6| Step: 3
Training loss: 2.9037228333166736
Validation loss: 2.590522533256526

Epoch: 6| Step: 4
Training loss: 2.318755067064039
Validation loss: 2.5861096797118335

Epoch: 6| Step: 5
Training loss: 3.580196397391697
Validation loss: 2.5894418874625926

Epoch: 6| Step: 6
Training loss: 2.653557164161745
Validation loss: 2.5993722129927375

Epoch: 6| Step: 7
Training loss: 2.3987521980915663
Validation loss: 2.5973274421936616

Epoch: 6| Step: 8
Training loss: 2.9502404066501513
Validation loss: 2.5716162574589196

Epoch: 6| Step: 9
Training loss: 3.0723900984996027
Validation loss: 2.5705205251752705

Epoch: 6| Step: 10
Training loss: 2.4212380833054366
Validation loss: 2.5974816077881426

Epoch: 6| Step: 11
Training loss: 2.469768362419352
Validation loss: 2.5952427701518617

Epoch: 6| Step: 12
Training loss: 2.5540015556731
Validation loss: 2.592179268684811

Epoch: 6| Step: 13
Training loss: 2.698845976995343
Validation loss: 2.578632089831664

Epoch: 72| Step: 0
Training loss: 3.0588821528500265
Validation loss: 2.5759499123587193

Epoch: 6| Step: 1
Training loss: 3.3063599883679733
Validation loss: 2.5631718478890586

Epoch: 6| Step: 2
Training loss: 3.167542303054244
Validation loss: 2.5581768934684255

Epoch: 6| Step: 3
Training loss: 2.984224804998373
Validation loss: 2.5757524090596036

Epoch: 6| Step: 4
Training loss: 3.123084740233242
Validation loss: 2.5957304807262656

Epoch: 6| Step: 5
Training loss: 2.7245105793860076
Validation loss: 2.5625865300393222

Epoch: 6| Step: 6
Training loss: 3.4636648208788974
Validation loss: 2.57647601629675

Epoch: 6| Step: 7
Training loss: 2.5378430064218196
Validation loss: 2.5725021563137584

Epoch: 6| Step: 8
Training loss: 2.9873370904278116
Validation loss: 2.578364931180443

Epoch: 6| Step: 9
Training loss: 2.874535564558919
Validation loss: 2.6075511077370312

Epoch: 6| Step: 10
Training loss: 1.9607776105523065
Validation loss: 2.569581352547102

Epoch: 6| Step: 11
Training loss: 1.7679095047191247
Validation loss: 2.6083852192394104

Epoch: 6| Step: 12
Training loss: 2.825660516945577
Validation loss: 2.575031240743464

Epoch: 6| Step: 13
Training loss: 2.279492262806849
Validation loss: 2.5912281907345305

Epoch: 73| Step: 0
Training loss: 3.213522508626966
Validation loss: 2.6007550192425817

Epoch: 6| Step: 1
Training loss: 2.8775003589991157
Validation loss: 2.6108606795571174

Epoch: 6| Step: 2
Training loss: 3.3618597732882773
Validation loss: 2.5734596478271707

Epoch: 6| Step: 3
Training loss: 2.3854578561572195
Validation loss: 2.586937318272293

Epoch: 6| Step: 4
Training loss: 2.441753490930981
Validation loss: 2.609067284066392

Epoch: 6| Step: 5
Training loss: 2.998520645332601
Validation loss: 2.59074912226924

Epoch: 6| Step: 6
Training loss: 3.0849433166638263
Validation loss: 2.570874625442604

Epoch: 6| Step: 7
Training loss: 2.577402464448484
Validation loss: 2.5747096574123733

Epoch: 6| Step: 8
Training loss: 2.492992689590967
Validation loss: 2.5656444446353017

Epoch: 6| Step: 9
Training loss: 3.3265526150995104
Validation loss: 2.5693187147037606

Epoch: 6| Step: 10
Training loss: 1.958549108860027
Validation loss: 2.57636496091237

Epoch: 6| Step: 11
Training loss: 3.2575030648721373
Validation loss: 2.5914210115222325

Epoch: 6| Step: 12
Training loss: 2.5073503205037433
Validation loss: 2.5895317895841967

Epoch: 6| Step: 13
Training loss: 3.1352926506449106
Validation loss: 2.594479060684478

Epoch: 74| Step: 0
Training loss: 3.208241614149524
Validation loss: 2.590802147025709

Epoch: 6| Step: 1
Training loss: 2.5521873816215384
Validation loss: 2.5810607741479763

Epoch: 6| Step: 2
Training loss: 2.792707012156755
Validation loss: 2.5824758788389

Epoch: 6| Step: 3
Training loss: 3.1963126335825036
Validation loss: 2.577897039821606

Epoch: 6| Step: 4
Training loss: 3.0827360519775464
Validation loss: 2.58793448870915

Epoch: 6| Step: 5
Training loss: 2.501714785894787
Validation loss: 2.5676498188431163

Epoch: 6| Step: 6
Training loss: 3.0089576820042327
Validation loss: 2.5865668193508498

Epoch: 6| Step: 7
Training loss: 2.127980106031313
Validation loss: 2.568473651111848

Epoch: 6| Step: 8
Training loss: 2.7937504881446635
Validation loss: 2.576225638636151

Epoch: 6| Step: 9
Training loss: 2.961416563065311
Validation loss: 2.5835070707096834

Epoch: 6| Step: 10
Training loss: 2.175479231030155
Validation loss: 2.5653824090575923

Epoch: 6| Step: 11
Training loss: 1.9883388068781185
Validation loss: 2.568455280678259

Epoch: 6| Step: 12
Training loss: 3.2216509736519745
Validation loss: 2.6135489524132542

Epoch: 6| Step: 13
Training loss: 4.254916320766898
Validation loss: 2.616931344532151

Epoch: 75| Step: 0
Training loss: 3.030468869584217
Validation loss: 2.569320587554992

Epoch: 6| Step: 1
Training loss: 3.4449783820593773
Validation loss: 2.564859814850444

Epoch: 6| Step: 2
Training loss: 2.254579968971342
Validation loss: 2.586958742493517

Epoch: 6| Step: 3
Training loss: 2.4774238700987383
Validation loss: 2.5772019549583365

Epoch: 6| Step: 4
Training loss: 2.709286145575919
Validation loss: 2.5681291364475176

Epoch: 6| Step: 5
Training loss: 3.21445022343676
Validation loss: 2.572158077571542

Epoch: 6| Step: 6
Training loss: 3.032766847497799
Validation loss: 2.5754393848143895

Epoch: 6| Step: 7
Training loss: 3.5265544629290617
Validation loss: 2.5880244654823907

Epoch: 6| Step: 8
Training loss: 2.21538837067783
Validation loss: 2.5946876421410034

Epoch: 6| Step: 9
Training loss: 2.1405074929612127
Validation loss: 2.576115625334867

Epoch: 6| Step: 10
Training loss: 2.8029674472994004
Validation loss: 2.5941115244876825

Epoch: 6| Step: 11
Training loss: 2.698308457214156
Validation loss: 2.589067526312581

Epoch: 6| Step: 12
Training loss: 2.867048629183337
Validation loss: 2.591072919914938

Epoch: 6| Step: 13
Training loss: 3.2140980408390605
Validation loss: 2.587703419974629

Epoch: 76| Step: 0
Training loss: 3.199126935114119
Validation loss: 2.5710701971256276

Epoch: 6| Step: 1
Training loss: 2.3951807432523085
Validation loss: 2.590705656516967

Epoch: 6| Step: 2
Training loss: 2.9681154878053846
Validation loss: 2.580830027703679

Epoch: 6| Step: 3
Training loss: 2.852046392483462
Validation loss: 2.5815079147979807

Epoch: 6| Step: 4
Training loss: 3.2214678798497
Validation loss: 2.58461026584775

Epoch: 6| Step: 5
Training loss: 3.097263383425535
Validation loss: 2.6093543144390106

Epoch: 6| Step: 6
Training loss: 3.0026278113001883
Validation loss: 2.6376799016204826

Epoch: 6| Step: 7
Training loss: 1.3841382584172386
Validation loss: 2.5726925571008796

Epoch: 6| Step: 8
Training loss: 2.782708117986805
Validation loss: 2.60252490034496

Epoch: 6| Step: 9
Training loss: 2.694797278655089
Validation loss: 2.592271108670402

Epoch: 6| Step: 10
Training loss: 3.216262596986359
Validation loss: 2.595554758273614

Epoch: 6| Step: 11
Training loss: 2.972308465611551
Validation loss: 2.6031273271962196

Epoch: 6| Step: 12
Training loss: 2.5889543067551077
Validation loss: 2.607889111076391

Epoch: 6| Step: 13
Training loss: 3.0593860910465933
Validation loss: 2.584403341064803

Epoch: 77| Step: 0
Training loss: 2.7470307359173662
Validation loss: 2.5948620302796943

Epoch: 6| Step: 1
Training loss: 3.274413625624412
Validation loss: 2.6058526977933805

Epoch: 6| Step: 2
Training loss: 3.0457783608405022
Validation loss: 2.5843097116516187

Epoch: 6| Step: 3
Training loss: 2.512910314050217
Validation loss: 2.588164216444979

Epoch: 6| Step: 4
Training loss: 2.5368765003907585
Validation loss: 2.587135272749343

Epoch: 6| Step: 5
Training loss: 2.4346430737409728
Validation loss: 2.6052717083404806

Epoch: 6| Step: 6
Training loss: 2.945887825626895
Validation loss: 2.5866322493866725

Epoch: 6| Step: 7
Training loss: 3.309820711057211
Validation loss: 2.5996765023025477

Epoch: 6| Step: 8
Training loss: 2.6573939833213993
Validation loss: 2.5777727201489027

Epoch: 6| Step: 9
Training loss: 2.8444466209237724
Validation loss: 2.586076410087781

Epoch: 6| Step: 10
Training loss: 2.6960518969965745
Validation loss: 2.598126860518485

Epoch: 6| Step: 11
Training loss: 2.889019989641698
Validation loss: 2.6029921694125835

Epoch: 6| Step: 12
Training loss: 2.673329899738926
Validation loss: 2.5872375474070646

Epoch: 6| Step: 13
Training loss: 2.996730294179756
Validation loss: 2.594025284072415

Epoch: 78| Step: 0
Training loss: 2.683521430805479
Validation loss: 2.589970449862737

Epoch: 6| Step: 1
Training loss: 2.10497067138827
Validation loss: 2.5491426771598418

Epoch: 6| Step: 2
Training loss: 2.586081970420341
Validation loss: 2.569258981308365

Epoch: 6| Step: 3
Training loss: 2.926839924711506
Validation loss: 2.5814207061151047

Epoch: 6| Step: 4
Training loss: 2.860541100699996
Validation loss: 2.5863877356100353

Epoch: 6| Step: 5
Training loss: 2.526546959956026
Validation loss: 2.574049823460482

Epoch: 6| Step: 6
Training loss: 2.8777857014053168
Validation loss: 2.58480076356928

Epoch: 6| Step: 7
Training loss: 3.5023365395935704
Validation loss: 2.5977067968221896

Epoch: 6| Step: 8
Training loss: 2.0031237050259074
Validation loss: 2.5955563721819632

Epoch: 6| Step: 9
Training loss: 2.57581341312357
Validation loss: 2.572635429176524

Epoch: 6| Step: 10
Training loss: 2.5680710315209376
Validation loss: 2.5807960254656055

Epoch: 6| Step: 11
Training loss: 3.7344998773740032
Validation loss: 2.570211610579115

Epoch: 6| Step: 12
Training loss: 2.971632190817437
Validation loss: 2.6046473837538278

Epoch: 6| Step: 13
Training loss: 3.2553416151099865
Validation loss: 2.5726669289628017

Epoch: 79| Step: 0
Training loss: 3.094353665112856
Validation loss: 2.5776054209280344

Epoch: 6| Step: 1
Training loss: 3.300914296736129
Validation loss: 2.5816004204116436

Epoch: 6| Step: 2
Training loss: 2.160726130609574
Validation loss: 2.5428650698800537

Epoch: 6| Step: 3
Training loss: 2.097991064192631
Validation loss: 2.5850754426701803

Epoch: 6| Step: 4
Training loss: 2.7137383934556465
Validation loss: 2.571357332911387

Epoch: 6| Step: 5
Training loss: 3.175533195839851
Validation loss: 2.5787041375045967

Epoch: 6| Step: 6
Training loss: 3.3473212164612876
Validation loss: 2.6007233416502715

Epoch: 6| Step: 7
Training loss: 3.478273532160225
Validation loss: 2.5509026721859853

Epoch: 6| Step: 8
Training loss: 2.4278355252837023
Validation loss: 2.585038556810485

Epoch: 6| Step: 9
Training loss: 3.2101026503172343
Validation loss: 2.5792787656902023

Epoch: 6| Step: 10
Training loss: 2.299275914530515
Validation loss: 2.600957484119583

Epoch: 6| Step: 11
Training loss: 2.647894339438568
Validation loss: 2.589712397199282

Epoch: 6| Step: 12
Training loss: 2.4458796906721876
Validation loss: 2.5785311391752943

Epoch: 6| Step: 13
Training loss: 2.6758323942990843
Validation loss: 2.586894760654739

Epoch: 80| Step: 0
Training loss: 3.1560100804157054
Validation loss: 2.5953043266031814

Epoch: 6| Step: 1
Training loss: 2.5504930692697094
Validation loss: 2.601641951506888

Epoch: 6| Step: 2
Training loss: 2.6019110918622976
Validation loss: 2.577383002846059

Epoch: 6| Step: 3
Training loss: 2.726866084907642
Validation loss: 2.5882360918827327

Epoch: 6| Step: 4
Training loss: 3.1297860688539068
Validation loss: 2.577161035092434

Epoch: 6| Step: 5
Training loss: 2.6978721074925383
Validation loss: 2.61619697086337

Epoch: 6| Step: 6
Training loss: 2.9699052670972903
Validation loss: 2.584218151212742

Epoch: 6| Step: 7
Training loss: 2.2445936949156584
Validation loss: 2.598850397361864

Epoch: 6| Step: 8
Training loss: 2.5045429913864776
Validation loss: 2.5714420659600212

Epoch: 6| Step: 9
Training loss: 2.8722715284623304
Validation loss: 2.5670261982507547

Epoch: 6| Step: 10
Training loss: 3.0396337291016304
Validation loss: 2.580231354944608

Epoch: 6| Step: 11
Training loss: 2.9051207943093877
Validation loss: 2.584758577423963

Epoch: 6| Step: 12
Training loss: 3.2569072389590086
Validation loss: 2.5783743291856798

Epoch: 6| Step: 13
Training loss: 2.65631076518846
Validation loss: 2.6041912276227532

Epoch: 81| Step: 0
Training loss: 2.0543766149149536
Validation loss: 2.59607901729886

Epoch: 6| Step: 1
Training loss: 3.0413323484310757
Validation loss: 2.585375172086719

Epoch: 6| Step: 2
Training loss: 3.658205471251917
Validation loss: 2.5810794253437956

Epoch: 6| Step: 3
Training loss: 2.518719588254678
Validation loss: 2.596937446657364

Epoch: 6| Step: 4
Training loss: 2.9726841608208425
Validation loss: 2.5609986984379614

Epoch: 6| Step: 5
Training loss: 2.704228346894625
Validation loss: 2.5786865229441456

Epoch: 6| Step: 6
Training loss: 2.9012123664936365
Validation loss: 2.5833324851816344

Epoch: 6| Step: 7
Training loss: 2.541024257167313
Validation loss: 2.578966764402943

Epoch: 6| Step: 8
Training loss: 2.690163290747197
Validation loss: 2.617614429164696

Epoch: 6| Step: 9
Training loss: 2.9211780716508784
Validation loss: 2.5738509133814076

Epoch: 6| Step: 10
Training loss: 3.144908508037361
Validation loss: 2.5938378892545426

Epoch: 6| Step: 11
Training loss: 3.059264361647787
Validation loss: 2.5917635131927175

Epoch: 6| Step: 12
Training loss: 2.8652649964280545
Validation loss: 2.5907038693835758

Epoch: 6| Step: 13
Training loss: 1.5257378059761249
Validation loss: 2.5852905927547916

Epoch: 82| Step: 0
Training loss: 2.6553001949621837
Validation loss: 2.5912841707179677

Epoch: 6| Step: 1
Training loss: 2.106558721086536
Validation loss: 2.571204130481347

Epoch: 6| Step: 2
Training loss: 2.5284011256216203
Validation loss: 2.6018279358800624

Epoch: 6| Step: 3
Training loss: 2.7698993303755715
Validation loss: 2.5813548867588065

Epoch: 6| Step: 4
Training loss: 3.3785012063045023
Validation loss: 2.61509734508994

Epoch: 6| Step: 5
Training loss: 3.2200459954430083
Validation loss: 2.602086351565432

Epoch: 6| Step: 6
Training loss: 2.5871677756683633
Validation loss: 2.597196994486636

Epoch: 6| Step: 7
Training loss: 2.4678915921642606
Validation loss: 2.5918513283651703

Epoch: 6| Step: 8
Training loss: 2.743898037542519
Validation loss: 2.5809215980824023

Epoch: 6| Step: 9
Training loss: 3.6108225112096686
Validation loss: 2.5970144632022114

Epoch: 6| Step: 10
Training loss: 2.5612008127578525
Validation loss: 2.586856071303952

Epoch: 6| Step: 11
Training loss: 3.52322068995846
Validation loss: 2.593543596848195

Epoch: 6| Step: 12
Training loss: 1.7532502372738274
Validation loss: 2.576826570210814

Epoch: 6| Step: 13
Training loss: 3.291698278605293
Validation loss: 2.5653286949889713

Epoch: 83| Step: 0
Training loss: 3.269746215024791
Validation loss: 2.591488297508179

Epoch: 6| Step: 1
Training loss: 2.74860225181529
Validation loss: 2.592955960836458

Epoch: 6| Step: 2
Training loss: 2.6666997569733177
Validation loss: 2.5684104514777832

Epoch: 6| Step: 3
Training loss: 2.4672006501613803
Validation loss: 2.585491668781224

Epoch: 6| Step: 4
Training loss: 2.6471962509758167
Validation loss: 2.597549046190135

Epoch: 6| Step: 5
Training loss: 1.8900416711724402
Validation loss: 2.585970122067104

Epoch: 6| Step: 6
Training loss: 3.4300317265680897
Validation loss: 2.574208599861489

Epoch: 6| Step: 7
Training loss: 2.7377063621183164
Validation loss: 2.5758513019384486

Epoch: 6| Step: 8
Training loss: 3.1819315122262664
Validation loss: 2.580879821350178

Epoch: 6| Step: 9
Training loss: 3.0285398027922907
Validation loss: 2.5926256279233164

Epoch: 6| Step: 10
Training loss: 3.0688734103558364
Validation loss: 2.6016681697352078

Epoch: 6| Step: 11
Training loss: 2.987688232620967
Validation loss: 2.6004761227178324

Epoch: 6| Step: 12
Training loss: 2.405763453054606
Validation loss: 2.568383610277026

Epoch: 6| Step: 13
Training loss: 2.3869155328170333
Validation loss: 2.570981546506885

Epoch: 84| Step: 0
Training loss: 2.833390871099534
Validation loss: 2.5970353995642697

Epoch: 6| Step: 1
Training loss: 2.5378265659302754
Validation loss: 2.5746881342524937

Epoch: 6| Step: 2
Training loss: 3.116163042418287
Validation loss: 2.584220987445647

Epoch: 6| Step: 3
Training loss: 2.2057248190184304
Validation loss: 2.580486958054986

Epoch: 6| Step: 4
Training loss: 2.9509842798479404
Validation loss: 2.590021477278957

Epoch: 6| Step: 5
Training loss: 3.241913344960113
Validation loss: 2.5806287772032843

Epoch: 6| Step: 6
Training loss: 2.774841554946843
Validation loss: 2.583961065863408

Epoch: 6| Step: 7
Training loss: 3.253332923305465
Validation loss: 2.5662619615955573

Epoch: 6| Step: 8
Training loss: 2.3760256309475447
Validation loss: 2.5778624559094534

Epoch: 6| Step: 9
Training loss: 2.5510972485939156
Validation loss: 2.587956440592317

Epoch: 6| Step: 10
Training loss: 3.685560848045849
Validation loss: 2.5869390653949935

Epoch: 6| Step: 11
Training loss: 2.5190710312784397
Validation loss: 2.606243863151051

Epoch: 6| Step: 12
Training loss: 2.555236010914093
Validation loss: 2.557415024533303

Epoch: 6| Step: 13
Training loss: 2.0350433142548967
Validation loss: 2.5892433147675864

Epoch: 85| Step: 0
Training loss: 2.545770136355245
Validation loss: 2.5672847637479586

Epoch: 6| Step: 1
Training loss: 2.845641460810959
Validation loss: 2.609086235190292

Epoch: 6| Step: 2
Training loss: 2.650876432914093
Validation loss: 2.580622289685063

Epoch: 6| Step: 3
Training loss: 2.7004525970892317
Validation loss: 2.585735197512262

Epoch: 6| Step: 4
Training loss: 2.8198765129755943
Validation loss: 2.5800956565318

Epoch: 6| Step: 5
Training loss: 3.034115410336625
Validation loss: 2.573736041311767

Epoch: 6| Step: 6
Training loss: 2.7165021702241505
Validation loss: 2.5919709393572297

Epoch: 6| Step: 7
Training loss: 3.1651624486613663
Validation loss: 2.581895563772321

Epoch: 6| Step: 8
Training loss: 2.9499318454434214
Validation loss: 2.565936492727856

Epoch: 6| Step: 9
Training loss: 2.874785042065917
Validation loss: 2.5615792219630023

Epoch: 6| Step: 10
Training loss: 3.093087019348977
Validation loss: 2.5539105137463016

Epoch: 6| Step: 11
Training loss: 2.2072537740419564
Validation loss: 2.592550766230352

Epoch: 6| Step: 12
Training loss: 2.489444574508696
Validation loss: 2.5821712141281217

Epoch: 6| Step: 13
Training loss: 3.5064584544293633
Validation loss: 2.583988339536403

Epoch: 86| Step: 0
Training loss: 3.104040890050731
Validation loss: 2.588802734911518

Epoch: 6| Step: 1
Training loss: 2.2659680337023165
Validation loss: 2.5958453680732028

Epoch: 6| Step: 2
Training loss: 2.7521976013102174
Validation loss: 2.5738721427427813

Epoch: 6| Step: 3
Training loss: 2.9316845407062164
Validation loss: 2.605934936361153

Epoch: 6| Step: 4
Training loss: 2.774526033219889
Validation loss: 2.577452099522919

Epoch: 6| Step: 5
Training loss: 3.2025869522380663
Validation loss: 2.6088255353549434

Epoch: 6| Step: 6
Training loss: 2.7259999216741604
Validation loss: 2.573041818109222

Epoch: 6| Step: 7
Training loss: 2.63481919422933
Validation loss: 2.5631111620737745

Epoch: 6| Step: 8
Training loss: 2.8460179601814346
Validation loss: 2.578346267308639

Epoch: 6| Step: 9
Training loss: 2.8461556791509803
Validation loss: 2.5805627488941325

Epoch: 6| Step: 10
Training loss: 2.5619214032733892
Validation loss: 2.5818170287937963

Epoch: 6| Step: 11
Training loss: 2.8540890722563383
Validation loss: 2.5831877746486693

Epoch: 6| Step: 12
Training loss: 2.876371636966495
Validation loss: 2.5836165594102254

Epoch: 6| Step: 13
Training loss: 3.093709155497031
Validation loss: 2.5631450298448373

Epoch: 87| Step: 0
Training loss: 2.425665270602043
Validation loss: 2.591192176038767

Epoch: 6| Step: 1
Training loss: 2.5028437652902245
Validation loss: 2.5749385558795184

Epoch: 6| Step: 2
Training loss: 2.646313921517215
Validation loss: 2.560197479545816

Epoch: 6| Step: 3
Training loss: 2.1556669912122217
Validation loss: 2.592626673106075

Epoch: 6| Step: 4
Training loss: 2.8361126974335744
Validation loss: 2.585808338111644

Epoch: 6| Step: 5
Training loss: 3.4464015493738347
Validation loss: 2.595727924719284

Epoch: 6| Step: 6
Training loss: 2.5620023662904625
Validation loss: 2.56199079587039

Epoch: 6| Step: 7
Training loss: 2.9667926961581825
Validation loss: 2.5904851460200793

Epoch: 6| Step: 8
Training loss: 2.7029586476201644
Validation loss: 2.57865088783726

Epoch: 6| Step: 9
Training loss: 3.1961856758886613
Validation loss: 2.570216039224044

Epoch: 6| Step: 10
Training loss: 2.4834340550864513
Validation loss: 2.5738008298611215

Epoch: 6| Step: 11
Training loss: 2.7296626001979054
Validation loss: 2.5738788639097474

Epoch: 6| Step: 12
Training loss: 3.0386978362112482
Validation loss: 2.5732039743342066

Epoch: 6| Step: 13
Training loss: 3.407978144436813
Validation loss: 2.6090610397062584

Epoch: 88| Step: 0
Training loss: 3.211121788212479
Validation loss: 2.584999251577884

Epoch: 6| Step: 1
Training loss: 2.2154229162086305
Validation loss: 2.5784727665589062

Epoch: 6| Step: 2
Training loss: 3.3329281242762794
Validation loss: 2.6022363083481412

Epoch: 6| Step: 3
Training loss: 2.400471275470788
Validation loss: 2.6100673689096108

Epoch: 6| Step: 4
Training loss: 3.0872645361685773
Validation loss: 2.5701982128843013

Epoch: 6| Step: 5
Training loss: 3.0858537493579887
Validation loss: 2.594504711004535

Epoch: 6| Step: 6
Training loss: 2.269000465712451
Validation loss: 2.595739878573418

Epoch: 6| Step: 7
Training loss: 2.696555030910551
Validation loss: 2.5868725515119633

Epoch: 6| Step: 8
Training loss: 3.1659226965753473
Validation loss: 2.60781937969276

Epoch: 6| Step: 9
Training loss: 2.585583250553815
Validation loss: 2.6028524542146543

Epoch: 6| Step: 10
Training loss: 2.761561107317867
Validation loss: 2.5781116871817917

Epoch: 6| Step: 11
Training loss: 2.9299540894332328
Validation loss: 2.603423706063678

Epoch: 6| Step: 12
Training loss: 2.6933195403032295
Validation loss: 2.5622402652792653

Epoch: 6| Step: 13
Training loss: 2.2571456610815694
Validation loss: 2.581243941964817

Epoch: 89| Step: 0
Training loss: 2.8277071649428174
Validation loss: 2.574674067830348

Epoch: 6| Step: 1
Training loss: 2.245180478392372
Validation loss: 2.5996048258224533

Epoch: 6| Step: 2
Training loss: 2.4406756719391667
Validation loss: 2.6005340221402946

Epoch: 6| Step: 3
Training loss: 3.0989068718919546
Validation loss: 2.5845839549263214

Epoch: 6| Step: 4
Training loss: 2.5749619934832633
Validation loss: 2.589727642115909

Epoch: 6| Step: 5
Training loss: 2.83919688837306
Validation loss: 2.5974985969685975

Epoch: 6| Step: 6
Training loss: 2.5927800582542586
Validation loss: 2.5847618970762403

Epoch: 6| Step: 7
Training loss: 2.5548801174518503
Validation loss: 2.577726415982731

Epoch: 6| Step: 8
Training loss: 2.9188869926111844
Validation loss: 2.5862666402254377

Epoch: 6| Step: 9
Training loss: 2.706506807683406
Validation loss: 2.577308756766224

Epoch: 6| Step: 10
Training loss: 3.0737716950794636
Validation loss: 2.5777791566595187

Epoch: 6| Step: 11
Training loss: 3.4991729304079007
Validation loss: 2.615336119357105

Epoch: 6| Step: 12
Training loss: 2.0894152050389247
Validation loss: 2.5788006177879272

Epoch: 6| Step: 13
Training loss: 4.20668259276586
Validation loss: 2.5722986177883462

Epoch: 90| Step: 0
Training loss: 2.9916296854806124
Validation loss: 2.6075288685570235

Epoch: 6| Step: 1
Training loss: 3.211737836977308
Validation loss: 2.589326788766786

Epoch: 6| Step: 2
Training loss: 2.5328414058741995
Validation loss: 2.5972444331075772

Epoch: 6| Step: 3
Training loss: 2.706428053286691
Validation loss: 2.5823754656152285

Epoch: 6| Step: 4
Training loss: 3.089922762896196
Validation loss: 2.5730133164697717

Epoch: 6| Step: 5
Training loss: 3.2218917772242923
Validation loss: 2.601187647485125

Epoch: 6| Step: 6
Training loss: 2.5762910735786013
Validation loss: 2.579026404663791

Epoch: 6| Step: 7
Training loss: 2.947530462804854
Validation loss: 2.5678354588062637

Epoch: 6| Step: 8
Training loss: 2.9850896009738612
Validation loss: 2.5844584253501113

Epoch: 6| Step: 9
Training loss: 2.68746114303532
Validation loss: 2.5813237785218495

Epoch: 6| Step: 10
Training loss: 1.9762890291069783
Validation loss: 2.6200124878763056

Epoch: 6| Step: 11
Training loss: 2.1367740937759496
Validation loss: 2.582745185082394

Epoch: 6| Step: 12
Training loss: 2.881477687883681
Validation loss: 2.5809860080988893

Epoch: 6| Step: 13
Training loss: 2.717345302358266
Validation loss: 2.5880491723661043

Epoch: 91| Step: 0
Training loss: 3.339532063535451
Validation loss: 2.6075106887221553

Epoch: 6| Step: 1
Training loss: 2.695046585897671
Validation loss: 2.5854080917822913

Epoch: 6| Step: 2
Training loss: 3.7057122958190867
Validation loss: 2.5690145263885156

Epoch: 6| Step: 3
Training loss: 3.0011704069146643
Validation loss: 2.5741598523474014

Epoch: 6| Step: 4
Training loss: 2.6902875416169905
Validation loss: 2.5859586598779374

Epoch: 6| Step: 5
Training loss: 2.3574175261778962
Validation loss: 2.5882892483508044

Epoch: 6| Step: 6
Training loss: 2.1155864672624154
Validation loss: 2.5737801362901513

Epoch: 6| Step: 7
Training loss: 2.722174844091654
Validation loss: 2.5794255978138043

Epoch: 6| Step: 8
Training loss: 2.4608485614509115
Validation loss: 2.5932554625286497

Epoch: 6| Step: 9
Training loss: 2.782020462130911
Validation loss: 2.5933527745465783

Epoch: 6| Step: 10
Training loss: 2.717873267513885
Validation loss: 2.598968578504779

Epoch: 6| Step: 11
Training loss: 2.7383405431403705
Validation loss: 2.5991876078406397

Epoch: 6| Step: 12
Training loss: 2.3770962549026113
Validation loss: 2.5961292867343486

Epoch: 6| Step: 13
Training loss: 3.288215582534716
Validation loss: 2.591762003750699

Epoch: 92| Step: 0
Training loss: 2.1058983302630696
Validation loss: 2.5868191989420426

Epoch: 6| Step: 1
Training loss: 2.2147190926807996
Validation loss: 2.5900879944291244

Epoch: 6| Step: 2
Training loss: 2.836509625861506
Validation loss: 2.5710117418655214

Epoch: 6| Step: 3
Training loss: 2.8966801089145737
Validation loss: 2.590593605024943

Epoch: 6| Step: 4
Training loss: 2.5871498055216935
Validation loss: 2.6049257500294822

Epoch: 6| Step: 5
Training loss: 2.171680469171435
Validation loss: 2.5668210929096054

Epoch: 6| Step: 6
Training loss: 2.851333399936383
Validation loss: 2.576208970406895

Epoch: 6| Step: 7
Training loss: 3.4205881425073117
Validation loss: 2.5512410149833054

Epoch: 6| Step: 8
Training loss: 2.8609944744676756
Validation loss: 2.590908612820734

Epoch: 6| Step: 9
Training loss: 2.230968733297855
Validation loss: 2.577939761888241

Epoch: 6| Step: 10
Training loss: 3.0644525025891656
Validation loss: 2.5920518014899456

Epoch: 6| Step: 11
Training loss: 3.09937984046935
Validation loss: 2.5754924769166525

Epoch: 6| Step: 12
Training loss: 3.078441468057078
Validation loss: 2.5570674824958552

Epoch: 6| Step: 13
Training loss: 3.3915766773579565
Validation loss: 2.596850277338884

Epoch: 93| Step: 0
Training loss: 2.338279953028061
Validation loss: 2.577193384281754

Epoch: 6| Step: 1
Training loss: 3.4345290783795055
Validation loss: 2.5540068465609473

Epoch: 6| Step: 2
Training loss: 2.802539651200588
Validation loss: 2.566258287349846

Epoch: 6| Step: 3
Training loss: 3.469313292259526
Validation loss: 2.5695695199394626

Epoch: 6| Step: 4
Training loss: 2.4741477385178396
Validation loss: 2.556393032995016

Epoch: 6| Step: 5
Training loss: 2.7825390689434233
Validation loss: 2.5633201277153046

Epoch: 6| Step: 6
Training loss: 2.714001685533443
Validation loss: 2.584750071477428

Epoch: 6| Step: 7
Training loss: 3.1977875690724145
Validation loss: 2.5715426613638885

Epoch: 6| Step: 8
Training loss: 2.191977468966501
Validation loss: 2.5511103908627533

Epoch: 6| Step: 9
Training loss: 2.749981099844054
Validation loss: 2.585164907089877

Epoch: 6| Step: 10
Training loss: 2.6629679380600404
Validation loss: 2.5997166555728337

Epoch: 6| Step: 11
Training loss: 2.287891804644512
Validation loss: 2.5651842100552513

Epoch: 6| Step: 12
Training loss: 2.5029470239962412
Validation loss: 2.5773019550208947

Epoch: 6| Step: 13
Training loss: 3.176420215548029
Validation loss: 2.5830954286016996

Epoch: 94| Step: 0
Training loss: 3.6146064926123764
Validation loss: 2.5958886351819612

Epoch: 6| Step: 1
Training loss: 3.0776865690498068
Validation loss: 2.59034789355027

Epoch: 6| Step: 2
Training loss: 2.3877952632773676
Validation loss: 2.595585317665232

Epoch: 6| Step: 3
Training loss: 2.4645898268015674
Validation loss: 2.5895587085780023

Epoch: 6| Step: 4
Training loss: 2.5868041093268963
Validation loss: 2.565187895833385

Epoch: 6| Step: 5
Training loss: 3.0808734532176443
Validation loss: 2.553692766052495

Epoch: 6| Step: 6
Training loss: 2.4942377440468912
Validation loss: 2.598601879530108

Epoch: 6| Step: 7
Training loss: 3.0071725932535425
Validation loss: 2.5602769390342774

Epoch: 6| Step: 8
Training loss: 2.526729739097254
Validation loss: 2.6193904078094112

Epoch: 6| Step: 9
Training loss: 3.0433150401685034
Validation loss: 2.578124860786541

Epoch: 6| Step: 10
Training loss: 2.750227311883294
Validation loss: 2.5617694418610126

Epoch: 6| Step: 11
Training loss: 1.8232790632150633
Validation loss: 2.601726085985481

Epoch: 6| Step: 12
Training loss: 3.351410264334657
Validation loss: 2.6199520188163374

Epoch: 6| Step: 13
Training loss: 2.0218158837097038
Validation loss: 2.5713311884742485

Epoch: 95| Step: 0
Training loss: 2.3068541606415516
Validation loss: 2.5883310164234348

Epoch: 6| Step: 1
Training loss: 3.447211401839842
Validation loss: 2.5826633516089057

Epoch: 6| Step: 2
Training loss: 2.3370953500318254
Validation loss: 2.5683026028684433

Epoch: 6| Step: 3
Training loss: 2.0235140870671207
Validation loss: 2.5798326014847146

Epoch: 6| Step: 4
Training loss: 3.2101442419901205
Validation loss: 2.606303398093062

Epoch: 6| Step: 5
Training loss: 3.3163445672543324
Validation loss: 2.564129967050077

Epoch: 6| Step: 6
Training loss: 2.0663021760919587
Validation loss: 2.569531386845559

Epoch: 6| Step: 7
Training loss: 2.4529203098694063
Validation loss: 2.5857525340399614

Epoch: 6| Step: 8
Training loss: 2.715320572728588
Validation loss: 2.5641531365229344

Epoch: 6| Step: 9
Training loss: 3.3851455501666377
Validation loss: 2.577396491007436

Epoch: 6| Step: 10
Training loss: 3.4779125549747896
Validation loss: 2.5626122364802897

Epoch: 6| Step: 11
Training loss: 1.856052732421462
Validation loss: 2.5735464957195764

Epoch: 6| Step: 12
Training loss: 2.866943182657349
Validation loss: 2.5861102804466194

Epoch: 6| Step: 13
Training loss: 3.0897437464063313
Validation loss: 2.581916999048434

Epoch: 96| Step: 0
Training loss: 2.9884580472618554
Validation loss: 2.5768454838598047

Epoch: 6| Step: 1
Training loss: 2.093124296154634
Validation loss: 2.5726732810898

Epoch: 6| Step: 2
Training loss: 3.3218195109429485
Validation loss: 2.600013623387289

Epoch: 6| Step: 3
Training loss: 3.540122709141078
Validation loss: 2.587460333601507

Epoch: 6| Step: 4
Training loss: 2.4383365467160742
Validation loss: 2.581418930429715

Epoch: 6| Step: 5
Training loss: 3.4821712897959936
Validation loss: 2.573032351805833

Epoch: 6| Step: 6
Training loss: 2.168684887526987
Validation loss: 2.5718010598679992

Epoch: 6| Step: 7
Training loss: 2.601984579769245
Validation loss: 2.582158565523912

Epoch: 6| Step: 8
Training loss: 2.631987581148387
Validation loss: 2.5767958052639104

Epoch: 6| Step: 9
Training loss: 1.9230625856305232
Validation loss: 2.579103376559044

Epoch: 6| Step: 10
Training loss: 3.238607981434256
Validation loss: 2.5828372443927496

Epoch: 6| Step: 11
Training loss: 2.9313397033890563
Validation loss: 2.570958037715841

Epoch: 6| Step: 12
Training loss: 2.0021870099658465
Validation loss: 2.5723231687567303

Epoch: 6| Step: 13
Training loss: 3.1302399001642938
Validation loss: 2.604646822727668

Epoch: 97| Step: 0
Training loss: 2.167533212163098
Validation loss: 2.6003984456386036

Epoch: 6| Step: 1
Training loss: 3.981699205864125
Validation loss: 2.601301725168305

Epoch: 6| Step: 2
Training loss: 2.629066496410391
Validation loss: 2.5930875981789407

Epoch: 6| Step: 3
Training loss: 2.8839315914659576
Validation loss: 2.575416427369595

Epoch: 6| Step: 4
Training loss: 2.500957115064959
Validation loss: 2.595419731630691

Epoch: 6| Step: 5
Training loss: 3.408459987634399
Validation loss: 2.5803333359414604

Epoch: 6| Step: 6
Training loss: 2.723277651833509
Validation loss: 2.582711781790016

Epoch: 6| Step: 7
Training loss: 2.3757911167611003
Validation loss: 2.564041869351902

Epoch: 6| Step: 8
Training loss: 2.72353765814532
Validation loss: 2.5697029838059553

Epoch: 6| Step: 9
Training loss: 3.141246980786343
Validation loss: 2.5866693345261114

Epoch: 6| Step: 10
Training loss: 1.9876475945137246
Validation loss: 2.5525025884535566

Epoch: 6| Step: 11
Training loss: 2.7933731746639454
Validation loss: 2.5733887862550766

Epoch: 6| Step: 12
Training loss: 2.831940832338955
Validation loss: 2.564301864476341

Epoch: 6| Step: 13
Training loss: 2.3986822245745154
Validation loss: 2.570852561606606

Epoch: 98| Step: 0
Training loss: 1.7542880519933022
Validation loss: 2.563644338747661

Epoch: 6| Step: 1
Training loss: 2.858679014458013
Validation loss: 2.6046661465643783

Epoch: 6| Step: 2
Training loss: 2.4117094256607285
Validation loss: 2.5416942391866026

Epoch: 6| Step: 3
Training loss: 3.207856196474259
Validation loss: 2.546017105016274

Epoch: 6| Step: 4
Training loss: 2.5268165474810442
Validation loss: 2.577955982364558

Epoch: 6| Step: 5
Training loss: 2.4539741941492657
Validation loss: 2.5694796102952253

Epoch: 6| Step: 6
Training loss: 2.9270016985785037
Validation loss: 2.566806233301398

Epoch: 6| Step: 7
Training loss: 3.3684452124249975
Validation loss: 2.575375290994818

Epoch: 6| Step: 8
Training loss: 2.7781050828320595
Validation loss: 2.558382031460014

Epoch: 6| Step: 9
Training loss: 2.8461355746073322
Validation loss: 2.561532719148503

Epoch: 6| Step: 10
Training loss: 2.798268828641632
Validation loss: 2.5795491838852675

Epoch: 6| Step: 11
Training loss: 3.0497143158240396
Validation loss: 2.5640334856503215

Epoch: 6| Step: 12
Training loss: 2.8260174902221507
Validation loss: 2.592041558980571

Epoch: 6| Step: 13
Training loss: 2.9355389156474763
Validation loss: 2.5728119223569523

Epoch: 99| Step: 0
Training loss: 2.3401551206639124
Validation loss: 2.5907891912580117

Epoch: 6| Step: 1
Training loss: 3.2483542750469536
Validation loss: 2.5668594340567954

Epoch: 6| Step: 2
Training loss: 3.3518171591589865
Validation loss: 2.57378822329235

Epoch: 6| Step: 3
Training loss: 2.208300200399721
Validation loss: 2.5707676889618543

Epoch: 6| Step: 4
Training loss: 2.1324326173393326
Validation loss: 2.5809648958555838

Epoch: 6| Step: 5
Training loss: 3.113577757994511
Validation loss: 2.581088066548702

Epoch: 6| Step: 6
Training loss: 3.8976558291522374
Validation loss: 2.581025900877387

Epoch: 6| Step: 7
Training loss: 2.2410199784184552
Validation loss: 2.5743296191335294

Epoch: 6| Step: 8
Training loss: 2.382582956733161
Validation loss: 2.583706148763324

Epoch: 6| Step: 9
Training loss: 1.952978265972471
Validation loss: 2.575251345340022

Epoch: 6| Step: 10
Training loss: 2.76493464760006
Validation loss: 2.6164026049802893

Epoch: 6| Step: 11
Training loss: 3.2127876242038322
Validation loss: 2.6034570602499953

Epoch: 6| Step: 12
Training loss: 2.952804305813817
Validation loss: 2.581251632148433

Epoch: 6| Step: 13
Training loss: 2.4679725485129738
Validation loss: 2.577459758250532

Epoch: 100| Step: 0
Training loss: 3.488462231972203
Validation loss: 2.594258957886168

Epoch: 6| Step: 1
Training loss: 2.5340244488217873
Validation loss: 2.58176376985025

Epoch: 6| Step: 2
Training loss: 2.2568148088312125
Validation loss: 2.5836418115210544

Epoch: 6| Step: 3
Training loss: 2.916286407387332
Validation loss: 2.5971395862792925

Epoch: 6| Step: 4
Training loss: 3.078597444014082
Validation loss: 2.6014880994673586

Epoch: 6| Step: 5
Training loss: 2.6402702318949136
Validation loss: 2.5836533167331357

Epoch: 6| Step: 6
Training loss: 3.0082246572320535
Validation loss: 2.5787014075439125

Epoch: 6| Step: 7
Training loss: 1.8368566931000165
Validation loss: 2.5831883889645852

Epoch: 6| Step: 8
Training loss: 2.777535519102409
Validation loss: 2.5954190303240487

Epoch: 6| Step: 9
Training loss: 2.78076270474357
Validation loss: 2.5800700298912433

Epoch: 6| Step: 10
Training loss: 3.259044533176261
Validation loss: 2.566493246673273

Epoch: 6| Step: 11
Training loss: 2.8873323400133577
Validation loss: 2.5542816284251173

Epoch: 6| Step: 12
Training loss: 2.770584401203893
Validation loss: 2.575015911806196

Epoch: 6| Step: 13
Training loss: 2.3271281521225613
Validation loss: 2.5649003692434027

Epoch: 101| Step: 0
Training loss: 2.937697708294266
Validation loss: 2.5598482917801904

Epoch: 6| Step: 1
Training loss: 3.6053741872502405
Validation loss: 2.5893236076378305

Epoch: 6| Step: 2
Training loss: 2.9549869540938327
Validation loss: 2.588023163862299

Epoch: 6| Step: 3
Training loss: 2.5532089761209575
Validation loss: 2.6020896934466298

Epoch: 6| Step: 4
Training loss: 3.5506332584843063
Validation loss: 2.6038087854070477

Epoch: 6| Step: 5
Training loss: 2.7140659013813604
Validation loss: 2.5715261372436804

Epoch: 6| Step: 6
Training loss: 2.0332455735992725
Validation loss: 2.5873248087291505

Epoch: 6| Step: 7
Training loss: 1.9943411163062594
Validation loss: 2.557072881834027

Epoch: 6| Step: 8
Training loss: 2.4106081843364535
Validation loss: 2.588334413702049

Epoch: 6| Step: 9
Training loss: 2.616384445650877
Validation loss: 2.5769841458868585

Epoch: 6| Step: 10
Training loss: 2.9527511763747585
Validation loss: 2.5983909464194155

Epoch: 6| Step: 11
Training loss: 2.673109249115857
Validation loss: 2.5757983486092186

Epoch: 6| Step: 12
Training loss: 2.8838136996809927
Validation loss: 2.574011697978446

Epoch: 6| Step: 13
Training loss: 3.007790780917932
Validation loss: 2.539100141601216

Epoch: 102| Step: 0
Training loss: 2.40749158657739
Validation loss: 2.5826639452042435

Epoch: 6| Step: 1
Training loss: 3.276303877694959
Validation loss: 2.5483082736330327

Epoch: 6| Step: 2
Training loss: 2.4639535012626106
Validation loss: 2.5864432880927666

Epoch: 6| Step: 3
Training loss: 2.5330565799157436
Validation loss: 2.570451887455394

Epoch: 6| Step: 4
Training loss: 3.18853922339845
Validation loss: 2.5767611220043847

Epoch: 6| Step: 5
Training loss: 2.7814318136730494
Validation loss: 2.577159038123483

Epoch: 6| Step: 6
Training loss: 1.9558865364920792
Validation loss: 2.587164924829604

Epoch: 6| Step: 7
Training loss: 2.600912110189739
Validation loss: 2.590922321472998

Epoch: 6| Step: 8
Training loss: 3.2832060297057346
Validation loss: 2.567646131606798

Epoch: 6| Step: 9
Training loss: 2.464251705590535
Validation loss: 2.5876840298999713

Epoch: 6| Step: 10
Training loss: 3.4716317518227178
Validation loss: 2.556401989299509

Epoch: 6| Step: 11
Training loss: 2.686409307542573
Validation loss: 2.562726000592325

Epoch: 6| Step: 12
Training loss: 3.0404109365890126
Validation loss: 2.556640042409172

Epoch: 6| Step: 13
Training loss: 2.3647127718234824
Validation loss: 2.603613069984079

Epoch: 103| Step: 0
Training loss: 3.0933473883780893
Validation loss: 2.5622697747287515

Epoch: 6| Step: 1
Training loss: 3.113835647979346
Validation loss: 2.581980351620974

Epoch: 6| Step: 2
Training loss: 2.6086481418291454
Validation loss: 2.565391401931934

Epoch: 6| Step: 3
Training loss: 2.79570852494741
Validation loss: 2.5772114875146532

Epoch: 6| Step: 4
Training loss: 2.8344238277044234
Validation loss: 2.5685025654390468

Epoch: 6| Step: 5
Training loss: 2.309994654958907
Validation loss: 2.5633812366268556

Epoch: 6| Step: 6
Training loss: 2.7291941362313796
Validation loss: 2.5586867534032374

Epoch: 6| Step: 7
Training loss: 2.5559928895317117
Validation loss: 2.569291735317089

Epoch: 6| Step: 8
Training loss: 2.7711233881141633
Validation loss: 2.5517642382762937

Epoch: 6| Step: 9
Training loss: 3.29338865668693
Validation loss: 2.561832868371222

Epoch: 6| Step: 10
Training loss: 2.3413689280384324
Validation loss: 2.5926047469227105

Epoch: 6| Step: 11
Training loss: 2.7494112598328755
Validation loss: 2.565002102234833

Epoch: 6| Step: 12
Training loss: 2.890772470372559
Validation loss: 2.5511020108904683

Epoch: 6| Step: 13
Training loss: 3.050458786024951
Validation loss: 2.5893069296662343

Epoch: 104| Step: 0
Training loss: 3.0154545394868606
Validation loss: 2.5866625990210315

Epoch: 6| Step: 1
Training loss: 3.1767957880357742
Validation loss: 2.5641504610563945

Epoch: 6| Step: 2
Training loss: 1.6576463103699786
Validation loss: 2.5631649296146475

Epoch: 6| Step: 3
Training loss: 2.0933222547266315
Validation loss: 2.5828038373280684

Epoch: 6| Step: 4
Training loss: 3.155616923378733
Validation loss: 2.588099467015155

Epoch: 6| Step: 5
Training loss: 3.1282851689783184
Validation loss: 2.5562331239329934

Epoch: 6| Step: 6
Training loss: 2.562730825309108
Validation loss: 2.5672177611143487

Epoch: 6| Step: 7
Training loss: 3.007497161584848
Validation loss: 2.5883636162477877

Epoch: 6| Step: 8
Training loss: 3.137643186181938
Validation loss: 2.5777699633443225

Epoch: 6| Step: 9
Training loss: 2.7942239995031564
Validation loss: 2.5980392308200058

Epoch: 6| Step: 10
Training loss: 2.4673305245340282
Validation loss: 2.5568785736750996

Epoch: 6| Step: 11
Training loss: 2.7474127649927516
Validation loss: 2.565811176891066

Epoch: 6| Step: 12
Training loss: 2.0565264345005536
Validation loss: 2.5602675827410173

Epoch: 6| Step: 13
Training loss: 3.612520110922408
Validation loss: 2.578373728637068

Epoch: 105| Step: 0
Training loss: 2.6676273602271037
Validation loss: 2.570787256488442

Epoch: 6| Step: 1
Training loss: 3.1089817737770247
Validation loss: 2.6016830933240493

Epoch: 6| Step: 2
Training loss: 3.3879326181658236
Validation loss: 2.603105658853134

Epoch: 6| Step: 3
Training loss: 2.4994685561843926
Validation loss: 2.561262238480965

Epoch: 6| Step: 4
Training loss: 3.349214883156518
Validation loss: 2.5877337104836062

Epoch: 6| Step: 5
Training loss: 2.7661562479424413
Validation loss: 2.59489551822674

Epoch: 6| Step: 6
Training loss: 1.9726196285663202
Validation loss: 2.583166897745

Epoch: 6| Step: 7
Training loss: 3.0711485522806905
Validation loss: 2.5839224739675766

Epoch: 6| Step: 8
Training loss: 3.320324850620412
Validation loss: 2.5970206037562766

Epoch: 6| Step: 9
Training loss: 2.7305256806252
Validation loss: 2.598085539044058

Epoch: 6| Step: 10
Training loss: 2.8141090029147136
Validation loss: 2.6006623531155135

Epoch: 6| Step: 11
Training loss: 2.0128230054865766
Validation loss: 2.5829411551999932

Epoch: 6| Step: 12
Training loss: 2.364134680130791
Validation loss: 2.600520681096718

Epoch: 6| Step: 13
Training loss: 2.1428644202880807
Validation loss: 2.5919539569701033

Epoch: 106| Step: 0
Training loss: 2.9077282499297374
Validation loss: 2.5793160937186017

Epoch: 6| Step: 1
Training loss: 2.765225742637545
Validation loss: 2.564620572462688

Epoch: 6| Step: 2
Training loss: 2.6089968835673902
Validation loss: 2.575213374030601

Epoch: 6| Step: 3
Training loss: 3.430591368563374
Validation loss: 2.5967662386070804

Epoch: 6| Step: 4
Training loss: 2.9665805318379412
Validation loss: 2.572313282221366

Epoch: 6| Step: 5
Training loss: 2.8979774788665247
Validation loss: 2.5664932326888334

Epoch: 6| Step: 6
Training loss: 2.7223486049232
Validation loss: 2.5754148048220693

Epoch: 6| Step: 7
Training loss: 2.7800994379111823
Validation loss: 2.5966421746740393

Epoch: 6| Step: 8
Training loss: 2.559090183232699
Validation loss: 2.552533970605034

Epoch: 6| Step: 9
Training loss: 2.5997896769625264
Validation loss: 2.58114006215367

Epoch: 6| Step: 10
Training loss: 2.4385976031858294
Validation loss: 2.571794897476342

Epoch: 6| Step: 11
Training loss: 3.043656904296905
Validation loss: 2.5814219435327246

Epoch: 6| Step: 12
Training loss: 2.466922034971847
Validation loss: 2.598693623741315

Epoch: 6| Step: 13
Training loss: 2.4067733988073714
Validation loss: 2.566827592837542

Epoch: 107| Step: 0
Training loss: 2.977706729300697
Validation loss: 2.594383835395489

Epoch: 6| Step: 1
Training loss: 3.0097345725604483
Validation loss: 2.573708728721009

Epoch: 6| Step: 2
Training loss: 3.1182165144449208
Validation loss: 2.5485532621294973

Epoch: 6| Step: 3
Training loss: 3.2387295954424813
Validation loss: 2.5625208982130214

Epoch: 6| Step: 4
Training loss: 3.265303016376478
Validation loss: 2.5951267724375744

Epoch: 6| Step: 5
Training loss: 2.7475797233087706
Validation loss: 2.5853036504492466

Epoch: 6| Step: 6
Training loss: 2.8294325698445904
Validation loss: 2.599054123238564

Epoch: 6| Step: 7
Training loss: 2.9937039110940487
Validation loss: 2.5866089046440903

Epoch: 6| Step: 8
Training loss: 1.95769582341377
Validation loss: 2.583640852999133

Epoch: 6| Step: 9
Training loss: 2.623624168602693
Validation loss: 2.569429348279807

Epoch: 6| Step: 10
Training loss: 2.196195160252222
Validation loss: 2.5695142910713464

Epoch: 6| Step: 11
Training loss: 2.2434110592682672
Validation loss: 2.5680049448778077

Epoch: 6| Step: 12
Training loss: 2.6792094969304627
Validation loss: 2.5887923151600676

Epoch: 6| Step: 13
Training loss: 2.40324888468115
Validation loss: 2.584472035791739

Epoch: 108| Step: 0
Training loss: 2.6158300722735217
Validation loss: 2.582514358834943

Epoch: 6| Step: 1
Training loss: 2.5710607674360078
Validation loss: 2.5798982927368224

Epoch: 6| Step: 2
Training loss: 2.3236823993800177
Validation loss: 2.5829965972021087

Epoch: 6| Step: 3
Training loss: 2.633172166294607
Validation loss: 2.5714700232306393

Epoch: 6| Step: 4
Training loss: 3.1906241272150804
Validation loss: 2.5601641245306155

Epoch: 6| Step: 5
Training loss: 2.7753426898679763
Validation loss: 2.6007620317119446

Epoch: 6| Step: 6
Training loss: 2.9878439988517824
Validation loss: 2.5653123676878833

Epoch: 6| Step: 7
Training loss: 2.3781790287331814
Validation loss: 2.547488929450516

Epoch: 6| Step: 8
Training loss: 2.9851825680005626
Validation loss: 2.593843662247662

Epoch: 6| Step: 9
Training loss: 3.073704212370482
Validation loss: 2.560512269004469

Epoch: 6| Step: 10
Training loss: 2.8307744045672774
Validation loss: 2.582869908594252

Epoch: 6| Step: 11
Training loss: 2.712413463003199
Validation loss: 2.570797107009374

Epoch: 6| Step: 12
Training loss: 2.5206506415968124
Validation loss: 2.5966880171378275

Epoch: 6| Step: 13
Training loss: 3.393054285273447
Validation loss: 2.573536617868382

Epoch: 109| Step: 0
Training loss: 2.4372296305630963
Validation loss: 2.5621785758396305

Epoch: 6| Step: 1
Training loss: 3.2673382075326
Validation loss: 2.5947306775982666

Epoch: 6| Step: 2
Training loss: 2.7036982463199033
Validation loss: 2.599444347085462

Epoch: 6| Step: 3
Training loss: 3.024856589204504
Validation loss: 2.565514365008836

Epoch: 6| Step: 4
Training loss: 2.9941454026992216
Validation loss: 2.5848568609314326

Epoch: 6| Step: 5
Training loss: 2.5146116502163527
Validation loss: 2.5578358459279213

Epoch: 6| Step: 6
Training loss: 2.636451176382836
Validation loss: 2.5784291187151416

Epoch: 6| Step: 7
Training loss: 2.6490773016140463
Validation loss: 2.572891329552176

Epoch: 6| Step: 8
Training loss: 2.9445620119467186
Validation loss: 2.5580092035961344

Epoch: 6| Step: 9
Training loss: 2.3543238854587534
Validation loss: 2.5528351798629814

Epoch: 6| Step: 10
Training loss: 2.9998912791578927
Validation loss: 2.566033375134599

Epoch: 6| Step: 11
Training loss: 2.714639296483009
Validation loss: 2.588745212844526

Epoch: 6| Step: 12
Training loss: 2.5765034517886556
Validation loss: 2.5951513366272776

Epoch: 6| Step: 13
Training loss: 3.0580014255737415
Validation loss: 2.5734044207577718

Epoch: 110| Step: 0
Training loss: 1.89375128667303
Validation loss: 2.5952728748726064

Epoch: 6| Step: 1
Training loss: 2.841461266694824
Validation loss: 2.5820536531898717

Epoch: 6| Step: 2
Training loss: 2.7442293308894423
Validation loss: 2.568483407700009

Epoch: 6| Step: 3
Training loss: 2.577899899915032
Validation loss: 2.5985880836323627

Epoch: 6| Step: 4
Training loss: 2.6761720246702083
Validation loss: 2.5774086064702595

Epoch: 6| Step: 5
Training loss: 2.5174705417277075
Validation loss: 2.5928794614681836

Epoch: 6| Step: 6
Training loss: 2.99394361789697
Validation loss: 2.584638681262708

Epoch: 6| Step: 7
Training loss: 2.775925758523361
Validation loss: 2.5482744425764556

Epoch: 6| Step: 8
Training loss: 3.516434504241424
Validation loss: 2.57602918052846

Epoch: 6| Step: 9
Training loss: 2.865303272752927
Validation loss: 2.5750872920869425

Epoch: 6| Step: 10
Training loss: 2.4376042661618897
Validation loss: 2.551523271642459

Epoch: 6| Step: 11
Training loss: 3.1433417113898052
Validation loss: 2.571175949468744

Epoch: 6| Step: 12
Training loss: 2.4047857015386436
Validation loss: 2.596113919435867

Epoch: 6| Step: 13
Training loss: 3.3084734069484165
Validation loss: 2.5780315920457784

Epoch: 111| Step: 0
Training loss: 2.4684303173284734
Validation loss: 2.5729622526507523

Epoch: 6| Step: 1
Training loss: 2.2619104913529036
Validation loss: 2.595212054600099

Epoch: 6| Step: 2
Training loss: 2.439420676950932
Validation loss: 2.56981937393128

Epoch: 6| Step: 3
Training loss: 2.8558444546996036
Validation loss: 2.580923965125569

Epoch: 6| Step: 4
Training loss: 2.711833706778986
Validation loss: 2.5687963953537216

Epoch: 6| Step: 5
Training loss: 2.6279405744618414
Validation loss: 2.583646405673981

Epoch: 6| Step: 6
Training loss: 3.4449742296027344
Validation loss: 2.575600371842442

Epoch: 6| Step: 7
Training loss: 2.947720057173243
Validation loss: 2.556014473830229

Epoch: 6| Step: 8
Training loss: 2.8808894993128384
Validation loss: 2.576506276613815

Epoch: 6| Step: 9
Training loss: 2.596824386599222
Validation loss: 2.5655175067106843

Epoch: 6| Step: 10
Training loss: 2.8969410120285244
Validation loss: 2.5680588745014576

Epoch: 6| Step: 11
Training loss: 3.124288096401157
Validation loss: 2.559592132050307

Epoch: 6| Step: 12
Training loss: 2.8774219760209623
Validation loss: 2.577565820336409

Epoch: 6| Step: 13
Training loss: 2.2597030591422462
Validation loss: 2.586494847720122

Epoch: 112| Step: 0
Training loss: 2.6976327832679186
Validation loss: 2.59471003287986

Epoch: 6| Step: 1
Training loss: 3.0384875540654988
Validation loss: 2.6003086209824757

Epoch: 6| Step: 2
Training loss: 2.6753704563204415
Validation loss: 2.575194864519072

Epoch: 6| Step: 3
Training loss: 2.587305911243766
Validation loss: 2.5803832007703384

Epoch: 6| Step: 4
Training loss: 2.8203228979368142
Validation loss: 2.5857757695240995

Epoch: 6| Step: 5
Training loss: 3.0359638175667882
Validation loss: 2.5783891628908515

Epoch: 6| Step: 6
Training loss: 2.7557798681003174
Validation loss: 2.5830602086348153

Epoch: 6| Step: 7
Training loss: 2.634169865378691
Validation loss: 2.5786177367244467

Epoch: 6| Step: 8
Training loss: 2.495430585136925
Validation loss: 2.591133766107054

Epoch: 6| Step: 9
Training loss: 2.825218941635545
Validation loss: 2.6065018036542815

Epoch: 6| Step: 10
Training loss: 3.277967573227779
Validation loss: 2.570199737982774

Epoch: 6| Step: 11
Training loss: 2.597796489400545
Validation loss: 2.5860983926128354

Epoch: 6| Step: 12
Training loss: 2.6058546978601593
Validation loss: 2.5882180489226116

Epoch: 6| Step: 13
Training loss: 2.624940417385549
Validation loss: 2.593118700734352

Epoch: 113| Step: 0
Training loss: 2.4725260768089967
Validation loss: 2.5930558417488276

Epoch: 6| Step: 1
Training loss: 2.414886531494069
Validation loss: 2.5748156555532455

Epoch: 6| Step: 2
Training loss: 2.373857725409904
Validation loss: 2.598498551566556

Epoch: 6| Step: 3
Training loss: 2.8668631804184965
Validation loss: 2.5869523625159423

Epoch: 6| Step: 4
Training loss: 2.597183436910485
Validation loss: 2.5709883001591005

Epoch: 6| Step: 5
Training loss: 2.845284519550265
Validation loss: 2.6215581405965014

Epoch: 6| Step: 6
Training loss: 2.5121656052980232
Validation loss: 2.5613055417895367

Epoch: 6| Step: 7
Training loss: 3.588200937307121
Validation loss: 2.569210402311383

Epoch: 6| Step: 8
Training loss: 2.215575620372693
Validation loss: 2.5765977051490006

Epoch: 6| Step: 9
Training loss: 2.780183566228365
Validation loss: 2.590064282440132

Epoch: 6| Step: 10
Training loss: 2.8627336298456445
Validation loss: 2.5671961631596525

Epoch: 6| Step: 11
Training loss: 3.533706755668698
Validation loss: 2.5588927031001645

Epoch: 6| Step: 12
Training loss: 2.5246749064342344
Validation loss: 2.5868120535356227

Epoch: 6| Step: 13
Training loss: 2.9173712469748825
Validation loss: 2.5676806903783786

Epoch: 114| Step: 0
Training loss: 2.477221091514174
Validation loss: 2.5699259977354685

Epoch: 6| Step: 1
Training loss: 3.203142863898357
Validation loss: 2.584501574597792

Epoch: 6| Step: 2
Training loss: 2.124007498144216
Validation loss: 2.5714070338271617

Epoch: 6| Step: 3
Training loss: 3.1390003158311544
Validation loss: 2.570224101532597

Epoch: 6| Step: 4
Training loss: 3.0814900086188457
Validation loss: 2.5792621688765394

Epoch: 6| Step: 5
Training loss: 2.8593106288647387
Validation loss: 2.5848300566189395

Epoch: 6| Step: 6
Training loss: 2.400227527959406
Validation loss: 2.5787273867904554

Epoch: 6| Step: 7
Training loss: 2.9714449245401124
Validation loss: 2.585821912696786

Epoch: 6| Step: 8
Training loss: 2.1589763930400783
Validation loss: 2.589119401277611

Epoch: 6| Step: 9
Training loss: 2.6251106238897233
Validation loss: 2.5754043707220844

Epoch: 6| Step: 10
Training loss: 3.134762582747745
Validation loss: 2.573745660414486

Epoch: 6| Step: 11
Training loss: 2.929574379326517
Validation loss: 2.5598773185546055

Epoch: 6| Step: 12
Training loss: 3.165637869775789
Validation loss: 2.553941428896223

Epoch: 6| Step: 13
Training loss: 1.4195412567743313
Validation loss: 2.588760602098309

Epoch: 115| Step: 0
Training loss: 2.4415944263417133
Validation loss: 2.56838268798319

Epoch: 6| Step: 1
Training loss: 3.591393801302658
Validation loss: 2.589026137484228

Epoch: 6| Step: 2
Training loss: 3.306516028736443
Validation loss: 2.584430823836879

Epoch: 6| Step: 3
Training loss: 2.787006892222795
Validation loss: 2.584600922257826

Epoch: 6| Step: 4
Training loss: 1.9580607799490939
Validation loss: 2.5933819492509365

Epoch: 6| Step: 5
Training loss: 2.7754848606505567
Validation loss: 2.591330938992747

Epoch: 6| Step: 6
Training loss: 2.39786803601951
Validation loss: 2.5599763555237556

Epoch: 6| Step: 7
Training loss: 2.1023723644292467
Validation loss: 2.554638623339572

Epoch: 6| Step: 8
Training loss: 3.3672022277085105
Validation loss: 2.5637619888781233

Epoch: 6| Step: 9
Training loss: 2.813953278501416
Validation loss: 2.5718429382213297

Epoch: 6| Step: 10
Training loss: 2.2732594213841106
Validation loss: 2.5788740186839916

Epoch: 6| Step: 11
Training loss: 3.1413160484283145
Validation loss: 2.570289220479163

Epoch: 6| Step: 12
Training loss: 2.1387739880017547
Validation loss: 2.6074891846188604

Epoch: 6| Step: 13
Training loss: 3.3808172037104853
Validation loss: 2.562307743250572

Epoch: 116| Step: 0
Training loss: 2.8346884422733836
Validation loss: 2.556552432674246

Epoch: 6| Step: 1
Training loss: 2.7719941157709287
Validation loss: 2.5883896035027867

Epoch: 6| Step: 2
Training loss: 2.2788570865615245
Validation loss: 2.5768365687643446

Epoch: 6| Step: 3
Training loss: 2.4381389269593603
Validation loss: 2.5642602258778617

Epoch: 6| Step: 4
Training loss: 2.341839024002987
Validation loss: 2.5803081875673795

Epoch: 6| Step: 5
Training loss: 2.904159286102885
Validation loss: 2.5681469551879927

Epoch: 6| Step: 6
Training loss: 3.012983677447318
Validation loss: 2.5624756525515218

Epoch: 6| Step: 7
Training loss: 2.580979587531855
Validation loss: 2.567512150441248

Epoch: 6| Step: 8
Training loss: 2.3061488803932018
Validation loss: 2.5688148182371062

Epoch: 6| Step: 9
Training loss: 2.9302492950935908
Validation loss: 2.572486286620074

Epoch: 6| Step: 10
Training loss: 3.23596756652686
Validation loss: 2.588029608559333

Epoch: 6| Step: 11
Training loss: 2.83792523798145
Validation loss: 2.593058308444778

Epoch: 6| Step: 12
Training loss: 3.4704291601036683
Validation loss: 2.569950326971236

Epoch: 6| Step: 13
Training loss: 2.019114940241575
Validation loss: 2.5984071181594506

Epoch: 117| Step: 0
Training loss: 2.4217381592515523
Validation loss: 2.5725492351480352

Epoch: 6| Step: 1
Training loss: 2.8139083726900243
Validation loss: 2.5876905829332304

Epoch: 6| Step: 2
Training loss: 2.898175908954314
Validation loss: 2.5860357040050617

Epoch: 6| Step: 3
Training loss: 2.3928317188628503
Validation loss: 2.57378743043059

Epoch: 6| Step: 4
Training loss: 2.6345046404053614
Validation loss: 2.5869894945971543

Epoch: 6| Step: 5
Training loss: 3.142181162777983
Validation loss: 2.5804954234130286

Epoch: 6| Step: 6
Training loss: 2.8257068391156572
Validation loss: 2.552279399064859

Epoch: 6| Step: 7
Training loss: 3.22111957325971
Validation loss: 2.599567717135378

Epoch: 6| Step: 8
Training loss: 3.35964467940081
Validation loss: 2.5547299228043623

Epoch: 6| Step: 9
Training loss: 3.240330911385935
Validation loss: 2.5585963170523165

Epoch: 6| Step: 10
Training loss: 2.483496552635643
Validation loss: 2.586257129149996

Epoch: 6| Step: 11
Training loss: 2.3334519038273718
Validation loss: 2.574663914508251

Epoch: 6| Step: 12
Training loss: 2.308521973192829
Validation loss: 2.5664762055785815

Epoch: 6| Step: 13
Training loss: 1.7642438769964688
Validation loss: 2.566092221535712

Epoch: 118| Step: 0
Training loss: 3.2116175764364274
Validation loss: 2.5769503018186795

Epoch: 6| Step: 1
Training loss: 2.8135773184893855
Validation loss: 2.5485647919581775

Epoch: 6| Step: 2
Training loss: 2.223922074057338
Validation loss: 2.5835327768758605

Epoch: 6| Step: 3
Training loss: 2.4083781553891135
Validation loss: 2.593567871586499

Epoch: 6| Step: 4
Training loss: 2.551167620946059
Validation loss: 2.576655563072466

Epoch: 6| Step: 5
Training loss: 3.078365878057222
Validation loss: 2.5666592935323855

Epoch: 6| Step: 6
Training loss: 2.3700595466762557
Validation loss: 2.5703544006114107

Epoch: 6| Step: 7
Training loss: 3.568502622672089
Validation loss: 2.572256722934227

Epoch: 6| Step: 8
Training loss: 2.6957770348103964
Validation loss: 2.572704863618437

Epoch: 6| Step: 9
Training loss: 2.4245176602485654
Validation loss: 2.581133057954806

Epoch: 6| Step: 10
Training loss: 2.604395701191313
Validation loss: 2.5754510172515523

Epoch: 6| Step: 11
Training loss: 2.68757629286241
Validation loss: 2.569400234852754

Epoch: 6| Step: 12
Training loss: 2.8436856105347688
Validation loss: 2.5688686879461673

Epoch: 6| Step: 13
Training loss: 2.9340039815947203
Validation loss: 2.553510464172294

Epoch: 119| Step: 0
Training loss: 2.6976969468675818
Validation loss: 2.6107449427171483

Epoch: 6| Step: 1
Training loss: 2.851587248394318
Validation loss: 2.5696228241097305

Epoch: 6| Step: 2
Training loss: 3.25239694676911
Validation loss: 2.5625638196007605

Epoch: 6| Step: 3
Training loss: 2.9584517298543873
Validation loss: 2.566066667845116

Epoch: 6| Step: 4
Training loss: 2.9342547407278543
Validation loss: 2.597751242829614

Epoch: 6| Step: 5
Training loss: 2.902952230546006
Validation loss: 2.6008827350911465

Epoch: 6| Step: 6
Training loss: 2.7570754841352687
Validation loss: 2.6044970559172653

Epoch: 6| Step: 7
Training loss: 2.159863747078696
Validation loss: 2.5913551652069606

Epoch: 6| Step: 8
Training loss: 2.8609961411504448
Validation loss: 2.582356891783653

Epoch: 6| Step: 9
Training loss: 2.451181601698829
Validation loss: 2.5825472981217192

Epoch: 6| Step: 10
Training loss: 2.2138148479559607
Validation loss: 2.5982255115615187

Epoch: 6| Step: 11
Training loss: 2.7172037748229987
Validation loss: 2.591733071949336

Epoch: 6| Step: 12
Training loss: 2.7249938474813176
Validation loss: 2.6007313596583588

Epoch: 6| Step: 13
Training loss: 3.2578152809771552
Validation loss: 2.599583645859377

Epoch: 120| Step: 0
Training loss: 2.913245201552749
Validation loss: 2.589505035642538

Epoch: 6| Step: 1
Training loss: 2.7243163029822854
Validation loss: 2.594103826967222

Epoch: 6| Step: 2
Training loss: 2.2467949610263305
Validation loss: 2.574063062670935

Epoch: 6| Step: 3
Training loss: 2.344405832720968
Validation loss: 2.58146317919222

Epoch: 6| Step: 4
Training loss: 3.0186962241364603
Validation loss: 2.5943163517714734

Epoch: 6| Step: 5
Training loss: 3.244170756604876
Validation loss: 2.6019774129521127

Epoch: 6| Step: 6
Training loss: 3.2138968610944008
Validation loss: 2.586185734005374

Epoch: 6| Step: 7
Training loss: 2.8817988735544384
Validation loss: 2.5765353395963793

Epoch: 6| Step: 8
Training loss: 3.171280979099909
Validation loss: 2.6041131789754406

Epoch: 6| Step: 9
Training loss: 2.3230003946265394
Validation loss: 2.598873929062862

Epoch: 6| Step: 10
Training loss: 2.593625352920787
Validation loss: 2.5900798885393317

Epoch: 6| Step: 11
Training loss: 2.640841683972117
Validation loss: 2.558681727185838

Epoch: 6| Step: 12
Training loss: 1.9585795416847274
Validation loss: 2.587956391062104

Epoch: 6| Step: 13
Training loss: 3.2127831716453903
Validation loss: 2.5977295296431997

Epoch: 121| Step: 0
Training loss: 2.142535616958113
Validation loss: 2.5608018610322936

Epoch: 6| Step: 1
Training loss: 3.0958563829867156
Validation loss: 2.577675248608394

Epoch: 6| Step: 2
Training loss: 2.9029809757966727
Validation loss: 2.565939784777562

Epoch: 6| Step: 3
Training loss: 3.1447032052168877
Validation loss: 2.588072082138771

Epoch: 6| Step: 4
Training loss: 3.0681778570592724
Validation loss: 2.5706452394534822

Epoch: 6| Step: 5
Training loss: 2.8378496265534734
Validation loss: 2.561452487924091

Epoch: 6| Step: 6
Training loss: 3.0535052809406475
Validation loss: 2.5951421702780433

Epoch: 6| Step: 7
Training loss: 2.273829685217855
Validation loss: 2.562915849295445

Epoch: 6| Step: 8
Training loss: 2.330539347557276
Validation loss: 2.5902576797835977

Epoch: 6| Step: 9
Training loss: 2.3441870726904024
Validation loss: 2.566006192361164

Epoch: 6| Step: 10
Training loss: 2.8998707314981154
Validation loss: 2.5711184318850613

Epoch: 6| Step: 11
Training loss: 3.1964746427754966
Validation loss: 2.5731015971950644

Epoch: 6| Step: 12
Training loss: 2.9497887875221185
Validation loss: 2.5578258633050734

Epoch: 6| Step: 13
Training loss: 1.4848597487934798
Validation loss: 2.576988926002347

Epoch: 122| Step: 0
Training loss: 3.0409256193528513
Validation loss: 2.5767796511071115

Epoch: 6| Step: 1
Training loss: 2.562492649719117
Validation loss: 2.569116675229546

Epoch: 6| Step: 2
Training loss: 3.448855423071261
Validation loss: 2.5802178155298066

Epoch: 6| Step: 3
Training loss: 2.610859979452347
Validation loss: 2.592681602453907

Epoch: 6| Step: 4
Training loss: 3.0462461164885677
Validation loss: 2.583632227278101

Epoch: 6| Step: 5
Training loss: 1.804313521835924
Validation loss: 2.5869325981612175

Epoch: 6| Step: 6
Training loss: 3.341214939194643
Validation loss: 2.5620236578081816

Epoch: 6| Step: 7
Training loss: 2.8042034273350143
Validation loss: 2.573687377484039

Epoch: 6| Step: 8
Training loss: 3.089948842881308
Validation loss: 2.599263823909624

Epoch: 6| Step: 9
Training loss: 2.3705364244740683
Validation loss: 2.55453992637348

Epoch: 6| Step: 10
Training loss: 3.187151422327275
Validation loss: 2.5570198985494126

Epoch: 6| Step: 11
Training loss: 2.1379812579997295
Validation loss: 2.5827661239579363

Epoch: 6| Step: 12
Training loss: 2.1384568197739795
Validation loss: 2.563606041516929

Epoch: 6| Step: 13
Training loss: 2.4252713906925885
Validation loss: 2.5971004306250456

Epoch: 123| Step: 0
Training loss: 3.2581295161066857
Validation loss: 2.574362574515735

Epoch: 6| Step: 1
Training loss: 3.054717939376392
Validation loss: 2.5882446834412987

Epoch: 6| Step: 2
Training loss: 2.4505168875575687
Validation loss: 2.5623520078825686

Epoch: 6| Step: 3
Training loss: 2.805001328955895
Validation loss: 2.5898942077717324

Epoch: 6| Step: 4
Training loss: 2.4300128682113704
Validation loss: 2.5703555635655557

Epoch: 6| Step: 5
Training loss: 2.3997192933909486
Validation loss: 2.5929349005748223

Epoch: 6| Step: 6
Training loss: 2.8738707937080648
Validation loss: 2.587999419581805

Epoch: 6| Step: 7
Training loss: 3.4156570028217548
Validation loss: 2.5520412385510567

Epoch: 6| Step: 8
Training loss: 3.115047628611098
Validation loss: 2.601131669722786

Epoch: 6| Step: 9
Training loss: 2.6068388897944903
Validation loss: 2.5768860864019394

Epoch: 6| Step: 10
Training loss: 2.824893686100161
Validation loss: 2.5862774151065833

Epoch: 6| Step: 11
Training loss: 2.092427305647426
Validation loss: 2.5759826599127402

Epoch: 6| Step: 12
Training loss: 2.4181000854123655
Validation loss: 2.5601989655411854

Epoch: 6| Step: 13
Training loss: 1.9733865424770847
Validation loss: 2.569360249374239

Epoch: 124| Step: 0
Training loss: 2.822741785767418
Validation loss: 2.5643452664144695

Epoch: 6| Step: 1
Training loss: 2.6293272953770135
Validation loss: 2.5711623194951194

Epoch: 6| Step: 2
Training loss: 3.3480573344910125
Validation loss: 2.5452702852884492

Epoch: 6| Step: 3
Training loss: 3.2257764842579535
Validation loss: 2.602973830841555

Epoch: 6| Step: 4
Training loss: 2.170258943076812
Validation loss: 2.5890217578482106

Epoch: 6| Step: 5
Training loss: 2.845083573761413
Validation loss: 2.5812262007241293

Epoch: 6| Step: 6
Training loss: 2.6228272664956505
Validation loss: 2.5774748409041908

Epoch: 6| Step: 7
Training loss: 2.5238538463553017
Validation loss: 2.594128427526029

Epoch: 6| Step: 8
Training loss: 2.7024547650047674
Validation loss: 2.5723960449041137

Epoch: 6| Step: 9
Training loss: 2.5948761483039267
Validation loss: 2.577939622664779

Epoch: 6| Step: 10
Training loss: 2.7863224364799812
Validation loss: 2.5713999482826098

Epoch: 6| Step: 11
Training loss: 3.481863716311258
Validation loss: 2.5818051152340944

Epoch: 6| Step: 12
Training loss: 1.6023246626365732
Validation loss: 2.589195719650784

Epoch: 6| Step: 13
Training loss: 2.648020123477316
Validation loss: 2.559447438466777

Epoch: 125| Step: 0
Training loss: 2.755045943110772
Validation loss: 2.5757181397340254

Epoch: 6| Step: 1
Training loss: 2.8179904328800456
Validation loss: 2.5678667823609254

Epoch: 6| Step: 2
Training loss: 2.992391156071114
Validation loss: 2.5587533021357296

Epoch: 6| Step: 3
Training loss: 2.8940872490206386
Validation loss: 2.585705923639997

Epoch: 6| Step: 4
Training loss: 2.5146285269236026
Validation loss: 2.5773377162046076

Epoch: 6| Step: 5
Training loss: 2.2697598314321303
Validation loss: 2.5659672040405193

Epoch: 6| Step: 6
Training loss: 3.0714814191054707
Validation loss: 2.5707473584012495

Epoch: 6| Step: 7
Training loss: 3.0512276101922025
Validation loss: 2.5773583588315767

Epoch: 6| Step: 8
Training loss: 2.796310453072652
Validation loss: 2.548963643432795

Epoch: 6| Step: 9
Training loss: 2.357553347229746
Validation loss: 2.5714992059402135

Epoch: 6| Step: 10
Training loss: 1.989059925302426
Validation loss: 2.570970291709966

Epoch: 6| Step: 11
Training loss: 2.2551653169988732
Validation loss: 2.564401124952895

Epoch: 6| Step: 12
Training loss: 3.2216674027406733
Validation loss: 2.5775128873115767

Epoch: 6| Step: 13
Training loss: 3.451604586094705
Validation loss: 2.571301348815271

Epoch: 126| Step: 0
Training loss: 2.583970627059752
Validation loss: 2.571360069672128

Epoch: 6| Step: 1
Training loss: 2.747683936948444
Validation loss: 2.589600670999953

Epoch: 6| Step: 2
Training loss: 2.480480091940113
Validation loss: 2.5619717825638055

Epoch: 6| Step: 3
Training loss: 3.5329901534590324
Validation loss: 2.587199345747846

Epoch: 6| Step: 4
Training loss: 3.907236325672006
Validation loss: 2.578520856877783

Epoch: 6| Step: 5
Training loss: 2.357503186382515
Validation loss: 2.596762004809804

Epoch: 6| Step: 6
Training loss: 1.9970325270531466
Validation loss: 2.5700258020990936

Epoch: 6| Step: 7
Training loss: 2.2493107057770048
Validation loss: 2.5726438984472373

Epoch: 6| Step: 8
Training loss: 2.460539286048088
Validation loss: 2.5642964098774197

Epoch: 6| Step: 9
Training loss: 3.2853217156976826
Validation loss: 2.598072143984189

Epoch: 6| Step: 10
Training loss: 2.9101182359094375
Validation loss: 2.5757486677325594

Epoch: 6| Step: 11
Training loss: 2.409431632993014
Validation loss: 2.5940256161367183

Epoch: 6| Step: 12
Training loss: 2.4097606266221563
Validation loss: 2.5679685206272325

Epoch: 6| Step: 13
Training loss: 2.5247428989765703
Validation loss: 2.596553417698974

Epoch: 127| Step: 0
Training loss: 2.7329213665433603
Validation loss: 2.5660220856466336

Epoch: 6| Step: 1
Training loss: 3.408909031033294
Validation loss: 2.577094061430404

Epoch: 6| Step: 2
Training loss: 3.012271894627556
Validation loss: 2.5544575089738264

Epoch: 6| Step: 3
Training loss: 2.342792060908419
Validation loss: 2.5702173917546225

Epoch: 6| Step: 4
Training loss: 2.8800435815268735
Validation loss: 2.5672532243860844

Epoch: 6| Step: 5
Training loss: 2.2556335071922278
Validation loss: 2.5636498242338686

Epoch: 6| Step: 6
Training loss: 2.5908234413263243
Validation loss: 2.609205007956786

Epoch: 6| Step: 7
Training loss: 3.1861659231425663
Validation loss: 2.608763526528329

Epoch: 6| Step: 8
Training loss: 2.8341970436227752
Validation loss: 2.5851842089591353

Epoch: 6| Step: 9
Training loss: 2.5449291823451308
Validation loss: 2.5950745651063

Epoch: 6| Step: 10
Training loss: 1.7256872798260106
Validation loss: 2.612243506139019

Epoch: 6| Step: 11
Training loss: 2.8088929676158414
Validation loss: 2.604086334630224

Epoch: 6| Step: 12
Training loss: 3.0393596592146714
Validation loss: 2.5765485416581178

Epoch: 6| Step: 13
Training loss: 2.692570007037487
Validation loss: 2.598183010570204

Epoch: 128| Step: 0
Training loss: 3.1147961155770325
Validation loss: 2.612737909305975

Epoch: 6| Step: 1
Training loss: 2.352886752242482
Validation loss: 2.5870102217368807

Epoch: 6| Step: 2
Training loss: 1.7006090812120316
Validation loss: 2.5920899622944864

Epoch: 6| Step: 3
Training loss: 3.005862864987415
Validation loss: 2.565207006228264

Epoch: 6| Step: 4
Training loss: 2.6117707179151437
Validation loss: 2.586319054098844

Epoch: 6| Step: 5
Training loss: 3.2132794455076383
Validation loss: 2.5858681958254794

Epoch: 6| Step: 6
Training loss: 2.921063805238164
Validation loss: 2.569792296049822

Epoch: 6| Step: 7
Training loss: 2.3497653316448535
Validation loss: 2.5788402361999645

Epoch: 6| Step: 8
Training loss: 2.9460713752133643
Validation loss: 2.5717280711621715

Epoch: 6| Step: 9
Training loss: 2.322034100797164
Validation loss: 2.6097945156765276

Epoch: 6| Step: 10
Training loss: 2.8195157180404835
Validation loss: 2.5906149643733403

Epoch: 6| Step: 11
Training loss: 3.2304554654163065
Validation loss: 2.559506108758992

Epoch: 6| Step: 12
Training loss: 2.5959527646956064
Validation loss: 2.568163398731104

Epoch: 6| Step: 13
Training loss: 2.9969322095706814
Validation loss: 2.572657440851827

Epoch: 129| Step: 0
Training loss: 3.1922801956109743
Validation loss: 2.6018698767963953

Epoch: 6| Step: 1
Training loss: 2.6906616775547096
Validation loss: 2.567119709054257

Epoch: 6| Step: 2
Training loss: 2.9907197464909316
Validation loss: 2.549519886612286

Epoch: 6| Step: 3
Training loss: 2.432836129938027
Validation loss: 2.5783505736031276

Epoch: 6| Step: 4
Training loss: 2.760460983976259
Validation loss: 2.563886062002557

Epoch: 6| Step: 5
Training loss: 2.241765318145096
Validation loss: 2.5639269097666304

Epoch: 6| Step: 6
Training loss: 2.9239468496269487
Validation loss: 2.593640121146908

Epoch: 6| Step: 7
Training loss: 3.001822871482895
Validation loss: 2.5949704594775858

Epoch: 6| Step: 8
Training loss: 3.066183405268454
Validation loss: 2.594657816175287

Epoch: 6| Step: 9
Training loss: 2.6665161110180082
Validation loss: 2.56425610986933

Epoch: 6| Step: 10
Training loss: 2.437618546170779
Validation loss: 2.560160109082187

Epoch: 6| Step: 11
Training loss: 2.051971845615869
Validation loss: 2.5970602117333232

Epoch: 6| Step: 12
Training loss: 2.698426766697268
Validation loss: 2.550886749019082

Epoch: 6| Step: 13
Training loss: 3.037555232546642
Validation loss: 2.588891136724698

Epoch: 130| Step: 0
Training loss: 2.491424730817902
Validation loss: 2.5717290600423914

Epoch: 6| Step: 1
Training loss: 2.4826452603439937
Validation loss: 2.591081331888655

Epoch: 6| Step: 2
Training loss: 2.3153506055927786
Validation loss: 2.5871769127984634

Epoch: 6| Step: 3
Training loss: 2.431197503707272
Validation loss: 2.5517373696631642

Epoch: 6| Step: 4
Training loss: 3.322266342638444
Validation loss: 2.56755465390176

Epoch: 6| Step: 5
Training loss: 2.486419124690998
Validation loss: 2.5768916302527716

Epoch: 6| Step: 6
Training loss: 2.5764879057422876
Validation loss: 2.609270151316188

Epoch: 6| Step: 7
Training loss: 2.3907998214328465
Validation loss: 2.5682865120789646

Epoch: 6| Step: 8
Training loss: 2.192029133498671
Validation loss: 2.6019324814654907

Epoch: 6| Step: 9
Training loss: 3.394646997091639
Validation loss: 2.5792147543582407

Epoch: 6| Step: 10
Training loss: 3.5209766938105305
Validation loss: 2.604760924103362

Epoch: 6| Step: 11
Training loss: 2.9060471986953207
Validation loss: 2.6014379040199036

Epoch: 6| Step: 12
Training loss: 2.43485928812328
Validation loss: 2.5680387570933427

Epoch: 6| Step: 13
Training loss: 3.1402628675606716
Validation loss: 2.5667046297486307

Epoch: 131| Step: 0
Training loss: 3.040587839211192
Validation loss: 2.582418145360637

Epoch: 6| Step: 1
Training loss: 2.535433009107252
Validation loss: 2.5675472262311385

Epoch: 6| Step: 2
Training loss: 2.6111110006381972
Validation loss: 2.5796687292649105

Epoch: 6| Step: 3
Training loss: 2.632162404380601
Validation loss: 2.5865591538902453

Epoch: 6| Step: 4
Training loss: 3.3383680150678896
Validation loss: 2.577534169064421

Epoch: 6| Step: 5
Training loss: 3.1682056568901245
Validation loss: 2.5768128079592056

Epoch: 6| Step: 6
Training loss: 2.0281800766624154
Validation loss: 2.573430998397406

Epoch: 6| Step: 7
Training loss: 2.333086806852528
Validation loss: 2.5717089354575537

Epoch: 6| Step: 8
Training loss: 3.1691595772132217
Validation loss: 2.584837802584022

Epoch: 6| Step: 9
Training loss: 2.698155415893501
Validation loss: 2.607608560040455

Epoch: 6| Step: 10
Training loss: 3.1254679520238913
Validation loss: 2.555593567189956

Epoch: 6| Step: 11
Training loss: 2.129732136248117
Validation loss: 2.594350328985673

Epoch: 6| Step: 12
Training loss: 2.369020765626585
Validation loss: 2.585628414589693

Epoch: 6| Step: 13
Training loss: 2.6056272352707266
Validation loss: 2.568050119574956

Epoch: 132| Step: 0
Training loss: 3.1703502579457434
Validation loss: 2.5874020905964015

Epoch: 6| Step: 1
Training loss: 3.3310934806539834
Validation loss: 2.5851530506092155

Epoch: 6| Step: 2
Training loss: 2.961406741037823
Validation loss: 2.5702608419194855

Epoch: 6| Step: 3
Training loss: 2.467313710826379
Validation loss: 2.5767866959914176

Epoch: 6| Step: 4
Training loss: 2.195393516701794
Validation loss: 2.59123183155279

Epoch: 6| Step: 5
Training loss: 2.143481054757539
Validation loss: 2.584351683911214

Epoch: 6| Step: 6
Training loss: 2.515965030032936
Validation loss: 2.5901988796031854

Epoch: 6| Step: 7
Training loss: 3.036538613219459
Validation loss: 2.6069202269443563

Epoch: 6| Step: 8
Training loss: 2.4905687773328493
Validation loss: 2.590341730745163

Epoch: 6| Step: 9
Training loss: 2.35356131228347
Validation loss: 2.57477515975633

Epoch: 6| Step: 10
Training loss: 2.811125186169569
Validation loss: 2.5808088913373823

Epoch: 6| Step: 11
Training loss: 2.8474772414050693
Validation loss: 2.575323929578993

Epoch: 6| Step: 12
Training loss: 3.274983844280434
Validation loss: 2.5969883470528248

Epoch: 6| Step: 13
Training loss: 2.0330129162499584
Validation loss: 2.575351961674904

Epoch: 133| Step: 0
Training loss: 2.739086517037193
Validation loss: 2.564792725877813

Epoch: 6| Step: 1
Training loss: 2.7897874760780845
Validation loss: 2.5677614268739934

Epoch: 6| Step: 2
Training loss: 2.530002804780996
Validation loss: 2.570038109416164

Epoch: 6| Step: 3
Training loss: 3.135829015508013
Validation loss: 2.593464232347596

Epoch: 6| Step: 4
Training loss: 2.2593178136402647
Validation loss: 2.5605354331666454

Epoch: 6| Step: 5
Training loss: 2.3524321408675055
Validation loss: 2.5416400567781126

Epoch: 6| Step: 6
Training loss: 1.926606966543497
Validation loss: 2.561415217841993

Epoch: 6| Step: 7
Training loss: 2.912559141942024
Validation loss: 2.5566856776201288

Epoch: 6| Step: 8
Training loss: 2.5671326234957577
Validation loss: 2.571551149187434

Epoch: 6| Step: 9
Training loss: 2.5884962071521214
Validation loss: 2.570717848037709

Epoch: 6| Step: 10
Training loss: 2.372675109125123
Validation loss: 2.569253485347146

Epoch: 6| Step: 11
Training loss: 2.7127466678530365
Validation loss: 2.587491176345061

Epoch: 6| Step: 12
Training loss: 3.3837968129871556
Validation loss: 2.5484857398625693

Epoch: 6| Step: 13
Training loss: 4.268235745598512
Validation loss: 2.5774177239886313

Epoch: 134| Step: 0
Training loss: 2.53232674008843
Validation loss: 2.5585866460049482

Epoch: 6| Step: 1
Training loss: 2.8679500885774303
Validation loss: 2.574974402652784

Epoch: 6| Step: 2
Training loss: 2.952652504880179
Validation loss: 2.5909823336346847

Epoch: 6| Step: 3
Training loss: 2.6327192250377367
Validation loss: 2.581412251736314

Epoch: 6| Step: 4
Training loss: 2.6364695339399535
Validation loss: 2.597241092888467

Epoch: 6| Step: 5
Training loss: 2.1693774895858438
Validation loss: 2.5834856530918873

Epoch: 6| Step: 6
Training loss: 3.149050518019529
Validation loss: 2.5611667230879833

Epoch: 6| Step: 7
Training loss: 1.6984407595100464
Validation loss: 2.5818168550258176

Epoch: 6| Step: 8
Training loss: 2.8538737088699633
Validation loss: 2.587600005554854

Epoch: 6| Step: 9
Training loss: 3.6949036837814697
Validation loss: 2.571140151440023

Epoch: 6| Step: 10
Training loss: 2.803605319817082
Validation loss: 2.5834518674026388

Epoch: 6| Step: 11
Training loss: 2.7910635472235117
Validation loss: 2.5933408111720477

Epoch: 6| Step: 12
Training loss: 2.7488383527280593
Validation loss: 2.587935604138751

Epoch: 6| Step: 13
Training loss: 2.4137761708544185
Validation loss: 2.579002100411313

Epoch: 135| Step: 0
Training loss: 3.1616531806407484
Validation loss: 2.5983529797784977

Epoch: 6| Step: 1
Training loss: 2.4072905433307725
Validation loss: 2.5759674550676794

Epoch: 6| Step: 2
Training loss: 2.7667476293674844
Validation loss: 2.5777633497859607

Epoch: 6| Step: 3
Training loss: 2.503692951133323
Validation loss: 2.5748385377068326

Epoch: 6| Step: 4
Training loss: 3.366207962765222
Validation loss: 2.570116366932876

Epoch: 6| Step: 5
Training loss: 2.19811517864568
Validation loss: 2.596198334768627

Epoch: 6| Step: 6
Training loss: 2.2252470715105677
Validation loss: 2.5694630200277118

Epoch: 6| Step: 7
Training loss: 2.9519266593527127
Validation loss: 2.5725943918317666

Epoch: 6| Step: 8
Training loss: 2.3641077535247583
Validation loss: 2.6120158107974847

Epoch: 6| Step: 9
Training loss: 2.5300728215227823
Validation loss: 2.5821048653536054

Epoch: 6| Step: 10
Training loss: 2.6656995648848074
Validation loss: 2.565955788375107

Epoch: 6| Step: 11
Training loss: 2.774172317515934
Validation loss: 2.561604343039683

Epoch: 6| Step: 12
Training loss: 3.294120614266862
Validation loss: 2.576094165172827

Epoch: 6| Step: 13
Training loss: 2.69212351682574
Validation loss: 2.575799591713665

Epoch: 136| Step: 0
Training loss: 2.5936972371445344
Validation loss: 2.591392861410702

Epoch: 6| Step: 1
Training loss: 2.6108965977239214
Validation loss: 2.5765167351064937

Epoch: 6| Step: 2
Training loss: 2.807187297251572
Validation loss: 2.58731873582642

Epoch: 6| Step: 3
Training loss: 2.593782907300192
Validation loss: 2.5770289413393432

Epoch: 6| Step: 4
Training loss: 2.767586739687545
Validation loss: 2.553799184787602

Epoch: 6| Step: 5
Training loss: 3.594865708688014
Validation loss: 2.5902229006427313

Epoch: 6| Step: 6
Training loss: 2.9576313815758426
Validation loss: 2.6049321568454973

Epoch: 6| Step: 7
Training loss: 2.6705080517660154
Validation loss: 2.5812522360001866

Epoch: 6| Step: 8
Training loss: 3.006726036528808
Validation loss: 2.586617465431655

Epoch: 6| Step: 9
Training loss: 2.243440922353121
Validation loss: 2.5803743078327064

Epoch: 6| Step: 10
Training loss: 3.001966626565685
Validation loss: 2.5836135568048104

Epoch: 6| Step: 11
Training loss: 2.4521680775672063
Validation loss: 2.594532479544298

Epoch: 6| Step: 12
Training loss: 2.190564216499687
Validation loss: 2.6155712913573637

Epoch: 6| Step: 13
Training loss: 2.617037094121529
Validation loss: 2.591555110874334

Epoch: 137| Step: 0
Training loss: 2.4653606084480826
Validation loss: 2.5880000287932265

Epoch: 6| Step: 1
Training loss: 3.1014161351642304
Validation loss: 2.5914000288112895

Epoch: 6| Step: 2
Training loss: 2.6056693255816907
Validation loss: 2.5980406941843563

Epoch: 6| Step: 3
Training loss: 2.7844637187690844
Validation loss: 2.541819883704755

Epoch: 6| Step: 4
Training loss: 3.0278660083790476
Validation loss: 2.5728091547564005

Epoch: 6| Step: 5
Training loss: 2.5168122516821323
Validation loss: 2.5757200776038425

Epoch: 6| Step: 6
Training loss: 2.319779254507276
Validation loss: 2.592819053718752

Epoch: 6| Step: 7
Training loss: 2.580537534207573
Validation loss: 2.578973677564892

Epoch: 6| Step: 8
Training loss: 2.1732569627078737
Validation loss: 2.5818464212308463

Epoch: 6| Step: 9
Training loss: 3.00502705592005
Validation loss: 2.572124328477419

Epoch: 6| Step: 10
Training loss: 2.5166741309992093
Validation loss: 2.590919562333652

Epoch: 6| Step: 11
Training loss: 3.063336627890635
Validation loss: 2.5731816490187773

Epoch: 6| Step: 12
Training loss: 2.9874194529380986
Validation loss: 2.576558215432504

Epoch: 6| Step: 13
Training loss: 3.1424603769115347
Validation loss: 2.57288354662444

Epoch: 138| Step: 0
Training loss: 2.564701344315682
Validation loss: 2.5858994189214064

Epoch: 6| Step: 1
Training loss: 3.5934852834315003
Validation loss: 2.5639825129545915

Epoch: 6| Step: 2
Training loss: 2.5818015038199498
Validation loss: 2.579979886997838

Epoch: 6| Step: 3
Training loss: 3.046444436975762
Validation loss: 2.5937326032616292

Epoch: 6| Step: 4
Training loss: 2.393653696378922
Validation loss: 2.5804169402036057

Epoch: 6| Step: 5
Training loss: 2.708379236468094
Validation loss: 2.5770295979103954

Epoch: 6| Step: 6
Training loss: 2.607489904309165
Validation loss: 2.581633786446149

Epoch: 6| Step: 7
Training loss: 2.9700160489146428
Validation loss: 2.568093590436138

Epoch: 6| Step: 8
Training loss: 1.9779263943591747
Validation loss: 2.582789494500515

Epoch: 6| Step: 9
Training loss: 2.9839670591504883
Validation loss: 2.562696461883569

Epoch: 6| Step: 10
Training loss: 2.231826288935672
Validation loss: 2.596642347943549

Epoch: 6| Step: 11
Training loss: 3.2126228754315522
Validation loss: 2.583106475247814

Epoch: 6| Step: 12
Training loss: 2.119193727733277
Validation loss: 2.564733880647277

Epoch: 6| Step: 13
Training loss: 2.8021950019981894
Validation loss: 2.5761225973984696

Epoch: 139| Step: 0
Training loss: 2.572027498083412
Validation loss: 2.604986664335964

Epoch: 6| Step: 1
Training loss: 2.797114015734182
Validation loss: 2.5938687806965537

Epoch: 6| Step: 2
Training loss: 2.021791473502918
Validation loss: 2.590386861299502

Epoch: 6| Step: 3
Training loss: 2.752914098483709
Validation loss: 2.567152825898046

Epoch: 6| Step: 4
Training loss: 2.792012425736592
Validation loss: 2.5706673738803043

Epoch: 6| Step: 5
Training loss: 2.9087072669456986
Validation loss: 2.572354637983666

Epoch: 6| Step: 6
Training loss: 2.7456928682264587
Validation loss: 2.566655818621699

Epoch: 6| Step: 7
Training loss: 2.8039778552793044
Validation loss: 2.581893341594828

Epoch: 6| Step: 8
Training loss: 2.2935068776019447
Validation loss: 2.5890902686469968

Epoch: 6| Step: 9
Training loss: 3.188719273160832
Validation loss: 2.621032393315209

Epoch: 6| Step: 10
Training loss: 2.956674209063291
Validation loss: 2.591499166421082

Epoch: 6| Step: 11
Training loss: 2.9757152563074802
Validation loss: 2.600481597054374

Epoch: 6| Step: 12
Training loss: 2.78748077933352
Validation loss: 2.5704730331867918

Epoch: 6| Step: 13
Training loss: 2.293666648909466
Validation loss: 2.5769861315508935

Epoch: 140| Step: 0
Training loss: 3.2400595426386456
Validation loss: 2.560491528611428

Epoch: 6| Step: 1
Training loss: 2.1042667276996303
Validation loss: 2.562367888816016

Epoch: 6| Step: 2
Training loss: 2.514750073795562
Validation loss: 2.558887371219832

Epoch: 6| Step: 3
Training loss: 3.4499381018351825
Validation loss: 2.5931679568884425

Epoch: 6| Step: 4
Training loss: 2.2172351017493486
Validation loss: 2.595492443260317

Epoch: 6| Step: 5
Training loss: 2.4869832676292813
Validation loss: 2.591069423327849

Epoch: 6| Step: 6
Training loss: 3.001353435394244
Validation loss: 2.582764984458672

Epoch: 6| Step: 7
Training loss: 2.604849540187333
Validation loss: 2.5942737467161185

Epoch: 6| Step: 8
Training loss: 2.1700179029860065
Validation loss: 2.570076434490835

Epoch: 6| Step: 9
Training loss: 2.845617666119853
Validation loss: 2.601299116489696

Epoch: 6| Step: 10
Training loss: 2.854886894591133
Validation loss: 2.6047685054882384

Epoch: 6| Step: 11
Training loss: 2.361600419997356
Validation loss: 2.5704507564600485

Epoch: 6| Step: 12
Training loss: 3.371842496784231
Validation loss: 2.585088752352299

Epoch: 6| Step: 13
Training loss: 2.53342965553606
Validation loss: 2.590293223503894

Epoch: 141| Step: 0
Training loss: 2.462373344920833
Validation loss: 2.580277212763456

Epoch: 6| Step: 1
Training loss: 2.343414282596641
Validation loss: 2.5803314531999133

Epoch: 6| Step: 2
Training loss: 2.9610827568880356
Validation loss: 2.5987512491737124

Epoch: 6| Step: 3
Training loss: 2.801709477515277
Validation loss: 2.598994588939151

Epoch: 6| Step: 4
Training loss: 2.7067074712800068
Validation loss: 2.5964445490751693

Epoch: 6| Step: 5
Training loss: 3.2893721554798407
Validation loss: 2.5949202733032144

Epoch: 6| Step: 6
Training loss: 2.839315457115438
Validation loss: 2.57225645184531

Epoch: 6| Step: 7
Training loss: 2.754894928633406
Validation loss: 2.588268312061272

Epoch: 6| Step: 8
Training loss: 2.7805678999206864
Validation loss: 2.588605526920271

Epoch: 6| Step: 9
Training loss: 2.612822305610506
Validation loss: 2.5997519575538397

Epoch: 6| Step: 10
Training loss: 2.3987246661416353
Validation loss: 2.5819524317018443

Epoch: 6| Step: 11
Training loss: 2.5007618696897236
Validation loss: 2.5769319938031257

Epoch: 6| Step: 12
Training loss: 2.692778084083356
Validation loss: 2.5831651708971526

Epoch: 6| Step: 13
Training loss: 3.067769246988925
Validation loss: 2.600581085420014

Epoch: 142| Step: 0
Training loss: 2.5872581774359094
Validation loss: 2.5660053401473886

Epoch: 6| Step: 1
Training loss: 2.6159604056917085
Validation loss: 2.584049729546741

Epoch: 6| Step: 2
Training loss: 2.886380600384481
Validation loss: 2.580203311277119

Epoch: 6| Step: 3
Training loss: 3.1404346009799706
Validation loss: 2.5669140369182646

Epoch: 6| Step: 4
Training loss: 2.4330985604865054
Validation loss: 2.5732716021650943

Epoch: 6| Step: 5
Training loss: 2.1634826985163955
Validation loss: 2.562826017324479

Epoch: 6| Step: 6
Training loss: 2.8396308325873734
Validation loss: 2.5708386626688364

Epoch: 6| Step: 7
Training loss: 2.3757816835281993
Validation loss: 2.5582076518374763

Epoch: 6| Step: 8
Training loss: 2.8939470327047427
Validation loss: 2.5712481422558584

Epoch: 6| Step: 9
Training loss: 2.1709753135286185
Validation loss: 2.5735197638715746

Epoch: 6| Step: 10
Training loss: 3.08571173892345
Validation loss: 2.570099535393927

Epoch: 6| Step: 11
Training loss: 2.620477413476834
Validation loss: 2.5917033148555926

Epoch: 6| Step: 12
Training loss: 2.8992510782226493
Validation loss: 2.5799730455921095

Epoch: 6| Step: 13
Training loss: 3.3835957173297935
Validation loss: 2.5750356352144634

Epoch: 143| Step: 0
Training loss: 2.517476413468576
Validation loss: 2.5841540385229247

Epoch: 6| Step: 1
Training loss: 2.7991553871932213
Validation loss: 2.5524637152695813

Epoch: 6| Step: 2
Training loss: 2.843894535625529
Validation loss: 2.5872863943324362

Epoch: 6| Step: 3
Training loss: 2.34552463738605
Validation loss: 2.565341737867555

Epoch: 6| Step: 4
Training loss: 2.3103371893441866
Validation loss: 2.57846696312851

Epoch: 6| Step: 5
Training loss: 3.589096639136176
Validation loss: 2.5941822429674364

Epoch: 6| Step: 6
Training loss: 2.4675341159120165
Validation loss: 2.5700223766285

Epoch: 6| Step: 7
Training loss: 2.3644137104605587
Validation loss: 2.586366364149233

Epoch: 6| Step: 8
Training loss: 2.9397219107280455
Validation loss: 2.5483676661538155

Epoch: 6| Step: 9
Training loss: 3.2620662298536582
Validation loss: 2.575391703815216

Epoch: 6| Step: 10
Training loss: 2.2833686292198894
Validation loss: 2.580776279525593

Epoch: 6| Step: 11
Training loss: 2.560798172945743
Validation loss: 2.5691930948551476

Epoch: 6| Step: 12
Training loss: 2.7877931244006553
Validation loss: 2.5900494512633445

Epoch: 6| Step: 13
Training loss: 2.946643639844217
Validation loss: 2.5564260080057486

Epoch: 144| Step: 0
Training loss: 2.747032124579041
Validation loss: 2.5752142241926745

Epoch: 6| Step: 1
Training loss: 2.8970828939527418
Validation loss: 2.5919043523329854

Epoch: 6| Step: 2
Training loss: 2.7176543911168847
Validation loss: 2.5472816380719623

Epoch: 6| Step: 3
Training loss: 3.001172790169716
Validation loss: 2.576320557916821

Epoch: 6| Step: 4
Training loss: 3.1917344931889633
Validation loss: 2.5694082647997103

Epoch: 6| Step: 5
Training loss: 3.2128824622331718
Validation loss: 2.5641614488477296

Epoch: 6| Step: 6
Training loss: 2.6209252839163635
Validation loss: 2.5829952265504166

Epoch: 6| Step: 7
Training loss: 2.895659809722575
Validation loss: 2.595460735021443

Epoch: 6| Step: 8
Training loss: 2.825484587031098
Validation loss: 2.574902057467582

Epoch: 6| Step: 9
Training loss: 2.082815283897239
Validation loss: 2.593736824706905

Epoch: 6| Step: 10
Training loss: 2.5052124996243186
Validation loss: 2.567633843776163

Epoch: 6| Step: 11
Training loss: 1.9102084224885492
Validation loss: 2.5830702262319627

Epoch: 6| Step: 12
Training loss: 2.659802114970586
Validation loss: 2.581284962964842

Epoch: 6| Step: 13
Training loss: 2.75871914665278
Validation loss: 2.561804536236084

Epoch: 145| Step: 0
Training loss: 2.6379048258262063
Validation loss: 2.570725679406391

Epoch: 6| Step: 1
Training loss: 2.7748792742337938
Validation loss: 2.5725365033591308

Epoch: 6| Step: 2
Training loss: 2.9667234229612927
Validation loss: 2.6109110159108315

Epoch: 6| Step: 3
Training loss: 2.851890565995659
Validation loss: 2.5857575884397983

Epoch: 6| Step: 4
Training loss: 2.135507746048948
Validation loss: 2.590012454114884

Epoch: 6| Step: 5
Training loss: 2.5743591548156988
Validation loss: 2.584471656870713

Epoch: 6| Step: 6
Training loss: 2.5872912594543314
Validation loss: 2.5697170963944824

Epoch: 6| Step: 7
Training loss: 2.3484452075539894
Validation loss: 2.5841611699496916

Epoch: 6| Step: 8
Training loss: 3.2267826919607856
Validation loss: 2.5997019129907564

Epoch: 6| Step: 9
Training loss: 3.097620229042615
Validation loss: 2.5877514992432626

Epoch: 6| Step: 10
Training loss: 2.570219368682256
Validation loss: 2.585492592904351

Epoch: 6| Step: 11
Training loss: 2.7079570117564185
Validation loss: 2.576662810270111

Epoch: 6| Step: 12
Training loss: 2.439521342683579
Validation loss: 2.5984401559093757

Epoch: 6| Step: 13
Training loss: 3.5667015864246343
Validation loss: 2.5675545430709676

Epoch: 146| Step: 0
Training loss: 2.336040890041848
Validation loss: 2.592223942978094

Epoch: 6| Step: 1
Training loss: 2.7384813265551244
Validation loss: 2.587916767578825

Epoch: 6| Step: 2
Training loss: 1.8266403821228212
Validation loss: 2.592197416596708

Epoch: 6| Step: 3
Training loss: 2.0405209758702085
Validation loss: 2.583415326025666

Epoch: 6| Step: 4
Training loss: 2.923707112246068
Validation loss: 2.6111653330021185

Epoch: 6| Step: 5
Training loss: 2.1067689974996506
Validation loss: 2.582151444948036

Epoch: 6| Step: 6
Training loss: 3.0312297073156933
Validation loss: 2.5927970431405982

Epoch: 6| Step: 7
Training loss: 3.0398782846277848
Validation loss: 2.5951709692400473

Epoch: 6| Step: 8
Training loss: 2.5995142666380646
Validation loss: 2.5900876425591073

Epoch: 6| Step: 9
Training loss: 2.6954364250552993
Validation loss: 2.5803064766901054

Epoch: 6| Step: 10
Training loss: 3.142748366368444
Validation loss: 2.5857731550964087

Epoch: 6| Step: 11
Training loss: 2.870809237337977
Validation loss: 2.5902877523779724

Epoch: 6| Step: 12
Training loss: 3.2807894428919555
Validation loss: 2.592321845544183

Epoch: 6| Step: 13
Training loss: 3.5005274783885247
Validation loss: 2.5913830743401736

Epoch: 147| Step: 0
Training loss: 2.8030679005874894
Validation loss: 2.5682736433675806

Epoch: 6| Step: 1
Training loss: 2.556106220109776
Validation loss: 2.5911656202967666

Epoch: 6| Step: 2
Training loss: 2.6430250467996426
Validation loss: 2.5941638697881384

Epoch: 6| Step: 3
Training loss: 2.5091761984169523
Validation loss: 2.5612112897073813

Epoch: 6| Step: 4
Training loss: 2.2069169546594143
Validation loss: 2.5869022972808624

Epoch: 6| Step: 5
Training loss: 2.8227145883975746
Validation loss: 2.5707088987276454

Epoch: 6| Step: 6
Training loss: 2.862273201432503
Validation loss: 2.611571775169848

Epoch: 6| Step: 7
Training loss: 3.1896059147994493
Validation loss: 2.5856388292443473

Epoch: 6| Step: 8
Training loss: 1.9776985612761318
Validation loss: 2.593366865199691

Epoch: 6| Step: 9
Training loss: 3.568318484217681
Validation loss: 2.5595137540776247

Epoch: 6| Step: 10
Training loss: 2.580683230784551
Validation loss: 2.581764378547119

Epoch: 6| Step: 11
Training loss: 3.1674447525854577
Validation loss: 2.5643573415671086

Epoch: 6| Step: 12
Training loss: 2.2837782136357174
Validation loss: 2.5805101435921887

Epoch: 6| Step: 13
Training loss: 2.941710680523371
Validation loss: 2.5800189735832277

Epoch: 148| Step: 0
Training loss: 1.8118325681741223
Validation loss: 2.5609954170542606

Epoch: 6| Step: 1
Training loss: 2.7219699777353132
Validation loss: 2.5809258345219535

Epoch: 6| Step: 2
Training loss: 2.9315679186624615
Validation loss: 2.5870305642185665

Epoch: 6| Step: 3
Training loss: 3.3861300298843617
Validation loss: 2.570514148280632

Epoch: 6| Step: 4
Training loss: 2.67079372723791
Validation loss: 2.58162909487012

Epoch: 6| Step: 5
Training loss: 2.687825028038034
Validation loss: 2.5848697016319635

Epoch: 6| Step: 6
Training loss: 2.8690166407648023
Validation loss: 2.5677767362200665

Epoch: 6| Step: 7
Training loss: 2.7443631227914334
Validation loss: 2.5983995162406237

Epoch: 6| Step: 8
Training loss: 2.762758828030038
Validation loss: 2.5714606867274252

Epoch: 6| Step: 9
Training loss: 2.679566316672677
Validation loss: 2.593118540081615

Epoch: 6| Step: 10
Training loss: 2.386634637877016
Validation loss: 2.5834094101510514

Epoch: 6| Step: 11
Training loss: 3.0345609220988132
Validation loss: 2.5987561091093396

Epoch: 6| Step: 12
Training loss: 2.6221379617669913
Validation loss: 2.5979773987292663

Epoch: 6| Step: 13
Training loss: 2.119576320597848
Validation loss: 2.5544353921545473

Epoch: 149| Step: 0
Training loss: 2.590692947656214
Validation loss: 2.5837002697712204

Epoch: 6| Step: 1
Training loss: 2.338019116534813
Validation loss: 2.5871981021754182

Epoch: 6| Step: 2
Training loss: 3.3752199737069946
Validation loss: 2.5712334139193334

Epoch: 6| Step: 3
Training loss: 2.6862482216297936
Validation loss: 2.579183435429452

Epoch: 6| Step: 4
Training loss: 2.7098751570038484
Validation loss: 2.599175848861526

Epoch: 6| Step: 5
Training loss: 2.3825672461195078
Validation loss: 2.5804178522351657

Epoch: 6| Step: 6
Training loss: 2.833113512225858
Validation loss: 2.588519604201147

Epoch: 6| Step: 7
Training loss: 3.147830876297048
Validation loss: 2.588891658584602

Epoch: 6| Step: 8
Training loss: 2.993871468964669
Validation loss: 2.5626551403320703

Epoch: 6| Step: 9
Training loss: 2.777480753807046
Validation loss: 2.5977370812182983

Epoch: 6| Step: 10
Training loss: 2.140335397551905
Validation loss: 2.577472237949227

Epoch: 6| Step: 11
Training loss: 2.7360405781062433
Validation loss: 2.5815454310541344

Epoch: 6| Step: 12
Training loss: 2.4745876970673915
Validation loss: 2.5773812611816402

Epoch: 6| Step: 13
Training loss: 2.738353690197303
Validation loss: 2.577448170686286

Epoch: 150| Step: 0
Training loss: 2.865354861773096
Validation loss: 2.569529662806488

Epoch: 6| Step: 1
Training loss: 2.858856821270335
Validation loss: 2.5792794674096386

Epoch: 6| Step: 2
Training loss: 2.8336407737732103
Validation loss: 2.572844808995829

Epoch: 6| Step: 3
Training loss: 2.74959960103347
Validation loss: 2.6097185619655248

Epoch: 6| Step: 4
Training loss: 3.0797245110504354
Validation loss: 2.5716688293658905

Epoch: 6| Step: 5
Training loss: 2.4095406758583104
Validation loss: 2.594171575036285

Epoch: 6| Step: 6
Training loss: 2.4164943852895133
Validation loss: 2.5473014202287176

Epoch: 6| Step: 7
Training loss: 2.365607310220146
Validation loss: 2.572666752085561

Epoch: 6| Step: 8
Training loss: 3.1862920828517356
Validation loss: 2.5448085852970905

Epoch: 6| Step: 9
Training loss: 2.3363300108539247
Validation loss: 2.5581468933553513

Epoch: 6| Step: 10
Training loss: 2.5402234049792924
Validation loss: 2.567703496336908

Epoch: 6| Step: 11
Training loss: 2.1973618685519156
Validation loss: 2.5669311220460753

Epoch: 6| Step: 12
Training loss: 2.937537335097679
Validation loss: 2.586641670874209

Epoch: 6| Step: 13
Training loss: 3.0672788119606498
Validation loss: 2.572354626024317

Epoch: 151| Step: 0
Training loss: 2.6054159499370306
Validation loss: 2.5762560571302178

Epoch: 6| Step: 1
Training loss: 3.2506953742637537
Validation loss: 2.5724944708678725

Epoch: 6| Step: 2
Training loss: 2.2246103395588888
Validation loss: 2.566678796493683

Epoch: 6| Step: 3
Training loss: 2.8187303834219883
Validation loss: 2.587362936205248

Epoch: 6| Step: 4
Training loss: 2.7010355023363894
Validation loss: 2.5528189875631306

Epoch: 6| Step: 5
Training loss: 2.8326314355938633
Validation loss: 2.5681871641940264

Epoch: 6| Step: 6
Training loss: 1.8735945202308353
Validation loss: 2.6022231976958103

Epoch: 6| Step: 7
Training loss: 2.896964878963625
Validation loss: 2.586252227388754

Epoch: 6| Step: 8
Training loss: 2.9802770790474344
Validation loss: 2.5698744855121567

Epoch: 6| Step: 9
Training loss: 2.7075926623774316
Validation loss: 2.570482456056441

Epoch: 6| Step: 10
Training loss: 2.9066329211571404
Validation loss: 2.5703780904620226

Epoch: 6| Step: 11
Training loss: 2.4591138107253885
Validation loss: 2.5718440686044484

Epoch: 6| Step: 12
Training loss: 2.6169240334970993
Validation loss: 2.5801072530718514

Epoch: 6| Step: 13
Training loss: 2.8759369360067155
Validation loss: 2.5768444083990825

Epoch: 152| Step: 0
Training loss: 2.15917217886528
Validation loss: 2.5983897575345494

Epoch: 6| Step: 1
Training loss: 2.657072590632798
Validation loss: 2.579819305428189

Epoch: 6| Step: 2
Training loss: 2.665109646744145
Validation loss: 2.554250194477421

Epoch: 6| Step: 3
Training loss: 2.764233082650102
Validation loss: 2.5585476092502506

Epoch: 6| Step: 4
Training loss: 2.489061553629224
Validation loss: 2.5450297821271537

Epoch: 6| Step: 5
Training loss: 2.5724724966642016
Validation loss: 2.5672301148470456

Epoch: 6| Step: 6
Training loss: 2.546014371221576
Validation loss: 2.570663923335655

Epoch: 6| Step: 7
Training loss: 2.951681278680109
Validation loss: 2.557672445737452

Epoch: 6| Step: 8
Training loss: 1.9976555673227347
Validation loss: 2.569528127333217

Epoch: 6| Step: 9
Training loss: 3.1899640899837323
Validation loss: 2.587696434531715

Epoch: 6| Step: 10
Training loss: 3.1419981426619605
Validation loss: 2.586327877034413

Epoch: 6| Step: 11
Training loss: 2.4114561362424745
Validation loss: 2.560986527866798

Epoch: 6| Step: 12
Training loss: 3.037326660233765
Validation loss: 2.593820515838033

Epoch: 6| Step: 13
Training loss: 3.127988835590468
Validation loss: 2.5602362122740927

Epoch: 153| Step: 0
Training loss: 2.613822755462324
Validation loss: 2.5744252476312757

Epoch: 6| Step: 1
Training loss: 2.4804146347751
Validation loss: 2.567695023750273

Epoch: 6| Step: 2
Training loss: 3.844993080162697
Validation loss: 2.5715022645625045

Epoch: 6| Step: 3
Training loss: 2.7602166349282475
Validation loss: 2.602870371106646

Epoch: 6| Step: 4
Training loss: 1.9944494234387167
Validation loss: 2.585632682977124

Epoch: 6| Step: 5
Training loss: 2.3820488378288975
Validation loss: 2.565428215526803

Epoch: 6| Step: 6
Training loss: 2.595653616703603
Validation loss: 2.5638914434817206

Epoch: 6| Step: 7
Training loss: 2.1971555962034692
Validation loss: 2.5747441253585373

Epoch: 6| Step: 8
Training loss: 2.6805286032771707
Validation loss: 2.579695281122993

Epoch: 6| Step: 9
Training loss: 3.021305564713482
Validation loss: 2.5547202882986033

Epoch: 6| Step: 10
Training loss: 2.0615712010765366
Validation loss: 2.5833088704623752

Epoch: 6| Step: 11
Training loss: 2.784419450501409
Validation loss: 2.566530423036879

Epoch: 6| Step: 12
Training loss: 2.984829054239493
Validation loss: 2.5800653647838914

Epoch: 6| Step: 13
Training loss: 3.4329590368096565
Validation loss: 2.5764513655969066

Epoch: 154| Step: 0
Training loss: 1.9280267279264136
Validation loss: 2.6025184925281275

Epoch: 6| Step: 1
Training loss: 1.975276000620037
Validation loss: 2.5660999351476512

Epoch: 6| Step: 2
Training loss: 2.0895884135049188
Validation loss: 2.5568733990207986

Epoch: 6| Step: 3
Training loss: 3.1906298062907603
Validation loss: 2.591239625656855

Epoch: 6| Step: 4
Training loss: 2.54930999994706
Validation loss: 2.5972666083421885

Epoch: 6| Step: 5
Training loss: 2.7022311987574428
Validation loss: 2.554869798167842

Epoch: 6| Step: 6
Training loss: 3.4606817766698805
Validation loss: 2.582032107845985

Epoch: 6| Step: 7
Training loss: 3.296107487583217
Validation loss: 2.5933159016319296

Epoch: 6| Step: 8
Training loss: 2.8178612367295326
Validation loss: 2.5893846652258086

Epoch: 6| Step: 9
Training loss: 2.641297835906638
Validation loss: 2.586140504363667

Epoch: 6| Step: 10
Training loss: 2.274471087332573
Validation loss: 2.58836865465396

Epoch: 6| Step: 11
Training loss: 2.641575027304341
Validation loss: 2.581881341008968

Epoch: 6| Step: 12
Training loss: 3.220239387285638
Validation loss: 2.560794539915009

Epoch: 6| Step: 13
Training loss: 2.584576297471439
Validation loss: 2.5862166885984563

Epoch: 155| Step: 0
Training loss: 3.046887520006328
Validation loss: 2.5603502501759925

Epoch: 6| Step: 1
Training loss: 2.571753750025271
Validation loss: 2.5982620538264856

Epoch: 6| Step: 2
Training loss: 2.6052863702039097
Validation loss: 2.58144538881002

Epoch: 6| Step: 3
Training loss: 1.9321860998334628
Validation loss: 2.589092739121052

Epoch: 6| Step: 4
Training loss: 2.5728567221964886
Validation loss: 2.5803622048043326

Epoch: 6| Step: 5
Training loss: 2.3871684298532
Validation loss: 2.59117794988826

Epoch: 6| Step: 6
Training loss: 3.733034284285555
Validation loss: 2.5815288855566227

Epoch: 6| Step: 7
Training loss: 2.2481486863348565
Validation loss: 2.5927880503996987

Epoch: 6| Step: 8
Training loss: 2.4319433797469303
Validation loss: 2.595649689244009

Epoch: 6| Step: 9
Training loss: 2.9703292661592005
Validation loss: 2.5627027721998545

Epoch: 6| Step: 10
Training loss: 2.250218910588223
Validation loss: 2.5902809698680906

Epoch: 6| Step: 11
Training loss: 2.8629226772300957
Validation loss: 2.6111595668876997

Epoch: 6| Step: 12
Training loss: 2.507930384446989
Validation loss: 2.5683461812509916

Epoch: 6| Step: 13
Training loss: 3.394124418227218
Validation loss: 2.6108409916163664

Epoch: 156| Step: 0
Training loss: 1.9200445622994848
Validation loss: 2.568380118734329

Epoch: 6| Step: 1
Training loss: 2.6655636135246485
Validation loss: 2.5707801303439797

Epoch: 6| Step: 2
Training loss: 2.6849295277644214
Validation loss: 2.5868876392413576

Epoch: 6| Step: 3
Training loss: 3.5519813381254695
Validation loss: 2.574434436957547

Epoch: 6| Step: 4
Training loss: 2.431022939400381
Validation loss: 2.583854867434561

Epoch: 6| Step: 5
Training loss: 2.6851214151617344
Validation loss: 2.5781500443789325

Epoch: 6| Step: 6
Training loss: 3.088644419478485
Validation loss: 2.5939839743485558

Epoch: 6| Step: 7
Training loss: 3.026414770519767
Validation loss: 2.5913135665762086

Epoch: 6| Step: 8
Training loss: 2.026360010341205
Validation loss: 2.580170233764551

Epoch: 6| Step: 9
Training loss: 2.991594778771606
Validation loss: 2.577108763236383

Epoch: 6| Step: 10
Training loss: 2.2663701377708354
Validation loss: 2.5976304531551286

Epoch: 6| Step: 11
Training loss: 2.440597424613896
Validation loss: 2.571933518810815

Epoch: 6| Step: 12
Training loss: 3.2303139074041476
Validation loss: 2.5863482268654057

Epoch: 6| Step: 13
Training loss: 2.458810619853965
Validation loss: 2.573973461875287

Epoch: 157| Step: 0
Training loss: 2.6005267123255154
Validation loss: 2.6013400592361693

Epoch: 6| Step: 1
Training loss: 2.920989692917935
Validation loss: 2.5754040770695457

Epoch: 6| Step: 2
Training loss: 2.5965152385697174
Validation loss: 2.5871791106197586

Epoch: 6| Step: 3
Training loss: 2.1070557453908454
Validation loss: 2.5960299338935062

Epoch: 6| Step: 4
Training loss: 3.132125512805371
Validation loss: 2.5805927635969765

Epoch: 6| Step: 5
Training loss: 2.962864875052905
Validation loss: 2.5665125760921943

Epoch: 6| Step: 6
Training loss: 2.294494641083083
Validation loss: 2.579953836894679

Epoch: 6| Step: 7
Training loss: 2.5314339464955373
Validation loss: 2.609092036346759

Epoch: 6| Step: 8
Training loss: 3.532088188686156
Validation loss: 2.5998863716790304

Epoch: 6| Step: 9
Training loss: 2.2960529543123234
Validation loss: 2.6027256200519293

Epoch: 6| Step: 10
Training loss: 2.5376015553564666
Validation loss: 2.5661304067351733

Epoch: 6| Step: 11
Training loss: 2.5714266602948066
Validation loss: 2.5857010942024794

Epoch: 6| Step: 12
Training loss: 2.527846886198988
Validation loss: 2.572999684272896

Epoch: 6| Step: 13
Training loss: 2.999076383192279
Validation loss: 2.596235742426288

Epoch: 158| Step: 0
Training loss: 2.8316715827646255
Validation loss: 2.5488896940014367

Epoch: 6| Step: 1
Training loss: 2.372830454058717
Validation loss: 2.575178104003279

Epoch: 6| Step: 2
Training loss: 2.2404479612586754
Validation loss: 2.5693008826370938

Epoch: 6| Step: 3
Training loss: 2.5044375137207626
Validation loss: 2.5712777502243567

Epoch: 6| Step: 4
Training loss: 3.1236926586662883
Validation loss: 2.5548725616207966

Epoch: 6| Step: 5
Training loss: 2.4558276213687487
Validation loss: 2.59432835215063

Epoch: 6| Step: 6
Training loss: 2.8656284344734737
Validation loss: 2.5587830927555806

Epoch: 6| Step: 7
Training loss: 3.841685911669628
Validation loss: 2.6012372189830297

Epoch: 6| Step: 8
Training loss: 2.329660817945901
Validation loss: 2.5807916110025424

Epoch: 6| Step: 9
Training loss: 2.406420416804202
Validation loss: 2.5591406222656

Epoch: 6| Step: 10
Training loss: 2.9568441878579823
Validation loss: 2.5715401869895707

Epoch: 6| Step: 11
Training loss: 2.5764875355971832
Validation loss: 2.5723212412839667

Epoch: 6| Step: 12
Training loss: 2.573575624002947
Validation loss: 2.5795903660008612

Epoch: 6| Step: 13
Training loss: 2.1646060192203165
Validation loss: 2.555365615533049

Epoch: 159| Step: 0
Training loss: 3.0127679602768453
Validation loss: 2.5906838872483706

Epoch: 6| Step: 1
Training loss: 2.8733246939308703
Validation loss: 2.585311843702361

Epoch: 6| Step: 2
Training loss: 2.4693273521080386
Validation loss: 2.579325826190633

Epoch: 6| Step: 3
Training loss: 2.8684337100859967
Validation loss: 2.5781493234590136

Epoch: 6| Step: 4
Training loss: 2.7277685083239125
Validation loss: 2.582424146895083

Epoch: 6| Step: 5
Training loss: 3.302184832403904
Validation loss: 2.5803139510892676

Epoch: 6| Step: 6
Training loss: 2.533908907438523
Validation loss: 2.5849510298767715

Epoch: 6| Step: 7
Training loss: 2.6547737956264417
Validation loss: 2.59420674000801

Epoch: 6| Step: 8
Training loss: 2.5463250625475364
Validation loss: 2.5558281884115774

Epoch: 6| Step: 9
Training loss: 3.4536237399658725
Validation loss: 2.5793415345337345

Epoch: 6| Step: 10
Training loss: 2.4763955622585674
Validation loss: 2.5719159545675874

Epoch: 6| Step: 11
Training loss: 2.2696374549900047
Validation loss: 2.5829101196649895

Epoch: 6| Step: 12
Training loss: 1.9731384896514161
Validation loss: 2.552276175778256

Epoch: 6| Step: 13
Training loss: 2.400646968900928
Validation loss: 2.600387858417682

Epoch: 160| Step: 0
Training loss: 2.7698907228804566
Validation loss: 2.5872298433075174

Epoch: 6| Step: 1
Training loss: 3.0366092773050566
Validation loss: 2.584957201566852

Epoch: 6| Step: 2
Training loss: 2.9284393500075026
Validation loss: 2.561504836070413

Epoch: 6| Step: 3
Training loss: 2.3662603092120165
Validation loss: 2.588901920487669

Epoch: 6| Step: 4
Training loss: 2.6428845010173587
Validation loss: 2.5793383793555362

Epoch: 6| Step: 5
Training loss: 2.6380322610821603
Validation loss: 2.577787796993372

Epoch: 6| Step: 6
Training loss: 1.7995431081744335
Validation loss: 2.601239676935222

Epoch: 6| Step: 7
Training loss: 2.5504526858462753
Validation loss: 2.5940956688948646

Epoch: 6| Step: 8
Training loss: 3.1387733580746753
Validation loss: 2.6126740053587283

Epoch: 6| Step: 9
Training loss: 2.188385702389292
Validation loss: 2.575393823100084

Epoch: 6| Step: 10
Training loss: 2.3668895571703987
Validation loss: 2.5803094225379004

Epoch: 6| Step: 11
Training loss: 2.746710543868446
Validation loss: 2.6107465275961084

Epoch: 6| Step: 12
Training loss: 2.833050564137958
Validation loss: 2.5771116649903294

Epoch: 6| Step: 13
Training loss: 3.8067566182141697
Validation loss: 2.5735889752275973

Epoch: 161| Step: 0
Training loss: 2.051814983139713
Validation loss: 2.5666814922974788

Epoch: 6| Step: 1
Training loss: 2.75499410583641
Validation loss: 2.5753876782641445

Epoch: 6| Step: 2
Training loss: 3.226804858104245
Validation loss: 2.598358851270286

Epoch: 6| Step: 3
Training loss: 1.6968910146277196
Validation loss: 2.5809005141182726

Epoch: 6| Step: 4
Training loss: 2.3053767838421804
Validation loss: 2.5687875087103245

Epoch: 6| Step: 5
Training loss: 3.0923606758527615
Validation loss: 2.577617578672959

Epoch: 6| Step: 6
Training loss: 2.8020564837865205
Validation loss: 2.621605005403258

Epoch: 6| Step: 7
Training loss: 2.7114521164785588
Validation loss: 2.5774181561660594

Epoch: 6| Step: 8
Training loss: 3.0172257202193093
Validation loss: 2.5907478101436023

Epoch: 6| Step: 9
Training loss: 3.021687161151154
Validation loss: 2.576302435487405

Epoch: 6| Step: 10
Training loss: 2.5844674440983955
Validation loss: 2.5955917495120375

Epoch: 6| Step: 11
Training loss: 2.2055010596951448
Validation loss: 2.609399978275472

Epoch: 6| Step: 12
Training loss: 3.092484957289133
Validation loss: 2.5818168431102984

Epoch: 6| Step: 13
Training loss: 2.9685079375513173
Validation loss: 2.566223506627401

Epoch: 162| Step: 0
Training loss: 2.2879217123896365
Validation loss: 2.5769811484862966

Epoch: 6| Step: 1
Training loss: 2.9583682385028607
Validation loss: 2.612141057370539

Epoch: 6| Step: 2
Training loss: 2.110912412639774
Validation loss: 2.5748400311829402

Epoch: 6| Step: 3
Training loss: 2.926468283403996
Validation loss: 2.5775203797578548

Epoch: 6| Step: 4
Training loss: 2.0414133368864382
Validation loss: 2.5775696157178443

Epoch: 6| Step: 5
Training loss: 3.490572903892382
Validation loss: 2.569077035594944

Epoch: 6| Step: 6
Training loss: 2.4266685054932777
Validation loss: 2.598198725282731

Epoch: 6| Step: 7
Training loss: 2.848501072277251
Validation loss: 2.539222398997067

Epoch: 6| Step: 8
Training loss: 3.0886916606091335
Validation loss: 2.6117413883833533

Epoch: 6| Step: 9
Training loss: 2.4970704079793196
Validation loss: 2.5864621943586816

Epoch: 6| Step: 10
Training loss: 2.5630238625572415
Validation loss: 2.553696916153054

Epoch: 6| Step: 11
Training loss: 2.5219038799764135
Validation loss: 2.603173416881637

Epoch: 6| Step: 12
Training loss: 3.2986746120475408
Validation loss: 2.586629450486646

Epoch: 6| Step: 13
Training loss: 2.401681998065173
Validation loss: 2.573999522205928

Epoch: 163| Step: 0
Training loss: 2.911785473582324
Validation loss: 2.5917793830528417

Epoch: 6| Step: 1
Training loss: 2.9309743267641206
Validation loss: 2.5836996148953224

Epoch: 6| Step: 2
Training loss: 3.159032822368697
Validation loss: 2.5794359570087777

Epoch: 6| Step: 3
Training loss: 3.0945804906951624
Validation loss: 2.606077509264629

Epoch: 6| Step: 4
Training loss: 2.6369125181984314
Validation loss: 2.6027359987976983

Epoch: 6| Step: 5
Training loss: 2.271318949533027
Validation loss: 2.5735182148403823

Epoch: 6| Step: 6
Training loss: 2.244905426140365
Validation loss: 2.5825327394495257

Epoch: 6| Step: 7
Training loss: 2.6239296683794806
Validation loss: 2.5658987792246197

Epoch: 6| Step: 8
Training loss: 2.327060737830293
Validation loss: 2.59317939907489

Epoch: 6| Step: 9
Training loss: 3.0034258672901544
Validation loss: 2.5874433607461653

Epoch: 6| Step: 10
Training loss: 2.7869484633768007
Validation loss: 2.5732072331754376

Epoch: 6| Step: 11
Training loss: 2.1290680710072816
Validation loss: 2.557925087442057

Epoch: 6| Step: 12
Training loss: 2.706902130702667
Validation loss: 2.5643909449525224

Epoch: 6| Step: 13
Training loss: 2.6139610330118717
Validation loss: 2.584021652910559

Epoch: 164| Step: 0
Training loss: 2.7471388758440716
Validation loss: 2.5742403896191006

Epoch: 6| Step: 1
Training loss: 2.924515291139773
Validation loss: 2.5681368399484166

Epoch: 6| Step: 2
Training loss: 2.2025502855360513
Validation loss: 2.584591147160239

Epoch: 6| Step: 3
Training loss: 2.8191646025722736
Validation loss: 2.5638951421172047

Epoch: 6| Step: 4
Training loss: 2.423397840597172
Validation loss: 2.5995713561355323

Epoch: 6| Step: 5
Training loss: 2.7464701800141635
Validation loss: 2.5887043110510697

Epoch: 6| Step: 6
Training loss: 2.4111627736785204
Validation loss: 2.557236664695174

Epoch: 6| Step: 7
Training loss: 2.9575380321904614
Validation loss: 2.589098916781126

Epoch: 6| Step: 8
Training loss: 2.928393757311979
Validation loss: 2.59355707262783

Epoch: 6| Step: 9
Training loss: 2.913081681609362
Validation loss: 2.5885977377597658

Epoch: 6| Step: 10
Training loss: 2.893975537864362
Validation loss: 2.579671694722906

Epoch: 6| Step: 11
Training loss: 3.0248081934626483
Validation loss: 2.5794191683932564

Epoch: 6| Step: 12
Training loss: 2.3476714833506396
Validation loss: 2.558335931484096

Epoch: 6| Step: 13
Training loss: 1.994877394252583
Validation loss: 2.602932311524197

Epoch: 165| Step: 0
Training loss: 1.7148274831499968
Validation loss: 2.5966600613578037

Epoch: 6| Step: 1
Training loss: 2.713739799153516
Validation loss: 2.552417093585168

Epoch: 6| Step: 2
Training loss: 1.9222329899529802
Validation loss: 2.5877087410247888

Epoch: 6| Step: 3
Training loss: 3.3125958698722555
Validation loss: 2.567746941117447

Epoch: 6| Step: 4
Training loss: 2.4147061474439115
Validation loss: 2.5882324210974588

Epoch: 6| Step: 5
Training loss: 2.5014929128543026
Validation loss: 2.5541179968379963

Epoch: 6| Step: 6
Training loss: 2.8221503950308624
Validation loss: 2.566113381463342

Epoch: 6| Step: 7
Training loss: 2.513255075135206
Validation loss: 2.590047519165722

Epoch: 6| Step: 8
Training loss: 3.095540308957763
Validation loss: 2.5703520298190408

Epoch: 6| Step: 9
Training loss: 2.8625647258520432
Validation loss: 2.570242665792096

Epoch: 6| Step: 10
Training loss: 2.9752923453166913
Validation loss: 2.569636155965527

Epoch: 6| Step: 11
Training loss: 3.152421498905674
Validation loss: 2.569748852926976

Epoch: 6| Step: 12
Training loss: 2.909895056965751
Validation loss: 2.570469803791468

Epoch: 6| Step: 13
Training loss: 2.4043090720839584
Validation loss: 2.608823178887277

Epoch: 166| Step: 0
Training loss: 1.914233889010415
Validation loss: 2.584115765981437

Epoch: 6| Step: 1
Training loss: 2.9901276911386185
Validation loss: 2.542560082138901

Epoch: 6| Step: 2
Training loss: 3.4022341512377765
Validation loss: 2.5691739991424654

Epoch: 6| Step: 3
Training loss: 2.5574804315349757
Validation loss: 2.5690147928299885

Epoch: 6| Step: 4
Training loss: 2.161706626756076
Validation loss: 2.58501454214108

Epoch: 6| Step: 5
Training loss: 2.3332908717333676
Validation loss: 2.5924647933039715

Epoch: 6| Step: 6
Training loss: 2.976431295551959
Validation loss: 2.5671387791036864

Epoch: 6| Step: 7
Training loss: 2.852446620217705
Validation loss: 2.558543121831446

Epoch: 6| Step: 8
Training loss: 2.133745261993243
Validation loss: 2.5416248280433558

Epoch: 6| Step: 9
Training loss: 3.0913935462704134
Validation loss: 2.5797375043548287

Epoch: 6| Step: 10
Training loss: 2.4187914507170243
Validation loss: 2.589510381700936

Epoch: 6| Step: 11
Training loss: 2.597245308631202
Validation loss: 2.579812488439899

Epoch: 6| Step: 12
Training loss: 3.1879925814725363
Validation loss: 2.588382266324211

Epoch: 6| Step: 13
Training loss: 2.442742993421367
Validation loss: 2.558748620205807

Epoch: 167| Step: 0
Training loss: 3.0714677573711096
Validation loss: 2.608567885559227

Epoch: 6| Step: 1
Training loss: 3.056610048768795
Validation loss: 2.550911313105567

Epoch: 6| Step: 2
Training loss: 2.512836498292493
Validation loss: 2.5725908940457276

Epoch: 6| Step: 3
Training loss: 2.4697948128111604
Validation loss: 2.597552776843328

Epoch: 6| Step: 4
Training loss: 2.083365122234685
Validation loss: 2.596938506886783

Epoch: 6| Step: 5
Training loss: 3.0017343911751375
Validation loss: 2.590372954351683

Epoch: 6| Step: 6
Training loss: 2.3903247919014707
Validation loss: 2.5756410328308808

Epoch: 6| Step: 7
Training loss: 2.3728101573034746
Validation loss: 2.580394649972586

Epoch: 6| Step: 8
Training loss: 2.229346104705465
Validation loss: 2.592345181364116

Epoch: 6| Step: 9
Training loss: 1.652344904328793
Validation loss: 2.572606564289414

Epoch: 6| Step: 10
Training loss: 3.226235435479569
Validation loss: 2.597514315328282

Epoch: 6| Step: 11
Training loss: 2.72471079210331
Validation loss: 2.567949029457727

Epoch: 6| Step: 12
Training loss: 3.197061297972431
Validation loss: 2.564089440465209

Epoch: 6| Step: 13
Training loss: 3.0439392031038306
Validation loss: 2.5646595832542234

Epoch: 168| Step: 0
Training loss: 2.518044392310332
Validation loss: 2.57941717366948

Epoch: 6| Step: 1
Training loss: 2.5685580216668153
Validation loss: 2.567998781363088

Epoch: 6| Step: 2
Training loss: 2.9501214471160973
Validation loss: 2.5789820464969515

Epoch: 6| Step: 3
Training loss: 2.7754456892463772
Validation loss: 2.5796814298284745

Epoch: 6| Step: 4
Training loss: 2.077810851710482
Validation loss: 2.582342043641818

Epoch: 6| Step: 5
Training loss: 2.6619466394626388
Validation loss: 2.6018020789081544

Epoch: 6| Step: 6
Training loss: 2.440269559603826
Validation loss: 2.5951306211653575

Epoch: 6| Step: 7
Training loss: 2.6704267179415346
Validation loss: 2.5751743708015495

Epoch: 6| Step: 8
Training loss: 2.189567134179015
Validation loss: 2.605147690275548

Epoch: 6| Step: 9
Training loss: 2.8812600687972285
Validation loss: 2.601386649187807

Epoch: 6| Step: 10
Training loss: 3.2434980937775157
Validation loss: 2.5878593090327286

Epoch: 6| Step: 11
Training loss: 2.4851460729760575
Validation loss: 2.5879317734384584

Epoch: 6| Step: 12
Training loss: 2.8300833481555494
Validation loss: 2.584468968712104

Epoch: 6| Step: 13
Training loss: 3.2769831935345666
Validation loss: 2.6032637936283023

Epoch: 169| Step: 0
Training loss: 2.8726455335544263
Validation loss: 2.6401591566312788

Epoch: 6| Step: 1
Training loss: 3.025903765391773
Validation loss: 2.6278354968128905

Epoch: 6| Step: 2
Training loss: 2.891248810962081
Validation loss: 2.564725412244576

Epoch: 6| Step: 3
Training loss: 2.2637113710895966
Validation loss: 2.5810095288515957

Epoch: 6| Step: 4
Training loss: 1.8556675212198717
Validation loss: 2.5672467015695015

Epoch: 6| Step: 5
Training loss: 2.8080894643546057
Validation loss: 2.5805419530790803

Epoch: 6| Step: 6
Training loss: 2.570022427501859
Validation loss: 2.579235479370005

Epoch: 6| Step: 7
Training loss: 2.4757754642687404
Validation loss: 2.57730905815932

Epoch: 6| Step: 8
Training loss: 2.824358376076101
Validation loss: 2.5865061045932123

Epoch: 6| Step: 9
Training loss: 2.1953320485395205
Validation loss: 2.592190717213399

Epoch: 6| Step: 10
Training loss: 2.3814377117512797
Validation loss: 2.5735532914519847

Epoch: 6| Step: 11
Training loss: 3.09491900311854
Validation loss: 2.566530161331865

Epoch: 6| Step: 12
Training loss: 3.3697007573328714
Validation loss: 2.610133207743409

Epoch: 6| Step: 13
Training loss: 2.962090984711473
Validation loss: 2.5815831553055575

Epoch: 170| Step: 0
Training loss: 2.3156232620212145
Validation loss: 2.5823935007528034

Epoch: 6| Step: 1
Training loss: 2.646082908894237
Validation loss: 2.597353066851903

Epoch: 6| Step: 2
Training loss: 2.8061003035483636
Validation loss: 2.596765234580229

Epoch: 6| Step: 3
Training loss: 2.739874491914787
Validation loss: 2.585155746485745

Epoch: 6| Step: 4
Training loss: 2.746900892949368
Validation loss: 2.5725190757738523

Epoch: 6| Step: 5
Training loss: 2.0790309222088275
Validation loss: 2.5576428636993964

Epoch: 6| Step: 6
Training loss: 2.69944830662225
Validation loss: 2.5793552539729503

Epoch: 6| Step: 7
Training loss: 2.2060664676049466
Validation loss: 2.6032870402277393

Epoch: 6| Step: 8
Training loss: 2.701411944772831
Validation loss: 2.5725422155314517

Epoch: 6| Step: 9
Training loss: 3.086312341257419
Validation loss: 2.5873592978695124

Epoch: 6| Step: 10
Training loss: 2.904234320474196
Validation loss: 2.578643975301207

Epoch: 6| Step: 11
Training loss: 3.317281474984802
Validation loss: 2.5897253088575374

Epoch: 6| Step: 12
Training loss: 2.424727402929167
Validation loss: 2.5719918026114197

Epoch: 6| Step: 13
Training loss: 2.758141084715316
Validation loss: 2.58518170599162

Epoch: 171| Step: 0
Training loss: 2.293201233289897
Validation loss: 2.567758328851877

Epoch: 6| Step: 1
Training loss: 2.338223974544153
Validation loss: 2.57993807812395

Epoch: 6| Step: 2
Training loss: 3.565612771550706
Validation loss: 2.5645544019020363

Epoch: 6| Step: 3
Training loss: 2.494733126171834
Validation loss: 2.591269916381725

Epoch: 6| Step: 4
Training loss: 2.7064670784028153
Validation loss: 2.5740953392480055

Epoch: 6| Step: 5
Training loss: 2.828505685380789
Validation loss: 2.5696998133014195

Epoch: 6| Step: 6
Training loss: 2.6253445717044883
Validation loss: 2.611367696604499

Epoch: 6| Step: 7
Training loss: 2.720248543799843
Validation loss: 2.6081167518858406

Epoch: 6| Step: 8
Training loss: 3.138915702307701
Validation loss: 2.5691066695824856

Epoch: 6| Step: 9
Training loss: 2.143673139701272
Validation loss: 2.5637615039010346

Epoch: 6| Step: 10
Training loss: 3.196199998043025
Validation loss: 2.5960395691426745

Epoch: 6| Step: 11
Training loss: 2.7809001402526796
Validation loss: 2.5793883657901167

Epoch: 6| Step: 12
Training loss: 1.911782163652482
Validation loss: 2.607151166796975

Epoch: 6| Step: 13
Training loss: 2.034978057030698
Validation loss: 2.5716581587593255

Epoch: 172| Step: 0
Training loss: 2.5853959637309183
Validation loss: 2.592716273465619

Epoch: 6| Step: 1
Training loss: 2.3123948356841297
Validation loss: 2.581997984419209

Epoch: 6| Step: 2
Training loss: 2.9998658468133126
Validation loss: 2.5958571164617483

Epoch: 6| Step: 3
Training loss: 2.909816235642299
Validation loss: 2.602456429961693

Epoch: 6| Step: 4
Training loss: 2.407902534083857
Validation loss: 2.589510343090554

Epoch: 6| Step: 5
Training loss: 2.670168861735734
Validation loss: 2.573224974908192

Epoch: 6| Step: 6
Training loss: 3.0641345897327326
Validation loss: 2.575324152562778

Epoch: 6| Step: 7
Training loss: 3.7551257388501913
Validation loss: 2.5694124543706707

Epoch: 6| Step: 8
Training loss: 2.8852257694119046
Validation loss: 2.57049944466112

Epoch: 6| Step: 9
Training loss: 2.1784770708398673
Validation loss: 2.5893586047917267

Epoch: 6| Step: 10
Training loss: 2.009479350321594
Validation loss: 2.5871694829992133

Epoch: 6| Step: 11
Training loss: 2.499708921653312
Validation loss: 2.5731799239383695

Epoch: 6| Step: 12
Training loss: 2.3909233754770027
Validation loss: 2.5742179562749516

Epoch: 6| Step: 13
Training loss: 2.167680380948205
Validation loss: 2.5537146870201997

Epoch: 173| Step: 0
Training loss: 3.0883336289294685
Validation loss: 2.5782289416309676

Epoch: 6| Step: 1
Training loss: 2.6776468497787618
Validation loss: 2.5850268316499867

Epoch: 6| Step: 2
Training loss: 2.653734789035236
Validation loss: 2.5776275443209755

Epoch: 6| Step: 3
Training loss: 2.8159293565938235
Validation loss: 2.5704764181632047

Epoch: 6| Step: 4
Training loss: 3.0026320990757265
Validation loss: 2.593209090294969

Epoch: 6| Step: 5
Training loss: 3.1096042567709525
Validation loss: 2.611958661550652

Epoch: 6| Step: 6
Training loss: 2.830272891633116
Validation loss: 2.5638734901752778

Epoch: 6| Step: 7
Training loss: 2.490043459287043
Validation loss: 2.585667121318432

Epoch: 6| Step: 8
Training loss: 2.47641067761544
Validation loss: 2.602876189071489

Epoch: 6| Step: 9
Training loss: 2.6693308356759617
Validation loss: 2.5583365267156846

Epoch: 6| Step: 10
Training loss: 2.6992042640485026
Validation loss: 2.603173788156345

Epoch: 6| Step: 11
Training loss: 2.2756604210690714
Validation loss: 2.611407380505827

Epoch: 6| Step: 12
Training loss: 2.14460551371301
Validation loss: 2.5610656815917823

Epoch: 6| Step: 13
Training loss: 2.133577761455735
Validation loss: 2.554998475173788

Epoch: 174| Step: 0
Training loss: 2.9999170291871136
Validation loss: 2.579352672296823

Epoch: 6| Step: 1
Training loss: 2.9410084003223456
Validation loss: 2.5665910839410024

Epoch: 6| Step: 2
Training loss: 2.4429458036403355
Validation loss: 2.580953775976043

Epoch: 6| Step: 3
Training loss: 3.3376457611143473
Validation loss: 2.5597998096030143

Epoch: 6| Step: 4
Training loss: 2.2569909102392476
Validation loss: 2.587322840908094

Epoch: 6| Step: 5
Training loss: 2.7933016491946505
Validation loss: 2.6070391387084055

Epoch: 6| Step: 6
Training loss: 1.984036574453435
Validation loss: 2.569580805813987

Epoch: 6| Step: 7
Training loss: 2.767551850037369
Validation loss: 2.584923581892611

Epoch: 6| Step: 8
Training loss: 2.6700213510752593
Validation loss: 2.5718649357464343

Epoch: 6| Step: 9
Training loss: 2.748864806563241
Validation loss: 2.5658611221177368

Epoch: 6| Step: 10
Training loss: 2.762746056002704
Validation loss: 2.5750447048850886

Epoch: 6| Step: 11
Training loss: 2.945887178165432
Validation loss: 2.56872083120779

Epoch: 6| Step: 12
Training loss: 2.183048623816087
Validation loss: 2.572856774010222

Epoch: 6| Step: 13
Training loss: 2.4718073974315957
Validation loss: 2.570678594102001

Epoch: 175| Step: 0
Training loss: 3.0767969664992654
Validation loss: 2.5576777721318362

Epoch: 6| Step: 1
Training loss: 2.7646120446982123
Validation loss: 2.566827532912037

Epoch: 6| Step: 2
Training loss: 2.352018293140921
Validation loss: 2.602895001091591

Epoch: 6| Step: 3
Training loss: 3.489268061881462
Validation loss: 2.602954465879419

Epoch: 6| Step: 4
Training loss: 2.260863674516563
Validation loss: 2.6100959766723215

Epoch: 6| Step: 5
Training loss: 2.371415495056763
Validation loss: 2.575706296501033

Epoch: 6| Step: 6
Training loss: 2.899391366953949
Validation loss: 2.5837166158167455

Epoch: 6| Step: 7
Training loss: 2.9245405635123944
Validation loss: 2.546816100634741

Epoch: 6| Step: 8
Training loss: 2.089607125549669
Validation loss: 2.551388830665451

Epoch: 6| Step: 9
Training loss: 2.5729009239137297
Validation loss: 2.5776410764555946

Epoch: 6| Step: 10
Training loss: 2.638930459838378
Validation loss: 2.565769118155664

Epoch: 6| Step: 11
Training loss: 2.644437847431976
Validation loss: 2.5835720121361723

Epoch: 6| Step: 12
Training loss: 2.444218790110043
Validation loss: 2.573207924595211

Epoch: 6| Step: 13
Training loss: 2.5484079065715455
Validation loss: 2.5974734529223147

Epoch: 176| Step: 0
Training loss: 2.6066808440496883
Validation loss: 2.581803932613192

Epoch: 6| Step: 1
Training loss: 2.150767779212832
Validation loss: 2.5808472685446446

Epoch: 6| Step: 2
Training loss: 2.280716925221796
Validation loss: 2.593390669075656

Epoch: 6| Step: 3
Training loss: 2.8045713777862997
Validation loss: 2.565004994697108

Epoch: 6| Step: 4
Training loss: 2.815739609632853
Validation loss: 2.602306303612176

Epoch: 6| Step: 5
Training loss: 2.6694278329717656
Validation loss: 2.591062716080947

Epoch: 6| Step: 6
Training loss: 3.0955775864233956
Validation loss: 2.606724647275988

Epoch: 6| Step: 7
Training loss: 2.6411853624586756
Validation loss: 2.5940841339000746

Epoch: 6| Step: 8
Training loss: 2.5677064246943706
Validation loss: 2.5523913477413562

Epoch: 6| Step: 9
Training loss: 2.4467811927011485
Validation loss: 2.5803816856647077

Epoch: 6| Step: 10
Training loss: 2.5364027911507905
Validation loss: 2.5725932438409753

Epoch: 6| Step: 11
Training loss: 3.418155826353571
Validation loss: 2.6138684824687934

Epoch: 6| Step: 12
Training loss: 2.803110938743953
Validation loss: 2.578145877956204

Epoch: 6| Step: 13
Training loss: 1.9418066214464775
Validation loss: 2.5685813637874175

Epoch: 177| Step: 0
Training loss: 1.9668154218418592
Validation loss: 2.5758081451318393

Epoch: 6| Step: 1
Training loss: 3.492869470559514
Validation loss: 2.5739517298746217

Epoch: 6| Step: 2
Training loss: 2.915813502916307
Validation loss: 2.578062385999456

Epoch: 6| Step: 3
Training loss: 2.6067886783828715
Validation loss: 2.569074400182188

Epoch: 6| Step: 4
Training loss: 2.415114090398446
Validation loss: 2.5944556966278225

Epoch: 6| Step: 5
Training loss: 2.468676795356995
Validation loss: 2.5682081748462577

Epoch: 6| Step: 6
Training loss: 2.5413212984499944
Validation loss: 2.553066044536417

Epoch: 6| Step: 7
Training loss: 2.8003150626444238
Validation loss: 2.562313622300476

Epoch: 6| Step: 8
Training loss: 3.1098845557959893
Validation loss: 2.5705117202892986

Epoch: 6| Step: 9
Training loss: 2.369115264832322
Validation loss: 2.5602127860578814

Epoch: 6| Step: 10
Training loss: 2.920941698473934
Validation loss: 2.5734662286136225

Epoch: 6| Step: 11
Training loss: 2.6949979294466404
Validation loss: 2.58066208030169

Epoch: 6| Step: 12
Training loss: 1.8561464377133836
Validation loss: 2.5891186170713323

Epoch: 6| Step: 13
Training loss: 3.084047922031722
Validation loss: 2.5637238773988957

Epoch: 178| Step: 0
Training loss: 2.347961507491471
Validation loss: 2.5777171240200625

Epoch: 6| Step: 1
Training loss: 3.2709893515403907
Validation loss: 2.571183513225421

Epoch: 6| Step: 2
Training loss: 2.09750689608835
Validation loss: 2.5888113047840076

Epoch: 6| Step: 3
Training loss: 2.9052604713471166
Validation loss: 2.581890257550867

Epoch: 6| Step: 4
Training loss: 2.6375030481402244
Validation loss: 2.587590877844705

Epoch: 6| Step: 5
Training loss: 2.9648635320795087
Validation loss: 2.58382915703142

Epoch: 6| Step: 6
Training loss: 2.489761558973958
Validation loss: 2.5763422435665606

Epoch: 6| Step: 7
Training loss: 2.663458971140439
Validation loss: 2.589800184911053

Epoch: 6| Step: 8
Training loss: 2.8680500115645557
Validation loss: 2.6000450611548147

Epoch: 6| Step: 9
Training loss: 2.4295832866140312
Validation loss: 2.572545551944448

Epoch: 6| Step: 10
Training loss: 2.5972800993519636
Validation loss: 2.575483274443638

Epoch: 6| Step: 11
Training loss: 2.3164260117200888
Validation loss: 2.574167471572617

Epoch: 6| Step: 12
Training loss: 2.8678180718385993
Validation loss: 2.5540938941954696

Epoch: 6| Step: 13
Training loss: 2.9856497553581067
Validation loss: 2.593574989484236

Epoch: 179| Step: 0
Training loss: 2.669925089724656
Validation loss: 2.6084073833024184

Epoch: 6| Step: 1
Training loss: 2.9496775693389816
Validation loss: 2.582298688048339

Epoch: 6| Step: 2
Training loss: 2.159122157441115
Validation loss: 2.584369479086427

Epoch: 6| Step: 3
Training loss: 2.758731332360574
Validation loss: 2.594343441481411

Epoch: 6| Step: 4
Training loss: 2.73779675691117
Validation loss: 2.562627105401807

Epoch: 6| Step: 5
Training loss: 2.390961467526563
Validation loss: 2.596195312153425

Epoch: 6| Step: 6
Training loss: 2.5428324251213517
Validation loss: 2.6052919387383398

Epoch: 6| Step: 7
Training loss: 2.6051033370010215
Validation loss: 2.6103648758882545

Epoch: 6| Step: 8
Training loss: 2.8420930164103044
Validation loss: 2.580609726374134

Epoch: 6| Step: 9
Training loss: 1.820959213700855
Validation loss: 2.588700682523149

Epoch: 6| Step: 10
Training loss: 2.498606865863776
Validation loss: 2.5983932615368075

Epoch: 6| Step: 11
Training loss: 3.068568387066835
Validation loss: 2.5881171264714102

Epoch: 6| Step: 12
Training loss: 2.7746940237905835
Validation loss: 2.5976840095230314

Epoch: 6| Step: 13
Training loss: 3.2401423978714092
Validation loss: 2.5901702114331373

Epoch: 180| Step: 0
Training loss: 2.4173137412367014
Validation loss: 2.5745002002282584

Epoch: 6| Step: 1
Training loss: 2.775318034737498
Validation loss: 2.5965055181995362

Epoch: 6| Step: 2
Training loss: 3.0180587830174916
Validation loss: 2.588880475707895

Epoch: 6| Step: 3
Training loss: 3.313128717604262
Validation loss: 2.5713144705710422

Epoch: 6| Step: 4
Training loss: 2.825239363800624
Validation loss: 2.5660164408840247

Epoch: 6| Step: 5
Training loss: 2.9130437056945473
Validation loss: 2.5814400652769884

Epoch: 6| Step: 6
Training loss: 2.650333232440962
Validation loss: 2.5963346944033447

Epoch: 6| Step: 7
Training loss: 2.2417093757427544
Validation loss: 2.580683467709508

Epoch: 6| Step: 8
Training loss: 2.2393046597530883
Validation loss: 2.5903772010656287

Epoch: 6| Step: 9
Training loss: 2.3024221892986216
Validation loss: 2.595587001680716

Epoch: 6| Step: 10
Training loss: 3.3063444127698634
Validation loss: 2.594931374826639

Epoch: 6| Step: 11
Training loss: 2.507926391677351
Validation loss: 2.592684259355106

Epoch: 6| Step: 12
Training loss: 2.1043460379211525
Validation loss: 2.5789408357800596

Epoch: 6| Step: 13
Training loss: 1.768803191985861
Validation loss: 2.5732299004888524

Epoch: 181| Step: 0
Training loss: 2.6989476554970526
Validation loss: 2.587709091732235

Epoch: 6| Step: 1
Training loss: 2.893390384351853
Validation loss: 2.588391094112253

Epoch: 6| Step: 2
Training loss: 1.857918433272463
Validation loss: 2.572440221649962

Epoch: 6| Step: 3
Training loss: 2.124206731494998
Validation loss: 2.584721018539444

Epoch: 6| Step: 4
Training loss: 2.6790493130134085
Validation loss: 2.61762621304484

Epoch: 6| Step: 5
Training loss: 2.434106861473779
Validation loss: 2.5617219657687498

Epoch: 6| Step: 6
Training loss: 2.4180579839211336
Validation loss: 2.5706579018249682

Epoch: 6| Step: 7
Training loss: 2.621233554073582
Validation loss: 2.5746458859649533

Epoch: 6| Step: 8
Training loss: 2.5235414276924946
Validation loss: 2.5732617820380854

Epoch: 6| Step: 9
Training loss: 2.9727805634219417
Validation loss: 2.5835167819360274

Epoch: 6| Step: 10
Training loss: 2.9573984056760123
Validation loss: 2.5872384996420843

Epoch: 6| Step: 11
Training loss: 2.3418226328141913
Validation loss: 2.5532406327388224

Epoch: 6| Step: 12
Training loss: 3.4561720992789096
Validation loss: 2.577493916893225

Epoch: 6| Step: 13
Training loss: 3.0656840063049016
Validation loss: 2.5616305086894546

Epoch: 182| Step: 0
Training loss: 1.8908747988789212
Validation loss: 2.612359602493469

Epoch: 6| Step: 1
Training loss: 2.5781542227273744
Validation loss: 2.580573830721109

Epoch: 6| Step: 2
Training loss: 3.5037320539196575
Validation loss: 2.58850288242387

Epoch: 6| Step: 3
Training loss: 2.8080407289230203
Validation loss: 2.5768908756530498

Epoch: 6| Step: 4
Training loss: 2.243812211643253
Validation loss: 2.5723898380942516

Epoch: 6| Step: 5
Training loss: 2.9498453649305
Validation loss: 2.562245048387542

Epoch: 6| Step: 6
Training loss: 3.2653449271533526
Validation loss: 2.6210730341735506

Epoch: 6| Step: 7
Training loss: 2.2867266614103943
Validation loss: 2.5819019224859128

Epoch: 6| Step: 8
Training loss: 2.825690132846784
Validation loss: 2.6067993817152155

Epoch: 6| Step: 9
Training loss: 2.1789709301112805
Validation loss: 2.584698873538394

Epoch: 6| Step: 10
Training loss: 2.2795999908907785
Validation loss: 2.565381828451998

Epoch: 6| Step: 11
Training loss: 3.0389771437242046
Validation loss: 2.599498980495113

Epoch: 6| Step: 12
Training loss: 2.2589250087440695
Validation loss: 2.6042294901171332

Epoch: 6| Step: 13
Training loss: 2.1811878140829495
Validation loss: 2.577334130360633

Epoch: 183| Step: 0
Training loss: 2.4340728728983927
Validation loss: 2.5874520688786684

Epoch: 6| Step: 1
Training loss: 1.491411256856692
Validation loss: 2.586434796607383

Epoch: 6| Step: 2
Training loss: 2.50244202553346
Validation loss: 2.5712699614154753

Epoch: 6| Step: 3
Training loss: 2.8477456663559377
Validation loss: 2.5849977490951703

Epoch: 6| Step: 4
Training loss: 2.851695938123618
Validation loss: 2.5774169108582914

Epoch: 6| Step: 5
Training loss: 3.7468838778303915
Validation loss: 2.6025121024266675

Epoch: 6| Step: 6
Training loss: 2.4013597411497503
Validation loss: 2.5733045541607837

Epoch: 6| Step: 7
Training loss: 2.960243324897894
Validation loss: 2.588450654400454

Epoch: 6| Step: 8
Training loss: 3.001766161783235
Validation loss: 2.5754865801708275

Epoch: 6| Step: 9
Training loss: 2.4869006292647975
Validation loss: 2.5830569786002857

Epoch: 6| Step: 10
Training loss: 2.8614767719494507
Validation loss: 2.5771647554688197

Epoch: 6| Step: 11
Training loss: 1.8457210156416317
Validation loss: 2.5904343365549605

Epoch: 6| Step: 12
Training loss: 2.6724975931354815
Validation loss: 2.5546649732296167

Epoch: 6| Step: 13
Training loss: 2.2980374878298204
Validation loss: 2.5823588172259395

Epoch: 184| Step: 0
Training loss: 1.9691729621070881
Validation loss: 2.582843817167215

Epoch: 6| Step: 1
Training loss: 3.0843027154709737
Validation loss: 2.5742894074788367

Epoch: 6| Step: 2
Training loss: 3.1128574212077345
Validation loss: 2.598080335947238

Epoch: 6| Step: 3
Training loss: 2.952117102050037
Validation loss: 2.586381721961887

Epoch: 6| Step: 4
Training loss: 3.2881408994979475
Validation loss: 2.578273850684241

Epoch: 6| Step: 5
Training loss: 2.615096347120718
Validation loss: 2.60158735817262

Epoch: 6| Step: 6
Training loss: 2.3781501558153844
Validation loss: 2.5762921636991045

Epoch: 6| Step: 7
Training loss: 1.9192724206332126
Validation loss: 2.5869601001443723

Epoch: 6| Step: 8
Training loss: 2.712985977024124
Validation loss: 2.583947586669399

Epoch: 6| Step: 9
Training loss: 2.3384202502250524
Validation loss: 2.5823119629002393

Epoch: 6| Step: 10
Training loss: 2.8263019566102567
Validation loss: 2.586528764387199

Epoch: 6| Step: 11
Training loss: 2.569186906251262
Validation loss: 2.581520655966813

Epoch: 6| Step: 12
Training loss: 2.8214108344101714
Validation loss: 2.603510968424372

Epoch: 6| Step: 13
Training loss: 2.1060862582257647
Validation loss: 2.580533143145207

Epoch: 185| Step: 0
Training loss: 3.3025403273125056
Validation loss: 2.6097525567308235

Epoch: 6| Step: 1
Training loss: 2.630420537766798
Validation loss: 2.5748054719238986

Epoch: 6| Step: 2
Training loss: 2.826684574424351
Validation loss: 2.5745312136679424

Epoch: 6| Step: 3
Training loss: 2.7151691049702973
Validation loss: 2.562690749773469

Epoch: 6| Step: 4
Training loss: 3.4393106027044142
Validation loss: 2.5819717183668214

Epoch: 6| Step: 5
Training loss: 2.752612260405383
Validation loss: 2.5925925813410586

Epoch: 6| Step: 6
Training loss: 1.7862462695478563
Validation loss: 2.5609904494237417

Epoch: 6| Step: 7
Training loss: 2.452682746821361
Validation loss: 2.5971905004806506

Epoch: 6| Step: 8
Training loss: 2.8992912084004945
Validation loss: 2.594483579325077

Epoch: 6| Step: 9
Training loss: 2.7226432022811013
Validation loss: 2.5806418619628295

Epoch: 6| Step: 10
Training loss: 2.384024290037902
Validation loss: 2.5952801165092994

Epoch: 6| Step: 11
Training loss: 2.372683951800542
Validation loss: 2.5835468744493317

Epoch: 6| Step: 12
Training loss: 2.272833150651557
Validation loss: 2.582704412599476

Epoch: 6| Step: 13
Training loss: 2.6864197800113137
Validation loss: 2.5804146789997855

Epoch: 186| Step: 0
Training loss: 3.300714941318067
Validation loss: 2.6198197702964277

Epoch: 6| Step: 1
Training loss: 2.125630341332176
Validation loss: 2.5758988649537353

Epoch: 6| Step: 2
Training loss: 2.7235027294477914
Validation loss: 2.5644236271789813

Epoch: 6| Step: 3
Training loss: 2.346057823736852
Validation loss: 2.5925347636413245

Epoch: 6| Step: 4
Training loss: 2.193900417811603
Validation loss: 2.585002611582272

Epoch: 6| Step: 5
Training loss: 2.856955249621499
Validation loss: 2.6248688564951603

Epoch: 6| Step: 6
Training loss: 2.3178586989642525
Validation loss: 2.5811482601807794

Epoch: 6| Step: 7
Training loss: 2.567508083579646
Validation loss: 2.58933925780413

Epoch: 6| Step: 8
Training loss: 2.267404948874143
Validation loss: 2.59043433061702

Epoch: 6| Step: 9
Training loss: 3.1340802830952224
Validation loss: 2.569611376796181

Epoch: 6| Step: 10
Training loss: 3.0638767184164406
Validation loss: 2.558812537878601

Epoch: 6| Step: 11
Training loss: 2.7025349584924485
Validation loss: 2.585491312319479

Epoch: 6| Step: 12
Training loss: 2.700097477884027
Validation loss: 2.5736503323937

Epoch: 6| Step: 13
Training loss: 2.5667449402536806
Validation loss: 2.591629216891957

Epoch: 187| Step: 0
Training loss: 1.7969568648555845
Validation loss: 2.5983414666434137

Epoch: 6| Step: 1
Training loss: 2.7940975442405294
Validation loss: 2.604988207448403

Epoch: 6| Step: 2
Training loss: 3.0230643266350836
Validation loss: 2.5859452862683217

Epoch: 6| Step: 3
Training loss: 3.3282701344253174
Validation loss: 2.5708138881095604

Epoch: 6| Step: 4
Training loss: 2.813664343677013
Validation loss: 2.558982335534972

Epoch: 6| Step: 5
Training loss: 2.196247594025477
Validation loss: 2.5629930049476592

Epoch: 6| Step: 6
Training loss: 2.8322794206996855
Validation loss: 2.580134248534139

Epoch: 6| Step: 7
Training loss: 1.9994841744897693
Validation loss: 2.6022549043179137

Epoch: 6| Step: 8
Training loss: 2.1584149977307883
Validation loss: 2.5854613986084725

Epoch: 6| Step: 9
Training loss: 2.5761755769021923
Validation loss: 2.59425141002145

Epoch: 6| Step: 10
Training loss: 3.2519006306761575
Validation loss: 2.59871591288213

Epoch: 6| Step: 11
Training loss: 2.758754839389499
Validation loss: 2.5910313108162066

Epoch: 6| Step: 12
Training loss: 2.395736714501909
Validation loss: 2.590592727253291

Epoch: 6| Step: 13
Training loss: 3.3113752650885453
Validation loss: 2.5818593816591404

Epoch: 188| Step: 0
Training loss: 3.0546629921791
Validation loss: 2.572973079261407

Epoch: 6| Step: 1
Training loss: 2.081287358495706
Validation loss: 2.5695119165106934

Epoch: 6| Step: 2
Training loss: 2.2114605503966587
Validation loss: 2.586422517753255

Epoch: 6| Step: 3
Training loss: 2.6168367520915723
Validation loss: 2.5869160702721126

Epoch: 6| Step: 4
Training loss: 2.296376699774152
Validation loss: 2.5811231187534336

Epoch: 6| Step: 5
Training loss: 2.4599473687100972
Validation loss: 2.6097039191089824

Epoch: 6| Step: 6
Training loss: 2.151332167497541
Validation loss: 2.5814834576353802

Epoch: 6| Step: 7
Training loss: 3.5068832559986385
Validation loss: 2.6073930461697503

Epoch: 6| Step: 8
Training loss: 2.4888457372118697
Validation loss: 2.5821304782526675

Epoch: 6| Step: 9
Training loss: 3.1733055459203032
Validation loss: 2.567004663599129

Epoch: 6| Step: 10
Training loss: 2.9371764633891853
Validation loss: 2.592297191250169

Epoch: 6| Step: 11
Training loss: 2.8741141903463734
Validation loss: 2.5676253989162365

Epoch: 6| Step: 12
Training loss: 2.6782105048294302
Validation loss: 2.571634961202353

Epoch: 6| Step: 13
Training loss: 2.201775428324533
Validation loss: 2.574170814344329

Epoch: 189| Step: 0
Training loss: 2.886325917854245
Validation loss: 2.6173088779015417

Epoch: 6| Step: 1
Training loss: 2.030182543284622
Validation loss: 2.5851844658007517

Epoch: 6| Step: 2
Training loss: 2.718525669006882
Validation loss: 2.581448086075807

Epoch: 6| Step: 3
Training loss: 2.919320851605582
Validation loss: 2.589388258143283

Epoch: 6| Step: 4
Training loss: 2.8868243000726155
Validation loss: 2.598022006870847

Epoch: 6| Step: 5
Training loss: 2.8949845714520333
Validation loss: 2.573435600816959

Epoch: 6| Step: 6
Training loss: 2.2043135663160585
Validation loss: 2.583764377349219

Epoch: 6| Step: 7
Training loss: 2.93092161506784
Validation loss: 2.5986927358809897

Epoch: 6| Step: 8
Training loss: 2.787362229573426
Validation loss: 2.576597698184202

Epoch: 6| Step: 9
Training loss: 2.9351732494683396
Validation loss: 2.5923812522324168

Epoch: 6| Step: 10
Training loss: 3.2394503518109588
Validation loss: 2.598513890950497

Epoch: 6| Step: 11
Training loss: 2.0966749115717613
Validation loss: 2.5725241462088286

Epoch: 6| Step: 12
Training loss: 2.01646618700421
Validation loss: 2.5775264459080818

Epoch: 6| Step: 13
Training loss: 1.3768573267733624
Validation loss: 2.587300830142984

Epoch: 190| Step: 0
Training loss: 3.6686160945337773
Validation loss: 2.569992981633746

Epoch: 6| Step: 1
Training loss: 2.3380137118744284
Validation loss: 2.601896481920326

Epoch: 6| Step: 2
Training loss: 2.9230050742242013
Validation loss: 2.5683117601995287

Epoch: 6| Step: 3
Training loss: 2.6198097870480024
Validation loss: 2.584379074482918

Epoch: 6| Step: 4
Training loss: 3.458139774160645
Validation loss: 2.565198385481

Epoch: 6| Step: 5
Training loss: 2.2189309489649323
Validation loss: 2.5860900903282635

Epoch: 6| Step: 6
Training loss: 1.9485233878361163
Validation loss: 2.5834819626567107

Epoch: 6| Step: 7
Training loss: 2.750118339766663
Validation loss: 2.5794570926986355

Epoch: 6| Step: 8
Training loss: 1.79636037340103
Validation loss: 2.571588151743227

Epoch: 6| Step: 9
Training loss: 2.5095528241496066
Validation loss: 2.58485546547956

Epoch: 6| Step: 10
Training loss: 3.055822605446768
Validation loss: 2.5566919897366396

Epoch: 6| Step: 11
Training loss: 2.1582210212069093
Validation loss: 2.5700876872171388

Epoch: 6| Step: 12
Training loss: 2.8009009342345537
Validation loss: 2.5727628469518597

Epoch: 6| Step: 13
Training loss: 2.8201172990955463
Validation loss: 2.5794860180794563

Epoch: 191| Step: 0
Training loss: 2.873316728170729
Validation loss: 2.558455456018846

Epoch: 6| Step: 1
Training loss: 2.226703411796561
Validation loss: 2.602907702083042

Epoch: 6| Step: 2
Training loss: 2.2056535860253828
Validation loss: 2.5920050323750936

Epoch: 6| Step: 3
Training loss: 2.3521468238156675
Validation loss: 2.566845955943913

Epoch: 6| Step: 4
Training loss: 2.3531105800961933
Validation loss: 2.5758620407667245

Epoch: 6| Step: 5
Training loss: 3.1666416535309834
Validation loss: 2.5956938618341967

Epoch: 6| Step: 6
Training loss: 2.999544426977067
Validation loss: 2.6235501298763606

Epoch: 6| Step: 7
Training loss: 2.8344598288496354
Validation loss: 2.557361584200427

Epoch: 6| Step: 8
Training loss: 2.7934452103976644
Validation loss: 2.5814088791137193

Epoch: 6| Step: 9
Training loss: 2.9823863808668847
Validation loss: 2.560342402091108

Epoch: 6| Step: 10
Training loss: 2.5499149270919794
Validation loss: 2.5664953583227312

Epoch: 6| Step: 11
Training loss: 2.248404042814835
Validation loss: 2.584130536966868

Epoch: 6| Step: 12
Training loss: 3.0271607177532545
Validation loss: 2.584719287770678

Epoch: 6| Step: 13
Training loss: 2.0328063870923776
Validation loss: 2.5942024402698753

Epoch: 192| Step: 0
Training loss: 2.1896656760119977
Validation loss: 2.5607807891123024

Epoch: 6| Step: 1
Training loss: 3.33235766119009
Validation loss: 2.5921916923535284

Epoch: 6| Step: 2
Training loss: 2.6668432495143897
Validation loss: 2.573340937750754

Epoch: 6| Step: 3
Training loss: 2.4926069618162767
Validation loss: 2.586840943253666

Epoch: 6| Step: 4
Training loss: 2.307428314318825
Validation loss: 2.589368629209025

Epoch: 6| Step: 5
Training loss: 1.938961954145889
Validation loss: 2.605705564224093

Epoch: 6| Step: 6
Training loss: 2.6164921534307806
Validation loss: 2.5851850895588573

Epoch: 6| Step: 7
Training loss: 2.4980667268562247
Validation loss: 2.5667714350343207

Epoch: 6| Step: 8
Training loss: 3.442261605800546
Validation loss: 2.5683669819869897

Epoch: 6| Step: 9
Training loss: 2.509329553860052
Validation loss: 2.608378317686593

Epoch: 6| Step: 10
Training loss: 3.100868128152721
Validation loss: 2.5863522898738593

Epoch: 6| Step: 11
Training loss: 1.8572643064778964
Validation loss: 2.568141456846978

Epoch: 6| Step: 12
Training loss: 2.5758454388577032
Validation loss: 2.6099416682281165

Epoch: 6| Step: 13
Training loss: 3.2903057294905085
Validation loss: 2.562867429148958

Epoch: 193| Step: 0
Training loss: 2.6085933039808507
Validation loss: 2.591410872373033

Epoch: 6| Step: 1
Training loss: 3.3987541665054826
Validation loss: 2.5806068126587625

Epoch: 6| Step: 2
Training loss: 2.941415976702045
Validation loss: 2.596863052318764

Epoch: 6| Step: 3
Training loss: 1.8659051298247908
Validation loss: 2.5868521537767197

Epoch: 6| Step: 4
Training loss: 2.6439819667045366
Validation loss: 2.577057197618593

Epoch: 6| Step: 5
Training loss: 3.3695022167827413
Validation loss: 2.55535641481811

Epoch: 6| Step: 6
Training loss: 2.7795360298765397
Validation loss: 2.595441925418638

Epoch: 6| Step: 7
Training loss: 2.6967721718360917
Validation loss: 2.5943325281588816

Epoch: 6| Step: 8
Training loss: 1.8295818295085684
Validation loss: 2.5781034606053708

Epoch: 6| Step: 9
Training loss: 2.8155133529018563
Validation loss: 2.5644957241452104

Epoch: 6| Step: 10
Training loss: 2.547737396828936
Validation loss: 2.589492746596454

Epoch: 6| Step: 11
Training loss: 2.386287369273123
Validation loss: 2.589500061818296

Epoch: 6| Step: 12
Training loss: 2.332627621151203
Validation loss: 2.583965682267803

Epoch: 6| Step: 13
Training loss: 2.193934975675039
Validation loss: 2.561571979128836

Epoch: 194| Step: 0
Training loss: 2.683753307324501
Validation loss: 2.575861371955001

Epoch: 6| Step: 1
Training loss: 3.174762332461242
Validation loss: 2.6059174261799365

Epoch: 6| Step: 2
Training loss: 3.0747626670491495
Validation loss: 2.5742070183802603

Epoch: 6| Step: 3
Training loss: 2.236891496485048
Validation loss: 2.569781698457687

Epoch: 6| Step: 4
Training loss: 2.624716607191414
Validation loss: 2.5791315743275596

Epoch: 6| Step: 5
Training loss: 2.1205730325957335
Validation loss: 2.577207316093038

Epoch: 6| Step: 6
Training loss: 2.397933857378638
Validation loss: 2.5572975926691566

Epoch: 6| Step: 7
Training loss: 2.8677844847463954
Validation loss: 2.596775554220202

Epoch: 6| Step: 8
Training loss: 2.9447932506584458
Validation loss: 2.5781040279048777

Epoch: 6| Step: 9
Training loss: 2.9150276119959364
Validation loss: 2.5603448652588954

Epoch: 6| Step: 10
Training loss: 2.3916354568341367
Validation loss: 2.557197527130847

Epoch: 6| Step: 11
Training loss: 2.5866149752489034
Validation loss: 2.584613366483821

Epoch: 6| Step: 12
Training loss: 2.3290241732425923
Validation loss: 2.6035492547014334

Epoch: 6| Step: 13
Training loss: 2.739062231904891
Validation loss: 2.582774074631322

Epoch: 195| Step: 0
Training loss: 2.5596552619678357
Validation loss: 2.558890085751427

Epoch: 6| Step: 1
Training loss: 2.5705809293605384
Validation loss: 2.617663907981372

Epoch: 6| Step: 2
Training loss: 2.34044434444865
Validation loss: 2.5850336229868485

Epoch: 6| Step: 3
Training loss: 2.0051955449741015
Validation loss: 2.620152045350703

Epoch: 6| Step: 4
Training loss: 2.869415664733683
Validation loss: 2.6139296115747133

Epoch: 6| Step: 5
Training loss: 2.477245056245964
Validation loss: 2.582124318670258

Epoch: 6| Step: 6
Training loss: 2.8773878381579356
Validation loss: 2.6304045267845497

Epoch: 6| Step: 7
Training loss: 2.6782092585267674
Validation loss: 2.5944990788052866

Epoch: 6| Step: 8
Training loss: 2.1336386621051107
Validation loss: 2.5681046861392742

Epoch: 6| Step: 9
Training loss: 3.7643046616707934
Validation loss: 2.6020021706056946

Epoch: 6| Step: 10
Training loss: 2.995035514302559
Validation loss: 2.5665385698406924

Epoch: 6| Step: 11
Training loss: 2.6495508425114664
Validation loss: 2.5677808226239285

Epoch: 6| Step: 12
Training loss: 2.5288145805858124
Validation loss: 2.585255373935968

Epoch: 6| Step: 13
Training loss: 1.7605157707654224
Validation loss: 2.5867849057664865

Epoch: 196| Step: 0
Training loss: 1.8420635204318183
Validation loss: 2.5787714550745497

Epoch: 6| Step: 1
Training loss: 2.3879191724686084
Validation loss: 2.6134328098175112

Epoch: 6| Step: 2
Training loss: 3.0038791055035747
Validation loss: 2.5808033971252784

Epoch: 6| Step: 3
Training loss: 3.0713000856817287
Validation loss: 2.6001879777154144

Epoch: 6| Step: 4
Training loss: 2.3058142025448873
Validation loss: 2.5886407764161588

Epoch: 6| Step: 5
Training loss: 2.79673050661694
Validation loss: 2.613963311291665

Epoch: 6| Step: 6
Training loss: 2.132922606368332
Validation loss: 2.565073644242943

Epoch: 6| Step: 7
Training loss: 2.150601161036448
Validation loss: 2.5792444388530527

Epoch: 6| Step: 8
Training loss: 3.361574810048446
Validation loss: 2.591302525731592

Epoch: 6| Step: 9
Training loss: 3.04411715382569
Validation loss: 2.589140167805179

Epoch: 6| Step: 10
Training loss: 2.593656239480983
Validation loss: 2.5724311128991757

Epoch: 6| Step: 11
Training loss: 2.5816171749814454
Validation loss: 2.5753601860906055

Epoch: 6| Step: 12
Training loss: 2.6637401217953682
Validation loss: 2.6155744258610447

Epoch: 6| Step: 13
Training loss: 2.9263716587097925
Validation loss: 2.5634499886615467

Epoch: 197| Step: 0
Training loss: 2.5674166149353317
Validation loss: 2.5832541675590837

Epoch: 6| Step: 1
Training loss: 2.4395158697019848
Validation loss: 2.5965573008430725

Epoch: 6| Step: 2
Training loss: 2.743288520116331
Validation loss: 2.5968611761317297

Epoch: 6| Step: 3
Training loss: 2.0687526368645863
Validation loss: 2.5838482119045825

Epoch: 6| Step: 4
Training loss: 2.5765772942279654
Validation loss: 2.5841018029624103

Epoch: 6| Step: 5
Training loss: 2.7196031306147073
Validation loss: 2.587826914855356

Epoch: 6| Step: 6
Training loss: 2.931723901632006
Validation loss: 2.5826724957413427

Epoch: 6| Step: 7
Training loss: 2.9295724261254494
Validation loss: 2.582452451851541

Epoch: 6| Step: 8
Training loss: 2.169640798416372
Validation loss: 2.5867491225636394

Epoch: 6| Step: 9
Training loss: 2.7036345778830944
Validation loss: 2.5830692129116217

Epoch: 6| Step: 10
Training loss: 2.8579952058531672
Validation loss: 2.5971349626912925

Epoch: 6| Step: 11
Training loss: 2.8892825746864426
Validation loss: 2.5973343943316003

Epoch: 6| Step: 12
Training loss: 3.004292754667812
Validation loss: 2.5689333941736585

Epoch: 6| Step: 13
Training loss: 2.260646111113184
Validation loss: 2.5850586053927307

Epoch: 198| Step: 0
Training loss: 3.3693499425466857
Validation loss: 2.613346811669562

Epoch: 6| Step: 1
Training loss: 2.6420148995013277
Validation loss: 2.5462643205589153

Epoch: 6| Step: 2
Training loss: 2.795765235704498
Validation loss: 2.546485902864237

Epoch: 6| Step: 3
Training loss: 3.2638512863987175
Validation loss: 2.5700021060085723

Epoch: 6| Step: 4
Training loss: 2.4696716326619312
Validation loss: 2.5819821001120604

Epoch: 6| Step: 5
Training loss: 2.9380760439697484
Validation loss: 2.5840107952066274

Epoch: 6| Step: 6
Training loss: 2.559806710933243
Validation loss: 2.5739804980063057

Epoch: 6| Step: 7
Training loss: 2.7248895535266118
Validation loss: 2.5799472527828695

Epoch: 6| Step: 8
Training loss: 2.236294115632501
Validation loss: 2.5770573070459135

Epoch: 6| Step: 9
Training loss: 2.509455822774878
Validation loss: 2.587731150540652

Epoch: 6| Step: 10
Training loss: 2.478805537060938
Validation loss: 2.5789268969313515

Epoch: 6| Step: 11
Training loss: 2.226725254468256
Validation loss: 2.553057990301386

Epoch: 6| Step: 12
Training loss: 1.7792195576556824
Validation loss: 2.5911075441834908

Epoch: 6| Step: 13
Training loss: 2.636552729148253
Validation loss: 2.564362176210949

Epoch: 199| Step: 0
Training loss: 2.520714202672079
Validation loss: 2.6086773597108786

Epoch: 6| Step: 1
Training loss: 2.7071297147383673
Validation loss: 2.5680819965481034

Epoch: 6| Step: 2
Training loss: 3.038481904493681
Validation loss: 2.5767876282109317

Epoch: 6| Step: 3
Training loss: 2.080733419007375
Validation loss: 2.582982366606247

Epoch: 6| Step: 4
Training loss: 1.7931610203791861
Validation loss: 2.5829452523510756

Epoch: 6| Step: 5
Training loss: 2.8086387407840316
Validation loss: 2.58905191262586

Epoch: 6| Step: 6
Training loss: 3.213271283728542
Validation loss: 2.564739601201407

Epoch: 6| Step: 7
Training loss: 2.3443465427348538
Validation loss: 2.5771875610597457

Epoch: 6| Step: 8
Training loss: 2.398830915858477
Validation loss: 2.5837297032947353

Epoch: 6| Step: 9
Training loss: 2.1904799735784937
Validation loss: 2.5694543137860144

Epoch: 6| Step: 10
Training loss: 3.017847694775584
Validation loss: 2.5715579521866907

Epoch: 6| Step: 11
Training loss: 2.8099498631630406
Validation loss: 2.5836136798462115

Epoch: 6| Step: 12
Training loss: 3.217744540604314
Validation loss: 2.5931906425012996

Epoch: 6| Step: 13
Training loss: 2.5417636060728572
Validation loss: 2.576083925394677

Epoch: 200| Step: 0
Training loss: 3.360658338401609
Validation loss: 2.593665957679996

Epoch: 6| Step: 1
Training loss: 2.898108121762334
Validation loss: 2.566721268808078

Epoch: 6| Step: 2
Training loss: 2.561810098213582
Validation loss: 2.5717992994709835

Epoch: 6| Step: 3
Training loss: 2.7235332811401043
Validation loss: 2.5599416762211433

Epoch: 6| Step: 4
Training loss: 2.465771290508994
Validation loss: 2.565801680913378

Epoch: 6| Step: 5
Training loss: 2.414962847564067
Validation loss: 2.567673811210067

Epoch: 6| Step: 6
Training loss: 2.4149121020889
Validation loss: 2.5909777158797302

Epoch: 6| Step: 7
Training loss: 2.4315504187585426
Validation loss: 2.6096591029699487

Epoch: 6| Step: 8
Training loss: 2.1698968235221336
Validation loss: 2.5747268690400134

Epoch: 6| Step: 9
Training loss: 2.2730796506111397
Validation loss: 2.5692697207498507

Epoch: 6| Step: 10
Training loss: 3.20404828418825
Validation loss: 2.6248125828777225

Epoch: 6| Step: 11
Training loss: 2.7510320287494956
Validation loss: 2.6052769561162483

Epoch: 6| Step: 12
Training loss: 2.5443503381390853
Validation loss: 2.589792534960216

Epoch: 6| Step: 13
Training loss: 2.5564785433129367
Validation loss: 2.5759908255880775

Testing loss: 2.529386892267466
