Epoch: 1| Step: 0
Training loss: 5.911324501037598
Validation loss: 6.697885610724009

Epoch: 5| Step: 1
Training loss: 5.759018898010254
Validation loss: 6.6939944144218195

Epoch: 5| Step: 2
Training loss: 5.928722858428955
Validation loss: 6.690320066226426

Epoch: 5| Step: 3
Training loss: 6.061278343200684
Validation loss: 6.686413908517489

Epoch: 5| Step: 4
Training loss: 7.363677978515625
Validation loss: 6.681552374234763

Epoch: 5| Step: 5
Training loss: 6.709409236907959
Validation loss: 6.677715645041517

Epoch: 5| Step: 6
Training loss: 7.525460243225098
Validation loss: 6.671702446476106

Epoch: 5| Step: 7
Training loss: 6.758702754974365
Validation loss: 6.667284755296604

Epoch: 5| Step: 8
Training loss: 6.297879219055176
Validation loss: 6.6626641724699285

Epoch: 5| Step: 9
Training loss: 6.2179718017578125
Validation loss: 6.657440662384033

Epoch: 5| Step: 10
Training loss: 6.647613048553467
Validation loss: 6.6505576410601215

Epoch: 2| Step: 0
Training loss: 6.570216178894043
Validation loss: 6.646959027936382

Epoch: 5| Step: 1
Training loss: 6.055016994476318
Validation loss: 6.641785170442315

Epoch: 5| Step: 2
Training loss: 6.307740211486816
Validation loss: 6.637073075899514

Epoch: 5| Step: 3
Training loss: 4.913849830627441
Validation loss: 6.635142613482731

Epoch: 5| Step: 4
Training loss: 7.066699981689453
Validation loss: 6.6292190295393745

Epoch: 5| Step: 5
Training loss: 5.987252712249756
Validation loss: 6.622432221648514

Epoch: 5| Step: 6
Training loss: 6.970786094665527
Validation loss: 6.616803087213988

Epoch: 5| Step: 7
Training loss: 6.578756809234619
Validation loss: 6.613622988423994

Epoch: 5| Step: 8
Training loss: 7.498972415924072
Validation loss: 6.605950704184911

Epoch: 5| Step: 9
Training loss: 6.832298278808594
Validation loss: 6.6014391478671826

Epoch: 5| Step: 10
Training loss: 5.6372761726379395
Validation loss: 6.600646424037154

Epoch: 3| Step: 0
Training loss: 7.392833709716797
Validation loss: 6.593875085153887

Epoch: 5| Step: 1
Training loss: 6.224887371063232
Validation loss: 6.585861026599843

Epoch: 5| Step: 2
Training loss: 6.135965824127197
Validation loss: 6.580951731692078

Epoch: 5| Step: 3
Training loss: 6.814915657043457
Validation loss: 6.574561836898968

Epoch: 5| Step: 4
Training loss: 6.2901787757873535
Validation loss: 6.565035373933854

Epoch: 5| Step: 5
Training loss: 6.284485340118408
Validation loss: 6.563838005065918

Epoch: 5| Step: 6
Training loss: 6.025689601898193
Validation loss: 6.557855390733288

Epoch: 5| Step: 7
Training loss: 6.6334662437438965
Validation loss: 6.552137446659867

Epoch: 5| Step: 8
Training loss: 6.2775750160217285
Validation loss: 6.548077034693892

Epoch: 5| Step: 9
Training loss: 5.947761535644531
Validation loss: 6.541973042231734

Epoch: 5| Step: 10
Training loss: 5.769677639007568
Validation loss: 6.535754306342012

Epoch: 4| Step: 0
Training loss: 6.268223762512207
Validation loss: 6.526611948526034

Epoch: 5| Step: 1
Training loss: 7.071913719177246
Validation loss: 6.5229015196523354

Epoch: 5| Step: 2
Training loss: 5.742038726806641
Validation loss: 6.515599953230991

Epoch: 5| Step: 3
Training loss: 6.025393486022949
Validation loss: 6.509836376354259

Epoch: 5| Step: 4
Training loss: 6.570084571838379
Validation loss: 6.504604539563579

Epoch: 5| Step: 5
Training loss: 6.622110843658447
Validation loss: 6.49747706485051

Epoch: 5| Step: 6
Training loss: 6.801152229309082
Validation loss: 6.490414547663863

Epoch: 5| Step: 7
Training loss: 4.580092906951904
Validation loss: 6.4829209081588255

Epoch: 5| Step: 8
Training loss: 6.926388740539551
Validation loss: 6.477204753506568

Epoch: 5| Step: 9
Training loss: 7.15078592300415
Validation loss: 6.471108974949006

Epoch: 5| Step: 10
Training loss: 5.2087883949279785
Validation loss: 6.465043831897038

Epoch: 5| Step: 0
Training loss: 4.501248359680176
Validation loss: 6.455729294848698

Epoch: 5| Step: 1
Training loss: 5.435169219970703
Validation loss: 6.449213079226914

Epoch: 5| Step: 2
Training loss: 6.5562424659729
Validation loss: 6.442302016801731

Epoch: 5| Step: 3
Training loss: 7.591036319732666
Validation loss: 6.435711676074613

Epoch: 5| Step: 4
Training loss: 5.517673492431641
Validation loss: 6.428825870636971

Epoch: 5| Step: 5
Training loss: 6.5475335121154785
Validation loss: 6.420479533492878

Epoch: 5| Step: 6
Training loss: 6.182304859161377
Validation loss: 6.412823559135519

Epoch: 5| Step: 7
Training loss: 6.464962005615234
Validation loss: 6.404241141452585

Epoch: 5| Step: 8
Training loss: 6.182868957519531
Validation loss: 6.39819331835675

Epoch: 5| Step: 9
Training loss: 7.286067962646484
Validation loss: 6.392200757098454

Epoch: 5| Step: 10
Training loss: 5.927218437194824
Validation loss: 6.383688665205432

Epoch: 6| Step: 0
Training loss: 5.4470744132995605
Validation loss: 6.3751295407613116

Epoch: 5| Step: 1
Training loss: 7.1291985511779785
Validation loss: 6.367773225230556

Epoch: 5| Step: 2
Training loss: 5.339300632476807
Validation loss: 6.357238226039435

Epoch: 5| Step: 3
Training loss: 5.832235813140869
Validation loss: 6.3508425579276135

Epoch: 5| Step: 4
Training loss: 5.996058940887451
Validation loss: 6.343431647105883

Epoch: 5| Step: 5
Training loss: 6.528033256530762
Validation loss: 6.33283277737197

Epoch: 5| Step: 6
Training loss: 6.618231773376465
Validation loss: 6.324749987612488

Epoch: 5| Step: 7
Training loss: 6.318363189697266
Validation loss: 6.317864741048505

Epoch: 5| Step: 8
Training loss: 6.607464790344238
Validation loss: 6.306502511424403

Epoch: 5| Step: 9
Training loss: 5.5898613929748535
Validation loss: 6.296422250809208

Epoch: 5| Step: 10
Training loss: 5.8433003425598145
Validation loss: 6.291201632509949

Epoch: 7| Step: 0
Training loss: 6.598855495452881
Validation loss: 6.282696282991799

Epoch: 5| Step: 1
Training loss: 6.951206207275391
Validation loss: 6.270742867582587

Epoch: 5| Step: 2
Training loss: 6.095730781555176
Validation loss: 6.261399807468537

Epoch: 5| Step: 3
Training loss: 5.821513652801514
Validation loss: 6.255702316120106

Epoch: 5| Step: 4
Training loss: 5.583244323730469
Validation loss: 6.246343884416806

Epoch: 5| Step: 5
Training loss: 5.981385231018066
Validation loss: 6.233982839891987

Epoch: 5| Step: 6
Training loss: 5.014342308044434
Validation loss: 6.230013109022571

Epoch: 5| Step: 7
Training loss: 5.893962383270264
Validation loss: 6.217775975504229

Epoch: 5| Step: 8
Training loss: 5.151350975036621
Validation loss: 6.2085836984777965

Epoch: 5| Step: 9
Training loss: 7.249594211578369
Validation loss: 6.197483811327206

Epoch: 5| Step: 10
Training loss: 5.807356834411621
Validation loss: 6.187430376647621

Epoch: 8| Step: 0
Training loss: 5.639528274536133
Validation loss: 6.175363576540383

Epoch: 5| Step: 1
Training loss: 5.121463775634766
Validation loss: 6.1693622219947075

Epoch: 5| Step: 2
Training loss: 5.489386081695557
Validation loss: 6.161414807842624

Epoch: 5| Step: 3
Training loss: 6.355316162109375
Validation loss: 6.149430033981159

Epoch: 5| Step: 4
Training loss: 4.9239630699157715
Validation loss: 6.138665465898411

Epoch: 5| Step: 5
Training loss: 8.088241577148438
Validation loss: 6.1299108689831145

Epoch: 5| Step: 6
Training loss: 5.830448150634766
Validation loss: 6.120348515049104

Epoch: 5| Step: 7
Training loss: 5.643218517303467
Validation loss: 6.105601474802981

Epoch: 5| Step: 8
Training loss: 6.065682411193848
Validation loss: 6.09914642764676

Epoch: 5| Step: 9
Training loss: 5.329319953918457
Validation loss: 6.08433259430752

Epoch: 5| Step: 10
Training loss: 6.567288875579834
Validation loss: 6.074092547098796

Epoch: 9| Step: 0
Training loss: 4.785843849182129
Validation loss: 6.061319587051227

Epoch: 5| Step: 1
Training loss: 6.145402908325195
Validation loss: 6.052547244615452

Epoch: 5| Step: 2
Training loss: 5.865914821624756
Validation loss: 6.0406569716750935

Epoch: 5| Step: 3
Training loss: 6.929262638092041
Validation loss: 6.030327314971595

Epoch: 5| Step: 4
Training loss: 6.568081855773926
Validation loss: 6.0184705385597805

Epoch: 5| Step: 5
Training loss: 4.901284217834473
Validation loss: 6.00230933261174

Epoch: 5| Step: 6
Training loss: 5.662090301513672
Validation loss: 5.99322626667638

Epoch: 5| Step: 7
Training loss: 6.728749752044678
Validation loss: 5.980193266304591

Epoch: 5| Step: 8
Training loss: 5.904463768005371
Validation loss: 5.965235822944231

Epoch: 5| Step: 9
Training loss: 4.890571594238281
Validation loss: 5.956503914248559

Epoch: 5| Step: 10
Training loss: 4.9887285232543945
Validation loss: 5.941747721805368

Epoch: 10| Step: 0
Training loss: 5.726149559020996
Validation loss: 5.929104158955235

Epoch: 5| Step: 1
Training loss: 4.97625207901001
Validation loss: 5.911659394541094

Epoch: 5| Step: 2
Training loss: 6.311820030212402
Validation loss: 5.902347692879298

Epoch: 5| Step: 3
Training loss: 5.154355525970459
Validation loss: 5.888684929058116

Epoch: 5| Step: 4
Training loss: 5.595372676849365
Validation loss: 5.875030794451313

Epoch: 5| Step: 5
Training loss: 6.2121782302856445
Validation loss: 5.857963685066469

Epoch: 5| Step: 6
Training loss: 6.322837829589844
Validation loss: 5.851662041038595

Epoch: 5| Step: 7
Training loss: 5.705418586730957
Validation loss: 5.828258386222265

Epoch: 5| Step: 8
Training loss: 4.923166751861572
Validation loss: 5.819723221563524

Epoch: 5| Step: 9
Training loss: 5.571507930755615
Validation loss: 5.7974821213753

Epoch: 5| Step: 10
Training loss: 5.363694190979004
Validation loss: 5.7905609582060125

Epoch: 11| Step: 0
Training loss: 6.06124210357666
Validation loss: 5.773476641665223

Epoch: 5| Step: 1
Training loss: 5.907990455627441
Validation loss: 5.7583129995612685

Epoch: 5| Step: 2
Training loss: 6.709619045257568
Validation loss: 5.741928782514346

Epoch: 5| Step: 3
Training loss: 4.97615909576416
Validation loss: 5.729872677915839

Epoch: 5| Step: 4
Training loss: 5.435899257659912
Validation loss: 5.712683867382747

Epoch: 5| Step: 5
Training loss: 6.115633487701416
Validation loss: 5.69610603906775

Epoch: 5| Step: 6
Training loss: 5.16326379776001
Validation loss: 5.68085587921963

Epoch: 5| Step: 7
Training loss: 5.68088960647583
Validation loss: 5.664436960733065

Epoch: 5| Step: 8
Training loss: 5.330173492431641
Validation loss: 5.6482414994188535

Epoch: 5| Step: 9
Training loss: 4.041301727294922
Validation loss: 5.6297674691805275

Epoch: 5| Step: 10
Training loss: 4.405083656311035
Validation loss: 5.610892967511249

Epoch: 12| Step: 0
Training loss: 6.332052230834961
Validation loss: 5.592200233090308

Epoch: 5| Step: 1
Training loss: 5.8352155685424805
Validation loss: 5.576954057139735

Epoch: 5| Step: 2
Training loss: 6.172738075256348
Validation loss: 5.560731923708352

Epoch: 5| Step: 3
Training loss: 5.483809947967529
Validation loss: 5.545417836917344

Epoch: 5| Step: 4
Training loss: 4.691290855407715
Validation loss: 5.531349469256657

Epoch: 5| Step: 5
Training loss: 4.412750244140625
Validation loss: 5.506355588154126

Epoch: 5| Step: 6
Training loss: 5.426161766052246
Validation loss: 5.490502690756193

Epoch: 5| Step: 7
Training loss: 4.870741844177246
Validation loss: 5.469024094202185

Epoch: 5| Step: 8
Training loss: 5.657362937927246
Validation loss: 5.446598396506361

Epoch: 5| Step: 9
Training loss: 4.58395528793335
Validation loss: 5.424085442737867

Epoch: 5| Step: 10
Training loss: 4.21594762802124
Validation loss: 5.404360478924167

Epoch: 13| Step: 0
Training loss: 5.566982269287109
Validation loss: 5.383929560261388

Epoch: 5| Step: 1
Training loss: 5.042580604553223
Validation loss: 5.372642214580249

Epoch: 5| Step: 2
Training loss: 4.6172685623168945
Validation loss: 5.344808445181898

Epoch: 5| Step: 3
Training loss: 4.704165458679199
Validation loss: 5.326147684486964

Epoch: 5| Step: 4
Training loss: 5.699030876159668
Validation loss: 5.307156275677425

Epoch: 5| Step: 5
Training loss: 4.552663326263428
Validation loss: 5.283757179014144

Epoch: 5| Step: 6
Training loss: 5.784951686859131
Validation loss: 5.268013154306719

Epoch: 5| Step: 7
Training loss: 5.241183280944824
Validation loss: 5.24332502324094

Epoch: 5| Step: 8
Training loss: 4.77117395401001
Validation loss: 5.213521408778365

Epoch: 5| Step: 9
Training loss: 4.7976484298706055
Validation loss: 5.1991923342468915

Epoch: 5| Step: 10
Training loss: 4.503643989562988
Validation loss: 5.174077905634398

Epoch: 14| Step: 0
Training loss: 4.933764457702637
Validation loss: 5.1470548568233365

Epoch: 5| Step: 1
Training loss: 5.1324543952941895
Validation loss: 5.126903913354361

Epoch: 5| Step: 2
Training loss: 4.025152206420898
Validation loss: 5.106543953700732

Epoch: 5| Step: 3
Training loss: 4.950837135314941
Validation loss: 5.082041986526981

Epoch: 5| Step: 4
Training loss: 4.33295202255249
Validation loss: 5.0614302337810555

Epoch: 5| Step: 5
Training loss: 5.3818864822387695
Validation loss: 5.032931727747763

Epoch: 5| Step: 6
Training loss: 4.608676910400391
Validation loss: 5.013786531263782

Epoch: 5| Step: 7
Training loss: 3.8103790283203125
Validation loss: 4.985226390182331

Epoch: 5| Step: 8
Training loss: 5.139205455780029
Validation loss: 4.958283044958628

Epoch: 5| Step: 9
Training loss: 4.881232738494873
Validation loss: 4.939018541766751

Epoch: 5| Step: 10
Training loss: 5.462704658508301
Validation loss: 4.907761589173348

Epoch: 15| Step: 0
Training loss: 4.487977027893066
Validation loss: 4.887831159817275

Epoch: 5| Step: 1
Training loss: 4.210315704345703
Validation loss: 4.859193478861163

Epoch: 5| Step: 2
Training loss: 4.673327445983887
Validation loss: 4.838119537599625

Epoch: 5| Step: 3
Training loss: 4.8096513748168945
Validation loss: 4.808822001180341

Epoch: 5| Step: 4
Training loss: 4.733786106109619
Validation loss: 4.778672049122472

Epoch: 5| Step: 5
Training loss: 4.202014923095703
Validation loss: 4.75672705968221

Epoch: 5| Step: 6
Training loss: 4.974165439605713
Validation loss: 4.721093372632098

Epoch: 5| Step: 7
Training loss: 4.118689060211182
Validation loss: 4.701848045472176

Epoch: 5| Step: 8
Training loss: 4.505495071411133
Validation loss: 4.676476360649191

Epoch: 5| Step: 9
Training loss: 4.545899868011475
Validation loss: 4.654020975994808

Epoch: 5| Step: 10
Training loss: 4.123711585998535
Validation loss: 4.61541022023847

Epoch: 16| Step: 0
Training loss: 3.558628797531128
Validation loss: 4.5898960892872145

Epoch: 5| Step: 1
Training loss: 3.2910265922546387
Validation loss: 4.566159848243959

Epoch: 5| Step: 2
Training loss: 4.630702495574951
Validation loss: 4.536663798875706

Epoch: 5| Step: 3
Training loss: 4.6995439529418945
Validation loss: 4.507273715029481

Epoch: 5| Step: 4
Training loss: 4.790465831756592
Validation loss: 4.480229264946394

Epoch: 5| Step: 5
Training loss: 4.295863628387451
Validation loss: 4.443797044856574

Epoch: 5| Step: 6
Training loss: 4.208014488220215
Validation loss: 4.419661014310775

Epoch: 5| Step: 7
Training loss: 3.720341444015503
Validation loss: 4.394413430203674

Epoch: 5| Step: 8
Training loss: 4.399540901184082
Validation loss: 4.356821454981322

Epoch: 5| Step: 9
Training loss: 4.1127028465271
Validation loss: 4.332519269758655

Epoch: 5| Step: 10
Training loss: 4.49778413772583
Validation loss: 4.298653623109223

Epoch: 17| Step: 0
Training loss: 3.588176727294922
Validation loss: 4.271659599837436

Epoch: 5| Step: 1
Training loss: 4.792105674743652
Validation loss: 4.244826947489092

Epoch: 5| Step: 2
Training loss: 2.8463544845581055
Validation loss: 4.195071015306699

Epoch: 5| Step: 3
Training loss: 3.4039406776428223
Validation loss: 4.161611818498181

Epoch: 5| Step: 4
Training loss: 4.128243923187256
Validation loss: 4.13337153773154

Epoch: 5| Step: 5
Training loss: 3.5741443634033203
Validation loss: 4.107486737671719

Epoch: 5| Step: 6
Training loss: 3.865311861038208
Validation loss: 4.077673968448434

Epoch: 5| Step: 7
Training loss: 4.564565658569336
Validation loss: 4.054790122534639

Epoch: 5| Step: 8
Training loss: 3.8589470386505127
Validation loss: 4.008384745608094

Epoch: 5| Step: 9
Training loss: 4.3814191818237305
Validation loss: 3.9705141795578824

Epoch: 5| Step: 10
Training loss: 3.5346925258636475
Validation loss: 3.95073192093962

Epoch: 18| Step: 0
Training loss: 4.068544864654541
Validation loss: 3.9236012684401644

Epoch: 5| Step: 1
Training loss: 2.614691734313965
Validation loss: 3.8963108678017893

Epoch: 5| Step: 2
Training loss: 4.016290664672852
Validation loss: 3.869652278961674

Epoch: 5| Step: 3
Training loss: 4.008145332336426
Validation loss: 3.836245923913935

Epoch: 5| Step: 4
Training loss: 3.2138800621032715
Validation loss: 3.804186749201949

Epoch: 5| Step: 5
Training loss: 3.6063873767852783
Validation loss: 3.7721932318902787

Epoch: 5| Step: 6
Training loss: 4.339081764221191
Validation loss: 3.7490163362154396

Epoch: 5| Step: 7
Training loss: 4.233866214752197
Validation loss: 3.7128867897936093

Epoch: 5| Step: 8
Training loss: 3.6544528007507324
Validation loss: 3.67609162997174

Epoch: 5| Step: 9
Training loss: 2.451779365539551
Validation loss: 3.6529326900359123

Epoch: 5| Step: 10
Training loss: 3.1613996028900146
Validation loss: 3.6221471960826586

Epoch: 19| Step: 0
Training loss: 2.682126998901367
Validation loss: 3.6079763238148024

Epoch: 5| Step: 1
Training loss: 3.507408857345581
Validation loss: 3.5669587222478722

Epoch: 5| Step: 2
Training loss: 3.117824077606201
Validation loss: 3.5386930793844242

Epoch: 5| Step: 3
Training loss: 3.605609178543091
Validation loss: 3.508107898055866

Epoch: 5| Step: 4
Training loss: 3.1981306076049805
Validation loss: 3.471721810679282

Epoch: 5| Step: 5
Training loss: 3.3861308097839355
Validation loss: 3.447729851609917

Epoch: 5| Step: 6
Training loss: 3.644991636276245
Validation loss: 3.4248451878947597

Epoch: 5| Step: 7
Training loss: 3.1757607460021973
Validation loss: 3.3877761415255967

Epoch: 5| Step: 8
Training loss: 3.218292236328125
Validation loss: 3.3527953240179245

Epoch: 5| Step: 9
Training loss: 2.8971760272979736
Validation loss: 3.3344587766995994

Epoch: 5| Step: 10
Training loss: 4.035557746887207
Validation loss: 3.300271846914804

Epoch: 20| Step: 0
Training loss: 3.759326457977295
Validation loss: 3.278269147360197

Epoch: 5| Step: 1
Training loss: 3.279946804046631
Validation loss: 3.247903577743038

Epoch: 5| Step: 2
Training loss: 3.2617321014404297
Validation loss: 3.213013736150598

Epoch: 5| Step: 3
Training loss: 2.482389450073242
Validation loss: 3.161416943355273

Epoch: 5| Step: 4
Training loss: 3.0081450939178467
Validation loss: 3.1528915769310406

Epoch: 5| Step: 5
Training loss: 3.2443840503692627
Validation loss: 3.1293497829027075

Epoch: 5| Step: 6
Training loss: 2.186882257461548
Validation loss: 3.1151834841697448

Epoch: 5| Step: 7
Training loss: 3.8477752208709717
Validation loss: 3.0633410689651326

Epoch: 5| Step: 8
Training loss: 3.322793960571289
Validation loss: 3.012761208318895

Epoch: 5| Step: 9
Training loss: 2.937832832336426
Validation loss: 2.9869887059734714

Epoch: 5| Step: 10
Training loss: 2.4459564685821533
Validation loss: 2.9752527359993226

Epoch: 21| Step: 0
Training loss: 3.470402479171753
Validation loss: 2.955895834071662

Epoch: 5| Step: 1
Training loss: 3.7771308422088623
Validation loss: 2.918488863975771

Epoch: 5| Step: 2
Training loss: 2.77327299118042
Validation loss: 2.883099050932033

Epoch: 5| Step: 3
Training loss: 2.104971170425415
Validation loss: 2.871843227776148

Epoch: 5| Step: 4
Training loss: 2.4774067401885986
Validation loss: 2.8743725617726645

Epoch: 5| Step: 5
Training loss: 2.977212905883789
Validation loss: 2.843029837454519

Epoch: 5| Step: 6
Training loss: 2.5855019092559814
Validation loss: 2.8329401631509104

Epoch: 5| Step: 7
Training loss: 2.791433334350586
Validation loss: 2.8024938080900457

Epoch: 5| Step: 8
Training loss: 3.458705186843872
Validation loss: 2.7987505569252917

Epoch: 5| Step: 9
Training loss: 2.7351672649383545
Validation loss: 2.790969089795184

Epoch: 5| Step: 10
Training loss: 2.3787240982055664
Validation loss: 2.7251466679316696

Epoch: 22| Step: 0
Training loss: 2.9012880325317383
Validation loss: 2.750189940134684

Epoch: 5| Step: 1
Training loss: 2.995004892349243
Validation loss: 2.697623268250496

Epoch: 5| Step: 2
Training loss: 2.8807382583618164
Validation loss: 2.6931860703293995

Epoch: 5| Step: 3
Training loss: 2.28483510017395
Validation loss: 2.672348786425847

Epoch: 5| Step: 4
Training loss: 3.087602138519287
Validation loss: 2.6301733627114245

Epoch: 5| Step: 5
Training loss: 2.570526361465454
Validation loss: 2.6317922261453446

Epoch: 5| Step: 6
Training loss: 2.545788288116455
Validation loss: 2.625269523230932

Epoch: 5| Step: 7
Training loss: 3.256817579269409
Validation loss: 2.5835763844110633

Epoch: 5| Step: 8
Training loss: 2.7707204818725586
Validation loss: 2.565838506144862

Epoch: 5| Step: 9
Training loss: 2.3389649391174316
Validation loss: 2.535489841174054

Epoch: 5| Step: 10
Training loss: 2.202916145324707
Validation loss: 2.5298473270990516

Epoch: 23| Step: 0
Training loss: 2.436694860458374
Validation loss: 2.5205639126480266

Epoch: 5| Step: 1
Training loss: 2.5549936294555664
Validation loss: 2.5347714603588147

Epoch: 5| Step: 2
Training loss: 2.593393087387085
Validation loss: 2.502500080293225

Epoch: 5| Step: 3
Training loss: 2.95353102684021
Validation loss: 2.4697709468103226

Epoch: 5| Step: 4
Training loss: 2.825885534286499
Validation loss: 2.4634125565969818

Epoch: 5| Step: 5
Training loss: 2.8093924522399902
Validation loss: 2.461118613519976

Epoch: 5| Step: 6
Training loss: 2.836447238922119
Validation loss: 2.4513928992773897

Epoch: 5| Step: 7
Training loss: 2.3840126991271973
Validation loss: 2.444547745489305

Epoch: 5| Step: 8
Training loss: 1.9696452617645264
Validation loss: 2.4266100416901293

Epoch: 5| Step: 9
Training loss: 2.142712116241455
Validation loss: 2.385149874994832

Epoch: 5| Step: 10
Training loss: 3.11674427986145
Validation loss: 2.3816454102916103

Epoch: 24| Step: 0
Training loss: 1.797512412071228
Validation loss: 2.373287877728862

Epoch: 5| Step: 1
Training loss: 2.4735355377197266
Validation loss: 2.3790861714270806

Epoch: 5| Step: 2
Training loss: 2.8397815227508545
Validation loss: 2.3311571510889197

Epoch: 5| Step: 3
Training loss: 1.6967649459838867
Validation loss: 2.3361585832411245

Epoch: 5| Step: 4
Training loss: 2.97759747505188
Validation loss: 2.3472886444419943

Epoch: 5| Step: 5
Training loss: 2.548971652984619
Validation loss: 2.3265598935465657

Epoch: 5| Step: 6
Training loss: 2.758575916290283
Validation loss: 2.2990220028867006

Epoch: 5| Step: 7
Training loss: 3.2151007652282715
Validation loss: 2.2954584167849634

Epoch: 5| Step: 8
Training loss: 2.268862247467041
Validation loss: 2.2951849942566245

Epoch: 5| Step: 9
Training loss: 2.688971757888794
Validation loss: 2.297657456449283

Epoch: 5| Step: 10
Training loss: 2.545032024383545
Validation loss: 2.282177904600738

Epoch: 25| Step: 0
Training loss: 2.2525277137756348
Validation loss: 2.2645560169732697

Epoch: 5| Step: 1
Training loss: 2.8331875801086426
Validation loss: 2.2701400428689937

Epoch: 5| Step: 2
Training loss: 1.936396837234497
Validation loss: 2.2777073101330827

Epoch: 5| Step: 3
Training loss: 2.7854342460632324
Validation loss: 2.2867873663543374

Epoch: 5| Step: 4
Training loss: 2.6825013160705566
Validation loss: 2.2581443555893435

Epoch: 5| Step: 5
Training loss: 2.6233253479003906
Validation loss: 2.2644955573543424

Epoch: 5| Step: 6
Training loss: 2.8713557720184326
Validation loss: 2.239630086447603

Epoch: 5| Step: 7
Training loss: 2.1428208351135254
Validation loss: 2.251067505087904

Epoch: 5| Step: 8
Training loss: 3.1719846725463867
Validation loss: 2.2478609008173787

Epoch: 5| Step: 9
Training loss: 2.245798349380493
Validation loss: 2.231919611653974

Epoch: 5| Step: 10
Training loss: 1.5689972639083862
Validation loss: 2.219893035068307

Epoch: 26| Step: 0
Training loss: 2.7299551963806152
Validation loss: 2.210940553295997

Epoch: 5| Step: 1
Training loss: 2.692033529281616
Validation loss: 2.224877998393069

Epoch: 5| Step: 2
Training loss: 2.5246927738189697
Validation loss: 2.214398628921919

Epoch: 5| Step: 3
Training loss: 2.388530731201172
Validation loss: 2.1937566623892835

Epoch: 5| Step: 4
Training loss: 2.3944907188415527
Validation loss: 2.1935777151456444

Epoch: 5| Step: 5
Training loss: 2.5946619510650635
Validation loss: 2.20431105039453

Epoch: 5| Step: 6
Training loss: 2.2746665477752686
Validation loss: 2.181008264582644

Epoch: 5| Step: 7
Training loss: 2.459313154220581
Validation loss: 2.1783267003233715

Epoch: 5| Step: 8
Training loss: 2.0684685707092285
Validation loss: 2.1787063883196924

Epoch: 5| Step: 9
Training loss: 2.5452427864074707
Validation loss: 2.2051456974398707

Epoch: 5| Step: 10
Training loss: 2.2652156352996826
Validation loss: 2.1886778416172152

Epoch: 27| Step: 0
Training loss: 2.6029224395751953
Validation loss: 2.1696279356556554

Epoch: 5| Step: 1
Training loss: 2.1520700454711914
Validation loss: 2.187122074506616

Epoch: 5| Step: 2
Training loss: 2.708085536956787
Validation loss: 2.1993842419757637

Epoch: 5| Step: 3
Training loss: 2.6806540489196777
Validation loss: 2.1748877750929965

Epoch: 5| Step: 4
Training loss: 2.6215219497680664
Validation loss: 2.1552154428215435

Epoch: 5| Step: 5
Training loss: 2.6193559169769287
Validation loss: 2.1781538327534995

Epoch: 5| Step: 6
Training loss: 2.4361865520477295
Validation loss: 2.172853144266272

Epoch: 5| Step: 7
Training loss: 2.0639097690582275
Validation loss: 2.148238907578171

Epoch: 5| Step: 8
Training loss: 2.684138774871826
Validation loss: 2.193294455928187

Epoch: 5| Step: 9
Training loss: 1.2992112636566162
Validation loss: 2.1670574885542675

Epoch: 5| Step: 10
Training loss: 3.2063004970550537
Validation loss: 2.191205865593367

Epoch: 28| Step: 0
Training loss: 2.75801157951355
Validation loss: 2.1579214988216275

Epoch: 5| Step: 1
Training loss: 2.5654995441436768
Validation loss: 2.17827501860998

Epoch: 5| Step: 2
Training loss: 1.5815041065216064
Validation loss: 2.184205362873693

Epoch: 5| Step: 3
Training loss: 2.5353314876556396
Validation loss: 2.159542050412906

Epoch: 5| Step: 4
Training loss: 2.5204975605010986
Validation loss: 2.155055994628578

Epoch: 5| Step: 5
Training loss: 3.0304694175720215
Validation loss: 2.191079085873019

Epoch: 5| Step: 6
Training loss: 3.2057747840881348
Validation loss: 2.1707547480060208

Epoch: 5| Step: 7
Training loss: 2.418865203857422
Validation loss: 2.1722330995785293

Epoch: 5| Step: 8
Training loss: 2.0728554725646973
Validation loss: 2.153983111022621

Epoch: 5| Step: 9
Training loss: 2.4710588455200195
Validation loss: 2.1715603002937893

Epoch: 5| Step: 10
Training loss: 1.7421468496322632
Validation loss: 2.1642605745664207

Epoch: 29| Step: 0
Training loss: 1.601057767868042
Validation loss: 2.169662134621733

Epoch: 5| Step: 1
Training loss: 2.178654909133911
Validation loss: 2.1534459385820615

Epoch: 5| Step: 2
Training loss: 2.6842100620269775
Validation loss: 2.163446790428572

Epoch: 5| Step: 3
Training loss: 2.968956470489502
Validation loss: 2.1559493798081593

Epoch: 5| Step: 4
Training loss: 2.2337772846221924
Validation loss: 2.1840232495338685

Epoch: 5| Step: 5
Training loss: 2.591118335723877
Validation loss: 2.1509427639745895

Epoch: 5| Step: 6
Training loss: 2.2733519077301025
Validation loss: 2.1470964313835226

Epoch: 5| Step: 7
Training loss: 2.605215311050415
Validation loss: 2.1683069531635573

Epoch: 5| Step: 8
Training loss: 2.504420042037964
Validation loss: 2.1720380577989804

Epoch: 5| Step: 9
Training loss: 2.0451531410217285
Validation loss: 2.175140301386515

Epoch: 5| Step: 10
Training loss: 3.2061002254486084
Validation loss: 2.145387617490625

Epoch: 30| Step: 0
Training loss: 2.5512309074401855
Validation loss: 2.181856511741556

Epoch: 5| Step: 1
Training loss: 2.964789390563965
Validation loss: 2.1953874147066506

Epoch: 5| Step: 2
Training loss: 2.211385726928711
Validation loss: 2.19734441080401

Epoch: 5| Step: 3
Training loss: 1.927737832069397
Validation loss: 2.175091323032174

Epoch: 5| Step: 4
Training loss: 2.1260104179382324
Validation loss: 2.1658399246072255

Epoch: 5| Step: 5
Training loss: 2.4688446521759033
Validation loss: 2.1673040133650585

Epoch: 5| Step: 6
Training loss: 2.470567226409912
Validation loss: 2.1626290223931752

Epoch: 5| Step: 7
Training loss: 2.6747913360595703
Validation loss: 2.174610766031409

Epoch: 5| Step: 8
Training loss: 2.50260591506958
Validation loss: 2.177326912521034

Epoch: 5| Step: 9
Training loss: 2.694868803024292
Validation loss: 2.1921329882837113

Epoch: 5| Step: 10
Training loss: 2.1880850791931152
Validation loss: 2.16182961515201

Epoch: 31| Step: 0
Training loss: 2.093024492263794
Validation loss: 2.1662199830496185

Epoch: 5| Step: 1
Training loss: 2.7069544792175293
Validation loss: 2.1886559763262348

Epoch: 5| Step: 2
Training loss: 1.7529983520507812
Validation loss: 2.163431285530008

Epoch: 5| Step: 3
Training loss: 2.670243263244629
Validation loss: 2.1494694371377268

Epoch: 5| Step: 4
Training loss: 2.782334804534912
Validation loss: 2.1695908961757535

Epoch: 5| Step: 5
Training loss: 3.0224831104278564
Validation loss: 2.1909396263860885

Epoch: 5| Step: 6
Training loss: 2.5842483043670654
Validation loss: 2.192270391730852

Epoch: 5| Step: 7
Training loss: 2.1760075092315674
Validation loss: 2.173181208231116

Epoch: 5| Step: 8
Training loss: 1.9869906902313232
Validation loss: 2.1804717304886028

Epoch: 5| Step: 9
Training loss: 2.9297890663146973
Validation loss: 2.2000054518381753

Epoch: 5| Step: 10
Training loss: 2.083857297897339
Validation loss: 2.1582635730825444

Epoch: 32| Step: 0
Training loss: 2.1491811275482178
Validation loss: 2.1692255568760697

Epoch: 5| Step: 1
Training loss: 2.5378377437591553
Validation loss: 2.167374223791143

Epoch: 5| Step: 2
Training loss: 1.958122968673706
Validation loss: 2.2115707115460466

Epoch: 5| Step: 3
Training loss: 2.2465081214904785
Validation loss: 2.1864490509033203

Epoch: 5| Step: 4
Training loss: 2.8260397911071777
Validation loss: 2.1891690736175864

Epoch: 5| Step: 5
Training loss: 3.128390312194824
Validation loss: 2.1782556041594474

Epoch: 5| Step: 6
Training loss: 1.7116107940673828
Validation loss: 2.1863107937638477

Epoch: 5| Step: 7
Training loss: 2.313538074493408
Validation loss: 2.1406485137119087

Epoch: 5| Step: 8
Training loss: 2.4989349842071533
Validation loss: 2.1864518478352535

Epoch: 5| Step: 9
Training loss: 2.478970766067505
Validation loss: 2.1642879286120014

Epoch: 5| Step: 10
Training loss: 2.8073999881744385
Validation loss: 2.1879638971820956

Epoch: 33| Step: 0
Training loss: 2.473846912384033
Validation loss: 2.193578322728475

Epoch: 5| Step: 1
Training loss: 2.018704891204834
Validation loss: 2.1682671782790974

Epoch: 5| Step: 2
Training loss: 2.222668409347534
Validation loss: 2.15692868668546

Epoch: 5| Step: 3
Training loss: 2.437748432159424
Validation loss: 2.1489840348561606

Epoch: 5| Step: 4
Training loss: 3.171079158782959
Validation loss: 2.1428451486813125

Epoch: 5| Step: 5
Training loss: 2.9106976985931396
Validation loss: 2.1779745676184215

Epoch: 5| Step: 6
Training loss: 2.218808650970459
Validation loss: 2.143570815363238

Epoch: 5| Step: 7
Training loss: 2.1966195106506348
Validation loss: 2.169280211130778

Epoch: 5| Step: 8
Training loss: 2.6209118366241455
Validation loss: 2.184757340338922

Epoch: 5| Step: 9
Training loss: 2.070462226867676
Validation loss: 2.1548150149724816

Epoch: 5| Step: 10
Training loss: 2.261038064956665
Validation loss: 2.1452293626723753

Epoch: 34| Step: 0
Training loss: 2.500441551208496
Validation loss: 2.157801705022012

Epoch: 5| Step: 1
Training loss: 2.2698001861572266
Validation loss: 2.1560806715360252

Epoch: 5| Step: 2
Training loss: 2.564207077026367
Validation loss: 2.164954182922199

Epoch: 5| Step: 3
Training loss: 2.049893379211426
Validation loss: 2.1641352484303136

Epoch: 5| Step: 4
Training loss: 2.2408711910247803
Validation loss: 2.159057596678375

Epoch: 5| Step: 5
Training loss: 2.5307655334472656
Validation loss: 2.1748285370488323

Epoch: 5| Step: 6
Training loss: 1.7157657146453857
Validation loss: 2.174772822728721

Epoch: 5| Step: 7
Training loss: 2.4604880809783936
Validation loss: 2.189503159574283

Epoch: 5| Step: 8
Training loss: 3.336360216140747
Validation loss: 2.1823015712922618

Epoch: 5| Step: 9
Training loss: 2.0556728839874268
Validation loss: 2.1882364749908447

Epoch: 5| Step: 10
Training loss: 2.8912603855133057
Validation loss: 2.174269445480839

Epoch: 35| Step: 0
Training loss: 2.4217476844787598
Validation loss: 2.1880376185140302

Epoch: 5| Step: 1
Training loss: 2.5672478675842285
Validation loss: 2.1773501647415983

Epoch: 5| Step: 2
Training loss: 3.136509656906128
Validation loss: 2.180571540709465

Epoch: 5| Step: 3
Training loss: 2.18953537940979
Validation loss: 2.1759076297924085

Epoch: 5| Step: 4
Training loss: 2.031862735748291
Validation loss: 2.164465308189392

Epoch: 5| Step: 5
Training loss: 2.5960893630981445
Validation loss: 2.177866546056604

Epoch: 5| Step: 6
Training loss: 2.6751620769500732
Validation loss: 2.1567774203515824

Epoch: 5| Step: 7
Training loss: 2.4637560844421387
Validation loss: 2.1558023139994633

Epoch: 5| Step: 8
Training loss: 2.1058876514434814
Validation loss: 2.165074788114076

Epoch: 5| Step: 9
Training loss: 2.020352363586426
Validation loss: 2.1885388487128803

Epoch: 5| Step: 10
Training loss: 2.21492862701416
Validation loss: 2.1537607767248668

Epoch: 36| Step: 0
Training loss: 2.007664442062378
Validation loss: 2.1599820249824115

Epoch: 5| Step: 1
Training loss: 2.820077896118164
Validation loss: 2.1643990521789878

Epoch: 5| Step: 2
Training loss: 2.550781726837158
Validation loss: 2.1503100625930296

Epoch: 5| Step: 3
Training loss: 1.787362813949585
Validation loss: 2.1453381097444923

Epoch: 5| Step: 4
Training loss: 2.473656177520752
Validation loss: 2.1575832225943126

Epoch: 5| Step: 5
Training loss: 2.4541163444519043
Validation loss: 2.148230360400292

Epoch: 5| Step: 6
Training loss: 2.1340994834899902
Validation loss: 2.1434797702297086

Epoch: 5| Step: 7
Training loss: 2.7476069927215576
Validation loss: 2.153077830550491

Epoch: 5| Step: 8
Training loss: 2.9288439750671387
Validation loss: 2.153478266090475

Epoch: 5| Step: 9
Training loss: 2.4730489253997803
Validation loss: 2.122697146989966

Epoch: 5| Step: 10
Training loss: 2.1389636993408203
Validation loss: 2.145253845440444

Epoch: 37| Step: 0
Training loss: 3.0202345848083496
Validation loss: 2.1322867972876436

Epoch: 5| Step: 1
Training loss: 1.8788211345672607
Validation loss: 2.167459871179314

Epoch: 5| Step: 2
Training loss: 2.3692526817321777
Validation loss: 2.1542090139081402

Epoch: 5| Step: 3
Training loss: 2.632265090942383
Validation loss: 2.163712147743471

Epoch: 5| Step: 4
Training loss: 2.355926513671875
Validation loss: 2.1512722148690173

Epoch: 5| Step: 5
Training loss: 1.5100667476654053
Validation loss: 2.162159066046438

Epoch: 5| Step: 6
Training loss: 3.439340591430664
Validation loss: 2.143654433629846

Epoch: 5| Step: 7
Training loss: 2.3825745582580566
Validation loss: 2.1526429806986163

Epoch: 5| Step: 8
Training loss: 2.4083094596862793
Validation loss: 2.152665276681223

Epoch: 5| Step: 9
Training loss: 2.3775196075439453
Validation loss: 2.1466995849404285

Epoch: 5| Step: 10
Training loss: 1.9060828685760498
Validation loss: 2.1632925541170183

Epoch: 38| Step: 0
Training loss: 1.9824798107147217
Validation loss: 2.1538769686093895

Epoch: 5| Step: 1
Training loss: 2.7482995986938477
Validation loss: 2.1708101957075057

Epoch: 5| Step: 2
Training loss: 2.746476650238037
Validation loss: 2.1850411635573193

Epoch: 5| Step: 3
Training loss: 2.563565492630005
Validation loss: 2.16466700133457

Epoch: 5| Step: 4
Training loss: 2.681997537612915
Validation loss: 2.1585821310679116

Epoch: 5| Step: 5
Training loss: 2.7857041358947754
Validation loss: 2.1727955033702235

Epoch: 5| Step: 6
Training loss: 2.421445369720459
Validation loss: 2.169001410084386

Epoch: 5| Step: 7
Training loss: 2.267177104949951
Validation loss: 2.154838180029264

Epoch: 5| Step: 8
Training loss: 3.16481351852417
Validation loss: 2.140462380583568

Epoch: 5| Step: 9
Training loss: 1.3786391019821167
Validation loss: 2.1552087209557973

Epoch: 5| Step: 10
Training loss: 1.4377933740615845
Validation loss: 2.1411978737000497

Epoch: 39| Step: 0
Training loss: 2.5543572902679443
Validation loss: 2.1606406857890468

Epoch: 5| Step: 1
Training loss: 2.208892345428467
Validation loss: 2.136598038417037

Epoch: 5| Step: 2
Training loss: 2.699018955230713
Validation loss: 2.167992530330535

Epoch: 5| Step: 3
Training loss: 2.1010947227478027
Validation loss: 2.1435647702986196

Epoch: 5| Step: 4
Training loss: 1.6451442241668701
Validation loss: 2.131673664175054

Epoch: 5| Step: 5
Training loss: 2.199709892272949
Validation loss: 2.147793581408839

Epoch: 5| Step: 6
Training loss: 3.233867645263672
Validation loss: 2.1203912381202943

Epoch: 5| Step: 7
Training loss: 2.3668017387390137
Validation loss: 2.157952880346647

Epoch: 5| Step: 8
Training loss: 3.0819220542907715
Validation loss: 2.126615462764617

Epoch: 5| Step: 9
Training loss: 2.642643928527832
Validation loss: 2.164510396219069

Epoch: 5| Step: 10
Training loss: 1.3683265447616577
Validation loss: 2.1347077661944973

Epoch: 40| Step: 0
Training loss: 2.093770742416382
Validation loss: 2.1408941104847896

Epoch: 5| Step: 1
Training loss: 1.8516327142715454
Validation loss: 2.1509202885371383

Epoch: 5| Step: 2
Training loss: 2.819448471069336
Validation loss: 2.1441484035984164

Epoch: 5| Step: 3
Training loss: 2.8117401599884033
Validation loss: 2.1306191093178204

Epoch: 5| Step: 4
Training loss: 2.8570666313171387
Validation loss: 2.1502541111361597

Epoch: 5| Step: 5
Training loss: 2.3542914390563965
Validation loss: 2.137460716309086

Epoch: 5| Step: 6
Training loss: 2.4028372764587402
Validation loss: 2.132945570894467

Epoch: 5| Step: 7
Training loss: 1.625353455543518
Validation loss: 2.1317903944241103

Epoch: 5| Step: 8
Training loss: 2.2852745056152344
Validation loss: 2.109170162549583

Epoch: 5| Step: 9
Training loss: 2.5869388580322266
Validation loss: 2.1115537356304865

Epoch: 5| Step: 10
Training loss: 2.475367784500122
Validation loss: 2.1493402732315885

Epoch: 41| Step: 0
Training loss: 2.0954291820526123
Validation loss: 2.1418155521474858

Epoch: 5| Step: 1
Training loss: 2.584578037261963
Validation loss: 2.1272090019718295

Epoch: 5| Step: 2
Training loss: 1.9696937799453735
Validation loss: 2.1348277048398088

Epoch: 5| Step: 3
Training loss: 2.8236851692199707
Validation loss: 2.1501105421332904

Epoch: 5| Step: 4
Training loss: 2.3931498527526855
Validation loss: 2.1566334232207267

Epoch: 5| Step: 5
Training loss: 2.0717411041259766
Validation loss: 2.140383328160932

Epoch: 5| Step: 6
Training loss: 2.420947313308716
Validation loss: 2.166707693889577

Epoch: 5| Step: 7
Training loss: 2.6837286949157715
Validation loss: 2.1470093240020094

Epoch: 5| Step: 8
Training loss: 2.217385768890381
Validation loss: 2.166451690017536

Epoch: 5| Step: 9
Training loss: 2.7486965656280518
Validation loss: 2.1700686382991012

Epoch: 5| Step: 10
Training loss: 2.10256290435791
Validation loss: 2.179245679609237

Epoch: 42| Step: 0
Training loss: 2.330876111984253
Validation loss: 2.1653051863434496

Epoch: 5| Step: 1
Training loss: 2.1233911514282227
Validation loss: 2.1730386634026804

Epoch: 5| Step: 2
Training loss: 1.8986552953720093
Validation loss: 2.16971347665274

Epoch: 5| Step: 3
Training loss: 1.9688808917999268
Validation loss: 2.1791362365086875

Epoch: 5| Step: 4
Training loss: 2.6278305053710938
Validation loss: 2.1633171266125095

Epoch: 5| Step: 5
Training loss: 3.8256869316101074
Validation loss: 2.192983337627944

Epoch: 5| Step: 6
Training loss: 1.8703358173370361
Validation loss: 2.180385387071999

Epoch: 5| Step: 7
Training loss: 2.784522771835327
Validation loss: 2.187472915136686

Epoch: 5| Step: 8
Training loss: 1.8792848587036133
Validation loss: 2.184286455954275

Epoch: 5| Step: 9
Training loss: 2.6122243404388428
Validation loss: 2.185966193035085

Epoch: 5| Step: 10
Training loss: 2.1422855854034424
Validation loss: 2.1570061201690347

Epoch: 43| Step: 0
Training loss: 1.5973984003067017
Validation loss: 2.1716670143988823

Epoch: 5| Step: 1
Training loss: 2.2774415016174316
Validation loss: 2.167582804156888

Epoch: 5| Step: 2
Training loss: 2.066113233566284
Validation loss: 2.170711173806139

Epoch: 5| Step: 3
Training loss: 2.825437068939209
Validation loss: 2.1714797404504593

Epoch: 5| Step: 4
Training loss: 2.678581714630127
Validation loss: 2.147815546681804

Epoch: 5| Step: 5
Training loss: 1.8810827732086182
Validation loss: 2.151396143820978

Epoch: 5| Step: 6
Training loss: 2.4965829849243164
Validation loss: 2.1420953530137257

Epoch: 5| Step: 7
Training loss: 2.174354314804077
Validation loss: 2.14538751622682

Epoch: 5| Step: 8
Training loss: 2.6500093936920166
Validation loss: 2.125593921189667

Epoch: 5| Step: 9
Training loss: 3.3034865856170654
Validation loss: 2.1141946777220695

Epoch: 5| Step: 10
Training loss: 2.2440237998962402
Validation loss: 2.1622649982411373

Epoch: 44| Step: 0
Training loss: 2.2410690784454346
Validation loss: 2.121986304560015

Epoch: 5| Step: 1
Training loss: 1.9838354587554932
Validation loss: 2.142512522717958

Epoch: 5| Step: 2
Training loss: 1.7431695461273193
Validation loss: 2.1199485460917153

Epoch: 5| Step: 3
Training loss: 2.747802257537842
Validation loss: 2.1377438063262613

Epoch: 5| Step: 4
Training loss: 2.5209403038024902
Validation loss: 2.1203737079456286

Epoch: 5| Step: 5
Training loss: 2.7787177562713623
Validation loss: 2.1518499723044773

Epoch: 5| Step: 6
Training loss: 2.6075010299682617
Validation loss: 2.1452147012115805

Epoch: 5| Step: 7
Training loss: 3.3173553943634033
Validation loss: 2.114752282378494

Epoch: 5| Step: 8
Training loss: 2.0300896167755127
Validation loss: 2.16172271133751

Epoch: 5| Step: 9
Training loss: 1.948225975036621
Validation loss: 2.1401947288103003

Epoch: 5| Step: 10
Training loss: 2.348259449005127
Validation loss: 2.1290134652968375

Epoch: 45| Step: 0
Training loss: 2.666074275970459
Validation loss: 2.1348248707350863

Epoch: 5| Step: 1
Training loss: 1.768240213394165
Validation loss: 2.1300215259675057

Epoch: 5| Step: 2
Training loss: 1.7684504985809326
Validation loss: 2.1489954712570354

Epoch: 5| Step: 3
Training loss: 2.3193612098693848
Validation loss: 2.1373923376042354

Epoch: 5| Step: 4
Training loss: 2.4815468788146973
Validation loss: 2.113378814471665

Epoch: 5| Step: 5
Training loss: 2.6149094104766846
Validation loss: 2.12948799902393

Epoch: 5| Step: 6
Training loss: 2.2995638847351074
Validation loss: 2.1250412746142318

Epoch: 5| Step: 7
Training loss: 2.2666964530944824
Validation loss: 2.134899708532518

Epoch: 5| Step: 8
Training loss: 2.558783769607544
Validation loss: 2.149398931892969

Epoch: 5| Step: 9
Training loss: 2.7870278358459473
Validation loss: 2.151627472651902

Epoch: 5| Step: 10
Training loss: 2.3468551635742188
Validation loss: 2.146318890715158

Epoch: 46| Step: 0
Training loss: 1.9433377981185913
Validation loss: 2.1529406501400854

Epoch: 5| Step: 1
Training loss: 2.428330659866333
Validation loss: 2.135056572575723

Epoch: 5| Step: 2
Training loss: 2.1814591884613037
Validation loss: 2.1558704453129924

Epoch: 5| Step: 3
Training loss: 2.691713809967041
Validation loss: 2.1648739794249177

Epoch: 5| Step: 4
Training loss: 2.180140495300293
Validation loss: 2.136380717318545

Epoch: 5| Step: 5
Training loss: 2.6249566078186035
Validation loss: 2.156302308523527

Epoch: 5| Step: 6
Training loss: 2.4900712966918945
Validation loss: 2.1690724178027083

Epoch: 5| Step: 7
Training loss: 1.9055944681167603
Validation loss: 2.1672393916755595

Epoch: 5| Step: 8
Training loss: 2.9142353534698486
Validation loss: 2.137513235051145

Epoch: 5| Step: 9
Training loss: 2.523937225341797
Validation loss: 2.1488939921061196

Epoch: 5| Step: 10
Training loss: 1.9436559677124023
Validation loss: 2.1759431105788036

Epoch: 47| Step: 0
Training loss: 2.6806206703186035
Validation loss: 2.156054304492089

Epoch: 5| Step: 1
Training loss: 2.390110969543457
Validation loss: 2.132662324495213

Epoch: 5| Step: 2
Training loss: 2.869870901107788
Validation loss: 2.1686246446383897

Epoch: 5| Step: 3
Training loss: 1.7144510746002197
Validation loss: 2.1426036550152685

Epoch: 5| Step: 4
Training loss: 2.5445306301116943
Validation loss: 2.1453620131297777

Epoch: 5| Step: 5
Training loss: 2.167705535888672
Validation loss: 2.162452418317077

Epoch: 5| Step: 6
Training loss: 1.5212225914001465
Validation loss: 2.140737724560563

Epoch: 5| Step: 7
Training loss: 2.5069046020507812
Validation loss: 2.138505305013349

Epoch: 5| Step: 8
Training loss: 2.9636635780334473
Validation loss: 2.1692212473961616

Epoch: 5| Step: 9
Training loss: 2.1929361820220947
Validation loss: 2.1645483150277087

Epoch: 5| Step: 10
Training loss: 2.291494607925415
Validation loss: 2.138210604267736

Epoch: 48| Step: 0
Training loss: 1.8689701557159424
Validation loss: 2.162347444923975

Epoch: 5| Step: 1
Training loss: 2.685542583465576
Validation loss: 2.1349778418899863

Epoch: 5| Step: 2
Training loss: 2.1537907123565674
Validation loss: 2.1344401746667843

Epoch: 5| Step: 3
Training loss: 2.3374152183532715
Validation loss: 2.14259530908318

Epoch: 5| Step: 4
Training loss: 2.704071521759033
Validation loss: 2.1484757290091565

Epoch: 5| Step: 5
Training loss: 2.2856428623199463
Validation loss: 2.173956483922979

Epoch: 5| Step: 6
Training loss: 2.0068225860595703
Validation loss: 2.1633965199993503

Epoch: 5| Step: 7
Training loss: 2.3761298656463623
Validation loss: 2.1588316707200903

Epoch: 5| Step: 8
Training loss: 3.164933681488037
Validation loss: 2.146126620231136

Epoch: 5| Step: 9
Training loss: 2.155233860015869
Validation loss: 2.1258766625517156

Epoch: 5| Step: 10
Training loss: 2.2601733207702637
Validation loss: 2.150861329929803

Epoch: 49| Step: 0
Training loss: 1.8128328323364258
Validation loss: 2.1337085423930997

Epoch: 5| Step: 1
Training loss: 2.6014742851257324
Validation loss: 2.1546610952705465

Epoch: 5| Step: 2
Training loss: 2.9822545051574707
Validation loss: 2.137948200266848

Epoch: 5| Step: 3
Training loss: 2.630826234817505
Validation loss: 2.1320132773409606

Epoch: 5| Step: 4
Training loss: 2.807523727416992
Validation loss: 2.1307648766425347

Epoch: 5| Step: 5
Training loss: 2.089669704437256
Validation loss: 2.1386803324504564

Epoch: 5| Step: 6
Training loss: 2.0360398292541504
Validation loss: 2.136687578693513

Epoch: 5| Step: 7
Training loss: 2.1520183086395264
Validation loss: 2.1246518396562144

Epoch: 5| Step: 8
Training loss: 1.972513198852539
Validation loss: 2.157599151775401

Epoch: 5| Step: 9
Training loss: 2.2983298301696777
Validation loss: 2.11854782027583

Epoch: 5| Step: 10
Training loss: 2.6267454624176025
Validation loss: 2.1353405649944017

Epoch: 50| Step: 0
Training loss: 2.1690104007720947
Validation loss: 2.1465582616867556

Epoch: 5| Step: 1
Training loss: 2.6502928733825684
Validation loss: 2.144434569984354

Epoch: 5| Step: 2
Training loss: 2.805817127227783
Validation loss: 2.11524619466515

Epoch: 5| Step: 3
Training loss: 2.3147122859954834
Validation loss: 2.124123498957644

Epoch: 5| Step: 4
Training loss: 2.3799753189086914
Validation loss: 2.115399013283432

Epoch: 5| Step: 5
Training loss: 2.227421522140503
Validation loss: 2.1351719351225

Epoch: 5| Step: 6
Training loss: 2.183516263961792
Validation loss: 2.1461026719821397

Epoch: 5| Step: 7
Training loss: 2.1064162254333496
Validation loss: 2.131830246217789

Epoch: 5| Step: 8
Training loss: 2.231881618499756
Validation loss: 2.158521362530288

Epoch: 5| Step: 9
Training loss: 2.957904100418091
Validation loss: 2.1413060606166883

Epoch: 5| Step: 10
Training loss: 1.6980319023132324
Validation loss: 2.1295909061226794

Epoch: 51| Step: 0
Training loss: 2.529785633087158
Validation loss: 2.1425350481464016

Epoch: 5| Step: 1
Training loss: 2.3770735263824463
Validation loss: 2.1442450374685307

Epoch: 5| Step: 2
Training loss: 2.5578808784484863
Validation loss: 2.130794289291546

Epoch: 5| Step: 3
Training loss: 2.2773842811584473
Validation loss: 2.1473644523210424

Epoch: 5| Step: 4
Training loss: 2.4404006004333496
Validation loss: 2.140697681775657

Epoch: 5| Step: 5
Training loss: 1.8145679235458374
Validation loss: 2.166719064917616

Epoch: 5| Step: 6
Training loss: 2.8624441623687744
Validation loss: 2.1452174263615764

Epoch: 5| Step: 7
Training loss: 2.113734722137451
Validation loss: 2.171396686184791

Epoch: 5| Step: 8
Training loss: 2.0546956062316895
Validation loss: 2.1734663337789555

Epoch: 5| Step: 9
Training loss: 2.43334698677063
Validation loss: 2.163189072762766

Epoch: 5| Step: 10
Training loss: 2.312350273132324
Validation loss: 2.1850024218200357

Epoch: 52| Step: 0
Training loss: 2.3261184692382812
Validation loss: 2.152101073213803

Epoch: 5| Step: 1
Training loss: 1.7283401489257812
Validation loss: 2.1422562086454002

Epoch: 5| Step: 2
Training loss: 2.879836320877075
Validation loss: 2.142011909074681

Epoch: 5| Step: 3
Training loss: 1.7105058431625366
Validation loss: 2.15277273167846

Epoch: 5| Step: 4
Training loss: 2.8365910053253174
Validation loss: 2.154375937677199

Epoch: 5| Step: 5
Training loss: 2.5435283184051514
Validation loss: 2.1318420697284

Epoch: 5| Step: 6
Training loss: 2.5090878009796143
Validation loss: 2.1572144698071223

Epoch: 5| Step: 7
Training loss: 2.6659114360809326
Validation loss: 2.162237585231822

Epoch: 5| Step: 8
Training loss: 1.660030722618103
Validation loss: 2.1322523188847367

Epoch: 5| Step: 9
Training loss: 2.720909833908081
Validation loss: 2.1858074280523483

Epoch: 5| Step: 10
Training loss: 2.1219940185546875
Validation loss: 2.148947941359653

Epoch: 53| Step: 0
Training loss: 2.674562692642212
Validation loss: 2.1489608800539406

Epoch: 5| Step: 1
Training loss: 1.556420922279358
Validation loss: 2.1445360798989572

Epoch: 5| Step: 2
Training loss: 2.1751980781555176
Validation loss: 2.1751528632256294

Epoch: 5| Step: 3
Training loss: 2.1610350608825684
Validation loss: 2.167572400903189

Epoch: 5| Step: 4
Training loss: 1.8800318241119385
Validation loss: 2.166990795443135

Epoch: 5| Step: 5
Training loss: 2.393108367919922
Validation loss: 2.1731245120366416

Epoch: 5| Step: 6
Training loss: 2.092251777648926
Validation loss: 2.1428917992499565

Epoch: 5| Step: 7
Training loss: 2.706240653991699
Validation loss: 2.1611281518013246

Epoch: 5| Step: 8
Training loss: 2.6402151584625244
Validation loss: 2.15048171499724

Epoch: 5| Step: 9
Training loss: 3.08209228515625
Validation loss: 2.133621641384658

Epoch: 5| Step: 10
Training loss: 2.4230782985687256
Validation loss: 2.1381624001328663

Epoch: 54| Step: 0
Training loss: 2.2749359607696533
Validation loss: 2.182178440914359

Epoch: 5| Step: 1
Training loss: 2.480612277984619
Validation loss: 2.1491601620951006

Epoch: 5| Step: 2
Training loss: 2.177976608276367
Validation loss: 2.130693648451118

Epoch: 5| Step: 3
Training loss: 2.1934189796447754
Validation loss: 2.1692841347827705

Epoch: 5| Step: 4
Training loss: 3.553997039794922
Validation loss: 2.1355804679214314

Epoch: 5| Step: 5
Training loss: 2.0763392448425293
Validation loss: 2.141403580224642

Epoch: 5| Step: 6
Training loss: 2.3171322345733643
Validation loss: 2.1826579493861042

Epoch: 5| Step: 7
Training loss: 2.2755513191223145
Validation loss: 2.1421721289234776

Epoch: 5| Step: 8
Training loss: 2.0862441062927246
Validation loss: 2.157090920273976

Epoch: 5| Step: 9
Training loss: 2.409066677093506
Validation loss: 2.148046226911647

Epoch: 5| Step: 10
Training loss: 1.6932543516159058
Validation loss: 2.160335918908478

Epoch: 55| Step: 0
Training loss: 1.7490758895874023
Validation loss: 2.1311672041493077

Epoch: 5| Step: 1
Training loss: 3.1363627910614014
Validation loss: 2.1602962427241827

Epoch: 5| Step: 2
Training loss: 1.9487117528915405
Validation loss: 2.1174217039538967

Epoch: 5| Step: 3
Training loss: 2.2486329078674316
Validation loss: 2.10352752541983

Epoch: 5| Step: 4
Training loss: 2.246575117111206
Validation loss: 2.1316444309808875

Epoch: 5| Step: 5
Training loss: 2.4517738819122314
Validation loss: 2.1509441150132047

Epoch: 5| Step: 6
Training loss: 2.403346538543701
Validation loss: 2.1287957250431018

Epoch: 5| Step: 7
Training loss: 2.648068904876709
Validation loss: 2.1586215983154955

Epoch: 5| Step: 8
Training loss: 2.0527658462524414
Validation loss: 2.1383601260441605

Epoch: 5| Step: 9
Training loss: 2.235250473022461
Validation loss: 2.1303075641714115

Epoch: 5| Step: 10
Training loss: 2.77712082862854
Validation loss: 2.1538176998015373

Epoch: 56| Step: 0
Training loss: 2.1845784187316895
Validation loss: 2.153264252088403

Epoch: 5| Step: 1
Training loss: 2.6438233852386475
Validation loss: 2.1455138088554464

Epoch: 5| Step: 2
Training loss: 2.132539749145508
Validation loss: 2.1600841552980485

Epoch: 5| Step: 3
Training loss: 2.3729584217071533
Validation loss: 2.13636121185877

Epoch: 5| Step: 4
Training loss: 1.9143394231796265
Validation loss: 2.13007475227438

Epoch: 5| Step: 5
Training loss: 2.489001512527466
Validation loss: 2.127291302527151

Epoch: 5| Step: 6
Training loss: 2.8145976066589355
Validation loss: 2.1391148772290958

Epoch: 5| Step: 7
Training loss: 2.1116318702697754
Validation loss: 2.1195930127174623

Epoch: 5| Step: 8
Training loss: 2.6044933795928955
Validation loss: 2.1378260991906606

Epoch: 5| Step: 9
Training loss: 1.8206268548965454
Validation loss: 2.1647505401283182

Epoch: 5| Step: 10
Training loss: 2.691148042678833
Validation loss: 2.16603059153403

Epoch: 57| Step: 0
Training loss: 2.7289369106292725
Validation loss: 2.148046105138717

Epoch: 5| Step: 1
Training loss: 2.1954853534698486
Validation loss: 2.151605406115132

Epoch: 5| Step: 2
Training loss: 2.3847782611846924
Validation loss: 2.1338886240477204

Epoch: 5| Step: 3
Training loss: 2.316737651824951
Validation loss: 2.161803162226113

Epoch: 5| Step: 4
Training loss: 2.5321812629699707
Validation loss: 2.138900864508844

Epoch: 5| Step: 5
Training loss: 1.6314960718154907
Validation loss: 2.1154417786546933

Epoch: 5| Step: 6
Training loss: 2.1967101097106934
Validation loss: 2.1326925882729153

Epoch: 5| Step: 7
Training loss: 2.8958067893981934
Validation loss: 2.145179848517141

Epoch: 5| Step: 8
Training loss: 2.141012668609619
Validation loss: 2.1505312047978884

Epoch: 5| Step: 9
Training loss: 2.3725674152374268
Validation loss: 2.1327573483990085

Epoch: 5| Step: 10
Training loss: 2.221099853515625
Validation loss: 2.13634132569836

Epoch: 58| Step: 0
Training loss: 1.8346326351165771
Validation loss: 2.14929469426473

Epoch: 5| Step: 1
Training loss: 3.270965576171875
Validation loss: 2.129801780946793

Epoch: 5| Step: 2
Training loss: 2.2997982501983643
Validation loss: 2.1313461860020957

Epoch: 5| Step: 3
Training loss: 2.458526372909546
Validation loss: 2.1154869192390033

Epoch: 5| Step: 4
Training loss: 1.9664011001586914
Validation loss: 2.1616459610641643

Epoch: 5| Step: 5
Training loss: 1.412830114364624
Validation loss: 2.1106936880337295

Epoch: 5| Step: 6
Training loss: 2.3232839107513428
Validation loss: 2.1359945702296432

Epoch: 5| Step: 7
Training loss: 2.3256936073303223
Validation loss: 2.17432245772372

Epoch: 5| Step: 8
Training loss: 2.764620065689087
Validation loss: 2.1277718902916036

Epoch: 5| Step: 9
Training loss: 2.4073543548583984
Validation loss: 2.1139152511473625

Epoch: 5| Step: 10
Training loss: 2.744377851486206
Validation loss: 2.1411241869772635

Epoch: 59| Step: 0
Training loss: 2.5771777629852295
Validation loss: 2.146658005252961

Epoch: 5| Step: 1
Training loss: 2.5291762351989746
Validation loss: 2.1349022157730593

Epoch: 5| Step: 2
Training loss: 1.904544472694397
Validation loss: 2.145333642600685

Epoch: 5| Step: 3
Training loss: 2.1624202728271484
Validation loss: 2.1662078775385374

Epoch: 5| Step: 4
Training loss: 2.473924160003662
Validation loss: 2.1671370819050777

Epoch: 5| Step: 5
Training loss: 2.4348747730255127
Validation loss: 2.138906322499757

Epoch: 5| Step: 6
Training loss: 2.2112951278686523
Validation loss: 2.1291156955944595

Epoch: 5| Step: 7
Training loss: 1.8592090606689453
Validation loss: 2.172996351795812

Epoch: 5| Step: 8
Training loss: 2.5241715908050537
Validation loss: 2.1726892737932104

Epoch: 5| Step: 9
Training loss: 1.794036865234375
Validation loss: 2.1561980555134435

Epoch: 5| Step: 10
Training loss: 3.2631449699401855
Validation loss: 2.196140791780205

Epoch: 60| Step: 0
Training loss: 2.098011016845703
Validation loss: 2.148732659637287

Epoch: 5| Step: 1
Training loss: 2.300656795501709
Validation loss: 2.1255842383189867

Epoch: 5| Step: 2
Training loss: 1.8115886449813843
Validation loss: 2.1508093008431057

Epoch: 5| Step: 3
Training loss: 2.355565309524536
Validation loss: 2.142615182425386

Epoch: 5| Step: 4
Training loss: 2.9308156967163086
Validation loss: 2.1513752578407206

Epoch: 5| Step: 5
Training loss: 2.5046722888946533
Validation loss: 2.1524740803626274

Epoch: 5| Step: 6
Training loss: 2.5225415229797363
Validation loss: 2.161403081750357

Epoch: 5| Step: 7
Training loss: 2.2350099086761475
Validation loss: 2.1425880642347437

Epoch: 5| Step: 8
Training loss: 2.397059917449951
Validation loss: 2.1391120931153655

Epoch: 5| Step: 9
Training loss: 2.3105814456939697
Validation loss: 2.1109521286461943

Epoch: 5| Step: 10
Training loss: 2.1613411903381348
Validation loss: 2.1526368651338803

Epoch: 61| Step: 0
Training loss: 2.219491958618164
Validation loss: 2.143226977317564

Epoch: 5| Step: 1
Training loss: 2.3884105682373047
Validation loss: 2.137706410500311

Epoch: 5| Step: 2
Training loss: 2.163668394088745
Validation loss: 2.154508104888342

Epoch: 5| Step: 3
Training loss: 2.8570430278778076
Validation loss: 2.1690383367640997

Epoch: 5| Step: 4
Training loss: 2.124363899230957
Validation loss: 2.130483311991538

Epoch: 5| Step: 5
Training loss: 2.352583885192871
Validation loss: 2.163592674398935

Epoch: 5| Step: 6
Training loss: 2.151059627532959
Validation loss: 2.1601522135478195

Epoch: 5| Step: 7
Training loss: 2.7210967540740967
Validation loss: 2.148192372373355

Epoch: 5| Step: 8
Training loss: 2.021113872528076
Validation loss: 2.1490898465597503

Epoch: 5| Step: 9
Training loss: 2.1104378700256348
Validation loss: 2.1752862776479414

Epoch: 5| Step: 10
Training loss: 2.775844097137451
Validation loss: 2.1468951189389793

Epoch: 62| Step: 0
Training loss: 2.6093387603759766
Validation loss: 2.1381773769214587

Epoch: 5| Step: 1
Training loss: 2.2031006813049316
Validation loss: 2.1585161685943604

Epoch: 5| Step: 2
Training loss: 2.540501117706299
Validation loss: 2.1410327265339513

Epoch: 5| Step: 3
Training loss: 1.9219030141830444
Validation loss: 2.1392022819929224

Epoch: 5| Step: 4
Training loss: 1.8695285320281982
Validation loss: 2.14193542029268

Epoch: 5| Step: 5
Training loss: 2.5907840728759766
Validation loss: 2.1559537456881617

Epoch: 5| Step: 6
Training loss: 1.6899429559707642
Validation loss: 2.1526015907205562

Epoch: 5| Step: 7
Training loss: 2.0973708629608154
Validation loss: 2.1439194089622906

Epoch: 5| Step: 8
Training loss: 2.316890239715576
Validation loss: 2.149927816083354

Epoch: 5| Step: 9
Training loss: 2.769460678100586
Validation loss: 2.1673446919328425

Epoch: 5| Step: 10
Training loss: 3.2254271507263184
Validation loss: 2.1423484176717777

Epoch: 63| Step: 0
Training loss: 2.639836311340332
Validation loss: 2.1294302376367713

Epoch: 5| Step: 1
Training loss: 2.03971529006958
Validation loss: 2.1455262271306847

Epoch: 5| Step: 2
Training loss: 2.51780366897583
Validation loss: 2.1564748389746553

Epoch: 5| Step: 3
Training loss: 2.017310619354248
Validation loss: 2.163640037659676

Epoch: 5| Step: 4
Training loss: 1.8409948348999023
Validation loss: 2.1467006385967298

Epoch: 5| Step: 5
Training loss: 2.347885847091675
Validation loss: 2.1355768378062914

Epoch: 5| Step: 6
Training loss: 2.3782713413238525
Validation loss: 2.1280416006683023

Epoch: 5| Step: 7
Training loss: 2.532374143600464
Validation loss: 2.144376770142586

Epoch: 5| Step: 8
Training loss: 2.4048829078674316
Validation loss: 2.136781123376662

Epoch: 5| Step: 9
Training loss: 2.755152463912964
Validation loss: 2.1667296963353313

Epoch: 5| Step: 10
Training loss: 1.9015556573867798
Validation loss: 2.1613603945701354

Epoch: 64| Step: 0
Training loss: 1.4045906066894531
Validation loss: 2.121912557591674

Epoch: 5| Step: 1
Training loss: 1.9524024724960327
Validation loss: 2.1604552038254274

Epoch: 5| Step: 2
Training loss: 2.7804527282714844
Validation loss: 2.1436822388761785

Epoch: 5| Step: 3
Training loss: 2.939828872680664
Validation loss: 2.1335530921977055

Epoch: 5| Step: 4
Training loss: 2.125688076019287
Validation loss: 2.1585151046834965

Epoch: 5| Step: 5
Training loss: 2.1395440101623535
Validation loss: 2.1457362072442168

Epoch: 5| Step: 6
Training loss: 1.7853858470916748
Validation loss: 2.177454651042979

Epoch: 5| Step: 7
Training loss: 2.279280662536621
Validation loss: 2.153425307684047

Epoch: 5| Step: 8
Training loss: 2.547898054122925
Validation loss: 2.1248063272045505

Epoch: 5| Step: 9
Training loss: 2.861316680908203
Validation loss: 2.154881513246926

Epoch: 5| Step: 10
Training loss: 2.8722715377807617
Validation loss: 2.1404572058749456

Epoch: 65| Step: 0
Training loss: 2.2046306133270264
Validation loss: 2.150880059888286

Epoch: 5| Step: 1
Training loss: 1.6353248357772827
Validation loss: 2.1580103392242105

Epoch: 5| Step: 2
Training loss: 2.2770285606384277
Validation loss: 2.1505014383664696

Epoch: 5| Step: 3
Training loss: 2.2858669757843018
Validation loss: 2.1439391464315434

Epoch: 5| Step: 4
Training loss: 1.896888017654419
Validation loss: 2.1218896604353383

Epoch: 5| Step: 5
Training loss: 2.1529717445373535
Validation loss: 2.1320485299633396

Epoch: 5| Step: 6
Training loss: 1.7673580646514893
Validation loss: 2.131510825567348

Epoch: 5| Step: 7
Training loss: 3.098844289779663
Validation loss: 2.1442782007237917

Epoch: 5| Step: 8
Training loss: 3.3102340698242188
Validation loss: 2.162190273243894

Epoch: 5| Step: 9
Training loss: 2.272376298904419
Validation loss: 2.1478825410207114

Epoch: 5| Step: 10
Training loss: 2.982651948928833
Validation loss: 2.1321531623922367

Epoch: 66| Step: 0
Training loss: 2.3000214099884033
Validation loss: 2.1316722746818297

Epoch: 5| Step: 1
Training loss: 2.66298246383667
Validation loss: 2.157307296670893

Epoch: 5| Step: 2
Training loss: 2.9124579429626465
Validation loss: 2.1169266828926663

Epoch: 5| Step: 3
Training loss: 2.4483718872070312
Validation loss: 2.143142372049311

Epoch: 5| Step: 4
Training loss: 1.5003407001495361
Validation loss: 2.1297945540438414

Epoch: 5| Step: 5
Training loss: 1.8815333843231201
Validation loss: 2.141641734748758

Epoch: 5| Step: 6
Training loss: 1.8220583200454712
Validation loss: 2.162784719979891

Epoch: 5| Step: 7
Training loss: 1.9728105068206787
Validation loss: 2.1524585626458608

Epoch: 5| Step: 8
Training loss: 2.948702573776245
Validation loss: 2.1439525491447857

Epoch: 5| Step: 9
Training loss: 2.7838516235351562
Validation loss: 2.169701927451677

Epoch: 5| Step: 10
Training loss: 2.18290376663208
Validation loss: 2.141813878090151

Epoch: 67| Step: 0
Training loss: 2.2933599948883057
Validation loss: 2.1633174624494327

Epoch: 5| Step: 1
Training loss: 2.697313070297241
Validation loss: 2.140644827196675

Epoch: 5| Step: 2
Training loss: 2.6121182441711426
Validation loss: 2.1797353708615868

Epoch: 5| Step: 3
Training loss: 2.566253900527954
Validation loss: 2.156706166523759

Epoch: 5| Step: 4
Training loss: 1.6432832479476929
Validation loss: 2.1396190633055983

Epoch: 5| Step: 5
Training loss: 2.0755746364593506
Validation loss: 2.1581930857832714

Epoch: 5| Step: 6
Training loss: 2.497454881668091
Validation loss: 2.1618967697184575

Epoch: 5| Step: 7
Training loss: 1.958900809288025
Validation loss: 2.1579720743240847

Epoch: 5| Step: 8
Training loss: 2.7620460987091064
Validation loss: 2.1831473522288825

Epoch: 5| Step: 9
Training loss: 2.0638937950134277
Validation loss: 2.159607598858495

Epoch: 5| Step: 10
Training loss: 2.3794474601745605
Validation loss: 2.159986893335978

Epoch: 68| Step: 0
Training loss: 2.408857822418213
Validation loss: 2.14822377568932

Epoch: 5| Step: 1
Training loss: 2.7491958141326904
Validation loss: 2.1597619569429787

Epoch: 5| Step: 2
Training loss: 2.201176166534424
Validation loss: 2.1724409313612085

Epoch: 5| Step: 3
Training loss: 2.3523354530334473
Validation loss: 2.1624167555121967

Epoch: 5| Step: 4
Training loss: 2.583040952682495
Validation loss: 2.1698380336966565

Epoch: 5| Step: 5
Training loss: 2.316443920135498
Validation loss: 2.2104523387006534

Epoch: 5| Step: 6
Training loss: 2.029981851577759
Validation loss: 2.2035953037200438

Epoch: 5| Step: 7
Training loss: 2.2426536083221436
Validation loss: 2.1624733478792253

Epoch: 5| Step: 8
Training loss: 2.7689948081970215
Validation loss: 2.177738861371112

Epoch: 5| Step: 9
Training loss: 1.854895830154419
Validation loss: 2.1583885761999313

Epoch: 5| Step: 10
Training loss: 2.079396963119507
Validation loss: 2.174685585883356

Epoch: 69| Step: 0
Training loss: 1.9767177104949951
Validation loss: 2.175048230796732

Epoch: 5| Step: 1
Training loss: 1.5123264789581299
Validation loss: 2.1728979438863774

Epoch: 5| Step: 2
Training loss: 2.946549892425537
Validation loss: 2.1484270121461604

Epoch: 5| Step: 3
Training loss: 2.195038080215454
Validation loss: 2.1544925243623796

Epoch: 5| Step: 4
Training loss: 2.4207725524902344
Validation loss: 2.1474034760587957

Epoch: 5| Step: 5
Training loss: 2.6744868755340576
Validation loss: 2.1604662966984574

Epoch: 5| Step: 6
Training loss: 2.1423354148864746
Validation loss: 2.146186761958625

Epoch: 5| Step: 7
Training loss: 2.270933151245117
Validation loss: 2.1150371541259108

Epoch: 5| Step: 8
Training loss: 2.3722949028015137
Validation loss: 2.145346636413246

Epoch: 5| Step: 9
Training loss: 2.571338176727295
Validation loss: 2.1466497657119588

Epoch: 5| Step: 10
Training loss: 2.265827178955078
Validation loss: 2.152298088996641

Epoch: 70| Step: 0
Training loss: 2.275838851928711
Validation loss: 2.148111540784118

Epoch: 5| Step: 1
Training loss: 2.1258726119995117
Validation loss: 2.1443248077105452

Epoch: 5| Step: 2
Training loss: 2.2043986320495605
Validation loss: 2.1321535956475044

Epoch: 5| Step: 3
Training loss: 2.1953444480895996
Validation loss: 2.1346718367709907

Epoch: 5| Step: 4
Training loss: 2.2362544536590576
Validation loss: 2.137916978969369

Epoch: 5| Step: 5
Training loss: 1.789096474647522
Validation loss: 2.159255942990703

Epoch: 5| Step: 6
Training loss: 2.7754154205322266
Validation loss: 2.1415023111527964

Epoch: 5| Step: 7
Training loss: 2.4026455879211426
Validation loss: 2.1633992246402207

Epoch: 5| Step: 8
Training loss: 2.242003917694092
Validation loss: 2.1390374783546693

Epoch: 5| Step: 9
Training loss: 2.8176960945129395
Validation loss: 2.1507031763753583

Epoch: 5| Step: 10
Training loss: 2.403867721557617
Validation loss: 2.1378650011554843

Epoch: 71| Step: 0
Training loss: 1.9341697692871094
Validation loss: 2.142045318439443

Epoch: 5| Step: 1
Training loss: 2.640453815460205
Validation loss: 2.1170677023549236

Epoch: 5| Step: 2
Training loss: 2.3954365253448486
Validation loss: 2.156542102495829

Epoch: 5| Step: 3
Training loss: 3.080406665802002
Validation loss: 2.1393925887282177

Epoch: 5| Step: 4
Training loss: 2.397496461868286
Validation loss: 2.1372540215010285

Epoch: 5| Step: 5
Training loss: 1.1136459112167358
Validation loss: 2.152973718540643

Epoch: 5| Step: 6
Training loss: 2.7253270149230957
Validation loss: 2.1310967155682143

Epoch: 5| Step: 7
Training loss: 1.3878185749053955
Validation loss: 2.163882008162878

Epoch: 5| Step: 8
Training loss: 2.2434792518615723
Validation loss: 2.1622281433433614

Epoch: 5| Step: 9
Training loss: 2.73799467086792
Validation loss: 2.1496188102229947

Epoch: 5| Step: 10
Training loss: 2.9530816078186035
Validation loss: 2.120395101526732

Epoch: 72| Step: 0
Training loss: 2.2741096019744873
Validation loss: 2.148125374188987

Epoch: 5| Step: 1
Training loss: 2.3814971446990967
Validation loss: 2.1129058637926654

Epoch: 5| Step: 2
Training loss: 2.3336808681488037
Validation loss: 2.1440213649503645

Epoch: 5| Step: 3
Training loss: 2.2725942134857178
Validation loss: 2.122534501937128

Epoch: 5| Step: 4
Training loss: 2.676880121231079
Validation loss: 2.146995395742437

Epoch: 5| Step: 5
Training loss: 2.0390963554382324
Validation loss: 2.152121946375857

Epoch: 5| Step: 6
Training loss: 2.1894640922546387
Validation loss: 2.153341488171649

Epoch: 5| Step: 7
Training loss: 2.228415012359619
Validation loss: 2.1545324299925115

Epoch: 5| Step: 8
Training loss: 2.278932809829712
Validation loss: 2.1343661123706448

Epoch: 5| Step: 9
Training loss: 2.3386178016662598
Validation loss: 2.1795498735161236

Epoch: 5| Step: 10
Training loss: 2.6596362590789795
Validation loss: 2.162288224825295

Epoch: 73| Step: 0
Training loss: 2.5375142097473145
Validation loss: 2.161265993631014

Epoch: 5| Step: 1
Training loss: 2.942059278488159
Validation loss: 2.177399657105887

Epoch: 5| Step: 2
Training loss: 2.0550167560577393
Validation loss: 2.133665128420758

Epoch: 5| Step: 3
Training loss: 2.2793211936950684
Validation loss: 2.154600707433557

Epoch: 5| Step: 4
Training loss: 2.3496479988098145
Validation loss: 2.1661279124598347

Epoch: 5| Step: 5
Training loss: 2.0054123401641846
Validation loss: 2.1432979747813237

Epoch: 5| Step: 6
Training loss: 1.6019790172576904
Validation loss: 2.1650093293959096

Epoch: 5| Step: 7
Training loss: 3.040487051010132
Validation loss: 2.1613895252186763

Epoch: 5| Step: 8
Training loss: 2.439378261566162
Validation loss: 2.168012231908819

Epoch: 5| Step: 9
Training loss: 1.7807624340057373
Validation loss: 2.1131694137409167

Epoch: 5| Step: 10
Training loss: 2.294354200363159
Validation loss: 2.1544077806575324

Epoch: 74| Step: 0
Training loss: 2.2038238048553467
Validation loss: 2.1453215229895806

Epoch: 5| Step: 1
Training loss: 1.8109619617462158
Validation loss: 2.166734230133795

Epoch: 5| Step: 2
Training loss: 2.093317985534668
Validation loss: 2.161676968297651

Epoch: 5| Step: 3
Training loss: 2.358884334564209
Validation loss: 2.1459815707258

Epoch: 5| Step: 4
Training loss: 2.4518070220947266
Validation loss: 2.1392514090384207

Epoch: 5| Step: 5
Training loss: 2.492267608642578
Validation loss: 2.1361301022191204

Epoch: 5| Step: 6
Training loss: 2.284862756729126
Validation loss: 2.147024900682511

Epoch: 5| Step: 7
Training loss: 2.2392706871032715
Validation loss: 2.1453301880949285

Epoch: 5| Step: 8
Training loss: 2.626364231109619
Validation loss: 2.1724549608845867

Epoch: 5| Step: 9
Training loss: 2.083068370819092
Validation loss: 2.154083210934875

Epoch: 5| Step: 10
Training loss: 2.8684346675872803
Validation loss: 2.1611426850800872

Epoch: 75| Step: 0
Training loss: 2.2148118019104004
Validation loss: 2.1899262602611254

Epoch: 5| Step: 1
Training loss: 2.6573173999786377
Validation loss: 2.133009790092386

Epoch: 5| Step: 2
Training loss: 2.5844671726226807
Validation loss: 2.1640443917243712

Epoch: 5| Step: 3
Training loss: 2.6168301105499268
Validation loss: 2.143274740506244

Epoch: 5| Step: 4
Training loss: 1.8142614364624023
Validation loss: 2.155369735533191

Epoch: 5| Step: 5
Training loss: 2.666611909866333
Validation loss: 2.136175937550042

Epoch: 5| Step: 6
Training loss: 2.214585781097412
Validation loss: 2.1489764746799263

Epoch: 5| Step: 7
Training loss: 1.7405465841293335
Validation loss: 2.1524870498206026

Epoch: 5| Step: 8
Training loss: 2.9259018898010254
Validation loss: 2.1516965076487553

Epoch: 5| Step: 9
Training loss: 1.993880271911621
Validation loss: 2.1663538666181665

Epoch: 5| Step: 10
Training loss: 2.0017337799072266
Validation loss: 2.130637030447683

Epoch: 76| Step: 0
Training loss: 1.51051926612854
Validation loss: 2.1513132869556384

Epoch: 5| Step: 1
Training loss: 2.0039572715759277
Validation loss: 2.142308315923137

Epoch: 5| Step: 2
Training loss: 3.2368977069854736
Validation loss: 2.1303105251763457

Epoch: 5| Step: 3
Training loss: 2.111006021499634
Validation loss: 2.143665629048501

Epoch: 5| Step: 4
Training loss: 3.15936017036438
Validation loss: 2.137817144393921

Epoch: 5| Step: 5
Training loss: 2.648862838745117
Validation loss: 2.1353279749552407

Epoch: 5| Step: 6
Training loss: 1.6428606510162354
Validation loss: 2.121029228292486

Epoch: 5| Step: 7
Training loss: 2.22011399269104
Validation loss: 2.145677799819618

Epoch: 5| Step: 8
Training loss: 1.8469598293304443
Validation loss: 2.1354547034027758

Epoch: 5| Step: 9
Training loss: 2.6029868125915527
Validation loss: 2.1452500076704126

Epoch: 5| Step: 10
Training loss: 2.520549774169922
Validation loss: 2.167259480363579

Epoch: 77| Step: 0
Training loss: 2.3718392848968506
Validation loss: 2.1579619120526057

Epoch: 5| Step: 1
Training loss: 2.5263442993164062
Validation loss: 2.1613142464750554

Epoch: 5| Step: 2
Training loss: 2.0255677700042725
Validation loss: 2.1699731221763034

Epoch: 5| Step: 3
Training loss: 2.685997724533081
Validation loss: 2.1318866296481063

Epoch: 5| Step: 4
Training loss: 2.296931505203247
Validation loss: 2.1521337878319526

Epoch: 5| Step: 5
Training loss: 2.330592632293701
Validation loss: 2.1647277647449124

Epoch: 5| Step: 6
Training loss: 2.0996153354644775
Validation loss: 2.1414342106029554

Epoch: 5| Step: 7
Training loss: 2.4901270866394043
Validation loss: 2.180046050779281

Epoch: 5| Step: 8
Training loss: 2.5423762798309326
Validation loss: 2.140094105915357

Epoch: 5| Step: 9
Training loss: 2.2436699867248535
Validation loss: 2.15789367306617

Epoch: 5| Step: 10
Training loss: 1.4523165225982666
Validation loss: 2.1719931992151404

Epoch: 78| Step: 0
Training loss: 2.5636980533599854
Validation loss: 2.1558605727329048

Epoch: 5| Step: 1
Training loss: 2.375244140625
Validation loss: 2.151356643246066

Epoch: 5| Step: 2
Training loss: 2.59755539894104
Validation loss: 2.1683960781302503

Epoch: 5| Step: 3
Training loss: 2.649163007736206
Validation loss: 2.1394703029304423

Epoch: 5| Step: 4
Training loss: 2.5887246131896973
Validation loss: 2.145577771689302

Epoch: 5| Step: 5
Training loss: 2.1630706787109375
Validation loss: 2.1656175480094007

Epoch: 5| Step: 6
Training loss: 2.010913133621216
Validation loss: 2.1855106943397113

Epoch: 5| Step: 7
Training loss: 2.0283594131469727
Validation loss: 2.1639484628554313

Epoch: 5| Step: 8
Training loss: 2.3976831436157227
Validation loss: 2.164301009588344

Epoch: 5| Step: 9
Training loss: 2.336613893508911
Validation loss: 2.1544236790749336

Epoch: 5| Step: 10
Training loss: 1.7110315561294556
Validation loss: 2.133790223829208

Epoch: 79| Step: 0
Training loss: 1.7837028503417969
Validation loss: 2.1700338548229587

Epoch: 5| Step: 1
Training loss: 3.144711494445801
Validation loss: 2.176518065955049

Epoch: 5| Step: 2
Training loss: 2.1736109256744385
Validation loss: 2.1602614272025322

Epoch: 5| Step: 3
Training loss: 2.3104946613311768
Validation loss: 2.185593920369302

Epoch: 5| Step: 4
Training loss: 1.718176245689392
Validation loss: 2.1169261855463826

Epoch: 5| Step: 5
Training loss: 1.9830970764160156
Validation loss: 2.164836279807552

Epoch: 5| Step: 6
Training loss: 2.512176036834717
Validation loss: 2.1729771860184206

Epoch: 5| Step: 7
Training loss: 2.3882393836975098
Validation loss: 2.153623260477538

Epoch: 5| Step: 8
Training loss: 1.9907468557357788
Validation loss: 2.1246852772210234

Epoch: 5| Step: 9
Training loss: 2.6501381397247314
Validation loss: 2.1572605550930066

Epoch: 5| Step: 10
Training loss: 2.8624751567840576
Validation loss: 2.1612331777490597

Epoch: 80| Step: 0
Training loss: 2.1275954246520996
Validation loss: 2.1717144032960296

Epoch: 5| Step: 1
Training loss: 1.700817346572876
Validation loss: 2.1540329866511847

Epoch: 5| Step: 2
Training loss: 2.3069682121276855
Validation loss: 2.1579672726251746

Epoch: 5| Step: 3
Training loss: 2.176708698272705
Validation loss: 2.1660388592750794

Epoch: 5| Step: 4
Training loss: 2.3491904735565186
Validation loss: 2.150360768841159

Epoch: 5| Step: 5
Training loss: 2.4484710693359375
Validation loss: 2.109547704778692

Epoch: 5| Step: 6
Training loss: 2.1788454055786133
Validation loss: 2.1444826203007854

Epoch: 5| Step: 7
Training loss: 2.400623321533203
Validation loss: 2.1482036241921048

Epoch: 5| Step: 8
Training loss: 2.2834839820861816
Validation loss: 2.1430476993642826

Epoch: 5| Step: 9
Training loss: 2.8947629928588867
Validation loss: 2.1277072596293625

Epoch: 5| Step: 10
Training loss: 2.7661025524139404
Validation loss: 2.105867583264587

Epoch: 81| Step: 0
Training loss: 2.282468318939209
Validation loss: 2.143072730751448

Epoch: 5| Step: 1
Training loss: 1.7013957500457764
Validation loss: 2.1301195288217194

Epoch: 5| Step: 2
Training loss: 1.8654533624649048
Validation loss: 2.148171986303022

Epoch: 5| Step: 3
Training loss: 2.825747013092041
Validation loss: 2.1301984056349723

Epoch: 5| Step: 4
Training loss: 2.4020469188690186
Validation loss: 2.173459847768148

Epoch: 5| Step: 5
Training loss: 2.531123638153076
Validation loss: 2.1293726403226136

Epoch: 5| Step: 6
Training loss: 2.1683335304260254
Validation loss: 2.1324583215098225

Epoch: 5| Step: 7
Training loss: 2.0886316299438477
Validation loss: 2.1539783170146327

Epoch: 5| Step: 8
Training loss: 2.05204439163208
Validation loss: 2.136157230664325

Epoch: 5| Step: 9
Training loss: 2.786205768585205
Validation loss: 2.132620926826231

Epoch: 5| Step: 10
Training loss: 2.4713282585144043
Validation loss: 2.1448421273180234

Epoch: 82| Step: 0
Training loss: 2.152269124984741
Validation loss: 2.1479143096554663

Epoch: 5| Step: 1
Training loss: 2.5189766883850098
Validation loss: 2.157755631272511

Epoch: 5| Step: 2
Training loss: 3.0201950073242188
Validation loss: 2.1419018763367847

Epoch: 5| Step: 3
Training loss: 2.109800338745117
Validation loss: 2.1541909274234565

Epoch: 5| Step: 4
Training loss: 2.178950786590576
Validation loss: 2.171982413978987

Epoch: 5| Step: 5
Training loss: 1.8395769596099854
Validation loss: 2.1513497547436784

Epoch: 5| Step: 6
Training loss: 1.9270591735839844
Validation loss: 2.1515557586505847

Epoch: 5| Step: 7
Training loss: 2.785151243209839
Validation loss: 2.1657442251841226

Epoch: 5| Step: 8
Training loss: 3.060717821121216
Validation loss: 2.1556597191800355

Epoch: 5| Step: 9
Training loss: 1.982771873474121
Validation loss: 2.1490563167038785

Epoch: 5| Step: 10
Training loss: 1.6753408908843994
Validation loss: 2.1393848619153424

Epoch: 83| Step: 0
Training loss: 1.9400631189346313
Validation loss: 2.162117842705019

Epoch: 5| Step: 1
Training loss: 1.8279539346694946
Validation loss: 2.1751608117934196

Epoch: 5| Step: 2
Training loss: 2.286940813064575
Validation loss: 2.172776360665598

Epoch: 5| Step: 3
Training loss: 2.9531867504119873
Validation loss: 2.1600988065042803

Epoch: 5| Step: 4
Training loss: 2.0583393573760986
Validation loss: 2.1418174441142748

Epoch: 5| Step: 5
Training loss: 1.776545763015747
Validation loss: 2.1535279161186627

Epoch: 5| Step: 6
Training loss: 3.3412652015686035
Validation loss: 2.179842870722535

Epoch: 5| Step: 7
Training loss: 2.094960927963257
Validation loss: 2.168001804300534

Epoch: 5| Step: 8
Training loss: 2.4303269386291504
Validation loss: 2.144582026748247

Epoch: 5| Step: 9
Training loss: 2.2226760387420654
Validation loss: 2.168517315259544

Epoch: 5| Step: 10
Training loss: 2.3247451782226562
Validation loss: 2.113751365292457

Epoch: 84| Step: 0
Training loss: 1.8129889965057373
Validation loss: 2.1326777371027137

Epoch: 5| Step: 1
Training loss: 2.001021385192871
Validation loss: 2.1523967173791703

Epoch: 5| Step: 2
Training loss: 3.325019359588623
Validation loss: 2.148206706969969

Epoch: 5| Step: 3
Training loss: 2.1706643104553223
Validation loss: 2.1315447950875885

Epoch: 5| Step: 4
Training loss: 2.3180456161499023
Validation loss: 2.1529508675298383

Epoch: 5| Step: 5
Training loss: 2.5194902420043945
Validation loss: 2.16742036163166

Epoch: 5| Step: 6
Training loss: 1.8737207651138306
Validation loss: 2.141450250020591

Epoch: 5| Step: 7
Training loss: 2.182384729385376
Validation loss: 2.18057236876539

Epoch: 5| Step: 8
Training loss: 2.306910514831543
Validation loss: 2.1577096369958695

Epoch: 5| Step: 9
Training loss: 2.54262113571167
Validation loss: 2.184454915344074

Epoch: 5| Step: 10
Training loss: 2.372335433959961
Validation loss: 2.150321719466999

Epoch: 85| Step: 0
Training loss: 2.497770309448242
Validation loss: 2.146988181657689

Epoch: 5| Step: 1
Training loss: 2.6008028984069824
Validation loss: 2.1604848164384083

Epoch: 5| Step: 2
Training loss: 1.5684759616851807
Validation loss: 2.157122278726229

Epoch: 5| Step: 3
Training loss: 1.900697112083435
Validation loss: 2.1765034852489347

Epoch: 5| Step: 4
Training loss: 2.3534507751464844
Validation loss: 2.1697706740389586

Epoch: 5| Step: 5
Training loss: 2.6650030612945557
Validation loss: 2.145055261991357

Epoch: 5| Step: 6
Training loss: 2.6171069145202637
Validation loss: 2.157284014968462

Epoch: 5| Step: 7
Training loss: 2.117048978805542
Validation loss: 2.161434009510984

Epoch: 5| Step: 8
Training loss: 2.348762035369873
Validation loss: 2.1459090607140654

Epoch: 5| Step: 9
Training loss: 1.792191743850708
Validation loss: 2.1405417714067685

Epoch: 5| Step: 10
Training loss: 2.6807353496551514
Validation loss: 2.1604850240933

Epoch: 86| Step: 0
Training loss: 2.693382740020752
Validation loss: 2.1585026556445706

Epoch: 5| Step: 1
Training loss: 1.5841795206069946
Validation loss: 2.165243569240775

Epoch: 5| Step: 2
Training loss: 3.0575084686279297
Validation loss: 2.171194548247963

Epoch: 5| Step: 3
Training loss: 1.9840571880340576
Validation loss: 2.1705193468319472

Epoch: 5| Step: 4
Training loss: 2.0674808025360107
Validation loss: 2.1315388525685957

Epoch: 5| Step: 5
Training loss: 2.3160388469696045
Validation loss: 2.15476393699646

Epoch: 5| Step: 6
Training loss: 2.44724702835083
Validation loss: 2.1454853037352204

Epoch: 5| Step: 7
Training loss: 1.6403281688690186
Validation loss: 2.1682759818210395

Epoch: 5| Step: 8
Training loss: 2.8702893257141113
Validation loss: 2.155634977484262

Epoch: 5| Step: 9
Training loss: 1.9527902603149414
Validation loss: 2.16837901197454

Epoch: 5| Step: 10
Training loss: 2.622523784637451
Validation loss: 2.1793012849746214

Epoch: 87| Step: 0
Training loss: 2.2721359729766846
Validation loss: 2.173667341150263

Epoch: 5| Step: 1
Training loss: 3.049744129180908
Validation loss: 2.175735581305719

Epoch: 5| Step: 2
Training loss: 2.2310054302215576
Validation loss: 2.13973839693172

Epoch: 5| Step: 3
Training loss: 2.0710082054138184
Validation loss: 2.162629396684708

Epoch: 5| Step: 4
Training loss: 1.846808671951294
Validation loss: 2.16054012954876

Epoch: 5| Step: 5
Training loss: 2.092923879623413
Validation loss: 2.1784860857071413

Epoch: 5| Step: 6
Training loss: 2.248547077178955
Validation loss: 2.1742153295906643

Epoch: 5| Step: 7
Training loss: 2.035346746444702
Validation loss: 2.1541911812238794

Epoch: 5| Step: 8
Training loss: 1.971551537513733
Validation loss: 2.1737502954339467

Epoch: 5| Step: 9
Training loss: 3.1368954181671143
Validation loss: 2.185235596472217

Epoch: 5| Step: 10
Training loss: 2.4215335845947266
Validation loss: 2.1443288198081394

Epoch: 88| Step: 0
Training loss: 2.2711987495422363
Validation loss: 2.1731993921341433

Epoch: 5| Step: 1
Training loss: 2.377185583114624
Validation loss: 2.189636622705767

Epoch: 5| Step: 2
Training loss: 2.555344581604004
Validation loss: 2.176194642179756

Epoch: 5| Step: 3
Training loss: 1.676159143447876
Validation loss: 2.1632941397287513

Epoch: 5| Step: 4
Training loss: 2.073024272918701
Validation loss: 2.1441704021987094

Epoch: 5| Step: 5
Training loss: 2.3272061347961426
Validation loss: 2.1693544797999884

Epoch: 5| Step: 6
Training loss: 2.624453544616699
Validation loss: 2.1529630396955755

Epoch: 5| Step: 7
Training loss: 1.9403873682022095
Validation loss: 2.1663419328710085

Epoch: 5| Step: 8
Training loss: 2.8524208068847656
Validation loss: 2.175665642625542

Epoch: 5| Step: 9
Training loss: 2.253976821899414
Validation loss: 2.1640010033884356

Epoch: 5| Step: 10
Training loss: 2.197486400604248
Validation loss: 2.1336920786929388

Epoch: 89| Step: 0
Training loss: 2.161553144454956
Validation loss: 2.1579275541408087

Epoch: 5| Step: 1
Training loss: 2.1012582778930664
Validation loss: 2.158267955626211

Epoch: 5| Step: 2
Training loss: 2.445490598678589
Validation loss: 2.144493323500438

Epoch: 5| Step: 3
Training loss: 1.8188806772232056
Validation loss: 2.153496385902487

Epoch: 5| Step: 4
Training loss: 2.5904555320739746
Validation loss: 2.1462046792430263

Epoch: 5| Step: 5
Training loss: 2.0989434719085693
Validation loss: 2.155198017756144

Epoch: 5| Step: 6
Training loss: 2.568356513977051
Validation loss: 2.1576521447909776

Epoch: 5| Step: 7
Training loss: 2.1575310230255127
Validation loss: 2.156373372641943

Epoch: 5| Step: 8
Training loss: 2.3849456310272217
Validation loss: 2.1321909504552043

Epoch: 5| Step: 9
Training loss: 2.23067569732666
Validation loss: 2.1730063384579075

Epoch: 5| Step: 10
Training loss: 2.7304348945617676
Validation loss: 2.1493874044828516

Epoch: 90| Step: 0
Training loss: 2.859501361846924
Validation loss: 2.133172324908677

Epoch: 5| Step: 1
Training loss: 1.776516318321228
Validation loss: 2.1627318846282138

Epoch: 5| Step: 2
Training loss: 1.404892086982727
Validation loss: 2.115868733775231

Epoch: 5| Step: 3
Training loss: 2.646778106689453
Validation loss: 2.145327111726166

Epoch: 5| Step: 4
Training loss: 1.4233368635177612
Validation loss: 2.1520704941083024

Epoch: 5| Step: 5
Training loss: 2.2625069618225098
Validation loss: 2.1608297209585867

Epoch: 5| Step: 6
Training loss: 2.611039638519287
Validation loss: 2.156431346811274

Epoch: 5| Step: 7
Training loss: 3.070539712905884
Validation loss: 2.157871941084503

Epoch: 5| Step: 8
Training loss: 2.349602460861206
Validation loss: 2.1515891526335027

Epoch: 5| Step: 9
Training loss: 2.5510706901550293
Validation loss: 2.1532631356229066

Epoch: 5| Step: 10
Training loss: 2.2671494483947754
Validation loss: 2.1717730927210983

Epoch: 91| Step: 0
Training loss: 3.1926231384277344
Validation loss: 2.1562791562849477

Epoch: 5| Step: 1
Training loss: 2.8252949714660645
Validation loss: 2.204899359774846

Epoch: 5| Step: 2
Training loss: 2.4903407096862793
Validation loss: 2.162175347728114

Epoch: 5| Step: 3
Training loss: 1.9495900869369507
Validation loss: 2.1621285997411257

Epoch: 5| Step: 4
Training loss: 2.0544283390045166
Validation loss: 2.1453789152124876

Epoch: 5| Step: 5
Training loss: 2.6790099143981934
Validation loss: 2.169591265340005

Epoch: 5| Step: 6
Training loss: 2.0438668727874756
Validation loss: 2.151288419641474

Epoch: 5| Step: 7
Training loss: 2.639253616333008
Validation loss: 2.1578015588944957

Epoch: 5| Step: 8
Training loss: 1.726845145225525
Validation loss: 2.1653335017542683

Epoch: 5| Step: 9
Training loss: 1.570336103439331
Validation loss: 2.161579109007312

Epoch: 5| Step: 10
Training loss: 2.1374967098236084
Validation loss: 2.177696445936798

Epoch: 92| Step: 0
Training loss: 2.077693462371826
Validation loss: 2.1589235310913413

Epoch: 5| Step: 1
Training loss: 2.6496615409851074
Validation loss: 2.1867031435812674

Epoch: 5| Step: 2
Training loss: 2.1439404487609863
Validation loss: 2.1597755339837845

Epoch: 5| Step: 3
Training loss: 1.9722042083740234
Validation loss: 2.132556785819351

Epoch: 5| Step: 4
Training loss: 1.859533667564392
Validation loss: 2.1917893937838975

Epoch: 5| Step: 5
Training loss: 2.6245334148406982
Validation loss: 2.1582641870744768

Epoch: 5| Step: 6
Training loss: 2.574422836303711
Validation loss: 2.161336637312366

Epoch: 5| Step: 7
Training loss: 1.872951865196228
Validation loss: 2.139457848764235

Epoch: 5| Step: 8
Training loss: 2.078800916671753
Validation loss: 2.1491814326214533

Epoch: 5| Step: 9
Training loss: 2.9894278049468994
Validation loss: 2.172833484988059

Epoch: 5| Step: 10
Training loss: 2.1617956161499023
Validation loss: 2.149454701331354

Epoch: 93| Step: 0
Training loss: 1.9114387035369873
Validation loss: 2.180274583960092

Epoch: 5| Step: 1
Training loss: 2.286196708679199
Validation loss: 2.160729269827566

Epoch: 5| Step: 2
Training loss: 2.114779233932495
Validation loss: 2.1615150897733626

Epoch: 5| Step: 3
Training loss: 2.2689318656921387
Validation loss: 2.129206677918793

Epoch: 5| Step: 4
Training loss: 2.3236992359161377
Validation loss: 2.1333569813800115

Epoch: 5| Step: 5
Training loss: 2.4333224296569824
Validation loss: 2.161997446449854

Epoch: 5| Step: 6
Training loss: 2.9013686180114746
Validation loss: 2.1506755352020264

Epoch: 5| Step: 7
Training loss: 1.8345022201538086
Validation loss: 2.1517897882769184

Epoch: 5| Step: 8
Training loss: 3.125746965408325
Validation loss: 2.1288324556043072

Epoch: 5| Step: 9
Training loss: 1.709244966506958
Validation loss: 2.1817307754229476

Epoch: 5| Step: 10
Training loss: 2.069998264312744
Validation loss: 2.1525711679971344

Epoch: 94| Step: 0
Training loss: 2.050421714782715
Validation loss: 2.1813817383140646

Epoch: 5| Step: 1
Training loss: 1.7661702632904053
Validation loss: 2.1609607383769047

Epoch: 5| Step: 2
Training loss: 2.5342438220977783
Validation loss: 2.14828005144673

Epoch: 5| Step: 3
Training loss: 1.5707030296325684
Validation loss: 2.156736445683305

Epoch: 5| Step: 4
Training loss: 2.3238613605499268
Validation loss: 2.158075160877679

Epoch: 5| Step: 5
Training loss: 2.017609119415283
Validation loss: 2.1593125148486068

Epoch: 5| Step: 6
Training loss: 2.301888942718506
Validation loss: 2.156095835470384

Epoch: 5| Step: 7
Training loss: 2.5157687664031982
Validation loss: 2.1403008045688754

Epoch: 5| Step: 8
Training loss: 2.789766311645508
Validation loss: 2.1819394455161145

Epoch: 5| Step: 9
Training loss: 2.3435752391815186
Validation loss: 2.1407452270548832

Epoch: 5| Step: 10
Training loss: 3.1492252349853516
Validation loss: 2.189706028148692

Epoch: 95| Step: 0
Training loss: 2.756873369216919
Validation loss: 2.1515671822332565

Epoch: 5| Step: 1
Training loss: 1.9628286361694336
Validation loss: 2.147453051741405

Epoch: 5| Step: 2
Training loss: 2.193725824356079
Validation loss: 2.140870463463568

Epoch: 5| Step: 3
Training loss: 1.8396475315093994
Validation loss: 2.1527311981365247

Epoch: 5| Step: 4
Training loss: 2.5235283374786377
Validation loss: 2.148421497755153

Epoch: 5| Step: 5
Training loss: 2.3160593509674072
Validation loss: 2.1554643710454306

Epoch: 5| Step: 6
Training loss: 1.9373674392700195
Validation loss: 2.1119112019897788

Epoch: 5| Step: 7
Training loss: 2.2798209190368652
Validation loss: 2.1550837665475826

Epoch: 5| Step: 8
Training loss: 2.33992600440979
Validation loss: 2.1598790409744426

Epoch: 5| Step: 9
Training loss: 2.5397584438323975
Validation loss: 2.164176671735702

Epoch: 5| Step: 10
Training loss: 2.4137325286865234
Validation loss: 2.1660476679443033

Epoch: 96| Step: 0
Training loss: 2.428295612335205
Validation loss: 2.1173832262715986

Epoch: 5| Step: 1
Training loss: 2.24762225151062
Validation loss: 2.147484781921551

Epoch: 5| Step: 2
Training loss: 2.4409453868865967
Validation loss: 2.1798367705396426

Epoch: 5| Step: 3
Training loss: 2.4350674152374268
Validation loss: 2.1343415014205442

Epoch: 5| Step: 4
Training loss: 2.193530559539795
Validation loss: 2.1539434066382785

Epoch: 5| Step: 5
Training loss: 1.899540662765503
Validation loss: 2.1494524914731263

Epoch: 5| Step: 6
Training loss: 1.8990657329559326
Validation loss: 2.1762321982332455

Epoch: 5| Step: 7
Training loss: 2.7665882110595703
Validation loss: 2.1522320931957615

Epoch: 5| Step: 8
Training loss: 2.594402551651001
Validation loss: 2.148338128161687

Epoch: 5| Step: 9
Training loss: 2.360877275466919
Validation loss: 2.1541509218113397

Epoch: 5| Step: 10
Training loss: 1.7891747951507568
Validation loss: 2.174260275338286

Epoch: 97| Step: 0
Training loss: 2.5089478492736816
Validation loss: 2.1751317029358237

Epoch: 5| Step: 1
Training loss: 2.202915668487549
Validation loss: 2.1613569413461993

Epoch: 5| Step: 2
Training loss: 2.2745938301086426
Validation loss: 2.175899395378687

Epoch: 5| Step: 3
Training loss: 2.3281188011169434
Validation loss: 2.186216236442648

Epoch: 5| Step: 4
Training loss: 2.6001358032226562
Validation loss: 2.1709123080776584

Epoch: 5| Step: 5
Training loss: 2.2814605236053467
Validation loss: 2.1782577294175343

Epoch: 5| Step: 6
Training loss: 2.074852705001831
Validation loss: 2.1512430175658195

Epoch: 5| Step: 7
Training loss: 2.677786350250244
Validation loss: 2.19223343172381

Epoch: 5| Step: 8
Training loss: 2.512457847595215
Validation loss: 2.19785475730896

Epoch: 5| Step: 9
Training loss: 2.118602752685547
Validation loss: 2.1750415525128766

Epoch: 5| Step: 10
Training loss: 1.489672303199768
Validation loss: 2.1607552997527586

Epoch: 98| Step: 0
Training loss: 2.458725690841675
Validation loss: 2.166159724676481

Epoch: 5| Step: 1
Training loss: 2.0722382068634033
Validation loss: 2.196860700525263

Epoch: 5| Step: 2
Training loss: 2.9629578590393066
Validation loss: 2.1727324993379655

Epoch: 5| Step: 3
Training loss: 2.182257890701294
Validation loss: 2.1669646206722466

Epoch: 5| Step: 4
Training loss: 2.52645206451416
Validation loss: 2.159120903220228

Epoch: 5| Step: 5
Training loss: 2.1182239055633545
Validation loss: 2.187651321452151

Epoch: 5| Step: 6
Training loss: 1.962563157081604
Validation loss: 2.1855967660104074

Epoch: 5| Step: 7
Training loss: 2.333829164505005
Validation loss: 2.2043212075387277

Epoch: 5| Step: 8
Training loss: 1.875030279159546
Validation loss: 2.1524668021868636

Epoch: 5| Step: 9
Training loss: 2.448861598968506
Validation loss: 2.160322771277479

Epoch: 5| Step: 10
Training loss: 2.203906774520874
Validation loss: 2.1548373750461045

Epoch: 99| Step: 0
Training loss: 1.9328054189682007
Validation loss: 2.1706335800950245

Epoch: 5| Step: 1
Training loss: 1.7007452249526978
Validation loss: 2.136566759437643

Epoch: 5| Step: 2
Training loss: 1.733039140701294
Validation loss: 2.1510867021417104

Epoch: 5| Step: 3
Training loss: 2.2672197818756104
Validation loss: 2.163522840828024

Epoch: 5| Step: 4
Training loss: 2.403836250305176
Validation loss: 2.1673862062474734

Epoch: 5| Step: 5
Training loss: 2.094536542892456
Validation loss: 2.122700574577496

Epoch: 5| Step: 6
Training loss: 2.438554048538208
Validation loss: 2.1689643988045315

Epoch: 5| Step: 7
Training loss: 2.0239884853363037
Validation loss: 2.167004516047816

Epoch: 5| Step: 8
Training loss: 2.8745369911193848
Validation loss: 2.1526126002752655

Epoch: 5| Step: 9
Training loss: 2.731131076812744
Validation loss: 2.148686703815255

Epoch: 5| Step: 10
Training loss: 3.114231586456299
Validation loss: 2.188725450987457

Epoch: 100| Step: 0
Training loss: 1.7302696704864502
Validation loss: 2.1640135908639557

Epoch: 5| Step: 1
Training loss: 2.043483018875122
Validation loss: 2.1419956273930048

Epoch: 5| Step: 2
Training loss: 1.7590259313583374
Validation loss: 2.1682887897696546

Epoch: 5| Step: 3
Training loss: 2.6454479694366455
Validation loss: 2.1743609725788073

Epoch: 5| Step: 4
Training loss: 2.705660104751587
Validation loss: 2.1809054215749106

Epoch: 5| Step: 5
Training loss: 2.275299549102783
Validation loss: 2.175961540591332

Epoch: 5| Step: 6
Training loss: 2.218524694442749
Validation loss: 2.15302001789052

Epoch: 5| Step: 7
Training loss: 2.083099842071533
Validation loss: 2.1429240626673542

Epoch: 5| Step: 8
Training loss: 2.913283586502075
Validation loss: 2.14274235181911

Epoch: 5| Step: 9
Training loss: 1.9906766414642334
Validation loss: 2.176399582175798

Epoch: 5| Step: 10
Training loss: 2.6718575954437256
Validation loss: 2.162740066487302

Epoch: 101| Step: 0
Training loss: 2.633098840713501
Validation loss: 2.144159152943601

Epoch: 5| Step: 1
Training loss: 2.636428117752075
Validation loss: 2.1327593249659382

Epoch: 5| Step: 2
Training loss: 2.1262521743774414
Validation loss: 2.1416649562056347

Epoch: 5| Step: 3
Training loss: 2.424132823944092
Validation loss: 2.171755116472962

Epoch: 5| Step: 4
Training loss: 2.72512149810791
Validation loss: 2.1595235434911584

Epoch: 5| Step: 5
Training loss: 1.7293516397476196
Validation loss: 2.185847818210561

Epoch: 5| Step: 6
Training loss: 2.5032105445861816
Validation loss: 2.1564009625424623

Epoch: 5| Step: 7
Training loss: 1.8466670513153076
Validation loss: 2.1482720862152758

Epoch: 5| Step: 8
Training loss: 2.1269335746765137
Validation loss: 2.189638060908164

Epoch: 5| Step: 9
Training loss: 1.7343213558197021
Validation loss: 2.1658438380046556

Epoch: 5| Step: 10
Training loss: 2.6620852947235107
Validation loss: 2.1815856566993137

Epoch: 102| Step: 0
Training loss: 2.470376968383789
Validation loss: 2.1717400191932597

Epoch: 5| Step: 1
Training loss: 2.0098066329956055
Validation loss: 2.16891743803537

Epoch: 5| Step: 2
Training loss: 2.486557722091675
Validation loss: 2.1541194146679294

Epoch: 5| Step: 3
Training loss: 2.08262300491333
Validation loss: 2.134423153374785

Epoch: 5| Step: 4
Training loss: 2.1664950847625732
Validation loss: 2.1667394330424647

Epoch: 5| Step: 5
Training loss: 2.049936294555664
Validation loss: 2.1679072251883884

Epoch: 5| Step: 6
Training loss: 2.10636568069458
Validation loss: 2.170322923250096

Epoch: 5| Step: 7
Training loss: 2.546868324279785
Validation loss: 2.147508877579884

Epoch: 5| Step: 8
Training loss: 2.9811618328094482
Validation loss: 2.2028792673541653

Epoch: 5| Step: 9
Training loss: 1.943982720375061
Validation loss: 2.1368165400720414

Epoch: 5| Step: 10
Training loss: 2.263773202896118
Validation loss: 2.1880173503711657

Epoch: 103| Step: 0
Training loss: 2.2289316654205322
Validation loss: 2.167875918008948

Epoch: 5| Step: 1
Training loss: 2.6041972637176514
Validation loss: 2.187393243594836

Epoch: 5| Step: 2
Training loss: 2.1499736309051514
Validation loss: 2.18267999669557

Epoch: 5| Step: 3
Training loss: 2.3243608474731445
Validation loss: 2.167233851648146

Epoch: 5| Step: 4
Training loss: 2.22871732711792
Validation loss: 2.180729822445941

Epoch: 5| Step: 5
Training loss: 2.2961838245391846
Validation loss: 2.1642096965543685

Epoch: 5| Step: 6
Training loss: 2.030735492706299
Validation loss: 2.1856918847689064

Epoch: 5| Step: 7
Training loss: 2.8923492431640625
Validation loss: 2.180368418334633

Epoch: 5| Step: 8
Training loss: 1.9500939846038818
Validation loss: 2.1559247586034958

Epoch: 5| Step: 9
Training loss: 2.616008996963501
Validation loss: 2.1999850632042013

Epoch: 5| Step: 10
Training loss: 1.6910220384597778
Validation loss: 2.212437216953565

Epoch: 104| Step: 0
Training loss: 2.304800271987915
Validation loss: 2.1629116535186768

Epoch: 5| Step: 1
Training loss: 2.853389263153076
Validation loss: 2.1888244293069326

Epoch: 5| Step: 2
Training loss: 2.189793109893799
Validation loss: 2.189888624734776

Epoch: 5| Step: 3
Training loss: 2.272477865219116
Validation loss: 2.185484714405511

Epoch: 5| Step: 4
Training loss: 2.747824192047119
Validation loss: 2.1713054641600578

Epoch: 5| Step: 5
Training loss: 2.182884693145752
Validation loss: 2.20300539078251

Epoch: 5| Step: 6
Training loss: 2.3486592769622803
Validation loss: 2.1917572175302813

Epoch: 5| Step: 7
Training loss: 2.2183268070220947
Validation loss: 2.221007218924902

Epoch: 5| Step: 8
Training loss: 1.410278558731079
Validation loss: 2.1961908442999727

Epoch: 5| Step: 9
Training loss: 2.227796792984009
Validation loss: 2.1942963702704317

Epoch: 5| Step: 10
Training loss: 2.2198822498321533
Validation loss: 2.1905776864738873

Epoch: 105| Step: 0
Training loss: 1.9347041845321655
Validation loss: 2.219683624082996

Epoch: 5| Step: 1
Training loss: 2.4021518230438232
Validation loss: 2.1660672515951176

Epoch: 5| Step: 2
Training loss: 2.2982914447784424
Validation loss: 2.1817497925091813

Epoch: 5| Step: 3
Training loss: 1.7535221576690674
Validation loss: 2.201818302113523

Epoch: 5| Step: 4
Training loss: 2.7795767784118652
Validation loss: 2.1780592959414244

Epoch: 5| Step: 5
Training loss: 2.262848377227783
Validation loss: 2.1815604535482263

Epoch: 5| Step: 6
Training loss: 2.1498632431030273
Validation loss: 2.1687336532018517

Epoch: 5| Step: 7
Training loss: 1.901759147644043
Validation loss: 2.1823335001545567

Epoch: 5| Step: 8
Training loss: 2.5191650390625
Validation loss: 2.1500485609936457

Epoch: 5| Step: 9
Training loss: 2.2365059852600098
Validation loss: 2.139089709968977

Epoch: 5| Step: 10
Training loss: 3.088940382003784
Validation loss: 2.193940701023225

Epoch: 106| Step: 0
Training loss: 2.0392165184020996
Validation loss: 2.1679041872742357

Epoch: 5| Step: 1
Training loss: 2.32147479057312
Validation loss: 2.158233147795482

Epoch: 5| Step: 2
Training loss: 1.9211326837539673
Validation loss: 2.1849444617507277

Epoch: 5| Step: 3
Training loss: 1.9863805770874023
Validation loss: 2.1498153466050343

Epoch: 5| Step: 4
Training loss: 2.8459339141845703
Validation loss: 2.1633813740104757

Epoch: 5| Step: 5
Training loss: 2.6820759773254395
Validation loss: 2.1594742190453315

Epoch: 5| Step: 6
Training loss: 1.6904903650283813
Validation loss: 2.162662631721907

Epoch: 5| Step: 7
Training loss: 2.6053354740142822
Validation loss: 2.1662729581197104

Epoch: 5| Step: 8
Training loss: 1.5875041484832764
Validation loss: 2.1722229821707613

Epoch: 5| Step: 9
Training loss: 2.5518901348114014
Validation loss: 2.1440614141443723

Epoch: 5| Step: 10
Training loss: 2.56634259223938
Validation loss: 2.1830480098724365

Epoch: 107| Step: 0
Training loss: 2.2594666481018066
Validation loss: 2.1703104357565604

Epoch: 5| Step: 1
Training loss: 1.5041991472244263
Validation loss: 2.140120606268606

Epoch: 5| Step: 2
Training loss: 2.1827266216278076
Validation loss: 2.1718933082395986

Epoch: 5| Step: 3
Training loss: 2.2260053157806396
Validation loss: 2.139665893329087

Epoch: 5| Step: 4
Training loss: 1.94794499874115
Validation loss: 2.1625663977797314

Epoch: 5| Step: 5
Training loss: 2.178956985473633
Validation loss: 2.175276164085634

Epoch: 5| Step: 6
Training loss: 2.391814708709717
Validation loss: 2.137982006995909

Epoch: 5| Step: 7
Training loss: 2.504518747329712
Validation loss: 2.2020877920171267

Epoch: 5| Step: 8
Training loss: 2.2846198081970215
Validation loss: 2.186122594341155

Epoch: 5| Step: 9
Training loss: 3.137178421020508
Validation loss: 2.1727883033854987

Epoch: 5| Step: 10
Training loss: 2.2374608516693115
Validation loss: 2.155568443318849

Epoch: 108| Step: 0
Training loss: 2.3345837593078613
Validation loss: 2.176205663270848

Epoch: 5| Step: 1
Training loss: 2.326676845550537
Validation loss: 2.170464192667315

Epoch: 5| Step: 2
Training loss: 2.197225570678711
Validation loss: 2.194991530910615

Epoch: 5| Step: 3
Training loss: 1.50709867477417
Validation loss: 2.1549463502822386

Epoch: 5| Step: 4
Training loss: 1.6171541213989258
Validation loss: 2.1553384270719302

Epoch: 5| Step: 5
Training loss: 2.209566593170166
Validation loss: 2.1771753962321947

Epoch: 5| Step: 6
Training loss: 2.78691029548645
Validation loss: 2.1946451343515867

Epoch: 5| Step: 7
Training loss: 1.848995566368103
Validation loss: 2.1804675132997575

Epoch: 5| Step: 8
Training loss: 3.3663687705993652
Validation loss: 2.154460600627366

Epoch: 5| Step: 9
Training loss: 2.48796010017395
Validation loss: 2.1718520695163357

Epoch: 5| Step: 10
Training loss: 2.1896274089813232
Validation loss: 2.187812776975734

Epoch: 109| Step: 0
Training loss: 1.832662582397461
Validation loss: 2.193622666020547

Epoch: 5| Step: 1
Training loss: 2.1587533950805664
Validation loss: 2.1517998864573817

Epoch: 5| Step: 2
Training loss: 1.8395010232925415
Validation loss: 2.173509442678062

Epoch: 5| Step: 3
Training loss: 2.9287123680114746
Validation loss: 2.194409055094565

Epoch: 5| Step: 4
Training loss: 2.3524043560028076
Validation loss: 2.1570585466200307

Epoch: 5| Step: 5
Training loss: 2.523080587387085
Validation loss: 2.158759408099677

Epoch: 5| Step: 6
Training loss: 1.5319435596466064
Validation loss: 2.15326553006326

Epoch: 5| Step: 7
Training loss: 2.428952693939209
Validation loss: 2.189819082137077

Epoch: 5| Step: 8
Training loss: 2.1134791374206543
Validation loss: 2.185781596809305

Epoch: 5| Step: 9
Training loss: 2.4554264545440674
Validation loss: 2.192662810766569

Epoch: 5| Step: 10
Training loss: 2.8874495029449463
Validation loss: 2.1763013344939037

Epoch: 110| Step: 0
Training loss: 2.0670955181121826
Validation loss: 2.165098487689931

Epoch: 5| Step: 1
Training loss: 2.65317702293396
Validation loss: 2.173191467920939

Epoch: 5| Step: 2
Training loss: 2.7652459144592285
Validation loss: 2.173073499433456

Epoch: 5| Step: 3
Training loss: 2.345526933670044
Validation loss: 2.1528771179978565

Epoch: 5| Step: 4
Training loss: 2.0559651851654053
Validation loss: 2.1619472375480075

Epoch: 5| Step: 5
Training loss: 2.302083969116211
Validation loss: 2.1513331013341106

Epoch: 5| Step: 6
Training loss: 2.0818142890930176
Validation loss: 2.17790747457935

Epoch: 5| Step: 7
Training loss: 2.1751625537872314
Validation loss: 2.178889233578918

Epoch: 5| Step: 8
Training loss: 2.3099615573883057
Validation loss: 2.1968833002992856

Epoch: 5| Step: 9
Training loss: 1.9083744287490845
Validation loss: 2.167684446098984

Epoch: 5| Step: 10
Training loss: 2.3875858783721924
Validation loss: 2.1703072645330943

Epoch: 111| Step: 0
Training loss: 2.5086143016815186
Validation loss: 2.1631291348447084

Epoch: 5| Step: 1
Training loss: 1.6188151836395264
Validation loss: 2.183651816460394

Epoch: 5| Step: 2
Training loss: 1.9071197509765625
Validation loss: 2.1650323278160504

Epoch: 5| Step: 3
Training loss: 2.550616502761841
Validation loss: 2.186071306146601

Epoch: 5| Step: 4
Training loss: 2.708599090576172
Validation loss: 2.192041176621632

Epoch: 5| Step: 5
Training loss: 1.5863616466522217
Validation loss: 2.182915233796643

Epoch: 5| Step: 6
Training loss: 3.04484224319458
Validation loss: 2.175690620176254

Epoch: 5| Step: 7
Training loss: 2.3473918437957764
Validation loss: 2.164764299187609

Epoch: 5| Step: 8
Training loss: 2.8887696266174316
Validation loss: 2.120124150347966

Epoch: 5| Step: 9
Training loss: 2.115835666656494
Validation loss: 2.1641603849267446

Epoch: 5| Step: 10
Training loss: 1.6210447549819946
Validation loss: 2.150955469377579

Epoch: 112| Step: 0
Training loss: 1.7923946380615234
Validation loss: 2.1865092310854184

Epoch: 5| Step: 1
Training loss: 2.906670331954956
Validation loss: 2.228211933566678

Epoch: 5| Step: 2
Training loss: 2.1786158084869385
Validation loss: 2.1796460766946115

Epoch: 5| Step: 3
Training loss: 2.655082941055298
Validation loss: 2.1512637804913264

Epoch: 5| Step: 4
Training loss: 1.834072470664978
Validation loss: 2.193997138289995

Epoch: 5| Step: 5
Training loss: 2.526480197906494
Validation loss: 2.161076194496565

Epoch: 5| Step: 6
Training loss: 2.0575623512268066
Validation loss: 2.161444433273808

Epoch: 5| Step: 7
Training loss: 1.943716049194336
Validation loss: 2.1562139218853367

Epoch: 5| Step: 8
Training loss: 2.8922219276428223
Validation loss: 2.174114291385938

Epoch: 5| Step: 9
Training loss: 2.105518341064453
Validation loss: 2.153966316612818

Epoch: 5| Step: 10
Training loss: 1.8993003368377686
Validation loss: 2.161680239503102

Epoch: 113| Step: 0
Training loss: 1.9703747034072876
Validation loss: 2.153422306942683

Epoch: 5| Step: 1
Training loss: 2.2519664764404297
Validation loss: 2.1738364004319712

Epoch: 5| Step: 2
Training loss: 2.1916308403015137
Validation loss: 2.1788621000064317

Epoch: 5| Step: 3
Training loss: 2.7919185161590576
Validation loss: 2.1814097871062574

Epoch: 5| Step: 4
Training loss: 2.8548738956451416
Validation loss: 2.2065904666018743

Epoch: 5| Step: 5
Training loss: 2.4561378955841064
Validation loss: 2.1422793044838855

Epoch: 5| Step: 6
Training loss: 1.965844750404358
Validation loss: 2.1772910189884964

Epoch: 5| Step: 7
Training loss: 1.8251845836639404
Validation loss: 2.1645156414278093

Epoch: 5| Step: 8
Training loss: 2.041762113571167
Validation loss: 2.176388435466315

Epoch: 5| Step: 9
Training loss: 2.569805860519409
Validation loss: 2.1670810355935046

Epoch: 5| Step: 10
Training loss: 1.8177392482757568
Validation loss: 2.20470513579666

Epoch: 114| Step: 0
Training loss: 3.0178444385528564
Validation loss: 2.1966390596923007

Epoch: 5| Step: 1
Training loss: 2.42802095413208
Validation loss: 2.1793917712344917

Epoch: 5| Step: 2
Training loss: 2.1374754905700684
Validation loss: 2.176992154890491

Epoch: 5| Step: 3
Training loss: 1.3722412586212158
Validation loss: 2.173254354025728

Epoch: 5| Step: 4
Training loss: 2.1508257389068604
Validation loss: 2.1416969094225156

Epoch: 5| Step: 5
Training loss: 2.5978829860687256
Validation loss: 2.177314199427123

Epoch: 5| Step: 6
Training loss: 2.2947726249694824
Validation loss: 2.153380009435838

Epoch: 5| Step: 7
Training loss: 2.586292028427124
Validation loss: 2.182983434328469

Epoch: 5| Step: 8
Training loss: 2.1109297275543213
Validation loss: 2.1618690926541566

Epoch: 5| Step: 9
Training loss: 1.954708456993103
Validation loss: 2.1616499500889934

Epoch: 5| Step: 10
Training loss: 2.1745822429656982
Validation loss: 2.1826734440301054

Epoch: 115| Step: 0
Training loss: 1.9326183795928955
Validation loss: 2.125781464320357

Epoch: 5| Step: 1
Training loss: 2.462883472442627
Validation loss: 2.1866556803385415

Epoch: 5| Step: 2
Training loss: 1.8645741939544678
Validation loss: 2.119931654263568

Epoch: 5| Step: 3
Training loss: 1.922703504562378
Validation loss: 2.188906623471168

Epoch: 5| Step: 4
Training loss: 3.1063780784606934
Validation loss: 2.160977566114036

Epoch: 5| Step: 5
Training loss: 2.503392457962036
Validation loss: 2.1463309052169963

Epoch: 5| Step: 6
Training loss: 1.7831491231918335
Validation loss: 2.131627990353492

Epoch: 5| Step: 7
Training loss: 1.8264083862304688
Validation loss: 2.15249026590778

Epoch: 5| Step: 8
Training loss: 2.1194729804992676
Validation loss: 2.1263446820679532

Epoch: 5| Step: 9
Training loss: 3.022752523422241
Validation loss: 2.131024824675693

Epoch: 5| Step: 10
Training loss: 2.3470966815948486
Validation loss: 2.153039441313795

Epoch: 116| Step: 0
Training loss: 2.0579750537872314
Validation loss: 2.1288708730410506

Epoch: 5| Step: 1
Training loss: 2.511807918548584
Validation loss: 2.1899428367614746

Epoch: 5| Step: 2
Training loss: 2.671560764312744
Validation loss: 2.145050020628078

Epoch: 5| Step: 3
Training loss: 1.9647325277328491
Validation loss: 2.1704607368797384

Epoch: 5| Step: 4
Training loss: 2.638042688369751
Validation loss: 2.1758133724171627

Epoch: 5| Step: 5
Training loss: 2.344160556793213
Validation loss: 2.15978088173815

Epoch: 5| Step: 6
Training loss: 2.2230300903320312
Validation loss: 2.1502056762736332

Epoch: 5| Step: 7
Training loss: 1.6647980213165283
Validation loss: 2.1670657819317234

Epoch: 5| Step: 8
Training loss: 2.292086362838745
Validation loss: 2.157106634109251

Epoch: 5| Step: 9
Training loss: 2.5223679542541504
Validation loss: 2.1555492903596614

Epoch: 5| Step: 10
Training loss: 2.318349838256836
Validation loss: 2.1877865317047283

Epoch: 117| Step: 0
Training loss: 2.52354097366333
Validation loss: 2.170862054312101

Epoch: 5| Step: 1
Training loss: 2.7707431316375732
Validation loss: 2.1858777576877224

Epoch: 5| Step: 2
Training loss: 2.4172425270080566
Validation loss: 2.1627159400652816

Epoch: 5| Step: 3
Training loss: 1.493786096572876
Validation loss: 2.1589603706072737

Epoch: 5| Step: 4
Training loss: 2.148895740509033
Validation loss: 2.176743063875424

Epoch: 5| Step: 5
Training loss: 1.8690944910049438
Validation loss: 2.1637457083630305

Epoch: 5| Step: 6
Training loss: 1.9277915954589844
Validation loss: 2.1750025159569195

Epoch: 5| Step: 7
Training loss: 2.04709792137146
Validation loss: 2.192076131861697

Epoch: 5| Step: 8
Training loss: 2.3465471267700195
Validation loss: 2.1793451206658476

Epoch: 5| Step: 9
Training loss: 2.2095999717712402
Validation loss: 2.200302034296015

Epoch: 5| Step: 10
Training loss: 3.2676539421081543
Validation loss: 2.1709544607388076

Epoch: 118| Step: 0
Training loss: 2.0229620933532715
Validation loss: 2.1674047836693386

Epoch: 5| Step: 1
Training loss: 2.0515947341918945
Validation loss: 2.193435001116927

Epoch: 5| Step: 2
Training loss: 2.4154715538024902
Validation loss: 2.17543266921915

Epoch: 5| Step: 3
Training loss: 1.6247539520263672
Validation loss: 2.1728941599527993

Epoch: 5| Step: 4
Training loss: 1.9571201801300049
Validation loss: 2.1383696089508715

Epoch: 5| Step: 5
Training loss: 2.4586987495422363
Validation loss: 2.159258031076001

Epoch: 5| Step: 6
Training loss: 2.4018619060516357
Validation loss: 2.1730721330129974

Epoch: 5| Step: 7
Training loss: 2.0319855213165283
Validation loss: 2.182823796426096

Epoch: 5| Step: 8
Training loss: 2.565171718597412
Validation loss: 2.1796405648672454

Epoch: 5| Step: 9
Training loss: 3.0985710620880127
Validation loss: 2.1597250328269055

Epoch: 5| Step: 10
Training loss: 2.0522959232330322
Validation loss: 2.1735640495054183

Epoch: 119| Step: 0
Training loss: 1.8937339782714844
Validation loss: 2.1357353964159564

Epoch: 5| Step: 1
Training loss: 2.7846813201904297
Validation loss: 2.189870265222365

Epoch: 5| Step: 2
Training loss: 2.6148571968078613
Validation loss: 2.175650074917783

Epoch: 5| Step: 3
Training loss: 1.9100620746612549
Validation loss: 2.1361796881562922

Epoch: 5| Step: 4
Training loss: 2.251521110534668
Validation loss: 2.1546563563808316

Epoch: 5| Step: 5
Training loss: 2.1304662227630615
Validation loss: 2.155999101618285

Epoch: 5| Step: 6
Training loss: 2.351280689239502
Validation loss: 2.196799309022965

Epoch: 5| Step: 7
Training loss: 2.4941248893737793
Validation loss: 2.164945281961913

Epoch: 5| Step: 8
Training loss: 1.5369479656219482
Validation loss: 2.1587279278744935

Epoch: 5| Step: 9
Training loss: 1.8491239547729492
Validation loss: 2.210877074990221

Epoch: 5| Step: 10
Training loss: 2.99581241607666
Validation loss: 2.1630549738484044

Epoch: 120| Step: 0
Training loss: 2.5612428188323975
Validation loss: 2.1473275538413756

Epoch: 5| Step: 1
Training loss: 2.0174224376678467
Validation loss: 2.1640699396851244

Epoch: 5| Step: 2
Training loss: 2.092968702316284
Validation loss: 2.163401578062324

Epoch: 5| Step: 3
Training loss: 2.1785783767700195
Validation loss: 2.180006621986307

Epoch: 5| Step: 4
Training loss: 2.2625250816345215
Validation loss: 2.1964290065150105

Epoch: 5| Step: 5
Training loss: 1.8285605907440186
Validation loss: 2.199174302880482

Epoch: 5| Step: 6
Training loss: 1.9138962030410767
Validation loss: 2.218202596069664

Epoch: 5| Step: 7
Training loss: 2.0995161533355713
Validation loss: 2.1865423071768975

Epoch: 5| Step: 8
Training loss: 2.247967004776001
Validation loss: 2.165545096961401

Epoch: 5| Step: 9
Training loss: 2.864417314529419
Validation loss: 2.171904886922529

Epoch: 5| Step: 10
Training loss: 2.729762554168701
Validation loss: 2.1853163139794463

Epoch: 121| Step: 0
Training loss: 2.4865174293518066
Validation loss: 2.2157259859064573

Epoch: 5| Step: 1
Training loss: 2.2824013233184814
Validation loss: 2.183068703579646

Epoch: 5| Step: 2
Training loss: 2.1879851818084717
Validation loss: 2.1867337406322522

Epoch: 5| Step: 3
Training loss: 2.1441919803619385
Validation loss: 2.1953075355099094

Epoch: 5| Step: 4
Training loss: 2.3516488075256348
Validation loss: 2.212276247239882

Epoch: 5| Step: 5
Training loss: 2.5490596294403076
Validation loss: 2.1847411765847156

Epoch: 5| Step: 6
Training loss: 2.002502679824829
Validation loss: 2.177548793054396

Epoch: 5| Step: 7
Training loss: 2.5634758472442627
Validation loss: 2.188811012493667

Epoch: 5| Step: 8
Training loss: 1.8575966358184814
Validation loss: 2.218913673072733

Epoch: 5| Step: 9
Training loss: 2.4539284706115723
Validation loss: 2.217283889811526

Epoch: 5| Step: 10
Training loss: 1.7507569789886475
Validation loss: 2.200326491427678

Epoch: 122| Step: 0
Training loss: 2.3303089141845703
Validation loss: 2.19387383871181

Epoch: 5| Step: 1
Training loss: 2.7681477069854736
Validation loss: 2.183462837690948

Epoch: 5| Step: 2
Training loss: 1.9226577281951904
Validation loss: 2.1640193385462605

Epoch: 5| Step: 3
Training loss: 1.5963596105575562
Validation loss: 2.154725597750756

Epoch: 5| Step: 4
Training loss: 1.7662512063980103
Validation loss: 2.17524625409034

Epoch: 5| Step: 5
Training loss: 2.922929048538208
Validation loss: 2.1583350678925872

Epoch: 5| Step: 6
Training loss: 2.5543951988220215
Validation loss: 2.169053339189099

Epoch: 5| Step: 7
Training loss: 2.055102825164795
Validation loss: 2.143222539655624

Epoch: 5| Step: 8
Training loss: 2.2041878700256348
Validation loss: 2.174759370024486

Epoch: 5| Step: 9
Training loss: 2.250563859939575
Validation loss: 2.2005604928539646

Epoch: 5| Step: 10
Training loss: 2.622145652770996
Validation loss: 2.1682999839064894

Epoch: 123| Step: 0
Training loss: 2.2684292793273926
Validation loss: 2.159088924366941

Epoch: 5| Step: 1
Training loss: 2.0605921745300293
Validation loss: 2.1763998769944712

Epoch: 5| Step: 2
Training loss: 2.4478821754455566
Validation loss: 2.150661360832953

Epoch: 5| Step: 3
Training loss: 2.76741623878479
Validation loss: 2.1812595218740483

Epoch: 5| Step: 4
Training loss: 1.6742805242538452
Validation loss: 2.1702684510138726

Epoch: 5| Step: 5
Training loss: 2.6934382915496826
Validation loss: 2.1782348130338933

Epoch: 5| Step: 6
Training loss: 2.4141499996185303
Validation loss: 2.1908801832506732

Epoch: 5| Step: 7
Training loss: 1.8092635869979858
Validation loss: 2.175974231894298

Epoch: 5| Step: 8
Training loss: 2.0229697227478027
Validation loss: 2.1495425265322448

Epoch: 5| Step: 9
Training loss: 2.356070041656494
Validation loss: 2.1487070257945726

Epoch: 5| Step: 10
Training loss: 1.884539246559143
Validation loss: 2.164623578389486

Epoch: 124| Step: 0
Training loss: 2.126858949661255
Validation loss: 2.175840905917588

Epoch: 5| Step: 1
Training loss: 2.9774622917175293
Validation loss: 2.205363376166231

Epoch: 5| Step: 2
Training loss: 1.9422216415405273
Validation loss: 2.1696431726537724

Epoch: 5| Step: 3
Training loss: 2.2602195739746094
Validation loss: 2.1623674220936273

Epoch: 5| Step: 4
Training loss: 2.4957118034362793
Validation loss: 2.1700896729705152

Epoch: 5| Step: 5
Training loss: 1.961669921875
Validation loss: 2.1640164531687254

Epoch: 5| Step: 6
Training loss: 2.806889057159424
Validation loss: 2.19210103378501

Epoch: 5| Step: 7
Training loss: 2.243072509765625
Validation loss: 2.1807196371016966

Epoch: 5| Step: 8
Training loss: 2.40311861038208
Validation loss: 2.1575213542548557

Epoch: 5| Step: 9
Training loss: 2.2197914123535156
Validation loss: 2.1802579766960553

Epoch: 5| Step: 10
Training loss: 1.4302598237991333
Validation loss: 2.175180410826078

Epoch: 125| Step: 0
Training loss: 2.5774099826812744
Validation loss: 2.211985759837653

Epoch: 5| Step: 1
Training loss: 2.681875228881836
Validation loss: 2.1584183733950377

Epoch: 5| Step: 2
Training loss: 1.9360336065292358
Validation loss: 2.199198794621293

Epoch: 5| Step: 3
Training loss: 2.625882387161255
Validation loss: 2.1767455634250434

Epoch: 5| Step: 4
Training loss: 1.9119793176651
Validation loss: 2.2178205982331307

Epoch: 5| Step: 5
Training loss: 1.9802348613739014
Validation loss: 2.1630348966967676

Epoch: 5| Step: 6
Training loss: 2.2366995811462402
Validation loss: 2.1671678122653755

Epoch: 5| Step: 7
Training loss: 2.0564568042755127
Validation loss: 2.182139835050029

Epoch: 5| Step: 8
Training loss: 2.589878559112549
Validation loss: 2.190940700551515

Epoch: 5| Step: 9
Training loss: 1.9602868556976318
Validation loss: 2.1911839157022457

Epoch: 5| Step: 10
Training loss: 2.0385334491729736
Validation loss: 2.1885363760814873

Epoch: 126| Step: 0
Training loss: 2.0321462154388428
Validation loss: 2.1654688594161824

Epoch: 5| Step: 1
Training loss: 2.2365775108337402
Validation loss: 2.189821586813978

Epoch: 5| Step: 2
Training loss: 2.4342198371887207
Validation loss: 2.1763368127166585

Epoch: 5| Step: 3
Training loss: 2.435011863708496
Validation loss: 2.199536459420317

Epoch: 5| Step: 4
Training loss: 2.259901762008667
Validation loss: 2.203565723152571

Epoch: 5| Step: 5
Training loss: 1.9978199005126953
Validation loss: 2.198066985735329

Epoch: 5| Step: 6
Training loss: 2.786203384399414
Validation loss: 2.2010017005346154

Epoch: 5| Step: 7
Training loss: 1.8151938915252686
Validation loss: 2.183330830707345

Epoch: 5| Step: 8
Training loss: 2.461543083190918
Validation loss: 2.1724695441543416

Epoch: 5| Step: 9
Training loss: 2.641127109527588
Validation loss: 2.1708528713513444

Epoch: 5| Step: 10
Training loss: 1.3275190591812134
Validation loss: 2.157039442370015

Epoch: 127| Step: 0
Training loss: 2.4528846740722656
Validation loss: 2.1808958412498556

Epoch: 5| Step: 1
Training loss: 2.7078657150268555
Validation loss: 2.1882599258935578

Epoch: 5| Step: 2
Training loss: 2.2652244567871094
Validation loss: 2.197266358201222

Epoch: 5| Step: 3
Training loss: 1.8353313207626343
Validation loss: 2.198035168391402

Epoch: 5| Step: 4
Training loss: 2.06803035736084
Validation loss: 2.178697201513475

Epoch: 5| Step: 5
Training loss: 2.146902561187744
Validation loss: 2.200792097276257

Epoch: 5| Step: 6
Training loss: 2.3022327423095703
Validation loss: 2.147887099173761

Epoch: 5| Step: 7
Training loss: 2.4356284141540527
Validation loss: 2.178600613788892

Epoch: 5| Step: 8
Training loss: 2.184925079345703
Validation loss: 2.1472153868726505

Epoch: 5| Step: 9
Training loss: 1.7102940082550049
Validation loss: 2.142236219939365

Epoch: 5| Step: 10
Training loss: 2.420088052749634
Validation loss: 2.1750457004834245

Epoch: 128| Step: 0
Training loss: 2.0606133937835693
Validation loss: 2.182524663145824

Epoch: 5| Step: 1
Training loss: 1.8801944255828857
Validation loss: 2.1399619989497687

Epoch: 5| Step: 2
Training loss: 2.756617546081543
Validation loss: 2.1937345022796304

Epoch: 5| Step: 3
Training loss: 2.0170133113861084
Validation loss: 2.1669161883733605

Epoch: 5| Step: 4
Training loss: 2.3800461292266846
Validation loss: 2.1620792663225563

Epoch: 5| Step: 5
Training loss: 3.0277340412139893
Validation loss: 2.1440586146487983

Epoch: 5| Step: 6
Training loss: 1.7927719354629517
Validation loss: 2.18871469395135

Epoch: 5| Step: 7
Training loss: 1.9236682653427124
Validation loss: 2.195467156748618

Epoch: 5| Step: 8
Training loss: 2.786101818084717
Validation loss: 2.191963726474393

Epoch: 5| Step: 9
Training loss: 1.9916213750839233
Validation loss: 2.166099921349556

Epoch: 5| Step: 10
Training loss: 2.198777675628662
Validation loss: 2.1777564761459187

Epoch: 129| Step: 0
Training loss: 2.2418127059936523
Validation loss: 2.154827123047203

Epoch: 5| Step: 1
Training loss: 2.2238059043884277
Validation loss: 2.155989848157411

Epoch: 5| Step: 2
Training loss: 1.6782102584838867
Validation loss: 2.162376155135452

Epoch: 5| Step: 3
Training loss: 2.0885353088378906
Validation loss: 2.16259450938112

Epoch: 5| Step: 4
Training loss: 2.7848904132843018
Validation loss: 2.164659692395118

Epoch: 5| Step: 5
Training loss: 2.7655653953552246
Validation loss: 2.1758057225135063

Epoch: 5| Step: 6
Training loss: 2.1874947547912598
Validation loss: 2.1694408975621706

Epoch: 5| Step: 7
Training loss: 2.129944086074829
Validation loss: 2.1797948037424395

Epoch: 5| Step: 8
Training loss: 1.623854637145996
Validation loss: 2.187645376369517

Epoch: 5| Step: 9
Training loss: 2.5108869075775146
Validation loss: 2.154117671392297

Epoch: 5| Step: 10
Training loss: 2.423081159591675
Validation loss: 2.1782450445236696

Epoch: 130| Step: 0
Training loss: 1.6453742980957031
Validation loss: 2.154778924039615

Epoch: 5| Step: 1
Training loss: 1.4583981037139893
Validation loss: 2.2104171206874232

Epoch: 5| Step: 2
Training loss: 2.8346238136291504
Validation loss: 2.1540684366738923

Epoch: 5| Step: 3
Training loss: 2.736497163772583
Validation loss: 2.164003211964843

Epoch: 5| Step: 4
Training loss: 1.8504321575164795
Validation loss: 2.1921031398157917

Epoch: 5| Step: 5
Training loss: 2.057619571685791
Validation loss: 2.1584001818010883

Epoch: 5| Step: 6
Training loss: 2.049407958984375
Validation loss: 2.1878910462061563

Epoch: 5| Step: 7
Training loss: 2.42229962348938
Validation loss: 2.1676415910003004

Epoch: 5| Step: 8
Training loss: 2.3623595237731934
Validation loss: 2.170906202767485

Epoch: 5| Step: 9
Training loss: 2.511991500854492
Validation loss: 2.1507810572142243

Epoch: 5| Step: 10
Training loss: 2.5800185203552246
Validation loss: 2.1749089994738178

Epoch: 131| Step: 0
Training loss: 1.749335527420044
Validation loss: 2.1759570772929857

Epoch: 5| Step: 1
Training loss: 2.4616074562072754
Validation loss: 2.158922090325304

Epoch: 5| Step: 2
Training loss: 2.695612668991089
Validation loss: 2.156219046602967

Epoch: 5| Step: 3
Training loss: 1.6887321472167969
Validation loss: 2.173769647075284

Epoch: 5| Step: 4
Training loss: 2.3344979286193848
Validation loss: 2.1404653056975333

Epoch: 5| Step: 5
Training loss: 2.157614231109619
Validation loss: 2.152519295292516

Epoch: 5| Step: 6
Training loss: 2.01576566696167
Validation loss: 2.1509732072071364

Epoch: 5| Step: 7
Training loss: 2.2708191871643066
Validation loss: 2.1739669922859437

Epoch: 5| Step: 8
Training loss: 2.307513475418091
Validation loss: 2.159459626802834

Epoch: 5| Step: 9
Training loss: 2.856266736984253
Validation loss: 2.1745455905955327

Epoch: 5| Step: 10
Training loss: 1.7498911619186401
Validation loss: 2.142563827576176

Epoch: 132| Step: 0
Training loss: 2.2071499824523926
Validation loss: 2.162974270441199

Epoch: 5| Step: 1
Training loss: 2.4207446575164795
Validation loss: 2.169102899489864

Epoch: 5| Step: 2
Training loss: 1.8033214807510376
Validation loss: 2.185575746720837

Epoch: 5| Step: 3
Training loss: 2.824401378631592
Validation loss: 2.1846303914182927

Epoch: 5| Step: 4
Training loss: 2.4483656883239746
Validation loss: 2.1546197347743536

Epoch: 5| Step: 5
Training loss: 1.9206361770629883
Validation loss: 2.177575844590382

Epoch: 5| Step: 6
Training loss: 2.217947006225586
Validation loss: 2.1275037129720054

Epoch: 5| Step: 7
Training loss: 2.274415969848633
Validation loss: 2.167185562913136

Epoch: 5| Step: 8
Training loss: 2.233024835586548
Validation loss: 2.1565270116252284

Epoch: 5| Step: 9
Training loss: 1.7536557912826538
Validation loss: 2.172385290104856

Epoch: 5| Step: 10
Training loss: 2.341329336166382
Validation loss: 2.1571119882727183

Epoch: 133| Step: 0
Training loss: 2.459937334060669
Validation loss: 2.155770981183616

Epoch: 5| Step: 1
Training loss: 1.729305624961853
Validation loss: 2.141489786486472

Epoch: 5| Step: 2
Training loss: 2.232250452041626
Validation loss: 2.1706167215942056

Epoch: 5| Step: 3
Training loss: 1.859167456626892
Validation loss: 2.156286567770025

Epoch: 5| Step: 4
Training loss: 2.1966934204101562
Validation loss: 2.1769413345603534

Epoch: 5| Step: 5
Training loss: 2.246507406234741
Validation loss: 2.177454134469391

Epoch: 5| Step: 6
Training loss: 2.318289041519165
Validation loss: 2.1765815109334965

Epoch: 5| Step: 7
Training loss: 2.433509111404419
Validation loss: 2.1769003970648653

Epoch: 5| Step: 8
Training loss: 2.782456874847412
Validation loss: 2.1490118862480245

Epoch: 5| Step: 9
Training loss: 2.491539478302002
Validation loss: 2.1662428532877276

Epoch: 5| Step: 10
Training loss: 1.8030651807785034
Validation loss: 2.172433077648122

Epoch: 134| Step: 0
Training loss: 1.837090253829956
Validation loss: 2.1880622179277482

Epoch: 5| Step: 1
Training loss: 2.1092445850372314
Validation loss: 2.200225358368248

Epoch: 5| Step: 2
Training loss: 2.5942904949188232
Validation loss: 2.1553957103401102

Epoch: 5| Step: 3
Training loss: 2.0980589389801025
Validation loss: 2.182049469281268

Epoch: 5| Step: 4
Training loss: 2.1952309608459473
Validation loss: 2.181080413121049

Epoch: 5| Step: 5
Training loss: 2.9372634887695312
Validation loss: 2.1573218440496795

Epoch: 5| Step: 6
Training loss: 2.2000279426574707
Validation loss: 2.216599387507285

Epoch: 5| Step: 7
Training loss: 2.2570204734802246
Validation loss: 2.1622302455286824

Epoch: 5| Step: 8
Training loss: 2.2771682739257812
Validation loss: 2.195100086991505

Epoch: 5| Step: 9
Training loss: 2.0949416160583496
Validation loss: 2.17290953154205

Epoch: 5| Step: 10
Training loss: 1.7568637132644653
Validation loss: 2.1518377642477713

Epoch: 135| Step: 0
Training loss: 1.5816506147384644
Validation loss: 2.14982710858827

Epoch: 5| Step: 1
Training loss: 2.8003153800964355
Validation loss: 2.1877693873579784

Epoch: 5| Step: 2
Training loss: 2.0439774990081787
Validation loss: 2.1938878656715475

Epoch: 5| Step: 3
Training loss: 1.7916816473007202
Validation loss: 2.1717540448711765

Epoch: 5| Step: 4
Training loss: 2.60349178314209
Validation loss: 2.1513303582386305

Epoch: 5| Step: 5
Training loss: 1.835260033607483
Validation loss: 2.1023288388406076

Epoch: 5| Step: 6
Training loss: 2.1217005252838135
Validation loss: 2.1793502018015873

Epoch: 5| Step: 7
Training loss: 1.6782267093658447
Validation loss: 2.1403471449370026

Epoch: 5| Step: 8
Training loss: 2.219719648361206
Validation loss: 2.158737564599642

Epoch: 5| Step: 9
Training loss: 3.0569043159484863
Validation loss: 2.1809557868588354

Epoch: 5| Step: 10
Training loss: 2.639638662338257
Validation loss: 2.1855096586288942

Epoch: 136| Step: 0
Training loss: 2.246511459350586
Validation loss: 2.15901639000062

Epoch: 5| Step: 1
Training loss: 2.110893726348877
Validation loss: 2.1611478738887335

Epoch: 5| Step: 2
Training loss: 2.4522626399993896
Validation loss: 2.1844132126018567

Epoch: 5| Step: 3
Training loss: 2.219194173812866
Validation loss: 2.137044391324443

Epoch: 5| Step: 4
Training loss: 2.350809097290039
Validation loss: 2.1931723779247654

Epoch: 5| Step: 5
Training loss: 1.6942920684814453
Validation loss: 2.1706748700911

Epoch: 5| Step: 6
Training loss: 2.712507486343384
Validation loss: 2.1923466728579615

Epoch: 5| Step: 7
Training loss: 2.004284620285034
Validation loss: 2.148177403275685

Epoch: 5| Step: 8
Training loss: 2.0067856311798096
Validation loss: 2.1536268752108336

Epoch: 5| Step: 9
Training loss: 2.207885503768921
Validation loss: 2.1444892139844995

Epoch: 5| Step: 10
Training loss: 2.8041725158691406
Validation loss: 2.1699703829262846

Epoch: 137| Step: 0
Training loss: 2.4159369468688965
Validation loss: 2.1280018180929203

Epoch: 5| Step: 1
Training loss: 1.6752952337265015
Validation loss: 2.141294333242601

Epoch: 5| Step: 2
Training loss: 2.3081283569335938
Validation loss: 2.1612048072199666

Epoch: 5| Step: 3
Training loss: 1.7698755264282227
Validation loss: 2.1917336576728412

Epoch: 5| Step: 4
Training loss: 2.0148427486419678
Validation loss: 2.1558709144592285

Epoch: 5| Step: 5
Training loss: 2.4444732666015625
Validation loss: 2.172938031534995

Epoch: 5| Step: 6
Training loss: 1.3687258958816528
Validation loss: 2.1630030242345666

Epoch: 5| Step: 7
Training loss: 2.6252410411834717
Validation loss: 2.206184992226221

Epoch: 5| Step: 8
Training loss: 2.4782960414886475
Validation loss: 2.156882664208771

Epoch: 5| Step: 9
Training loss: 2.712109088897705
Validation loss: 2.1638993447826755

Epoch: 5| Step: 10
Training loss: 2.708190679550171
Validation loss: 2.181082558888261

Epoch: 138| Step: 0
Training loss: 1.8407394886016846
Validation loss: 2.156762320508239

Epoch: 5| Step: 1
Training loss: 2.288966178894043
Validation loss: 2.130034731280419

Epoch: 5| Step: 2
Training loss: 2.1479287147521973
Validation loss: 2.1591882295505975

Epoch: 5| Step: 3
Training loss: 2.2139506340026855
Validation loss: 2.19654348845123

Epoch: 5| Step: 4
Training loss: 2.205134868621826
Validation loss: 2.1668315164504515

Epoch: 5| Step: 5
Training loss: 3.3687667846679688
Validation loss: 2.2057011537654425

Epoch: 5| Step: 6
Training loss: 2.126328468322754
Validation loss: 2.1824979243739957

Epoch: 5| Step: 7
Training loss: 1.8124704360961914
Validation loss: 2.1866984816007715

Epoch: 5| Step: 8
Training loss: 2.2128188610076904
Validation loss: 2.199894260334712

Epoch: 5| Step: 9
Training loss: 2.3260583877563477
Validation loss: 2.1817688454863844

Epoch: 5| Step: 10
Training loss: 1.8359251022338867
Validation loss: 2.1780083217928485

Epoch: 139| Step: 0
Training loss: 1.5753729343414307
Validation loss: 2.1557017551955355

Epoch: 5| Step: 1
Training loss: 2.1327476501464844
Validation loss: 2.169996056505429

Epoch: 5| Step: 2
Training loss: 2.736046075820923
Validation loss: 2.206317775992937

Epoch: 5| Step: 3
Training loss: 2.5329370498657227
Validation loss: 2.1692388685800696

Epoch: 5| Step: 4
Training loss: 2.2119479179382324
Validation loss: 2.1725098676578973

Epoch: 5| Step: 5
Training loss: 1.9668935537338257
Validation loss: 2.1625233157988517

Epoch: 5| Step: 6
Training loss: 2.5062215328216553
Validation loss: 2.1877483180774155

Epoch: 5| Step: 7
Training loss: 1.6605209112167358
Validation loss: 2.1752698088204987

Epoch: 5| Step: 8
Training loss: 2.7854840755462646
Validation loss: 2.155715263018044

Epoch: 5| Step: 9
Training loss: 2.2939300537109375
Validation loss: 2.1688951266709195

Epoch: 5| Step: 10
Training loss: 1.980414628982544
Validation loss: 2.1527138320348596

Epoch: 140| Step: 0
Training loss: 2.477111577987671
Validation loss: 2.2083543077591927

Epoch: 5| Step: 1
Training loss: 2.535757064819336
Validation loss: 2.181381094840265

Epoch: 5| Step: 2
Training loss: 2.083026647567749
Validation loss: 2.1467874421868274

Epoch: 5| Step: 3
Training loss: 2.5001561641693115
Validation loss: 2.165236016755463

Epoch: 5| Step: 4
Training loss: 1.8318067789077759
Validation loss: 2.177178475164598

Epoch: 5| Step: 5
Training loss: 2.6398541927337646
Validation loss: 2.1536538793194677

Epoch: 5| Step: 6
Training loss: 2.132845640182495
Validation loss: 2.1357126005234255

Epoch: 5| Step: 7
Training loss: 1.799612045288086
Validation loss: 2.164821852919876

Epoch: 5| Step: 8
Training loss: 2.1419007778167725
Validation loss: 2.144464146706366

Epoch: 5| Step: 9
Training loss: 2.6859958171844482
Validation loss: 2.1547994357283398

Epoch: 5| Step: 10
Training loss: 1.9961707592010498
Validation loss: 2.1344042542160198

Epoch: 141| Step: 0
Training loss: 2.6501755714416504
Validation loss: 2.155228845534786

Epoch: 5| Step: 1
Training loss: 2.303877353668213
Validation loss: 2.1402714662654425

Epoch: 5| Step: 2
Training loss: 2.4354395866394043
Validation loss: 2.121494890541159

Epoch: 5| Step: 3
Training loss: 1.798630952835083
Validation loss: 2.1740851889374437

Epoch: 5| Step: 4
Training loss: 2.2738196849823
Validation loss: 2.199420257281232

Epoch: 5| Step: 5
Training loss: 2.5929245948791504
Validation loss: 2.1661762627222205

Epoch: 5| Step: 6
Training loss: 2.148984909057617
Validation loss: 2.1998530818570043

Epoch: 5| Step: 7
Training loss: 2.1322546005249023
Validation loss: 2.1645193535794496

Epoch: 5| Step: 8
Training loss: 2.4424545764923096
Validation loss: 2.184485923859381

Epoch: 5| Step: 9
Training loss: 1.5874426364898682
Validation loss: 2.151944633453123

Epoch: 5| Step: 10
Training loss: 2.1653811931610107
Validation loss: 2.138794929750504

Epoch: 142| Step: 0
Training loss: 2.8848330974578857
Validation loss: 2.1493616552763086

Epoch: 5| Step: 1
Training loss: 2.2797069549560547
Validation loss: 2.1468736048667663

Epoch: 5| Step: 2
Training loss: 1.4075062274932861
Validation loss: 2.1947337196719263

Epoch: 5| Step: 3
Training loss: 1.846554160118103
Validation loss: 2.166341958507415

Epoch: 5| Step: 4
Training loss: 1.5265957117080688
Validation loss: 2.159732803221672

Epoch: 5| Step: 5
Training loss: 2.77489972114563
Validation loss: 2.1972503175017652

Epoch: 5| Step: 6
Training loss: 2.1537647247314453
Validation loss: 2.1418688809999855

Epoch: 5| Step: 7
Training loss: 1.711687684059143
Validation loss: 2.1693714229009484

Epoch: 5| Step: 8
Training loss: 2.353306770324707
Validation loss: 2.1790545243088917

Epoch: 5| Step: 9
Training loss: 3.148108959197998
Validation loss: 2.149910157726657

Epoch: 5| Step: 10
Training loss: 2.272918462753296
Validation loss: 2.1690635655515935

Epoch: 143| Step: 0
Training loss: 2.64784574508667
Validation loss: 2.1706937718135055

Epoch: 5| Step: 1
Training loss: 2.3565311431884766
Validation loss: 2.1493972680901967

Epoch: 5| Step: 2
Training loss: 1.8550384044647217
Validation loss: 2.1553611755371094

Epoch: 5| Step: 3
Training loss: 1.5432032346725464
Validation loss: 2.1961487044570265

Epoch: 5| Step: 4
Training loss: 2.510721206665039
Validation loss: 2.171607246962927

Epoch: 5| Step: 5
Training loss: 2.3237485885620117
Validation loss: 2.202267421189175

Epoch: 5| Step: 6
Training loss: 1.9617046117782593
Validation loss: 2.1999090948412494

Epoch: 5| Step: 7
Training loss: 2.408726215362549
Validation loss: 2.2384894278741654

Epoch: 5| Step: 8
Training loss: 2.1741249561309814
Validation loss: 2.1972477205338015

Epoch: 5| Step: 9
Training loss: 2.2678637504577637
Validation loss: 2.1990671234746135

Epoch: 5| Step: 10
Training loss: 2.323164701461792
Validation loss: 2.2118414319971555

Epoch: 144| Step: 0
Training loss: 2.104771852493286
Validation loss: 2.1966194055413686

Epoch: 5| Step: 1
Training loss: 2.3112633228302
Validation loss: 2.206644450464556

Epoch: 5| Step: 2
Training loss: 2.355607509613037
Validation loss: 2.2133794676872993

Epoch: 5| Step: 3
Training loss: 3.006596803665161
Validation loss: 2.1816553261972245

Epoch: 5| Step: 4
Training loss: 2.2474074363708496
Validation loss: 2.169217296825942

Epoch: 5| Step: 5
Training loss: 2.2490286827087402
Validation loss: 2.197130057119554

Epoch: 5| Step: 6
Training loss: 2.5920536518096924
Validation loss: 2.20685661736355

Epoch: 5| Step: 7
Training loss: 1.7082569599151611
Validation loss: 2.192770868219355

Epoch: 5| Step: 8
Training loss: 1.9266067743301392
Validation loss: 2.2107413430367746

Epoch: 5| Step: 9
Training loss: 2.066990613937378
Validation loss: 2.205321124804917

Epoch: 5| Step: 10
Training loss: 1.7135512828826904
Validation loss: 2.171621320068195

Epoch: 145| Step: 0
Training loss: 2.341696262359619
Validation loss: 2.1705867231533094

Epoch: 5| Step: 1
Training loss: 2.6568026542663574
Validation loss: 2.170714360411449

Epoch: 5| Step: 2
Training loss: 2.6250851154327393
Validation loss: 2.1877386890431887

Epoch: 5| Step: 3
Training loss: 1.8017717599868774
Validation loss: 2.182046182693974

Epoch: 5| Step: 4
Training loss: 2.3483288288116455
Validation loss: 2.180734078089396

Epoch: 5| Step: 5
Training loss: 1.9409078359603882
Validation loss: 2.177528417238625

Epoch: 5| Step: 6
Training loss: 2.4583353996276855
Validation loss: 2.1564748876838276

Epoch: 5| Step: 7
Training loss: 2.275480031967163
Validation loss: 2.149466118504924

Epoch: 5| Step: 8
Training loss: 1.6991126537322998
Validation loss: 2.206590337138022

Epoch: 5| Step: 9
Training loss: 2.1747379302978516
Validation loss: 2.1916775447066112

Epoch: 5| Step: 10
Training loss: 2.0935230255126953
Validation loss: 2.158078137264457

Epoch: 146| Step: 0
Training loss: 2.664865732192993
Validation loss: 2.181058858030586

Epoch: 5| Step: 1
Training loss: 2.0187253952026367
Validation loss: 2.1769422869528494

Epoch: 5| Step: 2
Training loss: 1.5006933212280273
Validation loss: 2.199336587741811

Epoch: 5| Step: 3
Training loss: 2.0298123359680176
Validation loss: 2.2012967832626833

Epoch: 5| Step: 4
Training loss: 2.8758506774902344
Validation loss: 2.1574939989274546

Epoch: 5| Step: 5
Training loss: 1.8532403707504272
Validation loss: 2.1892487515685377

Epoch: 5| Step: 6
Training loss: 2.319075107574463
Validation loss: 2.151673270810035

Epoch: 5| Step: 7
Training loss: 2.2915751934051514
Validation loss: 2.162586389049407

Epoch: 5| Step: 8
Training loss: 2.1660404205322266
Validation loss: 2.1561841785266833

Epoch: 5| Step: 9
Training loss: 2.204510450363159
Validation loss: 2.1666030319788123

Epoch: 5| Step: 10
Training loss: 2.336981773376465
Validation loss: 2.1849321319210913

Epoch: 147| Step: 0
Training loss: 2.432225465774536
Validation loss: 2.1333549714857534

Epoch: 5| Step: 1
Training loss: 2.570786952972412
Validation loss: 2.2154368585155857

Epoch: 5| Step: 2
Training loss: 1.7126201391220093
Validation loss: 2.170438321687842

Epoch: 5| Step: 3
Training loss: 1.817500114440918
Validation loss: 2.1526275860366

Epoch: 5| Step: 4
Training loss: 1.948800802230835
Validation loss: 2.163287211489934

Epoch: 5| Step: 5
Training loss: 2.345449924468994
Validation loss: 2.175521284021357

Epoch: 5| Step: 6
Training loss: 2.332893133163452
Validation loss: 2.1845450183396697

Epoch: 5| Step: 7
Training loss: 2.569361686706543
Validation loss: 2.2163526729870866

Epoch: 5| Step: 8
Training loss: 2.450549602508545
Validation loss: 2.1385997213343138

Epoch: 5| Step: 9
Training loss: 2.2717769145965576
Validation loss: 2.1973828397771364

Epoch: 5| Step: 10
Training loss: 2.0356252193450928
Validation loss: 2.1769224238652054

Epoch: 148| Step: 0
Training loss: 2.4561831951141357
Validation loss: 2.189456080877653

Epoch: 5| Step: 1
Training loss: 2.1842997074127197
Validation loss: 2.163958236735354

Epoch: 5| Step: 2
Training loss: 2.6372876167297363
Validation loss: 2.157260993475555

Epoch: 5| Step: 3
Training loss: 2.5943784713745117
Validation loss: 2.1594423299194663

Epoch: 5| Step: 4
Training loss: 2.5451133251190186
Validation loss: 2.164361043642926

Epoch: 5| Step: 5
Training loss: 2.22955060005188
Validation loss: 2.1503343043788785

Epoch: 5| Step: 6
Training loss: 1.3701136112213135
Validation loss: 2.139840269601473

Epoch: 5| Step: 7
Training loss: 2.8213305473327637
Validation loss: 2.19715170321926

Epoch: 5| Step: 8
Training loss: 1.5494794845581055
Validation loss: 2.185237355129693

Epoch: 5| Step: 9
Training loss: 2.262477159500122
Validation loss: 2.19063594777097

Epoch: 5| Step: 10
Training loss: 1.9073903560638428
Validation loss: 2.166908461560485

Epoch: 149| Step: 0
Training loss: 1.7945330142974854
Validation loss: 2.16490630180605

Epoch: 5| Step: 1
Training loss: 2.226452350616455
Validation loss: 2.175849387722631

Epoch: 5| Step: 2
Training loss: 2.3329129219055176
Validation loss: 2.172528007979034

Epoch: 5| Step: 3
Training loss: 1.4829965829849243
Validation loss: 2.1833083039970806

Epoch: 5| Step: 4
Training loss: 1.9271509647369385
Validation loss: 2.181186904189407

Epoch: 5| Step: 5
Training loss: 2.478731632232666
Validation loss: 2.1594362335820354

Epoch: 5| Step: 6
Training loss: 1.8253313302993774
Validation loss: 2.1470474299564155

Epoch: 5| Step: 7
Training loss: 3.1000378131866455
Validation loss: 2.1717635047051216

Epoch: 5| Step: 8
Training loss: 2.50227952003479
Validation loss: 2.1427025666800876

Epoch: 5| Step: 9
Training loss: 2.10750150680542
Validation loss: 2.1612300154983357

Epoch: 5| Step: 10
Training loss: 2.566918134689331
Validation loss: 2.1711145318964475

Epoch: 150| Step: 0
Training loss: 3.239698886871338
Validation loss: 2.1940741897911153

Epoch: 5| Step: 1
Training loss: 2.158818244934082
Validation loss: 2.1325768988619567

Epoch: 5| Step: 2
Training loss: 2.3928892612457275
Validation loss: 2.163303957190565

Epoch: 5| Step: 3
Training loss: 1.958865761756897
Validation loss: 2.1946806651289745

Epoch: 5| Step: 4
Training loss: 2.965635299682617
Validation loss: 2.14306321964469

Epoch: 5| Step: 5
Training loss: 1.8465919494628906
Validation loss: 2.140133503944643

Epoch: 5| Step: 6
Training loss: 3.109666347503662
Validation loss: 2.172330497413553

Epoch: 5| Step: 7
Training loss: 2.0288453102111816
Validation loss: 2.212829356552452

Epoch: 5| Step: 8
Training loss: 1.493438482284546
Validation loss: 2.1891056542755454

Epoch: 5| Step: 9
Training loss: 1.5062637329101562
Validation loss: 2.182612737019857

Epoch: 5| Step: 10
Training loss: 1.659675121307373
Validation loss: 2.187222949920162

Epoch: 151| Step: 0
Training loss: 2.6670472621917725
Validation loss: 2.2019929680773007

Epoch: 5| Step: 1
Training loss: 2.1391513347625732
Validation loss: 2.2020168406988985

Epoch: 5| Step: 2
Training loss: 1.5111862421035767
Validation loss: 2.1766286357756583

Epoch: 5| Step: 3
Training loss: 1.4868519306182861
Validation loss: 2.203436754083121

Epoch: 5| Step: 4
Training loss: 2.6769471168518066
Validation loss: 2.145743526438231

Epoch: 5| Step: 5
Training loss: 2.5390915870666504
Validation loss: 2.200368386442943

Epoch: 5| Step: 6
Training loss: 1.3071019649505615
Validation loss: 2.1702333060644006

Epoch: 5| Step: 7
Training loss: 3.0380358695983887
Validation loss: 2.1787890183028353

Epoch: 5| Step: 8
Training loss: 2.1964402198791504
Validation loss: 2.189780822364233

Epoch: 5| Step: 9
Training loss: 2.5402920246124268
Validation loss: 2.163169337857154

Epoch: 5| Step: 10
Training loss: 2.0830962657928467
Validation loss: 2.1943273980130433

Epoch: 152| Step: 0
Training loss: 2.8609795570373535
Validation loss: 2.1722498298973165

Epoch: 5| Step: 1
Training loss: 2.1369431018829346
Validation loss: 2.1460807502910657

Epoch: 5| Step: 2
Training loss: 1.6465409994125366
Validation loss: 2.197748987905441

Epoch: 5| Step: 3
Training loss: 2.4358062744140625
Validation loss: 2.1692318890684392

Epoch: 5| Step: 4
Training loss: 2.518749475479126
Validation loss: 2.1634060208515455

Epoch: 5| Step: 5
Training loss: 2.649038791656494
Validation loss: 2.157833960748488

Epoch: 5| Step: 6
Training loss: 1.5879563093185425
Validation loss: 2.162274706748224

Epoch: 5| Step: 7
Training loss: 2.1023147106170654
Validation loss: 2.1744738137850197

Epoch: 5| Step: 8
Training loss: 2.245584487915039
Validation loss: 2.176362966978422

Epoch: 5| Step: 9
Training loss: 1.9932657480239868
Validation loss: 2.1624719532587195

Epoch: 5| Step: 10
Training loss: 1.9209411144256592
Validation loss: 2.1623032041775283

Epoch: 153| Step: 0
Training loss: 2.608308792114258
Validation loss: 2.1415024124166018

Epoch: 5| Step: 1
Training loss: 1.8271026611328125
Validation loss: 2.1944583359585015

Epoch: 5| Step: 2
Training loss: 1.9235045909881592
Validation loss: 2.178516632767134

Epoch: 5| Step: 3
Training loss: 1.6461098194122314
Validation loss: 2.18611797594255

Epoch: 5| Step: 4
Training loss: 2.087247371673584
Validation loss: 2.1279404368451846

Epoch: 5| Step: 5
Training loss: 3.0919883251190186
Validation loss: 2.1876717639225784

Epoch: 5| Step: 6
Training loss: 2.279895305633545
Validation loss: 2.190619727616669

Epoch: 5| Step: 7
Training loss: 1.900389313697815
Validation loss: 2.154696872157435

Epoch: 5| Step: 8
Training loss: 2.0933454036712646
Validation loss: 2.1643789558000464

Epoch: 5| Step: 9
Training loss: 2.3147692680358887
Validation loss: 2.2041552528258292

Epoch: 5| Step: 10
Training loss: 2.8391668796539307
Validation loss: 2.1878762373360257

Epoch: 154| Step: 0
Training loss: 2.2991905212402344
Validation loss: 2.1639943584319083

Epoch: 5| Step: 1
Training loss: 2.140096426010132
Validation loss: 2.1770650558574225

Epoch: 5| Step: 2
Training loss: 2.9295153617858887
Validation loss: 2.172072838711482

Epoch: 5| Step: 3
Training loss: 2.0729126930236816
Validation loss: 2.1646406112178678

Epoch: 5| Step: 4
Training loss: 2.597273349761963
Validation loss: 2.2096175711642028

Epoch: 5| Step: 5
Training loss: 2.2387821674346924
Validation loss: 2.155815221930063

Epoch: 5| Step: 6
Training loss: 1.603440284729004
Validation loss: 2.141289270052346

Epoch: 5| Step: 7
Training loss: 1.5143425464630127
Validation loss: 2.1666706710733394

Epoch: 5| Step: 8
Training loss: 1.9347732067108154
Validation loss: 2.1948454251853367

Epoch: 5| Step: 9
Training loss: 2.2259254455566406
Validation loss: 2.1627218851479153

Epoch: 5| Step: 10
Training loss: 2.772367000579834
Validation loss: 2.182715118572276

Epoch: 155| Step: 0
Training loss: 2.1727652549743652
Validation loss: 2.1467373242942234

Epoch: 5| Step: 1
Training loss: 2.5796236991882324
Validation loss: 2.1584434945096254

Epoch: 5| Step: 2
Training loss: 3.1047987937927246
Validation loss: 2.175663612222159

Epoch: 5| Step: 3
Training loss: 1.3985378742218018
Validation loss: 2.1715715854398665

Epoch: 5| Step: 4
Training loss: 2.1242411136627197
Validation loss: 2.148133482984317

Epoch: 5| Step: 5
Training loss: 2.0399439334869385
Validation loss: 2.158078275701051

Epoch: 5| Step: 6
Training loss: 1.463057518005371
Validation loss: 2.159807382091399

Epoch: 5| Step: 7
Training loss: 2.3129067420959473
Validation loss: 2.2093412722310712

Epoch: 5| Step: 8
Training loss: 2.2271177768707275
Validation loss: 2.191877502267079

Epoch: 5| Step: 9
Training loss: 2.516662120819092
Validation loss: 2.200916991438917

Epoch: 5| Step: 10
Training loss: 2.28442120552063
Validation loss: 2.1666933874930105

Epoch: 156| Step: 0
Training loss: 2.428712844848633
Validation loss: 2.192505331449611

Epoch: 5| Step: 1
Training loss: 2.369638442993164
Validation loss: 2.1752912459834928

Epoch: 5| Step: 2
Training loss: 2.206066846847534
Validation loss: 2.163110380531639

Epoch: 5| Step: 3
Training loss: 2.386383533477783
Validation loss: 2.1508024443862257

Epoch: 5| Step: 4
Training loss: 2.1030941009521484
Validation loss: 2.1224851531367146

Epoch: 5| Step: 5
Training loss: 2.319319725036621
Validation loss: 2.181096666602678

Epoch: 5| Step: 6
Training loss: 2.590056896209717
Validation loss: 2.174045849871892

Epoch: 5| Step: 7
Training loss: 1.831290602684021
Validation loss: 2.139419917137392

Epoch: 5| Step: 8
Training loss: 2.6198534965515137
Validation loss: 2.2056687083295596

Epoch: 5| Step: 9
Training loss: 1.699336290359497
Validation loss: 2.160126898878364

Epoch: 5| Step: 10
Training loss: 1.674015760421753
Validation loss: 2.139091061007592

Epoch: 157| Step: 0
Training loss: 1.7400869131088257
Validation loss: 2.1772389565744708

Epoch: 5| Step: 1
Training loss: 2.074289560317993
Validation loss: 2.150573120322279

Epoch: 5| Step: 2
Training loss: 2.2555205821990967
Validation loss: 2.2136932521738033

Epoch: 5| Step: 3
Training loss: 1.6495048999786377
Validation loss: 2.168521906739922

Epoch: 5| Step: 4
Training loss: 2.597238302230835
Validation loss: 2.139034640404486

Epoch: 5| Step: 5
Training loss: 2.013713836669922
Validation loss: 2.199022500745712

Epoch: 5| Step: 6
Training loss: 2.6882355213165283
Validation loss: 2.184227366601267

Epoch: 5| Step: 7
Training loss: 2.1617860794067383
Validation loss: 2.160769652294856

Epoch: 5| Step: 8
Training loss: 2.272824287414551
Validation loss: 2.178359677714686

Epoch: 5| Step: 9
Training loss: 2.0927414894104004
Validation loss: 2.1728601019869567

Epoch: 5| Step: 10
Training loss: 2.928159475326538
Validation loss: 2.1878396375204927

Epoch: 158| Step: 0
Training loss: 2.5357978343963623
Validation loss: 2.233665194562686

Epoch: 5| Step: 1
Training loss: 1.9573230743408203
Validation loss: 2.1877375187412387

Epoch: 5| Step: 2
Training loss: 2.803056001663208
Validation loss: 2.2047041308495308

Epoch: 5| Step: 3
Training loss: 1.9824113845825195
Validation loss: 2.1819189440819526

Epoch: 5| Step: 4
Training loss: 2.599520683288574
Validation loss: 2.2121303901877454

Epoch: 5| Step: 5
Training loss: 1.933295488357544
Validation loss: 2.1911853026318293

Epoch: 5| Step: 6
Training loss: 1.7543017864227295
Validation loss: 2.1712874815028202

Epoch: 5| Step: 7
Training loss: 2.0814146995544434
Validation loss: 2.1834056890139015

Epoch: 5| Step: 8
Training loss: 1.8534717559814453
Validation loss: 2.18166382082047

Epoch: 5| Step: 9
Training loss: 2.4346871376037598
Validation loss: 2.1886012515714093

Epoch: 5| Step: 10
Training loss: 2.171797513961792
Validation loss: 2.106010636975688

Epoch: 159| Step: 0
Training loss: 1.6534744501113892
Validation loss: 2.179882569979596

Epoch: 5| Step: 1
Training loss: 2.2345542907714844
Validation loss: 2.2047821719159364

Epoch: 5| Step: 2
Training loss: 2.0823185443878174
Validation loss: 2.1499506581214165

Epoch: 5| Step: 3
Training loss: 2.4082324504852295
Validation loss: 2.218693458905784

Epoch: 5| Step: 4
Training loss: 2.37156343460083
Validation loss: 2.194389153552312

Epoch: 5| Step: 5
Training loss: 2.136528968811035
Validation loss: 2.1905022052026566

Epoch: 5| Step: 6
Training loss: 2.816781997680664
Validation loss: 2.2331783028059107

Epoch: 5| Step: 7
Training loss: 1.6140941381454468
Validation loss: 2.1827047717186714

Epoch: 5| Step: 8
Training loss: 2.0154857635498047
Validation loss: 2.154465462571831

Epoch: 5| Step: 9
Training loss: 2.6348438262939453
Validation loss: 2.1420626127591698

Epoch: 5| Step: 10
Training loss: 2.3153305053710938
Validation loss: 2.1987621899574035

Epoch: 160| Step: 0
Training loss: 2.561232089996338
Validation loss: 2.1981026395674674

Epoch: 5| Step: 1
Training loss: 2.2863175868988037
Validation loss: 2.193741943246575

Epoch: 5| Step: 2
Training loss: 2.3575081825256348
Validation loss: 2.1494463464265228

Epoch: 5| Step: 3
Training loss: 2.5329861640930176
Validation loss: 2.198166888247254

Epoch: 5| Step: 4
Training loss: 2.236670970916748
Validation loss: 2.1957039627977597

Epoch: 5| Step: 5
Training loss: 1.655362844467163
Validation loss: 2.2132413156570925

Epoch: 5| Step: 6
Training loss: 1.8448690176010132
Validation loss: 2.2388607109746625

Epoch: 5| Step: 7
Training loss: 2.2341959476470947
Validation loss: 2.200986849364414

Epoch: 5| Step: 8
Training loss: 2.8841910362243652
Validation loss: 2.2016467125185075

Epoch: 5| Step: 9
Training loss: 1.9713075160980225
Validation loss: 2.201326602248735

Epoch: 5| Step: 10
Training loss: 1.8874598741531372
Validation loss: 2.183700341050343

Epoch: 161| Step: 0
Training loss: 2.399509906768799
Validation loss: 2.1859882185536046

Epoch: 5| Step: 1
Training loss: 2.297799587249756
Validation loss: 2.182615460888032

Epoch: 5| Step: 2
Training loss: 2.0092685222625732
Validation loss: 2.2165430181769916

Epoch: 5| Step: 3
Training loss: 2.7346386909484863
Validation loss: 2.1618429076287056

Epoch: 5| Step: 4
Training loss: 2.2954297065734863
Validation loss: 2.2166458009391703

Epoch: 5| Step: 5
Training loss: 2.525524854660034
Validation loss: 2.208649476369222

Epoch: 5| Step: 6
Training loss: 1.334216833114624
Validation loss: 2.2033922710726337

Epoch: 5| Step: 7
Training loss: 1.9473743438720703
Validation loss: 2.169306811466012

Epoch: 5| Step: 8
Training loss: 2.3804433345794678
Validation loss: 2.1665693688136276

Epoch: 5| Step: 9
Training loss: 2.108139753341675
Validation loss: 2.185963051293486

Epoch: 5| Step: 10
Training loss: 2.326810598373413
Validation loss: 2.211907943089803

Epoch: 162| Step: 0
Training loss: 2.4154248237609863
Validation loss: 2.142717512704993

Epoch: 5| Step: 1
Training loss: 1.8408006429672241
Validation loss: 2.1221841945443103

Epoch: 5| Step: 2
Training loss: 1.8302595615386963
Validation loss: 2.140906572341919

Epoch: 5| Step: 3
Training loss: 2.9714531898498535
Validation loss: 2.1493009136569117

Epoch: 5| Step: 4
Training loss: 2.2143001556396484
Validation loss: 2.1700459193157893

Epoch: 5| Step: 5
Training loss: 2.4471383094787598
Validation loss: 2.1562984938262613

Epoch: 5| Step: 6
Training loss: 1.9005584716796875
Validation loss: 2.1821222920571604

Epoch: 5| Step: 7
Training loss: 1.4219305515289307
Validation loss: 2.1510551129618

Epoch: 5| Step: 8
Training loss: 2.1488215923309326
Validation loss: 2.168123798985635

Epoch: 5| Step: 9
Training loss: 2.661686420440674
Validation loss: 2.1522563862544235

Epoch: 5| Step: 10
Training loss: 2.3468494415283203
Validation loss: 2.1799195915140133

Epoch: 163| Step: 0
Training loss: 1.9237382411956787
Validation loss: 2.197946056242912

Epoch: 5| Step: 1
Training loss: 2.638068675994873
Validation loss: 2.208148330770513

Epoch: 5| Step: 2
Training loss: 2.368464708328247
Validation loss: 2.166402442480928

Epoch: 5| Step: 3
Training loss: 2.3254332542419434
Validation loss: 2.1691000641033216

Epoch: 5| Step: 4
Training loss: 1.9000381231307983
Validation loss: 2.20760017056619

Epoch: 5| Step: 5
Training loss: 1.6284058094024658
Validation loss: 2.188635963265614

Epoch: 5| Step: 6
Training loss: 2.0039172172546387
Validation loss: 2.192905966953565

Epoch: 5| Step: 7
Training loss: 2.5566487312316895
Validation loss: 2.182292899777812

Epoch: 5| Step: 8
Training loss: 2.503023862838745
Validation loss: 2.1768830873632945

Epoch: 5| Step: 9
Training loss: 2.686004638671875
Validation loss: 2.1699278636645247

Epoch: 5| Step: 10
Training loss: 1.5601712465286255
Validation loss: 2.1985193170526975

Epoch: 164| Step: 0
Training loss: 1.897226095199585
Validation loss: 2.2146687430720173

Epoch: 5| Step: 1
Training loss: 2.5754337310791016
Validation loss: 2.2084394039646273

Epoch: 5| Step: 2
Training loss: 1.7104930877685547
Validation loss: 2.213220706550024

Epoch: 5| Step: 3
Training loss: 2.728806972503662
Validation loss: 2.170320172463694

Epoch: 5| Step: 4
Training loss: 2.29028058052063
Validation loss: 2.1775630007507982

Epoch: 5| Step: 5
Training loss: 2.5689964294433594
Validation loss: 2.1602766270278604

Epoch: 5| Step: 6
Training loss: 2.3348708152770996
Validation loss: 2.2116343359793387

Epoch: 5| Step: 7
Training loss: 2.03381085395813
Validation loss: 2.1790149493884017

Epoch: 5| Step: 8
Training loss: 2.079314708709717
Validation loss: 2.199616365535285

Epoch: 5| Step: 9
Training loss: 1.984946846961975
Validation loss: 2.20509458357288

Epoch: 5| Step: 10
Training loss: 1.8369925022125244
Validation loss: 2.1879495164399505

Epoch: 165| Step: 0
Training loss: 2.3233447074890137
Validation loss: 2.1981545532903364

Epoch: 5| Step: 1
Training loss: 2.0072174072265625
Validation loss: 2.15452544407178

Epoch: 5| Step: 2
Training loss: 2.2120137214660645
Validation loss: 2.165287458768455

Epoch: 5| Step: 3
Training loss: 2.1559414863586426
Validation loss: 2.1843724404611895

Epoch: 5| Step: 4
Training loss: 1.706827163696289
Validation loss: 2.1675989474019697

Epoch: 5| Step: 5
Training loss: 2.5237910747528076
Validation loss: 2.159270466014903

Epoch: 5| Step: 6
Training loss: 2.3249363899230957
Validation loss: 2.182655135790507

Epoch: 5| Step: 7
Training loss: 2.1332898139953613
Validation loss: 2.1636576062889508

Epoch: 5| Step: 8
Training loss: 2.2141127586364746
Validation loss: 2.1918322245279946

Epoch: 5| Step: 9
Training loss: 2.2603819370269775
Validation loss: 2.1867448540144068

Epoch: 5| Step: 10
Training loss: 2.4011130332946777
Validation loss: 2.153842123605872

Epoch: 166| Step: 0
Training loss: 2.281047821044922
Validation loss: 2.1956271253606325

Epoch: 5| Step: 1
Training loss: 1.6214373111724854
Validation loss: 2.207668577471087

Epoch: 5| Step: 2
Training loss: 2.1636557579040527
Validation loss: 2.1797768941489597

Epoch: 5| Step: 3
Training loss: 1.893014669418335
Validation loss: 2.1789583800941386

Epoch: 5| Step: 4
Training loss: 1.971523642539978
Validation loss: 2.1907790066093527

Epoch: 5| Step: 5
Training loss: 1.9947878122329712
Validation loss: 2.2078144986142396

Epoch: 5| Step: 6
Training loss: 2.445403814315796
Validation loss: 2.175202860627123

Epoch: 5| Step: 7
Training loss: 1.9913021326065063
Validation loss: 2.188469515051893

Epoch: 5| Step: 8
Training loss: 2.791654586791992
Validation loss: 2.2185243611694663

Epoch: 5| Step: 9
Training loss: 2.339722156524658
Validation loss: 2.22936156488234

Epoch: 5| Step: 10
Training loss: 2.3010571002960205
Validation loss: 2.176631913390211

Epoch: 167| Step: 0
Training loss: 2.2739593982696533
Validation loss: 2.1791990162223898

Epoch: 5| Step: 1
Training loss: 1.532352328300476
Validation loss: 2.204717510490007

Epoch: 5| Step: 2
Training loss: 2.617863893508911
Validation loss: 2.186760833186488

Epoch: 5| Step: 3
Training loss: 2.0376179218292236
Validation loss: 2.18213459496857

Epoch: 5| Step: 4
Training loss: 2.55670166015625
Validation loss: 2.202156606540885

Epoch: 5| Step: 5
Training loss: 2.3287734985351562
Validation loss: 2.2051069582662275

Epoch: 5| Step: 6
Training loss: 1.4800119400024414
Validation loss: 2.190984267060475

Epoch: 5| Step: 7
Training loss: 2.9474339485168457
Validation loss: 2.2029721326725458

Epoch: 5| Step: 8
Training loss: 2.019361972808838
Validation loss: 2.165897512948641

Epoch: 5| Step: 9
Training loss: 2.0726277828216553
Validation loss: 2.17356542618044

Epoch: 5| Step: 10
Training loss: 2.133274555206299
Validation loss: 2.1793836867937477

Epoch: 168| Step: 0
Training loss: 2.3893468379974365
Validation loss: 2.1545930780390257

Epoch: 5| Step: 1
Training loss: 2.023245334625244
Validation loss: 2.1735016915106002

Epoch: 5| Step: 2
Training loss: 1.9492006301879883
Validation loss: 2.1303004436595465

Epoch: 5| Step: 3
Training loss: 2.652930498123169
Validation loss: 2.1926129236016223

Epoch: 5| Step: 4
Training loss: 2.075885057449341
Validation loss: 2.1440709393511534

Epoch: 5| Step: 5
Training loss: 1.8664833307266235
Validation loss: 2.1635047594706216

Epoch: 5| Step: 6
Training loss: 2.0055861473083496
Validation loss: 2.1129560060398553

Epoch: 5| Step: 7
Training loss: 1.8702523708343506
Validation loss: 2.1583245723478255

Epoch: 5| Step: 8
Training loss: 2.6258490085601807
Validation loss: 2.1460996097134006

Epoch: 5| Step: 9
Training loss: 2.5763893127441406
Validation loss: 2.139649898775162

Epoch: 5| Step: 10
Training loss: 2.0161821842193604
Validation loss: 2.1482055725589877

Epoch: 169| Step: 0
Training loss: 1.5615657567977905
Validation loss: 2.1886061263340775

Epoch: 5| Step: 1
Training loss: 2.6494967937469482
Validation loss: 2.184830081078314

Epoch: 5| Step: 2
Training loss: 1.754194974899292
Validation loss: 2.195012113099457

Epoch: 5| Step: 3
Training loss: 1.9073984622955322
Validation loss: 2.169360622282951

Epoch: 5| Step: 4
Training loss: 2.951045513153076
Validation loss: 2.1871981415697324

Epoch: 5| Step: 5
Training loss: 2.0030832290649414
Validation loss: 2.1831862849573933

Epoch: 5| Step: 6
Training loss: 2.310476303100586
Validation loss: 2.166445537280011

Epoch: 5| Step: 7
Training loss: 2.0748448371887207
Validation loss: 2.126518957076534

Epoch: 5| Step: 8
Training loss: 2.5209238529205322
Validation loss: 2.1751775767213557

Epoch: 5| Step: 9
Training loss: 1.92751944065094
Validation loss: 2.1773911394098753

Epoch: 5| Step: 10
Training loss: 2.237992286682129
Validation loss: 2.2022542620217926

Epoch: 170| Step: 0
Training loss: 1.671478509902954
Validation loss: 2.1760817202188636

Epoch: 5| Step: 1
Training loss: 2.412583589553833
Validation loss: 2.163757126818421

Epoch: 5| Step: 2
Training loss: 2.8086862564086914
Validation loss: 2.1859923485786683

Epoch: 5| Step: 3
Training loss: 2.013875722885132
Validation loss: 2.2105333228265085

Epoch: 5| Step: 4
Training loss: 1.857903242111206
Validation loss: 2.171743037880108

Epoch: 5| Step: 5
Training loss: 2.8137621879577637
Validation loss: 2.150169490486063

Epoch: 5| Step: 6
Training loss: 2.360028028488159
Validation loss: 2.1759731077378794

Epoch: 5| Step: 7
Training loss: 2.4172203540802
Validation loss: 2.1788274806032897

Epoch: 5| Step: 8
Training loss: 1.2041380405426025
Validation loss: 2.239943673533778

Epoch: 5| Step: 9
Training loss: 1.859850287437439
Validation loss: 2.1969612670201126

Epoch: 5| Step: 10
Training loss: 2.6362860202789307
Validation loss: 2.168625382966893

Epoch: 171| Step: 0
Training loss: 2.7213027477264404
Validation loss: 2.1923157938065065

Epoch: 5| Step: 1
Training loss: 2.601961851119995
Validation loss: 2.2142815820632444

Epoch: 5| Step: 2
Training loss: 1.9278627634048462
Validation loss: 2.1642301159520305

Epoch: 5| Step: 3
Training loss: 1.6354200839996338
Validation loss: 2.177839563738915

Epoch: 5| Step: 4
Training loss: 2.138456344604492
Validation loss: 2.1741263597242293

Epoch: 5| Step: 5
Training loss: 1.9298721551895142
Validation loss: 2.1989150560030373

Epoch: 5| Step: 6
Training loss: 2.6409192085266113
Validation loss: 2.1884237258665022

Epoch: 5| Step: 7
Training loss: 1.7233095169067383
Validation loss: 2.2076811816102717

Epoch: 5| Step: 8
Training loss: 1.8382432460784912
Validation loss: 2.182738155447027

Epoch: 5| Step: 9
Training loss: 2.4027493000030518
Validation loss: 2.2255024627972673

Epoch: 5| Step: 10
Training loss: 2.4449338912963867
Validation loss: 2.1789748899398313

Epoch: 172| Step: 0
Training loss: 2.3474597930908203
Validation loss: 2.1830589181633404

Epoch: 5| Step: 1
Training loss: 2.257866144180298
Validation loss: 2.164125934723885

Epoch: 5| Step: 2
Training loss: 2.647059917449951
Validation loss: 2.1896286446561097

Epoch: 5| Step: 3
Training loss: 2.0665605068206787
Validation loss: 2.1702227579650057

Epoch: 5| Step: 4
Training loss: 1.41631019115448
Validation loss: 2.1661388258780203

Epoch: 5| Step: 5
Training loss: 2.615718364715576
Validation loss: 2.15383041802273

Epoch: 5| Step: 6
Training loss: 2.328859806060791
Validation loss: 2.1867809321290705

Epoch: 5| Step: 7
Training loss: 2.0754165649414062
Validation loss: 2.1612910070726947

Epoch: 5| Step: 8
Training loss: 2.367513656616211
Validation loss: 2.1644991597821637

Epoch: 5| Step: 9
Training loss: 1.9310734272003174
Validation loss: 2.1510012841993764

Epoch: 5| Step: 10
Training loss: 2.07865571975708
Validation loss: 2.1911434614530174

Epoch: 173| Step: 0
Training loss: 2.097343921661377
Validation loss: 2.1627253486264135

Epoch: 5| Step: 1
Training loss: 2.3019917011260986
Validation loss: 2.138803670483251

Epoch: 5| Step: 2
Training loss: 1.714603066444397
Validation loss: 2.1479771444874425

Epoch: 5| Step: 3
Training loss: 1.7229816913604736
Validation loss: 2.1519824868889263

Epoch: 5| Step: 4
Training loss: 2.726501941680908
Validation loss: 2.173623049131004

Epoch: 5| Step: 5
Training loss: 1.9976310729980469
Validation loss: 2.1532730351212206

Epoch: 5| Step: 6
Training loss: 3.051553249359131
Validation loss: 2.1435396748204387

Epoch: 5| Step: 7
Training loss: 1.6209847927093506
Validation loss: 2.190901005139915

Epoch: 5| Step: 8
Training loss: 1.7260351181030273
Validation loss: 2.182639447591638

Epoch: 5| Step: 9
Training loss: 2.701937437057495
Validation loss: 2.1516768624705653

Epoch: 5| Step: 10
Training loss: 2.236268997192383
Validation loss: 2.1272633690987863

Epoch: 174| Step: 0
Training loss: 2.563947916030884
Validation loss: 2.1856791204021824

Epoch: 5| Step: 1
Training loss: 1.5655663013458252
Validation loss: 2.181007972327612

Epoch: 5| Step: 2
Training loss: 2.5533549785614014
Validation loss: 2.224663790836129

Epoch: 5| Step: 3
Training loss: 1.5680367946624756
Validation loss: 2.208897949546896

Epoch: 5| Step: 4
Training loss: 2.05375337600708
Validation loss: 2.186181640112272

Epoch: 5| Step: 5
Training loss: 2.5941338539123535
Validation loss: 2.230477653523927

Epoch: 5| Step: 6
Training loss: 2.741757869720459
Validation loss: 2.2383460742171093

Epoch: 5| Step: 7
Training loss: 3.193912982940674
Validation loss: 2.199194413359447

Epoch: 5| Step: 8
Training loss: 1.689932107925415
Validation loss: 2.1925568913900726

Epoch: 5| Step: 9
Training loss: 1.2903201580047607
Validation loss: 2.182618684666131

Epoch: 5| Step: 10
Training loss: 1.9898549318313599
Validation loss: 2.168250988888484

Epoch: 175| Step: 0
Training loss: 1.82793390750885
Validation loss: 2.2153210011861657

Epoch: 5| Step: 1
Training loss: 2.0038607120513916
Validation loss: 2.1782583395640054

Epoch: 5| Step: 2
Training loss: 2.4100849628448486
Validation loss: 2.1949445201504614

Epoch: 5| Step: 3
Training loss: 2.2549126148223877
Validation loss: 2.182950045472832

Epoch: 5| Step: 4
Training loss: 2.429758071899414
Validation loss: 2.2289760394762923

Epoch: 5| Step: 5
Training loss: 2.6498117446899414
Validation loss: 2.175446641060614

Epoch: 5| Step: 6
Training loss: 1.5880205631256104
Validation loss: 2.2125273122582385

Epoch: 5| Step: 7
Training loss: 3.1366729736328125
Validation loss: 2.2032934478534165

Epoch: 5| Step: 8
Training loss: 1.333478331565857
Validation loss: 2.187206816929643

Epoch: 5| Step: 9
Training loss: 2.3418357372283936
Validation loss: 2.165488305912223

Epoch: 5| Step: 10
Training loss: 2.1344821453094482
Validation loss: 2.183210580579696

Epoch: 176| Step: 0
Training loss: 2.3728816509246826
Validation loss: 2.1937293570528746

Epoch: 5| Step: 1
Training loss: 2.005760669708252
Validation loss: 2.225993302560622

Epoch: 5| Step: 2
Training loss: 1.736380934715271
Validation loss: 2.168930571566346

Epoch: 5| Step: 3
Training loss: 2.176863193511963
Validation loss: 2.1998337225247453

Epoch: 5| Step: 4
Training loss: 2.4829652309417725
Validation loss: 2.16512155789201

Epoch: 5| Step: 5
Training loss: 2.188875198364258
Validation loss: 2.1886962177932903

Epoch: 5| Step: 6
Training loss: 1.5899368524551392
Validation loss: 2.174511081428938

Epoch: 5| Step: 7
Training loss: 1.885859727859497
Validation loss: 2.165452448270654

Epoch: 5| Step: 8
Training loss: 2.6921985149383545
Validation loss: 2.192518077870851

Epoch: 5| Step: 9
Training loss: 2.7385401725769043
Validation loss: 2.1402515749777518

Epoch: 5| Step: 10
Training loss: 1.964039921760559
Validation loss: 2.1528889043356783

Epoch: 177| Step: 0
Training loss: 1.7864326238632202
Validation loss: 2.1507650959876274

Epoch: 5| Step: 1
Training loss: 2.157827138900757
Validation loss: 2.1832217439528434

Epoch: 5| Step: 2
Training loss: 1.9115768671035767
Validation loss: 2.1665683702756

Epoch: 5| Step: 3
Training loss: 1.734788179397583
Validation loss: 2.175058659686837

Epoch: 5| Step: 4
Training loss: 2.22576904296875
Validation loss: 2.1717309900509414

Epoch: 5| Step: 5
Training loss: 2.4802699089050293
Validation loss: 2.1635990053094845

Epoch: 5| Step: 6
Training loss: 2.3467154502868652
Validation loss: 2.173243481625793

Epoch: 5| Step: 7
Training loss: 1.7268340587615967
Validation loss: 2.158447070788312

Epoch: 5| Step: 8
Training loss: 2.9109792709350586
Validation loss: 2.2125208377838135

Epoch: 5| Step: 9
Training loss: 2.2044434547424316
Validation loss: 2.1537633583109868

Epoch: 5| Step: 10
Training loss: 2.5694031715393066
Validation loss: 2.223385128923642

Epoch: 178| Step: 0
Training loss: 1.4913464784622192
Validation loss: 2.1442955334981284

Epoch: 5| Step: 1
Training loss: 2.4475669860839844
Validation loss: 2.1863003161645707

Epoch: 5| Step: 2
Training loss: 2.296002149581909
Validation loss: 2.183576709480696

Epoch: 5| Step: 3
Training loss: 2.2553164958953857
Validation loss: 2.192113507178522

Epoch: 5| Step: 4
Training loss: 2.4132323265075684
Validation loss: 2.1949812699389715

Epoch: 5| Step: 5
Training loss: 2.3556861877441406
Validation loss: 2.2341696652032996

Epoch: 5| Step: 6
Training loss: 2.2478747367858887
Validation loss: 2.1928955021724907

Epoch: 5| Step: 7
Training loss: 2.045802354812622
Validation loss: 2.232697290758933

Epoch: 5| Step: 8
Training loss: 2.031127452850342
Validation loss: 2.225242999292189

Epoch: 5| Step: 9
Training loss: 1.9108127355575562
Validation loss: 2.208688656489054

Epoch: 5| Step: 10
Training loss: 2.397728204727173
Validation loss: 2.2062859509580877

Epoch: 179| Step: 0
Training loss: 1.6978752613067627
Validation loss: 2.237992391791395

Epoch: 5| Step: 1
Training loss: 2.362631320953369
Validation loss: 2.2067002711757535

Epoch: 5| Step: 2
Training loss: 2.202362537384033
Validation loss: 2.184774000157592

Epoch: 5| Step: 3
Training loss: 1.7390514612197876
Validation loss: 2.1798705926505466

Epoch: 5| Step: 4
Training loss: 2.4400687217712402
Validation loss: 2.1768409616203717

Epoch: 5| Step: 5
Training loss: 2.0161309242248535
Validation loss: 2.195604137195054

Epoch: 5| Step: 6
Training loss: 2.5549368858337402
Validation loss: 2.1755234515795143

Epoch: 5| Step: 7
Training loss: 2.1269962787628174
Validation loss: 2.1551985715025213

Epoch: 5| Step: 8
Training loss: 1.8153746128082275
Validation loss: 2.163016250056605

Epoch: 5| Step: 9
Training loss: 2.8664920330047607
Validation loss: 2.182760941084995

Epoch: 5| Step: 10
Training loss: 1.920990228652954
Validation loss: 2.1616606097067557

Epoch: 180| Step: 0
Training loss: 1.875049352645874
Validation loss: 2.1767828015870947

Epoch: 5| Step: 1
Training loss: 2.6509671211242676
Validation loss: 2.1879711958669845

Epoch: 5| Step: 2
Training loss: 1.9544662237167358
Validation loss: 2.1506867049842753

Epoch: 5| Step: 3
Training loss: 1.7575267553329468
Validation loss: 2.158230544418417

Epoch: 5| Step: 4
Training loss: 2.2412381172180176
Validation loss: 2.1339867768749112

Epoch: 5| Step: 5
Training loss: 1.8569313287734985
Validation loss: 2.172419709544028

Epoch: 5| Step: 6
Training loss: 2.1697540283203125
Validation loss: 2.204966652777887

Epoch: 5| Step: 7
Training loss: 1.6544967889785767
Validation loss: 2.1566552141661286

Epoch: 5| Step: 8
Training loss: 2.761892795562744
Validation loss: 2.1672738059874503

Epoch: 5| Step: 9
Training loss: 2.395555019378662
Validation loss: 2.14344512262652

Epoch: 5| Step: 10
Training loss: 2.4644086360931396
Validation loss: 2.181407615702639

Epoch: 181| Step: 0
Training loss: 1.9889017343521118
Validation loss: 2.152195267779853

Epoch: 5| Step: 1
Training loss: 2.088029384613037
Validation loss: 2.1685085117176013

Epoch: 5| Step: 2
Training loss: 2.50952410697937
Validation loss: 2.16277789685034

Epoch: 5| Step: 3
Training loss: 2.258608818054199
Validation loss: 2.1753424290687806

Epoch: 5| Step: 4
Training loss: 2.496920108795166
Validation loss: 2.167627062848819

Epoch: 5| Step: 5
Training loss: 1.9564571380615234
Validation loss: 2.1410497901260213

Epoch: 5| Step: 6
Training loss: 2.0889949798583984
Validation loss: 2.216890791411041

Epoch: 5| Step: 7
Training loss: 1.600245475769043
Validation loss: 2.199721379946637

Epoch: 5| Step: 8
Training loss: 2.4920217990875244
Validation loss: 2.1767158380118747

Epoch: 5| Step: 9
Training loss: 2.69148325920105
Validation loss: 2.1180248824498986

Epoch: 5| Step: 10
Training loss: 1.5306673049926758
Validation loss: 2.1543154178127164

Epoch: 182| Step: 0
Training loss: 2.018889904022217
Validation loss: 2.189698778172975

Epoch: 5| Step: 1
Training loss: 1.7652438879013062
Validation loss: 2.2095245802274315

Epoch: 5| Step: 2
Training loss: 2.363736391067505
Validation loss: 2.1748386070292485

Epoch: 5| Step: 3
Training loss: 3.4935288429260254
Validation loss: 2.1816691083292805

Epoch: 5| Step: 4
Training loss: 1.6940501928329468
Validation loss: 2.234677453194895

Epoch: 5| Step: 5
Training loss: 1.6002328395843506
Validation loss: 2.1954121871661116

Epoch: 5| Step: 6
Training loss: 2.7565929889678955
Validation loss: 2.170559516517065

Epoch: 5| Step: 7
Training loss: 1.2892100811004639
Validation loss: 2.173897140769548

Epoch: 5| Step: 8
Training loss: 2.131906032562256
Validation loss: 2.1879831283323226

Epoch: 5| Step: 9
Training loss: 2.4868650436401367
Validation loss: 2.1611204942067466

Epoch: 5| Step: 10
Training loss: 1.935719609260559
Validation loss: 2.200943159800704

Epoch: 183| Step: 0
Training loss: 1.9005531072616577
Validation loss: 2.2039572346595024

Epoch: 5| Step: 1
Training loss: 2.318830966949463
Validation loss: 2.195726092143725

Epoch: 5| Step: 2
Training loss: 2.3926265239715576
Validation loss: 2.154461594038112

Epoch: 5| Step: 3
Training loss: 2.300041437149048
Validation loss: 2.196491943892612

Epoch: 5| Step: 4
Training loss: 1.9763422012329102
Validation loss: 2.1695601568427136

Epoch: 5| Step: 5
Training loss: 2.5110878944396973
Validation loss: 2.17500304150325

Epoch: 5| Step: 6
Training loss: 1.7143535614013672
Validation loss: 2.1719436927508284

Epoch: 5| Step: 7
Training loss: 2.2060790061950684
Validation loss: 2.1830812987460884

Epoch: 5| Step: 8
Training loss: 2.7473812103271484
Validation loss: 2.1426912110338927

Epoch: 5| Step: 9
Training loss: 1.8733659982681274
Validation loss: 2.160248009107446

Epoch: 5| Step: 10
Training loss: 1.9957448244094849
Validation loss: 2.127578677669648

Epoch: 184| Step: 0
Training loss: 1.6912517547607422
Validation loss: 2.1909532598269883

Epoch: 5| Step: 1
Training loss: 2.3665480613708496
Validation loss: 2.1828904446735176

Epoch: 5| Step: 2
Training loss: 1.7099883556365967
Validation loss: 2.204587810782976

Epoch: 5| Step: 3
Training loss: 2.454700231552124
Validation loss: 2.163330942071894

Epoch: 5| Step: 4
Training loss: 1.893601417541504
Validation loss: 2.1564509740439792

Epoch: 5| Step: 5
Training loss: 3.0219969749450684
Validation loss: 2.161848488674369

Epoch: 5| Step: 6
Training loss: 2.2196478843688965
Validation loss: 2.1276574506554553

Epoch: 5| Step: 7
Training loss: 2.630338191986084
Validation loss: 2.1556494005264772

Epoch: 5| Step: 8
Training loss: 2.255211591720581
Validation loss: 2.1706536944194506

Epoch: 5| Step: 9
Training loss: 1.9872777462005615
Validation loss: 2.129527671362764

Epoch: 5| Step: 10
Training loss: 1.742587685585022
Validation loss: 2.1402679245959044

Epoch: 185| Step: 0
Training loss: 2.1658358573913574
Validation loss: 2.182788707876718

Epoch: 5| Step: 1
Training loss: 2.2636382579803467
Validation loss: 2.101390997568766

Epoch: 5| Step: 2
Training loss: 1.9157257080078125
Validation loss: 2.1906759636376494

Epoch: 5| Step: 3
Training loss: 2.192340135574341
Validation loss: 2.135062010057511

Epoch: 5| Step: 4
Training loss: 1.5153402090072632
Validation loss: 2.129506608491303

Epoch: 5| Step: 5
Training loss: 2.4574177265167236
Validation loss: 2.1880165812789754

Epoch: 5| Step: 6
Training loss: 1.883165955543518
Validation loss: 2.1778114111192766

Epoch: 5| Step: 7
Training loss: 2.350320816040039
Validation loss: 2.216446427888768

Epoch: 5| Step: 8
Training loss: 2.2544937133789062
Validation loss: 2.1968457545003583

Epoch: 5| Step: 9
Training loss: 2.3847110271453857
Validation loss: 2.163427842560635

Epoch: 5| Step: 10
Training loss: 2.4350404739379883
Validation loss: 2.159829326855239

Epoch: 186| Step: 0
Training loss: 2.0834827423095703
Validation loss: 2.207859290543423

Epoch: 5| Step: 1
Training loss: 1.938981056213379
Validation loss: 2.1914051758345736

Epoch: 5| Step: 2
Training loss: 2.7128520011901855
Validation loss: 2.2095088189648044

Epoch: 5| Step: 3
Training loss: 2.4561569690704346
Validation loss: 2.153222019954394

Epoch: 5| Step: 4
Training loss: 1.899634599685669
Validation loss: 2.200497476003503

Epoch: 5| Step: 5
Training loss: 1.9975591897964478
Validation loss: 2.174456811720325

Epoch: 5| Step: 6
Training loss: 2.3209140300750732
Validation loss: 2.1853528343221194

Epoch: 5| Step: 7
Training loss: 1.8594707250595093
Validation loss: 2.19115384035213

Epoch: 5| Step: 8
Training loss: 2.5180466175079346
Validation loss: 2.2142725388209024

Epoch: 5| Step: 9
Training loss: 2.4768872261047363
Validation loss: 2.206930829632667

Epoch: 5| Step: 10
Training loss: 1.6320382356643677
Validation loss: 2.230286685369348

Epoch: 187| Step: 0
Training loss: 2.0481765270233154
Validation loss: 2.2189338848155034

Epoch: 5| Step: 1
Training loss: 2.2116382122039795
Validation loss: 2.196517139352778

Epoch: 5| Step: 2
Training loss: 2.195237159729004
Validation loss: 2.232349657243298

Epoch: 5| Step: 3
Training loss: 2.120424270629883
Validation loss: 2.1847670309005247

Epoch: 5| Step: 4
Training loss: 2.3759453296661377
Validation loss: 2.1532898218401018

Epoch: 5| Step: 5
Training loss: 2.1415843963623047
Validation loss: 2.16776369976741

Epoch: 5| Step: 6
Training loss: 2.226931095123291
Validation loss: 2.1614141387324177

Epoch: 5| Step: 7
Training loss: 2.19720196723938
Validation loss: 2.2023681209933375

Epoch: 5| Step: 8
Training loss: 1.7446033954620361
Validation loss: 2.1936608975933445

Epoch: 5| Step: 9
Training loss: 2.0056958198547363
Validation loss: 2.1769836166853547

Epoch: 5| Step: 10
Training loss: 2.5294203758239746
Validation loss: 2.1859151035226803

Epoch: 188| Step: 0
Training loss: 2.451612949371338
Validation loss: 2.1703427325012865

Epoch: 5| Step: 1
Training loss: 2.1251463890075684
Validation loss: 2.20083624060436

Epoch: 5| Step: 2
Training loss: 2.6795170307159424
Validation loss: 2.1853385740710842

Epoch: 5| Step: 3
Training loss: 2.777780532836914
Validation loss: 2.154516658475322

Epoch: 5| Step: 4
Training loss: 1.8640034198760986
Validation loss: 2.1457435559200984

Epoch: 5| Step: 5
Training loss: 2.021733045578003
Validation loss: 2.1450418015962005

Epoch: 5| Step: 6
Training loss: 2.1829631328582764
Validation loss: 2.156541975595618

Epoch: 5| Step: 7
Training loss: 2.3250374794006348
Validation loss: 2.1815647168826033

Epoch: 5| Step: 8
Training loss: 1.6063413619995117
Validation loss: 2.169578065154373

Epoch: 5| Step: 9
Training loss: 1.8182671070098877
Validation loss: 2.141059221759919

Epoch: 5| Step: 10
Training loss: 1.9040781259536743
Validation loss: 2.1408273661008446

Epoch: 189| Step: 0
Training loss: 2.6751742362976074
Validation loss: 2.1662929750257924

Epoch: 5| Step: 1
Training loss: 1.988041639328003
Validation loss: 2.1569281726755123

Epoch: 5| Step: 2
Training loss: 1.9632365703582764
Validation loss: 2.1664415046732914

Epoch: 5| Step: 3
Training loss: 2.0696606636047363
Validation loss: 2.155173745206607

Epoch: 5| Step: 4
Training loss: 1.661888837814331
Validation loss: 2.166898855599024

Epoch: 5| Step: 5
Training loss: 2.429307460784912
Validation loss: 2.1646625585453485

Epoch: 5| Step: 6
Training loss: 2.4246201515197754
Validation loss: 2.2095511446716967

Epoch: 5| Step: 7
Training loss: 1.6713842153549194
Validation loss: 2.163335971934821

Epoch: 5| Step: 8
Training loss: 2.622781276702881
Validation loss: 2.1997258073540142

Epoch: 5| Step: 9
Training loss: 2.182565689086914
Validation loss: 2.151044721244484

Epoch: 5| Step: 10
Training loss: 2.0931427478790283
Validation loss: 2.175732425464097

Epoch: 190| Step: 0
Training loss: 2.2556025981903076
Validation loss: 2.1750566523562194

Epoch: 5| Step: 1
Training loss: 2.2764902114868164
Validation loss: 2.183842230868596

Epoch: 5| Step: 2
Training loss: 1.9355366230010986
Validation loss: 2.201358684929468

Epoch: 5| Step: 3
Training loss: 2.0371575355529785
Validation loss: 2.1575573977603706

Epoch: 5| Step: 4
Training loss: 1.9462082386016846
Validation loss: 2.1802866279437976

Epoch: 5| Step: 5
Training loss: 2.4192616939544678
Validation loss: 2.178528674187199

Epoch: 5| Step: 6
Training loss: 2.668607711791992
Validation loss: 2.186141005126379

Epoch: 5| Step: 7
Training loss: 1.5371992588043213
Validation loss: 2.1867334573499617

Epoch: 5| Step: 8
Training loss: 1.8667113780975342
Validation loss: 2.2228019814337454

Epoch: 5| Step: 9
Training loss: 2.7948217391967773
Validation loss: 2.1626297043215845

Epoch: 5| Step: 10
Training loss: 1.9324941635131836
Validation loss: 2.1877079599647113

Epoch: 191| Step: 0
Training loss: 2.2400498390197754
Validation loss: 2.150214533652029

Epoch: 5| Step: 1
Training loss: 2.4065163135528564
Validation loss: 2.1966716935557704

Epoch: 5| Step: 2
Training loss: 1.8127052783966064
Validation loss: 2.184072120215303

Epoch: 5| Step: 3
Training loss: 2.06441593170166
Validation loss: 2.160005000329787

Epoch: 5| Step: 4
Training loss: 2.2944159507751465
Validation loss: 2.189821620141306

Epoch: 5| Step: 5
Training loss: 2.267289638519287
Validation loss: 2.1730433074376916

Epoch: 5| Step: 6
Training loss: 2.118330240249634
Validation loss: 2.2116191476903935

Epoch: 5| Step: 7
Training loss: 1.9903148412704468
Validation loss: 2.2050827908259567

Epoch: 5| Step: 8
Training loss: 2.4501192569732666
Validation loss: 2.201777519718293

Epoch: 5| Step: 9
Training loss: 1.8421825170516968
Validation loss: 2.1649469150009977

Epoch: 5| Step: 10
Training loss: 2.319660186767578
Validation loss: 2.163797402894625

Epoch: 192| Step: 0
Training loss: 2.369255781173706
Validation loss: 2.1377896698572303

Epoch: 5| Step: 1
Training loss: 1.7269853353500366
Validation loss: 2.178682411870649

Epoch: 5| Step: 2
Training loss: 1.9026092290878296
Validation loss: 2.2267096760452434

Epoch: 5| Step: 3
Training loss: 1.8124210834503174
Validation loss: 2.156193474287628

Epoch: 5| Step: 4
Training loss: 2.3237087726593018
Validation loss: 2.1705264814438356

Epoch: 5| Step: 5
Training loss: 2.1373870372772217
Validation loss: 2.213119240217311

Epoch: 5| Step: 6
Training loss: 2.57066011428833
Validation loss: 2.206050063974114

Epoch: 5| Step: 7
Training loss: 1.8116836547851562
Validation loss: 2.1727874843023156

Epoch: 5| Step: 8
Training loss: 2.806605577468872
Validation loss: 2.1598967300948275

Epoch: 5| Step: 9
Training loss: 2.2138237953186035
Validation loss: 2.160097575956775

Epoch: 5| Step: 10
Training loss: 2.036728620529175
Validation loss: 2.152759075164795

Epoch: 193| Step: 0
Training loss: 1.7254142761230469
Validation loss: 2.1547896605665966

Epoch: 5| Step: 1
Training loss: 2.040515422821045
Validation loss: 2.206754425520538

Epoch: 5| Step: 2
Training loss: 2.429230213165283
Validation loss: 2.1236100222474787

Epoch: 5| Step: 3
Training loss: 2.2744712829589844
Validation loss: 2.1993467884678997

Epoch: 5| Step: 4
Training loss: 2.719517230987549
Validation loss: 2.1544811699980047

Epoch: 5| Step: 5
Training loss: 2.0409340858459473
Validation loss: 2.1830477791447795

Epoch: 5| Step: 6
Training loss: 2.0934042930603027
Validation loss: 2.1696177105749808

Epoch: 5| Step: 7
Training loss: 1.6419086456298828
Validation loss: 2.1456591365157918

Epoch: 5| Step: 8
Training loss: 2.335310459136963
Validation loss: 2.197952393562563

Epoch: 5| Step: 9
Training loss: 2.156806707382202
Validation loss: 2.1895264169221282

Epoch: 5| Step: 10
Training loss: 2.3087387084960938
Validation loss: 2.1566089917254705

Epoch: 194| Step: 0
Training loss: 3.0074362754821777
Validation loss: 2.204143206278483

Epoch: 5| Step: 1
Training loss: 1.8461580276489258
Validation loss: 2.1840202154651767

Epoch: 5| Step: 2
Training loss: 2.696850061416626
Validation loss: 2.1756359787397486

Epoch: 5| Step: 3
Training loss: 2.045738697052002
Validation loss: 2.2047784302824285

Epoch: 5| Step: 4
Training loss: 1.883532166481018
Validation loss: 2.2160550189274613

Epoch: 5| Step: 5
Training loss: 1.5351232290267944
Validation loss: 2.167535258877662

Epoch: 5| Step: 6
Training loss: 1.8995144367218018
Validation loss: 2.194349927286948

Epoch: 5| Step: 7
Training loss: 2.4892544746398926
Validation loss: 2.2109028203513033

Epoch: 5| Step: 8
Training loss: 2.129478693008423
Validation loss: 2.1870654372758764

Epoch: 5| Step: 9
Training loss: 2.126674175262451
Validation loss: 2.2149404710338962

Epoch: 5| Step: 10
Training loss: 1.599135398864746
Validation loss: 2.195774088623703

Epoch: 195| Step: 0
Training loss: 2.157013416290283
Validation loss: 2.193909583553191

Epoch: 5| Step: 1
Training loss: 2.300527334213257
Validation loss: 2.204186454896004

Epoch: 5| Step: 2
Training loss: 2.2788729667663574
Validation loss: 2.2118593826088855

Epoch: 5| Step: 3
Training loss: 2.1379740238189697
Validation loss: 2.2333160959264284

Epoch: 5| Step: 4
Training loss: 2.2867276668548584
Validation loss: 2.219984657020979

Epoch: 5| Step: 5
Training loss: 2.1505963802337646
Validation loss: 2.2037157448389197

Epoch: 5| Step: 6
Training loss: 2.111628293991089
Validation loss: 2.202254142812503

Epoch: 5| Step: 7
Training loss: 2.1976211071014404
Validation loss: 2.22347947858995

Epoch: 5| Step: 8
Training loss: 1.5739519596099854
Validation loss: 2.184826058726157

Epoch: 5| Step: 9
Training loss: 2.4039738178253174
Validation loss: 2.1544605570454753

Epoch: 5| Step: 10
Training loss: 2.0121307373046875
Validation loss: 2.1516860479949624

Epoch: 196| Step: 0
Training loss: 2.6500399112701416
Validation loss: 2.192524976627801

Epoch: 5| Step: 1
Training loss: 2.403580904006958
Validation loss: 2.1992696049392864

Epoch: 5| Step: 2
Training loss: 2.592428684234619
Validation loss: 2.2275122455371323

Epoch: 5| Step: 3
Training loss: 2.500349283218384
Validation loss: 2.2370631887066748

Epoch: 5| Step: 4
Training loss: 1.479729413986206
Validation loss: 2.2069315500156854

Epoch: 5| Step: 5
Training loss: 2.0187859535217285
Validation loss: 2.1419102940508115

Epoch: 5| Step: 6
Training loss: 2.229759693145752
Validation loss: 2.204233507956228

Epoch: 5| Step: 7
Training loss: 1.599857211112976
Validation loss: 2.1596036316246114

Epoch: 5| Step: 8
Training loss: 1.8044588565826416
Validation loss: 2.1885875937759236

Epoch: 5| Step: 9
Training loss: 1.9395774602890015
Validation loss: 2.181213532724688

Epoch: 5| Step: 10
Training loss: 2.545372247695923
Validation loss: 2.1898282522796304

Epoch: 197| Step: 0
Training loss: 1.6138519048690796
Validation loss: 2.1472089598255772

Epoch: 5| Step: 1
Training loss: 1.9777320623397827
Validation loss: 2.2194618909589705

Epoch: 5| Step: 2
Training loss: 2.7995834350585938
Validation loss: 2.184339310533257

Epoch: 5| Step: 3
Training loss: 1.814444899559021
Validation loss: 2.1391969534658615

Epoch: 5| Step: 4
Training loss: 1.3977179527282715
Validation loss: 2.196785872982394

Epoch: 5| Step: 5
Training loss: 1.65399968624115
Validation loss: 2.137775049414686

Epoch: 5| Step: 6
Training loss: 2.4076967239379883
Validation loss: 2.1442275021665838

Epoch: 5| Step: 7
Training loss: 2.998243570327759
Validation loss: 2.165142451563189

Epoch: 5| Step: 8
Training loss: 2.487532615661621
Validation loss: 2.210602557787331

Epoch: 5| Step: 9
Training loss: 1.9671436548233032
Validation loss: 2.1855441447227233

Epoch: 5| Step: 10
Training loss: 2.6284782886505127
Validation loss: 2.1909733972241803

Epoch: 198| Step: 0
Training loss: 2.234382152557373
Validation loss: 2.217856980139209

Epoch: 5| Step: 1
Training loss: 2.138962984085083
Validation loss: 2.138699241863784

Epoch: 5| Step: 2
Training loss: 2.483367443084717
Validation loss: 2.2051246678957375

Epoch: 5| Step: 3
Training loss: 2.385481357574463
Validation loss: 2.2042256888522895

Epoch: 5| Step: 4
Training loss: 1.7922461032867432
Validation loss: 2.1684524551514657

Epoch: 5| Step: 5
Training loss: 1.9299986362457275
Validation loss: 2.214744193579561

Epoch: 5| Step: 6
Training loss: 1.5994666814804077
Validation loss: 2.22140605731677

Epoch: 5| Step: 7
Training loss: 2.093442916870117
Validation loss: 2.214532216389974

Epoch: 5| Step: 8
Training loss: 2.219416618347168
Validation loss: 2.171598372920867

Epoch: 5| Step: 9
Training loss: 2.2930545806884766
Validation loss: 2.1957227722291024

Epoch: 5| Step: 10
Training loss: 2.6837291717529297
Validation loss: 2.1572074877318514

Epoch: 199| Step: 0
Training loss: 2.1509876251220703
Validation loss: 2.223504762495718

Epoch: 5| Step: 1
Training loss: 2.6365156173706055
Validation loss: 2.200082702021445

Epoch: 5| Step: 2
Training loss: 2.200234889984131
Validation loss: 2.1887510771392495

Epoch: 5| Step: 3
Training loss: 1.9348684549331665
Validation loss: 2.1835305793311006

Epoch: 5| Step: 4
Training loss: 2.199166774749756
Validation loss: 2.197928121013026

Epoch: 5| Step: 5
Training loss: 2.196070671081543
Validation loss: 2.205108209322858

Epoch: 5| Step: 6
Training loss: 2.164238691329956
Validation loss: 2.2341697985126125

Epoch: 5| Step: 7
Training loss: 1.9272844791412354
Validation loss: 2.164865529665383

Epoch: 5| Step: 8
Training loss: 1.9178426265716553
Validation loss: 2.200636955999559

Epoch: 5| Step: 9
Training loss: 2.1961257457733154
Validation loss: 2.206628978893321

Epoch: 5| Step: 10
Training loss: 2.2120964527130127
Validation loss: 2.1573458461351294

Epoch: 200| Step: 0
Training loss: 1.8030821084976196
Validation loss: 2.191929614672097

Epoch: 5| Step: 1
Training loss: 2.392615795135498
Validation loss: 2.2224646178624963

Epoch: 5| Step: 2
Training loss: 2.176001787185669
Validation loss: 2.1969516097858386

Epoch: 5| Step: 3
Training loss: 2.597348690032959
Validation loss: 2.183135167244942

Epoch: 5| Step: 4
Training loss: 2.1599223613739014
Validation loss: 2.171241285980389

Epoch: 5| Step: 5
Training loss: 1.948285460472107
Validation loss: 2.17030736964236

Epoch: 5| Step: 6
Training loss: 2.115610122680664
Validation loss: 2.1508424051346315

Epoch: 5| Step: 7
Training loss: 2.1025521755218506
Validation loss: 2.2084215353893977

Epoch: 5| Step: 8
Training loss: 2.0010933876037598
Validation loss: 2.179006104828209

Epoch: 5| Step: 9
Training loss: 2.263962507247925
Validation loss: 2.2240737330529

Epoch: 5| Step: 10
Training loss: 2.007460117340088
Validation loss: 2.15467232401653

Epoch: 201| Step: 0
Training loss: 2.336103916168213
Validation loss: 2.191497934761868

Epoch: 5| Step: 1
Training loss: 2.111785411834717
Validation loss: 2.2183284349338983

Epoch: 5| Step: 2
Training loss: 2.08500337600708
Validation loss: 2.1646280416878323

Epoch: 5| Step: 3
Training loss: 2.2678720951080322
Validation loss: 2.2401844634804675

Epoch: 5| Step: 4
Training loss: 1.8832595348358154
Validation loss: 2.226327601299491

Epoch: 5| Step: 5
Training loss: 2.281709671020508
Validation loss: 2.156049398965733

Epoch: 5| Step: 6
Training loss: 2.774620532989502
Validation loss: 2.185507274443103

Epoch: 5| Step: 7
Training loss: 2.0039961338043213
Validation loss: 2.2039239727040774

Epoch: 5| Step: 8
Training loss: 2.0349509716033936
Validation loss: 2.1933561102036507

Epoch: 5| Step: 9
Training loss: 2.039585828781128
Validation loss: 2.174871471620375

Epoch: 5| Step: 10
Training loss: 1.52418851852417
Validation loss: 2.21026369320449

Epoch: 202| Step: 0
Training loss: 2.2773940563201904
Validation loss: 2.186820435267623

Epoch: 5| Step: 1
Training loss: 2.0781331062316895
Validation loss: 2.1924740037610455

Epoch: 5| Step: 2
Training loss: 2.5041489601135254
Validation loss: 2.1696130024489535

Epoch: 5| Step: 3
Training loss: 2.0628457069396973
Validation loss: 2.2022127451435214

Epoch: 5| Step: 4
Training loss: 2.263948917388916
Validation loss: 2.187481936588082

Epoch: 5| Step: 5
Training loss: 1.9522342681884766
Validation loss: 2.188970528623109

Epoch: 5| Step: 6
Training loss: 2.017531633377075
Validation loss: 2.1379550105781964

Epoch: 5| Step: 7
Training loss: 2.323654890060425
Validation loss: 2.1847524284034647

Epoch: 5| Step: 8
Training loss: 1.574549913406372
Validation loss: 2.1400339680333293

Epoch: 5| Step: 9
Training loss: 2.1589767932891846
Validation loss: 2.1801892736906647

Epoch: 5| Step: 10
Training loss: 2.4891340732574463
Validation loss: 2.1616930679608415

Epoch: 203| Step: 0
Training loss: 2.6065189838409424
Validation loss: 2.153985684917819

Epoch: 5| Step: 1
Training loss: 1.9938303232192993
Validation loss: 2.187923651869579

Epoch: 5| Step: 2
Training loss: 2.772279739379883
Validation loss: 2.1758373052843156

Epoch: 5| Step: 3
Training loss: 1.9207592010498047
Validation loss: 2.195906376325956

Epoch: 5| Step: 4
Training loss: 2.822624444961548
Validation loss: 2.1591102282206216

Epoch: 5| Step: 5
Training loss: 1.3694449663162231
Validation loss: 2.174562931060791

Epoch: 5| Step: 6
Training loss: 2.5132904052734375
Validation loss: 2.167974325918382

Epoch: 5| Step: 7
Training loss: 2.471579074859619
Validation loss: 2.2148032957507717

Epoch: 5| Step: 8
Training loss: 1.6657625436782837
Validation loss: 2.1976082042981218

Epoch: 5| Step: 9
Training loss: 1.3511478900909424
Validation loss: 2.1724408018973564

Epoch: 5| Step: 10
Training loss: 2.070018768310547
Validation loss: 2.205777647674725

Epoch: 204| Step: 0
Training loss: 1.6653251647949219
Validation loss: 2.1967959660355763

Epoch: 5| Step: 1
Training loss: 2.365889072418213
Validation loss: 2.1488925359582387

Epoch: 5| Step: 2
Training loss: 2.5135490894317627
Validation loss: 2.187217561147546

Epoch: 5| Step: 3
Training loss: 2.1365506649017334
Validation loss: 2.1906808140457317

Epoch: 5| Step: 4
Training loss: 2.398010492324829
Validation loss: 2.236941232476183

Epoch: 5| Step: 5
Training loss: 1.7474491596221924
Validation loss: 2.197365617239347

Epoch: 5| Step: 6
Training loss: 2.1871562004089355
Validation loss: 2.2351385752360025

Epoch: 5| Step: 7
Training loss: 2.21789813041687
Validation loss: 2.228387289149787

Epoch: 5| Step: 8
Training loss: 1.5922505855560303
Validation loss: 2.214070362429465

Epoch: 5| Step: 9
Training loss: 2.0616652965545654
Validation loss: 2.2270374093004452

Epoch: 5| Step: 10
Training loss: 2.4693775177001953
Validation loss: 2.2247396207624868

Epoch: 205| Step: 0
Training loss: 2.4075353145599365
Validation loss: 2.2026989536900676

Epoch: 5| Step: 1
Training loss: 2.0839452743530273
Validation loss: 2.172386907762097

Epoch: 5| Step: 2
Training loss: 1.9368503093719482
Validation loss: 2.1894724471594698

Epoch: 5| Step: 3
Training loss: 2.0240371227264404
Validation loss: 2.193763191981982

Epoch: 5| Step: 4
Training loss: 1.5897998809814453
Validation loss: 2.185701443303016

Epoch: 5| Step: 5
Training loss: 1.9693586826324463
Validation loss: 2.164705866126604

Epoch: 5| Step: 6
Training loss: 2.2360572814941406
Validation loss: 2.235170018288397

Epoch: 5| Step: 7
Training loss: 2.522773027420044
Validation loss: 2.2259786128997803

Epoch: 5| Step: 8
Training loss: 1.6197868585586548
Validation loss: 2.167494576464417

Epoch: 5| Step: 9
Training loss: 2.930368185043335
Validation loss: 2.157420430132138

Epoch: 5| Step: 10
Training loss: 1.992034673690796
Validation loss: 2.1922574133001347

Epoch: 206| Step: 0
Training loss: 2.225266933441162
Validation loss: 2.2011069597736483

Epoch: 5| Step: 1
Training loss: 1.9026739597320557
Validation loss: 2.213414804909819

Epoch: 5| Step: 2
Training loss: 1.6356548070907593
Validation loss: 2.2128746355733564

Epoch: 5| Step: 3
Training loss: 1.9910846948623657
Validation loss: 2.180350947123702

Epoch: 5| Step: 4
Training loss: 1.8168246746063232
Validation loss: 2.1834845876181

Epoch: 5| Step: 5
Training loss: 2.4758708477020264
Validation loss: 2.1745068873128583

Epoch: 5| Step: 6
Training loss: 2.2788965702056885
Validation loss: 2.1892969403215634

Epoch: 5| Step: 7
Training loss: 1.4609811305999756
Validation loss: 2.2131133464074906

Epoch: 5| Step: 8
Training loss: 2.465150833129883
Validation loss: 2.1523026830406597

Epoch: 5| Step: 9
Training loss: 2.8770394325256348
Validation loss: 2.1832953396663872

Epoch: 5| Step: 10
Training loss: 2.798038959503174
Validation loss: 2.173080236681046

Epoch: 207| Step: 0
Training loss: 1.5404412746429443
Validation loss: 2.219200635469088

Epoch: 5| Step: 1
Training loss: 2.089064359664917
Validation loss: 2.1617548158091884

Epoch: 5| Step: 2
Training loss: 2.0436654090881348
Validation loss: 2.169857394310736

Epoch: 5| Step: 3
Training loss: 2.6413588523864746
Validation loss: 2.1834367552111225

Epoch: 5| Step: 4
Training loss: 2.256399154663086
Validation loss: 2.1839669058399815

Epoch: 5| Step: 5
Training loss: 1.783461332321167
Validation loss: 2.193549444598536

Epoch: 5| Step: 6
Training loss: 2.1483278274536133
Validation loss: 2.1448297398064726

Epoch: 5| Step: 7
Training loss: 1.4681880474090576
Validation loss: 2.1949850102906585

Epoch: 5| Step: 8
Training loss: 2.503763198852539
Validation loss: 2.1875492859912176

Epoch: 5| Step: 9
Training loss: 2.036043167114258
Validation loss: 2.206517155452441

Epoch: 5| Step: 10
Training loss: 2.9006810188293457
Validation loss: 2.149677840612268

Epoch: 208| Step: 0
Training loss: 1.8285331726074219
Validation loss: 2.204401945555082

Epoch: 5| Step: 1
Training loss: 1.9006786346435547
Validation loss: 2.1907404353541713

Epoch: 5| Step: 2
Training loss: 1.9471027851104736
Validation loss: 2.1853412735846733

Epoch: 5| Step: 3
Training loss: 2.858046770095825
Validation loss: 2.1423015235572733

Epoch: 5| Step: 4
Training loss: 1.8694976568222046
Validation loss: 2.182658282659387

Epoch: 5| Step: 5
Training loss: 2.801058769226074
Validation loss: 2.130464820451634

Epoch: 5| Step: 6
Training loss: 2.0983145236968994
Validation loss: 2.183190514964442

Epoch: 5| Step: 7
Training loss: 1.8753916025161743
Validation loss: 2.1807449709984565

Epoch: 5| Step: 8
Training loss: 1.8680156469345093
Validation loss: 2.202795413232619

Epoch: 5| Step: 9
Training loss: 2.042187213897705
Validation loss: 2.200615179154181

Epoch: 5| Step: 10
Training loss: 2.4477741718292236
Validation loss: 2.180192155222739

Epoch: 209| Step: 0
Training loss: 2.173941135406494
Validation loss: 2.1629008093187885

Epoch: 5| Step: 1
Training loss: 2.200997829437256
Validation loss: 2.137431985588484

Epoch: 5| Step: 2
Training loss: 2.0817203521728516
Validation loss: 2.1987557590648694

Epoch: 5| Step: 3
Training loss: 1.7225658893585205
Validation loss: 2.1624094901546353

Epoch: 5| Step: 4
Training loss: 2.2763400077819824
Validation loss: 2.166535246756769

Epoch: 5| Step: 5
Training loss: 2.466370105743408
Validation loss: 2.1469616646407754

Epoch: 5| Step: 6
Training loss: 2.520206928253174
Validation loss: 2.1657302405244563

Epoch: 5| Step: 7
Training loss: 2.0041086673736572
Validation loss: 2.141445493185392

Epoch: 5| Step: 8
Training loss: 1.860543966293335
Validation loss: 2.15156481599295

Epoch: 5| Step: 9
Training loss: 2.011308431625366
Validation loss: 2.208568693489157

Epoch: 5| Step: 10
Training loss: 2.0721089839935303
Validation loss: 2.133073354280123

Epoch: 210| Step: 0
Training loss: 2.351858615875244
Validation loss: 2.1707649846230783

Epoch: 5| Step: 1
Training loss: 1.9442647695541382
Validation loss: 2.190131201538988

Epoch: 5| Step: 2
Training loss: 2.7952334880828857
Validation loss: 2.189852904247981

Epoch: 5| Step: 3
Training loss: 1.8161271810531616
Validation loss: 2.168294434906334

Epoch: 5| Step: 4
Training loss: 1.935450792312622
Validation loss: 2.213956276575724

Epoch: 5| Step: 5
Training loss: 1.9333031177520752
Validation loss: 2.1859382147430093

Epoch: 5| Step: 6
Training loss: 2.2132761478424072
Validation loss: 2.1898504277711273

Epoch: 5| Step: 7
Training loss: 2.363421678543091
Validation loss: 2.1799950138215096

Epoch: 5| Step: 8
Training loss: 2.1941823959350586
Validation loss: 2.171212154050027

Epoch: 5| Step: 9
Training loss: 2.0456435680389404
Validation loss: 2.193639768067227

Epoch: 5| Step: 10
Training loss: 1.6787598133087158
Validation loss: 2.209636060140466

Epoch: 211| Step: 0
Training loss: 2.579636335372925
Validation loss: 2.156997852427985

Epoch: 5| Step: 1
Training loss: 1.5463802814483643
Validation loss: 2.1841713843807096

Epoch: 5| Step: 2
Training loss: 2.5492444038391113
Validation loss: 2.1726676905027

Epoch: 5| Step: 3
Training loss: 2.33652925491333
Validation loss: 2.215436133005286

Epoch: 5| Step: 4
Training loss: 2.3566787242889404
Validation loss: 2.191429397111298

Epoch: 5| Step: 5
Training loss: 2.0079009532928467
Validation loss: 2.163973390415151

Epoch: 5| Step: 6
Training loss: 2.0157880783081055
Validation loss: 2.203156417415988

Epoch: 5| Step: 7
Training loss: 2.3332815170288086
Validation loss: 2.1818321340827533

Epoch: 5| Step: 8
Training loss: 1.9294793605804443
Validation loss: 2.1752078481899795

Epoch: 5| Step: 9
Training loss: 2.525052309036255
Validation loss: 2.1612938463046985

Epoch: 5| Step: 10
Training loss: 1.1999729871749878
Validation loss: 2.189264787140713

Epoch: 212| Step: 0
Training loss: 2.528507947921753
Validation loss: 2.171169650170111

Epoch: 5| Step: 1
Training loss: 2.0720245838165283
Validation loss: 2.1753062176448044

Epoch: 5| Step: 2
Training loss: 2.271571397781372
Validation loss: 2.1872356758322766

Epoch: 5| Step: 3
Training loss: 1.4997398853302002
Validation loss: 2.215091372048983

Epoch: 5| Step: 4
Training loss: 1.6601463556289673
Validation loss: 2.1748202654623214

Epoch: 5| Step: 5
Training loss: 2.092209577560425
Validation loss: 2.2020506474279586

Epoch: 5| Step: 6
Training loss: 2.8793394565582275
Validation loss: 2.152669842525195

Epoch: 5| Step: 7
Training loss: 2.1007351875305176
Validation loss: 2.185207300288703

Epoch: 5| Step: 8
Training loss: 1.9162015914916992
Validation loss: 2.2374891055527555

Epoch: 5| Step: 9
Training loss: 2.147122621536255
Validation loss: 2.1758603793318554

Epoch: 5| Step: 10
Training loss: 1.9628758430480957
Validation loss: 2.1604775972263788

Epoch: 213| Step: 0
Training loss: 1.9957363605499268
Validation loss: 2.1686017833730227

Epoch: 5| Step: 1
Training loss: 2.059321165084839
Validation loss: 2.176525339003532

Epoch: 5| Step: 2
Training loss: 3.2583632469177246
Validation loss: 2.1869669293844574

Epoch: 5| Step: 3
Training loss: 1.8947010040283203
Validation loss: 2.175887441122404

Epoch: 5| Step: 4
Training loss: 2.0556836128234863
Validation loss: 2.184980628310993

Epoch: 5| Step: 5
Training loss: 1.7842872142791748
Validation loss: 2.218429519284156

Epoch: 5| Step: 6
Training loss: 2.014090061187744
Validation loss: 2.1561733471449984

Epoch: 5| Step: 7
Training loss: 2.217231273651123
Validation loss: 2.1669093690892702

Epoch: 5| Step: 8
Training loss: 2.083836078643799
Validation loss: 2.1850903085483018

Epoch: 5| Step: 9
Training loss: 2.186561107635498
Validation loss: 2.1747553527996106

Epoch: 5| Step: 10
Training loss: 2.1643600463867188
Validation loss: 2.130430098502867

Epoch: 214| Step: 0
Training loss: 2.5470986366271973
Validation loss: 2.2217938669266237

Epoch: 5| Step: 1
Training loss: 1.9759681224822998
Validation loss: 2.237769147401215

Epoch: 5| Step: 2
Training loss: 3.0761215686798096
Validation loss: 2.226622489190871

Epoch: 5| Step: 3
Training loss: 1.9040340185165405
Validation loss: 2.204365445721534

Epoch: 5| Step: 4
Training loss: 2.0336952209472656
Validation loss: 2.172865390777588

Epoch: 5| Step: 5
Training loss: 1.8283717632293701
Validation loss: 2.1341582395697154

Epoch: 5| Step: 6
Training loss: 2.2232515811920166
Validation loss: 2.2380233862066783

Epoch: 5| Step: 7
Training loss: 2.15802001953125
Validation loss: 2.2007011751974783

Epoch: 5| Step: 8
Training loss: 2.089329242706299
Validation loss: 2.161029492655108

Epoch: 5| Step: 9
Training loss: 1.8398231267929077
Validation loss: 2.2250068264622844

Epoch: 5| Step: 10
Training loss: 1.8147730827331543
Validation loss: 2.236450925950081

Epoch: 215| Step: 0
Training loss: 2.3257858753204346
Validation loss: 2.182044800891671

Epoch: 5| Step: 1
Training loss: 2.5021605491638184
Validation loss: 2.167619715454758

Epoch: 5| Step: 2
Training loss: 1.6337703466415405
Validation loss: 2.1714940994016585

Epoch: 5| Step: 3
Training loss: 2.075688362121582
Validation loss: 2.1816959740013204

Epoch: 5| Step: 4
Training loss: 1.6829841136932373
Validation loss: 2.2034005823955742

Epoch: 5| Step: 5
Training loss: 2.0418078899383545
Validation loss: 2.1758481276932584

Epoch: 5| Step: 6
Training loss: 2.0560920238494873
Validation loss: 2.194785657749381

Epoch: 5| Step: 7
Training loss: 2.3688242435455322
Validation loss: 2.183893644681541

Epoch: 5| Step: 8
Training loss: 2.328272819519043
Validation loss: 2.162939925347605

Epoch: 5| Step: 9
Training loss: 1.8433678150177002
Validation loss: 2.177394337551568

Epoch: 5| Step: 10
Training loss: 2.539585828781128
Validation loss: 2.1542273426568634

Epoch: 216| Step: 0
Training loss: 2.454965591430664
Validation loss: 2.161716022799092

Epoch: 5| Step: 1
Training loss: 2.4525883197784424
Validation loss: 2.113393969433282

Epoch: 5| Step: 2
Training loss: 1.972005844116211
Validation loss: 2.1850912237680085

Epoch: 5| Step: 3
Training loss: 1.7354106903076172
Validation loss: 2.1606414189902683

Epoch: 5| Step: 4
Training loss: 1.828579306602478
Validation loss: 2.186376246072913

Epoch: 5| Step: 5
Training loss: 2.8725857734680176
Validation loss: 2.1626827281008483

Epoch: 5| Step: 6
Training loss: 1.4181355237960815
Validation loss: 2.1476952157994753

Epoch: 5| Step: 7
Training loss: 2.4597089290618896
Validation loss: 2.1734782213805826

Epoch: 5| Step: 8
Training loss: 1.9685239791870117
Validation loss: 2.177977054349838

Epoch: 5| Step: 9
Training loss: 1.845890998840332
Validation loss: 2.1380628885761386

Epoch: 5| Step: 10
Training loss: 1.9995981454849243
Validation loss: 2.1637061308788996

Epoch: 217| Step: 0
Training loss: 1.8383662700653076
Validation loss: 2.1893385328272337

Epoch: 5| Step: 1
Training loss: 2.715510845184326
Validation loss: 2.200031218990203

Epoch: 5| Step: 2
Training loss: 2.287876605987549
Validation loss: 2.1707478518127115

Epoch: 5| Step: 3
Training loss: 2.3362114429473877
Validation loss: 2.182827975160332

Epoch: 5| Step: 4
Training loss: 1.6728496551513672
Validation loss: 2.163126508394877

Epoch: 5| Step: 5
Training loss: 2.185927152633667
Validation loss: 2.1729639037962882

Epoch: 5| Step: 6
Training loss: 1.8169666528701782
Validation loss: 2.1822505881709438

Epoch: 5| Step: 7
Training loss: 2.4799983501434326
Validation loss: 2.155238602751045

Epoch: 5| Step: 8
Training loss: 1.8015435934066772
Validation loss: 2.1585660596047678

Epoch: 5| Step: 9
Training loss: 2.211047649383545
Validation loss: 2.2006922614189888

Epoch: 5| Step: 10
Training loss: 1.7502557039260864
Validation loss: 2.163844249581778

Epoch: 218| Step: 0
Training loss: 1.6724424362182617
Validation loss: 2.1723026639671734

Epoch: 5| Step: 1
Training loss: 2.6445260047912598
Validation loss: 2.1689539160779727

Epoch: 5| Step: 2
Training loss: 2.519754409790039
Validation loss: 2.163785083319551

Epoch: 5| Step: 3
Training loss: 2.2134695053100586
Validation loss: 2.1777135992562897

Epoch: 5| Step: 4
Training loss: 2.3707549571990967
Validation loss: 2.1672969736078733

Epoch: 5| Step: 5
Training loss: 2.046546459197998
Validation loss: 2.178630833984703

Epoch: 5| Step: 6
Training loss: 1.792140245437622
Validation loss: 2.181863946299399

Epoch: 5| Step: 7
Training loss: 2.1415414810180664
Validation loss: 2.1838785653473227

Epoch: 5| Step: 8
Training loss: 1.6307728290557861
Validation loss: 2.184008426563714

Epoch: 5| Step: 9
Training loss: 2.2394092082977295
Validation loss: 2.1861525735547467

Epoch: 5| Step: 10
Training loss: 1.8443390130996704
Validation loss: 2.182382111908287

Epoch: 219| Step: 0
Training loss: 2.3198084831237793
Validation loss: 2.161197623898906

Epoch: 5| Step: 1
Training loss: 1.9260444641113281
Validation loss: 2.2061812390563307

Epoch: 5| Step: 2
Training loss: 2.0016627311706543
Validation loss: 2.1363291868599514

Epoch: 5| Step: 3
Training loss: 2.015450954437256
Validation loss: 2.202318250492055

Epoch: 5| Step: 4
Training loss: 2.563951253890991
Validation loss: 2.172301175773785

Epoch: 5| Step: 5
Training loss: 2.1793251037597656
Validation loss: 2.147936882511262

Epoch: 5| Step: 6
Training loss: 2.443077564239502
Validation loss: 2.214904208337107

Epoch: 5| Step: 7
Training loss: 2.1297030448913574
Validation loss: 2.1668330469439105

Epoch: 5| Step: 8
Training loss: 2.1684250831604004
Validation loss: 2.179273800183368

Epoch: 5| Step: 9
Training loss: 2.058718204498291
Validation loss: 2.1966444074466662

Epoch: 5| Step: 10
Training loss: 1.7062405347824097
Validation loss: 2.1801161625052012

Epoch: 220| Step: 0
Training loss: 1.940211534500122
Validation loss: 2.1574041843414307

Epoch: 5| Step: 1
Training loss: 1.874057412147522
Validation loss: 2.2189869214129705

Epoch: 5| Step: 2
Training loss: 2.019258499145508
Validation loss: 2.1720563570658364

Epoch: 5| Step: 3
Training loss: 2.4554784297943115
Validation loss: 2.1780869217329126

Epoch: 5| Step: 4
Training loss: 2.702777147293091
Validation loss: 2.1466746202079197

Epoch: 5| Step: 5
Training loss: 2.167973279953003
Validation loss: 2.1611474226879817

Epoch: 5| Step: 6
Training loss: 1.9243123531341553
Validation loss: 2.163348017200347

Epoch: 5| Step: 7
Training loss: 1.749326467514038
Validation loss: 2.1638378584256737

Epoch: 5| Step: 8
Training loss: 1.8288421630859375
Validation loss: 2.1369573864885556

Epoch: 5| Step: 9
Training loss: 2.3003602027893066
Validation loss: 2.1743931206323768

Epoch: 5| Step: 10
Training loss: 2.3010077476501465
Validation loss: 2.1483359490671465

Epoch: 221| Step: 0
Training loss: 1.8855355978012085
Validation loss: 2.1970412295351744

Epoch: 5| Step: 1
Training loss: 2.2781383991241455
Validation loss: 2.170832985190935

Epoch: 5| Step: 2
Training loss: 1.8162142038345337
Validation loss: 2.2100088211797897

Epoch: 5| Step: 3
Training loss: 2.0940170288085938
Validation loss: 2.224210585317304

Epoch: 5| Step: 4
Training loss: 2.6777570247650146
Validation loss: 2.2151498076736287

Epoch: 5| Step: 5
Training loss: 1.9379079341888428
Validation loss: 2.2162321434226087

Epoch: 5| Step: 6
Training loss: 2.256587028503418
Validation loss: 2.2208569767654582

Epoch: 5| Step: 7
Training loss: 2.5492160320281982
Validation loss: 2.1665960614399244

Epoch: 5| Step: 8
Training loss: 1.963579535484314
Validation loss: 2.1496040974893877

Epoch: 5| Step: 9
Training loss: 2.3263778686523438
Validation loss: 2.192634447928398

Epoch: 5| Step: 10
Training loss: 1.7423436641693115
Validation loss: 2.207693887013261

Epoch: 222| Step: 0
Training loss: 2.118452548980713
Validation loss: 2.218933715615221

Epoch: 5| Step: 1
Training loss: 2.5870792865753174
Validation loss: 2.1894217498840822

Epoch: 5| Step: 2
Training loss: 2.349886417388916
Validation loss: 2.196330060241043

Epoch: 5| Step: 3
Training loss: 1.7432390451431274
Validation loss: 2.1649906840375674

Epoch: 5| Step: 4
Training loss: 1.5548287630081177
Validation loss: 2.186690999615577

Epoch: 5| Step: 5
Training loss: 2.076292037963867
Validation loss: 2.209655028517528

Epoch: 5| Step: 6
Training loss: 2.743579626083374
Validation loss: 2.156976392192225

Epoch: 5| Step: 7
Training loss: 2.1637167930603027
Validation loss: 2.138668119266469

Epoch: 5| Step: 8
Training loss: 1.9056440591812134
Validation loss: 2.144156344475285

Epoch: 5| Step: 9
Training loss: 1.876692533493042
Validation loss: 2.207153913795307

Epoch: 5| Step: 10
Training loss: 2.0746567249298096
Validation loss: 2.15893478034645

Epoch: 223| Step: 0
Training loss: 1.8049300909042358
Validation loss: 2.185320664477605

Epoch: 5| Step: 1
Training loss: 2.640519618988037
Validation loss: 2.1396151101717384

Epoch: 5| Step: 2
Training loss: 2.075472354888916
Validation loss: 2.139968728506437

Epoch: 5| Step: 3
Training loss: 1.5515004396438599
Validation loss: 2.1757065250027563

Epoch: 5| Step: 4
Training loss: 2.761314630508423
Validation loss: 2.1665599769161594

Epoch: 5| Step: 5
Training loss: 1.9312629699707031
Validation loss: 2.223369554806781

Epoch: 5| Step: 6
Training loss: 1.527720332145691
Validation loss: 2.144565733530188

Epoch: 5| Step: 7
Training loss: 2.835214614868164
Validation loss: 2.1244042201708724

Epoch: 5| Step: 8
Training loss: 2.7485852241516113
Validation loss: 2.1537696148759577

Epoch: 5| Step: 9
Training loss: 1.1715837717056274
Validation loss: 2.182332282425255

Epoch: 5| Step: 10
Training loss: 2.218350648880005
Validation loss: 2.159768822372601

Epoch: 224| Step: 0
Training loss: 2.1622331142425537
Validation loss: 2.185682350589383

Epoch: 5| Step: 1
Training loss: 2.1549434661865234
Validation loss: 2.1612140311989734

Epoch: 5| Step: 2
Training loss: 2.31585431098938
Validation loss: 2.175781096181562

Epoch: 5| Step: 3
Training loss: 2.484279155731201
Validation loss: 2.171672764644828

Epoch: 5| Step: 4
Training loss: 1.8861663341522217
Validation loss: 2.173865492625903

Epoch: 5| Step: 5
Training loss: 1.9597660303115845
Validation loss: 2.193028726885396

Epoch: 5| Step: 6
Training loss: 2.370917797088623
Validation loss: 2.22727688922677

Epoch: 5| Step: 7
Training loss: 1.9916102886199951
Validation loss: 2.1701585785035165

Epoch: 5| Step: 8
Training loss: 2.2117695808410645
Validation loss: 2.1543876227512153

Epoch: 5| Step: 9
Training loss: 1.7286323308944702
Validation loss: 2.201987612632013

Epoch: 5| Step: 10
Training loss: 2.0283849239349365
Validation loss: 2.2041463018745504

Epoch: 225| Step: 0
Training loss: 2.8350577354431152
Validation loss: 2.1615943908691406

Epoch: 5| Step: 1
Training loss: 2.332453727722168
Validation loss: 2.171709996397777

Epoch: 5| Step: 2
Training loss: 1.795488953590393
Validation loss: 2.1565151470963673

Epoch: 5| Step: 3
Training loss: 2.334150791168213
Validation loss: 2.1653576666308987

Epoch: 5| Step: 4
Training loss: 2.0654232501983643
Validation loss: 2.1769995202300367

Epoch: 5| Step: 5
Training loss: 2.0434467792510986
Validation loss: 2.169564045885558

Epoch: 5| Step: 6
Training loss: 1.811581015586853
Validation loss: 2.1652255135197795

Epoch: 5| Step: 7
Training loss: 2.198746919631958
Validation loss: 2.152193409140392

Epoch: 5| Step: 8
Training loss: 1.9616258144378662
Validation loss: 2.1538228117009646

Epoch: 5| Step: 9
Training loss: 1.871548056602478
Validation loss: 2.1627514567426456

Epoch: 5| Step: 10
Training loss: 1.986363172531128
Validation loss: 2.145185750017884

Epoch: 226| Step: 0
Training loss: 1.8864014148712158
Validation loss: 2.1793107960813787

Epoch: 5| Step: 1
Training loss: 2.023127555847168
Validation loss: 2.202334734701341

Epoch: 5| Step: 2
Training loss: 2.4690475463867188
Validation loss: 2.1633480248912687

Epoch: 5| Step: 3
Training loss: 1.5130211114883423
Validation loss: 2.227496749611311

Epoch: 5| Step: 4
Training loss: 3.308366060256958
Validation loss: 2.1193446408035936

Epoch: 5| Step: 5
Training loss: 2.0441348552703857
Validation loss: 2.1245096960375385

Epoch: 5| Step: 6
Training loss: 1.757541298866272
Validation loss: 2.192651997330368

Epoch: 5| Step: 7
Training loss: 1.506687045097351
Validation loss: 2.1895439342785905

Epoch: 5| Step: 8
Training loss: 1.6817476749420166
Validation loss: 2.166269240840789

Epoch: 5| Step: 9
Training loss: 2.806215286254883
Validation loss: 2.1464817113773798

Epoch: 5| Step: 10
Training loss: 1.8898231983184814
Validation loss: 2.1571619741378294

Epoch: 227| Step: 0
Training loss: 2.4509360790252686
Validation loss: 2.1951740287965342

Epoch: 5| Step: 1
Training loss: 1.3159799575805664
Validation loss: 2.1500181844157558

Epoch: 5| Step: 2
Training loss: 1.8044483661651611
Validation loss: 2.1594435937942995

Epoch: 5| Step: 3
Training loss: 2.3745992183685303
Validation loss: 2.184432319415513

Epoch: 5| Step: 4
Training loss: 2.8233726024627686
Validation loss: 2.121630089257353

Epoch: 5| Step: 5
Training loss: 2.263646364212036
Validation loss: 2.15575433546497

Epoch: 5| Step: 6
Training loss: 2.207613706588745
Validation loss: 2.167424242983582

Epoch: 5| Step: 7
Training loss: 1.5399075746536255
Validation loss: 2.1531535912585515

Epoch: 5| Step: 8
Training loss: 2.04791522026062
Validation loss: 2.1596500027564263

Epoch: 5| Step: 9
Training loss: 2.089054584503174
Validation loss: 2.143984212670275

Epoch: 5| Step: 10
Training loss: 2.2136428356170654
Validation loss: 2.174598686156734

Epoch: 228| Step: 0
Training loss: 2.6211438179016113
Validation loss: 2.125796095017464

Epoch: 5| Step: 1
Training loss: 1.972678542137146
Validation loss: 2.152658571479141

Epoch: 5| Step: 2
Training loss: 2.6546740531921387
Validation loss: 2.169968076931533

Epoch: 5| Step: 3
Training loss: 2.15915846824646
Validation loss: 2.2083801992477907

Epoch: 5| Step: 4
Training loss: 1.8248180150985718
Validation loss: 2.1577470815309914

Epoch: 5| Step: 5
Training loss: 1.5957770347595215
Validation loss: 2.1954816054272395

Epoch: 5| Step: 6
Training loss: 2.144284248352051
Validation loss: 2.1745981144648727

Epoch: 5| Step: 7
Training loss: 1.7964633703231812
Validation loss: 2.202064114232217

Epoch: 5| Step: 8
Training loss: 1.5831875801086426
Validation loss: 2.187810303062521

Epoch: 5| Step: 9
Training loss: 2.310769557952881
Validation loss: 2.1684545573367866

Epoch: 5| Step: 10
Training loss: 2.5757904052734375
Validation loss: 2.1777765879067044

Epoch: 229| Step: 0
Training loss: 1.903974175453186
Validation loss: 2.149562762629601

Epoch: 5| Step: 1
Training loss: 1.6826345920562744
Validation loss: 2.2101035553921937

Epoch: 5| Step: 2
Training loss: 2.638546943664551
Validation loss: 2.16525448009532

Epoch: 5| Step: 3
Training loss: 1.8190736770629883
Validation loss: 2.1569807375631025

Epoch: 5| Step: 4
Training loss: 2.940124034881592
Validation loss: 2.172442936128186

Epoch: 5| Step: 5
Training loss: 1.6983444690704346
Validation loss: 2.165654302925192

Epoch: 5| Step: 6
Training loss: 2.5283236503601074
Validation loss: 2.16617872125359

Epoch: 5| Step: 7
Training loss: 2.3338823318481445
Validation loss: 2.1764742533365884

Epoch: 5| Step: 8
Training loss: 1.925378441810608
Validation loss: 2.1889600907602618

Epoch: 5| Step: 9
Training loss: 1.7296726703643799
Validation loss: 2.2038907735578475

Epoch: 5| Step: 10
Training loss: 2.129957675933838
Validation loss: 2.176922380283315

Epoch: 230| Step: 0
Training loss: 2.1618881225585938
Validation loss: 2.2157375325438795

Epoch: 5| Step: 1
Training loss: 2.3156490325927734
Validation loss: 2.154236016734954

Epoch: 5| Step: 2
Training loss: 2.653162956237793
Validation loss: 2.188203138689841

Epoch: 5| Step: 3
Training loss: 1.8038963079452515
Validation loss: 2.196807448581983

Epoch: 5| Step: 4
Training loss: 2.2437031269073486
Validation loss: 2.1646252421922583

Epoch: 5| Step: 5
Training loss: 1.5239002704620361
Validation loss: 2.1676968323287142

Epoch: 5| Step: 6
Training loss: 1.9277927875518799
Validation loss: 2.2021215884916243

Epoch: 5| Step: 7
Training loss: 1.8167827129364014
Validation loss: 2.2137441724859257

Epoch: 5| Step: 8
Training loss: 2.570509672164917
Validation loss: 2.1472397158222813

Epoch: 5| Step: 9
Training loss: 2.1432137489318848
Validation loss: 2.1878234878663094

Epoch: 5| Step: 10
Training loss: 2.3896679878234863
Validation loss: 2.218430165321596

Epoch: 231| Step: 0
Training loss: 1.8999649286270142
Validation loss: 2.207871121744956

Epoch: 5| Step: 1
Training loss: 2.4239697456359863
Validation loss: 2.1866751229891213

Epoch: 5| Step: 2
Training loss: 1.7498369216918945
Validation loss: 2.144794779439126

Epoch: 5| Step: 3
Training loss: 1.4975236654281616
Validation loss: 2.151394590254753

Epoch: 5| Step: 4
Training loss: 1.67118239402771
Validation loss: 2.184925701028557

Epoch: 5| Step: 5
Training loss: 1.957157850265503
Validation loss: 2.212237245293074

Epoch: 5| Step: 6
Training loss: 2.6553566455841064
Validation loss: 2.137185183904504

Epoch: 5| Step: 7
Training loss: 2.436126708984375
Validation loss: 2.191380741775677

Epoch: 5| Step: 8
Training loss: 2.705775737762451
Validation loss: 2.160910193638135

Epoch: 5| Step: 9
Training loss: 2.3295950889587402
Validation loss: 2.19840544526295

Epoch: 5| Step: 10
Training loss: 1.6722592115402222
Validation loss: 2.1803060552125335

Epoch: 232| Step: 0
Training loss: 1.4750394821166992
Validation loss: 2.2118055243645944

Epoch: 5| Step: 1
Training loss: 1.9454498291015625
Validation loss: 2.192079900413431

Epoch: 5| Step: 2
Training loss: 2.1555168628692627
Validation loss: 2.198332814760106

Epoch: 5| Step: 3
Training loss: 2.360590696334839
Validation loss: 2.217350957214191

Epoch: 5| Step: 4
Training loss: 2.2169063091278076
Validation loss: 2.1985024034336047

Epoch: 5| Step: 5
Training loss: 2.419246196746826
Validation loss: 2.196985729279057

Epoch: 5| Step: 6
Training loss: 2.3941054344177246
Validation loss: 2.1277846751674527

Epoch: 5| Step: 7
Training loss: 1.9113308191299438
Validation loss: 2.16948091342885

Epoch: 5| Step: 8
Training loss: 2.63331937789917
Validation loss: 2.205274051235568

Epoch: 5| Step: 9
Training loss: 1.9565808773040771
Validation loss: 2.1710495512972594

Epoch: 5| Step: 10
Training loss: 1.919970989227295
Validation loss: 2.1701172090345815

Epoch: 233| Step: 0
Training loss: 1.8899867534637451
Validation loss: 2.1446910519753732

Epoch: 5| Step: 1
Training loss: 1.6120697259902954
Validation loss: 2.1700855660182174

Epoch: 5| Step: 2
Training loss: 2.0931477546691895
Validation loss: 2.1291674003806165

Epoch: 5| Step: 3
Training loss: 2.725719451904297
Validation loss: 2.1664812334122194

Epoch: 5| Step: 4
Training loss: 1.366973638534546
Validation loss: 2.1615035072449715

Epoch: 5| Step: 5
Training loss: 2.6620922088623047
Validation loss: 2.1694965516367266

Epoch: 5| Step: 6
Training loss: 2.0691237449645996
Validation loss: 2.1255960643932386

Epoch: 5| Step: 7
Training loss: 1.8405380249023438
Validation loss: 2.1397022149896108

Epoch: 5| Step: 8
Training loss: 1.8348032236099243
Validation loss: 2.160749504643102

Epoch: 5| Step: 9
Training loss: 2.590961456298828
Validation loss: 2.1509891504882486

Epoch: 5| Step: 10
Training loss: 2.206113815307617
Validation loss: 2.159688836784773

Epoch: 234| Step: 0
Training loss: 1.9591686725616455
Validation loss: 2.1980563453448716

Epoch: 5| Step: 1
Training loss: 2.3094606399536133
Validation loss: 2.114633598635274

Epoch: 5| Step: 2
Training loss: 2.2957262992858887
Validation loss: 2.1771704663512526

Epoch: 5| Step: 3
Training loss: 2.0179736614227295
Validation loss: 2.1549886439436223

Epoch: 5| Step: 4
Training loss: 1.8644838333129883
Validation loss: 2.162844293860979

Epoch: 5| Step: 5
Training loss: 2.2525577545166016
Validation loss: 2.224592880536151

Epoch: 5| Step: 6
Training loss: 1.759204626083374
Validation loss: 2.153547324160094

Epoch: 5| Step: 7
Training loss: 1.3357903957366943
Validation loss: 2.1566834244676816

Epoch: 5| Step: 8
Training loss: 2.5700385570526123
Validation loss: 2.203207077518586

Epoch: 5| Step: 9
Training loss: 2.3431496620178223
Validation loss: 2.202025580149825

Epoch: 5| Step: 10
Training loss: 2.1233878135681152
Validation loss: 2.2327394562382854

Epoch: 235| Step: 0
Training loss: 1.9919697046279907
Validation loss: 2.1881892437575967

Epoch: 5| Step: 1
Training loss: 2.2170157432556152
Validation loss: 2.2092996874163227

Epoch: 5| Step: 2
Training loss: 2.1516852378845215
Validation loss: 2.1404701702056395

Epoch: 5| Step: 3
Training loss: 1.6972942352294922
Validation loss: 2.22718467250947

Epoch: 5| Step: 4
Training loss: 2.367814302444458
Validation loss: 2.280293080114549

Epoch: 5| Step: 5
Training loss: 1.8235307931900024
Validation loss: 2.2639635583405853

Epoch: 5| Step: 6
Training loss: 2.2537922859191895
Validation loss: 2.1967198810269757

Epoch: 5| Step: 7
Training loss: 1.8335050344467163
Validation loss: 2.186043039444954

Epoch: 5| Step: 8
Training loss: 1.6055246591567993
Validation loss: 2.1876707435936056

Epoch: 5| Step: 9
Training loss: 2.748298406600952
Validation loss: 2.202125508298156

Epoch: 5| Step: 10
Training loss: 2.242748260498047
Validation loss: 2.2073073297418575

Epoch: 236| Step: 0
Training loss: 2.133821487426758
Validation loss: 2.219087391771296

Epoch: 5| Step: 1
Training loss: 1.9980623722076416
Validation loss: 2.2064569047702256

Epoch: 5| Step: 2
Training loss: 2.212230682373047
Validation loss: 2.2220604881163566

Epoch: 5| Step: 3
Training loss: 1.9628384113311768
Validation loss: 2.154271856431038

Epoch: 5| Step: 4
Training loss: 1.593218207359314
Validation loss: 2.1553891730564896

Epoch: 5| Step: 5
Training loss: 2.5535635948181152
Validation loss: 2.183465389795201

Epoch: 5| Step: 6
Training loss: 2.3988187313079834
Validation loss: 2.161872581769061

Epoch: 5| Step: 7
Training loss: 2.060788631439209
Validation loss: 2.1665105922247774

Epoch: 5| Step: 8
Training loss: 2.408200740814209
Validation loss: 2.183076822629539

Epoch: 5| Step: 9
Training loss: 1.5684916973114014
Validation loss: 2.1633646001097975

Epoch: 5| Step: 10
Training loss: 2.3326916694641113
Validation loss: 2.1662815437521985

Epoch: 237| Step: 0
Training loss: 1.8686182498931885
Validation loss: 2.1765495871984832

Epoch: 5| Step: 1
Training loss: 2.2698256969451904
Validation loss: 2.107640484327911

Epoch: 5| Step: 2
Training loss: 2.1791164875030518
Validation loss: 2.1465981365532003

Epoch: 5| Step: 3
Training loss: 2.2903482913970947
Validation loss: 2.139583267191405

Epoch: 5| Step: 4
Training loss: 1.7351725101470947
Validation loss: 2.1593762597730084

Epoch: 5| Step: 5
Training loss: 2.1207938194274902
Validation loss: 2.148658267913326

Epoch: 5| Step: 6
Training loss: 2.0352416038513184
Validation loss: 2.162702238687905

Epoch: 5| Step: 7
Training loss: 1.9913079738616943
Validation loss: 2.1869385191189346

Epoch: 5| Step: 8
Training loss: 2.3208510875701904
Validation loss: 2.212457174895912

Epoch: 5| Step: 9
Training loss: 2.2569966316223145
Validation loss: 2.1513664196896296

Epoch: 5| Step: 10
Training loss: 2.315755844116211
Validation loss: 2.2071463728463776

Epoch: 238| Step: 0
Training loss: 2.321498155593872
Validation loss: 2.126932035210312

Epoch: 5| Step: 1
Training loss: 1.7275457382202148
Validation loss: 2.1686505425360894

Epoch: 5| Step: 2
Training loss: 2.1654105186462402
Validation loss: 2.1283865167248632

Epoch: 5| Step: 3
Training loss: 1.5069156885147095
Validation loss: 2.1215489064493487

Epoch: 5| Step: 4
Training loss: 2.2751362323760986
Validation loss: 2.143306964187212

Epoch: 5| Step: 5
Training loss: 1.9850075244903564
Validation loss: 2.133993684604604

Epoch: 5| Step: 6
Training loss: 2.57857608795166
Validation loss: 2.170209833370742

Epoch: 5| Step: 7
Training loss: 2.421358346939087
Validation loss: 2.1442038333544167

Epoch: 5| Step: 8
Training loss: 2.17461895942688
Validation loss: 2.169300889456144

Epoch: 5| Step: 9
Training loss: 2.301912546157837
Validation loss: 2.1842421536804526

Epoch: 5| Step: 10
Training loss: 1.5087709426879883
Validation loss: 2.1281856465083298

Epoch: 239| Step: 0
Training loss: 2.8641910552978516
Validation loss: 2.1694709741941063

Epoch: 5| Step: 1
Training loss: 2.7129387855529785
Validation loss: 2.1776834559696976

Epoch: 5| Step: 2
Training loss: 2.6224405765533447
Validation loss: 2.148325494540635

Epoch: 5| Step: 3
Training loss: 2.074234962463379
Validation loss: 2.189314293605025

Epoch: 5| Step: 4
Training loss: 2.199934482574463
Validation loss: 2.2083289213077997

Epoch: 5| Step: 5
Training loss: 1.7782760858535767
Validation loss: 2.164484611121557

Epoch: 5| Step: 6
Training loss: 1.9634904861450195
Validation loss: 2.2012996237765075

Epoch: 5| Step: 7
Training loss: 1.2930302619934082
Validation loss: 2.191661047679122

Epoch: 5| Step: 8
Training loss: 1.523323655128479
Validation loss: 2.108680038041966

Epoch: 5| Step: 9
Training loss: 2.2609782218933105
Validation loss: 2.183862352883944

Epoch: 5| Step: 10
Training loss: 1.7767807245254517
Validation loss: 2.210149636832617

Epoch: 240| Step: 0
Training loss: 1.6952791213989258
Validation loss: 2.1364448916527534

Epoch: 5| Step: 1
Training loss: 2.5576460361480713
Validation loss: 2.168884587544267

Epoch: 5| Step: 2
Training loss: 2.3158857822418213
Validation loss: 2.1365938135372695

Epoch: 5| Step: 3
Training loss: 1.6813457012176514
Validation loss: 2.1445177985775854

Epoch: 5| Step: 4
Training loss: 2.1984968185424805
Validation loss: 2.1758894048711306

Epoch: 5| Step: 5
Training loss: 1.6925491094589233
Validation loss: 2.1794718337315384

Epoch: 5| Step: 6
Training loss: 1.8397443294525146
Validation loss: 2.141721981827931

Epoch: 5| Step: 7
Training loss: 2.154531955718994
Validation loss: 2.163968857898507

Epoch: 5| Step: 8
Training loss: 2.0973243713378906
Validation loss: 2.1740278326055056

Epoch: 5| Step: 9
Training loss: 3.1223511695861816
Validation loss: 2.130318654480801

Epoch: 5| Step: 10
Training loss: 1.9078450202941895
Validation loss: 2.1667369065746183

Epoch: 241| Step: 0
Training loss: 2.553922653198242
Validation loss: 2.1604256053124704

Epoch: 5| Step: 1
Training loss: 2.166203260421753
Validation loss: 2.1734782623988327

Epoch: 5| Step: 2
Training loss: 1.7906471490859985
Validation loss: 2.167715031613586

Epoch: 5| Step: 3
Training loss: 1.6360832452774048
Validation loss: 2.1366190884702947

Epoch: 5| Step: 4
Training loss: 2.671844959259033
Validation loss: 2.1869257342430855

Epoch: 5| Step: 5
Training loss: 2.635967969894409
Validation loss: 2.1237165825341338

Epoch: 5| Step: 6
Training loss: 1.6878598928451538
Validation loss: 2.16607952374284

Epoch: 5| Step: 7
Training loss: 1.9309755563735962
Validation loss: 2.2093065118276947

Epoch: 5| Step: 8
Training loss: 2.304852247238159
Validation loss: 2.1837554490694435

Epoch: 5| Step: 9
Training loss: 1.9162654876708984
Validation loss: 2.1427889203512542

Epoch: 5| Step: 10
Training loss: 1.8086516857147217
Validation loss: 2.1220812233545447

Epoch: 242| Step: 0
Training loss: 2.0271620750427246
Validation loss: 2.1840127206617788

Epoch: 5| Step: 1
Training loss: 1.99982488155365
Validation loss: 2.1424763177030828

Epoch: 5| Step: 2
Training loss: 3.0021395683288574
Validation loss: 2.142764634983514

Epoch: 5| Step: 3
Training loss: 1.3479214906692505
Validation loss: 2.1464700827034573

Epoch: 5| Step: 4
Training loss: 1.7919037342071533
Validation loss: 2.2048555163926977

Epoch: 5| Step: 5
Training loss: 1.6210845708847046
Validation loss: 2.1718086106802827

Epoch: 5| Step: 6
Training loss: 2.41107177734375
Validation loss: 2.1540612148982223

Epoch: 5| Step: 7
Training loss: 1.7848256826400757
Validation loss: 2.152257634747413

Epoch: 5| Step: 8
Training loss: 2.1159002780914307
Validation loss: 2.1593850799786147

Epoch: 5| Step: 9
Training loss: 1.8314653635025024
Validation loss: 2.193086237035772

Epoch: 5| Step: 10
Training loss: 2.973142623901367
Validation loss: 2.1707594497229463

Epoch: 243| Step: 0
Training loss: 2.0675711631774902
Validation loss: 2.1612017846876577

Epoch: 5| Step: 1
Training loss: 2.283656358718872
Validation loss: 2.1892269016594015

Epoch: 5| Step: 2
Training loss: 1.8137290477752686
Validation loss: 2.2021652319098033

Epoch: 5| Step: 3
Training loss: 2.1527371406555176
Validation loss: 2.174088006378502

Epoch: 5| Step: 4
Training loss: 1.4844858646392822
Validation loss: 2.1660703779548727

Epoch: 5| Step: 5
Training loss: 1.5180928707122803
Validation loss: 2.197828833774854

Epoch: 5| Step: 6
Training loss: 2.153761863708496
Validation loss: 2.1579438230042816

Epoch: 5| Step: 7
Training loss: 2.20731258392334
Validation loss: 2.187361850533434

Epoch: 5| Step: 8
Training loss: 2.191265106201172
Validation loss: 2.1632683148948093

Epoch: 5| Step: 9
Training loss: 2.955897092819214
Validation loss: 2.2429754093129146

Epoch: 5| Step: 10
Training loss: 1.788801670074463
Validation loss: 2.233776607821065

Epoch: 244| Step: 0
Training loss: 1.7840591669082642
Validation loss: 2.1823326490258657

Epoch: 5| Step: 1
Training loss: 1.876569151878357
Validation loss: 2.1859780075729534

Epoch: 5| Step: 2
Training loss: 3.1977405548095703
Validation loss: 2.180514904760545

Epoch: 5| Step: 3
Training loss: 2.1578452587127686
Validation loss: 2.205792707781638

Epoch: 5| Step: 4
Training loss: 1.792471170425415
Validation loss: 2.2043674069066204

Epoch: 5| Step: 5
Training loss: 2.183985948562622
Validation loss: 2.1778812972448205

Epoch: 5| Step: 6
Training loss: 2.118807315826416
Validation loss: 2.1279840007905038

Epoch: 5| Step: 7
Training loss: 2.382603645324707
Validation loss: 2.1676583802828224

Epoch: 5| Step: 8
Training loss: 1.6408830881118774
Validation loss: 2.1908407390758557

Epoch: 5| Step: 9
Training loss: 1.8683969974517822
Validation loss: 2.1174964263874996

Epoch: 5| Step: 10
Training loss: 1.7585728168487549
Validation loss: 2.172467085622972

Epoch: 245| Step: 0
Training loss: 2.240694284439087
Validation loss: 2.188960665015764

Epoch: 5| Step: 1
Training loss: 1.9142745733261108
Validation loss: 2.1855755018931564

Epoch: 5| Step: 2
Training loss: 2.3776817321777344
Validation loss: 2.153959584492509

Epoch: 5| Step: 3
Training loss: 2.063854694366455
Validation loss: 2.199923389701433

Epoch: 5| Step: 4
Training loss: 1.820299506187439
Validation loss: 2.1969993229835265

Epoch: 5| Step: 5
Training loss: 2.248765707015991
Validation loss: 2.143968471916773

Epoch: 5| Step: 6
Training loss: 2.0171151161193848
Validation loss: 2.1495066483815513

Epoch: 5| Step: 7
Training loss: 1.9951584339141846
Validation loss: 2.13305845568257

Epoch: 5| Step: 8
Training loss: 2.061948537826538
Validation loss: 2.1617847052953576

Epoch: 5| Step: 9
Training loss: 1.6389411687850952
Validation loss: 2.1239133163165023

Epoch: 5| Step: 10
Training loss: 3.0060970783233643
Validation loss: 2.184906041750344

Epoch: 246| Step: 0
Training loss: 1.6257274150848389
Validation loss: 2.1498162233701317

Epoch: 5| Step: 1
Training loss: 2.197444438934326
Validation loss: 2.143040200715424

Epoch: 5| Step: 2
Training loss: 2.1660351753234863
Validation loss: 2.1924675049320346

Epoch: 5| Step: 3
Training loss: 1.983319640159607
Validation loss: 2.171099408980339

Epoch: 5| Step: 4
Training loss: 1.2533727884292603
Validation loss: 2.156307384531985

Epoch: 5| Step: 5
Training loss: 3.027341365814209
Validation loss: 2.1274264589432748

Epoch: 5| Step: 6
Training loss: 1.909799337387085
Validation loss: 2.1394825417508363

Epoch: 5| Step: 7
Training loss: 2.2027320861816406
Validation loss: 2.159134308497111

Epoch: 5| Step: 8
Training loss: 2.171943187713623
Validation loss: 2.1836917913088234

Epoch: 5| Step: 9
Training loss: 2.159595012664795
Validation loss: 2.1647658988993657

Epoch: 5| Step: 10
Training loss: 1.9792213439941406
Validation loss: 2.1269769284033004

Epoch: 247| Step: 0
Training loss: 2.028095006942749
Validation loss: 2.1800744994994132

Epoch: 5| Step: 1
Training loss: 2.4955244064331055
Validation loss: 2.1634463405096405

Epoch: 5| Step: 2
Training loss: 1.6117982864379883
Validation loss: 2.203393525974725

Epoch: 5| Step: 3
Training loss: 1.9342613220214844
Validation loss: 2.0665596710738314

Epoch: 5| Step: 4
Training loss: 2.4189772605895996
Validation loss: 2.160172398372363

Epoch: 5| Step: 5
Training loss: 1.6514346599578857
Validation loss: 2.148073193847492

Epoch: 5| Step: 6
Training loss: 1.7952911853790283
Validation loss: 2.1599276988737044

Epoch: 5| Step: 7
Training loss: 2.6945078372955322
Validation loss: 2.190660979158135

Epoch: 5| Step: 8
Training loss: 2.089174747467041
Validation loss: 2.1680894744011665

Epoch: 5| Step: 9
Training loss: 1.627092957496643
Validation loss: 2.210184328017696

Epoch: 5| Step: 10
Training loss: 2.3526668548583984
Validation loss: 2.184753851224017

Epoch: 248| Step: 0
Training loss: 1.8729099035263062
Validation loss: 2.1702815537811606

Epoch: 5| Step: 1
Training loss: 2.8707847595214844
Validation loss: 2.1991197601441415

Epoch: 5| Step: 2
Training loss: 2.258049249649048
Validation loss: 2.1631452883443525

Epoch: 5| Step: 3
Training loss: 2.1068191528320312
Validation loss: 2.197410188695436

Epoch: 5| Step: 4
Training loss: 1.6660633087158203
Validation loss: 2.1566434521828928

Epoch: 5| Step: 5
Training loss: 1.6583940982818604
Validation loss: 2.1701001095515426

Epoch: 5| Step: 6
Training loss: 2.3673529624938965
Validation loss: 2.16693103185264

Epoch: 5| Step: 7
Training loss: 1.8541990518569946
Validation loss: 2.173715711921774

Epoch: 5| Step: 8
Training loss: 2.1041462421417236
Validation loss: 2.1894458583606187

Epoch: 5| Step: 9
Training loss: 2.080535411834717
Validation loss: 2.1449872562962193

Epoch: 5| Step: 10
Training loss: 1.8552405834197998
Validation loss: 2.2461998667768253

Epoch: 249| Step: 0
Training loss: 2.2186763286590576
Validation loss: 2.1917556485822125

Epoch: 5| Step: 1
Training loss: 2.2143590450286865
Validation loss: 2.1781765850641395

Epoch: 5| Step: 2
Training loss: 1.7875158786773682
Validation loss: 2.20819563763116

Epoch: 5| Step: 3
Training loss: 2.301889181137085
Validation loss: 2.1873486490659815

Epoch: 5| Step: 4
Training loss: 2.246241807937622
Validation loss: 2.16960310423246

Epoch: 5| Step: 5
Training loss: 1.5354770421981812
Validation loss: 2.2219713016222884

Epoch: 5| Step: 6
Training loss: 2.0244641304016113
Validation loss: 2.1883794210290395

Epoch: 5| Step: 7
Training loss: 1.7163922786712646
Validation loss: 2.2156150084669872

Epoch: 5| Step: 8
Training loss: 2.0511348247528076
Validation loss: 2.2121179642215854

Epoch: 5| Step: 9
Training loss: 2.4492743015289307
Validation loss: 2.188805126374768

Epoch: 5| Step: 10
Training loss: 2.7012686729431152
Validation loss: 2.179939020064569

Epoch: 250| Step: 0
Training loss: 2.5597846508026123
Validation loss: 2.1938237233828475

Epoch: 5| Step: 1
Training loss: 1.9055875539779663
Validation loss: 2.217503442559191

Epoch: 5| Step: 2
Training loss: 1.704315423965454
Validation loss: 2.193608614706224

Epoch: 5| Step: 3
Training loss: 1.6065648794174194
Validation loss: 2.228376885896088

Epoch: 5| Step: 4
Training loss: 2.082192897796631
Validation loss: 2.158654732088889

Epoch: 5| Step: 5
Training loss: 2.2741150856018066
Validation loss: 2.1651479480087117

Epoch: 5| Step: 6
Training loss: 2.1394386291503906
Validation loss: 2.229938366079843

Epoch: 5| Step: 7
Training loss: 2.165356159210205
Validation loss: 2.150484203010477

Epoch: 5| Step: 8
Training loss: 1.886670708656311
Validation loss: 2.172250755371586

Epoch: 5| Step: 9
Training loss: 2.13883900642395
Validation loss: 2.186494891361524

Epoch: 5| Step: 10
Training loss: 2.5937182903289795
Validation loss: 2.159968694051107

Epoch: 251| Step: 0
Training loss: 1.770302414894104
Validation loss: 2.1473586482386433

Epoch: 5| Step: 1
Training loss: 1.1917221546173096
Validation loss: 2.1724138208614883

Epoch: 5| Step: 2
Training loss: 2.1062934398651123
Validation loss: 2.199371127672093

Epoch: 5| Step: 3
Training loss: 1.7328999042510986
Validation loss: 2.1677981063883793

Epoch: 5| Step: 4
Training loss: 2.010254383087158
Validation loss: 2.186165350739674

Epoch: 5| Step: 5
Training loss: 2.232689380645752
Validation loss: 2.1876472580817437

Epoch: 5| Step: 6
Training loss: 3.2340073585510254
Validation loss: 2.1972173311377086

Epoch: 5| Step: 7
Training loss: 2.508007049560547
Validation loss: 2.1827731952872327

Epoch: 5| Step: 8
Training loss: 1.659653902053833
Validation loss: 2.1626814206441245

Epoch: 5| Step: 9
Training loss: 2.478532552719116
Validation loss: 2.2021352603871334

Epoch: 5| Step: 10
Training loss: 1.8116440773010254
Validation loss: 2.1786083406017673

Epoch: 252| Step: 0
Training loss: 2.296360492706299
Validation loss: 2.1730435343198877

Epoch: 5| Step: 1
Training loss: 2.434385061264038
Validation loss: 2.194289122858355

Epoch: 5| Step: 2
Training loss: 2.188873052597046
Validation loss: 2.1682479484106905

Epoch: 5| Step: 3
Training loss: 2.5090489387512207
Validation loss: 2.187795175019131

Epoch: 5| Step: 4
Training loss: 1.7403818368911743
Validation loss: 2.151543080165822

Epoch: 5| Step: 5
Training loss: 2.0164263248443604
Validation loss: 2.1774978278785624

Epoch: 5| Step: 6
Training loss: 1.681938886642456
Validation loss: 2.15194369387883

Epoch: 5| Step: 7
Training loss: 2.127899646759033
Validation loss: 2.1840928728862474

Epoch: 5| Step: 8
Training loss: 1.6812289953231812
Validation loss: 2.180999458477061

Epoch: 5| Step: 9
Training loss: 2.0350422859191895
Validation loss: 2.181599804150161

Epoch: 5| Step: 10
Training loss: 1.8362680673599243
Validation loss: 2.172013423776114

Epoch: 253| Step: 0
Training loss: 2.348707675933838
Validation loss: 2.176544407362579

Epoch: 5| Step: 1
Training loss: 1.9626268148422241
Validation loss: 2.1780355233018116

Epoch: 5| Step: 2
Training loss: 2.333064556121826
Validation loss: 2.194673430535101

Epoch: 5| Step: 3
Training loss: 1.8579181432724
Validation loss: 2.1582734123353036

Epoch: 5| Step: 4
Training loss: 2.1814122200012207
Validation loss: 2.1643416625197216

Epoch: 5| Step: 5
Training loss: 2.016486644744873
Validation loss: 2.151315112267771

Epoch: 5| Step: 6
Training loss: 2.007033586502075
Validation loss: 2.1389596052067255

Epoch: 5| Step: 7
Training loss: 2.826918363571167
Validation loss: 2.144802131960469

Epoch: 5| Step: 8
Training loss: 1.5118706226348877
Validation loss: 2.1581524559246597

Epoch: 5| Step: 9
Training loss: 1.9464524984359741
Validation loss: 2.175849191604122

Epoch: 5| Step: 10
Training loss: 1.9669373035430908
Validation loss: 2.1869612586113716

Epoch: 254| Step: 0
Training loss: 2.4628353118896484
Validation loss: 2.2176821770206576

Epoch: 5| Step: 1
Training loss: 2.118696689605713
Validation loss: 2.1763937857843216

Epoch: 5| Step: 2
Training loss: 2.5541396141052246
Validation loss: 2.169420640955689

Epoch: 5| Step: 3
Training loss: 1.9699983596801758
Validation loss: 2.2058995667324273

Epoch: 5| Step: 4
Training loss: 1.9242099523544312
Validation loss: 2.1824318644821004

Epoch: 5| Step: 5
Training loss: 2.065703868865967
Validation loss: 2.1893614812563826

Epoch: 5| Step: 6
Training loss: 2.0464792251586914
Validation loss: 2.1578512089226836

Epoch: 5| Step: 7
Training loss: 2.373927593231201
Validation loss: 2.1438781522935435

Epoch: 5| Step: 8
Training loss: 2.149902820587158
Validation loss: 2.1770213137390795

Epoch: 5| Step: 9
Training loss: 1.644601821899414
Validation loss: 2.1849609036599436

Epoch: 5| Step: 10
Training loss: 1.6552821397781372
Validation loss: 2.180718275808519

Epoch: 255| Step: 0
Training loss: 2.817218542098999
Validation loss: 2.217674198971

Epoch: 5| Step: 1
Training loss: 1.9190044403076172
Validation loss: 2.1415333081317205

Epoch: 5| Step: 2
Training loss: 1.8188121318817139
Validation loss: 2.1930283795120897

Epoch: 5| Step: 3
Training loss: 1.9572842121124268
Validation loss: 2.1751457311773814

Epoch: 5| Step: 4
Training loss: 2.4004781246185303
Validation loss: 2.169386471471479

Epoch: 5| Step: 5
Training loss: 2.457913398742676
Validation loss: 2.1736608320666897

Epoch: 5| Step: 6
Training loss: 1.823184609413147
Validation loss: 2.1798261852674585

Epoch: 5| Step: 7
Training loss: 2.158057689666748
Validation loss: 2.201597975146386

Epoch: 5| Step: 8
Training loss: 1.8833467960357666
Validation loss: 2.2152661085128784

Epoch: 5| Step: 9
Training loss: 2.0905234813690186
Validation loss: 2.153806588983023

Epoch: 5| Step: 10
Training loss: 1.242648959159851
Validation loss: 2.186755993032968

Epoch: 256| Step: 0
Training loss: 2.102792501449585
Validation loss: 2.251344257785428

Epoch: 5| Step: 1
Training loss: 2.2147057056427
Validation loss: 2.2091074784596763

Epoch: 5| Step: 2
Training loss: 2.0014731884002686
Validation loss: 2.1119372485786356

Epoch: 5| Step: 3
Training loss: 2.6273157596588135
Validation loss: 2.165883051451816

Epoch: 5| Step: 4
Training loss: 1.947344183921814
Validation loss: 2.1620960363777737

Epoch: 5| Step: 5
Training loss: 2.0915420055389404
Validation loss: 2.131530738645984

Epoch: 5| Step: 6
Training loss: 2.2337989807128906
Validation loss: 2.168851929326211

Epoch: 5| Step: 7
Training loss: 1.7848190069198608
Validation loss: 2.169142084736978

Epoch: 5| Step: 8
Training loss: 1.7432048320770264
Validation loss: 2.167146587884554

Epoch: 5| Step: 9
Training loss: 2.1021454334259033
Validation loss: 2.123402467337988

Epoch: 5| Step: 10
Training loss: 2.0372109413146973
Validation loss: 2.1890201799331175

Epoch: 257| Step: 0
Training loss: 2.094557285308838
Validation loss: 2.1458577033012145

Epoch: 5| Step: 1
Training loss: 1.6600770950317383
Validation loss: 2.1735073725382485

Epoch: 5| Step: 2
Training loss: 2.206650495529175
Validation loss: 2.1418720188961236

Epoch: 5| Step: 3
Training loss: 2.0578489303588867
Validation loss: 2.172721134719028

Epoch: 5| Step: 4
Training loss: 2.1627941131591797
Validation loss: 2.1594477994467622

Epoch: 5| Step: 5
Training loss: 1.9198102951049805
Validation loss: 2.1514105181540213

Epoch: 5| Step: 6
Training loss: 2.486783266067505
Validation loss: 2.152455691368349

Epoch: 5| Step: 7
Training loss: 2.2346529960632324
Validation loss: 2.1521601779486543

Epoch: 5| Step: 8
Training loss: 1.8099838495254517
Validation loss: 2.193870762343048

Epoch: 5| Step: 9
Training loss: 2.3795928955078125
Validation loss: 2.1481742076976325

Epoch: 5| Step: 10
Training loss: 1.4614934921264648
Validation loss: 2.1933177004578295

Epoch: 258| Step: 0
Training loss: 1.7195625305175781
Validation loss: 2.168219861163888

Epoch: 5| Step: 1
Training loss: 2.586559295654297
Validation loss: 2.2323743194662113

Epoch: 5| Step: 2
Training loss: 2.053705930709839
Validation loss: 2.142448494511266

Epoch: 5| Step: 3
Training loss: 1.8796348571777344
Validation loss: 2.167645328788347

Epoch: 5| Step: 4
Training loss: 1.831618309020996
Validation loss: 2.2037871371033373

Epoch: 5| Step: 5
Training loss: 2.1065988540649414
Validation loss: 2.1568951478568454

Epoch: 5| Step: 6
Training loss: 1.9362595081329346
Validation loss: 2.1279053329139628

Epoch: 5| Step: 7
Training loss: 1.568284511566162
Validation loss: 2.1703596268930743

Epoch: 5| Step: 8
Training loss: 2.3898730278015137
Validation loss: 2.1894920923376597

Epoch: 5| Step: 9
Training loss: 2.6986172199249268
Validation loss: 2.1869126571122037

Epoch: 5| Step: 10
Training loss: 1.87798273563385
Validation loss: 2.16994571685791

Epoch: 259| Step: 0
Training loss: 2.021723508834839
Validation loss: 2.2038303985390613

Epoch: 5| Step: 1
Training loss: 1.8011085987091064
Validation loss: 2.2268521349917174

Epoch: 5| Step: 2
Training loss: 1.3736580610275269
Validation loss: 2.154529192114389

Epoch: 5| Step: 3
Training loss: 2.3086540699005127
Validation loss: 2.170041125307801

Epoch: 5| Step: 4
Training loss: 2.513749361038208
Validation loss: 2.1701071159813994

Epoch: 5| Step: 5
Training loss: 2.42140531539917
Validation loss: 2.174356283680085

Epoch: 5| Step: 6
Training loss: 2.0519723892211914
Validation loss: 2.170788821353707

Epoch: 5| Step: 7
Training loss: 2.2391724586486816
Validation loss: 2.1190498080304874

Epoch: 5| Step: 8
Training loss: 1.4628568887710571
Validation loss: 2.156616098137312

Epoch: 5| Step: 9
Training loss: 2.2394096851348877
Validation loss: 2.1730305558891705

Epoch: 5| Step: 10
Training loss: 2.0981085300445557
Validation loss: 2.1635955610582904

Epoch: 260| Step: 0
Training loss: 1.8763138055801392
Validation loss: 2.11324127258793

Epoch: 5| Step: 1
Training loss: 2.204113006591797
Validation loss: 2.206627922673379

Epoch: 5| Step: 2
Training loss: 2.2082438468933105
Validation loss: 2.166525379303963

Epoch: 5| Step: 3
Training loss: 1.6786792278289795
Validation loss: 2.147098448968703

Epoch: 5| Step: 4
Training loss: 1.7517398595809937
Validation loss: 2.1040917788782427

Epoch: 5| Step: 5
Training loss: 2.3465847969055176
Validation loss: 2.1573822818776613

Epoch: 5| Step: 6
Training loss: 1.1146786212921143
Validation loss: 2.1645482214548255

Epoch: 5| Step: 7
Training loss: 1.9500083923339844
Validation loss: 2.1733087237163256

Epoch: 5| Step: 8
Training loss: 2.399477005004883
Validation loss: 2.1200259911116732

Epoch: 5| Step: 9
Training loss: 2.280574321746826
Validation loss: 2.142620143070016

Epoch: 5| Step: 10
Training loss: 2.7620716094970703
Validation loss: 2.1598881239532144

Epoch: 261| Step: 0
Training loss: 2.5186514854431152
Validation loss: 2.1782330851401053

Epoch: 5| Step: 1
Training loss: 1.4966013431549072
Validation loss: 2.1418729341158302

Epoch: 5| Step: 2
Training loss: 1.9673042297363281
Validation loss: 2.154638208368773

Epoch: 5| Step: 3
Training loss: 1.5056374073028564
Validation loss: 2.172046207612561

Epoch: 5| Step: 4
Training loss: 1.8930743932724
Validation loss: 2.212022637808195

Epoch: 5| Step: 5
Training loss: 2.1216673851013184
Validation loss: 2.140230410842485

Epoch: 5| Step: 6
Training loss: 2.020124912261963
Validation loss: 2.2055952959163214

Epoch: 5| Step: 7
Training loss: 2.4209399223327637
Validation loss: 2.1819363153108986

Epoch: 5| Step: 8
Training loss: 1.919555425643921
Validation loss: 2.1691375881113033

Epoch: 5| Step: 9
Training loss: 2.180936336517334
Validation loss: 2.152202078091201

Epoch: 5| Step: 10
Training loss: 2.517998218536377
Validation loss: 2.1621161378839964

Epoch: 262| Step: 0
Training loss: 1.9077987670898438
Validation loss: 2.169570856196906

Epoch: 5| Step: 1
Training loss: 1.952439546585083
Validation loss: 2.1743346798804497

Epoch: 5| Step: 2
Training loss: 1.9536535739898682
Validation loss: 2.2083494740147747

Epoch: 5| Step: 3
Training loss: 2.8046507835388184
Validation loss: 2.2051633814329743

Epoch: 5| Step: 4
Training loss: 1.8148384094238281
Validation loss: 2.1724447229857087

Epoch: 5| Step: 5
Training loss: 1.9347169399261475
Validation loss: 2.2016923542945617

Epoch: 5| Step: 6
Training loss: 2.4899184703826904
Validation loss: 2.2475458755288074

Epoch: 5| Step: 7
Training loss: 1.5338319540023804
Validation loss: 2.1559178547192643

Epoch: 5| Step: 8
Training loss: 2.1078743934631348
Validation loss: 2.231141500575568

Epoch: 5| Step: 9
Training loss: 1.6378822326660156
Validation loss: 2.1971098556313464

Epoch: 5| Step: 10
Training loss: 2.6810922622680664
Validation loss: 2.188123418438819

Epoch: 263| Step: 0
Training loss: 2.092015504837036
Validation loss: 2.1925964099104687

Epoch: 5| Step: 1
Training loss: 2.520293951034546
Validation loss: 2.2060491154270787

Epoch: 5| Step: 2
Training loss: 2.2769131660461426
Validation loss: 2.2060777320656726

Epoch: 5| Step: 3
Training loss: 1.7475932836532593
Validation loss: 2.2152256324727047

Epoch: 5| Step: 4
Training loss: 1.8761295080184937
Validation loss: 2.2044769461436937

Epoch: 5| Step: 5
Training loss: 2.4337024688720703
Validation loss: 2.213288596881333

Epoch: 5| Step: 6
Training loss: 2.15769624710083
Validation loss: 2.189026350616127

Epoch: 5| Step: 7
Training loss: 2.0195631980895996
Validation loss: 2.1347410268681024

Epoch: 5| Step: 8
Training loss: 2.0958807468414307
Validation loss: 2.134077513089744

Epoch: 5| Step: 9
Training loss: 1.7519855499267578
Validation loss: 2.1524279861040014

Epoch: 5| Step: 10
Training loss: 1.6324185132980347
Validation loss: 2.156694991614229

Epoch: 264| Step: 0
Training loss: 1.468689203262329
Validation loss: 2.17779355408043

Epoch: 5| Step: 1
Training loss: 2.115694284439087
Validation loss: 2.1741584424049623

Epoch: 5| Step: 2
Training loss: 2.194070339202881
Validation loss: 2.171252457044458

Epoch: 5| Step: 3
Training loss: 2.067784309387207
Validation loss: 2.202938518216533

Epoch: 5| Step: 4
Training loss: 2.227945566177368
Validation loss: 2.171011104378649

Epoch: 5| Step: 5
Training loss: 2.3670248985290527
Validation loss: 2.1346354869104203

Epoch: 5| Step: 6
Training loss: 2.446685314178467
Validation loss: 2.1364813209861837

Epoch: 5| Step: 7
Training loss: 1.5556838512420654
Validation loss: 2.144848151873517

Epoch: 5| Step: 8
Training loss: 2.3440005779266357
Validation loss: 2.152272567954115

Epoch: 5| Step: 9
Training loss: 1.86428701877594
Validation loss: 2.171607276444794

Epoch: 5| Step: 10
Training loss: 2.051748514175415
Validation loss: 2.129983127758067

Epoch: 265| Step: 0
Training loss: 1.3778371810913086
Validation loss: 2.1261766161969913

Epoch: 5| Step: 1
Training loss: 2.182521343231201
Validation loss: 2.1308673838133454

Epoch: 5| Step: 2
Training loss: 2.655911445617676
Validation loss: 2.1660802864259288

Epoch: 5| Step: 3
Training loss: 2.3979177474975586
Validation loss: 2.1604114501707015

Epoch: 5| Step: 4
Training loss: 1.7203972339630127
Validation loss: 2.165575158211493

Epoch: 5| Step: 5
Training loss: 1.699384331703186
Validation loss: 2.1805657802089566

Epoch: 5| Step: 6
Training loss: 2.414518356323242
Validation loss: 2.1822076279629945

Epoch: 5| Step: 7
Training loss: 1.661703109741211
Validation loss: 2.151561270477951

Epoch: 5| Step: 8
Training loss: 2.244938373565674
Validation loss: 2.103839583294366

Epoch: 5| Step: 9
Training loss: 1.749718427658081
Validation loss: 2.121873870972664

Epoch: 5| Step: 10
Training loss: 2.827615976333618
Validation loss: 2.1396401851407942

Epoch: 266| Step: 0
Training loss: 1.9154560565948486
Validation loss: 2.1587008353202575

Epoch: 5| Step: 1
Training loss: 1.8252143859863281
Validation loss: 2.16635573551219

Epoch: 5| Step: 2
Training loss: 1.8769232034683228
Validation loss: 2.2022902363090107

Epoch: 5| Step: 3
Training loss: 1.7704105377197266
Validation loss: 2.1682312347555674

Epoch: 5| Step: 4
Training loss: 2.0496156215667725
Validation loss: 2.2267370102226094

Epoch: 5| Step: 5
Training loss: 2.4122917652130127
Validation loss: 2.1510067268084456

Epoch: 5| Step: 6
Training loss: 2.6611666679382324
Validation loss: 2.2020681468389367

Epoch: 5| Step: 7
Training loss: 1.9680309295654297
Validation loss: 2.2320426971681657

Epoch: 5| Step: 8
Training loss: 2.089034080505371
Validation loss: 2.231129551446566

Epoch: 5| Step: 9
Training loss: 2.063565731048584
Validation loss: 2.2043492947855303

Epoch: 5| Step: 10
Training loss: 1.7657899856567383
Validation loss: 2.2210470745640416

Epoch: 267| Step: 0
Training loss: 1.6156482696533203
Validation loss: 2.178005169796687

Epoch: 5| Step: 1
Training loss: 2.506450891494751
Validation loss: 2.17062109772877

Epoch: 5| Step: 2
Training loss: 1.6793622970581055
Validation loss: 2.1786832450538554

Epoch: 5| Step: 3
Training loss: 1.7710981369018555
Validation loss: 2.171170652553599

Epoch: 5| Step: 4
Training loss: 2.1545159816741943
Validation loss: 2.150924132716271

Epoch: 5| Step: 5
Training loss: 2.5230283737182617
Validation loss: 2.154501902159824

Epoch: 5| Step: 6
Training loss: 1.9258610010147095
Validation loss: 2.1892643949036956

Epoch: 5| Step: 7
Training loss: 1.5816638469696045
Validation loss: 2.1901037500750635

Epoch: 5| Step: 8
Training loss: 2.3074679374694824
Validation loss: 2.1961336904956448

Epoch: 5| Step: 9
Training loss: 2.6454246044158936
Validation loss: 2.1411434347911547

Epoch: 5| Step: 10
Training loss: 1.690282940864563
Validation loss: 2.15416241973959

Epoch: 268| Step: 0
Training loss: 1.747626543045044
Validation loss: 2.1579648679302585

Epoch: 5| Step: 1
Training loss: 1.945642113685608
Validation loss: 2.1212050504581903

Epoch: 5| Step: 2
Training loss: 2.243420124053955
Validation loss: 2.1635036289051013

Epoch: 5| Step: 3
Training loss: 2.1814723014831543
Validation loss: 2.168912290244974

Epoch: 5| Step: 4
Training loss: 2.5115437507629395
Validation loss: 2.1325260887863817

Epoch: 5| Step: 5
Training loss: 1.326430082321167
Validation loss: 2.1683460973924205

Epoch: 5| Step: 6
Training loss: 2.2947168350219727
Validation loss: 2.1541298999581286

Epoch: 5| Step: 7
Training loss: 2.1725070476531982
Validation loss: 2.1612878563583537

Epoch: 5| Step: 8
Training loss: 2.102756977081299
Validation loss: 2.2000946537140877

Epoch: 5| Step: 9
Training loss: 2.2306435108184814
Validation loss: 2.155055384482107

Epoch: 5| Step: 10
Training loss: 1.5080912113189697
Validation loss: 2.1402213394000964

Epoch: 269| Step: 0
Training loss: 1.7651036977767944
Validation loss: 2.1671547351344937

Epoch: 5| Step: 1
Training loss: 2.7686285972595215
Validation loss: 2.14078095651442

Epoch: 5| Step: 2
Training loss: 2.3474888801574707
Validation loss: 2.2277067527976087

Epoch: 5| Step: 3
Training loss: 1.9120073318481445
Validation loss: 2.1555505939709243

Epoch: 5| Step: 4
Training loss: 1.838870644569397
Validation loss: 2.141188713812059

Epoch: 5| Step: 5
Training loss: 1.2499220371246338
Validation loss: 2.1925949819626345

Epoch: 5| Step: 6
Training loss: 1.9821571111679077
Validation loss: 2.1714175567832044

Epoch: 5| Step: 7
Training loss: 2.0161142349243164
Validation loss: 2.1811636032596713

Epoch: 5| Step: 8
Training loss: 1.8616005182266235
Validation loss: 2.1365304736680883

Epoch: 5| Step: 9
Training loss: 1.8659518957138062
Validation loss: 2.1561156447215746

Epoch: 5| Step: 10
Training loss: 2.8784663677215576
Validation loss: 2.135125414017708

Epoch: 270| Step: 0
Training loss: 2.197582483291626
Validation loss: 2.1686865745052213

Epoch: 5| Step: 1
Training loss: 2.1779372692108154
Validation loss: 2.1846309272191857

Epoch: 5| Step: 2
Training loss: 2.1593832969665527
Validation loss: 2.1639254657171105

Epoch: 5| Step: 3
Training loss: 1.610299825668335
Validation loss: 2.155464497945642

Epoch: 5| Step: 4
Training loss: 2.256969451904297
Validation loss: 2.159284189183225

Epoch: 5| Step: 5
Training loss: 1.9879629611968994
Validation loss: 2.1636833708773375

Epoch: 5| Step: 6
Training loss: 1.679343819618225
Validation loss: 2.2002445344002015

Epoch: 5| Step: 7
Training loss: 1.8597326278686523
Validation loss: 2.1565148048503424

Epoch: 5| Step: 8
Training loss: 2.318524122238159
Validation loss: 2.178621768951416

Epoch: 5| Step: 9
Training loss: 2.2133185863494873
Validation loss: 2.1731416333106255

Epoch: 5| Step: 10
Training loss: 1.711695671081543
Validation loss: 2.161523611314835

Epoch: 271| Step: 0
Training loss: 1.7709405422210693
Validation loss: 2.183251432193223

Epoch: 5| Step: 1
Training loss: 2.0526132583618164
Validation loss: 2.2009718571939776

Epoch: 5| Step: 2
Training loss: 2.647976875305176
Validation loss: 2.125988991029801

Epoch: 5| Step: 3
Training loss: 1.7383897304534912
Validation loss: 2.130251278159439

Epoch: 5| Step: 4
Training loss: 1.896204948425293
Validation loss: 2.206941630250664

Epoch: 5| Step: 5
Training loss: 1.6103332042694092
Validation loss: 2.17142738321776

Epoch: 5| Step: 6
Training loss: 2.5171618461608887
Validation loss: 2.1326974591901227

Epoch: 5| Step: 7
Training loss: 1.6673431396484375
Validation loss: 2.181099727589597

Epoch: 5| Step: 8
Training loss: 2.513540744781494
Validation loss: 2.204904483210656

Epoch: 5| Step: 9
Training loss: 1.9306132793426514
Validation loss: 2.1977716286977134

Epoch: 5| Step: 10
Training loss: 2.138700485229492
Validation loss: 2.186405066520937

Epoch: 272| Step: 0
Training loss: 2.2798337936401367
Validation loss: 2.201682500941779

Epoch: 5| Step: 1
Training loss: 2.4878547191619873
Validation loss: 2.1874873202334166

Epoch: 5| Step: 2
Training loss: 1.8082067966461182
Validation loss: 2.210266269663329

Epoch: 5| Step: 3
Training loss: 1.8724594116210938
Validation loss: 2.1467734844453874

Epoch: 5| Step: 4
Training loss: 1.8297783136367798
Validation loss: 2.1811229746828795

Epoch: 5| Step: 5
Training loss: 2.2013614177703857
Validation loss: 2.2008707113163446

Epoch: 5| Step: 6
Training loss: 2.2694921493530273
Validation loss: 2.170875903098814

Epoch: 5| Step: 7
Training loss: 2.438786029815674
Validation loss: 2.1191330878965315

Epoch: 5| Step: 8
Training loss: 1.579611897468567
Validation loss: 2.165544189432616

Epoch: 5| Step: 9
Training loss: 1.7028586864471436
Validation loss: 2.137573537006173

Epoch: 5| Step: 10
Training loss: 2.0452327728271484
Validation loss: 2.215845231086977

Epoch: 273| Step: 0
Training loss: 1.991551160812378
Validation loss: 2.1943375987391316

Epoch: 5| Step: 1
Training loss: 2.006091594696045
Validation loss: 2.1823445494456957

Epoch: 5| Step: 2
Training loss: 2.451171398162842
Validation loss: 2.1608001980730283

Epoch: 5| Step: 3
Training loss: 1.6306244134902954
Validation loss: 2.1923368348870227

Epoch: 5| Step: 4
Training loss: 1.699298620223999
Validation loss: 2.2196017439647386

Epoch: 5| Step: 5
Training loss: 2.1128947734832764
Validation loss: 2.14231897682272

Epoch: 5| Step: 6
Training loss: 2.489419937133789
Validation loss: 2.122633017519469

Epoch: 5| Step: 7
Training loss: 2.308022975921631
Validation loss: 2.1569937467575073

Epoch: 5| Step: 8
Training loss: 1.900066614151001
Validation loss: 2.128579552455615

Epoch: 5| Step: 9
Training loss: 2.37040376663208
Validation loss: 2.168083010181304

Epoch: 5| Step: 10
Training loss: 1.639189600944519
Validation loss: 2.1488559143517607

Epoch: 274| Step: 0
Training loss: 2.293308734893799
Validation loss: 2.17355760194922

Epoch: 5| Step: 1
Training loss: 1.5032113790512085
Validation loss: 2.1886419634665213

Epoch: 5| Step: 2
Training loss: 1.8357871770858765
Validation loss: 2.1869692494792323

Epoch: 5| Step: 3
Training loss: 1.7518606185913086
Validation loss: 2.159729629434565

Epoch: 5| Step: 4
Training loss: 1.7682965993881226
Validation loss: 2.134643421378187

Epoch: 5| Step: 5
Training loss: 2.721004009246826
Validation loss: 2.118814642711352

Epoch: 5| Step: 6
Training loss: 1.9294207096099854
Validation loss: 2.1612121071866763

Epoch: 5| Step: 7
Training loss: 2.18745493888855
Validation loss: 2.137437544843202

Epoch: 5| Step: 8
Training loss: 2.1506879329681396
Validation loss: 2.1573334663145003

Epoch: 5| Step: 9
Training loss: 1.9234981536865234
Validation loss: 2.1159151177252493

Epoch: 5| Step: 10
Training loss: 2.4549713134765625
Validation loss: 2.132158847265346

Epoch: 275| Step: 0
Training loss: 2.180359125137329
Validation loss: 2.1744453368648404

Epoch: 5| Step: 1
Training loss: 2.760413646697998
Validation loss: 2.1483204262230986

Epoch: 5| Step: 2
Training loss: 1.8341872692108154
Validation loss: 2.171171942064839

Epoch: 5| Step: 3
Training loss: 1.890265703201294
Validation loss: 2.1983794935287966

Epoch: 5| Step: 4
Training loss: 2.3786816596984863
Validation loss: 2.186968316314041

Epoch: 5| Step: 5
Training loss: 1.8456122875213623
Validation loss: 2.1557786515963975

Epoch: 5| Step: 6
Training loss: 2.31425142288208
Validation loss: 2.1649074092988045

Epoch: 5| Step: 7
Training loss: 1.5406033992767334
Validation loss: 2.153649244257199

Epoch: 5| Step: 8
Training loss: 2.357996702194214
Validation loss: 2.1669184712953466

Epoch: 5| Step: 9
Training loss: 1.4565726518630981
Validation loss: 2.202037165241857

Epoch: 5| Step: 10
Training loss: 1.7271543741226196
Validation loss: 2.1717044717522076

Epoch: 276| Step: 0
Training loss: 1.9220432043075562
Validation loss: 2.1840324068582184

Epoch: 5| Step: 1
Training loss: 1.8679859638214111
Validation loss: 2.1760613290212487

Epoch: 5| Step: 2
Training loss: 2.492635726928711
Validation loss: 2.1337678124827724

Epoch: 5| Step: 3
Training loss: 1.780596137046814
Validation loss: 2.1764028431266866

Epoch: 5| Step: 4
Training loss: 1.6414804458618164
Validation loss: 2.2077019804267475

Epoch: 5| Step: 5
Training loss: 2.2475109100341797
Validation loss: 2.217190942456645

Epoch: 5| Step: 6
Training loss: 2.44287109375
Validation loss: 2.223360082154633

Epoch: 5| Step: 7
Training loss: 1.9805848598480225
Validation loss: 2.192414194025019

Epoch: 5| Step: 8
Training loss: 1.918046236038208
Validation loss: 2.2140311118095153

Epoch: 5| Step: 9
Training loss: 2.0648391246795654
Validation loss: 2.133816256318041

Epoch: 5| Step: 10
Training loss: 1.9801734685897827
Validation loss: 2.188751600121939

Epoch: 277| Step: 0
Training loss: 1.4280509948730469
Validation loss: 2.1614003694185646

Epoch: 5| Step: 1
Training loss: 1.8356692790985107
Validation loss: 2.157618731580755

Epoch: 5| Step: 2
Training loss: 2.156409978866577
Validation loss: 2.1728736687732

Epoch: 5| Step: 3
Training loss: 2.0486154556274414
Validation loss: 2.1864414548361175

Epoch: 5| Step: 4
Training loss: 2.1521925926208496
Validation loss: 2.1509815185300765

Epoch: 5| Step: 5
Training loss: 1.444301962852478
Validation loss: 2.182731984764017

Epoch: 5| Step: 6
Training loss: 2.4724910259246826
Validation loss: 2.1848252255429506

Epoch: 5| Step: 7
Training loss: 1.5802686214447021
Validation loss: 2.1393757225364767

Epoch: 5| Step: 8
Training loss: 2.169381856918335
Validation loss: 2.141408510105584

Epoch: 5| Step: 9
Training loss: 2.887993812561035
Validation loss: 2.138866545051657

Epoch: 5| Step: 10
Training loss: 2.1115942001342773
Validation loss: 2.154712459092499

Epoch: 278| Step: 0
Training loss: 2.013719081878662
Validation loss: 2.172422162948116

Epoch: 5| Step: 1
Training loss: 2.465507984161377
Validation loss: 2.181525840554186

Epoch: 5| Step: 2
Training loss: 2.132183790206909
Validation loss: 2.1661367493291057

Epoch: 5| Step: 3
Training loss: 1.9148286581039429
Validation loss: 2.1935261808415896

Epoch: 5| Step: 4
Training loss: 2.5373685359954834
Validation loss: 2.224077759250518

Epoch: 5| Step: 5
Training loss: 1.730539321899414
Validation loss: 2.1729149715874785

Epoch: 5| Step: 6
Training loss: 1.9368976354599
Validation loss: 2.132380344534433

Epoch: 5| Step: 7
Training loss: 2.196911334991455
Validation loss: 2.1416205757407734

Epoch: 5| Step: 8
Training loss: 1.523040533065796
Validation loss: 2.1257385182124313

Epoch: 5| Step: 9
Training loss: 2.4474527835845947
Validation loss: 2.1804765488511775

Epoch: 5| Step: 10
Training loss: 1.3898344039916992
Validation loss: 2.227766252333118

Epoch: 279| Step: 0
Training loss: 1.9494876861572266
Validation loss: 2.200625992590381

Epoch: 5| Step: 1
Training loss: 2.0379137992858887
Validation loss: 2.154704902761726

Epoch: 5| Step: 2
Training loss: 1.6544179916381836
Validation loss: 2.1538916851884577

Epoch: 5| Step: 3
Training loss: 2.6609981060028076
Validation loss: 2.173922993803537

Epoch: 5| Step: 4
Training loss: 2.708982467651367
Validation loss: 2.155862622363593

Epoch: 5| Step: 5
Training loss: 2.2002110481262207
Validation loss: 2.1506986938497072

Epoch: 5| Step: 6
Training loss: 2.0460622310638428
Validation loss: 2.1717871440354215

Epoch: 5| Step: 7
Training loss: 1.4765936136245728
Validation loss: 2.1950781076185164

Epoch: 5| Step: 8
Training loss: 1.2618894577026367
Validation loss: 2.230630425996678

Epoch: 5| Step: 9
Training loss: 2.40496563911438
Validation loss: 2.1829331767174507

Epoch: 5| Step: 10
Training loss: 2.112558364868164
Validation loss: 2.2124187689955517

Epoch: 280| Step: 0
Training loss: 2.2935686111450195
Validation loss: 2.2041805713407454

Epoch: 5| Step: 1
Training loss: 2.07643985748291
Validation loss: 2.1790519247772875

Epoch: 5| Step: 2
Training loss: 1.8682740926742554
Validation loss: 2.174861031193887

Epoch: 5| Step: 3
Training loss: 2.2160563468933105
Validation loss: 2.172793924167592

Epoch: 5| Step: 4
Training loss: 2.0850744247436523
Validation loss: 2.1666872834646576

Epoch: 5| Step: 5
Training loss: 2.9057364463806152
Validation loss: 2.179967967412805

Epoch: 5| Step: 6
Training loss: 1.8940656185150146
Validation loss: 2.1553643339423725

Epoch: 5| Step: 7
Training loss: 1.5341867208480835
Validation loss: 2.17109441244474

Epoch: 5| Step: 8
Training loss: 1.5259453058242798
Validation loss: 2.1667009271601194

Epoch: 5| Step: 9
Training loss: 1.7660417556762695
Validation loss: 2.1736771932212253

Epoch: 5| Step: 10
Training loss: 2.433605670928955
Validation loss: 2.1521534227555796

Epoch: 281| Step: 0
Training loss: 1.846112847328186
Validation loss: 2.1749626872360066

Epoch: 5| Step: 1
Training loss: 2.0995724201202393
Validation loss: 2.1580373446146646

Epoch: 5| Step: 2
Training loss: 1.4428237676620483
Validation loss: 2.136778229026384

Epoch: 5| Step: 3
Training loss: 2.3621087074279785
Validation loss: 2.191543799574657

Epoch: 5| Step: 4
Training loss: 2.2666726112365723
Validation loss: 2.169140487588862

Epoch: 5| Step: 5
Training loss: 1.9390575885772705
Validation loss: 2.152181734320938

Epoch: 5| Step: 6
Training loss: 3.0453498363494873
Validation loss: 2.128820553902657

Epoch: 5| Step: 7
Training loss: 1.917759895324707
Validation loss: 2.115038287255072

Epoch: 5| Step: 8
Training loss: 2.125339984893799
Validation loss: 2.149212675709878

Epoch: 5| Step: 9
Training loss: 1.4653724431991577
Validation loss: 2.2114461673203336

Epoch: 5| Step: 10
Training loss: 1.7778887748718262
Validation loss: 2.12691250155049

Epoch: 282| Step: 0
Training loss: 1.8697057962417603
Validation loss: 2.196380102506248

Epoch: 5| Step: 1
Training loss: 1.3471139669418335
Validation loss: 2.2077065437070784

Epoch: 5| Step: 2
Training loss: 1.386645793914795
Validation loss: 2.2085184999691543

Epoch: 5| Step: 3
Training loss: 2.2144103050231934
Validation loss: 2.2039857141433226

Epoch: 5| Step: 4
Training loss: 2.2616024017333984
Validation loss: 2.226753765536893

Epoch: 5| Step: 5
Training loss: 2.5116772651672363
Validation loss: 2.141795213504504

Epoch: 5| Step: 6
Training loss: 1.9718959331512451
Validation loss: 2.2331232691323883

Epoch: 5| Step: 7
Training loss: 1.791540503501892
Validation loss: 2.227527344098655

Epoch: 5| Step: 8
Training loss: 2.4360756874084473
Validation loss: 2.1753932775989657

Epoch: 5| Step: 9
Training loss: 2.376613140106201
Validation loss: 2.1880654340149253

Epoch: 5| Step: 10
Training loss: 2.308237075805664
Validation loss: 2.158967359091646

Epoch: 283| Step: 0
Training loss: 1.830810546875
Validation loss: 2.1896697551973405

Epoch: 5| Step: 1
Training loss: 2.273970603942871
Validation loss: 2.2133455507216917

Epoch: 5| Step: 2
Training loss: 2.2553207874298096
Validation loss: 2.1799273824179046

Epoch: 5| Step: 3
Training loss: 2.097102642059326
Validation loss: 2.2099254644045265

Epoch: 5| Step: 4
Training loss: 2.266209840774536
Validation loss: 2.142672041411041

Epoch: 5| Step: 5
Training loss: 1.5210583209991455
Validation loss: 2.153122958316598

Epoch: 5| Step: 6
Training loss: 1.6910507678985596
Validation loss: 2.1810500596159246

Epoch: 5| Step: 7
Training loss: 2.230217933654785
Validation loss: 2.147636954502393

Epoch: 5| Step: 8
Training loss: 2.479245662689209
Validation loss: 2.1469451253132155

Epoch: 5| Step: 9
Training loss: 1.8439117670059204
Validation loss: 2.1463283672127673

Epoch: 5| Step: 10
Training loss: 1.93721342086792
Validation loss: 2.1682091528369534

Epoch: 284| Step: 0
Training loss: 2.4710729122161865
Validation loss: 2.176638682683309

Epoch: 5| Step: 1
Training loss: 1.9912267923355103
Validation loss: 2.1756084734393704

Epoch: 5| Step: 2
Training loss: 1.4805920124053955
Validation loss: 2.1621272640843547

Epoch: 5| Step: 3
Training loss: 2.1431262493133545
Validation loss: 2.181516016683271

Epoch: 5| Step: 4
Training loss: 2.016726493835449
Validation loss: 2.1625257640756588

Epoch: 5| Step: 5
Training loss: 1.8187065124511719
Validation loss: 2.178703995161159

Epoch: 5| Step: 6
Training loss: 1.3614429235458374
Validation loss: 2.189651612312563

Epoch: 5| Step: 7
Training loss: 3.0223653316497803
Validation loss: 2.143336722927709

Epoch: 5| Step: 8
Training loss: 1.7982914447784424
Validation loss: 2.1606937403319986

Epoch: 5| Step: 9
Training loss: 1.9177135229110718
Validation loss: 2.160211575928555

Epoch: 5| Step: 10
Training loss: 2.1310110092163086
Validation loss: 2.108865317477975

Epoch: 285| Step: 0
Training loss: 2.732168436050415
Validation loss: 2.181603116373862

Epoch: 5| Step: 1
Training loss: 1.6467307806015015
Validation loss: 2.140568333287393

Epoch: 5| Step: 2
Training loss: 2.083859443664551
Validation loss: 2.184277283248081

Epoch: 5| Step: 3
Training loss: 2.3266351222991943
Validation loss: 2.192199557058273

Epoch: 5| Step: 4
Training loss: 1.769348382949829
Validation loss: 2.1351618715511855

Epoch: 5| Step: 5
Training loss: 1.6186937093734741
Validation loss: 2.1788251194902646

Epoch: 5| Step: 6
Training loss: 1.8341598510742188
Validation loss: 2.160265709764214

Epoch: 5| Step: 7
Training loss: 2.1101744174957275
Validation loss: 2.1829894793930875

Epoch: 5| Step: 8
Training loss: 2.0894856452941895
Validation loss: 2.143390078698435

Epoch: 5| Step: 9
Training loss: 2.261471748352051
Validation loss: 2.1911571820576987

Epoch: 5| Step: 10
Training loss: 1.7821704149246216
Validation loss: 2.1810824281425885

Epoch: 286| Step: 0
Training loss: 2.2144691944122314
Validation loss: 2.153713418591407

Epoch: 5| Step: 1
Training loss: 2.595045328140259
Validation loss: 2.1217406924052904

Epoch: 5| Step: 2
Training loss: 1.1427291631698608
Validation loss: 2.135121117356003

Epoch: 5| Step: 3
Training loss: 3.281126022338867
Validation loss: 2.1738879398633073

Epoch: 5| Step: 4
Training loss: 1.1379696130752563
Validation loss: 2.1483697993780977

Epoch: 5| Step: 5
Training loss: 1.841718316078186
Validation loss: 2.2085587004179597

Epoch: 5| Step: 6
Training loss: 1.751591444015503
Validation loss: 2.153997540473938

Epoch: 5| Step: 7
Training loss: 2.147806167602539
Validation loss: 2.173325131016393

Epoch: 5| Step: 8
Training loss: 2.3762800693511963
Validation loss: 2.2030586017075406

Epoch: 5| Step: 9
Training loss: 1.8298368453979492
Validation loss: 2.1252191528197257

Epoch: 5| Step: 10
Training loss: 1.8841527700424194
Validation loss: 2.1318063325779413

Epoch: 287| Step: 0
Training loss: 2.04681396484375
Validation loss: 2.1632881241460002

Epoch: 5| Step: 1
Training loss: 1.7756245136260986
Validation loss: 2.182600554599557

Epoch: 5| Step: 2
Training loss: 2.8197519779205322
Validation loss: 2.198850857314243

Epoch: 5| Step: 3
Training loss: 2.224064350128174
Validation loss: 2.159635046476959

Epoch: 5| Step: 4
Training loss: 1.6752712726593018
Validation loss: 2.1648962151619697

Epoch: 5| Step: 5
Training loss: 1.3868495225906372
Validation loss: 2.185453217516663

Epoch: 5| Step: 6
Training loss: 2.0121147632598877
Validation loss: 2.150641402890605

Epoch: 5| Step: 7
Training loss: 1.9932165145874023
Validation loss: 2.168528426078058

Epoch: 5| Step: 8
Training loss: 2.093374490737915
Validation loss: 2.1676098633837957

Epoch: 5| Step: 9
Training loss: 2.4615135192871094
Validation loss: 2.168686291222931

Epoch: 5| Step: 10
Training loss: 1.7318164110183716
Validation loss: 2.1839169802204257

Epoch: 288| Step: 0
Training loss: 1.801734209060669
Validation loss: 2.185350516790985

Epoch: 5| Step: 1
Training loss: 2.5657436847686768
Validation loss: 2.1686950255465764

Epoch: 5| Step: 2
Training loss: 1.594420075416565
Validation loss: 2.1553518823398057

Epoch: 5| Step: 3
Training loss: 2.7864153385162354
Validation loss: 2.147411970682042

Epoch: 5| Step: 4
Training loss: 1.8435214757919312
Validation loss: 2.1791973601105394

Epoch: 5| Step: 5
Training loss: 2.1201672554016113
Validation loss: 2.236234126552459

Epoch: 5| Step: 6
Training loss: 1.9285790920257568
Validation loss: 2.1775337855021157

Epoch: 5| Step: 7
Training loss: 1.9674030542373657
Validation loss: 2.177422620916879

Epoch: 5| Step: 8
Training loss: 1.9644094705581665
Validation loss: 2.2131188761803413

Epoch: 5| Step: 9
Training loss: 2.032712459564209
Validation loss: 2.1772620921493857

Epoch: 5| Step: 10
Training loss: 1.7784401178359985
Validation loss: 2.1372700365640784

Epoch: 289| Step: 0
Training loss: 1.8452380895614624
Validation loss: 2.196621282126314

Epoch: 5| Step: 1
Training loss: 2.324361801147461
Validation loss: 2.1643347688900527

Epoch: 5| Step: 2
Training loss: 1.8356444835662842
Validation loss: 2.209098308317123

Epoch: 5| Step: 3
Training loss: 1.871657133102417
Validation loss: 2.181345829399683

Epoch: 5| Step: 4
Training loss: 2.1760435104370117
Validation loss: 2.1394257084015877

Epoch: 5| Step: 5
Training loss: 1.8056871891021729
Validation loss: 2.1695862970044537

Epoch: 5| Step: 6
Training loss: 2.856085777282715
Validation loss: 2.1718162541748374

Epoch: 5| Step: 7
Training loss: 1.9691026210784912
Validation loss: 2.1637428934856127

Epoch: 5| Step: 8
Training loss: 1.7044460773468018
Validation loss: 2.1335123662025697

Epoch: 5| Step: 9
Training loss: 2.0542256832122803
Validation loss: 2.185388316390335

Epoch: 5| Step: 10
Training loss: 1.6413313150405884
Validation loss: 2.183454031585365

Epoch: 290| Step: 0
Training loss: 2.104538679122925
Validation loss: 2.161777501465172

Epoch: 5| Step: 1
Training loss: 2.626973867416382
Validation loss: 2.168799618239044

Epoch: 5| Step: 2
Training loss: 1.8360258340835571
Validation loss: 2.1297851313826857

Epoch: 5| Step: 3
Training loss: 2.2377638816833496
Validation loss: 2.1391139440639044

Epoch: 5| Step: 4
Training loss: 1.9091310501098633
Validation loss: 2.2031528872828328

Epoch: 5| Step: 5
Training loss: 1.5678235292434692
Validation loss: 2.18042084991291

Epoch: 5| Step: 6
Training loss: 1.7471812963485718
Validation loss: 2.1611505964750886

Epoch: 5| Step: 7
Training loss: 1.6134008169174194
Validation loss: 2.176037057753532

Epoch: 5| Step: 8
Training loss: 2.364107847213745
Validation loss: 2.189242478339903

Epoch: 5| Step: 9
Training loss: 2.3677101135253906
Validation loss: 2.1851218464553996

Epoch: 5| Step: 10
Training loss: 1.8176777362823486
Validation loss: 2.194144650172162

Epoch: 291| Step: 0
Training loss: 1.4259761571884155
Validation loss: 2.155994097391764

Epoch: 5| Step: 1
Training loss: 2.1866137981414795
Validation loss: 2.185348427423867

Epoch: 5| Step: 2
Training loss: 2.579726219177246
Validation loss: 2.149396527198053

Epoch: 5| Step: 3
Training loss: 1.804682970046997
Validation loss: 2.1942080067050074

Epoch: 5| Step: 4
Training loss: 1.8984782695770264
Validation loss: 2.1677103709149104

Epoch: 5| Step: 5
Training loss: 2.436443328857422
Validation loss: 2.2046630754265735

Epoch: 5| Step: 6
Training loss: 1.7493969202041626
Validation loss: 2.1962296475646315

Epoch: 5| Step: 7
Training loss: 2.8412461280822754
Validation loss: 2.2003088240982382

Epoch: 5| Step: 8
Training loss: 1.500313639640808
Validation loss: 2.1771223621983684

Epoch: 5| Step: 9
Training loss: 1.5149797201156616
Validation loss: 2.121024198429559

Epoch: 5| Step: 10
Training loss: 1.9610873460769653
Validation loss: 2.1248567822158977

Epoch: 292| Step: 0
Training loss: 1.7177711725234985
Validation loss: 2.157691142892325

Epoch: 5| Step: 1
Training loss: 2.122011423110962
Validation loss: 2.1611198943148375

Epoch: 5| Step: 2
Training loss: 2.143756628036499
Validation loss: 2.15465969680458

Epoch: 5| Step: 3
Training loss: 2.434823989868164
Validation loss: 2.1553944208288707

Epoch: 5| Step: 4
Training loss: 2.074669122695923
Validation loss: 2.1775983251551145

Epoch: 5| Step: 5
Training loss: 2.6204113960266113
Validation loss: 2.1027972570029636

Epoch: 5| Step: 6
Training loss: 1.7076666355133057
Validation loss: 2.21294298735998

Epoch: 5| Step: 7
Training loss: 2.0582125186920166
Validation loss: 2.147390215627609

Epoch: 5| Step: 8
Training loss: 1.690393090248108
Validation loss: 2.108581804460095

Epoch: 5| Step: 9
Training loss: 1.4740850925445557
Validation loss: 2.150453785414337

Epoch: 5| Step: 10
Training loss: 2.0966532230377197
Validation loss: 2.1033598915223153

Epoch: 293| Step: 0
Training loss: 1.760277509689331
Validation loss: 2.139344661466537

Epoch: 5| Step: 1
Training loss: 1.6612008810043335
Validation loss: 2.1706559811868975

Epoch: 5| Step: 2
Training loss: 1.502076506614685
Validation loss: 2.127682093651064

Epoch: 5| Step: 3
Training loss: 2.3776955604553223
Validation loss: 2.1867753049378753

Epoch: 5| Step: 4
Training loss: 2.5175411701202393
Validation loss: 2.181203326871318

Epoch: 5| Step: 5
Training loss: 2.487441301345825
Validation loss: 2.1811186536665885

Epoch: 5| Step: 6
Training loss: 1.1979036331176758
Validation loss: 2.2220567682737946

Epoch: 5| Step: 7
Training loss: 2.1127846240997314
Validation loss: 2.162363467677947

Epoch: 5| Step: 8
Training loss: 2.3223776817321777
Validation loss: 2.188966647271187

Epoch: 5| Step: 9
Training loss: 1.6834163665771484
Validation loss: 2.1562600187076035

Epoch: 5| Step: 10
Training loss: 2.2135374546051025
Validation loss: 2.150070389111837

Epoch: 294| Step: 0
Training loss: 1.6974741220474243
Validation loss: 2.1588793749450357

Epoch: 5| Step: 1
Training loss: 1.779842734336853
Validation loss: 2.1207909763500257

Epoch: 5| Step: 2
Training loss: 1.6135622262954712
Validation loss: 2.1452362857839113

Epoch: 5| Step: 3
Training loss: 1.9797489643096924
Validation loss: 2.186475823002477

Epoch: 5| Step: 4
Training loss: 2.272902727127075
Validation loss: 2.1672152729444605

Epoch: 5| Step: 5
Training loss: 1.7626571655273438
Validation loss: 2.1690552978105444

Epoch: 5| Step: 6
Training loss: 2.5309059619903564
Validation loss: 2.211021222094054

Epoch: 5| Step: 7
Training loss: 2.216587543487549
Validation loss: 2.1550678168573687

Epoch: 5| Step: 8
Training loss: 1.9485050439834595
Validation loss: 2.154096052210818

Epoch: 5| Step: 9
Training loss: 2.2079415321350098
Validation loss: 2.16070395387629

Epoch: 5| Step: 10
Training loss: 2.4542460441589355
Validation loss: 2.176983444921432

Epoch: 295| Step: 0
Training loss: 1.951939582824707
Validation loss: 2.1667031370183474

Epoch: 5| Step: 1
Training loss: 1.7862284183502197
Validation loss: 2.134172155011085

Epoch: 5| Step: 2
Training loss: 2.037097215652466
Validation loss: 2.1183230030921196

Epoch: 5| Step: 3
Training loss: 2.2653539180755615
Validation loss: 2.235176449180931

Epoch: 5| Step: 4
Training loss: 2.082364797592163
Validation loss: 2.162660027063021

Epoch: 5| Step: 5
Training loss: 2.129725933074951
Validation loss: 2.1814414506317465

Epoch: 5| Step: 6
Training loss: 2.097661018371582
Validation loss: 2.1463041959270353

Epoch: 5| Step: 7
Training loss: 2.4181575775146484
Validation loss: 2.161447436578812

Epoch: 5| Step: 8
Training loss: 1.7328617572784424
Validation loss: 2.1885003453941754

Epoch: 5| Step: 9
Training loss: 1.875963568687439
Validation loss: 2.1306075524258357

Epoch: 5| Step: 10
Training loss: 1.994422435760498
Validation loss: 2.1554801758899482

Epoch: 296| Step: 0
Training loss: 2.247213840484619
Validation loss: 2.177456855773926

Epoch: 5| Step: 1
Training loss: 2.0940327644348145
Validation loss: 2.144438894846106

Epoch: 5| Step: 2
Training loss: 2.4456779956817627
Validation loss: 2.2055920067653862

Epoch: 5| Step: 3
Training loss: 1.9751018285751343
Validation loss: 2.1628266739588913

Epoch: 5| Step: 4
Training loss: 1.23978590965271
Validation loss: 2.206025431233068

Epoch: 5| Step: 5
Training loss: 1.4303081035614014
Validation loss: 2.1595914389497493

Epoch: 5| Step: 6
Training loss: 2.1830296516418457
Validation loss: 2.12040013523512

Epoch: 5| Step: 7
Training loss: 2.3784453868865967
Validation loss: 2.191509623681345

Epoch: 5| Step: 8
Training loss: 2.10798978805542
Validation loss: 2.162715747792234

Epoch: 5| Step: 9
Training loss: 1.5940005779266357
Validation loss: 2.1805915089063745

Epoch: 5| Step: 10
Training loss: 2.4836275577545166
Validation loss: 2.174129698866157

Epoch: 297| Step: 0
Training loss: 2.1925995349884033
Validation loss: 2.2102410921486477

Epoch: 5| Step: 1
Training loss: 1.7592155933380127
Validation loss: 2.1654535493543072

Epoch: 5| Step: 2
Training loss: 2.2207589149475098
Validation loss: 2.1057858133828766

Epoch: 5| Step: 3
Training loss: 2.021735191345215
Validation loss: 2.1793599218450566

Epoch: 5| Step: 4
Training loss: 2.0389199256896973
Validation loss: 2.1697856559548327

Epoch: 5| Step: 5
Training loss: 1.7826217412948608
Validation loss: 2.1297602756049043

Epoch: 5| Step: 6
Training loss: 1.7438468933105469
Validation loss: 2.1465069427285144

Epoch: 5| Step: 7
Training loss: 2.308210849761963
Validation loss: 2.115404354628696

Epoch: 5| Step: 8
Training loss: 2.314544200897217
Validation loss: 2.1945307588064544

Epoch: 5| Step: 9
Training loss: 2.2840471267700195
Validation loss: 2.159818272436819

Epoch: 5| Step: 10
Training loss: 1.1784582138061523
Validation loss: 2.166581905016335

Epoch: 298| Step: 0
Training loss: 2.0022730827331543
Validation loss: 2.1351469703899917

Epoch: 5| Step: 1
Training loss: 2.406802177429199
Validation loss: 2.1660589671904042

Epoch: 5| Step: 2
Training loss: 2.1861727237701416
Validation loss: 2.0964028117477254

Epoch: 5| Step: 3
Training loss: 2.009645700454712
Validation loss: 2.141676457979346

Epoch: 5| Step: 4
Training loss: 2.357670545578003
Validation loss: 2.152530301001764

Epoch: 5| Step: 5
Training loss: 2.7062923908233643
Validation loss: 2.1585376698483705

Epoch: 5| Step: 6
Training loss: 2.043304920196533
Validation loss: 2.167746223429198

Epoch: 5| Step: 7
Training loss: 1.0163547992706299
Validation loss: 2.1398791882299606

Epoch: 5| Step: 8
Training loss: 1.6096789836883545
Validation loss: 2.106535816705355

Epoch: 5| Step: 9
Training loss: 2.013667583465576
Validation loss: 2.1181319657192437

Epoch: 5| Step: 10
Training loss: 1.8174304962158203
Validation loss: 2.1486022818473076

Epoch: 299| Step: 0
Training loss: 2.416454315185547
Validation loss: 2.170736143665929

Epoch: 5| Step: 1
Training loss: 1.2645689249038696
Validation loss: 2.1476400026711087

Epoch: 5| Step: 2
Training loss: 1.6965373754501343
Validation loss: 2.176658638062016

Epoch: 5| Step: 3
Training loss: 1.7013905048370361
Validation loss: 2.1752479999296126

Epoch: 5| Step: 4
Training loss: 2.206444501876831
Validation loss: 2.1460494226024998

Epoch: 5| Step: 5
Training loss: 2.133227825164795
Validation loss: 2.1604332385524625

Epoch: 5| Step: 6
Training loss: 2.1323416233062744
Validation loss: 2.1806853689173216

Epoch: 5| Step: 7
Training loss: 1.8920866250991821
Validation loss: 2.1524100585650374

Epoch: 5| Step: 8
Training loss: 2.2094290256500244
Validation loss: 2.1687292924491306

Epoch: 5| Step: 9
Training loss: 1.9641530513763428
Validation loss: 2.149375928345547

Epoch: 5| Step: 10
Training loss: 2.4754037857055664
Validation loss: 2.181999041188148

Epoch: 300| Step: 0
Training loss: 1.8473011255264282
Validation loss: 2.1859413628937094

Epoch: 5| Step: 1
Training loss: 1.7702983617782593
Validation loss: 2.164511626766574

Epoch: 5| Step: 2
Training loss: 1.8297736644744873
Validation loss: 2.2125682189900386

Epoch: 5| Step: 3
Training loss: 1.775527000427246
Validation loss: 2.126593694891981

Epoch: 5| Step: 4
Training loss: 2.2722322940826416
Validation loss: 2.195610718060565

Epoch: 5| Step: 5
Training loss: 2.3838870525360107
Validation loss: 2.200049777184763

Epoch: 5| Step: 6
Training loss: 2.149571180343628
Validation loss: 2.1670938179057133

Epoch: 5| Step: 7
Training loss: 2.1315135955810547
Validation loss: 2.1458421650753228

Epoch: 5| Step: 8
Training loss: 1.9265825748443604
Validation loss: 2.154479867668562

Epoch: 5| Step: 9
Training loss: 1.7243926525115967
Validation loss: 2.1589189114109164

Epoch: 5| Step: 10
Training loss: 2.088226795196533
Validation loss: 2.2043458902707664

Epoch: 301| Step: 0
Training loss: 2.033310651779175
Validation loss: 2.1846787365533973

Epoch: 5| Step: 1
Training loss: 1.844799280166626
Validation loss: 2.1946922502210064

Epoch: 5| Step: 2
Training loss: 1.672882080078125
Validation loss: 2.1748983347287743

Epoch: 5| Step: 3
Training loss: 2.1779119968414307
Validation loss: 2.1117211798185944

Epoch: 5| Step: 4
Training loss: 1.8308241367340088
Validation loss: 2.145403851744949

Epoch: 5| Step: 5
Training loss: 2.055952548980713
Validation loss: 2.1577055108162666

Epoch: 5| Step: 6
Training loss: 1.343855619430542
Validation loss: 2.1559157525339434

Epoch: 5| Step: 7
Training loss: 2.152264356613159
Validation loss: 2.1514389130377

Epoch: 5| Step: 8
Training loss: 2.2081046104431152
Validation loss: 2.153391154863501

Epoch: 5| Step: 9
Training loss: 1.9781560897827148
Validation loss: 2.1379416565741263

Epoch: 5| Step: 10
Training loss: 2.549452543258667
Validation loss: 2.165642794742379

Epoch: 302| Step: 0
Training loss: 1.644470453262329
Validation loss: 2.1611189124404744

Epoch: 5| Step: 1
Training loss: 2.254106044769287
Validation loss: 2.1421936635048158

Epoch: 5| Step: 2
Training loss: 1.8554188013076782
Validation loss: 2.1544372009974655

Epoch: 5| Step: 3
Training loss: 1.9146888256072998
Validation loss: 2.160411701407484

Epoch: 5| Step: 4
Training loss: 1.787580132484436
Validation loss: 2.1502572721050632

Epoch: 5| Step: 5
Training loss: 2.792860507965088
Validation loss: 2.1770811260387464

Epoch: 5| Step: 6
Training loss: 1.7233299016952515
Validation loss: 2.1613107394146662

Epoch: 5| Step: 7
Training loss: 1.451080083847046
Validation loss: 2.1494416703460035

Epoch: 5| Step: 8
Training loss: 2.030203104019165
Validation loss: 2.164249474002469

Epoch: 5| Step: 9
Training loss: 2.033698558807373
Validation loss: 2.1355609791253203

Epoch: 5| Step: 10
Training loss: 2.4062325954437256
Validation loss: 2.17290593988152

Epoch: 303| Step: 0
Training loss: 1.3937116861343384
Validation loss: 2.1695243645739812

Epoch: 5| Step: 1
Training loss: 1.5044740438461304
Validation loss: 2.1722620866631948

Epoch: 5| Step: 2
Training loss: 2.6917953491210938
Validation loss: 2.194385720837501

Epoch: 5| Step: 3
Training loss: 2.07501482963562
Validation loss: 2.151376215360498

Epoch: 5| Step: 4
Training loss: 2.5305190086364746
Validation loss: 2.170781526514279

Epoch: 5| Step: 5
Training loss: 1.5352962017059326
Validation loss: 2.1834154846847698

Epoch: 5| Step: 6
Training loss: 1.7600816488265991
Validation loss: 2.1756808321963073

Epoch: 5| Step: 7
Training loss: 1.6001567840576172
Validation loss: 2.214225563951718

Epoch: 5| Step: 8
Training loss: 1.7557989358901978
Validation loss: 2.157059182402908

Epoch: 5| Step: 9
Training loss: 2.205944776535034
Validation loss: 2.1760808088446177

Epoch: 5| Step: 10
Training loss: 2.9907100200653076
Validation loss: 2.1903982393203245

Epoch: 304| Step: 0
Training loss: 1.7659460306167603
Validation loss: 2.192103019324682

Epoch: 5| Step: 1
Training loss: 1.69281005859375
Validation loss: 2.155892772059287

Epoch: 5| Step: 2
Training loss: 2.1301674842834473
Validation loss: 2.1813524384652414

Epoch: 5| Step: 3
Training loss: 2.657876491546631
Validation loss: 2.159907897313436

Epoch: 5| Step: 4
Training loss: 1.922621488571167
Validation loss: 2.1690313995525403

Epoch: 5| Step: 5
Training loss: 1.447204351425171
Validation loss: 2.1744420502775457

Epoch: 5| Step: 6
Training loss: 2.8597874641418457
Validation loss: 2.1736623061600553

Epoch: 5| Step: 7
Training loss: 2.027752161026001
Validation loss: 2.1752985779957106

Epoch: 5| Step: 8
Training loss: 1.9494407176971436
Validation loss: 2.1211624555690314

Epoch: 5| Step: 9
Training loss: 1.7870235443115234
Validation loss: 2.1798987286065215

Epoch: 5| Step: 10
Training loss: 1.5384913682937622
Validation loss: 2.178048884996804

Epoch: 305| Step: 0
Training loss: 2.3596341609954834
Validation loss: 2.1305945611769155

Epoch: 5| Step: 1
Training loss: 2.2614989280700684
Validation loss: 2.2008228737820863

Epoch: 5| Step: 2
Training loss: 1.5104702711105347
Validation loss: 2.1609739180534118

Epoch: 5| Step: 3
Training loss: 2.2283682823181152
Validation loss: 2.1516908817393805

Epoch: 5| Step: 4
Training loss: 1.0161147117614746
Validation loss: 2.1393876832018615

Epoch: 5| Step: 5
Training loss: 1.6528303623199463
Validation loss: 2.1672240944318872

Epoch: 5| Step: 6
Training loss: 2.251720666885376
Validation loss: 2.219954118933729

Epoch: 5| Step: 7
Training loss: 2.6444506645202637
Validation loss: 2.1809773419492986

Epoch: 5| Step: 8
Training loss: 1.3307018280029297
Validation loss: 2.220113931163665

Epoch: 5| Step: 9
Training loss: 2.3146872520446777
Validation loss: 2.2005193976945776

Epoch: 5| Step: 10
Training loss: 2.250253677368164
Validation loss: 2.1884676256487445

Epoch: 306| Step: 0
Training loss: 2.0389580726623535
Validation loss: 2.189676555254126

Epoch: 5| Step: 1
Training loss: 2.1971704959869385
Validation loss: 2.1331214827875935

Epoch: 5| Step: 2
Training loss: 1.8619626760482788
Validation loss: 2.1622630370560514

Epoch: 5| Step: 3
Training loss: 2.4542431831359863
Validation loss: 2.19811216990153

Epoch: 5| Step: 4
Training loss: 1.9295085668563843
Validation loss: 2.2194244989784817

Epoch: 5| Step: 5
Training loss: 2.0137369632720947
Validation loss: 2.2223066822175057

Epoch: 5| Step: 6
Training loss: 2.269202470779419
Validation loss: 2.1931619503164805

Epoch: 5| Step: 7
Training loss: 1.5938739776611328
Validation loss: 2.166173552954069

Epoch: 5| Step: 8
Training loss: 1.721268653869629
Validation loss: 2.209001536010414

Epoch: 5| Step: 9
Training loss: 2.069668769836426
Validation loss: 2.2653148763923237

Epoch: 5| Step: 10
Training loss: 1.707745909690857
Validation loss: 2.1648265341276764

Epoch: 307| Step: 0
Training loss: 1.7859232425689697
Validation loss: 2.156773287762878

Epoch: 5| Step: 1
Training loss: 2.0662477016448975
Validation loss: 2.1862245041836976

Epoch: 5| Step: 2
Training loss: 2.2125134468078613
Validation loss: 2.180844404364145

Epoch: 5| Step: 3
Training loss: 1.8000671863555908
Validation loss: 2.177652866609635

Epoch: 5| Step: 4
Training loss: 2.342228412628174
Validation loss: 2.199171725139823

Epoch: 5| Step: 5
Training loss: 1.6657774448394775
Validation loss: 2.1795210325589744

Epoch: 5| Step: 6
Training loss: 1.7725908756256104
Validation loss: 2.1544110646811863

Epoch: 5| Step: 7
Training loss: 1.3899492025375366
Validation loss: 2.1697337140319166

Epoch: 5| Step: 8
Training loss: 2.3276309967041016
Validation loss: 2.1797649962927705

Epoch: 5| Step: 9
Training loss: 2.2022902965545654
Validation loss: 2.1327297251711608

Epoch: 5| Step: 10
Training loss: 2.2391357421875
Validation loss: 2.1769859072982625

Epoch: 308| Step: 0
Training loss: 2.573856830596924
Validation loss: 2.1540618276083343

Epoch: 5| Step: 1
Training loss: 2.305492877960205
Validation loss: 2.112592867625657

Epoch: 5| Step: 2
Training loss: 1.61655592918396
Validation loss: 2.1337866680596465

Epoch: 5| Step: 3
Training loss: 1.7889368534088135
Validation loss: 2.1278066840223087

Epoch: 5| Step: 4
Training loss: 1.8523893356323242
Validation loss: 2.1629943181109685

Epoch: 5| Step: 5
Training loss: 1.1100108623504639
Validation loss: 2.1602375481718328

Epoch: 5| Step: 6
Training loss: 2.4644646644592285
Validation loss: 2.1376617698259253

Epoch: 5| Step: 7
Training loss: 1.6843764781951904
Validation loss: 2.1474232776190645

Epoch: 5| Step: 8
Training loss: 2.366586208343506
Validation loss: 2.1457877979483655

Epoch: 5| Step: 9
Training loss: 2.575687885284424
Validation loss: 2.1083759659080097

Epoch: 5| Step: 10
Training loss: 1.6479768753051758
Validation loss: 2.063120681752441

Epoch: 309| Step: 0
Training loss: 1.6349194049835205
Validation loss: 2.133914268144997

Epoch: 5| Step: 1
Training loss: 2.3717684745788574
Validation loss: 2.1538277287637033

Epoch: 5| Step: 2
Training loss: 1.716139554977417
Validation loss: 2.1598793152839906

Epoch: 5| Step: 3
Training loss: 2.2407145500183105
Validation loss: 2.167467189091508

Epoch: 5| Step: 4
Training loss: 1.8098747730255127
Validation loss: 2.1553627214124127

Epoch: 5| Step: 5
Training loss: 1.5469123125076294
Validation loss: 2.1313008134083082

Epoch: 5| Step: 6
Training loss: 1.9963970184326172
Validation loss: 2.1201490009984663

Epoch: 5| Step: 7
Training loss: 2.1033947467803955
Validation loss: 2.078108079971806

Epoch: 5| Step: 8
Training loss: 2.425814151763916
Validation loss: 2.1277736489490797

Epoch: 5| Step: 9
Training loss: 2.2937965393066406
Validation loss: 2.1710167341334845

Epoch: 5| Step: 10
Training loss: 1.7829923629760742
Validation loss: 2.1433501371773342

Epoch: 310| Step: 0
Training loss: 2.586702346801758
Validation loss: 2.1616690389571653

Epoch: 5| Step: 1
Training loss: 2.369719982147217
Validation loss: 2.1675422012165027

Epoch: 5| Step: 2
Training loss: 1.7329362630844116
Validation loss: 2.187751980238063

Epoch: 5| Step: 3
Training loss: 1.6669566631317139
Validation loss: 2.194619640227287

Epoch: 5| Step: 4
Training loss: 1.6364943981170654
Validation loss: 2.161028495398901

Epoch: 5| Step: 5
Training loss: 1.9427862167358398
Validation loss: 2.1814834481926373

Epoch: 5| Step: 6
Training loss: 2.012509822845459
Validation loss: 2.172964644688432

Epoch: 5| Step: 7
Training loss: 1.8633501529693604
Validation loss: 2.2007620949898996

Epoch: 5| Step: 8
Training loss: 2.315458297729492
Validation loss: 2.197897147106868

Epoch: 5| Step: 9
Training loss: 1.7274200916290283
Validation loss: 2.165891344829272

Epoch: 5| Step: 10
Training loss: 1.9465703964233398
Validation loss: 2.1609879155312814

Epoch: 311| Step: 0
Training loss: 2.085014820098877
Validation loss: 2.1657513239050425

Epoch: 5| Step: 1
Training loss: 2.083350658416748
Validation loss: 2.169333460510418

Epoch: 5| Step: 2
Training loss: 2.0652987957000732
Validation loss: 2.1999564273383028

Epoch: 5| Step: 3
Training loss: 1.9966485500335693
Validation loss: 2.137070817332114

Epoch: 5| Step: 4
Training loss: 2.275836229324341
Validation loss: 2.170811367291276

Epoch: 5| Step: 5
Training loss: 2.1172943115234375
Validation loss: 2.1815651732106365

Epoch: 5| Step: 6
Training loss: 2.2651171684265137
Validation loss: 2.16059922915633

Epoch: 5| Step: 7
Training loss: 1.6996405124664307
Validation loss: 2.2155740120077647

Epoch: 5| Step: 8
Training loss: 2.068695545196533
Validation loss: 2.1315233284427273

Epoch: 5| Step: 9
Training loss: 1.3640934228897095
Validation loss: 2.2389349783620527

Epoch: 5| Step: 10
Training loss: 1.6529321670532227
Validation loss: 2.135517618989432

Epoch: 312| Step: 0
Training loss: 2.8508427143096924
Validation loss: 2.13928073452365

Epoch: 5| Step: 1
Training loss: 1.9049488306045532
Validation loss: 2.128384982385943

Epoch: 5| Step: 2
Training loss: 1.3634401559829712
Validation loss: 2.1544485604891213

Epoch: 5| Step: 3
Training loss: 2.0590243339538574
Validation loss: 2.083432025806878

Epoch: 5| Step: 4
Training loss: 1.7608579397201538
Validation loss: 2.1362384339814544

Epoch: 5| Step: 5
Training loss: 2.3487319946289062
Validation loss: 2.1001656952724663

Epoch: 5| Step: 6
Training loss: 1.8972899913787842
Validation loss: 2.1541916324246313

Epoch: 5| Step: 7
Training loss: 1.9926376342773438
Validation loss: 2.1938463590478383

Epoch: 5| Step: 8
Training loss: 2.2122676372528076
Validation loss: 2.1515520618807886

Epoch: 5| Step: 9
Training loss: 1.5233575105667114
Validation loss: 2.116263363950996

Epoch: 5| Step: 10
Training loss: 2.075223445892334
Validation loss: 2.1262070209749284

Epoch: 313| Step: 0
Training loss: 1.9421707391738892
Validation loss: 2.146003184779998

Epoch: 5| Step: 1
Training loss: 1.26862370967865
Validation loss: 2.0626041043189263

Epoch: 5| Step: 2
Training loss: 1.967970609664917
Validation loss: 2.126704533894857

Epoch: 5| Step: 3
Training loss: 2.362403392791748
Validation loss: 2.147769594705233

Epoch: 5| Step: 4
Training loss: 2.4711318016052246
Validation loss: 2.0889342805390716

Epoch: 5| Step: 5
Training loss: 1.5538043975830078
Validation loss: 2.1497309361734698

Epoch: 5| Step: 6
Training loss: 2.061060667037964
Validation loss: 2.1856161138062835

Epoch: 5| Step: 7
Training loss: 1.948351502418518
Validation loss: 2.200745003197783

Epoch: 5| Step: 8
Training loss: 2.629387378692627
Validation loss: 2.155798694138886

Epoch: 5| Step: 9
Training loss: 1.7440201044082642
Validation loss: 2.1988804519817395

Epoch: 5| Step: 10
Training loss: 2.33273983001709
Validation loss: 2.1381442687844716

Epoch: 314| Step: 0
Training loss: 1.4165149927139282
Validation loss: 2.1729341847922212

Epoch: 5| Step: 1
Training loss: 1.8612279891967773
Validation loss: 2.1602426651985414

Epoch: 5| Step: 2
Training loss: 1.8669464588165283
Validation loss: 2.1679680296169814

Epoch: 5| Step: 3
Training loss: 1.8283264636993408
Validation loss: 2.165347312086372

Epoch: 5| Step: 4
Training loss: 2.5197291374206543
Validation loss: 2.163611913240084

Epoch: 5| Step: 5
Training loss: 1.6003749370574951
Validation loss: 2.138279386745986

Epoch: 5| Step: 6
Training loss: 2.4506030082702637
Validation loss: 2.1612325124843146

Epoch: 5| Step: 7
Training loss: 2.1276259422302246
Validation loss: 2.1806581174173663

Epoch: 5| Step: 8
Training loss: 2.1038849353790283
Validation loss: 2.1797578719354447

Epoch: 5| Step: 9
Training loss: 2.2599031925201416
Validation loss: 2.1761336454781155

Epoch: 5| Step: 10
Training loss: 1.8217947483062744
Validation loss: 2.231559325289983

Epoch: 315| Step: 0
Training loss: 1.973533034324646
Validation loss: 2.1749654739133772

Epoch: 5| Step: 1
Training loss: 1.4170526266098022
Validation loss: 2.1836968698809223

Epoch: 5| Step: 2
Training loss: 2.3474068641662598
Validation loss: 2.1768113310619066

Epoch: 5| Step: 3
Training loss: 1.7508373260498047
Validation loss: 2.1821033852074736

Epoch: 5| Step: 4
Training loss: 1.9122343063354492
Validation loss: 2.2004713114871772

Epoch: 5| Step: 5
Training loss: 2.211668014526367
Validation loss: 2.1289055347442627

Epoch: 5| Step: 6
Training loss: 1.7828118801116943
Validation loss: 2.2047661042982534

Epoch: 5| Step: 7
Training loss: 2.44099497795105
Validation loss: 2.1549827424428796

Epoch: 5| Step: 8
Training loss: 2.375816822052002
Validation loss: 2.1384610001758864

Epoch: 5| Step: 9
Training loss: 1.7433007955551147
Validation loss: 2.1995936439883326

Epoch: 5| Step: 10
Training loss: 1.7160403728485107
Validation loss: 2.1420633151967037

Epoch: 316| Step: 0
Training loss: 2.3900809288024902
Validation loss: 2.160967787106832

Epoch: 5| Step: 1
Training loss: 1.7963666915893555
Validation loss: 2.1912139769523375

Epoch: 5| Step: 2
Training loss: 1.409616231918335
Validation loss: 2.163699121885402

Epoch: 5| Step: 3
Training loss: 2.4832403659820557
Validation loss: 2.186855605853501

Epoch: 5| Step: 4
Training loss: 2.4401628971099854
Validation loss: 2.168757551459856

Epoch: 5| Step: 5
Training loss: 2.309985876083374
Validation loss: 2.168408327205207

Epoch: 5| Step: 6
Training loss: 2.4839107990264893
Validation loss: 2.173829427329443

Epoch: 5| Step: 7
Training loss: 1.8426408767700195
Validation loss: 2.09788086593792

Epoch: 5| Step: 8
Training loss: 1.5928795337677002
Validation loss: 2.1886903214198288

Epoch: 5| Step: 9
Training loss: 1.0203361511230469
Validation loss: 2.1634244649640975

Epoch: 5| Step: 10
Training loss: 2.067086696624756
Validation loss: 2.111531008956253

Epoch: 317| Step: 0
Training loss: 2.138782262802124
Validation loss: 2.1546110799235683

Epoch: 5| Step: 1
Training loss: 1.8348373174667358
Validation loss: 2.1451856551631803

Epoch: 5| Step: 2
Training loss: 2.654529571533203
Validation loss: 2.165485338498187

Epoch: 5| Step: 3
Training loss: 1.9752280712127686
Validation loss: 2.1655631026914044

Epoch: 5| Step: 4
Training loss: 1.95791494846344
Validation loss: 2.165976744826122

Epoch: 5| Step: 5
Training loss: 2.500394105911255
Validation loss: 2.172567944372854

Epoch: 5| Step: 6
Training loss: 1.4308167695999146
Validation loss: 2.132765212366658

Epoch: 5| Step: 7
Training loss: 1.6747115850448608
Validation loss: 2.138594191561463

Epoch: 5| Step: 8
Training loss: 2.057499647140503
Validation loss: 2.1480266624881375

Epoch: 5| Step: 9
Training loss: 1.8280627727508545
Validation loss: 2.1719632507652364

Epoch: 5| Step: 10
Training loss: 1.6387380361557007
Validation loss: 2.136736405793057

Epoch: 318| Step: 0
Training loss: 2.401585578918457
Validation loss: 2.1457609720127557

Epoch: 5| Step: 1
Training loss: 1.862936019897461
Validation loss: 2.163107564372401

Epoch: 5| Step: 2
Training loss: 2.6555984020233154
Validation loss: 2.1208109035286853

Epoch: 5| Step: 3
Training loss: 1.723576307296753
Validation loss: 2.1672240752045826

Epoch: 5| Step: 4
Training loss: 1.3923954963684082
Validation loss: 2.1489678736655944

Epoch: 5| Step: 5
Training loss: 1.6957343816757202
Validation loss: 2.158855909942299

Epoch: 5| Step: 6
Training loss: 2.4962875843048096
Validation loss: 2.1883175693532473

Epoch: 5| Step: 7
Training loss: 1.9128210544586182
Validation loss: 2.1970522249898603

Epoch: 5| Step: 8
Training loss: 1.9870491027832031
Validation loss: 2.195166741648028

Epoch: 5| Step: 9
Training loss: 2.0955042839050293
Validation loss: 2.2445961198499127

Epoch: 5| Step: 10
Training loss: 1.7198972702026367
Validation loss: 2.180051644643148

Epoch: 319| Step: 0
Training loss: 2.1974854469299316
Validation loss: 2.2272037895776893

Epoch: 5| Step: 1
Training loss: 1.5767743587493896
Validation loss: 2.225527055801884

Epoch: 5| Step: 2
Training loss: 1.8807697296142578
Validation loss: 2.1961701044472317

Epoch: 5| Step: 3
Training loss: 2.380847454071045
Validation loss: 2.2015155976818455

Epoch: 5| Step: 4
Training loss: 2.102412700653076
Validation loss: 2.2200582552981634

Epoch: 5| Step: 5
Training loss: 2.1863207817077637
Validation loss: 2.151685678830711

Epoch: 5| Step: 6
Training loss: 2.0220096111297607
Validation loss: 2.1862046359687723

Epoch: 5| Step: 7
Training loss: 2.577110767364502
Validation loss: 2.199762549451602

Epoch: 5| Step: 8
Training loss: 2.199105739593506
Validation loss: 2.1480482650059525

Epoch: 5| Step: 9
Training loss: 1.4159384965896606
Validation loss: 2.2141321064323507

Epoch: 5| Step: 10
Training loss: 1.0840169191360474
Validation loss: 2.179378794085595

Epoch: 320| Step: 0
Training loss: 1.5133893489837646
Validation loss: 2.1889819868149294

Epoch: 5| Step: 1
Training loss: 2.0690860748291016
Validation loss: 2.1630255368448075

Epoch: 5| Step: 2
Training loss: 1.8336970806121826
Validation loss: 2.173736036464732

Epoch: 5| Step: 3
Training loss: 2.347925901412964
Validation loss: 2.146411463778506

Epoch: 5| Step: 4
Training loss: 1.7815887928009033
Validation loss: 2.1551228518127115

Epoch: 5| Step: 5
Training loss: 1.8420026302337646
Validation loss: 2.138641513803954

Epoch: 5| Step: 6
Training loss: 2.34846830368042
Validation loss: 2.1932139781213578

Epoch: 5| Step: 7
Training loss: 2.407186508178711
Validation loss: 2.118302196584722

Epoch: 5| Step: 8
Training loss: 2.0698235034942627
Validation loss: 2.1885776391593357

Epoch: 5| Step: 9
Training loss: 1.8525081872940063
Validation loss: 2.1333498326680993

Epoch: 5| Step: 10
Training loss: 1.7625622749328613
Validation loss: 2.161240336715534

Epoch: 321| Step: 0
Training loss: 2.091127872467041
Validation loss: 2.171424123548692

Epoch: 5| Step: 1
Training loss: 2.5553016662597656
Validation loss: 2.1843977743579495

Epoch: 5| Step: 2
Training loss: 1.639464020729065
Validation loss: 2.150442877123433

Epoch: 5| Step: 3
Training loss: 2.591783046722412
Validation loss: 2.1680555676901214

Epoch: 5| Step: 4
Training loss: 1.450249433517456
Validation loss: 2.169581492741903

Epoch: 5| Step: 5
Training loss: 1.853817343711853
Validation loss: 2.1585145201734317

Epoch: 5| Step: 6
Training loss: 1.8965059518814087
Validation loss: 2.150436137312202

Epoch: 5| Step: 7
Training loss: 2.1809983253479004
Validation loss: 2.138414159897835

Epoch: 5| Step: 8
Training loss: 1.345165491104126
Validation loss: 2.176736262536818

Epoch: 5| Step: 9
Training loss: 2.2319881916046143
Validation loss: 2.1818230895585913

Epoch: 5| Step: 10
Training loss: 1.5216275453567505
Validation loss: 2.149743867176835

Epoch: 322| Step: 0
Training loss: 2.0966544151306152
Validation loss: 2.1904227631066435

Epoch: 5| Step: 1
Training loss: 1.5954490900039673
Validation loss: 2.15373005021003

Epoch: 5| Step: 2
Training loss: 2.418917417526245
Validation loss: 2.1571272252708353

Epoch: 5| Step: 3
Training loss: 2.2706406116485596
Validation loss: 2.1324148588283087

Epoch: 5| Step: 4
Training loss: 1.3743784427642822
Validation loss: 2.1714761744263353

Epoch: 5| Step: 5
Training loss: 2.0306787490844727
Validation loss: 2.1750782305194485

Epoch: 5| Step: 6
Training loss: 1.592146873474121
Validation loss: 2.1698825641344954

Epoch: 5| Step: 7
Training loss: 1.6661770343780518
Validation loss: 2.130437543315272

Epoch: 5| Step: 8
Training loss: 2.8933918476104736
Validation loss: 2.1193684608705583

Epoch: 5| Step: 9
Training loss: 1.8505783081054688
Validation loss: 2.1695022160007107

Epoch: 5| Step: 10
Training loss: 1.7710351943969727
Validation loss: 2.153366432395033

Epoch: 323| Step: 0
Training loss: 1.8357433080673218
Validation loss: 2.1685141722361245

Epoch: 5| Step: 1
Training loss: 2.5096545219421387
Validation loss: 2.115945382784772

Epoch: 5| Step: 2
Training loss: 2.3851046562194824
Validation loss: 2.1848387513109433

Epoch: 5| Step: 3
Training loss: 1.5113182067871094
Validation loss: 2.127184893495293

Epoch: 5| Step: 4
Training loss: 1.7207176685333252
Validation loss: 2.1542449920408187

Epoch: 5| Step: 5
Training loss: 2.25317120552063
Validation loss: 2.171741215131616

Epoch: 5| Step: 6
Training loss: 1.5514333248138428
Validation loss: 2.159737281901862

Epoch: 5| Step: 7
Training loss: 1.8351142406463623
Validation loss: 2.1261570325461765

Epoch: 5| Step: 8
Training loss: 1.9268165826797485
Validation loss: 2.1673119042509343

Epoch: 5| Step: 9
Training loss: 2.2440881729125977
Validation loss: 2.1929441190535024

Epoch: 5| Step: 10
Training loss: 2.162776470184326
Validation loss: 2.1374334032817552

Epoch: 324| Step: 0
Training loss: 2.0164151191711426
Validation loss: 2.1767805827561246

Epoch: 5| Step: 1
Training loss: 1.8080371618270874
Validation loss: 2.1700009479317615

Epoch: 5| Step: 2
Training loss: 1.9252017736434937
Validation loss: 2.153970620965445

Epoch: 5| Step: 3
Training loss: 1.6675199270248413
Validation loss: 2.133409615485899

Epoch: 5| Step: 4
Training loss: 2.4646077156066895
Validation loss: 2.1388888923070764

Epoch: 5| Step: 5
Training loss: 1.7041828632354736
Validation loss: 2.1159595904811734

Epoch: 5| Step: 6
Training loss: 1.7511188983917236
Validation loss: 2.137067989636493

Epoch: 5| Step: 7
Training loss: 2.3444268703460693
Validation loss: 2.160747984404205

Epoch: 5| Step: 8
Training loss: 2.3284289836883545
Validation loss: 2.131868420108672

Epoch: 5| Step: 9
Training loss: 1.4272226095199585
Validation loss: 2.1682267112116658

Epoch: 5| Step: 10
Training loss: 2.222815990447998
Validation loss: 2.1338587243069886

Epoch: 325| Step: 0
Training loss: 2.242521047592163
Validation loss: 2.121492284600453

Epoch: 5| Step: 1
Training loss: 1.593408226966858
Validation loss: 2.1716013685349496

Epoch: 5| Step: 2
Training loss: 1.522613525390625
Validation loss: 2.142403070644666

Epoch: 5| Step: 3
Training loss: 2.075934886932373
Validation loss: 2.1637076998269684

Epoch: 5| Step: 4
Training loss: 1.7828155755996704
Validation loss: 2.1892167688697897

Epoch: 5| Step: 5
Training loss: 2.087123394012451
Validation loss: 2.18532052347737

Epoch: 5| Step: 6
Training loss: 2.735220432281494
Validation loss: 2.141231595828969

Epoch: 5| Step: 7
Training loss: 1.7560924291610718
Validation loss: 2.163586349897487

Epoch: 5| Step: 8
Training loss: 1.7278245687484741
Validation loss: 2.1978030191954745

Epoch: 5| Step: 9
Training loss: 1.588987112045288
Validation loss: 2.165763921635125

Epoch: 5| Step: 10
Training loss: 2.6685824394226074
Validation loss: 2.1902567904482604

Epoch: 326| Step: 0
Training loss: 1.71694815158844
Validation loss: 2.1642535386546964

Epoch: 5| Step: 1
Training loss: 1.904006004333496
Validation loss: 2.186025619506836

Epoch: 5| Step: 2
Training loss: 2.361192226409912
Validation loss: 2.1692480502590055

Epoch: 5| Step: 3
Training loss: 1.8376953601837158
Validation loss: 2.1692927037515948

Epoch: 5| Step: 4
Training loss: 2.69718337059021
Validation loss: 2.1934797251096336

Epoch: 5| Step: 5
Training loss: 1.7597787380218506
Validation loss: 2.1960579733694754

Epoch: 5| Step: 6
Training loss: 1.512428879737854
Validation loss: 2.2077202002207437

Epoch: 5| Step: 7
Training loss: 1.746291160583496
Validation loss: 2.148791718226607

Epoch: 5| Step: 8
Training loss: 2.2469286918640137
Validation loss: 2.1953324425605034

Epoch: 5| Step: 9
Training loss: 2.02243971824646
Validation loss: 2.15004030863444

Epoch: 5| Step: 10
Training loss: 1.6565054655075073
Validation loss: 2.1428604100340154

Epoch: 327| Step: 0
Training loss: 2.3464255332946777
Validation loss: 2.137286150327293

Epoch: 5| Step: 1
Training loss: 2.199413776397705
Validation loss: 2.152500041069523

Epoch: 5| Step: 2
Training loss: 1.8506332635879517
Validation loss: 2.12385650860366

Epoch: 5| Step: 3
Training loss: 2.17571759223938
Validation loss: 2.1757159720184984

Epoch: 5| Step: 4
Training loss: 2.318556547164917
Validation loss: 2.1796688495143766

Epoch: 5| Step: 5
Training loss: 1.6123149394989014
Validation loss: 2.1536818140296528

Epoch: 5| Step: 6
Training loss: 1.5883674621582031
Validation loss: 2.166122656996532

Epoch: 5| Step: 7
Training loss: 2.2546019554138184
Validation loss: 2.16785962863635

Epoch: 5| Step: 8
Training loss: 1.5301693677902222
Validation loss: 2.13213607060012

Epoch: 5| Step: 9
Training loss: 1.7019712924957275
Validation loss: 2.1458053537594375

Epoch: 5| Step: 10
Training loss: 2.189239263534546
Validation loss: 2.141702862196071

Epoch: 328| Step: 0
Training loss: 2.2190022468566895
Validation loss: 2.156652545416227

Epoch: 5| Step: 1
Training loss: 2.3775055408477783
Validation loss: 2.1400535542477845

Epoch: 5| Step: 2
Training loss: 2.3338592052459717
Validation loss: 2.1179236878630934

Epoch: 5| Step: 3
Training loss: 2.2342529296875
Validation loss: 2.152215128303856

Epoch: 5| Step: 4
Training loss: 1.64718496799469
Validation loss: 2.13475400658064

Epoch: 5| Step: 5
Training loss: 1.779950499534607
Validation loss: 2.1292607181815693

Epoch: 5| Step: 6
Training loss: 1.6549692153930664
Validation loss: 2.157531524217257

Epoch: 5| Step: 7
Training loss: 1.885744333267212
Validation loss: 2.156694978796026

Epoch: 5| Step: 8
Training loss: 1.6178966760635376
Validation loss: 2.191178925575749

Epoch: 5| Step: 9
Training loss: 1.8712676763534546
Validation loss: 2.159150344069286

Epoch: 5| Step: 10
Training loss: 1.7531472444534302
Validation loss: 2.146056831523936

Epoch: 329| Step: 0
Training loss: 1.7071311473846436
Validation loss: 2.151251282743228

Epoch: 5| Step: 1
Training loss: 2.1292595863342285
Validation loss: 2.1381758272006945

Epoch: 5| Step: 2
Training loss: 2.22829270362854
Validation loss: 2.164376554950591

Epoch: 5| Step: 3
Training loss: 2.1521527767181396
Validation loss: 2.155671324781192

Epoch: 5| Step: 4
Training loss: 1.8473167419433594
Validation loss: 2.1655028866183375

Epoch: 5| Step: 5
Training loss: 2.547752857208252
Validation loss: 2.203624565114257

Epoch: 5| Step: 6
Training loss: 1.7437394857406616
Validation loss: 2.1737421084475774

Epoch: 5| Step: 7
Training loss: 1.8301814794540405
Validation loss: 2.192023524674036

Epoch: 5| Step: 8
Training loss: 1.6386089324951172
Validation loss: 2.172735203978836

Epoch: 5| Step: 9
Training loss: 1.8218028545379639
Validation loss: 2.1441719429467314

Epoch: 5| Step: 10
Training loss: 2.036672592163086
Validation loss: 2.164852939626222

Epoch: 330| Step: 0
Training loss: 2.595046043395996
Validation loss: 2.179780262772755

Epoch: 5| Step: 1
Training loss: 1.4260576963424683
Validation loss: 2.2232407575012534

Epoch: 5| Step: 2
Training loss: 1.6874170303344727
Validation loss: 2.164394550426032

Epoch: 5| Step: 3
Training loss: 1.6814044713974
Validation loss: 2.138210524794876

Epoch: 5| Step: 4
Training loss: 1.6407301425933838
Validation loss: 2.183784948882236

Epoch: 5| Step: 5
Training loss: 1.611620545387268
Validation loss: 2.1362235084656747

Epoch: 5| Step: 6
Training loss: 2.217305898666382
Validation loss: 2.163912906441637

Epoch: 5| Step: 7
Training loss: 2.079524278640747
Validation loss: 2.139244515408752

Epoch: 5| Step: 8
Training loss: 2.5955405235290527
Validation loss: 2.1710105301231466

Epoch: 5| Step: 9
Training loss: 2.124089002609253
Validation loss: 2.150756347563959

Epoch: 5| Step: 10
Training loss: 1.6488572359085083
Validation loss: 2.1419909026033137

Epoch: 331| Step: 0
Training loss: 1.310943365097046
Validation loss: 2.1803253901902067

Epoch: 5| Step: 1
Training loss: 1.8876991271972656
Validation loss: 2.0988579911570393

Epoch: 5| Step: 2
Training loss: 2.1134438514709473
Validation loss: 2.136168201764425

Epoch: 5| Step: 3
Training loss: 1.925977349281311
Validation loss: 2.1476078315447737

Epoch: 5| Step: 4
Training loss: 1.543778419494629
Validation loss: 2.154683445089607

Epoch: 5| Step: 5
Training loss: 1.8884668350219727
Validation loss: 2.170055503486305

Epoch: 5| Step: 6
Training loss: 1.9785091876983643
Validation loss: 2.1535868670350764

Epoch: 5| Step: 7
Training loss: 2.5957400798797607
Validation loss: 2.1706316932555167

Epoch: 5| Step: 8
Training loss: 2.207533121109009
Validation loss: 2.1209636708741546

Epoch: 5| Step: 9
Training loss: 2.3034427165985107
Validation loss: 2.1518709698031024

Epoch: 5| Step: 10
Training loss: 1.7089948654174805
Validation loss: 2.137794692029235

Epoch: 332| Step: 0
Training loss: 1.9597508907318115
Validation loss: 2.162691480369978

Epoch: 5| Step: 1
Training loss: 1.989200234413147
Validation loss: 2.1431573411469818

Epoch: 5| Step: 2
Training loss: 1.91634202003479
Validation loss: 2.1099530163631646

Epoch: 5| Step: 3
Training loss: 2.09379243850708
Validation loss: 2.157952864964803

Epoch: 5| Step: 4
Training loss: 2.2202014923095703
Validation loss: 2.1987625911671627

Epoch: 5| Step: 5
Training loss: 1.8955419063568115
Validation loss: 2.1452141474652033

Epoch: 5| Step: 6
Training loss: 1.6075756549835205
Validation loss: 2.150905309184905

Epoch: 5| Step: 7
Training loss: 2.2104907035827637
Validation loss: 2.18239039374936

Epoch: 5| Step: 8
Training loss: 1.762243628501892
Validation loss: 2.1554647953279558

Epoch: 5| Step: 9
Training loss: 2.44529390335083
Validation loss: 2.122749804168619

Epoch: 5| Step: 10
Training loss: 1.3601298332214355
Validation loss: 2.1321667163602767

Epoch: 333| Step: 0
Training loss: 2.2841997146606445
Validation loss: 2.125991440588428

Epoch: 5| Step: 1
Training loss: 2.4101569652557373
Validation loss: 2.129312628058977

Epoch: 5| Step: 2
Training loss: 2.3041932582855225
Validation loss: 2.130206795148952

Epoch: 5| Step: 3
Training loss: 1.7687867879867554
Validation loss: 2.14522829363423

Epoch: 5| Step: 4
Training loss: 1.5452508926391602
Validation loss: 2.1597862858926096

Epoch: 5| Step: 5
Training loss: 1.6279293298721313
Validation loss: 2.135013541867656

Epoch: 5| Step: 6
Training loss: 1.8441272974014282
Validation loss: 2.1544264439613587

Epoch: 5| Step: 7
Training loss: 1.6224277019500732
Validation loss: 2.185718014676084

Epoch: 5| Step: 8
Training loss: 1.9894205331802368
Validation loss: 2.2117534927142564

Epoch: 5| Step: 9
Training loss: 2.249563455581665
Validation loss: 2.180671408612241

Epoch: 5| Step: 10
Training loss: 1.991694450378418
Validation loss: 2.156886992915984

Epoch: 334| Step: 0
Training loss: 2.088536024093628
Validation loss: 2.1891882957950717

Epoch: 5| Step: 1
Training loss: 1.3687728643417358
Validation loss: 2.1811354185945246

Epoch: 5| Step: 2
Training loss: 1.7506201267242432
Validation loss: 2.193238567280513

Epoch: 5| Step: 3
Training loss: 3.206547260284424
Validation loss: 2.194318071488411

Epoch: 5| Step: 4
Training loss: 1.582599401473999
Validation loss: 2.1949641473831667

Epoch: 5| Step: 5
Training loss: 1.934258222579956
Validation loss: 2.193629426340903

Epoch: 5| Step: 6
Training loss: 1.814126968383789
Validation loss: 2.187517417374478

Epoch: 5| Step: 7
Training loss: 2.446373701095581
Validation loss: 2.1607962090481996

Epoch: 5| Step: 8
Training loss: 1.7106151580810547
Validation loss: 2.2191714189385854

Epoch: 5| Step: 9
Training loss: 1.6062300205230713
Validation loss: 2.179553149848856

Epoch: 5| Step: 10
Training loss: 1.6354520320892334
Validation loss: 2.216590944156852

Epoch: 335| Step: 0
Training loss: 1.3342769145965576
Validation loss: 2.1447078874034267

Epoch: 5| Step: 1
Training loss: 2.064150810241699
Validation loss: 2.1380668019735687

Epoch: 5| Step: 2
Training loss: 1.719244360923767
Validation loss: 2.1860961401334373

Epoch: 5| Step: 3
Training loss: 1.6407874822616577
Validation loss: 2.1518283454320764

Epoch: 5| Step: 4
Training loss: 2.4149961471557617
Validation loss: 2.1664416200371197

Epoch: 5| Step: 5
Training loss: 1.3492947816848755
Validation loss: 2.1241735386592087

Epoch: 5| Step: 6
Training loss: 2.6503100395202637
Validation loss: 2.1598142782847085

Epoch: 5| Step: 7
Training loss: 1.8640062808990479
Validation loss: 2.1543826697975077

Epoch: 5| Step: 8
Training loss: 2.0655720233917236
Validation loss: 2.186542826314126

Epoch: 5| Step: 9
Training loss: 2.0457258224487305
Validation loss: 2.154057438655566

Epoch: 5| Step: 10
Training loss: 2.3898448944091797
Validation loss: 2.1695500484076877

Epoch: 336| Step: 0
Training loss: 1.5587215423583984
Validation loss: 2.1767870969669794

Epoch: 5| Step: 1
Training loss: 1.897080421447754
Validation loss: 2.1676786638075307

Epoch: 5| Step: 2
Training loss: 2.591479778289795
Validation loss: 2.146974653326055

Epoch: 5| Step: 3
Training loss: 2.1740787029266357
Validation loss: 2.099389365924302

Epoch: 5| Step: 4
Training loss: 2.4168686866760254
Validation loss: 2.1716276214968775

Epoch: 5| Step: 5
Training loss: 1.6147865056991577
Validation loss: 2.180333965568132

Epoch: 5| Step: 6
Training loss: 1.7921850681304932
Validation loss: 2.173781589795184

Epoch: 5| Step: 7
Training loss: 2.31132173538208
Validation loss: 2.17649015303581

Epoch: 5| Step: 8
Training loss: 1.9628114700317383
Validation loss: 2.1775005863558863

Epoch: 5| Step: 9
Training loss: 2.1755924224853516
Validation loss: 2.160773523392216

Epoch: 5| Step: 10
Training loss: 0.9835524559020996
Validation loss: 2.1919102617489394

Epoch: 337| Step: 0
Training loss: 2.3403050899505615
Validation loss: 2.1695728635275238

Epoch: 5| Step: 1
Training loss: 1.3875715732574463
Validation loss: 2.129895974231023

Epoch: 5| Step: 2
Training loss: 2.193871021270752
Validation loss: 2.1958228003594185

Epoch: 5| Step: 3
Training loss: 2.538194417953491
Validation loss: 2.1603649675205188

Epoch: 5| Step: 4
Training loss: 1.6663658618927002
Validation loss: 2.1848142480337494

Epoch: 5| Step: 5
Training loss: 2.5371317863464355
Validation loss: 2.1883605526339625

Epoch: 5| Step: 6
Training loss: 2.2727763652801514
Validation loss: 2.172861965753699

Epoch: 5| Step: 7
Training loss: 1.9944759607315063
Validation loss: 2.1697013224324873

Epoch: 5| Step: 8
Training loss: 1.8479337692260742
Validation loss: 2.2582008915562786

Epoch: 5| Step: 9
Training loss: 1.42337965965271
Validation loss: 2.164009481348017

Epoch: 5| Step: 10
Training loss: 1.1614532470703125
Validation loss: 2.167058895992976

Epoch: 338| Step: 0
Training loss: 2.010660171508789
Validation loss: 2.166229674893041

Epoch: 5| Step: 1
Training loss: 2.194159984588623
Validation loss: 2.1932419807680192

Epoch: 5| Step: 2
Training loss: 2.123342990875244
Validation loss: 2.1299708568921654

Epoch: 5| Step: 3
Training loss: 1.8710300922393799
Validation loss: 2.197203928424466

Epoch: 5| Step: 4
Training loss: 2.3657310009002686
Validation loss: 2.1750754989603514

Epoch: 5| Step: 5
Training loss: 1.845414400100708
Validation loss: 2.1991978563288206

Epoch: 5| Step: 6
Training loss: 1.5693336725234985
Validation loss: 2.18942355596891

Epoch: 5| Step: 7
Training loss: 1.767059326171875
Validation loss: 2.127593417321482

Epoch: 5| Step: 8
Training loss: 1.678166151046753
Validation loss: 2.1399206628081617

Epoch: 5| Step: 9
Training loss: 2.2665505409240723
Validation loss: 2.1479651389583463

Epoch: 5| Step: 10
Training loss: 2.0921616554260254
Validation loss: 2.130248495327529

Epoch: 339| Step: 0
Training loss: 2.1381468772888184
Validation loss: 2.16821059103935

Epoch: 5| Step: 1
Training loss: 1.4408940076828003
Validation loss: 2.118714742763068

Epoch: 5| Step: 2
Training loss: 2.165850877761841
Validation loss: 2.1264680867554038

Epoch: 5| Step: 3
Training loss: 2.3285346031188965
Validation loss: 2.1564675543897893

Epoch: 5| Step: 4
Training loss: 2.4063422679901123
Validation loss: 2.110135027157363

Epoch: 5| Step: 5
Training loss: 1.5039567947387695
Validation loss: 2.1548185553601993

Epoch: 5| Step: 6
Training loss: 1.425629734992981
Validation loss: 2.1235205832348076

Epoch: 5| Step: 7
Training loss: 2.4145805835723877
Validation loss: 2.091691570897256

Epoch: 5| Step: 8
Training loss: 1.6289314031600952
Validation loss: 2.1089667684288433

Epoch: 5| Step: 9
Training loss: 2.0992112159729004
Validation loss: 2.1451613659499795

Epoch: 5| Step: 10
Training loss: 2.181217908859253
Validation loss: 2.161458033387379

Epoch: 340| Step: 0
Training loss: 2.141904830932617
Validation loss: 2.176208024383873

Epoch: 5| Step: 1
Training loss: 2.0851781368255615
Validation loss: 2.1705556877197756

Epoch: 5| Step: 2
Training loss: 1.6948448419570923
Validation loss: 2.1640240940996396

Epoch: 5| Step: 3
Training loss: 2.2805140018463135
Validation loss: 2.2108327137526644

Epoch: 5| Step: 4
Training loss: 2.4314732551574707
Validation loss: 2.1534675334089544

Epoch: 5| Step: 5
Training loss: 1.3302103281021118
Validation loss: 2.1690668072751773

Epoch: 5| Step: 6
Training loss: 1.5947641134262085
Validation loss: 2.168080691368349

Epoch: 5| Step: 7
Training loss: 2.0148861408233643
Validation loss: 2.1617193170773086

Epoch: 5| Step: 8
Training loss: 1.740335464477539
Validation loss: 2.1331137931475075

Epoch: 5| Step: 9
Training loss: 2.186574697494507
Validation loss: 2.173255125681559

Epoch: 5| Step: 10
Training loss: 1.9416589736938477
Validation loss: 2.1085297933188816

Epoch: 341| Step: 0
Training loss: 1.8412765264511108
Validation loss: 2.1616972825860463

Epoch: 5| Step: 1
Training loss: 1.964464783668518
Validation loss: 2.174844447002616

Epoch: 5| Step: 2
Training loss: 2.391484260559082
Validation loss: 2.154654197795417

Epoch: 5| Step: 3
Training loss: 1.589929461479187
Validation loss: 2.1763514805865545

Epoch: 5| Step: 4
Training loss: 1.6845028400421143
Validation loss: 2.2210479385109356

Epoch: 5| Step: 5
Training loss: 2.61468243598938
Validation loss: 2.1346438623243764

Epoch: 5| Step: 6
Training loss: 1.7055761814117432
Validation loss: 2.1729148177690405

Epoch: 5| Step: 7
Training loss: 1.7120224237442017
Validation loss: 2.157914984610773

Epoch: 5| Step: 8
Training loss: 2.501586437225342
Validation loss: 2.174258029589089

Epoch: 5| Step: 9
Training loss: 1.5889976024627686
Validation loss: 2.194166825663659

Epoch: 5| Step: 10
Training loss: 1.5488989353179932
Validation loss: 2.1556486416888494

Epoch: 342| Step: 0
Training loss: 1.757720708847046
Validation loss: 2.0976771141893122

Epoch: 5| Step: 1
Training loss: 1.8764781951904297
Validation loss: 2.1758587539836927

Epoch: 5| Step: 2
Training loss: 1.993292212486267
Validation loss: 2.1853510154190885

Epoch: 5| Step: 3
Training loss: 1.9792413711547852
Validation loss: 2.1378849116704797

Epoch: 5| Step: 4
Training loss: 1.5150387287139893
Validation loss: 2.157243315891553

Epoch: 5| Step: 5
Training loss: 1.5805628299713135
Validation loss: 2.1670060491049163

Epoch: 5| Step: 6
Training loss: 2.4404234886169434
Validation loss: 2.1535798118960474

Epoch: 5| Step: 7
Training loss: 1.5682493448257446
Validation loss: 2.1483209979149605

Epoch: 5| Step: 8
Training loss: 2.317383050918579
Validation loss: 2.1196113953026394

Epoch: 5| Step: 9
Training loss: 1.799246072769165
Validation loss: 2.070576629331035

Epoch: 5| Step: 10
Training loss: 2.4827613830566406
Validation loss: 2.0825604956637145

Epoch: 343| Step: 0
Training loss: 1.6052076816558838
Validation loss: 2.154732140161658

Epoch: 5| Step: 1
Training loss: 2.200636386871338
Validation loss: 2.115393146391838

Epoch: 5| Step: 2
Training loss: 1.9377319812774658
Validation loss: 2.13732208231444

Epoch: 5| Step: 3
Training loss: 2.1095988750457764
Validation loss: 2.091538352351035

Epoch: 5| Step: 4
Training loss: 2.6273140907287598
Validation loss: 2.152383232629427

Epoch: 5| Step: 5
Training loss: 1.3546473979949951
Validation loss: 2.105380409507341

Epoch: 5| Step: 6
Training loss: 2.3964505195617676
Validation loss: 2.1428521320384037

Epoch: 5| Step: 7
Training loss: 1.9049491882324219
Validation loss: 2.130029542471773

Epoch: 5| Step: 8
Training loss: 1.6879581212997437
Validation loss: 2.14647009295802

Epoch: 5| Step: 9
Training loss: 1.3741767406463623
Validation loss: 2.1382582726017123

Epoch: 5| Step: 10
Training loss: 2.151799201965332
Validation loss: 2.153662189360588

Epoch: 344| Step: 0
Training loss: 1.7665789127349854
Validation loss: 2.1308804301805395

Epoch: 5| Step: 1
Training loss: 2.2559802532196045
Validation loss: 2.15848986564144

Epoch: 5| Step: 2
Training loss: 2.187912702560425
Validation loss: 2.126783635026665

Epoch: 5| Step: 3
Training loss: 2.451828956604004
Validation loss: 2.157492437670308

Epoch: 5| Step: 4
Training loss: 1.5573643445968628
Validation loss: 2.156925288579797

Epoch: 5| Step: 5
Training loss: 1.9067115783691406
Validation loss: 2.1614915414523055

Epoch: 5| Step: 6
Training loss: 1.4123613834381104
Validation loss: 2.179269685540148

Epoch: 5| Step: 7
Training loss: 1.4327462911605835
Validation loss: 2.1518205763191305

Epoch: 5| Step: 8
Training loss: 2.247661828994751
Validation loss: 2.1966702848352413

Epoch: 5| Step: 9
Training loss: 2.074263334274292
Validation loss: 2.196495258679954

Epoch: 5| Step: 10
Training loss: 1.655337929725647
Validation loss: 2.1593210158809537

Epoch: 345| Step: 0
Training loss: 2.7228245735168457
Validation loss: 2.147740405092957

Epoch: 5| Step: 1
Training loss: 1.0980345010757446
Validation loss: 2.2015087758341143

Epoch: 5| Step: 2
Training loss: 1.5808358192443848
Validation loss: 2.1864686755723852

Epoch: 5| Step: 3
Training loss: 2.0534026622772217
Validation loss: 2.1833660474387546

Epoch: 5| Step: 4
Training loss: 2.378232955932617
Validation loss: 2.19006162048668

Epoch: 5| Step: 5
Training loss: 1.798621416091919
Validation loss: 2.153679996408442

Epoch: 5| Step: 6
Training loss: 2.171224594116211
Validation loss: 2.192897440284811

Epoch: 5| Step: 7
Training loss: 2.1250805854797363
Validation loss: 2.1555160707043064

Epoch: 5| Step: 8
Training loss: 1.8388277292251587
Validation loss: 2.1859390902262863

Epoch: 5| Step: 9
Training loss: 1.9416770935058594
Validation loss: 2.1724871179108978

Epoch: 5| Step: 10
Training loss: 1.8364320993423462
Validation loss: 2.248178291064437

Epoch: 346| Step: 0
Training loss: 2.5555739402770996
Validation loss: 2.175564612111738

Epoch: 5| Step: 1
Training loss: 1.7946021556854248
Validation loss: 2.1295928314167965

Epoch: 5| Step: 2
Training loss: 2.3586411476135254
Validation loss: 2.1585688693549043

Epoch: 5| Step: 3
Training loss: 2.1687934398651123
Validation loss: 2.153436496693601

Epoch: 5| Step: 4
Training loss: 1.1369317770004272
Validation loss: 2.114589706543953

Epoch: 5| Step: 5
Training loss: 1.4654490947723389
Validation loss: 2.158033732445009

Epoch: 5| Step: 6
Training loss: 1.8662172555923462
Validation loss: 2.1002359569713636

Epoch: 5| Step: 7
Training loss: 2.3116583824157715
Validation loss: 2.15750902698886

Epoch: 5| Step: 8
Training loss: 1.8944896459579468
Validation loss: 2.117004745750017

Epoch: 5| Step: 9
Training loss: 1.9347187280654907
Validation loss: 2.0450869298750356

Epoch: 5| Step: 10
Training loss: 1.704309105873108
Validation loss: 2.158940112718972

Epoch: 347| Step: 0
Training loss: 2.3823776245117188
Validation loss: 2.1400221009408273

Epoch: 5| Step: 1
Training loss: 1.512620449066162
Validation loss: 2.141702313576975

Epoch: 5| Step: 2
Training loss: 2.2625892162323
Validation loss: 2.120734521137771

Epoch: 5| Step: 3
Training loss: 1.7615735530853271
Validation loss: 2.1438887055202196

Epoch: 5| Step: 4
Training loss: 2.00770902633667
Validation loss: 2.1040478560232345

Epoch: 5| Step: 5
Training loss: 1.8516899347305298
Validation loss: 2.1625715378792054

Epoch: 5| Step: 6
Training loss: 1.7727291584014893
Validation loss: 2.1461045716398504

Epoch: 5| Step: 7
Training loss: 2.1832022666931152
Validation loss: 2.162590140937477

Epoch: 5| Step: 8
Training loss: 2.281616687774658
Validation loss: 2.1560530944537093

Epoch: 5| Step: 9
Training loss: 1.7293922901153564
Validation loss: 2.1739414520161127

Epoch: 5| Step: 10
Training loss: 1.1232905387878418
Validation loss: 2.189231793085734

Epoch: 348| Step: 0
Training loss: 1.9519497156143188
Validation loss: 2.172397469961515

Epoch: 5| Step: 1
Training loss: 1.6288793087005615
Validation loss: 2.1726247533675163

Epoch: 5| Step: 2
Training loss: 2.120227336883545
Validation loss: 2.1592313102496568

Epoch: 5| Step: 3
Training loss: 1.4732027053833008
Validation loss: 2.1485792436907367

Epoch: 5| Step: 4
Training loss: 1.2347275018692017
Validation loss: 2.1885536947558

Epoch: 5| Step: 5
Training loss: 2.504621744155884
Validation loss: 2.123459526287612

Epoch: 5| Step: 6
Training loss: 2.208622694015503
Validation loss: 2.190067750151439

Epoch: 5| Step: 7
Training loss: 1.838547945022583
Validation loss: 2.1774101359869844

Epoch: 5| Step: 8
Training loss: 2.4228551387786865
Validation loss: 2.1895249812833724

Epoch: 5| Step: 9
Training loss: 1.5349947214126587
Validation loss: 2.1874124516722975

Epoch: 5| Step: 10
Training loss: 2.3586080074310303
Validation loss: 2.169234509109169

Epoch: 349| Step: 0
Training loss: 1.7651952505111694
Validation loss: 2.1741903494763117

Epoch: 5| Step: 1
Training loss: 1.5616719722747803
Validation loss: 2.169226328531901

Epoch: 5| Step: 2
Training loss: 2.1381020545959473
Validation loss: 2.16994579761259

Epoch: 5| Step: 3
Training loss: 2.4331588745117188
Validation loss: 2.148854442822036

Epoch: 5| Step: 4
Training loss: 1.698290467262268
Validation loss: 2.1272576060346378

Epoch: 5| Step: 5
Training loss: 1.9671752452850342
Validation loss: 2.109590353504304

Epoch: 5| Step: 6
Training loss: 2.219977855682373
Validation loss: 2.1454573382613478

Epoch: 5| Step: 7
Training loss: 2.3498916625976562
Validation loss: 2.160469288467079

Epoch: 5| Step: 8
Training loss: 1.2267080545425415
Validation loss: 2.153131649058352

Epoch: 5| Step: 9
Training loss: 2.1183502674102783
Validation loss: 2.1245067798963158

Epoch: 5| Step: 10
Training loss: 1.5383491516113281
Validation loss: 2.1345907270267444

Epoch: 350| Step: 0
Training loss: 1.9718945026397705
Validation loss: 2.1522076591368644

Epoch: 5| Step: 1
Training loss: 1.488022804260254
Validation loss: 2.1472848128247004

Epoch: 5| Step: 2
Training loss: 1.707707166671753
Validation loss: 2.097738314700383

Epoch: 5| Step: 3
Training loss: 1.7579030990600586
Validation loss: 2.1621282639042025

Epoch: 5| Step: 4
Training loss: 1.627393126487732
Validation loss: 2.17614842743002

Epoch: 5| Step: 5
Training loss: 1.788315773010254
Validation loss: 2.11914582919049

Epoch: 5| Step: 6
Training loss: 2.481966733932495
Validation loss: 2.193639891121977

Epoch: 5| Step: 7
Training loss: 1.9036457538604736
Validation loss: 2.176934975449757

Epoch: 5| Step: 8
Training loss: 2.4950356483459473
Validation loss: 2.1287095033994285

Epoch: 5| Step: 9
Training loss: 1.7093963623046875
Validation loss: 2.1853011884996967

Epoch: 5| Step: 10
Training loss: 2.078218936920166
Validation loss: 2.169701909506193

Epoch: 351| Step: 0
Training loss: 1.9098514318466187
Validation loss: 2.096402188783051

Epoch: 5| Step: 1
Training loss: 1.484626293182373
Validation loss: 2.136465867360433

Epoch: 5| Step: 2
Training loss: 2.187077045440674
Validation loss: 2.134422168936781

Epoch: 5| Step: 3
Training loss: 1.71505606174469
Validation loss: 2.1093834164322063

Epoch: 5| Step: 4
Training loss: 2.5971322059631348
Validation loss: 2.1092806336700276

Epoch: 5| Step: 5
Training loss: 1.5788325071334839
Validation loss: 2.123863363778719

Epoch: 5| Step: 6
Training loss: 2.084841251373291
Validation loss: 2.1471019496199903

Epoch: 5| Step: 7
Training loss: 2.303046226501465
Validation loss: 2.2157638995878157

Epoch: 5| Step: 8
Training loss: 1.839798927307129
Validation loss: 2.1445261701460807

Epoch: 5| Step: 9
Training loss: 1.8899872303009033
Validation loss: 2.171483316729146

Epoch: 5| Step: 10
Training loss: 1.8654204607009888
Validation loss: 2.163703890256984

Epoch: 352| Step: 0
Training loss: 1.957162857055664
Validation loss: 2.1603423895374423

Epoch: 5| Step: 1
Training loss: 2.196481943130493
Validation loss: 2.1284502629310853

Epoch: 5| Step: 2
Training loss: 1.9080969095230103
Validation loss: 2.143004266164636

Epoch: 5| Step: 3
Training loss: 2.3467156887054443
Validation loss: 2.164295611842986

Epoch: 5| Step: 4
Training loss: 2.1773018836975098
Validation loss: 2.1348123973415745

Epoch: 5| Step: 5
Training loss: 1.9455486536026
Validation loss: 2.11846298556174

Epoch: 5| Step: 6
Training loss: 1.638981580734253
Validation loss: 2.14875558371185

Epoch: 5| Step: 7
Training loss: 2.0019779205322266
Validation loss: 2.1675537299084406

Epoch: 5| Step: 8
Training loss: 2.492913007736206
Validation loss: 2.1525369869765414

Epoch: 5| Step: 9
Training loss: 1.3725290298461914
Validation loss: 2.132784428135041

Epoch: 5| Step: 10
Training loss: 1.200575590133667
Validation loss: 2.1526536992801133

Epoch: 353| Step: 0
Training loss: 2.0956332683563232
Validation loss: 2.1384606899753695

Epoch: 5| Step: 1
Training loss: 1.4188891649246216
Validation loss: 2.2065439224243164

Epoch: 5| Step: 2
Training loss: 1.8764660358428955
Validation loss: 2.177731858786716

Epoch: 5| Step: 3
Training loss: 1.309889554977417
Validation loss: 2.191102764939749

Epoch: 5| Step: 4
Training loss: 2.0000033378601074
Validation loss: 2.146978520577954

Epoch: 5| Step: 5
Training loss: 2.1682496070861816
Validation loss: 2.1916637946200628

Epoch: 5| Step: 6
Training loss: 1.4969028234481812
Validation loss: 2.1592326600064515

Epoch: 5| Step: 7
Training loss: 2.459421396255493
Validation loss: 2.147888191284672

Epoch: 5| Step: 8
Training loss: 2.023272752761841
Validation loss: 2.2015648503457346

Epoch: 5| Step: 9
Training loss: 1.9134238958358765
Validation loss: 2.1724539802920435

Epoch: 5| Step: 10
Training loss: 1.958000659942627
Validation loss: 2.1442590016190723

Epoch: 354| Step: 0
Training loss: 1.7902004718780518
Validation loss: 2.1322015870002007

Epoch: 5| Step: 1
Training loss: 1.5400701761245728
Validation loss: 2.1513718366622925

Epoch: 5| Step: 2
Training loss: 1.8818385601043701
Validation loss: 2.126340453342725

Epoch: 5| Step: 3
Training loss: 2.0579733848571777
Validation loss: 2.1775326036637828

Epoch: 5| Step: 4
Training loss: 1.8162949085235596
Validation loss: 2.121262151707885

Epoch: 5| Step: 5
Training loss: 2.2563719749450684
Validation loss: 2.14245411913882

Epoch: 5| Step: 6
Training loss: 2.465744733810425
Validation loss: 2.1062689699152464

Epoch: 5| Step: 7
Training loss: 1.6146831512451172
Validation loss: 2.179176204948015

Epoch: 5| Step: 8
Training loss: 2.140831232070923
Validation loss: 2.144138700218611

Epoch: 5| Step: 9
Training loss: 1.6476901769638062
Validation loss: 2.1739522103340394

Epoch: 5| Step: 10
Training loss: 1.6322755813598633
Validation loss: 2.1187205596636702

Epoch: 355| Step: 0
Training loss: 1.8268810510635376
Validation loss: 2.162669768897436

Epoch: 5| Step: 1
Training loss: 1.273081660270691
Validation loss: 2.164305797187231

Epoch: 5| Step: 2
Training loss: 2.353114128112793
Validation loss: 2.1895471157566195

Epoch: 5| Step: 3
Training loss: 2.209141969680786
Validation loss: 2.146019543370893

Epoch: 5| Step: 4
Training loss: 2.0770020484924316
Validation loss: 2.1524185724155878

Epoch: 5| Step: 5
Training loss: 1.8438491821289062
Validation loss: 2.115706051549604

Epoch: 5| Step: 6
Training loss: 2.081998825073242
Validation loss: 2.067643952626054

Epoch: 5| Step: 7
Training loss: 1.650754690170288
Validation loss: 2.143043912867064

Epoch: 5| Step: 8
Training loss: 2.087080955505371
Validation loss: 2.1296953001329975

Epoch: 5| Step: 9
Training loss: 1.796377420425415
Validation loss: 2.139619650379304

Epoch: 5| Step: 10
Training loss: 1.9963513612747192
Validation loss: 2.1410171293443248

Epoch: 356| Step: 0
Training loss: 2.137861728668213
Validation loss: 2.142640665013303

Epoch: 5| Step: 1
Training loss: 1.8622214794158936
Validation loss: 2.133854671191144

Epoch: 5| Step: 2
Training loss: 2.2682061195373535
Validation loss: 2.1132354441509453

Epoch: 5| Step: 3
Training loss: 1.6101185083389282
Validation loss: 2.120841278824755

Epoch: 5| Step: 4
Training loss: 1.8645511865615845
Validation loss: 2.208604117875458

Epoch: 5| Step: 5
Training loss: 1.608327865600586
Validation loss: 2.200425406937958

Epoch: 5| Step: 6
Training loss: 2.3842718601226807
Validation loss: 2.1548935854306785

Epoch: 5| Step: 7
Training loss: 1.7251663208007812
Validation loss: 2.1753033463672926

Epoch: 5| Step: 8
Training loss: 2.2248833179473877
Validation loss: 2.1427977520932435

Epoch: 5| Step: 9
Training loss: 1.4141709804534912
Validation loss: 2.1368778136468705

Epoch: 5| Step: 10
Training loss: 1.602263331413269
Validation loss: 2.1355314306033555

Epoch: 357| Step: 0
Training loss: 1.7158066034317017
Validation loss: 2.119195197218208

Epoch: 5| Step: 1
Training loss: 2.431337833404541
Validation loss: 2.128543582013858

Epoch: 5| Step: 2
Training loss: 1.9825022220611572
Validation loss: 2.1890522664593113

Epoch: 5| Step: 3
Training loss: 1.0761032104492188
Validation loss: 2.176895244147188

Epoch: 5| Step: 4
Training loss: 2.14616322517395
Validation loss: 2.1468039174233713

Epoch: 5| Step: 5
Training loss: 2.105273723602295
Validation loss: 2.123696788664787

Epoch: 5| Step: 6
Training loss: 1.8785619735717773
Validation loss: 2.157449996599587

Epoch: 5| Step: 7
Training loss: 1.409803032875061
Validation loss: 2.1473282908880584

Epoch: 5| Step: 8
Training loss: 1.838484764099121
Validation loss: 2.156504656678887

Epoch: 5| Step: 9
Training loss: 2.101210832595825
Validation loss: 2.183027513565556

Epoch: 5| Step: 10
Training loss: 1.9508723020553589
Validation loss: 2.157826651809036

Epoch: 358| Step: 0
Training loss: 1.5616471767425537
Validation loss: 2.126564828298425

Epoch: 5| Step: 1
Training loss: 2.239189386367798
Validation loss: 2.1759201326677875

Epoch: 5| Step: 2
Training loss: 1.9036868810653687
Validation loss: 2.125368131104336

Epoch: 5| Step: 3
Training loss: 1.643517255783081
Validation loss: 2.1552080108273413

Epoch: 5| Step: 4
Training loss: 2.396029233932495
Validation loss: 2.226109100926307

Epoch: 5| Step: 5
Training loss: 1.7373113632202148
Validation loss: 2.202217004632437

Epoch: 5| Step: 6
Training loss: 1.762186050415039
Validation loss: 2.1850316691142257

Epoch: 5| Step: 7
Training loss: 1.8084537982940674
Validation loss: 2.0874989494200675

Epoch: 5| Step: 8
Training loss: 1.8302799463272095
Validation loss: 2.1228916798868487

Epoch: 5| Step: 9
Training loss: 2.348841428756714
Validation loss: 2.114328699727212

Epoch: 5| Step: 10
Training loss: 1.6977392435073853
Validation loss: 2.1387000314651

Epoch: 359| Step: 0
Training loss: 2.3329803943634033
Validation loss: 2.1843053948494697

Epoch: 5| Step: 1
Training loss: 1.499846339225769
Validation loss: 2.1340466186564457

Epoch: 5| Step: 2
Training loss: 1.8137315511703491
Validation loss: 2.1322058939164683

Epoch: 5| Step: 3
Training loss: 2.011047840118408
Validation loss: 2.1411108227186304

Epoch: 5| Step: 4
Training loss: 1.780134916305542
Validation loss: 2.148783714540543

Epoch: 5| Step: 5
Training loss: 1.8312877416610718
Validation loss: 2.15517069062879

Epoch: 5| Step: 6
Training loss: 1.8419193029403687
Validation loss: 2.1425960012661514

Epoch: 5| Step: 7
Training loss: 1.8901382684707642
Validation loss: 2.1831668525613765

Epoch: 5| Step: 8
Training loss: 1.6158771514892578
Validation loss: 2.1933728956407115

Epoch: 5| Step: 9
Training loss: 1.8624805212020874
Validation loss: 2.1504194108388757

Epoch: 5| Step: 10
Training loss: 2.5175161361694336
Validation loss: 2.162439312986148

Epoch: 360| Step: 0
Training loss: 1.561133861541748
Validation loss: 2.15894426068952

Epoch: 5| Step: 1
Training loss: 2.4294543266296387
Validation loss: 2.1637006549425024

Epoch: 5| Step: 2
Training loss: 2.134016752243042
Validation loss: 2.163408995956503

Epoch: 5| Step: 3
Training loss: 1.4515695571899414
Validation loss: 2.1753870094976118

Epoch: 5| Step: 4
Training loss: 1.5486996173858643
Validation loss: 2.132989160476192

Epoch: 5| Step: 5
Training loss: 1.8353523015975952
Validation loss: 2.1341931691733738

Epoch: 5| Step: 6
Training loss: 1.6721264123916626
Validation loss: 2.177391013791484

Epoch: 5| Step: 7
Training loss: 2.2755656242370605
Validation loss: 2.1342356179350164

Epoch: 5| Step: 8
Training loss: 1.7270658016204834
Validation loss: 2.171156411529869

Epoch: 5| Step: 9
Training loss: 2.2535314559936523
Validation loss: 2.1661195524277224

Epoch: 5| Step: 10
Training loss: 1.8687907457351685
Validation loss: 2.134922363424814

Epoch: 361| Step: 0
Training loss: 1.147945523262024
Validation loss: 2.177872416793659

Epoch: 5| Step: 1
Training loss: 2.3726718425750732
Validation loss: 2.1177843104126635

Epoch: 5| Step: 2
Training loss: 1.8960506916046143
Validation loss: 2.1377914644056752

Epoch: 5| Step: 3
Training loss: 1.9967197179794312
Validation loss: 2.12203904890245

Epoch: 5| Step: 4
Training loss: 1.4112813472747803
Validation loss: 2.1568824078447077

Epoch: 5| Step: 5
Training loss: 2.6237666606903076
Validation loss: 2.1452801919752553

Epoch: 5| Step: 6
Training loss: 2.087245464324951
Validation loss: 2.151620662340554

Epoch: 5| Step: 7
Training loss: 1.9818811416625977
Validation loss: 2.1516679153647473

Epoch: 5| Step: 8
Training loss: 1.8228286504745483
Validation loss: 2.133305572694348

Epoch: 5| Step: 9
Training loss: 1.6119543313980103
Validation loss: 2.1664215031490532

Epoch: 5| Step: 10
Training loss: 2.078951835632324
Validation loss: 2.196600376918752

Epoch: 362| Step: 0
Training loss: 2.1270956993103027
Validation loss: 2.134622141879092

Epoch: 5| Step: 1
Training loss: 2.084681272506714
Validation loss: 2.1283348247569096

Epoch: 5| Step: 2
Training loss: 1.5003559589385986
Validation loss: 2.208544377357729

Epoch: 5| Step: 3
Training loss: 1.4924877882003784
Validation loss: 2.1768399771823677

Epoch: 5| Step: 4
Training loss: 1.7603988647460938
Validation loss: 2.1407773417811238

Epoch: 5| Step: 5
Training loss: 2.2616939544677734
Validation loss: 2.1526749557064426

Epoch: 5| Step: 6
Training loss: 1.976898193359375
Validation loss: 2.175352611849385

Epoch: 5| Step: 7
Training loss: 2.071115732192993
Validation loss: 2.089796737958026

Epoch: 5| Step: 8
Training loss: 1.9482568502426147
Validation loss: 2.143454759351669

Epoch: 5| Step: 9
Training loss: 1.8387762308120728
Validation loss: 2.121843819977135

Epoch: 5| Step: 10
Training loss: 1.7121005058288574
Validation loss: 2.1471774232003

Epoch: 363| Step: 0
Training loss: 1.935960054397583
Validation loss: 2.1597932077223256

Epoch: 5| Step: 1
Training loss: 1.71828293800354
Validation loss: 2.1677975270055954

Epoch: 5| Step: 2
Training loss: 2.430511474609375
Validation loss: 2.1724558517497075

Epoch: 5| Step: 3
Training loss: 1.8218857049942017
Validation loss: 2.1628650452501033

Epoch: 5| Step: 4
Training loss: 1.8308238983154297
Validation loss: 2.133085250854492

Epoch: 5| Step: 5
Training loss: 1.6984622478485107
Validation loss: 2.1400269449398084

Epoch: 5| Step: 6
Training loss: 1.726999044418335
Validation loss: 2.1014044477093603

Epoch: 5| Step: 7
Training loss: 1.8410402536392212
Validation loss: 2.1208753765270276

Epoch: 5| Step: 8
Training loss: 2.0640358924865723
Validation loss: 2.1176996961716683

Epoch: 5| Step: 9
Training loss: 1.8996474742889404
Validation loss: 2.15055602083924

Epoch: 5| Step: 10
Training loss: 1.7924449443817139
Validation loss: 2.1850308987402145

Epoch: 364| Step: 0
Training loss: 1.2719557285308838
Validation loss: 2.173075701600762

Epoch: 5| Step: 1
Training loss: 1.3881584405899048
Validation loss: 2.1458281752883748

Epoch: 5| Step: 2
Training loss: 1.3176953792572021
Validation loss: 2.17912495136261

Epoch: 5| Step: 3
Training loss: 1.9149837493896484
Validation loss: 2.193061115921185

Epoch: 5| Step: 4
Training loss: 1.9605481624603271
Validation loss: 2.2001432065040833

Epoch: 5| Step: 5
Training loss: 2.2471206188201904
Validation loss: 2.202709121088828

Epoch: 5| Step: 6
Training loss: 2.1414029598236084
Validation loss: 2.153018979616063

Epoch: 5| Step: 7
Training loss: 2.878943681716919
Validation loss: 2.1756528244223645

Epoch: 5| Step: 8
Training loss: 1.8486583232879639
Validation loss: 2.156543863716946

Epoch: 5| Step: 9
Training loss: 2.001182794570923
Validation loss: 2.2424059990913636

Epoch: 5| Step: 10
Training loss: 1.8815454244613647
Validation loss: 2.160021161520353

Epoch: 365| Step: 0
Training loss: 2.416963577270508
Validation loss: 2.2178706879256875

Epoch: 5| Step: 1
Training loss: 1.9373245239257812
Validation loss: 2.1991763537929905

Epoch: 5| Step: 2
Training loss: 2.5292694568634033
Validation loss: 2.192404527818003

Epoch: 5| Step: 3
Training loss: 1.7427514791488647
Validation loss: 2.1919040782477266

Epoch: 5| Step: 4
Training loss: 1.3553619384765625
Validation loss: 2.1447635209688576

Epoch: 5| Step: 5
Training loss: 1.2445356845855713
Validation loss: 2.182507568790067

Epoch: 5| Step: 6
Training loss: 2.618953227996826
Validation loss: 2.1401679272292764

Epoch: 5| Step: 7
Training loss: 1.6538078784942627
Validation loss: 2.150212303284676

Epoch: 5| Step: 8
Training loss: 1.448852300643921
Validation loss: 2.1759469714216007

Epoch: 5| Step: 9
Training loss: 1.728268027305603
Validation loss: 2.165917060708487

Epoch: 5| Step: 10
Training loss: 1.9895144701004028
Validation loss: 2.2166101009615007

Epoch: 366| Step: 0
Training loss: 2.3601365089416504
Validation loss: 2.1428912531945015

Epoch: 5| Step: 1
Training loss: 2.2442851066589355
Validation loss: 2.103902775754211

Epoch: 5| Step: 2
Training loss: 2.2075538635253906
Validation loss: 2.1879456261152863

Epoch: 5| Step: 3
Training loss: 2.1782727241516113
Validation loss: 2.1205476740355134

Epoch: 5| Step: 4
Training loss: 1.6950123310089111
Validation loss: 2.1420171081378894

Epoch: 5| Step: 5
Training loss: 1.6841309070587158
Validation loss: 2.1799401801119567

Epoch: 5| Step: 6
Training loss: 1.226684808731079
Validation loss: 2.1319606355441514

Epoch: 5| Step: 7
Training loss: 2.1813759803771973
Validation loss: 2.1309600914678266

Epoch: 5| Step: 8
Training loss: 1.846416711807251
Validation loss: 2.157960694323304

Epoch: 5| Step: 9
Training loss: 1.4861114025115967
Validation loss: 2.161744797101585

Epoch: 5| Step: 10
Training loss: 1.557948112487793
Validation loss: 2.1642580109257854

Epoch: 367| Step: 0
Training loss: 2.17134165763855
Validation loss: 2.0762399960589666

Epoch: 5| Step: 1
Training loss: 2.083379030227661
Validation loss: 2.1851642823988393

Epoch: 5| Step: 2
Training loss: 2.4177181720733643
Validation loss: 2.1724106752744285

Epoch: 5| Step: 3
Training loss: 2.3141677379608154
Validation loss: 2.190644710294662

Epoch: 5| Step: 4
Training loss: 1.9247674942016602
Validation loss: 2.157910313657535

Epoch: 5| Step: 5
Training loss: 1.2313188314437866
Validation loss: 2.1674522815212125

Epoch: 5| Step: 6
Training loss: 1.840399146080017
Validation loss: 2.14641579504936

Epoch: 5| Step: 7
Training loss: 1.8673721551895142
Validation loss: 2.191945124697942

Epoch: 5| Step: 8
Training loss: 1.3180049657821655
Validation loss: 2.1663536602450955

Epoch: 5| Step: 9
Training loss: 1.4257060289382935
Validation loss: 2.118121531701857

Epoch: 5| Step: 10
Training loss: 2.346553087234497
Validation loss: 2.1528629256832983

Epoch: 368| Step: 0
Training loss: 1.4217031002044678
Validation loss: 2.1597006654226654

Epoch: 5| Step: 1
Training loss: 1.9619286060333252
Validation loss: 2.1628711659421205

Epoch: 5| Step: 2
Training loss: 2.1876132488250732
Validation loss: 2.117394034580518

Epoch: 5| Step: 3
Training loss: 1.3644216060638428
Validation loss: 2.0970504668451126

Epoch: 5| Step: 4
Training loss: 2.3461742401123047
Validation loss: 2.1100349964634066

Epoch: 5| Step: 5
Training loss: 1.8145523071289062
Validation loss: 2.151340082127561

Epoch: 5| Step: 6
Training loss: 1.2403833866119385
Validation loss: 2.1588276381133706

Epoch: 5| Step: 7
Training loss: 2.1284477710723877
Validation loss: 2.1698589812042894

Epoch: 5| Step: 8
Training loss: 2.119192600250244
Validation loss: 2.157327513540945

Epoch: 5| Step: 9
Training loss: 2.384782314300537
Validation loss: 2.183355044293147

Epoch: 5| Step: 10
Training loss: 1.7672266960144043
Validation loss: 2.1610250767841133

Epoch: 369| Step: 0
Training loss: 1.9586527347564697
Validation loss: 2.1595486158965738

Epoch: 5| Step: 1
Training loss: 1.6809536218643188
Validation loss: 2.155922302635767

Epoch: 5| Step: 2
Training loss: 1.8017795085906982
Validation loss: 2.151354556442589

Epoch: 5| Step: 3
Training loss: 2.9800546169281006
Validation loss: 2.180865163444191

Epoch: 5| Step: 4
Training loss: 1.9649477005004883
Validation loss: 2.1543426103489374

Epoch: 5| Step: 5
Training loss: 2.0948967933654785
Validation loss: 2.183787512522872

Epoch: 5| Step: 6
Training loss: 1.4528229236602783
Validation loss: 2.1774941772542973

Epoch: 5| Step: 7
Training loss: 1.8759428262710571
Validation loss: 2.1948235022124423

Epoch: 5| Step: 8
Training loss: 1.6510734558105469
Validation loss: 2.200303926262804

Epoch: 5| Step: 9
Training loss: 1.674910306930542
Validation loss: 2.1705603907185216

Epoch: 5| Step: 10
Training loss: 1.7154940366744995
Validation loss: 2.1289625629301994

Epoch: 370| Step: 0
Training loss: 1.8803770542144775
Validation loss: 2.1758020257437103

Epoch: 5| Step: 1
Training loss: 1.934144377708435
Validation loss: 2.1537239064452467

Epoch: 5| Step: 2
Training loss: 1.6493635177612305
Validation loss: 2.145125501899309

Epoch: 5| Step: 3
Training loss: 2.1177003383636475
Validation loss: 2.155055202463622

Epoch: 5| Step: 4
Training loss: 2.623095989227295
Validation loss: 2.156744057132352

Epoch: 5| Step: 5
Training loss: 1.5527114868164062
Validation loss: 2.1607341535629763

Epoch: 5| Step: 6
Training loss: 1.4837162494659424
Validation loss: 2.1423760588451097

Epoch: 5| Step: 7
Training loss: 2.4558653831481934
Validation loss: 2.16647804808873

Epoch: 5| Step: 8
Training loss: 2.0720162391662598
Validation loss: 2.150552118978193

Epoch: 5| Step: 9
Training loss: 1.1642013788223267
Validation loss: 2.096603208972562

Epoch: 5| Step: 10
Training loss: 1.575076937675476
Validation loss: 2.178949999552901

Epoch: 371| Step: 0
Training loss: 1.6904296875
Validation loss: 2.1266676213151667

Epoch: 5| Step: 1
Training loss: 1.7989221811294556
Validation loss: 2.167898888229042

Epoch: 5| Step: 2
Training loss: 2.0729820728302
Validation loss: 2.142841218620218

Epoch: 5| Step: 3
Training loss: 2.2663800716400146
Validation loss: 2.1494460028986775

Epoch: 5| Step: 4
Training loss: 2.3080286979675293
Validation loss: 2.1569671835950626

Epoch: 5| Step: 5
Training loss: 1.7683855295181274
Validation loss: 2.13166824207511

Epoch: 5| Step: 6
Training loss: 1.7455612421035767
Validation loss: 2.1450585754968787

Epoch: 5| Step: 7
Training loss: 1.7181975841522217
Validation loss: 2.1283714412361063

Epoch: 5| Step: 8
Training loss: 1.9288727045059204
Validation loss: 2.161500098884747

Epoch: 5| Step: 9
Training loss: 1.7350523471832275
Validation loss: 2.079941964918567

Epoch: 5| Step: 10
Training loss: 1.996138572692871
Validation loss: 2.12325067545778

Epoch: 372| Step: 0
Training loss: 2.1732897758483887
Validation loss: 2.1952780318516556

Epoch: 5| Step: 1
Training loss: 1.5976688861846924
Validation loss: 2.0960310915464997

Epoch: 5| Step: 2
Training loss: 1.525818943977356
Validation loss: 2.1133018821798344

Epoch: 5| Step: 3
Training loss: 1.8986051082611084
Validation loss: 2.1192987580453195

Epoch: 5| Step: 4
Training loss: 1.7527134418487549
Validation loss: 2.137884391251431

Epoch: 5| Step: 5
Training loss: 1.7120237350463867
Validation loss: 2.168349349370567

Epoch: 5| Step: 6
Training loss: 1.6680349111557007
Validation loss: 2.128911115789926

Epoch: 5| Step: 7
Training loss: 1.5563395023345947
Validation loss: 2.143282610882995

Epoch: 5| Step: 8
Training loss: 2.654470205307007
Validation loss: 2.1217572073782645

Epoch: 5| Step: 9
Training loss: 2.0125396251678467
Validation loss: 2.1471858896234983

Epoch: 5| Step: 10
Training loss: 2.345322847366333
Validation loss: 2.128864916422034

Epoch: 373| Step: 0
Training loss: 1.8169701099395752
Validation loss: 2.123674278618187

Epoch: 5| Step: 1
Training loss: 1.400853157043457
Validation loss: 2.1183032348591793

Epoch: 5| Step: 2
Training loss: 1.8405921459197998
Validation loss: 2.193246691457687

Epoch: 5| Step: 3
Training loss: 1.8860321044921875
Validation loss: 2.1712915282095633

Epoch: 5| Step: 4
Training loss: 1.7691682577133179
Validation loss: 2.1869295335585073

Epoch: 5| Step: 5
Training loss: 2.198540210723877
Validation loss: 2.1336846992533696

Epoch: 5| Step: 6
Training loss: 2.1841773986816406
Validation loss: 2.144531742219002

Epoch: 5| Step: 7
Training loss: 1.6164792776107788
Validation loss: 2.1219859405230452

Epoch: 5| Step: 8
Training loss: 2.0236690044403076
Validation loss: 2.1630022692423996

Epoch: 5| Step: 9
Training loss: 1.7539784908294678
Validation loss: 2.149259163487342

Epoch: 5| Step: 10
Training loss: 2.3560373783111572
Validation loss: 2.144360303878784

Epoch: 374| Step: 0
Training loss: 1.9994258880615234
Validation loss: 2.1753005186716714

Epoch: 5| Step: 1
Training loss: 2.196071147918701
Validation loss: 2.12636758306975

Epoch: 5| Step: 2
Training loss: 1.1551501750946045
Validation loss: 2.1534291723723054

Epoch: 5| Step: 3
Training loss: 3.13012957572937
Validation loss: 2.1131495403987106

Epoch: 5| Step: 4
Training loss: 1.1427334547042847
Validation loss: 2.184564114898764

Epoch: 5| Step: 5
Training loss: 1.6307998895645142
Validation loss: 2.181456381274808

Epoch: 5| Step: 6
Training loss: 2.4523708820343018
Validation loss: 2.126595207439956

Epoch: 5| Step: 7
Training loss: 2.2998623847961426
Validation loss: 2.1622431829411495

Epoch: 5| Step: 8
Training loss: 1.375927448272705
Validation loss: 2.121837262184389

Epoch: 5| Step: 9
Training loss: 1.7079527378082275
Validation loss: 2.1783178903723277

Epoch: 5| Step: 10
Training loss: 1.6670905351638794
Validation loss: 2.125901504229474

Epoch: 375| Step: 0
Training loss: 2.30474853515625
Validation loss: 2.0819655746541996

Epoch: 5| Step: 1
Training loss: 1.809141755104065
Validation loss: 2.129684261096421

Epoch: 5| Step: 2
Training loss: 1.734267234802246
Validation loss: 2.130498763053648

Epoch: 5| Step: 3
Training loss: 3.1256136894226074
Validation loss: 2.1916933546784105

Epoch: 5| Step: 4
Training loss: 1.0881030559539795
Validation loss: 2.1706613802140757

Epoch: 5| Step: 5
Training loss: 1.8723713159561157
Validation loss: 2.1815702863918838

Epoch: 5| Step: 6
Training loss: 1.4011380672454834
Validation loss: 2.1336013373508247

Epoch: 5| Step: 7
Training loss: 1.7983843088150024
Validation loss: 2.1802309969420075

Epoch: 5| Step: 8
Training loss: 2.0190589427948
Validation loss: 2.1522496259340675

Epoch: 5| Step: 9
Training loss: 1.6864114999771118
Validation loss: 2.156780855630034

Epoch: 5| Step: 10
Training loss: 1.9618977308273315
Validation loss: 2.1771686179663545

Epoch: 376| Step: 0
Training loss: 1.4101206064224243
Validation loss: 2.1195019534839097

Epoch: 5| Step: 1
Training loss: 1.8078655004501343
Validation loss: 2.184707764656313

Epoch: 5| Step: 2
Training loss: 1.9889787435531616
Validation loss: 2.1277640070966495

Epoch: 5| Step: 3
Training loss: 1.8988277912139893
Validation loss: 2.173330630025556

Epoch: 5| Step: 4
Training loss: 2.6947617530822754
Validation loss: 2.127448363970685

Epoch: 5| Step: 5
Training loss: 1.5473636388778687
Validation loss: 2.153623496332476

Epoch: 5| Step: 6
Training loss: 2.277794361114502
Validation loss: 2.1523749354065105

Epoch: 5| Step: 7
Training loss: 2.0806965827941895
Validation loss: 2.1633387175939416

Epoch: 5| Step: 8
Training loss: 1.3318207263946533
Validation loss: 2.146604140599569

Epoch: 5| Step: 9
Training loss: 1.7212053537368774
Validation loss: 2.168259843703239

Epoch: 5| Step: 10
Training loss: 1.9582966566085815
Validation loss: 2.1916832667525097

Epoch: 377| Step: 0
Training loss: 1.3639066219329834
Validation loss: 2.165149170865295

Epoch: 5| Step: 1
Training loss: 1.5068086385726929
Validation loss: 2.1042387306049304

Epoch: 5| Step: 2
Training loss: 1.704045057296753
Validation loss: 2.1481491711831864

Epoch: 5| Step: 3
Training loss: 1.957201361656189
Validation loss: 2.169185071863154

Epoch: 5| Step: 4
Training loss: 2.279944896697998
Validation loss: 2.217178031962405

Epoch: 5| Step: 5
Training loss: 1.6675630807876587
Validation loss: 2.183757225672404

Epoch: 5| Step: 6
Training loss: 2.141655921936035
Validation loss: 2.20318914100688

Epoch: 5| Step: 7
Training loss: 2.020752429962158
Validation loss: 2.19403483534372

Epoch: 5| Step: 8
Training loss: 1.479785680770874
Validation loss: 2.1267502307891846

Epoch: 5| Step: 9
Training loss: 1.8722858428955078
Validation loss: 2.155474352580245

Epoch: 5| Step: 10
Training loss: 2.6070711612701416
Validation loss: 2.203018021839921

Epoch: 378| Step: 0
Training loss: 2.4919590950012207
Validation loss: 2.1901666605344383

Epoch: 5| Step: 1
Training loss: 2.2584099769592285
Validation loss: 2.108895112109441

Epoch: 5| Step: 2
Training loss: 2.013993501663208
Validation loss: 2.1238616410122124

Epoch: 5| Step: 3
Training loss: 1.796413779258728
Validation loss: 2.1407942669365996

Epoch: 5| Step: 4
Training loss: 1.828931212425232
Validation loss: 2.188540981661889

Epoch: 5| Step: 5
Training loss: 1.5709483623504639
Validation loss: 2.115619792733141

Epoch: 5| Step: 6
Training loss: 1.8504419326782227
Validation loss: 2.0888338447898946

Epoch: 5| Step: 7
Training loss: 1.755910873413086
Validation loss: 2.1240337061625656

Epoch: 5| Step: 8
Training loss: 1.5907834768295288
Validation loss: 2.1585444352960073

Epoch: 5| Step: 9
Training loss: 1.787205457687378
Validation loss: 2.1323959801786687

Epoch: 5| Step: 10
Training loss: 1.8137346506118774
Validation loss: 2.108649392281809

Epoch: 379| Step: 0
Training loss: 1.7319738864898682
Validation loss: 2.1573415904916744

Epoch: 5| Step: 1
Training loss: 1.779714822769165
Validation loss: 2.175172410985475

Epoch: 5| Step: 2
Training loss: 1.4820154905319214
Validation loss: 2.17443686403254

Epoch: 5| Step: 3
Training loss: 1.9325134754180908
Validation loss: 2.1646995672615628

Epoch: 5| Step: 4
Training loss: 1.8223087787628174
Validation loss: 2.1490109582101145

Epoch: 5| Step: 5
Training loss: 1.968553900718689
Validation loss: 2.1783226895075973

Epoch: 5| Step: 6
Training loss: 1.8165624141693115
Validation loss: 2.1555352057180097

Epoch: 5| Step: 7
Training loss: 2.131312847137451
Validation loss: 2.1572276571745514

Epoch: 5| Step: 8
Training loss: 2.2426183223724365
Validation loss: 2.1191502565978677

Epoch: 5| Step: 9
Training loss: 1.62481689453125
Validation loss: 2.144179795377998

Epoch: 5| Step: 10
Training loss: 1.9710700511932373
Validation loss: 2.149578464928494

Epoch: 380| Step: 0
Training loss: 1.8353559970855713
Validation loss: 2.144473639867639

Epoch: 5| Step: 1
Training loss: 1.562412977218628
Validation loss: 2.140858031088306

Epoch: 5| Step: 2
Training loss: 1.5428507328033447
Validation loss: 2.1338949177854802

Epoch: 5| Step: 3
Training loss: 1.976270318031311
Validation loss: 2.154086679540655

Epoch: 5| Step: 4
Training loss: 2.5153446197509766
Validation loss: 2.145011281454435

Epoch: 5| Step: 5
Training loss: 1.0987863540649414
Validation loss: 2.142961322620351

Epoch: 5| Step: 6
Training loss: 2.031904697418213
Validation loss: 2.100692859259985

Epoch: 5| Step: 7
Training loss: 1.9885728359222412
Validation loss: 2.1219447787090013

Epoch: 5| Step: 8
Training loss: 2.2564759254455566
Validation loss: 2.139570436170024

Epoch: 5| Step: 9
Training loss: 1.9638513326644897
Validation loss: 2.1220306452884468

Epoch: 5| Step: 10
Training loss: 1.6434285640716553
Validation loss: 2.144475552343553

Epoch: 381| Step: 0
Training loss: 1.3020678758621216
Validation loss: 2.1459558676647883

Epoch: 5| Step: 1
Training loss: 1.6013500690460205
Validation loss: 2.1481522257610033

Epoch: 5| Step: 2
Training loss: 1.9135339260101318
Validation loss: 2.147374588956115

Epoch: 5| Step: 3
Training loss: 1.815603256225586
Validation loss: 2.1301661306811916

Epoch: 5| Step: 4
Training loss: 1.440264344215393
Validation loss: 2.167569634734943

Epoch: 5| Step: 5
Training loss: 2.3587260246276855
Validation loss: 2.1547888735289216

Epoch: 5| Step: 6
Training loss: 1.7212915420532227
Validation loss: 2.1770199498822613

Epoch: 5| Step: 7
Training loss: 2.0739943981170654
Validation loss: 2.163118004798889

Epoch: 5| Step: 8
Training loss: 2.077310085296631
Validation loss: 2.1008732280423565

Epoch: 5| Step: 9
Training loss: 1.9595359563827515
Validation loss: 2.1438953979040987

Epoch: 5| Step: 10
Training loss: 2.2002205848693848
Validation loss: 2.113076571495302

Epoch: 382| Step: 0
Training loss: 2.084993839263916
Validation loss: 2.101439368340277

Epoch: 5| Step: 1
Training loss: 1.6075992584228516
Validation loss: 2.1656656957441762

Epoch: 5| Step: 2
Training loss: 1.92258620262146
Validation loss: 2.1346109208240303

Epoch: 5| Step: 3
Training loss: 2.344316005706787
Validation loss: 2.1725560618985083

Epoch: 5| Step: 4
Training loss: 1.8988463878631592
Validation loss: 2.17644505346975

Epoch: 5| Step: 5
Training loss: 1.902611494064331
Validation loss: 2.1514659107372327

Epoch: 5| Step: 6
Training loss: 1.8365741968154907
Validation loss: 2.1701311398577947

Epoch: 5| Step: 7
Training loss: 1.7924636602401733
Validation loss: 2.2016959805642404

Epoch: 5| Step: 8
Training loss: 1.5122967958450317
Validation loss: 2.1685438258673555

Epoch: 5| Step: 9
Training loss: 1.6249700784683228
Validation loss: 2.174095494772798

Epoch: 5| Step: 10
Training loss: 1.8534598350524902
Validation loss: 2.172136442635649

Epoch: 383| Step: 0
Training loss: 1.966456651687622
Validation loss: 2.1435332016278337

Epoch: 5| Step: 1
Training loss: 1.4816035032272339
Validation loss: 2.134040378755139

Epoch: 5| Step: 2
Training loss: 1.8351869583129883
Validation loss: 2.122718334197998

Epoch: 5| Step: 3
Training loss: 2.0028328895568848
Validation loss: 2.149207492028513

Epoch: 5| Step: 4
Training loss: 1.8136885166168213
Validation loss: 2.1576013334335817

Epoch: 5| Step: 5
Training loss: 2.000776767730713
Validation loss: 2.1768173556174

Epoch: 5| Step: 6
Training loss: 1.4499900341033936
Validation loss: 2.145671218954107

Epoch: 5| Step: 7
Training loss: 1.8952856063842773
Validation loss: 2.128395838122214

Epoch: 5| Step: 8
Training loss: 1.8188327550888062
Validation loss: 2.1224339726150676

Epoch: 5| Step: 9
Training loss: 2.0675482749938965
Validation loss: 2.1633526279080297

Epoch: 5| Step: 10
Training loss: 2.2292869091033936
Validation loss: 2.1229632580152122

Epoch: 384| Step: 0
Training loss: 1.5489871501922607
Validation loss: 2.128279206573322

Epoch: 5| Step: 1
Training loss: 2.0720489025115967
Validation loss: 2.169500063824397

Epoch: 5| Step: 2
Training loss: 1.8092161417007446
Validation loss: 2.156775010529385

Epoch: 5| Step: 3
Training loss: 2.047415018081665
Validation loss: 2.122225549913222

Epoch: 5| Step: 4
Training loss: 1.6960361003875732
Validation loss: 2.125182153076254

Epoch: 5| Step: 5
Training loss: 2.079373836517334
Validation loss: 2.144022226333618

Epoch: 5| Step: 6
Training loss: 2.0631661415100098
Validation loss: 2.145299792289734

Epoch: 5| Step: 7
Training loss: 1.5725549459457397
Validation loss: 2.1689830159628265

Epoch: 5| Step: 8
Training loss: 1.819581389427185
Validation loss: 2.1011845527156705

Epoch: 5| Step: 9
Training loss: 1.4252575635910034
Validation loss: 2.136541005103819

Epoch: 5| Step: 10
Training loss: 2.6452202796936035
Validation loss: 2.1584462824688164

Epoch: 385| Step: 0
Training loss: 1.398476481437683
Validation loss: 2.1424108679576586

Epoch: 5| Step: 1
Training loss: 1.7710072994232178
Validation loss: 2.126684647734447

Epoch: 5| Step: 2
Training loss: 1.9026134014129639
Validation loss: 2.214944347258537

Epoch: 5| Step: 3
Training loss: 1.565638542175293
Validation loss: 2.129175786049135

Epoch: 5| Step: 4
Training loss: 2.011274814605713
Validation loss: 2.122102040116505

Epoch: 5| Step: 5
Training loss: 2.1628201007843018
Validation loss: 2.1926183469833864

Epoch: 5| Step: 6
Training loss: 1.9602515697479248
Validation loss: 2.094674292431083

Epoch: 5| Step: 7
Training loss: 2.3025097846984863
Validation loss: 2.1844868224154235

Epoch: 5| Step: 8
Training loss: 1.97377610206604
Validation loss: 2.1606405678615777

Epoch: 5| Step: 9
Training loss: 1.3651156425476074
Validation loss: 2.2356469759377102

Epoch: 5| Step: 10
Training loss: 2.3484888076782227
Validation loss: 2.1038845431420112

Epoch: 386| Step: 0
Training loss: 1.8584587574005127
Validation loss: 2.1968909079028713

Epoch: 5| Step: 1
Training loss: 1.5073978900909424
Validation loss: 2.157624021653206

Epoch: 5| Step: 2
Training loss: 1.9968843460083008
Validation loss: 2.1294690255195863

Epoch: 5| Step: 3
Training loss: 2.590047836303711
Validation loss: 2.15096386273702

Epoch: 5| Step: 4
Training loss: 1.3586441278457642
Validation loss: 2.1290312454264653

Epoch: 5| Step: 5
Training loss: 2.147459030151367
Validation loss: 2.1391716516146095

Epoch: 5| Step: 6
Training loss: 1.2919657230377197
Validation loss: 2.1931283217604443

Epoch: 5| Step: 7
Training loss: 1.2872989177703857
Validation loss: 2.1180466580134567

Epoch: 5| Step: 8
Training loss: 1.3632773160934448
Validation loss: 2.1502687341423443

Epoch: 5| Step: 9
Training loss: 2.492192029953003
Validation loss: 2.1440262217675485

Epoch: 5| Step: 10
Training loss: 2.7376675605773926
Validation loss: 2.1593809845626994

Epoch: 387| Step: 0
Training loss: 1.5345689058303833
Validation loss: 2.1156599662637197

Epoch: 5| Step: 1
Training loss: 1.7441139221191406
Validation loss: 2.134067540527672

Epoch: 5| Step: 2
Training loss: 2.346593141555786
Validation loss: 2.147853782100062

Epoch: 5| Step: 3
Training loss: 1.9627454280853271
Validation loss: 2.140148203860047

Epoch: 5| Step: 4
Training loss: 2.0618319511413574
Validation loss: 2.114001453563731

Epoch: 5| Step: 5
Training loss: 1.4854589700698853
Validation loss: 2.1625214110138598

Epoch: 5| Step: 6
Training loss: 1.502838134765625
Validation loss: 2.1461525168470157

Epoch: 5| Step: 7
Training loss: 1.849887490272522
Validation loss: 2.12818242144841

Epoch: 5| Step: 8
Training loss: 1.9774566888809204
Validation loss: 2.12515087281504

Epoch: 5| Step: 9
Training loss: 1.760724425315857
Validation loss: 2.1701363350755427

Epoch: 5| Step: 10
Training loss: 2.0984416007995605
Validation loss: 2.153063125507806

Epoch: 388| Step: 0
Training loss: 1.7546517848968506
Validation loss: 2.130172057818341

Epoch: 5| Step: 1
Training loss: 2.0260705947875977
Validation loss: 2.1722209504855576

Epoch: 5| Step: 2
Training loss: 1.9436314105987549
Validation loss: 2.105208691730294

Epoch: 5| Step: 3
Training loss: 2.225736141204834
Validation loss: 2.176996284915555

Epoch: 5| Step: 4
Training loss: 1.6842715740203857
Validation loss: 2.154676683487431

Epoch: 5| Step: 5
Training loss: 1.876665711402893
Validation loss: 2.115402337043516

Epoch: 5| Step: 6
Training loss: 1.7694746255874634
Validation loss: 2.1030497115145446

Epoch: 5| Step: 7
Training loss: 1.4783978462219238
Validation loss: 2.1109275612779843

Epoch: 5| Step: 8
Training loss: 1.744222640991211
Validation loss: 2.1569171618389826

Epoch: 5| Step: 9
Training loss: 1.6558399200439453
Validation loss: 2.16752867544851

Epoch: 5| Step: 10
Training loss: 2.1186437606811523
Validation loss: 2.14379019634698

Epoch: 389| Step: 0
Training loss: 2.2706339359283447
Validation loss: 2.129106007596498

Epoch: 5| Step: 1
Training loss: 2.047112226486206
Validation loss: 2.140199636900297

Epoch: 5| Step: 2
Training loss: 2.365084171295166
Validation loss: 2.1297546932774205

Epoch: 5| Step: 3
Training loss: 1.591163992881775
Validation loss: 2.199997568643221

Epoch: 5| Step: 4
Training loss: 2.2230093479156494
Validation loss: 2.130736099776401

Epoch: 5| Step: 5
Training loss: 2.550307273864746
Validation loss: 2.1673396120789232

Epoch: 5| Step: 6
Training loss: 1.4958072900772095
Validation loss: 2.167907921216821

Epoch: 5| Step: 7
Training loss: 1.6176061630249023
Validation loss: 2.1648208466909264

Epoch: 5| Step: 8
Training loss: 1.1043944358825684
Validation loss: 2.1298378616250973

Epoch: 5| Step: 9
Training loss: 1.3259471654891968
Validation loss: 2.181945429053358

Epoch: 5| Step: 10
Training loss: 2.078209638595581
Validation loss: 2.127401157092023

Epoch: 390| Step: 0
Training loss: 1.6218467950820923
Validation loss: 2.158805357512607

Epoch: 5| Step: 1
Training loss: 2.0441131591796875
Validation loss: 2.133563604406131

Epoch: 5| Step: 2
Training loss: 1.4286755323410034
Validation loss: 2.1708980234720374

Epoch: 5| Step: 3
Training loss: 1.9863865375518799
Validation loss: 2.156948751018893

Epoch: 5| Step: 4
Training loss: 1.686258316040039
Validation loss: 2.1499768226377425

Epoch: 5| Step: 5
Training loss: 2.2381362915039062
Validation loss: 2.1613681162557294

Epoch: 5| Step: 6
Training loss: 1.7441778182983398
Validation loss: 2.122716698595273

Epoch: 5| Step: 7
Training loss: 1.663325548171997
Validation loss: 2.166084953533706

Epoch: 5| Step: 8
Training loss: 1.7153799533843994
Validation loss: 2.158725228360904

Epoch: 5| Step: 9
Training loss: 2.3183090686798096
Validation loss: 2.136847965178951

Epoch: 5| Step: 10
Training loss: 1.694797396659851
Validation loss: 2.1199463029061594

Epoch: 391| Step: 0
Training loss: 2.349637031555176
Validation loss: 2.166952012687601

Epoch: 5| Step: 1
Training loss: 1.7189133167266846
Validation loss: 2.152172618014838

Epoch: 5| Step: 2
Training loss: 1.598096489906311
Validation loss: 2.1666048444727415

Epoch: 5| Step: 3
Training loss: 2.11405611038208
Validation loss: 2.1664179755795385

Epoch: 5| Step: 4
Training loss: 1.258085012435913
Validation loss: 2.133683749424514

Epoch: 5| Step: 5
Training loss: 1.6969314813613892
Validation loss: 2.0971403019402617

Epoch: 5| Step: 6
Training loss: 1.7314373254776
Validation loss: 2.171242878001223

Epoch: 5| Step: 7
Training loss: 2.3403260707855225
Validation loss: 2.182987851481284

Epoch: 5| Step: 8
Training loss: 1.4989460706710815
Validation loss: 2.137934498889472

Epoch: 5| Step: 9
Training loss: 1.9742538928985596
Validation loss: 2.1388325691223145

Epoch: 5| Step: 10
Training loss: 2.0062270164489746
Validation loss: 2.143565103571902

Epoch: 392| Step: 0
Training loss: 1.0754609107971191
Validation loss: 2.145494022677022

Epoch: 5| Step: 1
Training loss: 2.061336040496826
Validation loss: 2.168535887554128

Epoch: 5| Step: 2
Training loss: 1.347420573234558
Validation loss: 2.1284520574795303

Epoch: 5| Step: 3
Training loss: 1.8141744136810303
Validation loss: 2.106336901264806

Epoch: 5| Step: 4
Training loss: 2.115812063217163
Validation loss: 2.141531172619071

Epoch: 5| Step: 5
Training loss: 2.752147912979126
Validation loss: 2.15634810796348

Epoch: 5| Step: 6
Training loss: 1.106774926185608
Validation loss: 2.1962842633647304

Epoch: 5| Step: 7
Training loss: 1.3309694528579712
Validation loss: 2.1513570431740052

Epoch: 5| Step: 8
Training loss: 2.281932830810547
Validation loss: 2.158286858630437

Epoch: 5| Step: 9
Training loss: 1.8302583694458008
Validation loss: 2.133134436863725

Epoch: 5| Step: 10
Training loss: 2.4300568103790283
Validation loss: 2.116816747573114

Epoch: 393| Step: 0
Training loss: 1.9247287511825562
Validation loss: 2.1669494823742936

Epoch: 5| Step: 1
Training loss: 1.5828325748443604
Validation loss: 2.1609581439725813

Epoch: 5| Step: 2
Training loss: 2.0260796546936035
Validation loss: 2.1478217596648843

Epoch: 5| Step: 3
Training loss: 1.889428734779358
Validation loss: 2.165143853874617

Epoch: 5| Step: 4
Training loss: 1.869863748550415
Validation loss: 2.173544397918127

Epoch: 5| Step: 5
Training loss: 1.7635557651519775
Validation loss: 2.1358614237077775

Epoch: 5| Step: 6
Training loss: 1.9009431600570679
Validation loss: 2.1456630640132452

Epoch: 5| Step: 7
Training loss: 2.158663034439087
Validation loss: 2.141031554950181

Epoch: 5| Step: 8
Training loss: 2.0078511238098145
Validation loss: 2.152720159099948

Epoch: 5| Step: 9
Training loss: 1.7680308818817139
Validation loss: 2.123847952453039

Epoch: 5| Step: 10
Training loss: 1.3291879892349243
Validation loss: 2.1424946579881894

Epoch: 394| Step: 0
Training loss: 2.065831184387207
Validation loss: 2.1532699087614655

Epoch: 5| Step: 1
Training loss: 2.0108063220977783
Validation loss: 2.137770596370902

Epoch: 5| Step: 2
Training loss: 2.0484790802001953
Validation loss: 2.139638195755661

Epoch: 5| Step: 3
Training loss: 1.6926805973052979
Validation loss: 2.1499793324419247

Epoch: 5| Step: 4
Training loss: 1.4775010347366333
Validation loss: 2.138959671861382

Epoch: 5| Step: 5
Training loss: 1.9127590656280518
Validation loss: 2.1480551817083873

Epoch: 5| Step: 6
Training loss: 1.5407112836837769
Validation loss: 2.1815810716280373

Epoch: 5| Step: 7
Training loss: 1.5801851749420166
Validation loss: 2.162440707606654

Epoch: 5| Step: 8
Training loss: 1.994323968887329
Validation loss: 2.1177531852517077

Epoch: 5| Step: 9
Training loss: 1.9241440296173096
Validation loss: 2.181654550695932

Epoch: 5| Step: 10
Training loss: 1.8086682558059692
Validation loss: 2.1271384659633843

Epoch: 395| Step: 0
Training loss: 2.518040657043457
Validation loss: 2.1299525589071293

Epoch: 5| Step: 1
Training loss: 1.6286290884017944
Validation loss: 2.1589210661508704

Epoch: 5| Step: 2
Training loss: 1.9485466480255127
Validation loss: 2.159403972728278

Epoch: 5| Step: 3
Training loss: 1.9564464092254639
Validation loss: 2.1053668068301294

Epoch: 5| Step: 4
Training loss: 1.2091906070709229
Validation loss: 2.1660072829133723

Epoch: 5| Step: 5
Training loss: 1.8242766857147217
Validation loss: 2.1232513420043455

Epoch: 5| Step: 6
Training loss: 2.3719067573547363
Validation loss: 2.1797767634032876

Epoch: 5| Step: 7
Training loss: 1.6869300603866577
Validation loss: 2.1583779999004897

Epoch: 5| Step: 8
Training loss: 1.2960551977157593
Validation loss: 2.1625137226555937

Epoch: 5| Step: 9
Training loss: 1.980210542678833
Validation loss: 2.136267961994294

Epoch: 5| Step: 10
Training loss: 1.6940736770629883
Validation loss: 2.163775428648918

Epoch: 396| Step: 0
Training loss: 1.17823326587677
Validation loss: 2.1796285234471804

Epoch: 5| Step: 1
Training loss: 1.8301843404769897
Validation loss: 2.1488028367360434

Epoch: 5| Step: 2
Training loss: 1.8138868808746338
Validation loss: 2.161405671027399

Epoch: 5| Step: 3
Training loss: 1.2621071338653564
Validation loss: 2.096747249685308

Epoch: 5| Step: 4
Training loss: 2.5753166675567627
Validation loss: 2.1134027729752245

Epoch: 5| Step: 5
Training loss: 1.4363088607788086
Validation loss: 2.173825328068067

Epoch: 5| Step: 6
Training loss: 1.6252597570419312
Validation loss: 2.1092939453740276

Epoch: 5| Step: 7
Training loss: 1.644836664199829
Validation loss: 2.170128845399426

Epoch: 5| Step: 8
Training loss: 1.861915946006775
Validation loss: 2.1348177079231507

Epoch: 5| Step: 9
Training loss: 2.413726329803467
Validation loss: 2.180745270944411

Epoch: 5| Step: 10
Training loss: 2.171578884124756
Validation loss: 2.134038984134633

Epoch: 397| Step: 0
Training loss: 1.723136305809021
Validation loss: 2.143813328076434

Epoch: 5| Step: 1
Training loss: 2.1538825035095215
Validation loss: 2.1777770775620655

Epoch: 5| Step: 2
Training loss: 2.2029309272766113
Validation loss: 2.1761453202975694

Epoch: 5| Step: 3
Training loss: 1.8386261463165283
Validation loss: 2.1316686945576824

Epoch: 5| Step: 4
Training loss: 1.5408204793930054
Validation loss: 2.0818809873314312

Epoch: 5| Step: 5
Training loss: 1.3852006196975708
Validation loss: 2.2159581568933304

Epoch: 5| Step: 6
Training loss: 1.7006428241729736
Validation loss: 2.176030907579648

Epoch: 5| Step: 7
Training loss: 2.373222827911377
Validation loss: 2.133497356086649

Epoch: 5| Step: 8
Training loss: 1.9637205600738525
Validation loss: 2.1729130386024393

Epoch: 5| Step: 9
Training loss: 1.8666521310806274
Validation loss: 2.177322209522288

Epoch: 5| Step: 10
Training loss: 1.7323395013809204
Validation loss: 2.1506610775506623

Epoch: 398| Step: 0
Training loss: 1.5767968893051147
Validation loss: 2.1602446699655182

Epoch: 5| Step: 1
Training loss: 1.5872571468353271
Validation loss: 2.1254201114818616

Epoch: 5| Step: 2
Training loss: 1.3669284582138062
Validation loss: 2.1566331591657413

Epoch: 5| Step: 3
Training loss: 1.281386137008667
Validation loss: 2.168451888586885

Epoch: 5| Step: 4
Training loss: 2.740490436553955
Validation loss: 2.1480776084366666

Epoch: 5| Step: 5
Training loss: 2.0015578269958496
Validation loss: 2.1139425975020214

Epoch: 5| Step: 6
Training loss: 1.9102290868759155
Validation loss: 2.120909252474385

Epoch: 5| Step: 7
Training loss: 2.0759694576263428
Validation loss: 2.140141205121112

Epoch: 5| Step: 8
Training loss: 1.9938223361968994
Validation loss: 2.0835698702002086

Epoch: 5| Step: 9
Training loss: 1.8609139919281006
Validation loss: 2.166367292404175

Epoch: 5| Step: 10
Training loss: 2.1905012130737305
Validation loss: 2.1846533642020276

Epoch: 399| Step: 0
Training loss: 1.466639757156372
Validation loss: 2.1573211749394736

Epoch: 5| Step: 1
Training loss: 2.055593967437744
Validation loss: 2.150760499379968

Epoch: 5| Step: 2
Training loss: 1.4535210132598877
Validation loss: 2.1504270748425554

Epoch: 5| Step: 3
Training loss: 1.456595778465271
Validation loss: 2.192031175859513

Epoch: 5| Step: 4
Training loss: 1.4751673936843872
Validation loss: 2.167328780697238

Epoch: 5| Step: 5
Training loss: 1.9557197093963623
Validation loss: 2.1478770881570797

Epoch: 5| Step: 6
Training loss: 2.0513994693756104
Validation loss: 2.169230024019877

Epoch: 5| Step: 7
Training loss: 2.3839221000671387
Validation loss: 2.203026763854488

Epoch: 5| Step: 8
Training loss: 2.384481430053711
Validation loss: 2.1741344441649733

Epoch: 5| Step: 9
Training loss: 1.7827192544937134
Validation loss: 2.1178536120281426

Epoch: 5| Step: 10
Training loss: 1.9545097351074219
Validation loss: 2.1564482437667025

Epoch: 400| Step: 0
Training loss: 2.061434507369995
Validation loss: 2.159472160441901

Epoch: 5| Step: 1
Training loss: 2.09016752243042
Validation loss: 2.218729985657559

Epoch: 5| Step: 2
Training loss: 1.6748460531234741
Validation loss: 2.1187675691420034

Epoch: 5| Step: 3
Training loss: 1.4265742301940918
Validation loss: 2.161268735444674

Epoch: 5| Step: 4
Training loss: 1.6255804300308228
Validation loss: 2.1508204475525887

Epoch: 5| Step: 5
Training loss: 1.9112939834594727
Validation loss: 2.1684363016518216

Epoch: 5| Step: 6
Training loss: 1.5984584093093872
Validation loss: 2.1561655459865445

Epoch: 5| Step: 7
Training loss: 2.0257532596588135
Validation loss: 2.151346073355726

Epoch: 5| Step: 8
Training loss: 1.7809722423553467
Validation loss: 2.1561049081945933

Epoch: 5| Step: 9
Training loss: 2.0396595001220703
Validation loss: 2.1778954229047223

Epoch: 5| Step: 10
Training loss: 2.12605619430542
Validation loss: 2.108074290778047

Testing loss: 2.0538263188468084
