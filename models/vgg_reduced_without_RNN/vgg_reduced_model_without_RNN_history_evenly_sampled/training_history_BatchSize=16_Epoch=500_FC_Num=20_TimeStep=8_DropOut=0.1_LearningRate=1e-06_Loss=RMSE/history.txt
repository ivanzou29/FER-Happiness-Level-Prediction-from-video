Epoch: 1| Step: 0
Training loss: 4.609988621099831
Validation loss: 4.070369421911038

Epoch: 6| Step: 1
Training loss: 4.021301532162596
Validation loss: 4.067126541387151

Epoch: 6| Step: 2
Training loss: 4.05403875846383
Validation loss: 4.0662328162538435

Epoch: 6| Step: 3
Training loss: 4.739639628428837
Validation loss: 4.060950243155611

Epoch: 6| Step: 4
Training loss: 4.833309217370916
Validation loss: 4.060351835106307

Epoch: 6| Step: 5
Training loss: 5.0040571918100865
Validation loss: 4.055613544926265

Epoch: 6| Step: 6
Training loss: 3.770996188586445
Validation loss: 4.05016867629337

Epoch: 6| Step: 7
Training loss: 3.792934303637998
Validation loss: 4.049171803538847

Epoch: 6| Step: 8
Training loss: 5.133336428026199
Validation loss: 4.044956855117422

Epoch: 6| Step: 9
Training loss: 3.619160124576449
Validation loss: 4.041016619746963

Epoch: 6| Step: 10
Training loss: 3.9375775041975363
Validation loss: 4.041488125080527

Epoch: 6| Step: 11
Training loss: 3.62617342142526
Validation loss: 4.036380523450362

Epoch: 6| Step: 12
Training loss: 3.947953048712878
Validation loss: 4.032930825499989

Epoch: 6| Step: 13
Training loss: 2.16118951680862
Validation loss: 4.030692644915539

Epoch: 2| Step: 0
Training loss: 3.8116861944417018
Validation loss: 4.02741587781854

Epoch: 6| Step: 1
Training loss: 3.0957467157321363
Validation loss: 4.025517424604383

Epoch: 6| Step: 2
Training loss: 4.686143195562467
Validation loss: 4.0211721910096045

Epoch: 6| Step: 3
Training loss: 4.882880468276944
Validation loss: 4.018526111025157

Epoch: 6| Step: 4
Training loss: 4.123810799003932
Validation loss: 4.018452634472362

Epoch: 6| Step: 5
Training loss: 4.328493398694176
Validation loss: 4.01411721419832

Epoch: 6| Step: 6
Training loss: 4.300692107812552
Validation loss: 4.008418458618797

Epoch: 6| Step: 7
Training loss: 3.0625524711006387
Validation loss: 4.010032148056658

Epoch: 6| Step: 8
Training loss: 3.876405645577478
Validation loss: 4.00390694662989

Epoch: 6| Step: 9
Training loss: 3.8506624667452085
Validation loss: 4.003689379637558

Epoch: 6| Step: 10
Training loss: 4.163577854946299
Validation loss: 3.9997037654824883

Epoch: 6| Step: 11
Training loss: 5.3738911394252815
Validation loss: 3.996525288409929

Epoch: 6| Step: 12
Training loss: 4.116739035110572
Validation loss: 3.9947414878222944

Epoch: 6| Step: 13
Training loss: 3.903008909308635
Validation loss: 3.9918505112997225

Epoch: 3| Step: 0
Training loss: 3.5282296286004105
Validation loss: 3.986085205310275

Epoch: 6| Step: 1
Training loss: 4.203520688856024
Validation loss: 3.9865041707189257

Epoch: 6| Step: 2
Training loss: 3.428582571783577
Validation loss: 3.9832620152415816

Epoch: 6| Step: 3
Training loss: 4.564140129539223
Validation loss: 3.9782025642973564

Epoch: 6| Step: 4
Training loss: 4.654374327277295
Validation loss: 3.976619502871281

Epoch: 6| Step: 5
Training loss: 4.581414717019861
Validation loss: 3.9707300764612725

Epoch: 6| Step: 6
Training loss: 3.871225056504769
Validation loss: 3.972500316606153

Epoch: 6| Step: 7
Training loss: 4.032467680374105
Validation loss: 3.968059483276711

Epoch: 6| Step: 8
Training loss: 3.8420190402685583
Validation loss: 3.965468651096155

Epoch: 6| Step: 9
Training loss: 3.017223191605796
Validation loss: 3.9611335827701186

Epoch: 6| Step: 10
Training loss: 4.833990293556983
Validation loss: 3.9590685685657174

Epoch: 6| Step: 11
Training loss: 4.036979448048361
Validation loss: 3.954193651724977

Epoch: 6| Step: 12
Training loss: 4.984637119013977
Validation loss: 3.9530781383980202

Epoch: 6| Step: 13
Training loss: 3.2684524196448725
Validation loss: 3.94979312017993

Epoch: 4| Step: 0
Training loss: 4.3978899924973565
Validation loss: 3.9456244018167714

Epoch: 6| Step: 1
Training loss: 4.623097002461125
Validation loss: 3.943307117037331

Epoch: 6| Step: 2
Training loss: 3.864591463119853
Validation loss: 3.9382977358747886

Epoch: 6| Step: 3
Training loss: 3.8239290870012943
Validation loss: 3.9362179097495704

Epoch: 6| Step: 4
Training loss: 5.026154016480961
Validation loss: 3.935340692942249

Epoch: 6| Step: 5
Training loss: 4.099968533278878
Validation loss: 3.930968068026991

Epoch: 6| Step: 6
Training loss: 4.1883227550668005
Validation loss: 3.9275591310089624

Epoch: 6| Step: 7
Training loss: 4.117919393557375
Validation loss: 3.9248913908970633

Epoch: 6| Step: 8
Training loss: 3.618727420084185
Validation loss: 3.920458761609588

Epoch: 6| Step: 9
Training loss: 4.005431064452983
Validation loss: 3.9201454905569446

Epoch: 6| Step: 10
Training loss: 3.5106222543405177
Validation loss: 3.91189671226229

Epoch: 6| Step: 11
Training loss: 4.07976162980813
Validation loss: 3.911630120765323

Epoch: 6| Step: 12
Training loss: 2.56233382267718
Validation loss: 3.907522895397454

Epoch: 6| Step: 13
Training loss: 5.195861144961413
Validation loss: 3.902318801626863

Epoch: 5| Step: 0
Training loss: 3.8820316135823183
Validation loss: 3.9032139421589656

Epoch: 6| Step: 1
Training loss: 4.032449469914904
Validation loss: 3.8968778092655887

Epoch: 6| Step: 2
Training loss: 3.731109851652408
Validation loss: 3.894972265104425

Epoch: 6| Step: 3
Training loss: 3.9453332881568666
Validation loss: 3.8911624950151955

Epoch: 6| Step: 4
Training loss: 3.7796826858142913
Validation loss: 3.890333248815873

Epoch: 6| Step: 5
Training loss: 5.0190725866565185
Validation loss: 3.885265947956515

Epoch: 6| Step: 6
Training loss: 4.484037486277821
Validation loss: 3.8827202614871306

Epoch: 6| Step: 7
Training loss: 4.022161603673385
Validation loss: 3.878628321198808

Epoch: 6| Step: 8
Training loss: 4.29047708166083
Validation loss: 3.8747480974148183

Epoch: 6| Step: 9
Training loss: 3.6150218833166017
Validation loss: 3.8714165063823196

Epoch: 6| Step: 10
Training loss: 2.305767155579837
Validation loss: 3.8695914120441293

Epoch: 6| Step: 11
Training loss: 4.73305500627056
Validation loss: 3.864149318627829

Epoch: 6| Step: 12
Training loss: 4.046980572947256
Validation loss: 3.8591171270829188

Epoch: 6| Step: 13
Training loss: 4.17524725815706
Validation loss: 3.8586968167378735

Epoch: 6| Step: 0
Training loss: 4.639175548313127
Validation loss: 3.8541772675416937

Epoch: 6| Step: 1
Training loss: 2.5818473992849733
Validation loss: 3.8488914930980296

Epoch: 6| Step: 2
Training loss: 3.837941192216169
Validation loss: 3.84954653294619

Epoch: 6| Step: 3
Training loss: 3.8206504875093033
Validation loss: 3.843118261697132

Epoch: 6| Step: 4
Training loss: 4.246062081226773
Validation loss: 3.8406010723414132

Epoch: 6| Step: 5
Training loss: 4.088545191413024
Validation loss: 3.8339055817049394

Epoch: 6| Step: 6
Training loss: 3.1368057029899936
Validation loss: 3.8331679450725384

Epoch: 6| Step: 7
Training loss: 3.2365248165089695
Validation loss: 3.830998967686289

Epoch: 6| Step: 8
Training loss: 3.4782463881978973
Validation loss: 3.8276225406732154

Epoch: 6| Step: 9
Training loss: 4.5638588749884175
Validation loss: 3.82002220122016

Epoch: 6| Step: 10
Training loss: 4.560017367547407
Validation loss: 3.8202682047304104

Epoch: 6| Step: 11
Training loss: 4.4482759543518045
Validation loss: 3.8142009177257408

Epoch: 6| Step: 12
Training loss: 4.74528811803036
Validation loss: 3.809691009097136

Epoch: 6| Step: 13
Training loss: 3.8482821657378805
Validation loss: 3.8044627665829336

Epoch: 7| Step: 0
Training loss: 4.143347424590337
Validation loss: 3.8000755147657466

Epoch: 6| Step: 1
Training loss: 4.259433822617487
Validation loss: 3.797141088724914

Epoch: 6| Step: 2
Training loss: 3.642300854477341
Validation loss: 3.7925966905623683

Epoch: 6| Step: 3
Training loss: 4.493862629249631
Validation loss: 3.7863877302799933

Epoch: 6| Step: 4
Training loss: 4.361035321353942
Validation loss: 3.7836888203790138

Epoch: 6| Step: 5
Training loss: 3.423274620565463
Validation loss: 3.780718065035814

Epoch: 6| Step: 6
Training loss: 4.33969431842195
Validation loss: 3.7759042320940854

Epoch: 6| Step: 7
Training loss: 3.915759542943966
Validation loss: 3.772529460354559

Epoch: 6| Step: 8
Training loss: 4.252651509451467
Validation loss: 3.7633892044940587

Epoch: 6| Step: 9
Training loss: 4.610114810862734
Validation loss: 3.759817290678911

Epoch: 6| Step: 10
Training loss: 3.2397516499222325
Validation loss: 3.753221693462866

Epoch: 6| Step: 11
Training loss: 3.2170885853616857
Validation loss: 3.749002624831243

Epoch: 6| Step: 12
Training loss: 3.1918487802313344
Validation loss: 3.7412716913844144

Epoch: 6| Step: 13
Training loss: 3.565080879010904
Validation loss: 3.7403861820267523

Epoch: 8| Step: 0
Training loss: 3.490225631284515
Validation loss: 3.7370482367598625

Epoch: 6| Step: 1
Training loss: 4.108762282030243
Validation loss: 3.729349235116628

Epoch: 6| Step: 2
Training loss: 2.77546570452855
Validation loss: 3.7270734275113444

Epoch: 6| Step: 3
Training loss: 4.132205796012656
Validation loss: 3.7228064242108254

Epoch: 6| Step: 4
Training loss: 4.02673204958382
Validation loss: 3.7185400661168733

Epoch: 6| Step: 5
Training loss: 4.185053551990969
Validation loss: 3.713621962618841

Epoch: 6| Step: 6
Training loss: 3.9004969842627957
Validation loss: 3.7097188599506885

Epoch: 6| Step: 7
Training loss: 2.9605983247978607
Validation loss: 3.702331156041106

Epoch: 6| Step: 8
Training loss: 3.7500595088051707
Validation loss: 3.694543526040172

Epoch: 6| Step: 9
Training loss: 4.0512059429613245
Validation loss: 3.6876713076998264

Epoch: 6| Step: 10
Training loss: 4.025940703408742
Validation loss: 3.6860016367812083

Epoch: 6| Step: 11
Training loss: 4.725427614268926
Validation loss: 3.679979918720728

Epoch: 6| Step: 12
Training loss: 4.134257246144091
Validation loss: 3.6770795540748233

Epoch: 6| Step: 13
Training loss: 3.5192419816007305
Validation loss: 3.66890928805858

Epoch: 9| Step: 0
Training loss: 3.7165309151346846
Validation loss: 3.6616085567046714

Epoch: 6| Step: 1
Training loss: 4.229800297417158
Validation loss: 3.658958040100874

Epoch: 6| Step: 2
Training loss: 3.5372979689420485
Validation loss: 3.6514926415553477

Epoch: 6| Step: 3
Training loss: 4.61550423393762
Validation loss: 3.641397075248716

Epoch: 6| Step: 4
Training loss: 3.773376590718947
Validation loss: 3.6389099867160413

Epoch: 6| Step: 5
Training loss: 2.563332399220125
Validation loss: 3.6293329376390226

Epoch: 6| Step: 6
Training loss: 3.6876598258862052
Validation loss: 3.6226994672428776

Epoch: 6| Step: 7
Training loss: 4.1214947690698
Validation loss: 3.6239011794323166

Epoch: 6| Step: 8
Training loss: 4.524846886842165
Validation loss: 3.6165158567311337

Epoch: 6| Step: 9
Training loss: 4.3611558127626395
Validation loss: 3.6067602065996622

Epoch: 6| Step: 10
Training loss: 2.902524303298388
Validation loss: 3.602997241531707

Epoch: 6| Step: 11
Training loss: 3.469389435537602
Validation loss: 3.5923415496401567

Epoch: 6| Step: 12
Training loss: 3.25859108089977
Validation loss: 3.5901103903241305

Epoch: 6| Step: 13
Training loss: 4.145396581804276
Validation loss: 3.5799026146823496

Epoch: 10| Step: 0
Training loss: 3.0420606871802054
Validation loss: 3.573966538485084

Epoch: 6| Step: 1
Training loss: 4.033166710640699
Validation loss: 3.565992457249109

Epoch: 6| Step: 2
Training loss: 4.326642054373669
Validation loss: 3.5623152749182636

Epoch: 6| Step: 3
Training loss: 3.5330848990377506
Validation loss: 3.5520346360366957

Epoch: 6| Step: 4
Training loss: 4.170345183066128
Validation loss: 3.5472710602297166

Epoch: 6| Step: 5
Training loss: 3.6175123031818255
Validation loss: 3.5355858594726657

Epoch: 6| Step: 6
Training loss: 4.024267966477335
Validation loss: 3.527626198629501

Epoch: 6| Step: 7
Training loss: 3.446412341279413
Validation loss: 3.520455042222376

Epoch: 6| Step: 8
Training loss: 4.618307271549107
Validation loss: 3.5169058690738044

Epoch: 6| Step: 9
Training loss: 3.469090625431405
Validation loss: 3.5025827017048368

Epoch: 6| Step: 10
Training loss: 3.1961385316772293
Validation loss: 3.4957086269066258

Epoch: 6| Step: 11
Training loss: 3.3807047913822066
Validation loss: 3.491575199293533

Epoch: 6| Step: 12
Training loss: 3.3603894498463527
Validation loss: 3.482667925381296

Epoch: 6| Step: 13
Training loss: 3.392660628629431
Validation loss: 3.469886300259543

Epoch: 11| Step: 0
Training loss: 3.4597648201104123
Validation loss: 3.4625966114689564

Epoch: 6| Step: 1
Training loss: 2.9265315032311365
Validation loss: 3.46030631472121

Epoch: 6| Step: 2
Training loss: 4.042943274376258
Validation loss: 3.4502562042690585

Epoch: 6| Step: 3
Training loss: 3.580494458453553
Validation loss: 3.442496241720586

Epoch: 6| Step: 4
Training loss: 3.549633684197876
Validation loss: 3.4363651255546603

Epoch: 6| Step: 5
Training loss: 3.9330967093807643
Validation loss: 3.4257602276379613

Epoch: 6| Step: 6
Training loss: 3.9332100644165493
Validation loss: 3.418425443219698

Epoch: 6| Step: 7
Training loss: 3.349132590657206
Validation loss: 3.4077693022916993

Epoch: 6| Step: 8
Training loss: 3.4878694947002455
Validation loss: 3.3986310478242214

Epoch: 6| Step: 9
Training loss: 3.8593964981530537
Validation loss: 3.3910348477314707

Epoch: 6| Step: 10
Training loss: 3.141124780468711
Validation loss: 3.383619556497218

Epoch: 6| Step: 11
Training loss: 3.619957145732319
Validation loss: 3.3741430412259215

Epoch: 6| Step: 12
Training loss: 3.735415134262959
Validation loss: 3.360233681920418

Epoch: 6| Step: 13
Training loss: 3.969094929761998
Validation loss: 3.3485537702005197

Epoch: 12| Step: 0
Training loss: 3.0531320343405084
Validation loss: 3.3428529048315703

Epoch: 6| Step: 1
Training loss: 3.3697287756560432
Validation loss: 3.3320119074105077

Epoch: 6| Step: 2
Training loss: 3.6274800202905904
Validation loss: 3.320756529832399

Epoch: 6| Step: 3
Training loss: 3.896754817134175
Validation loss: 3.31140319627404

Epoch: 6| Step: 4
Training loss: 4.054259878552656
Validation loss: 3.298882486823452

Epoch: 6| Step: 5
Training loss: 4.07529488649168
Validation loss: 3.2874252394431474

Epoch: 6| Step: 6
Training loss: 4.166957743332274
Validation loss: 3.276632084021238

Epoch: 6| Step: 7
Training loss: 3.131805029616351
Validation loss: 3.2688350194213895

Epoch: 6| Step: 8
Training loss: 3.5062280827617545
Validation loss: 3.2549882522839035

Epoch: 6| Step: 9
Training loss: 2.312620829956656
Validation loss: 3.2420957965239285

Epoch: 6| Step: 10
Training loss: 3.0147664325385524
Validation loss: 3.227904687582108

Epoch: 6| Step: 11
Training loss: 3.367211857329246
Validation loss: 3.221348068503838

Epoch: 6| Step: 12
Training loss: 3.4820602323350016
Validation loss: 3.2076024721391514

Epoch: 6| Step: 13
Training loss: 3.4077553878538973
Validation loss: 3.1983679197549604

Epoch: 13| Step: 0
Training loss: 3.0676385237949564
Validation loss: 3.187741784567506

Epoch: 6| Step: 1
Training loss: 2.1016849070923906
Validation loss: 3.1735949546663784

Epoch: 6| Step: 2
Training loss: 3.056194587314392
Validation loss: 3.1674549182796454

Epoch: 6| Step: 3
Training loss: 4.00844921386035
Validation loss: 3.154049831326773

Epoch: 6| Step: 4
Training loss: 3.257046909161955
Validation loss: 3.1385222205197314

Epoch: 6| Step: 5
Training loss: 2.786766752958397
Validation loss: 3.1340333204058153

Epoch: 6| Step: 6
Training loss: 3.3848988924464143
Validation loss: 3.120389739518828

Epoch: 6| Step: 7
Training loss: 3.804750665222587
Validation loss: 3.113465460856963

Epoch: 6| Step: 8
Training loss: 3.5439240535667142
Validation loss: 3.101740946778685

Epoch: 6| Step: 9
Training loss: 3.748271162151571
Validation loss: 3.0893262614913755

Epoch: 6| Step: 10
Training loss: 2.95671452749824
Validation loss: 3.0733235824798997

Epoch: 6| Step: 11
Training loss: 3.6535801717341667
Validation loss: 3.0584966993851435

Epoch: 6| Step: 12
Training loss: 4.096111053540841
Validation loss: 3.045937527759933

Epoch: 6| Step: 13
Training loss: 2.249589140784967
Validation loss: 3.0384388928183026

Epoch: 14| Step: 0
Training loss: 3.114863626547285
Validation loss: 3.01946032802886

Epoch: 6| Step: 1
Training loss: 3.2865551885407642
Validation loss: 3.0158227091358207

Epoch: 6| Step: 2
Training loss: 3.6958717100494107
Validation loss: 2.9956428357617475

Epoch: 6| Step: 3
Training loss: 3.357791261175341
Validation loss: 2.9885301415941443

Epoch: 6| Step: 4
Training loss: 2.5380157660617626
Validation loss: 2.9730791393159506

Epoch: 6| Step: 5
Training loss: 3.7300407763341186
Validation loss: 2.9684082119470983

Epoch: 6| Step: 6
Training loss: 3.0183878679437632
Validation loss: 2.951486867926699

Epoch: 6| Step: 7
Training loss: 2.6793155690091752
Validation loss: 2.9339603522551645

Epoch: 6| Step: 8
Training loss: 3.0463322082622084
Validation loss: 2.9263191497024175

Epoch: 6| Step: 9
Training loss: 3.433891483109715
Validation loss: 2.9190064732677237

Epoch: 6| Step: 10
Training loss: 2.8819456373669303
Validation loss: 2.9073433902699897

Epoch: 6| Step: 11
Training loss: 3.7283346572848615
Validation loss: 2.8900501011001705

Epoch: 6| Step: 12
Training loss: 3.1718619210109815
Validation loss: 2.877830724001731

Epoch: 6| Step: 13
Training loss: 2.8669137434236567
Validation loss: 2.8741414900315836

Epoch: 15| Step: 0
Training loss: 3.243734041443011
Validation loss: 2.8496973410610766

Epoch: 6| Step: 1
Training loss: 3.056810972689333
Validation loss: 2.841301097191419

Epoch: 6| Step: 2
Training loss: 2.972408249243515
Validation loss: 2.829144813556741

Epoch: 6| Step: 3
Training loss: 3.344209015615578
Validation loss: 2.8198630205118214

Epoch: 6| Step: 4
Training loss: 2.6685139893423675
Validation loss: 2.8034682676591127

Epoch: 6| Step: 5
Training loss: 3.3733117861555892
Validation loss: 2.7946793492186455

Epoch: 6| Step: 6
Training loss: 2.257983244145329
Validation loss: 2.768813728997781

Epoch: 6| Step: 7
Training loss: 3.7158833201376162
Validation loss: 2.7586619809975375

Epoch: 6| Step: 8
Training loss: 3.3820400986056716
Validation loss: 2.7536021307664806

Epoch: 6| Step: 9
Training loss: 3.4045837246475177
Validation loss: 2.7376227119232643

Epoch: 6| Step: 10
Training loss: 2.371835507753918
Validation loss: 2.7378113589101534

Epoch: 6| Step: 11
Training loss: 3.330383537360286
Validation loss: 2.7179981125983788

Epoch: 6| Step: 12
Training loss: 2.830323939839953
Validation loss: 2.705612241835312

Epoch: 6| Step: 13
Training loss: 2.4200783248710653
Validation loss: 2.702560914122736

Epoch: 16| Step: 0
Training loss: 3.4729326479307066
Validation loss: 2.6790723087019956

Epoch: 6| Step: 1
Training loss: 2.6613059003342343
Validation loss: 2.6742747075970987

Epoch: 6| Step: 2
Training loss: 3.0323767386825033
Validation loss: 2.6744036996900706

Epoch: 6| Step: 3
Training loss: 3.0991501350779083
Validation loss: 2.6529623997946277

Epoch: 6| Step: 4
Training loss: 2.245007167541345
Validation loss: 2.6441905165279778

Epoch: 6| Step: 5
Training loss: 2.8826204561604882
Validation loss: 2.650943524052808

Epoch: 6| Step: 6
Training loss: 3.5087544083576074
Validation loss: 2.6318124151102356

Epoch: 6| Step: 7
Training loss: 3.2829127866958743
Validation loss: 2.6314028358359263

Epoch: 6| Step: 8
Training loss: 2.5299093204577057
Validation loss: 2.6129725233854866

Epoch: 6| Step: 9
Training loss: 3.1670152238119167
Validation loss: 2.607910117420516

Epoch: 6| Step: 10
Training loss: 2.6705238539889735
Validation loss: 2.5928087954540375

Epoch: 6| Step: 11
Training loss: 2.4257018341972154
Validation loss: 2.5851083513071798

Epoch: 6| Step: 12
Training loss: 3.1735086978680767
Validation loss: 2.586486834394384

Epoch: 6| Step: 13
Training loss: 3.242863669607942
Validation loss: 2.5889974474164617

Epoch: 17| Step: 0
Training loss: 2.300551398151032
Validation loss: 2.5804067796733485

Epoch: 6| Step: 1
Training loss: 3.038819604890105
Validation loss: 2.5749675947412873

Epoch: 6| Step: 2
Training loss: 2.9409310614357618
Validation loss: 2.574994219964535

Epoch: 6| Step: 3
Training loss: 3.478475048893047
Validation loss: 2.567250564133435

Epoch: 6| Step: 4
Training loss: 3.5735647134692465
Validation loss: 2.5597473945393574

Epoch: 6| Step: 5
Training loss: 2.1426475604063384
Validation loss: 2.5466502231557104

Epoch: 6| Step: 6
Training loss: 2.2478964827382364
Validation loss: 2.539110636037911

Epoch: 6| Step: 7
Training loss: 2.8266461125412277
Validation loss: 2.5527984507909856

Epoch: 6| Step: 8
Training loss: 3.1452890561059665
Validation loss: 2.528077623385877

Epoch: 6| Step: 9
Training loss: 2.568968540371734
Validation loss: 2.523202810851163

Epoch: 6| Step: 10
Training loss: 3.3958755833780487
Validation loss: 2.524566326792435

Epoch: 6| Step: 11
Training loss: 3.199352890388356
Validation loss: 2.520318553259092

Epoch: 6| Step: 12
Training loss: 2.421983384199029
Validation loss: 2.5135950606352266

Epoch: 6| Step: 13
Training loss: 2.9051196453517356
Validation loss: 2.5090493595937655

Epoch: 18| Step: 0
Training loss: 2.935802699837066
Validation loss: 2.511964505553135

Epoch: 6| Step: 1
Training loss: 2.907106662952062
Validation loss: 2.5134752469169737

Epoch: 6| Step: 2
Training loss: 3.051088520357549
Validation loss: 2.5125814206827837

Epoch: 6| Step: 3
Training loss: 3.03316759627856
Validation loss: 2.5066452992838095

Epoch: 6| Step: 4
Training loss: 2.630477458417145
Validation loss: 2.490804892487504

Epoch: 6| Step: 5
Training loss: 2.616071776376568
Validation loss: 2.4972066819938306

Epoch: 6| Step: 6
Training loss: 2.6130027907743854
Validation loss: 2.490058948917657

Epoch: 6| Step: 7
Training loss: 3.496989726757551
Validation loss: 2.5048286935395128

Epoch: 6| Step: 8
Training loss: 2.666793184458044
Validation loss: 2.486174337571855

Epoch: 6| Step: 9
Training loss: 3.4155599771158154
Validation loss: 2.4987127589449534

Epoch: 6| Step: 10
Training loss: 1.8614311710105722
Validation loss: 2.488168446096037

Epoch: 6| Step: 11
Training loss: 3.1730959191453962
Validation loss: 2.4852309349076758

Epoch: 6| Step: 12
Training loss: 2.8625479015356974
Validation loss: 2.4902096735907246

Epoch: 6| Step: 13
Training loss: 2.4720155389044303
Validation loss: 2.4748509242510774

Epoch: 19| Step: 0
Training loss: 2.9171858915744426
Validation loss: 2.4816754105670213

Epoch: 6| Step: 1
Training loss: 2.61966144296255
Validation loss: 2.493442019701837

Epoch: 6| Step: 2
Training loss: 3.147569408908869
Validation loss: 2.482671400066185

Epoch: 6| Step: 3
Training loss: 2.956292285576443
Validation loss: 2.4655291844551086

Epoch: 6| Step: 4
Training loss: 3.695780492589063
Validation loss: 2.470734066509843

Epoch: 6| Step: 5
Training loss: 2.477522606770587
Validation loss: 2.470101880068216

Epoch: 6| Step: 6
Training loss: 2.8916729651244184
Validation loss: 2.480022507779427

Epoch: 6| Step: 7
Training loss: 2.4309194698074563
Validation loss: 2.480892209264853

Epoch: 6| Step: 8
Training loss: 2.947342312309959
Validation loss: 2.4844260530081956

Epoch: 6| Step: 9
Training loss: 3.2664049303206792
Validation loss: 2.470844301049554

Epoch: 6| Step: 10
Training loss: 2.0958059664305235
Validation loss: 2.4850494981921094

Epoch: 6| Step: 11
Training loss: 2.871295864750292
Validation loss: 2.4732026310036512

Epoch: 6| Step: 12
Training loss: 2.6438490468042226
Validation loss: 2.4744326660834037

Epoch: 6| Step: 13
Training loss: 3.1859087992783683
Validation loss: 2.482358722485836

Epoch: 20| Step: 0
Training loss: 2.5271359200495214
Validation loss: 2.4744804897764077

Epoch: 6| Step: 1
Training loss: 3.704675148790896
Validation loss: 2.489058985930811

Epoch: 6| Step: 2
Training loss: 3.3089456742623815
Validation loss: 2.4718957435939863

Epoch: 6| Step: 3
Training loss: 2.3966150970994526
Validation loss: 2.4825470599303348

Epoch: 6| Step: 4
Training loss: 2.617555324840542
Validation loss: 2.4870777258563765

Epoch: 6| Step: 5
Training loss: 3.3199399492279213
Validation loss: 2.478165866502585

Epoch: 6| Step: 6
Training loss: 2.7758650350769303
Validation loss: 2.4728611891616614

Epoch: 6| Step: 7
Training loss: 3.271635665811456
Validation loss: 2.466133128471527

Epoch: 6| Step: 8
Training loss: 2.735472104822308
Validation loss: 2.4612391039470696

Epoch: 6| Step: 9
Training loss: 2.6910405457276187
Validation loss: 2.4650737514144647

Epoch: 6| Step: 10
Training loss: 2.8972522543446533
Validation loss: 2.4583369439795333

Epoch: 6| Step: 11
Training loss: 2.520388813601686
Validation loss: 2.4551050135068038

Epoch: 6| Step: 12
Training loss: 2.7856349025496385
Validation loss: 2.4505287248658023

Epoch: 6| Step: 13
Training loss: 2.250304731290185
Validation loss: 2.4575252285829907

Epoch: 21| Step: 0
Training loss: 2.5342897600733614
Validation loss: 2.468693486588797

Epoch: 6| Step: 1
Training loss: 3.54263630477573
Validation loss: 2.4780730160797506

Epoch: 6| Step: 2
Training loss: 2.6879081416158725
Validation loss: 2.4662162454605125

Epoch: 6| Step: 3
Training loss: 2.1278580911329015
Validation loss: 2.4596603827354673

Epoch: 6| Step: 4
Training loss: 2.4362822204933168
Validation loss: 2.486262537209546

Epoch: 6| Step: 5
Training loss: 2.9514286073492926
Validation loss: 2.4681336929187774

Epoch: 6| Step: 6
Training loss: 2.94396148375526
Validation loss: 2.4801051396468656

Epoch: 6| Step: 7
Training loss: 2.535095402203378
Validation loss: 2.4591391612104854

Epoch: 6| Step: 8
Training loss: 3.16771481551051
Validation loss: 2.47781551648473

Epoch: 6| Step: 9
Training loss: 3.160114905767094
Validation loss: 2.4544468600996137

Epoch: 6| Step: 10
Training loss: 2.6787441361470377
Validation loss: 2.46698876669442

Epoch: 6| Step: 11
Training loss: 3.0791607193809822
Validation loss: 2.463260883257912

Epoch: 6| Step: 12
Training loss: 2.844998766692687
Validation loss: 2.467296341632774

Epoch: 6| Step: 13
Training loss: 3.1660577958326557
Validation loss: 2.4511154782119755

Epoch: 22| Step: 0
Training loss: 2.9044556359494855
Validation loss: 2.473081544556013

Epoch: 6| Step: 1
Training loss: 3.1190548612093836
Validation loss: 2.470133993582863

Epoch: 6| Step: 2
Training loss: 2.8228432245777366
Validation loss: 2.47068877991972

Epoch: 6| Step: 3
Training loss: 2.487768386854142
Validation loss: 2.470098326404328

Epoch: 6| Step: 4
Training loss: 2.0891751084260486
Validation loss: 2.4963780407384966

Epoch: 6| Step: 5
Training loss: 2.862603038282667
Validation loss: 2.46858617494221

Epoch: 6| Step: 6
Training loss: 2.824859926245065
Validation loss: 2.490464778940644

Epoch: 6| Step: 7
Training loss: 2.616570516710929
Validation loss: 2.4777948215807757

Epoch: 6| Step: 8
Training loss: 2.9706252750626945
Validation loss: 2.472158983120076

Epoch: 6| Step: 9
Training loss: 3.1340092302002667
Validation loss: 2.483354153008684

Epoch: 6| Step: 10
Training loss: 2.5028376687020724
Validation loss: 2.4828053946066744

Epoch: 6| Step: 11
Training loss: 3.692098046121979
Validation loss: 2.4808002235264137

Epoch: 6| Step: 12
Training loss: 2.5780092155581853
Validation loss: 2.465681162713008

Epoch: 6| Step: 13
Training loss: 3.4474183305412693
Validation loss: 2.482752260667254

Epoch: 23| Step: 0
Training loss: 3.0894900190615373
Validation loss: 2.4741247602785665

Epoch: 6| Step: 1
Training loss: 2.9494410551046144
Validation loss: 2.4738829587756834

Epoch: 6| Step: 2
Training loss: 2.73689197772837
Validation loss: 2.4743936874322654

Epoch: 6| Step: 3
Training loss: 2.3827032345593295
Validation loss: 2.459202659812425

Epoch: 6| Step: 4
Training loss: 3.0216503923766562
Validation loss: 2.4764150017437774

Epoch: 6| Step: 5
Training loss: 2.519159901776339
Validation loss: 2.4841087736802963

Epoch: 6| Step: 6
Training loss: 2.6482262991355374
Validation loss: 2.4799276976080384

Epoch: 6| Step: 7
Training loss: 3.2600922509463097
Validation loss: 2.471810162477982

Epoch: 6| Step: 8
Training loss: 3.2295293952914053
Validation loss: 2.478119517762556

Epoch: 6| Step: 9
Training loss: 2.8565846987893466
Validation loss: 2.464842282443278

Epoch: 6| Step: 10
Training loss: 2.3092909533082335
Validation loss: 2.468538250038544

Epoch: 6| Step: 11
Training loss: 2.7093212575543237
Validation loss: 2.4703829167621283

Epoch: 6| Step: 12
Training loss: 3.2421860292730096
Validation loss: 2.461282742671858

Epoch: 6| Step: 13
Training loss: 2.8922932527684266
Validation loss: 2.470206283269329

Epoch: 24| Step: 0
Training loss: 2.6904367768735997
Validation loss: 2.472100120473567

Epoch: 6| Step: 1
Training loss: 3.02822599291806
Validation loss: 2.462556997884358

Epoch: 6| Step: 2
Training loss: 3.2878465012966873
Validation loss: 2.4857487759266004

Epoch: 6| Step: 3
Training loss: 3.1091334570224967
Validation loss: 2.4762066761841086

Epoch: 6| Step: 4
Training loss: 2.2607232045639307
Validation loss: 2.474001847528346

Epoch: 6| Step: 5
Training loss: 2.7108433072219085
Validation loss: 2.4731636018688623

Epoch: 6| Step: 6
Training loss: 2.926505922176926
Validation loss: 2.4777814725414244

Epoch: 6| Step: 7
Training loss: 2.900899905308716
Validation loss: 2.469147626933213

Epoch: 6| Step: 8
Training loss: 3.194102013704352
Validation loss: 2.4632539143809673

Epoch: 6| Step: 9
Training loss: 2.9894071165956038
Validation loss: 2.4582584678035926

Epoch: 6| Step: 10
Training loss: 2.966354367252284
Validation loss: 2.4722472570928504

Epoch: 6| Step: 11
Training loss: 2.3249660284370246
Validation loss: 2.471837736023402

Epoch: 6| Step: 12
Training loss: 2.8050394076538767
Validation loss: 2.4780900299001196

Epoch: 6| Step: 13
Training loss: 2.4867741738296174
Validation loss: 2.462581428042291

Epoch: 25| Step: 0
Training loss: 2.491763853221193
Validation loss: 2.4572936693162752

Epoch: 6| Step: 1
Training loss: 2.5310013260372553
Validation loss: 2.4572873053117115

Epoch: 6| Step: 2
Training loss: 3.2756587756402085
Validation loss: 2.4598337672810464

Epoch: 6| Step: 3
Training loss: 2.758654846707529
Validation loss: 2.46625423902399

Epoch: 6| Step: 4
Training loss: 2.81113892576239
Validation loss: 2.4866347486069613

Epoch: 6| Step: 5
Training loss: 3.0194402880865705
Validation loss: 2.464759884648121

Epoch: 6| Step: 6
Training loss: 3.04574438783651
Validation loss: 2.46305290333495

Epoch: 6| Step: 7
Training loss: 3.2605636287307678
Validation loss: 2.457423560264647

Epoch: 6| Step: 8
Training loss: 2.6900367297533085
Validation loss: 2.4616039940749888

Epoch: 6| Step: 9
Training loss: 2.8205206205131255
Validation loss: 2.4651738614932563

Epoch: 6| Step: 10
Training loss: 2.9453918284451204
Validation loss: 2.4535835349122

Epoch: 6| Step: 11
Training loss: 3.026077419120137
Validation loss: 2.467079561129504

Epoch: 6| Step: 12
Training loss: 2.5861524970811716
Validation loss: 2.4778440081659965

Epoch: 6| Step: 13
Training loss: 1.9159325631245585
Validation loss: 2.4729467131713614

Epoch: 26| Step: 0
Training loss: 2.9854044312152954
Validation loss: 2.4763088518900926

Epoch: 6| Step: 1
Training loss: 2.9558996658331718
Validation loss: 2.445695744497346

Epoch: 6| Step: 2
Training loss: 2.8753902336320376
Validation loss: 2.4789541837144973

Epoch: 6| Step: 3
Training loss: 2.578134247734361
Validation loss: 2.4722022958370085

Epoch: 6| Step: 4
Training loss: 3.3591701711265576
Validation loss: 2.456185653274939

Epoch: 6| Step: 5
Training loss: 2.529285374913528
Validation loss: 2.4867657677743784

Epoch: 6| Step: 6
Training loss: 3.255894231123409
Validation loss: 2.4669298508291795

Epoch: 6| Step: 7
Training loss: 2.220721376422909
Validation loss: 2.4639332096429256

Epoch: 6| Step: 8
Training loss: 2.8486982618574004
Validation loss: 2.4706143315063485

Epoch: 6| Step: 9
Training loss: 2.7772971362616494
Validation loss: 2.4765844266808537

Epoch: 6| Step: 10
Training loss: 2.8176239809582984
Validation loss: 2.463802293074842

Epoch: 6| Step: 11
Training loss: 2.9478986400327165
Validation loss: 2.47253741370963

Epoch: 6| Step: 12
Training loss: 2.347497207916192
Validation loss: 2.4511689841758324

Epoch: 6| Step: 13
Training loss: 3.377487255103449
Validation loss: 2.457298287904021

Epoch: 27| Step: 0
Training loss: 3.0732507211610947
Validation loss: 2.450176548074579

Epoch: 6| Step: 1
Training loss: 2.66719296348115
Validation loss: 2.459626464813563

Epoch: 6| Step: 2
Training loss: 2.1277945599448866
Validation loss: 2.466556424496312

Epoch: 6| Step: 3
Training loss: 3.189146028253703
Validation loss: 2.4655239085384477

Epoch: 6| Step: 4
Training loss: 2.86745424614932
Validation loss: 2.463588963290272

Epoch: 6| Step: 5
Training loss: 2.871953262076314
Validation loss: 2.4681510110367055

Epoch: 6| Step: 6
Training loss: 2.779738454796637
Validation loss: 2.4663780503206056

Epoch: 6| Step: 7
Training loss: 3.0345189666381587
Validation loss: 2.4804226385986436

Epoch: 6| Step: 8
Training loss: 3.2145030326645014
Validation loss: 2.4810582203458025

Epoch: 6| Step: 9
Training loss: 2.8499391716606035
Validation loss: 2.482109938556274

Epoch: 6| Step: 10
Training loss: 2.7733710482521015
Validation loss: 2.457769225610228

Epoch: 6| Step: 11
Training loss: 2.9158579840594303
Validation loss: 2.4629668723554836

Epoch: 6| Step: 12
Training loss: 2.53947187204663
Validation loss: 2.457898187127727

Epoch: 6| Step: 13
Training loss: 2.709059534769815
Validation loss: 2.4758619572342204

Epoch: 28| Step: 0
Training loss: 2.473927922647521
Validation loss: 2.456733035353747

Epoch: 6| Step: 1
Training loss: 3.281124148907199
Validation loss: 2.459503304908591

Epoch: 6| Step: 2
Training loss: 3.0432849567937392
Validation loss: 2.456626216629826

Epoch: 6| Step: 3
Training loss: 2.9513098572764647
Validation loss: 2.4591156392800424

Epoch: 6| Step: 4
Training loss: 2.754136182776961
Validation loss: 2.4625677144116516

Epoch: 6| Step: 5
Training loss: 2.9187801514728435
Validation loss: 2.448540910672663

Epoch: 6| Step: 6
Training loss: 2.9764870461339528
Validation loss: 2.464184781145476

Epoch: 6| Step: 7
Training loss: 2.46704602889845
Validation loss: 2.469800358825131

Epoch: 6| Step: 8
Training loss: 2.924232225644378
Validation loss: 2.4639317503878444

Epoch: 6| Step: 9
Training loss: 3.1907938973224876
Validation loss: 2.461121854893915

Epoch: 6| Step: 10
Training loss: 2.1893823426755397
Validation loss: 2.470923198700994

Epoch: 6| Step: 11
Training loss: 1.6877458181418414
Validation loss: 2.4549543567993584

Epoch: 6| Step: 12
Training loss: 3.222226237882838
Validation loss: 2.47020018396713

Epoch: 6| Step: 13
Training loss: 3.256797284721905
Validation loss: 2.4565325364114026

Epoch: 29| Step: 0
Training loss: 2.2741360459643127
Validation loss: 2.46164973002461

Epoch: 6| Step: 1
Training loss: 2.7465864149270574
Validation loss: 2.4515034614942075

Epoch: 6| Step: 2
Training loss: 2.836151367194057
Validation loss: 2.468950586671009

Epoch: 6| Step: 3
Training loss: 2.4971796339300445
Validation loss: 2.459893308532376

Epoch: 6| Step: 4
Training loss: 2.037560505348924
Validation loss: 2.4626585911662255

Epoch: 6| Step: 5
Training loss: 2.9397405642268737
Validation loss: 2.4604760407461

Epoch: 6| Step: 6
Training loss: 3.702816205891707
Validation loss: 2.4788901113692927

Epoch: 6| Step: 7
Training loss: 3.4598450325015686
Validation loss: 2.468439464008081

Epoch: 6| Step: 8
Training loss: 2.7863345870351255
Validation loss: 2.464862880161588

Epoch: 6| Step: 9
Training loss: 2.445656066744005
Validation loss: 2.454735173072735

Epoch: 6| Step: 10
Training loss: 3.4533948145613556
Validation loss: 2.4516040295050083

Epoch: 6| Step: 11
Training loss: 3.113309738047985
Validation loss: 2.4572395747521125

Epoch: 6| Step: 12
Training loss: 2.5552890081120037
Validation loss: 2.4333077236647864

Epoch: 6| Step: 13
Training loss: 2.100680935678755
Validation loss: 2.4511907489440374

Epoch: 30| Step: 0
Training loss: 2.7731024741254573
Validation loss: 2.4515230596705346

Epoch: 6| Step: 1
Training loss: 2.6888275416218095
Validation loss: 2.4647677541668536

Epoch: 6| Step: 2
Training loss: 2.415813218614524
Validation loss: 2.4484696346014156

Epoch: 6| Step: 3
Training loss: 3.055356315898696
Validation loss: 2.43816621098985

Epoch: 6| Step: 4
Training loss: 2.8618386916493885
Validation loss: 2.46390195122162

Epoch: 6| Step: 5
Training loss: 2.656602813626624
Validation loss: 2.4615758393200196

Epoch: 6| Step: 6
Training loss: 3.54892661294439
Validation loss: 2.4419530910593497

Epoch: 6| Step: 7
Training loss: 2.678488949913658
Validation loss: 2.45002822935053

Epoch: 6| Step: 8
Training loss: 2.1525928609314073
Validation loss: 2.4480968444814137

Epoch: 6| Step: 9
Training loss: 2.5643646155232402
Validation loss: 2.455270441828763

Epoch: 6| Step: 10
Training loss: 2.647748739428648
Validation loss: 2.4720200781334856

Epoch: 6| Step: 11
Training loss: 2.963395439701468
Validation loss: 2.452002072958373

Epoch: 6| Step: 12
Training loss: 3.3615814769606756
Validation loss: 2.4623787192068023

Epoch: 6| Step: 13
Training loss: 3.119465925037602
Validation loss: 2.453704376807077

Epoch: 31| Step: 0
Training loss: 2.101850411926065
Validation loss: 2.459030671560146

Epoch: 6| Step: 1
Training loss: 2.539699814847442
Validation loss: 2.465436191910317

Epoch: 6| Step: 2
Training loss: 3.207117337408434
Validation loss: 2.4540914681702515

Epoch: 6| Step: 3
Training loss: 3.2513609750852974
Validation loss: 2.457361621251571

Epoch: 6| Step: 4
Training loss: 2.818280700727531
Validation loss: 2.4482465844168644

Epoch: 6| Step: 5
Training loss: 3.8725464959797953
Validation loss: 2.452877899886256

Epoch: 6| Step: 6
Training loss: 3.149599679607659
Validation loss: 2.4644374405594607

Epoch: 6| Step: 7
Training loss: 2.9066309525398464
Validation loss: 2.4628707186098633

Epoch: 6| Step: 8
Training loss: 2.6114650738911522
Validation loss: 2.439680870288399

Epoch: 6| Step: 9
Training loss: 2.124808134505201
Validation loss: 2.450298830240639

Epoch: 6| Step: 10
Training loss: 2.1842704911669624
Validation loss: 2.4485577799989837

Epoch: 6| Step: 11
Training loss: 3.039441082671572
Validation loss: 2.447942980692719

Epoch: 6| Step: 12
Training loss: 2.432078273868793
Validation loss: 2.4458153598247496

Epoch: 6| Step: 13
Training loss: 2.781939388944955
Validation loss: 2.4467121149731574

Epoch: 32| Step: 0
Training loss: 2.560881312779749
Validation loss: 2.4528691351903937

Epoch: 6| Step: 1
Training loss: 2.5782196027564916
Validation loss: 2.4615100075512424

Epoch: 6| Step: 2
Training loss: 2.515037325815293
Validation loss: 2.4550220884054528

Epoch: 6| Step: 3
Training loss: 3.1556897563186985
Validation loss: 2.4558495452773443

Epoch: 6| Step: 4
Training loss: 3.1875550508420143
Validation loss: 2.4455288508216935

Epoch: 6| Step: 5
Training loss: 2.4705678307200887
Validation loss: 2.4510182926304696

Epoch: 6| Step: 6
Training loss: 2.6854257785197633
Validation loss: 2.4448803952319875

Epoch: 6| Step: 7
Training loss: 2.9173048865182603
Validation loss: 2.453608747149658

Epoch: 6| Step: 8
Training loss: 3.2269861714409913
Validation loss: 2.4630920593733685

Epoch: 6| Step: 9
Training loss: 2.5661309731849826
Validation loss: 2.473614406200224

Epoch: 6| Step: 10
Training loss: 2.7204773775690976
Validation loss: 2.4623498684612697

Epoch: 6| Step: 11
Training loss: 2.7401835626525552
Validation loss: 2.466924750416113

Epoch: 6| Step: 12
Training loss: 3.0732071216620396
Validation loss: 2.450429896495688

Epoch: 6| Step: 13
Training loss: 2.8143807798322458
Validation loss: 2.43947893411134

Epoch: 33| Step: 0
Training loss: 3.1215529694823663
Validation loss: 2.459593884740588

Epoch: 6| Step: 1
Training loss: 2.7457793531963213
Validation loss: 2.44946673627202

Epoch: 6| Step: 2
Training loss: 3.4466165509690896
Validation loss: 2.4557960306368813

Epoch: 6| Step: 3
Training loss: 2.2018493855286136
Validation loss: 2.448267314427933

Epoch: 6| Step: 4
Training loss: 3.665429744739769
Validation loss: 2.4495278879858633

Epoch: 6| Step: 5
Training loss: 2.858307519319781
Validation loss: 2.4683922419760744

Epoch: 6| Step: 6
Training loss: 2.864709099985383
Validation loss: 2.458059254616366

Epoch: 6| Step: 7
Training loss: 2.701917168991685
Validation loss: 2.4649904159781912

Epoch: 6| Step: 8
Training loss: 2.235655091136251
Validation loss: 2.4493983952353666

Epoch: 6| Step: 9
Training loss: 2.3583290863897504
Validation loss: 2.446613585098673

Epoch: 6| Step: 10
Training loss: 2.2702967391809263
Validation loss: 2.4306917157296293

Epoch: 6| Step: 11
Training loss: 2.606104920372077
Validation loss: 2.4464487471490597

Epoch: 6| Step: 12
Training loss: 3.040183206358238
Validation loss: 2.4570667688090184

Epoch: 6| Step: 13
Training loss: 2.941055418777137
Validation loss: 2.4631620078698115

Epoch: 34| Step: 0
Training loss: 2.139883762304466
Validation loss: 2.454192818036556

Epoch: 6| Step: 1
Training loss: 2.6953405406433153
Validation loss: 2.4545729412026445

Epoch: 6| Step: 2
Training loss: 2.9481674644803686
Validation loss: 2.4564690794125936

Epoch: 6| Step: 3
Training loss: 2.7344489387324744
Validation loss: 2.456827739924952

Epoch: 6| Step: 4
Training loss: 2.594772321235112
Validation loss: 2.437387920313375

Epoch: 6| Step: 5
Training loss: 3.0346910274792696
Validation loss: 2.4529390846595795

Epoch: 6| Step: 6
Training loss: 2.8070145413002052
Validation loss: 2.449948349065659

Epoch: 6| Step: 7
Training loss: 3.057248654081925
Validation loss: 2.4611952759145574

Epoch: 6| Step: 8
Training loss: 2.781527130378647
Validation loss: 2.4559400865874683

Epoch: 6| Step: 9
Training loss: 3.0770785494185864
Validation loss: 2.4592786660387342

Epoch: 6| Step: 10
Training loss: 2.5787962993213625
Validation loss: 2.4512596900034183

Epoch: 6| Step: 11
Training loss: 2.7763014070095986
Validation loss: 2.4353084782884684

Epoch: 6| Step: 12
Training loss: 3.476816780992186
Validation loss: 2.4585986347929984

Epoch: 6| Step: 13
Training loss: 2.4553906128819123
Validation loss: 2.443879437622823

Epoch: 35| Step: 0
Training loss: 3.3729726565644067
Validation loss: 2.4584002234561884

Epoch: 6| Step: 1
Training loss: 2.771364968908562
Validation loss: 2.447091926155137

Epoch: 6| Step: 2
Training loss: 2.3560642482889618
Validation loss: 2.4545676010032933

Epoch: 6| Step: 3
Training loss: 2.538275494015673
Validation loss: 2.452749044415045

Epoch: 6| Step: 4
Training loss: 3.3228491573989856
Validation loss: 2.4444000398431696

Epoch: 6| Step: 5
Training loss: 2.6649343904073475
Validation loss: 2.462278583983634

Epoch: 6| Step: 6
Training loss: 3.0804920680348435
Validation loss: 2.440945740548453

Epoch: 6| Step: 7
Training loss: 2.911680009531486
Validation loss: 2.4485454300762566

Epoch: 6| Step: 8
Training loss: 2.993084247763331
Validation loss: 2.443437225414931

Epoch: 6| Step: 9
Training loss: 2.70818160194462
Validation loss: 2.4516041403491324

Epoch: 6| Step: 10
Training loss: 2.3474632856689106
Validation loss: 2.4620928277644807

Epoch: 6| Step: 11
Training loss: 2.833559662998034
Validation loss: 2.463863369922159

Epoch: 6| Step: 12
Training loss: 2.4734893889776957
Validation loss: 2.4541044059951

Epoch: 6| Step: 13
Training loss: 2.6243466972102225
Validation loss: 2.4348359549012657

Epoch: 36| Step: 0
Training loss: 2.9219399511288606
Validation loss: 2.462646507667608

Epoch: 6| Step: 1
Training loss: 2.460114647279429
Validation loss: 2.4342500272528675

Epoch: 6| Step: 2
Training loss: 3.3372335663363057
Validation loss: 2.4349982604617133

Epoch: 6| Step: 3
Training loss: 2.9456571584751474
Validation loss: 2.4469167419107682

Epoch: 6| Step: 4
Training loss: 2.6441701532632047
Validation loss: 2.4413464006861094

Epoch: 6| Step: 5
Training loss: 2.2082736409114996
Validation loss: 2.4541011446459238

Epoch: 6| Step: 6
Training loss: 2.9383959114160505
Validation loss: 2.461009732729552

Epoch: 6| Step: 7
Training loss: 2.608309956731236
Validation loss: 2.4514001410328317

Epoch: 6| Step: 8
Training loss: 3.5213484227431215
Validation loss: 2.4353251382057985

Epoch: 6| Step: 9
Training loss: 3.0142858822925187
Validation loss: 2.451252444370226

Epoch: 6| Step: 10
Training loss: 2.166028723578237
Validation loss: 2.440273527551863

Epoch: 6| Step: 11
Training loss: 2.660443485117867
Validation loss: 2.457072148441682

Epoch: 6| Step: 12
Training loss: 2.7461927241454513
Validation loss: 2.435040421750191

Epoch: 6| Step: 13
Training loss: 2.7637577973613365
Validation loss: 2.4467326997700973

Epoch: 37| Step: 0
Training loss: 2.9337260575814876
Validation loss: 2.4439020802810165

Epoch: 6| Step: 1
Training loss: 2.3918699127214933
Validation loss: 2.451915603002926

Epoch: 6| Step: 2
Training loss: 2.3117841695209687
Validation loss: 2.439555486539396

Epoch: 6| Step: 3
Training loss: 2.7894560378651994
Validation loss: 2.436979610066985

Epoch: 6| Step: 4
Training loss: 2.834332981660365
Validation loss: 2.4581399100747414

Epoch: 6| Step: 5
Training loss: 3.044333625626648
Validation loss: 2.4491491244885966

Epoch: 6| Step: 6
Training loss: 3.3425316418082356
Validation loss: 2.459118117313455

Epoch: 6| Step: 7
Training loss: 2.4853682541801967
Validation loss: 2.4495745181638204

Epoch: 6| Step: 8
Training loss: 2.5151965801244884
Validation loss: 2.4573000526049524

Epoch: 6| Step: 9
Training loss: 2.8016616522906572
Validation loss: 2.4539658836316423

Epoch: 6| Step: 10
Training loss: 2.7192337658064276
Validation loss: 2.4401602383643897

Epoch: 6| Step: 11
Training loss: 3.1632672852942556
Validation loss: 2.4456845462787324

Epoch: 6| Step: 12
Training loss: 2.6607633057684277
Validation loss: 2.451896977734644

Epoch: 6| Step: 13
Training loss: 3.1784533605797742
Validation loss: 2.454715961894869

Epoch: 38| Step: 0
Training loss: 2.5491976766039697
Validation loss: 2.4499239410010794

Epoch: 6| Step: 1
Training loss: 2.6065203190312847
Validation loss: 2.4353563249783443

Epoch: 6| Step: 2
Training loss: 3.2986081164608576
Validation loss: 2.4408922541512617

Epoch: 6| Step: 3
Training loss: 3.0403397335150606
Validation loss: 2.4332370591795156

Epoch: 6| Step: 4
Training loss: 2.5001369438811105
Validation loss: 2.44031746345178

Epoch: 6| Step: 5
Training loss: 2.49007275823591
Validation loss: 2.4379114235525194

Epoch: 6| Step: 6
Training loss: 3.081908403663116
Validation loss: 2.4453310102999084

Epoch: 6| Step: 7
Training loss: 3.287446628615974
Validation loss: 2.439492289922367

Epoch: 6| Step: 8
Training loss: 3.141884774108824
Validation loss: 2.4425806672091954

Epoch: 6| Step: 9
Training loss: 2.965185977448864
Validation loss: 2.4537692279914953

Epoch: 6| Step: 10
Training loss: 2.507157189619732
Validation loss: 2.4434764555275383

Epoch: 6| Step: 11
Training loss: 2.584819171564758
Validation loss: 2.4486102613716505

Epoch: 6| Step: 12
Training loss: 2.596809604890962
Validation loss: 2.432644538203483

Epoch: 6| Step: 13
Training loss: 2.2366075366182745
Validation loss: 2.4440234931711666

Epoch: 39| Step: 0
Training loss: 2.029240597338321
Validation loss: 2.4437341996769937

Epoch: 6| Step: 1
Training loss: 3.1375962261626618
Validation loss: 2.444235045271248

Epoch: 6| Step: 2
Training loss: 2.581691055855782
Validation loss: 2.454532708211964

Epoch: 6| Step: 3
Training loss: 2.5428946816810134
Validation loss: 2.443906846908854

Epoch: 6| Step: 4
Training loss: 3.409452560199937
Validation loss: 2.4327749822746707

Epoch: 6| Step: 5
Training loss: 2.8106456153390122
Validation loss: 2.443841010186245

Epoch: 6| Step: 6
Training loss: 3.0181204003042064
Validation loss: 2.4325407792622307

Epoch: 6| Step: 7
Training loss: 3.3197894234116565
Validation loss: 2.4417530993115824

Epoch: 6| Step: 8
Training loss: 2.9225880777810094
Validation loss: 2.451105977167706

Epoch: 6| Step: 9
Training loss: 2.6729182833287344
Validation loss: 2.460143093863226

Epoch: 6| Step: 10
Training loss: 2.4391858066667615
Validation loss: 2.4404518474310777

Epoch: 6| Step: 11
Training loss: 2.495483419336883
Validation loss: 2.441150806739029

Epoch: 6| Step: 12
Training loss: 2.9603560790256336
Validation loss: 2.455411067498881

Epoch: 6| Step: 13
Training loss: 2.4258336354863426
Validation loss: 2.4480063497696367

Epoch: 40| Step: 0
Training loss: 2.992888923681778
Validation loss: 2.4323134563067565

Epoch: 6| Step: 1
Training loss: 3.4238515223102435
Validation loss: 2.4474400625593047

Epoch: 6| Step: 2
Training loss: 3.3018004158834504
Validation loss: 2.449839617745317

Epoch: 6| Step: 3
Training loss: 3.122321545011714
Validation loss: 2.4503352051641003

Epoch: 6| Step: 4
Training loss: 2.233485971994713
Validation loss: 2.4478614729342825

Epoch: 6| Step: 5
Training loss: 2.8905210734062576
Validation loss: 2.4516758930909406

Epoch: 6| Step: 6
Training loss: 2.7472400687417715
Validation loss: 2.4531296556976074

Epoch: 6| Step: 7
Training loss: 3.1873894466600996
Validation loss: 2.4422619300209547

Epoch: 6| Step: 8
Training loss: 1.9819659530956495
Validation loss: 2.467680574200201

Epoch: 6| Step: 9
Training loss: 2.641186355423393
Validation loss: 2.4393447403555375

Epoch: 6| Step: 10
Training loss: 2.3563085169317985
Validation loss: 2.443603885309687

Epoch: 6| Step: 11
Training loss: 2.3319273754608716
Validation loss: 2.4375032993375303

Epoch: 6| Step: 12
Training loss: 2.300426617737717
Validation loss: 2.4490010251328513

Epoch: 6| Step: 13
Training loss: 3.4232687702671445
Validation loss: 2.4518339585891935

Epoch: 41| Step: 0
Training loss: 2.427434434722283
Validation loss: 2.442097043987261

Epoch: 6| Step: 1
Training loss: 2.183730556180934
Validation loss: 2.4412896362018652

Epoch: 6| Step: 2
Training loss: 3.3700052672212
Validation loss: 2.4511232649826864

Epoch: 6| Step: 3
Training loss: 3.2521715978602224
Validation loss: 2.441176524390167

Epoch: 6| Step: 4
Training loss: 2.2788397192438565
Validation loss: 2.439382265452729

Epoch: 6| Step: 5
Training loss: 2.1630475800775164
Validation loss: 2.443593724533906

Epoch: 6| Step: 6
Training loss: 3.683987383072213
Validation loss: 2.4360843288496787

Epoch: 6| Step: 7
Training loss: 2.8581793948464815
Validation loss: 2.4385874657043525

Epoch: 6| Step: 8
Training loss: 2.7869319525145886
Validation loss: 2.4415628005503027

Epoch: 6| Step: 9
Training loss: 2.542715033606099
Validation loss: 2.444099743823338

Epoch: 6| Step: 10
Training loss: 3.352102525149153
Validation loss: 2.443809373604978

Epoch: 6| Step: 11
Training loss: 2.4659719167504037
Validation loss: 2.442883014806669

Epoch: 6| Step: 12
Training loss: 2.119914083359322
Validation loss: 2.444380869097722

Epoch: 6| Step: 13
Training loss: 3.3039993038500035
Validation loss: 2.4288920071763265

Epoch: 42| Step: 0
Training loss: 2.843917674057462
Validation loss: 2.448474514840454

Epoch: 6| Step: 1
Training loss: 2.9954234819542087
Validation loss: 2.4304388624345425

Epoch: 6| Step: 2
Training loss: 2.581758193266704
Validation loss: 2.433936582064259

Epoch: 6| Step: 3
Training loss: 2.829640188090206
Validation loss: 2.438227539930303

Epoch: 6| Step: 4
Training loss: 2.966802661078953
Validation loss: 2.440954407322407

Epoch: 6| Step: 5
Training loss: 3.2678552340189997
Validation loss: 2.447953676368565

Epoch: 6| Step: 6
Training loss: 2.8154987878486897
Validation loss: 2.44564888207934

Epoch: 6| Step: 7
Training loss: 2.852243504137922
Validation loss: 2.4337418546913803

Epoch: 6| Step: 8
Training loss: 2.8746161826636674
Validation loss: 2.4308769501895156

Epoch: 6| Step: 9
Training loss: 2.3570085999206913
Validation loss: 2.4291620476695917

Epoch: 6| Step: 10
Training loss: 2.4442622942924026
Validation loss: 2.4456294768801423

Epoch: 6| Step: 11
Training loss: 2.826121511056729
Validation loss: 2.448868079697676

Epoch: 6| Step: 12
Training loss: 2.4268920124488216
Validation loss: 2.4444348339582986

Epoch: 6| Step: 13
Training loss: 2.76603523272226
Validation loss: 2.4315007659428503

Epoch: 43| Step: 0
Training loss: 3.14128159069566
Validation loss: 2.4385953545041117

Epoch: 6| Step: 1
Training loss: 2.8977336183094304
Validation loss: 2.449586032452434

Epoch: 6| Step: 2
Training loss: 2.3836994459035474
Validation loss: 2.4339572053916507

Epoch: 6| Step: 3
Training loss: 2.1749743843762555
Validation loss: 2.4348657044305897

Epoch: 6| Step: 4
Training loss: 2.7092982016198017
Validation loss: 2.448456652343413

Epoch: 6| Step: 5
Training loss: 3.034080835260092
Validation loss: 2.4343859435392368

Epoch: 6| Step: 6
Training loss: 3.312986230252221
Validation loss: 2.4347525600474906

Epoch: 6| Step: 7
Training loss: 2.959616655837664
Validation loss: 2.435355023344386

Epoch: 6| Step: 8
Training loss: 2.3017350245477823
Validation loss: 2.4442602469554098

Epoch: 6| Step: 9
Training loss: 2.6520236331985623
Validation loss: 2.435909074413052

Epoch: 6| Step: 10
Training loss: 2.542130433176517
Validation loss: 2.441403258356702

Epoch: 6| Step: 11
Training loss: 2.3039447169360443
Validation loss: 2.4452585303952996

Epoch: 6| Step: 12
Training loss: 3.2873133269132953
Validation loss: 2.4349753044354965

Epoch: 6| Step: 13
Training loss: 3.3599349154117886
Validation loss: 2.4456496766493623

Epoch: 44| Step: 0
Training loss: 3.395175956020375
Validation loss: 2.4459036312729467

Epoch: 6| Step: 1
Training loss: 2.4503625757164844
Validation loss: 2.4463856059954043

Epoch: 6| Step: 2
Training loss: 2.803830241578489
Validation loss: 2.4274348592789385

Epoch: 6| Step: 3
Training loss: 3.211412380771133
Validation loss: 2.428521465178958

Epoch: 6| Step: 4
Training loss: 2.5865037188706945
Validation loss: 2.4479613496205874

Epoch: 6| Step: 5
Training loss: 2.329649969831003
Validation loss: 2.4455243221743226

Epoch: 6| Step: 6
Training loss: 2.539412817629994
Validation loss: 2.4586133684437566

Epoch: 6| Step: 7
Training loss: 2.913529334498522
Validation loss: 2.451619357317539

Epoch: 6| Step: 8
Training loss: 2.869789045070736
Validation loss: 2.4609584491682526

Epoch: 6| Step: 9
Training loss: 2.710235064964078
Validation loss: 2.4381170467306474

Epoch: 6| Step: 10
Training loss: 2.727605144876175
Validation loss: 2.434260673565375

Epoch: 6| Step: 11
Training loss: 2.789476209031357
Validation loss: 2.4321318002048224

Epoch: 6| Step: 12
Training loss: 2.8811536528723978
Validation loss: 2.4373211475570864

Epoch: 6| Step: 13
Training loss: 2.5583039330730526
Validation loss: 2.4545071503480407

Epoch: 45| Step: 0
Training loss: 2.3433339067497294
Validation loss: 2.4360721382669985

Epoch: 6| Step: 1
Training loss: 2.7366144219761526
Validation loss: 2.427101572126565

Epoch: 6| Step: 2
Training loss: 2.9446515624257956
Validation loss: 2.4383047314722597

Epoch: 6| Step: 3
Training loss: 2.1969450721038313
Validation loss: 2.4481236656777385

Epoch: 6| Step: 4
Training loss: 2.9209315770959394
Validation loss: 2.438731258832032

Epoch: 6| Step: 5
Training loss: 3.350095627971347
Validation loss: 2.4558905416887566

Epoch: 6| Step: 6
Training loss: 2.4319310271496164
Validation loss: 2.4497787898494185

Epoch: 6| Step: 7
Training loss: 2.805483904218417
Validation loss: 2.454228037391299

Epoch: 6| Step: 8
Training loss: 2.7367730660456595
Validation loss: 2.4281833723754542

Epoch: 6| Step: 9
Training loss: 2.4861073721840397
Validation loss: 2.4337527929034533

Epoch: 6| Step: 10
Training loss: 3.0365583993291847
Validation loss: 2.44787750177901

Epoch: 6| Step: 11
Training loss: 2.636186650592612
Validation loss: 2.439834586313944

Epoch: 6| Step: 12
Training loss: 2.9694150480935195
Validation loss: 2.4193171240830535

Epoch: 6| Step: 13
Training loss: 3.3874006981740785
Validation loss: 2.4281997037375187

Epoch: 46| Step: 0
Training loss: 2.8479300159363796
Validation loss: 2.427211860705142

Epoch: 6| Step: 1
Training loss: 3.0367510716097312
Validation loss: 2.4257672765413005

Epoch: 6| Step: 2
Training loss: 2.0606179175401254
Validation loss: 2.4317034848370995

Epoch: 6| Step: 3
Training loss: 2.919560949160722
Validation loss: 2.4462292875848726

Epoch: 6| Step: 4
Training loss: 3.6815059242599797
Validation loss: 2.44259666773438

Epoch: 6| Step: 5
Training loss: 3.041794830827135
Validation loss: 2.4471039853648167

Epoch: 6| Step: 6
Training loss: 2.5112877649531367
Validation loss: 2.439098167632939

Epoch: 6| Step: 7
Training loss: 2.8334055124700566
Validation loss: 2.420147529874949

Epoch: 6| Step: 8
Training loss: 2.7194562849601622
Validation loss: 2.4316037901346808

Epoch: 6| Step: 9
Training loss: 2.096622603074211
Validation loss: 2.43675274328987

Epoch: 6| Step: 10
Training loss: 3.066710710900294
Validation loss: 2.442805482558507

Epoch: 6| Step: 11
Training loss: 2.5141993682761004
Validation loss: 2.4438251153677726

Epoch: 6| Step: 12
Training loss: 1.9893584864988954
Validation loss: 2.43058564581071

Epoch: 6| Step: 13
Training loss: 3.204051409476807
Validation loss: 2.45155410417463

Epoch: 47| Step: 0
Training loss: 2.684258657649857
Validation loss: 2.4523563417838234

Epoch: 6| Step: 1
Training loss: 2.157248113964042
Validation loss: 2.4419718094931757

Epoch: 6| Step: 2
Training loss: 3.540457006578344
Validation loss: 2.4380511325246688

Epoch: 6| Step: 3
Training loss: 3.0534756102861382
Validation loss: 2.451250584849478

Epoch: 6| Step: 4
Training loss: 2.740653366933795
Validation loss: 2.4420829938228525

Epoch: 6| Step: 5
Training loss: 2.9534534090086084
Validation loss: 2.4492145285838474

Epoch: 6| Step: 6
Training loss: 2.1094850864647254
Validation loss: 2.443038483272668

Epoch: 6| Step: 7
Training loss: 3.244231018975064
Validation loss: 2.45411224282604

Epoch: 6| Step: 8
Training loss: 2.7756244472339047
Validation loss: 2.438351363898612

Epoch: 6| Step: 9
Training loss: 2.37648726625761
Validation loss: 2.4538760143722116

Epoch: 6| Step: 10
Training loss: 1.943174481821686
Validation loss: 2.4553865827040164

Epoch: 6| Step: 11
Training loss: 3.14712262206922
Validation loss: 2.4419960876025266

Epoch: 6| Step: 12
Training loss: 3.119838266337771
Validation loss: 2.465601642423716

Epoch: 6| Step: 13
Training loss: 2.114715371605662
Validation loss: 2.450627828563338

Epoch: 48| Step: 0
Training loss: 2.4039305369898614
Validation loss: 2.440640675601789

Epoch: 6| Step: 1
Training loss: 2.3728782813696534
Validation loss: 2.441374598669158

Epoch: 6| Step: 2
Training loss: 2.1598017092922936
Validation loss: 2.4451391169174195

Epoch: 6| Step: 3
Training loss: 2.6306137729295536
Validation loss: 2.4520392747087763

Epoch: 6| Step: 4
Training loss: 2.7254239303786783
Validation loss: 2.4497025370126613

Epoch: 6| Step: 5
Training loss: 2.6192497668756367
Validation loss: 2.4368348509075255

Epoch: 6| Step: 6
Training loss: 3.0722856466389086
Validation loss: 2.4369500956890553

Epoch: 6| Step: 7
Training loss: 3.063835475667786
Validation loss: 2.429628189260391

Epoch: 6| Step: 8
Training loss: 3.279490117007714
Validation loss: 2.4458934244993524

Epoch: 6| Step: 9
Training loss: 2.5110167950760123
Validation loss: 2.4400722834146515

Epoch: 6| Step: 10
Training loss: 2.7049745615610927
Validation loss: 2.458363376584716

Epoch: 6| Step: 11
Training loss: 3.1686439029906723
Validation loss: 2.4443209400149297

Epoch: 6| Step: 12
Training loss: 2.853579124250697
Validation loss: 2.42455498447834

Epoch: 6| Step: 13
Training loss: 3.3435132664810476
Validation loss: 2.4368604720840246

Epoch: 49| Step: 0
Training loss: 3.210223116146966
Validation loss: 2.428038285173901

Epoch: 6| Step: 1
Training loss: 2.6599726004372495
Validation loss: 2.4409691540007237

Epoch: 6| Step: 2
Training loss: 3.1299303452903913
Validation loss: 2.437834873129792

Epoch: 6| Step: 3
Training loss: 3.2780398696886017
Validation loss: 2.450086632423898

Epoch: 6| Step: 4
Training loss: 3.1942474157044214
Validation loss: 2.4522073906838635

Epoch: 6| Step: 5
Training loss: 2.7550558950635313
Validation loss: 2.4561875226281877

Epoch: 6| Step: 6
Training loss: 2.6487700217022714
Validation loss: 2.42489253441262

Epoch: 6| Step: 7
Training loss: 2.2651474021796183
Validation loss: 2.4395195898175386

Epoch: 6| Step: 8
Training loss: 2.964482181098544
Validation loss: 2.435452363960089

Epoch: 6| Step: 9
Training loss: 2.737888542018843
Validation loss: 2.4525920434502764

Epoch: 6| Step: 10
Training loss: 2.4502939787452833
Validation loss: 2.431930795234747

Epoch: 6| Step: 11
Training loss: 2.3020502033410115
Validation loss: 2.4591454797654393

Epoch: 6| Step: 12
Training loss: 2.1240536321488857
Validation loss: 2.440721568978756

Epoch: 6| Step: 13
Training loss: 2.890214550673666
Validation loss: 2.43901269071228

Epoch: 50| Step: 0
Training loss: 2.6721775709013924
Validation loss: 2.4421965318293313

Epoch: 6| Step: 1
Training loss: 3.031327708713181
Validation loss: 2.423449048384455

Epoch: 6| Step: 2
Training loss: 2.3773804831323
Validation loss: 2.4391508252139795

Epoch: 6| Step: 3
Training loss: 2.430735665565981
Validation loss: 2.42834758052213

Epoch: 6| Step: 4
Training loss: 2.3153304227984046
Validation loss: 2.4295397221818957

Epoch: 6| Step: 5
Training loss: 2.957151382807834
Validation loss: 2.437973029149653

Epoch: 6| Step: 6
Training loss: 3.1454120042262455
Validation loss: 2.442780044426262

Epoch: 6| Step: 7
Training loss: 3.098738068945822
Validation loss: 2.4358194730220064

Epoch: 6| Step: 8
Training loss: 2.9731690294118183
Validation loss: 2.426740231733688

Epoch: 6| Step: 9
Training loss: 2.726414105331173
Validation loss: 2.426655490061933

Epoch: 6| Step: 10
Training loss: 2.5051803322943544
Validation loss: 2.4388795487366908

Epoch: 6| Step: 11
Training loss: 2.7493135289047164
Validation loss: 2.4439767728161375

Epoch: 6| Step: 12
Training loss: 2.849887303583677
Validation loss: 2.4222270242660313

Epoch: 6| Step: 13
Training loss: 2.7357892548001
Validation loss: 2.439421476702374

Epoch: 51| Step: 0
Training loss: 3.8637208755960364
Validation loss: 2.442851525334502

Epoch: 6| Step: 1
Training loss: 2.287375391500185
Validation loss: 2.4358900678544053

Epoch: 6| Step: 2
Training loss: 2.743892215875122
Validation loss: 2.4420584005916917

Epoch: 6| Step: 3
Training loss: 2.720867866737043
Validation loss: 2.442063367127918

Epoch: 6| Step: 4
Training loss: 2.856863784784716
Validation loss: 2.443328659711678

Epoch: 6| Step: 5
Training loss: 2.622088316104393
Validation loss: 2.4452573813344696

Epoch: 6| Step: 6
Training loss: 3.170498253206266
Validation loss: 2.4485936028508775

Epoch: 6| Step: 7
Training loss: 2.158216712874364
Validation loss: 2.4426355356119758

Epoch: 6| Step: 8
Training loss: 2.489953741080534
Validation loss: 2.4440471425191714

Epoch: 6| Step: 9
Training loss: 2.937483442543928
Validation loss: 2.4375117469674925

Epoch: 6| Step: 10
Training loss: 2.584040842282676
Validation loss: 2.4354443776107435

Epoch: 6| Step: 11
Training loss: 3.1916270745779043
Validation loss: 2.4159946309924187

Epoch: 6| Step: 12
Training loss: 1.8707501249210081
Validation loss: 2.433733024240281

Epoch: 6| Step: 13
Training loss: 2.5459401105682633
Validation loss: 2.4345840648455224

Epoch: 52| Step: 0
Training loss: 3.0161151388841008
Validation loss: 2.4240860229310806

Epoch: 6| Step: 1
Training loss: 2.0771506183507005
Validation loss: 2.419421646159691

Epoch: 6| Step: 2
Training loss: 2.320758096056411
Validation loss: 2.431220099979191

Epoch: 6| Step: 3
Training loss: 2.5878681455391597
Validation loss: 2.44810692687716

Epoch: 6| Step: 4
Training loss: 2.6859608168197404
Validation loss: 2.439910308028926

Epoch: 6| Step: 5
Training loss: 3.281724296078016
Validation loss: 2.438222734336535

Epoch: 6| Step: 6
Training loss: 2.3661166245907133
Validation loss: 2.4417421496917613

Epoch: 6| Step: 7
Training loss: 2.0424829784417105
Validation loss: 2.441116549722186

Epoch: 6| Step: 8
Training loss: 2.8289746436084733
Validation loss: 2.4372172931876013

Epoch: 6| Step: 9
Training loss: 3.1269813360005525
Validation loss: 2.4468346865754187

Epoch: 6| Step: 10
Training loss: 2.75683429432846
Validation loss: 2.415966556991964

Epoch: 6| Step: 11
Training loss: 2.7983789076813403
Validation loss: 2.444548269024944

Epoch: 6| Step: 12
Training loss: 3.449800159360882
Validation loss: 2.435120337318891

Epoch: 6| Step: 13
Training loss: 2.958470909967186
Validation loss: 2.431283527432751

Epoch: 53| Step: 0
Training loss: 2.670246006922919
Validation loss: 2.441179139302157

Epoch: 6| Step: 1
Training loss: 3.514821278571685
Validation loss: 2.4285335226514024

Epoch: 6| Step: 2
Training loss: 3.132671096160002
Validation loss: 2.438776624817246

Epoch: 6| Step: 3
Training loss: 2.753448664748983
Validation loss: 2.4333120084978073

Epoch: 6| Step: 4
Training loss: 2.481902901870406
Validation loss: 2.4319209008824894

Epoch: 6| Step: 5
Training loss: 3.1628108056573367
Validation loss: 2.451965057796159

Epoch: 6| Step: 6
Training loss: 2.3490406594295723
Validation loss: 2.447251124203572

Epoch: 6| Step: 7
Training loss: 2.672640685186974
Validation loss: 2.452596367761769

Epoch: 6| Step: 8
Training loss: 2.675239630688063
Validation loss: 2.43363302396631

Epoch: 6| Step: 9
Training loss: 2.3433368573042452
Validation loss: 2.4312583757646333

Epoch: 6| Step: 10
Training loss: 2.6945367111279013
Validation loss: 2.422649483854923

Epoch: 6| Step: 11
Training loss: 2.607122122575758
Validation loss: 2.435657663201552

Epoch: 6| Step: 12
Training loss: 2.419248769034683
Validation loss: 2.42801279791265

Epoch: 6| Step: 13
Training loss: 3.075182442563971
Validation loss: 2.447926473674273

Epoch: 54| Step: 0
Training loss: 2.025381090073687
Validation loss: 2.4339760485140096

Epoch: 6| Step: 1
Training loss: 2.7632268648455205
Validation loss: 2.4365440515577546

Epoch: 6| Step: 2
Training loss: 2.9574433899957064
Validation loss: 2.422905979367994

Epoch: 6| Step: 3
Training loss: 2.440868397785681
Validation loss: 2.4267732877368506

Epoch: 6| Step: 4
Training loss: 2.9748366751837914
Validation loss: 2.445748073450747

Epoch: 6| Step: 5
Training loss: 2.716306969948845
Validation loss: 2.4260309303651377

Epoch: 6| Step: 6
Training loss: 2.8795504839088832
Validation loss: 2.4367929152964063

Epoch: 6| Step: 7
Training loss: 2.9082316543891102
Validation loss: 2.44140703965041

Epoch: 6| Step: 8
Training loss: 2.420469700810213
Validation loss: 2.4277798049764483

Epoch: 6| Step: 9
Training loss: 2.7614567266800356
Validation loss: 2.4330911680486014

Epoch: 6| Step: 10
Training loss: 2.6220744042391257
Validation loss: 2.4339230451457894

Epoch: 6| Step: 11
Training loss: 2.4742860168814276
Validation loss: 2.4434611815530607

Epoch: 6| Step: 12
Training loss: 2.70029720507346
Validation loss: 2.4297322614456123

Epoch: 6| Step: 13
Training loss: 4.117575234499982
Validation loss: 2.442220795632973

Epoch: 55| Step: 0
Training loss: 2.216073799680941
Validation loss: 2.4377443755361172

Epoch: 6| Step: 1
Training loss: 2.819811071059717
Validation loss: 2.4342993249017018

Epoch: 6| Step: 2
Training loss: 2.696706571657021
Validation loss: 2.442923115389194

Epoch: 6| Step: 3
Training loss: 2.1890323176675506
Validation loss: 2.4391003496343235

Epoch: 6| Step: 4
Training loss: 2.3426329939145925
Validation loss: 2.4444507017394246

Epoch: 6| Step: 5
Training loss: 2.773632117951554
Validation loss: 2.459397079748717

Epoch: 6| Step: 6
Training loss: 3.095108196481151
Validation loss: 2.4454139862183677

Epoch: 6| Step: 7
Training loss: 2.5266851071042957
Validation loss: 2.4324981140888897

Epoch: 6| Step: 8
Training loss: 3.1481297344924197
Validation loss: 2.4466513245820134

Epoch: 6| Step: 9
Training loss: 2.9575659244570973
Validation loss: 2.440446108663778

Epoch: 6| Step: 10
Training loss: 2.463552484360884
Validation loss: 2.44251227257252

Epoch: 6| Step: 11
Training loss: 2.922423612120043
Validation loss: 2.441558217296546

Epoch: 6| Step: 12
Training loss: 3.006765842395056
Validation loss: 2.438776714694797

Epoch: 6| Step: 13
Training loss: 3.5422660021334655
Validation loss: 2.441001295800358

Epoch: 56| Step: 0
Training loss: 3.3920895274601297
Validation loss: 2.4422076799089614

Epoch: 6| Step: 1
Training loss: 3.0685958916840064
Validation loss: 2.435596295865245

Epoch: 6| Step: 2
Training loss: 2.3646710305329157
Validation loss: 2.448962042636534

Epoch: 6| Step: 3
Training loss: 2.794136624818016
Validation loss: 2.453610971623485

Epoch: 6| Step: 4
Training loss: 3.2321908551320147
Validation loss: 2.426563297185467

Epoch: 6| Step: 5
Training loss: 2.828539907464216
Validation loss: 2.446691422603643

Epoch: 6| Step: 6
Training loss: 2.40959123761761
Validation loss: 2.4484292950378745

Epoch: 6| Step: 7
Training loss: 2.440604360495616
Validation loss: 2.4320766906181515

Epoch: 6| Step: 8
Training loss: 2.7419323924805443
Validation loss: 2.444814294263055

Epoch: 6| Step: 9
Training loss: 2.2660893457682003
Validation loss: 2.4417799340193875

Epoch: 6| Step: 10
Training loss: 3.005197790558215
Validation loss: 2.443444631666924

Epoch: 6| Step: 11
Training loss: 2.972493271238573
Validation loss: 2.4605637852081466

Epoch: 6| Step: 12
Training loss: 2.243888820933526
Validation loss: 2.443208697041812

Epoch: 6| Step: 13
Training loss: 2.024049055258909
Validation loss: 2.441602214077491

Epoch: 57| Step: 0
Training loss: 2.8996799818587538
Validation loss: 2.443914605771629

Epoch: 6| Step: 1
Training loss: 3.0159118199700337
Validation loss: 2.4463266298853332

Epoch: 6| Step: 2
Training loss: 2.486072080602977
Validation loss: 2.4426417672403278

Epoch: 6| Step: 3
Training loss: 2.720511906922219
Validation loss: 2.43767125464417

Epoch: 6| Step: 4
Training loss: 2.7504378750457326
Validation loss: 2.4561180623089705

Epoch: 6| Step: 5
Training loss: 2.778326491095942
Validation loss: 2.450414218086963

Epoch: 6| Step: 6
Training loss: 2.659397907808394
Validation loss: 2.4369410548931323

Epoch: 6| Step: 7
Training loss: 2.5636682406017113
Validation loss: 2.422589485453328

Epoch: 6| Step: 8
Training loss: 2.1892749669654212
Validation loss: 2.4446623804627485

Epoch: 6| Step: 9
Training loss: 3.5640845539325476
Validation loss: 2.4533987588148256

Epoch: 6| Step: 10
Training loss: 2.678524376592182
Validation loss: 2.4333019469772954

Epoch: 6| Step: 11
Training loss: 2.9262127831792077
Validation loss: 2.4432800132663663

Epoch: 6| Step: 12
Training loss: 2.5149546612696994
Validation loss: 2.4302208106134597

Epoch: 6| Step: 13
Training loss: 2.851515009236387
Validation loss: 2.446658645662112

Epoch: 58| Step: 0
Training loss: 2.586568058271106
Validation loss: 2.4246450851423575

Epoch: 6| Step: 1
Training loss: 2.839165313992086
Validation loss: 2.435601590297004

Epoch: 6| Step: 2
Training loss: 2.9509217454804215
Validation loss: 2.44014103798647

Epoch: 6| Step: 3
Training loss: 2.6856003190704874
Validation loss: 2.447494118133395

Epoch: 6| Step: 4
Training loss: 2.4597876390426494
Validation loss: 2.4394297358809696

Epoch: 6| Step: 5
Training loss: 2.9991390264378115
Validation loss: 2.4260368839304602

Epoch: 6| Step: 6
Training loss: 3.2783534753126053
Validation loss: 2.450260006499825

Epoch: 6| Step: 7
Training loss: 2.4569130582537655
Validation loss: 2.4255623640996435

Epoch: 6| Step: 8
Training loss: 2.6344769477349717
Validation loss: 2.4271394217094966

Epoch: 6| Step: 9
Training loss: 2.453221215954978
Validation loss: 2.4440780386325565

Epoch: 6| Step: 10
Training loss: 2.658740413273654
Validation loss: 2.437727426121659

Epoch: 6| Step: 11
Training loss: 2.9034298575553947
Validation loss: 2.4401768693594885

Epoch: 6| Step: 12
Training loss: 2.5050788787788316
Validation loss: 2.430344089463827

Epoch: 6| Step: 13
Training loss: 3.0401800694590984
Validation loss: 2.434761660037014

Epoch: 59| Step: 0
Training loss: 3.1080417554252384
Validation loss: 2.442584176943077

Epoch: 6| Step: 1
Training loss: 2.4620857587453666
Validation loss: 2.4349183756309234

Epoch: 6| Step: 2
Training loss: 2.8408874524766308
Validation loss: 2.4391940109393064

Epoch: 6| Step: 3
Training loss: 2.4181533274663787
Validation loss: 2.4244824343782976

Epoch: 6| Step: 4
Training loss: 2.9145942591438985
Validation loss: 2.446570690137449

Epoch: 6| Step: 5
Training loss: 2.589394094519681
Validation loss: 2.4369340896491964

Epoch: 6| Step: 6
Training loss: 2.680584548854889
Validation loss: 2.44100978488689

Epoch: 6| Step: 7
Training loss: 2.2187353859003744
Validation loss: 2.42515984048501

Epoch: 6| Step: 8
Training loss: 3.173015821531075
Validation loss: 2.424947614857748

Epoch: 6| Step: 9
Training loss: 3.359116513265776
Validation loss: 2.441297967818808

Epoch: 6| Step: 10
Training loss: 2.4668210376513566
Validation loss: 2.4316063800220187

Epoch: 6| Step: 11
Training loss: 2.5416198059098
Validation loss: 2.44129009510311

Epoch: 6| Step: 12
Training loss: 2.852291317125841
Validation loss: 2.425710894688415

Epoch: 6| Step: 13
Training loss: 2.2854299006488974
Validation loss: 2.4404571407832765

Epoch: 60| Step: 0
Training loss: 2.9408962015242306
Validation loss: 2.4254199866647923

Epoch: 6| Step: 1
Training loss: 2.721873801720549
Validation loss: 2.445886084358474

Epoch: 6| Step: 2
Training loss: 2.493930506089065
Validation loss: 2.4289470000930664

Epoch: 6| Step: 3
Training loss: 2.755586758004526
Validation loss: 2.4398513151458325

Epoch: 6| Step: 4
Training loss: 2.6011694075616676
Validation loss: 2.430514247170189

Epoch: 6| Step: 5
Training loss: 2.661523677573694
Validation loss: 2.426209589613575

Epoch: 6| Step: 6
Training loss: 3.22451177642276
Validation loss: 2.436174937568931

Epoch: 6| Step: 7
Training loss: 2.827785745579108
Validation loss: 2.453427560171239

Epoch: 6| Step: 8
Training loss: 2.3463096374508887
Validation loss: 2.439338510288568

Epoch: 6| Step: 9
Training loss: 3.0627811847756004
Validation loss: 2.4202690545200287

Epoch: 6| Step: 10
Training loss: 2.8535644192867857
Validation loss: 2.440901728783847

Epoch: 6| Step: 11
Training loss: 2.4058723648793356
Validation loss: 2.4473174605199413

Epoch: 6| Step: 12
Training loss: 2.7561895766090276
Validation loss: 2.4334965309864995

Epoch: 6| Step: 13
Training loss: 2.292803418829233
Validation loss: 2.4259447129858502

Epoch: 61| Step: 0
Training loss: 2.0499154143211817
Validation loss: 2.433547114897198

Epoch: 6| Step: 1
Training loss: 2.7179909885304827
Validation loss: 2.42946260248468

Epoch: 6| Step: 2
Training loss: 3.3661462010111847
Validation loss: 2.439891434033969

Epoch: 6| Step: 3
Training loss: 2.2380655394461084
Validation loss: 2.4330200273295186

Epoch: 6| Step: 4
Training loss: 2.077868338201942
Validation loss: 2.447233177875895

Epoch: 6| Step: 5
Training loss: 2.4664552864369296
Validation loss: 2.423316884661288

Epoch: 6| Step: 6
Training loss: 3.131563541757448
Validation loss: 2.4484827529047934

Epoch: 6| Step: 7
Training loss: 2.585129718292757
Validation loss: 2.4326523535370077

Epoch: 6| Step: 8
Training loss: 3.1608285459935925
Validation loss: 2.4317569603856555

Epoch: 6| Step: 9
Training loss: 2.195770541698187
Validation loss: 2.4401169867404287

Epoch: 6| Step: 10
Training loss: 2.951156040555634
Validation loss: 2.44038466424524

Epoch: 6| Step: 11
Training loss: 2.9717809363399836
Validation loss: 2.4328736785014886

Epoch: 6| Step: 12
Training loss: 2.8915555538702975
Validation loss: 2.445677765267548

Epoch: 6| Step: 13
Training loss: 3.1309142033564727
Validation loss: 2.4532379240400273

Epoch: 62| Step: 0
Training loss: 2.498731195818938
Validation loss: 2.443257511741249

Epoch: 6| Step: 1
Training loss: 3.282317069796836
Validation loss: 2.429743073158311

Epoch: 6| Step: 2
Training loss: 2.6615295002499377
Validation loss: 2.4420137747975343

Epoch: 6| Step: 3
Training loss: 2.5102654460351608
Validation loss: 2.4244878387287265

Epoch: 6| Step: 4
Training loss: 2.409575307314775
Validation loss: 2.425975666337094

Epoch: 6| Step: 5
Training loss: 2.414211824113504
Validation loss: 2.4291865034054543

Epoch: 6| Step: 6
Training loss: 2.640537960265766
Validation loss: 2.4280508032817116

Epoch: 6| Step: 7
Training loss: 2.7673647306305047
Validation loss: 2.429673627087

Epoch: 6| Step: 8
Training loss: 2.3523117341973467
Validation loss: 2.440325670748201

Epoch: 6| Step: 9
Training loss: 2.851525042562203
Validation loss: 2.443783932284966

Epoch: 6| Step: 10
Training loss: 3.0371828518041135
Validation loss: 2.443214555234985

Epoch: 6| Step: 11
Training loss: 2.8842731693431998
Validation loss: 2.4298859479500323

Epoch: 6| Step: 12
Training loss: 3.033473349752667
Validation loss: 2.4273290114154316

Epoch: 6| Step: 13
Training loss: 2.8152028977227697
Validation loss: 2.431008214643151

Epoch: 63| Step: 0
Training loss: 3.256136602671385
Validation loss: 2.426482444747231

Epoch: 6| Step: 1
Training loss: 2.892491578243989
Validation loss: 2.425875747866789

Epoch: 6| Step: 2
Training loss: 2.8682363810788227
Validation loss: 2.442657720661229

Epoch: 6| Step: 3
Training loss: 2.5952791049928523
Validation loss: 2.4467764290534917

Epoch: 6| Step: 4
Training loss: 2.0939907106413918
Validation loss: 2.427736139015112

Epoch: 6| Step: 5
Training loss: 2.8363516008681926
Validation loss: 2.4427240699474395

Epoch: 6| Step: 6
Training loss: 2.120062533481978
Validation loss: 2.4332925839312542

Epoch: 6| Step: 7
Training loss: 1.8486089528554688
Validation loss: 2.4277427362407544

Epoch: 6| Step: 8
Training loss: 2.6669448965678586
Validation loss: 2.431812360800511

Epoch: 6| Step: 9
Training loss: 3.3620118194499398
Validation loss: 2.43645309250356

Epoch: 6| Step: 10
Training loss: 2.6670401033548092
Validation loss: 2.430270548125667

Epoch: 6| Step: 11
Training loss: 2.733720450396406
Validation loss: 2.435482181748688

Epoch: 6| Step: 12
Training loss: 3.2351947427471095
Validation loss: 2.424245700165091

Epoch: 6| Step: 13
Training loss: 2.9162985069796137
Validation loss: 2.4290564814014246

Epoch: 64| Step: 0
Training loss: 2.5289819234109223
Validation loss: 2.43486799867224

Epoch: 6| Step: 1
Training loss: 3.329171029773538
Validation loss: 2.4329774664475283

Epoch: 6| Step: 2
Training loss: 3.0367617490966206
Validation loss: 2.4380666159934052

Epoch: 6| Step: 3
Training loss: 2.140643265917735
Validation loss: 2.441608591665451

Epoch: 6| Step: 4
Training loss: 2.9562642199958606
Validation loss: 2.42151065643535

Epoch: 6| Step: 5
Training loss: 2.1211155561868273
Validation loss: 2.4423392087103974

Epoch: 6| Step: 6
Training loss: 2.744948515973784
Validation loss: 2.4251748798245294

Epoch: 6| Step: 7
Training loss: 2.508329629314472
Validation loss: 2.431228982790443

Epoch: 6| Step: 8
Training loss: 3.1427045172007633
Validation loss: 2.4135568494542836

Epoch: 6| Step: 9
Training loss: 1.7009640204264758
Validation loss: 2.4402818678907616

Epoch: 6| Step: 10
Training loss: 2.9036729112853643
Validation loss: 2.4339930956737006

Epoch: 6| Step: 11
Training loss: 2.7419749990001008
Validation loss: 2.439744905798927

Epoch: 6| Step: 12
Training loss: 3.2056087633459165
Validation loss: 2.4277670415430634

Epoch: 6| Step: 13
Training loss: 2.4228909238287994
Validation loss: 2.4243194596912314

Epoch: 65| Step: 0
Training loss: 2.849241383292422
Validation loss: 2.443733337343858

Epoch: 6| Step: 1
Training loss: 2.331447815875761
Validation loss: 2.426432701430917

Epoch: 6| Step: 2
Training loss: 2.865595653720629
Validation loss: 2.423531874348773

Epoch: 6| Step: 3
Training loss: 2.0699163093787223
Validation loss: 2.4282334498737717

Epoch: 6| Step: 4
Training loss: 3.049649115218364
Validation loss: 2.435233179851356

Epoch: 6| Step: 5
Training loss: 3.0966709104357637
Validation loss: 2.4223582192900266

Epoch: 6| Step: 6
Training loss: 2.590509895740215
Validation loss: 2.43416145116066

Epoch: 6| Step: 7
Training loss: 2.8964677477080913
Validation loss: 2.4252060174197654

Epoch: 6| Step: 8
Training loss: 2.869629030875125
Validation loss: 2.4442773031500638

Epoch: 6| Step: 9
Training loss: 1.9893068917109218
Validation loss: 2.450386289430549

Epoch: 6| Step: 10
Training loss: 2.58826694271556
Validation loss: 2.4380114712629717

Epoch: 6| Step: 11
Training loss: 2.8932001963394502
Validation loss: 2.432498388106174

Epoch: 6| Step: 12
Training loss: 3.0231990276592513
Validation loss: 2.425902815271759

Epoch: 6| Step: 13
Training loss: 2.811657419089633
Validation loss: 2.436903788870605

Epoch: 66| Step: 0
Training loss: 2.5649677582437715
Validation loss: 2.4346262670024994

Epoch: 6| Step: 1
Training loss: 2.387138866653753
Validation loss: 2.4305310496448955

Epoch: 6| Step: 2
Training loss: 2.9422377668676316
Validation loss: 2.446888847722072

Epoch: 6| Step: 3
Training loss: 2.172277399561799
Validation loss: 2.4291860084465124

Epoch: 6| Step: 4
Training loss: 2.8187412101117975
Validation loss: 2.4423023032216804

Epoch: 6| Step: 5
Training loss: 3.4892664219824514
Validation loss: 2.444306327355301

Epoch: 6| Step: 6
Training loss: 2.672832830417097
Validation loss: 2.44338547125503

Epoch: 6| Step: 7
Training loss: 3.3404310635832255
Validation loss: 2.452216043792154

Epoch: 6| Step: 8
Training loss: 2.533751299744373
Validation loss: 2.438715660794626

Epoch: 6| Step: 9
Training loss: 2.5361878070002444
Validation loss: 2.439987573992113

Epoch: 6| Step: 10
Training loss: 2.4658328820842996
Validation loss: 2.440744446801321

Epoch: 6| Step: 11
Training loss: 2.924088399612775
Validation loss: 2.4370136580388406

Epoch: 6| Step: 12
Training loss: 2.6340676776646377
Validation loss: 2.4330807621216097

Epoch: 6| Step: 13
Training loss: 2.0340295407485947
Validation loss: 2.438031862434994

Epoch: 67| Step: 0
Training loss: 2.500801530140258
Validation loss: 2.4317623443522467

Epoch: 6| Step: 1
Training loss: 2.9247442019517855
Validation loss: 2.443290521601724

Epoch: 6| Step: 2
Training loss: 2.2397633916346145
Validation loss: 2.4474219798726398

Epoch: 6| Step: 3
Training loss: 2.9834081871260496
Validation loss: 2.424027847422894

Epoch: 6| Step: 4
Training loss: 2.1738190218039968
Validation loss: 2.4441600061060176

Epoch: 6| Step: 5
Training loss: 2.4823727006341163
Validation loss: 2.4329056933233026

Epoch: 6| Step: 6
Training loss: 2.8092862735778357
Validation loss: 2.4324321930646016

Epoch: 6| Step: 7
Training loss: 3.082103191739967
Validation loss: 2.4310344898833973

Epoch: 6| Step: 8
Training loss: 2.8734611041461857
Validation loss: 2.423214925800994

Epoch: 6| Step: 9
Training loss: 3.277680408159439
Validation loss: 2.4366674081923483

Epoch: 6| Step: 10
Training loss: 2.869233692755363
Validation loss: 2.4287608811509434

Epoch: 6| Step: 11
Training loss: 2.422566075324416
Validation loss: 2.4520512865861646

Epoch: 6| Step: 12
Training loss: 2.660930862463279
Validation loss: 2.457481434462292

Epoch: 6| Step: 13
Training loss: 2.6102009454010076
Validation loss: 2.44001905104356

Epoch: 68| Step: 0
Training loss: 2.667910663201399
Validation loss: 2.4414980713999768

Epoch: 6| Step: 1
Training loss: 2.6164213511001853
Validation loss: 2.4303458278506977

Epoch: 6| Step: 2
Training loss: 3.2005245911234974
Validation loss: 2.45400781724473

Epoch: 6| Step: 3
Training loss: 3.1604405146792702
Validation loss: 2.43875356717401

Epoch: 6| Step: 4
Training loss: 2.102019419862598
Validation loss: 2.4215113784650666

Epoch: 6| Step: 5
Training loss: 2.8567571277457713
Validation loss: 2.4364648087438314

Epoch: 6| Step: 6
Training loss: 3.2997882139275094
Validation loss: 2.415989939812187

Epoch: 6| Step: 7
Training loss: 2.821711227717059
Validation loss: 2.4269057924592112

Epoch: 6| Step: 8
Training loss: 2.638490434870353
Validation loss: 2.4475556752586

Epoch: 6| Step: 9
Training loss: 2.522037838354782
Validation loss: 2.4514078882053556

Epoch: 6| Step: 10
Training loss: 2.1441775726898924
Validation loss: 2.455223554373926

Epoch: 6| Step: 11
Training loss: 2.723570310382257
Validation loss: 2.423474232440019

Epoch: 6| Step: 12
Training loss: 2.236074801427297
Validation loss: 2.4240024494013546

Epoch: 6| Step: 13
Training loss: 2.949064177447666
Validation loss: 2.4465640095566457

Epoch: 69| Step: 0
Training loss: 2.401057399827848
Validation loss: 2.4434201224372813

Epoch: 6| Step: 1
Training loss: 3.0050973502590046
Validation loss: 2.4537001735561854

Epoch: 6| Step: 2
Training loss: 3.0859280743032476
Validation loss: 2.4140111865528953

Epoch: 6| Step: 3
Training loss: 2.1664689658517564
Validation loss: 2.433852639737467

Epoch: 6| Step: 4
Training loss: 2.4113062459774057
Validation loss: 2.424714333200551

Epoch: 6| Step: 5
Training loss: 3.3144824735368283
Validation loss: 2.4263746513929183

Epoch: 6| Step: 6
Training loss: 2.4983678258135456
Validation loss: 2.437804336417138

Epoch: 6| Step: 7
Training loss: 2.7291471368998472
Validation loss: 2.4493081328276562

Epoch: 6| Step: 8
Training loss: 2.5950965603189315
Validation loss: 2.442160683375238

Epoch: 6| Step: 9
Training loss: 2.509399102310211
Validation loss: 2.4548499774834616

Epoch: 6| Step: 10
Training loss: 2.3261161176147147
Validation loss: 2.450856962730413

Epoch: 6| Step: 11
Training loss: 2.917950447566429
Validation loss: 2.4089946683013674

Epoch: 6| Step: 12
Training loss: 2.900939519557478
Validation loss: 2.421680193584236

Epoch: 6| Step: 13
Training loss: 3.180729875595208
Validation loss: 2.4364493214089404

Epoch: 70| Step: 0
Training loss: 3.28548644739008
Validation loss: 2.4309271029693185

Epoch: 6| Step: 1
Training loss: 2.690219301835405
Validation loss: 2.422270811235898

Epoch: 6| Step: 2
Training loss: 2.6377640072274673
Validation loss: 2.439243712097298

Epoch: 6| Step: 3
Training loss: 3.089112476181942
Validation loss: 2.4405811588802986

Epoch: 6| Step: 4
Training loss: 2.1976949450371066
Validation loss: 2.4213656913752635

Epoch: 6| Step: 5
Training loss: 2.500917266416847
Validation loss: 2.442651809705549

Epoch: 6| Step: 6
Training loss: 2.8416320962751414
Validation loss: 2.4316137521979253

Epoch: 6| Step: 7
Training loss: 2.6952524371987554
Validation loss: 2.442160705419837

Epoch: 6| Step: 8
Training loss: 2.891753105462017
Validation loss: 2.4393801005185454

Epoch: 6| Step: 9
Training loss: 2.53006990027081
Validation loss: 2.4481364098972254

Epoch: 6| Step: 10
Training loss: 2.7558539246546476
Validation loss: 2.4272249639864794

Epoch: 6| Step: 11
Training loss: 1.9497498914295748
Validation loss: 2.4363277015301

Epoch: 6| Step: 12
Training loss: 3.0346776715075174
Validation loss: 2.4392815729609225

Epoch: 6| Step: 13
Training loss: 2.7771614111426866
Validation loss: 2.4443682814954704

Epoch: 71| Step: 0
Training loss: 2.5708032388847464
Validation loss: 2.447684807270724

Epoch: 6| Step: 1
Training loss: 2.269437751879474
Validation loss: 2.440054174494575

Epoch: 6| Step: 2
Training loss: 3.0184278359689416
Validation loss: 2.4295463957599335

Epoch: 6| Step: 3
Training loss: 2.2963174156131574
Validation loss: 2.44957413512075

Epoch: 6| Step: 4
Training loss: 1.9987783277077549
Validation loss: 2.454984150227136

Epoch: 6| Step: 5
Training loss: 2.6266851919589165
Validation loss: 2.445930318252396

Epoch: 6| Step: 6
Training loss: 3.1626546105749545
Validation loss: 2.4325819798534454

Epoch: 6| Step: 7
Training loss: 2.1758542279755155
Validation loss: 2.4297059636818634

Epoch: 6| Step: 8
Training loss: 3.518913663645697
Validation loss: 2.45143382139441

Epoch: 6| Step: 9
Training loss: 2.503854355296618
Validation loss: 2.4366153618897055

Epoch: 6| Step: 10
Training loss: 3.258111514633081
Validation loss: 2.4493736007093565

Epoch: 6| Step: 11
Training loss: 2.7283824541365234
Validation loss: 2.452761393553627

Epoch: 6| Step: 12
Training loss: 2.9472572119247054
Validation loss: 2.4447164030765913

Epoch: 6| Step: 13
Training loss: 2.2592001481942297
Validation loss: 2.440525003188534

Epoch: 72| Step: 0
Training loss: 2.7144934119444812
Validation loss: 2.443325970505484

Epoch: 6| Step: 1
Training loss: 3.0015972971450577
Validation loss: 2.4470397673722055

Epoch: 6| Step: 2
Training loss: 2.4355130044131417
Validation loss: 2.4428514004504307

Epoch: 6| Step: 3
Training loss: 2.4870988800369016
Validation loss: 2.4406840214076313

Epoch: 6| Step: 4
Training loss: 2.7827007496161102
Validation loss: 2.4468943995542807

Epoch: 6| Step: 5
Training loss: 2.7368389254621035
Validation loss: 2.4268120752253464

Epoch: 6| Step: 6
Training loss: 3.1554464695959195
Validation loss: 2.42789548802067

Epoch: 6| Step: 7
Training loss: 2.5124109242909167
Validation loss: 2.4280402152642324

Epoch: 6| Step: 8
Training loss: 2.779999355343531
Validation loss: 2.4308710042597643

Epoch: 6| Step: 9
Training loss: 2.903776367172885
Validation loss: 2.432393834570218

Epoch: 6| Step: 10
Training loss: 2.873463427378439
Validation loss: 2.4405557038663264

Epoch: 6| Step: 11
Training loss: 2.278099078749135
Validation loss: 2.4390540720777794

Epoch: 6| Step: 12
Training loss: 2.7399937040716082
Validation loss: 2.456672968263695

Epoch: 6| Step: 13
Training loss: 2.451558481557165
Validation loss: 2.4494920641451072

Epoch: 73| Step: 0
Training loss: 2.946431319330429
Validation loss: 2.445484136351315

Epoch: 6| Step: 1
Training loss: 2.587362213889002
Validation loss: 2.4343646606514713

Epoch: 6| Step: 2
Training loss: 2.1936943634020607
Validation loss: 2.433239371814242

Epoch: 6| Step: 3
Training loss: 2.55576462742768
Validation loss: 2.447298850015403

Epoch: 6| Step: 4
Training loss: 3.1839208516773927
Validation loss: 2.4447015437259694

Epoch: 6| Step: 5
Training loss: 2.955234157882837
Validation loss: 2.4373496266634964

Epoch: 6| Step: 6
Training loss: 3.097531252403943
Validation loss: 2.4335518301724015

Epoch: 6| Step: 7
Training loss: 3.047948873005992
Validation loss: 2.434103464849354

Epoch: 6| Step: 8
Training loss: 2.190549414360555
Validation loss: 2.4304748231300084

Epoch: 6| Step: 9
Training loss: 2.9110918627613005
Validation loss: 2.437535988515971

Epoch: 6| Step: 10
Training loss: 2.001822237527698
Validation loss: 2.441448588342566

Epoch: 6| Step: 11
Training loss: 2.4031835065250293
Validation loss: 2.4508254245600978

Epoch: 6| Step: 12
Training loss: 2.6623711460794337
Validation loss: 2.4394497578886667

Epoch: 6| Step: 13
Training loss: 3.163373556601553
Validation loss: 2.455470910187413

Epoch: 74| Step: 0
Training loss: 2.5583842650406177
Validation loss: 2.4221553421913367

Epoch: 6| Step: 1
Training loss: 2.5723947363727087
Validation loss: 2.4524384413021494

Epoch: 6| Step: 2
Training loss: 3.3004726649393294
Validation loss: 2.454753491174608

Epoch: 6| Step: 3
Training loss: 2.8568851490962937
Validation loss: 2.44786751583678

Epoch: 6| Step: 4
Training loss: 2.741372881360397
Validation loss: 2.4334918825002725

Epoch: 6| Step: 5
Training loss: 3.40606744959512
Validation loss: 2.433400538602742

Epoch: 6| Step: 6
Training loss: 2.8571438448768
Validation loss: 2.431593829084927

Epoch: 6| Step: 7
Training loss: 2.7848461775701456
Validation loss: 2.438226370207279

Epoch: 6| Step: 8
Training loss: 2.0761106666880003
Validation loss: 2.439694814494966

Epoch: 6| Step: 9
Training loss: 1.5814943509285901
Validation loss: 2.436822330582001

Epoch: 6| Step: 10
Training loss: 2.7833114014026052
Validation loss: 2.4334612760131593

Epoch: 6| Step: 11
Training loss: 2.412253680526546
Validation loss: 2.4452899857258146

Epoch: 6| Step: 12
Training loss: 2.864103482832975
Validation loss: 2.449329055861688

Epoch: 6| Step: 13
Training loss: 2.3610762973786885
Validation loss: 2.430080315986768

Epoch: 75| Step: 0
Training loss: 3.215150468547373
Validation loss: 2.444045630482413

Epoch: 6| Step: 1
Training loss: 2.7363174950163796
Validation loss: 2.4254980651364226

Epoch: 6| Step: 2
Training loss: 2.7072393604336864
Validation loss: 2.4374223512156457

Epoch: 6| Step: 3
Training loss: 2.737977798778731
Validation loss: 2.4289317054681074

Epoch: 6| Step: 4
Training loss: 2.8402665150198096
Validation loss: 2.4278791773145

Epoch: 6| Step: 5
Training loss: 2.528868791445963
Validation loss: 2.429013496975738

Epoch: 6| Step: 6
Training loss: 2.359683995507616
Validation loss: 2.420232970253793

Epoch: 6| Step: 7
Training loss: 2.9262851337212323
Validation loss: 2.426230793202934

Epoch: 6| Step: 8
Training loss: 2.5369639013576823
Validation loss: 2.4509893949754713

Epoch: 6| Step: 9
Training loss: 2.4608193020970153
Validation loss: 2.431061743448693

Epoch: 6| Step: 10
Training loss: 2.6283362849123613
Validation loss: 2.4391094328773

Epoch: 6| Step: 11
Training loss: 2.7009404346009203
Validation loss: 2.4457342297936404

Epoch: 6| Step: 12
Training loss: 2.9391779875386317
Validation loss: 2.4509004364242726

Epoch: 6| Step: 13
Training loss: 2.2729646905522025
Validation loss: 2.4474214435596706

Epoch: 76| Step: 0
Training loss: 2.871978498883109
Validation loss: 2.45454167794599

Epoch: 6| Step: 1
Training loss: 2.5979455313548665
Validation loss: 2.451970553176298

Epoch: 6| Step: 2
Training loss: 2.7234985274690304
Validation loss: 2.4387702923835657

Epoch: 6| Step: 3
Training loss: 2.6720471243043553
Validation loss: 2.43018717172023

Epoch: 6| Step: 4
Training loss: 2.265278651631484
Validation loss: 2.441787778908188

Epoch: 6| Step: 5
Training loss: 2.8275225930361083
Validation loss: 2.4401110591237973

Epoch: 6| Step: 6
Training loss: 2.9918829461624328
Validation loss: 2.430154796166566

Epoch: 6| Step: 7
Training loss: 2.804068579429635
Validation loss: 2.442021098232988

Epoch: 6| Step: 8
Training loss: 2.544501667360227
Validation loss: 2.4390838768419916

Epoch: 6| Step: 9
Training loss: 2.5081626196102023
Validation loss: 2.4412614813428895

Epoch: 6| Step: 10
Training loss: 2.386774789804709
Validation loss: 2.4174176881897833

Epoch: 6| Step: 11
Training loss: 2.467183835568645
Validation loss: 2.4350225512477404

Epoch: 6| Step: 12
Training loss: 3.417132710251777
Validation loss: 2.44225220243818

Epoch: 6| Step: 13
Training loss: 2.5095235626215064
Validation loss: 2.4453574073639

Epoch: 77| Step: 0
Training loss: 2.5027688905381975
Validation loss: 2.448207574200434

Epoch: 6| Step: 1
Training loss: 2.786849653390112
Validation loss: 2.4249441150137114

Epoch: 6| Step: 2
Training loss: 2.748885188852772
Validation loss: 2.4316105228871545

Epoch: 6| Step: 3
Training loss: 2.4670340453459487
Validation loss: 2.4249457446804272

Epoch: 6| Step: 4
Training loss: 2.139600633986474
Validation loss: 2.444958233914762

Epoch: 6| Step: 5
Training loss: 2.5356128910293654
Validation loss: 2.4348228841561066

Epoch: 6| Step: 6
Training loss: 2.4314082390839777
Validation loss: 2.4459306353101784

Epoch: 6| Step: 7
Training loss: 2.3973461737425015
Validation loss: 2.4215993660202138

Epoch: 6| Step: 8
Training loss: 2.806653367174885
Validation loss: 2.4445685133844184

Epoch: 6| Step: 9
Training loss: 3.118240064010749
Validation loss: 2.4155704705187175

Epoch: 6| Step: 10
Training loss: 2.411788115941931
Validation loss: 2.4287061146594087

Epoch: 6| Step: 11
Training loss: 3.2354332118809808
Validation loss: 2.436694964885401

Epoch: 6| Step: 12
Training loss: 3.005149712919159
Validation loss: 2.4241942300199857

Epoch: 6| Step: 13
Training loss: 3.102647721234249
Validation loss: 2.4315934073630374

Epoch: 78| Step: 0
Training loss: 3.0471998775114604
Validation loss: 2.4329461796361085

Epoch: 6| Step: 1
Training loss: 3.1760412956647115
Validation loss: 2.438923346822283

Epoch: 6| Step: 2
Training loss: 2.557012683907067
Validation loss: 2.427326638757471

Epoch: 6| Step: 3
Training loss: 2.9902153986273277
Validation loss: 2.4306527386020487

Epoch: 6| Step: 4
Training loss: 2.7573971530137333
Validation loss: 2.428282918231958

Epoch: 6| Step: 5
Training loss: 2.2540166817888077
Validation loss: 2.42026240143783

Epoch: 6| Step: 6
Training loss: 2.711648985092516
Validation loss: 2.423334865816991

Epoch: 6| Step: 7
Training loss: 2.035356215246637
Validation loss: 2.4380292967234714

Epoch: 6| Step: 8
Training loss: 2.8475569510186154
Validation loss: 2.4445785306308334

Epoch: 6| Step: 9
Training loss: 2.344889859539066
Validation loss: 2.4354707765692405

Epoch: 6| Step: 10
Training loss: 2.3375034760638007
Validation loss: 2.435602504979973

Epoch: 6| Step: 11
Training loss: 3.0636999154014513
Validation loss: 2.45652574151371

Epoch: 6| Step: 12
Training loss: 2.8320881594497562
Validation loss: 2.444039901726957

Epoch: 6| Step: 13
Training loss: 2.753075613732834
Validation loss: 2.44804274618991

Epoch: 79| Step: 0
Training loss: 2.297653273989434
Validation loss: 2.440451786503361

Epoch: 6| Step: 1
Training loss: 2.9892070856934065
Validation loss: 2.453672882027181

Epoch: 6| Step: 2
Training loss: 2.5629469318946128
Validation loss: 2.4537708045588564

Epoch: 6| Step: 3
Training loss: 2.7017996300609184
Validation loss: 2.443837593522333

Epoch: 6| Step: 4
Training loss: 3.088952245756237
Validation loss: 2.4373831414628073

Epoch: 6| Step: 5
Training loss: 2.246220805679493
Validation loss: 2.450331416723279

Epoch: 6| Step: 6
Training loss: 3.0148380814276847
Validation loss: 2.425223419034486

Epoch: 6| Step: 7
Training loss: 2.7923783111696077
Validation loss: 2.4547155018482387

Epoch: 6| Step: 8
Training loss: 2.7501604726960633
Validation loss: 2.43447486634371

Epoch: 6| Step: 9
Training loss: 2.6737353891880336
Validation loss: 2.4303130250824907

Epoch: 6| Step: 10
Training loss: 3.022167323430413
Validation loss: 2.448532371264809

Epoch: 6| Step: 11
Training loss: 2.8002309431475356
Validation loss: 2.4402229302155654

Epoch: 6| Step: 12
Training loss: 2.4725251125375665
Validation loss: 2.4335197385199256

Epoch: 6| Step: 13
Training loss: 1.847925404467419
Validation loss: 2.4339228724052915

Epoch: 80| Step: 0
Training loss: 2.58319591854053
Validation loss: 2.4516533086352914

Epoch: 6| Step: 1
Training loss: 2.7316781832266237
Validation loss: 2.4340640647128753

Epoch: 6| Step: 2
Training loss: 3.392612981974069
Validation loss: 2.4383582704223126

Epoch: 6| Step: 3
Training loss: 2.3298040901959647
Validation loss: 2.4155431440576365

Epoch: 6| Step: 4
Training loss: 3.4506177819025723
Validation loss: 2.428940087918198

Epoch: 6| Step: 5
Training loss: 3.0256691121725425
Validation loss: 2.4341695349264323

Epoch: 6| Step: 6
Training loss: 2.5907030708136056
Validation loss: 2.4264779080223913

Epoch: 6| Step: 7
Training loss: 2.723578188879464
Validation loss: 2.451707543185519

Epoch: 6| Step: 8
Training loss: 2.567984317909915
Validation loss: 2.427716311327009

Epoch: 6| Step: 9
Training loss: 2.171641934191301
Validation loss: 2.433047333464902

Epoch: 6| Step: 10
Training loss: 2.2933404416521195
Validation loss: 2.4276296257910195

Epoch: 6| Step: 11
Training loss: 2.3505879660876166
Validation loss: 2.4551715761743624

Epoch: 6| Step: 12
Training loss: 2.814161699866951
Validation loss: 2.4420604959652144

Epoch: 6| Step: 13
Training loss: 2.0108567252012532
Validation loss: 2.4553515261418175

Epoch: 81| Step: 0
Training loss: 2.0541159411416143
Validation loss: 2.4286310284778443

Epoch: 6| Step: 1
Training loss: 2.8036049796570857
Validation loss: 2.424620377419164

Epoch: 6| Step: 2
Training loss: 2.6605928709685793
Validation loss: 2.4444766930052952

Epoch: 6| Step: 3
Training loss: 2.4814853777572807
Validation loss: 2.431848609537333

Epoch: 6| Step: 4
Training loss: 2.4778098445959413
Validation loss: 2.4287963220428144

Epoch: 6| Step: 5
Training loss: 2.4005920474634435
Validation loss: 2.4220573264040572

Epoch: 6| Step: 6
Training loss: 3.4679102525549
Validation loss: 2.426025090911476

Epoch: 6| Step: 7
Training loss: 2.8694281281455325
Validation loss: 2.437320071537641

Epoch: 6| Step: 8
Training loss: 2.9687114512299884
Validation loss: 2.444976922001859

Epoch: 6| Step: 9
Training loss: 2.4540294753514176
Validation loss: 2.450281830608992

Epoch: 6| Step: 10
Training loss: 2.649073251583398
Validation loss: 2.4485227628248514

Epoch: 6| Step: 11
Training loss: 3.1099297876803838
Validation loss: 2.4469910417442042

Epoch: 6| Step: 12
Training loss: 2.644649350841016
Validation loss: 2.439734283943456

Epoch: 6| Step: 13
Training loss: 2.370795594123414
Validation loss: 2.437154616588403

Epoch: 82| Step: 0
Training loss: 2.1510086488075477
Validation loss: 2.4526327598282935

Epoch: 6| Step: 1
Training loss: 2.6453562228740455
Validation loss: 2.450140172888333

Epoch: 6| Step: 2
Training loss: 3.216505434676539
Validation loss: 2.4499581957262673

Epoch: 6| Step: 3
Training loss: 2.1587039418213556
Validation loss: 2.45304947718481

Epoch: 6| Step: 4
Training loss: 2.621110304937939
Validation loss: 2.4542481601223525

Epoch: 6| Step: 5
Training loss: 2.4742843787857676
Validation loss: 2.441072816192418

Epoch: 6| Step: 6
Training loss: 2.8919460267956962
Validation loss: 2.4365442556772994

Epoch: 6| Step: 7
Training loss: 2.713812718731909
Validation loss: 2.444279325825197

Epoch: 6| Step: 8
Training loss: 2.9671724645505875
Validation loss: 2.4650076630982904

Epoch: 6| Step: 9
Training loss: 2.0970676384797144
Validation loss: 2.443827431620194

Epoch: 6| Step: 10
Training loss: 2.9510994882750508
Validation loss: 2.445854258309337

Epoch: 6| Step: 11
Training loss: 3.2013244033979147
Validation loss: 2.4394168705088064

Epoch: 6| Step: 12
Training loss: 2.9602220622096533
Validation loss: 2.440500189943416

Epoch: 6| Step: 13
Training loss: 2.1850680320152303
Validation loss: 2.45805123429358

Epoch: 83| Step: 0
Training loss: 2.775146044075606
Validation loss: 2.4469473346307073

Epoch: 6| Step: 1
Training loss: 2.5628445091337135
Validation loss: 2.452806959925999

Epoch: 6| Step: 2
Training loss: 2.8713664437888458
Validation loss: 2.456372811165104

Epoch: 6| Step: 3
Training loss: 3.0511794764500113
Validation loss: 2.458248999059649

Epoch: 6| Step: 4
Training loss: 2.73661973639644
Validation loss: 2.422616849895048

Epoch: 6| Step: 5
Training loss: 2.468255971417023
Validation loss: 2.427151662438703

Epoch: 6| Step: 6
Training loss: 2.1184744776722773
Validation loss: 2.446111310684376

Epoch: 6| Step: 7
Training loss: 2.45058547828909
Validation loss: 2.45102972169079

Epoch: 6| Step: 8
Training loss: 3.09525301094793
Validation loss: 2.4324294854880133

Epoch: 6| Step: 9
Training loss: 2.8145303814865006
Validation loss: 2.439887796441586

Epoch: 6| Step: 10
Training loss: 2.5899302840699736
Validation loss: 2.4438634979467926

Epoch: 6| Step: 11
Training loss: 2.808685937888548
Validation loss: 2.4377824058620527

Epoch: 6| Step: 12
Training loss: 2.4029887504298437
Validation loss: 2.4485521911052106

Epoch: 6| Step: 13
Training loss: 2.5562041560681337
Validation loss: 2.4183229075752872

Epoch: 84| Step: 0
Training loss: 2.4443913391394316
Validation loss: 2.4410964410914646

Epoch: 6| Step: 1
Training loss: 3.159517919249021
Validation loss: 2.4327493444157953

Epoch: 6| Step: 2
Training loss: 2.544024317241305
Validation loss: 2.4043674901294727

Epoch: 6| Step: 3
Training loss: 3.2769628219288225
Validation loss: 2.420416815810686

Epoch: 6| Step: 4
Training loss: 2.8119836969133627
Validation loss: 2.4373379409720277

Epoch: 6| Step: 5
Training loss: 2.6869382049303363
Validation loss: 2.4375529266408558

Epoch: 6| Step: 6
Training loss: 2.548143223203086
Validation loss: 2.4466607706258703

Epoch: 6| Step: 7
Training loss: 2.4170630119042458
Validation loss: 2.426169331130135

Epoch: 6| Step: 8
Training loss: 2.366994314840409
Validation loss: 2.419760696181651

Epoch: 6| Step: 9
Training loss: 2.4974758757227056
Validation loss: 2.450769626511767

Epoch: 6| Step: 10
Training loss: 2.8094538829281914
Validation loss: 2.45593748947962

Epoch: 6| Step: 11
Training loss: 2.517001989479779
Validation loss: 2.423512480349473

Epoch: 6| Step: 12
Training loss: 2.4095836187902635
Validation loss: 2.42992687704685

Epoch: 6| Step: 13
Training loss: 3.106009804478662
Validation loss: 2.441084188896906

Epoch: 85| Step: 0
Training loss: 2.0254789092228394
Validation loss: 2.4098442390100447

Epoch: 6| Step: 1
Training loss: 2.355676847410066
Validation loss: 2.4342314074154316

Epoch: 6| Step: 2
Training loss: 2.433587577897721
Validation loss: 2.4478673556005632

Epoch: 6| Step: 3
Training loss: 2.467765805074515
Validation loss: 2.435636895336759

Epoch: 6| Step: 4
Training loss: 2.813264615709683
Validation loss: 2.444821519129958

Epoch: 6| Step: 5
Training loss: 3.073541316968395
Validation loss: 2.4234879525466644

Epoch: 6| Step: 6
Training loss: 2.616866180281152
Validation loss: 2.4432419200406645

Epoch: 6| Step: 7
Training loss: 2.7157667608101206
Validation loss: 2.4250520824272863

Epoch: 6| Step: 8
Training loss: 2.86592377713967
Validation loss: 2.4278419791602412

Epoch: 6| Step: 9
Training loss: 2.7552882413087185
Validation loss: 2.453023781591214

Epoch: 6| Step: 10
Training loss: 2.056791323568352
Validation loss: 2.443482867567708

Epoch: 6| Step: 11
Training loss: 2.7951212238098435
Validation loss: 2.4546042416602742

Epoch: 6| Step: 12
Training loss: 3.004656515690723
Validation loss: 2.463549419710784

Epoch: 6| Step: 13
Training loss: 3.6620352857088716
Validation loss: 2.4354520965909683

Epoch: 86| Step: 0
Training loss: 2.8779904941934693
Validation loss: 2.4487319067030224

Epoch: 6| Step: 1
Training loss: 1.8672413838165145
Validation loss: 2.452710358755088

Epoch: 6| Step: 2
Training loss: 3.648036240397686
Validation loss: 2.441785031310147

Epoch: 6| Step: 3
Training loss: 2.618889372037076
Validation loss: 2.4305918656160115

Epoch: 6| Step: 4
Training loss: 3.254295151860815
Validation loss: 2.447674092614562

Epoch: 6| Step: 5
Training loss: 1.7789461060198448
Validation loss: 2.4413744096546033

Epoch: 6| Step: 6
Training loss: 2.6337648927387933
Validation loss: 2.432523985927022

Epoch: 6| Step: 7
Training loss: 2.630043633972935
Validation loss: 2.4421851370117333

Epoch: 6| Step: 8
Training loss: 2.5604643761142425
Validation loss: 2.440747856241298

Epoch: 6| Step: 9
Training loss: 2.711387750794093
Validation loss: 2.4171433701750344

Epoch: 6| Step: 10
Training loss: 2.118763242246943
Validation loss: 2.438475030713459

Epoch: 6| Step: 11
Training loss: 2.326066201321645
Validation loss: 2.417016123080034

Epoch: 6| Step: 12
Training loss: 3.0746631034583394
Validation loss: 2.4617550102930728

Epoch: 6| Step: 13
Training loss: 2.856037631163595
Validation loss: 2.4520599412908375

Epoch: 87| Step: 0
Training loss: 3.4785623691851546
Validation loss: 2.442321176430155

Epoch: 6| Step: 1
Training loss: 2.575971223942929
Validation loss: 2.444599908379675

Epoch: 6| Step: 2
Training loss: 2.963112065307734
Validation loss: 2.4456479784914817

Epoch: 6| Step: 3
Training loss: 2.6527093963952466
Validation loss: 2.4337145479213973

Epoch: 6| Step: 4
Training loss: 3.021800778571204
Validation loss: 2.4611903396523784

Epoch: 6| Step: 5
Training loss: 2.3962658920119293
Validation loss: 2.422488331480218

Epoch: 6| Step: 6
Training loss: 2.4207468666309304
Validation loss: 2.446728792066822

Epoch: 6| Step: 7
Training loss: 2.4525078647188003
Validation loss: 2.4504739128880324

Epoch: 6| Step: 8
Training loss: 2.0730589876886687
Validation loss: 2.4332878165287166

Epoch: 6| Step: 9
Training loss: 2.988833946028717
Validation loss: 2.4398762132689944

Epoch: 6| Step: 10
Training loss: 2.783269427664202
Validation loss: 2.4376855205889303

Epoch: 6| Step: 11
Training loss: 2.6615008346438778
Validation loss: 2.4366665738694673

Epoch: 6| Step: 12
Training loss: 2.6096249763308603
Validation loss: 2.434488557098396

Epoch: 6| Step: 13
Training loss: 2.021761638405496
Validation loss: 2.435566728936327

Epoch: 88| Step: 0
Training loss: 3.090977206474092
Validation loss: 2.433474636933846

Epoch: 6| Step: 1
Training loss: 2.8046716036120283
Validation loss: 2.4394009605253126

Epoch: 6| Step: 2
Training loss: 2.0279624744532447
Validation loss: 2.445072823205038

Epoch: 6| Step: 3
Training loss: 2.745616106192158
Validation loss: 2.461861773096433

Epoch: 6| Step: 4
Training loss: 2.9361068993422625
Validation loss: 2.442040504810808

Epoch: 6| Step: 5
Training loss: 2.64884707004313
Validation loss: 2.4368752814093764

Epoch: 6| Step: 6
Training loss: 2.621792604881762
Validation loss: 2.474487060281769

Epoch: 6| Step: 7
Training loss: 2.478116675960612
Validation loss: 2.4653937694995562

Epoch: 6| Step: 8
Training loss: 2.49211287909935
Validation loss: 2.4483420884451026

Epoch: 6| Step: 9
Training loss: 3.0087583169477483
Validation loss: 2.451990313336507

Epoch: 6| Step: 10
Training loss: 2.3935136484139887
Validation loss: 2.4546987808440495

Epoch: 6| Step: 11
Training loss: 2.870375521346453
Validation loss: 2.442348805788557

Epoch: 6| Step: 12
Training loss: 2.805779969542835
Validation loss: 2.4569043256913594

Epoch: 6| Step: 13
Training loss: 2.412252395652414
Validation loss: 2.4369560320463535

Epoch: 89| Step: 0
Training loss: 2.2370435877898927
Validation loss: 2.454810947928091

Epoch: 6| Step: 1
Training loss: 2.8515852417757532
Validation loss: 2.451521632243421

Epoch: 6| Step: 2
Training loss: 2.7613841154892533
Validation loss: 2.4466960439164254

Epoch: 6| Step: 3
Training loss: 2.33009572434154
Validation loss: 2.4362113655294246

Epoch: 6| Step: 4
Training loss: 2.728864250220295
Validation loss: 2.445052176202599

Epoch: 6| Step: 5
Training loss: 2.775840384585944
Validation loss: 2.4410089373448747

Epoch: 6| Step: 6
Training loss: 2.64382253416584
Validation loss: 2.4316609573156662

Epoch: 6| Step: 7
Training loss: 2.808996773826238
Validation loss: 2.4376607315502468

Epoch: 6| Step: 8
Training loss: 2.792454812308371
Validation loss: 2.4578023253250603

Epoch: 6| Step: 9
Training loss: 2.6912984397345325
Validation loss: 2.4381411319001547

Epoch: 6| Step: 10
Training loss: 2.898401635454492
Validation loss: 2.4553439334108673

Epoch: 6| Step: 11
Training loss: 2.694988905790067
Validation loss: 2.444955461568965

Epoch: 6| Step: 12
Training loss: 2.650898288129665
Validation loss: 2.4499774483971097

Epoch: 6| Step: 13
Training loss: 2.2998102856221676
Validation loss: 2.43822529458732

Epoch: 90| Step: 0
Training loss: 2.9573750264582848
Validation loss: 2.445369158520909

Epoch: 6| Step: 1
Training loss: 2.66744538699073
Validation loss: 2.4472895478526904

Epoch: 6| Step: 2
Training loss: 1.9593804853688044
Validation loss: 2.4451770621122346

Epoch: 6| Step: 3
Training loss: 2.7437602258026805
Validation loss: 2.437505940276786

Epoch: 6| Step: 4
Training loss: 2.4714670801982006
Validation loss: 2.443012437878709

Epoch: 6| Step: 5
Training loss: 3.074472186682548
Validation loss: 2.4347866059952907

Epoch: 6| Step: 6
Training loss: 2.5909106788447867
Validation loss: 2.4453958612925053

Epoch: 6| Step: 7
Training loss: 2.941881199723424
Validation loss: 2.429358778872644

Epoch: 6| Step: 8
Training loss: 2.6445881373993547
Validation loss: 2.4307572968919295

Epoch: 6| Step: 9
Training loss: 2.5518030337076087
Validation loss: 2.4656466751750243

Epoch: 6| Step: 10
Training loss: 2.5108339166076097
Validation loss: 2.4570435421410863

Epoch: 6| Step: 11
Training loss: 2.7292088124367333
Validation loss: 2.430171274100823

Epoch: 6| Step: 12
Training loss: 2.7855133640925303
Validation loss: 2.450104558897161

Epoch: 6| Step: 13
Training loss: 2.8437359149290606
Validation loss: 2.4301484961227398

Epoch: 91| Step: 0
Training loss: 2.861476438668964
Validation loss: 2.453350070660644

Epoch: 6| Step: 1
Training loss: 2.822726159981369
Validation loss: 2.433373156362296

Epoch: 6| Step: 2
Training loss: 2.3426516184394974
Validation loss: 2.4319313686969295

Epoch: 6| Step: 3
Training loss: 2.668809883821605
Validation loss: 2.420887335311806

Epoch: 6| Step: 4
Training loss: 2.391795750589214
Validation loss: 2.4437099042161288

Epoch: 6| Step: 5
Training loss: 2.934669916934834
Validation loss: 2.444056266642048

Epoch: 6| Step: 6
Training loss: 1.8259535062246028
Validation loss: 2.434358269087954

Epoch: 6| Step: 7
Training loss: 2.130489439631272
Validation loss: 2.4220052270613475

Epoch: 6| Step: 8
Training loss: 2.771609195320598
Validation loss: 2.4385876307554617

Epoch: 6| Step: 9
Training loss: 2.6696173515869352
Validation loss: 2.435722104450395

Epoch: 6| Step: 10
Training loss: 2.6475877326931263
Validation loss: 2.427515388518482

Epoch: 6| Step: 11
Training loss: 3.5384728485743193
Validation loss: 2.4353370335654683

Epoch: 6| Step: 12
Training loss: 3.1659745078973334
Validation loss: 2.4306385110116504

Epoch: 6| Step: 13
Training loss: 2.140705079300217
Validation loss: 2.4403385449860506

Epoch: 92| Step: 0
Training loss: 2.6720130393972146
Validation loss: 2.4218255140188902

Epoch: 6| Step: 1
Training loss: 2.696756788648918
Validation loss: 2.450300028203832

Epoch: 6| Step: 2
Training loss: 2.3992774312759715
Validation loss: 2.4333138427453878

Epoch: 6| Step: 3
Training loss: 2.660070387116947
Validation loss: 2.4353528121967103

Epoch: 6| Step: 4
Training loss: 1.6690039537907526
Validation loss: 2.4443759555146545

Epoch: 6| Step: 5
Training loss: 3.02028568609169
Validation loss: 2.4311251602706254

Epoch: 6| Step: 6
Training loss: 2.6378039578119963
Validation loss: 2.4269802269302634

Epoch: 6| Step: 7
Training loss: 2.920962920604252
Validation loss: 2.440474505082873

Epoch: 6| Step: 8
Training loss: 2.9572342635376248
Validation loss: 2.4386956422210058

Epoch: 6| Step: 9
Training loss: 2.398497341540217
Validation loss: 2.4382136141441304

Epoch: 6| Step: 10
Training loss: 2.1468717661115564
Validation loss: 2.430196615299986

Epoch: 6| Step: 11
Training loss: 2.7436728082108526
Validation loss: 2.4421221554104537

Epoch: 6| Step: 12
Training loss: 3.491245765779074
Validation loss: 2.445346128967754

Epoch: 6| Step: 13
Training loss: 2.404468520953355
Validation loss: 2.4573295661664547

Epoch: 93| Step: 0
Training loss: 3.243020559626271
Validation loss: 2.436246537562228

Epoch: 6| Step: 1
Training loss: 2.3696609516912877
Validation loss: 2.4404635161112567

Epoch: 6| Step: 2
Training loss: 2.2115672801765074
Validation loss: 2.4320974846674575

Epoch: 6| Step: 3
Training loss: 2.6035722181231904
Validation loss: 2.454954205379882

Epoch: 6| Step: 4
Training loss: 2.3335824788003037
Validation loss: 2.4393752115436027

Epoch: 6| Step: 5
Training loss: 2.610866463024132
Validation loss: 2.4387249714830874

Epoch: 6| Step: 6
Training loss: 2.482190977533799
Validation loss: 2.4555790591200486

Epoch: 6| Step: 7
Training loss: 2.1128550891282227
Validation loss: 2.4282251473341523

Epoch: 6| Step: 8
Training loss: 3.218588371292732
Validation loss: 2.4530233332458122

Epoch: 6| Step: 9
Training loss: 2.9472837453882987
Validation loss: 2.4468566470563955

Epoch: 6| Step: 10
Training loss: 2.621560977503814
Validation loss: 2.427407238122981

Epoch: 6| Step: 11
Training loss: 2.395208614557608
Validation loss: 2.427558356172611

Epoch: 6| Step: 12
Training loss: 2.9267939812579953
Validation loss: 2.4272491403371554

Epoch: 6| Step: 13
Training loss: 3.1419298488427185
Validation loss: 2.4344535586964864

Epoch: 94| Step: 0
Training loss: 2.3073439983234234
Validation loss: 2.437321040270711

Epoch: 6| Step: 1
Training loss: 2.318677126826682
Validation loss: 2.4387305923590947

Epoch: 6| Step: 2
Training loss: 2.654176957745765
Validation loss: 2.437798219143465

Epoch: 6| Step: 3
Training loss: 2.536099345177716
Validation loss: 2.4455574901289063

Epoch: 6| Step: 4
Training loss: 2.295557591471344
Validation loss: 2.4434852518162655

Epoch: 6| Step: 5
Training loss: 2.721854268289615
Validation loss: 2.4482850463696435

Epoch: 6| Step: 6
Training loss: 3.03821165437214
Validation loss: 2.438286113158844

Epoch: 6| Step: 7
Training loss: 3.1977997964550577
Validation loss: 2.4426141175808977

Epoch: 6| Step: 8
Training loss: 2.894307198649834
Validation loss: 2.4429206592316977

Epoch: 6| Step: 9
Training loss: 2.6167842725173283
Validation loss: 2.428411287805931

Epoch: 6| Step: 10
Training loss: 2.642068141269326
Validation loss: 2.4548922949168697

Epoch: 6| Step: 11
Training loss: 2.5336827020501143
Validation loss: 2.4414077290192093

Epoch: 6| Step: 12
Training loss: 2.422386952095972
Validation loss: 2.4680955693644426

Epoch: 6| Step: 13
Training loss: 3.3666232669664256
Validation loss: 2.4572823977139855

Epoch: 95| Step: 0
Training loss: 2.5288570065752216
Validation loss: 2.4196304076502613

Epoch: 6| Step: 1
Training loss: 2.6864458722558595
Validation loss: 2.444299772213142

Epoch: 6| Step: 2
Training loss: 2.6684103470441727
Validation loss: 2.446781467214379

Epoch: 6| Step: 3
Training loss: 2.4690505219084375
Validation loss: 2.4467886406951806

Epoch: 6| Step: 4
Training loss: 2.611277178179624
Validation loss: 2.4427205026919356

Epoch: 6| Step: 5
Training loss: 3.1809036216202182
Validation loss: 2.4274631560238547

Epoch: 6| Step: 6
Training loss: 3.1175547600948312
Validation loss: 2.449523823043987

Epoch: 6| Step: 7
Training loss: 2.6480926019029574
Validation loss: 2.4417044099268153

Epoch: 6| Step: 8
Training loss: 2.726555154785056
Validation loss: 2.45423918931558

Epoch: 6| Step: 9
Training loss: 2.0606382810739117
Validation loss: 2.4346551230091045

Epoch: 6| Step: 10
Training loss: 2.5367014074599186
Validation loss: 2.4195221861179013

Epoch: 6| Step: 11
Training loss: 2.959345326582028
Validation loss: 2.467569987422878

Epoch: 6| Step: 12
Training loss: 2.4134928700982097
Validation loss: 2.4347363800399746

Epoch: 6| Step: 13
Training loss: 2.6417839621928154
Validation loss: 2.4608396105383097

Epoch: 96| Step: 0
Training loss: 2.429215265729033
Validation loss: 2.453694441743837

Epoch: 6| Step: 1
Training loss: 2.782155264640157
Validation loss: 2.451550746886336

Epoch: 6| Step: 2
Training loss: 2.6758323942990843
Validation loss: 2.4571813390838613

Epoch: 6| Step: 3
Training loss: 2.9277900756667736
Validation loss: 2.441977454390349

Epoch: 6| Step: 4
Training loss: 2.4015431132182483
Validation loss: 2.434367951337863

Epoch: 6| Step: 5
Training loss: 2.5779977478064855
Validation loss: 2.447456717409422

Epoch: 6| Step: 6
Training loss: 2.656060155928401
Validation loss: 2.4417082012535256

Epoch: 6| Step: 7
Training loss: 2.7597984533388953
Validation loss: 2.4341698429842022

Epoch: 6| Step: 8
Training loss: 2.8018176343986063
Validation loss: 2.460351840750705

Epoch: 6| Step: 9
Training loss: 3.0103032883849967
Validation loss: 2.452318910674985

Epoch: 6| Step: 10
Training loss: 2.5142989365737827
Validation loss: 2.451174544093672

Epoch: 6| Step: 11
Training loss: 2.8077635831398187
Validation loss: 2.443466962550646

Epoch: 6| Step: 12
Training loss: 2.5085552696144546
Validation loss: 2.4456169523104823

Epoch: 6| Step: 13
Training loss: 1.8794343646321048
Validation loss: 2.4279422939755606

Epoch: 97| Step: 0
Training loss: 3.1207149882132286
Validation loss: 2.4309556190182438

Epoch: 6| Step: 1
Training loss: 2.4171578028802045
Validation loss: 2.4430107956034255

Epoch: 6| Step: 2
Training loss: 2.63682761638679
Validation loss: 2.4248324202379417

Epoch: 6| Step: 3
Training loss: 2.688157644315325
Validation loss: 2.4480321880897034

Epoch: 6| Step: 4
Training loss: 2.1077130587614934
Validation loss: 2.430211665138196

Epoch: 6| Step: 5
Training loss: 2.189362741011858
Validation loss: 2.4341791858049175

Epoch: 6| Step: 6
Training loss: 1.8398567085862645
Validation loss: 2.443936063805593

Epoch: 6| Step: 7
Training loss: 2.520182775196662
Validation loss: 2.4505869428761646

Epoch: 6| Step: 8
Training loss: 2.5060308194103427
Validation loss: 2.4383310121972075

Epoch: 6| Step: 9
Training loss: 2.745335524434788
Validation loss: 2.435832562626252

Epoch: 6| Step: 10
Training loss: 3.4209870880427444
Validation loss: 2.465003708444728

Epoch: 6| Step: 11
Training loss: 2.797318492656696
Validation loss: 2.439177680142591

Epoch: 6| Step: 12
Training loss: 2.791886809669728
Validation loss: 2.419933438212421

Epoch: 6| Step: 13
Training loss: 3.3213987480969314
Validation loss: 2.4504263122106393

Epoch: 98| Step: 0
Training loss: 2.4577947015718102
Validation loss: 2.4283716443487338

Epoch: 6| Step: 1
Training loss: 2.837034575484606
Validation loss: 2.440436479942071

Epoch: 6| Step: 2
Training loss: 2.550855650116151
Validation loss: 2.434207635320961

Epoch: 6| Step: 3
Training loss: 2.514700962740269
Validation loss: 2.4203853295640343

Epoch: 6| Step: 4
Training loss: 2.8766464826185913
Validation loss: 2.439788744040443

Epoch: 6| Step: 5
Training loss: 2.5619023254083793
Validation loss: 2.419543751874741

Epoch: 6| Step: 6
Training loss: 3.026085455485176
Validation loss: 2.449598011357677

Epoch: 6| Step: 7
Training loss: 2.4859847126043415
Validation loss: 2.4347087201015345

Epoch: 6| Step: 8
Training loss: 2.062392492093314
Validation loss: 2.4223322886177043

Epoch: 6| Step: 9
Training loss: 2.854283536945365
Validation loss: 2.4509723499269906

Epoch: 6| Step: 10
Training loss: 3.398591277052454
Validation loss: 2.4611428701999625

Epoch: 6| Step: 11
Training loss: 2.5937281228487206
Validation loss: 2.419257274048238

Epoch: 6| Step: 12
Training loss: 2.091149836465528
Validation loss: 2.4221969797997915

Epoch: 6| Step: 13
Training loss: 2.7684269736029896
Validation loss: 2.4436441503123523

Epoch: 99| Step: 0
Training loss: 2.0269050490992333
Validation loss: 2.4474488121308586

Epoch: 6| Step: 1
Training loss: 2.3831061510590703
Validation loss: 2.4440885445857266

Epoch: 6| Step: 2
Training loss: 2.5688350802622932
Validation loss: 2.437520830871575

Epoch: 6| Step: 3
Training loss: 2.4068913781602626
Validation loss: 2.4311888337860266

Epoch: 6| Step: 4
Training loss: 2.823524400295223
Validation loss: 2.446518943058685

Epoch: 6| Step: 5
Training loss: 3.1074789582673312
Validation loss: 2.458167353290175

Epoch: 6| Step: 6
Training loss: 3.1510283835054906
Validation loss: 2.440250187793468

Epoch: 6| Step: 7
Training loss: 2.704050776540969
Validation loss: 2.4444742001294517

Epoch: 6| Step: 8
Training loss: 3.1859324471591246
Validation loss: 2.4438802359151506

Epoch: 6| Step: 9
Training loss: 2.892691044016843
Validation loss: 2.435392792552589

Epoch: 6| Step: 10
Training loss: 2.285046801432108
Validation loss: 2.452604074048519

Epoch: 6| Step: 11
Training loss: 2.5320337283161467
Validation loss: 2.464200195079184

Epoch: 6| Step: 12
Training loss: 2.583285444082382
Validation loss: 2.449077233864389

Epoch: 6| Step: 13
Training loss: 2.0982966235855542
Validation loss: 2.4592439036794853

Epoch: 100| Step: 0
Training loss: 2.7527023389350624
Validation loss: 2.443089963034405

Epoch: 6| Step: 1
Training loss: 3.078736994751114
Validation loss: 2.4441814221283082

Epoch: 6| Step: 2
Training loss: 2.574566784313837
Validation loss: 2.4560239785832163

Epoch: 6| Step: 3
Training loss: 2.4977126147676074
Validation loss: 2.4381581015708966

Epoch: 6| Step: 4
Training loss: 2.7329711798199705
Validation loss: 2.459783878708897

Epoch: 6| Step: 5
Training loss: 2.4640773542944583
Validation loss: 2.456236813129471

Epoch: 6| Step: 6
Training loss: 3.066978138848532
Validation loss: 2.4373788543204857

Epoch: 6| Step: 7
Training loss: 2.9377553301287205
Validation loss: 2.43954337609178

Epoch: 6| Step: 8
Training loss: 2.3171431863242624
Validation loss: 2.4472775775514193

Epoch: 6| Step: 9
Training loss: 2.5189381455796216
Validation loss: 2.428738671022521

Epoch: 6| Step: 10
Training loss: 2.4612194081464214
Validation loss: 2.4532581296095275

Epoch: 6| Step: 11
Training loss: 2.977808573865669
Validation loss: 2.431113706179065

Epoch: 6| Step: 12
Training loss: 2.338084277400265
Validation loss: 2.4414580272147326

Epoch: 6| Step: 13
Training loss: 2.019440344529827
Validation loss: 2.4303875550915355

Epoch: 101| Step: 0
Training loss: 2.6410801963546393
Validation loss: 2.4202835787461066

Epoch: 6| Step: 1
Training loss: 3.289332435386153
Validation loss: 2.4419309904198023

Epoch: 6| Step: 2
Training loss: 2.733686960031594
Validation loss: 2.436873013253995

Epoch: 6| Step: 3
Training loss: 3.1485819818934524
Validation loss: 2.4562844233180483

Epoch: 6| Step: 4
Training loss: 2.1267690587681343
Validation loss: 2.4260620411226577

Epoch: 6| Step: 5
Training loss: 2.578169758726056
Validation loss: 2.4354780881006683

Epoch: 6| Step: 6
Training loss: 2.9349726091760666
Validation loss: 2.449445791388392

Epoch: 6| Step: 7
Training loss: 1.951220751389831
Validation loss: 2.447492593038033

Epoch: 6| Step: 8
Training loss: 2.4429015928381683
Validation loss: 2.4505184060630105

Epoch: 6| Step: 9
Training loss: 2.8124759249186595
Validation loss: 2.4403226783054652

Epoch: 6| Step: 10
Training loss: 2.660551828781084
Validation loss: 2.4320882677193976

Epoch: 6| Step: 11
Training loss: 3.007981491295706
Validation loss: 2.431473823061862

Epoch: 6| Step: 12
Training loss: 1.6501347631271552
Validation loss: 2.4523089501362176

Epoch: 6| Step: 13
Training loss: 2.5369186035980222
Validation loss: 2.436910477523996

Epoch: 102| Step: 0
Training loss: 3.2117443695197165
Validation loss: 2.4413988701165343

Epoch: 6| Step: 1
Training loss: 2.7432898237625976
Validation loss: 2.441886624237449

Epoch: 6| Step: 2
Training loss: 2.700094652282883
Validation loss: 2.4151545331629483

Epoch: 6| Step: 3
Training loss: 2.589001272579159
Validation loss: 2.4559698570970103

Epoch: 6| Step: 4
Training loss: 2.6858189670400643
Validation loss: 2.434669292905823

Epoch: 6| Step: 5
Training loss: 2.601229443008313
Validation loss: 2.433593002058758

Epoch: 6| Step: 6
Training loss: 1.8770015206186013
Validation loss: 2.4188898166383126

Epoch: 6| Step: 7
Training loss: 2.6349727472853997
Validation loss: 2.4579954573874008

Epoch: 6| Step: 8
Training loss: 2.9627634824607463
Validation loss: 2.443843472237383

Epoch: 6| Step: 9
Training loss: 1.9321684545287519
Validation loss: 2.451692776398924

Epoch: 6| Step: 10
Training loss: 3.6010518073984814
Validation loss: 2.445974435530659

Epoch: 6| Step: 11
Training loss: 2.185397745589347
Validation loss: 2.4266418385742745

Epoch: 6| Step: 12
Training loss: 2.4695029740131247
Validation loss: 2.444253666517415

Epoch: 6| Step: 13
Training loss: 2.122871005609507
Validation loss: 2.4437607209931107

Epoch: 103| Step: 0
Training loss: 2.9649934793693284
Validation loss: 2.4514916508532933

Epoch: 6| Step: 1
Training loss: 2.193915088669177
Validation loss: 2.439672969236509

Epoch: 6| Step: 2
Training loss: 2.030348122724446
Validation loss: 2.4389949144831573

Epoch: 6| Step: 3
Training loss: 2.777085948197855
Validation loss: 2.4388174977371753

Epoch: 6| Step: 4
Training loss: 2.673253467854022
Validation loss: 2.4261957639112888

Epoch: 6| Step: 5
Training loss: 2.732262716504757
Validation loss: 2.451179745261979

Epoch: 6| Step: 6
Training loss: 1.8296752616544696
Validation loss: 2.4368463869928854

Epoch: 6| Step: 7
Training loss: 2.9789917011945724
Validation loss: 2.430006233366684

Epoch: 6| Step: 8
Training loss: 2.6492951841361068
Validation loss: 2.426300445061139

Epoch: 6| Step: 9
Training loss: 3.223995933662671
Validation loss: 2.4195633880054173

Epoch: 6| Step: 10
Training loss: 3.2820166282627756
Validation loss: 2.4568553824905726

Epoch: 6| Step: 11
Training loss: 2.327265433549289
Validation loss: 2.459277369247998

Epoch: 6| Step: 12
Training loss: 2.645552512657612
Validation loss: 2.453921525571928

Epoch: 6| Step: 13
Training loss: 1.9250265193945548
Validation loss: 2.457141042381863

Epoch: 104| Step: 0
Training loss: 2.651505485285855
Validation loss: 2.450368470687265

Epoch: 6| Step: 1
Training loss: 2.199101121375484
Validation loss: 2.4281859315979974

Epoch: 6| Step: 2
Training loss: 2.9854978675917723
Validation loss: 2.428234889934978

Epoch: 6| Step: 3
Training loss: 2.6023086531742345
Validation loss: 2.4529589608645694

Epoch: 6| Step: 4
Training loss: 3.100026862735647
Validation loss: 2.451178150293985

Epoch: 6| Step: 5
Training loss: 2.855801543374322
Validation loss: 2.4518275406803625

Epoch: 6| Step: 6
Training loss: 2.544763169276764
Validation loss: 2.443713684038787

Epoch: 6| Step: 7
Training loss: 2.31667641516448
Validation loss: 2.438510859758209

Epoch: 6| Step: 8
Training loss: 2.142718217524342
Validation loss: 2.4527875329682423

Epoch: 6| Step: 9
Training loss: 2.794744436628232
Validation loss: 2.454830632486137

Epoch: 6| Step: 10
Training loss: 2.845819747095551
Validation loss: 2.4291931177991146

Epoch: 6| Step: 11
Training loss: 2.997290977590548
Validation loss: 2.450143250125488

Epoch: 6| Step: 12
Training loss: 2.5221754762497404
Validation loss: 2.4464028129439295

Epoch: 6| Step: 13
Training loss: 2.0108588593822185
Validation loss: 2.436530424961227

Epoch: 105| Step: 0
Training loss: 2.5018961391465995
Validation loss: 2.4384714404207126

Epoch: 6| Step: 1
Training loss: 2.5155449137764005
Validation loss: 2.450492931348917

Epoch: 6| Step: 2
Training loss: 2.37763930786057
Validation loss: 2.4350266646123164

Epoch: 6| Step: 3
Training loss: 2.7331768789717223
Validation loss: 2.4452175916249073

Epoch: 6| Step: 4
Training loss: 2.4033184276264956
Validation loss: 2.444476151851142

Epoch: 6| Step: 5
Training loss: 2.420686688689762
Validation loss: 2.439016389522291

Epoch: 6| Step: 6
Training loss: 2.8488550998504376
Validation loss: 2.4267776569987745

Epoch: 6| Step: 7
Training loss: 2.873917251372561
Validation loss: 2.433732904155195

Epoch: 6| Step: 8
Training loss: 2.9115358909872358
Validation loss: 2.437063341598302

Epoch: 6| Step: 9
Training loss: 2.260153642343704
Validation loss: 2.440983300897761

Epoch: 6| Step: 10
Training loss: 3.00335918549459
Validation loss: 2.451865275192033

Epoch: 6| Step: 11
Training loss: 2.8463927345187443
Validation loss: 2.4483339839357474

Epoch: 6| Step: 12
Training loss: 2.9938093525969998
Validation loss: 2.4385681462371434

Epoch: 6| Step: 13
Training loss: 1.6679069990033073
Validation loss: 2.43781019918436

Epoch: 106| Step: 0
Training loss: 2.2090095228522673
Validation loss: 2.4346422482012375

Epoch: 6| Step: 1
Training loss: 2.496591151291894
Validation loss: 2.443258978622458

Epoch: 6| Step: 2
Training loss: 2.710872770300704
Validation loss: 2.4588754792018133

Epoch: 6| Step: 3
Training loss: 2.780311683362249
Validation loss: 2.438538755164651

Epoch: 6| Step: 4
Training loss: 2.4548870003171577
Validation loss: 2.4605603980163604

Epoch: 6| Step: 5
Training loss: 2.5223673627024987
Validation loss: 2.444028303617718

Epoch: 6| Step: 6
Training loss: 1.9849793122220043
Validation loss: 2.445393759341748

Epoch: 6| Step: 7
Training loss: 3.089594352292668
Validation loss: 2.4418549381881234

Epoch: 6| Step: 8
Training loss: 2.9678401155001386
Validation loss: 2.4368914067129355

Epoch: 6| Step: 9
Training loss: 2.957230877405461
Validation loss: 2.4441999273587713

Epoch: 6| Step: 10
Training loss: 2.674619012957067
Validation loss: 2.425230607127076

Epoch: 6| Step: 11
Training loss: 2.278588192165293
Validation loss: 2.444606089382444

Epoch: 6| Step: 12
Training loss: 2.6437222526663358
Validation loss: 2.4498032113945607

Epoch: 6| Step: 13
Training loss: 3.1681386805630503
Validation loss: 2.450736807352032

Epoch: 107| Step: 0
Training loss: 2.5199633796998073
Validation loss: 2.4409875859105297

Epoch: 6| Step: 1
Training loss: 3.076907619107372
Validation loss: 2.4362530138794143

Epoch: 6| Step: 2
Training loss: 2.553726342120125
Validation loss: 2.43909346307996

Epoch: 6| Step: 3
Training loss: 2.6878759431708272
Validation loss: 2.457567061822609

Epoch: 6| Step: 4
Training loss: 2.062048891614525
Validation loss: 2.437419602903785

Epoch: 6| Step: 5
Training loss: 2.9254803776582534
Validation loss: 2.435613619034772

Epoch: 6| Step: 6
Training loss: 2.3176192248641625
Validation loss: 2.4549810947218016

Epoch: 6| Step: 7
Training loss: 2.575732791665801
Validation loss: 2.4564434425497637

Epoch: 6| Step: 8
Training loss: 2.9884880443153232
Validation loss: 2.4467280025622653

Epoch: 6| Step: 9
Training loss: 3.035782561616292
Validation loss: 2.455624959483281

Epoch: 6| Step: 10
Training loss: 2.1881158234382854
Validation loss: 2.4257104624319923

Epoch: 6| Step: 11
Training loss: 2.4304830837041673
Validation loss: 2.433407985937299

Epoch: 6| Step: 12
Training loss: 2.8367727011359505
Validation loss: 2.4578610490238924

Epoch: 6| Step: 13
Training loss: 2.3332450940840705
Validation loss: 2.4602946738659193

Epoch: 108| Step: 0
Training loss: 3.4555805847989642
Validation loss: 2.436831002552826

Epoch: 6| Step: 1
Training loss: 2.553558566797508
Validation loss: 2.4484188977576204

Epoch: 6| Step: 2
Training loss: 2.2291379790079318
Validation loss: 2.4384134714425985

Epoch: 6| Step: 3
Training loss: 2.253244603721855
Validation loss: 2.4461453436913247

Epoch: 6| Step: 4
Training loss: 2.757347694541577
Validation loss: 2.432169069776756

Epoch: 6| Step: 5
Training loss: 2.8025382049705985
Validation loss: 2.427959779455408

Epoch: 6| Step: 6
Training loss: 2.758711454937171
Validation loss: 2.4402357913380337

Epoch: 6| Step: 7
Training loss: 2.7513132427595255
Validation loss: 2.4374703467800063

Epoch: 6| Step: 8
Training loss: 2.703515878982433
Validation loss: 2.450196489587805

Epoch: 6| Step: 9
Training loss: 2.8178184238628363
Validation loss: 2.4630140964013623

Epoch: 6| Step: 10
Training loss: 2.72154013745105
Validation loss: 2.459234466354798

Epoch: 6| Step: 11
Training loss: 2.2620495173855066
Validation loss: 2.4575356634882097

Epoch: 6| Step: 12
Training loss: 2.4104035434568982
Validation loss: 2.4483582408407094

Epoch: 6| Step: 13
Training loss: 2.296519972163087
Validation loss: 2.4596473688649834

Epoch: 109| Step: 0
Training loss: 2.1148797439764593
Validation loss: 2.4436857511896446

Epoch: 6| Step: 1
Training loss: 3.197254290412102
Validation loss: 2.4552542054325546

Epoch: 6| Step: 2
Training loss: 2.688320123490643
Validation loss: 2.455997989479357

Epoch: 6| Step: 3
Training loss: 2.049111229435075
Validation loss: 2.4526205438360695

Epoch: 6| Step: 4
Training loss: 2.773326430984613
Validation loss: 2.4563419173189738

Epoch: 6| Step: 5
Training loss: 3.1275541929921116
Validation loss: 2.4606489260713373

Epoch: 6| Step: 6
Training loss: 2.211829339230065
Validation loss: 2.439270857126546

Epoch: 6| Step: 7
Training loss: 2.1274509880615358
Validation loss: 2.460233110367438

Epoch: 6| Step: 8
Training loss: 2.798357011499096
Validation loss: 2.430811324796376

Epoch: 6| Step: 9
Training loss: 2.6213618907414227
Validation loss: 2.456443276611127

Epoch: 6| Step: 10
Training loss: 3.5895714391923486
Validation loss: 2.4242482709470377

Epoch: 6| Step: 11
Training loss: 2.6294021025453898
Validation loss: 2.4650246313760986

Epoch: 6| Step: 12
Training loss: 2.292939012064934
Validation loss: 2.432376631808961

Epoch: 6| Step: 13
Training loss: 2.1862162501596583
Validation loss: 2.455732542079207

Epoch: 110| Step: 0
Training loss: 2.314443853818456
Validation loss: 2.4512878199672925

Epoch: 6| Step: 1
Training loss: 2.5774365054874457
Validation loss: 2.4330887551756093

Epoch: 6| Step: 2
Training loss: 2.644836858899405
Validation loss: 2.4315220478032114

Epoch: 6| Step: 3
Training loss: 2.157057016806668
Validation loss: 2.4114444377630555

Epoch: 6| Step: 4
Training loss: 2.999781282717229
Validation loss: 2.419694067918698

Epoch: 6| Step: 5
Training loss: 2.225266678505367
Validation loss: 2.461616139970601

Epoch: 6| Step: 6
Training loss: 3.156197877963427
Validation loss: 2.4434947866888908

Epoch: 6| Step: 7
Training loss: 2.2393828073078565
Validation loss: 2.452969481037027

Epoch: 6| Step: 8
Training loss: 2.7227522232457093
Validation loss: 2.4449339002867

Epoch: 6| Step: 9
Training loss: 2.9668949153690587
Validation loss: 2.4634288109949263

Epoch: 6| Step: 10
Training loss: 2.942920310338513
Validation loss: 2.452953759288361

Epoch: 6| Step: 11
Training loss: 2.1735117940045225
Validation loss: 2.4427307762477435

Epoch: 6| Step: 12
Training loss: 2.658761486464466
Validation loss: 2.459340658926787

Epoch: 6| Step: 13
Training loss: 2.8468758307747826
Validation loss: 2.46150443765082

Epoch: 111| Step: 0
Training loss: 2.935558245466169
Validation loss: 2.446530756748019

Epoch: 6| Step: 1
Training loss: 2.6014097243347742
Validation loss: 2.4480612149016068

Epoch: 6| Step: 2
Training loss: 2.6658084998524822
Validation loss: 2.442589030107457

Epoch: 6| Step: 3
Training loss: 2.253721338683317
Validation loss: 2.4525438943347

Epoch: 6| Step: 4
Training loss: 3.1489427033411994
Validation loss: 2.4644238620880206

Epoch: 6| Step: 5
Training loss: 2.1600158535410863
Validation loss: 2.456832306693159

Epoch: 6| Step: 6
Training loss: 2.3067212458127204
Validation loss: 2.449509406260878

Epoch: 6| Step: 7
Training loss: 3.271081190173971
Validation loss: 2.441379580247476

Epoch: 6| Step: 8
Training loss: 2.603085000782969
Validation loss: 2.4585736979139754

Epoch: 6| Step: 9
Training loss: 2.3935398457758437
Validation loss: 2.453681042039144

Epoch: 6| Step: 10
Training loss: 2.5268990126833906
Validation loss: 2.4497753207710025

Epoch: 6| Step: 11
Training loss: 1.8954417764047722
Validation loss: 2.4741931897501237

Epoch: 6| Step: 12
Training loss: 2.85361571922967
Validation loss: 2.457123166723112

Epoch: 6| Step: 13
Training loss: 2.9126943695306258
Validation loss: 2.450900902940006

Epoch: 112| Step: 0
Training loss: 2.195335958226536
Validation loss: 2.4429868812218367

Epoch: 6| Step: 1
Training loss: 2.825313203041741
Validation loss: 2.4588476987830052

Epoch: 6| Step: 2
Training loss: 2.704407580615589
Validation loss: 2.4340110095451704

Epoch: 6| Step: 3
Training loss: 2.265962562406651
Validation loss: 2.452427979481876

Epoch: 6| Step: 4
Training loss: 2.6496573820493348
Validation loss: 2.451245888978093

Epoch: 6| Step: 5
Training loss: 2.717029246218135
Validation loss: 2.459841899560178

Epoch: 6| Step: 6
Training loss: 3.0906799188098835
Validation loss: 2.4531277526626836

Epoch: 6| Step: 7
Training loss: 2.4098350273745663
Validation loss: 2.4580595341277935

Epoch: 6| Step: 8
Training loss: 2.2706330820617566
Validation loss: 2.4561775412464795

Epoch: 6| Step: 9
Training loss: 2.694925208531331
Validation loss: 2.4469434560817005

Epoch: 6| Step: 10
Training loss: 2.5141455049249
Validation loss: 2.448255028485597

Epoch: 6| Step: 11
Training loss: 2.88574813609793
Validation loss: 2.4544811410054566

Epoch: 6| Step: 12
Training loss: 2.94686257935189
Validation loss: 2.450397708884067

Epoch: 6| Step: 13
Training loss: 2.3886821556337945
Validation loss: 2.46507274262845

Epoch: 113| Step: 0
Training loss: 2.2917194244785346
Validation loss: 2.4498275772340015

Epoch: 6| Step: 1
Training loss: 2.3858259313612673
Validation loss: 2.4290085713040646

Epoch: 6| Step: 2
Training loss: 3.0557581593553502
Validation loss: 2.441534067134648

Epoch: 6| Step: 3
Training loss: 2.4721606874368134
Validation loss: 2.432124610372997

Epoch: 6| Step: 4
Training loss: 2.8709867911624563
Validation loss: 2.44098313495839

Epoch: 6| Step: 5
Training loss: 2.6386656404615003
Validation loss: 2.4387992465243937

Epoch: 6| Step: 6
Training loss: 2.631785025307651
Validation loss: 2.4307765276224087

Epoch: 6| Step: 7
Training loss: 2.845724573100367
Validation loss: 2.451914669311929

Epoch: 6| Step: 8
Training loss: 2.9234756736363074
Validation loss: 2.44228874024359

Epoch: 6| Step: 9
Training loss: 2.738353080732483
Validation loss: 2.4437643223980032

Epoch: 6| Step: 10
Training loss: 2.0890786740255405
Validation loss: 2.4346876587887962

Epoch: 6| Step: 11
Training loss: 2.326806738480032
Validation loss: 2.4450969426086595

Epoch: 6| Step: 12
Training loss: 2.6267298493636697
Validation loss: 2.4429414779872496

Epoch: 6| Step: 13
Training loss: 2.8253041736609625
Validation loss: 2.4336440574750124

Epoch: 114| Step: 0
Training loss: 3.222369335002515
Validation loss: 2.435886561104713

Epoch: 6| Step: 1
Training loss: 2.7868991015962576
Validation loss: 2.435285652563965

Epoch: 6| Step: 2
Training loss: 2.983425129023398
Validation loss: 2.4634783447746833

Epoch: 6| Step: 3
Training loss: 2.163820990021002
Validation loss: 2.4480203774570763

Epoch: 6| Step: 4
Training loss: 2.1189697196708783
Validation loss: 2.4339827420531046

Epoch: 6| Step: 5
Training loss: 2.323865026917458
Validation loss: 2.4500810035941014

Epoch: 6| Step: 6
Training loss: 2.8224784163671037
Validation loss: 2.436382527663972

Epoch: 6| Step: 7
Training loss: 2.2625153346095273
Validation loss: 2.4332308666809457

Epoch: 6| Step: 8
Training loss: 2.327442862918737
Validation loss: 2.4529949106973192

Epoch: 6| Step: 9
Training loss: 2.573888175704985
Validation loss: 2.4438738002659006

Epoch: 6| Step: 10
Training loss: 2.476126166091961
Validation loss: 2.4616067466291884

Epoch: 6| Step: 11
Training loss: 3.1188099398615177
Validation loss: 2.4555602115973696

Epoch: 6| Step: 12
Training loss: 2.3787447869889693
Validation loss: 2.453858631029543

Epoch: 6| Step: 13
Training loss: 3.0499638477121453
Validation loss: 2.441252280091098

Epoch: 115| Step: 0
Training loss: 2.0007189412154527
Validation loss: 2.444522269081544

Epoch: 6| Step: 1
Training loss: 2.4396225906284337
Validation loss: 2.4399465100083653

Epoch: 6| Step: 2
Training loss: 2.1376712217406824
Validation loss: 2.4458372256896537

Epoch: 6| Step: 3
Training loss: 2.1735379007324465
Validation loss: 2.4564494935623125

Epoch: 6| Step: 4
Training loss: 3.1032931402316772
Validation loss: 2.4501406950039883

Epoch: 6| Step: 5
Training loss: 2.244551631783167
Validation loss: 2.469065236798433

Epoch: 6| Step: 6
Training loss: 3.4318696120953995
Validation loss: 2.4528475713550746

Epoch: 6| Step: 7
Training loss: 2.1269601869071817
Validation loss: 2.464797086260822

Epoch: 6| Step: 8
Training loss: 2.089745292839903
Validation loss: 2.4212326568779114

Epoch: 6| Step: 9
Training loss: 3.0448451396480705
Validation loss: 2.435057035072445

Epoch: 6| Step: 10
Training loss: 3.40539372031794
Validation loss: 2.441576112412429

Epoch: 6| Step: 11
Training loss: 2.7036792870391095
Validation loss: 2.4510681776242214

Epoch: 6| Step: 12
Training loss: 2.307501674994525
Validation loss: 2.4377097404278047

Epoch: 6| Step: 13
Training loss: 3.214402012007802
Validation loss: 2.4602217334401635

Epoch: 116| Step: 0
Training loss: 1.9522348435378158
Validation loss: 2.4255291711023257

Epoch: 6| Step: 1
Training loss: 2.827285220406547
Validation loss: 2.4658407481786533

Epoch: 6| Step: 2
Training loss: 2.845903021730403
Validation loss: 2.4690999615976117

Epoch: 6| Step: 3
Training loss: 2.9648530781514983
Validation loss: 2.441499644865997

Epoch: 6| Step: 4
Training loss: 2.3335264898005925
Validation loss: 2.4497267426923495

Epoch: 6| Step: 5
Training loss: 2.4934258807272904
Validation loss: 2.4583861100455144

Epoch: 6| Step: 6
Training loss: 3.162382607674824
Validation loss: 2.4483244720975246

Epoch: 6| Step: 7
Training loss: 2.7683894247687824
Validation loss: 2.441056880244206

Epoch: 6| Step: 8
Training loss: 2.662804628236773
Validation loss: 2.465992214985375

Epoch: 6| Step: 9
Training loss: 2.4211151900054544
Validation loss: 2.451500587270072

Epoch: 6| Step: 10
Training loss: 2.465569197454767
Validation loss: 2.4360204233774003

Epoch: 6| Step: 11
Training loss: 2.5570156676193214
Validation loss: 2.458080107333139

Epoch: 6| Step: 12
Training loss: 2.3291666657567807
Validation loss: 2.4666190482728485

Epoch: 6| Step: 13
Training loss: 2.639502563284547
Validation loss: 2.455997074041614

Epoch: 117| Step: 0
Training loss: 1.994544814915743
Validation loss: 2.4419366369860933

Epoch: 6| Step: 1
Training loss: 2.7552194480936216
Validation loss: 2.442153934569342

Epoch: 6| Step: 2
Training loss: 2.3290845698410525
Validation loss: 2.456674099984386

Epoch: 6| Step: 3
Training loss: 1.6166442843326512
Validation loss: 2.46669798961109

Epoch: 6| Step: 4
Training loss: 2.843416634606857
Validation loss: 2.432047439297365

Epoch: 6| Step: 5
Training loss: 2.2497299880032045
Validation loss: 2.449577740537448

Epoch: 6| Step: 6
Training loss: 2.9507992583056852
Validation loss: 2.458461579456726

Epoch: 6| Step: 7
Training loss: 2.3530200990595826
Validation loss: 2.4394097767645353

Epoch: 6| Step: 8
Training loss: 2.828439768772482
Validation loss: 2.4436183316884206

Epoch: 6| Step: 9
Training loss: 2.9258532852655845
Validation loss: 2.431146461236457

Epoch: 6| Step: 10
Training loss: 3.002744373092988
Validation loss: 2.4397509057581828

Epoch: 6| Step: 11
Training loss: 3.002749137102714
Validation loss: 2.4489713143695093

Epoch: 6| Step: 12
Training loss: 2.976838987630397
Validation loss: 2.458607051649453

Epoch: 6| Step: 13
Training loss: 2.2089825401669545
Validation loss: 2.464828042625349

Epoch: 118| Step: 0
Training loss: 2.856565335352356
Validation loss: 2.449911956364527

Epoch: 6| Step: 1
Training loss: 2.9913198144260225
Validation loss: 2.444811429476827

Epoch: 6| Step: 2
Training loss: 2.793126839385128
Validation loss: 2.445595547286693

Epoch: 6| Step: 3
Training loss: 2.4127897098503968
Validation loss: 2.463576857819259

Epoch: 6| Step: 4
Training loss: 2.7541352305347155
Validation loss: 2.45734263821514

Epoch: 6| Step: 5
Training loss: 2.710588328276388
Validation loss: 2.4454432275660993

Epoch: 6| Step: 6
Training loss: 2.900927849025878
Validation loss: 2.4528518387770424

Epoch: 6| Step: 7
Training loss: 2.6817226855786958
Validation loss: 2.439417753284428

Epoch: 6| Step: 8
Training loss: 2.2840011937928293
Validation loss: 2.4388731676914097

Epoch: 6| Step: 9
Training loss: 2.2863365841879646
Validation loss: 2.4535307665219643

Epoch: 6| Step: 10
Training loss: 2.6194437350823567
Validation loss: 2.4276984830068007

Epoch: 6| Step: 11
Training loss: 2.580745498087174
Validation loss: 2.433759414374278

Epoch: 6| Step: 12
Training loss: 2.4027813768696764
Validation loss: 2.4521041782943

Epoch: 6| Step: 13
Training loss: 1.856600960071648
Validation loss: 2.447793809211658

Epoch: 119| Step: 0
Training loss: 2.6527153282959093
Validation loss: 2.4483704330749734

Epoch: 6| Step: 1
Training loss: 2.7605587520859363
Validation loss: 2.4454273379200364

Epoch: 6| Step: 2
Training loss: 2.8689533169905013
Validation loss: 2.446337560033322

Epoch: 6| Step: 3
Training loss: 2.449965659698848
Validation loss: 2.4517016613682063

Epoch: 6| Step: 4
Training loss: 3.045435795409248
Validation loss: 2.463739910906606

Epoch: 6| Step: 5
Training loss: 2.052082455500949
Validation loss: 2.446103103411302

Epoch: 6| Step: 6
Training loss: 2.3079342489083037
Validation loss: 2.449465681287162

Epoch: 6| Step: 7
Training loss: 2.8413914551872868
Validation loss: 2.453876767623233

Epoch: 6| Step: 8
Training loss: 2.183320657921414
Validation loss: 2.457286299588826

Epoch: 6| Step: 9
Training loss: 2.8895545420808646
Validation loss: 2.442004546985638

Epoch: 6| Step: 10
Training loss: 2.0440785181898935
Validation loss: 2.44836041877777

Epoch: 6| Step: 11
Training loss: 2.7174337423576684
Validation loss: 2.4451687337525487

Epoch: 6| Step: 12
Training loss: 2.7669143688433366
Validation loss: 2.4514836989783597

Epoch: 6| Step: 13
Training loss: 2.758140738948241
Validation loss: 2.4392104730032482

Epoch: 120| Step: 0
Training loss: 3.1026059180414802
Validation loss: 2.431213441012862

Epoch: 6| Step: 1
Training loss: 2.859760696163028
Validation loss: 2.4303507597782823

Epoch: 6| Step: 2
Training loss: 2.365540488584185
Validation loss: 2.4567218884887843

Epoch: 6| Step: 3
Training loss: 2.469935072381415
Validation loss: 2.4503662563476984

Epoch: 6| Step: 4
Training loss: 2.8790039708440385
Validation loss: 2.4533979876531546

Epoch: 6| Step: 5
Training loss: 2.736912971855158
Validation loss: 2.433210391550292

Epoch: 6| Step: 6
Training loss: 1.9009561667528396
Validation loss: 2.461675201755748

Epoch: 6| Step: 7
Training loss: 3.1248162787791296
Validation loss: 2.4355163969665785

Epoch: 6| Step: 8
Training loss: 2.2823277892947074
Validation loss: 2.4586107376646082

Epoch: 6| Step: 9
Training loss: 2.5586136911794477
Validation loss: 2.4445510329184454

Epoch: 6| Step: 10
Training loss: 2.8133502946435756
Validation loss: 2.4732583997614004

Epoch: 6| Step: 11
Training loss: 2.550876586441008
Validation loss: 2.449417381751727

Epoch: 6| Step: 12
Training loss: 1.9520397375470846
Validation loss: 2.4414188759754163

Epoch: 6| Step: 13
Training loss: 2.635862581627664
Validation loss: 2.429165869125409

Epoch: 121| Step: 0
Training loss: 2.5441271228218207
Validation loss: 2.4589166899809243

Epoch: 6| Step: 1
Training loss: 2.341297341360473
Validation loss: 2.4376225373646685

Epoch: 6| Step: 2
Training loss: 2.40757090986011
Validation loss: 2.44556858410131

Epoch: 6| Step: 3
Training loss: 3.136909982592998
Validation loss: 2.435875411459453

Epoch: 6| Step: 4
Training loss: 1.7575577614898308
Validation loss: 2.4546034249227833

Epoch: 6| Step: 5
Training loss: 2.712734539246316
Validation loss: 2.4475453612041402

Epoch: 6| Step: 6
Training loss: 2.7337951045246514
Validation loss: 2.4655054614576857

Epoch: 6| Step: 7
Training loss: 2.854062674825319
Validation loss: 2.456847207978433

Epoch: 6| Step: 8
Training loss: 2.59097205622455
Validation loss: 2.4694311142953733

Epoch: 6| Step: 9
Training loss: 2.543045535005052
Validation loss: 2.4659561687396163

Epoch: 6| Step: 10
Training loss: 3.0096678721045644
Validation loss: 2.4361728045111763

Epoch: 6| Step: 11
Training loss: 2.2160182845948477
Validation loss: 2.431385793230221

Epoch: 6| Step: 12
Training loss: 2.586983460546352
Validation loss: 2.434687659841761

Epoch: 6| Step: 13
Training loss: 2.7568809946116515
Validation loss: 2.453899145654905

Epoch: 122| Step: 0
Training loss: 2.740837786601195
Validation loss: 2.4350318623707197

Epoch: 6| Step: 1
Training loss: 2.7835147509203733
Validation loss: 2.465135706724281

Epoch: 6| Step: 2
Training loss: 2.4367765673559583
Validation loss: 2.455745965561794

Epoch: 6| Step: 3
Training loss: 3.0854383620264167
Validation loss: 2.4373639607547015

Epoch: 6| Step: 4
Training loss: 2.397568535963791
Validation loss: 2.473869982417155

Epoch: 6| Step: 5
Training loss: 2.460007361579363
Validation loss: 2.4627612972095405

Epoch: 6| Step: 6
Training loss: 2.116459907986508
Validation loss: 2.445558253280089

Epoch: 6| Step: 7
Training loss: 1.8888148319773648
Validation loss: 2.4381259948415686

Epoch: 6| Step: 8
Training loss: 2.6935277364778134
Validation loss: 2.4449316773551857

Epoch: 6| Step: 9
Training loss: 2.7666121623021
Validation loss: 2.472498070273479

Epoch: 6| Step: 10
Training loss: 2.6389852093523873
Validation loss: 2.449916289069071

Epoch: 6| Step: 11
Training loss: 3.1654155334280487
Validation loss: 2.4470509541508183

Epoch: 6| Step: 12
Training loss: 2.558413154110662
Validation loss: 2.4455803845608006

Epoch: 6| Step: 13
Training loss: 2.3956131101373432
Validation loss: 2.4296811174991344

Epoch: 123| Step: 0
Training loss: 3.104525210435013
Validation loss: 2.4430496915213316

Epoch: 6| Step: 1
Training loss: 3.067934158553717
Validation loss: 2.452358219282921

Epoch: 6| Step: 2
Training loss: 2.7252202706160222
Validation loss: 2.465130081578379

Epoch: 6| Step: 3
Training loss: 2.563542130857878
Validation loss: 2.4506247320584396

Epoch: 6| Step: 4
Training loss: 3.0044971772775964
Validation loss: 2.4416304679045577

Epoch: 6| Step: 5
Training loss: 1.849241709596854
Validation loss: 2.450814671332518

Epoch: 6| Step: 6
Training loss: 1.737926318333062
Validation loss: 2.4407162131781974

Epoch: 6| Step: 7
Training loss: 3.047650830210991
Validation loss: 2.437503664294261

Epoch: 6| Step: 8
Training loss: 2.433439442746602
Validation loss: 2.438192497939409

Epoch: 6| Step: 9
Training loss: 2.677864188422053
Validation loss: 2.4346082449871833

Epoch: 6| Step: 10
Training loss: 2.3494876059468894
Validation loss: 2.446658328174765

Epoch: 6| Step: 11
Training loss: 2.391182828160153
Validation loss: 2.449419974259864

Epoch: 6| Step: 12
Training loss: 2.5524052215824065
Validation loss: 2.4484069172717877

Epoch: 6| Step: 13
Training loss: 2.4878035585367106
Validation loss: 2.445665968946758

Epoch: 124| Step: 0
Training loss: 2.26851422474542
Validation loss: 2.4449309895042695

Epoch: 6| Step: 1
Training loss: 2.23311456728574
Validation loss: 2.446106054720944

Epoch: 6| Step: 2
Training loss: 3.1643382764655983
Validation loss: 2.4331750397124825

Epoch: 6| Step: 3
Training loss: 2.3664378373464414
Validation loss: 2.4464726863727377

Epoch: 6| Step: 4
Training loss: 3.05657104803001
Validation loss: 2.4536451242007367

Epoch: 6| Step: 5
Training loss: 2.0425924680362737
Validation loss: 2.4541272572550845

Epoch: 6| Step: 6
Training loss: 2.2586958586004746
Validation loss: 2.441694948908345

Epoch: 6| Step: 7
Training loss: 2.365270259972412
Validation loss: 2.4623964952872543

Epoch: 6| Step: 8
Training loss: 2.5148898169951655
Validation loss: 2.4746746272799798

Epoch: 6| Step: 9
Training loss: 3.0849584644062578
Validation loss: 2.4541609346624482

Epoch: 6| Step: 10
Training loss: 2.868306204183408
Validation loss: 2.462087777723437

Epoch: 6| Step: 11
Training loss: 2.8302890654220563
Validation loss: 2.4455926587812935

Epoch: 6| Step: 12
Training loss: 2.3036039229727723
Validation loss: 2.441537695974225

Epoch: 6| Step: 13
Training loss: 2.7952296356149904
Validation loss: 2.4642246505603187

Epoch: 125| Step: 0
Training loss: 2.4601030176193444
Validation loss: 2.4802521972592273

Epoch: 6| Step: 1
Training loss: 2.3740806808066766
Validation loss: 2.4423364543850377

Epoch: 6| Step: 2
Training loss: 3.3911043874185927
Validation loss: 2.460936266587419

Epoch: 6| Step: 3
Training loss: 2.703634401514151
Validation loss: 2.4753639626028425

Epoch: 6| Step: 4
Training loss: 3.2693218132218496
Validation loss: 2.459628080360369

Epoch: 6| Step: 5
Training loss: 2.538028165975106
Validation loss: 2.4514539649702263

Epoch: 6| Step: 6
Training loss: 2.53443190655396
Validation loss: 2.4489412420872108

Epoch: 6| Step: 7
Training loss: 1.944996390645814
Validation loss: 2.4429975303860494

Epoch: 6| Step: 8
Training loss: 2.2582132056499074
Validation loss: 2.430862351102597

Epoch: 6| Step: 9
Training loss: 2.127836578138787
Validation loss: 2.445892269447943

Epoch: 6| Step: 10
Training loss: 2.840927232164201
Validation loss: 2.4495785327865014

Epoch: 6| Step: 11
Training loss: 2.40267619492183
Validation loss: 2.453467723512582

Epoch: 6| Step: 12
Training loss: 2.6042836480886926
Validation loss: 2.4578379247792257

Epoch: 6| Step: 13
Training loss: 2.6248862832278905
Validation loss: 2.454292355595504

Epoch: 126| Step: 0
Training loss: 2.875128038291906
Validation loss: 2.4432922350384407

Epoch: 6| Step: 1
Training loss: 2.6766220665141884
Validation loss: 2.4557320159327327

Epoch: 6| Step: 2
Training loss: 2.3203372632898382
Validation loss: 2.458194091201679

Epoch: 6| Step: 3
Training loss: 2.4762436333564355
Validation loss: 2.4299841575286747

Epoch: 6| Step: 4
Training loss: 2.182168293988196
Validation loss: 2.439171684028441

Epoch: 6| Step: 5
Training loss: 3.005299496824367
Validation loss: 2.4482382607397546

Epoch: 6| Step: 6
Training loss: 2.758774889344124
Validation loss: 2.450085842955009

Epoch: 6| Step: 7
Training loss: 2.79402040542655
Validation loss: 2.443001590446386

Epoch: 6| Step: 8
Training loss: 3.300851746658424
Validation loss: 2.4412494657318775

Epoch: 6| Step: 9
Training loss: 1.912179137098014
Validation loss: 2.458600238502508

Epoch: 6| Step: 10
Training loss: 1.9014920750587498
Validation loss: 2.430058996180781

Epoch: 6| Step: 11
Training loss: 2.6117088251498717
Validation loss: 2.4462300442384954

Epoch: 6| Step: 12
Training loss: 2.950582873418016
Validation loss: 2.4292572878276824

Epoch: 6| Step: 13
Training loss: 1.9206923280652592
Validation loss: 2.4456643122056296

Epoch: 127| Step: 0
Training loss: 2.677036052439715
Validation loss: 2.4575196658205005

Epoch: 6| Step: 1
Training loss: 2.2721512029731565
Validation loss: 2.4442132825457454

Epoch: 6| Step: 2
Training loss: 2.207329923962205
Validation loss: 2.4418131024404053

Epoch: 6| Step: 3
Training loss: 2.684381316669391
Validation loss: 2.4410870465050616

Epoch: 6| Step: 4
Training loss: 3.002653220251047
Validation loss: 2.4502880025100664

Epoch: 6| Step: 5
Training loss: 3.0065610982401756
Validation loss: 2.4417330814921203

Epoch: 6| Step: 6
Training loss: 2.7607397694099776
Validation loss: 2.4418675754918375

Epoch: 6| Step: 7
Training loss: 2.4404447325341567
Validation loss: 2.457112031018205

Epoch: 6| Step: 8
Training loss: 1.8477110904998917
Validation loss: 2.440316559990903

Epoch: 6| Step: 9
Training loss: 2.707801874297305
Validation loss: 2.4488816397360833

Epoch: 6| Step: 10
Training loss: 2.400728008003886
Validation loss: 2.4461929165831306

Epoch: 6| Step: 11
Training loss: 2.366729792796249
Validation loss: 2.4444229021161035

Epoch: 6| Step: 12
Training loss: 2.7351943178205445
Validation loss: 2.457400294196464

Epoch: 6| Step: 13
Training loss: 3.197948012472766
Validation loss: 2.4714109411510323

Epoch: 128| Step: 0
Training loss: 3.0963330515448217
Validation loss: 2.469912036786512

Epoch: 6| Step: 1
Training loss: 2.696131396631858
Validation loss: 2.4369158080246494

Epoch: 6| Step: 2
Training loss: 2.169780791852574
Validation loss: 2.4252495444778326

Epoch: 6| Step: 3
Training loss: 2.650684225171355
Validation loss: 2.444826954019393

Epoch: 6| Step: 4
Training loss: 2.4601938244205557
Validation loss: 2.4372300323761342

Epoch: 6| Step: 5
Training loss: 3.185622017334935
Validation loss: 2.4378441903369894

Epoch: 6| Step: 6
Training loss: 2.834267032337585
Validation loss: 2.4491982447142706

Epoch: 6| Step: 7
Training loss: 3.362222857203833
Validation loss: 2.461413507868939

Epoch: 6| Step: 8
Training loss: 2.1435019658237393
Validation loss: 2.4420666561010096

Epoch: 6| Step: 9
Training loss: 2.1292895610699807
Validation loss: 2.4709383392335673

Epoch: 6| Step: 10
Training loss: 2.1047911394029177
Validation loss: 2.4686786386361304

Epoch: 6| Step: 11
Training loss: 2.014700389197769
Validation loss: 2.4660111896555206

Epoch: 6| Step: 12
Training loss: 2.4583994538633993
Validation loss: 2.4724739081475904

Epoch: 6| Step: 13
Training loss: 2.7212848465895805
Validation loss: 2.4595843976857488

Epoch: 129| Step: 0
Training loss: 2.1989403340084737
Validation loss: 2.4459387331092235

Epoch: 6| Step: 1
Training loss: 3.8088984753895967
Validation loss: 2.474538455080301

Epoch: 6| Step: 2
Training loss: 2.7244016287846247
Validation loss: 2.445723013407498

Epoch: 6| Step: 3
Training loss: 2.745407778498352
Validation loss: 2.4472716410899262

Epoch: 6| Step: 4
Training loss: 2.676203205781058
Validation loss: 2.4883279936239973

Epoch: 6| Step: 5
Training loss: 2.1174344414985296
Validation loss: 2.4833763294196354

Epoch: 6| Step: 6
Training loss: 2.2679388398429774
Validation loss: 2.4494528958393085

Epoch: 6| Step: 7
Training loss: 2.337335786814181
Validation loss: 2.459009808138379

Epoch: 6| Step: 8
Training loss: 2.514513516556447
Validation loss: 2.446630243479188

Epoch: 6| Step: 9
Training loss: 2.312893602021074
Validation loss: 2.4369104554319025

Epoch: 6| Step: 10
Training loss: 2.5413003772221194
Validation loss: 2.462495239005018

Epoch: 6| Step: 11
Training loss: 2.5223669846154673
Validation loss: 2.4411069162936005

Epoch: 6| Step: 12
Training loss: 2.765440336624916
Validation loss: 2.449166147683446

Epoch: 6| Step: 13
Training loss: 2.2370469982682386
Validation loss: 2.444192044586152

Epoch: 130| Step: 0
Training loss: 2.0966260145377444
Validation loss: 2.443375204648874

Epoch: 6| Step: 1
Training loss: 2.3399986254044105
Validation loss: 2.4451546881327353

Epoch: 6| Step: 2
Training loss: 2.156397938836354
Validation loss: 2.4599971580905806

Epoch: 6| Step: 3
Training loss: 3.109134223855291
Validation loss: 2.4327278656908207

Epoch: 6| Step: 4
Training loss: 2.9364261693547293
Validation loss: 2.440425007574149

Epoch: 6| Step: 5
Training loss: 2.114038920359134
Validation loss: 2.457162549758064

Epoch: 6| Step: 6
Training loss: 2.0719246974870695
Validation loss: 2.4413884869985525

Epoch: 6| Step: 7
Training loss: 2.342173542085453
Validation loss: 2.4372420309878193

Epoch: 6| Step: 8
Training loss: 2.366400962564248
Validation loss: 2.448121105306823

Epoch: 6| Step: 9
Training loss: 3.0041560948397947
Validation loss: 2.46266778791034

Epoch: 6| Step: 10
Training loss: 3.296461034159428
Validation loss: 2.4474328401849825

Epoch: 6| Step: 11
Training loss: 2.3260823960474624
Validation loss: 2.457172927777032

Epoch: 6| Step: 12
Training loss: 2.9989723988757797
Validation loss: 2.4372388470015043

Epoch: 6| Step: 13
Training loss: 2.7533057890646515
Validation loss: 2.453683729299628

Epoch: 131| Step: 0
Training loss: 3.0101328433305183
Validation loss: 2.4480593110682958

Epoch: 6| Step: 1
Training loss: 2.5832668008748056
Validation loss: 2.430244900197066

Epoch: 6| Step: 2
Training loss: 2.8507257775523183
Validation loss: 2.4541958024462525

Epoch: 6| Step: 3
Training loss: 2.792083130323043
Validation loss: 2.4393090496753915

Epoch: 6| Step: 4
Training loss: 2.26478055804635
Validation loss: 2.4543143538019114

Epoch: 6| Step: 5
Training loss: 2.5132959613837875
Validation loss: 2.4510630944092697

Epoch: 6| Step: 6
Training loss: 2.913719504780627
Validation loss: 2.469649411042968

Epoch: 6| Step: 7
Training loss: 2.8081555190424226
Validation loss: 2.474422968100701

Epoch: 6| Step: 8
Training loss: 2.6430788094486592
Validation loss: 2.4782826650414544

Epoch: 6| Step: 9
Training loss: 2.5671887184739197
Validation loss: 2.46041886111776

Epoch: 6| Step: 10
Training loss: 2.030005675434767
Validation loss: 2.461478434547658

Epoch: 6| Step: 11
Training loss: 1.9593971555391128
Validation loss: 2.4403040018500817

Epoch: 6| Step: 12
Training loss: 2.2521415691156865
Validation loss: 2.4552242675335467

Epoch: 6| Step: 13
Training loss: 2.7940921684851396
Validation loss: 2.44713378741791

Epoch: 132| Step: 0
Training loss: 2.337514287731547
Validation loss: 2.4272096458359123

Epoch: 6| Step: 1
Training loss: 2.202021978769265
Validation loss: 2.4542321039428066

Epoch: 6| Step: 2
Training loss: 2.645924143596984
Validation loss: 2.4585188442318557

Epoch: 6| Step: 3
Training loss: 2.1940381026667173
Validation loss: 2.4558415459232217

Epoch: 6| Step: 4
Training loss: 2.6881972007394617
Validation loss: 2.4532550217946643

Epoch: 6| Step: 5
Training loss: 3.1906982533025476
Validation loss: 2.4440929584152

Epoch: 6| Step: 6
Training loss: 2.810374749740374
Validation loss: 2.4694077786428226

Epoch: 6| Step: 7
Training loss: 2.713382552760394
Validation loss: 2.437801705265722

Epoch: 6| Step: 8
Training loss: 2.8210391643338313
Validation loss: 2.4543077809966496

Epoch: 6| Step: 9
Training loss: 2.198003348378346
Validation loss: 2.448718100853444

Epoch: 6| Step: 10
Training loss: 2.3942618039547106
Validation loss: 2.429998794596552

Epoch: 6| Step: 11
Training loss: 2.944633425839835
Validation loss: 2.434828756208105

Epoch: 6| Step: 12
Training loss: 2.631883225166551
Validation loss: 2.451954950488543

Epoch: 6| Step: 13
Training loss: 2.1178313117495584
Validation loss: 2.4378247861086733

Epoch: 133| Step: 0
Training loss: 2.3324090852835573
Validation loss: 2.474445905755061

Epoch: 6| Step: 1
Training loss: 2.6402961481043796
Validation loss: 2.4572567505573177

Epoch: 6| Step: 2
Training loss: 3.137052867381904
Validation loss: 2.476864860319141

Epoch: 6| Step: 3
Training loss: 2.1501251805258113
Validation loss: 2.4664674453414106

Epoch: 6| Step: 4
Training loss: 2.5663444709019205
Validation loss: 2.4264933533487416

Epoch: 6| Step: 5
Training loss: 2.494852584275641
Validation loss: 2.443063678411706

Epoch: 6| Step: 6
Training loss: 2.465229082895207
Validation loss: 2.4497299585867447

Epoch: 6| Step: 7
Training loss: 2.1247987090870946
Validation loss: 2.4551256511497095

Epoch: 6| Step: 8
Training loss: 2.7507605801352604
Validation loss: 2.4426739505270625

Epoch: 6| Step: 9
Training loss: 3.0049343854751207
Validation loss: 2.449614521763948

Epoch: 6| Step: 10
Training loss: 2.473511365702071
Validation loss: 2.4522903900571222

Epoch: 6| Step: 11
Training loss: 2.5665535848238146
Validation loss: 2.4467561029000704

Epoch: 6| Step: 12
Training loss: 3.115144676902218
Validation loss: 2.4291985121971402

Epoch: 6| Step: 13
Training loss: 1.568228026100064
Validation loss: 2.4377092493027632

Epoch: 134| Step: 0
Training loss: 2.7829282176457752
Validation loss: 2.445853390434722

Epoch: 6| Step: 1
Training loss: 2.009699309712825
Validation loss: 2.4300170865874615

Epoch: 6| Step: 2
Training loss: 2.609491037312816
Validation loss: 2.4594424418763836

Epoch: 6| Step: 3
Training loss: 2.747911787474617
Validation loss: 2.4462415994211133

Epoch: 6| Step: 4
Training loss: 1.8246251701140084
Validation loss: 2.4401769397494357

Epoch: 6| Step: 5
Training loss: 2.1368428251795883
Validation loss: 2.4426781696028224

Epoch: 6| Step: 6
Training loss: 2.5683690292118935
Validation loss: 2.443979368997604

Epoch: 6| Step: 7
Training loss: 3.0408628960724227
Validation loss: 2.4786584236132048

Epoch: 6| Step: 8
Training loss: 2.5372793656064125
Validation loss: 2.446691651547697

Epoch: 6| Step: 9
Training loss: 2.599313491273326
Validation loss: 2.4338886189862285

Epoch: 6| Step: 10
Training loss: 3.0525727037024293
Validation loss: 2.423027721693415

Epoch: 6| Step: 11
Training loss: 2.8715104196483296
Validation loss: 2.4712421885426346

Epoch: 6| Step: 12
Training loss: 2.602160685733108
Validation loss: 2.4559361606528785

Epoch: 6| Step: 13
Training loss: 2.7274725414540817
Validation loss: 2.440228912190288

Epoch: 135| Step: 0
Training loss: 2.245283587753408
Validation loss: 2.454787818971184

Epoch: 6| Step: 1
Training loss: 1.6705834935230826
Validation loss: 2.4481168380160128

Epoch: 6| Step: 2
Training loss: 2.9006344265693187
Validation loss: 2.4457582389029797

Epoch: 6| Step: 3
Training loss: 2.841495500557321
Validation loss: 2.4425805811450836

Epoch: 6| Step: 4
Training loss: 2.6256655802924467
Validation loss: 2.4577640201328355

Epoch: 6| Step: 5
Training loss: 2.464190751767442
Validation loss: 2.4558170090493885

Epoch: 6| Step: 6
Training loss: 2.7135740975011893
Validation loss: 2.483463541432682

Epoch: 6| Step: 7
Training loss: 3.4711685684317826
Validation loss: 2.453610790865471

Epoch: 6| Step: 8
Training loss: 2.50914322672267
Validation loss: 2.4295178563116564

Epoch: 6| Step: 9
Training loss: 2.858016061181119
Validation loss: 2.444016319441419

Epoch: 6| Step: 10
Training loss: 2.50399765823791
Validation loss: 2.450488194270973

Epoch: 6| Step: 11
Training loss: 2.090026505224636
Validation loss: 2.4585191560165316

Epoch: 6| Step: 12
Training loss: 2.1931980579869244
Validation loss: 2.4511371284064527

Epoch: 6| Step: 13
Training loss: 2.5369619278206894
Validation loss: 2.4541491577029726

Epoch: 136| Step: 0
Training loss: 2.358149532349241
Validation loss: 2.457826214461922

Epoch: 6| Step: 1
Training loss: 2.840973389331403
Validation loss: 2.4462754681790195

Epoch: 6| Step: 2
Training loss: 3.048771351219071
Validation loss: 2.4596739270518158

Epoch: 6| Step: 3
Training loss: 2.7976378354231124
Validation loss: 2.4658143031971917

Epoch: 6| Step: 4
Training loss: 2.7824959696477474
Validation loss: 2.469085311288898

Epoch: 6| Step: 5
Training loss: 2.7430435105286017
Validation loss: 2.4452148782853382

Epoch: 6| Step: 6
Training loss: 2.4061017671975824
Validation loss: 2.4501387195437703

Epoch: 6| Step: 7
Training loss: 2.5478578321058833
Validation loss: 2.4428439283834695

Epoch: 6| Step: 8
Training loss: 2.7091241317815924
Validation loss: 2.464813299319097

Epoch: 6| Step: 9
Training loss: 2.8427217741569635
Validation loss: 2.439347938408363

Epoch: 6| Step: 10
Training loss: 2.265542285330082
Validation loss: 2.447433866716642

Epoch: 6| Step: 11
Training loss: 2.271271607921312
Validation loss: 2.4743843151414993

Epoch: 6| Step: 12
Training loss: 2.3101355346948083
Validation loss: 2.4610916404546828

Epoch: 6| Step: 13
Training loss: 1.7402583504854463
Validation loss: 2.4694813000468927

Epoch: 137| Step: 0
Training loss: 2.482727272102516
Validation loss: 2.43592342013842

Epoch: 6| Step: 1
Training loss: 2.5707881220753133
Validation loss: 2.4349315879995075

Epoch: 6| Step: 2
Training loss: 2.5131321277911036
Validation loss: 2.4658593091923944

Epoch: 6| Step: 3
Training loss: 2.74507688793347
Validation loss: 2.4639509791906327

Epoch: 6| Step: 4
Training loss: 2.8166695946522076
Validation loss: 2.4541764972103444

Epoch: 6| Step: 5
Training loss: 2.8290831907951124
Validation loss: 2.448981883076401

Epoch: 6| Step: 6
Training loss: 1.7079321537523933
Validation loss: 2.4581915819927684

Epoch: 6| Step: 7
Training loss: 2.7705811311676696
Validation loss: 2.462986881014275

Epoch: 6| Step: 8
Training loss: 1.9932047920607336
Validation loss: 2.4235527633974416

Epoch: 6| Step: 9
Training loss: 2.6045498578752917
Validation loss: 2.456943707017042

Epoch: 6| Step: 10
Training loss: 2.6693039509029144
Validation loss: 2.449821825896396

Epoch: 6| Step: 11
Training loss: 2.4066225234163423
Validation loss: 2.4506079156670633

Epoch: 6| Step: 12
Training loss: 3.1999636051969342
Validation loss: 2.4451752136979747

Epoch: 6| Step: 13
Training loss: 2.671517063726797
Validation loss: 2.441782697371744

Epoch: 138| Step: 0
Training loss: 1.7535527814062897
Validation loss: 2.4726675240963156

Epoch: 6| Step: 1
Training loss: 2.510563467542804
Validation loss: 2.4381600583485583

Epoch: 6| Step: 2
Training loss: 2.9902120498431786
Validation loss: 2.447926600393973

Epoch: 6| Step: 3
Training loss: 2.4819262450246558
Validation loss: 2.4283613586069825

Epoch: 6| Step: 4
Training loss: 2.7432866081006866
Validation loss: 2.4680197401416883

Epoch: 6| Step: 5
Training loss: 1.865869032651884
Validation loss: 2.4425611316275835

Epoch: 6| Step: 6
Training loss: 2.500100324525084
Validation loss: 2.4448945551487498

Epoch: 6| Step: 7
Training loss: 2.8067609937708564
Validation loss: 2.466478555958298

Epoch: 6| Step: 8
Training loss: 2.6821659293224593
Validation loss: 2.450512801240628

Epoch: 6| Step: 9
Training loss: 2.8196704588084147
Validation loss: 2.459454854346435

Epoch: 6| Step: 10
Training loss: 2.381855756951673
Validation loss: 2.4570840616359417

Epoch: 6| Step: 11
Training loss: 2.8017868301096236
Validation loss: 2.4318643475512265

Epoch: 6| Step: 12
Training loss: 2.2765810492498857
Validation loss: 2.4804993795270964

Epoch: 6| Step: 13
Training loss: 3.163060008287518
Validation loss: 2.448820215396629

Epoch: 139| Step: 0
Training loss: 2.3469082724578425
Validation loss: 2.4431942545367398

Epoch: 6| Step: 1
Training loss: 2.164898321922463
Validation loss: 2.4486836649334136

Epoch: 6| Step: 2
Training loss: 2.443108195834801
Validation loss: 2.4526768537545607

Epoch: 6| Step: 3
Training loss: 2.4950655877736923
Validation loss: 2.443376816251836

Epoch: 6| Step: 4
Training loss: 2.9589701938604076
Validation loss: 2.467597090446554

Epoch: 6| Step: 5
Training loss: 1.948085172440058
Validation loss: 2.4645875238207804

Epoch: 6| Step: 6
Training loss: 3.2034457906724216
Validation loss: 2.447769002097774

Epoch: 6| Step: 7
Training loss: 2.6706483043865314
Validation loss: 2.464082285813524

Epoch: 6| Step: 8
Training loss: 2.6385488982665644
Validation loss: 2.4455232282740997

Epoch: 6| Step: 9
Training loss: 2.3917831906455667
Validation loss: 2.4580293686122516

Epoch: 6| Step: 10
Training loss: 2.9864529869866434
Validation loss: 2.442291776988437

Epoch: 6| Step: 11
Training loss: 2.5427425067068468
Validation loss: 2.434984462025011

Epoch: 6| Step: 12
Training loss: 1.8978171885354143
Validation loss: 2.4462580507378524

Epoch: 6| Step: 13
Training loss: 3.265264025728217
Validation loss: 2.468522642504374

Epoch: 140| Step: 0
Training loss: 2.4884117487487947
Validation loss: 2.471487107173112

Epoch: 6| Step: 1
Training loss: 2.4720618330496706
Validation loss: 2.4657586603083255

Epoch: 6| Step: 2
Training loss: 3.2269074114794094
Validation loss: 2.4679643027918563

Epoch: 6| Step: 3
Training loss: 2.729353124252645
Validation loss: 2.472346571719696

Epoch: 6| Step: 4
Training loss: 2.296247227832697
Validation loss: 2.4582060938617407

Epoch: 6| Step: 5
Training loss: 2.636253756741578
Validation loss: 2.4419088528354442

Epoch: 6| Step: 6
Training loss: 2.870927995321598
Validation loss: 2.453422222703436

Epoch: 6| Step: 7
Training loss: 2.9232202380874024
Validation loss: 2.4627307333380606

Epoch: 6| Step: 8
Training loss: 2.2173953151829213
Validation loss: 2.4544011560065475

Epoch: 6| Step: 9
Training loss: 2.276851646686825
Validation loss: 2.445795584889753

Epoch: 6| Step: 10
Training loss: 2.768066535447717
Validation loss: 2.4485117283064275

Epoch: 6| Step: 11
Training loss: 2.038167472052903
Validation loss: 2.4593039012001476

Epoch: 6| Step: 12
Training loss: 2.4233962664856326
Validation loss: 2.468017048754581

Epoch: 6| Step: 13
Training loss: 2.0759924939411274
Validation loss: 2.4514930511084523

Epoch: 141| Step: 0
Training loss: 2.642622243170385
Validation loss: 2.4634621801671384

Epoch: 6| Step: 1
Training loss: 2.6238851450462786
Validation loss: 2.4296482213447392

Epoch: 6| Step: 2
Training loss: 3.253170521002658
Validation loss: 2.462456736651253

Epoch: 6| Step: 3
Training loss: 2.001335056077155
Validation loss: 2.465355039968137

Epoch: 6| Step: 4
Training loss: 2.5517612695214336
Validation loss: 2.4635233736732456

Epoch: 6| Step: 5
Training loss: 2.3570157817754063
Validation loss: 2.4334388833353793

Epoch: 6| Step: 6
Training loss: 2.3792603077362076
Validation loss: 2.4452015180845006

Epoch: 6| Step: 7
Training loss: 2.3488750118750747
Validation loss: 2.4409844866287624

Epoch: 6| Step: 8
Training loss: 2.740174861813645
Validation loss: 2.4348957168151784

Epoch: 6| Step: 9
Training loss: 2.582114906514018
Validation loss: 2.44761320147456

Epoch: 6| Step: 10
Training loss: 2.2122722142091744
Validation loss: 2.4491660325420224

Epoch: 6| Step: 11
Training loss: 3.0435494296122685
Validation loss: 2.4450028216949686

Epoch: 6| Step: 12
Training loss: 2.0828273031477065
Validation loss: 2.452414849876096

Epoch: 6| Step: 13
Training loss: 3.069866740164492
Validation loss: 2.4479262610783974

Epoch: 142| Step: 0
Training loss: 2.2971656252146837
Validation loss: 2.458233219303013

Epoch: 6| Step: 1
Training loss: 1.9685253438987096
Validation loss: 2.435442346019082

Epoch: 6| Step: 2
Training loss: 2.7266206489199143
Validation loss: 2.4652371609792953

Epoch: 6| Step: 3
Training loss: 2.9021061714042338
Validation loss: 2.448956779705987

Epoch: 6| Step: 4
Training loss: 2.732464542560228
Validation loss: 2.4692037582583723

Epoch: 6| Step: 5
Training loss: 2.4744139777088745
Validation loss: 2.447882745560573

Epoch: 6| Step: 6
Training loss: 2.5320771361197703
Validation loss: 2.4733156277185038

Epoch: 6| Step: 7
Training loss: 2.5852022998682127
Validation loss: 2.4581887327965033

Epoch: 6| Step: 8
Training loss: 2.663013240436065
Validation loss: 2.432210009993088

Epoch: 6| Step: 9
Training loss: 1.8614000464651188
Validation loss: 2.444301263640631

Epoch: 6| Step: 10
Training loss: 3.191545200941594
Validation loss: 2.4468114790781232

Epoch: 6| Step: 11
Training loss: 2.5183804981688387
Validation loss: 2.4492195088702204

Epoch: 6| Step: 12
Training loss: 2.7218826486543564
Validation loss: 2.443051498520001

Epoch: 6| Step: 13
Training loss: 2.5208880415935795
Validation loss: 2.4621071948142865

Epoch: 143| Step: 0
Training loss: 2.3418542951936594
Validation loss: 2.4253596012264467

Epoch: 6| Step: 1
Training loss: 2.232717045638293
Validation loss: 2.442391870939792

Epoch: 6| Step: 2
Training loss: 2.670870229512836
Validation loss: 2.4339555548999208

Epoch: 6| Step: 3
Training loss: 2.9265706075952163
Validation loss: 2.4654095367003723

Epoch: 6| Step: 4
Training loss: 2.3005677724869713
Validation loss: 2.4522591614713942

Epoch: 6| Step: 5
Training loss: 2.9335222299038137
Validation loss: 2.429160642984929

Epoch: 6| Step: 6
Training loss: 2.344522577744499
Validation loss: 2.454247591874736

Epoch: 6| Step: 7
Training loss: 2.3145947634337194
Validation loss: 2.4403603890138323

Epoch: 6| Step: 8
Training loss: 2.7002034357924827
Validation loss: 2.4563729364054043

Epoch: 6| Step: 9
Training loss: 2.9341960750869505
Validation loss: 2.452494577174778

Epoch: 6| Step: 10
Training loss: 2.5649949930004605
Validation loss: 2.4760961316360244

Epoch: 6| Step: 11
Training loss: 2.2776927647840286
Validation loss: 2.438604043297874

Epoch: 6| Step: 12
Training loss: 2.7181644028267824
Validation loss: 2.451546818628365

Epoch: 6| Step: 13
Training loss: 2.4843892990756444
Validation loss: 2.4575204299513027

Epoch: 144| Step: 0
Training loss: 2.225173463381826
Validation loss: 2.4625403608361895

Epoch: 6| Step: 1
Training loss: 2.4181986808840774
Validation loss: 2.447877120564973

Epoch: 6| Step: 2
Training loss: 1.9430958324757353
Validation loss: 2.4640241099064863

Epoch: 6| Step: 3
Training loss: 2.6968829458745107
Validation loss: 2.482522706461017

Epoch: 6| Step: 4
Training loss: 2.885192880777566
Validation loss: 2.4471554896003513

Epoch: 6| Step: 5
Training loss: 2.3964408988708663
Validation loss: 2.457455811290259

Epoch: 6| Step: 6
Training loss: 2.5658623570478096
Validation loss: 2.4728265441345685

Epoch: 6| Step: 7
Training loss: 2.7666238823612104
Validation loss: 2.4628799931506995

Epoch: 6| Step: 8
Training loss: 2.6383039216526614
Validation loss: 2.4519593919794254

Epoch: 6| Step: 9
Training loss: 2.4098609483737494
Validation loss: 2.4660648963705833

Epoch: 6| Step: 10
Training loss: 2.307445466460362
Validation loss: 2.4628633572434984

Epoch: 6| Step: 11
Training loss: 2.838213551073813
Validation loss: 2.462573275660884

Epoch: 6| Step: 12
Training loss: 2.1707053568404486
Validation loss: 2.441950937327936

Epoch: 6| Step: 13
Training loss: 3.674681025565136
Validation loss: 2.4673788817477944

Epoch: 145| Step: 0
Training loss: 2.7248543796652434
Validation loss: 2.44548832541926

Epoch: 6| Step: 1
Training loss: 1.722804748639501
Validation loss: 2.4684920679224716

Epoch: 6| Step: 2
Training loss: 2.8900984000907357
Validation loss: 2.4464704595999396

Epoch: 6| Step: 3
Training loss: 2.4986145949208365
Validation loss: 2.4477394533822907

Epoch: 6| Step: 4
Training loss: 2.4738696166076264
Validation loss: 2.439333078935151

Epoch: 6| Step: 5
Training loss: 2.427179642978061
Validation loss: 2.462305128366599

Epoch: 6| Step: 6
Training loss: 2.9201044440206685
Validation loss: 2.4451162188780273

Epoch: 6| Step: 7
Training loss: 2.0665038577933754
Validation loss: 2.4548963509693587

Epoch: 6| Step: 8
Training loss: 2.6597340790761255
Validation loss: 2.456546489321631

Epoch: 6| Step: 9
Training loss: 2.4208755892175127
Validation loss: 2.4353657443030685

Epoch: 6| Step: 10
Training loss: 2.9577310154930867
Validation loss: 2.450737356538374

Epoch: 6| Step: 11
Training loss: 2.788193511223759
Validation loss: 2.4592748528048602

Epoch: 6| Step: 12
Training loss: 2.5510736037955515
Validation loss: 2.447795698588902

Epoch: 6| Step: 13
Training loss: 1.677466694235437
Validation loss: 2.4457732228576656

Epoch: 146| Step: 0
Training loss: 2.7153864256403284
Validation loss: 2.4211495711950586

Epoch: 6| Step: 1
Training loss: 3.3293078116112316
Validation loss: 2.4408889761992003

Epoch: 6| Step: 2
Training loss: 2.334591072428717
Validation loss: 2.440716791928736

Epoch: 6| Step: 3
Training loss: 1.938023281189841
Validation loss: 2.4642825346049597

Epoch: 6| Step: 4
Training loss: 2.712329606008842
Validation loss: 2.4552645716791304

Epoch: 6| Step: 5
Training loss: 2.7648585922476636
Validation loss: 2.433503906917584

Epoch: 6| Step: 6
Training loss: 2.5163425346297577
Validation loss: 2.442035893059314

Epoch: 6| Step: 7
Training loss: 2.2247881327707977
Validation loss: 2.4345063809745544

Epoch: 6| Step: 8
Training loss: 2.9327027127056096
Validation loss: 2.4481066299979033

Epoch: 6| Step: 9
Training loss: 2.553025010951316
Validation loss: 2.448557473227888

Epoch: 6| Step: 10
Training loss: 2.3147798589257005
Validation loss: 2.4657444736088463

Epoch: 6| Step: 11
Training loss: 2.483456903835214
Validation loss: 2.446052980910041

Epoch: 6| Step: 12
Training loss: 2.353751649536916
Validation loss: 2.4376770567343935

Epoch: 6| Step: 13
Training loss: 2.5236579161004244
Validation loss: 2.439867421831246

Epoch: 147| Step: 0
Training loss: 2.4474446808872754
Validation loss: 2.451793343963709

Epoch: 6| Step: 1
Training loss: 2.4159023347781514
Validation loss: 2.4597069479805374

Epoch: 6| Step: 2
Training loss: 2.3773661421549575
Validation loss: 2.44885664682999

Epoch: 6| Step: 3
Training loss: 2.755007000341366
Validation loss: 2.4507930172434245

Epoch: 6| Step: 4
Training loss: 2.5681150370943278
Validation loss: 2.4446231893063053

Epoch: 6| Step: 5
Training loss: 2.107144002475381
Validation loss: 2.4723243720696124

Epoch: 6| Step: 6
Training loss: 2.5717236201996174
Validation loss: 2.4801116962846455

Epoch: 6| Step: 7
Training loss: 2.1003602854158725
Validation loss: 2.477765435389284

Epoch: 6| Step: 8
Training loss: 2.609118968714864
Validation loss: 2.4554336706391053

Epoch: 6| Step: 9
Training loss: 2.6765221231402476
Validation loss: 2.4558599032695962

Epoch: 6| Step: 10
Training loss: 2.8690276100954892
Validation loss: 2.4435313636175695

Epoch: 6| Step: 11
Training loss: 2.7895724474177204
Validation loss: 2.472109871642281

Epoch: 6| Step: 12
Training loss: 2.2896040448358983
Validation loss: 2.460295134432317

Epoch: 6| Step: 13
Training loss: 3.1152057514848797
Validation loss: 2.4555740249152773

Epoch: 148| Step: 0
Training loss: 2.9774412124685274
Validation loss: 2.469579866370677

Epoch: 6| Step: 1
Training loss: 2.3946085134863546
Validation loss: 2.456834467205127

Epoch: 6| Step: 2
Training loss: 3.101567727187818
Validation loss: 2.453722157220511

Epoch: 6| Step: 3
Training loss: 2.6082467021104088
Validation loss: 2.461950595903859

Epoch: 6| Step: 4
Training loss: 2.4193072088741943
Validation loss: 2.462762149757175

Epoch: 6| Step: 5
Training loss: 2.483619047109881
Validation loss: 2.459111368132872

Epoch: 6| Step: 6
Training loss: 1.7528672571142494
Validation loss: 2.455818139598676

Epoch: 6| Step: 7
Training loss: 1.945228789340009
Validation loss: 2.4627770916735328

Epoch: 6| Step: 8
Training loss: 2.913717049993756
Validation loss: 2.444694278655614

Epoch: 6| Step: 9
Training loss: 1.9236394954320912
Validation loss: 2.4366627147278845

Epoch: 6| Step: 10
Training loss: 2.6189143163437207
Validation loss: 2.444141065283053

Epoch: 6| Step: 11
Training loss: 2.416434890769736
Validation loss: 2.4538943326192872

Epoch: 6| Step: 12
Training loss: 3.2933030869437365
Validation loss: 2.4625293797606527

Epoch: 6| Step: 13
Training loss: 2.106620289658249
Validation loss: 2.4299784372955435

Epoch: 149| Step: 0
Training loss: 2.8429337891695705
Validation loss: 2.4589178274457675

Epoch: 6| Step: 1
Training loss: 2.8281139563244753
Validation loss: 2.453941372925369

Epoch: 6| Step: 2
Training loss: 2.5519693362148685
Validation loss: 2.4503977716569123

Epoch: 6| Step: 3
Training loss: 2.207408231424059
Validation loss: 2.4578249043882168

Epoch: 6| Step: 4
Training loss: 2.6821405065713777
Validation loss: 2.444164685173632

Epoch: 6| Step: 5
Training loss: 2.0668261845871125
Validation loss: 2.4335885955213965

Epoch: 6| Step: 6
Training loss: 2.643914245120855
Validation loss: 2.4515108872983586

Epoch: 6| Step: 7
Training loss: 3.345868589247957
Validation loss: 2.4284560094347487

Epoch: 6| Step: 8
Training loss: 2.897488749813854
Validation loss: 2.43269153204942

Epoch: 6| Step: 9
Training loss: 2.4122876800241486
Validation loss: 2.44472282916722

Epoch: 6| Step: 10
Training loss: 2.427678986068672
Validation loss: 2.4615038439995085

Epoch: 6| Step: 11
Training loss: 2.2458879194072234
Validation loss: 2.4412446309071947

Epoch: 6| Step: 12
Training loss: 2.218845848914502
Validation loss: 2.4389982349227393

Epoch: 6| Step: 13
Training loss: 1.1264701879512642
Validation loss: 2.453554886892559

Epoch: 150| Step: 0
Training loss: 2.2721377717946845
Validation loss: 2.445291670503124

Epoch: 6| Step: 1
Training loss: 2.452361650210187
Validation loss: 2.4527976870141543

Epoch: 6| Step: 2
Training loss: 2.6250136238834516
Validation loss: 2.4416126970845142

Epoch: 6| Step: 3
Training loss: 2.1506238874960797
Validation loss: 2.442039416173692

Epoch: 6| Step: 4
Training loss: 3.04059991463549
Validation loss: 2.4729461585504766

Epoch: 6| Step: 5
Training loss: 2.5928286099355833
Validation loss: 2.4657694128260275

Epoch: 6| Step: 6
Training loss: 3.2298028298775847
Validation loss: 2.4537101911355546

Epoch: 6| Step: 7
Training loss: 2.596292743064701
Validation loss: 2.4357270239131728

Epoch: 6| Step: 8
Training loss: 2.210954753687095
Validation loss: 2.4576374064470783

Epoch: 6| Step: 9
Training loss: 2.0090395966383032
Validation loss: 2.461096853477132

Epoch: 6| Step: 10
Training loss: 2.6371997535801497
Validation loss: 2.4663747854518783

Epoch: 6| Step: 11
Training loss: 2.3746218129262284
Validation loss: 2.4525952879912065

Epoch: 6| Step: 12
Training loss: 2.700449683571193
Validation loss: 2.458888616014146

Epoch: 6| Step: 13
Training loss: 2.210082303236433
Validation loss: 2.4335408299563035

Epoch: 151| Step: 0
Training loss: 2.5448102011664715
Validation loss: 2.4605502697537385

Epoch: 6| Step: 1
Training loss: 2.621366074538374
Validation loss: 2.4554213850558346

Epoch: 6| Step: 2
Training loss: 2.3156990399795494
Validation loss: 2.4580229939968454

Epoch: 6| Step: 3
Training loss: 2.4767919969572345
Validation loss: 2.459827418185789

Epoch: 6| Step: 4
Training loss: 2.826863381570458
Validation loss: 2.454021997622315

Epoch: 6| Step: 5
Training loss: 2.5173085899281933
Validation loss: 2.4563416762283454

Epoch: 6| Step: 6
Training loss: 2.6275506116527754
Validation loss: 2.4290164584954033

Epoch: 6| Step: 7
Training loss: 2.7765011481707433
Validation loss: 2.4675195383838773

Epoch: 6| Step: 8
Training loss: 2.654516754137756
Validation loss: 2.4628345340347817

Epoch: 6| Step: 9
Training loss: 1.772692082573776
Validation loss: 2.469664274958319

Epoch: 6| Step: 10
Training loss: 2.6719501328640485
Validation loss: 2.4553578711493844

Epoch: 6| Step: 11
Training loss: 2.205059095356329
Validation loss: 2.4375750832763976

Epoch: 6| Step: 12
Training loss: 2.443651116363262
Validation loss: 2.457679096956818

Epoch: 6| Step: 13
Training loss: 2.853839122234416
Validation loss: 2.469884749497823

Epoch: 152| Step: 0
Training loss: 2.9088956214639716
Validation loss: 2.4583956642932234

Epoch: 6| Step: 1
Training loss: 2.2103565113200654
Validation loss: 2.4678993493754846

Epoch: 6| Step: 2
Training loss: 2.5251433567860175
Validation loss: 2.471210024072657

Epoch: 6| Step: 3
Training loss: 2.005107318926495
Validation loss: 2.4329926977063057

Epoch: 6| Step: 4
Training loss: 2.286350766188295
Validation loss: 2.47100286365094

Epoch: 6| Step: 5
Training loss: 2.8155184337166297
Validation loss: 2.464596442398362

Epoch: 6| Step: 6
Training loss: 3.0010215291640043
Validation loss: 2.4547097718845214

Epoch: 6| Step: 7
Training loss: 2.553960014143764
Validation loss: 2.4806583449969506

Epoch: 6| Step: 8
Training loss: 2.3507547100035775
Validation loss: 2.4313052941235327

Epoch: 6| Step: 9
Training loss: 2.6903505510990704
Validation loss: 2.447780504980161

Epoch: 6| Step: 10
Training loss: 2.0581063375776636
Validation loss: 2.459834650024937

Epoch: 6| Step: 11
Training loss: 2.8076668643703013
Validation loss: 2.417981285250783

Epoch: 6| Step: 12
Training loss: 2.5209415717308987
Validation loss: 2.4610506931829823

Epoch: 6| Step: 13
Training loss: 2.199060681694551
Validation loss: 2.447908694102217

Epoch: 153| Step: 0
Training loss: 2.723780483374633
Validation loss: 2.4450392858923804

Epoch: 6| Step: 1
Training loss: 2.4000832940588563
Validation loss: 2.4662834630044967

Epoch: 6| Step: 2
Training loss: 2.3495214989671593
Validation loss: 2.471188873928958

Epoch: 6| Step: 3
Training loss: 2.3670802328148413
Validation loss: 2.452762888197583

Epoch: 6| Step: 4
Training loss: 2.3802375263007067
Validation loss: 2.477088451839897

Epoch: 6| Step: 5
Training loss: 2.8298942974825607
Validation loss: 2.470088022929678

Epoch: 6| Step: 6
Training loss: 2.996434636225994
Validation loss: 2.44775808514943

Epoch: 6| Step: 7
Training loss: 2.870327012840964
Validation loss: 2.442200364905954

Epoch: 6| Step: 8
Training loss: 2.2808138286670436
Validation loss: 2.470701201259531

Epoch: 6| Step: 9
Training loss: 2.1716316141660084
Validation loss: 2.4596921411474146

Epoch: 6| Step: 10
Training loss: 2.3066781450364546
Validation loss: 2.4541050097934147

Epoch: 6| Step: 11
Training loss: 2.40936572992147
Validation loss: 2.4576191859899614

Epoch: 6| Step: 12
Training loss: 2.8354508584058675
Validation loss: 2.4510559564489975

Epoch: 6| Step: 13
Training loss: 2.0346784561652265
Validation loss: 2.4661546551433715

Epoch: 154| Step: 0
Training loss: 2.245867218535739
Validation loss: 2.448636082849497

Epoch: 6| Step: 1
Training loss: 2.512041845349732
Validation loss: 2.4423340286027746

Epoch: 6| Step: 2
Training loss: 2.375930804506978
Validation loss: 2.4608757608993033

Epoch: 6| Step: 3
Training loss: 2.6148779856295827
Validation loss: 2.482806466401673

Epoch: 6| Step: 4
Training loss: 2.5683824893505998
Validation loss: 2.452093429628981

Epoch: 6| Step: 5
Training loss: 2.815045539934787
Validation loss: 2.4400602073140454

Epoch: 6| Step: 6
Training loss: 2.033887354099297
Validation loss: 2.4475906895100312

Epoch: 6| Step: 7
Training loss: 2.3835029977371893
Validation loss: 2.46363846367287

Epoch: 6| Step: 8
Training loss: 2.729670723141328
Validation loss: 2.4618142999290034

Epoch: 6| Step: 9
Training loss: 2.70286532350971
Validation loss: 2.452202140468444

Epoch: 6| Step: 10
Training loss: 2.338990936509635
Validation loss: 2.455699486499242

Epoch: 6| Step: 11
Training loss: 2.859759862461753
Validation loss: 2.465426326999821

Epoch: 6| Step: 12
Training loss: 2.641199354199809
Validation loss: 2.451483107083429

Epoch: 6| Step: 13
Training loss: 2.6770436225845216
Validation loss: 2.4547218949743272

Epoch: 155| Step: 0
Training loss: 2.6200301944652598
Validation loss: 2.459033614652018

Epoch: 6| Step: 1
Training loss: 2.6312742182326123
Validation loss: 2.4569485850319674

Epoch: 6| Step: 2
Training loss: 2.8983266146031563
Validation loss: 2.441822328351063

Epoch: 6| Step: 3
Training loss: 3.3626454601945173
Validation loss: 2.458776591158253

Epoch: 6| Step: 4
Training loss: 2.154719708086474
Validation loss: 2.47819866793061

Epoch: 6| Step: 5
Training loss: 2.2676445740156237
Validation loss: 2.4385204687493474

Epoch: 6| Step: 6
Training loss: 2.507848151122906
Validation loss: 2.4485992576100286

Epoch: 6| Step: 7
Training loss: 2.332820075215064
Validation loss: 2.4598037412937335

Epoch: 6| Step: 8
Training loss: 2.0862607098322226
Validation loss: 2.454761520183241

Epoch: 6| Step: 9
Training loss: 2.5104852142050524
Validation loss: 2.4676127048737126

Epoch: 6| Step: 10
Training loss: 2.3431073134134577
Validation loss: 2.4566008078620722

Epoch: 6| Step: 11
Training loss: 1.995517236874584
Validation loss: 2.468684043849547

Epoch: 6| Step: 12
Training loss: 2.865874694129381
Validation loss: 2.438360472010624

Epoch: 6| Step: 13
Training loss: 2.4397817837739715
Validation loss: 2.4628692613275445

Epoch: 156| Step: 0
Training loss: 2.8792673037248258
Validation loss: 2.4726447000632144

Epoch: 6| Step: 1
Training loss: 2.0138352602545067
Validation loss: 2.469830674323555

Epoch: 6| Step: 2
Training loss: 2.618080009753232
Validation loss: 2.4368442466326266

Epoch: 6| Step: 3
Training loss: 3.134702041313876
Validation loss: 2.455277815518713

Epoch: 6| Step: 4
Training loss: 2.463384664961678
Validation loss: 2.463197111470365

Epoch: 6| Step: 5
Training loss: 2.303023329086179
Validation loss: 2.4593799178487394

Epoch: 6| Step: 6
Training loss: 1.7780793732217937
Validation loss: 2.4604387217023556

Epoch: 6| Step: 7
Training loss: 2.7465286887181173
Validation loss: 2.44899366604212

Epoch: 6| Step: 8
Training loss: 2.418621314122306
Validation loss: 2.439911909311987

Epoch: 6| Step: 9
Training loss: 2.5372241128609545
Validation loss: 2.4675906963934913

Epoch: 6| Step: 10
Training loss: 2.0887313591737686
Validation loss: 2.4384935435036335

Epoch: 6| Step: 11
Training loss: 2.4813031092420132
Validation loss: 2.4408585575183603

Epoch: 6| Step: 12
Training loss: 2.9800215519375373
Validation loss: 2.430693353671841

Epoch: 6| Step: 13
Training loss: 3.0451085374151563
Validation loss: 2.4553886938498426

Epoch: 157| Step: 0
Training loss: 2.7218420050774896
Validation loss: 2.4527591714449155

Epoch: 6| Step: 1
Training loss: 2.2504776341721726
Validation loss: 2.4576763170551756

Epoch: 6| Step: 2
Training loss: 2.5678408719431634
Validation loss: 2.441985687077321

Epoch: 6| Step: 3
Training loss: 2.0050376390077793
Validation loss: 2.4607547315163423

Epoch: 6| Step: 4
Training loss: 2.0566111795286455
Validation loss: 2.4415461516955204

Epoch: 6| Step: 5
Training loss: 2.655354786531999
Validation loss: 2.463420307585494

Epoch: 6| Step: 6
Training loss: 2.619026471750334
Validation loss: 2.460896230866929

Epoch: 6| Step: 7
Training loss: 2.325957652748728
Validation loss: 2.4647949342886295

Epoch: 6| Step: 8
Training loss: 2.4426803316139454
Validation loss: 2.4655271391809124

Epoch: 6| Step: 9
Training loss: 2.3278395714621505
Validation loss: 2.4290003685134702

Epoch: 6| Step: 10
Training loss: 3.032102170103489
Validation loss: 2.4587683490051178

Epoch: 6| Step: 11
Training loss: 2.573480850530914
Validation loss: 2.4190165693416112

Epoch: 6| Step: 12
Training loss: 2.524956308119045
Validation loss: 2.46382817384409

Epoch: 6| Step: 13
Training loss: 3.2065619660836098
Validation loss: 2.463795128029524

Epoch: 158| Step: 0
Training loss: 2.629677283935286
Validation loss: 2.4391151947595566

Epoch: 6| Step: 1
Training loss: 2.3412358341307837
Validation loss: 2.4528568704687554

Epoch: 6| Step: 2
Training loss: 2.3102886865070436
Validation loss: 2.4323281331108717

Epoch: 6| Step: 3
Training loss: 2.614478323196775
Validation loss: 2.4703966772929027

Epoch: 6| Step: 4
Training loss: 2.526485149872133
Validation loss: 2.4433641311450884

Epoch: 6| Step: 5
Training loss: 2.2540154124886387
Validation loss: 2.4643198755423343

Epoch: 6| Step: 6
Training loss: 2.5090722458412937
Validation loss: 2.4534897500106263

Epoch: 6| Step: 7
Training loss: 2.8339515647329687
Validation loss: 2.43818652148298

Epoch: 6| Step: 8
Training loss: 2.5311093703399705
Validation loss: 2.462226752635073

Epoch: 6| Step: 9
Training loss: 2.3135278840207656
Validation loss: 2.458217729367384

Epoch: 6| Step: 10
Training loss: 2.357985940245822
Validation loss: 2.4736826487347034

Epoch: 6| Step: 11
Training loss: 2.5426510848294877
Validation loss: 2.4526326668000897

Epoch: 6| Step: 12
Training loss: 2.5120704131796754
Validation loss: 2.4390512719994

Epoch: 6| Step: 13
Training loss: 3.109662066679483
Validation loss: 2.46450578741309

Epoch: 159| Step: 0
Training loss: 2.593722239885802
Validation loss: 2.4514628915896672

Epoch: 6| Step: 1
Training loss: 2.526570551192384
Validation loss: 2.4580186969627347

Epoch: 6| Step: 2
Training loss: 2.6388801362634253
Validation loss: 2.45909327640111

Epoch: 6| Step: 3
Training loss: 2.6661465455491657
Validation loss: 2.4492164111081656

Epoch: 6| Step: 4
Training loss: 2.373839345719994
Validation loss: 2.4592785555405148

Epoch: 6| Step: 5
Training loss: 2.210471383824838
Validation loss: 2.4812276268303695

Epoch: 6| Step: 6
Training loss: 2.0962249020988764
Validation loss: 2.4716268589297865

Epoch: 6| Step: 7
Training loss: 3.0924434793005444
Validation loss: 2.4633822775982464

Epoch: 6| Step: 8
Training loss: 2.7602751113776183
Validation loss: 2.4696250508033186

Epoch: 6| Step: 9
Training loss: 2.7368955493546685
Validation loss: 2.4602112067657775

Epoch: 6| Step: 10
Training loss: 2.5393731029971915
Validation loss: 2.4638553071034037

Epoch: 6| Step: 11
Training loss: 2.5940342942664274
Validation loss: 2.44595518646302

Epoch: 6| Step: 12
Training loss: 2.3241815131273924
Validation loss: 2.4763152912419564

Epoch: 6| Step: 13
Training loss: 1.8036123929369328
Validation loss: 2.4626767134402407

Epoch: 160| Step: 0
Training loss: 2.509294493869564
Validation loss: 2.44905069265955

Epoch: 6| Step: 1
Training loss: 1.8855006864875752
Validation loss: 2.4683893432774426

Epoch: 6| Step: 2
Training loss: 2.0470229233733357
Validation loss: 2.4367357606758326

Epoch: 6| Step: 3
Training loss: 2.7156108403687234
Validation loss: 2.452199327176345

Epoch: 6| Step: 4
Training loss: 2.8649857302005763
Validation loss: 2.4613535466690974

Epoch: 6| Step: 5
Training loss: 2.420058128825279
Validation loss: 2.462629266392945

Epoch: 6| Step: 6
Training loss: 2.53435984652842
Validation loss: 2.466935589300875

Epoch: 6| Step: 7
Training loss: 2.7271979610714125
Validation loss: 2.4593992687579598

Epoch: 6| Step: 8
Training loss: 2.249487924584518
Validation loss: 2.4625556830400765

Epoch: 6| Step: 9
Training loss: 2.3702368908404856
Validation loss: 2.4733960769314134

Epoch: 6| Step: 10
Training loss: 2.6300159849834204
Validation loss: 2.4668853237010144

Epoch: 6| Step: 11
Training loss: 2.8422477023735895
Validation loss: 2.4611825972317667

Epoch: 6| Step: 12
Training loss: 2.860412909571733
Validation loss: 2.4537114041500554

Epoch: 6| Step: 13
Training loss: 2.365640166018612
Validation loss: 2.47032882966167

Epoch: 161| Step: 0
Training loss: 2.5054344239127184
Validation loss: 2.4523509554651

Epoch: 6| Step: 1
Training loss: 1.9331226738349345
Validation loss: 2.4628765654260394

Epoch: 6| Step: 2
Training loss: 2.4804650974997715
Validation loss: 2.4555002254416047

Epoch: 6| Step: 3
Training loss: 2.009708563140075
Validation loss: 2.46744375587576

Epoch: 6| Step: 4
Training loss: 2.3608703926895016
Validation loss: 2.4874544443431947

Epoch: 6| Step: 5
Training loss: 2.4126420764890937
Validation loss: 2.446772903853956

Epoch: 6| Step: 6
Training loss: 3.072785058947933
Validation loss: 2.450217026278527

Epoch: 6| Step: 7
Training loss: 3.022708144424001
Validation loss: 2.478781253358134

Epoch: 6| Step: 8
Training loss: 2.1205422262220854
Validation loss: 2.4619303945105164

Epoch: 6| Step: 9
Training loss: 2.4796214180826395
Validation loss: 2.4618435422504614

Epoch: 6| Step: 10
Training loss: 3.0884529774343727
Validation loss: 2.4668539234190288

Epoch: 6| Step: 11
Training loss: 2.466418553666948
Validation loss: 2.4985543470419977

Epoch: 6| Step: 12
Training loss: 2.059708989893202
Validation loss: 2.4327586716158285

Epoch: 6| Step: 13
Training loss: 2.615683690076922
Validation loss: 2.4785102391589113

Epoch: 162| Step: 0
Training loss: 2.3440818043127374
Validation loss: 2.500744462686674

Epoch: 6| Step: 1
Training loss: 1.992465848737747
Validation loss: 2.4861377321948623

Epoch: 6| Step: 2
Training loss: 2.62298143068024
Validation loss: 2.4691394110931077

Epoch: 6| Step: 3
Training loss: 2.9909346624473923
Validation loss: 2.442038639325309

Epoch: 6| Step: 4
Training loss: 2.718432528496395
Validation loss: 2.4450536724136427

Epoch: 6| Step: 5
Training loss: 2.633562292535214
Validation loss: 2.4525100285176817

Epoch: 6| Step: 6
Training loss: 2.605019595023059
Validation loss: 2.469414204845503

Epoch: 6| Step: 7
Training loss: 3.100019787140731
Validation loss: 2.471925104150781

Epoch: 6| Step: 8
Training loss: 2.551527115809507
Validation loss: 2.451828397029873

Epoch: 6| Step: 9
Training loss: 2.2805554103296286
Validation loss: 2.460815626682527

Epoch: 6| Step: 10
Training loss: 2.1978168796347592
Validation loss: 2.465610114395689

Epoch: 6| Step: 11
Training loss: 2.431862008308369
Validation loss: 2.450399659026375

Epoch: 6| Step: 12
Training loss: 1.995168333289605
Validation loss: 2.475724762019184

Epoch: 6| Step: 13
Training loss: 2.1895589675297713
Validation loss: 2.4582306360895325

Epoch: 163| Step: 0
Training loss: 3.368230175896871
Validation loss: 2.467144080477884

Epoch: 6| Step: 1
Training loss: 1.757766926492558
Validation loss: 2.442695126645503

Epoch: 6| Step: 2
Training loss: 2.2812173919437493
Validation loss: 2.4762870532139014

Epoch: 6| Step: 3
Training loss: 2.0200264358679134
Validation loss: 2.4541220153254293

Epoch: 6| Step: 4
Training loss: 2.040007156845703
Validation loss: 2.4737250761592513

Epoch: 6| Step: 5
Training loss: 2.188374045003721
Validation loss: 2.467682150190887

Epoch: 6| Step: 6
Training loss: 2.485657558827414
Validation loss: 2.478555371462688

Epoch: 6| Step: 7
Training loss: 2.7150726002352754
Validation loss: 2.469677563029828

Epoch: 6| Step: 8
Training loss: 2.439345126055854
Validation loss: 2.447253946850435

Epoch: 6| Step: 9
Training loss: 2.334619973438855
Validation loss: 2.430426744797068

Epoch: 6| Step: 10
Training loss: 2.6914142226501108
Validation loss: 2.4396851859605455

Epoch: 6| Step: 11
Training loss: 2.862839231421461
Validation loss: 2.457275326332509

Epoch: 6| Step: 12
Training loss: 2.543890485703576
Validation loss: 2.4646332824181854

Epoch: 6| Step: 13
Training loss: 3.231811687120068
Validation loss: 2.457970375671174

Epoch: 164| Step: 0
Training loss: 1.986473415766247
Validation loss: 2.4622822540908933

Epoch: 6| Step: 1
Training loss: 2.833069415048957
Validation loss: 2.472537537094306

Epoch: 6| Step: 2
Training loss: 2.310389818930451
Validation loss: 2.4614093870446108

Epoch: 6| Step: 3
Training loss: 2.7822645244371804
Validation loss: 2.4795262637870294

Epoch: 6| Step: 4
Training loss: 2.1808196378323284
Validation loss: 2.4527413861410343

Epoch: 6| Step: 5
Training loss: 2.190006019549175
Validation loss: 2.437670165107471

Epoch: 6| Step: 6
Training loss: 2.2959538902942764
Validation loss: 2.4587199694593886

Epoch: 6| Step: 7
Training loss: 2.284040964651104
Validation loss: 2.4753759006510623

Epoch: 6| Step: 8
Training loss: 2.5376813213039324
Validation loss: 2.468476452307165

Epoch: 6| Step: 9
Training loss: 2.622773815948303
Validation loss: 2.467404758250063

Epoch: 6| Step: 10
Training loss: 2.9090664250253826
Validation loss: 2.448310451387937

Epoch: 6| Step: 11
Training loss: 2.6549776508087493
Validation loss: 2.4418215120627917

Epoch: 6| Step: 12
Training loss: 2.9844101509300978
Validation loss: 2.4708634179546385

Epoch: 6| Step: 13
Training loss: 2.8592570963247255
Validation loss: 2.4531309353597455

Epoch: 165| Step: 0
Training loss: 2.015983490520573
Validation loss: 2.451355042130425

Epoch: 6| Step: 1
Training loss: 2.273158734721301
Validation loss: 2.4674776598487598

Epoch: 6| Step: 2
Training loss: 2.278703496294206
Validation loss: 2.4525687315483533

Epoch: 6| Step: 3
Training loss: 2.3465390712916214
Validation loss: 2.46603530074911

Epoch: 6| Step: 4
Training loss: 2.950578510004635
Validation loss: 2.48732792533333

Epoch: 6| Step: 5
Training loss: 2.5549186578631264
Validation loss: 2.4412244723994405

Epoch: 6| Step: 6
Training loss: 1.809214277491719
Validation loss: 2.455441672888104

Epoch: 6| Step: 7
Training loss: 3.2995481817569132
Validation loss: 2.4798386937369936

Epoch: 6| Step: 8
Training loss: 2.6081984374372844
Validation loss: 2.465767198281157

Epoch: 6| Step: 9
Training loss: 2.329853005418039
Validation loss: 2.4642892477761387

Epoch: 6| Step: 10
Training loss: 2.4189569429095656
Validation loss: 2.480715663700986

Epoch: 6| Step: 11
Training loss: 2.9749108886195317
Validation loss: 2.454974158209331

Epoch: 6| Step: 12
Training loss: 2.5188613829110964
Validation loss: 2.4770123100532766

Epoch: 6| Step: 13
Training loss: 2.228022581852379
Validation loss: 2.4744399329406757

Epoch: 166| Step: 0
Training loss: 1.8789186853960889
Validation loss: 2.46713940550562

Epoch: 6| Step: 1
Training loss: 2.687901489076195
Validation loss: 2.4798223886954065

Epoch: 6| Step: 2
Training loss: 2.6373711577127623
Validation loss: 2.4808896191609446

Epoch: 6| Step: 3
Training loss: 2.588290155627459
Validation loss: 2.4574967016230653

Epoch: 6| Step: 4
Training loss: 2.3005858048486676
Validation loss: 2.46768551825726

Epoch: 6| Step: 5
Training loss: 2.638731508971769
Validation loss: 2.466794839090952

Epoch: 6| Step: 6
Training loss: 2.7231705780452584
Validation loss: 2.459872568109532

Epoch: 6| Step: 7
Training loss: 2.592920009687098
Validation loss: 2.4357163545393945

Epoch: 6| Step: 8
Training loss: 2.1315445816635843
Validation loss: 2.4703842243271716

Epoch: 6| Step: 9
Training loss: 2.297570155819109
Validation loss: 2.4630991858719384

Epoch: 6| Step: 10
Training loss: 2.5057172251794566
Validation loss: 2.4601268833731877

Epoch: 6| Step: 11
Training loss: 2.5022553760883572
Validation loss: 2.4773265668870503

Epoch: 6| Step: 12
Training loss: 3.2542503147551485
Validation loss: 2.4655291501419305

Epoch: 6| Step: 13
Training loss: 1.7684773723652767
Validation loss: 2.479812801214738

Epoch: 167| Step: 0
Training loss: 2.8530659096021056
Validation loss: 2.4633074074997636

Epoch: 6| Step: 1
Training loss: 2.639408350450852
Validation loss: 2.484175690777043

Epoch: 6| Step: 2
Training loss: 2.5640441149994535
Validation loss: 2.475255705065598

Epoch: 6| Step: 3
Training loss: 2.4096561450919394
Validation loss: 2.462249116728427

Epoch: 6| Step: 4
Training loss: 1.8225759423946917
Validation loss: 2.4979549739564986

Epoch: 6| Step: 5
Training loss: 1.9287004301533408
Validation loss: 2.4838459929622467

Epoch: 6| Step: 6
Training loss: 2.252189736289074
Validation loss: 2.4797030242968057

Epoch: 6| Step: 7
Training loss: 2.5908414780161646
Validation loss: 2.470755481501644

Epoch: 6| Step: 8
Training loss: 2.303127472046725
Validation loss: 2.4565022665681733

Epoch: 6| Step: 9
Training loss: 2.6309369478634057
Validation loss: 2.45891368992791

Epoch: 6| Step: 10
Training loss: 2.9323880782237186
Validation loss: 2.48032178791435

Epoch: 6| Step: 11
Training loss: 2.607340310639062
Validation loss: 2.46195104991265

Epoch: 6| Step: 12
Training loss: 2.37046873599945
Validation loss: 2.483531510751778

Epoch: 6| Step: 13
Training loss: 2.7969870092030957
Validation loss: 2.4740554419188525

Epoch: 168| Step: 0
Training loss: 2.6353960802885017
Validation loss: 2.4530701582477703

Epoch: 6| Step: 1
Training loss: 2.184000540359486
Validation loss: 2.4785951410771814

Epoch: 6| Step: 2
Training loss: 2.7717878566663936
Validation loss: 2.461795792768397

Epoch: 6| Step: 3
Training loss: 2.242252362206974
Validation loss: 2.4571498617434817

Epoch: 6| Step: 4
Training loss: 2.1519978932508628
Validation loss: 2.4467657172299275

Epoch: 6| Step: 5
Training loss: 2.788555708289225
Validation loss: 2.465620307133404

Epoch: 6| Step: 6
Training loss: 2.739453118037484
Validation loss: 2.485316452048167

Epoch: 6| Step: 7
Training loss: 2.6849719732658106
Validation loss: 2.4561850833880707

Epoch: 6| Step: 8
Training loss: 2.235137595905862
Validation loss: 2.460980730512069

Epoch: 6| Step: 9
Training loss: 1.8449489768398295
Validation loss: 2.4686825526141365

Epoch: 6| Step: 10
Training loss: 2.715975343078244
Validation loss: 2.4652226998589604

Epoch: 6| Step: 11
Training loss: 2.1451068376730653
Validation loss: 2.4580085425823737

Epoch: 6| Step: 12
Training loss: 2.4893162369933615
Validation loss: 2.481029578032533

Epoch: 6| Step: 13
Training loss: 3.1035910633826256
Validation loss: 2.4497808901307057

Epoch: 169| Step: 0
Training loss: 2.90485208998201
Validation loss: 2.448383949798246

Epoch: 6| Step: 1
Training loss: 2.6707159729721495
Validation loss: 2.4802663030442376

Epoch: 6| Step: 2
Training loss: 2.042198254674424
Validation loss: 2.460854209926722

Epoch: 6| Step: 3
Training loss: 2.9402620032725286
Validation loss: 2.4778165862995842

Epoch: 6| Step: 4
Training loss: 2.577011885355437
Validation loss: 2.452985759728772

Epoch: 6| Step: 5
Training loss: 2.7521423318118527
Validation loss: 2.458187591865594

Epoch: 6| Step: 6
Training loss: 1.7335484227584939
Validation loss: 2.461224239147493

Epoch: 6| Step: 7
Training loss: 2.890285327646307
Validation loss: 2.4477983148084212

Epoch: 6| Step: 8
Training loss: 1.8605674958753213
Validation loss: 2.4415510079732274

Epoch: 6| Step: 9
Training loss: 2.0825521021595663
Validation loss: 2.4476705388575413

Epoch: 6| Step: 10
Training loss: 2.741124308392463
Validation loss: 2.4466190851640093

Epoch: 6| Step: 11
Training loss: 2.196489229151114
Validation loss: 2.47657317662638

Epoch: 6| Step: 12
Training loss: 1.9185878275079231
Validation loss: 2.480686735303441

Epoch: 6| Step: 13
Training loss: 3.219343112261085
Validation loss: 2.46172383564334

Epoch: 170| Step: 0
Training loss: 2.5226988287032155
Validation loss: 2.469654439393365

Epoch: 6| Step: 1
Training loss: 2.2925813987865853
Validation loss: 2.4396916673354894

Epoch: 6| Step: 2
Training loss: 2.5217460892451182
Validation loss: 2.4630813243108953

Epoch: 6| Step: 3
Training loss: 2.928042506925622
Validation loss: 2.476266929954257

Epoch: 6| Step: 4
Training loss: 2.657473921697207
Validation loss: 2.4729232583010505

Epoch: 6| Step: 5
Training loss: 2.289656422090328
Validation loss: 2.464767991312944

Epoch: 6| Step: 6
Training loss: 2.2394132564342075
Validation loss: 2.43324680278466

Epoch: 6| Step: 7
Training loss: 2.7675598617737207
Validation loss: 2.4505738839592333

Epoch: 6| Step: 8
Training loss: 2.262737670554647
Validation loss: 2.4479396880949573

Epoch: 6| Step: 9
Training loss: 2.7497702415894243
Validation loss: 2.4459838218264958

Epoch: 6| Step: 10
Training loss: 2.083816535862276
Validation loss: 2.441371711995283

Epoch: 6| Step: 11
Training loss: 2.4598434680666443
Validation loss: 2.480163499625797

Epoch: 6| Step: 12
Training loss: 2.689234329221948
Validation loss: 2.4371349743982162

Epoch: 6| Step: 13
Training loss: 2.111900682476632
Validation loss: 2.44160664920134

Epoch: 171| Step: 0
Training loss: 2.3580869480827076
Validation loss: 2.4559820188517665

Epoch: 6| Step: 1
Training loss: 2.958162240108908
Validation loss: 2.4571361908326366

Epoch: 6| Step: 2
Training loss: 2.0685795278699244
Validation loss: 2.4936040770990724

Epoch: 6| Step: 3
Training loss: 2.5156581710618737
Validation loss: 2.4878491240409177

Epoch: 6| Step: 4
Training loss: 2.9137785826941767
Validation loss: 2.4590518324478525

Epoch: 6| Step: 5
Training loss: 2.2883735114578423
Validation loss: 2.454546418689939

Epoch: 6| Step: 6
Training loss: 2.4864223848921023
Validation loss: 2.4867341525462177

Epoch: 6| Step: 7
Training loss: 1.7484858638289076
Validation loss: 2.492329368188439

Epoch: 6| Step: 8
Training loss: 2.808009992902315
Validation loss: 2.495730427419748

Epoch: 6| Step: 9
Training loss: 2.3101504994366944
Validation loss: 2.484791891026959

Epoch: 6| Step: 10
Training loss: 2.3067306513906614
Validation loss: 2.4711280243060982

Epoch: 6| Step: 11
Training loss: 2.536730637447605
Validation loss: 2.487794432557679

Epoch: 6| Step: 12
Training loss: 2.7467818937698962
Validation loss: 2.4629658543795268

Epoch: 6| Step: 13
Training loss: 2.859009099176637
Validation loss: 2.461829524598954

Epoch: 172| Step: 0
Training loss: 2.459696138735366
Validation loss: 2.439587024860965

Epoch: 6| Step: 1
Training loss: 2.228914323826235
Validation loss: 2.463242406740381

Epoch: 6| Step: 2
Training loss: 2.5071579503811043
Validation loss: 2.4731782145435948

Epoch: 6| Step: 3
Training loss: 2.4189604911589786
Validation loss: 2.4609856526107015

Epoch: 6| Step: 4
Training loss: 2.60059840578592
Validation loss: 2.4755791793659476

Epoch: 6| Step: 5
Training loss: 2.8271601595989715
Validation loss: 2.4560085383872687

Epoch: 6| Step: 6
Training loss: 2.904883278686593
Validation loss: 2.4796076601515584

Epoch: 6| Step: 7
Training loss: 2.2453079043071225
Validation loss: 2.473694003134734

Epoch: 6| Step: 8
Training loss: 2.3534707472705194
Validation loss: 2.464528145908716

Epoch: 6| Step: 9
Training loss: 2.1198807931170016
Validation loss: 2.4493864996088925

Epoch: 6| Step: 10
Training loss: 2.6352335950469112
Validation loss: 2.44874006538227

Epoch: 6| Step: 11
Training loss: 2.909385384480662
Validation loss: 2.479476259637417

Epoch: 6| Step: 12
Training loss: 2.128173253972942
Validation loss: 2.4418791938375186

Epoch: 6| Step: 13
Training loss: 2.194528242783406
Validation loss: 2.4712912576150123

Epoch: 173| Step: 0
Training loss: 2.409940391531472
Validation loss: 2.4516931298324702

Epoch: 6| Step: 1
Training loss: 2.1967183563255945
Validation loss: 2.4382627585820256

Epoch: 6| Step: 2
Training loss: 1.9565463198163529
Validation loss: 2.4719680387998926

Epoch: 6| Step: 3
Training loss: 3.397854599345872
Validation loss: 2.472917095205403

Epoch: 6| Step: 4
Training loss: 2.2320354457624854
Validation loss: 2.4790799532587138

Epoch: 6| Step: 5
Training loss: 1.9563134375088231
Validation loss: 2.4793311878219955

Epoch: 6| Step: 6
Training loss: 2.77533349791114
Validation loss: 2.4828973793669586

Epoch: 6| Step: 7
Training loss: 2.276356085411044
Validation loss: 2.4870883774429773

Epoch: 6| Step: 8
Training loss: 2.3495914144614356
Validation loss: 2.4474225161854917

Epoch: 6| Step: 9
Training loss: 2.6560369069511114
Validation loss: 2.464826715471375

Epoch: 6| Step: 10
Training loss: 2.4522197049144383
Validation loss: 2.453814704605289

Epoch: 6| Step: 11
Training loss: 2.2937306790486613
Validation loss: 2.4766985909330006

Epoch: 6| Step: 12
Training loss: 3.0545735447694287
Validation loss: 2.452373325989774

Epoch: 6| Step: 13
Training loss: 1.9270302086458244
Validation loss: 2.437393125657937

Epoch: 174| Step: 0
Training loss: 2.4043974247227067
Validation loss: 2.4688228587599834

Epoch: 6| Step: 1
Training loss: 2.38231135867417
Validation loss: 2.477563471682395

Epoch: 6| Step: 2
Training loss: 3.0734910503584194
Validation loss: 2.4966231191810895

Epoch: 6| Step: 3
Training loss: 2.3715040678294628
Validation loss: 2.457403050416025

Epoch: 6| Step: 4
Training loss: 2.2688011268760886
Validation loss: 2.4614808570857147

Epoch: 6| Step: 5
Training loss: 2.512311281167249
Validation loss: 2.45659869149647

Epoch: 6| Step: 6
Training loss: 2.374770906341279
Validation loss: 2.482635607350216

Epoch: 6| Step: 7
Training loss: 2.733885454224234
Validation loss: 2.4814042971393766

Epoch: 6| Step: 8
Training loss: 1.9014797872892908
Validation loss: 2.469767523708315

Epoch: 6| Step: 9
Training loss: 2.7947120187855377
Validation loss: 2.456317456936449

Epoch: 6| Step: 10
Training loss: 2.825113959250399
Validation loss: 2.4760224494400758

Epoch: 6| Step: 11
Training loss: 2.4000014384583297
Validation loss: 2.4993994011900855

Epoch: 6| Step: 12
Training loss: 1.9879390519506954
Validation loss: 2.4666324670754953

Epoch: 6| Step: 13
Training loss: 2.382275330076483
Validation loss: 2.441917076829996

Epoch: 175| Step: 0
Training loss: 2.045233148094837
Validation loss: 2.472431610638752

Epoch: 6| Step: 1
Training loss: 2.2092032488548843
Validation loss: 2.4725101642085967

Epoch: 6| Step: 2
Training loss: 2.2103354776796125
Validation loss: 2.4457882612262183

Epoch: 6| Step: 3
Training loss: 2.1777405058770203
Validation loss: 2.4454943034248404

Epoch: 6| Step: 4
Training loss: 2.1958617476978013
Validation loss: 2.462834117662376

Epoch: 6| Step: 5
Training loss: 2.9264534558756847
Validation loss: 2.4503786844530078

Epoch: 6| Step: 6
Training loss: 2.3926640210984256
Validation loss: 2.469612881493161

Epoch: 6| Step: 7
Training loss: 2.2936908683119097
Validation loss: 2.4745997383147658

Epoch: 6| Step: 8
Training loss: 2.949328368720256
Validation loss: 2.4566704152376495

Epoch: 6| Step: 9
Training loss: 2.258291860201974
Validation loss: 2.4810769330694478

Epoch: 6| Step: 10
Training loss: 2.4553812912583304
Validation loss: 2.4540966798706774

Epoch: 6| Step: 11
Training loss: 2.3344956863438635
Validation loss: 2.4925830974688967

Epoch: 6| Step: 12
Training loss: 3.2009961008407455
Validation loss: 2.466357009979655

Epoch: 6| Step: 13
Training loss: 2.427561231286809
Validation loss: 2.4793644019054186

Epoch: 176| Step: 0
Training loss: 2.903569780160573
Validation loss: 2.478680512751654

Epoch: 6| Step: 1
Training loss: 2.4116408167123495
Validation loss: 2.4440507172787354

Epoch: 6| Step: 2
Training loss: 2.159989583378859
Validation loss: 2.474295336702956

Epoch: 6| Step: 3
Training loss: 1.8943107555323098
Validation loss: 2.4646926037097616

Epoch: 6| Step: 4
Training loss: 2.4340189015916995
Validation loss: 2.4567006704867027

Epoch: 6| Step: 5
Training loss: 2.5147601234299772
Validation loss: 2.4575269623471794

Epoch: 6| Step: 6
Training loss: 2.1389398554995265
Validation loss: 2.4500149299278853

Epoch: 6| Step: 7
Training loss: 2.954004873159388
Validation loss: 2.4731532650363848

Epoch: 6| Step: 8
Training loss: 2.7555960158313884
Validation loss: 2.475111269901947

Epoch: 6| Step: 9
Training loss: 2.2902742374912792
Validation loss: 2.4720392823921022

Epoch: 6| Step: 10
Training loss: 2.856860947325066
Validation loss: 2.459395983679786

Epoch: 6| Step: 11
Training loss: 2.1787525208940655
Validation loss: 2.4255830163514682

Epoch: 6| Step: 12
Training loss: 2.1965394850494047
Validation loss: 2.4490159819193824

Epoch: 6| Step: 13
Training loss: 2.2167645019318463
Validation loss: 2.4439459918588966

Epoch: 177| Step: 0
Training loss: 2.499149940929134
Validation loss: 2.461430505089749

Epoch: 6| Step: 1
Training loss: 2.1918983926821913
Validation loss: 2.4751304356757173

Epoch: 6| Step: 2
Training loss: 2.436031388191739
Validation loss: 2.4535767882699493

Epoch: 6| Step: 3
Training loss: 2.355580999378924
Validation loss: 2.464614615434581

Epoch: 6| Step: 4
Training loss: 2.261607429255241
Validation loss: 2.463909078499126

Epoch: 6| Step: 5
Training loss: 2.2982175886494804
Validation loss: 2.4894693174927625

Epoch: 6| Step: 6
Training loss: 3.163912696588789
Validation loss: 2.453575329647008

Epoch: 6| Step: 7
Training loss: 2.844539658456228
Validation loss: 2.4542561082631824

Epoch: 6| Step: 8
Training loss: 2.821653686496586
Validation loss: 2.4728487299460338

Epoch: 6| Step: 9
Training loss: 2.216084881014177
Validation loss: 2.4612637482141255

Epoch: 6| Step: 10
Training loss: 2.5262684723538746
Validation loss: 2.470337899521862

Epoch: 6| Step: 11
Training loss: 1.7476113229637542
Validation loss: 2.4656222400368843

Epoch: 6| Step: 12
Training loss: 2.211306376064715
Validation loss: 2.452960355056519

Epoch: 6| Step: 13
Training loss: 2.6081918558217496
Validation loss: 2.44876388274927

Epoch: 178| Step: 0
Training loss: 2.6451778551096243
Validation loss: 2.453712598357544

Epoch: 6| Step: 1
Training loss: 2.207288122841866
Validation loss: 2.5002827822817073

Epoch: 6| Step: 2
Training loss: 2.355858816362788
Validation loss: 2.470565434732808

Epoch: 6| Step: 3
Training loss: 2.5790446172954216
Validation loss: 2.4484232901689147

Epoch: 6| Step: 4
Training loss: 2.915062617681212
Validation loss: 2.4553799506455767

Epoch: 6| Step: 5
Training loss: 1.7129325209118746
Validation loss: 2.451306050881268

Epoch: 6| Step: 6
Training loss: 2.4649764567831305
Validation loss: 2.459344820222914

Epoch: 6| Step: 7
Training loss: 2.0615031983625762
Validation loss: 2.4756287051044157

Epoch: 6| Step: 8
Training loss: 2.432401852014555
Validation loss: 2.458031402394775

Epoch: 6| Step: 9
Training loss: 2.108092193483963
Validation loss: 2.461815929660485

Epoch: 6| Step: 10
Training loss: 2.7664628133778946
Validation loss: 2.4580402394210377

Epoch: 6| Step: 11
Training loss: 2.6681094935367127
Validation loss: 2.473323739509206

Epoch: 6| Step: 12
Training loss: 2.570403680082715
Validation loss: 2.463097825521021

Epoch: 6| Step: 13
Training loss: 2.5109408347126076
Validation loss: 2.4512058984055263

Epoch: 179| Step: 0
Training loss: 2.6613325971450754
Validation loss: 2.443071391157425

Epoch: 6| Step: 1
Training loss: 2.224357074902202
Validation loss: 2.4623554780946475

Epoch: 6| Step: 2
Training loss: 2.0161465701909362
Validation loss: 2.4760587726087566

Epoch: 6| Step: 3
Training loss: 2.3663982422706726
Validation loss: 2.4929233282152015

Epoch: 6| Step: 4
Training loss: 2.4019642103643206
Validation loss: 2.4528704426851697

Epoch: 6| Step: 5
Training loss: 2.2041467772693975
Validation loss: 2.4476933464934127

Epoch: 6| Step: 6
Training loss: 2.330520012419931
Validation loss: 2.4568397743034947

Epoch: 6| Step: 7
Training loss: 2.5385392339415875
Validation loss: 2.4570370898441554

Epoch: 6| Step: 8
Training loss: 3.257859776288791
Validation loss: 2.470064561152982

Epoch: 6| Step: 9
Training loss: 2.7247687180388316
Validation loss: 2.483603709825347

Epoch: 6| Step: 10
Training loss: 1.8602541600157643
Validation loss: 2.461281861488917

Epoch: 6| Step: 11
Training loss: 3.0062727516883667
Validation loss: 2.4753520690307327

Epoch: 6| Step: 12
Training loss: 1.9002053149871
Validation loss: 2.4925131178586084

Epoch: 6| Step: 13
Training loss: 2.545131624936269
Validation loss: 2.4667874780030226

Epoch: 180| Step: 0
Training loss: 3.0701264380844635
Validation loss: 2.4717064856423177

Epoch: 6| Step: 1
Training loss: 2.285025829277715
Validation loss: 2.471743935344264

Epoch: 6| Step: 2
Training loss: 1.956679748521752
Validation loss: 2.466142810715251

Epoch: 6| Step: 3
Training loss: 2.528497777363436
Validation loss: 2.462612864063564

Epoch: 6| Step: 4
Training loss: 2.1310936565610317
Validation loss: 2.452140458481739

Epoch: 6| Step: 5
Training loss: 2.6828658492438757
Validation loss: 2.473903611791789

Epoch: 6| Step: 6
Training loss: 2.7069474024262004
Validation loss: 2.4839557973284774

Epoch: 6| Step: 7
Training loss: 1.9071529938727947
Validation loss: 2.4930255751286245

Epoch: 6| Step: 8
Training loss: 3.0906377994592455
Validation loss: 2.491169876076225

Epoch: 6| Step: 9
Training loss: 2.4767918044351425
Validation loss: 2.473369815343865

Epoch: 6| Step: 10
Training loss: 1.9327564623024862
Validation loss: 2.459708822995668

Epoch: 6| Step: 11
Training loss: 2.556409343052878
Validation loss: 2.471207599660711

Epoch: 6| Step: 12
Training loss: 2.155155733504365
Validation loss: 2.4573364496050685

Epoch: 6| Step: 13
Training loss: 2.389629281313697
Validation loss: 2.4694414739754196

Epoch: 181| Step: 0
Training loss: 1.9129923417396222
Validation loss: 2.4754890063219404

Epoch: 6| Step: 1
Training loss: 2.497289523400137
Validation loss: 2.4515822569030497

Epoch: 6| Step: 2
Training loss: 2.6754799777646774
Validation loss: 2.480785900663394

Epoch: 6| Step: 3
Training loss: 2.6564743844794565
Validation loss: 2.4722060901680396

Epoch: 6| Step: 4
Training loss: 3.4451937492821463
Validation loss: 2.4863759157965086

Epoch: 6| Step: 5
Training loss: 2.206513200573017
Validation loss: 2.4614479068227

Epoch: 6| Step: 6
Training loss: 2.885024465262146
Validation loss: 2.4939528526355925

Epoch: 6| Step: 7
Training loss: 2.6547293405451926
Validation loss: 2.4809659049323365

Epoch: 6| Step: 8
Training loss: 1.8147005994405085
Validation loss: 2.4813706464741387

Epoch: 6| Step: 9
Training loss: 2.192378897546616
Validation loss: 2.4722557042175786

Epoch: 6| Step: 10
Training loss: 2.1094671158633727
Validation loss: 2.467098873467654

Epoch: 6| Step: 11
Training loss: 2.020282893247874
Validation loss: 2.4554007681700143

Epoch: 6| Step: 12
Training loss: 2.1930199867517124
Validation loss: 2.4694138108647374

Epoch: 6| Step: 13
Training loss: 2.4798888962992436
Validation loss: 2.4638493242230335

Epoch: 182| Step: 0
Training loss: 2.2326579932751236
Validation loss: 2.4818788509304057

Epoch: 6| Step: 1
Training loss: 2.379357406354769
Validation loss: 2.455776531283944

Epoch: 6| Step: 2
Training loss: 2.3541407850975204
Validation loss: 2.460370147252245

Epoch: 6| Step: 3
Training loss: 2.7097091310377026
Validation loss: 2.486386149197172

Epoch: 6| Step: 4
Training loss: 2.2097765567071503
Validation loss: 2.4664188072850055

Epoch: 6| Step: 5
Training loss: 2.2239964740231235
Validation loss: 2.4771133989693763

Epoch: 6| Step: 6
Training loss: 1.6726095422016647
Validation loss: 2.4748169783358045

Epoch: 6| Step: 7
Training loss: 3.3431448700849757
Validation loss: 2.4826633859379017

Epoch: 6| Step: 8
Training loss: 2.7439185436158677
Validation loss: 2.4753045708116566

Epoch: 6| Step: 9
Training loss: 2.4189438340541
Validation loss: 2.4466401998932468

Epoch: 6| Step: 10
Training loss: 2.588308486311572
Validation loss: 2.4667248023808623

Epoch: 6| Step: 11
Training loss: 1.9543850915622043
Validation loss: 2.474387867830293

Epoch: 6| Step: 12
Training loss: 2.076418871824351
Validation loss: 2.4437685920438836

Epoch: 6| Step: 13
Training loss: 3.2587551152899206
Validation loss: 2.469686803704232

Epoch: 183| Step: 0
Training loss: 2.5236748267848723
Validation loss: 2.4335878675939453

Epoch: 6| Step: 1
Training loss: 2.9438573343912275
Validation loss: 2.4950923217436003

Epoch: 6| Step: 2
Training loss: 2.4314100041240057
Validation loss: 2.452840593795839

Epoch: 6| Step: 3
Training loss: 2.360445095697989
Validation loss: 2.4654350896876394

Epoch: 6| Step: 4
Training loss: 2.691295250540125
Validation loss: 2.482013902553177

Epoch: 6| Step: 5
Training loss: 3.2545826221550427
Validation loss: 2.4595566607129147

Epoch: 6| Step: 6
Training loss: 2.212407678089602
Validation loss: 2.4695614360917864

Epoch: 6| Step: 7
Training loss: 2.13311318314613
Validation loss: 2.4651960797782246

Epoch: 6| Step: 8
Training loss: 2.1160230073453232
Validation loss: 2.4382424550325275

Epoch: 6| Step: 9
Training loss: 2.4809684190073966
Validation loss: 2.4753844950366166

Epoch: 6| Step: 10
Training loss: 2.0613319094769365
Validation loss: 2.446846252523149

Epoch: 6| Step: 11
Training loss: 2.2931039175716017
Validation loss: 2.4395194815769683

Epoch: 6| Step: 12
Training loss: 2.223722875728797
Validation loss: 2.4577255776981928

Epoch: 6| Step: 13
Training loss: 2.115921599249926
Validation loss: 2.455641835475811

Epoch: 184| Step: 0
Training loss: 2.6234231481562835
Validation loss: 2.4642003542533475

Epoch: 6| Step: 1
Training loss: 2.2867407367302235
Validation loss: 2.4659446591547867

Epoch: 6| Step: 2
Training loss: 1.809762597611561
Validation loss: 2.458995985971847

Epoch: 6| Step: 3
Training loss: 2.1165745822770594
Validation loss: 2.4653359344230354

Epoch: 6| Step: 4
Training loss: 2.679443170291138
Validation loss: 2.469247979869265

Epoch: 6| Step: 5
Training loss: 2.9868799052863704
Validation loss: 2.473066487634955

Epoch: 6| Step: 6
Training loss: 2.6417739445256494
Validation loss: 2.4976893236955306

Epoch: 6| Step: 7
Training loss: 2.3735187328267173
Validation loss: 2.4571272149196393

Epoch: 6| Step: 8
Training loss: 2.287157535453118
Validation loss: 2.499361034487298

Epoch: 6| Step: 9
Training loss: 2.8143922162530077
Validation loss: 2.4660843985776117

Epoch: 6| Step: 10
Training loss: 2.288878658059885
Validation loss: 2.466527815940264

Epoch: 6| Step: 11
Training loss: 2.5569183222108443
Validation loss: 2.4806755276224783

Epoch: 6| Step: 12
Training loss: 2.4845601138839797
Validation loss: 2.452195921112695

Epoch: 6| Step: 13
Training loss: 1.8506805637293147
Validation loss: 2.46564368591003

Epoch: 185| Step: 0
Training loss: 2.5533393312322357
Validation loss: 2.4773298452631303

Epoch: 6| Step: 1
Training loss: 2.239667692739565
Validation loss: 2.439884031706381

Epoch: 6| Step: 2
Training loss: 2.07753739618276
Validation loss: 2.4556705551939935

Epoch: 6| Step: 3
Training loss: 2.0010070649517497
Validation loss: 2.4527017220239746

Epoch: 6| Step: 4
Training loss: 2.280155075889572
Validation loss: 2.460997202055129

Epoch: 6| Step: 5
Training loss: 2.978101117417601
Validation loss: 2.4874797255238663

Epoch: 6| Step: 6
Training loss: 2.074761673442739
Validation loss: 2.4855962326193457

Epoch: 6| Step: 7
Training loss: 2.7772682061631793
Validation loss: 2.4516307354741604

Epoch: 6| Step: 8
Training loss: 2.1308227871586736
Validation loss: 2.4705413730391963

Epoch: 6| Step: 9
Training loss: 2.397516626771746
Validation loss: 2.454455586782509

Epoch: 6| Step: 10
Training loss: 2.4878868377316516
Validation loss: 2.4789557680504335

Epoch: 6| Step: 11
Training loss: 2.177651387502307
Validation loss: 2.4728880247802096

Epoch: 6| Step: 12
Training loss: 2.662285265076153
Validation loss: 2.4577258030066473

Epoch: 6| Step: 13
Training loss: 3.4380689670287152
Validation loss: 2.4637643543079415

Epoch: 186| Step: 0
Training loss: 2.450559598891095
Validation loss: 2.453802476736289

Epoch: 6| Step: 1
Training loss: 3.01953630335929
Validation loss: 2.473058740929975

Epoch: 6| Step: 2
Training loss: 2.034369083987774
Validation loss: 2.4634236492176433

Epoch: 6| Step: 3
Training loss: 2.0886416391496057
Validation loss: 2.479950833997649

Epoch: 6| Step: 4
Training loss: 2.272427049227605
Validation loss: 2.4946849169129206

Epoch: 6| Step: 5
Training loss: 2.7372835221766905
Validation loss: 2.492534243908105

Epoch: 6| Step: 6
Training loss: 2.5001762328020716
Validation loss: 2.48529184617297

Epoch: 6| Step: 7
Training loss: 2.262869375857746
Validation loss: 2.4673708117146407

Epoch: 6| Step: 8
Training loss: 2.1861727366418315
Validation loss: 2.4792429546125514

Epoch: 6| Step: 9
Training loss: 2.6385289286895715
Validation loss: 2.4678350892213516

Epoch: 6| Step: 10
Training loss: 2.8434637575397184
Validation loss: 2.4568827983159904

Epoch: 6| Step: 11
Training loss: 1.7692523256474986
Validation loss: 2.454974357663708

Epoch: 6| Step: 12
Training loss: 2.213302156542849
Validation loss: 2.4913338820644255

Epoch: 6| Step: 13
Training loss: 3.0665990683803788
Validation loss: 2.454353993946743

Epoch: 187| Step: 0
Training loss: 2.8575548726417646
Validation loss: 2.475105397091369

Epoch: 6| Step: 1
Training loss: 2.984539566695489
Validation loss: 2.4839987696639527

Epoch: 6| Step: 2
Training loss: 3.2948246225274103
Validation loss: 2.511367142721349

Epoch: 6| Step: 3
Training loss: 2.291189826137715
Validation loss: 2.4673418182897033

Epoch: 6| Step: 4
Training loss: 1.8686217860506118
Validation loss: 2.479517365824859

Epoch: 6| Step: 5
Training loss: 1.9977352313203616
Validation loss: 2.4621492021792406

Epoch: 6| Step: 6
Training loss: 2.352346701415867
Validation loss: 2.4744130483631377

Epoch: 6| Step: 7
Training loss: 2.2823606948709267
Validation loss: 2.470016058278876

Epoch: 6| Step: 8
Training loss: 2.432133072468701
Validation loss: 2.4804081543876855

Epoch: 6| Step: 9
Training loss: 2.067219161456501
Validation loss: 2.4928515193830227

Epoch: 6| Step: 10
Training loss: 2.7124492376825033
Validation loss: 2.4574617773967216

Epoch: 6| Step: 11
Training loss: 2.2488442737608474
Validation loss: 2.4579972867740207

Epoch: 6| Step: 12
Training loss: 1.7080485021194953
Validation loss: 2.459596897513861

Epoch: 6| Step: 13
Training loss: 2.7122938297516166
Validation loss: 2.460001521491484

Epoch: 188| Step: 0
Training loss: 1.6623918627224965
Validation loss: 2.50073118694625

Epoch: 6| Step: 1
Training loss: 2.7929494577021634
Validation loss: 2.479796940541549

Epoch: 6| Step: 2
Training loss: 2.2119110444239896
Validation loss: 2.469611243412029

Epoch: 6| Step: 3
Training loss: 2.3298904586386397
Validation loss: 2.4647561308601125

Epoch: 6| Step: 4
Training loss: 2.1421752662225892
Validation loss: 2.4458427180673583

Epoch: 6| Step: 5
Training loss: 2.4134670868931694
Validation loss: 2.456459354864898

Epoch: 6| Step: 6
Training loss: 2.9373152654469914
Validation loss: 2.4479258138939093

Epoch: 6| Step: 7
Training loss: 2.2801760928432215
Validation loss: 2.481414306189661

Epoch: 6| Step: 8
Training loss: 2.4970947550866684
Validation loss: 2.4670294044574823

Epoch: 6| Step: 9
Training loss: 3.147382611546743
Validation loss: 2.4748608738276623

Epoch: 6| Step: 10
Training loss: 2.0968081786286192
Validation loss: 2.4633201886852825

Epoch: 6| Step: 11
Training loss: 2.9177974870256107
Validation loss: 2.446162793375762

Epoch: 6| Step: 12
Training loss: 1.762028770489008
Validation loss: 2.471258890456735

Epoch: 6| Step: 13
Training loss: 2.378010698697059
Validation loss: 2.459978801917087

Epoch: 189| Step: 0
Training loss: 2.6256357967061197
Validation loss: 2.4805801698599033

Epoch: 6| Step: 1
Training loss: 1.9020329716990445
Validation loss: 2.465652924026837

Epoch: 6| Step: 2
Training loss: 2.5672011632201643
Validation loss: 2.4655721868100717

Epoch: 6| Step: 3
Training loss: 2.4549194381765385
Validation loss: 2.463412762098905

Epoch: 6| Step: 4
Training loss: 2.5276710734593273
Validation loss: 2.452040399681251

Epoch: 6| Step: 5
Training loss: 2.5499140855864284
Validation loss: 2.4736270087265666

Epoch: 6| Step: 6
Training loss: 2.7533365296105896
Validation loss: 2.490065469050401

Epoch: 6| Step: 7
Training loss: 1.487849455744836
Validation loss: 2.452727382318421

Epoch: 6| Step: 8
Training loss: 1.9395263903898174
Validation loss: 2.4656914430137724

Epoch: 6| Step: 9
Training loss: 2.2740539553975685
Validation loss: 2.4816761915362036

Epoch: 6| Step: 10
Training loss: 2.707527060192981
Validation loss: 2.452408847448511

Epoch: 6| Step: 11
Training loss: 2.7506914136583602
Validation loss: 2.4743375629808866

Epoch: 6| Step: 12
Training loss: 2.0970924230608854
Validation loss: 2.4674888874760446

Epoch: 6| Step: 13
Training loss: 3.1190608234743076
Validation loss: 2.4789048402438376

Epoch: 190| Step: 0
Training loss: 2.1672113418642804
Validation loss: 2.4763651480299638

Epoch: 6| Step: 1
Training loss: 2.20626434235058
Validation loss: 2.4778319195719796

Epoch: 6| Step: 2
Training loss: 2.7416536077712084
Validation loss: 2.4449262196303234

Epoch: 6| Step: 3
Training loss: 2.52476697922956
Validation loss: 2.4506941378121803

Epoch: 6| Step: 4
Training loss: 2.478852570027981
Validation loss: 2.4472694035210316

Epoch: 6| Step: 5
Training loss: 2.3157541215858486
Validation loss: 2.4571292765759263

Epoch: 6| Step: 6
Training loss: 2.816994022405022
Validation loss: 2.456582446138257

Epoch: 6| Step: 7
Training loss: 2.2187440898977733
Validation loss: 2.4558433748265274

Epoch: 6| Step: 8
Training loss: 2.635182748497902
Validation loss: 2.4821108655365838

Epoch: 6| Step: 9
Training loss: 2.767145977861119
Validation loss: 2.469639163307906

Epoch: 6| Step: 10
Training loss: 1.5975079082836519
Validation loss: 2.4761717849682072

Epoch: 6| Step: 11
Training loss: 2.189536645199757
Validation loss: 2.4751874038813173

Epoch: 6| Step: 12
Training loss: 2.793000334447724
Validation loss: 2.47970138771193

Epoch: 6| Step: 13
Training loss: 2.1443516946191603
Validation loss: 2.469598848770531

Epoch: 191| Step: 0
Training loss: 2.7437388495911668
Validation loss: 2.472304011759405

Epoch: 6| Step: 1
Training loss: 2.507351366469998
Validation loss: 2.4681242906245253

Epoch: 6| Step: 2
Training loss: 2.3003756257868746
Validation loss: 2.4848988690705944

Epoch: 6| Step: 3
Training loss: 2.3119910427566777
Validation loss: 2.4588022871053954

Epoch: 6| Step: 4
Training loss: 2.3834482814394424
Validation loss: 2.422556891956487

Epoch: 6| Step: 5
Training loss: 2.3799775816558797
Validation loss: 2.4521994484480145

Epoch: 6| Step: 6
Training loss: 3.1658570275186095
Validation loss: 2.4668653877119433

Epoch: 6| Step: 7
Training loss: 2.92266639150957
Validation loss: 2.478866321807892

Epoch: 6| Step: 8
Training loss: 2.1612419173275406
Validation loss: 2.461166706079341

Epoch: 6| Step: 9
Training loss: 2.3173341484763434
Validation loss: 2.465098004793948

Epoch: 6| Step: 10
Training loss: 2.276583457960272
Validation loss: 2.4925194731773344

Epoch: 6| Step: 11
Training loss: 1.977391909552022
Validation loss: 2.4606210052271855

Epoch: 6| Step: 12
Training loss: 1.7657056131780426
Validation loss: 2.468288420537045

Epoch: 6| Step: 13
Training loss: 2.37213865882908
Validation loss: 2.478078542532327

Epoch: 192| Step: 0
Training loss: 3.3137675325382423
Validation loss: 2.4692978604764293

Epoch: 6| Step: 1
Training loss: 2.2146144526230946
Validation loss: 2.481225183276613

Epoch: 6| Step: 2
Training loss: 2.3748255213844747
Validation loss: 2.479379520359664

Epoch: 6| Step: 3
Training loss: 2.1688972752939657
Validation loss: 2.484052484811934

Epoch: 6| Step: 4
Training loss: 2.0092575869510148
Validation loss: 2.4754415625118686

Epoch: 6| Step: 5
Training loss: 2.6693107391103665
Validation loss: 2.477363026158685

Epoch: 6| Step: 6
Training loss: 2.0965434555619327
Validation loss: 2.482083841465464

Epoch: 6| Step: 7
Training loss: 2.07176635365265
Validation loss: 2.47873168614869

Epoch: 6| Step: 8
Training loss: 2.164859996612169
Validation loss: 2.4931559607638607

Epoch: 6| Step: 9
Training loss: 1.547368597019703
Validation loss: 2.4662103514681264

Epoch: 6| Step: 10
Training loss: 2.8736771567107144
Validation loss: 2.4519813849777994

Epoch: 6| Step: 11
Training loss: 2.470513595126741
Validation loss: 2.4640667931114604

Epoch: 6| Step: 12
Training loss: 2.6015553517286367
Validation loss: 2.4728938930081497

Epoch: 6| Step: 13
Training loss: 3.2358567534005322
Validation loss: 2.4757945027139363

Epoch: 193| Step: 0
Training loss: 2.7413854050842588
Validation loss: 2.4571844116763604

Epoch: 6| Step: 1
Training loss: 2.072979170529452
Validation loss: 2.474724402133259

Epoch: 6| Step: 2
Training loss: 1.9787305317907227
Validation loss: 2.4609872943497706

Epoch: 6| Step: 3
Training loss: 2.277089125988553
Validation loss: 2.4880607961807715

Epoch: 6| Step: 4
Training loss: 2.96569265242209
Validation loss: 2.4604597657657705

Epoch: 6| Step: 5
Training loss: 2.4800455047678045
Validation loss: 2.471622548206372

Epoch: 6| Step: 6
Training loss: 2.320165969897122
Validation loss: 2.49228475275935

Epoch: 6| Step: 7
Training loss: 2.405335091386535
Validation loss: 2.489117382132956

Epoch: 6| Step: 8
Training loss: 2.459235871583391
Validation loss: 2.4411926638132986

Epoch: 6| Step: 9
Training loss: 2.1304634768424613
Validation loss: 2.4925352199807476

Epoch: 6| Step: 10
Training loss: 2.8750076293844082
Validation loss: 2.426075443320878

Epoch: 6| Step: 11
Training loss: 1.3818874389971953
Validation loss: 2.459930326329001

Epoch: 6| Step: 12
Training loss: 2.9781558760716633
Validation loss: 2.4699573765405383

Epoch: 6| Step: 13
Training loss: 2.581879442516338
Validation loss: 2.446385196254777

Epoch: 194| Step: 0
Training loss: 2.080326033312257
Validation loss: 2.45934481709569

Epoch: 6| Step: 1
Training loss: 2.3233269527280185
Validation loss: 2.495910473986482

Epoch: 6| Step: 2
Training loss: 2.5513488231547896
Validation loss: 2.469333645631542

Epoch: 6| Step: 3
Training loss: 2.5339817329958674
Validation loss: 2.4614900170909086

Epoch: 6| Step: 4
Training loss: 2.1707284219862792
Validation loss: 2.4993197859066343

Epoch: 6| Step: 5
Training loss: 1.9462803037975587
Validation loss: 2.462287246469149

Epoch: 6| Step: 6
Training loss: 2.494375577776982
Validation loss: 2.468231010584764

Epoch: 6| Step: 7
Training loss: 1.9413818726265988
Validation loss: 2.4849436738499

Epoch: 6| Step: 8
Training loss: 2.643276170334589
Validation loss: 2.448248128938061

Epoch: 6| Step: 9
Training loss: 2.539114332403639
Validation loss: 2.4416750965044987

Epoch: 6| Step: 10
Training loss: 2.29553100293793
Validation loss: 2.4357006835159027

Epoch: 6| Step: 11
Training loss: 2.808265974631185
Validation loss: 2.453327762858035

Epoch: 6| Step: 12
Training loss: 2.667401321859748
Validation loss: 2.477819991804818

Epoch: 6| Step: 13
Training loss: 2.679573790692853
Validation loss: 2.4567112090726844

Epoch: 195| Step: 0
Training loss: 1.9912573344543976
Validation loss: 2.4714813906796533

Epoch: 6| Step: 1
Training loss: 2.377284507251492
Validation loss: 2.489053117190197

Epoch: 6| Step: 2
Training loss: 2.5408506699076234
Validation loss: 2.458492351774796

Epoch: 6| Step: 3
Training loss: 2.1846368853708507
Validation loss: 2.4495913290907465

Epoch: 6| Step: 4
Training loss: 3.229484509648418
Validation loss: 2.490743023991533

Epoch: 6| Step: 5
Training loss: 2.093432615906251
Validation loss: 2.4738166524130047

Epoch: 6| Step: 6
Training loss: 1.8824315615672127
Validation loss: 2.4881353057479663

Epoch: 6| Step: 7
Training loss: 2.8637656599638155
Validation loss: 2.4776828558629225

Epoch: 6| Step: 8
Training loss: 2.602723558481576
Validation loss: 2.487618859144825

Epoch: 6| Step: 9
Training loss: 2.1937026233393615
Validation loss: 2.475390327312475

Epoch: 6| Step: 10
Training loss: 2.333541100198301
Validation loss: 2.467625896985145

Epoch: 6| Step: 11
Training loss: 2.3282103042847706
Validation loss: 2.4924770056816605

Epoch: 6| Step: 12
Training loss: 2.6674728267755032
Validation loss: 2.4781600154137826

Epoch: 6| Step: 13
Training loss: 1.7282996091185678
Validation loss: 2.464878408422585

Epoch: 196| Step: 0
Training loss: 2.345323365127231
Validation loss: 2.500935416420044

Epoch: 6| Step: 1
Training loss: 1.8800896548138175
Validation loss: 2.472222666317713

Epoch: 6| Step: 2
Training loss: 2.530406858577111
Validation loss: 2.45332073755105

Epoch: 6| Step: 3
Training loss: 2.599967765608287
Validation loss: 2.4606257644725438

Epoch: 6| Step: 4
Training loss: 1.9528217538024364
Validation loss: 2.4994488190561124

Epoch: 6| Step: 5
Training loss: 2.2915931227471793
Validation loss: 2.476524524831689

Epoch: 6| Step: 6
Training loss: 1.7286530003672544
Validation loss: 2.4655310217691198

Epoch: 6| Step: 7
Training loss: 2.45189028239003
Validation loss: 2.4794322266555437

Epoch: 6| Step: 8
Training loss: 2.6943975250074206
Validation loss: 2.4587366521688967

Epoch: 6| Step: 9
Training loss: 2.648085039029503
Validation loss: 2.4770374401029978

Epoch: 6| Step: 10
Training loss: 2.9682443288502975
Validation loss: 2.455421676352351

Epoch: 6| Step: 11
Training loss: 2.995918676640108
Validation loss: 2.483966727029654

Epoch: 6| Step: 12
Training loss: 2.2147375010684485
Validation loss: 2.4685528999591253

Epoch: 6| Step: 13
Training loss: 2.0315237007608182
Validation loss: 2.479374745930443

Epoch: 197| Step: 0
Training loss: 1.7805366426171956
Validation loss: 2.453358715558844

Epoch: 6| Step: 1
Training loss: 2.2938700631548823
Validation loss: 2.4390814604377025

Epoch: 6| Step: 2
Training loss: 2.5990217936278337
Validation loss: 2.482715352881576

Epoch: 6| Step: 3
Training loss: 2.547595899160124
Validation loss: 2.448525503909202

Epoch: 6| Step: 4
Training loss: 2.4796371868295783
Validation loss: 2.4534677433657768

Epoch: 6| Step: 5
Training loss: 2.4000453467853426
Validation loss: 2.4821011118272533

Epoch: 6| Step: 6
Training loss: 2.196877786952024
Validation loss: 2.474453626360376

Epoch: 6| Step: 7
Training loss: 2.200750708376558
Validation loss: 2.4761566629763943

Epoch: 6| Step: 8
Training loss: 2.270312281567221
Validation loss: 2.4625821369890093

Epoch: 6| Step: 9
Training loss: 2.282976516168413
Validation loss: 2.425257467149222

Epoch: 6| Step: 10
Training loss: 2.1757365415626535
Validation loss: 2.464128974533257

Epoch: 6| Step: 11
Training loss: 2.6934746267378076
Validation loss: 2.476308245223604

Epoch: 6| Step: 12
Training loss: 3.0249811219185925
Validation loss: 2.458607243510067

Epoch: 6| Step: 13
Training loss: 2.535393984423328
Validation loss: 2.4759293011970778

Epoch: 198| Step: 0
Training loss: 1.7956695493754409
Validation loss: 2.4778534418634934

Epoch: 6| Step: 1
Training loss: 2.7592277029604984
Validation loss: 2.4297317317791305

Epoch: 6| Step: 2
Training loss: 2.3867353323252716
Validation loss: 2.458612271504081

Epoch: 6| Step: 3
Training loss: 2.3679102433244115
Validation loss: 2.473928300883585

Epoch: 6| Step: 4
Training loss: 2.194973956846443
Validation loss: 2.4467075476520197

Epoch: 6| Step: 5
Training loss: 2.3838776755984767
Validation loss: 2.4774279389328293

Epoch: 6| Step: 6
Training loss: 2.6231685789140773
Validation loss: 2.495958520399544

Epoch: 6| Step: 7
Training loss: 1.5124163139458173
Validation loss: 2.4642124504193346

Epoch: 6| Step: 8
Training loss: 2.4745411611306616
Validation loss: 2.4829534817274475

Epoch: 6| Step: 9
Training loss: 2.503498300060002
Validation loss: 2.4789434945912725

Epoch: 6| Step: 10
Training loss: 2.498391301418019
Validation loss: 2.457890855718722

Epoch: 6| Step: 11
Training loss: 2.5363048426083705
Validation loss: 2.477741519146674

Epoch: 6| Step: 12
Training loss: 2.5704319702952683
Validation loss: 2.4575389213226804

Epoch: 6| Step: 13
Training loss: 2.6857979286062577
Validation loss: 2.480963683285589

Epoch: 199| Step: 0
Training loss: 2.0958080141068813
Validation loss: 2.465219152680647

Epoch: 6| Step: 1
Training loss: 2.569064222733598
Validation loss: 2.488072773254269

Epoch: 6| Step: 2
Training loss: 1.7001662846190146
Validation loss: 2.4724580677929895

Epoch: 6| Step: 3
Training loss: 1.750705644846692
Validation loss: 2.4816933614328023

Epoch: 6| Step: 4
Training loss: 2.5149597804833244
Validation loss: 2.466406071260727

Epoch: 6| Step: 5
Training loss: 2.5803812962079036
Validation loss: 2.458057450306759

Epoch: 6| Step: 6
Training loss: 2.7829791919233284
Validation loss: 2.4739605087676573

Epoch: 6| Step: 7
Training loss: 1.8646280151923824
Validation loss: 2.4595533336310167

Epoch: 6| Step: 8
Training loss: 2.4138363235343787
Validation loss: 2.4675202303275063

Epoch: 6| Step: 9
Training loss: 2.8367442935433367
Validation loss: 2.4780984622811126

Epoch: 6| Step: 10
Training loss: 2.968974697242914
Validation loss: 2.457827377464666

Epoch: 6| Step: 11
Training loss: 2.1124886597097614
Validation loss: 2.4819174166094173

Epoch: 6| Step: 12
Training loss: 2.5456594363027447
Validation loss: 2.4593308831888976

Epoch: 6| Step: 13
Training loss: 2.142406974918444
Validation loss: 2.477028809536436

Epoch: 200| Step: 0
Training loss: 2.404868187414922
Validation loss: 2.4789174231134745

Epoch: 6| Step: 1
Training loss: 2.408833491606093
Validation loss: 2.495807848105586

Epoch: 6| Step: 2
Training loss: 2.615890591535423
Validation loss: 2.490895830520351

Epoch: 6| Step: 3
Training loss: 2.051330027951485
Validation loss: 2.4806754165271854

Epoch: 6| Step: 4
Training loss: 2.499872585864456
Validation loss: 2.482797482101918

Epoch: 6| Step: 5
Training loss: 2.6837751613196126
Validation loss: 2.4802110396818926

Epoch: 6| Step: 6
Training loss: 1.7271204258425492
Validation loss: 2.4592045227024406

Epoch: 6| Step: 7
Training loss: 2.770693859137016
Validation loss: 2.490391148187192

Epoch: 6| Step: 8
Training loss: 2.50238762327875
Validation loss: 2.4668109974489245

Epoch: 6| Step: 9
Training loss: 1.6572320293994978
Validation loss: 2.4933735725410267

Epoch: 6| Step: 10
Training loss: 2.6237284895990647
Validation loss: 2.4893618149730665

Epoch: 6| Step: 11
Training loss: 2.22323541855521
Validation loss: 2.485206416899979

Epoch: 6| Step: 12
Training loss: 2.6003356423509754
Validation loss: 2.458939246300535

Epoch: 6| Step: 13
Training loss: 2.772752790148866
Validation loss: 2.459283070326925

Epoch: 201| Step: 0
Training loss: 2.838861476602443
Validation loss: 2.4702221982569834

Epoch: 6| Step: 1
Training loss: 2.3136509273675006
Validation loss: 2.4826590840513867

Epoch: 6| Step: 2
Training loss: 2.0931750974358048
Validation loss: 2.462598810711528

Epoch: 6| Step: 3
Training loss: 2.5886017596038635
Validation loss: 2.454366013297103

Epoch: 6| Step: 4
Training loss: 1.9208217929429974
Validation loss: 2.476571438598133

Epoch: 6| Step: 5
Training loss: 2.3765237838932216
Validation loss: 2.454482904076179

Epoch: 6| Step: 6
Training loss: 2.056494089034156
Validation loss: 2.4513903911479495

Epoch: 6| Step: 7
Training loss: 2.6108427202884146
Validation loss: 2.4638894685517645

Epoch: 6| Step: 8
Training loss: 2.9440350177900605
Validation loss: 2.455199261924328

Epoch: 6| Step: 9
Training loss: 2.192622807542046
Validation loss: 2.475225981638492

Epoch: 6| Step: 10
Training loss: 2.3243473818790403
Validation loss: 2.482172901164097

Epoch: 6| Step: 11
Training loss: 1.8403274969266241
Validation loss: 2.4739438209475044

Epoch: 6| Step: 12
Training loss: 3.0447386465677675
Validation loss: 2.484009148057328

Epoch: 6| Step: 13
Training loss: 1.8875228400459017
Validation loss: 2.5011162122089963

Epoch: 202| Step: 0
Training loss: 1.854014386842414
Validation loss: 2.4642436856558123

Epoch: 6| Step: 1
Training loss: 2.814534786397705
Validation loss: 2.4742832110850363

Epoch: 6| Step: 2
Training loss: 2.204369808804159
Validation loss: 2.48559890084626

Epoch: 6| Step: 3
Training loss: 2.839597247941612
Validation loss: 2.4818168714804094

Epoch: 6| Step: 4
Training loss: 2.1092931660920113
Validation loss: 2.4819606349506884

Epoch: 6| Step: 5
Training loss: 1.793817389946912
Validation loss: 2.462934559220114

Epoch: 6| Step: 6
Training loss: 2.861199469163894
Validation loss: 2.478593454113776

Epoch: 6| Step: 7
Training loss: 2.6302375313425514
Validation loss: 2.4604032906449183

Epoch: 6| Step: 8
Training loss: 2.276165351445892
Validation loss: 2.481380508952728

Epoch: 6| Step: 9
Training loss: 2.486264068425624
Validation loss: 2.477174805819692

Epoch: 6| Step: 10
Training loss: 2.266695598342855
Validation loss: 2.4521244376386844

Epoch: 6| Step: 11
Training loss: 2.2485337248061406
Validation loss: 2.4469800851802725

Epoch: 6| Step: 12
Training loss: 2.2031953408124827
Validation loss: 2.4705857616381843

Epoch: 6| Step: 13
Training loss: 2.6242572096799837
Validation loss: 2.4556013360308846

Epoch: 203| Step: 0
Training loss: 2.8820478877815026
Validation loss: 2.471287057304862

Epoch: 6| Step: 1
Training loss: 2.8058154884845727
Validation loss: 2.4449599094838064

Epoch: 6| Step: 2
Training loss: 2.7186173154527724
Validation loss: 2.5104563240231346

Epoch: 6| Step: 3
Training loss: 2.3052691226832556
Validation loss: 2.4540172224358017

Epoch: 6| Step: 4
Training loss: 2.154961021053119
Validation loss: 2.4691320299997455

Epoch: 6| Step: 5
Training loss: 2.3714949191491623
Validation loss: 2.4842210988860884

Epoch: 6| Step: 6
Training loss: 1.7084820690380713
Validation loss: 2.472940313771797

Epoch: 6| Step: 7
Training loss: 1.8099896376929643
Validation loss: 2.4759132054534727

Epoch: 6| Step: 8
Training loss: 2.4612705550296887
Validation loss: 2.475338941915757

Epoch: 6| Step: 9
Training loss: 2.398948788896513
Validation loss: 2.4779050834267484

Epoch: 6| Step: 10
Training loss: 2.2031641746988058
Validation loss: 2.469070863362109

Epoch: 6| Step: 11
Training loss: 2.3820032965751787
Validation loss: 2.464159369167638

Epoch: 6| Step: 12
Training loss: 2.6160732345537623
Validation loss: 2.480390544598699

Epoch: 6| Step: 13
Training loss: 2.4660618306844597
Validation loss: 2.4657570498179298

Epoch: 204| Step: 0
Training loss: 2.79815354772971
Validation loss: 2.4551258046470106

Epoch: 6| Step: 1
Training loss: 2.3870733469068735
Validation loss: 2.4886636451609077

Epoch: 6| Step: 2
Training loss: 2.0079813489161733
Validation loss: 2.454923845064033

Epoch: 6| Step: 3
Training loss: 2.1673264110356465
Validation loss: 2.4633147748242252

Epoch: 6| Step: 4
Training loss: 2.8115051205334205
Validation loss: 2.4771899764458887

Epoch: 6| Step: 5
Training loss: 2.819808111764063
Validation loss: 2.468395219603837

Epoch: 6| Step: 6
Training loss: 2.4467827517682452
Validation loss: 2.466475124399801

Epoch: 6| Step: 7
Training loss: 1.9826190418230603
Validation loss: 2.497900421635204

Epoch: 6| Step: 8
Training loss: 2.483629030719251
Validation loss: 2.505094641808414

Epoch: 6| Step: 9
Training loss: 2.0518859794199784
Validation loss: 2.490745630095266

Epoch: 6| Step: 10
Training loss: 1.8442612925076842
Validation loss: 2.4854374870444094

Epoch: 6| Step: 11
Training loss: 2.5758031388875073
Validation loss: 2.4674003071577353

Epoch: 6| Step: 12
Training loss: 2.3906415552301565
Validation loss: 2.49108226904338

Epoch: 6| Step: 13
Training loss: 2.519114378515727
Validation loss: 2.4847642043301454

Epoch: 205| Step: 0
Training loss: 2.2859899320605988
Validation loss: 2.459806630307824

Epoch: 6| Step: 1
Training loss: 2.1759298332065042
Validation loss: 2.4691032778921396

Epoch: 6| Step: 2
Training loss: 2.860167846822894
Validation loss: 2.488324915186196

Epoch: 6| Step: 3
Training loss: 2.3481776821551295
Validation loss: 2.490106656271591

Epoch: 6| Step: 4
Training loss: 2.060929365048032
Validation loss: 2.444686318303304

Epoch: 6| Step: 5
Training loss: 2.1198596490429797
Validation loss: 2.4671607218109277

Epoch: 6| Step: 6
Training loss: 2.1181780197788194
Validation loss: 2.458401627076021

Epoch: 6| Step: 7
Training loss: 2.7639772495818513
Validation loss: 2.482208217198785

Epoch: 6| Step: 8
Training loss: 2.4010354550185435
Validation loss: 2.4505633367642767

Epoch: 6| Step: 9
Training loss: 2.0862101973113165
Validation loss: 2.452835265502517

Epoch: 6| Step: 10
Training loss: 2.194957337888125
Validation loss: 2.466051977632852

Epoch: 6| Step: 11
Training loss: 2.254747679945525
Validation loss: 2.4866172983828476

Epoch: 6| Step: 12
Training loss: 2.6006689971597856
Validation loss: 2.4808008259942365

Epoch: 6| Step: 13
Training loss: 2.8315334961284258
Validation loss: 2.4434271268980345

Epoch: 206| Step: 0
Training loss: 1.5618087765506052
Validation loss: 2.4829523521760826

Epoch: 6| Step: 1
Training loss: 2.2231133766932185
Validation loss: 2.457289748674101

Epoch: 6| Step: 2
Training loss: 2.1784941438460947
Validation loss: 2.4763340253125414

Epoch: 6| Step: 3
Training loss: 2.6205948697411197
Validation loss: 2.441850895119018

Epoch: 6| Step: 4
Training loss: 2.267533439044787
Validation loss: 2.475715790334184

Epoch: 6| Step: 5
Training loss: 2.815357960221639
Validation loss: 2.4729526439786897

Epoch: 6| Step: 6
Training loss: 2.6850251623924613
Validation loss: 2.465657742702166

Epoch: 6| Step: 7
Training loss: 2.34015939968417
Validation loss: 2.4619137459386646

Epoch: 6| Step: 8
Training loss: 2.321165191465126
Validation loss: 2.4752254461712813

Epoch: 6| Step: 9
Training loss: 2.9485975002749916
Validation loss: 2.4757020655814075

Epoch: 6| Step: 10
Training loss: 1.8367165069371671
Validation loss: 2.480852973525127

Epoch: 6| Step: 11
Training loss: 2.2085780841823692
Validation loss: 2.474678355663338

Epoch: 6| Step: 12
Training loss: 2.318894900501166
Validation loss: 2.4714690209765275

Epoch: 6| Step: 13
Training loss: 2.6771270708798443
Validation loss: 2.4655534936619623

Epoch: 207| Step: 0
Training loss: 2.858873667308488
Validation loss: 2.4906209673829394

Epoch: 6| Step: 1
Training loss: 2.107587947435826
Validation loss: 2.472522020645348

Epoch: 6| Step: 2
Training loss: 2.1058733096729303
Validation loss: 2.4810221914973116

Epoch: 6| Step: 3
Training loss: 2.2191256352908635
Validation loss: 2.479261686207448

Epoch: 6| Step: 4
Training loss: 2.3532883910335536
Validation loss: 2.4704368428683634

Epoch: 6| Step: 5
Training loss: 2.22457154252702
Validation loss: 2.4894758226931364

Epoch: 6| Step: 6
Training loss: 2.5294780415933307
Validation loss: 2.4669603252657613

Epoch: 6| Step: 7
Training loss: 2.8487091420395907
Validation loss: 2.4709989357108704

Epoch: 6| Step: 8
Training loss: 2.25334300601546
Validation loss: 2.4894322899433314

Epoch: 6| Step: 9
Training loss: 1.7128073868921412
Validation loss: 2.438836451523065

Epoch: 6| Step: 10
Training loss: 2.602051560080926
Validation loss: 2.4781220688641104

Epoch: 6| Step: 11
Training loss: 2.151989916398486
Validation loss: 2.4961686473024516

Epoch: 6| Step: 12
Training loss: 2.3418240581395104
Validation loss: 2.4668911963355664

Epoch: 6| Step: 13
Training loss: 2.758147827164621
Validation loss: 2.456157497991803

Epoch: 208| Step: 0
Training loss: 2.2460914147406337
Validation loss: 2.4636918339795515

Epoch: 6| Step: 1
Training loss: 1.7782135229081992
Validation loss: 2.506914334406148

Epoch: 6| Step: 2
Training loss: 2.254790504518945
Validation loss: 2.4551675889704496

Epoch: 6| Step: 3
Training loss: 2.104316353588263
Validation loss: 2.4823965051310424

Epoch: 6| Step: 4
Training loss: 2.5893193285033305
Validation loss: 2.4900736004031434

Epoch: 6| Step: 5
Training loss: 2.4407556750376043
Validation loss: 2.474515218356835

Epoch: 6| Step: 6
Training loss: 1.874375430034246
Validation loss: 2.4776777403363908

Epoch: 6| Step: 7
Training loss: 3.2261894693944497
Validation loss: 2.465193477862577

Epoch: 6| Step: 8
Training loss: 2.378098524550289
Validation loss: 2.467914024903237

Epoch: 6| Step: 9
Training loss: 1.9593253632848797
Validation loss: 2.486160104445703

Epoch: 6| Step: 10
Training loss: 2.1083925573100033
Validation loss: 2.4733072588434286

Epoch: 6| Step: 11
Training loss: 2.3555368695127727
Validation loss: 2.453434152575801

Epoch: 6| Step: 12
Training loss: 2.520766979847009
Validation loss: 2.4786818459335116

Epoch: 6| Step: 13
Training loss: 3.0990398150505514
Validation loss: 2.4966261226958335

Epoch: 209| Step: 0
Training loss: 2.5024404058687026
Validation loss: 2.488318961262387

Epoch: 6| Step: 1
Training loss: 2.311983514792993
Validation loss: 2.4572724635544043

Epoch: 6| Step: 2
Training loss: 2.0472714571623185
Validation loss: 2.468322177368564

Epoch: 6| Step: 3
Training loss: 2.5227822790623984
Validation loss: 2.4792597060317347

Epoch: 6| Step: 4
Training loss: 2.4924739087115655
Validation loss: 2.454138114532321

Epoch: 6| Step: 5
Training loss: 2.959739905863988
Validation loss: 2.4760963801214175

Epoch: 6| Step: 6
Training loss: 2.289624246145554
Validation loss: 2.459437620926172

Epoch: 6| Step: 7
Training loss: 2.4777738574937374
Validation loss: 2.4659322076176857

Epoch: 6| Step: 8
Training loss: 2.681605417308024
Validation loss: 2.4544131312568487

Epoch: 6| Step: 9
Training loss: 2.672309884712864
Validation loss: 2.4301321678353425

Epoch: 6| Step: 10
Training loss: 2.3218955859251027
Validation loss: 2.494045338523469

Epoch: 6| Step: 11
Training loss: 2.0586081111631422
Validation loss: 2.4833539424133844

Epoch: 6| Step: 12
Training loss: 1.65316816825246
Validation loss: 2.480834377434002

Epoch: 6| Step: 13
Training loss: 2.053458306650242
Validation loss: 2.4567913213012433

Epoch: 210| Step: 0
Training loss: 2.6460452457979735
Validation loss: 2.4915808683444816

Epoch: 6| Step: 1
Training loss: 2.359318208326738
Validation loss: 2.4800798690884065

Epoch: 6| Step: 2
Training loss: 2.58389782634487
Validation loss: 2.4961874336685455

Epoch: 6| Step: 3
Training loss: 2.6118753297855326
Validation loss: 2.451002858555401

Epoch: 6| Step: 4
Training loss: 1.7494778535350957
Validation loss: 2.4735324819953224

Epoch: 6| Step: 5
Training loss: 2.6478194244160957
Validation loss: 2.4654735153749243

Epoch: 6| Step: 6
Training loss: 2.8174533035213187
Validation loss: 2.442799377808736

Epoch: 6| Step: 7
Training loss: 2.5573384474277905
Validation loss: 2.481588326829495

Epoch: 6| Step: 8
Training loss: 2.10419953827314
Validation loss: 2.5083407430716855

Epoch: 6| Step: 9
Training loss: 2.1791810024901026
Validation loss: 2.4947284104137144

Epoch: 6| Step: 10
Training loss: 2.351536544707258
Validation loss: 2.479914110396189

Epoch: 6| Step: 11
Training loss: 2.290358453207106
Validation loss: 2.47551603144735

Epoch: 6| Step: 12
Training loss: 1.9867198636572774
Validation loss: 2.4655271412605004

Epoch: 6| Step: 13
Training loss: 1.6525870791069899
Validation loss: 2.4411004607304627

Epoch: 211| Step: 0
Training loss: 2.1106337570898894
Validation loss: 2.495826854947689

Epoch: 6| Step: 1
Training loss: 2.4514761078627454
Validation loss: 2.497733537749363

Epoch: 6| Step: 2
Training loss: 3.0109355615709577
Validation loss: 2.4686417219062866

Epoch: 6| Step: 3
Training loss: 1.592513857890487
Validation loss: 2.4831240608002094

Epoch: 6| Step: 4
Training loss: 1.9207659366834782
Validation loss: 2.4741296469025116

Epoch: 6| Step: 5
Training loss: 2.3714345972966178
Validation loss: 2.4897588457837205

Epoch: 6| Step: 6
Training loss: 2.0962792677363065
Validation loss: 2.470390787047936

Epoch: 6| Step: 7
Training loss: 2.425249468369323
Validation loss: 2.467370940552766

Epoch: 6| Step: 8
Training loss: 2.593122199501333
Validation loss: 2.4565827999118968

Epoch: 6| Step: 9
Training loss: 2.9781664434153203
Validation loss: 2.4584470305126707

Epoch: 6| Step: 10
Training loss: 2.0440083005105807
Validation loss: 2.426552971555351

Epoch: 6| Step: 11
Training loss: 2.512155735096439
Validation loss: 2.4584549118965784

Epoch: 6| Step: 12
Training loss: 2.3473692351981996
Validation loss: 2.4999760308706103

Epoch: 6| Step: 13
Training loss: 1.913771252953281
Validation loss: 2.4691663863150093

Epoch: 212| Step: 0
Training loss: 1.8617674238122903
Validation loss: 2.4523448310939595

Epoch: 6| Step: 1
Training loss: 2.987606196730614
Validation loss: 2.460522706206787

Epoch: 6| Step: 2
Training loss: 2.5138503739677414
Validation loss: 2.4632077481955394

Epoch: 6| Step: 3
Training loss: 2.7519254012975427
Validation loss: 2.4748214627038823

Epoch: 6| Step: 4
Training loss: 2.2496574988883724
Validation loss: 2.472197445845956

Epoch: 6| Step: 5
Training loss: 1.7409390479542977
Validation loss: 2.49216274182699

Epoch: 6| Step: 6
Training loss: 1.6400404842543632
Validation loss: 2.4704962089976985

Epoch: 6| Step: 7
Training loss: 2.0770659078353635
Validation loss: 2.478842910538555

Epoch: 6| Step: 8
Training loss: 2.389696626602131
Validation loss: 2.454808774669686

Epoch: 6| Step: 9
Training loss: 2.2915654477972227
Validation loss: 2.4765516483846417

Epoch: 6| Step: 10
Training loss: 2.665204024529943
Validation loss: 2.476920247502211

Epoch: 6| Step: 11
Training loss: 2.605230088863164
Validation loss: 2.4560601340652055

Epoch: 6| Step: 12
Training loss: 2.407617353864986
Validation loss: 2.4905140992516808

Epoch: 6| Step: 13
Training loss: 2.2702754207347686
Validation loss: 2.436374643273838

Epoch: 213| Step: 0
Training loss: 2.5752002193793317
Validation loss: 2.4453009477657193

Epoch: 6| Step: 1
Training loss: 2.272721954686272
Validation loss: 2.4553051748264387

Epoch: 6| Step: 2
Training loss: 2.1563842289374264
Validation loss: 2.4691799470124898

Epoch: 6| Step: 3
Training loss: 2.2440757111273517
Validation loss: 2.49524942876064

Epoch: 6| Step: 4
Training loss: 2.2309582602350795
Validation loss: 2.4649092805614212

Epoch: 6| Step: 5
Training loss: 2.21469605506783
Validation loss: 2.4545566897481965

Epoch: 6| Step: 6
Training loss: 2.6050665457750326
Validation loss: 2.458003398625945

Epoch: 6| Step: 7
Training loss: 2.691174589908719
Validation loss: 2.4851636614464634

Epoch: 6| Step: 8
Training loss: 2.214470941293926
Validation loss: 2.477113647352725

Epoch: 6| Step: 9
Training loss: 2.3480096382840103
Validation loss: 2.477822497173521

Epoch: 6| Step: 10
Training loss: 2.4033661442323324
Validation loss: 2.492308931635541

Epoch: 6| Step: 11
Training loss: 2.5449306812851282
Validation loss: 2.4712513123662205

Epoch: 6| Step: 12
Training loss: 1.7994811687835581
Validation loss: 2.478676421151033

Epoch: 6| Step: 13
Training loss: 2.8208156147507895
Validation loss: 2.480884894138969

Epoch: 214| Step: 0
Training loss: 2.4740263169969725
Validation loss: 2.4597000534573565

Epoch: 6| Step: 1
Training loss: 3.2026176236876434
Validation loss: 2.4753601140794936

Epoch: 6| Step: 2
Training loss: 1.843212372580368
Validation loss: 2.4965004792509125

Epoch: 6| Step: 3
Training loss: 2.267844329900773
Validation loss: 2.440620956952205

Epoch: 6| Step: 4
Training loss: 2.0916401495398858
Validation loss: 2.4862191523621107

Epoch: 6| Step: 5
Training loss: 1.9911718434850056
Validation loss: 2.51670011133345

Epoch: 6| Step: 6
Training loss: 2.0513493214330176
Validation loss: 2.4825458672014262

Epoch: 6| Step: 7
Training loss: 2.1948094996551775
Validation loss: 2.4811103263026038

Epoch: 6| Step: 8
Training loss: 2.3894702391286735
Validation loss: 2.461525697563864

Epoch: 6| Step: 9
Training loss: 2.039700463126526
Validation loss: 2.44367788721568

Epoch: 6| Step: 10
Training loss: 2.2475638446502044
Validation loss: 2.4972055363042784

Epoch: 6| Step: 11
Training loss: 2.4716762149323688
Validation loss: 2.472430939770563

Epoch: 6| Step: 12
Training loss: 2.829902216970966
Validation loss: 2.4796250821644357

Epoch: 6| Step: 13
Training loss: 2.7054606143169257
Validation loss: 2.4664974229485344

Epoch: 215| Step: 0
Training loss: 2.477661177919035
Validation loss: 2.476320364031472

Epoch: 6| Step: 1
Training loss: 2.500235737176612
Validation loss: 2.4899524746799853

Epoch: 6| Step: 2
Training loss: 2.170942806282988
Validation loss: 2.4666820269419305

Epoch: 6| Step: 3
Training loss: 1.9948785296486047
Validation loss: 2.4995328794941107

Epoch: 6| Step: 4
Training loss: 2.736235329077623
Validation loss: 2.508730503402618

Epoch: 6| Step: 5
Training loss: 2.8517089806127522
Validation loss: 2.459692911899136

Epoch: 6| Step: 6
Training loss: 1.6892301379215044
Validation loss: 2.5001633929110083

Epoch: 6| Step: 7
Training loss: 2.1798203950792523
Validation loss: 2.4845066975973995

Epoch: 6| Step: 8
Training loss: 2.154052499172073
Validation loss: 2.4886108433601

Epoch: 6| Step: 9
Training loss: 2.4890689291814136
Validation loss: 2.4463302233209667

Epoch: 6| Step: 10
Training loss: 2.524491317422812
Validation loss: 2.467073514367424

Epoch: 6| Step: 11
Training loss: 2.392811791045109
Validation loss: 2.4786909873632643

Epoch: 6| Step: 12
Training loss: 2.19832775978074
Validation loss: 2.488611270872009

Epoch: 6| Step: 13
Training loss: 2.1510549795802527
Validation loss: 2.4472753054188376

Epoch: 216| Step: 0
Training loss: 2.193638934070803
Validation loss: 2.4821951666222843

Epoch: 6| Step: 1
Training loss: 2.2377883341751867
Validation loss: 2.504554549807857

Epoch: 6| Step: 2
Training loss: 2.243242181888256
Validation loss: 2.4461223848523166

Epoch: 6| Step: 3
Training loss: 2.960814138776678
Validation loss: 2.4797419649800414

Epoch: 6| Step: 4
Training loss: 2.5156955116767814
Validation loss: 2.492022344508579

Epoch: 6| Step: 5
Training loss: 2.2042111364059935
Validation loss: 2.4550771998212824

Epoch: 6| Step: 6
Training loss: 2.0336247574050295
Validation loss: 2.472576716083399

Epoch: 6| Step: 7
Training loss: 2.4290408534277166
Validation loss: 2.4844730373590282

Epoch: 6| Step: 8
Training loss: 2.260705908861182
Validation loss: 2.4664079786022644

Epoch: 6| Step: 9
Training loss: 2.89835639284893
Validation loss: 2.474063961621627

Epoch: 6| Step: 10
Training loss: 1.5117828592117228
Validation loss: 2.475644078851949

Epoch: 6| Step: 11
Training loss: 2.1357079159987484
Validation loss: 2.492280854245909

Epoch: 6| Step: 12
Training loss: 2.3385539121809877
Validation loss: 2.5006519595526315

Epoch: 6| Step: 13
Training loss: 2.4660308929265593
Validation loss: 2.457316907182481

Epoch: 217| Step: 0
Training loss: 2.3069994693353686
Validation loss: 2.45262415104606

Epoch: 6| Step: 1
Training loss: 2.7817106401256373
Validation loss: 2.497514452045141

Epoch: 6| Step: 2
Training loss: 2.820728387575558
Validation loss: 2.47153163852603

Epoch: 6| Step: 3
Training loss: 1.9890053860000252
Validation loss: 2.46726130830431

Epoch: 6| Step: 4
Training loss: 2.160891306087572
Validation loss: 2.4875501260227724

Epoch: 6| Step: 5
Training loss: 2.2694482574783637
Validation loss: 2.443415470272353

Epoch: 6| Step: 6
Training loss: 2.0743401270984045
Validation loss: 2.4755056821723223

Epoch: 6| Step: 7
Training loss: 2.199062850060922
Validation loss: 2.496536730389414

Epoch: 6| Step: 8
Training loss: 1.8855721284903164
Validation loss: 2.4813534392169765

Epoch: 6| Step: 9
Training loss: 2.618332888358127
Validation loss: 2.501340923834217

Epoch: 6| Step: 10
Training loss: 2.571996259090379
Validation loss: 2.4831447691048254

Epoch: 6| Step: 11
Training loss: 1.8011066531681086
Validation loss: 2.4819389396254308

Epoch: 6| Step: 12
Training loss: 2.4705817271929593
Validation loss: 2.4946473964282685

Epoch: 6| Step: 13
Training loss: 2.3814649429832477
Validation loss: 2.472819867617762

Epoch: 218| Step: 0
Training loss: 1.9749466393903738
Validation loss: 2.470365434758564

Epoch: 6| Step: 1
Training loss: 2.196646831270463
Validation loss: 2.458038592584727

Epoch: 6| Step: 2
Training loss: 1.785244528426186
Validation loss: 2.4807608106523107

Epoch: 6| Step: 3
Training loss: 2.6933976157546318
Validation loss: 2.4929811053296183

Epoch: 6| Step: 4
Training loss: 1.9349765341466971
Validation loss: 2.4652157724052706

Epoch: 6| Step: 5
Training loss: 2.5913745159406147
Validation loss: 2.490466604034988

Epoch: 6| Step: 6
Training loss: 3.1375617275776984
Validation loss: 2.469497806245938

Epoch: 6| Step: 7
Training loss: 2.4830479946529427
Validation loss: 2.485509063464092

Epoch: 6| Step: 8
Training loss: 2.640499676320642
Validation loss: 2.4407901177765594

Epoch: 6| Step: 9
Training loss: 2.067769226663737
Validation loss: 2.4783944940159586

Epoch: 6| Step: 10
Training loss: 2.3020861411329268
Validation loss: 2.461649543087571

Epoch: 6| Step: 11
Training loss: 2.0070313592883267
Validation loss: 2.502845793385814

Epoch: 6| Step: 12
Training loss: 2.2512457895530797
Validation loss: 2.4792024798213768

Epoch: 6| Step: 13
Training loss: 1.9240296853684022
Validation loss: 2.478384760333201

Epoch: 219| Step: 0
Training loss: 2.9600474446592555
Validation loss: 2.4718977504110735

Epoch: 6| Step: 1
Training loss: 2.447336352666608
Validation loss: 2.465109747125254

Epoch: 6| Step: 2
Training loss: 1.8788775721401618
Validation loss: 2.48626736646594

Epoch: 6| Step: 3
Training loss: 2.3442888784798175
Validation loss: 2.4876607623944147

Epoch: 6| Step: 4
Training loss: 2.018199607058396
Validation loss: 2.4555934621922497

Epoch: 6| Step: 5
Training loss: 2.9629366524729117
Validation loss: 2.462382300669436

Epoch: 6| Step: 6
Training loss: 2.1946842475702977
Validation loss: 2.5036277660285235

Epoch: 6| Step: 7
Training loss: 2.6103091823392846
Validation loss: 2.460642434261107

Epoch: 6| Step: 8
Training loss: 2.690089730109849
Validation loss: 2.4774178506541555

Epoch: 6| Step: 9
Training loss: 2.2355173032018874
Validation loss: 2.49128406757703

Epoch: 6| Step: 10
Training loss: 1.1606072470807334
Validation loss: 2.4756269498442633

Epoch: 6| Step: 11
Training loss: 2.2237207314085974
Validation loss: 2.5074416394844734

Epoch: 6| Step: 12
Training loss: 1.8084950100864443
Validation loss: 2.482898345805277

Epoch: 6| Step: 13
Training loss: 2.7220803394668054
Validation loss: 2.472637546125581

Epoch: 220| Step: 0
Training loss: 2.6628976551806405
Validation loss: 2.456076666790442

Epoch: 6| Step: 1
Training loss: 1.8251011937970691
Validation loss: 2.483957917735548

Epoch: 6| Step: 2
Training loss: 1.7937519964014301
Validation loss: 2.498116563104943

Epoch: 6| Step: 3
Training loss: 2.7980708117901067
Validation loss: 2.480714089789883

Epoch: 6| Step: 4
Training loss: 2.1973529713541686
Validation loss: 2.4580091902695553

Epoch: 6| Step: 5
Training loss: 2.5516871761176336
Validation loss: 2.442551057827079

Epoch: 6| Step: 6
Training loss: 1.6776511690159288
Validation loss: 2.4717704620892564

Epoch: 6| Step: 7
Training loss: 2.9217173487925474
Validation loss: 2.4438106618191506

Epoch: 6| Step: 8
Training loss: 1.4450290711326388
Validation loss: 2.4417456553813106

Epoch: 6| Step: 9
Training loss: 2.7919709243845365
Validation loss: 2.4581798279939866

Epoch: 6| Step: 10
Training loss: 2.672455038721976
Validation loss: 2.4778417909625237

Epoch: 6| Step: 11
Training loss: 2.4035845769734316
Validation loss: 2.4823007828157424

Epoch: 6| Step: 12
Training loss: 2.1287561766198286
Validation loss: 2.4710967173593277

Epoch: 6| Step: 13
Training loss: 1.5489881319806706
Validation loss: 2.4492620983835356

Epoch: 221| Step: 0
Training loss: 2.202805191527955
Validation loss: 2.4610593401984984

Epoch: 6| Step: 1
Training loss: 2.3240402537813947
Validation loss: 2.4803123925457222

Epoch: 6| Step: 2
Training loss: 2.147107964859348
Validation loss: 2.4687154717378306

Epoch: 6| Step: 3
Training loss: 2.2693913165498443
Validation loss: 2.491928544376485

Epoch: 6| Step: 4
Training loss: 2.12911118387194
Validation loss: 2.4673511232997547

Epoch: 6| Step: 5
Training loss: 2.107569395033723
Validation loss: 2.4922076109483213

Epoch: 6| Step: 6
Training loss: 2.4727067746368476
Validation loss: 2.473395023861319

Epoch: 6| Step: 7
Training loss: 2.1993123063401185
Validation loss: 2.488083579772826

Epoch: 6| Step: 8
Training loss: 2.3563162068341668
Validation loss: 2.5106196552270683

Epoch: 6| Step: 9
Training loss: 2.650388645966929
Validation loss: 2.43007095318739

Epoch: 6| Step: 10
Training loss: 2.550837704558077
Validation loss: 2.4815133081722522

Epoch: 6| Step: 11
Training loss: 2.320311575224721
Validation loss: 2.4542489049025766

Epoch: 6| Step: 12
Training loss: 2.8522899797105015
Validation loss: 2.4618600132274304

Epoch: 6| Step: 13
Training loss: 1.98381647374793
Validation loss: 2.488894453046454

Epoch: 222| Step: 0
Training loss: 2.4519194538210516
Validation loss: 2.447159863851171

Epoch: 6| Step: 1
Training loss: 2.362137547699221
Validation loss: 2.469451954036426

Epoch: 6| Step: 2
Training loss: 1.8791220812643243
Validation loss: 2.4891917900393143

Epoch: 6| Step: 3
Training loss: 2.7407302679638867
Validation loss: 2.4489248789340405

Epoch: 6| Step: 4
Training loss: 2.8116843842327124
Validation loss: 2.4749734877120035

Epoch: 6| Step: 5
Training loss: 2.4336270594881317
Validation loss: 2.4922972032743687

Epoch: 6| Step: 6
Training loss: 2.008541939481536
Validation loss: 2.4737176020044336

Epoch: 6| Step: 7
Training loss: 2.109603304340551
Validation loss: 2.5060053816499255

Epoch: 6| Step: 8
Training loss: 2.082534929511507
Validation loss: 2.4796233349026293

Epoch: 6| Step: 9
Training loss: 2.850262405629493
Validation loss: 2.5245901975122784

Epoch: 6| Step: 10
Training loss: 2.265713499248095
Validation loss: 2.484392400964283

Epoch: 6| Step: 11
Training loss: 2.15030602783329
Validation loss: 2.4821924069474295

Epoch: 6| Step: 12
Training loss: 2.077381890310127
Validation loss: 2.475502494067025

Epoch: 6| Step: 13
Training loss: 1.949630357479975
Validation loss: 2.4560940855802524

Epoch: 223| Step: 0
Training loss: 2.4611194361691093
Validation loss: 2.4792642319976075

Epoch: 6| Step: 1
Training loss: 2.3497513294542927
Validation loss: 2.4910346786575457

Epoch: 6| Step: 2
Training loss: 2.5129536726810664
Validation loss: 2.4900480861100283

Epoch: 6| Step: 3
Training loss: 2.8011047091375816
Validation loss: 2.48942672999647

Epoch: 6| Step: 4
Training loss: 2.079132294864456
Validation loss: 2.472729171986342

Epoch: 6| Step: 5
Training loss: 2.4387513885415886
Validation loss: 2.471420465792428

Epoch: 6| Step: 6
Training loss: 2.4287714074448385
Validation loss: 2.4798996774879134

Epoch: 6| Step: 7
Training loss: 2.034118270496261
Validation loss: 2.513190516492634

Epoch: 6| Step: 8
Training loss: 2.053522163890103
Validation loss: 2.4931483649124497

Epoch: 6| Step: 9
Training loss: 2.3105257215523123
Validation loss: 2.5096525287838474

Epoch: 6| Step: 10
Training loss: 1.8521524125365971
Validation loss: 2.47838423692686

Epoch: 6| Step: 11
Training loss: 2.5254240454212624
Validation loss: 2.4744192564274816

Epoch: 6| Step: 12
Training loss: 1.7576226025898636
Validation loss: 2.479267842837656

Epoch: 6| Step: 13
Training loss: 2.855765978246426
Validation loss: 2.4815623781814242

Epoch: 224| Step: 0
Training loss: 2.386947695775541
Validation loss: 2.4904677615743904

Epoch: 6| Step: 1
Training loss: 2.339362959589995
Validation loss: 2.468718803087151

Epoch: 6| Step: 2
Training loss: 2.157780090574803
Validation loss: 2.4757590113141026

Epoch: 6| Step: 3
Training loss: 2.557540746757651
Validation loss: 2.4711662795141547

Epoch: 6| Step: 4
Training loss: 2.0719979964581676
Validation loss: 2.469844282234613

Epoch: 6| Step: 5
Training loss: 2.1606983242773983
Validation loss: 2.4769617811255262

Epoch: 6| Step: 6
Training loss: 2.1994604923058643
Validation loss: 2.482588331095598

Epoch: 6| Step: 7
Training loss: 2.721447538145988
Validation loss: 2.472043007490765

Epoch: 6| Step: 8
Training loss: 2.0974725681916335
Validation loss: 2.486364844085968

Epoch: 6| Step: 9
Training loss: 1.7652010788534547
Validation loss: 2.4531248704136774

Epoch: 6| Step: 10
Training loss: 2.5696909422528402
Validation loss: 2.4592914400164028

Epoch: 6| Step: 11
Training loss: 1.9641056077303662
Validation loss: 2.484305242197722

Epoch: 6| Step: 12
Training loss: 3.0279560872651787
Validation loss: 2.478384137624459

Epoch: 6| Step: 13
Training loss: 2.163961690489574
Validation loss: 2.4968133274624273

Epoch: 225| Step: 0
Training loss: 2.2663674026100185
Validation loss: 2.470608936741959

Epoch: 6| Step: 1
Training loss: 2.511132535261661
Validation loss: 2.4544281699576764

Epoch: 6| Step: 2
Training loss: 2.3299295485163936
Validation loss: 2.445836754015421

Epoch: 6| Step: 3
Training loss: 3.4251279653882523
Validation loss: 2.4900503171539987

Epoch: 6| Step: 4
Training loss: 2.32159963543427
Validation loss: 2.439761950478225

Epoch: 6| Step: 5
Training loss: 2.388489610981203
Validation loss: 2.4687266049484387

Epoch: 6| Step: 6
Training loss: 2.3956516252247817
Validation loss: 2.4897244039706585

Epoch: 6| Step: 7
Training loss: 1.3884396902166243
Validation loss: 2.4745187926140226

Epoch: 6| Step: 8
Training loss: 2.240277051311306
Validation loss: 2.475797880453906

Epoch: 6| Step: 9
Training loss: 1.962241480133888
Validation loss: 2.4729923523421977

Epoch: 6| Step: 10
Training loss: 2.756129629400188
Validation loss: 2.4597259096435713

Epoch: 6| Step: 11
Training loss: 1.6446122899327968
Validation loss: 2.4832971254203122

Epoch: 6| Step: 12
Training loss: 2.0579271196263496
Validation loss: 2.451022775564664

Epoch: 6| Step: 13
Training loss: 1.6604104240169302
Validation loss: 2.4851802244107124

Epoch: 226| Step: 0
Training loss: 2.349520484213173
Validation loss: 2.45033555670098

Epoch: 6| Step: 1
Training loss: 2.5944833293327023
Validation loss: 2.4766978818866545

Epoch: 6| Step: 2
Training loss: 2.8599371018862643
Validation loss: 2.4809309866153106

Epoch: 6| Step: 3
Training loss: 1.9768883960425574
Validation loss: 2.4481845127066997

Epoch: 6| Step: 4
Training loss: 1.7031462081848603
Validation loss: 2.4900800432819157

Epoch: 6| Step: 5
Training loss: 2.235039885504266
Validation loss: 2.5143395947890603

Epoch: 6| Step: 6
Training loss: 2.3727107810799604
Validation loss: 2.483848749767764

Epoch: 6| Step: 7
Training loss: 2.7308449765670075
Validation loss: 2.4541531637976233

Epoch: 6| Step: 8
Training loss: 1.7702546314770973
Validation loss: 2.487721386936851

Epoch: 6| Step: 9
Training loss: 2.281614300628723
Validation loss: 2.469865549246147

Epoch: 6| Step: 10
Training loss: 2.5816282572473837
Validation loss: 2.4599728075244154

Epoch: 6| Step: 11
Training loss: 2.1373094931137717
Validation loss: 2.4600665807880415

Epoch: 6| Step: 12
Training loss: 2.2860040119165976
Validation loss: 2.4594483062238366

Epoch: 6| Step: 13
Training loss: 2.1946994563573736
Validation loss: 2.466298960492406

Epoch: 227| Step: 0
Training loss: 2.346971865914053
Validation loss: 2.4520906193486325

Epoch: 6| Step: 1
Training loss: 2.456084003614799
Validation loss: 2.4735503592934154

Epoch: 6| Step: 2
Training loss: 2.4685240050584487
Validation loss: 2.491603437631061

Epoch: 6| Step: 3
Training loss: 2.8601485076441064
Validation loss: 2.4750652730966403

Epoch: 6| Step: 4
Training loss: 2.2198423463671038
Validation loss: 2.471847967383722

Epoch: 6| Step: 5
Training loss: 2.273793615391579
Validation loss: 2.4779759473414544

Epoch: 6| Step: 6
Training loss: 1.9778306835518231
Validation loss: 2.4701270534374875

Epoch: 6| Step: 7
Training loss: 2.17611346627772
Validation loss: 2.4793356919433163

Epoch: 6| Step: 8
Training loss: 1.8460328145732077
Validation loss: 2.464254408372358

Epoch: 6| Step: 9
Training loss: 2.034489557231466
Validation loss: 2.47969283568546

Epoch: 6| Step: 10
Training loss: 2.782933443623067
Validation loss: 2.4570814803444168

Epoch: 6| Step: 11
Training loss: 2.4714381394961027
Validation loss: 2.4673122364264546

Epoch: 6| Step: 12
Training loss: 2.0577926090237884
Validation loss: 2.4712414333229815

Epoch: 6| Step: 13
Training loss: 1.9531315917857515
Validation loss: 2.480437725281038

Epoch: 228| Step: 0
Training loss: 2.2410934916122915
Validation loss: 2.4984523151015945

Epoch: 6| Step: 1
Training loss: 2.050805431405054
Validation loss: 2.4489038995807477

Epoch: 6| Step: 2
Training loss: 2.6227129100852857
Validation loss: 2.4666972579433777

Epoch: 6| Step: 3
Training loss: 1.8263363034889748
Validation loss: 2.4905325175582815

Epoch: 6| Step: 4
Training loss: 2.4472449713563824
Validation loss: 2.4889286323596793

Epoch: 6| Step: 5
Training loss: 1.867478160500652
Validation loss: 2.476032511307278

Epoch: 6| Step: 6
Training loss: 2.4220090767448568
Validation loss: 2.497290339522558

Epoch: 6| Step: 7
Training loss: 2.457265481867286
Validation loss: 2.4648089631581334

Epoch: 6| Step: 8
Training loss: 2.3570275154627875
Validation loss: 2.4623814375790625

Epoch: 6| Step: 9
Training loss: 1.806369674572345
Validation loss: 2.470070487982797

Epoch: 6| Step: 10
Training loss: 2.6939549662416296
Validation loss: 2.477104817309376

Epoch: 6| Step: 11
Training loss: 2.572088028346138
Validation loss: 2.4754094287870694

Epoch: 6| Step: 12
Training loss: 2.5606299298839303
Validation loss: 2.4964082275770396

Epoch: 6| Step: 13
Training loss: 1.9503006923362725
Validation loss: 2.446013992305771

Epoch: 229| Step: 0
Training loss: 2.2115238342311754
Validation loss: 2.494557348456742

Epoch: 6| Step: 1
Training loss: 2.410899043193673
Validation loss: 2.476160366350996

Epoch: 6| Step: 2
Training loss: 2.1283809468741937
Validation loss: 2.474386748873743

Epoch: 6| Step: 3
Training loss: 2.5541777029208723
Validation loss: 2.504654290667558

Epoch: 6| Step: 4
Training loss: 2.548204601505066
Validation loss: 2.4800075798319092

Epoch: 6| Step: 5
Training loss: 2.473096088262602
Validation loss: 2.471432714373367

Epoch: 6| Step: 6
Training loss: 2.1778434144506833
Validation loss: 2.4812612298415986

Epoch: 6| Step: 7
Training loss: 2.2054500350671593
Validation loss: 2.4714553110202333

Epoch: 6| Step: 8
Training loss: 2.1946209127022303
Validation loss: 2.4297151020920746

Epoch: 6| Step: 9
Training loss: 2.023722624849834
Validation loss: 2.442506680341481

Epoch: 6| Step: 10
Training loss: 2.2619987143218605
Validation loss: 2.4889443926111627

Epoch: 6| Step: 11
Training loss: 2.0506326676085553
Validation loss: 2.4504949284932125

Epoch: 6| Step: 12
Training loss: 2.249567838067758
Validation loss: 2.4936490868329493

Epoch: 6| Step: 13
Training loss: 2.646562210571259
Validation loss: 2.4839032396560756

Epoch: 230| Step: 0
Training loss: 2.1611928263526656
Validation loss: 2.485142816258524

Epoch: 6| Step: 1
Training loss: 2.0713840230839975
Validation loss: 2.468083227356875

Epoch: 6| Step: 2
Training loss: 2.380414713142012
Validation loss: 2.4752822485502226

Epoch: 6| Step: 3
Training loss: 2.414918025740195
Validation loss: 2.4698608949946457

Epoch: 6| Step: 4
Training loss: 1.9504713418043842
Validation loss: 2.490489559140112

Epoch: 6| Step: 5
Training loss: 2.311046865479131
Validation loss: 2.4676715015855923

Epoch: 6| Step: 6
Training loss: 2.261229994281018
Validation loss: 2.4542044610788363

Epoch: 6| Step: 7
Training loss: 1.8386278285368458
Validation loss: 2.4886591404096663

Epoch: 6| Step: 8
Training loss: 2.4511730422058973
Validation loss: 2.488221805925137

Epoch: 6| Step: 9
Training loss: 2.9457049121049477
Validation loss: 2.4803965630304905

Epoch: 6| Step: 10
Training loss: 2.0867154960078524
Validation loss: 2.488030842940888

Epoch: 6| Step: 11
Training loss: 2.28019731872417
Validation loss: 2.487992897531072

Epoch: 6| Step: 12
Training loss: 2.716851283940262
Validation loss: 2.511997392249937

Epoch: 6| Step: 13
Training loss: 1.8598850736695833
Validation loss: 2.489592798062038

Epoch: 231| Step: 0
Training loss: 2.1391901929706156
Validation loss: 2.4661209928677876

Epoch: 6| Step: 1
Training loss: 2.492947166681777
Validation loss: 2.5081888909969323

Epoch: 6| Step: 2
Training loss: 1.8280644202995184
Validation loss: 2.4561307629600826

Epoch: 6| Step: 3
Training loss: 2.990870571916161
Validation loss: 2.4933272844074166

Epoch: 6| Step: 4
Training loss: 2.494355983293648
Validation loss: 2.4413893659110393

Epoch: 6| Step: 5
Training loss: 1.929997901816537
Validation loss: 2.459956938779141

Epoch: 6| Step: 6
Training loss: 1.9620359467412751
Validation loss: 2.4821997326793688

Epoch: 6| Step: 7
Training loss: 2.4833265287404207
Validation loss: 2.4705016750907283

Epoch: 6| Step: 8
Training loss: 2.296367147963729
Validation loss: 2.483337056535087

Epoch: 6| Step: 9
Training loss: 1.9249325133544912
Validation loss: 2.4862020755898024

Epoch: 6| Step: 10
Training loss: 2.516719698399828
Validation loss: 2.4748769857380606

Epoch: 6| Step: 11
Training loss: 2.199130935677414
Validation loss: 2.4611845388285682

Epoch: 6| Step: 12
Training loss: 2.5999117359438353
Validation loss: 2.46898205270001

Epoch: 6| Step: 13
Training loss: 1.9822415274531482
Validation loss: 2.465386512373109

Epoch: 232| Step: 0
Training loss: 2.1983556324153435
Validation loss: 2.4779596207317502

Epoch: 6| Step: 1
Training loss: 2.6908633455516826
Validation loss: 2.4994172729694863

Epoch: 6| Step: 2
Training loss: 2.3192191582442754
Validation loss: 2.454562721389894

Epoch: 6| Step: 3
Training loss: 2.5056854449332215
Validation loss: 2.4510545585589667

Epoch: 6| Step: 4
Training loss: 2.364853517217916
Validation loss: 2.44954044279465

Epoch: 6| Step: 5
Training loss: 2.7805383178891376
Validation loss: 2.472659769920637

Epoch: 6| Step: 6
Training loss: 1.3008470948196207
Validation loss: 2.4824620876629573

Epoch: 6| Step: 7
Training loss: 2.373391459999783
Validation loss: 2.459285310516874

Epoch: 6| Step: 8
Training loss: 2.4640595508042553
Validation loss: 2.481752043546414

Epoch: 6| Step: 9
Training loss: 1.694102897338299
Validation loss: 2.4849844915190364

Epoch: 6| Step: 10
Training loss: 1.9785114676157889
Validation loss: 2.4684485296458414

Epoch: 6| Step: 11
Training loss: 2.545274477324006
Validation loss: 2.5026801806529675

Epoch: 6| Step: 12
Training loss: 2.448154735486856
Validation loss: 2.4896854237769186

Epoch: 6| Step: 13
Training loss: 1.731419562564094
Validation loss: 2.4865547658609657

Epoch: 233| Step: 0
Training loss: 2.136075050149935
Validation loss: 2.425896765210377

Epoch: 6| Step: 1
Training loss: 2.8004746954302004
Validation loss: 2.486405928153358

Epoch: 6| Step: 2
Training loss: 2.188187082560006
Validation loss: 2.477043163438506

Epoch: 6| Step: 3
Training loss: 2.3328733217827837
Validation loss: 2.474537849015783

Epoch: 6| Step: 4
Training loss: 2.007241728286338
Validation loss: 2.4834025285468964

Epoch: 6| Step: 5
Training loss: 2.0043428477083625
Validation loss: 2.4681575236064415

Epoch: 6| Step: 6
Training loss: 2.3053819547607346
Validation loss: 2.465670028228157

Epoch: 6| Step: 7
Training loss: 2.147109852567898
Validation loss: 2.4900090945102833

Epoch: 6| Step: 8
Training loss: 2.1642460383726747
Validation loss: 2.4721699032745934

Epoch: 6| Step: 9
Training loss: 2.2237721945227045
Validation loss: 2.504504446552169

Epoch: 6| Step: 10
Training loss: 2.3373652659053925
Validation loss: 2.497014547846955

Epoch: 6| Step: 11
Training loss: 2.716605469730142
Validation loss: 2.494791017567759

Epoch: 6| Step: 12
Training loss: 2.1706939340108193
Validation loss: 2.483049587217573

Epoch: 6| Step: 13
Training loss: 2.4732029989849664
Validation loss: 2.4951931168891757

Epoch: 234| Step: 0
Training loss: 1.620633420734765
Validation loss: 2.466986579223604

Epoch: 6| Step: 1
Training loss: 2.2929506577357994
Validation loss: 2.4862976013057145

Epoch: 6| Step: 2
Training loss: 2.213910695150343
Validation loss: 2.5024175411820164

Epoch: 6| Step: 3
Training loss: 1.7334159742730861
Validation loss: 2.4948019604279277

Epoch: 6| Step: 4
Training loss: 1.9838237447318103
Validation loss: 2.4626059610195945

Epoch: 6| Step: 5
Training loss: 2.015483525951971
Validation loss: 2.485871406927954

Epoch: 6| Step: 6
Training loss: 2.341294999227347
Validation loss: 2.4647594769219086

Epoch: 6| Step: 7
Training loss: 2.5284476132132285
Validation loss: 2.472487479736788

Epoch: 6| Step: 8
Training loss: 2.7411799739968385
Validation loss: 2.440605969726601

Epoch: 6| Step: 9
Training loss: 2.395012712225894
Validation loss: 2.464740698560458

Epoch: 6| Step: 10
Training loss: 3.1526598765939453
Validation loss: 2.4556478801117985

Epoch: 6| Step: 11
Training loss: 2.377163754662159
Validation loss: 2.464628080516369

Epoch: 6| Step: 12
Training loss: 2.3017940655953906
Validation loss: 2.478040666118546

Epoch: 6| Step: 13
Training loss: 2.4003546691138418
Validation loss: 2.458024040094061

Epoch: 235| Step: 0
Training loss: 2.226343190953778
Validation loss: 2.4876350996877634

Epoch: 6| Step: 1
Training loss: 2.2745719255407177
Validation loss: 2.4743066136918737

Epoch: 6| Step: 2
Training loss: 1.8233639268325104
Validation loss: 2.4633281835271603

Epoch: 6| Step: 3
Training loss: 1.8150860983023611
Validation loss: 2.472562126811579

Epoch: 6| Step: 4
Training loss: 1.782075121990507
Validation loss: 2.489492945489704

Epoch: 6| Step: 5
Training loss: 2.138303068228795
Validation loss: 2.4713248691754086

Epoch: 6| Step: 6
Training loss: 1.8574676989369139
Validation loss: 2.468884600574298

Epoch: 6| Step: 7
Training loss: 2.523309190635466
Validation loss: 2.4857994438856394

Epoch: 6| Step: 8
Training loss: 2.791962384935159
Validation loss: 2.4955222391094756

Epoch: 6| Step: 9
Training loss: 3.179616716426511
Validation loss: 2.483228651561496

Epoch: 6| Step: 10
Training loss: 2.192103637048281
Validation loss: 2.5049361146132623

Epoch: 6| Step: 11
Training loss: 2.0596795882876275
Validation loss: 2.4781215298846413

Epoch: 6| Step: 12
Training loss: 2.2560409406775364
Validation loss: 2.4997977287747792

Epoch: 6| Step: 13
Training loss: 2.6024030181081574
Validation loss: 2.4700816830669794

Epoch: 236| Step: 0
Training loss: 1.667112608696018
Validation loss: 2.487857344044039

Epoch: 6| Step: 1
Training loss: 2.3577659122017867
Validation loss: 2.5110063833330667

Epoch: 6| Step: 2
Training loss: 2.067253415072498
Validation loss: 2.489685882510294

Epoch: 6| Step: 3
Training loss: 2.635586870047476
Validation loss: 2.5229109271806367

Epoch: 6| Step: 4
Training loss: 2.780404294481557
Validation loss: 2.493833583759555

Epoch: 6| Step: 5
Training loss: 2.466508161332172
Validation loss: 2.4979554245003026

Epoch: 6| Step: 6
Training loss: 2.5013967426955035
Validation loss: 2.465832229174468

Epoch: 6| Step: 7
Training loss: 3.165350155135172
Validation loss: 2.53791059365365

Epoch: 6| Step: 8
Training loss: 2.019754954478725
Validation loss: 2.4923888192129025

Epoch: 6| Step: 9
Training loss: 2.1591470026641932
Validation loss: 2.50144155430703

Epoch: 6| Step: 10
Training loss: 1.398875375741665
Validation loss: 2.479103997226832

Epoch: 6| Step: 11
Training loss: 1.9614865571630296
Validation loss: 2.5169192438062034

Epoch: 6| Step: 12
Training loss: 1.8709107630055162
Validation loss: 2.4842313292955804

Epoch: 6| Step: 13
Training loss: 2.376180656500911
Validation loss: 2.455800859779763

Epoch: 237| Step: 0
Training loss: 2.559651722462964
Validation loss: 2.483520573973959

Epoch: 6| Step: 1
Training loss: 2.201187472216257
Validation loss: 2.4748398258422455

Epoch: 6| Step: 2
Training loss: 1.7629848083992687
Validation loss: 2.4817937018708665

Epoch: 6| Step: 3
Training loss: 2.4862671370416733
Validation loss: 2.4865041555651684

Epoch: 6| Step: 4
Training loss: 1.9005336413618787
Validation loss: 2.492182311378828

Epoch: 6| Step: 5
Training loss: 2.410193345636069
Validation loss: 2.4612617410592557

Epoch: 6| Step: 6
Training loss: 2.472307852596734
Validation loss: 2.4424584069319475

Epoch: 6| Step: 7
Training loss: 1.9506451542090273
Validation loss: 2.4939133289534383

Epoch: 6| Step: 8
Training loss: 2.231827784508605
Validation loss: 2.4773020451586807

Epoch: 6| Step: 9
Training loss: 2.389743817058522
Validation loss: 2.4763757085252047

Epoch: 6| Step: 10
Training loss: 2.1433144263130184
Validation loss: 2.4969761763279017

Epoch: 6| Step: 11
Training loss: 2.6246869945105518
Validation loss: 2.4738545986808087

Epoch: 6| Step: 12
Training loss: 2.124015243339079
Validation loss: 2.4626129525506557

Epoch: 6| Step: 13
Training loss: 2.4238739624115646
Validation loss: 2.4959281761069345

Epoch: 238| Step: 0
Training loss: 2.715737438617779
Validation loss: 2.476779011515606

Epoch: 6| Step: 1
Training loss: 2.1001409664978676
Validation loss: 2.465064223050097

Epoch: 6| Step: 2
Training loss: 2.1754987386017293
Validation loss: 2.44504144896122

Epoch: 6| Step: 3
Training loss: 1.9865367258490272
Validation loss: 2.482323519097547

Epoch: 6| Step: 4
Training loss: 2.6420070485057847
Validation loss: 2.4998057771936923

Epoch: 6| Step: 5
Training loss: 2.4582314766510196
Validation loss: 2.478852455231272

Epoch: 6| Step: 6
Training loss: 2.0558983313660173
Validation loss: 2.4974055404822595

Epoch: 6| Step: 7
Training loss: 2.622026394097976
Validation loss: 2.460905505036017

Epoch: 6| Step: 8
Training loss: 2.344047222364829
Validation loss: 2.4935193613341737

Epoch: 6| Step: 9
Training loss: 2.057963613234801
Validation loss: 2.475561627910636

Epoch: 6| Step: 10
Training loss: 1.853505012956153
Validation loss: 2.4868648716470703

Epoch: 6| Step: 11
Training loss: 2.1720441573977705
Validation loss: 2.4825439727749816

Epoch: 6| Step: 12
Training loss: 2.232132860433809
Validation loss: 2.4859370731007844

Epoch: 6| Step: 13
Training loss: 2.471900764263545
Validation loss: 2.492246081602094

Epoch: 239| Step: 0
Training loss: 2.7847824808917028
Validation loss: 2.4837734334840724

Epoch: 6| Step: 1
Training loss: 1.8725903604093312
Validation loss: 2.4640239059825135

Epoch: 6| Step: 2
Training loss: 2.0969382536624326
Validation loss: 2.4715582111143495

Epoch: 6| Step: 3
Training loss: 2.2665236170826044
Validation loss: 2.4925778099057663

Epoch: 6| Step: 4
Training loss: 1.971996234727712
Validation loss: 2.4619471825048076

Epoch: 6| Step: 5
Training loss: 2.667576058616402
Validation loss: 2.491003066151405

Epoch: 6| Step: 6
Training loss: 2.007366323806614
Validation loss: 2.4785236587458215

Epoch: 6| Step: 7
Training loss: 2.162508961212466
Validation loss: 2.4972145108583703

Epoch: 6| Step: 8
Training loss: 2.606821238169859
Validation loss: 2.4822176405068688

Epoch: 6| Step: 9
Training loss: 1.998151163043861
Validation loss: 2.490845284756395

Epoch: 6| Step: 10
Training loss: 1.8829995216778246
Validation loss: 2.4994267411451845

Epoch: 6| Step: 11
Training loss: 2.4327808571621508
Validation loss: 2.4918248517098873

Epoch: 6| Step: 12
Training loss: 2.1179585196635995
Validation loss: 2.4789657311423814

Epoch: 6| Step: 13
Training loss: 2.191438997673374
Validation loss: 2.4858714234285055

Epoch: 240| Step: 0
Training loss: 2.3230145580609025
Validation loss: 2.4331582259946263

Epoch: 6| Step: 1
Training loss: 1.7914884020222062
Validation loss: 2.4856547132670768

Epoch: 6| Step: 2
Training loss: 2.2793185274718657
Validation loss: 2.477593842745648

Epoch: 6| Step: 3
Training loss: 2.9079294581928363
Validation loss: 2.4875328450542233

Epoch: 6| Step: 4
Training loss: 1.8489146554292097
Validation loss: 2.4973815372132324

Epoch: 6| Step: 5
Training loss: 2.2098766787889597
Validation loss: 2.4670959441536655

Epoch: 6| Step: 6
Training loss: 2.401012517017052
Validation loss: 2.470975329551773

Epoch: 6| Step: 7
Training loss: 2.247541143700589
Validation loss: 2.4834925050990715

Epoch: 6| Step: 8
Training loss: 1.9977823718153358
Validation loss: 2.4863936409477194

Epoch: 6| Step: 9
Training loss: 1.932076400186081
Validation loss: 2.503812943196747

Epoch: 6| Step: 10
Training loss: 2.4917868169523842
Validation loss: 2.474814276212655

Epoch: 6| Step: 11
Training loss: 2.134930798840708
Validation loss: 2.48437919056537

Epoch: 6| Step: 12
Training loss: 2.807094210803263
Validation loss: 2.519007175329771

Epoch: 6| Step: 13
Training loss: 2.2339399220952667
Validation loss: 2.4954758223513815

Epoch: 241| Step: 0
Training loss: 1.7946454355184744
Validation loss: 2.4798825437598593

Epoch: 6| Step: 1
Training loss: 2.9265194459468202
Validation loss: 2.439860227475867

Epoch: 6| Step: 2
Training loss: 2.6672740383668585
Validation loss: 2.489341672795292

Epoch: 6| Step: 3
Training loss: 1.5353006775453437
Validation loss: 2.4933830816597027

Epoch: 6| Step: 4
Training loss: 1.8146453525647144
Validation loss: 2.5176211008126854

Epoch: 6| Step: 5
Training loss: 2.141551687318232
Validation loss: 2.481129109927905

Epoch: 6| Step: 6
Training loss: 2.3769275472701987
Validation loss: 2.501172738193468

Epoch: 6| Step: 7
Training loss: 2.5230076662930663
Validation loss: 2.4799395361557957

Epoch: 6| Step: 8
Training loss: 2.1841470362035693
Validation loss: 2.4742701850196434

Epoch: 6| Step: 9
Training loss: 2.259242466248647
Validation loss: 2.4754129375433243

Epoch: 6| Step: 10
Training loss: 2.188203970849608
Validation loss: 2.502029912547609

Epoch: 6| Step: 11
Training loss: 2.1586169092162684
Validation loss: 2.48047715052341

Epoch: 6| Step: 12
Training loss: 2.2053119815859863
Validation loss: 2.4770163774934684

Epoch: 6| Step: 13
Training loss: 2.8868332196202178
Validation loss: 2.4927573061678125

Epoch: 242| Step: 0
Training loss: 2.1351879710727966
Validation loss: 2.4926295012424178

Epoch: 6| Step: 1
Training loss: 2.17553841076387
Validation loss: 2.4597603420990515

Epoch: 6| Step: 2
Training loss: 2.0137767745925026
Validation loss: 2.488814420342588

Epoch: 6| Step: 3
Training loss: 2.6002421192995646
Validation loss: 2.4881536396598305

Epoch: 6| Step: 4
Training loss: 2.067019279711187
Validation loss: 2.446389609084366

Epoch: 6| Step: 5
Training loss: 2.2022804102292564
Validation loss: 2.4433431633271394

Epoch: 6| Step: 6
Training loss: 1.8741278209310117
Validation loss: 2.4341547696981363

Epoch: 6| Step: 7
Training loss: 2.394981852166022
Validation loss: 2.4870170526378934

Epoch: 6| Step: 8
Training loss: 2.492883567107877
Validation loss: 2.480841702525907

Epoch: 6| Step: 9
Training loss: 2.4147440617945763
Validation loss: 2.4842026286256558

Epoch: 6| Step: 10
Training loss: 2.2334532003356595
Validation loss: 2.5103957925455522

Epoch: 6| Step: 11
Training loss: 2.24146155325367
Validation loss: 2.4909644064863783

Epoch: 6| Step: 12
Training loss: 2.258253747398724
Validation loss: 2.4658676981467127

Epoch: 6| Step: 13
Training loss: 2.3588952593608328
Validation loss: 2.4778823593678303

Epoch: 243| Step: 0
Training loss: 2.220930720252245
Validation loss: 2.4942059891823805

Epoch: 6| Step: 1
Training loss: 2.1330153819413464
Validation loss: 2.4794620190800685

Epoch: 6| Step: 2
Training loss: 2.000863484901252
Validation loss: 2.484332187928907

Epoch: 6| Step: 3
Training loss: 1.8068602062505115
Validation loss: 2.471915192538721

Epoch: 6| Step: 4
Training loss: 2.1649447959574992
Validation loss: 2.4533694095682104

Epoch: 6| Step: 5
Training loss: 2.0790282846190067
Validation loss: 2.456486717711072

Epoch: 6| Step: 6
Training loss: 2.947357843674058
Validation loss: 2.495269769312509

Epoch: 6| Step: 7
Training loss: 2.1232532727265587
Validation loss: 2.488988334561682

Epoch: 6| Step: 8
Training loss: 2.4880817519000824
Validation loss: 2.4723287033449397

Epoch: 6| Step: 9
Training loss: 2.493004739633669
Validation loss: 2.4708135435323855

Epoch: 6| Step: 10
Training loss: 2.3474919266404495
Validation loss: 2.4700740629632767

Epoch: 6| Step: 11
Training loss: 2.015744464498113
Validation loss: 2.4769556472258616

Epoch: 6| Step: 12
Training loss: 1.7628124420052398
Validation loss: 2.4890010394932767

Epoch: 6| Step: 13
Training loss: 3.0854361984043406
Validation loss: 2.468536484024807

Epoch: 244| Step: 0
Training loss: 2.2999017196887026
Validation loss: 2.481264596006928

Epoch: 6| Step: 1
Training loss: 1.7581765709130146
Validation loss: 2.501799229270354

Epoch: 6| Step: 2
Training loss: 2.2316831366016956
Validation loss: 2.460945264026318

Epoch: 6| Step: 3
Training loss: 2.4418854021993672
Validation loss: 2.4986471997254127

Epoch: 6| Step: 4
Training loss: 2.0596317808439335
Validation loss: 2.4940757802458866

Epoch: 6| Step: 5
Training loss: 1.3708894582851907
Validation loss: 2.4888298764199783

Epoch: 6| Step: 6
Training loss: 2.1433733817828733
Validation loss: 2.493131720179198

Epoch: 6| Step: 7
Training loss: 3.256696551083979
Validation loss: 2.523439009674341

Epoch: 6| Step: 8
Training loss: 2.458788220836251
Validation loss: 2.4498790644987585

Epoch: 6| Step: 9
Training loss: 1.6725629300308344
Validation loss: 2.431908501787596

Epoch: 6| Step: 10
Training loss: 2.235591957161633
Validation loss: 2.4594804733697972

Epoch: 6| Step: 11
Training loss: 2.73627645592166
Validation loss: 2.4889176265958346

Epoch: 6| Step: 12
Training loss: 2.1124994943832607
Validation loss: 2.5043147231306246

Epoch: 6| Step: 13
Training loss: 2.3934457132348226
Validation loss: 2.4798978818324535

Epoch: 245| Step: 0
Training loss: 1.9188624395670475
Validation loss: 2.457980047306389

Epoch: 6| Step: 1
Training loss: 2.3909786187224653
Validation loss: 2.5017867112745105

Epoch: 6| Step: 2
Training loss: 1.9359376822680125
Validation loss: 2.4546087514667465

Epoch: 6| Step: 3
Training loss: 2.0742324282667526
Validation loss: 2.4523211676806143

Epoch: 6| Step: 4
Training loss: 2.13458681186579
Validation loss: 2.4779284073397063

Epoch: 6| Step: 5
Training loss: 2.5996098335661224
Validation loss: 2.47605466218057

Epoch: 6| Step: 6
Training loss: 1.5441034321705016
Validation loss: 2.4790369546043434

Epoch: 6| Step: 7
Training loss: 2.6188027023802576
Validation loss: 2.511339441739372

Epoch: 6| Step: 8
Training loss: 2.5229300824372243
Validation loss: 2.4531074660723355

Epoch: 6| Step: 9
Training loss: 2.777073242062327
Validation loss: 2.474025656923435

Epoch: 6| Step: 10
Training loss: 2.653374046256144
Validation loss: 2.4891638165280576

Epoch: 6| Step: 11
Training loss: 1.9545633131747715
Validation loss: 2.486815635915384

Epoch: 6| Step: 12
Training loss: 2.0013580479901347
Validation loss: 2.4616902965884204

Epoch: 6| Step: 13
Training loss: 2.239038788589394
Validation loss: 2.506700479466048

Epoch: 246| Step: 0
Training loss: 2.5914953152678426
Validation loss: 2.459578342920238

Epoch: 6| Step: 1
Training loss: 2.1251709813163506
Validation loss: 2.5061286775998033

Epoch: 6| Step: 2
Training loss: 1.9132800935965268
Validation loss: 2.465410338419754

Epoch: 6| Step: 3
Training loss: 2.0932261252841906
Validation loss: 2.4832217851791234

Epoch: 6| Step: 4
Training loss: 1.9743000093801788
Validation loss: 2.488420644783516

Epoch: 6| Step: 5
Training loss: 2.367679960184624
Validation loss: 2.4613742506570695

Epoch: 6| Step: 6
Training loss: 2.9673953529423853
Validation loss: 2.493640730168841

Epoch: 6| Step: 7
Training loss: 2.198831148021827
Validation loss: 2.4682755227847712

Epoch: 6| Step: 8
Training loss: 2.036800137947
Validation loss: 2.47780476554405

Epoch: 6| Step: 9
Training loss: 1.7955969868116959
Validation loss: 2.4936036154882006

Epoch: 6| Step: 10
Training loss: 2.878719411762834
Validation loss: 2.477721825191754

Epoch: 6| Step: 11
Training loss: 1.6635102981097274
Validation loss: 2.434039647451302

Epoch: 6| Step: 12
Training loss: 2.1417487320471524
Validation loss: 2.467245797118861

Epoch: 6| Step: 13
Training loss: 2.518119380941818
Validation loss: 2.468862182884567

Epoch: 247| Step: 0
Training loss: 1.4792446420381367
Validation loss: 2.4994082047805852

Epoch: 6| Step: 1
Training loss: 2.187107377920927
Validation loss: 2.4605486673151984

Epoch: 6| Step: 2
Training loss: 2.1450428170152254
Validation loss: 2.4481182642867996

Epoch: 6| Step: 3
Training loss: 2.241784142555921
Validation loss: 2.4802387870247524

Epoch: 6| Step: 4
Training loss: 2.0984550106087747
Validation loss: 2.4586192973316674

Epoch: 6| Step: 5
Training loss: 2.1782661644002994
Validation loss: 2.475396180805389

Epoch: 6| Step: 6
Training loss: 2.775308327256691
Validation loss: 2.4449078656473864

Epoch: 6| Step: 7
Training loss: 2.744828389819095
Validation loss: 2.4764614538140552

Epoch: 6| Step: 8
Training loss: 2.283857762425607
Validation loss: 2.470835213075208

Epoch: 6| Step: 9
Training loss: 2.3498600979006836
Validation loss: 2.4735663688436533

Epoch: 6| Step: 10
Training loss: 1.5489290259880268
Validation loss: 2.480362240306247

Epoch: 6| Step: 11
Training loss: 2.0367848036238865
Validation loss: 2.504801794308783

Epoch: 6| Step: 12
Training loss: 2.957647342574762
Validation loss: 2.486479967670006

Epoch: 6| Step: 13
Training loss: 1.401934125574362
Validation loss: 2.4810786214440874

Epoch: 248| Step: 0
Training loss: 2.6947311880203744
Validation loss: 2.4790021208041844

Epoch: 6| Step: 1
Training loss: 1.9015011027571405
Validation loss: 2.4893440110614256

Epoch: 6| Step: 2
Training loss: 2.8523449803989402
Validation loss: 2.491768884271802

Epoch: 6| Step: 3
Training loss: 2.742813690939796
Validation loss: 2.5044371779670533

Epoch: 6| Step: 4
Training loss: 1.614361786767966
Validation loss: 2.483810428761393

Epoch: 6| Step: 5
Training loss: 1.3513533590276083
Validation loss: 2.480555099988056

Epoch: 6| Step: 6
Training loss: 2.9664369908554153
Validation loss: 2.4827779893328743

Epoch: 6| Step: 7
Training loss: 1.8449724961378495
Validation loss: 2.463985552369135

Epoch: 6| Step: 8
Training loss: 2.045828049206821
Validation loss: 2.4775458587474755

Epoch: 6| Step: 9
Training loss: 2.042333675602197
Validation loss: 2.4697711723068534

Epoch: 6| Step: 10
Training loss: 2.067083410063008
Validation loss: 2.4595186272705813

Epoch: 6| Step: 11
Training loss: 2.3237786397251505
Validation loss: 2.4663055299259975

Epoch: 6| Step: 12
Training loss: 2.1947933139683196
Validation loss: 2.4834205577711796

Epoch: 6| Step: 13
Training loss: 2.008774107792535
Validation loss: 2.470380434462142

Epoch: 249| Step: 0
Training loss: 2.0116362619617525
Validation loss: 2.4126066751011823

Epoch: 6| Step: 1
Training loss: 2.5634018776322955
Validation loss: 2.483019581269834

Epoch: 6| Step: 2
Training loss: 2.596231950633783
Validation loss: 2.490424726378394

Epoch: 6| Step: 3
Training loss: 1.9258680343417778
Validation loss: 2.438297869481658

Epoch: 6| Step: 4
Training loss: 1.8179668982233665
Validation loss: 2.4666085405853932

Epoch: 6| Step: 5
Training loss: 2.2150072579017372
Validation loss: 2.4792834266749173

Epoch: 6| Step: 6
Training loss: 2.69273939182415
Validation loss: 2.4940259321233795

Epoch: 6| Step: 7
Training loss: 1.9589941722438522
Validation loss: 2.4927658853637604

Epoch: 6| Step: 8
Training loss: 2.0882419615309624
Validation loss: 2.507166819778238

Epoch: 6| Step: 9
Training loss: 1.8085843903729872
Validation loss: 2.5224402236908996

Epoch: 6| Step: 10
Training loss: 2.2817888015519086
Validation loss: 2.485233911959964

Epoch: 6| Step: 11
Training loss: 2.386341920563946
Validation loss: 2.5095088500038556

Epoch: 6| Step: 12
Training loss: 2.454940609961369
Validation loss: 2.484689022068711

Epoch: 6| Step: 13
Training loss: 2.8795314405009536
Validation loss: 2.5148763947187307

Epoch: 250| Step: 0
Training loss: 2.1106509270401466
Validation loss: 2.498550284908413

Epoch: 6| Step: 1
Training loss: 2.413394576326565
Validation loss: 2.513460772643135

Epoch: 6| Step: 2
Training loss: 1.9741759234826364
Validation loss: 2.5266168076404405

Epoch: 6| Step: 3
Training loss: 1.792326502576916
Validation loss: 2.485199838630319

Epoch: 6| Step: 4
Training loss: 2.0427061535792674
Validation loss: 2.4703966689909462

Epoch: 6| Step: 5
Training loss: 2.1490888128518333
Validation loss: 2.480909914694272

Epoch: 6| Step: 6
Training loss: 2.621433287230601
Validation loss: 2.500743210977015

Epoch: 6| Step: 7
Training loss: 1.6577477790358566
Validation loss: 2.469534408089216

Epoch: 6| Step: 8
Training loss: 1.960660694540389
Validation loss: 2.4755945492787794

Epoch: 6| Step: 9
Training loss: 2.3606696208506968
Validation loss: 2.485148432210959

Epoch: 6| Step: 10
Training loss: 2.7209966738062628
Validation loss: 2.465979466361845

Epoch: 6| Step: 11
Training loss: 2.150359358807099
Validation loss: 2.4927595085619174

Epoch: 6| Step: 12
Training loss: 2.974764704014502
Validation loss: 2.483159217737365

Epoch: 6| Step: 13
Training loss: 2.049783518456078
Validation loss: 2.492763853180959

Epoch: 251| Step: 0
Training loss: 1.7802142427933052
Validation loss: 2.489457505727242

Epoch: 6| Step: 1
Training loss: 2.7281850452085648
Validation loss: 2.493087436853299

Epoch: 6| Step: 2
Training loss: 1.8249742793530799
Validation loss: 2.4806769387906273

Epoch: 6| Step: 3
Training loss: 2.2630126625209104
Validation loss: 2.4871948640009625

Epoch: 6| Step: 4
Training loss: 1.996255468696647
Validation loss: 2.475657641346541

Epoch: 6| Step: 5
Training loss: 2.1778313722092464
Validation loss: 2.4845645332027217

Epoch: 6| Step: 6
Training loss: 1.8717444449161817
Validation loss: 2.491496488166309

Epoch: 6| Step: 7
Training loss: 2.9952181216690232
Validation loss: 2.4583289527193575

Epoch: 6| Step: 8
Training loss: 2.057923296448967
Validation loss: 2.489822523115639

Epoch: 6| Step: 9
Training loss: 2.0999663577336856
Validation loss: 2.4487971418751653

Epoch: 6| Step: 10
Training loss: 2.8334829253555154
Validation loss: 2.449677454108758

Epoch: 6| Step: 11
Training loss: 1.8301861221219184
Validation loss: 2.473374523109203

Epoch: 6| Step: 12
Training loss: 1.902300636382599
Validation loss: 2.438336852670303

Epoch: 6| Step: 13
Training loss: 2.579477406292832
Validation loss: 2.452687908208073

Epoch: 252| Step: 0
Training loss: 2.687561655446243
Validation loss: 2.439018344560269

Epoch: 6| Step: 1
Training loss: 2.5967710435168345
Validation loss: 2.4730800725581346

Epoch: 6| Step: 2
Training loss: 2.216409550241804
Validation loss: 2.490740564041195

Epoch: 6| Step: 3
Training loss: 2.2514485888286297
Validation loss: 2.478062710071432

Epoch: 6| Step: 4
Training loss: 2.4007890834612278
Validation loss: 2.468479777747753

Epoch: 6| Step: 5
Training loss: 2.3474515041749267
Validation loss: 2.4720911283748266

Epoch: 6| Step: 6
Training loss: 2.112799005960435
Validation loss: 2.4881622017585237

Epoch: 6| Step: 7
Training loss: 2.115353173242328
Validation loss: 2.484454721688732

Epoch: 6| Step: 8
Training loss: 2.071215162887855
Validation loss: 2.4838009691782887

Epoch: 6| Step: 9
Training loss: 2.0128250191329857
Validation loss: 2.480545627990726

Epoch: 6| Step: 10
Training loss: 1.7054069001065495
Validation loss: 2.511097669917873

Epoch: 6| Step: 11
Training loss: 2.4218072697182484
Validation loss: 2.460787683247587

Epoch: 6| Step: 12
Training loss: 1.89517880413993
Validation loss: 2.495819385349964

Epoch: 6| Step: 13
Training loss: 2.3311300661055614
Validation loss: 2.4820520111539532

Epoch: 253| Step: 0
Training loss: 2.6208208513392237
Validation loss: 2.467345346311435

Epoch: 6| Step: 1
Training loss: 1.923465039995804
Validation loss: 2.48691479320911

Epoch: 6| Step: 2
Training loss: 2.1604136198114916
Validation loss: 2.4967621837719927

Epoch: 6| Step: 3
Training loss: 1.9244446981506729
Validation loss: 2.4733659305496913

Epoch: 6| Step: 4
Training loss: 2.594813668795708
Validation loss: 2.485094262086202

Epoch: 6| Step: 5
Training loss: 1.9454971899886317
Validation loss: 2.5030480886878252

Epoch: 6| Step: 6
Training loss: 2.48459686632153
Validation loss: 2.4940091904549653

Epoch: 6| Step: 7
Training loss: 1.93407062853635
Validation loss: 2.518750641187434

Epoch: 6| Step: 8
Training loss: 2.304174851120755
Validation loss: 2.4641902523955372

Epoch: 6| Step: 9
Training loss: 1.6728629642416464
Validation loss: 2.4897777773029732

Epoch: 6| Step: 10
Training loss: 2.1840249934041425
Validation loss: 2.4997819641360417

Epoch: 6| Step: 11
Training loss: 2.437728577680198
Validation loss: 2.4641328177091704

Epoch: 6| Step: 12
Training loss: 2.418084704156289
Validation loss: 2.4937702514605795

Epoch: 6| Step: 13
Training loss: 2.746966422754468
Validation loss: 2.475342029253753

Epoch: 254| Step: 0
Training loss: 2.6504648376734616
Validation loss: 2.468281070654504

Epoch: 6| Step: 1
Training loss: 1.7190695032179242
Validation loss: 2.4772160267784753

Epoch: 6| Step: 2
Training loss: 2.234094028546572
Validation loss: 2.4737589468969836

Epoch: 6| Step: 3
Training loss: 1.9543913131242867
Validation loss: 2.4951628598680626

Epoch: 6| Step: 4
Training loss: 2.850444250450578
Validation loss: 2.474903541053383

Epoch: 6| Step: 5
Training loss: 2.337359247712823
Validation loss: 2.460371651861602

Epoch: 6| Step: 6
Training loss: 2.1577685993211952
Validation loss: 2.4580240108909543

Epoch: 6| Step: 7
Training loss: 1.9208491619172325
Validation loss: 2.460318646128166

Epoch: 6| Step: 8
Training loss: 2.5025912207441614
Validation loss: 2.4894851278702657

Epoch: 6| Step: 9
Training loss: 1.9591405773927235
Validation loss: 2.4813788455791377

Epoch: 6| Step: 10
Training loss: 1.3986498708740802
Validation loss: 2.436915150523226

Epoch: 6| Step: 11
Training loss: 2.451304057535298
Validation loss: 2.4387453745599137

Epoch: 6| Step: 12
Training loss: 2.2389703192573003
Validation loss: 2.488672313667967

Epoch: 6| Step: 13
Training loss: 2.506584270759892
Validation loss: 2.501809156726126

Epoch: 255| Step: 0
Training loss: 2.035522193737098
Validation loss: 2.46259038199312

Epoch: 6| Step: 1
Training loss: 2.3723304200741677
Validation loss: 2.520361999066731

Epoch: 6| Step: 2
Training loss: 1.731727159757294
Validation loss: 2.492924458390521

Epoch: 6| Step: 3
Training loss: 2.1546253220270835
Validation loss: 2.4892391339836184

Epoch: 6| Step: 4
Training loss: 2.0651945372567417
Validation loss: 2.479711355045019

Epoch: 6| Step: 5
Training loss: 3.1157734275977167
Validation loss: 2.479379051964524

Epoch: 6| Step: 6
Training loss: 1.8972841377760967
Validation loss: 2.476000408030567

Epoch: 6| Step: 7
Training loss: 2.0654777070363552
Validation loss: 2.4428678042858105

Epoch: 6| Step: 8
Training loss: 2.3101165448138237
Validation loss: 2.471742525817748

Epoch: 6| Step: 9
Training loss: 1.977919764666652
Validation loss: 2.5111670841540574

Epoch: 6| Step: 10
Training loss: 2.1290181261816694
Validation loss: 2.4605115640072204

Epoch: 6| Step: 11
Training loss: 2.142486987614148
Validation loss: 2.4497449140622902

Epoch: 6| Step: 12
Training loss: 2.545827357591607
Validation loss: 2.485980901147656

Epoch: 6| Step: 13
Training loss: 2.167732184622738
Validation loss: 2.5025367377306083

Epoch: 256| Step: 0
Training loss: 2.143677032385533
Validation loss: 2.4777655709295208

Epoch: 6| Step: 1
Training loss: 2.1873916599147822
Validation loss: 2.4606426056467843

Epoch: 6| Step: 2
Training loss: 1.967736543446783
Validation loss: 2.47350613790437

Epoch: 6| Step: 3
Training loss: 2.2875521627846953
Validation loss: 2.4690847558006417

Epoch: 6| Step: 4
Training loss: 2.219233930224695
Validation loss: 2.4642896087659194

Epoch: 6| Step: 5
Training loss: 2.633508878804093
Validation loss: 2.5055444468182766

Epoch: 6| Step: 6
Training loss: 2.4008104346773433
Validation loss: 2.4987579562326823

Epoch: 6| Step: 7
Training loss: 2.3930560946363992
Validation loss: 2.4884640406993603

Epoch: 6| Step: 8
Training loss: 2.1641732197886205
Validation loss: 2.482094228898592

Epoch: 6| Step: 9
Training loss: 2.2654546213212634
Validation loss: 2.5035832480091567

Epoch: 6| Step: 10
Training loss: 1.630692268993008
Validation loss: 2.4688613864396713

Epoch: 6| Step: 11
Training loss: 2.1055035137073816
Validation loss: 2.5108067815266173

Epoch: 6| Step: 12
Training loss: 2.4716191097870936
Validation loss: 2.4933821362502195

Epoch: 6| Step: 13
Training loss: 1.9437603254135982
Validation loss: 2.525383654996738

Epoch: 257| Step: 0
Training loss: 1.9276322141591131
Validation loss: 2.4756855696823457

Epoch: 6| Step: 1
Training loss: 2.2019019012150527
Validation loss: 2.502504532932965

Epoch: 6| Step: 2
Training loss: 2.048851282154344
Validation loss: 2.4867564998438962

Epoch: 6| Step: 3
Training loss: 2.197438795259411
Validation loss: 2.4844305066175325

Epoch: 6| Step: 4
Training loss: 2.275547791648243
Validation loss: 2.4950634033411854

Epoch: 6| Step: 5
Training loss: 2.285708629652246
Validation loss: 2.5098813590431743

Epoch: 6| Step: 6
Training loss: 2.347953688683071
Validation loss: 2.496800196129803

Epoch: 6| Step: 7
Training loss: 2.5700835615889623
Validation loss: 2.5137765776557037

Epoch: 6| Step: 8
Training loss: 2.2468682852738895
Validation loss: 2.481006253824403

Epoch: 6| Step: 9
Training loss: 1.7816278826444614
Validation loss: 2.443985639682313

Epoch: 6| Step: 10
Training loss: 2.1010337646618207
Validation loss: 2.4753488765849174

Epoch: 6| Step: 11
Training loss: 2.344114148143466
Validation loss: 2.5224303479584296

Epoch: 6| Step: 12
Training loss: 2.174899294045474
Validation loss: 2.448565346658181

Epoch: 6| Step: 13
Training loss: 2.51500120781022
Validation loss: 2.4678795493506716

Epoch: 258| Step: 0
Training loss: 2.6547839438537557
Validation loss: 2.495138677823935

Epoch: 6| Step: 1
Training loss: 2.382574651135028
Validation loss: 2.4637941634625813

Epoch: 6| Step: 2
Training loss: 1.9790476980759624
Validation loss: 2.466445978566912

Epoch: 6| Step: 3
Training loss: 1.6080471597891894
Validation loss: 2.4431438236698573

Epoch: 6| Step: 4
Training loss: 2.177858084000289
Validation loss: 2.485439933677095

Epoch: 6| Step: 5
Training loss: 2.880271556820265
Validation loss: 2.4927418518164592

Epoch: 6| Step: 6
Training loss: 2.1862732853639084
Validation loss: 2.468212862098129

Epoch: 6| Step: 7
Training loss: 2.090559849201467
Validation loss: 2.4852277144056543

Epoch: 6| Step: 8
Training loss: 2.49173074680291
Validation loss: 2.4781672108234587

Epoch: 6| Step: 9
Training loss: 1.7326580862826257
Validation loss: 2.486307779349125

Epoch: 6| Step: 10
Training loss: 1.9876495736898159
Validation loss: 2.4525222562974403

Epoch: 6| Step: 11
Training loss: 2.1234816568371455
Validation loss: 2.461291045930728

Epoch: 6| Step: 12
Training loss: 2.2682962389437145
Validation loss: 2.475997728424565

Epoch: 6| Step: 13
Training loss: 2.11539645291731
Validation loss: 2.4818620531463065

Epoch: 259| Step: 0
Training loss: 2.18558352851302
Validation loss: 2.4602503288372835

Epoch: 6| Step: 1
Training loss: 2.2587317473070425
Validation loss: 2.50222844509601

Epoch: 6| Step: 2
Training loss: 2.2601703093507153
Validation loss: 2.4790469349501074

Epoch: 6| Step: 3
Training loss: 2.041917577882845
Validation loss: 2.49334739233157

Epoch: 6| Step: 4
Training loss: 2.031897456345129
Validation loss: 2.472915051894776

Epoch: 6| Step: 5
Training loss: 1.6529653836299052
Validation loss: 2.4627111410733944

Epoch: 6| Step: 6
Training loss: 2.218342058530979
Validation loss: 2.497434964522968

Epoch: 6| Step: 7
Training loss: 2.7187763958230584
Validation loss: 2.4824053514642164

Epoch: 6| Step: 8
Training loss: 2.321607645694439
Validation loss: 2.5205796481157154

Epoch: 6| Step: 9
Training loss: 2.193879117725249
Validation loss: 2.510040374141565

Epoch: 6| Step: 10
Training loss: 2.1528510241883048
Validation loss: 2.5140307120980605

Epoch: 6| Step: 11
Training loss: 1.9399428810480803
Validation loss: 2.484769736019609

Epoch: 6| Step: 12
Training loss: 2.869652127971488
Validation loss: 2.4779472016353905

Epoch: 6| Step: 13
Training loss: 2.16871775842276
Validation loss: 2.4776209576964865

Epoch: 260| Step: 0
Training loss: 2.3138007552372617
Validation loss: 2.494485309177883

Epoch: 6| Step: 1
Training loss: 1.9072246248750078
Validation loss: 2.4391394366632313

Epoch: 6| Step: 2
Training loss: 2.1382794303175485
Validation loss: 2.4635064039004897

Epoch: 6| Step: 3
Training loss: 2.484217032922566
Validation loss: 2.474344570059196

Epoch: 6| Step: 4
Training loss: 2.428261390498296
Validation loss: 2.4866985636709167

Epoch: 6| Step: 5
Training loss: 1.9540582487156772
Validation loss: 2.4937922355280002

Epoch: 6| Step: 6
Training loss: 2.4845267195528646
Validation loss: 2.4911153079253956

Epoch: 6| Step: 7
Training loss: 1.7086367531498547
Validation loss: 2.4694314968537268

Epoch: 6| Step: 8
Training loss: 2.3581264805024507
Validation loss: 2.469503550169704

Epoch: 6| Step: 9
Training loss: 2.567037333521251
Validation loss: 2.515790910038863

Epoch: 6| Step: 10
Training loss: 2.4867238391341164
Validation loss: 2.498404669628525

Epoch: 6| Step: 11
Training loss: 2.1508835063976064
Validation loss: 2.475258240993853

Epoch: 6| Step: 12
Training loss: 2.1181112716378494
Validation loss: 2.5129201415008087

Epoch: 6| Step: 13
Training loss: 1.369054075980114
Validation loss: 2.498128468363723

Epoch: 261| Step: 0
Training loss: 1.87551230743202
Validation loss: 2.4869208674960284

Epoch: 6| Step: 1
Training loss: 2.313819302716831
Validation loss: 2.4854789773592443

Epoch: 6| Step: 2
Training loss: 2.577145292071309
Validation loss: 2.51066333524099

Epoch: 6| Step: 3
Training loss: 2.135628765706847
Validation loss: 2.4713381898120805

Epoch: 6| Step: 4
Training loss: 2.369148273251257
Validation loss: 2.489396921919951

Epoch: 6| Step: 5
Training loss: 1.8407461621960608
Validation loss: 2.512857892169617

Epoch: 6| Step: 6
Training loss: 2.594077583676293
Validation loss: 2.4990496398016067

Epoch: 6| Step: 7
Training loss: 2.4271910374746897
Validation loss: 2.4873597669759384

Epoch: 6| Step: 8
Training loss: 2.4261096971559795
Validation loss: 2.4739217672360474

Epoch: 6| Step: 9
Training loss: 1.82039029851519
Validation loss: 2.516841093352235

Epoch: 6| Step: 10
Training loss: 1.8792400737671318
Validation loss: 2.4627243719328344

Epoch: 6| Step: 11
Training loss: 2.144352250541374
Validation loss: 2.458988751666204

Epoch: 6| Step: 12
Training loss: 2.229241188681304
Validation loss: 2.4723585367807637

Epoch: 6| Step: 13
Training loss: 2.1132585732306315
Validation loss: 2.4710703535254486

Epoch: 262| Step: 0
Training loss: 2.3915946838853204
Validation loss: 2.490203340173337

Epoch: 6| Step: 1
Training loss: 2.5025644500999964
Validation loss: 2.4812233224545692

Epoch: 6| Step: 2
Training loss: 1.9114542726340198
Validation loss: 2.503120999933918

Epoch: 6| Step: 3
Training loss: 1.9453468166526366
Validation loss: 2.490479425979881

Epoch: 6| Step: 4
Training loss: 2.31728414589918
Validation loss: 2.4580824821161618

Epoch: 6| Step: 5
Training loss: 1.9570078591416509
Validation loss: 2.4636073914221126

Epoch: 6| Step: 6
Training loss: 2.360349239274043
Validation loss: 2.488398376305558

Epoch: 6| Step: 7
Training loss: 2.456247856779838
Validation loss: 2.4791438293921826

Epoch: 6| Step: 8
Training loss: 2.371115871370243
Validation loss: 2.4950966710341085

Epoch: 6| Step: 9
Training loss: 2.0501145214564054
Validation loss: 2.4521317570149064

Epoch: 6| Step: 10
Training loss: 1.8611929204936097
Validation loss: 2.4608549474987775

Epoch: 6| Step: 11
Training loss: 2.147904652495012
Validation loss: 2.4828114087336086

Epoch: 6| Step: 12
Training loss: 1.8069490076753996
Validation loss: 2.477002532644911

Epoch: 6| Step: 13
Training loss: 2.9312565785153226
Validation loss: 2.442816940598459

Epoch: 263| Step: 0
Training loss: 2.192175310336187
Validation loss: 2.4824315432828707

Epoch: 6| Step: 1
Training loss: 2.56152250673115
Validation loss: 2.481236617847618

Epoch: 6| Step: 2
Training loss: 1.9088211854702304
Validation loss: 2.4747806799310084

Epoch: 6| Step: 3
Training loss: 2.379847548594914
Validation loss: 2.472759308506237

Epoch: 6| Step: 4
Training loss: 2.0769025605973477
Validation loss: 2.496338088186536

Epoch: 6| Step: 5
Training loss: 2.523145818239381
Validation loss: 2.459429451869614

Epoch: 6| Step: 6
Training loss: 2.5828486777539434
Validation loss: 2.4751153632530367

Epoch: 6| Step: 7
Training loss: 1.9543178730304944
Validation loss: 2.5101999332163034

Epoch: 6| Step: 8
Training loss: 1.990031433240602
Validation loss: 2.47872988654434

Epoch: 6| Step: 9
Training loss: 1.8034833713925067
Validation loss: 2.4819731031695422

Epoch: 6| Step: 10
Training loss: 1.6878124936716001
Validation loss: 2.48854096529398

Epoch: 6| Step: 11
Training loss: 1.9904154956226712
Validation loss: 2.5149449503313503

Epoch: 6| Step: 12
Training loss: 2.6606154528628703
Validation loss: 2.4648013007509446

Epoch: 6| Step: 13
Training loss: 2.383949583806995
Validation loss: 2.4877983973545112

Epoch: 264| Step: 0
Training loss: 1.9192530416822562
Validation loss: 2.437387131990371

Epoch: 6| Step: 1
Training loss: 1.6994600672753897
Validation loss: 2.481089902733033

Epoch: 6| Step: 2
Training loss: 2.4393377956374933
Validation loss: 2.460402560752165

Epoch: 6| Step: 3
Training loss: 1.8755227949546578
Validation loss: 2.477098501097548

Epoch: 6| Step: 4
Training loss: 2.058452680991324
Validation loss: 2.5103244743290793

Epoch: 6| Step: 5
Training loss: 2.139221733859637
Validation loss: 2.4820752439389615

Epoch: 6| Step: 6
Training loss: 2.3328285579550303
Validation loss: 2.478624399521639

Epoch: 6| Step: 7
Training loss: 3.035318063475385
Validation loss: 2.489870211832993

Epoch: 6| Step: 8
Training loss: 2.724836180076144
Validation loss: 2.471167858468931

Epoch: 6| Step: 9
Training loss: 2.4129335794551627
Validation loss: 2.481722772391128

Epoch: 6| Step: 10
Training loss: 1.8375874998058592
Validation loss: 2.479132734690214

Epoch: 6| Step: 11
Training loss: 1.518425546533514
Validation loss: 2.461792612421928

Epoch: 6| Step: 12
Training loss: 1.7092007396518742
Validation loss: 2.4676430067307127

Epoch: 6| Step: 13
Training loss: 2.2870025218888004
Validation loss: 2.4514760806731446

Epoch: 265| Step: 0
Training loss: 2.378951850541756
Validation loss: 2.4847245953611092

Epoch: 6| Step: 1
Training loss: 2.058119543712993
Validation loss: 2.521894677135178

Epoch: 6| Step: 2
Training loss: 1.5348922851990938
Validation loss: 2.4704224827513164

Epoch: 6| Step: 3
Training loss: 2.411200447107285
Validation loss: 2.4552180673189614

Epoch: 6| Step: 4
Training loss: 2.4232916841596546
Validation loss: 2.511543268944051

Epoch: 6| Step: 5
Training loss: 1.757826198948357
Validation loss: 2.4404300415142277

Epoch: 6| Step: 6
Training loss: 1.7075815950393238
Validation loss: 2.49816463327951

Epoch: 6| Step: 7
Training loss: 2.5784950684327725
Validation loss: 2.491457878345512

Epoch: 6| Step: 8
Training loss: 2.323002857838719
Validation loss: 2.5149525511965343

Epoch: 6| Step: 9
Training loss: 2.5653768997947433
Validation loss: 2.4847985869620857

Epoch: 6| Step: 10
Training loss: 2.4894166089870504
Validation loss: 2.4930664635678985

Epoch: 6| Step: 11
Training loss: 2.3058303327119267
Validation loss: 2.4580614802773746

Epoch: 6| Step: 12
Training loss: 2.006139392121125
Validation loss: 2.5077869668398756

Epoch: 6| Step: 13
Training loss: 1.9890063449457307
Validation loss: 2.4577062532489697

Epoch: 266| Step: 0
Training loss: 2.4597240544441625
Validation loss: 2.471976514879948

Epoch: 6| Step: 1
Training loss: 1.9739411956392097
Validation loss: 2.453277187095616

Epoch: 6| Step: 2
Training loss: 3.2098336283032984
Validation loss: 2.4498335933112365

Epoch: 6| Step: 3
Training loss: 1.953110839792419
Validation loss: 2.450220061567564

Epoch: 6| Step: 4
Training loss: 1.674971164625974
Validation loss: 2.501133156403587

Epoch: 6| Step: 5
Training loss: 2.360018711824106
Validation loss: 2.4856050273402013

Epoch: 6| Step: 6
Training loss: 2.4570075732911287
Validation loss: 2.4490301503755645

Epoch: 6| Step: 7
Training loss: 2.254533650627447
Validation loss: 2.4675361636784743

Epoch: 6| Step: 8
Training loss: 2.1276150488759975
Validation loss: 2.4536818340081306

Epoch: 6| Step: 9
Training loss: 2.0637394042179182
Validation loss: 2.4731303387165546

Epoch: 6| Step: 10
Training loss: 2.1298944542036264
Validation loss: 2.454977956193822

Epoch: 6| Step: 11
Training loss: 2.1848064733213097
Validation loss: 2.4720420005116965

Epoch: 6| Step: 12
Training loss: 1.1629424370963128
Validation loss: 2.49812631226512

Epoch: 6| Step: 13
Training loss: 2.2510915863371985
Validation loss: 2.4674714561380933

Epoch: 267| Step: 0
Training loss: 1.9668003298171308
Validation loss: 2.50700320533444

Epoch: 6| Step: 1
Training loss: 2.1108554872157725
Validation loss: 2.5186826039351504

Epoch: 6| Step: 2
Training loss: 1.9257571700565708
Validation loss: 2.4769814769834526

Epoch: 6| Step: 3
Training loss: 2.2595815097248817
Validation loss: 2.4619277703998357

Epoch: 6| Step: 4
Training loss: 1.8565174231252326
Validation loss: 2.4987279834830125

Epoch: 6| Step: 5
Training loss: 1.9940911865083988
Validation loss: 2.491429614379657

Epoch: 6| Step: 6
Training loss: 1.9917025106654886
Validation loss: 2.494663683703117

Epoch: 6| Step: 7
Training loss: 2.2868822149479335
Validation loss: 2.5152908589386254

Epoch: 6| Step: 8
Training loss: 2.1418904371904692
Validation loss: 2.4359658069430465

Epoch: 6| Step: 9
Training loss: 1.8332321688165782
Validation loss: 2.434417199210017

Epoch: 6| Step: 10
Training loss: 2.830393855856895
Validation loss: 2.4510391968821437

Epoch: 6| Step: 11
Training loss: 1.9922345324181647
Validation loss: 2.4543461181955464

Epoch: 6| Step: 12
Training loss: 2.6939465586028075
Validation loss: 2.4853029928069668

Epoch: 6| Step: 13
Training loss: 2.65307481266716
Validation loss: 2.4731699353860686

Epoch: 268| Step: 0
Training loss: 2.639806948018896
Validation loss: 2.495506862491848

Epoch: 6| Step: 1
Training loss: 2.377133665853065
Validation loss: 2.482814908578091

Epoch: 6| Step: 2
Training loss: 2.2353611617175937
Validation loss: 2.4576161577529616

Epoch: 6| Step: 3
Training loss: 2.02271461093201
Validation loss: 2.488170129143488

Epoch: 6| Step: 4
Training loss: 2.4755398055674593
Validation loss: 2.4622028119653248

Epoch: 6| Step: 5
Training loss: 2.6488006252835343
Validation loss: 2.4644053760850726

Epoch: 6| Step: 6
Training loss: 1.8883957133324696
Validation loss: 2.4790626328947836

Epoch: 6| Step: 7
Training loss: 1.9268757338867373
Validation loss: 2.493378164395477

Epoch: 6| Step: 8
Training loss: 2.255126517017963
Validation loss: 2.491413380049837

Epoch: 6| Step: 9
Training loss: 1.5963647374295284
Validation loss: 2.4695592540140625

Epoch: 6| Step: 10
Training loss: 2.200425679032426
Validation loss: 2.445171321853514

Epoch: 6| Step: 11
Training loss: 2.3123872059300377
Validation loss: 2.473393428708029

Epoch: 6| Step: 12
Training loss: 1.8315248094399361
Validation loss: 2.508335124876313

Epoch: 6| Step: 13
Training loss: 1.6979091464697182
Validation loss: 2.464024874621234

Epoch: 269| Step: 0
Training loss: 2.389847173872282
Validation loss: 2.4672667238961985

Epoch: 6| Step: 1
Training loss: 1.8896871715587635
Validation loss: 2.503379049704481

Epoch: 6| Step: 2
Training loss: 2.869957357747764
Validation loss: 2.482876066002352

Epoch: 6| Step: 3
Training loss: 1.8014958550466116
Validation loss: 2.488323950855499

Epoch: 6| Step: 4
Training loss: 2.1014658398716506
Validation loss: 2.4566952013403442

Epoch: 6| Step: 5
Training loss: 2.1824439336297967
Validation loss: 2.473891459383171

Epoch: 6| Step: 6
Training loss: 1.16018327366859
Validation loss: 2.4861059553332328

Epoch: 6| Step: 7
Training loss: 2.3108133918496976
Validation loss: 2.5014656364757992

Epoch: 6| Step: 8
Training loss: 2.6860673323803352
Validation loss: 2.4858463063679355

Epoch: 6| Step: 9
Training loss: 2.0778985151047937
Validation loss: 2.4655819419610214

Epoch: 6| Step: 10
Training loss: 2.1450108059697626
Validation loss: 2.5023904344443295

Epoch: 6| Step: 11
Training loss: 2.2478078123457697
Validation loss: 2.4759347848050965

Epoch: 6| Step: 12
Training loss: 2.226890780692511
Validation loss: 2.513842387341434

Epoch: 6| Step: 13
Training loss: 1.4047726394260103
Validation loss: 2.476564485437786

Epoch: 270| Step: 0
Training loss: 2.1767694225660548
Validation loss: 2.4743140850313634

Epoch: 6| Step: 1
Training loss: 1.784216969668974
Validation loss: 2.4849293439190143

Epoch: 6| Step: 2
Training loss: 2.5871892475260965
Validation loss: 2.5253270273215755

Epoch: 6| Step: 3
Training loss: 1.8866349669625213
Validation loss: 2.499390860662224

Epoch: 6| Step: 4
Training loss: 2.022756100956692
Validation loss: 2.4505188815438532

Epoch: 6| Step: 5
Training loss: 2.1414503747791125
Validation loss: 2.465265156410635

Epoch: 6| Step: 6
Training loss: 2.2646464372093904
Validation loss: 2.5060153282480506

Epoch: 6| Step: 7
Training loss: 2.2129440637854723
Validation loss: 2.477541372067311

Epoch: 6| Step: 8
Training loss: 2.2943489560795203
Validation loss: 2.5052310616046776

Epoch: 6| Step: 9
Training loss: 2.073151337137452
Validation loss: 2.4799324280719026

Epoch: 6| Step: 10
Training loss: 2.1027429378192735
Validation loss: 2.4626208632837976

Epoch: 6| Step: 11
Training loss: 1.9143970430694839
Validation loss: 2.444446187874827

Epoch: 6| Step: 12
Training loss: 2.3179404724679684
Validation loss: 2.512682508013999

Epoch: 6| Step: 13
Training loss: 2.8661548719495253
Validation loss: 2.493406280837079

Epoch: 271| Step: 0
Training loss: 2.5814147305515243
Validation loss: 2.49072586707389

Epoch: 6| Step: 1
Training loss: 1.9068084899246005
Validation loss: 2.4627815459168323

Epoch: 6| Step: 2
Training loss: 2.456264746235852
Validation loss: 2.471641320957773

Epoch: 6| Step: 3
Training loss: 2.2654075781316156
Validation loss: 2.488538751697603

Epoch: 6| Step: 4
Training loss: 1.7469785355950873
Validation loss: 2.480697687158537

Epoch: 6| Step: 5
Training loss: 2.588658126165956
Validation loss: 2.46253508372134

Epoch: 6| Step: 6
Training loss: 1.8675501004485922
Validation loss: 2.4661784675317793

Epoch: 6| Step: 7
Training loss: 2.481921922234877
Validation loss: 2.516444954181921

Epoch: 6| Step: 8
Training loss: 2.123132895207092
Validation loss: 2.4611380025814746

Epoch: 6| Step: 9
Training loss: 2.1440981790709497
Validation loss: 2.4917458113169086

Epoch: 6| Step: 10
Training loss: 2.2394002676966798
Validation loss: 2.474857547638421

Epoch: 6| Step: 11
Training loss: 1.911548692055635
Validation loss: 2.489330729103876

Epoch: 6| Step: 12
Training loss: 2.041406446209448
Validation loss: 2.4445103429097954

Epoch: 6| Step: 13
Training loss: 1.8014023510303998
Validation loss: 2.4497575598497368

Epoch: 272| Step: 0
Training loss: 1.9953224199805715
Validation loss: 2.473283511980314

Epoch: 6| Step: 1
Training loss: 1.962260799044354
Validation loss: 2.5047184654503227

Epoch: 6| Step: 2
Training loss: 2.3227959389098127
Validation loss: 2.433310748439507

Epoch: 6| Step: 3
Training loss: 1.7566848189461435
Validation loss: 2.4955551847963555

Epoch: 6| Step: 4
Training loss: 2.5821741846547575
Validation loss: 2.4602400336156234

Epoch: 6| Step: 5
Training loss: 2.3930796070431404
Validation loss: 2.4890366788750122

Epoch: 6| Step: 6
Training loss: 2.405845608109002
Validation loss: 2.4768861094867187

Epoch: 6| Step: 7
Training loss: 1.4100071202091595
Validation loss: 2.512406838643401

Epoch: 6| Step: 8
Training loss: 1.982193596385642
Validation loss: 2.5214528849878626

Epoch: 6| Step: 9
Training loss: 2.687284771484816
Validation loss: 2.4938446911869145

Epoch: 6| Step: 10
Training loss: 2.306000933340104
Validation loss: 2.474453347664763

Epoch: 6| Step: 11
Training loss: 2.1510298192126696
Validation loss: 2.469251408093393

Epoch: 6| Step: 12
Training loss: 1.8486008920951555
Validation loss: 2.4477667482261127

Epoch: 6| Step: 13
Training loss: 2.021726849890065
Validation loss: 2.459027731592378

Epoch: 273| Step: 0
Training loss: 2.470898333290103
Validation loss: 2.5037882395690594

Epoch: 6| Step: 1
Training loss: 2.488287957150988
Validation loss: 2.4791091935722487

Epoch: 6| Step: 2
Training loss: 2.0964563443573985
Validation loss: 2.4728872581411525

Epoch: 6| Step: 3
Training loss: 2.591448210640177
Validation loss: 2.500708986060233

Epoch: 6| Step: 4
Training loss: 1.9315523102322898
Validation loss: 2.4756660488753646

Epoch: 6| Step: 5
Training loss: 1.8500356696530604
Validation loss: 2.5226768648422784

Epoch: 6| Step: 6
Training loss: 2.381410680440998
Validation loss: 2.445766941033204

Epoch: 6| Step: 7
Training loss: 1.7611958812577957
Validation loss: 2.47953982055576

Epoch: 6| Step: 8
Training loss: 2.190070141056629
Validation loss: 2.4797623066071

Epoch: 6| Step: 9
Training loss: 2.1026127683173645
Validation loss: 2.487027995686749

Epoch: 6| Step: 10
Training loss: 2.3345690134664463
Validation loss: 2.461911646636147

Epoch: 6| Step: 11
Training loss: 1.8836821767523646
Validation loss: 2.5224473685056603

Epoch: 6| Step: 12
Training loss: 1.89846707544719
Validation loss: 2.5010476993386677

Epoch: 6| Step: 13
Training loss: 2.5812837612354955
Validation loss: 2.475407347143611

Epoch: 274| Step: 0
Training loss: 2.4531365655517074
Validation loss: 2.5013216483429215

Epoch: 6| Step: 1
Training loss: 1.4222295968705614
Validation loss: 2.4762496018202222

Epoch: 6| Step: 2
Training loss: 2.648529771305848
Validation loss: 2.4606735366590606

Epoch: 6| Step: 3
Training loss: 2.1219298680083876
Validation loss: 2.502425577333232

Epoch: 6| Step: 4
Training loss: 1.960991604123192
Validation loss: 2.4824721833256524

Epoch: 6| Step: 5
Training loss: 1.8000241754815727
Validation loss: 2.4542525285215104

Epoch: 6| Step: 6
Training loss: 2.1895888028740433
Validation loss: 2.444153478891377

Epoch: 6| Step: 7
Training loss: 2.4597170755466653
Validation loss: 2.4601544096723376

Epoch: 6| Step: 8
Training loss: 2.0651131461783288
Validation loss: 2.501274201529507

Epoch: 6| Step: 9
Training loss: 2.8147905982613604
Validation loss: 2.46682609566975

Epoch: 6| Step: 10
Training loss: 2.201077639467399
Validation loss: 2.486834049398849

Epoch: 6| Step: 11
Training loss: 1.8872448679300522
Validation loss: 2.4362649089177504

Epoch: 6| Step: 12
Training loss: 2.07524333584139
Validation loss: 2.475045561989993

Epoch: 6| Step: 13
Training loss: 2.3127724770519755
Validation loss: 2.485261833772303

Epoch: 275| Step: 0
Training loss: 2.364438314374149
Validation loss: 2.5242640527946385

Epoch: 6| Step: 1
Training loss: 2.2554714645512113
Validation loss: 2.4763326504916674

Epoch: 6| Step: 2
Training loss: 2.0715183417124914
Validation loss: 2.450817105457328

Epoch: 6| Step: 3
Training loss: 2.6237525700760567
Validation loss: 2.477354646120411

Epoch: 6| Step: 4
Training loss: 2.2327309275222476
Validation loss: 2.437107422154449

Epoch: 6| Step: 5
Training loss: 2.285836925367017
Validation loss: 2.4590914019591508

Epoch: 6| Step: 6
Training loss: 2.297071902599941
Validation loss: 2.4595720630005142

Epoch: 6| Step: 7
Training loss: 1.764805561410713
Validation loss: 2.432670712516629

Epoch: 6| Step: 8
Training loss: 2.1166002648618796
Validation loss: 2.513066962076611

Epoch: 6| Step: 9
Training loss: 1.628017484955303
Validation loss: 2.5130038492550253

Epoch: 6| Step: 10
Training loss: 2.3078823897743397
Validation loss: 2.5142648013551923

Epoch: 6| Step: 11
Training loss: 2.2546480700137437
Validation loss: 2.4697017006117044

Epoch: 6| Step: 12
Training loss: 2.0125173816759574
Validation loss: 2.496885777006037

Epoch: 6| Step: 13
Training loss: 1.9638650022520163
Validation loss: 2.489590565578318

Epoch: 276| Step: 0
Training loss: 2.2977478029856733
Validation loss: 2.467351661514884

Epoch: 6| Step: 1
Training loss: 1.8529636537967684
Validation loss: 2.478209333370156

Epoch: 6| Step: 2
Training loss: 2.1461183550034844
Validation loss: 2.526704137359609

Epoch: 6| Step: 3
Training loss: 2.612091477864608
Validation loss: 2.498817578507866

Epoch: 6| Step: 4
Training loss: 2.068953503513534
Validation loss: 2.492783956908393

Epoch: 6| Step: 5
Training loss: 2.380539507263446
Validation loss: 2.4802006087010358

Epoch: 6| Step: 6
Training loss: 1.8984288344950764
Validation loss: 2.477209496627872

Epoch: 6| Step: 7
Training loss: 2.118218315277431
Validation loss: 2.4574103478105718

Epoch: 6| Step: 8
Training loss: 1.926477271652105
Validation loss: 2.4816801604260528

Epoch: 6| Step: 9
Training loss: 2.6222657995679968
Validation loss: 2.482899185243383

Epoch: 6| Step: 10
Training loss: 2.268300758630567
Validation loss: 2.513267653314749

Epoch: 6| Step: 11
Training loss: 2.1276030585209464
Validation loss: 2.4380311095461553

Epoch: 6| Step: 12
Training loss: 1.3583217793930848
Validation loss: 2.4681961582680656

Epoch: 6| Step: 13
Training loss: 2.32258263710921
Validation loss: 2.482123917072746

Epoch: 277| Step: 0
Training loss: 1.7183445538963225
Validation loss: 2.4922135982715

Epoch: 6| Step: 1
Training loss: 2.937597394911332
Validation loss: 2.523089919157879

Epoch: 6| Step: 2
Training loss: 1.9454533169806532
Validation loss: 2.4402754311560972

Epoch: 6| Step: 3
Training loss: 1.7739336437299953
Validation loss: 2.456006581216505

Epoch: 6| Step: 4
Training loss: 1.8724155416145574
Validation loss: 2.470049388279306

Epoch: 6| Step: 5
Training loss: 2.117979570147977
Validation loss: 2.4881550079490604

Epoch: 6| Step: 6
Training loss: 2.3846848432775793
Validation loss: 2.4508320856797425

Epoch: 6| Step: 7
Training loss: 2.067392499682075
Validation loss: 2.4934547440945836

Epoch: 6| Step: 8
Training loss: 1.799218946118164
Validation loss: 2.450319795035079

Epoch: 6| Step: 9
Training loss: 2.398919569644538
Validation loss: 2.504613692223828

Epoch: 6| Step: 10
Training loss: 1.9849196760323309
Validation loss: 2.5071029111541248

Epoch: 6| Step: 11
Training loss: 2.0576913437337145
Validation loss: 2.4937628558883254

Epoch: 6| Step: 12
Training loss: 1.868277195856453
Validation loss: 2.469036070663124

Epoch: 6| Step: 13
Training loss: 3.297063596131199
Validation loss: 2.5048542271741105

Epoch: 278| Step: 0
Training loss: 1.9956686085978848
Validation loss: 2.469231918440871

Epoch: 6| Step: 1
Training loss: 1.822050255644514
Validation loss: 2.4248000926586855

Epoch: 6| Step: 2
Training loss: 1.672828830045668
Validation loss: 2.477661464531434

Epoch: 6| Step: 3
Training loss: 2.6065698953342293
Validation loss: 2.500728514362031

Epoch: 6| Step: 4
Training loss: 2.589737327540996
Validation loss: 2.4973852748113647

Epoch: 6| Step: 5
Training loss: 2.1109435854357486
Validation loss: 2.5096248385003177

Epoch: 6| Step: 6
Training loss: 2.016525067594272
Validation loss: 2.4802325914595342

Epoch: 6| Step: 7
Training loss: 2.4790909913211157
Validation loss: 2.4749853732630953

Epoch: 6| Step: 8
Training loss: 1.8413774127992304
Validation loss: 2.4529141769909777

Epoch: 6| Step: 9
Training loss: 1.9393355995672907
Validation loss: 2.4803043449552535

Epoch: 6| Step: 10
Training loss: 2.668707325078243
Validation loss: 2.543948240996679

Epoch: 6| Step: 11
Training loss: 1.9699382526383318
Validation loss: 2.4832974124145863

Epoch: 6| Step: 12
Training loss: 2.3183388070380806
Validation loss: 2.496670963457751

Epoch: 6| Step: 13
Training loss: 1.9272094754011058
Validation loss: 2.5025081481437064

Epoch: 279| Step: 0
Training loss: 1.843322187025552
Validation loss: 2.5033331729022676

Epoch: 6| Step: 1
Training loss: 2.744716076229257
Validation loss: 2.4851006301880516

Epoch: 6| Step: 2
Training loss: 2.1135286478989355
Validation loss: 2.484500585936612

Epoch: 6| Step: 3
Training loss: 2.0042650522468834
Validation loss: 2.5116059836420885

Epoch: 6| Step: 4
Training loss: 1.691919121281441
Validation loss: 2.513162697897008

Epoch: 6| Step: 5
Training loss: 2.495413960763081
Validation loss: 2.487724314120329

Epoch: 6| Step: 6
Training loss: 2.243233998079915
Validation loss: 2.4598150690860447

Epoch: 6| Step: 7
Training loss: 2.0657636079438104
Validation loss: 2.4840925689081934

Epoch: 6| Step: 8
Training loss: 1.6249190090243488
Validation loss: 2.4931194434989656

Epoch: 6| Step: 9
Training loss: 2.237532618620535
Validation loss: 2.472864052553819

Epoch: 6| Step: 10
Training loss: 2.404301238191614
Validation loss: 2.4747685406345

Epoch: 6| Step: 11
Training loss: 1.751747553065167
Validation loss: 2.512331142760222

Epoch: 6| Step: 12
Training loss: 2.6582107487778717
Validation loss: 2.4865264255419257

Epoch: 6| Step: 13
Training loss: 1.84744822841265
Validation loss: 2.4972769756126585

Epoch: 280| Step: 0
Training loss: 1.3241871517766277
Validation loss: 2.456867191346541

Epoch: 6| Step: 1
Training loss: 2.3156453985018484
Validation loss: 2.49301116979562

Epoch: 6| Step: 2
Training loss: 2.2536483431976166
Validation loss: 2.4861094654919786

Epoch: 6| Step: 3
Training loss: 1.7401334003305737
Validation loss: 2.4527916290830207

Epoch: 6| Step: 4
Training loss: 2.4111830442317164
Validation loss: 2.51469969351047

Epoch: 6| Step: 5
Training loss: 1.748817589348709
Validation loss: 2.492408831336042

Epoch: 6| Step: 6
Training loss: 2.120938065296804
Validation loss: 2.4975194951205535

Epoch: 6| Step: 7
Training loss: 2.3441869709841066
Validation loss: 2.457635367122844

Epoch: 6| Step: 8
Training loss: 3.1469306463570113
Validation loss: 2.492942148292675

Epoch: 6| Step: 9
Training loss: 2.0625589535697357
Validation loss: 2.4962042079705253

Epoch: 6| Step: 10
Training loss: 1.990751279840821
Validation loss: 2.5087344003680183

Epoch: 6| Step: 11
Training loss: 1.9317866348301886
Validation loss: 2.4600024620133536

Epoch: 6| Step: 12
Training loss: 2.3379055140633866
Validation loss: 2.480283019644477

Epoch: 6| Step: 13
Training loss: 1.6561435449324762
Validation loss: 2.491037163016941

Epoch: 281| Step: 0
Training loss: 1.8055757260622347
Validation loss: 2.4988469941291958

Epoch: 6| Step: 1
Training loss: 2.2365929326023974
Validation loss: 2.5058065703042343

Epoch: 6| Step: 2
Training loss: 1.718228000788097
Validation loss: 2.479157349474275

Epoch: 6| Step: 3
Training loss: 2.7640115805464744
Validation loss: 2.4760751200350866

Epoch: 6| Step: 4
Training loss: 2.0479155945669985
Validation loss: 2.4885171629129923

Epoch: 6| Step: 5
Training loss: 3.0963315115384047
Validation loss: 2.484987899065137

Epoch: 6| Step: 6
Training loss: 1.1675773653785375
Validation loss: 2.497023642182194

Epoch: 6| Step: 7
Training loss: 2.0421437335413937
Validation loss: 2.499957156070579

Epoch: 6| Step: 8
Training loss: 1.742463299598763
Validation loss: 2.478918152208508

Epoch: 6| Step: 9
Training loss: 2.2137870622630933
Validation loss: 2.521464611941995

Epoch: 6| Step: 10
Training loss: 2.3246669817917813
Validation loss: 2.4723152501321635

Epoch: 6| Step: 11
Training loss: 1.8165781247438078
Validation loss: 2.472204561651675

Epoch: 6| Step: 12
Training loss: 2.148059270683911
Validation loss: 2.495444353428946

Epoch: 6| Step: 13
Training loss: 1.8477505746519765
Validation loss: 2.4462375636021516

Epoch: 282| Step: 0
Training loss: 1.8923697499613672
Validation loss: 2.4696939952543655

Epoch: 6| Step: 1
Training loss: 2.2373778965202007
Validation loss: 2.4770960969379705

Epoch: 6| Step: 2
Training loss: 1.978611423172805
Validation loss: 2.4592148686487545

Epoch: 6| Step: 3
Training loss: 2.3831896874237004
Validation loss: 2.484401463079829

Epoch: 6| Step: 4
Training loss: 2.0634707853829446
Validation loss: 2.4775846015549328

Epoch: 6| Step: 5
Training loss: 1.9956653829587128
Validation loss: 2.4770320800268837

Epoch: 6| Step: 6
Training loss: 1.6464709081132978
Validation loss: 2.482823406483533

Epoch: 6| Step: 7
Training loss: 3.284083133291115
Validation loss: 2.463555144203517

Epoch: 6| Step: 8
Training loss: 2.236847263365665
Validation loss: 2.5237139057068556

Epoch: 6| Step: 9
Training loss: 2.06638963544833
Validation loss: 2.478394285068016

Epoch: 6| Step: 10
Training loss: 2.5072400161585464
Validation loss: 2.480486564904924

Epoch: 6| Step: 11
Training loss: 1.6923480858517
Validation loss: 2.524114799981323

Epoch: 6| Step: 12
Training loss: 1.94122989091449
Validation loss: 2.466756102457424

Epoch: 6| Step: 13
Training loss: 1.4643898222462532
Validation loss: 2.4732348908365127

Epoch: 283| Step: 0
Training loss: 2.0608410955155123
Validation loss: 2.5035019742529703

Epoch: 6| Step: 1
Training loss: 1.9849947464726878
Validation loss: 2.4756444454348214

Epoch: 6| Step: 2
Training loss: 2.212136634255882
Validation loss: 2.507187367332977

Epoch: 6| Step: 3
Training loss: 2.0242071271391153
Validation loss: 2.479459246023665

Epoch: 6| Step: 4
Training loss: 1.9577165268058123
Validation loss: 2.476624356301512

Epoch: 6| Step: 5
Training loss: 1.9634383467011096
Validation loss: 2.4692945667646944

Epoch: 6| Step: 6
Training loss: 2.0696979114305734
Validation loss: 2.480751844779321

Epoch: 6| Step: 7
Training loss: 3.01207401540327
Validation loss: 2.4594528550965897

Epoch: 6| Step: 8
Training loss: 2.021383885636361
Validation loss: 2.4759886138079428

Epoch: 6| Step: 9
Training loss: 2.3742941761243133
Validation loss: 2.4938032794032563

Epoch: 6| Step: 10
Training loss: 2.0572767297387604
Validation loss: 2.480103576718827

Epoch: 6| Step: 11
Training loss: 2.5417158611935697
Validation loss: 2.465091166947938

Epoch: 6| Step: 12
Training loss: 1.58151357210639
Validation loss: 2.4686828184611835

Epoch: 6| Step: 13
Training loss: 2.2171229454573416
Validation loss: 2.4502190947954556

Epoch: 284| Step: 0
Training loss: 2.32722855276752
Validation loss: 2.499062893699669

Epoch: 6| Step: 1
Training loss: 2.508697258623448
Validation loss: 2.493199486078338

Epoch: 6| Step: 2
Training loss: 1.9272794950155383
Validation loss: 2.456220165627696

Epoch: 6| Step: 3
Training loss: 1.9705247902306569
Validation loss: 2.475084393652307

Epoch: 6| Step: 4
Training loss: 2.37903302736515
Validation loss: 2.504658986713736

Epoch: 6| Step: 5
Training loss: 2.203407215412892
Validation loss: 2.493584038584997

Epoch: 6| Step: 6
Training loss: 1.9115360947538058
Validation loss: 2.486034733306802

Epoch: 6| Step: 7
Training loss: 2.3053671659028203
Validation loss: 2.4929451942915275

Epoch: 6| Step: 8
Training loss: 1.6206501181377557
Validation loss: 2.4664548498876973

Epoch: 6| Step: 9
Training loss: 2.0836850695914393
Validation loss: 2.5218696616647787

Epoch: 6| Step: 10
Training loss: 1.9727030833510821
Validation loss: 2.482614995996964

Epoch: 6| Step: 11
Training loss: 1.9645726526913267
Validation loss: 2.4730621773476638

Epoch: 6| Step: 12
Training loss: 2.7992630465572184
Validation loss: 2.4406734010132523

Epoch: 6| Step: 13
Training loss: 1.7428158708840409
Validation loss: 2.4638736656111964

Epoch: 285| Step: 0
Training loss: 2.361944353266962
Validation loss: 2.5174240713953138

Epoch: 6| Step: 1
Training loss: 1.7582814587116922
Validation loss: 2.452734514891892

Epoch: 6| Step: 2
Training loss: 1.9905249745676243
Validation loss: 2.482667007323387

Epoch: 6| Step: 3
Training loss: 1.9626109365220932
Validation loss: 2.4736780104742433

Epoch: 6| Step: 4
Training loss: 1.9394177205982994
Validation loss: 2.491733938322768

Epoch: 6| Step: 5
Training loss: 1.8856893380896962
Validation loss: 2.4733860447621767

Epoch: 6| Step: 6
Training loss: 1.9124873940046148
Validation loss: 2.4970888662192174

Epoch: 6| Step: 7
Training loss: 2.052381142114823
Validation loss: 2.523203792332462

Epoch: 6| Step: 8
Training loss: 1.7558220338510633
Validation loss: 2.4609140379699297

Epoch: 6| Step: 9
Training loss: 2.457290029316338
Validation loss: 2.511699938947274

Epoch: 6| Step: 10
Training loss: 2.2720647383721273
Validation loss: 2.477104021962271

Epoch: 6| Step: 11
Training loss: 2.4188322580628165
Validation loss: 2.47396164346073

Epoch: 6| Step: 12
Training loss: 2.6908323343211524
Validation loss: 2.4428490045640334

Epoch: 6| Step: 13
Training loss: 2.224340139546217
Validation loss: 2.476440666848068

Epoch: 286| Step: 0
Training loss: 1.7463856566157718
Validation loss: 2.4878804973705506

Epoch: 6| Step: 1
Training loss: 2.00333448436448
Validation loss: 2.464516788808576

Epoch: 6| Step: 2
Training loss: 2.449831847823659
Validation loss: 2.500458117523656

Epoch: 6| Step: 3
Training loss: 2.004719649047431
Validation loss: 2.478505674579607

Epoch: 6| Step: 4
Training loss: 1.638755023288084
Validation loss: 2.517406788770958

Epoch: 6| Step: 5
Training loss: 2.485124582894162
Validation loss: 2.465228685645796

Epoch: 6| Step: 6
Training loss: 2.409273403217538
Validation loss: 2.472992350268887

Epoch: 6| Step: 7
Training loss: 1.5960273926805408
Validation loss: 2.4820252085118

Epoch: 6| Step: 8
Training loss: 2.3616691702769095
Validation loss: 2.468658445567961

Epoch: 6| Step: 9
Training loss: 1.9600901197618161
Validation loss: 2.4952095875932296

Epoch: 6| Step: 10
Training loss: 2.523341410316162
Validation loss: 2.4777823685495726

Epoch: 6| Step: 11
Training loss: 1.8834470573905613
Validation loss: 2.4781536108557294

Epoch: 6| Step: 12
Training loss: 1.7206155536030647
Validation loss: 2.4758894255998634

Epoch: 6| Step: 13
Training loss: 2.640682603557636
Validation loss: 2.476969284820818

Epoch: 287| Step: 0
Training loss: 2.2657464356599055
Validation loss: 2.4897269122906285

Epoch: 6| Step: 1
Training loss: 2.1197150089234107
Validation loss: 2.508005024609275

Epoch: 6| Step: 2
Training loss: 2.1253475578163945
Validation loss: 2.4973261326444267

Epoch: 6| Step: 3
Training loss: 1.8618960559854214
Validation loss: 2.4712656458821036

Epoch: 6| Step: 4
Training loss: 2.9428715393359752
Validation loss: 2.469196261073472

Epoch: 6| Step: 5
Training loss: 1.9775482252874144
Validation loss: 2.45232244096958

Epoch: 6| Step: 6
Training loss: 1.9694519002773598
Validation loss: 2.5155906993372312

Epoch: 6| Step: 7
Training loss: 1.5888599097818497
Validation loss: 2.5134266964198186

Epoch: 6| Step: 8
Training loss: 2.19309630476583
Validation loss: 2.5031237662362784

Epoch: 6| Step: 9
Training loss: 1.8635359296147112
Validation loss: 2.484457800794521

Epoch: 6| Step: 10
Training loss: 1.991873622926129
Validation loss: 2.5025579635563466

Epoch: 6| Step: 11
Training loss: 2.454641177337079
Validation loss: 2.475047916351659

Epoch: 6| Step: 12
Training loss: 1.9317302316646716
Validation loss: 2.48551432429191

Epoch: 6| Step: 13
Training loss: 2.7243822885036444
Validation loss: 2.5331185909531517

Epoch: 288| Step: 0
Training loss: 2.342544143733077
Validation loss: 2.44660805044243

Epoch: 6| Step: 1
Training loss: 2.4449464566661487
Validation loss: 2.4512284127273745

Epoch: 6| Step: 2
Training loss: 1.5315336626408986
Validation loss: 2.478728851254119

Epoch: 6| Step: 3
Training loss: 2.063981766605422
Validation loss: 2.4686132964062

Epoch: 6| Step: 4
Training loss: 1.7543281438568228
Validation loss: 2.4709621688100714

Epoch: 6| Step: 5
Training loss: 1.7896032057677584
Validation loss: 2.4962467476207726

Epoch: 6| Step: 6
Training loss: 2.3534705446603192
Validation loss: 2.422230940274972

Epoch: 6| Step: 7
Training loss: 2.0403959510857277
Validation loss: 2.5386589250806306

Epoch: 6| Step: 8
Training loss: 1.6873279766423266
Validation loss: 2.4539747269407615

Epoch: 6| Step: 9
Training loss: 2.0738733151258693
Validation loss: 2.502326392563318

Epoch: 6| Step: 10
Training loss: 2.1295005038946684
Validation loss: 2.476179837706939

Epoch: 6| Step: 11
Training loss: 2.331920525304031
Validation loss: 2.465240933793228

Epoch: 6| Step: 12
Training loss: 1.6400838050131556
Validation loss: 2.4764802902984777

Epoch: 6| Step: 13
Training loss: 3.671920191709933
Validation loss: 2.5383766215963486

Epoch: 289| Step: 0
Training loss: 2.1621862327195958
Validation loss: 2.5079773731231882

Epoch: 6| Step: 1
Training loss: 2.223403349216715
Validation loss: 2.4928189292739993

Epoch: 6| Step: 2
Training loss: 1.8751613547515744
Validation loss: 2.50605964092178

Epoch: 6| Step: 3
Training loss: 2.1578625164270835
Validation loss: 2.442582055779752

Epoch: 6| Step: 4
Training loss: 2.3479367309182373
Validation loss: 2.4413408404376256

Epoch: 6| Step: 5
Training loss: 2.0946297007398313
Validation loss: 2.475181623432099

Epoch: 6| Step: 6
Training loss: 1.9988260399988516
Validation loss: 2.480087609367807

Epoch: 6| Step: 7
Training loss: 1.8823689298353932
Validation loss: 2.4341076829822303

Epoch: 6| Step: 8
Training loss: 2.078417076293828
Validation loss: 2.523703694657282

Epoch: 6| Step: 9
Training loss: 2.106658090058908
Validation loss: 2.4812183103167373

Epoch: 6| Step: 10
Training loss: 1.9424093253281045
Validation loss: 2.4836114737020174

Epoch: 6| Step: 11
Training loss: 2.3455896913923824
Validation loss: 2.476826733494061

Epoch: 6| Step: 12
Training loss: 2.683549150432249
Validation loss: 2.4553017375710757

Epoch: 6| Step: 13
Training loss: 2.2764478331247733
Validation loss: 2.4802646172174807

Epoch: 290| Step: 0
Training loss: 2.254863885971078
Validation loss: 2.4805761232488654

Epoch: 6| Step: 1
Training loss: 2.5758045273001806
Validation loss: 2.478214551246458

Epoch: 6| Step: 2
Training loss: 2.6795505677762037
Validation loss: 2.4612909430743355

Epoch: 6| Step: 3
Training loss: 2.018338055698321
Validation loss: 2.4865970087091713

Epoch: 6| Step: 4
Training loss: 2.0372467726165677
Validation loss: 2.4875559302906196

Epoch: 6| Step: 5
Training loss: 1.7488902524231622
Validation loss: 2.500046724477587

Epoch: 6| Step: 6
Training loss: 2.5284566654643026
Validation loss: 2.5263297397639755

Epoch: 6| Step: 7
Training loss: 1.5848493930490908
Validation loss: 2.4600468797682975

Epoch: 6| Step: 8
Training loss: 1.4364603678371008
Validation loss: 2.480179185335077

Epoch: 6| Step: 9
Training loss: 2.0073014733378995
Validation loss: 2.4741485788525415

Epoch: 6| Step: 10
Training loss: 1.9163310406712577
Validation loss: 2.4764273436361797

Epoch: 6| Step: 11
Training loss: 2.236161378199388
Validation loss: 2.455463784518503

Epoch: 6| Step: 12
Training loss: 2.529972271974626
Validation loss: 2.4582432012023423

Epoch: 6| Step: 13
Training loss: 1.8004049375482032
Validation loss: 2.484030724160783

Epoch: 291| Step: 0
Training loss: 1.9671780804930483
Validation loss: 2.496335105891434

Epoch: 6| Step: 1
Training loss: 2.722708089983522
Validation loss: 2.493796321860066

Epoch: 6| Step: 2
Training loss: 2.411910594826795
Validation loss: 2.4358813104427486

Epoch: 6| Step: 3
Training loss: 2.1645147078365334
Validation loss: 2.4693520817633057

Epoch: 6| Step: 4
Training loss: 1.8636904732954116
Validation loss: 2.45125322875707

Epoch: 6| Step: 5
Training loss: 1.6614576556962724
Validation loss: 2.472668272659655

Epoch: 6| Step: 6
Training loss: 1.9562592040019102
Validation loss: 2.476185912962284

Epoch: 6| Step: 7
Training loss: 2.7594050923107427
Validation loss: 2.4858382436912767

Epoch: 6| Step: 8
Training loss: 1.8273667939532403
Validation loss: 2.451774997471743

Epoch: 6| Step: 9
Training loss: 1.5796444065392818
Validation loss: 2.4983395445898045

Epoch: 6| Step: 10
Training loss: 2.243056285163858
Validation loss: 2.474411738782822

Epoch: 6| Step: 11
Training loss: 2.0971865563240595
Validation loss: 2.5107686075174613

Epoch: 6| Step: 12
Training loss: 1.7756444164209495
Validation loss: 2.520481879042769

Epoch: 6| Step: 13
Training loss: 2.134172390303657
Validation loss: 2.492135175079217

Epoch: 292| Step: 0
Training loss: 2.229461709815499
Validation loss: 2.4612419298216626

Epoch: 6| Step: 1
Training loss: 2.117751043001291
Validation loss: 2.489384085130996

Epoch: 6| Step: 2
Training loss: 2.3444597314072047
Validation loss: 2.5111964914039366

Epoch: 6| Step: 3
Training loss: 2.582726458566186
Validation loss: 2.4800919084789035

Epoch: 6| Step: 4
Training loss: 2.1124008516598507
Validation loss: 2.4994967907867616

Epoch: 6| Step: 5
Training loss: 2.2040046396777826
Validation loss: 2.4602373920715417

Epoch: 6| Step: 6
Training loss: 2.2343989017515287
Validation loss: 2.49094981067043

Epoch: 6| Step: 7
Training loss: 2.3076619237953624
Validation loss: 2.4865256522821864

Epoch: 6| Step: 8
Training loss: 1.406399485802041
Validation loss: 2.506420928205667

Epoch: 6| Step: 9
Training loss: 1.646135213987816
Validation loss: 2.4513163250585026

Epoch: 6| Step: 10
Training loss: 2.276677395677582
Validation loss: 2.480687084089381

Epoch: 6| Step: 11
Training loss: 2.2631714261909974
Validation loss: 2.507921480950421

Epoch: 6| Step: 12
Training loss: 1.7266846350369487
Validation loss: 2.482282623590847

Epoch: 6| Step: 13
Training loss: 2.2852338728803594
Validation loss: 2.478836069239281

Epoch: 293| Step: 0
Training loss: 1.8748767176470889
Validation loss: 2.475229744405778

Epoch: 6| Step: 1
Training loss: 1.719968745147262
Validation loss: 2.4908871368166747

Epoch: 6| Step: 2
Training loss: 2.3692098609009364
Validation loss: 2.4956704725283934

Epoch: 6| Step: 3
Training loss: 1.7388640723253574
Validation loss: 2.4656747668107064

Epoch: 6| Step: 4
Training loss: 2.5494092256942453
Validation loss: 2.4748696341869665

Epoch: 6| Step: 5
Training loss: 2.4989345187385106
Validation loss: 2.4804975377974245

Epoch: 6| Step: 6
Training loss: 2.227221153950257
Validation loss: 2.480486861526091

Epoch: 6| Step: 7
Training loss: 1.5819182178949422
Validation loss: 2.4904376247140227

Epoch: 6| Step: 8
Training loss: 1.9323194832526183
Validation loss: 2.501085434898935

Epoch: 6| Step: 9
Training loss: 2.094368003621791
Validation loss: 2.481659576260546

Epoch: 6| Step: 10
Training loss: 2.0921273847494457
Validation loss: 2.4671477817943845

Epoch: 6| Step: 11
Training loss: 2.3490229990333837
Validation loss: 2.4702154783774097

Epoch: 6| Step: 12
Training loss: 2.0771392549456174
Validation loss: 2.511228561253095

Epoch: 6| Step: 13
Training loss: 2.690748513606681
Validation loss: 2.489086719611372

Epoch: 294| Step: 0
Training loss: 2.0196704336935976
Validation loss: 2.484864384655999

Epoch: 6| Step: 1
Training loss: 1.3764268234539336
Validation loss: 2.4815120927349077

Epoch: 6| Step: 2
Training loss: 2.232304073506344
Validation loss: 2.469269473157055

Epoch: 6| Step: 3
Training loss: 2.4535418113813616
Validation loss: 2.50526350355148

Epoch: 6| Step: 4
Training loss: 1.9107662545281041
Validation loss: 2.477043610541193

Epoch: 6| Step: 5
Training loss: 1.7189174223766397
Validation loss: 2.4980409652862114

Epoch: 6| Step: 6
Training loss: 1.659695191032447
Validation loss: 2.473270066034243

Epoch: 6| Step: 7
Training loss: 2.4227313096795045
Validation loss: 2.514128709609806

Epoch: 6| Step: 8
Training loss: 1.7689034061831908
Validation loss: 2.480492035337666

Epoch: 6| Step: 9
Training loss: 2.761953815993915
Validation loss: 2.500673379757799

Epoch: 6| Step: 10
Training loss: 2.0737077618804802
Validation loss: 2.4856712610985356

Epoch: 6| Step: 11
Training loss: 2.1585696362292053
Validation loss: 2.492586195331834

Epoch: 6| Step: 12
Training loss: 2.3719219539854888
Validation loss: 2.478787365675409

Epoch: 6| Step: 13
Training loss: 2.2682344339501546
Validation loss: 2.475962512251148

Epoch: 295| Step: 0
Training loss: 2.5114310234754704
Validation loss: 2.4929793088130725

Epoch: 6| Step: 1
Training loss: 1.7467892347651814
Validation loss: 2.5318015452365756

Epoch: 6| Step: 2
Training loss: 2.2614800783503246
Validation loss: 2.4826354214770534

Epoch: 6| Step: 3
Training loss: 1.8800074152090052
Validation loss: 2.4517430523318415

Epoch: 6| Step: 4
Training loss: 1.7947532400252624
Validation loss: 2.475221794219673

Epoch: 6| Step: 5
Training loss: 2.093214507445935
Validation loss: 2.476719361760459

Epoch: 6| Step: 6
Training loss: 1.999886747968421
Validation loss: 2.453232653562465

Epoch: 6| Step: 7
Training loss: 2.0491408990287283
Validation loss: 2.4804125397617547

Epoch: 6| Step: 8
Training loss: 2.2447329437528936
Validation loss: 2.4586588555569318

Epoch: 6| Step: 9
Training loss: 2.118207960082816
Validation loss: 2.5115772053629146

Epoch: 6| Step: 10
Training loss: 2.6582330818366184
Validation loss: 2.485984844602737

Epoch: 6| Step: 11
Training loss: 1.6822423622614437
Validation loss: 2.5281121734338785

Epoch: 6| Step: 12
Training loss: 2.336573485485995
Validation loss: 2.52625357869427

Epoch: 6| Step: 13
Training loss: 1.9027417528341872
Validation loss: 2.451462883223591

Epoch: 296| Step: 0
Training loss: 1.9364237103197925
Validation loss: 2.472863123662302

Epoch: 6| Step: 1
Training loss: 1.2897541387010583
Validation loss: 2.4756825707927175

Epoch: 6| Step: 2
Training loss: 2.3974874895105542
Validation loss: 2.4771056307675687

Epoch: 6| Step: 3
Training loss: 2.304561495165091
Validation loss: 2.4956135969472446

Epoch: 6| Step: 4
Training loss: 2.1599183874253525
Validation loss: 2.481905358185039

Epoch: 6| Step: 5
Training loss: 2.555081305059365
Validation loss: 2.4510867396366938

Epoch: 6| Step: 6
Training loss: 1.6260263429645063
Validation loss: 2.494197022304262

Epoch: 6| Step: 7
Training loss: 1.8397346998807829
Validation loss: 2.5048115675997176

Epoch: 6| Step: 8
Training loss: 2.468072532700845
Validation loss: 2.517031016383014

Epoch: 6| Step: 9
Training loss: 2.045461384925582
Validation loss: 2.5203321062506143

Epoch: 6| Step: 10
Training loss: 2.5938296018588045
Validation loss: 2.466034450892427

Epoch: 6| Step: 11
Training loss: 1.7196207788394386
Validation loss: 2.48784209523145

Epoch: 6| Step: 12
Training loss: 1.680378332680585
Validation loss: 2.4241593886239077

Epoch: 6| Step: 13
Training loss: 2.7277295257468444
Validation loss: 2.4854036589031296

Epoch: 297| Step: 0
Training loss: 2.03097004061549
Validation loss: 2.5185200979510474

Epoch: 6| Step: 1
Training loss: 1.842174179896116
Validation loss: 2.470745499828866

Epoch: 6| Step: 2
Training loss: 1.6118556783168176
Validation loss: 2.4690875810022317

Epoch: 6| Step: 3
Training loss: 2.3916500113125516
Validation loss: 2.5096643323293746

Epoch: 6| Step: 4
Training loss: 2.7383204306331197
Validation loss: 2.479412379660566

Epoch: 6| Step: 5
Training loss: 2.0606814372161595
Validation loss: 2.4465670619519573

Epoch: 6| Step: 6
Training loss: 2.055158321843901
Validation loss: 2.4911722501881575

Epoch: 6| Step: 7
Training loss: 2.2234659714527893
Validation loss: 2.4937126666260463

Epoch: 6| Step: 8
Training loss: 1.5870869797617728
Validation loss: 2.4669246942990397

Epoch: 6| Step: 9
Training loss: 2.294452038009102
Validation loss: 2.44796187953174

Epoch: 6| Step: 10
Training loss: 1.9132017107404604
Validation loss: 2.453587351766945

Epoch: 6| Step: 11
Training loss: 2.4377339568710985
Validation loss: 2.4314355380155233

Epoch: 6| Step: 12
Training loss: 2.02887316806455
Validation loss: 2.4869211040759316

Epoch: 6| Step: 13
Training loss: 1.8430466037556164
Validation loss: 2.4936123336479157

Epoch: 298| Step: 0
Training loss: 1.8062325341459295
Validation loss: 2.485372262559824

Epoch: 6| Step: 1
Training loss: 2.211931092994592
Validation loss: 2.4832118876855125

Epoch: 6| Step: 2
Training loss: 2.133014599513628
Validation loss: 2.4704762066779473

Epoch: 6| Step: 3
Training loss: 2.036704384329132
Validation loss: 2.4768872785479052

Epoch: 6| Step: 4
Training loss: 2.1522583433953946
Validation loss: 2.481650383267079

Epoch: 6| Step: 5
Training loss: 1.5846681823937199
Validation loss: 2.478908729802125

Epoch: 6| Step: 6
Training loss: 1.965252448893391
Validation loss: 2.4793202873182136

Epoch: 6| Step: 7
Training loss: 2.149923136911854
Validation loss: 2.440491922832413

Epoch: 6| Step: 8
Training loss: 2.334256080550067
Validation loss: 2.5157957998004026

Epoch: 6| Step: 9
Training loss: 1.6269551766005972
Validation loss: 2.465603098091074

Epoch: 6| Step: 10
Training loss: 2.723814883323704
Validation loss: 2.455012245347344

Epoch: 6| Step: 11
Training loss: 2.169248460987825
Validation loss: 2.5036576575929543

Epoch: 6| Step: 12
Training loss: 2.211313599857348
Validation loss: 2.492682845281707

Epoch: 6| Step: 13
Training loss: 2.2536620961510465
Validation loss: 2.4695045195139165

Epoch: 299| Step: 0
Training loss: 2.6811862680112273
Validation loss: 2.526090816370203

Epoch: 6| Step: 1
Training loss: 1.9600808753630212
Validation loss: 2.4339867455285087

Epoch: 6| Step: 2
Training loss: 2.245681220608189
Validation loss: 2.482476685878837

Epoch: 6| Step: 3
Training loss: 1.5921141513030461
Validation loss: 2.462864344034271

Epoch: 6| Step: 4
Training loss: 2.083351618368651
Validation loss: 2.474952121129397

Epoch: 6| Step: 5
Training loss: 1.8675118009099931
Validation loss: 2.4998229569125114

Epoch: 6| Step: 6
Training loss: 1.9101823988296789
Validation loss: 2.4792264274687414

Epoch: 6| Step: 7
Training loss: 2.1354174234032257
Validation loss: 2.4786564150298176

Epoch: 6| Step: 8
Training loss: 1.8447359972379829
Validation loss: 2.47335324377275

Epoch: 6| Step: 9
Training loss: 1.9558344853704848
Validation loss: 2.50944773328356

Epoch: 6| Step: 10
Training loss: 2.790723546457127
Validation loss: 2.5311902260821784

Epoch: 6| Step: 11
Training loss: 1.6005512301281994
Validation loss: 2.464622387640631

Epoch: 6| Step: 12
Training loss: 1.949846063553368
Validation loss: 2.4498517440061325

Epoch: 6| Step: 13
Training loss: 2.296829015569926
Validation loss: 2.430168597762763

Epoch: 300| Step: 0
Training loss: 1.5972211100625116
Validation loss: 2.4748940267090425

Epoch: 6| Step: 1
Training loss: 1.9831987033424279
Validation loss: 2.481642764595716

Epoch: 6| Step: 2
Training loss: 2.416695945386997
Validation loss: 2.4876111469366764

Epoch: 6| Step: 3
Training loss: 1.7890143908566356
Validation loss: 2.5026967383220113

Epoch: 6| Step: 4
Training loss: 2.060821312441116
Validation loss: 2.505432594373264

Epoch: 6| Step: 5
Training loss: 1.5619446339679581
Validation loss: 2.4832438048186933

Epoch: 6| Step: 6
Training loss: 1.7711373086965092
Validation loss: 2.4984195307506436

Epoch: 6| Step: 7
Training loss: 2.051238090857154
Validation loss: 2.472687595779614

Epoch: 6| Step: 8
Training loss: 2.2367841630405043
Validation loss: 2.497978271788236

Epoch: 6| Step: 9
Training loss: 2.1101045830286136
Validation loss: 2.4353119606058975

Epoch: 6| Step: 10
Training loss: 2.720688490544139
Validation loss: 2.5314416239347266

Epoch: 6| Step: 11
Training loss: 2.16378738362211
Validation loss: 2.470083041647423

Epoch: 6| Step: 12
Training loss: 2.5296638134229714
Validation loss: 2.5152238288882804

Epoch: 6| Step: 13
Training loss: 2.0255078656098724
Validation loss: 2.458911022458063

Epoch: 301| Step: 0
Training loss: 1.771422329355484
Validation loss: 2.4980676966621567

Epoch: 6| Step: 1
Training loss: 1.7950617390165453
Validation loss: 2.5171697377262943

Epoch: 6| Step: 2
Training loss: 2.161473898467739
Validation loss: 2.4887362608730186

Epoch: 6| Step: 3
Training loss: 1.8376149407592737
Validation loss: 2.481970995011016

Epoch: 6| Step: 4
Training loss: 1.0611854162435566
Validation loss: 2.4973668208153215

Epoch: 6| Step: 5
Training loss: 2.4414414059968785
Validation loss: 2.5119781128027356

Epoch: 6| Step: 6
Training loss: 1.7480144817398373
Validation loss: 2.474368335231354

Epoch: 6| Step: 7
Training loss: 2.3641868180429206
Validation loss: 2.4953995902782524

Epoch: 6| Step: 8
Training loss: 2.1840030511757913
Validation loss: 2.4766026980765097

Epoch: 6| Step: 9
Training loss: 1.9690692582201375
Validation loss: 2.4497284144765716

Epoch: 6| Step: 10
Training loss: 2.3509847241696
Validation loss: 2.4975843223169014

Epoch: 6| Step: 11
Training loss: 2.372062070603734
Validation loss: 2.5176080388052413

Epoch: 6| Step: 12
Training loss: 2.815698119303249
Validation loss: 2.453686742538443

Epoch: 6| Step: 13
Training loss: 1.8911488335397495
Validation loss: 2.472170416589629

Epoch: 302| Step: 0
Training loss: 1.7670579345048323
Validation loss: 2.4547791655292928

Epoch: 6| Step: 1
Training loss: 1.9309160900642204
Validation loss: 2.4664760764849634

Epoch: 6| Step: 2
Training loss: 1.8872003986987267
Validation loss: 2.4805135934587477

Epoch: 6| Step: 3
Training loss: 2.0019282344108147
Validation loss: 2.5023962206819084

Epoch: 6| Step: 4
Training loss: 1.8154199691274304
Validation loss: 2.4640143964478995

Epoch: 6| Step: 5
Training loss: 2.104991058910527
Validation loss: 2.478587947426956

Epoch: 6| Step: 6
Training loss: 2.4757084381673438
Validation loss: 2.460528105373055

Epoch: 6| Step: 7
Training loss: 1.9852967411846703
Validation loss: 2.480318453027679

Epoch: 6| Step: 8
Training loss: 2.3444523076994748
Validation loss: 2.4656515640451286

Epoch: 6| Step: 9
Training loss: 1.816064552243741
Validation loss: 2.4979225797466125

Epoch: 6| Step: 10
Training loss: 2.1566093255998315
Validation loss: 2.477049712656838

Epoch: 6| Step: 11
Training loss: 2.379965560407458
Validation loss: 2.4758851978853524

Epoch: 6| Step: 12
Training loss: 2.108866312361475
Validation loss: 2.46664377909748

Epoch: 6| Step: 13
Training loss: 2.430223608207416
Validation loss: 2.457913863690766

Epoch: 303| Step: 0
Training loss: 2.3957757251834777
Validation loss: 2.5162242689493506

Epoch: 6| Step: 1
Training loss: 2.0052315714757034
Validation loss: 2.4591725646130436

Epoch: 6| Step: 2
Training loss: 2.8046047017831515
Validation loss: 2.4442547845847944

Epoch: 6| Step: 3
Training loss: 2.1250344441932154
Validation loss: 2.43598312222282

Epoch: 6| Step: 4
Training loss: 1.893314938567803
Validation loss: 2.4725298965643856

Epoch: 6| Step: 5
Training loss: 2.4414929672099297
Validation loss: 2.4951725013859094

Epoch: 6| Step: 6
Training loss: 1.7265953647713475
Validation loss: 2.4900113101456416

Epoch: 6| Step: 7
Training loss: 2.311048000291136
Validation loss: 2.447281327770245

Epoch: 6| Step: 8
Training loss: 2.078082435573552
Validation loss: 2.4751983350146447

Epoch: 6| Step: 9
Training loss: 1.3310197138512199
Validation loss: 2.4727885509884935

Epoch: 6| Step: 10
Training loss: 1.7006035434612856
Validation loss: 2.5078262923167465

Epoch: 6| Step: 11
Training loss: 2.011900069574434
Validation loss: 2.500973392000272

Epoch: 6| Step: 12
Training loss: 1.981966253830585
Validation loss: 2.4672016663900465

Epoch: 6| Step: 13
Training loss: 2.1601771100159732
Validation loss: 2.450458020292328

Epoch: 304| Step: 0
Training loss: 1.382482801885711
Validation loss: 2.490970642255596

Epoch: 6| Step: 1
Training loss: 1.5634916591928076
Validation loss: 2.4683662517133684

Epoch: 6| Step: 2
Training loss: 1.8647270431404461
Validation loss: 2.4791702480054183

Epoch: 6| Step: 3
Training loss: 1.9949393620274536
Validation loss: 2.4899677115979864

Epoch: 6| Step: 4
Training loss: 1.797001179121052
Validation loss: 2.469719442668707

Epoch: 6| Step: 5
Training loss: 2.147426741996954
Validation loss: 2.488326270502906

Epoch: 6| Step: 6
Training loss: 2.406922580800438
Validation loss: 2.4939629953256146

Epoch: 6| Step: 7
Training loss: 2.516339692186285
Validation loss: 2.495442516565248

Epoch: 6| Step: 8
Training loss: 2.951881106352361
Validation loss: 2.4592735726911243

Epoch: 6| Step: 9
Training loss: 2.154889437678171
Validation loss: 2.483622539106845

Epoch: 6| Step: 10
Training loss: 1.683475003402756
Validation loss: 2.5138887520480746

Epoch: 6| Step: 11
Training loss: 2.46248033389841
Validation loss: 2.49116516952384

Epoch: 6| Step: 12
Training loss: 1.626380554049004
Validation loss: 2.499225330821426

Epoch: 6| Step: 13
Training loss: 2.059580383710262
Validation loss: 2.4687470653761046

Epoch: 305| Step: 0
Training loss: 1.7679419380208075
Validation loss: 2.4638301071130098

Epoch: 6| Step: 1
Training loss: 1.7082584953973354
Validation loss: 2.4926602178890054

Epoch: 6| Step: 2
Training loss: 2.7476862797575294
Validation loss: 2.4859436349820205

Epoch: 6| Step: 3
Training loss: 2.169913744288885
Validation loss: 2.4544540722796238

Epoch: 6| Step: 4
Training loss: 2.122433065700232
Validation loss: 2.478584657268831

Epoch: 6| Step: 5
Training loss: 1.7966876388392106
Validation loss: 2.4376715038913965

Epoch: 6| Step: 6
Training loss: 2.138299723257227
Validation loss: 2.470023523914236

Epoch: 6| Step: 7
Training loss: 1.749163700275108
Validation loss: 2.4844293890884144

Epoch: 6| Step: 8
Training loss: 2.1583591042333867
Validation loss: 2.4904232512492404

Epoch: 6| Step: 9
Training loss: 1.7220644810264056
Validation loss: 2.491573232707786

Epoch: 6| Step: 10
Training loss: 1.9252904301316323
Validation loss: 2.515170184195663

Epoch: 6| Step: 11
Training loss: 2.003488121505874
Validation loss: 2.50591085886511

Epoch: 6| Step: 12
Training loss: 2.3047708787221697
Validation loss: 2.4755407096360837

Epoch: 6| Step: 13
Training loss: 2.733002061850771
Validation loss: 2.4761582263250284

Epoch: 306| Step: 0
Training loss: 2.2416238641256863
Validation loss: 2.483557444503352

Epoch: 6| Step: 1
Training loss: 2.2025857901345938
Validation loss: 2.4685419191474325

Epoch: 6| Step: 2
Training loss: 2.500416816296536
Validation loss: 2.496593800580035

Epoch: 6| Step: 3
Training loss: 2.140034949293585
Validation loss: 2.4823168092567096

Epoch: 6| Step: 4
Training loss: 1.7466897992550874
Validation loss: 2.449915377637354

Epoch: 6| Step: 5
Training loss: 1.7088218393691117
Validation loss: 2.485203966942716

Epoch: 6| Step: 6
Training loss: 1.9005100569485287
Validation loss: 2.501944207405186

Epoch: 6| Step: 7
Training loss: 2.503472205761824
Validation loss: 2.4530352295250677

Epoch: 6| Step: 8
Training loss: 1.6432606915222319
Validation loss: 2.505312185637994

Epoch: 6| Step: 9
Training loss: 2.023172132846332
Validation loss: 2.490935454569749

Epoch: 6| Step: 10
Training loss: 1.6796026873800314
Validation loss: 2.4996098336966845

Epoch: 6| Step: 11
Training loss: 2.497261359313921
Validation loss: 2.5028385926147396

Epoch: 6| Step: 12
Training loss: 1.8182045187399993
Validation loss: 2.441953898380068

Epoch: 6| Step: 13
Training loss: 1.7077018764786882
Validation loss: 2.4565569623010224

Epoch: 307| Step: 0
Training loss: 1.7704485606122324
Validation loss: 2.483295701804341

Epoch: 6| Step: 1
Training loss: 1.717978842004379
Validation loss: 2.492464226926699

Epoch: 6| Step: 2
Training loss: 2.3035223650433445
Validation loss: 2.4936858322799265

Epoch: 6| Step: 3
Training loss: 1.8201407159127194
Validation loss: 2.5057534677962194

Epoch: 6| Step: 4
Training loss: 1.3865864435397908
Validation loss: 2.527604056288438

Epoch: 6| Step: 5
Training loss: 2.1454769196541252
Validation loss: 2.4651855088288603

Epoch: 6| Step: 6
Training loss: 2.11063048122825
Validation loss: 2.482799916880307

Epoch: 6| Step: 7
Training loss: 2.388648718458893
Validation loss: 2.47255746312029

Epoch: 6| Step: 8
Training loss: 1.9816874529574804
Validation loss: 2.4550188742221346

Epoch: 6| Step: 9
Training loss: 1.6203736693737214
Validation loss: 2.525016905797966

Epoch: 6| Step: 10
Training loss: 2.3475792692895685
Validation loss: 2.4925168987557926

Epoch: 6| Step: 11
Training loss: 2.215451649931362
Validation loss: 2.4564161449715334

Epoch: 6| Step: 12
Training loss: 2.589988094582314
Validation loss: 2.473004192990718

Epoch: 6| Step: 13
Training loss: 2.383505698509118
Validation loss: 2.5095026429327927

Epoch: 308| Step: 0
Training loss: 2.3948035528732308
Validation loss: 2.476784608652455

Epoch: 6| Step: 1
Training loss: 2.5520718217447382
Validation loss: 2.5067616340197723

Epoch: 6| Step: 2
Training loss: 1.8018786878280135
Validation loss: 2.5311797727431276

Epoch: 6| Step: 3
Training loss: 1.9333636522656195
Validation loss: 2.4716992320111943

Epoch: 6| Step: 4
Training loss: 2.340235605686853
Validation loss: 2.4689056006841037

Epoch: 6| Step: 5
Training loss: 1.970042697424422
Validation loss: 2.5075135340165007

Epoch: 6| Step: 6
Training loss: 1.6982339745839
Validation loss: 2.4423223090279604

Epoch: 6| Step: 7
Training loss: 2.4007924599452535
Validation loss: 2.4889182827199474

Epoch: 6| Step: 8
Training loss: 2.566851015612815
Validation loss: 2.4688475000129873

Epoch: 6| Step: 9
Training loss: 1.537745032905119
Validation loss: 2.4756404689397455

Epoch: 6| Step: 10
Training loss: 1.7072350142526895
Validation loss: 2.4801055448502707

Epoch: 6| Step: 11
Training loss: 1.6895541651505404
Validation loss: 2.478062405918357

Epoch: 6| Step: 12
Training loss: 2.114920102317005
Validation loss: 2.5037790141703957

Epoch: 6| Step: 13
Training loss: 1.898400639933604
Validation loss: 2.450955177150885

Epoch: 309| Step: 0
Training loss: 2.259544368320943
Validation loss: 2.4424415721012123

Epoch: 6| Step: 1
Training loss: 1.7319481168556927
Validation loss: 2.492887758796002

Epoch: 6| Step: 2
Training loss: 1.6642660813427812
Validation loss: 2.4745301400693673

Epoch: 6| Step: 3
Training loss: 2.583825946313626
Validation loss: 2.4896200078410904

Epoch: 6| Step: 4
Training loss: 1.797797322944382
Validation loss: 2.420133619754456

Epoch: 6| Step: 5
Training loss: 2.002797078207028
Validation loss: 2.501788636729977

Epoch: 6| Step: 6
Training loss: 2.174963532065356
Validation loss: 2.4774695716622523

Epoch: 6| Step: 7
Training loss: 1.602911553106571
Validation loss: 2.4663527783984454

Epoch: 6| Step: 8
Training loss: 1.5877987317736686
Validation loss: 2.4603594784618563

Epoch: 6| Step: 9
Training loss: 2.0999110657161735
Validation loss: 2.483982796389661

Epoch: 6| Step: 10
Training loss: 2.3074351338602472
Validation loss: 2.4665635742449243

Epoch: 6| Step: 11
Training loss: 1.657019814142012
Validation loss: 2.479645048420215

Epoch: 6| Step: 12
Training loss: 2.9060110998919657
Validation loss: 2.5227996295290063

Epoch: 6| Step: 13
Training loss: 2.535915737093973
Validation loss: 2.4581431566792147

Epoch: 310| Step: 0
Training loss: 2.6498337387614743
Validation loss: 2.4899714036974703

Epoch: 6| Step: 1
Training loss: 2.0474535874170514
Validation loss: 2.473901751680244

Epoch: 6| Step: 2
Training loss: 1.6503800792470023
Validation loss: 2.505574592541234

Epoch: 6| Step: 3
Training loss: 1.8628190145009076
Validation loss: 2.4744216051687253

Epoch: 6| Step: 4
Training loss: 2.193143920642882
Validation loss: 2.4784709326114727

Epoch: 6| Step: 5
Training loss: 2.0332923598408463
Validation loss: 2.47063127528582

Epoch: 6| Step: 6
Training loss: 2.2473141215923507
Validation loss: 2.4928187441601404

Epoch: 6| Step: 7
Training loss: 2.4642965976008786
Validation loss: 2.481731010619975

Epoch: 6| Step: 8
Training loss: 1.8949052264587647
Validation loss: 2.4277697416478707

Epoch: 6| Step: 9
Training loss: 1.6348582324706629
Validation loss: 2.4725617856926165

Epoch: 6| Step: 10
Training loss: 1.6440544977738392
Validation loss: 2.4940883698357874

Epoch: 6| Step: 11
Training loss: 1.9493282187995316
Validation loss: 2.5167729922546727

Epoch: 6| Step: 12
Training loss: 1.9951891258292154
Validation loss: 2.4706018765247197

Epoch: 6| Step: 13
Training loss: 2.4082258955102516
Validation loss: 2.4790417777709646

Epoch: 311| Step: 0
Training loss: 2.5789124182228944
Validation loss: 2.465866061736251

Epoch: 6| Step: 1
Training loss: 2.1459661522904137
Validation loss: 2.5017854324187563

Epoch: 6| Step: 2
Training loss: 1.7614365582179532
Validation loss: 2.4739256055617673

Epoch: 6| Step: 3
Training loss: 1.6514051580772864
Validation loss: 2.5039963436538373

Epoch: 6| Step: 4
Training loss: 2.010879489681439
Validation loss: 2.476011974410991

Epoch: 6| Step: 5
Training loss: 2.0839727056403605
Validation loss: 2.485908970150552

Epoch: 6| Step: 6
Training loss: 2.057869191934828
Validation loss: 2.5011471352008345

Epoch: 6| Step: 7
Training loss: 1.5028513193302575
Validation loss: 2.4706420180113984

Epoch: 6| Step: 8
Training loss: 2.051659619370646
Validation loss: 2.508007349819462

Epoch: 6| Step: 9
Training loss: 1.8481837481390686
Validation loss: 2.49081827156638

Epoch: 6| Step: 10
Training loss: 1.4318647638535325
Validation loss: 2.471075312586984

Epoch: 6| Step: 11
Training loss: 2.5665011918202465
Validation loss: 2.4881822808462473

Epoch: 6| Step: 12
Training loss: 2.345404486024525
Validation loss: 2.479286375711992

Epoch: 6| Step: 13
Training loss: 2.3989881448774804
Validation loss: 2.4893835743356174

Epoch: 312| Step: 0
Training loss: 2.2232908606678414
Validation loss: 2.50676183855781

Epoch: 6| Step: 1
Training loss: 1.7265446864801506
Validation loss: 2.481175420529924

Epoch: 6| Step: 2
Training loss: 2.541834612024404
Validation loss: 2.492846256042418

Epoch: 6| Step: 3
Training loss: 1.9766886674622615
Validation loss: 2.4981692609676074

Epoch: 6| Step: 4
Training loss: 2.466911500516262
Validation loss: 2.5074027430182713

Epoch: 6| Step: 5
Training loss: 2.007308956191216
Validation loss: 2.5127867070875176

Epoch: 6| Step: 6
Training loss: 1.5867025850675618
Validation loss: 2.5532661019340037

Epoch: 6| Step: 7
Training loss: 1.6132750430230172
Validation loss: 2.449558042024819

Epoch: 6| Step: 8
Training loss: 1.9535630612257673
Validation loss: 2.4943943951193934

Epoch: 6| Step: 9
Training loss: 1.7900040327058684
Validation loss: 2.4279557375332135

Epoch: 6| Step: 10
Training loss: 2.0664630153769745
Validation loss: 2.45850653339796

Epoch: 6| Step: 11
Training loss: 2.205705686862344
Validation loss: 2.4919297871396946

Epoch: 6| Step: 12
Training loss: 1.6548597150739717
Validation loss: 2.4715531627802014

Epoch: 6| Step: 13
Training loss: 3.3424605976256005
Validation loss: 2.4935158760001666

Epoch: 313| Step: 0
Training loss: 1.8092864915879348
Validation loss: 2.476683255819662

Epoch: 6| Step: 1
Training loss: 2.2754111620586066
Validation loss: 2.516153522466402

Epoch: 6| Step: 2
Training loss: 1.943023867375613
Validation loss: 2.4682959017841144

Epoch: 6| Step: 3
Training loss: 2.122976349305831
Validation loss: 2.4453449537386898

Epoch: 6| Step: 4
Training loss: 2.3365532819344925
Validation loss: 2.478008920950739

Epoch: 6| Step: 5
Training loss: 2.1570061726064
Validation loss: 2.48637809239538

Epoch: 6| Step: 6
Training loss: 1.6118136697426406
Validation loss: 2.509428610474409

Epoch: 6| Step: 7
Training loss: 1.820343148296845
Validation loss: 2.495776912373259

Epoch: 6| Step: 8
Training loss: 2.5482546574098968
Validation loss: 2.5109585477721486

Epoch: 6| Step: 9
Training loss: 2.62125138151308
Validation loss: 2.4961295489827937

Epoch: 6| Step: 10
Training loss: 1.9350467655533652
Validation loss: 2.435633171396003

Epoch: 6| Step: 11
Training loss: 1.9693634651739724
Validation loss: 2.5085714732330513

Epoch: 6| Step: 12
Training loss: 1.459458852315324
Validation loss: 2.471657185216616

Epoch: 6| Step: 13
Training loss: 2.256428013592209
Validation loss: 2.4938399480490667

Epoch: 314| Step: 0
Training loss: 1.4610252150044447
Validation loss: 2.4391305800326055

Epoch: 6| Step: 1
Training loss: 2.0416161926673735
Validation loss: 2.486373775283396

Epoch: 6| Step: 2
Training loss: 1.8386061731824728
Validation loss: 2.499861320627982

Epoch: 6| Step: 3
Training loss: 2.2150898145803737
Validation loss: 2.5316403805891907

Epoch: 6| Step: 4
Training loss: 1.7753009836460942
Validation loss: 2.5087639613129187

Epoch: 6| Step: 5
Training loss: 2.026523431476368
Validation loss: 2.467814870032422

Epoch: 6| Step: 6
Training loss: 2.526967511480341
Validation loss: 2.508167917247316

Epoch: 6| Step: 7
Training loss: 2.3353267624015106
Validation loss: 2.487634692619165

Epoch: 6| Step: 8
Training loss: 2.4553667261506367
Validation loss: 2.4970552960215633

Epoch: 6| Step: 9
Training loss: 2.1243478110790908
Validation loss: 2.5033918997281868

Epoch: 6| Step: 10
Training loss: 2.190679365019506
Validation loss: 2.4647626555203903

Epoch: 6| Step: 11
Training loss: 2.0089711212011765
Validation loss: 2.4751309452694925

Epoch: 6| Step: 12
Training loss: 1.6199716384194653
Validation loss: 2.4933756833967986

Epoch: 6| Step: 13
Training loss: 2.1396883286588326
Validation loss: 2.4588491928551743

Epoch: 315| Step: 0
Training loss: 1.6776866262122627
Validation loss: 2.504116102092405

Epoch: 6| Step: 1
Training loss: 1.8147120953090834
Validation loss: 2.4167334036758277

Epoch: 6| Step: 2
Training loss: 2.1317899719119806
Validation loss: 2.477151151917682

Epoch: 6| Step: 3
Training loss: 2.0969948747142033
Validation loss: 2.5181955879784925

Epoch: 6| Step: 4
Training loss: 2.2441221390801935
Validation loss: 2.483304905224577

Epoch: 6| Step: 5
Training loss: 2.0817307475448015
Validation loss: 2.4983703121160445

Epoch: 6| Step: 6
Training loss: 1.6805714255320114
Validation loss: 2.4763775315803582

Epoch: 6| Step: 7
Training loss: 1.9951488550243148
Validation loss: 2.481726815582973

Epoch: 6| Step: 8
Training loss: 1.4124136316006237
Validation loss: 2.4922204203358027

Epoch: 6| Step: 9
Training loss: 2.644761226238985
Validation loss: 2.5100712699202736

Epoch: 6| Step: 10
Training loss: 2.1831641687373606
Validation loss: 2.498745969843482

Epoch: 6| Step: 11
Training loss: 2.8459477578017345
Validation loss: 2.5099932422815794

Epoch: 6| Step: 12
Training loss: 1.8755105912863685
Validation loss: 2.4586401145386443

Epoch: 6| Step: 13
Training loss: 1.9390603827035366
Validation loss: 2.480042393307495

Epoch: 316| Step: 0
Training loss: 1.9720833428008966
Validation loss: 2.4557677435277268

Epoch: 6| Step: 1
Training loss: 2.1367258912129294
Validation loss: 2.468839716186527

Epoch: 6| Step: 2
Training loss: 1.9631912229019983
Validation loss: 2.4725785346817832

Epoch: 6| Step: 3
Training loss: 1.8536734478629875
Validation loss: 2.4670818919190416

Epoch: 6| Step: 4
Training loss: 2.1155114102543866
Validation loss: 2.469107004305441

Epoch: 6| Step: 5
Training loss: 2.276939395451509
Validation loss: 2.515310950788372

Epoch: 6| Step: 6
Training loss: 1.8316458030232112
Validation loss: 2.4547053061275284

Epoch: 6| Step: 7
Training loss: 1.9993500845651406
Validation loss: 2.48887883771415

Epoch: 6| Step: 8
Training loss: 2.730820705449422
Validation loss: 2.462541942198646

Epoch: 6| Step: 9
Training loss: 1.7943227139425113
Validation loss: 2.4999335198125734

Epoch: 6| Step: 10
Training loss: 1.9240795610200243
Validation loss: 2.478381270265907

Epoch: 6| Step: 11
Training loss: 1.7921127902408782
Validation loss: 2.483488181938722

Epoch: 6| Step: 12
Training loss: 2.1711307046167305
Validation loss: 2.5296315141459362

Epoch: 6| Step: 13
Training loss: 1.6383188660850534
Validation loss: 2.471580934195271

Epoch: 317| Step: 0
Training loss: 1.8144560157908889
Validation loss: 2.4850029879491156

Epoch: 6| Step: 1
Training loss: 1.8897530302529857
Validation loss: 2.5225714441845053

Epoch: 6| Step: 2
Training loss: 2.0134408635145857
Validation loss: 2.4358981432524907

Epoch: 6| Step: 3
Training loss: 2.326835736177321
Validation loss: 2.510413761687833

Epoch: 6| Step: 4
Training loss: 2.0069960778563476
Validation loss: 2.499288846972884

Epoch: 6| Step: 5
Training loss: 1.7233392654602149
Validation loss: 2.507842712762149

Epoch: 6| Step: 6
Training loss: 2.2533328485582422
Validation loss: 2.4871161918514697

Epoch: 6| Step: 7
Training loss: 2.4481686617960663
Validation loss: 2.491779983412559

Epoch: 6| Step: 8
Training loss: 2.6127572439478572
Validation loss: 2.496833040759986

Epoch: 6| Step: 9
Training loss: 1.4515676048690005
Validation loss: 2.4637717223470825

Epoch: 6| Step: 10
Training loss: 1.9021981749557035
Validation loss: 2.4735135909329897

Epoch: 6| Step: 11
Training loss: 2.163531186539587
Validation loss: 2.4607599009756584

Epoch: 6| Step: 12
Training loss: 1.9604413746145997
Validation loss: 2.46904328902816

Epoch: 6| Step: 13
Training loss: 1.9528947618201624
Validation loss: 2.477496305625423

Epoch: 318| Step: 0
Training loss: 1.686080830361659
Validation loss: 2.488374842485365

Epoch: 6| Step: 1
Training loss: 1.7231919197534171
Validation loss: 2.477029338921496

Epoch: 6| Step: 2
Training loss: 2.3192929683519665
Validation loss: 2.478711292624743

Epoch: 6| Step: 3
Training loss: 2.3219219752369233
Validation loss: 2.452707494568402

Epoch: 6| Step: 4
Training loss: 2.5469358472049963
Validation loss: 2.5159705975653806

Epoch: 6| Step: 5
Training loss: 1.878101517567002
Validation loss: 2.4321803328583087

Epoch: 6| Step: 6
Training loss: 1.5818766200472925
Validation loss: 2.4726124086834793

Epoch: 6| Step: 7
Training loss: 1.9908411001525257
Validation loss: 2.4932991876392316

Epoch: 6| Step: 8
Training loss: 2.3151520651520565
Validation loss: 2.5039143978365987

Epoch: 6| Step: 9
Training loss: 1.7833393625650655
Validation loss: 2.49278127683214

Epoch: 6| Step: 10
Training loss: 2.0203468549953856
Validation loss: 2.5048137732119913

Epoch: 6| Step: 11
Training loss: 1.8989149835367347
Validation loss: 2.5027364357171153

Epoch: 6| Step: 12
Training loss: 2.4779125108091216
Validation loss: 2.503854576454191

Epoch: 6| Step: 13
Training loss: 2.0188151109901225
Validation loss: 2.476606959761044

Epoch: 319| Step: 0
Training loss: 1.7848591296389862
Validation loss: 2.529246177328366

Epoch: 6| Step: 1
Training loss: 2.106728935689563
Validation loss: 2.48081490282511

Epoch: 6| Step: 2
Training loss: 2.3077616216569203
Validation loss: 2.490332339195849

Epoch: 6| Step: 3
Training loss: 1.858997659301105
Validation loss: 2.460699157580062

Epoch: 6| Step: 4
Training loss: 1.6927069404791946
Validation loss: 2.463365670060091

Epoch: 6| Step: 5
Training loss: 1.7256195116905688
Validation loss: 2.4566048068279964

Epoch: 6| Step: 6
Training loss: 1.8877136892656659
Validation loss: 2.49401841704317

Epoch: 6| Step: 7
Training loss: 2.4242823295849014
Validation loss: 2.47975174295923

Epoch: 6| Step: 8
Training loss: 3.014834285502765
Validation loss: 2.53391708122063

Epoch: 6| Step: 9
Training loss: 1.6202744953109116
Validation loss: 2.47986181855158

Epoch: 6| Step: 10
Training loss: 1.4957446296056083
Validation loss: 2.508787708530147

Epoch: 6| Step: 11
Training loss: 2.3144806292867317
Validation loss: 2.5003308374679065

Epoch: 6| Step: 12
Training loss: 1.9039318184746072
Validation loss: 2.470114837820947

Epoch: 6| Step: 13
Training loss: 1.763264115723131
Validation loss: 2.5100264458937547

Epoch: 320| Step: 0
Training loss: 1.9219226986308084
Validation loss: 2.4598872258673206

Epoch: 6| Step: 1
Training loss: 2.3646357414274677
Validation loss: 2.4753854763181207

Epoch: 6| Step: 2
Training loss: 2.2420369273810445
Validation loss: 2.5052689127189187

Epoch: 6| Step: 3
Training loss: 2.224789204416759
Validation loss: 2.475567926814348

Epoch: 6| Step: 4
Training loss: 1.7013890229655448
Validation loss: 2.475056107917681

Epoch: 6| Step: 5
Training loss: 1.6555551474881505
Validation loss: 2.4492977633518036

Epoch: 6| Step: 6
Training loss: 2.1133646217019613
Validation loss: 2.4529526629531295

Epoch: 6| Step: 7
Training loss: 2.1546775502285684
Validation loss: 2.4815049447322215

Epoch: 6| Step: 8
Training loss: 2.065056805510529
Validation loss: 2.5165567213377993

Epoch: 6| Step: 9
Training loss: 2.2641816902247216
Validation loss: 2.499394421398669

Epoch: 6| Step: 10
Training loss: 1.756492559984599
Validation loss: 2.4750376039616757

Epoch: 6| Step: 11
Training loss: 2.2845630364841494
Validation loss: 2.4943052876991882

Epoch: 6| Step: 12
Training loss: 1.7425371169921917
Validation loss: 2.440890499118841

Epoch: 6| Step: 13
Training loss: 1.7196358911893534
Validation loss: 2.4564114015741403

Epoch: 321| Step: 0
Training loss: 2.357284023549535
Validation loss: 2.4702321145864223

Epoch: 6| Step: 1
Training loss: 1.9628243050829872
Validation loss: 2.493289759943773

Epoch: 6| Step: 2
Training loss: 1.6453534967978913
Validation loss: 2.4767682876455384

Epoch: 6| Step: 3
Training loss: 2.2970611081661843
Validation loss: 2.4694025006312152

Epoch: 6| Step: 4
Training loss: 2.2732231327467356
Validation loss: 2.4940446338947777

Epoch: 6| Step: 5
Training loss: 2.197937180361604
Validation loss: 2.4709743102063295

Epoch: 6| Step: 6
Training loss: 1.8010055832551264
Validation loss: 2.491249099391364

Epoch: 6| Step: 7
Training loss: 1.6103022598482901
Validation loss: 2.467111700475959

Epoch: 6| Step: 8
Training loss: 2.291164227517542
Validation loss: 2.477897130443673

Epoch: 6| Step: 9
Training loss: 1.6911839433782998
Validation loss: 2.528341640252431

Epoch: 6| Step: 10
Training loss: 2.077459128261239
Validation loss: 2.491330510981784

Epoch: 6| Step: 11
Training loss: 2.1481024463525094
Validation loss: 2.4787739392422563

Epoch: 6| Step: 12
Training loss: 2.2620835611237053
Validation loss: 2.513097344254508

Epoch: 6| Step: 13
Training loss: 1.5277707022686118
Validation loss: 2.473958950247739

Epoch: 322| Step: 0
Training loss: 2.124949735159193
Validation loss: 2.490871378565186

Epoch: 6| Step: 1
Training loss: 1.3925831755858185
Validation loss: 2.436268481942738

Epoch: 6| Step: 2
Training loss: 1.7316748417993915
Validation loss: 2.526073965498963

Epoch: 6| Step: 3
Training loss: 1.9533714444128163
Validation loss: 2.5052800748459116

Epoch: 6| Step: 4
Training loss: 1.8194988216722348
Validation loss: 2.4686107604020164

Epoch: 6| Step: 5
Training loss: 2.4201149728749654
Validation loss: 2.4533629800018195

Epoch: 6| Step: 6
Training loss: 2.1086023116388453
Validation loss: 2.4703774581894717

Epoch: 6| Step: 7
Training loss: 2.1591348561464074
Validation loss: 2.4734680784993044

Epoch: 6| Step: 8
Training loss: 1.9526088795605474
Validation loss: 2.5073481702902196

Epoch: 6| Step: 9
Training loss: 2.072673444680196
Validation loss: 2.513441986867685

Epoch: 6| Step: 10
Training loss: 2.4130458234094982
Validation loss: 2.443703591909746

Epoch: 6| Step: 11
Training loss: 1.6218167450720034
Validation loss: 2.4605610408642526

Epoch: 6| Step: 12
Training loss: 2.002666126842062
Validation loss: 2.448275224393468

Epoch: 6| Step: 13
Training loss: 2.6395675076615186
Validation loss: 2.4914577003333327

Epoch: 323| Step: 0
Training loss: 1.8079650972761476
Validation loss: 2.475176248979746

Epoch: 6| Step: 1
Training loss: 1.539090074011398
Validation loss: 2.477397754688894

Epoch: 6| Step: 2
Training loss: 2.1870160248652906
Validation loss: 2.5080233223886856

Epoch: 6| Step: 3
Training loss: 2.5009346168632054
Validation loss: 2.4820334209477175

Epoch: 6| Step: 4
Training loss: 2.496983424805796
Validation loss: 2.5152692126014213

Epoch: 6| Step: 5
Training loss: 1.8713176171286439
Validation loss: 2.454841503883768

Epoch: 6| Step: 6
Training loss: 2.7851977672933375
Validation loss: 2.4801320617546767

Epoch: 6| Step: 7
Training loss: 1.1783282299461801
Validation loss: 2.486557801126277

Epoch: 6| Step: 8
Training loss: 1.969774736412017
Validation loss: 2.5113100295279835

Epoch: 6| Step: 9
Training loss: 1.835398233633614
Validation loss: 2.451361348329601

Epoch: 6| Step: 10
Training loss: 2.260559206451537
Validation loss: 2.539737438927683

Epoch: 6| Step: 11
Training loss: 1.5625007629392669
Validation loss: 2.4868169242734783

Epoch: 6| Step: 12
Training loss: 2.2236199460266755
Validation loss: 2.5193481673870717

Epoch: 6| Step: 13
Training loss: 1.2955722010113706
Validation loss: 2.4740609089560173

Epoch: 324| Step: 0
Training loss: 1.7919063703480698
Validation loss: 2.462193444289128

Epoch: 6| Step: 1
Training loss: 1.995468370149191
Validation loss: 2.4696966806618414

Epoch: 6| Step: 2
Training loss: 1.9931946845087671
Validation loss: 2.4807277341088176

Epoch: 6| Step: 3
Training loss: 2.709340617347798
Validation loss: 2.512691823156498

Epoch: 6| Step: 4
Training loss: 1.699671612605871
Validation loss: 2.4820567060666447

Epoch: 6| Step: 5
Training loss: 2.047111089937397
Validation loss: 2.520079213058946

Epoch: 6| Step: 6
Training loss: 1.7997587201214156
Validation loss: 2.4865866137957036

Epoch: 6| Step: 7
Training loss: 1.7561188401086973
Validation loss: 2.5066877957202793

Epoch: 6| Step: 8
Training loss: 2.055717529181462
Validation loss: 2.495392462536387

Epoch: 6| Step: 9
Training loss: 2.112391370880873
Validation loss: 2.486517626862906

Epoch: 6| Step: 10
Training loss: 2.234852133004885
Validation loss: 2.497959447575775

Epoch: 6| Step: 11
Training loss: 2.1025474537541564
Validation loss: 2.496612224350275

Epoch: 6| Step: 12
Training loss: 2.1629146465051288
Validation loss: 2.4799870608642567

Epoch: 6| Step: 13
Training loss: 2.1385940607276526
Validation loss: 2.503623000465913

Epoch: 325| Step: 0
Training loss: 2.1330052103586135
Validation loss: 2.471388317127948

Epoch: 6| Step: 1
Training loss: 1.9540999763783542
Validation loss: 2.399314641684264

Epoch: 6| Step: 2
Training loss: 1.9413075105360993
Validation loss: 2.448236975902435

Epoch: 6| Step: 3
Training loss: 2.343682758638299
Validation loss: 2.452601432119777

Epoch: 6| Step: 4
Training loss: 1.9080756778383814
Validation loss: 2.4939353148434797

Epoch: 6| Step: 5
Training loss: 2.921808089035841
Validation loss: 2.474164356575764

Epoch: 6| Step: 6
Training loss: 1.6528303002668188
Validation loss: 2.4578526911521785

Epoch: 6| Step: 7
Training loss: 2.226322843804598
Validation loss: 2.467302117177265

Epoch: 6| Step: 8
Training loss: 1.919361362539255
Validation loss: 2.466160175039097

Epoch: 6| Step: 9
Training loss: 1.6995718052086475
Validation loss: 2.4956261962426893

Epoch: 6| Step: 10
Training loss: 2.120641277238396
Validation loss: 2.471546830306207

Epoch: 6| Step: 11
Training loss: 1.8357962046692777
Validation loss: 2.5290434393270393

Epoch: 6| Step: 12
Training loss: 1.6000386501650812
Validation loss: 2.482534734520977

Epoch: 6| Step: 13
Training loss: 1.7751758139134683
Validation loss: 2.4857826261856584

Epoch: 326| Step: 0
Training loss: 2.0790264497719404
Validation loss: 2.403236821960037

Epoch: 6| Step: 1
Training loss: 1.6351675179900218
Validation loss: 2.484535428289572

Epoch: 6| Step: 2
Training loss: 1.892701577017242
Validation loss: 2.4638134203926163

Epoch: 6| Step: 3
Training loss: 1.940784500619334
Validation loss: 2.4738734436151133

Epoch: 6| Step: 4
Training loss: 2.251945713954089
Validation loss: 2.4595341413254266

Epoch: 6| Step: 5
Training loss: 1.8059258113970633
Validation loss: 2.455439545604807

Epoch: 6| Step: 6
Training loss: 1.8480453242858044
Validation loss: 2.491527125147325

Epoch: 6| Step: 7
Training loss: 1.42271507514447
Validation loss: 2.4648346295004453

Epoch: 6| Step: 8
Training loss: 2.3627014962306445
Validation loss: 2.470360185774779

Epoch: 6| Step: 9
Training loss: 2.2722731292584957
Validation loss: 2.4575545814004385

Epoch: 6| Step: 10
Training loss: 2.4599035603917936
Validation loss: 2.473483669856585

Epoch: 6| Step: 11
Training loss: 1.983367904660973
Validation loss: 2.458892369376207

Epoch: 6| Step: 12
Training loss: 2.225210107034115
Validation loss: 2.512540872782492

Epoch: 6| Step: 13
Training loss: 2.1239473316106627
Validation loss: 2.4976271576809013

Epoch: 327| Step: 0
Training loss: 1.6746030992017056
Validation loss: 2.4926109904386826

Epoch: 6| Step: 1
Training loss: 2.195528175918597
Validation loss: 2.5027273375567227

Epoch: 6| Step: 2
Training loss: 2.187213115953635
Validation loss: 2.4909490336379205

Epoch: 6| Step: 3
Training loss: 2.01240992848012
Validation loss: 2.4572253399113158

Epoch: 6| Step: 4
Training loss: 2.0834873396852944
Validation loss: 2.4943696578234213

Epoch: 6| Step: 5
Training loss: 1.5604385510256722
Validation loss: 2.462787562619693

Epoch: 6| Step: 6
Training loss: 1.9950692670074066
Validation loss: 2.5225454780793597

Epoch: 6| Step: 7
Training loss: 1.4304662365893914
Validation loss: 2.473950622926537

Epoch: 6| Step: 8
Training loss: 2.195126888804581
Validation loss: 2.4588515491709164

Epoch: 6| Step: 9
Training loss: 1.7796164266512826
Validation loss: 2.455862865297645

Epoch: 6| Step: 10
Training loss: 1.8855114345724782
Validation loss: 2.508514986733105

Epoch: 6| Step: 11
Training loss: 2.885532822089951
Validation loss: 2.4846027682878478

Epoch: 6| Step: 12
Training loss: 2.172555830471874
Validation loss: 2.483279983130231

Epoch: 6| Step: 13
Training loss: 1.2555887693093075
Validation loss: 2.4368125118496486

Epoch: 328| Step: 0
Training loss: 1.9996674380374333
Validation loss: 2.4646815521316543

Epoch: 6| Step: 1
Training loss: 2.6629702658688954
Validation loss: 2.4718416740390725

Epoch: 6| Step: 2
Training loss: 1.9000649717164344
Validation loss: 2.516386309891342

Epoch: 6| Step: 3
Training loss: 1.7057291123096565
Validation loss: 2.4724827049597176

Epoch: 6| Step: 4
Training loss: 2.2924198877944604
Validation loss: 2.4835107339295366

Epoch: 6| Step: 5
Training loss: 2.043685058121914
Validation loss: 2.4874695414542085

Epoch: 6| Step: 6
Training loss: 1.8941137738723095
Validation loss: 2.4660617724686134

Epoch: 6| Step: 7
Training loss: 1.6544739899745167
Validation loss: 2.478473300786283

Epoch: 6| Step: 8
Training loss: 2.1136256587781945
Validation loss: 2.4949136706274717

Epoch: 6| Step: 9
Training loss: 1.946242757304784
Validation loss: 2.4947167001067707

Epoch: 6| Step: 10
Training loss: 2.8325619114896456
Validation loss: 2.456498915520707

Epoch: 6| Step: 11
Training loss: 1.461967717003458
Validation loss: 2.4968175618378607

Epoch: 6| Step: 12
Training loss: 1.3574091409868088
Validation loss: 2.445369503433131

Epoch: 6| Step: 13
Training loss: 1.8276538078615958
Validation loss: 2.450826204899485

Epoch: 329| Step: 0
Training loss: 1.6253217231945
Validation loss: 2.513382938460766

Epoch: 6| Step: 1
Training loss: 2.7277388781199403
Validation loss: 2.480214945280392

Epoch: 6| Step: 2
Training loss: 1.7260773266193732
Validation loss: 2.478485384700483

Epoch: 6| Step: 3
Training loss: 1.617750134473526
Validation loss: 2.4712957701655056

Epoch: 6| Step: 4
Training loss: 1.5614664092394774
Validation loss: 2.452949167532144

Epoch: 6| Step: 5
Training loss: 2.5039873749777275
Validation loss: 2.4752176440798097

Epoch: 6| Step: 6
Training loss: 1.9469876105252804
Validation loss: 2.4630342181288003

Epoch: 6| Step: 7
Training loss: 1.7919534705030704
Validation loss: 2.5135205908064107

Epoch: 6| Step: 8
Training loss: 2.5819612571474897
Validation loss: 2.500007513506684

Epoch: 6| Step: 9
Training loss: 2.4440066229672763
Validation loss: 2.4835926995609707

Epoch: 6| Step: 10
Training loss: 1.815353974748353
Validation loss: 2.4549344528901633

Epoch: 6| Step: 11
Training loss: 1.635591031961911
Validation loss: 2.5273726104535488

Epoch: 6| Step: 12
Training loss: 1.4546224610307417
Validation loss: 2.4545830930848838

Epoch: 6| Step: 13
Training loss: 2.325449795437139
Validation loss: 2.4666333619368968

Epoch: 330| Step: 0
Training loss: 1.7963585152761887
Validation loss: 2.4973232233881233

Epoch: 6| Step: 1
Training loss: 1.331327683237344
Validation loss: 2.4732617892572715

Epoch: 6| Step: 2
Training loss: 2.241860608452705
Validation loss: 2.4831713588598334

Epoch: 6| Step: 3
Training loss: 1.752790134155978
Validation loss: 2.4591163533959435

Epoch: 6| Step: 4
Training loss: 1.7923721949984168
Validation loss: 2.5407849003935086

Epoch: 6| Step: 5
Training loss: 2.0422967859634866
Validation loss: 2.464118657022416

Epoch: 6| Step: 6
Training loss: 2.127468470553837
Validation loss: 2.4917739513217088

Epoch: 6| Step: 7
Training loss: 2.075023889978603
Validation loss: 2.5303412223612414

Epoch: 6| Step: 8
Training loss: 1.6951336041123766
Validation loss: 2.489753549133614

Epoch: 6| Step: 9
Training loss: 2.113375339070536
Validation loss: 2.486394350322324

Epoch: 6| Step: 10
Training loss: 2.559001860939533
Validation loss: 2.4630252251983067

Epoch: 6| Step: 11
Training loss: 2.576855526114303
Validation loss: 2.4861142295655454

Epoch: 6| Step: 12
Training loss: 1.611834970001588
Validation loss: 2.522001700656999

Epoch: 6| Step: 13
Training loss: 1.7225928608483216
Validation loss: 2.4947000149695873

Epoch: 331| Step: 0
Training loss: 2.297856231567983
Validation loss: 2.479244631827645

Epoch: 6| Step: 1
Training loss: 2.5328298277500467
Validation loss: 2.4887308950901206

Epoch: 6| Step: 2
Training loss: 2.3162634871492136
Validation loss: 2.4324952948708054

Epoch: 6| Step: 3
Training loss: 2.070549602246947
Validation loss: 2.499806534039092

Epoch: 6| Step: 4
Training loss: 2.0920207155854067
Validation loss: 2.467364465389611

Epoch: 6| Step: 5
Training loss: 2.1108358340343307
Validation loss: 2.4741042324150806

Epoch: 6| Step: 6
Training loss: 2.0715360660566913
Validation loss: 2.469373396617155

Epoch: 6| Step: 7
Training loss: 2.1459275999628287
Validation loss: 2.465001228007895

Epoch: 6| Step: 8
Training loss: 1.2050024469437823
Validation loss: 2.4691544587369743

Epoch: 6| Step: 9
Training loss: 1.3469361523687915
Validation loss: 2.45514683055399

Epoch: 6| Step: 10
Training loss: 1.549357801113407
Validation loss: 2.5268970596927463

Epoch: 6| Step: 11
Training loss: 1.7796043691401866
Validation loss: 2.481402706618224

Epoch: 6| Step: 12
Training loss: 2.2467202548457017
Validation loss: 2.47561883317376

Epoch: 6| Step: 13
Training loss: 1.7304272786632622
Validation loss: 2.477964922934454

Epoch: 332| Step: 0
Training loss: 2.1648721110077247
Validation loss: 2.481289636496777

Epoch: 6| Step: 1
Training loss: 2.3847868197512287
Validation loss: 2.4469414298464685

Epoch: 6| Step: 2
Training loss: 1.7525962916325288
Validation loss: 2.4741792617534903

Epoch: 6| Step: 3
Training loss: 1.6870109414569483
Validation loss: 2.465537474712856

Epoch: 6| Step: 4
Training loss: 2.1149101819024487
Validation loss: 2.4886199725261573

Epoch: 6| Step: 5
Training loss: 2.4382730871942124
Validation loss: 2.4889246255874604

Epoch: 6| Step: 6
Training loss: 1.8751047740908664
Validation loss: 2.45321312860947

Epoch: 6| Step: 7
Training loss: 1.5614283892419898
Validation loss: 2.4805485186848535

Epoch: 6| Step: 8
Training loss: 2.1778118855320465
Validation loss: 2.5369269414942766

Epoch: 6| Step: 9
Training loss: 1.6078815382360625
Validation loss: 2.501905432968598

Epoch: 6| Step: 10
Training loss: 2.3750349343390833
Validation loss: 2.482561918909367

Epoch: 6| Step: 11
Training loss: 1.7857370579493688
Validation loss: 2.44940148073091

Epoch: 6| Step: 12
Training loss: 2.176158824327565
Validation loss: 2.481951894455392

Epoch: 6| Step: 13
Training loss: 1.952108377996929
Validation loss: 2.4700674070294357

Epoch: 333| Step: 0
Training loss: 1.675009027143607
Validation loss: 2.4900848018179826

Epoch: 6| Step: 1
Training loss: 2.3896612082055566
Validation loss: 2.4914226635845997

Epoch: 6| Step: 2
Training loss: 2.0604064025726108
Validation loss: 2.5028157968650118

Epoch: 6| Step: 3
Training loss: 2.394230336733388
Validation loss: 2.497187147709721

Epoch: 6| Step: 4
Training loss: 1.8335642307995124
Validation loss: 2.4847560339357337

Epoch: 6| Step: 5
Training loss: 1.7816350420341844
Validation loss: 2.469475170924516

Epoch: 6| Step: 6
Training loss: 2.019148592971014
Validation loss: 2.4735780834116765

Epoch: 6| Step: 7
Training loss: 1.7027345962331741
Validation loss: 2.446646062443928

Epoch: 6| Step: 8
Training loss: 2.013387931984456
Validation loss: 2.4558237558007168

Epoch: 6| Step: 9
Training loss: 1.768782771046208
Validation loss: 2.476072448792864

Epoch: 6| Step: 10
Training loss: 2.1851513924952153
Validation loss: 2.4728640069386185

Epoch: 6| Step: 11
Training loss: 2.2896831829685826
Validation loss: 2.4595456433850194

Epoch: 6| Step: 12
Training loss: 1.825494944724003
Validation loss: 2.5052557571449294

Epoch: 6| Step: 13
Training loss: 2.2507797585468854
Validation loss: 2.475449023176498

Epoch: 334| Step: 0
Training loss: 1.9018980283468123
Validation loss: 2.4766898453238047

Epoch: 6| Step: 1
Training loss: 2.0720322861383713
Validation loss: 2.4989793878389275

Epoch: 6| Step: 2
Training loss: 2.13904485367824
Validation loss: 2.4816439040405274

Epoch: 6| Step: 3
Training loss: 1.599292914791104
Validation loss: 2.4679306615639125

Epoch: 6| Step: 4
Training loss: 2.4434820277031406
Validation loss: 2.4620851267080544

Epoch: 6| Step: 5
Training loss: 1.9782560428646163
Validation loss: 2.5060920660046486

Epoch: 6| Step: 6
Training loss: 2.102815049161824
Validation loss: 2.4763598486134115

Epoch: 6| Step: 7
Training loss: 1.8944872034989286
Validation loss: 2.490965938414295

Epoch: 6| Step: 8
Training loss: 1.6956047122696363
Validation loss: 2.4941880327813

Epoch: 6| Step: 9
Training loss: 2.3845685647812314
Validation loss: 2.485396634524077

Epoch: 6| Step: 10
Training loss: 1.6845451905961937
Validation loss: 2.505351627728693

Epoch: 6| Step: 11
Training loss: 2.011362699832708
Validation loss: 2.5012534885552613

Epoch: 6| Step: 12
Training loss: 2.306460975156405
Validation loss: 2.4681760079930646

Epoch: 6| Step: 13
Training loss: 2.401840727951437
Validation loss: 2.449087601133646

Epoch: 335| Step: 0
Training loss: 1.9110947626114483
Validation loss: 2.4685631532421035

Epoch: 6| Step: 1
Training loss: 2.206708442238768
Validation loss: 2.5191504416193724

Epoch: 6| Step: 2
Training loss: 2.767940780149487
Validation loss: 2.5053630688374695

Epoch: 6| Step: 3
Training loss: 2.047365784956286
Validation loss: 2.4508726581810847

Epoch: 6| Step: 4
Training loss: 1.4189022973951457
Validation loss: 2.5275490768642235

Epoch: 6| Step: 5
Training loss: 1.5619454734995293
Validation loss: 2.4998694283217286

Epoch: 6| Step: 6
Training loss: 2.3228002499088385
Validation loss: 2.470039326948932

Epoch: 6| Step: 7
Training loss: 2.422035851828272
Validation loss: 2.523974436027874

Epoch: 6| Step: 8
Training loss: 1.3232979512869538
Validation loss: 2.4893764139208234

Epoch: 6| Step: 9
Training loss: 1.6667378013053435
Validation loss: 2.485917212038023

Epoch: 6| Step: 10
Training loss: 1.8696639106763273
Validation loss: 2.4784116887162204

Epoch: 6| Step: 11
Training loss: 2.0658857126226535
Validation loss: 2.5085951563571305

Epoch: 6| Step: 12
Training loss: 1.6712054756984236
Validation loss: 2.508334679263043

Epoch: 6| Step: 13
Training loss: 2.2855379747612874
Validation loss: 2.5108620907940167

Epoch: 336| Step: 0
Training loss: 2.3329984106654424
Validation loss: 2.4628440345930316

Epoch: 6| Step: 1
Training loss: 1.363881500925089
Validation loss: 2.488279430514756

Epoch: 6| Step: 2
Training loss: 1.7289125493241262
Validation loss: 2.5079449938817135

Epoch: 6| Step: 3
Training loss: 1.9026574849377447
Validation loss: 2.4823079853288212

Epoch: 6| Step: 4
Training loss: 1.9196713847831925
Validation loss: 2.477874272846762

Epoch: 6| Step: 5
Training loss: 2.0558123972238675
Validation loss: 2.492020284972201

Epoch: 6| Step: 6
Training loss: 1.9737995120718266
Validation loss: 2.4458689869750456

Epoch: 6| Step: 7
Training loss: 1.8818536113231745
Validation loss: 2.4805119191686966

Epoch: 6| Step: 8
Training loss: 2.147635792356923
Validation loss: 2.489375713634652

Epoch: 6| Step: 9
Training loss: 1.8023824131212172
Validation loss: 2.4826274299505333

Epoch: 6| Step: 10
Training loss: 1.0157859087903063
Validation loss: 2.499849963044143

Epoch: 6| Step: 11
Training loss: 2.518593878439261
Validation loss: 2.4603223587548646

Epoch: 6| Step: 12
Training loss: 2.481008011478649
Validation loss: 2.4485366168912446

Epoch: 6| Step: 13
Training loss: 2.4632516788409964
Validation loss: 2.479179122395781

Epoch: 337| Step: 0
Training loss: 1.797542481218872
Validation loss: 2.498156199361326

Epoch: 6| Step: 1
Training loss: 2.0804833818838646
Validation loss: 2.4276843843591513

Epoch: 6| Step: 2
Training loss: 1.394193720641529
Validation loss: 2.435353313271056

Epoch: 6| Step: 3
Training loss: 1.9595902514823944
Validation loss: 2.4775826303861783

Epoch: 6| Step: 4
Training loss: 2.4835013526895926
Validation loss: 2.4805241631637434

Epoch: 6| Step: 5
Training loss: 1.732619763483036
Validation loss: 2.4395522036385646

Epoch: 6| Step: 6
Training loss: 2.68894883956843
Validation loss: 2.4821617972792276

Epoch: 6| Step: 7
Training loss: 1.489450951231244
Validation loss: 2.459236662805962

Epoch: 6| Step: 8
Training loss: 1.793115746948578
Validation loss: 2.4669096205835297

Epoch: 6| Step: 9
Training loss: 2.2311896179748243
Validation loss: 2.446757675604171

Epoch: 6| Step: 10
Training loss: 1.415917796997843
Validation loss: 2.5084695687126892

Epoch: 6| Step: 11
Training loss: 2.154048625237814
Validation loss: 2.4907508402360237

Epoch: 6| Step: 12
Training loss: 2.2629355417090817
Validation loss: 2.4711863011462163

Epoch: 6| Step: 13
Training loss: 1.8237756358404544
Validation loss: 2.455059738312878

Epoch: 338| Step: 0
Training loss: 2.061973388951561
Validation loss: 2.486926521182588

Epoch: 6| Step: 1
Training loss: 1.8794759096964757
Validation loss: 2.504422391451893

Epoch: 6| Step: 2
Training loss: 1.549524908165332
Validation loss: 2.4925850032927332

Epoch: 6| Step: 3
Training loss: 2.1241222139388625
Validation loss: 2.458038317242766

Epoch: 6| Step: 4
Training loss: 1.7455134782360913
Validation loss: 2.4715732108398534

Epoch: 6| Step: 5
Training loss: 2.832068965266107
Validation loss: 2.503140620028664

Epoch: 6| Step: 6
Training loss: 2.1204692560551885
Validation loss: 2.493382374787502

Epoch: 6| Step: 7
Training loss: 1.5598739681929814
Validation loss: 2.4891498687917353

Epoch: 6| Step: 8
Training loss: 1.9321303253130055
Validation loss: 2.468645737713921

Epoch: 6| Step: 9
Training loss: 2.3761652045694843
Validation loss: 2.4578039535445737

Epoch: 6| Step: 10
Training loss: 0.9133764447411836
Validation loss: 2.4845477700856002

Epoch: 6| Step: 11
Training loss: 1.5577324421015109
Validation loss: 2.4512693431448502

Epoch: 6| Step: 12
Training loss: 2.1648988725685285
Validation loss: 2.4759575898988766

Epoch: 6| Step: 13
Training loss: 2.203467159891256
Validation loss: 2.4892092994579653

Epoch: 339| Step: 0
Training loss: 2.0210587942715432
Validation loss: 2.4981220636884154

Epoch: 6| Step: 1
Training loss: 2.480646947031736
Validation loss: 2.513254751779992

Epoch: 6| Step: 2
Training loss: 2.346405457766221
Validation loss: 2.520866110261563

Epoch: 6| Step: 3
Training loss: 1.9647160331215943
Validation loss: 2.490720934785575

Epoch: 6| Step: 4
Training loss: 2.17595459608785
Validation loss: 2.519124782189463

Epoch: 6| Step: 5
Training loss: 1.9300834465764145
Validation loss: 2.492176550803414

Epoch: 6| Step: 6
Training loss: 1.5466462553804041
Validation loss: 2.440456555668307

Epoch: 6| Step: 7
Training loss: 1.4693142233302219
Validation loss: 2.472181128776059

Epoch: 6| Step: 8
Training loss: 2.0637064786281116
Validation loss: 2.5288515236770692

Epoch: 6| Step: 9
Training loss: 2.066610228885642
Validation loss: 2.4678403051395805

Epoch: 6| Step: 10
Training loss: 2.0205196123990867
Validation loss: 2.474152158302153

Epoch: 6| Step: 11
Training loss: 1.7155140324960674
Validation loss: 2.4923466632155877

Epoch: 6| Step: 12
Training loss: 1.900399908844872
Validation loss: 2.4548981743110594

Epoch: 6| Step: 13
Training loss: 1.6156164822086423
Validation loss: 2.454514577509528

Epoch: 340| Step: 0
Training loss: 1.9269733569407168
Validation loss: 2.571086945533177

Epoch: 6| Step: 1
Training loss: 2.2063855872487794
Validation loss: 2.449362313593212

Epoch: 6| Step: 2
Training loss: 2.0465096882978284
Validation loss: 2.4990858160068377

Epoch: 6| Step: 3
Training loss: 1.820478832847877
Validation loss: 2.477444971152951

Epoch: 6| Step: 4
Training loss: 1.7587590360646586
Validation loss: 2.51383184503744

Epoch: 6| Step: 5
Training loss: 1.9403183650282796
Validation loss: 2.468439555142364

Epoch: 6| Step: 6
Training loss: 2.0585441800542807
Validation loss: 2.464129138913941

Epoch: 6| Step: 7
Training loss: 1.7402239626863023
Validation loss: 2.4353573818646046

Epoch: 6| Step: 8
Training loss: 2.1135010102637146
Validation loss: 2.4951410728184524

Epoch: 6| Step: 9
Training loss: 1.6375281033033529
Validation loss: 2.4814885659243315

Epoch: 6| Step: 10
Training loss: 1.5784493292480637
Validation loss: 2.4573865912951858

Epoch: 6| Step: 11
Training loss: 2.950902839480521
Validation loss: 2.4961138104755656

Epoch: 6| Step: 12
Training loss: 2.1909171525899693
Validation loss: 2.4739905401356004

Epoch: 6| Step: 13
Training loss: 1.690036280541669
Validation loss: 2.451669306938066

Epoch: 341| Step: 0
Training loss: 2.464531203100482
Validation loss: 2.4942345331186146

Epoch: 6| Step: 1
Training loss: 1.2935671156468072
Validation loss: 2.5225521744128345

Epoch: 6| Step: 2
Training loss: 2.1864930151202584
Validation loss: 2.465481142418921

Epoch: 6| Step: 3
Training loss: 2.044665826108047
Validation loss: 2.4470434121430213

Epoch: 6| Step: 4
Training loss: 1.9642418001889113
Validation loss: 2.4975939893862225

Epoch: 6| Step: 5
Training loss: 1.8286718870990781
Validation loss: 2.526035985674917

Epoch: 6| Step: 6
Training loss: 2.3944921194740627
Validation loss: 2.4630046157549854

Epoch: 6| Step: 7
Training loss: 1.8383953119080398
Validation loss: 2.5359213002515877

Epoch: 6| Step: 8
Training loss: 2.1267921519951325
Validation loss: 2.4900867600013217

Epoch: 6| Step: 9
Training loss: 1.8664542957251875
Validation loss: 2.4756214003144503

Epoch: 6| Step: 10
Training loss: 2.120050725330036
Validation loss: 2.5150712099915085

Epoch: 6| Step: 11
Training loss: 1.8443761505878289
Validation loss: 2.4765787084961364

Epoch: 6| Step: 12
Training loss: 2.0122140811610607
Validation loss: 2.51321658945221

Epoch: 6| Step: 13
Training loss: 1.7745789874811007
Validation loss: 2.491792035204443

Epoch: 342| Step: 0
Training loss: 2.557044199191929
Validation loss: 2.5013055417608974

Epoch: 6| Step: 1
Training loss: 2.256397054429102
Validation loss: 2.4952656309411116

Epoch: 6| Step: 2
Training loss: 1.5444617665338667
Validation loss: 2.4422481694740807

Epoch: 6| Step: 3
Training loss: 1.9101249832683547
Validation loss: 2.4447797671786695

Epoch: 6| Step: 4
Training loss: 1.8078593334570783
Validation loss: 2.4884742469692833

Epoch: 6| Step: 5
Training loss: 1.299892178979255
Validation loss: 2.4854275045105396

Epoch: 6| Step: 6
Training loss: 2.3831906878414615
Validation loss: 2.483932545493536

Epoch: 6| Step: 7
Training loss: 1.8888256874294371
Validation loss: 2.500948014531873

Epoch: 6| Step: 8
Training loss: 2.7200603615851073
Validation loss: 2.503846378252759

Epoch: 6| Step: 9
Training loss: 1.8739887689561285
Validation loss: 2.486283214218158

Epoch: 6| Step: 10
Training loss: 1.5540076067872108
Validation loss: 2.468844615348039

Epoch: 6| Step: 11
Training loss: 1.6175140198655682
Validation loss: 2.4883416260711884

Epoch: 6| Step: 12
Training loss: 2.110352918208727
Validation loss: 2.4348550860329765

Epoch: 6| Step: 13
Training loss: 1.4975389318229557
Validation loss: 2.522300770741896

Epoch: 343| Step: 0
Training loss: 2.1196841900796985
Validation loss: 2.489047992073

Epoch: 6| Step: 1
Training loss: 1.885045164260334
Validation loss: 2.494743700371517

Epoch: 6| Step: 2
Training loss: 1.8288624897984531
Validation loss: 2.4604114549052034

Epoch: 6| Step: 3
Training loss: 2.0702141504499347
Validation loss: 2.5094941996161233

Epoch: 6| Step: 4
Training loss: 2.192790364402023
Validation loss: 2.4609339935230876

Epoch: 6| Step: 5
Training loss: 1.9050994903136067
Validation loss: 2.437095740035288

Epoch: 6| Step: 6
Training loss: 2.077262297801996
Validation loss: 2.487790257019525

Epoch: 6| Step: 7
Training loss: 1.80414140373791
Validation loss: 2.4875076654128216

Epoch: 6| Step: 8
Training loss: 1.4964168986435225
Validation loss: 2.4566955926649015

Epoch: 6| Step: 9
Training loss: 2.1071212596571582
Validation loss: 2.502619887235143

Epoch: 6| Step: 10
Training loss: 2.3186023716573794
Validation loss: 2.4783831751150407

Epoch: 6| Step: 11
Training loss: 1.8602471109538796
Validation loss: 2.43996026619944

Epoch: 6| Step: 12
Training loss: 2.116596660307371
Validation loss: 2.494527732206612

Epoch: 6| Step: 13
Training loss: 1.365167706216528
Validation loss: 2.4495930423064176

Epoch: 344| Step: 0
Training loss: 2.1814216087188076
Validation loss: 2.4622648957367645

Epoch: 6| Step: 1
Training loss: 2.259067490203196
Validation loss: 2.4392809991247706

Epoch: 6| Step: 2
Training loss: 1.6095552806432383
Validation loss: 2.472050182852909

Epoch: 6| Step: 3
Training loss: 2.37156177407642
Validation loss: 2.5163653413019036

Epoch: 6| Step: 4
Training loss: 2.2797307220189387
Validation loss: 2.4871620441277678

Epoch: 6| Step: 5
Training loss: 2.3041066617780737
Validation loss: 2.4527386330447385

Epoch: 6| Step: 6
Training loss: 1.6647762147048464
Validation loss: 2.4911251081549044

Epoch: 6| Step: 7
Training loss: 1.1770721142439562
Validation loss: 2.503839094353009

Epoch: 6| Step: 8
Training loss: 2.2139124182080026
Validation loss: 2.514563697687777

Epoch: 6| Step: 9
Training loss: 1.7539312620014993
Validation loss: 2.465005970476142

Epoch: 6| Step: 10
Training loss: 2.0186566168855347
Validation loss: 2.4734086691689

Epoch: 6| Step: 11
Training loss: 1.8704632869605946
Validation loss: 2.498490075495784

Epoch: 6| Step: 12
Training loss: 1.9769453198170117
Validation loss: 2.4279104797933986

Epoch: 6| Step: 13
Training loss: 2.0101433075637565
Validation loss: 2.4995944699170156

Epoch: 345| Step: 0
Training loss: 1.8257643627451665
Validation loss: 2.487584534044161

Epoch: 6| Step: 1
Training loss: 2.4489715792158315
Validation loss: 2.51112511017133

Epoch: 6| Step: 2
Training loss: 2.4116012717631676
Validation loss: 2.4807946556007443

Epoch: 6| Step: 3
Training loss: 2.110923481293951
Validation loss: 2.4584122052965895

Epoch: 6| Step: 4
Training loss: 2.5314227386685424
Validation loss: 2.5147652338646975

Epoch: 6| Step: 5
Training loss: 1.8841486578239157
Validation loss: 2.4801800964986005

Epoch: 6| Step: 6
Training loss: 2.0845349343406485
Validation loss: 2.4607883598944897

Epoch: 6| Step: 7
Training loss: 2.1796034930048056
Validation loss: 2.4971654060401876

Epoch: 6| Step: 8
Training loss: 1.8586884200689904
Validation loss: 2.4610858373148954

Epoch: 6| Step: 9
Training loss: 1.8295007729311068
Validation loss: 2.4650939884066965

Epoch: 6| Step: 10
Training loss: 1.1817055424284184
Validation loss: 2.4533562985850548

Epoch: 6| Step: 11
Training loss: 1.5812924013747836
Validation loss: 2.481485696987413

Epoch: 6| Step: 12
Training loss: 1.4376116170257776
Validation loss: 2.4837016460253154

Epoch: 6| Step: 13
Training loss: 2.101103324786052
Validation loss: 2.477550448894328

Epoch: 346| Step: 0
Training loss: 1.7379530007402335
Validation loss: 2.480384847591249

Epoch: 6| Step: 1
Training loss: 1.673248297416474
Validation loss: 2.460650575328053

Epoch: 6| Step: 2
Training loss: 2.887244975400188
Validation loss: 2.5051695637089395

Epoch: 6| Step: 3
Training loss: 1.3669050524372715
Validation loss: 2.498401713400845

Epoch: 6| Step: 4
Training loss: 2.3469510407706973
Validation loss: 2.4788316045444474

Epoch: 6| Step: 5
Training loss: 1.7798989509446121
Validation loss: 2.480227932888707

Epoch: 6| Step: 6
Training loss: 2.4146145186386594
Validation loss: 2.510040272006129

Epoch: 6| Step: 7
Training loss: 1.6336991672444396
Validation loss: 2.45035292841895

Epoch: 6| Step: 8
Training loss: 1.6165062395442065
Validation loss: 2.4512288980061556

Epoch: 6| Step: 9
Training loss: 1.886121825255031
Validation loss: 2.4805870099662455

Epoch: 6| Step: 10
Training loss: 1.579113792131446
Validation loss: 2.4554199196981052

Epoch: 6| Step: 11
Training loss: 1.7903063585466015
Validation loss: 2.499893462054228

Epoch: 6| Step: 12
Training loss: 2.1726013725343147
Validation loss: 2.4832920513973664

Epoch: 6| Step: 13
Training loss: 1.8146644690937317
Validation loss: 2.51964205509121

Epoch: 347| Step: 0
Training loss: 1.7898994054179422
Validation loss: 2.46569173205726

Epoch: 6| Step: 1
Training loss: 1.384298054642796
Validation loss: 2.4285980389292647

Epoch: 6| Step: 2
Training loss: 1.8208252671657417
Validation loss: 2.480733287200093

Epoch: 6| Step: 3
Training loss: 1.6542630783285852
Validation loss: 2.460740507633601

Epoch: 6| Step: 4
Training loss: 1.4554148034885528
Validation loss: 2.4449352822780095

Epoch: 6| Step: 5
Training loss: 2.3382621093945444
Validation loss: 2.4533131897386045

Epoch: 6| Step: 6
Training loss: 2.04451073536768
Validation loss: 2.471904172214804

Epoch: 6| Step: 7
Training loss: 1.7043128114943653
Validation loss: 2.436456449025391

Epoch: 6| Step: 8
Training loss: 2.226701377419172
Validation loss: 2.5040525210311397

Epoch: 6| Step: 9
Training loss: 2.1219830132972137
Validation loss: 2.4938839784955458

Epoch: 6| Step: 10
Training loss: 1.5817778961389057
Validation loss: 2.471811956748738

Epoch: 6| Step: 11
Training loss: 2.046820021029286
Validation loss: 2.5066933787444867

Epoch: 6| Step: 12
Training loss: 2.161467831755454
Validation loss: 2.448998962914777

Epoch: 6| Step: 13
Training loss: 3.3848998785496116
Validation loss: 2.4912536076918244

Epoch: 348| Step: 0
Training loss: 1.7640873788138534
Validation loss: 2.4215529170438823

Epoch: 6| Step: 1
Training loss: 2.11680323643282
Validation loss: 2.49991358330789

Epoch: 6| Step: 2
Training loss: 1.3773559413982701
Validation loss: 2.4579658689035373

Epoch: 6| Step: 3
Training loss: 2.2611213909835057
Validation loss: 2.5167092440379433

Epoch: 6| Step: 4
Training loss: 1.64661425964008
Validation loss: 2.508400242841475

Epoch: 6| Step: 5
Training loss: 2.0303802975876297
Validation loss: 2.4877131391756886

Epoch: 6| Step: 6
Training loss: 1.839334664506881
Validation loss: 2.479758187844287

Epoch: 6| Step: 7
Training loss: 1.4662753421190202
Validation loss: 2.4721644828687084

Epoch: 6| Step: 8
Training loss: 2.1775048926174763
Validation loss: 2.4870982883716843

Epoch: 6| Step: 9
Training loss: 2.2749389724091578
Validation loss: 2.510721036990776

Epoch: 6| Step: 10
Training loss: 1.7663189359847118
Validation loss: 2.457380547806336

Epoch: 6| Step: 11
Training loss: 1.9180117600351936
Validation loss: 2.5071863397036105

Epoch: 6| Step: 12
Training loss: 2.0873058845585835
Validation loss: 2.45516684446891

Epoch: 6| Step: 13
Training loss: 2.9025614311558163
Validation loss: 2.50998896885113

Epoch: 349| Step: 0
Training loss: 1.6309912348452673
Validation loss: 2.463083791589187

Epoch: 6| Step: 1
Training loss: 2.1987956912274167
Validation loss: 2.501991516506786

Epoch: 6| Step: 2
Training loss: 1.796476236960734
Validation loss: 2.4906150405636693

Epoch: 6| Step: 3
Training loss: 1.7843507247315753
Validation loss: 2.4941689044980495

Epoch: 6| Step: 4
Training loss: 1.7756843617663192
Validation loss: 2.4763226312544466

Epoch: 6| Step: 5
Training loss: 2.0986366751215035
Validation loss: 2.479091980959498

Epoch: 6| Step: 6
Training loss: 2.1478529256199073
Validation loss: 2.483013239837407

Epoch: 6| Step: 7
Training loss: 2.01103231329544
Validation loss: 2.5020169540905917

Epoch: 6| Step: 8
Training loss: 1.8964775863195953
Validation loss: 2.4929590359544878

Epoch: 6| Step: 9
Training loss: 1.19480835499149
Validation loss: 2.4862870747047805

Epoch: 6| Step: 10
Training loss: 2.4932747027019597
Validation loss: 2.460409830495163

Epoch: 6| Step: 11
Training loss: 1.8721364088732837
Validation loss: 2.4983350706250054

Epoch: 6| Step: 12
Training loss: 1.9119841833697409
Validation loss: 2.4784169113384302

Epoch: 6| Step: 13
Training loss: 1.8868227469963266
Validation loss: 2.471110686591428

Epoch: 350| Step: 0
Training loss: 1.5649714950549332
Validation loss: 2.5081332263622684

Epoch: 6| Step: 1
Training loss: 1.9378977951719927
Validation loss: 2.455034104484957

Epoch: 6| Step: 2
Training loss: 1.7442457417319523
Validation loss: 2.4786782425140244

Epoch: 6| Step: 3
Training loss: 2.071150930241996
Validation loss: 2.46136227177873

Epoch: 6| Step: 4
Training loss: 2.2967474246763766
Validation loss: 2.540435074709601

Epoch: 6| Step: 5
Training loss: 2.163433658387607
Validation loss: 2.484098415311541

Epoch: 6| Step: 6
Training loss: 1.8343627669334301
Validation loss: 2.451024768093446

Epoch: 6| Step: 7
Training loss: 1.9690168896169173
Validation loss: 2.446359537552198

Epoch: 6| Step: 8
Training loss: 2.0111865478520956
Validation loss: 2.4588065014444753

Epoch: 6| Step: 9
Training loss: 2.0840394031584997
Validation loss: 2.4867690316446756

Epoch: 6| Step: 10
Training loss: 2.0479132661632766
Validation loss: 2.5112683402008824

Epoch: 6| Step: 11
Training loss: 2.5081101475610246
Validation loss: 2.4866208536981014

Epoch: 6| Step: 12
Training loss: 1.5075392401350205
Validation loss: 2.5087942596937225

Epoch: 6| Step: 13
Training loss: 1.1409845177505253
Validation loss: 2.4547044789798784

Epoch: 351| Step: 0
Training loss: 1.6711669563426867
Validation loss: 2.5059767620705404

Epoch: 6| Step: 1
Training loss: 1.646644376354213
Validation loss: 2.4683542070611755

Epoch: 6| Step: 2
Training loss: 2.1347722143296637
Validation loss: 2.447450915459091

Epoch: 6| Step: 3
Training loss: 1.582677939777885
Validation loss: 2.461472580244428

Epoch: 6| Step: 4
Training loss: 2.037268891128395
Validation loss: 2.4842831948163084

Epoch: 6| Step: 5
Training loss: 1.6430484855774197
Validation loss: 2.4708393062473775

Epoch: 6| Step: 6
Training loss: 1.9092897661480182
Validation loss: 2.4356761426736764

Epoch: 6| Step: 7
Training loss: 2.204965134083347
Validation loss: 2.507423125052429

Epoch: 6| Step: 8
Training loss: 2.0774698013332613
Validation loss: 2.4848362283053325

Epoch: 6| Step: 9
Training loss: 2.609040564388752
Validation loss: 2.499117681203645

Epoch: 6| Step: 10
Training loss: 1.6770007979971728
Validation loss: 2.4895987247405396

Epoch: 6| Step: 11
Training loss: 2.3722892148248733
Validation loss: 2.518873522932781

Epoch: 6| Step: 12
Training loss: 1.8091929948678314
Validation loss: 2.4635819516355517

Epoch: 6| Step: 13
Training loss: 1.7719836220253489
Validation loss: 2.4560233669061264

Epoch: 352| Step: 0
Training loss: 1.946007049234135
Validation loss: 2.5016589310893127

Epoch: 6| Step: 1
Training loss: 1.6519601796040844
Validation loss: 2.450511898400098

Epoch: 6| Step: 2
Training loss: 1.879457515811798
Validation loss: 2.476493347181757

Epoch: 6| Step: 3
Training loss: 2.0088400975681604
Validation loss: 2.5147045537905868

Epoch: 6| Step: 4
Training loss: 1.6303242245106853
Validation loss: 2.483259641411892

Epoch: 6| Step: 5
Training loss: 2.0330132680704853
Validation loss: 2.468925103296203

Epoch: 6| Step: 6
Training loss: 2.5825111762633095
Validation loss: 2.4924601445820436

Epoch: 6| Step: 7
Training loss: 1.5787793304304234
Validation loss: 2.476016527021248

Epoch: 6| Step: 8
Training loss: 2.5239793886531054
Validation loss: 2.4913946122218884

Epoch: 6| Step: 9
Training loss: 1.8851034701658158
Validation loss: 2.470448953898724

Epoch: 6| Step: 10
Training loss: 1.6216694372662475
Validation loss: 2.476227955846956

Epoch: 6| Step: 11
Training loss: 1.6492317781064794
Validation loss: 2.493340131740943

Epoch: 6| Step: 12
Training loss: 2.0158076240547524
Validation loss: 2.4899961538013717

Epoch: 6| Step: 13
Training loss: 1.9251796564264938
Validation loss: 2.471577458377145

Epoch: 353| Step: 0
Training loss: 2.204616826125715
Validation loss: 2.500544191423493

Epoch: 6| Step: 1
Training loss: 1.8992873436401212
Validation loss: 2.4425030865285904

Epoch: 6| Step: 2
Training loss: 1.6210790426667179
Validation loss: 2.4174765339110458

Epoch: 6| Step: 3
Training loss: 1.5996470091774426
Validation loss: 2.46970502959268

Epoch: 6| Step: 4
Training loss: 1.4823023731580445
Validation loss: 2.4649863214139693

Epoch: 6| Step: 5
Training loss: 2.4343615158158123
Validation loss: 2.4488746875170166

Epoch: 6| Step: 6
Training loss: 1.8579270952332285
Validation loss: 2.484467401306303

Epoch: 6| Step: 7
Training loss: 2.321416521565111
Validation loss: 2.4611197497076445

Epoch: 6| Step: 8
Training loss: 1.647754328753724
Validation loss: 2.4275324926644135

Epoch: 6| Step: 9
Training loss: 2.1500564301648146
Validation loss: 2.5235510725342296

Epoch: 6| Step: 10
Training loss: 2.1481990057611684
Validation loss: 2.4426697471868755

Epoch: 6| Step: 11
Training loss: 1.8950404790414928
Validation loss: 2.491775979167627

Epoch: 6| Step: 12
Training loss: 1.9397874065793907
Validation loss: 2.4667732312268207

Epoch: 6| Step: 13
Training loss: 2.188873404831616
Validation loss: 2.5115926382333114

Epoch: 354| Step: 0
Training loss: 1.9470417961567865
Validation loss: 2.5263653315146675

Epoch: 6| Step: 1
Training loss: 1.8598306562386948
Validation loss: 2.4931938522720625

Epoch: 6| Step: 2
Training loss: 1.9185452031985872
Validation loss: 2.484980980802863

Epoch: 6| Step: 3
Training loss: 2.0619225127038057
Validation loss: 2.5288983572907067

Epoch: 6| Step: 4
Training loss: 1.7237383499471053
Validation loss: 2.4910645515257035

Epoch: 6| Step: 5
Training loss: 2.134464951235264
Validation loss: 2.481723575038577

Epoch: 6| Step: 6
Training loss: 1.5483690233226877
Validation loss: 2.496161485810453

Epoch: 6| Step: 7
Training loss: 1.3602073138367512
Validation loss: 2.4828769632695735

Epoch: 6| Step: 8
Training loss: 2.984926502338916
Validation loss: 2.4958195281271376

Epoch: 6| Step: 9
Training loss: 1.5808832218152122
Validation loss: 2.4501263592790337

Epoch: 6| Step: 10
Training loss: 2.204138340134015
Validation loss: 2.5050842095450503

Epoch: 6| Step: 11
Training loss: 1.818314532291453
Validation loss: 2.478620107173895

Epoch: 6| Step: 12
Training loss: 1.614288385174419
Validation loss: 2.4552231419315906

Epoch: 6| Step: 13
Training loss: 2.1129113964851847
Validation loss: 2.468949385816228

Epoch: 355| Step: 0
Training loss: 1.660179802222641
Validation loss: 2.501118202755501

Epoch: 6| Step: 1
Training loss: 1.472743105161059
Validation loss: 2.4765834846926067

Epoch: 6| Step: 2
Training loss: 1.6715461193572205
Validation loss: 2.504042947490167

Epoch: 6| Step: 3
Training loss: 2.1032546934408485
Validation loss: 2.470121539292828

Epoch: 6| Step: 4
Training loss: 1.7137205577410846
Validation loss: 2.467966636381511

Epoch: 6| Step: 5
Training loss: 2.4960532506006325
Validation loss: 2.4661684403061876

Epoch: 6| Step: 6
Training loss: 2.11844476622334
Validation loss: 2.4655483113779892

Epoch: 6| Step: 7
Training loss: 2.041841214043217
Validation loss: 2.511135942036444

Epoch: 6| Step: 8
Training loss: 2.118337734026756
Validation loss: 2.5179268856749784

Epoch: 6| Step: 9
Training loss: 1.6778640430510159
Validation loss: 2.45585393588136

Epoch: 6| Step: 10
Training loss: 1.84563944065892
Validation loss: 2.4735803148010294

Epoch: 6| Step: 11
Training loss: 1.940073642021213
Validation loss: 2.4720874769781442

Epoch: 6| Step: 12
Training loss: 1.7028857421804995
Validation loss: 2.4473186693702886

Epoch: 6| Step: 13
Training loss: 2.6635455303937396
Validation loss: 2.450404531236721

Epoch: 356| Step: 0
Training loss: 1.5913641780335184
Validation loss: 2.4445145425607135

Epoch: 6| Step: 1
Training loss: 1.9826192823317608
Validation loss: 2.518144354767618

Epoch: 6| Step: 2
Training loss: 1.6497571824321082
Validation loss: 2.5486004393397

Epoch: 6| Step: 3
Training loss: 2.3598346388799505
Validation loss: 2.4950592718199114

Epoch: 6| Step: 4
Training loss: 2.6412448494134773
Validation loss: 2.4492643116279567

Epoch: 6| Step: 5
Training loss: 2.2986178889435576
Validation loss: 2.5079090200910117

Epoch: 6| Step: 6
Training loss: 1.9759887948316952
Validation loss: 2.4753414679198587

Epoch: 6| Step: 7
Training loss: 1.7065982225720653
Validation loss: 2.524121753175218

Epoch: 6| Step: 8
Training loss: 1.69845949946582
Validation loss: 2.492358041105582

Epoch: 6| Step: 9
Training loss: 1.9239219371559169
Validation loss: 2.476480996301538

Epoch: 6| Step: 10
Training loss: 1.6650190156417826
Validation loss: 2.5042432747278744

Epoch: 6| Step: 11
Training loss: 1.9660795962732118
Validation loss: 2.5123416071769213

Epoch: 6| Step: 12
Training loss: 1.699016830899832
Validation loss: 2.436330229047892

Epoch: 6| Step: 13
Training loss: 1.4227441499757725
Validation loss: 2.4796233535125247

Epoch: 357| Step: 0
Training loss: 1.9550841004607111
Validation loss: 2.497361665538791

Epoch: 6| Step: 1
Training loss: 1.7483891157421956
Validation loss: 2.483122211725425

Epoch: 6| Step: 2
Training loss: 2.1825753500254734
Validation loss: 2.4877101609682115

Epoch: 6| Step: 3
Training loss: 1.596783163934832
Validation loss: 2.460534814200933

Epoch: 6| Step: 4
Training loss: 1.8759472043918963
Validation loss: 2.4739436178412006

Epoch: 6| Step: 5
Training loss: 2.579917330932959
Validation loss: 2.492111739297659

Epoch: 6| Step: 6
Training loss: 1.617180423444662
Validation loss: 2.4914746320128516

Epoch: 6| Step: 7
Training loss: 2.193015964218598
Validation loss: 2.445804796302031

Epoch: 6| Step: 8
Training loss: 1.6019003907095382
Validation loss: 2.496253165323571

Epoch: 6| Step: 9
Training loss: 2.405109482016026
Validation loss: 2.5208921236650594

Epoch: 6| Step: 10
Training loss: 1.9727797667858786
Validation loss: 2.460235387205423

Epoch: 6| Step: 11
Training loss: 2.0569250882777967
Validation loss: 2.431466651317238

Epoch: 6| Step: 12
Training loss: 1.949235935173649
Validation loss: 2.480565412177086

Epoch: 6| Step: 13
Training loss: 1.8757976742573133
Validation loss: 2.502068912005897

Epoch: 358| Step: 0
Training loss: 1.6503235933132885
Validation loss: 2.446513212235674

Epoch: 6| Step: 1
Training loss: 1.9687073718103238
Validation loss: 2.4701232600643066

Epoch: 6| Step: 2
Training loss: 1.5458355889042579
Validation loss: 2.5119113556423076

Epoch: 6| Step: 3
Training loss: 2.411762611081761
Validation loss: 2.5120324441123403

Epoch: 6| Step: 4
Training loss: 1.8676213993308182
Validation loss: 2.4905905971744184

Epoch: 6| Step: 5
Training loss: 1.8473691172819418
Validation loss: 2.4858349249712868

Epoch: 6| Step: 6
Training loss: 1.7980779187267564
Validation loss: 2.5122957583209686

Epoch: 6| Step: 7
Training loss: 1.8790564843783635
Validation loss: 2.4804726867153613

Epoch: 6| Step: 8
Training loss: 2.169649369702665
Validation loss: 2.476655848014412

Epoch: 6| Step: 9
Training loss: 2.8035855904690936
Validation loss: 2.4591070698730553

Epoch: 6| Step: 10
Training loss: 1.4321055158388623
Validation loss: 2.513216125323252

Epoch: 6| Step: 11
Training loss: 1.7681407054258889
Validation loss: 2.4389340494676577

Epoch: 6| Step: 12
Training loss: 2.0518969017066024
Validation loss: 2.4670330342440328

Epoch: 6| Step: 13
Training loss: 1.37222990689376
Validation loss: 2.442519892596456

Epoch: 359| Step: 0
Training loss: 1.8995499981482689
Validation loss: 2.4759825727545017

Epoch: 6| Step: 1
Training loss: 1.6684976851344662
Validation loss: 2.4926509615898946

Epoch: 6| Step: 2
Training loss: 1.9788185482718883
Validation loss: 2.4938373390110082

Epoch: 6| Step: 3
Training loss: 2.106406376407649
Validation loss: 2.4463783302072546

Epoch: 6| Step: 4
Training loss: 1.6413616161641802
Validation loss: 2.5155157759647424

Epoch: 6| Step: 5
Training loss: 1.9060676362404718
Validation loss: 2.509180487535507

Epoch: 6| Step: 6
Training loss: 2.1912602394678626
Validation loss: 2.4717958912376115

Epoch: 6| Step: 7
Training loss: 1.845037237272296
Validation loss: 2.4935282442873126

Epoch: 6| Step: 8
Training loss: 1.8494257448072984
Validation loss: 2.430582326535538

Epoch: 6| Step: 9
Training loss: 1.5598967418975815
Validation loss: 2.491069968884167

Epoch: 6| Step: 10
Training loss: 1.249636454168073
Validation loss: 2.512608979413121

Epoch: 6| Step: 11
Training loss: 2.164266308162867
Validation loss: 2.4878945640266528

Epoch: 6| Step: 12
Training loss: 1.8604708735936928
Validation loss: 2.483536637446575

Epoch: 6| Step: 13
Training loss: 2.846882363068054
Validation loss: 2.4903081709825132

Epoch: 360| Step: 0
Training loss: 1.7644999472752405
Validation loss: 2.4505095110496087

Epoch: 6| Step: 1
Training loss: 1.6521499556216426
Validation loss: 2.4804680482325465

Epoch: 6| Step: 2
Training loss: 1.8647992809988148
Validation loss: 2.448131191791384

Epoch: 6| Step: 3
Training loss: 1.9949280083843814
Validation loss: 2.4833239736942905

Epoch: 6| Step: 4
Training loss: 1.8457719739556369
Validation loss: 2.4784124241663594

Epoch: 6| Step: 5
Training loss: 2.0484140448605914
Validation loss: 2.4772782951945893

Epoch: 6| Step: 6
Training loss: 2.2924059513481394
Validation loss: 2.471945540178483

Epoch: 6| Step: 7
Training loss: 1.71936419523471
Validation loss: 2.4698366115754333

Epoch: 6| Step: 8
Training loss: 1.9960336694801735
Validation loss: 2.5065817598764615

Epoch: 6| Step: 9
Training loss: 2.1797072980521683
Validation loss: 2.46215423699663

Epoch: 6| Step: 10
Training loss: 1.4075702403753323
Validation loss: 2.4339470085579

Epoch: 6| Step: 11
Training loss: 2.359397029142295
Validation loss: 2.4867630626556356

Epoch: 6| Step: 12
Training loss: 1.486967853919542
Validation loss: 2.5134326683855455

Epoch: 6| Step: 13
Training loss: 2.3998333475744458
Validation loss: 2.4886014566222787

Epoch: 361| Step: 0
Training loss: 2.1122759051220394
Validation loss: 2.4890126566982476

Epoch: 6| Step: 1
Training loss: 1.6181032103732338
Validation loss: 2.458301319423462

Epoch: 6| Step: 2
Training loss: 2.002748508154247
Validation loss: 2.468607443445847

Epoch: 6| Step: 3
Training loss: 2.2861313524530793
Validation loss: 2.4804272740657316

Epoch: 6| Step: 4
Training loss: 2.2540605779798555
Validation loss: 2.483730505762088

Epoch: 6| Step: 5
Training loss: 1.6352650598445766
Validation loss: 2.528757412340149

Epoch: 6| Step: 6
Training loss: 1.9793357241521785
Validation loss: 2.4651179150375415

Epoch: 6| Step: 7
Training loss: 2.057382534933659
Validation loss: 2.487992326686567

Epoch: 6| Step: 8
Training loss: 1.85457234463007
Validation loss: 2.4871521633449674

Epoch: 6| Step: 9
Training loss: 1.3964643570325528
Validation loss: 2.4659904268761244

Epoch: 6| Step: 10
Training loss: 1.7214212640178728
Validation loss: 2.454992796158827

Epoch: 6| Step: 11
Training loss: 1.8491651249254952
Validation loss: 2.46992901185124

Epoch: 6| Step: 12
Training loss: 2.222919683147506
Validation loss: 2.4925224435813065

Epoch: 6| Step: 13
Training loss: 1.8714051435495498
Validation loss: 2.50269707226051

Epoch: 362| Step: 0
Training loss: 2.1133457815644023
Validation loss: 2.4801254348809203

Epoch: 6| Step: 1
Training loss: 2.8561232791227473
Validation loss: 2.4779155576951584

Epoch: 6| Step: 2
Training loss: 2.087839580943223
Validation loss: 2.472315825633361

Epoch: 6| Step: 3
Training loss: 1.6645671813461298
Validation loss: 2.488018730683876

Epoch: 6| Step: 4
Training loss: 2.2050080605011404
Validation loss: 2.481435060789657

Epoch: 6| Step: 5
Training loss: 1.6316389767430926
Validation loss: 2.5089480747904322

Epoch: 6| Step: 6
Training loss: 1.394695624913972
Validation loss: 2.4933062843497154

Epoch: 6| Step: 7
Training loss: 1.6644649108598362
Validation loss: 2.459682743585191

Epoch: 6| Step: 8
Training loss: 1.7920580443876102
Validation loss: 2.497365739871124

Epoch: 6| Step: 9
Training loss: 1.7212781865312958
Validation loss: 2.5073964683652226

Epoch: 6| Step: 10
Training loss: 2.031483328696179
Validation loss: 2.5019361853339293

Epoch: 6| Step: 11
Training loss: 1.623060976924297
Validation loss: 2.4587432115707384

Epoch: 6| Step: 12
Training loss: 1.8410363351364036
Validation loss: 2.467969895508707

Epoch: 6| Step: 13
Training loss: 1.7656298612004429
Validation loss: 2.473695321385906

Epoch: 363| Step: 0
Training loss: 2.0531219203699433
Validation loss: 2.4550373651168784

Epoch: 6| Step: 1
Training loss: 1.677384896344491
Validation loss: 2.480649857243446

Epoch: 6| Step: 2
Training loss: 2.0443015191433664
Validation loss: 2.436148402597448

Epoch: 6| Step: 3
Training loss: 1.8087460019186739
Validation loss: 2.48259461113833

Epoch: 6| Step: 4
Training loss: 1.773259359815036
Validation loss: 2.4573263706502813

Epoch: 6| Step: 5
Training loss: 1.9825159210296976
Validation loss: 2.436127821497599

Epoch: 6| Step: 6
Training loss: 1.9288105072202042
Validation loss: 2.422358827297277

Epoch: 6| Step: 7
Training loss: 1.591615781253597
Validation loss: 2.461980495744388

Epoch: 6| Step: 8
Training loss: 2.4493186236739146
Validation loss: 2.5088312594983493

Epoch: 6| Step: 9
Training loss: 1.9372124612390502
Validation loss: 2.442596278349278

Epoch: 6| Step: 10
Training loss: 1.7813912051264609
Validation loss: 2.488421247466826

Epoch: 6| Step: 11
Training loss: 1.9884224412471678
Validation loss: 2.461824899933175

Epoch: 6| Step: 12
Training loss: 1.6752055853321561
Validation loss: 2.5023646625763454

Epoch: 6| Step: 13
Training loss: 1.6296609644133024
Validation loss: 2.470061501468878

Epoch: 364| Step: 0
Training loss: 1.5729729429708057
Validation loss: 2.4876042127821654

Epoch: 6| Step: 1
Training loss: 2.532562104166925
Validation loss: 2.4826061070399033

Epoch: 6| Step: 2
Training loss: 1.896853818570925
Validation loss: 2.4107486035951977

Epoch: 6| Step: 3
Training loss: 1.719731692079587
Validation loss: 2.4343245504626463

Epoch: 6| Step: 4
Training loss: 1.9498595749593217
Validation loss: 2.4828038344110075

Epoch: 6| Step: 5
Training loss: 2.230185255216034
Validation loss: 2.47118528759357

Epoch: 6| Step: 6
Training loss: 2.2448436143946373
Validation loss: 2.496612146823269

Epoch: 6| Step: 7
Training loss: 2.087688496924977
Validation loss: 2.4484226315694873

Epoch: 6| Step: 8
Training loss: 2.0325835325523474
Validation loss: 2.467593804853886

Epoch: 6| Step: 9
Training loss: 1.6252823364298776
Validation loss: 2.4874195645493056

Epoch: 6| Step: 10
Training loss: 1.7539751001110855
Validation loss: 2.45554955949362

Epoch: 6| Step: 11
Training loss: 1.3413117043841343
Validation loss: 2.4584561361262125

Epoch: 6| Step: 12
Training loss: 1.3885037820755601
Validation loss: 2.4862948183444376

Epoch: 6| Step: 13
Training loss: 1.877258720488442
Validation loss: 2.4079072484730237

Epoch: 365| Step: 0
Training loss: 1.6526277627191144
Validation loss: 2.4746997603495706

Epoch: 6| Step: 1
Training loss: 1.6315476478495408
Validation loss: 2.5144717345461056

Epoch: 6| Step: 2
Training loss: 2.1558559997609588
Validation loss: 2.472292052656148

Epoch: 6| Step: 3
Training loss: 2.169405844075422
Validation loss: 2.530023933932003

Epoch: 6| Step: 4
Training loss: 1.2823041905468906
Validation loss: 2.48221760022757

Epoch: 6| Step: 5
Training loss: 2.265953408478593
Validation loss: 2.498402355747039

Epoch: 6| Step: 6
Training loss: 1.8584060708879948
Validation loss: 2.5022113177520775

Epoch: 6| Step: 7
Training loss: 1.817780727340297
Validation loss: 2.495290545312663

Epoch: 6| Step: 8
Training loss: 1.7020060511973445
Validation loss: 2.4767544548662284

Epoch: 6| Step: 9
Training loss: 1.7585451082936265
Validation loss: 2.460637277057335

Epoch: 6| Step: 10
Training loss: 1.4555225896782642
Validation loss: 2.512012993481378

Epoch: 6| Step: 11
Training loss: 2.237967850345963
Validation loss: 2.507154380220058

Epoch: 6| Step: 12
Training loss: 2.4323173592386063
Validation loss: 2.4721602612281135

Epoch: 6| Step: 13
Training loss: 1.8300239286265365
Validation loss: 2.4777723468972566

Epoch: 366| Step: 0
Training loss: 2.3507418293561955
Validation loss: 2.475567507405721

Epoch: 6| Step: 1
Training loss: 1.7652055360245222
Validation loss: 2.4993748036933554

Epoch: 6| Step: 2
Training loss: 2.26472613163136
Validation loss: 2.4626348082443936

Epoch: 6| Step: 3
Training loss: 2.1175922978089976
Validation loss: 2.4754233343275955

Epoch: 6| Step: 4
Training loss: 1.794377324266566
Validation loss: 2.474234857222516

Epoch: 6| Step: 5
Training loss: 2.106844365958968
Validation loss: 2.502125179276267

Epoch: 6| Step: 6
Training loss: 1.515115711338212
Validation loss: 2.52815878599481

Epoch: 6| Step: 7
Training loss: 1.5679228710842856
Validation loss: 2.527135680640468

Epoch: 6| Step: 8
Training loss: 2.34419846376763
Validation loss: 2.4929781179902872

Epoch: 6| Step: 9
Training loss: 1.592653907393173
Validation loss: 2.4617905536296356

Epoch: 6| Step: 10
Training loss: 1.942013375048637
Validation loss: 2.493690258043188

Epoch: 6| Step: 11
Training loss: 1.254691380248952
Validation loss: 2.4434949136384185

Epoch: 6| Step: 12
Training loss: 2.0417490832243947
Validation loss: 2.4513151485084275

Epoch: 6| Step: 13
Training loss: 2.162379743286272
Validation loss: 2.45730958029885

Epoch: 367| Step: 0
Training loss: 1.5237891158230303
Validation loss: 2.4429885885751954

Epoch: 6| Step: 1
Training loss: 1.6128498082390585
Validation loss: 2.4913655737227294

Epoch: 6| Step: 2
Training loss: 1.852675155925393
Validation loss: 2.4923806398696042

Epoch: 6| Step: 3
Training loss: 2.2709665405213975
Validation loss: 2.4764313996145675

Epoch: 6| Step: 4
Training loss: 2.1710904028373577
Validation loss: 2.5053996481091754

Epoch: 6| Step: 5
Training loss: 1.933068653053852
Validation loss: 2.4383202354099494

Epoch: 6| Step: 6
Training loss: 1.913038703993543
Validation loss: 2.456940249098564

Epoch: 6| Step: 7
Training loss: 2.135997029656049
Validation loss: 2.485842767992591

Epoch: 6| Step: 8
Training loss: 2.6102900014369212
Validation loss: 2.5040121759507

Epoch: 6| Step: 9
Training loss: 1.5621945654840361
Validation loss: 2.4641183449058555

Epoch: 6| Step: 10
Training loss: 1.700535126217591
Validation loss: 2.453028018398961

Epoch: 6| Step: 11
Training loss: 2.025401101595674
Validation loss: 2.4614106077217137

Epoch: 6| Step: 12
Training loss: 1.0492736324860086
Validation loss: 2.473366475747961

Epoch: 6| Step: 13
Training loss: 1.969949326710649
Validation loss: 2.4491518721991485

Epoch: 368| Step: 0
Training loss: 1.9610469833145794
Validation loss: 2.4479627728402025

Epoch: 6| Step: 1
Training loss: 1.507875905655598
Validation loss: 2.5206907651189274

Epoch: 6| Step: 2
Training loss: 1.630875017468021
Validation loss: 2.461839502850714

Epoch: 6| Step: 3
Training loss: 2.4618744534881443
Validation loss: 2.4596190885260483

Epoch: 6| Step: 4
Training loss: 2.238773205337089
Validation loss: 2.5041223071587866

Epoch: 6| Step: 5
Training loss: 1.9181558241966834
Validation loss: 2.490191089206473

Epoch: 6| Step: 6
Training loss: 2.0276120987652155
Validation loss: 2.469889976656937

Epoch: 6| Step: 7
Training loss: 2.1049001063839645
Validation loss: 2.4877883063029755

Epoch: 6| Step: 8
Training loss: 1.2324366742438
Validation loss: 2.490315930942998

Epoch: 6| Step: 9
Training loss: 2.1023290434471447
Validation loss: 2.5014591470828114

Epoch: 6| Step: 10
Training loss: 1.9480892723706504
Validation loss: 2.4752830688215464

Epoch: 6| Step: 11
Training loss: 1.4743527624920103
Validation loss: 2.494772086069972

Epoch: 6| Step: 12
Training loss: 1.6670225081454582
Validation loss: 2.4362968428728853

Epoch: 6| Step: 13
Training loss: 2.2950012453030135
Validation loss: 2.5161410493934477

Epoch: 369| Step: 0
Training loss: 2.026574255233471
Validation loss: 2.4893641001836473

Epoch: 6| Step: 1
Training loss: 2.5235366093213716
Validation loss: 2.478407111542727

Epoch: 6| Step: 2
Training loss: 1.5316334458416134
Validation loss: 2.456896379856919

Epoch: 6| Step: 3
Training loss: 1.491895157702215
Validation loss: 2.483413171121427

Epoch: 6| Step: 4
Training loss: 2.0492491021419026
Validation loss: 2.450307226433217

Epoch: 6| Step: 5
Training loss: 1.867086240185438
Validation loss: 2.5037717147159997

Epoch: 6| Step: 6
Training loss: 1.7272350675638903
Validation loss: 2.475851058023686

Epoch: 6| Step: 7
Training loss: 2.041715102367277
Validation loss: 2.469350358378062

Epoch: 6| Step: 8
Training loss: 1.7385607548285393
Validation loss: 2.472302982073869

Epoch: 6| Step: 9
Training loss: 1.4614581643954356
Validation loss: 2.484332747231352

Epoch: 6| Step: 10
Training loss: 2.0657999631159507
Validation loss: 2.475755957632035

Epoch: 6| Step: 11
Training loss: 1.3732706812730655
Validation loss: 2.4793719810483323

Epoch: 6| Step: 12
Training loss: 2.6127806955333353
Validation loss: 2.4794384143980737

Epoch: 6| Step: 13
Training loss: 1.7684827649865071
Validation loss: 2.512032024668558

Epoch: 370| Step: 0
Training loss: 1.6237142317828408
Validation loss: 2.477127295979462

Epoch: 6| Step: 1
Training loss: 1.9242254011602213
Validation loss: 2.5039694037427256

Epoch: 6| Step: 2
Training loss: 2.65549215837864
Validation loss: 2.4443110197774685

Epoch: 6| Step: 3
Training loss: 1.676262135187951
Validation loss: 2.4476093826354384

Epoch: 6| Step: 4
Training loss: 1.9435182439381071
Validation loss: 2.4757223182116253

Epoch: 6| Step: 5
Training loss: 1.5506474896068176
Validation loss: 2.5099502012323742

Epoch: 6| Step: 6
Training loss: 2.2227493561617293
Validation loss: 2.4954007059765635

Epoch: 6| Step: 7
Training loss: 1.866141628892701
Validation loss: 2.4692516593440352

Epoch: 6| Step: 8
Training loss: 1.1996238098965404
Validation loss: 2.4774640583382297

Epoch: 6| Step: 9
Training loss: 2.1151438629425665
Validation loss: 2.5177049903284514

Epoch: 6| Step: 10
Training loss: 2.6830537077724523
Validation loss: 2.453113713423671

Epoch: 6| Step: 11
Training loss: 1.556443645884727
Validation loss: 2.483344601874488

Epoch: 6| Step: 12
Training loss: 1.7207637434120582
Validation loss: 2.4846646792760065

Epoch: 6| Step: 13
Training loss: 1.3365938682344722
Validation loss: 2.451472116216961

Epoch: 371| Step: 0
Training loss: 1.7668220715578424
Validation loss: 2.4956624015281292

Epoch: 6| Step: 1
Training loss: 1.3303241250173392
Validation loss: 2.48592833627399

Epoch: 6| Step: 2
Training loss: 2.4819362354433365
Validation loss: 2.5364004017632142

Epoch: 6| Step: 3
Training loss: 1.2596766713991672
Validation loss: 2.5008996247253186

Epoch: 6| Step: 4
Training loss: 2.098952590770454
Validation loss: 2.4282957792488045

Epoch: 6| Step: 5
Training loss: 2.4627241158523585
Validation loss: 2.4987719534472355

Epoch: 6| Step: 6
Training loss: 2.2780241432417663
Validation loss: 2.496760648726343

Epoch: 6| Step: 7
Training loss: 1.9592147493918626
Validation loss: 2.4567884694375697

Epoch: 6| Step: 8
Training loss: 1.4729104063052991
Validation loss: 2.48265622989117

Epoch: 6| Step: 9
Training loss: 2.246711022517398
Validation loss: 2.439264014669621

Epoch: 6| Step: 10
Training loss: 1.5747064256297285
Validation loss: 2.472444585214454

Epoch: 6| Step: 11
Training loss: 1.9677076456510663
Validation loss: 2.499823282005145

Epoch: 6| Step: 12
Training loss: 1.495964741933946
Validation loss: 2.426845154546386

Epoch: 6| Step: 13
Training loss: 2.1670659015318456
Validation loss: 2.463686455274014

Epoch: 372| Step: 0
Training loss: 2.1023674880282033
Validation loss: 2.4610505108880263

Epoch: 6| Step: 1
Training loss: 2.6852737787279035
Validation loss: 2.5262713807501567

Epoch: 6| Step: 2
Training loss: 1.917814477748886
Validation loss: 2.514204682763503

Epoch: 6| Step: 3
Training loss: 1.5313781373263762
Validation loss: 2.483596406298655

Epoch: 6| Step: 4
Training loss: 1.6664752214468384
Validation loss: 2.46368524196795

Epoch: 6| Step: 5
Training loss: 1.8619634738785455
Validation loss: 2.477708153972966

Epoch: 6| Step: 6
Training loss: 2.0288581263696175
Validation loss: 2.4677076567901004

Epoch: 6| Step: 7
Training loss: 1.935246849480309
Validation loss: 2.5011822519974367

Epoch: 6| Step: 8
Training loss: 1.6691188733169784
Validation loss: 2.5153390095987644

Epoch: 6| Step: 9
Training loss: 1.7620199753736399
Validation loss: 2.435536659033054

Epoch: 6| Step: 10
Training loss: 1.964264801459023
Validation loss: 2.4807771415615383

Epoch: 6| Step: 11
Training loss: 1.984695889216925
Validation loss: 2.4869591245964155

Epoch: 6| Step: 12
Training loss: 1.493158473920624
Validation loss: 2.4454555024750095

Epoch: 6| Step: 13
Training loss: 1.710776752602239
Validation loss: 2.51352808557064

Epoch: 373| Step: 0
Training loss: 1.6859519356859967
Validation loss: 2.500058388797264

Epoch: 6| Step: 1
Training loss: 1.6157776220015507
Validation loss: 2.4771096131900836

Epoch: 6| Step: 2
Training loss: 2.4233736385192683
Validation loss: 2.502890658434694

Epoch: 6| Step: 3
Training loss: 2.5761238423367594
Validation loss: 2.501282708466122

Epoch: 6| Step: 4
Training loss: 1.2459485199581828
Validation loss: 2.5268638210823404

Epoch: 6| Step: 5
Training loss: 1.8745767115588845
Validation loss: 2.5150320956528445

Epoch: 6| Step: 6
Training loss: 2.3390398634717955
Validation loss: 2.51281323313707

Epoch: 6| Step: 7
Training loss: 1.532187505726325
Validation loss: 2.5204705218193477

Epoch: 6| Step: 8
Training loss: 1.8946214792060694
Validation loss: 2.5017939760440506

Epoch: 6| Step: 9
Training loss: 1.765140905942475
Validation loss: 2.4555995340912555

Epoch: 6| Step: 10
Training loss: 1.90830526400694
Validation loss: 2.4995826352295576

Epoch: 6| Step: 11
Training loss: 2.1676956692102203
Validation loss: 2.4334312601594608

Epoch: 6| Step: 12
Training loss: 1.2993968664900986
Validation loss: 2.4969423381834392

Epoch: 6| Step: 13
Training loss: 1.4354140862532603
Validation loss: 2.4871074158743154

Epoch: 374| Step: 0
Training loss: 2.684353872089484
Validation loss: 2.50149546778972

Epoch: 6| Step: 1
Training loss: 2.2956257231825705
Validation loss: 2.497250172637576

Epoch: 6| Step: 2
Training loss: 1.6353453926380983
Validation loss: 2.482719839504855

Epoch: 6| Step: 3
Training loss: 1.4156566085823397
Validation loss: 2.4864521420202905

Epoch: 6| Step: 4
Training loss: 1.6682873316674791
Validation loss: 2.4988435244335045

Epoch: 6| Step: 5
Training loss: 2.1261914223076044
Validation loss: 2.464702791920692

Epoch: 6| Step: 6
Training loss: 1.875701137422348
Validation loss: 2.5049004281853495

Epoch: 6| Step: 7
Training loss: 1.9396340092786994
Validation loss: 2.519088760443594

Epoch: 6| Step: 8
Training loss: 2.135094619905569
Validation loss: 2.5229718630722697

Epoch: 6| Step: 9
Training loss: 1.5483026563208075
Validation loss: 2.4758324745830516

Epoch: 6| Step: 10
Training loss: 2.2852560950743492
Validation loss: 2.4363524851914833

Epoch: 6| Step: 11
Training loss: 1.2313180081712052
Validation loss: 2.4637413042005267

Epoch: 6| Step: 12
Training loss: 1.6159212619228998
Validation loss: 2.50595909973136

Epoch: 6| Step: 13
Training loss: 1.4707854755745764
Validation loss: 2.4329254033778174

Epoch: 375| Step: 0
Training loss: 2.296692406279892
Validation loss: 2.4729793412472665

Epoch: 6| Step: 1
Training loss: 2.109811921257109
Validation loss: 2.489563401301578

Epoch: 6| Step: 2
Training loss: 1.5742753920292125
Validation loss: 2.4901546262662615

Epoch: 6| Step: 3
Training loss: 1.724784384257979
Validation loss: 2.529314673373775

Epoch: 6| Step: 4
Training loss: 2.195177175891989
Validation loss: 2.476373514852858

Epoch: 6| Step: 5
Training loss: 1.7854115910793642
Validation loss: 2.5022434494832453

Epoch: 6| Step: 6
Training loss: 1.9252447344286046
Validation loss: 2.5315845632500853

Epoch: 6| Step: 7
Training loss: 1.41659571900077
Validation loss: 2.4811096061178692

Epoch: 6| Step: 8
Training loss: 1.8958966241130133
Validation loss: 2.536471628602032

Epoch: 6| Step: 9
Training loss: 1.6307182936263775
Validation loss: 2.4591210550881577

Epoch: 6| Step: 10
Training loss: 2.1164843528307946
Validation loss: 2.496297409949316

Epoch: 6| Step: 11
Training loss: 1.876661009986081
Validation loss: 2.452095741207612

Epoch: 6| Step: 12
Training loss: 1.7362548675359024
Validation loss: 2.4769527766611703

Epoch: 6| Step: 13
Training loss: 1.383812365069873
Validation loss: 2.523266062781081

Epoch: 376| Step: 0
Training loss: 1.6420902067303718
Validation loss: 2.496773696584282

Epoch: 6| Step: 1
Training loss: 1.8792834626953967
Validation loss: 2.525988760519838

Epoch: 6| Step: 2
Training loss: 1.9822869315987057
Validation loss: 2.451249513898756

Epoch: 6| Step: 3
Training loss: 1.9730293147775164
Validation loss: 2.453938037707837

Epoch: 6| Step: 4
Training loss: 1.8919996828316872
Validation loss: 2.4905601483654936

Epoch: 6| Step: 5
Training loss: 1.9572495511978187
Validation loss: 2.5234122641255983

Epoch: 6| Step: 6
Training loss: 2.136290903163006
Validation loss: 2.4957920880531885

Epoch: 6| Step: 7
Training loss: 1.5070028552539003
Validation loss: 2.515671863296469

Epoch: 6| Step: 8
Training loss: 1.3799236747809007
Validation loss: 2.5358891827806125

Epoch: 6| Step: 9
Training loss: 1.4941547467929457
Validation loss: 2.4864366979698342

Epoch: 6| Step: 10
Training loss: 2.3400832930844575
Validation loss: 2.50180580385736

Epoch: 6| Step: 11
Training loss: 1.9656104834768018
Validation loss: 2.4686644344473216

Epoch: 6| Step: 12
Training loss: 1.742677354584783
Validation loss: 2.5121835709655373

Epoch: 6| Step: 13
Training loss: 2.651331757647716
Validation loss: 2.5195306272856506

Epoch: 377| Step: 0
Training loss: 1.5819013377408186
Validation loss: 2.458777695323159

Epoch: 6| Step: 1
Training loss: 2.0438939875006024
Validation loss: 2.4989891972370217

Epoch: 6| Step: 2
Training loss: 2.1947118405775705
Validation loss: 2.476011896756661

Epoch: 6| Step: 3
Training loss: 1.1082435533304649
Validation loss: 2.4909204520525163

Epoch: 6| Step: 4
Training loss: 2.368114629799796
Validation loss: 2.526941833018896

Epoch: 6| Step: 5
Training loss: 1.5021307434698534
Validation loss: 2.504278805703978

Epoch: 6| Step: 6
Training loss: 2.1723452271705668
Validation loss: 2.4739003755076823

Epoch: 6| Step: 7
Training loss: 1.9046147320861098
Validation loss: 2.4605617576863392

Epoch: 6| Step: 8
Training loss: 2.0896987436915366
Validation loss: 2.5117548090571233

Epoch: 6| Step: 9
Training loss: 1.5189418875582208
Validation loss: 2.47910305102545

Epoch: 6| Step: 10
Training loss: 1.2750508204784845
Validation loss: 2.487383762858708

Epoch: 6| Step: 11
Training loss: 2.2528655560199273
Validation loss: 2.510623338399456

Epoch: 6| Step: 12
Training loss: 1.8853883969486587
Validation loss: 2.4530588620134015

Epoch: 6| Step: 13
Training loss: 2.2413882648734362
Validation loss: 2.481668485136432

Epoch: 378| Step: 0
Training loss: 1.8652540595329108
Validation loss: 2.45411407824124

Epoch: 6| Step: 1
Training loss: 1.6016488400888653
Validation loss: 2.483057871118319

Epoch: 6| Step: 2
Training loss: 2.9713775250483243
Validation loss: 2.472552462447313

Epoch: 6| Step: 3
Training loss: 1.7113878885337892
Validation loss: 2.502426433271328

Epoch: 6| Step: 4
Training loss: 1.974831528057263
Validation loss: 2.4609758021532886

Epoch: 6| Step: 5
Training loss: 1.5023909427969036
Validation loss: 2.4594363888461372

Epoch: 6| Step: 6
Training loss: 1.972097245884683
Validation loss: 2.514536228689088

Epoch: 6| Step: 7
Training loss: 1.6364942592446732
Validation loss: 2.482714642455789

Epoch: 6| Step: 8
Training loss: 1.285821852460738
Validation loss: 2.4898030647528064

Epoch: 6| Step: 9
Training loss: 1.7970015771484247
Validation loss: 2.464923313980379

Epoch: 6| Step: 10
Training loss: 2.035116770063022
Validation loss: 2.4469276929959936

Epoch: 6| Step: 11
Training loss: 1.9978175176124569
Validation loss: 2.466381225793684

Epoch: 6| Step: 12
Training loss: 1.9394182737970465
Validation loss: 2.483206819682744

Epoch: 6| Step: 13
Training loss: 2.0181885024045183
Validation loss: 2.4599941489339083

Epoch: 379| Step: 0
Training loss: 2.1208145210715825
Validation loss: 2.5071744171271306

Epoch: 6| Step: 1
Training loss: 1.8757245253407013
Validation loss: 2.4803645162375596

Epoch: 6| Step: 2
Training loss: 1.6292408112469792
Validation loss: 2.475106790202017

Epoch: 6| Step: 3
Training loss: 1.8618241536809368
Validation loss: 2.4906688302033713

Epoch: 6| Step: 4
Training loss: 1.7469141865328883
Validation loss: 2.5206298854505085

Epoch: 6| Step: 5
Training loss: 2.4868246033790142
Validation loss: 2.448070979092743

Epoch: 6| Step: 6
Training loss: 1.9284186264842906
Validation loss: 2.4991084221505737

Epoch: 6| Step: 7
Training loss: 2.3135015020157437
Validation loss: 2.4862032614089506

Epoch: 6| Step: 8
Training loss: 1.4061629798243702
Validation loss: 2.4874683412946927

Epoch: 6| Step: 9
Training loss: 1.2035898573880697
Validation loss: 2.519544424645944

Epoch: 6| Step: 10
Training loss: 1.6924940315941477
Validation loss: 2.4278917500941897

Epoch: 6| Step: 11
Training loss: 1.937392754816799
Validation loss: 2.524947990597427

Epoch: 6| Step: 12
Training loss: 1.8558098730423847
Validation loss: 2.4725700357815015

Epoch: 6| Step: 13
Training loss: 1.8805066943649176
Validation loss: 2.4818126259729567

Epoch: 380| Step: 0
Training loss: 1.6432531468918286
Validation loss: 2.506428586116555

Epoch: 6| Step: 1
Training loss: 1.5329023515690101
Validation loss: 2.441835454543958

Epoch: 6| Step: 2
Training loss: 1.5523358679361576
Validation loss: 2.443156365114996

Epoch: 6| Step: 3
Training loss: 1.5986046249710275
Validation loss: 2.489321669484981

Epoch: 6| Step: 4
Training loss: 2.499329286249316
Validation loss: 2.4260504138658354

Epoch: 6| Step: 5
Training loss: 1.7121741994308808
Validation loss: 2.4472176319327406

Epoch: 6| Step: 6
Training loss: 2.4326467860629064
Validation loss: 2.508796324875262

Epoch: 6| Step: 7
Training loss: 1.821729771369453
Validation loss: 2.43499796145781

Epoch: 6| Step: 8
Training loss: 1.9774416449770524
Validation loss: 2.478575132231263

Epoch: 6| Step: 9
Training loss: 1.474076130431775
Validation loss: 2.4846144215347197

Epoch: 6| Step: 10
Training loss: 1.832162945859528
Validation loss: 2.507347832881368

Epoch: 6| Step: 11
Training loss: 2.126545736567722
Validation loss: 2.4795517033458565

Epoch: 6| Step: 12
Training loss: 2.195160884305157
Validation loss: 2.469022705418295

Epoch: 6| Step: 13
Training loss: 1.6991665536164224
Validation loss: 2.4920228208147015

Epoch: 381| Step: 0
Training loss: 1.7964531444763796
Validation loss: 2.5114959999245614

Epoch: 6| Step: 1
Training loss: 2.74654691817833
Validation loss: 2.451853178755914

Epoch: 6| Step: 2
Training loss: 1.858130928386799
Validation loss: 2.457037324084533

Epoch: 6| Step: 3
Training loss: 1.520689535092516
Validation loss: 2.4840526654188646

Epoch: 6| Step: 4
Training loss: 1.437927265524272
Validation loss: 2.523120094787194

Epoch: 6| Step: 5
Training loss: 1.6194645427651195
Validation loss: 2.4673128390706456

Epoch: 6| Step: 6
Training loss: 1.8211568421342363
Validation loss: 2.5208891510959734

Epoch: 6| Step: 7
Training loss: 2.4513034739636104
Validation loss: 2.4652105556137025

Epoch: 6| Step: 8
Training loss: 1.908048687935459
Validation loss: 2.505131165644982

Epoch: 6| Step: 9
Training loss: 2.123085730512078
Validation loss: 2.5089940021915527

Epoch: 6| Step: 10
Training loss: 1.4599446069320776
Validation loss: 2.4326738719206515

Epoch: 6| Step: 11
Training loss: 1.4668575025440527
Validation loss: 2.489037778885959

Epoch: 6| Step: 12
Training loss: 1.6250566325956355
Validation loss: 2.471603324113941

Epoch: 6| Step: 13
Training loss: 2.2391856232231
Validation loss: 2.490639892349148

Epoch: 382| Step: 0
Training loss: 1.4409493236433075
Validation loss: 2.5096730335141495

Epoch: 6| Step: 1
Training loss: 2.0351043518829637
Validation loss: 2.483258501676093

Epoch: 6| Step: 2
Training loss: 2.4732427157675834
Validation loss: 2.476360365200912

Epoch: 6| Step: 3
Training loss: 2.161993035664312
Validation loss: 2.459140143761963

Epoch: 6| Step: 4
Training loss: 2.1461271313271166
Validation loss: 2.425734393363274

Epoch: 6| Step: 5
Training loss: 1.6119732669194422
Validation loss: 2.496869258834742

Epoch: 6| Step: 6
Training loss: 1.3796326018284115
Validation loss: 2.4851221772148264

Epoch: 6| Step: 7
Training loss: 1.814459497873799
Validation loss: 2.4560291726132517

Epoch: 6| Step: 8
Training loss: 1.7408761190899893
Validation loss: 2.4429092893048856

Epoch: 6| Step: 9
Training loss: 1.1484264970109603
Validation loss: 2.4481181093029365

Epoch: 6| Step: 10
Training loss: 1.5133823437813851
Validation loss: 2.4845386496889468

Epoch: 6| Step: 11
Training loss: 1.9402802730912285
Validation loss: 2.489504071768812

Epoch: 6| Step: 12
Training loss: 2.5692692178540293
Validation loss: 2.4612175582392313

Epoch: 6| Step: 13
Training loss: 1.9830746332379479
Validation loss: 2.4966293161725037

Epoch: 383| Step: 0
Training loss: 1.839932579277298
Validation loss: 2.4457827152686242

Epoch: 6| Step: 1
Training loss: 2.1977509229699534
Validation loss: 2.470489138600099

Epoch: 6| Step: 2
Training loss: 1.7817776216453656
Validation loss: 2.526910796540364

Epoch: 6| Step: 3
Training loss: 1.5748027920253227
Validation loss: 2.487362029289863

Epoch: 6| Step: 4
Training loss: 1.6644951343047008
Validation loss: 2.478369237047181

Epoch: 6| Step: 5
Training loss: 1.533260660246098
Validation loss: 2.489548233477472

Epoch: 6| Step: 6
Training loss: 2.031376526633244
Validation loss: 2.470497724562056

Epoch: 6| Step: 7
Training loss: 1.7593206420957215
Validation loss: 2.5011117288610674

Epoch: 6| Step: 8
Training loss: 2.3455312445158865
Validation loss: 2.4345793705237546

Epoch: 6| Step: 9
Training loss: 2.168223433097927
Validation loss: 2.4633769367227667

Epoch: 6| Step: 10
Training loss: 2.390454255034
Validation loss: 2.4571574228106314

Epoch: 6| Step: 11
Training loss: 1.2583051392047158
Validation loss: 2.4819767658454084

Epoch: 6| Step: 12
Training loss: 1.529943414776178
Validation loss: 2.4832539034975487

Epoch: 6| Step: 13
Training loss: 1.5785960636916767
Validation loss: 2.51481953350364

Epoch: 384| Step: 0
Training loss: 2.0199014409259397
Validation loss: 2.488291244781682

Epoch: 6| Step: 1
Training loss: 2.071339018065075
Validation loss: 2.471714263552433

Epoch: 6| Step: 2
Training loss: 1.9699196141684057
Validation loss: 2.4968387705704775

Epoch: 6| Step: 3
Training loss: 1.8959904979355036
Validation loss: 2.4835365362856807

Epoch: 6| Step: 4
Training loss: 1.6367162736314051
Validation loss: 2.4568384198779856

Epoch: 6| Step: 5
Training loss: 1.725170558292772
Validation loss: 2.4718794224582847

Epoch: 6| Step: 6
Training loss: 2.2245920128684857
Validation loss: 2.4567964573605856

Epoch: 6| Step: 7
Training loss: 1.867843640332572
Validation loss: 2.501761291844312

Epoch: 6| Step: 8
Training loss: 1.2109211582188657
Validation loss: 2.519156163919511

Epoch: 6| Step: 9
Training loss: 1.7033368600085952
Validation loss: 2.494499987078651

Epoch: 6| Step: 10
Training loss: 1.7822922451509584
Validation loss: 2.4378812779369867

Epoch: 6| Step: 11
Training loss: 2.243013236555686
Validation loss: 2.4666086996041425

Epoch: 6| Step: 12
Training loss: 1.6607781176744352
Validation loss: 2.4664634873117226

Epoch: 6| Step: 13
Training loss: 1.206185794762109
Validation loss: 2.4621663989197287

Epoch: 385| Step: 0
Training loss: 2.0665625817740017
Validation loss: 2.46028110795863

Epoch: 6| Step: 1
Training loss: 1.6162014963848115
Validation loss: 2.4711048333216112

Epoch: 6| Step: 2
Training loss: 2.0853166549231914
Validation loss: 2.4647794075819593

Epoch: 6| Step: 3
Training loss: 1.2260774272844817
Validation loss: 2.473084041378579

Epoch: 6| Step: 4
Training loss: 1.433476830477858
Validation loss: 2.4508638366284283

Epoch: 6| Step: 5
Training loss: 2.1097469425769164
Validation loss: 2.5166919748405148

Epoch: 6| Step: 6
Training loss: 1.8995545166177208
Validation loss: 2.531272548796399

Epoch: 6| Step: 7
Training loss: 1.6639061796167025
Validation loss: 2.5304725128460825

Epoch: 6| Step: 8
Training loss: 2.0767788076151192
Validation loss: 2.468675549195673

Epoch: 6| Step: 9
Training loss: 2.136106748649509
Validation loss: 2.455523778350681

Epoch: 6| Step: 10
Training loss: 1.8556061061412472
Validation loss: 2.4419152443204277

Epoch: 6| Step: 11
Training loss: 2.062116876333084
Validation loss: 2.443977985941275

Epoch: 6| Step: 12
Training loss: 1.9510011035010786
Validation loss: 2.4810507186842137

Epoch: 6| Step: 13
Training loss: 1.4121123718820854
Validation loss: 2.4597200845211775

Epoch: 386| Step: 0
Training loss: 1.6715677995182339
Validation loss: 2.4849148292345116

Epoch: 6| Step: 1
Training loss: 2.3466381334426902
Validation loss: 2.4910590600576077

Epoch: 6| Step: 2
Training loss: 2.0095084186120387
Validation loss: 2.4653716912975385

Epoch: 6| Step: 3
Training loss: 2.035131882651627
Validation loss: 2.4542552370922146

Epoch: 6| Step: 4
Training loss: 1.1356041546400606
Validation loss: 2.488683619251234

Epoch: 6| Step: 5
Training loss: 1.3711538274487007
Validation loss: 2.4654318204506858

Epoch: 6| Step: 6
Training loss: 2.003750503168739
Validation loss: 2.486415254098812

Epoch: 6| Step: 7
Training loss: 1.789076492721276
Validation loss: 2.4769825595783543

Epoch: 6| Step: 8
Training loss: 1.778492583509526
Validation loss: 2.4771969454437937

Epoch: 6| Step: 9
Training loss: 2.2783423928352997
Validation loss: 2.5269655925288386

Epoch: 6| Step: 10
Training loss: 1.7016843249494205
Validation loss: 2.499606073784433

Epoch: 6| Step: 11
Training loss: 2.074686403591707
Validation loss: 2.500319722968242

Epoch: 6| Step: 12
Training loss: 1.736959507805692
Validation loss: 2.4644813066353706

Epoch: 6| Step: 13
Training loss: 1.8687170937999567
Validation loss: 2.4365224484585446

Epoch: 387| Step: 0
Training loss: 1.7543399673839983
Validation loss: 2.4701890034307317

Epoch: 6| Step: 1
Training loss: 2.0742362213835746
Validation loss: 2.485858138386246

Epoch: 6| Step: 2
Training loss: 2.3114081202091823
Validation loss: 2.485058661073638

Epoch: 6| Step: 3
Training loss: 1.84511606073653
Validation loss: 2.4965069918023177

Epoch: 6| Step: 4
Training loss: 1.3291998608947553
Validation loss: 2.4588083427392924

Epoch: 6| Step: 5
Training loss: 1.3547167712154458
Validation loss: 2.48283916005706

Epoch: 6| Step: 6
Training loss: 1.4575933849850404
Validation loss: 2.4434971745979084

Epoch: 6| Step: 7
Training loss: 1.3719865983831194
Validation loss: 2.497167123575317

Epoch: 6| Step: 8
Training loss: 2.0408946024227324
Validation loss: 2.449483352223599

Epoch: 6| Step: 9
Training loss: 1.2691517424045138
Validation loss: 2.4576105070506564

Epoch: 6| Step: 10
Training loss: 1.5225833943896452
Validation loss: 2.4543710364008833

Epoch: 6| Step: 11
Training loss: 2.649794689358395
Validation loss: 2.4886916191436357

Epoch: 6| Step: 12
Training loss: 1.774523633514152
Validation loss: 2.4457242398173467

Epoch: 6| Step: 13
Training loss: 2.2603227329220292
Validation loss: 2.501919179461974

Epoch: 388| Step: 0
Training loss: 2.291808788632054
Validation loss: 2.4595992994956513

Epoch: 6| Step: 1
Training loss: 1.367362092995451
Validation loss: 2.509148702111651

Epoch: 6| Step: 2
Training loss: 1.488799397940619
Validation loss: 2.5197596140051597

Epoch: 6| Step: 3
Training loss: 1.8738632571020595
Validation loss: 2.4971019015823672

Epoch: 6| Step: 4
Training loss: 2.5354810603628053
Validation loss: 2.4604164917156615

Epoch: 6| Step: 5
Training loss: 1.9294858510530888
Validation loss: 2.4795733006595726

Epoch: 6| Step: 6
Training loss: 1.7719517336314723
Validation loss: 2.4730091865303607

Epoch: 6| Step: 7
Training loss: 1.945391917618341
Validation loss: 2.4748933347553

Epoch: 6| Step: 8
Training loss: 1.8087538448522231
Validation loss: 2.4398528723367097

Epoch: 6| Step: 9
Training loss: 1.7019601040343124
Validation loss: 2.4878258519178824

Epoch: 6| Step: 10
Training loss: 1.6109993154096895
Validation loss: 2.4390436358834293

Epoch: 6| Step: 11
Training loss: 2.0594324361522345
Validation loss: 2.4917131100324212

Epoch: 6| Step: 12
Training loss: 1.7446723631499927
Validation loss: 2.4645193519103046

Epoch: 6| Step: 13
Training loss: 2.0247242492553057
Validation loss: 2.5169654861383566

Epoch: 389| Step: 0
Training loss: 1.7009259647312542
Validation loss: 2.5155059820947523

Epoch: 6| Step: 1
Training loss: 1.128144637594728
Validation loss: 2.5200603316563206

Epoch: 6| Step: 2
Training loss: 0.8603037583821201
Validation loss: 2.495458307590394

Epoch: 6| Step: 3
Training loss: 2.1317529526765333
Validation loss: 2.5102617735715644

Epoch: 6| Step: 4
Training loss: 1.5645722952231962
Validation loss: 2.4678963051858918

Epoch: 6| Step: 5
Training loss: 1.7406045196807647
Validation loss: 2.455263783353093

Epoch: 6| Step: 6
Training loss: 1.673668015789032
Validation loss: 2.5009215263900337

Epoch: 6| Step: 7
Training loss: 2.7845320463578083
Validation loss: 2.5403333266877848

Epoch: 6| Step: 8
Training loss: 1.769189258394659
Validation loss: 2.4777996171605965

Epoch: 6| Step: 9
Training loss: 2.1240101921282415
Validation loss: 2.5270039433833245

Epoch: 6| Step: 10
Training loss: 1.4777906043628162
Validation loss: 2.5060798528140227

Epoch: 6| Step: 11
Training loss: 1.7950641297597005
Validation loss: 2.5046117464216646

Epoch: 6| Step: 12
Training loss: 2.1828712537390724
Validation loss: 2.4427804736621774

Epoch: 6| Step: 13
Training loss: 2.369864784761565
Validation loss: 2.424619679576698

Epoch: 390| Step: 0
Training loss: 1.5320834791432216
Validation loss: 2.4564047827191695

Epoch: 6| Step: 1
Training loss: 1.7233241855863073
Validation loss: 2.4643857903722943

Epoch: 6| Step: 2
Training loss: 2.3328334636218977
Validation loss: 2.5143981308195937

Epoch: 6| Step: 3
Training loss: 1.689296543163822
Validation loss: 2.497538624430259

Epoch: 6| Step: 4
Training loss: 2.1548861184531765
Validation loss: 2.514588827638681

Epoch: 6| Step: 5
Training loss: 1.9950264841487277
Validation loss: 2.420694062879342

Epoch: 6| Step: 6
Training loss: 1.824463266326445
Validation loss: 2.4167625979632446

Epoch: 6| Step: 7
Training loss: 1.5756290451173407
Validation loss: 2.4611993976181865

Epoch: 6| Step: 8
Training loss: 1.3224222155304788
Validation loss: 2.495006274511916

Epoch: 6| Step: 9
Training loss: 1.7741968486984523
Validation loss: 2.4943847557327645

Epoch: 6| Step: 10
Training loss: 2.071326817047474
Validation loss: 2.5072225713089265

Epoch: 6| Step: 11
Training loss: 1.8335874410292372
Validation loss: 2.4765509713863625

Epoch: 6| Step: 12
Training loss: 1.5683113366319834
Validation loss: 2.470177558195413

Epoch: 6| Step: 13
Training loss: 2.419106753355639
Validation loss: 2.488642501705998

Epoch: 391| Step: 0
Training loss: 1.260784452809894
Validation loss: 2.4928863406569666

Epoch: 6| Step: 1
Training loss: 1.627658137126018
Validation loss: 2.5372283515340097

Epoch: 6| Step: 2
Training loss: 1.4968774401300406
Validation loss: 2.448459667826851

Epoch: 6| Step: 3
Training loss: 1.7221938570140949
Validation loss: 2.5559430985137004

Epoch: 6| Step: 4
Training loss: 1.765964441669402
Validation loss: 2.4564775087838644

Epoch: 6| Step: 5
Training loss: 1.6559149925140666
Validation loss: 2.470313941724914

Epoch: 6| Step: 6
Training loss: 2.2711848998830515
Validation loss: 2.4215547898414984

Epoch: 6| Step: 7
Training loss: 1.9865220836964466
Validation loss: 2.494412137289992

Epoch: 6| Step: 8
Training loss: 1.6920414320019128
Validation loss: 2.5140967195826485

Epoch: 6| Step: 9
Training loss: 2.1869168185378274
Validation loss: 2.518822085194515

Epoch: 6| Step: 10
Training loss: 1.7815962337825795
Validation loss: 2.5288473870387294

Epoch: 6| Step: 11
Training loss: 2.184816512864468
Validation loss: 2.512886241581797

Epoch: 6| Step: 12
Training loss: 2.026646371016186
Validation loss: 2.4789666474056253

Epoch: 6| Step: 13
Training loss: 2.2438260248847173
Validation loss: 2.515621066321256

Epoch: 392| Step: 0
Training loss: 1.599632477273268
Validation loss: 2.4970441787489652

Epoch: 6| Step: 1
Training loss: 2.036233276523321
Validation loss: 2.4776429448530757

Epoch: 6| Step: 2
Training loss: 1.7518106357973247
Validation loss: 2.503909348187787

Epoch: 6| Step: 3
Training loss: 2.362773544379885
Validation loss: 2.5131392256217966

Epoch: 6| Step: 4
Training loss: 1.449038265536495
Validation loss: 2.46933075426716

Epoch: 6| Step: 5
Training loss: 1.7413804447252428
Validation loss: 2.4915385093521785

Epoch: 6| Step: 6
Training loss: 1.7774691694673588
Validation loss: 2.4766731386297907

Epoch: 6| Step: 7
Training loss: 2.299653429374338
Validation loss: 2.515460354999057

Epoch: 6| Step: 8
Training loss: 1.3346024473506577
Validation loss: 2.502355453443711

Epoch: 6| Step: 9
Training loss: 1.7704143552105938
Validation loss: 2.483880680391787

Epoch: 6| Step: 10
Training loss: 2.0989647447915676
Validation loss: 2.4848917204933483

Epoch: 6| Step: 11
Training loss: 1.7615307625156078
Validation loss: 2.4697547416338184

Epoch: 6| Step: 12
Training loss: 1.630702284139843
Validation loss: 2.4515823395140273

Epoch: 6| Step: 13
Training loss: 1.5772716367806234
Validation loss: 2.5204982068688744

Epoch: 393| Step: 0
Training loss: 1.8094150334542944
Validation loss: 2.481288044352342

Epoch: 6| Step: 1
Training loss: 1.5328630009380406
Validation loss: 2.4808485661954145

Epoch: 6| Step: 2
Training loss: 2.062449136742623
Validation loss: 2.4186813335842072

Epoch: 6| Step: 3
Training loss: 1.8845721367854744
Validation loss: 2.4516643279683303

Epoch: 6| Step: 4
Training loss: 2.398562549226363
Validation loss: 2.496505471489685

Epoch: 6| Step: 5
Training loss: 1.4769163161934573
Validation loss: 2.4437685993872487

Epoch: 6| Step: 6
Training loss: 1.7318293817322277
Validation loss: 2.4199527650213457

Epoch: 6| Step: 7
Training loss: 1.7575325297876334
Validation loss: 2.4821133996252804

Epoch: 6| Step: 8
Training loss: 1.382122277021766
Validation loss: 2.522210026849582

Epoch: 6| Step: 9
Training loss: 2.1377389205451003
Validation loss: 2.4886839664013607

Epoch: 6| Step: 10
Training loss: 1.9065313913245585
Validation loss: 2.4976640575839797

Epoch: 6| Step: 11
Training loss: 1.4757017826072398
Validation loss: 2.523257489750773

Epoch: 6| Step: 12
Training loss: 2.3229425083884085
Validation loss: 2.5068360745364253

Epoch: 6| Step: 13
Training loss: 1.505636037847044
Validation loss: 2.5021084528656115

Epoch: 394| Step: 0
Training loss: 1.6844705303328444
Validation loss: 2.4731362784128867

Epoch: 6| Step: 1
Training loss: 1.4186966974269593
Validation loss: 2.4775610343448426

Epoch: 6| Step: 2
Training loss: 1.957118658675956
Validation loss: 2.4099622967405105

Epoch: 6| Step: 3
Training loss: 1.7862064936620536
Validation loss: 2.4820865186324608

Epoch: 6| Step: 4
Training loss: 1.3508419696140357
Validation loss: 2.488725636426238

Epoch: 6| Step: 5
Training loss: 1.7351577641988483
Validation loss: 2.4720310263836622

Epoch: 6| Step: 6
Training loss: 1.9619653447286003
Validation loss: 2.5409396463362652

Epoch: 6| Step: 7
Training loss: 1.6737329017500842
Validation loss: 2.5244769509930216

Epoch: 6| Step: 8
Training loss: 1.812180984309061
Validation loss: 2.498731127078481

Epoch: 6| Step: 9
Training loss: 2.0525791969771303
Validation loss: 2.509735383290902

Epoch: 6| Step: 10
Training loss: 2.361709248444489
Validation loss: 2.522733220211164

Epoch: 6| Step: 11
Training loss: 1.8702634111812617
Validation loss: 2.5096927709336914

Epoch: 6| Step: 12
Training loss: 1.8476746378784081
Validation loss: 2.561244173657823

Epoch: 6| Step: 13
Training loss: 1.9482882616144996
Validation loss: 2.477466198271008

Epoch: 395| Step: 0
Training loss: 2.2739932505055345
Validation loss: 2.522068485514139

Epoch: 6| Step: 1
Training loss: 1.9911037114988406
Validation loss: 2.4595709143727986

Epoch: 6| Step: 2
Training loss: 1.47255619427589
Validation loss: 2.4887225574502003

Epoch: 6| Step: 3
Training loss: 1.4931710082766427
Validation loss: 2.4709812453783013

Epoch: 6| Step: 4
Training loss: 1.6403191417603957
Validation loss: 2.48331617846458

Epoch: 6| Step: 5
Training loss: 2.0931810203748786
Validation loss: 2.492029888240427

Epoch: 6| Step: 6
Training loss: 2.209134502351815
Validation loss: 2.514854456324113

Epoch: 6| Step: 7
Training loss: 2.131320529341259
Validation loss: 2.455455293199889

Epoch: 6| Step: 8
Training loss: 1.5601419584778262
Validation loss: 2.4831681171033506

Epoch: 6| Step: 9
Training loss: 1.4545800912049278
Validation loss: 2.474215742535407

Epoch: 6| Step: 10
Training loss: 1.582104264446472
Validation loss: 2.4821111779727665

Epoch: 6| Step: 11
Training loss: 1.9585427787730805
Validation loss: 2.5056979690298338

Epoch: 6| Step: 12
Training loss: 1.6063814933181955
Validation loss: 2.460305695133638

Epoch: 6| Step: 13
Training loss: 1.9166614560042607
Validation loss: 2.503133899418444

Epoch: 396| Step: 0
Training loss: 1.6564594352308135
Validation loss: 2.4470024885666857

Epoch: 6| Step: 1
Training loss: 2.014625005544175
Validation loss: 2.486084747846852

Epoch: 6| Step: 2
Training loss: 1.620486961691292
Validation loss: 2.474011027493299

Epoch: 6| Step: 3
Training loss: 2.1477148331818143
Validation loss: 2.5097628987053593

Epoch: 6| Step: 4
Training loss: 1.8504549085786612
Validation loss: 2.5097832825125224

Epoch: 6| Step: 5
Training loss: 1.9865567686206183
Validation loss: 2.512718632821328

Epoch: 6| Step: 6
Training loss: 1.4880953294663175
Validation loss: 2.517833523174531

Epoch: 6| Step: 7
Training loss: 1.7808929888679645
Validation loss: 2.5303160335573227

Epoch: 6| Step: 8
Training loss: 1.6111438992697247
Validation loss: 2.5071360824897235

Epoch: 6| Step: 9
Training loss: 1.6459832022633702
Validation loss: 2.502620831715858

Epoch: 6| Step: 10
Training loss: 2.31315933313377
Validation loss: 2.4751331333106785

Epoch: 6| Step: 11
Training loss: 1.6252923849130343
Validation loss: 2.5057914747130727

Epoch: 6| Step: 12
Training loss: 1.7138372782735667
Validation loss: 2.4763188649714887

Epoch: 6| Step: 13
Training loss: 2.5960833613290863
Validation loss: 2.5030471709977333

Epoch: 397| Step: 0
Training loss: 1.6817178918896032
Validation loss: 2.477405975220854

Epoch: 6| Step: 1
Training loss: 1.923173667234892
Validation loss: 2.4581362577699486

Epoch: 6| Step: 2
Training loss: 1.4248794839324797
Validation loss: 2.462841481197993

Epoch: 6| Step: 3
Training loss: 1.6441293982052028
Validation loss: 2.5222816411979774

Epoch: 6| Step: 4
Training loss: 1.8130573862612471
Validation loss: 2.472195757627895

Epoch: 6| Step: 5
Training loss: 1.5687767604050031
Validation loss: 2.469225703564074

Epoch: 6| Step: 6
Training loss: 2.5326562436739426
Validation loss: 2.5226241926656834

Epoch: 6| Step: 7
Training loss: 1.593572793720484
Validation loss: 2.509956993473571

Epoch: 6| Step: 8
Training loss: 1.8969385328132613
Validation loss: 2.508778551587301

Epoch: 6| Step: 9
Training loss: 2.1138778662286284
Validation loss: 2.5331673095209455

Epoch: 6| Step: 10
Training loss: 1.7961283583789187
Validation loss: 2.491405352882216

Epoch: 6| Step: 11
Training loss: 1.7655169698698558
Validation loss: 2.4868500723972633

Epoch: 6| Step: 12
Training loss: 1.6889796657523954
Validation loss: 2.5103631064726017

Epoch: 6| Step: 13
Training loss: 1.7889497546522681
Validation loss: 2.467552322376709

Epoch: 398| Step: 0
Training loss: 1.5850150145532542
Validation loss: 2.514797579321647

Epoch: 6| Step: 1
Training loss: 1.9605579996866958
Validation loss: 2.438461771310269

Epoch: 6| Step: 2
Training loss: 2.256862770624233
Validation loss: 2.487395918403111

Epoch: 6| Step: 3
Training loss: 1.9289315167576433
Validation loss: 2.4711996074874123

Epoch: 6| Step: 4
Training loss: 1.8524628072034655
Validation loss: 2.513869394304473

Epoch: 6| Step: 5
Training loss: 1.155789464013984
Validation loss: 2.5537243052421563

Epoch: 6| Step: 6
Training loss: 2.1426655865381474
Validation loss: 2.4667204384013295

Epoch: 6| Step: 7
Training loss: 1.8253080395482573
Validation loss: 2.533289403917722

Epoch: 6| Step: 8
Training loss: 1.5752639519055902
Validation loss: 2.469023314913244

Epoch: 6| Step: 9
Training loss: 1.6782600902547828
Validation loss: 2.519828106453668

Epoch: 6| Step: 10
Training loss: 1.7182972398378007
Validation loss: 2.5070012266187462

Epoch: 6| Step: 11
Training loss: 2.2024498304007127
Validation loss: 2.486506913547648

Epoch: 6| Step: 12
Training loss: 1.6512339226332042
Validation loss: 2.4874891072191048

Epoch: 6| Step: 13
Training loss: 1.5026831471155189
Validation loss: 2.456699221544992

Epoch: 399| Step: 0
Training loss: 1.5335335345113739
Validation loss: 2.5048544134454604

Epoch: 6| Step: 1
Training loss: 2.109358271779734
Validation loss: 2.4989186204166423

Epoch: 6| Step: 2
Training loss: 1.976470402317212
Validation loss: 2.4872362683109586

Epoch: 6| Step: 3
Training loss: 1.6983745714196767
Validation loss: 2.4907240524622756

Epoch: 6| Step: 4
Training loss: 1.5106394460963526
Validation loss: 2.4646408298890816

Epoch: 6| Step: 5
Training loss: 1.5093143869554329
Validation loss: 2.4875621539924637

Epoch: 6| Step: 6
Training loss: 1.659394643778649
Validation loss: 2.4749087286086286

Epoch: 6| Step: 7
Training loss: 1.5134960835421614
Validation loss: 2.491511275251267

Epoch: 6| Step: 8
Training loss: 2.6675553231906393
Validation loss: 2.488720053268486

Epoch: 6| Step: 9
Training loss: 1.5201108949764564
Validation loss: 2.5088013636658384

Epoch: 6| Step: 10
Training loss: 1.5243521267847222
Validation loss: 2.4521329373550627

Epoch: 6| Step: 11
Training loss: 1.9465766078004767
Validation loss: 2.4900893564965183

Epoch: 6| Step: 12
Training loss: 2.035560611670451
Validation loss: 2.5196085244001636

Epoch: 6| Step: 13
Training loss: 1.4184167747891216
Validation loss: 2.506952869798544

Epoch: 400| Step: 0
Training loss: 1.293817800320913
Validation loss: 2.463817051275268

Epoch: 6| Step: 1
Training loss: 2.1557864368097346
Validation loss: 2.5322922769020693

Epoch: 6| Step: 2
Training loss: 1.7847512618430588
Validation loss: 2.4877090480039485

Epoch: 6| Step: 3
Training loss: 1.7029265541864238
Validation loss: 2.4776826199529505

Epoch: 6| Step: 4
Training loss: 1.5706231108964155
Validation loss: 2.46937361515289

Epoch: 6| Step: 5
Training loss: 1.6156847324802872
Validation loss: 2.467542863842085

Epoch: 6| Step: 6
Training loss: 1.4757262591753435
Validation loss: 2.5307961840386866

Epoch: 6| Step: 7
Training loss: 1.9518241517561623
Validation loss: 2.478672550879518

Epoch: 6| Step: 8
Training loss: 1.8523978751137213
Validation loss: 2.4766422754592483

Epoch: 6| Step: 9
Training loss: 1.6735279076639573
Validation loss: 2.5088335499664067

Epoch: 6| Step: 10
Training loss: 1.965916850585377
Validation loss: 2.489737816657185

Epoch: 6| Step: 11
Training loss: 2.490443369753265
Validation loss: 2.4740002092445303

Epoch: 6| Step: 12
Training loss: 2.2006070513265525
Validation loss: 2.4684147968716754

Epoch: 6| Step: 13
Training loss: 1.6993295918410127
Validation loss: 2.485086496136575

Epoch: 401| Step: 0
Training loss: 2.064319501610694
Validation loss: 2.4805586748437682

Epoch: 6| Step: 1
Training loss: 1.9781667358430994
Validation loss: 2.4910552028497657

Epoch: 6| Step: 2
Training loss: 1.4690626095802382
Validation loss: 2.5213292779066956

Epoch: 6| Step: 3
Training loss: 1.7136228903522954
Validation loss: 2.509933723076705

Epoch: 6| Step: 4
Training loss: 1.819959483481677
Validation loss: 2.5210936867909646

Epoch: 6| Step: 5
Training loss: 1.969146083165107
Validation loss: 2.4530961940462195

Epoch: 6| Step: 6
Training loss: 2.021680857374553
Validation loss: 2.5108410770916314

Epoch: 6| Step: 7
Training loss: 1.7695205384997614
Validation loss: 2.449829645033305

Epoch: 6| Step: 8
Training loss: 2.2893484932929447
Validation loss: 2.4533872227124878

Epoch: 6| Step: 9
Training loss: 2.215364694301994
Validation loss: 2.5048264357428796

Epoch: 6| Step: 10
Training loss: 0.7818197461676119
Validation loss: 2.5203517825745205

Epoch: 6| Step: 11
Training loss: 1.8362190842281902
Validation loss: 2.456837735360649

Epoch: 6| Step: 12
Training loss: 1.651394546616023
Validation loss: 2.4393173933119634

Epoch: 6| Step: 13
Training loss: 1.5660320795897507
Validation loss: 2.504279458827148

Epoch: 402| Step: 0
Training loss: 2.320627929619898
Validation loss: 2.495124092041927

Epoch: 6| Step: 1
Training loss: 1.7591281968462256
Validation loss: 2.493006648220172

Epoch: 6| Step: 2
Training loss: 1.60636442496776
Validation loss: 2.5005792274934873

Epoch: 6| Step: 3
Training loss: 1.6532121545211447
Validation loss: 2.4787219155224656

Epoch: 6| Step: 4
Training loss: 1.9470081828748225
Validation loss: 2.4715132310998715

Epoch: 6| Step: 5
Training loss: 1.5109253213227911
Validation loss: 2.4866673187319446

Epoch: 6| Step: 6
Training loss: 1.1208168777808316
Validation loss: 2.4799246976457288

Epoch: 6| Step: 7
Training loss: 2.182083617666781
Validation loss: 2.515077046561538

Epoch: 6| Step: 8
Training loss: 2.0716449408441817
Validation loss: 2.4865732647866836

Epoch: 6| Step: 9
Training loss: 1.917401822397996
Validation loss: 2.4775014323916498

Epoch: 6| Step: 10
Training loss: 2.074497125196545
Validation loss: 2.519558358275153

Epoch: 6| Step: 11
Training loss: 1.7832751891500194
Validation loss: 2.4531387037149583

Epoch: 6| Step: 12
Training loss: 1.7237393181506526
Validation loss: 2.4903895783321097

Epoch: 6| Step: 13
Training loss: 2.015427217464447
Validation loss: 2.4962174605445093

Epoch: 403| Step: 0
Training loss: 2.0817399098461107
Validation loss: 2.5134477950919476

Epoch: 6| Step: 1
Training loss: 1.8946143063301766
Validation loss: 2.515167135553533

Epoch: 6| Step: 2
Training loss: 2.0721016692252823
Validation loss: 2.4858141668856866

Epoch: 6| Step: 3
Training loss: 1.3217469047364396
Validation loss: 2.473527912375928

Epoch: 6| Step: 4
Training loss: 2.1140379053505143
Validation loss: 2.4430919048438278

Epoch: 6| Step: 5
Training loss: 1.7199124653299123
Validation loss: 2.4836165904256573

Epoch: 6| Step: 6
Training loss: 1.7116360566479898
Validation loss: 2.486673166298476

Epoch: 6| Step: 7
Training loss: 1.4721393841804105
Validation loss: 2.4628391172493904

Epoch: 6| Step: 8
Training loss: 2.176731853920756
Validation loss: 2.486722771604861

Epoch: 6| Step: 9
Training loss: 2.135042917682326
Validation loss: 2.5172606979407632

Epoch: 6| Step: 10
Training loss: 1.395353400815295
Validation loss: 2.4619642109246804

Epoch: 6| Step: 11
Training loss: 1.923897152354599
Validation loss: 2.4754492727624746

Epoch: 6| Step: 12
Training loss: 1.7480897013783192
Validation loss: 2.4552861706699436

Epoch: 6| Step: 13
Training loss: 1.999994814389182
Validation loss: 2.4672890667237697

Epoch: 404| Step: 0
Training loss: 2.4798990872063826
Validation loss: 2.4717713519790347

Epoch: 6| Step: 1
Training loss: 2.0552082054678222
Validation loss: 2.4386238754982115

Epoch: 6| Step: 2
Training loss: 1.6108782515929247
Validation loss: 2.494333989291984

Epoch: 6| Step: 3
Training loss: 1.183657956034276
Validation loss: 2.4708833865324

Epoch: 6| Step: 4
Training loss: 1.5580237548593978
Validation loss: 2.500054583415085

Epoch: 6| Step: 5
Training loss: 2.2875676921563457
Validation loss: 2.523596480205762

Epoch: 6| Step: 6
Training loss: 2.015201731160667
Validation loss: 2.5439999537020044

Epoch: 6| Step: 7
Training loss: 1.5750999540068258
Validation loss: 2.5167305856400173

Epoch: 6| Step: 8
Training loss: 1.8300998812657563
Validation loss: 2.5253202500259366

Epoch: 6| Step: 9
Training loss: 2.336790203505697
Validation loss: 2.517099081981909

Epoch: 6| Step: 10
Training loss: 1.5398586944056174
Validation loss: 2.4908459228759123

Epoch: 6| Step: 11
Training loss: 1.6540485362319879
Validation loss: 2.437132051145432

Epoch: 6| Step: 12
Training loss: 0.9490372284057754
Validation loss: 2.4837820679666587

Epoch: 6| Step: 13
Training loss: 1.7328085483956577
Validation loss: 2.489372195723494

Epoch: 405| Step: 0
Training loss: 1.9713537769661589
Validation loss: 2.4931841270112693

Epoch: 6| Step: 1
Training loss: 1.1004705224706026
Validation loss: 2.489228762462276

Epoch: 6| Step: 2
Training loss: 1.6999868476583293
Validation loss: 2.4853053766493733

Epoch: 6| Step: 3
Training loss: 1.2963469935650793
Validation loss: 2.491035877613404

Epoch: 6| Step: 4
Training loss: 1.7096718064963068
Validation loss: 2.4965260159130493

Epoch: 6| Step: 5
Training loss: 1.3792261719711953
Validation loss: 2.4934832863492686

Epoch: 6| Step: 6
Training loss: 2.056515189001826
Validation loss: 2.5121269523997634

Epoch: 6| Step: 7
Training loss: 1.8511515616054846
Validation loss: 2.4644245444982382

Epoch: 6| Step: 8
Training loss: 1.8031857009269976
Validation loss: 2.4525633713056916

Epoch: 6| Step: 9
Training loss: 1.6671936950282482
Validation loss: 2.450100105673146

Epoch: 6| Step: 10
Training loss: 1.6081775543722523
Validation loss: 2.4585910093380843

Epoch: 6| Step: 11
Training loss: 2.264714130272938
Validation loss: 2.490721093294158

Epoch: 6| Step: 12
Training loss: 1.9815987216903759
Validation loss: 2.4301190401418538

Epoch: 6| Step: 13
Training loss: 2.419938623895327
Validation loss: 2.4114063216312114

Epoch: 406| Step: 0
Training loss: 1.6408050438318422
Validation loss: 2.4890671597100558

Epoch: 6| Step: 1
Training loss: 1.8925972102003066
Validation loss: 2.4742151312111256

Epoch: 6| Step: 2
Training loss: 1.8462012854924446
Validation loss: 2.4735740092812883

Epoch: 6| Step: 3
Training loss: 1.8745677449746294
Validation loss: 2.4769097741999473

Epoch: 6| Step: 4
Training loss: 1.417209895082147
Validation loss: 2.4863807577211046

Epoch: 6| Step: 5
Training loss: 1.7502204892357283
Validation loss: 2.467534648373017

Epoch: 6| Step: 6
Training loss: 1.6204975548537137
Validation loss: 2.5024578707373726

Epoch: 6| Step: 7
Training loss: 2.0266648407141505
Validation loss: 2.4550645271350415

Epoch: 6| Step: 8
Training loss: 1.4681796325937888
Validation loss: 2.4385652751643345

Epoch: 6| Step: 9
Training loss: 2.187562778117036
Validation loss: 2.4856121934624382

Epoch: 6| Step: 10
Training loss: 1.8778531936245788
Validation loss: 2.4980302269869528

Epoch: 6| Step: 11
Training loss: 1.8422525434845298
Validation loss: 2.4675499234613745

Epoch: 6| Step: 12
Training loss: 2.3211010963942558
Validation loss: 2.4837080011828374

Epoch: 6| Step: 13
Training loss: 1.4456044495041753
Validation loss: 2.494600104768933

Epoch: 407| Step: 0
Training loss: 2.230114696615085
Validation loss: 2.468120195027131

Epoch: 6| Step: 1
Training loss: 1.6906948223256524
Validation loss: 2.489724669630282

Epoch: 6| Step: 2
Training loss: 2.176044003083792
Validation loss: 2.465939181401074

Epoch: 6| Step: 3
Training loss: 1.5402286197594495
Validation loss: 2.4780442523606743

Epoch: 6| Step: 4
Training loss: 2.1476377906158657
Validation loss: 2.4446655191258038

Epoch: 6| Step: 5
Training loss: 1.190995792913173
Validation loss: 2.5357247535583753

Epoch: 6| Step: 6
Training loss: 2.547328229958797
Validation loss: 2.473160520104133

Epoch: 6| Step: 7
Training loss: 1.6381977836801604
Validation loss: 2.4601786688243266

Epoch: 6| Step: 8
Training loss: 1.9423075067297795
Validation loss: 2.4579430752338074

Epoch: 6| Step: 9
Training loss: 1.185753541935089
Validation loss: 2.4297075843515086

Epoch: 6| Step: 10
Training loss: 1.227535857785942
Validation loss: 2.5241719687638033

Epoch: 6| Step: 11
Training loss: 1.6197005202314523
Validation loss: 2.474601979142686

Epoch: 6| Step: 12
Training loss: 1.8270497868878914
Validation loss: 2.522247874215771

Epoch: 6| Step: 13
Training loss: 1.9349619946949077
Validation loss: 2.548068978311697

Epoch: 408| Step: 0
Training loss: 1.392689661639335
Validation loss: 2.469911583722102

Epoch: 6| Step: 1
Training loss: 1.7400168680053056
Validation loss: 2.506623998635334

Epoch: 6| Step: 2
Training loss: 2.5300350334546384
Validation loss: 2.4945178179089926

Epoch: 6| Step: 3
Training loss: 1.5992253067187814
Validation loss: 2.549538506605158

Epoch: 6| Step: 4
Training loss: 1.3945089386509564
Validation loss: 2.452201630291596

Epoch: 6| Step: 5
Training loss: 1.1088883313024933
Validation loss: 2.5068486082243684

Epoch: 6| Step: 6
Training loss: 2.3140832790598345
Validation loss: 2.460778056505796

Epoch: 6| Step: 7
Training loss: 1.9099848695724921
Validation loss: 2.487582370352523

Epoch: 6| Step: 8
Training loss: 1.9232654658838317
Validation loss: 2.498558422507601

Epoch: 6| Step: 9
Training loss: 1.767660469961242
Validation loss: 2.5119927017580608

Epoch: 6| Step: 10
Training loss: 1.8874886089259117
Validation loss: 2.4514696918928975

Epoch: 6| Step: 11
Training loss: 1.6102020212744754
Validation loss: 2.473025028538114

Epoch: 6| Step: 12
Training loss: 1.5162585792393135
Validation loss: 2.4511422177432496

Epoch: 6| Step: 13
Training loss: 1.6952141939833638
Validation loss: 2.507236471165523

Epoch: 409| Step: 0
Training loss: 1.888307017417668
Validation loss: 2.475342491163099

Epoch: 6| Step: 1
Training loss: 2.771599732915684
Validation loss: 2.4767338256227647

Epoch: 6| Step: 2
Training loss: 1.811411168817248
Validation loss: 2.4767730117227806

Epoch: 6| Step: 3
Training loss: 1.034166489067544
Validation loss: 2.4748928277022477

Epoch: 6| Step: 4
Training loss: 1.832886908826479
Validation loss: 2.4687532482279018

Epoch: 6| Step: 5
Training loss: 1.845286876426274
Validation loss: 2.438135105898441

Epoch: 6| Step: 6
Training loss: 1.5672188266045897
Validation loss: 2.4884534975074906

Epoch: 6| Step: 7
Training loss: 1.5006063348450598
Validation loss: 2.4689286825310908

Epoch: 6| Step: 8
Training loss: 1.2869941532503122
Validation loss: 2.4192426260353264

Epoch: 6| Step: 9
Training loss: 1.8286944423535805
Validation loss: 2.509268500713707

Epoch: 6| Step: 10
Training loss: 2.288045507538666
Validation loss: 2.429162376941912

Epoch: 6| Step: 11
Training loss: 1.8540109147508763
Validation loss: 2.4947720614074482

Epoch: 6| Step: 12
Training loss: 1.6384700609951919
Validation loss: 2.4493617651452197

Epoch: 6| Step: 13
Training loss: 1.310053452500511
Validation loss: 2.477978342370837

Epoch: 410| Step: 0
Training loss: 2.127243204363971
Validation loss: 2.506594715189761

Epoch: 6| Step: 1
Training loss: 1.6672504674144644
Validation loss: 2.447337238870739

Epoch: 6| Step: 2
Training loss: 1.4690545760547387
Validation loss: 2.504429840508899

Epoch: 6| Step: 3
Training loss: 1.5344632746831441
Validation loss: 2.4395272538682247

Epoch: 6| Step: 4
Training loss: 1.5201314412556066
Validation loss: 2.4607289257297285

Epoch: 6| Step: 5
Training loss: 1.6118845215982496
Validation loss: 2.489451777979094

Epoch: 6| Step: 6
Training loss: 1.6964874415114108
Validation loss: 2.47774144154655

Epoch: 6| Step: 7
Training loss: 1.6679321570927466
Validation loss: 2.5179217582396034

Epoch: 6| Step: 8
Training loss: 1.7623490180961525
Validation loss: 2.4393196108500734

Epoch: 6| Step: 9
Training loss: 1.4799594456039409
Validation loss: 2.4469023590094316

Epoch: 6| Step: 10
Training loss: 1.773213242119054
Validation loss: 2.448644841234433

Epoch: 6| Step: 11
Training loss: 2.4484931321144185
Validation loss: 2.4684023510440762

Epoch: 6| Step: 12
Training loss: 2.0797702328614527
Validation loss: 2.4738331276125987

Epoch: 6| Step: 13
Training loss: 1.5182560372523866
Validation loss: 2.489247285028776

Epoch: 411| Step: 0
Training loss: 2.546128239592651
Validation loss: 2.4649468928148752

Epoch: 6| Step: 1
Training loss: 1.7563376788316478
Validation loss: 2.458318009145398

Epoch: 6| Step: 2
Training loss: 1.8713825297645936
Validation loss: 2.47760468255324

Epoch: 6| Step: 3
Training loss: 1.9306710396979705
Validation loss: 2.489334442745108

Epoch: 6| Step: 4
Training loss: 1.594603067114318
Validation loss: 2.454643912633441

Epoch: 6| Step: 5
Training loss: 1.3084016117980508
Validation loss: 2.483459616684348

Epoch: 6| Step: 6
Training loss: 1.8982446517637892
Validation loss: 2.4517937423443494

Epoch: 6| Step: 7
Training loss: 1.5005395236887629
Validation loss: 2.506731820376856

Epoch: 6| Step: 8
Training loss: 1.8801903411201624
Validation loss: 2.482066859669364

Epoch: 6| Step: 9
Training loss: 1.3887222645734274
Validation loss: 2.504829440167643

Epoch: 6| Step: 10
Training loss: 1.3567008539214716
Validation loss: 2.4803246302905864

Epoch: 6| Step: 11
Training loss: 1.7615696067862952
Validation loss: 2.4978248070113587

Epoch: 6| Step: 12
Training loss: 2.1730516937328606
Validation loss: 2.45218433648818

Epoch: 6| Step: 13
Training loss: 1.4210044795052286
Validation loss: 2.5320999357267557

Epoch: 412| Step: 0
Training loss: 2.140832487199952
Validation loss: 2.4721896891588564

Epoch: 6| Step: 1
Training loss: 1.3403285625808943
Validation loss: 2.4271462777506922

Epoch: 6| Step: 2
Training loss: 1.726629057416938
Validation loss: 2.505312982774474

Epoch: 6| Step: 3
Training loss: 1.6762640553225807
Validation loss: 2.503078920728533

Epoch: 6| Step: 4
Training loss: 1.8467803233708975
Validation loss: 2.429568089905976

Epoch: 6| Step: 5
Training loss: 1.8007146529256062
Validation loss: 2.503005367604049

Epoch: 6| Step: 6
Training loss: 1.8038168123789204
Validation loss: 2.4729001650144897

Epoch: 6| Step: 7
Training loss: 1.9696700353270304
Validation loss: 2.4835711877799804

Epoch: 6| Step: 8
Training loss: 1.5898014597223922
Validation loss: 2.4863702139439123

Epoch: 6| Step: 9
Training loss: 1.4926671560410762
Validation loss: 2.463890086599922

Epoch: 6| Step: 10
Training loss: 1.1434113423247811
Validation loss: 2.4818980367488828

Epoch: 6| Step: 11
Training loss: 2.2113402306502135
Validation loss: 2.476447211448509

Epoch: 6| Step: 12
Training loss: 2.623497669286549
Validation loss: 2.4115651619808065

Epoch: 6| Step: 13
Training loss: 1.614478454464983
Validation loss: 2.495089375976032

Epoch: 413| Step: 0
Training loss: 1.4083960370583049
Validation loss: 2.4743339801731614

Epoch: 6| Step: 1
Training loss: 1.9336725392328336
Validation loss: 2.471039161007711

Epoch: 6| Step: 2
Training loss: 1.6480256058685092
Validation loss: 2.48383330397969

Epoch: 6| Step: 3
Training loss: 2.0429818205843833
Validation loss: 2.4840988477281174

Epoch: 6| Step: 4
Training loss: 2.0259817027916087
Validation loss: 2.51595333043065

Epoch: 6| Step: 5
Training loss: 1.4933672330760834
Validation loss: 2.478875952248636

Epoch: 6| Step: 6
Training loss: 1.6045695290293218
Validation loss: 2.4846972907018015

Epoch: 6| Step: 7
Training loss: 1.7919991059130753
Validation loss: 2.4971272668057263

Epoch: 6| Step: 8
Training loss: 1.650585925944415
Validation loss: 2.4750640653686085

Epoch: 6| Step: 9
Training loss: 1.916839951131652
Validation loss: 2.5009005708807885

Epoch: 6| Step: 10
Training loss: 1.9760834486557053
Validation loss: 2.4945720053798843

Epoch: 6| Step: 11
Training loss: 1.4937469163168517
Validation loss: 2.463107134594448

Epoch: 6| Step: 12
Training loss: 2.1271831293510908
Validation loss: 2.454591904926405

Epoch: 6| Step: 13
Training loss: 2.0236522899316607
Validation loss: 2.505119208726686

Epoch: 414| Step: 0
Training loss: 1.8055473360053877
Validation loss: 2.46052227798217

Epoch: 6| Step: 1
Training loss: 1.7968103148385963
Validation loss: 2.5383545207025042

Epoch: 6| Step: 2
Training loss: 1.4458493447127199
Validation loss: 2.4791136670740257

Epoch: 6| Step: 3
Training loss: 1.5395320427816184
Validation loss: 2.458570933622162

Epoch: 6| Step: 4
Training loss: 1.93202235015041
Validation loss: 2.5162880426971896

Epoch: 6| Step: 5
Training loss: 1.234049790433581
Validation loss: 2.4904888385794903

Epoch: 6| Step: 6
Training loss: 2.1072058933795494
Validation loss: 2.488672858603409

Epoch: 6| Step: 7
Training loss: 1.483571688471435
Validation loss: 2.525180656633195

Epoch: 6| Step: 8
Training loss: 1.697930841055215
Validation loss: 2.475341152040028

Epoch: 6| Step: 9
Training loss: 2.1056177656276454
Validation loss: 2.5206148704974427

Epoch: 6| Step: 10
Training loss: 2.2824987886557233
Validation loss: 2.4624450389291486

Epoch: 6| Step: 11
Training loss: 1.2541334475218797
Validation loss: 2.4819587684825803

Epoch: 6| Step: 12
Training loss: 2.1259749924632465
Validation loss: 2.4604932085456173

Epoch: 6| Step: 13
Training loss: 1.6584803121535032
Validation loss: 2.5472779802280705

Epoch: 415| Step: 0
Training loss: 1.644075017786073
Validation loss: 2.460027171295947

Epoch: 6| Step: 1
Training loss: 2.1257984680801916
Validation loss: 2.4996580761715372

Epoch: 6| Step: 2
Training loss: 1.8656449590027488
Validation loss: 2.4181408927634243

Epoch: 6| Step: 3
Training loss: 1.6790794513981957
Validation loss: 2.4559988318487918

Epoch: 6| Step: 4
Training loss: 1.286560265625076
Validation loss: 2.523320862227523

Epoch: 6| Step: 5
Training loss: 1.7179148639105417
Validation loss: 2.4749793271713374

Epoch: 6| Step: 6
Training loss: 1.7337377253773791
Validation loss: 2.457476578369065

Epoch: 6| Step: 7
Training loss: 1.5819323096713722
Validation loss: 2.5063632972519017

Epoch: 6| Step: 8
Training loss: 1.4753445239107368
Validation loss: 2.455977512610804

Epoch: 6| Step: 9
Training loss: 1.386209528739012
Validation loss: 2.488790442116404

Epoch: 6| Step: 10
Training loss: 2.006570513545457
Validation loss: 2.4523379838229755

Epoch: 6| Step: 11
Training loss: 1.7490487919539988
Validation loss: 2.4675106407611254

Epoch: 6| Step: 12
Training loss: 2.3894686426666305
Validation loss: 2.491368411731298

Epoch: 6| Step: 13
Training loss: 2.366169827206847
Validation loss: 2.472980281498394

Epoch: 416| Step: 0
Training loss: 1.2848571614833453
Validation loss: 2.4377560571760113

Epoch: 6| Step: 1
Training loss: 1.8209843521283786
Validation loss: 2.4990641267599853

Epoch: 6| Step: 2
Training loss: 2.122714440394417
Validation loss: 2.472944576584429

Epoch: 6| Step: 3
Training loss: 1.46668796668336
Validation loss: 2.501049926720665

Epoch: 6| Step: 4
Training loss: 1.9607137119213955
Validation loss: 2.497050587215603

Epoch: 6| Step: 5
Training loss: 1.5561767806021756
Validation loss: 2.4937247365775495

Epoch: 6| Step: 6
Training loss: 2.775463642875252
Validation loss: 2.4833526602592633

Epoch: 6| Step: 7
Training loss: 1.2593719103753975
Validation loss: 2.4873193541787026

Epoch: 6| Step: 8
Training loss: 1.6057470966748202
Validation loss: 2.474969624597809

Epoch: 6| Step: 9
Training loss: 1.5712108414777042
Validation loss: 2.5233072328344006

Epoch: 6| Step: 10
Training loss: 2.1072107585837987
Validation loss: 2.4656754738282767

Epoch: 6| Step: 11
Training loss: 1.330468522417337
Validation loss: 2.4498832690733368

Epoch: 6| Step: 12
Training loss: 1.933671676144388
Validation loss: 2.488927560110985

Epoch: 6| Step: 13
Training loss: 1.6053794223409938
Validation loss: 2.4449908632658452

Epoch: 417| Step: 0
Training loss: 1.9102132277776693
Validation loss: 2.484965105659989

Epoch: 6| Step: 1
Training loss: 2.124863900706843
Validation loss: 2.492732280087567

Epoch: 6| Step: 2
Training loss: 1.4895065750227936
Validation loss: 2.4771475007352257

Epoch: 6| Step: 3
Training loss: 1.3390117764742104
Validation loss: 2.4519352930308127

Epoch: 6| Step: 4
Training loss: 1.7425131044483408
Validation loss: 2.4794091505668563

Epoch: 6| Step: 5
Training loss: 1.9817199967857215
Validation loss: 2.4880011855809

Epoch: 6| Step: 6
Training loss: 1.6511049067984094
Validation loss: 2.469539853991853

Epoch: 6| Step: 7
Training loss: 1.999538070262865
Validation loss: 2.5365027310313697

Epoch: 6| Step: 8
Training loss: 1.758258542583991
Validation loss: 2.4191468040348303

Epoch: 6| Step: 9
Training loss: 1.3593985018397656
Validation loss: 2.4374508806763844

Epoch: 6| Step: 10
Training loss: 1.4671578401242775
Validation loss: 2.5235869168073104

Epoch: 6| Step: 11
Training loss: 1.0074061084473511
Validation loss: 2.499457742476966

Epoch: 6| Step: 12
Training loss: 2.557380586672209
Validation loss: 2.51643069361038

Epoch: 6| Step: 13
Training loss: 1.989779763902236
Validation loss: 2.4988343289984685

Epoch: 418| Step: 0
Training loss: 1.413616721349369
Validation loss: 2.4727180650911262

Epoch: 6| Step: 1
Training loss: 2.005879105839545
Validation loss: 2.4933281275317745

Epoch: 6| Step: 2
Training loss: 1.9052987148342444
Validation loss: 2.4410862362721444

Epoch: 6| Step: 3
Training loss: 1.6652148201546169
Validation loss: 2.493786238116813

Epoch: 6| Step: 4
Training loss: 1.7852461977946101
Validation loss: 2.400644751948379

Epoch: 6| Step: 5
Training loss: 1.9257767311646716
Validation loss: 2.4617052366793835

Epoch: 6| Step: 6
Training loss: 1.7393248436426838
Validation loss: 2.4708882017513862

Epoch: 6| Step: 7
Training loss: 2.010260488607301
Validation loss: 2.4448733896918973

Epoch: 6| Step: 8
Training loss: 1.6158848920560525
Validation loss: 2.5106449257450523

Epoch: 6| Step: 9
Training loss: 1.9170103456061818
Validation loss: 2.495799727217652

Epoch: 6| Step: 10
Training loss: 1.6638562428338022
Validation loss: 2.519135378159281

Epoch: 6| Step: 11
Training loss: 2.1512064897569143
Validation loss: 2.458124598934301

Epoch: 6| Step: 12
Training loss: 1.4216206920534693
Validation loss: 2.493297169257872

Epoch: 6| Step: 13
Training loss: 1.5416006469337202
Validation loss: 2.502009800116484

Epoch: 419| Step: 0
Training loss: 1.81449057352535
Validation loss: 2.4998332306397133

Epoch: 6| Step: 1
Training loss: 1.448314456589879
Validation loss: 2.478739645762376

Epoch: 6| Step: 2
Training loss: 1.1725241833858673
Validation loss: 2.483347817076109

Epoch: 6| Step: 3
Training loss: 1.7718664259930204
Validation loss: 2.4124547309842734

Epoch: 6| Step: 4
Training loss: 2.2695610845446508
Validation loss: 2.4511583380902846

Epoch: 6| Step: 5
Training loss: 1.2566767712565436
Validation loss: 2.4752239257337734

Epoch: 6| Step: 6
Training loss: 1.6200961432949859
Validation loss: 2.4908131933091924

Epoch: 6| Step: 7
Training loss: 1.8181313475192806
Validation loss: 2.499481405798862

Epoch: 6| Step: 8
Training loss: 1.1639476949928107
Validation loss: 2.4440488061256516

Epoch: 6| Step: 9
Training loss: 2.0056920116400327
Validation loss: 2.4634416560723746

Epoch: 6| Step: 10
Training loss: 1.8908153469641893
Validation loss: 2.52385449898378

Epoch: 6| Step: 11
Training loss: 2.256748463525457
Validation loss: 2.4677870339005836

Epoch: 6| Step: 12
Training loss: 2.1476054852016837
Validation loss: 2.4459861879157083

Epoch: 6| Step: 13
Training loss: 1.8808493608978611
Validation loss: 2.4860461756614263

Epoch: 420| Step: 0
Training loss: 1.5954785416563855
Validation loss: 2.5009467506232737

Epoch: 6| Step: 1
Training loss: 1.6068024305042727
Validation loss: 2.5203304024674082

Epoch: 6| Step: 2
Training loss: 1.5818678783315219
Validation loss: 2.4615027650118453

Epoch: 6| Step: 3
Training loss: 1.4537796678738455
Validation loss: 2.486496351746954

Epoch: 6| Step: 4
Training loss: 0.9675113696531802
Validation loss: 2.4105630656512536

Epoch: 6| Step: 5
Training loss: 2.3503029323687974
Validation loss: 2.493856845050979

Epoch: 6| Step: 6
Training loss: 2.0749926371616123
Validation loss: 2.494400408540249

Epoch: 6| Step: 7
Training loss: 2.0247815944487706
Validation loss: 2.5117401421703085

Epoch: 6| Step: 8
Training loss: 2.0529073103370266
Validation loss: 2.458943825307196

Epoch: 6| Step: 9
Training loss: 1.6523904275275687
Validation loss: 2.5542639959942863

Epoch: 6| Step: 10
Training loss: 1.957078761820347
Validation loss: 2.5226858732698556

Epoch: 6| Step: 11
Training loss: 1.5120551944881473
Validation loss: 2.4922070528988254

Epoch: 6| Step: 12
Training loss: 1.7881893375986337
Validation loss: 2.4839136819225835

Epoch: 6| Step: 13
Training loss: 1.5095288089708374
Validation loss: 2.5044637996161163

Epoch: 421| Step: 0
Training loss: 1.7536363287784187
Validation loss: 2.4834921303841813

Epoch: 6| Step: 1
Training loss: 1.5228345411346735
Validation loss: 2.480620483170766

Epoch: 6| Step: 2
Training loss: 1.8509526274444679
Validation loss: 2.450563953988799

Epoch: 6| Step: 3
Training loss: 1.6520991583984626
Validation loss: 2.529862873912678

Epoch: 6| Step: 4
Training loss: 1.9413880744559158
Validation loss: 2.5163432773322008

Epoch: 6| Step: 5
Training loss: 1.2970329096610835
Validation loss: 2.4569095564676218

Epoch: 6| Step: 6
Training loss: 1.1683238838746026
Validation loss: 2.4738093940879646

Epoch: 6| Step: 7
Training loss: 1.9482467766040876
Validation loss: 2.436392738505789

Epoch: 6| Step: 8
Training loss: 1.8348921376679368
Validation loss: 2.503229260341827

Epoch: 6| Step: 9
Training loss: 2.0008085523810744
Validation loss: 2.441265870880145

Epoch: 6| Step: 10
Training loss: 1.712948596978112
Validation loss: 2.476138571544303

Epoch: 6| Step: 11
Training loss: 2.2064639282251677
Validation loss: 2.4785120203045037

Epoch: 6| Step: 12
Training loss: 1.9251191585371152
Validation loss: 2.4870339083766067

Epoch: 6| Step: 13
Training loss: 1.8148427489495935
Validation loss: 2.4711241484369277

Epoch: 422| Step: 0
Training loss: 1.4248133888527996
Validation loss: 2.4468411605373164

Epoch: 6| Step: 1
Training loss: 1.6802578689579373
Validation loss: 2.5065359733992887

Epoch: 6| Step: 2
Training loss: 2.4545035406830413
Validation loss: 2.499127582382202

Epoch: 6| Step: 3
Training loss: 1.4515436243117288
Validation loss: 2.495959408855316

Epoch: 6| Step: 4
Training loss: 1.6360377531475614
Validation loss: 2.5009095229494394

Epoch: 6| Step: 5
Training loss: 1.939628662278989
Validation loss: 2.530366298454767

Epoch: 6| Step: 6
Training loss: 2.0149038044801526
Validation loss: 2.494246118753304

Epoch: 6| Step: 7
Training loss: 1.9942430849121606
Validation loss: 2.5055039280276037

Epoch: 6| Step: 8
Training loss: 1.9420050881394773
Validation loss: 2.4779043861062404

Epoch: 6| Step: 9
Training loss: 1.6298210813467067
Validation loss: 2.4959866837800897

Epoch: 6| Step: 10
Training loss: 1.31002610799384
Validation loss: 2.458410650476211

Epoch: 6| Step: 11
Training loss: 1.794011429932075
Validation loss: 2.4809213569184037

Epoch: 6| Step: 12
Training loss: 1.518645982359193
Validation loss: 2.461111398735756

Epoch: 6| Step: 13
Training loss: 1.6595526102708265
Validation loss: 2.5016024663059824

Epoch: 423| Step: 0
Training loss: 1.9772698263866546
Validation loss: 2.482579221055524

Epoch: 6| Step: 1
Training loss: 1.478871311554909
Validation loss: 2.4797374440214592

Epoch: 6| Step: 2
Training loss: 1.1308492551360667
Validation loss: 2.442809355608708

Epoch: 6| Step: 3
Training loss: 1.6699654199823324
Validation loss: 2.4895617428804204

Epoch: 6| Step: 4
Training loss: 1.8461275450349093
Validation loss: 2.481965572253028

Epoch: 6| Step: 5
Training loss: 1.7828431617447125
Validation loss: 2.4872759455062377

Epoch: 6| Step: 6
Training loss: 1.597715567907645
Validation loss: 2.4584918387321895

Epoch: 6| Step: 7
Training loss: 1.9905132364131461
Validation loss: 2.4344838415314034

Epoch: 6| Step: 8
Training loss: 2.101179577284463
Validation loss: 2.501820836397086

Epoch: 6| Step: 9
Training loss: 1.8451616734326388
Validation loss: 2.4797325550084928

Epoch: 6| Step: 10
Training loss: 1.1812809672661213
Validation loss: 2.4822235646550572

Epoch: 6| Step: 11
Training loss: 1.8368919975582014
Validation loss: 2.4568168783598825

Epoch: 6| Step: 12
Training loss: 1.779429727026927
Validation loss: 2.4584093594844316

Epoch: 6| Step: 13
Training loss: 2.608020270900699
Validation loss: 2.4299639657418988

Epoch: 424| Step: 0
Training loss: 2.462466391706828
Validation loss: 2.521255093463422

Epoch: 6| Step: 1
Training loss: 1.485728720710133
Validation loss: 2.461831458396052

Epoch: 6| Step: 2
Training loss: 1.8367686236906615
Validation loss: 2.519017978390302

Epoch: 6| Step: 3
Training loss: 1.6430724281325384
Validation loss: 2.5012775930333677

Epoch: 6| Step: 4
Training loss: 1.6865910095214067
Validation loss: 2.4401500853120393

Epoch: 6| Step: 5
Training loss: 1.6135553676679426
Validation loss: 2.473460226296783

Epoch: 6| Step: 6
Training loss: 1.3854267817919137
Validation loss: 2.5078703726330924

Epoch: 6| Step: 7
Training loss: 2.3905339441847633
Validation loss: 2.4717080186154705

Epoch: 6| Step: 8
Training loss: 1.5752467734154423
Validation loss: 2.4010353386367402

Epoch: 6| Step: 9
Training loss: 1.712697069287038
Validation loss: 2.4867226030475686

Epoch: 6| Step: 10
Training loss: 1.6184646060291952
Validation loss: 2.4931792499709835

Epoch: 6| Step: 11
Training loss: 1.406541243169852
Validation loss: 2.45107963260001

Epoch: 6| Step: 12
Training loss: 1.6503638993305758
Validation loss: 2.488340299095027

Epoch: 6| Step: 13
Training loss: 1.3934672167137954
Validation loss: 2.478275604962107

Epoch: 425| Step: 0
Training loss: 2.03802849871894
Validation loss: 2.492574203433641

Epoch: 6| Step: 1
Training loss: 1.1484390570182366
Validation loss: 2.4630117534355533

Epoch: 6| Step: 2
Training loss: 1.8122658413870738
Validation loss: 2.490870858811871

Epoch: 6| Step: 3
Training loss: 1.249764229473888
Validation loss: 2.4935230512591753

Epoch: 6| Step: 4
Training loss: 1.5096527096864119
Validation loss: 2.5165405105588086

Epoch: 6| Step: 5
Training loss: 2.041930304911798
Validation loss: 2.480990322248993

Epoch: 6| Step: 6
Training loss: 1.9012910095848168
Validation loss: 2.481940391908411

Epoch: 6| Step: 7
Training loss: 1.9114042546437973
Validation loss: 2.5042468034837

Epoch: 6| Step: 8
Training loss: 1.7561052636071952
Validation loss: 2.5178370298290096

Epoch: 6| Step: 9
Training loss: 1.4863497798911174
Validation loss: 2.5214814763329585

Epoch: 6| Step: 10
Training loss: 2.2759831913493316
Validation loss: 2.493558420388653

Epoch: 6| Step: 11
Training loss: 1.9919684196136642
Validation loss: 2.4508108177324734

Epoch: 6| Step: 12
Training loss: 1.2411050938963464
Validation loss: 2.4486420055334097

Epoch: 6| Step: 13
Training loss: 1.8999221710527354
Validation loss: 2.477906475480677

Epoch: 426| Step: 0
Training loss: 1.6116093060773695
Validation loss: 2.4614299129828936

Epoch: 6| Step: 1
Training loss: 1.4971008894871523
Validation loss: 2.5116434385981186

Epoch: 6| Step: 2
Training loss: 1.5129647258219276
Validation loss: 2.4205320871223726

Epoch: 6| Step: 3
Training loss: 1.6486964451766166
Validation loss: 2.538284597066807

Epoch: 6| Step: 4
Training loss: 1.6689360268447797
Validation loss: 2.4588641439530505

Epoch: 6| Step: 5
Training loss: 1.0533009775439515
Validation loss: 2.4804679614159406

Epoch: 6| Step: 6
Training loss: 2.059246734190483
Validation loss: 2.4675420919060356

Epoch: 6| Step: 7
Training loss: 1.6910126472600255
Validation loss: 2.4655326001736113

Epoch: 6| Step: 8
Training loss: 1.5239282844520454
Validation loss: 2.4791364119033017

Epoch: 6| Step: 9
Training loss: 1.6694483749391336
Validation loss: 2.4660563667054385

Epoch: 6| Step: 10
Training loss: 1.7357327756844385
Validation loss: 2.5220369428219054

Epoch: 6| Step: 11
Training loss: 2.534223528943988
Validation loss: 2.4781302890623644

Epoch: 6| Step: 12
Training loss: 2.180416299810317
Validation loss: 2.5297167170269956

Epoch: 6| Step: 13
Training loss: 1.603351394104831
Validation loss: 2.49220354104162

Epoch: 427| Step: 0
Training loss: 1.3831116088825703
Validation loss: 2.4768046226475655

Epoch: 6| Step: 1
Training loss: 1.4290288856902387
Validation loss: 2.468791466506581

Epoch: 6| Step: 2
Training loss: 1.9026059199158987
Validation loss: 2.4801195853140956

Epoch: 6| Step: 3
Training loss: 2.2635815053547943
Validation loss: 2.4770760439000292

Epoch: 6| Step: 4
Training loss: 1.471149837743516
Validation loss: 2.5297405969114126

Epoch: 6| Step: 5
Training loss: 1.3837779494911475
Validation loss: 2.4960962965965425

Epoch: 6| Step: 6
Training loss: 1.4909894037976723
Validation loss: 2.4830507812532048

Epoch: 6| Step: 7
Training loss: 1.2353332276924969
Validation loss: 2.4630093334440946

Epoch: 6| Step: 8
Training loss: 1.701185049012566
Validation loss: 2.4542035105005664

Epoch: 6| Step: 9
Training loss: 2.347267766155778
Validation loss: 2.437900637549421

Epoch: 6| Step: 10
Training loss: 1.835582682635146
Validation loss: 2.4821773856694183

Epoch: 6| Step: 11
Training loss: 1.9299261277643036
Validation loss: 2.4745293578808805

Epoch: 6| Step: 12
Training loss: 2.1915698746845833
Validation loss: 2.4540182545705367

Epoch: 6| Step: 13
Training loss: 1.569893472665642
Validation loss: 2.5090067314981956

Epoch: 428| Step: 0
Training loss: 1.7058839761695335
Validation loss: 2.4451966921225488

Epoch: 6| Step: 1
Training loss: 2.0345413538455817
Validation loss: 2.44343353959225

Epoch: 6| Step: 2
Training loss: 1.7354206678963369
Validation loss: 2.4931666403663537

Epoch: 6| Step: 3
Training loss: 1.8360260637714663
Validation loss: 2.4583760072380634

Epoch: 6| Step: 4
Training loss: 2.329473527360389
Validation loss: 2.4923520633868215

Epoch: 6| Step: 5
Training loss: 1.5044702834607695
Validation loss: 2.4573903594702498

Epoch: 6| Step: 6
Training loss: 1.8727395737387948
Validation loss: 2.4749845259617653

Epoch: 6| Step: 7
Training loss: 1.6456999261925949
Validation loss: 2.474830120132088

Epoch: 6| Step: 8
Training loss: 1.7471532828607326
Validation loss: 2.4634479583884006

Epoch: 6| Step: 9
Training loss: 1.7678438271465542
Validation loss: 2.5049277613184877

Epoch: 6| Step: 10
Training loss: 1.7953851909214098
Validation loss: 2.5031245968433136

Epoch: 6| Step: 11
Training loss: 1.5976817681622693
Validation loss: 2.4461099293574935

Epoch: 6| Step: 12
Training loss: 1.3826972353035176
Validation loss: 2.456915611549396

Epoch: 6| Step: 13
Training loss: 1.7174063545694997
Validation loss: 2.456507627608443

Epoch: 429| Step: 0
Training loss: 1.7456340824796446
Validation loss: 2.4814911693499937

Epoch: 6| Step: 1
Training loss: 1.4385932414067542
Validation loss: 2.471771527260317

Epoch: 6| Step: 2
Training loss: 1.3311287068016189
Validation loss: 2.459089854865823

Epoch: 6| Step: 3
Training loss: 1.6791569781280262
Validation loss: 2.465398941709896

Epoch: 6| Step: 4
Training loss: 1.1015885803165415
Validation loss: 2.4818311863276805

Epoch: 6| Step: 5
Training loss: 1.5196241335686331
Validation loss: 2.457806380747445

Epoch: 6| Step: 6
Training loss: 1.3782136815055341
Validation loss: 2.4593032840842857

Epoch: 6| Step: 7
Training loss: 2.81971696393696
Validation loss: 2.4942607240588908

Epoch: 6| Step: 8
Training loss: 1.8735845309251715
Validation loss: 2.49069417653953

Epoch: 6| Step: 9
Training loss: 2.05362502792259
Validation loss: 2.4922344840982165

Epoch: 6| Step: 10
Training loss: 1.5431971899971066
Validation loss: 2.4560155027710655

Epoch: 6| Step: 11
Training loss: 1.764130356381478
Validation loss: 2.491073158163209

Epoch: 6| Step: 12
Training loss: 2.0315937631663417
Validation loss: 2.4797269991592623

Epoch: 6| Step: 13
Training loss: 1.627525933992224
Validation loss: 2.4332686246100033

Epoch: 430| Step: 0
Training loss: 1.732705283395256
Validation loss: 2.4727302885826807

Epoch: 6| Step: 1
Training loss: 2.5475916877995504
Validation loss: 2.4805590562027464

Epoch: 6| Step: 2
Training loss: 1.4243111334053495
Validation loss: 2.491349998575364

Epoch: 6| Step: 3
Training loss: 1.5056525854083262
Validation loss: 2.5324871666179223

Epoch: 6| Step: 4
Training loss: 1.7848788991287488
Validation loss: 2.4778340519446536

Epoch: 6| Step: 5
Training loss: 1.81182072505869
Validation loss: 2.480534388667104

Epoch: 6| Step: 6
Training loss: 1.853630424136062
Validation loss: 2.4631276292116047

Epoch: 6| Step: 7
Training loss: 1.3803199674936761
Validation loss: 2.5251801216066196

Epoch: 6| Step: 8
Training loss: 1.2842138017539826
Validation loss: 2.4562793749033043

Epoch: 6| Step: 9
Training loss: 1.836976491870092
Validation loss: 2.497711220922321

Epoch: 6| Step: 10
Training loss: 1.6551694404093025
Validation loss: 2.5093583834569495

Epoch: 6| Step: 11
Training loss: 1.354750253176485
Validation loss: 2.4783188112981804

Epoch: 6| Step: 12
Training loss: 1.8663506328332637
Validation loss: 2.4696152358436074

Epoch: 6| Step: 13
Training loss: 2.2168833442662157
Validation loss: 2.459407283642317

Epoch: 431| Step: 0
Training loss: 2.369079035550433
Validation loss: 2.4868349581240645

Epoch: 6| Step: 1
Training loss: 1.8281110453276825
Validation loss: 2.488163411371535

Epoch: 6| Step: 2
Training loss: 1.8684878749152867
Validation loss: 2.4640467838580484

Epoch: 6| Step: 3
Training loss: 1.619301487716456
Validation loss: 2.4759648895553457

Epoch: 6| Step: 4
Training loss: 1.0458357477856814
Validation loss: 2.492003902235847

Epoch: 6| Step: 5
Training loss: 1.4787028306288639
Validation loss: 2.475276262736291

Epoch: 6| Step: 6
Training loss: 1.5531183499782966
Validation loss: 2.5283578960281097

Epoch: 6| Step: 7
Training loss: 1.614312089675638
Validation loss: 2.4860309497697

Epoch: 6| Step: 8
Training loss: 1.5064170586473522
Validation loss: 2.495635012116279

Epoch: 6| Step: 9
Training loss: 1.5848296105770385
Validation loss: 2.5175559774659453

Epoch: 6| Step: 10
Training loss: 1.8355812538760845
Validation loss: 2.4357835728136954

Epoch: 6| Step: 11
Training loss: 1.7123469291272515
Validation loss: 2.5487392660400574

Epoch: 6| Step: 12
Training loss: 2.1114919706531134
Validation loss: 2.5416545571762104

Epoch: 6| Step: 13
Training loss: 1.9472077111419857
Validation loss: 2.4775073347045913

Epoch: 432| Step: 0
Training loss: 1.2785313769336653
Validation loss: 2.4854037146029726

Epoch: 6| Step: 1
Training loss: 1.9433587615812473
Validation loss: 2.5391637446535387

Epoch: 6| Step: 2
Training loss: 1.9485446781148907
Validation loss: 2.4399403823449517

Epoch: 6| Step: 3
Training loss: 1.6166335184428413
Validation loss: 2.489394289173565

Epoch: 6| Step: 4
Training loss: 1.954686265635539
Validation loss: 2.483734238098407

Epoch: 6| Step: 5
Training loss: 1.8781853639165833
Validation loss: 2.4441926356245385

Epoch: 6| Step: 6
Training loss: 1.8283933132884738
Validation loss: 2.472000723350364

Epoch: 6| Step: 7
Training loss: 1.4064048681812853
Validation loss: 2.470181277798925

Epoch: 6| Step: 8
Training loss: 1.687769479780717
Validation loss: 2.43629931465247

Epoch: 6| Step: 9
Training loss: 1.2065814022548722
Validation loss: 2.490773051658117

Epoch: 6| Step: 10
Training loss: 1.5159663179827911
Validation loss: 2.512241966406224

Epoch: 6| Step: 11
Training loss: 1.608338105321469
Validation loss: 2.459165101480353

Epoch: 6| Step: 12
Training loss: 2.3388277373042965
Validation loss: 2.468529611046646

Epoch: 6| Step: 13
Training loss: 1.97219377894181
Validation loss: 2.4833014231044763

Epoch: 433| Step: 0
Training loss: 1.577056825415882
Validation loss: 2.4982782341564387

Epoch: 6| Step: 1
Training loss: 1.6690326665580766
Validation loss: 2.4912258734366093

Epoch: 6| Step: 2
Training loss: 1.769265801264723
Validation loss: 2.4456316907913753

Epoch: 6| Step: 3
Training loss: 1.6070022127887562
Validation loss: 2.465290169109666

Epoch: 6| Step: 4
Training loss: 2.372860999343322
Validation loss: 2.494022705503697

Epoch: 6| Step: 5
Training loss: 1.6761545330173728
Validation loss: 2.4649269395879716

Epoch: 6| Step: 6
Training loss: 1.9119152247177615
Validation loss: 2.5224919342120526

Epoch: 6| Step: 7
Training loss: 1.5856754481102058
Validation loss: 2.479299730607891

Epoch: 6| Step: 8
Training loss: 1.630829990145077
Validation loss: 2.447499712585649

Epoch: 6| Step: 9
Training loss: 1.354860460620235
Validation loss: 2.506868629679101

Epoch: 6| Step: 10
Training loss: 1.5124268758452597
Validation loss: 2.463170911833873

Epoch: 6| Step: 11
Training loss: 1.6759379564832713
Validation loss: 2.4956981810177084

Epoch: 6| Step: 12
Training loss: 1.7577955457081675
Validation loss: 2.499627019377448

Epoch: 6| Step: 13
Training loss: 1.3595022821579101
Validation loss: 2.517230283519834

Epoch: 434| Step: 0
Training loss: 2.054360367293741
Validation loss: 2.5170024610588673

Epoch: 6| Step: 1
Training loss: 1.44309282745277
Validation loss: 2.5123610328147254

Epoch: 6| Step: 2
Training loss: 1.211732763213065
Validation loss: 2.4693097889190887

Epoch: 6| Step: 3
Training loss: 2.4106037336563166
Validation loss: 2.445530821619319

Epoch: 6| Step: 4
Training loss: 1.6402615099100308
Validation loss: 2.486128467079043

Epoch: 6| Step: 5
Training loss: 1.0991346510089581
Validation loss: 2.4499901521052454

Epoch: 6| Step: 6
Training loss: 1.66995535476764
Validation loss: 2.493033620216629

Epoch: 6| Step: 7
Training loss: 1.4421554313888298
Validation loss: 2.471532525389996

Epoch: 6| Step: 8
Training loss: 1.9703353069779337
Validation loss: 2.460911613832148

Epoch: 6| Step: 9
Training loss: 1.5560172830028791
Validation loss: 2.492089488371417

Epoch: 6| Step: 10
Training loss: 1.517764125506275
Validation loss: 2.4693349215682843

Epoch: 6| Step: 11
Training loss: 2.277936331598548
Validation loss: 2.4871663567792672

Epoch: 6| Step: 12
Training loss: 1.8517037510813652
Validation loss: 2.478608444362102

Epoch: 6| Step: 13
Training loss: 1.7725710327592992
Validation loss: 2.4763187883620454

Epoch: 435| Step: 0
Training loss: 2.2912360278014168
Validation loss: 2.446370941744329

Epoch: 6| Step: 1
Training loss: 2.5696836125408105
Validation loss: 2.5296712976024844

Epoch: 6| Step: 2
Training loss: 1.85391742302654
Validation loss: 2.451545180501625

Epoch: 6| Step: 3
Training loss: 1.3349444619245532
Validation loss: 2.473453666537736

Epoch: 6| Step: 4
Training loss: 1.9841531344158843
Validation loss: 2.5086062771134987

Epoch: 6| Step: 5
Training loss: 1.8621947121516527
Validation loss: 2.4749801040385027

Epoch: 6| Step: 6
Training loss: 1.6350657416609347
Validation loss: 2.5053704598416826

Epoch: 6| Step: 7
Training loss: 1.0028608051480814
Validation loss: 2.4926707206614362

Epoch: 6| Step: 8
Training loss: 1.498858892002231
Validation loss: 2.487114872467641

Epoch: 6| Step: 9
Training loss: 1.4597921522678754
Validation loss: 2.4604891070184363

Epoch: 6| Step: 10
Training loss: 1.7042984026268795
Validation loss: 2.436807456759866

Epoch: 6| Step: 11
Training loss: 1.3198416056389208
Validation loss: 2.4955138810131974

Epoch: 6| Step: 12
Training loss: 1.3017101923022851
Validation loss: 2.5115223875142365

Epoch: 6| Step: 13
Training loss: 1.7911951272549782
Validation loss: 2.4647701412284335

Epoch: 436| Step: 0
Training loss: 1.709825197732905
Validation loss: 2.496309676135388

Epoch: 6| Step: 1
Training loss: 2.017866913474019
Validation loss: 2.4868763514168597

Epoch: 6| Step: 2
Training loss: 2.3685947176077415
Validation loss: 2.4661312458663627

Epoch: 6| Step: 3
Training loss: 1.3622713474582937
Validation loss: 2.4711133113250745

Epoch: 6| Step: 4
Training loss: 1.8738295398648765
Validation loss: 2.455774815074581

Epoch: 6| Step: 5
Training loss: 1.696256172770525
Validation loss: 2.4663784754496443

Epoch: 6| Step: 6
Training loss: 0.9307066836609695
Validation loss: 2.5016508824837693

Epoch: 6| Step: 7
Training loss: 1.2380815699979164
Validation loss: 2.5088524356465234

Epoch: 6| Step: 8
Training loss: 1.67096578528066
Validation loss: 2.519370061563093

Epoch: 6| Step: 9
Training loss: 1.7273364511626381
Validation loss: 2.467591799731152

Epoch: 6| Step: 10
Training loss: 1.236127406214107
Validation loss: 2.4479628587150906

Epoch: 6| Step: 11
Training loss: 1.9669845173337446
Validation loss: 2.3939050596639526

Epoch: 6| Step: 12
Training loss: 1.7986829866885334
Validation loss: 2.4552713559712216

Epoch: 6| Step: 13
Training loss: 2.161825738650549
Validation loss: 2.5366701902332416

Epoch: 437| Step: 0
Training loss: 1.5347122443302976
Validation loss: 2.459294248322818

Epoch: 6| Step: 1
Training loss: 1.6560189427844973
Validation loss: 2.4995256199477702

Epoch: 6| Step: 2
Training loss: 1.557252387972936
Validation loss: 2.5282077350020637

Epoch: 6| Step: 3
Training loss: 2.321813746346461
Validation loss: 2.4628074800913873

Epoch: 6| Step: 4
Training loss: 2.0139776787605306
Validation loss: 2.4879786882038064

Epoch: 6| Step: 5
Training loss: 1.7443359539017886
Validation loss: 2.5045737553806884

Epoch: 6| Step: 6
Training loss: 1.1567230803302866
Validation loss: 2.4452646615063682

Epoch: 6| Step: 7
Training loss: 1.7638558495632035
Validation loss: 2.453933171990808

Epoch: 6| Step: 8
Training loss: 1.8513375318646974
Validation loss: 2.456949514723125

Epoch: 6| Step: 9
Training loss: 1.4773989936912975
Validation loss: 2.483731410978021

Epoch: 6| Step: 10
Training loss: 1.8724103209917025
Validation loss: 2.4880416202755935

Epoch: 6| Step: 11
Training loss: 1.8645505920036043
Validation loss: 2.4807346363301894

Epoch: 6| Step: 12
Training loss: 0.9849072788379727
Validation loss: 2.445674928746858

Epoch: 6| Step: 13
Training loss: 1.751066700221053
Validation loss: 2.4815719103483045

Epoch: 438| Step: 0
Training loss: 2.234822368518211
Validation loss: 2.492635133238771

Epoch: 6| Step: 1
Training loss: 1.9928525525190124
Validation loss: 2.497942444906258

Epoch: 6| Step: 2
Training loss: 1.4280370973208165
Validation loss: 2.4981154701704043

Epoch: 6| Step: 3
Training loss: 1.6622503738575016
Validation loss: 2.479810583703957

Epoch: 6| Step: 4
Training loss: 1.7097135023853112
Validation loss: 2.4685334754116086

Epoch: 6| Step: 5
Training loss: 1.5700086612826967
Validation loss: 2.418067598914179

Epoch: 6| Step: 6
Training loss: 1.3349131622360533
Validation loss: 2.4418856389430466

Epoch: 6| Step: 7
Training loss: 1.491070873824931
Validation loss: 2.4921875123440502

Epoch: 6| Step: 8
Training loss: 1.8669955741531554
Validation loss: 2.518605208499249

Epoch: 6| Step: 9
Training loss: 1.4184939249989015
Validation loss: 2.4814979878328307

Epoch: 6| Step: 10
Training loss: 1.87334878057625
Validation loss: 2.502382441464534

Epoch: 6| Step: 11
Training loss: 1.9424476209964945
Validation loss: 2.465209175109352

Epoch: 6| Step: 12
Training loss: 1.618742853686491
Validation loss: 2.5439558252432257

Epoch: 6| Step: 13
Training loss: 1.9591672893714105
Validation loss: 2.5069668120547597

Epoch: 439| Step: 0
Training loss: 1.6573446722883116
Validation loss: 2.491319992269079

Epoch: 6| Step: 1
Training loss: 1.805407359896502
Validation loss: 2.4929127524642665

Epoch: 6| Step: 2
Training loss: 1.8114336757579401
Validation loss: 2.4979116905834937

Epoch: 6| Step: 3
Training loss: 1.4686299538758933
Validation loss: 2.5377496912028916

Epoch: 6| Step: 4
Training loss: 2.0459103240257326
Validation loss: 2.490157602579688

Epoch: 6| Step: 5
Training loss: 1.809972381802602
Validation loss: 2.4555744947191456

Epoch: 6| Step: 6
Training loss: 2.0452650887958916
Validation loss: 2.4529940411686555

Epoch: 6| Step: 7
Training loss: 1.5258501559791469
Validation loss: 2.4988154242862888

Epoch: 6| Step: 8
Training loss: 2.19554511633196
Validation loss: 2.4991744452400866

Epoch: 6| Step: 9
Training loss: 1.7222047936504483
Validation loss: 2.415528463970009

Epoch: 6| Step: 10
Training loss: 1.3273020270190787
Validation loss: 2.4936335161816205

Epoch: 6| Step: 11
Training loss: 1.5792575209491215
Validation loss: 2.480914793120316

Epoch: 6| Step: 12
Training loss: 1.2809900624904471
Validation loss: 2.503344081494398

Epoch: 6| Step: 13
Training loss: 1.4530133440333033
Validation loss: 2.522835807621951

Epoch: 440| Step: 0
Training loss: 1.401551769474931
Validation loss: 2.493766998809596

Epoch: 6| Step: 1
Training loss: 1.6588595723094526
Validation loss: 2.498057453645253

Epoch: 6| Step: 2
Training loss: 1.7602588500060603
Validation loss: 2.5068276150797684

Epoch: 6| Step: 3
Training loss: 1.7348129819175364
Validation loss: 2.4949697689160155

Epoch: 6| Step: 4
Training loss: 1.631486418096725
Validation loss: 2.4661155550084985

Epoch: 6| Step: 5
Training loss: 1.6404123804283326
Validation loss: 2.5131084532491035

Epoch: 6| Step: 6
Training loss: 2.281423483744878
Validation loss: 2.504887029140585

Epoch: 6| Step: 7
Training loss: 1.9867818458609396
Validation loss: 2.4943567510426274

Epoch: 6| Step: 8
Training loss: 1.3267071504662
Validation loss: 2.472710801467777

Epoch: 6| Step: 9
Training loss: 1.8316033032292747
Validation loss: 2.4675520408237523

Epoch: 6| Step: 10
Training loss: 1.7889536195631228
Validation loss: 2.4827371942449594

Epoch: 6| Step: 11
Training loss: 1.7806641803258982
Validation loss: 2.5479866207456228

Epoch: 6| Step: 12
Training loss: 1.1737483500508665
Validation loss: 2.54411516074286

Epoch: 6| Step: 13
Training loss: 1.4251177354327504
Validation loss: 2.4814623734506096

Epoch: 441| Step: 0
Training loss: 1.7047117348686913
Validation loss: 2.5250340419128663

Epoch: 6| Step: 1
Training loss: 2.117785942830885
Validation loss: 2.5207095528090426

Epoch: 6| Step: 2
Training loss: 2.1213013492948765
Validation loss: 2.4837217900743522

Epoch: 6| Step: 3
Training loss: 2.2129076479789855
Validation loss: 2.4690103119755955

Epoch: 6| Step: 4
Training loss: 1.3587152041811403
Validation loss: 2.4548078619214695

Epoch: 6| Step: 5
Training loss: 1.4295304842751
Validation loss: 2.4536438474188413

Epoch: 6| Step: 6
Training loss: 1.66647436304113
Validation loss: 2.4925009965268745

Epoch: 6| Step: 7
Training loss: 1.6203464486107255
Validation loss: 2.518547694506874

Epoch: 6| Step: 8
Training loss: 1.8244202071701938
Validation loss: 2.499782215394725

Epoch: 6| Step: 9
Training loss: 1.3343694307090443
Validation loss: 2.5052242601320014

Epoch: 6| Step: 10
Training loss: 1.437974851380411
Validation loss: 2.4780905761280976

Epoch: 6| Step: 11
Training loss: 1.7127053520542646
Validation loss: 2.4823402042872855

Epoch: 6| Step: 12
Training loss: 1.8080409216427367
Validation loss: 2.4806024583987085

Epoch: 6| Step: 13
Training loss: 1.2253868154041536
Validation loss: 2.497362613034658

Epoch: 442| Step: 0
Training loss: 1.8335239860353458
Validation loss: 2.4968758967132048

Epoch: 6| Step: 1
Training loss: 1.9183395244897297
Validation loss: 2.497485861423263

Epoch: 6| Step: 2
Training loss: 1.5848642861540962
Validation loss: 2.4807460871133915

Epoch: 6| Step: 3
Training loss: 1.5604310643236847
Validation loss: 2.5050051832785103

Epoch: 6| Step: 4
Training loss: 1.9668615457458278
Validation loss: 2.4480346878146264

Epoch: 6| Step: 5
Training loss: 1.0879394410719194
Validation loss: 2.49851766960455

Epoch: 6| Step: 6
Training loss: 2.038407026733013
Validation loss: 2.477651370995373

Epoch: 6| Step: 7
Training loss: 2.1047416379857404
Validation loss: 2.4597223597495477

Epoch: 6| Step: 8
Training loss: 2.108127479404741
Validation loss: 2.5066881577632594

Epoch: 6| Step: 9
Training loss: 1.4693606304470457
Validation loss: 2.4225514018139305

Epoch: 6| Step: 10
Training loss: 1.7519205317872943
Validation loss: 2.4264824701038434

Epoch: 6| Step: 11
Training loss: 1.9450766791990148
Validation loss: 2.4747374382389196

Epoch: 6| Step: 12
Training loss: 1.1231527527366523
Validation loss: 2.476133804843044

Epoch: 6| Step: 13
Training loss: 1.7561440921223244
Validation loss: 2.4707718474148734

Epoch: 443| Step: 0
Training loss: 1.6423741779878422
Validation loss: 2.5305627345376043

Epoch: 6| Step: 1
Training loss: 1.7234997403482453
Validation loss: 2.4911600194226025

Epoch: 6| Step: 2
Training loss: 2.052670725553406
Validation loss: 2.534443943670064

Epoch: 6| Step: 3
Training loss: 1.52475138029057
Validation loss: 2.470503851147559

Epoch: 6| Step: 4
Training loss: 1.2784735206782976
Validation loss: 2.5275918293882107

Epoch: 6| Step: 5
Training loss: 1.2987734216628668
Validation loss: 2.50668349415477

Epoch: 6| Step: 6
Training loss: 2.0710975166323964
Validation loss: 2.4869475967593115

Epoch: 6| Step: 7
Training loss: 1.7021052956380123
Validation loss: 2.4467209436362802

Epoch: 6| Step: 8
Training loss: 1.8471564167255414
Validation loss: 2.4372948285952254

Epoch: 6| Step: 9
Training loss: 2.116620540366614
Validation loss: 2.510007866265051

Epoch: 6| Step: 10
Training loss: 1.6077416288513529
Validation loss: 2.500908535794008

Epoch: 6| Step: 11
Training loss: 1.619918286770539
Validation loss: 2.45300225778418

Epoch: 6| Step: 12
Training loss: 1.0283882430227658
Validation loss: 2.4835895915123825

Epoch: 6| Step: 13
Training loss: 2.0558762973130253
Validation loss: 2.507095322791532

Epoch: 444| Step: 0
Training loss: 1.5656396983174352
Validation loss: 2.492868975329939

Epoch: 6| Step: 1
Training loss: 1.4904474628534772
Validation loss: 2.4796075360848002

Epoch: 6| Step: 2
Training loss: 1.8290297396887158
Validation loss: 2.5265007560082706

Epoch: 6| Step: 3
Training loss: 1.2722142903433737
Validation loss: 2.4676177581526404

Epoch: 6| Step: 4
Training loss: 1.6229651989452223
Validation loss: 2.4495068337326917

Epoch: 6| Step: 5
Training loss: 1.515578436382021
Validation loss: 2.4750728591895985

Epoch: 6| Step: 6
Training loss: 1.632629895380431
Validation loss: 2.519259894257006

Epoch: 6| Step: 7
Training loss: 1.8029402163808381
Validation loss: 2.454574488009635

Epoch: 6| Step: 8
Training loss: 1.9808196409675276
Validation loss: 2.5009982331116642

Epoch: 6| Step: 9
Training loss: 2.152187888703603
Validation loss: 2.4772464823042255

Epoch: 6| Step: 10
Training loss: 2.1050152971522835
Validation loss: 2.4763660290219267

Epoch: 6| Step: 11
Training loss: 2.0211201362671662
Validation loss: 2.49136217078361

Epoch: 6| Step: 12
Training loss: 1.424565714195052
Validation loss: 2.50170202665815

Epoch: 6| Step: 13
Training loss: 1.3884797426091553
Validation loss: 2.5158415863998784

Epoch: 445| Step: 0
Training loss: 1.4004516588262184
Validation loss: 2.4315621048516225

Epoch: 6| Step: 1
Training loss: 1.534138038502142
Validation loss: 2.4862928277879712

Epoch: 6| Step: 2
Training loss: 1.5626541061699435
Validation loss: 2.445439423160011

Epoch: 6| Step: 3
Training loss: 1.6713464917650314
Validation loss: 2.506623718402808

Epoch: 6| Step: 4
Training loss: 1.6844158953229895
Validation loss: 2.4886133816465987

Epoch: 6| Step: 5
Training loss: 1.8968518075043628
Validation loss: 2.4598717739649474

Epoch: 6| Step: 6
Training loss: 1.9444795226914218
Validation loss: 2.4988511963325473

Epoch: 6| Step: 7
Training loss: 1.4141425852990908
Validation loss: 2.493696816999615

Epoch: 6| Step: 8
Training loss: 1.887718299216614
Validation loss: 2.524154674449934

Epoch: 6| Step: 9
Training loss: 1.695799445611157
Validation loss: 2.473166107289965

Epoch: 6| Step: 10
Training loss: 1.381119418984084
Validation loss: 2.498908822539397

Epoch: 6| Step: 11
Training loss: 1.6395289801862996
Validation loss: 2.453389473510627

Epoch: 6| Step: 12
Training loss: 1.6992214159012853
Validation loss: 2.5179499172609705

Epoch: 6| Step: 13
Training loss: 2.514715373805728
Validation loss: 2.48827817614066

Epoch: 446| Step: 0
Training loss: 1.2426578902659795
Validation loss: 2.491510224693051

Epoch: 6| Step: 1
Training loss: 1.646782066430287
Validation loss: 2.4694846044099115

Epoch: 6| Step: 2
Training loss: 1.4352287926195972
Validation loss: 2.5053686077438235

Epoch: 6| Step: 3
Training loss: 1.6111221459255647
Validation loss: 2.456382369590833

Epoch: 6| Step: 4
Training loss: 1.821423236721572
Validation loss: 2.451453904315953

Epoch: 6| Step: 5
Training loss: 2.0161178341216153
Validation loss: 2.476798970180125

Epoch: 6| Step: 6
Training loss: 1.3982739912376019
Validation loss: 2.4592962873138857

Epoch: 6| Step: 7
Training loss: 1.5835883119298741
Validation loss: 2.532984371456895

Epoch: 6| Step: 8
Training loss: 1.6103651833869068
Validation loss: 2.47184392773866

Epoch: 6| Step: 9
Training loss: 1.6857801079310857
Validation loss: 2.5081944686356192

Epoch: 6| Step: 10
Training loss: 1.7754914745060595
Validation loss: 2.526462740996753

Epoch: 6| Step: 11
Training loss: 2.0986014568388147
Validation loss: 2.49271163909014

Epoch: 6| Step: 12
Training loss: 1.8966477988611392
Validation loss: 2.5112756883038316

Epoch: 6| Step: 13
Training loss: 1.2843147467891936
Validation loss: 2.42695239567388

Epoch: 447| Step: 0
Training loss: 1.3822090858259097
Validation loss: 2.516924400785027

Epoch: 6| Step: 1
Training loss: 1.9590838664720231
Validation loss: 2.468056122919988

Epoch: 6| Step: 2
Training loss: 1.6657457032403744
Validation loss: 2.460239440180228

Epoch: 6| Step: 3
Training loss: 1.4460513314281067
Validation loss: 2.5194610552855945

Epoch: 6| Step: 4
Training loss: 2.231537410913963
Validation loss: 2.477456763098959

Epoch: 6| Step: 5
Training loss: 1.5985318421744237
Validation loss: 2.5001860031541554

Epoch: 6| Step: 6
Training loss: 1.6779884439100015
Validation loss: 2.4485781608212496

Epoch: 6| Step: 7
Training loss: 1.6737637412865376
Validation loss: 2.4649993081376724

Epoch: 6| Step: 8
Training loss: 2.15081012455645
Validation loss: 2.4653923833786173

Epoch: 6| Step: 9
Training loss: 1.5985577192245843
Validation loss: 2.525406938346356

Epoch: 6| Step: 10
Training loss: 1.8038729856653117
Validation loss: 2.4745317489940466

Epoch: 6| Step: 11
Training loss: 1.1427647104094696
Validation loss: 2.485171191440064

Epoch: 6| Step: 12
Training loss: 1.6129011024953341
Validation loss: 2.4708526336519845

Epoch: 6| Step: 13
Training loss: 1.5750570408013653
Validation loss: 2.478009867569903

Epoch: 448| Step: 0
Training loss: 1.4666377360929606
Validation loss: 2.4835693545216984

Epoch: 6| Step: 1
Training loss: 1.5706487646707235
Validation loss: 2.4915567132708665

Epoch: 6| Step: 2
Training loss: 1.583356740008894
Validation loss: 2.485972863657342

Epoch: 6| Step: 3
Training loss: 2.042600755389253
Validation loss: 2.424303474949845

Epoch: 6| Step: 4
Training loss: 1.6429762204771763
Validation loss: 2.447681043006836

Epoch: 6| Step: 5
Training loss: 2.219170973693969
Validation loss: 2.4069448298092566

Epoch: 6| Step: 6
Training loss: 1.4998421585959985
Validation loss: 2.4948840586071683

Epoch: 6| Step: 7
Training loss: 1.6822808406076004
Validation loss: 2.5190685979736047

Epoch: 6| Step: 8
Training loss: 1.6360947322979127
Validation loss: 2.4920319940619455

Epoch: 6| Step: 9
Training loss: 1.1525886921878832
Validation loss: 2.545944138374883

Epoch: 6| Step: 10
Training loss: 1.2852165416732226
Validation loss: 2.48011938788193

Epoch: 6| Step: 11
Training loss: 1.6937080913018216
Validation loss: 2.4824773416399153

Epoch: 6| Step: 12
Training loss: 1.6896867359033363
Validation loss: 2.468824561485745

Epoch: 6| Step: 13
Training loss: 1.8250910697057632
Validation loss: 2.436323453568604

Epoch: 449| Step: 0
Training loss: 1.8864306749253836
Validation loss: 2.548763112538861

Epoch: 6| Step: 1
Training loss: 1.4305849020868553
Validation loss: 2.493774357360978

Epoch: 6| Step: 2
Training loss: 1.6591996612154873
Validation loss: 2.4435618382029576

Epoch: 6| Step: 3
Training loss: 1.6192697581666666
Validation loss: 2.4708700826384464

Epoch: 6| Step: 4
Training loss: 1.1072504358280002
Validation loss: 2.4842406205781695

Epoch: 6| Step: 5
Training loss: 1.874201986246641
Validation loss: 2.4768828532939087

Epoch: 6| Step: 6
Training loss: 1.743859690289125
Validation loss: 2.4586420200844854

Epoch: 6| Step: 7
Training loss: 1.4984579106791436
Validation loss: 2.4336456260115713

Epoch: 6| Step: 8
Training loss: 1.5510391289985073
Validation loss: 2.5245155041640834

Epoch: 6| Step: 9
Training loss: 1.944069154792682
Validation loss: 2.5458126543852413

Epoch: 6| Step: 10
Training loss: 2.458222165800045
Validation loss: 2.4892311095885593

Epoch: 6| Step: 11
Training loss: 1.5489935960926642
Validation loss: 2.5076489920910388

Epoch: 6| Step: 12
Training loss: 1.4874532804445075
Validation loss: 2.452470836283911

Epoch: 6| Step: 13
Training loss: 1.3515641317192326
Validation loss: 2.5178300755704477

Epoch: 450| Step: 0
Training loss: 0.8774852879695633
Validation loss: 2.5176450653851803

Epoch: 6| Step: 1
Training loss: 1.571470829779432
Validation loss: 2.49505902214059

Epoch: 6| Step: 2
Training loss: 1.3747204583117896
Validation loss: 2.48810187233626

Epoch: 6| Step: 3
Training loss: 1.7813461010088942
Validation loss: 2.4885507210623476

Epoch: 6| Step: 4
Training loss: 1.2742426380605658
Validation loss: 2.467222628870403

Epoch: 6| Step: 5
Training loss: 1.903743534390246
Validation loss: 2.476234686327921

Epoch: 6| Step: 6
Training loss: 1.248395987382678
Validation loss: 2.488986747341917

Epoch: 6| Step: 7
Training loss: 2.353686213345686
Validation loss: 2.5262121425724304

Epoch: 6| Step: 8
Training loss: 1.204867352271917
Validation loss: 2.5119140785845375

Epoch: 6| Step: 9
Training loss: 1.9060644465956038
Validation loss: 2.4835636214518737

Epoch: 6| Step: 10
Training loss: 1.5320743755085273
Validation loss: 2.4962963151913335

Epoch: 6| Step: 11
Training loss: 1.8913765036360344
Validation loss: 2.4444698855709746

Epoch: 6| Step: 12
Training loss: 2.188440720053154
Validation loss: 2.482653475891931

Epoch: 6| Step: 13
Training loss: 1.6419874074827088
Validation loss: 2.4416134488689454

Epoch: 451| Step: 0
Training loss: 1.8965654601373985
Validation loss: 2.5160152076875097

Epoch: 6| Step: 1
Training loss: 1.2698776007414527
Validation loss: 2.5106968924772866

Epoch: 6| Step: 2
Training loss: 1.0674968913298821
Validation loss: 2.5192957176675477

Epoch: 6| Step: 3
Training loss: 1.8678380878209044
Validation loss: 2.488571389360585

Epoch: 6| Step: 4
Training loss: 2.363308286906294
Validation loss: 2.491521492704251

Epoch: 6| Step: 5
Training loss: 1.527404471748922
Validation loss: 2.4493629101872627

Epoch: 6| Step: 6
Training loss: 1.8400639039842746
Validation loss: 2.477493351870643

Epoch: 6| Step: 7
Training loss: 1.8091482544179798
Validation loss: 2.4572107539131585

Epoch: 6| Step: 8
Training loss: 0.7048908312461145
Validation loss: 2.485725360378056

Epoch: 6| Step: 9
Training loss: 2.2903530401763437
Validation loss: 2.5063618570747908

Epoch: 6| Step: 10
Training loss: 1.7092858969498335
Validation loss: 2.522407908142238

Epoch: 6| Step: 11
Training loss: 1.5335430958913991
Validation loss: 2.4860112864211947

Epoch: 6| Step: 12
Training loss: 1.531921161779415
Validation loss: 2.467347442029804

Epoch: 6| Step: 13
Training loss: 1.059653395810165
Validation loss: 2.4579798726061015

Epoch: 452| Step: 0
Training loss: 1.0786688718203468
Validation loss: 2.4450966280639777

Epoch: 6| Step: 1
Training loss: 1.5962906576428926
Validation loss: 2.493427230700943

Epoch: 6| Step: 2
Training loss: 1.6104500152306487
Validation loss: 2.4920275756410275

Epoch: 6| Step: 3
Training loss: 1.8709158603786038
Validation loss: 2.5256747474166903

Epoch: 6| Step: 4
Training loss: 1.9473791825863997
Validation loss: 2.567765149886926

Epoch: 6| Step: 5
Training loss: 1.737855323300919
Validation loss: 2.536519113397673

Epoch: 6| Step: 6
Training loss: 1.5879216302563737
Validation loss: 2.435562705164275

Epoch: 6| Step: 7
Training loss: 1.9400896178517169
Validation loss: 2.4546123567993554

Epoch: 6| Step: 8
Training loss: 1.3566180806438253
Validation loss: 2.505661743515256

Epoch: 6| Step: 9
Training loss: 1.388801579380236
Validation loss: 2.5396239916433974

Epoch: 6| Step: 10
Training loss: 1.620497260600137
Validation loss: 2.5314353005054326

Epoch: 6| Step: 11
Training loss: 1.7455112245100994
Validation loss: 2.451573975922706

Epoch: 6| Step: 12
Training loss: 2.073908608448967
Validation loss: 2.5085070674331416

Epoch: 6| Step: 13
Training loss: 1.6792691441668979
Validation loss: 2.5140271165161523

Epoch: 453| Step: 0
Training loss: 1.4612895520994713
Validation loss: 2.5458638337843884

Epoch: 6| Step: 1
Training loss: 1.670316807854631
Validation loss: 2.4261023711280663

Epoch: 6| Step: 2
Training loss: 1.4995800066111935
Validation loss: 2.4638646174768657

Epoch: 6| Step: 3
Training loss: 1.7359073502388545
Validation loss: 2.5114201101988054

Epoch: 6| Step: 4
Training loss: 1.5947465959588267
Validation loss: 2.463599044720263

Epoch: 6| Step: 5
Training loss: 1.1633150914318635
Validation loss: 2.473641331585626

Epoch: 6| Step: 6
Training loss: 1.5385882426318584
Validation loss: 2.482290794897019

Epoch: 6| Step: 7
Training loss: 2.2499491367948883
Validation loss: 2.485859456374514

Epoch: 6| Step: 8
Training loss: 1.2071797794941446
Validation loss: 2.475758935722832

Epoch: 6| Step: 9
Training loss: 1.782165693523917
Validation loss: 2.458940938407132

Epoch: 6| Step: 10
Training loss: 1.800774232929319
Validation loss: 2.5010932541848114

Epoch: 6| Step: 11
Training loss: 1.2632355917073623
Validation loss: 2.555051242512061

Epoch: 6| Step: 12
Training loss: 2.049791078854004
Validation loss: 2.5314868353863402

Epoch: 6| Step: 13
Training loss: 1.9746707714281986
Validation loss: 2.5304985566660974

Epoch: 454| Step: 0
Training loss: 1.0547697812232941
Validation loss: 2.467836037665379

Epoch: 6| Step: 1
Training loss: 1.8205454926918727
Validation loss: 2.478389112049229

Epoch: 6| Step: 2
Training loss: 1.7268023432199902
Validation loss: 2.5214380335467474

Epoch: 6| Step: 3
Training loss: 1.57162056716079
Validation loss: 2.4986950278173956

Epoch: 6| Step: 4
Training loss: 1.4328197083869076
Validation loss: 2.446729315434334

Epoch: 6| Step: 5
Training loss: 2.0037159968850613
Validation loss: 2.457469340633789

Epoch: 6| Step: 6
Training loss: 1.441864767778234
Validation loss: 2.4806331694685544

Epoch: 6| Step: 7
Training loss: 2.3208461366182718
Validation loss: 2.503352393989929

Epoch: 6| Step: 8
Training loss: 1.7105294354985625
Validation loss: 2.51730592985191

Epoch: 6| Step: 9
Training loss: 1.487340274217233
Validation loss: 2.45218673893534

Epoch: 6| Step: 10
Training loss: 1.1264989192126118
Validation loss: 2.4943028107060834

Epoch: 6| Step: 11
Training loss: 1.9406404577551828
Validation loss: 2.5085268359990267

Epoch: 6| Step: 12
Training loss: 1.2492651209714818
Validation loss: 2.4705552540957187

Epoch: 6| Step: 13
Training loss: 1.2926344886035337
Validation loss: 2.5113636678655173

Epoch: 455| Step: 0
Training loss: 1.3230031152949486
Validation loss: 2.465505951204976

Epoch: 6| Step: 1
Training loss: 1.933281397395975
Validation loss: 2.501156271908773

Epoch: 6| Step: 2
Training loss: 1.7128227681515291
Validation loss: 2.4757717292536388

Epoch: 6| Step: 3
Training loss: 1.7978200666247492
Validation loss: 2.545370704901277

Epoch: 6| Step: 4
Training loss: 1.489521220941853
Validation loss: 2.5260801196726286

Epoch: 6| Step: 5
Training loss: 2.3198316698831873
Validation loss: 2.4790205863780193

Epoch: 6| Step: 6
Training loss: 1.7353904432106808
Validation loss: 2.440991503329837

Epoch: 6| Step: 7
Training loss: 1.4858766689745255
Validation loss: 2.4722748236893954

Epoch: 6| Step: 8
Training loss: 1.6228381228099922
Validation loss: 2.525021347715915

Epoch: 6| Step: 9
Training loss: 1.4954169512932947
Validation loss: 2.463390957016552

Epoch: 6| Step: 10
Training loss: 1.069496344811113
Validation loss: 2.4699531324448043

Epoch: 6| Step: 11
Training loss: 1.7669904712016369
Validation loss: 2.4789006817914943

Epoch: 6| Step: 12
Training loss: 1.7421042931363389
Validation loss: 2.453413445323146

Epoch: 6| Step: 13
Training loss: 1.5497655352795177
Validation loss: 2.477010689285171

Epoch: 456| Step: 0
Training loss: 1.6557167202350815
Validation loss: 2.4965814926617855

Epoch: 6| Step: 1
Training loss: 1.7572274824027476
Validation loss: 2.4676661699934637

Epoch: 6| Step: 2
Training loss: 1.9070505431127975
Validation loss: 2.4868696755083333

Epoch: 6| Step: 3
Training loss: 1.1321756611730733
Validation loss: 2.466252432393925

Epoch: 6| Step: 4
Training loss: 1.750853738982105
Validation loss: 2.5167633519964863

Epoch: 6| Step: 5
Training loss: 1.448185390354151
Validation loss: 2.4882944190772056

Epoch: 6| Step: 6
Training loss: 1.5716990711813037
Validation loss: 2.450305367241403

Epoch: 6| Step: 7
Training loss: 2.395876234472099
Validation loss: 2.4894446610122523

Epoch: 6| Step: 8
Training loss: 1.7205141204015084
Validation loss: 2.4983046987594992

Epoch: 6| Step: 9
Training loss: 1.8391852688709236
Validation loss: 2.5407896300557056

Epoch: 6| Step: 10
Training loss: 1.760578877877811
Validation loss: 2.4882091361667253

Epoch: 6| Step: 11
Training loss: 1.5644279792279228
Validation loss: 2.5190906594444145

Epoch: 6| Step: 12
Training loss: 1.169425285803605
Validation loss: 2.536873001864126

Epoch: 6| Step: 13
Training loss: 1.2527062684424937
Validation loss: 2.4855429561817504

Epoch: 457| Step: 0
Training loss: 2.1299073271672073
Validation loss: 2.4702198787330496

Epoch: 6| Step: 1
Training loss: 1.8325020321448326
Validation loss: 2.4978296344404254

Epoch: 6| Step: 2
Training loss: 1.5755461215257036
Validation loss: 2.477778601381492

Epoch: 6| Step: 3
Training loss: 1.2153037816247714
Validation loss: 2.5096569968741624

Epoch: 6| Step: 4
Training loss: 1.659271507124946
Validation loss: 2.4859733199820644

Epoch: 6| Step: 5
Training loss: 2.274999337667851
Validation loss: 2.518333154394672

Epoch: 6| Step: 6
Training loss: 1.3935478867897522
Validation loss: 2.5075217048926692

Epoch: 6| Step: 7
Training loss: 1.420533186382885
Validation loss: 2.497759963989501

Epoch: 6| Step: 8
Training loss: 1.5428428115633255
Validation loss: 2.5020291881381276

Epoch: 6| Step: 9
Training loss: 1.863029798899012
Validation loss: 2.530925936092288

Epoch: 6| Step: 10
Training loss: 1.3127404855482523
Validation loss: 2.496646934643349

Epoch: 6| Step: 11
Training loss: 1.612442648407402
Validation loss: 2.4658902335084174

Epoch: 6| Step: 12
Training loss: 1.4304587363325436
Validation loss: 2.4667330605596307

Epoch: 6| Step: 13
Training loss: 1.3061298004771884
Validation loss: 2.4767565457282785

Epoch: 458| Step: 0
Training loss: 1.4310173145368978
Validation loss: 2.4816027225406008

Epoch: 6| Step: 1
Training loss: 1.6014628309545098
Validation loss: 2.4480984398861234

Epoch: 6| Step: 2
Training loss: 1.883945235150919
Validation loss: 2.473163093942885

Epoch: 6| Step: 3
Training loss: 1.4468810771377842
Validation loss: 2.461924925527477

Epoch: 6| Step: 4
Training loss: 1.126471616594832
Validation loss: 2.47165557908821

Epoch: 6| Step: 5
Training loss: 1.7674193590213134
Validation loss: 2.4462553747078477

Epoch: 6| Step: 6
Training loss: 2.358121728558651
Validation loss: 2.430452810089585

Epoch: 6| Step: 7
Training loss: 1.6510409366192893
Validation loss: 2.458210191376464

Epoch: 6| Step: 8
Training loss: 1.1000397349897018
Validation loss: 2.49136557680976

Epoch: 6| Step: 9
Training loss: 1.318161741914005
Validation loss: 2.515697233884883

Epoch: 6| Step: 10
Training loss: 1.7387015188274484
Validation loss: 2.4497778699947155

Epoch: 6| Step: 11
Training loss: 2.296801611318259
Validation loss: 2.518567706426746

Epoch: 6| Step: 12
Training loss: 1.1948044638487445
Validation loss: 2.5170382213668945

Epoch: 6| Step: 13
Training loss: 1.8256984158138965
Validation loss: 2.442834965021306

Epoch: 459| Step: 0
Training loss: 2.3833904628531157
Validation loss: 2.4947011597545297

Epoch: 6| Step: 1
Training loss: 1.3804745927135438
Validation loss: 2.5179360668737716

Epoch: 6| Step: 2
Training loss: 1.5204661026111215
Validation loss: 2.4966677382027793

Epoch: 6| Step: 3
Training loss: 1.9799145406525387
Validation loss: 2.494367279560344

Epoch: 6| Step: 4
Training loss: 1.8416584889272078
Validation loss: 2.504220277805712

Epoch: 6| Step: 5
Training loss: 1.3865412638811032
Validation loss: 2.4656447599663562

Epoch: 6| Step: 6
Training loss: 1.5189197555301017
Validation loss: 2.5542507685802565

Epoch: 6| Step: 7
Training loss: 1.4530342647978105
Validation loss: 2.5264011307856826

Epoch: 6| Step: 8
Training loss: 2.0208286272236666
Validation loss: 2.501671129995942

Epoch: 6| Step: 9
Training loss: 1.5107380842906464
Validation loss: 2.4624581962598837

Epoch: 6| Step: 10
Training loss: 1.7464905017121624
Validation loss: 2.453298068964596

Epoch: 6| Step: 11
Training loss: 1.960451468612501
Validation loss: 2.5067522641143607

Epoch: 6| Step: 12
Training loss: 1.0823204122378476
Validation loss: 2.494327837473498

Epoch: 6| Step: 13
Training loss: 1.3013601303768016
Validation loss: 2.4298719142195955

Epoch: 460| Step: 0
Training loss: 1.1504904634063053
Validation loss: 2.4991073275981597

Epoch: 6| Step: 1
Training loss: 1.4715508883689092
Validation loss: 2.4963526740640436

Epoch: 6| Step: 2
Training loss: 2.0703772192861765
Validation loss: 2.4661860497754393

Epoch: 6| Step: 3
Training loss: 1.2219555098992834
Validation loss: 2.482782659639981

Epoch: 6| Step: 4
Training loss: 2.2994838093890406
Validation loss: 2.514441086555081

Epoch: 6| Step: 5
Training loss: 1.1058014817143582
Validation loss: 2.465593671070045

Epoch: 6| Step: 6
Training loss: 1.905183399913966
Validation loss: 2.4844065503153585

Epoch: 6| Step: 7
Training loss: 1.7820218739478244
Validation loss: 2.469979099263137

Epoch: 6| Step: 8
Training loss: 1.8843151759936176
Validation loss: 2.4445983615534965

Epoch: 6| Step: 9
Training loss: 1.6411498184018514
Validation loss: 2.5134659887359216

Epoch: 6| Step: 10
Training loss: 1.8340870723875464
Validation loss: 2.5086700667081483

Epoch: 6| Step: 11
Training loss: 1.4200192592550545
Validation loss: 2.497921790514802

Epoch: 6| Step: 12
Training loss: 1.4737757467491222
Validation loss: 2.490467114608237

Epoch: 6| Step: 13
Training loss: 1.645315386560413
Validation loss: 2.5229146289902737

Epoch: 461| Step: 0
Training loss: 1.979768708331549
Validation loss: 2.5289803197297203

Epoch: 6| Step: 1
Training loss: 1.526383666512732
Validation loss: 2.493226491977131

Epoch: 6| Step: 2
Training loss: 1.3722230439348801
Validation loss: 2.4855765204499005

Epoch: 6| Step: 3
Training loss: 1.6922703885588626
Validation loss: 2.4771585691416624

Epoch: 6| Step: 4
Training loss: 1.7368980819634454
Validation loss: 2.510587991158157

Epoch: 6| Step: 5
Training loss: 1.4960366180905622
Validation loss: 2.4813221512515353

Epoch: 6| Step: 6
Training loss: 1.1869652698613362
Validation loss: 2.4991755428404896

Epoch: 6| Step: 7
Training loss: 1.658004551153068
Validation loss: 2.474936616710989

Epoch: 6| Step: 8
Training loss: 1.5714800844790577
Validation loss: 2.5106092362209687

Epoch: 6| Step: 9
Training loss: 1.3402712393004392
Validation loss: 2.515476707266433

Epoch: 6| Step: 10
Training loss: 1.3815379330276412
Validation loss: 2.5076010669250763

Epoch: 6| Step: 11
Training loss: 2.211912014520299
Validation loss: 2.450438770351059

Epoch: 6| Step: 12
Training loss: 1.6435865284673783
Validation loss: 2.4453026692292656

Epoch: 6| Step: 13
Training loss: 1.9857852760398393
Validation loss: 2.5397463469701385

Epoch: 462| Step: 0
Training loss: 1.4881715909352564
Validation loss: 2.4323452666525287

Epoch: 6| Step: 1
Training loss: 0.8961561345914661
Validation loss: 2.429252143143587

Epoch: 6| Step: 2
Training loss: 1.4863522661732398
Validation loss: 2.467937133683362

Epoch: 6| Step: 3
Training loss: 2.010739460332354
Validation loss: 2.461921667249057

Epoch: 6| Step: 4
Training loss: 2.1734649546772555
Validation loss: 2.5496431385314686

Epoch: 6| Step: 5
Training loss: 1.6553366679940118
Validation loss: 2.4301404564751086

Epoch: 6| Step: 6
Training loss: 1.5736772159534453
Validation loss: 2.4598238267500587

Epoch: 6| Step: 7
Training loss: 1.8401780523314113
Validation loss: 2.487709728148835

Epoch: 6| Step: 8
Training loss: 1.438217813148572
Validation loss: 2.395195244077889

Epoch: 6| Step: 9
Training loss: 1.508407238296545
Validation loss: 2.500012278783034

Epoch: 6| Step: 10
Training loss: 1.6521226090151773
Validation loss: 2.5248667897593364

Epoch: 6| Step: 11
Training loss: 2.1842168966332274
Validation loss: 2.496353428875494

Epoch: 6| Step: 12
Training loss: 1.4598716070601352
Validation loss: 2.465805499230231

Epoch: 6| Step: 13
Training loss: 1.5599563493490418
Validation loss: 2.508823002453494

Epoch: 463| Step: 0
Training loss: 1.2994438375538926
Validation loss: 2.4582163235567744

Epoch: 6| Step: 1
Training loss: 1.6856554334564304
Validation loss: 2.4634953938302533

Epoch: 6| Step: 2
Training loss: 1.320850059732292
Validation loss: 2.5005432000229035

Epoch: 6| Step: 3
Training loss: 1.2184362741304204
Validation loss: 2.482262769435562

Epoch: 6| Step: 4
Training loss: 1.3156468496071294
Validation loss: 2.4957672279937433

Epoch: 6| Step: 5
Training loss: 1.7331085392486323
Validation loss: 2.4467142535117365

Epoch: 6| Step: 6
Training loss: 1.3257517535424472
Validation loss: 2.449879479933651

Epoch: 6| Step: 7
Training loss: 2.612947588091658
Validation loss: 2.509229368460917

Epoch: 6| Step: 8
Training loss: 1.8435447707961778
Validation loss: 2.471639360607506

Epoch: 6| Step: 9
Training loss: 1.7571485833884406
Validation loss: 2.4801147590751333

Epoch: 6| Step: 10
Training loss: 1.496116618088732
Validation loss: 2.461827380966955

Epoch: 6| Step: 11
Training loss: 1.4082259812530526
Validation loss: 2.430892889069399

Epoch: 6| Step: 12
Training loss: 1.8849623187116094
Validation loss: 2.4817934766814465

Epoch: 6| Step: 13
Training loss: 1.4974503305441884
Validation loss: 2.497211480333073

Epoch: 464| Step: 0
Training loss: 1.6979947998542373
Validation loss: 2.501161579773417

Epoch: 6| Step: 1
Training loss: 1.8785899445254788
Validation loss: 2.491702962299532

Epoch: 6| Step: 2
Training loss: 0.9398306169488108
Validation loss: 2.40686496930143

Epoch: 6| Step: 3
Training loss: 1.1544796561740598
Validation loss: 2.4411889924544035

Epoch: 6| Step: 4
Training loss: 1.59460889822538
Validation loss: 2.4780871828917395

Epoch: 6| Step: 5
Training loss: 1.8125672163502908
Validation loss: 2.4592149014863405

Epoch: 6| Step: 6
Training loss: 1.900709637078005
Validation loss: 2.4251073315599836

Epoch: 6| Step: 7
Training loss: 2.1444371937622053
Validation loss: 2.455046487031471

Epoch: 6| Step: 8
Training loss: 1.4247236954362072
Validation loss: 2.478649791450823

Epoch: 6| Step: 9
Training loss: 1.5563842102763568
Validation loss: 2.4691695582021507

Epoch: 6| Step: 10
Training loss: 1.202236937698031
Validation loss: 2.4906774639406706

Epoch: 6| Step: 11
Training loss: 1.3830161941418715
Validation loss: 2.5041555783785223

Epoch: 6| Step: 12
Training loss: 1.851012715671581
Validation loss: 2.435680111789599

Epoch: 6| Step: 13
Training loss: 1.8313972335839528
Validation loss: 2.4771858927323334

Epoch: 465| Step: 0
Training loss: 1.5035912914666312
Validation loss: 2.4892749579086044

Epoch: 6| Step: 1
Training loss: 1.5629944591167737
Validation loss: 2.486943255380356

Epoch: 6| Step: 2
Training loss: 1.6862381349772524
Validation loss: 2.5405575413277113

Epoch: 6| Step: 3
Training loss: 2.4848275402254956
Validation loss: 2.480204228514257

Epoch: 6| Step: 4
Training loss: 1.0960467610581892
Validation loss: 2.573830231667581

Epoch: 6| Step: 5
Training loss: 1.422877702230719
Validation loss: 2.4906702835718306

Epoch: 6| Step: 6
Training loss: 1.3049817695659722
Validation loss: 2.5354080099203973

Epoch: 6| Step: 7
Training loss: 2.365479914097565
Validation loss: 2.530713070875151

Epoch: 6| Step: 8
Training loss: 1.6204810030069983
Validation loss: 2.5088709584347084

Epoch: 6| Step: 9
Training loss: 1.2955997125611747
Validation loss: 2.5228237862526317

Epoch: 6| Step: 10
Training loss: 1.874952633577331
Validation loss: 2.4847988975127224

Epoch: 6| Step: 11
Training loss: 1.4194501384430955
Validation loss: 2.422885645003848

Epoch: 6| Step: 12
Training loss: 1.3351522000308857
Validation loss: 2.4667194718604026

Epoch: 6| Step: 13
Training loss: 1.4002695709642512
Validation loss: 2.5540328933085212

Epoch: 466| Step: 0
Training loss: 1.739480554281756
Validation loss: 2.4798303613489683

Epoch: 6| Step: 1
Training loss: 1.6940846017656417
Validation loss: 2.4579898909956803

Epoch: 6| Step: 2
Training loss: 1.5981063395318167
Validation loss: 2.5046193638037293

Epoch: 6| Step: 3
Training loss: 1.7022420011577
Validation loss: 2.456092476581087

Epoch: 6| Step: 4
Training loss: 1.6612687276756215
Validation loss: 2.5081182582317503

Epoch: 6| Step: 5
Training loss: 2.2262316006173757
Validation loss: 2.525760562852445

Epoch: 6| Step: 6
Training loss: 1.1651346274588872
Validation loss: 2.522175133709358

Epoch: 6| Step: 7
Training loss: 1.8560590266879786
Validation loss: 2.4492600133578772

Epoch: 6| Step: 8
Training loss: 1.7289632961068515
Validation loss: 2.5055325744949903

Epoch: 6| Step: 9
Training loss: 1.1308833566076284
Validation loss: 2.4820632978309547

Epoch: 6| Step: 10
Training loss: 1.8445684265242113
Validation loss: 2.5053427401378308

Epoch: 6| Step: 11
Training loss: 1.4329857641392778
Validation loss: 2.530154498686637

Epoch: 6| Step: 12
Training loss: 1.2527200667703406
Validation loss: 2.4976288369205975

Epoch: 6| Step: 13
Training loss: 1.2265988484238985
Validation loss: 2.4975636516199025

Epoch: 467| Step: 0
Training loss: 1.5618999855024407
Validation loss: 2.4778458389351705

Epoch: 6| Step: 1
Training loss: 2.508403957889277
Validation loss: 2.4809585662572324

Epoch: 6| Step: 2
Training loss: 1.3386510762228823
Validation loss: 2.4801352227186384

Epoch: 6| Step: 3
Training loss: 1.8820331274191873
Validation loss: 2.4542577555484484

Epoch: 6| Step: 4
Training loss: 1.6365770082848625
Validation loss: 2.4559310040049827

Epoch: 6| Step: 5
Training loss: 1.3263953670900512
Validation loss: 2.519174576347122

Epoch: 6| Step: 6
Training loss: 2.0999446725368895
Validation loss: 2.477211674036579

Epoch: 6| Step: 7
Training loss: 1.8497101092676729
Validation loss: 2.4929858166803975

Epoch: 6| Step: 8
Training loss: 1.2818963351210921
Validation loss: 2.4589852507508883

Epoch: 6| Step: 9
Training loss: 1.1099195084298574
Validation loss: 2.4949909317049412

Epoch: 6| Step: 10
Training loss: 1.5659347166920874
Validation loss: 2.477527694678979

Epoch: 6| Step: 11
Training loss: 1.4121081931292598
Validation loss: 2.4940795289653304

Epoch: 6| Step: 12
Training loss: 1.28336573576377
Validation loss: 2.4345024373241984

Epoch: 6| Step: 13
Training loss: 1.6380825142297604
Validation loss: 2.5054792840477327

Epoch: 468| Step: 0
Training loss: 2.072193716169597
Validation loss: 2.4762057412993297

Epoch: 6| Step: 1
Training loss: 1.70956470336482
Validation loss: 2.501140279060517

Epoch: 6| Step: 2
Training loss: 1.2477119485918757
Validation loss: 2.419928559740625

Epoch: 6| Step: 3
Training loss: 1.594669600320327
Validation loss: 2.5043210157419495

Epoch: 6| Step: 4
Training loss: 1.8181024978414915
Validation loss: 2.492135456940932

Epoch: 6| Step: 5
Training loss: 1.3586688783744303
Validation loss: 2.455266430248124

Epoch: 6| Step: 6
Training loss: 1.54886614643393
Validation loss: 2.4836136217569416

Epoch: 6| Step: 7
Training loss: 1.4878633167648128
Validation loss: 2.485223257067175

Epoch: 6| Step: 8
Training loss: 1.7571264666059803
Validation loss: 2.4546337239262335

Epoch: 6| Step: 9
Training loss: 1.6609742068148878
Validation loss: 2.5015620612148526

Epoch: 6| Step: 10
Training loss: 1.2018084072285573
Validation loss: 2.4969818857893737

Epoch: 6| Step: 11
Training loss: 2.0344919009981464
Validation loss: 2.478114587797914

Epoch: 6| Step: 12
Training loss: 1.806156567859686
Validation loss: 2.4989149651322364

Epoch: 6| Step: 13
Training loss: 1.9155226762584927
Validation loss: 2.5108594626869323

Epoch: 469| Step: 0
Training loss: 1.4651628884125132
Validation loss: 2.4987719970505444

Epoch: 6| Step: 1
Training loss: 0.9626595798330203
Validation loss: 2.4308813015293866

Epoch: 6| Step: 2
Training loss: 1.544570747916263
Validation loss: 2.455460354793568

Epoch: 6| Step: 3
Training loss: 2.078484640336793
Validation loss: 2.498458309007789

Epoch: 6| Step: 4
Training loss: 2.1039331388401963
Validation loss: 2.466606157381605

Epoch: 6| Step: 5
Training loss: 1.3546395967631133
Validation loss: 2.5249482332598836

Epoch: 6| Step: 6
Training loss: 1.7586308587665593
Validation loss: 2.496766377162789

Epoch: 6| Step: 7
Training loss: 1.9126199073850854
Validation loss: 2.4571557826859953

Epoch: 6| Step: 8
Training loss: 1.6336849382400056
Validation loss: 2.4683857393729274

Epoch: 6| Step: 9
Training loss: 1.3168988763485046
Validation loss: 2.4933808849572903

Epoch: 6| Step: 10
Training loss: 1.7696895570657163
Validation loss: 2.4757450538128376

Epoch: 6| Step: 11
Training loss: 1.9031589649094822
Validation loss: 2.4673787300517795

Epoch: 6| Step: 12
Training loss: 1.3575517990177377
Validation loss: 2.456211471307623

Epoch: 6| Step: 13
Training loss: 1.4750987068382142
Validation loss: 2.4899883547498765

Epoch: 470| Step: 0
Training loss: 1.7457828799705917
Validation loss: 2.4217163722036608

Epoch: 6| Step: 1
Training loss: 1.3676716410510568
Validation loss: 2.55368505511964

Epoch: 6| Step: 2
Training loss: 1.4670704105280774
Validation loss: 2.478565168603549

Epoch: 6| Step: 3
Training loss: 1.6697097732854669
Validation loss: 2.4938291171309035

Epoch: 6| Step: 4
Training loss: 1.4825999840250996
Validation loss: 2.4820451306713176

Epoch: 6| Step: 5
Training loss: 1.5154211949443455
Validation loss: 2.4749012248810356

Epoch: 6| Step: 6
Training loss: 1.4853923323012594
Validation loss: 2.481036765120011

Epoch: 6| Step: 7
Training loss: 1.570376494512839
Validation loss: 2.453244218606651

Epoch: 6| Step: 8
Training loss: 1.9092376934322721
Validation loss: 2.447594731477132

Epoch: 6| Step: 9
Training loss: 1.5160554097751253
Validation loss: 2.497744393818541

Epoch: 6| Step: 10
Training loss: 2.1963911020093483
Validation loss: 2.502032433634417

Epoch: 6| Step: 11
Training loss: 1.4031928846763888
Validation loss: 2.532786365030133

Epoch: 6| Step: 12
Training loss: 1.9112707837747986
Validation loss: 2.4592230827226484

Epoch: 6| Step: 13
Training loss: 1.1066825861436935
Validation loss: 2.4462127585224036

Epoch: 471| Step: 0
Training loss: 1.46568969713905
Validation loss: 2.508718734806275

Epoch: 6| Step: 1
Training loss: 1.3798261389193276
Validation loss: 2.4721085473605386

Epoch: 6| Step: 2
Training loss: 1.7160104593033805
Validation loss: 2.4706071166937664

Epoch: 6| Step: 3
Training loss: 1.857972072617275
Validation loss: 2.4818641273100335

Epoch: 6| Step: 4
Training loss: 1.6123449088335609
Validation loss: 2.5366979228405

Epoch: 6| Step: 5
Training loss: 1.5022670779845344
Validation loss: 2.438588650497736

Epoch: 6| Step: 6
Training loss: 1.7279286912889564
Validation loss: 2.534230057853202

Epoch: 6| Step: 7
Training loss: 1.4839999076349688
Validation loss: 2.463665349282369

Epoch: 6| Step: 8
Training loss: 1.79305125859057
Validation loss: 2.5287221878010806

Epoch: 6| Step: 9
Training loss: 1.1189472237755593
Validation loss: 2.430099132203273

Epoch: 6| Step: 10
Training loss: 1.8927347061371707
Validation loss: 2.4539175201438344

Epoch: 6| Step: 11
Training loss: 1.2638306319023302
Validation loss: 2.455213288193732

Epoch: 6| Step: 12
Training loss: 1.7107351523109997
Validation loss: 2.5018363525066185

Epoch: 6| Step: 13
Training loss: 2.4769972169973657
Validation loss: 2.4362111056097477

Epoch: 472| Step: 0
Training loss: 1.1778967193508603
Validation loss: 2.4969374304953065

Epoch: 6| Step: 1
Training loss: 1.7579621653950142
Validation loss: 2.5141811886063743

Epoch: 6| Step: 2
Training loss: 2.526491849969567
Validation loss: 2.4926439990304754

Epoch: 6| Step: 3
Training loss: 1.5528013202942665
Validation loss: 2.499287084224256

Epoch: 6| Step: 4
Training loss: 1.9781077379675764
Validation loss: 2.506641727881235

Epoch: 6| Step: 5
Training loss: 1.2653789516569283
Validation loss: 2.495381880812298

Epoch: 6| Step: 6
Training loss: 1.143916098202249
Validation loss: 2.469098575480702

Epoch: 6| Step: 7
Training loss: 1.870098446585274
Validation loss: 2.4503401141209595

Epoch: 6| Step: 8
Training loss: 1.2471646577162219
Validation loss: 2.446914538067698

Epoch: 6| Step: 9
Training loss: 1.8183759612772337
Validation loss: 2.4563730668640433

Epoch: 6| Step: 10
Training loss: 1.3101192407720752
Validation loss: 2.4891545451671986

Epoch: 6| Step: 11
Training loss: 1.6244240253560807
Validation loss: 2.4712578105413545

Epoch: 6| Step: 12
Training loss: 1.8071387351757495
Validation loss: 2.501932613357279

Epoch: 6| Step: 13
Training loss: 1.5881806844161463
Validation loss: 2.5253876648320164

Epoch: 473| Step: 0
Training loss: 1.398950876806426
Validation loss: 2.4910748315296694

Epoch: 6| Step: 1
Training loss: 2.1577121365994842
Validation loss: 2.514735801573794

Epoch: 6| Step: 2
Training loss: 0.9386515856076835
Validation loss: 2.4829326355367742

Epoch: 6| Step: 3
Training loss: 1.0525626925464928
Validation loss: 2.488198730987942

Epoch: 6| Step: 4
Training loss: 1.358749333357801
Validation loss: 2.478521649018879

Epoch: 6| Step: 5
Training loss: 2.2731553784223997
Validation loss: 2.497070795029858

Epoch: 6| Step: 6
Training loss: 1.7352509906844562
Validation loss: 2.4712360015440633

Epoch: 6| Step: 7
Training loss: 1.9531753533548284
Validation loss: 2.5241567524551507

Epoch: 6| Step: 8
Training loss: 1.6170244365065352
Validation loss: 2.4940448500117682

Epoch: 6| Step: 9
Training loss: 1.7478996342710829
Validation loss: 2.4905224782444657

Epoch: 6| Step: 10
Training loss: 1.5977424281225447
Validation loss: 2.541330764848018

Epoch: 6| Step: 11
Training loss: 1.6682554619469758
Validation loss: 2.460137544835686

Epoch: 6| Step: 12
Training loss: 1.5387996700894364
Validation loss: 2.499720833686259

Epoch: 6| Step: 13
Training loss: 1.2794182406797416
Validation loss: 2.5031640385821756

Epoch: 474| Step: 0
Training loss: 1.9025899426206774
Validation loss: 2.465833711217157

Epoch: 6| Step: 1
Training loss: 1.595240251509857
Validation loss: 2.459779288759353

Epoch: 6| Step: 2
Training loss: 1.1661984094327922
Validation loss: 2.5179711587513633

Epoch: 6| Step: 3
Training loss: 1.7224816473881484
Validation loss: 2.5123239518286185

Epoch: 6| Step: 4
Training loss: 1.5772193349486585
Validation loss: 2.5124686981456907

Epoch: 6| Step: 5
Training loss: 1.6065827377579154
Validation loss: 2.483388795692364

Epoch: 6| Step: 6
Training loss: 1.3721373843704259
Validation loss: 2.5101645922684095

Epoch: 6| Step: 7
Training loss: 1.660268838094028
Validation loss: 2.5232247132369263

Epoch: 6| Step: 8
Training loss: 1.8082652112842355
Validation loss: 2.5352315131373113

Epoch: 6| Step: 9
Training loss: 1.7358419726824146
Validation loss: 2.53093860472582

Epoch: 6| Step: 10
Training loss: 2.284219977132383
Validation loss: 2.4893314757459994

Epoch: 6| Step: 11
Training loss: 1.6827146000485866
Validation loss: 2.494347432177933

Epoch: 6| Step: 12
Training loss: 0.9455474057227994
Validation loss: 2.454629344194752

Epoch: 6| Step: 13
Training loss: 1.1842887021634638
Validation loss: 2.4925114649999585

Epoch: 475| Step: 0
Training loss: 1.723323078801373
Validation loss: 2.459869333167256

Epoch: 6| Step: 1
Training loss: 1.281596532340484
Validation loss: 2.4585114156113583

Epoch: 6| Step: 2
Training loss: 1.7156207642216323
Validation loss: 2.48786125773286

Epoch: 6| Step: 3
Training loss: 1.283891234981503
Validation loss: 2.4907759016636013

Epoch: 6| Step: 4
Training loss: 1.131128203437342
Validation loss: 2.552107139879851

Epoch: 6| Step: 5
Training loss: 1.6852106176668888
Validation loss: 2.51627397481297

Epoch: 6| Step: 6
Training loss: 1.2672859407657517
Validation loss: 2.476554589287863

Epoch: 6| Step: 7
Training loss: 1.524518534216437
Validation loss: 2.4288333958087915

Epoch: 6| Step: 8
Training loss: 1.3987015629376793
Validation loss: 2.4459582469548935

Epoch: 6| Step: 9
Training loss: 2.3970097072501835
Validation loss: 2.468538176822475

Epoch: 6| Step: 10
Training loss: 1.8265539738543386
Validation loss: 2.513679128367504

Epoch: 6| Step: 11
Training loss: 1.7072693682694886
Validation loss: 2.467414258874053

Epoch: 6| Step: 12
Training loss: 1.668468605919026
Validation loss: 2.4279136453918335

Epoch: 6| Step: 13
Training loss: 1.6900883356968346
Validation loss: 2.460447744925327

Epoch: 476| Step: 0
Training loss: 1.5880183957953766
Validation loss: 2.4849254493410835

Epoch: 6| Step: 1
Training loss: 1.5149008997366624
Validation loss: 2.414733754101745

Epoch: 6| Step: 2
Training loss: 1.3129179152944122
Validation loss: 2.4661881329652555

Epoch: 6| Step: 3
Training loss: 1.4644201861584734
Validation loss: 2.4784607172134385

Epoch: 6| Step: 4
Training loss: 1.4753967204231877
Validation loss: 2.499497744652894

Epoch: 6| Step: 5
Training loss: 1.9854052414887264
Validation loss: 2.527418399830531

Epoch: 6| Step: 6
Training loss: 1.3663327406166679
Validation loss: 2.4591772573367168

Epoch: 6| Step: 7
Training loss: 1.4131179521225476
Validation loss: 2.5052826760605136

Epoch: 6| Step: 8
Training loss: 1.6375638468867757
Validation loss: 2.5065864318563253

Epoch: 6| Step: 9
Training loss: 2.163240572738782
Validation loss: 2.5001100885086425

Epoch: 6| Step: 10
Training loss: 1.9669328811124362
Validation loss: 2.524630081735058

Epoch: 6| Step: 11
Training loss: 1.8289025112343646
Validation loss: 2.4339050748018067

Epoch: 6| Step: 12
Training loss: 1.2318465980418087
Validation loss: 2.5109921858034627

Epoch: 6| Step: 13
Training loss: 1.383197493758504
Validation loss: 2.4828297432380766

Epoch: 477| Step: 0
Training loss: 1.5794056143773083
Validation loss: 2.494753600412501

Epoch: 6| Step: 1
Training loss: 1.2904133510002984
Validation loss: 2.4705038916178395

Epoch: 6| Step: 2
Training loss: 1.8708734880427134
Validation loss: 2.539201766392022

Epoch: 6| Step: 3
Training loss: 1.9901428501097034
Validation loss: 2.4559216113622284

Epoch: 6| Step: 4
Training loss: 2.1770382987540535
Validation loss: 2.477979687310728

Epoch: 6| Step: 5
Training loss: 1.7868664185517067
Validation loss: 2.5083440493896223

Epoch: 6| Step: 6
Training loss: 1.3296811131683697
Validation loss: 2.432019718207483

Epoch: 6| Step: 7
Training loss: 1.1543463940011442
Validation loss: 2.4753228816891646

Epoch: 6| Step: 8
Training loss: 1.5816882103007825
Validation loss: 2.505462913598859

Epoch: 6| Step: 9
Training loss: 1.615494436157053
Validation loss: 2.4695270395956577

Epoch: 6| Step: 10
Training loss: 1.8706500138465771
Validation loss: 2.4708490769176397

Epoch: 6| Step: 11
Training loss: 1.613875974529434
Validation loss: 2.520582306771272

Epoch: 6| Step: 12
Training loss: 1.208296227159445
Validation loss: 2.4569243404196666

Epoch: 6| Step: 13
Training loss: 0.7556391747646259
Validation loss: 2.521362709456474

Epoch: 478| Step: 0
Training loss: 2.2379823388569546
Validation loss: 2.490648845271744

Epoch: 6| Step: 1
Training loss: 1.4918731837747015
Validation loss: 2.487486538928155

Epoch: 6| Step: 2
Training loss: 1.2192857493982319
Validation loss: 2.5322124373761126

Epoch: 6| Step: 3
Training loss: 1.4178389392630002
Validation loss: 2.4753985783307804

Epoch: 6| Step: 4
Training loss: 2.0529671200415462
Validation loss: 2.50072150124962

Epoch: 6| Step: 5
Training loss: 1.4667250289286808
Validation loss: 2.457532645580058

Epoch: 6| Step: 6
Training loss: 1.5721343749807826
Validation loss: 2.493798018585413

Epoch: 6| Step: 7
Training loss: 1.7064885514168981
Validation loss: 2.4577299576491254

Epoch: 6| Step: 8
Training loss: 1.5997503681948477
Validation loss: 2.5009002684801085

Epoch: 6| Step: 9
Training loss: 1.4162577244547112
Validation loss: 2.4682975485278735

Epoch: 6| Step: 10
Training loss: 1.0819247086607142
Validation loss: 2.476628053801091

Epoch: 6| Step: 11
Training loss: 1.8219951661984821
Validation loss: 2.467618122811143

Epoch: 6| Step: 12
Training loss: 1.3996876930258828
Validation loss: 2.4653747807187334

Epoch: 6| Step: 13
Training loss: 1.263042216431292
Validation loss: 2.4940234846623204

Epoch: 479| Step: 0
Training loss: 1.3906045547868324
Validation loss: 2.5410843707834547

Epoch: 6| Step: 1
Training loss: 1.688794240195582
Validation loss: 2.4489245062577925

Epoch: 6| Step: 2
Training loss: 1.196268534581527
Validation loss: 2.4612333303200025

Epoch: 6| Step: 3
Training loss: 1.3534593006211177
Validation loss: 2.483717864701921

Epoch: 6| Step: 4
Training loss: 1.3992388256854302
Validation loss: 2.445494013566599

Epoch: 6| Step: 5
Training loss: 2.299291779488924
Validation loss: 2.5028040767676445

Epoch: 6| Step: 6
Training loss: 1.6455055666944987
Validation loss: 2.421704963592593

Epoch: 6| Step: 7
Training loss: 2.0183457338858872
Validation loss: 2.4595935772613573

Epoch: 6| Step: 8
Training loss: 1.415877973508773
Validation loss: 2.4897402775982727

Epoch: 6| Step: 9
Training loss: 1.5050645207360278
Validation loss: 2.4901063499862617

Epoch: 6| Step: 10
Training loss: 1.614480521917764
Validation loss: 2.4609009484309388

Epoch: 6| Step: 11
Training loss: 1.336514264802341
Validation loss: 2.5038726867358325

Epoch: 6| Step: 12
Training loss: 1.4697255080716733
Validation loss: 2.503825814543099

Epoch: 6| Step: 13
Training loss: 1.922721800293176
Validation loss: 2.471854595706155

Epoch: 480| Step: 0
Training loss: 1.2646345336621065
Validation loss: 2.4603351752451807

Epoch: 6| Step: 1
Training loss: 1.9638614208681187
Validation loss: 2.5099592252059524

Epoch: 6| Step: 2
Training loss: 1.4250360919330316
Validation loss: 2.460784785488193

Epoch: 6| Step: 3
Training loss: 1.270828476359774
Validation loss: 2.5109785425818414

Epoch: 6| Step: 4
Training loss: 1.6274317372856337
Validation loss: 2.561133708015862

Epoch: 6| Step: 5
Training loss: 1.5037645149323178
Validation loss: 2.512098223460743

Epoch: 6| Step: 6
Training loss: 2.413257254706298
Validation loss: 2.479848174120362

Epoch: 6| Step: 7
Training loss: 1.6666674931842027
Validation loss: 2.4740589940436917

Epoch: 6| Step: 8
Training loss: 1.3927831298251225
Validation loss: 2.513433654702004

Epoch: 6| Step: 9
Training loss: 1.0574683932728184
Validation loss: 2.509112375711832

Epoch: 6| Step: 10
Training loss: 1.8914188578396975
Validation loss: 2.473332060648923

Epoch: 6| Step: 11
Training loss: 1.6879315707451858
Validation loss: 2.472551846564435

Epoch: 6| Step: 12
Training loss: 1.4543142067170804
Validation loss: 2.5558781336282785

Epoch: 6| Step: 13
Training loss: 1.059922120364269
Validation loss: 2.514446327122937

Epoch: 481| Step: 0
Training loss: 1.4666622826481812
Validation loss: 2.4984107708773706

Epoch: 6| Step: 1
Training loss: 1.8059591461748485
Validation loss: 2.4906949587979845

Epoch: 6| Step: 2
Training loss: 1.7120547196030387
Validation loss: 2.5212054827526527

Epoch: 6| Step: 3
Training loss: 1.5845712122661302
Validation loss: 2.4772971208111985

Epoch: 6| Step: 4
Training loss: 2.0497733991105984
Validation loss: 2.4728261823175823

Epoch: 6| Step: 5
Training loss: 1.712809614051374
Validation loss: 2.4543198595899587

Epoch: 6| Step: 6
Training loss: 1.153311475030308
Validation loss: 2.4857039650321693

Epoch: 6| Step: 7
Training loss: 1.3059577012536372
Validation loss: 2.5036614636424637

Epoch: 6| Step: 8
Training loss: 1.8772940906524107
Validation loss: 2.487946306296643

Epoch: 6| Step: 9
Training loss: 1.5565490312803465
Validation loss: 2.4231354555131177

Epoch: 6| Step: 10
Training loss: 1.529788662893962
Validation loss: 2.4939384634521313

Epoch: 6| Step: 11
Training loss: 1.119797385740831
Validation loss: 2.466072420747837

Epoch: 6| Step: 12
Training loss: 2.0392018705363206
Validation loss: 2.4689690038578904

Epoch: 6| Step: 13
Training loss: 1.4192369742831403
Validation loss: 2.4670051149897136

Epoch: 482| Step: 0
Training loss: 1.5762411525396336
Validation loss: 2.5385630510314763

Epoch: 6| Step: 1
Training loss: 2.0555615324786927
Validation loss: 2.5039412185499867

Epoch: 6| Step: 2
Training loss: 1.6505583367541314
Validation loss: 2.520812709204982

Epoch: 6| Step: 3
Training loss: 1.3411574526780368
Validation loss: 2.4944555204406105

Epoch: 6| Step: 4
Training loss: 1.7739702676433977
Validation loss: 2.460703990644353

Epoch: 6| Step: 5
Training loss: 1.249126796904735
Validation loss: 2.5062500260225504

Epoch: 6| Step: 6
Training loss: 1.1711752264526938
Validation loss: 2.536501396908411

Epoch: 6| Step: 7
Training loss: 1.9332783759735581
Validation loss: 2.5011969479962652

Epoch: 6| Step: 8
Training loss: 1.3017713656224323
Validation loss: 2.4697529936171896

Epoch: 6| Step: 9
Training loss: 1.557230494221645
Validation loss: 2.5081892374916155

Epoch: 6| Step: 10
Training loss: 1.6364423932764793
Validation loss: 2.48675453285265

Epoch: 6| Step: 11
Training loss: 2.3252394029970334
Validation loss: 2.419830414028394

Epoch: 6| Step: 12
Training loss: 1.3141478684281687
Validation loss: 2.492053056294167

Epoch: 6| Step: 13
Training loss: 1.3675446833924034
Validation loss: 2.451823763955877

Epoch: 483| Step: 0
Training loss: 1.6264247517152286
Validation loss: 2.5221032012312325

Epoch: 6| Step: 1
Training loss: 1.5672757976755765
Validation loss: 2.466997478108835

Epoch: 6| Step: 2
Training loss: 1.6732670345445262
Validation loss: 2.5105178629475997

Epoch: 6| Step: 3
Training loss: 2.264692022340938
Validation loss: 2.500251484599267

Epoch: 6| Step: 4
Training loss: 1.0327538593398349
Validation loss: 2.4573171732158627

Epoch: 6| Step: 5
Training loss: 1.0877623559473146
Validation loss: 2.480499653409338

Epoch: 6| Step: 6
Training loss: 1.7568563615969899
Validation loss: 2.5323991393961323

Epoch: 6| Step: 7
Training loss: 0.9642484735937205
Validation loss: 2.460411335080253

Epoch: 6| Step: 8
Training loss: 2.215753385324097
Validation loss: 2.4692083296507623

Epoch: 6| Step: 9
Training loss: 1.2199062828902203
Validation loss: 2.466619185464911

Epoch: 6| Step: 10
Training loss: 1.5194210218444804
Validation loss: 2.4798864783044783

Epoch: 6| Step: 11
Training loss: 1.3251889256075364
Validation loss: 2.4030271995775223

Epoch: 6| Step: 12
Training loss: 1.45398317653153
Validation loss: 2.50456624943086

Epoch: 6| Step: 13
Training loss: 1.6862176331848813
Validation loss: 2.495516774914745

Epoch: 484| Step: 0
Training loss: 1.753068277729951
Validation loss: 2.5585580434580115

Epoch: 6| Step: 1
Training loss: 1.3539252383864597
Validation loss: 2.506894701918128

Epoch: 6| Step: 2
Training loss: 1.7231030911840128
Validation loss: 2.52943041346744

Epoch: 6| Step: 3
Training loss: 1.3261419413675803
Validation loss: 2.454855691977365

Epoch: 6| Step: 4
Training loss: 1.5532327104211294
Validation loss: 2.4828645656717803

Epoch: 6| Step: 5
Training loss: 1.711211160869681
Validation loss: 2.4852546717975215

Epoch: 6| Step: 6
Training loss: 1.6068456829160835
Validation loss: 2.5377046453763796

Epoch: 6| Step: 7
Training loss: 1.6859701780982863
Validation loss: 2.5107755649977466

Epoch: 6| Step: 8
Training loss: 1.5624322495077212
Validation loss: 2.5151056369968

Epoch: 6| Step: 9
Training loss: 1.8882092892654563
Validation loss: 2.451957596773274

Epoch: 6| Step: 10
Training loss: 1.2004159425051164
Validation loss: 2.4365806276132753

Epoch: 6| Step: 11
Training loss: 1.289158256904446
Validation loss: 2.550778827849192

Epoch: 6| Step: 12
Training loss: 2.315589490610518
Validation loss: 2.485412857612079

Epoch: 6| Step: 13
Training loss: 1.4703144912625166
Validation loss: 2.538147506488228

Epoch: 485| Step: 0
Training loss: 1.8126957228645424
Validation loss: 2.520571081204614

Epoch: 6| Step: 1
Training loss: 1.739630152211252
Validation loss: 2.5061425773858215

Epoch: 6| Step: 2
Training loss: 2.00553141051341
Validation loss: 2.4945356784152537

Epoch: 6| Step: 3
Training loss: 1.034334597994242
Validation loss: 2.391736112778821

Epoch: 6| Step: 4
Training loss: 1.145112446673172
Validation loss: 2.485929359284569

Epoch: 6| Step: 5
Training loss: 1.8782619077319502
Validation loss: 2.5204716742248814

Epoch: 6| Step: 6
Training loss: 1.696166355260597
Validation loss: 2.4945206667191844

Epoch: 6| Step: 7
Training loss: 1.4129123119728495
Validation loss: 2.51588231241241

Epoch: 6| Step: 8
Training loss: 1.0401372872117263
Validation loss: 2.5121962177795645

Epoch: 6| Step: 9
Training loss: 1.6917781288871723
Validation loss: 2.4793007982312822

Epoch: 6| Step: 10
Training loss: 1.3097508111941394
Validation loss: 2.5145482427808856

Epoch: 6| Step: 11
Training loss: 1.3286951075615625
Validation loss: 2.5114310081636386

Epoch: 6| Step: 12
Training loss: 2.2750818133053294
Validation loss: 2.45984678146813

Epoch: 6| Step: 13
Training loss: 1.1658919123415463
Validation loss: 2.4752267449638894

Epoch: 486| Step: 0
Training loss: 1.3186853076560956
Validation loss: 2.456107003462045

Epoch: 6| Step: 1
Training loss: 2.0829368468338036
Validation loss: 2.452082413269763

Epoch: 6| Step: 2
Training loss: 1.1761292611076464
Validation loss: 2.5108449600605245

Epoch: 6| Step: 3
Training loss: 1.6897880442727902
Validation loss: 2.486341630246355

Epoch: 6| Step: 4
Training loss: 1.2319898618955991
Validation loss: 2.4897966541063696

Epoch: 6| Step: 5
Training loss: 1.8022894181031095
Validation loss: 2.526730789216491

Epoch: 6| Step: 6
Training loss: 1.1846724526695704
Validation loss: 2.4422559950139076

Epoch: 6| Step: 7
Training loss: 2.2619348399712753
Validation loss: 2.5023532897177883

Epoch: 6| Step: 8
Training loss: 1.2443447454617094
Validation loss: 2.460791489449106

Epoch: 6| Step: 9
Training loss: 1.7473898905062257
Validation loss: 2.4920121527702235

Epoch: 6| Step: 10
Training loss: 1.7832051973863574
Validation loss: 2.5163676855300086

Epoch: 6| Step: 11
Training loss: 1.6977592426487171
Validation loss: 2.4572772277202777

Epoch: 6| Step: 12
Training loss: 1.3721788682451115
Validation loss: 2.4547062773990342

Epoch: 6| Step: 13
Training loss: 1.349960436064635
Validation loss: 2.521720337281906

Epoch: 487| Step: 0
Training loss: 1.5264043626511006
Validation loss: 2.5088200901794733

Epoch: 6| Step: 1
Training loss: 1.6574792438893315
Validation loss: 2.427310450440561

Epoch: 6| Step: 2
Training loss: 1.4337421724992114
Validation loss: 2.454569838185816

Epoch: 6| Step: 3
Training loss: 1.39007437445268
Validation loss: 2.4306122325455504

Epoch: 6| Step: 4
Training loss: 1.2661093267871142
Validation loss: 2.4713511286344856

Epoch: 6| Step: 5
Training loss: 1.4717478897704257
Validation loss: 2.4882712459055627

Epoch: 6| Step: 6
Training loss: 2.1006247544792145
Validation loss: 2.4643410040162053

Epoch: 6| Step: 7
Training loss: 1.5423247333289867
Validation loss: 2.497066656563305

Epoch: 6| Step: 8
Training loss: 0.9179211218632443
Validation loss: 2.5053002633521064

Epoch: 6| Step: 9
Training loss: 1.5970356302413087
Validation loss: 2.516886928671288

Epoch: 6| Step: 10
Training loss: 1.93974604704334
Validation loss: 2.502405660170375

Epoch: 6| Step: 11
Training loss: 1.9081134130811448
Validation loss: 2.444926746005087

Epoch: 6| Step: 12
Training loss: 1.3040240308296709
Validation loss: 2.494536156296886

Epoch: 6| Step: 13
Training loss: 1.132081578664832
Validation loss: 2.4976461373347423

Epoch: 488| Step: 0
Training loss: 1.3664958403210326
Validation loss: 2.480989511097813

Epoch: 6| Step: 1
Training loss: 1.4287302950670853
Validation loss: 2.478087262550085

Epoch: 6| Step: 2
Training loss: 2.1716141578413763
Validation loss: 2.5556948300462534

Epoch: 6| Step: 3
Training loss: 1.6603238368998037
Validation loss: 2.5161212647436213

Epoch: 6| Step: 4
Training loss: 1.6471882647051381
Validation loss: 2.4790854867735614

Epoch: 6| Step: 5
Training loss: 1.1893459328142997
Validation loss: 2.5594315293958774

Epoch: 6| Step: 6
Training loss: 1.3119326682316859
Validation loss: 2.5668571279512067

Epoch: 6| Step: 7
Training loss: 1.5948462362523255
Validation loss: 2.4495688698423024

Epoch: 6| Step: 8
Training loss: 1.9068112407016107
Validation loss: 2.481662824119745

Epoch: 6| Step: 9
Training loss: 1.7515321563896402
Validation loss: 2.4908260083237934

Epoch: 6| Step: 10
Training loss: 1.8588202795045012
Validation loss: 2.482533940913494

Epoch: 6| Step: 11
Training loss: 1.3701334576446202
Validation loss: 2.4686055346882108

Epoch: 6| Step: 12
Training loss: 1.3529516148652334
Validation loss: 2.451214767359894

Epoch: 6| Step: 13
Training loss: 1.2116639942068006
Validation loss: 2.4863748352294257

Epoch: 489| Step: 0
Training loss: 1.927071779233645
Validation loss: 2.478433344579974

Epoch: 6| Step: 1
Training loss: 1.5734375181832638
Validation loss: 2.47685086557784

Epoch: 6| Step: 2
Training loss: 1.7066968507382394
Validation loss: 2.4984510986698476

Epoch: 6| Step: 3
Training loss: 1.1403165426310675
Validation loss: 2.5062393858046073

Epoch: 6| Step: 4
Training loss: 0.6583673289329947
Validation loss: 2.471479403232994

Epoch: 6| Step: 5
Training loss: 1.586819257985429
Validation loss: 2.4784622398027736

Epoch: 6| Step: 6
Training loss: 1.7131333565186329
Validation loss: 2.492648644424304

Epoch: 6| Step: 7
Training loss: 1.8846109119224472
Validation loss: 2.528873309725497

Epoch: 6| Step: 8
Training loss: 1.5249058616223832
Validation loss: 2.4985012114735032

Epoch: 6| Step: 9
Training loss: 1.2725855311819256
Validation loss: 2.504891260102426

Epoch: 6| Step: 10
Training loss: 2.2216491026397507
Validation loss: 2.4770152586893386

Epoch: 6| Step: 11
Training loss: 1.8028072454039035
Validation loss: 2.544958118379626

Epoch: 6| Step: 12
Training loss: 1.3302767657085852
Validation loss: 2.442829849981724

Epoch: 6| Step: 13
Training loss: 0.9941556438518182
Validation loss: 2.5037326173742764

Epoch: 490| Step: 0
Training loss: 1.640157433140813
Validation loss: 2.557170381763629

Epoch: 6| Step: 1
Training loss: 1.634040261411106
Validation loss: 2.4415952626556376

Epoch: 6| Step: 2
Training loss: 1.494600432211008
Validation loss: 2.521001783895662

Epoch: 6| Step: 3
Training loss: 1.3421666331328892
Validation loss: 2.5335970810794084

Epoch: 6| Step: 4
Training loss: 2.041076600838568
Validation loss: 2.535278715781409

Epoch: 6| Step: 5
Training loss: 1.6862004539048439
Validation loss: 2.479969126075509

Epoch: 6| Step: 6
Training loss: 1.2198399780418387
Validation loss: 2.4790427891456224

Epoch: 6| Step: 7
Training loss: 1.2915376885940881
Validation loss: 2.5067694514517114

Epoch: 6| Step: 8
Training loss: 1.2687349609836678
Validation loss: 2.4652191578802674

Epoch: 6| Step: 9
Training loss: 1.3132758799119182
Validation loss: 2.46848008723575

Epoch: 6| Step: 10
Training loss: 1.9719155308930383
Validation loss: 2.4431419181032816

Epoch: 6| Step: 11
Training loss: 1.8685914192405269
Validation loss: 2.4732505873185158

Epoch: 6| Step: 12
Training loss: 1.2711398218922385
Validation loss: 2.501420980051629

Epoch: 6| Step: 13
Training loss: 1.9298652845022382
Validation loss: 2.4767763084277883

Epoch: 491| Step: 0
Training loss: 1.3168209339660983
Validation loss: 2.437589879846513

Epoch: 6| Step: 1
Training loss: 1.493857841908344
Validation loss: 2.495041283542478

Epoch: 6| Step: 2
Training loss: 1.5167849319934865
Validation loss: 2.494212564255811

Epoch: 6| Step: 3
Training loss: 1.454402567065736
Validation loss: 2.471724054619315

Epoch: 6| Step: 4
Training loss: 1.4404365565249353
Validation loss: 2.5683244475509315

Epoch: 6| Step: 5
Training loss: 1.5703632099826745
Validation loss: 2.4621513866592317

Epoch: 6| Step: 6
Training loss: 1.46599433979019
Validation loss: 2.440783564744703

Epoch: 6| Step: 7
Training loss: 1.7827611168587127
Validation loss: 2.4696137098759814

Epoch: 6| Step: 8
Training loss: 1.5659283981713412
Validation loss: 2.5022266956882278

Epoch: 6| Step: 9
Training loss: 1.552788192488142
Validation loss: 2.4739757032491654

Epoch: 6| Step: 10
Training loss: 1.4080436288186309
Validation loss: 2.4812028946489812

Epoch: 6| Step: 11
Training loss: 1.3044967968844021
Validation loss: 2.5261167653148373

Epoch: 6| Step: 12
Training loss: 1.3633292553163705
Validation loss: 2.4899516494600946

Epoch: 6| Step: 13
Training loss: 2.6570862295266475
Validation loss: 2.5689228000238975

Epoch: 492| Step: 0
Training loss: 1.1142789419111616
Validation loss: 2.523751523295861

Epoch: 6| Step: 1
Training loss: 1.79197602225764
Validation loss: 2.5137828577998715

Epoch: 6| Step: 2
Training loss: 1.1285777422485201
Validation loss: 2.490487143202463

Epoch: 6| Step: 3
Training loss: 1.171848093359727
Validation loss: 2.546102487549428

Epoch: 6| Step: 4
Training loss: 1.843577490026106
Validation loss: 2.481012117833569

Epoch: 6| Step: 5
Training loss: 0.9917885887037229
Validation loss: 2.475573419507438

Epoch: 6| Step: 6
Training loss: 1.1864217581175616
Validation loss: 2.4721748793149505

Epoch: 6| Step: 7
Training loss: 2.1235320687024863
Validation loss: 2.5378346442606894

Epoch: 6| Step: 8
Training loss: 2.031037539594887
Validation loss: 2.499335497045487

Epoch: 6| Step: 9
Training loss: 1.8216970523674478
Validation loss: 2.4737306973057325

Epoch: 6| Step: 10
Training loss: 1.385350113419824
Validation loss: 2.486785660203528

Epoch: 6| Step: 11
Training loss: 1.4599431371720046
Validation loss: 2.449652264201712

Epoch: 6| Step: 12
Training loss: 1.6123693812495903
Validation loss: 2.52819050682805

Epoch: 6| Step: 13
Training loss: 1.7768492293661062
Validation loss: 2.4994566932074083

Epoch: 493| Step: 0
Training loss: 0.7394186875374356
Validation loss: 2.4647989116393387

Epoch: 6| Step: 1
Training loss: 1.3830835971073927
Validation loss: 2.50417992928555

Epoch: 6| Step: 2
Training loss: 1.4142257006133747
Validation loss: 2.494226062271189

Epoch: 6| Step: 3
Training loss: 2.0903060829496383
Validation loss: 2.450355428915071

Epoch: 6| Step: 4
Training loss: 1.4000136374763028
Validation loss: 2.451232883772857

Epoch: 6| Step: 5
Training loss: 1.4024989645235044
Validation loss: 2.502550307118534

Epoch: 6| Step: 6
Training loss: 1.9397407003524676
Validation loss: 2.5007515116148746

Epoch: 6| Step: 7
Training loss: 1.1459444974670563
Validation loss: 2.5131328928643613

Epoch: 6| Step: 8
Training loss: 2.1244506125757403
Validation loss: 2.4601448414135327

Epoch: 6| Step: 9
Training loss: 1.5649488713745505
Validation loss: 2.4747909068937792

Epoch: 6| Step: 10
Training loss: 1.5102873735885243
Validation loss: 2.5695641563381537

Epoch: 6| Step: 11
Training loss: 1.5581554284091208
Validation loss: 2.5305821185707997

Epoch: 6| Step: 12
Training loss: 1.4556246352041728
Validation loss: 2.52073761661585

Epoch: 6| Step: 13
Training loss: 1.6179597641618457
Validation loss: 2.4453183133144236

Epoch: 494| Step: 0
Training loss: 2.4900937268798216
Validation loss: 2.4793185801680044

Epoch: 6| Step: 1
Training loss: 1.8070524498948952
Validation loss: 2.50266836977657

Epoch: 6| Step: 2
Training loss: 1.2032396831597227
Validation loss: 2.483768457456985

Epoch: 6| Step: 3
Training loss: 1.3198247606824636
Validation loss: 2.457702821437878

Epoch: 6| Step: 4
Training loss: 1.473470043094025
Validation loss: 2.4994352769348467

Epoch: 6| Step: 5
Training loss: 1.221044581150043
Validation loss: 2.515194666971719

Epoch: 6| Step: 6
Training loss: 1.266301339361764
Validation loss: 2.4564512646130106

Epoch: 6| Step: 7
Training loss: 1.8055196057514662
Validation loss: 2.4663263493017573

Epoch: 6| Step: 8
Training loss: 1.4079336048667905
Validation loss: 2.460749507871895

Epoch: 6| Step: 9
Training loss: 1.5303204887669262
Validation loss: 2.536815017781615

Epoch: 6| Step: 10
Training loss: 1.4245533293318124
Validation loss: 2.478733686397049

Epoch: 6| Step: 11
Training loss: 1.8315563114974869
Validation loss: 2.494129445911797

Epoch: 6| Step: 12
Training loss: 1.8204718917021991
Validation loss: 2.4926865004487317

Epoch: 6| Step: 13
Training loss: 1.284373778553774
Validation loss: 2.4736960888108914

Epoch: 495| Step: 0
Training loss: 2.26890095610507
Validation loss: 2.440971939276021

Epoch: 6| Step: 1
Training loss: 1.6493459069742349
Validation loss: 2.5019655130572507

Epoch: 6| Step: 2
Training loss: 1.4269252420369838
Validation loss: 2.5182694146228353

Epoch: 6| Step: 3
Training loss: 1.5562586680710926
Validation loss: 2.510410975846056

Epoch: 6| Step: 4
Training loss: 1.1504917586063335
Validation loss: 2.467591186765846

Epoch: 6| Step: 5
Training loss: 1.587911645578884
Validation loss: 2.5103047817049666

Epoch: 6| Step: 6
Training loss: 1.9398639163237663
Validation loss: 2.5029258362946494

Epoch: 6| Step: 7
Training loss: 1.4513361595265304
Validation loss: 2.5310620281551603

Epoch: 6| Step: 8
Training loss: 1.94610058857173
Validation loss: 2.5708094604945253

Epoch: 6| Step: 9
Training loss: 1.2173805367766612
Validation loss: 2.5298813006313843

Epoch: 6| Step: 10
Training loss: 1.4635464633125448
Validation loss: 2.4864261698956747

Epoch: 6| Step: 11
Training loss: 1.3746092848088027
Validation loss: 2.432286035478018

Epoch: 6| Step: 12
Training loss: 1.6236258345212737
Validation loss: 2.475383661853229

Epoch: 6| Step: 13
Training loss: 1.0484895355000743
Validation loss: 2.4911643951312374

Epoch: 496| Step: 0
Training loss: 1.1202064751289273
Validation loss: 2.4837918088820823

Epoch: 6| Step: 1
Training loss: 1.435436343135244
Validation loss: 2.4988565927063697

Epoch: 6| Step: 2
Training loss: 1.4626040821045077
Validation loss: 2.497118499832602

Epoch: 6| Step: 3
Training loss: 1.2731026987511191
Validation loss: 2.462732396815231

Epoch: 6| Step: 4
Training loss: 1.651703261744057
Validation loss: 2.4552995271585694

Epoch: 6| Step: 5
Training loss: 1.3854722128992931
Validation loss: 2.494703004357528

Epoch: 6| Step: 6
Training loss: 1.163783507228375
Validation loss: 2.4512987279937257

Epoch: 6| Step: 7
Training loss: 1.8134943109238513
Validation loss: 2.4664615893677126

Epoch: 6| Step: 8
Training loss: 1.386396988625291
Validation loss: 2.510639124821502

Epoch: 6| Step: 9
Training loss: 1.245264141909993
Validation loss: 2.4509422812771287

Epoch: 6| Step: 10
Training loss: 2.476785162413804
Validation loss: 2.477369474153526

Epoch: 6| Step: 11
Training loss: 1.6561660025547524
Validation loss: 2.485169022552542

Epoch: 6| Step: 12
Training loss: 1.3666958170007235
Validation loss: 2.456722602256976

Epoch: 6| Step: 13
Training loss: 1.8996234219451593
Validation loss: 2.435688192093912

Epoch: 497| Step: 0
Training loss: 1.4278641209963099
Validation loss: 2.5258679579613075

Epoch: 6| Step: 1
Training loss: 1.9562111847655548
Validation loss: 2.5147480216589466

Epoch: 6| Step: 2
Training loss: 1.2615277881018707
Validation loss: 2.4463073799211057

Epoch: 6| Step: 3
Training loss: 1.5123523892340045
Validation loss: 2.459255980441694

Epoch: 6| Step: 4
Training loss: 1.7640375073050332
Validation loss: 2.4442477405419942

Epoch: 6| Step: 5
Training loss: 1.6573616471811814
Validation loss: 2.5098883062152337

Epoch: 6| Step: 6
Training loss: 1.672291071091584
Validation loss: 2.4753274676727965

Epoch: 6| Step: 7
Training loss: 1.6227389524392615
Validation loss: 2.458013488363258

Epoch: 6| Step: 8
Training loss: 1.4260502809645639
Validation loss: 2.493642707149297

Epoch: 6| Step: 9
Training loss: 1.0411041966417558
Validation loss: 2.4542405744236566

Epoch: 6| Step: 10
Training loss: 1.3025275528056484
Validation loss: 2.476233441899501

Epoch: 6| Step: 11
Training loss: 1.6282623994514167
Validation loss: 2.492751306266647

Epoch: 6| Step: 12
Training loss: 1.8220246739355122
Validation loss: 2.445704893392365

Epoch: 6| Step: 13
Training loss: 1.534352798456677
Validation loss: 2.5150606407298914

Epoch: 498| Step: 0
Training loss: 1.5041441890202965
Validation loss: 2.5198580388220586

Epoch: 6| Step: 1
Training loss: 1.3756223483928827
Validation loss: 2.464107040017394

Epoch: 6| Step: 2
Training loss: 1.1652525380861327
Validation loss: 2.473427906178035

Epoch: 6| Step: 3
Training loss: 1.8017795137581987
Validation loss: 2.5369294617547005

Epoch: 6| Step: 4
Training loss: 1.6381643825717802
Validation loss: 2.482396465887374

Epoch: 6| Step: 5
Training loss: 1.3279290447410288
Validation loss: 2.4605594363489405

Epoch: 6| Step: 6
Training loss: 1.463443748302753
Validation loss: 2.493357679888587

Epoch: 6| Step: 7
Training loss: 1.9752152265300946
Validation loss: 2.5230827644778206

Epoch: 6| Step: 8
Training loss: 1.1593429334786671
Validation loss: 2.459390397004162

Epoch: 6| Step: 9
Training loss: 1.3594356830250331
Validation loss: 2.4882207117353237

Epoch: 6| Step: 10
Training loss: 1.4251922645029163
Validation loss: 2.4727840727828063

Epoch: 6| Step: 11
Training loss: 2.189098101373377
Validation loss: 2.4634228957637645

Epoch: 6| Step: 12
Training loss: 1.3632386646341645
Validation loss: 2.464891624528544

Epoch: 6| Step: 13
Training loss: 1.4350650731395067
Validation loss: 2.5079585186750686

Epoch: 499| Step: 0
Training loss: 1.741982212716004
Validation loss: 2.4666763138630907

Epoch: 6| Step: 1
Training loss: 1.0557306852676367
Validation loss: 2.523778693914666

Epoch: 6| Step: 2
Training loss: 1.3616691173234146
Validation loss: 2.444034229076262

Epoch: 6| Step: 3
Training loss: 1.729838788343537
Validation loss: 2.4837906776476664

Epoch: 6| Step: 4
Training loss: 1.707613010045788
Validation loss: 2.4623019684599603

Epoch: 6| Step: 5
Training loss: 1.6495685042083865
Validation loss: 2.5386154288573604

Epoch: 6| Step: 6
Training loss: 1.5049604411961897
Validation loss: 2.472914680760549

Epoch: 6| Step: 7
Training loss: 1.8136964992254052
Validation loss: 2.50585234146321

Epoch: 6| Step: 8
Training loss: 1.3497827973299839
Validation loss: 2.4434064387099177

Epoch: 6| Step: 9
Training loss: 2.244603573264295
Validation loss: 2.4830952291179145

Epoch: 6| Step: 10
Training loss: 1.4905236039773646
Validation loss: 2.476689232539993

Epoch: 6| Step: 11
Training loss: 1.2603713833999992
Validation loss: 2.521589220932492

Epoch: 6| Step: 12
Training loss: 1.2792411500864342
Validation loss: 2.485806655856421

Epoch: 6| Step: 13
Training loss: 1.2773791666982954
Validation loss: 2.5127440505721608

Epoch: 500| Step: 0
Training loss: 1.6922592584641591
Validation loss: 2.511840474417216

Epoch: 6| Step: 1
Training loss: 1.1453049684201437
Validation loss: 2.4436836173443552

Epoch: 6| Step: 2
Training loss: 1.5333743248864404
Validation loss: 2.4838671080947248

Epoch: 6| Step: 3
Training loss: 1.0506101561160912
Validation loss: 2.495044498569994

Epoch: 6| Step: 4
Training loss: 1.611650728240917
Validation loss: 2.475262040997471

Epoch: 6| Step: 5
Training loss: 1.0955375233452176
Validation loss: 2.503615273558913

Epoch: 6| Step: 6
Training loss: 1.6029524563445496
Validation loss: 2.5132282089692444

Epoch: 6| Step: 7
Training loss: 2.0107592618568404
Validation loss: 2.4930088591348225

Epoch: 6| Step: 8
Training loss: 1.7161946808303468
Validation loss: 2.5082374498691955

Epoch: 6| Step: 9
Training loss: 1.6772842602780875
Validation loss: 2.5029580745927955

Epoch: 6| Step: 10
Training loss: 1.3558287568455702
Validation loss: 2.536916764426816

Epoch: 6| Step: 11
Training loss: 1.0649722452084234
Validation loss: 2.44989446379645

Epoch: 6| Step: 12
Training loss: 1.4025337281820907
Validation loss: 2.4895020719359255

Epoch: 6| Step: 13
Training loss: 1.6828229161810582
Validation loss: 2.521343311484099

Testing loss: 2.4868614416569605
