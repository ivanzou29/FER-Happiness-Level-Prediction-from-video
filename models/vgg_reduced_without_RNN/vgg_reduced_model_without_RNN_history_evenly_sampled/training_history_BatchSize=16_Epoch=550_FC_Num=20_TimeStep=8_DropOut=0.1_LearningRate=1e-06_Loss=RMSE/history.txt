Epoch: 1| Step: 0
Training loss: 3.6345134731687962
Validation loss: 4.274944315947491

Epoch: 6| Step: 1
Training loss: 4.579831999650154
Validation loss: 4.26897282006929

Epoch: 6| Step: 2
Training loss: 4.695433959405528
Validation loss: 4.265497513974401

Epoch: 6| Step: 3
Training loss: 4.3417314189004355
Validation loss: 4.262569236415596

Epoch: 6| Step: 4
Training loss: 4.565328478991819
Validation loss: 4.260561690289341

Epoch: 6| Step: 5
Training loss: 3.865378216673573
Validation loss: 4.254471313030607

Epoch: 6| Step: 6
Training loss: 3.2325115640880373
Validation loss: 4.250622312284128

Epoch: 6| Step: 7
Training loss: 4.756358057466363
Validation loss: 4.249968693308462

Epoch: 6| Step: 8
Training loss: 5.272567202491132
Validation loss: 4.2464231559594685

Epoch: 6| Step: 9
Training loss: 4.085660206592133
Validation loss: 4.243076322375704

Epoch: 6| Step: 10
Training loss: 4.345880658241631
Validation loss: 4.238192702278988

Epoch: 6| Step: 11
Training loss: 4.8645451263081805
Validation loss: 4.2346894490633

Epoch: 6| Step: 12
Training loss: 4.339081375361245
Validation loss: 4.234834759655454

Epoch: 6| Step: 13
Training loss: 4.295033785206404
Validation loss: 4.233489487157806

Epoch: 2| Step: 0
Training loss: 4.074007608532999
Validation loss: 4.22743469850348

Epoch: 6| Step: 1
Training loss: 4.05715684907523
Validation loss: 4.2238971844411495

Epoch: 6| Step: 2
Training loss: 5.554879100730318
Validation loss: 4.219695243843866

Epoch: 6| Step: 3
Training loss: 4.625426813999971
Validation loss: 4.2153116048816415

Epoch: 6| Step: 4
Training loss: 3.821284320690899
Validation loss: 4.21569526702771

Epoch: 6| Step: 5
Training loss: 4.084842921847423
Validation loss: 4.21206803342828

Epoch: 6| Step: 6
Training loss: 3.036167364209155
Validation loss: 4.210029600520338

Epoch: 6| Step: 7
Training loss: 4.1080542933247965
Validation loss: 4.207100132674695

Epoch: 6| Step: 8
Training loss: 5.349026757248075
Validation loss: 4.2006808776477085

Epoch: 6| Step: 9
Training loss: 4.096700755123123
Validation loss: 4.198037670999906

Epoch: 6| Step: 10
Training loss: 4.671145787310496
Validation loss: 4.195372047382872

Epoch: 6| Step: 11
Training loss: 4.7427523683475
Validation loss: 4.192437785958388

Epoch: 6| Step: 12
Training loss: 3.7553520157512574
Validation loss: 4.190213963002546

Epoch: 6| Step: 13
Training loss: 4.013921829199933
Validation loss: 4.184325627434816

Epoch: 3| Step: 0
Training loss: 4.108254863822721
Validation loss: 4.183745350093085

Epoch: 6| Step: 1
Training loss: 4.361625500665622
Validation loss: 4.180063007282394

Epoch: 6| Step: 2
Training loss: 5.27033473535185
Validation loss: 4.178717019738074

Epoch: 6| Step: 3
Training loss: 3.1211282778323244
Validation loss: 4.175165569561015

Epoch: 6| Step: 4
Training loss: 4.526059459772754
Validation loss: 4.170494584622183

Epoch: 6| Step: 5
Training loss: 3.7211885551118358
Validation loss: 4.166866284582717

Epoch: 6| Step: 6
Training loss: 4.363090654409297
Validation loss: 4.16374549027652

Epoch: 6| Step: 7
Training loss: 4.189054741402271
Validation loss: 4.1581628952462015

Epoch: 6| Step: 8
Training loss: 4.854050052317177
Validation loss: 4.161771669344755

Epoch: 6| Step: 9
Training loss: 4.244372063552769
Validation loss: 4.1569093324200175

Epoch: 6| Step: 10
Training loss: 3.8271131774259235
Validation loss: 4.149998368066357

Epoch: 6| Step: 11
Training loss: 4.472556033948221
Validation loss: 4.149064610676461

Epoch: 6| Step: 12
Training loss: 4.265777920507565
Validation loss: 4.144435207573252

Epoch: 6| Step: 13
Training loss: 4.536190312640138
Validation loss: 4.142603002755105

Epoch: 4| Step: 0
Training loss: 4.230513610320204
Validation loss: 4.1349992447125885

Epoch: 6| Step: 1
Training loss: 3.7837891683577
Validation loss: 4.135318642838988

Epoch: 6| Step: 2
Training loss: 4.598672111247722
Validation loss: 4.134368073360417

Epoch: 6| Step: 3
Training loss: 4.50418997778258
Validation loss: 4.129963794011148

Epoch: 6| Step: 4
Training loss: 3.616092128795331
Validation loss: 4.124616546060727

Epoch: 6| Step: 5
Training loss: 4.068172543942801
Validation loss: 4.123387280946374

Epoch: 6| Step: 6
Training loss: 4.738292722381515
Validation loss: 4.119165007000383

Epoch: 6| Step: 7
Training loss: 3.90653661057911
Validation loss: 4.1199883263845996

Epoch: 6| Step: 8
Training loss: 4.802556652427983
Validation loss: 4.114217432195557

Epoch: 6| Step: 9
Training loss: 4.867430067064515
Validation loss: 4.107706991055698

Epoch: 6| Step: 10
Training loss: 4.05048954206717
Validation loss: 4.107993005941616

Epoch: 6| Step: 11
Training loss: 4.007409147968751
Validation loss: 4.105927675404358

Epoch: 6| Step: 12
Training loss: 4.774335261705247
Validation loss: 4.100494185007215

Epoch: 6| Step: 13
Training loss: 2.3524584916736804
Validation loss: 4.097932451409837

Epoch: 5| Step: 0
Training loss: 4.641371130766289
Validation loss: 4.092248034433085

Epoch: 6| Step: 1
Training loss: 3.764177226103224
Validation loss: 4.090413604939316

Epoch: 6| Step: 2
Training loss: 4.79017653583945
Validation loss: 4.091229448508204

Epoch: 6| Step: 3
Training loss: 4.874381392917777
Validation loss: 4.085074482753855

Epoch: 6| Step: 4
Training loss: 3.6860956653717576
Validation loss: 4.079325620123939

Epoch: 6| Step: 5
Training loss: 3.02721080857297
Validation loss: 4.078834143574738

Epoch: 6| Step: 6
Training loss: 5.214523705651998
Validation loss: 4.074271698514466

Epoch: 6| Step: 7
Training loss: 4.005582252116014
Validation loss: 4.070520657651903

Epoch: 6| Step: 8
Training loss: 4.455423397747765
Validation loss: 4.06836895565469

Epoch: 6| Step: 9
Training loss: 3.405156931348659
Validation loss: 4.063673293292004

Epoch: 6| Step: 10
Training loss: 3.7432285206751144
Validation loss: 4.059256104925071

Epoch: 6| Step: 11
Training loss: 4.074719406483979
Validation loss: 4.055175301734033

Epoch: 6| Step: 12
Training loss: 4.801229383071297
Validation loss: 4.052352456418304

Epoch: 6| Step: 13
Training loss: 3.6661048516545724
Validation loss: 4.050062131892533

Epoch: 6| Step: 0
Training loss: 4.600878523816725
Validation loss: 4.04652481885749

Epoch: 6| Step: 1
Training loss: 3.802972113138689
Validation loss: 4.041702136302838

Epoch: 6| Step: 2
Training loss: 5.049207024587964
Validation loss: 4.040812395851402

Epoch: 6| Step: 3
Training loss: 4.184980630955145
Validation loss: 4.032855695428385

Epoch: 6| Step: 4
Training loss: 4.632968121595772
Validation loss: 4.029818512890545

Epoch: 6| Step: 5
Training loss: 4.1236842976007875
Validation loss: 4.02570907674448

Epoch: 6| Step: 6
Training loss: 4.257306718095768
Validation loss: 4.023351499341452

Epoch: 6| Step: 7
Training loss: 4.817295608025073
Validation loss: 4.0181471744153185

Epoch: 6| Step: 8
Training loss: 4.120105961298109
Validation loss: 4.013310840036583

Epoch: 6| Step: 9
Training loss: 3.382017962948894
Validation loss: 4.007548587725024

Epoch: 6| Step: 10
Training loss: 4.278552019697074
Validation loss: 4.0088366656902945

Epoch: 6| Step: 11
Training loss: 3.282267676075812
Validation loss: 3.998429407929371

Epoch: 6| Step: 12
Training loss: 3.4351046452692233
Validation loss: 3.9956221465362094

Epoch: 6| Step: 13
Training loss: 3.752370085376627
Validation loss: 3.9926572772559616

Epoch: 7| Step: 0
Training loss: 3.446154294793393
Validation loss: 3.9933832416424937

Epoch: 6| Step: 1
Training loss: 2.933955062376456
Validation loss: 3.9845481106275433

Epoch: 6| Step: 2
Training loss: 3.940851389880621
Validation loss: 3.9824930886438965

Epoch: 6| Step: 3
Training loss: 3.763068126482477
Validation loss: 3.976918305233789

Epoch: 6| Step: 4
Training loss: 4.553748529660671
Validation loss: 3.9749705533276942

Epoch: 6| Step: 5
Training loss: 4.0108300462512885
Validation loss: 3.9708485899582437

Epoch: 6| Step: 6
Training loss: 4.2088273516968595
Validation loss: 3.9710101867641474

Epoch: 6| Step: 7
Training loss: 4.005964124361803
Validation loss: 3.965238884048699

Epoch: 6| Step: 8
Training loss: 5.020943077228184
Validation loss: 3.9566193441060213

Epoch: 6| Step: 9
Training loss: 4.248412789556678
Validation loss: 3.9554843660634096

Epoch: 6| Step: 10
Training loss: 4.345937274239698
Validation loss: 3.9512981535553893

Epoch: 6| Step: 11
Training loss: 4.84338692565658
Validation loss: 3.943414500542453

Epoch: 6| Step: 12
Training loss: 3.331002437704037
Validation loss: 3.9378273615103496

Epoch: 6| Step: 13
Training loss: 4.514374767790927
Validation loss: 3.9316482540203492

Epoch: 8| Step: 0
Training loss: 3.7456571227067474
Validation loss: 3.9311921534338596

Epoch: 6| Step: 1
Training loss: 4.670950603572642
Validation loss: 3.9240668316230853

Epoch: 6| Step: 2
Training loss: 4.157857713019861
Validation loss: 3.9161179541523228

Epoch: 6| Step: 3
Training loss: 4.229134896195065
Validation loss: 3.91340898034165

Epoch: 6| Step: 4
Training loss: 3.9366372995037575
Validation loss: 3.908392171882345

Epoch: 6| Step: 5
Training loss: 4.231872269417295
Validation loss: 3.9019125048798537

Epoch: 6| Step: 6
Training loss: 4.6254925852155235
Validation loss: 3.89559153530909

Epoch: 6| Step: 7
Training loss: 4.382794222054133
Validation loss: 3.8953195263458764

Epoch: 6| Step: 8
Training loss: 3.7590680156378395
Validation loss: 3.8854724805575707

Epoch: 6| Step: 9
Training loss: 3.098185740528237
Validation loss: 3.8783720774481805

Epoch: 6| Step: 10
Training loss: 3.2233246820985295
Validation loss: 3.8730880712525773

Epoch: 6| Step: 11
Training loss: 4.1035488586677795
Validation loss: 3.864585669272222

Epoch: 6| Step: 12
Training loss: 4.20772167834472
Validation loss: 3.862308674036267

Epoch: 6| Step: 13
Training loss: 3.930096523468203
Validation loss: 3.8561642158308405

Epoch: 9| Step: 0
Training loss: 4.752484123769346
Validation loss: 3.8484661983192208

Epoch: 6| Step: 1
Training loss: 3.3313475574858726
Validation loss: 3.8453038934181136

Epoch: 6| Step: 2
Training loss: 4.85620052749394
Validation loss: 3.8405473881207444

Epoch: 6| Step: 3
Training loss: 4.027443441494675
Validation loss: 3.830791351948416

Epoch: 6| Step: 4
Training loss: 3.6173860235917257
Validation loss: 3.8291795267190007

Epoch: 6| Step: 5
Training loss: 4.412636531630304
Validation loss: 3.8191720485909557

Epoch: 6| Step: 6
Training loss: 4.087660358794785
Validation loss: 3.8113226616762566

Epoch: 6| Step: 7
Training loss: 3.5097225570795962
Validation loss: 3.806771153820037

Epoch: 6| Step: 8
Training loss: 3.8332284968317945
Validation loss: 3.8017085496522234

Epoch: 6| Step: 9
Training loss: 3.1737213022888526
Validation loss: 3.7968454188056215

Epoch: 6| Step: 10
Training loss: 4.325292658964635
Validation loss: 3.7883157149588684

Epoch: 6| Step: 11
Training loss: 3.8872012351675322
Validation loss: 3.7800275907612577

Epoch: 6| Step: 12
Training loss: 3.9926909187163364
Validation loss: 3.77442673256517

Epoch: 6| Step: 13
Training loss: 2.687410220043806
Validation loss: 3.7684515841295867

Epoch: 10| Step: 0
Training loss: 4.142373691030612
Validation loss: 3.7595298843406777

Epoch: 6| Step: 1
Training loss: 3.8111199554647195
Validation loss: 3.752894410486318

Epoch: 6| Step: 2
Training loss: 3.017390707670993
Validation loss: 3.7439154070209515

Epoch: 6| Step: 3
Training loss: 3.481701565122177
Validation loss: 3.741399392543981

Epoch: 6| Step: 4
Training loss: 3.6891192744085934
Validation loss: 3.734690440705414

Epoch: 6| Step: 5
Training loss: 4.555940903800322
Validation loss: 3.723355999483753

Epoch: 6| Step: 6
Training loss: 3.446442779805383
Validation loss: 3.7180868267369105

Epoch: 6| Step: 7
Training loss: 4.731557479804338
Validation loss: 3.7058195272423746

Epoch: 6| Step: 8
Training loss: 3.3962077927028878
Validation loss: 3.6991852131187346

Epoch: 6| Step: 9
Training loss: 2.8345735490899147
Validation loss: 3.6980835565704813

Epoch: 6| Step: 10
Training loss: 3.838092392915097
Validation loss: 3.6858623602264085

Epoch: 6| Step: 11
Training loss: 4.219345163819878
Validation loss: 3.6765164327543918

Epoch: 6| Step: 12
Training loss: 4.180287084622692
Validation loss: 3.6729296675723204

Epoch: 6| Step: 13
Training loss: 4.862621927571385
Validation loss: 3.6609837616833567

Epoch: 11| Step: 0
Training loss: 4.607265390517688
Validation loss: 3.652765319229861

Epoch: 6| Step: 1
Training loss: 2.9202626721584233
Validation loss: 3.641896557766793

Epoch: 6| Step: 2
Training loss: 3.9960231084909594
Validation loss: 3.6379199832970377

Epoch: 6| Step: 3
Training loss: 4.267949962347674
Validation loss: 3.628068750195263

Epoch: 6| Step: 4
Training loss: 3.4921278297737013
Validation loss: 3.608544123923724

Epoch: 6| Step: 5
Training loss: 4.31612873825101
Validation loss: 3.609387631468131

Epoch: 6| Step: 6
Training loss: 3.598769952653148
Validation loss: 3.5975288971687824

Epoch: 6| Step: 7
Training loss: 3.556981145320293
Validation loss: 3.5884066470493643

Epoch: 6| Step: 8
Training loss: 3.58472284094245
Validation loss: 3.57290734845611

Epoch: 6| Step: 9
Training loss: 2.841824896500593
Validation loss: 3.5682119113661055

Epoch: 6| Step: 10
Training loss: 3.7134216346263766
Validation loss: 3.5575055105379274

Epoch: 6| Step: 11
Training loss: 4.2142481767585185
Validation loss: 3.5505369392436026

Epoch: 6| Step: 12
Training loss: 3.3128054495999932
Validation loss: 3.5446716956155475

Epoch: 6| Step: 13
Training loss: 4.028804303311329
Validation loss: 3.52432246629555

Epoch: 12| Step: 0
Training loss: 3.7689553883321945
Validation loss: 3.521355417630251

Epoch: 6| Step: 1
Training loss: 2.841928422642595
Validation loss: 3.5085762282019237

Epoch: 6| Step: 2
Training loss: 3.364906476607259
Validation loss: 3.5007005919114373

Epoch: 6| Step: 3
Training loss: 3.0908499332111465
Validation loss: 3.4856191943186663

Epoch: 6| Step: 4
Training loss: 4.167064393452504
Validation loss: 3.4782259895491645

Epoch: 6| Step: 5
Training loss: 2.2996354933781973
Validation loss: 3.4660209600662917

Epoch: 6| Step: 6
Training loss: 3.486380645612799
Validation loss: 3.456757027718463

Epoch: 6| Step: 7
Training loss: 3.7302637173694633
Validation loss: 3.4418610481845486

Epoch: 6| Step: 8
Training loss: 3.4694867425652367
Validation loss: 3.4408627317468095

Epoch: 6| Step: 9
Training loss: 3.92213445162404
Validation loss: 3.430978187993079

Epoch: 6| Step: 10
Training loss: 3.525798809904616
Validation loss: 3.4066984963839007

Epoch: 6| Step: 11
Training loss: 4.625989241096463
Validation loss: 3.4012556540932084

Epoch: 6| Step: 12
Training loss: 4.184053283585524
Validation loss: 3.3861250572448265

Epoch: 6| Step: 13
Training loss: 4.030332948926083
Validation loss: 3.3831803096942776

Epoch: 13| Step: 0
Training loss: 3.540560037096072
Validation loss: 3.3648744471984156

Epoch: 6| Step: 1
Training loss: 3.9944507730286793
Validation loss: 3.3432869738674102

Epoch: 6| Step: 2
Training loss: 3.913195729173195
Validation loss: 3.3425217861556153

Epoch: 6| Step: 3
Training loss: 4.296208222413345
Validation loss: 3.332126139393627

Epoch: 6| Step: 4
Training loss: 3.6140617558618318
Validation loss: 3.315184155993844

Epoch: 6| Step: 5
Training loss: 3.7611962071353493
Validation loss: 3.2928763929275244

Epoch: 6| Step: 6
Training loss: 3.708491175574833
Validation loss: 3.273608551227886

Epoch: 6| Step: 7
Training loss: 2.733090867554099
Validation loss: 3.2726899591394356

Epoch: 6| Step: 8
Training loss: 2.8211365233025454
Validation loss: 3.2541593813551044

Epoch: 6| Step: 9
Training loss: 2.696993361756639
Validation loss: 3.2320244350262004

Epoch: 6| Step: 10
Training loss: 3.23275111616294
Validation loss: 3.21746057396742

Epoch: 6| Step: 11
Training loss: 3.284121900510039
Validation loss: 3.2181175830047

Epoch: 6| Step: 12
Training loss: 3.815084613146706
Validation loss: 3.195340385067623

Epoch: 6| Step: 13
Training loss: 2.563813593915935
Validation loss: 3.186979382806493

Epoch: 14| Step: 0
Training loss: 3.717326685258712
Validation loss: 3.180053448002491

Epoch: 6| Step: 1
Training loss: 2.591650423283184
Validation loss: 3.1483495637861862

Epoch: 6| Step: 2
Training loss: 3.331338253605677
Validation loss: 3.141343062987217

Epoch: 6| Step: 3
Training loss: 3.2298933298549057
Validation loss: 3.128186055016266

Epoch: 6| Step: 4
Training loss: 3.2268635237624737
Validation loss: 3.118416198336967

Epoch: 6| Step: 5
Training loss: 3.6002348399389117
Validation loss: 3.101798584210498

Epoch: 6| Step: 6
Training loss: 3.879166608756475
Validation loss: 3.08739293041376

Epoch: 6| Step: 7
Training loss: 2.9081606583219943
Validation loss: 3.08031422958761

Epoch: 6| Step: 8
Training loss: 4.012430426924335
Validation loss: 3.0565691290130714

Epoch: 6| Step: 9
Training loss: 3.2226279887491867
Validation loss: 3.044757414475388

Epoch: 6| Step: 10
Training loss: 2.5522434314154134
Validation loss: 3.036564893359626

Epoch: 6| Step: 11
Training loss: 3.404312842851966
Validation loss: 3.008722320207372

Epoch: 6| Step: 12
Training loss: 3.5429575792702206
Validation loss: 3.008881361173596

Epoch: 6| Step: 13
Training loss: 2.47051919244948
Validation loss: 2.98905759749815

Epoch: 15| Step: 0
Training loss: 3.1302284752086127
Validation loss: 2.973688015520627

Epoch: 6| Step: 1
Training loss: 3.504925123603971
Validation loss: 2.95495522189846

Epoch: 6| Step: 2
Training loss: 4.043671625194403
Validation loss: 2.942402756042025

Epoch: 6| Step: 3
Training loss: 2.531234364402423
Validation loss: 2.930672293146827

Epoch: 6| Step: 4
Training loss: 3.124138064724563
Validation loss: 2.914072611805886

Epoch: 6| Step: 5
Training loss: 2.798403359635672
Validation loss: 2.900861580796388

Epoch: 6| Step: 6
Training loss: 2.9542478011323974
Validation loss: 2.889667286481971

Epoch: 6| Step: 7
Training loss: 2.942518776158765
Validation loss: 2.874512126772517

Epoch: 6| Step: 8
Training loss: 3.1470108018076988
Validation loss: 2.8641899189253768

Epoch: 6| Step: 9
Training loss: 3.2531526386651612
Validation loss: 2.84097919524534

Epoch: 6| Step: 10
Training loss: 3.055374575563047
Validation loss: 2.830771567219969

Epoch: 6| Step: 11
Training loss: 3.226529543803015
Validation loss: 2.813716231680177

Epoch: 6| Step: 12
Training loss: 3.1455651141551875
Validation loss: 2.80257921595823

Epoch: 6| Step: 13
Training loss: 2.909068064166448
Validation loss: 2.7924908899911505

Epoch: 16| Step: 0
Training loss: 3.0264259571475858
Validation loss: 2.7832481633075394

Epoch: 6| Step: 1
Training loss: 3.287577604240887
Validation loss: 2.7548660489691863

Epoch: 6| Step: 2
Training loss: 2.7258812345632095
Validation loss: 2.7539434210110807

Epoch: 6| Step: 3
Training loss: 3.1582312078412844
Validation loss: 2.7442567670751155

Epoch: 6| Step: 4
Training loss: 2.7783925668877867
Validation loss: 2.730702368691943

Epoch: 6| Step: 5
Training loss: 3.495024823494921
Validation loss: 2.7132269752990497

Epoch: 6| Step: 6
Training loss: 3.2746384632229764
Validation loss: 2.6861007006604587

Epoch: 6| Step: 7
Training loss: 3.161125722835346
Validation loss: 2.6882611394289007

Epoch: 6| Step: 8
Training loss: 2.7779984916314904
Validation loss: 2.6833536175839043

Epoch: 6| Step: 9
Training loss: 2.7449629342333464
Validation loss: 2.6652051499443137

Epoch: 6| Step: 10
Training loss: 3.0241125964743416
Validation loss: 2.650867493103206

Epoch: 6| Step: 11
Training loss: 3.338685094615954
Validation loss: 2.6368768776011287

Epoch: 6| Step: 12
Training loss: 2.486527188491299
Validation loss: 2.6468263803261265

Epoch: 6| Step: 13
Training loss: 2.515500178113221
Validation loss: 2.627105862398414

Epoch: 17| Step: 0
Training loss: 3.4780083896388803
Validation loss: 2.6201602974332907

Epoch: 6| Step: 1
Training loss: 2.950806691709224
Validation loss: 2.612663689641133

Epoch: 6| Step: 2
Training loss: 3.0980740009332877
Validation loss: 2.6039084085362165

Epoch: 6| Step: 3
Training loss: 2.882067741810346
Validation loss: 2.588978151201517

Epoch: 6| Step: 4
Training loss: 3.2699091065166277
Validation loss: 2.581707750257273

Epoch: 6| Step: 5
Training loss: 3.2347009466933065
Validation loss: 2.566402629902747

Epoch: 6| Step: 6
Training loss: 2.7126773231311407
Validation loss: 2.5768517794247603

Epoch: 6| Step: 7
Training loss: 3.080516989531226
Validation loss: 2.565798523572944

Epoch: 6| Step: 8
Training loss: 1.8899957539747874
Validation loss: 2.5530945198341386

Epoch: 6| Step: 9
Training loss: 2.7464333727130454
Validation loss: 2.5380478465212675

Epoch: 6| Step: 10
Training loss: 2.800988778867788
Validation loss: 2.5445306299178303

Epoch: 6| Step: 11
Training loss: 2.833091295413364
Validation loss: 2.534277022207109

Epoch: 6| Step: 12
Training loss: 2.6613830336776068
Validation loss: 2.537605558008564

Epoch: 6| Step: 13
Training loss: 2.9334071439068645
Validation loss: 2.5140910449098617

Epoch: 18| Step: 0
Training loss: 2.8809442850304667
Validation loss: 2.5165400256498414

Epoch: 6| Step: 1
Training loss: 2.197462339284672
Validation loss: 2.511429337642218

Epoch: 6| Step: 2
Training loss: 3.076158079086128
Validation loss: 2.516210589909229

Epoch: 6| Step: 3
Training loss: 3.134270763850879
Validation loss: 2.510125657823014

Epoch: 6| Step: 4
Training loss: 3.0157069061699113
Validation loss: 2.5011482206607045

Epoch: 6| Step: 5
Training loss: 2.179622526123337
Validation loss: 2.5092350643452797

Epoch: 6| Step: 6
Training loss: 3.016671903264961
Validation loss: 2.496102834338342

Epoch: 6| Step: 7
Training loss: 3.256050053935804
Validation loss: 2.505487797170945

Epoch: 6| Step: 8
Training loss: 2.8200427319961703
Validation loss: 2.5036540378983165

Epoch: 6| Step: 9
Training loss: 3.084232989504023
Validation loss: 2.5024559539924307

Epoch: 6| Step: 10
Training loss: 3.128522489828122
Validation loss: 2.514481142976195

Epoch: 6| Step: 11
Training loss: 2.5771275295784135
Validation loss: 2.485204402261614

Epoch: 6| Step: 12
Training loss: 2.6949542263581265
Validation loss: 2.4776249610197447

Epoch: 6| Step: 13
Training loss: 2.964892320398435
Validation loss: 2.492450214860179

Epoch: 19| Step: 0
Training loss: 3.1972190932777695
Validation loss: 2.4881056893019378

Epoch: 6| Step: 1
Training loss: 2.707838678426048
Validation loss: 2.48783025306978

Epoch: 6| Step: 2
Training loss: 2.8829347331280455
Validation loss: 2.4944522686831863

Epoch: 6| Step: 3
Training loss: 2.8944930307024674
Validation loss: 2.4860229970013705

Epoch: 6| Step: 4
Training loss: 2.9959314095930716
Validation loss: 2.4791350831022387

Epoch: 6| Step: 5
Training loss: 3.424711541050472
Validation loss: 2.476759741017517

Epoch: 6| Step: 6
Training loss: 3.0311515241534743
Validation loss: 2.476277948979736

Epoch: 6| Step: 7
Training loss: 2.5080965540794002
Validation loss: 2.4617913981824735

Epoch: 6| Step: 8
Training loss: 2.7505302784911727
Validation loss: 2.4790644891339753

Epoch: 6| Step: 9
Training loss: 2.367450359593451
Validation loss: 2.4785515982291884

Epoch: 6| Step: 10
Training loss: 2.5669234638640743
Validation loss: 2.4660964314455778

Epoch: 6| Step: 11
Training loss: 3.1469917101464486
Validation loss: 2.4813645725481157

Epoch: 6| Step: 12
Training loss: 2.523041968747649
Validation loss: 2.486798656793284

Epoch: 6| Step: 13
Training loss: 2.927618247102761
Validation loss: 2.4769061019613328

Epoch: 20| Step: 0
Training loss: 2.1902130740949666
Validation loss: 2.476205127360407

Epoch: 6| Step: 1
Training loss: 2.6974216335958436
Validation loss: 2.4706504778878857

Epoch: 6| Step: 2
Training loss: 3.363868015335496
Validation loss: 2.4786819152299886

Epoch: 6| Step: 3
Training loss: 2.7459001323657546
Validation loss: 2.468602586392094

Epoch: 6| Step: 4
Training loss: 2.5215908415143957
Validation loss: 2.468060077356838

Epoch: 6| Step: 5
Training loss: 2.943860897882912
Validation loss: 2.4616439375733865

Epoch: 6| Step: 6
Training loss: 2.8018548203404716
Validation loss: 2.470479775363917

Epoch: 6| Step: 7
Training loss: 3.2756349020977322
Validation loss: 2.4588938248450645

Epoch: 6| Step: 8
Training loss: 3.186592720908229
Validation loss: 2.459377499495578

Epoch: 6| Step: 9
Training loss: 2.9409797024822524
Validation loss: 2.4647903359889236

Epoch: 6| Step: 10
Training loss: 3.0584362861566188
Validation loss: 2.466334545408014

Epoch: 6| Step: 11
Training loss: 2.303173330723813
Validation loss: 2.4631084949402235

Epoch: 6| Step: 12
Training loss: 2.7192685739833817
Validation loss: 2.4621331944006624

Epoch: 6| Step: 13
Training loss: 3.042372286395654
Validation loss: 2.457864550497455

Epoch: 21| Step: 0
Training loss: 2.709847442724737
Validation loss: 2.4596076483054117

Epoch: 6| Step: 1
Training loss: 3.2358224182442568
Validation loss: 2.473630217385848

Epoch: 6| Step: 2
Training loss: 2.6382834983773176
Validation loss: 2.454338093050658

Epoch: 6| Step: 3
Training loss: 2.9461118387513165
Validation loss: 2.467418478244871

Epoch: 6| Step: 4
Training loss: 2.6836712199971546
Validation loss: 2.45862773705705

Epoch: 6| Step: 5
Training loss: 2.6115492482457965
Validation loss: 2.4583523549518396

Epoch: 6| Step: 6
Training loss: 2.922188155584473
Validation loss: 2.461191213055893

Epoch: 6| Step: 7
Training loss: 3.441753322320131
Validation loss: 2.453267489605156

Epoch: 6| Step: 8
Training loss: 3.5852595334565684
Validation loss: 2.453267141623374

Epoch: 6| Step: 9
Training loss: 3.0622703310425257
Validation loss: 2.4575301002277503

Epoch: 6| Step: 10
Training loss: 2.446698560723388
Validation loss: 2.4618635912793

Epoch: 6| Step: 11
Training loss: 2.0200271440325186
Validation loss: 2.4525942876612294

Epoch: 6| Step: 12
Training loss: 2.6686247749341026
Validation loss: 2.458249261863542

Epoch: 6| Step: 13
Training loss: 2.404878696229625
Validation loss: 2.461549659920504

Epoch: 22| Step: 0
Training loss: 2.802538800477155
Validation loss: 2.453406750459713

Epoch: 6| Step: 1
Training loss: 2.5741232592363277
Validation loss: 2.469663327216404

Epoch: 6| Step: 2
Training loss: 3.528492889280372
Validation loss: 2.444752807579603

Epoch: 6| Step: 3
Training loss: 2.665502343704318
Validation loss: 2.4502440565407326

Epoch: 6| Step: 4
Training loss: 2.8349518547477652
Validation loss: 2.4650478764426786

Epoch: 6| Step: 5
Training loss: 2.52492401461946
Validation loss: 2.4440143568630526

Epoch: 6| Step: 6
Training loss: 3.261035523268797
Validation loss: 2.465671112150476

Epoch: 6| Step: 7
Training loss: 3.1279719144726177
Validation loss: 2.453729314589371

Epoch: 6| Step: 8
Training loss: 2.7164263386898293
Validation loss: 2.439039005852399

Epoch: 6| Step: 9
Training loss: 2.1303754024387724
Validation loss: 2.462599048587001

Epoch: 6| Step: 10
Training loss: 3.2865705677501826
Validation loss: 2.4603958015494594

Epoch: 6| Step: 11
Training loss: 2.4927042362632723
Validation loss: 2.4583522287695514

Epoch: 6| Step: 12
Training loss: 2.951650746017361
Validation loss: 2.4600021842858806

Epoch: 6| Step: 13
Training loss: 3.0252716257766017
Validation loss: 2.4606151441955433

Epoch: 23| Step: 0
Training loss: 3.07470513147323
Validation loss: 2.4691544649665738

Epoch: 6| Step: 1
Training loss: 3.383631089611564
Validation loss: 2.4609103283193514

Epoch: 6| Step: 2
Training loss: 2.9891601865592023
Validation loss: 2.475555704907148

Epoch: 6| Step: 3
Training loss: 2.3010293150041137
Validation loss: 2.4698509750988307

Epoch: 6| Step: 4
Training loss: 2.831847549268386
Validation loss: 2.472759522077346

Epoch: 6| Step: 5
Training loss: 2.2058463097413896
Validation loss: 2.4707787297195547

Epoch: 6| Step: 6
Training loss: 2.5573253020789273
Validation loss: 2.476671992757614

Epoch: 6| Step: 7
Training loss: 3.4183682802206596
Validation loss: 2.4656296472333956

Epoch: 6| Step: 8
Training loss: 2.5106820774783776
Validation loss: 2.450784001361983

Epoch: 6| Step: 9
Training loss: 3.035900991772977
Validation loss: 2.4712834928967733

Epoch: 6| Step: 10
Training loss: 3.2604852411210756
Validation loss: 2.465563645042601

Epoch: 6| Step: 11
Training loss: 2.3388478192700144
Validation loss: 2.4789504948552956

Epoch: 6| Step: 12
Training loss: 2.7909299438223925
Validation loss: 2.4645041261731384

Epoch: 6| Step: 13
Training loss: 3.134267416844869
Validation loss: 2.4846800724340796

Epoch: 24| Step: 0
Training loss: 3.1333559853837447
Validation loss: 2.4753839254271215

Epoch: 6| Step: 1
Training loss: 3.172776568587017
Validation loss: 2.4677451245837374

Epoch: 6| Step: 2
Training loss: 2.876336160402953
Validation loss: 2.4665352406849586

Epoch: 6| Step: 3
Training loss: 2.882209528690263
Validation loss: 2.4740959076552556

Epoch: 6| Step: 4
Training loss: 2.418126509393106
Validation loss: 2.4842248893075105

Epoch: 6| Step: 5
Training loss: 2.841307209209256
Validation loss: 2.464957156937331

Epoch: 6| Step: 6
Training loss: 3.435742570552747
Validation loss: 2.4779638293884054

Epoch: 6| Step: 7
Training loss: 2.763196320613141
Validation loss: 2.4719923614315307

Epoch: 6| Step: 8
Training loss: 2.7514387181961757
Validation loss: 2.459341490769612

Epoch: 6| Step: 9
Training loss: 2.9244797464009515
Validation loss: 2.458552472953166

Epoch: 6| Step: 10
Training loss: 2.656330152312072
Validation loss: 2.4576700865174845

Epoch: 6| Step: 11
Training loss: 2.505565551752909
Validation loss: 2.4742565879805234

Epoch: 6| Step: 12
Training loss: 2.7422381882723976
Validation loss: 2.4622610840040595

Epoch: 6| Step: 13
Training loss: 2.2019883057424963
Validation loss: 2.4694568644409918

Epoch: 25| Step: 0
Training loss: 3.2425933951498656
Validation loss: 2.4681393403025593

Epoch: 6| Step: 1
Training loss: 3.20596351459039
Validation loss: 2.464012604822499

Epoch: 6| Step: 2
Training loss: 2.9519182595615368
Validation loss: 2.4555038644405838

Epoch: 6| Step: 3
Training loss: 2.4587811423163606
Validation loss: 2.464003702859556

Epoch: 6| Step: 4
Training loss: 3.040114821223156
Validation loss: 2.467881435816166

Epoch: 6| Step: 5
Training loss: 2.9293165455254506
Validation loss: 2.4671396528148883

Epoch: 6| Step: 6
Training loss: 2.4069606177575467
Validation loss: 2.4492561866194196

Epoch: 6| Step: 7
Training loss: 2.6052196560908127
Validation loss: 2.46837096954098

Epoch: 6| Step: 8
Training loss: 2.806190704195021
Validation loss: 2.469930406843576

Epoch: 6| Step: 9
Training loss: 3.1928838999996465
Validation loss: 2.4582452707871165

Epoch: 6| Step: 10
Training loss: 3.0436504809894394
Validation loss: 2.4681522491533596

Epoch: 6| Step: 11
Training loss: 2.7700897213283517
Validation loss: 2.459936734561611

Epoch: 6| Step: 12
Training loss: 2.560220867851326
Validation loss: 2.4622184996455663

Epoch: 6| Step: 13
Training loss: 2.4557494684851977
Validation loss: 2.455590467997185

Epoch: 26| Step: 0
Training loss: 3.0641250969670413
Validation loss: 2.466153234106069

Epoch: 6| Step: 1
Training loss: 2.3286537747612805
Validation loss: 2.4596469665449683

Epoch: 6| Step: 2
Training loss: 2.7828018488136634
Validation loss: 2.464354941843822

Epoch: 6| Step: 3
Training loss: 2.6970469326055944
Validation loss: 2.454482137433023

Epoch: 6| Step: 4
Training loss: 2.9341461839929734
Validation loss: 2.4729163176901428

Epoch: 6| Step: 5
Training loss: 2.0146396801342625
Validation loss: 2.457692036757788

Epoch: 6| Step: 6
Training loss: 2.763628481466972
Validation loss: 2.4633575233962306

Epoch: 6| Step: 7
Training loss: 3.0980793879208233
Validation loss: 2.471491347597388

Epoch: 6| Step: 8
Training loss: 3.1486177227225878
Validation loss: 2.4440190005453943

Epoch: 6| Step: 9
Training loss: 3.1567923202668715
Validation loss: 2.452939336535937

Epoch: 6| Step: 10
Training loss: 3.2770875232731993
Validation loss: 2.4646857480966506

Epoch: 6| Step: 11
Training loss: 2.948497719445397
Validation loss: 2.452288518778538

Epoch: 6| Step: 12
Training loss: 2.7358464232948947
Validation loss: 2.4683630429622823

Epoch: 6| Step: 13
Training loss: 2.4806517525996634
Validation loss: 2.4611069352197643

Epoch: 27| Step: 0
Training loss: 3.2992685316495693
Validation loss: 2.4673644487652937

Epoch: 6| Step: 1
Training loss: 2.129356406679032
Validation loss: 2.4631851674764698

Epoch: 6| Step: 2
Training loss: 3.288909111161251
Validation loss: 2.467319962469688

Epoch: 6| Step: 3
Training loss: 2.8071400749500595
Validation loss: 2.45942851060743

Epoch: 6| Step: 4
Training loss: 2.778864662732199
Validation loss: 2.47535267075323

Epoch: 6| Step: 5
Training loss: 2.5991263682462216
Validation loss: 2.469712496168241

Epoch: 6| Step: 6
Training loss: 2.5962510517322097
Validation loss: 2.457111630369772

Epoch: 6| Step: 7
Training loss: 3.0537601243740147
Validation loss: 2.457339084878221

Epoch: 6| Step: 8
Training loss: 3.3328977936079465
Validation loss: 2.4723141395700146

Epoch: 6| Step: 9
Training loss: 2.4123901697962014
Validation loss: 2.4525017004948055

Epoch: 6| Step: 10
Training loss: 3.0822223173803223
Validation loss: 2.460633447696309

Epoch: 6| Step: 11
Training loss: 2.5148549293252995
Validation loss: 2.4442154505410185

Epoch: 6| Step: 12
Training loss: 2.733193627330486
Validation loss: 2.455709486527251

Epoch: 6| Step: 13
Training loss: 2.958940219864444
Validation loss: 2.4550230308349485

Epoch: 28| Step: 0
Training loss: 3.296725156732542
Validation loss: 2.459025081448208

Epoch: 6| Step: 1
Training loss: 2.963731076981763
Validation loss: 2.462678341560004

Epoch: 6| Step: 2
Training loss: 2.8877152928269707
Validation loss: 2.4585866569893438

Epoch: 6| Step: 3
Training loss: 2.8214914494245815
Validation loss: 2.4612423370889833

Epoch: 6| Step: 4
Training loss: 2.0969708848568347
Validation loss: 2.468002400327599

Epoch: 6| Step: 5
Training loss: 2.9020761030170514
Validation loss: 2.458821438205123

Epoch: 6| Step: 6
Training loss: 3.2455219816463434
Validation loss: 2.4615841074824294

Epoch: 6| Step: 7
Training loss: 2.618839482711007
Validation loss: 2.4629756094447104

Epoch: 6| Step: 8
Training loss: 3.4519565728595434
Validation loss: 2.460864923451643

Epoch: 6| Step: 9
Training loss: 2.9418810376376228
Validation loss: 2.4751085334018206

Epoch: 6| Step: 10
Training loss: 2.622378448054933
Validation loss: 2.4650638663337103

Epoch: 6| Step: 11
Training loss: 2.242671688316127
Validation loss: 2.4685480552603143

Epoch: 6| Step: 12
Training loss: 2.7380880377459578
Validation loss: 2.4575918284506373

Epoch: 6| Step: 13
Training loss: 2.4620630021761367
Validation loss: 2.453100844573191

Epoch: 29| Step: 0
Training loss: 1.9598624029323422
Validation loss: 2.4604360282743047

Epoch: 6| Step: 1
Training loss: 2.9562700266895656
Validation loss: 2.46346746153999

Epoch: 6| Step: 2
Training loss: 3.075657199008132
Validation loss: 2.4571616170175075

Epoch: 6| Step: 3
Training loss: 3.1437494478926733
Validation loss: 2.4541069658691157

Epoch: 6| Step: 4
Training loss: 2.9189663857866774
Validation loss: 2.4599926050136536

Epoch: 6| Step: 5
Training loss: 2.37134521759733
Validation loss: 2.453407312632497

Epoch: 6| Step: 6
Training loss: 3.359149304282546
Validation loss: 2.4588230876449977

Epoch: 6| Step: 7
Training loss: 2.791851796706435
Validation loss: 2.4404752004926613

Epoch: 6| Step: 8
Training loss: 3.260260012502238
Validation loss: 2.446466689276011

Epoch: 6| Step: 9
Training loss: 2.8832908171530836
Validation loss: 2.4541188532392924

Epoch: 6| Step: 10
Training loss: 2.371985077848023
Validation loss: 2.4564574961548447

Epoch: 6| Step: 11
Training loss: 2.1366935324008938
Validation loss: 2.459428789963243

Epoch: 6| Step: 12
Training loss: 3.067002237314777
Validation loss: 2.476027438963405

Epoch: 6| Step: 13
Training loss: 3.3074353925258193
Validation loss: 2.4510729784286625

Epoch: 30| Step: 0
Training loss: 2.7515881894075127
Validation loss: 2.4559969613080943

Epoch: 6| Step: 1
Training loss: 3.17684186841224
Validation loss: 2.453851994841488

Epoch: 6| Step: 2
Training loss: 2.892569552865421
Validation loss: 2.4687784436561526

Epoch: 6| Step: 3
Training loss: 3.213372043149581
Validation loss: 2.4483437972994646

Epoch: 6| Step: 4
Training loss: 2.484684187165188
Validation loss: 2.462135995300875

Epoch: 6| Step: 5
Training loss: 2.454132844943379
Validation loss: 2.4552001964545584

Epoch: 6| Step: 6
Training loss: 2.895140054902353
Validation loss: 2.457267596615314

Epoch: 6| Step: 7
Training loss: 2.428238906054239
Validation loss: 2.4662569541640385

Epoch: 6| Step: 8
Training loss: 3.174844338513544
Validation loss: 2.4630536121459623

Epoch: 6| Step: 9
Training loss: 3.2558397499596
Validation loss: 2.4536471668414213

Epoch: 6| Step: 10
Training loss: 2.5663945446008745
Validation loss: 2.464830085359379

Epoch: 6| Step: 11
Training loss: 2.084653080316002
Validation loss: 2.448108839574575

Epoch: 6| Step: 12
Training loss: 3.197538686940313
Validation loss: 2.4496409040654057

Epoch: 6| Step: 13
Training loss: 2.964719747128911
Validation loss: 2.456177275089662

Epoch: 31| Step: 0
Training loss: 2.3317459928785502
Validation loss: 2.451564182809082

Epoch: 6| Step: 1
Training loss: 3.088782126901446
Validation loss: 2.464570714284276

Epoch: 6| Step: 2
Training loss: 3.0878685426254213
Validation loss: 2.4441790369855374

Epoch: 6| Step: 3
Training loss: 2.8332572440607913
Validation loss: 2.4678258166814633

Epoch: 6| Step: 4
Training loss: 2.229156482233568
Validation loss: 2.454270790685634

Epoch: 6| Step: 5
Training loss: 3.2255276921020366
Validation loss: 2.4676949253399436

Epoch: 6| Step: 6
Training loss: 2.6987945620809803
Validation loss: 2.4579471768374974

Epoch: 6| Step: 7
Training loss: 2.6997917660134427
Validation loss: 2.458336346434813

Epoch: 6| Step: 8
Training loss: 2.119085720774926
Validation loss: 2.446963093922996

Epoch: 6| Step: 9
Training loss: 3.2062640927843455
Validation loss: 2.4531377474984857

Epoch: 6| Step: 10
Training loss: 2.748717529188355
Validation loss: 2.4452382833611686

Epoch: 6| Step: 11
Training loss: 2.7003545952115937
Validation loss: 2.4725147968834364

Epoch: 6| Step: 12
Training loss: 3.6157379211886584
Validation loss: 2.4454536395946014

Epoch: 6| Step: 13
Training loss: 2.66064269425806
Validation loss: 2.466214484540806

Epoch: 32| Step: 0
Training loss: 2.202916994488656
Validation loss: 2.459429462293335

Epoch: 6| Step: 1
Training loss: 2.833348124596377
Validation loss: 2.4665999254954882

Epoch: 6| Step: 2
Training loss: 3.4660528195819986
Validation loss: 2.4551107597774644

Epoch: 6| Step: 3
Training loss: 3.0783680466486527
Validation loss: 2.4572877497492867

Epoch: 6| Step: 4
Training loss: 2.8001103788145425
Validation loss: 2.4444701676850213

Epoch: 6| Step: 5
Training loss: 3.092264454536046
Validation loss: 2.4475655126913924

Epoch: 6| Step: 6
Training loss: 2.7906600693638235
Validation loss: 2.468001308599769

Epoch: 6| Step: 7
Training loss: 2.5876783521431697
Validation loss: 2.450810577143779

Epoch: 6| Step: 8
Training loss: 2.901792984838076
Validation loss: 2.4543483085761015

Epoch: 6| Step: 9
Training loss: 2.9622468091715897
Validation loss: 2.4470788957304195

Epoch: 6| Step: 10
Training loss: 3.126697231975673
Validation loss: 2.4584954759099835

Epoch: 6| Step: 11
Training loss: 1.9895940916825732
Validation loss: 2.4511721218285336

Epoch: 6| Step: 12
Training loss: 2.3981630249031136
Validation loss: 2.4608194562809502

Epoch: 6| Step: 13
Training loss: 3.317010651454896
Validation loss: 2.455255826988719

Epoch: 33| Step: 0
Training loss: 3.4015562983514607
Validation loss: 2.4543557445744777

Epoch: 6| Step: 1
Training loss: 2.574299326259322
Validation loss: 2.440985096823146

Epoch: 6| Step: 2
Training loss: 3.108179523934055
Validation loss: 2.450925314350162

Epoch: 6| Step: 3
Training loss: 2.675635830902512
Validation loss: 2.466910813597945

Epoch: 6| Step: 4
Training loss: 3.1677065363315116
Validation loss: 2.4424050455040525

Epoch: 6| Step: 5
Training loss: 2.5362115905771216
Validation loss: 2.4516432784686315

Epoch: 6| Step: 6
Training loss: 2.9059479259070518
Validation loss: 2.4559428914191055

Epoch: 6| Step: 7
Training loss: 2.4341647487042097
Validation loss: 2.452590534068304

Epoch: 6| Step: 8
Training loss: 2.912186496872396
Validation loss: 2.4606151145022537

Epoch: 6| Step: 9
Training loss: 2.9906304593569555
Validation loss: 2.4487848292777685

Epoch: 6| Step: 10
Training loss: 2.1090687847397076
Validation loss: 2.4549229010300317

Epoch: 6| Step: 11
Training loss: 2.7276554922786906
Validation loss: 2.4484246806612413

Epoch: 6| Step: 12
Training loss: 2.7550883468336624
Validation loss: 2.4576952620486403

Epoch: 6| Step: 13
Training loss: 3.436962154966984
Validation loss: 2.442752440935262

Epoch: 34| Step: 0
Training loss: 2.776170356635208
Validation loss: 2.465182609479392

Epoch: 6| Step: 1
Training loss: 2.9376529085659615
Validation loss: 2.4674170033880514

Epoch: 6| Step: 2
Training loss: 2.743272876312813
Validation loss: 2.443869344080255

Epoch: 6| Step: 3
Training loss: 3.230291912953922
Validation loss: 2.4530823490094598

Epoch: 6| Step: 4
Training loss: 3.054255852604917
Validation loss: 2.458208065967541

Epoch: 6| Step: 5
Training loss: 2.3407124481366908
Validation loss: 2.462668124153772

Epoch: 6| Step: 6
Training loss: 2.6239490221642545
Validation loss: 2.441304538371883

Epoch: 6| Step: 7
Training loss: 2.6449983936441948
Validation loss: 2.4566298383074776

Epoch: 6| Step: 8
Training loss: 3.095103882754817
Validation loss: 2.4577694383977677

Epoch: 6| Step: 9
Training loss: 3.5033961576520536
Validation loss: 2.45748588891531

Epoch: 6| Step: 10
Training loss: 2.777630368665943
Validation loss: 2.470175637159152

Epoch: 6| Step: 11
Training loss: 2.6401704475981482
Validation loss: 2.4643443194328607

Epoch: 6| Step: 12
Training loss: 2.153340574415726
Validation loss: 2.46998055131275

Epoch: 6| Step: 13
Training loss: 2.8502491892243085
Validation loss: 2.453174700030083

Epoch: 35| Step: 0
Training loss: 3.03754173218744
Validation loss: 2.449730670206151

Epoch: 6| Step: 1
Training loss: 2.811040202751354
Validation loss: 2.4571681065473725

Epoch: 6| Step: 2
Training loss: 2.542448257174839
Validation loss: 2.459455542304817

Epoch: 6| Step: 3
Training loss: 2.577875853550904
Validation loss: 2.462946638703309

Epoch: 6| Step: 4
Training loss: 2.9590723610062155
Validation loss: 2.4582289455797657

Epoch: 6| Step: 5
Training loss: 1.9485285880693564
Validation loss: 2.4701892172240676

Epoch: 6| Step: 6
Training loss: 2.2446966188020654
Validation loss: 2.462762602575395

Epoch: 6| Step: 7
Training loss: 3.18761937534965
Validation loss: 2.469546413765988

Epoch: 6| Step: 8
Training loss: 3.0819630198305474
Validation loss: 2.4557066041765543

Epoch: 6| Step: 9
Training loss: 3.6560657161340684
Validation loss: 2.4512122677403894

Epoch: 6| Step: 10
Training loss: 3.102286842763763
Validation loss: 2.4624862014219833

Epoch: 6| Step: 11
Training loss: 2.632156969636343
Validation loss: 2.471808254119216

Epoch: 6| Step: 12
Training loss: 2.3413934686290907
Validation loss: 2.4554221472294415

Epoch: 6| Step: 13
Training loss: 3.3161882704055556
Validation loss: 2.4581067653663506

Epoch: 36| Step: 0
Training loss: 2.779767873801778
Validation loss: 2.4657906775540073

Epoch: 6| Step: 1
Training loss: 2.2513127206286674
Validation loss: 2.452215232531879

Epoch: 6| Step: 2
Training loss: 2.9007817168457577
Validation loss: 2.442187296310132

Epoch: 6| Step: 3
Training loss: 2.71382668743957
Validation loss: 2.461496851401176

Epoch: 6| Step: 4
Training loss: 2.913904426112257
Validation loss: 2.46627946517942

Epoch: 6| Step: 5
Training loss: 2.553979991502884
Validation loss: 2.4585966390178045

Epoch: 6| Step: 6
Training loss: 3.1257941190706875
Validation loss: 2.456157032474493

Epoch: 6| Step: 7
Training loss: 3.271997977407712
Validation loss: 2.4642737553349057

Epoch: 6| Step: 8
Training loss: 3.3032486039839144
Validation loss: 2.447474191263039

Epoch: 6| Step: 9
Training loss: 2.7921477705098776
Validation loss: 2.4486074816439585

Epoch: 6| Step: 10
Training loss: 3.1633256219006824
Validation loss: 2.457464816777615

Epoch: 6| Step: 11
Training loss: 2.4305424305394943
Validation loss: 2.4495547474116646

Epoch: 6| Step: 12
Training loss: 2.2162887461417147
Validation loss: 2.449773100139646

Epoch: 6| Step: 13
Training loss: 2.7129475729713994
Validation loss: 2.4506007015828635

Epoch: 37| Step: 0
Training loss: 2.121598944031408
Validation loss: 2.448568403887588

Epoch: 6| Step: 1
Training loss: 2.97058434283402
Validation loss: 2.464013130241233

Epoch: 6| Step: 2
Training loss: 2.3943346947902397
Validation loss: 2.4541880222904475

Epoch: 6| Step: 3
Training loss: 2.9683783047535965
Validation loss: 2.45100126033443

Epoch: 6| Step: 4
Training loss: 2.8702791680325115
Validation loss: 2.451015039726282

Epoch: 6| Step: 5
Training loss: 2.321765277883343
Validation loss: 2.4508923895368953

Epoch: 6| Step: 6
Training loss: 2.869611583304975
Validation loss: 2.4717366973807704

Epoch: 6| Step: 7
Training loss: 3.0838614518428997
Validation loss: 2.466210167475545

Epoch: 6| Step: 8
Training loss: 2.738191828988628
Validation loss: 2.439216518419511

Epoch: 6| Step: 9
Training loss: 3.194440727416009
Validation loss: 2.474532265963184

Epoch: 6| Step: 10
Training loss: 2.787173189583473
Validation loss: 2.4621259911787168

Epoch: 6| Step: 11
Training loss: 2.854650377555222
Validation loss: 2.4568583647094453

Epoch: 6| Step: 12
Training loss: 3.2673272619724845
Validation loss: 2.462638831244926

Epoch: 6| Step: 13
Training loss: 2.780674821334853
Validation loss: 2.450043163647619

Epoch: 38| Step: 0
Training loss: 2.831942347742535
Validation loss: 2.4476260824189664

Epoch: 6| Step: 1
Training loss: 2.5788318011964844
Validation loss: 2.454500618270973

Epoch: 6| Step: 2
Training loss: 2.8352833563535462
Validation loss: 2.454317096774317

Epoch: 6| Step: 3
Training loss: 3.5433388446275753
Validation loss: 2.4484169313788073

Epoch: 6| Step: 4
Training loss: 3.14285578665766
Validation loss: 2.4494290077215637

Epoch: 6| Step: 5
Training loss: 2.3293654446294574
Validation loss: 2.4384629708834096

Epoch: 6| Step: 6
Training loss: 2.9769189175656523
Validation loss: 2.455001731317909

Epoch: 6| Step: 7
Training loss: 2.625065030700244
Validation loss: 2.4638562081759536

Epoch: 6| Step: 8
Training loss: 2.7448260445706962
Validation loss: 2.464712456900241

Epoch: 6| Step: 9
Training loss: 2.2254239567809435
Validation loss: 2.444655509576534

Epoch: 6| Step: 10
Training loss: 2.873438535506543
Validation loss: 2.449284895385631

Epoch: 6| Step: 11
Training loss: 2.785174312238723
Validation loss: 2.452066280701485

Epoch: 6| Step: 12
Training loss: 2.732592017743778
Validation loss: 2.447227835802321

Epoch: 6| Step: 13
Training loss: 3.0724101193273685
Validation loss: 2.4440622890584605

Epoch: 39| Step: 0
Training loss: 2.2941860106798493
Validation loss: 2.4713961572415615

Epoch: 6| Step: 1
Training loss: 3.3076559672125097
Validation loss: 2.457625662837075

Epoch: 6| Step: 2
Training loss: 2.93812197329867
Validation loss: 2.4498136457046393

Epoch: 6| Step: 3
Training loss: 2.9731143392933475
Validation loss: 2.4592871264348237

Epoch: 6| Step: 4
Training loss: 2.558567844871244
Validation loss: 2.462155477608206

Epoch: 6| Step: 5
Training loss: 2.4581893835649016
Validation loss: 2.4601267249775405

Epoch: 6| Step: 6
Training loss: 2.557219297753753
Validation loss: 2.46643851249682

Epoch: 6| Step: 7
Training loss: 2.8426160962125677
Validation loss: 2.456050865085393

Epoch: 6| Step: 8
Training loss: 2.8563733631429997
Validation loss: 2.4583292864277273

Epoch: 6| Step: 9
Training loss: 3.2288895682940724
Validation loss: 2.4589158991766884

Epoch: 6| Step: 10
Training loss: 2.643321990589693
Validation loss: 2.452531941316378

Epoch: 6| Step: 11
Training loss: 2.404513636717953
Validation loss: 2.4492309400440875

Epoch: 6| Step: 12
Training loss: 3.398702676884852
Validation loss: 2.449518350432644

Epoch: 6| Step: 13
Training loss: 2.8006508343285486
Validation loss: 2.4500606321341545

Epoch: 40| Step: 0
Training loss: 3.2302643089689025
Validation loss: 2.4583111868546097

Epoch: 6| Step: 1
Training loss: 2.492374425114208
Validation loss: 2.4588704475755803

Epoch: 6| Step: 2
Training loss: 2.77743869195362
Validation loss: 2.4558873004574027

Epoch: 6| Step: 3
Training loss: 3.5753940338448595
Validation loss: 2.4363945472850337

Epoch: 6| Step: 4
Training loss: 2.4405931263111067
Validation loss: 2.4348874380456

Epoch: 6| Step: 5
Training loss: 2.3541802825083873
Validation loss: 2.4613302875442136

Epoch: 6| Step: 6
Training loss: 3.137463396930335
Validation loss: 2.453800037214805

Epoch: 6| Step: 7
Training loss: 2.906156312806545
Validation loss: 2.4595449502402236

Epoch: 6| Step: 8
Training loss: 2.602949809284797
Validation loss: 2.446829588802948

Epoch: 6| Step: 9
Training loss: 3.486446705572644
Validation loss: 2.447717246313276

Epoch: 6| Step: 10
Training loss: 2.5026345676212367
Validation loss: 2.4576501524459844

Epoch: 6| Step: 11
Training loss: 2.2581966297773524
Validation loss: 2.448050099761465

Epoch: 6| Step: 12
Training loss: 2.504637993640401
Validation loss: 2.4342549338933313

Epoch: 6| Step: 13
Training loss: 2.7336223329334555
Validation loss: 2.450234137265885

Epoch: 41| Step: 0
Training loss: 2.234042589763498
Validation loss: 2.4357327201208183

Epoch: 6| Step: 1
Training loss: 2.8328536319429225
Validation loss: 2.4686266493287454

Epoch: 6| Step: 2
Training loss: 3.4344902040078353
Validation loss: 2.441358181125408

Epoch: 6| Step: 3
Training loss: 2.522525020055627
Validation loss: 2.446499724996199

Epoch: 6| Step: 4
Training loss: 3.3549554185705217
Validation loss: 2.454688711946696

Epoch: 6| Step: 5
Training loss: 2.772942469300313
Validation loss: 2.4606018681336606

Epoch: 6| Step: 6
Training loss: 2.7871847376428547
Validation loss: 2.4588167296841967

Epoch: 6| Step: 7
Training loss: 3.5413082315415148
Validation loss: 2.4627656775732456

Epoch: 6| Step: 8
Training loss: 2.2417739327255988
Validation loss: 2.4651762731202083

Epoch: 6| Step: 9
Training loss: 2.2482127402700787
Validation loss: 2.4514619362881676

Epoch: 6| Step: 10
Training loss: 2.7862119666781453
Validation loss: 2.4462754367397066

Epoch: 6| Step: 11
Training loss: 2.973083545587471
Validation loss: 2.435361954681945

Epoch: 6| Step: 12
Training loss: 2.4414667961242373
Validation loss: 2.4590362585317593

Epoch: 6| Step: 13
Training loss: 2.68095986101381
Validation loss: 2.4446112489452343

Epoch: 42| Step: 0
Training loss: 2.6684015015236633
Validation loss: 2.4457733727491586

Epoch: 6| Step: 1
Training loss: 2.4932266986538
Validation loss: 2.4412376264852074

Epoch: 6| Step: 2
Training loss: 3.323106016944617
Validation loss: 2.4555726979798664

Epoch: 6| Step: 3
Training loss: 2.8517718512620167
Validation loss: 2.453652900853857

Epoch: 6| Step: 4
Training loss: 2.913049762231385
Validation loss: 2.476413076229099

Epoch: 6| Step: 5
Training loss: 2.6147288146458716
Validation loss: 2.4404538611963056

Epoch: 6| Step: 6
Training loss: 2.6632862917963425
Validation loss: 2.4679429082476436

Epoch: 6| Step: 7
Training loss: 3.1785901774776537
Validation loss: 2.4514355479632295

Epoch: 6| Step: 8
Training loss: 2.269656048230768
Validation loss: 2.4448129939944656

Epoch: 6| Step: 9
Training loss: 2.067332069376084
Validation loss: 2.4655721192246873

Epoch: 6| Step: 10
Training loss: 3.1918616279305514
Validation loss: 2.46070919823706

Epoch: 6| Step: 11
Training loss: 3.2278163588802995
Validation loss: 2.4569801541626424

Epoch: 6| Step: 12
Training loss: 2.925893376523015
Validation loss: 2.4429633895135363

Epoch: 6| Step: 13
Training loss: 2.5076345220139427
Validation loss: 2.4420246045718894

Epoch: 43| Step: 0
Training loss: 2.0507714843517486
Validation loss: 2.476157354059439

Epoch: 6| Step: 1
Training loss: 3.0195160898713866
Validation loss: 2.461375520304352

Epoch: 6| Step: 2
Training loss: 2.982218817272918
Validation loss: 2.4511985909068654

Epoch: 6| Step: 3
Training loss: 3.3525618194865556
Validation loss: 2.436887106081345

Epoch: 6| Step: 4
Training loss: 3.1953733853459667
Validation loss: 2.4470733579360493

Epoch: 6| Step: 5
Training loss: 3.2634420445238965
Validation loss: 2.4539095740404777

Epoch: 6| Step: 6
Training loss: 3.0106527022563587
Validation loss: 2.465925786895685

Epoch: 6| Step: 7
Training loss: 2.9423495903886994
Validation loss: 2.452418404075682

Epoch: 6| Step: 8
Training loss: 2.487524758987276
Validation loss: 2.4585606835050577

Epoch: 6| Step: 9
Training loss: 2.387835002783651
Validation loss: 2.457405870269553

Epoch: 6| Step: 10
Training loss: 2.0641834440179636
Validation loss: 2.4548411169630935

Epoch: 6| Step: 11
Training loss: 2.495358545383715
Validation loss: 2.4733294082109394

Epoch: 6| Step: 12
Training loss: 2.9487495099593235
Validation loss: 2.452079970991529

Epoch: 6| Step: 13
Training loss: 2.81977336094559
Validation loss: 2.444016234476808

Epoch: 44| Step: 0
Training loss: 2.8740552925732077
Validation loss: 2.456807791714421

Epoch: 6| Step: 1
Training loss: 2.2973086408386605
Validation loss: 2.4447531746000037

Epoch: 6| Step: 2
Training loss: 3.0894474204571813
Validation loss: 2.4613731247428934

Epoch: 6| Step: 3
Training loss: 2.848815096102628
Validation loss: 2.44491819187686

Epoch: 6| Step: 4
Training loss: 3.4954834815655276
Validation loss: 2.4626153604393513

Epoch: 6| Step: 5
Training loss: 2.5005811969378735
Validation loss: 2.4561626291139764

Epoch: 6| Step: 6
Training loss: 2.8935228823028436
Validation loss: 2.469591389117949

Epoch: 6| Step: 7
Training loss: 1.8684793257127157
Validation loss: 2.4435688128816238

Epoch: 6| Step: 8
Training loss: 3.17211251708462
Validation loss: 2.4606203873997816

Epoch: 6| Step: 9
Training loss: 2.86348391618403
Validation loss: 2.451556060717097

Epoch: 6| Step: 10
Training loss: 2.590743194939248
Validation loss: 2.4561258071254013

Epoch: 6| Step: 11
Training loss: 2.8788785894299576
Validation loss: 2.463454734192682

Epoch: 6| Step: 12
Training loss: 3.295593591226059
Validation loss: 2.4496939671191464

Epoch: 6| Step: 13
Training loss: 2.07202595754882
Validation loss: 2.4713157020543246

Epoch: 45| Step: 0
Training loss: 3.0346924416375427
Validation loss: 2.4568635820185714

Epoch: 6| Step: 1
Training loss: 2.220146921468323
Validation loss: 2.4552108396324126

Epoch: 6| Step: 2
Training loss: 3.117918612374074
Validation loss: 2.457269119817009

Epoch: 6| Step: 3
Training loss: 3.3970604923983427
Validation loss: 2.451223547383937

Epoch: 6| Step: 4
Training loss: 2.261363368864292
Validation loss: 2.4526307555400826

Epoch: 6| Step: 5
Training loss: 3.0889312515586145
Validation loss: 2.4527011941821057

Epoch: 6| Step: 6
Training loss: 2.796865196850182
Validation loss: 2.450644083057646

Epoch: 6| Step: 7
Training loss: 3.0490198655474403
Validation loss: 2.4585759971433876

Epoch: 6| Step: 8
Training loss: 1.8902187699148552
Validation loss: 2.448375373195207

Epoch: 6| Step: 9
Training loss: 3.0732249649481673
Validation loss: 2.461204340111921

Epoch: 6| Step: 10
Training loss: 3.123632818606187
Validation loss: 2.4564843883483403

Epoch: 6| Step: 11
Training loss: 2.4158702612330214
Validation loss: 2.4617377232016304

Epoch: 6| Step: 12
Training loss: 2.68415660036322
Validation loss: 2.444789067880381

Epoch: 6| Step: 13
Training loss: 2.5946517663640893
Validation loss: 2.4474031344766978

Epoch: 46| Step: 0
Training loss: 3.2526343013119825
Validation loss: 2.462271795572244

Epoch: 6| Step: 1
Training loss: 2.7405581945717685
Validation loss: 2.4485222843388423

Epoch: 6| Step: 2
Training loss: 2.592357951349467
Validation loss: 2.456684939222906

Epoch: 6| Step: 3
Training loss: 2.868727101751955
Validation loss: 2.454365050247127

Epoch: 6| Step: 4
Training loss: 2.3351840331848694
Validation loss: 2.448214479097996

Epoch: 6| Step: 5
Training loss: 3.3287123757276276
Validation loss: 2.4570601527628604

Epoch: 6| Step: 6
Training loss: 2.6142419437672095
Validation loss: 2.4476254435056117

Epoch: 6| Step: 7
Training loss: 3.0587580650107906
Validation loss: 2.4574037483378985

Epoch: 6| Step: 8
Training loss: 2.6380178006535404
Validation loss: 2.466685852629132

Epoch: 6| Step: 9
Training loss: 3.0140125134062132
Validation loss: 2.4490931877588284

Epoch: 6| Step: 10
Training loss: 2.723975323149369
Validation loss: 2.4619130420060755

Epoch: 6| Step: 11
Training loss: 2.6705585828396767
Validation loss: 2.4587697930782197

Epoch: 6| Step: 12
Training loss: 2.358285311242559
Validation loss: 2.4478949014136377

Epoch: 6| Step: 13
Training loss: 3.0926542557258134
Validation loss: 2.4313634868778515

Epoch: 47| Step: 0
Training loss: 2.7388871810869935
Validation loss: 2.4623219721102387

Epoch: 6| Step: 1
Training loss: 2.5816350912876653
Validation loss: 2.4517106498250216

Epoch: 6| Step: 2
Training loss: 3.3106273900146386
Validation loss: 2.4532419311002034

Epoch: 6| Step: 3
Training loss: 2.8862277840692343
Validation loss: 2.455645757705037

Epoch: 6| Step: 4
Training loss: 2.8212894850347987
Validation loss: 2.443944026077124

Epoch: 6| Step: 5
Training loss: 3.3275315019705594
Validation loss: 2.453767097691113

Epoch: 6| Step: 6
Training loss: 2.582982059920064
Validation loss: 2.4626103114698585

Epoch: 6| Step: 7
Training loss: 2.672346642343254
Validation loss: 2.456006360969458

Epoch: 6| Step: 8
Training loss: 2.5039271980159223
Validation loss: 2.4409848899242066

Epoch: 6| Step: 9
Training loss: 3.2516008982483164
Validation loss: 2.455932660605396

Epoch: 6| Step: 10
Training loss: 2.5863939326167067
Validation loss: 2.4455551970049285

Epoch: 6| Step: 11
Training loss: 2.961954470596851
Validation loss: 2.452673951116063

Epoch: 6| Step: 12
Training loss: 2.349146010069092
Validation loss: 2.458091011291605

Epoch: 6| Step: 13
Training loss: 2.2051148863465833
Validation loss: 2.452703560585161

Epoch: 48| Step: 0
Training loss: 2.4668125324250716
Validation loss: 2.45346976316625

Epoch: 6| Step: 1
Training loss: 2.80301899278938
Validation loss: 2.464641372856742

Epoch: 6| Step: 2
Training loss: 2.712124347604231
Validation loss: 2.4546453988202974

Epoch: 6| Step: 3
Training loss: 2.675736787524068
Validation loss: 2.4505540464702955

Epoch: 6| Step: 4
Training loss: 2.5737522842967717
Validation loss: 2.447787487537504

Epoch: 6| Step: 5
Training loss: 3.012266354186165
Validation loss: 2.457667402572641

Epoch: 6| Step: 6
Training loss: 3.231781882923714
Validation loss: 2.44773403752793

Epoch: 6| Step: 7
Training loss: 2.3922658039136677
Validation loss: 2.4460821344424173

Epoch: 6| Step: 8
Training loss: 2.945599367453918
Validation loss: 2.442509952973737

Epoch: 6| Step: 9
Training loss: 2.7462291005884234
Validation loss: 2.468554223032775

Epoch: 6| Step: 10
Training loss: 2.829275329330844
Validation loss: 2.4634447812155766

Epoch: 6| Step: 11
Training loss: 3.2052450467844924
Validation loss: 2.44676870545989

Epoch: 6| Step: 12
Training loss: 2.2936636344595063
Validation loss: 2.4417556521859693

Epoch: 6| Step: 13
Training loss: 3.2792653212355516
Validation loss: 2.424164834938413

Epoch: 49| Step: 0
Training loss: 3.596048167600937
Validation loss: 2.4616105281316605

Epoch: 6| Step: 1
Training loss: 2.5790800233091025
Validation loss: 2.441787417741484

Epoch: 6| Step: 2
Training loss: 2.847141465279769
Validation loss: 2.444194878107837

Epoch: 6| Step: 3
Training loss: 2.8521396836667177
Validation loss: 2.450884574836501

Epoch: 6| Step: 4
Training loss: 2.7817694361105327
Validation loss: 2.4576502671899254

Epoch: 6| Step: 5
Training loss: 2.457247629023041
Validation loss: 2.468951844115381

Epoch: 6| Step: 6
Training loss: 3.233175746446467
Validation loss: 2.4469683307588257

Epoch: 6| Step: 7
Training loss: 2.441495115570176
Validation loss: 2.4393051521500273

Epoch: 6| Step: 8
Training loss: 3.219853184356174
Validation loss: 2.455916326288616

Epoch: 6| Step: 9
Training loss: 2.154131083191498
Validation loss: 2.4481668261121983

Epoch: 6| Step: 10
Training loss: 2.5538660997914637
Validation loss: 2.4470678358437126

Epoch: 6| Step: 11
Training loss: 2.4537234214241046
Validation loss: 2.4514633182595107

Epoch: 6| Step: 12
Training loss: 3.05424695362627
Validation loss: 2.445547449636907

Epoch: 6| Step: 13
Training loss: 2.87264586553909
Validation loss: 2.4539914220603904

Epoch: 50| Step: 0
Training loss: 2.635549509271323
Validation loss: 2.461352996726807

Epoch: 6| Step: 1
Training loss: 3.031436875078861
Validation loss: 2.435723228539043

Epoch: 6| Step: 2
Training loss: 2.816943240459542
Validation loss: 2.4518491281251045

Epoch: 6| Step: 3
Training loss: 2.977566767407595
Validation loss: 2.460440451329646

Epoch: 6| Step: 4
Training loss: 3.1807708019585887
Validation loss: 2.4397770290515384

Epoch: 6| Step: 5
Training loss: 2.12678721948227
Validation loss: 2.464235642807529

Epoch: 6| Step: 6
Training loss: 2.2558184731478654
Validation loss: 2.44793002077613

Epoch: 6| Step: 7
Training loss: 3.4488427031702877
Validation loss: 2.4705436943366537

Epoch: 6| Step: 8
Training loss: 2.688754476475237
Validation loss: 2.4359782116964896

Epoch: 6| Step: 9
Training loss: 2.1449229954411115
Validation loss: 2.4677274015758557

Epoch: 6| Step: 10
Training loss: 3.0934569865483037
Validation loss: 2.4361983663546782

Epoch: 6| Step: 11
Training loss: 2.7055391325072486
Validation loss: 2.4540829292729516

Epoch: 6| Step: 12
Training loss: 3.0295857058771865
Validation loss: 2.435773354155758

Epoch: 6| Step: 13
Training loss: 2.675390952944753
Validation loss: 2.4525473981730173

Epoch: 51| Step: 0
Training loss: 2.610847834126659
Validation loss: 2.448361074776221

Epoch: 6| Step: 1
Training loss: 2.602425646860352
Validation loss: 2.441605698968334

Epoch: 6| Step: 2
Training loss: 2.903152784331607
Validation loss: 2.4418348403625405

Epoch: 6| Step: 3
Training loss: 2.479104840017923
Validation loss: 2.438984234703732

Epoch: 6| Step: 4
Training loss: 2.305554449956953
Validation loss: 2.457862723098113

Epoch: 6| Step: 5
Training loss: 3.0414734522099725
Validation loss: 2.4406240834809036

Epoch: 6| Step: 6
Training loss: 3.1049570873692116
Validation loss: 2.455893587711618

Epoch: 6| Step: 7
Training loss: 3.0595776374892365
Validation loss: 2.4431539663797155

Epoch: 6| Step: 8
Training loss: 2.6591306437418716
Validation loss: 2.438624802714021

Epoch: 6| Step: 9
Training loss: 2.9247918079328272
Validation loss: 2.444363100443885

Epoch: 6| Step: 10
Training loss: 2.9509217454804215
Validation loss: 2.4506032928391592

Epoch: 6| Step: 11
Training loss: 3.213561236766577
Validation loss: 2.4484952188401445

Epoch: 6| Step: 12
Training loss: 2.5959244770767187
Validation loss: 2.462634983655474

Epoch: 6| Step: 13
Training loss: 2.4505245737066854
Validation loss: 2.4402861184165365

Epoch: 52| Step: 0
Training loss: 2.5691596231313496
Validation loss: 2.4442282801669615

Epoch: 6| Step: 1
Training loss: 3.3289865444251747
Validation loss: 2.455934149143945

Epoch: 6| Step: 2
Training loss: 3.2438733968618694
Validation loss: 2.4408836464981225

Epoch: 6| Step: 3
Training loss: 3.074503826025448
Validation loss: 2.4583220449459247

Epoch: 6| Step: 4
Training loss: 3.176946184710543
Validation loss: 2.449638026086075

Epoch: 6| Step: 5
Training loss: 2.6455664813019775
Validation loss: 2.4478049506513133

Epoch: 6| Step: 6
Training loss: 2.6343683462183356
Validation loss: 2.459466758084028

Epoch: 6| Step: 7
Training loss: 2.357931238500051
Validation loss: 2.4548138814583687

Epoch: 6| Step: 8
Training loss: 2.877177367629143
Validation loss: 2.4541500080193073

Epoch: 6| Step: 9
Training loss: 3.3689526668585303
Validation loss: 2.45683704458229

Epoch: 6| Step: 10
Training loss: 2.208567936749466
Validation loss: 2.4529445088791495

Epoch: 6| Step: 11
Training loss: 2.6518708876398778
Validation loss: 2.4377668795743968

Epoch: 6| Step: 12
Training loss: 2.101287823846662
Validation loss: 2.4461213939277715

Epoch: 6| Step: 13
Training loss: 2.311180356814161
Validation loss: 2.455687236696523

Epoch: 53| Step: 0
Training loss: 2.5022460384865397
Validation loss: 2.4469860213014165

Epoch: 6| Step: 1
Training loss: 2.5079885640834254
Validation loss: 2.4619151267289276

Epoch: 6| Step: 2
Training loss: 2.6864306961852735
Validation loss: 2.43966037415661

Epoch: 6| Step: 3
Training loss: 2.195876514027134
Validation loss: 2.4430414256921438

Epoch: 6| Step: 4
Training loss: 2.7215876185595835
Validation loss: 2.439083937278345

Epoch: 6| Step: 5
Training loss: 2.6534745020988186
Validation loss: 2.4493601637601117

Epoch: 6| Step: 6
Training loss: 3.306122452523733
Validation loss: 2.4484242524148185

Epoch: 6| Step: 7
Training loss: 2.5961324022499714
Validation loss: 2.4576095682212507

Epoch: 6| Step: 8
Training loss: 3.1322983012981744
Validation loss: 2.455720073212601

Epoch: 6| Step: 9
Training loss: 3.4142532819084264
Validation loss: 2.438131495127061

Epoch: 6| Step: 10
Training loss: 3.057269397938269
Validation loss: 2.465964963851782

Epoch: 6| Step: 11
Training loss: 3.133791192738447
Validation loss: 2.439570011536089

Epoch: 6| Step: 12
Training loss: 2.47551967675131
Validation loss: 2.444672086919887

Epoch: 6| Step: 13
Training loss: 2.116038668829031
Validation loss: 2.4437898772188116

Epoch: 54| Step: 0
Training loss: 2.6928144737786246
Validation loss: 2.439754088567707

Epoch: 6| Step: 1
Training loss: 1.9802161663234275
Validation loss: 2.457474369391151

Epoch: 6| Step: 2
Training loss: 1.9774055341686159
Validation loss: 2.429009515910827

Epoch: 6| Step: 3
Training loss: 2.7459603028953103
Validation loss: 2.4398876041596886

Epoch: 6| Step: 4
Training loss: 2.6838883372926796
Validation loss: 2.4474818723030873

Epoch: 6| Step: 5
Training loss: 2.9364927472311275
Validation loss: 2.436147513901624

Epoch: 6| Step: 6
Training loss: 2.838931182360487
Validation loss: 2.452116976055262

Epoch: 6| Step: 7
Training loss: 2.3812930406099895
Validation loss: 2.4472301305016932

Epoch: 6| Step: 8
Training loss: 3.4475025646706405
Validation loss: 2.446829625997709

Epoch: 6| Step: 9
Training loss: 2.888957104325844
Validation loss: 2.459047659709314

Epoch: 6| Step: 10
Training loss: 3.2646975135594882
Validation loss: 2.4402015162227264

Epoch: 6| Step: 11
Training loss: 2.3861325007545635
Validation loss: 2.432687787792465

Epoch: 6| Step: 12
Training loss: 2.981448191326812
Validation loss: 2.4529790511567073

Epoch: 6| Step: 13
Training loss: 4.009453807362547
Validation loss: 2.4592977863256675

Epoch: 55| Step: 0
Training loss: 1.8193564462452823
Validation loss: 2.4522035894537515

Epoch: 6| Step: 1
Training loss: 2.782759524681317
Validation loss: 2.449429692216087

Epoch: 6| Step: 2
Training loss: 2.8813353685156775
Validation loss: 2.4437540626287544

Epoch: 6| Step: 3
Training loss: 3.3520763510154583
Validation loss: 2.4451984618876725

Epoch: 6| Step: 4
Training loss: 2.5015545779977817
Validation loss: 2.440515241896101

Epoch: 6| Step: 5
Training loss: 2.9206447357222767
Validation loss: 2.433500780195547

Epoch: 6| Step: 6
Training loss: 2.631314992215268
Validation loss: 2.454798062910937

Epoch: 6| Step: 7
Training loss: 2.628148053189478
Validation loss: 2.4458024945003936

Epoch: 6| Step: 8
Training loss: 3.0481067221873563
Validation loss: 2.442826689020435

Epoch: 6| Step: 9
Training loss: 2.801718582937061
Validation loss: 2.43888915627523

Epoch: 6| Step: 10
Training loss: 3.156825702397873
Validation loss: 2.436049764853117

Epoch: 6| Step: 11
Training loss: 3.2134388186392617
Validation loss: 2.436040992229862

Epoch: 6| Step: 12
Training loss: 2.2916065439371516
Validation loss: 2.458727596599687

Epoch: 6| Step: 13
Training loss: 2.7106699522942654
Validation loss: 2.4472887904791025

Epoch: 56| Step: 0
Training loss: 2.566786553526558
Validation loss: 2.448077079074412

Epoch: 6| Step: 1
Training loss: 2.218923535075172
Validation loss: 2.4480975256832234

Epoch: 6| Step: 2
Training loss: 2.788810312532846
Validation loss: 2.4247934773829

Epoch: 6| Step: 3
Training loss: 3.358380973484325
Validation loss: 2.440985348882743

Epoch: 6| Step: 4
Training loss: 2.9042901434753023
Validation loss: 2.4278986462472867

Epoch: 6| Step: 5
Training loss: 3.1351778228800837
Validation loss: 2.443951124492964

Epoch: 6| Step: 6
Training loss: 2.934052737479099
Validation loss: 2.452282721987493

Epoch: 6| Step: 7
Training loss: 2.6774138210756866
Validation loss: 2.448639263009027

Epoch: 6| Step: 8
Training loss: 3.0756775086387056
Validation loss: 2.4497330729666196

Epoch: 6| Step: 9
Training loss: 2.168912994679872
Validation loss: 2.446773741017272

Epoch: 6| Step: 10
Training loss: 3.022895863043203
Validation loss: 2.455378705566487

Epoch: 6| Step: 11
Training loss: 2.1327088718600566
Validation loss: 2.4567538508042657

Epoch: 6| Step: 12
Training loss: 3.2081763654350177
Validation loss: 2.444792933593728

Epoch: 6| Step: 13
Training loss: 2.472466676986979
Validation loss: 2.4452349194981484

Epoch: 57| Step: 0
Training loss: 2.616768783552943
Validation loss: 2.464326486662322

Epoch: 6| Step: 1
Training loss: 2.372194239024265
Validation loss: 2.4508335072322978

Epoch: 6| Step: 2
Training loss: 2.4708032881747144
Validation loss: 2.4496652034950017

Epoch: 6| Step: 3
Training loss: 2.606552333356904
Validation loss: 2.453044768035688

Epoch: 6| Step: 4
Training loss: 3.2120638540151263
Validation loss: 2.443818210656632

Epoch: 6| Step: 5
Training loss: 2.9652864831761416
Validation loss: 2.452940985750617

Epoch: 6| Step: 6
Training loss: 2.563750729386381
Validation loss: 2.4321898440634317

Epoch: 6| Step: 7
Training loss: 3.1227543200605825
Validation loss: 2.4550037388916897

Epoch: 6| Step: 8
Training loss: 3.591245093390422
Validation loss: 2.451715484923572

Epoch: 6| Step: 9
Training loss: 2.0183792813166437
Validation loss: 2.454093109298198

Epoch: 6| Step: 10
Training loss: 2.548068650319438
Validation loss: 2.4599464557842183

Epoch: 6| Step: 11
Training loss: 2.9056960367539846
Validation loss: 2.446875007375951

Epoch: 6| Step: 12
Training loss: 2.8472114707516347
Validation loss: 2.4581694474471067

Epoch: 6| Step: 13
Training loss: 2.9371832818890775
Validation loss: 2.472404687632575

Epoch: 58| Step: 0
Training loss: 2.8340400674554465
Validation loss: 2.462973258115311

Epoch: 6| Step: 1
Training loss: 3.335902479644561
Validation loss: 2.4515807672907046

Epoch: 6| Step: 2
Training loss: 2.838760190245842
Validation loss: 2.446947174334233

Epoch: 6| Step: 3
Training loss: 2.661859669942392
Validation loss: 2.4678953759827578

Epoch: 6| Step: 4
Training loss: 3.113419399283521
Validation loss: 2.4530402940221228

Epoch: 6| Step: 5
Training loss: 2.408176790141389
Validation loss: 2.4527640985449577

Epoch: 6| Step: 6
Training loss: 3.287868980906616
Validation loss: 2.4544648638756517

Epoch: 6| Step: 7
Training loss: 2.73317330248598
Validation loss: 2.463973277692564

Epoch: 6| Step: 8
Training loss: 2.389381035176727
Validation loss: 2.4518903744008242

Epoch: 6| Step: 9
Training loss: 3.3665079727792317
Validation loss: 2.4649570955752913

Epoch: 6| Step: 10
Training loss: 2.6260318544581027
Validation loss: 2.4538441038974153

Epoch: 6| Step: 11
Training loss: 2.2958392448372265
Validation loss: 2.4432149560637377

Epoch: 6| Step: 12
Training loss: 2.3259840984768547
Validation loss: 2.454018546033607

Epoch: 6| Step: 13
Training loss: 2.1051219874031397
Validation loss: 2.4434644592020094

Epoch: 59| Step: 0
Training loss: 2.4579261399447763
Validation loss: 2.443086651828666

Epoch: 6| Step: 1
Training loss: 2.8726652865751428
Validation loss: 2.447249843562012

Epoch: 6| Step: 2
Training loss: 3.102480966169942
Validation loss: 2.454403298290679

Epoch: 6| Step: 3
Training loss: 3.21743999600127
Validation loss: 2.4502277978232705

Epoch: 6| Step: 4
Training loss: 2.8581443598108467
Validation loss: 2.444229585990875

Epoch: 6| Step: 5
Training loss: 2.652544915684581
Validation loss: 2.437208307028515

Epoch: 6| Step: 6
Training loss: 2.6932717378893964
Validation loss: 2.4552538180548447

Epoch: 6| Step: 7
Training loss: 2.7968449084831564
Validation loss: 2.4509911213343805

Epoch: 6| Step: 8
Training loss: 3.30530890355758
Validation loss: 2.443983753653375

Epoch: 6| Step: 9
Training loss: 2.53374414835679
Validation loss: 2.455126098066995

Epoch: 6| Step: 10
Training loss: 2.7299991143752678
Validation loss: 2.446829456263865

Epoch: 6| Step: 11
Training loss: 2.741281908704525
Validation loss: 2.449813263222189

Epoch: 6| Step: 12
Training loss: 2.5945734762071204
Validation loss: 2.4511205027475795

Epoch: 6| Step: 13
Training loss: 2.0714716131690145
Validation loss: 2.453523553195201

Epoch: 60| Step: 0
Training loss: 2.2551445955662404
Validation loss: 2.445069947188286

Epoch: 6| Step: 1
Training loss: 2.9846520420125437
Validation loss: 2.4542261320743264

Epoch: 6| Step: 2
Training loss: 2.6328962635332953
Validation loss: 2.437733935838117

Epoch: 6| Step: 3
Training loss: 3.203554599144854
Validation loss: 2.456063187184343

Epoch: 6| Step: 4
Training loss: 2.6721728421004287
Validation loss: 2.4413355059474795

Epoch: 6| Step: 5
Training loss: 2.7331016845546077
Validation loss: 2.4581188690953524

Epoch: 6| Step: 6
Training loss: 2.945389561947767
Validation loss: 2.4498632821064086

Epoch: 6| Step: 7
Training loss: 2.2517354418314777
Validation loss: 2.4245057678472786

Epoch: 6| Step: 8
Training loss: 3.4485415596379005
Validation loss: 2.4451014867263163

Epoch: 6| Step: 9
Training loss: 3.191499332858803
Validation loss: 2.4581211577994613

Epoch: 6| Step: 10
Training loss: 2.184192445737016
Validation loss: 2.4471311877735227

Epoch: 6| Step: 11
Training loss: 3.1114001556123774
Validation loss: 2.4454503279201867

Epoch: 6| Step: 12
Training loss: 2.499197831204947
Validation loss: 2.451677233637791

Epoch: 6| Step: 13
Training loss: 2.6072978815321415
Validation loss: 2.460118671795948

Epoch: 61| Step: 0
Training loss: 2.5707713358208037
Validation loss: 2.4517140931606716

Epoch: 6| Step: 1
Training loss: 2.7948751279065798
Validation loss: 2.4411078257631376

Epoch: 6| Step: 2
Training loss: 1.8770431830388004
Validation loss: 2.4423823107685174

Epoch: 6| Step: 3
Training loss: 2.7202526631531128
Validation loss: 2.438040231472787

Epoch: 6| Step: 4
Training loss: 3.2568934765813036
Validation loss: 2.451822898194295

Epoch: 6| Step: 5
Training loss: 2.416525858580704
Validation loss: 2.442710845153246

Epoch: 6| Step: 6
Training loss: 2.719207286743699
Validation loss: 2.4397730886668096

Epoch: 6| Step: 7
Training loss: 3.15177418835214
Validation loss: 2.4532286783598423

Epoch: 6| Step: 8
Training loss: 2.9326866159468037
Validation loss: 2.446279312155949

Epoch: 6| Step: 9
Training loss: 3.157762825871051
Validation loss: 2.4550170405276224

Epoch: 6| Step: 10
Training loss: 2.574315811665958
Validation loss: 2.4367197016758224

Epoch: 6| Step: 11
Training loss: 2.2402909927729935
Validation loss: 2.452266948792193

Epoch: 6| Step: 12
Training loss: 2.804961719761718
Validation loss: 2.454457495054814

Epoch: 6| Step: 13
Training loss: 3.679239752026642
Validation loss: 2.4611852544274324

Epoch: 62| Step: 0
Training loss: 2.5758262790010287
Validation loss: 2.4301670620581874

Epoch: 6| Step: 1
Training loss: 3.270857857452266
Validation loss: 2.441399472856857

Epoch: 6| Step: 2
Training loss: 2.5390497295351926
Validation loss: 2.4348412804675026

Epoch: 6| Step: 3
Training loss: 2.4509510685531635
Validation loss: 2.4508756743529774

Epoch: 6| Step: 4
Training loss: 2.544060960363164
Validation loss: 2.4531863301390198

Epoch: 6| Step: 5
Training loss: 2.773179764927971
Validation loss: 2.4361053549357803

Epoch: 6| Step: 6
Training loss: 2.3973941086663384
Validation loss: 2.4444963349322144

Epoch: 6| Step: 7
Training loss: 2.5396590720428347
Validation loss: 2.445626424362882

Epoch: 6| Step: 8
Training loss: 2.877425953221381
Validation loss: 2.460399904795123

Epoch: 6| Step: 9
Training loss: 2.5732625710767625
Validation loss: 2.437254351408395

Epoch: 6| Step: 10
Training loss: 3.239362474049678
Validation loss: 2.4580172868664087

Epoch: 6| Step: 11
Training loss: 2.864328897909664
Validation loss: 2.444101408442924

Epoch: 6| Step: 12
Training loss: 2.6641805404510257
Validation loss: 2.441650804703811

Epoch: 6| Step: 13
Training loss: 3.7471940032849105
Validation loss: 2.4437709377233103

Epoch: 63| Step: 0
Training loss: 2.7151877205936876
Validation loss: 2.4601273543917617

Epoch: 6| Step: 1
Training loss: 2.793163116734465
Validation loss: 2.447701535865919

Epoch: 6| Step: 2
Training loss: 2.7212318405085156
Validation loss: 2.4524243489856525

Epoch: 6| Step: 3
Training loss: 2.939225684203352
Validation loss: 2.4438733103795993

Epoch: 6| Step: 4
Training loss: 3.384968341583559
Validation loss: 2.470947362502802

Epoch: 6| Step: 5
Training loss: 2.339565152250207
Validation loss: 2.4434839707747553

Epoch: 6| Step: 6
Training loss: 2.955753186278137
Validation loss: 2.4447607834448135

Epoch: 6| Step: 7
Training loss: 2.865728937591621
Validation loss: 2.4391987641706714

Epoch: 6| Step: 8
Training loss: 2.730478878848345
Validation loss: 2.454096609879985

Epoch: 6| Step: 9
Training loss: 2.863900360995466
Validation loss: 2.4463205538337207

Epoch: 6| Step: 10
Training loss: 2.280266327612042
Validation loss: 2.451042207096435

Epoch: 6| Step: 11
Training loss: 2.637405961516176
Validation loss: 2.450286544021878

Epoch: 6| Step: 12
Training loss: 3.0120192401367727
Validation loss: 2.4597775649205045

Epoch: 6| Step: 13
Training loss: 2.587727920887647
Validation loss: 2.448236491077745

Epoch: 64| Step: 0
Training loss: 2.8383051129153585
Validation loss: 2.439213060594588

Epoch: 6| Step: 1
Training loss: 2.5973136044868532
Validation loss: 2.4329319997036234

Epoch: 6| Step: 2
Training loss: 2.5795990400206366
Validation loss: 2.455903842697073

Epoch: 6| Step: 3
Training loss: 2.327045062190688
Validation loss: 2.456486737539867

Epoch: 6| Step: 4
Training loss: 3.1287021832349904
Validation loss: 2.441494889813934

Epoch: 6| Step: 5
Training loss: 2.8948982613562633
Validation loss: 2.4452517083629144

Epoch: 6| Step: 6
Training loss: 2.4114668140852715
Validation loss: 2.447941068389342

Epoch: 6| Step: 7
Training loss: 2.6143344188206252
Validation loss: 2.452533709969548

Epoch: 6| Step: 8
Training loss: 2.2271969610714186
Validation loss: 2.4490857629982346

Epoch: 6| Step: 9
Training loss: 3.483260588061252
Validation loss: 2.4517909055800056

Epoch: 6| Step: 10
Training loss: 3.0801480998313266
Validation loss: 2.4540603742815676

Epoch: 6| Step: 11
Training loss: 2.7413631406467265
Validation loss: 2.4517194233677992

Epoch: 6| Step: 12
Training loss: 3.2227938535963356
Validation loss: 2.456617461132911

Epoch: 6| Step: 13
Training loss: 2.374515986061223
Validation loss: 2.4464133110093527

Epoch: 65| Step: 0
Training loss: 3.14404444747063
Validation loss: 2.454107590037135

Epoch: 6| Step: 1
Training loss: 3.337370017731613
Validation loss: 2.4482874065699867

Epoch: 6| Step: 2
Training loss: 2.2180087503479045
Validation loss: 2.4505256250971974

Epoch: 6| Step: 3
Training loss: 3.020600794468858
Validation loss: 2.446152184192064

Epoch: 6| Step: 4
Training loss: 2.461231420009959
Validation loss: 2.4453720457177637

Epoch: 6| Step: 5
Training loss: 3.147221559990408
Validation loss: 2.4485963721244874

Epoch: 6| Step: 6
Training loss: 2.128523093924717
Validation loss: 2.4312786332483203

Epoch: 6| Step: 7
Training loss: 3.188461457898756
Validation loss: 2.44957323612052

Epoch: 6| Step: 8
Training loss: 2.93615464589559
Validation loss: 2.4445796475009276

Epoch: 6| Step: 9
Training loss: 2.8122895903824237
Validation loss: 2.445762752442468

Epoch: 6| Step: 10
Training loss: 2.3795808483928607
Validation loss: 2.451836493125297

Epoch: 6| Step: 11
Training loss: 2.684657878425915
Validation loss: 2.4662792001127856

Epoch: 6| Step: 12
Training loss: 2.6071808321402434
Validation loss: 2.4474873651798923

Epoch: 6| Step: 13
Training loss: 2.3889229892790715
Validation loss: 2.4613929578384184

Epoch: 66| Step: 0
Training loss: 3.341801012974133
Validation loss: 2.431838224648354

Epoch: 6| Step: 1
Training loss: 2.755947963228876
Validation loss: 2.455895645706077

Epoch: 6| Step: 2
Training loss: 2.9164175381302773
Validation loss: 2.4660276400732144

Epoch: 6| Step: 3
Training loss: 3.1769900115435155
Validation loss: 2.4390734970074943

Epoch: 6| Step: 4
Training loss: 1.9992007208156928
Validation loss: 2.431116076722789

Epoch: 6| Step: 5
Training loss: 2.4043702548966612
Validation loss: 2.4371038287950477

Epoch: 6| Step: 6
Training loss: 3.005577941767288
Validation loss: 2.4526906963767123

Epoch: 6| Step: 7
Training loss: 2.977230127309112
Validation loss: 2.433043621365789

Epoch: 6| Step: 8
Training loss: 2.544382478782178
Validation loss: 2.4523111527903296

Epoch: 6| Step: 9
Training loss: 2.7552159867543944
Validation loss: 2.4479184013016697

Epoch: 6| Step: 10
Training loss: 2.474343927684072
Validation loss: 2.44268118277411

Epoch: 6| Step: 11
Training loss: 2.5033835402566034
Validation loss: 2.4489564567590096

Epoch: 6| Step: 12
Training loss: 3.0038843439342666
Validation loss: 2.4709689831468866

Epoch: 6| Step: 13
Training loss: 2.7389787555607445
Validation loss: 2.4271039803890857

Epoch: 67| Step: 0
Training loss: 2.9019034091430567
Validation loss: 2.4488966255168636

Epoch: 6| Step: 1
Training loss: 2.734454170170831
Validation loss: 2.4701003979917253

Epoch: 6| Step: 2
Training loss: 3.0957824504328006
Validation loss: 2.4487251341305902

Epoch: 6| Step: 3
Training loss: 3.176876540828123
Validation loss: 2.456552875073632

Epoch: 6| Step: 4
Training loss: 2.45454725111308
Validation loss: 2.447045601726788

Epoch: 6| Step: 5
Training loss: 2.919180867251973
Validation loss: 2.4287659651270124

Epoch: 6| Step: 6
Training loss: 2.234734352931871
Validation loss: 2.4416589345462745

Epoch: 6| Step: 7
Training loss: 2.917255360366221
Validation loss: 2.4509830982789285

Epoch: 6| Step: 8
Training loss: 3.0157655673298422
Validation loss: 2.4413736462456703

Epoch: 6| Step: 9
Training loss: 2.7270405085275407
Validation loss: 2.4540774469801887

Epoch: 6| Step: 10
Training loss: 2.47716469167231
Validation loss: 2.45832182803485

Epoch: 6| Step: 11
Training loss: 2.0144778987063177
Validation loss: 2.4456428950173708

Epoch: 6| Step: 12
Training loss: 2.8540685223785585
Validation loss: 2.454895962490883

Epoch: 6| Step: 13
Training loss: 3.124354639172051
Validation loss: 2.439239648935055

Epoch: 68| Step: 0
Training loss: 2.9895052129837523
Validation loss: 2.459164071505799

Epoch: 6| Step: 1
Training loss: 2.5717138858728075
Validation loss: 2.4477090611827856

Epoch: 6| Step: 2
Training loss: 2.783860941998498
Validation loss: 2.4577838401077075

Epoch: 6| Step: 3
Training loss: 2.707811647691279
Validation loss: 2.4287057420473386

Epoch: 6| Step: 4
Training loss: 3.23605892555898
Validation loss: 2.4383696631472316

Epoch: 6| Step: 5
Training loss: 2.3451264472169253
Validation loss: 2.454242832795783

Epoch: 6| Step: 6
Training loss: 3.0779645074355884
Validation loss: 2.4471070077532033

Epoch: 6| Step: 7
Training loss: 3.212619313202624
Validation loss: 2.442967643768893

Epoch: 6| Step: 8
Training loss: 2.6399006047466815
Validation loss: 2.447550718296143

Epoch: 6| Step: 9
Training loss: 2.8171091247590643
Validation loss: 2.450503873252565

Epoch: 6| Step: 10
Training loss: 2.617440282655989
Validation loss: 2.4466191480338026

Epoch: 6| Step: 11
Training loss: 2.8258369421328875
Validation loss: 2.4579089615161287

Epoch: 6| Step: 12
Training loss: 2.354912383764007
Validation loss: 2.4487588156892723

Epoch: 6| Step: 13
Training loss: 2.3867372302949126
Validation loss: 2.446228817034233

Epoch: 69| Step: 0
Training loss: 2.2726361412504152
Validation loss: 2.4460374416151387

Epoch: 6| Step: 1
Training loss: 2.8443405041313854
Validation loss: 2.452778485223261

Epoch: 6| Step: 2
Training loss: 2.304160261461439
Validation loss: 2.4588348140671292

Epoch: 6| Step: 3
Training loss: 3.331567550897236
Validation loss: 2.4337043816726602

Epoch: 6| Step: 4
Training loss: 2.9096381014183854
Validation loss: 2.4326400055936124

Epoch: 6| Step: 5
Training loss: 2.7416701304250557
Validation loss: 2.4409309527680905

Epoch: 6| Step: 6
Training loss: 2.5296245112361397
Validation loss: 2.450037797356285

Epoch: 6| Step: 7
Training loss: 2.6813290742182407
Validation loss: 2.4369592079863103

Epoch: 6| Step: 8
Training loss: 3.47950630281483
Validation loss: 2.4364393159848

Epoch: 6| Step: 9
Training loss: 2.815798372441316
Validation loss: 2.448256464100041

Epoch: 6| Step: 10
Training loss: 2.421904532960055
Validation loss: 2.4500779262787664

Epoch: 6| Step: 11
Training loss: 3.2862832838413785
Validation loss: 2.444744630350786

Epoch: 6| Step: 12
Training loss: 2.396542673559945
Validation loss: 2.461218083213035

Epoch: 6| Step: 13
Training loss: 2.1646075612371494
Validation loss: 2.4512319717848263

Epoch: 70| Step: 0
Training loss: 3.0520843575294694
Validation loss: 2.4611720236270203

Epoch: 6| Step: 1
Training loss: 3.287402243665614
Validation loss: 2.437824101510544

Epoch: 6| Step: 2
Training loss: 2.655892381716872
Validation loss: 2.4465697633133923

Epoch: 6| Step: 3
Training loss: 2.592516502394063
Validation loss: 2.4449702963085937

Epoch: 6| Step: 4
Training loss: 2.607965785527614
Validation loss: 2.436866565411142

Epoch: 6| Step: 5
Training loss: 3.014047318692732
Validation loss: 2.447960361011331

Epoch: 6| Step: 6
Training loss: 2.211973345301038
Validation loss: 2.441500372009611

Epoch: 6| Step: 7
Training loss: 3.1817809016037772
Validation loss: 2.454293339565074

Epoch: 6| Step: 8
Training loss: 2.3078804269555455
Validation loss: 2.4363906698246813

Epoch: 6| Step: 9
Training loss: 2.604997446421362
Validation loss: 2.446295681477535

Epoch: 6| Step: 10
Training loss: 3.06395951350383
Validation loss: 2.4455984032923967

Epoch: 6| Step: 11
Training loss: 2.5162532803722057
Validation loss: 2.4434932674907266

Epoch: 6| Step: 12
Training loss: 2.916453998623401
Validation loss: 2.443733533519428

Epoch: 6| Step: 13
Training loss: 2.387266704884786
Validation loss: 2.4465098328356696

Epoch: 71| Step: 0
Training loss: 2.783840387570163
Validation loss: 2.4437828318359465

Epoch: 6| Step: 1
Training loss: 3.168471290625661
Validation loss: 2.4511181546884053

Epoch: 6| Step: 2
Training loss: 3.004411632551788
Validation loss: 2.4548491900686025

Epoch: 6| Step: 3
Training loss: 2.7364910548276704
Validation loss: 2.444183585956346

Epoch: 6| Step: 4
Training loss: 2.746020993046209
Validation loss: 2.4309248018445717

Epoch: 6| Step: 5
Training loss: 2.5004717381769446
Validation loss: 2.4481170244156196

Epoch: 6| Step: 6
Training loss: 3.0888151634193863
Validation loss: 2.4452819990058883

Epoch: 6| Step: 7
Training loss: 2.3405775852264754
Validation loss: 2.451788681546099

Epoch: 6| Step: 8
Training loss: 1.5904344215964403
Validation loss: 2.4442975707302557

Epoch: 6| Step: 9
Training loss: 2.6882901471763185
Validation loss: 2.4369169610187176

Epoch: 6| Step: 10
Training loss: 2.660007377413508
Validation loss: 2.4461813789868425

Epoch: 6| Step: 11
Training loss: 3.342968145211297
Validation loss: 2.4516173040989266

Epoch: 6| Step: 12
Training loss: 3.048636685213201
Validation loss: 2.452312929965912

Epoch: 6| Step: 13
Training loss: 2.5005357168324522
Validation loss: 2.431449609113263

Epoch: 72| Step: 0
Training loss: 3.6120916274352446
Validation loss: 2.4447515743906534

Epoch: 6| Step: 1
Training loss: 3.106149351765171
Validation loss: 2.452406145201412

Epoch: 6| Step: 2
Training loss: 3.395237189702778
Validation loss: 2.4433685022157765

Epoch: 6| Step: 3
Training loss: 2.3265523014908274
Validation loss: 2.4494923817884646

Epoch: 6| Step: 4
Training loss: 2.6505523609803183
Validation loss: 2.4283887899700276

Epoch: 6| Step: 5
Training loss: 2.8874844373143245
Validation loss: 2.457361775652453

Epoch: 6| Step: 6
Training loss: 2.4752012537040073
Validation loss: 2.4504100337782857

Epoch: 6| Step: 7
Training loss: 2.824436543404671
Validation loss: 2.429833078509077

Epoch: 6| Step: 8
Training loss: 1.4668531140392018
Validation loss: 2.4481209262378365

Epoch: 6| Step: 9
Training loss: 2.7097659699009617
Validation loss: 2.4584267043924726

Epoch: 6| Step: 10
Training loss: 2.3166730189979607
Validation loss: 2.4456123074692564

Epoch: 6| Step: 11
Training loss: 2.892848793569421
Validation loss: 2.4467764494848607

Epoch: 6| Step: 12
Training loss: 2.6554704307557566
Validation loss: 2.43924634484625

Epoch: 6| Step: 13
Training loss: 2.9421889845509566
Validation loss: 2.4550740713362647

Epoch: 73| Step: 0
Training loss: 2.2092251566316397
Validation loss: 2.4486543418820665

Epoch: 6| Step: 1
Training loss: 2.8198456523130218
Validation loss: 2.446256225672083

Epoch: 6| Step: 2
Training loss: 2.617402116317051
Validation loss: 2.4481559308341225

Epoch: 6| Step: 3
Training loss: 2.6209063626431153
Validation loss: 2.449108262266959

Epoch: 6| Step: 4
Training loss: 3.2365588495569653
Validation loss: 2.441117271203861

Epoch: 6| Step: 5
Training loss: 3.3862256457810824
Validation loss: 2.4619992201862284

Epoch: 6| Step: 6
Training loss: 3.2042237420986557
Validation loss: 2.4493886462789423

Epoch: 6| Step: 7
Training loss: 2.508948713414726
Validation loss: 2.449568800768807

Epoch: 6| Step: 8
Training loss: 2.4030276433820728
Validation loss: 2.44582464453447

Epoch: 6| Step: 9
Training loss: 3.1265823935543553
Validation loss: 2.4450599896225653

Epoch: 6| Step: 10
Training loss: 2.3635945766596564
Validation loss: 2.4579496925539077

Epoch: 6| Step: 11
Training loss: 2.470993567723509
Validation loss: 2.445225994780707

Epoch: 6| Step: 12
Training loss: 2.2892688228595284
Validation loss: 2.4545014000530987

Epoch: 6| Step: 13
Training loss: 3.3517611073511717
Validation loss: 2.444603045025551

Epoch: 74| Step: 0
Training loss: 3.016939341268167
Validation loss: 2.450602503013651

Epoch: 6| Step: 1
Training loss: 2.582040853092959
Validation loss: 2.446246444281459

Epoch: 6| Step: 2
Training loss: 3.013729309998307
Validation loss: 2.4336120418322746

Epoch: 6| Step: 3
Training loss: 3.331255519497362
Validation loss: 2.457289578619496

Epoch: 6| Step: 4
Training loss: 2.913564521846294
Validation loss: 2.455710512730974

Epoch: 6| Step: 5
Training loss: 2.4310624626417203
Validation loss: 2.4497519517168684

Epoch: 6| Step: 6
Training loss: 2.1493885501524304
Validation loss: 2.437735393423297

Epoch: 6| Step: 7
Training loss: 2.5349837657401117
Validation loss: 2.4499664225233087

Epoch: 6| Step: 8
Training loss: 2.4452021272265334
Validation loss: 2.45110852814523

Epoch: 6| Step: 9
Training loss: 3.3401552646205626
Validation loss: 2.4541045929845593

Epoch: 6| Step: 10
Training loss: 2.9217604344392925
Validation loss: 2.4467695405291114

Epoch: 6| Step: 11
Training loss: 2.426312325496141
Validation loss: 2.457142619915806

Epoch: 6| Step: 12
Training loss: 2.6862832797169247
Validation loss: 2.4460685007170095

Epoch: 6| Step: 13
Training loss: 2.657245404598301
Validation loss: 2.439265842865006

Epoch: 75| Step: 0
Training loss: 2.929607420780569
Validation loss: 2.447441253541972

Epoch: 6| Step: 1
Training loss: 2.1658457765983785
Validation loss: 2.4462935886836923

Epoch: 6| Step: 2
Training loss: 2.950463766077551
Validation loss: 2.453216826909167

Epoch: 6| Step: 3
Training loss: 2.706027286518841
Validation loss: 2.4493716863829538

Epoch: 6| Step: 4
Training loss: 1.9556705823336467
Validation loss: 2.4363185900276703

Epoch: 6| Step: 5
Training loss: 2.7423002649145554
Validation loss: 2.4471933899115124

Epoch: 6| Step: 6
Training loss: 1.9660071991471417
Validation loss: 2.4592890601462063

Epoch: 6| Step: 7
Training loss: 2.6203089987561397
Validation loss: 2.4514542766076755

Epoch: 6| Step: 8
Training loss: 2.9183208860795995
Validation loss: 2.437844666712427

Epoch: 6| Step: 9
Training loss: 2.92351840716185
Validation loss: 2.4431892965951962

Epoch: 6| Step: 10
Training loss: 3.251329590183669
Validation loss: 2.4605099662320877

Epoch: 6| Step: 11
Training loss: 2.892403710031115
Validation loss: 2.439116275242346

Epoch: 6| Step: 12
Training loss: 3.063626296348691
Validation loss: 2.443390037441475

Epoch: 6| Step: 13
Training loss: 3.2820211321832113
Validation loss: 2.4375604049354096

Epoch: 76| Step: 0
Training loss: 2.719987697152756
Validation loss: 2.4374712681240447

Epoch: 6| Step: 1
Training loss: 2.6624810231566785
Validation loss: 2.4542054033000102

Epoch: 6| Step: 2
Training loss: 2.973632972855086
Validation loss: 2.45850692964802

Epoch: 6| Step: 3
Training loss: 2.7109309919207725
Validation loss: 2.451378527672493

Epoch: 6| Step: 4
Training loss: 3.10375960239088
Validation loss: 2.450323769725605

Epoch: 6| Step: 5
Training loss: 2.283066744683815
Validation loss: 2.4582081222836014

Epoch: 6| Step: 6
Training loss: 2.862049123911591
Validation loss: 2.4508127110600713

Epoch: 6| Step: 7
Training loss: 3.6393930864023902
Validation loss: 2.446343675864715

Epoch: 6| Step: 8
Training loss: 2.1558645152621496
Validation loss: 2.464756300399567

Epoch: 6| Step: 9
Training loss: 2.9076305104925
Validation loss: 2.444095716005661

Epoch: 6| Step: 10
Training loss: 2.158302988357006
Validation loss: 2.431861411637681

Epoch: 6| Step: 11
Training loss: 2.806017886887174
Validation loss: 2.464105878938116

Epoch: 6| Step: 12
Training loss: 2.875254412465333
Validation loss: 2.4650181906099515

Epoch: 6| Step: 13
Training loss: 2.1201495744014083
Validation loss: 2.45523169252573

Epoch: 77| Step: 0
Training loss: 2.514194152685158
Validation loss: 2.459187433995608

Epoch: 6| Step: 1
Training loss: 2.712538013103997
Validation loss: 2.445815858755633

Epoch: 6| Step: 2
Training loss: 2.107525275860556
Validation loss: 2.436350599567041

Epoch: 6| Step: 3
Training loss: 2.469527689452412
Validation loss: 2.4510739846091423

Epoch: 6| Step: 4
Training loss: 2.9425095392557084
Validation loss: 2.448554657842214

Epoch: 6| Step: 5
Training loss: 2.6730216616442495
Validation loss: 2.4284769210504025

Epoch: 6| Step: 6
Training loss: 2.8973478752271027
Validation loss: 2.471937013174422

Epoch: 6| Step: 7
Training loss: 2.2953367726683114
Validation loss: 2.44825021482548

Epoch: 6| Step: 8
Training loss: 1.9044986246293827
Validation loss: 2.4495647714781983

Epoch: 6| Step: 9
Training loss: 3.5389269535473526
Validation loss: 2.438613097902643

Epoch: 6| Step: 10
Training loss: 2.986418818112713
Validation loss: 2.4377126829693427

Epoch: 6| Step: 11
Training loss: 3.2200923453884966
Validation loss: 2.4627641421567215

Epoch: 6| Step: 12
Training loss: 2.9718784913885905
Validation loss: 2.4593989565636654

Epoch: 6| Step: 13
Training loss: 3.003668608275121
Validation loss: 2.4561788866426566

Epoch: 78| Step: 0
Training loss: 2.6402150575145877
Validation loss: 2.4517728779861376

Epoch: 6| Step: 1
Training loss: 2.36653949189899
Validation loss: 2.425229972884469

Epoch: 6| Step: 2
Training loss: 2.6023440175212356
Validation loss: 2.4402497948822495

Epoch: 6| Step: 3
Training loss: 2.6662379357288115
Validation loss: 2.450153114836563

Epoch: 6| Step: 4
Training loss: 2.8114492360877494
Validation loss: 2.4463736847157596

Epoch: 6| Step: 5
Training loss: 2.8887294843499003
Validation loss: 2.439737154165973

Epoch: 6| Step: 6
Training loss: 2.7822178217548728
Validation loss: 2.4564962981313414

Epoch: 6| Step: 7
Training loss: 2.8782877160547384
Validation loss: 2.4370911652114904

Epoch: 6| Step: 8
Training loss: 2.3964586077783956
Validation loss: 2.4195993487564404

Epoch: 6| Step: 9
Training loss: 2.8707964477236443
Validation loss: 2.448127309882031

Epoch: 6| Step: 10
Training loss: 2.956088400813286
Validation loss: 2.45368267090384

Epoch: 6| Step: 11
Training loss: 2.751093473648384
Validation loss: 2.4344012291709576

Epoch: 6| Step: 12
Training loss: 3.1030740201667424
Validation loss: 2.4588803408731614

Epoch: 6| Step: 13
Training loss: 2.999615008764569
Validation loss: 2.425976764296177

Epoch: 79| Step: 0
Training loss: 2.801188717281983
Validation loss: 2.4579084900724357

Epoch: 6| Step: 1
Training loss: 2.5242501949050675
Validation loss: 2.4472271564535664

Epoch: 6| Step: 2
Training loss: 2.665836403660041
Validation loss: 2.459247990083004

Epoch: 6| Step: 3
Training loss: 2.278834069605963
Validation loss: 2.461983529026164

Epoch: 6| Step: 4
Training loss: 3.3147405568319286
Validation loss: 2.442654229924572

Epoch: 6| Step: 5
Training loss: 2.9253382430173045
Validation loss: 2.4457429099969805

Epoch: 6| Step: 6
Training loss: 2.128082956131238
Validation loss: 2.4402582997150915

Epoch: 6| Step: 7
Training loss: 2.2800592946825016
Validation loss: 2.4434468968697014

Epoch: 6| Step: 8
Training loss: 2.954418565119432
Validation loss: 2.4415869105283927

Epoch: 6| Step: 9
Training loss: 3.078476319378567
Validation loss: 2.4572891164464914

Epoch: 6| Step: 10
Training loss: 2.938371082769525
Validation loss: 2.4389928438047126

Epoch: 6| Step: 11
Training loss: 3.042933648706407
Validation loss: 2.4357541070934454

Epoch: 6| Step: 12
Training loss: 2.6883704971358777
Validation loss: 2.4493226701162247

Epoch: 6| Step: 13
Training loss: 2.679750936663713
Validation loss: 2.4514494200786277

Epoch: 80| Step: 0
Training loss: 2.6768313832351227
Validation loss: 2.446276449609363

Epoch: 6| Step: 1
Training loss: 3.0250673459966047
Validation loss: 2.4450143050871582

Epoch: 6| Step: 2
Training loss: 3.0127154134762972
Validation loss: 2.4447812001150626

Epoch: 6| Step: 3
Training loss: 3.2362140826504535
Validation loss: 2.4479379705803725

Epoch: 6| Step: 4
Training loss: 2.8940014064656223
Validation loss: 2.4414673631464

Epoch: 6| Step: 5
Training loss: 3.1854786166813276
Validation loss: 2.4366519295099898

Epoch: 6| Step: 6
Training loss: 2.1059755412508188
Validation loss: 2.4457619442826193

Epoch: 6| Step: 7
Training loss: 1.8891696845884354
Validation loss: 2.4473609237618854

Epoch: 6| Step: 8
Training loss: 2.0924596653632
Validation loss: 2.4446702999950625

Epoch: 6| Step: 9
Training loss: 3.308348014920678
Validation loss: 2.443806501346503

Epoch: 6| Step: 10
Training loss: 2.8806195278864783
Validation loss: 2.446495766098489

Epoch: 6| Step: 11
Training loss: 2.3596799539701263
Validation loss: 2.4323603943649146

Epoch: 6| Step: 12
Training loss: 2.6626934214078593
Validation loss: 2.455156256442212

Epoch: 6| Step: 13
Training loss: 2.8412321912658
Validation loss: 2.4446625367143624

Epoch: 81| Step: 0
Training loss: 2.7219810141098186
Validation loss: 2.436995715744797

Epoch: 6| Step: 1
Training loss: 3.00934987597411
Validation loss: 2.450718536636827

Epoch: 6| Step: 2
Training loss: 2.897962670106208
Validation loss: 2.4585042455739923

Epoch: 6| Step: 3
Training loss: 2.746819477583418
Validation loss: 2.4503050554578314

Epoch: 6| Step: 4
Training loss: 3.10430986385621
Validation loss: 2.444992815623635

Epoch: 6| Step: 5
Training loss: 3.0013860043965845
Validation loss: 2.4509390544216343

Epoch: 6| Step: 6
Training loss: 3.0356562729108814
Validation loss: 2.456470571800601

Epoch: 6| Step: 7
Training loss: 3.198333878695183
Validation loss: 2.4358879145507206

Epoch: 6| Step: 8
Training loss: 2.1423573410630263
Validation loss: 2.4561108925912367

Epoch: 6| Step: 9
Training loss: 2.0457518313373013
Validation loss: 2.440694689022598

Epoch: 6| Step: 10
Training loss: 2.2606149987845106
Validation loss: 2.4569805031836673

Epoch: 6| Step: 11
Training loss: 2.2103926455684313
Validation loss: 2.4550228110217853

Epoch: 6| Step: 12
Training loss: 3.135093258287412
Validation loss: 2.441725398116804

Epoch: 6| Step: 13
Training loss: 2.6126802263653466
Validation loss: 2.4498744706422273

Epoch: 82| Step: 0
Training loss: 2.672220308175815
Validation loss: 2.4591042175674636

Epoch: 6| Step: 1
Training loss: 3.06673216818917
Validation loss: 2.459119099091463

Epoch: 6| Step: 2
Training loss: 3.196685570616875
Validation loss: 2.4404877577525377

Epoch: 6| Step: 3
Training loss: 3.0498737934453657
Validation loss: 2.454269463045611

Epoch: 6| Step: 4
Training loss: 2.4921620526105777
Validation loss: 2.4586525951853733

Epoch: 6| Step: 5
Training loss: 2.643397213459415
Validation loss: 2.447246468321905

Epoch: 6| Step: 6
Training loss: 2.8818787920928344
Validation loss: 2.4495405380334505

Epoch: 6| Step: 7
Training loss: 2.787636272024638
Validation loss: 2.444258912829151

Epoch: 6| Step: 8
Training loss: 2.0228863411020734
Validation loss: 2.454379560194869

Epoch: 6| Step: 9
Training loss: 2.950586913609837
Validation loss: 2.452131889790134

Epoch: 6| Step: 10
Training loss: 2.9671327703409323
Validation loss: 2.4497265585082277

Epoch: 6| Step: 11
Training loss: 2.803052250184938
Validation loss: 2.446433380653282

Epoch: 6| Step: 12
Training loss: 1.9945582028281337
Validation loss: 2.4596385709659105

Epoch: 6| Step: 13
Training loss: 2.898385019161415
Validation loss: 2.4663442081509324

Epoch: 83| Step: 0
Training loss: 2.3997339975447627
Validation loss: 2.455021528690921

Epoch: 6| Step: 1
Training loss: 2.871397830145172
Validation loss: 2.460344225939503

Epoch: 6| Step: 2
Training loss: 3.0175341951697177
Validation loss: 2.4567293037371067

Epoch: 6| Step: 3
Training loss: 2.3880748236545695
Validation loss: 2.4423473026721676

Epoch: 6| Step: 4
Training loss: 2.5525594358034693
Validation loss: 2.4317433754896145

Epoch: 6| Step: 5
Training loss: 3.629832236876946
Validation loss: 2.453684601195914

Epoch: 6| Step: 6
Training loss: 1.562805603658971
Validation loss: 2.4567845427717043

Epoch: 6| Step: 7
Training loss: 3.0217848408296013
Validation loss: 2.4512770719056585

Epoch: 6| Step: 8
Training loss: 2.8530130955622526
Validation loss: 2.440084472924185

Epoch: 6| Step: 9
Training loss: 3.1485871310209697
Validation loss: 2.4548671042163153

Epoch: 6| Step: 10
Training loss: 2.8743082955905384
Validation loss: 2.4387846296878855

Epoch: 6| Step: 11
Training loss: 2.594049551338329
Validation loss: 2.463940772264059

Epoch: 6| Step: 12
Training loss: 2.129940796508405
Validation loss: 2.4373199979097047

Epoch: 6| Step: 13
Training loss: 2.9634327703669716
Validation loss: 2.4416693270137273

Epoch: 84| Step: 0
Training loss: 2.5472798406013872
Validation loss: 2.4551432980554853

Epoch: 6| Step: 1
Training loss: 2.381626421795489
Validation loss: 2.45022837641972

Epoch: 6| Step: 2
Training loss: 2.031932540074131
Validation loss: 2.4412411990579734

Epoch: 6| Step: 3
Training loss: 2.7345441493440754
Validation loss: 2.4333625008990807

Epoch: 6| Step: 4
Training loss: 2.4761311730070967
Validation loss: 2.4299918996560357

Epoch: 6| Step: 5
Training loss: 2.9720885126890653
Validation loss: 2.4534388186583853

Epoch: 6| Step: 6
Training loss: 3.472361840725947
Validation loss: 2.443619974604515

Epoch: 6| Step: 7
Training loss: 2.565342698729795
Validation loss: 2.4343817985522196

Epoch: 6| Step: 8
Training loss: 3.167180839422418
Validation loss: 2.444238749813444

Epoch: 6| Step: 9
Training loss: 2.9736618366297014
Validation loss: 2.452486735697308

Epoch: 6| Step: 10
Training loss: 2.1175516526228773
Validation loss: 2.462204756922415

Epoch: 6| Step: 11
Training loss: 3.0050491123343566
Validation loss: 2.4450251708513453

Epoch: 6| Step: 12
Training loss: 3.0138482903140313
Validation loss: 2.4332320372250567

Epoch: 6| Step: 13
Training loss: 2.4792449575505433
Validation loss: 2.4607823560140885

Epoch: 85| Step: 0
Training loss: 2.6287879860564574
Validation loss: 2.449192187300692

Epoch: 6| Step: 1
Training loss: 3.069974380783891
Validation loss: 2.4338896470171387

Epoch: 6| Step: 2
Training loss: 2.9284727299237785
Validation loss: 2.452690113657568

Epoch: 6| Step: 3
Training loss: 2.0185323639231854
Validation loss: 2.436075457428582

Epoch: 6| Step: 4
Training loss: 3.323339325782426
Validation loss: 2.434462624526088

Epoch: 6| Step: 5
Training loss: 2.0761941529995953
Validation loss: 2.4484413005434122

Epoch: 6| Step: 6
Training loss: 2.5264692016814054
Validation loss: 2.4753380719506484

Epoch: 6| Step: 7
Training loss: 2.2249410514309202
Validation loss: 2.458608918118921

Epoch: 6| Step: 8
Training loss: 3.1549126841799926
Validation loss: 2.4483367901513255

Epoch: 6| Step: 9
Training loss: 2.949193527416979
Validation loss: 2.4473354957928053

Epoch: 6| Step: 10
Training loss: 2.734268535176242
Validation loss: 2.4421371217840497

Epoch: 6| Step: 11
Training loss: 2.7202233016691117
Validation loss: 2.446115430555294

Epoch: 6| Step: 12
Training loss: 2.7667706374276557
Validation loss: 2.442876823147541

Epoch: 6| Step: 13
Training loss: 3.2336790653760867
Validation loss: 2.4426287125510626

Epoch: 86| Step: 0
Training loss: 3.2045219538581398
Validation loss: 2.4472911013582244

Epoch: 6| Step: 1
Training loss: 2.6898749747168833
Validation loss: 2.4533888716260903

Epoch: 6| Step: 2
Training loss: 2.280899125380145
Validation loss: 2.4340075148338887

Epoch: 6| Step: 3
Training loss: 3.0520713901394596
Validation loss: 2.439497958422152

Epoch: 6| Step: 4
Training loss: 2.2225307435869057
Validation loss: 2.4594676680608973

Epoch: 6| Step: 5
Training loss: 2.6790991490361478
Validation loss: 2.4512738271886794

Epoch: 6| Step: 6
Training loss: 2.8515165142375096
Validation loss: 2.4456534524258067

Epoch: 6| Step: 7
Training loss: 3.0049708827380535
Validation loss: 2.4552039262185947

Epoch: 6| Step: 8
Training loss: 2.1783659835894134
Validation loss: 2.4513618356736715

Epoch: 6| Step: 9
Training loss: 3.3950133162449405
Validation loss: 2.4329813461864176

Epoch: 6| Step: 10
Training loss: 2.7813277501586344
Validation loss: 2.4435418656262597

Epoch: 6| Step: 11
Training loss: 2.5572650750066717
Validation loss: 2.4436100499476887

Epoch: 6| Step: 12
Training loss: 2.7366789784156453
Validation loss: 2.451859255735171

Epoch: 6| Step: 13
Training loss: 2.380868687975274
Validation loss: 2.454713769753627

Epoch: 87| Step: 0
Training loss: 2.945719966478593
Validation loss: 2.452619424356029

Epoch: 6| Step: 1
Training loss: 2.5701496107437882
Validation loss: 2.4534153355973403

Epoch: 6| Step: 2
Training loss: 2.9892318111311993
Validation loss: 2.4497429435153855

Epoch: 6| Step: 3
Training loss: 1.9871653964929037
Validation loss: 2.4426689705389584

Epoch: 6| Step: 4
Training loss: 2.4304011728817567
Validation loss: 2.437913256442716

Epoch: 6| Step: 5
Training loss: 2.7805856489885517
Validation loss: 2.4402141127118604

Epoch: 6| Step: 6
Training loss: 3.1639791595409217
Validation loss: 2.433938390562216

Epoch: 6| Step: 7
Training loss: 1.4715538857095085
Validation loss: 2.4449340575695135

Epoch: 6| Step: 8
Training loss: 3.344841039327451
Validation loss: 2.4470703805544782

Epoch: 6| Step: 9
Training loss: 3.130433813385191
Validation loss: 2.4416355088090462

Epoch: 6| Step: 10
Training loss: 3.0846179313802824
Validation loss: 2.4412924242618725

Epoch: 6| Step: 11
Training loss: 3.169097134989866
Validation loss: 2.4270267162209263

Epoch: 6| Step: 12
Training loss: 2.1796101655537856
Validation loss: 2.4285471518935187

Epoch: 6| Step: 13
Training loss: 2.344162968174846
Validation loss: 2.448209316657464

Epoch: 88| Step: 0
Training loss: 2.8456917306309286
Validation loss: 2.4483884323204888

Epoch: 6| Step: 1
Training loss: 2.6990109928185673
Validation loss: 2.4583845958784214

Epoch: 6| Step: 2
Training loss: 2.6224178147870525
Validation loss: 2.440094191288003

Epoch: 6| Step: 3
Training loss: 2.869734544872091
Validation loss: 2.443477335787342

Epoch: 6| Step: 4
Training loss: 2.648874792496014
Validation loss: 2.4599188687968576

Epoch: 6| Step: 5
Training loss: 2.691382686251619
Validation loss: 2.4342893538192634

Epoch: 6| Step: 6
Training loss: 2.5011807514386457
Validation loss: 2.456542617579617

Epoch: 6| Step: 7
Training loss: 3.4301006789487403
Validation loss: 2.4397579617334193

Epoch: 6| Step: 8
Training loss: 2.574426946484053
Validation loss: 2.449565387907762

Epoch: 6| Step: 9
Training loss: 2.6013007504866525
Validation loss: 2.4573842387909357

Epoch: 6| Step: 10
Training loss: 2.768856940346235
Validation loss: 2.4565767137458994

Epoch: 6| Step: 11
Training loss: 2.939499357246475
Validation loss: 2.4569747769370873

Epoch: 6| Step: 12
Training loss: 2.416466759492347
Validation loss: 2.440381746986169

Epoch: 6| Step: 13
Training loss: 2.2861431370909
Validation loss: 2.458663509117267

Epoch: 89| Step: 0
Training loss: 2.6742730338281557
Validation loss: 2.4384513630698135

Epoch: 6| Step: 1
Training loss: 2.059433014997506
Validation loss: 2.4444727864149702

Epoch: 6| Step: 2
Training loss: 2.0598062205605085
Validation loss: 2.4622230860892484

Epoch: 6| Step: 3
Training loss: 3.5747379447018233
Validation loss: 2.4371501344424127

Epoch: 6| Step: 4
Training loss: 2.9137756370094094
Validation loss: 2.4465770793983137

Epoch: 6| Step: 5
Training loss: 2.4374915880889505
Validation loss: 2.444232883586472

Epoch: 6| Step: 6
Training loss: 3.03718536380018
Validation loss: 2.444566819194683

Epoch: 6| Step: 7
Training loss: 2.438253237420691
Validation loss: 2.460516666253176

Epoch: 6| Step: 8
Training loss: 3.2733272269891884
Validation loss: 2.452820940300311

Epoch: 6| Step: 9
Training loss: 2.541986466180413
Validation loss: 2.43472171459422

Epoch: 6| Step: 10
Training loss: 2.7540042508050253
Validation loss: 2.4326240259950933

Epoch: 6| Step: 11
Training loss: 3.336328559485102
Validation loss: 2.436603238144203

Epoch: 6| Step: 12
Training loss: 2.1553006501029004
Validation loss: 2.452471652686281

Epoch: 6| Step: 13
Training loss: 2.603372396777632
Validation loss: 2.466662486848003

Epoch: 90| Step: 0
Training loss: 3.044506854634267
Validation loss: 2.4384262727196613

Epoch: 6| Step: 1
Training loss: 2.3222194246744747
Validation loss: 2.4557457144952695

Epoch: 6| Step: 2
Training loss: 2.804776331097824
Validation loss: 2.4358746094913077

Epoch: 6| Step: 3
Training loss: 3.182054842780202
Validation loss: 2.4486380228781726

Epoch: 6| Step: 4
Training loss: 2.223764689559408
Validation loss: 2.44476315333927

Epoch: 6| Step: 5
Training loss: 2.5597549249642837
Validation loss: 2.422287355502283

Epoch: 6| Step: 6
Training loss: 2.2452056455836495
Validation loss: 2.4469541650318196

Epoch: 6| Step: 7
Training loss: 2.6848351329573497
Validation loss: 2.4391796014184677

Epoch: 6| Step: 8
Training loss: 2.6810745786533556
Validation loss: 2.4359166356343445

Epoch: 6| Step: 9
Training loss: 3.030768287372554
Validation loss: 2.4377238852072005

Epoch: 6| Step: 10
Training loss: 2.604464358798646
Validation loss: 2.439885773278022

Epoch: 6| Step: 11
Training loss: 2.939520607614087
Validation loss: 2.4617205151353443

Epoch: 6| Step: 12
Training loss: 2.8811293239518854
Validation loss: 2.4313537436334185

Epoch: 6| Step: 13
Training loss: 3.0535266748652727
Validation loss: 2.4465931879109286

Epoch: 91| Step: 0
Training loss: 2.169803976706828
Validation loss: 2.4501425731545723

Epoch: 6| Step: 1
Training loss: 3.2609817129006657
Validation loss: 2.450580557270107

Epoch: 6| Step: 2
Training loss: 2.6381405310228985
Validation loss: 2.455429298076869

Epoch: 6| Step: 3
Training loss: 3.6558912052269235
Validation loss: 2.4621332995646315

Epoch: 6| Step: 4
Training loss: 2.8064429439832286
Validation loss: 2.448662736908202

Epoch: 6| Step: 5
Training loss: 2.6909408720644574
Validation loss: 2.444949354847619

Epoch: 6| Step: 6
Training loss: 2.266040316695276
Validation loss: 2.453123472135021

Epoch: 6| Step: 7
Training loss: 2.984203553393015
Validation loss: 2.43675632769836

Epoch: 6| Step: 8
Training loss: 2.408956318656802
Validation loss: 2.44711900717446

Epoch: 6| Step: 9
Training loss: 2.541114986978094
Validation loss: 2.455666848062046

Epoch: 6| Step: 10
Training loss: 2.1818173301940758
Validation loss: 2.4475792695290775

Epoch: 6| Step: 11
Training loss: 2.3410963167096153
Validation loss: 2.4343891312569212

Epoch: 6| Step: 12
Training loss: 2.9586968713461794
Validation loss: 2.454004256989721

Epoch: 6| Step: 13
Training loss: 3.081241946567743
Validation loss: 2.456584506164576

Epoch: 92| Step: 0
Training loss: 2.6594857646678056
Validation loss: 2.4520945483036694

Epoch: 6| Step: 1
Training loss: 2.311209653726066
Validation loss: 2.4475746776405822

Epoch: 6| Step: 2
Training loss: 3.213708280739913
Validation loss: 2.4401667499955555

Epoch: 6| Step: 3
Training loss: 3.1483746467923637
Validation loss: 2.4283270151255416

Epoch: 6| Step: 4
Training loss: 2.889493978741959
Validation loss: 2.4505168415263867

Epoch: 6| Step: 5
Training loss: 2.396266190499545
Validation loss: 2.467265968498734

Epoch: 6| Step: 6
Training loss: 2.8214967729765337
Validation loss: 2.4477851394230985

Epoch: 6| Step: 7
Training loss: 2.236992429990754
Validation loss: 2.412645417258392

Epoch: 6| Step: 8
Training loss: 2.661442785845967
Validation loss: 2.4590430986191136

Epoch: 6| Step: 9
Training loss: 3.1248202462950205
Validation loss: 2.4539163333490697

Epoch: 6| Step: 10
Training loss: 2.387385748081789
Validation loss: 2.4593339301627664

Epoch: 6| Step: 11
Training loss: 2.8876687268919077
Validation loss: 2.4424036883220124

Epoch: 6| Step: 12
Training loss: 2.52101609589501
Validation loss: 2.4496714219502014

Epoch: 6| Step: 13
Training loss: 2.7928331035405924
Validation loss: 2.4533791986107683

Epoch: 93| Step: 0
Training loss: 2.616844860820803
Validation loss: 2.445969951204759

Epoch: 6| Step: 1
Training loss: 3.1810391339338553
Validation loss: 2.456485216983902

Epoch: 6| Step: 2
Training loss: 2.2913563142492914
Validation loss: 2.4416453207459696

Epoch: 6| Step: 3
Training loss: 2.4230471819960915
Validation loss: 2.4501102007520528

Epoch: 6| Step: 4
Training loss: 2.818806507702977
Validation loss: 2.441692250553222

Epoch: 6| Step: 5
Training loss: 3.0974568979929837
Validation loss: 2.4464031315123593

Epoch: 6| Step: 6
Training loss: 3.4084320078947457
Validation loss: 2.4648435669454885

Epoch: 6| Step: 7
Training loss: 2.1208084504691938
Validation loss: 2.4563088490656995

Epoch: 6| Step: 8
Training loss: 1.87413717126542
Validation loss: 2.4495876985766074

Epoch: 6| Step: 9
Training loss: 3.0608671856953866
Validation loss: 2.450874911811518

Epoch: 6| Step: 10
Training loss: 2.6475627883799673
Validation loss: 2.444994352763526

Epoch: 6| Step: 11
Training loss: 2.85126550251293
Validation loss: 2.461337690991985

Epoch: 6| Step: 12
Training loss: 2.8881067802681666
Validation loss: 2.443659074842303

Epoch: 6| Step: 13
Training loss: 2.1979165702446166
Validation loss: 2.4521003037200524

Epoch: 94| Step: 0
Training loss: 2.260523768640278
Validation loss: 2.4581627373782067

Epoch: 6| Step: 1
Training loss: 3.390438232903353
Validation loss: 2.4526561892349776

Epoch: 6| Step: 2
Training loss: 2.992945801585459
Validation loss: 2.4472455936080824

Epoch: 6| Step: 3
Training loss: 2.9535786921045633
Validation loss: 2.460310449778941

Epoch: 6| Step: 4
Training loss: 3.092564519457409
Validation loss: 2.45586862649721

Epoch: 6| Step: 5
Training loss: 2.4933889715681343
Validation loss: 2.4629769511274566

Epoch: 6| Step: 6
Training loss: 2.9381494007180677
Validation loss: 2.456444605163542

Epoch: 6| Step: 7
Training loss: 2.867332683494274
Validation loss: 2.453526898902523

Epoch: 6| Step: 8
Training loss: 3.079886769777168
Validation loss: 2.448412459379364

Epoch: 6| Step: 9
Training loss: 2.535589007807873
Validation loss: 2.4479795854101845

Epoch: 6| Step: 10
Training loss: 2.3768763909848656
Validation loss: 2.4264742788477185

Epoch: 6| Step: 11
Training loss: 1.9837849858737773
Validation loss: 2.475931183600142

Epoch: 6| Step: 12
Training loss: 2.2187830962815465
Validation loss: 2.442593137027307

Epoch: 6| Step: 13
Training loss: 2.315683493345176
Validation loss: 2.4438132277551294

Epoch: 95| Step: 0
Training loss: 2.421024690069632
Validation loss: 2.4528756674315177

Epoch: 6| Step: 1
Training loss: 2.716260186504112
Validation loss: 2.4530760221527896

Epoch: 6| Step: 2
Training loss: 2.582438426728552
Validation loss: 2.4528939419368783

Epoch: 6| Step: 3
Training loss: 2.9888853173153827
Validation loss: 2.4546107410846143

Epoch: 6| Step: 4
Training loss: 2.56807316682988
Validation loss: 2.449990674776065

Epoch: 6| Step: 5
Training loss: 2.672651657640247
Validation loss: 2.439897163073368

Epoch: 6| Step: 6
Training loss: 2.8966243038730592
Validation loss: 2.4269574501643136

Epoch: 6| Step: 7
Training loss: 2.3767567210994702
Validation loss: 2.440455544059869

Epoch: 6| Step: 8
Training loss: 3.2389017023785853
Validation loss: 2.4489498072869953

Epoch: 6| Step: 9
Training loss: 2.6921722252269085
Validation loss: 2.454286775582262

Epoch: 6| Step: 10
Training loss: 2.466301971831464
Validation loss: 2.460038863841423

Epoch: 6| Step: 11
Training loss: 2.902187666668625
Validation loss: 2.439865200588107

Epoch: 6| Step: 12
Training loss: 2.8034905134747765
Validation loss: 2.437895892828646

Epoch: 6| Step: 13
Training loss: 2.7576203968259887
Validation loss: 2.441331382210593

Epoch: 96| Step: 0
Training loss: 2.5992335070003953
Validation loss: 2.4402454838856205

Epoch: 6| Step: 1
Training loss: 2.534391549429147
Validation loss: 2.4616775892125915

Epoch: 6| Step: 2
Training loss: 2.2570734101316123
Validation loss: 2.438793496509985

Epoch: 6| Step: 3
Training loss: 2.5513125650527315
Validation loss: 2.430512281072651

Epoch: 6| Step: 4
Training loss: 2.907232139102814
Validation loss: 2.4346076258235505

Epoch: 6| Step: 5
Training loss: 3.184024636532727
Validation loss: 2.447865293474719

Epoch: 6| Step: 6
Training loss: 2.885142142299823
Validation loss: 2.433382922600137

Epoch: 6| Step: 7
Training loss: 2.9831796219366815
Validation loss: 2.433026797256598

Epoch: 6| Step: 8
Training loss: 2.857930803639856
Validation loss: 2.456893029346999

Epoch: 6| Step: 9
Training loss: 3.1502345709276436
Validation loss: 2.446983805472494

Epoch: 6| Step: 10
Training loss: 2.306291028823411
Validation loss: 2.437856793222728

Epoch: 6| Step: 11
Training loss: 2.3295737245793986
Validation loss: 2.4459845376800846

Epoch: 6| Step: 12
Training loss: 2.389133761174577
Validation loss: 2.4470469406196282

Epoch: 6| Step: 13
Training loss: 3.121124916732685
Validation loss: 2.422483976176466

Epoch: 97| Step: 0
Training loss: 2.4363841901905974
Validation loss: 2.4471617882885837

Epoch: 6| Step: 1
Training loss: 3.0682586711673054
Validation loss: 2.4419119530437023

Epoch: 6| Step: 2
Training loss: 2.29040748219149
Validation loss: 2.4456568707458723

Epoch: 6| Step: 3
Training loss: 3.2903589153756747
Validation loss: 2.438470364908855

Epoch: 6| Step: 4
Training loss: 2.47162113549894
Validation loss: 2.4380891249435614

Epoch: 6| Step: 5
Training loss: 2.6422735181056525
Validation loss: 2.46254339030518

Epoch: 6| Step: 6
Training loss: 2.4624549667965456
Validation loss: 2.442506442083606

Epoch: 6| Step: 7
Training loss: 2.666851832001106
Validation loss: 2.4598234036148017

Epoch: 6| Step: 8
Training loss: 2.909791163131318
Validation loss: 2.4378380300475513

Epoch: 6| Step: 9
Training loss: 2.902863857649856
Validation loss: 2.448675793977459

Epoch: 6| Step: 10
Training loss: 3.010058072565997
Validation loss: 2.4631063394111066

Epoch: 6| Step: 11
Training loss: 2.122726570680282
Validation loss: 2.444183420234247

Epoch: 6| Step: 12
Training loss: 2.637686725533274
Validation loss: 2.4479502162235764

Epoch: 6| Step: 13
Training loss: 3.1355864689029525
Validation loss: 2.445140191068676

Epoch: 98| Step: 0
Training loss: 3.0042729147765455
Validation loss: 2.448885670150687

Epoch: 6| Step: 1
Training loss: 2.8552855551593197
Validation loss: 2.4465313582240236

Epoch: 6| Step: 2
Training loss: 2.319620973439131
Validation loss: 2.447464404789118

Epoch: 6| Step: 3
Training loss: 2.5428494895709672
Validation loss: 2.4595932353861003

Epoch: 6| Step: 4
Training loss: 2.922469787441489
Validation loss: 2.4534172415439754

Epoch: 6| Step: 5
Training loss: 2.7489018415048063
Validation loss: 2.4457091261074226

Epoch: 6| Step: 6
Training loss: 2.4313039033302934
Validation loss: 2.449503625918129

Epoch: 6| Step: 7
Training loss: 2.653882216736926
Validation loss: 2.445552778084391

Epoch: 6| Step: 8
Training loss: 2.3720771472215243
Validation loss: 2.461814884133192

Epoch: 6| Step: 9
Training loss: 2.7126261703750956
Validation loss: 2.447097863052604

Epoch: 6| Step: 10
Training loss: 3.1729053646561796
Validation loss: 2.432057183452095

Epoch: 6| Step: 11
Training loss: 2.2703589080877067
Validation loss: 2.4310519299225777

Epoch: 6| Step: 12
Training loss: 3.283427070273629
Validation loss: 2.4482911248756722

Epoch: 6| Step: 13
Training loss: 2.594257902490851
Validation loss: 2.452476378615787

Epoch: 99| Step: 0
Training loss: 2.3258167062964876
Validation loss: 2.443811684627151

Epoch: 6| Step: 1
Training loss: 2.8356644259884503
Validation loss: 2.4536014332243163

Epoch: 6| Step: 2
Training loss: 2.299700705086924
Validation loss: 2.4564487390129237

Epoch: 6| Step: 3
Training loss: 2.870288471252171
Validation loss: 2.469034347576463

Epoch: 6| Step: 4
Training loss: 2.3464004788642443
Validation loss: 2.457395569390486

Epoch: 6| Step: 5
Training loss: 3.0623997263159874
Validation loss: 2.4292023926947777

Epoch: 6| Step: 6
Training loss: 2.7030203914797557
Validation loss: 2.460906775966884

Epoch: 6| Step: 7
Training loss: 2.3512581156175356
Validation loss: 2.460050699100243

Epoch: 6| Step: 8
Training loss: 2.6054700310974175
Validation loss: 2.4490008733452857

Epoch: 6| Step: 9
Training loss: 2.2042815507203684
Validation loss: 2.4566820267105443

Epoch: 6| Step: 10
Training loss: 2.3647288027030187
Validation loss: 2.442780075910562

Epoch: 6| Step: 11
Training loss: 3.4600199221439896
Validation loss: 2.460104113894309

Epoch: 6| Step: 12
Training loss: 3.090352977356827
Validation loss: 2.442287441779466

Epoch: 6| Step: 13
Training loss: 3.105384451243816
Validation loss: 2.4646978283585654

Epoch: 100| Step: 0
Training loss: 2.674573194020332
Validation loss: 2.4621794650719537

Epoch: 6| Step: 1
Training loss: 3.190813922426193
Validation loss: 2.449650838300806

Epoch: 6| Step: 2
Training loss: 3.1372364799809467
Validation loss: 2.439233330315452

Epoch: 6| Step: 3
Training loss: 2.6148890181088693
Validation loss: 2.430174789097692

Epoch: 6| Step: 4
Training loss: 2.9938225723421765
Validation loss: 2.455912854397212

Epoch: 6| Step: 5
Training loss: 2.630927704488034
Validation loss: 2.4524045917999913

Epoch: 6| Step: 6
Training loss: 2.5246340155929947
Validation loss: 2.4729947003653434

Epoch: 6| Step: 7
Training loss: 1.9379406089618756
Validation loss: 2.47871752095176

Epoch: 6| Step: 8
Training loss: 2.8600306358563907
Validation loss: 2.4508090180238624

Epoch: 6| Step: 9
Training loss: 2.4126120348596274
Validation loss: 2.4546380566515955

Epoch: 6| Step: 10
Training loss: 2.800369807072981
Validation loss: 2.4608638160561975

Epoch: 6| Step: 11
Training loss: 2.6306102382674426
Validation loss: 2.4472423702587585

Epoch: 6| Step: 12
Training loss: 2.9528940907781536
Validation loss: 2.459287470437499

Epoch: 6| Step: 13
Training loss: 2.417036280374325
Validation loss: 2.4670831492767276

Epoch: 101| Step: 0
Training loss: 2.706225430771302
Validation loss: 2.4745278712040686

Epoch: 6| Step: 1
Training loss: 2.47908887554118
Validation loss: 2.4574555577903983

Epoch: 6| Step: 2
Training loss: 2.637956975607728
Validation loss: 2.4621969125304073

Epoch: 6| Step: 3
Training loss: 2.7960138966620227
Validation loss: 2.43590529721403

Epoch: 6| Step: 4
Training loss: 2.7144764603728757
Validation loss: 2.4426926938728304

Epoch: 6| Step: 5
Training loss: 3.084662142512088
Validation loss: 2.454586701588466

Epoch: 6| Step: 6
Training loss: 2.5165485084871397
Validation loss: 2.464536268938986

Epoch: 6| Step: 7
Training loss: 2.7901268218554787
Validation loss: 2.452922272638098

Epoch: 6| Step: 8
Training loss: 2.8800339786856317
Validation loss: 2.4499388518664564

Epoch: 6| Step: 9
Training loss: 3.4594417465648957
Validation loss: 2.461649969553943

Epoch: 6| Step: 10
Training loss: 1.7254901852943467
Validation loss: 2.473339428690038

Epoch: 6| Step: 11
Training loss: 2.7331541987389723
Validation loss: 2.4601391725517283

Epoch: 6| Step: 12
Training loss: 2.795112779283436
Validation loss: 2.4473533931844766

Epoch: 6| Step: 13
Training loss: 2.2795487422430165
Validation loss: 2.4691145775560477

Epoch: 102| Step: 0
Training loss: 2.319554677185183
Validation loss: 2.4540995139697106

Epoch: 6| Step: 1
Training loss: 3.137493185210711
Validation loss: 2.4507391630990543

Epoch: 6| Step: 2
Training loss: 2.4089218762478533
Validation loss: 2.463701361408246

Epoch: 6| Step: 3
Training loss: 3.0084353111784554
Validation loss: 2.462468819519461

Epoch: 6| Step: 4
Training loss: 2.3379561973560614
Validation loss: 2.4467548550042246

Epoch: 6| Step: 5
Training loss: 2.277476285607898
Validation loss: 2.469390408086873

Epoch: 6| Step: 6
Training loss: 2.9786472178922474
Validation loss: 2.460457655845265

Epoch: 6| Step: 7
Training loss: 2.3283382036526348
Validation loss: 2.443870578763391

Epoch: 6| Step: 8
Training loss: 3.153404388299258
Validation loss: 2.4599628269115823

Epoch: 6| Step: 9
Training loss: 2.5306824412837394
Validation loss: 2.4583297119058334

Epoch: 6| Step: 10
Training loss: 2.9460411081236453
Validation loss: 2.453466743391518

Epoch: 6| Step: 11
Training loss: 2.943273835435862
Validation loss: 2.4568698229491948

Epoch: 6| Step: 12
Training loss: 3.007859742425258
Validation loss: 2.4492856029475902

Epoch: 6| Step: 13
Training loss: 2.5378105011185137
Validation loss: 2.442656066602629

Epoch: 103| Step: 0
Training loss: 3.134324315460949
Validation loss: 2.443793048473707

Epoch: 6| Step: 1
Training loss: 2.3769796051832315
Validation loss: 2.469906149018599

Epoch: 6| Step: 2
Training loss: 2.900215035720277
Validation loss: 2.448453515399062

Epoch: 6| Step: 3
Training loss: 3.332032537963189
Validation loss: 2.4513095554431015

Epoch: 6| Step: 4
Training loss: 2.5672108217876106
Validation loss: 2.441967881048573

Epoch: 6| Step: 5
Training loss: 2.875114106940747
Validation loss: 2.430286904492302

Epoch: 6| Step: 6
Training loss: 3.5139609234395253
Validation loss: 2.4577947777155837

Epoch: 6| Step: 7
Training loss: 2.5010732254479744
Validation loss: 2.4504920044390683

Epoch: 6| Step: 8
Training loss: 2.433119922145637
Validation loss: 2.427324347421441

Epoch: 6| Step: 9
Training loss: 2.720519969550696
Validation loss: 2.454497942349509

Epoch: 6| Step: 10
Training loss: 2.067892019983402
Validation loss: 2.4497231531924806

Epoch: 6| Step: 11
Training loss: 2.79045125969386
Validation loss: 2.443324746039569

Epoch: 6| Step: 12
Training loss: 2.27783051354786
Validation loss: 2.433271296484788

Epoch: 6| Step: 13
Training loss: 1.3867208131586766
Validation loss: 2.4353331944234364

Epoch: 104| Step: 0
Training loss: 2.842291657152525
Validation loss: 2.441898984215393

Epoch: 6| Step: 1
Training loss: 2.669470524955456
Validation loss: 2.4545433553285703

Epoch: 6| Step: 2
Training loss: 2.849896673370661
Validation loss: 2.4450613285542104

Epoch: 6| Step: 3
Training loss: 2.6700433174648444
Validation loss: 2.455799350282165

Epoch: 6| Step: 4
Training loss: 2.9681105075529763
Validation loss: 2.4458491888900364

Epoch: 6| Step: 5
Training loss: 3.1011409136688166
Validation loss: 2.456103762516348

Epoch: 6| Step: 6
Training loss: 1.9927750263396586
Validation loss: 2.4462304487651285

Epoch: 6| Step: 7
Training loss: 2.553228772597976
Validation loss: 2.4493834601469597

Epoch: 6| Step: 8
Training loss: 2.3302591258348024
Validation loss: 2.458917631439031

Epoch: 6| Step: 9
Training loss: 3.292849718433636
Validation loss: 2.448371851344933

Epoch: 6| Step: 10
Training loss: 2.815410041012791
Validation loss: 2.453950160953742

Epoch: 6| Step: 11
Training loss: 3.032129690984813
Validation loss: 2.4502469573495054

Epoch: 6| Step: 12
Training loss: 2.3252324306019907
Validation loss: 2.425565843498501

Epoch: 6| Step: 13
Training loss: 2.21017043755388
Validation loss: 2.45890347929433

Epoch: 105| Step: 0
Training loss: 2.1378381785074687
Validation loss: 2.4464028862985057

Epoch: 6| Step: 1
Training loss: 1.711605829843469
Validation loss: 2.456380332877479

Epoch: 6| Step: 2
Training loss: 3.0886536825022275
Validation loss: 2.452661142673114

Epoch: 6| Step: 3
Training loss: 2.77471576300352
Validation loss: 2.44868987122402

Epoch: 6| Step: 4
Training loss: 3.1647883583406298
Validation loss: 2.463061190478265

Epoch: 6| Step: 5
Training loss: 2.7859412928719625
Validation loss: 2.4427545231195915

Epoch: 6| Step: 6
Training loss: 2.4645868279332084
Validation loss: 2.443955842772447

Epoch: 6| Step: 7
Training loss: 2.568633577627553
Validation loss: 2.4439562434796223

Epoch: 6| Step: 8
Training loss: 2.8820593038647995
Validation loss: 2.447217307184897

Epoch: 6| Step: 9
Training loss: 3.3278877281177968
Validation loss: 2.4328724529899315

Epoch: 6| Step: 10
Training loss: 3.1278269379002714
Validation loss: 2.444717262965677

Epoch: 6| Step: 11
Training loss: 2.585631384118977
Validation loss: 2.4427123511944484

Epoch: 6| Step: 12
Training loss: 2.2929600158213126
Validation loss: 2.44877037673666

Epoch: 6| Step: 13
Training loss: 2.575227345920882
Validation loss: 2.4489654039970974

Epoch: 106| Step: 0
Training loss: 2.6424611947522494
Validation loss: 2.448225429090492

Epoch: 6| Step: 1
Training loss: 2.9603071120462885
Validation loss: 2.452140408299152

Epoch: 6| Step: 2
Training loss: 3.120884130359048
Validation loss: 2.464793771453188

Epoch: 6| Step: 3
Training loss: 2.7543067153973446
Validation loss: 2.446128281657292

Epoch: 6| Step: 4
Training loss: 2.1471813621871867
Validation loss: 2.4394623340888137

Epoch: 6| Step: 5
Training loss: 2.817192147875785
Validation loss: 2.455970952085379

Epoch: 6| Step: 6
Training loss: 2.3023235028906974
Validation loss: 2.4342667997288436

Epoch: 6| Step: 7
Training loss: 3.1691874125066857
Validation loss: 2.4186169799440322

Epoch: 6| Step: 8
Training loss: 2.725258326753683
Validation loss: 2.4409716326018227

Epoch: 6| Step: 9
Training loss: 2.6362285243064463
Validation loss: 2.4487942534820992

Epoch: 6| Step: 10
Training loss: 2.7148725549281227
Validation loss: 2.454656217773956

Epoch: 6| Step: 11
Training loss: 3.0860453526445624
Validation loss: 2.441576942957661

Epoch: 6| Step: 12
Training loss: 2.2459740117540563
Validation loss: 2.4398370849810025

Epoch: 6| Step: 13
Training loss: 2.61164921317956
Validation loss: 2.460911759155473

Epoch: 107| Step: 0
Training loss: 2.446878437609834
Validation loss: 2.4549387386143593

Epoch: 6| Step: 1
Training loss: 2.7090487977875086
Validation loss: 2.431874394990117

Epoch: 6| Step: 2
Training loss: 2.62437222558075
Validation loss: 2.4347229107453154

Epoch: 6| Step: 3
Training loss: 2.7713093073946466
Validation loss: 2.4494006251028715

Epoch: 6| Step: 4
Training loss: 2.514416896196981
Validation loss: 2.4515475571706244

Epoch: 6| Step: 5
Training loss: 2.8683707059220565
Validation loss: 2.443369189457336

Epoch: 6| Step: 6
Training loss: 2.268216249507266
Validation loss: 2.434263311703674

Epoch: 6| Step: 7
Training loss: 2.2259325709108304
Validation loss: 2.4523477790734423

Epoch: 6| Step: 8
Training loss: 3.351141914352025
Validation loss: 2.4376396994239298

Epoch: 6| Step: 9
Training loss: 2.723826437407605
Validation loss: 2.449661558438949

Epoch: 6| Step: 10
Training loss: 2.7712555374826624
Validation loss: 2.4408335349756256

Epoch: 6| Step: 11
Training loss: 2.921718001610117
Validation loss: 2.4296785366385105

Epoch: 6| Step: 12
Training loss: 3.0470111523065144
Validation loss: 2.44310027543614

Epoch: 6| Step: 13
Training loss: 2.5291172980109855
Validation loss: 2.4553371963042365

Epoch: 108| Step: 0
Training loss: 2.2804961330629436
Validation loss: 2.4379196867953015

Epoch: 6| Step: 1
Training loss: 2.1651146049208125
Validation loss: 2.4553726816717796

Epoch: 6| Step: 2
Training loss: 3.000125882368704
Validation loss: 2.4353368114491074

Epoch: 6| Step: 3
Training loss: 2.7421902822279334
Validation loss: 2.4368321713675942

Epoch: 6| Step: 4
Training loss: 3.0657748404464495
Validation loss: 2.4308479385971875

Epoch: 6| Step: 5
Training loss: 2.7220661503519876
Validation loss: 2.4389230031007187

Epoch: 6| Step: 6
Training loss: 2.216448597710198
Validation loss: 2.452390125048658

Epoch: 6| Step: 7
Training loss: 3.292168751985951
Validation loss: 2.4526256491707588

Epoch: 6| Step: 8
Training loss: 2.3041464994995446
Validation loss: 2.454209983304546

Epoch: 6| Step: 9
Training loss: 3.261563051813438
Validation loss: 2.4669225774374155

Epoch: 6| Step: 10
Training loss: 2.9738233082455574
Validation loss: 2.4377274576712153

Epoch: 6| Step: 11
Training loss: 2.230208774253615
Validation loss: 2.440683022498013

Epoch: 6| Step: 12
Training loss: 2.6098360122669186
Validation loss: 2.4460779982704635

Epoch: 6| Step: 13
Training loss: 2.630115429335918
Validation loss: 2.4369172734631843

Epoch: 109| Step: 0
Training loss: 2.974160975262587
Validation loss: 2.443168069146537

Epoch: 6| Step: 1
Training loss: 2.5495150871720718
Validation loss: 2.4574042313539675

Epoch: 6| Step: 2
Training loss: 2.51542435313827
Validation loss: 2.4441248483060853

Epoch: 6| Step: 3
Training loss: 3.0819999973661014
Validation loss: 2.443257922006397

Epoch: 6| Step: 4
Training loss: 3.091644495415855
Validation loss: 2.434428229164618

Epoch: 6| Step: 5
Training loss: 2.8117596817535047
Validation loss: 2.4413054603691258

Epoch: 6| Step: 6
Training loss: 2.3408993487647782
Validation loss: 2.4473059486521596

Epoch: 6| Step: 7
Training loss: 2.775631147213343
Validation loss: 2.4539646968602673

Epoch: 6| Step: 8
Training loss: 2.4967650464499203
Validation loss: 2.4368779935144773

Epoch: 6| Step: 9
Training loss: 2.7746629183754754
Validation loss: 2.4722810734163403

Epoch: 6| Step: 10
Training loss: 2.6893320271052734
Validation loss: 2.4510255996207264

Epoch: 6| Step: 11
Training loss: 2.1457068273296045
Validation loss: 2.4379144457700406

Epoch: 6| Step: 12
Training loss: 2.5166974358435588
Validation loss: 2.4504200423147

Epoch: 6| Step: 13
Training loss: 3.1028172335558333
Validation loss: 2.4526934458684937

Epoch: 110| Step: 0
Training loss: 2.5909415977665553
Validation loss: 2.436390296283399

Epoch: 6| Step: 1
Training loss: 2.4215301268123457
Validation loss: 2.45396370440137

Epoch: 6| Step: 2
Training loss: 3.7509921986542754
Validation loss: 2.4488771591634904

Epoch: 6| Step: 3
Training loss: 2.7332610558823816
Validation loss: 2.455884425622535

Epoch: 6| Step: 4
Training loss: 2.951430384524979
Validation loss: 2.4436859610071737

Epoch: 6| Step: 5
Training loss: 2.909462086883032
Validation loss: 2.455210381244756

Epoch: 6| Step: 6
Training loss: 2.428655963516351
Validation loss: 2.464669011000831

Epoch: 6| Step: 7
Training loss: 2.1411793680115956
Validation loss: 2.4409006816502274

Epoch: 6| Step: 8
Training loss: 2.667910663201399
Validation loss: 2.465019571741265

Epoch: 6| Step: 9
Training loss: 2.8109251063414504
Validation loss: 2.4478171980072903

Epoch: 6| Step: 10
Training loss: 2.341098964562891
Validation loss: 2.463066688163331

Epoch: 6| Step: 11
Training loss: 3.0306996897979204
Validation loss: 2.4626349607531375

Epoch: 6| Step: 12
Training loss: 2.5216688447662583
Validation loss: 2.447458486587785

Epoch: 6| Step: 13
Training loss: 1.9105236737627231
Validation loss: 2.439765942368829

Epoch: 111| Step: 0
Training loss: 2.4383580580435833
Validation loss: 2.472746614469902

Epoch: 6| Step: 1
Training loss: 2.38812164681785
Validation loss: 2.4521283017200406

Epoch: 6| Step: 2
Training loss: 2.3723041894982577
Validation loss: 2.4470209316046008

Epoch: 6| Step: 3
Training loss: 2.9004567148404554
Validation loss: 2.458628900723362

Epoch: 6| Step: 4
Training loss: 2.9988865375482097
Validation loss: 2.441727075904294

Epoch: 6| Step: 5
Training loss: 2.551395266414233
Validation loss: 2.4565094664519536

Epoch: 6| Step: 6
Training loss: 3.1908913317198264
Validation loss: 2.4406612039411524

Epoch: 6| Step: 7
Training loss: 2.177769079915451
Validation loss: 2.4664905209022154

Epoch: 6| Step: 8
Training loss: 2.7686454529323483
Validation loss: 2.4565104745801043

Epoch: 6| Step: 9
Training loss: 2.571287857095948
Validation loss: 2.4467243300791934

Epoch: 6| Step: 10
Training loss: 2.404305105559379
Validation loss: 2.448942182669463

Epoch: 6| Step: 11
Training loss: 3.216914125585892
Validation loss: 2.4503346841361324

Epoch: 6| Step: 12
Training loss: 3.217128604536953
Validation loss: 2.456957212051552

Epoch: 6| Step: 13
Training loss: 2.465773707789777
Validation loss: 2.4577747872863447

Epoch: 112| Step: 0
Training loss: 3.0144483415230288
Validation loss: 2.444709554363824

Epoch: 6| Step: 1
Training loss: 3.106348452936272
Validation loss: 2.4610417190466904

Epoch: 6| Step: 2
Training loss: 2.0658762491909903
Validation loss: 2.4371111017658156

Epoch: 6| Step: 3
Training loss: 2.552915559393525
Validation loss: 2.455726593694445

Epoch: 6| Step: 4
Training loss: 2.1275772846318177
Validation loss: 2.446190725188113

Epoch: 6| Step: 5
Training loss: 2.8607332932800222
Validation loss: 2.4361152301880615

Epoch: 6| Step: 6
Training loss: 2.467656726439773
Validation loss: 2.4355698530061525

Epoch: 6| Step: 7
Training loss: 2.3635321365731445
Validation loss: 2.4510555166340757

Epoch: 6| Step: 8
Training loss: 2.9744574043993195
Validation loss: 2.4591560579137406

Epoch: 6| Step: 9
Training loss: 2.7944908849431362
Validation loss: 2.4538059066889457

Epoch: 6| Step: 10
Training loss: 3.299073268348498
Validation loss: 2.460319235897474

Epoch: 6| Step: 11
Training loss: 1.9216783624553948
Validation loss: 2.4502507051161158

Epoch: 6| Step: 12
Training loss: 2.512701764711887
Validation loss: 2.4446289518257602

Epoch: 6| Step: 13
Training loss: 3.6852685674680044
Validation loss: 2.4495556129283194

Epoch: 113| Step: 0
Training loss: 3.2619397848010574
Validation loss: 2.43854923346903

Epoch: 6| Step: 1
Training loss: 2.3971016111516406
Validation loss: 2.446299618691744

Epoch: 6| Step: 2
Training loss: 2.7212597892981165
Validation loss: 2.4705258907491405

Epoch: 6| Step: 3
Training loss: 3.136857083169313
Validation loss: 2.444956240636199

Epoch: 6| Step: 4
Training loss: 2.2162077402387816
Validation loss: 2.452056226609184

Epoch: 6| Step: 5
Training loss: 2.5811791103133124
Validation loss: 2.4372769567410577

Epoch: 6| Step: 6
Training loss: 2.307204084836648
Validation loss: 2.440735022500452

Epoch: 6| Step: 7
Training loss: 2.266009383644277
Validation loss: 2.4450419962812924

Epoch: 6| Step: 8
Training loss: 2.525801835358234
Validation loss: 2.4499221898225776

Epoch: 6| Step: 9
Training loss: 2.401149943152137
Validation loss: 2.4489192385357703

Epoch: 6| Step: 10
Training loss: 3.065519751434583
Validation loss: 2.4307876247203475

Epoch: 6| Step: 11
Training loss: 3.014241746286072
Validation loss: 2.417922313979243

Epoch: 6| Step: 12
Training loss: 2.8188773860186305
Validation loss: 2.438673707066348

Epoch: 6| Step: 13
Training loss: 3.0068855739955485
Validation loss: 2.437027859456065

Epoch: 114| Step: 0
Training loss: 2.6409492067929112
Validation loss: 2.460787317576897

Epoch: 6| Step: 1
Training loss: 3.0532310506466445
Validation loss: 2.4548993919600317

Epoch: 6| Step: 2
Training loss: 2.827022611621395
Validation loss: 2.448502339136994

Epoch: 6| Step: 3
Training loss: 2.534984424099293
Validation loss: 2.443175085872291

Epoch: 6| Step: 4
Training loss: 3.2153834542323976
Validation loss: 2.4573569141065073

Epoch: 6| Step: 5
Training loss: 2.7203200618982795
Validation loss: 2.4497389155576994

Epoch: 6| Step: 6
Training loss: 2.1814765834351575
Validation loss: 2.448762069496773

Epoch: 6| Step: 7
Training loss: 2.708974869868869
Validation loss: 2.467693420001348

Epoch: 6| Step: 8
Training loss: 3.0477148219085644
Validation loss: 2.43968106258659

Epoch: 6| Step: 9
Training loss: 2.6071245002473584
Validation loss: 2.467375705480653

Epoch: 6| Step: 10
Training loss: 2.0753491441145044
Validation loss: 2.464153867678171

Epoch: 6| Step: 11
Training loss: 2.802097155077193
Validation loss: 2.4542530487177356

Epoch: 6| Step: 12
Training loss: 2.6127854405756104
Validation loss: 2.450343801063336

Epoch: 6| Step: 13
Training loss: 2.393522414103107
Validation loss: 2.442992971861052

Epoch: 115| Step: 0
Training loss: 3.0257074080640822
Validation loss: 2.451112806962167

Epoch: 6| Step: 1
Training loss: 2.5285547294403954
Validation loss: 2.4443695610247382

Epoch: 6| Step: 2
Training loss: 2.647376013744212
Validation loss: 2.465595759439307

Epoch: 6| Step: 3
Training loss: 2.473481581410187
Validation loss: 2.471277103713529

Epoch: 6| Step: 4
Training loss: 3.317555725963476
Validation loss: 2.4499973130520085

Epoch: 6| Step: 5
Training loss: 2.634138639261345
Validation loss: 2.4676646698317937

Epoch: 6| Step: 6
Training loss: 2.37956181154809
Validation loss: 2.449416370704209

Epoch: 6| Step: 7
Training loss: 2.6902072489148967
Validation loss: 2.443206243794645

Epoch: 6| Step: 8
Training loss: 2.148952796868499
Validation loss: 2.4520041065125135

Epoch: 6| Step: 9
Training loss: 2.873642642491088
Validation loss: 2.4392282918036594

Epoch: 6| Step: 10
Training loss: 2.2379468631453165
Validation loss: 2.4541531961806307

Epoch: 6| Step: 11
Training loss: 2.7692875290824697
Validation loss: 2.428351807597468

Epoch: 6| Step: 12
Training loss: 2.6408857408714015
Validation loss: 2.444812396290124

Epoch: 6| Step: 13
Training loss: 3.4605201486773423
Validation loss: 2.453769370081107

Epoch: 116| Step: 0
Training loss: 2.730558074668877
Validation loss: 2.460821936765758

Epoch: 6| Step: 1
Training loss: 2.6308220377129676
Validation loss: 2.446546360496658

Epoch: 6| Step: 2
Training loss: 2.0830281860671485
Validation loss: 2.4537219252756484

Epoch: 6| Step: 3
Training loss: 2.974860718616254
Validation loss: 2.4417103063770025

Epoch: 6| Step: 4
Training loss: 2.5773987643084624
Validation loss: 2.4524295109161893

Epoch: 6| Step: 5
Training loss: 2.230987435073385
Validation loss: 2.4566329382005034

Epoch: 6| Step: 6
Training loss: 2.3547987862901523
Validation loss: 2.454782161758281

Epoch: 6| Step: 7
Training loss: 2.956456157439893
Validation loss: 2.4479099555481025

Epoch: 6| Step: 8
Training loss: 3.0183349450407424
Validation loss: 2.4498306873039524

Epoch: 6| Step: 9
Training loss: 2.959883771624879
Validation loss: 2.448354249347183

Epoch: 6| Step: 10
Training loss: 2.4261751454051375
Validation loss: 2.440238228661232

Epoch: 6| Step: 11
Training loss: 2.531795490026853
Validation loss: 2.444234037324339

Epoch: 6| Step: 12
Training loss: 3.458423674602248
Validation loss: 2.436134136596248

Epoch: 6| Step: 13
Training loss: 2.0564006437177826
Validation loss: 2.4530345920205705

Epoch: 117| Step: 0
Training loss: 2.630220036748147
Validation loss: 2.4767568510767966

Epoch: 6| Step: 1
Training loss: 2.7801102435256064
Validation loss: 2.443928790690286

Epoch: 6| Step: 2
Training loss: 2.5524883545732258
Validation loss: 2.46794691895973

Epoch: 6| Step: 3
Training loss: 2.415509922696553
Validation loss: 2.4623933740192085

Epoch: 6| Step: 4
Training loss: 3.1362939834399333
Validation loss: 2.455869705350527

Epoch: 6| Step: 5
Training loss: 2.627997911716601
Validation loss: 2.45768517830667

Epoch: 6| Step: 6
Training loss: 2.6363464544746846
Validation loss: 2.4703120228702717

Epoch: 6| Step: 7
Training loss: 2.499803821495914
Validation loss: 2.4617477382741577

Epoch: 6| Step: 8
Training loss: 2.478479359559102
Validation loss: 2.469070714884952

Epoch: 6| Step: 9
Training loss: 2.7839619134237967
Validation loss: 2.461229289918767

Epoch: 6| Step: 10
Training loss: 3.475699945666295
Validation loss: 2.4546524673340824

Epoch: 6| Step: 11
Training loss: 2.682722236123488
Validation loss: 2.466021171778742

Epoch: 6| Step: 12
Training loss: 2.4835608725878093
Validation loss: 2.4392248003632253

Epoch: 6| Step: 13
Training loss: 2.319414369562005
Validation loss: 2.4526804504293307

Epoch: 118| Step: 0
Training loss: 2.802108216204768
Validation loss: 2.4464546646493455

Epoch: 6| Step: 1
Training loss: 2.6209684020768083
Validation loss: 2.4641022822939047

Epoch: 6| Step: 2
Training loss: 2.879165617026668
Validation loss: 2.4394445049124687

Epoch: 6| Step: 3
Training loss: 3.3079040601164746
Validation loss: 2.4571856198458053

Epoch: 6| Step: 4
Training loss: 2.7599600840183824
Validation loss: 2.4473984176056836

Epoch: 6| Step: 5
Training loss: 2.295535572864028
Validation loss: 2.4507179257277016

Epoch: 6| Step: 6
Training loss: 2.8057373122290645
Validation loss: 2.4433857419529015

Epoch: 6| Step: 7
Training loss: 2.0766017752234847
Validation loss: 2.438653301287408

Epoch: 6| Step: 8
Training loss: 2.9215596890780278
Validation loss: 2.459130677370364

Epoch: 6| Step: 9
Training loss: 2.2100690342404237
Validation loss: 2.444186473504786

Epoch: 6| Step: 10
Training loss: 2.0113155220127337
Validation loss: 2.448762874049216

Epoch: 6| Step: 11
Training loss: 3.0329264301517256
Validation loss: 2.451078830376915

Epoch: 6| Step: 12
Training loss: 2.875931630326001
Validation loss: 2.446292462116411

Epoch: 6| Step: 13
Training loss: 2.592235996558382
Validation loss: 2.455549327721369

Epoch: 119| Step: 0
Training loss: 3.2921264584842946
Validation loss: 2.462759770117986

Epoch: 6| Step: 1
Training loss: 2.6958723730673295
Validation loss: 2.4408491845979645

Epoch: 6| Step: 2
Training loss: 2.8053019496077245
Validation loss: 2.4665101184849916

Epoch: 6| Step: 3
Training loss: 3.0196177876102057
Validation loss: 2.4491746278344033

Epoch: 6| Step: 4
Training loss: 2.4952809617850793
Validation loss: 2.448322522396487

Epoch: 6| Step: 5
Training loss: 2.563925276948442
Validation loss: 2.44774106944326

Epoch: 6| Step: 6
Training loss: 2.55311727534308
Validation loss: 2.441305408913708

Epoch: 6| Step: 7
Training loss: 2.3237440634287925
Validation loss: 2.445199225150909

Epoch: 6| Step: 8
Training loss: 2.489178314675543
Validation loss: 2.4496285098925275

Epoch: 6| Step: 9
Training loss: 2.7525849764229258
Validation loss: 2.459368568246572

Epoch: 6| Step: 10
Training loss: 2.731794960247563
Validation loss: 2.433604701518954

Epoch: 6| Step: 11
Training loss: 2.8290440873196103
Validation loss: 2.445342192839286

Epoch: 6| Step: 12
Training loss: 2.58432989484733
Validation loss: 2.4438499048194475

Epoch: 6| Step: 13
Training loss: 2.253213177567909
Validation loss: 2.458403310167394

Epoch: 120| Step: 0
Training loss: 2.593532507176976
Validation loss: 2.446618483709572

Epoch: 6| Step: 1
Training loss: 2.1372551671848177
Validation loss: 2.4443681503961225

Epoch: 6| Step: 2
Training loss: 2.711507863664488
Validation loss: 2.4448968190081697

Epoch: 6| Step: 3
Training loss: 1.9773603796589336
Validation loss: 2.4598366552176727

Epoch: 6| Step: 4
Training loss: 3.372264459866734
Validation loss: 2.4418471523082315

Epoch: 6| Step: 5
Training loss: 2.8663268915535722
Validation loss: 2.442807260352804

Epoch: 6| Step: 6
Training loss: 2.9549643626379742
Validation loss: 2.4358170165426465

Epoch: 6| Step: 7
Training loss: 3.2652657781268957
Validation loss: 2.439918828229668

Epoch: 6| Step: 8
Training loss: 2.1910913686570037
Validation loss: 2.4602528776274095

Epoch: 6| Step: 9
Training loss: 3.2517965193147225
Validation loss: 2.450619423007997

Epoch: 6| Step: 10
Training loss: 1.905804191114125
Validation loss: 2.455888985271916

Epoch: 6| Step: 11
Training loss: 2.3546082299146573
Validation loss: 2.4479679070012184

Epoch: 6| Step: 12
Training loss: 2.7125555920507547
Validation loss: 2.4506822448139247

Epoch: 6| Step: 13
Training loss: 2.8911876234029266
Validation loss: 2.4414323398303552

Epoch: 121| Step: 0
Training loss: 3.2159192127689775
Validation loss: 2.4491926248333997

Epoch: 6| Step: 1
Training loss: 2.6998677115351484
Validation loss: 2.4547091410811728

Epoch: 6| Step: 2
Training loss: 2.4859050141998633
Validation loss: 2.441673995105038

Epoch: 6| Step: 3
Training loss: 2.8478181685683563
Validation loss: 2.4595085874860785

Epoch: 6| Step: 4
Training loss: 2.5261683376577118
Validation loss: 2.470422974637036

Epoch: 6| Step: 5
Training loss: 2.4381909491511746
Validation loss: 2.455907501453405

Epoch: 6| Step: 6
Training loss: 2.3382240765098232
Validation loss: 2.4666958361793614

Epoch: 6| Step: 7
Training loss: 2.5746432751712938
Validation loss: 2.451605121214842

Epoch: 6| Step: 8
Training loss: 3.2889717433848804
Validation loss: 2.4341646907786987

Epoch: 6| Step: 9
Training loss: 2.4273577249871785
Validation loss: 2.4528516015240442

Epoch: 6| Step: 10
Training loss: 2.8566686611398553
Validation loss: 2.461800097788802

Epoch: 6| Step: 11
Training loss: 3.1296303586271375
Validation loss: 2.444816974491933

Epoch: 6| Step: 12
Training loss: 2.4886991667908847
Validation loss: 2.451136759727205

Epoch: 6| Step: 13
Training loss: 1.443048466916012
Validation loss: 2.443404236422147

Epoch: 122| Step: 0
Training loss: 2.563745521604736
Validation loss: 2.447632163608878

Epoch: 6| Step: 1
Training loss: 2.771884709183161
Validation loss: 2.4642487718517128

Epoch: 6| Step: 2
Training loss: 2.681262829445332
Validation loss: 2.456811391733007

Epoch: 6| Step: 3
Training loss: 2.394879513379735
Validation loss: 2.44579901139662

Epoch: 6| Step: 4
Training loss: 3.1408114401672615
Validation loss: 2.429442039140161

Epoch: 6| Step: 5
Training loss: 2.5299563457658145
Validation loss: 2.452757152104491

Epoch: 6| Step: 6
Training loss: 2.2431016713202365
Validation loss: 2.447223335964458

Epoch: 6| Step: 7
Training loss: 2.553863859247839
Validation loss: 2.446317028501238

Epoch: 6| Step: 8
Training loss: 2.7404711968339077
Validation loss: 2.450264894681924

Epoch: 6| Step: 9
Training loss: 2.402661806467174
Validation loss: 2.451994221018845

Epoch: 6| Step: 10
Training loss: 2.9077497324864297
Validation loss: 2.44523631023092

Epoch: 6| Step: 11
Training loss: 2.54161764837639
Validation loss: 2.4458302794912568

Epoch: 6| Step: 12
Training loss: 3.304943462586547
Validation loss: 2.4384609039585947

Epoch: 6| Step: 13
Training loss: 2.151605884610476
Validation loss: 2.4519032234651825

Epoch: 123| Step: 0
Training loss: 2.5458469305180014
Validation loss: 2.421088968064113

Epoch: 6| Step: 1
Training loss: 2.957636540696025
Validation loss: 2.444963220773948

Epoch: 6| Step: 2
Training loss: 2.381180801787891
Validation loss: 2.450373964940013

Epoch: 6| Step: 3
Training loss: 3.0599360729845246
Validation loss: 2.4471336046100434

Epoch: 6| Step: 4
Training loss: 2.4743565503247034
Validation loss: 2.455718355919834

Epoch: 6| Step: 5
Training loss: 2.3116587577891723
Validation loss: 2.435024921144586

Epoch: 6| Step: 6
Training loss: 2.6994118297102045
Validation loss: 2.455382857915843

Epoch: 6| Step: 7
Training loss: 2.896141603011217
Validation loss: 2.450852119139019

Epoch: 6| Step: 8
Training loss: 2.684048765384746
Validation loss: 2.4335874283091115

Epoch: 6| Step: 9
Training loss: 2.6774293153980064
Validation loss: 2.4415759171135094

Epoch: 6| Step: 10
Training loss: 3.185403171574756
Validation loss: 2.4637346353205425

Epoch: 6| Step: 11
Training loss: 2.3936347714570863
Validation loss: 2.445191085062028

Epoch: 6| Step: 12
Training loss: 2.0145319850917036
Validation loss: 2.4502380200225224

Epoch: 6| Step: 13
Training loss: 3.3167442625799377
Validation loss: 2.4617470624116495

Epoch: 124| Step: 0
Training loss: 3.354870139961584
Validation loss: 2.448260925913153

Epoch: 6| Step: 1
Training loss: 3.2206880234826367
Validation loss: 2.4690773049778563

Epoch: 6| Step: 2
Training loss: 2.432764588694588
Validation loss: 2.446573344865576

Epoch: 6| Step: 3
Training loss: 2.9731188300154736
Validation loss: 2.452308659515356

Epoch: 6| Step: 4
Training loss: 2.495028893985745
Validation loss: 2.434541672411943

Epoch: 6| Step: 5
Training loss: 2.556963638637907
Validation loss: 2.4460728260805653

Epoch: 6| Step: 6
Training loss: 2.0398184007335534
Validation loss: 2.4597527473436473

Epoch: 6| Step: 7
Training loss: 2.2283033559071947
Validation loss: 2.4528623050604703

Epoch: 6| Step: 8
Training loss: 3.155872284600406
Validation loss: 2.4401873133143264

Epoch: 6| Step: 9
Training loss: 2.5576448734004096
Validation loss: 2.4524807104485027

Epoch: 6| Step: 10
Training loss: 2.804125121112597
Validation loss: 2.4616034702249383

Epoch: 6| Step: 11
Training loss: 2.6092832629130482
Validation loss: 2.4480337589267775

Epoch: 6| Step: 12
Training loss: 2.0877714060619104
Validation loss: 2.4611101341605184

Epoch: 6| Step: 13
Training loss: 2.906818621393613
Validation loss: 2.4335055566621615

Epoch: 125| Step: 0
Training loss: 1.921650260872908
Validation loss: 2.4553393309849674

Epoch: 6| Step: 1
Training loss: 2.4861869682043505
Validation loss: 2.464796418515181

Epoch: 6| Step: 2
Training loss: 2.6609840841466044
Validation loss: 2.4483995459246826

Epoch: 6| Step: 3
Training loss: 2.5486169018681077
Validation loss: 2.4484140634784413

Epoch: 6| Step: 4
Training loss: 2.0977220578233577
Validation loss: 2.4478755569584263

Epoch: 6| Step: 5
Training loss: 3.061362230355032
Validation loss: 2.4592382567173248

Epoch: 6| Step: 6
Training loss: 2.7526305361915924
Validation loss: 2.4630729633363813

Epoch: 6| Step: 7
Training loss: 2.358272269528903
Validation loss: 2.453046229064279

Epoch: 6| Step: 8
Training loss: 2.5752982624235767
Validation loss: 2.4491314113639535

Epoch: 6| Step: 9
Training loss: 2.6166242762086114
Validation loss: 2.4460803197260006

Epoch: 6| Step: 10
Training loss: 2.7130389684514187
Validation loss: 2.4503190595230695

Epoch: 6| Step: 11
Training loss: 3.065974697190281
Validation loss: 2.4664540900839675

Epoch: 6| Step: 12
Training loss: 3.2861307810172025
Validation loss: 2.4473651949895037

Epoch: 6| Step: 13
Training loss: 3.229997704330904
Validation loss: 2.4583125373401495

Epoch: 126| Step: 0
Training loss: 2.593130750155561
Validation loss: 2.4647897545701865

Epoch: 6| Step: 1
Training loss: 2.361467759616
Validation loss: 2.4454930879069585

Epoch: 6| Step: 2
Training loss: 2.3661764774497533
Validation loss: 2.453245624131483

Epoch: 6| Step: 3
Training loss: 3.27010961086405
Validation loss: 2.4607757239126196

Epoch: 6| Step: 4
Training loss: 3.406848120015626
Validation loss: 2.447765992047516

Epoch: 6| Step: 5
Training loss: 3.0533859719260334
Validation loss: 2.4669307263574605

Epoch: 6| Step: 6
Training loss: 2.3113715021557617
Validation loss: 2.455011307612824

Epoch: 6| Step: 7
Training loss: 2.7941691346635924
Validation loss: 2.482750216157768

Epoch: 6| Step: 8
Training loss: 2.5904810885041143
Validation loss: 2.4837526576533735

Epoch: 6| Step: 9
Training loss: 2.6718641135903036
Validation loss: 2.4541856050887914

Epoch: 6| Step: 10
Training loss: 2.738501002572186
Validation loss: 2.462638252441269

Epoch: 6| Step: 11
Training loss: 2.3253583406334424
Validation loss: 2.466884073517053

Epoch: 6| Step: 12
Training loss: 2.2105898095097163
Validation loss: 2.460547715020279

Epoch: 6| Step: 13
Training loss: 2.514004582318217
Validation loss: 2.4857864544474744

Epoch: 127| Step: 0
Training loss: 2.1206736561359123
Validation loss: 2.458308138613092

Epoch: 6| Step: 1
Training loss: 2.279491321471057
Validation loss: 2.4699567216071894

Epoch: 6| Step: 2
Training loss: 3.0304576978804008
Validation loss: 2.465720688740428

Epoch: 6| Step: 3
Training loss: 2.980970427961809
Validation loss: 2.4553580037501574

Epoch: 6| Step: 4
Training loss: 1.9526033238853195
Validation loss: 2.4469686927323595

Epoch: 6| Step: 5
Training loss: 2.8564807022380356
Validation loss: 2.453444166016777

Epoch: 6| Step: 6
Training loss: 2.8202404742144704
Validation loss: 2.4611988976393424

Epoch: 6| Step: 7
Training loss: 2.4403407831320165
Validation loss: 2.4530604578487223

Epoch: 6| Step: 8
Training loss: 2.990069164892318
Validation loss: 2.467808411097149

Epoch: 6| Step: 9
Training loss: 2.7720772859717737
Validation loss: 2.4501460615931174

Epoch: 6| Step: 10
Training loss: 3.3650521501918425
Validation loss: 2.441807077101388

Epoch: 6| Step: 11
Training loss: 2.9222490203879277
Validation loss: 2.4600574248616467

Epoch: 6| Step: 12
Training loss: 2.216897647936639
Validation loss: 2.4589567063241455

Epoch: 6| Step: 13
Training loss: 2.2583857141967876
Validation loss: 2.4501626075431493

Epoch: 128| Step: 0
Training loss: 2.711531692159291
Validation loss: 2.469765361534859

Epoch: 6| Step: 1
Training loss: 2.919503458210811
Validation loss: 2.451825432741832

Epoch: 6| Step: 2
Training loss: 2.136996235517043
Validation loss: 2.448834951348572

Epoch: 6| Step: 3
Training loss: 3.0021332467717134
Validation loss: 2.4442962607473593

Epoch: 6| Step: 4
Training loss: 2.7224695478265266
Validation loss: 2.4401550599347517

Epoch: 6| Step: 5
Training loss: 2.6402172247787785
Validation loss: 2.4468029776400555

Epoch: 6| Step: 6
Training loss: 2.8948422572457964
Validation loss: 2.454039904227819

Epoch: 6| Step: 7
Training loss: 2.3079008815115603
Validation loss: 2.448189332778948

Epoch: 6| Step: 8
Training loss: 2.7101947745397164
Validation loss: 2.458794499630034

Epoch: 6| Step: 9
Training loss: 2.9023927091471187
Validation loss: 2.4651099343198797

Epoch: 6| Step: 10
Training loss: 3.095498255740737
Validation loss: 2.440967360164121

Epoch: 6| Step: 11
Training loss: 2.5991683803730856
Validation loss: 2.451848834312955

Epoch: 6| Step: 12
Training loss: 2.106176819930835
Validation loss: 2.454353431990797

Epoch: 6| Step: 13
Training loss: 2.753306048845351
Validation loss: 2.468647420051873

Epoch: 129| Step: 0
Training loss: 2.903554999922206
Validation loss: 2.4668016888425814

Epoch: 6| Step: 1
Training loss: 3.405054285006025
Validation loss: 2.46100469504984

Epoch: 6| Step: 2
Training loss: 2.5140184283616716
Validation loss: 2.449292097121735

Epoch: 6| Step: 3
Training loss: 1.7499594002510046
Validation loss: 2.459588289654883

Epoch: 6| Step: 4
Training loss: 2.946526962553074
Validation loss: 2.4432055449650183

Epoch: 6| Step: 5
Training loss: 2.2023032529422286
Validation loss: 2.443485283291478

Epoch: 6| Step: 6
Training loss: 2.3724251894315787
Validation loss: 2.4371882623992964

Epoch: 6| Step: 7
Training loss: 2.6279499190681177
Validation loss: 2.4700523441894977

Epoch: 6| Step: 8
Training loss: 2.4615703435126104
Validation loss: 2.456351161195905

Epoch: 6| Step: 9
Training loss: 2.219078576916506
Validation loss: 2.452073719960943

Epoch: 6| Step: 10
Training loss: 3.285951425157355
Validation loss: 2.4586290373185653

Epoch: 6| Step: 11
Training loss: 2.656299096944005
Validation loss: 2.451529147925421

Epoch: 6| Step: 12
Training loss: 3.1434401615418635
Validation loss: 2.478828936272675

Epoch: 6| Step: 13
Training loss: 2.1767616460192243
Validation loss: 2.458776909166138

Epoch: 130| Step: 0
Training loss: 2.7715180108016613
Validation loss: 2.4542052716815532

Epoch: 6| Step: 1
Training loss: 2.3662004584734944
Validation loss: 2.456124413686511

Epoch: 6| Step: 2
Training loss: 2.3715491069717625
Validation loss: 2.450568640705522

Epoch: 6| Step: 3
Training loss: 2.4936151989137993
Validation loss: 2.441575947563342

Epoch: 6| Step: 4
Training loss: 2.137501128793162
Validation loss: 2.4659016622556567

Epoch: 6| Step: 5
Training loss: 2.3073028724920697
Validation loss: 2.4531165779198583

Epoch: 6| Step: 6
Training loss: 2.8851275982068056
Validation loss: 2.4634193975076877

Epoch: 6| Step: 7
Training loss: 2.8208804417277626
Validation loss: 2.467363407667186

Epoch: 6| Step: 8
Training loss: 2.7708048615869094
Validation loss: 2.4294619065607175

Epoch: 6| Step: 9
Training loss: 2.32894923833658
Validation loss: 2.460636730080543

Epoch: 6| Step: 10
Training loss: 3.181327827865599
Validation loss: 2.440440227017318

Epoch: 6| Step: 11
Training loss: 3.2317089942755737
Validation loss: 2.447017629384897

Epoch: 6| Step: 12
Training loss: 2.9900187708032635
Validation loss: 2.449826915872722

Epoch: 6| Step: 13
Training loss: 2.467558561207965
Validation loss: 2.455467028397009

Epoch: 131| Step: 0
Training loss: 2.759893307765984
Validation loss: 2.455079854227007

Epoch: 6| Step: 1
Training loss: 2.7808454412193497
Validation loss: 2.464335038959758

Epoch: 6| Step: 2
Training loss: 2.5269681719280235
Validation loss: 2.4350197549560044

Epoch: 6| Step: 3
Training loss: 2.863528044552467
Validation loss: 2.4508340710413608

Epoch: 6| Step: 4
Training loss: 3.44083880488659
Validation loss: 2.4503105095720974

Epoch: 6| Step: 5
Training loss: 2.1715321441737703
Validation loss: 2.4545315640149603

Epoch: 6| Step: 6
Training loss: 2.924857346406175
Validation loss: 2.4474420621947806

Epoch: 6| Step: 7
Training loss: 2.1055817582583796
Validation loss: 2.451582383433786

Epoch: 6| Step: 8
Training loss: 2.8254742080896498
Validation loss: 2.4351117424257502

Epoch: 6| Step: 9
Training loss: 2.6034830238722164
Validation loss: 2.434291783405535

Epoch: 6| Step: 10
Training loss: 2.292365805588912
Validation loss: 2.452014778200605

Epoch: 6| Step: 11
Training loss: 2.4448479646870824
Validation loss: 2.446745821099451

Epoch: 6| Step: 12
Training loss: 2.9814747403763864
Validation loss: 2.4445324763365672

Epoch: 6| Step: 13
Training loss: 2.0721014391027976
Validation loss: 2.4708988645073724

Epoch: 132| Step: 0
Training loss: 2.9619406256536376
Validation loss: 2.4593749987908216

Epoch: 6| Step: 1
Training loss: 2.5937611223464936
Validation loss: 2.453681525788041

Epoch: 6| Step: 2
Training loss: 2.268086746830884
Validation loss: 2.4571836343995037

Epoch: 6| Step: 3
Training loss: 3.270513644459566
Validation loss: 2.4617681395496347

Epoch: 6| Step: 4
Training loss: 2.494056885462881
Validation loss: 2.4415423170668173

Epoch: 6| Step: 5
Training loss: 2.246879957509308
Validation loss: 2.463902898058213

Epoch: 6| Step: 6
Training loss: 2.113878994101337
Validation loss: 2.4666022432268204

Epoch: 6| Step: 7
Training loss: 2.4537049598077507
Validation loss: 2.467389693701403

Epoch: 6| Step: 8
Training loss: 2.656822950615635
Validation loss: 2.4527548630985834

Epoch: 6| Step: 9
Training loss: 2.5561543491067824
Validation loss: 2.4713812207559838

Epoch: 6| Step: 10
Training loss: 2.409077358044157
Validation loss: 2.4723352329070254

Epoch: 6| Step: 11
Training loss: 2.788450713604626
Validation loss: 2.438271190438049

Epoch: 6| Step: 12
Training loss: 3.451105830667581
Validation loss: 2.466772287050869

Epoch: 6| Step: 13
Training loss: 2.8872079808920517
Validation loss: 2.4543052610249263

Epoch: 133| Step: 0
Training loss: 2.8084883159430403
Validation loss: 2.444972766659377

Epoch: 6| Step: 1
Training loss: 2.480698462234914
Validation loss: 2.4705464587220187

Epoch: 6| Step: 2
Training loss: 3.040298014639727
Validation loss: 2.4436794666217674

Epoch: 6| Step: 3
Training loss: 2.7182398350312527
Validation loss: 2.459386416118686

Epoch: 6| Step: 4
Training loss: 2.155461485056509
Validation loss: 2.460998348975442

Epoch: 6| Step: 5
Training loss: 2.4754826932366463
Validation loss: 2.463618431169216

Epoch: 6| Step: 6
Training loss: 2.6436502857206583
Validation loss: 2.4750158375929083

Epoch: 6| Step: 7
Training loss: 2.665173609305183
Validation loss: 2.4576294296024455

Epoch: 6| Step: 8
Training loss: 2.5199716109235912
Validation loss: 2.462803776415678

Epoch: 6| Step: 9
Training loss: 3.0242332180251634
Validation loss: 2.464805943234376

Epoch: 6| Step: 10
Training loss: 1.9887252341885715
Validation loss: 2.494181262351981

Epoch: 6| Step: 11
Training loss: 3.194860300463471
Validation loss: 2.4767453088766307

Epoch: 6| Step: 12
Training loss: 2.557603950364275
Validation loss: 2.463375331960179

Epoch: 6| Step: 13
Training loss: 3.1626705922793406
Validation loss: 2.458253854669888

Epoch: 134| Step: 0
Training loss: 2.958757146287611
Validation loss: 2.450426908284093

Epoch: 6| Step: 1
Training loss: 2.6604571067307496
Validation loss: 2.4719082314665024

Epoch: 6| Step: 2
Training loss: 2.568767048206049
Validation loss: 2.467618012686359

Epoch: 6| Step: 3
Training loss: 2.7801442037546638
Validation loss: 2.460609684270741

Epoch: 6| Step: 4
Training loss: 2.4780025687646985
Validation loss: 2.45385168559803

Epoch: 6| Step: 5
Training loss: 2.5307831510313057
Validation loss: 2.458876993066622

Epoch: 6| Step: 6
Training loss: 1.9179365539956184
Validation loss: 2.4487851360203825

Epoch: 6| Step: 7
Training loss: 2.8298698648786726
Validation loss: 2.442059279263072

Epoch: 6| Step: 8
Training loss: 2.2098911356975304
Validation loss: 2.4483901809312387

Epoch: 6| Step: 9
Training loss: 2.576834985911341
Validation loss: 2.4579090606027343

Epoch: 6| Step: 10
Training loss: 2.715054861958112
Validation loss: 2.4454784114898493

Epoch: 6| Step: 11
Training loss: 2.7974628704426316
Validation loss: 2.4558301131589046

Epoch: 6| Step: 12
Training loss: 3.150816366585006
Validation loss: 2.4693832447213784

Epoch: 6| Step: 13
Training loss: 3.059975965816881
Validation loss: 2.446643478522517

Epoch: 135| Step: 0
Training loss: 3.309942445744431
Validation loss: 2.4605581714900286

Epoch: 6| Step: 1
Training loss: 2.419412850330476
Validation loss: 2.464647007439363

Epoch: 6| Step: 2
Training loss: 3.0837669754952746
Validation loss: 2.453972865304089

Epoch: 6| Step: 3
Training loss: 2.559830368203536
Validation loss: 2.4585420991934233

Epoch: 6| Step: 4
Training loss: 2.382561141967787
Validation loss: 2.459950528514861

Epoch: 6| Step: 5
Training loss: 2.4044390713053283
Validation loss: 2.458381523743149

Epoch: 6| Step: 6
Training loss: 2.4028478574241303
Validation loss: 2.4588206979378153

Epoch: 6| Step: 7
Training loss: 2.688665270461251
Validation loss: 2.4633638238460893

Epoch: 6| Step: 8
Training loss: 3.073242032342306
Validation loss: 2.450859188132817

Epoch: 6| Step: 9
Training loss: 2.0813304301348974
Validation loss: 2.4504616029617172

Epoch: 6| Step: 10
Training loss: 2.581738892594232
Validation loss: 2.4594387206248363

Epoch: 6| Step: 11
Training loss: 2.597486814551716
Validation loss: 2.4772464543625983

Epoch: 6| Step: 12
Training loss: 2.6855284090274227
Validation loss: 2.4439573018917145

Epoch: 6| Step: 13
Training loss: 3.2045651059559623
Validation loss: 2.4470335726113084

Epoch: 136| Step: 0
Training loss: 3.397878877175088
Validation loss: 2.4805476949872274

Epoch: 6| Step: 1
Training loss: 2.266987147768909
Validation loss: 2.4590000081490033

Epoch: 6| Step: 2
Training loss: 3.178618530242851
Validation loss: 2.438990662758257

Epoch: 6| Step: 3
Training loss: 3.040870109315509
Validation loss: 2.469842425812719

Epoch: 6| Step: 4
Training loss: 2.306877104728026
Validation loss: 2.464954585970555

Epoch: 6| Step: 5
Training loss: 2.6647316548154136
Validation loss: 2.443530137156269

Epoch: 6| Step: 6
Training loss: 2.488955898839839
Validation loss: 2.4575571277705563

Epoch: 6| Step: 7
Training loss: 2.6367350259914324
Validation loss: 2.4637011813905487

Epoch: 6| Step: 8
Training loss: 2.8931708594672236
Validation loss: 2.4331747173048983

Epoch: 6| Step: 9
Training loss: 2.11430754217641
Validation loss: 2.455191361736121

Epoch: 6| Step: 10
Training loss: 2.8899967645013245
Validation loss: 2.4539350033611194

Epoch: 6| Step: 11
Training loss: 2.631137575479677
Validation loss: 2.4561788939489175

Epoch: 6| Step: 12
Training loss: 1.7031007817497563
Validation loss: 2.459114074479365

Epoch: 6| Step: 13
Training loss: 3.0202419535237084
Validation loss: 2.442077025837793

Epoch: 137| Step: 0
Training loss: 2.369757839981505
Validation loss: 2.4574704662501157

Epoch: 6| Step: 1
Training loss: 2.148710809142753
Validation loss: 2.4415375794230383

Epoch: 6| Step: 2
Training loss: 3.313266737388268
Validation loss: 2.460352574305438

Epoch: 6| Step: 3
Training loss: 2.2809602736342125
Validation loss: 2.453301611434869

Epoch: 6| Step: 4
Training loss: 2.642776515643993
Validation loss: 2.4580998199443

Epoch: 6| Step: 5
Training loss: 2.9245169216220166
Validation loss: 2.4687798787587383

Epoch: 6| Step: 6
Training loss: 2.637111154249696
Validation loss: 2.4669256327010345

Epoch: 6| Step: 7
Training loss: 3.068728127955167
Validation loss: 2.441859520884949

Epoch: 6| Step: 8
Training loss: 2.503999467325611
Validation loss: 2.4649743798494983

Epoch: 6| Step: 9
Training loss: 2.507001418866128
Validation loss: 2.45290620359901

Epoch: 6| Step: 10
Training loss: 2.4749271035296463
Validation loss: 2.455303229624496

Epoch: 6| Step: 11
Training loss: 2.294999375353626
Validation loss: 2.4722337754385846

Epoch: 6| Step: 12
Training loss: 3.2963328706741843
Validation loss: 2.462577942644885

Epoch: 6| Step: 13
Training loss: 2.175802727255982
Validation loss: 2.4620805238680066

Epoch: 138| Step: 0
Training loss: 2.9166876292610717
Validation loss: 2.4671348500229033

Epoch: 6| Step: 1
Training loss: 2.6590927171441656
Validation loss: 2.4688661567980907

Epoch: 6| Step: 2
Training loss: 2.819949985358229
Validation loss: 2.466939391212882

Epoch: 6| Step: 3
Training loss: 2.900806867227984
Validation loss: 2.4745503339148827

Epoch: 6| Step: 4
Training loss: 2.344835767383502
Validation loss: 2.4636814480413576

Epoch: 6| Step: 5
Training loss: 2.8038691014687878
Validation loss: 2.4658123704442656

Epoch: 6| Step: 6
Training loss: 2.4968606311064767
Validation loss: 2.475676406282015

Epoch: 6| Step: 7
Training loss: 2.5898628982135268
Validation loss: 2.467572129702417

Epoch: 6| Step: 8
Training loss: 2.547223962385479
Validation loss: 2.457428726299224

Epoch: 6| Step: 9
Training loss: 2.4185283549478025
Validation loss: 2.4479912360115095

Epoch: 6| Step: 10
Training loss: 2.8661908072653404
Validation loss: 2.4615132340883923

Epoch: 6| Step: 11
Training loss: 3.1141798763864355
Validation loss: 2.4750878862968997

Epoch: 6| Step: 12
Training loss: 1.5944940662674354
Validation loss: 2.4754589506723277

Epoch: 6| Step: 13
Training loss: 2.7602448799853523
Validation loss: 2.471180670581093

Epoch: 139| Step: 0
Training loss: 2.5795223264073686
Validation loss: 2.4584720020454096

Epoch: 6| Step: 1
Training loss: 2.2762206565142873
Validation loss: 2.4498024977032897

Epoch: 6| Step: 2
Training loss: 2.8831982031525527
Validation loss: 2.442735302727667

Epoch: 6| Step: 3
Training loss: 2.9614656727141146
Validation loss: 2.459369861862028

Epoch: 6| Step: 4
Training loss: 2.8284979305654248
Validation loss: 2.4622502391185037

Epoch: 6| Step: 5
Training loss: 2.5919431344729205
Validation loss: 2.455978284006357

Epoch: 6| Step: 6
Training loss: 2.9876030046270934
Validation loss: 2.4462597442802947

Epoch: 6| Step: 7
Training loss: 3.164240024437302
Validation loss: 2.4350874404223255

Epoch: 6| Step: 8
Training loss: 2.370697742555988
Validation loss: 2.445786504466111

Epoch: 6| Step: 9
Training loss: 2.7397352594716495
Validation loss: 2.456316939264808

Epoch: 6| Step: 10
Training loss: 2.490976069080833
Validation loss: 2.4390975748345376

Epoch: 6| Step: 11
Training loss: 1.7707754985864366
Validation loss: 2.4482021520515724

Epoch: 6| Step: 12
Training loss: 2.76013077509008
Validation loss: 2.473095517089424

Epoch: 6| Step: 13
Training loss: 2.5692287583652957
Validation loss: 2.4586775197945894

Epoch: 140| Step: 0
Training loss: 3.0312205834288655
Validation loss: 2.4587665055950443

Epoch: 6| Step: 1
Training loss: 2.8383654245147953
Validation loss: 2.4655896487317315

Epoch: 6| Step: 2
Training loss: 2.813752128773125
Validation loss: 2.449757778565612

Epoch: 6| Step: 3
Training loss: 2.9049008427044156
Validation loss: 2.4458003446827914

Epoch: 6| Step: 4
Training loss: 2.4721471856072625
Validation loss: 2.455485349391558

Epoch: 6| Step: 5
Training loss: 2.5183995270460815
Validation loss: 2.442461194707421

Epoch: 6| Step: 6
Training loss: 2.863209972040846
Validation loss: 2.4511423850866554

Epoch: 6| Step: 7
Training loss: 2.3102178911764826
Validation loss: 2.4486035690802748

Epoch: 6| Step: 8
Training loss: 2.898741837227248
Validation loss: 2.4629072274142123

Epoch: 6| Step: 9
Training loss: 3.0307651407287954
Validation loss: 2.4533624690214175

Epoch: 6| Step: 10
Training loss: 1.6607394282463774
Validation loss: 2.4451419021607714

Epoch: 6| Step: 11
Training loss: 2.222502852310393
Validation loss: 2.4523952337377724

Epoch: 6| Step: 12
Training loss: 2.779500432444863
Validation loss: 2.467624130837916

Epoch: 6| Step: 13
Training loss: 2.4030674286334204
Validation loss: 2.449774733695708

Epoch: 141| Step: 0
Training loss: 2.514117814161438
Validation loss: 2.459754089742082

Epoch: 6| Step: 1
Training loss: 2.006284733646897
Validation loss: 2.4742560087862353

Epoch: 6| Step: 2
Training loss: 2.7792233573320777
Validation loss: 2.450811881291126

Epoch: 6| Step: 3
Training loss: 2.385723399690656
Validation loss: 2.4447797026886473

Epoch: 6| Step: 4
Training loss: 2.4681702911015813
Validation loss: 2.4505275447991073

Epoch: 6| Step: 5
Training loss: 2.676085606549982
Validation loss: 2.4535028843131164

Epoch: 6| Step: 6
Training loss: 2.822807582047291
Validation loss: 2.474417741710949

Epoch: 6| Step: 7
Training loss: 2.564833067431064
Validation loss: 2.466256928176878

Epoch: 6| Step: 8
Training loss: 2.9854239173334367
Validation loss: 2.4519144173303116

Epoch: 6| Step: 9
Training loss: 2.5381197543678287
Validation loss: 2.4733360465561436

Epoch: 6| Step: 10
Training loss: 2.5638681806520416
Validation loss: 2.473095362634222

Epoch: 6| Step: 11
Training loss: 2.8672111156852718
Validation loss: 2.4537531895737166

Epoch: 6| Step: 12
Training loss: 3.193629635448213
Validation loss: 2.491012839035289

Epoch: 6| Step: 13
Training loss: 2.607286999818042
Validation loss: 2.4733607501236343

Epoch: 142| Step: 0
Training loss: 2.8590628031410374
Validation loss: 2.449429896308454

Epoch: 6| Step: 1
Training loss: 2.61823527300818
Validation loss: 2.462751402846974

Epoch: 6| Step: 2
Training loss: 2.730964495578593
Validation loss: 2.4525041684859565

Epoch: 6| Step: 3
Training loss: 2.6192539540463335
Validation loss: 2.452454221757174

Epoch: 6| Step: 4
Training loss: 3.265224012369159
Validation loss: 2.442162873137773

Epoch: 6| Step: 5
Training loss: 2.483762845609456
Validation loss: 2.4713833721797784

Epoch: 6| Step: 6
Training loss: 1.8721341165525796
Validation loss: 2.4498830179292144

Epoch: 6| Step: 7
Training loss: 2.2967451409200996
Validation loss: 2.463072279510869

Epoch: 6| Step: 8
Training loss: 2.085720665337796
Validation loss: 2.4265677080285464

Epoch: 6| Step: 9
Training loss: 2.660080963279346
Validation loss: 2.4445413317486047

Epoch: 6| Step: 10
Training loss: 1.8636485763369561
Validation loss: 2.458680370509812

Epoch: 6| Step: 11
Training loss: 3.7645977724379307
Validation loss: 2.4771205979366724

Epoch: 6| Step: 12
Training loss: 3.170995430598099
Validation loss: 2.4568827816207497

Epoch: 6| Step: 13
Training loss: 1.9290254515120262
Validation loss: 2.4562823818267945

Epoch: 143| Step: 0
Training loss: 2.506753382941406
Validation loss: 2.4536027988403175

Epoch: 6| Step: 1
Training loss: 2.7464564641435762
Validation loss: 2.4419746870590897

Epoch: 6| Step: 2
Training loss: 2.241239234230409
Validation loss: 2.4492501994783282

Epoch: 6| Step: 3
Training loss: 2.349908088347636
Validation loss: 2.4618449241214497

Epoch: 6| Step: 4
Training loss: 2.422528775480239
Validation loss: 2.4376734589563114

Epoch: 6| Step: 5
Training loss: 2.4391421141940177
Validation loss: 2.4497546171251527

Epoch: 6| Step: 6
Training loss: 2.445524846323753
Validation loss: 2.459875198581366

Epoch: 6| Step: 7
Training loss: 2.7882911619959887
Validation loss: 2.4493663201904687

Epoch: 6| Step: 8
Training loss: 2.5204248544016923
Validation loss: 2.447371744016123

Epoch: 6| Step: 9
Training loss: 3.0615525629097053
Validation loss: 2.451243500250756

Epoch: 6| Step: 10
Training loss: 2.724633788953119
Validation loss: 2.4705723362905694

Epoch: 6| Step: 11
Training loss: 2.5232931278843758
Validation loss: 2.4671845639747714

Epoch: 6| Step: 12
Training loss: 3.7206662153681083
Validation loss: 2.4592512915168063

Epoch: 6| Step: 13
Training loss: 2.0818755071909094
Validation loss: 2.4668965696124623

Epoch: 144| Step: 0
Training loss: 2.101336045100468
Validation loss: 2.448604741698358

Epoch: 6| Step: 1
Training loss: 3.188770863619163
Validation loss: 2.4295340721282583

Epoch: 6| Step: 2
Training loss: 3.253433028267431
Validation loss: 2.454885086112913

Epoch: 6| Step: 3
Training loss: 2.739328573200357
Validation loss: 2.476258386254632

Epoch: 6| Step: 4
Training loss: 2.566315299502612
Validation loss: 2.459360666857783

Epoch: 6| Step: 5
Training loss: 2.029074222513797
Validation loss: 2.462571398662594

Epoch: 6| Step: 6
Training loss: 2.5523966279053454
Validation loss: 2.4506880119158096

Epoch: 6| Step: 7
Training loss: 2.8565857003428623
Validation loss: 2.4654895929689498

Epoch: 6| Step: 8
Training loss: 2.84544808129145
Validation loss: 2.4675277310463293

Epoch: 6| Step: 9
Training loss: 2.561103719515373
Validation loss: 2.447924496427192

Epoch: 6| Step: 10
Training loss: 1.941927496400325
Validation loss: 2.4526490951081152

Epoch: 6| Step: 11
Training loss: 2.5086065918704508
Validation loss: 2.4585230340306525

Epoch: 6| Step: 12
Training loss: 2.4941649051162544
Validation loss: 2.4493025896067

Epoch: 6| Step: 13
Training loss: 3.3030749415535583
Validation loss: 2.4623572521853943

Epoch: 145| Step: 0
Training loss: 2.114043093167229
Validation loss: 2.4244708547952722

Epoch: 6| Step: 1
Training loss: 2.3252084372004638
Validation loss: 2.4397311741378735

Epoch: 6| Step: 2
Training loss: 2.383858873094432
Validation loss: 2.47246932101862

Epoch: 6| Step: 3
Training loss: 2.3334563994877957
Validation loss: 2.472993646087677

Epoch: 6| Step: 4
Training loss: 2.36903696863355
Validation loss: 2.4486313076293564

Epoch: 6| Step: 5
Training loss: 2.6818286582554056
Validation loss: 2.469335359684735

Epoch: 6| Step: 6
Training loss: 2.638119744984938
Validation loss: 2.4720695859897797

Epoch: 6| Step: 7
Training loss: 3.3551070670086385
Validation loss: 2.4672675935901043

Epoch: 6| Step: 8
Training loss: 3.194494315232649
Validation loss: 2.4769306069094177

Epoch: 6| Step: 9
Training loss: 2.784858933853495
Validation loss: 2.4604773077310895

Epoch: 6| Step: 10
Training loss: 2.509063598769405
Validation loss: 2.444418997537358

Epoch: 6| Step: 11
Training loss: 2.417396194138651
Validation loss: 2.4501956159271328

Epoch: 6| Step: 12
Training loss: 2.8219462811326923
Validation loss: 2.4771523772566204

Epoch: 6| Step: 13
Training loss: 2.891050565168539
Validation loss: 2.463077710558183

Epoch: 146| Step: 0
Training loss: 2.3881176534068986
Validation loss: 2.4637677547840466

Epoch: 6| Step: 1
Training loss: 2.5855217452498658
Validation loss: 2.461594052360975

Epoch: 6| Step: 2
Training loss: 2.1132257422527596
Validation loss: 2.48222135033075

Epoch: 6| Step: 3
Training loss: 2.6260588190793914
Validation loss: 2.45400309948786

Epoch: 6| Step: 4
Training loss: 2.559223126759901
Validation loss: 2.4643833363607133

Epoch: 6| Step: 5
Training loss: 2.2355183697045797
Validation loss: 2.447184159631498

Epoch: 6| Step: 6
Training loss: 3.0954384868155884
Validation loss: 2.4412961185677418

Epoch: 6| Step: 7
Training loss: 3.932607244834712
Validation loss: 2.4653744708409153

Epoch: 6| Step: 8
Training loss: 2.483764573444679
Validation loss: 2.4764783876088754

Epoch: 6| Step: 9
Training loss: 2.0301938172068215
Validation loss: 2.4678423079827665

Epoch: 6| Step: 10
Training loss: 2.362092329102233
Validation loss: 2.441773384168874

Epoch: 6| Step: 11
Training loss: 2.5852581872149187
Validation loss: 2.471710283846048

Epoch: 6| Step: 12
Training loss: 2.735307719687241
Validation loss: 2.4540676377405872

Epoch: 6| Step: 13
Training loss: 2.7675163569048844
Validation loss: 2.4587351194496825

Epoch: 147| Step: 0
Training loss: 3.1278121502171286
Validation loss: 2.4494525389426633

Epoch: 6| Step: 1
Training loss: 3.138804653091453
Validation loss: 2.4600564046396483

Epoch: 6| Step: 2
Training loss: 2.2589974115567113
Validation loss: 2.4480394076485665

Epoch: 6| Step: 3
Training loss: 2.8500758646187
Validation loss: 2.4548884811353475

Epoch: 6| Step: 4
Training loss: 2.311553142632325
Validation loss: 2.463349258584458

Epoch: 6| Step: 5
Training loss: 2.905586905357918
Validation loss: 2.453212619687883

Epoch: 6| Step: 6
Training loss: 2.8869642016546972
Validation loss: 2.460373628483438

Epoch: 6| Step: 7
Training loss: 2.507899107581358
Validation loss: 2.4703219585568803

Epoch: 6| Step: 8
Training loss: 1.6034189025478431
Validation loss: 2.478921416069605

Epoch: 6| Step: 9
Training loss: 2.4655460862366643
Validation loss: 2.448293787685877

Epoch: 6| Step: 10
Training loss: 3.238004555287258
Validation loss: 2.4565045291227063

Epoch: 6| Step: 11
Training loss: 2.5359407454285976
Validation loss: 2.456923211944549

Epoch: 6| Step: 12
Training loss: 2.4609146359304934
Validation loss: 2.470848401469553

Epoch: 6| Step: 13
Training loss: 2.1388760961284885
Validation loss: 2.4536698625024314

Epoch: 148| Step: 0
Training loss: 2.4871115338049665
Validation loss: 2.4397779663367825

Epoch: 6| Step: 1
Training loss: 2.4610517202845963
Validation loss: 2.4499625801458342

Epoch: 6| Step: 2
Training loss: 2.7575456960286324
Validation loss: 2.476147870933769

Epoch: 6| Step: 3
Training loss: 2.9232182806407003
Validation loss: 2.476838837344498

Epoch: 6| Step: 4
Training loss: 1.813347848361956
Validation loss: 2.4665967918776905

Epoch: 6| Step: 5
Training loss: 2.3224881950218013
Validation loss: 2.452732704574798

Epoch: 6| Step: 6
Training loss: 2.7978121929494484
Validation loss: 2.4594426190786978

Epoch: 6| Step: 7
Training loss: 2.1379475799785945
Validation loss: 2.442649015850425

Epoch: 6| Step: 8
Training loss: 3.2086345646790817
Validation loss: 2.445285451918262

Epoch: 6| Step: 9
Training loss: 2.7685723413513426
Validation loss: 2.4695478972130487

Epoch: 6| Step: 10
Training loss: 2.191004643214645
Validation loss: 2.4419004828834

Epoch: 6| Step: 11
Training loss: 2.8660771769256734
Validation loss: 2.4524571392904324

Epoch: 6| Step: 12
Training loss: 2.801439620225691
Validation loss: 2.467954351380981

Epoch: 6| Step: 13
Training loss: 3.261124279191312
Validation loss: 2.4692758197770717

Epoch: 149| Step: 0
Training loss: 2.5257412341812566
Validation loss: 2.446450967654209

Epoch: 6| Step: 1
Training loss: 2.4489450012735476
Validation loss: 2.445212711176186

Epoch: 6| Step: 2
Training loss: 2.6727726192614445
Validation loss: 2.477268049524312

Epoch: 6| Step: 3
Training loss: 2.1145798506183477
Validation loss: 2.4489265831943623

Epoch: 6| Step: 4
Training loss: 2.5524033533942023
Validation loss: 2.4340977377085538

Epoch: 6| Step: 5
Training loss: 2.5684698392951106
Validation loss: 2.4605241096577455

Epoch: 6| Step: 6
Training loss: 2.8841323105702847
Validation loss: 2.471086202775687

Epoch: 6| Step: 7
Training loss: 2.5792335670023867
Validation loss: 2.444901511345591

Epoch: 6| Step: 8
Training loss: 2.7358438089080894
Validation loss: 2.460478554918801

Epoch: 6| Step: 9
Training loss: 3.12216164434756
Validation loss: 2.4760003189865194

Epoch: 6| Step: 10
Training loss: 3.2659447618381314
Validation loss: 2.4315778267965773

Epoch: 6| Step: 11
Training loss: 2.2537048355629543
Validation loss: 2.4492699972861773

Epoch: 6| Step: 12
Training loss: 2.6052569027267394
Validation loss: 2.4485473644182316

Epoch: 6| Step: 13
Training loss: 2.0819984991707647
Validation loss: 2.459654519935927

Epoch: 150| Step: 0
Training loss: 3.0554039156498694
Validation loss: 2.4312034931264166

Epoch: 6| Step: 1
Training loss: 2.6553173447374285
Validation loss: 2.4508098668839735

Epoch: 6| Step: 2
Training loss: 2.828961833417277
Validation loss: 2.4713111791666216

Epoch: 6| Step: 3
Training loss: 2.6066758135011523
Validation loss: 2.462624677062173

Epoch: 6| Step: 4
Training loss: 3.007491295247787
Validation loss: 2.4575310755987205

Epoch: 6| Step: 5
Training loss: 2.1405974894517006
Validation loss: 2.4756651614210896

Epoch: 6| Step: 6
Training loss: 2.5683868522769733
Validation loss: 2.4312826991706253

Epoch: 6| Step: 7
Training loss: 2.309683863487679
Validation loss: 2.5007195739473396

Epoch: 6| Step: 8
Training loss: 2.7273726257176816
Validation loss: 2.463443474129858

Epoch: 6| Step: 9
Training loss: 2.4592674765051674
Validation loss: 2.4628658221378537

Epoch: 6| Step: 10
Training loss: 2.68279368816661
Validation loss: 2.4796427315074165

Epoch: 6| Step: 11
Training loss: 2.2142201778716024
Validation loss: 2.461909467150042

Epoch: 6| Step: 12
Training loss: 2.8991056839100384
Validation loss: 2.4520834702652823

Epoch: 6| Step: 13
Training loss: 2.722550990780504
Validation loss: 2.4451872005819326

Epoch: 151| Step: 0
Training loss: 2.943944476723576
Validation loss: 2.4680430307492016

Epoch: 6| Step: 1
Training loss: 2.2748228486224473
Validation loss: 2.4820971570375927

Epoch: 6| Step: 2
Training loss: 2.282473928212805
Validation loss: 2.4676157665552525

Epoch: 6| Step: 3
Training loss: 2.6290810967579676
Validation loss: 2.465652622501905

Epoch: 6| Step: 4
Training loss: 2.471028013316813
Validation loss: 2.4607695981102746

Epoch: 6| Step: 5
Training loss: 2.3758366767416446
Validation loss: 2.4744854005625725

Epoch: 6| Step: 6
Training loss: 2.3582324362514973
Validation loss: 2.4640105843003046

Epoch: 6| Step: 7
Training loss: 2.558593470449651
Validation loss: 2.474188478361734

Epoch: 6| Step: 8
Training loss: 2.5626003897006067
Validation loss: 2.47056175929003

Epoch: 6| Step: 9
Training loss: 3.420050426356787
Validation loss: 2.4572824185796427

Epoch: 6| Step: 10
Training loss: 2.599850386202954
Validation loss: 2.480591026071871

Epoch: 6| Step: 11
Training loss: 2.5284885366737044
Validation loss: 2.462113254814504

Epoch: 6| Step: 12
Training loss: 3.3374637444630717
Validation loss: 2.4531553460020725

Epoch: 6| Step: 13
Training loss: 2.0469848370384147
Validation loss: 2.4524436868303288

Epoch: 152| Step: 0
Training loss: 2.2176977536898916
Validation loss: 2.4650060287169233

Epoch: 6| Step: 1
Training loss: 2.91202848489684
Validation loss: 2.4465415078473276

Epoch: 6| Step: 2
Training loss: 2.6448570512820364
Validation loss: 2.458819536447535

Epoch: 6| Step: 3
Training loss: 2.173833608834615
Validation loss: 2.449914863845043

Epoch: 6| Step: 4
Training loss: 2.681060795010391
Validation loss: 2.4575224933640767

Epoch: 6| Step: 5
Training loss: 3.1055981878979924
Validation loss: 2.462710870417778

Epoch: 6| Step: 6
Training loss: 2.206726593325605
Validation loss: 2.45748331952103

Epoch: 6| Step: 7
Training loss: 2.6210138845996522
Validation loss: 2.4528823705379854

Epoch: 6| Step: 8
Training loss: 3.0194614496096337
Validation loss: 2.4622651164651645

Epoch: 6| Step: 9
Training loss: 2.5237522932762997
Validation loss: 2.4660396368328987

Epoch: 6| Step: 10
Training loss: 2.1434532471726415
Validation loss: 2.4465113229158746

Epoch: 6| Step: 11
Training loss: 2.768942701811124
Validation loss: 2.461516741823142

Epoch: 6| Step: 12
Training loss: 2.264652438075919
Validation loss: 2.484274946475838

Epoch: 6| Step: 13
Training loss: 3.710939041940469
Validation loss: 2.462443490819541

Epoch: 153| Step: 0
Training loss: 3.167464774763128
Validation loss: 2.4538712420358175

Epoch: 6| Step: 1
Training loss: 2.8258558411650068
Validation loss: 2.4601952843297017

Epoch: 6| Step: 2
Training loss: 2.9915786801064717
Validation loss: 2.448765018648678

Epoch: 6| Step: 3
Training loss: 1.4341583387512487
Validation loss: 2.478876703073952

Epoch: 6| Step: 4
Training loss: 1.887499661477166
Validation loss: 2.4558086337820884

Epoch: 6| Step: 5
Training loss: 2.5955440337580016
Validation loss: 2.465139036671492

Epoch: 6| Step: 6
Training loss: 3.02950118437796
Validation loss: 2.461076281531562

Epoch: 6| Step: 7
Training loss: 3.036408744045025
Validation loss: 2.4623449886528723

Epoch: 6| Step: 8
Training loss: 2.637747737585274
Validation loss: 2.4742678040149126

Epoch: 6| Step: 9
Training loss: 2.673724153669288
Validation loss: 2.458528352082556

Epoch: 6| Step: 10
Training loss: 2.266352885162734
Validation loss: 2.4355204968658373

Epoch: 6| Step: 11
Training loss: 2.2787888719985734
Validation loss: 2.4400823516891412

Epoch: 6| Step: 12
Training loss: 2.561771661480145
Validation loss: 2.4744895229217465

Epoch: 6| Step: 13
Training loss: 2.78356383010754
Validation loss: 2.4558066106856917

Epoch: 154| Step: 0
Training loss: 2.300611816799588
Validation loss: 2.443140854091342

Epoch: 6| Step: 1
Training loss: 2.438497192637752
Validation loss: 2.4478597181857102

Epoch: 6| Step: 2
Training loss: 2.0919908563621945
Validation loss: 2.4679582062589946

Epoch: 6| Step: 3
Training loss: 2.697273491938428
Validation loss: 2.467269256086562

Epoch: 6| Step: 4
Training loss: 2.4387279254143044
Validation loss: 2.4510951226711346

Epoch: 6| Step: 5
Training loss: 2.203810240321952
Validation loss: 2.4618858748444308

Epoch: 6| Step: 6
Training loss: 2.737317404035303
Validation loss: 2.4588530776470883

Epoch: 6| Step: 7
Training loss: 2.8301918528197145
Validation loss: 2.458833194871242

Epoch: 6| Step: 8
Training loss: 2.139598293926923
Validation loss: 2.4605590518902463

Epoch: 6| Step: 9
Training loss: 3.075248497327086
Validation loss: 2.4778598234011624

Epoch: 6| Step: 10
Training loss: 2.5207244176954013
Validation loss: 2.4704005916621634

Epoch: 6| Step: 11
Training loss: 3.1030153191766425
Validation loss: 2.4713953232322456

Epoch: 6| Step: 12
Training loss: 2.9090756042034522
Validation loss: 2.4547275356162235

Epoch: 6| Step: 13
Training loss: 3.0481131361041576
Validation loss: 2.4438675177551183

Epoch: 155| Step: 0
Training loss: 2.568775494302804
Validation loss: 2.4776622250370983

Epoch: 6| Step: 1
Training loss: 2.1945938617469927
Validation loss: 2.4642385515938727

Epoch: 6| Step: 2
Training loss: 2.296679014810366
Validation loss: 2.4647585376951984

Epoch: 6| Step: 3
Training loss: 2.3024109021902266
Validation loss: 2.463436235193528

Epoch: 6| Step: 4
Training loss: 3.2879284423596626
Validation loss: 2.4733511028727233

Epoch: 6| Step: 5
Training loss: 2.7417156106895333
Validation loss: 2.4583549401230744

Epoch: 6| Step: 6
Training loss: 2.7614290120513028
Validation loss: 2.449651251158071

Epoch: 6| Step: 7
Training loss: 2.356572994688871
Validation loss: 2.4719297514044007

Epoch: 6| Step: 8
Training loss: 3.0659810737279525
Validation loss: 2.458550938033641

Epoch: 6| Step: 9
Training loss: 2.175670901775646
Validation loss: 2.4764389949804237

Epoch: 6| Step: 10
Training loss: 2.5012668260945383
Validation loss: 2.445000833695373

Epoch: 6| Step: 11
Training loss: 2.453451438614468
Validation loss: 2.4846064776458676

Epoch: 6| Step: 12
Training loss: 2.567869561777566
Validation loss: 2.4555561587294688

Epoch: 6| Step: 13
Training loss: 3.627920224163297
Validation loss: 2.46990948602761

Epoch: 156| Step: 0
Training loss: 2.7252796729522797
Validation loss: 2.4540226954610884

Epoch: 6| Step: 1
Training loss: 2.717214742812413
Validation loss: 2.462370733255158

Epoch: 6| Step: 2
Training loss: 2.750457378845686
Validation loss: 2.4721720643820246

Epoch: 6| Step: 3
Training loss: 3.092438699273544
Validation loss: 2.4790573681999106

Epoch: 6| Step: 4
Training loss: 2.531500909873321
Validation loss: 2.4535398668711474

Epoch: 6| Step: 5
Training loss: 2.608125398856598
Validation loss: 2.4533929489729647

Epoch: 6| Step: 6
Training loss: 3.4244536695026717
Validation loss: 2.459528376204002

Epoch: 6| Step: 7
Training loss: 2.7013836141195395
Validation loss: 2.459147240534584

Epoch: 6| Step: 8
Training loss: 1.5611554273391701
Validation loss: 2.4567993958244907

Epoch: 6| Step: 9
Training loss: 2.6765263988690218
Validation loss: 2.479738925507309

Epoch: 6| Step: 10
Training loss: 2.7632812223900904
Validation loss: 2.447788800888647

Epoch: 6| Step: 11
Training loss: 2.372418054224683
Validation loss: 2.464165353896155

Epoch: 6| Step: 12
Training loss: 2.2281653273518964
Validation loss: 2.4566065287189387

Epoch: 6| Step: 13
Training loss: 2.0922805412179266
Validation loss: 2.4718015686290062

Epoch: 157| Step: 0
Training loss: 2.7191039107159014
Validation loss: 2.477419414241734

Epoch: 6| Step: 1
Training loss: 2.9270535034252556
Validation loss: 2.4637912603947467

Epoch: 6| Step: 2
Training loss: 2.521653244308918
Validation loss: 2.465116070135859

Epoch: 6| Step: 3
Training loss: 2.4976963874042704
Validation loss: 2.471246132694269

Epoch: 6| Step: 4
Training loss: 2.6439586115207656
Validation loss: 2.482111649983718

Epoch: 6| Step: 5
Training loss: 2.76055840662168
Validation loss: 2.4640364254265514

Epoch: 6| Step: 6
Training loss: 2.262159130067674
Validation loss: 2.499645997692086

Epoch: 6| Step: 7
Training loss: 2.82644308248099
Validation loss: 2.4504524629335056

Epoch: 6| Step: 8
Training loss: 2.857869903838883
Validation loss: 2.473448836620286

Epoch: 6| Step: 9
Training loss: 2.6368739103652716
Validation loss: 2.462490492742473

Epoch: 6| Step: 10
Training loss: 2.742323130326375
Validation loss: 2.454531407869367

Epoch: 6| Step: 11
Training loss: 1.7110140709312365
Validation loss: 2.486426396727632

Epoch: 6| Step: 12
Training loss: 2.3219066756335325
Validation loss: 2.4590653848074115

Epoch: 6| Step: 13
Training loss: 3.3445725899778807
Validation loss: 2.4743417710637865

Epoch: 158| Step: 0
Training loss: 2.671660386774397
Validation loss: 2.4668451351136307

Epoch: 6| Step: 1
Training loss: 2.2121841636273665
Validation loss: 2.463092690111477

Epoch: 6| Step: 2
Training loss: 3.19653774358173
Validation loss: 2.4471064441330523

Epoch: 6| Step: 3
Training loss: 2.963694554537909
Validation loss: 2.432880201205237

Epoch: 6| Step: 4
Training loss: 2.830456863028793
Validation loss: 2.4692623032113987

Epoch: 6| Step: 5
Training loss: 2.509236819594572
Validation loss: 2.4549918563283653

Epoch: 6| Step: 6
Training loss: 2.607040548836709
Validation loss: 2.443165280079021

Epoch: 6| Step: 7
Training loss: 2.3530006446756437
Validation loss: 2.451064426923838

Epoch: 6| Step: 8
Training loss: 2.815594475482258
Validation loss: 2.4637512591013797

Epoch: 6| Step: 9
Training loss: 2.4191211425548653
Validation loss: 2.4661329527894935

Epoch: 6| Step: 10
Training loss: 2.328709676150795
Validation loss: 2.460039070179962

Epoch: 6| Step: 11
Training loss: 2.6828015086727017
Validation loss: 2.439118314284439

Epoch: 6| Step: 12
Training loss: 2.368033984829632
Validation loss: 2.465035043895108

Epoch: 6| Step: 13
Training loss: 2.695916415019661
Validation loss: 2.4529696357143704

Epoch: 159| Step: 0
Training loss: 3.1808147260044857
Validation loss: 2.464702644220538

Epoch: 6| Step: 1
Training loss: 2.173097115689667
Validation loss: 2.4557372878317953

Epoch: 6| Step: 2
Training loss: 3.311110871021282
Validation loss: 2.4477300554900636

Epoch: 6| Step: 3
Training loss: 2.7958874370799576
Validation loss: 2.482747711631353

Epoch: 6| Step: 4
Training loss: 2.3161898893079815
Validation loss: 2.4433654080525287

Epoch: 6| Step: 5
Training loss: 2.35595111114865
Validation loss: 2.464235411852243

Epoch: 6| Step: 6
Training loss: 3.0925953569566964
Validation loss: 2.479182437616657

Epoch: 6| Step: 7
Training loss: 2.421679778075599
Validation loss: 2.4794929753604595

Epoch: 6| Step: 8
Training loss: 2.7895315935171747
Validation loss: 2.464380938521687

Epoch: 6| Step: 9
Training loss: 2.3600610405091644
Validation loss: 2.4761242652009328

Epoch: 6| Step: 10
Training loss: 2.612119772952985
Validation loss: 2.4704181263414506

Epoch: 6| Step: 11
Training loss: 1.8022839943479938
Validation loss: 2.4476918882920646

Epoch: 6| Step: 12
Training loss: 2.3751526833695613
Validation loss: 2.473112551676719

Epoch: 6| Step: 13
Training loss: 2.6972410517187115
Validation loss: 2.468938420785765

Epoch: 160| Step: 0
Training loss: 2.6080545522214984
Validation loss: 2.468100672551522

Epoch: 6| Step: 1
Training loss: 2.8038529453434835
Validation loss: 2.4714742489340815

Epoch: 6| Step: 2
Training loss: 2.583007166381063
Validation loss: 2.455908071404685

Epoch: 6| Step: 3
Training loss: 2.043270635820139
Validation loss: 2.4718970301350507

Epoch: 6| Step: 4
Training loss: 2.7558277109383105
Validation loss: 2.461361804121138

Epoch: 6| Step: 5
Training loss: 2.328729026319129
Validation loss: 2.4783361451358217

Epoch: 6| Step: 6
Training loss: 2.5965258899604886
Validation loss: 2.480493432657679

Epoch: 6| Step: 7
Training loss: 2.381490672206772
Validation loss: 2.4658472450172018

Epoch: 6| Step: 8
Training loss: 2.509936612609252
Validation loss: 2.481947036143852

Epoch: 6| Step: 9
Training loss: 2.196149347525009
Validation loss: 2.4897897080194986

Epoch: 6| Step: 10
Training loss: 2.448615917139307
Validation loss: 2.4630077284419967

Epoch: 6| Step: 11
Training loss: 3.002023173639871
Validation loss: 2.4734741355402905

Epoch: 6| Step: 12
Training loss: 3.163994079603595
Validation loss: 2.4801297060173053

Epoch: 6| Step: 13
Training loss: 2.978970252189124
Validation loss: 2.464530650746619

Epoch: 161| Step: 0
Training loss: 2.3424935597073704
Validation loss: 2.491261576692358

Epoch: 6| Step: 1
Training loss: 3.226070190999926
Validation loss: 2.471239296817782

Epoch: 6| Step: 2
Training loss: 2.635645940605634
Validation loss: 2.4581335331386955

Epoch: 6| Step: 3
Training loss: 2.9224833298885664
Validation loss: 2.4675042615489797

Epoch: 6| Step: 4
Training loss: 2.2580481805518144
Validation loss: 2.4605722328503967

Epoch: 6| Step: 5
Training loss: 2.5906235569488594
Validation loss: 2.48159957377648

Epoch: 6| Step: 6
Training loss: 2.2600091194711522
Validation loss: 2.4511856701667827

Epoch: 6| Step: 7
Training loss: 2.6200331064127282
Validation loss: 2.472851315513167

Epoch: 6| Step: 8
Training loss: 2.599162326265678
Validation loss: 2.4596719634171924

Epoch: 6| Step: 9
Training loss: 2.202099933639892
Validation loss: 2.479558470296931

Epoch: 6| Step: 10
Training loss: 2.3946057256719526
Validation loss: 2.467180770233803

Epoch: 6| Step: 11
Training loss: 2.5779593674599797
Validation loss: 2.4572437020476117

Epoch: 6| Step: 12
Training loss: 2.880138945936531
Validation loss: 2.4675483546588333

Epoch: 6| Step: 13
Training loss: 3.1173883435551772
Validation loss: 2.443536873768017

Epoch: 162| Step: 0
Training loss: 2.3182876948625517
Validation loss: 2.461744890069573

Epoch: 6| Step: 1
Training loss: 2.4379154731548933
Validation loss: 2.4582763190425165

Epoch: 6| Step: 2
Training loss: 2.781720753809205
Validation loss: 2.4507967411620353

Epoch: 6| Step: 3
Training loss: 3.34161094625414
Validation loss: 2.4672694659766603

Epoch: 6| Step: 4
Training loss: 3.356874466808833
Validation loss: 2.462436739301232

Epoch: 6| Step: 5
Training loss: 2.3679085316390465
Validation loss: 2.468179060666433

Epoch: 6| Step: 6
Training loss: 2.4157075184376584
Validation loss: 2.447536751286864

Epoch: 6| Step: 7
Training loss: 2.710156242962219
Validation loss: 2.467491109306934

Epoch: 6| Step: 8
Training loss: 2.51017398109668
Validation loss: 2.448507342335915

Epoch: 6| Step: 9
Training loss: 2.4346040982726387
Validation loss: 2.4720505644874273

Epoch: 6| Step: 10
Training loss: 2.3040242938111932
Validation loss: 2.4663986352132055

Epoch: 6| Step: 11
Training loss: 2.710892119014074
Validation loss: 2.469192344795006

Epoch: 6| Step: 12
Training loss: 2.121130056052943
Validation loss: 2.481946163846875

Epoch: 6| Step: 13
Training loss: 2.4983265043966534
Validation loss: 2.4618168856302707

Epoch: 163| Step: 0
Training loss: 2.2335478845659265
Validation loss: 2.4698050578244146

Epoch: 6| Step: 1
Training loss: 2.5975958566170307
Validation loss: 2.4500876751083953

Epoch: 6| Step: 2
Training loss: 3.0786809274016336
Validation loss: 2.4487972622684233

Epoch: 6| Step: 3
Training loss: 2.6254569972825834
Validation loss: 2.449071512168116

Epoch: 6| Step: 4
Training loss: 2.5692031460660356
Validation loss: 2.4803267770576793

Epoch: 6| Step: 5
Training loss: 2.3089871918466365
Validation loss: 2.475275778029209

Epoch: 6| Step: 6
Training loss: 2.719095843888544
Validation loss: 2.44362491698465

Epoch: 6| Step: 7
Training loss: 2.5379583687039498
Validation loss: 2.47417845873091

Epoch: 6| Step: 8
Training loss: 2.9051629771543155
Validation loss: 2.4611115695679455

Epoch: 6| Step: 9
Training loss: 2.5645846749329846
Validation loss: 2.4763073124477057

Epoch: 6| Step: 10
Training loss: 2.5338086042133576
Validation loss: 2.473804549320322

Epoch: 6| Step: 11
Training loss: 2.9656915269309714
Validation loss: 2.4679928843088397

Epoch: 6| Step: 12
Training loss: 2.4398674838242846
Validation loss: 2.4651594000015935

Epoch: 6| Step: 13
Training loss: 2.290513135564679
Validation loss: 2.4547149561628507

Epoch: 164| Step: 0
Training loss: 2.368532912641106
Validation loss: 2.4626160485558355

Epoch: 6| Step: 1
Training loss: 2.521936117611038
Validation loss: 2.4651195498647107

Epoch: 6| Step: 2
Training loss: 2.2849125137108643
Validation loss: 2.484854651556168

Epoch: 6| Step: 3
Training loss: 2.7285000712580127
Validation loss: 2.4560695199154243

Epoch: 6| Step: 4
Training loss: 2.355453971955611
Validation loss: 2.4429445191677295

Epoch: 6| Step: 5
Training loss: 2.3276238638168993
Validation loss: 2.468430285132766

Epoch: 6| Step: 6
Training loss: 2.67077185628979
Validation loss: 2.460848675524832

Epoch: 6| Step: 7
Training loss: 2.727249102779139
Validation loss: 2.466297535380373

Epoch: 6| Step: 8
Training loss: 2.7497565421796466
Validation loss: 2.4644868125950583

Epoch: 6| Step: 9
Training loss: 3.094626408524525
Validation loss: 2.4775322310521872

Epoch: 6| Step: 10
Training loss: 3.0272254576183193
Validation loss: 2.4602483760829634

Epoch: 6| Step: 11
Training loss: 2.4991170277573063
Validation loss: 2.452641457427157

Epoch: 6| Step: 12
Training loss: 2.4405226916801976
Validation loss: 2.4647883514678752

Epoch: 6| Step: 13
Training loss: 2.636359657984156
Validation loss: 2.466979842216977

Epoch: 165| Step: 0
Training loss: 2.925394641304494
Validation loss: 2.4643793073656495

Epoch: 6| Step: 1
Training loss: 2.9034475945968636
Validation loss: 2.469259208271864

Epoch: 6| Step: 2
Training loss: 2.8978854987860903
Validation loss: 2.467738209924762

Epoch: 6| Step: 3
Training loss: 2.482445213274194
Validation loss: 2.467672455286945

Epoch: 6| Step: 4
Training loss: 2.70121971413485
Validation loss: 2.465593371097516

Epoch: 6| Step: 5
Training loss: 2.3143496977154143
Validation loss: 2.475966677709046

Epoch: 6| Step: 6
Training loss: 1.84873572787024
Validation loss: 2.4607910492906164

Epoch: 6| Step: 7
Training loss: 2.529610373609531
Validation loss: 2.458810396730185

Epoch: 6| Step: 8
Training loss: 2.518650297174661
Validation loss: 2.448264913370326

Epoch: 6| Step: 9
Training loss: 3.0171233096769345
Validation loss: 2.4716666383787333

Epoch: 6| Step: 10
Training loss: 2.1597426503132904
Validation loss: 2.4586086209437092

Epoch: 6| Step: 11
Training loss: 3.003065132870205
Validation loss: 2.473397420217025

Epoch: 6| Step: 12
Training loss: 2.300210205092105
Validation loss: 2.4651929006986615

Epoch: 6| Step: 13
Training loss: 2.674309407869814
Validation loss: 2.4688713985744237

Epoch: 166| Step: 0
Training loss: 2.5562260745544747
Validation loss: 2.476702277970729

Epoch: 6| Step: 1
Training loss: 2.712045404689901
Validation loss: 2.464646908623645

Epoch: 6| Step: 2
Training loss: 2.2523356077303074
Validation loss: 2.465084814753996

Epoch: 6| Step: 3
Training loss: 2.456078955831891
Validation loss: 2.4596544824139652

Epoch: 6| Step: 4
Training loss: 2.145916489653408
Validation loss: 2.5017424561320216

Epoch: 6| Step: 5
Training loss: 2.716895161324219
Validation loss: 2.4831905956035096

Epoch: 6| Step: 6
Training loss: 2.1172022519882163
Validation loss: 2.4529593088900703

Epoch: 6| Step: 7
Training loss: 2.6549647194912334
Validation loss: 2.47115028657501

Epoch: 6| Step: 8
Training loss: 2.3845039742761225
Validation loss: 2.4762109841037616

Epoch: 6| Step: 9
Training loss: 3.011532551393969
Validation loss: 2.446715936260525

Epoch: 6| Step: 10
Training loss: 2.57502310288815
Validation loss: 2.4680918943984347

Epoch: 6| Step: 11
Training loss: 2.8462164945309825
Validation loss: 2.4737750815292365

Epoch: 6| Step: 12
Training loss: 2.8384752924913728
Validation loss: 2.4814547387052093

Epoch: 6| Step: 13
Training loss: 3.4687963259241137
Validation loss: 2.4714759220856215

Epoch: 167| Step: 0
Training loss: 2.7957919277378895
Validation loss: 2.4619582172008907

Epoch: 6| Step: 1
Training loss: 2.6610421429507762
Validation loss: 2.455366666637116

Epoch: 6| Step: 2
Training loss: 2.1709823420582692
Validation loss: 2.437607815663737

Epoch: 6| Step: 3
Training loss: 2.726982980566628
Validation loss: 2.4818609416913255

Epoch: 6| Step: 4
Training loss: 3.005391680029514
Validation loss: 2.488269613410743

Epoch: 6| Step: 5
Training loss: 2.3675102794387803
Validation loss: 2.451262992783497

Epoch: 6| Step: 6
Training loss: 3.0685584418338374
Validation loss: 2.475907695911794

Epoch: 6| Step: 7
Training loss: 2.4787645628285415
Validation loss: 2.467721656634495

Epoch: 6| Step: 8
Training loss: 2.6801953070914952
Validation loss: 2.4631983302207554

Epoch: 6| Step: 9
Training loss: 2.9032311295901483
Validation loss: 2.4591068426061375

Epoch: 6| Step: 10
Training loss: 2.4678988377690674
Validation loss: 2.4322782342505653

Epoch: 6| Step: 11
Training loss: 2.26283713510814
Validation loss: 2.449013038303721

Epoch: 6| Step: 12
Training loss: 2.382952876724424
Validation loss: 2.462050323796777

Epoch: 6| Step: 13
Training loss: 2.165538848880796
Validation loss: 2.4698401282486615

Epoch: 168| Step: 0
Training loss: 2.6990941152767047
Validation loss: 2.4593526184645556

Epoch: 6| Step: 1
Training loss: 2.5017069711134488
Validation loss: 2.4781001288911115

Epoch: 6| Step: 2
Training loss: 2.5525181510197728
Validation loss: 2.474912580941441

Epoch: 6| Step: 3
Training loss: 2.358664298226544
Validation loss: 2.4669225098890277

Epoch: 6| Step: 4
Training loss: 2.611453753055126
Validation loss: 2.476879965566888

Epoch: 6| Step: 5
Training loss: 2.6686194144468405
Validation loss: 2.4716318894805687

Epoch: 6| Step: 6
Training loss: 2.3406208766600445
Validation loss: 2.453699842352665

Epoch: 6| Step: 7
Training loss: 2.641943968970702
Validation loss: 2.4588980275586856

Epoch: 6| Step: 8
Training loss: 2.1166372111916747
Validation loss: 2.4370220042743678

Epoch: 6| Step: 9
Training loss: 3.160144480528918
Validation loss: 2.469433684235087

Epoch: 6| Step: 10
Training loss: 1.7878512484227587
Validation loss: 2.4654822602182063

Epoch: 6| Step: 11
Training loss: 2.8671153212772817
Validation loss: 2.464906210317851

Epoch: 6| Step: 12
Training loss: 3.0570309130821753
Validation loss: 2.4675187092980124

Epoch: 6| Step: 13
Training loss: 2.635382962419705
Validation loss: 2.4645365206703196

Epoch: 169| Step: 0
Training loss: 2.03119037247217
Validation loss: 2.4862624072881383

Epoch: 6| Step: 1
Training loss: 2.8747848761971078
Validation loss: 2.457072537619461

Epoch: 6| Step: 2
Training loss: 2.5887203858439376
Validation loss: 2.4682350353698514

Epoch: 6| Step: 3
Training loss: 1.8503527975051097
Validation loss: 2.446209250850665

Epoch: 6| Step: 4
Training loss: 3.3086735919565036
Validation loss: 2.4695938950488414

Epoch: 6| Step: 5
Training loss: 2.6299404700326448
Validation loss: 2.4512512405973945

Epoch: 6| Step: 6
Training loss: 2.6352453565644383
Validation loss: 2.445926867298506

Epoch: 6| Step: 7
Training loss: 2.6405811193307644
Validation loss: 2.477963648337689

Epoch: 6| Step: 8
Training loss: 1.9084291353568659
Validation loss: 2.457067089124947

Epoch: 6| Step: 9
Training loss: 2.5440206622718136
Validation loss: 2.468397099443721

Epoch: 6| Step: 10
Training loss: 3.384205449895087
Validation loss: 2.439413040940387

Epoch: 6| Step: 11
Training loss: 1.9887118070089165
Validation loss: 2.4760945361521327

Epoch: 6| Step: 12
Training loss: 2.949930552295545
Validation loss: 2.464279649797904

Epoch: 6| Step: 13
Training loss: 2.491554777850379
Validation loss: 2.455283098834343

Epoch: 170| Step: 0
Training loss: 2.9451117409198426
Validation loss: 2.4532556393869696

Epoch: 6| Step: 1
Training loss: 2.2253271055338213
Validation loss: 2.4533686603412046

Epoch: 6| Step: 2
Training loss: 2.538199785826757
Validation loss: 2.498979901802281

Epoch: 6| Step: 3
Training loss: 2.45529574428928
Validation loss: 2.469361056843523

Epoch: 6| Step: 4
Training loss: 2.8860096970446145
Validation loss: 2.4702935814492224

Epoch: 6| Step: 5
Training loss: 2.6093813958917687
Validation loss: 2.4662677980626313

Epoch: 6| Step: 6
Training loss: 2.830910170078211
Validation loss: 2.4633070614566477

Epoch: 6| Step: 7
Training loss: 2.9959982567083077
Validation loss: 2.462616506606036

Epoch: 6| Step: 8
Training loss: 2.63181392398609
Validation loss: 2.4653011701245204

Epoch: 6| Step: 9
Training loss: 2.328871844017385
Validation loss: 2.4782577969217043

Epoch: 6| Step: 10
Training loss: 2.2799085043233505
Validation loss: 2.467627978959431

Epoch: 6| Step: 11
Training loss: 2.644480492063894
Validation loss: 2.477520811461797

Epoch: 6| Step: 12
Training loss: 1.8866247307707644
Validation loss: 2.4582163402429584

Epoch: 6| Step: 13
Training loss: 3.028544368777242
Validation loss: 2.4853998754368205

Epoch: 171| Step: 0
Training loss: 2.2007541750974786
Validation loss: 2.4490863575661037

Epoch: 6| Step: 1
Training loss: 2.83837953623606
Validation loss: 2.463218969786731

Epoch: 6| Step: 2
Training loss: 2.1666013512181004
Validation loss: 2.480511268055594

Epoch: 6| Step: 3
Training loss: 2.277284703217153
Validation loss: 2.4701758883157874

Epoch: 6| Step: 4
Training loss: 2.7211935528292046
Validation loss: 2.4724880344605626

Epoch: 6| Step: 5
Training loss: 2.6899683063440993
Validation loss: 2.477273389944878

Epoch: 6| Step: 6
Training loss: 2.601621060098942
Validation loss: 2.4537569131789803

Epoch: 6| Step: 7
Training loss: 2.484945555614383
Validation loss: 2.468571166413252

Epoch: 6| Step: 8
Training loss: 3.1025467471182764
Validation loss: 2.4855378403294544

Epoch: 6| Step: 9
Training loss: 2.4961363500741744
Validation loss: 2.487016582588748

Epoch: 6| Step: 10
Training loss: 2.482001268243581
Validation loss: 2.4716220244052525

Epoch: 6| Step: 11
Training loss: 3.061655667748489
Validation loss: 2.460227135351009

Epoch: 6| Step: 12
Training loss: 2.3246489311061715
Validation loss: 2.448241527804719

Epoch: 6| Step: 13
Training loss: 2.740828043985835
Validation loss: 2.479085735993431

Epoch: 172| Step: 0
Training loss: 2.30912513878204
Validation loss: 2.487776536019896

Epoch: 6| Step: 1
Training loss: 3.346991420683566
Validation loss: 2.458644946958313

Epoch: 6| Step: 2
Training loss: 1.8339782649741805
Validation loss: 2.468155485703692

Epoch: 6| Step: 3
Training loss: 1.6661896340838624
Validation loss: 2.4741761512052194

Epoch: 6| Step: 4
Training loss: 2.617540751288461
Validation loss: 2.495920849583813

Epoch: 6| Step: 5
Training loss: 2.686921345714124
Validation loss: 2.4619558399085566

Epoch: 6| Step: 6
Training loss: 2.8020652477337804
Validation loss: 2.4799935671615065

Epoch: 6| Step: 7
Training loss: 2.2246642470186124
Validation loss: 2.461680954038785

Epoch: 6| Step: 8
Training loss: 2.9659339800102256
Validation loss: 2.4503696367065158

Epoch: 6| Step: 9
Training loss: 2.4629530630281877
Validation loss: 2.489225865370047

Epoch: 6| Step: 10
Training loss: 3.0392815282977574
Validation loss: 2.4726171521057063

Epoch: 6| Step: 11
Training loss: 2.51524359613545
Validation loss: 2.4545045590352497

Epoch: 6| Step: 12
Training loss: 2.9063513953456384
Validation loss: 2.4800693202312303

Epoch: 6| Step: 13
Training loss: 2.3991608662704658
Validation loss: 2.4462976432736423

Epoch: 173| Step: 0
Training loss: 3.2732205922224553
Validation loss: 2.454839872655032

Epoch: 6| Step: 1
Training loss: 3.12529448075388
Validation loss: 2.4679708085829324

Epoch: 6| Step: 2
Training loss: 2.666702439147701
Validation loss: 2.4697633104266536

Epoch: 6| Step: 3
Training loss: 2.7575394708708423
Validation loss: 2.4890812268696023

Epoch: 6| Step: 4
Training loss: 2.3035383042565725
Validation loss: 2.4706796114761387

Epoch: 6| Step: 5
Training loss: 2.0787630177340866
Validation loss: 2.466401200517008

Epoch: 6| Step: 6
Training loss: 2.354667869035465
Validation loss: 2.4716251609869326

Epoch: 6| Step: 7
Training loss: 2.726042164992123
Validation loss: 2.481743615315432

Epoch: 6| Step: 8
Training loss: 1.8271894751078626
Validation loss: 2.461570789259812

Epoch: 6| Step: 9
Training loss: 1.7239538309858677
Validation loss: 2.4492690003082185

Epoch: 6| Step: 10
Training loss: 2.1645525986732443
Validation loss: 2.480856663688953

Epoch: 6| Step: 11
Training loss: 2.8915760022405426
Validation loss: 2.475085788846334

Epoch: 6| Step: 12
Training loss: 3.210745775573608
Validation loss: 2.468878908168034

Epoch: 6| Step: 13
Training loss: 2.164542354995019
Validation loss: 2.451841640609494

Epoch: 174| Step: 0
Training loss: 2.5077746617204832
Validation loss: 2.4565818064235523

Epoch: 6| Step: 1
Training loss: 3.4546951245552027
Validation loss: 2.4667397327654252

Epoch: 6| Step: 2
Training loss: 2.575416945987331
Validation loss: 2.4753198088268147

Epoch: 6| Step: 3
Training loss: 2.5072741539701044
Validation loss: 2.4528944655566725

Epoch: 6| Step: 4
Training loss: 3.116232819033564
Validation loss: 2.4809525770886665

Epoch: 6| Step: 5
Training loss: 2.227629288882633
Validation loss: 2.4671915757819454

Epoch: 6| Step: 6
Training loss: 2.3128583475781466
Validation loss: 2.4664920103447616

Epoch: 6| Step: 7
Training loss: 1.6591064005849396
Validation loss: 2.4645690759724515

Epoch: 6| Step: 8
Training loss: 2.7976248817421663
Validation loss: 2.462586814366573

Epoch: 6| Step: 9
Training loss: 2.6241857083129365
Validation loss: 2.4575842645473727

Epoch: 6| Step: 10
Training loss: 2.047123435282652
Validation loss: 2.4526193585042457

Epoch: 6| Step: 11
Training loss: 2.806708242813692
Validation loss: 2.4768268846114228

Epoch: 6| Step: 12
Training loss: 2.296405147321999
Validation loss: 2.478009116999219

Epoch: 6| Step: 13
Training loss: 2.9320930878978984
Validation loss: 2.472784613444023

Epoch: 175| Step: 0
Training loss: 2.148374910309889
Validation loss: 2.467365883651287

Epoch: 6| Step: 1
Training loss: 2.597345181533427
Validation loss: 2.468509249554781

Epoch: 6| Step: 2
Training loss: 2.38939320861919
Validation loss: 2.4706551804584866

Epoch: 6| Step: 3
Training loss: 2.140256863980849
Validation loss: 2.455076490795822

Epoch: 6| Step: 4
Training loss: 3.052470229345013
Validation loss: 2.4571131567982167

Epoch: 6| Step: 5
Training loss: 3.2810753185459913
Validation loss: 2.4734289011916792

Epoch: 6| Step: 6
Training loss: 3.1631059872685796
Validation loss: 2.467337983748803

Epoch: 6| Step: 7
Training loss: 2.4732870589946057
Validation loss: 2.4710401263777397

Epoch: 6| Step: 8
Training loss: 2.398574377869716
Validation loss: 2.4516101635694714

Epoch: 6| Step: 9
Training loss: 2.310750350957074
Validation loss: 2.4739062480700467

Epoch: 6| Step: 10
Training loss: 2.539141562771453
Validation loss: 2.4776342858716873

Epoch: 6| Step: 11
Training loss: 2.6081019054115258
Validation loss: 2.471319320358527

Epoch: 6| Step: 12
Training loss: 2.331746606372169
Validation loss: 2.4665289249502353

Epoch: 6| Step: 13
Training loss: 2.377548356391769
Validation loss: 2.4702660451521457

Epoch: 176| Step: 0
Training loss: 2.4459089337892643
Validation loss: 2.485303155787178

Epoch: 6| Step: 1
Training loss: 2.2805835325151538
Validation loss: 2.4408546524893375

Epoch: 6| Step: 2
Training loss: 2.26749421982202
Validation loss: 2.438613147312329

Epoch: 6| Step: 3
Training loss: 2.3557278568101965
Validation loss: 2.4540509619432798

Epoch: 6| Step: 4
Training loss: 2.6042342113636243
Validation loss: 2.4575263218351604

Epoch: 6| Step: 5
Training loss: 2.1716686123272995
Validation loss: 2.4792331105158856

Epoch: 6| Step: 6
Training loss: 2.6497331448913384
Validation loss: 2.4601878024164283

Epoch: 6| Step: 7
Training loss: 2.3016963880950874
Validation loss: 2.477330729016546

Epoch: 6| Step: 8
Training loss: 3.04235159769849
Validation loss: 2.460720964115905

Epoch: 6| Step: 9
Training loss: 3.0831951076007504
Validation loss: 2.4786453595177673

Epoch: 6| Step: 10
Training loss: 2.7168035445415977
Validation loss: 2.480069830877579

Epoch: 6| Step: 11
Training loss: 2.667321681003469
Validation loss: 2.479218535597207

Epoch: 6| Step: 12
Training loss: 2.3771252409182697
Validation loss: 2.4660741079599777

Epoch: 6| Step: 13
Training loss: 3.306317876396683
Validation loss: 2.4863001574204233

Epoch: 177| Step: 0
Training loss: 2.3351348212322343
Validation loss: 2.48261576531157

Epoch: 6| Step: 1
Training loss: 2.9569327213295264
Validation loss: 2.4748270254222233

Epoch: 6| Step: 2
Training loss: 2.869033260946445
Validation loss: 2.470798054647172

Epoch: 6| Step: 3
Training loss: 2.7036322850859333
Validation loss: 2.4613298886239843

Epoch: 6| Step: 4
Training loss: 3.177203883817994
Validation loss: 2.4743131287094564

Epoch: 6| Step: 5
Training loss: 2.1965196216244354
Validation loss: 2.4369081546970914

Epoch: 6| Step: 6
Training loss: 1.4323444795986384
Validation loss: 2.4679581875611367

Epoch: 6| Step: 7
Training loss: 2.5069064110723662
Validation loss: 2.4941263715509696

Epoch: 6| Step: 8
Training loss: 3.1485987922492162
Validation loss: 2.4844591886609964

Epoch: 6| Step: 9
Training loss: 2.882388861731174
Validation loss: 2.4685054941985505

Epoch: 6| Step: 10
Training loss: 2.5704037728380187
Validation loss: 2.476226010516101

Epoch: 6| Step: 11
Training loss: 1.8825754356721256
Validation loss: 2.44817309549575

Epoch: 6| Step: 12
Training loss: 2.485516363949146
Validation loss: 2.4834150777886266

Epoch: 6| Step: 13
Training loss: 2.7840824063371183
Validation loss: 2.472707395665011

Epoch: 178| Step: 0
Training loss: 2.1253671889861288
Validation loss: 2.4986729709481015

Epoch: 6| Step: 1
Training loss: 2.530274379763912
Validation loss: 2.4874295442418473

Epoch: 6| Step: 2
Training loss: 2.6326960416217444
Validation loss: 2.476369211356912

Epoch: 6| Step: 3
Training loss: 2.8758535362056503
Validation loss: 2.452872374139007

Epoch: 6| Step: 4
Training loss: 2.922991371061135
Validation loss: 2.462967584313879

Epoch: 6| Step: 5
Training loss: 2.711729170444857
Validation loss: 2.482967291328956

Epoch: 6| Step: 6
Training loss: 2.549157085602301
Validation loss: 2.447591524298808

Epoch: 6| Step: 7
Training loss: 2.235683031616711
Validation loss: 2.4580026706279976

Epoch: 6| Step: 8
Training loss: 2.344626199337097
Validation loss: 2.461105893557925

Epoch: 6| Step: 9
Training loss: 2.1833214223211623
Validation loss: 2.469655533504585

Epoch: 6| Step: 10
Training loss: 2.5962772236821503
Validation loss: 2.479390827474212

Epoch: 6| Step: 11
Training loss: 2.8052299633719695
Validation loss: 2.4520065635036983

Epoch: 6| Step: 12
Training loss: 2.9961739620129757
Validation loss: 2.4721397398663334

Epoch: 6| Step: 13
Training loss: 2.348751377594581
Validation loss: 2.462932016848267

Epoch: 179| Step: 0
Training loss: 2.3079872431939683
Validation loss: 2.4714033490042473

Epoch: 6| Step: 1
Training loss: 2.559478094425644
Validation loss: 2.4507804751276048

Epoch: 6| Step: 2
Training loss: 3.0011286202019263
Validation loss: 2.4601222586329308

Epoch: 6| Step: 3
Training loss: 2.9690998072077557
Validation loss: 2.453025134465129

Epoch: 6| Step: 4
Training loss: 2.499963378638025
Validation loss: 2.4700740920239186

Epoch: 6| Step: 5
Training loss: 2.5420176988011054
Validation loss: 2.4530602148679694

Epoch: 6| Step: 6
Training loss: 2.8130373971177502
Validation loss: 2.4580404281970103

Epoch: 6| Step: 7
Training loss: 1.932084174381896
Validation loss: 2.478923725383178

Epoch: 6| Step: 8
Training loss: 2.3440724468948275
Validation loss: 2.4591924383902217

Epoch: 6| Step: 9
Training loss: 2.88947813635121
Validation loss: 2.4631014793157195

Epoch: 6| Step: 10
Training loss: 2.8377803983238956
Validation loss: 2.4759274053320386

Epoch: 6| Step: 11
Training loss: 2.4997538445404337
Validation loss: 2.466120736100471

Epoch: 6| Step: 12
Training loss: 2.33712891269725
Validation loss: 2.465422145813134

Epoch: 6| Step: 13
Training loss: 2.3905757325524846
Validation loss: 2.473309396153578

Epoch: 180| Step: 0
Training loss: 2.79827428157526
Validation loss: 2.4530286851677423

Epoch: 6| Step: 1
Training loss: 2.0336292124531146
Validation loss: 2.475781367589962

Epoch: 6| Step: 2
Training loss: 2.794551800872768
Validation loss: 2.467684246662106

Epoch: 6| Step: 3
Training loss: 2.37566376495648
Validation loss: 2.4741400770561115

Epoch: 6| Step: 4
Training loss: 2.172102991665586
Validation loss: 2.4657502772212396

Epoch: 6| Step: 5
Training loss: 2.2914819007140443
Validation loss: 2.4933945216515374

Epoch: 6| Step: 6
Training loss: 2.819573556567297
Validation loss: 2.482548809265031

Epoch: 6| Step: 7
Training loss: 2.4895028988495125
Validation loss: 2.4907868446662795

Epoch: 6| Step: 8
Training loss: 2.831340837179321
Validation loss: 2.4757346676991827

Epoch: 6| Step: 9
Training loss: 2.8196489816355994
Validation loss: 2.4756360181572132

Epoch: 6| Step: 10
Training loss: 2.2708691118787345
Validation loss: 2.4773551304207517

Epoch: 6| Step: 11
Training loss: 2.700338261219528
Validation loss: 2.4960198703521326

Epoch: 6| Step: 12
Training loss: 2.956460350892006
Validation loss: 2.484248272560783

Epoch: 6| Step: 13
Training loss: 2.3564569478512474
Validation loss: 2.4676625536049506

Epoch: 181| Step: 0
Training loss: 2.4401934487623747
Validation loss: 2.4663021152779683

Epoch: 6| Step: 1
Training loss: 2.0784910639684804
Validation loss: 2.478398017165247

Epoch: 6| Step: 2
Training loss: 2.387753026845933
Validation loss: 2.4744854109228704

Epoch: 6| Step: 3
Training loss: 2.900288363622329
Validation loss: 2.4649135957448522

Epoch: 6| Step: 4
Training loss: 2.5562686052088344
Validation loss: 2.459641542514301

Epoch: 6| Step: 5
Training loss: 2.0846353531280895
Validation loss: 2.458308239769303

Epoch: 6| Step: 6
Training loss: 2.737212098890092
Validation loss: 2.4609751687891954

Epoch: 6| Step: 7
Training loss: 2.364102509356067
Validation loss: 2.4793470039107373

Epoch: 6| Step: 8
Training loss: 2.9007511415776035
Validation loss: 2.480530493389866

Epoch: 6| Step: 9
Training loss: 2.8848400067636373
Validation loss: 2.479763953490015

Epoch: 6| Step: 10
Training loss: 2.5753564939663023
Validation loss: 2.481574946026363

Epoch: 6| Step: 11
Training loss: 2.5054237659057073
Validation loss: 2.4751604414556017

Epoch: 6| Step: 12
Training loss: 3.173432367152576
Validation loss: 2.482836186328608

Epoch: 6| Step: 13
Training loss: 2.091786389008498
Validation loss: 2.4821095161216777

Epoch: 182| Step: 0
Training loss: 2.7872636908707236
Validation loss: 2.4657935023710853

Epoch: 6| Step: 1
Training loss: 2.880985497768861
Validation loss: 2.471390788042332

Epoch: 6| Step: 2
Training loss: 1.994772696010598
Validation loss: 2.474298661575759

Epoch: 6| Step: 3
Training loss: 2.351694502563254
Validation loss: 2.4640133185596036

Epoch: 6| Step: 4
Training loss: 2.534463984835785
Validation loss: 2.4858711326062632

Epoch: 6| Step: 5
Training loss: 2.1702364222331747
Validation loss: 2.4892239106290552

Epoch: 6| Step: 6
Training loss: 2.6721361713032254
Validation loss: 2.4748421337850113

Epoch: 6| Step: 7
Training loss: 2.8474824326453065
Validation loss: 2.4689666841949616

Epoch: 6| Step: 8
Training loss: 2.4529407213328756
Validation loss: 2.5047613394998294

Epoch: 6| Step: 9
Training loss: 2.1790685287560683
Validation loss: 2.4750392560599885

Epoch: 6| Step: 10
Training loss: 3.284121900510039
Validation loss: 2.4561917362349557

Epoch: 6| Step: 11
Training loss: 2.319744721377156
Validation loss: 2.4800371058834316

Epoch: 6| Step: 12
Training loss: 2.3187608250779155
Validation loss: 2.458916256263669

Epoch: 6| Step: 13
Training loss: 2.9596574175255097
Validation loss: 2.4643619512992148

Epoch: 183| Step: 0
Training loss: 2.5812701836413425
Validation loss: 2.458538497016724

Epoch: 6| Step: 1
Training loss: 2.3278279979126917
Validation loss: 2.4566311036236526

Epoch: 6| Step: 2
Training loss: 2.336354502325079
Validation loss: 2.4768017420747612

Epoch: 6| Step: 3
Training loss: 1.5635229195579161
Validation loss: 2.4663617914186133

Epoch: 6| Step: 4
Training loss: 2.0203562956722267
Validation loss: 2.469972515727986

Epoch: 6| Step: 5
Training loss: 3.1501929451115633
Validation loss: 2.4747667754410565

Epoch: 6| Step: 6
Training loss: 3.0799375512864247
Validation loss: 2.487747626352475

Epoch: 6| Step: 7
Training loss: 2.0293069789660634
Validation loss: 2.488496930967697

Epoch: 6| Step: 8
Training loss: 2.9148720442626344
Validation loss: 2.481438138476774

Epoch: 6| Step: 9
Training loss: 2.275045029749991
Validation loss: 2.4849649509108915

Epoch: 6| Step: 10
Training loss: 2.5328335929994807
Validation loss: 2.487800532004692

Epoch: 6| Step: 11
Training loss: 2.9206546948305183
Validation loss: 2.456781545854283

Epoch: 6| Step: 12
Training loss: 3.3348898750207066
Validation loss: 2.4797761236417197

Epoch: 6| Step: 13
Training loss: 2.075490902661351
Validation loss: 2.494664822338835

Epoch: 184| Step: 0
Training loss: 2.775893292687544
Validation loss: 2.4721087900245915

Epoch: 6| Step: 1
Training loss: 3.160059075105131
Validation loss: 2.4709050803634516

Epoch: 6| Step: 2
Training loss: 1.7805053760733422
Validation loss: 2.4820073462923884

Epoch: 6| Step: 3
Training loss: 3.069545349104248
Validation loss: 2.4646073757773475

Epoch: 6| Step: 4
Training loss: 1.9175459945513935
Validation loss: 2.478364022599775

Epoch: 6| Step: 5
Training loss: 2.6203619536599283
Validation loss: 2.4776582528151425

Epoch: 6| Step: 6
Training loss: 2.867619702768237
Validation loss: 2.471339204339367

Epoch: 6| Step: 7
Training loss: 2.0863512178966763
Validation loss: 2.4587655348847726

Epoch: 6| Step: 8
Training loss: 2.460004066370883
Validation loss: 2.467955387035946

Epoch: 6| Step: 9
Training loss: 2.1711206017886218
Validation loss: 2.4667174556340252

Epoch: 6| Step: 10
Training loss: 3.301887642790898
Validation loss: 2.466205365991965

Epoch: 6| Step: 11
Training loss: 2.0028385046742194
Validation loss: 2.491339992397342

Epoch: 6| Step: 12
Training loss: 2.5560808494210145
Validation loss: 2.483791396022866

Epoch: 6| Step: 13
Training loss: 2.778384328952731
Validation loss: 2.464530436462413

Epoch: 185| Step: 0
Training loss: 2.96773921423382
Validation loss: 2.4909245667671343

Epoch: 6| Step: 1
Training loss: 2.450108416747042
Validation loss: 2.4590454703870734

Epoch: 6| Step: 2
Training loss: 2.311898230533673
Validation loss: 2.4772648326410636

Epoch: 6| Step: 3
Training loss: 2.082200034566265
Validation loss: 2.4531096126214105

Epoch: 6| Step: 4
Training loss: 2.486447986911001
Validation loss: 2.457887239549761

Epoch: 6| Step: 5
Training loss: 2.4637641295517057
Validation loss: 2.465348762284813

Epoch: 6| Step: 6
Training loss: 2.153577502887603
Validation loss: 2.4733577660357526

Epoch: 6| Step: 7
Training loss: 2.2693811258639416
Validation loss: 2.4732448489873113

Epoch: 6| Step: 8
Training loss: 3.07356412284441
Validation loss: 2.4757505481839552

Epoch: 6| Step: 9
Training loss: 2.6450056949258514
Validation loss: 2.4418311143252973

Epoch: 6| Step: 10
Training loss: 2.808769294866032
Validation loss: 2.465771033705262

Epoch: 6| Step: 11
Training loss: 2.5730931971810493
Validation loss: 2.4766597059106212

Epoch: 6| Step: 12
Training loss: 2.961960588109284
Validation loss: 2.467884604160806

Epoch: 6| Step: 13
Training loss: 2.6346291633258505
Validation loss: 2.4799746131556892

Epoch: 186| Step: 0
Training loss: 2.682575238000183
Validation loss: 2.4665305390941294

Epoch: 6| Step: 1
Training loss: 2.650278087635895
Validation loss: 2.4752010921300944

Epoch: 6| Step: 2
Training loss: 2.604176533998233
Validation loss: 2.493431251829098

Epoch: 6| Step: 3
Training loss: 1.8385011994516436
Validation loss: 2.4743295446541547

Epoch: 6| Step: 4
Training loss: 1.9407540344487253
Validation loss: 2.476820843014922

Epoch: 6| Step: 5
Training loss: 2.9640293535743023
Validation loss: 2.5004187935584783

Epoch: 6| Step: 6
Training loss: 2.2703977627899783
Validation loss: 2.4849846978495416

Epoch: 6| Step: 7
Training loss: 2.5875538732845076
Validation loss: 2.4547970217050255

Epoch: 6| Step: 8
Training loss: 2.648691350873556
Validation loss: 2.4731610425428237

Epoch: 6| Step: 9
Training loss: 2.257690215181669
Validation loss: 2.460848238501884

Epoch: 6| Step: 10
Training loss: 3.8873415654024996
Validation loss: 2.4664259584719614

Epoch: 6| Step: 11
Training loss: 2.650370834602789
Validation loss: 2.467083621045479

Epoch: 6| Step: 12
Training loss: 2.2817062548743463
Validation loss: 2.4559682882043408

Epoch: 6| Step: 13
Training loss: 1.6786425511675958
Validation loss: 2.4767869830974423

Epoch: 187| Step: 0
Training loss: 2.65876803257059
Validation loss: 2.4667085717468313

Epoch: 6| Step: 1
Training loss: 2.4474055196198727
Validation loss: 2.482573529070647

Epoch: 6| Step: 2
Training loss: 3.1570095243699994
Validation loss: 2.451416898654913

Epoch: 6| Step: 3
Training loss: 2.35152458084305
Validation loss: 2.502225666533854

Epoch: 6| Step: 4
Training loss: 2.3872585154533414
Validation loss: 2.4829431877165815

Epoch: 6| Step: 5
Training loss: 2.220358574407317
Validation loss: 2.472570000529201

Epoch: 6| Step: 6
Training loss: 2.1202168206235603
Validation loss: 2.475104667908977

Epoch: 6| Step: 7
Training loss: 2.8098102847638566
Validation loss: 2.4707058004909292

Epoch: 6| Step: 8
Training loss: 2.7632568910499544
Validation loss: 2.4724455365562337

Epoch: 6| Step: 9
Training loss: 2.0765962642453477
Validation loss: 2.499548870319286

Epoch: 6| Step: 10
Training loss: 2.95203181625423
Validation loss: 2.461992742349337

Epoch: 6| Step: 11
Training loss: 2.432787717326706
Validation loss: 2.477092806868198

Epoch: 6| Step: 12
Training loss: 2.9167762372461934
Validation loss: 2.4760027563073224

Epoch: 6| Step: 13
Training loss: 2.2540164702388292
Validation loss: 2.48426748032645

Epoch: 188| Step: 0
Training loss: 2.33571457835771
Validation loss: 2.4667113258799986

Epoch: 6| Step: 1
Training loss: 2.9034523573025077
Validation loss: 2.469082724892981

Epoch: 6| Step: 2
Training loss: 2.9407426508557344
Validation loss: 2.486227719060539

Epoch: 6| Step: 3
Training loss: 2.36143979296805
Validation loss: 2.4669624576828317

Epoch: 6| Step: 4
Training loss: 2.7953683215346685
Validation loss: 2.454029299847559

Epoch: 6| Step: 5
Training loss: 2.90652513739837
Validation loss: 2.4710268274775857

Epoch: 6| Step: 6
Training loss: 2.6244377260645226
Validation loss: 2.4763096045290283

Epoch: 6| Step: 7
Training loss: 2.0765739905597016
Validation loss: 2.4919798561959245

Epoch: 6| Step: 8
Training loss: 3.0338538872496295
Validation loss: 2.491885495828571

Epoch: 6| Step: 9
Training loss: 2.714736080092889
Validation loss: 2.487023538482383

Epoch: 6| Step: 10
Training loss: 2.7287151943613455
Validation loss: 2.4676865322084818

Epoch: 6| Step: 11
Training loss: 1.6176761497084926
Validation loss: 2.465710310828213

Epoch: 6| Step: 12
Training loss: 1.5434782707975894
Validation loss: 2.4920622993832477

Epoch: 6| Step: 13
Training loss: 2.91957270853374
Validation loss: 2.5069461532724966

Epoch: 189| Step: 0
Training loss: 1.990837208023016
Validation loss: 2.4679298061272257

Epoch: 6| Step: 1
Training loss: 2.509625786473905
Validation loss: 2.4937128843138687

Epoch: 6| Step: 2
Training loss: 3.500548319781279
Validation loss: 2.4715762665780407

Epoch: 6| Step: 3
Training loss: 2.719795815152867
Validation loss: 2.475581270185058

Epoch: 6| Step: 4
Training loss: 2.3739702100290705
Validation loss: 2.4786003167689

Epoch: 6| Step: 5
Training loss: 2.106619384251113
Validation loss: 2.4715406025796756

Epoch: 6| Step: 6
Training loss: 2.5364496020741876
Validation loss: 2.476197353203275

Epoch: 6| Step: 7
Training loss: 2.085256629720187
Validation loss: 2.4628494984123317

Epoch: 6| Step: 8
Training loss: 2.857638639622849
Validation loss: 2.46337887138652

Epoch: 6| Step: 9
Training loss: 2.3046229466595034
Validation loss: 2.4523486206059424

Epoch: 6| Step: 10
Training loss: 2.9209687974746172
Validation loss: 2.4563952207278468

Epoch: 6| Step: 11
Training loss: 2.0217891150132195
Validation loss: 2.4780454508771883

Epoch: 6| Step: 12
Training loss: 2.778252003773626
Validation loss: 2.475209922750418

Epoch: 6| Step: 13
Training loss: 2.1995294327757864
Validation loss: 2.4740009304625867

Epoch: 190| Step: 0
Training loss: 3.018986543032161
Validation loss: 2.472955010699615

Epoch: 6| Step: 1
Training loss: 2.5266429277309705
Validation loss: 2.4736161805071584

Epoch: 6| Step: 2
Training loss: 1.942055913958997
Validation loss: 2.4860842590599024

Epoch: 6| Step: 3
Training loss: 2.5152671038113676
Validation loss: 2.4725766787575343

Epoch: 6| Step: 4
Training loss: 1.7982822381021104
Validation loss: 2.4898972075089603

Epoch: 6| Step: 5
Training loss: 2.7005046867297446
Validation loss: 2.484836014740499

Epoch: 6| Step: 6
Training loss: 2.934093691795872
Validation loss: 2.481424947476713

Epoch: 6| Step: 7
Training loss: 2.624915802831463
Validation loss: 2.503998778295758

Epoch: 6| Step: 8
Training loss: 2.284949868818819
Validation loss: 2.4712603324179385

Epoch: 6| Step: 9
Training loss: 2.7629855216907147
Validation loss: 2.4563157186656173

Epoch: 6| Step: 10
Training loss: 2.2994693973343816
Validation loss: 2.4917844969255323

Epoch: 6| Step: 11
Training loss: 2.889974489990424
Validation loss: 2.4869728408283756

Epoch: 6| Step: 12
Training loss: 2.6940681570560314
Validation loss: 2.473768910451587

Epoch: 6| Step: 13
Training loss: 2.5724360728870557
Validation loss: 2.482343404782203

Epoch: 191| Step: 0
Training loss: 2.25471532306172
Validation loss: 2.4699674485839833

Epoch: 6| Step: 1
Training loss: 2.662892193630809
Validation loss: 2.504648072589378

Epoch: 6| Step: 2
Training loss: 2.3169895614895974
Validation loss: 2.483932394808468

Epoch: 6| Step: 3
Training loss: 2.5948555669850264
Validation loss: 2.4827505775610823

Epoch: 6| Step: 4
Training loss: 2.4051223688856176
Validation loss: 2.4748147335589885

Epoch: 6| Step: 5
Training loss: 2.7027863747944747
Validation loss: 2.4862050586972426

Epoch: 6| Step: 6
Training loss: 2.924686486812318
Validation loss: 2.469303279388351

Epoch: 6| Step: 7
Training loss: 2.4364433932869045
Validation loss: 2.476696618023978

Epoch: 6| Step: 8
Training loss: 1.8610623180895218
Validation loss: 2.481971699452232

Epoch: 6| Step: 9
Training loss: 2.483884559061991
Validation loss: 2.448318083731889

Epoch: 6| Step: 10
Training loss: 2.986539844420223
Validation loss: 2.5087011745456325

Epoch: 6| Step: 11
Training loss: 3.0069651809772218
Validation loss: 2.4461676038074223

Epoch: 6| Step: 12
Training loss: 2.301562450276858
Validation loss: 2.502602375350809

Epoch: 6| Step: 13
Training loss: 2.580108249670368
Validation loss: 2.482031034995673

Epoch: 192| Step: 0
Training loss: 2.9463510478336272
Validation loss: 2.463733378335057

Epoch: 6| Step: 1
Training loss: 2.3854805439443663
Validation loss: 2.4712660463106073

Epoch: 6| Step: 2
Training loss: 2.1461242429207696
Validation loss: 2.4775181024573674

Epoch: 6| Step: 3
Training loss: 1.686397616271446
Validation loss: 2.4687523489427274

Epoch: 6| Step: 4
Training loss: 3.340832872765778
Validation loss: 2.4940643295023026

Epoch: 6| Step: 5
Training loss: 2.4775708188618113
Validation loss: 2.4648064456018357

Epoch: 6| Step: 6
Training loss: 2.347396861645259
Validation loss: 2.4695395301032024

Epoch: 6| Step: 7
Training loss: 1.6521254230668145
Validation loss: 2.4998614713784093

Epoch: 6| Step: 8
Training loss: 2.7599174959871102
Validation loss: 2.4568419071569427

Epoch: 6| Step: 9
Training loss: 2.771057741260837
Validation loss: 2.484507937881951

Epoch: 6| Step: 10
Training loss: 2.7088650303785196
Validation loss: 2.437197815595895

Epoch: 6| Step: 11
Training loss: 3.059806573526343
Validation loss: 2.506770907757636

Epoch: 6| Step: 12
Training loss: 2.6898076994843105
Validation loss: 2.4872651931982905

Epoch: 6| Step: 13
Training loss: 2.191755678329866
Validation loss: 2.476615439632284

Epoch: 193| Step: 0
Training loss: 2.508395973851278
Validation loss: 2.4691052724428397

Epoch: 6| Step: 1
Training loss: 2.9890081581165195
Validation loss: 2.4934376531309574

Epoch: 6| Step: 2
Training loss: 2.2499785952079727
Validation loss: 2.4971758960241233

Epoch: 6| Step: 3
Training loss: 2.7719970401016
Validation loss: 2.4905097260032796

Epoch: 6| Step: 4
Training loss: 2.4816978953565516
Validation loss: 2.4858948974151653

Epoch: 6| Step: 5
Training loss: 2.287410934465334
Validation loss: 2.4738620610225257

Epoch: 6| Step: 6
Training loss: 2.384988360426549
Validation loss: 2.4912204420101904

Epoch: 6| Step: 7
Training loss: 2.838623456330736
Validation loss: 2.4772292153534465

Epoch: 6| Step: 8
Training loss: 2.5689375426056658
Validation loss: 2.494581586492674

Epoch: 6| Step: 9
Training loss: 2.8349710294127988
Validation loss: 2.4757666957242344

Epoch: 6| Step: 10
Training loss: 1.9252829380920546
Validation loss: 2.4813697326483215

Epoch: 6| Step: 11
Training loss: 2.76179161137532
Validation loss: 2.4930780505175343

Epoch: 6| Step: 12
Training loss: 2.518202793702521
Validation loss: 2.4839752880792823

Epoch: 6| Step: 13
Training loss: 2.0103717331155595
Validation loss: 2.474844236621474

Epoch: 194| Step: 0
Training loss: 1.6012977939593138
Validation loss: 2.462197711131055

Epoch: 6| Step: 1
Training loss: 2.672153659142765
Validation loss: 2.478304837180393

Epoch: 6| Step: 2
Training loss: 2.2699123463113113
Validation loss: 2.484463418811319

Epoch: 6| Step: 3
Training loss: 2.1159417685805253
Validation loss: 2.4802401653653603

Epoch: 6| Step: 4
Training loss: 3.2030490773204887
Validation loss: 2.4828357722779404

Epoch: 6| Step: 5
Training loss: 2.920213686035139
Validation loss: 2.4953320854929104

Epoch: 6| Step: 6
Training loss: 2.8696949983482427
Validation loss: 2.488884260860121

Epoch: 6| Step: 7
Training loss: 2.1430420977382183
Validation loss: 2.4833887667875314

Epoch: 6| Step: 8
Training loss: 3.1459378526179087
Validation loss: 2.5112939451534015

Epoch: 6| Step: 9
Training loss: 2.9692319779908636
Validation loss: 2.4812184219043316

Epoch: 6| Step: 10
Training loss: 2.5491837410564395
Validation loss: 2.4811163150903788

Epoch: 6| Step: 11
Training loss: 2.185479020743476
Validation loss: 2.4960719156139155

Epoch: 6| Step: 12
Training loss: 2.149896743424031
Validation loss: 2.4801830325825263

Epoch: 6| Step: 13
Training loss: 2.1220355954865515
Validation loss: 2.5063763396136087

Epoch: 195| Step: 0
Training loss: 1.7896760113498746
Validation loss: 2.491032894116169

Epoch: 6| Step: 1
Training loss: 2.2237864538831884
Validation loss: 2.4864832112948423

Epoch: 6| Step: 2
Training loss: 2.491421477162721
Validation loss: 2.4795282003251113

Epoch: 6| Step: 3
Training loss: 2.871867588104214
Validation loss: 2.488880791696121

Epoch: 6| Step: 4
Training loss: 2.6753162731834266
Validation loss: 2.4843446060646346

Epoch: 6| Step: 5
Training loss: 2.738556547379623
Validation loss: 2.470859048834038

Epoch: 6| Step: 6
Training loss: 2.9354903468858753
Validation loss: 2.4970808193098946

Epoch: 6| Step: 7
Training loss: 2.4212692979980015
Validation loss: 2.470694846887164

Epoch: 6| Step: 8
Training loss: 2.9770821345553555
Validation loss: 2.4790563526947222

Epoch: 6| Step: 9
Training loss: 2.469077559361112
Validation loss: 2.486012043341306

Epoch: 6| Step: 10
Training loss: 2.542506303357438
Validation loss: 2.4388663451419474

Epoch: 6| Step: 11
Training loss: 2.3265554782820397
Validation loss: 2.4855711602227504

Epoch: 6| Step: 12
Training loss: 2.259979158828648
Validation loss: 2.4676484671965238

Epoch: 6| Step: 13
Training loss: 2.6283078015558297
Validation loss: 2.4939972501136776

Epoch: 196| Step: 0
Training loss: 2.1275955505072117
Validation loss: 2.482356627047736

Epoch: 6| Step: 1
Training loss: 2.6060574394096614
Validation loss: 2.4838535367556234

Epoch: 6| Step: 2
Training loss: 2.1555358146252925
Validation loss: 2.4482992609402268

Epoch: 6| Step: 3
Training loss: 2.7996878518088257
Validation loss: 2.4792897290482747

Epoch: 6| Step: 4
Training loss: 2.5537779702602807
Validation loss: 2.460935094636548

Epoch: 6| Step: 5
Training loss: 2.605309339962718
Validation loss: 2.474846374676026

Epoch: 6| Step: 6
Training loss: 2.478374408038644
Validation loss: 2.4660155153858225

Epoch: 6| Step: 7
Training loss: 3.0282242608114562
Validation loss: 2.4621999007740047

Epoch: 6| Step: 8
Training loss: 2.717648776420301
Validation loss: 2.4563993483983895

Epoch: 6| Step: 9
Training loss: 2.2702445453888704
Validation loss: 2.476441380108905

Epoch: 6| Step: 10
Training loss: 2.456500118809221
Validation loss: 2.4867610853604254

Epoch: 6| Step: 11
Training loss: 2.366254465267202
Validation loss: 2.4518663260076354

Epoch: 6| Step: 12
Training loss: 1.9971251687721132
Validation loss: 2.4839370557204443

Epoch: 6| Step: 13
Training loss: 3.552218810301151
Validation loss: 2.4707462354857515

Epoch: 197| Step: 0
Training loss: 1.9800829991370765
Validation loss: 2.466451049827305

Epoch: 6| Step: 1
Training loss: 2.70164758075026
Validation loss: 2.4659777250255366

Epoch: 6| Step: 2
Training loss: 2.0719319469514077
Validation loss: 2.4933683277815653

Epoch: 6| Step: 3
Training loss: 3.085336206500211
Validation loss: 2.4649678931907273

Epoch: 6| Step: 4
Training loss: 2.5370927418082077
Validation loss: 2.4851938060415515

Epoch: 6| Step: 5
Training loss: 2.552404194079063
Validation loss: 2.478946883552997

Epoch: 6| Step: 6
Training loss: 2.6444086359130288
Validation loss: 2.495172824002124

Epoch: 6| Step: 7
Training loss: 2.5450155573221394
Validation loss: 2.4832589806955507

Epoch: 6| Step: 8
Training loss: 3.0751199528317916
Validation loss: 2.493332286598368

Epoch: 6| Step: 9
Training loss: 2.191471962445018
Validation loss: 2.478284126708116

Epoch: 6| Step: 10
Training loss: 2.8868974725840046
Validation loss: 2.491231052730082

Epoch: 6| Step: 11
Training loss: 2.563514229633978
Validation loss: 2.46170195311635

Epoch: 6| Step: 12
Training loss: 1.8466383729183342
Validation loss: 2.493357947217472

Epoch: 6| Step: 13
Training loss: 2.215586166149118
Validation loss: 2.500907224711581

Epoch: 198| Step: 0
Training loss: 3.0350110818324376
Validation loss: 2.48989573670056

Epoch: 6| Step: 1
Training loss: 2.9407394078829365
Validation loss: 2.465563497913906

Epoch: 6| Step: 2
Training loss: 1.650190316408396
Validation loss: 2.4668130073633336

Epoch: 6| Step: 3
Training loss: 1.706635662830392
Validation loss: 2.4796624567301353

Epoch: 6| Step: 4
Training loss: 2.529298760255089
Validation loss: 2.482290606932493

Epoch: 6| Step: 5
Training loss: 2.61656568741385
Validation loss: 2.464669634054288

Epoch: 6| Step: 6
Training loss: 2.2646518064065067
Validation loss: 2.478423484855

Epoch: 6| Step: 7
Training loss: 2.649341890200635
Validation loss: 2.4735837618946053

Epoch: 6| Step: 8
Training loss: 2.9822946057897526
Validation loss: 2.4646039660578527

Epoch: 6| Step: 9
Training loss: 2.4285045822945417
Validation loss: 2.4949721466047863

Epoch: 6| Step: 10
Training loss: 2.381146358126858
Validation loss: 2.509769257331008

Epoch: 6| Step: 11
Training loss: 2.381485566429659
Validation loss: 2.475484136879946

Epoch: 6| Step: 12
Training loss: 2.7632824303233803
Validation loss: 2.487345061369938

Epoch: 6| Step: 13
Training loss: 2.918267782431144
Validation loss: 2.4585755305199055

Epoch: 199| Step: 0
Training loss: 2.1035764892613473
Validation loss: 2.505570230743515

Epoch: 6| Step: 1
Training loss: 2.112869420000706
Validation loss: 2.498680359169424

Epoch: 6| Step: 2
Training loss: 2.3242218274007986
Validation loss: 2.4838500068948353

Epoch: 6| Step: 3
Training loss: 2.7449255855736627
Validation loss: 2.4974932336531337

Epoch: 6| Step: 4
Training loss: 2.6493816661998326
Validation loss: 2.4741591871469595

Epoch: 6| Step: 5
Training loss: 2.0698387899603583
Validation loss: 2.4789297380686137

Epoch: 6| Step: 6
Training loss: 3.374483846119606
Validation loss: 2.4648939116242876

Epoch: 6| Step: 7
Training loss: 1.8412116730035923
Validation loss: 2.4830430171720734

Epoch: 6| Step: 8
Training loss: 2.7780482690296426
Validation loss: 2.4771479943903114

Epoch: 6| Step: 9
Training loss: 2.4892260136748856
Validation loss: 2.4843456833870947

Epoch: 6| Step: 10
Training loss: 2.099225982437764
Validation loss: 2.4814973266474363

Epoch: 6| Step: 11
Training loss: 2.0203627861119653
Validation loss: 2.4971831346827815

Epoch: 6| Step: 12
Training loss: 2.769606832702336
Validation loss: 2.485316250902778

Epoch: 6| Step: 13
Training loss: 4.0755181293255145
Validation loss: 2.4826867033548607

Epoch: 200| Step: 0
Training loss: 2.480859248143744
Validation loss: 2.4884733166932596

Epoch: 6| Step: 1
Training loss: 2.8547201988882254
Validation loss: 2.475862512237387

Epoch: 6| Step: 2
Training loss: 2.9600448672012942
Validation loss: 2.468427233808656

Epoch: 6| Step: 3
Training loss: 2.755726314281967
Validation loss: 2.4663374631529003

Epoch: 6| Step: 4
Training loss: 2.4788749801053274
Validation loss: 2.452666566462123

Epoch: 6| Step: 5
Training loss: 1.8603165110091946
Validation loss: 2.452545784233794

Epoch: 6| Step: 6
Training loss: 2.4124618211008113
Validation loss: 2.499898179349575

Epoch: 6| Step: 7
Training loss: 2.2300494813775074
Validation loss: 2.502470580020247

Epoch: 6| Step: 8
Training loss: 2.5599015249743333
Validation loss: 2.486761825042212

Epoch: 6| Step: 9
Training loss: 2.61160420660988
Validation loss: 2.473103337278431

Epoch: 6| Step: 10
Training loss: 2.2001550012951636
Validation loss: 2.476616988199385

Epoch: 6| Step: 11
Training loss: 2.0576511374824364
Validation loss: 2.5025010073547507

Epoch: 6| Step: 12
Training loss: 3.437918897594233
Validation loss: 2.4811315463434975

Epoch: 6| Step: 13
Training loss: 2.0378882289855573
Validation loss: 2.4767770547142467

Epoch: 201| Step: 0
Training loss: 2.4681644952569455
Validation loss: 2.4751331545437316

Epoch: 6| Step: 1
Training loss: 2.8701509134310585
Validation loss: 2.4739728660135065

Epoch: 6| Step: 2
Training loss: 2.207591622029156
Validation loss: 2.486086223487883

Epoch: 6| Step: 3
Training loss: 1.9838110054697684
Validation loss: 2.5229201110727995

Epoch: 6| Step: 4
Training loss: 2.92139598163384
Validation loss: 2.492588948641711

Epoch: 6| Step: 5
Training loss: 2.720460375645369
Validation loss: 2.4710169008500817

Epoch: 6| Step: 6
Training loss: 2.4947739337033417
Validation loss: 2.49081378717969

Epoch: 6| Step: 7
Training loss: 2.337938963120269
Validation loss: 2.4801629063060817

Epoch: 6| Step: 8
Training loss: 3.100689743587115
Validation loss: 2.481182500771911

Epoch: 6| Step: 9
Training loss: 2.4902811921150594
Validation loss: 2.4924263315262576

Epoch: 6| Step: 10
Training loss: 2.5234860631090408
Validation loss: 2.491019319621751

Epoch: 6| Step: 11
Training loss: 1.91888275432778
Validation loss: 2.4782447203697764

Epoch: 6| Step: 12
Training loss: 2.409884395754975
Validation loss: 2.4839549933381724

Epoch: 6| Step: 13
Training loss: 2.7504723750067095
Validation loss: 2.46729891691321

Epoch: 202| Step: 0
Training loss: 2.654160878540946
Validation loss: 2.458385154827264

Epoch: 6| Step: 1
Training loss: 2.578321229807238
Validation loss: 2.466285899533295

Epoch: 6| Step: 2
Training loss: 2.9352903780676725
Validation loss: 2.4932772007667725

Epoch: 6| Step: 3
Training loss: 2.9686068851709013
Validation loss: 2.479336790054299

Epoch: 6| Step: 4
Training loss: 2.2117018170451352
Validation loss: 2.4883836260979457

Epoch: 6| Step: 5
Training loss: 2.2594144741213684
Validation loss: 2.48216072830434

Epoch: 6| Step: 6
Training loss: 2.7538495429943954
Validation loss: 2.495115410502078

Epoch: 6| Step: 7
Training loss: 2.5149181628705692
Validation loss: 2.4837338985138353

Epoch: 6| Step: 8
Training loss: 2.286214260783472
Validation loss: 2.4813133904265317

Epoch: 6| Step: 9
Training loss: 2.2145007639935526
Validation loss: 2.4648681304512694

Epoch: 6| Step: 10
Training loss: 2.3613491262506954
Validation loss: 2.494946217961041

Epoch: 6| Step: 11
Training loss: 2.604254535464197
Validation loss: 2.4865629860189458

Epoch: 6| Step: 12
Training loss: 2.621719854081693
Validation loss: 2.4456681435160577

Epoch: 6| Step: 13
Training loss: 2.0101122320925042
Validation loss: 2.4627414366177076

Epoch: 203| Step: 0
Training loss: 2.3835982231065658
Validation loss: 2.479689266818496

Epoch: 6| Step: 1
Training loss: 2.27190974443778
Validation loss: 2.4758857715212987

Epoch: 6| Step: 2
Training loss: 2.243839838041146
Validation loss: 2.478058213981699

Epoch: 6| Step: 3
Training loss: 2.127853609277064
Validation loss: 2.48228154743856

Epoch: 6| Step: 4
Training loss: 2.750528978276607
Validation loss: 2.449508582591651

Epoch: 6| Step: 5
Training loss: 3.1177899918513714
Validation loss: 2.4856312297924594

Epoch: 6| Step: 6
Training loss: 2.1832456362440555
Validation loss: 2.4846814457315034

Epoch: 6| Step: 7
Training loss: 2.714231485169279
Validation loss: 2.4520903841129664

Epoch: 6| Step: 8
Training loss: 2.494084607767083
Validation loss: 2.4814778784201255

Epoch: 6| Step: 9
Training loss: 2.6417241263733957
Validation loss: 2.4572793085514615

Epoch: 6| Step: 10
Training loss: 2.2302203198722093
Validation loss: 2.4863659246573926

Epoch: 6| Step: 11
Training loss: 3.0720849587295507
Validation loss: 2.4599933876557665

Epoch: 6| Step: 12
Training loss: 2.0124375327704516
Validation loss: 2.4762959545012295

Epoch: 6| Step: 13
Training loss: 2.978416366173972
Validation loss: 2.5091520288209725

Epoch: 204| Step: 0
Training loss: 2.2291623647297736
Validation loss: 2.4930217389590945

Epoch: 6| Step: 1
Training loss: 1.971928286550341
Validation loss: 2.493659217907709

Epoch: 6| Step: 2
Training loss: 2.4745640919914633
Validation loss: 2.489617918514601

Epoch: 6| Step: 3
Training loss: 2.9558193288262875
Validation loss: 2.4841903769613487

Epoch: 6| Step: 4
Training loss: 2.6283067130137874
Validation loss: 2.491412156579863

Epoch: 6| Step: 5
Training loss: 2.132987549693152
Validation loss: 2.46201998017975

Epoch: 6| Step: 6
Training loss: 2.2782649537517377
Validation loss: 2.4985192097271014

Epoch: 6| Step: 7
Training loss: 2.3409964089804007
Validation loss: 2.4631609566691246

Epoch: 6| Step: 8
Training loss: 2.7091797508628606
Validation loss: 2.479618023839508

Epoch: 6| Step: 9
Training loss: 2.3870633589826147
Validation loss: 2.4916722698630873

Epoch: 6| Step: 10
Training loss: 3.0060963676675607
Validation loss: 2.4775198553429245

Epoch: 6| Step: 11
Training loss: 2.7036936608316213
Validation loss: 2.486099887820352

Epoch: 6| Step: 12
Training loss: 2.6687487778672003
Validation loss: 2.4802887737341313

Epoch: 6| Step: 13
Training loss: 2.2787520436556594
Validation loss: 2.483115824095796

Epoch: 205| Step: 0
Training loss: 2.080824854961697
Validation loss: 2.484478000624459

Epoch: 6| Step: 1
Training loss: 2.6017992982978235
Validation loss: 2.5015974570816386

Epoch: 6| Step: 2
Training loss: 2.9945568932545723
Validation loss: 2.4807315980737097

Epoch: 6| Step: 3
Training loss: 1.8740852031697022
Validation loss: 2.4890398717893394

Epoch: 6| Step: 4
Training loss: 2.935555321636218
Validation loss: 2.473736302894288

Epoch: 6| Step: 5
Training loss: 2.989214423586609
Validation loss: 2.4862155732717306

Epoch: 6| Step: 6
Training loss: 1.9102406239353742
Validation loss: 2.490990570059732

Epoch: 6| Step: 7
Training loss: 2.902357386355499
Validation loss: 2.481728638839276

Epoch: 6| Step: 8
Training loss: 2.9281177435167223
Validation loss: 2.4959271900627367

Epoch: 6| Step: 9
Training loss: 2.220283945156371
Validation loss: 2.4793207298742237

Epoch: 6| Step: 10
Training loss: 2.2200482291060446
Validation loss: 2.4660445966547075

Epoch: 6| Step: 11
Training loss: 2.4570758857978596
Validation loss: 2.4713762202962886

Epoch: 6| Step: 12
Training loss: 2.5369832607344067
Validation loss: 2.491959909555067

Epoch: 6| Step: 13
Training loss: 1.7157014339909946
Validation loss: 2.4876080093848745

Epoch: 206| Step: 0
Training loss: 2.772227708466664
Validation loss: 2.482606924891371

Epoch: 6| Step: 1
Training loss: 2.625860254925928
Validation loss: 2.4608351465293428

Epoch: 6| Step: 2
Training loss: 2.182007788597913
Validation loss: 2.482039349667109

Epoch: 6| Step: 3
Training loss: 1.9089635077815783
Validation loss: 2.484317678010942

Epoch: 6| Step: 4
Training loss: 2.2552453464586484
Validation loss: 2.4745281519633116

Epoch: 6| Step: 5
Training loss: 2.395312332780388
Validation loss: 2.4819244745926676

Epoch: 6| Step: 6
Training loss: 2.4017025471781617
Validation loss: 2.4631226864138993

Epoch: 6| Step: 7
Training loss: 3.0620327028587506
Validation loss: 2.4700345868794567

Epoch: 6| Step: 8
Training loss: 2.1717598424885853
Validation loss: 2.493948628815451

Epoch: 6| Step: 9
Training loss: 2.6201563152245204
Validation loss: 2.4989003634333873

Epoch: 6| Step: 10
Training loss: 3.077156805367867
Validation loss: 2.506263035218219

Epoch: 6| Step: 11
Training loss: 2.5297599456950493
Validation loss: 2.4659294791247657

Epoch: 6| Step: 12
Training loss: 2.925621527474373
Validation loss: 2.465188265703546

Epoch: 6| Step: 13
Training loss: 1.6379261889100445
Validation loss: 2.4878757438924146

Epoch: 207| Step: 0
Training loss: 2.4842348838976607
Validation loss: 2.4585046887488105

Epoch: 6| Step: 1
Training loss: 2.7867856602914856
Validation loss: 2.480715284432939

Epoch: 6| Step: 2
Training loss: 1.6387129768245592
Validation loss: 2.5007754212857627

Epoch: 6| Step: 3
Training loss: 2.6868056353967815
Validation loss: 2.4746415046101586

Epoch: 6| Step: 4
Training loss: 2.161497503331702
Validation loss: 2.477784478202582

Epoch: 6| Step: 5
Training loss: 2.719444799980614
Validation loss: 2.489750115160232

Epoch: 6| Step: 6
Training loss: 3.1002489666792097
Validation loss: 2.4709924493048834

Epoch: 6| Step: 7
Training loss: 2.596019441434832
Validation loss: 2.4783303016899874

Epoch: 6| Step: 8
Training loss: 2.817828407949197
Validation loss: 2.476312926697333

Epoch: 6| Step: 9
Training loss: 2.3043498163629312
Validation loss: 2.4601596689684233

Epoch: 6| Step: 10
Training loss: 2.107058574200899
Validation loss: 2.4773446910368686

Epoch: 6| Step: 11
Training loss: 2.4989478758359525
Validation loss: 2.4843964883106295

Epoch: 6| Step: 12
Training loss: 2.7274298832147426
Validation loss: 2.5014136983132205

Epoch: 6| Step: 13
Training loss: 2.175058241316516
Validation loss: 2.497863021294109

Epoch: 208| Step: 0
Training loss: 2.609610541214694
Validation loss: 2.4879260779525745

Epoch: 6| Step: 1
Training loss: 2.7228016096195256
Validation loss: 2.4859811940195353

Epoch: 6| Step: 2
Training loss: 2.7703236467252306
Validation loss: 2.4912295461773195

Epoch: 6| Step: 3
Training loss: 2.3889858635236254
Validation loss: 2.5034125243494127

Epoch: 6| Step: 4
Training loss: 2.270900503675847
Validation loss: 2.4812939438571013

Epoch: 6| Step: 5
Training loss: 2.2528638627547926
Validation loss: 2.474273946132108

Epoch: 6| Step: 6
Training loss: 2.207389437886565
Validation loss: 2.4743728447603273

Epoch: 6| Step: 7
Training loss: 2.6782523446537048
Validation loss: 2.4755496384610516

Epoch: 6| Step: 8
Training loss: 2.8680219137719254
Validation loss: 2.4820193386330778

Epoch: 6| Step: 9
Training loss: 2.4100828484188415
Validation loss: 2.4856885720266084

Epoch: 6| Step: 10
Training loss: 2.3716593889387054
Validation loss: 2.4875389296837516

Epoch: 6| Step: 11
Training loss: 2.356283828128252
Validation loss: 2.461842476428563

Epoch: 6| Step: 12
Training loss: 2.738096483992457
Validation loss: 2.4859763915351074

Epoch: 6| Step: 13
Training loss: 2.0800576079167126
Validation loss: 2.4778215432403305

Epoch: 209| Step: 0
Training loss: 2.6434960642396255
Validation loss: 2.4728533039306395

Epoch: 6| Step: 1
Training loss: 2.5182276939116903
Validation loss: 2.498933868321958

Epoch: 6| Step: 2
Training loss: 2.617954699672971
Validation loss: 2.484829629453025

Epoch: 6| Step: 3
Training loss: 2.5160696454135145
Validation loss: 2.4759229654195933

Epoch: 6| Step: 4
Training loss: 2.809602813479681
Validation loss: 2.479397763402642

Epoch: 6| Step: 5
Training loss: 2.5545504005344757
Validation loss: 2.4808686827759234

Epoch: 6| Step: 6
Training loss: 1.906652564394535
Validation loss: 2.4551008904475076

Epoch: 6| Step: 7
Training loss: 2.4716752503293833
Validation loss: 2.441505586961763

Epoch: 6| Step: 8
Training loss: 2.6925004083177972
Validation loss: 2.4758657946229747

Epoch: 6| Step: 9
Training loss: 1.9458336189591106
Validation loss: 2.47297590471447

Epoch: 6| Step: 10
Training loss: 2.935464031702807
Validation loss: 2.4745066162900398

Epoch: 6| Step: 11
Training loss: 2.4491864313308285
Validation loss: 2.4836686716108844

Epoch: 6| Step: 12
Training loss: 2.384284193477131
Validation loss: 2.486022070964193

Epoch: 6| Step: 13
Training loss: 2.087729152505466
Validation loss: 2.4912071607952164

Epoch: 210| Step: 0
Training loss: 2.268828764249699
Validation loss: 2.4732902276702244

Epoch: 6| Step: 1
Training loss: 2.4600124982190725
Validation loss: 2.4713077123053515

Epoch: 6| Step: 2
Training loss: 2.7048055904002326
Validation loss: 2.463543224839364

Epoch: 6| Step: 3
Training loss: 2.5157959684478386
Validation loss: 2.488402469434683

Epoch: 6| Step: 4
Training loss: 3.3696172670086804
Validation loss: 2.4721119840620416

Epoch: 6| Step: 5
Training loss: 1.7088307687664566
Validation loss: 2.4715303678724254

Epoch: 6| Step: 6
Training loss: 2.688027618425263
Validation loss: 2.464551000379797

Epoch: 6| Step: 7
Training loss: 2.1567828860602867
Validation loss: 2.470182931069558

Epoch: 6| Step: 8
Training loss: 2.1988243169407644
Validation loss: 2.5054462514233005

Epoch: 6| Step: 9
Training loss: 2.6291804857893397
Validation loss: 2.4857510232053577

Epoch: 6| Step: 10
Training loss: 2.4587471069567153
Validation loss: 2.4670784024883217

Epoch: 6| Step: 11
Training loss: 2.6178047021770428
Validation loss: 2.4981055885837455

Epoch: 6| Step: 12
Training loss: 2.405000238240125
Validation loss: 2.471670277950602

Epoch: 6| Step: 13
Training loss: 2.133296478469711
Validation loss: 2.450743736505547

Epoch: 211| Step: 0
Training loss: 2.7267055528599107
Validation loss: 2.4956649870862293

Epoch: 6| Step: 1
Training loss: 2.6484945735576937
Validation loss: 2.4744359192841934

Epoch: 6| Step: 2
Training loss: 1.9967849639509865
Validation loss: 2.497314507917586

Epoch: 6| Step: 3
Training loss: 2.1346157401779204
Validation loss: 2.4983214311397557

Epoch: 6| Step: 4
Training loss: 2.4685341463004753
Validation loss: 2.501044095342242

Epoch: 6| Step: 5
Training loss: 2.5067105828489638
Validation loss: 2.507713742465249

Epoch: 6| Step: 6
Training loss: 2.560887084986048
Validation loss: 2.4752454064877027

Epoch: 6| Step: 7
Training loss: 2.896884882806177
Validation loss: 2.497386618538631

Epoch: 6| Step: 8
Training loss: 2.7184542791083572
Validation loss: 2.4673656031160753

Epoch: 6| Step: 9
Training loss: 2.7343304439729224
Validation loss: 2.490186915628031

Epoch: 6| Step: 10
Training loss: 2.3115269443757724
Validation loss: 2.475437612617299

Epoch: 6| Step: 11
Training loss: 1.8740018094928355
Validation loss: 2.4728683673332768

Epoch: 6| Step: 12
Training loss: 2.12122975399896
Validation loss: 2.4903782372578305

Epoch: 6| Step: 13
Training loss: 3.15415099193419
Validation loss: 2.486464844445332

Epoch: 212| Step: 0
Training loss: 2.5782287576777403
Validation loss: 2.502251128375195

Epoch: 6| Step: 1
Training loss: 3.1900905479088557
Validation loss: 2.4799864049615614

Epoch: 6| Step: 2
Training loss: 2.1668170241001374
Validation loss: 2.4823361527997405

Epoch: 6| Step: 3
Training loss: 2.1288636929519336
Validation loss: 2.4882908141239444

Epoch: 6| Step: 4
Training loss: 2.1122830160989547
Validation loss: 2.4784439541877625

Epoch: 6| Step: 5
Training loss: 2.3643269897071795
Validation loss: 2.4961100268102454

Epoch: 6| Step: 6
Training loss: 1.8788364579845822
Validation loss: 2.4800210006200483

Epoch: 6| Step: 7
Training loss: 2.667255982210911
Validation loss: 2.4843642578388074

Epoch: 6| Step: 8
Training loss: 3.1088538571791777
Validation loss: 2.467645691253466

Epoch: 6| Step: 9
Training loss: 2.3706251306631834
Validation loss: 2.491758764544947

Epoch: 6| Step: 10
Training loss: 2.257494947020155
Validation loss: 2.4837107994287844

Epoch: 6| Step: 11
Training loss: 2.3033931912466543
Validation loss: 2.4854083057097864

Epoch: 6| Step: 12
Training loss: 3.3857916208624452
Validation loss: 2.4791258848839117

Epoch: 6| Step: 13
Training loss: 1.3905021527495554
Validation loss: 2.4881770879942664

Epoch: 213| Step: 0
Training loss: 2.56950221870239
Validation loss: 2.4710889572170682

Epoch: 6| Step: 1
Training loss: 2.513274617137463
Validation loss: 2.503405672365251

Epoch: 6| Step: 2
Training loss: 2.4792740956172494
Validation loss: 2.4819329053082444

Epoch: 6| Step: 3
Training loss: 2.3116299822627844
Validation loss: 2.4833591339952443

Epoch: 6| Step: 4
Training loss: 2.1740114969267137
Validation loss: 2.4713801014754577

Epoch: 6| Step: 5
Training loss: 2.548887990197346
Validation loss: 2.4931137611822467

Epoch: 6| Step: 6
Training loss: 2.3766515911992037
Validation loss: 2.4768484777385558

Epoch: 6| Step: 7
Training loss: 2.358736065377142
Validation loss: 2.484460615737761

Epoch: 6| Step: 8
Training loss: 2.154962348697582
Validation loss: 2.4868822582820678

Epoch: 6| Step: 9
Training loss: 2.7895611656472434
Validation loss: 2.4817018218579867

Epoch: 6| Step: 10
Training loss: 2.4709624022491434
Validation loss: 2.4647249416428436

Epoch: 6| Step: 11
Training loss: 2.500189201824909
Validation loss: 2.4921402084662847

Epoch: 6| Step: 12
Training loss: 2.7212567228305184
Validation loss: 2.4799539393703607

Epoch: 6| Step: 13
Training loss: 3.0554866282077313
Validation loss: 2.47972421244233

Epoch: 214| Step: 0
Training loss: 2.8889113836961355
Validation loss: 2.495410830453626

Epoch: 6| Step: 1
Training loss: 2.6451175552522264
Validation loss: 2.468090430850528

Epoch: 6| Step: 2
Training loss: 2.536023383998462
Validation loss: 2.4896239949590284

Epoch: 6| Step: 3
Training loss: 2.0915107709482816
Validation loss: 2.4709942363882065

Epoch: 6| Step: 4
Training loss: 2.7292107343149237
Validation loss: 2.4639791421811834

Epoch: 6| Step: 5
Training loss: 2.5306217685564834
Validation loss: 2.474069534332771

Epoch: 6| Step: 6
Training loss: 1.9146976584863433
Validation loss: 2.4738934179488408

Epoch: 6| Step: 7
Training loss: 2.6591704526384357
Validation loss: 2.45442399510324

Epoch: 6| Step: 8
Training loss: 2.893428618214241
Validation loss: 2.4678419386827057

Epoch: 6| Step: 9
Training loss: 2.6674988362131913
Validation loss: 2.4877897695981535

Epoch: 6| Step: 10
Training loss: 2.2990122083727234
Validation loss: 2.4860885086158016

Epoch: 6| Step: 11
Training loss: 2.016689522143442
Validation loss: 2.475052945128095

Epoch: 6| Step: 12
Training loss: 2.181649367708534
Validation loss: 2.471644617246938

Epoch: 6| Step: 13
Training loss: 2.412948598315006
Validation loss: 2.511465932167895

Epoch: 215| Step: 0
Training loss: 2.453444441874324
Validation loss: 2.487916123951811

Epoch: 6| Step: 1
Training loss: 2.0837689389361875
Validation loss: 2.480714216901585

Epoch: 6| Step: 2
Training loss: 2.420319974726444
Validation loss: 2.476281580738747

Epoch: 6| Step: 3
Training loss: 2.8235446658376895
Validation loss: 2.498100073596691

Epoch: 6| Step: 4
Training loss: 1.884782449123421
Validation loss: 2.499719524032035

Epoch: 6| Step: 5
Training loss: 2.954441644938957
Validation loss: 2.4978753588193094

Epoch: 6| Step: 6
Training loss: 2.797310139994782
Validation loss: 2.4844176049557607

Epoch: 6| Step: 7
Training loss: 2.6362890274827193
Validation loss: 2.491916675339343

Epoch: 6| Step: 8
Training loss: 2.1580162001912973
Validation loss: 2.476741633288907

Epoch: 6| Step: 9
Training loss: 2.4187146640138284
Validation loss: 2.4850365739532068

Epoch: 6| Step: 10
Training loss: 2.546612591477266
Validation loss: 2.4975638353556224

Epoch: 6| Step: 11
Training loss: 2.6830694361064356
Validation loss: 2.4889128745834594

Epoch: 6| Step: 12
Training loss: 2.6373114025790705
Validation loss: 2.4842910613114264

Epoch: 6| Step: 13
Training loss: 1.9820977307734244
Validation loss: 2.475463310638615

Epoch: 216| Step: 0
Training loss: 3.0953622335475632
Validation loss: 2.5004193877107763

Epoch: 6| Step: 1
Training loss: 2.387140264921435
Validation loss: 2.4692116997883584

Epoch: 6| Step: 2
Training loss: 2.0716557589566285
Validation loss: 2.50386087226969

Epoch: 6| Step: 3
Training loss: 2.644378522466208
Validation loss: 2.496012681728813

Epoch: 6| Step: 4
Training loss: 2.206872444853577
Validation loss: 2.503495184979131

Epoch: 6| Step: 5
Training loss: 1.7787140981625797
Validation loss: 2.4954733567933065

Epoch: 6| Step: 6
Training loss: 2.413344390626028
Validation loss: 2.4991994293780824

Epoch: 6| Step: 7
Training loss: 2.161682913882635
Validation loss: 2.512832982619342

Epoch: 6| Step: 8
Training loss: 2.730223550551553
Validation loss: 2.477313884870547

Epoch: 6| Step: 9
Training loss: 2.8109437663595296
Validation loss: 2.486606526731178

Epoch: 6| Step: 10
Training loss: 2.583253049115665
Validation loss: 2.488221602953993

Epoch: 6| Step: 11
Training loss: 2.750586707211158
Validation loss: 2.486473325752417

Epoch: 6| Step: 12
Training loss: 2.669050363259144
Validation loss: 2.474121799908178

Epoch: 6| Step: 13
Training loss: 1.9284087975368398
Validation loss: 2.4947226999054055

Epoch: 217| Step: 0
Training loss: 2.259673938523247
Validation loss: 2.479092877528099

Epoch: 6| Step: 1
Training loss: 1.5228791607553567
Validation loss: 2.483298854095752

Epoch: 6| Step: 2
Training loss: 2.6263665774660927
Validation loss: 2.453587690299628

Epoch: 6| Step: 3
Training loss: 2.1668372698399123
Validation loss: 2.491306620000735

Epoch: 6| Step: 4
Training loss: 2.721017965816137
Validation loss: 2.481026051903718

Epoch: 6| Step: 5
Training loss: 3.131167010580006
Validation loss: 2.498859739217819

Epoch: 6| Step: 6
Training loss: 2.889730119082544
Validation loss: 2.4698716576784414

Epoch: 6| Step: 7
Training loss: 2.2747941311761375
Validation loss: 2.5001449912080287

Epoch: 6| Step: 8
Training loss: 2.9434329240769253
Validation loss: 2.4846741985094836

Epoch: 6| Step: 9
Training loss: 2.5404858165120556
Validation loss: 2.4893769659109606

Epoch: 6| Step: 10
Training loss: 2.22787865003154
Validation loss: 2.487274053136392

Epoch: 6| Step: 11
Training loss: 2.5841054275311026
Validation loss: 2.5088159945968154

Epoch: 6| Step: 12
Training loss: 1.849057462658644
Validation loss: 2.478872827944157

Epoch: 6| Step: 13
Training loss: 2.491480233692977
Validation loss: 2.469888076156164

Epoch: 218| Step: 0
Training loss: 2.459765539703925
Validation loss: 2.488551897520954

Epoch: 6| Step: 1
Training loss: 2.548783505805574
Validation loss: 2.47515025693188

Epoch: 6| Step: 2
Training loss: 2.4118210346069238
Validation loss: 2.4683024949843086

Epoch: 6| Step: 3
Training loss: 2.598930975413895
Validation loss: 2.5009055886765648

Epoch: 6| Step: 4
Training loss: 2.8218198853240013
Validation loss: 2.4820774501307263

Epoch: 6| Step: 5
Training loss: 2.210612889915387
Validation loss: 2.4897519757874766

Epoch: 6| Step: 6
Training loss: 1.8771475890660474
Validation loss: 2.4729308934688903

Epoch: 6| Step: 7
Training loss: 1.5589590003181135
Validation loss: 2.468109822010834

Epoch: 6| Step: 8
Training loss: 3.1524500870288965
Validation loss: 2.478800250101268

Epoch: 6| Step: 9
Training loss: 2.884274491928186
Validation loss: 2.489351934682898

Epoch: 6| Step: 10
Training loss: 2.580105477476133
Validation loss: 2.4484200118288353

Epoch: 6| Step: 11
Training loss: 2.4224272067664945
Validation loss: 2.4834907925586585

Epoch: 6| Step: 12
Training loss: 2.4857567357602477
Validation loss: 2.4834072229710333

Epoch: 6| Step: 13
Training loss: 2.3326633944834154
Validation loss: 2.4971448037395247

Epoch: 219| Step: 0
Training loss: 2.4123830539642652
Validation loss: 2.460455409429148

Epoch: 6| Step: 1
Training loss: 2.19492974796706
Validation loss: 2.4795642322714246

Epoch: 6| Step: 2
Training loss: 2.141807285348241
Validation loss: 2.477528354854246

Epoch: 6| Step: 3
Training loss: 1.50592230876821
Validation loss: 2.49846740629647

Epoch: 6| Step: 4
Training loss: 2.46834271125463
Validation loss: 2.4750929854248613

Epoch: 6| Step: 5
Training loss: 2.466890334822719
Validation loss: 2.473508876177264

Epoch: 6| Step: 6
Training loss: 2.524872079762664
Validation loss: 2.503832552749975

Epoch: 6| Step: 7
Training loss: 2.4306879958142726
Validation loss: 2.4682809984694405

Epoch: 6| Step: 8
Training loss: 2.5684050465283366
Validation loss: 2.5147857295293607

Epoch: 6| Step: 9
Training loss: 2.613655462685262
Validation loss: 2.474412326229141

Epoch: 6| Step: 10
Training loss: 2.500627629651263
Validation loss: 2.4544936286994767

Epoch: 6| Step: 11
Training loss: 2.2991850777589766
Validation loss: 2.4819672564079913

Epoch: 6| Step: 12
Training loss: 3.2835638697932645
Validation loss: 2.483947635627905

Epoch: 6| Step: 13
Training loss: 2.8436505646141494
Validation loss: 2.495985278699927

Epoch: 220| Step: 0
Training loss: 1.9839306431460664
Validation loss: 2.47889522025719

Epoch: 6| Step: 1
Training loss: 1.9594163808149
Validation loss: 2.519006214603162

Epoch: 6| Step: 2
Training loss: 1.9645993514906395
Validation loss: 2.4908097021300253

Epoch: 6| Step: 3
Training loss: 3.0929325449482565
Validation loss: 2.484248847361492

Epoch: 6| Step: 4
Training loss: 2.746202794998899
Validation loss: 2.518643056087751

Epoch: 6| Step: 5
Training loss: 2.0937314388534203
Validation loss: 2.4945820664208784

Epoch: 6| Step: 6
Training loss: 2.4981159740492043
Validation loss: 2.5074596333754435

Epoch: 6| Step: 7
Training loss: 2.548986764699128
Validation loss: 2.47848607254831

Epoch: 6| Step: 8
Training loss: 3.0007064305487177
Validation loss: 2.5057117044367447

Epoch: 6| Step: 9
Training loss: 2.443177872830002
Validation loss: 2.4961746975301464

Epoch: 6| Step: 10
Training loss: 2.5720766268894604
Validation loss: 2.481054105800891

Epoch: 6| Step: 11
Training loss: 3.179429252316113
Validation loss: 2.4760400675169496

Epoch: 6| Step: 12
Training loss: 2.0180950555029993
Validation loss: 2.4959880262060854

Epoch: 6| Step: 13
Training loss: 1.8505479310493647
Validation loss: 2.477194973966571

Epoch: 221| Step: 0
Training loss: 2.876007566948753
Validation loss: 2.473925754783813

Epoch: 6| Step: 1
Training loss: 2.066332868055494
Validation loss: 2.501589793604854

Epoch: 6| Step: 2
Training loss: 2.6454822177148736
Validation loss: 2.490209036337656

Epoch: 6| Step: 3
Training loss: 2.5521255385872914
Validation loss: 2.463615648604009

Epoch: 6| Step: 4
Training loss: 2.7167784459183535
Validation loss: 2.4863376904504277

Epoch: 6| Step: 5
Training loss: 2.6669912041432187
Validation loss: 2.505116395506445

Epoch: 6| Step: 6
Training loss: 2.1924714408241095
Validation loss: 2.4577087556516655

Epoch: 6| Step: 7
Training loss: 2.1538389796619617
Validation loss: 2.462210629267475

Epoch: 6| Step: 8
Training loss: 2.5833844723305632
Validation loss: 2.501139934664275

Epoch: 6| Step: 9
Training loss: 2.7290877313822386
Validation loss: 2.5053577908510207

Epoch: 6| Step: 10
Training loss: 2.671430941260841
Validation loss: 2.488786583710252

Epoch: 6| Step: 11
Training loss: 2.449660557957499
Validation loss: 2.5012500385969227

Epoch: 6| Step: 12
Training loss: 2.0663224836075824
Validation loss: 2.493606138411611

Epoch: 6| Step: 13
Training loss: 1.7261120653117428
Validation loss: 2.4754000810550143

Epoch: 222| Step: 0
Training loss: 2.412895043795027
Validation loss: 2.4873251394021114

Epoch: 6| Step: 1
Training loss: 2.900432054628349
Validation loss: 2.4972759603303616

Epoch: 6| Step: 2
Training loss: 2.274756190052492
Validation loss: 2.4877433559289805

Epoch: 6| Step: 3
Training loss: 2.383693444671816
Validation loss: 2.497500700810871

Epoch: 6| Step: 4
Training loss: 2.524207124768911
Validation loss: 2.4915917357875923

Epoch: 6| Step: 5
Training loss: 2.688290590615357
Validation loss: 2.4661765776845836

Epoch: 6| Step: 6
Training loss: 2.5345268232258595
Validation loss: 2.480462457857039

Epoch: 6| Step: 7
Training loss: 2.8658330976998765
Validation loss: 2.4893563372560625

Epoch: 6| Step: 8
Training loss: 2.0644717184075776
Validation loss: 2.478829272392339

Epoch: 6| Step: 9
Training loss: 2.3427958262790147
Validation loss: 2.4809504897628907

Epoch: 6| Step: 10
Training loss: 2.6540927878676976
Validation loss: 2.513138377922749

Epoch: 6| Step: 11
Training loss: 2.130295606347242
Validation loss: 2.507321739792653

Epoch: 6| Step: 12
Training loss: 2.5578119146291614
Validation loss: 2.4878151694829826

Epoch: 6| Step: 13
Training loss: 1.5454417823580677
Validation loss: 2.4816410373492745

Epoch: 223| Step: 0
Training loss: 2.4217662171574665
Validation loss: 2.513120797538941

Epoch: 6| Step: 1
Training loss: 2.5968462376660035
Validation loss: 2.4835399798827873

Epoch: 6| Step: 2
Training loss: 2.7827728045897158
Validation loss: 2.49784895330045

Epoch: 6| Step: 3
Training loss: 2.482742829062493
Validation loss: 2.4572375903927086

Epoch: 6| Step: 4
Training loss: 2.288499261610509
Validation loss: 2.4801498304958414

Epoch: 6| Step: 5
Training loss: 2.7007470227788057
Validation loss: 2.482460541709347

Epoch: 6| Step: 6
Training loss: 2.353087985493608
Validation loss: 2.48408319399368

Epoch: 6| Step: 7
Training loss: 1.9634062891532718
Validation loss: 2.4926995464921693

Epoch: 6| Step: 8
Training loss: 2.6165377137629693
Validation loss: 2.474001911774748

Epoch: 6| Step: 9
Training loss: 2.2949835846091555
Validation loss: 2.519190649076424

Epoch: 6| Step: 10
Training loss: 2.4547619065942845
Validation loss: 2.5097903545737066

Epoch: 6| Step: 11
Training loss: 2.1834323666464317
Validation loss: 2.4937825478102265

Epoch: 6| Step: 12
Training loss: 2.4030786398197033
Validation loss: 2.4955603751367335

Epoch: 6| Step: 13
Training loss: 2.7974086657248542
Validation loss: 2.486184584176091

Epoch: 224| Step: 0
Training loss: 2.3872157701600374
Validation loss: 2.5159766990124828

Epoch: 6| Step: 1
Training loss: 2.299495525597128
Validation loss: 2.491231830703693

Epoch: 6| Step: 2
Training loss: 2.1438490819693876
Validation loss: 2.5044977275544333

Epoch: 6| Step: 3
Training loss: 2.7547901223163036
Validation loss: 2.4939356643464317

Epoch: 6| Step: 4
Training loss: 2.450042732021813
Validation loss: 2.4689523103353026

Epoch: 6| Step: 5
Training loss: 2.485483558012581
Validation loss: 2.501759225979087

Epoch: 6| Step: 6
Training loss: 1.893456852447739
Validation loss: 2.51397413972165

Epoch: 6| Step: 7
Training loss: 2.1203619887241705
Validation loss: 2.49643095449807

Epoch: 6| Step: 8
Training loss: 2.811274961069849
Validation loss: 2.484875886048123

Epoch: 6| Step: 9
Training loss: 2.914450284708273
Validation loss: 2.4751454955775727

Epoch: 6| Step: 10
Training loss: 2.28088396872177
Validation loss: 2.501067267021562

Epoch: 6| Step: 11
Training loss: 2.6786460520930717
Validation loss: 2.497381695299067

Epoch: 6| Step: 12
Training loss: 2.990868499313868
Validation loss: 2.493980151560538

Epoch: 6| Step: 13
Training loss: 1.861383907607029
Validation loss: 2.4822898953523715

Epoch: 225| Step: 0
Training loss: 1.932044871182366
Validation loss: 2.4927499117040743

Epoch: 6| Step: 1
Training loss: 2.240426997290469
Validation loss: 2.4965459681739848

Epoch: 6| Step: 2
Training loss: 2.5085597365932677
Validation loss: 2.506329213520225

Epoch: 6| Step: 3
Training loss: 2.569578674750953
Validation loss: 2.477682346794008

Epoch: 6| Step: 4
Training loss: 2.954021983690533
Validation loss: 2.469713345278282

Epoch: 6| Step: 5
Training loss: 2.6899840828803994
Validation loss: 2.5061529633030766

Epoch: 6| Step: 6
Training loss: 1.0273591827277755
Validation loss: 2.4794918395799144

Epoch: 6| Step: 7
Training loss: 2.4158952292910247
Validation loss: 2.476148945610461

Epoch: 6| Step: 8
Training loss: 1.9624924896485285
Validation loss: 2.4807968991001372

Epoch: 6| Step: 9
Training loss: 3.1802004838520284
Validation loss: 2.507004180886719

Epoch: 6| Step: 10
Training loss: 2.0094293993383525
Validation loss: 2.4756073364101865

Epoch: 6| Step: 11
Training loss: 2.567542162941806
Validation loss: 2.462504992811306

Epoch: 6| Step: 12
Training loss: 2.6619898096831043
Validation loss: 2.4824391326829818

Epoch: 6| Step: 13
Training loss: 3.3111851799835326
Validation loss: 2.472283072661976

Epoch: 226| Step: 0
Training loss: 2.7343212885349715
Validation loss: 2.4749673592428807

Epoch: 6| Step: 1
Training loss: 2.836708825676319
Validation loss: 2.4576856883883322

Epoch: 6| Step: 2
Training loss: 2.082032624149406
Validation loss: 2.4866205346117294

Epoch: 6| Step: 3
Training loss: 2.4147213527497913
Validation loss: 2.5000433046425563

Epoch: 6| Step: 4
Training loss: 2.728309836576772
Validation loss: 2.464483511933378

Epoch: 6| Step: 5
Training loss: 2.1244139143591356
Validation loss: 2.476179939168381

Epoch: 6| Step: 6
Training loss: 2.6825127569145915
Validation loss: 2.497883684382114

Epoch: 6| Step: 7
Training loss: 2.523833252665866
Validation loss: 2.4816481704974134

Epoch: 6| Step: 8
Training loss: 2.4499943674762363
Validation loss: 2.4854121015409634

Epoch: 6| Step: 9
Training loss: 2.159799059952133
Validation loss: 2.4623558685196576

Epoch: 6| Step: 10
Training loss: 2.616228799164484
Validation loss: 2.474045452835666

Epoch: 6| Step: 11
Training loss: 1.8214717988085845
Validation loss: 2.4762064246038538

Epoch: 6| Step: 12
Training loss: 2.7365065631505465
Validation loss: 2.499988745592278

Epoch: 6| Step: 13
Training loss: 2.336144683733737
Validation loss: 2.503230495446375

Epoch: 227| Step: 0
Training loss: 1.984798115954414
Validation loss: 2.4771448399636684

Epoch: 6| Step: 1
Training loss: 2.532975162316559
Validation loss: 2.472501824749895

Epoch: 6| Step: 2
Training loss: 2.627226384922056
Validation loss: 2.5027125921567315

Epoch: 6| Step: 3
Training loss: 2.7168592696768905
Validation loss: 2.5058199040706564

Epoch: 6| Step: 4
Training loss: 2.047625687948551
Validation loss: 2.4913691166023955

Epoch: 6| Step: 5
Training loss: 2.9791469617783286
Validation loss: 2.508844991545997

Epoch: 6| Step: 6
Training loss: 2.079669693799676
Validation loss: 2.499709760574064

Epoch: 6| Step: 7
Training loss: 2.353190824644262
Validation loss: 2.5013249864869715

Epoch: 6| Step: 8
Training loss: 2.645856381613799
Validation loss: 2.4712085411046565

Epoch: 6| Step: 9
Training loss: 3.258372745779625
Validation loss: 2.476679258220009

Epoch: 6| Step: 10
Training loss: 1.8331888604315307
Validation loss: 2.4978899716415515

Epoch: 6| Step: 11
Training loss: 2.356274316798844
Validation loss: 2.510964874782611

Epoch: 6| Step: 12
Training loss: 2.0920281233419784
Validation loss: 2.4837853249201673

Epoch: 6| Step: 13
Training loss: 2.72487809144753
Validation loss: 2.4991291303353953

Epoch: 228| Step: 0
Training loss: 3.258917385612148
Validation loss: 2.4961079439431755

Epoch: 6| Step: 1
Training loss: 2.7023522479719664
Validation loss: 2.4929263331024103

Epoch: 6| Step: 2
Training loss: 2.3948062409008206
Validation loss: 2.5160887885628775

Epoch: 6| Step: 3
Training loss: 1.8810548294569565
Validation loss: 2.4722282950281516

Epoch: 6| Step: 4
Training loss: 2.128041727058483
Validation loss: 2.483859582920722

Epoch: 6| Step: 5
Training loss: 2.6029292918042017
Validation loss: 2.4958017980157696

Epoch: 6| Step: 6
Training loss: 2.482504854533663
Validation loss: 2.4973965943308265

Epoch: 6| Step: 7
Training loss: 2.807653277621303
Validation loss: 2.495857363790324

Epoch: 6| Step: 8
Training loss: 2.6474276167328625
Validation loss: 2.4854906646613735

Epoch: 6| Step: 9
Training loss: 2.4292093769417002
Validation loss: 2.509714895924539

Epoch: 6| Step: 10
Training loss: 2.5562894039334823
Validation loss: 2.490771377059657

Epoch: 6| Step: 11
Training loss: 1.8650968970318924
Validation loss: 2.52258346675636

Epoch: 6| Step: 12
Training loss: 1.933451206077924
Validation loss: 2.4954612344306724

Epoch: 6| Step: 13
Training loss: 2.0208698020344857
Validation loss: 2.469718087002338

Epoch: 229| Step: 0
Training loss: 2.46404106987129
Validation loss: 2.4959764691990367

Epoch: 6| Step: 1
Training loss: 2.0955604582875624
Validation loss: 2.4750543299819334

Epoch: 6| Step: 2
Training loss: 2.6881462916914822
Validation loss: 2.485632824311833

Epoch: 6| Step: 3
Training loss: 2.358393281729613
Validation loss: 2.479541887356806

Epoch: 6| Step: 4
Training loss: 2.3797149035453304
Validation loss: 2.481479615078122

Epoch: 6| Step: 5
Training loss: 2.3269641209333427
Validation loss: 2.4766402797325395

Epoch: 6| Step: 6
Training loss: 2.66809206854915
Validation loss: 2.4950826891632176

Epoch: 6| Step: 7
Training loss: 1.8078884784686897
Validation loss: 2.478537343050128

Epoch: 6| Step: 8
Training loss: 2.4032182295911677
Validation loss: 2.497612603880761

Epoch: 6| Step: 9
Training loss: 2.532913414970361
Validation loss: 2.5031030250391675

Epoch: 6| Step: 10
Training loss: 2.917981332856488
Validation loss: 2.4762669708479925

Epoch: 6| Step: 11
Training loss: 1.9708310587616498
Validation loss: 2.4824232691683004

Epoch: 6| Step: 12
Training loss: 2.6611948996484256
Validation loss: 2.4853875615962897

Epoch: 6| Step: 13
Training loss: 2.770326486757689
Validation loss: 2.491670542366991

Epoch: 230| Step: 0
Training loss: 3.013214412835118
Validation loss: 2.502458229294521

Epoch: 6| Step: 1
Training loss: 2.1123887749458747
Validation loss: 2.507112486303578

Epoch: 6| Step: 2
Training loss: 2.659040533565268
Validation loss: 2.478955200295701

Epoch: 6| Step: 3
Training loss: 2.6065854449028887
Validation loss: 2.4880407109607106

Epoch: 6| Step: 4
Training loss: 2.368975779057324
Validation loss: 2.475167831501241

Epoch: 6| Step: 5
Training loss: 2.325754072077308
Validation loss: 2.482744545216584

Epoch: 6| Step: 6
Training loss: 2.509448127108613
Validation loss: 2.476137829206765

Epoch: 6| Step: 7
Training loss: 2.1018826265675967
Validation loss: 2.499375112432878

Epoch: 6| Step: 8
Training loss: 2.6411125139378853
Validation loss: 2.5069696743288064

Epoch: 6| Step: 9
Training loss: 2.667735769619084
Validation loss: 2.5067727823411943

Epoch: 6| Step: 10
Training loss: 2.6076743243016973
Validation loss: 2.486949022408162

Epoch: 6| Step: 11
Training loss: 1.9253363104983918
Validation loss: 2.4857528940453246

Epoch: 6| Step: 12
Training loss: 2.6072644132580973
Validation loss: 2.49396483996061

Epoch: 6| Step: 13
Training loss: 1.7621249050030219
Validation loss: 2.5089043649138336

Epoch: 231| Step: 0
Training loss: 2.252931698193457
Validation loss: 2.505069365446217

Epoch: 6| Step: 1
Training loss: 2.221738065853885
Validation loss: 2.4879345970411655

Epoch: 6| Step: 2
Training loss: 1.8709772826323854
Validation loss: 2.475969312826071

Epoch: 6| Step: 3
Training loss: 2.735853307834864
Validation loss: 2.5079081992463355

Epoch: 6| Step: 4
Training loss: 2.5228008022105666
Validation loss: 2.4680381694684863

Epoch: 6| Step: 5
Training loss: 3.0378969600298
Validation loss: 2.483950820634632

Epoch: 6| Step: 6
Training loss: 2.5704907758391813
Validation loss: 2.485937996075854

Epoch: 6| Step: 7
Training loss: 2.331536066334678
Validation loss: 2.49064235497219

Epoch: 6| Step: 8
Training loss: 1.8473975099208793
Validation loss: 2.5033015323909313

Epoch: 6| Step: 9
Training loss: 2.176623525537622
Validation loss: 2.4732917617348167

Epoch: 6| Step: 10
Training loss: 2.112328841820404
Validation loss: 2.4871776279782174

Epoch: 6| Step: 11
Training loss: 3.057910048654411
Validation loss: 2.500167597003348

Epoch: 6| Step: 12
Training loss: 2.423212383545409
Validation loss: 2.5120649237483392

Epoch: 6| Step: 13
Training loss: 3.0232526540313205
Validation loss: 2.479482018701131

Epoch: 232| Step: 0
Training loss: 2.7240181230118625
Validation loss: 2.4813146013119054

Epoch: 6| Step: 1
Training loss: 2.6578442445504202
Validation loss: 2.4769716083742677

Epoch: 6| Step: 2
Training loss: 2.5699421810073284
Validation loss: 2.4804833144720475

Epoch: 6| Step: 3
Training loss: 2.6831708238884113
Validation loss: 2.487096287635124

Epoch: 6| Step: 4
Training loss: 2.7090076096245848
Validation loss: 2.502486388163613

Epoch: 6| Step: 5
Training loss: 2.137293987496633
Validation loss: 2.4930872651272717

Epoch: 6| Step: 6
Training loss: 3.052111229535794
Validation loss: 2.5077475374952165

Epoch: 6| Step: 7
Training loss: 2.4414248046169926
Validation loss: 2.512525640112059

Epoch: 6| Step: 8
Training loss: 2.5547678523594786
Validation loss: 2.4893059497269863

Epoch: 6| Step: 9
Training loss: 2.4250622849478454
Validation loss: 2.513290040094911

Epoch: 6| Step: 10
Training loss: 2.0268177680523176
Validation loss: 2.5150683661112287

Epoch: 6| Step: 11
Training loss: 1.7303172576932584
Validation loss: 2.5068552053614765

Epoch: 6| Step: 12
Training loss: 1.8832617259408089
Validation loss: 2.50034444958672

Epoch: 6| Step: 13
Training loss: 1.7528248875139958
Validation loss: 2.4847967969103175

Epoch: 233| Step: 0
Training loss: 2.6632472605954813
Validation loss: 2.4837392157423057

Epoch: 6| Step: 1
Training loss: 2.1495402887033284
Validation loss: 2.516757067066098

Epoch: 6| Step: 2
Training loss: 2.3648167185503417
Validation loss: 2.50343096757334

Epoch: 6| Step: 3
Training loss: 2.3895702154392033
Validation loss: 2.4986400843258783

Epoch: 6| Step: 4
Training loss: 2.48626215053867
Validation loss: 2.4860329719879846

Epoch: 6| Step: 5
Training loss: 2.143748100435622
Validation loss: 2.5122083920510083

Epoch: 6| Step: 6
Training loss: 2.2790780375076682
Validation loss: 2.5098604540831104

Epoch: 6| Step: 7
Training loss: 2.7030513510841594
Validation loss: 2.4956787838748116

Epoch: 6| Step: 8
Training loss: 1.941041969800713
Validation loss: 2.4813757616195615

Epoch: 6| Step: 9
Training loss: 2.1880847694252883
Validation loss: 2.4646475524859928

Epoch: 6| Step: 10
Training loss: 2.7821288702574893
Validation loss: 2.4721935664684582

Epoch: 6| Step: 11
Training loss: 2.7807646767296603
Validation loss: 2.481663963555346

Epoch: 6| Step: 12
Training loss: 2.592491396059273
Validation loss: 2.496979129109822

Epoch: 6| Step: 13
Training loss: 2.4939427427986214
Validation loss: 2.4785590629786083

Epoch: 234| Step: 0
Training loss: 2.2735347137116477
Validation loss: 2.4560642007146773

Epoch: 6| Step: 1
Training loss: 2.478916433405405
Validation loss: 2.489791688057799

Epoch: 6| Step: 2
Training loss: 3.1260064602404984
Validation loss: 2.501983465897203

Epoch: 6| Step: 3
Training loss: 2.6361456806348977
Validation loss: 2.5343397054061576

Epoch: 6| Step: 4
Training loss: 2.1483607053036446
Validation loss: 2.5176524656463184

Epoch: 6| Step: 5
Training loss: 2.474633268679043
Validation loss: 2.4968970156247603

Epoch: 6| Step: 6
Training loss: 2.475368368305488
Validation loss: 2.501753190281726

Epoch: 6| Step: 7
Training loss: 2.1480150951941956
Validation loss: 2.4938230098128193

Epoch: 6| Step: 8
Training loss: 2.545377513413485
Validation loss: 2.5044620870849745

Epoch: 6| Step: 9
Training loss: 2.3983099589778374
Validation loss: 2.483707044349214

Epoch: 6| Step: 10
Training loss: 1.753997596451995
Validation loss: 2.5251316519925817

Epoch: 6| Step: 11
Training loss: 2.2315921125809695
Validation loss: 2.4949227705656103

Epoch: 6| Step: 12
Training loss: 2.3392665450414154
Validation loss: 2.4852644507814166

Epoch: 6| Step: 13
Training loss: 3.137068219509257
Validation loss: 2.5037084034200845

Epoch: 235| Step: 0
Training loss: 2.937158118298987
Validation loss: 2.529026847359137

Epoch: 6| Step: 1
Training loss: 2.766828372166917
Validation loss: 2.492424503752645

Epoch: 6| Step: 2
Training loss: 2.326791163595916
Validation loss: 2.48019031980274

Epoch: 6| Step: 3
Training loss: 2.7990952528663864
Validation loss: 2.4976474542346905

Epoch: 6| Step: 4
Training loss: 2.4087240208015177
Validation loss: 2.5028550171028505

Epoch: 6| Step: 5
Training loss: 1.9521955796427668
Validation loss: 2.4716666497880575

Epoch: 6| Step: 6
Training loss: 2.3094594400580926
Validation loss: 2.4953510846578166

Epoch: 6| Step: 7
Training loss: 1.9388475346580338
Validation loss: 2.4989055104060363

Epoch: 6| Step: 8
Training loss: 2.5367020653733143
Validation loss: 2.4847433062669224

Epoch: 6| Step: 9
Training loss: 2.7238056050087263
Validation loss: 2.4876747293004016

Epoch: 6| Step: 10
Training loss: 1.7974808044894206
Validation loss: 2.471770873844823

Epoch: 6| Step: 11
Training loss: 1.8813792745080242
Validation loss: 2.508284377601272

Epoch: 6| Step: 12
Training loss: 2.6610888220274576
Validation loss: 2.502965895710339

Epoch: 6| Step: 13
Training loss: 2.6167921991871665
Validation loss: 2.492987707285426

Epoch: 236| Step: 0
Training loss: 2.2258749452407667
Validation loss: 2.4881057346377076

Epoch: 6| Step: 1
Training loss: 2.540736471172972
Validation loss: 2.4861617955553

Epoch: 6| Step: 2
Training loss: 1.900615243682859
Validation loss: 2.4893128652380976

Epoch: 6| Step: 3
Training loss: 1.9729876853570159
Validation loss: 2.4654461014939586

Epoch: 6| Step: 4
Training loss: 2.3610681180841953
Validation loss: 2.496919669306523

Epoch: 6| Step: 5
Training loss: 2.5355886316923493
Validation loss: 2.4938259324043694

Epoch: 6| Step: 6
Training loss: 1.8581043678264793
Validation loss: 2.4855803407779162

Epoch: 6| Step: 7
Training loss: 3.0375395344488676
Validation loss: 2.466752354824999

Epoch: 6| Step: 8
Training loss: 1.5995104785944425
Validation loss: 2.476100175732704

Epoch: 6| Step: 9
Training loss: 2.4486417197121537
Validation loss: 2.488305146847348

Epoch: 6| Step: 10
Training loss: 2.903224231350379
Validation loss: 2.472218144052308

Epoch: 6| Step: 11
Training loss: 2.231298289056964
Validation loss: 2.5070734635569507

Epoch: 6| Step: 12
Training loss: 2.9827753543289326
Validation loss: 2.4937616068424733

Epoch: 6| Step: 13
Training loss: 3.0304292177167427
Validation loss: 2.510152872779952

Epoch: 237| Step: 0
Training loss: 2.328977492764625
Validation loss: 2.489727608359269

Epoch: 6| Step: 1
Training loss: 2.1583781037664274
Validation loss: 2.478944023050363

Epoch: 6| Step: 2
Training loss: 2.660860973787652
Validation loss: 2.4950681734365094

Epoch: 6| Step: 3
Training loss: 2.1469604963800237
Validation loss: 2.497145243136589

Epoch: 6| Step: 4
Training loss: 1.3748487909577718
Validation loss: 2.468199477854288

Epoch: 6| Step: 5
Training loss: 3.1296888651394927
Validation loss: 2.505940197361135

Epoch: 6| Step: 6
Training loss: 2.599701086614785
Validation loss: 2.501362243848902

Epoch: 6| Step: 7
Training loss: 2.1073607823918254
Validation loss: 2.47939298952554

Epoch: 6| Step: 8
Training loss: 2.482993647579159
Validation loss: 2.540457200895918

Epoch: 6| Step: 9
Training loss: 2.5801973279262183
Validation loss: 2.460832513958299

Epoch: 6| Step: 10
Training loss: 2.635806953168718
Validation loss: 2.514874302419243

Epoch: 6| Step: 11
Training loss: 2.2913219770664903
Validation loss: 2.5091169837193337

Epoch: 6| Step: 12
Training loss: 2.680248679964267
Validation loss: 2.5141350551542803

Epoch: 6| Step: 13
Training loss: 2.3171204467866993
Validation loss: 2.506382120740701

Epoch: 238| Step: 0
Training loss: 2.80715332445296
Validation loss: 2.4585717678108905

Epoch: 6| Step: 1
Training loss: 2.126818159601048
Validation loss: 2.4984509314168495

Epoch: 6| Step: 2
Training loss: 2.3228587555330904
Validation loss: 2.494938523778882

Epoch: 6| Step: 3
Training loss: 2.095192597306011
Validation loss: 2.4695952954208797

Epoch: 6| Step: 4
Training loss: 1.9871586776445256
Validation loss: 2.46143594652946

Epoch: 6| Step: 5
Training loss: 2.454651181676544
Validation loss: 2.4742655131504963

Epoch: 6| Step: 6
Training loss: 2.2788146096348973
Validation loss: 2.4790889541332333

Epoch: 6| Step: 7
Training loss: 2.5343421604648837
Validation loss: 2.497264059220041

Epoch: 6| Step: 8
Training loss: 2.222164481790414
Validation loss: 2.4827649035460935

Epoch: 6| Step: 9
Training loss: 2.780218554626024
Validation loss: 2.48482803029137

Epoch: 6| Step: 10
Training loss: 1.8495649032321928
Validation loss: 2.456263003230996

Epoch: 6| Step: 11
Training loss: 3.0296233226949174
Validation loss: 2.477277307936251

Epoch: 6| Step: 12
Training loss: 2.6687662879035856
Validation loss: 2.5021738906602313

Epoch: 6| Step: 13
Training loss: 2.388804421915304
Validation loss: 2.4828169850434545

Epoch: 239| Step: 0
Training loss: 2.264622538863877
Validation loss: 2.5079782343218926

Epoch: 6| Step: 1
Training loss: 2.346847013873009
Validation loss: 2.4969271202119576

Epoch: 6| Step: 2
Training loss: 2.9867569769534117
Validation loss: 2.4781933589866565

Epoch: 6| Step: 3
Training loss: 2.130455866999575
Validation loss: 2.4994157600684104

Epoch: 6| Step: 4
Training loss: 2.4009140102077002
Validation loss: 2.4882333144649333

Epoch: 6| Step: 5
Training loss: 2.327568243646791
Validation loss: 2.475205878234933

Epoch: 6| Step: 6
Training loss: 2.27745157971295
Validation loss: 2.479028599355995

Epoch: 6| Step: 7
Training loss: 2.5684523881090167
Validation loss: 2.4762722611457706

Epoch: 6| Step: 8
Training loss: 2.337773752757009
Validation loss: 2.505923129146151

Epoch: 6| Step: 9
Training loss: 2.626441196633764
Validation loss: 2.502683182020308

Epoch: 6| Step: 10
Training loss: 2.0204483399596738
Validation loss: 2.490553873482708

Epoch: 6| Step: 11
Training loss: 2.2634405720642636
Validation loss: 2.4891012140881354

Epoch: 6| Step: 12
Training loss: 2.9628333310627264
Validation loss: 2.4882333762832665

Epoch: 6| Step: 13
Training loss: 2.021596652980943
Validation loss: 2.4652576784451425

Epoch: 240| Step: 0
Training loss: 2.412598298595214
Validation loss: 2.475641823434098

Epoch: 6| Step: 1
Training loss: 1.4159585454551662
Validation loss: 2.5045278216451674

Epoch: 6| Step: 2
Training loss: 1.9019431567758394
Validation loss: 2.4889317945121205

Epoch: 6| Step: 3
Training loss: 2.488674258540983
Validation loss: 2.475433415200143

Epoch: 6| Step: 4
Training loss: 1.842397549393449
Validation loss: 2.5186604014791643

Epoch: 6| Step: 5
Training loss: 2.485643746638902
Validation loss: 2.4953429792349895

Epoch: 6| Step: 6
Training loss: 2.934686815231092
Validation loss: 2.5004274618112685

Epoch: 6| Step: 7
Training loss: 2.9123900167630725
Validation loss: 2.516035821553862

Epoch: 6| Step: 8
Training loss: 2.4708537542090023
Validation loss: 2.4984836481476216

Epoch: 6| Step: 9
Training loss: 2.1883343876383154
Validation loss: 2.4946987448126094

Epoch: 6| Step: 10
Training loss: 2.2133327490258115
Validation loss: 2.499323844738087

Epoch: 6| Step: 11
Training loss: 2.4318548514130245
Validation loss: 2.5094337675227414

Epoch: 6| Step: 12
Training loss: 2.8142476903630254
Validation loss: 2.483459842754975

Epoch: 6| Step: 13
Training loss: 3.0361631237932896
Validation loss: 2.5236308234178866

Epoch: 241| Step: 0
Training loss: 1.7906891203845652
Validation loss: 2.498680004174149

Epoch: 6| Step: 1
Training loss: 2.3401960766797147
Validation loss: 2.5228311982516103

Epoch: 6| Step: 2
Training loss: 2.4307480242378943
Validation loss: 2.4867109947319097

Epoch: 6| Step: 3
Training loss: 2.1187162053386595
Validation loss: 2.5332372114741912

Epoch: 6| Step: 4
Training loss: 2.505515689725363
Validation loss: 2.4947709259034916

Epoch: 6| Step: 5
Training loss: 1.819330761134779
Validation loss: 2.4677679284847645

Epoch: 6| Step: 6
Training loss: 2.548005584471136
Validation loss: 2.484994805960019

Epoch: 6| Step: 7
Training loss: 2.2624430443776333
Validation loss: 2.4736442604031765

Epoch: 6| Step: 8
Training loss: 2.499604003061113
Validation loss: 2.4693141088709236

Epoch: 6| Step: 9
Training loss: 2.618720399966962
Validation loss: 2.484463630860377

Epoch: 6| Step: 10
Training loss: 2.4368311624627106
Validation loss: 2.5153216565915333

Epoch: 6| Step: 11
Training loss: 2.230809174061161
Validation loss: 2.489585467311174

Epoch: 6| Step: 12
Training loss: 3.1399842173185784
Validation loss: 2.493840398308314

Epoch: 6| Step: 13
Training loss: 3.194727911788246
Validation loss: 2.48440193465565

Epoch: 242| Step: 0
Training loss: 2.6367917199104354
Validation loss: 2.501522937536192

Epoch: 6| Step: 1
Training loss: 2.702637468594634
Validation loss: 2.4818016857522767

Epoch: 6| Step: 2
Training loss: 2.942300971988696
Validation loss: 2.4675016288204623

Epoch: 6| Step: 3
Training loss: 2.1994357772715905
Validation loss: 2.501094699445697

Epoch: 6| Step: 4
Training loss: 1.7242140181787204
Validation loss: 2.4997189815047514

Epoch: 6| Step: 5
Training loss: 1.9994085152509864
Validation loss: 2.503336526797605

Epoch: 6| Step: 6
Training loss: 2.838448917845151
Validation loss: 2.471138874840055

Epoch: 6| Step: 7
Training loss: 2.490064523925633
Validation loss: 2.4908444901944455

Epoch: 6| Step: 8
Training loss: 2.4842636755226857
Validation loss: 2.491656888006386

Epoch: 6| Step: 9
Training loss: 2.07876175611593
Validation loss: 2.5136004355549644

Epoch: 6| Step: 10
Training loss: 2.3668398963857467
Validation loss: 2.461245899373158

Epoch: 6| Step: 11
Training loss: 2.018995675175396
Validation loss: 2.512221254058777

Epoch: 6| Step: 12
Training loss: 2.252291042784269
Validation loss: 2.492345957592349

Epoch: 6| Step: 13
Training loss: 2.97547440152382
Validation loss: 2.495957276560931

Epoch: 243| Step: 0
Training loss: 2.106593014097568
Validation loss: 2.468678752867468

Epoch: 6| Step: 1
Training loss: 1.8407287412983337
Validation loss: 2.4975294488261213

Epoch: 6| Step: 2
Training loss: 1.9474959165557244
Validation loss: 2.497127927959194

Epoch: 6| Step: 3
Training loss: 2.2359075025762816
Validation loss: 2.4760138598573733

Epoch: 6| Step: 4
Training loss: 2.088091249167491
Validation loss: 2.514255795893783

Epoch: 6| Step: 5
Training loss: 2.3470196106672065
Validation loss: 2.4822667869610733

Epoch: 6| Step: 6
Training loss: 2.928522229196735
Validation loss: 2.5108307779546757

Epoch: 6| Step: 7
Training loss: 2.8105784315679783
Validation loss: 2.511686852781326

Epoch: 6| Step: 8
Training loss: 2.705599671913005
Validation loss: 2.5173672142610175

Epoch: 6| Step: 9
Training loss: 2.678431625350867
Validation loss: 2.48114396086671

Epoch: 6| Step: 10
Training loss: 1.9433223855030313
Validation loss: 2.513753941266991

Epoch: 6| Step: 11
Training loss: 2.5895062394966515
Validation loss: 2.5001634903229837

Epoch: 6| Step: 12
Training loss: 2.7506472086080294
Validation loss: 2.4879938248955127

Epoch: 6| Step: 13
Training loss: 2.5850341694268746
Validation loss: 2.496193092556055

Epoch: 244| Step: 0
Training loss: 3.3596578789420803
Validation loss: 2.488233107373506

Epoch: 6| Step: 1
Training loss: 1.675411085669573
Validation loss: 2.4857890946246024

Epoch: 6| Step: 2
Training loss: 2.1818320822995436
Validation loss: 2.481729068569745

Epoch: 6| Step: 3
Training loss: 2.0050785435539207
Validation loss: 2.5245751807263828

Epoch: 6| Step: 4
Training loss: 2.0673018535606627
Validation loss: 2.493819612282987

Epoch: 6| Step: 5
Training loss: 2.3222834888794623
Validation loss: 2.4808012905040613

Epoch: 6| Step: 6
Training loss: 1.8052764856233734
Validation loss: 2.464450230447856

Epoch: 6| Step: 7
Training loss: 2.954804765219104
Validation loss: 2.4843395630748373

Epoch: 6| Step: 8
Training loss: 1.8424260186465538
Validation loss: 2.494969902494096

Epoch: 6| Step: 9
Training loss: 2.7456832296725486
Validation loss: 2.4890075036881405

Epoch: 6| Step: 10
Training loss: 2.674831249582881
Validation loss: 2.492670990120938

Epoch: 6| Step: 11
Training loss: 2.5085157317530693
Validation loss: 2.4795835404231727

Epoch: 6| Step: 12
Training loss: 2.3221465289583096
Validation loss: 2.4955179645261225

Epoch: 6| Step: 13
Training loss: 2.7869955145201297
Validation loss: 2.4906630033401456

Epoch: 245| Step: 0
Training loss: 2.1893884409351148
Validation loss: 2.4888397309711614

Epoch: 6| Step: 1
Training loss: 2.3775610918124257
Validation loss: 2.4482106507252896

Epoch: 6| Step: 2
Training loss: 2.791631034130226
Validation loss: 2.4820167171694703

Epoch: 6| Step: 3
Training loss: 1.8078228026206133
Validation loss: 2.4807878992554495

Epoch: 6| Step: 4
Training loss: 2.522029330271364
Validation loss: 2.472368586599255

Epoch: 6| Step: 5
Training loss: 2.3617325681735806
Validation loss: 2.4853070569938582

Epoch: 6| Step: 6
Training loss: 2.0389134144267973
Validation loss: 2.4856950087382184

Epoch: 6| Step: 7
Training loss: 2.2967508503065344
Validation loss: 2.498444602473075

Epoch: 6| Step: 8
Training loss: 2.6015877937255767
Validation loss: 2.5118044421058165

Epoch: 6| Step: 9
Training loss: 2.4073831441531457
Validation loss: 2.508508827279739

Epoch: 6| Step: 10
Training loss: 2.6643002759140337
Validation loss: 2.4914741422253788

Epoch: 6| Step: 11
Training loss: 2.668309381279396
Validation loss: 2.492421832547043

Epoch: 6| Step: 12
Training loss: 2.382662408823152
Validation loss: 2.4932318367742377

Epoch: 6| Step: 13
Training loss: 2.5175611733634593
Validation loss: 2.5069674450481223

Epoch: 246| Step: 0
Training loss: 2.225048420411351
Validation loss: 2.4670439511092446

Epoch: 6| Step: 1
Training loss: 2.8390850328675503
Validation loss: 2.515233575952384

Epoch: 6| Step: 2
Training loss: 3.0086614822533493
Validation loss: 2.5117467897406858

Epoch: 6| Step: 3
Training loss: 2.10044110524644
Validation loss: 2.483609156360528

Epoch: 6| Step: 4
Training loss: 2.662494723892357
Validation loss: 2.4859493372974057

Epoch: 6| Step: 5
Training loss: 2.012763898144557
Validation loss: 2.470503641532249

Epoch: 6| Step: 6
Training loss: 2.1670183727716035
Validation loss: 2.5021855225234657

Epoch: 6| Step: 7
Training loss: 2.131865238647123
Validation loss: 2.500989738533082

Epoch: 6| Step: 8
Training loss: 2.5254232901623896
Validation loss: 2.4985276860274968

Epoch: 6| Step: 9
Training loss: 1.4592178750252522
Validation loss: 2.5109564659912973

Epoch: 6| Step: 10
Training loss: 2.054789957603196
Validation loss: 2.5009398657441677

Epoch: 6| Step: 11
Training loss: 2.976494895988355
Validation loss: 2.463750853289337

Epoch: 6| Step: 12
Training loss: 2.3059587496321097
Validation loss: 2.496862328316356

Epoch: 6| Step: 13
Training loss: 2.6386730496215467
Validation loss: 2.468937967542691

Epoch: 247| Step: 0
Training loss: 2.519950417833137
Validation loss: 2.486547941655489

Epoch: 6| Step: 1
Training loss: 2.550046385548884
Validation loss: 2.4759476685440496

Epoch: 6| Step: 2
Training loss: 2.7060536302325615
Validation loss: 2.517086603409592

Epoch: 6| Step: 3
Training loss: 2.368770259076047
Validation loss: 2.484067885891758

Epoch: 6| Step: 4
Training loss: 2.27760221869572
Validation loss: 2.491800346112507

Epoch: 6| Step: 5
Training loss: 2.924609857607313
Validation loss: 2.4832391880301374

Epoch: 6| Step: 6
Training loss: 2.722328374267834
Validation loss: 2.506008133515334

Epoch: 6| Step: 7
Training loss: 1.960663916967998
Validation loss: 2.5104984797226106

Epoch: 6| Step: 8
Training loss: 2.283911837317642
Validation loss: 2.5003037955170013

Epoch: 6| Step: 9
Training loss: 2.6041107985543666
Validation loss: 2.5017143811171763

Epoch: 6| Step: 10
Training loss: 1.8056230638387354
Validation loss: 2.5016485398366486

Epoch: 6| Step: 11
Training loss: 2.38039498185129
Validation loss: 2.4863062955907558

Epoch: 6| Step: 12
Training loss: 1.9075534304113915
Validation loss: 2.458525494934532

Epoch: 6| Step: 13
Training loss: 2.522689661281433
Validation loss: 2.4985569932224605

Epoch: 248| Step: 0
Training loss: 2.22612278929862
Validation loss: 2.469973832851589

Epoch: 6| Step: 1
Training loss: 2.383049624791979
Validation loss: 2.508919136254044

Epoch: 6| Step: 2
Training loss: 3.0097843196815575
Validation loss: 2.504074318591193

Epoch: 6| Step: 3
Training loss: 2.014702874325136
Validation loss: 2.4652408152429337

Epoch: 6| Step: 4
Training loss: 2.53420866433337
Validation loss: 2.472676374132598

Epoch: 6| Step: 5
Training loss: 2.4003242750441474
Validation loss: 2.475854802238225

Epoch: 6| Step: 6
Training loss: 2.8493098310049616
Validation loss: 2.4894956636037584

Epoch: 6| Step: 7
Training loss: 2.1532588612617607
Validation loss: 2.500601057380411

Epoch: 6| Step: 8
Training loss: 2.1785842126833037
Validation loss: 2.4891920815034996

Epoch: 6| Step: 9
Training loss: 3.048717704498669
Validation loss: 2.5070469166575977

Epoch: 6| Step: 10
Training loss: 2.2174190773976687
Validation loss: 2.499233468787066

Epoch: 6| Step: 11
Training loss: 1.830963669612846
Validation loss: 2.4928049613663212

Epoch: 6| Step: 12
Training loss: 1.9613752142551308
Validation loss: 2.4980911217225974

Epoch: 6| Step: 13
Training loss: 2.4163160946761226
Validation loss: 2.4907098185740955

Epoch: 249| Step: 0
Training loss: 2.6951059455783635
Validation loss: 2.5087440101658345

Epoch: 6| Step: 1
Training loss: 3.194674477149998
Validation loss: 2.459311335766232

Epoch: 6| Step: 2
Training loss: 2.1271394169880353
Validation loss: 2.486295472067374

Epoch: 6| Step: 3
Training loss: 2.597571258301794
Validation loss: 2.47571610098864

Epoch: 6| Step: 4
Training loss: 2.513217034199878
Validation loss: 2.4932991876392316

Epoch: 6| Step: 5
Training loss: 2.173730071702
Validation loss: 2.4787464376838337

Epoch: 6| Step: 6
Training loss: 2.368215507656418
Validation loss: 2.4977889856258977

Epoch: 6| Step: 7
Training loss: 2.0886927777527324
Validation loss: 2.4812483499292686

Epoch: 6| Step: 8
Training loss: 2.7113012240237304
Validation loss: 2.4702230648347174

Epoch: 6| Step: 9
Training loss: 1.6091320261822977
Validation loss: 2.475664988486556

Epoch: 6| Step: 10
Training loss: 2.5002992450909636
Validation loss: 2.4947388181591377

Epoch: 6| Step: 11
Training loss: 2.5567892685613662
Validation loss: 2.4741328248607846

Epoch: 6| Step: 12
Training loss: 1.9714894082473953
Validation loss: 2.4856953867307787

Epoch: 6| Step: 13
Training loss: 1.950349712802241
Validation loss: 2.4788485997134893

Epoch: 250| Step: 0
Training loss: 2.392442598202381
Validation loss: 2.4940101495036573

Epoch: 6| Step: 1
Training loss: 2.0599784464773343
Validation loss: 2.500795614121962

Epoch: 6| Step: 2
Training loss: 2.8500663281134346
Validation loss: 2.5071660181185464

Epoch: 6| Step: 3
Training loss: 3.2916519229091943
Validation loss: 2.4987347220992606

Epoch: 6| Step: 4
Training loss: 2.544873346201254
Validation loss: 2.4927436155940166

Epoch: 6| Step: 5
Training loss: 2.0180910387250313
Validation loss: 2.4978734313736686

Epoch: 6| Step: 6
Training loss: 1.9804317914836134
Validation loss: 2.492639911580702

Epoch: 6| Step: 7
Training loss: 2.311202020059444
Validation loss: 2.495697757801456

Epoch: 6| Step: 8
Training loss: 1.5800500591411937
Validation loss: 2.5022932875822606

Epoch: 6| Step: 9
Training loss: 1.9113691414821932
Validation loss: 2.4996106470102926

Epoch: 6| Step: 10
Training loss: 2.484877625489768
Validation loss: 2.446508525085206

Epoch: 6| Step: 11
Training loss: 2.569389107827122
Validation loss: 2.482051859838283

Epoch: 6| Step: 12
Training loss: 2.26633731562317
Validation loss: 2.5176166020521515

Epoch: 6| Step: 13
Training loss: 2.4765960979890247
Validation loss: 2.4655133722682554

Epoch: 251| Step: 0
Training loss: 2.421683223883921
Validation loss: 2.5030813506297256

Epoch: 6| Step: 1
Training loss: 2.321371125988159
Validation loss: 2.504767439593815

Epoch: 6| Step: 2
Training loss: 2.198996171816989
Validation loss: 2.4822283217275545

Epoch: 6| Step: 3
Training loss: 2.6873245181966903
Validation loss: 2.5132841585734926

Epoch: 6| Step: 4
Training loss: 2.60616127430307
Validation loss: 2.4956025076655624

Epoch: 6| Step: 5
Training loss: 2.6559963329588614
Validation loss: 2.492663741444501

Epoch: 6| Step: 6
Training loss: 1.8959122805523774
Validation loss: 2.4888204554861284

Epoch: 6| Step: 7
Training loss: 2.240244485421551
Validation loss: 2.5035164948401967

Epoch: 6| Step: 8
Training loss: 2.401778587294269
Validation loss: 2.443904519192768

Epoch: 6| Step: 9
Training loss: 1.7927577075295185
Validation loss: 2.498310278968436

Epoch: 6| Step: 10
Training loss: 2.4540884470712507
Validation loss: 2.4841932551584693

Epoch: 6| Step: 11
Training loss: 2.767924931131161
Validation loss: 2.5018101158589072

Epoch: 6| Step: 12
Training loss: 2.5444843328904008
Validation loss: 2.511796136147902

Epoch: 6| Step: 13
Training loss: 1.9903467388086014
Validation loss: 2.491567614773918

Epoch: 252| Step: 0
Training loss: 2.535959078449572
Validation loss: 2.4959847702825675

Epoch: 6| Step: 1
Training loss: 2.8661295838646073
Validation loss: 2.490068806841103

Epoch: 6| Step: 2
Training loss: 2.639143759705657
Validation loss: 2.5008279557395507

Epoch: 6| Step: 3
Training loss: 2.229757700017505
Validation loss: 2.53112204109393

Epoch: 6| Step: 4
Training loss: 2.6497700357522738
Validation loss: 2.4833870923712786

Epoch: 6| Step: 5
Training loss: 2.2255630123737
Validation loss: 2.5220937998885677

Epoch: 6| Step: 6
Training loss: 2.070939800306648
Validation loss: 2.4738547427256683

Epoch: 6| Step: 7
Training loss: 2.2230097752680935
Validation loss: 2.469851332161797

Epoch: 6| Step: 8
Training loss: 1.9424786129317841
Validation loss: 2.5057453832335352

Epoch: 6| Step: 9
Training loss: 2.3699236375441566
Validation loss: 2.484600554020309

Epoch: 6| Step: 10
Training loss: 1.9233948195406834
Validation loss: 2.482286215581378

Epoch: 6| Step: 11
Training loss: 2.4381488034382808
Validation loss: 2.496331451958901

Epoch: 6| Step: 12
Training loss: 2.202732132316756
Validation loss: 2.5074150847252583

Epoch: 6| Step: 13
Training loss: 2.86188851034454
Validation loss: 2.522135407857378

Epoch: 253| Step: 0
Training loss: 2.2835032165518054
Validation loss: 2.497435753908624

Epoch: 6| Step: 1
Training loss: 2.661784252259866
Validation loss: 2.4698507799597462

Epoch: 6| Step: 2
Training loss: 2.182017731752735
Validation loss: 2.507677033378339

Epoch: 6| Step: 3
Training loss: 2.874527270386949
Validation loss: 2.505027017578477

Epoch: 6| Step: 4
Training loss: 2.001328980449811
Validation loss: 2.497488065806447

Epoch: 6| Step: 5
Training loss: 1.2521640165529337
Validation loss: 2.4838476711976436

Epoch: 6| Step: 6
Training loss: 2.209228070457499
Validation loss: 2.509189729856095

Epoch: 6| Step: 7
Training loss: 2.1921470328393635
Validation loss: 2.4931259114115734

Epoch: 6| Step: 8
Training loss: 2.0296803204862437
Validation loss: 2.4885549087167633

Epoch: 6| Step: 9
Training loss: 2.4837972101064567
Validation loss: 2.5017468287024296

Epoch: 6| Step: 10
Training loss: 2.9918176009021455
Validation loss: 2.488203398332653

Epoch: 6| Step: 11
Training loss: 2.5294832256701234
Validation loss: 2.4740503344351956

Epoch: 6| Step: 12
Training loss: 2.1889894047145675
Validation loss: 2.481014472733085

Epoch: 6| Step: 13
Training loss: 3.5841751588355537
Validation loss: 2.5214113196438173

Epoch: 254| Step: 0
Training loss: 2.310807510857165
Validation loss: 2.503522761809511

Epoch: 6| Step: 1
Training loss: 2.3014677671785493
Validation loss: 2.4972523982737904

Epoch: 6| Step: 2
Training loss: 2.3921171032235584
Validation loss: 2.486078502916062

Epoch: 6| Step: 3
Training loss: 2.6274524313470833
Validation loss: 2.49654851995705

Epoch: 6| Step: 4
Training loss: 2.2516642879056565
Validation loss: 2.484443485603099

Epoch: 6| Step: 5
Training loss: 1.807692762677624
Validation loss: 2.4831522520512728

Epoch: 6| Step: 6
Training loss: 2.328077584622289
Validation loss: 2.504875484534912

Epoch: 6| Step: 7
Training loss: 2.220142733307051
Validation loss: 2.523557637182126

Epoch: 6| Step: 8
Training loss: 2.547069331519154
Validation loss: 2.5080298229069813

Epoch: 6| Step: 9
Training loss: 2.860982140985007
Validation loss: 2.482722366260127

Epoch: 6| Step: 10
Training loss: 2.3802961226174477
Validation loss: 2.496455030575465

Epoch: 6| Step: 11
Training loss: 2.1039321189562026
Validation loss: 2.479078464140293

Epoch: 6| Step: 12
Training loss: 3.0061233335207476
Validation loss: 2.4813083133802305

Epoch: 6| Step: 13
Training loss: 1.7454634175156396
Validation loss: 2.4877246026648967

Epoch: 255| Step: 0
Training loss: 1.971715842714259
Validation loss: 2.4885912086376187

Epoch: 6| Step: 1
Training loss: 2.6726991152120587
Validation loss: 2.463483776487762

Epoch: 6| Step: 2
Training loss: 2.258015765375829
Validation loss: 2.4852674886541286

Epoch: 6| Step: 3
Training loss: 2.7186009157894166
Validation loss: 2.5112218673924445

Epoch: 6| Step: 4
Training loss: 2.5939020319124753
Validation loss: 2.4925070237725935

Epoch: 6| Step: 5
Training loss: 2.7234982648451425
Validation loss: 2.496546158145852

Epoch: 6| Step: 6
Training loss: 1.7622272578024918
Validation loss: 2.4966649965787537

Epoch: 6| Step: 7
Training loss: 2.3003105368577965
Validation loss: 2.5083708063864885

Epoch: 6| Step: 8
Training loss: 2.383690644091837
Validation loss: 2.5024432845890208

Epoch: 6| Step: 9
Training loss: 1.7722440896965506
Validation loss: 2.497165557979984

Epoch: 6| Step: 10
Training loss: 3.067035352962734
Validation loss: 2.4790256039933807

Epoch: 6| Step: 11
Training loss: 2.333713046467357
Validation loss: 2.517891927578723

Epoch: 6| Step: 12
Training loss: 1.844720681919723
Validation loss: 2.5006213836193094

Epoch: 6| Step: 13
Training loss: 2.0880145186946235
Validation loss: 2.503756718463358

Epoch: 256| Step: 0
Training loss: 2.7880511333477846
Validation loss: 2.48077965169429

Epoch: 6| Step: 1
Training loss: 2.499578821943684
Validation loss: 2.4962147266420285

Epoch: 6| Step: 2
Training loss: 3.231469955188979
Validation loss: 2.4743759819993008

Epoch: 6| Step: 3
Training loss: 1.938865795501981
Validation loss: 2.4695625198632594

Epoch: 6| Step: 4
Training loss: 2.7160833149801524
Validation loss: 2.505352005313745

Epoch: 6| Step: 5
Training loss: 1.776252965206541
Validation loss: 2.5213150485196714

Epoch: 6| Step: 6
Training loss: 2.5859375
Validation loss: 2.4919074059904456

Epoch: 6| Step: 7
Training loss: 2.0179987687711107
Validation loss: 2.467596431250526

Epoch: 6| Step: 8
Training loss: 2.1105642851415563
Validation loss: 2.477462710014065

Epoch: 6| Step: 9
Training loss: 2.0867154960078524
Validation loss: 2.477950456429576

Epoch: 6| Step: 10
Training loss: 1.96666946680333
Validation loss: 2.4958098665108954

Epoch: 6| Step: 11
Training loss: 2.2136807626142283
Validation loss: 2.4890997278751517

Epoch: 6| Step: 12
Training loss: 2.5304627312744397
Validation loss: 2.5104651419411352

Epoch: 6| Step: 13
Training loss: 2.3593640864037737
Validation loss: 2.4914008983641187

Epoch: 257| Step: 0
Training loss: 2.2937750625280557
Validation loss: 2.5053165115585285

Epoch: 6| Step: 1
Training loss: 2.437365014666798
Validation loss: 2.4649685816905116

Epoch: 6| Step: 2
Training loss: 2.0254875020150314
Validation loss: 2.4821919256565157

Epoch: 6| Step: 3
Training loss: 2.226635419755777
Validation loss: 2.4734586042375852

Epoch: 6| Step: 4
Training loss: 2.1546581861066265
Validation loss: 2.488386359589562

Epoch: 6| Step: 5
Training loss: 3.0006258629589273
Validation loss: 2.484742507690198

Epoch: 6| Step: 6
Training loss: 2.427092414369635
Validation loss: 2.476314241483808

Epoch: 6| Step: 7
Training loss: 2.1261881704159786
Validation loss: 2.4952227221594754

Epoch: 6| Step: 8
Training loss: 2.3657081942121168
Validation loss: 2.5164292378009523

Epoch: 6| Step: 9
Training loss: 2.6396055341558227
Validation loss: 2.504945218055814

Epoch: 6| Step: 10
Training loss: 2.5767733643200628
Validation loss: 2.4955229695170016

Epoch: 6| Step: 11
Training loss: 2.1920543671012442
Validation loss: 2.51790644408779

Epoch: 6| Step: 12
Training loss: 2.088967169767095
Validation loss: 2.5094618946011065

Epoch: 6| Step: 13
Training loss: 2.179524733506102
Validation loss: 2.4990978674447573

Epoch: 258| Step: 0
Training loss: 1.8898385674293992
Validation loss: 2.514552632844577

Epoch: 6| Step: 1
Training loss: 2.8459708795404746
Validation loss: 2.5052323110720356

Epoch: 6| Step: 2
Training loss: 1.9269946378624374
Validation loss: 2.470609119369298

Epoch: 6| Step: 3
Training loss: 2.1702800355574525
Validation loss: 2.4719379118195715

Epoch: 6| Step: 4
Training loss: 2.3597575502805275
Validation loss: 2.474847217881141

Epoch: 6| Step: 5
Training loss: 2.9540542674416517
Validation loss: 2.4521281407167725

Epoch: 6| Step: 6
Training loss: 2.132503501111071
Validation loss: 2.493602508238612

Epoch: 6| Step: 7
Training loss: 3.336103305671646
Validation loss: 2.5111964515894556

Epoch: 6| Step: 8
Training loss: 2.208945303519956
Validation loss: 2.5069527849217286

Epoch: 6| Step: 9
Training loss: 2.3624104558535692
Validation loss: 2.495473456442993

Epoch: 6| Step: 10
Training loss: 1.9689661543123063
Validation loss: 2.4845234630553255

Epoch: 6| Step: 11
Training loss: 1.7593245043377046
Validation loss: 2.4784186532444403

Epoch: 6| Step: 12
Training loss: 2.2065498299607036
Validation loss: 2.4715018936503843

Epoch: 6| Step: 13
Training loss: 2.444433182150973
Validation loss: 2.4732846801530286

Epoch: 259| Step: 0
Training loss: 3.3478971058610965
Validation loss: 2.4772677313029767

Epoch: 6| Step: 1
Training loss: 2.5040289838350485
Validation loss: 2.4799658243111624

Epoch: 6| Step: 2
Training loss: 2.6644111472283343
Validation loss: 2.5168763201798274

Epoch: 6| Step: 3
Training loss: 2.0517804717855745
Validation loss: 2.483917662718728

Epoch: 6| Step: 4
Training loss: 2.2904338179217896
Validation loss: 2.5155014459199876

Epoch: 6| Step: 5
Training loss: 2.0015417355510805
Validation loss: 2.485929559349089

Epoch: 6| Step: 6
Training loss: 2.1583559008072695
Validation loss: 2.512761211719173

Epoch: 6| Step: 7
Training loss: 2.208542891821911
Validation loss: 2.484368941674456

Epoch: 6| Step: 8
Training loss: 2.3074913426461037
Validation loss: 2.473553697086424

Epoch: 6| Step: 9
Training loss: 1.8919788273882778
Validation loss: 2.501637097111442

Epoch: 6| Step: 10
Training loss: 2.05871535345593
Validation loss: 2.5119868080140115

Epoch: 6| Step: 11
Training loss: 3.0403383219835227
Validation loss: 2.5062560560048786

Epoch: 6| Step: 12
Training loss: 1.4822414926743857
Validation loss: 2.5100389850992753

Epoch: 6| Step: 13
Training loss: 2.227362345200077
Validation loss: 2.481884636440225

Epoch: 260| Step: 0
Training loss: 2.431672490535435
Validation loss: 2.5130277777772507

Epoch: 6| Step: 1
Training loss: 2.715153386962491
Validation loss: 2.4922755058664263

Epoch: 6| Step: 2
Training loss: 1.987798486044603
Validation loss: 2.51015108855325

Epoch: 6| Step: 3
Training loss: 2.134283990441635
Validation loss: 2.514841898313942

Epoch: 6| Step: 4
Training loss: 2.2554650164296794
Validation loss: 2.5001891259468874

Epoch: 6| Step: 5
Training loss: 2.399905969844031
Validation loss: 2.4869929274569333

Epoch: 6| Step: 6
Training loss: 1.7309372657325313
Validation loss: 2.495980530899445

Epoch: 6| Step: 7
Training loss: 2.6601703212102605
Validation loss: 2.484950769662695

Epoch: 6| Step: 8
Training loss: 2.23582016952266
Validation loss: 2.485937902231477

Epoch: 6| Step: 9
Training loss: 2.7332583517939475
Validation loss: 2.489401997917153

Epoch: 6| Step: 10
Training loss: 2.6727750277337137
Validation loss: 2.4620407774838178

Epoch: 6| Step: 11
Training loss: 2.531939753992318
Validation loss: 2.5344191896327253

Epoch: 6| Step: 12
Training loss: 2.457849702838472
Validation loss: 2.45679697284421

Epoch: 6| Step: 13
Training loss: 0.7462936053802944
Validation loss: 2.479888124071159

Epoch: 261| Step: 0
Training loss: 2.3922666012114897
Validation loss: 2.476075559029657

Epoch: 6| Step: 1
Training loss: 2.339426656239844
Validation loss: 2.499042123415023

Epoch: 6| Step: 2
Training loss: 2.1742440894209834
Validation loss: 2.49503387324276

Epoch: 6| Step: 3
Training loss: 2.2241938255636664
Validation loss: 2.5095506472197124

Epoch: 6| Step: 4
Training loss: 2.6205635728466987
Validation loss: 2.5133926227944774

Epoch: 6| Step: 5
Training loss: 2.397152634199155
Validation loss: 2.5177141351706083

Epoch: 6| Step: 6
Training loss: 1.9205677579821254
Validation loss: 2.4887141301630824

Epoch: 6| Step: 7
Training loss: 2.2374005940268846
Validation loss: 2.5092133054865284

Epoch: 6| Step: 8
Training loss: 2.406166471542573
Validation loss: 2.510543291747265

Epoch: 6| Step: 9
Training loss: 2.147314603572068
Validation loss: 2.497396435219409

Epoch: 6| Step: 10
Training loss: 2.285804904265403
Validation loss: 2.4968007834424255

Epoch: 6| Step: 11
Training loss: 2.405937273585642
Validation loss: 2.501503041369549

Epoch: 6| Step: 12
Training loss: 2.824820848708998
Validation loss: 2.5238551241864675

Epoch: 6| Step: 13
Training loss: 2.1568111850403224
Validation loss: 2.4910982533964847

Epoch: 262| Step: 0
Training loss: 2.7597189735308576
Validation loss: 2.4866019440225737

Epoch: 6| Step: 1
Training loss: 1.9057614059897579
Validation loss: 2.491079923661282

Epoch: 6| Step: 2
Training loss: 2.288561352758133
Validation loss: 2.4899559258773647

Epoch: 6| Step: 3
Training loss: 2.1168325204024985
Validation loss: 2.484880577172952

Epoch: 6| Step: 4
Training loss: 2.371746042638521
Validation loss: 2.4850193900171

Epoch: 6| Step: 5
Training loss: 2.421841135095896
Validation loss: 2.4907930376516645

Epoch: 6| Step: 6
Training loss: 2.265864602935098
Validation loss: 2.4861581452319266

Epoch: 6| Step: 7
Training loss: 2.1195582105846116
Validation loss: 2.5003179399272115

Epoch: 6| Step: 8
Training loss: 2.242280964780799
Validation loss: 2.4896775032762215

Epoch: 6| Step: 9
Training loss: 1.656227687469473
Validation loss: 2.463455301357146

Epoch: 6| Step: 10
Training loss: 2.388858516509895
Validation loss: 2.5233668531391205

Epoch: 6| Step: 11
Training loss: 2.628141521533468
Validation loss: 2.5151120167711327

Epoch: 6| Step: 12
Training loss: 3.278727697310399
Validation loss: 2.5118682566257298

Epoch: 6| Step: 13
Training loss: 1.6419714352705361
Validation loss: 2.504606914152099

Epoch: 263| Step: 0
Training loss: 2.249884920356193
Validation loss: 2.493197514915955

Epoch: 6| Step: 1
Training loss: 2.1148538150273053
Validation loss: 2.505391570590758

Epoch: 6| Step: 2
Training loss: 1.851059213475353
Validation loss: 2.5081866306034506

Epoch: 6| Step: 3
Training loss: 2.309252236785086
Validation loss: 2.4825641561647167

Epoch: 6| Step: 4
Training loss: 2.5269003336143885
Validation loss: 2.4984417222237374

Epoch: 6| Step: 5
Training loss: 2.967214086653532
Validation loss: 2.526176826726933

Epoch: 6| Step: 6
Training loss: 2.136969012959105
Validation loss: 2.502435688243369

Epoch: 6| Step: 7
Training loss: 2.185337632759028
Validation loss: 2.477168743338682

Epoch: 6| Step: 8
Training loss: 2.254034875012682
Validation loss: 2.4996377200488324

Epoch: 6| Step: 9
Training loss: 2.596732022495828
Validation loss: 2.4948818113345643

Epoch: 6| Step: 10
Training loss: 2.495938530574618
Validation loss: 2.4696866127043466

Epoch: 6| Step: 11
Training loss: 2.0093520381202854
Validation loss: 2.4924613983943282

Epoch: 6| Step: 12
Training loss: 2.5502717004276616
Validation loss: 2.4747624059603224

Epoch: 6| Step: 13
Training loss: 2.4818541975453625
Validation loss: 2.5089697930341908

Epoch: 264| Step: 0
Training loss: 2.0524283052995482
Validation loss: 2.465444938965642

Epoch: 6| Step: 1
Training loss: 3.1276924741264955
Validation loss: 2.5171691297046657

Epoch: 6| Step: 2
Training loss: 2.493278623310486
Validation loss: 2.5016288414283694

Epoch: 6| Step: 3
Training loss: 2.4167785180176042
Validation loss: 2.516218857861705

Epoch: 6| Step: 4
Training loss: 2.0496847654668424
Validation loss: 2.517969354102157

Epoch: 6| Step: 5
Training loss: 2.589438290164362
Validation loss: 2.5040920464372785

Epoch: 6| Step: 6
Training loss: 1.9073219412194877
Validation loss: 2.500961804727505

Epoch: 6| Step: 7
Training loss: 1.7014670044835403
Validation loss: 2.484281710880684

Epoch: 6| Step: 8
Training loss: 2.2841283328451056
Validation loss: 2.5046770092957096

Epoch: 6| Step: 9
Training loss: 2.339237089910144
Validation loss: 2.4971179777863317

Epoch: 6| Step: 10
Training loss: 3.2678209432343466
Validation loss: 2.4811123597642557

Epoch: 6| Step: 11
Training loss: 2.4151364995950075
Validation loss: 2.482507637612869

Epoch: 6| Step: 12
Training loss: 1.5999753950134474
Validation loss: 2.51454172597922

Epoch: 6| Step: 13
Training loss: 1.4605642239646428
Validation loss: 2.505046231809701

Epoch: 265| Step: 0
Training loss: 2.290771887676647
Validation loss: 2.489303363743138

Epoch: 6| Step: 1
Training loss: 2.0216454778044657
Validation loss: 2.4882629489674812

Epoch: 6| Step: 2
Training loss: 2.2151365271658485
Validation loss: 2.4953536438269803

Epoch: 6| Step: 3
Training loss: 2.7145824718303198
Validation loss: 2.4965546236883367

Epoch: 6| Step: 4
Training loss: 2.123195779837329
Validation loss: 2.4690909523429347

Epoch: 6| Step: 5
Training loss: 1.8591343058743908
Validation loss: 2.4881880887910697

Epoch: 6| Step: 6
Training loss: 2.432864059852487
Validation loss: 2.493597596547531

Epoch: 6| Step: 7
Training loss: 2.6651741460474523
Validation loss: 2.5112530268199955

Epoch: 6| Step: 8
Training loss: 3.1603714123484377
Validation loss: 2.50911336372657

Epoch: 6| Step: 9
Training loss: 1.8915136471446867
Validation loss: 2.508105611297958

Epoch: 6| Step: 10
Training loss: 2.41504794750438
Validation loss: 2.5032014549662165

Epoch: 6| Step: 11
Training loss: 1.8486315227973578
Validation loss: 2.5159949217500417

Epoch: 6| Step: 12
Training loss: 2.297532694587072
Validation loss: 2.477907667856237

Epoch: 6| Step: 13
Training loss: 2.303442770828098
Validation loss: 2.4933871938526275

Epoch: 266| Step: 0
Training loss: 2.832313260473944
Validation loss: 2.494734245251064

Epoch: 6| Step: 1
Training loss: 2.2470671294387494
Validation loss: 2.470550221352684

Epoch: 6| Step: 2
Training loss: 2.4366046532681755
Validation loss: 2.47195060223059

Epoch: 6| Step: 3
Training loss: 1.8211591986208102
Validation loss: 2.5021262801929116

Epoch: 6| Step: 4
Training loss: 2.179458223268493
Validation loss: 2.4913048706413528

Epoch: 6| Step: 5
Training loss: 2.361760935152674
Validation loss: 2.4986161729465395

Epoch: 6| Step: 6
Training loss: 1.9056291663605063
Validation loss: 2.5000515163405117

Epoch: 6| Step: 7
Training loss: 2.257474141358294
Validation loss: 2.5113377583967087

Epoch: 6| Step: 8
Training loss: 2.6660989713391334
Validation loss: 2.515297407433637

Epoch: 6| Step: 9
Training loss: 2.606271691540802
Validation loss: 2.4923331257063266

Epoch: 6| Step: 10
Training loss: 2.4779910230558664
Validation loss: 2.4975934381856755

Epoch: 6| Step: 11
Training loss: 2.3473477025948757
Validation loss: 2.5025427162198155

Epoch: 6| Step: 12
Training loss: 2.061984951560075
Validation loss: 2.502202622381018

Epoch: 6| Step: 13
Training loss: 2.372215445590955
Validation loss: 2.493508746986171

Epoch: 267| Step: 0
Training loss: 2.511769817776437
Validation loss: 2.4907607170355677

Epoch: 6| Step: 1
Training loss: 2.296882992685126
Validation loss: 2.4790366929700367

Epoch: 6| Step: 2
Training loss: 1.959082527782388
Validation loss: 2.4961797227717755

Epoch: 6| Step: 3
Training loss: 2.2847968968250134
Validation loss: 2.5056872006227864

Epoch: 6| Step: 4
Training loss: 2.389999008497727
Validation loss: 2.5008772162148736

Epoch: 6| Step: 5
Training loss: 2.6693754941689316
Validation loss: 2.5258239110964698

Epoch: 6| Step: 6
Training loss: 2.630345578279694
Validation loss: 2.4904068621246855

Epoch: 6| Step: 7
Training loss: 2.2547863807065247
Validation loss: 2.4894815267008163

Epoch: 6| Step: 8
Training loss: 2.4314809968940403
Validation loss: 2.524374717170466

Epoch: 6| Step: 9
Training loss: 2.074572516839195
Validation loss: 2.5172007680220556

Epoch: 6| Step: 10
Training loss: 2.3545902062498425
Validation loss: 2.5043504946803172

Epoch: 6| Step: 11
Training loss: 2.2475991685690957
Validation loss: 2.5037355237907484

Epoch: 6| Step: 12
Training loss: 2.0832172615777615
Validation loss: 2.4949818592446538

Epoch: 6| Step: 13
Training loss: 2.2445728758879984
Validation loss: 2.5200679511720483

Epoch: 268| Step: 0
Training loss: 2.127245445936096
Validation loss: 2.495722462416401

Epoch: 6| Step: 1
Training loss: 2.427783182993133
Validation loss: 2.484561077611875

Epoch: 6| Step: 2
Training loss: 2.516919957818715
Validation loss: 2.4936783603811765

Epoch: 6| Step: 3
Training loss: 1.8352087644271295
Validation loss: 2.492302461602744

Epoch: 6| Step: 4
Training loss: 2.2252530714836047
Validation loss: 2.494915386630089

Epoch: 6| Step: 5
Training loss: 2.6619781663315956
Validation loss: 2.5092608371664356

Epoch: 6| Step: 6
Training loss: 2.4481561962922407
Validation loss: 2.4986563291586132

Epoch: 6| Step: 7
Training loss: 2.0672374993215157
Validation loss: 2.514211159652379

Epoch: 6| Step: 8
Training loss: 2.0432625845546424
Validation loss: 2.4995127264573846

Epoch: 6| Step: 9
Training loss: 2.147826950710642
Validation loss: 2.482237011675357

Epoch: 6| Step: 10
Training loss: 2.8253786019009186
Validation loss: 2.4850970185385766

Epoch: 6| Step: 11
Training loss: 2.1924663298401894
Validation loss: 2.511394281955795

Epoch: 6| Step: 12
Training loss: 2.5997841745443844
Validation loss: 2.48846585077774

Epoch: 6| Step: 13
Training loss: 2.4044403603547098
Validation loss: 2.4875983787404876

Epoch: 269| Step: 0
Training loss: 1.6656619699465498
Validation loss: 2.4999224055974354

Epoch: 6| Step: 1
Training loss: 2.943962293611461
Validation loss: 2.4856669834980134

Epoch: 6| Step: 2
Training loss: 1.4805950020375571
Validation loss: 2.5185000907424984

Epoch: 6| Step: 3
Training loss: 2.4524926992574083
Validation loss: 2.4841624627137953

Epoch: 6| Step: 4
Training loss: 2.248276262155178
Validation loss: 2.522830619031197

Epoch: 6| Step: 5
Training loss: 1.3784277412589732
Validation loss: 2.519797784065792

Epoch: 6| Step: 6
Training loss: 2.2581218784710857
Validation loss: 2.527445882998874

Epoch: 6| Step: 7
Training loss: 2.6200493040614505
Validation loss: 2.502154170773483

Epoch: 6| Step: 8
Training loss: 2.131957612909935
Validation loss: 2.476430769168133

Epoch: 6| Step: 9
Training loss: 2.790715430354771
Validation loss: 2.495142112600856

Epoch: 6| Step: 10
Training loss: 2.6795899843317184
Validation loss: 2.4759675215680446

Epoch: 6| Step: 11
Training loss: 2.388704812796722
Validation loss: 2.4862447162597334

Epoch: 6| Step: 12
Training loss: 2.9224761507678108
Validation loss: 2.486086553470384

Epoch: 6| Step: 13
Training loss: 1.7348298859542608
Validation loss: 2.484331186962961

Epoch: 270| Step: 0
Training loss: 2.400438300482607
Validation loss: 2.4904329903795728

Epoch: 6| Step: 1
Training loss: 2.2979816703098566
Validation loss: 2.4962266045125143

Epoch: 6| Step: 2
Training loss: 2.173636620818391
Validation loss: 2.4910398825334465

Epoch: 6| Step: 3
Training loss: 2.5001489594904367
Validation loss: 2.477219886906949

Epoch: 6| Step: 4
Training loss: 1.8017805723494735
Validation loss: 2.524147467435204

Epoch: 6| Step: 5
Training loss: 1.9201478718399385
Validation loss: 2.5015642000047715

Epoch: 6| Step: 6
Training loss: 2.3223545323734798
Validation loss: 2.490342818844026

Epoch: 6| Step: 7
Training loss: 2.135376000986332
Validation loss: 2.5144648280753445

Epoch: 6| Step: 8
Training loss: 2.7645690971262855
Validation loss: 2.510141678191778

Epoch: 6| Step: 9
Training loss: 2.2501735620314127
Validation loss: 2.4984499186637916

Epoch: 6| Step: 10
Training loss: 2.40836053412717
Validation loss: 2.5248746364244066

Epoch: 6| Step: 11
Training loss: 1.646682093865925
Validation loss: 2.50137429559298

Epoch: 6| Step: 12
Training loss: 2.5880148112891757
Validation loss: 2.512494420450613

Epoch: 6| Step: 13
Training loss: 3.3673114090002287
Validation loss: 2.4735494316960485

Epoch: 271| Step: 0
Training loss: 1.8085778649705682
Validation loss: 2.5203285227100336

Epoch: 6| Step: 1
Training loss: 1.3232102956834877
Validation loss: 2.489935340629092

Epoch: 6| Step: 2
Training loss: 3.1233890195731835
Validation loss: 2.4801584274612143

Epoch: 6| Step: 3
Training loss: 2.0574380428214183
Validation loss: 2.4958248057409675

Epoch: 6| Step: 4
Training loss: 2.2730467155680687
Validation loss: 2.509049147068144

Epoch: 6| Step: 5
Training loss: 2.792050596188623
Validation loss: 2.4976697644466004

Epoch: 6| Step: 6
Training loss: 2.1171481983999225
Validation loss: 2.4883980435389126

Epoch: 6| Step: 7
Training loss: 1.8328576410040387
Validation loss: 2.5037453355452333

Epoch: 6| Step: 8
Training loss: 2.4889606883652338
Validation loss: 2.48497805296701

Epoch: 6| Step: 9
Training loss: 2.2116148217838663
Validation loss: 2.486104319869798

Epoch: 6| Step: 10
Training loss: 2.370677226401727
Validation loss: 2.5230342891189896

Epoch: 6| Step: 11
Training loss: 1.978242725406665
Validation loss: 2.5047513725693342

Epoch: 6| Step: 12
Training loss: 2.8775999503586664
Validation loss: 2.4740796020699096

Epoch: 6| Step: 13
Training loss: 2.4195916025125435
Validation loss: 2.5054120426595734

Epoch: 272| Step: 0
Training loss: 2.434477178855636
Validation loss: 2.49354822053508

Epoch: 6| Step: 1
Training loss: 2.274976910484435
Validation loss: 2.480226566428065

Epoch: 6| Step: 2
Training loss: 2.269751218027174
Validation loss: 2.4680147323519037

Epoch: 6| Step: 3
Training loss: 2.1549072507649636
Validation loss: 2.495359231662532

Epoch: 6| Step: 4
Training loss: 2.748087911834899
Validation loss: 2.5396481831597075

Epoch: 6| Step: 5
Training loss: 2.2698841969532553
Validation loss: 2.52969681762673

Epoch: 6| Step: 6
Training loss: 1.7661507422977925
Validation loss: 2.4951809582321993

Epoch: 6| Step: 7
Training loss: 1.893471962438389
Validation loss: 2.507632880144614

Epoch: 6| Step: 8
Training loss: 2.416428378842813
Validation loss: 2.471505542800369

Epoch: 6| Step: 9
Training loss: 2.075475854198816
Validation loss: 2.524219111620727

Epoch: 6| Step: 10
Training loss: 2.726748134993974
Validation loss: 2.45976175171726

Epoch: 6| Step: 11
Training loss: 2.022998069856546
Validation loss: 2.490175893805849

Epoch: 6| Step: 12
Training loss: 2.1881762957777897
Validation loss: 2.4821071075201138

Epoch: 6| Step: 13
Training loss: 3.1640739534900724
Validation loss: 2.5195725970744105

Epoch: 273| Step: 0
Training loss: 2.873280550065511
Validation loss: 2.4992216129004046

Epoch: 6| Step: 1
Training loss: 2.3849877606283787
Validation loss: 2.507175705504337

Epoch: 6| Step: 2
Training loss: 2.778281352703551
Validation loss: 2.489175016887392

Epoch: 6| Step: 3
Training loss: 2.558990867023039
Validation loss: 2.4824430755680438

Epoch: 6| Step: 4
Training loss: 1.9171692838790517
Validation loss: 2.492095792306335

Epoch: 6| Step: 5
Training loss: 1.822749262797963
Validation loss: 2.474930356598439

Epoch: 6| Step: 6
Training loss: 2.5415271241284567
Validation loss: 2.5007607399809526

Epoch: 6| Step: 7
Training loss: 2.0377850385809477
Validation loss: 2.516999949364477

Epoch: 6| Step: 8
Training loss: 2.5543648518957394
Validation loss: 2.4882266834094695

Epoch: 6| Step: 9
Training loss: 1.8337311168652728
Validation loss: 2.4896460104901115

Epoch: 6| Step: 10
Training loss: 2.4173397792990423
Validation loss: 2.503951747720827

Epoch: 6| Step: 11
Training loss: 2.3228504416657834
Validation loss: 2.5054515977794716

Epoch: 6| Step: 12
Training loss: 1.9816759632342766
Validation loss: 2.490682717968946

Epoch: 6| Step: 13
Training loss: 1.546033534052715
Validation loss: 2.488305752134321

Epoch: 274| Step: 0
Training loss: 2.077170705025801
Validation loss: 2.5084053876957544

Epoch: 6| Step: 1
Training loss: 2.904679396988933
Validation loss: 2.515714804416376

Epoch: 6| Step: 2
Training loss: 2.1365085198509055
Validation loss: 2.479680007590453

Epoch: 6| Step: 3
Training loss: 2.755467182155733
Validation loss: 2.51507641713816

Epoch: 6| Step: 4
Training loss: 1.8765448881493296
Validation loss: 2.4904643270417255

Epoch: 6| Step: 5
Training loss: 2.7235171737003374
Validation loss: 2.494793988349926

Epoch: 6| Step: 6
Training loss: 2.172163690275453
Validation loss: 2.512787424314771

Epoch: 6| Step: 7
Training loss: 1.8468953475218557
Validation loss: 2.46658164444319

Epoch: 6| Step: 8
Training loss: 2.007598271797137
Validation loss: 2.506846742901411

Epoch: 6| Step: 9
Training loss: 2.173902045927011
Validation loss: 2.4730243288049314

Epoch: 6| Step: 10
Training loss: 1.9271896195527605
Validation loss: 2.4830432546376806

Epoch: 6| Step: 11
Training loss: 2.741524205859484
Validation loss: 2.5071397237430793

Epoch: 6| Step: 12
Training loss: 2.457836704413856
Validation loss: 2.5159620608131212

Epoch: 6| Step: 13
Training loss: 2.0152484630810266
Validation loss: 2.5057896843116128

Epoch: 275| Step: 0
Training loss: 1.9964546728341097
Validation loss: 2.5045287695007907

Epoch: 6| Step: 1
Training loss: 2.6210980251862956
Validation loss: 2.501064090999207

Epoch: 6| Step: 2
Training loss: 2.3713585895776643
Validation loss: 2.492654568465202

Epoch: 6| Step: 3
Training loss: 2.5215298554731085
Validation loss: 2.4719344307993527

Epoch: 6| Step: 4
Training loss: 2.1472062345400036
Validation loss: 2.5194108562063113

Epoch: 6| Step: 5
Training loss: 2.3362579636210996
Validation loss: 2.5238662366178195

Epoch: 6| Step: 6
Training loss: 2.8436866166313752
Validation loss: 2.5064700378481093

Epoch: 6| Step: 7
Training loss: 1.5045932538235356
Validation loss: 2.4947182472001863

Epoch: 6| Step: 8
Training loss: 2.073485508860996
Validation loss: 2.5108482579757467

Epoch: 6| Step: 9
Training loss: 2.5798844316015246
Validation loss: 2.505566186123457

Epoch: 6| Step: 10
Training loss: 2.44087650502703
Validation loss: 2.4825596852663114

Epoch: 6| Step: 11
Training loss: 1.8135386154905795
Validation loss: 2.4889894541638533

Epoch: 6| Step: 12
Training loss: 2.178953204327801
Validation loss: 2.476651853993452

Epoch: 6| Step: 13
Training loss: 2.3001499832013015
Validation loss: 2.4974133933598597

Epoch: 276| Step: 0
Training loss: 2.234422589842297
Validation loss: 2.526196779225488

Epoch: 6| Step: 1
Training loss: 1.961374302578596
Validation loss: 2.5076514927049156

Epoch: 6| Step: 2
Training loss: 2.6137852660271528
Validation loss: 2.4947408918931155

Epoch: 6| Step: 3
Training loss: 2.32726133571351
Validation loss: 2.519845096761129

Epoch: 6| Step: 4
Training loss: 2.261628091474261
Validation loss: 2.488870316192345

Epoch: 6| Step: 5
Training loss: 2.095147876118231
Validation loss: 2.500579334116232

Epoch: 6| Step: 6
Training loss: 2.090217913350895
Validation loss: 2.5125094482198516

Epoch: 6| Step: 7
Training loss: 2.8214442130236406
Validation loss: 2.519201048873441

Epoch: 6| Step: 8
Training loss: 1.971856890079867
Validation loss: 2.4867038482712

Epoch: 6| Step: 9
Training loss: 1.9468859089014572
Validation loss: 2.49173697756773

Epoch: 6| Step: 10
Training loss: 2.8876753320347817
Validation loss: 2.49829668757714

Epoch: 6| Step: 11
Training loss: 2.5875239274397526
Validation loss: 2.4731106111515495

Epoch: 6| Step: 12
Training loss: 1.9080966697211588
Validation loss: 2.4977599188289608

Epoch: 6| Step: 13
Training loss: 2.0380945941209307
Validation loss: 2.4822966631010597

Epoch: 277| Step: 0
Training loss: 2.447713532372622
Validation loss: 2.5068573396354137

Epoch: 6| Step: 1
Training loss: 2.1416945187233263
Validation loss: 2.482827037961107

Epoch: 6| Step: 2
Training loss: 2.307188584297604
Validation loss: 2.482201759051706

Epoch: 6| Step: 3
Training loss: 3.106007194623702
Validation loss: 2.494148664949524

Epoch: 6| Step: 4
Training loss: 2.0702141504499347
Validation loss: 2.4987194514330797

Epoch: 6| Step: 5
Training loss: 2.305339242625711
Validation loss: 2.522531934947189

Epoch: 6| Step: 6
Training loss: 1.7492359400761108
Validation loss: 2.476565064092191

Epoch: 6| Step: 7
Training loss: 1.9768905668945265
Validation loss: 2.4955442950624738

Epoch: 6| Step: 8
Training loss: 2.195278181031793
Validation loss: 2.490620561317012

Epoch: 6| Step: 9
Training loss: 2.068925270423552
Validation loss: 2.4989851255515645

Epoch: 6| Step: 10
Training loss: 1.703899172593731
Validation loss: 2.487967207337832

Epoch: 6| Step: 11
Training loss: 2.4302184086043144
Validation loss: 2.497177636137573

Epoch: 6| Step: 12
Training loss: 3.042525566451294
Validation loss: 2.474561718521513

Epoch: 6| Step: 13
Training loss: 2.224628773270616
Validation loss: 2.4881898073713984

Epoch: 278| Step: 0
Training loss: 2.0166523998586046
Validation loss: 2.511674933195751

Epoch: 6| Step: 1
Training loss: 1.8114368346044305
Validation loss: 2.5056901042605215

Epoch: 6| Step: 2
Training loss: 2.0652873538058287
Validation loss: 2.4979390478478947

Epoch: 6| Step: 3
Training loss: 2.655633473372683
Validation loss: 2.5325630982174188

Epoch: 6| Step: 4
Training loss: 2.395206623760842
Validation loss: 2.4993948378347475

Epoch: 6| Step: 5
Training loss: 3.043255969927363
Validation loss: 2.499556559027714

Epoch: 6| Step: 6
Training loss: 2.131679135967865
Validation loss: 2.5094097240224977

Epoch: 6| Step: 7
Training loss: 2.530199939833741
Validation loss: 2.5105164169845025

Epoch: 6| Step: 8
Training loss: 2.0841313804538406
Validation loss: 2.4901969861499795

Epoch: 6| Step: 9
Training loss: 1.6094198868797216
Validation loss: 2.495082372700213

Epoch: 6| Step: 10
Training loss: 2.5523244211932163
Validation loss: 2.4973753790436035

Epoch: 6| Step: 11
Training loss: 2.4581590256614145
Validation loss: 2.496924290574866

Epoch: 6| Step: 12
Training loss: 2.0875602439364975
Validation loss: 2.497809826885854

Epoch: 6| Step: 13
Training loss: 1.9184892185197544
Validation loss: 2.4840555850570816

Epoch: 279| Step: 0
Training loss: 2.507393775279727
Validation loss: 2.496888248356554

Epoch: 6| Step: 1
Training loss: 2.114744233522762
Validation loss: 2.4844743973566543

Epoch: 6| Step: 2
Training loss: 1.6936392547325119
Validation loss: 2.50521815040549

Epoch: 6| Step: 3
Training loss: 2.8507486932703516
Validation loss: 2.5017015819128834

Epoch: 6| Step: 4
Training loss: 2.7248494797878284
Validation loss: 2.498779950794391

Epoch: 6| Step: 5
Training loss: 2.535339630971077
Validation loss: 2.5133495746789665

Epoch: 6| Step: 6
Training loss: 2.060580892417664
Validation loss: 2.4966332489693497

Epoch: 6| Step: 7
Training loss: 2.1679837063110226
Validation loss: 2.5297065464221347

Epoch: 6| Step: 8
Training loss: 2.736183483976065
Validation loss: 2.4903225198901984

Epoch: 6| Step: 9
Training loss: 2.341272596096443
Validation loss: 2.512512043990551

Epoch: 6| Step: 10
Training loss: 2.1957764050549624
Validation loss: 2.4992451133097005

Epoch: 6| Step: 11
Training loss: 1.8919327681776112
Validation loss: 2.5336703820527275

Epoch: 6| Step: 12
Training loss: 2.4083056895991555
Validation loss: 2.4906303434216457

Epoch: 6| Step: 13
Training loss: 1.4352855210911288
Validation loss: 2.4918566580088704

Epoch: 280| Step: 0
Training loss: 2.159812527397556
Validation loss: 2.5160794151830257

Epoch: 6| Step: 1
Training loss: 2.0522897167956184
Validation loss: 2.529364183817627

Epoch: 6| Step: 2
Training loss: 2.4690416381093643
Validation loss: 2.5060934572345817

Epoch: 6| Step: 3
Training loss: 2.380754426265673
Validation loss: 2.4653553612869294

Epoch: 6| Step: 4
Training loss: 1.7077505311603527
Validation loss: 2.4955102248509236

Epoch: 6| Step: 5
Training loss: 2.308050876050081
Validation loss: 2.476379410536991

Epoch: 6| Step: 6
Training loss: 2.839596912093149
Validation loss: 2.4991711903904505

Epoch: 6| Step: 7
Training loss: 2.469296938029945
Validation loss: 2.500783323808059

Epoch: 6| Step: 8
Training loss: 2.2690041433862254
Validation loss: 2.4932097459688007

Epoch: 6| Step: 9
Training loss: 2.2703486167308533
Validation loss: 2.496951568307164

Epoch: 6| Step: 10
Training loss: 2.0565518235962856
Validation loss: 2.496790011573039

Epoch: 6| Step: 11
Training loss: 2.041786449837074
Validation loss: 2.4989690613592135

Epoch: 6| Step: 12
Training loss: 2.7768547389467346
Validation loss: 2.498627084689976

Epoch: 6| Step: 13
Training loss: 1.5977174332149366
Validation loss: 2.561402590849793

Epoch: 281| Step: 0
Training loss: 2.253636071260622
Validation loss: 2.4863272124807088

Epoch: 6| Step: 1
Training loss: 2.3760374714436523
Validation loss: 2.4689645794675807

Epoch: 6| Step: 2
Training loss: 2.654058562212607
Validation loss: 2.5015124063408836

Epoch: 6| Step: 3
Training loss: 2.5386418859844446
Validation loss: 2.4792882059330967

Epoch: 6| Step: 4
Training loss: 2.1659079714991165
Validation loss: 2.495598763288364

Epoch: 6| Step: 5
Training loss: 2.0096049935048015
Validation loss: 2.478612166828125

Epoch: 6| Step: 6
Training loss: 2.428260408649191
Validation loss: 2.511890325202696

Epoch: 6| Step: 7
Training loss: 2.289484915962523
Validation loss: 2.510461556570222

Epoch: 6| Step: 8
Training loss: 2.337518979571802
Validation loss: 2.482881703602299

Epoch: 6| Step: 9
Training loss: 2.2638359635712337
Validation loss: 2.48496536254347

Epoch: 6| Step: 10
Training loss: 2.352973995961576
Validation loss: 2.4849079778282857

Epoch: 6| Step: 11
Training loss: 2.2539916129781257
Validation loss: 2.5071604985210074

Epoch: 6| Step: 12
Training loss: 1.8233885090840665
Validation loss: 2.4796286635303497

Epoch: 6| Step: 13
Training loss: 2.655305851706575
Validation loss: 2.5054012382332447

Epoch: 282| Step: 0
Training loss: 2.129881693102067
Validation loss: 2.5066804996226395

Epoch: 6| Step: 1
Training loss: 2.43848379773406
Validation loss: 2.5021827193241646

Epoch: 6| Step: 2
Training loss: 2.1928010197589427
Validation loss: 2.4897180446062404

Epoch: 6| Step: 3
Training loss: 2.3842685940699324
Validation loss: 2.4948839877055944

Epoch: 6| Step: 4
Training loss: 2.370262641357213
Validation loss: 2.488343696894374

Epoch: 6| Step: 5
Training loss: 2.465532064680765
Validation loss: 2.485160730731093

Epoch: 6| Step: 6
Training loss: 2.511861129688277
Validation loss: 2.494523617269168

Epoch: 6| Step: 7
Training loss: 1.8944555523093973
Validation loss: 2.4996451566987306

Epoch: 6| Step: 8
Training loss: 2.1602352741818045
Validation loss: 2.527040350413472

Epoch: 6| Step: 9
Training loss: 2.630373948929326
Validation loss: 2.4907468147805405

Epoch: 6| Step: 10
Training loss: 2.1681782389284647
Validation loss: 2.493256950380847

Epoch: 6| Step: 11
Training loss: 2.1920576300458854
Validation loss: 2.4995206701517536

Epoch: 6| Step: 12
Training loss: 2.0301177170169935
Validation loss: 2.485529578618333

Epoch: 6| Step: 13
Training loss: 2.7807238649064216
Validation loss: 2.5365120152948912

Epoch: 283| Step: 0
Training loss: 2.777493200559903
Validation loss: 2.471569923790722

Epoch: 6| Step: 1
Training loss: 2.360739913135177
Validation loss: 2.470675977708302

Epoch: 6| Step: 2
Training loss: 2.8811101254750304
Validation loss: 2.5163007880834822

Epoch: 6| Step: 3
Training loss: 2.4446179070722627
Validation loss: 2.534088034601207

Epoch: 6| Step: 4
Training loss: 2.3093894452171067
Validation loss: 2.4957786247007716

Epoch: 6| Step: 5
Training loss: 2.719696406363336
Validation loss: 2.522636164173415

Epoch: 6| Step: 6
Training loss: 2.4504307815810313
Validation loss: 2.5016854132167636

Epoch: 6| Step: 7
Training loss: 1.891706425365222
Validation loss: 2.499949690609962

Epoch: 6| Step: 8
Training loss: 0.9640103961336516
Validation loss: 2.491896906173564

Epoch: 6| Step: 9
Training loss: 2.337852993999305
Validation loss: 2.5014643041633877

Epoch: 6| Step: 10
Training loss: 1.9589361791491555
Validation loss: 2.484484006059187

Epoch: 6| Step: 11
Training loss: 1.955688929916395
Validation loss: 2.5286351528512236

Epoch: 6| Step: 12
Training loss: 2.3979228209928345
Validation loss: 2.4901602515059404

Epoch: 6| Step: 13
Training loss: 2.072178183534516
Validation loss: 2.5192040839839542

Epoch: 284| Step: 0
Training loss: 1.8186135283455822
Validation loss: 2.5005978382196603

Epoch: 6| Step: 1
Training loss: 2.67193978214365
Validation loss: 2.4998354016744853

Epoch: 6| Step: 2
Training loss: 2.6141551200296336
Validation loss: 2.4693585184927382

Epoch: 6| Step: 3
Training loss: 2.03672732814889
Validation loss: 2.515568668318451

Epoch: 6| Step: 4
Training loss: 2.100720318371312
Validation loss: 2.491284904189568

Epoch: 6| Step: 5
Training loss: 2.1526547742042377
Validation loss: 2.5116492004568944

Epoch: 6| Step: 6
Training loss: 2.7996612820790587
Validation loss: 2.5159481857267934

Epoch: 6| Step: 7
Training loss: 2.0666977905678037
Validation loss: 2.4960562301512663

Epoch: 6| Step: 8
Training loss: 2.5086742596105456
Validation loss: 2.5208109060815467

Epoch: 6| Step: 9
Training loss: 2.544432047666125
Validation loss: 2.5018681345105946

Epoch: 6| Step: 10
Training loss: 2.543685788555587
Validation loss: 2.5151596199366977

Epoch: 6| Step: 11
Training loss: 1.6855126440433428
Validation loss: 2.5232338279140625

Epoch: 6| Step: 12
Training loss: 2.0503217491170362
Validation loss: 2.4979132895795058

Epoch: 6| Step: 13
Training loss: 1.8067500230813727
Validation loss: 2.4986952124959143

Epoch: 285| Step: 0
Training loss: 2.3240623100909543
Validation loss: 2.492288977342097

Epoch: 6| Step: 1
Training loss: 1.7842491733527197
Validation loss: 2.4584457562246222

Epoch: 6| Step: 2
Training loss: 2.2914495423080665
Validation loss: 2.4755848527409885

Epoch: 6| Step: 3
Training loss: 1.9908755900754023
Validation loss: 2.4771466324401934

Epoch: 6| Step: 4
Training loss: 2.1967024017730683
Validation loss: 2.5120825237677895

Epoch: 6| Step: 5
Training loss: 1.820132005117279
Validation loss: 2.481682163463054

Epoch: 6| Step: 6
Training loss: 2.19779637687038
Validation loss: 2.485033254678416

Epoch: 6| Step: 7
Training loss: 2.720131534032677
Validation loss: 2.5212143149338093

Epoch: 6| Step: 8
Training loss: 2.7014790192784326
Validation loss: 2.5025184303113055

Epoch: 6| Step: 9
Training loss: 2.1920777514305123
Validation loss: 2.527790707208014

Epoch: 6| Step: 10
Training loss: 2.7536291104732413
Validation loss: 2.498729582982637

Epoch: 6| Step: 11
Training loss: 2.4468091583162876
Validation loss: 2.5070731077049913

Epoch: 6| Step: 12
Training loss: 1.9381605068424579
Validation loss: 2.472902265355537

Epoch: 6| Step: 13
Training loss: 2.27199191247817
Validation loss: 2.5003074108338126

Epoch: 286| Step: 0
Training loss: 2.815004632244737
Validation loss: 2.487905176565855

Epoch: 6| Step: 1
Training loss: 2.4006554106017925
Validation loss: 2.5018723213926797

Epoch: 6| Step: 2
Training loss: 2.52078135623363
Validation loss: 2.471779817324755

Epoch: 6| Step: 3
Training loss: 2.542909683033767
Validation loss: 2.4910989058588866

Epoch: 6| Step: 4
Training loss: 2.3726120036210223
Validation loss: 2.5205065695879116

Epoch: 6| Step: 5
Training loss: 1.4798455449003705
Validation loss: 2.491437535484121

Epoch: 6| Step: 6
Training loss: 1.8749314613531154
Validation loss: 2.4997583887804016

Epoch: 6| Step: 7
Training loss: 2.5359430958233085
Validation loss: 2.509160688870375

Epoch: 6| Step: 8
Training loss: 2.436480773674572
Validation loss: 2.5379459472369823

Epoch: 6| Step: 9
Training loss: 2.0247132981404423
Validation loss: 2.49885302863873

Epoch: 6| Step: 10
Training loss: 2.34603526283553
Validation loss: 2.5040787014227543

Epoch: 6| Step: 11
Training loss: 2.4668190079977483
Validation loss: 2.5275384066237683

Epoch: 6| Step: 12
Training loss: 1.864664583904443
Validation loss: 2.472445018632335

Epoch: 6| Step: 13
Training loss: 1.9148905305972825
Validation loss: 2.5141083737806293

Epoch: 287| Step: 0
Training loss: 2.729437506440201
Validation loss: 2.4774476942070263

Epoch: 6| Step: 1
Training loss: 2.0444470631310834
Validation loss: 2.4809644438123275

Epoch: 6| Step: 2
Training loss: 1.7760909475460647
Validation loss: 2.4762873586203122

Epoch: 6| Step: 3
Training loss: 1.8374537922764809
Validation loss: 2.503840449974978

Epoch: 6| Step: 4
Training loss: 2.1996722930976524
Validation loss: 2.4736381281226847

Epoch: 6| Step: 5
Training loss: 2.0556693976326255
Validation loss: 2.4681823335352515

Epoch: 6| Step: 6
Training loss: 2.18047479883583
Validation loss: 2.491477100499088

Epoch: 6| Step: 7
Training loss: 3.045946967792287
Validation loss: 2.513244783850576

Epoch: 6| Step: 8
Training loss: 2.5863976198881025
Validation loss: 2.547324626024486

Epoch: 6| Step: 9
Training loss: 2.178884597621498
Validation loss: 2.4937116331869023

Epoch: 6| Step: 10
Training loss: 2.165743618973913
Validation loss: 2.4532378022971915

Epoch: 6| Step: 11
Training loss: 2.1659436364417877
Validation loss: 2.5150587203385006

Epoch: 6| Step: 12
Training loss: 2.5662644810182065
Validation loss: 2.490812273169875

Epoch: 6| Step: 13
Training loss: 2.610118097724665
Validation loss: 2.4837865407933344

Epoch: 288| Step: 0
Training loss: 2.1968735544300344
Validation loss: 2.469126763858036

Epoch: 6| Step: 1
Training loss: 1.978007455620827
Validation loss: 2.499867015295969

Epoch: 6| Step: 2
Training loss: 1.6835020531556015
Validation loss: 2.4935076864741994

Epoch: 6| Step: 3
Training loss: 2.9974414723642266
Validation loss: 2.4967140568181683

Epoch: 6| Step: 4
Training loss: 2.135424568968007
Validation loss: 2.5079899869713937

Epoch: 6| Step: 5
Training loss: 2.3904793888201636
Validation loss: 2.512036428314506

Epoch: 6| Step: 6
Training loss: 2.11014220802581
Validation loss: 2.4713388423046263

Epoch: 6| Step: 7
Training loss: 2.4725542333689434
Validation loss: 2.513998537269586

Epoch: 6| Step: 8
Training loss: 2.5374310225709427
Validation loss: 2.51081516427221

Epoch: 6| Step: 9
Training loss: 1.6333412154001021
Validation loss: 2.5006323517128277

Epoch: 6| Step: 10
Training loss: 2.421142073447846
Validation loss: 2.4944072801225423

Epoch: 6| Step: 11
Training loss: 1.8504252743995027
Validation loss: 2.4926861661976085

Epoch: 6| Step: 12
Training loss: 2.0785994597592214
Validation loss: 2.4931435690360417

Epoch: 6| Step: 13
Training loss: 2.602527886057146
Validation loss: 2.508939766529002

Epoch: 289| Step: 0
Training loss: 1.9303630928077917
Validation loss: 2.5031764564921186

Epoch: 6| Step: 1
Training loss: 2.372586881536061
Validation loss: 2.502535557602195

Epoch: 6| Step: 2
Training loss: 1.741705584053234
Validation loss: 2.486984476784877

Epoch: 6| Step: 3
Training loss: 2.0712170046547738
Validation loss: 2.5119000923461643

Epoch: 6| Step: 4
Training loss: 2.0458930768873684
Validation loss: 2.5174958076315463

Epoch: 6| Step: 5
Training loss: 2.3281964796729304
Validation loss: 2.482111459939932

Epoch: 6| Step: 6
Training loss: 2.2456200672395945
Validation loss: 2.4892973328599735

Epoch: 6| Step: 7
Training loss: 2.6366740809294975
Validation loss: 2.4921537387940047

Epoch: 6| Step: 8
Training loss: 2.9210943311316786
Validation loss: 2.512023203065829

Epoch: 6| Step: 9
Training loss: 2.234355579638614
Validation loss: 2.506836797556844

Epoch: 6| Step: 10
Training loss: 2.7537531816946412
Validation loss: 2.4881977727902624

Epoch: 6| Step: 11
Training loss: 1.536142900922451
Validation loss: 2.4842639046159984

Epoch: 6| Step: 12
Training loss: 1.9061404962824733
Validation loss: 2.4995283543315034

Epoch: 6| Step: 13
Training loss: 2.508741830490336
Validation loss: 2.5056302526289294

Epoch: 290| Step: 0
Training loss: 2.287249892272847
Validation loss: 2.484618114366467

Epoch: 6| Step: 1
Training loss: 2.94347245189644
Validation loss: 2.483026817834203

Epoch: 6| Step: 2
Training loss: 2.0332354892056723
Validation loss: 2.5272771400485783

Epoch: 6| Step: 3
Training loss: 2.2219228489870178
Validation loss: 2.4928577864255135

Epoch: 6| Step: 4
Training loss: 1.7960335793191597
Validation loss: 2.509579735791447

Epoch: 6| Step: 5
Training loss: 2.059138361716884
Validation loss: 2.509538871743107

Epoch: 6| Step: 6
Training loss: 1.7750545976865237
Validation loss: 2.522043299980302

Epoch: 6| Step: 7
Training loss: 1.8929917835151993
Validation loss: 2.4930594854588293

Epoch: 6| Step: 8
Training loss: 2.794430820877643
Validation loss: 2.5106441241748265

Epoch: 6| Step: 9
Training loss: 2.411100378857394
Validation loss: 2.516619222473983

Epoch: 6| Step: 10
Training loss: 3.016703358492049
Validation loss: 2.5128907437099883

Epoch: 6| Step: 11
Training loss: 1.8732897269896926
Validation loss: 2.4896659427185988

Epoch: 6| Step: 12
Training loss: 2.047843179972114
Validation loss: 2.496930076132041

Epoch: 6| Step: 13
Training loss: 1.9376308027844649
Validation loss: 2.4984268078763168

Epoch: 291| Step: 0
Training loss: 2.3239349961373645
Validation loss: 2.5032589241893266

Epoch: 6| Step: 1
Training loss: 2.166849593241073
Validation loss: 2.4966487983454018

Epoch: 6| Step: 2
Training loss: 1.8586774527393217
Validation loss: 2.482825967207538

Epoch: 6| Step: 3
Training loss: 1.6978486950458573
Validation loss: 2.474118267560997

Epoch: 6| Step: 4
Training loss: 2.774673143674717
Validation loss: 2.500967363631959

Epoch: 6| Step: 5
Training loss: 2.043290588819634
Validation loss: 2.490595026379226

Epoch: 6| Step: 6
Training loss: 2.598478304782868
Validation loss: 2.4919874175452015

Epoch: 6| Step: 7
Training loss: 2.5876245441041092
Validation loss: 2.4729195977661944

Epoch: 6| Step: 8
Training loss: 2.4559628539615703
Validation loss: 2.502098938484979

Epoch: 6| Step: 9
Training loss: 1.9108633905046746
Validation loss: 2.5096399427006695

Epoch: 6| Step: 10
Training loss: 1.6682470299459802
Validation loss: 2.458489139000124

Epoch: 6| Step: 11
Training loss: 2.9800837956878476
Validation loss: 2.5153301496529648

Epoch: 6| Step: 12
Training loss: 1.853379979209826
Validation loss: 2.501223145977807

Epoch: 6| Step: 13
Training loss: 2.176300479976119
Validation loss: 2.4857829799288482

Epoch: 292| Step: 0
Training loss: 1.9686205382393736
Validation loss: 2.4935615005902383

Epoch: 6| Step: 1
Training loss: 1.6057640973487446
Validation loss: 2.473349800503924

Epoch: 6| Step: 2
Training loss: 2.135977831043256
Validation loss: 2.4910942212985434

Epoch: 6| Step: 3
Training loss: 2.3743020086071973
Validation loss: 2.483785098879165

Epoch: 6| Step: 4
Training loss: 2.3597395659461653
Validation loss: 2.493379068165207

Epoch: 6| Step: 5
Training loss: 2.5526309820599824
Validation loss: 2.492365537534484

Epoch: 6| Step: 6
Training loss: 2.0521893417422166
Validation loss: 2.4856645030535915

Epoch: 6| Step: 7
Training loss: 2.514852654025671
Validation loss: 2.4997172513649715

Epoch: 6| Step: 8
Training loss: 2.444772679033459
Validation loss: 2.508444436734426

Epoch: 6| Step: 9
Training loss: 1.8545950348324287
Validation loss: 2.4848495136526068

Epoch: 6| Step: 10
Training loss: 2.4074039417089748
Validation loss: 2.504974678390853

Epoch: 6| Step: 11
Training loss: 2.8274033611050156
Validation loss: 2.50535816741188

Epoch: 6| Step: 12
Training loss: 2.1814804086620776
Validation loss: 2.4972362367015157

Epoch: 6| Step: 13
Training loss: 1.9099205823435106
Validation loss: 2.4843314903485583

Epoch: 293| Step: 0
Training loss: 2.098831160284191
Validation loss: 2.512064255300313

Epoch: 6| Step: 1
Training loss: 2.6991562125307893
Validation loss: 2.5215614258590375

Epoch: 6| Step: 2
Training loss: 2.4002404410401654
Validation loss: 2.4849729937245515

Epoch: 6| Step: 3
Training loss: 2.4220521923587373
Validation loss: 2.4871590966982833

Epoch: 6| Step: 4
Training loss: 2.335073457987825
Validation loss: 2.520539423148973

Epoch: 6| Step: 5
Training loss: 2.342478903367056
Validation loss: 2.484722821764215

Epoch: 6| Step: 6
Training loss: 2.2892589289520355
Validation loss: 2.48415473822706

Epoch: 6| Step: 7
Training loss: 2.481589813408767
Validation loss: 2.501629275938684

Epoch: 6| Step: 8
Training loss: 2.1371310043844116
Validation loss: 2.4797697242914483

Epoch: 6| Step: 9
Training loss: 1.6632855531306259
Validation loss: 2.509257775214661

Epoch: 6| Step: 10
Training loss: 1.869373143640615
Validation loss: 2.4968041728085497

Epoch: 6| Step: 11
Training loss: 2.385278245221908
Validation loss: 2.51340572965887

Epoch: 6| Step: 12
Training loss: 2.456024011985374
Validation loss: 2.5159295662739205

Epoch: 6| Step: 13
Training loss: 2.0389967867614063
Validation loss: 2.4849997000946744

Epoch: 294| Step: 0
Training loss: 1.7527380368334966
Validation loss: 2.4962288007646802

Epoch: 6| Step: 1
Training loss: 1.7464829934835036
Validation loss: 2.474849461592615

Epoch: 6| Step: 2
Training loss: 2.4395469482557903
Validation loss: 2.483955290577237

Epoch: 6| Step: 3
Training loss: 1.7717856894292712
Validation loss: 2.5025739934428746

Epoch: 6| Step: 4
Training loss: 2.426786205348239
Validation loss: 2.480445698023864

Epoch: 6| Step: 5
Training loss: 1.8801236402152752
Validation loss: 2.4849102227723856

Epoch: 6| Step: 6
Training loss: 3.188370380123233
Validation loss: 2.5213014189600487

Epoch: 6| Step: 7
Training loss: 2.4326045442954762
Validation loss: 2.46958828940041

Epoch: 6| Step: 8
Training loss: 2.176151264718244
Validation loss: 2.508149383134396

Epoch: 6| Step: 9
Training loss: 2.443369035221461
Validation loss: 2.4797787154255717

Epoch: 6| Step: 10
Training loss: 2.1053613978603734
Validation loss: 2.4953192525246224

Epoch: 6| Step: 11
Training loss: 2.2717757296485743
Validation loss: 2.4839707954670445

Epoch: 6| Step: 12
Training loss: 2.2454732286534536
Validation loss: 2.5120434185125395

Epoch: 6| Step: 13
Training loss: 2.0303920401114293
Validation loss: 2.4857695417775525

Epoch: 295| Step: 0
Training loss: 2.873438535506543
Validation loss: 2.5028549218442033

Epoch: 6| Step: 1
Training loss: 2.8517012888956073
Validation loss: 2.492566208288536

Epoch: 6| Step: 2
Training loss: 1.325545195210136
Validation loss: 2.530415632300332

Epoch: 6| Step: 3
Training loss: 2.240934546887217
Validation loss: 2.520837337524955

Epoch: 6| Step: 4
Training loss: 1.7620617179540075
Validation loss: 2.5220000396786673

Epoch: 6| Step: 5
Training loss: 2.4370545200264893
Validation loss: 2.5028738546852027

Epoch: 6| Step: 6
Training loss: 1.6669909002905838
Validation loss: 2.4918668683872562

Epoch: 6| Step: 7
Training loss: 2.803753625643763
Validation loss: 2.522641345034106

Epoch: 6| Step: 8
Training loss: 2.2459282590188456
Validation loss: 2.546488281781782

Epoch: 6| Step: 9
Training loss: 2.2941003765704675
Validation loss: 2.481276961304335

Epoch: 6| Step: 10
Training loss: 2.429403797525616
Validation loss: 2.498350699708888

Epoch: 6| Step: 11
Training loss: 1.717693767250658
Validation loss: 2.49832342391301

Epoch: 6| Step: 12
Training loss: 1.8535943451737116
Validation loss: 2.517315640338833

Epoch: 6| Step: 13
Training loss: 2.8150251285115755
Validation loss: 2.5297105757539415

Epoch: 296| Step: 0
Training loss: 3.0680799448074185
Validation loss: 2.493862843320346

Epoch: 6| Step: 1
Training loss: 2.034795278800705
Validation loss: 2.4903280268798778

Epoch: 6| Step: 2
Training loss: 2.268824665953199
Validation loss: 2.5084412399033935

Epoch: 6| Step: 3
Training loss: 1.8624429476403652
Validation loss: 2.4877967418787077

Epoch: 6| Step: 4
Training loss: 1.8903628080802626
Validation loss: 2.500609607615277

Epoch: 6| Step: 5
Training loss: 2.2830289410408016
Validation loss: 2.4952019928562934

Epoch: 6| Step: 6
Training loss: 1.6657749015530408
Validation loss: 2.4850649219783247

Epoch: 6| Step: 7
Training loss: 1.9725171937181054
Validation loss: 2.4958357892639027

Epoch: 6| Step: 8
Training loss: 1.8245780639967264
Validation loss: 2.497779493793809

Epoch: 6| Step: 9
Training loss: 2.4629184076979276
Validation loss: 2.5149214901030903

Epoch: 6| Step: 10
Training loss: 2.750680059095587
Validation loss: 2.493378104761058

Epoch: 6| Step: 11
Training loss: 2.3619208337435498
Validation loss: 2.48998083880915

Epoch: 6| Step: 12
Training loss: 2.485925538461657
Validation loss: 2.4938944247158994

Epoch: 6| Step: 13
Training loss: 2.158287191695572
Validation loss: 2.470497699657206

Epoch: 297| Step: 0
Training loss: 2.75390010319017
Validation loss: 2.4947556628304595

Epoch: 6| Step: 1
Training loss: 2.8503599374590025
Validation loss: 2.500936554250489

Epoch: 6| Step: 2
Training loss: 1.8267253506183674
Validation loss: 2.5134903320590554

Epoch: 6| Step: 3
Training loss: 2.472218262268019
Validation loss: 2.4971565493713705

Epoch: 6| Step: 4
Training loss: 2.2571518931458043
Validation loss: 2.4796765638021974

Epoch: 6| Step: 5
Training loss: 1.9499951729347933
Validation loss: 2.4772341522544767

Epoch: 6| Step: 6
Training loss: 2.3157451644792615
Validation loss: 2.4992361860523538

Epoch: 6| Step: 7
Training loss: 1.9648080750520014
Validation loss: 2.4923619996713207

Epoch: 6| Step: 8
Training loss: 2.555604729202344
Validation loss: 2.4938635772978177

Epoch: 6| Step: 9
Training loss: 1.6948228823415574
Validation loss: 2.443602060884396

Epoch: 6| Step: 10
Training loss: 1.8045046494895205
Validation loss: 2.4754989150165243

Epoch: 6| Step: 11
Training loss: 2.13367386077032
Validation loss: 2.4489624686952602

Epoch: 6| Step: 12
Training loss: 2.0609361904507426
Validation loss: 2.466858289240887

Epoch: 6| Step: 13
Training loss: 2.0956589835460786
Validation loss: 2.487156089481702

Epoch: 298| Step: 0
Training loss: 2.1068808043973415
Validation loss: 2.509239045837397

Epoch: 6| Step: 1
Training loss: 2.94493169371788
Validation loss: 2.4756999831484854

Epoch: 6| Step: 2
Training loss: 2.287514641720132
Validation loss: 2.493886234377086

Epoch: 6| Step: 3
Training loss: 1.8505907687725525
Validation loss: 2.4909374048800603

Epoch: 6| Step: 4
Training loss: 2.1705978260926044
Validation loss: 2.4743683357493937

Epoch: 6| Step: 5
Training loss: 1.6341230617673064
Validation loss: 2.49240987328686

Epoch: 6| Step: 6
Training loss: 2.686618039217235
Validation loss: 2.517829965605444

Epoch: 6| Step: 7
Training loss: 2.5211492503381208
Validation loss: 2.5034440927988064

Epoch: 6| Step: 8
Training loss: 2.091989260819188
Validation loss: 2.5306978645186344

Epoch: 6| Step: 9
Training loss: 2.1171710587317105
Validation loss: 2.5290321306881967

Epoch: 6| Step: 10
Training loss: 2.2113969413104817
Validation loss: 2.4931587967343987

Epoch: 6| Step: 11
Training loss: 1.8618032803636773
Validation loss: 2.505059070211225

Epoch: 6| Step: 12
Training loss: 2.2953554693449676
Validation loss: 2.4724978152052803

Epoch: 6| Step: 13
Training loss: 2.458424377910681
Validation loss: 2.5200210221171115

Epoch: 299| Step: 0
Training loss: 1.9762745523103866
Validation loss: 2.5012586850075924

Epoch: 6| Step: 1
Training loss: 1.6641611419239644
Validation loss: 2.4828759844325883

Epoch: 6| Step: 2
Training loss: 2.390701990820088
Validation loss: 2.4944474547589137

Epoch: 6| Step: 3
Training loss: 2.4843181867521205
Validation loss: 2.4974585351221315

Epoch: 6| Step: 4
Training loss: 2.5695619733811417
Validation loss: 2.4815822183119898

Epoch: 6| Step: 5
Training loss: 2.000335665191595
Validation loss: 2.462298493078553

Epoch: 6| Step: 6
Training loss: 1.9730927541500658
Validation loss: 2.5197454261163186

Epoch: 6| Step: 7
Training loss: 2.178436795525826
Validation loss: 2.5192119421810086

Epoch: 6| Step: 8
Training loss: 2.2485736988587273
Validation loss: 2.5294347685800647

Epoch: 6| Step: 9
Training loss: 2.100025394831107
Validation loss: 2.4986527104268315

Epoch: 6| Step: 10
Training loss: 2.871354985192317
Validation loss: 2.502165562979314

Epoch: 6| Step: 11
Training loss: 1.970716069975757
Validation loss: 2.4998538538556496

Epoch: 6| Step: 12
Training loss: 2.1673336714094344
Validation loss: 2.4891561013822585

Epoch: 6| Step: 13
Training loss: 2.0390679954951687
Validation loss: 2.4986914111936462

Epoch: 300| Step: 0
Training loss: 1.970440214708376
Validation loss: 2.464514696924468

Epoch: 6| Step: 1
Training loss: 1.9745095187180173
Validation loss: 2.5310336361944317

Epoch: 6| Step: 2
Training loss: 1.9528698563817188
Validation loss: 2.51834943354608

Epoch: 6| Step: 3
Training loss: 2.042346633513356
Validation loss: 2.4992025949477834

Epoch: 6| Step: 4
Training loss: 1.8320450446742111
Validation loss: 2.4931707935327463

Epoch: 6| Step: 5
Training loss: 2.640380757790827
Validation loss: 2.500451455320868

Epoch: 6| Step: 6
Training loss: 1.9029447322964492
Validation loss: 2.488741166191781

Epoch: 6| Step: 7
Training loss: 2.5296097138516926
Validation loss: 2.49285407751886

Epoch: 6| Step: 8
Training loss: 2.0389650986599714
Validation loss: 2.5182979128246004

Epoch: 6| Step: 9
Training loss: 2.5211770530061908
Validation loss: 2.506411162212972

Epoch: 6| Step: 10
Training loss: 2.7024378261419075
Validation loss: 2.524954931343677

Epoch: 6| Step: 11
Training loss: 2.4604840542067854
Validation loss: 2.50317039758392

Epoch: 6| Step: 12
Training loss: 2.2149290038155534
Validation loss: 2.5311036699992773

Epoch: 6| Step: 13
Training loss: 2.264652543354137
Validation loss: 2.5089259987259003

Epoch: 301| Step: 0
Training loss: 2.1940649431435353
Validation loss: 2.520974090139416

Epoch: 6| Step: 1
Training loss: 1.851937750925725
Validation loss: 2.507341367914512

Epoch: 6| Step: 2
Training loss: 2.4736744500295513
Validation loss: 2.514718051914127

Epoch: 6| Step: 3
Training loss: 2.6304398437942025
Validation loss: 2.489038650757586

Epoch: 6| Step: 4
Training loss: 2.038182562021354
Validation loss: 2.500161511321049

Epoch: 6| Step: 5
Training loss: 1.9912812808465994
Validation loss: 2.5186616839809166

Epoch: 6| Step: 6
Training loss: 2.3493390391551485
Validation loss: 2.4986095673940714

Epoch: 6| Step: 7
Training loss: 2.2643626938774246
Validation loss: 2.517174238303936

Epoch: 6| Step: 8
Training loss: 2.3393136317127485
Validation loss: 2.4990315797135825

Epoch: 6| Step: 9
Training loss: 1.8652102164256823
Validation loss: 2.535216495676522

Epoch: 6| Step: 10
Training loss: 2.36903968589716
Validation loss: 2.5202684470416785

Epoch: 6| Step: 11
Training loss: 1.5958294485790223
Validation loss: 2.4780029298258723

Epoch: 6| Step: 12
Training loss: 2.5400820519117757
Validation loss: 2.4981317122572575

Epoch: 6| Step: 13
Training loss: 2.414373383981913
Validation loss: 2.5168067817607414

Epoch: 302| Step: 0
Training loss: 1.8713121386284606
Validation loss: 2.4684184464311194

Epoch: 6| Step: 1
Training loss: 1.9355234708631686
Validation loss: 2.522900140789716

Epoch: 6| Step: 2
Training loss: 1.8496791741837442
Validation loss: 2.460776662575883

Epoch: 6| Step: 3
Training loss: 2.12340283677845
Validation loss: 2.512402999924572

Epoch: 6| Step: 4
Training loss: 2.606112147648878
Validation loss: 2.4939671589871226

Epoch: 6| Step: 5
Training loss: 1.974046092904989
Validation loss: 2.493254960241632

Epoch: 6| Step: 6
Training loss: 2.4938926483886616
Validation loss: 2.5037892225174123

Epoch: 6| Step: 7
Training loss: 2.4810636512866493
Validation loss: 2.5058627469984187

Epoch: 6| Step: 8
Training loss: 2.900108493222441
Validation loss: 2.5488328784607086

Epoch: 6| Step: 9
Training loss: 2.53552694799162
Validation loss: 2.5049985935501238

Epoch: 6| Step: 10
Training loss: 2.0316979721240216
Validation loss: 2.5316679242508

Epoch: 6| Step: 11
Training loss: 2.0779566875933475
Validation loss: 2.5137840836397576

Epoch: 6| Step: 12
Training loss: 1.7787827922615786
Validation loss: 2.5084138305892965

Epoch: 6| Step: 13
Training loss: 1.9877313779108083
Validation loss: 2.4956600676410443

Epoch: 303| Step: 0
Training loss: 2.1768636151524534
Validation loss: 2.5065454760516532

Epoch: 6| Step: 1
Training loss: 1.7744086207220835
Validation loss: 2.481150710042945

Epoch: 6| Step: 2
Training loss: 1.9477204276664979
Validation loss: 2.488930851016894

Epoch: 6| Step: 3
Training loss: 2.749260542894188
Validation loss: 2.5066337617533203

Epoch: 6| Step: 4
Training loss: 1.8540943074483767
Validation loss: 2.5295242975745538

Epoch: 6| Step: 5
Training loss: 2.0115058860379778
Validation loss: 2.5181077269819285

Epoch: 6| Step: 6
Training loss: 2.3212497244050536
Validation loss: 2.5148050272096603

Epoch: 6| Step: 7
Training loss: 2.7515517971647325
Validation loss: 2.5275523266129194

Epoch: 6| Step: 8
Training loss: 2.135333907841988
Validation loss: 2.4737018442316043

Epoch: 6| Step: 9
Training loss: 1.8244197497837165
Validation loss: 2.495125847457018

Epoch: 6| Step: 10
Training loss: 2.6649397583069816
Validation loss: 2.49480883552836

Epoch: 6| Step: 11
Training loss: 1.9040954170280482
Validation loss: 2.48455810284887

Epoch: 6| Step: 12
Training loss: 2.5040902056792427
Validation loss: 2.5072911536845726

Epoch: 6| Step: 13
Training loss: 1.9985393912771217
Validation loss: 2.4912697761745637

Epoch: 304| Step: 0
Training loss: 2.296624306212912
Validation loss: 2.487762480031929

Epoch: 6| Step: 1
Training loss: 2.6445774091244827
Validation loss: 2.502490008522747

Epoch: 6| Step: 2
Training loss: 1.9474571692442042
Validation loss: 2.5218368610137603

Epoch: 6| Step: 3
Training loss: 2.161818900923059
Validation loss: 2.4933786075408575

Epoch: 6| Step: 4
Training loss: 2.4875617551565976
Validation loss: 2.4969921373251758

Epoch: 6| Step: 5
Training loss: 1.9615461765039774
Validation loss: 2.4856797023117734

Epoch: 6| Step: 6
Training loss: 2.1072001230064594
Validation loss: 2.4894736817560266

Epoch: 6| Step: 7
Training loss: 1.9849366121716834
Validation loss: 2.531025778236861

Epoch: 6| Step: 8
Training loss: 2.2331039975211895
Validation loss: 2.516714825713029

Epoch: 6| Step: 9
Training loss: 2.7505327055567177
Validation loss: 2.493504688970399

Epoch: 6| Step: 10
Training loss: 1.6491942634734411
Validation loss: 2.5202779874301395

Epoch: 6| Step: 11
Training loss: 2.146088470796883
Validation loss: 2.4576648458855725

Epoch: 6| Step: 12
Training loss: 2.1137430811068896
Validation loss: 2.5158516388071845

Epoch: 6| Step: 13
Training loss: 2.513083459472383
Validation loss: 2.48463669090875

Epoch: 305| Step: 0
Training loss: 2.2633995965388127
Validation loss: 2.5306558685263405

Epoch: 6| Step: 1
Training loss: 2.4851548032687454
Validation loss: 2.552766322713153

Epoch: 6| Step: 2
Training loss: 2.763172678800341
Validation loss: 2.5059057518569943

Epoch: 6| Step: 3
Training loss: 2.0943797288987547
Validation loss: 2.488428494593416

Epoch: 6| Step: 4
Training loss: 2.108070591875616
Validation loss: 2.4952604405013443

Epoch: 6| Step: 5
Training loss: 2.4130985841686003
Validation loss: 2.4975799886493424

Epoch: 6| Step: 6
Training loss: 2.0733821352686816
Validation loss: 2.473789486436679

Epoch: 6| Step: 7
Training loss: 2.119036553284075
Validation loss: 2.4830888858138

Epoch: 6| Step: 8
Training loss: 2.2428081862891975
Validation loss: 2.5253013606040073

Epoch: 6| Step: 9
Training loss: 2.3416516892937276
Validation loss: 2.532040789361449

Epoch: 6| Step: 10
Training loss: 2.0542864389946938
Validation loss: 2.4661646190139668

Epoch: 6| Step: 11
Training loss: 1.9198627637454222
Validation loss: 2.509938478700083

Epoch: 6| Step: 12
Training loss: 1.905062696571599
Validation loss: 2.5156704824589817

Epoch: 6| Step: 13
Training loss: 1.7876339335382747
Validation loss: 2.5129301147986887

Epoch: 306| Step: 0
Training loss: 2.736997730737818
Validation loss: 2.5340847466974887

Epoch: 6| Step: 1
Training loss: 2.1350403492887016
Validation loss: 2.501352780949708

Epoch: 6| Step: 2
Training loss: 2.4517599790939304
Validation loss: 2.4809897890592025

Epoch: 6| Step: 3
Training loss: 2.3674006098636977
Validation loss: 2.504342762852184

Epoch: 6| Step: 4
Training loss: 2.2006571048473758
Validation loss: 2.507710876951261

Epoch: 6| Step: 5
Training loss: 1.7482849981840742
Validation loss: 2.507259095844549

Epoch: 6| Step: 6
Training loss: 1.6774872319152017
Validation loss: 2.46269309452455

Epoch: 6| Step: 7
Training loss: 2.5345936108247593
Validation loss: 2.5030691463055326

Epoch: 6| Step: 8
Training loss: 1.8962859846509166
Validation loss: 2.4957781614377152

Epoch: 6| Step: 9
Training loss: 1.2489527607025381
Validation loss: 2.5096253329176212

Epoch: 6| Step: 10
Training loss: 2.6224091777948138
Validation loss: 2.487923795542875

Epoch: 6| Step: 11
Training loss: 2.0031672671139127
Validation loss: 2.511846572628611

Epoch: 6| Step: 12
Training loss: 2.35926505331573
Validation loss: 2.4937683342063255

Epoch: 6| Step: 13
Training loss: 2.7650503649961924
Validation loss: 2.4906543222047324

Epoch: 307| Step: 0
Training loss: 2.784999591546568
Validation loss: 2.5096209035888846

Epoch: 6| Step: 1
Training loss: 3.1908040593311187
Validation loss: 2.501451941295225

Epoch: 6| Step: 2
Training loss: 2.026691192093742
Validation loss: 2.5058983235559777

Epoch: 6| Step: 3
Training loss: 2.229191990883795
Validation loss: 2.4835064118331855

Epoch: 6| Step: 4
Training loss: 1.5599473319577348
Validation loss: 2.506511422412651

Epoch: 6| Step: 5
Training loss: 1.5419620368430558
Validation loss: 2.4890657455740097

Epoch: 6| Step: 6
Training loss: 2.1686348656426597
Validation loss: 2.5254416335499017

Epoch: 6| Step: 7
Training loss: 2.3961252007101024
Validation loss: 2.549258808276825

Epoch: 6| Step: 8
Training loss: 2.1608425381551815
Validation loss: 2.531362006715927

Epoch: 6| Step: 9
Training loss: 2.1612329817499565
Validation loss: 2.52090000151551

Epoch: 6| Step: 10
Training loss: 2.042877720396687
Validation loss: 2.5333668273736607

Epoch: 6| Step: 11
Training loss: 2.3403956505898846
Validation loss: 2.487751752497942

Epoch: 6| Step: 12
Training loss: 1.6682030113504942
Validation loss: 2.49100154916915

Epoch: 6| Step: 13
Training loss: 1.9468279837477225
Validation loss: 2.521829295130199

Epoch: 308| Step: 0
Training loss: 2.084090997887469
Validation loss: 2.50893266294877

Epoch: 6| Step: 1
Training loss: 2.083474523210492
Validation loss: 2.510301319676049

Epoch: 6| Step: 2
Training loss: 2.6313234187595693
Validation loss: 2.504801097311711

Epoch: 6| Step: 3
Training loss: 1.9488531775134506
Validation loss: 2.499235437240395

Epoch: 6| Step: 4
Training loss: 1.9994506677569164
Validation loss: 2.5088269059172297

Epoch: 6| Step: 5
Training loss: 2.2928097619431207
Validation loss: 2.504325773322332

Epoch: 6| Step: 6
Training loss: 2.0924943033776624
Validation loss: 2.5309176898484465

Epoch: 6| Step: 7
Training loss: 2.1277755114236463
Validation loss: 2.4918135253986184

Epoch: 6| Step: 8
Training loss: 2.250742683755521
Validation loss: 2.4896195897699864

Epoch: 6| Step: 9
Training loss: 2.6736857207045417
Validation loss: 2.4588289347023404

Epoch: 6| Step: 10
Training loss: 1.9970715063413302
Validation loss: 2.5026318673626977

Epoch: 6| Step: 11
Training loss: 1.7606217379636273
Validation loss: 2.4962949164473214

Epoch: 6| Step: 12
Training loss: 2.368450268626571
Validation loss: 2.4951707382978334

Epoch: 6| Step: 13
Training loss: 2.223045918342627
Validation loss: 2.478951017107913

Epoch: 309| Step: 0
Training loss: 1.9870998267605584
Validation loss: 2.479564420442625

Epoch: 6| Step: 1
Training loss: 1.882009501191012
Validation loss: 2.521463091934977

Epoch: 6| Step: 2
Training loss: 2.577740634818699
Validation loss: 2.46938654713927

Epoch: 6| Step: 3
Training loss: 1.9238965327304751
Validation loss: 2.5365580838818977

Epoch: 6| Step: 4
Training loss: 2.6746244505608794
Validation loss: 2.501306479563458

Epoch: 6| Step: 5
Training loss: 1.9875044888619648
Validation loss: 2.5056052395068305

Epoch: 6| Step: 6
Training loss: 2.073889984685567
Validation loss: 2.516342269742688

Epoch: 6| Step: 7
Training loss: 2.2248997955046472
Validation loss: 2.524011600794246

Epoch: 6| Step: 8
Training loss: 1.9628056597943484
Validation loss: 2.4945827138613508

Epoch: 6| Step: 9
Training loss: 2.268386525864827
Validation loss: 2.528092112336729

Epoch: 6| Step: 10
Training loss: 2.423613680959928
Validation loss: 2.5169823796560147

Epoch: 6| Step: 11
Training loss: 1.9282600590470576
Validation loss: 2.5264809241238217

Epoch: 6| Step: 12
Training loss: 2.5775016262223214
Validation loss: 2.487482030499286

Epoch: 6| Step: 13
Training loss: 2.374017010095166
Validation loss: 2.4829199413702416

Epoch: 310| Step: 0
Training loss: 1.9377750693687756
Validation loss: 2.5439402072737094

Epoch: 6| Step: 1
Training loss: 1.8692669003681661
Validation loss: 2.5199427928753217

Epoch: 6| Step: 2
Training loss: 2.9008617699191928
Validation loss: 2.4969234928137567

Epoch: 6| Step: 3
Training loss: 2.2952474419999525
Validation loss: 2.496573541669155

Epoch: 6| Step: 4
Training loss: 2.0076893572022523
Validation loss: 2.5092792016469683

Epoch: 6| Step: 5
Training loss: 1.8387025829349948
Validation loss: 2.491377384674031

Epoch: 6| Step: 6
Training loss: 2.38983250865057
Validation loss: 2.505668680900683

Epoch: 6| Step: 7
Training loss: 2.0762087369214104
Validation loss: 2.4892996953695663

Epoch: 6| Step: 8
Training loss: 1.8973482248673992
Validation loss: 2.5138814972458157

Epoch: 6| Step: 9
Training loss: 1.987801184715734
Validation loss: 2.4648933104688138

Epoch: 6| Step: 10
Training loss: 2.7192268391890937
Validation loss: 2.474330305147817

Epoch: 6| Step: 11
Training loss: 2.2320550999420345
Validation loss: 2.5183184133319942

Epoch: 6| Step: 12
Training loss: 2.3126690776977696
Validation loss: 2.5162790679096263

Epoch: 6| Step: 13
Training loss: 2.4440005747143556
Validation loss: 2.508020605444055

Epoch: 311| Step: 0
Training loss: 2.1732605829914813
Validation loss: 2.526420705047141

Epoch: 6| Step: 1
Training loss: 1.8352230548675967
Validation loss: 2.4836947138583367

Epoch: 6| Step: 2
Training loss: 2.4318237725957683
Validation loss: 2.5093854248866667

Epoch: 6| Step: 3
Training loss: 1.6038633613036297
Validation loss: 2.4691668794892188

Epoch: 6| Step: 4
Training loss: 2.178851004714326
Validation loss: 2.5140139323319124

Epoch: 6| Step: 5
Training loss: 2.101015154384917
Validation loss: 2.5113209116371786

Epoch: 6| Step: 6
Training loss: 1.8836265481999068
Validation loss: 2.528937368673409

Epoch: 6| Step: 7
Training loss: 2.8854156567586697
Validation loss: 2.476503807752523

Epoch: 6| Step: 8
Training loss: 2.055772270199841
Validation loss: 2.478141746189752

Epoch: 6| Step: 9
Training loss: 2.0348030120584353
Validation loss: 2.4855303532193815

Epoch: 6| Step: 10
Training loss: 2.2364202355484766
Validation loss: 2.489414510221501

Epoch: 6| Step: 11
Training loss: 2.480775156395056
Validation loss: 2.4534779510211813

Epoch: 6| Step: 12
Training loss: 2.381018591823032
Validation loss: 2.4678572388781763

Epoch: 6| Step: 13
Training loss: 2.4635720335128504
Validation loss: 2.5121419073604714

Epoch: 312| Step: 0
Training loss: 2.5622554755426403
Validation loss: 2.5271425524828413

Epoch: 6| Step: 1
Training loss: 1.504876633717442
Validation loss: 2.454129071244276

Epoch: 6| Step: 2
Training loss: 2.4687942307771333
Validation loss: 2.511993430438183

Epoch: 6| Step: 3
Training loss: 2.604663547160879
Validation loss: 2.5086917853148716

Epoch: 6| Step: 4
Training loss: 2.211981105841019
Validation loss: 2.486233269663177

Epoch: 6| Step: 5
Training loss: 2.388903927078031
Validation loss: 2.526015803554937

Epoch: 6| Step: 6
Training loss: 1.9966428714325655
Validation loss: 2.513678496044398

Epoch: 6| Step: 7
Training loss: 2.278199861026465
Validation loss: 2.499215285908283

Epoch: 6| Step: 8
Training loss: 1.854022938447546
Validation loss: 2.5021097530726895

Epoch: 6| Step: 9
Training loss: 2.1722137406561113
Validation loss: 2.5025918353807746

Epoch: 6| Step: 10
Training loss: 2.2164013749271705
Validation loss: 2.47515781894216

Epoch: 6| Step: 11
Training loss: 2.6750470344472688
Validation loss: 2.49732754826227

Epoch: 6| Step: 12
Training loss: 1.764190698903545
Validation loss: 2.47511030974498

Epoch: 6| Step: 13
Training loss: 1.6471357946181837
Validation loss: 2.494533076784935

Epoch: 313| Step: 0
Training loss: 2.266609556750228
Validation loss: 2.5166856652840965

Epoch: 6| Step: 1
Training loss: 2.141687839368765
Validation loss: 2.475159200112204

Epoch: 6| Step: 2
Training loss: 2.342111548883992
Validation loss: 2.4963062501537836

Epoch: 6| Step: 3
Training loss: 1.6242458354091582
Validation loss: 2.4434682100272784

Epoch: 6| Step: 4
Training loss: 1.5849666536595937
Validation loss: 2.511754140526567

Epoch: 6| Step: 5
Training loss: 2.413314950497131
Validation loss: 2.5100760630726273

Epoch: 6| Step: 6
Training loss: 2.78130983438315
Validation loss: 2.5124312401867726

Epoch: 6| Step: 7
Training loss: 2.4405927355559323
Validation loss: 2.528287094628626

Epoch: 6| Step: 8
Training loss: 2.6240508770546147
Validation loss: 2.448765819535962

Epoch: 6| Step: 9
Training loss: 2.16661301570882
Validation loss: 2.5198182540576313

Epoch: 6| Step: 10
Training loss: 1.908089172646678
Validation loss: 2.486695106921815

Epoch: 6| Step: 11
Training loss: 1.9514414130488293
Validation loss: 2.5047307845605276

Epoch: 6| Step: 12
Training loss: 2.159065950970384
Validation loss: 2.4798669719577875

Epoch: 6| Step: 13
Training loss: 1.7295988148022665
Validation loss: 2.489521905428941

Epoch: 314| Step: 0
Training loss: 2.6701875232180172
Validation loss: 2.4761819994559477

Epoch: 6| Step: 1
Training loss: 2.6695033919589193
Validation loss: 2.5188561617067142

Epoch: 6| Step: 2
Training loss: 2.54671501172032
Validation loss: 2.520386753850278

Epoch: 6| Step: 3
Training loss: 2.5212914757255667
Validation loss: 2.518337062968311

Epoch: 6| Step: 4
Training loss: 1.7176780132010485
Validation loss: 2.514367741928532

Epoch: 6| Step: 5
Training loss: 2.1426392149235878
Validation loss: 2.4840977775227535

Epoch: 6| Step: 6
Training loss: 1.884896102895416
Validation loss: 2.506685404598946

Epoch: 6| Step: 7
Training loss: 2.0597903630149093
Validation loss: 2.523487753586611

Epoch: 6| Step: 8
Training loss: 2.2170351950639717
Validation loss: 2.4897485191589968

Epoch: 6| Step: 9
Training loss: 1.3446176965509302
Validation loss: 2.5367784306776184

Epoch: 6| Step: 10
Training loss: 2.0146657154342726
Validation loss: 2.5200649644060116

Epoch: 6| Step: 11
Training loss: 2.4123838446132946
Validation loss: 2.5041930280632214

Epoch: 6| Step: 12
Training loss: 2.178262990250168
Validation loss: 2.486238160328797

Epoch: 6| Step: 13
Training loss: 1.1789093482682738
Validation loss: 2.4900944403480283

Epoch: 315| Step: 0
Training loss: 2.4161933457333387
Validation loss: 2.4981949657999794

Epoch: 6| Step: 1
Training loss: 2.791182623125622
Validation loss: 2.510429290043968

Epoch: 6| Step: 2
Training loss: 2.138641106371135
Validation loss: 2.5051405590107265

Epoch: 6| Step: 3
Training loss: 1.9758435174279207
Validation loss: 2.477221048048975

Epoch: 6| Step: 4
Training loss: 2.1456262679947735
Validation loss: 2.5030187654552227

Epoch: 6| Step: 5
Training loss: 1.9241246028888088
Validation loss: 2.4879609712538016

Epoch: 6| Step: 6
Training loss: 2.267136063311029
Validation loss: 2.4768824485983174

Epoch: 6| Step: 7
Training loss: 2.2252162142508296
Validation loss: 2.526273535153199

Epoch: 6| Step: 8
Training loss: 1.7899877829108137
Validation loss: 2.495361320291361

Epoch: 6| Step: 9
Training loss: 1.8854872829076168
Validation loss: 2.5051913484796597

Epoch: 6| Step: 10
Training loss: 2.707121259946116
Validation loss: 2.5159111382498174

Epoch: 6| Step: 11
Training loss: 2.0290945501130153
Validation loss: 2.4883689597682266

Epoch: 6| Step: 12
Training loss: 2.108657941092039
Validation loss: 2.4930166950118875

Epoch: 6| Step: 13
Training loss: 1.6830193409298568
Validation loss: 2.4973508175580483

Epoch: 316| Step: 0
Training loss: 2.678146764606719
Validation loss: 2.4759097636739402

Epoch: 6| Step: 1
Training loss: 2.0945375014841083
Validation loss: 2.4681464636532633

Epoch: 6| Step: 2
Training loss: 1.968170080604449
Validation loss: 2.529207114960048

Epoch: 6| Step: 3
Training loss: 2.1120990259768186
Validation loss: 2.514346969602535

Epoch: 6| Step: 4
Training loss: 1.6586936342023968
Validation loss: 2.51437498003391

Epoch: 6| Step: 5
Training loss: 2.339391393988787
Validation loss: 2.501538998650986

Epoch: 6| Step: 6
Training loss: 2.031892880161904
Validation loss: 2.512218003867062

Epoch: 6| Step: 7
Training loss: 2.1556236352471037
Validation loss: 2.488627631646073

Epoch: 6| Step: 8
Training loss: 2.1201713902991814
Validation loss: 2.4881789281609104

Epoch: 6| Step: 9
Training loss: 2.1975624799471536
Validation loss: 2.4804368881105483

Epoch: 6| Step: 10
Training loss: 2.6443202781199497
Validation loss: 2.497777494428385

Epoch: 6| Step: 11
Training loss: 2.1778587408434826
Validation loss: 2.539198001498998

Epoch: 6| Step: 12
Training loss: 1.7549802894246194
Validation loss: 2.47785833561872

Epoch: 6| Step: 13
Training loss: 2.180827071934381
Validation loss: 2.5118538343288095

Epoch: 317| Step: 0
Training loss: 2.166061634782415
Validation loss: 2.5265500963348115

Epoch: 6| Step: 1
Training loss: 2.319608536611848
Validation loss: 2.532149964750146

Epoch: 6| Step: 2
Training loss: 1.790113914743637
Validation loss: 2.4577042995163736

Epoch: 6| Step: 3
Training loss: 1.5289122193950437
Validation loss: 2.510228442348587

Epoch: 6| Step: 4
Training loss: 2.0278432594537747
Validation loss: 2.4777358191523864

Epoch: 6| Step: 5
Training loss: 2.877704012190083
Validation loss: 2.51132278486604

Epoch: 6| Step: 6
Training loss: 2.2541330312686183
Validation loss: 2.506946585838586

Epoch: 6| Step: 7
Training loss: 1.859363139138739
Validation loss: 2.487817022798302

Epoch: 6| Step: 8
Training loss: 2.0413784160972015
Validation loss: 2.4963805433999506

Epoch: 6| Step: 9
Training loss: 1.8311624968261868
Validation loss: 2.50003888294787

Epoch: 6| Step: 10
Training loss: 2.2426387319529786
Validation loss: 2.5114866180799993

Epoch: 6| Step: 11
Training loss: 2.0753485697084755
Validation loss: 2.5010008244290365

Epoch: 6| Step: 12
Training loss: 2.6419381031290987
Validation loss: 2.5199694073876384

Epoch: 6| Step: 13
Training loss: 2.828058905909311
Validation loss: 2.4859479770754285

Epoch: 318| Step: 0
Training loss: 2.18156937061906
Validation loss: 2.5061042678832117

Epoch: 6| Step: 1
Training loss: 2.2349720403983366
Validation loss: 2.475131646478642

Epoch: 6| Step: 2
Training loss: 2.0996387852227976
Validation loss: 2.4950148685798212

Epoch: 6| Step: 3
Training loss: 1.2413402042861175
Validation loss: 2.5194189920590064

Epoch: 6| Step: 4
Training loss: 2.312434324414474
Validation loss: 2.4952861069768484

Epoch: 6| Step: 5
Training loss: 2.8154217273018753
Validation loss: 2.5075162750253503

Epoch: 6| Step: 6
Training loss: 1.9525060664826344
Validation loss: 2.510961357509923

Epoch: 6| Step: 7
Training loss: 1.8833674329298185
Validation loss: 2.5164210026307856

Epoch: 6| Step: 8
Training loss: 2.0895144764694713
Validation loss: 2.5282588834306776

Epoch: 6| Step: 9
Training loss: 1.869317726984783
Validation loss: 2.5177413831616415

Epoch: 6| Step: 10
Training loss: 2.7577879475049056
Validation loss: 2.522022254410951

Epoch: 6| Step: 11
Training loss: 1.7464012199575836
Validation loss: 2.5008302786530354

Epoch: 6| Step: 12
Training loss: 2.327384062767157
Validation loss: 2.510836424259834

Epoch: 6| Step: 13
Training loss: 2.5386176555928706
Validation loss: 2.485365842547754

Epoch: 319| Step: 0
Training loss: 1.9915464678875794
Validation loss: 2.500737250482845

Epoch: 6| Step: 1
Training loss: 1.7116423944586612
Validation loss: 2.5227256996970446

Epoch: 6| Step: 2
Training loss: 2.3145886860352665
Validation loss: 2.484773869689427

Epoch: 6| Step: 3
Training loss: 2.09842637911965
Validation loss: 2.4680763344195444

Epoch: 6| Step: 4
Training loss: 2.714564554691624
Validation loss: 2.4940187665344764

Epoch: 6| Step: 5
Training loss: 2.3230632057212475
Validation loss: 2.4916487813695842

Epoch: 6| Step: 6
Training loss: 1.9524865899987012
Validation loss: 2.5161438166644396

Epoch: 6| Step: 7
Training loss: 2.07141510014781
Validation loss: 2.4666230652948506

Epoch: 6| Step: 8
Training loss: 2.0567637349638392
Validation loss: 2.462358080926878

Epoch: 6| Step: 9
Training loss: 2.1985994215645346
Validation loss: 2.483627913861718

Epoch: 6| Step: 10
Training loss: 2.0023861002824836
Validation loss: 2.4768292931725115

Epoch: 6| Step: 11
Training loss: 2.2933855603983817
Validation loss: 2.48428789428392

Epoch: 6| Step: 12
Training loss: 2.249963654118603
Validation loss: 2.5248811270641642

Epoch: 6| Step: 13
Training loss: 2.4914094194623537
Validation loss: 2.49425241415413

Epoch: 320| Step: 0
Training loss: 2.1924706796144933
Validation loss: 2.5434196043136312

Epoch: 6| Step: 1
Training loss: 1.7571822329284001
Validation loss: 2.4767717458282945

Epoch: 6| Step: 2
Training loss: 2.249272864784877
Validation loss: 2.4817408107194154

Epoch: 6| Step: 3
Training loss: 2.0985985030205
Validation loss: 2.4850381683383245

Epoch: 6| Step: 4
Training loss: 2.0812078569057535
Validation loss: 2.5002743047539413

Epoch: 6| Step: 5
Training loss: 2.332909500139224
Validation loss: 2.5220059090060154

Epoch: 6| Step: 6
Training loss: 2.2398366267367438
Validation loss: 2.5034651716624543

Epoch: 6| Step: 7
Training loss: 2.1049021452134236
Validation loss: 2.5161883269239405

Epoch: 6| Step: 8
Training loss: 1.963907189248715
Validation loss: 2.5379310337193837

Epoch: 6| Step: 9
Training loss: 2.0923956291029104
Validation loss: 2.503480428741271

Epoch: 6| Step: 10
Training loss: 1.942106124633981
Validation loss: 2.4910255315830394

Epoch: 6| Step: 11
Training loss: 2.6571167373252393
Validation loss: 2.4919178172878205

Epoch: 6| Step: 12
Training loss: 2.2657562217858476
Validation loss: 2.498828719181696

Epoch: 6| Step: 13
Training loss: 2.1908352085752165
Validation loss: 2.46742576160377

Epoch: 321| Step: 0
Training loss: 2.139131233665894
Validation loss: 2.5116459474835113

Epoch: 6| Step: 1
Training loss: 2.5590836616486174
Validation loss: 2.48580941358146

Epoch: 6| Step: 2
Training loss: 2.0061015992226836
Validation loss: 2.4997086560292012

Epoch: 6| Step: 3
Training loss: 2.3444031886025876
Validation loss: 2.5051484234586066

Epoch: 6| Step: 4
Training loss: 2.4607120471195145
Validation loss: 2.4843671931054283

Epoch: 6| Step: 5
Training loss: 1.8725370124856444
Validation loss: 2.510056176486206

Epoch: 6| Step: 6
Training loss: 1.9245674687742214
Validation loss: 2.4925975027045824

Epoch: 6| Step: 7
Training loss: 3.023316373542678
Validation loss: 2.481693393456444

Epoch: 6| Step: 8
Training loss: 2.19414861377785
Validation loss: 2.4669326431657703

Epoch: 6| Step: 9
Training loss: 1.8321616445633508
Validation loss: 2.4863404413999297

Epoch: 6| Step: 10
Training loss: 1.4497653310892324
Validation loss: 2.4848800169621175

Epoch: 6| Step: 11
Training loss: 2.346038514870725
Validation loss: 2.5110130961454113

Epoch: 6| Step: 12
Training loss: 1.8253532329103428
Validation loss: 2.481086905209256

Epoch: 6| Step: 13
Training loss: 1.7461172354055363
Validation loss: 2.5220310156263683

Epoch: 322| Step: 0
Training loss: 2.743481713736167
Validation loss: 2.4800151104918258

Epoch: 6| Step: 1
Training loss: 1.8869171354195555
Validation loss: 2.4967497863261796

Epoch: 6| Step: 2
Training loss: 1.8255458146225776
Validation loss: 2.518892576582907

Epoch: 6| Step: 3
Training loss: 1.9958092175050757
Validation loss: 2.5436247940615018

Epoch: 6| Step: 4
Training loss: 2.244405998030789
Validation loss: 2.523420344915747

Epoch: 6| Step: 5
Training loss: 1.976737274765791
Validation loss: 2.518174007332687

Epoch: 6| Step: 6
Training loss: 2.1939831166969626
Validation loss: 2.491398808473119

Epoch: 6| Step: 7
Training loss: 2.217307252990121
Validation loss: 2.48480892899962

Epoch: 6| Step: 8
Training loss: 2.1097156390897385
Validation loss: 2.5149807291918025

Epoch: 6| Step: 9
Training loss: 2.2024465828522115
Validation loss: 2.511811094609194

Epoch: 6| Step: 10
Training loss: 2.3543865697549604
Validation loss: 2.528674240276326

Epoch: 6| Step: 11
Training loss: 2.5259807985713145
Validation loss: 2.4815099459601404

Epoch: 6| Step: 12
Training loss: 1.2439257856966568
Validation loss: 2.4913538275433855

Epoch: 6| Step: 13
Training loss: 2.187467302350492
Validation loss: 2.4990267899983607

Epoch: 323| Step: 0
Training loss: 2.074548957245184
Validation loss: 2.5059825441194308

Epoch: 6| Step: 1
Training loss: 1.9972077189511208
Validation loss: 2.5181050972742525

Epoch: 6| Step: 2
Training loss: 2.2547863807065247
Validation loss: 2.486532970402728

Epoch: 6| Step: 3
Training loss: 2.2205867418106577
Validation loss: 2.5155709511233253

Epoch: 6| Step: 4
Training loss: 2.3278449997442854
Validation loss: 2.4868879785470615

Epoch: 6| Step: 5
Training loss: 2.561218220265518
Validation loss: 2.496740201212204

Epoch: 6| Step: 6
Training loss: 2.1735132200103626
Validation loss: 2.5236967687547387

Epoch: 6| Step: 7
Training loss: 2.709936831255395
Validation loss: 2.458257243996953

Epoch: 6| Step: 8
Training loss: 2.13961879721882
Validation loss: 2.4975121455507128

Epoch: 6| Step: 9
Training loss: 1.7900018349963112
Validation loss: 2.515673826020626

Epoch: 6| Step: 10
Training loss: 1.7528178824894516
Validation loss: 2.5059162830037582

Epoch: 6| Step: 11
Training loss: 2.1759710314729768
Validation loss: 2.524159460156351

Epoch: 6| Step: 12
Training loss: 1.7856268398127226
Validation loss: 2.5004106143379925

Epoch: 6| Step: 13
Training loss: 1.8041133875684914
Validation loss: 2.474619423965273

Epoch: 324| Step: 0
Training loss: 2.22545716807437
Validation loss: 2.5186127224863073

Epoch: 6| Step: 1
Training loss: 1.6548466044903711
Validation loss: 2.4801238099452045

Epoch: 6| Step: 2
Training loss: 2.3219709538262094
Validation loss: 2.498539571884376

Epoch: 6| Step: 3
Training loss: 2.55098154587241
Validation loss: 2.540363363591984

Epoch: 6| Step: 4
Training loss: 1.7167778491462113
Validation loss: 2.525160687476243

Epoch: 6| Step: 5
Training loss: 2.3572513547095024
Validation loss: 2.498898692229504

Epoch: 6| Step: 6
Training loss: 2.3967437230731568
Validation loss: 2.49427949498861

Epoch: 6| Step: 7
Training loss: 2.64880683596716
Validation loss: 2.5323067346515704

Epoch: 6| Step: 8
Training loss: 2.0580531646489915
Validation loss: 2.5051736928831034

Epoch: 6| Step: 9
Training loss: 2.068057347076212
Validation loss: 2.519437147162052

Epoch: 6| Step: 10
Training loss: 2.089655730443975
Validation loss: 2.4690362713177594

Epoch: 6| Step: 11
Training loss: 2.2145634226533457
Validation loss: 2.5065320592083586

Epoch: 6| Step: 12
Training loss: 1.598744215488781
Validation loss: 2.522402657690373

Epoch: 6| Step: 13
Training loss: 1.6812054539561383
Validation loss: 2.478504493352413

Epoch: 325| Step: 0
Training loss: 2.116775303653467
Validation loss: 2.5253418203608606

Epoch: 6| Step: 1
Training loss: 2.319819234185473
Validation loss: 2.484026862231612

Epoch: 6| Step: 2
Training loss: 2.4818653410255536
Validation loss: 2.49237844382656

Epoch: 6| Step: 3
Training loss: 2.0251781385269134
Validation loss: 2.505870327839946

Epoch: 6| Step: 4
Training loss: 1.8694246688157052
Validation loss: 2.524218596194887

Epoch: 6| Step: 5
Training loss: 1.6860768003427522
Validation loss: 2.5124651268579736

Epoch: 6| Step: 6
Training loss: 1.6054151391501361
Validation loss: 2.4861561344582874

Epoch: 6| Step: 7
Training loss: 1.6712220244823086
Validation loss: 2.534833444007641

Epoch: 6| Step: 8
Training loss: 2.532229010495828
Validation loss: 2.4800645982980667

Epoch: 6| Step: 9
Training loss: 1.9676903188865973
Validation loss: 2.544020256163768

Epoch: 6| Step: 10
Training loss: 2.4651085761185496
Validation loss: 2.487764766711627

Epoch: 6| Step: 11
Training loss: 2.2600110183717295
Validation loss: 2.500044644890306

Epoch: 6| Step: 12
Training loss: 2.8713299089737134
Validation loss: 2.481963656209039

Epoch: 6| Step: 13
Training loss: 2.1982318838954993
Validation loss: 2.4802412294830636

Epoch: 326| Step: 0
Training loss: 1.8498665813071722
Validation loss: 2.469946182968801

Epoch: 6| Step: 1
Training loss: 1.6940346397722483
Validation loss: 2.4709419394150784

Epoch: 6| Step: 2
Training loss: 2.101726539761301
Validation loss: 2.5246801612995036

Epoch: 6| Step: 3
Training loss: 2.2366324804832565
Validation loss: 2.4780389653286

Epoch: 6| Step: 4
Training loss: 1.976266047142936
Validation loss: 2.515579968182327

Epoch: 6| Step: 5
Training loss: 2.07967072558212
Validation loss: 2.4953850573889413

Epoch: 6| Step: 6
Training loss: 3.1039679205505073
Validation loss: 2.4663154204247375

Epoch: 6| Step: 7
Training loss: 2.4426076145731535
Validation loss: 2.5274644455063773

Epoch: 6| Step: 8
Training loss: 1.9704401542095642
Validation loss: 2.5263149129333153

Epoch: 6| Step: 9
Training loss: 1.8009554102290202
Validation loss: 2.51409388275771

Epoch: 6| Step: 10
Training loss: 2.506011601475244
Validation loss: 2.5072503832149504

Epoch: 6| Step: 11
Training loss: 2.0169252445285624
Validation loss: 2.5532407140687545

Epoch: 6| Step: 12
Training loss: 1.6604827918746452
Validation loss: 2.498245565018233

Epoch: 6| Step: 13
Training loss: 1.5877714030235202
Validation loss: 2.517839045847666

Epoch: 327| Step: 0
Training loss: 2.5862160155256135
Validation loss: 2.5001967926915523

Epoch: 6| Step: 1
Training loss: 1.824545396072263
Validation loss: 2.5227841244732097

Epoch: 6| Step: 2
Training loss: 2.1421280755969616
Validation loss: 2.52173320262189

Epoch: 6| Step: 3
Training loss: 2.142198527256959
Validation loss: 2.492230389033398

Epoch: 6| Step: 4
Training loss: 2.208999269470674
Validation loss: 2.5102686446281095

Epoch: 6| Step: 5
Training loss: 1.8993690622681887
Validation loss: 2.4966302752415483

Epoch: 6| Step: 6
Training loss: 2.359580934139242
Validation loss: 2.4888791899872387

Epoch: 6| Step: 7
Training loss: 2.1326377713240423
Validation loss: 2.510080775530135

Epoch: 6| Step: 8
Training loss: 2.100748237642718
Validation loss: 2.5488579079102727

Epoch: 6| Step: 9
Training loss: 2.6848235886798117
Validation loss: 2.5243008720607008

Epoch: 6| Step: 10
Training loss: 2.167785966745709
Validation loss: 2.5103237196335275

Epoch: 6| Step: 11
Training loss: 2.3717625285988118
Validation loss: 2.497214394852558

Epoch: 6| Step: 12
Training loss: 1.0129130027408677
Validation loss: 2.4902494670966346

Epoch: 6| Step: 13
Training loss: 1.8688919396223724
Validation loss: 2.4960237096169715

Epoch: 328| Step: 0
Training loss: 1.8534855895427675
Validation loss: 2.550580483078924

Epoch: 6| Step: 1
Training loss: 2.3591235702640483
Validation loss: 2.4733133608486484

Epoch: 6| Step: 2
Training loss: 1.9192178857781679
Validation loss: 2.4931881793792527

Epoch: 6| Step: 3
Training loss: 2.1113389656289687
Validation loss: 2.4983708149173225

Epoch: 6| Step: 4
Training loss: 2.490939410764904
Validation loss: 2.5158780367572278

Epoch: 6| Step: 5
Training loss: 2.4420166229194655
Validation loss: 2.4880394054621617

Epoch: 6| Step: 6
Training loss: 1.7564844158294595
Validation loss: 2.483280458016103

Epoch: 6| Step: 7
Training loss: 2.5133675818635246
Validation loss: 2.474131819768456

Epoch: 6| Step: 8
Training loss: 1.4958049605006658
Validation loss: 2.5048217113531317

Epoch: 6| Step: 9
Training loss: 1.6353353330307336
Validation loss: 2.5334866637096245

Epoch: 6| Step: 10
Training loss: 2.204811478771232
Validation loss: 2.4969432611973468

Epoch: 6| Step: 11
Training loss: 2.1073476585634214
Validation loss: 2.48795613034369

Epoch: 6| Step: 12
Training loss: 2.0686479894835976
Validation loss: 2.511618715021457

Epoch: 6| Step: 13
Training loss: 3.11257677711256
Validation loss: 2.4985756918602133

Epoch: 329| Step: 0
Training loss: 2.4830768000401156
Validation loss: 2.5108299182448923

Epoch: 6| Step: 1
Training loss: 2.1084613092756532
Validation loss: 2.493427191116806

Epoch: 6| Step: 2
Training loss: 2.341136645227266
Validation loss: 2.4795753932802893

Epoch: 6| Step: 3
Training loss: 3.031572776991716
Validation loss: 2.491600884899122

Epoch: 6| Step: 4
Training loss: 1.7631932619897277
Validation loss: 2.506640726619405

Epoch: 6| Step: 5
Training loss: 2.052187018187472
Validation loss: 2.519154279724128

Epoch: 6| Step: 6
Training loss: 2.1082964364945793
Validation loss: 2.530329585684747

Epoch: 6| Step: 7
Training loss: 2.4708545261479857
Validation loss: 2.49912309136347

Epoch: 6| Step: 8
Training loss: 1.6948626927938193
Validation loss: 2.4986942685833404

Epoch: 6| Step: 9
Training loss: 1.497506294046208
Validation loss: 2.5166705616045677

Epoch: 6| Step: 10
Training loss: 1.6940316842278862
Validation loss: 2.4805362365704307

Epoch: 6| Step: 11
Training loss: 2.4372247393781348
Validation loss: 2.4839169701824444

Epoch: 6| Step: 12
Training loss: 1.9863271647613214
Validation loss: 2.5160919063922322

Epoch: 6| Step: 13
Training loss: 2.2671310154867177
Validation loss: 2.4854680223330927

Epoch: 330| Step: 0
Training loss: 2.2532387840967854
Validation loss: 2.4931250569077057

Epoch: 6| Step: 1
Training loss: 1.9144962986979817
Validation loss: 2.4653663172968185

Epoch: 6| Step: 2
Training loss: 2.2686522155370215
Validation loss: 2.5112735210342474

Epoch: 6| Step: 3
Training loss: 3.0006732185301845
Validation loss: 2.482858394211873

Epoch: 6| Step: 4
Training loss: 2.4013244947785863
Validation loss: 2.5046973664280676

Epoch: 6| Step: 5
Training loss: 2.3587447581513445
Validation loss: 2.5022036802323573

Epoch: 6| Step: 6
Training loss: 2.3393182180261856
Validation loss: 2.4647303009199746

Epoch: 6| Step: 7
Training loss: 1.9750936727401114
Validation loss: 2.500846982346679

Epoch: 6| Step: 8
Training loss: 1.8181796697040349
Validation loss: 2.4984458358385377

Epoch: 6| Step: 9
Training loss: 1.9572797606063619
Validation loss: 2.4870067022588485

Epoch: 6| Step: 10
Training loss: 1.618218429655861
Validation loss: 2.546213409982338

Epoch: 6| Step: 11
Training loss: 2.023042971763226
Validation loss: 2.5410790418915097

Epoch: 6| Step: 12
Training loss: 2.0364058569921886
Validation loss: 2.537267667288874

Epoch: 6| Step: 13
Training loss: 0.939340247591976
Validation loss: 2.4840511472881985

Epoch: 331| Step: 0
Training loss: 1.9890121585441725
Validation loss: 2.506742822585073

Epoch: 6| Step: 1
Training loss: 2.0412653574041713
Validation loss: 2.4958101130335693

Epoch: 6| Step: 2
Training loss: 1.974296929970525
Validation loss: 2.507348067022667

Epoch: 6| Step: 3
Training loss: 2.731521949061205
Validation loss: 2.4949965635083626

Epoch: 6| Step: 4
Training loss: 1.88391524189422
Validation loss: 2.544167488251202

Epoch: 6| Step: 5
Training loss: 2.839431333963364
Validation loss: 2.5087476235383916

Epoch: 6| Step: 6
Training loss: 1.8337743474362007
Validation loss: 2.5007245100935616

Epoch: 6| Step: 7
Training loss: 2.270277941152631
Validation loss: 2.5021331997170098

Epoch: 6| Step: 8
Training loss: 1.9778506337306554
Validation loss: 2.5130362143224634

Epoch: 6| Step: 9
Training loss: 2.533359637458499
Validation loss: 2.4787519884911595

Epoch: 6| Step: 10
Training loss: 1.8467929105378442
Validation loss: 2.49811858682848

Epoch: 6| Step: 11
Training loss: 1.4866848290763781
Validation loss: 2.523264138474609

Epoch: 6| Step: 12
Training loss: 2.095116923490358
Validation loss: 2.5394476717840413

Epoch: 6| Step: 13
Training loss: 1.26376219814311
Validation loss: 2.5054016219502913

Epoch: 332| Step: 0
Training loss: 1.7591945386251042
Validation loss: 2.474719808298511

Epoch: 6| Step: 1
Training loss: 1.5163195090466999
Validation loss: 2.4840740760194358

Epoch: 6| Step: 2
Training loss: 2.208702872204758
Validation loss: 2.538788484312668

Epoch: 6| Step: 3
Training loss: 2.700710386847862
Validation loss: 2.5300723513666052

Epoch: 6| Step: 4
Training loss: 2.6787521464828314
Validation loss: 2.523620781172527

Epoch: 6| Step: 5
Training loss: 2.6018658252108047
Validation loss: 2.5058037568326004

Epoch: 6| Step: 6
Training loss: 2.226820117703468
Validation loss: 2.5037270789443986

Epoch: 6| Step: 7
Training loss: 2.3339392238702823
Validation loss: 2.483329969531722

Epoch: 6| Step: 8
Training loss: 1.9754412339259977
Validation loss: 2.455984448899055

Epoch: 6| Step: 9
Training loss: 1.876052179753657
Validation loss: 2.487051162918892

Epoch: 6| Step: 10
Training loss: 2.026725307210188
Validation loss: 2.491561010598647

Epoch: 6| Step: 11
Training loss: 1.9369838396224415
Validation loss: 2.497075931400414

Epoch: 6| Step: 12
Training loss: 1.9468858476707034
Validation loss: 2.536366315347807

Epoch: 6| Step: 13
Training loss: 2.0075901962293234
Validation loss: 2.4822270875335466

Epoch: 333| Step: 0
Training loss: 2.0239608264645312
Validation loss: 2.5185090443824163

Epoch: 6| Step: 1
Training loss: 2.2110706734061285
Validation loss: 2.4943523100174843

Epoch: 6| Step: 2
Training loss: 1.9069937208859429
Validation loss: 2.5004179256549977

Epoch: 6| Step: 3
Training loss: 2.4787768744061696
Validation loss: 2.477231486919025

Epoch: 6| Step: 4
Training loss: 2.7878520486671396
Validation loss: 2.5279915742619505

Epoch: 6| Step: 5
Training loss: 2.4898450599477844
Validation loss: 2.4857577542004563

Epoch: 6| Step: 6
Training loss: 2.6570598489713446
Validation loss: 2.4851967697279793

Epoch: 6| Step: 7
Training loss: 1.893085612469472
Validation loss: 2.504045969747671

Epoch: 6| Step: 8
Training loss: 1.6328131570769087
Validation loss: 2.4852792388426206

Epoch: 6| Step: 9
Training loss: 1.6843856754566253
Validation loss: 2.498270513294253

Epoch: 6| Step: 10
Training loss: 2.1774148886303233
Validation loss: 2.487402470251949

Epoch: 6| Step: 11
Training loss: 1.6623394422513857
Validation loss: 2.5082509761518414

Epoch: 6| Step: 12
Training loss: 2.027204975530936
Validation loss: 2.515502938955272

Epoch: 6| Step: 13
Training loss: 1.1874129112834462
Validation loss: 2.5045086413103537

Epoch: 334| Step: 0
Training loss: 1.6666633446978205
Validation loss: 2.512800642480539

Epoch: 6| Step: 1
Training loss: 2.1815122124318953
Validation loss: 2.5072101990015847

Epoch: 6| Step: 2
Training loss: 2.993595280163305
Validation loss: 2.5120339892160817

Epoch: 6| Step: 3
Training loss: 2.005812424330326
Validation loss: 2.5244628099267623

Epoch: 6| Step: 4
Training loss: 2.0258997954944062
Validation loss: 2.453298634297216

Epoch: 6| Step: 5
Training loss: 2.1449089898851503
Validation loss: 2.4922053756635982

Epoch: 6| Step: 6
Training loss: 1.7346887390649075
Validation loss: 2.53560348315782

Epoch: 6| Step: 7
Training loss: 1.908700337441531
Validation loss: 2.481307092159973

Epoch: 6| Step: 8
Training loss: 2.8482077735590683
Validation loss: 2.495886801460349

Epoch: 6| Step: 9
Training loss: 1.9235824815415266
Validation loss: 2.492266523299234

Epoch: 6| Step: 10
Training loss: 2.206370134838105
Validation loss: 2.511121680921732

Epoch: 6| Step: 11
Training loss: 2.5099974053965983
Validation loss: 2.5357224646328875

Epoch: 6| Step: 12
Training loss: 1.695143379178738
Validation loss: 2.4688468032493724

Epoch: 6| Step: 13
Training loss: 1.4723628634726558
Validation loss: 2.479921391687195

Epoch: 335| Step: 0
Training loss: 1.960844668436529
Validation loss: 2.4816674614024365

Epoch: 6| Step: 1
Training loss: 2.115550291469358
Validation loss: 2.4962247625759018

Epoch: 6| Step: 2
Training loss: 2.2783437532281066
Validation loss: 2.5063716580364797

Epoch: 6| Step: 3
Training loss: 2.0718465627614573
Validation loss: 2.4940062711619273

Epoch: 6| Step: 4
Training loss: 2.7793722779157934
Validation loss: 2.5295937752256377

Epoch: 6| Step: 5
Training loss: 2.2231597062030133
Validation loss: 2.4858311112223337

Epoch: 6| Step: 6
Training loss: 2.3016038858560557
Validation loss: 2.538391517346833

Epoch: 6| Step: 7
Training loss: 1.8749361663124913
Validation loss: 2.5076262574503203

Epoch: 6| Step: 8
Training loss: 2.131388765443322
Validation loss: 2.5018304010212202

Epoch: 6| Step: 9
Training loss: 1.924077764279868
Validation loss: 2.462073704193575

Epoch: 6| Step: 10
Training loss: 1.691623030727703
Validation loss: 2.5326292512995727

Epoch: 6| Step: 11
Training loss: 2.0292423597104805
Validation loss: 2.480807760047323

Epoch: 6| Step: 12
Training loss: 1.8515256081297997
Validation loss: 2.5376113619439162

Epoch: 6| Step: 13
Training loss: 2.530719842845832
Validation loss: 2.4733409777534963

Epoch: 336| Step: 0
Training loss: 1.5420770700295392
Validation loss: 2.4606691036042214

Epoch: 6| Step: 1
Training loss: 1.951117987361156
Validation loss: 2.4859104306847177

Epoch: 6| Step: 2
Training loss: 2.4288275567598605
Validation loss: 2.5202613845472475

Epoch: 6| Step: 3
Training loss: 2.4003228844565885
Validation loss: 2.4862214889248166

Epoch: 6| Step: 4
Training loss: 2.5129615473630693
Validation loss: 2.4930653159757066

Epoch: 6| Step: 5
Training loss: 1.9195027170323515
Validation loss: 2.4881010722615944

Epoch: 6| Step: 6
Training loss: 1.9431844201240378
Validation loss: 2.4839558148738337

Epoch: 6| Step: 7
Training loss: 1.6951513960975664
Validation loss: 2.4969418443349234

Epoch: 6| Step: 8
Training loss: 1.5950038689832489
Validation loss: 2.4938782054032136

Epoch: 6| Step: 9
Training loss: 2.326127597185647
Validation loss: 2.490835938345186

Epoch: 6| Step: 10
Training loss: 1.6044896613929445
Validation loss: 2.5013831168302025

Epoch: 6| Step: 11
Training loss: 2.5115438967010215
Validation loss: 2.468472870339446

Epoch: 6| Step: 12
Training loss: 2.7195012600238826
Validation loss: 2.480679597840549

Epoch: 6| Step: 13
Training loss: 1.9277584302458415
Validation loss: 2.488749985852309

Epoch: 337| Step: 0
Training loss: 2.1694258458567757
Validation loss: 2.4678612995924034

Epoch: 6| Step: 1
Training loss: 1.804038587550808
Validation loss: 2.5278334140646046

Epoch: 6| Step: 2
Training loss: 1.9746728843489763
Validation loss: 2.510560337742045

Epoch: 6| Step: 3
Training loss: 2.3752720325677923
Validation loss: 2.5215218159011803

Epoch: 6| Step: 4
Training loss: 2.283678721551125
Validation loss: 2.5194403015495324

Epoch: 6| Step: 5
Training loss: 2.5351500430273592
Validation loss: 2.519548702219293

Epoch: 6| Step: 6
Training loss: 1.9969397616443898
Validation loss: 2.4945433162887864

Epoch: 6| Step: 7
Training loss: 1.7544041799762504
Validation loss: 2.4933841710136333

Epoch: 6| Step: 8
Training loss: 1.7485645401442307
Validation loss: 2.5137312485824275

Epoch: 6| Step: 9
Training loss: 2.2709211863284424
Validation loss: 2.4671670322914454

Epoch: 6| Step: 10
Training loss: 2.2115665255395793
Validation loss: 2.5002173524119637

Epoch: 6| Step: 11
Training loss: 1.7429567016020988
Validation loss: 2.496026138683302

Epoch: 6| Step: 12
Training loss: 2.9245009428568336
Validation loss: 2.505091568624103

Epoch: 6| Step: 13
Training loss: 1.426635569845558
Validation loss: 2.505781369670467

Epoch: 338| Step: 0
Training loss: 1.9484099581193588
Validation loss: 2.508917670976949

Epoch: 6| Step: 1
Training loss: 3.0190963135778195
Validation loss: 2.491595307155301

Epoch: 6| Step: 2
Training loss: 2.1141800018158636
Validation loss: 2.4533532149284847

Epoch: 6| Step: 3
Training loss: 1.9834150260107624
Validation loss: 2.493008150614015

Epoch: 6| Step: 4
Training loss: 2.256825795763669
Validation loss: 2.5241944700853565

Epoch: 6| Step: 5
Training loss: 2.173335181432457
Validation loss: 2.488041529601716

Epoch: 6| Step: 6
Training loss: 1.5184733574482872
Validation loss: 2.4987699979662814

Epoch: 6| Step: 7
Training loss: 1.8948345138237883
Validation loss: 2.4883497012416096

Epoch: 6| Step: 8
Training loss: 1.6421802959774119
Validation loss: 2.4811707983428066

Epoch: 6| Step: 9
Training loss: 1.8431440747846648
Validation loss: 2.4831844388912905

Epoch: 6| Step: 10
Training loss: 2.0420966830852127
Validation loss: 2.521554844830585

Epoch: 6| Step: 11
Training loss: 1.9696759059975726
Validation loss: 2.4902054979844515

Epoch: 6| Step: 12
Training loss: 2.4495181641396733
Validation loss: 2.4946431193182104

Epoch: 6| Step: 13
Training loss: 2.329586824612249
Validation loss: 2.4599507015119704

Epoch: 339| Step: 0
Training loss: 1.8937378785403243
Validation loss: 2.4768963230986953

Epoch: 6| Step: 1
Training loss: 1.4082614077121751
Validation loss: 2.5040947522877075

Epoch: 6| Step: 2
Training loss: 2.2347388338091037
Validation loss: 2.4820607218599595

Epoch: 6| Step: 3
Training loss: 1.8193470764638207
Validation loss: 2.484082842072488

Epoch: 6| Step: 4
Training loss: 2.0906395653643517
Validation loss: 2.4926453687116172

Epoch: 6| Step: 5
Training loss: 2.0297348240128676
Validation loss: 2.519286900129843

Epoch: 6| Step: 6
Training loss: 2.1967602500411574
Validation loss: 2.495718918526163

Epoch: 6| Step: 7
Training loss: 2.3510352269125177
Validation loss: 2.544884219778889

Epoch: 6| Step: 8
Training loss: 2.73249202744559
Validation loss: 2.4745579858184215

Epoch: 6| Step: 9
Training loss: 2.6882669108683803
Validation loss: 2.5066749717969294

Epoch: 6| Step: 10
Training loss: 1.7741342259862403
Validation loss: 2.497278564749338

Epoch: 6| Step: 11
Training loss: 2.0266796634073296
Validation loss: 2.5025357993646584

Epoch: 6| Step: 12
Training loss: 2.1192614542885693
Validation loss: 2.5093323572486956

Epoch: 6| Step: 13
Training loss: 1.6111939160490663
Validation loss: 2.4840702358303406

Epoch: 340| Step: 0
Training loss: 2.670373059473885
Validation loss: 2.4943932347772453

Epoch: 6| Step: 1
Training loss: 2.0922130808217223
Validation loss: 2.4862913465984553

Epoch: 6| Step: 2
Training loss: 1.973649060287679
Validation loss: 2.495100540488651

Epoch: 6| Step: 3
Training loss: 2.0761501709457617
Validation loss: 2.537793831104463

Epoch: 6| Step: 4
Training loss: 1.6216698783275536
Validation loss: 2.501040891102151

Epoch: 6| Step: 5
Training loss: 2.255679697254565
Validation loss: 2.4977438375192724

Epoch: 6| Step: 6
Training loss: 2.3848574009137047
Validation loss: 2.531549595774066

Epoch: 6| Step: 7
Training loss: 2.3389639243107823
Validation loss: 2.4944739209501696

Epoch: 6| Step: 8
Training loss: 1.7821060934241835
Validation loss: 2.5130912694804963

Epoch: 6| Step: 9
Training loss: 1.6347099850755749
Validation loss: 2.5287289402651267

Epoch: 6| Step: 10
Training loss: 2.231625766260649
Validation loss: 2.518172840640933

Epoch: 6| Step: 11
Training loss: 2.323389652377776
Validation loss: 2.4832090888773584

Epoch: 6| Step: 12
Training loss: 1.8528574990096656
Validation loss: 2.4749925991364923

Epoch: 6| Step: 13
Training loss: 1.6782382124179
Validation loss: 2.5032685601275353

Epoch: 341| Step: 0
Training loss: 1.8062863224165748
Validation loss: 2.496507865686431

Epoch: 6| Step: 1
Training loss: 2.691250247060549
Validation loss: 2.4632161295279418

Epoch: 6| Step: 2
Training loss: 2.473905371383485
Validation loss: 2.493893805879818

Epoch: 6| Step: 3
Training loss: 1.6812068720961877
Validation loss: 2.5198420079927955

Epoch: 6| Step: 4
Training loss: 2.1496671729520767
Validation loss: 2.5057288845879553

Epoch: 6| Step: 5
Training loss: 1.5954922147995465
Validation loss: 2.4955800485090065

Epoch: 6| Step: 6
Training loss: 1.936189762210328
Validation loss: 2.520266896814148

Epoch: 6| Step: 7
Training loss: 2.316230754412074
Validation loss: 2.511075487176663

Epoch: 6| Step: 8
Training loss: 1.8070247427381618
Validation loss: 2.5205716375512623

Epoch: 6| Step: 9
Training loss: 1.7690879148521914
Validation loss: 2.46411412508608

Epoch: 6| Step: 10
Training loss: 2.7733630533031994
Validation loss: 2.508001537684364

Epoch: 6| Step: 11
Training loss: 2.3084537056983705
Validation loss: 2.525054543571194

Epoch: 6| Step: 12
Training loss: 1.768907314893599
Validation loss: 2.468751638652589

Epoch: 6| Step: 13
Training loss: 2.218601705404032
Validation loss: 2.503327156361203

Epoch: 342| Step: 0
Training loss: 1.6681075384570319
Validation loss: 2.481977247178045

Epoch: 6| Step: 1
Training loss: 2.1010157217738445
Validation loss: 2.49131154186822

Epoch: 6| Step: 2
Training loss: 2.3884399001985273
Validation loss: 2.5099202436545185

Epoch: 6| Step: 3
Training loss: 2.6163301344626904
Validation loss: 2.515807810424725

Epoch: 6| Step: 4
Training loss: 1.7468276561674774
Validation loss: 2.472861888941007

Epoch: 6| Step: 5
Training loss: 2.0579048755856593
Validation loss: 2.4556299747919046

Epoch: 6| Step: 6
Training loss: 1.598391785625165
Validation loss: 2.5008449510924606

Epoch: 6| Step: 7
Training loss: 2.073431925417572
Validation loss: 2.4988738671798

Epoch: 6| Step: 8
Training loss: 2.9210213622892582
Validation loss: 2.510648764088612

Epoch: 6| Step: 9
Training loss: 2.532364023216556
Validation loss: 2.499633412504639

Epoch: 6| Step: 10
Training loss: 1.4201847132238408
Validation loss: 2.5189922372108207

Epoch: 6| Step: 11
Training loss: 2.192147467880539
Validation loss: 2.484119888470505

Epoch: 6| Step: 12
Training loss: 1.525365616792439
Validation loss: 2.533275305971781

Epoch: 6| Step: 13
Training loss: 2.0778325384180363
Validation loss: 2.4547119598518314

Epoch: 343| Step: 0
Training loss: 2.3162516498920063
Validation loss: 2.4645171320812835

Epoch: 6| Step: 1
Training loss: 2.1907988605807636
Validation loss: 2.5027470191244063

Epoch: 6| Step: 2
Training loss: 2.633222327327162
Validation loss: 2.474055135200716

Epoch: 6| Step: 3
Training loss: 1.9602006842577873
Validation loss: 2.4878948710994977

Epoch: 6| Step: 4
Training loss: 2.5800307195150523
Validation loss: 2.5465354791269803

Epoch: 6| Step: 5
Training loss: 2.081490680879894
Validation loss: 2.503151780380386

Epoch: 6| Step: 6
Training loss: 2.0291805582791653
Validation loss: 2.504878828177507

Epoch: 6| Step: 7
Training loss: 1.7754168115075795
Validation loss: 2.479895483488072

Epoch: 6| Step: 8
Training loss: 1.5898290535062436
Validation loss: 2.513754766321862

Epoch: 6| Step: 9
Training loss: 1.9009482652546552
Validation loss: 2.5102610157933682

Epoch: 6| Step: 10
Training loss: 1.202988554908806
Validation loss: 2.4884322636678267

Epoch: 6| Step: 11
Training loss: 2.431872596553261
Validation loss: 2.494773178414004

Epoch: 6| Step: 12
Training loss: 1.940777744050188
Validation loss: 2.478362728554492

Epoch: 6| Step: 13
Training loss: 3.0267449949718928
Validation loss: 2.4930535736915513

Epoch: 344| Step: 0
Training loss: 1.8527622118665696
Validation loss: 2.5271618653640546

Epoch: 6| Step: 1
Training loss: 2.1340547514079473
Validation loss: 2.4902522703457124

Epoch: 6| Step: 2
Training loss: 2.2992844173322946
Validation loss: 2.5008031272885267

Epoch: 6| Step: 3
Training loss: 2.367401214117699
Validation loss: 2.501208741221759

Epoch: 6| Step: 4
Training loss: 2.3816318275923605
Validation loss: 2.5036852029393213

Epoch: 6| Step: 5
Training loss: 1.3624842809067848
Validation loss: 2.5117959330404522

Epoch: 6| Step: 6
Training loss: 2.122220746328874
Validation loss: 2.5025459677088064

Epoch: 6| Step: 7
Training loss: 2.0423051912562378
Validation loss: 2.46144136920978

Epoch: 6| Step: 8
Training loss: 2.149725288761025
Validation loss: 2.5217312039491198

Epoch: 6| Step: 9
Training loss: 2.3925552055662433
Validation loss: 2.524864337671501

Epoch: 6| Step: 10
Training loss: 1.922969227489568
Validation loss: 2.477911830044259

Epoch: 6| Step: 11
Training loss: 2.4766682984289834
Validation loss: 2.489309972363188

Epoch: 6| Step: 12
Training loss: 1.9068401861373017
Validation loss: 2.5011376909625973

Epoch: 6| Step: 13
Training loss: 1.0036731256331846
Validation loss: 2.5003273836731865

Epoch: 345| Step: 0
Training loss: 1.7839064615942315
Validation loss: 2.4914266961799783

Epoch: 6| Step: 1
Training loss: 1.9461649669968548
Validation loss: 2.4935579834438606

Epoch: 6| Step: 2
Training loss: 2.3377570271064623
Validation loss: 2.501880231977984

Epoch: 6| Step: 3
Training loss: 1.8750014623000482
Validation loss: 2.502203407188931

Epoch: 6| Step: 4
Training loss: 2.269839451359662
Validation loss: 2.5069128515952

Epoch: 6| Step: 5
Training loss: 2.0265720199561357
Validation loss: 2.5067522426377855

Epoch: 6| Step: 6
Training loss: 2.1929660624510383
Validation loss: 2.4794341746406543

Epoch: 6| Step: 7
Training loss: 2.1715405982023714
Validation loss: 2.5144386783371617

Epoch: 6| Step: 8
Training loss: 2.3621197833536396
Validation loss: 2.4937356100983865

Epoch: 6| Step: 9
Training loss: 1.9715101481869923
Validation loss: 2.468770425965647

Epoch: 6| Step: 10
Training loss: 1.801469121201961
Validation loss: 2.4998580482134067

Epoch: 6| Step: 11
Training loss: 1.8671727519071388
Validation loss: 2.4954656190343956

Epoch: 6| Step: 12
Training loss: 2.0773543456210133
Validation loss: 2.4698752697944233

Epoch: 6| Step: 13
Training loss: 2.222801270807166
Validation loss: 2.5346400991334983

Epoch: 346| Step: 0
Training loss: 1.7353492268818693
Validation loss: 2.5107815534797937

Epoch: 6| Step: 1
Training loss: 2.121270441104047
Validation loss: 2.4946583193653935

Epoch: 6| Step: 2
Training loss: 2.1711694682926956
Validation loss: 2.4944719096857084

Epoch: 6| Step: 3
Training loss: 1.6252064206991037
Validation loss: 2.499154403177127

Epoch: 6| Step: 4
Training loss: 2.4303384871661247
Validation loss: 2.4877563227834476

Epoch: 6| Step: 5
Training loss: 2.1656489427352175
Validation loss: 2.490858223112272

Epoch: 6| Step: 6
Training loss: 2.067322727892524
Validation loss: 2.5153326543514933

Epoch: 6| Step: 7
Training loss: 2.001950147673091
Validation loss: 2.4949577304189874

Epoch: 6| Step: 8
Training loss: 2.010682663261129
Validation loss: 2.4968027124861902

Epoch: 6| Step: 9
Training loss: 2.122887290424402
Validation loss: 2.5006644945059135

Epoch: 6| Step: 10
Training loss: 1.303659228038772
Validation loss: 2.535670637711328

Epoch: 6| Step: 11
Training loss: 2.429376416668431
Validation loss: 2.50482871605606

Epoch: 6| Step: 12
Training loss: 2.2871921436373692
Validation loss: 2.4995810014044504

Epoch: 6| Step: 13
Training loss: 3.1066090919278575
Validation loss: 2.5049946268097845

Epoch: 347| Step: 0
Training loss: 1.496925780006403
Validation loss: 2.5148902247490814

Epoch: 6| Step: 1
Training loss: 2.406998951270236
Validation loss: 2.4838955902229074

Epoch: 6| Step: 2
Training loss: 2.2215682921935764
Validation loss: 2.501849667469342

Epoch: 6| Step: 3
Training loss: 2.2927792940390743
Validation loss: 2.495818149659406

Epoch: 6| Step: 4
Training loss: 1.9597447632015124
Validation loss: 2.471444329100557

Epoch: 6| Step: 5
Training loss: 1.3344439808081263
Validation loss: 2.470223374104302

Epoch: 6| Step: 6
Training loss: 2.162059972899923
Validation loss: 2.516632217796778

Epoch: 6| Step: 7
Training loss: 1.8104651637398608
Validation loss: 2.500675453183732

Epoch: 6| Step: 8
Training loss: 1.8565684703608265
Validation loss: 2.465930095102189

Epoch: 6| Step: 9
Training loss: 2.292467520680287
Validation loss: 2.462373425087525

Epoch: 6| Step: 10
Training loss: 1.978970594899913
Validation loss: 2.5026620975946576

Epoch: 6| Step: 11
Training loss: 2.4513566756781033
Validation loss: 2.5004132841861417

Epoch: 6| Step: 12
Training loss: 2.77057889377224
Validation loss: 2.5006168014772894

Epoch: 6| Step: 13
Training loss: 1.983598211643269
Validation loss: 2.517439689913824

Epoch: 348| Step: 0
Training loss: 1.9932702805786244
Validation loss: 2.5005881181744245

Epoch: 6| Step: 1
Training loss: 2.188543452304969
Validation loss: 2.492435362374519

Epoch: 6| Step: 2
Training loss: 1.833694971425177
Validation loss: 2.492910034476689

Epoch: 6| Step: 3
Training loss: 2.4295840716656634
Validation loss: 2.4773962588678655

Epoch: 6| Step: 4
Training loss: 1.9920784116310652
Validation loss: 2.4943541302118053

Epoch: 6| Step: 5
Training loss: 2.4954983235382033
Validation loss: 2.471320937597712

Epoch: 6| Step: 6
Training loss: 1.8753907114484594
Validation loss: 2.4455102183192694

Epoch: 6| Step: 7
Training loss: 2.083282495514164
Validation loss: 2.4835587090035895

Epoch: 6| Step: 8
Training loss: 2.109911589013186
Validation loss: 2.4462856670707556

Epoch: 6| Step: 9
Training loss: 1.804952626755828
Validation loss: 2.4986551564315356

Epoch: 6| Step: 10
Training loss: 1.435318577058179
Validation loss: 2.4965248781261997

Epoch: 6| Step: 11
Training loss: 2.4157807491176877
Validation loss: 2.472569337993222

Epoch: 6| Step: 12
Training loss: 1.7514587861661695
Validation loss: 2.4967248711141123

Epoch: 6| Step: 13
Training loss: 2.5990632570501147
Validation loss: 2.5423658264345113

Epoch: 349| Step: 0
Training loss: 1.9319536748074921
Validation loss: 2.5343550942455058

Epoch: 6| Step: 1
Training loss: 2.334297037929278
Validation loss: 2.474754527823004

Epoch: 6| Step: 2
Training loss: 1.6914726402873255
Validation loss: 2.496822633016642

Epoch: 6| Step: 3
Training loss: 1.6724313541118239
Validation loss: 2.4976716202005567

Epoch: 6| Step: 4
Training loss: 2.457643174961196
Validation loss: 2.503842361564528

Epoch: 6| Step: 5
Training loss: 2.1942554250291315
Validation loss: 2.50641173909085

Epoch: 6| Step: 6
Training loss: 1.8146871984503568
Validation loss: 2.4793096783584394

Epoch: 6| Step: 7
Training loss: 2.424519233632043
Validation loss: 2.524993409698798

Epoch: 6| Step: 8
Training loss: 2.1406120801104174
Validation loss: 2.5080114600109846

Epoch: 6| Step: 9
Training loss: 1.9954456090776393
Validation loss: 2.5167978159532627

Epoch: 6| Step: 10
Training loss: 1.8394298695382059
Validation loss: 2.502994583515949

Epoch: 6| Step: 11
Training loss: 2.006253241895867
Validation loss: 2.4872138150360565

Epoch: 6| Step: 12
Training loss: 2.6953666349862444
Validation loss: 2.505618849573803

Epoch: 6| Step: 13
Training loss: 1.8478799245020785
Validation loss: 2.544212126429535

Epoch: 350| Step: 0
Training loss: 1.9216225310939858
Validation loss: 2.509841646467011

Epoch: 6| Step: 1
Training loss: 2.0421533069506204
Validation loss: 2.5224215149534697

Epoch: 6| Step: 2
Training loss: 2.5389819323154925
Validation loss: 2.4854291806465847

Epoch: 6| Step: 3
Training loss: 2.630905230263424
Validation loss: 2.496479059183154

Epoch: 6| Step: 4
Training loss: 1.415737277329954
Validation loss: 2.532282982229379

Epoch: 6| Step: 5
Training loss: 1.3808562671243314
Validation loss: 2.4972969167409382

Epoch: 6| Step: 6
Training loss: 1.5350243897628297
Validation loss: 2.546182769006696

Epoch: 6| Step: 7
Training loss: 2.3108153521772157
Validation loss: 2.484825030054984

Epoch: 6| Step: 8
Training loss: 1.690815529514143
Validation loss: 2.5291780240607924

Epoch: 6| Step: 9
Training loss: 2.3257842105209785
Validation loss: 2.5225039012659285

Epoch: 6| Step: 10
Training loss: 2.423995535553702
Validation loss: 2.509971066121727

Epoch: 6| Step: 11
Training loss: 2.5630007929032343
Validation loss: 2.5232202376755724

Epoch: 6| Step: 12
Training loss: 1.9413400558147433
Validation loss: 2.5269291504349165

Epoch: 6| Step: 13
Training loss: 1.0430853274911147
Validation loss: 2.482088075147593

Epoch: 351| Step: 0
Training loss: 1.8008384447262076
Validation loss: 2.4797083992764253

Epoch: 6| Step: 1
Training loss: 2.425336959866914
Validation loss: 2.4832977561882594

Epoch: 6| Step: 2
Training loss: 2.1477282653923733
Validation loss: 2.5085170388588915

Epoch: 6| Step: 3
Training loss: 1.5120398207572656
Validation loss: 2.496403699831262

Epoch: 6| Step: 4
Training loss: 1.639905353931969
Validation loss: 2.5108320001306663

Epoch: 6| Step: 5
Training loss: 1.8350009558568643
Validation loss: 2.5109768732908613

Epoch: 6| Step: 6
Training loss: 1.7872217028393813
Validation loss: 2.5093635038709325

Epoch: 6| Step: 7
Training loss: 2.226016007666598
Validation loss: 2.5231675463608947

Epoch: 6| Step: 8
Training loss: 2.1497706490545396
Validation loss: 2.49802739962567

Epoch: 6| Step: 9
Training loss: 2.871794198677138
Validation loss: 2.479120085697357

Epoch: 6| Step: 10
Training loss: 1.6268035710027562
Validation loss: 2.503661024365051

Epoch: 6| Step: 11
Training loss: 2.302679292571694
Validation loss: 2.5122404306145336

Epoch: 6| Step: 12
Training loss: 2.307820921761779
Validation loss: 2.482636390598917

Epoch: 6| Step: 13
Training loss: 1.9339599262650005
Validation loss: 2.488975588365303

Epoch: 352| Step: 0
Training loss: 1.9730399485670223
Validation loss: 2.5164038939493207

Epoch: 6| Step: 1
Training loss: 2.3400446784815965
Validation loss: 2.4668155254699236

Epoch: 6| Step: 2
Training loss: 1.841544432345109
Validation loss: 2.4957500614450505

Epoch: 6| Step: 3
Training loss: 1.864990346234165
Validation loss: 2.4734356548362118

Epoch: 6| Step: 4
Training loss: 2.0801122814830597
Validation loss: 2.471820210377442

Epoch: 6| Step: 5
Training loss: 2.0043102548703184
Validation loss: 2.5105194385971172

Epoch: 6| Step: 6
Training loss: 1.7313273691454836
Validation loss: 2.549859116676029

Epoch: 6| Step: 7
Training loss: 1.7111687351545106
Validation loss: 2.496409980548761

Epoch: 6| Step: 8
Training loss: 1.971350995308573
Validation loss: 2.5004325933371416

Epoch: 6| Step: 9
Training loss: 2.1074380529311267
Validation loss: 2.500373659614748

Epoch: 6| Step: 10
Training loss: 1.8877134998153862
Validation loss: 2.5048258932982357

Epoch: 6| Step: 11
Training loss: 2.439394288159056
Validation loss: 2.5143593159686546

Epoch: 6| Step: 12
Training loss: 2.501975232874612
Validation loss: 2.5210575955559578

Epoch: 6| Step: 13
Training loss: 2.4176796291958764
Validation loss: 2.5127388452238213

Epoch: 353| Step: 0
Training loss: 1.7866850135463792
Validation loss: 2.472509796124167

Epoch: 6| Step: 1
Training loss: 2.4052080152491286
Validation loss: 2.530161553830845

Epoch: 6| Step: 2
Training loss: 2.087304056987951
Validation loss: 2.492417132473092

Epoch: 6| Step: 3
Training loss: 1.6789586814762936
Validation loss: 2.4520235250399365

Epoch: 6| Step: 4
Training loss: 1.552204775912823
Validation loss: 2.518785816881387

Epoch: 6| Step: 5
Training loss: 1.971460867798884
Validation loss: 2.4872603488725815

Epoch: 6| Step: 6
Training loss: 2.503158386236415
Validation loss: 2.5222783135105216

Epoch: 6| Step: 7
Training loss: 1.9512448225618595
Validation loss: 2.4592503501864327

Epoch: 6| Step: 8
Training loss: 2.1955058056852983
Validation loss: 2.4653414665506

Epoch: 6| Step: 9
Training loss: 2.1691741616521023
Validation loss: 2.4994163098413815

Epoch: 6| Step: 10
Training loss: 1.9900682134774208
Validation loss: 2.518748701217334

Epoch: 6| Step: 11
Training loss: 2.1266033631153864
Validation loss: 2.4926578349095085

Epoch: 6| Step: 12
Training loss: 1.8321522101384242
Validation loss: 2.479625919609007

Epoch: 6| Step: 13
Training loss: 2.8216372942160874
Validation loss: 2.5016993007988217

Epoch: 354| Step: 0
Training loss: 2.3535565511223764
Validation loss: 2.518538988355983

Epoch: 6| Step: 1
Training loss: 1.7367426202654874
Validation loss: 2.4375241222928627

Epoch: 6| Step: 2
Training loss: 2.3153528709974918
Validation loss: 2.5109927258950484

Epoch: 6| Step: 3
Training loss: 2.27342973950297
Validation loss: 2.4917681342446563

Epoch: 6| Step: 4
Training loss: 1.1990750006092954
Validation loss: 2.4779572158557794

Epoch: 6| Step: 5
Training loss: 2.133726043119735
Validation loss: 2.5024202280976717

Epoch: 6| Step: 6
Training loss: 2.148653886475145
Validation loss: 2.5197115905532046

Epoch: 6| Step: 7
Training loss: 1.584481910243585
Validation loss: 2.490947342690841

Epoch: 6| Step: 8
Training loss: 1.9956973404500908
Validation loss: 2.4967819842360925

Epoch: 6| Step: 9
Training loss: 2.5111421246521743
Validation loss: 2.485419282660066

Epoch: 6| Step: 10
Training loss: 1.729927822327289
Validation loss: 2.4770656147244168

Epoch: 6| Step: 11
Training loss: 1.9741683754270132
Validation loss: 2.515731631942357

Epoch: 6| Step: 12
Training loss: 2.7120988540412383
Validation loss: 2.500020276264289

Epoch: 6| Step: 13
Training loss: 2.0503767504725015
Validation loss: 2.5169088116630713

Epoch: 355| Step: 0
Training loss: 1.598976019182672
Validation loss: 2.5107639382144074

Epoch: 6| Step: 1
Training loss: 2.5570509124568646
Validation loss: 2.495208018714807

Epoch: 6| Step: 2
Training loss: 2.2345212875175067
Validation loss: 2.492256481712563

Epoch: 6| Step: 3
Training loss: 1.6624130168904496
Validation loss: 2.5430648934487254

Epoch: 6| Step: 4
Training loss: 2.3396798969653245
Validation loss: 2.5158030027172265

Epoch: 6| Step: 5
Training loss: 1.9019417778674785
Validation loss: 2.500132854582226

Epoch: 6| Step: 6
Training loss: 0.927048728954262
Validation loss: 2.466477050397025

Epoch: 6| Step: 7
Training loss: 1.7797154291253958
Validation loss: 2.5167405204093214

Epoch: 6| Step: 8
Training loss: 1.9234868555375946
Validation loss: 2.526423985167098

Epoch: 6| Step: 9
Training loss: 2.6245018622634686
Validation loss: 2.515511481342159

Epoch: 6| Step: 10
Training loss: 2.2920949593490536
Validation loss: 2.5033253186250537

Epoch: 6| Step: 11
Training loss: 2.3586068829337914
Validation loss: 2.501697581251447

Epoch: 6| Step: 12
Training loss: 2.431271150394024
Validation loss: 2.450769610820937

Epoch: 6| Step: 13
Training loss: 1.0617261200032213
Validation loss: 2.4787970915718587

Epoch: 356| Step: 0
Training loss: 1.88732079166749
Validation loss: 2.5116672147286767

Epoch: 6| Step: 1
Training loss: 2.3486592059327793
Validation loss: 2.50538495015784

Epoch: 6| Step: 2
Training loss: 2.339093274237061
Validation loss: 2.5038576880163097

Epoch: 6| Step: 3
Training loss: 3.013980080845654
Validation loss: 2.50669860482842

Epoch: 6| Step: 4
Training loss: 1.6809748484711564
Validation loss: 2.4829026059765424

Epoch: 6| Step: 5
Training loss: 1.9782391700520499
Validation loss: 2.4844177184634346

Epoch: 6| Step: 6
Training loss: 1.5446916063776215
Validation loss: 2.4481037842487066

Epoch: 6| Step: 7
Training loss: 1.8980540449529502
Validation loss: 2.5127184287681796

Epoch: 6| Step: 8
Training loss: 1.8150553612370806
Validation loss: 2.4913444531984528

Epoch: 6| Step: 9
Training loss: 1.4331038882817095
Validation loss: 2.542174679039187

Epoch: 6| Step: 10
Training loss: 2.109846048388458
Validation loss: 2.4868407769471395

Epoch: 6| Step: 11
Training loss: 1.9255305314656013
Validation loss: 2.5241898134302154

Epoch: 6| Step: 12
Training loss: 2.282050214490803
Validation loss: 2.4873291240145776

Epoch: 6| Step: 13
Training loss: 1.6967230347648552
Validation loss: 2.516465922107981

Epoch: 357| Step: 0
Training loss: 2.1789099834488117
Validation loss: 2.509904119731392

Epoch: 6| Step: 1
Training loss: 1.8542623673790737
Validation loss: 2.487993885689392

Epoch: 6| Step: 2
Training loss: 1.4613498371043907
Validation loss: 2.4652198047129272

Epoch: 6| Step: 3
Training loss: 2.1611072178500206
Validation loss: 2.502412870382966

Epoch: 6| Step: 4
Training loss: 1.9862774717760996
Validation loss: 2.4476365082044738

Epoch: 6| Step: 5
Training loss: 1.5868808590276369
Validation loss: 2.478639033785821

Epoch: 6| Step: 6
Training loss: 2.156490920608692
Validation loss: 2.5137293587909526

Epoch: 6| Step: 7
Training loss: 2.3914928980137073
Validation loss: 2.463930618359065

Epoch: 6| Step: 8
Training loss: 2.0855634832640817
Validation loss: 2.4954796716990555

Epoch: 6| Step: 9
Training loss: 2.7988708876160104
Validation loss: 2.5766221405320247

Epoch: 6| Step: 10
Training loss: 1.9527185245976346
Validation loss: 2.4789963037476466

Epoch: 6| Step: 11
Training loss: 1.65460821867748
Validation loss: 2.492781887717004

Epoch: 6| Step: 12
Training loss: 2.111144955123975
Validation loss: 2.513417874612204

Epoch: 6| Step: 13
Training loss: 2.0985321546212945
Validation loss: 2.521418974730036

Epoch: 358| Step: 0
Training loss: 2.0187331491245364
Validation loss: 2.4701635266049635

Epoch: 6| Step: 1
Training loss: 1.6793002369703494
Validation loss: 2.4800958132313218

Epoch: 6| Step: 2
Training loss: 1.8879013620044034
Validation loss: 2.4756528043380204

Epoch: 6| Step: 3
Training loss: 2.596679595683291
Validation loss: 2.5014570481725693

Epoch: 6| Step: 4
Training loss: 1.3518425094643598
Validation loss: 2.4870767739269075

Epoch: 6| Step: 5
Training loss: 2.213582859030017
Validation loss: 2.4918860215430265

Epoch: 6| Step: 6
Training loss: 2.088259201418629
Validation loss: 2.502678247688546

Epoch: 6| Step: 7
Training loss: 2.405095405510337
Validation loss: 2.489284162909266

Epoch: 6| Step: 8
Training loss: 2.3285206708131874
Validation loss: 2.5110044047090607

Epoch: 6| Step: 9
Training loss: 2.2361336569376737
Validation loss: 2.4809246439776396

Epoch: 6| Step: 10
Training loss: 2.1866765243416624
Validation loss: 2.4906493074302456

Epoch: 6| Step: 11
Training loss: 1.9490312321735732
Validation loss: 2.4806692840592963

Epoch: 6| Step: 12
Training loss: 1.4056482511084045
Validation loss: 2.47451590730826

Epoch: 6| Step: 13
Training loss: 1.7677574446117732
Validation loss: 2.4499447525656204

Epoch: 359| Step: 0
Training loss: 2.2617331917784282
Validation loss: 2.501470596771153

Epoch: 6| Step: 1
Training loss: 2.041168645205826
Validation loss: 2.5133521797820753

Epoch: 6| Step: 2
Training loss: 1.5708949588792611
Validation loss: 2.507033444210831

Epoch: 6| Step: 3
Training loss: 2.510526240530963
Validation loss: 2.4948344013230126

Epoch: 6| Step: 4
Training loss: 2.030015658426262
Validation loss: 2.484080474601355

Epoch: 6| Step: 5
Training loss: 1.7565879116585335
Validation loss: 2.543027882129253

Epoch: 6| Step: 6
Training loss: 1.832307123751898
Validation loss: 2.531802103165706

Epoch: 6| Step: 7
Training loss: 2.059227746263202
Validation loss: 2.515746508918303

Epoch: 6| Step: 8
Training loss: 2.5281223707338674
Validation loss: 2.5064492072292106

Epoch: 6| Step: 9
Training loss: 1.9210076584670766
Validation loss: 2.4899854678076565

Epoch: 6| Step: 10
Training loss: 2.211392736577604
Validation loss: 2.4902447613783636

Epoch: 6| Step: 11
Training loss: 2.3166039625322172
Validation loss: 2.53661401766166

Epoch: 6| Step: 12
Training loss: 1.731732529142487
Validation loss: 2.4965229794175667

Epoch: 6| Step: 13
Training loss: 1.751019044904331
Validation loss: 2.499437771406687

Epoch: 360| Step: 0
Training loss: 2.431579245899536
Validation loss: 2.498612266869394

Epoch: 6| Step: 1
Training loss: 1.8045905281204733
Validation loss: 2.465585459503852

Epoch: 6| Step: 2
Training loss: 2.029818103514626
Validation loss: 2.470161409405401

Epoch: 6| Step: 3
Training loss: 2.2396320308151894
Validation loss: 2.5166325529421787

Epoch: 6| Step: 4
Training loss: 2.155726161849318
Validation loss: 2.5261083572323986

Epoch: 6| Step: 5
Training loss: 2.1021860325063746
Validation loss: 2.501494270772569

Epoch: 6| Step: 6
Training loss: 2.123434836727715
Validation loss: 2.4434738902870876

Epoch: 6| Step: 7
Training loss: 1.639995345132316
Validation loss: 2.4410589959064275

Epoch: 6| Step: 8
Training loss: 1.5127019321796733
Validation loss: 2.479686980445782

Epoch: 6| Step: 9
Training loss: 2.2934647759576228
Validation loss: 2.500316051276269

Epoch: 6| Step: 10
Training loss: 2.1328919783654614
Validation loss: 2.512817851701768

Epoch: 6| Step: 11
Training loss: 2.01695148674075
Validation loss: 2.528787117361556

Epoch: 6| Step: 12
Training loss: 2.329949400192737
Validation loss: 2.5132581536379717

Epoch: 6| Step: 13
Training loss: 1.270594319030849
Validation loss: 2.5036970571442114

Epoch: 361| Step: 0
Training loss: 2.096224105938899
Validation loss: 2.5059598966620587

Epoch: 6| Step: 1
Training loss: 2.207752427284791
Validation loss: 2.527043583570187

Epoch: 6| Step: 2
Training loss: 2.026207166121348
Validation loss: 2.4983688858016655

Epoch: 6| Step: 3
Training loss: 1.6246093867403522
Validation loss: 2.4857103336347333

Epoch: 6| Step: 4
Training loss: 1.7918005900638672
Validation loss: 2.5445453118182733

Epoch: 6| Step: 5
Training loss: 2.2093325339718564
Validation loss: 2.4574126783820485

Epoch: 6| Step: 6
Training loss: 1.9485099895241782
Validation loss: 2.5179836533026663

Epoch: 6| Step: 7
Training loss: 1.82529928810316
Validation loss: 2.476266637486384

Epoch: 6| Step: 8
Training loss: 1.7831489078431206
Validation loss: 2.5201286267204486

Epoch: 6| Step: 9
Training loss: 2.2858349436180494
Validation loss: 2.5217966235697413

Epoch: 6| Step: 10
Training loss: 1.7481207293886862
Validation loss: 2.4429676946646017

Epoch: 6| Step: 11
Training loss: 2.7106123407695857
Validation loss: 2.49382751654419

Epoch: 6| Step: 12
Training loss: 2.049992524110142
Validation loss: 2.524501078972711

Epoch: 6| Step: 13
Training loss: 1.621021168014622
Validation loss: 2.492386099625378

Epoch: 362| Step: 0
Training loss: 1.7502206935687536
Validation loss: 2.5461116179955563

Epoch: 6| Step: 1
Training loss: 1.7282180788658867
Validation loss: 2.5341175850766935

Epoch: 6| Step: 2
Training loss: 2.3112726820910217
Validation loss: 2.5051530755979363

Epoch: 6| Step: 3
Training loss: 2.4445670944809317
Validation loss: 2.489711430891202

Epoch: 6| Step: 4
Training loss: 2.3264029874105567
Validation loss: 2.508450620873941

Epoch: 6| Step: 5
Training loss: 2.093528849750767
Validation loss: 2.5355159503646028

Epoch: 6| Step: 6
Training loss: 0.8896819358573977
Validation loss: 2.5032745491583333

Epoch: 6| Step: 7
Training loss: 1.679677280128793
Validation loss: 2.486215612455116

Epoch: 6| Step: 8
Training loss: 2.9013550256392695
Validation loss: 2.5388689430237013

Epoch: 6| Step: 9
Training loss: 1.6172933497779058
Validation loss: 2.5050949723571514

Epoch: 6| Step: 10
Training loss: 1.9370106725206715
Validation loss: 2.5053544181729737

Epoch: 6| Step: 11
Training loss: 2.3192672687203006
Validation loss: 2.4767889404084906

Epoch: 6| Step: 12
Training loss: 1.7587866224476412
Validation loss: 2.5231030462639636

Epoch: 6| Step: 13
Training loss: 2.2157005523153432
Validation loss: 2.50220925686888

Epoch: 363| Step: 0
Training loss: 2.0943673205939253
Validation loss: 2.5056497528072548

Epoch: 6| Step: 1
Training loss: 2.4936086973154286
Validation loss: 2.4731267012933813

Epoch: 6| Step: 2
Training loss: 1.5965007903410415
Validation loss: 2.4863933563729668

Epoch: 6| Step: 3
Training loss: 1.9373746031513346
Validation loss: 2.498287895462206

Epoch: 6| Step: 4
Training loss: 1.5662074545571698
Validation loss: 2.48927036929884

Epoch: 6| Step: 5
Training loss: 2.50580171680792
Validation loss: 2.526089034266996

Epoch: 6| Step: 6
Training loss: 1.547954298394566
Validation loss: 2.5307168088836463

Epoch: 6| Step: 7
Training loss: 1.3755240742092623
Validation loss: 2.5123162067834772

Epoch: 6| Step: 8
Training loss: 1.7997651450273309
Validation loss: 2.4870562622579855

Epoch: 6| Step: 9
Training loss: 2.5628453463935843
Validation loss: 2.517454639282001

Epoch: 6| Step: 10
Training loss: 2.351026607043218
Validation loss: 2.5116902873833866

Epoch: 6| Step: 11
Training loss: 2.2763128286423098
Validation loss: 2.5151354767511607

Epoch: 6| Step: 12
Training loss: 1.967694923216516
Validation loss: 2.4953656526752477

Epoch: 6| Step: 13
Training loss: 2.11072525324011
Validation loss: 2.4724783635854615

Epoch: 364| Step: 0
Training loss: 1.9338937237720615
Validation loss: 2.4725496152837665

Epoch: 6| Step: 1
Training loss: 1.8750160852378075
Validation loss: 2.4582847839311253

Epoch: 6| Step: 2
Training loss: 1.975636382125993
Validation loss: 2.500519757949239

Epoch: 6| Step: 3
Training loss: 1.6520017445811372
Validation loss: 2.4799759838901014

Epoch: 6| Step: 4
Training loss: 2.0479721739636965
Validation loss: 2.493818654189018

Epoch: 6| Step: 5
Training loss: 1.9466310498275814
Validation loss: 2.4919299682044813

Epoch: 6| Step: 6
Training loss: 1.894346625387096
Validation loss: 2.5076222700748856

Epoch: 6| Step: 7
Training loss: 2.137794795538054
Validation loss: 2.4876078991144652

Epoch: 6| Step: 8
Training loss: 1.8491426904312158
Validation loss: 2.5141142136056027

Epoch: 6| Step: 9
Training loss: 2.145566040971341
Validation loss: 2.550924601050163

Epoch: 6| Step: 10
Training loss: 2.5123128944683453
Validation loss: 2.486229356505073

Epoch: 6| Step: 11
Training loss: 2.444016280630424
Validation loss: 2.522443014541293

Epoch: 6| Step: 12
Training loss: 2.391159297102276
Validation loss: 2.510954597594066

Epoch: 6| Step: 13
Training loss: 1.1756771206291399
Validation loss: 2.467075419114665

Epoch: 365| Step: 0
Training loss: 1.9024382456157014
Validation loss: 2.5186425675121185

Epoch: 6| Step: 1
Training loss: 1.7956544130534038
Validation loss: 2.497034932540786

Epoch: 6| Step: 2
Training loss: 2.2232960080278885
Validation loss: 2.4986451169213018

Epoch: 6| Step: 3
Training loss: 1.462595931599312
Validation loss: 2.488320429396852

Epoch: 6| Step: 4
Training loss: 2.692052578105129
Validation loss: 2.4959048385959615

Epoch: 6| Step: 5
Training loss: 2.043638976461665
Validation loss: 2.519653450642467

Epoch: 6| Step: 6
Training loss: 1.8901837677398001
Validation loss: 2.5140957630978185

Epoch: 6| Step: 7
Training loss: 1.5740791050616545
Validation loss: 2.5152967510560726

Epoch: 6| Step: 8
Training loss: 2.171049770858316
Validation loss: 2.5647141140004095

Epoch: 6| Step: 9
Training loss: 2.2200641232757894
Validation loss: 2.5123900296645325

Epoch: 6| Step: 10
Training loss: 1.8705818256426423
Validation loss: 2.471601578441943

Epoch: 6| Step: 11
Training loss: 1.9000921377629363
Validation loss: 2.5048468070129153

Epoch: 6| Step: 12
Training loss: 2.2809889134493417
Validation loss: 2.4662036965412737

Epoch: 6| Step: 13
Training loss: 1.8721740407369194
Validation loss: 2.484781934788054

Epoch: 366| Step: 0
Training loss: 1.7760516154289336
Validation loss: 2.5434661691768317

Epoch: 6| Step: 1
Training loss: 2.094626513672785
Validation loss: 2.4878503121664024

Epoch: 6| Step: 2
Training loss: 1.9172375561336081
Validation loss: 2.479307218438184

Epoch: 6| Step: 3
Training loss: 1.800382226521723
Validation loss: 2.4831667615523307

Epoch: 6| Step: 4
Training loss: 2.232042709283784
Validation loss: 2.5116358971266735

Epoch: 6| Step: 5
Training loss: 1.8112945494296893
Validation loss: 2.506400462331669

Epoch: 6| Step: 6
Training loss: 2.3407715246076064
Validation loss: 2.5090714948560833

Epoch: 6| Step: 7
Training loss: 2.0975741862293784
Validation loss: 2.4820206297390377

Epoch: 6| Step: 8
Training loss: 2.2875533092519786
Validation loss: 2.48910866367872

Epoch: 6| Step: 9
Training loss: 1.2864338284319494
Validation loss: 2.4866300174907106

Epoch: 6| Step: 10
Training loss: 2.445232938502006
Validation loss: 2.494165226834945

Epoch: 6| Step: 11
Training loss: 2.2593108488607285
Validation loss: 2.539879988082343

Epoch: 6| Step: 12
Training loss: 2.108300055239957
Validation loss: 2.5115466894520813

Epoch: 6| Step: 13
Training loss: 1.8001062282369955
Validation loss: 2.49512318890427

Epoch: 367| Step: 0
Training loss: 2.302313665084074
Validation loss: 2.487076094639711

Epoch: 6| Step: 1
Training loss: 1.727692799388137
Validation loss: 2.490116035791124

Epoch: 6| Step: 2
Training loss: 2.770562715628446
Validation loss: 2.5038759027100745

Epoch: 6| Step: 3
Training loss: 1.9522755721248424
Validation loss: 2.515306262398688

Epoch: 6| Step: 4
Training loss: 1.9161770098397304
Validation loss: 2.5270526094018546

Epoch: 6| Step: 5
Training loss: 1.6265574107974539
Validation loss: 2.4928459984284514

Epoch: 6| Step: 6
Training loss: 2.1811936073336864
Validation loss: 2.474083386268459

Epoch: 6| Step: 7
Training loss: 2.234015375820376
Validation loss: 2.5199807221071957

Epoch: 6| Step: 8
Training loss: 1.6479215130772884
Validation loss: 2.4876664664417123

Epoch: 6| Step: 9
Training loss: 2.0973540075915653
Validation loss: 2.4775641468518934

Epoch: 6| Step: 10
Training loss: 1.5697403050326957
Validation loss: 2.4556768492669305

Epoch: 6| Step: 11
Training loss: 2.139886102051845
Validation loss: 2.489331987581919

Epoch: 6| Step: 12
Training loss: 1.918839701689865
Validation loss: 2.477822196094864

Epoch: 6| Step: 13
Training loss: 1.1902633438115533
Validation loss: 2.524514653684302

Epoch: 368| Step: 0
Training loss: 1.5666587416806896
Validation loss: 2.533524919393977

Epoch: 6| Step: 1
Training loss: 1.7616893825070958
Validation loss: 2.487890839992554

Epoch: 6| Step: 2
Training loss: 2.2033187023529264
Validation loss: 2.5024253627083732

Epoch: 6| Step: 3
Training loss: 1.9973075744413469
Validation loss: 2.5044462944831896

Epoch: 6| Step: 4
Training loss: 1.8566869330655564
Validation loss: 2.506888792098029

Epoch: 6| Step: 5
Training loss: 2.340809312395931
Validation loss: 2.4829753375159402

Epoch: 6| Step: 6
Training loss: 2.3159708318240675
Validation loss: 2.47589879219317

Epoch: 6| Step: 7
Training loss: 1.8423387331114176
Validation loss: 2.4881417969202504

Epoch: 6| Step: 8
Training loss: 2.3369089613530827
Validation loss: 2.4737445490660863

Epoch: 6| Step: 9
Training loss: 1.803667845570119
Validation loss: 2.4760877773355103

Epoch: 6| Step: 10
Training loss: 1.5645047868635291
Validation loss: 2.478459887650105

Epoch: 6| Step: 11
Training loss: 2.7298645311496603
Validation loss: 2.4826556103190542

Epoch: 6| Step: 12
Training loss: 1.9020994683619268
Validation loss: 2.4924241879807036

Epoch: 6| Step: 13
Training loss: 1.9264113689462579
Validation loss: 2.501602522669947

Epoch: 369| Step: 0
Training loss: 2.3357167219363433
Validation loss: 2.4568270814915456

Epoch: 6| Step: 1
Training loss: 1.9170082935000627
Validation loss: 2.4883820902622262

Epoch: 6| Step: 2
Training loss: 1.8864851465396233
Validation loss: 2.4484064419043343

Epoch: 6| Step: 3
Training loss: 2.1848647456785923
Validation loss: 2.504805595549311

Epoch: 6| Step: 4
Training loss: 2.1693075908891206
Validation loss: 2.5157450201037252

Epoch: 6| Step: 5
Training loss: 1.970697136407681
Validation loss: 2.4947432081430025

Epoch: 6| Step: 6
Training loss: 2.0727624755969796
Validation loss: 2.5033794378277765

Epoch: 6| Step: 7
Training loss: 1.9501980632061535
Validation loss: 2.4835714324207636

Epoch: 6| Step: 8
Training loss: 2.1794691625917713
Validation loss: 2.4595226100267307

Epoch: 6| Step: 9
Training loss: 1.4431087704783019
Validation loss: 2.4832532943982706

Epoch: 6| Step: 10
Training loss: 1.5123762726422514
Validation loss: 2.4722276790645163

Epoch: 6| Step: 11
Training loss: 1.6636254538127657
Validation loss: 2.5108947652663054

Epoch: 6| Step: 12
Training loss: 2.399687301609902
Validation loss: 2.499735769028854

Epoch: 6| Step: 13
Training loss: 2.5133741272095595
Validation loss: 2.4986414396904952

Epoch: 370| Step: 0
Training loss: 1.9370516596706104
Validation loss: 2.5233703551519677

Epoch: 6| Step: 1
Training loss: 2.457063271415445
Validation loss: 2.4671422428064695

Epoch: 6| Step: 2
Training loss: 1.8393892346374772
Validation loss: 2.481695194010863

Epoch: 6| Step: 3
Training loss: 2.0076854383585525
Validation loss: 2.480708698387551

Epoch: 6| Step: 4
Training loss: 2.6521233311164374
Validation loss: 2.5211725595740258

Epoch: 6| Step: 5
Training loss: 1.8824677211025538
Validation loss: 2.477912997069623

Epoch: 6| Step: 6
Training loss: 2.1730115372991814
Validation loss: 2.51215688417277

Epoch: 6| Step: 7
Training loss: 2.200365976757308
Validation loss: 2.492607140774878

Epoch: 6| Step: 8
Training loss: 2.0029853950687926
Validation loss: 2.4806277081314985

Epoch: 6| Step: 9
Training loss: 1.5106332119460852
Validation loss: 2.5053405099211172

Epoch: 6| Step: 10
Training loss: 1.5341139499462475
Validation loss: 2.5057240790275115

Epoch: 6| Step: 11
Training loss: 2.2932875247564604
Validation loss: 2.5088873638682743

Epoch: 6| Step: 12
Training loss: 1.8036246865164054
Validation loss: 2.514838907379958

Epoch: 6| Step: 13
Training loss: 1.7649908361656321
Validation loss: 2.5104222213145153

Epoch: 371| Step: 0
Training loss: 1.773034407056433
Validation loss: 2.4777830979785995

Epoch: 6| Step: 1
Training loss: 2.427262546542634
Validation loss: 2.4779293777851956

Epoch: 6| Step: 2
Training loss: 2.416015822365089
Validation loss: 2.4625546867561745

Epoch: 6| Step: 3
Training loss: 1.8350542906543794
Validation loss: 2.4982440626955342

Epoch: 6| Step: 4
Training loss: 1.7654631548947413
Validation loss: 2.471594028370422

Epoch: 6| Step: 5
Training loss: 1.6690963757106785
Validation loss: 2.5244056781970645

Epoch: 6| Step: 6
Training loss: 1.985761803659289
Validation loss: 2.478887278724279

Epoch: 6| Step: 7
Training loss: 1.9388104590821502
Validation loss: 2.473345648259464

Epoch: 6| Step: 8
Training loss: 1.943555291043206
Validation loss: 2.4925510983353454

Epoch: 6| Step: 9
Training loss: 1.5961523462594298
Validation loss: 2.4939515378965296

Epoch: 6| Step: 10
Training loss: 2.366324591652439
Validation loss: 2.503835726796468

Epoch: 6| Step: 11
Training loss: 2.155154405979033
Validation loss: 2.504143710987805

Epoch: 6| Step: 12
Training loss: 2.2217100573130306
Validation loss: 2.4745642826148786

Epoch: 6| Step: 13
Training loss: 1.690356979701712
Validation loss: 2.52124661324303

Epoch: 372| Step: 0
Training loss: 2.056884055661042
Validation loss: 2.5008149223711817

Epoch: 6| Step: 1
Training loss: 2.2328045000663086
Validation loss: 2.5111082834244853

Epoch: 6| Step: 2
Training loss: 1.8406740813519884
Validation loss: 2.494651991076291

Epoch: 6| Step: 3
Training loss: 2.136324272494069
Validation loss: 2.503669596916386

Epoch: 6| Step: 4
Training loss: 1.839999765313175
Validation loss: 2.4876774004506452

Epoch: 6| Step: 5
Training loss: 1.581244982081959
Validation loss: 2.5152050379342654

Epoch: 6| Step: 6
Training loss: 1.616536769695357
Validation loss: 2.4837107829138785

Epoch: 6| Step: 7
Training loss: 2.4681994633129314
Validation loss: 2.510952302424417

Epoch: 6| Step: 8
Training loss: 1.840083080364923
Validation loss: 2.5206925642601505

Epoch: 6| Step: 9
Training loss: 2.149978806147243
Validation loss: 2.495829842985954

Epoch: 6| Step: 10
Training loss: 2.367504942102319
Validation loss: 2.4884063111800065

Epoch: 6| Step: 11
Training loss: 1.8691970673173803
Validation loss: 2.5190428461166396

Epoch: 6| Step: 12
Training loss: 2.035602074114237
Validation loss: 2.545810916297704

Epoch: 6| Step: 13
Training loss: 1.6521458428363964
Validation loss: 2.4710693067264593

Epoch: 373| Step: 0
Training loss: 1.7418133115709395
Validation loss: 2.5378670441985856

Epoch: 6| Step: 1
Training loss: 2.0732705917964163
Validation loss: 2.502887774595425

Epoch: 6| Step: 2
Training loss: 2.0343435352429458
Validation loss: 2.5244313763630304

Epoch: 6| Step: 3
Training loss: 2.8599082574601704
Validation loss: 2.4460292524356535

Epoch: 6| Step: 4
Training loss: 1.5314430582219412
Validation loss: 2.491953143359798

Epoch: 6| Step: 5
Training loss: 2.0574751245007685
Validation loss: 2.4946083122897353

Epoch: 6| Step: 6
Training loss: 2.155919809906112
Validation loss: 2.5274827046001045

Epoch: 6| Step: 7
Training loss: 2.1548749436914476
Validation loss: 2.5353111635503316

Epoch: 6| Step: 8
Training loss: 2.4422238865226618
Validation loss: 2.4602615790269544

Epoch: 6| Step: 9
Training loss: 1.4813512421465926
Validation loss: 2.5108641695900573

Epoch: 6| Step: 10
Training loss: 1.7848682797341031
Validation loss: 2.46759688422055

Epoch: 6| Step: 11
Training loss: 1.9787790286934448
Validation loss: 2.461667416599582

Epoch: 6| Step: 12
Training loss: 1.1473784981190216
Validation loss: 2.476878988500066

Epoch: 6| Step: 13
Training loss: 2.2266066162022042
Validation loss: 2.5050437132442966

Epoch: 374| Step: 0
Training loss: 2.1768687627693692
Validation loss: 2.4620087661396837

Epoch: 6| Step: 1
Training loss: 2.534015416460479
Validation loss: 2.5432088971760662

Epoch: 6| Step: 2
Training loss: 1.5096980347499727
Validation loss: 2.489359752205698

Epoch: 6| Step: 3
Training loss: 1.8738977371209486
Validation loss: 2.49376498594697

Epoch: 6| Step: 4
Training loss: 2.4336186341900916
Validation loss: 2.5250546928175397

Epoch: 6| Step: 5
Training loss: 2.0955379310766613
Validation loss: 2.498960598866525

Epoch: 6| Step: 6
Training loss: 1.6622816415667632
Validation loss: 2.5083492260424913

Epoch: 6| Step: 7
Training loss: 1.5341437886176292
Validation loss: 2.4799454057885386

Epoch: 6| Step: 8
Training loss: 1.5719435083464728
Validation loss: 2.5097663338974097

Epoch: 6| Step: 9
Training loss: 1.6843923988929914
Validation loss: 2.5145030713738343

Epoch: 6| Step: 10
Training loss: 1.871777881274542
Validation loss: 2.500114067100544

Epoch: 6| Step: 11
Training loss: 1.989142150962223
Validation loss: 2.5055856131321357

Epoch: 6| Step: 12
Training loss: 2.172931331927612
Validation loss: 2.4916633360511193

Epoch: 6| Step: 13
Training loss: 2.2846468365827826
Validation loss: 2.484092632893618

Epoch: 375| Step: 0
Training loss: 3.184780980698599
Validation loss: 2.5061786982605625

Epoch: 6| Step: 1
Training loss: 1.7995042224102082
Validation loss: 2.471290181863253

Epoch: 6| Step: 2
Training loss: 1.9677145520810888
Validation loss: 2.483125914003316

Epoch: 6| Step: 3
Training loss: 1.8686757560959844
Validation loss: 2.477297548723257

Epoch: 6| Step: 4
Training loss: 2.288811054675844
Validation loss: 2.4864758435382295

Epoch: 6| Step: 5
Training loss: 1.6152554825461092
Validation loss: 2.486476388955049

Epoch: 6| Step: 6
Training loss: 1.7581726383463765
Validation loss: 2.470249132596223

Epoch: 6| Step: 7
Training loss: 2.1720710501246385
Validation loss: 2.466896612739964

Epoch: 6| Step: 8
Training loss: 1.9337629147907758
Validation loss: 2.519336184325615

Epoch: 6| Step: 9
Training loss: 1.3230496537455596
Validation loss: 2.5055185168220393

Epoch: 6| Step: 10
Training loss: 1.8988746171229829
Validation loss: 2.490584325456346

Epoch: 6| Step: 11
Training loss: 1.7855807744932712
Validation loss: 2.462598034623118

Epoch: 6| Step: 12
Training loss: 1.5255378525100314
Validation loss: 2.4750166279141106

Epoch: 6| Step: 13
Training loss: 1.4202774631052166
Validation loss: 2.519068055542721

Epoch: 376| Step: 0
Training loss: 1.7370599807019895
Validation loss: 2.4955264315019465

Epoch: 6| Step: 1
Training loss: 2.3119413371184088
Validation loss: 2.479228879196778

Epoch: 6| Step: 2
Training loss: 2.200575848555687
Validation loss: 2.4806793787506516

Epoch: 6| Step: 3
Training loss: 2.072789851260029
Validation loss: 2.534838990830339

Epoch: 6| Step: 4
Training loss: 1.6292765171386092
Validation loss: 2.5058188554189966

Epoch: 6| Step: 5
Training loss: 1.3052733699165542
Validation loss: 2.5084570298380062

Epoch: 6| Step: 6
Training loss: 2.714138900041684
Validation loss: 2.508548512412444

Epoch: 6| Step: 7
Training loss: 1.2033795669546667
Validation loss: 2.476477480776973

Epoch: 6| Step: 8
Training loss: 2.181030625294028
Validation loss: 2.5116961777405034

Epoch: 6| Step: 9
Training loss: 2.205490681900338
Validation loss: 2.4678896433786064

Epoch: 6| Step: 10
Training loss: 1.8593061418365306
Validation loss: 2.450197595526676

Epoch: 6| Step: 11
Training loss: 1.8487060016505978
Validation loss: 2.501922175338053

Epoch: 6| Step: 12
Training loss: 2.00909620281983
Validation loss: 2.462600723604451

Epoch: 6| Step: 13
Training loss: 2.0247487418569663
Validation loss: 2.50138627963639

Epoch: 377| Step: 0
Training loss: 1.5496187633386749
Validation loss: 2.5082723886989013

Epoch: 6| Step: 1
Training loss: 2.355286852137818
Validation loss: 2.5194196382046457

Epoch: 6| Step: 2
Training loss: 2.253598937664926
Validation loss: 2.5141152333047483

Epoch: 6| Step: 3
Training loss: 2.20445243939536
Validation loss: 2.49513037289807

Epoch: 6| Step: 4
Training loss: 2.0462417205288843
Validation loss: 2.489099290147666

Epoch: 6| Step: 5
Training loss: 1.8306320475777689
Validation loss: 2.4867157885810904

Epoch: 6| Step: 6
Training loss: 1.6152816082876278
Validation loss: 2.4418546122021456

Epoch: 6| Step: 7
Training loss: 2.6452327457128795
Validation loss: 2.4378839952324394

Epoch: 6| Step: 8
Training loss: 1.6983019229853096
Validation loss: 2.4603658772409003

Epoch: 6| Step: 9
Training loss: 1.9829696725246986
Validation loss: 2.479937970022133

Epoch: 6| Step: 10
Training loss: 1.961838594981761
Validation loss: 2.4954368847409407

Epoch: 6| Step: 11
Training loss: 1.914636891653319
Validation loss: 2.4568308922637447

Epoch: 6| Step: 12
Training loss: 1.7024072657128937
Validation loss: 2.4739831869866338

Epoch: 6| Step: 13
Training loss: 1.2982185482135822
Validation loss: 2.520731697552351

Epoch: 378| Step: 0
Training loss: 2.2917786195169993
Validation loss: 2.5220969712828096

Epoch: 6| Step: 1
Training loss: 1.534595882265375
Validation loss: 2.5163547275551523

Epoch: 6| Step: 2
Training loss: 1.5319403046065638
Validation loss: 2.5180359206210805

Epoch: 6| Step: 3
Training loss: 1.711787321944899
Validation loss: 2.471666556439037

Epoch: 6| Step: 4
Training loss: 2.151990248767925
Validation loss: 2.5333684576246336

Epoch: 6| Step: 5
Training loss: 2.103988778428877
Validation loss: 2.513940249936488

Epoch: 6| Step: 6
Training loss: 1.4935619156030144
Validation loss: 2.4977105999527054

Epoch: 6| Step: 7
Training loss: 2.9282965448015807
Validation loss: 2.546759734598837

Epoch: 6| Step: 8
Training loss: 1.2314833560303646
Validation loss: 2.467516155545565

Epoch: 6| Step: 9
Training loss: 2.278017863618038
Validation loss: 2.470391526961438

Epoch: 6| Step: 10
Training loss: 1.962150654405078
Validation loss: 2.498527400782654

Epoch: 6| Step: 11
Training loss: 2.227283561800506
Validation loss: 2.4799728558027705

Epoch: 6| Step: 12
Training loss: 1.9850118020809435
Validation loss: 2.4811266363126805

Epoch: 6| Step: 13
Training loss: 2.2797766330124194
Validation loss: 2.4987407466202036

Epoch: 379| Step: 0
Training loss: 2.111621141171293
Validation loss: 2.511658041745756

Epoch: 6| Step: 1
Training loss: 1.9425439705407266
Validation loss: 2.4754294331878977

Epoch: 6| Step: 2
Training loss: 1.6258962800422418
Validation loss: 2.5266966880199675

Epoch: 6| Step: 3
Training loss: 1.4357835224269377
Validation loss: 2.4764523978405615

Epoch: 6| Step: 4
Training loss: 1.7823057559459945
Validation loss: 2.508646670940339

Epoch: 6| Step: 5
Training loss: 1.902839674333508
Validation loss: 2.540282364862419

Epoch: 6| Step: 6
Training loss: 2.8007013157886025
Validation loss: 2.5096385820392477

Epoch: 6| Step: 7
Training loss: 1.6712260903222385
Validation loss: 2.4596695359707383

Epoch: 6| Step: 8
Training loss: 2.0272698949396726
Validation loss: 2.507521165075846

Epoch: 6| Step: 9
Training loss: 2.0000710474746364
Validation loss: 2.4920765306901034

Epoch: 6| Step: 10
Training loss: 2.5983296604224333
Validation loss: 2.514396823712295

Epoch: 6| Step: 11
Training loss: 1.8948421891662859
Validation loss: 2.491418322286183

Epoch: 6| Step: 12
Training loss: 1.5864856693403242
Validation loss: 2.5234647542577067

Epoch: 6| Step: 13
Training loss: 1.855402830860297
Validation loss: 2.4511663401773713

Epoch: 380| Step: 0
Training loss: 2.1783883109399356
Validation loss: 2.4810926212700797

Epoch: 6| Step: 1
Training loss: 1.974408449841785
Validation loss: 2.490276796324251

Epoch: 6| Step: 2
Training loss: 2.0591448457005037
Validation loss: 2.52198174343186

Epoch: 6| Step: 3
Training loss: 1.440964545825698
Validation loss: 2.488374243911805

Epoch: 6| Step: 4
Training loss: 1.8818340370790223
Validation loss: 2.521356753223154

Epoch: 6| Step: 5
Training loss: 1.8433910602385504
Validation loss: 2.467931968870044

Epoch: 6| Step: 6
Training loss: 1.6151720839900865
Validation loss: 2.533356499390608

Epoch: 6| Step: 7
Training loss: 2.2663718209450816
Validation loss: 2.5066383139756203

Epoch: 6| Step: 8
Training loss: 1.784988762742689
Validation loss: 2.4974914886271438

Epoch: 6| Step: 9
Training loss: 1.8343472350324692
Validation loss: 2.4517061493267986

Epoch: 6| Step: 10
Training loss: 2.2497085806421553
Validation loss: 2.465896731256226

Epoch: 6| Step: 11
Training loss: 2.552846822910673
Validation loss: 2.4831985667345267

Epoch: 6| Step: 12
Training loss: 2.0202227059904354
Validation loss: 2.4713885603813837

Epoch: 6| Step: 13
Training loss: 2.080209246160708
Validation loss: 2.517018558862227

Epoch: 381| Step: 0
Training loss: 1.7767132992854153
Validation loss: 2.4911513029716312

Epoch: 6| Step: 1
Training loss: 2.0818472202981972
Validation loss: 2.482975802135206

Epoch: 6| Step: 2
Training loss: 2.109469715393794
Validation loss: 2.4589089706364113

Epoch: 6| Step: 3
Training loss: 2.277425826672758
Validation loss: 2.4579951882984905

Epoch: 6| Step: 4
Training loss: 1.5238401223272429
Validation loss: 2.48909817883448

Epoch: 6| Step: 5
Training loss: 2.045519897110536
Validation loss: 2.5054394587206352

Epoch: 6| Step: 6
Training loss: 2.1942936715374866
Validation loss: 2.4794185235089663

Epoch: 6| Step: 7
Training loss: 1.3775790908733074
Validation loss: 2.50490564061137

Epoch: 6| Step: 8
Training loss: 1.6282117355585382
Validation loss: 2.5035947028311143

Epoch: 6| Step: 9
Training loss: 2.753252187122712
Validation loss: 2.528912020416014

Epoch: 6| Step: 10
Training loss: 1.453083981170892
Validation loss: 2.500706918300518

Epoch: 6| Step: 11
Training loss: 2.3441899204648986
Validation loss: 2.4533152399704488

Epoch: 6| Step: 12
Training loss: 1.6071366234310296
Validation loss: 2.4982736246280837

Epoch: 6| Step: 13
Training loss: 2.0723290177553397
Validation loss: 2.4676129386296477

Epoch: 382| Step: 0
Training loss: 2.421456085399206
Validation loss: 2.4732158451265476

Epoch: 6| Step: 1
Training loss: 1.4960610806954477
Validation loss: 2.503604299077721

Epoch: 6| Step: 2
Training loss: 2.2339271149865256
Validation loss: 2.4529714824356796

Epoch: 6| Step: 3
Training loss: 2.0424267139150594
Validation loss: 2.5149874864407726

Epoch: 6| Step: 4
Training loss: 1.801297128393059
Validation loss: 2.48323765804599

Epoch: 6| Step: 5
Training loss: 1.7912757875938168
Validation loss: 2.4627356946189654

Epoch: 6| Step: 6
Training loss: 2.5460522030545074
Validation loss: 2.522396253669151

Epoch: 6| Step: 7
Training loss: 1.9596347813061332
Validation loss: 2.4945197469197127

Epoch: 6| Step: 8
Training loss: 1.7345413265720784
Validation loss: 2.503860065456033

Epoch: 6| Step: 9
Training loss: 1.7002503519280823
Validation loss: 2.479269226371195

Epoch: 6| Step: 10
Training loss: 1.7296558132560138
Validation loss: 2.4565796284702826

Epoch: 6| Step: 11
Training loss: 2.1821480812293848
Validation loss: 2.470270025628562

Epoch: 6| Step: 12
Training loss: 1.9056809623510789
Validation loss: 2.485522179154873

Epoch: 6| Step: 13
Training loss: 2.369654009387561
Validation loss: 2.5053743871032212

Epoch: 383| Step: 0
Training loss: 1.8060428434593927
Validation loss: 2.492190834948666

Epoch: 6| Step: 1
Training loss: 1.541049120482177
Validation loss: 2.4773185706529546

Epoch: 6| Step: 2
Training loss: 1.9640402999752213
Validation loss: 2.481190699465408

Epoch: 6| Step: 3
Training loss: 2.0467538579371163
Validation loss: 2.490665639377291

Epoch: 6| Step: 4
Training loss: 2.328967665176357
Validation loss: 2.4976665938549303

Epoch: 6| Step: 5
Training loss: 2.7507375248362016
Validation loss: 2.487932620161822

Epoch: 6| Step: 6
Training loss: 2.1021767324889504
Validation loss: 2.4815175505759646

Epoch: 6| Step: 7
Training loss: 1.5341458089233595
Validation loss: 2.502751234241736

Epoch: 6| Step: 8
Training loss: 2.0191190730631208
Validation loss: 2.493469706688277

Epoch: 6| Step: 9
Training loss: 2.144048473166044
Validation loss: 2.49424636337489

Epoch: 6| Step: 10
Training loss: 1.7422902714134807
Validation loss: 2.4700387125152146

Epoch: 6| Step: 11
Training loss: 1.7517553789860034
Validation loss: 2.507364439477695

Epoch: 6| Step: 12
Training loss: 2.14104440854523
Validation loss: 2.4823762098753837

Epoch: 6| Step: 13
Training loss: 1.3516293547748988
Validation loss: 2.4980617823794926

Epoch: 384| Step: 0
Training loss: 1.5757055337215944
Validation loss: 2.47936958839917

Epoch: 6| Step: 1
Training loss: 1.5787206602050832
Validation loss: 2.5319891584303864

Epoch: 6| Step: 2
Training loss: 2.086230768168804
Validation loss: 2.4782000127509285

Epoch: 6| Step: 3
Training loss: 1.754288867430163
Validation loss: 2.5205331028816778

Epoch: 6| Step: 4
Training loss: 2.0687219808012136
Validation loss: 2.499522864022354

Epoch: 6| Step: 5
Training loss: 1.8316880415044428
Validation loss: 2.540443914712291

Epoch: 6| Step: 6
Training loss: 1.9334706276891296
Validation loss: 2.5143386990633183

Epoch: 6| Step: 7
Training loss: 2.0041502567922738
Validation loss: 2.4985258155184553

Epoch: 6| Step: 8
Training loss: 1.6808630090204804
Validation loss: 2.4446736274074343

Epoch: 6| Step: 9
Training loss: 1.9525911135545448
Validation loss: 2.4708390956229676

Epoch: 6| Step: 10
Training loss: 2.250185746896982
Validation loss: 2.503120067932064

Epoch: 6| Step: 11
Training loss: 1.3352607217432153
Validation loss: 2.5252658990305106

Epoch: 6| Step: 12
Training loss: 2.4984014168543833
Validation loss: 2.4508171671733963

Epoch: 6| Step: 13
Training loss: 2.537124128643833
Validation loss: 2.465613804498091

Epoch: 385| Step: 0
Training loss: 1.9307842149717134
Validation loss: 2.478882405615828

Epoch: 6| Step: 1
Training loss: 1.9244922092049126
Validation loss: 2.472418922178201

Epoch: 6| Step: 2
Training loss: 1.8901177348447655
Validation loss: 2.5113074514003637

Epoch: 6| Step: 3
Training loss: 1.559772170253962
Validation loss: 2.4959443389592186

Epoch: 6| Step: 4
Training loss: 1.7119513865012792
Validation loss: 2.528683457983298

Epoch: 6| Step: 5
Training loss: 1.9970180215495188
Validation loss: 2.5065996141973943

Epoch: 6| Step: 6
Training loss: 2.162078829638288
Validation loss: 2.494290159502519

Epoch: 6| Step: 7
Training loss: 1.9851937594842757
Validation loss: 2.469217594922483

Epoch: 6| Step: 8
Training loss: 1.8594606524061432
Validation loss: 2.4637893718380286

Epoch: 6| Step: 9
Training loss: 1.9414983531818188
Validation loss: 2.51626668613461

Epoch: 6| Step: 10
Training loss: 1.7495594832607233
Validation loss: 2.499910324293136

Epoch: 6| Step: 11
Training loss: 2.1892656012886698
Validation loss: 2.4621396645794547

Epoch: 6| Step: 12
Training loss: 2.3964542303078114
Validation loss: 2.4835863059157735

Epoch: 6| Step: 13
Training loss: 2.2963170003071567
Validation loss: 2.47198146693823

Epoch: 386| Step: 0
Training loss: 1.909121804689206
Validation loss: 2.5105032398925884

Epoch: 6| Step: 1
Training loss: 2.5483358675152203
Validation loss: 2.4885924510071264

Epoch: 6| Step: 2
Training loss: 1.5177032536945503
Validation loss: 2.494495129054539

Epoch: 6| Step: 3
Training loss: 1.5602849900524922
Validation loss: 2.4956219690911365

Epoch: 6| Step: 4
Training loss: 1.3241613144923452
Validation loss: 2.4656116074893517

Epoch: 6| Step: 5
Training loss: 2.0496326536089313
Validation loss: 2.4821037559244257

Epoch: 6| Step: 6
Training loss: 2.0100659738218076
Validation loss: 2.4861887979857356

Epoch: 6| Step: 7
Training loss: 2.315981538122512
Validation loss: 2.44929449560236

Epoch: 6| Step: 8
Training loss: 1.5663295356058788
Validation loss: 2.4679566023977877

Epoch: 6| Step: 9
Training loss: 2.113770264404903
Validation loss: 2.514791805307329

Epoch: 6| Step: 10
Training loss: 1.2514269789951866
Validation loss: 2.454588503749412

Epoch: 6| Step: 11
Training loss: 2.33880724740521
Validation loss: 2.5021693712984487

Epoch: 6| Step: 12
Training loss: 2.2089687249044974
Validation loss: 2.4878714376228936

Epoch: 6| Step: 13
Training loss: 2.1277152273326068
Validation loss: 2.469150660754785

Epoch: 387| Step: 0
Training loss: 1.6355462802460408
Validation loss: 2.53033593315368

Epoch: 6| Step: 1
Training loss: 1.7727583202230828
Validation loss: 2.48892238838433

Epoch: 6| Step: 2
Training loss: 2.0559284828453315
Validation loss: 2.481156760727893

Epoch: 6| Step: 3
Training loss: 2.1167462441611677
Validation loss: 2.466292451330662

Epoch: 6| Step: 4
Training loss: 1.8294231012013673
Validation loss: 2.49817352229162

Epoch: 6| Step: 5
Training loss: 2.5111117422990183
Validation loss: 2.5186252678021703

Epoch: 6| Step: 6
Training loss: 1.6991660625138019
Validation loss: 2.462987241154072

Epoch: 6| Step: 7
Training loss: 1.601557736273403
Validation loss: 2.4940161802976486

Epoch: 6| Step: 8
Training loss: 1.6908383726618639
Validation loss: 2.482953118288673

Epoch: 6| Step: 9
Training loss: 1.8247685063525518
Validation loss: 2.5183748188970836

Epoch: 6| Step: 10
Training loss: 1.668192077980307
Validation loss: 2.5034648921003737

Epoch: 6| Step: 11
Training loss: 2.1622480918266316
Validation loss: 2.5249401573595716

Epoch: 6| Step: 12
Training loss: 2.4302594164926954
Validation loss: 2.508536469586238

Epoch: 6| Step: 13
Training loss: 2.3308376407776703
Validation loss: 2.5153435623736833

Epoch: 388| Step: 0
Training loss: 2.061894645863277
Validation loss: 2.48661975519541

Epoch: 6| Step: 1
Training loss: 2.4824310950851594
Validation loss: 2.503068828803857

Epoch: 6| Step: 2
Training loss: 1.556154565297873
Validation loss: 2.4729986780047644

Epoch: 6| Step: 3
Training loss: 0.9559239423774962
Validation loss: 2.5044233239927425

Epoch: 6| Step: 4
Training loss: 1.3622891989206887
Validation loss: 2.48963524010062

Epoch: 6| Step: 5
Training loss: 1.9054025736285578
Validation loss: 2.496813955842552

Epoch: 6| Step: 6
Training loss: 1.9681419765773556
Validation loss: 2.5147711292525523

Epoch: 6| Step: 7
Training loss: 2.2882151418652543
Validation loss: 2.5194887036038676

Epoch: 6| Step: 8
Training loss: 1.5986946294410747
Validation loss: 2.5156205690059927

Epoch: 6| Step: 9
Training loss: 1.8338195921753366
Validation loss: 2.5178208155838986

Epoch: 6| Step: 10
Training loss: 1.963880845244807
Validation loss: 2.500964043461672

Epoch: 6| Step: 11
Training loss: 1.8903840597175625
Validation loss: 2.469369322816828

Epoch: 6| Step: 12
Training loss: 2.6169945489158315
Validation loss: 2.475613519732918

Epoch: 6| Step: 13
Training loss: 1.946232712117016
Validation loss: 2.5064271112008503

Epoch: 389| Step: 0
Training loss: 2.161860809235484
Validation loss: 2.4773207231295347

Epoch: 6| Step: 1
Training loss: 1.863478228315699
Validation loss: 2.5079917451364464

Epoch: 6| Step: 2
Training loss: 1.8980100173967223
Validation loss: 2.463856141583998

Epoch: 6| Step: 3
Training loss: 2.149812681332803
Validation loss: 2.444310602871751

Epoch: 6| Step: 4
Training loss: 1.516724099479619
Validation loss: 2.4683812069622

Epoch: 6| Step: 5
Training loss: 1.897116998510207
Validation loss: 2.459106908284194

Epoch: 6| Step: 6
Training loss: 1.678689491618757
Validation loss: 2.501170151154112

Epoch: 6| Step: 7
Training loss: 1.960736876175693
Validation loss: 2.5211250277432318

Epoch: 6| Step: 8
Training loss: 1.8899670551597543
Validation loss: 2.4885295581047013

Epoch: 6| Step: 9
Training loss: 1.8446943806334626
Validation loss: 2.453899950090152

Epoch: 6| Step: 10
Training loss: 2.5829640606526154
Validation loss: 2.4962456980285066

Epoch: 6| Step: 11
Training loss: 2.033434705343945
Validation loss: 2.495006635167441

Epoch: 6| Step: 12
Training loss: 1.811887242886728
Validation loss: 2.558582138114079

Epoch: 6| Step: 13
Training loss: 1.7541542472611136
Validation loss: 2.490359285597004

Epoch: 390| Step: 0
Training loss: 1.6042539729681007
Validation loss: 2.5094193526879174

Epoch: 6| Step: 1
Training loss: 2.219717647536266
Validation loss: 2.5064685261356434

Epoch: 6| Step: 2
Training loss: 1.6749052590293707
Validation loss: 2.505401393766561

Epoch: 6| Step: 3
Training loss: 1.926925040952319
Validation loss: 2.5101609615307767

Epoch: 6| Step: 4
Training loss: 1.5452585733568072
Validation loss: 2.511413717983491

Epoch: 6| Step: 5
Training loss: 2.5257788977005844
Validation loss: 2.510078049577792

Epoch: 6| Step: 6
Training loss: 2.136388219621838
Validation loss: 2.5136932077141716

Epoch: 6| Step: 7
Training loss: 2.13919621140937
Validation loss: 2.48906265465914

Epoch: 6| Step: 8
Training loss: 1.8618730705996502
Validation loss: 2.504946292658991

Epoch: 6| Step: 9
Training loss: 2.298683751838603
Validation loss: 2.501552952634336

Epoch: 6| Step: 10
Training loss: 1.7185294269864735
Validation loss: 2.4617271436500663

Epoch: 6| Step: 11
Training loss: 1.5936790151308489
Validation loss: 2.5107243646799824

Epoch: 6| Step: 12
Training loss: 1.6702340888236313
Validation loss: 2.500230591917006

Epoch: 6| Step: 13
Training loss: 2.2595317063391485
Validation loss: 2.4761839386094637

Epoch: 391| Step: 0
Training loss: 1.8073916961808423
Validation loss: 2.54308522857752

Epoch: 6| Step: 1
Training loss: 2.6169074520761972
Validation loss: 2.46225160670535

Epoch: 6| Step: 2
Training loss: 1.8923088960900214
Validation loss: 2.5032796226181513

Epoch: 6| Step: 3
Training loss: 1.677013593214853
Validation loss: 2.470983750937179

Epoch: 6| Step: 4
Training loss: 1.593120600266665
Validation loss: 2.49111122337018

Epoch: 6| Step: 5
Training loss: 1.742414451151944
Validation loss: 2.4961315455600164

Epoch: 6| Step: 6
Training loss: 1.6199923898965556
Validation loss: 2.5107972439497575

Epoch: 6| Step: 7
Training loss: 1.8922733655956854
Validation loss: 2.455646007215814

Epoch: 6| Step: 8
Training loss: 1.8925529297213526
Validation loss: 2.518837640083876

Epoch: 6| Step: 9
Training loss: 2.223464899169068
Validation loss: 2.5093678611184185

Epoch: 6| Step: 10
Training loss: 1.8859502834591604
Validation loss: 2.50895423929623

Epoch: 6| Step: 11
Training loss: 2.024903462310548
Validation loss: 2.4780075232642957

Epoch: 6| Step: 12
Training loss: 2.114221275665825
Validation loss: 2.452912132694761

Epoch: 6| Step: 13
Training loss: 1.961800313246783
Validation loss: 2.488786229363902

Epoch: 392| Step: 0
Training loss: 2.206284226106135
Validation loss: 2.47924326068888

Epoch: 6| Step: 1
Training loss: 2.2013734388427673
Validation loss: 2.4761228384963596

Epoch: 6| Step: 2
Training loss: 2.3955052247871267
Validation loss: 2.5159459124348094

Epoch: 6| Step: 3
Training loss: 2.1155350771659935
Validation loss: 2.474733904698627

Epoch: 6| Step: 4
Training loss: 1.6794084893860104
Validation loss: 2.5001602782892585

Epoch: 6| Step: 5
Training loss: 1.2908623354768827
Validation loss: 2.5115073334237

Epoch: 6| Step: 6
Training loss: 1.602067225870911
Validation loss: 2.476144828084614

Epoch: 6| Step: 7
Training loss: 1.909496919076596
Validation loss: 2.474967298129025

Epoch: 6| Step: 8
Training loss: 2.1877528453202917
Validation loss: 2.4589519052731057

Epoch: 6| Step: 9
Training loss: 2.26726015212461
Validation loss: 2.476296707144085

Epoch: 6| Step: 10
Training loss: 2.0518679691395256
Validation loss: 2.4945998709726336

Epoch: 6| Step: 11
Training loss: 1.6166361730524679
Validation loss: 2.4591687366198904

Epoch: 6| Step: 12
Training loss: 1.5060974012137294
Validation loss: 2.493407963947584

Epoch: 6| Step: 13
Training loss: 1.5720721202739947
Validation loss: 2.480323602901152

Epoch: 393| Step: 0
Training loss: 1.8843215656454042
Validation loss: 2.4957000300199117

Epoch: 6| Step: 1
Training loss: 2.081883523649313
Validation loss: 2.457262036921115

Epoch: 6| Step: 2
Training loss: 1.7386188307868058
Validation loss: 2.488432753023796

Epoch: 6| Step: 3
Training loss: 1.7293085553274778
Validation loss: 2.477292540026088

Epoch: 6| Step: 4
Training loss: 2.15381816895613
Validation loss: 2.4741936415124273

Epoch: 6| Step: 5
Training loss: 1.7167279920765832
Validation loss: 2.5012029512121234

Epoch: 6| Step: 6
Training loss: 1.6635016270713543
Validation loss: 2.4961346061536873

Epoch: 6| Step: 7
Training loss: 1.6884565115025474
Validation loss: 2.483786502603779

Epoch: 6| Step: 8
Training loss: 2.1876087706635037
Validation loss: 2.450028331371786

Epoch: 6| Step: 9
Training loss: 2.4719015358755625
Validation loss: 2.507998588679959

Epoch: 6| Step: 10
Training loss: 1.9648506058256696
Validation loss: 2.497246772584326

Epoch: 6| Step: 11
Training loss: 2.0379116274435285
Validation loss: 2.465033580092281

Epoch: 6| Step: 12
Training loss: 1.5929029120908191
Validation loss: 2.4838462902143554

Epoch: 6| Step: 13
Training loss: 1.617536571625778
Validation loss: 2.4778347120382973

Epoch: 394| Step: 0
Training loss: 2.357058467840603
Validation loss: 2.472502137881887

Epoch: 6| Step: 1
Training loss: 1.470398809350313
Validation loss: 2.4979051077996566

Epoch: 6| Step: 2
Training loss: 1.8725563656073771
Validation loss: 2.4708606176096475

Epoch: 6| Step: 3
Training loss: 1.6402673240599113
Validation loss: 2.445107675897441

Epoch: 6| Step: 4
Training loss: 2.244911692184525
Validation loss: 2.4951389120834744

Epoch: 6| Step: 5
Training loss: 1.8380939561699163
Validation loss: 2.4866469846195236

Epoch: 6| Step: 6
Training loss: 1.6633857461294526
Validation loss: 2.48724142808282

Epoch: 6| Step: 7
Training loss: 1.5251714766353617
Validation loss: 2.48183313552874

Epoch: 6| Step: 8
Training loss: 1.156117405892358
Validation loss: 2.492453985567174

Epoch: 6| Step: 9
Training loss: 2.460933527867578
Validation loss: 2.4513470385677114

Epoch: 6| Step: 10
Training loss: 2.076116293793882
Validation loss: 2.5074241280466723

Epoch: 6| Step: 11
Training loss: 2.5806452599263943
Validation loss: 2.469060725362861

Epoch: 6| Step: 12
Training loss: 2.2057318449097956
Validation loss: 2.4502013726651315

Epoch: 6| Step: 13
Training loss: 1.3978245846494397
Validation loss: 2.459079627762132

Epoch: 395| Step: 0
Training loss: 1.6507247315754419
Validation loss: 2.4645036757553505

Epoch: 6| Step: 1
Training loss: 1.9202048635463511
Validation loss: 2.4606528194822888

Epoch: 6| Step: 2
Training loss: 1.9419380549521243
Validation loss: 2.4784728989362943

Epoch: 6| Step: 3
Training loss: 1.9821654506264674
Validation loss: 2.470552302419114

Epoch: 6| Step: 4
Training loss: 1.8980135346142122
Validation loss: 2.497541452858097

Epoch: 6| Step: 5
Training loss: 2.2327907254203088
Validation loss: 2.477695550476483

Epoch: 6| Step: 6
Training loss: 2.145840160272596
Validation loss: 2.517913269083548

Epoch: 6| Step: 7
Training loss: 1.486580425007631
Validation loss: 2.4957724687392115

Epoch: 6| Step: 8
Training loss: 1.8965914192201099
Validation loss: 2.4959457666591107

Epoch: 6| Step: 9
Training loss: 2.2859752263406343
Validation loss: 2.4708420121987924

Epoch: 6| Step: 10
Training loss: 1.5682154835290179
Validation loss: 2.4672750103937777

Epoch: 6| Step: 11
Training loss: 2.1904874837378903
Validation loss: 2.5053024439752822

Epoch: 6| Step: 12
Training loss: 1.3889432875258567
Validation loss: 2.420152698680143

Epoch: 6| Step: 13
Training loss: 2.4509473720645008
Validation loss: 2.4924321738099633

Epoch: 396| Step: 0
Training loss: 1.6760437944239484
Validation loss: 2.4874184071373655

Epoch: 6| Step: 1
Training loss: 2.155995561266065
Validation loss: 2.495607691230322

Epoch: 6| Step: 2
Training loss: 1.639550865591866
Validation loss: 2.45301664463335

Epoch: 6| Step: 3
Training loss: 1.9372767658223282
Validation loss: 2.4649091666754224

Epoch: 6| Step: 4
Training loss: 2.046510154298167
Validation loss: 2.4627947295553887

Epoch: 6| Step: 5
Training loss: 1.089696074294239
Validation loss: 2.495889260960705

Epoch: 6| Step: 6
Training loss: 2.144778155790228
Validation loss: 2.4916628051452423

Epoch: 6| Step: 7
Training loss: 1.4711537272442232
Validation loss: 2.5164845406485767

Epoch: 6| Step: 8
Training loss: 2.223971174025857
Validation loss: 2.4853221625073894

Epoch: 6| Step: 9
Training loss: 1.682224150287985
Validation loss: 2.479358224318112

Epoch: 6| Step: 10
Training loss: 2.190950342852661
Validation loss: 2.4743397791800605

Epoch: 6| Step: 11
Training loss: 1.8719246757424408
Validation loss: 2.5059255813536927

Epoch: 6| Step: 12
Training loss: 2.373325761647237
Validation loss: 2.490921263057336

Epoch: 6| Step: 13
Training loss: 2.230960290730684
Validation loss: 2.4421214132304607

Epoch: 397| Step: 0
Training loss: 1.5864858196212708
Validation loss: 2.4624003651127566

Epoch: 6| Step: 1
Training loss: 1.694005576695402
Validation loss: 2.4711005061258127

Epoch: 6| Step: 2
Training loss: 2.2632440091888886
Validation loss: 2.4757388646055896

Epoch: 6| Step: 3
Training loss: 1.6374068896197036
Validation loss: 2.4477124546375193

Epoch: 6| Step: 4
Training loss: 1.7772453532386914
Validation loss: 2.477670267758223

Epoch: 6| Step: 5
Training loss: 2.697268099994339
Validation loss: 2.513180470782501

Epoch: 6| Step: 6
Training loss: 2.3294413896479935
Validation loss: 2.4907084727886444

Epoch: 6| Step: 7
Training loss: 1.867466734113687
Validation loss: 2.481736587807905

Epoch: 6| Step: 8
Training loss: 1.9654358716744418
Validation loss: 2.443682207368864

Epoch: 6| Step: 9
Training loss: 1.67340773441118
Validation loss: 2.5039757688898194

Epoch: 6| Step: 10
Training loss: 1.8634957563936898
Validation loss: 2.5295203510521063

Epoch: 6| Step: 11
Training loss: 1.5639588983847343
Validation loss: 2.5247269753198514

Epoch: 6| Step: 12
Training loss: 1.5470742761970275
Validation loss: 2.473038891507446

Epoch: 6| Step: 13
Training loss: 2.0963742336157836
Validation loss: 2.475742337687821

Epoch: 398| Step: 0
Training loss: 1.818668523582413
Validation loss: 2.4613025322285784

Epoch: 6| Step: 1
Training loss: 2.51161528236295
Validation loss: 2.4983389022274616

Epoch: 6| Step: 2
Training loss: 2.2899795101531777
Validation loss: 2.4535069896825026

Epoch: 6| Step: 3
Training loss: 1.9277866901383462
Validation loss: 2.5028779743311573

Epoch: 6| Step: 4
Training loss: 1.481293219728532
Validation loss: 2.4751624761802495

Epoch: 6| Step: 5
Training loss: 1.6364964445724117
Validation loss: 2.4823842538473158

Epoch: 6| Step: 6
Training loss: 1.8569592081169557
Validation loss: 2.557072313377644

Epoch: 6| Step: 7
Training loss: 2.0051740238838
Validation loss: 2.443810051281248

Epoch: 6| Step: 8
Training loss: 1.4709355751934308
Validation loss: 2.523766851754052

Epoch: 6| Step: 9
Training loss: 1.5982781204907528
Validation loss: 2.498718965117668

Epoch: 6| Step: 10
Training loss: 1.6248183515698438
Validation loss: 2.477096241829272

Epoch: 6| Step: 11
Training loss: 2.173672597690527
Validation loss: 2.4820225591665324

Epoch: 6| Step: 12
Training loss: 2.2625574852822066
Validation loss: 2.4800089588178786

Epoch: 6| Step: 13
Training loss: 1.9158508043237867
Validation loss: 2.515467887552504

Epoch: 399| Step: 0
Training loss: 2.2925026726993134
Validation loss: 2.456902327496411

Epoch: 6| Step: 1
Training loss: 2.284627217408121
Validation loss: 2.447667698361924

Epoch: 6| Step: 2
Training loss: 1.996844424877794
Validation loss: 2.4652091433915406

Epoch: 6| Step: 3
Training loss: 1.7538585358992136
Validation loss: 2.4747850498974304

Epoch: 6| Step: 4
Training loss: 1.7953721105441691
Validation loss: 2.5233907382535725

Epoch: 6| Step: 5
Training loss: 1.8164658403363623
Validation loss: 2.5368248860226728

Epoch: 6| Step: 6
Training loss: 1.4969592267830814
Validation loss: 2.476854578782383

Epoch: 6| Step: 7
Training loss: 1.7147962003124329
Validation loss: 2.500141367453165

Epoch: 6| Step: 8
Training loss: 1.5558764641369422
Validation loss: 2.529967481050814

Epoch: 6| Step: 9
Training loss: 1.6097443536409686
Validation loss: 2.5497459367494764

Epoch: 6| Step: 10
Training loss: 2.5191748551834925
Validation loss: 2.4934223685304184

Epoch: 6| Step: 11
Training loss: 1.7250792056710391
Validation loss: 2.4728795751502677

Epoch: 6| Step: 12
Training loss: 2.150968080852194
Validation loss: 2.492192876856736

Epoch: 6| Step: 13
Training loss: 2.09781093488817
Validation loss: 2.515825047988041

Epoch: 400| Step: 0
Training loss: 1.790712220629154
Validation loss: 2.506480222450111

Epoch: 6| Step: 1
Training loss: 1.393043900290291
Validation loss: 2.4985536031559423

Epoch: 6| Step: 2
Training loss: 2.4290373199033306
Validation loss: 2.4849499113159608

Epoch: 6| Step: 3
Training loss: 1.648330901979531
Validation loss: 2.442744470056974

Epoch: 6| Step: 4
Training loss: 2.1318369440346343
Validation loss: 2.436749652298802

Epoch: 6| Step: 5
Training loss: 2.0236733788823167
Validation loss: 2.4598138757568075

Epoch: 6| Step: 6
Training loss: 1.6627444209497184
Validation loss: 2.5012537950130063

Epoch: 6| Step: 7
Training loss: 2.000346630575825
Validation loss: 2.4680554145069387

Epoch: 6| Step: 8
Training loss: 1.821371793529842
Validation loss: 2.4457541069001674

Epoch: 6| Step: 9
Training loss: 1.667850106015302
Validation loss: 2.495022914959703

Epoch: 6| Step: 10
Training loss: 1.7125227738696904
Validation loss: 2.4876925513419312

Epoch: 6| Step: 11
Training loss: 1.9246654566589365
Validation loss: 2.4821036268181835

Epoch: 6| Step: 12
Training loss: 2.116160914556449
Validation loss: 2.51508749241834

Epoch: 6| Step: 13
Training loss: 2.398645149710506
Validation loss: 2.4442852354671705

Epoch: 401| Step: 0
Training loss: 2.069908707305612
Validation loss: 2.5143609921904155

Epoch: 6| Step: 1
Training loss: 1.907560679619247
Validation loss: 2.4328138584861305

Epoch: 6| Step: 2
Training loss: 1.8946047424534103
Validation loss: 2.484128185830219

Epoch: 6| Step: 3
Training loss: 2.2024212518095543
Validation loss: 2.4663218203826593

Epoch: 6| Step: 4
Training loss: 2.4701847784139663
Validation loss: 2.5255309275010274

Epoch: 6| Step: 5
Training loss: 2.139934567672212
Validation loss: 2.481148223533659

Epoch: 6| Step: 6
Training loss: 1.6712340079821362
Validation loss: 2.4352804574526576

Epoch: 6| Step: 7
Training loss: 1.6470492334146756
Validation loss: 2.4833041578028263

Epoch: 6| Step: 8
Training loss: 1.955378826541201
Validation loss: 2.5065108343069973

Epoch: 6| Step: 9
Training loss: 1.6332588133388035
Validation loss: 2.5100598737629256

Epoch: 6| Step: 10
Training loss: 1.8720137020938246
Validation loss: 2.500717256056832

Epoch: 6| Step: 11
Training loss: 1.55538150498611
Validation loss: 2.5178891861559904

Epoch: 6| Step: 12
Training loss: 1.8664853359885925
Validation loss: 2.458306824103395

Epoch: 6| Step: 13
Training loss: 1.5080284794109013
Validation loss: 2.5301811527013913

Epoch: 402| Step: 0
Training loss: 1.598227923274937
Validation loss: 2.503471699888981

Epoch: 6| Step: 1
Training loss: 1.9532687935349204
Validation loss: 2.498834641908507

Epoch: 6| Step: 2
Training loss: 1.898527669138862
Validation loss: 2.532778763532301

Epoch: 6| Step: 3
Training loss: 1.883766027836747
Validation loss: 2.504168994645794

Epoch: 6| Step: 4
Training loss: 1.6816109932693488
Validation loss: 2.5510900061478283

Epoch: 6| Step: 5
Training loss: 1.869644272572495
Validation loss: 2.533590393700643

Epoch: 6| Step: 6
Training loss: 2.089141442484286
Validation loss: 2.500917602643112

Epoch: 6| Step: 7
Training loss: 2.218767300390573
Validation loss: 2.4732549511778066

Epoch: 6| Step: 8
Training loss: 1.2071822482475498
Validation loss: 2.4999222148566447

Epoch: 6| Step: 9
Training loss: 1.8160073119112938
Validation loss: 2.4775162667895803

Epoch: 6| Step: 10
Training loss: 2.199739709541537
Validation loss: 2.5183451865112536

Epoch: 6| Step: 11
Training loss: 1.8075559204863967
Validation loss: 2.537173137084447

Epoch: 6| Step: 12
Training loss: 2.3836888437172563
Validation loss: 2.497655501371275

Epoch: 6| Step: 13
Training loss: 1.298461449284034
Validation loss: 2.463547062685278

Epoch: 403| Step: 0
Training loss: 1.6891804557780725
Validation loss: 2.501889171319149

Epoch: 6| Step: 1
Training loss: 1.9189584823816517
Validation loss: 2.4745471181606526

Epoch: 6| Step: 2
Training loss: 2.2903530401763437
Validation loss: 2.4676372408147715

Epoch: 6| Step: 3
Training loss: 1.9952754006039795
Validation loss: 2.4556438545320427

Epoch: 6| Step: 4
Training loss: 2.0345714702751216
Validation loss: 2.487179788672045

Epoch: 6| Step: 5
Training loss: 1.7277714565988735
Validation loss: 2.501294436716958

Epoch: 6| Step: 6
Training loss: 1.710754872508164
Validation loss: 2.517382292884101

Epoch: 6| Step: 7
Training loss: 1.7029992853365892
Validation loss: 2.4645920996147326

Epoch: 6| Step: 8
Training loss: 1.4960618775162415
Validation loss: 2.514555437546838

Epoch: 6| Step: 9
Training loss: 1.5127085518303787
Validation loss: 2.442851493851123

Epoch: 6| Step: 10
Training loss: 1.8002811159385719
Validation loss: 2.4897688879192583

Epoch: 6| Step: 11
Training loss: 2.467858358717661
Validation loss: 2.4914918871846337

Epoch: 6| Step: 12
Training loss: 1.6200552314008638
Validation loss: 2.442111438393446

Epoch: 6| Step: 13
Training loss: 2.3925350761433304
Validation loss: 2.4698710473548746

Epoch: 404| Step: 0
Training loss: 1.8248608131110695
Validation loss: 2.495022122755659

Epoch: 6| Step: 1
Training loss: 1.3921526971955913
Validation loss: 2.485466097643161

Epoch: 6| Step: 2
Training loss: 1.4632403333883313
Validation loss: 2.441119857824182

Epoch: 6| Step: 3
Training loss: 1.8795282361425574
Validation loss: 2.451558496197227

Epoch: 6| Step: 4
Training loss: 2.0040241526520686
Validation loss: 2.4774691318799116

Epoch: 6| Step: 5
Training loss: 2.2618311193615246
Validation loss: 2.459506891600659

Epoch: 6| Step: 6
Training loss: 1.393098795367536
Validation loss: 2.4478201681965825

Epoch: 6| Step: 7
Training loss: 2.034243212297228
Validation loss: 2.466632364182003

Epoch: 6| Step: 8
Training loss: 2.2574817454802947
Validation loss: 2.495642687715186

Epoch: 6| Step: 9
Training loss: 2.217182304048263
Validation loss: 2.469521342441583

Epoch: 6| Step: 10
Training loss: 1.6866212605532676
Validation loss: 2.4737146525466653

Epoch: 6| Step: 11
Training loss: 1.94059291204931
Validation loss: 2.4552488468761697

Epoch: 6| Step: 12
Training loss: 1.9924161891948118
Validation loss: 2.46783649682435

Epoch: 6| Step: 13
Training loss: 1.553975541308952
Validation loss: 2.5152106744198064

Epoch: 405| Step: 0
Training loss: 1.9138496747711038
Validation loss: 2.4365320179438603

Epoch: 6| Step: 1
Training loss: 1.6985920068112377
Validation loss: 2.4584505864193615

Epoch: 6| Step: 2
Training loss: 1.5205818212158815
Validation loss: 2.475525079454721

Epoch: 6| Step: 3
Training loss: 1.602993061072073
Validation loss: 2.462826593800868

Epoch: 6| Step: 4
Training loss: 2.3524164315926193
Validation loss: 2.446603411674136

Epoch: 6| Step: 5
Training loss: 2.3051309449906454
Validation loss: 2.542309053667393

Epoch: 6| Step: 6
Training loss: 1.9254530806965267
Validation loss: 2.4756227910636195

Epoch: 6| Step: 7
Training loss: 2.468725276774939
Validation loss: 2.4908829726381665

Epoch: 6| Step: 8
Training loss: 1.6970985953755124
Validation loss: 2.4574227564612388

Epoch: 6| Step: 9
Training loss: 2.5018458227990648
Validation loss: 2.4258922733602843

Epoch: 6| Step: 10
Training loss: 1.5506291927479308
Validation loss: 2.4747421817317194

Epoch: 6| Step: 11
Training loss: 1.093566824696973
Validation loss: 2.473438131997095

Epoch: 6| Step: 12
Training loss: 1.4797935858686353
Validation loss: 2.4486629415879713

Epoch: 6| Step: 13
Training loss: 1.6155986997725225
Validation loss: 2.4880687671645263

Epoch: 406| Step: 0
Training loss: 2.9585282883857493
Validation loss: 2.505417534388669

Epoch: 6| Step: 1
Training loss: 1.5609138066934605
Validation loss: 2.4856286224519786

Epoch: 6| Step: 2
Training loss: 2.0441571311349866
Validation loss: 2.5210144322334926

Epoch: 6| Step: 3
Training loss: 1.8381010253338896
Validation loss: 2.505310257774136

Epoch: 6| Step: 4
Training loss: 1.8304350514063568
Validation loss: 2.491661272102443

Epoch: 6| Step: 5
Training loss: 1.6523885517945482
Validation loss: 2.4659247503883157

Epoch: 6| Step: 6
Training loss: 2.203230402163398
Validation loss: 2.53668580041054

Epoch: 6| Step: 7
Training loss: 1.6547046145381663
Validation loss: 2.464999679423634

Epoch: 6| Step: 8
Training loss: 1.0816968270217813
Validation loss: 2.5064866328725803

Epoch: 6| Step: 9
Training loss: 2.1295471906446726
Validation loss: 2.492263676026975

Epoch: 6| Step: 10
Training loss: 1.6318754582895711
Validation loss: 2.491299798521234

Epoch: 6| Step: 11
Training loss: 2.083313166202845
Validation loss: 2.4486224523510485

Epoch: 6| Step: 12
Training loss: 1.8590609501639694
Validation loss: 2.463089783094397

Epoch: 6| Step: 13
Training loss: 1.2643200304317301
Validation loss: 2.465815255537506

Epoch: 407| Step: 0
Training loss: 1.4890898662986496
Validation loss: 2.4486268182229325

Epoch: 6| Step: 1
Training loss: 2.18522460306874
Validation loss: 2.4734429992482396

Epoch: 6| Step: 2
Training loss: 1.7727898578889052
Validation loss: 2.50630431273013

Epoch: 6| Step: 3
Training loss: 1.9744065781471374
Validation loss: 2.5227177853746157

Epoch: 6| Step: 4
Training loss: 1.8387101684239353
Validation loss: 2.4634368096469865

Epoch: 6| Step: 5
Training loss: 2.1851905620937444
Validation loss: 2.4610817966715186

Epoch: 6| Step: 6
Training loss: 2.1197476269195477
Validation loss: 2.5518125837872807

Epoch: 6| Step: 7
Training loss: 1.6833432181543373
Validation loss: 2.4941215775551435

Epoch: 6| Step: 8
Training loss: 0.9705481914089733
Validation loss: 2.4989719492077787

Epoch: 6| Step: 9
Training loss: 2.4372661184931643
Validation loss: 2.483429003021547

Epoch: 6| Step: 10
Training loss: 2.068331710154931
Validation loss: 2.5002302504715437

Epoch: 6| Step: 11
Training loss: 1.463362613825304
Validation loss: 2.5493477144922516

Epoch: 6| Step: 12
Training loss: 2.1641812619008585
Validation loss: 2.467160498403204

Epoch: 6| Step: 13
Training loss: 1.9372336296820447
Validation loss: 2.4678614273661115

Epoch: 408| Step: 0
Training loss: 2.468653616653441
Validation loss: 2.4492753673531262

Epoch: 6| Step: 1
Training loss: 1.5755567141984328
Validation loss: 2.4953887373636845

Epoch: 6| Step: 2
Training loss: 1.646403427215731
Validation loss: 2.520008484767023

Epoch: 6| Step: 3
Training loss: 1.6603078256861123
Validation loss: 2.495518435028566

Epoch: 6| Step: 4
Training loss: 2.0023883625586967
Validation loss: 2.467273304260752

Epoch: 6| Step: 5
Training loss: 1.8767606098631782
Validation loss: 2.5058948697619154

Epoch: 6| Step: 6
Training loss: 2.4846003208307894
Validation loss: 2.4086616383743844

Epoch: 6| Step: 7
Training loss: 1.5324552813877228
Validation loss: 2.4723802461832305

Epoch: 6| Step: 8
Training loss: 1.902712807702458
Validation loss: 2.4695907953344483

Epoch: 6| Step: 9
Training loss: 1.6482951749133339
Validation loss: 2.5332552007544384

Epoch: 6| Step: 10
Training loss: 1.999273466231293
Validation loss: 2.4999847791064838

Epoch: 6| Step: 11
Training loss: 1.6373245465579231
Validation loss: 2.4767905778827535

Epoch: 6| Step: 12
Training loss: 1.903254171663776
Validation loss: 2.5058903059586104

Epoch: 6| Step: 13
Training loss: 2.2778845221879314
Validation loss: 2.482085972767434

Epoch: 409| Step: 0
Training loss: 1.8659690808006841
Validation loss: 2.495010540724361

Epoch: 6| Step: 1
Training loss: 1.6519496438708445
Validation loss: 2.4648660222241694

Epoch: 6| Step: 2
Training loss: 1.771829422191305
Validation loss: 2.48618106174953

Epoch: 6| Step: 3
Training loss: 1.9609579260016845
Validation loss: 2.5247707950883336

Epoch: 6| Step: 4
Training loss: 1.6691341572320864
Validation loss: 2.523106835173325

Epoch: 6| Step: 5
Training loss: 1.7642453635274975
Validation loss: 2.4837856314688915

Epoch: 6| Step: 6
Training loss: 2.1736750107521052
Validation loss: 2.4281872333797163

Epoch: 6| Step: 7
Training loss: 2.563700697046768
Validation loss: 2.426667187578386

Epoch: 6| Step: 8
Training loss: 2.2103649247202033
Validation loss: 2.466598214738139

Epoch: 6| Step: 9
Training loss: 2.458475873877253
Validation loss: 2.507001242980226

Epoch: 6| Step: 10
Training loss: 1.3469851384635159
Validation loss: 2.4959052638313772

Epoch: 6| Step: 11
Training loss: 0.9627005677748246
Validation loss: 2.4546503733098834

Epoch: 6| Step: 12
Training loss: 1.6474862630963163
Validation loss: 2.494256102994676

Epoch: 6| Step: 13
Training loss: 1.8751245457292858
Validation loss: 2.4850501481161413

Epoch: 410| Step: 0
Training loss: 1.7526187376537987
Validation loss: 2.4594140372227353

Epoch: 6| Step: 1
Training loss: 1.8268516866349434
Validation loss: 2.51181637281409

Epoch: 6| Step: 2
Training loss: 1.9420493459629575
Validation loss: 2.4535112037132136

Epoch: 6| Step: 3
Training loss: 1.5088668852553044
Validation loss: 2.4669506716908596

Epoch: 6| Step: 4
Training loss: 2.1187582910426137
Validation loss: 2.515004291310993

Epoch: 6| Step: 5
Training loss: 2.5142003165642
Validation loss: 2.496614719589051

Epoch: 6| Step: 6
Training loss: 1.6606120123479173
Validation loss: 2.46175647240054

Epoch: 6| Step: 7
Training loss: 1.9736018869731962
Validation loss: 2.4927627609848617

Epoch: 6| Step: 8
Training loss: 1.714764082672136
Validation loss: 2.5168291696561202

Epoch: 6| Step: 9
Training loss: 1.5889876026368546
Validation loss: 2.460642240475464

Epoch: 6| Step: 10
Training loss: 2.3132222053080786
Validation loss: 2.468580244029445

Epoch: 6| Step: 11
Training loss: 1.8349452157638757
Validation loss: 2.4831174904355438

Epoch: 6| Step: 12
Training loss: 2.0510093344146334
Validation loss: 2.4638760275267177

Epoch: 6| Step: 13
Training loss: 1.4284584307258534
Validation loss: 2.504015205412028

Epoch: 411| Step: 0
Training loss: 1.8038585129505758
Validation loss: 2.483205406338917

Epoch: 6| Step: 1
Training loss: 2.1907678445996703
Validation loss: 2.470348299244769

Epoch: 6| Step: 2
Training loss: 2.1294253775031637
Validation loss: 2.4552974347303476

Epoch: 6| Step: 3
Training loss: 1.7359059081134323
Validation loss: 2.457849546382157

Epoch: 6| Step: 4
Training loss: 2.024967749068025
Validation loss: 2.5326154169129396

Epoch: 6| Step: 5
Training loss: 1.7317286742009572
Validation loss: 2.463350053169027

Epoch: 6| Step: 6
Training loss: 1.7430259158319243
Validation loss: 2.4922738297059013

Epoch: 6| Step: 7
Training loss: 1.8074028428005002
Validation loss: 2.4494858494209906

Epoch: 6| Step: 8
Training loss: 2.064336825787874
Validation loss: 2.499167811415055

Epoch: 6| Step: 9
Training loss: 2.2279374010205517
Validation loss: 2.4508753814701403

Epoch: 6| Step: 10
Training loss: 2.1234559452022075
Validation loss: 2.4821104828667595

Epoch: 6| Step: 11
Training loss: 1.6564712376652238
Validation loss: 2.469190522664387

Epoch: 6| Step: 12
Training loss: 1.7171580484795952
Validation loss: 2.4763423622182557

Epoch: 6| Step: 13
Training loss: 1.0980917721597039
Validation loss: 2.5097522652086397

Epoch: 412| Step: 0
Training loss: 1.5440983367695538
Validation loss: 2.464477276760234

Epoch: 6| Step: 1
Training loss: 2.2438356941031463
Validation loss: 2.439396129393464

Epoch: 6| Step: 2
Training loss: 2.0201908414223153
Validation loss: 2.5065538761167865

Epoch: 6| Step: 3
Training loss: 1.7046799167425926
Validation loss: 2.4887828527702816

Epoch: 6| Step: 4
Training loss: 2.1412370461129435
Validation loss: 2.5038377264436926

Epoch: 6| Step: 5
Training loss: 1.8615357482330182
Validation loss: 2.505373339288343

Epoch: 6| Step: 6
Training loss: 1.797947041360673
Validation loss: 2.5092183250493596

Epoch: 6| Step: 7
Training loss: 2.0363777580483737
Validation loss: 2.560076249859163

Epoch: 6| Step: 8
Training loss: 1.9198276811003165
Validation loss: 2.5128406975056317

Epoch: 6| Step: 9
Training loss: 1.9696527258254342
Validation loss: 2.5185013977560393

Epoch: 6| Step: 10
Training loss: 1.9723601166182774
Validation loss: 2.5312101618504235

Epoch: 6| Step: 11
Training loss: 1.6298905652994913
Validation loss: 2.4869742221371864

Epoch: 6| Step: 12
Training loss: 1.597338731174445
Validation loss: 2.4540985612615174

Epoch: 6| Step: 13
Training loss: 1.4381504245916181
Validation loss: 2.491896709160116

Epoch: 413| Step: 0
Training loss: 2.160951657638456
Validation loss: 2.4917542067448246

Epoch: 6| Step: 1
Training loss: 1.4949565978113208
Validation loss: 2.4377599724268393

Epoch: 6| Step: 2
Training loss: 1.6929155975996895
Validation loss: 2.52728749794739

Epoch: 6| Step: 3
Training loss: 2.8382904968195093
Validation loss: 2.444979884107694

Epoch: 6| Step: 4
Training loss: 1.5145259687150001
Validation loss: 2.436352877678977

Epoch: 6| Step: 5
Training loss: 1.9814803870994633
Validation loss: 2.4676429423187534

Epoch: 6| Step: 6
Training loss: 1.752213508708196
Validation loss: 2.485865285215661

Epoch: 6| Step: 7
Training loss: 1.8097715559264664
Validation loss: 2.4346517408383144

Epoch: 6| Step: 8
Training loss: 1.7454205949960253
Validation loss: 2.492368382118886

Epoch: 6| Step: 9
Training loss: 1.5339660690066281
Validation loss: 2.495801770281878

Epoch: 6| Step: 10
Training loss: 2.0388075862869863
Validation loss: 2.4693723709004787

Epoch: 6| Step: 11
Training loss: 1.650582603710321
Validation loss: 2.448678414491409

Epoch: 6| Step: 12
Training loss: 1.2618284384463283
Validation loss: 2.480780176662037

Epoch: 6| Step: 13
Training loss: 1.801597889985192
Validation loss: 2.476888018073267

Epoch: 414| Step: 0
Training loss: 1.8913219207784189
Validation loss: 2.4264690923409256

Epoch: 6| Step: 1
Training loss: 2.1176161666405764
Validation loss: 2.4952790282258452

Epoch: 6| Step: 2
Training loss: 1.8346996923323204
Validation loss: 2.4760371084011377

Epoch: 6| Step: 3
Training loss: 1.7747289853655352
Validation loss: 2.478229467236303

Epoch: 6| Step: 4
Training loss: 2.2091074132677417
Validation loss: 2.505418393909182

Epoch: 6| Step: 5
Training loss: 1.9455763549801537
Validation loss: 2.450121192496203

Epoch: 6| Step: 6
Training loss: 1.0946844196630159
Validation loss: 2.5403989464290824

Epoch: 6| Step: 7
Training loss: 1.3928988436510417
Validation loss: 2.5154701775828854

Epoch: 6| Step: 8
Training loss: 2.1754942453001864
Validation loss: 2.487381456246239

Epoch: 6| Step: 9
Training loss: 1.6702940409026643
Validation loss: 2.4847872131472437

Epoch: 6| Step: 10
Training loss: 2.117810822680832
Validation loss: 2.4482249809135066

Epoch: 6| Step: 11
Training loss: 1.5095866147766472
Validation loss: 2.4863807407083964

Epoch: 6| Step: 12
Training loss: 2.0933091567803825
Validation loss: 2.4500132190999833

Epoch: 6| Step: 13
Training loss: 1.6349773019270857
Validation loss: 2.492617457613651

Epoch: 415| Step: 0
Training loss: 1.8393884569272732
Validation loss: 2.456772114723308

Epoch: 6| Step: 1
Training loss: 1.707092633223983
Validation loss: 2.4902295415977367

Epoch: 6| Step: 2
Training loss: 1.944413003970076
Validation loss: 2.486491178056639

Epoch: 6| Step: 3
Training loss: 1.7807372174932221
Validation loss: 2.4445764804125725

Epoch: 6| Step: 4
Training loss: 1.9951011145453585
Validation loss: 2.4930994833531694

Epoch: 6| Step: 5
Training loss: 1.283100466635352
Validation loss: 2.4906133658589686

Epoch: 6| Step: 6
Training loss: 2.031110435973115
Validation loss: 2.4785966728927424

Epoch: 6| Step: 7
Training loss: 1.6752049448831148
Validation loss: 2.5029731575694676

Epoch: 6| Step: 8
Training loss: 2.0735607073240003
Validation loss: 2.47667908328606

Epoch: 6| Step: 9
Training loss: 1.7090077425857788
Validation loss: 2.444676854143691

Epoch: 6| Step: 10
Training loss: 1.7877526964954924
Validation loss: 2.4503657180635754

Epoch: 6| Step: 11
Training loss: 2.2891856085576037
Validation loss: 2.4977418945763903

Epoch: 6| Step: 12
Training loss: 1.9839113549879372
Validation loss: 2.5228466928564

Epoch: 6| Step: 13
Training loss: 1.85870368443181
Validation loss: 2.5082110890463474

Epoch: 416| Step: 0
Training loss: 2.048195915030507
Validation loss: 2.4186112211669006

Epoch: 6| Step: 1
Training loss: 2.0620588350976545
Validation loss: 2.507755951935009

Epoch: 6| Step: 2
Training loss: 2.0803829918897954
Validation loss: 2.503100589013899

Epoch: 6| Step: 3
Training loss: 1.0387432783990418
Validation loss: 2.4610709903397754

Epoch: 6| Step: 4
Training loss: 2.3445163745401865
Validation loss: 2.5154325401034976

Epoch: 6| Step: 5
Training loss: 2.1628402398199964
Validation loss: 2.479624732712173

Epoch: 6| Step: 6
Training loss: 1.260094509516091
Validation loss: 2.5087510417268146

Epoch: 6| Step: 7
Training loss: 1.638567697262076
Validation loss: 2.512534845639387

Epoch: 6| Step: 8
Training loss: 1.6102605809037478
Validation loss: 2.479350261003304

Epoch: 6| Step: 9
Training loss: 1.7707867410551597
Validation loss: 2.5137360163986413

Epoch: 6| Step: 10
Training loss: 2.1187705565048947
Validation loss: 2.431715499121198

Epoch: 6| Step: 11
Training loss: 1.3787688275985865
Validation loss: 2.439632129038451

Epoch: 6| Step: 12
Training loss: 2.3508499434663106
Validation loss: 2.4658592634476153

Epoch: 6| Step: 13
Training loss: 1.7244669767974512
Validation loss: 2.4680031617321645

Epoch: 417| Step: 0
Training loss: 1.6322600237666691
Validation loss: 2.4682311237981636

Epoch: 6| Step: 1
Training loss: 1.891567216127101
Validation loss: 2.500289882753029

Epoch: 6| Step: 2
Training loss: 1.7183916585343288
Validation loss: 2.459728098360175

Epoch: 6| Step: 3
Training loss: 2.510277603117702
Validation loss: 2.4489142492639626

Epoch: 6| Step: 4
Training loss: 1.6245931702979923
Validation loss: 2.452983326710832

Epoch: 6| Step: 5
Training loss: 2.014611987673176
Validation loss: 2.489698344477227

Epoch: 6| Step: 6
Training loss: 1.9761919118993099
Validation loss: 2.4571470749830455

Epoch: 6| Step: 7
Training loss: 1.8281429974574834
Validation loss: 2.463074058809885

Epoch: 6| Step: 8
Training loss: 1.4355625696686702
Validation loss: 2.4392976813063947

Epoch: 6| Step: 9
Training loss: 1.7110453532465757
Validation loss: 2.420770167270324

Epoch: 6| Step: 10
Training loss: 2.1707168894439994
Validation loss: 2.4873900168803242

Epoch: 6| Step: 11
Training loss: 1.8646668214771769
Validation loss: 2.4828511716121593

Epoch: 6| Step: 12
Training loss: 1.8766303921248986
Validation loss: 2.518881529737665

Epoch: 6| Step: 13
Training loss: 1.5319064543228946
Validation loss: 2.4535389118558943

Epoch: 418| Step: 0
Training loss: 2.5738375067413246
Validation loss: 2.4730832580848334

Epoch: 6| Step: 1
Training loss: 2.03295076033467
Validation loss: 2.4979362917114987

Epoch: 6| Step: 2
Training loss: 1.845203150287935
Validation loss: 2.4803502993844435

Epoch: 6| Step: 3
Training loss: 2.170372093047142
Validation loss: 2.5214452411886756

Epoch: 6| Step: 4
Training loss: 1.3796370085552816
Validation loss: 2.471926019912451

Epoch: 6| Step: 5
Training loss: 1.7678484799501721
Validation loss: 2.5054267087316826

Epoch: 6| Step: 6
Training loss: 1.7575665789347577
Validation loss: 2.4797386019169645

Epoch: 6| Step: 7
Training loss: 1.806120596609504
Validation loss: 2.4298198363067303

Epoch: 6| Step: 8
Training loss: 2.069761037255937
Validation loss: 2.4793698903239108

Epoch: 6| Step: 9
Training loss: 1.5050375906473148
Validation loss: 2.5137676897665275

Epoch: 6| Step: 10
Training loss: 2.0844673376491354
Validation loss: 2.4804750638310895

Epoch: 6| Step: 11
Training loss: 1.8126708640755789
Validation loss: 2.529944391670212

Epoch: 6| Step: 12
Training loss: 1.5506996882824011
Validation loss: 2.4989338047165446

Epoch: 6| Step: 13
Training loss: 0.8642555366098212
Validation loss: 2.4687163211907963

Epoch: 419| Step: 0
Training loss: 1.3135487136026598
Validation loss: 2.5294122186035013

Epoch: 6| Step: 1
Training loss: 1.6208609907966216
Validation loss: 2.489450702866322

Epoch: 6| Step: 2
Training loss: 1.945062950704205
Validation loss: 2.477351453668144

Epoch: 6| Step: 3
Training loss: 2.067185829951966
Validation loss: 2.52305966086486

Epoch: 6| Step: 4
Training loss: 1.7777759068532213
Validation loss: 2.4938050989703036

Epoch: 6| Step: 5
Training loss: 2.3043568519434294
Validation loss: 2.4405942387025106

Epoch: 6| Step: 6
Training loss: 1.5066952692259512
Validation loss: 2.4615418759295014

Epoch: 6| Step: 7
Training loss: 2.7669722729152944
Validation loss: 2.495642681551706

Epoch: 6| Step: 8
Training loss: 1.5235885154016868
Validation loss: 2.47144486538699

Epoch: 6| Step: 9
Training loss: 1.7413660687431214
Validation loss: 2.4796533829817538

Epoch: 6| Step: 10
Training loss: 2.0849509888887354
Validation loss: 2.52059198327742

Epoch: 6| Step: 11
Training loss: 1.5138928455141647
Validation loss: 2.5029059287461215

Epoch: 6| Step: 12
Training loss: 1.2925346083591542
Validation loss: 2.5015864209707632

Epoch: 6| Step: 13
Training loss: 1.6897325935082412
Validation loss: 2.485143284598907

Epoch: 420| Step: 0
Training loss: 1.4025708282999945
Validation loss: 2.444020435501243

Epoch: 6| Step: 1
Training loss: 1.7655599126381256
Validation loss: 2.491387232235683

Epoch: 6| Step: 2
Training loss: 1.6716587960744753
Validation loss: 2.477933950668206

Epoch: 6| Step: 3
Training loss: 1.7222011250396658
Validation loss: 2.4783230379645222

Epoch: 6| Step: 4
Training loss: 2.4157294286582163
Validation loss: 2.4804483795427696

Epoch: 6| Step: 5
Training loss: 1.681572854053243
Validation loss: 2.455230357052066

Epoch: 6| Step: 6
Training loss: 2.4596128743749026
Validation loss: 2.494532456565732

Epoch: 6| Step: 7
Training loss: 1.3953172194517487
Validation loss: 2.451694958693409

Epoch: 6| Step: 8
Training loss: 1.94352615637582
Validation loss: 2.4677516641960566

Epoch: 6| Step: 9
Training loss: 1.930094872845743
Validation loss: 2.4946051624711965

Epoch: 6| Step: 10
Training loss: 1.3791040381341964
Validation loss: 2.4734850835731463

Epoch: 6| Step: 11
Training loss: 2.082267361362795
Validation loss: 2.4815825055045924

Epoch: 6| Step: 12
Training loss: 1.5993242952956186
Validation loss: 2.4578127058578896

Epoch: 6| Step: 13
Training loss: 1.8456523585528213
Validation loss: 2.4227220666224727

Epoch: 421| Step: 0
Training loss: 2.1038578927382225
Validation loss: 2.4826899560660065

Epoch: 6| Step: 1
Training loss: 1.935939960616721
Validation loss: 2.4376832321540216

Epoch: 6| Step: 2
Training loss: 1.182282177499118
Validation loss: 2.468659186000686

Epoch: 6| Step: 3
Training loss: 2.342547604169767
Validation loss: 2.4528800246879654

Epoch: 6| Step: 4
Training loss: 2.171805511021615
Validation loss: 2.4867595946561143

Epoch: 6| Step: 5
Training loss: 1.819312217832159
Validation loss: 2.5114178011634674

Epoch: 6| Step: 6
Training loss: 1.4271466132100528
Validation loss: 2.4469037105531473

Epoch: 6| Step: 7
Training loss: 1.5530977795554624
Validation loss: 2.5036286118279016

Epoch: 6| Step: 8
Training loss: 1.4247400113565727
Validation loss: 2.4781389592419245

Epoch: 6| Step: 9
Training loss: 2.2288123826706445
Validation loss: 2.449570035718887

Epoch: 6| Step: 10
Training loss: 2.329065939192982
Validation loss: 2.4611394879717445

Epoch: 6| Step: 11
Training loss: 1.7310256234205774
Validation loss: 2.4816185634081505

Epoch: 6| Step: 12
Training loss: 1.6680638020431855
Validation loss: 2.4777742620437344

Epoch: 6| Step: 13
Training loss: 1.433961743098527
Validation loss: 2.4855511415235214

Epoch: 422| Step: 0
Training loss: 1.4368656251393277
Validation loss: 2.4903684814426184

Epoch: 6| Step: 1
Training loss: 1.8564159665906166
Validation loss: 2.449950449201587

Epoch: 6| Step: 2
Training loss: 1.7864809692846808
Validation loss: 2.5263281526650507

Epoch: 6| Step: 3
Training loss: 1.871525979340994
Validation loss: 2.4677554092720353

Epoch: 6| Step: 4
Training loss: 1.3028523221590014
Validation loss: 2.4757804449704364

Epoch: 6| Step: 5
Training loss: 1.6122461281764098
Validation loss: 2.4985401711008017

Epoch: 6| Step: 6
Training loss: 2.353484423418692
Validation loss: 2.4809681451769032

Epoch: 6| Step: 7
Training loss: 1.7370705492344225
Validation loss: 2.4504576593573204

Epoch: 6| Step: 8
Training loss: 1.8017305532321406
Validation loss: 2.4815249278885134

Epoch: 6| Step: 9
Training loss: 1.690868970715694
Validation loss: 2.4841996885206865

Epoch: 6| Step: 10
Training loss: 1.9736925481318999
Validation loss: 2.4546666815857905

Epoch: 6| Step: 11
Training loss: 2.0032279668044035
Validation loss: 2.456965041869907

Epoch: 6| Step: 12
Training loss: 1.5709543766703449
Validation loss: 2.495290031616792

Epoch: 6| Step: 13
Training loss: 2.6519750864173424
Validation loss: 2.4663822132558373

Epoch: 423| Step: 0
Training loss: 2.1026517746582845
Validation loss: 2.494026648578346

Epoch: 6| Step: 1
Training loss: 1.2372165759958458
Validation loss: 2.433883792185705

Epoch: 6| Step: 2
Training loss: 2.0648129527652683
Validation loss: 2.5231833071332597

Epoch: 6| Step: 3
Training loss: 1.4219896878111355
Validation loss: 2.5066915378512697

Epoch: 6| Step: 4
Training loss: 1.0186309932167767
Validation loss: 2.469890053465785

Epoch: 6| Step: 5
Training loss: 2.1901010580566216
Validation loss: 2.4882684764848757

Epoch: 6| Step: 6
Training loss: 2.1448852024614933
Validation loss: 2.5004371455710594

Epoch: 6| Step: 7
Training loss: 2.2586737973184334
Validation loss: 2.435042821108361

Epoch: 6| Step: 8
Training loss: 1.715161409261693
Validation loss: 2.469726587412626

Epoch: 6| Step: 9
Training loss: 1.5746974170006893
Validation loss: 2.4774132726792906

Epoch: 6| Step: 10
Training loss: 1.6402568585752877
Validation loss: 2.458442479778834

Epoch: 6| Step: 11
Training loss: 2.327005923858302
Validation loss: 2.4843246548763207

Epoch: 6| Step: 12
Training loss: 1.2841780165744832
Validation loss: 2.465383042379752

Epoch: 6| Step: 13
Training loss: 2.1815859822778676
Validation loss: 2.4779417142041096

Epoch: 424| Step: 0
Training loss: 1.9188315632038648
Validation loss: 2.491577713669767

Epoch: 6| Step: 1
Training loss: 2.062141734131466
Validation loss: 2.511679442598624

Epoch: 6| Step: 2
Training loss: 1.3741956438873006
Validation loss: 2.4923741268220168

Epoch: 6| Step: 3
Training loss: 1.7457520152646708
Validation loss: 2.513451837738669

Epoch: 6| Step: 4
Training loss: 2.1532966179960535
Validation loss: 2.4662863631387575

Epoch: 6| Step: 5
Training loss: 2.236788852990771
Validation loss: 2.4844943463106377

Epoch: 6| Step: 6
Training loss: 2.1574185287281105
Validation loss: 2.497231869578919

Epoch: 6| Step: 7
Training loss: 1.9372635974020396
Validation loss: 2.4779542533391945

Epoch: 6| Step: 8
Training loss: 1.2929561187956944
Validation loss: 2.5152303908080156

Epoch: 6| Step: 9
Training loss: 1.5426664804795356
Validation loss: 2.46684778776868

Epoch: 6| Step: 10
Training loss: 1.751779128740408
Validation loss: 2.475875352863602

Epoch: 6| Step: 11
Training loss: 1.906888073301559
Validation loss: 2.4840418705195555

Epoch: 6| Step: 12
Training loss: 1.770917000383506
Validation loss: 2.5006519277717754

Epoch: 6| Step: 13
Training loss: 1.3695988779295132
Validation loss: 2.473461997604941

Epoch: 425| Step: 0
Training loss: 1.4576456446695796
Validation loss: 2.4589591459425804

Epoch: 6| Step: 1
Training loss: 2.4625539163796315
Validation loss: 2.4844349158480123

Epoch: 6| Step: 2
Training loss: 1.72116820407677
Validation loss: 2.4347825532947405

Epoch: 6| Step: 3
Training loss: 1.5471668931316482
Validation loss: 2.4517656035462743

Epoch: 6| Step: 4
Training loss: 1.9067237140328626
Validation loss: 2.465680750460357

Epoch: 6| Step: 5
Training loss: 1.9274774784103321
Validation loss: 2.446830790036283

Epoch: 6| Step: 6
Training loss: 1.9189481080013036
Validation loss: 2.4457114552506223

Epoch: 6| Step: 7
Training loss: 2.0728787621590086
Validation loss: 2.481102838231024

Epoch: 6| Step: 8
Training loss: 1.409866895074527
Validation loss: 2.4453037679459264

Epoch: 6| Step: 9
Training loss: 2.0859947625347743
Validation loss: 2.4859608104668887

Epoch: 6| Step: 10
Training loss: 1.8128920821628085
Validation loss: 2.492887298080871

Epoch: 6| Step: 11
Training loss: 1.7085327946901154
Validation loss: 2.429275000759774

Epoch: 6| Step: 12
Training loss: 1.8642872268010828
Validation loss: 2.3868968337228766

Epoch: 6| Step: 13
Training loss: 1.5975407416412306
Validation loss: 2.4324069710656913

Epoch: 426| Step: 0
Training loss: 1.5530959374147526
Validation loss: 2.4783393208033857

Epoch: 6| Step: 1
Training loss: 2.0646962119256873
Validation loss: 2.430366455277176

Epoch: 6| Step: 2
Training loss: 1.5869399036357568
Validation loss: 2.445350526898447

Epoch: 6| Step: 3
Training loss: 1.6177592717993985
Validation loss: 2.4629939183029057

Epoch: 6| Step: 4
Training loss: 1.2311169082820324
Validation loss: 2.47584570107415

Epoch: 6| Step: 5
Training loss: 1.8435475513066737
Validation loss: 2.481965960626184

Epoch: 6| Step: 6
Training loss: 2.0650531109868067
Validation loss: 2.470621847216366

Epoch: 6| Step: 7
Training loss: 1.7740193895400669
Validation loss: 2.469697499674209

Epoch: 6| Step: 8
Training loss: 1.9139171311586682
Validation loss: 2.440476867584504

Epoch: 6| Step: 9
Training loss: 2.1650527175933836
Validation loss: 2.4792677807957753

Epoch: 6| Step: 10
Training loss: 1.8388058595970185
Validation loss: 2.4281115388393504

Epoch: 6| Step: 11
Training loss: 1.841900884254194
Validation loss: 2.452662244364895

Epoch: 6| Step: 12
Training loss: 1.6871288032587792
Validation loss: 2.4931102557437037

Epoch: 6| Step: 13
Training loss: 1.8347827282783113
Validation loss: 2.4512829129083156

Epoch: 427| Step: 0
Training loss: 1.5216887781152941
Validation loss: 2.465770236261923

Epoch: 6| Step: 1
Training loss: 2.06683656650427
Validation loss: 2.4812617660726612

Epoch: 6| Step: 2
Training loss: 1.3664846302931002
Validation loss: 2.492617711651511

Epoch: 6| Step: 3
Training loss: 2.204110216116154
Validation loss: 2.434086181487002

Epoch: 6| Step: 4
Training loss: 1.4452331521187696
Validation loss: 2.4925750833248688

Epoch: 6| Step: 5
Training loss: 1.7941122294080227
Validation loss: 2.4136920998825873

Epoch: 6| Step: 6
Training loss: 2.082303199398996
Validation loss: 2.4422090434982593

Epoch: 6| Step: 7
Training loss: 1.4324535856333693
Validation loss: 2.4294179310430692

Epoch: 6| Step: 8
Training loss: 1.9417710757800684
Validation loss: 2.463085071283915

Epoch: 6| Step: 9
Training loss: 1.97818686341851
Validation loss: 2.490516134299572

Epoch: 6| Step: 10
Training loss: 1.5214676078685385
Validation loss: 2.4694677607288087

Epoch: 6| Step: 11
Training loss: 1.3319837276449962
Validation loss: 2.501925431475997

Epoch: 6| Step: 12
Training loss: 2.3168389107687544
Validation loss: 2.4117264420616586

Epoch: 6| Step: 13
Training loss: 2.208694992200824
Validation loss: 2.447719815485507

Epoch: 428| Step: 0
Training loss: 1.9154171256805506
Validation loss: 2.4346240609844187

Epoch: 6| Step: 1
Training loss: 1.5048446303864007
Validation loss: 2.4330790014545913

Epoch: 6| Step: 2
Training loss: 1.816743355920122
Validation loss: 2.4950973234784044

Epoch: 6| Step: 3
Training loss: 1.8453580018973625
Validation loss: 2.492704547371679

Epoch: 6| Step: 4
Training loss: 1.691511824839116
Validation loss: 2.495256385334338

Epoch: 6| Step: 5
Training loss: 1.9555401327627995
Validation loss: 2.4498672836986017

Epoch: 6| Step: 6
Training loss: 1.8440022053612288
Validation loss: 2.4938037091090406

Epoch: 6| Step: 7
Training loss: 1.4012558311320658
Validation loss: 2.4968960176423924

Epoch: 6| Step: 8
Training loss: 2.1541504520516814
Validation loss: 2.5100488717953087

Epoch: 6| Step: 9
Training loss: 1.8242659960883592
Validation loss: 2.469897073161644

Epoch: 6| Step: 10
Training loss: 1.7883673237642321
Validation loss: 2.485559326838337

Epoch: 6| Step: 11
Training loss: 1.3056652494209733
Validation loss: 2.5258596896222785

Epoch: 6| Step: 12
Training loss: 2.0726786210009958
Validation loss: 2.4706362352286733

Epoch: 6| Step: 13
Training loss: 2.00989160615533
Validation loss: 2.4476658989607087

Epoch: 429| Step: 0
Training loss: 2.2791986517838265
Validation loss: 2.407740755099572

Epoch: 6| Step: 1
Training loss: 1.7441203253954118
Validation loss: 2.459318742164529

Epoch: 6| Step: 2
Training loss: 1.4089497400420639
Validation loss: 2.4934907063977763

Epoch: 6| Step: 3
Training loss: 1.6509589125374504
Validation loss: 2.5245804043195985

Epoch: 6| Step: 4
Training loss: 2.103120474505834
Validation loss: 2.470394122364552

Epoch: 6| Step: 5
Training loss: 1.5216987272786826
Validation loss: 2.453339167052563

Epoch: 6| Step: 6
Training loss: 1.3998412433937777
Validation loss: 2.47402675376453

Epoch: 6| Step: 7
Training loss: 1.8104500852718879
Validation loss: 2.5160976916875772

Epoch: 6| Step: 8
Training loss: 1.7812518738853904
Validation loss: 2.5139336826096557

Epoch: 6| Step: 9
Training loss: 1.6862395488847794
Validation loss: 2.5021606809044723

Epoch: 6| Step: 10
Training loss: 2.0262457606690742
Validation loss: 2.451994230428641

Epoch: 6| Step: 11
Training loss: 2.2023478550921745
Validation loss: 2.4720692862845475

Epoch: 6| Step: 12
Training loss: 1.318365297657414
Validation loss: 2.4614697140158164

Epoch: 6| Step: 13
Training loss: 1.813271128286425
Validation loss: 2.5025004956512094

Epoch: 430| Step: 0
Training loss: 2.381926124682721
Validation loss: 2.461999098876628

Epoch: 6| Step: 1
Training loss: 1.6858132727588016
Validation loss: 2.4664897320066013

Epoch: 6| Step: 2
Training loss: 1.8508661304621266
Validation loss: 2.4737551466570924

Epoch: 6| Step: 3
Training loss: 1.974547976662746
Validation loss: 2.4844783524896776

Epoch: 6| Step: 4
Training loss: 1.566870870200559
Validation loss: 2.44317784344944

Epoch: 6| Step: 5
Training loss: 1.5885311772568216
Validation loss: 2.492316230717561

Epoch: 6| Step: 6
Training loss: 1.8249844694129955
Validation loss: 2.4759357477486046

Epoch: 6| Step: 7
Training loss: 1.624697583741954
Validation loss: 2.4335482852891923

Epoch: 6| Step: 8
Training loss: 1.7806948415730675
Validation loss: 2.489521171201201

Epoch: 6| Step: 9
Training loss: 1.8546829647789695
Validation loss: 2.4753322576759866

Epoch: 6| Step: 10
Training loss: 1.9173437525864463
Validation loss: 2.4107228208157365

Epoch: 6| Step: 11
Training loss: 1.2944004395626816
Validation loss: 2.4732215006003075

Epoch: 6| Step: 12
Training loss: 1.771693106974657
Validation loss: 2.4285821974108757

Epoch: 6| Step: 13
Training loss: 2.0213318698134612
Validation loss: 2.4939622634332794

Epoch: 431| Step: 0
Training loss: 1.4894531121943024
Validation loss: 2.4868806295143537

Epoch: 6| Step: 1
Training loss: 1.6602437792872429
Validation loss: 2.496881467794486

Epoch: 6| Step: 2
Training loss: 1.229609355842895
Validation loss: 2.4596092831470515

Epoch: 6| Step: 3
Training loss: 2.5143647443129344
Validation loss: 2.4780602577068858

Epoch: 6| Step: 4
Training loss: 1.3976401074896863
Validation loss: 2.4570701764675387

Epoch: 6| Step: 5
Training loss: 2.2644151285328875
Validation loss: 2.4901605778600486

Epoch: 6| Step: 6
Training loss: 1.7515465169920934
Validation loss: 2.4361848777828565

Epoch: 6| Step: 7
Training loss: 1.5095662408517916
Validation loss: 2.4636039480598217

Epoch: 6| Step: 8
Training loss: 1.6894499497576736
Validation loss: 2.5307413418332674

Epoch: 6| Step: 9
Training loss: 1.826375662300878
Validation loss: 2.4961378783144474

Epoch: 6| Step: 10
Training loss: 1.7837188743650478
Validation loss: 2.4623699216965336

Epoch: 6| Step: 11
Training loss: 2.055880008327961
Validation loss: 2.4379125666115704

Epoch: 6| Step: 12
Training loss: 1.6918793824853917
Validation loss: 2.52258860199296

Epoch: 6| Step: 13
Training loss: 2.2323270362072916
Validation loss: 2.4271808903759706

Epoch: 432| Step: 0
Training loss: 2.5294262944990074
Validation loss: 2.5147791735853597

Epoch: 6| Step: 1
Training loss: 1.662450591765739
Validation loss: 2.461977503069313

Epoch: 6| Step: 2
Training loss: 1.8612070754758896
Validation loss: 2.4634956498305547

Epoch: 6| Step: 3
Training loss: 2.0209857712763384
Validation loss: 2.46413426592117

Epoch: 6| Step: 4
Training loss: 1.6442406911889522
Validation loss: 2.5063422979966106

Epoch: 6| Step: 5
Training loss: 1.6514626175948497
Validation loss: 2.4652442989553593

Epoch: 6| Step: 6
Training loss: 1.5891398153185312
Validation loss: 2.4954434493798674

Epoch: 6| Step: 7
Training loss: 1.7206698705640187
Validation loss: 2.4747174168490846

Epoch: 6| Step: 8
Training loss: 1.6114015134802637
Validation loss: 2.481640905119832

Epoch: 6| Step: 9
Training loss: 1.4753614920198406
Validation loss: 2.465317136535169

Epoch: 6| Step: 10
Training loss: 1.8122180851017824
Validation loss: 2.443621830489885

Epoch: 6| Step: 11
Training loss: 1.7932764923678735
Validation loss: 2.4469983555219117

Epoch: 6| Step: 12
Training loss: 1.9934330655455434
Validation loss: 2.4503610921631696

Epoch: 6| Step: 13
Training loss: 1.7331559992211054
Validation loss: 2.481526674844484

Epoch: 433| Step: 0
Training loss: 1.5813464531110333
Validation loss: 2.4335607466106373

Epoch: 6| Step: 1
Training loss: 2.181274601926032
Validation loss: 2.4641503761818893

Epoch: 6| Step: 2
Training loss: 1.2477140982921389
Validation loss: 2.453327812493853

Epoch: 6| Step: 3
Training loss: 2.3003809115903877
Validation loss: 2.4677240533051474

Epoch: 6| Step: 4
Training loss: 1.3709551531957471
Validation loss: 2.439187293863999

Epoch: 6| Step: 5
Training loss: 1.5191870449092317
Validation loss: 2.470922876031196

Epoch: 6| Step: 6
Training loss: 2.071190759321561
Validation loss: 2.5001000722729554

Epoch: 6| Step: 7
Training loss: 1.9476190703477858
Validation loss: 2.4716281150126007

Epoch: 6| Step: 8
Training loss: 1.7248928230272123
Validation loss: 2.45838282882756

Epoch: 6| Step: 9
Training loss: 1.4971551939509042
Validation loss: 2.483068278223104

Epoch: 6| Step: 10
Training loss: 1.8584548211978336
Validation loss: 2.4901356790807108

Epoch: 6| Step: 11
Training loss: 2.086559074459603
Validation loss: 2.4765719230516323

Epoch: 6| Step: 12
Training loss: 1.7208609362490506
Validation loss: 2.4725244344367874

Epoch: 6| Step: 13
Training loss: 2.1891610514793025
Validation loss: 2.4783828172124642

Epoch: 434| Step: 0
Training loss: 1.4118544479029322
Validation loss: 2.4422342807849127

Epoch: 6| Step: 1
Training loss: 2.0823256407945188
Validation loss: 2.5081870154275356

Epoch: 6| Step: 2
Training loss: 1.8010250431291603
Validation loss: 2.4805083649158854

Epoch: 6| Step: 3
Training loss: 2.4321603242644234
Validation loss: 2.5001914658599493

Epoch: 6| Step: 4
Training loss: 1.9888107104478765
Validation loss: 2.5280681945713264

Epoch: 6| Step: 5
Training loss: 1.628740553810206
Validation loss: 2.4527032093876784

Epoch: 6| Step: 6
Training loss: 1.7231232232938012
Validation loss: 2.5037172256490505

Epoch: 6| Step: 7
Training loss: 1.702194519644785
Validation loss: 2.53044423888452

Epoch: 6| Step: 8
Training loss: 1.3423713886735646
Validation loss: 2.4721862079746613

Epoch: 6| Step: 9
Training loss: 1.558304762280863
Validation loss: 2.492301860886605

Epoch: 6| Step: 10
Training loss: 2.1283260569775417
Validation loss: 2.490149198680353

Epoch: 6| Step: 11
Training loss: 1.854777060630499
Validation loss: 2.4092746066827946

Epoch: 6| Step: 12
Training loss: 1.3943115830715749
Validation loss: 2.489420552148747

Epoch: 6| Step: 13
Training loss: 1.530820591720746
Validation loss: 2.4501291226349213

Epoch: 435| Step: 0
Training loss: 1.881760679362424
Validation loss: 2.412442756801297

Epoch: 6| Step: 1
Training loss: 1.6916869461397472
Validation loss: 2.4602217219777627

Epoch: 6| Step: 2
Training loss: 1.5540245597990066
Validation loss: 2.5002193446994605

Epoch: 6| Step: 3
Training loss: 1.592274450262038
Validation loss: 2.448855906691034

Epoch: 6| Step: 4
Training loss: 1.3377346866809812
Validation loss: 2.489190024774932

Epoch: 6| Step: 5
Training loss: 1.7029437047375133
Validation loss: 2.485799360349176

Epoch: 6| Step: 6
Training loss: 1.6282913913745933
Validation loss: 2.5001943143576444

Epoch: 6| Step: 7
Training loss: 1.5144431628710582
Validation loss: 2.4914581201539425

Epoch: 6| Step: 8
Training loss: 2.5403029947458524
Validation loss: 2.4683748850454363

Epoch: 6| Step: 9
Training loss: 1.9937271451686474
Validation loss: 2.4481004316534585

Epoch: 6| Step: 10
Training loss: 2.2809273478549525
Validation loss: 2.463222312732784

Epoch: 6| Step: 11
Training loss: 1.4309746623165256
Validation loss: 2.4856806228040003

Epoch: 6| Step: 12
Training loss: 1.8546261450269115
Validation loss: 2.4320397295393126

Epoch: 6| Step: 13
Training loss: 1.4888254207080687
Validation loss: 2.439107218301275

Epoch: 436| Step: 0
Training loss: 1.958701024809515
Validation loss: 2.4212788202996873

Epoch: 6| Step: 1
Training loss: 1.9046610479106194
Validation loss: 2.4979423474076685

Epoch: 6| Step: 2
Training loss: 1.311558340237365
Validation loss: 2.437033385362935

Epoch: 6| Step: 3
Training loss: 1.6796910485518475
Validation loss: 2.4604206647376166

Epoch: 6| Step: 4
Training loss: 1.5939676472768152
Validation loss: 2.4870076887473846

Epoch: 6| Step: 5
Training loss: 1.6915825802555353
Validation loss: 2.4619390759234205

Epoch: 6| Step: 6
Training loss: 1.9072789401329984
Validation loss: 2.461526661978237

Epoch: 6| Step: 7
Training loss: 1.6687234426378246
Validation loss: 2.4321653684588447

Epoch: 6| Step: 8
Training loss: 2.405390598356962
Validation loss: 2.444955594733907

Epoch: 6| Step: 9
Training loss: 1.4001669818205937
Validation loss: 2.4427303900325135

Epoch: 6| Step: 10
Training loss: 1.7064817054677708
Validation loss: 2.4884001627362635

Epoch: 6| Step: 11
Training loss: 1.5665035074914944
Validation loss: 2.4544793768889934

Epoch: 6| Step: 12
Training loss: 1.9266333870944965
Validation loss: 2.455623646147232

Epoch: 6| Step: 13
Training loss: 2.239392921574069
Validation loss: 2.523770641698445

Epoch: 437| Step: 0
Training loss: 2.188914032720143
Validation loss: 2.456464119042302

Epoch: 6| Step: 1
Training loss: 2.249162942101908
Validation loss: 2.469060809465648

Epoch: 6| Step: 2
Training loss: 1.8247485157387902
Validation loss: 2.5202738697789036

Epoch: 6| Step: 3
Training loss: 1.3972893375627384
Validation loss: 2.461239263312734

Epoch: 6| Step: 4
Training loss: 1.661051860902282
Validation loss: 2.4752095457459244

Epoch: 6| Step: 5
Training loss: 1.6792999530204114
Validation loss: 2.420320803032889

Epoch: 6| Step: 6
Training loss: 1.626304542981485
Validation loss: 2.453359768347158

Epoch: 6| Step: 7
Training loss: 1.6279964696485028
Validation loss: 2.458259655109239

Epoch: 6| Step: 8
Training loss: 2.0788527053537584
Validation loss: 2.483718718829635

Epoch: 6| Step: 9
Training loss: 1.4971550347031573
Validation loss: 2.462832450090184

Epoch: 6| Step: 10
Training loss: 1.6507651722274466
Validation loss: 2.3942077050910866

Epoch: 6| Step: 11
Training loss: 1.945348226073642
Validation loss: 2.460788196332438

Epoch: 6| Step: 12
Training loss: 1.7527180408441865
Validation loss: 2.4740976370606163

Epoch: 6| Step: 13
Training loss: 1.2752215286483741
Validation loss: 2.448395233048095

Epoch: 438| Step: 0
Training loss: 2.0775329205306643
Validation loss: 2.4658106165138602

Epoch: 6| Step: 1
Training loss: 1.225837250129948
Validation loss: 2.4520504386785675

Epoch: 6| Step: 2
Training loss: 1.3564275598977795
Validation loss: 2.5007135952001764

Epoch: 6| Step: 3
Training loss: 1.8693426614946722
Validation loss: 2.4656751109619317

Epoch: 6| Step: 4
Training loss: 1.567944539505219
Validation loss: 2.449384570639515

Epoch: 6| Step: 5
Training loss: 1.6166422196470112
Validation loss: 2.479814647588169

Epoch: 6| Step: 6
Training loss: 1.7818937644117665
Validation loss: 2.478504568342773

Epoch: 6| Step: 7
Training loss: 1.999184501804791
Validation loss: 2.490656815177947

Epoch: 6| Step: 8
Training loss: 1.7785819969804344
Validation loss: 2.4932671205792314

Epoch: 6| Step: 9
Training loss: 1.6093240378005227
Validation loss: 2.5017694523026943

Epoch: 6| Step: 10
Training loss: 1.9833730736392134
Validation loss: 2.4749264499114236

Epoch: 6| Step: 11
Training loss: 1.6786086765319137
Validation loss: 2.485639238477427

Epoch: 6| Step: 12
Training loss: 2.2615420679316167
Validation loss: 2.454324552713521

Epoch: 6| Step: 13
Training loss: 1.315937626679468
Validation loss: 2.526798883697928

Epoch: 439| Step: 0
Training loss: 1.9868433461363233
Validation loss: 2.4566554241783334

Epoch: 6| Step: 1
Training loss: 1.8181685891537136
Validation loss: 2.5023174732252107

Epoch: 6| Step: 2
Training loss: 1.9603726610791115
Validation loss: 2.470181643116825

Epoch: 6| Step: 3
Training loss: 1.8241107916897172
Validation loss: 2.4622605712261287

Epoch: 6| Step: 4
Training loss: 2.05679491701481
Validation loss: 2.4457293440866037

Epoch: 6| Step: 5
Training loss: 1.9163375101929232
Validation loss: 2.5102366046429867

Epoch: 6| Step: 6
Training loss: 1.5194325549869112
Validation loss: 2.482725994787719

Epoch: 6| Step: 7
Training loss: 2.042832787622926
Validation loss: 2.4839037551907968

Epoch: 6| Step: 8
Training loss: 1.753731563849146
Validation loss: 2.442001753439802

Epoch: 6| Step: 9
Training loss: 1.9462682375485232
Validation loss: 2.4615660537123993

Epoch: 6| Step: 10
Training loss: 1.5709032304560957
Validation loss: 2.4726573531509244

Epoch: 6| Step: 11
Training loss: 1.8253461143769742
Validation loss: 2.42733883735261

Epoch: 6| Step: 12
Training loss: 1.4020566088475697
Validation loss: 2.4458763355524185

Epoch: 6| Step: 13
Training loss: 1.5757864820084266
Validation loss: 2.4961105403373627

Epoch: 440| Step: 0
Training loss: 1.8239854422456803
Validation loss: 2.452998100882475

Epoch: 6| Step: 1
Training loss: 2.3741504756026823
Validation loss: 2.4794776461564925

Epoch: 6| Step: 2
Training loss: 1.6071098460485629
Validation loss: 2.4715459693789237

Epoch: 6| Step: 3
Training loss: 1.4094164061966263
Validation loss: 2.4267100757007114

Epoch: 6| Step: 4
Training loss: 1.4094722705777898
Validation loss: 2.449982244014123

Epoch: 6| Step: 5
Training loss: 1.3581697228937564
Validation loss: 2.421390798635625

Epoch: 6| Step: 6
Training loss: 1.5490478513701087
Validation loss: 2.4645591909479037

Epoch: 6| Step: 7
Training loss: 2.0633316675198947
Validation loss: 2.4106626659508805

Epoch: 6| Step: 8
Training loss: 1.620471218946991
Validation loss: 2.4400413292253034

Epoch: 6| Step: 9
Training loss: 1.4610110177702358
Validation loss: 2.504367241944988

Epoch: 6| Step: 10
Training loss: 1.8256188845638142
Validation loss: 2.4214755900937144

Epoch: 6| Step: 11
Training loss: 2.2319682570698953
Validation loss: 2.4505386706712993

Epoch: 6| Step: 12
Training loss: 2.0087471653004974
Validation loss: 2.5023507817604

Epoch: 6| Step: 13
Training loss: 1.5262662008489483
Validation loss: 2.471810382354006

Epoch: 441| Step: 0
Training loss: 1.9790071590461795
Validation loss: 2.4664074173138997

Epoch: 6| Step: 1
Training loss: 1.068452708963672
Validation loss: 2.4566576912877767

Epoch: 6| Step: 2
Training loss: 1.4054435960979523
Validation loss: 2.4952757302812927

Epoch: 6| Step: 3
Training loss: 1.7686227651602575
Validation loss: 2.51417279567058

Epoch: 6| Step: 4
Training loss: 1.7574851176254458
Validation loss: 2.4685997492119505

Epoch: 6| Step: 5
Training loss: 1.639514656357376
Validation loss: 2.4622654829575583

Epoch: 6| Step: 6
Training loss: 1.9338212312920622
Validation loss: 2.4876454124135594

Epoch: 6| Step: 7
Training loss: 1.7106582204640444
Validation loss: 2.482607465994972

Epoch: 6| Step: 8
Training loss: 2.3593805578305296
Validation loss: 2.4161504820803854

Epoch: 6| Step: 9
Training loss: 1.5951902576206427
Validation loss: 2.49544833278199

Epoch: 6| Step: 10
Training loss: 1.4017848013960805
Validation loss: 2.4213170631843557

Epoch: 6| Step: 11
Training loss: 1.3073655471087993
Validation loss: 2.486652571916354

Epoch: 6| Step: 12
Training loss: 2.451779914002091
Validation loss: 2.493652591

Epoch: 6| Step: 13
Training loss: 1.668777662755159
Validation loss: 2.458389682203924

Epoch: 442| Step: 0
Training loss: 1.5020547145422218
Validation loss: 2.4413779862275264

Epoch: 6| Step: 1
Training loss: 1.1398705900926662
Validation loss: 2.4907562490134474

Epoch: 6| Step: 2
Training loss: 1.3553003212010182
Validation loss: 2.444043635935095

Epoch: 6| Step: 3
Training loss: 1.57498998184651
Validation loss: 2.4514434424771245

Epoch: 6| Step: 4
Training loss: 2.4021537891740534
Validation loss: 2.426910094933203

Epoch: 6| Step: 5
Training loss: 1.8835126279484067
Validation loss: 2.421167895629647

Epoch: 6| Step: 6
Training loss: 1.342992879796131
Validation loss: 2.449365547759219

Epoch: 6| Step: 7
Training loss: 2.7313812433829336
Validation loss: 2.442723002604988

Epoch: 6| Step: 8
Training loss: 1.3924887522820188
Validation loss: 2.429795274051227

Epoch: 6| Step: 9
Training loss: 1.3630245371461989
Validation loss: 2.4632342711172335

Epoch: 6| Step: 10
Training loss: 1.687384707433046
Validation loss: 2.456707845787902

Epoch: 6| Step: 11
Training loss: 1.771749222208517
Validation loss: 2.4251555549908557

Epoch: 6| Step: 12
Training loss: 1.9340833872439074
Validation loss: 2.4511521098107223

Epoch: 6| Step: 13
Training loss: 1.5399405980729457
Validation loss: 2.3948368548707673

Epoch: 443| Step: 0
Training loss: 1.8688033386579503
Validation loss: 2.463083008367808

Epoch: 6| Step: 1
Training loss: 1.7724325550843953
Validation loss: 2.467534601100874

Epoch: 6| Step: 2
Training loss: 1.606233512111009
Validation loss: 2.463529485343602

Epoch: 6| Step: 3
Training loss: 1.4552648232522107
Validation loss: 2.44214205981691

Epoch: 6| Step: 4
Training loss: 1.7856664283334045
Validation loss: 2.465394282145738

Epoch: 6| Step: 5
Training loss: 1.491427162946987
Validation loss: 2.468045957900364

Epoch: 6| Step: 6
Training loss: 1.657333451500968
Validation loss: 2.459379534248052

Epoch: 6| Step: 7
Training loss: 1.9146435536850839
Validation loss: 2.472733211221965

Epoch: 6| Step: 8
Training loss: 1.3459049510895071
Validation loss: 2.419777087037988

Epoch: 6| Step: 9
Training loss: 2.2698766343796604
Validation loss: 2.415425860062718

Epoch: 6| Step: 10
Training loss: 1.2094191353405892
Validation loss: 2.468549580848168

Epoch: 6| Step: 11
Training loss: 2.4709237101999766
Validation loss: 2.494360722366908

Epoch: 6| Step: 12
Training loss: 1.8699984918680077
Validation loss: 2.4386147378831917

Epoch: 6| Step: 13
Training loss: 1.2276913253319868
Validation loss: 2.419080775642902

Epoch: 444| Step: 0
Training loss: 1.7822045562639666
Validation loss: 2.4378846388019713

Epoch: 6| Step: 1
Training loss: 2.000435781686178
Validation loss: 2.4632713240474056

Epoch: 6| Step: 2
Training loss: 1.7549905462635305
Validation loss: 2.4349373924065176

Epoch: 6| Step: 3
Training loss: 1.5626110037474434
Validation loss: 2.4304460129515015

Epoch: 6| Step: 4
Training loss: 2.1761235459260555
Validation loss: 2.4580681384752197

Epoch: 6| Step: 5
Training loss: 2.4312331015188358
Validation loss: 2.4301804118162065

Epoch: 6| Step: 6
Training loss: 1.5224145046589552
Validation loss: 2.4442237281327635

Epoch: 6| Step: 7
Training loss: 1.533543795502231
Validation loss: 2.4585020641099584

Epoch: 6| Step: 8
Training loss: 1.9208175106872576
Validation loss: 2.3948188759817226

Epoch: 6| Step: 9
Training loss: 1.3507681039023758
Validation loss: 2.482758497443365

Epoch: 6| Step: 10
Training loss: 1.469907426319584
Validation loss: 2.417488586025218

Epoch: 6| Step: 11
Training loss: 1.499739942259717
Validation loss: 2.532984111346456

Epoch: 6| Step: 12
Training loss: 1.9794385890545165
Validation loss: 2.476335868068239

Epoch: 6| Step: 13
Training loss: 1.8055617951831435
Validation loss: 2.420533637677603

Epoch: 445| Step: 0
Training loss: 1.7037872986548577
Validation loss: 2.467001153665966

Epoch: 6| Step: 1
Training loss: 1.6549658925670652
Validation loss: 2.456648769978281

Epoch: 6| Step: 2
Training loss: 1.3082889030995366
Validation loss: 2.439528936320116

Epoch: 6| Step: 3
Training loss: 1.3888262141179653
Validation loss: 2.465332949980642

Epoch: 6| Step: 4
Training loss: 1.1284739052523591
Validation loss: 2.4409568176715455

Epoch: 6| Step: 5
Training loss: 2.22641269112937
Validation loss: 2.5251611671764427

Epoch: 6| Step: 6
Training loss: 1.8175227845664583
Validation loss: 2.4873638679981607

Epoch: 6| Step: 7
Training loss: 2.036608977408666
Validation loss: 2.486685158303043

Epoch: 6| Step: 8
Training loss: 1.424881324511073
Validation loss: 2.443307343238292

Epoch: 6| Step: 9
Training loss: 2.01839759041865
Validation loss: 2.4543063358649952

Epoch: 6| Step: 10
Training loss: 1.8567467715151962
Validation loss: 2.457184476362477

Epoch: 6| Step: 11
Training loss: 1.8847854850394723
Validation loss: 2.5164922484151178

Epoch: 6| Step: 12
Training loss: 1.8602303212625395
Validation loss: 2.4681000108932185

Epoch: 6| Step: 13
Training loss: 2.217666791386756
Validation loss: 2.4717844109191134

Epoch: 446| Step: 0
Training loss: 1.5548248230368014
Validation loss: 2.4859898677552095

Epoch: 6| Step: 1
Training loss: 1.7564655483916465
Validation loss: 2.4693575026326036

Epoch: 6| Step: 2
Training loss: 2.227568282120117
Validation loss: 2.4839847046837606

Epoch: 6| Step: 3
Training loss: 1.7589593155727998
Validation loss: 2.4482456042998573

Epoch: 6| Step: 4
Training loss: 1.8141720392897882
Validation loss: 2.389087628511725

Epoch: 6| Step: 5
Training loss: 1.536075307226845
Validation loss: 2.444620402947622

Epoch: 6| Step: 6
Training loss: 2.0358274089005106
Validation loss: 2.488043403356107

Epoch: 6| Step: 7
Training loss: 1.6800709841127888
Validation loss: 2.4659494569875275

Epoch: 6| Step: 8
Training loss: 1.3676118900475078
Validation loss: 2.4377186900338215

Epoch: 6| Step: 9
Training loss: 1.0789172813520043
Validation loss: 2.45525477135891

Epoch: 6| Step: 10
Training loss: 1.318315881082316
Validation loss: 2.4411753061972794

Epoch: 6| Step: 11
Training loss: 2.7669653796369365
Validation loss: 2.4768786717812885

Epoch: 6| Step: 12
Training loss: 1.4500902542438112
Validation loss: 2.440634082253507

Epoch: 6| Step: 13
Training loss: 1.5611009055935712
Validation loss: 2.491077307101421

Epoch: 447| Step: 0
Training loss: 2.416023716955426
Validation loss: 2.4790200289794786

Epoch: 6| Step: 1
Training loss: 1.6795480359752488
Validation loss: 2.46300812500876

Epoch: 6| Step: 2
Training loss: 1.6844473885178035
Validation loss: 2.408393938199246

Epoch: 6| Step: 3
Training loss: 1.81933868948564
Validation loss: 2.4509637938871798

Epoch: 6| Step: 4
Training loss: 1.5823411426087635
Validation loss: 2.4265474022365368

Epoch: 6| Step: 5
Training loss: 1.4270809572668783
Validation loss: 2.4631449950162465

Epoch: 6| Step: 6
Training loss: 2.0953706760281094
Validation loss: 2.4301924399594856

Epoch: 6| Step: 7
Training loss: 1.638216121254007
Validation loss: 2.4254420089167916

Epoch: 6| Step: 8
Training loss: 1.3731911639046228
Validation loss: 2.472411818913765

Epoch: 6| Step: 9
Training loss: 1.561552065359647
Validation loss: 2.4548869146844847

Epoch: 6| Step: 10
Training loss: 1.637431642692594
Validation loss: 2.4286570549858144

Epoch: 6| Step: 11
Training loss: 1.794728730512076
Validation loss: 2.4404872745397843

Epoch: 6| Step: 12
Training loss: 1.6689153125046519
Validation loss: 2.443766781379244

Epoch: 6| Step: 13
Training loss: 1.6806344844824286
Validation loss: 2.473894086347881

Epoch: 448| Step: 0
Training loss: 1.996386840563545
Validation loss: 2.4832922516743587

Epoch: 6| Step: 1
Training loss: 1.6478432402265548
Validation loss: 2.4317977451907087

Epoch: 6| Step: 2
Training loss: 1.5561305111280268
Validation loss: 2.5092414845875965

Epoch: 6| Step: 3
Training loss: 1.3136836572913306
Validation loss: 2.4757611589336195

Epoch: 6| Step: 4
Training loss: 1.526162551761579
Validation loss: 2.4917442042477016

Epoch: 6| Step: 5
Training loss: 1.4879504860002741
Validation loss: 2.4529744536997016

Epoch: 6| Step: 6
Training loss: 2.3103305847624216
Validation loss: 2.5226040432094035

Epoch: 6| Step: 7
Training loss: 1.4814535202372334
Validation loss: 2.4596036646446637

Epoch: 6| Step: 8
Training loss: 1.501871689670961
Validation loss: 2.4566886928211695

Epoch: 6| Step: 9
Training loss: 1.5253934383976937
Validation loss: 2.471560354604659

Epoch: 6| Step: 10
Training loss: 2.1928795198742868
Validation loss: 2.4579563359311134

Epoch: 6| Step: 11
Training loss: 1.412643648118167
Validation loss: 2.4603836834934962

Epoch: 6| Step: 12
Training loss: 1.868298634908196
Validation loss: 2.4370476592494232

Epoch: 6| Step: 13
Training loss: 2.2576988746008673
Validation loss: 2.4755752897542274

Epoch: 449| Step: 0
Training loss: 1.7713310738949812
Validation loss: 2.4695976217599234

Epoch: 6| Step: 1
Training loss: 1.444878012844033
Validation loss: 2.430275096230924

Epoch: 6| Step: 2
Training loss: 1.8056594411193565
Validation loss: 2.4496999699198496

Epoch: 6| Step: 3
Training loss: 2.495233856280424
Validation loss: 2.440787744024465

Epoch: 6| Step: 4
Training loss: 1.002077329198624
Validation loss: 2.4504631685797955

Epoch: 6| Step: 5
Training loss: 1.68902540139701
Validation loss: 2.488658483187102

Epoch: 6| Step: 6
Training loss: 2.029729655637811
Validation loss: 2.42612234039314

Epoch: 6| Step: 7
Training loss: 1.7140035808663814
Validation loss: 2.4737227816831777

Epoch: 6| Step: 8
Training loss: 1.2712086086980385
Validation loss: 2.4989522799692505

Epoch: 6| Step: 9
Training loss: 1.560934503225938
Validation loss: 2.4068014245268157

Epoch: 6| Step: 10
Training loss: 1.5418408097897638
Validation loss: 2.4666045204217166

Epoch: 6| Step: 11
Training loss: 1.9431545437161633
Validation loss: 2.4790047764798575

Epoch: 6| Step: 12
Training loss: 1.6817767257642335
Validation loss: 2.4838996360705456

Epoch: 6| Step: 13
Training loss: 1.6752434425515994
Validation loss: 2.483911443302504

Epoch: 450| Step: 0
Training loss: 1.1590017617634376
Validation loss: 2.464267708970284

Epoch: 6| Step: 1
Training loss: 1.9398307931984287
Validation loss: 2.4221123755356264

Epoch: 6| Step: 2
Training loss: 1.6045424116264448
Validation loss: 2.4357089058426347

Epoch: 6| Step: 3
Training loss: 1.3784595230546794
Validation loss: 2.436469759325056

Epoch: 6| Step: 4
Training loss: 2.1029492875903495
Validation loss: 2.4549875957590923

Epoch: 6| Step: 5
Training loss: 2.296499208602586
Validation loss: 2.4412146241160704

Epoch: 6| Step: 6
Training loss: 1.8448810017985222
Validation loss: 2.4354436086587623

Epoch: 6| Step: 7
Training loss: 1.4926229909958884
Validation loss: 2.491782204675151

Epoch: 6| Step: 8
Training loss: 1.4756609066412107
Validation loss: 2.4243107894942932

Epoch: 6| Step: 9
Training loss: 1.801634613208377
Validation loss: 2.4829656321158473

Epoch: 6| Step: 10
Training loss: 1.787419926910626
Validation loss: 2.473674843849912

Epoch: 6| Step: 11
Training loss: 1.4216917150391937
Validation loss: 2.4990522208293724

Epoch: 6| Step: 12
Training loss: 1.9698790083197555
Validation loss: 2.452086295190735

Epoch: 6| Step: 13
Training loss: 1.3611394458641413
Validation loss: 2.5003612585441077

Epoch: 451| Step: 0
Training loss: 2.3988929340979634
Validation loss: 2.48180773278419

Epoch: 6| Step: 1
Training loss: 1.2409556296606163
Validation loss: 2.4988730464449596

Epoch: 6| Step: 2
Training loss: 1.4530724956912422
Validation loss: 2.4783502876865935

Epoch: 6| Step: 3
Training loss: 1.8222134205494476
Validation loss: 2.4461957388790347

Epoch: 6| Step: 4
Training loss: 1.319725041362478
Validation loss: 2.477973747843749

Epoch: 6| Step: 5
Training loss: 1.3145775020528472
Validation loss: 2.4992108627486354

Epoch: 6| Step: 6
Training loss: 1.1991956379306594
Validation loss: 2.431860498710161

Epoch: 6| Step: 7
Training loss: 1.9298919692959697
Validation loss: 2.4416337280616385

Epoch: 6| Step: 8
Training loss: 1.749686485545046
Validation loss: 2.533425033058747

Epoch: 6| Step: 9
Training loss: 1.3421360347948248
Validation loss: 2.488605356779057

Epoch: 6| Step: 10
Training loss: 2.118998748670913
Validation loss: 2.4385466575260475

Epoch: 6| Step: 11
Training loss: 2.1927919953273562
Validation loss: 2.4703886357974616

Epoch: 6| Step: 12
Training loss: 1.7360159869095158
Validation loss: 2.4360313450439914

Epoch: 6| Step: 13
Training loss: 2.0407756755633852
Validation loss: 2.4331230346061146

Epoch: 452| Step: 0
Training loss: 1.8713783891828206
Validation loss: 2.4438705168718977

Epoch: 6| Step: 1
Training loss: 1.6926863761847137
Validation loss: 2.4130455578073335

Epoch: 6| Step: 2
Training loss: 1.4721514496896588
Validation loss: 2.408715661658538

Epoch: 6| Step: 3
Training loss: 1.6240367969140086
Validation loss: 2.5126634062523308

Epoch: 6| Step: 4
Training loss: 1.5844101339503913
Validation loss: 2.49155917344434

Epoch: 6| Step: 5
Training loss: 1.6810995155120019
Validation loss: 2.4049111434243113

Epoch: 6| Step: 6
Training loss: 1.6473345207730847
Validation loss: 2.417431957003617

Epoch: 6| Step: 7
Training loss: 2.0282688272082683
Validation loss: 2.4533002007172313

Epoch: 6| Step: 8
Training loss: 1.5553888627081172
Validation loss: 2.4840666794446045

Epoch: 6| Step: 9
Training loss: 2.137377314922762
Validation loss: 2.446329350375438

Epoch: 6| Step: 10
Training loss: 1.626499731078479
Validation loss: 2.4306099385058273

Epoch: 6| Step: 11
Training loss: 1.9412798159164721
Validation loss: 2.4785306808823893

Epoch: 6| Step: 12
Training loss: 1.8303313675504396
Validation loss: 2.498619949738729

Epoch: 6| Step: 13
Training loss: 1.411120140784368
Validation loss: 2.482595567884381

Epoch: 453| Step: 0
Training loss: 0.9280657367216981
Validation loss: 2.4915107607761926

Epoch: 6| Step: 1
Training loss: 1.193675447302975
Validation loss: 2.440708162124259

Epoch: 6| Step: 2
Training loss: 1.9839444632063565
Validation loss: 2.509701210517836

Epoch: 6| Step: 3
Training loss: 1.901788211362902
Validation loss: 2.502620252939757

Epoch: 6| Step: 4
Training loss: 1.602135830115427
Validation loss: 2.4463496826945104

Epoch: 6| Step: 5
Training loss: 1.9789578243964034
Validation loss: 2.5097653869983754

Epoch: 6| Step: 6
Training loss: 1.8786664084025293
Validation loss: 2.4546940017521868

Epoch: 6| Step: 7
Training loss: 1.4845192287043865
Validation loss: 2.432443378517411

Epoch: 6| Step: 8
Training loss: 1.6535526119198514
Validation loss: 2.493293058972899

Epoch: 6| Step: 9
Training loss: 2.1806030538235808
Validation loss: 2.4807848527970093

Epoch: 6| Step: 10
Training loss: 1.7525960875764715
Validation loss: 2.4570728235033665

Epoch: 6| Step: 11
Training loss: 1.8234198902002203
Validation loss: 2.4469363233909793

Epoch: 6| Step: 12
Training loss: 1.5548600910943104
Validation loss: 2.4246043597692952

Epoch: 6| Step: 13
Training loss: 1.9361754781469924
Validation loss: 2.490942379965517

Epoch: 454| Step: 0
Training loss: 1.5110622823919933
Validation loss: 2.436006530226902

Epoch: 6| Step: 1
Training loss: 1.6846867175587779
Validation loss: 2.4638488253021795

Epoch: 6| Step: 2
Training loss: 1.3851419429825496
Validation loss: 2.439469627351418

Epoch: 6| Step: 3
Training loss: 1.6008288680329896
Validation loss: 2.4203810737469937

Epoch: 6| Step: 4
Training loss: 2.24620562730882
Validation loss: 2.4376694447089036

Epoch: 6| Step: 5
Training loss: 2.180207002593496
Validation loss: 2.4644954600372375

Epoch: 6| Step: 6
Training loss: 1.6022749641939016
Validation loss: 2.4132326486976217

Epoch: 6| Step: 7
Training loss: 1.645566202367225
Validation loss: 2.487943331459557

Epoch: 6| Step: 8
Training loss: 1.9683896295032055
Validation loss: 2.546502292483826

Epoch: 6| Step: 9
Training loss: 1.4864914111400263
Validation loss: 2.430970503334878

Epoch: 6| Step: 10
Training loss: 1.6334626578040612
Validation loss: 2.44795210966914

Epoch: 6| Step: 11
Training loss: 1.819764214322996
Validation loss: 2.4622094131517755

Epoch: 6| Step: 12
Training loss: 1.8728554223060914
Validation loss: 2.4456181263605803

Epoch: 6| Step: 13
Training loss: 1.617279787240688
Validation loss: 2.4753193489845984

Epoch: 455| Step: 0
Training loss: 2.105122440428769
Validation loss: 2.505822280671769

Epoch: 6| Step: 1
Training loss: 1.4544125666928394
Validation loss: 2.4533784932743576

Epoch: 6| Step: 2
Training loss: 1.8290889839354931
Validation loss: 2.5054423672500157

Epoch: 6| Step: 3
Training loss: 2.3758441027349604
Validation loss: 2.4561994004508794

Epoch: 6| Step: 4
Training loss: 1.0593991752274183
Validation loss: 2.4886571584401525

Epoch: 6| Step: 5
Training loss: 1.9825966743863876
Validation loss: 2.4795513042554225

Epoch: 6| Step: 6
Training loss: 1.663354570843128
Validation loss: 2.416828379950631

Epoch: 6| Step: 7
Training loss: 2.2614082821707924
Validation loss: 2.457085882832514

Epoch: 6| Step: 8
Training loss: 1.130453191622458
Validation loss: 2.4741289516264535

Epoch: 6| Step: 9
Training loss: 1.037460468871969
Validation loss: 2.4559122291222018

Epoch: 6| Step: 10
Training loss: 1.7480989757424203
Validation loss: 2.403300976209076

Epoch: 6| Step: 11
Training loss: 1.7844879435321417
Validation loss: 2.452892451553379

Epoch: 6| Step: 12
Training loss: 1.4250680472205475
Validation loss: 2.443778576901615

Epoch: 6| Step: 13
Training loss: 1.3987451140426648
Validation loss: 2.4326491140126465

Epoch: 456| Step: 0
Training loss: 1.7244373896761476
Validation loss: 2.4504155561854173

Epoch: 6| Step: 1
Training loss: 1.8504509144343595
Validation loss: 2.441144166460296

Epoch: 6| Step: 2
Training loss: 1.4291735282859277
Validation loss: 2.467460954158577

Epoch: 6| Step: 3
Training loss: 1.5503051180626304
Validation loss: 2.4576746230347717

Epoch: 6| Step: 4
Training loss: 2.4963428450630847
Validation loss: 2.4599132338058145

Epoch: 6| Step: 5
Training loss: 1.6293543649763487
Validation loss: 2.446598524559286

Epoch: 6| Step: 6
Training loss: 1.9428026791760462
Validation loss: 2.4691552145949522

Epoch: 6| Step: 7
Training loss: 1.334046838507154
Validation loss: 2.4184818819708034

Epoch: 6| Step: 8
Training loss: 1.4737839971993865
Validation loss: 2.4958686286101046

Epoch: 6| Step: 9
Training loss: 1.644875750849599
Validation loss: 2.4561271149740675

Epoch: 6| Step: 10
Training loss: 1.4904350655585792
Validation loss: 2.4189417122971864

Epoch: 6| Step: 11
Training loss: 1.8389005085685899
Validation loss: 2.4538925837518253

Epoch: 6| Step: 12
Training loss: 1.565026643666408
Validation loss: 2.431197208453834

Epoch: 6| Step: 13
Training loss: 1.6668799104965077
Validation loss: 2.4557076021947806

Epoch: 457| Step: 0
Training loss: 1.024844302005564
Validation loss: 2.4804276513107215

Epoch: 6| Step: 1
Training loss: 1.301865958824757
Validation loss: 2.464877534765488

Epoch: 6| Step: 2
Training loss: 1.6575165710081163
Validation loss: 2.5016552029505705

Epoch: 6| Step: 3
Training loss: 1.4413268524880556
Validation loss: 2.417078727398472

Epoch: 6| Step: 4
Training loss: 2.3594920148316247
Validation loss: 2.4752618493920866

Epoch: 6| Step: 5
Training loss: 1.4316819251375723
Validation loss: 2.4174053631755483

Epoch: 6| Step: 6
Training loss: 1.9013206660413615
Validation loss: 2.4528474281668955

Epoch: 6| Step: 7
Training loss: 1.5285673971594094
Validation loss: 2.450685168641082

Epoch: 6| Step: 8
Training loss: 1.6041906610981567
Validation loss: 2.475498220125043

Epoch: 6| Step: 9
Training loss: 1.824004134106552
Validation loss: 2.440635454599969

Epoch: 6| Step: 10
Training loss: 1.3211696032241276
Validation loss: 2.426545941100412

Epoch: 6| Step: 11
Training loss: 2.0928240194540506
Validation loss: 2.5158277024970808

Epoch: 6| Step: 12
Training loss: 1.750155510123626
Validation loss: 2.415413926081637

Epoch: 6| Step: 13
Training loss: 1.778930827403678
Validation loss: 2.4197731432201492

Epoch: 458| Step: 0
Training loss: 2.476910202696432
Validation loss: 2.4080824494115665

Epoch: 6| Step: 1
Training loss: 1.6346908059995573
Validation loss: 2.500290026300256

Epoch: 6| Step: 2
Training loss: 1.7219965010905411
Validation loss: 2.499492812237969

Epoch: 6| Step: 3
Training loss: 2.0325334455640394
Validation loss: 2.536295859810132

Epoch: 6| Step: 4
Training loss: 1.5648461085209853
Validation loss: 2.4674747341013754

Epoch: 6| Step: 5
Training loss: 1.6028574104881985
Validation loss: 2.4264887268398625

Epoch: 6| Step: 6
Training loss: 1.8443943772676397
Validation loss: 2.4796896576158822

Epoch: 6| Step: 7
Training loss: 2.04054107259754
Validation loss: 2.4475619022157002

Epoch: 6| Step: 8
Training loss: 1.1615881512313453
Validation loss: 2.4704784237467643

Epoch: 6| Step: 9
Training loss: 1.4133432993597461
Validation loss: 2.470506843871133

Epoch: 6| Step: 10
Training loss: 1.1246618186433142
Validation loss: 2.4780964801413807

Epoch: 6| Step: 11
Training loss: 1.8542097779594795
Validation loss: 2.489088287198306

Epoch: 6| Step: 12
Training loss: 1.7332754687896577
Validation loss: 2.43143145758755

Epoch: 6| Step: 13
Training loss: 1.2995751548689944
Validation loss: 2.4883739129448648

Epoch: 459| Step: 0
Training loss: 1.6752325551306395
Validation loss: 2.4682774702271257

Epoch: 6| Step: 1
Training loss: 1.8598290538167148
Validation loss: 2.4946514906084425

Epoch: 6| Step: 2
Training loss: 1.6437043854508901
Validation loss: 2.4663438505802255

Epoch: 6| Step: 3
Training loss: 1.5032327308037152
Validation loss: 2.425555866108096

Epoch: 6| Step: 4
Training loss: 1.5574501067569488
Validation loss: 2.4663491029144993

Epoch: 6| Step: 5
Training loss: 1.8130529152269896
Validation loss: 2.4875375394131742

Epoch: 6| Step: 6
Training loss: 1.546983657257417
Validation loss: 2.467993270725773

Epoch: 6| Step: 7
Training loss: 1.7563841038883965
Validation loss: 2.413036826916701

Epoch: 6| Step: 8
Training loss: 2.332150761339091
Validation loss: 2.4581978341523554

Epoch: 6| Step: 9
Training loss: 1.9568932155271832
Validation loss: 2.447519834072862

Epoch: 6| Step: 10
Training loss: 1.673715166978707
Validation loss: 2.438992416004429

Epoch: 6| Step: 11
Training loss: 1.1198014842941113
Validation loss: 2.445315061214893

Epoch: 6| Step: 12
Training loss: 1.2118267116989176
Validation loss: 2.441525662822278

Epoch: 6| Step: 13
Training loss: 1.2684849579685717
Validation loss: 2.481077372212289

Epoch: 460| Step: 0
Training loss: 1.9193744053493462
Validation loss: 2.469257405916829

Epoch: 6| Step: 1
Training loss: 1.3137736725421145
Validation loss: 2.4055190918657248

Epoch: 6| Step: 2
Training loss: 1.2675095643956107
Validation loss: 2.4817170867060154

Epoch: 6| Step: 3
Training loss: 1.53116716433309
Validation loss: 2.441826979876641

Epoch: 6| Step: 4
Training loss: 1.8822563901324867
Validation loss: 2.4694155295339923

Epoch: 6| Step: 5
Training loss: 1.4521275039734012
Validation loss: 2.431734155090895

Epoch: 6| Step: 6
Training loss: 1.9403880344752482
Validation loss: 2.4163613690556605

Epoch: 6| Step: 7
Training loss: 2.4719733911890773
Validation loss: 2.425739775372734

Epoch: 6| Step: 8
Training loss: 1.6338207289687443
Validation loss: 2.443094814669379

Epoch: 6| Step: 9
Training loss: 1.0826342723640072
Validation loss: 2.4148936516267003

Epoch: 6| Step: 10
Training loss: 1.8717036835952319
Validation loss: 2.433652061846594

Epoch: 6| Step: 11
Training loss: 1.3477189643752312
Validation loss: 2.403195453236563

Epoch: 6| Step: 12
Training loss: 1.468747483920925
Validation loss: 2.4806308167907196

Epoch: 6| Step: 13
Training loss: 2.3808951246098324
Validation loss: 2.438861223618488

Epoch: 461| Step: 0
Training loss: 2.2931654681640143
Validation loss: 2.4959345422454104

Epoch: 6| Step: 1
Training loss: 1.5807106817213141
Validation loss: 2.409117142352902

Epoch: 6| Step: 2
Training loss: 1.8538505484744723
Validation loss: 2.451933087947935

Epoch: 6| Step: 3
Training loss: 1.5124362553806907
Validation loss: 2.3866357077456337

Epoch: 6| Step: 4
Training loss: 1.5376064170667771
Validation loss: 2.4452746192870376

Epoch: 6| Step: 5
Training loss: 1.492941940282489
Validation loss: 2.434323409404738

Epoch: 6| Step: 6
Training loss: 2.0653536158050736
Validation loss: 2.471110671029758

Epoch: 6| Step: 7
Training loss: 1.5554937831027291
Validation loss: 2.4491939484217022

Epoch: 6| Step: 8
Training loss: 1.6488162505032464
Validation loss: 2.4564181842643187

Epoch: 6| Step: 9
Training loss: 1.5517115649083002
Validation loss: 2.461816370156413

Epoch: 6| Step: 10
Training loss: 1.4249947664934393
Validation loss: 2.4812719947354838

Epoch: 6| Step: 11
Training loss: 1.7623977874986125
Validation loss: 2.472201734827198

Epoch: 6| Step: 12
Training loss: 1.6173692684023382
Validation loss: 2.459990500945273

Epoch: 6| Step: 13
Training loss: 1.9209410095927477
Validation loss: 2.4676766326607487

Epoch: 462| Step: 0
Training loss: 2.0251189208727367
Validation loss: 2.47020622618898

Epoch: 6| Step: 1
Training loss: 1.1185399119282315
Validation loss: 2.4338092201928574

Epoch: 6| Step: 2
Training loss: 1.4791943543041177
Validation loss: 2.4326814500474643

Epoch: 6| Step: 3
Training loss: 1.5345948724091047
Validation loss: 2.472007743275018

Epoch: 6| Step: 4
Training loss: 1.7089596119857717
Validation loss: 2.4495224886447575

Epoch: 6| Step: 5
Training loss: 1.4865570894551445
Validation loss: 2.466856549564167

Epoch: 6| Step: 6
Training loss: 2.1965164738520775
Validation loss: 2.47708791470541

Epoch: 6| Step: 7
Training loss: 1.8922965486889025
Validation loss: 2.450818457718788

Epoch: 6| Step: 8
Training loss: 2.2562389764490054
Validation loss: 2.4989673071049916

Epoch: 6| Step: 9
Training loss: 1.5856114696005092
Validation loss: 2.4857772921860346

Epoch: 6| Step: 10
Training loss: 1.5102733237112556
Validation loss: 2.436100148944279

Epoch: 6| Step: 11
Training loss: 1.6411944173217254
Validation loss: 2.48119140309493

Epoch: 6| Step: 12
Training loss: 1.2032648475915027
Validation loss: 2.4301905205452443

Epoch: 6| Step: 13
Training loss: 1.767596131965426
Validation loss: 2.465737834059892

Epoch: 463| Step: 0
Training loss: 1.452243660714499
Validation loss: 2.459584037047697

Epoch: 6| Step: 1
Training loss: 2.4915502803842062
Validation loss: 2.4745712299995515

Epoch: 6| Step: 2
Training loss: 1.530149025110705
Validation loss: 2.432372329518685

Epoch: 6| Step: 3
Training loss: 1.526134431729701
Validation loss: 2.4062708813949585

Epoch: 6| Step: 4
Training loss: 1.5442748131360324
Validation loss: 2.449862537039358

Epoch: 6| Step: 5
Training loss: 1.655877269334117
Validation loss: 2.4283648508867017

Epoch: 6| Step: 6
Training loss: 1.4033304212786135
Validation loss: 2.4234487595919445

Epoch: 6| Step: 7
Training loss: 1.6567162631162884
Validation loss: 2.4864366536346827

Epoch: 6| Step: 8
Training loss: 1.735568486503484
Validation loss: 2.4618475191626863

Epoch: 6| Step: 9
Training loss: 1.6954766119353795
Validation loss: 2.414369984017703

Epoch: 6| Step: 10
Training loss: 1.3762603532088153
Validation loss: 2.436105151831813

Epoch: 6| Step: 11
Training loss: 2.288061867170927
Validation loss: 2.435497724706512

Epoch: 6| Step: 12
Training loss: 1.2015437349161282
Validation loss: 2.4667468040367275

Epoch: 6| Step: 13
Training loss: 1.4162232976754705
Validation loss: 2.4653905210048452

Epoch: 464| Step: 0
Training loss: 1.5729672590123434
Validation loss: 2.4466705802226087

Epoch: 6| Step: 1
Training loss: 1.7761647768132578
Validation loss: 2.500263145400318

Epoch: 6| Step: 2
Training loss: 1.4411688715126485
Validation loss: 2.4485513932890606

Epoch: 6| Step: 3
Training loss: 1.3859323770284315
Validation loss: 2.4485448557936493

Epoch: 6| Step: 4
Training loss: 1.851548915121083
Validation loss: 2.4244011540748485

Epoch: 6| Step: 5
Training loss: 1.5876215370091797
Validation loss: 2.4315387241746707

Epoch: 6| Step: 6
Training loss: 2.55351449710517
Validation loss: 2.4435704998947734

Epoch: 6| Step: 7
Training loss: 1.5493177142830517
Validation loss: 2.4276091694201405

Epoch: 6| Step: 8
Training loss: 2.4019306603046684
Validation loss: 2.4247957198333703

Epoch: 6| Step: 9
Training loss: 1.4502129858718957
Validation loss: 2.4583815550276413

Epoch: 6| Step: 10
Training loss: 1.639117174718536
Validation loss: 2.473363060483054

Epoch: 6| Step: 11
Training loss: 1.139560777811743
Validation loss: 2.4541885048948147

Epoch: 6| Step: 12
Training loss: 1.2941285431882552
Validation loss: 2.4606997222541547

Epoch: 6| Step: 13
Training loss: 1.3045962181823645
Validation loss: 2.473020839465839

Epoch: 465| Step: 0
Training loss: 1.8286184965296124
Validation loss: 2.4923125472347882

Epoch: 6| Step: 1
Training loss: 2.2121546330268966
Validation loss: 2.4386107945691253

Epoch: 6| Step: 2
Training loss: 1.76390842950899
Validation loss: 2.536699200265344

Epoch: 6| Step: 3
Training loss: 1.4728892013096968
Validation loss: 2.4080875296696

Epoch: 6| Step: 4
Training loss: 1.9102418720425405
Validation loss: 2.4807611537440866

Epoch: 6| Step: 5
Training loss: 1.2673238020098199
Validation loss: 2.4725578623027475

Epoch: 6| Step: 6
Training loss: 1.4903897145754381
Validation loss: 2.456858990787125

Epoch: 6| Step: 7
Training loss: 1.4363923158844298
Validation loss: 2.4675992456890756

Epoch: 6| Step: 8
Training loss: 1.7816709054599698
Validation loss: 2.484966091927344

Epoch: 6| Step: 9
Training loss: 1.5616370297567612
Validation loss: 2.407247115401079

Epoch: 6| Step: 10
Training loss: 1.7250015314067733
Validation loss: 2.4839435929547036

Epoch: 6| Step: 11
Training loss: 2.014120679063885
Validation loss: 2.4264556659035423

Epoch: 6| Step: 12
Training loss: 1.631178627060478
Validation loss: 2.4076519262060665

Epoch: 6| Step: 13
Training loss: 1.1089464891283627
Validation loss: 2.462617579900604

Epoch: 466| Step: 0
Training loss: 1.5321668099008725
Validation loss: 2.512981029418213

Epoch: 6| Step: 1
Training loss: 1.315023403394603
Validation loss: 2.449109450344865

Epoch: 6| Step: 2
Training loss: 1.4674432501144699
Validation loss: 2.4576801254674727

Epoch: 6| Step: 3
Training loss: 1.3407594093221622
Validation loss: 2.4223053633505978

Epoch: 6| Step: 4
Training loss: 1.7260530160251852
Validation loss: 2.4665511060843173

Epoch: 6| Step: 5
Training loss: 1.6618138553752018
Validation loss: 2.4389439237778645

Epoch: 6| Step: 6
Training loss: 1.1922465878464004
Validation loss: 2.466237692405282

Epoch: 6| Step: 7
Training loss: 1.4974672869896852
Validation loss: 2.4805523694934637

Epoch: 6| Step: 8
Training loss: 1.6781403269147748
Validation loss: 2.4671591226268204

Epoch: 6| Step: 9
Training loss: 1.5782503890277704
Validation loss: 2.5063230865413377

Epoch: 6| Step: 10
Training loss: 1.7134986415976758
Validation loss: 2.481916442558638

Epoch: 6| Step: 11
Training loss: 1.7875828517039238
Validation loss: 2.4500356795069624

Epoch: 6| Step: 12
Training loss: 2.536617569099452
Validation loss: 2.451810975120541

Epoch: 6| Step: 13
Training loss: 2.1268799263905236
Validation loss: 2.4783205015518113

Epoch: 467| Step: 0
Training loss: 1.6655732223736472
Validation loss: 2.4644295585431277

Epoch: 6| Step: 1
Training loss: 1.7970898043737633
Validation loss: 2.43760430191986

Epoch: 6| Step: 2
Training loss: 1.1941236680074407
Validation loss: 2.514155373433039

Epoch: 6| Step: 3
Training loss: 1.6963402933083014
Validation loss: 2.4402565999065127

Epoch: 6| Step: 4
Training loss: 1.5292197021656029
Validation loss: 2.449245441156107

Epoch: 6| Step: 5
Training loss: 2.243312327592214
Validation loss: 2.4836368187737583

Epoch: 6| Step: 6
Training loss: 1.907223562305628
Validation loss: 2.4821965609179193

Epoch: 6| Step: 7
Training loss: 1.5860648268526882
Validation loss: 2.444438236153488

Epoch: 6| Step: 8
Training loss: 1.2311996953147128
Validation loss: 2.5119675560409864

Epoch: 6| Step: 9
Training loss: 1.3805890068173563
Validation loss: 2.4226272330425163

Epoch: 6| Step: 10
Training loss: 2.165826732492852
Validation loss: 2.438429357380022

Epoch: 6| Step: 11
Training loss: 1.5979901177121034
Validation loss: 2.4566729030423393

Epoch: 6| Step: 12
Training loss: 1.4266488557814907
Validation loss: 2.4456981134858204

Epoch: 6| Step: 13
Training loss: 1.4085665801226535
Validation loss: 2.4925949540762

Epoch: 468| Step: 0
Training loss: 1.302031503281591
Validation loss: 2.4464267096526875

Epoch: 6| Step: 1
Training loss: 1.5166484091082502
Validation loss: 2.4616537561971685

Epoch: 6| Step: 2
Training loss: 1.8729260100349805
Validation loss: 2.4704548318117943

Epoch: 6| Step: 3
Training loss: 1.388379630926914
Validation loss: 2.3875236450357646

Epoch: 6| Step: 4
Training loss: 1.9516767091218543
Validation loss: 2.441453825981333

Epoch: 6| Step: 5
Training loss: 1.3934962601900647
Validation loss: 2.4613990925047573

Epoch: 6| Step: 6
Training loss: 1.8520469836460867
Validation loss: 2.47647918056892

Epoch: 6| Step: 7
Training loss: 1.7834737181741616
Validation loss: 2.42833454347445

Epoch: 6| Step: 8
Training loss: 1.945083972422471
Validation loss: 2.4284181719268263

Epoch: 6| Step: 9
Training loss: 1.9961317323777434
Validation loss: 2.488949499401523

Epoch: 6| Step: 10
Training loss: 1.6266283533138992
Validation loss: 2.4626240113300284

Epoch: 6| Step: 11
Training loss: 1.2440210880841054
Validation loss: 2.450281877690853

Epoch: 6| Step: 12
Training loss: 1.5737953847290265
Validation loss: 2.4762505967353365

Epoch: 6| Step: 13
Training loss: 1.6919122163803333
Validation loss: 2.490225008794715

Epoch: 469| Step: 0
Training loss: 1.7741217952493178
Validation loss: 2.4507504224297123

Epoch: 6| Step: 1
Training loss: 0.8868994843730402
Validation loss: 2.4476838667289815

Epoch: 6| Step: 2
Training loss: 1.1969906863086868
Validation loss: 2.4809879518268376

Epoch: 6| Step: 3
Training loss: 1.978907283717931
Validation loss: 2.462471165084024

Epoch: 6| Step: 4
Training loss: 1.5329346245538744
Validation loss: 2.4829937952237575

Epoch: 6| Step: 5
Training loss: 2.111947306727041
Validation loss: 2.466324471001915

Epoch: 6| Step: 6
Training loss: 1.390918614969155
Validation loss: 2.44679085827248

Epoch: 6| Step: 7
Training loss: 1.4911071701269345
Validation loss: 2.4513759602431935

Epoch: 6| Step: 8
Training loss: 1.9763617734046062
Validation loss: 2.435684358768049

Epoch: 6| Step: 9
Training loss: 2.1776312423028865
Validation loss: 2.3938351966666453

Epoch: 6| Step: 10
Training loss: 1.5843383544054706
Validation loss: 2.444122331995573

Epoch: 6| Step: 11
Training loss: 1.6591059694758619
Validation loss: 2.4468306967874884

Epoch: 6| Step: 12
Training loss: 1.3771170011358893
Validation loss: 2.456247895397562

Epoch: 6| Step: 13
Training loss: 1.7365010607732931
Validation loss: 2.5051967670128557

Epoch: 470| Step: 0
Training loss: 1.894609272716844
Validation loss: 2.4232956693284216

Epoch: 6| Step: 1
Training loss: 1.4009370682064959
Validation loss: 2.4269676694984472

Epoch: 6| Step: 2
Training loss: 1.3412319809982227
Validation loss: 2.439329646498523

Epoch: 6| Step: 3
Training loss: 2.201282136282868
Validation loss: 2.4456846332818456

Epoch: 6| Step: 4
Training loss: 1.1967558281037196
Validation loss: 2.4783661700307436

Epoch: 6| Step: 5
Training loss: 1.6400575655626772
Validation loss: 2.4539372745509245

Epoch: 6| Step: 6
Training loss: 1.5836879768059233
Validation loss: 2.466238640424127

Epoch: 6| Step: 7
Training loss: 1.8441503057890365
Validation loss: 2.4593168877003913

Epoch: 6| Step: 8
Training loss: 1.6936728287461926
Validation loss: 2.437639505387167

Epoch: 6| Step: 9
Training loss: 1.3695660636206857
Validation loss: 2.44685609385586

Epoch: 6| Step: 10
Training loss: 1.6082235865464543
Validation loss: 2.4685014501221505

Epoch: 6| Step: 11
Training loss: 1.4270666729402393
Validation loss: 2.4463796076372746

Epoch: 6| Step: 12
Training loss: 2.136782908478896
Validation loss: 2.4812798676775443

Epoch: 6| Step: 13
Training loss: 1.8736652073624027
Validation loss: 2.4932035332800995

Epoch: 471| Step: 0
Training loss: 0.9137843108095428
Validation loss: 2.477923298527656

Epoch: 6| Step: 1
Training loss: 1.623286884800025
Validation loss: 2.517852076620227

Epoch: 6| Step: 2
Training loss: 2.0532255011685105
Validation loss: 2.5032791945389756

Epoch: 6| Step: 3
Training loss: 1.7134388097562903
Validation loss: 2.436664228715728

Epoch: 6| Step: 4
Training loss: 2.1217391856890946
Validation loss: 2.4570570236725313

Epoch: 6| Step: 5
Training loss: 1.9022822751994415
Validation loss: 2.484316407705434

Epoch: 6| Step: 6
Training loss: 1.5214439455275124
Validation loss: 2.433032568275283

Epoch: 6| Step: 7
Training loss: 1.786029159850369
Validation loss: 2.398828539059195

Epoch: 6| Step: 8
Training loss: 1.6553129028296778
Validation loss: 2.455240005023737

Epoch: 6| Step: 9
Training loss: 1.5883391287672235
Validation loss: 2.482384963334923

Epoch: 6| Step: 10
Training loss: 1.116604686316991
Validation loss: 2.4654389173097466

Epoch: 6| Step: 11
Training loss: 2.0872010251055504
Validation loss: 2.462578820240933

Epoch: 6| Step: 12
Training loss: 1.2795829161967611
Validation loss: 2.472072493854572

Epoch: 6| Step: 13
Training loss: 1.4518482793351708
Validation loss: 2.471095912297574

Epoch: 472| Step: 0
Training loss: 1.705883766525797
Validation loss: 2.444319100917014

Epoch: 6| Step: 1
Training loss: 2.149926907383664
Validation loss: 2.444543660955751

Epoch: 6| Step: 2
Training loss: 1.8665762184005534
Validation loss: 2.448029168938017

Epoch: 6| Step: 3
Training loss: 1.6062851660771575
Validation loss: 2.4338496567159766

Epoch: 6| Step: 4
Training loss: 1.5724398498675287
Validation loss: 2.4706183596724234

Epoch: 6| Step: 5
Training loss: 1.2053512189608533
Validation loss: 2.4669333435876273

Epoch: 6| Step: 6
Training loss: 2.2275841226330786
Validation loss: 2.432398010347732

Epoch: 6| Step: 7
Training loss: 1.4812772852963954
Validation loss: 2.425216881022945

Epoch: 6| Step: 8
Training loss: 1.5232972691869766
Validation loss: 2.45421045702559

Epoch: 6| Step: 9
Training loss: 1.8737246944660402
Validation loss: 2.5001427496896524

Epoch: 6| Step: 10
Training loss: 1.1961127700140561
Validation loss: 2.446150765159164

Epoch: 6| Step: 11
Training loss: 1.6290728074506362
Validation loss: 2.4395250627907865

Epoch: 6| Step: 12
Training loss: 1.2837742386621804
Validation loss: 2.460194734128498

Epoch: 6| Step: 13
Training loss: 1.5234794415300288
Validation loss: 2.4082716615619915

Epoch: 473| Step: 0
Training loss: 1.7055989067678903
Validation loss: 2.446678811787216

Epoch: 6| Step: 1
Training loss: 1.5842515223915523
Validation loss: 2.394115603364542

Epoch: 6| Step: 2
Training loss: 1.657476870460291
Validation loss: 2.427822081060399

Epoch: 6| Step: 3
Training loss: 1.6027468140445045
Validation loss: 2.4802332281749915

Epoch: 6| Step: 4
Training loss: 1.6452809706634817
Validation loss: 2.4387125975209427

Epoch: 6| Step: 5
Training loss: 1.8337569903219029
Validation loss: 2.4543341917114696

Epoch: 6| Step: 6
Training loss: 1.3967972411630964
Validation loss: 2.4712800768279686

Epoch: 6| Step: 7
Training loss: 1.7257865439420557
Validation loss: 2.492114688584899

Epoch: 6| Step: 8
Training loss: 1.1530165437800135
Validation loss: 2.479149677124986

Epoch: 6| Step: 9
Training loss: 1.2381692829714632
Validation loss: 2.44837305915115

Epoch: 6| Step: 10
Training loss: 1.8203083742283248
Validation loss: 2.478231793746079

Epoch: 6| Step: 11
Training loss: 2.1682398171262176
Validation loss: 2.4754292633437998

Epoch: 6| Step: 12
Training loss: 1.6546005816950744
Validation loss: 2.4919354114584897

Epoch: 6| Step: 13
Training loss: 1.3872212963451684
Validation loss: 2.4319949836828654

Epoch: 474| Step: 0
Training loss: 1.7546811845076407
Validation loss: 2.464056142407519

Epoch: 6| Step: 1
Training loss: 1.9856864620466697
Validation loss: 2.405002823731353

Epoch: 6| Step: 2
Training loss: 2.3886413322735596
Validation loss: 2.478777881751969

Epoch: 6| Step: 3
Training loss: 1.2078447779281738
Validation loss: 2.4509755981809818

Epoch: 6| Step: 4
Training loss: 1.3385801000557034
Validation loss: 2.46313979101212

Epoch: 6| Step: 5
Training loss: 1.9251670244756156
Validation loss: 2.470595917245701

Epoch: 6| Step: 6
Training loss: 1.7420318944575535
Validation loss: 2.39337973095549

Epoch: 6| Step: 7
Training loss: 1.3636108699496259
Validation loss: 2.4693102602624344

Epoch: 6| Step: 8
Training loss: 1.895304225265164
Validation loss: 2.46288121622166

Epoch: 6| Step: 9
Training loss: 1.3963856055270407
Validation loss: 2.4499995753355077

Epoch: 6| Step: 10
Training loss: 1.3731521848228316
Validation loss: 2.4419857007249557

Epoch: 6| Step: 11
Training loss: 1.2553709038311798
Validation loss: 2.420360716051767

Epoch: 6| Step: 12
Training loss: 1.5012862730448222
Validation loss: 2.3980731383386416

Epoch: 6| Step: 13
Training loss: 1.5273291545668113
Validation loss: 2.3898045607003353

Epoch: 475| Step: 0
Training loss: 2.314088739610843
Validation loss: 2.4425359564946545

Epoch: 6| Step: 1
Training loss: 1.584125554840441
Validation loss: 2.4559305060851693

Epoch: 6| Step: 2
Training loss: 1.42554210590755
Validation loss: 2.403739372677308

Epoch: 6| Step: 3
Training loss: 1.6925451659764472
Validation loss: 2.4446088694652928

Epoch: 6| Step: 4
Training loss: 1.760057634688747
Validation loss: 2.4787860542691824

Epoch: 6| Step: 5
Training loss: 1.1574051216244203
Validation loss: 2.414204752941115

Epoch: 6| Step: 6
Training loss: 1.8531884888553107
Validation loss: 2.4217509195256928

Epoch: 6| Step: 7
Training loss: 1.6954318237502166
Validation loss: 2.4877454282806797

Epoch: 6| Step: 8
Training loss: 1.8946524355168448
Validation loss: 2.466647223412872

Epoch: 6| Step: 9
Training loss: 1.489250128053945
Validation loss: 2.4434178981285877

Epoch: 6| Step: 10
Training loss: 1.4031165923480529
Validation loss: 2.440656335389066

Epoch: 6| Step: 11
Training loss: 1.4958840165898115
Validation loss: 2.445144969961371

Epoch: 6| Step: 12
Training loss: 2.006569562993721
Validation loss: 2.407756069342154

Epoch: 6| Step: 13
Training loss: 0.9790391872831513
Validation loss: 2.490092994879761

Epoch: 476| Step: 0
Training loss: 1.672194405821098
Validation loss: 2.4127704627302156

Epoch: 6| Step: 1
Training loss: 1.0590296337062783
Validation loss: 2.4417819393399878

Epoch: 6| Step: 2
Training loss: 1.652022670996697
Validation loss: 2.494030332613261

Epoch: 6| Step: 3
Training loss: 1.1293760595860285
Validation loss: 2.422294327936896

Epoch: 6| Step: 4
Training loss: 1.7630123286603248
Validation loss: 2.537820698846125

Epoch: 6| Step: 5
Training loss: 1.5524485966869321
Validation loss: 2.445148901689253

Epoch: 6| Step: 6
Training loss: 1.4448126676097055
Validation loss: 2.476274556365381

Epoch: 6| Step: 7
Training loss: 1.8854085033373502
Validation loss: 2.443488728775668

Epoch: 6| Step: 8
Training loss: 1.7893954970784407
Validation loss: 2.4808935205911147

Epoch: 6| Step: 9
Training loss: 1.5253693680497111
Validation loss: 2.4691505481026814

Epoch: 6| Step: 10
Training loss: 1.374575809590375
Validation loss: 2.4909790341210702

Epoch: 6| Step: 11
Training loss: 1.873435066736978
Validation loss: 2.4154915362353826

Epoch: 6| Step: 12
Training loss: 2.6169321419558833
Validation loss: 2.4632781856785235

Epoch: 6| Step: 13
Training loss: 1.6291091024208084
Validation loss: 2.5066128516976884

Epoch: 477| Step: 0
Training loss: 1.4103621652159966
Validation loss: 2.4987516680793274

Epoch: 6| Step: 1
Training loss: 1.1698197207168146
Validation loss: 2.4571583409460818

Epoch: 6| Step: 2
Training loss: 1.5904126098570412
Validation loss: 2.4712029966949

Epoch: 6| Step: 3
Training loss: 2.4594776485983925
Validation loss: 2.430723982882436

Epoch: 6| Step: 4
Training loss: 1.5274165689812207
Validation loss: 2.455070382099644

Epoch: 6| Step: 5
Training loss: 1.965880285524103
Validation loss: 2.4909182598681165

Epoch: 6| Step: 6
Training loss: 1.5489631199543648
Validation loss: 2.480485160346375

Epoch: 6| Step: 7
Training loss: 1.7606659511452525
Validation loss: 2.4648797428291966

Epoch: 6| Step: 8
Training loss: 1.6603673464136246
Validation loss: 2.471644038477793

Epoch: 6| Step: 9
Training loss: 0.9031257708589109
Validation loss: 2.465676630009513

Epoch: 6| Step: 10
Training loss: 1.6047097149790501
Validation loss: 2.433714523693521

Epoch: 6| Step: 11
Training loss: 1.9313935062953038
Validation loss: 2.4648728716154937

Epoch: 6| Step: 12
Training loss: 1.3280852367956124
Validation loss: 2.477430113045153

Epoch: 6| Step: 13
Training loss: 1.7483173182468859
Validation loss: 2.4335514214313023

Epoch: 478| Step: 0
Training loss: 2.11424484425151
Validation loss: 2.4401556120279455

Epoch: 6| Step: 1
Training loss: 1.143325587256599
Validation loss: 2.437094515068939

Epoch: 6| Step: 2
Training loss: 1.545337028038758
Validation loss: 2.3915501980547638

Epoch: 6| Step: 3
Training loss: 1.425383713575581
Validation loss: 2.4162721817598163

Epoch: 6| Step: 4
Training loss: 1.3671369270780345
Validation loss: 2.3936515425654257

Epoch: 6| Step: 5
Training loss: 2.0641805564506477
Validation loss: 2.4264999005991443

Epoch: 6| Step: 6
Training loss: 1.408746833966953
Validation loss: 2.449647994345512

Epoch: 6| Step: 7
Training loss: 2.0727960624945996
Validation loss: 2.444432665108832

Epoch: 6| Step: 8
Training loss: 1.2812772143195192
Validation loss: 2.465649520951932

Epoch: 6| Step: 9
Training loss: 1.6114005517576802
Validation loss: 2.435446052356793

Epoch: 6| Step: 10
Training loss: 1.757834133438927
Validation loss: 2.4345409395043194

Epoch: 6| Step: 11
Training loss: 1.46420786979654
Validation loss: 2.457738096889441

Epoch: 6| Step: 12
Training loss: 1.3611648439756592
Validation loss: 2.4346633615026003

Epoch: 6| Step: 13
Training loss: 1.546597619666736
Validation loss: 2.4076664083540207

Epoch: 479| Step: 0
Training loss: 2.1518972941143133
Validation loss: 2.425334499112583

Epoch: 6| Step: 1
Training loss: 1.5055311268274847
Validation loss: 2.498005763791755

Epoch: 6| Step: 2
Training loss: 2.068745952498519
Validation loss: 2.4114100106927023

Epoch: 6| Step: 3
Training loss: 1.528760404262868
Validation loss: 2.461334803774991

Epoch: 6| Step: 4
Training loss: 1.2016931906712358
Validation loss: 2.4462590023076363

Epoch: 6| Step: 5
Training loss: 1.583156308099116
Validation loss: 2.462917365761333

Epoch: 6| Step: 6
Training loss: 2.2386187819849783
Validation loss: 2.434629156409315

Epoch: 6| Step: 7
Training loss: 2.042863248650175
Validation loss: 2.4215634751994113

Epoch: 6| Step: 8
Training loss: 1.4466012518606381
Validation loss: 2.4137581269885153

Epoch: 6| Step: 9
Training loss: 1.3278663832248365
Validation loss: 2.410779878603266

Epoch: 6| Step: 10
Training loss: 1.1021963690110788
Validation loss: 2.4612404986566827

Epoch: 6| Step: 11
Training loss: 1.4179223423449179
Validation loss: 2.418092545343724

Epoch: 6| Step: 12
Training loss: 1.3948328456065704
Validation loss: 2.498810224548428

Epoch: 6| Step: 13
Training loss: 1.578831807098784
Validation loss: 2.460932823654604

Epoch: 480| Step: 0
Training loss: 1.6557432155087108
Validation loss: 2.465287964533245

Epoch: 6| Step: 1
Training loss: 1.613452006394323
Validation loss: 2.466712823503574

Epoch: 6| Step: 2
Training loss: 1.9174758681826654
Validation loss: 2.448950661502295

Epoch: 6| Step: 3
Training loss: 1.537215620583612
Validation loss: 2.442804636688983

Epoch: 6| Step: 4
Training loss: 1.6226175890427776
Validation loss: 2.4204724524805123

Epoch: 6| Step: 5
Training loss: 1.3317613971581288
Validation loss: 2.4825440011733173

Epoch: 6| Step: 6
Training loss: 1.967784463174756
Validation loss: 2.4720701366591595

Epoch: 6| Step: 7
Training loss: 0.9460780929164481
Validation loss: 2.415362347340138

Epoch: 6| Step: 8
Training loss: 1.8120527702251632
Validation loss: 2.4590065501675213

Epoch: 6| Step: 9
Training loss: 1.4255397644384098
Validation loss: 2.4451839084671154

Epoch: 6| Step: 10
Training loss: 1.7371891319952084
Validation loss: 2.4111038929483875

Epoch: 6| Step: 11
Training loss: 1.525862265534261
Validation loss: 2.4569049246278056

Epoch: 6| Step: 12
Training loss: 2.252819519921016
Validation loss: 2.451491784708937

Epoch: 6| Step: 13
Training loss: 1.3100343887532826
Validation loss: 2.492271283832435

Epoch: 481| Step: 0
Training loss: 1.7664408191535943
Validation loss: 2.4399461454170255

Epoch: 6| Step: 1
Training loss: 1.8589993265652476
Validation loss: 2.4851055808524256

Epoch: 6| Step: 2
Training loss: 1.4479296932960921
Validation loss: 2.5030534432389295

Epoch: 6| Step: 3
Training loss: 1.585676199898735
Validation loss: 2.434041002977529

Epoch: 6| Step: 4
Training loss: 1.4807769535103399
Validation loss: 2.472694610643912

Epoch: 6| Step: 5
Training loss: 2.060236064014348
Validation loss: 2.419136975026041

Epoch: 6| Step: 6
Training loss: 1.459585288211008
Validation loss: 2.4264878235127103

Epoch: 6| Step: 7
Training loss: 0.9470293831944535
Validation loss: 2.457300910698799

Epoch: 6| Step: 8
Training loss: 1.4346709401133209
Validation loss: 2.4391355598877356

Epoch: 6| Step: 9
Training loss: 1.6720307892560882
Validation loss: 2.4227850700286275

Epoch: 6| Step: 10
Training loss: 1.7349139226838646
Validation loss: 2.454572917180651

Epoch: 6| Step: 11
Training loss: 1.7571510257154481
Validation loss: 2.4645010200571127

Epoch: 6| Step: 12
Training loss: 1.6299693345771837
Validation loss: 2.44157161318335

Epoch: 6| Step: 13
Training loss: 1.8963111303304467
Validation loss: 2.4205249337966515

Epoch: 482| Step: 0
Training loss: 1.3982130328699829
Validation loss: 2.4293896444036056

Epoch: 6| Step: 1
Training loss: 1.5868215117242395
Validation loss: 2.4322245957207174

Epoch: 6| Step: 2
Training loss: 1.2446202382219496
Validation loss: 2.3692981871923813

Epoch: 6| Step: 3
Training loss: 1.4759789984121259
Validation loss: 2.445801960976845

Epoch: 6| Step: 4
Training loss: 1.8886694765125023
Validation loss: 2.4453278588620524

Epoch: 6| Step: 5
Training loss: 1.4063785070406607
Validation loss: 2.4220724934990163

Epoch: 6| Step: 6
Training loss: 1.066721607571534
Validation loss: 2.428925924705957

Epoch: 6| Step: 7
Training loss: 1.7803423392667945
Validation loss: 2.462830225617905

Epoch: 6| Step: 8
Training loss: 1.605432366100423
Validation loss: 2.4803258855862547

Epoch: 6| Step: 9
Training loss: 2.3437109371744738
Validation loss: 2.3915461299718546

Epoch: 6| Step: 10
Training loss: 1.3864640982622896
Validation loss: 2.457217468146662

Epoch: 6| Step: 11
Training loss: 2.0897729023840887
Validation loss: 2.422921544807416

Epoch: 6| Step: 12
Training loss: 1.6534880154812395
Validation loss: 2.4185545198521816

Epoch: 6| Step: 13
Training loss: 1.6967815591224615
Validation loss: 2.45093625955341

Epoch: 483| Step: 0
Training loss: 1.759109425531295
Validation loss: 2.4861324814512162

Epoch: 6| Step: 1
Training loss: 1.6299895199631866
Validation loss: 2.446662121255229

Epoch: 6| Step: 2
Training loss: 1.5498345317502975
Validation loss: 2.4242082072583515

Epoch: 6| Step: 3
Training loss: 1.4410521529777918
Validation loss: 2.4670362462837323

Epoch: 6| Step: 4
Training loss: 1.5446988606715266
Validation loss: 2.4481702440643995

Epoch: 6| Step: 5
Training loss: 1.5630352629322077
Validation loss: 2.4411436886283764

Epoch: 6| Step: 6
Training loss: 1.3330533309822221
Validation loss: 2.482164006492537

Epoch: 6| Step: 7
Training loss: 1.5841916250917962
Validation loss: 2.4200547898142193

Epoch: 6| Step: 8
Training loss: 2.0054215619220135
Validation loss: 2.400595036570101

Epoch: 6| Step: 9
Training loss: 1.6481433624066335
Validation loss: 2.4014635193053486

Epoch: 6| Step: 10
Training loss: 1.2128579938494979
Validation loss: 2.4332092694615834

Epoch: 6| Step: 11
Training loss: 1.0676829203240752
Validation loss: 2.4199669299005575

Epoch: 6| Step: 12
Training loss: 1.7345721158573555
Validation loss: 2.4862061393381145

Epoch: 6| Step: 13
Training loss: 2.8209249829984118
Validation loss: 2.427647154707632

Epoch: 484| Step: 0
Training loss: 1.3812473728620998
Validation loss: 2.4266126580241747

Epoch: 6| Step: 1
Training loss: 1.3019306958060897
Validation loss: 2.42849047354759

Epoch: 6| Step: 2
Training loss: 1.356682577453841
Validation loss: 2.473479221411812

Epoch: 6| Step: 3
Training loss: 1.6991755337536014
Validation loss: 2.5100777513467825

Epoch: 6| Step: 4
Training loss: 2.1192857543190047
Validation loss: 2.492890090136666

Epoch: 6| Step: 5
Training loss: 2.2887973045906587
Validation loss: 2.4460821779369035

Epoch: 6| Step: 6
Training loss: 1.1870124719602453
Validation loss: 2.4260329634977142

Epoch: 6| Step: 7
Training loss: 1.6958676321449253
Validation loss: 2.429193889785011

Epoch: 6| Step: 8
Training loss: 1.7940146194551274
Validation loss: 2.4381638730615904

Epoch: 6| Step: 9
Training loss: 1.7518181211919028
Validation loss: 2.4519010674953776

Epoch: 6| Step: 10
Training loss: 1.591424704263513
Validation loss: 2.4775097922728913

Epoch: 6| Step: 11
Training loss: 1.5486256874816389
Validation loss: 2.410181605926201

Epoch: 6| Step: 12
Training loss: 1.189552841641964
Validation loss: 2.414023688193146

Epoch: 6| Step: 13
Training loss: 1.29456772139931
Validation loss: 2.4548004889085555

Epoch: 485| Step: 0
Training loss: 2.1971356298351528
Validation loss: 2.3563299121624555

Epoch: 6| Step: 1
Training loss: 1.4556337255901848
Validation loss: 2.4979916914705784

Epoch: 6| Step: 2
Training loss: 1.1748044845568195
Validation loss: 2.453434632193701

Epoch: 6| Step: 3
Training loss: 1.4652344042890644
Validation loss: 2.442535161961304

Epoch: 6| Step: 4
Training loss: 1.3271933485548526
Validation loss: 2.459045234774183

Epoch: 6| Step: 5
Training loss: 1.5357316275976687
Validation loss: 2.413229171169804

Epoch: 6| Step: 6
Training loss: 1.300480071704536
Validation loss: 2.469739040580244

Epoch: 6| Step: 7
Training loss: 1.4745412242374603
Validation loss: 2.4343914991376727

Epoch: 6| Step: 8
Training loss: 1.5552369493465203
Validation loss: 2.4135859446135877

Epoch: 6| Step: 9
Training loss: 1.9564019141154108
Validation loss: 2.477536250040125

Epoch: 6| Step: 10
Training loss: 1.7467109562206617
Validation loss: 2.4175485540766464

Epoch: 6| Step: 11
Training loss: 1.5604012699496557
Validation loss: 2.4371702267203714

Epoch: 6| Step: 12
Training loss: 1.15091691988159
Validation loss: 2.4658475683511742

Epoch: 6| Step: 13
Training loss: 2.1213651873324695
Validation loss: 2.4653427778293926

Epoch: 486| Step: 0
Training loss: 1.0382919322455328
Validation loss: 2.442099447959773

Epoch: 6| Step: 1
Training loss: 1.7050692458648036
Validation loss: 2.44604249911544

Epoch: 6| Step: 2
Training loss: 1.1243962681250048
Validation loss: 2.4572790195617262

Epoch: 6| Step: 3
Training loss: 1.7565345017855853
Validation loss: 2.4371167500320894

Epoch: 6| Step: 4
Training loss: 1.490460419916001
Validation loss: 2.4914938674136153

Epoch: 6| Step: 5
Training loss: 1.5045812107783583
Validation loss: 2.4435921749725447

Epoch: 6| Step: 6
Training loss: 2.7094075835665516
Validation loss: 2.4165472160948474

Epoch: 6| Step: 7
Training loss: 1.581218143187465
Validation loss: 2.5029416436111975

Epoch: 6| Step: 8
Training loss: 1.4282324218416136
Validation loss: 2.461724064230757

Epoch: 6| Step: 9
Training loss: 1.8027165867681094
Validation loss: 2.4195209199375873

Epoch: 6| Step: 10
Training loss: 1.646034115805103
Validation loss: 2.5250673076553167

Epoch: 6| Step: 11
Training loss: 1.4392619737183705
Validation loss: 2.4574925851844087

Epoch: 6| Step: 12
Training loss: 1.2842411389170505
Validation loss: 2.4908467647817347

Epoch: 6| Step: 13
Training loss: 1.4204631125451876
Validation loss: 2.4347993020969168

Epoch: 487| Step: 0
Training loss: 1.3539277917520658
Validation loss: 2.3984565206349826

Epoch: 6| Step: 1
Training loss: 2.032612270431018
Validation loss: 2.4610672267584994

Epoch: 6| Step: 2
Training loss: 1.7779303284930665
Validation loss: 2.446015451245381

Epoch: 6| Step: 3
Training loss: 1.852711703189708
Validation loss: 2.460818527010063

Epoch: 6| Step: 4
Training loss: 1.577707669815306
Validation loss: 2.4269168871857274

Epoch: 6| Step: 5
Training loss: 1.3250742711538066
Validation loss: 2.4213734287673883

Epoch: 6| Step: 6
Training loss: 1.5520649168556169
Validation loss: 2.429377476156215

Epoch: 6| Step: 7
Training loss: 1.341008028030545
Validation loss: 2.4440686644227583

Epoch: 6| Step: 8
Training loss: 1.3199293043249827
Validation loss: 2.451392492140043

Epoch: 6| Step: 9
Training loss: 1.3716134936539195
Validation loss: 2.4659867820401136

Epoch: 6| Step: 10
Training loss: 1.0049242135315561
Validation loss: 2.41821460102538

Epoch: 6| Step: 11
Training loss: 1.634955501125832
Validation loss: 2.462744407545086

Epoch: 6| Step: 12
Training loss: 1.4633640801509546
Validation loss: 2.530099894873033

Epoch: 6| Step: 13
Training loss: 2.430421675370569
Validation loss: 2.446281205846834

Epoch: 488| Step: 0
Training loss: 1.3219482852470035
Validation loss: 2.4479102524512113

Epoch: 6| Step: 1
Training loss: 1.6306026416560184
Validation loss: 2.440872106387183

Epoch: 6| Step: 2
Training loss: 1.3810929204768048
Validation loss: 2.4334224096180472

Epoch: 6| Step: 3
Training loss: 1.5290854589257732
Validation loss: 2.4740847188189248

Epoch: 6| Step: 4
Training loss: 1.42850374504242
Validation loss: 2.4237870167626396

Epoch: 6| Step: 5
Training loss: 1.6247419005610462
Validation loss: 2.4182483396745647

Epoch: 6| Step: 6
Training loss: 2.1056049706267035
Validation loss: 2.4340615717051604

Epoch: 6| Step: 7
Training loss: 1.8937016194524536
Validation loss: 2.4189594557235314

Epoch: 6| Step: 8
Training loss: 1.1993358443062327
Validation loss: 2.3725984209801174

Epoch: 6| Step: 9
Training loss: 1.9663137469474006
Validation loss: 2.4521499231083683

Epoch: 6| Step: 10
Training loss: 1.6283688470617763
Validation loss: 2.4274260312311093

Epoch: 6| Step: 11
Training loss: 1.4393545709668396
Validation loss: 2.4593010042985

Epoch: 6| Step: 12
Training loss: 1.6339336725731581
Validation loss: 2.475637089949457

Epoch: 6| Step: 13
Training loss: 1.7284463814697066
Validation loss: 2.3824973040638677

Epoch: 489| Step: 0
Training loss: 1.537535863938773
Validation loss: 2.4191211467938274

Epoch: 6| Step: 1
Training loss: 2.1292451081380426
Validation loss: 2.4584590653069083

Epoch: 6| Step: 2
Training loss: 1.6337057344354566
Validation loss: 2.4558651973376544

Epoch: 6| Step: 3
Training loss: 1.4750802810287094
Validation loss: 2.481832393861533

Epoch: 6| Step: 4
Training loss: 1.9420303784478268
Validation loss: 2.4872328437461175

Epoch: 6| Step: 5
Training loss: 1.2843360950675582
Validation loss: 2.4529653319181697

Epoch: 6| Step: 6
Training loss: 1.720681232568592
Validation loss: 2.4783509766063294

Epoch: 6| Step: 7
Training loss: 1.3421331925335296
Validation loss: 2.4934982426029095

Epoch: 6| Step: 8
Training loss: 1.238558524583584
Validation loss: 2.468431241656668

Epoch: 6| Step: 9
Training loss: 1.4707903386532966
Validation loss: 2.4203721214663148

Epoch: 6| Step: 10
Training loss: 1.712354099713367
Validation loss: 2.4289425999034

Epoch: 6| Step: 11
Training loss: 1.4439721568215584
Validation loss: 2.48029390971558

Epoch: 6| Step: 12
Training loss: 1.8488295461011268
Validation loss: 2.4774483347425873

Epoch: 6| Step: 13
Training loss: 1.4307484676733482
Validation loss: 2.423735676496413

Epoch: 490| Step: 0
Training loss: 1.783132060745973
Validation loss: 2.358745253762412

Epoch: 6| Step: 1
Training loss: 1.3541942398002866
Validation loss: 2.3996649276213864

Epoch: 6| Step: 2
Training loss: 1.4054770146583366
Validation loss: 2.385605455633509

Epoch: 6| Step: 3
Training loss: 1.7207755204557993
Validation loss: 2.3795011242593085

Epoch: 6| Step: 4
Training loss: 1.5836057010419862
Validation loss: 2.497917542616548

Epoch: 6| Step: 5
Training loss: 1.2083755463866963
Validation loss: 2.4761902333418577

Epoch: 6| Step: 6
Training loss: 2.095775706091112
Validation loss: 2.4724984020694705

Epoch: 6| Step: 7
Training loss: 1.522562724608156
Validation loss: 2.455956913441551

Epoch: 6| Step: 8
Training loss: 1.7353567832821017
Validation loss: 2.4597535373577215

Epoch: 6| Step: 9
Training loss: 2.286242939065799
Validation loss: 2.455487285052818

Epoch: 6| Step: 10
Training loss: 1.3082667155627623
Validation loss: 2.4738594288423483

Epoch: 6| Step: 11
Training loss: 1.5364857902875293
Validation loss: 2.4639759636123966

Epoch: 6| Step: 12
Training loss: 1.6636905164854294
Validation loss: 2.44891181010724

Epoch: 6| Step: 13
Training loss: 0.9299432739267259
Validation loss: 2.505257135536328

Epoch: 491| Step: 0
Training loss: 1.5213318186364309
Validation loss: 2.4462278057168505

Epoch: 6| Step: 1
Training loss: 1.2626898367896546
Validation loss: 2.521841614522006

Epoch: 6| Step: 2
Training loss: 1.7765579666442202
Validation loss: 2.414579180145224

Epoch: 6| Step: 3
Training loss: 1.9030224100658644
Validation loss: 2.4343975022868904

Epoch: 6| Step: 4
Training loss: 1.193600294702202
Validation loss: 2.463382975907493

Epoch: 6| Step: 5
Training loss: 1.6184166553994195
Validation loss: 2.4349027594853396

Epoch: 6| Step: 6
Training loss: 1.4207687266288804
Validation loss: 2.4458257996178157

Epoch: 6| Step: 7
Training loss: 2.403209499267466
Validation loss: 2.4406320712629803

Epoch: 6| Step: 8
Training loss: 1.4364195370523827
Validation loss: 2.436559223695867

Epoch: 6| Step: 9
Training loss: 1.3959243611882464
Validation loss: 2.4600383511213426

Epoch: 6| Step: 10
Training loss: 1.5934128498176452
Validation loss: 2.4423667313249044

Epoch: 6| Step: 11
Training loss: 1.1524532460061196
Validation loss: 2.454720218235934

Epoch: 6| Step: 12
Training loss: 1.374805046479278
Validation loss: 2.443588307884183

Epoch: 6| Step: 13
Training loss: 1.7539349322108397
Validation loss: 2.441936982383143

Epoch: 492| Step: 0
Training loss: 1.697753133875112
Validation loss: 2.4000962848217626

Epoch: 6| Step: 1
Training loss: 1.5913121146449618
Validation loss: 2.4192364692444013

Epoch: 6| Step: 2
Training loss: 1.691397228613355
Validation loss: 2.4714770039802794

Epoch: 6| Step: 3
Training loss: 1.3330007923206857
Validation loss: 2.465171741048291

Epoch: 6| Step: 4
Training loss: 1.5835247007803723
Validation loss: 2.4831145345917163

Epoch: 6| Step: 5
Training loss: 1.3610912757301898
Validation loss: 2.4610144235126183

Epoch: 6| Step: 6
Training loss: 1.3112654556512675
Validation loss: 2.4807115868247984

Epoch: 6| Step: 7
Training loss: 1.448331741373104
Validation loss: 2.4898500578086376

Epoch: 6| Step: 8
Training loss: 2.2522870202516905
Validation loss: 2.471682471358938

Epoch: 6| Step: 9
Training loss: 1.0622121757655598
Validation loss: 2.4241184086806045

Epoch: 6| Step: 10
Training loss: 2.0009579748404605
Validation loss: 2.488731955577406

Epoch: 6| Step: 11
Training loss: 1.7783168266886484
Validation loss: 2.469113737584648

Epoch: 6| Step: 12
Training loss: 1.257835056268538
Validation loss: 2.393992799834078

Epoch: 6| Step: 13
Training loss: 1.7987230831462466
Validation loss: 2.4309462121337515

Epoch: 493| Step: 0
Training loss: 1.333365926741544
Validation loss: 2.4571106496155206

Epoch: 6| Step: 1
Training loss: 0.9913277092162494
Validation loss: 2.456243927162276

Epoch: 6| Step: 2
Training loss: 1.3149881846836282
Validation loss: 2.462915194451488

Epoch: 6| Step: 3
Training loss: 1.720808010823266
Validation loss: 2.43614126197785

Epoch: 6| Step: 4
Training loss: 1.3389962410307834
Validation loss: 2.444746068026621

Epoch: 6| Step: 5
Training loss: 1.9461039576191925
Validation loss: 2.400597348613248

Epoch: 6| Step: 6
Training loss: 1.537976031539532
Validation loss: 2.3940803799128045

Epoch: 6| Step: 7
Training loss: 1.7884297813770211
Validation loss: 2.4927267964072644

Epoch: 6| Step: 8
Training loss: 1.981620859761534
Validation loss: 2.4671495638692704

Epoch: 6| Step: 9
Training loss: 1.3880689038892395
Validation loss: 2.4363518833070543

Epoch: 6| Step: 10
Training loss: 0.9416766906024718
Validation loss: 2.4279186830985107

Epoch: 6| Step: 11
Training loss: 2.0974825710804677
Validation loss: 2.400759032330624

Epoch: 6| Step: 12
Training loss: 1.8627628908941312
Validation loss: 2.449668449819426

Epoch: 6| Step: 13
Training loss: 1.1449816341676302
Validation loss: 2.525017223585727

Epoch: 494| Step: 0
Training loss: 2.064137357961368
Validation loss: 2.4222858558123734

Epoch: 6| Step: 1
Training loss: 1.4038360221505226
Validation loss: 2.451506009443766

Epoch: 6| Step: 2
Training loss: 1.5592073461274396
Validation loss: 2.4083130537966815

Epoch: 6| Step: 3
Training loss: 1.4803604448706642
Validation loss: 2.401073915158541

Epoch: 6| Step: 4
Training loss: 1.8372956142807753
Validation loss: 2.4987861762933563

Epoch: 6| Step: 5
Training loss: 1.1084077943919481
Validation loss: 2.42005535231926

Epoch: 6| Step: 6
Training loss: 2.1048228559461553
Validation loss: 2.44808311097267

Epoch: 6| Step: 7
Training loss: 1.8544910304350655
Validation loss: 2.390488680403853

Epoch: 6| Step: 8
Training loss: 1.1879731289814113
Validation loss: 2.462887221231036

Epoch: 6| Step: 9
Training loss: 1.5912825988163304
Validation loss: 2.4349069951852114

Epoch: 6| Step: 10
Training loss: 1.5366055003230488
Validation loss: 2.4581397974394945

Epoch: 6| Step: 11
Training loss: 1.4131727422640692
Validation loss: 2.419207927386227

Epoch: 6| Step: 12
Training loss: 1.20854580863651
Validation loss: 2.437019967686132

Epoch: 6| Step: 13
Training loss: 1.228081412670284
Validation loss: 2.4298874582474324

Epoch: 495| Step: 0
Training loss: 1.7170837648695574
Validation loss: 2.4577019869542136

Epoch: 6| Step: 1
Training loss: 1.4819500037703455
Validation loss: 2.434330183605479

Epoch: 6| Step: 2
Training loss: 1.1810290054196197
Validation loss: 2.451758159169378

Epoch: 6| Step: 3
Training loss: 1.7305731817211547
Validation loss: 2.4419333625356505

Epoch: 6| Step: 4
Training loss: 1.5075909545687807
Validation loss: 2.3790462171250364

Epoch: 6| Step: 5
Training loss: 1.827101657417418
Validation loss: 2.4554345351275653

Epoch: 6| Step: 6
Training loss: 1.3455106600364293
Validation loss: 2.486829699574572

Epoch: 6| Step: 7
Training loss: 1.744113353759534
Validation loss: 2.44419694123261

Epoch: 6| Step: 8
Training loss: 1.201418372192428
Validation loss: 2.4732994009477056

Epoch: 6| Step: 9
Training loss: 1.9811308767806932
Validation loss: 2.4918585865076452

Epoch: 6| Step: 10
Training loss: 1.5345279096872533
Validation loss: 2.474225921580574

Epoch: 6| Step: 11
Training loss: 1.5525833536276072
Validation loss: 2.4189240217320322

Epoch: 6| Step: 12
Training loss: 1.594377730668921
Validation loss: 2.402320245560618

Epoch: 6| Step: 13
Training loss: 1.31443593891126
Validation loss: 2.383567333573498

Epoch: 496| Step: 0
Training loss: 1.6971522601758426
Validation loss: 2.4214259784307557

Epoch: 6| Step: 1
Training loss: 1.1964128204480144
Validation loss: 2.41303721257243

Epoch: 6| Step: 2
Training loss: 1.5793221342645953
Validation loss: 2.451526816989361

Epoch: 6| Step: 3
Training loss: 1.5747430652369423
Validation loss: 2.4125503969186024

Epoch: 6| Step: 4
Training loss: 1.912388034111141
Validation loss: 2.432342548439377

Epoch: 6| Step: 5
Training loss: 2.2953925506364556
Validation loss: 2.4695569416531913

Epoch: 6| Step: 6
Training loss: 1.363163590477453
Validation loss: 2.4567466991164144

Epoch: 6| Step: 7
Training loss: 1.6416144883953485
Validation loss: 2.460874438906177

Epoch: 6| Step: 8
Training loss: 1.697811692938217
Validation loss: 2.395919514337043

Epoch: 6| Step: 9
Training loss: 1.5695153485751077
Validation loss: 2.3932671206106173

Epoch: 6| Step: 10
Training loss: 1.261773359221173
Validation loss: 2.3889230407896265

Epoch: 6| Step: 11
Training loss: 1.540855873249765
Validation loss: 2.446475868820508

Epoch: 6| Step: 12
Training loss: 1.1702430551702212
Validation loss: 2.455036109421671

Epoch: 6| Step: 13
Training loss: 0.7441857592093876
Validation loss: 2.4365692338883824

Epoch: 497| Step: 0
Training loss: 1.4385222241935998
Validation loss: 2.4228159632249433

Epoch: 6| Step: 1
Training loss: 1.6285112299943318
Validation loss: 2.460133303598686

Epoch: 6| Step: 2
Training loss: 1.4986716587695086
Validation loss: 2.4624611529537455

Epoch: 6| Step: 3
Training loss: 1.0380749132175675
Validation loss: 2.4004391740970874

Epoch: 6| Step: 4
Training loss: 1.5061677649118541
Validation loss: 2.403541042618618

Epoch: 6| Step: 5
Training loss: 1.8778008205020764
Validation loss: 2.488342419371816

Epoch: 6| Step: 6
Training loss: 1.3870663059587887
Validation loss: 2.452248437530159

Epoch: 6| Step: 7
Training loss: 1.3636800625330467
Validation loss: 2.420817196770536

Epoch: 6| Step: 8
Training loss: 1.2651947137752961
Validation loss: 2.48908844684081

Epoch: 6| Step: 9
Training loss: 1.525028356694968
Validation loss: 2.4575073630210826

Epoch: 6| Step: 10
Training loss: 2.2810670962234196
Validation loss: 2.4309797181934645

Epoch: 6| Step: 11
Training loss: 1.9100648823048545
Validation loss: 2.4499720343508242

Epoch: 6| Step: 12
Training loss: 1.4321875054602693
Validation loss: 2.4675596827414035

Epoch: 6| Step: 13
Training loss: 1.6230935871549657
Validation loss: 2.4655350104098774

Epoch: 498| Step: 0
Training loss: 1.8858249987885696
Validation loss: 2.432907807117066

Epoch: 6| Step: 1
Training loss: 1.6916030874973282
Validation loss: 2.4736789965781614

Epoch: 6| Step: 2
Training loss: 1.9200204724968766
Validation loss: 2.410132469136642

Epoch: 6| Step: 3
Training loss: 1.6581857273730296
Validation loss: 2.395684300121464

Epoch: 6| Step: 4
Training loss: 1.6487331034942003
Validation loss: 2.448653386008337

Epoch: 6| Step: 5
Training loss: 1.1016884589721017
Validation loss: 2.415859480818302

Epoch: 6| Step: 6
Training loss: 1.1858352737696827
Validation loss: 2.3627798363634254

Epoch: 6| Step: 7
Training loss: 1.4102594226913912
Validation loss: 2.4312963346174317

Epoch: 6| Step: 8
Training loss: 1.2226938357685075
Validation loss: 2.4785925723620603

Epoch: 6| Step: 9
Training loss: 1.2557344507997275
Validation loss: 2.428034696342121

Epoch: 6| Step: 10
Training loss: 2.1326283805099964
Validation loss: 2.4388206717786396

Epoch: 6| Step: 11
Training loss: 1.2171608271877703
Validation loss: 2.424842591965528

Epoch: 6| Step: 12
Training loss: 1.1349513415690966
Validation loss: 2.4731415536390817

Epoch: 6| Step: 13
Training loss: 1.8876872291924707
Validation loss: 2.4377502500156067

Epoch: 499| Step: 0
Training loss: 1.651202156938948
Validation loss: 2.415197210690738

Epoch: 6| Step: 1
Training loss: 1.4475400512635936
Validation loss: 2.464891409235657

Epoch: 6| Step: 2
Training loss: 2.530032960277461
Validation loss: 2.3881718644640837

Epoch: 6| Step: 3
Training loss: 1.157453786697795
Validation loss: 2.4447633546753305

Epoch: 6| Step: 4
Training loss: 1.6480342136646253
Validation loss: 2.4664099108884536

Epoch: 6| Step: 5
Training loss: 1.3985214634415395
Validation loss: 2.485534778032992

Epoch: 6| Step: 6
Training loss: 1.4955628252317212
Validation loss: 2.46216473870441

Epoch: 6| Step: 7
Training loss: 1.9575062554114548
Validation loss: 2.450893915654704

Epoch: 6| Step: 8
Training loss: 1.405033857270238
Validation loss: 2.4267993785366673

Epoch: 6| Step: 9
Training loss: 1.0967774589619352
Validation loss: 2.416509213337716

Epoch: 6| Step: 10
Training loss: 1.619757853295102
Validation loss: 2.473306476268203

Epoch: 6| Step: 11
Training loss: 1.3380223118927437
Validation loss: 2.4222455913841623

Epoch: 6| Step: 12
Training loss: 1.3308528934698256
Validation loss: 2.422290704136105

Epoch: 6| Step: 13
Training loss: 1.2101746648245615
Validation loss: 2.440054607887276

Epoch: 500| Step: 0
Training loss: 1.8530580942771306
Validation loss: 2.4619659613475164

Epoch: 6| Step: 1
Training loss: 1.5422772753401905
Validation loss: 2.4442287395653333

Epoch: 6| Step: 2
Training loss: 1.4567187590344863
Validation loss: 2.3663363095158956

Epoch: 6| Step: 3
Training loss: 1.5193925416687786
Validation loss: 2.4281781757939878

Epoch: 6| Step: 4
Training loss: 1.4043091838440478
Validation loss: 2.4710211763181755

Epoch: 6| Step: 5
Training loss: 2.3701993710321423
Validation loss: 2.4817492048710057

Epoch: 6| Step: 6
Training loss: 1.228470842427644
Validation loss: 2.493513698435031

Epoch: 6| Step: 7
Training loss: 1.2645813677467181
Validation loss: 2.4442998540214242

Epoch: 6| Step: 8
Training loss: 1.7222563610316595
Validation loss: 2.4494303578711283

Epoch: 6| Step: 9
Training loss: 1.6262475873268052
Validation loss: 2.4053465168891353

Epoch: 6| Step: 10
Training loss: 1.4228654702370223
Validation loss: 2.437271016958027

Epoch: 6| Step: 11
Training loss: 1.2710998703821563
Validation loss: 2.4269689766870313

Epoch: 6| Step: 12
Training loss: 1.3091022471396903
Validation loss: 2.5188551866735853

Epoch: 6| Step: 13
Training loss: 1.7892775760288255
Validation loss: 2.443621326914571

Epoch: 501| Step: 0
Training loss: 0.974952041228969
Validation loss: 2.443066016373116

Epoch: 6| Step: 1
Training loss: 1.3378583695358996
Validation loss: 2.503807157161488

Epoch: 6| Step: 2
Training loss: 2.4119425233284155
Validation loss: 2.480286824352999

Epoch: 6| Step: 3
Training loss: 1.6996712619225363
Validation loss: 2.453205736695925

Epoch: 6| Step: 4
Training loss: 1.4419631502466739
Validation loss: 2.4219310615076712

Epoch: 6| Step: 5
Training loss: 1.4276214847212463
Validation loss: 2.390359602015358

Epoch: 6| Step: 6
Training loss: 1.8048117458625816
Validation loss: 2.449771913430075

Epoch: 6| Step: 7
Training loss: 1.8051957244638146
Validation loss: 2.4866761282217635

Epoch: 6| Step: 8
Training loss: 1.2278558023515662
Validation loss: 2.4845814447888177

Epoch: 6| Step: 9
Training loss: 1.2688426336287253
Validation loss: 2.398068325507232

Epoch: 6| Step: 10
Training loss: 1.3441089771627983
Validation loss: 2.4865323311763765

Epoch: 6| Step: 11
Training loss: 1.529309970609639
Validation loss: 2.4484560262113164

Epoch: 6| Step: 12
Training loss: 1.800665067619528
Validation loss: 2.4098532516767137

Epoch: 6| Step: 13
Training loss: 1.7670880897684027
Validation loss: 2.45993834990465

Epoch: 502| Step: 0
Training loss: 1.6770311509379994
Validation loss: 2.4221815838112186

Epoch: 6| Step: 1
Training loss: 1.811571014684356
Validation loss: 2.437166467254333

Epoch: 6| Step: 2
Training loss: 1.7848442355882208
Validation loss: 2.4001966057083832

Epoch: 6| Step: 3
Training loss: 2.182155510805736
Validation loss: 2.487712050945273

Epoch: 6| Step: 4
Training loss: 1.5164676172337648
Validation loss: 2.463039337006748

Epoch: 6| Step: 5
Training loss: 1.0471126799007233
Validation loss: 2.4373359214769152

Epoch: 6| Step: 6
Training loss: 1.0628114131752566
Validation loss: 2.478416017628458

Epoch: 6| Step: 7
Training loss: 1.6200106392028328
Validation loss: 2.43962199375412

Epoch: 6| Step: 8
Training loss: 1.5918702652751842
Validation loss: 2.5079758388087994

Epoch: 6| Step: 9
Training loss: 1.6558471045699747
Validation loss: 2.461077140392115

Epoch: 6| Step: 10
Training loss: 1.752949885089942
Validation loss: 2.451320711232207

Epoch: 6| Step: 11
Training loss: 0.9408681447527035
Validation loss: 2.393041037704567

Epoch: 6| Step: 12
Training loss: 1.440864192278443
Validation loss: 2.4316248665608833

Epoch: 6| Step: 13
Training loss: 1.551463709641313
Validation loss: 2.40184182840446

Epoch: 503| Step: 0
Training loss: 2.1428788842506097
Validation loss: 2.395471485806724

Epoch: 6| Step: 1
Training loss: 1.9825194687145944
Validation loss: 2.4533263208064797

Epoch: 6| Step: 2
Training loss: 1.3498019179088212
Validation loss: 2.4215324051040716

Epoch: 6| Step: 3
Training loss: 1.2988544662213768
Validation loss: 2.4555020864423303

Epoch: 6| Step: 4
Training loss: 1.3308943654021272
Validation loss: 2.470302689058501

Epoch: 6| Step: 5
Training loss: 1.0738332715679575
Validation loss: 2.468244954489596

Epoch: 6| Step: 6
Training loss: 1.8850255599173578
Validation loss: 2.4643399699631576

Epoch: 6| Step: 7
Training loss: 1.4191323962341857
Validation loss: 2.406247029637609

Epoch: 6| Step: 8
Training loss: 1.257098356533759
Validation loss: 2.4360627648208215

Epoch: 6| Step: 9
Training loss: 1.3772150750945282
Validation loss: 2.4816399629848527

Epoch: 6| Step: 10
Training loss: 1.0665924692176698
Validation loss: 2.4353309448328746

Epoch: 6| Step: 11
Training loss: 1.5716749515227437
Validation loss: 2.3932155498186125

Epoch: 6| Step: 12
Training loss: 1.648149727385229
Validation loss: 2.4569814161681767

Epoch: 6| Step: 13
Training loss: 1.7988411802466326
Validation loss: 2.402447290371055

Epoch: 504| Step: 0
Training loss: 1.3542651458535522
Validation loss: 2.417282077760506

Epoch: 6| Step: 1
Training loss: 1.5561703458570038
Validation loss: 2.442352469630882

Epoch: 6| Step: 2
Training loss: 2.0169096408891796
Validation loss: 2.424026472548519

Epoch: 6| Step: 3
Training loss: 2.371789669869178
Validation loss: 2.4444239603261373

Epoch: 6| Step: 4
Training loss: 0.9323653754962294
Validation loss: 2.4719739426576974

Epoch: 6| Step: 5
Training loss: 1.5682350194900574
Validation loss: 2.4041423977730094

Epoch: 6| Step: 6
Training loss: 0.8564296185959643
Validation loss: 2.4153792382362256

Epoch: 6| Step: 7
Training loss: 1.470060940342169
Validation loss: 2.413180721095702

Epoch: 6| Step: 8
Training loss: 1.715082660273386
Validation loss: 2.405627639632609

Epoch: 6| Step: 9
Training loss: 1.6072436543296522
Validation loss: 2.390015386786839

Epoch: 6| Step: 10
Training loss: 1.3267476288533664
Validation loss: 2.487326159776838

Epoch: 6| Step: 11
Training loss: 1.5399213998726184
Validation loss: 2.4052235992934454

Epoch: 6| Step: 12
Training loss: 1.0165517833296112
Validation loss: 2.476942062340935

Epoch: 6| Step: 13
Training loss: 1.2378038033457028
Validation loss: 2.449911843874209

Epoch: 505| Step: 0
Training loss: 1.576501672363362
Validation loss: 2.382190681712352

Epoch: 6| Step: 1
Training loss: 1.5848122348940883
Validation loss: 2.4385704758931523

Epoch: 6| Step: 2
Training loss: 1.1255491294051863
Validation loss: 2.4867291185260427

Epoch: 6| Step: 3
Training loss: 1.741416315705964
Validation loss: 2.4917523270356643

Epoch: 6| Step: 4
Training loss: 1.5962017125508507
Validation loss: 2.442870469859302

Epoch: 6| Step: 5
Training loss: 1.3262452230268589
Validation loss: 2.421112477714361

Epoch: 6| Step: 6
Training loss: 1.1667758118574014
Validation loss: 2.4217339820308923

Epoch: 6| Step: 7
Training loss: 1.6654626391436773
Validation loss: 2.445740562016023

Epoch: 6| Step: 8
Training loss: 2.5704308572436094
Validation loss: 2.373321610476868

Epoch: 6| Step: 9
Training loss: 1.2449211415054369
Validation loss: 2.4057698878199423

Epoch: 6| Step: 10
Training loss: 1.2905891395001934
Validation loss: 2.4622623000942387

Epoch: 6| Step: 11
Training loss: 1.5553129078820636
Validation loss: 2.449128095241759

Epoch: 6| Step: 12
Training loss: 1.5998451515606653
Validation loss: 2.4377766176937667

Epoch: 6| Step: 13
Training loss: 1.189506642307434
Validation loss: 2.4433099810517858

Epoch: 506| Step: 0
Training loss: 1.9105168725721033
Validation loss: 2.4868126821476872

Epoch: 6| Step: 1
Training loss: 2.2978379702703076
Validation loss: 2.4651956856432973

Epoch: 6| Step: 2
Training loss: 1.6969477067127399
Validation loss: 2.412825519742494

Epoch: 6| Step: 3
Training loss: 1.407354683903975
Validation loss: 2.478759207521406

Epoch: 6| Step: 4
Training loss: 1.2095431267633612
Validation loss: 2.410614791746792

Epoch: 6| Step: 5
Training loss: 1.3854075935850645
Validation loss: 2.4233781181117116

Epoch: 6| Step: 6
Training loss: 1.5733893317962977
Validation loss: 2.422638989691646

Epoch: 6| Step: 7
Training loss: 1.4090404798623375
Validation loss: 2.4143465048087402

Epoch: 6| Step: 8
Training loss: 1.4757395070494745
Validation loss: 2.4127393383738633

Epoch: 6| Step: 9
Training loss: 1.1433345540450746
Validation loss: 2.446859147982258

Epoch: 6| Step: 10
Training loss: 1.711626584711374
Validation loss: 2.5194230225805145

Epoch: 6| Step: 11
Training loss: 1.000633337211306
Validation loss: 2.4062286768078884

Epoch: 6| Step: 12
Training loss: 1.6979344216883065
Validation loss: 2.4261413436939456

Epoch: 6| Step: 13
Training loss: 1.8344745407521263
Validation loss: 2.4686446379627514

Epoch: 507| Step: 0
Training loss: 2.101184229505067
Validation loss: 2.410165626341573

Epoch: 6| Step: 1
Training loss: 1.7172800887800197
Validation loss: 2.4534716617562804

Epoch: 6| Step: 2
Training loss: 1.3938774478272695
Validation loss: 2.4665633362321113

Epoch: 6| Step: 3
Training loss: 1.2891725897740265
Validation loss: 2.4542389762219603

Epoch: 6| Step: 4
Training loss: 1.4883299491704305
Validation loss: 2.378907239287247

Epoch: 6| Step: 5
Training loss: 1.3991900928316694
Validation loss: 2.395968297408954

Epoch: 6| Step: 6
Training loss: 1.5901328533978154
Validation loss: 2.469848830644001

Epoch: 6| Step: 7
Training loss: 1.4640420983520488
Validation loss: 2.442267005311791

Epoch: 6| Step: 8
Training loss: 1.5090057711228624
Validation loss: 2.398073323282881

Epoch: 6| Step: 9
Training loss: 1.534017281097992
Validation loss: 2.475080788102704

Epoch: 6| Step: 10
Training loss: 1.3203171950036716
Validation loss: 2.4957825875994124

Epoch: 6| Step: 11
Training loss: 1.5515353965889036
Validation loss: 2.4701990838701837

Epoch: 6| Step: 12
Training loss: 1.326368224674831
Validation loss: 2.4600812295741354

Epoch: 6| Step: 13
Training loss: 1.4315943274616627
Validation loss: 2.365007017152483

Epoch: 508| Step: 0
Training loss: 2.2510909508625314
Validation loss: 2.4281700525498864

Epoch: 6| Step: 1
Training loss: 1.2620839632640806
Validation loss: 2.4521582700988214

Epoch: 6| Step: 2
Training loss: 1.7864109029303075
Validation loss: 2.4837283154891034

Epoch: 6| Step: 3
Training loss: 1.348510825063151
Validation loss: 2.4966963299787928

Epoch: 6| Step: 4
Training loss: 1.3923998447060875
Validation loss: 2.46313765736725

Epoch: 6| Step: 5
Training loss: 1.8274487932078631
Validation loss: 2.4547379150527266

Epoch: 6| Step: 6
Training loss: 1.30445526248985
Validation loss: 2.4931485181253303

Epoch: 6| Step: 7
Training loss: 1.161660603015313
Validation loss: 2.4634576022743966

Epoch: 6| Step: 8
Training loss: 1.14817786363434
Validation loss: 2.4688619056345478

Epoch: 6| Step: 9
Training loss: 1.4117119151943749
Validation loss: 2.418923542690247

Epoch: 6| Step: 10
Training loss: 1.6191337042316656
Validation loss: 2.41601190052675

Epoch: 6| Step: 11
Training loss: 1.4514224014590913
Validation loss: 2.445011998347256

Epoch: 6| Step: 12
Training loss: 1.3805739392379102
Validation loss: 2.4664474056719876

Epoch: 6| Step: 13
Training loss: 1.7093926688611372
Validation loss: 2.4470241138631854

Epoch: 509| Step: 0
Training loss: 1.4262553223787273
Validation loss: 2.393204791079142

Epoch: 6| Step: 1
Training loss: 1.1016953841336483
Validation loss: 2.433137428366986

Epoch: 6| Step: 2
Training loss: 1.6020145429601171
Validation loss: 2.4355883741949618

Epoch: 6| Step: 3
Training loss: 1.620180392052798
Validation loss: 2.4701664958705085

Epoch: 6| Step: 4
Training loss: 1.308186481924683
Validation loss: 2.4518277006577662

Epoch: 6| Step: 5
Training loss: 1.4579652957632092
Validation loss: 2.331974482799134

Epoch: 6| Step: 6
Training loss: 1.5072295490041034
Validation loss: 2.4758093804745647

Epoch: 6| Step: 7
Training loss: 1.6341019061282
Validation loss: 2.4315608312346777

Epoch: 6| Step: 8
Training loss: 1.7456682271279675
Validation loss: 2.507199051602634

Epoch: 6| Step: 9
Training loss: 1.2507614200885773
Validation loss: 2.428787742769329

Epoch: 6| Step: 10
Training loss: 1.4608155877964446
Validation loss: 2.439748659190228

Epoch: 6| Step: 11
Training loss: 2.0221548838925973
Validation loss: 2.4784782507246206

Epoch: 6| Step: 12
Training loss: 1.5955992049669727
Validation loss: 2.3986833339579667

Epoch: 6| Step: 13
Training loss: 1.5885730511009186
Validation loss: 2.454318784755812

Epoch: 510| Step: 0
Training loss: 1.8875462709527926
Validation loss: 2.414028873827338

Epoch: 6| Step: 1
Training loss: 0.8507170373593698
Validation loss: 2.4404214873815846

Epoch: 6| Step: 2
Training loss: 1.3640772728049029
Validation loss: 2.4431108852807055

Epoch: 6| Step: 3
Training loss: 1.696505359833444
Validation loss: 2.432034157500436

Epoch: 6| Step: 4
Training loss: 1.2046435297401519
Validation loss: 2.457439105280534

Epoch: 6| Step: 5
Training loss: 2.055158785883191
Validation loss: 2.437472019082284

Epoch: 6| Step: 6
Training loss: 1.3144097739066973
Validation loss: 2.4390921481999244

Epoch: 6| Step: 7
Training loss: 1.5898981858290455
Validation loss: 2.433913590745379

Epoch: 6| Step: 8
Training loss: 1.29573321349222
Validation loss: 2.4316897193633356

Epoch: 6| Step: 9
Training loss: 1.7947745610368642
Validation loss: 2.473299215409436

Epoch: 6| Step: 10
Training loss: 1.626925135047722
Validation loss: 2.463113974825888

Epoch: 6| Step: 11
Training loss: 1.5856272577217818
Validation loss: 2.4062542935948232

Epoch: 6| Step: 12
Training loss: 1.4884552941469051
Validation loss: 2.4756159066922594

Epoch: 6| Step: 13
Training loss: 1.622090302217285
Validation loss: 2.4160903721603617

Epoch: 511| Step: 0
Training loss: 1.5934614032419567
Validation loss: 2.377755732222159

Epoch: 6| Step: 1
Training loss: 1.6427218162291315
Validation loss: 2.3923790229022726

Epoch: 6| Step: 2
Training loss: 1.1853868857309477
Validation loss: 2.478944654925958

Epoch: 6| Step: 3
Training loss: 0.7600947356156308
Validation loss: 2.446027523098795

Epoch: 6| Step: 4
Training loss: 1.3394883465745908
Validation loss: 2.4521502775214916

Epoch: 6| Step: 5
Training loss: 1.2590318538887113
Validation loss: 2.464168202944337

Epoch: 6| Step: 6
Training loss: 1.2991735472302204
Validation loss: 2.404155491897336

Epoch: 6| Step: 7
Training loss: 1.071255623392059
Validation loss: 2.470108356358414

Epoch: 6| Step: 8
Training loss: 1.8505242249357274
Validation loss: 2.40782108697569

Epoch: 6| Step: 9
Training loss: 1.6056352886317264
Validation loss: 2.432248658080202

Epoch: 6| Step: 10
Training loss: 2.0809409201290716
Validation loss: 2.418862556292721

Epoch: 6| Step: 11
Training loss: 1.7043517707833638
Validation loss: 2.3708802043740214

Epoch: 6| Step: 12
Training loss: 1.5356378552120384
Validation loss: 2.4169591133387924

Epoch: 6| Step: 13
Training loss: 1.8697966537479918
Validation loss: 2.424388560020757

Epoch: 512| Step: 0
Training loss: 1.6119905716878276
Validation loss: 2.424944417900278

Epoch: 6| Step: 1
Training loss: 1.1592553747931542
Validation loss: 2.445393874660789

Epoch: 6| Step: 2
Training loss: 1.1125521229738489
Validation loss: 2.4355155801437194

Epoch: 6| Step: 3
Training loss: 1.5286396119631793
Validation loss: 2.4485687247917545

Epoch: 6| Step: 4
Training loss: 1.4504725541230632
Validation loss: 2.462704648453349

Epoch: 6| Step: 5
Training loss: 1.4683077531910858
Validation loss: 2.482394245520923

Epoch: 6| Step: 6
Training loss: 1.3137028041967926
Validation loss: 2.44605992962023

Epoch: 6| Step: 7
Training loss: 1.8142053539664338
Validation loss: 2.462345248937328

Epoch: 6| Step: 8
Training loss: 1.4203135541821754
Validation loss: 2.4270985818639437

Epoch: 6| Step: 9
Training loss: 1.3457880754606664
Validation loss: 2.4067400297635824

Epoch: 6| Step: 10
Training loss: 2.1742034067208125
Validation loss: 2.4275116816890447

Epoch: 6| Step: 11
Training loss: 1.184013166489723
Validation loss: 2.490568465442984

Epoch: 6| Step: 12
Training loss: 1.6047844460982044
Validation loss: 2.4682705861413483

Epoch: 6| Step: 13
Training loss: 1.7815693351535529
Validation loss: 2.4117810100262904

Epoch: 513| Step: 0
Training loss: 1.339422042810891
Validation loss: 2.477246986288335

Epoch: 6| Step: 1
Training loss: 1.1851221671889864
Validation loss: 2.4280729125351197

Epoch: 6| Step: 2
Training loss: 1.3318133133951058
Validation loss: 2.462538781554829

Epoch: 6| Step: 3
Training loss: 1.3799622898201542
Validation loss: 2.4394195409040833

Epoch: 6| Step: 4
Training loss: 1.5382944117148176
Validation loss: 2.4841015485239826

Epoch: 6| Step: 5
Training loss: 1.0215876510665374
Validation loss: 2.480057492640018

Epoch: 6| Step: 6
Training loss: 0.8951459546661549
Validation loss: 2.463109841754658

Epoch: 6| Step: 7
Training loss: 1.6405437631022113
Validation loss: 2.464932001493037

Epoch: 6| Step: 8
Training loss: 1.2099249759776458
Validation loss: 2.4474443635018943

Epoch: 6| Step: 9
Training loss: 1.8815171467133815
Validation loss: 2.470334789584994

Epoch: 6| Step: 10
Training loss: 1.7644715719248931
Validation loss: 2.488287312193783

Epoch: 6| Step: 11
Training loss: 2.592862080641019
Validation loss: 2.489683400406477

Epoch: 6| Step: 12
Training loss: 1.4226318692459716
Validation loss: 2.453484946098419

Epoch: 6| Step: 13
Training loss: 1.070459954344384
Validation loss: 2.45893008200613

Epoch: 514| Step: 0
Training loss: 1.2177678576894522
Validation loss: 2.4344906568812057

Epoch: 6| Step: 1
Training loss: 0.8072239426949458
Validation loss: 2.4113686227138933

Epoch: 6| Step: 2
Training loss: 1.3552135919952208
Validation loss: 2.400934163612187

Epoch: 6| Step: 3
Training loss: 1.540665928914053
Validation loss: 2.4446580672850597

Epoch: 6| Step: 4
Training loss: 1.5113714247924628
Validation loss: 2.465089469703222

Epoch: 6| Step: 5
Training loss: 1.3142322280985441
Validation loss: 2.4457644379423056

Epoch: 6| Step: 6
Training loss: 1.7461743773549598
Validation loss: 2.447742091656259

Epoch: 6| Step: 7
Training loss: 1.55629382703724
Validation loss: 2.4758199609434195

Epoch: 6| Step: 8
Training loss: 1.6424489373060323
Validation loss: 2.469467150305419

Epoch: 6| Step: 9
Training loss: 1.726632923744052
Validation loss: 2.4309979432206235

Epoch: 6| Step: 10
Training loss: 2.2853030426610066
Validation loss: 2.4342448815360167

Epoch: 6| Step: 11
Training loss: 1.3882681773551824
Validation loss: 2.4324835626728287

Epoch: 6| Step: 12
Training loss: 0.9705086403864513
Validation loss: 2.463293150483124

Epoch: 6| Step: 13
Training loss: 1.2711704880446202
Validation loss: 2.439678223297007

Epoch: 515| Step: 0
Training loss: 1.5313422506142236
Validation loss: 2.4036751010765047

Epoch: 6| Step: 1
Training loss: 1.4117719951609753
Validation loss: 2.436898587740841

Epoch: 6| Step: 2
Training loss: 1.1565234917589684
Validation loss: 2.425131552278034

Epoch: 6| Step: 3
Training loss: 2.368982622706847
Validation loss: 2.442031660276319

Epoch: 6| Step: 4
Training loss: 1.5242456884462388
Validation loss: 2.4508415647732504

Epoch: 6| Step: 5
Training loss: 1.536575942198891
Validation loss: 2.398675885688712

Epoch: 6| Step: 6
Training loss: 1.2224429008395394
Validation loss: 2.4753792271794435

Epoch: 6| Step: 7
Training loss: 1.154515899172047
Validation loss: 2.367846662206139

Epoch: 6| Step: 8
Training loss: 1.1280333632344153
Validation loss: 2.413311821519545

Epoch: 6| Step: 9
Training loss: 1.5777546665277984
Validation loss: 2.366334392474804

Epoch: 6| Step: 10
Training loss: 1.8548969873579817
Validation loss: 2.4642078572747974

Epoch: 6| Step: 11
Training loss: 1.6087546773396442
Validation loss: 2.4184187261783667

Epoch: 6| Step: 12
Training loss: 1.256938132849221
Validation loss: 2.459084494242465

Epoch: 6| Step: 13
Training loss: 0.9392411276322372
Validation loss: 2.412511466210153

Epoch: 516| Step: 0
Training loss: 1.5889263833711968
Validation loss: 2.410107473289127

Epoch: 6| Step: 1
Training loss: 1.114692944042022
Validation loss: 2.4954231575011936

Epoch: 6| Step: 2
Training loss: 1.231793758939778
Validation loss: 2.426840482227913

Epoch: 6| Step: 3
Training loss: 1.9954327647888126
Validation loss: 2.4266988157536002

Epoch: 6| Step: 4
Training loss: 1.5892661355222486
Validation loss: 2.417991868543953

Epoch: 6| Step: 5
Training loss: 1.2560472599996872
Validation loss: 2.4134125368685333

Epoch: 6| Step: 6
Training loss: 2.5758679306815164
Validation loss: 2.522309451711764

Epoch: 6| Step: 7
Training loss: 1.3469581454428905
Validation loss: 2.4657192960451333

Epoch: 6| Step: 8
Training loss: 0.9618116914910715
Validation loss: 2.4170743756051785

Epoch: 6| Step: 9
Training loss: 1.3048303948459987
Validation loss: 2.4617521037791392

Epoch: 6| Step: 10
Training loss: 1.1518441879282806
Validation loss: 2.386536454980653

Epoch: 6| Step: 11
Training loss: 1.590049111789388
Validation loss: 2.4290795487717913

Epoch: 6| Step: 12
Training loss: 1.2782729382694114
Validation loss: 2.4150732807334543

Epoch: 6| Step: 13
Training loss: 1.4131846363790552
Validation loss: 2.4393852837461116

Epoch: 517| Step: 0
Training loss: 1.905863488207157
Validation loss: 2.4615312174250406

Epoch: 6| Step: 1
Training loss: 1.5470110130238615
Validation loss: 2.403847336395705

Epoch: 6| Step: 2
Training loss: 1.3154596383381516
Validation loss: 2.4817889780536633

Epoch: 6| Step: 3
Training loss: 1.1866989445493354
Validation loss: 2.420022724692054

Epoch: 6| Step: 4
Training loss: 1.6708680444982016
Validation loss: 2.4279452082309465

Epoch: 6| Step: 5
Training loss: 1.2220979823680242
Validation loss: 2.377310342108362

Epoch: 6| Step: 6
Training loss: 1.479185408710786
Validation loss: 2.390730047307372

Epoch: 6| Step: 7
Training loss: 1.5609402310000977
Validation loss: 2.486022749508172

Epoch: 6| Step: 8
Training loss: 1.603918064555168
Validation loss: 2.4604444263419727

Epoch: 6| Step: 9
Training loss: 1.0067573760913153
Validation loss: 2.479632962403273

Epoch: 6| Step: 10
Training loss: 1.9701823519044777
Validation loss: 2.4450670774591217

Epoch: 6| Step: 11
Training loss: 1.785098552814863
Validation loss: 2.4631201364301556

Epoch: 6| Step: 12
Training loss: 1.3626611824239443
Validation loss: 2.400602237535951

Epoch: 6| Step: 13
Training loss: 1.106653825147265
Validation loss: 2.44013600922856

Epoch: 518| Step: 0
Training loss: 1.7884967025884273
Validation loss: 2.445819128008209

Epoch: 6| Step: 1
Training loss: 1.5005956103057696
Validation loss: 2.42905560910826

Epoch: 6| Step: 2
Training loss: 0.9503996610701885
Validation loss: 2.43230159885994

Epoch: 6| Step: 3
Training loss: 1.6171907434108477
Validation loss: 2.4485092007989557

Epoch: 6| Step: 4
Training loss: 1.437980239923399
Validation loss: 2.4324673438593205

Epoch: 6| Step: 5
Training loss: 1.542629079008571
Validation loss: 2.366294706287706

Epoch: 6| Step: 6
Training loss: 1.670959364528801
Validation loss: 2.4353381141454835

Epoch: 6| Step: 7
Training loss: 1.2665517263380155
Validation loss: 2.5058482185226483

Epoch: 6| Step: 8
Training loss: 1.4944582134134075
Validation loss: 2.432104116969405

Epoch: 6| Step: 9
Training loss: 0.9451593322249594
Validation loss: 2.4117811067561727

Epoch: 6| Step: 10
Training loss: 2.2061255833284976
Validation loss: 2.435528120870679

Epoch: 6| Step: 11
Training loss: 1.3806081756492299
Validation loss: 2.4331158845809546

Epoch: 6| Step: 12
Training loss: 1.134574099216062
Validation loss: 2.4481751102399536

Epoch: 6| Step: 13
Training loss: 1.299941424737443
Validation loss: 2.456759920878868

Epoch: 519| Step: 0
Training loss: 1.5616880214429383
Validation loss: 2.4276548039665666

Epoch: 6| Step: 1
Training loss: 1.5551520185586445
Validation loss: 2.474533868670424

Epoch: 6| Step: 2
Training loss: 1.5667040915111143
Validation loss: 2.462591025352128

Epoch: 6| Step: 3
Training loss: 1.2851115859598439
Validation loss: 2.4668068118540694

Epoch: 6| Step: 4
Training loss: 1.7842497078487911
Validation loss: 2.4250658147499067

Epoch: 6| Step: 5
Training loss: 1.3570678249211265
Validation loss: 2.49470264982391

Epoch: 6| Step: 6
Training loss: 1.110149113459672
Validation loss: 2.4259390529742313

Epoch: 6| Step: 7
Training loss: 1.630300752825219
Validation loss: 2.417258626837163

Epoch: 6| Step: 8
Training loss: 0.9954879115111717
Validation loss: 2.3907567566400822

Epoch: 6| Step: 9
Training loss: 1.147695963713211
Validation loss: 2.431222685530164

Epoch: 6| Step: 10
Training loss: 2.0182108297848105
Validation loss: 2.429787821974186

Epoch: 6| Step: 11
Training loss: 1.1644109933954687
Validation loss: 2.389892810767061

Epoch: 6| Step: 12
Training loss: 1.8770897981262091
Validation loss: 2.4250737385501075

Epoch: 6| Step: 13
Training loss: 1.6128644427897312
Validation loss: 2.424767188434769

Epoch: 520| Step: 0
Training loss: 1.2347232472220364
Validation loss: 2.421254757449955

Epoch: 6| Step: 1
Training loss: 1.5610369126563859
Validation loss: 2.4377689712752395

Epoch: 6| Step: 2
Training loss: 2.1663976526760416
Validation loss: 2.3647856411444588

Epoch: 6| Step: 3
Training loss: 1.42925426818947
Validation loss: 2.4123489367867226

Epoch: 6| Step: 4
Training loss: 1.3568647160573062
Validation loss: 2.4631545641103383

Epoch: 6| Step: 5
Training loss: 1.2858520294003746
Validation loss: 2.4297187844575623

Epoch: 6| Step: 6
Training loss: 0.9444249613160991
Validation loss: 2.4537529168852306

Epoch: 6| Step: 7
Training loss: 1.622224711970737
Validation loss: 2.4501891790786607

Epoch: 6| Step: 8
Training loss: 1.478842614724764
Validation loss: 2.434166204740462

Epoch: 6| Step: 9
Training loss: 1.2194467167023324
Validation loss: 2.431074103626538

Epoch: 6| Step: 10
Training loss: 1.2162694384912216
Validation loss: 2.3666300106835068

Epoch: 6| Step: 11
Training loss: 1.564241049652075
Validation loss: 2.4695518357658606

Epoch: 6| Step: 12
Training loss: 1.3871116403976413
Validation loss: 2.4680222622107713

Epoch: 6| Step: 13
Training loss: 1.32472300423182
Validation loss: 2.44908952510306

Epoch: 521| Step: 0
Training loss: 1.5596962760261073
Validation loss: 2.421140495752

Epoch: 6| Step: 1
Training loss: 1.1521718559724001
Validation loss: 2.5156049707851387

Epoch: 6| Step: 2
Training loss: 1.439234971967716
Validation loss: 2.456232547413592

Epoch: 6| Step: 3
Training loss: 2.1958780340848105
Validation loss: 2.449216884748335

Epoch: 6| Step: 4
Training loss: 1.2998668675843705
Validation loss: 2.4107861973604563

Epoch: 6| Step: 5
Training loss: 1.2082543950220954
Validation loss: 2.4282949003479577

Epoch: 6| Step: 6
Training loss: 1.6830789084202185
Validation loss: 2.4253713234906122

Epoch: 6| Step: 7
Training loss: 1.7704306499922229
Validation loss: 2.452490858447503

Epoch: 6| Step: 8
Training loss: 1.3777306492027477
Validation loss: 2.409269103298301

Epoch: 6| Step: 9
Training loss: 1.3796708793978272
Validation loss: 2.428037008124777

Epoch: 6| Step: 10
Training loss: 1.1236356303197763
Validation loss: 2.432162384949021

Epoch: 6| Step: 11
Training loss: 1.5124221466456733
Validation loss: 2.4016016508507514

Epoch: 6| Step: 12
Training loss: 1.1559894886891922
Validation loss: 2.401994457741798

Epoch: 6| Step: 13
Training loss: 1.5545464839911614
Validation loss: 2.42812625054424

Epoch: 522| Step: 0
Training loss: 1.316163988771903
Validation loss: 2.4013878674148335

Epoch: 6| Step: 1
Training loss: 1.254931924653009
Validation loss: 2.4145324665857575

Epoch: 6| Step: 2
Training loss: 1.5364020730618149
Validation loss: 2.4324081883801574

Epoch: 6| Step: 3
Training loss: 1.1065381811615937
Validation loss: 2.3787942423499855

Epoch: 6| Step: 4
Training loss: 1.342609320581418
Validation loss: 2.453119615891547

Epoch: 6| Step: 5
Training loss: 1.5028997050189168
Validation loss: 2.470648632966966

Epoch: 6| Step: 6
Training loss: 2.102456962516912
Validation loss: 2.4112012423969844

Epoch: 6| Step: 7
Training loss: 1.556129438640458
Validation loss: 2.473722271799317

Epoch: 6| Step: 8
Training loss: 1.430229626205578
Validation loss: 2.4563455529836515

Epoch: 6| Step: 9
Training loss: 1.5090137499567702
Validation loss: 2.4382653845045263

Epoch: 6| Step: 10
Training loss: 1.7996720810057625
Validation loss: 2.489785385496719

Epoch: 6| Step: 11
Training loss: 0.9413694952283499
Validation loss: 2.41153748822063

Epoch: 6| Step: 12
Training loss: 1.6665539067588846
Validation loss: 2.4540059263822376

Epoch: 6| Step: 13
Training loss: 1.115842796885724
Validation loss: 2.449602905570278

Epoch: 523| Step: 0
Training loss: 1.0444935143444254
Validation loss: 2.4506317180190145

Epoch: 6| Step: 1
Training loss: 1.4536296009381595
Validation loss: 2.502643168273553

Epoch: 6| Step: 2
Training loss: 1.2293257475675465
Validation loss: 2.4753183961581118

Epoch: 6| Step: 3
Training loss: 1.1457654528307226
Validation loss: 2.432472256203557

Epoch: 6| Step: 4
Training loss: 0.9354194442832392
Validation loss: 2.401234446838715

Epoch: 6| Step: 5
Training loss: 1.4551857722869803
Validation loss: 2.368232704506594

Epoch: 6| Step: 6
Training loss: 1.3927556549379263
Validation loss: 2.482034746131347

Epoch: 6| Step: 7
Training loss: 1.8773391120335838
Validation loss: 2.4406022691239975

Epoch: 6| Step: 8
Training loss: 1.2492996161018526
Validation loss: 2.438585857243913

Epoch: 6| Step: 9
Training loss: 1.1996658932965214
Validation loss: 2.4874074822964407

Epoch: 6| Step: 10
Training loss: 1.698846184236976
Validation loss: 2.45977000669625

Epoch: 6| Step: 11
Training loss: 1.203944732031186
Validation loss: 2.4516826219595065

Epoch: 6| Step: 12
Training loss: 2.457538885854765
Validation loss: 2.420188307470306

Epoch: 6| Step: 13
Training loss: 0.9629472015658699
Validation loss: 2.4493837071557145

Epoch: 524| Step: 0
Training loss: 1.7773433475703528
Validation loss: 2.469311658718924

Epoch: 6| Step: 1
Training loss: 1.5136556513747506
Validation loss: 2.456328662517724

Epoch: 6| Step: 2
Training loss: 1.6026925170996043
Validation loss: 2.4340178883609465

Epoch: 6| Step: 3
Training loss: 1.5235680157433706
Validation loss: 2.526565791361101

Epoch: 6| Step: 4
Training loss: 1.2228732662958752
Validation loss: 2.506386813549562

Epoch: 6| Step: 5
Training loss: 1.5336510653869573
Validation loss: 2.4332889744025894

Epoch: 6| Step: 6
Training loss: 0.9620256233391552
Validation loss: 2.5072869666490334

Epoch: 6| Step: 7
Training loss: 0.848011452221913
Validation loss: 2.493581944355131

Epoch: 6| Step: 8
Training loss: 2.310788732850992
Validation loss: 2.4624538413765085

Epoch: 6| Step: 9
Training loss: 1.5176360955083708
Validation loss: 2.4209414924140273

Epoch: 6| Step: 10
Training loss: 1.5002568342946005
Validation loss: 2.4523778691691356

Epoch: 6| Step: 11
Training loss: 0.7913059408290984
Validation loss: 2.4731395162151677

Epoch: 6| Step: 12
Training loss: 1.4751753169466875
Validation loss: 2.4172981152951594

Epoch: 6| Step: 13
Training loss: 1.5728860898445847
Validation loss: 2.4280542252667185

Epoch: 525| Step: 0
Training loss: 1.6517878469799516
Validation loss: 2.432456620138391

Epoch: 6| Step: 1
Training loss: 1.0093225802105348
Validation loss: 2.467125011647861

Epoch: 6| Step: 2
Training loss: 1.662951389499188
Validation loss: 2.4624098548528073

Epoch: 6| Step: 3
Training loss: 1.3910159729397689
Validation loss: 2.4676223792341805

Epoch: 6| Step: 4
Training loss: 2.280021232037649
Validation loss: 2.4754892880077857

Epoch: 6| Step: 5
Training loss: 1.7215730544296635
Validation loss: 2.480404119381929

Epoch: 6| Step: 6
Training loss: 1.5863991051494866
Validation loss: 2.4422714759677224

Epoch: 6| Step: 7
Training loss: 1.6701527218456191
Validation loss: 2.4262034637102685

Epoch: 6| Step: 8
Training loss: 1.1084458664480756
Validation loss: 2.4362497396820495

Epoch: 6| Step: 9
Training loss: 1.0313407395640855
Validation loss: 2.433108317290061

Epoch: 6| Step: 10
Training loss: 1.331571840953136
Validation loss: 2.4063864835576734

Epoch: 6| Step: 11
Training loss: 0.9719148744210473
Validation loss: 2.5382084639311397

Epoch: 6| Step: 12
Training loss: 1.0113429840870491
Validation loss: 2.4316385122132615

Epoch: 6| Step: 13
Training loss: 1.828204030994044
Validation loss: 2.4480294160834215

Epoch: 526| Step: 0
Training loss: 1.2063032504172253
Validation loss: 2.4086120267369275

Epoch: 6| Step: 1
Training loss: 1.4440320090447274
Validation loss: 2.4543632756019846

Epoch: 6| Step: 2
Training loss: 1.759071475690725
Validation loss: 2.4275832129931993

Epoch: 6| Step: 3
Training loss: 1.449611394701419
Validation loss: 2.4369363314478996

Epoch: 6| Step: 4
Training loss: 2.4531290819656526
Validation loss: 2.434264550205937

Epoch: 6| Step: 5
Training loss: 1.4363485783543803
Validation loss: 2.457674868167107

Epoch: 6| Step: 6
Training loss: 1.2532052906218138
Validation loss: 2.4821299436956896

Epoch: 6| Step: 7
Training loss: 1.1222812331508774
Validation loss: 2.350959521462263

Epoch: 6| Step: 8
Training loss: 1.2017227522362166
Validation loss: 2.4758720818806315

Epoch: 6| Step: 9
Training loss: 1.2964389481592726
Validation loss: 2.425498320919352

Epoch: 6| Step: 10
Training loss: 0.992103933584826
Validation loss: 2.3871139253727978

Epoch: 6| Step: 11
Training loss: 1.3715537840018042
Validation loss: 2.444441622612494

Epoch: 6| Step: 12
Training loss: 1.417721056781809
Validation loss: 2.474698587665137

Epoch: 6| Step: 13
Training loss: 1.5840214020602936
Validation loss: 2.417584239928581

Epoch: 527| Step: 0
Training loss: 1.6400321979385857
Validation loss: 2.4585429704094874

Epoch: 6| Step: 1
Training loss: 1.7025249018927568
Validation loss: 2.4308498084521575

Epoch: 6| Step: 2
Training loss: 1.3013724052030324
Validation loss: 2.4566863438227613

Epoch: 6| Step: 3
Training loss: 1.3552500963434446
Validation loss: 2.4143312047617544

Epoch: 6| Step: 4
Training loss: 1.8196255939113442
Validation loss: 2.3886863037212365

Epoch: 6| Step: 5
Training loss: 1.4044212742487345
Validation loss: 2.4911382055976983

Epoch: 6| Step: 6
Training loss: 2.0888803132988145
Validation loss: 2.485479900504426

Epoch: 6| Step: 7
Training loss: 1.2180007196308384
Validation loss: 2.415276583409694

Epoch: 6| Step: 8
Training loss: 1.1281659295854618
Validation loss: 2.4398388806993565

Epoch: 6| Step: 9
Training loss: 1.398202716575606
Validation loss: 2.4419383860174584

Epoch: 6| Step: 10
Training loss: 1.1090516707213298
Validation loss: 2.4374715242281764

Epoch: 6| Step: 11
Training loss: 1.4001707705159971
Validation loss: 2.4878298532464216

Epoch: 6| Step: 12
Training loss: 1.3855780409519918
Validation loss: 2.4413163583921564

Epoch: 6| Step: 13
Training loss: 1.137827172230595
Validation loss: 2.4685899364067283

Epoch: 528| Step: 0
Training loss: 2.0989838275986092
Validation loss: 2.4603074540304513

Epoch: 6| Step: 1
Training loss: 1.237364372373484
Validation loss: 2.47329923924955

Epoch: 6| Step: 2
Training loss: 1.1958690668985443
Validation loss: 2.4106347787071845

Epoch: 6| Step: 3
Training loss: 1.5809287668451806
Validation loss: 2.4588887703191435

Epoch: 6| Step: 4
Training loss: 0.9493479699612034
Validation loss: 2.423863484126362

Epoch: 6| Step: 5
Training loss: 1.2938628087641817
Validation loss: 2.3996485318626326

Epoch: 6| Step: 6
Training loss: 1.7249257887204938
Validation loss: 2.439265020991769

Epoch: 6| Step: 7
Training loss: 1.514998001500187
Validation loss: 2.4689214918668245

Epoch: 6| Step: 8
Training loss: 1.591755085964115
Validation loss: 2.4364717048323308

Epoch: 6| Step: 9
Training loss: 1.779773166862052
Validation loss: 2.494527261517308

Epoch: 6| Step: 10
Training loss: 1.1555756329255367
Validation loss: 2.4810456834653043

Epoch: 6| Step: 11
Training loss: 1.1113254433115163
Validation loss: 2.419749978656508

Epoch: 6| Step: 12
Training loss: 1.5809201706982567
Validation loss: 2.4006137336201125

Epoch: 6| Step: 13
Training loss: 1.1573891054755046
Validation loss: 2.40528649615658

Epoch: 529| Step: 0
Training loss: 1.488123927975156
Validation loss: 2.4419599296557903

Epoch: 6| Step: 1
Training loss: 1.37307231331454
Validation loss: 2.4349244201220928

Epoch: 6| Step: 2
Training loss: 2.072170359644604
Validation loss: 2.4149083806908562

Epoch: 6| Step: 3
Training loss: 1.6863303192668722
Validation loss: 2.426606467108934

Epoch: 6| Step: 4
Training loss: 1.3979371950070154
Validation loss: 2.455017010244501

Epoch: 6| Step: 5
Training loss: 1.3148172449533235
Validation loss: 2.43884323368608

Epoch: 6| Step: 6
Training loss: 1.6153419763226518
Validation loss: 2.4151263825229172

Epoch: 6| Step: 7
Training loss: 1.1919947937173243
Validation loss: 2.4360725928892712

Epoch: 6| Step: 8
Training loss: 1.3706284736140497
Validation loss: 2.4633890015483577

Epoch: 6| Step: 9
Training loss: 1.1352966431807936
Validation loss: 2.4112680202787145

Epoch: 6| Step: 10
Training loss: 1.0020850617095782
Validation loss: 2.4272863063858177

Epoch: 6| Step: 11
Training loss: 1.4095622156139773
Validation loss: 2.4784399656342884

Epoch: 6| Step: 12
Training loss: 1.0395833481130554
Validation loss: 2.3871411047408015

Epoch: 6| Step: 13
Training loss: 1.1273222373342637
Validation loss: 2.419971451287968

Epoch: 530| Step: 0
Training loss: 1.1428986971827795
Validation loss: 2.520732586429784

Epoch: 6| Step: 1
Training loss: 1.0569870921946498
Validation loss: 2.451026592223362

Epoch: 6| Step: 2
Training loss: 1.2265347034196086
Validation loss: 2.4301322564501975

Epoch: 6| Step: 3
Training loss: 1.640425533703181
Validation loss: 2.4521235029817277

Epoch: 6| Step: 4
Training loss: 1.3441178904980113
Validation loss: 2.4836733670802764

Epoch: 6| Step: 5
Training loss: 1.5513536756422472
Validation loss: 2.477678482212556

Epoch: 6| Step: 6
Training loss: 1.6407007835687173
Validation loss: 2.4505684283388645

Epoch: 6| Step: 7
Training loss: 2.1134112136562093
Validation loss: 2.446693697897945

Epoch: 6| Step: 8
Training loss: 1.5412052168454136
Validation loss: 2.415838358112143

Epoch: 6| Step: 9
Training loss: 1.1439299582567448
Validation loss: 2.442397024683706

Epoch: 6| Step: 10
Training loss: 1.286085818742107
Validation loss: 2.353700731279492

Epoch: 6| Step: 11
Training loss: 1.5427107583215145
Validation loss: 2.446038009149887

Epoch: 6| Step: 12
Training loss: 1.5550568875029496
Validation loss: 2.4587123527221912

Epoch: 6| Step: 13
Training loss: 1.4877738187713658
Validation loss: 2.4182117481929573

Epoch: 531| Step: 0
Training loss: 1.3880252754564995
Validation loss: 2.373514089466747

Epoch: 6| Step: 1
Training loss: 1.574162863219745
Validation loss: 2.4231478529480404

Epoch: 6| Step: 2
Training loss: 1.4585435806579339
Validation loss: 2.438570413867141

Epoch: 6| Step: 3
Training loss: 1.378752702587588
Validation loss: 2.432701414836748

Epoch: 6| Step: 4
Training loss: 1.8086356699886716
Validation loss: 2.4213332433971364

Epoch: 6| Step: 5
Training loss: 1.1120401525040586
Validation loss: 2.4332575872917483

Epoch: 6| Step: 6
Training loss: 1.5742382871868448
Validation loss: 2.3845636214837165

Epoch: 6| Step: 7
Training loss: 1.4488054287619703
Validation loss: 2.4912039469898795

Epoch: 6| Step: 8
Training loss: 1.7577244715371565
Validation loss: 2.4388103891097033

Epoch: 6| Step: 9
Training loss: 1.2456812160762745
Validation loss: 2.4118718142929096

Epoch: 6| Step: 10
Training loss: 1.277473093186192
Validation loss: 2.4147427623206354

Epoch: 6| Step: 11
Training loss: 2.060048004072539
Validation loss: 2.4466341319551286

Epoch: 6| Step: 12
Training loss: 0.8733690252060126
Validation loss: 2.3842261790366943

Epoch: 6| Step: 13
Training loss: 1.2594563422426108
Validation loss: 2.4699767950797265

Epoch: 532| Step: 0
Training loss: 1.3287954545522638
Validation loss: 2.463845952993608

Epoch: 6| Step: 1
Training loss: 1.2304126545063094
Validation loss: 2.5012290025626003

Epoch: 6| Step: 2
Training loss: 1.246300467920357
Validation loss: 2.4451622191909608

Epoch: 6| Step: 3
Training loss: 1.095371678994314
Validation loss: 2.443820140872589

Epoch: 6| Step: 4
Training loss: 1.658235044138462
Validation loss: 2.417574399795072

Epoch: 6| Step: 5
Training loss: 1.4720839949360813
Validation loss: 2.479652006382719

Epoch: 6| Step: 6
Training loss: 1.6162743685626695
Validation loss: 2.4676847224714806

Epoch: 6| Step: 7
Training loss: 1.5115982520209181
Validation loss: 2.4570897250259534

Epoch: 6| Step: 8
Training loss: 2.11355425469147
Validation loss: 2.451661788025868

Epoch: 6| Step: 9
Training loss: 1.2998977272445211
Validation loss: 2.3825589237885607

Epoch: 6| Step: 10
Training loss: 1.3740372321568997
Validation loss: 2.4412730001859155

Epoch: 6| Step: 11
Training loss: 1.5618067157010378
Validation loss: 2.427863663721853

Epoch: 6| Step: 12
Training loss: 1.2892126747277624
Validation loss: 2.471088627825464

Epoch: 6| Step: 13
Training loss: 1.4526500951327406
Validation loss: 2.4897508827849775

Epoch: 533| Step: 0
Training loss: 1.182095627629473
Validation loss: 2.459732448689204

Epoch: 6| Step: 1
Training loss: 1.6010169612026581
Validation loss: 2.4141777922471412

Epoch: 6| Step: 2
Training loss: 1.0320958223435572
Validation loss: 2.414545962509088

Epoch: 6| Step: 3
Training loss: 1.3165684269016302
Validation loss: 2.425777869195524

Epoch: 6| Step: 4
Training loss: 1.3350467947284415
Validation loss: 2.395095740190204

Epoch: 6| Step: 5
Training loss: 1.9422487698847057
Validation loss: 2.4642117513047954

Epoch: 6| Step: 6
Training loss: 1.2389003517683064
Validation loss: 2.4472014259151673

Epoch: 6| Step: 7
Training loss: 1.6227506328200119
Validation loss: 2.444258423020035

Epoch: 6| Step: 8
Training loss: 1.6136486752683914
Validation loss: 2.4528673072049227

Epoch: 6| Step: 9
Training loss: 1.5684004952822748
Validation loss: 2.4820396667602385

Epoch: 6| Step: 10
Training loss: 1.2955333710071177
Validation loss: 2.4137024736267283

Epoch: 6| Step: 11
Training loss: 1.5461094050219613
Validation loss: 2.405483599503919

Epoch: 6| Step: 12
Training loss: 1.2800887823607032
Validation loss: 2.361522847331066

Epoch: 6| Step: 13
Training loss: 1.3758267171474612
Validation loss: 2.4914656162036586

Epoch: 534| Step: 0
Training loss: 1.4927181878023061
Validation loss: 2.4639427418608277

Epoch: 6| Step: 1
Training loss: 1.3741569535509959
Validation loss: 2.3899246209699867

Epoch: 6| Step: 2
Training loss: 1.3544925395412304
Validation loss: 2.449243616746345

Epoch: 6| Step: 3
Training loss: 1.6393623943185978
Validation loss: 2.485177005906121

Epoch: 6| Step: 4
Training loss: 0.8841821628786174
Validation loss: 2.4498688868451044

Epoch: 6| Step: 5
Training loss: 0.9470165121759778
Validation loss: 2.4488207587314696

Epoch: 6| Step: 6
Training loss: 1.566156610016894
Validation loss: 2.446340105503729

Epoch: 6| Step: 7
Training loss: 2.022769773619299
Validation loss: 2.3886727443318487

Epoch: 6| Step: 8
Training loss: 1.631170295726626
Validation loss: 2.4090169205208567

Epoch: 6| Step: 9
Training loss: 1.331923270673231
Validation loss: 2.4391257441610237

Epoch: 6| Step: 10
Training loss: 1.6032899797702123
Validation loss: 2.410294316267655

Epoch: 6| Step: 11
Training loss: 1.1493334746002972
Validation loss: 2.429053800141158

Epoch: 6| Step: 12
Training loss: 1.4027157770855756
Validation loss: 2.4182992992492647

Epoch: 6| Step: 13
Training loss: 1.2168184771388284
Validation loss: 2.467383847189608

Epoch: 535| Step: 0
Training loss: 1.144257808999537
Validation loss: 2.468477434776962

Epoch: 6| Step: 1
Training loss: 1.6391757195046088
Validation loss: 2.4403194636709493

Epoch: 6| Step: 2
Training loss: 1.482385205203575
Validation loss: 2.4703820367497094

Epoch: 6| Step: 3
Training loss: 1.5642903561159305
Validation loss: 2.4558685294160463

Epoch: 6| Step: 4
Training loss: 1.2454605646310715
Validation loss: 2.3796841639831063

Epoch: 6| Step: 5
Training loss: 0.9465676479256286
Validation loss: 2.436298788518243

Epoch: 6| Step: 6
Training loss: 1.3848389685487028
Validation loss: 2.4306360514056826

Epoch: 6| Step: 7
Training loss: 1.1581451247103887
Validation loss: 2.466683582784467

Epoch: 6| Step: 8
Training loss: 1.3863993532096732
Validation loss: 2.452377011443442

Epoch: 6| Step: 9
Training loss: 2.152741161841733
Validation loss: 2.3709648148490223

Epoch: 6| Step: 10
Training loss: 1.3839992452409924
Validation loss: 2.4755695785587437

Epoch: 6| Step: 11
Training loss: 1.2922703911280782
Validation loss: 2.4608905022725716

Epoch: 6| Step: 12
Training loss: 1.1323389576310054
Validation loss: 2.4735641633521115

Epoch: 6| Step: 13
Training loss: 1.5448123010486392
Validation loss: 2.474828271593724

Epoch: 536| Step: 0
Training loss: 1.1807556369250367
Validation loss: 2.4051741714860766

Epoch: 6| Step: 1
Training loss: 1.7416035995137802
Validation loss: 2.4265336613945157

Epoch: 6| Step: 2
Training loss: 1.2947388946917255
Validation loss: 2.44964764898917

Epoch: 6| Step: 3
Training loss: 1.4304257347352127
Validation loss: 2.492826138419701

Epoch: 6| Step: 4
Training loss: 1.0076739785268458
Validation loss: 2.448973582834906

Epoch: 6| Step: 5
Training loss: 0.9632772168696141
Validation loss: 2.469836395156625

Epoch: 6| Step: 6
Training loss: 1.442191553575103
Validation loss: 2.519466468567733

Epoch: 6| Step: 7
Training loss: 1.0466320268301017
Validation loss: 2.4307902550267637

Epoch: 6| Step: 8
Training loss: 1.240228415647592
Validation loss: 2.459228487869575

Epoch: 6| Step: 9
Training loss: 1.516322575127143
Validation loss: 2.426638340117292

Epoch: 6| Step: 10
Training loss: 1.4310559670135539
Validation loss: 2.47328491648249

Epoch: 6| Step: 11
Training loss: 1.7431633786325689
Validation loss: 2.4698894140839496

Epoch: 6| Step: 12
Training loss: 2.0898752370583575
Validation loss: 2.4617071580772243

Epoch: 6| Step: 13
Training loss: 1.5786964968014154
Validation loss: 2.41787694053358

Epoch: 537| Step: 0
Training loss: 1.2936293651711002
Validation loss: 2.452724710733686

Epoch: 6| Step: 1
Training loss: 1.293898556422345
Validation loss: 2.412943135183682

Epoch: 6| Step: 2
Training loss: 1.2657441448126725
Validation loss: 2.509026210543327

Epoch: 6| Step: 3
Training loss: 1.1858358769357136
Validation loss: 2.4317699221569686

Epoch: 6| Step: 4
Training loss: 1.1985659733113403
Validation loss: 2.438566944613161

Epoch: 6| Step: 5
Training loss: 0.9904461696233521
Validation loss: 2.4667640144536036

Epoch: 6| Step: 6
Training loss: 1.5277731211427563
Validation loss: 2.4484734227818015

Epoch: 6| Step: 7
Training loss: 1.415673365829877
Validation loss: 2.4276419115694456

Epoch: 6| Step: 8
Training loss: 1.3980244713880343
Validation loss: 2.3932967216553984

Epoch: 6| Step: 9
Training loss: 1.9504517227648326
Validation loss: 2.4438556502800126

Epoch: 6| Step: 10
Training loss: 1.494890810063344
Validation loss: 2.426009953811292

Epoch: 6| Step: 11
Training loss: 1.7371836422312805
Validation loss: 2.445071717045149

Epoch: 6| Step: 12
Training loss: 1.2919608160637615
Validation loss: 2.432525330177992

Epoch: 6| Step: 13
Training loss: 1.6745439420978847
Validation loss: 2.3764944442632614

Epoch: 538| Step: 0
Training loss: 2.122036157255044
Validation loss: 2.4125025251076626

Epoch: 6| Step: 1
Training loss: 1.2312662597976824
Validation loss: 2.4258489422465725

Epoch: 6| Step: 2
Training loss: 1.2110321992330946
Validation loss: 2.4419881646466464

Epoch: 6| Step: 3
Training loss: 1.3683041181632136
Validation loss: 2.4593800544022306

Epoch: 6| Step: 4
Training loss: 1.5183866843360243
Validation loss: 2.435148618977522

Epoch: 6| Step: 5
Training loss: 1.4993842768570969
Validation loss: 2.4240960772281426

Epoch: 6| Step: 6
Training loss: 1.2475889317953819
Validation loss: 2.4168083572293275

Epoch: 6| Step: 7
Training loss: 1.5170430893533755
Validation loss: 2.4662364470904987

Epoch: 6| Step: 8
Training loss: 1.1983347066589325
Validation loss: 2.3980503922265144

Epoch: 6| Step: 9
Training loss: 1.6103154369810873
Validation loss: 2.41144891400091

Epoch: 6| Step: 10
Training loss: 1.2597107394778222
Validation loss: 2.4227046586811354

Epoch: 6| Step: 11
Training loss: 1.4600416078256233
Validation loss: 2.4494752724224726

Epoch: 6| Step: 12
Training loss: 1.6140515425864983
Validation loss: 2.4886563879027217

Epoch: 6| Step: 13
Training loss: 1.3006295697096655
Validation loss: 2.441959282960969

Epoch: 539| Step: 0
Training loss: 1.8303033614813826
Validation loss: 2.4842931293193886

Epoch: 6| Step: 1
Training loss: 1.0565324259023157
Validation loss: 2.4435797259896166

Epoch: 6| Step: 2
Training loss: 1.318959101149141
Validation loss: 2.4422268131281415

Epoch: 6| Step: 3
Training loss: 1.3425016592857293
Validation loss: 2.4354385438854704

Epoch: 6| Step: 4
Training loss: 1.1703343754800581
Validation loss: 2.390195685356287

Epoch: 6| Step: 5
Training loss: 1.046913374012462
Validation loss: 2.4775004245268497

Epoch: 6| Step: 6
Training loss: 1.4420617740007464
Validation loss: 2.4112657780059483

Epoch: 6| Step: 7
Training loss: 1.2321368823489063
Validation loss: 2.3986802553641877

Epoch: 6| Step: 8
Training loss: 1.092009876744525
Validation loss: 2.4116639130013913

Epoch: 6| Step: 9
Training loss: 1.039362813817359
Validation loss: 2.426703446087662

Epoch: 6| Step: 10
Training loss: 2.07630645803803
Validation loss: 2.464083487479649

Epoch: 6| Step: 11
Training loss: 1.6711014714002452
Validation loss: 2.4570680615495952

Epoch: 6| Step: 12
Training loss: 1.356387659636924
Validation loss: 2.4776813462456535

Epoch: 6| Step: 13
Training loss: 1.6422108569602936
Validation loss: 2.5350122722326978

Epoch: 540| Step: 0
Training loss: 1.226231524282592
Validation loss: 2.449573724866902

Epoch: 6| Step: 1
Training loss: 1.3077539282732293
Validation loss: 2.4673177007414178

Epoch: 6| Step: 2
Training loss: 1.6582567545527367
Validation loss: 2.441127096775863

Epoch: 6| Step: 3
Training loss: 1.386939662476293
Validation loss: 2.4733696090809336

Epoch: 6| Step: 4
Training loss: 0.9123846451468636
Validation loss: 2.4500477943337553

Epoch: 6| Step: 5
Training loss: 1.5571378634061521
Validation loss: 2.434475422357707

Epoch: 6| Step: 6
Training loss: 1.4532739706485658
Validation loss: 2.407601726750482

Epoch: 6| Step: 7
Training loss: 1.336758456150445
Validation loss: 2.3912505821185848

Epoch: 6| Step: 8
Training loss: 2.398685206442165
Validation loss: 2.415354359308302

Epoch: 6| Step: 9
Training loss: 1.212095678893199
Validation loss: 2.452578671694334

Epoch: 6| Step: 10
Training loss: 1.4162415633324879
Validation loss: 2.4781907096828184

Epoch: 6| Step: 11
Training loss: 1.0996054722122126
Validation loss: 2.428015950707386

Epoch: 6| Step: 12
Training loss: 1.2144433738633587
Validation loss: 2.46132756696946

Epoch: 6| Step: 13
Training loss: 1.1311744685801632
Validation loss: 2.470151900666166

Epoch: 541| Step: 0
Training loss: 1.199001926366485
Validation loss: 2.422671842398078

Epoch: 6| Step: 1
Training loss: 1.5784395867460237
Validation loss: 2.43579373775194

Epoch: 6| Step: 2
Training loss: 2.1222613020933103
Validation loss: 2.433110547862658

Epoch: 6| Step: 3
Training loss: 1.614298575937224
Validation loss: 2.5095998263738832

Epoch: 6| Step: 4
Training loss: 1.4645626357864814
Validation loss: 2.459448381274051

Epoch: 6| Step: 5
Training loss: 1.3097916315797842
Validation loss: 2.417259683151736

Epoch: 6| Step: 6
Training loss: 1.3913668250485576
Validation loss: 2.48151505771914

Epoch: 6| Step: 7
Training loss: 1.0449221602109715
Validation loss: 2.401353039948574

Epoch: 6| Step: 8
Training loss: 1.2604582545878038
Validation loss: 2.3614491206489436

Epoch: 6| Step: 9
Training loss: 1.0465899976260036
Validation loss: 2.4965602725017244

Epoch: 6| Step: 10
Training loss: 1.242465390005423
Validation loss: 2.4385540463040902

Epoch: 6| Step: 11
Training loss: 1.4365627716508982
Validation loss: 2.4364263632714276

Epoch: 6| Step: 12
Training loss: 1.4813959041797888
Validation loss: 2.4745927288510385

Epoch: 6| Step: 13
Training loss: 1.971288286029614
Validation loss: 2.4388207401053688

Epoch: 542| Step: 0
Training loss: 1.2880068531298317
Validation loss: 2.4501713123410735

Epoch: 6| Step: 1
Training loss: 1.5488058042902202
Validation loss: 2.482671529142901

Epoch: 6| Step: 2
Training loss: 2.0585537930108804
Validation loss: 2.4451955482748593

Epoch: 6| Step: 3
Training loss: 1.2795913939665684
Validation loss: 2.40277732673505

Epoch: 6| Step: 4
Training loss: 1.0117126229001243
Validation loss: 2.37488553527484

Epoch: 6| Step: 5
Training loss: 1.9192787560170461
Validation loss: 2.527496161360741

Epoch: 6| Step: 6
Training loss: 1.4542073146673353
Validation loss: 2.4540249394083746

Epoch: 6| Step: 7
Training loss: 1.227575090679273
Validation loss: 2.3819458405992373

Epoch: 6| Step: 8
Training loss: 1.3909184864109916
Validation loss: 2.4196230535284764

Epoch: 6| Step: 9
Training loss: 1.4569001739696656
Validation loss: 2.4508184370596067

Epoch: 6| Step: 10
Training loss: 1.8886538231508687
Validation loss: 2.466060509392317

Epoch: 6| Step: 11
Training loss: 1.079001416008332
Validation loss: 2.485210031485147

Epoch: 6| Step: 12
Training loss: 1.1498935318465442
Validation loss: 2.408207261818381

Epoch: 6| Step: 13
Training loss: 1.2267226582339668
Validation loss: 2.440440762763519

Epoch: 543| Step: 0
Training loss: 1.0827317156801348
Validation loss: 2.4268883817807034

Epoch: 6| Step: 1
Training loss: 1.2065212814376507
Validation loss: 2.4442178209642256

Epoch: 6| Step: 2
Training loss: 1.6167988333145304
Validation loss: 2.521869607786913

Epoch: 6| Step: 3
Training loss: 0.9874187822381766
Validation loss: 2.477217453370892

Epoch: 6| Step: 4
Training loss: 1.7309051032408365
Validation loss: 2.4569783308008764

Epoch: 6| Step: 5
Training loss: 1.612437473238122
Validation loss: 2.4574361571493815

Epoch: 6| Step: 6
Training loss: 1.2962602284247702
Validation loss: 2.492146449522951

Epoch: 6| Step: 7
Training loss: 1.3660088390326872
Validation loss: 2.3911243871269403

Epoch: 6| Step: 8
Training loss: 0.9262890610071315
Validation loss: 2.529214282216989

Epoch: 6| Step: 9
Training loss: 1.2243822486433094
Validation loss: 2.4015220364603325

Epoch: 6| Step: 10
Training loss: 1.73581319753634
Validation loss: 2.5193285178228053

Epoch: 6| Step: 11
Training loss: 1.1560792539151492
Validation loss: 2.451741881214748

Epoch: 6| Step: 12
Training loss: 2.0624771116894065
Validation loss: 2.4489019152714433

Epoch: 6| Step: 13
Training loss: 1.1446807034660684
Validation loss: 2.4531682856288612

Epoch: 544| Step: 0
Training loss: 1.5598700706464574
Validation loss: 2.4413785107421107

Epoch: 6| Step: 1
Training loss: 0.9055276820281706
Validation loss: 2.459535233684644

Epoch: 6| Step: 2
Training loss: 1.3484034139451337
Validation loss: 2.4931568245115745

Epoch: 6| Step: 3
Training loss: 1.106482159235871
Validation loss: 2.3822764896074897

Epoch: 6| Step: 4
Training loss: 1.4974951492765958
Validation loss: 2.4349904137027436

Epoch: 6| Step: 5
Training loss: 1.9651854200943897
Validation loss: 2.367561813515867

Epoch: 6| Step: 6
Training loss: 1.0350661328513824
Validation loss: 2.456717301166626

Epoch: 6| Step: 7
Training loss: 1.3578982169220717
Validation loss: 2.4332051656679554

Epoch: 6| Step: 8
Training loss: 2.015960074082369
Validation loss: 2.376743957638732

Epoch: 6| Step: 9
Training loss: 1.2159042880920348
Validation loss: 2.378449160672125

Epoch: 6| Step: 10
Training loss: 0.8409378022838717
Validation loss: 2.464646767161135

Epoch: 6| Step: 11
Training loss: 1.2789421696357912
Validation loss: 2.4194234898784215

Epoch: 6| Step: 12
Training loss: 1.2655916562809657
Validation loss: 2.4327202034032798

Epoch: 6| Step: 13
Training loss: 0.9930731657700148
Validation loss: 2.4217164071376196

Epoch: 545| Step: 0
Training loss: 0.9354607974533634
Validation loss: 2.4617460251862378

Epoch: 6| Step: 1
Training loss: 0.8664759560587809
Validation loss: 2.425594547291726

Epoch: 6| Step: 2
Training loss: 1.4762422729083235
Validation loss: 2.4862532529674213

Epoch: 6| Step: 3
Training loss: 1.3344613112111512
Validation loss: 2.4696953011080756

Epoch: 6| Step: 4
Training loss: 1.7162643492030052
Validation loss: 2.4153489557495966

Epoch: 6| Step: 5
Training loss: 2.3439880250227807
Validation loss: 2.4181037589609122

Epoch: 6| Step: 6
Training loss: 1.522690027213625
Validation loss: 2.455035741850063

Epoch: 6| Step: 7
Training loss: 0.9942478204578109
Validation loss: 2.4018307363272524

Epoch: 6| Step: 8
Training loss: 1.160315505891251
Validation loss: 2.5043381982677424

Epoch: 6| Step: 9
Training loss: 1.599251992495585
Validation loss: 2.4585991665823537

Epoch: 6| Step: 10
Training loss: 1.241479251892531
Validation loss: 2.3932275505738447

Epoch: 6| Step: 11
Training loss: 1.1394167732453173
Validation loss: 2.4684520701063994

Epoch: 6| Step: 12
Training loss: 1.0195218374468222
Validation loss: 2.4559882484527127

Epoch: 6| Step: 13
Training loss: 1.6356733165305455
Validation loss: 2.3852486338750114

Epoch: 546| Step: 0
Training loss: 1.3063258317902506
Validation loss: 2.4163634421527216

Epoch: 6| Step: 1
Training loss: 1.392853312434704
Validation loss: 2.4048662941604038

Epoch: 6| Step: 2
Training loss: 0.8523530702579617
Validation loss: 2.439965481291207

Epoch: 6| Step: 3
Training loss: 1.5928540422823614
Validation loss: 2.4193968639005266

Epoch: 6| Step: 4
Training loss: 1.0019567537892682
Validation loss: 2.401520584650911

Epoch: 6| Step: 5
Training loss: 1.3623367141732707
Validation loss: 2.4659624812630145

Epoch: 6| Step: 6
Training loss: 1.329994367071284
Validation loss: 2.445675649932031

Epoch: 6| Step: 7
Training loss: 2.055260639971917
Validation loss: 2.4167537786662434

Epoch: 6| Step: 8
Training loss: 1.1696240996642386
Validation loss: 2.4838257508356585

Epoch: 6| Step: 9
Training loss: 1.5541810404067677
Validation loss: 2.424501010658953

Epoch: 6| Step: 10
Training loss: 1.265303017431647
Validation loss: 2.4124783210560334

Epoch: 6| Step: 11
Training loss: 1.371889063039662
Validation loss: 2.4393380920075236

Epoch: 6| Step: 12
Training loss: 1.5886163495961583
Validation loss: 2.470535406350431

Epoch: 6| Step: 13
Training loss: 1.05025193734139
Validation loss: 2.4633763185458624

Epoch: 547| Step: 0
Training loss: 1.423330463358884
Validation loss: 2.4222766999577914

Epoch: 6| Step: 1
Training loss: 1.0791592267539727
Validation loss: 2.4250522621425574

Epoch: 6| Step: 2
Training loss: 1.670875393091565
Validation loss: 2.3993002410842954

Epoch: 6| Step: 3
Training loss: 1.962487204929117
Validation loss: 2.4226877744140527

Epoch: 6| Step: 4
Training loss: 1.2472440856927942
Validation loss: 2.418590580401374

Epoch: 6| Step: 5
Training loss: 1.175845122265852
Validation loss: 2.4416193161394855

Epoch: 6| Step: 6
Training loss: 1.2166418279873241
Validation loss: 2.4446544818782177

Epoch: 6| Step: 7
Training loss: 1.3929073164011094
Validation loss: 2.425388920521656

Epoch: 6| Step: 8
Training loss: 1.6183505828493372
Validation loss: 2.4625844064499645

Epoch: 6| Step: 9
Training loss: 1.325008460683621
Validation loss: 2.4065842574107035

Epoch: 6| Step: 10
Training loss: 1.1620553140327288
Validation loss: 2.4556179647601435

Epoch: 6| Step: 11
Training loss: 1.3901302014577646
Validation loss: 2.4415392909399145

Epoch: 6| Step: 12
Training loss: 1.4166975391988303
Validation loss: 2.412650752491372

Epoch: 6| Step: 13
Training loss: 1.0283150958067464
Validation loss: 2.4283270705509974

Epoch: 548| Step: 0
Training loss: 1.1658938550384552
Validation loss: 2.5048614190804055

Epoch: 6| Step: 1
Training loss: 1.674515110260934
Validation loss: 2.4303371496169572

Epoch: 6| Step: 2
Training loss: 0.9900314755204552
Validation loss: 2.445152285067092

Epoch: 6| Step: 3
Training loss: 1.2929793988391496
Validation loss: 2.4928805220621086

Epoch: 6| Step: 4
Training loss: 0.9626136056314577
Validation loss: 2.4503887365355124

Epoch: 6| Step: 5
Training loss: 1.6963539967601746
Validation loss: 2.4328327473459734

Epoch: 6| Step: 6
Training loss: 1.1884890001660195
Validation loss: 2.460451305234109

Epoch: 6| Step: 7
Training loss: 1.2539037781688058
Validation loss: 2.457224950757738

Epoch: 6| Step: 8
Training loss: 1.2667535530373264
Validation loss: 2.4428642645256513

Epoch: 6| Step: 9
Training loss: 1.4833670958773462
Validation loss: 2.381757458859838

Epoch: 6| Step: 10
Training loss: 1.195311053904737
Validation loss: 2.455481206611954

Epoch: 6| Step: 11
Training loss: 2.1091274540075893
Validation loss: 2.4405697244826308

Epoch: 6| Step: 12
Training loss: 1.0158676444484747
Validation loss: 2.532003453886523

Epoch: 6| Step: 13
Training loss: 1.366412482620952
Validation loss: 2.411135626925139

Epoch: 549| Step: 0
Training loss: 1.1267185859643025
Validation loss: 2.4272788043587488

Epoch: 6| Step: 1
Training loss: 1.3498149003183584
Validation loss: 2.40449104642272

Epoch: 6| Step: 2
Training loss: 1.0384412356644375
Validation loss: 2.487709765247642

Epoch: 6| Step: 3
Training loss: 1.2183043325306295
Validation loss: 2.4063158179429314

Epoch: 6| Step: 4
Training loss: 1.4134449321543836
Validation loss: 2.4772679030907594

Epoch: 6| Step: 5
Training loss: 0.9713936696274131
Validation loss: 2.4507126859204043

Epoch: 6| Step: 6
Training loss: 2.344239654254571
Validation loss: 2.355517050637097

Epoch: 6| Step: 7
Training loss: 0.9604877566977605
Validation loss: 2.470077168298487

Epoch: 6| Step: 8
Training loss: 1.113304057640549
Validation loss: 2.432782940504492

Epoch: 6| Step: 9
Training loss: 1.3448996837601128
Validation loss: 2.4206527404397895

Epoch: 6| Step: 10
Training loss: 1.1867919115790542
Validation loss: 2.373220871346808

Epoch: 6| Step: 11
Training loss: 1.4874473498347003
Validation loss: 2.435336066148565

Epoch: 6| Step: 12
Training loss: 1.4134106055464617
Validation loss: 2.4138663456788434

Epoch: 6| Step: 13
Training loss: 1.3095186068278748
Validation loss: 2.4248611950895964

Epoch: 550| Step: 0
Training loss: 0.7968093620643643
Validation loss: 2.395219024471169

Epoch: 6| Step: 1
Training loss: 1.361963372901774
Validation loss: 2.4695289600983514

Epoch: 6| Step: 2
Training loss: 2.2853910928672967
Validation loss: 2.477525775202869

Epoch: 6| Step: 3
Training loss: 1.1689435788351283
Validation loss: 2.5093963122771465

Epoch: 6| Step: 4
Training loss: 1.2509849482544853
Validation loss: 2.4878669468940706

Epoch: 6| Step: 5
Training loss: 1.4546023826404424
Validation loss: 2.429406563347538

Epoch: 6| Step: 6
Training loss: 1.316086184024632
Validation loss: 2.508915724936415

Epoch: 6| Step: 7
Training loss: 1.0392217298988906
Validation loss: 2.4431673041994424

Epoch: 6| Step: 8
Training loss: 1.5041590886792515
Validation loss: 2.4255936394039175

Epoch: 6| Step: 9
Training loss: 1.409519717616815
Validation loss: 2.456372607649602

Epoch: 6| Step: 10
Training loss: 1.5500400414986135
Validation loss: 2.430372853910432

Epoch: 6| Step: 11
Training loss: 1.21898795519191
Validation loss: 2.4281640176397423

Epoch: 6| Step: 12
Training loss: 1.3492426284240913
Validation loss: 2.4273113777533606

Epoch: 6| Step: 13
Training loss: 1.021431215846843
Validation loss: 2.4098049156446257

Testing loss: 2.620806412187109
