Epoch: 1| Step: 0
Training loss: 2.4877655506134033
Validation loss: 2.1387625330237934

Epoch: 6| Step: 1
Training loss: 2.7221972942352295
Validation loss: 2.1387101655365317

Epoch: 6| Step: 2
Training loss: 3.0261483192443848
Validation loss: 2.1376214847769788

Epoch: 6| Step: 3
Training loss: 2.458568572998047
Validation loss: 2.139223829392464

Epoch: 6| Step: 4
Training loss: 3.0361576080322266
Validation loss: 2.138962100910884

Epoch: 6| Step: 5
Training loss: 2.589365005493164
Validation loss: 2.137375457312471

Epoch: 6| Step: 6
Training loss: 2.9559507369995117
Validation loss: 2.1388433928130777

Epoch: 6| Step: 7
Training loss: 2.6433491706848145
Validation loss: 2.13741389654016

Epoch: 6| Step: 8
Training loss: 2.0193123817443848
Validation loss: 2.1390706416099303

Epoch: 6| Step: 9
Training loss: 2.6200499534606934
Validation loss: 2.137779571676767

Epoch: 6| Step: 10
Training loss: 2.5869593620300293
Validation loss: 2.138716706665613

Epoch: 6| Step: 11
Training loss: 2.8427438735961914
Validation loss: 2.137293134966204

Epoch: 6| Step: 12
Training loss: 2.466769218444824
Validation loss: 2.13741333253922

Epoch: 6| Step: 13
Training loss: 3.096987724304199
Validation loss: 2.137968260754821

Epoch: 2| Step: 0
Training loss: 2.7363672256469727
Validation loss: 2.137752127903764

Epoch: 6| Step: 1
Training loss: 3.246354103088379
Validation loss: 2.137639541779795

Epoch: 6| Step: 2
Training loss: 2.216886043548584
Validation loss: 2.1372193213432067

Epoch: 6| Step: 3
Training loss: 2.856842041015625
Validation loss: 2.137768422403643

Epoch: 6| Step: 4
Training loss: 2.354297637939453
Validation loss: 2.137949961487965

Epoch: 6| Step: 5
Training loss: 2.8243136405944824
Validation loss: 2.138320376796107

Epoch: 6| Step: 6
Training loss: 3.2876358032226562
Validation loss: 2.135993496064217

Epoch: 6| Step: 7
Training loss: 2.463217258453369
Validation loss: 2.1388132033809537

Epoch: 6| Step: 8
Training loss: 2.5781195163726807
Validation loss: 2.1393171228388304

Epoch: 6| Step: 9
Training loss: 2.7300190925598145
Validation loss: 2.1378931999206543

Epoch: 6| Step: 10
Training loss: 2.6116509437561035
Validation loss: 2.1373151809938493

Epoch: 6| Step: 11
Training loss: 2.945084571838379
Validation loss: 2.1370200521202496

Epoch: 6| Step: 12
Training loss: 2.0717296600341797
Validation loss: 2.1388823088779243

Epoch: 6| Step: 13
Training loss: 2.2306833267211914
Validation loss: 2.1373561043893137

Epoch: 3| Step: 0
Training loss: 2.6787092685699463
Validation loss: 2.1373148682296916

Epoch: 6| Step: 1
Training loss: 2.3397769927978516
Validation loss: 2.1402194269241823

Epoch: 6| Step: 2
Training loss: 2.103358745574951
Validation loss: 2.1366030029071275

Epoch: 6| Step: 3
Training loss: 2.7910871505737305
Validation loss: 2.1374005681724957

Epoch: 6| Step: 4
Training loss: 2.9571144580841064
Validation loss: 2.13774436776356

Epoch: 6| Step: 5
Training loss: 2.751993179321289
Validation loss: 2.138482191229379

Epoch: 6| Step: 6
Training loss: 3.0970022678375244
Validation loss: 2.136563011395034

Epoch: 6| Step: 7
Training loss: 2.6158785820007324
Validation loss: 2.137795004793393

Epoch: 6| Step: 8
Training loss: 3.7809667587280273
Validation loss: 2.1375554223214426

Epoch: 6| Step: 9
Training loss: 2.4767343997955322
Validation loss: 2.1362662930642404

Epoch: 6| Step: 10
Training loss: 1.7828691005706787
Validation loss: 2.137865674111151

Epoch: 6| Step: 11
Training loss: 2.5995805263519287
Validation loss: 2.1368758934800343

Epoch: 6| Step: 12
Training loss: 2.63517427444458
Validation loss: 2.1380104659706034

Epoch: 6| Step: 13
Training loss: 2.7698307037353516
Validation loss: 2.1376635438652447

Epoch: 4| Step: 0
Training loss: 2.3927974700927734
Validation loss: 2.136039146813013

Epoch: 6| Step: 1
Training loss: 2.248755931854248
Validation loss: 2.135630538386683

Epoch: 6| Step: 2
Training loss: 2.0834383964538574
Validation loss: 2.136477090979135

Epoch: 6| Step: 3
Training loss: 2.796405076980591
Validation loss: 2.1368104386073288

Epoch: 6| Step: 4
Training loss: 3.045675039291382
Validation loss: 2.1364506034440893

Epoch: 6| Step: 5
Training loss: 2.3568146228790283
Validation loss: 2.1363758220467517

Epoch: 6| Step: 6
Training loss: 3.0650312900543213
Validation loss: 2.1388045241755824

Epoch: 6| Step: 7
Training loss: 2.8392622470855713
Validation loss: 2.135750519332065

Epoch: 6| Step: 8
Training loss: 3.14436936378479
Validation loss: 2.137492487507482

Epoch: 6| Step: 9
Training loss: 2.904157876968384
Validation loss: 2.1378043313180246

Epoch: 6| Step: 10
Training loss: 2.502631902694702
Validation loss: 2.1373716426152054

Epoch: 6| Step: 11
Training loss: 2.483907461166382
Validation loss: 2.137040691991006

Epoch: 6| Step: 12
Training loss: 2.979372024536133
Validation loss: 2.1363653290656304

Epoch: 6| Step: 13
Training loss: 2.3006694316864014
Validation loss: 2.137349021050238

Epoch: 5| Step: 0
Training loss: 2.460236072540283
Validation loss: 2.136370453783261

Epoch: 6| Step: 1
Training loss: 2.2945566177368164
Validation loss: 2.135701851178241

Epoch: 6| Step: 2
Training loss: 3.078545331954956
Validation loss: 2.1356545417539534

Epoch: 6| Step: 3
Training loss: 2.456834077835083
Validation loss: 2.1363405232788413

Epoch: 6| Step: 4
Training loss: 2.2888474464416504
Validation loss: 2.136039556995515

Epoch: 6| Step: 5
Training loss: 3.236074447631836
Validation loss: 2.1342246814440657

Epoch: 6| Step: 6
Training loss: 2.6093478202819824
Validation loss: 2.1362780396656325

Epoch: 6| Step: 7
Training loss: 3.122498035430908
Validation loss: 2.137021372395177

Epoch: 6| Step: 8
Training loss: 2.3865835666656494
Validation loss: 2.1346756771046627

Epoch: 6| Step: 9
Training loss: 2.775388240814209
Validation loss: 2.1360226036399923

Epoch: 6| Step: 10
Training loss: 3.6089320182800293
Validation loss: 2.1348406371249946

Epoch: 6| Step: 11
Training loss: 2.058542490005493
Validation loss: 2.135293209424583

Epoch: 6| Step: 12
Training loss: 2.1711864471435547
Validation loss: 2.135724359943021

Epoch: 6| Step: 13
Training loss: 2.8003218173980713
Validation loss: 2.135511995643698

Epoch: 6| Step: 0
Training loss: 2.7800793647766113
Validation loss: 2.1374769954271216

Epoch: 6| Step: 1
Training loss: 2.2424023151397705
Validation loss: 2.1345694347094466

Epoch: 6| Step: 2
Training loss: 2.446855068206787
Validation loss: 2.134209435473206

Epoch: 6| Step: 3
Training loss: 2.438528060913086
Validation loss: 2.136223919929997

Epoch: 6| Step: 4
Training loss: 2.298892021179199
Validation loss: 2.135313110966836

Epoch: 6| Step: 5
Training loss: 3.106250524520874
Validation loss: 2.1358200555206626

Epoch: 6| Step: 6
Training loss: 2.9639523029327393
Validation loss: 2.13583287372384

Epoch: 6| Step: 7
Training loss: 2.4148941040039062
Validation loss: 2.1353843571037374

Epoch: 6| Step: 8
Training loss: 2.928366184234619
Validation loss: 2.1340956277744745

Epoch: 6| Step: 9
Training loss: 2.6064000129699707
Validation loss: 2.1344021956125894

Epoch: 6| Step: 10
Training loss: 2.776060104370117
Validation loss: 2.134852167098753

Epoch: 6| Step: 11
Training loss: 2.761925220489502
Validation loss: 2.1347417959602932

Epoch: 6| Step: 12
Training loss: 2.4224038124084473
Validation loss: 2.135055554810391

Epoch: 6| Step: 13
Training loss: 3.410736083984375
Validation loss: 2.1358957341922227

Epoch: 7| Step: 0
Training loss: 2.5847785472869873
Validation loss: 2.1347985767549083

Epoch: 6| Step: 1
Training loss: 2.7929868698120117
Validation loss: 2.1344518135952693

Epoch: 6| Step: 2
Training loss: 2.846071243286133
Validation loss: 2.1361161124321724

Epoch: 6| Step: 3
Training loss: 2.7902169227600098
Validation loss: 2.134902725937546

Epoch: 6| Step: 4
Training loss: 2.8003218173980713
Validation loss: 2.1345684669351064

Epoch: 6| Step: 5
Training loss: 2.4103071689605713
Validation loss: 2.133286633799153

Epoch: 6| Step: 6
Training loss: 2.9986324310302734
Validation loss: 2.1359984515815653

Epoch: 6| Step: 7
Training loss: 2.393352508544922
Validation loss: 2.134493604783089

Epoch: 6| Step: 8
Training loss: 2.2206153869628906
Validation loss: 2.134790235950101

Epoch: 6| Step: 9
Training loss: 2.469512701034546
Validation loss: 2.1346751823220202

Epoch: 6| Step: 10
Training loss: 2.5971553325653076
Validation loss: 2.133903721327423

Epoch: 6| Step: 11
Training loss: 2.8308849334716797
Validation loss: 2.1352496608611076

Epoch: 6| Step: 12
Training loss: 2.5423848628997803
Validation loss: 2.1349727748542704

Epoch: 6| Step: 13
Training loss: 3.2221152782440186
Validation loss: 2.1349607590706117

Epoch: 8| Step: 0
Training loss: 2.508439064025879
Validation loss: 2.13572120922868

Epoch: 6| Step: 1
Training loss: 2.308770179748535
Validation loss: 2.1348989599494526

Epoch: 6| Step: 2
Training loss: 2.525777816772461
Validation loss: 2.1348330000395417

Epoch: 6| Step: 3
Training loss: 2.598133087158203
Validation loss: 2.1338036406424736

Epoch: 6| Step: 4
Training loss: 2.883863925933838
Validation loss: 2.13446964756135

Epoch: 6| Step: 5
Training loss: 2.5472307205200195
Validation loss: 2.1344180645481234

Epoch: 6| Step: 6
Training loss: 2.3956027030944824
Validation loss: 2.1333189036256526

Epoch: 6| Step: 7
Training loss: 2.211193084716797
Validation loss: 2.1337988043344147

Epoch: 6| Step: 8
Training loss: 3.15995717048645
Validation loss: 2.133441868648734

Epoch: 6| Step: 9
Training loss: 2.428008794784546
Validation loss: 2.134647415530297

Epoch: 6| Step: 10
Training loss: 2.6160728931427
Validation loss: 2.1344234110206686

Epoch: 6| Step: 11
Training loss: 3.108776092529297
Validation loss: 2.1343667173898346

Epoch: 6| Step: 12
Training loss: 3.0338125228881836
Validation loss: 2.1357370217641196

Epoch: 6| Step: 13
Training loss: 3.085148811340332
Validation loss: 2.1340758236505653

Epoch: 9| Step: 0
Training loss: 2.8121466636657715
Validation loss: 2.1340809893864456

Epoch: 6| Step: 1
Training loss: 2.5911200046539307
Validation loss: 2.134439014619397

Epoch: 6| Step: 2
Training loss: 2.666368007659912
Validation loss: 2.134470796072355

Epoch: 6| Step: 3
Training loss: 2.6630640029907227
Validation loss: 2.1327172120412192

Epoch: 6| Step: 4
Training loss: 2.744934558868408
Validation loss: 2.1323322570452126

Epoch: 6| Step: 5
Training loss: 2.3708581924438477
Validation loss: 2.133847180233207

Epoch: 6| Step: 6
Training loss: 2.7372477054595947
Validation loss: 2.1324134513896

Epoch: 6| Step: 7
Training loss: 2.272317886352539
Validation loss: 2.1344061577191917

Epoch: 6| Step: 8
Training loss: 2.717985153198242
Validation loss: 2.133308582408454

Epoch: 6| Step: 9
Training loss: 2.545788526535034
Validation loss: 2.133951211488375

Epoch: 6| Step: 10
Training loss: 2.8820061683654785
Validation loss: 2.1323002717828237

Epoch: 6| Step: 11
Training loss: 2.7047009468078613
Validation loss: 2.1331194241841636

Epoch: 6| Step: 12
Training loss: 2.843557834625244
Validation loss: 2.132603919634255

Epoch: 6| Step: 13
Training loss: 2.6474504470825195
Validation loss: 2.133326791947888

Epoch: 10| Step: 0
Training loss: 2.5745034217834473
Validation loss: 2.133548116171232

Epoch: 6| Step: 1
Training loss: 3.6363651752471924
Validation loss: 2.1332794658599363

Epoch: 6| Step: 2
Training loss: 2.8776438236236572
Validation loss: 2.134597591174546

Epoch: 6| Step: 3
Training loss: 2.4441518783569336
Validation loss: 2.133412012489893

Epoch: 6| Step: 4
Training loss: 2.4756526947021484
Validation loss: 2.1320180239215976

Epoch: 6| Step: 5
Training loss: 2.4856977462768555
Validation loss: 2.1343170647980063

Epoch: 6| Step: 6
Training loss: 2.1779379844665527
Validation loss: 2.132309300925142

Epoch: 6| Step: 7
Training loss: 3.2407217025756836
Validation loss: 2.1330232004965506

Epoch: 6| Step: 8
Training loss: 2.0981838703155518
Validation loss: 2.132007768077235

Epoch: 6| Step: 9
Training loss: 2.7325873374938965
Validation loss: 2.133302265597928

Epoch: 6| Step: 10
Training loss: 2.781510829925537
Validation loss: 2.133306295641007

Epoch: 6| Step: 11
Training loss: 2.560948371887207
Validation loss: 2.134264426846658

Epoch: 6| Step: 12
Training loss: 2.532926559448242
Validation loss: 2.132709131445936

Epoch: 6| Step: 13
Training loss: 2.4964065551757812
Validation loss: 2.1325263387413433

Epoch: 11| Step: 0
Training loss: 2.6176679134368896
Validation loss: 2.1319363219763643

Epoch: 6| Step: 1
Training loss: 2.7732534408569336
Validation loss: 2.1326809519080707

Epoch: 6| Step: 2
Training loss: 2.484752893447876
Validation loss: 2.1326323401543403

Epoch: 6| Step: 3
Training loss: 2.9523398876190186
Validation loss: 2.131765083600116

Epoch: 6| Step: 4
Training loss: 2.6539626121520996
Validation loss: 2.13234943215565

Epoch: 6| Step: 5
Training loss: 2.7145802974700928
Validation loss: 2.1330527259457495

Epoch: 6| Step: 6
Training loss: 2.1195924282073975
Validation loss: 2.1312076276348484

Epoch: 6| Step: 7
Training loss: 2.5291244983673096
Validation loss: 2.1305640974352436

Epoch: 6| Step: 8
Training loss: 2.7460672855377197
Validation loss: 2.133442117321876

Epoch: 6| Step: 9
Training loss: 2.271817207336426
Validation loss: 2.1316142159123577

Epoch: 6| Step: 10
Training loss: 2.478630542755127
Validation loss: 2.1320172227838987

Epoch: 6| Step: 11
Training loss: 3.355193853378296
Validation loss: 2.1335528922337357

Epoch: 6| Step: 12
Training loss: 3.209503173828125
Validation loss: 2.132468767063592

Epoch: 6| Step: 13
Training loss: 1.962425708770752
Validation loss: 2.1304651460339947

Epoch: 12| Step: 0
Training loss: 2.5081214904785156
Validation loss: 2.132407901107624

Epoch: 6| Step: 1
Training loss: 3.054938316345215
Validation loss: 2.1344566345214844

Epoch: 6| Step: 2
Training loss: 2.759455919265747
Validation loss: 2.1321507397518364

Epoch: 6| Step: 3
Training loss: 3.004047393798828
Validation loss: 2.131659428278605

Epoch: 6| Step: 4
Training loss: 2.491811752319336
Validation loss: 2.1323711487554733

Epoch: 6| Step: 5
Training loss: 3.0826640129089355
Validation loss: 2.130929531589631

Epoch: 6| Step: 6
Training loss: 2.280122995376587
Validation loss: 2.131319304948212

Epoch: 6| Step: 7
Training loss: 2.9908924102783203
Validation loss: 2.1311816130914996

Epoch: 6| Step: 8
Training loss: 1.7957221269607544
Validation loss: 2.1311845689691524

Epoch: 6| Step: 9
Training loss: 2.5505762100219727
Validation loss: 2.129944598802956

Epoch: 6| Step: 10
Training loss: 2.0601882934570312
Validation loss: 2.132724554307999

Epoch: 6| Step: 11
Training loss: 2.670119524002075
Validation loss: 2.131331753987138

Epoch: 6| Step: 12
Training loss: 2.7302632331848145
Validation loss: 2.131533299722979

Epoch: 6| Step: 13
Training loss: 3.540419101715088
Validation loss: 2.131191930463237

Epoch: 13| Step: 0
Training loss: 2.0519859790802
Validation loss: 2.1323805816711916

Epoch: 6| Step: 1
Training loss: 2.6685502529144287
Validation loss: 2.1308186438775834

Epoch: 6| Step: 2
Training loss: 2.6834144592285156
Validation loss: 2.1308861470991567

Epoch: 6| Step: 3
Training loss: 2.800489902496338
Validation loss: 2.130526127353791

Epoch: 6| Step: 4
Training loss: 2.6359853744506836
Validation loss: 2.1296762343375915

Epoch: 6| Step: 5
Training loss: 2.804334878921509
Validation loss: 2.1309262655114614

Epoch: 6| Step: 6
Training loss: 3.0312438011169434
Validation loss: 2.1312853700371197

Epoch: 6| Step: 7
Training loss: 2.0584983825683594
Validation loss: 2.130642714038972

Epoch: 6| Step: 8
Training loss: 2.801326274871826
Validation loss: 2.132058838362335

Epoch: 6| Step: 9
Training loss: 3.3817849159240723
Validation loss: 2.129081754274266

Epoch: 6| Step: 10
Training loss: 2.426185369491577
Validation loss: 2.1333464525079213

Epoch: 6| Step: 11
Training loss: 2.908379077911377
Validation loss: 2.130906730569819

Epoch: 6| Step: 12
Training loss: 2.395512819290161
Validation loss: 2.1313383912527435

Epoch: 6| Step: 13
Training loss: 2.3077495098114014
Validation loss: 2.1305832862854004

Epoch: 14| Step: 0
Training loss: 2.9844131469726562
Validation loss: 2.1317275826649

Epoch: 6| Step: 1
Training loss: 2.8212151527404785
Validation loss: 2.1312897166898175

Epoch: 6| Step: 2
Training loss: 2.594146728515625
Validation loss: 2.130141258239746

Epoch: 6| Step: 3
Training loss: 2.547738790512085
Validation loss: 2.1282761327682005

Epoch: 6| Step: 4
Training loss: 2.390984058380127
Validation loss: 2.1303681993997223

Epoch: 6| Step: 5
Training loss: 2.361844062805176
Validation loss: 2.129188055633217

Epoch: 6| Step: 6
Training loss: 2.011406898498535
Validation loss: 2.1296607114935435

Epoch: 6| Step: 7
Training loss: 2.9679598808288574
Validation loss: 2.131113047240883

Epoch: 6| Step: 8
Training loss: 2.5667622089385986
Validation loss: 2.1300232948795443

Epoch: 6| Step: 9
Training loss: 2.980546474456787
Validation loss: 2.1310480281870854

Epoch: 6| Step: 10
Training loss: 2.64668607711792
Validation loss: 2.128163804290115

Epoch: 6| Step: 11
Training loss: 3.044466495513916
Validation loss: 2.1294830845248316

Epoch: 6| Step: 12
Training loss: 2.5750346183776855
Validation loss: 2.1278626764974287

Epoch: 6| Step: 13
Training loss: 2.536391258239746
Validation loss: 2.1295020964837845

Epoch: 15| Step: 0
Training loss: 3.083780527114868
Validation loss: 2.130990997437508

Epoch: 6| Step: 1
Training loss: 3.1846680641174316
Validation loss: 2.1302498002206125

Epoch: 6| Step: 2
Training loss: 2.192018508911133
Validation loss: 2.130327178585914

Epoch: 6| Step: 3
Training loss: 2.717891216278076
Validation loss: 2.130732277388214

Epoch: 6| Step: 4
Training loss: 3.0863561630249023
Validation loss: 2.129349313756471

Epoch: 6| Step: 5
Training loss: 2.674135208129883
Validation loss: 2.129771868387858

Epoch: 6| Step: 6
Training loss: 2.5881052017211914
Validation loss: 2.1280697596970426

Epoch: 6| Step: 7
Training loss: 2.549057960510254
Validation loss: 2.1305200130708757

Epoch: 6| Step: 8
Training loss: 2.7810113430023193
Validation loss: 2.1291131511811288

Epoch: 6| Step: 9
Training loss: 3.106660842895508
Validation loss: 2.131533340741229

Epoch: 6| Step: 10
Training loss: 2.4203884601593018
Validation loss: 2.1309466669636388

Epoch: 6| Step: 11
Training loss: 2.6572136878967285
Validation loss: 2.1269010882223807

Epoch: 6| Step: 12
Training loss: 1.7357237339019775
Validation loss: 2.1317453820218324

Epoch: 6| Step: 13
Training loss: 2.0333125591278076
Validation loss: 2.1282972879307245

Epoch: 16| Step: 0
Training loss: 2.34409236907959
Validation loss: 2.1304457867017357

Epoch: 6| Step: 1
Training loss: 2.287238121032715
Validation loss: 2.1298506747009935

Epoch: 6| Step: 2
Training loss: 2.7556777000427246
Validation loss: 2.1277364659053024

Epoch: 6| Step: 3
Training loss: 2.935850143432617
Validation loss: 2.1295529796231176

Epoch: 6| Step: 4
Training loss: 2.369727611541748
Validation loss: 2.1292033105768184

Epoch: 6| Step: 5
Training loss: 3.5090887546539307
Validation loss: 2.1305499897208264

Epoch: 6| Step: 6
Training loss: 3.117537260055542
Validation loss: 2.1310964733041744

Epoch: 6| Step: 7
Training loss: 2.014331817626953
Validation loss: 2.1283080949578235

Epoch: 6| Step: 8
Training loss: 3.3904623985290527
Validation loss: 2.129225879587153

Epoch: 6| Step: 9
Training loss: 2.355363368988037
Validation loss: 2.1302504308762087

Epoch: 6| Step: 10
Training loss: 2.0073323249816895
Validation loss: 2.12644628811908

Epoch: 6| Step: 11
Training loss: 2.3247647285461426
Validation loss: 2.127020074475196

Epoch: 6| Step: 12
Training loss: 2.9458694458007812
Validation loss: 2.1291591223850044

Epoch: 6| Step: 13
Training loss: 2.7193262577056885
Validation loss: 2.129100985424493

Epoch: 17| Step: 0
Training loss: 2.3663363456726074
Validation loss: 2.1311420343255483

Epoch: 6| Step: 1
Training loss: 2.4510498046875
Validation loss: 2.131206040741295

Epoch: 6| Step: 2
Training loss: 2.991787910461426
Validation loss: 2.12685461454494

Epoch: 6| Step: 3
Training loss: 3.360356569290161
Validation loss: 2.130318965963138

Epoch: 6| Step: 4
Training loss: 2.593848705291748
Validation loss: 2.1303505974431194

Epoch: 6| Step: 5
Training loss: 2.645397901535034
Validation loss: 2.1288712204143567

Epoch: 6| Step: 6
Training loss: 2.8219504356384277
Validation loss: 2.129627513629134

Epoch: 6| Step: 7
Training loss: 1.8075767755508423
Validation loss: 2.1282024550181564

Epoch: 6| Step: 8
Training loss: 2.288076639175415
Validation loss: 2.1298708659346386

Epoch: 6| Step: 9
Training loss: 2.410151481628418
Validation loss: 2.130102970266855

Epoch: 6| Step: 10
Training loss: 3.008453130722046
Validation loss: 2.127692955796437

Epoch: 6| Step: 11
Training loss: 2.6923561096191406
Validation loss: 2.128627518171905

Epoch: 6| Step: 12
Training loss: 2.474686861038208
Validation loss: 2.1296466781247045

Epoch: 6| Step: 13
Training loss: 3.4450817108154297
Validation loss: 2.1289739275491364

Epoch: 18| Step: 0
Training loss: 2.265285015106201
Validation loss: 2.128685066776891

Epoch: 6| Step: 1
Training loss: 3.0637311935424805
Validation loss: 2.127122299645537

Epoch: 6| Step: 2
Training loss: 2.6872639656066895
Validation loss: 2.1277377220892135

Epoch: 6| Step: 3
Training loss: 2.7807016372680664
Validation loss: 2.128108903925906

Epoch: 6| Step: 4
Training loss: 2.771000385284424
Validation loss: 2.12906293202472

Epoch: 6| Step: 5
Training loss: 3.1984755992889404
Validation loss: 2.1284249226252236

Epoch: 6| Step: 6
Training loss: 2.123995780944824
Validation loss: 2.1275720673222698

Epoch: 6| Step: 7
Training loss: 2.8253285884857178
Validation loss: 2.1291390772788756

Epoch: 6| Step: 8
Training loss: 2.38671612739563
Validation loss: 2.1283393265098653

Epoch: 6| Step: 9
Training loss: 2.225996971130371
Validation loss: 2.1299187342325845

Epoch: 6| Step: 10
Training loss: 2.339433193206787
Validation loss: 2.127856416086997

Epoch: 6| Step: 11
Training loss: 3.1901919841766357
Validation loss: 2.12757836234185

Epoch: 6| Step: 12
Training loss: 2.741865634918213
Validation loss: 2.127925386992834

Epoch: 6| Step: 13
Training loss: 2.1974751949310303
Validation loss: 2.1276490713960383

Epoch: 19| Step: 0
Training loss: 2.5506482124328613
Validation loss: 2.1299845018694477

Epoch: 6| Step: 1
Training loss: 1.7879226207733154
Validation loss: 2.1280487621984174

Epoch: 6| Step: 2
Training loss: 2.044334888458252
Validation loss: 2.1274571085488923

Epoch: 6| Step: 3
Training loss: 2.9207396507263184
Validation loss: 2.127533233293923

Epoch: 6| Step: 4
Training loss: 2.2414913177490234
Validation loss: 2.127894619459747

Epoch: 6| Step: 5
Training loss: 2.3314805030822754
Validation loss: 2.1281653424744964

Epoch: 6| Step: 6
Training loss: 3.3719935417175293
Validation loss: 2.1282449588980725

Epoch: 6| Step: 7
Training loss: 3.0456082820892334
Validation loss: 2.128255374969975

Epoch: 6| Step: 8
Training loss: 2.292713165283203
Validation loss: 2.1274203446603592

Epoch: 6| Step: 9
Training loss: 2.6185779571533203
Validation loss: 2.126618525033356

Epoch: 6| Step: 10
Training loss: 2.8725366592407227
Validation loss: 2.1283227807732037

Epoch: 6| Step: 11
Training loss: 3.212952136993408
Validation loss: 2.12795849000254

Epoch: 6| Step: 12
Training loss: 2.6919760704040527
Validation loss: 2.125084702686597

Epoch: 6| Step: 13
Training loss: 3.2539286613464355
Validation loss: 2.1273612078799995

Epoch: 20| Step: 0
Training loss: 2.9063425064086914
Validation loss: 2.1272050616561726

Epoch: 6| Step: 1
Training loss: 2.2531676292419434
Validation loss: 2.12689644546919

Epoch: 6| Step: 2
Training loss: 2.693756580352783
Validation loss: 2.1250779603117254

Epoch: 6| Step: 3
Training loss: 2.703854560852051
Validation loss: 2.1281165384477183

Epoch: 6| Step: 4
Training loss: 3.1052422523498535
Validation loss: 2.1254482653833207

Epoch: 6| Step: 5
Training loss: 2.299266815185547
Validation loss: 2.128065022089148

Epoch: 6| Step: 6
Training loss: 3.11063814163208
Validation loss: 2.1280373142611597

Epoch: 6| Step: 7
Training loss: 2.410808563232422
Validation loss: 2.1293178860859205

Epoch: 6| Step: 8
Training loss: 2.527674674987793
Validation loss: 2.1244596614632556

Epoch: 6| Step: 9
Training loss: 3.004754066467285
Validation loss: 2.127425327095934

Epoch: 6| Step: 10
Training loss: 3.2157320976257324
Validation loss: 2.125413243488599

Epoch: 6| Step: 11
Training loss: 2.2863717079162598
Validation loss: 2.125307201057352

Epoch: 6| Step: 12
Training loss: 2.122887134552002
Validation loss: 2.124537529483918

Epoch: 6| Step: 13
Training loss: 1.9851621389389038
Validation loss: 2.1257226492768977

Epoch: 21| Step: 0
Training loss: 2.501649856567383
Validation loss: 2.1265193826408795

Epoch: 6| Step: 1
Training loss: 3.0604467391967773
Validation loss: 2.1266469070988316

Epoch: 6| Step: 2
Training loss: 2.5923495292663574
Validation loss: 2.125688497738172

Epoch: 6| Step: 3
Training loss: 2.476179361343384
Validation loss: 2.125141159180672

Epoch: 6| Step: 4
Training loss: 2.493007183074951
Validation loss: 2.1267512665000012

Epoch: 6| Step: 5
Training loss: 2.2433969974517822
Validation loss: 2.1264827225797918

Epoch: 6| Step: 6
Training loss: 2.3922712802886963
Validation loss: 2.124149545546501

Epoch: 6| Step: 7
Training loss: 3.100409984588623
Validation loss: 2.1256120922744914

Epoch: 6| Step: 8
Training loss: 3.168982982635498
Validation loss: 2.1257537795651342

Epoch: 6| Step: 9
Training loss: 1.844865322113037
Validation loss: 2.1261234052719606

Epoch: 6| Step: 10
Training loss: 2.9616355895996094
Validation loss: 2.1280846493218535

Epoch: 6| Step: 11
Training loss: 2.1944291591644287
Validation loss: 2.1265589267976823

Epoch: 6| Step: 12
Training loss: 3.039113998413086
Validation loss: 2.1243379500604447

Epoch: 6| Step: 13
Training loss: 2.9818310737609863
Validation loss: 2.1265221000999532

Epoch: 22| Step: 0
Training loss: 2.6047258377075195
Validation loss: 2.12685203295882

Epoch: 6| Step: 1
Training loss: 2.3615498542785645
Validation loss: 2.125520803595102

Epoch: 6| Step: 2
Training loss: 3.130397081375122
Validation loss: 2.1275685371891147

Epoch: 6| Step: 3
Training loss: 1.8873393535614014
Validation loss: 2.129084158969182

Epoch: 6| Step: 4
Training loss: 3.1045312881469727
Validation loss: 2.1262839314758137

Epoch: 6| Step: 5
Training loss: 3.3561439514160156
Validation loss: 2.125675309088922

Epoch: 6| Step: 6
Training loss: 2.4263100624084473
Validation loss: 2.1271142844230897

Epoch: 6| Step: 7
Training loss: 2.154175281524658
Validation loss: 2.1280775762373403

Epoch: 6| Step: 8
Training loss: 2.1757760047912598
Validation loss: 2.126617221422093

Epoch: 6| Step: 9
Training loss: 2.7548134326934814
Validation loss: 2.124915166567731

Epoch: 6| Step: 10
Training loss: 2.3875200748443604
Validation loss: 2.1247116160649124

Epoch: 6| Step: 11
Training loss: 2.8124618530273438
Validation loss: 2.1272421549725276

Epoch: 6| Step: 12
Training loss: 3.062671422958374
Validation loss: 2.126008492644115

Epoch: 6| Step: 13
Training loss: 2.6710422039031982
Validation loss: 2.1255583660576933

Epoch: 23| Step: 0
Training loss: 2.709827423095703
Validation loss: 2.1277991251278947

Epoch: 6| Step: 1
Training loss: 2.905045986175537
Validation loss: 2.128228223452004

Epoch: 6| Step: 2
Training loss: 2.3218584060668945
Validation loss: 2.124782536619453

Epoch: 6| Step: 3
Training loss: 2.793715238571167
Validation loss: 2.1263381204297467

Epoch: 6| Step: 4
Training loss: 2.3154544830322266
Validation loss: 2.127612139589043

Epoch: 6| Step: 5
Training loss: 2.6379518508911133
Validation loss: 2.1245314344283073

Epoch: 6| Step: 6
Training loss: 3.4434409141540527
Validation loss: 2.12574904195724

Epoch: 6| Step: 7
Training loss: 2.174816608428955
Validation loss: 2.1229464905236357

Epoch: 6| Step: 8
Training loss: 2.147566795349121
Validation loss: 2.127142983098184

Epoch: 6| Step: 9
Training loss: 1.7979369163513184
Validation loss: 2.1251987975130797

Epoch: 6| Step: 10
Training loss: 3.3411622047424316
Validation loss: 2.1248943498057704

Epoch: 6| Step: 11
Training loss: 2.495906114578247
Validation loss: 2.1242340649327924

Epoch: 6| Step: 12
Training loss: 2.5049710273742676
Validation loss: 2.1241638250248407

Epoch: 6| Step: 13
Training loss: 3.7105026245117188
Validation loss: 2.122325324243115

Epoch: 24| Step: 0
Training loss: 2.6146960258483887
Validation loss: 2.1246894559552594

Epoch: 6| Step: 1
Training loss: 3.190490245819092
Validation loss: 2.122134231751965

Epoch: 6| Step: 2
Training loss: 2.493201732635498
Validation loss: 2.125457658562609

Epoch: 6| Step: 3
Training loss: 2.7632553577423096
Validation loss: 2.125851341473159

Epoch: 6| Step: 4
Training loss: 3.102358818054199
Validation loss: 2.1253752836617092

Epoch: 6| Step: 5
Training loss: 2.185241937637329
Validation loss: 2.126264887471353

Epoch: 6| Step: 6
Training loss: 2.9564802646636963
Validation loss: 2.1269305688078686

Epoch: 6| Step: 7
Training loss: 1.9050683975219727
Validation loss: 2.12433684256769

Epoch: 6| Step: 8
Training loss: 2.6822996139526367
Validation loss: 2.125988721847534

Epoch: 6| Step: 9
Training loss: 2.159233570098877
Validation loss: 2.1262098935342606

Epoch: 6| Step: 10
Training loss: 2.7337265014648438
Validation loss: 2.124714784724738

Epoch: 6| Step: 11
Training loss: 2.4622411727905273
Validation loss: 2.1253627436135405

Epoch: 6| Step: 12
Training loss: 3.246232032775879
Validation loss: 2.126868942732452

Epoch: 6| Step: 13
Training loss: 2.065641403198242
Validation loss: 2.122739371433053

Epoch: 25| Step: 0
Training loss: 2.9513254165649414
Validation loss: 2.1251585868097123

Epoch: 6| Step: 1
Training loss: 2.477060317993164
Validation loss: 2.1265008936646166

Epoch: 6| Step: 2
Training loss: 2.1353464126586914
Validation loss: 2.1232532711439234

Epoch: 6| Step: 3
Training loss: 2.4383606910705566
Validation loss: 2.1252189784921627

Epoch: 6| Step: 4
Training loss: 2.9180402755737305
Validation loss: 2.124894466451419

Epoch: 6| Step: 5
Training loss: 2.3875226974487305
Validation loss: 2.1242868297843525

Epoch: 6| Step: 6
Training loss: 2.9229795932769775
Validation loss: 2.1223461192141295

Epoch: 6| Step: 7
Training loss: 3.2180404663085938
Validation loss: 2.126502867667906

Epoch: 6| Step: 8
Training loss: 3.3269577026367188
Validation loss: 2.1245052006936844

Epoch: 6| Step: 9
Training loss: 2.0844976902008057
Validation loss: 2.1238114192921627

Epoch: 6| Step: 10
Training loss: 2.7359237670898438
Validation loss: 2.1268499564099055

Epoch: 6| Step: 11
Training loss: 2.528773784637451
Validation loss: 2.1266298755522697

Epoch: 6| Step: 12
Training loss: 2.2367746829986572
Validation loss: 2.1267469595837336

Epoch: 6| Step: 13
Training loss: 2.273249626159668
Validation loss: 2.121601971246863

Epoch: 26| Step: 0
Training loss: 3.0911383628845215
Validation loss: 2.1202078916693248

Epoch: 6| Step: 1
Training loss: 2.2833445072174072
Validation loss: 2.124166747575165

Epoch: 6| Step: 2
Training loss: 2.293686866760254
Validation loss: 2.124940279991396

Epoch: 6| Step: 3
Training loss: 2.634708881378174
Validation loss: 2.1195705398436515

Epoch: 6| Step: 4
Training loss: 2.15940523147583
Validation loss: 2.1220529374255928

Epoch: 6| Step: 5
Training loss: 2.877045154571533
Validation loss: 2.123750641781797

Epoch: 6| Step: 6
Training loss: 2.8486461639404297
Validation loss: 2.1233110453492854

Epoch: 6| Step: 7
Training loss: 2.523766279220581
Validation loss: 2.124878465488393

Epoch: 6| Step: 8
Training loss: 2.834003448486328
Validation loss: 2.1236201204279417

Epoch: 6| Step: 9
Training loss: 2.5317845344543457
Validation loss: 2.123758905677385

Epoch: 6| Step: 10
Training loss: 1.9434545040130615
Validation loss: 2.1202895000416744

Epoch: 6| Step: 11
Training loss: 3.1571364402770996
Validation loss: 2.1256043962253037

Epoch: 6| Step: 12
Training loss: 2.6828742027282715
Validation loss: 2.1241195919693157

Epoch: 6| Step: 13
Training loss: 3.1052277088165283
Validation loss: 2.125023973885403

Epoch: 27| Step: 0
Training loss: 2.9193918704986572
Validation loss: 2.1227573861357985

Epoch: 6| Step: 1
Training loss: 2.3760247230529785
Validation loss: 2.1245305730450537

Epoch: 6| Step: 2
Training loss: 2.2329165935516357
Validation loss: 2.1226432990002375

Epoch: 6| Step: 3
Training loss: 2.7515110969543457
Validation loss: 2.122580953823623

Epoch: 6| Step: 4
Training loss: 2.284165382385254
Validation loss: 2.11913162918501

Epoch: 6| Step: 5
Training loss: 3.466526508331299
Validation loss: 2.122736361718947

Epoch: 6| Step: 6
Training loss: 2.8611769676208496
Validation loss: 2.121597461802985

Epoch: 6| Step: 7
Training loss: 2.8531575202941895
Validation loss: 2.122001478748937

Epoch: 6| Step: 8
Training loss: 2.5246169567108154
Validation loss: 2.122850433472664

Epoch: 6| Step: 9
Training loss: 2.4875288009643555
Validation loss: 2.1235790637231644

Epoch: 6| Step: 10
Training loss: 1.870937705039978
Validation loss: 2.1241533243527977

Epoch: 6| Step: 11
Training loss: 2.232919692993164
Validation loss: 2.1202684422974944

Epoch: 6| Step: 12
Training loss: 3.099501132965088
Validation loss: 2.121582459377986

Epoch: 6| Step: 13
Training loss: 2.831136465072632
Validation loss: 2.1219327885617494

Epoch: 28| Step: 0
Training loss: 2.7280304431915283
Validation loss: 2.1234544054154427

Epoch: 6| Step: 1
Training loss: 2.35178279876709
Validation loss: 2.1253246658591816

Epoch: 6| Step: 2
Training loss: 2.70234751701355
Validation loss: 2.1212737150089715

Epoch: 6| Step: 3
Training loss: 2.4305777549743652
Validation loss: 2.1194036186382337

Epoch: 6| Step: 4
Training loss: 2.5025596618652344
Validation loss: 2.122914369388293

Epoch: 6| Step: 5
Training loss: 3.022658109664917
Validation loss: 2.1218873018859536

Epoch: 6| Step: 6
Training loss: 1.970457911491394
Validation loss: 2.122571619608069

Epoch: 6| Step: 7
Training loss: 2.5671465396881104
Validation loss: 2.123153514759515

Epoch: 6| Step: 8
Training loss: 2.6610701084136963
Validation loss: 2.121625643904491

Epoch: 6| Step: 9
Training loss: 2.8537304401397705
Validation loss: 2.1197120553703717

Epoch: 6| Step: 10
Training loss: 2.807624340057373
Validation loss: 2.121947473095309

Epoch: 6| Step: 11
Training loss: 2.6645896434783936
Validation loss: 2.1210647911153813

Epoch: 6| Step: 12
Training loss: 2.2795026302337646
Validation loss: 2.1227526434006228

Epoch: 6| Step: 13
Training loss: 3.497481107711792
Validation loss: 2.118425505135649

Epoch: 29| Step: 0
Training loss: 3.026827335357666
Validation loss: 2.124267050015029

Epoch: 6| Step: 1
Training loss: 2.420255422592163
Validation loss: 2.1190816099925707

Epoch: 6| Step: 2
Training loss: 2.464236259460449
Validation loss: 2.1213699156238186

Epoch: 6| Step: 3
Training loss: 2.6856250762939453
Validation loss: 2.123965363348684

Epoch: 6| Step: 4
Training loss: 2.5547080039978027
Validation loss: 2.1214336285027127

Epoch: 6| Step: 5
Training loss: 2.343836784362793
Validation loss: 2.1215731661806823

Epoch: 6| Step: 6
Training loss: 2.577810287475586
Validation loss: 2.1192667727829306

Epoch: 6| Step: 7
Training loss: 3.0445547103881836
Validation loss: 2.1219557562182025

Epoch: 6| Step: 8
Training loss: 2.6659791469573975
Validation loss: 2.119722866242932

Epoch: 6| Step: 9
Training loss: 2.4436397552490234
Validation loss: 2.120806783758184

Epoch: 6| Step: 10
Training loss: 3.063622236251831
Validation loss: 2.122367892214047

Epoch: 6| Step: 11
Training loss: 2.5449612140655518
Validation loss: 2.1205958986795075

Epoch: 6| Step: 12
Training loss: 2.5938632488250732
Validation loss: 2.118075006751604

Epoch: 6| Step: 13
Training loss: 1.8654022216796875
Validation loss: 2.121658968669112

Epoch: 30| Step: 0
Training loss: 2.462130069732666
Validation loss: 2.1206991698152278

Epoch: 6| Step: 1
Training loss: 2.239973545074463
Validation loss: 2.119251540912095

Epoch: 6| Step: 2
Training loss: 2.8711097240448
Validation loss: 2.1192232562649633

Epoch: 6| Step: 3
Training loss: 2.8500759601593018
Validation loss: 2.119860241490026

Epoch: 6| Step: 4
Training loss: 2.5826449394226074
Validation loss: 2.120132069433889

Epoch: 6| Step: 5
Training loss: 2.376256227493286
Validation loss: 2.1206686368552585

Epoch: 6| Step: 6
Training loss: 2.3204030990600586
Validation loss: 2.120433638172765

Epoch: 6| Step: 7
Training loss: 2.6809744834899902
Validation loss: 2.1222703341514833

Epoch: 6| Step: 8
Training loss: 2.797856569290161
Validation loss: 2.120271428938835

Epoch: 6| Step: 9
Training loss: 2.875281810760498
Validation loss: 2.121897243684338

Epoch: 6| Step: 10
Training loss: 2.0404646396636963
Validation loss: 2.120793460517801

Epoch: 6| Step: 11
Training loss: 2.7600393295288086
Validation loss: 2.119232698153424

Epoch: 6| Step: 12
Training loss: 3.1866941452026367
Validation loss: 2.120566991067702

Epoch: 6| Step: 13
Training loss: 2.5112154483795166
Validation loss: 2.121579844464538

Epoch: 31| Step: 0
Training loss: 2.569014072418213
Validation loss: 2.121138039455619

Epoch: 6| Step: 1
Training loss: 2.287266492843628
Validation loss: 2.1199966271718345

Epoch: 6| Step: 2
Training loss: 3.1493613719940186
Validation loss: 2.117766764856154

Epoch: 6| Step: 3
Training loss: 2.705798387527466
Validation loss: 2.121304500487543

Epoch: 6| Step: 4
Training loss: 2.401498556137085
Validation loss: 2.1228466956846175

Epoch: 6| Step: 5
Training loss: 2.897078037261963
Validation loss: 2.12036298167321

Epoch: 6| Step: 6
Training loss: 2.9281740188598633
Validation loss: 2.120163047185508

Epoch: 6| Step: 7
Training loss: 2.209770679473877
Validation loss: 2.120033474378688

Epoch: 6| Step: 8
Training loss: 3.1021764278411865
Validation loss: 2.118761363849845

Epoch: 6| Step: 9
Training loss: 1.7780964374542236
Validation loss: 2.121069513341432

Epoch: 6| Step: 10
Training loss: 3.143723964691162
Validation loss: 2.1193055029838317

Epoch: 6| Step: 11
Training loss: 2.5770347118377686
Validation loss: 2.1203175257611018

Epoch: 6| Step: 12
Training loss: 2.1691174507141113
Validation loss: 2.1193939383311937

Epoch: 6| Step: 13
Training loss: 2.6692214012145996
Validation loss: 2.1194132451088197

Epoch: 32| Step: 0
Training loss: 2.404961585998535
Validation loss: 2.1187253728989632

Epoch: 6| Step: 1
Training loss: 2.887737512588501
Validation loss: 2.1194926026046916

Epoch: 6| Step: 2
Training loss: 2.5306248664855957
Validation loss: 2.1180616245474866

Epoch: 6| Step: 3
Training loss: 2.6961259841918945
Validation loss: 2.1177216550355316

Epoch: 6| Step: 4
Training loss: 2.0615153312683105
Validation loss: 2.1208719156121694

Epoch: 6| Step: 5
Training loss: 2.5706701278686523
Validation loss: 2.1186424045152563

Epoch: 6| Step: 6
Training loss: 3.3375353813171387
Validation loss: 2.1180243722854124

Epoch: 6| Step: 7
Training loss: 2.646824359893799
Validation loss: 2.1250470992057555

Epoch: 6| Step: 8
Training loss: 2.623173236846924
Validation loss: 2.1205542164464153

Epoch: 6| Step: 9
Training loss: 2.6480519771575928
Validation loss: 2.1182730966998684

Epoch: 6| Step: 10
Training loss: 3.2494943141937256
Validation loss: 2.1164386759522142

Epoch: 6| Step: 11
Training loss: 2.3773996829986572
Validation loss: 2.1186253255413425

Epoch: 6| Step: 12
Training loss: 1.9462658166885376
Validation loss: 2.1163849446081344

Epoch: 6| Step: 13
Training loss: 2.429870843887329
Validation loss: 2.1169719516590075

Epoch: 33| Step: 0
Training loss: 2.2472128868103027
Validation loss: 2.1194927384776454

Epoch: 6| Step: 1
Training loss: 2.503192901611328
Validation loss: 2.1158621516278995

Epoch: 6| Step: 2
Training loss: 2.644352912902832
Validation loss: 2.114736226297194

Epoch: 6| Step: 3
Training loss: 2.6781868934631348
Validation loss: 2.116852557787331

Epoch: 6| Step: 4
Training loss: 2.946316719055176
Validation loss: 2.11592673999007

Epoch: 6| Step: 5
Training loss: 2.9340367317199707
Validation loss: 2.1197113272964314

Epoch: 6| Step: 6
Training loss: 2.5736613273620605
Validation loss: 2.116108602093112

Epoch: 6| Step: 7
Training loss: 2.836362361907959
Validation loss: 2.118132811720653

Epoch: 6| Step: 8
Training loss: 3.0178041458129883
Validation loss: 2.1189368463331655

Epoch: 6| Step: 9
Training loss: 2.370180130004883
Validation loss: 2.1171367809336674

Epoch: 6| Step: 10
Training loss: 2.0155458450317383
Validation loss: 2.115437824239013

Epoch: 6| Step: 11
Training loss: 2.8983724117279053
Validation loss: 2.11837036378922

Epoch: 6| Step: 12
Training loss: 2.5257773399353027
Validation loss: 2.116452081229097

Epoch: 6| Step: 13
Training loss: 2.0577025413513184
Validation loss: 2.117168644423126

Epoch: 34| Step: 0
Training loss: 2.4410252571105957
Validation loss: 2.114502642744331

Epoch: 6| Step: 1
Training loss: 2.709803819656372
Validation loss: 2.11650380908802

Epoch: 6| Step: 2
Training loss: 2.013110399246216
Validation loss: 2.1141500332022227

Epoch: 6| Step: 3
Training loss: 2.510152816772461
Validation loss: 2.1131123753004175

Epoch: 6| Step: 4
Training loss: 2.3427062034606934
Validation loss: 2.119413139999554

Epoch: 6| Step: 5
Training loss: 1.8482074737548828
Validation loss: 2.1150600371822232

Epoch: 6| Step: 6
Training loss: 3.110867977142334
Validation loss: 2.117157305440595

Epoch: 6| Step: 7
Training loss: 2.937965154647827
Validation loss: 2.1204204046598045

Epoch: 6| Step: 8
Training loss: 2.4967904090881348
Validation loss: 2.117017848517305

Epoch: 6| Step: 9
Training loss: 2.3868913650512695
Validation loss: 2.1186625803670576

Epoch: 6| Step: 10
Training loss: 2.982170581817627
Validation loss: 2.1156006577194377

Epoch: 6| Step: 11
Training loss: 3.7469825744628906
Validation loss: 2.1165244169132684

Epoch: 6| Step: 12
Training loss: 2.247239112854004
Validation loss: 2.120038499114334

Epoch: 6| Step: 13
Training loss: 2.6509246826171875
Validation loss: 2.1190774697129444

Epoch: 35| Step: 0
Training loss: 3.319448471069336
Validation loss: 2.1161426062225015

Epoch: 6| Step: 1
Training loss: 2.2354211807250977
Validation loss: 2.113823929140645

Epoch: 6| Step: 2
Training loss: 2.525763988494873
Validation loss: 2.117362206982028

Epoch: 6| Step: 3
Training loss: 2.7884483337402344
Validation loss: 2.1141527929613666

Epoch: 6| Step: 4
Training loss: 2.3441643714904785
Validation loss: 2.115640591549617

Epoch: 6| Step: 5
Training loss: 2.6680822372436523
Validation loss: 2.116064279310165

Epoch: 6| Step: 6
Training loss: 3.0853281021118164
Validation loss: 2.1177041389608897

Epoch: 6| Step: 7
Training loss: 2.628708600997925
Validation loss: 2.1156398609120357

Epoch: 6| Step: 8
Training loss: 2.300821304321289
Validation loss: 2.1134126083825224

Epoch: 6| Step: 9
Training loss: 2.384331226348877
Validation loss: 2.114219222017514

Epoch: 6| Step: 10
Training loss: 2.787896156311035
Validation loss: 2.117145292220577

Epoch: 6| Step: 11
Training loss: 2.412440776824951
Validation loss: 2.1137581204855316

Epoch: 6| Step: 12
Training loss: 2.2454428672790527
Validation loss: 2.1174142078686784

Epoch: 6| Step: 13
Training loss: 2.711212635040283
Validation loss: 2.1129286443033526

Epoch: 36| Step: 0
Training loss: 3.407573699951172
Validation loss: 2.1145579968729327

Epoch: 6| Step: 1
Training loss: 2.430971384048462
Validation loss: 2.111105175428493

Epoch: 6| Step: 2
Training loss: 2.6303911209106445
Validation loss: 2.113971059040357

Epoch: 6| Step: 3
Training loss: 2.4666266441345215
Validation loss: 2.1136634503641436

Epoch: 6| Step: 4
Training loss: 2.935638904571533
Validation loss: 2.1123030467699935

Epoch: 6| Step: 5
Training loss: 2.740139961242676
Validation loss: 2.115022192719162

Epoch: 6| Step: 6
Training loss: 2.650076389312744
Validation loss: 2.116751000445376

Epoch: 6| Step: 7
Training loss: 2.780719757080078
Validation loss: 2.1146433199605634

Epoch: 6| Step: 8
Training loss: 2.736659049987793
Validation loss: 2.111553922776253

Epoch: 6| Step: 9
Training loss: 2.3295352458953857
Validation loss: 2.1117754020998554

Epoch: 6| Step: 10
Training loss: 2.827280044555664
Validation loss: 2.1179163507235947

Epoch: 6| Step: 11
Training loss: 1.9075264930725098
Validation loss: 2.114716147863737

Epoch: 6| Step: 12
Training loss: 1.9917118549346924
Validation loss: 2.113105759825758

Epoch: 6| Step: 13
Training loss: 2.446533203125
Validation loss: 2.1127904820185837

Epoch: 37| Step: 0
Training loss: 2.1243414878845215
Validation loss: 2.1166156235561577

Epoch: 6| Step: 1
Training loss: 2.429612159729004
Validation loss: 2.114935544229323

Epoch: 6| Step: 2
Training loss: 2.5304083824157715
Validation loss: 2.1132881026114188

Epoch: 6| Step: 3
Training loss: 2.9577951431274414
Validation loss: 2.110935593164095

Epoch: 6| Step: 4
Training loss: 1.8828219175338745
Validation loss: 2.111171346838756

Epoch: 6| Step: 5
Training loss: 3.218198537826538
Validation loss: 2.1135901148601244

Epoch: 6| Step: 6
Training loss: 2.4841721057891846
Validation loss: 2.10912924684504

Epoch: 6| Step: 7
Training loss: 2.89235520362854
Validation loss: 2.114522550695686

Epoch: 6| Step: 8
Training loss: 2.511524200439453
Validation loss: 2.110034978517922

Epoch: 6| Step: 9
Training loss: 2.887788772583008
Validation loss: 2.11438343345478

Epoch: 6| Step: 10
Training loss: 3.084139108657837
Validation loss: 2.112042825709107

Epoch: 6| Step: 11
Training loss: 2.2599382400512695
Validation loss: 2.108086100188635

Epoch: 6| Step: 12
Training loss: 2.2816286087036133
Validation loss: 2.109543638844644

Epoch: 6| Step: 13
Training loss: 2.8473877906799316
Validation loss: 2.1120702028274536

Epoch: 38| Step: 0
Training loss: 2.1200380325317383
Validation loss: 2.109429436345254

Epoch: 6| Step: 1
Training loss: 3.0747475624084473
Validation loss: 2.1086992884194977

Epoch: 6| Step: 2
Training loss: 2.350360870361328
Validation loss: 2.1086376456804174

Epoch: 6| Step: 3
Training loss: 2.5972900390625
Validation loss: 2.1091788584186184

Epoch: 6| Step: 4
Training loss: 2.7565183639526367
Validation loss: 2.1067588970225346

Epoch: 6| Step: 5
Training loss: 2.9905624389648438
Validation loss: 2.110663058937237

Epoch: 6| Step: 6
Training loss: 2.241061210632324
Validation loss: 2.1081638207999607

Epoch: 6| Step: 7
Training loss: 2.702798843383789
Validation loss: 2.1104452097287743

Epoch: 6| Step: 8
Training loss: 2.898512840270996
Validation loss: 2.1125812838154454

Epoch: 6| Step: 9
Training loss: 3.082092761993408
Validation loss: 2.1140091111583095

Epoch: 6| Step: 10
Training loss: 2.103118658065796
Validation loss: 2.1079428990681968

Epoch: 6| Step: 11
Training loss: 2.158731460571289
Validation loss: 2.107699091716479

Epoch: 6| Step: 12
Training loss: 2.3486592769622803
Validation loss: 2.109604263818392

Epoch: 6| Step: 13
Training loss: 3.0321948528289795
Validation loss: 2.1076445912802093

Epoch: 39| Step: 0
Training loss: 2.1040587425231934
Validation loss: 2.1106548860508907

Epoch: 6| Step: 1
Training loss: 2.262873649597168
Validation loss: 2.107569417645854

Epoch: 6| Step: 2
Training loss: 2.2953009605407715
Validation loss: 2.1079196622294765

Epoch: 6| Step: 3
Training loss: 2.8000540733337402
Validation loss: 2.107135224085982

Epoch: 6| Step: 4
Training loss: 2.9273977279663086
Validation loss: 2.110130317749516

Epoch: 6| Step: 5
Training loss: 3.287538528442383
Validation loss: 2.109395985962242

Epoch: 6| Step: 6
Training loss: 2.1546993255615234
Validation loss: 2.1084269849202966

Epoch: 6| Step: 7
Training loss: 2.381286859512329
Validation loss: 2.1076035576481975

Epoch: 6| Step: 8
Training loss: 2.8581910133361816
Validation loss: 2.112032808283324

Epoch: 6| Step: 9
Training loss: 2.9126832485198975
Validation loss: 2.114438851674398

Epoch: 6| Step: 10
Training loss: 2.788485050201416
Validation loss: 2.1065424539709605

Epoch: 6| Step: 11
Training loss: 2.3659844398498535
Validation loss: 2.105760819168501

Epoch: 6| Step: 12
Training loss: 2.5767250061035156
Validation loss: 2.1102839272509337

Epoch: 6| Step: 13
Training loss: 2.4151432514190674
Validation loss: 2.10418781926555

Epoch: 40| Step: 0
Training loss: 2.357973575592041
Validation loss: 2.1030155715122016

Epoch: 6| Step: 1
Training loss: 1.8955295085906982
Validation loss: 2.1078259150187173

Epoch: 6| Step: 2
Training loss: 2.9102940559387207
Validation loss: 2.1089879146186252

Epoch: 6| Step: 3
Training loss: 2.7068276405334473
Validation loss: 2.1051304263453328

Epoch: 6| Step: 4
Training loss: 2.7850396633148193
Validation loss: 2.107060888762115

Epoch: 6| Step: 5
Training loss: 2.564659357070923
Validation loss: 2.106105699334093

Epoch: 6| Step: 6
Training loss: 2.463656425476074
Validation loss: 2.108324678995276

Epoch: 6| Step: 7
Training loss: 2.8515636920928955
Validation loss: 2.1092231171105498

Epoch: 6| Step: 8
Training loss: 2.871922016143799
Validation loss: 2.10611472334913

Epoch: 6| Step: 9
Training loss: 2.4470415115356445
Validation loss: 2.1077703019624114

Epoch: 6| Step: 10
Training loss: 2.6479413509368896
Validation loss: 2.1092542781624743

Epoch: 6| Step: 11
Training loss: 2.8487775325775146
Validation loss: 2.106811713146907

Epoch: 6| Step: 12
Training loss: 2.464850902557373
Validation loss: 2.1067277205887662

Epoch: 6| Step: 13
Training loss: 2.1707334518432617
Validation loss: 2.1027854437469156

Epoch: 41| Step: 0
Training loss: 2.324819564819336
Validation loss: 2.1071508007664836

Epoch: 6| Step: 1
Training loss: 2.9486804008483887
Validation loss: 2.104567680307614

Epoch: 6| Step: 2
Training loss: 2.7101049423217773
Validation loss: 2.105304456526233

Epoch: 6| Step: 3
Training loss: 2.0917978286743164
Validation loss: 2.10184754607498

Epoch: 6| Step: 4
Training loss: 2.2694296836853027
Validation loss: 2.1048614799335437

Epoch: 6| Step: 5
Training loss: 2.537667751312256
Validation loss: 2.1060333739044848

Epoch: 6| Step: 6
Training loss: 2.6966915130615234
Validation loss: 2.108883560344737

Epoch: 6| Step: 7
Training loss: 2.2766947746276855
Validation loss: 2.1084804227275233

Epoch: 6| Step: 8
Training loss: 3.230600357055664
Validation loss: 2.099722921207387

Epoch: 6| Step: 9
Training loss: 2.6360883712768555
Validation loss: 2.105591684259394

Epoch: 6| Step: 10
Training loss: 2.7341275215148926
Validation loss: 2.1022277288539435

Epoch: 6| Step: 11
Training loss: 2.9868545532226562
Validation loss: 2.108524999310893

Epoch: 6| Step: 12
Training loss: 2.432034969329834
Validation loss: 2.1053236556309525

Epoch: 6| Step: 13
Training loss: 1.9797015190124512
Validation loss: 2.1055923097877094

Epoch: 42| Step: 0
Training loss: 2.5877561569213867
Validation loss: 2.101698421662854

Epoch: 6| Step: 1
Training loss: 2.671191692352295
Validation loss: 2.10361373296348

Epoch: 6| Step: 2
Training loss: 2.1378910541534424
Validation loss: 2.1017926046925206

Epoch: 6| Step: 3
Training loss: 2.412531852722168
Validation loss: 2.1000549049787622

Epoch: 6| Step: 4
Training loss: 2.4573616981506348
Validation loss: 2.103770871316233

Epoch: 6| Step: 5
Training loss: 3.055406093597412
Validation loss: 2.1104028814582416

Epoch: 6| Step: 6
Training loss: 1.981218695640564
Validation loss: 2.1053484127085698

Epoch: 6| Step: 7
Training loss: 2.8229517936706543
Validation loss: 2.104416638292292

Epoch: 6| Step: 8
Training loss: 2.3390469551086426
Validation loss: 2.1008485760740054

Epoch: 6| Step: 9
Training loss: 2.359919548034668
Validation loss: 2.0997516903825986

Epoch: 6| Step: 10
Training loss: 2.5954360961914062
Validation loss: 2.102902547005684

Epoch: 6| Step: 11
Training loss: 3.03190016746521
Validation loss: 2.100096515429917

Epoch: 6| Step: 12
Training loss: 2.8555619716644287
Validation loss: 2.1014488512469875

Epoch: 6| Step: 13
Training loss: 2.8282060623168945
Validation loss: 2.1007522485589467

Epoch: 43| Step: 0
Training loss: 2.4507553577423096
Validation loss: 2.101632164370629

Epoch: 6| Step: 1
Training loss: 2.2802674770355225
Validation loss: 2.099170256686467

Epoch: 6| Step: 2
Training loss: 2.275771141052246
Validation loss: 2.0999479114368396

Epoch: 6| Step: 3
Training loss: 2.492781639099121
Validation loss: 2.0960012789695495

Epoch: 6| Step: 4
Training loss: 2.916486978530884
Validation loss: 2.1036029169636388

Epoch: 6| Step: 5
Training loss: 2.9532277584075928
Validation loss: 2.0986801988335064

Epoch: 6| Step: 6
Training loss: 2.694343090057373
Validation loss: 2.09544615591726

Epoch: 6| Step: 7
Training loss: 2.183612823486328
Validation loss: 2.095928745885049

Epoch: 6| Step: 8
Training loss: 2.5804948806762695
Validation loss: 2.0984218338484406

Epoch: 6| Step: 9
Training loss: 2.6847753524780273
Validation loss: 2.102451762845439

Epoch: 6| Step: 10
Training loss: 2.2468862533569336
Validation loss: 2.098512323953772

Epoch: 6| Step: 11
Training loss: 2.780384063720703
Validation loss: 2.093582373793407

Epoch: 6| Step: 12
Training loss: 2.946902275085449
Validation loss: 2.0966998325881137

Epoch: 6| Step: 13
Training loss: 2.411067008972168
Validation loss: 2.10290442743609

Epoch: 44| Step: 0
Training loss: 1.9934465885162354
Validation loss: 2.0981949939522693

Epoch: 6| Step: 1
Training loss: 3.175760507583618
Validation loss: 2.101248582204183

Epoch: 6| Step: 2
Training loss: 2.8899784088134766
Validation loss: 2.09842844675946

Epoch: 6| Step: 3
Training loss: 2.6977288722991943
Validation loss: 2.0953065759392193

Epoch: 6| Step: 4
Training loss: 2.539346694946289
Validation loss: 2.095925167042722

Epoch: 6| Step: 5
Training loss: 2.0955610275268555
Validation loss: 2.099890075704103

Epoch: 6| Step: 6
Training loss: 2.556694984436035
Validation loss: 2.0994179505173878

Epoch: 6| Step: 7
Training loss: 2.4143950939178467
Validation loss: 2.0958571203293337

Epoch: 6| Step: 8
Training loss: 2.8682656288146973
Validation loss: 2.0947459282413607

Epoch: 6| Step: 9
Training loss: 2.263932228088379
Validation loss: 2.09513517092633

Epoch: 6| Step: 10
Training loss: 2.794020652770996
Validation loss: 2.094914195358112

Epoch: 6| Step: 11
Training loss: 2.7636301517486572
Validation loss: 2.100048557404549

Epoch: 6| Step: 12
Training loss: 2.518796443939209
Validation loss: 2.097672698318317

Epoch: 6| Step: 13
Training loss: 2.2143969535827637
Validation loss: 2.093912398943337

Epoch: 45| Step: 0
Training loss: 2.9834024906158447
Validation loss: 2.096119834530738

Epoch: 6| Step: 1
Training loss: 2.474010944366455
Validation loss: 2.100356789045436

Epoch: 6| Step: 2
Training loss: 3.2109792232513428
Validation loss: 2.0954284283422653

Epoch: 6| Step: 3
Training loss: 2.8660035133361816
Validation loss: 2.101069117105135

Epoch: 6| Step: 4
Training loss: 2.1645166873931885
Validation loss: 2.09392027701101

Epoch: 6| Step: 5
Training loss: 2.5402584075927734
Validation loss: 2.100965207622897

Epoch: 6| Step: 6
Training loss: 2.3613789081573486
Validation loss: 2.0973327441882064

Epoch: 6| Step: 7
Training loss: 2.997450113296509
Validation loss: 2.1032927292649464

Epoch: 6| Step: 8
Training loss: 1.8103543519973755
Validation loss: 2.0961252130487913

Epoch: 6| Step: 9
Training loss: 2.2428550720214844
Validation loss: 2.0951846312451106

Epoch: 6| Step: 10
Training loss: 2.488771438598633
Validation loss: 2.095061461130778

Epoch: 6| Step: 11
Training loss: 2.6057026386260986
Validation loss: 2.0965818205187396

Epoch: 6| Step: 12
Training loss: 2.715611457824707
Validation loss: 2.094141150033602

Epoch: 6| Step: 13
Training loss: 2.278780698776245
Validation loss: 2.0904481000797723

Epoch: 46| Step: 0
Training loss: 2.4853286743164062
Validation loss: 2.0957663418144308

Epoch: 6| Step: 1
Training loss: 3.025063991546631
Validation loss: 2.0973495924344627

Epoch: 6| Step: 2
Training loss: 3.0409953594207764
Validation loss: 2.089742168303459

Epoch: 6| Step: 3
Training loss: 2.1783607006073
Validation loss: 2.095324654732981

Epoch: 6| Step: 4
Training loss: 2.486074924468994
Validation loss: 2.0924545846959597

Epoch: 6| Step: 5
Training loss: 2.6311750411987305
Validation loss: 2.0948100705300607

Epoch: 6| Step: 6
Training loss: 2.15286922454834
Validation loss: 2.0944263909452703

Epoch: 6| Step: 7
Training loss: 2.6520748138427734
Validation loss: 2.0923470656077066

Epoch: 6| Step: 8
Training loss: 2.2972769737243652
Validation loss: 2.0910015388201644

Epoch: 6| Step: 9
Training loss: 2.187912940979004
Validation loss: 2.0877123007210354

Epoch: 6| Step: 10
Training loss: 2.547245502471924
Validation loss: 2.0996886171320432

Epoch: 6| Step: 11
Training loss: 2.832850456237793
Validation loss: 2.093438445880849

Epoch: 6| Step: 12
Training loss: 2.8500003814697266
Validation loss: 2.0884178453876125

Epoch: 6| Step: 13
Training loss: 2.3126301765441895
Validation loss: 2.097942203603765

Epoch: 47| Step: 0
Training loss: 2.860718250274658
Validation loss: 2.0973282911444224

Epoch: 6| Step: 1
Training loss: 2.6269569396972656
Validation loss: 2.0918966544571744

Epoch: 6| Step: 2
Training loss: 2.8997209072113037
Validation loss: 2.0903101531408166

Epoch: 6| Step: 3
Training loss: 1.7925775051116943
Validation loss: 2.083848649455655

Epoch: 6| Step: 4
Training loss: 2.697216033935547
Validation loss: 2.0936448304883895

Epoch: 6| Step: 5
Training loss: 2.2965481281280518
Validation loss: 2.089799360562396

Epoch: 6| Step: 6
Training loss: 2.374910354614258
Validation loss: 2.0917184545147802

Epoch: 6| Step: 7
Training loss: 2.032792091369629
Validation loss: 2.0854603628958426

Epoch: 6| Step: 8
Training loss: 2.9201064109802246
Validation loss: 2.09226893865934

Epoch: 6| Step: 9
Training loss: 3.156777858734131
Validation loss: 2.0911867310923915

Epoch: 6| Step: 10
Training loss: 2.3848838806152344
Validation loss: 2.0929416507802983

Epoch: 6| Step: 11
Training loss: 2.8793540000915527
Validation loss: 2.0904984012726815

Epoch: 6| Step: 12
Training loss: 2.1866209506988525
Validation loss: 2.0838690342441684

Epoch: 6| Step: 13
Training loss: 2.739684820175171
Validation loss: 2.0830843474275325

Epoch: 48| Step: 0
Training loss: 2.230599880218506
Validation loss: 2.086512980922576

Epoch: 6| Step: 1
Training loss: 3.106234550476074
Validation loss: 2.0766872539315173

Epoch: 6| Step: 2
Training loss: 2.304779052734375
Validation loss: 2.0867246415025447

Epoch: 6| Step: 3
Training loss: 2.214442014694214
Validation loss: 2.0843886790737027

Epoch: 6| Step: 4
Training loss: 2.385471820831299
Validation loss: 2.086262502977925

Epoch: 6| Step: 5
Training loss: 2.3414859771728516
Validation loss: 2.0880747097794727

Epoch: 6| Step: 6
Training loss: 2.2247581481933594
Validation loss: 2.0834034899229645

Epoch: 6| Step: 7
Training loss: 3.0784718990325928
Validation loss: 2.087347394676619

Epoch: 6| Step: 8
Training loss: 3.174196243286133
Validation loss: 2.0902961864266345

Epoch: 6| Step: 9
Training loss: 2.7631607055664062
Validation loss: 2.087389161509852

Epoch: 6| Step: 10
Training loss: 2.467683792114258
Validation loss: 2.08726829354481

Epoch: 6| Step: 11
Training loss: 2.903125762939453
Validation loss: 2.087409493743732

Epoch: 6| Step: 12
Training loss: 2.4320895671844482
Validation loss: 2.080160963919855

Epoch: 6| Step: 13
Training loss: 1.6376948356628418
Validation loss: 2.092426256466937

Epoch: 49| Step: 0
Training loss: 2.516350030899048
Validation loss: 2.0805838838700326

Epoch: 6| Step: 1
Training loss: 2.333139419555664
Validation loss: 2.0808931063580256

Epoch: 6| Step: 2
Training loss: 2.410778760910034
Validation loss: 2.0845604583781254

Epoch: 6| Step: 3
Training loss: 1.7362470626831055
Validation loss: 2.0871396346758773

Epoch: 6| Step: 4
Training loss: 2.0711722373962402
Validation loss: 2.0834454439019643

Epoch: 6| Step: 5
Training loss: 2.8641197681427
Validation loss: 2.0842295051902853

Epoch: 6| Step: 6
Training loss: 2.3515844345092773
Validation loss: 2.0826794755074287

Epoch: 6| Step: 7
Training loss: 2.83199405670166
Validation loss: 2.086674863292325

Epoch: 6| Step: 8
Training loss: 2.7370762825012207
Validation loss: 2.08615025653634

Epoch: 6| Step: 9
Training loss: 2.390636444091797
Validation loss: 2.0801558674022718

Epoch: 6| Step: 10
Training loss: 2.8914551734924316
Validation loss: 2.0888962104756343

Epoch: 6| Step: 11
Training loss: 2.9156832695007324
Validation loss: 2.0810738686592347

Epoch: 6| Step: 12
Training loss: 2.619873285293579
Validation loss: 2.079839680784492

Epoch: 6| Step: 13
Training loss: 3.2004048824310303
Validation loss: 2.0813545565451346

Epoch: 50| Step: 0
Training loss: 2.4179325103759766
Validation loss: 2.0795733236497447

Epoch: 6| Step: 1
Training loss: 2.5150442123413086
Validation loss: 2.087455088092435

Epoch: 6| Step: 2
Training loss: 2.630427837371826
Validation loss: 2.0748779286620436

Epoch: 6| Step: 3
Training loss: 2.0903100967407227
Validation loss: 2.0834131112662693

Epoch: 6| Step: 4
Training loss: 2.213360071182251
Validation loss: 2.0860296756990495

Epoch: 6| Step: 5
Training loss: 3.1329588890075684
Validation loss: 2.080893519104168

Epoch: 6| Step: 6
Training loss: 2.5910801887512207
Validation loss: 2.0822505925291326

Epoch: 6| Step: 7
Training loss: 2.6823983192443848
Validation loss: 2.0835152851637972

Epoch: 6| Step: 8
Training loss: 3.1035542488098145
Validation loss: 2.093219477643249

Epoch: 6| Step: 9
Training loss: 2.7031760215759277
Validation loss: 2.0791684401932584

Epoch: 6| Step: 10
Training loss: 2.4689393043518066
Validation loss: 2.082203518959784

Epoch: 6| Step: 11
Training loss: 2.972701072692871
Validation loss: 2.0775556525876446

Epoch: 6| Step: 12
Training loss: 1.7654820680618286
Validation loss: 2.084767033976893

Epoch: 6| Step: 13
Training loss: 2.0941827297210693
Validation loss: 2.0846315583875104

Epoch: 51| Step: 0
Training loss: 2.2845780849456787
Validation loss: 2.0804476507248415

Epoch: 6| Step: 1
Training loss: 2.2773096561431885
Validation loss: 2.077794844104398

Epoch: 6| Step: 2
Training loss: 2.3903021812438965
Validation loss: 2.080218433051981

Epoch: 6| Step: 3
Training loss: 2.6127800941467285
Validation loss: 2.0752618107744443

Epoch: 6| Step: 4
Training loss: 2.303190231323242
Validation loss: 2.0846521444218133

Epoch: 6| Step: 5
Training loss: 2.8642418384552
Validation loss: 2.0775046374208186

Epoch: 6| Step: 6
Training loss: 3.0965065956115723
Validation loss: 2.0776036144584737

Epoch: 6| Step: 7
Training loss: 2.7225823402404785
Validation loss: 2.0833957297827608

Epoch: 6| Step: 8
Training loss: 1.70358145236969
Validation loss: 2.074872096379598

Epoch: 6| Step: 9
Training loss: 2.480076789855957
Validation loss: 2.081118027369181

Epoch: 6| Step: 10
Training loss: 2.709873676300049
Validation loss: 2.0820373809465798

Epoch: 6| Step: 11
Training loss: 2.7447752952575684
Validation loss: 2.0753749775630173

Epoch: 6| Step: 12
Training loss: 2.404975414276123
Validation loss: 2.076550288866925

Epoch: 6| Step: 13
Training loss: 3.0908639430999756
Validation loss: 2.0774660879565823

Epoch: 52| Step: 0
Training loss: 2.8995680809020996
Validation loss: 2.0755655278441725

Epoch: 6| Step: 1
Training loss: 3.1081886291503906
Validation loss: 2.0783343571488575

Epoch: 6| Step: 2
Training loss: 2.1282472610473633
Validation loss: 2.0750514691875828

Epoch: 6| Step: 3
Training loss: 2.7235379219055176
Validation loss: 2.0752823019540436

Epoch: 6| Step: 4
Training loss: 2.6867551803588867
Validation loss: 2.077540606580755

Epoch: 6| Step: 5
Training loss: 2.8611526489257812
Validation loss: 2.0779830717271373

Epoch: 6| Step: 6
Training loss: 2.3445401191711426
Validation loss: 2.0776548385620117

Epoch: 6| Step: 7
Training loss: 2.560288906097412
Validation loss: 2.0725274034725722

Epoch: 6| Step: 8
Training loss: 1.958138108253479
Validation loss: 2.0845311482747397

Epoch: 6| Step: 9
Training loss: 2.254406213760376
Validation loss: 2.079088959642636

Epoch: 6| Step: 10
Training loss: 1.816087245941162
Validation loss: 2.0753432063646216

Epoch: 6| Step: 11
Training loss: 2.987428903579712
Validation loss: 2.0666645598667923

Epoch: 6| Step: 12
Training loss: 2.8783295154571533
Validation loss: 2.075489559481221

Epoch: 6| Step: 13
Training loss: 1.9851175546646118
Validation loss: 2.076530553961313

Epoch: 53| Step: 0
Training loss: 2.2125535011291504
Validation loss: 2.0720502971321024

Epoch: 6| Step: 1
Training loss: 2.1365766525268555
Validation loss: 2.070479864715248

Epoch: 6| Step: 2
Training loss: 2.8688671588897705
Validation loss: 2.074867179316859

Epoch: 6| Step: 3
Training loss: 3.1464900970458984
Validation loss: 2.0763307899557133

Epoch: 6| Step: 4
Training loss: 2.14845609664917
Validation loss: 2.072027519185056

Epoch: 6| Step: 5
Training loss: 1.7469732761383057
Validation loss: 2.0724973396588395

Epoch: 6| Step: 6
Training loss: 3.0866713523864746
Validation loss: 2.0732058273848666

Epoch: 6| Step: 7
Training loss: 2.8148584365844727
Validation loss: 2.0777215368004254

Epoch: 6| Step: 8
Training loss: 2.7520751953125
Validation loss: 2.073597490146596

Epoch: 6| Step: 9
Training loss: 2.7562594413757324
Validation loss: 2.0734323532350603

Epoch: 6| Step: 10
Training loss: 2.6821916103363037
Validation loss: 2.072188667071763

Epoch: 6| Step: 11
Training loss: 1.986070156097412
Validation loss: 2.067751028204477

Epoch: 6| Step: 12
Training loss: 2.4356935024261475
Validation loss: 2.0698514369226273

Epoch: 6| Step: 13
Training loss: 2.62679123878479
Validation loss: 2.0645425858036166

Epoch: 54| Step: 0
Training loss: 2.6658167839050293
Validation loss: 2.079692244529724

Epoch: 6| Step: 1
Training loss: 1.9376013278961182
Validation loss: 2.0726642839370237

Epoch: 6| Step: 2
Training loss: 2.014854907989502
Validation loss: 2.069960694159231

Epoch: 6| Step: 3
Training loss: 2.3903865814208984
Validation loss: 2.076503465252538

Epoch: 6| Step: 4
Training loss: 2.3193538188934326
Validation loss: 2.0767172792906403

Epoch: 6| Step: 5
Training loss: 2.5300750732421875
Validation loss: 2.0737476682150238

Epoch: 6| Step: 6
Training loss: 2.2972280979156494
Validation loss: 2.0715590241134807

Epoch: 6| Step: 7
Training loss: 2.5862810611724854
Validation loss: 2.0698114287468696

Epoch: 6| Step: 8
Training loss: 2.3773722648620605
Validation loss: 2.071436643600464

Epoch: 6| Step: 9
Training loss: 3.326448440551758
Validation loss: 2.076032525749617

Epoch: 6| Step: 10
Training loss: 2.355821132659912
Validation loss: 2.0708867324295865

Epoch: 6| Step: 11
Training loss: 3.127096652984619
Validation loss: 2.0696248110904487

Epoch: 6| Step: 12
Training loss: 2.998485565185547
Validation loss: 2.078170863530969

Epoch: 6| Step: 13
Training loss: 2.207427740097046
Validation loss: 2.073644618834219

Epoch: 55| Step: 0
Training loss: 2.2848687171936035
Validation loss: 2.0684670940522225

Epoch: 6| Step: 1
Training loss: 2.9381747245788574
Validation loss: 2.069483031508743

Epoch: 6| Step: 2
Training loss: 2.8006672859191895
Validation loss: 2.0683683861968336

Epoch: 6| Step: 3
Training loss: 2.9833924770355225
Validation loss: 2.0764110267803235

Epoch: 6| Step: 4
Training loss: 2.670635223388672
Validation loss: 2.067212854662249

Epoch: 6| Step: 5
Training loss: 2.3769993782043457
Validation loss: 2.074174596417335

Epoch: 6| Step: 6
Training loss: 2.617736339569092
Validation loss: 2.0701943738486177

Epoch: 6| Step: 7
Training loss: 2.520550012588501
Validation loss: 2.0703674131824124

Epoch: 6| Step: 8
Training loss: 2.2712488174438477
Validation loss: 2.0732787039972123

Epoch: 6| Step: 9
Training loss: 2.5856242179870605
Validation loss: 2.071359278053366

Epoch: 6| Step: 10
Training loss: 2.4845478534698486
Validation loss: 2.0713124903299476

Epoch: 6| Step: 11
Training loss: 2.604893207550049
Validation loss: 2.066292506392284

Epoch: 6| Step: 12
Training loss: 2.3179216384887695
Validation loss: 2.068596878359395

Epoch: 6| Step: 13
Training loss: 1.1398264169692993
Validation loss: 2.0672867310944425

Epoch: 56| Step: 0
Training loss: 2.2004990577697754
Validation loss: 2.0658629299491964

Epoch: 6| Step: 1
Training loss: 2.6971282958984375
Validation loss: 2.0572508278713433

Epoch: 6| Step: 2
Training loss: 2.8154165744781494
Validation loss: 2.065292558362407

Epoch: 6| Step: 3
Training loss: 1.9636582136154175
Validation loss: 2.0687226377507693

Epoch: 6| Step: 4
Training loss: 2.1851084232330322
Validation loss: 2.063821199119732

Epoch: 6| Step: 5
Training loss: 2.5488321781158447
Validation loss: 2.064652108377026

Epoch: 6| Step: 6
Training loss: 3.2087128162384033
Validation loss: 2.068477863906532

Epoch: 6| Step: 7
Training loss: 2.5753884315490723
Validation loss: 2.068704351302116

Epoch: 6| Step: 8
Training loss: 2.9657301902770996
Validation loss: 2.060671132097962

Epoch: 6| Step: 9
Training loss: 2.7167797088623047
Validation loss: 2.065966449758058

Epoch: 6| Step: 10
Training loss: 2.717264175415039
Validation loss: 2.0676112059623963

Epoch: 6| Step: 11
Training loss: 2.506960391998291
Validation loss: 2.0683138293604695

Epoch: 6| Step: 12
Training loss: 2.0190541744232178
Validation loss: 2.0636397766810592

Epoch: 6| Step: 13
Training loss: 1.5732271671295166
Validation loss: 2.0604098496898526

Epoch: 57| Step: 0
Training loss: 2.7812294960021973
Validation loss: 2.070444145510274

Epoch: 6| Step: 1
Training loss: 2.202465534210205
Validation loss: 2.06554719837763

Epoch: 6| Step: 2
Training loss: 2.2344181537628174
Validation loss: 2.0706847008838447

Epoch: 6| Step: 3
Training loss: 2.652475595474243
Validation loss: 2.0638969482914096

Epoch: 6| Step: 4
Training loss: 2.747918128967285
Validation loss: 2.0675883575152327

Epoch: 6| Step: 5
Training loss: 2.6744813919067383
Validation loss: 2.0662415412164505

Epoch: 6| Step: 6
Training loss: 1.7450973987579346
Validation loss: 2.061348940736504

Epoch: 6| Step: 7
Training loss: 3.035515546798706
Validation loss: 2.067333831582018

Epoch: 6| Step: 8
Training loss: 1.9971165657043457
Validation loss: 2.056664894985896

Epoch: 6| Step: 9
Training loss: 3.042682409286499
Validation loss: 2.0550387879853607

Epoch: 6| Step: 10
Training loss: 2.8491005897521973
Validation loss: 2.0586642116628666

Epoch: 6| Step: 11
Training loss: 2.501493453979492
Validation loss: 2.065845271592499

Epoch: 6| Step: 12
Training loss: 2.05294132232666
Validation loss: 2.056525344489723

Epoch: 6| Step: 13
Training loss: 2.607090950012207
Validation loss: 2.060090723858085

Epoch: 58| Step: 0
Training loss: 2.184145927429199
Validation loss: 2.0614477562647995

Epoch: 6| Step: 1
Training loss: 2.723660469055176
Validation loss: 2.050345387510074

Epoch: 6| Step: 2
Training loss: 2.2149033546447754
Validation loss: 2.0582291541561

Epoch: 6| Step: 3
Training loss: 2.194767475128174
Validation loss: 2.0609427703324186

Epoch: 6| Step: 4
Training loss: 2.7728867530822754
Validation loss: 2.0559180077686103

Epoch: 6| Step: 5
Training loss: 2.7261953353881836
Validation loss: 2.0587219576681814

Epoch: 6| Step: 6
Training loss: 2.2156119346618652
Validation loss: 2.0580158656643284

Epoch: 6| Step: 7
Training loss: 2.724616527557373
Validation loss: 2.054301582356935

Epoch: 6| Step: 8
Training loss: 2.1060550212860107
Validation loss: 2.0522943786395493

Epoch: 6| Step: 9
Training loss: 2.0976924896240234
Validation loss: 2.0654972599398707

Epoch: 6| Step: 10
Training loss: 2.7433102130889893
Validation loss: 2.0544298874434603

Epoch: 6| Step: 11
Training loss: 2.3663406372070312
Validation loss: 2.057517150396942

Epoch: 6| Step: 12
Training loss: 2.83585786819458
Validation loss: 2.0619652809635287

Epoch: 6| Step: 13
Training loss: 3.528079032897949
Validation loss: 2.0620779837331464

Epoch: 59| Step: 0
Training loss: 1.9674752950668335
Validation loss: 2.0621661473346014

Epoch: 6| Step: 1
Training loss: 2.69817852973938
Validation loss: 2.0589890044222594

Epoch: 6| Step: 2
Training loss: 2.016918182373047
Validation loss: 2.057074022549455

Epoch: 6| Step: 3
Training loss: 2.290369749069214
Validation loss: 2.053115757562781

Epoch: 6| Step: 4
Training loss: 2.5946693420410156
Validation loss: 2.060309084512854

Epoch: 6| Step: 5
Training loss: 2.6180381774902344
Validation loss: 2.0422047427905503

Epoch: 6| Step: 6
Training loss: 2.605447292327881
Validation loss: 2.052118573137509

Epoch: 6| Step: 7
Training loss: 2.55880069732666
Validation loss: 2.047414198998482

Epoch: 6| Step: 8
Training loss: 2.281956672668457
Validation loss: 2.059415796751617

Epoch: 6| Step: 9
Training loss: 2.27901291847229
Validation loss: 2.0414594450304584

Epoch: 6| Step: 10
Training loss: 2.187704563140869
Validation loss: 2.0497742365765315

Epoch: 6| Step: 11
Training loss: 2.342195510864258
Validation loss: 2.055038400875625

Epoch: 6| Step: 12
Training loss: 3.464388847351074
Validation loss: 2.047736071771191

Epoch: 6| Step: 13
Training loss: 3.502054214477539
Validation loss: 2.052727122460642

Epoch: 60| Step: 0
Training loss: 2.298633337020874
Validation loss: 2.0476150769059376

Epoch: 6| Step: 1
Training loss: 3.0552117824554443
Validation loss: 2.0513005461744083

Epoch: 6| Step: 2
Training loss: 2.2540202140808105
Validation loss: 2.063796479214904

Epoch: 6| Step: 3
Training loss: 2.426185369491577
Validation loss: 2.0517252722094135

Epoch: 6| Step: 4
Training loss: 2.528414726257324
Validation loss: 2.0511162024672314

Epoch: 6| Step: 5
Training loss: 2.4307303428649902
Validation loss: 2.058747983747913

Epoch: 6| Step: 6
Training loss: 2.2421047687530518
Validation loss: 2.044200271688482

Epoch: 6| Step: 7
Training loss: 2.335465431213379
Validation loss: 2.0643253890416955

Epoch: 6| Step: 8
Training loss: 2.4248712062835693
Validation loss: 2.046869718900291

Epoch: 6| Step: 9
Training loss: 2.409238338470459
Validation loss: 2.053329103736467

Epoch: 6| Step: 10
Training loss: 2.713386058807373
Validation loss: 2.0459694593183455

Epoch: 6| Step: 11
Training loss: 2.6228156089782715
Validation loss: 2.0431941260573683

Epoch: 6| Step: 12
Training loss: 2.2761478424072266
Validation loss: 2.0376348444210586

Epoch: 6| Step: 13
Training loss: 3.1684274673461914
Validation loss: 2.049626373475598

Epoch: 61| Step: 0
Training loss: 2.731755495071411
Validation loss: 2.056427695417917

Epoch: 6| Step: 1
Training loss: 3.076808452606201
Validation loss: 2.0502180694251932

Epoch: 6| Step: 2
Training loss: 2.309821367263794
Validation loss: 2.049614857601863

Epoch: 6| Step: 3
Training loss: 2.1285886764526367
Validation loss: 2.054257695392896

Epoch: 6| Step: 4
Training loss: 2.2631516456604004
Validation loss: 2.0519168479468233

Epoch: 6| Step: 5
Training loss: 2.5825157165527344
Validation loss: 2.0506393140362156

Epoch: 6| Step: 6
Training loss: 2.5541696548461914
Validation loss: 2.0526661129407984

Epoch: 6| Step: 7
Training loss: 2.538595199584961
Validation loss: 2.0491608958090506

Epoch: 6| Step: 8
Training loss: 2.5268542766571045
Validation loss: 2.0499564627165436

Epoch: 6| Step: 9
Training loss: 2.4172892570495605
Validation loss: 2.0561618112748667

Epoch: 6| Step: 10
Training loss: 2.303156852722168
Validation loss: 2.0492174343396257

Epoch: 6| Step: 11
Training loss: 2.56693959236145
Validation loss: 2.050483420330991

Epoch: 6| Step: 12
Training loss: 2.0635452270507812
Validation loss: 2.0477664573218233

Epoch: 6| Step: 13
Training loss: 2.9812822341918945
Validation loss: 2.046902305336409

Epoch: 62| Step: 0
Training loss: 1.9215048551559448
Validation loss: 2.0473168101362003

Epoch: 6| Step: 1
Training loss: 2.695894241333008
Validation loss: 2.0582123930736254

Epoch: 6| Step: 2
Training loss: 2.3233885765075684
Validation loss: 2.0501108451556136

Epoch: 6| Step: 3
Training loss: 2.5611612796783447
Validation loss: 2.0516975695087063

Epoch: 6| Step: 4
Training loss: 2.3546395301818848
Validation loss: 2.053871234258016

Epoch: 6| Step: 5
Training loss: 3.0162405967712402
Validation loss: 2.0523844790715042

Epoch: 6| Step: 6
Training loss: 2.315779209136963
Validation loss: 2.0563547047235633

Epoch: 6| Step: 7
Training loss: 2.3616461753845215
Validation loss: 2.0533855935578704

Epoch: 6| Step: 8
Training loss: 2.549278974533081
Validation loss: 2.03731595828969

Epoch: 6| Step: 9
Training loss: 2.1878340244293213
Validation loss: 2.050129557168612

Epoch: 6| Step: 10
Training loss: 2.279097557067871
Validation loss: 2.0499959914915022

Epoch: 6| Step: 11
Training loss: 3.152994155883789
Validation loss: 2.0497601775712866

Epoch: 6| Step: 12
Training loss: 2.2406811714172363
Validation loss: 2.0459082331708682

Epoch: 6| Step: 13
Training loss: 3.027313709259033
Validation loss: 2.043842366946641

Epoch: 63| Step: 0
Training loss: 2.9403157234191895
Validation loss: 2.0536385966885473

Epoch: 6| Step: 1
Training loss: 2.1634535789489746
Validation loss: 2.0404471043617494

Epoch: 6| Step: 2
Training loss: 3.0067434310913086
Validation loss: 2.0409952825115574

Epoch: 6| Step: 3
Training loss: 2.5207839012145996
Validation loss: 2.044501905800194

Epoch: 6| Step: 4
Training loss: 2.3659229278564453
Validation loss: 2.0510898610597015

Epoch: 6| Step: 5
Training loss: 2.4605348110198975
Validation loss: 2.037765941312236

Epoch: 6| Step: 6
Training loss: 2.4057562351226807
Validation loss: 2.042005036466865

Epoch: 6| Step: 7
Training loss: 2.519923686981201
Validation loss: 2.0449925750814457

Epoch: 6| Step: 8
Training loss: 2.5889477729797363
Validation loss: 2.048323690250356

Epoch: 6| Step: 9
Training loss: 2.3220832347869873
Validation loss: 2.0432038409735567

Epoch: 6| Step: 10
Training loss: 2.6043007373809814
Validation loss: 2.037096982361168

Epoch: 6| Step: 11
Training loss: 2.4881582260131836
Validation loss: 2.043110603927284

Epoch: 6| Step: 12
Training loss: 1.8859920501708984
Validation loss: 2.043353219186106

Epoch: 6| Step: 13
Training loss: 2.33359432220459
Validation loss: 2.0437391983565463

Epoch: 64| Step: 0
Training loss: 2.1612367630004883
Validation loss: 2.0454361836115518

Epoch: 6| Step: 1
Training loss: 2.0971570014953613
Validation loss: 2.0382450101196126

Epoch: 6| Step: 2
Training loss: 2.324396848678589
Validation loss: 2.046605630587506

Epoch: 6| Step: 3
Training loss: 2.792544364929199
Validation loss: 2.0430500750900595

Epoch: 6| Step: 4
Training loss: 2.223639965057373
Validation loss: 2.0383266607920327

Epoch: 6| Step: 5
Training loss: 2.232161521911621
Validation loss: 2.0456675483334448

Epoch: 6| Step: 6
Training loss: 3.254944324493408
Validation loss: 2.037732455038255

Epoch: 6| Step: 7
Training loss: 1.8854403495788574
Validation loss: 2.0466606732337707

Epoch: 6| Step: 8
Training loss: 2.6527230739593506
Validation loss: 2.0408512200078657

Epoch: 6| Step: 9
Training loss: 2.149749517440796
Validation loss: 2.0400618455743276

Epoch: 6| Step: 10
Training loss: 3.3073983192443848
Validation loss: 2.0355024747951056

Epoch: 6| Step: 11
Training loss: 2.362881660461426
Validation loss: 2.0319746014892415

Epoch: 6| Step: 12
Training loss: 2.6698148250579834
Validation loss: 2.0438274234853764

Epoch: 6| Step: 13
Training loss: 2.5374536514282227
Validation loss: 2.0389200628444715

Epoch: 65| Step: 0
Training loss: 2.8328065872192383
Validation loss: 2.0365389905950075

Epoch: 6| Step: 1
Training loss: 2.7605888843536377
Validation loss: 2.0366852514205442

Epoch: 6| Step: 2
Training loss: 2.1179733276367188
Validation loss: 2.0434364349611345

Epoch: 6| Step: 3
Training loss: 2.583965301513672
Validation loss: 2.039697990622572

Epoch: 6| Step: 4
Training loss: 1.9867795705795288
Validation loss: 2.0380810755555347

Epoch: 6| Step: 5
Training loss: 2.050262451171875
Validation loss: 2.0344773646323913

Epoch: 6| Step: 6
Training loss: 1.9852294921875
Validation loss: 2.035278207512312

Epoch: 6| Step: 7
Training loss: 2.6786203384399414
Validation loss: 2.0297506522106867

Epoch: 6| Step: 8
Training loss: 2.212174415588379
Validation loss: 2.0372623564094625

Epoch: 6| Step: 9
Training loss: 2.6300058364868164
Validation loss: 2.0341438657494

Epoch: 6| Step: 10
Training loss: 3.0180914402008057
Validation loss: 2.032834053039551

Epoch: 6| Step: 11
Training loss: 3.0105719566345215
Validation loss: 2.03068632207891

Epoch: 6| Step: 12
Training loss: 2.1042325496673584
Validation loss: 2.028158930040175

Epoch: 6| Step: 13
Training loss: 2.6520063877105713
Validation loss: 2.028444456797774

Epoch: 66| Step: 0
Training loss: 3.0106520652770996
Validation loss: 2.0335027607538367

Epoch: 6| Step: 1
Training loss: 2.2989816665649414
Validation loss: 2.0246493918921358

Epoch: 6| Step: 2
Training loss: 2.6853206157684326
Validation loss: 2.021820076050297

Epoch: 6| Step: 3
Training loss: 2.8243823051452637
Validation loss: 2.030257419873309

Epoch: 6| Step: 4
Training loss: 2.5603957176208496
Validation loss: 2.041681356327508

Epoch: 6| Step: 5
Training loss: 2.2287611961364746
Validation loss: 2.0249087797698153

Epoch: 6| Step: 6
Training loss: 2.3580572605133057
Validation loss: 2.027279496192932

Epoch: 6| Step: 7
Training loss: 2.2375130653381348
Validation loss: 2.034650787230461

Epoch: 6| Step: 8
Training loss: 2.553842782974243
Validation loss: 2.031254901680895

Epoch: 6| Step: 9
Training loss: 1.9629979133605957
Validation loss: 2.028666844931982

Epoch: 6| Step: 10
Training loss: 2.370328426361084
Validation loss: 2.038091468554671

Epoch: 6| Step: 11
Training loss: 2.519181251525879
Validation loss: 2.0365209630740586

Epoch: 6| Step: 12
Training loss: 2.7015151977539062
Validation loss: 2.0266390410802697

Epoch: 6| Step: 13
Training loss: 1.8463948965072632
Validation loss: 2.036338157551263

Epoch: 67| Step: 0
Training loss: 1.8499380350112915
Validation loss: 2.0282810221436205

Epoch: 6| Step: 1
Training loss: 2.7584638595581055
Validation loss: 2.035638581040085

Epoch: 6| Step: 2
Training loss: 2.3948824405670166
Validation loss: 2.0325396291671263

Epoch: 6| Step: 3
Training loss: 2.761422634124756
Validation loss: 2.0300650442800214

Epoch: 6| Step: 4
Training loss: 2.6007320880889893
Validation loss: 2.0324517398752193

Epoch: 6| Step: 5
Training loss: 2.4758009910583496
Validation loss: 2.0284931839153333

Epoch: 6| Step: 6
Training loss: 1.841214895248413
Validation loss: 2.0233936079086794

Epoch: 6| Step: 7
Training loss: 2.714026689529419
Validation loss: 2.03340567440115

Epoch: 6| Step: 8
Training loss: 3.1580116748809814
Validation loss: 2.0351483411686395

Epoch: 6| Step: 9
Training loss: 2.0298731327056885
Validation loss: 2.031411461932685

Epoch: 6| Step: 10
Training loss: 2.8869571685791016
Validation loss: 2.028623947533228

Epoch: 6| Step: 11
Training loss: 2.367453098297119
Validation loss: 2.0298854189534343

Epoch: 6| Step: 12
Training loss: 2.4275600910186768
Validation loss: 2.0381618776629047

Epoch: 6| Step: 13
Training loss: 1.7773551940917969
Validation loss: 2.0308703607128513

Epoch: 68| Step: 0
Training loss: 2.3928818702697754
Validation loss: 2.0287891639176237

Epoch: 6| Step: 1
Training loss: 2.5194382667541504
Validation loss: 2.035320928019862

Epoch: 6| Step: 2
Training loss: 2.334127902984619
Validation loss: 2.0330456867012927

Epoch: 6| Step: 3
Training loss: 2.5813236236572266
Validation loss: 2.030647939251315

Epoch: 6| Step: 4
Training loss: 3.079890727996826
Validation loss: 2.0196173050070323

Epoch: 6| Step: 5
Training loss: 2.172208547592163
Validation loss: 2.028506516128458

Epoch: 6| Step: 6
Training loss: 2.726212501525879
Validation loss: 2.0312953687483266

Epoch: 6| Step: 7
Training loss: 2.097658395767212
Validation loss: 2.029957789246754

Epoch: 6| Step: 8
Training loss: 2.9622550010681152
Validation loss: 2.022589856578458

Epoch: 6| Step: 9
Training loss: 2.7352890968322754
Validation loss: 2.0199971519490725

Epoch: 6| Step: 10
Training loss: 2.1854352951049805
Validation loss: 2.0276801714333157

Epoch: 6| Step: 11
Training loss: 1.9775738716125488
Validation loss: 2.010409797391584

Epoch: 6| Step: 12
Training loss: 2.231843948364258
Validation loss: 2.0314959056915773

Epoch: 6| Step: 13
Training loss: 2.2305097579956055
Validation loss: 2.0276521905775993

Epoch: 69| Step: 0
Training loss: 2.588897466659546
Validation loss: 2.0320264242028676

Epoch: 6| Step: 1
Training loss: 2.485229015350342
Validation loss: 2.025272061747889

Epoch: 6| Step: 2
Training loss: 1.9493041038513184
Validation loss: 2.028704268957979

Epoch: 6| Step: 3
Training loss: 3.102534294128418
Validation loss: 2.0285956295587684

Epoch: 6| Step: 4
Training loss: 2.1644766330718994
Validation loss: 2.0200128170751754

Epoch: 6| Step: 5
Training loss: 2.7316086292266846
Validation loss: 2.0157733783927014

Epoch: 6| Step: 6
Training loss: 3.3109424114227295
Validation loss: 2.0179595895992812

Epoch: 6| Step: 7
Training loss: 2.1767666339874268
Validation loss: 2.0208459656725646

Epoch: 6| Step: 8
Training loss: 2.4448366165161133
Validation loss: 2.0251297284198064

Epoch: 6| Step: 9
Training loss: 1.7953267097473145
Validation loss: 2.0192351084883495

Epoch: 6| Step: 10
Training loss: 2.629727840423584
Validation loss: 2.0146499808116625

Epoch: 6| Step: 11
Training loss: 2.3365044593811035
Validation loss: 2.015163201157765

Epoch: 6| Step: 12
Training loss: 2.075920581817627
Validation loss: 2.024426419247863

Epoch: 6| Step: 13
Training loss: 2.520103693008423
Validation loss: 2.019342109721194

Epoch: 70| Step: 0
Training loss: 2.4351649284362793
Validation loss: 2.031286585715509

Epoch: 6| Step: 1
Training loss: 2.7623672485351562
Validation loss: 2.033390978331207

Epoch: 6| Step: 2
Training loss: 2.53175950050354
Validation loss: 2.0218406172208887

Epoch: 6| Step: 3
Training loss: 2.34407377243042
Validation loss: 2.022616781214232

Epoch: 6| Step: 4
Training loss: 2.3331680297851562
Validation loss: 2.0138970164842505

Epoch: 6| Step: 5
Training loss: 2.3420448303222656
Validation loss: 2.0062019927527315

Epoch: 6| Step: 6
Training loss: 2.293545722961426
Validation loss: 2.0223603415232834

Epoch: 6| Step: 7
Training loss: 2.1030232906341553
Validation loss: 2.029761296446605

Epoch: 6| Step: 8
Training loss: 2.5588836669921875
Validation loss: 2.0099986778792513

Epoch: 6| Step: 9
Training loss: 2.7170352935791016
Validation loss: 2.0161952023865073

Epoch: 6| Step: 10
Training loss: 2.3365650177001953
Validation loss: 2.016841680772843

Epoch: 6| Step: 11
Training loss: 2.157046318054199
Validation loss: 2.0258100468625306

Epoch: 6| Step: 12
Training loss: 2.7503209114074707
Validation loss: 2.0209633355499594

Epoch: 6| Step: 13
Training loss: 2.665764331817627
Validation loss: 2.010300423509331

Epoch: 71| Step: 0
Training loss: 2.6094539165496826
Validation loss: 2.0115385388815277

Epoch: 6| Step: 1
Training loss: 2.8062551021575928
Validation loss: 2.0190807004128732

Epoch: 6| Step: 2
Training loss: 1.791733980178833
Validation loss: 2.008673603816699

Epoch: 6| Step: 3
Training loss: 2.4966206550598145
Validation loss: 2.0267297503768757

Epoch: 6| Step: 4
Training loss: 2.286068916320801
Validation loss: 2.018296016159878

Epoch: 6| Step: 5
Training loss: 2.7529983520507812
Validation loss: 2.0126502924068

Epoch: 6| Step: 6
Training loss: 2.2586472034454346
Validation loss: 2.0228762934284825

Epoch: 6| Step: 7
Training loss: 2.201296806335449
Validation loss: 2.0215848415128645

Epoch: 6| Step: 8
Training loss: 2.3441131114959717
Validation loss: 2.0112816056897564

Epoch: 6| Step: 9
Training loss: 2.759018898010254
Validation loss: 2.0185358537140714

Epoch: 6| Step: 10
Training loss: 2.294252634048462
Validation loss: 2.013254665559338

Epoch: 6| Step: 11
Training loss: 3.0962815284729004
Validation loss: 2.016432144308603

Epoch: 6| Step: 12
Training loss: 2.037797451019287
Validation loss: 2.018022237285491

Epoch: 6| Step: 13
Training loss: 2.5034821033477783
Validation loss: 2.0168981193214335

Epoch: 72| Step: 0
Training loss: 2.523862838745117
Validation loss: 2.0097098247979277

Epoch: 6| Step: 1
Training loss: 2.3100123405456543
Validation loss: 2.0120334817517187

Epoch: 6| Step: 2
Training loss: 2.1339919567108154
Validation loss: 2.010267074390124

Epoch: 6| Step: 3
Training loss: 2.4139926433563232
Validation loss: 2.0120832048436648

Epoch: 6| Step: 4
Training loss: 2.267451286315918
Validation loss: 2.011968412706929

Epoch: 6| Step: 5
Training loss: 1.906580924987793
Validation loss: 2.007978029148553

Epoch: 6| Step: 6
Training loss: 3.138758897781372
Validation loss: 2.008364333901354

Epoch: 6| Step: 7
Training loss: 2.9066572189331055
Validation loss: 2.0104680189522366

Epoch: 6| Step: 8
Training loss: 2.3770933151245117
Validation loss: 2.003685648723315

Epoch: 6| Step: 9
Training loss: 2.644618272781372
Validation loss: 2.0202155933585217

Epoch: 6| Step: 10
Training loss: 2.410081386566162
Validation loss: 2.019609639721532

Epoch: 6| Step: 11
Training loss: 2.834972858428955
Validation loss: 2.005252230551935

Epoch: 6| Step: 12
Training loss: 1.7299764156341553
Validation loss: 2.005766830136699

Epoch: 6| Step: 13
Training loss: 2.3682703971862793
Validation loss: 2.0065932953229515

Epoch: 73| Step: 0
Training loss: 1.8963466882705688
Validation loss: 2.0046132469689972

Epoch: 6| Step: 1
Training loss: 2.668278932571411
Validation loss: 2.0053990246147237

Epoch: 6| Step: 2
Training loss: 2.5975794792175293
Validation loss: 1.9966306814583399

Epoch: 6| Step: 3
Training loss: 2.5380868911743164
Validation loss: 1.999661212326378

Epoch: 6| Step: 4
Training loss: 2.3418664932250977
Validation loss: 1.9949522569615354

Epoch: 6| Step: 5
Training loss: 2.4099907875061035
Validation loss: 1.9989293877796461

Epoch: 6| Step: 6
Training loss: 3.7281839847564697
Validation loss: 1.9964142037976174

Epoch: 6| Step: 7
Training loss: 2.259169340133667
Validation loss: 1.993004962962161

Epoch: 6| Step: 8
Training loss: 1.754009485244751
Validation loss: 2.000873972010869

Epoch: 6| Step: 9
Training loss: 2.196901798248291
Validation loss: 2.0038644549667195

Epoch: 6| Step: 10
Training loss: 2.272688865661621
Validation loss: 1.992022962980373

Epoch: 6| Step: 11
Training loss: 2.0928962230682373
Validation loss: 2.0074791010989936

Epoch: 6| Step: 12
Training loss: 2.4937753677368164
Validation loss: 2.0012836379389607

Epoch: 6| Step: 13
Training loss: 2.9874675273895264
Validation loss: 1.9966132256292528

Epoch: 74| Step: 0
Training loss: 2.0899252891540527
Validation loss: 1.988328056950723

Epoch: 6| Step: 1
Training loss: 2.6064603328704834
Validation loss: 1.991467668164161

Epoch: 6| Step: 2
Training loss: 1.951355218887329
Validation loss: 2.007696808025401

Epoch: 6| Step: 3
Training loss: 2.265909194946289
Validation loss: 1.9985931560557375

Epoch: 6| Step: 4
Training loss: 3.4383232593536377
Validation loss: 1.998766517126432

Epoch: 6| Step: 5
Training loss: 2.049306869506836
Validation loss: 2.0005619256727156

Epoch: 6| Step: 6
Training loss: 2.487086296081543
Validation loss: 2.0090089997937604

Epoch: 6| Step: 7
Training loss: 2.490203619003296
Validation loss: 1.9909714524463942

Epoch: 6| Step: 8
Training loss: 2.3833093643188477
Validation loss: 2.0064490046552432

Epoch: 6| Step: 9
Training loss: 1.9425698518753052
Validation loss: 1.9998696209282003

Epoch: 6| Step: 10
Training loss: 2.2116334438323975
Validation loss: 1.9966312980139127

Epoch: 6| Step: 11
Training loss: 2.3797361850738525
Validation loss: 2.014540115992228

Epoch: 6| Step: 12
Training loss: 3.2943115234375
Validation loss: 1.9993915570679532

Epoch: 6| Step: 13
Training loss: 1.923341155052185
Validation loss: 1.9963186915202806

Epoch: 75| Step: 0
Training loss: 2.938999652862549
Validation loss: 1.9890342066364903

Epoch: 6| Step: 1
Training loss: 2.457442283630371
Validation loss: 2.0032644041122927

Epoch: 6| Step: 2
Training loss: 3.2778072357177734
Validation loss: 1.9952434468012985

Epoch: 6| Step: 3
Training loss: 2.167548179626465
Validation loss: 2.0019420859634236

Epoch: 6| Step: 4
Training loss: 1.672222375869751
Validation loss: 1.988765129479029

Epoch: 6| Step: 5
Training loss: 2.31056547164917
Validation loss: 1.988033975324323

Epoch: 6| Step: 6
Training loss: 2.6316521167755127
Validation loss: 2.0014055082874913

Epoch: 6| Step: 7
Training loss: 2.7922003269195557
Validation loss: 1.9997710707367107

Epoch: 6| Step: 8
Training loss: 2.3182570934295654
Validation loss: 1.9980514023893623

Epoch: 6| Step: 9
Training loss: 1.6964447498321533
Validation loss: 1.992894781533108

Epoch: 6| Step: 10
Training loss: 2.522707939147949
Validation loss: 1.989046109619961

Epoch: 6| Step: 11
Training loss: 2.2323920726776123
Validation loss: 1.9826667795899093

Epoch: 6| Step: 12
Training loss: 2.2452127933502197
Validation loss: 2.008959601002355

Epoch: 6| Step: 13
Training loss: 2.5329060554504395
Validation loss: 1.9888737688782394

Epoch: 76| Step: 0
Training loss: 2.3959131240844727
Validation loss: 1.9906009038289387

Epoch: 6| Step: 1
Training loss: 2.606814384460449
Validation loss: 1.9847265610130884

Epoch: 6| Step: 2
Training loss: 2.285613536834717
Validation loss: 1.9872977861794092

Epoch: 6| Step: 3
Training loss: 2.746086597442627
Validation loss: 1.988802598368737

Epoch: 6| Step: 4
Training loss: 1.688549280166626
Validation loss: 1.987298857781195

Epoch: 6| Step: 5
Training loss: 2.6295008659362793
Validation loss: 2.012038597496607

Epoch: 6| Step: 6
Training loss: 1.9564636945724487
Validation loss: 1.9901270071665447

Epoch: 6| Step: 7
Training loss: 2.6262807846069336
Validation loss: 1.998397542584327

Epoch: 6| Step: 8
Training loss: 2.982975482940674
Validation loss: 1.9987201677855624

Epoch: 6| Step: 9
Training loss: 2.6790711879730225
Validation loss: 1.9834240995427614

Epoch: 6| Step: 10
Training loss: 2.2795424461364746
Validation loss: 2.0004455966334187

Epoch: 6| Step: 11
Training loss: 2.4205875396728516
Validation loss: 1.9913003175489363

Epoch: 6| Step: 12
Training loss: 2.2669196128845215
Validation loss: 1.9957916377693095

Epoch: 6| Step: 13
Training loss: 2.0331881046295166
Validation loss: 1.989896276945709

Epoch: 77| Step: 0
Training loss: 2.838897228240967
Validation loss: 1.988738827807929

Epoch: 6| Step: 1
Training loss: 1.6270742416381836
Validation loss: 1.9846857875906012

Epoch: 6| Step: 2
Training loss: 2.280238628387451
Validation loss: 1.9885514320865754

Epoch: 6| Step: 3
Training loss: 2.3055927753448486
Validation loss: 1.9915662209192913

Epoch: 6| Step: 4
Training loss: 3.052523136138916
Validation loss: 1.9844107845778107

Epoch: 6| Step: 5
Training loss: 2.415851354598999
Validation loss: 1.9853572922368203

Epoch: 6| Step: 6
Training loss: 2.371501922607422
Validation loss: 1.9715269086181477

Epoch: 6| Step: 7
Training loss: 2.4551403522491455
Validation loss: 1.980050850940007

Epoch: 6| Step: 8
Training loss: 2.3061556816101074
Validation loss: 1.9933873889266804

Epoch: 6| Step: 9
Training loss: 2.06270694732666
Validation loss: 1.976822510842354

Epoch: 6| Step: 10
Training loss: 2.1727755069732666
Validation loss: 1.9902977751147362

Epoch: 6| Step: 11
Training loss: 2.718482494354248
Validation loss: 1.984053865555794

Epoch: 6| Step: 12
Training loss: 2.8131394386291504
Validation loss: 1.974510560753525

Epoch: 6| Step: 13
Training loss: 2.0729517936706543
Validation loss: 1.9717228745901456

Epoch: 78| Step: 0
Training loss: 2.214287519454956
Validation loss: 1.9746036132176716

Epoch: 6| Step: 1
Training loss: 2.1987528800964355
Validation loss: 1.9737333136220132

Epoch: 6| Step: 2
Training loss: 3.0131309032440186
Validation loss: 1.9730507302027878

Epoch: 6| Step: 3
Training loss: 2.3777294158935547
Validation loss: 1.9722702221203876

Epoch: 6| Step: 4
Training loss: 2.454263687133789
Validation loss: 1.995072563489278

Epoch: 6| Step: 5
Training loss: 2.489147186279297
Validation loss: 1.9736957703867266

Epoch: 6| Step: 6
Training loss: 1.970552921295166
Validation loss: 1.9766500047458115

Epoch: 6| Step: 7
Training loss: 1.4612784385681152
Validation loss: 1.9835950020820863

Epoch: 6| Step: 8
Training loss: 2.3123083114624023
Validation loss: 1.9686116608240272

Epoch: 6| Step: 9
Training loss: 1.8635785579681396
Validation loss: 1.9718495312557425

Epoch: 6| Step: 10
Training loss: 2.579948902130127
Validation loss: 1.974821356035048

Epoch: 6| Step: 11
Training loss: 3.042154312133789
Validation loss: 1.9795464418267692

Epoch: 6| Step: 12
Training loss: 3.13578724861145
Validation loss: 1.9702613610093311

Epoch: 6| Step: 13
Training loss: 2.4196438789367676
Validation loss: 2.0010643646281254

Epoch: 79| Step: 0
Training loss: 2.785522937774658
Validation loss: 1.9760556067189863

Epoch: 6| Step: 1
Training loss: 2.429083824157715
Validation loss: 1.9796197875853507

Epoch: 6| Step: 2
Training loss: 1.9431865215301514
Validation loss: 1.9810552955955587

Epoch: 6| Step: 3
Training loss: 2.0412511825561523
Validation loss: 1.9862670757437264

Epoch: 6| Step: 4
Training loss: 2.6623525619506836
Validation loss: 1.98179417656314

Epoch: 6| Step: 5
Training loss: 2.434429883956909
Validation loss: 1.977561867365273

Epoch: 6| Step: 6
Training loss: 2.2600488662719727
Validation loss: 1.975259837283883

Epoch: 6| Step: 7
Training loss: 2.2314672470092773
Validation loss: 1.9812940602661462

Epoch: 6| Step: 8
Training loss: 2.049257278442383
Validation loss: 1.980358144288422

Epoch: 6| Step: 9
Training loss: 2.6416006088256836
Validation loss: 1.964314345390566

Epoch: 6| Step: 10
Training loss: 2.3053791522979736
Validation loss: 1.977005982911715

Epoch: 6| Step: 11
Training loss: 2.824990749359131
Validation loss: 1.9787216622342345

Epoch: 6| Step: 12
Training loss: 2.4545717239379883
Validation loss: 1.9759159703408518

Epoch: 6| Step: 13
Training loss: 2.320801258087158
Validation loss: 1.9725347539430023

Epoch: 80| Step: 0
Training loss: 2.0748579502105713
Validation loss: 1.9687134424845378

Epoch: 6| Step: 1
Training loss: 2.898711681365967
Validation loss: 1.9754669538108252

Epoch: 6| Step: 2
Training loss: 2.0262246131896973
Validation loss: 1.9649328993212791

Epoch: 6| Step: 3
Training loss: 2.720961570739746
Validation loss: 1.9690191130484305

Epoch: 6| Step: 4
Training loss: 2.7968506813049316
Validation loss: 1.9739626953678746

Epoch: 6| Step: 5
Training loss: 2.570246696472168
Validation loss: 1.9767340024312336

Epoch: 6| Step: 6
Training loss: 2.416290760040283
Validation loss: 1.9588672576412078

Epoch: 6| Step: 7
Training loss: 2.535651683807373
Validation loss: 1.9716044869474185

Epoch: 6| Step: 8
Training loss: 2.435487985610962
Validation loss: 1.9680624508088636

Epoch: 6| Step: 9
Training loss: 2.543782949447632
Validation loss: 1.9633896312405985

Epoch: 6| Step: 10
Training loss: 1.5962969064712524
Validation loss: 1.9558018945878552

Epoch: 6| Step: 11
Training loss: 2.3819756507873535
Validation loss: 1.9629396776999197

Epoch: 6| Step: 12
Training loss: 2.0027806758880615
Validation loss: 1.9596093085504347

Epoch: 6| Step: 13
Training loss: 2.034468650817871
Validation loss: 1.9625920454661052

Epoch: 81| Step: 0
Training loss: 2.6319997310638428
Validation loss: 1.9594505448495187

Epoch: 6| Step: 1
Training loss: 2.373800754547119
Validation loss: 1.969460807820802

Epoch: 6| Step: 2
Training loss: 2.3557167053222656
Validation loss: 1.9559760298780215

Epoch: 6| Step: 3
Training loss: 2.7792835235595703
Validation loss: 1.9549844752075851

Epoch: 6| Step: 4
Training loss: 2.3657310009002686
Validation loss: 1.9703112443288167

Epoch: 6| Step: 5
Training loss: 2.6999716758728027
Validation loss: 1.971108603221114

Epoch: 6| Step: 6
Training loss: 2.7816519737243652
Validation loss: 1.953779851236651

Epoch: 6| Step: 7
Training loss: 2.2398087978363037
Validation loss: 1.9491986151664489

Epoch: 6| Step: 8
Training loss: 2.0283052921295166
Validation loss: 1.9756729987359816

Epoch: 6| Step: 9
Training loss: 1.9502449035644531
Validation loss: 1.968470691352762

Epoch: 6| Step: 10
Training loss: 2.5931777954101562
Validation loss: 1.948674532674974

Epoch: 6| Step: 11
Training loss: 1.6118659973144531
Validation loss: 1.9489817952597013

Epoch: 6| Step: 12
Training loss: 2.405390977859497
Validation loss: 1.9458046754201253

Epoch: 6| Step: 13
Training loss: 2.1114423274993896
Validation loss: 1.9496803693873908

Epoch: 82| Step: 0
Training loss: 1.6191420555114746
Validation loss: 1.9589204493389334

Epoch: 6| Step: 1
Training loss: 3.0503108501434326
Validation loss: 1.950814567586427

Epoch: 6| Step: 2
Training loss: 2.925755023956299
Validation loss: 1.9604386719324256

Epoch: 6| Step: 3
Training loss: 2.5201706886291504
Validation loss: 1.966331261460499

Epoch: 6| Step: 4
Training loss: 2.6106696128845215
Validation loss: 1.9527308556341356

Epoch: 6| Step: 5
Training loss: 2.260788917541504
Validation loss: 1.950539488946238

Epoch: 6| Step: 6
Training loss: 2.2466015815734863
Validation loss: 1.951602940918297

Epoch: 6| Step: 7
Training loss: 2.457801342010498
Validation loss: 1.9585657119750977

Epoch: 6| Step: 8
Training loss: 1.9428222179412842
Validation loss: 1.9628052493577361

Epoch: 6| Step: 9
Training loss: 2.0697712898254395
Validation loss: 1.9346273470950384

Epoch: 6| Step: 10
Training loss: 2.5754387378692627
Validation loss: 1.9512971985724665

Epoch: 6| Step: 11
Training loss: 2.1475229263305664
Validation loss: 1.936625244796917

Epoch: 6| Step: 12
Training loss: 1.9607880115509033
Validation loss: 1.9483294820272794

Epoch: 6| Step: 13
Training loss: 3.0199475288391113
Validation loss: 1.956898917434036

Epoch: 83| Step: 0
Training loss: 1.5959768295288086
Validation loss: 1.964014063599289

Epoch: 6| Step: 1
Training loss: 2.531416893005371
Validation loss: 1.9322070511438514

Epoch: 6| Step: 2
Training loss: 2.1385068893432617
Validation loss: 1.945557548153785

Epoch: 6| Step: 3
Training loss: 2.5313613414764404
Validation loss: 1.9147043561422696

Epoch: 6| Step: 4
Training loss: 2.5050368309020996
Validation loss: 1.9627630210691882

Epoch: 6| Step: 5
Training loss: 2.3631463050842285
Validation loss: 1.9373986810766242

Epoch: 6| Step: 6
Training loss: 2.5422651767730713
Validation loss: 1.954195155892321

Epoch: 6| Step: 7
Training loss: 2.6413509845733643
Validation loss: 1.9400473589538245

Epoch: 6| Step: 8
Training loss: 2.929582118988037
Validation loss: 1.9245202259350849

Epoch: 6| Step: 9
Training loss: 2.3402018547058105
Validation loss: 1.9241125199102587

Epoch: 6| Step: 10
Training loss: 2.028938055038452
Validation loss: 1.9272528066430041

Epoch: 6| Step: 11
Training loss: 2.064884662628174
Validation loss: 1.947113831837972

Epoch: 6| Step: 12
Training loss: 2.029219627380371
Validation loss: 1.9242390048119329

Epoch: 6| Step: 13
Training loss: 2.860630512237549
Validation loss: 1.932932537089112

Epoch: 84| Step: 0
Training loss: 2.4262547492980957
Validation loss: 1.9277782222276092

Epoch: 6| Step: 1
Training loss: 2.6867783069610596
Validation loss: 1.955237183519589

Epoch: 6| Step: 2
Training loss: 2.2772374153137207
Validation loss: 1.943402204462277

Epoch: 6| Step: 3
Training loss: 2.317695140838623
Validation loss: 1.9378937944289176

Epoch: 6| Step: 4
Training loss: 2.373922824859619
Validation loss: 1.942346513912242

Epoch: 6| Step: 5
Training loss: 3.196617603302002
Validation loss: 1.9298109021238101

Epoch: 6| Step: 6
Training loss: 2.7444510459899902
Validation loss: 1.9543661943045996

Epoch: 6| Step: 7
Training loss: 2.2537858486175537
Validation loss: 1.9415916114725091

Epoch: 6| Step: 8
Training loss: 2.063387155532837
Validation loss: 1.9320155561611216

Epoch: 6| Step: 9
Training loss: 1.8178943395614624
Validation loss: 1.9412336926306448

Epoch: 6| Step: 10
Training loss: 2.1548233032226562
Validation loss: 1.9336570014235794

Epoch: 6| Step: 11
Training loss: 2.148240566253662
Validation loss: 1.942150923513597

Epoch: 6| Step: 12
Training loss: 2.2605786323547363
Validation loss: 1.9421703584732548

Epoch: 6| Step: 13
Training loss: 1.9305979013442993
Validation loss: 1.9466626951771397

Epoch: 85| Step: 0
Training loss: 1.8385452032089233
Validation loss: 1.9539548325282272

Epoch: 6| Step: 1
Training loss: 2.5857930183410645
Validation loss: 1.943624278550507

Epoch: 6| Step: 2
Training loss: 2.276341438293457
Validation loss: 1.9425790361178819

Epoch: 6| Step: 3
Training loss: 3.297297954559326
Validation loss: 1.9276305629361061

Epoch: 6| Step: 4
Training loss: 2.705702781677246
Validation loss: 1.9485904811530985

Epoch: 6| Step: 5
Training loss: 2.2930591106414795
Validation loss: 1.9288544142118065

Epoch: 6| Step: 6
Training loss: 2.558000087738037
Validation loss: 1.9370274953944708

Epoch: 6| Step: 7
Training loss: 1.5617895126342773
Validation loss: 1.9385678281066239

Epoch: 6| Step: 8
Training loss: 2.6061041355133057
Validation loss: 1.9266305943971038

Epoch: 6| Step: 9
Training loss: 2.2069289684295654
Validation loss: 1.9394468543350056

Epoch: 6| Step: 10
Training loss: 2.173959255218506
Validation loss: 1.9260068760123303

Epoch: 6| Step: 11
Training loss: 1.7507960796356201
Validation loss: 1.9406834469046643

Epoch: 6| Step: 12
Training loss: 2.181912899017334
Validation loss: 1.9344668772912794

Epoch: 6| Step: 13
Training loss: 2.740457534790039
Validation loss: 1.9380140766020744

Epoch: 86| Step: 0
Training loss: 2.705306053161621
Validation loss: 1.9197167529854724

Epoch: 6| Step: 1
Training loss: 2.5041050910949707
Validation loss: 1.9188223192768712

Epoch: 6| Step: 2
Training loss: 2.0320239067077637
Validation loss: 1.9159358137397355

Epoch: 6| Step: 3
Training loss: 2.0652754306793213
Validation loss: 1.9077536867510887

Epoch: 6| Step: 4
Training loss: 2.567492961883545
Validation loss: 1.9151197287344164

Epoch: 6| Step: 5
Training loss: 1.730364203453064
Validation loss: 1.9348986046288603

Epoch: 6| Step: 6
Training loss: 2.954904556274414
Validation loss: 1.9096164165004608

Epoch: 6| Step: 7
Training loss: 2.7304866313934326
Validation loss: 1.902935976623207

Epoch: 6| Step: 8
Training loss: 2.118969678878784
Validation loss: 1.9140798455925399

Epoch: 6| Step: 9
Training loss: 2.719900608062744
Validation loss: 1.9181467897148543

Epoch: 6| Step: 10
Training loss: 1.7705509662628174
Validation loss: 1.9227416028258622

Epoch: 6| Step: 11
Training loss: 1.7936781644821167
Validation loss: 1.892399421302221

Epoch: 6| Step: 12
Training loss: 1.8775286674499512
Validation loss: 1.9089554817445817

Epoch: 6| Step: 13
Training loss: 3.2322914600372314
Validation loss: 1.9157043067357873

Epoch: 87| Step: 0
Training loss: 2.5632359981536865
Validation loss: 1.942766333139071

Epoch: 6| Step: 1
Training loss: 2.339751720428467
Validation loss: 1.926896273448903

Epoch: 6| Step: 2
Training loss: 2.0567407608032227
Validation loss: 1.894291562418784

Epoch: 6| Step: 3
Training loss: 2.2160229682922363
Validation loss: 1.9343213394124021

Epoch: 6| Step: 4
Training loss: 2.074363946914673
Validation loss: 1.8971396748737623

Epoch: 6| Step: 5
Training loss: 2.237405300140381
Validation loss: 1.904215822937668

Epoch: 6| Step: 6
Training loss: 2.255272388458252
Validation loss: 1.9337064643060007

Epoch: 6| Step: 7
Training loss: 2.7734789848327637
Validation loss: 1.915357151339131

Epoch: 6| Step: 8
Training loss: 2.151139259338379
Validation loss: 1.9213320132224792

Epoch: 6| Step: 9
Training loss: 2.2928848266601562
Validation loss: 1.9218728209054599

Epoch: 6| Step: 10
Training loss: 2.519596815109253
Validation loss: 1.9037820728876258

Epoch: 6| Step: 11
Training loss: 2.507615804672241
Validation loss: 1.9238841328569638

Epoch: 6| Step: 12
Training loss: 2.075761079788208
Validation loss: 1.9377238750457764

Epoch: 6| Step: 13
Training loss: 2.153055429458618
Validation loss: 1.921877359831205

Epoch: 88| Step: 0
Training loss: 2.7003769874572754
Validation loss: 1.9294566851790234

Epoch: 6| Step: 1
Training loss: 1.9859037399291992
Validation loss: 1.939686982862411

Epoch: 6| Step: 2
Training loss: 2.723496913909912
Validation loss: 1.9206603111759308

Epoch: 6| Step: 3
Training loss: 2.8610219955444336
Validation loss: 1.9215705843381985

Epoch: 6| Step: 4
Training loss: 1.9557433128356934
Validation loss: 1.9316379716319423

Epoch: 6| Step: 5
Training loss: 2.40155291557312
Validation loss: 1.9296750073791833

Epoch: 6| Step: 6
Training loss: 2.2305731773376465
Validation loss: 1.9407752085757513

Epoch: 6| Step: 7
Training loss: 1.9665765762329102
Validation loss: 1.9177806608138546

Epoch: 6| Step: 8
Training loss: 1.860145926475525
Validation loss: 1.9167764315041163

Epoch: 6| Step: 9
Training loss: 2.5557703971862793
Validation loss: 1.9256778429913264

Epoch: 6| Step: 10
Training loss: 1.9235961437225342
Validation loss: 1.9199424789797874

Epoch: 6| Step: 11
Training loss: 2.640824794769287
Validation loss: 1.8970381457318541

Epoch: 6| Step: 12
Training loss: 1.8482666015625
Validation loss: 1.9017160041357881

Epoch: 6| Step: 13
Training loss: 2.394291400909424
Validation loss: 1.9231326221137919

Epoch: 89| Step: 0
Training loss: 1.8162044286727905
Validation loss: 1.90746864580339

Epoch: 6| Step: 1
Training loss: 2.5175065994262695
Validation loss: 1.9202494672549668

Epoch: 6| Step: 2
Training loss: 2.1963489055633545
Validation loss: 1.9106194408991004

Epoch: 6| Step: 3
Training loss: 3.0127320289611816
Validation loss: 1.9113422927036081

Epoch: 6| Step: 4
Training loss: 2.4789016246795654
Validation loss: 1.8949845939554193

Epoch: 6| Step: 5
Training loss: 2.5123753547668457
Validation loss: 1.9178578827970771

Epoch: 6| Step: 6
Training loss: 2.1320831775665283
Validation loss: 1.9238955961760653

Epoch: 6| Step: 7
Training loss: 2.5134265422821045
Validation loss: 1.9005365781886603

Epoch: 6| Step: 8
Training loss: 1.9852361679077148
Validation loss: 1.9088345612249067

Epoch: 6| Step: 9
Training loss: 2.6669774055480957
Validation loss: 1.9076756726029098

Epoch: 6| Step: 10
Training loss: 2.0373876094818115
Validation loss: 1.928862666571012

Epoch: 6| Step: 11
Training loss: 2.389624834060669
Validation loss: 1.9228527187019266

Epoch: 6| Step: 12
Training loss: 1.5161689519882202
Validation loss: 1.9185831341692197

Epoch: 6| Step: 13
Training loss: 2.2033963203430176
Validation loss: 1.896617486912717

Epoch: 90| Step: 0
Training loss: 2.4997692108154297
Validation loss: 1.8988340234243741

Epoch: 6| Step: 1
Training loss: 1.9104490280151367
Validation loss: 1.9179619102067844

Epoch: 6| Step: 2
Training loss: 1.77578604221344
Validation loss: 1.8950676853938768

Epoch: 6| Step: 3
Training loss: 2.2569940090179443
Validation loss: 1.900864734444567

Epoch: 6| Step: 4
Training loss: 2.278959274291992
Validation loss: 1.8870287877257153

Epoch: 6| Step: 5
Training loss: 2.675105571746826
Validation loss: 1.9117344323024954

Epoch: 6| Step: 6
Training loss: 2.255380153656006
Validation loss: 1.893308824108493

Epoch: 6| Step: 7
Training loss: 1.7558043003082275
Validation loss: 1.884778025329754

Epoch: 6| Step: 8
Training loss: 1.8893498182296753
Validation loss: 1.896896162340718

Epoch: 6| Step: 9
Training loss: 2.6012887954711914
Validation loss: 1.8732287550485263

Epoch: 6| Step: 10
Training loss: 2.859821319580078
Validation loss: 1.886088212331136

Epoch: 6| Step: 11
Training loss: 2.637608289718628
Validation loss: 1.8913370255501039

Epoch: 6| Step: 12
Training loss: 2.081651210784912
Validation loss: 1.8872122303132088

Epoch: 6| Step: 13
Training loss: 2.277052402496338
Validation loss: 1.910578868722403

Epoch: 91| Step: 0
Training loss: 2.1600852012634277
Validation loss: 1.893284587449925

Epoch: 6| Step: 1
Training loss: 2.284550666809082
Validation loss: 1.9019551200251426

Epoch: 6| Step: 2
Training loss: 2.160597801208496
Validation loss: 1.8967376908948343

Epoch: 6| Step: 3
Training loss: 2.3750991821289062
Validation loss: 1.8846612335533224

Epoch: 6| Step: 4
Training loss: 2.2158637046813965
Validation loss: 1.8946790784917853

Epoch: 6| Step: 5
Training loss: 3.053515672683716
Validation loss: 1.9098518535655031

Epoch: 6| Step: 6
Training loss: 2.1359739303588867
Validation loss: 1.899866041316781

Epoch: 6| Step: 7
Training loss: 2.1786961555480957
Validation loss: 1.8967482428396902

Epoch: 6| Step: 8
Training loss: 1.763416051864624
Validation loss: 1.9093232885483773

Epoch: 6| Step: 9
Training loss: 1.9684319496154785
Validation loss: 1.9133353002609745

Epoch: 6| Step: 10
Training loss: 2.1573729515075684
Validation loss: 1.8842098674466532

Epoch: 6| Step: 11
Training loss: 2.7537131309509277
Validation loss: 1.8818594460846276

Epoch: 6| Step: 12
Training loss: 2.4265363216400146
Validation loss: 1.9015628701897078

Epoch: 6| Step: 13
Training loss: 1.79526686668396
Validation loss: 1.8843481027951805

Epoch: 92| Step: 0
Training loss: 2.2709429264068604
Validation loss: 1.8937574971106745

Epoch: 6| Step: 1
Training loss: 2.4979052543640137
Validation loss: 1.8921236235608336

Epoch: 6| Step: 2
Training loss: 2.2744734287261963
Validation loss: 1.897280002153048

Epoch: 6| Step: 3
Training loss: 2.4149017333984375
Validation loss: 1.8852949437274729

Epoch: 6| Step: 4
Training loss: 2.129343032836914
Validation loss: 1.922932182588885

Epoch: 6| Step: 5
Training loss: 2.2908952236175537
Validation loss: 1.8792525440134027

Epoch: 6| Step: 6
Training loss: 2.044440984725952
Validation loss: 1.8822014639454503

Epoch: 6| Step: 7
Training loss: 2.3277902603149414
Validation loss: 1.8835668461297148

Epoch: 6| Step: 8
Training loss: 2.127284288406372
Validation loss: 1.9156326106799546

Epoch: 6| Step: 9
Training loss: 2.4604332447052
Validation loss: 1.8886690421770977

Epoch: 6| Step: 10
Training loss: 2.2706263065338135
Validation loss: 1.875793130167069

Epoch: 6| Step: 11
Training loss: 2.40748929977417
Validation loss: 1.8933365960274973

Epoch: 6| Step: 12
Training loss: 1.9907406568527222
Validation loss: 1.9010564152912428

Epoch: 6| Step: 13
Training loss: 1.9731316566467285
Validation loss: 1.8745790155985023

Epoch: 93| Step: 0
Training loss: 2.4040300846099854
Validation loss: 1.9046334579426756

Epoch: 6| Step: 1
Training loss: 2.6844983100891113
Validation loss: 1.8755545436695058

Epoch: 6| Step: 2
Training loss: 2.3841519355773926
Validation loss: 1.8941043807614235

Epoch: 6| Step: 3
Training loss: 1.2965319156646729
Validation loss: 1.8900147996922976

Epoch: 6| Step: 4
Training loss: 2.306058645248413
Validation loss: 1.889635338578173

Epoch: 6| Step: 5
Training loss: 2.4482345581054688
Validation loss: 1.918157353196093

Epoch: 6| Step: 6
Training loss: 1.688948154449463
Validation loss: 1.880777100081085

Epoch: 6| Step: 7
Training loss: 2.31430721282959
Validation loss: 1.9050037437869656

Epoch: 6| Step: 8
Training loss: 2.970628023147583
Validation loss: 1.9051198600440897

Epoch: 6| Step: 9
Training loss: 2.1892900466918945
Validation loss: 1.9074946782922233

Epoch: 6| Step: 10
Training loss: 2.067077398300171
Validation loss: 1.8898343258006598

Epoch: 6| Step: 11
Training loss: 1.9859381914138794
Validation loss: 1.8771404322757517

Epoch: 6| Step: 12
Training loss: 2.217482566833496
Validation loss: 1.9045960339166785

Epoch: 6| Step: 13
Training loss: 2.673637866973877
Validation loss: 1.906451980272929

Epoch: 94| Step: 0
Training loss: 2.531484842300415
Validation loss: 1.8853257804788568

Epoch: 6| Step: 1
Training loss: 2.347970962524414
Validation loss: 1.8922622152554092

Epoch: 6| Step: 2
Training loss: 2.2446084022521973
Validation loss: 1.8689267507163427

Epoch: 6| Step: 3
Training loss: 1.899751901626587
Validation loss: 1.8922272407880394

Epoch: 6| Step: 4
Training loss: 2.259526014328003
Validation loss: 1.9038830354649534

Epoch: 6| Step: 5
Training loss: 2.048482894897461
Validation loss: 1.8671171306281962

Epoch: 6| Step: 6
Training loss: 1.79567289352417
Validation loss: 1.883665987240371

Epoch: 6| Step: 7
Training loss: 2.050640106201172
Validation loss: 1.885788732959378

Epoch: 6| Step: 8
Training loss: 2.2824110984802246
Validation loss: 1.8960316206819268

Epoch: 6| Step: 9
Training loss: 2.7432479858398438
Validation loss: 1.8730611634510819

Epoch: 6| Step: 10
Training loss: 2.7236621379852295
Validation loss: 1.8801165511531215

Epoch: 6| Step: 11
Training loss: 2.0469067096710205
Validation loss: 1.8751182889425626

Epoch: 6| Step: 12
Training loss: 1.9607837200164795
Validation loss: 1.868637151615594

Epoch: 6| Step: 13
Training loss: 2.351395845413208
Validation loss: 1.8721031232546734

Epoch: 95| Step: 0
Training loss: 1.7716104984283447
Validation loss: 1.8634833635822419

Epoch: 6| Step: 1
Training loss: 2.712568759918213
Validation loss: 1.8767685415924236

Epoch: 6| Step: 2
Training loss: 2.393728256225586
Validation loss: 1.864490121923467

Epoch: 6| Step: 3
Training loss: 2.10076642036438
Validation loss: 1.8611302785975958

Epoch: 6| Step: 4
Training loss: 1.7797777652740479
Validation loss: 1.8728421093315206

Epoch: 6| Step: 5
Training loss: 2.1624457836151123
Validation loss: 1.8796467909248926

Epoch: 6| Step: 6
Training loss: 2.543691396713257
Validation loss: 1.8814100244993806

Epoch: 6| Step: 7
Training loss: 2.0351462364196777
Validation loss: 1.862534740919708

Epoch: 6| Step: 8
Training loss: 2.9657490253448486
Validation loss: 1.895945167669686

Epoch: 6| Step: 9
Training loss: 2.3813114166259766
Validation loss: 1.8674982529814526

Epoch: 6| Step: 10
Training loss: 1.7821040153503418
Validation loss: 1.88906390436234

Epoch: 6| Step: 11
Training loss: 2.235384225845337
Validation loss: 1.8727247996996808

Epoch: 6| Step: 12
Training loss: 2.190552234649658
Validation loss: 1.8891711517046856

Epoch: 6| Step: 13
Training loss: 1.9893527030944824
Validation loss: 1.8776194818558232

Epoch: 96| Step: 0
Training loss: 2.1517333984375
Validation loss: 1.8453193723514516

Epoch: 6| Step: 1
Training loss: 2.19105863571167
Validation loss: 1.8809664454511417

Epoch: 6| Step: 2
Training loss: 2.094240665435791
Validation loss: 1.8713726946102676

Epoch: 6| Step: 3
Training loss: 1.8967355489730835
Validation loss: 1.8720102797272384

Epoch: 6| Step: 4
Training loss: 2.0781872272491455
Validation loss: 1.8618533688206826

Epoch: 6| Step: 5
Training loss: 2.094362258911133
Validation loss: 1.8507790770581973

Epoch: 6| Step: 6
Training loss: 2.4079747200012207
Validation loss: 1.8759239091668078

Epoch: 6| Step: 7
Training loss: 2.0639302730560303
Validation loss: 1.8595783518206688

Epoch: 6| Step: 8
Training loss: 2.3143110275268555
Validation loss: 1.8778843879699707

Epoch: 6| Step: 9
Training loss: 2.5471363067626953
Validation loss: 1.84879272214828

Epoch: 6| Step: 10
Training loss: 2.2773995399475098
Validation loss: 1.854140732877998

Epoch: 6| Step: 11
Training loss: 2.5289201736450195
Validation loss: 1.8731805842409852

Epoch: 6| Step: 12
Training loss: 2.131474018096924
Validation loss: 1.8611868478918587

Epoch: 6| Step: 13
Training loss: 2.016512155532837
Validation loss: 1.8627649109850648

Epoch: 97| Step: 0
Training loss: 2.3249804973602295
Validation loss: 1.8799824176296112

Epoch: 6| Step: 1
Training loss: 2.3363759517669678
Validation loss: 1.8499648135195497

Epoch: 6| Step: 2
Training loss: 2.1496477127075195
Validation loss: 1.8464803118859567

Epoch: 6| Step: 3
Training loss: 3.0644309520721436
Validation loss: 1.8494664276799848

Epoch: 6| Step: 4
Training loss: 1.9612727165222168
Validation loss: 1.8428467063493625

Epoch: 6| Step: 5
Training loss: 2.3034534454345703
Validation loss: 1.855631592453167

Epoch: 6| Step: 6
Training loss: 1.943323016166687
Validation loss: 1.8478766026035431

Epoch: 6| Step: 7
Training loss: 1.7294219732284546
Validation loss: 1.8977133458660496

Epoch: 6| Step: 8
Training loss: 2.500753402709961
Validation loss: 1.8779586104936496

Epoch: 6| Step: 9
Training loss: 2.3699393272399902
Validation loss: 1.8499436865570724

Epoch: 6| Step: 10
Training loss: 2.281308650970459
Validation loss: 1.8751114453038862

Epoch: 6| Step: 11
Training loss: 1.7387824058532715
Validation loss: 1.8699250836526193

Epoch: 6| Step: 12
Training loss: 1.9580100774765015
Validation loss: 1.897764225159922

Epoch: 6| Step: 13
Training loss: 2.253507614135742
Validation loss: 1.8654074681702482

Epoch: 98| Step: 0
Training loss: 2.0027379989624023
Validation loss: 1.8751452994602982

Epoch: 6| Step: 1
Training loss: 2.261396884918213
Validation loss: 1.8537724069369736

Epoch: 6| Step: 2
Training loss: 2.4619081020355225
Validation loss: 1.8532904091701712

Epoch: 6| Step: 3
Training loss: 2.12265682220459
Validation loss: 1.8338605229572584

Epoch: 6| Step: 4
Training loss: 1.9020106792449951
Validation loss: 1.8798908392588298

Epoch: 6| Step: 5
Training loss: 1.917077898979187
Validation loss: 1.857059936369619

Epoch: 6| Step: 6
Training loss: 2.5483827590942383
Validation loss: 1.8723084093422018

Epoch: 6| Step: 7
Training loss: 2.1195578575134277
Validation loss: 1.8752784895640549

Epoch: 6| Step: 8
Training loss: 1.9846237897872925
Validation loss: 1.8527745816015428

Epoch: 6| Step: 9
Training loss: 1.6992073059082031
Validation loss: 1.8389048499445761

Epoch: 6| Step: 10
Training loss: 2.2284982204437256
Validation loss: 1.83429882859671

Epoch: 6| Step: 11
Training loss: 2.4118707180023193
Validation loss: 1.8476702423505886

Epoch: 6| Step: 12
Training loss: 2.5093743801116943
Validation loss: 1.8281935466233121

Epoch: 6| Step: 13
Training loss: 2.61000657081604
Validation loss: 1.8407282290920135

Epoch: 99| Step: 0
Training loss: 2.5792627334594727
Validation loss: 1.8392101769806237

Epoch: 6| Step: 1
Training loss: 2.0822770595550537
Validation loss: 1.844277674152005

Epoch: 6| Step: 2
Training loss: 1.9906554222106934
Validation loss: 1.867134778730331

Epoch: 6| Step: 3
Training loss: 2.421938419342041
Validation loss: 1.8557652696486442

Epoch: 6| Step: 4
Training loss: 2.077122688293457
Validation loss: 1.8374894613860755

Epoch: 6| Step: 5
Training loss: 1.517335057258606
Validation loss: 1.8846399848179152

Epoch: 6| Step: 6
Training loss: 2.595409631729126
Validation loss: 1.8428107692349343

Epoch: 6| Step: 7
Training loss: 2.476059913635254
Validation loss: 1.84848815138622

Epoch: 6| Step: 8
Training loss: 2.1168594360351562
Validation loss: 1.8479063177621493

Epoch: 6| Step: 9
Training loss: 2.2703070640563965
Validation loss: 1.8764191237829064

Epoch: 6| Step: 10
Training loss: 2.185011386871338
Validation loss: 1.8650781582760554

Epoch: 6| Step: 11
Training loss: 2.3212220668792725
Validation loss: 1.8605829297855336

Epoch: 6| Step: 12
Training loss: 2.1634650230407715
Validation loss: 1.862893573699459

Epoch: 6| Step: 13
Training loss: 1.7831151485443115
Validation loss: 1.8526620044503161

Epoch: 100| Step: 0
Training loss: 2.5522921085357666
Validation loss: 1.8607291636928436

Epoch: 6| Step: 1
Training loss: 1.9634144306182861
Validation loss: 1.8798962818678988

Epoch: 6| Step: 2
Training loss: 2.4720571041107178
Validation loss: 1.8673398674175303

Epoch: 6| Step: 3
Training loss: 2.457301616668701
Validation loss: 1.8585974862498622

Epoch: 6| Step: 4
Training loss: 2.3971738815307617
Validation loss: 1.855287374988679

Epoch: 6| Step: 5
Training loss: 1.6601139307022095
Validation loss: 1.851414562553488

Epoch: 6| Step: 6
Training loss: 1.7826776504516602
Validation loss: 1.8252845630850842

Epoch: 6| Step: 7
Training loss: 1.508506178855896
Validation loss: 1.8741389833470827

Epoch: 6| Step: 8
Training loss: 2.032975912094116
Validation loss: 1.842619235797595

Epoch: 6| Step: 9
Training loss: 2.739304304122925
Validation loss: 1.8422423806241763

Epoch: 6| Step: 10
Training loss: 2.2896151542663574
Validation loss: 1.8207460090678225

Epoch: 6| Step: 11
Training loss: 2.056654930114746
Validation loss: 1.8461864456053703

Epoch: 6| Step: 12
Training loss: 2.365550994873047
Validation loss: 1.858227991288708

Epoch: 6| Step: 13
Training loss: 2.0570716857910156
Validation loss: 1.846828515811633

Epoch: 101| Step: 0
Training loss: 2.5602662563323975
Validation loss: 1.855490219208502

Epoch: 6| Step: 1
Training loss: 2.8613204956054688
Validation loss: 1.8288198440305647

Epoch: 6| Step: 2
Training loss: 1.9817328453063965
Validation loss: 1.8398165395182948

Epoch: 6| Step: 3
Training loss: 1.4539685249328613
Validation loss: 1.8404188233037149

Epoch: 6| Step: 4
Training loss: 1.2842254638671875
Validation loss: 1.8089255722620154

Epoch: 6| Step: 5
Training loss: 2.2221148014068604
Validation loss: 1.834739100548529

Epoch: 6| Step: 6
Training loss: 2.4124372005462646
Validation loss: 1.8538165387286936

Epoch: 6| Step: 7
Training loss: 2.7054951190948486
Validation loss: 1.8600142040560323

Epoch: 6| Step: 8
Training loss: 1.8886268138885498
Validation loss: 1.8645462169442126

Epoch: 6| Step: 9
Training loss: 2.678354263305664
Validation loss: 1.873566081446986

Epoch: 6| Step: 10
Training loss: 2.1825687885284424
Validation loss: 1.8638396622032247

Epoch: 6| Step: 11
Training loss: 2.0492124557495117
Validation loss: 1.8554208201746787

Epoch: 6| Step: 12
Training loss: 1.8374909162521362
Validation loss: 1.8657658561583488

Epoch: 6| Step: 13
Training loss: 2.3741531372070312
Validation loss: 1.8227677024820799

Epoch: 102| Step: 0
Training loss: 1.8493163585662842
Validation loss: 1.8762441309549476

Epoch: 6| Step: 1
Training loss: 1.9266341924667358
Validation loss: 1.8643456684645785

Epoch: 6| Step: 2
Training loss: 2.0325591564178467
Validation loss: 1.8052117593826786

Epoch: 6| Step: 3
Training loss: 1.8863317966461182
Validation loss: 1.8420559129407328

Epoch: 6| Step: 4
Training loss: 2.373772144317627
Validation loss: 1.8741729977310344

Epoch: 6| Step: 5
Training loss: 1.8504630327224731
Validation loss: 1.850019871547658

Epoch: 6| Step: 6
Training loss: 2.6327764987945557
Validation loss: 1.8403648407228532

Epoch: 6| Step: 7
Training loss: 2.121896743774414
Validation loss: 1.8656282040380663

Epoch: 6| Step: 8
Training loss: 2.6278538703918457
Validation loss: 1.85435224604863

Epoch: 6| Step: 9
Training loss: 2.3838109970092773
Validation loss: 1.8512547451962706

Epoch: 6| Step: 10
Training loss: 1.887662649154663
Validation loss: 1.8650133020134383

Epoch: 6| Step: 11
Training loss: 2.335968255996704
Validation loss: 1.8762922133168867

Epoch: 6| Step: 12
Training loss: 2.198211669921875
Validation loss: 1.857333670380295

Epoch: 6| Step: 13
Training loss: 2.774832010269165
Validation loss: 1.8580719283832017

Epoch: 103| Step: 0
Training loss: 2.243875026702881
Validation loss: 1.8536972358662596

Epoch: 6| Step: 1
Training loss: 1.694520115852356
Validation loss: 1.838254145396653

Epoch: 6| Step: 2
Training loss: 2.1222751140594482
Validation loss: 1.8503786774091824

Epoch: 6| Step: 3
Training loss: 1.8965463638305664
Validation loss: 1.8774425124609342

Epoch: 6| Step: 4
Training loss: 2.290109395980835
Validation loss: 1.843237812801074

Epoch: 6| Step: 5
Training loss: 2.5387985706329346
Validation loss: 1.8380971288168302

Epoch: 6| Step: 6
Training loss: 1.8632934093475342
Validation loss: 1.8630369837566088

Epoch: 6| Step: 7
Training loss: 2.027289390563965
Validation loss: 1.8436511883171656

Epoch: 6| Step: 8
Training loss: 2.348557472229004
Validation loss: 1.8185037746224353

Epoch: 6| Step: 9
Training loss: 2.689295768737793
Validation loss: 1.8236910348297448

Epoch: 6| Step: 10
Training loss: 2.3024377822875977
Validation loss: 1.8258768076537757

Epoch: 6| Step: 11
Training loss: 1.6193643808364868
Validation loss: 1.8594552393882506

Epoch: 6| Step: 12
Training loss: 1.8970032930374146
Validation loss: 1.8509016767624886

Epoch: 6| Step: 13
Training loss: 2.6005024909973145
Validation loss: 1.8215913041945426

Epoch: 104| Step: 0
Training loss: 2.7234878540039062
Validation loss: 1.8609809003850466

Epoch: 6| Step: 1
Training loss: 2.7182819843292236
Validation loss: 1.8588952069641442

Epoch: 6| Step: 2
Training loss: 2.1688716411590576
Validation loss: 1.8462633279062086

Epoch: 6| Step: 3
Training loss: 2.5397090911865234
Validation loss: 1.839952471435711

Epoch: 6| Step: 4
Training loss: 1.953477382659912
Validation loss: 1.8158610828461186

Epoch: 6| Step: 5
Training loss: 1.7148782014846802
Validation loss: 1.835067795168969

Epoch: 6| Step: 6
Training loss: 1.7578980922698975
Validation loss: 1.8496084828530588

Epoch: 6| Step: 7
Training loss: 1.730948567390442
Validation loss: 1.8127175210624613

Epoch: 6| Step: 8
Training loss: 2.610381603240967
Validation loss: 1.8683322732166578

Epoch: 6| Step: 9
Training loss: 2.3980154991149902
Validation loss: 1.8544949895592147

Epoch: 6| Step: 10
Training loss: 1.5979293584823608
Validation loss: 1.8734196552666285

Epoch: 6| Step: 11
Training loss: 1.8574713468551636
Validation loss: 1.8522583259049283

Epoch: 6| Step: 12
Training loss: 2.251249313354492
Validation loss: 1.8498941852200417

Epoch: 6| Step: 13
Training loss: 1.9202139377593994
Validation loss: 1.8323100882191812

Epoch: 105| Step: 0
Training loss: 2.203683853149414
Validation loss: 1.8170784378564486

Epoch: 6| Step: 1
Training loss: 1.9843809604644775
Validation loss: 1.8499678309245775

Epoch: 6| Step: 2
Training loss: 2.1633658409118652
Validation loss: 1.8557614075240267

Epoch: 6| Step: 3
Training loss: 3.1252198219299316
Validation loss: 1.846924724117402

Epoch: 6| Step: 4
Training loss: 1.8840683698654175
Validation loss: 1.8511165213841263

Epoch: 6| Step: 5
Training loss: 1.941186785697937
Validation loss: 1.82157447133013

Epoch: 6| Step: 6
Training loss: 1.5258926153182983
Validation loss: 1.8457622925440471

Epoch: 6| Step: 7
Training loss: 2.485283374786377
Validation loss: 1.8101669370487172

Epoch: 6| Step: 8
Training loss: 1.8617948293685913
Validation loss: 1.8383582663792435

Epoch: 6| Step: 9
Training loss: 2.3026647567749023
Validation loss: 1.8262076300959433

Epoch: 6| Step: 10
Training loss: 2.030958890914917
Validation loss: 1.841870460458981

Epoch: 6| Step: 11
Training loss: 2.242410182952881
Validation loss: 1.8095627523237658

Epoch: 6| Step: 12
Training loss: 2.0360686779022217
Validation loss: 1.8164940367462814

Epoch: 6| Step: 13
Training loss: 2.494718551635742
Validation loss: 1.858214589857286

Epoch: 106| Step: 0
Training loss: 2.661771297454834
Validation loss: 1.860607345898946

Epoch: 6| Step: 1
Training loss: 2.570343494415283
Validation loss: 1.8490289949601697

Epoch: 6| Step: 2
Training loss: 1.7937512397766113
Validation loss: 1.8390185986795733

Epoch: 6| Step: 3
Training loss: 1.6124236583709717
Validation loss: 1.8242746950477682

Epoch: 6| Step: 4
Training loss: 1.9256539344787598
Validation loss: 1.8558238629371888

Epoch: 6| Step: 5
Training loss: 2.094562292098999
Validation loss: 1.8415983864056167

Epoch: 6| Step: 6
Training loss: 2.93391752243042
Validation loss: 1.8042733054007254

Epoch: 6| Step: 7
Training loss: 1.476586937904358
Validation loss: 1.8531345295649704

Epoch: 6| Step: 8
Training loss: 2.249418258666992
Validation loss: 1.8634648451241114

Epoch: 6| Step: 9
Training loss: 2.234457492828369
Validation loss: 1.8379566618191299

Epoch: 6| Step: 10
Training loss: 2.3675971031188965
Validation loss: 1.8553925662912347

Epoch: 6| Step: 11
Training loss: 1.9678385257720947
Validation loss: 1.8391386155159242

Epoch: 6| Step: 12
Training loss: 1.7242236137390137
Validation loss: 1.8236765502601542

Epoch: 6| Step: 13
Training loss: 2.316160202026367
Validation loss: 1.8344995578130086

Epoch: 107| Step: 0
Training loss: 2.2492687702178955
Validation loss: 1.8390811463837982

Epoch: 6| Step: 1
Training loss: 2.5306191444396973
Validation loss: 1.8079476048869472

Epoch: 6| Step: 2
Training loss: 1.4632608890533447
Validation loss: 1.8521649940039522

Epoch: 6| Step: 3
Training loss: 1.8955039978027344
Validation loss: 1.857584386743525

Epoch: 6| Step: 4
Training loss: 2.211336612701416
Validation loss: 1.8259312260535456

Epoch: 6| Step: 5
Training loss: 2.6122946739196777
Validation loss: 1.8125689132239229

Epoch: 6| Step: 6
Training loss: 1.0965416431427002
Validation loss: 1.8284019295887282

Epoch: 6| Step: 7
Training loss: 2.820948600769043
Validation loss: 1.8324376767681492

Epoch: 6| Step: 8
Training loss: 2.0127787590026855
Validation loss: 1.83061933261092

Epoch: 6| Step: 9
Training loss: 2.576284408569336
Validation loss: 1.8286020691676805

Epoch: 6| Step: 10
Training loss: 1.5780032873153687
Validation loss: 1.8450259752171014

Epoch: 6| Step: 11
Training loss: 2.1854567527770996
Validation loss: 1.8080149837719497

Epoch: 6| Step: 12
Training loss: 2.189227342605591
Validation loss: 1.8337129021203646

Epoch: 6| Step: 13
Training loss: 2.297860622406006
Validation loss: 1.8309344245541481

Epoch: 108| Step: 0
Training loss: 1.8744126558303833
Validation loss: 1.8293258669555827

Epoch: 6| Step: 1
Training loss: 2.4206647872924805
Validation loss: 1.8266247959547146

Epoch: 6| Step: 2
Training loss: 1.7860106229782104
Validation loss: 1.851441171861464

Epoch: 6| Step: 3
Training loss: 2.523115634918213
Validation loss: 1.8503027898009106

Epoch: 6| Step: 4
Training loss: 2.6073660850524902
Validation loss: 1.8765319534527358

Epoch: 6| Step: 5
Training loss: 2.0785744190216064
Validation loss: 1.8316034258052867

Epoch: 6| Step: 6
Training loss: 2.0518836975097656
Validation loss: 1.8926213633629583

Epoch: 6| Step: 7
Training loss: 1.7502892017364502
Validation loss: 1.8372598078943068

Epoch: 6| Step: 8
Training loss: 1.9231486320495605
Validation loss: 1.86609665296411

Epoch: 6| Step: 9
Training loss: 1.9041248559951782
Validation loss: 1.8631330074802521

Epoch: 6| Step: 10
Training loss: 2.020963668823242
Validation loss: 1.8581363513905516

Epoch: 6| Step: 11
Training loss: 2.6777377128601074
Validation loss: 1.8596729373419156

Epoch: 6| Step: 12
Training loss: 2.369051456451416
Validation loss: 1.8047181765238445

Epoch: 6| Step: 13
Training loss: 1.4439153671264648
Validation loss: 1.8537149249866445

Epoch: 109| Step: 0
Training loss: 2.1858770847320557
Validation loss: 1.8123511216973747

Epoch: 6| Step: 1
Training loss: 2.000387668609619
Validation loss: 1.8379449382905038

Epoch: 6| Step: 2
Training loss: 2.1679134368896484
Validation loss: 1.8238822157664965

Epoch: 6| Step: 3
Training loss: 2.188873767852783
Validation loss: 1.8679487577048681

Epoch: 6| Step: 4
Training loss: 2.2187767028808594
Validation loss: 1.842923770668686

Epoch: 6| Step: 5
Training loss: 1.8713018894195557
Validation loss: 1.837100128973684

Epoch: 6| Step: 6
Training loss: 2.431192398071289
Validation loss: 1.859312495877666

Epoch: 6| Step: 7
Training loss: 2.224607467651367
Validation loss: 1.8304330136186333

Epoch: 6| Step: 8
Training loss: 2.05271053314209
Validation loss: 1.8464904241664435

Epoch: 6| Step: 9
Training loss: 1.872952938079834
Validation loss: 1.8573303645656956

Epoch: 6| Step: 10
Training loss: 2.2747976779937744
Validation loss: 1.8457520187542003

Epoch: 6| Step: 11
Training loss: 2.2436342239379883
Validation loss: 1.8462858943529026

Epoch: 6| Step: 12
Training loss: 1.5490295886993408
Validation loss: 1.8431565851293585

Epoch: 6| Step: 13
Training loss: 2.6211729049682617
Validation loss: 1.8771000241720548

Epoch: 110| Step: 0
Training loss: 1.588125467300415
Validation loss: 1.862286925315857

Epoch: 6| Step: 1
Training loss: 2.3168396949768066
Validation loss: 1.8529546927380305

Epoch: 6| Step: 2
Training loss: 1.5970783233642578
Validation loss: 1.8412095833850164

Epoch: 6| Step: 3
Training loss: 2.597475051879883
Validation loss: 1.8432102023914296

Epoch: 6| Step: 4
Training loss: 2.2851641178131104
Validation loss: 1.853969548338203

Epoch: 6| Step: 5
Training loss: 1.77488374710083
Validation loss: 1.8294545629973054

Epoch: 6| Step: 6
Training loss: 1.982132077217102
Validation loss: 1.8231794475227274

Epoch: 6| Step: 7
Training loss: 2.298588752746582
Validation loss: 1.852373448751306

Epoch: 6| Step: 8
Training loss: 2.351012706756592
Validation loss: 1.859488296252425

Epoch: 6| Step: 9
Training loss: 1.9844367504119873
Validation loss: 1.8412509361902873

Epoch: 6| Step: 10
Training loss: 2.5751798152923584
Validation loss: 1.8467332137528287

Epoch: 6| Step: 11
Training loss: 2.2394790649414062
Validation loss: 1.8682882029523131

Epoch: 6| Step: 12
Training loss: 1.688414216041565
Validation loss: 1.8418747750661706

Epoch: 6| Step: 13
Training loss: 2.0202507972717285
Validation loss: 1.8676330991970596

Epoch: 111| Step: 0
Training loss: 2.416632890701294
Validation loss: 1.8393500697228216

Epoch: 6| Step: 1
Training loss: 1.8339018821716309
Validation loss: 1.8488656564425396

Epoch: 6| Step: 2
Training loss: 2.6017727851867676
Validation loss: 1.848646762550518

Epoch: 6| Step: 3
Training loss: 2.3428118228912354
Validation loss: 1.8096084351180701

Epoch: 6| Step: 4
Training loss: 1.5440354347229004
Validation loss: 1.8148938789162585

Epoch: 6| Step: 5
Training loss: 3.170207977294922
Validation loss: 1.8101223809744722

Epoch: 6| Step: 6
Training loss: 1.4713456630706787
Validation loss: 1.8343421848871375

Epoch: 6| Step: 7
Training loss: 1.7670071125030518
Validation loss: 1.8222552345645042

Epoch: 6| Step: 8
Training loss: 2.263583183288574
Validation loss: 1.8456940650939941

Epoch: 6| Step: 9
Training loss: 2.500080108642578
Validation loss: 1.8416727371113275

Epoch: 6| Step: 10
Training loss: 1.7761152982711792
Validation loss: 1.8371355854054934

Epoch: 6| Step: 11
Training loss: 1.618131160736084
Validation loss: 1.833568093597248

Epoch: 6| Step: 12
Training loss: 1.950700044631958
Validation loss: 1.8278773189872823

Epoch: 6| Step: 13
Training loss: 2.088934898376465
Validation loss: 1.8503627674553984

Epoch: 112| Step: 0
Training loss: 2.0496253967285156
Validation loss: 1.8242461963366436

Epoch: 6| Step: 1
Training loss: 2.108151435852051
Validation loss: 1.8262545011376823

Epoch: 6| Step: 2
Training loss: 2.4368181228637695
Validation loss: 1.8397580628753991

Epoch: 6| Step: 3
Training loss: 2.1780893802642822
Validation loss: 1.8460061396321943

Epoch: 6| Step: 4
Training loss: 2.314155101776123
Validation loss: 1.8556383143189132

Epoch: 6| Step: 5
Training loss: 3.276528835296631
Validation loss: 1.8491590433223273

Epoch: 6| Step: 6
Training loss: 1.78489351272583
Validation loss: 1.8134243103765673

Epoch: 6| Step: 7
Training loss: 1.47398042678833
Validation loss: 1.8388531400311379

Epoch: 6| Step: 8
Training loss: 2.51017427444458
Validation loss: 1.8452059556079168

Epoch: 6| Step: 9
Training loss: 1.8413950204849243
Validation loss: 1.868355889474192

Epoch: 6| Step: 10
Training loss: 2.232388496398926
Validation loss: 1.9034635584841493

Epoch: 6| Step: 11
Training loss: 1.7118358612060547
Validation loss: 1.8559473560702415

Epoch: 6| Step: 12
Training loss: 1.8945890665054321
Validation loss: 1.863586792381861

Epoch: 6| Step: 13
Training loss: 1.2901499271392822
Validation loss: 1.8406944710721251

Epoch: 113| Step: 0
Training loss: 2.605821371078491
Validation loss: 1.8539974497210594

Epoch: 6| Step: 1
Training loss: 2.222085475921631
Validation loss: 1.7979843116575671

Epoch: 6| Step: 2
Training loss: 1.4064240455627441
Validation loss: 1.8487162897663731

Epoch: 6| Step: 3
Training loss: 3.1294872760772705
Validation loss: 1.848337370862243

Epoch: 6| Step: 4
Training loss: 1.8302416801452637
Validation loss: 1.8489160076264413

Epoch: 6| Step: 5
Training loss: 1.5791666507720947
Validation loss: 1.8591588671489427

Epoch: 6| Step: 6
Training loss: 1.7679977416992188
Validation loss: 1.8471840427767845

Epoch: 6| Step: 7
Training loss: 2.1868484020233154
Validation loss: 1.804415346473776

Epoch: 6| Step: 8
Training loss: 2.7204325199127197
Validation loss: 1.8523495171659736

Epoch: 6| Step: 9
Training loss: 1.888540267944336
Validation loss: 1.838546162010521

Epoch: 6| Step: 10
Training loss: 1.6268422603607178
Validation loss: 1.8018971553412817

Epoch: 6| Step: 11
Training loss: 2.3184876441955566
Validation loss: 1.8126054656121038

Epoch: 6| Step: 12
Training loss: 2.135774850845337
Validation loss: 1.863038315567919

Epoch: 6| Step: 13
Training loss: 1.970411777496338
Validation loss: 1.8367925895157682

Epoch: 114| Step: 0
Training loss: 2.730935573577881
Validation loss: 1.8437326223619523

Epoch: 6| Step: 1
Training loss: 1.6584186553955078
Validation loss: 1.8449883871181036

Epoch: 6| Step: 2
Training loss: 1.8156120777130127
Validation loss: 1.8600354899642288

Epoch: 6| Step: 3
Training loss: 2.3997466564178467
Validation loss: 1.875562640928453

Epoch: 6| Step: 4
Training loss: 2.5066657066345215
Validation loss: 1.8750491039727324

Epoch: 6| Step: 5
Training loss: 1.8349661827087402
Validation loss: 1.8554425342108614

Epoch: 6| Step: 6
Training loss: 1.9443016052246094
Validation loss: 1.8515777959618518

Epoch: 6| Step: 7
Training loss: 1.5491887331008911
Validation loss: 1.8581934487947853

Epoch: 6| Step: 8
Training loss: 2.720768928527832
Validation loss: 1.8436791576364988

Epoch: 6| Step: 9
Training loss: 1.9000766277313232
Validation loss: 1.874328927327228

Epoch: 6| Step: 10
Training loss: 2.0222063064575195
Validation loss: 1.8717057910016788

Epoch: 6| Step: 11
Training loss: 1.8388028144836426
Validation loss: 1.8210559609115764

Epoch: 6| Step: 12
Training loss: 2.3903918266296387
Validation loss: 1.8418516420548963

Epoch: 6| Step: 13
Training loss: 2.3908257484436035
Validation loss: 1.844439071993674

Epoch: 115| Step: 0
Training loss: 1.8865811824798584
Validation loss: 1.8139185315819197

Epoch: 6| Step: 1
Training loss: 2.2519278526306152
Validation loss: 1.8541647939271824

Epoch: 6| Step: 2
Training loss: 2.5898940563201904
Validation loss: 1.8560388177953742

Epoch: 6| Step: 3
Training loss: 1.5420658588409424
Validation loss: 1.8217524251630228

Epoch: 6| Step: 4
Training loss: 2.1714048385620117
Validation loss: 1.8198662804019066

Epoch: 6| Step: 5
Training loss: 1.4672741889953613
Validation loss: 1.8474698887076428

Epoch: 6| Step: 6
Training loss: 1.8551552295684814
Validation loss: 1.863213828814927

Epoch: 6| Step: 7
Training loss: 2.6300954818725586
Validation loss: 1.823646096773045

Epoch: 6| Step: 8
Training loss: 2.2498726844787598
Validation loss: 1.8160557054704236

Epoch: 6| Step: 9
Training loss: 2.30399227142334
Validation loss: 1.8522558109734648

Epoch: 6| Step: 10
Training loss: 2.099760055541992
Validation loss: 1.8754543245479625

Epoch: 6| Step: 11
Training loss: 1.7221441268920898
Validation loss: 1.8591654172507666

Epoch: 6| Step: 12
Training loss: 2.0642056465148926
Validation loss: 1.8609113052327146

Epoch: 6| Step: 13
Training loss: 2.899994134902954
Validation loss: 1.82875047960589

Epoch: 116| Step: 0
Training loss: 2.288684129714966
Validation loss: 1.8368828681207472

Epoch: 6| Step: 1
Training loss: 1.8820075988769531
Validation loss: 1.873261550421356

Epoch: 6| Step: 2
Training loss: 2.132331371307373
Validation loss: 1.8195952625684841

Epoch: 6| Step: 3
Training loss: 2.889277219772339
Validation loss: 1.891750278011445

Epoch: 6| Step: 4
Training loss: 2.5993850231170654
Validation loss: 1.8705204943174958

Epoch: 6| Step: 5
Training loss: 1.6631146669387817
Validation loss: 1.8442478423477502

Epoch: 6| Step: 6
Training loss: 1.8177193403244019
Validation loss: 1.865824778874715

Epoch: 6| Step: 7
Training loss: 2.117116928100586
Validation loss: 1.8620572577240646

Epoch: 6| Step: 8
Training loss: 2.016549825668335
Validation loss: 1.8913950561195292

Epoch: 6| Step: 9
Training loss: 1.7220484018325806
Validation loss: 1.8921127396245156

Epoch: 6| Step: 10
Training loss: 1.6846989393234253
Validation loss: 1.8730335107413671

Epoch: 6| Step: 11
Training loss: 1.9169807434082031
Validation loss: 1.8630705392488869

Epoch: 6| Step: 12
Training loss: 2.599397897720337
Validation loss: 1.9061603905052267

Epoch: 6| Step: 13
Training loss: 1.633756399154663
Validation loss: 1.9088708713490476

Epoch: 117| Step: 0
Training loss: 1.6360430717468262
Validation loss: 1.8664482870409567

Epoch: 6| Step: 1
Training loss: 1.8887403011322021
Validation loss: 1.855403987310266

Epoch: 6| Step: 2
Training loss: 2.4326231479644775
Validation loss: 1.8619477723234443

Epoch: 6| Step: 3
Training loss: 2.3590521812438965
Validation loss: 1.8574395051566504

Epoch: 6| Step: 4
Training loss: 2.636136054992676
Validation loss: 1.8475006754680345

Epoch: 6| Step: 5
Training loss: 1.2173268795013428
Validation loss: 1.842607525087172

Epoch: 6| Step: 6
Training loss: 2.36590313911438
Validation loss: 1.832993443294238

Epoch: 6| Step: 7
Training loss: 2.3760361671447754
Validation loss: 1.8477558679478143

Epoch: 6| Step: 8
Training loss: 2.025632381439209
Validation loss: 1.865986518962409

Epoch: 6| Step: 9
Training loss: 1.872318983078003
Validation loss: 1.8712532674112627

Epoch: 6| Step: 10
Training loss: 2.1488776206970215
Validation loss: 1.8276017788917787

Epoch: 6| Step: 11
Training loss: 1.768052339553833
Validation loss: 1.7889816068833875

Epoch: 6| Step: 12
Training loss: 1.53733229637146
Validation loss: 1.8047569080065655

Epoch: 6| Step: 13
Training loss: 2.612238883972168
Validation loss: 1.818086560054492

Epoch: 118| Step: 0
Training loss: 2.4766855239868164
Validation loss: 1.8090989474327333

Epoch: 6| Step: 1
Training loss: 2.0483765602111816
Validation loss: 1.8416711207359069

Epoch: 6| Step: 2
Training loss: 2.6220502853393555
Validation loss: 1.8354101860395042

Epoch: 6| Step: 3
Training loss: 1.5570285320281982
Validation loss: 1.8317483073921614

Epoch: 6| Step: 4
Training loss: 2.1380741596221924
Validation loss: 1.8012541596607496

Epoch: 6| Step: 5
Training loss: 2.0592870712280273
Validation loss: 1.810555532414426

Epoch: 6| Step: 6
Training loss: 2.2470145225524902
Validation loss: 1.8238574856071061

Epoch: 6| Step: 7
Training loss: 1.6819138526916504
Validation loss: 1.8202810364384805

Epoch: 6| Step: 8
Training loss: 1.5279793739318848
Validation loss: 1.83438075998778

Epoch: 6| Step: 9
Training loss: 1.929016351699829
Validation loss: 1.8855203890031385

Epoch: 6| Step: 10
Training loss: 1.8105769157409668
Validation loss: 1.8112423009769891

Epoch: 6| Step: 11
Training loss: 2.393186092376709
Validation loss: 1.8433326905773533

Epoch: 6| Step: 12
Training loss: 1.9603769779205322
Validation loss: 1.8358641132231681

Epoch: 6| Step: 13
Training loss: 3.1727497577667236
Validation loss: 1.831047495206197

Epoch: 119| Step: 0
Training loss: 2.1581010818481445
Validation loss: 1.8380341209391111

Epoch: 6| Step: 1
Training loss: 2.4389467239379883
Validation loss: 1.8802232383399882

Epoch: 6| Step: 2
Training loss: 2.1416666507720947
Validation loss: 1.8637625517383698

Epoch: 6| Step: 3
Training loss: 1.3437106609344482
Validation loss: 1.8555973575961204

Epoch: 6| Step: 4
Training loss: 1.734217643737793
Validation loss: 1.860022670479231

Epoch: 6| Step: 5
Training loss: 1.720565915107727
Validation loss: 1.8612150658843338

Epoch: 6| Step: 6
Training loss: 1.948233962059021
Validation loss: 1.860711725809241

Epoch: 6| Step: 7
Training loss: 2.128389835357666
Validation loss: 1.85172257115764

Epoch: 6| Step: 8
Training loss: 2.291184425354004
Validation loss: 1.8418547158600183

Epoch: 6| Step: 9
Training loss: 1.8786200284957886
Validation loss: 1.820765838828138

Epoch: 6| Step: 10
Training loss: 2.307469367980957
Validation loss: 1.8259740273157756

Epoch: 6| Step: 11
Training loss: 2.6082911491394043
Validation loss: 1.873057178271714

Epoch: 6| Step: 12
Training loss: 2.208386182785034
Validation loss: 1.8297434109513477

Epoch: 6| Step: 13
Training loss: 2.4828648567199707
Validation loss: 1.8222886182928597

Epoch: 120| Step: 0
Training loss: 1.9124884605407715
Validation loss: 1.8256801917988768

Epoch: 6| Step: 1
Training loss: 2.1487228870391846
Validation loss: 1.7977116761669036

Epoch: 6| Step: 2
Training loss: 2.3451240062713623
Validation loss: 1.8547661445474113

Epoch: 6| Step: 3
Training loss: 2.321945905685425
Validation loss: 1.8221348921457927

Epoch: 6| Step: 4
Training loss: 2.1250076293945312
Validation loss: 1.8270834184462024

Epoch: 6| Step: 5
Training loss: 2.1006245613098145
Validation loss: 1.8315783213543635

Epoch: 6| Step: 6
Training loss: 1.993281364440918
Validation loss: 1.8357526448465162

Epoch: 6| Step: 7
Training loss: 1.6040692329406738
Validation loss: 1.8654429425475418

Epoch: 6| Step: 8
Training loss: 1.939079761505127
Validation loss: 1.8359463676329582

Epoch: 6| Step: 9
Training loss: 2.933483600616455
Validation loss: 1.8192093141617314

Epoch: 6| Step: 10
Training loss: 1.62786865234375
Validation loss: 1.8570020045003583

Epoch: 6| Step: 11
Training loss: 1.8994944095611572
Validation loss: 1.8669495531307754

Epoch: 6| Step: 12
Training loss: 2.090508222579956
Validation loss: 1.8710290014102895

Epoch: 6| Step: 13
Training loss: 1.863842487335205
Validation loss: 1.8478136729168635

Epoch: 121| Step: 0
Training loss: 1.7155834436416626
Validation loss: 1.8056930700937908

Epoch: 6| Step: 1
Training loss: 2.682715654373169
Validation loss: 1.8638281694022558

Epoch: 6| Step: 2
Training loss: 1.305677890777588
Validation loss: 1.8288119159718996

Epoch: 6| Step: 3
Training loss: 2.1281070709228516
Validation loss: 1.820042715277723

Epoch: 6| Step: 4
Training loss: 2.437579870223999
Validation loss: 1.8368215022548553

Epoch: 6| Step: 5
Training loss: 2.0142250061035156
Validation loss: 1.837725140715158

Epoch: 6| Step: 6
Training loss: 2.08998703956604
Validation loss: 1.8848362725268129

Epoch: 6| Step: 7
Training loss: 1.7282967567443848
Validation loss: 1.8638710001463532

Epoch: 6| Step: 8
Training loss: 1.8671520948410034
Validation loss: 1.8544734267778293

Epoch: 6| Step: 9
Training loss: 1.6095123291015625
Validation loss: 1.8708568234597482

Epoch: 6| Step: 10
Training loss: 2.2513952255249023
Validation loss: 1.8235387840578634

Epoch: 6| Step: 11
Training loss: 2.500804901123047
Validation loss: 1.865119004762301

Epoch: 6| Step: 12
Training loss: 2.341965675354004
Validation loss: 1.8381882636777815

Epoch: 6| Step: 13
Training loss: 2.1923935413360596
Validation loss: 1.8604818133897678

Epoch: 122| Step: 0
Training loss: 1.7329148054122925
Validation loss: 1.8348799264559181

Epoch: 6| Step: 1
Training loss: 1.4718070030212402
Validation loss: 1.7971470343169345

Epoch: 6| Step: 2
Training loss: 2.3476643562316895
Validation loss: 1.8189831010756954

Epoch: 6| Step: 3
Training loss: 2.072930097579956
Validation loss: 1.8165141869616765

Epoch: 6| Step: 4
Training loss: 2.522329807281494
Validation loss: 1.8312852587751163

Epoch: 6| Step: 5
Training loss: 2.3905348777770996
Validation loss: 1.853701852983044

Epoch: 6| Step: 6
Training loss: 1.8818373680114746
Validation loss: 1.8387319990383681

Epoch: 6| Step: 7
Training loss: 1.8236713409423828
Validation loss: 1.8377058121465868

Epoch: 6| Step: 8
Training loss: 1.9759221076965332
Validation loss: 1.8570636587758218

Epoch: 6| Step: 9
Training loss: 1.7520370483398438
Validation loss: 1.8560671088516072

Epoch: 6| Step: 10
Training loss: 2.1058614253997803
Validation loss: 1.8302298489437308

Epoch: 6| Step: 11
Training loss: 2.1047258377075195
Validation loss: 1.8511280744306502

Epoch: 6| Step: 12
Training loss: 1.9842197895050049
Validation loss: 1.8560998708971086

Epoch: 6| Step: 13
Training loss: 2.5733652114868164
Validation loss: 1.8343331377993348

Epoch: 123| Step: 0
Training loss: 2.139270782470703
Validation loss: 1.823211549430765

Epoch: 6| Step: 1
Training loss: 1.429036259651184
Validation loss: 1.8335926660927393

Epoch: 6| Step: 2
Training loss: 2.1282167434692383
Validation loss: 1.8266345685528171

Epoch: 6| Step: 3
Training loss: 2.1258463859558105
Validation loss: 1.848451852798462

Epoch: 6| Step: 4
Training loss: 1.9973403215408325
Validation loss: 1.8550264630266415

Epoch: 6| Step: 5
Training loss: 2.0244863033294678
Validation loss: 1.8357184074258293

Epoch: 6| Step: 6
Training loss: 2.285369873046875
Validation loss: 1.8447690548435334

Epoch: 6| Step: 7
Training loss: 1.9045497179031372
Validation loss: 1.8296093030642437

Epoch: 6| Step: 8
Training loss: 2.122310161590576
Validation loss: 1.8217094098367999

Epoch: 6| Step: 9
Training loss: 1.7155706882476807
Validation loss: 1.8680090494053339

Epoch: 6| Step: 10
Training loss: 2.598893165588379
Validation loss: 1.8241185590785036

Epoch: 6| Step: 11
Training loss: 1.858620524406433
Validation loss: 1.823483197919784

Epoch: 6| Step: 12
Training loss: 1.9596309661865234
Validation loss: 1.8324728447903869

Epoch: 6| Step: 13
Training loss: 2.3547260761260986
Validation loss: 1.8480668452478224

Epoch: 124| Step: 0
Training loss: 1.73089599609375
Validation loss: 1.8591351598821662

Epoch: 6| Step: 1
Training loss: 2.489370584487915
Validation loss: 1.8783033227407804

Epoch: 6| Step: 2
Training loss: 1.820372462272644
Validation loss: 1.8424165428325694

Epoch: 6| Step: 3
Training loss: 2.0014467239379883
Validation loss: 1.8369231018968808

Epoch: 6| Step: 4
Training loss: 1.91013765335083
Validation loss: 1.8188017376007573

Epoch: 6| Step: 5
Training loss: 1.8548154830932617
Validation loss: 1.8545686711547196

Epoch: 6| Step: 6
Training loss: 2.8016557693481445
Validation loss: 1.895303713378086

Epoch: 6| Step: 7
Training loss: 2.3175528049468994
Validation loss: 1.8858480350945586

Epoch: 6| Step: 8
Training loss: 2.5285863876342773
Validation loss: 1.8811774702482327

Epoch: 6| Step: 9
Training loss: 1.6544370651245117
Validation loss: 1.848743929657885

Epoch: 6| Step: 10
Training loss: 2.11716365814209
Validation loss: 1.8504855389236121

Epoch: 6| Step: 11
Training loss: 1.569624423980713
Validation loss: 1.8504562788112189

Epoch: 6| Step: 12
Training loss: 1.7672380208969116
Validation loss: 1.8856733819489837

Epoch: 6| Step: 13
Training loss: 1.9372152090072632
Validation loss: 1.8829693204613143

Epoch: 125| Step: 0
Training loss: 1.923511028289795
Validation loss: 1.8787160624739945

Epoch: 6| Step: 1
Training loss: 1.7241480350494385
Validation loss: 1.8501973869980022

Epoch: 6| Step: 2
Training loss: 2.325076103210449
Validation loss: 1.8746414722934845

Epoch: 6| Step: 3
Training loss: 2.828869581222534
Validation loss: 1.840231644209995

Epoch: 6| Step: 4
Training loss: 2.8282008171081543
Validation loss: 1.8508592395372288

Epoch: 6| Step: 5
Training loss: 2.3077988624572754
Validation loss: 1.8355072877740348

Epoch: 6| Step: 6
Training loss: 1.48789644241333
Validation loss: 1.8506946691902735

Epoch: 6| Step: 7
Training loss: 1.6152429580688477
Validation loss: 1.817000945409139

Epoch: 6| Step: 8
Training loss: 1.6502952575683594
Validation loss: 1.8413465228132022

Epoch: 6| Step: 9
Training loss: 1.5165116786956787
Validation loss: 1.84907377407115

Epoch: 6| Step: 10
Training loss: 1.2335489988327026
Validation loss: 1.890321082966302

Epoch: 6| Step: 11
Training loss: 2.25697660446167
Validation loss: 1.8493617298782512

Epoch: 6| Step: 12
Training loss: 2.226567268371582
Validation loss: 1.8130947915456628

Epoch: 6| Step: 13
Training loss: 2.576209545135498
Validation loss: 1.834981918334961

Epoch: 126| Step: 0
Training loss: 3.2146291732788086
Validation loss: 1.861688119108959

Epoch: 6| Step: 1
Training loss: 1.6819416284561157
Validation loss: 1.8594212942225958

Epoch: 6| Step: 2
Training loss: 2.178208112716675
Validation loss: 1.8461957900754866

Epoch: 6| Step: 3
Training loss: 1.6605666875839233
Validation loss: 1.8469170165318314

Epoch: 6| Step: 4
Training loss: 2.804576873779297
Validation loss: 1.84034865133224

Epoch: 6| Step: 5
Training loss: 1.942140817642212
Validation loss: 1.811913251876831

Epoch: 6| Step: 6
Training loss: 1.5379714965820312
Validation loss: 1.8247185137964064

Epoch: 6| Step: 7
Training loss: 2.218502998352051
Validation loss: 1.816174114904096

Epoch: 6| Step: 8
Training loss: 2.2755322456359863
Validation loss: 1.7958825147280129

Epoch: 6| Step: 9
Training loss: 2.0017881393432617
Validation loss: 1.8849737798013995

Epoch: 6| Step: 10
Training loss: 1.935765027999878
Validation loss: 1.8053697847550916

Epoch: 6| Step: 11
Training loss: 1.8793352842330933
Validation loss: 1.8525440705719816

Epoch: 6| Step: 12
Training loss: 1.2712321281433105
Validation loss: 1.8194255675038984

Epoch: 6| Step: 13
Training loss: 1.888548493385315
Validation loss: 1.8592639853877406

Epoch: 127| Step: 0
Training loss: 1.8677866458892822
Validation loss: 1.850677159524733

Epoch: 6| Step: 1
Training loss: 2.7823104858398438
Validation loss: 1.8125040838795323

Epoch: 6| Step: 2
Training loss: 2.1951236724853516
Validation loss: 1.8412114292062738

Epoch: 6| Step: 3
Training loss: 2.154655933380127
Validation loss: 1.8438458519597207

Epoch: 6| Step: 4
Training loss: 1.6450389623641968
Validation loss: 1.8173581118224769

Epoch: 6| Step: 5
Training loss: 1.783442735671997
Validation loss: 1.8542746625920778

Epoch: 6| Step: 6
Training loss: 1.7993770837783813
Validation loss: 1.8207401024397982

Epoch: 6| Step: 7
Training loss: 2.6481752395629883
Validation loss: 1.8676217602145286

Epoch: 6| Step: 8
Training loss: 2.139219284057617
Validation loss: 1.848755782650363

Epoch: 6| Step: 9
Training loss: 1.8618487119674683
Validation loss: 1.8609564227442588

Epoch: 6| Step: 10
Training loss: 1.3464710712432861
Validation loss: 1.8956620231751473

Epoch: 6| Step: 11
Training loss: 1.5631532669067383
Validation loss: 1.8776530745208904

Epoch: 6| Step: 12
Training loss: 2.370950698852539
Validation loss: 1.8768902414588517

Epoch: 6| Step: 13
Training loss: 2.1365983486175537
Validation loss: 1.8622139243669407

Epoch: 128| Step: 0
Training loss: 1.4899088144302368
Validation loss: 1.9086072624370616

Epoch: 6| Step: 1
Training loss: 1.2905974388122559
Validation loss: 1.8625646842423307

Epoch: 6| Step: 2
Training loss: 2.1704769134521484
Validation loss: 1.8500556766345937

Epoch: 6| Step: 3
Training loss: 2.2171077728271484
Validation loss: 1.9027386711489769

Epoch: 6| Step: 4
Training loss: 1.8363745212554932
Validation loss: 1.902889686246072

Epoch: 6| Step: 5
Training loss: 2.180616617202759
Validation loss: 1.8587238775786532

Epoch: 6| Step: 6
Training loss: 2.074802875518799
Validation loss: 1.864439037538344

Epoch: 6| Step: 7
Training loss: 2.4515457153320312
Validation loss: 1.8657253185908

Epoch: 6| Step: 8
Training loss: 2.289034843444824
Validation loss: 1.8576756497865081

Epoch: 6| Step: 9
Training loss: 1.7704435586929321
Validation loss: 1.8323820457663587

Epoch: 6| Step: 10
Training loss: 2.0248966217041016
Validation loss: 1.869554563235211

Epoch: 6| Step: 11
Training loss: 2.4661760330200195
Validation loss: 1.8361994246000886

Epoch: 6| Step: 12
Training loss: 1.8106424808502197
Validation loss: 1.8384028198898479

Epoch: 6| Step: 13
Training loss: 2.5632827281951904
Validation loss: 1.8586776820562219

Epoch: 129| Step: 0
Training loss: 1.4443825483322144
Validation loss: 1.829334807652299

Epoch: 6| Step: 1
Training loss: 1.8054710626602173
Validation loss: 1.7937097831438946

Epoch: 6| Step: 2
Training loss: 1.8809518814086914
Validation loss: 1.8125280539194744

Epoch: 6| Step: 3
Training loss: 2.092949390411377
Validation loss: 1.8480588454072193

Epoch: 6| Step: 4
Training loss: 1.9311134815216064
Validation loss: 1.8362775079665645

Epoch: 6| Step: 5
Training loss: 1.9550111293792725
Validation loss: 1.7950949463793027

Epoch: 6| Step: 6
Training loss: 2.1033148765563965
Validation loss: 1.8354886654884583

Epoch: 6| Step: 7
Training loss: 1.7309699058532715
Validation loss: 1.8176334314448859

Epoch: 6| Step: 8
Training loss: 2.6716268062591553
Validation loss: 1.8332929085659724

Epoch: 6| Step: 9
Training loss: 3.0588951110839844
Validation loss: 1.840911333278943

Epoch: 6| Step: 10
Training loss: 2.2352190017700195
Validation loss: 1.7882684007767709

Epoch: 6| Step: 11
Training loss: 1.9703457355499268
Validation loss: 1.824076767890684

Epoch: 6| Step: 12
Training loss: 1.4176273345947266
Validation loss: 1.8435136707880164

Epoch: 6| Step: 13
Training loss: 2.0403380393981934
Validation loss: 1.8602262056002052

Epoch: 130| Step: 0
Training loss: 2.4817450046539307
Validation loss: 1.8328643703973422

Epoch: 6| Step: 1
Training loss: 1.8988792896270752
Validation loss: 1.8194190212475356

Epoch: 6| Step: 2
Training loss: 2.080474615097046
Validation loss: 1.883658915437678

Epoch: 6| Step: 3
Training loss: 2.283308982849121
Validation loss: 1.8413665243374404

Epoch: 6| Step: 4
Training loss: 1.7392586469650269
Validation loss: 1.8744199993789836

Epoch: 6| Step: 5
Training loss: 1.7205438613891602
Validation loss: 1.8705175333125617

Epoch: 6| Step: 6
Training loss: 2.3177599906921387
Validation loss: 1.8245942169620144

Epoch: 6| Step: 7
Training loss: 1.508861780166626
Validation loss: 1.8579184957729873

Epoch: 6| Step: 8
Training loss: 1.6548492908477783
Validation loss: 1.8419033609410769

Epoch: 6| Step: 9
Training loss: 2.4269485473632812
Validation loss: 1.8639724933972923

Epoch: 6| Step: 10
Training loss: 2.703382968902588
Validation loss: 1.8730070296154226

Epoch: 6| Step: 11
Training loss: 1.5775980949401855
Validation loss: 1.8453085114878993

Epoch: 6| Step: 12
Training loss: 1.522286295890808
Validation loss: 1.8591686230833813

Epoch: 6| Step: 13
Training loss: 2.4348056316375732
Validation loss: 1.8016074934313375

Epoch: 131| Step: 0
Training loss: 1.6665586233139038
Validation loss: 1.864239586296902

Epoch: 6| Step: 1
Training loss: 2.0654759407043457
Validation loss: 1.8657108481212328

Epoch: 6| Step: 2
Training loss: 2.346771717071533
Validation loss: 1.8832338497202883

Epoch: 6| Step: 3
Training loss: 1.88890540599823
Validation loss: 1.8804753493237238

Epoch: 6| Step: 4
Training loss: 2.0817883014678955
Validation loss: 1.8706492839321014

Epoch: 6| Step: 5
Training loss: 2.3353240489959717
Validation loss: 1.8785900569731189

Epoch: 6| Step: 6
Training loss: 1.8690072298049927
Validation loss: 1.8655491452063284

Epoch: 6| Step: 7
Training loss: 1.7906692028045654
Validation loss: 1.9015114486858409

Epoch: 6| Step: 8
Training loss: 2.009627103805542
Validation loss: 1.852560773972542

Epoch: 6| Step: 9
Training loss: 2.1401543617248535
Validation loss: 1.8554478140287503

Epoch: 6| Step: 10
Training loss: 1.9289333820343018
Validation loss: 1.9081051490640129

Epoch: 6| Step: 11
Training loss: 2.3815855979919434
Validation loss: 1.8508296935789046

Epoch: 6| Step: 12
Training loss: 1.6160695552825928
Validation loss: 1.8360918862845308

Epoch: 6| Step: 13
Training loss: 1.7410836219787598
Validation loss: 1.9016756242321384

Epoch: 132| Step: 0
Training loss: 2.0780539512634277
Validation loss: 1.890915011846891

Epoch: 6| Step: 1
Training loss: 1.6304819583892822
Validation loss: 1.8512196207559237

Epoch: 6| Step: 2
Training loss: 2.065739870071411
Validation loss: 1.8639307047731133

Epoch: 6| Step: 3
Training loss: 2.434356689453125
Validation loss: 1.8720461758234168

Epoch: 6| Step: 4
Training loss: 1.6413546800613403
Validation loss: 1.8798974367880052

Epoch: 6| Step: 5
Training loss: 1.6480029821395874
Validation loss: 1.8448456243802143

Epoch: 6| Step: 6
Training loss: 2.4963340759277344
Validation loss: 1.8630351058898433

Epoch: 6| Step: 7
Training loss: 1.3388090133666992
Validation loss: 1.8688336674885084

Epoch: 6| Step: 8
Training loss: 2.1738176345825195
Validation loss: 1.8718853817191174

Epoch: 6| Step: 9
Training loss: 1.7201049327850342
Validation loss: 1.8460484909754928

Epoch: 6| Step: 10
Training loss: 2.290921926498413
Validation loss: 1.8368822490015337

Epoch: 6| Step: 11
Training loss: 2.186216354370117
Validation loss: 1.8647177116845244

Epoch: 6| Step: 12
Training loss: 2.4846255779266357
Validation loss: 1.8632118253297703

Epoch: 6| Step: 13
Training loss: 1.509916067123413
Validation loss: 1.8494462415736208

Epoch: 133| Step: 0
Training loss: 1.6321263313293457
Validation loss: 1.8701555344366259

Epoch: 6| Step: 1
Training loss: 1.819096326828003
Validation loss: 1.838766049313289

Epoch: 6| Step: 2
Training loss: 1.5301915407180786
Validation loss: 1.8519848649219801

Epoch: 6| Step: 3
Training loss: 2.2653932571411133
Validation loss: 1.8302884896596272

Epoch: 6| Step: 4
Training loss: 1.2223776578903198
Validation loss: 1.8640569102379583

Epoch: 6| Step: 5
Training loss: 2.7713518142700195
Validation loss: 1.8509628285643875

Epoch: 6| Step: 6
Training loss: 1.9434089660644531
Validation loss: 1.824144131393843

Epoch: 6| Step: 7
Training loss: 1.7205495834350586
Validation loss: 1.8175540470307874

Epoch: 6| Step: 8
Training loss: 2.0773978233337402
Validation loss: 1.8557315616197483

Epoch: 6| Step: 9
Training loss: 2.1721878051757812
Validation loss: 1.8716381788253784

Epoch: 6| Step: 10
Training loss: 2.037205696105957
Validation loss: 1.8395863527892737

Epoch: 6| Step: 11
Training loss: 2.243196964263916
Validation loss: 1.85681228996605

Epoch: 6| Step: 12
Training loss: 2.1562395095825195
Validation loss: 1.8594685651922738

Epoch: 6| Step: 13
Training loss: 2.150681495666504
Validation loss: 1.8367549527075984

Epoch: 134| Step: 0
Training loss: 2.2007040977478027
Validation loss: 1.848723921724545

Epoch: 6| Step: 1
Training loss: 1.7885648012161255
Validation loss: 1.8425465053127659

Epoch: 6| Step: 2
Training loss: 1.8036112785339355
Validation loss: 1.8105086690636092

Epoch: 6| Step: 3
Training loss: 2.038172960281372
Validation loss: 1.8290089150910736

Epoch: 6| Step: 4
Training loss: 2.4807276725769043
Validation loss: 1.863304712439096

Epoch: 6| Step: 5
Training loss: 2.57684326171875
Validation loss: 1.8239845806552517

Epoch: 6| Step: 6
Training loss: 1.3386329412460327
Validation loss: 1.8102472328370618

Epoch: 6| Step: 7
Training loss: 2.174117088317871
Validation loss: 1.8712169406234578

Epoch: 6| Step: 8
Training loss: 1.8464832305908203
Validation loss: 1.835943627101119

Epoch: 6| Step: 9
Training loss: 1.7588908672332764
Validation loss: 1.8359206235536965

Epoch: 6| Step: 10
Training loss: 2.2455506324768066
Validation loss: 1.8061932556090816

Epoch: 6| Step: 11
Training loss: 1.7860571146011353
Validation loss: 1.8400854936210058

Epoch: 6| Step: 12
Training loss: 1.5845746994018555
Validation loss: 1.795188602580819

Epoch: 6| Step: 13
Training loss: 2.089562177658081
Validation loss: 1.8413734512944375

Epoch: 135| Step: 0
Training loss: 2.4754273891448975
Validation loss: 1.869695596797492

Epoch: 6| Step: 1
Training loss: 2.2229461669921875
Validation loss: 1.7826843441173594

Epoch: 6| Step: 2
Training loss: 2.0226078033447266
Validation loss: 1.8193795001634987

Epoch: 6| Step: 3
Training loss: 1.5128753185272217
Validation loss: 1.8165961183527464

Epoch: 6| Step: 4
Training loss: 2.054323673248291
Validation loss: 1.8379505744544409

Epoch: 6| Step: 5
Training loss: 1.9195985794067383
Validation loss: 1.8205529630825084

Epoch: 6| Step: 6
Training loss: 1.7851600646972656
Validation loss: 1.85586719359121

Epoch: 6| Step: 7
Training loss: 2.012110948562622
Validation loss: 1.8533913807202411

Epoch: 6| Step: 8
Training loss: 2.451848030090332
Validation loss: 1.8836947871792702

Epoch: 6| Step: 9
Training loss: 2.1031570434570312
Validation loss: 1.9152056619685183

Epoch: 6| Step: 10
Training loss: 1.1192834377288818
Validation loss: 1.8487292207697386

Epoch: 6| Step: 11
Training loss: 1.640878438949585
Validation loss: 1.8531482860606203

Epoch: 6| Step: 12
Training loss: 2.241705894470215
Validation loss: 1.8573804478491507

Epoch: 6| Step: 13
Training loss: 2.2861204147338867
Validation loss: 1.8952216435504217

Epoch: 136| Step: 0
Training loss: 1.5852653980255127
Validation loss: 1.8731674712191346

Epoch: 6| Step: 1
Training loss: 2.295076608657837
Validation loss: 1.839007951880014

Epoch: 6| Step: 2
Training loss: 2.3934712409973145
Validation loss: 1.901620695667882

Epoch: 6| Step: 3
Training loss: 1.9055815935134888
Validation loss: 1.8603623220997472

Epoch: 6| Step: 4
Training loss: 2.3052268028259277
Validation loss: 1.8937989998889226

Epoch: 6| Step: 5
Training loss: 1.3615531921386719
Validation loss: 1.8722329626801193

Epoch: 6| Step: 6
Training loss: 2.328010082244873
Validation loss: 1.8591817527688959

Epoch: 6| Step: 7
Training loss: 2.0182385444641113
Validation loss: 1.8448429466575704

Epoch: 6| Step: 8
Training loss: 2.346816062927246
Validation loss: 1.8795557188731369

Epoch: 6| Step: 9
Training loss: 1.8757927417755127
Validation loss: 1.8304553275467248

Epoch: 6| Step: 10
Training loss: 1.9420928955078125
Validation loss: 1.8452146437860304

Epoch: 6| Step: 11
Training loss: 2.145843982696533
Validation loss: 1.8506775620163127

Epoch: 6| Step: 12
Training loss: 1.8401129245758057
Validation loss: 1.8395276479823615

Epoch: 6| Step: 13
Training loss: 1.4353654384613037
Validation loss: 1.8517327436836817

Epoch: 137| Step: 0
Training loss: 1.7057440280914307
Validation loss: 1.8604603877631567

Epoch: 6| Step: 1
Training loss: 1.9319654703140259
Validation loss: 1.8687909687719038

Epoch: 6| Step: 2
Training loss: 1.8084616661071777
Validation loss: 1.8411108998842136

Epoch: 6| Step: 3
Training loss: 1.461418867111206
Validation loss: 1.8783138311037453

Epoch: 6| Step: 4
Training loss: 2.1194403171539307
Validation loss: 1.8607345127290296

Epoch: 6| Step: 5
Training loss: 2.072633743286133
Validation loss: 1.8594258344301613

Epoch: 6| Step: 6
Training loss: 1.697248935699463
Validation loss: 1.858852978675596

Epoch: 6| Step: 7
Training loss: 2.1161184310913086
Validation loss: 1.8937738416015462

Epoch: 6| Step: 8
Training loss: 2.4015870094299316
Validation loss: 1.8692066067008561

Epoch: 6| Step: 9
Training loss: 1.878880262374878
Validation loss: 1.8641698039988035

Epoch: 6| Step: 10
Training loss: 1.3758056163787842
Validation loss: 1.857269916483151

Epoch: 6| Step: 11
Training loss: 2.7030277252197266
Validation loss: 1.854336279694752

Epoch: 6| Step: 12
Training loss: 2.092437267303467
Validation loss: 1.850627517187467

Epoch: 6| Step: 13
Training loss: 2.5156843662261963
Validation loss: 1.8402268809656943

Epoch: 138| Step: 0
Training loss: 2.1529603004455566
Validation loss: 1.8647952925774358

Epoch: 6| Step: 1
Training loss: 2.2189736366271973
Validation loss: 1.8237596763077604

Epoch: 6| Step: 2
Training loss: 2.180741786956787
Validation loss: 1.8382508190729285

Epoch: 6| Step: 3
Training loss: 2.248055934906006
Validation loss: 1.85004735121163

Epoch: 6| Step: 4
Training loss: 1.7468633651733398
Validation loss: 1.8910238217282038

Epoch: 6| Step: 5
Training loss: 2.2731776237487793
Validation loss: 1.8569223906404229

Epoch: 6| Step: 6
Training loss: 1.6253559589385986
Validation loss: 1.8744804384887859

Epoch: 6| Step: 7
Training loss: 1.439468264579773
Validation loss: 1.8710152487601004

Epoch: 6| Step: 8
Training loss: 1.6472015380859375
Validation loss: 1.8687648619374921

Epoch: 6| Step: 9
Training loss: 2.1368513107299805
Validation loss: 1.809735253293027

Epoch: 6| Step: 10
Training loss: 1.986317753791809
Validation loss: 1.8345906529375302

Epoch: 6| Step: 11
Training loss: 2.24800181388855
Validation loss: 1.8565006409921954

Epoch: 6| Step: 12
Training loss: 2.0079758167266846
Validation loss: 1.8222146329059397

Epoch: 6| Step: 13
Training loss: 1.7680631875991821
Validation loss: 1.823053244621523

Epoch: 139| Step: 0
Training loss: 1.4332371950149536
Validation loss: 1.8537651582430767

Epoch: 6| Step: 1
Training loss: 1.5988881587982178
Validation loss: 1.8314762397478985

Epoch: 6| Step: 2
Training loss: 1.849839210510254
Validation loss: 1.8159599047835155

Epoch: 6| Step: 3
Training loss: 1.5038387775421143
Validation loss: 1.8443099478239655

Epoch: 6| Step: 4
Training loss: 2.2740416526794434
Validation loss: 1.910098769331491

Epoch: 6| Step: 5
Training loss: 2.7588677406311035
Validation loss: 1.84581579572411

Epoch: 6| Step: 6
Training loss: 2.0544955730438232
Validation loss: 1.8722199304129488

Epoch: 6| Step: 7
Training loss: 2.415609359741211
Validation loss: 1.8937273115240119

Epoch: 6| Step: 8
Training loss: 1.5302975177764893
Validation loss: 1.874315651514197

Epoch: 6| Step: 9
Training loss: 2.4756298065185547
Validation loss: 1.8338667346585182

Epoch: 6| Step: 10
Training loss: 1.918107032775879
Validation loss: 1.8655710066518476

Epoch: 6| Step: 11
Training loss: 1.961700201034546
Validation loss: 1.8799693674169562

Epoch: 6| Step: 12
Training loss: 2.0909292697906494
Validation loss: 1.8877157113885368

Epoch: 6| Step: 13
Training loss: 1.3990048170089722
Validation loss: 1.86232921513178

Epoch: 140| Step: 0
Training loss: 2.1032943725585938
Validation loss: 1.8786321993797057

Epoch: 6| Step: 1
Training loss: 1.9356355667114258
Validation loss: 1.8977033361311881

Epoch: 6| Step: 2
Training loss: 1.85359787940979
Validation loss: 1.8470042623499388

Epoch: 6| Step: 3
Training loss: 1.6439173221588135
Validation loss: 1.83847265730622

Epoch: 6| Step: 4
Training loss: 2.104184865951538
Validation loss: 1.8465392243477605

Epoch: 6| Step: 5
Training loss: 1.8297477960586548
Validation loss: 1.8454563515160674

Epoch: 6| Step: 6
Training loss: 1.9783844947814941
Validation loss: 1.8826716792198919

Epoch: 6| Step: 7
Training loss: 1.9846408367156982
Validation loss: 1.845200607853551

Epoch: 6| Step: 8
Training loss: 2.734740734100342
Validation loss: 1.8449532549868348

Epoch: 6| Step: 9
Training loss: 2.5144519805908203
Validation loss: 1.8065007104668567

Epoch: 6| Step: 10
Training loss: 1.91355562210083
Validation loss: 1.832335796407474

Epoch: 6| Step: 11
Training loss: 1.877954125404358
Validation loss: 1.862993924848495

Epoch: 6| Step: 12
Training loss: 1.9260101318359375
Validation loss: 1.8614145363530805

Epoch: 6| Step: 13
Training loss: 1.7009053230285645
Validation loss: 1.823839541404478

Epoch: 141| Step: 0
Training loss: 1.891735315322876
Validation loss: 1.8494041760762532

Epoch: 6| Step: 1
Training loss: 2.0866360664367676
Validation loss: 1.8379729050461964

Epoch: 6| Step: 2
Training loss: 1.929337739944458
Validation loss: 1.8821640963195472

Epoch: 6| Step: 3
Training loss: 1.3863365650177002
Validation loss: 1.8734136781384867

Epoch: 6| Step: 4
Training loss: 2.53369140625
Validation loss: 1.904699897253385

Epoch: 6| Step: 5
Training loss: 2.1022286415100098
Validation loss: 1.8818033561911633

Epoch: 6| Step: 6
Training loss: 2.058250665664673
Validation loss: 1.9007282564716954

Epoch: 6| Step: 7
Training loss: 1.6019400358200073
Validation loss: 1.890410554024481

Epoch: 6| Step: 8
Training loss: 1.6876899003982544
Validation loss: 1.9452083059536514

Epoch: 6| Step: 9
Training loss: 1.8754879236221313
Validation loss: 1.8770334336065477

Epoch: 6| Step: 10
Training loss: 2.1912331581115723
Validation loss: 1.892513721219955

Epoch: 6| Step: 11
Training loss: 2.2347068786621094
Validation loss: 1.8920294187402213

Epoch: 6| Step: 12
Training loss: 2.38887882232666
Validation loss: 1.870523650159118

Epoch: 6| Step: 13
Training loss: 2.1010422706604004
Validation loss: 1.8994205715835735

Epoch: 142| Step: 0
Training loss: 2.1867733001708984
Validation loss: 1.8719797416399884

Epoch: 6| Step: 1
Training loss: 1.914781928062439
Validation loss: 1.9097892533066452

Epoch: 6| Step: 2
Training loss: 1.7853409051895142
Validation loss: 1.8747088486148464

Epoch: 6| Step: 3
Training loss: 1.6776816844940186
Validation loss: 1.865896786412885

Epoch: 6| Step: 4
Training loss: 1.7634220123291016
Validation loss: 1.8882918742395216

Epoch: 6| Step: 5
Training loss: 1.8656091690063477
Validation loss: 1.8830915292104085

Epoch: 6| Step: 6
Training loss: 1.4385521411895752
Validation loss: 1.845437333148013

Epoch: 6| Step: 7
Training loss: 2.922661781311035
Validation loss: 1.8377634620153775

Epoch: 6| Step: 8
Training loss: 1.7801811695098877
Validation loss: 1.9016598988604803

Epoch: 6| Step: 9
Training loss: 1.660341739654541
Validation loss: 1.8760940156957155

Epoch: 6| Step: 10
Training loss: 2.3962039947509766
Validation loss: 1.8489661921737015

Epoch: 6| Step: 11
Training loss: 2.179396629333496
Validation loss: 1.8343236959108742

Epoch: 6| Step: 12
Training loss: 2.4548869132995605
Validation loss: 1.8406084583651634

Epoch: 6| Step: 13
Training loss: 1.7257421016693115
Validation loss: 1.8499285995319326

Epoch: 143| Step: 0
Training loss: 1.9575490951538086
Validation loss: 1.8499851085806405

Epoch: 6| Step: 1
Training loss: 1.543926477432251
Validation loss: 1.8478724905239639

Epoch: 6| Step: 2
Training loss: 1.7623697519302368
Validation loss: 1.8194626480020502

Epoch: 6| Step: 3
Training loss: 2.438875198364258
Validation loss: 1.8496323708565003

Epoch: 6| Step: 4
Training loss: 2.002049207687378
Validation loss: 1.8643613066724551

Epoch: 6| Step: 5
Training loss: 1.567598581314087
Validation loss: 1.7988555392911356

Epoch: 6| Step: 6
Training loss: 3.0042572021484375
Validation loss: 1.8225672860299387

Epoch: 6| Step: 7
Training loss: 1.7113807201385498
Validation loss: 1.8687503735224407

Epoch: 6| Step: 8
Training loss: 1.6073650121688843
Validation loss: 1.8569122001688967

Epoch: 6| Step: 9
Training loss: 2.20365309715271
Validation loss: 1.8538013709488737

Epoch: 6| Step: 10
Training loss: 1.870110034942627
Validation loss: 1.8708824983207129

Epoch: 6| Step: 11
Training loss: 1.966070294380188
Validation loss: 1.834129141223046

Epoch: 6| Step: 12
Training loss: 1.502232551574707
Validation loss: 1.836383440161264

Epoch: 6| Step: 13
Training loss: 2.4023947715759277
Validation loss: 1.8721156094663887

Epoch: 144| Step: 0
Training loss: 2.9800515174865723
Validation loss: 1.8634279953536166

Epoch: 6| Step: 1
Training loss: 2.178220510482788
Validation loss: 1.875180862283194

Epoch: 6| Step: 2
Training loss: 2.3628029823303223
Validation loss: 1.8637039264043171

Epoch: 6| Step: 3
Training loss: 1.7842117547988892
Validation loss: 1.866260741346626

Epoch: 6| Step: 4
Training loss: 1.8147341012954712
Validation loss: 1.8692961328773088

Epoch: 6| Step: 5
Training loss: 1.2123998403549194
Validation loss: 1.8819301013023622

Epoch: 6| Step: 6
Training loss: 2.109283924102783
Validation loss: 1.8827547398946618

Epoch: 6| Step: 7
Training loss: 1.6227495670318604
Validation loss: 1.876246335685894

Epoch: 6| Step: 8
Training loss: 1.4661921262741089
Validation loss: 1.8805285794760591

Epoch: 6| Step: 9
Training loss: 1.761178970336914
Validation loss: 1.8861925614777433

Epoch: 6| Step: 10
Training loss: 1.9833709001541138
Validation loss: 1.890008572609194

Epoch: 6| Step: 11
Training loss: 2.211045503616333
Validation loss: 1.8483447156926638

Epoch: 6| Step: 12
Training loss: 2.2923901081085205
Validation loss: 1.880688581415402

Epoch: 6| Step: 13
Training loss: 1.7406948804855347
Validation loss: 1.8499670003050117

Epoch: 145| Step: 0
Training loss: 2.3514938354492188
Validation loss: 1.8942111717757357

Epoch: 6| Step: 1
Training loss: 1.8299834728240967
Validation loss: 1.838917004164829

Epoch: 6| Step: 2
Training loss: 2.498699903488159
Validation loss: 1.8676905350018573

Epoch: 6| Step: 3
Training loss: 1.6792206764221191
Validation loss: 1.8279153326506257

Epoch: 6| Step: 4
Training loss: 1.6070270538330078
Validation loss: 1.8436886328522877

Epoch: 6| Step: 5
Training loss: 1.4182863235473633
Validation loss: 1.8353145750620032

Epoch: 6| Step: 6
Training loss: 2.377511739730835
Validation loss: 1.8570762988059752

Epoch: 6| Step: 7
Training loss: 1.8906335830688477
Validation loss: 1.882422516422887

Epoch: 6| Step: 8
Training loss: 2.709716558456421
Validation loss: 1.8558310283127653

Epoch: 6| Step: 9
Training loss: 1.6250616312026978
Validation loss: 1.884403423596454

Epoch: 6| Step: 10
Training loss: 1.8057743310928345
Validation loss: 1.8295780356212328

Epoch: 6| Step: 11
Training loss: 1.9538006782531738
Validation loss: 1.890938679377238

Epoch: 6| Step: 12
Training loss: 2.1566672325134277
Validation loss: 1.8162838720506238

Epoch: 6| Step: 13
Training loss: 1.8410886526107788
Validation loss: 1.8927167820674118

Epoch: 146| Step: 0
Training loss: 1.865281105041504
Validation loss: 1.8462557241480837

Epoch: 6| Step: 1
Training loss: 1.9674906730651855
Validation loss: 1.836833442411115

Epoch: 6| Step: 2
Training loss: 1.5886280536651611
Validation loss: 1.8832152581983996

Epoch: 6| Step: 3
Training loss: 2.6759033203125
Validation loss: 1.8268550685656968

Epoch: 6| Step: 4
Training loss: 2.2126352787017822
Validation loss: 1.8773110310236614

Epoch: 6| Step: 5
Training loss: 2.0931525230407715
Validation loss: 1.9021338147501792

Epoch: 6| Step: 6
Training loss: 1.965494155883789
Validation loss: 1.9206687109444731

Epoch: 6| Step: 7
Training loss: 2.0227460861206055
Validation loss: 1.9044195810953777

Epoch: 6| Step: 8
Training loss: 2.2920660972595215
Validation loss: 1.858247346775506

Epoch: 6| Step: 9
Training loss: 1.468367099761963
Validation loss: 1.8857528266086374

Epoch: 6| Step: 10
Training loss: 1.680056095123291
Validation loss: 1.8823526777246946

Epoch: 6| Step: 11
Training loss: 1.9265625476837158
Validation loss: 1.8844384249820505

Epoch: 6| Step: 12
Training loss: 1.8446496725082397
Validation loss: 1.9499513833753523

Epoch: 6| Step: 13
Training loss: 2.008122682571411
Validation loss: 1.8846403655185495

Epoch: 147| Step: 0
Training loss: 2.3784842491149902
Validation loss: 1.8654086307812763

Epoch: 6| Step: 1
Training loss: 1.8985528945922852
Validation loss: 1.85368735431343

Epoch: 6| Step: 2
Training loss: 2.5087485313415527
Validation loss: 1.8426792454975907

Epoch: 6| Step: 3
Training loss: 1.2875127792358398
Validation loss: 1.8665636175422258

Epoch: 6| Step: 4
Training loss: 1.7238233089447021
Validation loss: 1.8443796839765323

Epoch: 6| Step: 5
Training loss: 1.8266631364822388
Validation loss: 1.840880314509074

Epoch: 6| Step: 6
Training loss: 2.0137667655944824
Validation loss: 1.8746325136512838

Epoch: 6| Step: 7
Training loss: 1.7969412803649902
Validation loss: 1.8288498706715082

Epoch: 6| Step: 8
Training loss: 2.4485459327697754
Validation loss: 1.867545791851577

Epoch: 6| Step: 9
Training loss: 2.0073843002319336
Validation loss: 1.8458639293588617

Epoch: 6| Step: 10
Training loss: 1.7257933616638184
Validation loss: 1.8503883500253

Epoch: 6| Step: 11
Training loss: 1.834829568862915
Validation loss: 1.8678345808418848

Epoch: 6| Step: 12
Training loss: 1.9420994520187378
Validation loss: 1.8843706525782102

Epoch: 6| Step: 13
Training loss: 1.5053141117095947
Validation loss: 1.8383887275572746

Epoch: 148| Step: 0
Training loss: 1.3460251092910767
Validation loss: 1.8869550510119366

Epoch: 6| Step: 1
Training loss: 2.2484130859375
Validation loss: 1.8177879715478549

Epoch: 6| Step: 2
Training loss: 1.66213059425354
Validation loss: 1.8778593950374152

Epoch: 6| Step: 3
Training loss: 1.9111738204956055
Validation loss: 1.8084788155812088

Epoch: 6| Step: 4
Training loss: 2.398043155670166
Validation loss: 1.8406485472956011

Epoch: 6| Step: 5
Training loss: 1.8662935495376587
Validation loss: 1.839080701592148

Epoch: 6| Step: 6
Training loss: 1.9125734567642212
Validation loss: 1.8540551854718117

Epoch: 6| Step: 7
Training loss: 1.6445667743682861
Validation loss: 1.841238981934004

Epoch: 6| Step: 8
Training loss: 2.3211283683776855
Validation loss: 1.8213802409428421

Epoch: 6| Step: 9
Training loss: 1.8408927917480469
Validation loss: 1.8821441973409345

Epoch: 6| Step: 10
Training loss: 2.3799071311950684
Validation loss: 1.8353962898254395

Epoch: 6| Step: 11
Training loss: 1.8133666515350342
Validation loss: 1.8519812207068167

Epoch: 6| Step: 12
Training loss: 1.7189000844955444
Validation loss: 1.8740739527569021

Epoch: 6| Step: 13
Training loss: 2.2033376693725586
Validation loss: 1.8617221488747546

Epoch: 149| Step: 0
Training loss: 2.426251173019409
Validation loss: 1.796543913502847

Epoch: 6| Step: 1
Training loss: 1.996224284172058
Validation loss: 1.8513618797384284

Epoch: 6| Step: 2
Training loss: 1.7785422801971436
Validation loss: 1.8437683351578251

Epoch: 6| Step: 3
Training loss: 1.9678531885147095
Validation loss: 1.8578302398804696

Epoch: 6| Step: 4
Training loss: 1.6256260871887207
Validation loss: 1.9339153253903953

Epoch: 6| Step: 5
Training loss: 1.0490858554840088
Validation loss: 1.8570926176604403

Epoch: 6| Step: 6
Training loss: 1.8929753303527832
Validation loss: 1.9137320313402402

Epoch: 6| Step: 7
Training loss: 1.7789278030395508
Validation loss: 1.9017576261233258

Epoch: 6| Step: 8
Training loss: 1.7466037273406982
Validation loss: 1.8388312824310795

Epoch: 6| Step: 9
Training loss: 2.02775239944458
Validation loss: 1.905879811574054

Epoch: 6| Step: 10
Training loss: 2.4520115852355957
Validation loss: 1.9077095729048534

Epoch: 6| Step: 11
Training loss: 2.360348701477051
Validation loss: 1.9286107734967304

Epoch: 6| Step: 12
Training loss: 1.8603838682174683
Validation loss: 1.9117599482177405

Epoch: 6| Step: 13
Training loss: 2.3605663776397705
Validation loss: 1.940695152487806

Epoch: 150| Step: 0
Training loss: 1.4942315816879272
Validation loss: 1.9249900861452984

Epoch: 6| Step: 1
Training loss: 2.6771726608276367
Validation loss: 1.9266778781849851

Epoch: 6| Step: 2
Training loss: 2.126791477203369
Validation loss: 1.9268992536811418

Epoch: 6| Step: 3
Training loss: 2.279162883758545
Validation loss: 1.965608412219632

Epoch: 6| Step: 4
Training loss: 0.8625236749649048
Validation loss: 1.8457356293996174

Epoch: 6| Step: 5
Training loss: 2.1254780292510986
Validation loss: 1.8975338717942596

Epoch: 6| Step: 6
Training loss: 1.48622465133667
Validation loss: 1.8625495151806903

Epoch: 6| Step: 7
Training loss: 2.2292394638061523
Validation loss: 1.8570123436630412

Epoch: 6| Step: 8
Training loss: 2.2831685543060303
Validation loss: 1.839003412954269

Epoch: 6| Step: 9
Training loss: 2.3494465351104736
Validation loss: 1.8526318329636768

Epoch: 6| Step: 10
Training loss: 1.7546160221099854
Validation loss: 1.8467067249359623

Epoch: 6| Step: 11
Training loss: 1.8998628854751587
Validation loss: 1.8369552448231687

Epoch: 6| Step: 12
Training loss: 2.0221307277679443
Validation loss: 1.8639249314544022

Epoch: 6| Step: 13
Training loss: 2.195434093475342
Validation loss: 1.8796746500076786

Epoch: 151| Step: 0
Training loss: 2.069589614868164
Validation loss: 1.9190220589278846

Epoch: 6| Step: 1
Training loss: 2.1232824325561523
Validation loss: 1.8061868003619614

Epoch: 6| Step: 2
Training loss: 2.223775863647461
Validation loss: 1.835174229837233

Epoch: 6| Step: 3
Training loss: 2.770112991333008
Validation loss: 1.8819902930208432

Epoch: 6| Step: 4
Training loss: 1.1959866285324097
Validation loss: 1.885466484613316

Epoch: 6| Step: 5
Training loss: 2.0756618976593018
Validation loss: 1.8782830545979161

Epoch: 6| Step: 6
Training loss: 2.6378889083862305
Validation loss: 1.8403652047598233

Epoch: 6| Step: 7
Training loss: 1.9311634302139282
Validation loss: 1.83346850128584

Epoch: 6| Step: 8
Training loss: 2.30106782913208
Validation loss: 1.8775920111645934

Epoch: 6| Step: 9
Training loss: 1.6626546382904053
Validation loss: 1.8650821229462982

Epoch: 6| Step: 10
Training loss: 1.1072680950164795
Validation loss: 1.861496087043516

Epoch: 6| Step: 11
Training loss: 2.014183759689331
Validation loss: 1.8563087345451437

Epoch: 6| Step: 12
Training loss: 1.0159239768981934
Validation loss: 1.913783129825387

Epoch: 6| Step: 13
Training loss: 2.0983731746673584
Validation loss: 1.8759346469756095

Epoch: 152| Step: 0
Training loss: 1.013695478439331
Validation loss: 1.9220796413319086

Epoch: 6| Step: 1
Training loss: 2.188049793243408
Validation loss: 1.9060665087033344

Epoch: 6| Step: 2
Training loss: 1.4573800563812256
Validation loss: 1.9050552447636921

Epoch: 6| Step: 3
Training loss: 1.879603624343872
Validation loss: 1.9110274135425527

Epoch: 6| Step: 4
Training loss: 2.456972360610962
Validation loss: 1.933998292492282

Epoch: 6| Step: 5
Training loss: 1.7997212409973145
Validation loss: 1.910670272765621

Epoch: 6| Step: 6
Training loss: 1.8621190786361694
Validation loss: 1.9395102454769997

Epoch: 6| Step: 7
Training loss: 1.8608121871948242
Validation loss: 1.9460974354897775

Epoch: 6| Step: 8
Training loss: 2.626438617706299
Validation loss: 1.8861833182714318

Epoch: 6| Step: 9
Training loss: 2.343651294708252
Validation loss: 1.9158312095108854

Epoch: 6| Step: 10
Training loss: 2.629507541656494
Validation loss: 1.8891556314242783

Epoch: 6| Step: 11
Training loss: 1.9224202632904053
Validation loss: 1.8830899525714178

Epoch: 6| Step: 12
Training loss: 1.4030687808990479
Validation loss: 1.8992077394198346

Epoch: 6| Step: 13
Training loss: 1.847791075706482
Validation loss: 1.885036478760422

Epoch: 153| Step: 0
Training loss: 1.7952550649642944
Validation loss: 1.8749937806078183

Epoch: 6| Step: 1
Training loss: 2.3343825340270996
Validation loss: 1.8488280555253387

Epoch: 6| Step: 2
Training loss: 1.8245213031768799
Validation loss: 1.89829622801914

Epoch: 6| Step: 3
Training loss: 1.539475679397583
Validation loss: 1.8419322018982263

Epoch: 6| Step: 4
Training loss: 1.6076912879943848
Validation loss: 1.8572361571814424

Epoch: 6| Step: 5
Training loss: 2.6730639934539795
Validation loss: 1.8413672062658495

Epoch: 6| Step: 6
Training loss: 1.751516580581665
Validation loss: 1.8861200271114227

Epoch: 6| Step: 7
Training loss: 2.2639849185943604
Validation loss: 1.8569528954003447

Epoch: 6| Step: 8
Training loss: 2.030263662338257
Validation loss: 1.8621750429112425

Epoch: 6| Step: 9
Training loss: 2.445054769515991
Validation loss: 1.8414940654590566

Epoch: 6| Step: 10
Training loss: 1.1135469675064087
Validation loss: 1.846712008599312

Epoch: 6| Step: 11
Training loss: 2.0962445735931396
Validation loss: 1.8512480515305714

Epoch: 6| Step: 12
Training loss: 1.3516225814819336
Validation loss: 1.8560786683072326

Epoch: 6| Step: 13
Training loss: 2.1062071323394775
Validation loss: 1.8767769080336376

Epoch: 154| Step: 0
Training loss: 2.4229750633239746
Validation loss: 1.8961501044611777

Epoch: 6| Step: 1
Training loss: 1.6452947854995728
Validation loss: 1.8938614296656784

Epoch: 6| Step: 2
Training loss: 2.2509255409240723
Validation loss: 1.8433685533462032

Epoch: 6| Step: 3
Training loss: 1.6415255069732666
Validation loss: 1.858221597568963

Epoch: 6| Step: 4
Training loss: 1.8741028308868408
Validation loss: 1.8947425632066623

Epoch: 6| Step: 5
Training loss: 2.0275259017944336
Validation loss: 1.8306721679625972

Epoch: 6| Step: 6
Training loss: 1.868177056312561
Validation loss: 1.7988309911502305

Epoch: 6| Step: 7
Training loss: 2.0290603637695312
Validation loss: 1.8582713155336277

Epoch: 6| Step: 8
Training loss: 1.4951846599578857
Validation loss: 1.8590062292673255

Epoch: 6| Step: 9
Training loss: 2.0465335845947266
Validation loss: 1.8451428208299863

Epoch: 6| Step: 10
Training loss: 1.8035976886749268
Validation loss: 1.846414122530209

Epoch: 6| Step: 11
Training loss: 2.108400821685791
Validation loss: 1.8443750360960602

Epoch: 6| Step: 12
Training loss: 1.8501331806182861
Validation loss: 1.8543800359131188

Epoch: 6| Step: 13
Training loss: 2.2589111328125
Validation loss: 1.8420289126775597

Epoch: 155| Step: 0
Training loss: 2.0021190643310547
Validation loss: 1.8433839838991883

Epoch: 6| Step: 1
Training loss: 1.9929137229919434
Validation loss: 1.8776553625701575

Epoch: 6| Step: 2
Training loss: 1.9881209135055542
Validation loss: 1.8846933123885945

Epoch: 6| Step: 3
Training loss: 1.8621325492858887
Validation loss: 1.8529718614393664

Epoch: 6| Step: 4
Training loss: 1.8718997240066528
Validation loss: 1.8808121450485722

Epoch: 6| Step: 5
Training loss: 1.8784096240997314
Validation loss: 1.8728604226984003

Epoch: 6| Step: 6
Training loss: 1.388548731803894
Validation loss: 1.8777448567011024

Epoch: 6| Step: 7
Training loss: 2.0626473426818848
Validation loss: 1.8750298228315128

Epoch: 6| Step: 8
Training loss: 2.6860103607177734
Validation loss: 1.8807956057210122

Epoch: 6| Step: 9
Training loss: 1.674640417098999
Validation loss: 1.876394373114391

Epoch: 6| Step: 10
Training loss: 2.1354317665100098
Validation loss: 1.8762164654270295

Epoch: 6| Step: 11
Training loss: 1.5434924364089966
Validation loss: 1.9332249062035674

Epoch: 6| Step: 12
Training loss: 1.878127098083496
Validation loss: 1.8789927728714482

Epoch: 6| Step: 13
Training loss: 2.1799325942993164
Validation loss: 1.846488251481005

Epoch: 156| Step: 0
Training loss: 2.0008621215820312
Validation loss: 1.8901738030936128

Epoch: 6| Step: 1
Training loss: 1.2573375701904297
Validation loss: 1.8676243853825394

Epoch: 6| Step: 2
Training loss: 2.466970205307007
Validation loss: 1.874896498136623

Epoch: 6| Step: 3
Training loss: 2.230574131011963
Validation loss: 1.8971494308082006

Epoch: 6| Step: 4
Training loss: 1.9605566263198853
Validation loss: 1.8486067812929872

Epoch: 6| Step: 5
Training loss: 1.9289414882659912
Validation loss: 1.8885212136853127

Epoch: 6| Step: 6
Training loss: 1.6366853713989258
Validation loss: 1.841102841079876

Epoch: 6| Step: 7
Training loss: 2.4380099773406982
Validation loss: 1.9008002076097714

Epoch: 6| Step: 8
Training loss: 1.7713780403137207
Validation loss: 1.8519710622807986

Epoch: 6| Step: 9
Training loss: 1.7837660312652588
Validation loss: 1.8680692052328458

Epoch: 6| Step: 10
Training loss: 1.8916754722595215
Validation loss: 1.885034207374819

Epoch: 6| Step: 11
Training loss: 1.537837266921997
Validation loss: 1.8569261656012586

Epoch: 6| Step: 12
Training loss: 2.168085813522339
Validation loss: 1.8098390435659757

Epoch: 6| Step: 13
Training loss: 2.1125941276550293
Validation loss: 1.8111912717101395

Epoch: 157| Step: 0
Training loss: 1.9267646074295044
Validation loss: 1.8558747870947725

Epoch: 6| Step: 1
Training loss: 1.5705056190490723
Validation loss: 1.8403231174715105

Epoch: 6| Step: 2
Training loss: 2.060788869857788
Validation loss: 1.8696127912049652

Epoch: 6| Step: 3
Training loss: 2.5085866451263428
Validation loss: 1.8511520508796937

Epoch: 6| Step: 4
Training loss: 2.001185417175293
Validation loss: 1.8524202903111775

Epoch: 6| Step: 5
Training loss: 2.376357078552246
Validation loss: 1.8464384117434103

Epoch: 6| Step: 6
Training loss: 1.7293932437896729
Validation loss: 1.8432129967597224

Epoch: 6| Step: 7
Training loss: 1.8727822303771973
Validation loss: 1.834072059200656

Epoch: 6| Step: 8
Training loss: 1.5677838325500488
Validation loss: 1.8392750370887019

Epoch: 6| Step: 9
Training loss: 2.1402056217193604
Validation loss: 1.8705874873745827

Epoch: 6| Step: 10
Training loss: 1.4459267854690552
Validation loss: 1.8419974209159933

Epoch: 6| Step: 11
Training loss: 2.3541526794433594
Validation loss: 1.829190090138425

Epoch: 6| Step: 12
Training loss: 2.2350454330444336
Validation loss: 1.8205261768833283

Epoch: 6| Step: 13
Training loss: 1.1902086734771729
Validation loss: 1.8503209108947425

Epoch: 158| Step: 0
Training loss: 1.5887043476104736
Validation loss: 1.852472794953213

Epoch: 6| Step: 1
Training loss: 2.592639923095703
Validation loss: 1.86847335292447

Epoch: 6| Step: 2
Training loss: 2.2017359733581543
Validation loss: 1.86957008992472

Epoch: 6| Step: 3
Training loss: 1.9285798072814941
Validation loss: 1.8671516987585253

Epoch: 6| Step: 4
Training loss: 1.8491308689117432
Validation loss: 1.8769818557206022

Epoch: 6| Step: 5
Training loss: 1.9644335508346558
Validation loss: 1.8539926569948915

Epoch: 6| Step: 6
Training loss: 1.4983100891113281
Validation loss: 1.8523944167680637

Epoch: 6| Step: 7
Training loss: 1.7450544834136963
Validation loss: 1.8965878217451033

Epoch: 6| Step: 8
Training loss: 2.2098493576049805
Validation loss: 1.878065211798555

Epoch: 6| Step: 9
Training loss: 1.6762335300445557
Validation loss: 1.8459311864709342

Epoch: 6| Step: 10
Training loss: 1.9795348644256592
Validation loss: 1.9123959772048458

Epoch: 6| Step: 11
Training loss: 2.0053749084472656
Validation loss: 1.8618164677773752

Epoch: 6| Step: 12
Training loss: 1.5721216201782227
Validation loss: 1.8911349670861357

Epoch: 6| Step: 13
Training loss: 1.8401010036468506
Validation loss: 1.915886225238923

Epoch: 159| Step: 0
Training loss: 1.6197090148925781
Validation loss: 1.891408279377927

Epoch: 6| Step: 1
Training loss: 1.1504428386688232
Validation loss: 1.8660389325952018

Epoch: 6| Step: 2
Training loss: 2.270650863647461
Validation loss: 1.9074287453005392

Epoch: 6| Step: 3
Training loss: 2.5196077823638916
Validation loss: 1.8544976480545536

Epoch: 6| Step: 4
Training loss: 1.2952135801315308
Validation loss: 1.8810401193557247

Epoch: 6| Step: 5
Training loss: 1.7626159191131592
Validation loss: 1.8914256018977011

Epoch: 6| Step: 6
Training loss: 2.551276206970215
Validation loss: 1.84946882852944

Epoch: 6| Step: 7
Training loss: 1.1791062355041504
Validation loss: 1.8308966518730245

Epoch: 6| Step: 8
Training loss: 2.298938274383545
Validation loss: 1.8645448248873475

Epoch: 6| Step: 9
Training loss: 2.2406320571899414
Validation loss: 1.8470676124736827

Epoch: 6| Step: 10
Training loss: 2.1097826957702637
Validation loss: 1.8785411106642855

Epoch: 6| Step: 11
Training loss: 1.9658392667770386
Validation loss: 1.8695191926853632

Epoch: 6| Step: 12
Training loss: 2.3840880393981934
Validation loss: 1.8353842330235306

Epoch: 6| Step: 13
Training loss: 1.4737144708633423
Validation loss: 1.8818503092694026

Epoch: 160| Step: 0
Training loss: 2.0482072830200195
Validation loss: 1.8712571308177004

Epoch: 6| Step: 1
Training loss: 1.740013837814331
Validation loss: 1.821080869243991

Epoch: 6| Step: 2
Training loss: 1.3236010074615479
Validation loss: 1.8469212978116927

Epoch: 6| Step: 3
Training loss: 1.8762210607528687
Validation loss: 1.859571788900642

Epoch: 6| Step: 4
Training loss: 1.9253618717193604
Validation loss: 1.8183481116448679

Epoch: 6| Step: 5
Training loss: 2.2111544609069824
Validation loss: 1.8656627772956766

Epoch: 6| Step: 6
Training loss: 2.019223213195801
Validation loss: 1.8835481469349196

Epoch: 6| Step: 7
Training loss: 2.365373373031616
Validation loss: 1.8905298376596102

Epoch: 6| Step: 8
Training loss: 1.9517619609832764
Validation loss: 1.8502281814493158

Epoch: 6| Step: 9
Training loss: 1.9372544288635254
Validation loss: 1.8762989018553047

Epoch: 6| Step: 10
Training loss: 1.5239980220794678
Validation loss: 1.8810168927715671

Epoch: 6| Step: 11
Training loss: 1.9074565172195435
Validation loss: 1.8865582058506627

Epoch: 6| Step: 12
Training loss: 2.050036907196045
Validation loss: 1.8736736197625437

Epoch: 6| Step: 13
Training loss: 1.410538673400879
Validation loss: 1.8537328332983039

Epoch: 161| Step: 0
Training loss: 2.0473968982696533
Validation loss: 1.8668890294208322

Epoch: 6| Step: 1
Training loss: 2.4395570755004883
Validation loss: 1.8687519873342207

Epoch: 6| Step: 2
Training loss: 1.856364130973816
Validation loss: 1.8484356941715363

Epoch: 6| Step: 3
Training loss: 2.7345058917999268
Validation loss: 1.8465666142843102

Epoch: 6| Step: 4
Training loss: 2.56289005279541
Validation loss: 1.8078213404583674

Epoch: 6| Step: 5
Training loss: 1.7383439540863037
Validation loss: 1.8067200440232472

Epoch: 6| Step: 6
Training loss: 1.5176132917404175
Validation loss: 1.8589765474360476

Epoch: 6| Step: 7
Training loss: 1.4334651231765747
Validation loss: 1.8525074271745579

Epoch: 6| Step: 8
Training loss: 1.8864810466766357
Validation loss: 1.8055246158312726

Epoch: 6| Step: 9
Training loss: 2.054508686065674
Validation loss: 1.854606761727282

Epoch: 6| Step: 10
Training loss: 1.777482032775879
Validation loss: 1.8411396741867065

Epoch: 6| Step: 11
Training loss: 1.48263418674469
Validation loss: 1.8672574373983568

Epoch: 6| Step: 12
Training loss: 1.4734714031219482
Validation loss: 1.8408154313282301

Epoch: 6| Step: 13
Training loss: 1.146914005279541
Validation loss: 1.864302699283887

Epoch: 162| Step: 0
Training loss: 2.2238850593566895
Validation loss: 1.9496423454694851

Epoch: 6| Step: 1
Training loss: 1.5553159713745117
Validation loss: 1.9121246748073126

Epoch: 6| Step: 2
Training loss: 1.5054306983947754
Validation loss: 1.9024931051397835

Epoch: 6| Step: 3
Training loss: 1.6292471885681152
Validation loss: 1.9123675105392293

Epoch: 6| Step: 4
Training loss: 2.708388328552246
Validation loss: 1.8557102475115048

Epoch: 6| Step: 5
Training loss: 2.0934879779815674
Validation loss: 1.8625818132072367

Epoch: 6| Step: 6
Training loss: 1.883408546447754
Validation loss: 1.8751362472452142

Epoch: 6| Step: 7
Training loss: 1.6260218620300293
Validation loss: 1.8711559900673487

Epoch: 6| Step: 8
Training loss: 1.847682237625122
Validation loss: 1.854924230165379

Epoch: 6| Step: 9
Training loss: 1.0142865180969238
Validation loss: 1.8447535896813998

Epoch: 6| Step: 10
Training loss: 2.661689519882202
Validation loss: 1.8274492999558807

Epoch: 6| Step: 11
Training loss: 2.2741880416870117
Validation loss: 1.8504504003832418

Epoch: 6| Step: 12
Training loss: 1.7505338191986084
Validation loss: 1.8545909927737327

Epoch: 6| Step: 13
Training loss: 2.0695741176605225
Validation loss: 1.844839984370816

Epoch: 163| Step: 0
Training loss: 2.4134368896484375
Validation loss: 1.8679297995823685

Epoch: 6| Step: 1
Training loss: 1.5262906551361084
Validation loss: 1.8448456948803318

Epoch: 6| Step: 2
Training loss: 1.9206137657165527
Validation loss: 1.8441538580002323

Epoch: 6| Step: 3
Training loss: 2.7271876335144043
Validation loss: 1.840723083865258

Epoch: 6| Step: 4
Training loss: 1.3260815143585205
Validation loss: 1.8736789918714953

Epoch: 6| Step: 5
Training loss: 1.5273280143737793
Validation loss: 1.8773594312770392

Epoch: 6| Step: 6
Training loss: 1.641537070274353
Validation loss: 1.8296839960159794

Epoch: 6| Step: 7
Training loss: 2.01387882232666
Validation loss: 1.8533295251989876

Epoch: 6| Step: 8
Training loss: 2.251495361328125
Validation loss: 1.8676768118335354

Epoch: 6| Step: 9
Training loss: 1.8703337907791138
Validation loss: 1.882213979639033

Epoch: 6| Step: 10
Training loss: 1.70624577999115
Validation loss: 1.843154041997848

Epoch: 6| Step: 11
Training loss: 2.5272746086120605
Validation loss: 1.886725615429622

Epoch: 6| Step: 12
Training loss: 1.683322548866272
Validation loss: 1.8875115071573565

Epoch: 6| Step: 13
Training loss: 1.555680751800537
Validation loss: 1.8446458514018724

Epoch: 164| Step: 0
Training loss: 1.7838952541351318
Validation loss: 1.8422641933605235

Epoch: 6| Step: 1
Training loss: 1.871185541152954
Validation loss: 1.8415962983203191

Epoch: 6| Step: 2
Training loss: 1.4892369508743286
Validation loss: 1.8752673415727512

Epoch: 6| Step: 3
Training loss: 1.9452266693115234
Validation loss: 1.8396980749663485

Epoch: 6| Step: 4
Training loss: 1.302136778831482
Validation loss: 1.867541374698762

Epoch: 6| Step: 5
Training loss: 2.054321765899658
Validation loss: 1.8496266565015238

Epoch: 6| Step: 6
Training loss: 2.0608131885528564
Validation loss: 1.8435210079275153

Epoch: 6| Step: 7
Training loss: 2.184748649597168
Validation loss: 1.8288998244911112

Epoch: 6| Step: 8
Training loss: 1.6225264072418213
Validation loss: 1.8092621962229412

Epoch: 6| Step: 9
Training loss: 1.7441915273666382
Validation loss: 1.8748955290804628

Epoch: 6| Step: 10
Training loss: 2.308434247970581
Validation loss: 1.8673789103825886

Epoch: 6| Step: 11
Training loss: 3.1558074951171875
Validation loss: 1.8782784810630224

Epoch: 6| Step: 12
Training loss: 1.695995807647705
Validation loss: 1.8280414086516186

Epoch: 6| Step: 13
Training loss: 0.751480221748352
Validation loss: 1.8766706707657024

Epoch: 165| Step: 0
Training loss: 1.2817802429199219
Validation loss: 1.8358338250908801

Epoch: 6| Step: 1
Training loss: 2.378864288330078
Validation loss: 1.812307555188415

Epoch: 6| Step: 2
Training loss: 2.167654275894165
Validation loss: 1.8770315057487899

Epoch: 6| Step: 3
Training loss: 1.532200813293457
Validation loss: 1.892335714832429

Epoch: 6| Step: 4
Training loss: 2.185234785079956
Validation loss: 1.822725228084031

Epoch: 6| Step: 5
Training loss: 1.5210552215576172
Validation loss: 1.8551501740691483

Epoch: 6| Step: 6
Training loss: 0.959926962852478
Validation loss: 1.8336707007500432

Epoch: 6| Step: 7
Training loss: 1.877139925956726
Validation loss: 1.881716065509345

Epoch: 6| Step: 8
Training loss: 2.6683759689331055
Validation loss: 1.8946052417960217

Epoch: 6| Step: 9
Training loss: 1.8775265216827393
Validation loss: 1.8709580475284207

Epoch: 6| Step: 10
Training loss: 1.9661121368408203
Validation loss: 1.8564042122133317

Epoch: 6| Step: 11
Training loss: 2.152677536010742
Validation loss: 1.869037224400428

Epoch: 6| Step: 12
Training loss: 1.8296163082122803
Validation loss: 1.9199995494657947

Epoch: 6| Step: 13
Training loss: 2.2704505920410156
Validation loss: 1.8869481650731896

Epoch: 166| Step: 0
Training loss: 1.4781544208526611
Validation loss: 1.8541089334795553

Epoch: 6| Step: 1
Training loss: 2.0524561405181885
Validation loss: 1.883815550035046

Epoch: 6| Step: 2
Training loss: 1.6115226745605469
Validation loss: 1.821713650098411

Epoch: 6| Step: 3
Training loss: 1.2039655447006226
Validation loss: 1.9034797927384735

Epoch: 6| Step: 4
Training loss: 2.1820905208587646
Validation loss: 1.8832268714904785

Epoch: 6| Step: 5
Training loss: 1.9154386520385742
Validation loss: 1.8584133130247875

Epoch: 6| Step: 6
Training loss: 1.8439204692840576
Validation loss: 1.8726052520095662

Epoch: 6| Step: 7
Training loss: 1.94379460811615
Validation loss: 1.8824055989583333

Epoch: 6| Step: 8
Training loss: 2.2118053436279297
Validation loss: 1.8946230988348685

Epoch: 6| Step: 9
Training loss: 1.9414026737213135
Validation loss: 1.8698573804670764

Epoch: 6| Step: 10
Training loss: 1.8446156978607178
Validation loss: 1.8615999734529884

Epoch: 6| Step: 11
Training loss: 2.4659342765808105
Validation loss: 1.8301460025131062

Epoch: 6| Step: 12
Training loss: 2.1119651794433594
Validation loss: 1.8827047001930974

Epoch: 6| Step: 13
Training loss: 2.23067569732666
Validation loss: 1.8387950851071266

Epoch: 167| Step: 0
Training loss: 2.280670642852783
Validation loss: 1.8750010023834884

Epoch: 6| Step: 1
Training loss: 1.6024529933929443
Validation loss: 1.8721447785695393

Epoch: 6| Step: 2
Training loss: 2.049938440322876
Validation loss: 1.8517925111196374

Epoch: 6| Step: 3
Training loss: 1.5601470470428467
Validation loss: 1.862156255270845

Epoch: 6| Step: 4
Training loss: 1.643588662147522
Validation loss: 1.8871136275670861

Epoch: 6| Step: 5
Training loss: 1.6696157455444336
Validation loss: 1.8664159544052616

Epoch: 6| Step: 6
Training loss: 1.661261796951294
Validation loss: 1.847626047749673

Epoch: 6| Step: 7
Training loss: 2.0721335411071777
Validation loss: 1.8236035749476442

Epoch: 6| Step: 8
Training loss: 1.827160120010376
Validation loss: 1.853175538842396

Epoch: 6| Step: 9
Training loss: 1.5250322818756104
Validation loss: 1.851572577671338

Epoch: 6| Step: 10
Training loss: 2.3116092681884766
Validation loss: 1.8536284597971107

Epoch: 6| Step: 11
Training loss: 2.345147132873535
Validation loss: 1.8989881046356694

Epoch: 6| Step: 12
Training loss: 2.0581846237182617
Validation loss: 1.8517686602889851

Epoch: 6| Step: 13
Training loss: 1.6782987117767334
Validation loss: 1.8216231997295091

Epoch: 168| Step: 0
Training loss: 1.7873095273971558
Validation loss: 1.852936972853958

Epoch: 6| Step: 1
Training loss: 1.3378686904907227
Validation loss: 1.8383344527213805

Epoch: 6| Step: 2
Training loss: 2.2160093784332275
Validation loss: 1.8562825725924583

Epoch: 6| Step: 3
Training loss: 1.6737730503082275
Validation loss: 1.8560740614450106

Epoch: 6| Step: 4
Training loss: 1.9841506481170654
Validation loss: 1.8648758062752344

Epoch: 6| Step: 5
Training loss: 2.034825086593628
Validation loss: 1.8954716523488362

Epoch: 6| Step: 6
Training loss: 2.021864175796509
Validation loss: 1.8497233865081624

Epoch: 6| Step: 7
Training loss: 1.886634111404419
Validation loss: 1.8910563620187903

Epoch: 6| Step: 8
Training loss: 1.7411527633666992
Validation loss: 1.8621272963862265

Epoch: 6| Step: 9
Training loss: 1.6005442142486572
Validation loss: 1.857925699603173

Epoch: 6| Step: 10
Training loss: 2.1317293643951416
Validation loss: 1.8601242521757722

Epoch: 6| Step: 11
Training loss: 2.2364072799682617
Validation loss: 1.8680468913047545

Epoch: 6| Step: 12
Training loss: 2.0866336822509766
Validation loss: 1.8887702700912312

Epoch: 6| Step: 13
Training loss: 1.060866117477417
Validation loss: 1.8182625462931972

Epoch: 169| Step: 0
Training loss: 1.87494695186615
Validation loss: 1.8742242987437914

Epoch: 6| Step: 1
Training loss: 1.788649082183838
Validation loss: 1.882287247206575

Epoch: 6| Step: 2
Training loss: 1.9870188236236572
Validation loss: 1.8725836802554388

Epoch: 6| Step: 3
Training loss: 2.0444302558898926
Validation loss: 1.8603580100561983

Epoch: 6| Step: 4
Training loss: 1.6251474618911743
Validation loss: 1.8590570457520024

Epoch: 6| Step: 5
Training loss: 2.3183329105377197
Validation loss: 1.845709264919322

Epoch: 6| Step: 6
Training loss: 2.1504318714141846
Validation loss: 1.9128665385707733

Epoch: 6| Step: 7
Training loss: 2.2743468284606934
Validation loss: 1.8495837334663636

Epoch: 6| Step: 8
Training loss: 1.8011457920074463
Validation loss: 1.8780090565322547

Epoch: 6| Step: 9
Training loss: 2.082479238510132
Validation loss: 1.8308163740301644

Epoch: 6| Step: 10
Training loss: 1.8573870658874512
Validation loss: 1.893632076119864

Epoch: 6| Step: 11
Training loss: 1.4462273120880127
Validation loss: 1.8647864608354465

Epoch: 6| Step: 12
Training loss: 1.3048958778381348
Validation loss: 1.8370983574980049

Epoch: 6| Step: 13
Training loss: 2.1350491046905518
Validation loss: 1.8466875155766804

Epoch: 170| Step: 0
Training loss: 2.345346450805664
Validation loss: 1.8587690117538616

Epoch: 6| Step: 1
Training loss: 1.6540875434875488
Validation loss: 1.845350497512407

Epoch: 6| Step: 2
Training loss: 1.7896536588668823
Validation loss: 1.8574831895930792

Epoch: 6| Step: 3
Training loss: 1.6076316833496094
Validation loss: 1.8329102557192567

Epoch: 6| Step: 4
Training loss: 1.832721471786499
Validation loss: 1.8191562724369827

Epoch: 6| Step: 5
Training loss: 2.1237664222717285
Validation loss: 1.8243064777825468

Epoch: 6| Step: 6
Training loss: 1.8826608657836914
Validation loss: 1.8574828114560855

Epoch: 6| Step: 7
Training loss: 1.618835210800171
Validation loss: 1.8240164608083747

Epoch: 6| Step: 8
Training loss: 1.9409093856811523
Validation loss: 1.8056595017833095

Epoch: 6| Step: 9
Training loss: 1.5937016010284424
Validation loss: 1.8431768250721756

Epoch: 6| Step: 10
Training loss: 2.565915584564209
Validation loss: 1.8406323514958864

Epoch: 6| Step: 11
Training loss: 2.1516032218933105
Validation loss: 1.8410859402789865

Epoch: 6| Step: 12
Training loss: 1.5295886993408203
Validation loss: 1.8727627364538049

Epoch: 6| Step: 13
Training loss: 2.249148368835449
Validation loss: 1.864324790175243

Epoch: 171| Step: 0
Training loss: 1.985133171081543
Validation loss: 1.8635946255858227

Epoch: 6| Step: 1
Training loss: 1.3150548934936523
Validation loss: 1.8877711501172794

Epoch: 6| Step: 2
Training loss: 1.5949362516403198
Validation loss: 1.837520771129157

Epoch: 6| Step: 3
Training loss: 1.9792238473892212
Validation loss: 1.8591919406767814

Epoch: 6| Step: 4
Training loss: 2.2366082668304443
Validation loss: 1.845295709948386

Epoch: 6| Step: 5
Training loss: 2.028048515319824
Validation loss: 1.858169440300234

Epoch: 6| Step: 6
Training loss: 2.311422348022461
Validation loss: 1.823510649383709

Epoch: 6| Step: 7
Training loss: 2.015516757965088
Validation loss: 1.8355759100247455

Epoch: 6| Step: 8
Training loss: 1.6886200904846191
Validation loss: 1.8667708417420745

Epoch: 6| Step: 9
Training loss: 2.114351272583008
Validation loss: 1.854287894823218

Epoch: 6| Step: 10
Training loss: 1.6015962362289429
Validation loss: 1.8482377657326319

Epoch: 6| Step: 11
Training loss: 2.195307493209839
Validation loss: 1.8797325857224003

Epoch: 6| Step: 12
Training loss: 2.2539501190185547
Validation loss: 1.8486362599557447

Epoch: 6| Step: 13
Training loss: 1.200990080833435
Validation loss: 1.9005723755846742

Epoch: 172| Step: 0
Training loss: 2.1273486614227295
Validation loss: 1.9226724537470008

Epoch: 6| Step: 1
Training loss: 1.9931939840316772
Validation loss: 1.8336321576949088

Epoch: 6| Step: 2
Training loss: 1.7025213241577148
Validation loss: 1.8582480594676027

Epoch: 6| Step: 3
Training loss: 1.1774137020111084
Validation loss: 1.8971522264583136

Epoch: 6| Step: 4
Training loss: 1.3435529470443726
Validation loss: 1.8324409069553498

Epoch: 6| Step: 5
Training loss: 1.778294563293457
Validation loss: 1.9008641358344787

Epoch: 6| Step: 6
Training loss: 2.677341938018799
Validation loss: 1.9014565675489363

Epoch: 6| Step: 7
Training loss: 1.7711535692214966
Validation loss: 1.8934286576445385

Epoch: 6| Step: 8
Training loss: 2.032336950302124
Validation loss: 1.879652718062042

Epoch: 6| Step: 9
Training loss: 2.2183756828308105
Validation loss: 1.868906464627994

Epoch: 6| Step: 10
Training loss: 2.0948665142059326
Validation loss: 1.8866986023482455

Epoch: 6| Step: 11
Training loss: 1.6394965648651123
Validation loss: 1.8439170404147076

Epoch: 6| Step: 12
Training loss: 2.2171483039855957
Validation loss: 1.8621764836772796

Epoch: 6| Step: 13
Training loss: 1.640697956085205
Validation loss: 1.8126776244050713

Epoch: 173| Step: 0
Training loss: 1.7587780952453613
Validation loss: 1.8602307663168958

Epoch: 6| Step: 1
Training loss: 1.5469038486480713
Validation loss: 1.82637273111651

Epoch: 6| Step: 2
Training loss: 2.084282159805298
Validation loss: 1.8165773319941696

Epoch: 6| Step: 3
Training loss: 1.5256510972976685
Validation loss: 1.8796089362072688

Epoch: 6| Step: 4
Training loss: 2.0794355869293213
Validation loss: 1.887565073146615

Epoch: 6| Step: 5
Training loss: 2.0959198474884033
Validation loss: 1.8591843292277346

Epoch: 6| Step: 6
Training loss: 2.6081724166870117
Validation loss: 1.8562507398666874

Epoch: 6| Step: 7
Training loss: 1.1142596006393433
Validation loss: 1.8536986945777811

Epoch: 6| Step: 8
Training loss: 2.21858549118042
Validation loss: 1.8537524489946262

Epoch: 6| Step: 9
Training loss: 2.0453689098358154
Validation loss: 1.88436633540738

Epoch: 6| Step: 10
Training loss: 1.4925386905670166
Validation loss: 1.896515582197456

Epoch: 6| Step: 11
Training loss: 1.9931820631027222
Validation loss: 1.8539613062335598

Epoch: 6| Step: 12
Training loss: 2.085028886795044
Validation loss: 1.8296496034950338

Epoch: 6| Step: 13
Training loss: 2.75364089012146
Validation loss: 1.8447466434970978

Epoch: 174| Step: 0
Training loss: 1.7433085441589355
Validation loss: 1.8344093586808892

Epoch: 6| Step: 1
Training loss: 2.501354694366455
Validation loss: 1.8562614058935514

Epoch: 6| Step: 2
Training loss: 2.0418925285339355
Validation loss: 1.8188527143129738

Epoch: 6| Step: 3
Training loss: 1.022160291671753
Validation loss: 1.840029296054635

Epoch: 6| Step: 4
Training loss: 2.2845635414123535
Validation loss: 1.864355166753133

Epoch: 6| Step: 5
Training loss: 2.507612705230713
Validation loss: 1.9456714763436267

Epoch: 6| Step: 6
Training loss: 1.5946236848831177
Validation loss: 1.8690980326744817

Epoch: 6| Step: 7
Training loss: 1.9700884819030762
Validation loss: 1.9262220244253836

Epoch: 6| Step: 8
Training loss: 1.1727231740951538
Validation loss: 1.8811710880648704

Epoch: 6| Step: 9
Training loss: 2.1048200130462646
Validation loss: 1.8429208186364943

Epoch: 6| Step: 10
Training loss: 1.6837568283081055
Validation loss: 1.8711050466824604

Epoch: 6| Step: 11
Training loss: 1.768237590789795
Validation loss: 1.9037991813434068

Epoch: 6| Step: 12
Training loss: 2.115497589111328
Validation loss: 1.8333230326252599

Epoch: 6| Step: 13
Training loss: 2.0631320476531982
Validation loss: 1.8548652407943562

Epoch: 175| Step: 0
Training loss: 1.8733065128326416
Validation loss: 1.865265001532852

Epoch: 6| Step: 1
Training loss: 1.5428507328033447
Validation loss: 1.8652883216898928

Epoch: 6| Step: 2
Training loss: 2.094822883605957
Validation loss: 1.8396428874743882

Epoch: 6| Step: 3
Training loss: 1.3965638875961304
Validation loss: 1.8460522120998752

Epoch: 6| Step: 4
Training loss: 2.3639917373657227
Validation loss: 1.8402793151076122

Epoch: 6| Step: 5
Training loss: 2.0667996406555176
Validation loss: 1.8467973304051224

Epoch: 6| Step: 6
Training loss: 1.7020307779312134
Validation loss: 1.8341437911474576

Epoch: 6| Step: 7
Training loss: 1.5326449871063232
Validation loss: 1.8443081532755206

Epoch: 6| Step: 8
Training loss: 1.9033938646316528
Validation loss: 1.8311123040414625

Epoch: 6| Step: 9
Training loss: 1.9570374488830566
Validation loss: 1.8539618176798667

Epoch: 6| Step: 10
Training loss: 1.8530199527740479
Validation loss: 1.7890932508694228

Epoch: 6| Step: 11
Training loss: 1.810021162033081
Validation loss: 1.8544228192298644

Epoch: 6| Step: 12
Training loss: 2.098501205444336
Validation loss: 1.781938281110538

Epoch: 6| Step: 13
Training loss: 2.2947957515716553
Validation loss: 1.8413728244843022

Epoch: 176| Step: 0
Training loss: 1.340163230895996
Validation loss: 1.8829711303916028

Epoch: 6| Step: 1
Training loss: 2.2989587783813477
Validation loss: 1.8604484065886466

Epoch: 6| Step: 2
Training loss: 2.373678207397461
Validation loss: 1.8298394885114444

Epoch: 6| Step: 3
Training loss: 2.1528942584991455
Validation loss: 1.85411774727606

Epoch: 6| Step: 4
Training loss: 1.6884503364562988
Validation loss: 1.856943985467316

Epoch: 6| Step: 5
Training loss: 1.503526210784912
Validation loss: 1.8400712769518617

Epoch: 6| Step: 6
Training loss: 1.7226558923721313
Validation loss: 1.842713672627685

Epoch: 6| Step: 7
Training loss: 2.007326364517212
Validation loss: 1.8992405655563518

Epoch: 6| Step: 8
Training loss: 1.954912781715393
Validation loss: 1.8728670471458024

Epoch: 6| Step: 9
Training loss: 1.5676090717315674
Validation loss: 1.845362542777933

Epoch: 6| Step: 10
Training loss: 1.6960115432739258
Validation loss: 1.9370497939407185

Epoch: 6| Step: 11
Training loss: 2.440169095993042
Validation loss: 1.8985132337898336

Epoch: 6| Step: 12
Training loss: 1.5192736387252808
Validation loss: 1.8236255081751014

Epoch: 6| Step: 13
Training loss: 1.6682313680648804
Validation loss: 1.863898649010607

Epoch: 177| Step: 0
Training loss: 1.8250924348831177
Validation loss: 1.88212965637125

Epoch: 6| Step: 1
Training loss: 1.3667631149291992
Validation loss: 1.8389765549731512

Epoch: 6| Step: 2
Training loss: 1.9664390087127686
Validation loss: 1.8238481962552635

Epoch: 6| Step: 3
Training loss: 1.7760019302368164
Validation loss: 1.8655785245280112

Epoch: 6| Step: 4
Training loss: 1.6440438032150269
Validation loss: 1.8947514282759799

Epoch: 6| Step: 5
Training loss: 1.5886638164520264
Validation loss: 1.8667267073867142

Epoch: 6| Step: 6
Training loss: 2.1648900508880615
Validation loss: 1.8079452860739924

Epoch: 6| Step: 7
Training loss: 2.6187963485717773
Validation loss: 1.855393289237894

Epoch: 6| Step: 8
Training loss: 2.050642490386963
Validation loss: 1.8577467382595103

Epoch: 6| Step: 9
Training loss: 2.232670783996582
Validation loss: 1.8239115258698821

Epoch: 6| Step: 10
Training loss: 1.6260101795196533
Validation loss: 1.876741463138211

Epoch: 6| Step: 11
Training loss: 1.6258604526519775
Validation loss: 1.8395867296444472

Epoch: 6| Step: 12
Training loss: 2.4031574726104736
Validation loss: 1.8615483904397616

Epoch: 6| Step: 13
Training loss: 1.083068609237671
Validation loss: 1.860514720280965

Epoch: 178| Step: 0
Training loss: 2.2143754959106445
Validation loss: 1.872645055094073

Epoch: 6| Step: 1
Training loss: 1.5151088237762451
Validation loss: 1.879369225553287

Epoch: 6| Step: 2
Training loss: 1.6581144332885742
Validation loss: 1.8919348562917402

Epoch: 6| Step: 3
Training loss: 1.9411413669586182
Validation loss: 1.8945199738266647

Epoch: 6| Step: 4
Training loss: 2.2284762859344482
Validation loss: 1.8880427101606965

Epoch: 6| Step: 5
Training loss: 1.7845110893249512
Validation loss: 1.8576036883938698

Epoch: 6| Step: 6
Training loss: 2.2871246337890625
Validation loss: 1.868699207100817

Epoch: 6| Step: 7
Training loss: 2.0366196632385254
Validation loss: 1.8645814208574192

Epoch: 6| Step: 8
Training loss: 1.565625548362732
Validation loss: 1.881319353657384

Epoch: 6| Step: 9
Training loss: 1.8421757221221924
Validation loss: 1.8081047176032938

Epoch: 6| Step: 10
Training loss: 1.7716953754425049
Validation loss: 1.8740780533000987

Epoch: 6| Step: 11
Training loss: 2.3393683433532715
Validation loss: 1.861723397367744

Epoch: 6| Step: 12
Training loss: 1.9990707635879517
Validation loss: 1.8834529666490452

Epoch: 6| Step: 13
Training loss: 1.4282195568084717
Validation loss: 1.866443012350349

Epoch: 179| Step: 0
Training loss: 1.7717671394348145
Validation loss: 1.8257480077846076

Epoch: 6| Step: 1
Training loss: 1.5062878131866455
Validation loss: 1.8623054386467062

Epoch: 6| Step: 2
Training loss: 1.8734140396118164
Validation loss: 1.872309015643212

Epoch: 6| Step: 3
Training loss: 2.2742724418640137
Validation loss: 1.88278668157516

Epoch: 6| Step: 4
Training loss: 1.7442151308059692
Validation loss: 1.8106684915481075

Epoch: 6| Step: 5
Training loss: 2.009345054626465
Validation loss: 1.8033155138774584

Epoch: 6| Step: 6
Training loss: 1.6020379066467285
Validation loss: 1.8761236462541806

Epoch: 6| Step: 7
Training loss: 1.4416518211364746
Validation loss: 1.8968671034741145

Epoch: 6| Step: 8
Training loss: 1.8968031406402588
Validation loss: 1.8534384747987152

Epoch: 6| Step: 9
Training loss: 1.8346847295761108
Validation loss: 1.7887585598935363

Epoch: 6| Step: 10
Training loss: 2.1420271396636963
Validation loss: 1.8794229056245537

Epoch: 6| Step: 11
Training loss: 2.156485080718994
Validation loss: 1.8561527946943879

Epoch: 6| Step: 12
Training loss: 2.5814669132232666
Validation loss: 1.8541491852011731

Epoch: 6| Step: 13
Training loss: 0.8507959842681885
Validation loss: 1.8647765113461403

Epoch: 180| Step: 0
Training loss: 1.8481006622314453
Validation loss: 1.8006229772362659

Epoch: 6| Step: 1
Training loss: 1.8744927644729614
Validation loss: 1.8157696621392363

Epoch: 6| Step: 2
Training loss: 2.2407889366149902
Validation loss: 1.8481637829093522

Epoch: 6| Step: 3
Training loss: 1.7943603992462158
Validation loss: 1.8713414233217958

Epoch: 6| Step: 4
Training loss: 1.566002368927002
Validation loss: 1.8877903389674362

Epoch: 6| Step: 5
Training loss: 1.646923303604126
Validation loss: 1.9027454596693798

Epoch: 6| Step: 6
Training loss: 2.4562675952911377
Validation loss: 1.889644617675453

Epoch: 6| Step: 7
Training loss: 2.081627130508423
Validation loss: 1.8390449862326346

Epoch: 6| Step: 8
Training loss: 1.6687331199645996
Validation loss: 1.85250747588373

Epoch: 6| Step: 9
Training loss: 2.042116641998291
Validation loss: 1.8638493591739285

Epoch: 6| Step: 10
Training loss: 2.109180212020874
Validation loss: 1.83828878530892

Epoch: 6| Step: 11
Training loss: 1.444753646850586
Validation loss: 1.8569214523479503

Epoch: 6| Step: 12
Training loss: 1.7782680988311768
Validation loss: 1.853925076864099

Epoch: 6| Step: 13
Training loss: 1.97709059715271
Validation loss: 1.8586331362365394

Epoch: 181| Step: 0
Training loss: 1.9730174541473389
Validation loss: 1.8964425927849227

Epoch: 6| Step: 1
Training loss: 2.696173667907715
Validation loss: 1.8053459185425953

Epoch: 6| Step: 2
Training loss: 1.5615851879119873
Validation loss: 1.8659475541883899

Epoch: 6| Step: 3
Training loss: 1.9420850276947021
Validation loss: 1.8091374007604455

Epoch: 6| Step: 4
Training loss: 1.354474663734436
Validation loss: 1.895285588438793

Epoch: 6| Step: 5
Training loss: 2.03829288482666
Validation loss: 1.8074452210498113

Epoch: 6| Step: 6
Training loss: 1.3433709144592285
Validation loss: 1.8401946047300934

Epoch: 6| Step: 7
Training loss: 2.4243853092193604
Validation loss: 1.8391754524682158

Epoch: 6| Step: 8
Training loss: 2.4754884243011475
Validation loss: 1.8589396784382481

Epoch: 6| Step: 9
Training loss: 1.6245441436767578
Validation loss: 1.8349854946136475

Epoch: 6| Step: 10
Training loss: 1.4611371755599976
Validation loss: 1.8479245772925756

Epoch: 6| Step: 11
Training loss: 2.3415870666503906
Validation loss: 1.8322179714838664

Epoch: 6| Step: 12
Training loss: 1.7139004468917847
Validation loss: 1.8544851092882053

Epoch: 6| Step: 13
Training loss: 1.4852004051208496
Validation loss: 1.8941439095363821

Epoch: 182| Step: 0
Training loss: 2.386260509490967
Validation loss: 1.8881140203886135

Epoch: 6| Step: 1
Training loss: 1.862600326538086
Validation loss: 1.8713962570313485

Epoch: 6| Step: 2
Training loss: 1.882716417312622
Validation loss: 1.8974004727537914

Epoch: 6| Step: 3
Training loss: 1.386519193649292
Validation loss: 1.8465520463963991

Epoch: 6| Step: 4
Training loss: 1.769631028175354
Validation loss: 1.8813280354263962

Epoch: 6| Step: 5
Training loss: 1.909348487854004
Validation loss: 1.8065247843342442

Epoch: 6| Step: 6
Training loss: 1.5300555229187012
Validation loss: 1.8880440522265691

Epoch: 6| Step: 7
Training loss: 1.9370635747909546
Validation loss: 1.8765343068748392

Epoch: 6| Step: 8
Training loss: 1.59384024143219
Validation loss: 1.8657373228380758

Epoch: 6| Step: 9
Training loss: 1.6038073301315308
Validation loss: 1.869146902074096

Epoch: 6| Step: 10
Training loss: 2.1771974563598633
Validation loss: 1.858885980421497

Epoch: 6| Step: 11
Training loss: 1.4248523712158203
Validation loss: 1.8380381894367996

Epoch: 6| Step: 12
Training loss: 2.250497579574585
Validation loss: 1.8615838455897507

Epoch: 6| Step: 13
Training loss: 2.479193925857544
Validation loss: 1.8958150033027894

Epoch: 183| Step: 0
Training loss: 1.9259004592895508
Validation loss: 1.8548223613410868

Epoch: 6| Step: 1
Training loss: 1.81232488155365
Validation loss: 1.8751369855737174

Epoch: 6| Step: 2
Training loss: 1.8556714057922363
Validation loss: 1.8653944769213278

Epoch: 6| Step: 3
Training loss: 2.3859710693359375
Validation loss: 1.845941392324304

Epoch: 6| Step: 4
Training loss: 1.7815345525741577
Validation loss: 1.8197278476530505

Epoch: 6| Step: 5
Training loss: 1.864394187927246
Validation loss: 1.8532741249248545

Epoch: 6| Step: 6
Training loss: 2.143261194229126
Validation loss: 1.818145034133747

Epoch: 6| Step: 7
Training loss: 1.2957823276519775
Validation loss: 1.835200281553371

Epoch: 6| Step: 8
Training loss: 2.0920674800872803
Validation loss: 1.8556333664924867

Epoch: 6| Step: 9
Training loss: 1.2434569597244263
Validation loss: 1.8151526963838966

Epoch: 6| Step: 10
Training loss: 1.7573171854019165
Validation loss: 1.860754056002504

Epoch: 6| Step: 11
Training loss: 1.7300078868865967
Validation loss: 1.8369847638632661

Epoch: 6| Step: 12
Training loss: 2.307645797729492
Validation loss: 1.8014974004478865

Epoch: 6| Step: 13
Training loss: 1.5965027809143066
Validation loss: 1.848543252355309

Epoch: 184| Step: 0
Training loss: 1.5040932893753052
Validation loss: 1.872026498599719

Epoch: 6| Step: 1
Training loss: 1.4280149936676025
Validation loss: 1.8942586683457898

Epoch: 6| Step: 2
Training loss: 1.315944790840149
Validation loss: 1.8397637656939927

Epoch: 6| Step: 3
Training loss: 1.890332579612732
Validation loss: 1.884957262264785

Epoch: 6| Step: 4
Training loss: 1.7849442958831787
Validation loss: 1.8638026342597058

Epoch: 6| Step: 5
Training loss: 1.8184624910354614
Validation loss: 1.907307791453536

Epoch: 6| Step: 6
Training loss: 1.8943710327148438
Validation loss: 1.923571999355029

Epoch: 6| Step: 7
Training loss: 2.1171350479125977
Validation loss: 1.8254148883204306

Epoch: 6| Step: 8
Training loss: 1.942870855331421
Validation loss: 1.8510904901771135

Epoch: 6| Step: 9
Training loss: 2.864203691482544
Validation loss: 1.8846466182380595

Epoch: 6| Step: 10
Training loss: 1.5867221355438232
Validation loss: 1.8586234277294529

Epoch: 6| Step: 11
Training loss: 1.8480225801467896
Validation loss: 1.938748332761949

Epoch: 6| Step: 12
Training loss: 2.2634971141815186
Validation loss: 1.9055232796617734

Epoch: 6| Step: 13
Training loss: 1.3496336936950684
Validation loss: 1.914107165028972

Epoch: 185| Step: 0
Training loss: 1.6440266370773315
Validation loss: 1.8884411614428285

Epoch: 6| Step: 1
Training loss: 2.376492977142334
Validation loss: 1.8721527335464314

Epoch: 6| Step: 2
Training loss: 1.8704166412353516
Validation loss: 1.8778018477142497

Epoch: 6| Step: 3
Training loss: 1.9889167547225952
Validation loss: 1.9002139350419402

Epoch: 6| Step: 4
Training loss: 2.1713008880615234
Validation loss: 1.941530841653065

Epoch: 6| Step: 5
Training loss: 1.9536595344543457
Validation loss: 1.8757952131250852

Epoch: 6| Step: 6
Training loss: 1.7904527187347412
Validation loss: 1.8595085502952657

Epoch: 6| Step: 7
Training loss: 1.3123390674591064
Validation loss: 1.9003957317721458

Epoch: 6| Step: 8
Training loss: 1.6144707202911377
Validation loss: 1.8979254512376682

Epoch: 6| Step: 9
Training loss: 1.568435788154602
Validation loss: 1.9135359205225462

Epoch: 6| Step: 10
Training loss: 2.101062297821045
Validation loss: 1.9211160008625319

Epoch: 6| Step: 11
Training loss: 2.0090858936309814
Validation loss: 1.8982166833775018

Epoch: 6| Step: 12
Training loss: 1.5840471982955933
Validation loss: 1.9312165796115834

Epoch: 6| Step: 13
Training loss: 1.4645254611968994
Validation loss: 1.8504040266877861

Epoch: 186| Step: 0
Training loss: 2.2257585525512695
Validation loss: 1.881541023972214

Epoch: 6| Step: 1
Training loss: 1.8540246486663818
Validation loss: 1.8153331266936434

Epoch: 6| Step: 2
Training loss: 1.2965087890625
Validation loss: 1.877675626867561

Epoch: 6| Step: 3
Training loss: 2.0590100288391113
Validation loss: 1.8830565124429681

Epoch: 6| Step: 4
Training loss: 1.5815331935882568
Validation loss: 1.8581490260298534

Epoch: 6| Step: 5
Training loss: 1.884418249130249
Validation loss: 1.8786271772077006

Epoch: 6| Step: 6
Training loss: 1.738642692565918
Validation loss: 1.8744083476322952

Epoch: 6| Step: 7
Training loss: 2.2111525535583496
Validation loss: 1.8581964738907353

Epoch: 6| Step: 8
Training loss: 2.6376819610595703
Validation loss: 1.850761559701735

Epoch: 6| Step: 9
Training loss: 1.4650084972381592
Validation loss: 1.862574851641091

Epoch: 6| Step: 10
Training loss: 2.3341081142425537
Validation loss: 1.883247644670548

Epoch: 6| Step: 11
Training loss: 1.6645770072937012
Validation loss: 1.8842976606020363

Epoch: 6| Step: 12
Training loss: 1.5006991624832153
Validation loss: 1.829747543540052

Epoch: 6| Step: 13
Training loss: 2.0268757343292236
Validation loss: 1.865572311544931

Epoch: 187| Step: 0
Training loss: 1.747056245803833
Validation loss: 1.893869238515054

Epoch: 6| Step: 1
Training loss: 1.7595080137252808
Validation loss: 1.9050398411289338

Epoch: 6| Step: 2
Training loss: 1.476860761642456
Validation loss: 1.8633098038293983

Epoch: 6| Step: 3
Training loss: 1.9367092847824097
Validation loss: 1.901627863607099

Epoch: 6| Step: 4
Training loss: 1.8841768503189087
Validation loss: 1.8861196848653978

Epoch: 6| Step: 5
Training loss: 2.1923677921295166
Validation loss: 1.8713697438598962

Epoch: 6| Step: 6
Training loss: 2.2500433921813965
Validation loss: 1.8981494429290935

Epoch: 6| Step: 7
Training loss: 1.7694531679153442
Validation loss: 1.8500682051463793

Epoch: 6| Step: 8
Training loss: 1.4701347351074219
Validation loss: 1.8869436863929994

Epoch: 6| Step: 9
Training loss: 2.628572463989258
Validation loss: 1.890600718477721

Epoch: 6| Step: 10
Training loss: 1.6026948690414429
Validation loss: 1.8969413580433014

Epoch: 6| Step: 11
Training loss: 2.3645105361938477
Validation loss: 1.8425463027851556

Epoch: 6| Step: 12
Training loss: 1.3141964673995972
Validation loss: 1.8408268702927457

Epoch: 6| Step: 13
Training loss: 0.7578501105308533
Validation loss: 1.8239302660829277

Epoch: 188| Step: 0
Training loss: 1.8003098964691162
Validation loss: 1.8531808724967382

Epoch: 6| Step: 1
Training loss: 2.1286017894744873
Validation loss: 1.8446391526088919

Epoch: 6| Step: 2
Training loss: 1.204207420349121
Validation loss: 1.8615510476532804

Epoch: 6| Step: 3
Training loss: 1.5995938777923584
Validation loss: 1.8167911678232171

Epoch: 6| Step: 4
Training loss: 1.7597074508666992
Validation loss: 1.8569819042759557

Epoch: 6| Step: 5
Training loss: 2.233325242996216
Validation loss: 1.8594167668332335

Epoch: 6| Step: 6
Training loss: 1.7127680778503418
Validation loss: 1.778124076063915

Epoch: 6| Step: 7
Training loss: 2.64432954788208
Validation loss: 1.8167919753700175

Epoch: 6| Step: 8
Training loss: 1.3014638423919678
Validation loss: 1.8103130402103547

Epoch: 6| Step: 9
Training loss: 1.9169466495513916
Validation loss: 1.842712971471971

Epoch: 6| Step: 10
Training loss: 1.9946894645690918
Validation loss: 1.8341908275440175

Epoch: 6| Step: 11
Training loss: 2.067969560623169
Validation loss: 1.8175063620331466

Epoch: 6| Step: 12
Training loss: 1.6981756687164307
Validation loss: 1.8156129557599303

Epoch: 6| Step: 13
Training loss: 2.3125052452087402
Validation loss: 1.8445139995185278

Epoch: 189| Step: 0
Training loss: 1.8948365449905396
Validation loss: 1.8939433943840764

Epoch: 6| Step: 1
Training loss: 2.565419912338257
Validation loss: 1.8386650098267423

Epoch: 6| Step: 2
Training loss: 1.0839648246765137
Validation loss: 1.8289736573414137

Epoch: 6| Step: 3
Training loss: 1.41934335231781
Validation loss: 1.892314698106499

Epoch: 6| Step: 4
Training loss: 2.027620792388916
Validation loss: 1.833052368574245

Epoch: 6| Step: 5
Training loss: 2.471182346343994
Validation loss: 1.8624933227416007

Epoch: 6| Step: 6
Training loss: 1.8535454273223877
Validation loss: 1.8944346366390106

Epoch: 6| Step: 7
Training loss: 1.5574951171875
Validation loss: 1.918692534969699

Epoch: 6| Step: 8
Training loss: 1.889945149421692
Validation loss: 1.9025828171801824

Epoch: 6| Step: 9
Training loss: 1.2818063497543335
Validation loss: 1.902025084341726

Epoch: 6| Step: 10
Training loss: 1.8107928037643433
Validation loss: 1.868586419731058

Epoch: 6| Step: 11
Training loss: 2.1940712928771973
Validation loss: 1.89403316667003

Epoch: 6| Step: 12
Training loss: 2.12526535987854
Validation loss: 1.8782931655965827

Epoch: 6| Step: 13
Training loss: 1.7571841478347778
Validation loss: 1.8691233460621168

Epoch: 190| Step: 0
Training loss: 2.083643913269043
Validation loss: 1.850798592772535

Epoch: 6| Step: 1
Training loss: 1.5201221704483032
Validation loss: 1.881577270005339

Epoch: 6| Step: 2
Training loss: 1.819239616394043
Validation loss: 1.8194745779037476

Epoch: 6| Step: 3
Training loss: 1.6626088619232178
Validation loss: 1.8431598153165591

Epoch: 6| Step: 4
Training loss: 1.9786038398742676
Validation loss: 1.8738855623429822

Epoch: 6| Step: 5
Training loss: 1.4264304637908936
Validation loss: 1.8494171583524315

Epoch: 6| Step: 6
Training loss: 2.386840343475342
Validation loss: 1.8291095354223763

Epoch: 6| Step: 7
Training loss: 2.172985792160034
Validation loss: 1.8782563914534867

Epoch: 6| Step: 8
Training loss: 1.6623692512512207
Validation loss: 1.8693242893424085

Epoch: 6| Step: 9
Training loss: 1.8397637605667114
Validation loss: 1.863074501355489

Epoch: 6| Step: 10
Training loss: 1.5605312585830688
Validation loss: 1.8708465804335892

Epoch: 6| Step: 11
Training loss: 1.8815085887908936
Validation loss: 1.8513131910754788

Epoch: 6| Step: 12
Training loss: 2.0955488681793213
Validation loss: 1.8930261314556163

Epoch: 6| Step: 13
Training loss: 1.3882662057876587
Validation loss: 1.880662702745007

Epoch: 191| Step: 0
Training loss: 1.3889269828796387
Validation loss: 1.826124680939541

Epoch: 6| Step: 1
Training loss: 1.9710214138031006
Validation loss: 1.8454418131100234

Epoch: 6| Step: 2
Training loss: 2.4094557762145996
Validation loss: 1.865934043802241

Epoch: 6| Step: 3
Training loss: 1.7666525840759277
Validation loss: 1.8731115761623587

Epoch: 6| Step: 4
Training loss: 1.6803592443466187
Validation loss: 1.8967820854597195

Epoch: 6| Step: 5
Training loss: 1.3130741119384766
Validation loss: 1.8925057200975315

Epoch: 6| Step: 6
Training loss: 1.4453153610229492
Validation loss: 1.8811527093251545

Epoch: 6| Step: 7
Training loss: 1.8617470264434814
Validation loss: 1.8741735309682868

Epoch: 6| Step: 8
Training loss: 2.0898728370666504
Validation loss: 1.9001318639324558

Epoch: 6| Step: 9
Training loss: 2.070746898651123
Validation loss: 1.9432376584699076

Epoch: 6| Step: 10
Training loss: 1.685558557510376
Validation loss: 1.8479177426266413

Epoch: 6| Step: 11
Training loss: 2.2990424633026123
Validation loss: 1.8707160770252187

Epoch: 6| Step: 12
Training loss: 1.9908249378204346
Validation loss: 1.914728303109446

Epoch: 6| Step: 13
Training loss: 1.789732575416565
Validation loss: 1.8456366959438528

Epoch: 192| Step: 0
Training loss: 1.7642394304275513
Validation loss: 1.8837969431313135

Epoch: 6| Step: 1
Training loss: 1.4167366027832031
Validation loss: 1.8475319595747097

Epoch: 6| Step: 2
Training loss: 1.6452741622924805
Validation loss: 1.8628512172288791

Epoch: 6| Step: 3
Training loss: 1.6670029163360596
Validation loss: 1.8491737483650126

Epoch: 6| Step: 4
Training loss: 2.4173245429992676
Validation loss: 1.8567285883811213

Epoch: 6| Step: 5
Training loss: 1.6140787601470947
Validation loss: 1.880119526258079

Epoch: 6| Step: 6
Training loss: 1.84674072265625
Validation loss: 1.8595367118876467

Epoch: 6| Step: 7
Training loss: 2.0992038249969482
Validation loss: 1.8133708238601685

Epoch: 6| Step: 8
Training loss: 1.7607656717300415
Validation loss: 1.8246119855552592

Epoch: 6| Step: 9
Training loss: 1.8110169172286987
Validation loss: 1.8693811983190558

Epoch: 6| Step: 10
Training loss: 1.9981484413146973
Validation loss: 1.85778425329475

Epoch: 6| Step: 11
Training loss: 2.552356004714966
Validation loss: 1.8838610162017166

Epoch: 6| Step: 12
Training loss: 1.6551589965820312
Validation loss: 1.8256033441071868

Epoch: 6| Step: 13
Training loss: 0.8191573619842529
Validation loss: 1.8400553426434916

Epoch: 193| Step: 0
Training loss: 1.9475915431976318
Validation loss: 1.866114095974994

Epoch: 6| Step: 1
Training loss: 2.348568916320801
Validation loss: 1.8342249316553916

Epoch: 6| Step: 2
Training loss: 1.7187776565551758
Validation loss: 1.8457998921794276

Epoch: 6| Step: 3
Training loss: 1.8656463623046875
Validation loss: 1.8605561025681034

Epoch: 6| Step: 4
Training loss: 1.6637074947357178
Validation loss: 1.8825449712814823

Epoch: 6| Step: 5
Training loss: 2.0015883445739746
Validation loss: 1.8254372971032256

Epoch: 6| Step: 6
Training loss: 1.7120596170425415
Validation loss: 1.8692916734244234

Epoch: 6| Step: 7
Training loss: 2.6160378456115723
Validation loss: 1.907639839315927

Epoch: 6| Step: 8
Training loss: 1.2351899147033691
Validation loss: 1.8674501757467947

Epoch: 6| Step: 9
Training loss: 2.1067025661468506
Validation loss: 1.8886746591137302

Epoch: 6| Step: 10
Training loss: 1.2159918546676636
Validation loss: 1.8272856973832654

Epoch: 6| Step: 11
Training loss: 1.7902088165283203
Validation loss: 1.8298038513429704

Epoch: 6| Step: 12
Training loss: 2.072047710418701
Validation loss: 1.8803580217463995

Epoch: 6| Step: 13
Training loss: 0.8860174417495728
Validation loss: 1.8531803008048766

Epoch: 194| Step: 0
Training loss: 1.6465424299240112
Validation loss: 1.8287603598768993

Epoch: 6| Step: 1
Training loss: 1.826964020729065
Validation loss: 1.92232177078083

Epoch: 6| Step: 2
Training loss: 2.261153221130371
Validation loss: 1.848166964387381

Epoch: 6| Step: 3
Training loss: 2.2532660961151123
Validation loss: 1.8476537337867163

Epoch: 6| Step: 4
Training loss: 2.529900312423706
Validation loss: 1.8281458103528587

Epoch: 6| Step: 5
Training loss: 1.5126254558563232
Validation loss: 1.8569675542974984

Epoch: 6| Step: 6
Training loss: 1.5980982780456543
Validation loss: 1.8749978811510148

Epoch: 6| Step: 7
Training loss: 1.7354291677474976
Validation loss: 1.9078542186367897

Epoch: 6| Step: 8
Training loss: 1.4849783182144165
Validation loss: 1.9109694316822996

Epoch: 6| Step: 9
Training loss: 1.670945167541504
Validation loss: 1.8905093708345968

Epoch: 6| Step: 10
Training loss: 2.148874282836914
Validation loss: 1.845561924801078

Epoch: 6| Step: 11
Training loss: 1.6185302734375
Validation loss: 1.878865534259427

Epoch: 6| Step: 12
Training loss: 1.3762457370758057
Validation loss: 1.892058664752591

Epoch: 6| Step: 13
Training loss: 1.7471964359283447
Validation loss: 1.9152231767613401

Epoch: 195| Step: 0
Training loss: 2.2178335189819336
Validation loss: 1.8889525577586184

Epoch: 6| Step: 1
Training loss: 1.5568556785583496
Validation loss: 1.8921972936199558

Epoch: 6| Step: 2
Training loss: 1.4299993515014648
Validation loss: 1.89981476465861

Epoch: 6| Step: 3
Training loss: 2.1304988861083984
Validation loss: 1.836935140753305

Epoch: 6| Step: 4
Training loss: 2.3332347869873047
Validation loss: 1.8535698049811906

Epoch: 6| Step: 5
Training loss: 1.4736651182174683
Validation loss: 1.8435322815372097

Epoch: 6| Step: 6
Training loss: 2.1310012340545654
Validation loss: 1.8584308624267578

Epoch: 6| Step: 7
Training loss: 1.6464815139770508
Validation loss: 1.855309236434198

Epoch: 6| Step: 8
Training loss: 1.6577658653259277
Validation loss: 1.8979883475970196

Epoch: 6| Step: 9
Training loss: 1.8956172466278076
Validation loss: 1.8569773320228822

Epoch: 6| Step: 10
Training loss: 1.4159941673278809
Validation loss: 1.8986483748241136

Epoch: 6| Step: 11
Training loss: 2.0363783836364746
Validation loss: 1.93751690336453

Epoch: 6| Step: 12
Training loss: 1.722848653793335
Validation loss: 1.8529039275261663

Epoch: 6| Step: 13
Training loss: 1.8679184913635254
Validation loss: 1.830946409574119

Epoch: 196| Step: 0
Training loss: 2.188997983932495
Validation loss: 1.8581908428540794

Epoch: 6| Step: 1
Training loss: 0.7709915637969971
Validation loss: 1.8521313013569

Epoch: 6| Step: 2
Training loss: 1.6333893537521362
Validation loss: 1.8628881592904367

Epoch: 6| Step: 3
Training loss: 1.644540786743164
Validation loss: 1.842862408648255

Epoch: 6| Step: 4
Training loss: 2.497858762741089
Validation loss: 1.838755617859543

Epoch: 6| Step: 5
Training loss: 1.8996766805648804
Validation loss: 1.8583151127702446

Epoch: 6| Step: 6
Training loss: 2.1367266178131104
Validation loss: 1.8976422407293831

Epoch: 6| Step: 7
Training loss: 1.939307451248169
Validation loss: 1.8150410818797287

Epoch: 6| Step: 8
Training loss: 1.1648218631744385
Validation loss: 1.8677966030695106

Epoch: 6| Step: 9
Training loss: 1.611987590789795
Validation loss: 1.8604444637093493

Epoch: 6| Step: 10
Training loss: 2.077195644378662
Validation loss: 1.8857139220801733

Epoch: 6| Step: 11
Training loss: 1.9185080528259277
Validation loss: 1.8650007094106367

Epoch: 6| Step: 12
Training loss: 2.189462184906006
Validation loss: 1.8921068868329447

Epoch: 6| Step: 13
Training loss: 1.6218019723892212
Validation loss: 1.8436869062403196

Epoch: 197| Step: 0
Training loss: 1.6823959350585938
Validation loss: 1.8702941479221467

Epoch: 6| Step: 1
Training loss: 1.538804054260254
Validation loss: 1.8395442167917888

Epoch: 6| Step: 2
Training loss: 1.5986309051513672
Validation loss: 1.8614410687518377

Epoch: 6| Step: 3
Training loss: 2.6478641033172607
Validation loss: 1.8520253114802863

Epoch: 6| Step: 4
Training loss: 1.6806079149246216
Validation loss: 1.864614978913338

Epoch: 6| Step: 5
Training loss: 2.4161643981933594
Validation loss: 1.8057557652073521

Epoch: 6| Step: 6
Training loss: 1.607010841369629
Validation loss: 1.875114038426389

Epoch: 6| Step: 7
Training loss: 2.1632299423217773
Validation loss: 1.821884847456409

Epoch: 6| Step: 8
Training loss: 1.6523386240005493
Validation loss: 1.8286500489839943

Epoch: 6| Step: 9
Training loss: 2.3676419258117676
Validation loss: 1.818329507304776

Epoch: 6| Step: 10
Training loss: 1.6719251871109009
Validation loss: 1.837857259217129

Epoch: 6| Step: 11
Training loss: 1.3568966388702393
Validation loss: 1.8441354933605398

Epoch: 6| Step: 12
Training loss: 1.6064366102218628
Validation loss: 1.8243720082826511

Epoch: 6| Step: 13
Training loss: 1.5707957744598389
Validation loss: 1.8534844639480754

Epoch: 198| Step: 0
Training loss: 1.9391767978668213
Validation loss: 1.8474322044721214

Epoch: 6| Step: 1
Training loss: 1.5314594507217407
Validation loss: 1.8187651813671153

Epoch: 6| Step: 2
Training loss: 1.388244867324829
Validation loss: 1.8773327001961329

Epoch: 6| Step: 3
Training loss: 1.7562540769577026
Validation loss: 1.8579950383914414

Epoch: 6| Step: 4
Training loss: 1.7097959518432617
Validation loss: 1.838214833249328

Epoch: 6| Step: 5
Training loss: 1.8818100690841675
Validation loss: 1.8516457439750753

Epoch: 6| Step: 6
Training loss: 1.8414335250854492
Validation loss: 1.8699337000487952

Epoch: 6| Step: 7
Training loss: 1.772575855255127
Validation loss: 1.8661206255676925

Epoch: 6| Step: 8
Training loss: 2.5238122940063477
Validation loss: 1.8654135555349372

Epoch: 6| Step: 9
Training loss: 1.7437783479690552
Validation loss: 1.9093903469783005

Epoch: 6| Step: 10
Training loss: 2.014566659927368
Validation loss: 1.8711059631839875

Epoch: 6| Step: 11
Training loss: 2.0373659133911133
Validation loss: 1.8930505667963335

Epoch: 6| Step: 12
Training loss: 1.2675613164901733
Validation loss: 1.8504210159342775

Epoch: 6| Step: 13
Training loss: 2.4163150787353516
Validation loss: 1.8728510397736744

Epoch: 199| Step: 0
Training loss: 1.5769871473312378
Validation loss: 1.877636883848457

Epoch: 6| Step: 1
Training loss: 1.5224552154541016
Validation loss: 1.864176704037574

Epoch: 6| Step: 2
Training loss: 2.025019407272339
Validation loss: 1.8661505201811432

Epoch: 6| Step: 3
Training loss: 2.054030656814575
Validation loss: 1.8517198818986134

Epoch: 6| Step: 4
Training loss: 1.325727939605713
Validation loss: 1.8799214132370488

Epoch: 6| Step: 5
Training loss: 2.001957893371582
Validation loss: 1.8844498447192612

Epoch: 6| Step: 6
Training loss: 2.040374517440796
Validation loss: 1.840220453918621

Epoch: 6| Step: 7
Training loss: 1.702502965927124
Validation loss: 1.8295809786806825

Epoch: 6| Step: 8
Training loss: 1.5243477821350098
Validation loss: 1.8413855785964637

Epoch: 6| Step: 9
Training loss: 2.047471284866333
Validation loss: 1.883979448708155

Epoch: 6| Step: 10
Training loss: 1.632885217666626
Validation loss: 1.796104396543195

Epoch: 6| Step: 11
Training loss: 1.8374508619308472
Validation loss: 1.8749639603399462

Epoch: 6| Step: 12
Training loss: 2.3117835521698
Validation loss: 1.848892763096799

Epoch: 6| Step: 13
Training loss: 2.0325682163238525
Validation loss: 1.8676906913839362

Epoch: 200| Step: 0
Training loss: 2.047760009765625
Validation loss: 1.9028772743799354

Epoch: 6| Step: 1
Training loss: 1.980947732925415
Validation loss: 1.8050029034255652

Epoch: 6| Step: 2
Training loss: 2.7144482135772705
Validation loss: 1.8270546249164048

Epoch: 6| Step: 3
Training loss: 1.6386704444885254
Validation loss: 1.8730627913628854

Epoch: 6| Step: 4
Training loss: 1.746789813041687
Validation loss: 1.8821563464339062

Epoch: 6| Step: 5
Training loss: 2.2486963272094727
Validation loss: 1.8811528041798582

Epoch: 6| Step: 6
Training loss: 1.273790955543518
Validation loss: 1.8730826672687326

Epoch: 6| Step: 7
Training loss: 1.280358076095581
Validation loss: 1.8412606793065225

Epoch: 6| Step: 8
Training loss: 1.6826565265655518
Validation loss: 1.814525076138076

Epoch: 6| Step: 9
Training loss: 1.5742411613464355
Validation loss: 1.8276480961871404

Epoch: 6| Step: 10
Training loss: 2.108340263366699
Validation loss: 1.809839798558143

Epoch: 6| Step: 11
Training loss: 1.3438037633895874
Validation loss: 1.8193101203569801

Epoch: 6| Step: 12
Training loss: 1.5282660722732544
Validation loss: 1.845835611384402

Epoch: 6| Step: 13
Training loss: 2.1302902698516846
Validation loss: 1.840336093338587

Epoch: 201| Step: 0
Training loss: 2.0575718879699707
Validation loss: 1.8680254592690417

Epoch: 6| Step: 1
Training loss: 1.8047738075256348
Validation loss: 1.8574866325624528

Epoch: 6| Step: 2
Training loss: 1.827062964439392
Validation loss: 1.8608622320236698

Epoch: 6| Step: 3
Training loss: 2.264021873474121
Validation loss: 1.8662343614844865

Epoch: 6| Step: 4
Training loss: 1.9470267295837402
Validation loss: 1.8730522509544127

Epoch: 6| Step: 5
Training loss: 1.3533682823181152
Validation loss: 1.843644126769035

Epoch: 6| Step: 6
Training loss: 2.0380074977874756
Validation loss: 1.8548125477247341

Epoch: 6| Step: 7
Training loss: 1.3544013500213623
Validation loss: 1.8341224065390966

Epoch: 6| Step: 8
Training loss: 1.5713825225830078
Validation loss: 1.8645698729381766

Epoch: 6| Step: 9
Training loss: 1.8314568996429443
Validation loss: 1.9061448702248194

Epoch: 6| Step: 10
Training loss: 1.6892802715301514
Validation loss: 1.8954186311332129

Epoch: 6| Step: 11
Training loss: 1.5683164596557617
Validation loss: 1.8671020205302904

Epoch: 6| Step: 12
Training loss: 2.523932456970215
Validation loss: 1.9167639414469402

Epoch: 6| Step: 13
Training loss: 1.4466767311096191
Validation loss: 1.8150753898005332

Epoch: 202| Step: 0
Training loss: 1.3042367696762085
Validation loss: 1.8945037921269734

Epoch: 6| Step: 1
Training loss: 1.818746566772461
Validation loss: 1.8768870830535889

Epoch: 6| Step: 2
Training loss: 2.096381187438965
Validation loss: 1.8862116477822746

Epoch: 6| Step: 3
Training loss: 1.8634355068206787
Validation loss: 1.8838438064821306

Epoch: 6| Step: 4
Training loss: 1.8634552955627441
Validation loss: 1.8760613318412536

Epoch: 6| Step: 5
Training loss: 1.248522162437439
Validation loss: 1.8744576797690442

Epoch: 6| Step: 6
Training loss: 2.3579015731811523
Validation loss: 1.8794138969913605

Epoch: 6| Step: 7
Training loss: 1.729285478591919
Validation loss: 1.850194497775006

Epoch: 6| Step: 8
Training loss: 1.9394547939300537
Validation loss: 1.8653947512308757

Epoch: 6| Step: 9
Training loss: 1.8584014177322388
Validation loss: 1.8510841490120016

Epoch: 6| Step: 10
Training loss: 2.504570960998535
Validation loss: 1.9376454148241269

Epoch: 6| Step: 11
Training loss: 1.521365761756897
Validation loss: 1.8444847060788063

Epoch: 6| Step: 12
Training loss: 1.5688247680664062
Validation loss: 1.8246189714759908

Epoch: 6| Step: 13
Training loss: 1.495397686958313
Validation loss: 1.8287730550253263

Epoch: 203| Step: 0
Training loss: 1.6413040161132812
Validation loss: 1.8958220866418654

Epoch: 6| Step: 1
Training loss: 1.4737272262573242
Validation loss: 1.8532624847145491

Epoch: 6| Step: 2
Training loss: 1.7812433242797852
Validation loss: 1.831296395230037

Epoch: 6| Step: 3
Training loss: 2.069437026977539
Validation loss: 1.8787514804511942

Epoch: 6| Step: 4
Training loss: 1.9310359954833984
Validation loss: 1.892955764647453

Epoch: 6| Step: 5
Training loss: 2.101181983947754
Validation loss: 1.8841522303960656

Epoch: 6| Step: 6
Training loss: 1.675962209701538
Validation loss: 1.830189371621737

Epoch: 6| Step: 7
Training loss: 1.3171727657318115
Validation loss: 1.8795243194026332

Epoch: 6| Step: 8
Training loss: 1.8269133567810059
Validation loss: 1.8952845296552103

Epoch: 6| Step: 9
Training loss: 1.7815053462982178
Validation loss: 1.9088305299000075

Epoch: 6| Step: 10
Training loss: 2.0566086769104004
Validation loss: 1.9047180273199593

Epoch: 6| Step: 11
Training loss: 1.3781509399414062
Validation loss: 1.8803794204547841

Epoch: 6| Step: 12
Training loss: 2.2879116535186768
Validation loss: 1.9112995106686828

Epoch: 6| Step: 13
Training loss: 2.280186653137207
Validation loss: 1.9130437463842414

Epoch: 204| Step: 0
Training loss: 0.9871568083763123
Validation loss: 1.8882902360731555

Epoch: 6| Step: 1
Training loss: 1.8531174659729004
Validation loss: 1.8824465479902042

Epoch: 6| Step: 2
Training loss: 2.0430521965026855
Validation loss: 1.9184177306390577

Epoch: 6| Step: 3
Training loss: 2.320490598678589
Validation loss: 1.9286795777659262

Epoch: 6| Step: 4
Training loss: 1.9571160078048706
Validation loss: 1.8541540151001306

Epoch: 6| Step: 5
Training loss: 2.01277756690979
Validation loss: 1.8624704089216007

Epoch: 6| Step: 6
Training loss: 2.3568508625030518
Validation loss: 1.8865837115113453

Epoch: 6| Step: 7
Training loss: 2.300215482711792
Validation loss: 1.8892145477315432

Epoch: 6| Step: 8
Training loss: 2.148686408996582
Validation loss: 1.875234483390726

Epoch: 6| Step: 9
Training loss: 0.9832762479782104
Validation loss: 1.887601496070944

Epoch: 6| Step: 10
Training loss: 1.584133267402649
Validation loss: 1.8656269542632564

Epoch: 6| Step: 11
Training loss: 1.002975344657898
Validation loss: 1.8377040278527044

Epoch: 6| Step: 12
Training loss: 1.94265615940094
Validation loss: 1.8187292032344367

Epoch: 6| Step: 13
Training loss: 1.8660125732421875
Validation loss: 1.8834348058187833

Epoch: 205| Step: 0
Training loss: 1.3131413459777832
Validation loss: 1.8578721387411958

Epoch: 6| Step: 1
Training loss: 1.2023470401763916
Validation loss: 1.857034029499177

Epoch: 6| Step: 2
Training loss: 1.5412447452545166
Validation loss: 1.9144572263122888

Epoch: 6| Step: 3
Training loss: 1.9638562202453613
Validation loss: 1.8539302784909484

Epoch: 6| Step: 4
Training loss: 1.8271632194519043
Validation loss: 1.8475606813225696

Epoch: 6| Step: 5
Training loss: 2.003584146499634
Validation loss: 1.8544636926343363

Epoch: 6| Step: 6
Training loss: 2.038027763366699
Validation loss: 1.8166678438904464

Epoch: 6| Step: 7
Training loss: 2.593191623687744
Validation loss: 1.8418236624810003

Epoch: 6| Step: 8
Training loss: 1.9551674127578735
Validation loss: 1.8572900782349289

Epoch: 6| Step: 9
Training loss: 1.5548794269561768
Validation loss: 1.854881840367471

Epoch: 6| Step: 10
Training loss: 1.433032512664795
Validation loss: 1.9079644154476862

Epoch: 6| Step: 11
Training loss: 2.1739678382873535
Validation loss: 1.8773364610569452

Epoch: 6| Step: 12
Training loss: 1.7481422424316406
Validation loss: 1.8813247885755313

Epoch: 6| Step: 13
Training loss: 2.3030192852020264
Validation loss: 1.9054813461918985

Epoch: 206| Step: 0
Training loss: 2.231877326965332
Validation loss: 1.8932236548393004

Epoch: 6| Step: 1
Training loss: 2.111651659011841
Validation loss: 1.930925089825866

Epoch: 6| Step: 2
Training loss: 1.742084264755249
Validation loss: 1.871460392910947

Epoch: 6| Step: 3
Training loss: 1.4363595247268677
Validation loss: 1.889609488107825

Epoch: 6| Step: 4
Training loss: 1.8650612831115723
Validation loss: 1.898463733734623

Epoch: 6| Step: 5
Training loss: 2.1780033111572266
Validation loss: 1.8896486054184616

Epoch: 6| Step: 6
Training loss: 1.7256619930267334
Validation loss: 1.826760781708584

Epoch: 6| Step: 7
Training loss: 1.6620185375213623
Validation loss: 1.8923822872100338

Epoch: 6| Step: 8
Training loss: 1.3593238592147827
Validation loss: 1.8949915375760806

Epoch: 6| Step: 9
Training loss: 1.6883357763290405
Validation loss: 1.913614934490573

Epoch: 6| Step: 10
Training loss: 1.6630648374557495
Validation loss: 1.9068290469467

Epoch: 6| Step: 11
Training loss: 1.7296042442321777
Validation loss: 1.8942716736947336

Epoch: 6| Step: 12
Training loss: 2.068615436553955
Validation loss: 1.8710649500611007

Epoch: 6| Step: 13
Training loss: 1.9763281345367432
Validation loss: 1.8769211615285566

Epoch: 207| Step: 0
Training loss: 2.1387131214141846
Validation loss: 1.8261486368794595

Epoch: 6| Step: 1
Training loss: 1.2464640140533447
Validation loss: 1.8123869549843572

Epoch: 6| Step: 2
Training loss: 2.0296783447265625
Validation loss: 1.8389175912385345

Epoch: 6| Step: 3
Training loss: 0.940011739730835
Validation loss: 1.8425133625666301

Epoch: 6| Step: 4
Training loss: 1.9148513078689575
Validation loss: 1.8625604362897976

Epoch: 6| Step: 5
Training loss: 1.8620065450668335
Validation loss: 1.8383403926767328

Epoch: 6| Step: 6
Training loss: 2.099677324295044
Validation loss: 1.8774875351177749

Epoch: 6| Step: 7
Training loss: 2.0431041717529297
Validation loss: 1.8411794580439085

Epoch: 6| Step: 8
Training loss: 1.8308448791503906
Validation loss: 1.8921479358468005

Epoch: 6| Step: 9
Training loss: 1.798910140991211
Validation loss: 1.8302329022397277

Epoch: 6| Step: 10
Training loss: 1.510324478149414
Validation loss: 1.8636678918715446

Epoch: 6| Step: 11
Training loss: 1.7284672260284424
Validation loss: 1.84692528042742

Epoch: 6| Step: 12
Training loss: 2.0648257732391357
Validation loss: 1.8707323176886446

Epoch: 6| Step: 13
Training loss: 2.302096366882324
Validation loss: 1.902110658666139

Epoch: 208| Step: 0
Training loss: 2.028329849243164
Validation loss: 1.882567641555622

Epoch: 6| Step: 1
Training loss: 2.0933361053466797
Validation loss: 1.8977188346206502

Epoch: 6| Step: 2
Training loss: 1.3406975269317627
Validation loss: 1.8960414881347327

Epoch: 6| Step: 3
Training loss: 1.612436294555664
Validation loss: 1.889999948522096

Epoch: 6| Step: 4
Training loss: 1.8704729080200195
Validation loss: 1.905864482284874

Epoch: 6| Step: 5
Training loss: 2.1301956176757812
Validation loss: 1.895292180840687

Epoch: 6| Step: 6
Training loss: 2.342994213104248
Validation loss: 1.8710006859994703

Epoch: 6| Step: 7
Training loss: 1.6759004592895508
Validation loss: 1.9167452537885277

Epoch: 6| Step: 8
Training loss: 1.5941376686096191
Validation loss: 1.932082929918843

Epoch: 6| Step: 9
Training loss: 1.7713321447372437
Validation loss: 1.9366514426405712

Epoch: 6| Step: 10
Training loss: 1.5086171627044678
Validation loss: 1.9654193347500217

Epoch: 6| Step: 11
Training loss: 1.6290884017944336
Validation loss: 1.955999897372338

Epoch: 6| Step: 12
Training loss: 1.5591225624084473
Validation loss: 1.8666208790194603

Epoch: 6| Step: 13
Training loss: 2.56282639503479
Validation loss: 1.9055085182189941

Epoch: 209| Step: 0
Training loss: 1.4541962146759033
Validation loss: 1.8423233929500784

Epoch: 6| Step: 1
Training loss: 2.127035140991211
Validation loss: 1.8718622897260933

Epoch: 6| Step: 2
Training loss: 1.8856905698776245
Validation loss: 1.8810097825142644

Epoch: 6| Step: 3
Training loss: 1.680767297744751
Validation loss: 1.8211189457165298

Epoch: 6| Step: 4
Training loss: 1.8668617010116577
Validation loss: 1.8614242153782998

Epoch: 6| Step: 5
Training loss: 1.488083839416504
Validation loss: 1.8560768596587642

Epoch: 6| Step: 6
Training loss: 1.9733493328094482
Validation loss: 1.7912999994011336

Epoch: 6| Step: 7
Training loss: 2.7207908630371094
Validation loss: 1.8564864550867388

Epoch: 6| Step: 8
Training loss: 1.6028354167938232
Validation loss: 1.8107251364697692

Epoch: 6| Step: 9
Training loss: 1.4008768796920776
Validation loss: 1.839527391618298

Epoch: 6| Step: 10
Training loss: 1.9161295890808105
Validation loss: 1.8245591668672458

Epoch: 6| Step: 11
Training loss: 1.9481534957885742
Validation loss: 1.8981715530477545

Epoch: 6| Step: 12
Training loss: 1.6599366664886475
Validation loss: 1.8781768634755125

Epoch: 6| Step: 13
Training loss: 2.0128862857818604
Validation loss: 1.8766578448716031

Epoch: 210| Step: 0
Training loss: 1.7351737022399902
Validation loss: 1.8860635449809413

Epoch: 6| Step: 1
Training loss: 2.006547451019287
Validation loss: 1.8441972783816758

Epoch: 6| Step: 2
Training loss: 1.7111461162567139
Validation loss: 1.8512660764878797

Epoch: 6| Step: 3
Training loss: 1.7627604007720947
Validation loss: 1.8738581647155106

Epoch: 6| Step: 4
Training loss: 2.5467426776885986
Validation loss: 1.8716859150958318

Epoch: 6| Step: 5
Training loss: 1.6674679517745972
Validation loss: 1.8965143772863573

Epoch: 6| Step: 6
Training loss: 1.9111627340316772
Validation loss: 1.8825242903924757

Epoch: 6| Step: 7
Training loss: 1.7831709384918213
Validation loss: 1.9185578207815848

Epoch: 6| Step: 8
Training loss: 1.6999576091766357
Validation loss: 1.877180302014915

Epoch: 6| Step: 9
Training loss: 1.3943445682525635
Validation loss: 1.874297680393342

Epoch: 6| Step: 10
Training loss: 1.414188027381897
Validation loss: 1.8759646800256544

Epoch: 6| Step: 11
Training loss: 1.4619216918945312
Validation loss: 1.893865866045798

Epoch: 6| Step: 12
Training loss: 2.01979660987854
Validation loss: 1.9100556142868534

Epoch: 6| Step: 13
Training loss: 1.4743475914001465
Validation loss: 1.882742194719212

Epoch: 211| Step: 0
Training loss: 1.938982605934143
Validation loss: 1.8757866941472536

Epoch: 6| Step: 1
Training loss: 2.1357688903808594
Validation loss: 1.902123201277948

Epoch: 6| Step: 2
Training loss: 1.8808033466339111
Validation loss: 1.8454708963312128

Epoch: 6| Step: 3
Training loss: 1.9267151355743408
Validation loss: 1.8879509395168674

Epoch: 6| Step: 4
Training loss: 1.229398250579834
Validation loss: 1.8626687667703117

Epoch: 6| Step: 5
Training loss: 1.8627564907073975
Validation loss: 1.911639000779839

Epoch: 6| Step: 6
Training loss: 1.5444765090942383
Validation loss: 1.8848588671735538

Epoch: 6| Step: 7
Training loss: 1.358320713043213
Validation loss: 1.86366533207637

Epoch: 6| Step: 8
Training loss: 1.3698476552963257
Validation loss: 1.877113014139155

Epoch: 6| Step: 9
Training loss: 1.5517417192459106
Validation loss: 1.9237738527277464

Epoch: 6| Step: 10
Training loss: 2.192911148071289
Validation loss: 1.9151399212498819

Epoch: 6| Step: 11
Training loss: 1.6316003799438477
Validation loss: 1.9326688769043132

Epoch: 6| Step: 12
Training loss: 1.9620418548583984
Validation loss: 1.891930668584762

Epoch: 6| Step: 13
Training loss: 2.514526844024658
Validation loss: 1.8407988368823964

Epoch: 212| Step: 0
Training loss: 1.702986717224121
Validation loss: 1.8089526930162985

Epoch: 6| Step: 1
Training loss: 1.7884961366653442
Validation loss: 1.8311526365177606

Epoch: 6| Step: 2
Training loss: 1.8613791465759277
Validation loss: 1.8573076494278447

Epoch: 6| Step: 3
Training loss: 1.8415160179138184
Validation loss: 1.8211018154698033

Epoch: 6| Step: 4
Training loss: 1.979722261428833
Validation loss: 1.8612028488548853

Epoch: 6| Step: 5
Training loss: 1.85812246799469
Validation loss: 1.8215121633263045

Epoch: 6| Step: 6
Training loss: 2.259889602661133
Validation loss: 1.8594977496772684

Epoch: 6| Step: 7
Training loss: 1.1011769771575928
Validation loss: 1.8672218527845157

Epoch: 6| Step: 8
Training loss: 2.0722508430480957
Validation loss: 1.885954341580791

Epoch: 6| Step: 9
Training loss: 1.4203007221221924
Validation loss: 1.9165039523955314

Epoch: 6| Step: 10
Training loss: 1.3718006610870361
Validation loss: 1.8006483982968073

Epoch: 6| Step: 11
Training loss: 1.7326343059539795
Validation loss: 1.87283787163355

Epoch: 6| Step: 12
Training loss: 2.0998029708862305
Validation loss: 1.8932197542600735

Epoch: 6| Step: 13
Training loss: 2.1128931045532227
Validation loss: 1.8701229544096096

Epoch: 213| Step: 0
Training loss: 1.567566156387329
Validation loss: 1.877363867657159

Epoch: 6| Step: 1
Training loss: 1.6006543636322021
Validation loss: 1.8873730397993518

Epoch: 6| Step: 2
Training loss: 1.7128266096115112
Validation loss: 1.8850451054111603

Epoch: 6| Step: 3
Training loss: 1.847324252128601
Validation loss: 1.8389811720899356

Epoch: 6| Step: 4
Training loss: 1.9076170921325684
Validation loss: 1.902860124905904

Epoch: 6| Step: 5
Training loss: 1.9351110458374023
Validation loss: 1.9017800284970192

Epoch: 6| Step: 6
Training loss: 2.14585280418396
Validation loss: 1.8660811711383123

Epoch: 6| Step: 7
Training loss: 1.8086028099060059
Validation loss: 1.8395942218842045

Epoch: 6| Step: 8
Training loss: 2.6964786052703857
Validation loss: 1.8640596815334853

Epoch: 6| Step: 9
Training loss: 1.296461820602417
Validation loss: 1.8839584371095062

Epoch: 6| Step: 10
Training loss: 1.5810871124267578
Validation loss: 1.8668808296162596

Epoch: 6| Step: 11
Training loss: 1.845228910446167
Validation loss: 1.8761111715788483

Epoch: 6| Step: 12
Training loss: 2.113689661026001
Validation loss: 1.940309242535663

Epoch: 6| Step: 13
Training loss: 1.3015772104263306
Validation loss: 1.8703907997377458

Epoch: 214| Step: 0
Training loss: 1.7602012157440186
Validation loss: 1.8987955111329273

Epoch: 6| Step: 1
Training loss: 1.5849725008010864
Validation loss: 1.9178745362066454

Epoch: 6| Step: 2
Training loss: 1.6544543504714966
Validation loss: 1.9041652935807423

Epoch: 6| Step: 3
Training loss: 1.931395411491394
Validation loss: 1.8928555775714178

Epoch: 6| Step: 4
Training loss: 1.2879714965820312
Validation loss: 1.9205640797973962

Epoch: 6| Step: 5
Training loss: 1.320379376411438
Validation loss: 1.8949287578623781

Epoch: 6| Step: 6
Training loss: 1.06556236743927
Validation loss: 1.8742675768431796

Epoch: 6| Step: 7
Training loss: 2.386699676513672
Validation loss: 1.8788331529145599

Epoch: 6| Step: 8
Training loss: 1.8342854976654053
Validation loss: 1.886711617951752

Epoch: 6| Step: 9
Training loss: 2.284165859222412
Validation loss: 1.8714334298205633

Epoch: 6| Step: 10
Training loss: 1.6569010019302368
Validation loss: 1.8837526357302101

Epoch: 6| Step: 11
Training loss: 1.911656379699707
Validation loss: 1.8615748305474558

Epoch: 6| Step: 12
Training loss: 1.788228154182434
Validation loss: 1.8708291553681897

Epoch: 6| Step: 13
Training loss: 1.8824928998947144
Validation loss: 1.8829595542723132

Epoch: 215| Step: 0
Training loss: 2.100076198577881
Validation loss: 1.8737172106260895

Epoch: 6| Step: 1
Training loss: 1.9226890802383423
Validation loss: 1.8308683415894866

Epoch: 6| Step: 2
Training loss: 1.0443103313446045
Validation loss: 1.8303083424927087

Epoch: 6| Step: 3
Training loss: 2.646787405014038
Validation loss: 1.8469693853009133

Epoch: 6| Step: 4
Training loss: 1.0966663360595703
Validation loss: 1.8199563308428692

Epoch: 6| Step: 5
Training loss: 1.8462581634521484
Validation loss: 1.8542741139729817

Epoch: 6| Step: 6
Training loss: 1.3123137950897217
Validation loss: 1.8806834208068026

Epoch: 6| Step: 7
Training loss: 1.3997907638549805
Validation loss: 1.8565297216497443

Epoch: 6| Step: 8
Training loss: 1.3743773698806763
Validation loss: 1.8722672436826973

Epoch: 6| Step: 9
Training loss: 2.161652088165283
Validation loss: 1.8703050587766914

Epoch: 6| Step: 10
Training loss: 2.1756985187530518
Validation loss: 1.8950903466952744

Epoch: 6| Step: 11
Training loss: 2.149345874786377
Validation loss: 1.865034721230948

Epoch: 6| Step: 12
Training loss: 1.554429531097412
Validation loss: 1.882142287428661

Epoch: 6| Step: 13
Training loss: 1.4493826627731323
Validation loss: 1.8827934316409531

Epoch: 216| Step: 0
Training loss: 1.7284681797027588
Validation loss: 1.8795597040525047

Epoch: 6| Step: 1
Training loss: 2.1751327514648438
Validation loss: 1.8887624971328243

Epoch: 6| Step: 2
Training loss: 1.7205291986465454
Validation loss: 1.883217711602488

Epoch: 6| Step: 3
Training loss: 2.044546604156494
Validation loss: 1.8872603677934217

Epoch: 6| Step: 4
Training loss: 1.8049484491348267
Validation loss: 1.9284076652219218

Epoch: 6| Step: 5
Training loss: 1.235495924949646
Validation loss: 1.9139245504974036

Epoch: 6| Step: 6
Training loss: 1.5989997386932373
Validation loss: 1.9146342905618812

Epoch: 6| Step: 7
Training loss: 2.354149341583252
Validation loss: 1.9228731227177445

Epoch: 6| Step: 8
Training loss: 1.7681448459625244
Validation loss: 1.9471356227833738

Epoch: 6| Step: 9
Training loss: 1.8754547834396362
Validation loss: 1.943690271787746

Epoch: 6| Step: 10
Training loss: 1.6931304931640625
Validation loss: 1.9169113982108332

Epoch: 6| Step: 11
Training loss: 1.8114030361175537
Validation loss: 1.9141332846815868

Epoch: 6| Step: 12
Training loss: 2.181807041168213
Validation loss: 1.9055311218384774

Epoch: 6| Step: 13
Training loss: 1.118647575378418
Validation loss: 1.8725776621090469

Epoch: 217| Step: 0
Training loss: 1.8504403829574585
Validation loss: 1.903927421057096

Epoch: 6| Step: 1
Training loss: 1.7225613594055176
Validation loss: 1.9116003013426257

Epoch: 6| Step: 2
Training loss: 1.4378690719604492
Validation loss: 1.8364385738167712

Epoch: 6| Step: 3
Training loss: 2.1909894943237305
Validation loss: 1.869336696081264

Epoch: 6| Step: 4
Training loss: 1.273826003074646
Validation loss: 1.904418037783715

Epoch: 6| Step: 5
Training loss: 1.7231552600860596
Validation loss: 1.799925220909939

Epoch: 6| Step: 6
Training loss: 1.7751924991607666
Validation loss: 1.9038610227646366

Epoch: 6| Step: 7
Training loss: 2.0150153636932373
Validation loss: 1.8802981274102324

Epoch: 6| Step: 8
Training loss: 1.5605850219726562
Validation loss: 1.884401621357087

Epoch: 6| Step: 9
Training loss: 1.8675907850265503
Validation loss: 1.884276960485725

Epoch: 6| Step: 10
Training loss: 2.0425760746002197
Validation loss: 1.8785443126514394

Epoch: 6| Step: 11
Training loss: 2.211136817932129
Validation loss: 1.8986415798946092

Epoch: 6| Step: 12
Training loss: 1.957170844078064
Validation loss: 1.8660405887070524

Epoch: 6| Step: 13
Training loss: 1.4550881385803223
Validation loss: 1.8350350356871081

Epoch: 218| Step: 0
Training loss: 1.6976115703582764
Validation loss: 1.869772635480409

Epoch: 6| Step: 1
Training loss: 1.2882466316223145
Validation loss: 1.9016378951329056

Epoch: 6| Step: 2
Training loss: 2.2289373874664307
Validation loss: 1.8848253193721975

Epoch: 6| Step: 3
Training loss: 1.2281545400619507
Validation loss: 1.8605658879844091

Epoch: 6| Step: 4
Training loss: 1.6509323120117188
Validation loss: 1.8737179079363424

Epoch: 6| Step: 5
Training loss: 1.2602925300598145
Validation loss: 1.9277512822099911

Epoch: 6| Step: 6
Training loss: 2.2223479747772217
Validation loss: 1.8210133967861053

Epoch: 6| Step: 7
Training loss: 1.8458964824676514
Validation loss: 1.8837988222798994

Epoch: 6| Step: 8
Training loss: 2.1130211353302
Validation loss: 1.9006193171265304

Epoch: 6| Step: 9
Training loss: 2.3667383193969727
Validation loss: 1.85884355473262

Epoch: 6| Step: 10
Training loss: 1.425357460975647
Validation loss: 1.8636467482454033

Epoch: 6| Step: 11
Training loss: 1.373598575592041
Validation loss: 1.8966806242542882

Epoch: 6| Step: 12
Training loss: 2.0060513019561768
Validation loss: 1.8678533249003912

Epoch: 6| Step: 13
Training loss: 2.28608775138855
Validation loss: 1.855557544257051

Epoch: 219| Step: 0
Training loss: 1.9312580823898315
Validation loss: 1.8616686367219495

Epoch: 6| Step: 1
Training loss: 1.6301590204238892
Validation loss: 1.88615797668375

Epoch: 6| Step: 2
Training loss: 1.8774914741516113
Validation loss: 1.8831516030014201

Epoch: 6| Step: 3
Training loss: 1.9435113668441772
Validation loss: 1.827490710443066

Epoch: 6| Step: 4
Training loss: 1.267892837524414
Validation loss: 1.8477606683649042

Epoch: 6| Step: 5
Training loss: 1.9790377616882324
Validation loss: 1.917406294935493

Epoch: 6| Step: 6
Training loss: 1.5623531341552734
Validation loss: 1.8173725271737704

Epoch: 6| Step: 7
Training loss: 1.8778271675109863
Validation loss: 1.8374721029753327

Epoch: 6| Step: 8
Training loss: 2.303354263305664
Validation loss: 1.8693844861881708

Epoch: 6| Step: 9
Training loss: 2.036111354827881
Validation loss: 1.858030926796698

Epoch: 6| Step: 10
Training loss: 1.713292121887207
Validation loss: 1.851210868486794

Epoch: 6| Step: 11
Training loss: 1.1622352600097656
Validation loss: 1.8779632276104343

Epoch: 6| Step: 12
Training loss: 2.2445831298828125
Validation loss: 1.8601530777510775

Epoch: 6| Step: 13
Training loss: 1.5149145126342773
Validation loss: 1.8685164118325839

Epoch: 220| Step: 0
Training loss: 1.7075326442718506
Validation loss: 1.8547314238804642

Epoch: 6| Step: 1
Training loss: 1.8369501829147339
Validation loss: 1.8677864215707267

Epoch: 6| Step: 2
Training loss: 2.0583314895629883
Validation loss: 1.8860629220162668

Epoch: 6| Step: 3
Training loss: 2.1887505054473877
Validation loss: 1.8957312389086651

Epoch: 6| Step: 4
Training loss: 2.083961009979248
Validation loss: 1.9196719277289607

Epoch: 6| Step: 5
Training loss: 1.6027164459228516
Validation loss: 1.9228224959424747

Epoch: 6| Step: 6
Training loss: 2.224677562713623
Validation loss: 1.868835122354569

Epoch: 6| Step: 7
Training loss: 1.0901353359222412
Validation loss: 1.8557747717826598

Epoch: 6| Step: 8
Training loss: 1.7830101251602173
Validation loss: 1.8914840439314484

Epoch: 6| Step: 9
Training loss: 1.61557137966156
Validation loss: 1.894272473550612

Epoch: 6| Step: 10
Training loss: 1.9418394565582275
Validation loss: 1.9192342937633555

Epoch: 6| Step: 11
Training loss: 1.4399547576904297
Validation loss: 1.888161358012948

Epoch: 6| Step: 12
Training loss: 1.4075438976287842
Validation loss: 1.9058896213449457

Epoch: 6| Step: 13
Training loss: 2.1124107837677
Validation loss: 1.895536635511665

Epoch: 221| Step: 0
Training loss: 1.4671297073364258
Validation loss: 1.9307771549429944

Epoch: 6| Step: 1
Training loss: 1.8261345624923706
Validation loss: 1.8789735827394711

Epoch: 6| Step: 2
Training loss: 1.498313546180725
Validation loss: 1.9010497229073637

Epoch: 6| Step: 3
Training loss: 1.3735432624816895
Validation loss: 1.9067502060244161

Epoch: 6| Step: 4
Training loss: 1.449817180633545
Validation loss: 1.8989685812304098

Epoch: 6| Step: 5
Training loss: 1.7991617918014526
Validation loss: 1.8539218633405623

Epoch: 6| Step: 6
Training loss: 1.847764015197754
Validation loss: 1.8671434412720382

Epoch: 6| Step: 7
Training loss: 2.2504336833953857
Validation loss: 1.8220831296777213

Epoch: 6| Step: 8
Training loss: 1.5973395109176636
Validation loss: 1.8485262278587586

Epoch: 6| Step: 9
Training loss: 2.241440773010254
Validation loss: 1.8547991603933356

Epoch: 6| Step: 10
Training loss: 2.0923962593078613
Validation loss: 1.9188107572576052

Epoch: 6| Step: 11
Training loss: 1.6760401725769043
Validation loss: 1.8730196440091698

Epoch: 6| Step: 12
Training loss: 1.93556809425354
Validation loss: 1.883174160475372

Epoch: 6| Step: 13
Training loss: 1.7643914222717285
Validation loss: 1.8485725207995343

Epoch: 222| Step: 0
Training loss: 1.8965102434158325
Validation loss: 1.8377381652914069

Epoch: 6| Step: 1
Training loss: 1.6842129230499268
Validation loss: 1.869748286021653

Epoch: 6| Step: 2
Training loss: 1.2618763446807861
Validation loss: 1.8442977384854389

Epoch: 6| Step: 3
Training loss: 1.6633044481277466
Validation loss: 1.861044147963165

Epoch: 6| Step: 4
Training loss: 1.2327141761779785
Validation loss: 1.867850524122997

Epoch: 6| Step: 5
Training loss: 1.8514187335968018
Validation loss: 1.8934184261547622

Epoch: 6| Step: 6
Training loss: 1.7320032119750977
Validation loss: 1.8686706199440906

Epoch: 6| Step: 7
Training loss: 2.1945080757141113
Validation loss: 1.8860857320088211

Epoch: 6| Step: 8
Training loss: 2.074258804321289
Validation loss: 1.8815240629257695

Epoch: 6| Step: 9
Training loss: 2.276510238647461
Validation loss: 1.9053118844186105

Epoch: 6| Step: 10
Training loss: 1.8229665756225586
Validation loss: 1.8818850389090918

Epoch: 6| Step: 11
Training loss: 1.5930445194244385
Validation loss: 1.8807880237538328

Epoch: 6| Step: 12
Training loss: 1.7757813930511475
Validation loss: 1.8709562145253664

Epoch: 6| Step: 13
Training loss: 1.3361653089523315
Validation loss: 1.8718791930906233

Epoch: 223| Step: 0
Training loss: 2.5629754066467285
Validation loss: 1.8663030157807052

Epoch: 6| Step: 1
Training loss: 2.298720359802246
Validation loss: 1.849455851380543

Epoch: 6| Step: 2
Training loss: 1.7820876836776733
Validation loss: 1.8588406347459363

Epoch: 6| Step: 3
Training loss: 2.3422651290893555
Validation loss: 1.8578055956030404

Epoch: 6| Step: 4
Training loss: 1.4746943712234497
Validation loss: 1.844983873828765

Epoch: 6| Step: 5
Training loss: 1.5022940635681152
Validation loss: 1.8341674650869062

Epoch: 6| Step: 6
Training loss: 1.6991114616394043
Validation loss: 1.8409205367488246

Epoch: 6| Step: 7
Training loss: 1.3731756210327148
Validation loss: 1.8969069719314575

Epoch: 6| Step: 8
Training loss: 1.8171546459197998
Validation loss: 1.9081704501182801

Epoch: 6| Step: 9
Training loss: 1.4268701076507568
Validation loss: 1.8940135394373248

Epoch: 6| Step: 10
Training loss: 2.0003514289855957
Validation loss: 1.8541538458998486

Epoch: 6| Step: 11
Training loss: 1.612862467765808
Validation loss: 1.8785529572476622

Epoch: 6| Step: 12
Training loss: 1.3593723773956299
Validation loss: 1.8632332842837098

Epoch: 6| Step: 13
Training loss: 1.4162123203277588
Validation loss: 1.8532789420056086

Epoch: 224| Step: 0
Training loss: 1.5898473262786865
Validation loss: 1.86822170852333

Epoch: 6| Step: 1
Training loss: 1.6616578102111816
Validation loss: 1.8425013249920261

Epoch: 6| Step: 2
Training loss: 1.8766767978668213
Validation loss: 1.917800526465139

Epoch: 6| Step: 3
Training loss: 1.8357347249984741
Validation loss: 1.9004760711423812

Epoch: 6| Step: 4
Training loss: 1.972528338432312
Validation loss: 1.9557325737450713

Epoch: 6| Step: 5
Training loss: 1.738349437713623
Validation loss: 1.9053564712565432

Epoch: 6| Step: 6
Training loss: 1.8852181434631348
Validation loss: 1.8585269092231669

Epoch: 6| Step: 7
Training loss: 1.8670942783355713
Validation loss: 1.8928551776434785

Epoch: 6| Step: 8
Training loss: 1.5443307161331177
Validation loss: 1.8589424702429003

Epoch: 6| Step: 9
Training loss: 1.649008870124817
Validation loss: 1.87049352353619

Epoch: 6| Step: 10
Training loss: 1.553250789642334
Validation loss: 1.8617306396525393

Epoch: 6| Step: 11
Training loss: 1.5344257354736328
Validation loss: 1.8496129358968427

Epoch: 6| Step: 12
Training loss: 2.167482852935791
Validation loss: 1.8263899472451979

Epoch: 6| Step: 13
Training loss: 2.00724196434021
Validation loss: 1.8992381249704668

Epoch: 225| Step: 0
Training loss: 1.9940298795700073
Validation loss: 1.8400757530684113

Epoch: 6| Step: 1
Training loss: 1.4545761346817017
Validation loss: 1.8606376699222031

Epoch: 6| Step: 2
Training loss: 1.7344295978546143
Validation loss: 1.866694857997279

Epoch: 6| Step: 3
Training loss: 2.5362961292266846
Validation loss: 1.8873460472271006

Epoch: 6| Step: 4
Training loss: 1.878394603729248
Validation loss: 1.9187081295956847

Epoch: 6| Step: 5
Training loss: 1.0420793294906616
Validation loss: 1.871013722112102

Epoch: 6| Step: 6
Training loss: 2.1486096382141113
Validation loss: 1.8492563886027182

Epoch: 6| Step: 7
Training loss: 1.8967621326446533
Validation loss: 1.8916577510936285

Epoch: 6| Step: 8
Training loss: 1.4393024444580078
Validation loss: 1.9330727208045222

Epoch: 6| Step: 9
Training loss: 1.701863408088684
Validation loss: 1.8794199702560261

Epoch: 6| Step: 10
Training loss: 1.4057996273040771
Validation loss: 1.9245580473253805

Epoch: 6| Step: 11
Training loss: 1.9993271827697754
Validation loss: 1.843608279382029

Epoch: 6| Step: 12
Training loss: 1.7664899826049805
Validation loss: 1.9004657024978309

Epoch: 6| Step: 13
Training loss: 1.4511277675628662
Validation loss: 1.9244641616780271

Epoch: 226| Step: 0
Training loss: 1.3548495769500732
Validation loss: 1.876240481612503

Epoch: 6| Step: 1
Training loss: 1.6171038150787354
Validation loss: 1.8998174846813243

Epoch: 6| Step: 2
Training loss: 1.9403491020202637
Validation loss: 1.8939188270158664

Epoch: 6| Step: 3
Training loss: 2.296828508377075
Validation loss: 1.8879139449006768

Epoch: 6| Step: 4
Training loss: 2.1099987030029297
Validation loss: 1.8460434188124955

Epoch: 6| Step: 5
Training loss: 1.6624372005462646
Validation loss: 1.9101644985137447

Epoch: 6| Step: 6
Training loss: 1.324657917022705
Validation loss: 1.8686379668533162

Epoch: 6| Step: 7
Training loss: 1.4139324426651
Validation loss: 1.904855876840571

Epoch: 6| Step: 8
Training loss: 1.3637487888336182
Validation loss: 1.8568568703948811

Epoch: 6| Step: 9
Training loss: 2.2756168842315674
Validation loss: 1.8629102412090506

Epoch: 6| Step: 10
Training loss: 1.2649638652801514
Validation loss: 1.8647076801587177

Epoch: 6| Step: 11
Training loss: 1.593435525894165
Validation loss: 1.8751697745374454

Epoch: 6| Step: 12
Training loss: 2.6692771911621094
Validation loss: 1.8867775265888502

Epoch: 6| Step: 13
Training loss: 1.725556492805481
Validation loss: 1.9098780680728216

Epoch: 227| Step: 0
Training loss: 1.9914636611938477
Validation loss: 1.854233172632033

Epoch: 6| Step: 1
Training loss: 1.6240605115890503
Validation loss: 1.8869057573297972

Epoch: 6| Step: 2
Training loss: 1.3847675323486328
Validation loss: 1.8844188913222282

Epoch: 6| Step: 3
Training loss: 1.5556524991989136
Validation loss: 1.9238202212959208

Epoch: 6| Step: 4
Training loss: 1.7759103775024414
Validation loss: 1.8867789994003952

Epoch: 6| Step: 5
Training loss: 1.7161853313446045
Validation loss: 1.8913037277037097

Epoch: 6| Step: 6
Training loss: 1.0729548931121826
Validation loss: 1.8967239497810282

Epoch: 6| Step: 7
Training loss: 1.6108583211898804
Validation loss: 1.9012074611520255

Epoch: 6| Step: 8
Training loss: 1.9367430210113525
Validation loss: 1.8588430163680867

Epoch: 6| Step: 9
Training loss: 1.2991496324539185
Validation loss: 1.8306915426767

Epoch: 6| Step: 10
Training loss: 2.174863338470459
Validation loss: 1.8617549609112483

Epoch: 6| Step: 11
Training loss: 2.0459647178649902
Validation loss: 1.817479013114847

Epoch: 6| Step: 12
Training loss: 2.107306480407715
Validation loss: 1.8691178983257664

Epoch: 6| Step: 13
Training loss: 2.3566606044769287
Validation loss: 1.8681821720574492

Epoch: 228| Step: 0
Training loss: 2.0733070373535156
Validation loss: 1.858724586425289

Epoch: 6| Step: 1
Training loss: 2.688166856765747
Validation loss: 1.8486985570640975

Epoch: 6| Step: 2
Training loss: 1.3285245895385742
Validation loss: 1.8712539813851798

Epoch: 6| Step: 3
Training loss: 1.2233939170837402
Validation loss: 1.88648425122743

Epoch: 6| Step: 4
Training loss: 2.313628911972046
Validation loss: 1.8530329376138666

Epoch: 6| Step: 5
Training loss: 1.782372236251831
Validation loss: 1.8762330342364568

Epoch: 6| Step: 6
Training loss: 1.797677755355835
Validation loss: 1.8690736063065068

Epoch: 6| Step: 7
Training loss: 1.6323180198669434
Validation loss: 1.8809588109293292

Epoch: 6| Step: 8
Training loss: 1.5951738357543945
Validation loss: 1.8652035254304127

Epoch: 6| Step: 9
Training loss: 1.7613729238510132
Validation loss: 1.8645686539270545

Epoch: 6| Step: 10
Training loss: 1.3222239017486572
Validation loss: 1.8855178125442997

Epoch: 6| Step: 11
Training loss: 1.5595159530639648
Validation loss: 1.843325525201777

Epoch: 6| Step: 12
Training loss: 1.3190701007843018
Validation loss: 1.8887006851934618

Epoch: 6| Step: 13
Training loss: 2.036109209060669
Validation loss: 1.8757171477040937

Epoch: 229| Step: 0
Training loss: 1.724420189857483
Validation loss: 1.8757132407157653

Epoch: 6| Step: 1
Training loss: 1.6260275840759277
Validation loss: 1.8834386012887443

Epoch: 6| Step: 2
Training loss: 1.745115041732788
Validation loss: 1.81377915669513

Epoch: 6| Step: 3
Training loss: 1.2862539291381836
Validation loss: 1.876367635624383

Epoch: 6| Step: 4
Training loss: 1.5959620475769043
Validation loss: 1.9252877876322756

Epoch: 6| Step: 5
Training loss: 1.1915802955627441
Validation loss: 1.8907042472593245

Epoch: 6| Step: 6
Training loss: 2.1553714275360107
Validation loss: 1.8921760987210017

Epoch: 6| Step: 7
Training loss: 2.196528911590576
Validation loss: 1.8580835532116633

Epoch: 6| Step: 8
Training loss: 1.2706427574157715
Validation loss: 1.8460920164662022

Epoch: 6| Step: 9
Training loss: 1.319084644317627
Validation loss: 1.8458685234028807

Epoch: 6| Step: 10
Training loss: 2.655089855194092
Validation loss: 1.8192386691288283

Epoch: 6| Step: 11
Training loss: 2.2108452320098877
Validation loss: 1.890685732646655

Epoch: 6| Step: 12
Training loss: 1.7968828678131104
Validation loss: 1.8524090397742488

Epoch: 6| Step: 13
Training loss: 1.525916576385498
Validation loss: 1.8639019958434566

Epoch: 230| Step: 0
Training loss: 1.9263935089111328
Validation loss: 1.8777033718683387

Epoch: 6| Step: 1
Training loss: 1.6435813903808594
Validation loss: 1.8865972180520334

Epoch: 6| Step: 2
Training loss: 1.6370155811309814
Validation loss: 1.8493428396922287

Epoch: 6| Step: 3
Training loss: 1.285994529724121
Validation loss: 1.8247822177025579

Epoch: 6| Step: 4
Training loss: 2.18422794342041
Validation loss: 1.8148028132736043

Epoch: 6| Step: 5
Training loss: 1.8307173252105713
Validation loss: 1.9806288314122025

Epoch: 6| Step: 6
Training loss: 1.4899377822875977
Validation loss: 1.8872157783918484

Epoch: 6| Step: 7
Training loss: 1.6948875188827515
Validation loss: 1.9130943898231751

Epoch: 6| Step: 8
Training loss: 1.4675841331481934
Validation loss: 1.9080423975503573

Epoch: 6| Step: 9
Training loss: 1.5395174026489258
Validation loss: 1.915517019969161

Epoch: 6| Step: 10
Training loss: 1.908268690109253
Validation loss: 1.8371790621870308

Epoch: 6| Step: 11
Training loss: 1.9493300914764404
Validation loss: 1.8839750430917228

Epoch: 6| Step: 12
Training loss: 2.05656099319458
Validation loss: 1.896296396050402

Epoch: 6| Step: 13
Training loss: 1.9219063520431519
Validation loss: 1.9086713637075117

Epoch: 231| Step: 0
Training loss: 1.7800405025482178
Validation loss: 1.9117509703482352

Epoch: 6| Step: 1
Training loss: 2.0574586391448975
Validation loss: 1.8582949253820604

Epoch: 6| Step: 2
Training loss: 1.4818427562713623
Validation loss: 1.8777049113345403

Epoch: 6| Step: 3
Training loss: 1.7699779272079468
Validation loss: 1.871190071105957

Epoch: 6| Step: 4
Training loss: 2.3792896270751953
Validation loss: 1.8187234222248037

Epoch: 6| Step: 5
Training loss: 1.462792158126831
Validation loss: 1.8499679770520938

Epoch: 6| Step: 6
Training loss: 1.793562889099121
Validation loss: 1.8293968887739285

Epoch: 6| Step: 7
Training loss: 1.3348863124847412
Validation loss: 1.8804896916112592

Epoch: 6| Step: 8
Training loss: 2.2453842163085938
Validation loss: 1.89069829833123

Epoch: 6| Step: 9
Training loss: 1.3528985977172852
Validation loss: 1.8853026564403246

Epoch: 6| Step: 10
Training loss: 1.1666102409362793
Validation loss: 1.8853544663357478

Epoch: 6| Step: 11
Training loss: 2.170936107635498
Validation loss: 1.8594308617294475

Epoch: 6| Step: 12
Training loss: 1.7687568664550781
Validation loss: 1.8745459894980154

Epoch: 6| Step: 13
Training loss: 1.6585447788238525
Validation loss: 1.8640711512616885

Epoch: 232| Step: 0
Training loss: 1.1245231628417969
Validation loss: 1.8954289203049035

Epoch: 6| Step: 1
Training loss: 1.3016200065612793
Validation loss: 1.8689905520408385

Epoch: 6| Step: 2
Training loss: 1.7277870178222656
Validation loss: 1.8434737049123293

Epoch: 6| Step: 3
Training loss: 1.746664047241211
Validation loss: 1.8455317456235167

Epoch: 6| Step: 4
Training loss: 2.2914633750915527
Validation loss: 1.8905433762458064

Epoch: 6| Step: 5
Training loss: 1.7280614376068115
Validation loss: 1.8145702308224094

Epoch: 6| Step: 6
Training loss: 1.963082194328308
Validation loss: 1.8579604112973778

Epoch: 6| Step: 7
Training loss: 1.8772209882736206
Validation loss: 1.8615870552678262

Epoch: 6| Step: 8
Training loss: 2.029890537261963
Validation loss: 1.8468926581003333

Epoch: 6| Step: 9
Training loss: 1.5035595893859863
Validation loss: 1.872603319024527

Epoch: 6| Step: 10
Training loss: 1.397809624671936
Validation loss: 1.8778635929989558

Epoch: 6| Step: 11
Training loss: 1.4819051027297974
Validation loss: 1.8607380518349268

Epoch: 6| Step: 12
Training loss: 2.467700481414795
Validation loss: 1.9437765946952246

Epoch: 6| Step: 13
Training loss: 1.2966008186340332
Validation loss: 1.8732231458028157

Epoch: 233| Step: 0
Training loss: 2.1395201683044434
Validation loss: 1.8576144044117262

Epoch: 6| Step: 1
Training loss: 2.44820499420166
Validation loss: 1.8852375335590814

Epoch: 6| Step: 2
Training loss: 2.0370850563049316
Validation loss: 1.900428028516872

Epoch: 6| Step: 3
Training loss: 1.3388609886169434
Validation loss: 1.8431325804802678

Epoch: 6| Step: 4
Training loss: 1.7774678468704224
Validation loss: 1.8854298386522519

Epoch: 6| Step: 5
Training loss: 1.910658597946167
Validation loss: 1.8293346794702674

Epoch: 6| Step: 6
Training loss: 1.4751949310302734
Validation loss: 1.901276667912801

Epoch: 6| Step: 7
Training loss: 1.385918378829956
Validation loss: 1.9002195506967523

Epoch: 6| Step: 8
Training loss: 1.4101085662841797
Validation loss: 1.8843963761483469

Epoch: 6| Step: 9
Training loss: 1.8501343727111816
Validation loss: 1.8978003212200698

Epoch: 6| Step: 10
Training loss: 1.491039514541626
Validation loss: 1.8387645995745094

Epoch: 6| Step: 11
Training loss: 2.1786348819732666
Validation loss: 1.8796053522376603

Epoch: 6| Step: 12
Training loss: 1.312373161315918
Validation loss: 1.9109669398236018

Epoch: 6| Step: 13
Training loss: 1.722305178642273
Validation loss: 1.8442799481012488

Epoch: 234| Step: 0
Training loss: 1.886031985282898
Validation loss: 1.8450841903686523

Epoch: 6| Step: 1
Training loss: 1.554762363433838
Validation loss: 1.8785870793045207

Epoch: 6| Step: 2
Training loss: 2.6538751125335693
Validation loss: 1.8170956411669332

Epoch: 6| Step: 3
Training loss: 1.3758794069290161
Validation loss: 1.8772642650911886

Epoch: 6| Step: 4
Training loss: 1.9614777565002441
Validation loss: 1.8102164973494828

Epoch: 6| Step: 5
Training loss: 1.8724732398986816
Validation loss: 1.8430488763316986

Epoch: 6| Step: 6
Training loss: 2.1083245277404785
Validation loss: 1.8801783611697536

Epoch: 6| Step: 7
Training loss: 1.3434841632843018
Validation loss: 1.8373220723162416

Epoch: 6| Step: 8
Training loss: 1.7050803899765015
Validation loss: 1.8769819621116883

Epoch: 6| Step: 9
Training loss: 2.043360948562622
Validation loss: 1.8248885088069464

Epoch: 6| Step: 10
Training loss: 1.6097785234451294
Validation loss: 1.908789292458565

Epoch: 6| Step: 11
Training loss: 1.826361894607544
Validation loss: 1.8582918990042903

Epoch: 6| Step: 12
Training loss: 1.550275444984436
Validation loss: 1.8462031400331886

Epoch: 6| Step: 13
Training loss: 1.0516228675842285
Validation loss: 1.8914684070053922

Epoch: 235| Step: 0
Training loss: 1.3585586547851562
Validation loss: 1.894068847420395

Epoch: 6| Step: 1
Training loss: 1.9436099529266357
Validation loss: 1.9094387959408503

Epoch: 6| Step: 2
Training loss: 1.88837730884552
Validation loss: 1.8543473712859615

Epoch: 6| Step: 3
Training loss: 1.5689098834991455
Validation loss: 1.8668253255146805

Epoch: 6| Step: 4
Training loss: 1.6155059337615967
Validation loss: 1.8994593594663887

Epoch: 6| Step: 5
Training loss: 1.9047906398773193
Validation loss: 1.8372627112173265

Epoch: 6| Step: 6
Training loss: 1.7986187934875488
Validation loss: 1.855926521362797

Epoch: 6| Step: 7
Training loss: 1.2142753601074219
Validation loss: 1.8967937756610174

Epoch: 6| Step: 8
Training loss: 1.8468923568725586
Validation loss: 1.888010182688313

Epoch: 6| Step: 9
Training loss: 2.2045540809631348
Validation loss: 1.9052697086846957

Epoch: 6| Step: 10
Training loss: 1.321502923965454
Validation loss: 1.920569699297669

Epoch: 6| Step: 11
Training loss: 1.7616281509399414
Validation loss: 1.8844565306940386

Epoch: 6| Step: 12
Training loss: 1.906682014465332
Validation loss: 2.016375635259895

Epoch: 6| Step: 13
Training loss: 2.013735055923462
Validation loss: 1.926761519524359

Epoch: 236| Step: 0
Training loss: 1.319217562675476
Validation loss: 1.9313518936916063

Epoch: 6| Step: 1
Training loss: 2.0844483375549316
Validation loss: 1.9759392289705173

Epoch: 6| Step: 2
Training loss: 2.0523903369903564
Validation loss: 1.8790009713942004

Epoch: 6| Step: 3
Training loss: 1.1852951049804688
Validation loss: 1.9076916889477802

Epoch: 6| Step: 4
Training loss: 1.804787278175354
Validation loss: 1.9338455341195548

Epoch: 6| Step: 5
Training loss: 1.7895903587341309
Validation loss: 1.9131514192909322

Epoch: 6| Step: 6
Training loss: 1.4687238931655884
Validation loss: 1.91015366841388

Epoch: 6| Step: 7
Training loss: 1.545993685722351
Validation loss: 1.9139865213824856

Epoch: 6| Step: 8
Training loss: 1.7573450803756714
Validation loss: 1.9266906425517092

Epoch: 6| Step: 9
Training loss: 1.9774720668792725
Validation loss: 1.8568527647244033

Epoch: 6| Step: 10
Training loss: 2.1934444904327393
Validation loss: 1.9130982301568473

Epoch: 6| Step: 11
Training loss: 2.0657055377960205
Validation loss: 1.9061951944904942

Epoch: 6| Step: 12
Training loss: 1.6479628086090088
Validation loss: 1.924886154872115

Epoch: 6| Step: 13
Training loss: 1.510922908782959
Validation loss: 1.923645814259847

Epoch: 237| Step: 0
Training loss: 1.7235026359558105
Validation loss: 1.8752323850508659

Epoch: 6| Step: 1
Training loss: 1.8456356525421143
Validation loss: 1.8203623294830322

Epoch: 6| Step: 2
Training loss: 1.154610514640808
Validation loss: 1.8684389924490323

Epoch: 6| Step: 3
Training loss: 1.4680352210998535
Validation loss: 1.927379572263328

Epoch: 6| Step: 4
Training loss: 1.8813719749450684
Validation loss: 1.8760093745364939

Epoch: 6| Step: 5
Training loss: 2.120530128479004
Validation loss: 1.8531236148649646

Epoch: 6| Step: 6
Training loss: 1.259800672531128
Validation loss: 1.8133586773308374

Epoch: 6| Step: 7
Training loss: 2.3284945487976074
Validation loss: 1.8082254266226163

Epoch: 6| Step: 8
Training loss: 1.249556541442871
Validation loss: 1.8397625530919721

Epoch: 6| Step: 9
Training loss: 2.1043145656585693
Validation loss: 1.8836984813854258

Epoch: 6| Step: 10
Training loss: 2.431183338165283
Validation loss: 1.823040133522403

Epoch: 6| Step: 11
Training loss: 1.6207671165466309
Validation loss: 1.9278445705290763

Epoch: 6| Step: 12
Training loss: 1.714252233505249
Validation loss: 1.859452239928707

Epoch: 6| Step: 13
Training loss: 1.5486278533935547
Validation loss: 1.835688523066941

Epoch: 238| Step: 0
Training loss: 2.105623960494995
Validation loss: 1.904334258007747

Epoch: 6| Step: 1
Training loss: 2.0327444076538086
Validation loss: 1.9154645794181413

Epoch: 6| Step: 2
Training loss: 1.3199703693389893
Validation loss: 1.8271607481023318

Epoch: 6| Step: 3
Training loss: 1.4017980098724365
Validation loss: 1.8614301809700586

Epoch: 6| Step: 4
Training loss: 1.9023510217666626
Validation loss: 1.8869672001049083

Epoch: 6| Step: 5
Training loss: 2.218207359313965
Validation loss: 1.9205835429571008

Epoch: 6| Step: 6
Training loss: 1.6197504997253418
Validation loss: 1.8845228854046072

Epoch: 6| Step: 7
Training loss: 1.7532036304473877
Validation loss: 1.8860681159521944

Epoch: 6| Step: 8
Training loss: 1.3072824478149414
Validation loss: 1.8435494566476474

Epoch: 6| Step: 9
Training loss: 1.7044825553894043
Validation loss: 1.8652518359563683

Epoch: 6| Step: 10
Training loss: 2.1607413291931152
Validation loss: 1.8524317151756697

Epoch: 6| Step: 11
Training loss: 1.0111513137817383
Validation loss: 1.8630477164381294

Epoch: 6| Step: 12
Training loss: 2.022151231765747
Validation loss: 1.8541944616584367

Epoch: 6| Step: 13
Training loss: 1.5786900520324707
Validation loss: 1.8603482784763459

Epoch: 239| Step: 0
Training loss: 1.6343765258789062
Validation loss: 1.860394512453387

Epoch: 6| Step: 1
Training loss: 2.458559989929199
Validation loss: 1.8366714754412252

Epoch: 6| Step: 2
Training loss: 2.243729829788208
Validation loss: 1.852053770454981

Epoch: 6| Step: 3
Training loss: 1.264458179473877
Validation loss: 1.8378671651245446

Epoch: 6| Step: 4
Training loss: 1.1068488359451294
Validation loss: 1.9346587722019484

Epoch: 6| Step: 5
Training loss: 1.5096898078918457
Validation loss: 1.8432403674689672

Epoch: 6| Step: 6
Training loss: 1.530272126197815
Validation loss: 1.8493036839269823

Epoch: 6| Step: 7
Training loss: 1.3420484066009521
Validation loss: 1.8552811273964502

Epoch: 6| Step: 8
Training loss: 1.6441688537597656
Validation loss: 1.8806058540139148

Epoch: 6| Step: 9
Training loss: 1.7213048934936523
Validation loss: 1.8884622063688052

Epoch: 6| Step: 10
Training loss: 1.8042739629745483
Validation loss: 1.8983315921598864

Epoch: 6| Step: 11
Training loss: 2.107943534851074
Validation loss: 1.878981182652135

Epoch: 6| Step: 12
Training loss: 1.7773897647857666
Validation loss: 1.8789113670267084

Epoch: 6| Step: 13
Training loss: 2.210374355316162
Validation loss: 1.8585736187555457

Epoch: 240| Step: 0
Training loss: 2.2063589096069336
Validation loss: 1.93344081858153

Epoch: 6| Step: 1
Training loss: 1.2971690893173218
Validation loss: 1.8996055087735575

Epoch: 6| Step: 2
Training loss: 1.2674665451049805
Validation loss: 1.8663105528841737

Epoch: 6| Step: 3
Training loss: 1.8847815990447998
Validation loss: 1.9038633223502868

Epoch: 6| Step: 4
Training loss: 1.6242667436599731
Validation loss: 1.9186664832535612

Epoch: 6| Step: 5
Training loss: 1.632796287536621
Validation loss: 1.9010516815288092

Epoch: 6| Step: 6
Training loss: 1.7930772304534912
Validation loss: 1.855103342122929

Epoch: 6| Step: 7
Training loss: 1.170755386352539
Validation loss: 1.8949252725929342

Epoch: 6| Step: 8
Training loss: 1.9112977981567383
Validation loss: 1.8629547165286156

Epoch: 6| Step: 9
Training loss: 1.8479782342910767
Validation loss: 1.8592661426913353

Epoch: 6| Step: 10
Training loss: 1.8107402324676514
Validation loss: 1.8066459496815999

Epoch: 6| Step: 11
Training loss: 1.8681282997131348
Validation loss: 1.8404170236279886

Epoch: 6| Step: 12
Training loss: 1.50335693359375
Validation loss: 1.937487607361168

Epoch: 6| Step: 13
Training loss: 2.012697219848633
Validation loss: 1.8815846673903927

Epoch: 241| Step: 0
Training loss: 1.0590157508850098
Validation loss: 1.873640198861399

Epoch: 6| Step: 1
Training loss: 2.0599913597106934
Validation loss: 1.8559893292765464

Epoch: 6| Step: 2
Training loss: 1.5088282823562622
Validation loss: 1.9123335628099338

Epoch: 6| Step: 3
Training loss: 1.9155116081237793
Validation loss: 1.8637280156535487

Epoch: 6| Step: 4
Training loss: 1.4593901634216309
Validation loss: 1.8321504080167381

Epoch: 6| Step: 5
Training loss: 1.995431661605835
Validation loss: 1.8558979700970393

Epoch: 6| Step: 6
Training loss: 1.3571105003356934
Validation loss: 1.8837098588225663

Epoch: 6| Step: 7
Training loss: 2.086448907852173
Validation loss: 1.9042324660926737

Epoch: 6| Step: 8
Training loss: 1.6367030143737793
Validation loss: 1.8659572460318123

Epoch: 6| Step: 9
Training loss: 1.7664484977722168
Validation loss: 1.862955213874899

Epoch: 6| Step: 10
Training loss: 1.1763617992401123
Validation loss: 1.9359576727754326

Epoch: 6| Step: 11
Training loss: 1.6732971668243408
Validation loss: 1.8373470280760078

Epoch: 6| Step: 12
Training loss: 2.4991073608398438
Validation loss: 1.8264250832219278

Epoch: 6| Step: 13
Training loss: 1.689652442932129
Validation loss: 1.8643216907337148

Epoch: 242| Step: 0
Training loss: 1.5978703498840332
Validation loss: 1.8782106381590649

Epoch: 6| Step: 1
Training loss: 2.021782875061035
Validation loss: 1.8598170357365762

Epoch: 6| Step: 2
Training loss: 1.6316970586776733
Validation loss: 1.9097508589426677

Epoch: 6| Step: 3
Training loss: 2.3247268199920654
Validation loss: 1.8303512962915565

Epoch: 6| Step: 4
Training loss: 1.8338207006454468
Validation loss: 1.8743099038318922

Epoch: 6| Step: 5
Training loss: 1.1184680461883545
Validation loss: 1.8749022894008185

Epoch: 6| Step: 6
Training loss: 1.7574326992034912
Validation loss: 1.8712548350775113

Epoch: 6| Step: 7
Training loss: 1.265897512435913
Validation loss: 1.815831163878082

Epoch: 6| Step: 8
Training loss: 2.7896697521209717
Validation loss: 1.8579627365194342

Epoch: 6| Step: 9
Training loss: 0.9588169455528259
Validation loss: 1.8951616851232385

Epoch: 6| Step: 10
Training loss: 1.8112990856170654
Validation loss: 1.8565846130412111

Epoch: 6| Step: 11
Training loss: 1.7604928016662598
Validation loss: 1.8687303809709446

Epoch: 6| Step: 12
Training loss: 1.6612486839294434
Validation loss: 1.9098367844858477

Epoch: 6| Step: 13
Training loss: 1.7393450736999512
Validation loss: 1.8486949346398796

Epoch: 243| Step: 0
Training loss: 2.2394258975982666
Validation loss: 1.8466127969885384

Epoch: 6| Step: 1
Training loss: 1.8107163906097412
Validation loss: 1.827530676318753

Epoch: 6| Step: 2
Training loss: 1.1690560579299927
Validation loss: 1.8635290758584135

Epoch: 6| Step: 3
Training loss: 2.485658645629883
Validation loss: 1.8766880099491408

Epoch: 6| Step: 4
Training loss: 1.365438461303711
Validation loss: 1.9434369276928645

Epoch: 6| Step: 5
Training loss: 1.757127046585083
Validation loss: 1.8815031436181837

Epoch: 6| Step: 6
Training loss: 1.6390804052352905
Validation loss: 1.9028849268472323

Epoch: 6| Step: 7
Training loss: 1.9881644248962402
Validation loss: 1.9254797145884524

Epoch: 6| Step: 8
Training loss: 1.8514087200164795
Validation loss: 1.907178778802195

Epoch: 6| Step: 9
Training loss: 1.492771863937378
Validation loss: 1.848311807519646

Epoch: 6| Step: 10
Training loss: 1.8616324663162231
Validation loss: 1.932601967165547

Epoch: 6| Step: 11
Training loss: 1.7444541454315186
Validation loss: 1.922703162316353

Epoch: 6| Step: 12
Training loss: 1.288771629333496
Validation loss: 1.9313895087088309

Epoch: 6| Step: 13
Training loss: 1.4317705631256104
Validation loss: 1.9453161198605773

Epoch: 244| Step: 0
Training loss: 1.1655402183532715
Validation loss: 1.8687730155965334

Epoch: 6| Step: 1
Training loss: 1.8701598644256592
Validation loss: 1.9152059196144022

Epoch: 6| Step: 2
Training loss: 1.7620328664779663
Validation loss: 1.8854324099838093

Epoch: 6| Step: 3
Training loss: 1.9162578582763672
Validation loss: 1.8544910594981203

Epoch: 6| Step: 4
Training loss: 1.5404877662658691
Validation loss: 1.8986416491129066

Epoch: 6| Step: 5
Training loss: 1.2639944553375244
Validation loss: 1.9366598577909573

Epoch: 6| Step: 6
Training loss: 2.1277222633361816
Validation loss: 1.8811609680934618

Epoch: 6| Step: 7
Training loss: 2.04457950592041
Validation loss: 1.904450144819034

Epoch: 6| Step: 8
Training loss: 2.070884943008423
Validation loss: 1.8298543396816458

Epoch: 6| Step: 9
Training loss: 1.6853628158569336
Validation loss: 1.8589821425817346

Epoch: 6| Step: 10
Training loss: 1.8893566131591797
Validation loss: 1.9059077180841917

Epoch: 6| Step: 11
Training loss: 1.1012706756591797
Validation loss: 1.8704328998442619

Epoch: 6| Step: 12
Training loss: 1.6813082695007324
Validation loss: 1.9172883174752677

Epoch: 6| Step: 13
Training loss: 1.9971201419830322
Validation loss: 1.8264103794610629

Epoch: 245| Step: 0
Training loss: 1.5373883247375488
Validation loss: 1.8676395416259766

Epoch: 6| Step: 1
Training loss: 2.2235639095306396
Validation loss: 1.8499990906766666

Epoch: 6| Step: 2
Training loss: 1.1552915573120117
Validation loss: 1.9096003168372697

Epoch: 6| Step: 3
Training loss: 1.549778699874878
Validation loss: 1.9113115751615135

Epoch: 6| Step: 4
Training loss: 1.2121082544326782
Validation loss: 1.8798884422548356

Epoch: 6| Step: 5
Training loss: 1.9891552925109863
Validation loss: 1.8723065724936865

Epoch: 6| Step: 6
Training loss: 2.0448389053344727
Validation loss: 1.939577699989401

Epoch: 6| Step: 7
Training loss: 1.631352424621582
Validation loss: 1.9056059583540885

Epoch: 6| Step: 8
Training loss: 1.7049483060836792
Validation loss: 1.9029942251020862

Epoch: 6| Step: 9
Training loss: 2.116854429244995
Validation loss: 1.8700767024870841

Epoch: 6| Step: 10
Training loss: 1.74569833278656
Validation loss: 1.8187445594418434

Epoch: 6| Step: 11
Training loss: 1.4736260175704956
Validation loss: 1.8768564706207604

Epoch: 6| Step: 12
Training loss: 1.9738686084747314
Validation loss: 1.8817839686588576

Epoch: 6| Step: 13
Training loss: 1.0103617906570435
Validation loss: 1.8627466527364587

Epoch: 246| Step: 0
Training loss: 1.9103838205337524
Validation loss: 1.8586631872320687

Epoch: 6| Step: 1
Training loss: 1.5541908740997314
Validation loss: 1.8857700606828094

Epoch: 6| Step: 2
Training loss: 2.1346890926361084
Validation loss: 1.8317980971387637

Epoch: 6| Step: 3
Training loss: 1.4232177734375
Validation loss: 1.877607980082112

Epoch: 6| Step: 4
Training loss: 2.042513132095337
Validation loss: 1.872009910562987

Epoch: 6| Step: 5
Training loss: 1.4748446941375732
Validation loss: 1.8280499173748879

Epoch: 6| Step: 6
Training loss: 1.4171802997589111
Validation loss: 1.9123945646388556

Epoch: 6| Step: 7
Training loss: 1.7709459066390991
Validation loss: 1.8684346150326472

Epoch: 6| Step: 8
Training loss: 1.9003673791885376
Validation loss: 1.875495546607561

Epoch: 6| Step: 9
Training loss: 1.4305062294006348
Validation loss: 1.8974189578845937

Epoch: 6| Step: 10
Training loss: 1.8813352584838867
Validation loss: 1.8836992068957257

Epoch: 6| Step: 11
Training loss: 1.3850096464157104
Validation loss: 1.8900412500545543

Epoch: 6| Step: 12
Training loss: 1.6410033702850342
Validation loss: 1.910974471799789

Epoch: 6| Step: 13
Training loss: 1.9902629852294922
Validation loss: 1.927444197798288

Epoch: 247| Step: 0
Training loss: 2.2434844970703125
Validation loss: 1.8917499255108576

Epoch: 6| Step: 1
Training loss: 2.001354455947876
Validation loss: 1.9356833850183794

Epoch: 6| Step: 2
Training loss: 1.3994886875152588
Validation loss: 1.9471101235317927

Epoch: 6| Step: 3
Training loss: 1.6119983196258545
Validation loss: 1.9347934146081247

Epoch: 6| Step: 4
Training loss: 1.6284139156341553
Validation loss: 1.9088982792310818

Epoch: 6| Step: 5
Training loss: 1.1364246606826782
Validation loss: 1.8551094839649815

Epoch: 6| Step: 6
Training loss: 1.5591028928756714
Validation loss: 1.9275310500975578

Epoch: 6| Step: 7
Training loss: 1.7573236227035522
Validation loss: 1.9365135303107641

Epoch: 6| Step: 8
Training loss: 1.5655858516693115
Validation loss: 1.9242278407978755

Epoch: 6| Step: 9
Training loss: 1.541172742843628
Validation loss: 1.8911557043752363

Epoch: 6| Step: 10
Training loss: 1.7898292541503906
Validation loss: 1.8886004929901452

Epoch: 6| Step: 11
Training loss: 1.9752072095870972
Validation loss: 1.9066841781780284

Epoch: 6| Step: 12
Training loss: 1.7050964832305908
Validation loss: 1.874644269225418

Epoch: 6| Step: 13
Training loss: 2.2184109687805176
Validation loss: 1.8366496691139795

Epoch: 248| Step: 0
Training loss: 1.683124303817749
Validation loss: 1.8553069278758059

Epoch: 6| Step: 1
Training loss: 0.9931021928787231
Validation loss: 1.8863051373471496

Epoch: 6| Step: 2
Training loss: 1.979694128036499
Validation loss: 1.8487325150479552

Epoch: 6| Step: 3
Training loss: 1.6992881298065186
Validation loss: 1.8703318334394885

Epoch: 6| Step: 4
Training loss: 1.3813482522964478
Validation loss: 1.8763873884754796

Epoch: 6| Step: 5
Training loss: 2.0277581214904785
Validation loss: 1.8231397610838695

Epoch: 6| Step: 6
Training loss: 2.016118288040161
Validation loss: 1.9039939988044001

Epoch: 6| Step: 7
Training loss: 1.9245681762695312
Validation loss: 1.8875887816952122

Epoch: 6| Step: 8
Training loss: 2.0042412281036377
Validation loss: 1.9139288433136479

Epoch: 6| Step: 9
Training loss: 1.683843731880188
Validation loss: 1.850345133453287

Epoch: 6| Step: 10
Training loss: 1.8083233833312988
Validation loss: 1.9062598725800872

Epoch: 6| Step: 11
Training loss: 1.717152714729309
Validation loss: 1.9344004764351794

Epoch: 6| Step: 12
Training loss: 1.6015729904174805
Validation loss: 1.9475778366929741

Epoch: 6| Step: 13
Training loss: 0.9327881932258606
Validation loss: 1.9159919984879032

Epoch: 249| Step: 0
Training loss: 1.928236961364746
Validation loss: 1.8685861979761431

Epoch: 6| Step: 1
Training loss: 2.0140252113342285
Validation loss: 1.9679121804493729

Epoch: 6| Step: 2
Training loss: 1.5571465492248535
Validation loss: 1.858309571461011

Epoch: 6| Step: 3
Training loss: 1.5598381757736206
Validation loss: 1.9441587591683993

Epoch: 6| Step: 4
Training loss: 1.461960792541504
Validation loss: 1.9188542071209158

Epoch: 6| Step: 5
Training loss: 1.9582394361495972
Validation loss: 1.8951183442146546

Epoch: 6| Step: 6
Training loss: 1.37613844871521
Validation loss: 1.8963832650133359

Epoch: 6| Step: 7
Training loss: 1.7687257528305054
Validation loss: 1.9178929252009238

Epoch: 6| Step: 8
Training loss: 1.5621633529663086
Validation loss: 1.9120129308392924

Epoch: 6| Step: 9
Training loss: 1.5178742408752441
Validation loss: 1.9031670016627158

Epoch: 6| Step: 10
Training loss: 1.5050219297409058
Validation loss: 1.850956206680626

Epoch: 6| Step: 11
Training loss: 1.5837324857711792
Validation loss: 1.855500372507239

Epoch: 6| Step: 12
Training loss: 2.2390968799591064
Validation loss: 1.8750628476501794

Epoch: 6| Step: 13
Training loss: 2.258491039276123
Validation loss: 1.893405988652219

Epoch: 250| Step: 0
Training loss: 2.137524127960205
Validation loss: 1.8828939571175525

Epoch: 6| Step: 1
Training loss: 1.8985871076583862
Validation loss: 1.8719114001079271

Epoch: 6| Step: 2
Training loss: 2.492777109146118
Validation loss: 1.8285972020959342

Epoch: 6| Step: 3
Training loss: 1.5762170553207397
Validation loss: 1.8634125455733268

Epoch: 6| Step: 4
Training loss: 2.019108295440674
Validation loss: 1.9045615093682402

Epoch: 6| Step: 5
Training loss: 1.4406355619430542
Validation loss: 1.8696050797739336

Epoch: 6| Step: 6
Training loss: 1.1948925256729126
Validation loss: 1.8962247628037647

Epoch: 6| Step: 7
Training loss: 1.2582206726074219
Validation loss: 1.876439017634238

Epoch: 6| Step: 8
Training loss: 1.446721076965332
Validation loss: 1.9167696660564792

Epoch: 6| Step: 9
Training loss: 1.7103949785232544
Validation loss: 1.8999616920307119

Epoch: 6| Step: 10
Training loss: 2.008695125579834
Validation loss: 1.860438649372388

Epoch: 6| Step: 11
Training loss: 1.6964455842971802
Validation loss: 1.9003480685654508

Epoch: 6| Step: 12
Training loss: 1.607069492340088
Validation loss: 1.8552722700180546

Epoch: 6| Step: 13
Training loss: 1.3858847618103027
Validation loss: 1.9110055328697286

Epoch: 251| Step: 0
Training loss: 2.2731027603149414
Validation loss: 1.9260452062852922

Epoch: 6| Step: 1
Training loss: 1.8545703887939453
Validation loss: 1.8898107082613054

Epoch: 6| Step: 2
Training loss: 1.55534029006958
Validation loss: 1.8933708385754657

Epoch: 6| Step: 3
Training loss: 2.059701442718506
Validation loss: 1.89581629665949

Epoch: 6| Step: 4
Training loss: 1.391032099723816
Validation loss: 1.8436230433884488

Epoch: 6| Step: 5
Training loss: 1.3765246868133545
Validation loss: 1.8802165177560621

Epoch: 6| Step: 6
Training loss: 1.9595855474472046
Validation loss: 1.890115632805773

Epoch: 6| Step: 7
Training loss: 0.828931987285614
Validation loss: 1.8642859535832559

Epoch: 6| Step: 8
Training loss: 1.4713691473007202
Validation loss: 1.8704264676699074

Epoch: 6| Step: 9
Training loss: 1.4438276290893555
Validation loss: 1.9052506646802347

Epoch: 6| Step: 10
Training loss: 2.39030122756958
Validation loss: 1.87374908180647

Epoch: 6| Step: 11
Training loss: 1.609682321548462
Validation loss: 1.9178412088783838

Epoch: 6| Step: 12
Training loss: 1.9312422275543213
Validation loss: 1.9248540504004366

Epoch: 6| Step: 13
Training loss: 1.8751174211502075
Validation loss: 1.9172160779276202

Epoch: 252| Step: 0
Training loss: 1.3790768384933472
Validation loss: 1.909650856448758

Epoch: 6| Step: 1
Training loss: 2.0669617652893066
Validation loss: 1.9105247002775951

Epoch: 6| Step: 2
Training loss: 1.334413766860962
Validation loss: 1.8921967616645239

Epoch: 6| Step: 3
Training loss: 1.4456918239593506
Validation loss: 1.9575892251024964

Epoch: 6| Step: 4
Training loss: 1.5522129535675049
Validation loss: 1.830099045589406

Epoch: 6| Step: 5
Training loss: 1.9082932472229004
Validation loss: 1.8665537218893729

Epoch: 6| Step: 6
Training loss: 1.6718225479125977
Validation loss: 1.8913856603766

Epoch: 6| Step: 7
Training loss: 1.6169675588607788
Validation loss: 1.8698482308336484

Epoch: 6| Step: 8
Training loss: 1.4083154201507568
Validation loss: 1.8570723995085685

Epoch: 6| Step: 9
Training loss: 2.496764898300171
Validation loss: 1.8875948639326199

Epoch: 6| Step: 10
Training loss: 1.3841259479522705
Validation loss: 1.8840455624365038

Epoch: 6| Step: 11
Training loss: 1.8354768753051758
Validation loss: 1.8362850783973612

Epoch: 6| Step: 12
Training loss: 2.024968385696411
Validation loss: 1.832235941322901

Epoch: 6| Step: 13
Training loss: 1.849457025527954
Validation loss: 1.9157009919484456

Epoch: 253| Step: 0
Training loss: 2.004436492919922
Validation loss: 1.9050720532735188

Epoch: 6| Step: 1
Training loss: 1.0425820350646973
Validation loss: 1.87156674169725

Epoch: 6| Step: 2
Training loss: 1.6952584981918335
Validation loss: 1.8597603920967347

Epoch: 6| Step: 3
Training loss: 1.6949350833892822
Validation loss: 1.8265394677398026

Epoch: 6| Step: 4
Training loss: 2.007495641708374
Validation loss: 1.8939086006533714

Epoch: 6| Step: 5
Training loss: 1.4760346412658691
Validation loss: 1.829911635768029

Epoch: 6| Step: 6
Training loss: 1.243443250656128
Validation loss: 1.8726113701379428

Epoch: 6| Step: 7
Training loss: 2.528775215148926
Validation loss: 1.9164957987364901

Epoch: 6| Step: 8
Training loss: 1.2933976650238037
Validation loss: 1.890969478955833

Epoch: 6| Step: 9
Training loss: 2.052448272705078
Validation loss: 1.9051191140246648

Epoch: 6| Step: 10
Training loss: 1.6449517011642456
Validation loss: 1.8787811802279564

Epoch: 6| Step: 11
Training loss: 1.6756025552749634
Validation loss: 1.899645789977043

Epoch: 6| Step: 12
Training loss: 1.9385448694229126
Validation loss: 1.8384604274585683

Epoch: 6| Step: 13
Training loss: 1.4459067583084106
Validation loss: 1.9081815263276458

Epoch: 254| Step: 0
Training loss: 1.4814949035644531
Validation loss: 1.8563551082405993

Epoch: 6| Step: 1
Training loss: 1.4179670810699463
Validation loss: 1.8900034350733603

Epoch: 6| Step: 2
Training loss: 1.5787603855133057
Validation loss: 1.8634959126031527

Epoch: 6| Step: 3
Training loss: 2.138465642929077
Validation loss: 1.8979382309862363

Epoch: 6| Step: 4
Training loss: 1.7099967002868652
Validation loss: 1.8710781156375844

Epoch: 6| Step: 5
Training loss: 2.1815598011016846
Validation loss: 1.9065089866679201

Epoch: 6| Step: 6
Training loss: 1.3655798435211182
Validation loss: 1.878174215234736

Epoch: 6| Step: 7
Training loss: 1.594029426574707
Validation loss: 1.8650559225390035

Epoch: 6| Step: 8
Training loss: 1.9662986993789673
Validation loss: 1.8114270651212303

Epoch: 6| Step: 9
Training loss: 1.7905936241149902
Validation loss: 1.8812626933538785

Epoch: 6| Step: 10
Training loss: 0.9943943023681641
Validation loss: 1.872209277204288

Epoch: 6| Step: 11
Training loss: 1.5180062055587769
Validation loss: 1.8801618122285413

Epoch: 6| Step: 12
Training loss: 1.4561729431152344
Validation loss: 1.9036920711558352

Epoch: 6| Step: 13
Training loss: 2.800261974334717
Validation loss: 1.9098420835310412

Epoch: 255| Step: 0
Training loss: 1.3263039588928223
Validation loss: 1.9326774689459032

Epoch: 6| Step: 1
Training loss: 0.9964748024940491
Validation loss: 1.9728943583785847

Epoch: 6| Step: 2
Training loss: 2.0648348331451416
Validation loss: 1.9751561636565833

Epoch: 6| Step: 3
Training loss: 1.7419791221618652
Validation loss: 1.8650083182960429

Epoch: 6| Step: 4
Training loss: 1.9169195890426636
Validation loss: 1.8978395385126914

Epoch: 6| Step: 5
Training loss: 1.699323296546936
Validation loss: 1.9075704466912053

Epoch: 6| Step: 6
Training loss: 2.0176196098327637
Validation loss: 1.9438472229947326

Epoch: 6| Step: 7
Training loss: 1.6532176733016968
Validation loss: 1.9091250640089794

Epoch: 6| Step: 8
Training loss: 1.6503674983978271
Validation loss: 1.9451200449338524

Epoch: 6| Step: 9
Training loss: 1.832640528678894
Validation loss: 1.913260441954418

Epoch: 6| Step: 10
Training loss: 1.5046474933624268
Validation loss: 1.9226718346277873

Epoch: 6| Step: 11
Training loss: 1.454672932624817
Validation loss: 1.8670461895645305

Epoch: 6| Step: 12
Training loss: 2.089798927307129
Validation loss: 1.8904468192849109

Epoch: 6| Step: 13
Training loss: 1.5926966667175293
Validation loss: 1.8997461077987507

Epoch: 256| Step: 0
Training loss: 1.8638583421707153
Validation loss: 1.8701611193277503

Epoch: 6| Step: 1
Training loss: 1.7503635883331299
Validation loss: 1.8265999581224175

Epoch: 6| Step: 2
Training loss: 2.0212697982788086
Validation loss: 1.853666599078845

Epoch: 6| Step: 3
Training loss: 2.262639045715332
Validation loss: 1.8148164646599882

Epoch: 6| Step: 4
Training loss: 1.5003252029418945
Validation loss: 1.8446987367445422

Epoch: 6| Step: 5
Training loss: 0.974262535572052
Validation loss: 1.8522524884952012

Epoch: 6| Step: 6
Training loss: 2.0041110515594482
Validation loss: 1.9246112902959187

Epoch: 6| Step: 7
Training loss: 1.4753086566925049
Validation loss: 1.883988759850943

Epoch: 6| Step: 8
Training loss: 1.641546368598938
Validation loss: 1.9143942350982337

Epoch: 6| Step: 9
Training loss: 2.008617401123047
Validation loss: 1.8917230072841849

Epoch: 6| Step: 10
Training loss: 1.542952299118042
Validation loss: 1.8948185238786923

Epoch: 6| Step: 11
Training loss: 1.3629450798034668
Validation loss: 1.8837656641519198

Epoch: 6| Step: 12
Training loss: 1.6538197994232178
Validation loss: 1.9152261185389694

Epoch: 6| Step: 13
Training loss: 1.3628946542739868
Validation loss: 1.9347538666058612

Epoch: 257| Step: 0
Training loss: 2.428506374359131
Validation loss: 1.9254876247016333

Epoch: 6| Step: 1
Training loss: 2.0719470977783203
Validation loss: 1.8981986327837872

Epoch: 6| Step: 2
Training loss: 2.170750379562378
Validation loss: 1.9264829517692648

Epoch: 6| Step: 3
Training loss: 1.9309849739074707
Validation loss: 1.8839507782331077

Epoch: 6| Step: 4
Training loss: 0.9507084488868713
Validation loss: 1.91446901136829

Epoch: 6| Step: 5
Training loss: 1.2299063205718994
Validation loss: 1.8310189939314319

Epoch: 6| Step: 6
Training loss: 2.454871654510498
Validation loss: 1.9036984597482989

Epoch: 6| Step: 7
Training loss: 1.6859651803970337
Validation loss: 1.8929448717383928

Epoch: 6| Step: 8
Training loss: 1.2314311265945435
Validation loss: 1.8752135153739684

Epoch: 6| Step: 9
Training loss: 1.3458569049835205
Validation loss: 1.8751682171257593

Epoch: 6| Step: 10
Training loss: 1.477873682975769
Validation loss: 1.898505046803464

Epoch: 6| Step: 11
Training loss: 0.8685095310211182
Validation loss: 1.902693333164338

Epoch: 6| Step: 12
Training loss: 1.5987259149551392
Validation loss: 1.947236495633279

Epoch: 6| Step: 13
Training loss: 1.9769529104232788
Validation loss: 1.9545721238659275

Epoch: 258| Step: 0
Training loss: 1.4983386993408203
Validation loss: 1.8701674617746824

Epoch: 6| Step: 1
Training loss: 1.5230752229690552
Validation loss: 1.9133251738804642

Epoch: 6| Step: 2
Training loss: 1.9040484428405762
Validation loss: 1.9200935504769767

Epoch: 6| Step: 3
Training loss: 2.012917995452881
Validation loss: 1.8879137423730665

Epoch: 6| Step: 4
Training loss: 1.4287090301513672
Validation loss: 1.863587853729084

Epoch: 6| Step: 5
Training loss: 2.0965912342071533
Validation loss: 1.8688608600247292

Epoch: 6| Step: 6
Training loss: 1.2048779726028442
Validation loss: 1.8385443764348184

Epoch: 6| Step: 7
Training loss: 1.7798686027526855
Validation loss: 1.8762038446241809

Epoch: 6| Step: 8
Training loss: 1.58627188205719
Validation loss: 1.851010500743825

Epoch: 6| Step: 9
Training loss: 1.7825125455856323
Validation loss: 1.8652714606254333

Epoch: 6| Step: 10
Training loss: 1.863969326019287
Validation loss: 1.8964178831346574

Epoch: 6| Step: 11
Training loss: 2.413968563079834
Validation loss: 1.9051802773629465

Epoch: 6| Step: 12
Training loss: 1.332329273223877
Validation loss: 1.852812914438145

Epoch: 6| Step: 13
Training loss: 1.031671166419983
Validation loss: 1.8787484976553148

Epoch: 259| Step: 0
Training loss: 1.9427235126495361
Validation loss: 1.9193549066461542

Epoch: 6| Step: 1
Training loss: 1.9138154983520508
Validation loss: 1.8995460899927283

Epoch: 6| Step: 2
Training loss: 1.426382303237915
Validation loss: 1.9030701473195066

Epoch: 6| Step: 3
Training loss: 1.5473589897155762
Validation loss: 1.9045740968437606

Epoch: 6| Step: 4
Training loss: 1.4082555770874023
Validation loss: 1.8824003960496636

Epoch: 6| Step: 5
Training loss: 1.9411778450012207
Validation loss: 1.9258573516722648

Epoch: 6| Step: 6
Training loss: 1.4490165710449219
Validation loss: 1.8900603414863668

Epoch: 6| Step: 7
Training loss: 1.838552713394165
Validation loss: 1.9161818514588058

Epoch: 6| Step: 8
Training loss: 1.8629945516586304
Validation loss: 1.9428697965478385

Epoch: 6| Step: 9
Training loss: 2.112468719482422
Validation loss: 1.8746574796656126

Epoch: 6| Step: 10
Training loss: 1.881791353225708
Validation loss: 1.8831831152721117

Epoch: 6| Step: 11
Training loss: 1.6510423421859741
Validation loss: 1.873740396191997

Epoch: 6| Step: 12
Training loss: 1.2616446018218994
Validation loss: 1.8961792325460782

Epoch: 6| Step: 13
Training loss: 0.8673502206802368
Validation loss: 1.8974621039564892

Epoch: 260| Step: 0
Training loss: 1.108883261680603
Validation loss: 1.9206931873034405

Epoch: 6| Step: 1
Training loss: 1.7664217948913574
Validation loss: 1.8867154429035802

Epoch: 6| Step: 2
Training loss: 1.9032702445983887
Validation loss: 1.9317382638172438

Epoch: 6| Step: 3
Training loss: 1.5056151151657104
Validation loss: 1.9089869901698122

Epoch: 6| Step: 4
Training loss: 1.8029323816299438
Validation loss: 1.9445713412377141

Epoch: 6| Step: 5
Training loss: 2.127619743347168
Validation loss: 1.8536823462414485

Epoch: 6| Step: 6
Training loss: 1.5004706382751465
Validation loss: 1.9251194871881956

Epoch: 6| Step: 7
Training loss: 1.7039844989776611
Validation loss: 1.8782691571020311

Epoch: 6| Step: 8
Training loss: 1.2449398040771484
Validation loss: 1.930472356016918

Epoch: 6| Step: 9
Training loss: 1.5036381483078003
Validation loss: 1.8815448348240187

Epoch: 6| Step: 10
Training loss: 1.5686488151550293
Validation loss: 1.9074229630090858

Epoch: 6| Step: 11
Training loss: 1.3239047527313232
Validation loss: 1.8388382337426628

Epoch: 6| Step: 12
Training loss: 2.0192177295684814
Validation loss: 1.9129515001850743

Epoch: 6| Step: 13
Training loss: 2.4670796394348145
Validation loss: 1.8601053248169601

Epoch: 261| Step: 0
Training loss: 1.7711966037750244
Validation loss: 1.909367818986216

Epoch: 6| Step: 1
Training loss: 2.1177096366882324
Validation loss: 1.9291098540829075

Epoch: 6| Step: 2
Training loss: 1.4742431640625
Validation loss: 1.8541060596384027

Epoch: 6| Step: 3
Training loss: 1.5991621017456055
Validation loss: 1.9146646402215446

Epoch: 6| Step: 4
Training loss: 1.7504327297210693
Validation loss: 1.9315608701398295

Epoch: 6| Step: 5
Training loss: 1.335963249206543
Validation loss: 1.920299494138328

Epoch: 6| Step: 6
Training loss: 1.9808061122894287
Validation loss: 1.953536941159156

Epoch: 6| Step: 7
Training loss: 1.401021957397461
Validation loss: 1.865692255317524

Epoch: 6| Step: 8
Training loss: 1.3464020490646362
Validation loss: 1.864113547468698

Epoch: 6| Step: 9
Training loss: 1.375636339187622
Validation loss: 1.9246908669830651

Epoch: 6| Step: 10
Training loss: 1.477454423904419
Validation loss: 1.921257093388547

Epoch: 6| Step: 11
Training loss: 1.7606436014175415
Validation loss: 1.9078466917878838

Epoch: 6| Step: 12
Training loss: 2.33915376663208
Validation loss: 1.9001074721736293

Epoch: 6| Step: 13
Training loss: 1.781746745109558
Validation loss: 1.9013038219944123

Epoch: 262| Step: 0
Training loss: 1.7963316440582275
Validation loss: 1.8919654892336937

Epoch: 6| Step: 1
Training loss: 1.067903757095337
Validation loss: 1.8945654617842806

Epoch: 6| Step: 2
Training loss: 1.7471613883972168
Validation loss: 1.9187274389369513

Epoch: 6| Step: 3
Training loss: 1.0013097524642944
Validation loss: 1.9034665258981849

Epoch: 6| Step: 4
Training loss: 1.7007790803909302
Validation loss: 1.88143112069817

Epoch: 6| Step: 5
Training loss: 2.0521676540374756
Validation loss: 1.8752107645875664

Epoch: 6| Step: 6
Training loss: 1.5530674457550049
Validation loss: 1.855646724342018

Epoch: 6| Step: 7
Training loss: 2.020663261413574
Validation loss: 1.8958840293269004

Epoch: 6| Step: 8
Training loss: 1.601241946220398
Validation loss: 1.874499685020857

Epoch: 6| Step: 9
Training loss: 1.5520495176315308
Validation loss: 1.9104340012355516

Epoch: 6| Step: 10
Training loss: 2.080124855041504
Validation loss: 1.8701871428438412

Epoch: 6| Step: 11
Training loss: 1.6405200958251953
Validation loss: 1.8898704333971905

Epoch: 6| Step: 12
Training loss: 1.7134006023406982
Validation loss: 1.8645769896045807

Epoch: 6| Step: 13
Training loss: 1.899659514427185
Validation loss: 1.91025209939608

Epoch: 263| Step: 0
Training loss: 1.9876391887664795
Validation loss: 1.882607675367786

Epoch: 6| Step: 1
Training loss: 2.1525936126708984
Validation loss: 1.8745236806972052

Epoch: 6| Step: 2
Training loss: 1.6964555978775024
Validation loss: 1.8657662099407566

Epoch: 6| Step: 3
Training loss: 1.7836254835128784
Validation loss: 1.8872168602481965

Epoch: 6| Step: 4
Training loss: 1.8322339057922363
Validation loss: 1.9082393364239765

Epoch: 6| Step: 5
Training loss: 1.8464771509170532
Validation loss: 1.8839569745525238

Epoch: 6| Step: 6
Training loss: 1.6981773376464844
Validation loss: 1.8982718811240247

Epoch: 6| Step: 7
Training loss: 1.5764870643615723
Validation loss: 1.9560656342455136

Epoch: 6| Step: 8
Training loss: 1.3280774354934692
Validation loss: 1.8999514195226854

Epoch: 6| Step: 9
Training loss: 1.8540830612182617
Validation loss: 1.9137613811800558

Epoch: 6| Step: 10
Training loss: 1.709530234336853
Validation loss: 1.8682912575301303

Epoch: 6| Step: 11
Training loss: 1.3717436790466309
Validation loss: 1.9144370812241749

Epoch: 6| Step: 12
Training loss: 1.214560627937317
Validation loss: 1.904283909387486

Epoch: 6| Step: 13
Training loss: 1.291759967803955
Validation loss: 1.9758885163132862

Epoch: 264| Step: 0
Training loss: 1.4744209051132202
Validation loss: 1.936413755980871

Epoch: 6| Step: 1
Training loss: 1.673856496810913
Validation loss: 1.8830476576282131

Epoch: 6| Step: 2
Training loss: 1.452748417854309
Validation loss: 1.9127746884540846

Epoch: 6| Step: 3
Training loss: 1.420924186706543
Validation loss: 1.8711848079517324

Epoch: 6| Step: 4
Training loss: 1.3456556797027588
Validation loss: 1.9032852188233407

Epoch: 6| Step: 5
Training loss: 1.4187839031219482
Validation loss: 1.8372643763019192

Epoch: 6| Step: 6
Training loss: 1.5512892007827759
Validation loss: 1.8988796664822487

Epoch: 6| Step: 7
Training loss: 1.4688764810562134
Validation loss: 1.8398972941983132

Epoch: 6| Step: 8
Training loss: 1.5059807300567627
Validation loss: 1.9409357604160105

Epoch: 6| Step: 9
Training loss: 1.4195584058761597
Validation loss: 1.8628723236822313

Epoch: 6| Step: 10
Training loss: 2.575380325317383
Validation loss: 1.838102948281073

Epoch: 6| Step: 11
Training loss: 1.7446227073669434
Validation loss: 1.8983537048421881

Epoch: 6| Step: 12
Training loss: 1.9469550848007202
Validation loss: 1.8622645178148824

Epoch: 6| Step: 13
Training loss: 2.2424657344818115
Validation loss: 1.8532482731726863

Epoch: 265| Step: 0
Training loss: 1.3863500356674194
Validation loss: 1.8964300514549337

Epoch: 6| Step: 1
Training loss: 1.8468263149261475
Validation loss: 1.8759272034450243

Epoch: 6| Step: 2
Training loss: 1.567579746246338
Validation loss: 1.8756189987223635

Epoch: 6| Step: 3
Training loss: 1.7278226613998413
Validation loss: 1.9266102544723018

Epoch: 6| Step: 4
Training loss: 2.0943846702575684
Validation loss: 1.8813744360400784

Epoch: 6| Step: 5
Training loss: 1.4434072971343994
Validation loss: 1.923426423021542

Epoch: 6| Step: 6
Training loss: 1.8747963905334473
Validation loss: 1.9174876956529514

Epoch: 6| Step: 7
Training loss: 1.8884979486465454
Validation loss: 1.9228630629918908

Epoch: 6| Step: 8
Training loss: 1.6094005107879639
Validation loss: 1.923180962121615

Epoch: 6| Step: 9
Training loss: 1.3487955331802368
Validation loss: 1.8657896839162356

Epoch: 6| Step: 10
Training loss: 1.5602208375930786
Validation loss: 1.8679716484521025

Epoch: 6| Step: 11
Training loss: 1.7391623258590698
Validation loss: 1.897760724508634

Epoch: 6| Step: 12
Training loss: 1.668536901473999
Validation loss: 1.8862533787245392

Epoch: 6| Step: 13
Training loss: 0.7878459692001343
Validation loss: 1.846955516005075

Epoch: 266| Step: 0
Training loss: 1.6849960088729858
Validation loss: 1.89400730850876

Epoch: 6| Step: 1
Training loss: 1.563156247138977
Validation loss: 1.931040556200089

Epoch: 6| Step: 2
Training loss: 1.7063713073730469
Validation loss: 1.8644732159952964

Epoch: 6| Step: 3
Training loss: 1.6513516902923584
Validation loss: 1.8726463253780077

Epoch: 6| Step: 4
Training loss: 1.7421859502792358
Validation loss: 1.9023327314725487

Epoch: 6| Step: 5
Training loss: 1.546748161315918
Validation loss: 1.9100163739214662

Epoch: 6| Step: 6
Training loss: 1.5986096858978271
Validation loss: 1.940879903813844

Epoch: 6| Step: 7
Training loss: 2.1367244720458984
Validation loss: 1.8859693978422432

Epoch: 6| Step: 8
Training loss: 1.0749249458312988
Validation loss: 1.84907502512778

Epoch: 6| Step: 9
Training loss: 1.3930118083953857
Validation loss: 1.884720790770746

Epoch: 6| Step: 10
Training loss: 1.9266717433929443
Validation loss: 1.870400777427099

Epoch: 6| Step: 11
Training loss: 2.0561318397521973
Validation loss: 1.8926147312246344

Epoch: 6| Step: 12
Training loss: 1.3489563465118408
Validation loss: 1.9103874339852283

Epoch: 6| Step: 13
Training loss: 1.7127104997634888
Validation loss: 1.879028812531502

Epoch: 267| Step: 0
Training loss: 1.9441050291061401
Validation loss: 1.8856968290062361

Epoch: 6| Step: 1
Training loss: 1.427294373512268
Validation loss: 1.9317704426345004

Epoch: 6| Step: 2
Training loss: 1.6287412643432617
Validation loss: 1.923569651060207

Epoch: 6| Step: 3
Training loss: 1.734273910522461
Validation loss: 1.9084707447277602

Epoch: 6| Step: 4
Training loss: 1.3143103122711182
Validation loss: 1.9063334208662792

Epoch: 6| Step: 5
Training loss: 1.2195239067077637
Validation loss: 1.9156736148300992

Epoch: 6| Step: 6
Training loss: 1.5537205934524536
Validation loss: 1.9635575279112785

Epoch: 6| Step: 7
Training loss: 1.3372409343719482
Validation loss: 1.863415684751285

Epoch: 6| Step: 8
Training loss: 1.5943162441253662
Validation loss: 1.8893560183945524

Epoch: 6| Step: 9
Training loss: 1.9230718612670898
Validation loss: 1.8885691101833055

Epoch: 6| Step: 10
Training loss: 1.8638536930084229
Validation loss: 1.86699979535995

Epoch: 6| Step: 11
Training loss: 1.9783542156219482
Validation loss: 1.8753350998765679

Epoch: 6| Step: 12
Training loss: 1.8615763187408447
Validation loss: 1.8513076074661747

Epoch: 6| Step: 13
Training loss: 2.8805129528045654
Validation loss: 1.8676539108317385

Epoch: 268| Step: 0
Training loss: 2.3151488304138184
Validation loss: 1.9411078499209495

Epoch: 6| Step: 1
Training loss: 1.2937997579574585
Validation loss: 1.8709230986974572

Epoch: 6| Step: 2
Training loss: 1.4279508590698242
Validation loss: 1.8861699283763926

Epoch: 6| Step: 3
Training loss: 1.153038740158081
Validation loss: 1.8747584037883307

Epoch: 6| Step: 4
Training loss: 1.980016827583313
Validation loss: 1.902750781787339

Epoch: 6| Step: 5
Training loss: 1.4160349369049072
Validation loss: 1.9054690881441998

Epoch: 6| Step: 6
Training loss: 1.8163402080535889
Validation loss: 1.9173666995058778

Epoch: 6| Step: 7
Training loss: 1.4862197637557983
Validation loss: 1.8885067419339252

Epoch: 6| Step: 8
Training loss: 1.7328431606292725
Validation loss: 1.9246944714617986

Epoch: 6| Step: 9
Training loss: 1.562159776687622
Validation loss: 1.928918884646508

Epoch: 6| Step: 10
Training loss: 1.3343372344970703
Validation loss: 1.8839199748090518

Epoch: 6| Step: 11
Training loss: 1.6746727228164673
Validation loss: 1.8802135464965657

Epoch: 6| Step: 12
Training loss: 1.6188099384307861
Validation loss: 1.8651102057067297

Epoch: 6| Step: 13
Training loss: 2.326201915740967
Validation loss: 1.8829173913566015

Epoch: 269| Step: 0
Training loss: 1.83113431930542
Validation loss: 1.8794346804259925

Epoch: 6| Step: 1
Training loss: 1.8165931701660156
Validation loss: 1.8932633746054865

Epoch: 6| Step: 2
Training loss: 1.4228616952896118
Validation loss: 1.907806710530353

Epoch: 6| Step: 3
Training loss: 1.7364575862884521
Validation loss: 1.9130569837426628

Epoch: 6| Step: 4
Training loss: 1.369126796722412
Validation loss: 1.85911903970985

Epoch: 6| Step: 5
Training loss: 1.4829031229019165
Validation loss: 1.9389560196989326

Epoch: 6| Step: 6
Training loss: 1.587552785873413
Validation loss: 1.9071730080471243

Epoch: 6| Step: 7
Training loss: 1.5125967264175415
Validation loss: 1.8988398967250701

Epoch: 6| Step: 8
Training loss: 1.96138334274292
Validation loss: 1.8699700806730537

Epoch: 6| Step: 9
Training loss: 1.4977388381958008
Validation loss: 1.8886779328828216

Epoch: 6| Step: 10
Training loss: 1.6198316812515259
Validation loss: 1.9399082199219735

Epoch: 6| Step: 11
Training loss: 1.7451623678207397
Validation loss: 1.9150968418326428

Epoch: 6| Step: 12
Training loss: 1.5239827632904053
Validation loss: 1.9090482163172897

Epoch: 6| Step: 13
Training loss: 2.2937750816345215
Validation loss: 1.902921526662765

Epoch: 270| Step: 0
Training loss: 1.2873456478118896
Validation loss: 1.9199235362391318

Epoch: 6| Step: 1
Training loss: 1.891907811164856
Validation loss: 1.9012969540011497

Epoch: 6| Step: 2
Training loss: 1.536863088607788
Validation loss: 1.9324004432206512

Epoch: 6| Step: 3
Training loss: 2.0264651775360107
Validation loss: 1.9235699612607238

Epoch: 6| Step: 4
Training loss: 1.7949223518371582
Validation loss: 1.908377403854042

Epoch: 6| Step: 5
Training loss: 1.5806820392608643
Validation loss: 1.918993870417277

Epoch: 6| Step: 6
Training loss: 1.0988185405731201
Validation loss: 1.8973741659554102

Epoch: 6| Step: 7
Training loss: 1.5493170022964478
Validation loss: 1.9561307404630928

Epoch: 6| Step: 8
Training loss: 1.9035348892211914
Validation loss: 1.9225909043383855

Epoch: 6| Step: 9
Training loss: 1.2200002670288086
Validation loss: 1.8745786195160241

Epoch: 6| Step: 10
Training loss: 1.9625142812728882
Validation loss: 1.870591014944097

Epoch: 6| Step: 11
Training loss: 2.0571916103363037
Validation loss: 1.9219775815163889

Epoch: 6| Step: 12
Training loss: 1.612100601196289
Validation loss: 1.911662704201155

Epoch: 6| Step: 13
Training loss: 1.6363215446472168
Validation loss: 1.8892255752317366

Epoch: 271| Step: 0
Training loss: 1.9105854034423828
Validation loss: 1.9186758033690914

Epoch: 6| Step: 1
Training loss: 1.283913254737854
Validation loss: 1.9167259636745657

Epoch: 6| Step: 2
Training loss: 1.3221888542175293
Validation loss: 1.8576435183966031

Epoch: 6| Step: 3
Training loss: 1.2809054851531982
Validation loss: 1.9194531312552832

Epoch: 6| Step: 4
Training loss: 1.3995778560638428
Validation loss: 1.9204525127205798

Epoch: 6| Step: 5
Training loss: 1.6119182109832764
Validation loss: 1.9079720794513662

Epoch: 6| Step: 6
Training loss: 1.6987504959106445
Validation loss: 1.9076409852632912

Epoch: 6| Step: 7
Training loss: 2.1810388565063477
Validation loss: 1.8929372269620177

Epoch: 6| Step: 8
Training loss: 1.6525914669036865
Validation loss: 1.9098465417021064

Epoch: 6| Step: 9
Training loss: 2.0575215816497803
Validation loss: 1.8883714778448946

Epoch: 6| Step: 10
Training loss: 1.4616611003875732
Validation loss: 1.8938368058973742

Epoch: 6| Step: 11
Training loss: 1.6076397895812988
Validation loss: 1.9019439053791825

Epoch: 6| Step: 12
Training loss: 1.4356541633605957
Validation loss: 1.891919876939507

Epoch: 6| Step: 13
Training loss: 2.0171234607696533
Validation loss: 1.8609298416363296

Epoch: 272| Step: 0
Training loss: 1.9953198432922363
Validation loss: 1.8935837540575253

Epoch: 6| Step: 1
Training loss: 1.1097607612609863
Validation loss: 1.8453515627050912

Epoch: 6| Step: 2
Training loss: 1.5608983039855957
Validation loss: 1.8607892054383472

Epoch: 6| Step: 3
Training loss: 1.2721853256225586
Validation loss: 1.8673205529489825

Epoch: 6| Step: 4
Training loss: 1.6735550165176392
Validation loss: 1.8822105584606048

Epoch: 6| Step: 5
Training loss: 1.6678745746612549
Validation loss: 1.900391286419284

Epoch: 6| Step: 6
Training loss: 1.8738245964050293
Validation loss: 1.8680334796187699

Epoch: 6| Step: 7
Training loss: 1.7713652849197388
Validation loss: 1.895402144360286

Epoch: 6| Step: 8
Training loss: 2.3669867515563965
Validation loss: 1.8994477038742394

Epoch: 6| Step: 9
Training loss: 0.9283084869384766
Validation loss: 1.9332407200208275

Epoch: 6| Step: 10
Training loss: 1.4877793788909912
Validation loss: 1.9116989886888893

Epoch: 6| Step: 11
Training loss: 1.9698208570480347
Validation loss: 1.9209257274545648

Epoch: 6| Step: 12
Training loss: 1.2768898010253906
Validation loss: 1.8986526163675452

Epoch: 6| Step: 13
Training loss: 2.3191473484039307
Validation loss: 1.8956136267672303

Epoch: 273| Step: 0
Training loss: 1.6379852294921875
Validation loss: 1.8472513870526386

Epoch: 6| Step: 1
Training loss: 1.3223731517791748
Validation loss: 1.9509976064005206

Epoch: 6| Step: 2
Training loss: 1.6951950788497925
Validation loss: 1.923143873932541

Epoch: 6| Step: 3
Training loss: 2.0779459476470947
Validation loss: 1.9056558506463164

Epoch: 6| Step: 4
Training loss: 1.6225311756134033
Validation loss: 1.8740604833890033

Epoch: 6| Step: 5
Training loss: 1.5794451236724854
Validation loss: 1.8876478684845792

Epoch: 6| Step: 6
Training loss: 2.0502922534942627
Validation loss: 1.9424963279436993

Epoch: 6| Step: 7
Training loss: 1.6298699378967285
Validation loss: 1.8776588927033127

Epoch: 6| Step: 8
Training loss: 1.7582429647445679
Validation loss: 1.8501639904514435

Epoch: 6| Step: 9
Training loss: 1.2246462106704712
Validation loss: 1.9059795743675643

Epoch: 6| Step: 10
Training loss: 1.6674777269363403
Validation loss: 1.9097709963398595

Epoch: 6| Step: 11
Training loss: 1.7721903324127197
Validation loss: 1.8972347026230187

Epoch: 6| Step: 12
Training loss: 1.400334119796753
Validation loss: 1.8823047760994203

Epoch: 6| Step: 13
Training loss: 1.9331024885177612
Validation loss: 1.8431392228731545

Epoch: 274| Step: 0
Training loss: 1.828458547592163
Validation loss: 1.9092025090289373

Epoch: 6| Step: 1
Training loss: 1.446488857269287
Validation loss: 1.9147470971589446

Epoch: 6| Step: 2
Training loss: 1.5283342599868774
Validation loss: 1.9229294766661942

Epoch: 6| Step: 3
Training loss: 1.8360462188720703
Validation loss: 1.8403892042816326

Epoch: 6| Step: 4
Training loss: 1.085924506187439
Validation loss: 1.863685679692094

Epoch: 6| Step: 5
Training loss: 1.6557995080947876
Validation loss: 1.917523536630856

Epoch: 6| Step: 6
Training loss: 1.8955975770950317
Validation loss: 1.9024735996800084

Epoch: 6| Step: 7
Training loss: 1.5154439210891724
Validation loss: 1.8758561188174832

Epoch: 6| Step: 8
Training loss: 1.4005593061447144
Validation loss: 1.8832523335692704

Epoch: 6| Step: 9
Training loss: 1.694091796875
Validation loss: 1.9084307250156198

Epoch: 6| Step: 10
Training loss: 2.33315372467041
Validation loss: 1.8344405363964778

Epoch: 6| Step: 11
Training loss: 1.439436912536621
Validation loss: 1.9081820313648512

Epoch: 6| Step: 12
Training loss: 1.817554235458374
Validation loss: 1.861992725761988

Epoch: 6| Step: 13
Training loss: 2.684467077255249
Validation loss: 1.846761280490506

Epoch: 275| Step: 0
Training loss: 2.0879359245300293
Validation loss: 1.899148948730961

Epoch: 6| Step: 1
Training loss: 1.1459729671478271
Validation loss: 1.860492862680907

Epoch: 6| Step: 2
Training loss: 1.6942917108535767
Validation loss: 1.9381042680432718

Epoch: 6| Step: 3
Training loss: 1.5839208364486694
Validation loss: 1.9265177570363528

Epoch: 6| Step: 4
Training loss: 1.8220267295837402
Validation loss: 1.902154900694406

Epoch: 6| Step: 5
Training loss: 2.5090482234954834
Validation loss: 1.9237257011475102

Epoch: 6| Step: 6
Training loss: 0.6977859139442444
Validation loss: 1.9380864045953239

Epoch: 6| Step: 7
Training loss: 1.382488489151001
Validation loss: 1.9446007615776473

Epoch: 6| Step: 8
Training loss: 1.357416033744812
Validation loss: 1.9137936817702426

Epoch: 6| Step: 9
Training loss: 1.308469533920288
Validation loss: 1.934605388231175

Epoch: 6| Step: 10
Training loss: 1.4866479635238647
Validation loss: 1.8585052656871017

Epoch: 6| Step: 11
Training loss: 1.9932284355163574
Validation loss: 1.925753967736357

Epoch: 6| Step: 12
Training loss: 1.8951475620269775
Validation loss: 1.89856977616587

Epoch: 6| Step: 13
Training loss: 1.6249866485595703
Validation loss: 1.8701750873237528

Epoch: 276| Step: 0
Training loss: 1.4840550422668457
Validation loss: 1.9001048662329232

Epoch: 6| Step: 1
Training loss: 1.4072110652923584
Validation loss: 1.8789968541873399

Epoch: 6| Step: 2
Training loss: 1.2820942401885986
Validation loss: 1.8982344250525198

Epoch: 6| Step: 3
Training loss: 1.5762097835540771
Validation loss: 1.8250359078889251

Epoch: 6| Step: 4
Training loss: 2.024496555328369
Validation loss: 1.9082744788098078

Epoch: 6| Step: 5
Training loss: 1.7684293985366821
Validation loss: 1.82792329788208

Epoch: 6| Step: 6
Training loss: 1.9145554304122925
Validation loss: 1.8973901951184837

Epoch: 6| Step: 7
Training loss: 1.7666425704956055
Validation loss: 1.8679227687979256

Epoch: 6| Step: 8
Training loss: 1.112036108970642
Validation loss: 1.866872969494071

Epoch: 6| Step: 9
Training loss: 1.6711580753326416
Validation loss: 1.9664775145951139

Epoch: 6| Step: 10
Training loss: 1.4577529430389404
Validation loss: 1.8930855066545549

Epoch: 6| Step: 11
Training loss: 2.1109960079193115
Validation loss: 1.8816802373496435

Epoch: 6| Step: 12
Training loss: 1.5787503719329834
Validation loss: 1.8767465083829817

Epoch: 6| Step: 13
Training loss: 2.528730630874634
Validation loss: 1.867121172207658

Epoch: 277| Step: 0
Training loss: 1.3660788536071777
Validation loss: 1.938283033268426

Epoch: 6| Step: 1
Training loss: 1.9427120685577393
Validation loss: 1.9036834457869172

Epoch: 6| Step: 2
Training loss: 2.0261759757995605
Validation loss: 1.978244540511921

Epoch: 6| Step: 3
Training loss: 0.9541345834732056
Validation loss: 1.9207979235597836

Epoch: 6| Step: 4
Training loss: 1.3939576148986816
Validation loss: 1.922829548517863

Epoch: 6| Step: 5
Training loss: 2.0248374938964844
Validation loss: 1.905987035843634

Epoch: 6| Step: 6
Training loss: 1.5538287162780762
Validation loss: 1.9372083051230318

Epoch: 6| Step: 7
Training loss: 1.1598519086837769
Validation loss: 1.9061689248649023

Epoch: 6| Step: 8
Training loss: 1.9050170183181763
Validation loss: 1.8935651535628943

Epoch: 6| Step: 9
Training loss: 1.6824533939361572
Validation loss: 1.931144420818616

Epoch: 6| Step: 10
Training loss: 1.833191156387329
Validation loss: 1.8484254780636038

Epoch: 6| Step: 11
Training loss: 1.91691255569458
Validation loss: 1.8914334184379988

Epoch: 6| Step: 12
Training loss: 1.7228586673736572
Validation loss: 1.8437419411956624

Epoch: 6| Step: 13
Training loss: 2.0573301315307617
Validation loss: 1.922850852371544

Epoch: 278| Step: 0
Training loss: 1.8253766298294067
Validation loss: 1.9299013473654305

Epoch: 6| Step: 1
Training loss: 2.0869851112365723
Validation loss: 1.909394287293957

Epoch: 6| Step: 2
Training loss: 1.4080777168273926
Validation loss: 1.8371251680517708

Epoch: 6| Step: 3
Training loss: 1.4023053646087646
Validation loss: 1.8904571020474998

Epoch: 6| Step: 4
Training loss: 2.0732250213623047
Validation loss: 1.889128218414963

Epoch: 6| Step: 5
Training loss: 2.0949859619140625
Validation loss: 1.9558750583279518

Epoch: 6| Step: 6
Training loss: 1.7206530570983887
Validation loss: 1.8474560617118754

Epoch: 6| Step: 7
Training loss: 1.5648058652877808
Validation loss: 1.9087614718303885

Epoch: 6| Step: 8
Training loss: 1.2535464763641357
Validation loss: 1.9067516762723205

Epoch: 6| Step: 9
Training loss: 1.4775002002716064
Validation loss: 1.9054762919743855

Epoch: 6| Step: 10
Training loss: 1.3991607427597046
Validation loss: 1.8873613431889524

Epoch: 6| Step: 11
Training loss: 1.3558013439178467
Validation loss: 1.9409959405981085

Epoch: 6| Step: 12
Training loss: 1.5882127285003662
Validation loss: 1.8903746502373808

Epoch: 6| Step: 13
Training loss: 2.033189058303833
Validation loss: 1.8690210709007837

Epoch: 279| Step: 0
Training loss: 1.7836554050445557
Validation loss: 1.889646162268936

Epoch: 6| Step: 1
Training loss: 1.3068442344665527
Validation loss: 1.856881223699098

Epoch: 6| Step: 2
Training loss: 1.7770097255706787
Validation loss: 1.907702922821045

Epoch: 6| Step: 3
Training loss: 1.5796632766723633
Validation loss: 1.9284547977550055

Epoch: 6| Step: 4
Training loss: 1.5276254415512085
Validation loss: 1.9112229347229004

Epoch: 6| Step: 5
Training loss: 1.614019513130188
Validation loss: 1.9463917927075458

Epoch: 6| Step: 6
Training loss: 1.0597047805786133
Validation loss: 1.9187463739866852

Epoch: 6| Step: 7
Training loss: 2.3885498046875
Validation loss: 1.8932245905681322

Epoch: 6| Step: 8
Training loss: 1.8237967491149902
Validation loss: 1.8884740311612365

Epoch: 6| Step: 9
Training loss: 1.446526050567627
Validation loss: 1.9171507896915558

Epoch: 6| Step: 10
Training loss: 1.63760244846344
Validation loss: 1.8849406037279355

Epoch: 6| Step: 11
Training loss: 1.8744511604309082
Validation loss: 1.9419633329555552

Epoch: 6| Step: 12
Training loss: 0.9249262809753418
Validation loss: 1.8499132125608382

Epoch: 6| Step: 13
Training loss: 2.2090649604797363
Validation loss: 1.852030784853043

Epoch: 280| Step: 0
Training loss: 1.5521278381347656
Validation loss: 1.9245095534991192

Epoch: 6| Step: 1
Training loss: 1.54534113407135
Validation loss: 1.9028092097210627

Epoch: 6| Step: 2
Training loss: 2.687858819961548
Validation loss: 1.8881265437731178

Epoch: 6| Step: 3
Training loss: 1.7593724727630615
Validation loss: 1.9175150573894542

Epoch: 6| Step: 4
Training loss: 0.6818280220031738
Validation loss: 1.8865526055776944

Epoch: 6| Step: 5
Training loss: 1.513010025024414
Validation loss: 1.8704879591541905

Epoch: 6| Step: 6
Training loss: 1.7416653633117676
Validation loss: 1.9233843485514324

Epoch: 6| Step: 7
Training loss: 2.448298215866089
Validation loss: 1.8337583567506524

Epoch: 6| Step: 8
Training loss: 1.5909541845321655
Validation loss: 1.9037317806674587

Epoch: 6| Step: 9
Training loss: 1.0294816493988037
Validation loss: 1.9262116698808567

Epoch: 6| Step: 10
Training loss: 1.104949951171875
Validation loss: 1.934613145807738

Epoch: 6| Step: 11
Training loss: 1.6856212615966797
Validation loss: 1.8678086009076846

Epoch: 6| Step: 12
Training loss: 1.5843548774719238
Validation loss: 1.9330145748712684

Epoch: 6| Step: 13
Training loss: 2.0688183307647705
Validation loss: 1.8760141326535134

Epoch: 281| Step: 0
Training loss: 1.625150442123413
Validation loss: 1.9133896020150953

Epoch: 6| Step: 1
Training loss: 1.698899745941162
Validation loss: 1.931765051298244

Epoch: 6| Step: 2
Training loss: 1.5781546831130981
Validation loss: 1.9064109953500892

Epoch: 6| Step: 3
Training loss: 1.439469337463379
Validation loss: 1.8707418377681444

Epoch: 6| Step: 4
Training loss: 1.3568978309631348
Validation loss: 1.9013187411010906

Epoch: 6| Step: 5
Training loss: 1.6801445484161377
Validation loss: 1.9032333358641593

Epoch: 6| Step: 6
Training loss: 1.9517090320587158
Validation loss: 1.8910064645992812

Epoch: 6| Step: 7
Training loss: 1.464721918106079
Validation loss: 1.8597801628933157

Epoch: 6| Step: 8
Training loss: 1.5606085062026978
Validation loss: 1.9081136462508992

Epoch: 6| Step: 9
Training loss: 1.2170772552490234
Validation loss: 1.905987347325971

Epoch: 6| Step: 10
Training loss: 1.6092907190322876
Validation loss: 1.83004960449793

Epoch: 6| Step: 11
Training loss: 2.352614402770996
Validation loss: 1.9250745747679023

Epoch: 6| Step: 12
Training loss: 1.6044464111328125
Validation loss: 1.9173281320961573

Epoch: 6| Step: 13
Training loss: 1.2213072776794434
Validation loss: 1.9021939180230583

Epoch: 282| Step: 0
Training loss: 1.521976351737976
Validation loss: 1.897429294483636

Epoch: 6| Step: 1
Training loss: 1.3438018560409546
Validation loss: 1.9155201655562206

Epoch: 6| Step: 2
Training loss: 1.0067572593688965
Validation loss: 1.9221404393513997

Epoch: 6| Step: 3
Training loss: 1.5715440511703491
Validation loss: 1.8899655957375803

Epoch: 6| Step: 4
Training loss: 1.7266783714294434
Validation loss: 1.9445769427925028

Epoch: 6| Step: 5
Training loss: 1.310105562210083
Validation loss: 1.9013299788198164

Epoch: 6| Step: 6
Training loss: 2.060173749923706
Validation loss: 1.9702830981182795

Epoch: 6| Step: 7
Training loss: 1.9043128490447998
Validation loss: 1.9362055922067294

Epoch: 6| Step: 8
Training loss: 1.1371264457702637
Validation loss: 1.8736578418362526

Epoch: 6| Step: 9
Training loss: 2.078443765640259
Validation loss: 1.9293894601124588

Epoch: 6| Step: 10
Training loss: 1.49579656124115
Validation loss: 1.914766837191838

Epoch: 6| Step: 11
Training loss: 2.141132354736328
Validation loss: 1.9420373542334444

Epoch: 6| Step: 12
Training loss: 1.443740725517273
Validation loss: 1.880387488231864

Epoch: 6| Step: 13
Training loss: 1.3942338228225708
Validation loss: 1.911898438648511

Epoch: 283| Step: 0
Training loss: 1.4246492385864258
Validation loss: 1.8757549062851937

Epoch: 6| Step: 1
Training loss: 1.9002323150634766
Validation loss: 1.8891024871539044

Epoch: 6| Step: 2
Training loss: 1.7165842056274414
Validation loss: 1.8897901568361508

Epoch: 6| Step: 3
Training loss: 2.1448874473571777
Validation loss: 1.8989474004314792

Epoch: 6| Step: 4
Training loss: 1.3429425954818726
Validation loss: 1.908408393142044

Epoch: 6| Step: 5
Training loss: 1.81790292263031
Validation loss: 1.8854460588065527

Epoch: 6| Step: 6
Training loss: 1.2717291116714478
Validation loss: 1.9016025156103156

Epoch: 6| Step: 7
Training loss: 2.025308609008789
Validation loss: 1.8968235792652253

Epoch: 6| Step: 8
Training loss: 1.3519803285598755
Validation loss: 1.9440328408313055

Epoch: 6| Step: 9
Training loss: 2.259498119354248
Validation loss: 1.9059298166664698

Epoch: 6| Step: 10
Training loss: 1.3671586513519287
Validation loss: 1.9208472480056107

Epoch: 6| Step: 11
Training loss: 1.0661169290542603
Validation loss: 1.8760924313658027

Epoch: 6| Step: 12
Training loss: 1.4423041343688965
Validation loss: 1.9090077184861707

Epoch: 6| Step: 13
Training loss: 2.002052068710327
Validation loss: 1.9235067316280898

Epoch: 284| Step: 0
Training loss: 1.9346340894699097
Validation loss: 1.8949788783186226

Epoch: 6| Step: 1
Training loss: 2.0653841495513916
Validation loss: 1.9839935136097733

Epoch: 6| Step: 2
Training loss: 1.6227973699569702
Validation loss: 1.9174083535389235

Epoch: 6| Step: 3
Training loss: 1.8669835329055786
Validation loss: 1.9347892410011702

Epoch: 6| Step: 4
Training loss: 0.9816156029701233
Validation loss: 1.9226610968189854

Epoch: 6| Step: 5
Training loss: 1.3853682279586792
Validation loss: 1.9447825172896027

Epoch: 6| Step: 6
Training loss: 1.7140823602676392
Validation loss: 1.9673595851467502

Epoch: 6| Step: 7
Training loss: 1.8953213691711426
Validation loss: 1.8651839840796687

Epoch: 6| Step: 8
Training loss: 1.7506535053253174
Validation loss: 1.937847400224337

Epoch: 6| Step: 9
Training loss: 1.9333380460739136
Validation loss: 1.931540967315756

Epoch: 6| Step: 10
Training loss: 1.2916476726531982
Validation loss: 1.9700088782977032

Epoch: 6| Step: 11
Training loss: 1.551191806793213
Validation loss: 1.8764978096049318

Epoch: 6| Step: 12
Training loss: 1.3415639400482178
Validation loss: 1.952298355358903

Epoch: 6| Step: 13
Training loss: 1.5247544050216675
Validation loss: 1.869158967848747

Epoch: 285| Step: 0
Training loss: 1.5153617858886719
Validation loss: 1.883589958631864

Epoch: 6| Step: 1
Training loss: 1.5034717321395874
Validation loss: 1.8730748622648177

Epoch: 6| Step: 2
Training loss: 1.8141865730285645
Validation loss: 1.9120114221367785

Epoch: 6| Step: 3
Training loss: 1.7877509593963623
Validation loss: 1.9319398467258742

Epoch: 6| Step: 4
Training loss: 1.3191331624984741
Validation loss: 1.875015744598963

Epoch: 6| Step: 5
Training loss: 1.3463547229766846
Validation loss: 1.9163436607647968

Epoch: 6| Step: 6
Training loss: 2.063727378845215
Validation loss: 1.8911722219118507

Epoch: 6| Step: 7
Training loss: 1.7942404747009277
Validation loss: 1.9329275520898963

Epoch: 6| Step: 8
Training loss: 1.393035650253296
Validation loss: 1.8732437779826503

Epoch: 6| Step: 9
Training loss: 1.3527973890304565
Validation loss: 1.9065791765848796

Epoch: 6| Step: 10
Training loss: 2.3164777755737305
Validation loss: 1.8877718397366103

Epoch: 6| Step: 11
Training loss: 1.5965306758880615
Validation loss: 1.8757296069975822

Epoch: 6| Step: 12
Training loss: 1.2180798053741455
Validation loss: 1.878913015447637

Epoch: 6| Step: 13
Training loss: 1.4876476526260376
Validation loss: 1.8445296184990996

Epoch: 286| Step: 0
Training loss: 1.6549499034881592
Validation loss: 1.8145082958282963

Epoch: 6| Step: 1
Training loss: 1.4930126667022705
Validation loss: 1.9171146872223064

Epoch: 6| Step: 2
Training loss: 2.1043739318847656
Validation loss: 1.9245756108273742

Epoch: 6| Step: 3
Training loss: 1.3948266506195068
Validation loss: 1.852229634920756

Epoch: 6| Step: 4
Training loss: 1.808765172958374
Validation loss: 1.8790411718430058

Epoch: 6| Step: 5
Training loss: 1.1515253782272339
Validation loss: 1.911594072977702

Epoch: 6| Step: 6
Training loss: 1.5866626501083374
Validation loss: 1.9158223316233645

Epoch: 6| Step: 7
Training loss: 2.2595229148864746
Validation loss: 1.912186812329036

Epoch: 6| Step: 8
Training loss: 0.9690677523612976
Validation loss: 1.908099917955296

Epoch: 6| Step: 9
Training loss: 1.7517571449279785
Validation loss: 1.9010671082363333

Epoch: 6| Step: 10
Training loss: 1.9146162271499634
Validation loss: 1.9075881127388246

Epoch: 6| Step: 11
Training loss: 1.7792824506759644
Validation loss: 1.9372636374606882

Epoch: 6| Step: 12
Training loss: 1.2477394342422485
Validation loss: 1.8843929485608173

Epoch: 6| Step: 13
Training loss: 1.462106466293335
Validation loss: 1.9119488026506157

Epoch: 287| Step: 0
Training loss: 1.9509117603302002
Validation loss: 1.9225562234078684

Epoch: 6| Step: 1
Training loss: 1.2012689113616943
Validation loss: 1.899274331267162

Epoch: 6| Step: 2
Training loss: 1.0720927715301514
Validation loss: 1.916332806310346

Epoch: 6| Step: 3
Training loss: 2.0709993839263916
Validation loss: 1.9103765513307305

Epoch: 6| Step: 4
Training loss: 1.4744220972061157
Validation loss: 1.8304355759774484

Epoch: 6| Step: 5
Training loss: 1.5453293323516846
Validation loss: 1.936366291456325

Epoch: 6| Step: 6
Training loss: 1.766873836517334
Validation loss: 1.8604285742646904

Epoch: 6| Step: 7
Training loss: 1.7371814250946045
Validation loss: 1.9163171706661102

Epoch: 6| Step: 8
Training loss: 1.4145259857177734
Validation loss: 1.82975185045632

Epoch: 6| Step: 9
Training loss: 2.0331003665924072
Validation loss: 1.9071350841112034

Epoch: 6| Step: 10
Training loss: 1.302715539932251
Validation loss: 1.8400163932513165

Epoch: 6| Step: 11
Training loss: 2.498161792755127
Validation loss: 1.9271138278386926

Epoch: 6| Step: 12
Training loss: 1.7677193880081177
Validation loss: 1.8912004937407791

Epoch: 6| Step: 13
Training loss: 0.9320723414421082
Validation loss: 1.880396068737071

Epoch: 288| Step: 0
Training loss: 1.760778784751892
Validation loss: 1.8462576943059121

Epoch: 6| Step: 1
Training loss: 1.104536771774292
Validation loss: 1.9084442456563313

Epoch: 6| Step: 2
Training loss: 1.920557975769043
Validation loss: 1.8393543253662765

Epoch: 6| Step: 3
Training loss: 0.840460479259491
Validation loss: 1.8644315465804069

Epoch: 6| Step: 4
Training loss: 1.4429452419281006
Validation loss: 1.9270836691702566

Epoch: 6| Step: 5
Training loss: 1.2921514511108398
Validation loss: 1.8994543552398682

Epoch: 6| Step: 6
Training loss: 1.6108227968215942
Validation loss: 1.9611169394626413

Epoch: 6| Step: 7
Training loss: 1.4124958515167236
Validation loss: 1.8900456941255959

Epoch: 6| Step: 8
Training loss: 1.6361631155014038
Validation loss: 1.9987174618628718

Epoch: 6| Step: 9
Training loss: 1.2222697734832764
Validation loss: 1.9906065028200868

Epoch: 6| Step: 10
Training loss: 2.377997875213623
Validation loss: 1.8926976585900912

Epoch: 6| Step: 11
Training loss: 2.296504497528076
Validation loss: 1.9514363888771302

Epoch: 6| Step: 12
Training loss: 1.8990774154663086
Validation loss: 1.9383677410823044

Epoch: 6| Step: 13
Training loss: 1.5610471963882446
Validation loss: 1.9108088272874073

Epoch: 289| Step: 0
Training loss: 1.9241331815719604
Validation loss: 1.9507241466993928

Epoch: 6| Step: 1
Training loss: 1.8217792510986328
Validation loss: 1.8899262528265677

Epoch: 6| Step: 2
Training loss: 1.2204945087432861
Validation loss: 1.8714678941234466

Epoch: 6| Step: 3
Training loss: 1.881387710571289
Validation loss: 1.9041642142880348

Epoch: 6| Step: 4
Training loss: 1.1901129484176636
Validation loss: 1.9208431795079222

Epoch: 6| Step: 5
Training loss: 1.6727139949798584
Validation loss: 1.911739541638282

Epoch: 6| Step: 6
Training loss: 1.541821002960205
Validation loss: 1.927819041795628

Epoch: 6| Step: 7
Training loss: 1.5232670307159424
Validation loss: 1.8598372705521122

Epoch: 6| Step: 8
Training loss: 1.6575425863265991
Validation loss: 1.9152691595015987

Epoch: 6| Step: 9
Training loss: 1.9814287424087524
Validation loss: 1.8221272845422067

Epoch: 6| Step: 10
Training loss: 1.4302024841308594
Validation loss: 1.8624374981849425

Epoch: 6| Step: 11
Training loss: 2.467827796936035
Validation loss: 1.8210700660623529

Epoch: 6| Step: 12
Training loss: 1.2742552757263184
Validation loss: 1.8823551695833924

Epoch: 6| Step: 13
Training loss: 1.306821584701538
Validation loss: 1.8437794472581597

Epoch: 290| Step: 0
Training loss: 1.7509610652923584
Validation loss: 1.86857674583312

Epoch: 6| Step: 1
Training loss: 1.1259996891021729
Validation loss: 1.915628078163311

Epoch: 6| Step: 2
Training loss: 1.6621801853179932
Validation loss: 1.8788822338145266

Epoch: 6| Step: 3
Training loss: 1.6764048337936401
Validation loss: 1.873231239216302

Epoch: 6| Step: 4
Training loss: 1.307708740234375
Validation loss: 1.8907928748797345

Epoch: 6| Step: 5
Training loss: 1.414345145225525
Validation loss: 1.8894784014712098

Epoch: 6| Step: 6
Training loss: 1.5353264808654785
Validation loss: 1.8931962072208364

Epoch: 6| Step: 7
Training loss: 1.9269990921020508
Validation loss: 1.9167835814978487

Epoch: 6| Step: 8
Training loss: 1.7043418884277344
Validation loss: 1.940306871168075

Epoch: 6| Step: 9
Training loss: 1.249466896057129
Validation loss: 1.8908563916401198

Epoch: 6| Step: 10
Training loss: 1.7996165752410889
Validation loss: 1.8785613057433919

Epoch: 6| Step: 11
Training loss: 1.7450897693634033
Validation loss: 1.9165147478862474

Epoch: 6| Step: 12
Training loss: 1.4636032581329346
Validation loss: 1.9780617683164534

Epoch: 6| Step: 13
Training loss: 2.549855947494507
Validation loss: 1.945085137121139

Epoch: 291| Step: 0
Training loss: 1.4166638851165771
Validation loss: 1.980982652274511

Epoch: 6| Step: 1
Training loss: 1.321482539176941
Validation loss: 1.936852632030364

Epoch: 6| Step: 2
Training loss: 1.4736098051071167
Validation loss: 1.9119214460413942

Epoch: 6| Step: 3
Training loss: 1.4354393482208252
Validation loss: 1.8848099939284786

Epoch: 6| Step: 4
Training loss: 1.0784064531326294
Validation loss: 1.9464799255453131

Epoch: 6| Step: 5
Training loss: 1.7702171802520752
Validation loss: 1.9195212446233278

Epoch: 6| Step: 6
Training loss: 1.9598798751831055
Validation loss: 1.9530780776854484

Epoch: 6| Step: 7
Training loss: 1.8626271486282349
Validation loss: 1.9034478549034364

Epoch: 6| Step: 8
Training loss: 1.6124333143234253
Validation loss: 1.867436869170076

Epoch: 6| Step: 9
Training loss: 2.093078136444092
Validation loss: 1.9241492902078936

Epoch: 6| Step: 10
Training loss: 1.3462961912155151
Validation loss: 1.8612987482419578

Epoch: 6| Step: 11
Training loss: 1.9336373805999756
Validation loss: 1.9220268623803252

Epoch: 6| Step: 12
Training loss: 1.4803012609481812
Validation loss: 1.9001015040182299

Epoch: 6| Step: 13
Training loss: 2.07205867767334
Validation loss: 1.8475044863198393

Epoch: 292| Step: 0
Training loss: 2.149961471557617
Validation loss: 1.8651752241196171

Epoch: 6| Step: 1
Training loss: 1.7120962142944336
Validation loss: 1.9309717096308225

Epoch: 6| Step: 2
Training loss: 1.675719141960144
Validation loss: 1.9181365120795466

Epoch: 6| Step: 3
Training loss: 1.4440789222717285
Validation loss: 1.9040877998516124

Epoch: 6| Step: 4
Training loss: 1.6710093021392822
Validation loss: 1.8982947052166026

Epoch: 6| Step: 5
Training loss: 1.873725175857544
Validation loss: 1.928109174133629

Epoch: 6| Step: 6
Training loss: 1.3676714897155762
Validation loss: 1.917343790813159

Epoch: 6| Step: 7
Training loss: 2.0778279304504395
Validation loss: 1.875559227440947

Epoch: 6| Step: 8
Training loss: 1.5399706363677979
Validation loss: 1.8831039372310843

Epoch: 6| Step: 9
Training loss: 1.2728159427642822
Validation loss: 1.8925911764944754

Epoch: 6| Step: 10
Training loss: 1.3023649454116821
Validation loss: 1.9782788317690614

Epoch: 6| Step: 11
Training loss: 1.5602459907531738
Validation loss: 1.9340681593905213

Epoch: 6| Step: 12
Training loss: 1.660484790802002
Validation loss: 1.9575384855270386

Epoch: 6| Step: 13
Training loss: 1.3479899168014526
Validation loss: 1.909058722116614

Epoch: 293| Step: 0
Training loss: 1.6145435571670532
Validation loss: 1.897389901581631

Epoch: 6| Step: 1
Training loss: 1.4299640655517578
Validation loss: 1.8885705381311395

Epoch: 6| Step: 2
Training loss: 1.9996141195297241
Validation loss: 1.8730785013526998

Epoch: 6| Step: 3
Training loss: 1.1128356456756592
Validation loss: 1.833280142917428

Epoch: 6| Step: 4
Training loss: 1.5120224952697754
Validation loss: 1.831427284466323

Epoch: 6| Step: 5
Training loss: 1.3093211650848389
Validation loss: 1.9387326548176427

Epoch: 6| Step: 6
Training loss: 1.6979146003723145
Validation loss: 1.8518152083120039

Epoch: 6| Step: 7
Training loss: 1.5382174253463745
Validation loss: 1.8883029376306841

Epoch: 6| Step: 8
Training loss: 2.0012543201446533
Validation loss: 1.886262874449453

Epoch: 6| Step: 9
Training loss: 1.596706748008728
Validation loss: 1.8906368696561424

Epoch: 6| Step: 10
Training loss: 1.8689676523208618
Validation loss: 1.8325467301953224

Epoch: 6| Step: 11
Training loss: 1.1566466093063354
Validation loss: 1.8347302995702273

Epoch: 6| Step: 12
Training loss: 1.5280308723449707
Validation loss: 1.876347198281237

Epoch: 6| Step: 13
Training loss: 2.9896745681762695
Validation loss: 1.851846024554263

Epoch: 294| Step: 0
Training loss: 1.0571463108062744
Validation loss: 1.8899551540292718

Epoch: 6| Step: 1
Training loss: 1.6486432552337646
Validation loss: 1.9057688277254823

Epoch: 6| Step: 2
Training loss: 1.711104154586792
Validation loss: 1.881552582146019

Epoch: 6| Step: 3
Training loss: 1.6478962898254395
Validation loss: 1.870209675963207

Epoch: 6| Step: 4
Training loss: 1.7316765785217285
Validation loss: 1.8947521563499206

Epoch: 6| Step: 5
Training loss: 1.4786484241485596
Validation loss: 1.9074028845756286

Epoch: 6| Step: 6
Training loss: 1.9193395376205444
Validation loss: 1.9730143700876543

Epoch: 6| Step: 7
Training loss: 1.7999677658081055
Validation loss: 1.9675547589537918

Epoch: 6| Step: 8
Training loss: 2.0882558822631836
Validation loss: 1.9595837003441268

Epoch: 6| Step: 9
Training loss: 1.9940481185913086
Validation loss: 1.928625019647742

Epoch: 6| Step: 10
Training loss: 1.7224984169006348
Validation loss: 1.9209182877694406

Epoch: 6| Step: 11
Training loss: 0.8250488042831421
Validation loss: 1.9455294737251856

Epoch: 6| Step: 12
Training loss: 1.6392052173614502
Validation loss: 1.9281955419048187

Epoch: 6| Step: 13
Training loss: 2.083913564682007
Validation loss: 1.9331688342555877

Epoch: 295| Step: 0
Training loss: 1.8052401542663574
Validation loss: 1.8782182995991041

Epoch: 6| Step: 1
Training loss: 0.8309627771377563
Validation loss: 1.9132723321196854

Epoch: 6| Step: 2
Training loss: 2.20849871635437
Validation loss: 1.8755128114454207

Epoch: 6| Step: 3
Training loss: 1.92629873752594
Validation loss: 1.8883823258902437

Epoch: 6| Step: 4
Training loss: 1.6109853982925415
Validation loss: 1.8430848442098147

Epoch: 6| Step: 5
Training loss: 0.9813568592071533
Validation loss: 1.9075942731672717

Epoch: 6| Step: 6
Training loss: 1.6536998748779297
Validation loss: 1.9422937759789087

Epoch: 6| Step: 7
Training loss: 1.5036990642547607
Validation loss: 1.8226241501428748

Epoch: 6| Step: 8
Training loss: 2.4262301921844482
Validation loss: 1.8674361398143153

Epoch: 6| Step: 9
Training loss: 1.667813777923584
Validation loss: 1.901115612317157

Epoch: 6| Step: 10
Training loss: 1.147695779800415
Validation loss: 1.8671206748613747

Epoch: 6| Step: 11
Training loss: 1.8045315742492676
Validation loss: 1.9168410006389822

Epoch: 6| Step: 12
Training loss: 1.2697257995605469
Validation loss: 1.8310269835174724

Epoch: 6| Step: 13
Training loss: 2.0283143520355225
Validation loss: 1.8654091230002783

Epoch: 296| Step: 0
Training loss: 1.6728248596191406
Validation loss: 1.8643312915678947

Epoch: 6| Step: 1
Training loss: 1.1964514255523682
Validation loss: 1.8944302669135473

Epoch: 6| Step: 2
Training loss: 1.6329998970031738
Validation loss: 1.8861784165905369

Epoch: 6| Step: 3
Training loss: 1.7423313856124878
Validation loss: 1.9014616538119573

Epoch: 6| Step: 4
Training loss: 1.7886377573013306
Validation loss: 1.858744308512698

Epoch: 6| Step: 5
Training loss: 1.8659883737564087
Validation loss: 1.8714264028815812

Epoch: 6| Step: 6
Training loss: 1.8211100101470947
Validation loss: 1.905717803585914

Epoch: 6| Step: 7
Training loss: 1.7053743600845337
Validation loss: 1.8745727154516405

Epoch: 6| Step: 8
Training loss: 1.108778476715088
Validation loss: 1.875420613955426

Epoch: 6| Step: 9
Training loss: 2.2015585899353027
Validation loss: 1.9253734106658607

Epoch: 6| Step: 10
Training loss: 1.2493093013763428
Validation loss: 1.8997844182034975

Epoch: 6| Step: 11
Training loss: 1.362029790878296
Validation loss: 1.9013275625885173

Epoch: 6| Step: 12
Training loss: 1.4218153953552246
Validation loss: 1.8751427576106081

Epoch: 6| Step: 13
Training loss: 1.017392635345459
Validation loss: 1.8883266846338909

Epoch: 297| Step: 0
Training loss: 0.9844180941581726
Validation loss: 1.895831872058171

Epoch: 6| Step: 1
Training loss: 1.864686131477356
Validation loss: 1.870891095489584

Epoch: 6| Step: 2
Training loss: 2.128828525543213
Validation loss: 1.8486897022493425

Epoch: 6| Step: 3
Training loss: 1.4575588703155518
Validation loss: 1.898744701057352

Epoch: 6| Step: 4
Training loss: 1.5541276931762695
Validation loss: 1.8742595231661232

Epoch: 6| Step: 5
Training loss: 2.2838666439056396
Validation loss: 1.9152505013250536

Epoch: 6| Step: 6
Training loss: 1.2809748649597168
Validation loss: 1.917994531252051

Epoch: 6| Step: 7
Training loss: 1.410205602645874
Validation loss: 1.9386651567233506

Epoch: 6| Step: 8
Training loss: 1.3961862325668335
Validation loss: 1.9026490001268284

Epoch: 6| Step: 9
Training loss: 1.8897202014923096
Validation loss: 1.916029917296543

Epoch: 6| Step: 10
Training loss: 1.5934160947799683
Validation loss: 1.9331447103972077

Epoch: 6| Step: 11
Training loss: 1.1949527263641357
Validation loss: 1.886397889865342

Epoch: 6| Step: 12
Training loss: 2.0510191917419434
Validation loss: 1.8983729603470012

Epoch: 6| Step: 13
Training loss: 1.5904425382614136
Validation loss: 1.9291577672445646

Epoch: 298| Step: 0
Training loss: 1.2541954517364502
Validation loss: 1.9233781855593446

Epoch: 6| Step: 1
Training loss: 1.8875490427017212
Validation loss: 1.9449662918685584

Epoch: 6| Step: 2
Training loss: 2.125685214996338
Validation loss: 1.9183002582160376

Epoch: 6| Step: 3
Training loss: 1.435043454170227
Validation loss: 1.9145591425639328

Epoch: 6| Step: 4
Training loss: 1.7298200130462646
Validation loss: 1.8686950950212375

Epoch: 6| Step: 5
Training loss: 1.5498442649841309
Validation loss: 1.9361917998201104

Epoch: 6| Step: 6
Training loss: 1.0563745498657227
Validation loss: 1.9260482249721405

Epoch: 6| Step: 7
Training loss: 1.7429481744766235
Validation loss: 1.8858980158323884

Epoch: 6| Step: 8
Training loss: 1.5187119245529175
Validation loss: 1.9097526060637606

Epoch: 6| Step: 9
Training loss: 1.4079980850219727
Validation loss: 1.897014078273568

Epoch: 6| Step: 10
Training loss: 1.7844719886779785
Validation loss: 1.8135416251356884

Epoch: 6| Step: 11
Training loss: 1.572009563446045
Validation loss: 1.8388924316693378

Epoch: 6| Step: 12
Training loss: 1.7264139652252197
Validation loss: 1.8945279839218303

Epoch: 6| Step: 13
Training loss: 1.7020372152328491
Validation loss: 1.9082949264075166

Epoch: 299| Step: 0
Training loss: 2.4006435871124268
Validation loss: 1.902937791680777

Epoch: 6| Step: 1
Training loss: 1.6117699146270752
Validation loss: 1.9209669809187613

Epoch: 6| Step: 2
Training loss: 1.499985694885254
Validation loss: 1.8675286257138817

Epoch: 6| Step: 3
Training loss: 1.5918493270874023
Validation loss: 1.8261774073364914

Epoch: 6| Step: 4
Training loss: 1.3092927932739258
Validation loss: 1.8845742402538177

Epoch: 6| Step: 5
Training loss: 1.4784672260284424
Validation loss: 1.8399003282670052

Epoch: 6| Step: 6
Training loss: 1.7326124906539917
Validation loss: 1.8463791083264094

Epoch: 6| Step: 7
Training loss: 1.797142744064331
Validation loss: 1.960539512736823

Epoch: 6| Step: 8
Training loss: 1.2196152210235596
Validation loss: 1.9007127490094913

Epoch: 6| Step: 9
Training loss: 1.6496655941009521
Validation loss: 1.8956459927302536

Epoch: 6| Step: 10
Training loss: 2.105574131011963
Validation loss: 1.924546205869285

Epoch: 6| Step: 11
Training loss: 1.8996185064315796
Validation loss: 1.9787537769604755

Epoch: 6| Step: 12
Training loss: 0.9481382369995117
Validation loss: 1.9947504587070917

Epoch: 6| Step: 13
Training loss: 2.1030359268188477
Validation loss: 1.9180461860472156

Epoch: 300| Step: 0
Training loss: 1.0109474658966064
Validation loss: 1.9548026028499808

Epoch: 6| Step: 1
Training loss: 1.4165992736816406
Validation loss: 1.9503921924098846

Epoch: 6| Step: 2
Training loss: 0.936371922492981
Validation loss: 1.9042497873306274

Epoch: 6| Step: 3
Training loss: 1.356062889099121
Validation loss: 1.9234215931225849

Epoch: 6| Step: 4
Training loss: 1.8690083026885986
Validation loss: 1.9442360734426847

Epoch: 6| Step: 5
Training loss: 1.5286586284637451
Validation loss: 1.8991118067054338

Epoch: 6| Step: 6
Training loss: 1.5070661306381226
Validation loss: 1.8645630075085549

Epoch: 6| Step: 7
Training loss: 2.290673017501831
Validation loss: 1.8441350806143977

Epoch: 6| Step: 8
Training loss: 1.5228259563446045
Validation loss: 1.8321136915555565

Epoch: 6| Step: 9
Training loss: 1.9823265075683594
Validation loss: 1.8612418879744828

Epoch: 6| Step: 10
Training loss: 1.6015431880950928
Validation loss: 1.8513318415611022

Epoch: 6| Step: 11
Training loss: 2.044065475463867
Validation loss: 1.8779562096441946

Epoch: 6| Step: 12
Training loss: 1.9482465982437134
Validation loss: 1.8791002201777633

Epoch: 6| Step: 13
Training loss: 1.3596456050872803
Validation loss: 1.9468103493413618

Testing loss: 2.2087075233459474
