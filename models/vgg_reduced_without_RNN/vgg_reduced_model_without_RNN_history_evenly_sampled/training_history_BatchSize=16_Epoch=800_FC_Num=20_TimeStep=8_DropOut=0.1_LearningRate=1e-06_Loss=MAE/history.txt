Epoch: 1| Step: 0
Training loss: 2.965252637863159
Validation loss: 3.3205874991673294

Epoch: 6| Step: 1
Training loss: 3.885550022125244
Validation loss: 3.3191286979183072

Epoch: 6| Step: 2
Training loss: 2.6657779216766357
Validation loss: 3.3187540602940384

Epoch: 6| Step: 3
Training loss: 3.2042617797851562
Validation loss: 3.3162300073972313

Epoch: 6| Step: 4
Training loss: 3.920403003692627
Validation loss: 3.314975033524216

Epoch: 6| Step: 5
Training loss: 2.6091842651367188
Validation loss: 3.3137501414104173

Epoch: 6| Step: 6
Training loss: 2.3821940422058105
Validation loss: 3.3111255732915734

Epoch: 6| Step: 7
Training loss: 3.940436363220215
Validation loss: 3.3116323768451648

Epoch: 6| Step: 8
Training loss: 1.853356122970581
Validation loss: 3.3096775675332673

Epoch: 6| Step: 9
Training loss: 3.6196465492248535
Validation loss: 3.308502807412096

Epoch: 6| Step: 10
Training loss: 4.2172160148620605
Validation loss: 3.3073855856413483

Epoch: 6| Step: 11
Training loss: 3.1029577255249023
Validation loss: 3.3076325026891564

Epoch: 6| Step: 12
Training loss: 4.034727096557617
Validation loss: 3.3039892437637493

Epoch: 6| Step: 13
Training loss: 3.7574915885925293
Validation loss: 3.3048193762379308

Epoch: 2| Step: 0
Training loss: 3.5462427139282227
Validation loss: 3.3033978323782645

Epoch: 6| Step: 1
Training loss: 3.8386776447296143
Validation loss: 3.300577143187164

Epoch: 6| Step: 2
Training loss: 3.710024356842041
Validation loss: 3.2996198951557116

Epoch: 6| Step: 3
Training loss: 3.4286482334136963
Validation loss: 3.299514485943702

Epoch: 6| Step: 4
Training loss: 2.0603649616241455
Validation loss: 3.297416866466563

Epoch: 6| Step: 5
Training loss: 2.276857376098633
Validation loss: 3.2956398866509877

Epoch: 6| Step: 6
Training loss: 3.9389781951904297
Validation loss: 3.295009366927608

Epoch: 6| Step: 7
Training loss: 3.5828869342803955
Validation loss: 3.2944155944290983

Epoch: 6| Step: 8
Training loss: 3.4990596771240234
Validation loss: 3.2924927460250033

Epoch: 6| Step: 9
Training loss: 3.4045281410217285
Validation loss: 3.292448889824652

Epoch: 6| Step: 10
Training loss: 2.585171699523926
Validation loss: 3.2901865615639636

Epoch: 6| Step: 11
Training loss: 3.2124061584472656
Validation loss: 3.2891198024954846

Epoch: 6| Step: 12
Training loss: 3.723891258239746
Validation loss: 3.28741039511978

Epoch: 6| Step: 13
Training loss: 2.677628517150879
Validation loss: 3.286451285885226

Epoch: 3| Step: 0
Training loss: 2.178617000579834
Validation loss: 3.284453345883277

Epoch: 6| Step: 1
Training loss: 3.144280433654785
Validation loss: 3.2842019988644506

Epoch: 6| Step: 2
Training loss: 3.943817138671875
Validation loss: 3.281934230558334

Epoch: 6| Step: 3
Training loss: 3.7738656997680664
Validation loss: 3.282121807016352

Epoch: 6| Step: 4
Training loss: 2.929629325866699
Validation loss: 3.279741797395932

Epoch: 6| Step: 5
Training loss: 3.3613228797912598
Validation loss: 3.279028872007965

Epoch: 6| Step: 6
Training loss: 3.013082981109619
Validation loss: 3.277438573939826

Epoch: 6| Step: 7
Training loss: 3.76469087600708
Validation loss: 3.2767601295184066

Epoch: 6| Step: 8
Training loss: 3.3775672912597656
Validation loss: 3.274368950115737

Epoch: 6| Step: 9
Training loss: 3.3052284717559814
Validation loss: 3.2733571760116087

Epoch: 6| Step: 10
Training loss: 2.9590954780578613
Validation loss: 3.2718685057855423

Epoch: 6| Step: 11
Training loss: 3.6929707527160645
Validation loss: 3.2695347339876237

Epoch: 6| Step: 12
Training loss: 3.065546989440918
Validation loss: 3.2694647619801183

Epoch: 6| Step: 13
Training loss: 2.872541666030884
Validation loss: 3.2671753565470376

Epoch: 4| Step: 0
Training loss: 4.1251373291015625
Validation loss: 3.2656875220678185

Epoch: 6| Step: 1
Training loss: 4.230307579040527
Validation loss: 3.2644167587321293

Epoch: 6| Step: 2
Training loss: 3.2199172973632812
Validation loss: 3.2615303147223687

Epoch: 6| Step: 3
Training loss: 2.3585495948791504
Validation loss: 3.2606982979723202

Epoch: 6| Step: 4
Training loss: 3.2692346572875977
Validation loss: 3.260096155187135

Epoch: 6| Step: 5
Training loss: 2.749305009841919
Validation loss: 3.2594010009560535

Epoch: 6| Step: 6
Training loss: 3.262507915496826
Validation loss: 3.2583589784560667

Epoch: 6| Step: 7
Training loss: 2.237692356109619
Validation loss: 3.2555736546875327

Epoch: 6| Step: 8
Training loss: 3.858649492263794
Validation loss: 3.2533841133117676

Epoch: 6| Step: 9
Training loss: 3.400259017944336
Validation loss: 3.2521275397269958

Epoch: 6| Step: 10
Training loss: 3.1117849349975586
Validation loss: 3.2515188340217835

Epoch: 6| Step: 11
Training loss: 3.0373611450195312
Validation loss: 3.250119129816691

Epoch: 6| Step: 12
Training loss: 3.613226890563965
Validation loss: 3.2489019311884397

Epoch: 6| Step: 13
Training loss: 2.6035687923431396
Validation loss: 3.246007104073801

Epoch: 5| Step: 0
Training loss: 3.5988523960113525
Validation loss: 3.2451865596155964

Epoch: 6| Step: 1
Training loss: 4.704554080963135
Validation loss: 3.245325534574447

Epoch: 6| Step: 2
Training loss: 3.541200876235962
Validation loss: 3.239214171645462

Epoch: 6| Step: 3
Training loss: 2.8134260177612305
Validation loss: 3.2403524742331555

Epoch: 6| Step: 4
Training loss: 2.3383984565734863
Validation loss: 3.2381737514208724

Epoch: 6| Step: 5
Training loss: 3.3596458435058594
Validation loss: 3.235784561403336

Epoch: 6| Step: 6
Training loss: 2.4785988330841064
Validation loss: 3.2354085906859367

Epoch: 6| Step: 7
Training loss: 3.5890979766845703
Validation loss: 3.231504350580195

Epoch: 6| Step: 8
Training loss: 2.411250114440918
Validation loss: 3.2332079436189387

Epoch: 6| Step: 9
Training loss: 3.4115636348724365
Validation loss: 3.2310297104620163

Epoch: 6| Step: 10
Training loss: 2.93072772026062
Validation loss: 3.2283271563950406

Epoch: 6| Step: 11
Training loss: 2.900000810623169
Validation loss: 3.226247610584382

Epoch: 6| Step: 12
Training loss: 3.7143213748931885
Validation loss: 3.223682762474142

Epoch: 6| Step: 13
Training loss: 3.432323932647705
Validation loss: 3.221691511010611

Epoch: 6| Step: 0
Training loss: 2.7393035888671875
Validation loss: 3.222830054580524

Epoch: 6| Step: 1
Training loss: 2.817072629928589
Validation loss: 3.2198076273805354

Epoch: 6| Step: 2
Training loss: 2.712024211883545
Validation loss: 3.21695468759024

Epoch: 6| Step: 3
Training loss: 4.274174690246582
Validation loss: 3.217865743944722

Epoch: 6| Step: 4
Training loss: 3.8337512016296387
Validation loss: 3.2150948791093725

Epoch: 6| Step: 5
Training loss: 2.472766399383545
Validation loss: 3.212706196692682

Epoch: 6| Step: 6
Training loss: 3.0952746868133545
Validation loss: 3.2104225184327815

Epoch: 6| Step: 7
Training loss: 2.727895498275757
Validation loss: 3.2086374528946413

Epoch: 6| Step: 8
Training loss: 3.278693675994873
Validation loss: 3.205905109323481

Epoch: 6| Step: 9
Training loss: 3.3191614151000977
Validation loss: 3.207246998304962

Epoch: 6| Step: 10
Training loss: 3.841501235961914
Validation loss: 3.2049741334812616

Epoch: 6| Step: 11
Training loss: 2.1126012802124023
Validation loss: 3.2022762554948048

Epoch: 6| Step: 12
Training loss: 3.837726593017578
Validation loss: 3.2015914865719375

Epoch: 6| Step: 13
Training loss: 4.27396297454834
Validation loss: 3.1976878566126667

Epoch: 7| Step: 0
Training loss: 4.382741928100586
Validation loss: 3.195452464524136

Epoch: 6| Step: 1
Training loss: 3.0416858196258545
Validation loss: 3.193748340811781

Epoch: 6| Step: 2
Training loss: 3.291689872741699
Validation loss: 3.192158570853613

Epoch: 6| Step: 3
Training loss: 3.483614444732666
Validation loss: 3.190004138536351

Epoch: 6| Step: 4
Training loss: 3.100348711013794
Validation loss: 3.1875486604629026

Epoch: 6| Step: 5
Training loss: 2.7557077407836914
Validation loss: 3.1861859624103834

Epoch: 6| Step: 6
Training loss: 3.0455679893493652
Validation loss: 3.183398836402483

Epoch: 6| Step: 7
Training loss: 2.768608570098877
Validation loss: 3.17893244630547

Epoch: 6| Step: 8
Training loss: 3.169961929321289
Validation loss: 3.1781071796212146

Epoch: 6| Step: 9
Training loss: 4.003658294677734
Validation loss: 3.1744006013357513

Epoch: 6| Step: 10
Training loss: 2.9358112812042236
Validation loss: 3.1723787143666256

Epoch: 6| Step: 11
Training loss: 3.278149366378784
Validation loss: 3.1718258985909085

Epoch: 6| Step: 12
Training loss: 2.735896348953247
Validation loss: 3.169290106783631

Epoch: 6| Step: 13
Training loss: 2.1538071632385254
Validation loss: 3.1663945541586926

Epoch: 8| Step: 0
Training loss: 2.8124961853027344
Validation loss: 3.16345130243609

Epoch: 6| Step: 1
Training loss: 2.535346031188965
Validation loss: 3.161094832163985

Epoch: 6| Step: 2
Training loss: 2.091435432434082
Validation loss: 3.1613828905167116

Epoch: 6| Step: 3
Training loss: 3.4025931358337402
Validation loss: 3.156863051076089

Epoch: 6| Step: 4
Training loss: 3.636774778366089
Validation loss: 3.155855409560665

Epoch: 6| Step: 5
Training loss: 4.237570762634277
Validation loss: 3.1545982771022345

Epoch: 6| Step: 6
Training loss: 2.976383686065674
Validation loss: 3.1535239963121313

Epoch: 6| Step: 7
Training loss: 3.8724260330200195
Validation loss: 3.1471668289553736

Epoch: 6| Step: 8
Training loss: 3.633626937866211
Validation loss: 3.146107127589564

Epoch: 6| Step: 9
Training loss: 3.3820321559906006
Validation loss: 3.144422718273696

Epoch: 6| Step: 10
Training loss: 1.8317235708236694
Validation loss: 3.140511599920129

Epoch: 6| Step: 11
Training loss: 3.4860987663269043
Validation loss: 3.1377803561508015

Epoch: 6| Step: 12
Training loss: 3.2977988719940186
Validation loss: 3.1354344608963176

Epoch: 6| Step: 13
Training loss: 3.007812976837158
Validation loss: 3.13414833622594

Epoch: 9| Step: 0
Training loss: 3.7613589763641357
Validation loss: 3.1266674072511735

Epoch: 6| Step: 1
Training loss: 2.3887834548950195
Validation loss: 3.124056500773276

Epoch: 6| Step: 2
Training loss: 3.5285730361938477
Validation loss: 3.1255287688265563

Epoch: 6| Step: 3
Training loss: 2.297067165374756
Validation loss: 3.11963887112115

Epoch: 6| Step: 4
Training loss: 3.574131488800049
Validation loss: 3.117693588297854

Epoch: 6| Step: 5
Training loss: 3.8988752365112305
Validation loss: 3.1142565563160884

Epoch: 6| Step: 6
Training loss: 3.69470477104187
Validation loss: 3.1109753372848674

Epoch: 6| Step: 7
Training loss: 2.593405246734619
Validation loss: 3.1029154331453386

Epoch: 6| Step: 8
Training loss: 2.5944268703460693
Validation loss: 3.1057050407573743

Epoch: 6| Step: 9
Training loss: 3.679734706878662
Validation loss: 3.0966813154118036

Epoch: 6| Step: 10
Training loss: 3.294125556945801
Validation loss: 3.094250750798051

Epoch: 6| Step: 11
Training loss: 3.96201491355896
Validation loss: 3.0904842166490454

Epoch: 6| Step: 12
Training loss: 2.598133087158203
Validation loss: 3.0862631592699277

Epoch: 6| Step: 13
Training loss: 1.0675406455993652
Validation loss: 3.0841397470043552

Epoch: 10| Step: 0
Training loss: 2.255280017852783
Validation loss: 3.078689459831484

Epoch: 6| Step: 1
Training loss: 3.6601181030273438
Validation loss: 3.0757497049147084

Epoch: 6| Step: 2
Training loss: 2.9349870681762695
Validation loss: 3.0733387572790987

Epoch: 6| Step: 3
Training loss: 3.4384548664093018
Validation loss: 3.071323935703565

Epoch: 6| Step: 4
Training loss: 3.5464887619018555
Validation loss: 3.065310021882416

Epoch: 6| Step: 5
Training loss: 2.7351644039154053
Validation loss: 3.0620419568912958

Epoch: 6| Step: 6
Training loss: 3.3084888458251953
Validation loss: 3.057908465785365

Epoch: 6| Step: 7
Training loss: 3.8571085929870605
Validation loss: 3.0539972115588445

Epoch: 6| Step: 8
Training loss: 3.757317066192627
Validation loss: 3.0499347153530327

Epoch: 6| Step: 9
Training loss: 2.275327682495117
Validation loss: 3.043873320343674

Epoch: 6| Step: 10
Training loss: 2.910945177078247
Validation loss: 3.0410306453704834

Epoch: 6| Step: 11
Training loss: 3.1732699871063232
Validation loss: 3.035853837126045

Epoch: 6| Step: 12
Training loss: 2.7817935943603516
Validation loss: 3.0300838203840357

Epoch: 6| Step: 13
Training loss: 2.328129768371582
Validation loss: 3.0263976999508437

Epoch: 11| Step: 0
Training loss: 3.3473026752471924
Validation loss: 3.02200045124177

Epoch: 6| Step: 1
Training loss: 3.428057909011841
Validation loss: 3.0187846511922856

Epoch: 6| Step: 2
Training loss: 2.872056007385254
Validation loss: 3.0121725387470697

Epoch: 6| Step: 3
Training loss: 2.3755390644073486
Validation loss: 3.0086993427686792

Epoch: 6| Step: 4
Training loss: 3.259906530380249
Validation loss: 3.0056444060417915

Epoch: 6| Step: 5
Training loss: 3.87825608253479
Validation loss: 3.0001693079548497

Epoch: 6| Step: 6
Training loss: 3.1378283500671387
Validation loss: 2.9968813465487574

Epoch: 6| Step: 7
Training loss: 2.8180017471313477
Validation loss: 2.990001381084483

Epoch: 6| Step: 8
Training loss: 2.9266350269317627
Validation loss: 2.9869036161771385

Epoch: 6| Step: 9
Training loss: 2.503385305404663
Validation loss: 2.979990848930933

Epoch: 6| Step: 10
Training loss: 3.248135566711426
Validation loss: 2.97738475953379

Epoch: 6| Step: 11
Training loss: 2.6772217750549316
Validation loss: 2.9683345287076888

Epoch: 6| Step: 12
Training loss: 3.0958991050720215
Validation loss: 2.968361218770345

Epoch: 6| Step: 13
Training loss: 3.2471179962158203
Validation loss: 2.9564501854681198

Epoch: 12| Step: 0
Training loss: 3.4362716674804688
Validation loss: 2.9545273755186345

Epoch: 6| Step: 1
Training loss: 2.95938777923584
Validation loss: 2.9495717094790552

Epoch: 6| Step: 2
Training loss: 2.5175702571868896
Validation loss: 2.9470295495884393

Epoch: 6| Step: 3
Training loss: 2.4048662185668945
Validation loss: 2.9430457058773247

Epoch: 6| Step: 4
Training loss: 3.699354648590088
Validation loss: 2.9380918061861427

Epoch: 6| Step: 5
Training loss: 3.2558140754699707
Validation loss: 2.9362892668734313

Epoch: 6| Step: 6
Training loss: 2.674175500869751
Validation loss: 2.9298637067118

Epoch: 6| Step: 7
Training loss: 2.8290786743164062
Validation loss: 2.928251189570273

Epoch: 6| Step: 8
Training loss: 2.471118927001953
Validation loss: 2.9176551295864965

Epoch: 6| Step: 9
Training loss: 1.915285348892212
Validation loss: 2.91230772900325

Epoch: 6| Step: 10
Training loss: 4.015007019042969
Validation loss: 2.9100536992472987

Epoch: 6| Step: 11
Training loss: 3.2276084423065186
Validation loss: 2.9062200848774244

Epoch: 6| Step: 12
Training loss: 3.6838724613189697
Validation loss: 2.894824294633763

Epoch: 6| Step: 13
Training loss: 2.987823247909546
Validation loss: 2.8939415665083033

Epoch: 13| Step: 0
Training loss: 2.944444417953491
Validation loss: 2.884564071573237

Epoch: 6| Step: 1
Training loss: 2.9302995204925537
Validation loss: 2.8792694973689255

Epoch: 6| Step: 2
Training loss: 2.6267592906951904
Validation loss: 2.87789846235706

Epoch: 6| Step: 3
Training loss: 2.435620069503784
Validation loss: 2.870408473476287

Epoch: 6| Step: 4
Training loss: 3.0887672901153564
Validation loss: 2.860985889229723

Epoch: 6| Step: 5
Training loss: 2.6814756393432617
Validation loss: 2.857031596604214

Epoch: 6| Step: 6
Training loss: 3.2139699459075928
Validation loss: 2.8494357883289294

Epoch: 6| Step: 7
Training loss: 3.7339353561401367
Validation loss: 2.8404569318217616

Epoch: 6| Step: 8
Training loss: 3.315692901611328
Validation loss: 2.8408445568494898

Epoch: 6| Step: 9
Training loss: 2.8944084644317627
Validation loss: 2.830176889255483

Epoch: 6| Step: 10
Training loss: 2.070448160171509
Validation loss: 2.8300264984048824

Epoch: 6| Step: 11
Training loss: 2.6102142333984375
Validation loss: 2.824506877571024

Epoch: 6| Step: 12
Training loss: 3.289513111114502
Validation loss: 2.8158716847819667

Epoch: 6| Step: 13
Training loss: 3.8288040161132812
Validation loss: 2.806817344439927

Epoch: 14| Step: 0
Training loss: 3.1246652603149414
Validation loss: 2.8021153403866674

Epoch: 6| Step: 1
Training loss: 2.8872146606445312
Validation loss: 2.790586894558322

Epoch: 6| Step: 2
Training loss: 2.831195592880249
Validation loss: 2.7870386877367572

Epoch: 6| Step: 3
Training loss: 3.7799744606018066
Validation loss: 2.7817209741120696

Epoch: 6| Step: 4
Training loss: 2.550600528717041
Validation loss: 2.7753854233731508

Epoch: 6| Step: 5
Training loss: 3.421691417694092
Validation loss: 2.7653646315297773

Epoch: 6| Step: 6
Training loss: 3.3309006690979004
Validation loss: 2.7552905723612797

Epoch: 6| Step: 7
Training loss: 2.9671192169189453
Validation loss: 2.7587276838159047

Epoch: 6| Step: 8
Training loss: 2.9072425365448
Validation loss: 2.747038697683683

Epoch: 6| Step: 9
Training loss: 3.0163984298706055
Validation loss: 2.740764776865641

Epoch: 6| Step: 10
Training loss: 1.9264695644378662
Validation loss: 2.733590825911491

Epoch: 6| Step: 11
Training loss: 2.6499505043029785
Validation loss: 2.729396750850062

Epoch: 6| Step: 12
Training loss: 2.7215609550476074
Validation loss: 2.718287642284106

Epoch: 6| Step: 13
Training loss: 1.8791389465332031
Validation loss: 2.708398929206274

Epoch: 15| Step: 0
Training loss: 2.8843369483947754
Validation loss: 2.7054174536017963

Epoch: 6| Step: 1
Training loss: 2.719442844390869
Validation loss: 2.6899274882449897

Epoch: 6| Step: 2
Training loss: 3.2457432746887207
Validation loss: 2.687993259840114

Epoch: 6| Step: 3
Training loss: 2.9266958236694336
Validation loss: 2.6868800450396795

Epoch: 6| Step: 4
Training loss: 2.086653709411621
Validation loss: 2.6724412979618197

Epoch: 6| Step: 5
Training loss: 2.7502260208129883
Validation loss: 2.6720220145358833

Epoch: 6| Step: 6
Training loss: 3.5507102012634277
Validation loss: 2.660413134482599

Epoch: 6| Step: 7
Training loss: 2.835355758666992
Validation loss: 2.6459496918544976

Epoch: 6| Step: 8
Training loss: 2.451249599456787
Validation loss: 2.649862353519727

Epoch: 6| Step: 9
Training loss: 2.7617390155792236
Validation loss: 2.634036038511543

Epoch: 6| Step: 10
Training loss: 2.4042019844055176
Validation loss: 2.6327666800509215

Epoch: 6| Step: 11
Training loss: 3.1396424770355225
Validation loss: 2.6201969218510452

Epoch: 6| Step: 12
Training loss: 2.792351245880127
Validation loss: 2.6138435820097565

Epoch: 6| Step: 13
Training loss: 3.0984551906585693
Validation loss: 2.6053895437589256

Epoch: 16| Step: 0
Training loss: 2.1568257808685303
Validation loss: 2.5928110896900134

Epoch: 6| Step: 1
Training loss: 2.831564426422119
Validation loss: 2.590487434018043

Epoch: 6| Step: 2
Training loss: 2.6081974506378174
Validation loss: 2.577137900936988

Epoch: 6| Step: 3
Training loss: 2.908017635345459
Validation loss: 2.573141687659807

Epoch: 6| Step: 4
Training loss: 1.8920903205871582
Validation loss: 2.5681412143092

Epoch: 6| Step: 5
Training loss: 2.072190046310425
Validation loss: 2.563311549925035

Epoch: 6| Step: 6
Training loss: 2.6761484146118164
Validation loss: 2.5569912182387484

Epoch: 6| Step: 7
Training loss: 2.892577886581421
Validation loss: 2.5469497249972437

Epoch: 6| Step: 8
Training loss: 3.6591696739196777
Validation loss: 2.5410185911322154

Epoch: 6| Step: 9
Training loss: 3.1924893856048584
Validation loss: 2.5392951221876245

Epoch: 6| Step: 10
Training loss: 2.8790266513824463
Validation loss: 2.529610833814067

Epoch: 6| Step: 11
Training loss: 2.527620792388916
Validation loss: 2.516130993443151

Epoch: 6| Step: 12
Training loss: 3.3733973503112793
Validation loss: 2.5094320081895396

Epoch: 6| Step: 13
Training loss: 3.0525736808776855
Validation loss: 2.503213272299818

Epoch: 17| Step: 0
Training loss: 1.9571311473846436
Validation loss: 2.493091860125142

Epoch: 6| Step: 1
Training loss: 1.7169325351715088
Validation loss: 2.480322704520277

Epoch: 6| Step: 2
Training loss: 3.8776450157165527
Validation loss: 2.470404250647432

Epoch: 6| Step: 3
Training loss: 2.38515567779541
Validation loss: 2.4694415189886607

Epoch: 6| Step: 4
Training loss: 3.1362831592559814
Validation loss: 2.458514951890515

Epoch: 6| Step: 5
Training loss: 2.6467607021331787
Validation loss: 2.4526129999468402

Epoch: 6| Step: 6
Training loss: 3.328639268875122
Validation loss: 2.438764295270366

Epoch: 6| Step: 7
Training loss: 2.6479015350341797
Validation loss: 2.4327834703589

Epoch: 6| Step: 8
Training loss: 2.3595757484436035
Validation loss: 2.420828757747527

Epoch: 6| Step: 9
Training loss: 3.0918691158294678
Validation loss: 2.4101875059066282

Epoch: 6| Step: 10
Training loss: 3.199492931365967
Validation loss: 2.3999420929980535

Epoch: 6| Step: 11
Training loss: 2.6398909091949463
Validation loss: 2.396020979009649

Epoch: 6| Step: 12
Training loss: 2.230999231338501
Validation loss: 2.3917506792212047

Epoch: 6| Step: 13
Training loss: 2.5457763671875
Validation loss: 2.370732779143959

Epoch: 18| Step: 0
Training loss: 2.402590751647949
Validation loss: 2.3693955790612007

Epoch: 6| Step: 1
Training loss: 2.3458471298217773
Validation loss: 2.362554442497992

Epoch: 6| Step: 2
Training loss: 2.2375736236572266
Validation loss: 2.3509058747240292

Epoch: 6| Step: 3
Training loss: 2.82848858833313
Validation loss: 2.3374510375402306

Epoch: 6| Step: 4
Training loss: 3.2054619789123535
Validation loss: 2.3322081540220525

Epoch: 6| Step: 5
Training loss: 1.9884638786315918
Validation loss: 2.3301561545300227

Epoch: 6| Step: 6
Training loss: 2.751131772994995
Validation loss: 2.322703251274683

Epoch: 6| Step: 7
Training loss: 2.545163154602051
Validation loss: 2.3105383355130433

Epoch: 6| Step: 8
Training loss: 3.0387892723083496
Validation loss: 2.308627747720288

Epoch: 6| Step: 9
Training loss: 2.9580650329589844
Validation loss: 2.30746982430899

Epoch: 6| Step: 10
Training loss: 3.134861707687378
Validation loss: 2.3024742295665126

Epoch: 6| Step: 11
Training loss: 2.798469305038452
Validation loss: 2.287311368091132

Epoch: 6| Step: 12
Training loss: 2.207249164581299
Validation loss: 2.2829919553572133

Epoch: 6| Step: 13
Training loss: 2.234269142150879
Validation loss: 2.2802643558030486

Epoch: 19| Step: 0
Training loss: 2.2738516330718994
Validation loss: 2.2600476908427414

Epoch: 6| Step: 1
Training loss: 1.8301527500152588
Validation loss: 2.2634431495461413

Epoch: 6| Step: 2
Training loss: 2.265873908996582
Validation loss: 2.2468900577996367

Epoch: 6| Step: 3
Training loss: 1.9031333923339844
Validation loss: 2.250351534094862

Epoch: 6| Step: 4
Training loss: 2.519651412963867
Validation loss: 2.242399259280133

Epoch: 6| Step: 5
Training loss: 2.2933664321899414
Validation loss: 2.2397419124521236

Epoch: 6| Step: 6
Training loss: 3.197537422180176
Validation loss: 2.226460099220276

Epoch: 6| Step: 7
Training loss: 2.7562453746795654
Validation loss: 2.2268322936950193

Epoch: 6| Step: 8
Training loss: 2.5499267578125
Validation loss: 2.2263842372484106

Epoch: 6| Step: 9
Training loss: 2.9102134704589844
Validation loss: 2.2131864768202587

Epoch: 6| Step: 10
Training loss: 2.8814010620117188
Validation loss: 2.207230234658846

Epoch: 6| Step: 11
Training loss: 2.965932607650757
Validation loss: 2.197273080066968

Epoch: 6| Step: 12
Training loss: 2.5455615520477295
Validation loss: 2.185766209838211

Epoch: 6| Step: 13
Training loss: 3.6482925415039062
Validation loss: 2.1949368548649613

Epoch: 20| Step: 0
Training loss: 2.1697936058044434
Validation loss: 2.1933493691106

Epoch: 6| Step: 1
Training loss: 2.2812881469726562
Validation loss: 2.1902765086902085

Epoch: 6| Step: 2
Training loss: 2.9509668350219727
Validation loss: 2.183114274855583

Epoch: 6| Step: 3
Training loss: 2.826139450073242
Validation loss: 2.1675282011749926

Epoch: 6| Step: 4
Training loss: 2.3334689140319824
Validation loss: 2.1767365240281626

Epoch: 6| Step: 5
Training loss: 2.7007088661193848
Validation loss: 2.1675208025081183

Epoch: 6| Step: 6
Training loss: 2.5963211059570312
Validation loss: 2.167013765663229

Epoch: 6| Step: 7
Training loss: 2.8925256729125977
Validation loss: 2.1662579454401487

Epoch: 6| Step: 8
Training loss: 2.576666831970215
Validation loss: 2.1705914440975396

Epoch: 6| Step: 9
Training loss: 2.491703510284424
Validation loss: 2.164073846673453

Epoch: 6| Step: 10
Training loss: 2.4228930473327637
Validation loss: 2.140589480758995

Epoch: 6| Step: 11
Training loss: 2.247081756591797
Validation loss: 2.155138747666472

Epoch: 6| Step: 12
Training loss: 2.204896926879883
Validation loss: 2.1501483789054294

Epoch: 6| Step: 13
Training loss: 2.986436605453491
Validation loss: 2.152431380364203

Epoch: 21| Step: 0
Training loss: 2.7147092819213867
Validation loss: 2.134276372130199

Epoch: 6| Step: 1
Training loss: 2.1972036361694336
Validation loss: 2.1338938884837653

Epoch: 6| Step: 2
Training loss: 3.033194065093994
Validation loss: 2.1242080503894436

Epoch: 6| Step: 3
Training loss: 2.2605414390563965
Validation loss: 2.1305488668462282

Epoch: 6| Step: 4
Training loss: 2.976336717605591
Validation loss: 2.108524675010353

Epoch: 6| Step: 5
Training loss: 2.4528305530548096
Validation loss: 2.114226605302544

Epoch: 6| Step: 6
Training loss: 2.6300048828125
Validation loss: 2.1193372331639773

Epoch: 6| Step: 7
Training loss: 2.270516872406006
Validation loss: 2.122304256244372

Epoch: 6| Step: 8
Training loss: 1.9768633842468262
Validation loss: 2.111077534255161

Epoch: 6| Step: 9
Training loss: 2.264247417449951
Validation loss: 2.1018366647023026

Epoch: 6| Step: 10
Training loss: 2.463813304901123
Validation loss: 2.0994910552937496

Epoch: 6| Step: 11
Training loss: 2.611009120941162
Validation loss: 2.0913617816022647

Epoch: 6| Step: 12
Training loss: 2.383244752883911
Validation loss: 2.0760888373979958

Epoch: 6| Step: 13
Training loss: 3.1834332942962646
Validation loss: 2.0766211555850123

Epoch: 22| Step: 0
Training loss: 2.13940691947937
Validation loss: 2.0882887994089434

Epoch: 6| Step: 1
Training loss: 2.385709285736084
Validation loss: 2.0807363346058834

Epoch: 6| Step: 2
Training loss: 2.57163143157959
Validation loss: 2.0835191716430006

Epoch: 6| Step: 3
Training loss: 2.7657361030578613
Validation loss: 2.0729136325979747

Epoch: 6| Step: 4
Training loss: 2.269674301147461
Validation loss: 2.0633457758093394

Epoch: 6| Step: 5
Training loss: 2.9274020195007324
Validation loss: 2.070476826801095

Epoch: 6| Step: 6
Training loss: 2.758889675140381
Validation loss: 2.0626198732724754

Epoch: 6| Step: 7
Training loss: 2.373660087585449
Validation loss: 2.0603542225335234

Epoch: 6| Step: 8
Training loss: 1.8465871810913086
Validation loss: 2.057289095335109

Epoch: 6| Step: 9
Training loss: 2.5909557342529297
Validation loss: 2.0667127511834584

Epoch: 6| Step: 10
Training loss: 2.421663284301758
Validation loss: 2.0594128613830893

Epoch: 6| Step: 11
Training loss: 2.4508628845214844
Validation loss: 2.0506513298198743

Epoch: 6| Step: 12
Training loss: 2.3297438621520996
Validation loss: 2.060291979902534

Epoch: 6| Step: 13
Training loss: 3.508399724960327
Validation loss: 2.043794346112077

Epoch: 23| Step: 0
Training loss: 2.5934267044067383
Validation loss: 2.050319666503578

Epoch: 6| Step: 1
Training loss: 3.01479434967041
Validation loss: 2.063315950414186

Epoch: 6| Step: 2
Training loss: 1.6472911834716797
Validation loss: 2.037906587764781

Epoch: 6| Step: 3
Training loss: 2.9955966472625732
Validation loss: 2.0512008538810154

Epoch: 6| Step: 4
Training loss: 2.67519474029541
Validation loss: 2.03922616025453

Epoch: 6| Step: 5
Training loss: 2.2620849609375
Validation loss: 2.0533143884392193

Epoch: 6| Step: 6
Training loss: 2.538477897644043
Validation loss: 2.049785021812685

Epoch: 6| Step: 7
Training loss: 2.189218759536743
Validation loss: 2.036686561440909

Epoch: 6| Step: 8
Training loss: 2.9660298824310303
Validation loss: 2.0340476548799904

Epoch: 6| Step: 9
Training loss: 2.553128957748413
Validation loss: 2.033919483102778

Epoch: 6| Step: 10
Training loss: 2.4895505905151367
Validation loss: 2.032660702223419

Epoch: 6| Step: 11
Training loss: 2.059648036956787
Validation loss: 2.03064836225202

Epoch: 6| Step: 12
Training loss: 2.7073464393615723
Validation loss: 2.0377857761998333

Epoch: 6| Step: 13
Training loss: 1.855450987815857
Validation loss: 2.047305158389512

Epoch: 24| Step: 0
Training loss: 2.0755162239074707
Validation loss: 2.0322477868808213

Epoch: 6| Step: 1
Training loss: 2.8567514419555664
Validation loss: 2.0364234037296747

Epoch: 6| Step: 2
Training loss: 2.722698926925659
Validation loss: 2.0346898276318788

Epoch: 6| Step: 3
Training loss: 2.7138819694519043
Validation loss: 2.0395123958587646

Epoch: 6| Step: 4
Training loss: 2.365795850753784
Validation loss: 2.032897028871762

Epoch: 6| Step: 5
Training loss: 2.441929817199707
Validation loss: 2.034777069604525

Epoch: 6| Step: 6
Training loss: 2.5893263816833496
Validation loss: 2.0347146577732538

Epoch: 6| Step: 7
Training loss: 2.1837587356567383
Validation loss: 2.050231751575265

Epoch: 6| Step: 8
Training loss: 2.5586180686950684
Validation loss: 2.042519241250971

Epoch: 6| Step: 9
Training loss: 2.2114944458007812
Validation loss: 2.049970817822282

Epoch: 6| Step: 10
Training loss: 2.114410400390625
Validation loss: 2.0338956937995007

Epoch: 6| Step: 11
Training loss: 2.5964653491973877
Validation loss: 2.041577390445176

Epoch: 6| Step: 12
Training loss: 2.7719969749450684
Validation loss: 2.031932484719061

Epoch: 6| Step: 13
Training loss: 2.593716859817505
Validation loss: 2.044700580258523

Epoch: 25| Step: 0
Training loss: 2.4864354133605957
Validation loss: 2.040998146098147

Epoch: 6| Step: 1
Training loss: 2.1828622817993164
Validation loss: 2.0333581637310725

Epoch: 6| Step: 2
Training loss: 2.737234592437744
Validation loss: 2.039462343338997

Epoch: 6| Step: 3
Training loss: 3.1761209964752197
Validation loss: 2.0356768254310853

Epoch: 6| Step: 4
Training loss: 2.978283166885376
Validation loss: 2.0424717369899956

Epoch: 6| Step: 5
Training loss: 1.958085060119629
Validation loss: 2.046138894173407

Epoch: 6| Step: 6
Training loss: 2.1238012313842773
Validation loss: 2.0448827589711835

Epoch: 6| Step: 7
Training loss: 2.321464776992798
Validation loss: 2.033550931561378

Epoch: 6| Step: 8
Training loss: 2.7457780838012695
Validation loss: 2.037584807283135

Epoch: 6| Step: 9
Training loss: 2.0181803703308105
Validation loss: 2.035467883592011

Epoch: 6| Step: 10
Training loss: 2.7130050659179688
Validation loss: 2.043087378624947

Epoch: 6| Step: 11
Training loss: 2.52099871635437
Validation loss: 2.036175953444614

Epoch: 6| Step: 12
Training loss: 2.025689125061035
Validation loss: 2.0353319593655166

Epoch: 6| Step: 13
Training loss: 3.107835292816162
Validation loss: 2.030600837481919

Epoch: 26| Step: 0
Training loss: 2.1648621559143066
Validation loss: 2.0354455260820288

Epoch: 6| Step: 1
Training loss: 3.001269817352295
Validation loss: 2.0389108427109255

Epoch: 6| Step: 2
Training loss: 2.1592085361480713
Validation loss: 2.0244825783596245

Epoch: 6| Step: 3
Training loss: 2.476844310760498
Validation loss: 2.051723272569718

Epoch: 6| Step: 4
Training loss: 2.2989439964294434
Validation loss: 2.024697729336318

Epoch: 6| Step: 5
Training loss: 2.3119635581970215
Validation loss: 2.0262207138922905

Epoch: 6| Step: 6
Training loss: 1.8650611639022827
Validation loss: 2.024543087969544

Epoch: 6| Step: 7
Training loss: 2.0140695571899414
Validation loss: 2.046966783462032

Epoch: 6| Step: 8
Training loss: 2.3137943744659424
Validation loss: 2.041038836202314

Epoch: 6| Step: 9
Training loss: 2.645026206970215
Validation loss: 2.040103466280045

Epoch: 6| Step: 10
Training loss: 3.056234359741211
Validation loss: 2.033844965760426

Epoch: 6| Step: 11
Training loss: 2.4716262817382812
Validation loss: 2.0376303144680556

Epoch: 6| Step: 12
Training loss: 3.1685380935668945
Validation loss: 2.0331508677492858

Epoch: 6| Step: 13
Training loss: 2.788804054260254
Validation loss: 2.0348068949996785

Epoch: 27| Step: 0
Training loss: 2.5338969230651855
Validation loss: 2.031393407493509

Epoch: 6| Step: 1
Training loss: 2.9599204063415527
Validation loss: 2.040427613001998

Epoch: 6| Step: 2
Training loss: 2.9825031757354736
Validation loss: 2.0279933021914576

Epoch: 6| Step: 3
Training loss: 2.0793251991271973
Validation loss: 2.0319487817825808

Epoch: 6| Step: 4
Training loss: 2.30846905708313
Validation loss: 2.040348691325034

Epoch: 6| Step: 5
Training loss: 2.4719433784484863
Validation loss: 2.047478110559525

Epoch: 6| Step: 6
Training loss: 2.1573479175567627
Validation loss: 2.0354385581067813

Epoch: 6| Step: 7
Training loss: 2.446442127227783
Validation loss: 2.045982430058141

Epoch: 6| Step: 8
Training loss: 2.1204605102539062
Validation loss: 2.04112135723073

Epoch: 6| Step: 9
Training loss: 2.1715242862701416
Validation loss: 2.0546176638654483

Epoch: 6| Step: 10
Training loss: 2.6699066162109375
Validation loss: 2.0499169300961237

Epoch: 6| Step: 11
Training loss: 1.7510364055633545
Validation loss: 2.0421834581641742

Epoch: 6| Step: 12
Training loss: 3.0793087482452393
Validation loss: 2.046978081426313

Epoch: 6| Step: 13
Training loss: 3.1492795944213867
Validation loss: 2.0509211171057915

Epoch: 28| Step: 0
Training loss: 1.9083240032196045
Validation loss: 2.0566094306207474

Epoch: 6| Step: 1
Training loss: 2.2189016342163086
Validation loss: 2.0566660422150806

Epoch: 6| Step: 2
Training loss: 2.9802398681640625
Validation loss: 2.0355587287615706

Epoch: 6| Step: 3
Training loss: 2.231781482696533
Validation loss: 2.042634000060379

Epoch: 6| Step: 4
Training loss: 2.6595685482025146
Validation loss: 2.030263138073747

Epoch: 6| Step: 5
Training loss: 2.290181875228882
Validation loss: 2.0450010453501055

Epoch: 6| Step: 6
Training loss: 2.282768726348877
Validation loss: 2.0357037128940707

Epoch: 6| Step: 7
Training loss: 2.0373058319091797
Validation loss: 2.0434794823328652

Epoch: 6| Step: 8
Training loss: 3.0746781826019287
Validation loss: 2.0200173752282256

Epoch: 6| Step: 9
Training loss: 2.584291458129883
Validation loss: 2.031991804799726

Epoch: 6| Step: 10
Training loss: 2.8902587890625
Validation loss: 2.0413958205971667

Epoch: 6| Step: 11
Training loss: 2.414727210998535
Validation loss: 2.0420792205359346

Epoch: 6| Step: 12
Training loss: 2.495354652404785
Validation loss: 2.0377351596791256

Epoch: 6| Step: 13
Training loss: 2.6150522232055664
Validation loss: 2.033319107947811

Epoch: 29| Step: 0
Training loss: 2.6754257678985596
Validation loss: 2.03612587528844

Epoch: 6| Step: 1
Training loss: 2.3671884536743164
Validation loss: 2.0354846421108452

Epoch: 6| Step: 2
Training loss: 3.3604049682617188
Validation loss: 2.031444744397235

Epoch: 6| Step: 3
Training loss: 2.576207160949707
Validation loss: 2.0295662905580256

Epoch: 6| Step: 4
Training loss: 2.225905179977417
Validation loss: 2.0194135865857525

Epoch: 6| Step: 5
Training loss: 2.670490264892578
Validation loss: 2.0257622682920067

Epoch: 6| Step: 6
Training loss: 2.745307207107544
Validation loss: 2.0170251554058445

Epoch: 6| Step: 7
Training loss: 2.634993553161621
Validation loss: 2.026683217735701

Epoch: 6| Step: 8
Training loss: 2.097925901412964
Validation loss: 2.0225205626539005

Epoch: 6| Step: 9
Training loss: 2.535806655883789
Validation loss: 2.0231883064393075

Epoch: 6| Step: 10
Training loss: 1.9366940259933472
Validation loss: 2.0316130858595653

Epoch: 6| Step: 11
Training loss: 2.1864893436431885
Validation loss: 2.0317763525952577

Epoch: 6| Step: 12
Training loss: 2.388155937194824
Validation loss: 2.0456328315119587

Epoch: 6| Step: 13
Training loss: 1.8109101057052612
Validation loss: 2.038874732550754

Epoch: 30| Step: 0
Training loss: 2.3138418197631836
Validation loss: 2.023467743268577

Epoch: 6| Step: 1
Training loss: 2.292222499847412
Validation loss: 2.029947820530143

Epoch: 6| Step: 2
Training loss: 2.7475695610046387
Validation loss: 2.0385812674799273

Epoch: 6| Step: 3
Training loss: 2.6742637157440186
Validation loss: 2.0262572521804483

Epoch: 6| Step: 4
Training loss: 3.1672940254211426
Validation loss: 2.026577006104172

Epoch: 6| Step: 5
Training loss: 2.421668529510498
Validation loss: 2.023491956854379

Epoch: 6| Step: 6
Training loss: 2.4215340614318848
Validation loss: 2.03022373748082

Epoch: 6| Step: 7
Training loss: 2.534085988998413
Validation loss: 2.0313771527300597

Epoch: 6| Step: 8
Training loss: 1.8073357343673706
Validation loss: 2.023761519821741

Epoch: 6| Step: 9
Training loss: 1.9921480417251587
Validation loss: 2.0283284302680724

Epoch: 6| Step: 10
Training loss: 2.825502634048462
Validation loss: 2.038261684038306

Epoch: 6| Step: 11
Training loss: 2.7422704696655273
Validation loss: 2.033502265971194

Epoch: 6| Step: 12
Training loss: 2.277304172515869
Validation loss: 2.0247691856917513

Epoch: 6| Step: 13
Training loss: 2.203986644744873
Validation loss: 2.0425393119935067

Epoch: 31| Step: 0
Training loss: 2.640598773956299
Validation loss: 2.025050256841926

Epoch: 6| Step: 1
Training loss: 2.37735652923584
Validation loss: 2.017745985779711

Epoch: 6| Step: 2
Training loss: 2.2908921241760254
Validation loss: 2.024492476576118

Epoch: 6| Step: 3
Training loss: 3.175408363342285
Validation loss: 2.0302815321953065

Epoch: 6| Step: 4
Training loss: 2.443819046020508
Validation loss: 2.0332086970729213

Epoch: 6| Step: 5
Training loss: 2.6186885833740234
Validation loss: 2.0255691082246843

Epoch: 6| Step: 6
Training loss: 2.406111717224121
Validation loss: 2.0378909444296234

Epoch: 6| Step: 7
Training loss: 1.9434477090835571
Validation loss: 2.0316837013408704

Epoch: 6| Step: 8
Training loss: 2.7300710678100586
Validation loss: 2.0273547621183496

Epoch: 6| Step: 9
Training loss: 2.0408968925476074
Validation loss: 2.039626652194608

Epoch: 6| Step: 10
Training loss: 2.1949782371520996
Validation loss: 2.034261152308474

Epoch: 6| Step: 11
Training loss: 2.015768051147461
Validation loss: 2.025764198713405

Epoch: 6| Step: 12
Training loss: 2.887803554534912
Validation loss: 2.0224053654619443

Epoch: 6| Step: 13
Training loss: 2.6661934852600098
Validation loss: 2.035274790179345

Epoch: 32| Step: 0
Training loss: 2.1795578002929688
Validation loss: 2.0146980695827033

Epoch: 6| Step: 1
Training loss: 1.866838812828064
Validation loss: 2.024566635008781

Epoch: 6| Step: 2
Training loss: 2.1873726844787598
Validation loss: 2.0226755385757773

Epoch: 6| Step: 3
Training loss: 3.3397722244262695
Validation loss: 2.028196757839572

Epoch: 6| Step: 4
Training loss: 2.8825807571411133
Validation loss: 2.025862378458823

Epoch: 6| Step: 5
Training loss: 2.7843947410583496
Validation loss: 2.0351021392371065

Epoch: 6| Step: 6
Training loss: 2.3375914096832275
Validation loss: 2.026426761381088

Epoch: 6| Step: 7
Training loss: 2.5779078006744385
Validation loss: 2.0229188370448288

Epoch: 6| Step: 8
Training loss: 2.0933022499084473
Validation loss: 2.0130064692548526

Epoch: 6| Step: 9
Training loss: 2.854081153869629
Validation loss: 2.027598971961647

Epoch: 6| Step: 10
Training loss: 2.292567729949951
Validation loss: 2.0237642436899166

Epoch: 6| Step: 11
Training loss: 2.505314826965332
Validation loss: 2.0343779953577186

Epoch: 6| Step: 12
Training loss: 2.1183338165283203
Validation loss: 2.024907135194348

Epoch: 6| Step: 13
Training loss: 2.1764299869537354
Validation loss: 2.019430209231633

Epoch: 33| Step: 0
Training loss: 2.71332049369812
Validation loss: 2.0332741993729786

Epoch: 6| Step: 1
Training loss: 2.3503432273864746
Validation loss: 2.023310451097386

Epoch: 6| Step: 2
Training loss: 3.14479923248291
Validation loss: 2.0138434081949215

Epoch: 6| Step: 3
Training loss: 1.6806386709213257
Validation loss: 2.0208531297663206

Epoch: 6| Step: 4
Training loss: 2.1141839027404785
Validation loss: 2.0135003802596882

Epoch: 6| Step: 5
Training loss: 2.466982126235962
Validation loss: 2.0040998535771526

Epoch: 6| Step: 6
Training loss: 2.5470354557037354
Validation loss: 2.0100958026865476

Epoch: 6| Step: 7
Training loss: 2.445955753326416
Validation loss: 2.01048723600244

Epoch: 6| Step: 8
Training loss: 2.9922289848327637
Validation loss: 2.020067127802039

Epoch: 6| Step: 9
Training loss: 2.371830463409424
Validation loss: 2.0134147059532905

Epoch: 6| Step: 10
Training loss: 2.184267997741699
Validation loss: 2.0222359395796254

Epoch: 6| Step: 11
Training loss: 2.76525616645813
Validation loss: 2.0190750847580614

Epoch: 6| Step: 12
Training loss: 2.2622923851013184
Validation loss: 2.019093426324988

Epoch: 6| Step: 13
Training loss: 2.1343655586242676
Validation loss: 2.0131266232459777

Epoch: 34| Step: 0
Training loss: 1.8325996398925781
Validation loss: 2.0051247483940533

Epoch: 6| Step: 1
Training loss: 1.981818675994873
Validation loss: 2.0168544220668014

Epoch: 6| Step: 2
Training loss: 2.6085174083709717
Validation loss: 2.0042025927574403

Epoch: 6| Step: 3
Training loss: 2.150689125061035
Validation loss: 2.0202416604565037

Epoch: 6| Step: 4
Training loss: 3.015549898147583
Validation loss: 2.01101468839953

Epoch: 6| Step: 5
Training loss: 2.4833855628967285
Validation loss: 2.0217341607616794

Epoch: 6| Step: 6
Training loss: 2.394592046737671
Validation loss: 2.0103046330072547

Epoch: 6| Step: 7
Training loss: 2.4399142265319824
Validation loss: 2.0116468526983775

Epoch: 6| Step: 8
Training loss: 2.5876870155334473
Validation loss: 2.0083100180472098

Epoch: 6| Step: 9
Training loss: 3.214726448059082
Validation loss: 2.024559674724456

Epoch: 6| Step: 10
Training loss: 2.057682991027832
Validation loss: 2.008765579551779

Epoch: 6| Step: 11
Training loss: 2.3619794845581055
Validation loss: 2.012485937405658

Epoch: 6| Step: 12
Training loss: 2.4652669429779053
Validation loss: 2.022541945980441

Epoch: 6| Step: 13
Training loss: 2.806324005126953
Validation loss: 2.023408812861289

Epoch: 35| Step: 0
Training loss: 1.630707025527954
Validation loss: 2.021732904577768

Epoch: 6| Step: 1
Training loss: 2.6847047805786133
Validation loss: 2.007496964546942

Epoch: 6| Step: 2
Training loss: 2.509498119354248
Validation loss: 2.0141110317681425

Epoch: 6| Step: 3
Training loss: 2.5049805641174316
Validation loss: 2.0215122392100673

Epoch: 6| Step: 4
Training loss: 2.330752372741699
Validation loss: 2.0120667488344255

Epoch: 6| Step: 5
Training loss: 2.2170777320861816
Validation loss: 2.019108397986299

Epoch: 6| Step: 6
Training loss: 2.594254493713379
Validation loss: 2.030639893265181

Epoch: 6| Step: 7
Training loss: 2.5218586921691895
Validation loss: 2.0110189940339778

Epoch: 6| Step: 8
Training loss: 2.345188617706299
Validation loss: 2.0176880269922237

Epoch: 6| Step: 9
Training loss: 2.5708119869232178
Validation loss: 2.0220309906108405

Epoch: 6| Step: 10
Training loss: 3.0101311206817627
Validation loss: 2.026078777928506

Epoch: 6| Step: 11
Training loss: 1.9283467531204224
Validation loss: 2.009148233680315

Epoch: 6| Step: 12
Training loss: 2.94791841506958
Validation loss: 2.0124171703092513

Epoch: 6| Step: 13
Training loss: 2.481053113937378
Validation loss: 2.0283783635785504

Epoch: 36| Step: 0
Training loss: 2.077925682067871
Validation loss: 2.029850980286957

Epoch: 6| Step: 1
Training loss: 2.4566733837127686
Validation loss: 2.0175377297145065

Epoch: 6| Step: 2
Training loss: 3.0714874267578125
Validation loss: 2.0280570112248903

Epoch: 6| Step: 3
Training loss: 2.8541817665100098
Validation loss: 2.025358735874135

Epoch: 6| Step: 4
Training loss: 2.2144722938537598
Validation loss: 2.026978877282912

Epoch: 6| Step: 5
Training loss: 2.1134328842163086
Validation loss: 2.02685579305054

Epoch: 6| Step: 6
Training loss: 1.6185600757598877
Validation loss: 2.03235278847397

Epoch: 6| Step: 7
Training loss: 2.670091390609741
Validation loss: 2.042599880567161

Epoch: 6| Step: 8
Training loss: 2.5455002784729004
Validation loss: 2.0134807427724204

Epoch: 6| Step: 9
Training loss: 2.289829730987549
Validation loss: 2.0192208956646662

Epoch: 6| Step: 10
Training loss: 2.64457631111145
Validation loss: 2.029098044159592

Epoch: 6| Step: 11
Training loss: 2.488154888153076
Validation loss: 2.029961350143597

Epoch: 6| Step: 12
Training loss: 2.586275100708008
Validation loss: 2.018508626568702

Epoch: 6| Step: 13
Training loss: 2.5135011672973633
Validation loss: 2.0208463233004332

Epoch: 37| Step: 0
Training loss: 2.6052443981170654
Validation loss: 2.0125765390293573

Epoch: 6| Step: 1
Training loss: 2.135157823562622
Validation loss: 2.025617155977475

Epoch: 6| Step: 2
Training loss: 2.371288299560547
Validation loss: 2.033168130023505

Epoch: 6| Step: 3
Training loss: 2.1897597312927246
Validation loss: 2.028292503408206

Epoch: 6| Step: 4
Training loss: 2.304978847503662
Validation loss: 2.0209724518560592

Epoch: 6| Step: 5
Training loss: 2.7816169261932373
Validation loss: 2.0352261463801065

Epoch: 6| Step: 6
Training loss: 2.1939566135406494
Validation loss: 2.031008816534473

Epoch: 6| Step: 7
Training loss: 2.3582942485809326
Validation loss: 2.0282127934117473

Epoch: 6| Step: 8
Training loss: 2.9099738597869873
Validation loss: 2.0144101048028595

Epoch: 6| Step: 9
Training loss: 2.3787732124328613
Validation loss: 2.0256573538626395

Epoch: 6| Step: 10
Training loss: 2.342005968093872
Validation loss: 2.0415264380875455

Epoch: 6| Step: 11
Training loss: 2.8973066806793213
Validation loss: 2.0323849339638986

Epoch: 6| Step: 12
Training loss: 2.009186029434204
Validation loss: 2.031915421126991

Epoch: 6| Step: 13
Training loss: 2.485607862472534
Validation loss: 2.021995782852173

Epoch: 38| Step: 0
Training loss: 2.752047061920166
Validation loss: 2.0290054967326503

Epoch: 6| Step: 1
Training loss: 2.0636966228485107
Validation loss: 2.0161176471300024

Epoch: 6| Step: 2
Training loss: 2.0861446857452393
Validation loss: 2.0265233914057412

Epoch: 6| Step: 3
Training loss: 2.8262500762939453
Validation loss: 2.014391400480783

Epoch: 6| Step: 4
Training loss: 2.8713464736938477
Validation loss: 2.024683751085753

Epoch: 6| Step: 5
Training loss: 2.524904727935791
Validation loss: 2.02004833375254

Epoch: 6| Step: 6
Training loss: 2.371255874633789
Validation loss: 2.025169413576844

Epoch: 6| Step: 7
Training loss: 2.13075852394104
Validation loss: 2.0212571441486316

Epoch: 6| Step: 8
Training loss: 2.558363199234009
Validation loss: 2.0204455801235732

Epoch: 6| Step: 9
Training loss: 2.407832622528076
Validation loss: 2.0207955747522335

Epoch: 6| Step: 10
Training loss: 2.1208860874176025
Validation loss: 2.032903684082852

Epoch: 6| Step: 11
Training loss: 2.511059522628784
Validation loss: 2.0280980679296676

Epoch: 6| Step: 12
Training loss: 2.397869110107422
Validation loss: 2.028310970593524

Epoch: 6| Step: 13
Training loss: 2.2459826469421387
Validation loss: 2.018039716187344

Epoch: 39| Step: 0
Training loss: 2.693753242492676
Validation loss: 2.0272312830853205

Epoch: 6| Step: 1
Training loss: 2.5018513202667236
Validation loss: 2.0129641243206557

Epoch: 6| Step: 2
Training loss: 1.9568383693695068
Validation loss: 2.005901969889159

Epoch: 6| Step: 3
Training loss: 2.7175042629241943
Validation loss: 2.0232477149655743

Epoch: 6| Step: 4
Training loss: 1.968883752822876
Validation loss: 2.018251927950049

Epoch: 6| Step: 5
Training loss: 2.3471360206604004
Validation loss: 2.0145287206096034

Epoch: 6| Step: 6
Training loss: 2.127807378768921
Validation loss: 2.001603223944223

Epoch: 6| Step: 7
Training loss: 2.2747340202331543
Validation loss: 2.000934577757312

Epoch: 6| Step: 8
Training loss: 2.2297263145446777
Validation loss: 2.007537446996217

Epoch: 6| Step: 9
Training loss: 2.572805643081665
Validation loss: 2.0265839625430364

Epoch: 6| Step: 10
Training loss: 2.3505215644836426
Validation loss: 2.0129366997749574

Epoch: 6| Step: 11
Training loss: 2.807112693786621
Validation loss: 2.013699463618699

Epoch: 6| Step: 12
Training loss: 2.905097007751465
Validation loss: 2.0079905679149013

Epoch: 6| Step: 13
Training loss: 2.5319104194641113
Validation loss: 2.0195829688861804

Epoch: 40| Step: 0
Training loss: 2.0007033348083496
Validation loss: 2.006601163136062

Epoch: 6| Step: 1
Training loss: 2.239011287689209
Validation loss: 2.0097345459845757

Epoch: 6| Step: 2
Training loss: 2.959970474243164
Validation loss: 2.011025586435872

Epoch: 6| Step: 3
Training loss: 2.091151237487793
Validation loss: 2.0131811839278027

Epoch: 6| Step: 4
Training loss: 2.7141151428222656
Validation loss: 2.014714451246364

Epoch: 6| Step: 5
Training loss: 2.603011131286621
Validation loss: 2.0144964815467916

Epoch: 6| Step: 6
Training loss: 2.163278102874756
Validation loss: 2.020940911385321

Epoch: 6| Step: 7
Training loss: 2.0311226844787598
Validation loss: 2.0116856854449034

Epoch: 6| Step: 8
Training loss: 2.6102075576782227
Validation loss: 2.0117579224289104

Epoch: 6| Step: 9
Training loss: 2.583164691925049
Validation loss: 2.014868788821723

Epoch: 6| Step: 10
Training loss: 2.220329523086548
Validation loss: 2.022662901109265

Epoch: 6| Step: 11
Training loss: 2.610198497772217
Validation loss: 2.0154913497227493

Epoch: 6| Step: 12
Training loss: 2.1250152587890625
Validation loss: 2.01729481450973

Epoch: 6| Step: 13
Training loss: 3.179337739944458
Validation loss: 2.0178746023485736

Epoch: 41| Step: 0
Training loss: 2.394023895263672
Validation loss: 2.0047597769768006

Epoch: 6| Step: 1
Training loss: 2.607161521911621
Validation loss: 2.017123629969935

Epoch: 6| Step: 2
Training loss: 2.1731579303741455
Validation loss: 2.032321762013179

Epoch: 6| Step: 3
Training loss: 2.9119455814361572
Validation loss: 2.000788629695933

Epoch: 6| Step: 4
Training loss: 1.536756992340088
Validation loss: 2.0221472158226916

Epoch: 6| Step: 5
Training loss: 2.3476531505584717
Validation loss: 2.0125056902567544

Epoch: 6| Step: 6
Training loss: 2.3002758026123047
Validation loss: 2.0097766307092484

Epoch: 6| Step: 7
Training loss: 1.9466369152069092
Validation loss: 2.024623856749586

Epoch: 6| Step: 8
Training loss: 2.94846248626709
Validation loss: 2.0298290470595

Epoch: 6| Step: 9
Training loss: 2.6298604011535645
Validation loss: 2.022625305319345

Epoch: 6| Step: 10
Training loss: 2.4390106201171875
Validation loss: 2.028182529634045

Epoch: 6| Step: 11
Training loss: 2.8994874954223633
Validation loss: 2.0173967653705227

Epoch: 6| Step: 12
Training loss: 2.108006477355957
Validation loss: 2.0238960289186045

Epoch: 6| Step: 13
Training loss: 2.642951488494873
Validation loss: 2.022479032957426

Epoch: 42| Step: 0
Training loss: 2.8024041652679443
Validation loss: 2.0188535926162556

Epoch: 6| Step: 1
Training loss: 2.276519298553467
Validation loss: 2.0076270052181777

Epoch: 6| Step: 2
Training loss: 2.581937789916992
Validation loss: 2.0079282701656385

Epoch: 6| Step: 3
Training loss: 2.769834280014038
Validation loss: 2.022038318777597

Epoch: 6| Step: 4
Training loss: 2.3643336296081543
Validation loss: 2.020198336211584

Epoch: 6| Step: 5
Training loss: 3.2385311126708984
Validation loss: 2.023323848683347

Epoch: 6| Step: 6
Training loss: 1.4583227634429932
Validation loss: 2.0174374798292756

Epoch: 6| Step: 7
Training loss: 2.07816743850708
Validation loss: 2.0108571360188146

Epoch: 6| Step: 8
Training loss: 2.018721103668213
Validation loss: 2.0177411751080583

Epoch: 6| Step: 9
Training loss: 2.5385727882385254
Validation loss: 2.03010836467948

Epoch: 6| Step: 10
Training loss: 2.3617441654205322
Validation loss: 2.0301144264077626

Epoch: 6| Step: 11
Training loss: 2.6118109226226807
Validation loss: 2.0177675242065103

Epoch: 6| Step: 12
Training loss: 2.2875773906707764
Validation loss: 2.0216000362109114

Epoch: 6| Step: 13
Training loss: 2.5344667434692383
Validation loss: 2.016724717232489

Epoch: 43| Step: 0
Training loss: 2.4112789630889893
Validation loss: 2.0140624725690452

Epoch: 6| Step: 1
Training loss: 1.900515079498291
Validation loss: 2.0163146757310435

Epoch: 6| Step: 2
Training loss: 2.098039388656616
Validation loss: 2.0370764399087555

Epoch: 6| Step: 3
Training loss: 3.003887176513672
Validation loss: 2.0055083984969766

Epoch: 6| Step: 4
Training loss: 2.6508734226226807
Validation loss: 2.017302123449182

Epoch: 6| Step: 5
Training loss: 1.9651679992675781
Validation loss: 2.025148222523351

Epoch: 6| Step: 6
Training loss: 2.4099674224853516
Validation loss: 1.9987931892436037

Epoch: 6| Step: 7
Training loss: 2.465604305267334
Validation loss: 1.9957911570866902

Epoch: 6| Step: 8
Training loss: 2.8862924575805664
Validation loss: 2.0174365364095217

Epoch: 6| Step: 9
Training loss: 2.1983814239501953
Validation loss: 1.9995258392826203

Epoch: 6| Step: 10
Training loss: 2.4475913047790527
Validation loss: 2.009306760244472

Epoch: 6| Step: 11
Training loss: 2.666003704071045
Validation loss: 2.0099177309261855

Epoch: 6| Step: 12
Training loss: 2.492419719696045
Validation loss: 2.0005016929359845

Epoch: 6| Step: 13
Training loss: 1.9573683738708496
Validation loss: 2.003366231918335

Epoch: 44| Step: 0
Training loss: 2.354614734649658
Validation loss: 1.9915253423875379

Epoch: 6| Step: 1
Training loss: 2.0417943000793457
Validation loss: 1.9943746353990288

Epoch: 6| Step: 2
Training loss: 2.1657230854034424
Validation loss: 2.0006566688578618

Epoch: 6| Step: 3
Training loss: 1.7536206245422363
Validation loss: 2.005435230911419

Epoch: 6| Step: 4
Training loss: 2.3073315620422363
Validation loss: 2.008245342521257

Epoch: 6| Step: 5
Training loss: 2.490494728088379
Validation loss: 1.9935817590323828

Epoch: 6| Step: 6
Training loss: 2.5496985912323
Validation loss: 2.005954332249139

Epoch: 6| Step: 7
Training loss: 2.6438751220703125
Validation loss: 2.007069359543503

Epoch: 6| Step: 8
Training loss: 2.8232622146606445
Validation loss: 2.010047076850809

Epoch: 6| Step: 9
Training loss: 2.1105918884277344
Validation loss: 2.0088925297542284

Epoch: 6| Step: 10
Training loss: 2.71280574798584
Validation loss: 1.997049198355726

Epoch: 6| Step: 11
Training loss: 2.483163356781006
Validation loss: 2.0107720898043726

Epoch: 6| Step: 12
Training loss: 2.972078800201416
Validation loss: 2.009730382632184

Epoch: 6| Step: 13
Training loss: 2.1459555625915527
Validation loss: 2.00092000474212

Epoch: 45| Step: 0
Training loss: 2.194746255874634
Validation loss: 2.0027715160000708

Epoch: 6| Step: 1
Training loss: 2.223123550415039
Validation loss: 2.010378732476183

Epoch: 6| Step: 2
Training loss: 2.035560131072998
Validation loss: 1.9992547753036662

Epoch: 6| Step: 3
Training loss: 2.2915725708007812
Validation loss: 1.9968161198400682

Epoch: 6| Step: 4
Training loss: 1.7010180950164795
Validation loss: 2.004463267582719

Epoch: 6| Step: 5
Training loss: 2.643636703491211
Validation loss: 2.0046443977663593

Epoch: 6| Step: 6
Training loss: 2.355576515197754
Validation loss: 1.9915893654669485

Epoch: 6| Step: 7
Training loss: 2.8002917766571045
Validation loss: 2.0021065460738314

Epoch: 6| Step: 8
Training loss: 2.422567367553711
Validation loss: 1.991210029971215

Epoch: 6| Step: 9
Training loss: 2.917893409729004
Validation loss: 1.9877381427313692

Epoch: 6| Step: 10
Training loss: 2.1265757083892822
Validation loss: 1.981341141526417

Epoch: 6| Step: 11
Training loss: 2.6437630653381348
Validation loss: 1.9991707186545096

Epoch: 6| Step: 12
Training loss: 2.614973783493042
Validation loss: 1.9893154687778924

Epoch: 6| Step: 13
Training loss: 2.884690999984741
Validation loss: 1.9890627425204042

Epoch: 46| Step: 0
Training loss: 1.91641104221344
Validation loss: 1.982861336841378

Epoch: 6| Step: 1
Training loss: 2.384044885635376
Validation loss: 1.9955873053560975

Epoch: 6| Step: 2
Training loss: 2.0039005279541016
Validation loss: 1.9851801856871574

Epoch: 6| Step: 3
Training loss: 2.714250087738037
Validation loss: 1.992499847565928

Epoch: 6| Step: 4
Training loss: 2.3673720359802246
Validation loss: 1.9980318251476492

Epoch: 6| Step: 5
Training loss: 3.077214241027832
Validation loss: 1.9925757108196136

Epoch: 6| Step: 6
Training loss: 2.2393593788146973
Validation loss: 1.9936056367812618

Epoch: 6| Step: 7
Training loss: 2.5833640098571777
Validation loss: 2.0037217396561817

Epoch: 6| Step: 8
Training loss: 2.1527247428894043
Validation loss: 1.9851914041785783

Epoch: 6| Step: 9
Training loss: 2.3212368488311768
Validation loss: 1.9914000393241964

Epoch: 6| Step: 10
Training loss: 2.403872489929199
Validation loss: 2.0038702693036807

Epoch: 6| Step: 11
Training loss: 2.738619804382324
Validation loss: 1.9951889322650047

Epoch: 6| Step: 12
Training loss: 2.0387260913848877
Validation loss: 1.9931784009420743

Epoch: 6| Step: 13
Training loss: 2.95241641998291
Validation loss: 1.9783476155291322

Epoch: 47| Step: 0
Training loss: 2.9156758785247803
Validation loss: 1.9927758709076913

Epoch: 6| Step: 1
Training loss: 2.331820011138916
Validation loss: 1.9979061631746189

Epoch: 6| Step: 2
Training loss: 2.1092264652252197
Validation loss: 1.9962553183237712

Epoch: 6| Step: 3
Training loss: 2.2425904273986816
Validation loss: 1.9876833205581994

Epoch: 6| Step: 4
Training loss: 1.8635858297348022
Validation loss: 1.9823219519789501

Epoch: 6| Step: 5
Training loss: 2.000319480895996
Validation loss: 1.9857101876248595

Epoch: 6| Step: 6
Training loss: 1.977996587753296
Validation loss: 2.0014409147283083

Epoch: 6| Step: 7
Training loss: 2.965847969055176
Validation loss: 1.9819693347459197

Epoch: 6| Step: 8
Training loss: 2.370333194732666
Validation loss: 1.989105914228706

Epoch: 6| Step: 9
Training loss: 2.7354159355163574
Validation loss: 1.999636321939448

Epoch: 6| Step: 10
Training loss: 2.7311058044433594
Validation loss: 1.9729846869745562

Epoch: 6| Step: 11
Training loss: 2.2695837020874023
Validation loss: 1.9824518901045605

Epoch: 6| Step: 12
Training loss: 2.8387317657470703
Validation loss: 1.984735756792048

Epoch: 6| Step: 13
Training loss: 2.097708225250244
Validation loss: 1.999621327205371

Epoch: 48| Step: 0
Training loss: 2.51497745513916
Validation loss: 1.9834358512714345

Epoch: 6| Step: 1
Training loss: 1.7139201164245605
Validation loss: 1.98842933998313

Epoch: 6| Step: 2
Training loss: 2.5517001152038574
Validation loss: 1.988420203167905

Epoch: 6| Step: 3
Training loss: 2.6856322288513184
Validation loss: 1.985204609491492

Epoch: 6| Step: 4
Training loss: 2.044586181640625
Validation loss: 1.9965670185704385

Epoch: 6| Step: 5
Training loss: 2.739476203918457
Validation loss: 1.997796667519436

Epoch: 6| Step: 6
Training loss: 2.3740622997283936
Validation loss: 1.990619562005484

Epoch: 6| Step: 7
Training loss: 2.1602895259857178
Validation loss: 1.9885780888219033

Epoch: 6| Step: 8
Training loss: 2.245448589324951
Validation loss: 1.9768070969530331

Epoch: 6| Step: 9
Training loss: 2.6387743949890137
Validation loss: 2.0001454507150958

Epoch: 6| Step: 10
Training loss: 2.6738979816436768
Validation loss: 1.9948848550037672

Epoch: 6| Step: 11
Training loss: 2.383436679840088
Validation loss: 2.0051558222821964

Epoch: 6| Step: 12
Training loss: 2.2379024028778076
Validation loss: 1.9963016343373123

Epoch: 6| Step: 13
Training loss: 2.534320831298828
Validation loss: 2.0092223818584154

Epoch: 49| Step: 0
Training loss: 2.304044723510742
Validation loss: 1.9962915412841304

Epoch: 6| Step: 1
Training loss: 2.370366096496582
Validation loss: 2.001867454539063

Epoch: 6| Step: 2
Training loss: 2.707077980041504
Validation loss: 2.000991316251857

Epoch: 6| Step: 3
Training loss: 2.481994152069092
Validation loss: 2.0126973967398367

Epoch: 6| Step: 4
Training loss: 2.6025712490081787
Validation loss: 1.9929636601478822

Epoch: 6| Step: 5
Training loss: 2.641782760620117
Validation loss: 1.9954244552120086

Epoch: 6| Step: 6
Training loss: 2.5475845336914062
Validation loss: 2.0042305120857815

Epoch: 6| Step: 7
Training loss: 2.3903603553771973
Validation loss: 2.0111409182189615

Epoch: 6| Step: 8
Training loss: 2.4788992404937744
Validation loss: 2.0023276395695184

Epoch: 6| Step: 9
Training loss: 2.042025089263916
Validation loss: 2.0038752889120452

Epoch: 6| Step: 10
Training loss: 2.059274911880493
Validation loss: 2.0009597270719466

Epoch: 6| Step: 11
Training loss: 2.192239999771118
Validation loss: 1.9905005142252932

Epoch: 6| Step: 12
Training loss: 2.1292479038238525
Validation loss: 2.00741042629365

Epoch: 6| Step: 13
Training loss: 2.586179494857788
Validation loss: 2.0174705995026456

Epoch: 50| Step: 0
Training loss: 2.2753424644470215
Validation loss: 1.9951395937191543

Epoch: 6| Step: 1
Training loss: 2.3993382453918457
Validation loss: 2.012843907520335

Epoch: 6| Step: 2
Training loss: 1.8370640277862549
Validation loss: 2.0046003223747335

Epoch: 6| Step: 3
Training loss: 2.309346914291382
Validation loss: 2.001778873064185

Epoch: 6| Step: 4
Training loss: 2.3496813774108887
Validation loss: 2.0018207347521217

Epoch: 6| Step: 5
Training loss: 1.9970307350158691
Validation loss: 2.0132704691220353

Epoch: 6| Step: 6
Training loss: 2.722482681274414
Validation loss: 2.0180200376818256

Epoch: 6| Step: 7
Training loss: 2.29508900642395
Validation loss: 2.0166359921937347

Epoch: 6| Step: 8
Training loss: 2.484646797180176
Validation loss: 2.002873871916084

Epoch: 6| Step: 9
Training loss: 2.337347984313965
Validation loss: 2.0168688194726103

Epoch: 6| Step: 10
Training loss: 2.7814369201660156
Validation loss: 2.0093988269887944

Epoch: 6| Step: 11
Training loss: 2.5311927795410156
Validation loss: 2.0058501510209936

Epoch: 6| Step: 12
Training loss: 2.6727941036224365
Validation loss: 2.007083946658719

Epoch: 6| Step: 13
Training loss: 2.289425849914551
Validation loss: 2.000941122731855

Epoch: 51| Step: 0
Training loss: 2.0730161666870117
Validation loss: 2.0113396208773375

Epoch: 6| Step: 1
Training loss: 2.639636516571045
Validation loss: 2.0101685293259157

Epoch: 6| Step: 2
Training loss: 1.8269298076629639
Validation loss: 2.006773038577008

Epoch: 6| Step: 3
Training loss: 2.731159210205078
Validation loss: 1.9905620159641388

Epoch: 6| Step: 4
Training loss: 1.8222500085830688
Validation loss: 1.9949732826602073

Epoch: 6| Step: 5
Training loss: 3.0181658267974854
Validation loss: 2.0097694422609065

Epoch: 6| Step: 6
Training loss: 2.803342819213867
Validation loss: 1.9821718738925072

Epoch: 6| Step: 7
Training loss: 2.247866153717041
Validation loss: 1.9880070583794707

Epoch: 6| Step: 8
Training loss: 2.5145459175109863
Validation loss: 1.990433874950614

Epoch: 6| Step: 9
Training loss: 3.05179500579834
Validation loss: 1.985617611997871

Epoch: 6| Step: 10
Training loss: 1.5788307189941406
Validation loss: 1.978401050772718

Epoch: 6| Step: 11
Training loss: 2.1891016960144043
Validation loss: 1.9830240357306697

Epoch: 6| Step: 12
Training loss: 2.700366497039795
Validation loss: 1.9913706600025136

Epoch: 6| Step: 13
Training loss: 1.8066221475601196
Validation loss: 1.9948330745902112

Epoch: 52| Step: 0
Training loss: 2.433565139770508
Validation loss: 1.9851534892153997

Epoch: 6| Step: 1
Training loss: 2.5341415405273438
Validation loss: 1.9878071546554565

Epoch: 6| Step: 2
Training loss: 2.732913017272949
Validation loss: 1.9826422224762619

Epoch: 6| Step: 3
Training loss: 2.763629198074341
Validation loss: 1.998657057362218

Epoch: 6| Step: 4
Training loss: 2.5434484481811523
Validation loss: 1.978236521444013

Epoch: 6| Step: 5
Training loss: 1.9814541339874268
Validation loss: 1.9777613442431214

Epoch: 6| Step: 6
Training loss: 1.9865539073944092
Validation loss: 1.9732498058708765

Epoch: 6| Step: 7
Training loss: 3.188866138458252
Validation loss: 1.9873832220672278

Epoch: 6| Step: 8
Training loss: 2.0041356086730957
Validation loss: 1.9812103522721158

Epoch: 6| Step: 9
Training loss: 2.3421502113342285
Validation loss: 1.9729223020615116

Epoch: 6| Step: 10
Training loss: 2.153542995452881
Validation loss: 1.992082925253017

Epoch: 6| Step: 11
Training loss: 1.7254137992858887
Validation loss: 1.99396223919366

Epoch: 6| Step: 12
Training loss: 2.235267162322998
Validation loss: 1.9778094701869513

Epoch: 6| Step: 13
Training loss: 3.0043249130249023
Validation loss: 1.977683336504044

Epoch: 53| Step: 0
Training loss: 2.7820751667022705
Validation loss: 1.987269313104691

Epoch: 6| Step: 1
Training loss: 2.3459696769714355
Validation loss: 1.9864391665304861

Epoch: 6| Step: 2
Training loss: 1.7956442832946777
Validation loss: 1.9903797282967517

Epoch: 6| Step: 3
Training loss: 2.296391010284424
Validation loss: 1.9885960253336097

Epoch: 6| Step: 4
Training loss: 2.585272789001465
Validation loss: 2.001695486807054

Epoch: 6| Step: 5
Training loss: 1.7987151145935059
Validation loss: 1.9728537426199964

Epoch: 6| Step: 6
Training loss: 2.0605015754699707
Validation loss: 1.9903945410123436

Epoch: 6| Step: 7
Training loss: 3.035996198654175
Validation loss: 1.9913148815913866

Epoch: 6| Step: 8
Training loss: 2.422179698944092
Validation loss: 1.992858027899137

Epoch: 6| Step: 9
Training loss: 2.417205333709717
Validation loss: 2.001095223170455

Epoch: 6| Step: 10
Training loss: 2.635866641998291
Validation loss: 1.9858360226436327

Epoch: 6| Step: 11
Training loss: 2.3262524604797363
Validation loss: 1.9901384281855758

Epoch: 6| Step: 12
Training loss: 2.5541062355041504
Validation loss: 1.9930434355171778

Epoch: 6| Step: 13
Training loss: 1.9239720106124878
Validation loss: 1.9851438640266337

Epoch: 54| Step: 0
Training loss: 2.461622953414917
Validation loss: 1.9888315636624572

Epoch: 6| Step: 1
Training loss: 2.788018226623535
Validation loss: 2.0048954512483332

Epoch: 6| Step: 2
Training loss: 2.2567946910858154
Validation loss: 1.9827273584181262

Epoch: 6| Step: 3
Training loss: 2.4673428535461426
Validation loss: 1.9824107667451263

Epoch: 6| Step: 4
Training loss: 2.1912245750427246
Validation loss: 1.990122143940259

Epoch: 6| Step: 5
Training loss: 2.4124257564544678
Validation loss: 1.9974247383814987

Epoch: 6| Step: 6
Training loss: 2.7642834186553955
Validation loss: 1.9910590469196279

Epoch: 6| Step: 7
Training loss: 2.1087193489074707
Validation loss: 1.9663717285279305

Epoch: 6| Step: 8
Training loss: 2.663294553756714
Validation loss: 1.9904277209312684

Epoch: 6| Step: 9
Training loss: 2.694700241088867
Validation loss: 1.9978773004265242

Epoch: 6| Step: 10
Training loss: 1.7768276929855347
Validation loss: 1.9944390942973476

Epoch: 6| Step: 11
Training loss: 1.9370428323745728
Validation loss: 1.9868046314485612

Epoch: 6| Step: 12
Training loss: 2.373365640640259
Validation loss: 2.0004137023802726

Epoch: 6| Step: 13
Training loss: 2.0181820392608643
Validation loss: 1.9927021072756859

Epoch: 55| Step: 0
Training loss: 3.127635955810547
Validation loss: 1.9921703979533205

Epoch: 6| Step: 1
Training loss: 3.131648063659668
Validation loss: 1.9937655207931355

Epoch: 6| Step: 2
Training loss: 2.146394729614258
Validation loss: 1.9775279196359778

Epoch: 6| Step: 3
Training loss: 1.718783974647522
Validation loss: 1.9829776158896826

Epoch: 6| Step: 4
Training loss: 2.0158472061157227
Validation loss: 1.9770443798393331

Epoch: 6| Step: 5
Training loss: 2.6638596057891846
Validation loss: 1.9840618282236078

Epoch: 6| Step: 6
Training loss: 1.7744793891906738
Validation loss: 1.9790349621926584

Epoch: 6| Step: 7
Training loss: 1.5639922618865967
Validation loss: 1.993064292015568

Epoch: 6| Step: 8
Training loss: 1.6851975917816162
Validation loss: 1.9658853597538446

Epoch: 6| Step: 9
Training loss: 2.5781476497650146
Validation loss: 1.983726518128508

Epoch: 6| Step: 10
Training loss: 2.7932419776916504
Validation loss: 1.9830951972674298

Epoch: 6| Step: 11
Training loss: 3.195465087890625
Validation loss: 1.9705272105432325

Epoch: 6| Step: 12
Training loss: 1.8570833206176758
Validation loss: 1.9961325955647293

Epoch: 6| Step: 13
Training loss: 3.222123622894287
Validation loss: 1.9800846692054503

Epoch: 56| Step: 0
Training loss: 2.7870676517486572
Validation loss: 1.9898774700780069

Epoch: 6| Step: 1
Training loss: 2.7926254272460938
Validation loss: 1.9735385679429578

Epoch: 6| Step: 2
Training loss: 2.169222593307495
Validation loss: 1.9840457541968233

Epoch: 6| Step: 3
Training loss: 2.402398109436035
Validation loss: 1.9929194924651936

Epoch: 6| Step: 4
Training loss: 2.549625873565674
Validation loss: 1.9978711246162333

Epoch: 6| Step: 5
Training loss: 1.4393165111541748
Validation loss: 1.9786895654534782

Epoch: 6| Step: 6
Training loss: 1.9905128479003906
Validation loss: 1.9950923483858827

Epoch: 6| Step: 7
Training loss: 2.13606333732605
Validation loss: 1.9962120184334375

Epoch: 6| Step: 8
Training loss: 2.7680628299713135
Validation loss: 1.9867056082653742

Epoch: 6| Step: 9
Training loss: 2.570357322692871
Validation loss: 1.986769142971244

Epoch: 6| Step: 10
Training loss: 2.1639034748077393
Validation loss: 1.9797830197118944

Epoch: 6| Step: 11
Training loss: 2.3842430114746094
Validation loss: 1.9946245378063572

Epoch: 6| Step: 12
Training loss: 2.515805721282959
Validation loss: 1.993922536091138

Epoch: 6| Step: 13
Training loss: 2.326303005218506
Validation loss: 1.995359823267947

Epoch: 57| Step: 0
Training loss: 2.2893636226654053
Validation loss: 1.9989112936040407

Epoch: 6| Step: 1
Training loss: 1.904482126235962
Validation loss: 1.9803694832709529

Epoch: 6| Step: 2
Training loss: 2.813112735748291
Validation loss: 1.9960909120498165

Epoch: 6| Step: 3
Training loss: 1.8497941493988037
Validation loss: 1.9917822371246994

Epoch: 6| Step: 4
Training loss: 2.7051475048065186
Validation loss: 1.9773628404063563

Epoch: 6| Step: 5
Training loss: 2.095634937286377
Validation loss: 1.9937741897439445

Epoch: 6| Step: 6
Training loss: 1.8133442401885986
Validation loss: 1.9875051539431337

Epoch: 6| Step: 7
Training loss: 2.6254849433898926
Validation loss: 1.9951398693105227

Epoch: 6| Step: 8
Training loss: 2.448953151702881
Validation loss: 1.9862327101410076

Epoch: 6| Step: 9
Training loss: 1.933988094329834
Validation loss: 2.000997994535713

Epoch: 6| Step: 10
Training loss: 2.558929920196533
Validation loss: 1.990179528472244

Epoch: 6| Step: 11
Training loss: 2.8949084281921387
Validation loss: 1.9966312390501781

Epoch: 6| Step: 12
Training loss: 2.7038350105285645
Validation loss: 1.9842825089731524

Epoch: 6| Step: 13
Training loss: 2.0459413528442383
Validation loss: 1.9969181373555174

Epoch: 58| Step: 0
Training loss: 2.6681861877441406
Validation loss: 1.9807581786186463

Epoch: 6| Step: 1
Training loss: 2.639298915863037
Validation loss: 1.9986679912895284

Epoch: 6| Step: 2
Training loss: 2.187913179397583
Validation loss: 1.986647072658744

Epoch: 6| Step: 3
Training loss: 2.110743284225464
Validation loss: 1.9768853982289631

Epoch: 6| Step: 4
Training loss: 2.478119134902954
Validation loss: 1.9723353193652244

Epoch: 6| Step: 5
Training loss: 2.4583115577697754
Validation loss: 1.9916293428790184

Epoch: 6| Step: 6
Training loss: 2.269932985305786
Validation loss: 1.9903547046005086

Epoch: 6| Step: 7
Training loss: 2.478898525238037
Validation loss: 1.9695046319756457

Epoch: 6| Step: 8
Training loss: 2.01440167427063
Validation loss: 1.9840359995442052

Epoch: 6| Step: 9
Training loss: 1.730665683746338
Validation loss: 1.9827344789299914

Epoch: 6| Step: 10
Training loss: 2.400824546813965
Validation loss: 1.9839363956964144

Epoch: 6| Step: 11
Training loss: 2.5765275955200195
Validation loss: 1.9975315486231158

Epoch: 6| Step: 12
Training loss: 2.7474122047424316
Validation loss: 1.9897754833262453

Epoch: 6| Step: 13
Training loss: 1.7621334791183472
Validation loss: 1.9773642016995339

Epoch: 59| Step: 0
Training loss: 2.3978450298309326
Validation loss: 1.9785026299056185

Epoch: 6| Step: 1
Training loss: 2.261878252029419
Validation loss: 1.9921249663957985

Epoch: 6| Step: 2
Training loss: 2.4605953693389893
Validation loss: 1.9856783164444791

Epoch: 6| Step: 3
Training loss: 2.553194046020508
Validation loss: 1.9986815939667404

Epoch: 6| Step: 4
Training loss: 2.1715455055236816
Validation loss: 1.9921036369057112

Epoch: 6| Step: 5
Training loss: 2.220552444458008
Validation loss: 1.9866203979779316

Epoch: 6| Step: 6
Training loss: 2.9946818351745605
Validation loss: 1.9863530435869772

Epoch: 6| Step: 7
Training loss: 1.906217336654663
Validation loss: 1.9808028603112826

Epoch: 6| Step: 8
Training loss: 1.8508541584014893
Validation loss: 1.9860526361773092

Epoch: 6| Step: 9
Training loss: 2.9133355617523193
Validation loss: 1.979625093039646

Epoch: 6| Step: 10
Training loss: 2.5027782917022705
Validation loss: 1.9858602246930521

Epoch: 6| Step: 11
Training loss: 2.2007875442504883
Validation loss: 1.9839044642704788

Epoch: 6| Step: 12
Training loss: 1.638024091720581
Validation loss: 1.9690180145284182

Epoch: 6| Step: 13
Training loss: 3.0487449169158936
Validation loss: 1.9962920373485935

Epoch: 60| Step: 0
Training loss: 2.4910080432891846
Validation loss: 1.9859200472472816

Epoch: 6| Step: 1
Training loss: 2.746433734893799
Validation loss: 1.988773751002486

Epoch: 6| Step: 2
Training loss: 2.6296286582946777
Validation loss: 1.9876828706392677

Epoch: 6| Step: 3
Training loss: 2.1284477710723877
Validation loss: 1.9682871782651512

Epoch: 6| Step: 4
Training loss: 2.065930128097534
Validation loss: 1.9755507771686842

Epoch: 6| Step: 5
Training loss: 1.9110033512115479
Validation loss: 1.9622642429926063

Epoch: 6| Step: 6
Training loss: 2.6640734672546387
Validation loss: 1.9846804167634697

Epoch: 6| Step: 7
Training loss: 2.028125047683716
Validation loss: 1.9663143696323517

Epoch: 6| Step: 8
Training loss: 2.281161308288574
Validation loss: 1.971175455277966

Epoch: 6| Step: 9
Training loss: 2.351260185241699
Validation loss: 1.9790692303770332

Epoch: 6| Step: 10
Training loss: 2.1029632091522217
Validation loss: 1.969896367801133

Epoch: 6| Step: 11
Training loss: 2.141991138458252
Validation loss: 1.967845275837888

Epoch: 6| Step: 12
Training loss: 2.6022064685821533
Validation loss: 1.9561007266403527

Epoch: 6| Step: 13
Training loss: 2.5317509174346924
Validation loss: 1.9616370906112015

Epoch: 61| Step: 0
Training loss: 2.16056752204895
Validation loss: 1.9709048219906387

Epoch: 6| Step: 1
Training loss: 2.5565531253814697
Validation loss: 1.962932470024273

Epoch: 6| Step: 2
Training loss: 2.707634449005127
Validation loss: 1.9633051015997445

Epoch: 6| Step: 3
Training loss: 2.2203869819641113
Validation loss: 1.980004367008004

Epoch: 6| Step: 4
Training loss: 2.131218433380127
Validation loss: 1.982451238939839

Epoch: 6| Step: 5
Training loss: 2.499955177307129
Validation loss: 1.9712199677703202

Epoch: 6| Step: 6
Training loss: 1.9769480228424072
Validation loss: 1.9617424267594532

Epoch: 6| Step: 7
Training loss: 2.5448200702667236
Validation loss: 1.9841502302436418

Epoch: 6| Step: 8
Training loss: 2.0125479698181152
Validation loss: 1.97884234305351

Epoch: 6| Step: 9
Training loss: 2.26291823387146
Validation loss: 1.9752740783076133

Epoch: 6| Step: 10
Training loss: 2.560593843460083
Validation loss: 1.9838092391208937

Epoch: 6| Step: 11
Training loss: 2.4226486682891846
Validation loss: 1.9648274708819646

Epoch: 6| Step: 12
Training loss: 2.0259547233581543
Validation loss: 1.9761300086975098

Epoch: 6| Step: 13
Training loss: 2.7810351848602295
Validation loss: 1.9696814065338464

Epoch: 62| Step: 0
Training loss: 2.014056444168091
Validation loss: 1.982194410857334

Epoch: 6| Step: 1
Training loss: 2.3260395526885986
Validation loss: 1.9725988731589368

Epoch: 6| Step: 2
Training loss: 2.6292550563812256
Validation loss: 1.9837905514624812

Epoch: 6| Step: 3
Training loss: 2.317558526992798
Validation loss: 1.982110172189692

Epoch: 6| Step: 4
Training loss: 3.023664951324463
Validation loss: 1.990834330999723

Epoch: 6| Step: 5
Training loss: 2.4246621131896973
Validation loss: 1.974831340133503

Epoch: 6| Step: 6
Training loss: 2.0582220554351807
Validation loss: 1.9879946888134044

Epoch: 6| Step: 7
Training loss: 1.5951282978057861
Validation loss: 1.9974770263959003

Epoch: 6| Step: 8
Training loss: 2.154757261276245
Validation loss: 1.9747653071598341

Epoch: 6| Step: 9
Training loss: 2.341930389404297
Validation loss: 1.996271405168759

Epoch: 6| Step: 10
Training loss: 2.2817554473876953
Validation loss: 1.9916507274873796

Epoch: 6| Step: 11
Training loss: 2.31624174118042
Validation loss: 1.9914544192693566

Epoch: 6| Step: 12
Training loss: 2.302344799041748
Validation loss: 1.9952156287367626

Epoch: 6| Step: 13
Training loss: 3.181290626525879
Validation loss: 1.9900152016711492

Epoch: 63| Step: 0
Training loss: 2.7064857482910156
Validation loss: 1.9945839041022844

Epoch: 6| Step: 1
Training loss: 2.176011562347412
Validation loss: 1.9835641922489289

Epoch: 6| Step: 2
Training loss: 1.6666074991226196
Validation loss: 1.990014906852476

Epoch: 6| Step: 3
Training loss: 2.245669364929199
Validation loss: 1.975906111860788

Epoch: 6| Step: 4
Training loss: 2.5181009769439697
Validation loss: 1.9924661831189228

Epoch: 6| Step: 5
Training loss: 2.7563204765319824
Validation loss: 1.9907328723579325

Epoch: 6| Step: 6
Training loss: 2.2216038703918457
Validation loss: 1.999027172724406

Epoch: 6| Step: 7
Training loss: 2.3556151390075684
Validation loss: 1.98069167137146

Epoch: 6| Step: 8
Training loss: 2.3267650604248047
Validation loss: 1.9712194383785289

Epoch: 6| Step: 9
Training loss: 2.3968803882598877
Validation loss: 1.9979542660456833

Epoch: 6| Step: 10
Training loss: 2.248767852783203
Validation loss: 1.9625926274125294

Epoch: 6| Step: 11
Training loss: 2.3396828174591064
Validation loss: 1.9823123178174418

Epoch: 6| Step: 12
Training loss: 2.381363868713379
Validation loss: 1.969142101144278

Epoch: 6| Step: 13
Training loss: 2.05731201171875
Validation loss: 1.9722769350133917

Epoch: 64| Step: 0
Training loss: 2.4846768379211426
Validation loss: 1.9796389533627419

Epoch: 6| Step: 1
Training loss: 2.5706958770751953
Validation loss: 1.9724490360547138

Epoch: 6| Step: 2
Training loss: 2.472158432006836
Validation loss: 1.9655836346328899

Epoch: 6| Step: 3
Training loss: 2.7721238136291504
Validation loss: 1.9699423697686964

Epoch: 6| Step: 4
Training loss: 2.259099006652832
Validation loss: 1.9656516070006995

Epoch: 6| Step: 5
Training loss: 2.6476125717163086
Validation loss: 1.9682154437547088

Epoch: 6| Step: 6
Training loss: 2.449775218963623
Validation loss: 1.983498236184479

Epoch: 6| Step: 7
Training loss: 2.307562828063965
Validation loss: 1.9710497240866385

Epoch: 6| Step: 8
Training loss: 1.6849231719970703
Validation loss: 1.9787116460902716

Epoch: 6| Step: 9
Training loss: 2.5147593021392822
Validation loss: 1.972336866522348

Epoch: 6| Step: 10
Training loss: 1.5393991470336914
Validation loss: 1.9629166882525209

Epoch: 6| Step: 11
Training loss: 2.110642910003662
Validation loss: 1.9745670210930608

Epoch: 6| Step: 12
Training loss: 2.4019479751586914
Validation loss: 1.9546170465407833

Epoch: 6| Step: 13
Training loss: 2.139176845550537
Validation loss: 1.973688284556071

Epoch: 65| Step: 0
Training loss: 1.9289131164550781
Validation loss: 1.9559053144147318

Epoch: 6| Step: 1
Training loss: 2.8201003074645996
Validation loss: 1.9497112945843769

Epoch: 6| Step: 2
Training loss: 2.3183493614196777
Validation loss: 1.9624958307512346

Epoch: 6| Step: 3
Training loss: 2.387211322784424
Validation loss: 1.9668112416421213

Epoch: 6| Step: 4
Training loss: 1.8595551252365112
Validation loss: 1.9628938167325911

Epoch: 6| Step: 5
Training loss: 2.450144052505493
Validation loss: 1.963835875193278

Epoch: 6| Step: 6
Training loss: 2.0325753688812256
Validation loss: 1.9590559492829025

Epoch: 6| Step: 7
Training loss: 2.7219667434692383
Validation loss: 1.94141335000274

Epoch: 6| Step: 8
Training loss: 2.4096615314483643
Validation loss: 1.9395785818817795

Epoch: 6| Step: 9
Training loss: 2.4424495697021484
Validation loss: 1.9446686852362849

Epoch: 6| Step: 10
Training loss: 1.9082696437835693
Validation loss: 1.946418164878763

Epoch: 6| Step: 11
Training loss: 2.103330135345459
Validation loss: 1.9420366812777776

Epoch: 6| Step: 12
Training loss: 2.229526996612549
Validation loss: 1.9451241775225567

Epoch: 6| Step: 13
Training loss: 3.0313758850097656
Validation loss: 1.9459917519682197

Epoch: 66| Step: 0
Training loss: 2.321779727935791
Validation loss: 1.9447224358076691

Epoch: 6| Step: 1
Training loss: 1.8929624557495117
Validation loss: 1.9695152595479002

Epoch: 6| Step: 2
Training loss: 2.489748477935791
Validation loss: 1.9580667044526787

Epoch: 6| Step: 3
Training loss: 2.521427631378174
Validation loss: 1.9597178402767386

Epoch: 6| Step: 4
Training loss: 2.1717209815979004
Validation loss: 1.9695218070860832

Epoch: 6| Step: 5
Training loss: 2.3214826583862305
Validation loss: 1.9680991403518184

Epoch: 6| Step: 6
Training loss: 2.4577550888061523
Validation loss: 1.971181713124757

Epoch: 6| Step: 7
Training loss: 1.8995919227600098
Validation loss: 1.9745356344407605

Epoch: 6| Step: 8
Training loss: 2.247501850128174
Validation loss: 1.9681172601638302

Epoch: 6| Step: 9
Training loss: 1.5701513290405273
Validation loss: 1.9583946274172874

Epoch: 6| Step: 10
Training loss: 3.050245761871338
Validation loss: 1.9685219539109098

Epoch: 6| Step: 11
Training loss: 2.5039916038513184
Validation loss: 1.9625087104817873

Epoch: 6| Step: 12
Training loss: 2.3703083992004395
Validation loss: 1.9633739776508783

Epoch: 6| Step: 13
Training loss: 2.490556478500366
Validation loss: 1.97614041707849

Epoch: 67| Step: 0
Training loss: 2.0467164516448975
Validation loss: 1.9814381125152751

Epoch: 6| Step: 1
Training loss: 2.4948675632476807
Validation loss: 1.9760479414334862

Epoch: 6| Step: 2
Training loss: 2.202345609664917
Validation loss: 1.9874538888213455

Epoch: 6| Step: 3
Training loss: 1.3422564268112183
Validation loss: 1.9658882412859189

Epoch: 6| Step: 4
Training loss: 2.751222848892212
Validation loss: 1.9908709628607637

Epoch: 6| Step: 5
Training loss: 2.1513381004333496
Validation loss: 1.9885048981635802

Epoch: 6| Step: 6
Training loss: 1.810869574546814
Validation loss: 1.9897126497760895

Epoch: 6| Step: 7
Training loss: 2.248044013977051
Validation loss: 1.9909760003448815

Epoch: 6| Step: 8
Training loss: 1.9464735984802246
Validation loss: 1.9929492396693076

Epoch: 6| Step: 9
Training loss: 3.438239097595215
Validation loss: 1.9815000257184427

Epoch: 6| Step: 10
Training loss: 2.528560161590576
Validation loss: 1.9750083928467126

Epoch: 6| Step: 11
Training loss: 2.5743823051452637
Validation loss: 1.9792853119552776

Epoch: 6| Step: 12
Training loss: 2.739992380142212
Validation loss: 1.9748340370834514

Epoch: 6| Step: 13
Training loss: 1.773468255996704
Validation loss: 1.9672418678960493

Epoch: 68| Step: 0
Training loss: 1.8865305185317993
Validation loss: 1.9782439444654731

Epoch: 6| Step: 1
Training loss: 2.241760730743408
Validation loss: 1.964245629566972

Epoch: 6| Step: 2
Training loss: 2.0220108032226562
Validation loss: 1.9623039845497376

Epoch: 6| Step: 3
Training loss: 2.588294506072998
Validation loss: 1.973562112418554

Epoch: 6| Step: 4
Training loss: 1.7577253580093384
Validation loss: 1.9663131531848703

Epoch: 6| Step: 5
Training loss: 2.2543387413024902
Validation loss: 1.958248221746055

Epoch: 6| Step: 6
Training loss: 2.0800528526306152
Validation loss: 1.9680570940817557

Epoch: 6| Step: 7
Training loss: 2.201087713241577
Validation loss: 1.9733560392933507

Epoch: 6| Step: 8
Training loss: 2.9659817218780518
Validation loss: 1.97803436299806

Epoch: 6| Step: 9
Training loss: 2.193906307220459
Validation loss: 1.97599026977375

Epoch: 6| Step: 10
Training loss: 2.118527412414551
Validation loss: 1.9677844201364825

Epoch: 6| Step: 11
Training loss: 2.483531951904297
Validation loss: 1.9609974673999253

Epoch: 6| Step: 12
Training loss: 3.049006223678589
Validation loss: 1.9468548144063642

Epoch: 6| Step: 13
Training loss: 2.455961227416992
Validation loss: 1.945147660470778

Epoch: 69| Step: 0
Training loss: 2.5061826705932617
Validation loss: 1.9543943520515197

Epoch: 6| Step: 1
Training loss: 2.0174412727355957
Validation loss: 1.9545721520659745

Epoch: 6| Step: 2
Training loss: 2.0945839881896973
Validation loss: 1.9458873323214951

Epoch: 6| Step: 3
Training loss: 2.611776351928711
Validation loss: 1.9574231921985585

Epoch: 6| Step: 4
Training loss: 3.0734329223632812
Validation loss: 1.9418896872510192

Epoch: 6| Step: 5
Training loss: 2.1022768020629883
Validation loss: 1.9509409191787883

Epoch: 6| Step: 6
Training loss: 1.8479394912719727
Validation loss: 1.962957807766494

Epoch: 6| Step: 7
Training loss: 1.6856789588928223
Validation loss: 1.9275809616170905

Epoch: 6| Step: 8
Training loss: 1.8918592929840088
Validation loss: 1.9540444227956957

Epoch: 6| Step: 9
Training loss: 3.330871105194092
Validation loss: 1.9501560157345188

Epoch: 6| Step: 10
Training loss: 2.0619232654571533
Validation loss: 1.953376687983031

Epoch: 6| Step: 11
Training loss: 2.870330333709717
Validation loss: 1.9489542822684012

Epoch: 6| Step: 12
Training loss: 1.855583906173706
Validation loss: 1.9374842131009666

Epoch: 6| Step: 13
Training loss: 2.192904472351074
Validation loss: 1.9459411444202546

Epoch: 70| Step: 0
Training loss: 2.4104437828063965
Validation loss: 1.961394004924323

Epoch: 6| Step: 1
Training loss: 1.9191503524780273
Validation loss: 1.953733560859516

Epoch: 6| Step: 2
Training loss: 2.528475284576416
Validation loss: 1.9488944827869374

Epoch: 6| Step: 3
Training loss: 2.0041255950927734
Validation loss: 1.9563797520053001

Epoch: 6| Step: 4
Training loss: 1.8858201503753662
Validation loss: 1.9493451618379163

Epoch: 6| Step: 5
Training loss: 2.5855116844177246
Validation loss: 1.938975885350217

Epoch: 6| Step: 6
Training loss: 2.409470558166504
Validation loss: 1.945850380005375

Epoch: 6| Step: 7
Training loss: 2.0617589950561523
Validation loss: 1.9456933441982474

Epoch: 6| Step: 8
Training loss: 1.7828937768936157
Validation loss: 1.9397392811313752

Epoch: 6| Step: 9
Training loss: 2.2740554809570312
Validation loss: 1.9517389523085726

Epoch: 6| Step: 10
Training loss: 3.192655324935913
Validation loss: 1.9538278348984257

Epoch: 6| Step: 11
Training loss: 2.249569892883301
Validation loss: 1.9530757498997513

Epoch: 6| Step: 12
Training loss: 1.8293461799621582
Validation loss: 1.932374672223163

Epoch: 6| Step: 13
Training loss: 3.1487767696380615
Validation loss: 1.9494704123466247

Epoch: 71| Step: 0
Training loss: 2.370702028274536
Validation loss: 1.9497535408184092

Epoch: 6| Step: 1
Training loss: 2.868696689605713
Validation loss: 1.9550703007687804

Epoch: 6| Step: 2
Training loss: 2.3069653511047363
Validation loss: 1.9578176775286276

Epoch: 6| Step: 3
Training loss: 2.5724430084228516
Validation loss: 1.942590295627553

Epoch: 6| Step: 4
Training loss: 1.2186627388000488
Validation loss: 1.960296510368265

Epoch: 6| Step: 5
Training loss: 2.4499294757843018
Validation loss: 1.97079804635817

Epoch: 6| Step: 6
Training loss: 1.8806674480438232
Validation loss: 1.9602246130666425

Epoch: 6| Step: 7
Training loss: 2.3410274982452393
Validation loss: 1.987905453610164

Epoch: 6| Step: 8
Training loss: 2.413609027862549
Validation loss: 1.954494794209798

Epoch: 6| Step: 9
Training loss: 2.538713216781616
Validation loss: 1.9840364481813164

Epoch: 6| Step: 10
Training loss: 2.677016258239746
Validation loss: 1.982420672652542

Epoch: 6| Step: 11
Training loss: 2.048698902130127
Validation loss: 1.977386345145523

Epoch: 6| Step: 12
Training loss: 1.8350005149841309
Validation loss: 1.9772888486103346

Epoch: 6| Step: 13
Training loss: 2.788513660430908
Validation loss: 1.9773018616502003

Epoch: 72| Step: 0
Training loss: 2.5410985946655273
Validation loss: 1.9608925106704875

Epoch: 6| Step: 1
Training loss: 2.7739038467407227
Validation loss: 1.9752724503958097

Epoch: 6| Step: 2
Training loss: 2.398808479309082
Validation loss: 1.9665251342199181

Epoch: 6| Step: 3
Training loss: 2.6910877227783203
Validation loss: 1.9711973462053525

Epoch: 6| Step: 4
Training loss: 1.291639804840088
Validation loss: 1.9657464347859865

Epoch: 6| Step: 5
Training loss: 2.169161319732666
Validation loss: 1.9581371045881701

Epoch: 6| Step: 6
Training loss: 2.4360170364379883
Validation loss: 1.9566350290852208

Epoch: 6| Step: 7
Training loss: 2.0862607955932617
Validation loss: 1.9739466098047072

Epoch: 6| Step: 8
Training loss: 2.5341796875
Validation loss: 1.9611817047160158

Epoch: 6| Step: 9
Training loss: 2.6002256870269775
Validation loss: 1.9584498969457482

Epoch: 6| Step: 10
Training loss: 1.9165806770324707
Validation loss: 1.9610066106242519

Epoch: 6| Step: 11
Training loss: 2.1176249980926514
Validation loss: 1.9596879866815382

Epoch: 6| Step: 12
Training loss: 2.174247980117798
Validation loss: 1.9686920924853253

Epoch: 6| Step: 13
Training loss: 1.9059734344482422
Validation loss: 1.9634019533793132

Epoch: 73| Step: 0
Training loss: 1.606046438217163
Validation loss: 1.9740652935479277

Epoch: 6| Step: 1
Training loss: 2.652836322784424
Validation loss: 1.9527660210927327

Epoch: 6| Step: 2
Training loss: 2.2916457653045654
Validation loss: 1.9568484803681732

Epoch: 6| Step: 3
Training loss: 2.4257144927978516
Validation loss: 1.960125313010267

Epoch: 6| Step: 4
Training loss: 2.613039970397949
Validation loss: 1.9498458857177405

Epoch: 6| Step: 5
Training loss: 1.5104764699935913
Validation loss: 1.9287643624890236

Epoch: 6| Step: 6
Training loss: 2.00349760055542
Validation loss: 1.9360034978517922

Epoch: 6| Step: 7
Training loss: 2.4337339401245117
Validation loss: 1.9357004819377777

Epoch: 6| Step: 8
Training loss: 2.1530954837799072
Validation loss: 1.927599694139214

Epoch: 6| Step: 9
Training loss: 2.360677719116211
Validation loss: 1.9445307306064072

Epoch: 6| Step: 10
Training loss: 2.486570358276367
Validation loss: 1.9620986305257326

Epoch: 6| Step: 11
Training loss: 2.6540677547454834
Validation loss: 1.940029667269799

Epoch: 6| Step: 12
Training loss: 2.636082887649536
Validation loss: 1.9676471243622482

Epoch: 6| Step: 13
Training loss: 1.8151838779449463
Validation loss: 1.9465219769426572

Epoch: 74| Step: 0
Training loss: 2.4708118438720703
Validation loss: 1.9554470303238078

Epoch: 6| Step: 1
Training loss: 2.6744678020477295
Validation loss: 1.9344526862585416

Epoch: 6| Step: 2
Training loss: 2.044370651245117
Validation loss: 1.9412073089230446

Epoch: 6| Step: 3
Training loss: 2.353437900543213
Validation loss: 1.961947315482683

Epoch: 6| Step: 4
Training loss: 2.8679919242858887
Validation loss: 1.9445010846660984

Epoch: 6| Step: 5
Training loss: 2.377755641937256
Validation loss: 1.9526150918775989

Epoch: 6| Step: 6
Training loss: 2.054596424102783
Validation loss: 1.9547713668115678

Epoch: 6| Step: 7
Training loss: 2.1976914405822754
Validation loss: 1.9572383639633015

Epoch: 6| Step: 8
Training loss: 2.5679492950439453
Validation loss: 1.9642168373189948

Epoch: 6| Step: 9
Training loss: 2.274747133255005
Validation loss: 1.9635573997292468

Epoch: 6| Step: 10
Training loss: 2.047701358795166
Validation loss: 1.9666146296326832

Epoch: 6| Step: 11
Training loss: 2.0531370639801025
Validation loss: 1.9767632574163458

Epoch: 6| Step: 12
Training loss: 1.49550461769104
Validation loss: 1.9745075215575516

Epoch: 6| Step: 13
Training loss: 2.5237395763397217
Validation loss: 1.9809241307679044

Epoch: 75| Step: 0
Training loss: 1.8287289142608643
Validation loss: 1.981145889528336

Epoch: 6| Step: 1
Training loss: 2.4194188117980957
Validation loss: 1.9581981615353656

Epoch: 6| Step: 2
Training loss: 2.6622605323791504
Validation loss: 1.9580780665079753

Epoch: 6| Step: 3
Training loss: 1.4752039909362793
Validation loss: 1.948168154685728

Epoch: 6| Step: 4
Training loss: 2.3818249702453613
Validation loss: 1.9805652095425514

Epoch: 6| Step: 5
Training loss: 2.477426528930664
Validation loss: 1.9617744594491937

Epoch: 6| Step: 6
Training loss: 2.6308250427246094
Validation loss: 1.9641849148658015

Epoch: 6| Step: 7
Training loss: 1.9453128576278687
Validation loss: 1.962442986426815

Epoch: 6| Step: 8
Training loss: 2.2508726119995117
Validation loss: 1.9602020940473002

Epoch: 6| Step: 9
Training loss: 2.2151641845703125
Validation loss: 1.9645727654939056

Epoch: 6| Step: 10
Training loss: 2.218830108642578
Validation loss: 1.9543829682052776

Epoch: 6| Step: 11
Training loss: 2.0915770530700684
Validation loss: 1.9631030931267688

Epoch: 6| Step: 12
Training loss: 2.7694826126098633
Validation loss: 1.9526560024548603

Epoch: 6| Step: 13
Training loss: 2.536888599395752
Validation loss: 1.9520260621142644

Epoch: 76| Step: 0
Training loss: 2.1928374767303467
Validation loss: 1.943626626845329

Epoch: 6| Step: 1
Training loss: 2.875588893890381
Validation loss: 1.94127534538187

Epoch: 6| Step: 2
Training loss: 2.3411645889282227
Validation loss: 1.9551921198444981

Epoch: 6| Step: 3
Training loss: 2.503190517425537
Validation loss: 1.9582456145235287

Epoch: 6| Step: 4
Training loss: 2.592104911804199
Validation loss: 1.9576411567708498

Epoch: 6| Step: 5
Training loss: 2.501274585723877
Validation loss: 1.9441917557870187

Epoch: 6| Step: 6
Training loss: 2.5447142124176025
Validation loss: 1.9343950056260633

Epoch: 6| Step: 7
Training loss: 2.4337425231933594
Validation loss: 1.9513067199337868

Epoch: 6| Step: 8
Training loss: 1.9409511089324951
Validation loss: 1.941096910866358

Epoch: 6| Step: 9
Training loss: 1.6188013553619385
Validation loss: 1.9591037227261452

Epoch: 6| Step: 10
Training loss: 2.1862051486968994
Validation loss: 1.934641904728387

Epoch: 6| Step: 11
Training loss: 2.277644634246826
Validation loss: 1.9380681604467414

Epoch: 6| Step: 12
Training loss: 1.5644874572753906
Validation loss: 1.944533271174277

Epoch: 6| Step: 13
Training loss: 2.2056798934936523
Validation loss: 1.921441908805601

Epoch: 77| Step: 0
Training loss: 1.6242923736572266
Validation loss: 1.925241853601189

Epoch: 6| Step: 1
Training loss: 2.1256766319274902
Validation loss: 1.946123864061089

Epoch: 6| Step: 2
Training loss: 2.1370511054992676
Validation loss: 1.933446471409131

Epoch: 6| Step: 3
Training loss: 2.693955898284912
Validation loss: 1.9307632625743907

Epoch: 6| Step: 4
Training loss: 2.4721031188964844
Validation loss: 1.9239820382928337

Epoch: 6| Step: 5
Training loss: 2.586371421813965
Validation loss: 1.932576669159756

Epoch: 6| Step: 6
Training loss: 1.769503116607666
Validation loss: 1.921604428240048

Epoch: 6| Step: 7
Training loss: 2.472783327102661
Validation loss: 1.9449386353133826

Epoch: 6| Step: 8
Training loss: 1.8264451026916504
Validation loss: 1.9243827263514202

Epoch: 6| Step: 9
Training loss: 2.131535053253174
Validation loss: 1.9315052891290316

Epoch: 6| Step: 10
Training loss: 2.705718517303467
Validation loss: 1.9398790046732912

Epoch: 6| Step: 11
Training loss: 2.2387890815734863
Validation loss: 1.916508663085199

Epoch: 6| Step: 12
Training loss: 2.402529716491699
Validation loss: 1.925787457855799

Epoch: 6| Step: 13
Training loss: 2.6492557525634766
Validation loss: 1.92329671946905

Epoch: 78| Step: 0
Training loss: 2.411435842514038
Validation loss: 1.9273786467890586

Epoch: 6| Step: 1
Training loss: 2.4525656700134277
Validation loss: 1.9478954999677596

Epoch: 6| Step: 2
Training loss: 1.9969782829284668
Validation loss: 1.9327626664151427

Epoch: 6| Step: 3
Training loss: 2.1521096229553223
Validation loss: 1.9425968380384548

Epoch: 6| Step: 4
Training loss: 2.1984128952026367
Validation loss: 1.9384568788672005

Epoch: 6| Step: 5
Training loss: 1.8991466760635376
Validation loss: 1.946763671854491

Epoch: 6| Step: 6
Training loss: 2.786867380142212
Validation loss: 1.9550883949443858

Epoch: 6| Step: 7
Training loss: 2.406353235244751
Validation loss: 1.9646820509305565

Epoch: 6| Step: 8
Training loss: 2.1662840843200684
Validation loss: 1.9544495779980895

Epoch: 6| Step: 9
Training loss: 2.2483341693878174
Validation loss: 1.9561355601074875

Epoch: 6| Step: 10
Training loss: 2.6946277618408203
Validation loss: 1.963841317802347

Epoch: 6| Step: 11
Training loss: 2.2255821228027344
Validation loss: 1.9542507228030954

Epoch: 6| Step: 12
Training loss: 1.955080509185791
Validation loss: 1.960355693294156

Epoch: 6| Step: 13
Training loss: 1.9167428016662598
Validation loss: 1.9722093510371383

Epoch: 79| Step: 0
Training loss: 2.2752139568328857
Validation loss: 1.9727299828683176

Epoch: 6| Step: 1
Training loss: 2.455798625946045
Validation loss: 1.9599405706569712

Epoch: 6| Step: 2
Training loss: 2.3824591636657715
Validation loss: 1.9798485335483347

Epoch: 6| Step: 3
Training loss: 2.003192901611328
Validation loss: 1.9760619363477152

Epoch: 6| Step: 4
Training loss: 2.495241165161133
Validation loss: 1.9818169019555534

Epoch: 6| Step: 5
Training loss: 1.9849936962127686
Validation loss: 1.9726115618982623

Epoch: 6| Step: 6
Training loss: 2.0037219524383545
Validation loss: 1.9786736413996706

Epoch: 6| Step: 7
Training loss: 2.8265879154205322
Validation loss: 1.9830106253265052

Epoch: 6| Step: 8
Training loss: 2.5889828205108643
Validation loss: 1.9714114909530969

Epoch: 6| Step: 9
Training loss: 2.0673904418945312
Validation loss: 1.9832082307466896

Epoch: 6| Step: 10
Training loss: 1.5337846279144287
Validation loss: 1.9767355342065134

Epoch: 6| Step: 11
Training loss: 2.682199478149414
Validation loss: 1.9805271804973643

Epoch: 6| Step: 12
Training loss: 2.026564598083496
Validation loss: 1.969763699398246

Epoch: 6| Step: 13
Training loss: 2.305920362472534
Validation loss: 1.976471165175079

Epoch: 80| Step: 0
Training loss: 1.9313156604766846
Validation loss: 1.9583168273331018

Epoch: 6| Step: 1
Training loss: 2.5521225929260254
Validation loss: 1.980945243630358

Epoch: 6| Step: 2
Training loss: 2.80517840385437
Validation loss: 1.9720038790856638

Epoch: 6| Step: 3
Training loss: 2.277665615081787
Validation loss: 1.9697898305872434

Epoch: 6| Step: 4
Training loss: 1.740319848060608
Validation loss: 1.9687217845711658

Epoch: 6| Step: 5
Training loss: 2.7759552001953125
Validation loss: 1.977651349959835

Epoch: 6| Step: 6
Training loss: 2.2989299297332764
Validation loss: 1.9780133206357238

Epoch: 6| Step: 7
Training loss: 2.1984426975250244
Validation loss: 1.972733974456787

Epoch: 6| Step: 8
Training loss: 2.288221836090088
Validation loss: 1.9766385145084833

Epoch: 6| Step: 9
Training loss: 1.7961082458496094
Validation loss: 1.9747742427292692

Epoch: 6| Step: 10
Training loss: 1.7671984434127808
Validation loss: 1.9695723928431028

Epoch: 6| Step: 11
Training loss: 2.2815818786621094
Validation loss: 1.9813389278227282

Epoch: 6| Step: 12
Training loss: 2.9769599437713623
Validation loss: 1.9964608069389098

Epoch: 6| Step: 13
Training loss: 1.4363937377929688
Validation loss: 1.9605810744788057

Epoch: 81| Step: 0
Training loss: 2.563210964202881
Validation loss: 1.985857040651383

Epoch: 6| Step: 1
Training loss: 1.6412990093231201
Validation loss: 1.9601536899484613

Epoch: 6| Step: 2
Training loss: 2.4721169471740723
Validation loss: 1.9837977129925963

Epoch: 6| Step: 3
Training loss: 1.8015766143798828
Validation loss: 1.9685818918289677

Epoch: 6| Step: 4
Training loss: 2.4963839054107666
Validation loss: 1.9831621762244933

Epoch: 6| Step: 5
Training loss: 2.2059431076049805
Validation loss: 1.9751187024577972

Epoch: 6| Step: 6
Training loss: 2.102867841720581
Validation loss: 1.9627737281143025

Epoch: 6| Step: 7
Training loss: 2.3777647018432617
Validation loss: 1.974734596026841

Epoch: 6| Step: 8
Training loss: 2.1124706268310547
Validation loss: 1.9667013665681243

Epoch: 6| Step: 9
Training loss: 2.532252311706543
Validation loss: 1.9690212665065643

Epoch: 6| Step: 10
Training loss: 2.391162395477295
Validation loss: 1.9464975441655805

Epoch: 6| Step: 11
Training loss: 2.693732500076294
Validation loss: 1.9739021255124

Epoch: 6| Step: 12
Training loss: 2.041086435317993
Validation loss: 1.9680108101137224

Epoch: 6| Step: 13
Training loss: 1.8410224914550781
Validation loss: 1.9666095600333264

Epoch: 82| Step: 0
Training loss: 1.837199091911316
Validation loss: 1.9608270378522976

Epoch: 6| Step: 1
Training loss: 1.594557523727417
Validation loss: 1.9520244521479453

Epoch: 6| Step: 2
Training loss: 1.8747875690460205
Validation loss: 1.9650382854605233

Epoch: 6| Step: 3
Training loss: 2.2583842277526855
Validation loss: 1.9656474846665577

Epoch: 6| Step: 4
Training loss: 2.301194190979004
Validation loss: 1.9374438562700826

Epoch: 6| Step: 5
Training loss: 2.4039363861083984
Validation loss: 1.9517293501925725

Epoch: 6| Step: 6
Training loss: 2.3215043544769287
Validation loss: 1.9378034683965868

Epoch: 6| Step: 7
Training loss: 2.528465747833252
Validation loss: 1.9551048432627032

Epoch: 6| Step: 8
Training loss: 2.939896583557129
Validation loss: 1.9651103263260217

Epoch: 6| Step: 9
Training loss: 1.7042672634124756
Validation loss: 1.9335863410785634

Epoch: 6| Step: 10
Training loss: 1.6605173349380493
Validation loss: 1.9530764202917776

Epoch: 6| Step: 11
Training loss: 2.9277000427246094
Validation loss: 1.95525602627826

Epoch: 6| Step: 12
Training loss: 2.3012077808380127
Validation loss: 1.9536845030323151

Epoch: 6| Step: 13
Training loss: 3.343681812286377
Validation loss: 1.9500099817911785

Epoch: 83| Step: 0
Training loss: 2.60017728805542
Validation loss: 1.950708076518069

Epoch: 6| Step: 1
Training loss: 2.9105005264282227
Validation loss: 1.948803876035957

Epoch: 6| Step: 2
Training loss: 2.749389171600342
Validation loss: 1.9358459582892797

Epoch: 6| Step: 3
Training loss: 2.7230658531188965
Validation loss: 1.9344358444213867

Epoch: 6| Step: 4
Training loss: 2.3839869499206543
Validation loss: 1.9599112810627106

Epoch: 6| Step: 5
Training loss: 2.830754041671753
Validation loss: 1.9579639255359609

Epoch: 6| Step: 6
Training loss: 1.6982171535491943
Validation loss: 1.9551156836171304

Epoch: 6| Step: 7
Training loss: 2.697838306427002
Validation loss: 1.9507479436935917

Epoch: 6| Step: 8
Training loss: 1.9300860166549683
Validation loss: 1.938212335750621

Epoch: 6| Step: 9
Training loss: 2.3007431030273438
Validation loss: 1.9642666578292847

Epoch: 6| Step: 10
Training loss: 1.9428355693817139
Validation loss: 1.950205743953746

Epoch: 6| Step: 11
Training loss: 1.6641563177108765
Validation loss: 1.9533940989484069

Epoch: 6| Step: 12
Training loss: 1.1568098068237305
Validation loss: 1.93694374510037

Epoch: 6| Step: 13
Training loss: 1.4662162065505981
Validation loss: 1.9474418881118938

Epoch: 84| Step: 0
Training loss: 2.10133695602417
Validation loss: 1.9413696745390534

Epoch: 6| Step: 1
Training loss: 2.369131565093994
Validation loss: 1.9450096058589157

Epoch: 6| Step: 2
Training loss: 2.175971746444702
Validation loss: 1.9440751229563067

Epoch: 6| Step: 3
Training loss: 2.652928352355957
Validation loss: 1.9632175558356828

Epoch: 6| Step: 4
Training loss: 2.6412830352783203
Validation loss: 1.952165283182616

Epoch: 6| Step: 5
Training loss: 2.442674160003662
Validation loss: 1.9682962484257196

Epoch: 6| Step: 6
Training loss: 1.9999651908874512
Validation loss: 1.9581451967198362

Epoch: 6| Step: 7
Training loss: 1.731689691543579
Validation loss: 1.9418958656249508

Epoch: 6| Step: 8
Training loss: 1.7486701011657715
Validation loss: 1.9512667425217167

Epoch: 6| Step: 9
Training loss: 1.885101556777954
Validation loss: 1.9547029310657131

Epoch: 6| Step: 10
Training loss: 2.056079149246216
Validation loss: 1.9761413194799935

Epoch: 6| Step: 11
Training loss: 2.5664854049682617
Validation loss: 1.9654470438598304

Epoch: 6| Step: 12
Training loss: 2.5572214126586914
Validation loss: 1.9632564321641

Epoch: 6| Step: 13
Training loss: 2.7128729820251465
Validation loss: 1.9424537381818217

Epoch: 85| Step: 0
Training loss: 1.9216601848602295
Validation loss: 1.9583672887535506

Epoch: 6| Step: 1
Training loss: 2.3257405757904053
Validation loss: 1.9467648331836989

Epoch: 6| Step: 2
Training loss: 2.414731025695801
Validation loss: 1.955312600699804

Epoch: 6| Step: 3
Training loss: 2.565606117248535
Validation loss: 1.952506237132575

Epoch: 6| Step: 4
Training loss: 1.731283187866211
Validation loss: 1.9646483877653718

Epoch: 6| Step: 5
Training loss: 3.5357537269592285
Validation loss: 1.9530980715187647

Epoch: 6| Step: 6
Training loss: 2.29460072517395
Validation loss: 1.9666535392884286

Epoch: 6| Step: 7
Training loss: 2.6916699409484863
Validation loss: 1.9521367396077802

Epoch: 6| Step: 8
Training loss: 1.660306453704834
Validation loss: 1.9908192901201145

Epoch: 6| Step: 9
Training loss: 2.1986589431762695
Validation loss: 1.9799654688886417

Epoch: 6| Step: 10
Training loss: 2.8167471885681152
Validation loss: 1.9641240463461926

Epoch: 6| Step: 11
Training loss: 2.1165285110473633
Validation loss: 1.9690007445632771

Epoch: 6| Step: 12
Training loss: 1.1138341426849365
Validation loss: 1.9683241177630681

Epoch: 6| Step: 13
Training loss: 1.5699352025985718
Validation loss: 1.960549618608208

Epoch: 86| Step: 0
Training loss: 1.9803143739700317
Validation loss: 1.9763899285306212

Epoch: 6| Step: 1
Training loss: 2.0827484130859375
Validation loss: 1.9811506809726838

Epoch: 6| Step: 2
Training loss: 2.665224075317383
Validation loss: 1.975321956860122

Epoch: 6| Step: 3
Training loss: 2.673625946044922
Validation loss: 1.9677268958860827

Epoch: 6| Step: 4
Training loss: 2.262667655944824
Validation loss: 1.9773917172544746

Epoch: 6| Step: 5
Training loss: 2.090941905975342
Validation loss: 1.9690925664799188

Epoch: 6| Step: 6
Training loss: 2.15802001953125
Validation loss: 1.9903912851887364

Epoch: 6| Step: 7
Training loss: 1.8064451217651367
Validation loss: 1.9845175858466857

Epoch: 6| Step: 8
Training loss: 2.538959503173828
Validation loss: 1.9874338155151696

Epoch: 6| Step: 9
Training loss: 1.7625012397766113
Validation loss: 1.9861321769734865

Epoch: 6| Step: 10
Training loss: 2.3485562801361084
Validation loss: 1.955721483435682

Epoch: 6| Step: 11
Training loss: 2.3717284202575684
Validation loss: 1.984894367956346

Epoch: 6| Step: 12
Training loss: 2.5056657791137695
Validation loss: 1.976349074353454

Epoch: 6| Step: 13
Training loss: 2.0044949054718018
Validation loss: 1.9534230104056738

Epoch: 87| Step: 0
Training loss: 2.528325080871582
Validation loss: 1.9742916989070114

Epoch: 6| Step: 1
Training loss: 1.7457032203674316
Validation loss: 1.9666131440029349

Epoch: 6| Step: 2
Training loss: 2.0982723236083984
Validation loss: 1.9907827736229025

Epoch: 6| Step: 3
Training loss: 2.467151641845703
Validation loss: 1.9638748732946252

Epoch: 6| Step: 4
Training loss: 2.0124104022979736
Validation loss: 1.984776617378317

Epoch: 6| Step: 5
Training loss: 1.9405627250671387
Validation loss: 1.9961192966789327

Epoch: 6| Step: 6
Training loss: 1.8721541166305542
Validation loss: 1.9708338886178949

Epoch: 6| Step: 7
Training loss: 2.467118740081787
Validation loss: 1.9838558999441003

Epoch: 6| Step: 8
Training loss: 2.7242584228515625
Validation loss: 1.9799604697894024

Epoch: 6| Step: 9
Training loss: 2.5581984519958496
Validation loss: 1.974211464646042

Epoch: 6| Step: 10
Training loss: 2.1595869064331055
Validation loss: 1.9695127933256087

Epoch: 6| Step: 11
Training loss: 2.005401611328125
Validation loss: 1.9822644315740114

Epoch: 6| Step: 12
Training loss: 2.0461196899414062
Validation loss: 1.9799271245156564

Epoch: 6| Step: 13
Training loss: 2.6684978008270264
Validation loss: 1.9762738750826927

Epoch: 88| Step: 0
Training loss: 1.67435884475708
Validation loss: 1.9797379111730924

Epoch: 6| Step: 1
Training loss: 2.0720555782318115
Validation loss: 1.994123702408165

Epoch: 6| Step: 2
Training loss: 2.2556300163269043
Validation loss: 1.986521949050247

Epoch: 6| Step: 3
Training loss: 1.9335006475448608
Validation loss: 1.9817799240030267

Epoch: 6| Step: 4
Training loss: 2.742842674255371
Validation loss: 1.9900262535259288

Epoch: 6| Step: 5
Training loss: 2.507638931274414
Validation loss: 1.9707346718798402

Epoch: 6| Step: 6
Training loss: 2.2537269592285156
Validation loss: 1.990180394982779

Epoch: 6| Step: 7
Training loss: 2.4681499004364014
Validation loss: 1.9827744319874754

Epoch: 6| Step: 8
Training loss: 2.052218437194824
Validation loss: 1.9833647051165182

Epoch: 6| Step: 9
Training loss: 2.6113405227661133
Validation loss: 1.9950888003072431

Epoch: 6| Step: 10
Training loss: 2.1162049770355225
Validation loss: 1.9809295426132858

Epoch: 6| Step: 11
Training loss: 2.3653271198272705
Validation loss: 1.9784949902565248

Epoch: 6| Step: 12
Training loss: 1.901320457458496
Validation loss: 1.980329732741079

Epoch: 6| Step: 13
Training loss: 2.273050546646118
Validation loss: 1.986925217413133

Epoch: 89| Step: 0
Training loss: 2.060899257659912
Validation loss: 1.9947432164222962

Epoch: 6| Step: 1
Training loss: 1.8717502355575562
Validation loss: 1.9941136503732333

Epoch: 6| Step: 2
Training loss: 1.7992498874664307
Validation loss: 1.9758430680921

Epoch: 6| Step: 3
Training loss: 3.016092300415039
Validation loss: 1.95337252975792

Epoch: 6| Step: 4
Training loss: 2.010969638824463
Validation loss: 1.9540301599810201

Epoch: 6| Step: 5
Training loss: 2.378195285797119
Validation loss: 1.953895458611109

Epoch: 6| Step: 6
Training loss: 2.030087471008301
Validation loss: 1.9711983344888175

Epoch: 6| Step: 7
Training loss: 2.297435760498047
Validation loss: 1.9610874640044345

Epoch: 6| Step: 8
Training loss: 2.2059388160705566
Validation loss: 1.9421643467359646

Epoch: 6| Step: 9
Training loss: 2.220038652420044
Validation loss: 1.941199364200715

Epoch: 6| Step: 10
Training loss: 2.1671409606933594
Validation loss: 1.9382126254420127

Epoch: 6| Step: 11
Training loss: 2.5481956005096436
Validation loss: 1.950659539109917

Epoch: 6| Step: 12
Training loss: 2.1765458583831787
Validation loss: 1.9547476563402402

Epoch: 6| Step: 13
Training loss: 2.5415773391723633
Validation loss: 1.9345858661077355

Epoch: 90| Step: 0
Training loss: 2.4625372886657715
Validation loss: 1.9515593000637588

Epoch: 6| Step: 1
Training loss: 1.7944462299346924
Validation loss: 1.9526837654011224

Epoch: 6| Step: 2
Training loss: 2.381685972213745
Validation loss: 1.9573604752940517

Epoch: 6| Step: 3
Training loss: 1.8263837099075317
Validation loss: 1.9522122362608552

Epoch: 6| Step: 4
Training loss: 1.7882691621780396
Validation loss: 1.9711014455364597

Epoch: 6| Step: 5
Training loss: 2.275575637817383
Validation loss: 1.9653913692761493

Epoch: 6| Step: 6
Training loss: 2.7520065307617188
Validation loss: 1.9597503780036845

Epoch: 6| Step: 7
Training loss: 2.145674228668213
Validation loss: 1.9861698432635235

Epoch: 6| Step: 8
Training loss: 2.517467975616455
Validation loss: 1.9746683105345695

Epoch: 6| Step: 9
Training loss: 1.8989901542663574
Validation loss: 1.9510446312606975

Epoch: 6| Step: 10
Training loss: 1.740387201309204
Validation loss: 1.9937283941494521

Epoch: 6| Step: 11
Training loss: 2.9473533630371094
Validation loss: 1.9814904018114972

Epoch: 6| Step: 12
Training loss: 2.450014352798462
Validation loss: 1.9909524815056914

Epoch: 6| Step: 13
Training loss: 2.1094601154327393
Validation loss: 1.9727725021300777

Epoch: 91| Step: 0
Training loss: 2.7512893676757812
Validation loss: 1.9878776906639017

Epoch: 6| Step: 1
Training loss: 2.2047877311706543
Validation loss: 1.9750317732493083

Epoch: 6| Step: 2
Training loss: 1.9700958728790283
Validation loss: 1.977613514469516

Epoch: 6| Step: 3
Training loss: 1.736586332321167
Validation loss: 1.9983507766518542

Epoch: 6| Step: 4
Training loss: 2.115966796875
Validation loss: 1.9890582728129562

Epoch: 6| Step: 5
Training loss: 2.2131922245025635
Validation loss: 1.9669931934725853

Epoch: 6| Step: 6
Training loss: 2.143258571624756
Validation loss: 1.9730229916111115

Epoch: 6| Step: 7
Training loss: 2.2110302448272705
Validation loss: 1.990597483932331

Epoch: 6| Step: 8
Training loss: 2.286355495452881
Validation loss: 1.9858647008096018

Epoch: 6| Step: 9
Training loss: 2.1027591228485107
Validation loss: 1.9730369249979656

Epoch: 6| Step: 10
Training loss: 2.919792652130127
Validation loss: 1.9840895642516434

Epoch: 6| Step: 11
Training loss: 1.1400363445281982
Validation loss: 1.975713719603836

Epoch: 6| Step: 12
Training loss: 2.457127809524536
Validation loss: 1.9828385960671209

Epoch: 6| Step: 13
Training loss: 3.1990420818328857
Validation loss: 1.994654570856402

Epoch: 92| Step: 0
Training loss: 2.520153045654297
Validation loss: 1.9829429721319547

Epoch: 6| Step: 1
Training loss: 1.933365821838379
Validation loss: 1.9813307639091247

Epoch: 6| Step: 2
Training loss: 2.303654193878174
Validation loss: 1.9931924830200851

Epoch: 6| Step: 3
Training loss: 2.459529399871826
Validation loss: 1.9621351303592804

Epoch: 6| Step: 4
Training loss: 2.3772318363189697
Validation loss: 1.9591625198241203

Epoch: 6| Step: 5
Training loss: 1.983407735824585
Validation loss: 1.967713456000051

Epoch: 6| Step: 6
Training loss: 2.2376492023468018
Validation loss: 1.9761833093499626

Epoch: 6| Step: 7
Training loss: 2.0375914573669434
Validation loss: 1.9928690336083854

Epoch: 6| Step: 8
Training loss: 1.8805166482925415
Validation loss: 1.9899167450525428

Epoch: 6| Step: 9
Training loss: 2.2130253314971924
Validation loss: 1.9969979486157816

Epoch: 6| Step: 10
Training loss: 2.3994994163513184
Validation loss: 1.9691290804134902

Epoch: 6| Step: 11
Training loss: 2.0720438957214355
Validation loss: 1.9841851931746288

Epoch: 6| Step: 12
Training loss: 2.492323398590088
Validation loss: 2.0019477977547595

Epoch: 6| Step: 13
Training loss: 2.2030136585235596
Validation loss: 1.9846196764258928

Epoch: 93| Step: 0
Training loss: 1.474984884262085
Validation loss: 1.9805942068817795

Epoch: 6| Step: 1
Training loss: 1.781797170639038
Validation loss: 1.9869890687286214

Epoch: 6| Step: 2
Training loss: 2.5260701179504395
Validation loss: 2.0076614144027873

Epoch: 6| Step: 3
Training loss: 2.6515119075775146
Validation loss: 1.9922020948061379

Epoch: 6| Step: 4
Training loss: 1.837618112564087
Validation loss: 1.9828883268499886

Epoch: 6| Step: 5
Training loss: 2.353701114654541
Validation loss: 2.002366917107695

Epoch: 6| Step: 6
Training loss: 2.471916675567627
Validation loss: 1.996087674171694

Epoch: 6| Step: 7
Training loss: 2.489865779876709
Validation loss: 1.9863760996890325

Epoch: 6| Step: 8
Training loss: 2.215578556060791
Validation loss: 1.9831119468135219

Epoch: 6| Step: 9
Training loss: 1.9577045440673828
Validation loss: 1.986129919687907

Epoch: 6| Step: 10
Training loss: 2.624616861343384
Validation loss: 1.9892858869285994

Epoch: 6| Step: 11
Training loss: 2.1061925888061523
Validation loss: 1.9931693294996857

Epoch: 6| Step: 12
Training loss: 2.0836281776428223
Validation loss: 1.999711908319945

Epoch: 6| Step: 13
Training loss: 2.3276796340942383
Validation loss: 1.9988495162738267

Epoch: 94| Step: 0
Training loss: 1.9266387224197388
Validation loss: 1.9828848838806152

Epoch: 6| Step: 1
Training loss: 2.0419929027557373
Validation loss: 1.9831421362456454

Epoch: 6| Step: 2
Training loss: 2.3780431747436523
Validation loss: 1.9916203483458488

Epoch: 6| Step: 3
Training loss: 1.9816802740097046
Validation loss: 1.980757377480948

Epoch: 6| Step: 4
Training loss: 2.4108409881591797
Validation loss: 1.9868971942573466

Epoch: 6| Step: 5
Training loss: 1.8908851146697998
Validation loss: 1.9869390431270804

Epoch: 6| Step: 6
Training loss: 2.118901014328003
Validation loss: 1.9715457065131075

Epoch: 6| Step: 7
Training loss: 1.962956428527832
Validation loss: 1.9751457629665252

Epoch: 6| Step: 8
Training loss: 2.5103421211242676
Validation loss: 1.9766079405302643

Epoch: 6| Step: 9
Training loss: 2.830789089202881
Validation loss: 1.9669533775698753

Epoch: 6| Step: 10
Training loss: 2.12530517578125
Validation loss: 1.9661334945309548

Epoch: 6| Step: 11
Training loss: 1.8254603147506714
Validation loss: 1.955565675612419

Epoch: 6| Step: 12
Training loss: 2.8399362564086914
Validation loss: 1.965267942797753

Epoch: 6| Step: 13
Training loss: 1.934215784072876
Validation loss: 1.9549218070122503

Epoch: 95| Step: 0
Training loss: 3.098752737045288
Validation loss: 1.9798632616637855

Epoch: 6| Step: 1
Training loss: 2.22991681098938
Validation loss: 1.9593092228776665

Epoch: 6| Step: 2
Training loss: 1.3811806440353394
Validation loss: 1.974678211314704

Epoch: 6| Step: 3
Training loss: 2.834564208984375
Validation loss: 1.9525379724400018

Epoch: 6| Step: 4
Training loss: 1.8437769412994385
Validation loss: 1.9756874397236814

Epoch: 6| Step: 5
Training loss: 2.061995506286621
Validation loss: 1.9604742116825555

Epoch: 6| Step: 6
Training loss: 2.537628173828125
Validation loss: 1.9513691945742535

Epoch: 6| Step: 7
Training loss: 2.8335928916931152
Validation loss: 1.954847006387608

Epoch: 6| Step: 8
Training loss: 2.2519898414611816
Validation loss: 1.9701860963657338

Epoch: 6| Step: 9
Training loss: 1.7314376831054688
Validation loss: 1.95691506965186

Epoch: 6| Step: 10
Training loss: 2.183328151702881
Validation loss: 1.9769483779066352

Epoch: 6| Step: 11
Training loss: 1.3489675521850586
Validation loss: 1.984038863130795

Epoch: 6| Step: 12
Training loss: 2.478811740875244
Validation loss: 1.9575890353930894

Epoch: 6| Step: 13
Training loss: 1.9236929416656494
Validation loss: 1.976044657409832

Epoch: 96| Step: 0
Training loss: 2.2814126014709473
Validation loss: 1.9708314223956036

Epoch: 6| Step: 1
Training loss: 1.8343727588653564
Validation loss: 1.9818455532032957

Epoch: 6| Step: 2
Training loss: 2.7578814029693604
Validation loss: 1.9754385255998181

Epoch: 6| Step: 3
Training loss: 1.5820468664169312
Validation loss: 1.9880887513519616

Epoch: 6| Step: 4
Training loss: 2.277700901031494
Validation loss: 1.9805102758510138

Epoch: 6| Step: 5
Training loss: 2.637085437774658
Validation loss: 1.9844308284021193

Epoch: 6| Step: 6
Training loss: 2.1382524967193604
Validation loss: 1.9845854877143778

Epoch: 6| Step: 7
Training loss: 1.6938951015472412
Validation loss: 1.9827234898844073

Epoch: 6| Step: 8
Training loss: 1.9994417428970337
Validation loss: 1.9883835354158956

Epoch: 6| Step: 9
Training loss: 2.406996250152588
Validation loss: 2.009374395493538

Epoch: 6| Step: 10
Training loss: 1.8395278453826904
Validation loss: 1.9514449373368294

Epoch: 6| Step: 11
Training loss: 2.9723856449127197
Validation loss: 1.9748740914047405

Epoch: 6| Step: 12
Training loss: 2.050539016723633
Validation loss: 1.97368819995593

Epoch: 6| Step: 13
Training loss: 2.5260820388793945
Validation loss: 1.9824059573552941

Epoch: 97| Step: 0
Training loss: 2.155068874359131
Validation loss: 1.9805220045069212

Epoch: 6| Step: 1
Training loss: 2.4397101402282715
Validation loss: 1.9859501956611552

Epoch: 6| Step: 2
Training loss: 2.2949705123901367
Validation loss: 1.9800549604559456

Epoch: 6| Step: 3
Training loss: 1.945029854774475
Validation loss: 1.9751792902587562

Epoch: 6| Step: 4
Training loss: 2.3507232666015625
Validation loss: 1.97528709519294

Epoch: 6| Step: 5
Training loss: 2.3058037757873535
Validation loss: 1.9507181362439228

Epoch: 6| Step: 6
Training loss: 1.5740182399749756
Validation loss: 1.981038232003489

Epoch: 6| Step: 7
Training loss: 2.4163053035736084
Validation loss: 1.9716009683506464

Epoch: 6| Step: 8
Training loss: 2.465959310531616
Validation loss: 1.9770727606229885

Epoch: 6| Step: 9
Training loss: 2.51650071144104
Validation loss: 1.9861811335368822

Epoch: 6| Step: 10
Training loss: 1.8659989833831787
Validation loss: 1.9568461064369447

Epoch: 6| Step: 11
Training loss: 2.3444671630859375
Validation loss: 1.97218241101952

Epoch: 6| Step: 12
Training loss: 1.6779359579086304
Validation loss: 1.9829550814884964

Epoch: 6| Step: 13
Training loss: 2.452224016189575
Validation loss: 1.9782061987025763

Epoch: 98| Step: 0
Training loss: 2.6992061138153076
Validation loss: 1.977685127207028

Epoch: 6| Step: 1
Training loss: 2.280904769897461
Validation loss: 1.9681042548148864

Epoch: 6| Step: 2
Training loss: 1.7173771858215332
Validation loss: 1.995620281465592

Epoch: 6| Step: 3
Training loss: 1.711877465248108
Validation loss: 1.9428843170083978

Epoch: 6| Step: 4
Training loss: 2.404940366744995
Validation loss: 1.9861465859156784

Epoch: 6| Step: 5
Training loss: 2.1496529579162598
Validation loss: 1.9874920383576424

Epoch: 6| Step: 6
Training loss: 2.5029501914978027
Validation loss: 1.975555125103202

Epoch: 6| Step: 7
Training loss: 2.11568284034729
Validation loss: 1.9722358667722313

Epoch: 6| Step: 8
Training loss: 2.1454381942749023
Validation loss: 1.9911000318424676

Epoch: 6| Step: 9
Training loss: 1.575042963027954
Validation loss: 1.9878835511463944

Epoch: 6| Step: 10
Training loss: 2.4275128841400146
Validation loss: 1.9886197172185427

Epoch: 6| Step: 11
Training loss: 2.5573368072509766
Validation loss: 1.970532755697927

Epoch: 6| Step: 12
Training loss: 2.6484415531158447
Validation loss: 1.9820447890989241

Epoch: 6| Step: 13
Training loss: 1.1311501264572144
Validation loss: 1.9742429282075615

Epoch: 99| Step: 0
Training loss: 1.8706483840942383
Validation loss: 1.96630431759742

Epoch: 6| Step: 1
Training loss: 2.934521198272705
Validation loss: 2.00542793222653

Epoch: 6| Step: 2
Training loss: 2.121919870376587
Validation loss: 1.9869133259660454

Epoch: 6| Step: 3
Training loss: 2.3264291286468506
Validation loss: 1.975692569568593

Epoch: 6| Step: 4
Training loss: 1.554422378540039
Validation loss: 1.988435181238318

Epoch: 6| Step: 5
Training loss: 1.7880887985229492
Validation loss: 1.9755332982668312

Epoch: 6| Step: 6
Training loss: 2.2080886363983154
Validation loss: 1.9917145134300314

Epoch: 6| Step: 7
Training loss: 2.0436007976531982
Validation loss: 1.9861349572417557

Epoch: 6| Step: 8
Training loss: 1.919565200805664
Validation loss: 1.98985973224845

Epoch: 6| Step: 9
Training loss: 2.1854796409606934
Validation loss: 1.995759646097819

Epoch: 6| Step: 10
Training loss: 2.4171595573425293
Validation loss: 1.9982460057863625

Epoch: 6| Step: 11
Training loss: 2.5608012676239014
Validation loss: 2.0092898825163483

Epoch: 6| Step: 12
Training loss: 2.4009201526641846
Validation loss: 1.9974747793648833

Epoch: 6| Step: 13
Training loss: 2.56244158744812
Validation loss: 2.0048319934516825

Epoch: 100| Step: 0
Training loss: 2.104525566101074
Validation loss: 2.002720830261066

Epoch: 6| Step: 1
Training loss: 2.39890456199646
Validation loss: 2.0137686934522403

Epoch: 6| Step: 2
Training loss: 2.5402584075927734
Validation loss: 2.0302096810392154

Epoch: 6| Step: 3
Training loss: 2.122424840927124
Validation loss: 2.019745542157081

Epoch: 6| Step: 4
Training loss: 2.003098726272583
Validation loss: 2.007213838638798

Epoch: 6| Step: 5
Training loss: 2.4349403381347656
Validation loss: 2.007082655865659

Epoch: 6| Step: 6
Training loss: 2.02524995803833
Validation loss: 2.0193242180731987

Epoch: 6| Step: 7
Training loss: 2.1651227474212646
Validation loss: 2.0273794589504117

Epoch: 6| Step: 8
Training loss: 2.082059860229492
Validation loss: 2.0161766749556347

Epoch: 6| Step: 9
Training loss: 2.1787562370300293
Validation loss: 2.01816076232541

Epoch: 6| Step: 10
Training loss: 2.580209970474243
Validation loss: 2.014323693449779

Epoch: 6| Step: 11
Training loss: 1.5924491882324219
Validation loss: 2.031130817628676

Epoch: 6| Step: 12
Training loss: 2.2491276264190674
Validation loss: 2.0185903631230837

Epoch: 6| Step: 13
Training loss: 2.1762733459472656
Validation loss: 2.004319506306802

Epoch: 101| Step: 0
Training loss: 1.934455394744873
Validation loss: 2.002707435238746

Epoch: 6| Step: 1
Training loss: 2.226516008377075
Validation loss: 2.0004843716980307

Epoch: 6| Step: 2
Training loss: 2.4466166496276855
Validation loss: 1.9831667433502853

Epoch: 6| Step: 3
Training loss: 1.7917243242263794
Validation loss: 1.9902303270114365

Epoch: 6| Step: 4
Training loss: 2.5038537979125977
Validation loss: 1.9816229138323056

Epoch: 6| Step: 5
Training loss: 2.6234145164489746
Validation loss: 1.9739549467640538

Epoch: 6| Step: 6
Training loss: 2.374433994293213
Validation loss: 1.9961489708192888

Epoch: 6| Step: 7
Training loss: 1.6633883714675903
Validation loss: 1.9668434537867063

Epoch: 6| Step: 8
Training loss: 2.467109203338623
Validation loss: 1.9850261108849638

Epoch: 6| Step: 9
Training loss: 2.6997458934783936
Validation loss: 1.9712420996799265

Epoch: 6| Step: 10
Training loss: 1.8350610733032227
Validation loss: 1.98929593383625

Epoch: 6| Step: 11
Training loss: 2.0321366786956787
Validation loss: 1.9810519397899669

Epoch: 6| Step: 12
Training loss: 2.280601739883423
Validation loss: 1.9740059760309034

Epoch: 6| Step: 13
Training loss: 1.5563241243362427
Validation loss: 1.979131611444617

Epoch: 102| Step: 0
Training loss: 2.3803138732910156
Validation loss: 1.9638471436756912

Epoch: 6| Step: 1
Training loss: 2.202415943145752
Validation loss: 1.9694429059182443

Epoch: 6| Step: 2
Training loss: 1.8955600261688232
Validation loss: 1.9656446595345773

Epoch: 6| Step: 3
Training loss: 1.6111171245574951
Validation loss: 1.9587838777931788

Epoch: 6| Step: 4
Training loss: 2.066352367401123
Validation loss: 1.967825302513697

Epoch: 6| Step: 5
Training loss: 2.713685989379883
Validation loss: 1.9655507943963493

Epoch: 6| Step: 6
Training loss: 1.9614522457122803
Validation loss: 1.987346310769358

Epoch: 6| Step: 7
Training loss: 1.742521047592163
Validation loss: 1.9869841196203744

Epoch: 6| Step: 8
Training loss: 2.508762836456299
Validation loss: 1.9595514946086432

Epoch: 6| Step: 9
Training loss: 1.8839707374572754
Validation loss: 1.9672545604808356

Epoch: 6| Step: 10
Training loss: 2.3610148429870605
Validation loss: 1.9719558210783108

Epoch: 6| Step: 11
Training loss: 3.0153067111968994
Validation loss: 1.965063984676074

Epoch: 6| Step: 12
Training loss: 2.1702768802642822
Validation loss: 1.9671584867662

Epoch: 6| Step: 13
Training loss: 2.0043628215789795
Validation loss: 1.966177330222181

Epoch: 103| Step: 0
Training loss: 2.4554407596588135
Validation loss: 1.9695668361520255

Epoch: 6| Step: 1
Training loss: 2.1062419414520264
Validation loss: 1.9642251383873723

Epoch: 6| Step: 2
Training loss: 2.8438220024108887
Validation loss: 1.988429659156389

Epoch: 6| Step: 3
Training loss: 1.7283437252044678
Validation loss: 1.9707637627919514

Epoch: 6| Step: 4
Training loss: 1.9163364171981812
Validation loss: 1.9826528462030555

Epoch: 6| Step: 5
Training loss: 2.970409631729126
Validation loss: 1.9972740219485374

Epoch: 6| Step: 6
Training loss: 2.04620099067688
Validation loss: 2.004470416294631

Epoch: 6| Step: 7
Training loss: 2.2437660694122314
Validation loss: 1.9810636094821397

Epoch: 6| Step: 8
Training loss: 2.985853433609009
Validation loss: 2.009147959370767

Epoch: 6| Step: 9
Training loss: 1.4733878374099731
Validation loss: 1.9951457208202732

Epoch: 6| Step: 10
Training loss: 1.999483585357666
Validation loss: 2.0204611606495355

Epoch: 6| Step: 11
Training loss: 1.340197205543518
Validation loss: 2.008358035036313

Epoch: 6| Step: 12
Training loss: 2.459686040878296
Validation loss: 2.004943293909873

Epoch: 6| Step: 13
Training loss: 2.0125036239624023
Validation loss: 1.9895523337907688

Epoch: 104| Step: 0
Training loss: 1.8526759147644043
Validation loss: 1.9904341620783652

Epoch: 6| Step: 1
Training loss: 2.4272375106811523
Validation loss: 1.9920054020420197

Epoch: 6| Step: 2
Training loss: 2.307060718536377
Validation loss: 1.9884685816303376

Epoch: 6| Step: 3
Training loss: 1.9757232666015625
Validation loss: 1.9788613101487518

Epoch: 6| Step: 4
Training loss: 1.787329077720642
Validation loss: 1.9811693288946663

Epoch: 6| Step: 5
Training loss: 1.9896119832992554
Validation loss: 1.9957327073620212

Epoch: 6| Step: 6
Training loss: 2.1981096267700195
Validation loss: 1.9662713286697224

Epoch: 6| Step: 7
Training loss: 2.1901001930236816
Validation loss: 1.9838936777525051

Epoch: 6| Step: 8
Training loss: 1.4570863246917725
Validation loss: 1.9680132019904353

Epoch: 6| Step: 9
Training loss: 3.2637135982513428
Validation loss: 1.9755006849124868

Epoch: 6| Step: 10
Training loss: 1.9637022018432617
Validation loss: 1.9795282566419212

Epoch: 6| Step: 11
Training loss: 2.360832691192627
Validation loss: 1.9654825438735306

Epoch: 6| Step: 12
Training loss: 3.009787082672119
Validation loss: 1.9615374265178558

Epoch: 6| Step: 13
Training loss: 1.550347089767456
Validation loss: 1.9777880150784728

Epoch: 105| Step: 0
Training loss: 2.784440517425537
Validation loss: 1.969903774158929

Epoch: 6| Step: 1
Training loss: 2.557340145111084
Validation loss: 1.9770027950245848

Epoch: 6| Step: 2
Training loss: 2.4310755729675293
Validation loss: 1.9820251977571877

Epoch: 6| Step: 3
Training loss: 2.047511339187622
Validation loss: 1.975378579990838

Epoch: 6| Step: 4
Training loss: 2.253384828567505
Validation loss: 1.9769136585215086

Epoch: 6| Step: 5
Training loss: 2.154500961303711
Validation loss: 1.99101000191063

Epoch: 6| Step: 6
Training loss: 1.7986475229263306
Validation loss: 1.9607926568677347

Epoch: 6| Step: 7
Training loss: 2.185849189758301
Validation loss: 1.9890705539334206

Epoch: 6| Step: 8
Training loss: 1.7744858264923096
Validation loss: 1.9743506164960964

Epoch: 6| Step: 9
Training loss: 1.897657871246338
Validation loss: 1.9673952133424821

Epoch: 6| Step: 10
Training loss: 1.7987874746322632
Validation loss: 1.9351187265047463

Epoch: 6| Step: 11
Training loss: 2.2800817489624023
Validation loss: 1.9765207306031258

Epoch: 6| Step: 12
Training loss: 1.9124130010604858
Validation loss: 1.9512752486813454

Epoch: 6| Step: 13
Training loss: 3.044583320617676
Validation loss: 1.9632025072651524

Epoch: 106| Step: 0
Training loss: 1.9754091501235962
Validation loss: 1.979944900799823

Epoch: 6| Step: 1
Training loss: 2.2088279724121094
Validation loss: 1.9725573293624385

Epoch: 6| Step: 2
Training loss: 1.9114233255386353
Validation loss: 1.9813609430866856

Epoch: 6| Step: 3
Training loss: 2.594128131866455
Validation loss: 1.9650407401464318

Epoch: 6| Step: 4
Training loss: 1.350923776626587
Validation loss: 1.9750859506668583

Epoch: 6| Step: 5
Training loss: 2.2873589992523193
Validation loss: 1.9941020498993576

Epoch: 6| Step: 6
Training loss: 2.4085469245910645
Validation loss: 1.9698830125152424

Epoch: 6| Step: 7
Training loss: 2.4966890811920166
Validation loss: 1.9871132783992316

Epoch: 6| Step: 8
Training loss: 2.503554582595825
Validation loss: 1.9982024495319655

Epoch: 6| Step: 9
Training loss: 2.4049124717712402
Validation loss: 2.0046030629065728

Epoch: 6| Step: 10
Training loss: 2.270691156387329
Validation loss: 2.013494840232275

Epoch: 6| Step: 11
Training loss: 2.1223628520965576
Validation loss: 2.013224886309716

Epoch: 6| Step: 12
Training loss: 2.48766827583313
Validation loss: 2.010633009736256

Epoch: 6| Step: 13
Training loss: 1.192667841911316
Validation loss: 2.0109366293876403

Epoch: 107| Step: 0
Training loss: 2.0595951080322266
Validation loss: 2.015699230214601

Epoch: 6| Step: 1
Training loss: 2.046079158782959
Validation loss: 1.9976359413516136

Epoch: 6| Step: 2
Training loss: 2.8946211338043213
Validation loss: 2.016129844932146

Epoch: 6| Step: 3
Training loss: 2.0771031379699707
Validation loss: 1.982744986011136

Epoch: 6| Step: 4
Training loss: 2.3623154163360596
Validation loss: 1.9947656277687318

Epoch: 6| Step: 5
Training loss: 2.327005386352539
Validation loss: 2.004067700396302

Epoch: 6| Step: 6
Training loss: 2.1746811866760254
Validation loss: 1.9999066424626175

Epoch: 6| Step: 7
Training loss: 1.9975793361663818
Validation loss: 2.007352630297343

Epoch: 6| Step: 8
Training loss: 2.64585280418396
Validation loss: 2.0040622821418186

Epoch: 6| Step: 9
Training loss: 2.4941930770874023
Validation loss: 1.9886337364873579

Epoch: 6| Step: 10
Training loss: 2.2406115531921387
Validation loss: 2.009608317446965

Epoch: 6| Step: 11
Training loss: 1.8260691165924072
Validation loss: 1.9951610385730703

Epoch: 6| Step: 12
Training loss: 1.2716178894042969
Validation loss: 1.9786218033042005

Epoch: 6| Step: 13
Training loss: 1.711369276046753
Validation loss: 1.9542249223237396

Epoch: 108| Step: 0
Training loss: 2.5334489345550537
Validation loss: 1.9640682179440734

Epoch: 6| Step: 1
Training loss: 2.6575942039489746
Validation loss: 1.9837510585784912

Epoch: 6| Step: 2
Training loss: 2.1889185905456543
Validation loss: 1.983936631551353

Epoch: 6| Step: 3
Training loss: 2.3900833129882812
Validation loss: 1.9749626703159784

Epoch: 6| Step: 4
Training loss: 2.224216938018799
Validation loss: 1.981969202718427

Epoch: 6| Step: 5
Training loss: 2.1819567680358887
Validation loss: 1.9915326949088805

Epoch: 6| Step: 6
Training loss: 1.7118127346038818
Validation loss: 1.9918119971470167

Epoch: 6| Step: 7
Training loss: 1.8544890880584717
Validation loss: 2.0116298275609172

Epoch: 6| Step: 8
Training loss: 2.0890233516693115
Validation loss: 1.9841545051144016

Epoch: 6| Step: 9
Training loss: 1.7960821390151978
Validation loss: 1.986125188489114

Epoch: 6| Step: 10
Training loss: 1.8780105113983154
Validation loss: 1.9852227792944959

Epoch: 6| Step: 11
Training loss: 2.6838743686676025
Validation loss: 1.9824356776411816

Epoch: 6| Step: 12
Training loss: 2.0764122009277344
Validation loss: 1.9857760321709417

Epoch: 6| Step: 13
Training loss: 2.0862209796905518
Validation loss: 1.9886480710839713

Epoch: 109| Step: 0
Training loss: 2.7936739921569824
Validation loss: 1.977961778640747

Epoch: 6| Step: 1
Training loss: 2.7504255771636963
Validation loss: 1.9714577377483409

Epoch: 6| Step: 2
Training loss: 1.7467676401138306
Validation loss: 1.9893177196543703

Epoch: 6| Step: 3
Training loss: 1.9150826930999756
Validation loss: 1.9825814347113333

Epoch: 6| Step: 4
Training loss: 2.4531517028808594
Validation loss: 2.0060014699095037

Epoch: 6| Step: 5
Training loss: 2.0522372722625732
Validation loss: 1.9708012060452533

Epoch: 6| Step: 6
Training loss: 1.6223714351654053
Validation loss: 1.9774394035339355

Epoch: 6| Step: 7
Training loss: 1.9952268600463867
Validation loss: 1.986775775109568

Epoch: 6| Step: 8
Training loss: 2.181863307952881
Validation loss: 1.9793676894198182

Epoch: 6| Step: 9
Training loss: 1.793031930923462
Validation loss: 2.002784434185233

Epoch: 6| Step: 10
Training loss: 2.136249542236328
Validation loss: 1.991242249806722

Epoch: 6| Step: 11
Training loss: 2.4117345809936523
Validation loss: 1.9824103539989841

Epoch: 6| Step: 12
Training loss: 2.7902982234954834
Validation loss: 1.9756945051172727

Epoch: 6| Step: 13
Training loss: 1.517648696899414
Validation loss: 2.008004044973722

Epoch: 110| Step: 0
Training loss: 3.0255582332611084
Validation loss: 1.9778216423526886

Epoch: 6| Step: 1
Training loss: 2.3998477458953857
Validation loss: 1.9703310381981634

Epoch: 6| Step: 2
Training loss: 1.519536018371582
Validation loss: 1.9822971410648798

Epoch: 6| Step: 3
Training loss: 1.5619127750396729
Validation loss: 1.962072362181961

Epoch: 6| Step: 4
Training loss: 2.075913429260254
Validation loss: 1.9891014278575938

Epoch: 6| Step: 5
Training loss: 2.367150068283081
Validation loss: 1.988348017456711

Epoch: 6| Step: 6
Training loss: 1.5197432041168213
Validation loss: 1.9809621418676069

Epoch: 6| Step: 7
Training loss: 1.9892674684524536
Validation loss: 1.9969548230530114

Epoch: 6| Step: 8
Training loss: 2.568333148956299
Validation loss: 2.0042706945891022

Epoch: 6| Step: 9
Training loss: 2.2762489318847656
Validation loss: 2.005868165723739

Epoch: 6| Step: 10
Training loss: 2.423764944076538
Validation loss: 2.0158485571543374

Epoch: 6| Step: 11
Training loss: 2.5301437377929688
Validation loss: 2.003098859581896

Epoch: 6| Step: 12
Training loss: 2.0924668312072754
Validation loss: 2.002876338138375

Epoch: 6| Step: 13
Training loss: 1.947329044342041
Validation loss: 1.9957950884296047

Epoch: 111| Step: 0
Training loss: 2.478600025177002
Validation loss: 2.006014754695277

Epoch: 6| Step: 1
Training loss: 1.5692541599273682
Validation loss: 2.005668277381569

Epoch: 6| Step: 2
Training loss: 2.736809253692627
Validation loss: 2.032255308602446

Epoch: 6| Step: 3
Training loss: 2.786943197250366
Validation loss: 1.9951926226256995

Epoch: 6| Step: 4
Training loss: 2.6982123851776123
Validation loss: 1.9936267663073797

Epoch: 6| Step: 5
Training loss: 2.097659111022949
Validation loss: 2.005449806490252

Epoch: 6| Step: 6
Training loss: 1.8958330154418945
Validation loss: 2.0046159054643367

Epoch: 6| Step: 7
Training loss: 2.774172306060791
Validation loss: 1.986190749752906

Epoch: 6| Step: 8
Training loss: 1.8602511882781982
Validation loss: 1.983958867288405

Epoch: 6| Step: 9
Training loss: 2.241377830505371
Validation loss: 1.987972451794532

Epoch: 6| Step: 10
Training loss: 1.7109858989715576
Validation loss: 1.9978307767580914

Epoch: 6| Step: 11
Training loss: 1.6906291246414185
Validation loss: 2.0084448424718713

Epoch: 6| Step: 12
Training loss: 2.060800313949585
Validation loss: 2.0250285440875637

Epoch: 6| Step: 13
Training loss: 1.2325276136398315
Validation loss: 2.032568834161246

Epoch: 112| Step: 0
Training loss: 1.936816692352295
Validation loss: 1.9843071006959485

Epoch: 6| Step: 1
Training loss: 2.0844123363494873
Validation loss: 2.0108651397048787

Epoch: 6| Step: 2
Training loss: 1.8389477729797363
Validation loss: 1.9952544140559372

Epoch: 6| Step: 3
Training loss: 1.7563108205795288
Validation loss: 2.000548506295809

Epoch: 6| Step: 4
Training loss: 1.4416311979293823
Validation loss: 1.9605322781429495

Epoch: 6| Step: 5
Training loss: 2.4070096015930176
Validation loss: 1.9797257851528864

Epoch: 6| Step: 6
Training loss: 2.6902730464935303
Validation loss: 1.9968494753683768

Epoch: 6| Step: 7
Training loss: 2.585190773010254
Validation loss: 1.999183847058204

Epoch: 6| Step: 8
Training loss: 2.0941238403320312
Validation loss: 1.9881622304198563

Epoch: 6| Step: 9
Training loss: 1.2699472904205322
Validation loss: 1.9940747061083395

Epoch: 6| Step: 10
Training loss: 2.2828991413116455
Validation loss: 1.9562664160164454

Epoch: 6| Step: 11
Training loss: 2.513418674468994
Validation loss: 1.9918528372241604

Epoch: 6| Step: 12
Training loss: 3.174752712249756
Validation loss: 1.9591436937291136

Epoch: 6| Step: 13
Training loss: 2.3444664478302
Validation loss: 1.9964366587259437

Epoch: 113| Step: 0
Training loss: 2.451338291168213
Validation loss: 1.9626722169178787

Epoch: 6| Step: 1
Training loss: 2.7346272468566895
Validation loss: 1.9718942206393006

Epoch: 6| Step: 2
Training loss: 1.9849281311035156
Validation loss: 1.9670162406018985

Epoch: 6| Step: 3
Training loss: 2.2672524452209473
Validation loss: 1.9652044132191648

Epoch: 6| Step: 4
Training loss: 2.7765369415283203
Validation loss: 1.9685434782376854

Epoch: 6| Step: 5
Training loss: 2.177870988845825
Validation loss: 1.9725066077324651

Epoch: 6| Step: 6
Training loss: 1.3515007495880127
Validation loss: 1.9599709356984785

Epoch: 6| Step: 7
Training loss: 1.732847809791565
Validation loss: 1.9986272037670176

Epoch: 6| Step: 8
Training loss: 2.0000662803649902
Validation loss: 1.9906536122804046

Epoch: 6| Step: 9
Training loss: 1.6030631065368652
Validation loss: 1.9814126273637176

Epoch: 6| Step: 10
Training loss: 1.8994998931884766
Validation loss: 1.9784668350732455

Epoch: 6| Step: 11
Training loss: 2.616058349609375
Validation loss: 2.0007532924734135

Epoch: 6| Step: 12
Training loss: 2.20928955078125
Validation loss: 2.003942721633501

Epoch: 6| Step: 13
Training loss: 2.717074394226074
Validation loss: 1.9864911904899023

Epoch: 114| Step: 0
Training loss: 1.8478562831878662
Validation loss: 2.0048982366438834

Epoch: 6| Step: 1
Training loss: 2.167285919189453
Validation loss: 1.9981663573172785

Epoch: 6| Step: 2
Training loss: 1.6636106967926025
Validation loss: 1.9904141477359238

Epoch: 6| Step: 3
Training loss: 2.0034592151641846
Validation loss: 1.9990403165099442

Epoch: 6| Step: 4
Training loss: 2.4962892532348633
Validation loss: 2.009700322663912

Epoch: 6| Step: 5
Training loss: 1.9983271360397339
Validation loss: 2.0055953892328406

Epoch: 6| Step: 6
Training loss: 2.1693921089172363
Validation loss: 1.9964632629066386

Epoch: 6| Step: 7
Training loss: 2.1572580337524414
Validation loss: 2.003840886136537

Epoch: 6| Step: 8
Training loss: 2.417207717895508
Validation loss: 2.0022469592350784

Epoch: 6| Step: 9
Training loss: 1.9771519899368286
Validation loss: 1.9952030130611953

Epoch: 6| Step: 10
Training loss: 2.5569820404052734
Validation loss: 1.97827959317033

Epoch: 6| Step: 11
Training loss: 2.122758150100708
Validation loss: 1.9900778416664369

Epoch: 6| Step: 12
Training loss: 2.3619070053100586
Validation loss: 1.9890810981873543

Epoch: 6| Step: 13
Training loss: 2.214191436767578
Validation loss: 1.9971543486400316

Epoch: 115| Step: 0
Training loss: 2.2689924240112305
Validation loss: 1.9891151997350878

Epoch: 6| Step: 1
Training loss: 2.1844735145568848
Validation loss: 1.9899308784033662

Epoch: 6| Step: 2
Training loss: 2.075521469116211
Validation loss: 1.99163786057503

Epoch: 6| Step: 3
Training loss: 2.722259998321533
Validation loss: 1.9937481085459392

Epoch: 6| Step: 4
Training loss: 2.6816391944885254
Validation loss: 1.9829305384748726

Epoch: 6| Step: 5
Training loss: 2.138011932373047
Validation loss: 1.9990214904149373

Epoch: 6| Step: 6
Training loss: 2.211984395980835
Validation loss: 1.9972035154219596

Epoch: 6| Step: 7
Training loss: 1.4876346588134766
Validation loss: 1.99203920877108

Epoch: 6| Step: 8
Training loss: 2.508589267730713
Validation loss: 1.9926190286554315

Epoch: 6| Step: 9
Training loss: 1.685227394104004
Validation loss: 2.0145453868373746

Epoch: 6| Step: 10
Training loss: 1.5580527782440186
Validation loss: 2.011143822823801

Epoch: 6| Step: 11
Training loss: 2.6642422676086426
Validation loss: 2.007692836946057

Epoch: 6| Step: 12
Training loss: 1.6727683544158936
Validation loss: 1.996290845255698

Epoch: 6| Step: 13
Training loss: 2.580395221710205
Validation loss: 2.0116653045018515

Epoch: 116| Step: 0
Training loss: 2.6615705490112305
Validation loss: 1.994376282538137

Epoch: 6| Step: 1
Training loss: 2.0757851600646973
Validation loss: 2.0039170147270284

Epoch: 6| Step: 2
Training loss: 2.128749370574951
Validation loss: 2.002779165903727

Epoch: 6| Step: 3
Training loss: 1.9612035751342773
Validation loss: 2.017149697067917

Epoch: 6| Step: 4
Training loss: 1.4818878173828125
Validation loss: 1.9953275931778776

Epoch: 6| Step: 5
Training loss: 2.3754286766052246
Validation loss: 1.9744433459415232

Epoch: 6| Step: 6
Training loss: 1.7350932359695435
Validation loss: 1.9984280499078895

Epoch: 6| Step: 7
Training loss: 2.4373891353607178
Validation loss: 1.9702457035741499

Epoch: 6| Step: 8
Training loss: 2.5358824729919434
Validation loss: 1.9691417114709013

Epoch: 6| Step: 9
Training loss: 2.486759901046753
Validation loss: 1.975174678269253

Epoch: 6| Step: 10
Training loss: 1.6234676837921143
Validation loss: 1.986107418614049

Epoch: 6| Step: 11
Training loss: 2.0301222801208496
Validation loss: 1.9841909152205273

Epoch: 6| Step: 12
Training loss: 2.039553165435791
Validation loss: 1.9721713296828731

Epoch: 6| Step: 13
Training loss: 2.602541923522949
Validation loss: 1.9558206168554162

Epoch: 117| Step: 0
Training loss: 2.126767158508301
Validation loss: 1.9652930869851062

Epoch: 6| Step: 1
Training loss: 1.8084468841552734
Validation loss: 1.987829408337993

Epoch: 6| Step: 2
Training loss: 2.336699962615967
Validation loss: 1.9917737360923522

Epoch: 6| Step: 3
Training loss: 2.8138794898986816
Validation loss: 1.9912681618044454

Epoch: 6| Step: 4
Training loss: 2.2278077602386475
Validation loss: 1.992417504710536

Epoch: 6| Step: 5
Training loss: 1.355015516281128
Validation loss: 2.000621750790586

Epoch: 6| Step: 6
Training loss: 2.81514310836792
Validation loss: 2.008537596271884

Epoch: 6| Step: 7
Training loss: 1.9579654932022095
Validation loss: 2.002470982972012

Epoch: 6| Step: 8
Training loss: 2.6933956146240234
Validation loss: 2.012717754610123

Epoch: 6| Step: 9
Training loss: 2.552117347717285
Validation loss: 2.022927984114616

Epoch: 6| Step: 10
Training loss: 2.047222375869751
Validation loss: 2.0049027960787535

Epoch: 6| Step: 11
Training loss: 2.259577751159668
Validation loss: 2.014890217011975

Epoch: 6| Step: 12
Training loss: 1.448545217514038
Validation loss: 2.0209240490390408

Epoch: 6| Step: 13
Training loss: 1.5636426210403442
Validation loss: 2.033368336257114

Epoch: 118| Step: 0
Training loss: 2.0835049152374268
Validation loss: 2.0262032131994925

Epoch: 6| Step: 1
Training loss: 1.6230552196502686
Validation loss: 2.0504976421274166

Epoch: 6| Step: 2
Training loss: 2.3709421157836914
Validation loss: 2.021686247600022

Epoch: 6| Step: 3
Training loss: 1.1063507795333862
Validation loss: 2.0339377285331808

Epoch: 6| Step: 4
Training loss: 2.2355637550354004
Validation loss: 2.024456816334878

Epoch: 6| Step: 5
Training loss: 2.047822952270508
Validation loss: 2.0355866391171693

Epoch: 6| Step: 6
Training loss: 2.4411988258361816
Validation loss: 2.0261762988182808

Epoch: 6| Step: 7
Training loss: 1.9197076559066772
Validation loss: 2.0272810587318997

Epoch: 6| Step: 8
Training loss: 2.3933849334716797
Validation loss: 2.020161026267595

Epoch: 6| Step: 9
Training loss: 1.7846460342407227
Validation loss: 2.0160917505141227

Epoch: 6| Step: 10
Training loss: 2.186905860900879
Validation loss: 1.980475418029293

Epoch: 6| Step: 11
Training loss: 3.1959757804870605
Validation loss: 2.0211089490562357

Epoch: 6| Step: 12
Training loss: 2.6280694007873535
Validation loss: 1.9928672621327062

Epoch: 6| Step: 13
Training loss: 1.9983950853347778
Validation loss: 1.9967660493748163

Epoch: 119| Step: 0
Training loss: 1.9426765441894531
Validation loss: 1.9801029928268925

Epoch: 6| Step: 1
Training loss: 2.014371633529663
Validation loss: 1.9930896553941952

Epoch: 6| Step: 2
Training loss: 1.7765815258026123
Validation loss: 1.9884161026247087

Epoch: 6| Step: 3
Training loss: 1.0598869323730469
Validation loss: 1.9924755019526328

Epoch: 6| Step: 4
Training loss: 2.5550286769866943
Validation loss: 2.0038517123909405

Epoch: 6| Step: 5
Training loss: 2.8142385482788086
Validation loss: 1.9723427577685284

Epoch: 6| Step: 6
Training loss: 2.0453689098358154
Validation loss: 1.9980641539378832

Epoch: 6| Step: 7
Training loss: 2.363921642303467
Validation loss: 1.9686406761087396

Epoch: 6| Step: 8
Training loss: 2.3395867347717285
Validation loss: 1.9834760427474976

Epoch: 6| Step: 9
Training loss: 2.676966905593872
Validation loss: 2.0075044580685195

Epoch: 6| Step: 10
Training loss: 2.2665483951568604
Validation loss: 1.9984006061348865

Epoch: 6| Step: 11
Training loss: 1.9840848445892334
Validation loss: 1.9904727474335702

Epoch: 6| Step: 12
Training loss: 2.2318825721740723
Validation loss: 2.016655529699018

Epoch: 6| Step: 13
Training loss: 2.1709489822387695
Validation loss: 2.0137695061263217

Epoch: 120| Step: 0
Training loss: 2.610257625579834
Validation loss: 2.011746150191112

Epoch: 6| Step: 1
Training loss: 2.907824993133545
Validation loss: 1.9778240342294016

Epoch: 6| Step: 2
Training loss: 2.5553407669067383
Validation loss: 2.008091042118688

Epoch: 6| Step: 3
Training loss: 2.0920019149780273
Validation loss: 2.00074492731402

Epoch: 6| Step: 4
Training loss: 2.0604233741760254
Validation loss: 1.9798319006478915

Epoch: 6| Step: 5
Training loss: 2.786184310913086
Validation loss: 2.0067566492224254

Epoch: 6| Step: 6
Training loss: 1.5241496562957764
Validation loss: 1.9849668971953853

Epoch: 6| Step: 7
Training loss: 2.2161550521850586
Validation loss: 1.9793264135237663

Epoch: 6| Step: 8
Training loss: 2.0059032440185547
Validation loss: 1.9888209604447888

Epoch: 6| Step: 9
Training loss: 2.3035166263580322
Validation loss: 1.9647744163390128

Epoch: 6| Step: 10
Training loss: 1.5373555421829224
Validation loss: 1.9777817418498378

Epoch: 6| Step: 11
Training loss: 1.622727632522583
Validation loss: 1.9675160787438835

Epoch: 6| Step: 12
Training loss: 1.8762526512145996
Validation loss: 1.9997976492809992

Epoch: 6| Step: 13
Training loss: 1.9642423391342163
Validation loss: 1.9795731126621205

Epoch: 121| Step: 0
Training loss: 2.038724422454834
Validation loss: 1.9835121605985908

Epoch: 6| Step: 1
Training loss: 2.7157106399536133
Validation loss: 2.0044819744684363

Epoch: 6| Step: 2
Training loss: 1.7249064445495605
Validation loss: 1.9896828820628505

Epoch: 6| Step: 3
Training loss: 1.7805594205856323
Validation loss: 1.994479763892389

Epoch: 6| Step: 4
Training loss: 2.1445484161376953
Validation loss: 2.0178401149729246

Epoch: 6| Step: 5
Training loss: 1.2730576992034912
Validation loss: 1.9954320358973678

Epoch: 6| Step: 6
Training loss: 2.6136021614074707
Validation loss: 2.020100889667388

Epoch: 6| Step: 7
Training loss: 1.9025853872299194
Validation loss: 1.9952276881023119

Epoch: 6| Step: 8
Training loss: 2.7503132820129395
Validation loss: 2.010408778344431

Epoch: 6| Step: 9
Training loss: 2.2335240840911865
Validation loss: 2.0125047250460555

Epoch: 6| Step: 10
Training loss: 1.836893081665039
Validation loss: 1.9935006403153943

Epoch: 6| Step: 11
Training loss: 2.1666221618652344
Validation loss: 2.0186913154458486

Epoch: 6| Step: 12
Training loss: 2.85347580909729
Validation loss: 2.0203991615644066

Epoch: 6| Step: 13
Training loss: 2.425375461578369
Validation loss: 2.0058112798198575

Epoch: 122| Step: 0
Training loss: 1.7627127170562744
Validation loss: 2.006179186605638

Epoch: 6| Step: 1
Training loss: 2.021683692932129
Validation loss: 2.028342745637381

Epoch: 6| Step: 2
Training loss: 2.1131751537323
Validation loss: 2.0052046955272718

Epoch: 6| Step: 3
Training loss: 1.967858076095581
Validation loss: 2.0153236581433203

Epoch: 6| Step: 4
Training loss: 2.0167014598846436
Validation loss: 2.011132305668246

Epoch: 6| Step: 5
Training loss: 2.0931124687194824
Validation loss: 1.996295141917403

Epoch: 6| Step: 6
Training loss: 2.0756258964538574
Validation loss: 2.0102229861802954

Epoch: 6| Step: 7
Training loss: 2.415290355682373
Validation loss: 1.9991027309048561

Epoch: 6| Step: 8
Training loss: 2.715881586074829
Validation loss: 2.0111173122159895

Epoch: 6| Step: 9
Training loss: 2.1027719974517822
Validation loss: 2.0036494244811354

Epoch: 6| Step: 10
Training loss: 2.140501022338867
Validation loss: 1.9949353497515443

Epoch: 6| Step: 11
Training loss: 1.8334197998046875
Validation loss: 1.995942666966428

Epoch: 6| Step: 12
Training loss: 1.9140236377716064
Validation loss: 2.0100236849118303

Epoch: 6| Step: 13
Training loss: 3.4138479232788086
Validation loss: 2.0005629857381186

Epoch: 123| Step: 0
Training loss: 1.93392813205719
Validation loss: 2.0052771235025055

Epoch: 6| Step: 1
Training loss: 2.524442434310913
Validation loss: 2.005569579780743

Epoch: 6| Step: 2
Training loss: 2.2378525733947754
Validation loss: 2.0106574591769966

Epoch: 6| Step: 3
Training loss: 2.0102367401123047
Validation loss: 1.9830512577487576

Epoch: 6| Step: 4
Training loss: 1.6013942956924438
Validation loss: 1.9894397386940577

Epoch: 6| Step: 5
Training loss: 1.8460253477096558
Validation loss: 1.996466262366182

Epoch: 6| Step: 6
Training loss: 1.9528858661651611
Validation loss: 1.9955070518678235

Epoch: 6| Step: 7
Training loss: 2.1075053215026855
Validation loss: 2.0113296995880785

Epoch: 6| Step: 8
Training loss: 2.1707026958465576
Validation loss: 1.9861140340887091

Epoch: 6| Step: 9
Training loss: 2.3582324981689453
Validation loss: 2.0103984801999983

Epoch: 6| Step: 10
Training loss: 2.8092169761657715
Validation loss: 1.9720320060688963

Epoch: 6| Step: 11
Training loss: 2.768923282623291
Validation loss: 2.0021242813397477

Epoch: 6| Step: 12
Training loss: 1.7165167331695557
Validation loss: 1.9885737203782605

Epoch: 6| Step: 13
Training loss: 1.8462382555007935
Validation loss: 2.001994571378154

Epoch: 124| Step: 0
Training loss: 1.9850776195526123
Validation loss: 1.9848489043533162

Epoch: 6| Step: 1
Training loss: 2.060328245162964
Validation loss: 1.989065194642672

Epoch: 6| Step: 2
Training loss: 1.8760995864868164
Validation loss: 2.002593225048434

Epoch: 6| Step: 3
Training loss: 2.7607262134552
Validation loss: 1.9823584415579354

Epoch: 6| Step: 4
Training loss: 2.3360702991485596
Validation loss: 1.989152467379006

Epoch: 6| Step: 5
Training loss: 1.9291458129882812
Validation loss: 2.0091916514981176

Epoch: 6| Step: 6
Training loss: 2.1070408821105957
Validation loss: 1.9897453528578564

Epoch: 6| Step: 7
Training loss: 2.2018280029296875
Validation loss: 1.9939946602749568

Epoch: 6| Step: 8
Training loss: 2.7963104248046875
Validation loss: 1.9958152501813826

Epoch: 6| Step: 9
Training loss: 2.408019781112671
Validation loss: 1.9725108685032013

Epoch: 6| Step: 10
Training loss: 1.8318713903427124
Validation loss: 1.989662777992987

Epoch: 6| Step: 11
Training loss: 2.006892681121826
Validation loss: 1.977893275599326

Epoch: 6| Step: 12
Training loss: 1.7287280559539795
Validation loss: 1.9863058918265886

Epoch: 6| Step: 13
Training loss: 1.4307998418807983
Validation loss: 1.9710844306535618

Epoch: 125| Step: 0
Training loss: 3.260593891143799
Validation loss: 2.0011844378645702

Epoch: 6| Step: 1
Training loss: 1.9622853994369507
Validation loss: 1.9943258223995086

Epoch: 6| Step: 2
Training loss: 2.01912784576416
Validation loss: 2.0109975004708893

Epoch: 6| Step: 3
Training loss: 1.8102234601974487
Validation loss: 2.02415273779182

Epoch: 6| Step: 4
Training loss: 2.4319229125976562
Validation loss: 2.037702429679132

Epoch: 6| Step: 5
Training loss: 2.3551077842712402
Validation loss: 2.002969971267126

Epoch: 6| Step: 6
Training loss: 1.9249812364578247
Validation loss: 2.0274604648672123

Epoch: 6| Step: 7
Training loss: 1.545127272605896
Validation loss: 2.0435412083902667

Epoch: 6| Step: 8
Training loss: 2.7612738609313965
Validation loss: 2.002888891004747

Epoch: 6| Step: 9
Training loss: 2.671677589416504
Validation loss: 2.007007433522132

Epoch: 6| Step: 10
Training loss: 1.6461567878723145
Validation loss: 2.021739516206967

Epoch: 6| Step: 11
Training loss: 1.5031123161315918
Validation loss: 2.024908083741383

Epoch: 6| Step: 12
Training loss: 2.590963363647461
Validation loss: 2.015438482325564

Epoch: 6| Step: 13
Training loss: 1.2243273258209229
Validation loss: 2.02663420092675

Epoch: 126| Step: 0
Training loss: 2.100830078125
Validation loss: 1.9948090237955893

Epoch: 6| Step: 1
Training loss: 1.756922721862793
Validation loss: 1.994659709674056

Epoch: 6| Step: 2
Training loss: 2.1942334175109863
Validation loss: 1.9784078444204023

Epoch: 6| Step: 3
Training loss: 2.3903374671936035
Validation loss: 2.0039871508075344

Epoch: 6| Step: 4
Training loss: 1.972874641418457
Validation loss: 1.9784503521457795

Epoch: 6| Step: 5
Training loss: 2.013312816619873
Validation loss: 1.9920683483923636

Epoch: 6| Step: 6
Training loss: 2.287172794342041
Validation loss: 2.0019455827692503

Epoch: 6| Step: 7
Training loss: 1.502580165863037
Validation loss: 1.9698402548349032

Epoch: 6| Step: 8
Training loss: 2.2483363151550293
Validation loss: 1.9810344531971922

Epoch: 6| Step: 9
Training loss: 2.5250115394592285
Validation loss: 1.9946272680836339

Epoch: 6| Step: 10
Training loss: 2.642467975616455
Validation loss: 1.9848346543568436

Epoch: 6| Step: 11
Training loss: 2.22635555267334
Validation loss: 1.9361726058426725

Epoch: 6| Step: 12
Training loss: 1.95677649974823
Validation loss: 1.9750323833957795

Epoch: 6| Step: 13
Training loss: 2.192526340484619
Validation loss: 1.9842531604151572

Epoch: 127| Step: 0
Training loss: 1.9931280612945557
Validation loss: 1.9883965497375817

Epoch: 6| Step: 1
Training loss: 1.4552900791168213
Validation loss: 1.9831412402532433

Epoch: 6| Step: 2
Training loss: 2.520951271057129
Validation loss: 1.9903097614165275

Epoch: 6| Step: 3
Training loss: 1.779101848602295
Validation loss: 1.9752609806676065

Epoch: 6| Step: 4
Training loss: 2.1762595176696777
Validation loss: 1.9879283046209684

Epoch: 6| Step: 5
Training loss: 2.6306629180908203
Validation loss: 1.9981429423055341

Epoch: 6| Step: 6
Training loss: 1.525739312171936
Validation loss: 1.969249322850217

Epoch: 6| Step: 7
Training loss: 2.2717952728271484
Validation loss: 1.9916105936932307

Epoch: 6| Step: 8
Training loss: 2.459956169128418
Validation loss: 1.9877145405738585

Epoch: 6| Step: 9
Training loss: 2.448500633239746
Validation loss: 2.0075752606955906

Epoch: 6| Step: 10
Training loss: 2.6272695064544678
Validation loss: 2.011259831408019

Epoch: 6| Step: 11
Training loss: 1.4414827823638916
Validation loss: 1.9888782757584766

Epoch: 6| Step: 12
Training loss: 1.963085412979126
Validation loss: 2.006405862428809

Epoch: 6| Step: 13
Training loss: 3.019057273864746
Validation loss: 1.9847266622768935

Epoch: 128| Step: 0
Training loss: 2.2023966312408447
Validation loss: 1.9882915494262532

Epoch: 6| Step: 1
Training loss: 2.57419753074646
Validation loss: 2.0216210990823726

Epoch: 6| Step: 2
Training loss: 1.7119107246398926
Validation loss: 2.0090100637046238

Epoch: 6| Step: 3
Training loss: 1.7809219360351562
Validation loss: 2.0241564012342885

Epoch: 6| Step: 4
Training loss: 2.6128287315368652
Validation loss: 1.9995448858507219

Epoch: 6| Step: 5
Training loss: 2.06366229057312
Validation loss: 2.001580469069942

Epoch: 6| Step: 6
Training loss: 1.8859021663665771
Validation loss: 2.0262846254533335

Epoch: 6| Step: 7
Training loss: 2.1764864921569824
Validation loss: 1.993678408284341

Epoch: 6| Step: 8
Training loss: 2.246878147125244
Validation loss: 2.003943504825715

Epoch: 6| Step: 9
Training loss: 2.6618738174438477
Validation loss: 2.0089957085988854

Epoch: 6| Step: 10
Training loss: 1.7430315017700195
Validation loss: 2.0089650256659395

Epoch: 6| Step: 11
Training loss: 2.0786807537078857
Validation loss: 2.0073979798183648

Epoch: 6| Step: 12
Training loss: 2.2134103775024414
Validation loss: 2.004115184148153

Epoch: 6| Step: 13
Training loss: 1.4783494472503662
Validation loss: 2.004192676595462

Epoch: 129| Step: 0
Training loss: 2.5510518550872803
Validation loss: 1.9868071489436652

Epoch: 6| Step: 1
Training loss: 2.004952907562256
Validation loss: 2.0051812612882225

Epoch: 6| Step: 2
Training loss: 2.26267671585083
Validation loss: 1.9876124807583389

Epoch: 6| Step: 3
Training loss: 1.9323647022247314
Validation loss: 1.9969736811935261

Epoch: 6| Step: 4
Training loss: 2.358149528503418
Validation loss: 2.0102623508822535

Epoch: 6| Step: 5
Training loss: 2.7688987255096436
Validation loss: 1.988822203810497

Epoch: 6| Step: 6
Training loss: 2.3140342235565186
Validation loss: 2.023431859990602

Epoch: 6| Step: 7
Training loss: 2.1500589847564697
Validation loss: 2.0072448330540813

Epoch: 6| Step: 8
Training loss: 2.3542556762695312
Validation loss: 1.9886647296208206

Epoch: 6| Step: 9
Training loss: 1.414212703704834
Validation loss: 2.0179187508039576

Epoch: 6| Step: 10
Training loss: 1.4474049806594849
Validation loss: 2.0161507885943175

Epoch: 6| Step: 11
Training loss: 2.6082606315612793
Validation loss: 2.0027330049904446

Epoch: 6| Step: 12
Training loss: 2.049248218536377
Validation loss: 2.018084772171513

Epoch: 6| Step: 13
Training loss: 1.468737244606018
Validation loss: 1.999442260752442

Epoch: 130| Step: 0
Training loss: 2.1868762969970703
Validation loss: 2.008723102590089

Epoch: 6| Step: 1
Training loss: 2.3975777626037598
Validation loss: 1.9879166182651316

Epoch: 6| Step: 2
Training loss: 2.149566650390625
Validation loss: 2.002770951999131

Epoch: 6| Step: 3
Training loss: 2.1553149223327637
Validation loss: 1.9882491596283451

Epoch: 6| Step: 4
Training loss: 2.4427943229675293
Validation loss: 1.966437767910701

Epoch: 6| Step: 5
Training loss: 2.1996052265167236
Validation loss: 1.9986610015233357

Epoch: 6| Step: 6
Training loss: 2.365821599960327
Validation loss: 1.9838799507387224

Epoch: 6| Step: 7
Training loss: 1.9609241485595703
Validation loss: 1.9957981083982734

Epoch: 6| Step: 8
Training loss: 2.4698662757873535
Validation loss: 1.9940819765931816

Epoch: 6| Step: 9
Training loss: 1.9493553638458252
Validation loss: 1.9945868779254217

Epoch: 6| Step: 10
Training loss: 2.04075026512146
Validation loss: 1.9831111482394639

Epoch: 6| Step: 11
Training loss: 1.4480454921722412
Validation loss: 1.978889847314486

Epoch: 6| Step: 12
Training loss: 2.075948715209961
Validation loss: 1.9975000504524476

Epoch: 6| Step: 13
Training loss: 1.8089345693588257
Validation loss: 1.9781052950889833

Epoch: 131| Step: 0
Training loss: 1.4294304847717285
Validation loss: 1.9927788139671407

Epoch: 6| Step: 1
Training loss: 2.7067229747772217
Validation loss: 2.002917338443059

Epoch: 6| Step: 2
Training loss: 2.2097463607788086
Validation loss: 2.013935083984047

Epoch: 6| Step: 3
Training loss: 2.0035362243652344
Validation loss: 2.000755451058829

Epoch: 6| Step: 4
Training loss: 2.055093765258789
Validation loss: 2.0126327058320403

Epoch: 6| Step: 5
Training loss: 2.3371667861938477
Validation loss: 1.9995929271944108

Epoch: 6| Step: 6
Training loss: 1.8130967617034912
Validation loss: 2.0010487161656862

Epoch: 6| Step: 7
Training loss: 2.214648723602295
Validation loss: 2.012794256210327

Epoch: 6| Step: 8
Training loss: 2.2900779247283936
Validation loss: 2.0134150340992916

Epoch: 6| Step: 9
Training loss: 1.9870491027832031
Validation loss: 1.9947830361704673

Epoch: 6| Step: 10
Training loss: 1.8296359777450562
Validation loss: 2.0065437619404127

Epoch: 6| Step: 11
Training loss: 1.8437657356262207
Validation loss: 2.017657664514357

Epoch: 6| Step: 12
Training loss: 2.212864398956299
Validation loss: 1.9955467947067753

Epoch: 6| Step: 13
Training loss: 3.094425678253174
Validation loss: 2.016062198146697

Epoch: 132| Step: 0
Training loss: 1.8629099130630493
Validation loss: 2.0184608659436627

Epoch: 6| Step: 1
Training loss: 1.8854459524154663
Validation loss: 2.040219594073552

Epoch: 6| Step: 2
Training loss: 2.8310227394104004
Validation loss: 2.017418237142665

Epoch: 6| Step: 3
Training loss: 2.0886752605438232
Validation loss: 2.0477824006029355

Epoch: 6| Step: 4
Training loss: 2.5896284580230713
Validation loss: 2.0235873217223794

Epoch: 6| Step: 5
Training loss: 1.9871242046356201
Validation loss: 2.040267075261762

Epoch: 6| Step: 6
Training loss: 1.939050316810608
Validation loss: 2.039570382846299

Epoch: 6| Step: 7
Training loss: 2.1949028968811035
Validation loss: 2.035674125917496

Epoch: 6| Step: 8
Training loss: 1.8344459533691406
Validation loss: 2.020700300893476

Epoch: 6| Step: 9
Training loss: 2.83482027053833
Validation loss: 2.030306996837739

Epoch: 6| Step: 10
Training loss: 1.8212878704071045
Validation loss: 2.034049436610232

Epoch: 6| Step: 11
Training loss: 2.3616724014282227
Validation loss: 2.0185383263454644

Epoch: 6| Step: 12
Training loss: 2.0032458305358887
Validation loss: 2.0129171827787995

Epoch: 6| Step: 13
Training loss: 1.00581693649292
Validation loss: 2.0259427101381364

Epoch: 133| Step: 0
Training loss: 2.137261152267456
Validation loss: 2.0114906026471044

Epoch: 6| Step: 1
Training loss: 2.158315658569336
Validation loss: 2.02887031596194

Epoch: 6| Step: 2
Training loss: 2.736943244934082
Validation loss: 2.023025429376992

Epoch: 6| Step: 3
Training loss: 2.2375504970550537
Validation loss: 2.0171002290582143

Epoch: 6| Step: 4
Training loss: 2.0338211059570312
Validation loss: 2.0158511054131294

Epoch: 6| Step: 5
Training loss: 2.187997817993164
Validation loss: 2.0119991674218127

Epoch: 6| Step: 6
Training loss: 1.8005709648132324
Validation loss: 2.0218303254855576

Epoch: 6| Step: 7
Training loss: 2.0872445106506348
Validation loss: 2.0049583963168565

Epoch: 6| Step: 8
Training loss: 1.808985948562622
Validation loss: 2.017696745934025

Epoch: 6| Step: 9
Training loss: 1.9227595329284668
Validation loss: 2.0179264186530985

Epoch: 6| Step: 10
Training loss: 1.7857158184051514
Validation loss: 1.991864206970379

Epoch: 6| Step: 11
Training loss: 1.9282872676849365
Validation loss: 2.0015684686681277

Epoch: 6| Step: 12
Training loss: 2.4875521659851074
Validation loss: 1.9922265955196914

Epoch: 6| Step: 13
Training loss: 2.6474592685699463
Validation loss: 2.018948215310292

Epoch: 134| Step: 0
Training loss: 1.543770670890808
Validation loss: 1.9820096146675847

Epoch: 6| Step: 1
Training loss: 2.1095147132873535
Validation loss: 2.00993077985702

Epoch: 6| Step: 2
Training loss: 2.1797027587890625
Validation loss: 1.9908117889076151

Epoch: 6| Step: 3
Training loss: 1.8604230880737305
Validation loss: 2.004382619293787

Epoch: 6| Step: 4
Training loss: 2.751213550567627
Validation loss: 1.9969264973876297

Epoch: 6| Step: 5
Training loss: 2.7772324085235596
Validation loss: 1.9547259576859013

Epoch: 6| Step: 6
Training loss: 2.7030673027038574
Validation loss: 1.954382828486863

Epoch: 6| Step: 7
Training loss: 1.9917941093444824
Validation loss: 1.969116340401352

Epoch: 6| Step: 8
Training loss: 1.909814715385437
Validation loss: 1.9859339319249636

Epoch: 6| Step: 9
Training loss: 1.3836127519607544
Validation loss: 1.9838372840676257

Epoch: 6| Step: 10
Training loss: 2.258207321166992
Validation loss: 1.9575639963150024

Epoch: 6| Step: 11
Training loss: 2.0402638912200928
Validation loss: 2.0011259458398305

Epoch: 6| Step: 12
Training loss: 1.990685224533081
Validation loss: 1.982694383590452

Epoch: 6| Step: 13
Training loss: 2.1595730781555176
Validation loss: 1.9849002540752452

Epoch: 135| Step: 0
Training loss: 2.3189821243286133
Validation loss: 1.988207794004871

Epoch: 6| Step: 1
Training loss: 1.720449447631836
Validation loss: 1.9950209612487464

Epoch: 6| Step: 2
Training loss: 2.39158034324646
Validation loss: 1.9918959640687512

Epoch: 6| Step: 3
Training loss: 2.1225714683532715
Validation loss: 1.9574821995150657

Epoch: 6| Step: 4
Training loss: 2.079108238220215
Validation loss: 1.9907520060898156

Epoch: 6| Step: 5
Training loss: 1.930517315864563
Validation loss: 1.9793645489600398

Epoch: 6| Step: 6
Training loss: 2.2410590648651123
Validation loss: 1.984935745116203

Epoch: 6| Step: 7
Training loss: 2.5108795166015625
Validation loss: 1.9846335764854186

Epoch: 6| Step: 8
Training loss: 1.6362961530685425
Validation loss: 2.002715896534663

Epoch: 6| Step: 9
Training loss: 2.276398181915283
Validation loss: 2.0216668369949504

Epoch: 6| Step: 10
Training loss: 1.975545883178711
Validation loss: 2.0068889074428107

Epoch: 6| Step: 11
Training loss: 2.170457363128662
Validation loss: 2.0005755193771853

Epoch: 6| Step: 12
Training loss: 2.1229248046875
Validation loss: 2.0149750927443146

Epoch: 6| Step: 13
Training loss: 2.0873091220855713
Validation loss: 2.0339898281199957

Epoch: 136| Step: 0
Training loss: 2.3976337909698486
Validation loss: 1.9989257063916934

Epoch: 6| Step: 1
Training loss: 1.9651494026184082
Validation loss: 2.001348231428413

Epoch: 6| Step: 2
Training loss: 1.9372332096099854
Validation loss: 2.0047508093618576

Epoch: 6| Step: 3
Training loss: 1.3338289260864258
Validation loss: 2.0043868967281875

Epoch: 6| Step: 4
Training loss: 2.2902638912200928
Validation loss: 2.009197727326424

Epoch: 6| Step: 5
Training loss: 2.0850367546081543
Validation loss: 2.0408686232823197

Epoch: 6| Step: 6
Training loss: 1.9746253490447998
Validation loss: 2.026085727958269

Epoch: 6| Step: 7
Training loss: 2.9778573513031006
Validation loss: 2.004600594120641

Epoch: 6| Step: 8
Training loss: 2.570591449737549
Validation loss: 2.0323625687629945

Epoch: 6| Step: 9
Training loss: 2.223273754119873
Validation loss: 2.012383730180802

Epoch: 6| Step: 10
Training loss: 2.196296215057373
Validation loss: 2.0267955821047545

Epoch: 6| Step: 11
Training loss: 1.5649645328521729
Validation loss: 2.0123920594492266

Epoch: 6| Step: 12
Training loss: 2.1664061546325684
Validation loss: 2.0354357304111605

Epoch: 6| Step: 13
Training loss: 1.6612422466278076
Validation loss: 2.041475026838241

Epoch: 137| Step: 0
Training loss: 2.1964621543884277
Validation loss: 2.0316733955055155

Epoch: 6| Step: 1
Training loss: 2.348792552947998
Validation loss: 2.036204776456279

Epoch: 6| Step: 2
Training loss: 1.81889808177948
Validation loss: 2.0243355433146157

Epoch: 6| Step: 3
Training loss: 1.846468448638916
Validation loss: 2.001242181306244

Epoch: 6| Step: 4
Training loss: 1.7584069967269897
Validation loss: 1.9985600081823205

Epoch: 6| Step: 5
Training loss: 2.244425058364868
Validation loss: 2.0124369129057853

Epoch: 6| Step: 6
Training loss: 1.6973395347595215
Validation loss: 2.0081795518116285

Epoch: 6| Step: 7
Training loss: 2.198514938354492
Validation loss: 1.9999878637252315

Epoch: 6| Step: 8
Training loss: 2.7160263061523438
Validation loss: 2.0196642106579197

Epoch: 6| Step: 9
Training loss: 2.0096254348754883
Validation loss: 2.0014019909725396

Epoch: 6| Step: 10
Training loss: 2.066638946533203
Validation loss: 1.991229913567984

Epoch: 6| Step: 11
Training loss: 1.3481848239898682
Validation loss: 1.989258776428879

Epoch: 6| Step: 12
Training loss: 2.777681589126587
Validation loss: 1.965837933683908

Epoch: 6| Step: 13
Training loss: 2.4959490299224854
Validation loss: 1.9756115277608235

Epoch: 138| Step: 0
Training loss: 2.674830436706543
Validation loss: 1.9780806726024998

Epoch: 6| Step: 1
Training loss: 2.273401975631714
Validation loss: 1.9799740493938487

Epoch: 6| Step: 2
Training loss: 2.1700103282928467
Validation loss: 1.9888231215938446

Epoch: 6| Step: 3
Training loss: 1.976215124130249
Validation loss: 1.9775763865440124

Epoch: 6| Step: 4
Training loss: 2.4804306030273438
Validation loss: 1.9859875889234646

Epoch: 6| Step: 5
Training loss: 1.1736112833023071
Validation loss: 1.9951253091135333

Epoch: 6| Step: 6
Training loss: 1.979630470275879
Validation loss: 1.9670072396596272

Epoch: 6| Step: 7
Training loss: 1.940454363822937
Validation loss: 1.964216088735929

Epoch: 6| Step: 8
Training loss: 2.019104480743408
Validation loss: 1.9797177019939627

Epoch: 6| Step: 9
Training loss: 1.8304580450057983
Validation loss: 1.9938791310915382

Epoch: 6| Step: 10
Training loss: 1.4943228960037231
Validation loss: 1.973472974633658

Epoch: 6| Step: 11
Training loss: 2.2773427963256836
Validation loss: 1.9885743587247786

Epoch: 6| Step: 12
Training loss: 2.9353504180908203
Validation loss: 1.9832968506761777

Epoch: 6| Step: 13
Training loss: 2.0348527431488037
Validation loss: 1.9837188515611874

Epoch: 139| Step: 0
Training loss: 2.3100743293762207
Validation loss: 1.9974512002801383

Epoch: 6| Step: 1
Training loss: 2.4284744262695312
Validation loss: 2.0036297869938675

Epoch: 6| Step: 2
Training loss: 1.7114660739898682
Validation loss: 2.0066851467214604

Epoch: 6| Step: 3
Training loss: 2.122668504714966
Validation loss: 2.001524043339555

Epoch: 6| Step: 4
Training loss: 1.929421305656433
Validation loss: 1.989217335178006

Epoch: 6| Step: 5
Training loss: 1.9886009693145752
Validation loss: 2.0141445757240377

Epoch: 6| Step: 6
Training loss: 1.8804306983947754
Validation loss: 2.047497716001285

Epoch: 6| Step: 7
Training loss: 2.298278570175171
Validation loss: 2.020639008091342

Epoch: 6| Step: 8
Training loss: 2.6469483375549316
Validation loss: 2.04042955880524

Epoch: 6| Step: 9
Training loss: 2.151625633239746
Validation loss: 2.0211079966637397

Epoch: 6| Step: 10
Training loss: 1.655052661895752
Validation loss: 2.056557837352958

Epoch: 6| Step: 11
Training loss: 2.2468628883361816
Validation loss: 2.037476279402292

Epoch: 6| Step: 12
Training loss: 2.2761409282684326
Validation loss: 2.0562617009685886

Epoch: 6| Step: 13
Training loss: 2.3923826217651367
Validation loss: 2.0464695807426208

Epoch: 140| Step: 0
Training loss: 1.5392682552337646
Validation loss: 2.053178095048474

Epoch: 6| Step: 1
Training loss: 2.3619136810302734
Validation loss: 2.026854112584104

Epoch: 6| Step: 2
Training loss: 1.9698054790496826
Validation loss: 2.0248230811088317

Epoch: 6| Step: 3
Training loss: 2.42671275138855
Validation loss: 2.025941970527813

Epoch: 6| Step: 4
Training loss: 2.525257110595703
Validation loss: 2.0082211366263767

Epoch: 6| Step: 5
Training loss: 1.368342638015747
Validation loss: 1.9948325426347795

Epoch: 6| Step: 6
Training loss: 2.016411781311035
Validation loss: 1.9850208733671455

Epoch: 6| Step: 7
Training loss: 1.7258999347686768
Validation loss: 1.9833298678039222

Epoch: 6| Step: 8
Training loss: 2.348879814147949
Validation loss: 1.951000649441955

Epoch: 6| Step: 9
Training loss: 2.2228832244873047
Validation loss: 1.9756296321909914

Epoch: 6| Step: 10
Training loss: 2.1282222270965576
Validation loss: 1.940712450652994

Epoch: 6| Step: 11
Training loss: 2.392747640609741
Validation loss: 1.978422003407632

Epoch: 6| Step: 12
Training loss: 2.300640821456909
Validation loss: 1.9609036240526425

Epoch: 6| Step: 13
Training loss: 2.3723630905151367
Validation loss: 1.9589371155667048

Epoch: 141| Step: 0
Training loss: 1.7416234016418457
Validation loss: 1.9689474541653869

Epoch: 6| Step: 1
Training loss: 2.0464272499084473
Validation loss: 1.9893154969779394

Epoch: 6| Step: 2
Training loss: 1.7855186462402344
Validation loss: 1.976444411021407

Epoch: 6| Step: 3
Training loss: 1.9433165788650513
Validation loss: 1.9721757314538444

Epoch: 6| Step: 4
Training loss: 2.1129164695739746
Validation loss: 1.9805500943173644

Epoch: 6| Step: 5
Training loss: 1.5547324419021606
Validation loss: 1.9951960758496357

Epoch: 6| Step: 6
Training loss: 2.981924057006836
Validation loss: 1.9672681106034147

Epoch: 6| Step: 7
Training loss: 1.6972949504852295
Validation loss: 1.979972972664782

Epoch: 6| Step: 8
Training loss: 2.8754215240478516
Validation loss: 1.9790270866886261

Epoch: 6| Step: 9
Training loss: 1.599752426147461
Validation loss: 1.9718234641577608

Epoch: 6| Step: 10
Training loss: 2.218778133392334
Validation loss: 2.002582726940032

Epoch: 6| Step: 11
Training loss: 1.964598298072815
Validation loss: 2.0044720301064114

Epoch: 6| Step: 12
Training loss: 2.620945453643799
Validation loss: 2.008787360242618

Epoch: 6| Step: 13
Training loss: 2.230504035949707
Validation loss: 1.9941068105800177

Epoch: 142| Step: 0
Training loss: 2.1823413372039795
Validation loss: 2.010330048940515

Epoch: 6| Step: 1
Training loss: 2.3104512691497803
Validation loss: 2.0111233149805376

Epoch: 6| Step: 2
Training loss: 1.7209385633468628
Validation loss: 2.0038741096373527

Epoch: 6| Step: 3
Training loss: 2.0148541927337646
Validation loss: 2.0095994805776947

Epoch: 6| Step: 4
Training loss: 2.14418363571167
Validation loss: 1.9938625187002204

Epoch: 6| Step: 5
Training loss: 1.941301703453064
Validation loss: 2.0123522025282665

Epoch: 6| Step: 6
Training loss: 2.3906466960906982
Validation loss: 1.9676124254862468

Epoch: 6| Step: 7
Training loss: 2.6343796253204346
Validation loss: 2.0112727611295638

Epoch: 6| Step: 8
Training loss: 2.295266628265381
Validation loss: 1.9845137339766308

Epoch: 6| Step: 9
Training loss: 1.829026699066162
Validation loss: 1.989830700300073

Epoch: 6| Step: 10
Training loss: 1.326937198638916
Validation loss: 1.9900257766887706

Epoch: 6| Step: 11
Training loss: 2.013524055480957
Validation loss: 2.002094284180672

Epoch: 6| Step: 12
Training loss: 2.2057528495788574
Validation loss: 2.0058496177837415

Epoch: 6| Step: 13
Training loss: 2.63858962059021
Validation loss: 2.0062466385543987

Epoch: 143| Step: 0
Training loss: 1.9500551223754883
Validation loss: 1.9899813936602684

Epoch: 6| Step: 1
Training loss: 2.211880683898926
Validation loss: 2.0014554313434068

Epoch: 6| Step: 2
Training loss: 2.098076820373535
Validation loss: 2.006266560605777

Epoch: 6| Step: 3
Training loss: 1.9559009075164795
Validation loss: 2.0021108132536694

Epoch: 6| Step: 4
Training loss: 2.3224096298217773
Validation loss: 1.9843312796726023

Epoch: 6| Step: 5
Training loss: 1.062049150466919
Validation loss: 2.011457356073523

Epoch: 6| Step: 6
Training loss: 2.311398983001709
Validation loss: 1.9907043877468313

Epoch: 6| Step: 7
Training loss: 1.898524284362793
Validation loss: 2.02073142092715

Epoch: 6| Step: 8
Training loss: 1.964348554611206
Validation loss: 2.022365136813092

Epoch: 6| Step: 9
Training loss: 2.1616220474243164
Validation loss: 2.0185552579100414

Epoch: 6| Step: 10
Training loss: 2.1234660148620605
Validation loss: 2.0032721680979573

Epoch: 6| Step: 11
Training loss: 2.1845057010650635
Validation loss: 2.0064571096051123

Epoch: 6| Step: 12
Training loss: 2.445444107055664
Validation loss: 2.020475443973336

Epoch: 6| Step: 13
Training loss: 2.8092451095581055
Validation loss: 1.9945578036769744

Epoch: 144| Step: 0
Training loss: 1.6556346416473389
Validation loss: 2.000779410844208

Epoch: 6| Step: 1
Training loss: 1.6149488687515259
Validation loss: 2.0108612301529094

Epoch: 6| Step: 2
Training loss: 1.5415046215057373
Validation loss: 1.9927407387764222

Epoch: 6| Step: 3
Training loss: 2.359539031982422
Validation loss: 2.025306829842188

Epoch: 6| Step: 4
Training loss: 2.246716022491455
Validation loss: 2.026030032865463

Epoch: 6| Step: 5
Training loss: 2.3396594524383545
Validation loss: 1.997087727310837

Epoch: 6| Step: 6
Training loss: 2.412642478942871
Validation loss: 1.988156472482989

Epoch: 6| Step: 7
Training loss: 2.400831460952759
Validation loss: 2.0052016935040875

Epoch: 6| Step: 8
Training loss: 2.1091861724853516
Validation loss: 2.004803278112924

Epoch: 6| Step: 9
Training loss: 2.303762912750244
Validation loss: 2.0298248080797094

Epoch: 6| Step: 10
Training loss: 1.7745946645736694
Validation loss: 2.0137176590581096

Epoch: 6| Step: 11
Training loss: 2.3740394115448
Validation loss: 1.978734565037553

Epoch: 6| Step: 12
Training loss: 2.646667957305908
Validation loss: 1.9946514150147796

Epoch: 6| Step: 13
Training loss: 1.01700758934021
Validation loss: 2.0075634064212924

Epoch: 145| Step: 0
Training loss: 2.251138210296631
Validation loss: 2.027074949715727

Epoch: 6| Step: 1
Training loss: 1.8500328063964844
Validation loss: 2.0189694871184645

Epoch: 6| Step: 2
Training loss: 2.261647939682007
Validation loss: 2.0128844553424465

Epoch: 6| Step: 3
Training loss: 2.4578726291656494
Validation loss: 2.003924628739716

Epoch: 6| Step: 4
Training loss: 2.0768887996673584
Validation loss: 2.0260674748369443

Epoch: 6| Step: 5
Training loss: 2.1283342838287354
Validation loss: 1.998113022055677

Epoch: 6| Step: 6
Training loss: 2.7413439750671387
Validation loss: 2.0618612266355947

Epoch: 6| Step: 7
Training loss: 1.1375832557678223
Validation loss: 2.039068627101119

Epoch: 6| Step: 8
Training loss: 1.952048420906067
Validation loss: 2.0254867384510655

Epoch: 6| Step: 9
Training loss: 2.3919944763183594
Validation loss: 2.0228154710544053

Epoch: 6| Step: 10
Training loss: 1.8733906745910645
Validation loss: 2.0498270347554195

Epoch: 6| Step: 11
Training loss: 1.9514954090118408
Validation loss: 2.0203468876500286

Epoch: 6| Step: 12
Training loss: 1.9114983081817627
Validation loss: 2.015164534250895

Epoch: 6| Step: 13
Training loss: 2.5693750381469727
Validation loss: 2.010563463293096

Epoch: 146| Step: 0
Training loss: 2.048792600631714
Validation loss: 2.003659312443067

Epoch: 6| Step: 1
Training loss: 2.378225803375244
Validation loss: 1.993850972062798

Epoch: 6| Step: 2
Training loss: 2.814371109008789
Validation loss: 1.993059765908026

Epoch: 6| Step: 3
Training loss: 1.779496669769287
Validation loss: 1.9853665136521863

Epoch: 6| Step: 4
Training loss: 2.43973708152771
Validation loss: 1.9724019560762631

Epoch: 6| Step: 5
Training loss: 2.091111898422241
Validation loss: 1.96180042400155

Epoch: 6| Step: 6
Training loss: 1.4403090476989746
Validation loss: 1.9628737408627746

Epoch: 6| Step: 7
Training loss: 2.4336812496185303
Validation loss: 1.968988889007158

Epoch: 6| Step: 8
Training loss: 1.9941316843032837
Validation loss: 1.9840432085016722

Epoch: 6| Step: 9
Training loss: 1.4419422149658203
Validation loss: 1.9687631566037413

Epoch: 6| Step: 10
Training loss: 2.0578222274780273
Validation loss: 1.9799383583889212

Epoch: 6| Step: 11
Training loss: 2.3798413276672363
Validation loss: 1.9522219678407073

Epoch: 6| Step: 12
Training loss: 1.7382875680923462
Validation loss: 1.9556479377131308

Epoch: 6| Step: 13
Training loss: 2.717298984527588
Validation loss: 1.9704034225915068

Epoch: 147| Step: 0
Training loss: 2.1778318881988525
Validation loss: 1.9558854692725725

Epoch: 6| Step: 1
Training loss: 2.20266056060791
Validation loss: 1.9794240510591896

Epoch: 6| Step: 2
Training loss: 1.9856657981872559
Validation loss: 1.999735834777996

Epoch: 6| Step: 3
Training loss: 1.8867331743240356
Validation loss: 1.9942143655592395

Epoch: 6| Step: 4
Training loss: 2.0045647621154785
Validation loss: 2.01820174853007

Epoch: 6| Step: 5
Training loss: 1.9096271991729736
Validation loss: 2.026213476734777

Epoch: 6| Step: 6
Training loss: 2.177705764770508
Validation loss: 1.9967313222987677

Epoch: 6| Step: 7
Training loss: 1.915221095085144
Validation loss: 2.0194849967956543

Epoch: 6| Step: 8
Training loss: 2.5986199378967285
Validation loss: 2.022176824590211

Epoch: 6| Step: 9
Training loss: 2.476367950439453
Validation loss: 2.026480767034715

Epoch: 6| Step: 10
Training loss: 1.8689453601837158
Validation loss: 2.0429093953101867

Epoch: 6| Step: 11
Training loss: 2.0821759700775146
Validation loss: 2.051435970490979

Epoch: 6| Step: 12
Training loss: 1.854346513748169
Validation loss: 2.0448521978111676

Epoch: 6| Step: 13
Training loss: 2.1339168548583984
Validation loss: 2.0382880408276796

Epoch: 148| Step: 0
Training loss: 1.738706111907959
Validation loss: 2.041323338785479

Epoch: 6| Step: 1
Training loss: 2.180671453475952
Validation loss: 2.0302428942854687

Epoch: 6| Step: 2
Training loss: 2.3155999183654785
Validation loss: 2.015819900779314

Epoch: 6| Step: 3
Training loss: 1.8849760293960571
Validation loss: 1.9895196678817912

Epoch: 6| Step: 4
Training loss: 2.405083179473877
Validation loss: 1.9926747993756366

Epoch: 6| Step: 5
Training loss: 2.2545578479766846
Validation loss: 1.979595450944798

Epoch: 6| Step: 6
Training loss: 1.9780240058898926
Validation loss: 1.994124585582364

Epoch: 6| Step: 7
Training loss: 1.4364835023880005
Validation loss: 1.9922703337925736

Epoch: 6| Step: 8
Training loss: 2.4031894207000732
Validation loss: 1.9846294951695267

Epoch: 6| Step: 9
Training loss: 2.8676562309265137
Validation loss: 2.0092472517362205

Epoch: 6| Step: 10
Training loss: 1.796156644821167
Validation loss: 1.9688563667317873

Epoch: 6| Step: 11
Training loss: 1.9221961498260498
Validation loss: 1.9912918331802532

Epoch: 6| Step: 12
Training loss: 2.2584805488586426
Validation loss: 1.9815572666865524

Epoch: 6| Step: 13
Training loss: 1.8539115190505981
Validation loss: 1.974173568910168

Epoch: 149| Step: 0
Training loss: 2.0353074073791504
Validation loss: 1.9711342255274455

Epoch: 6| Step: 1
Training loss: 1.6976512670516968
Validation loss: 1.9842460719488

Epoch: 6| Step: 2
Training loss: 1.4744311571121216
Validation loss: 1.9800284870209233

Epoch: 6| Step: 3
Training loss: 2.4100852012634277
Validation loss: 1.9908005422161472

Epoch: 6| Step: 4
Training loss: 1.3513978719711304
Validation loss: 2.004556467456202

Epoch: 6| Step: 5
Training loss: 1.6029460430145264
Validation loss: 2.0126200632382463

Epoch: 6| Step: 6
Training loss: 2.557033061981201
Validation loss: 2.019499578783589

Epoch: 6| Step: 7
Training loss: 2.2009716033935547
Validation loss: 2.0084091822306314

Epoch: 6| Step: 8
Training loss: 1.915981650352478
Validation loss: 1.9908345476273568

Epoch: 6| Step: 9
Training loss: 2.787660598754883
Validation loss: 2.015220485707765

Epoch: 6| Step: 10
Training loss: 2.4770126342773438
Validation loss: 2.008111958862633

Epoch: 6| Step: 11
Training loss: 2.3548200130462646
Validation loss: 2.053553560728668

Epoch: 6| Step: 12
Training loss: 2.12131667137146
Validation loss: 2.0059312633288804

Epoch: 6| Step: 13
Training loss: 2.016676902770996
Validation loss: 2.021210765325895

Epoch: 150| Step: 0
Training loss: 2.4055497646331787
Validation loss: 2.007635589568846

Epoch: 6| Step: 1
Training loss: 1.976362943649292
Validation loss: 2.0108367473848405

Epoch: 6| Step: 2
Training loss: 2.4250905513763428
Validation loss: 2.0242401297374437

Epoch: 6| Step: 3
Training loss: 2.9641435146331787
Validation loss: 2.0215652437620264

Epoch: 6| Step: 4
Training loss: 1.9908621311187744
Validation loss: 2.0303936376366565

Epoch: 6| Step: 5
Training loss: 1.6355185508728027
Validation loss: 2.02167558798226

Epoch: 6| Step: 6
Training loss: 2.2152345180511475
Validation loss: 2.035330746763496

Epoch: 6| Step: 7
Training loss: 1.3384040594100952
Validation loss: 2.0023785098906486

Epoch: 6| Step: 8
Training loss: 2.174412250518799
Validation loss: 2.0210922661648003

Epoch: 6| Step: 9
Training loss: 1.7316025495529175
Validation loss: 2.0522222903466996

Epoch: 6| Step: 10
Training loss: 1.919032335281372
Validation loss: 2.020500918870331

Epoch: 6| Step: 11
Training loss: 2.241668224334717
Validation loss: 2.015014979147142

Epoch: 6| Step: 12
Training loss: 2.1050195693969727
Validation loss: 2.020962425457534

Epoch: 6| Step: 13
Training loss: 1.828468918800354
Validation loss: 2.0168034492000455

Epoch: 151| Step: 0
Training loss: 2.5909423828125
Validation loss: 2.014820593659596

Epoch: 6| Step: 1
Training loss: 1.4904327392578125
Validation loss: 2.0124828815460205

Epoch: 6| Step: 2
Training loss: 1.7651350498199463
Validation loss: 2.005724592875409

Epoch: 6| Step: 3
Training loss: 3.063396453857422
Validation loss: 2.01866288082574

Epoch: 6| Step: 4
Training loss: 1.7677254676818848
Validation loss: 2.005440624811316

Epoch: 6| Step: 5
Training loss: 2.5589592456817627
Validation loss: 2.0152844100870113

Epoch: 6| Step: 6
Training loss: 1.680062174797058
Validation loss: 1.9690981116346133

Epoch: 6| Step: 7
Training loss: 2.0352389812469482
Validation loss: 1.993385802033127

Epoch: 6| Step: 8
Training loss: 2.161651372909546
Validation loss: 2.0012170678825787

Epoch: 6| Step: 9
Training loss: 2.301536798477173
Validation loss: 1.990105830213075

Epoch: 6| Step: 10
Training loss: 1.767594814300537
Validation loss: 1.9724499128198112

Epoch: 6| Step: 11
Training loss: 2.050173759460449
Validation loss: 1.9835240802457255

Epoch: 6| Step: 12
Training loss: 1.7797574996948242
Validation loss: 1.9769447593278782

Epoch: 6| Step: 13
Training loss: 2.1216084957122803
Validation loss: 1.9736794169231127

Epoch: 152| Step: 0
Training loss: 2.7426066398620605
Validation loss: 1.9902811691325197

Epoch: 6| Step: 1
Training loss: 2.203831195831299
Validation loss: 2.012688734198129

Epoch: 6| Step: 2
Training loss: 1.9432178735733032
Validation loss: 1.9914650276143064

Epoch: 6| Step: 3
Training loss: 2.603045701980591
Validation loss: 1.988226875182121

Epoch: 6| Step: 4
Training loss: 2.1100125312805176
Validation loss: 2.0191429379165813

Epoch: 6| Step: 5
Training loss: 1.8853741884231567
Validation loss: 1.99468522174384

Epoch: 6| Step: 6
Training loss: 2.4531660079956055
Validation loss: 1.9829131749368483

Epoch: 6| Step: 7
Training loss: 2.202324867248535
Validation loss: 1.9868156294668875

Epoch: 6| Step: 8
Training loss: 1.1944345235824585
Validation loss: 1.9951340190825924

Epoch: 6| Step: 9
Training loss: 2.153809070587158
Validation loss: 2.0170952914863505

Epoch: 6| Step: 10
Training loss: 1.931730031967163
Validation loss: 1.9886358976364136

Epoch: 6| Step: 11
Training loss: 1.844165325164795
Validation loss: 2.0203937330553607

Epoch: 6| Step: 12
Training loss: 1.2860305309295654
Validation loss: 2.0100816975357714

Epoch: 6| Step: 13
Training loss: 2.568589210510254
Validation loss: 2.023832037884702

Epoch: 153| Step: 0
Training loss: 1.8100361824035645
Validation loss: 2.003770577010288

Epoch: 6| Step: 1
Training loss: 2.656097412109375
Validation loss: 2.026314516221323

Epoch: 6| Step: 2
Training loss: 1.9755529165267944
Validation loss: 2.0201441857122604

Epoch: 6| Step: 3
Training loss: 2.1252713203430176
Validation loss: 2.022171915218394

Epoch: 6| Step: 4
Training loss: 2.299189567565918
Validation loss: 2.026119800024135

Epoch: 6| Step: 5
Training loss: 2.7140870094299316
Validation loss: 2.016867724798059

Epoch: 6| Step: 6
Training loss: 2.062929630279541
Validation loss: 2.010503912484774

Epoch: 6| Step: 7
Training loss: 1.4491339921951294
Validation loss: 2.0369903272198093

Epoch: 6| Step: 8
Training loss: 1.7552510499954224
Validation loss: 2.0378664244887648

Epoch: 6| Step: 9
Training loss: 2.3957462310791016
Validation loss: 2.044300320327923

Epoch: 6| Step: 10
Training loss: 2.9630141258239746
Validation loss: 2.0319041308536323

Epoch: 6| Step: 11
Training loss: 1.738728404045105
Validation loss: 2.002376289777858

Epoch: 6| Step: 12
Training loss: 1.6928045749664307
Validation loss: 2.023276388004262

Epoch: 6| Step: 13
Training loss: 0.8877013921737671
Validation loss: 2.022494254573699

Epoch: 154| Step: 0
Training loss: 2.156167507171631
Validation loss: 2.0303276533721597

Epoch: 6| Step: 1
Training loss: 1.9110007286071777
Validation loss: 2.0344757521024315

Epoch: 6| Step: 2
Training loss: 1.325961709022522
Validation loss: 2.0315076330656647

Epoch: 6| Step: 3
Training loss: 2.386857032775879
Validation loss: 1.9762278961878952

Epoch: 6| Step: 4
Training loss: 2.007532835006714
Validation loss: 1.9910611529504099

Epoch: 6| Step: 5
Training loss: 1.7224282026290894
Validation loss: 2.018371452567398

Epoch: 6| Step: 6
Training loss: 1.966571569442749
Validation loss: 1.984144756870885

Epoch: 6| Step: 7
Training loss: 2.4727931022644043
Validation loss: 2.0203735597672

Epoch: 6| Step: 8
Training loss: 3.163012981414795
Validation loss: 2.0108696286396315

Epoch: 6| Step: 9
Training loss: 2.1863670349121094
Validation loss: 2.033593600796115

Epoch: 6| Step: 10
Training loss: 1.5468504428863525
Validation loss: 2.0244886785425167

Epoch: 6| Step: 11
Training loss: 2.2773218154907227
Validation loss: 2.0294572871218444

Epoch: 6| Step: 12
Training loss: 1.6243422031402588
Validation loss: 2.0160757034055647

Epoch: 6| Step: 13
Training loss: 2.2306697368621826
Validation loss: 2.032770182496758

Epoch: 155| Step: 0
Training loss: 2.0227441787719727
Validation loss: 1.9925907081173313

Epoch: 6| Step: 1
Training loss: 1.915071964263916
Validation loss: 1.995315021084201

Epoch: 6| Step: 2
Training loss: 2.380934715270996
Validation loss: 1.9898784032431982

Epoch: 6| Step: 3
Training loss: 2.1621713638305664
Validation loss: 2.005264077135312

Epoch: 6| Step: 4
Training loss: 2.321807861328125
Validation loss: 1.9960924527978385

Epoch: 6| Step: 5
Training loss: 1.9630398750305176
Validation loss: 1.9582266858828965

Epoch: 6| Step: 6
Training loss: 1.792311429977417
Validation loss: 1.979996032612298

Epoch: 6| Step: 7
Training loss: 2.591413974761963
Validation loss: 1.9961151615265877

Epoch: 6| Step: 8
Training loss: 2.053882598876953
Validation loss: 1.9805924443788425

Epoch: 6| Step: 9
Training loss: 1.7232505083084106
Validation loss: 1.9915899679224978

Epoch: 6| Step: 10
Training loss: 1.6881053447723389
Validation loss: 1.9782538452456075

Epoch: 6| Step: 11
Training loss: 2.464885711669922
Validation loss: 1.9672677568210069

Epoch: 6| Step: 12
Training loss: 1.9067872762680054
Validation loss: 1.981520337443198

Epoch: 6| Step: 13
Training loss: 1.9539552927017212
Validation loss: 1.9994211043080976

Epoch: 156| Step: 0
Training loss: 2.638735294342041
Validation loss: 1.9937667051951091

Epoch: 6| Step: 1
Training loss: 2.354571580886841
Validation loss: 1.9902827893534014

Epoch: 6| Step: 2
Training loss: 1.7940486669540405
Validation loss: 2.002272382859261

Epoch: 6| Step: 3
Training loss: 1.9765434265136719
Validation loss: 1.9909483924988778

Epoch: 6| Step: 4
Training loss: 1.5176620483398438
Validation loss: 1.9924516383037771

Epoch: 6| Step: 5
Training loss: 2.21817946434021
Validation loss: 2.030601273300827

Epoch: 6| Step: 6
Training loss: 2.3215816020965576
Validation loss: 2.0095571138525523

Epoch: 6| Step: 7
Training loss: 1.8366427421569824
Validation loss: 2.0132487461131108

Epoch: 6| Step: 8
Training loss: 2.5859479904174805
Validation loss: 2.0506289748735327

Epoch: 6| Step: 9
Training loss: 2.418470621109009
Validation loss: 2.0473095627241236

Epoch: 6| Step: 10
Training loss: 2.196812152862549
Validation loss: 2.0310478082267185

Epoch: 6| Step: 11
Training loss: 1.3565868139266968
Validation loss: 2.0348787538466917

Epoch: 6| Step: 12
Training loss: 1.806382417678833
Validation loss: 2.0163076487920617

Epoch: 6| Step: 13
Training loss: 1.7804527282714844
Validation loss: 2.020075446815901

Epoch: 157| Step: 0
Training loss: 2.185509443283081
Validation loss: 2.020908268549109

Epoch: 6| Step: 1
Training loss: 1.7726414203643799
Validation loss: 2.0047037140015633

Epoch: 6| Step: 2
Training loss: 2.6590075492858887
Validation loss: 2.0112500101007442

Epoch: 6| Step: 3
Training loss: 2.1712911128997803
Validation loss: 2.0365699478375014

Epoch: 6| Step: 4
Training loss: 1.767324447631836
Validation loss: 2.0195057289574736

Epoch: 6| Step: 5
Training loss: 1.8916046619415283
Validation loss: 2.002831776936849

Epoch: 6| Step: 6
Training loss: 1.4673171043395996
Validation loss: 2.030563533947032

Epoch: 6| Step: 7
Training loss: 1.7925477027893066
Validation loss: 1.9865916826391732

Epoch: 6| Step: 8
Training loss: 1.736846685409546
Validation loss: 1.9991774661566621

Epoch: 6| Step: 9
Training loss: 1.885486125946045
Validation loss: 2.017269952322847

Epoch: 6| Step: 10
Training loss: 2.5317769050598145
Validation loss: 1.9909481361348143

Epoch: 6| Step: 11
Training loss: 2.3177804946899414
Validation loss: 1.9726841757374425

Epoch: 6| Step: 12
Training loss: 2.424872875213623
Validation loss: 1.9954171206361504

Epoch: 6| Step: 13
Training loss: 2.163020133972168
Validation loss: 1.9973124688671482

Epoch: 158| Step: 0
Training loss: 1.967241883277893
Validation loss: 1.999015200522638

Epoch: 6| Step: 1
Training loss: 2.2317471504211426
Validation loss: 2.015860958765912

Epoch: 6| Step: 2
Training loss: 3.189887285232544
Validation loss: 1.9973659541017266

Epoch: 6| Step: 3
Training loss: 1.5250492095947266
Validation loss: 1.9959277132506013

Epoch: 6| Step: 4
Training loss: 2.0566744804382324
Validation loss: 2.0011925646053847

Epoch: 6| Step: 5
Training loss: 1.6616698503494263
Validation loss: 1.9826901061560518

Epoch: 6| Step: 6
Training loss: 1.4762136936187744
Validation loss: 2.009504400273805

Epoch: 6| Step: 7
Training loss: 2.7274861335754395
Validation loss: 1.996073034501845

Epoch: 6| Step: 8
Training loss: 2.761336326599121
Validation loss: 1.9891678376864361

Epoch: 6| Step: 9
Training loss: 2.0697429180145264
Validation loss: 2.001090629126436

Epoch: 6| Step: 10
Training loss: 1.9110944271087646
Validation loss: 1.9698102089666552

Epoch: 6| Step: 11
Training loss: 1.4929146766662598
Validation loss: 1.9737077182339084

Epoch: 6| Step: 12
Training loss: 1.7468489408493042
Validation loss: 1.9944094150297103

Epoch: 6| Step: 13
Training loss: 1.9793744087219238
Validation loss: 2.007138685513568

Epoch: 159| Step: 0
Training loss: 2.2290234565734863
Validation loss: 1.9915739349139634

Epoch: 6| Step: 1
Training loss: 1.8874996900558472
Validation loss: 2.0122249895526516

Epoch: 6| Step: 2
Training loss: 2.017523765563965
Validation loss: 2.0234295116957797

Epoch: 6| Step: 3
Training loss: 2.0520310401916504
Validation loss: 2.009282837631882

Epoch: 6| Step: 4
Training loss: 2.471776247024536
Validation loss: 2.0048380590254262

Epoch: 6| Step: 5
Training loss: 2.3644299507141113
Validation loss: 2.0049355824788413

Epoch: 6| Step: 6
Training loss: 2.583836555480957
Validation loss: 1.99841611103345

Epoch: 6| Step: 7
Training loss: 2.532719135284424
Validation loss: 2.0291075193753807

Epoch: 6| Step: 8
Training loss: 1.2275669574737549
Validation loss: 2.040978818811396

Epoch: 6| Step: 9
Training loss: 1.8274813890457153
Validation loss: 2.0529401533065306

Epoch: 6| Step: 10
Training loss: 1.6898707151412964
Validation loss: 2.0097003559912405

Epoch: 6| Step: 11
Training loss: 2.2422475814819336
Validation loss: 2.046828362249559

Epoch: 6| Step: 12
Training loss: 1.658994197845459
Validation loss: 2.027821392141363

Epoch: 6| Step: 13
Training loss: 1.6874158382415771
Validation loss: 2.022712610101187

Epoch: 160| Step: 0
Training loss: 2.081899642944336
Validation loss: 2.032855454311576

Epoch: 6| Step: 1
Training loss: 2.2238779067993164
Validation loss: 2.0529717322318786

Epoch: 6| Step: 2
Training loss: 1.6964178085327148
Validation loss: 2.0352853703242477

Epoch: 6| Step: 3
Training loss: 2.537614583969116
Validation loss: 2.0370137858134445

Epoch: 6| Step: 4
Training loss: 2.204977512359619
Validation loss: 2.0651297338547243

Epoch: 6| Step: 5
Training loss: 2.207524061203003
Validation loss: 2.0530420862218386

Epoch: 6| Step: 6
Training loss: 1.806085467338562
Validation loss: 2.04388306730537

Epoch: 6| Step: 7
Training loss: 1.7288036346435547
Validation loss: 2.048977582685409

Epoch: 6| Step: 8
Training loss: 2.0618348121643066
Validation loss: 2.024278122891662

Epoch: 6| Step: 9
Training loss: 2.28446626663208
Validation loss: 2.0146383265013337

Epoch: 6| Step: 10
Training loss: 2.0152838230133057
Validation loss: 2.0119387257483696

Epoch: 6| Step: 11
Training loss: 1.1570825576782227
Validation loss: 2.025030054071898

Epoch: 6| Step: 12
Training loss: 2.683894634246826
Validation loss: 2.0184690157572427

Epoch: 6| Step: 13
Training loss: 2.4682912826538086
Validation loss: 2.0229703072578675

Epoch: 161| Step: 0
Training loss: 2.5339369773864746
Validation loss: 2.000457432962233

Epoch: 6| Step: 1
Training loss: 1.9685510396957397
Validation loss: 2.0280800250268753

Epoch: 6| Step: 2
Training loss: 2.1081271171569824
Validation loss: 2.025927746167747

Epoch: 6| Step: 3
Training loss: 2.6001698970794678
Validation loss: 2.019592031355827

Epoch: 6| Step: 4
Training loss: 1.789756178855896
Validation loss: 2.0139867503155946

Epoch: 6| Step: 5
Training loss: 2.2694644927978516
Validation loss: 2.004759065566524

Epoch: 6| Step: 6
Training loss: 1.8954434394836426
Validation loss: 2.0038294843448106

Epoch: 6| Step: 7
Training loss: 1.428283929824829
Validation loss: 1.9812175407204577

Epoch: 6| Step: 8
Training loss: 1.81215238571167
Validation loss: 1.9915063560649913

Epoch: 6| Step: 9
Training loss: 2.2911477088928223
Validation loss: 1.990617262419834

Epoch: 6| Step: 10
Training loss: 1.7502402067184448
Validation loss: 2.0128270708104616

Epoch: 6| Step: 11
Training loss: 1.8383923768997192
Validation loss: 2.011245507065968

Epoch: 6| Step: 12
Training loss: 2.174887180328369
Validation loss: 1.972833082240115

Epoch: 6| Step: 13
Training loss: 2.3812835216522217
Validation loss: 1.993713484015516

Epoch: 162| Step: 0
Training loss: 2.226357936859131
Validation loss: 2.0107516857885543

Epoch: 6| Step: 1
Training loss: 2.5593278408050537
Validation loss: 2.0068007669141217

Epoch: 6| Step: 2
Training loss: 1.3661731481552124
Validation loss: 2.0135225736966698

Epoch: 6| Step: 3
Training loss: 2.55002498626709
Validation loss: 1.998856234294112

Epoch: 6| Step: 4
Training loss: 2.0346264839172363
Validation loss: 2.0178018462273384

Epoch: 6| Step: 5
Training loss: 2.163949489593506
Validation loss: 2.0123764545686784

Epoch: 6| Step: 6
Training loss: 2.424548387527466
Validation loss: 2.0365260237006733

Epoch: 6| Step: 7
Training loss: 1.8902204036712646
Validation loss: 2.036962383536882

Epoch: 6| Step: 8
Training loss: 2.339953660964966
Validation loss: 2.0310779181859826

Epoch: 6| Step: 9
Training loss: 1.5438209772109985
Validation loss: 2.0246505122030936

Epoch: 6| Step: 10
Training loss: 2.3038222789764404
Validation loss: 2.0552420513604277

Epoch: 6| Step: 11
Training loss: 1.6596076488494873
Validation loss: 2.0398333713572514

Epoch: 6| Step: 12
Training loss: 2.070096492767334
Validation loss: 2.0374845830343102

Epoch: 6| Step: 13
Training loss: 1.3462516069412231
Validation loss: 2.0330524918853596

Epoch: 163| Step: 0
Training loss: 2.061607599258423
Validation loss: 2.033943724888627

Epoch: 6| Step: 1
Training loss: 2.443845510482788
Validation loss: 2.0428434136093303

Epoch: 6| Step: 2
Training loss: 2.3022005558013916
Validation loss: 1.9971610307693481

Epoch: 6| Step: 3
Training loss: 2.491692066192627
Validation loss: 2.0007186833248345

Epoch: 6| Step: 4
Training loss: 0.9337480664253235
Validation loss: 2.003576229977351

Epoch: 6| Step: 5
Training loss: 2.8502252101898193
Validation loss: 2.0402724358343307

Epoch: 6| Step: 6
Training loss: 1.8776451349258423
Validation loss: 2.0130750235690864

Epoch: 6| Step: 7
Training loss: 2.247960090637207
Validation loss: 2.014510803325202

Epoch: 6| Step: 8
Training loss: 1.9952729940414429
Validation loss: 1.9931311274087558

Epoch: 6| Step: 9
Training loss: 2.045685052871704
Validation loss: 1.9924155473709106

Epoch: 6| Step: 10
Training loss: 1.8094241619110107
Validation loss: 1.996426046535533

Epoch: 6| Step: 11
Training loss: 2.044412612915039
Validation loss: 2.021340475287489

Epoch: 6| Step: 12
Training loss: 1.851776361465454
Validation loss: 2.005336489728702

Epoch: 6| Step: 13
Training loss: 1.1413147449493408
Validation loss: 2.0135907075738393

Epoch: 164| Step: 0
Training loss: 1.8878775835037231
Validation loss: 1.9985426292624524

Epoch: 6| Step: 1
Training loss: 1.0199564695358276
Validation loss: 1.985463838423452

Epoch: 6| Step: 2
Training loss: 1.2770605087280273
Validation loss: 2.0090958405566472

Epoch: 6| Step: 3
Training loss: 1.6548147201538086
Validation loss: 2.015348885648994

Epoch: 6| Step: 4
Training loss: 2.6832218170166016
Validation loss: 2.0029053277866815

Epoch: 6| Step: 5
Training loss: 2.6085591316223145
Validation loss: 1.9979875485102336

Epoch: 6| Step: 6
Training loss: 1.9406673908233643
Validation loss: 2.01609754818742

Epoch: 6| Step: 7
Training loss: 2.269279956817627
Validation loss: 2.022574902862631

Epoch: 6| Step: 8
Training loss: 2.8163113594055176
Validation loss: 2.004719042008923

Epoch: 6| Step: 9
Training loss: 1.982861042022705
Validation loss: 1.997196517964845

Epoch: 6| Step: 10
Training loss: 2.2148525714874268
Validation loss: 2.018204841562497

Epoch: 6| Step: 11
Training loss: 2.5037965774536133
Validation loss: 2.01804284767438

Epoch: 6| Step: 12
Training loss: 1.8750426769256592
Validation loss: 1.9954711185988558

Epoch: 6| Step: 13
Training loss: 1.8463232517242432
Validation loss: 1.9950145354834936

Epoch: 165| Step: 0
Training loss: 2.234656572341919
Validation loss: 2.0289803294725317

Epoch: 6| Step: 1
Training loss: 1.999651312828064
Validation loss: 2.011574258086502

Epoch: 6| Step: 2
Training loss: 2.3021347522735596
Validation loss: 2.0186285049684587

Epoch: 6| Step: 3
Training loss: 1.3355658054351807
Validation loss: 2.033606921472857

Epoch: 6| Step: 4
Training loss: 1.812193512916565
Validation loss: 2.019680489775955

Epoch: 6| Step: 5
Training loss: 1.99637770652771
Validation loss: 2.0336817746521323

Epoch: 6| Step: 6
Training loss: 2.423421621322632
Validation loss: 2.0027970767790273

Epoch: 6| Step: 7
Training loss: 1.7233881950378418
Validation loss: 2.033603737431188

Epoch: 6| Step: 8
Training loss: 2.577327251434326
Validation loss: 2.0232054110496276

Epoch: 6| Step: 9
Training loss: 2.4227442741394043
Validation loss: 2.003701771459272

Epoch: 6| Step: 10
Training loss: 2.437530279159546
Validation loss: 1.9966177555822557

Epoch: 6| Step: 11
Training loss: 1.8891575336456299
Validation loss: 2.0197862322612474

Epoch: 6| Step: 12
Training loss: 1.696627140045166
Validation loss: 2.01067828875716

Epoch: 6| Step: 13
Training loss: 1.7541697025299072
Validation loss: 2.0104764994754585

Epoch: 166| Step: 0
Training loss: 2.1640608310699463
Validation loss: 1.9931487396199217

Epoch: 6| Step: 1
Training loss: 2.1433138847351074
Validation loss: 1.9849976288375033

Epoch: 6| Step: 2
Training loss: 1.5104584693908691
Validation loss: 2.0078477731315036

Epoch: 6| Step: 3
Training loss: 2.267927408218384
Validation loss: 1.962490604769799

Epoch: 6| Step: 4
Training loss: 2.063241481781006
Validation loss: 2.0215405930754957

Epoch: 6| Step: 5
Training loss: 1.8249704837799072
Validation loss: 1.9939616136653449

Epoch: 6| Step: 6
Training loss: 2.289004325866699
Validation loss: 1.9860665644368818

Epoch: 6| Step: 7
Training loss: 2.8796262741088867
Validation loss: 2.0061117141477522

Epoch: 6| Step: 8
Training loss: 2.369900703430176
Validation loss: 1.9881663424994356

Epoch: 6| Step: 9
Training loss: 1.4848113059997559
Validation loss: 1.996282390368882

Epoch: 6| Step: 10
Training loss: 1.8277629613876343
Validation loss: 1.987966743848657

Epoch: 6| Step: 11
Training loss: 2.046671152114868
Validation loss: 2.0050663794240644

Epoch: 6| Step: 12
Training loss: 1.8409862518310547
Validation loss: 2.0098112334487257

Epoch: 6| Step: 13
Training loss: 1.5375096797943115
Validation loss: 2.012448272397441

Epoch: 167| Step: 0
Training loss: 2.135805130004883
Validation loss: 1.994756813972227

Epoch: 6| Step: 1
Training loss: 2.2757527828216553
Validation loss: 2.0151342679095525

Epoch: 6| Step: 2
Training loss: 1.916344404220581
Validation loss: 1.995212411367765

Epoch: 6| Step: 3
Training loss: 1.9643993377685547
Validation loss: 2.012922013959577

Epoch: 6| Step: 4
Training loss: 1.9372539520263672
Validation loss: 2.00279644227797

Epoch: 6| Step: 5
Training loss: 2.632725954055786
Validation loss: 2.023896960801976

Epoch: 6| Step: 6
Training loss: 2.4023592472076416
Validation loss: 2.0183591201741207

Epoch: 6| Step: 7
Training loss: 2.1997480392456055
Validation loss: 1.9935018106173443

Epoch: 6| Step: 8
Training loss: 1.468835711479187
Validation loss: 2.0053555555241083

Epoch: 6| Step: 9
Training loss: 2.0113987922668457
Validation loss: 2.0229375734124133

Epoch: 6| Step: 10
Training loss: 1.8599879741668701
Validation loss: 2.0173066918567946

Epoch: 6| Step: 11
Training loss: 1.7822442054748535
Validation loss: 2.022941399646062

Epoch: 6| Step: 12
Training loss: 2.1969780921936035
Validation loss: 1.996266670124505

Epoch: 6| Step: 13
Training loss: 1.4505054950714111
Validation loss: 2.030771291384133

Epoch: 168| Step: 0
Training loss: 1.6313776969909668
Validation loss: 2.004321341873497

Epoch: 6| Step: 1
Training loss: 1.8324986696243286
Validation loss: 2.0266385796249553

Epoch: 6| Step: 2
Training loss: 1.9558367729187012
Validation loss: 2.0200859910698346

Epoch: 6| Step: 3
Training loss: 1.8484596014022827
Validation loss: 2.0351909283668763

Epoch: 6| Step: 4
Training loss: 2.128828287124634
Validation loss: 2.0410883965030795

Epoch: 6| Step: 5
Training loss: 2.372465133666992
Validation loss: 2.039647384356427

Epoch: 6| Step: 6
Training loss: 1.975498080253601
Validation loss: 2.060563040036027

Epoch: 6| Step: 7
Training loss: 1.9583513736724854
Validation loss: 2.047674121395234

Epoch: 6| Step: 8
Training loss: 1.8885530233383179
Validation loss: 2.049011061268468

Epoch: 6| Step: 9
Training loss: 2.201397180557251
Validation loss: 2.0592227905027327

Epoch: 6| Step: 10
Training loss: 2.3019304275512695
Validation loss: 2.0386624541333926

Epoch: 6| Step: 11
Training loss: 2.4319682121276855
Validation loss: 2.0476239483843566

Epoch: 6| Step: 12
Training loss: 1.9200928211212158
Validation loss: 2.0460525558840845

Epoch: 6| Step: 13
Training loss: 2.25750470161438
Validation loss: 2.036540792834374

Epoch: 169| Step: 0
Training loss: 1.8518171310424805
Validation loss: 2.041967450931508

Epoch: 6| Step: 1
Training loss: 2.412595272064209
Validation loss: 2.029014600220547

Epoch: 6| Step: 2
Training loss: 1.8811914920806885
Validation loss: 2.0183672340967322

Epoch: 6| Step: 3
Training loss: 2.3715806007385254
Validation loss: 2.0122002991296912

Epoch: 6| Step: 4
Training loss: 2.2121570110321045
Validation loss: 2.026309895259078

Epoch: 6| Step: 5
Training loss: 2.061997890472412
Validation loss: 2.0238057451863445

Epoch: 6| Step: 6
Training loss: 1.434712529182434
Validation loss: 2.0068227244961645

Epoch: 6| Step: 7
Training loss: 1.741280436515808
Validation loss: 2.0174087221904466

Epoch: 6| Step: 8
Training loss: 2.2384276390075684
Validation loss: 1.993188411958756

Epoch: 6| Step: 9
Training loss: 2.5597286224365234
Validation loss: 2.0307044572727655

Epoch: 6| Step: 10
Training loss: 2.0065410137176514
Validation loss: 2.0102990314524662

Epoch: 6| Step: 11
Training loss: 1.800551176071167
Validation loss: 1.9864232796494679

Epoch: 6| Step: 12
Training loss: 1.7106342315673828
Validation loss: 2.0105441706154936

Epoch: 6| Step: 13
Training loss: 2.1140027046203613
Validation loss: 2.0179912620975125

Epoch: 170| Step: 0
Training loss: 2.025005578994751
Validation loss: 1.9876301621878019

Epoch: 6| Step: 1
Training loss: 2.2812113761901855
Validation loss: 1.9946478156633274

Epoch: 6| Step: 2
Training loss: 2.0898759365081787
Validation loss: 1.9871370933389152

Epoch: 6| Step: 3
Training loss: 1.8707530498504639
Validation loss: 1.9720794282933718

Epoch: 6| Step: 4
Training loss: 1.85890531539917
Validation loss: 1.9878564624376194

Epoch: 6| Step: 5
Training loss: 2.748854875564575
Validation loss: 1.9934711430662422

Epoch: 6| Step: 6
Training loss: 2.2996296882629395
Validation loss: 1.9950880389059744

Epoch: 6| Step: 7
Training loss: 1.4987835884094238
Validation loss: 1.9944913797481085

Epoch: 6| Step: 8
Training loss: 1.728434681892395
Validation loss: 1.9929174146344584

Epoch: 6| Step: 9
Training loss: 1.8399443626403809
Validation loss: 2.0055190029964653

Epoch: 6| Step: 10
Training loss: 1.5215601921081543
Validation loss: 2.006664947796893

Epoch: 6| Step: 11
Training loss: 2.2880382537841797
Validation loss: 2.0073811584903347

Epoch: 6| Step: 12
Training loss: 2.1066901683807373
Validation loss: 2.0368708179843042

Epoch: 6| Step: 13
Training loss: 2.6132936477661133
Validation loss: 2.0102138698741956

Epoch: 171| Step: 0
Training loss: 2.1760733127593994
Validation loss: 1.9903247920415734

Epoch: 6| Step: 1
Training loss: 2.0654141902923584
Validation loss: 2.006347966450517

Epoch: 6| Step: 2
Training loss: 1.5262471437454224
Validation loss: 2.023589293162028

Epoch: 6| Step: 3
Training loss: 1.487421989440918
Validation loss: 2.0031841698513237

Epoch: 6| Step: 4
Training loss: 2.1258621215820312
Validation loss: 1.9810753355744064

Epoch: 6| Step: 5
Training loss: 1.356094241142273
Validation loss: 2.002982549769904

Epoch: 6| Step: 6
Training loss: 1.9657652378082275
Validation loss: 2.0045972280604865

Epoch: 6| Step: 7
Training loss: 2.188432216644287
Validation loss: 2.0178290310726372

Epoch: 6| Step: 8
Training loss: 2.179873466491699
Validation loss: 2.021026974083275

Epoch: 6| Step: 9
Training loss: 2.5048344135284424
Validation loss: 1.9961196312340357

Epoch: 6| Step: 10
Training loss: 2.196727752685547
Validation loss: 2.01333095694101

Epoch: 6| Step: 11
Training loss: 2.237823486328125
Validation loss: 2.017591594367899

Epoch: 6| Step: 12
Training loss: 1.6525402069091797
Validation loss: 2.011526425679525

Epoch: 6| Step: 13
Training loss: 3.291720151901245
Validation loss: 1.987625301525157

Epoch: 172| Step: 0
Training loss: 1.808580756187439
Validation loss: 2.032862271032026

Epoch: 6| Step: 1
Training loss: 1.6977723836898804
Validation loss: 2.017698350773063

Epoch: 6| Step: 2
Training loss: 2.0994532108306885
Validation loss: 2.020495853116435

Epoch: 6| Step: 3
Training loss: 2.306757688522339
Validation loss: 2.0004766371942337

Epoch: 6| Step: 4
Training loss: 1.6680076122283936
Validation loss: 2.015740530465239

Epoch: 6| Step: 5
Training loss: 2.0248963832855225
Validation loss: 2.032843683355598

Epoch: 6| Step: 6
Training loss: 2.102247953414917
Validation loss: 2.0112574100494385

Epoch: 6| Step: 7
Training loss: 1.9970874786376953
Validation loss: 2.0379781453840193

Epoch: 6| Step: 8
Training loss: 2.392645835876465
Validation loss: 2.0246842074137863

Epoch: 6| Step: 9
Training loss: 2.0541276931762695
Validation loss: 2.019847026435278

Epoch: 6| Step: 10
Training loss: 2.575766086578369
Validation loss: 2.0390398117803756

Epoch: 6| Step: 11
Training loss: 1.9592618942260742
Validation loss: 2.023518773817247

Epoch: 6| Step: 12
Training loss: 1.8963587284088135
Validation loss: 2.0019511433057886

Epoch: 6| Step: 13
Training loss: 1.4980831146240234
Validation loss: 2.0129101994217082

Epoch: 173| Step: 0
Training loss: 1.963374376296997
Validation loss: 2.0386630181343324

Epoch: 6| Step: 1
Training loss: 3.0231497287750244
Validation loss: 1.9916777585142402

Epoch: 6| Step: 2
Training loss: 2.084094762802124
Validation loss: 1.9940076720330022

Epoch: 6| Step: 3
Training loss: 2.074535608291626
Validation loss: 2.00536451801177

Epoch: 6| Step: 4
Training loss: 2.012777328491211
Validation loss: 2.0151945685827606

Epoch: 6| Step: 5
Training loss: 1.8354730606079102
Validation loss: 2.023031175777476

Epoch: 6| Step: 6
Training loss: 1.0863597393035889
Validation loss: 2.0111906810473372

Epoch: 6| Step: 7
Training loss: 2.1709694862365723
Validation loss: 2.033945324600384

Epoch: 6| Step: 8
Training loss: 1.9468603134155273
Validation loss: 2.012026135639478

Epoch: 6| Step: 9
Training loss: 1.5045146942138672
Validation loss: 2.0305558955797585

Epoch: 6| Step: 10
Training loss: 1.9446684122085571
Validation loss: 2.023281874195222

Epoch: 6| Step: 11
Training loss: 2.487133502960205
Validation loss: 2.006749524865099

Epoch: 6| Step: 12
Training loss: 2.279916286468506
Validation loss: 1.9956532473205237

Epoch: 6| Step: 13
Training loss: 1.7187142372131348
Validation loss: 2.009141560523741

Epoch: 174| Step: 0
Training loss: 2.204099655151367
Validation loss: 2.0367386443640596

Epoch: 6| Step: 1
Training loss: 1.5408234596252441
Validation loss: 2.004059571091847

Epoch: 6| Step: 2
Training loss: 1.8773958683013916
Validation loss: 1.988719742785218

Epoch: 6| Step: 3
Training loss: 2.2744951248168945
Validation loss: 2.019816570384528

Epoch: 6| Step: 4
Training loss: 2.515990734100342
Validation loss: 1.986430909043999

Epoch: 6| Step: 5
Training loss: 1.4513219594955444
Validation loss: 2.0078722866632606

Epoch: 6| Step: 6
Training loss: 2.0043585300445557
Validation loss: 2.0161015679759364

Epoch: 6| Step: 7
Training loss: 1.9257423877716064
Validation loss: 2.016927724243492

Epoch: 6| Step: 8
Training loss: 2.5108513832092285
Validation loss: 1.9994550174282444

Epoch: 6| Step: 9
Training loss: 1.6563992500305176
Validation loss: 2.0036278898997972

Epoch: 6| Step: 10
Training loss: 2.2576167583465576
Validation loss: 2.0107468866532847

Epoch: 6| Step: 11
Training loss: 2.006484270095825
Validation loss: 2.0108204733940864

Epoch: 6| Step: 12
Training loss: 1.999677300453186
Validation loss: 2.022937488812272

Epoch: 6| Step: 13
Training loss: 1.790526270866394
Validation loss: 2.016959972279046

Epoch: 175| Step: 0
Training loss: 2.760255813598633
Validation loss: 2.0279753669615714

Epoch: 6| Step: 1
Training loss: 1.8563110828399658
Validation loss: 2.0272394559716664

Epoch: 6| Step: 2
Training loss: 2.3468360900878906
Validation loss: 2.022644903070183

Epoch: 6| Step: 3
Training loss: 2.0258865356445312
Validation loss: 2.0015088819688365

Epoch: 6| Step: 4
Training loss: 1.476790428161621
Validation loss: 2.01182294917363

Epoch: 6| Step: 5
Training loss: 1.2687443494796753
Validation loss: 2.05313547965019

Epoch: 6| Step: 6
Training loss: 1.725853681564331
Validation loss: 2.029053158657525

Epoch: 6| Step: 7
Training loss: 2.2308998107910156
Validation loss: 2.0004104260475404

Epoch: 6| Step: 8
Training loss: 1.927628993988037
Validation loss: 2.027353568743634

Epoch: 6| Step: 9
Training loss: 1.8157813549041748
Validation loss: 2.016622151097944

Epoch: 6| Step: 10
Training loss: 1.959160327911377
Validation loss: 2.033384911475643

Epoch: 6| Step: 11
Training loss: 2.5741870403289795
Validation loss: 2.0163276400617374

Epoch: 6| Step: 12
Training loss: 2.0973424911499023
Validation loss: 1.9922781836601995

Epoch: 6| Step: 13
Training loss: 2.307650566101074
Validation loss: 1.99688623925691

Epoch: 176| Step: 0
Training loss: 1.6580835580825806
Validation loss: 2.007669802634947

Epoch: 6| Step: 1
Training loss: 1.7043297290802002
Validation loss: 1.9844407291822537

Epoch: 6| Step: 2
Training loss: 1.81136953830719
Validation loss: 1.99316184366903

Epoch: 6| Step: 3
Training loss: 1.9932634830474854
Validation loss: 2.0115751233152164

Epoch: 6| Step: 4
Training loss: 1.739614486694336
Validation loss: 2.0076977873361237

Epoch: 6| Step: 5
Training loss: 1.893272876739502
Validation loss: 2.006849391486055

Epoch: 6| Step: 6
Training loss: 1.958886981010437
Validation loss: 2.0023828834615727

Epoch: 6| Step: 7
Training loss: 2.143096923828125
Validation loss: 1.9859422663206696

Epoch: 6| Step: 8
Training loss: 2.506122350692749
Validation loss: 2.0148588226687525

Epoch: 6| Step: 9
Training loss: 2.2674379348754883
Validation loss: 1.9785594042911325

Epoch: 6| Step: 10
Training loss: 1.601374626159668
Validation loss: 1.9948933329633487

Epoch: 6| Step: 11
Training loss: 2.3656766414642334
Validation loss: 1.973486077400946

Epoch: 6| Step: 12
Training loss: 1.9442437887191772
Validation loss: 2.0031915005817207

Epoch: 6| Step: 13
Training loss: 3.0383856296539307
Validation loss: 1.9781100852515108

Epoch: 177| Step: 0
Training loss: 1.2744784355163574
Validation loss: 1.9901744857911141

Epoch: 6| Step: 1
Training loss: 1.8947117328643799
Validation loss: 1.9853435588139359

Epoch: 6| Step: 2
Training loss: 3.4273219108581543
Validation loss: 1.9964861075083415

Epoch: 6| Step: 3
Training loss: 2.16096830368042
Validation loss: 2.0143113418291976

Epoch: 6| Step: 4
Training loss: 2.099656820297241
Validation loss: 2.0081125100453696

Epoch: 6| Step: 5
Training loss: 1.9623523950576782
Validation loss: 2.036125818888346

Epoch: 6| Step: 6
Training loss: 1.9564412832260132
Validation loss: 2.0038801572656118

Epoch: 6| Step: 7
Training loss: 2.0097882747650146
Validation loss: 2.0547605253035024

Epoch: 6| Step: 8
Training loss: 1.740093469619751
Validation loss: 2.031538389062369

Epoch: 6| Step: 9
Training loss: 1.7392792701721191
Validation loss: 2.00980697395981

Epoch: 6| Step: 10
Training loss: 2.530076742172241
Validation loss: 2.00083008632865

Epoch: 6| Step: 11
Training loss: 1.8645086288452148
Validation loss: 2.040156646441388

Epoch: 6| Step: 12
Training loss: 1.8153836727142334
Validation loss: 2.039565984920789

Epoch: 6| Step: 13
Training loss: 1.43113374710083
Validation loss: 2.012958134374311

Epoch: 178| Step: 0
Training loss: 2.782276153564453
Validation loss: 2.0070200081794494

Epoch: 6| Step: 1
Training loss: 2.433156967163086
Validation loss: 2.001173178354899

Epoch: 6| Step: 2
Training loss: 2.208859443664551
Validation loss: 1.984229951776484

Epoch: 6| Step: 3
Training loss: 1.8378158807754517
Validation loss: 2.018626464310513

Epoch: 6| Step: 4
Training loss: 1.8416047096252441
Validation loss: 2.003666045845196

Epoch: 6| Step: 5
Training loss: 1.7106952667236328
Validation loss: 1.9901336739140172

Epoch: 6| Step: 6
Training loss: 1.5764589309692383
Validation loss: 2.010529387381769

Epoch: 6| Step: 7
Training loss: 2.086526393890381
Validation loss: 2.0056076562532814

Epoch: 6| Step: 8
Training loss: 1.9409940242767334
Validation loss: 1.9880714019139607

Epoch: 6| Step: 9
Training loss: 1.781191110610962
Validation loss: 1.9882616304582166

Epoch: 6| Step: 10
Training loss: 2.0218024253845215
Validation loss: 2.0179102472079697

Epoch: 6| Step: 11
Training loss: 1.8591957092285156
Validation loss: 1.9963007255267071

Epoch: 6| Step: 12
Training loss: 2.116489887237549
Validation loss: 1.9610626492449033

Epoch: 6| Step: 13
Training loss: 1.8759112358093262
Validation loss: 2.017725961182707

Epoch: 179| Step: 0
Training loss: 1.8254401683807373
Validation loss: 1.9715730041585944

Epoch: 6| Step: 1
Training loss: 2.2547192573547363
Validation loss: 1.9830668177655948

Epoch: 6| Step: 2
Training loss: 1.7621691226959229
Validation loss: 2.0113467965074765

Epoch: 6| Step: 3
Training loss: 1.5758311748504639
Validation loss: 1.998565307227514

Epoch: 6| Step: 4
Training loss: 2.3339405059814453
Validation loss: 2.0036914912603234

Epoch: 6| Step: 5
Training loss: 2.223691463470459
Validation loss: 1.9998789679619573

Epoch: 6| Step: 6
Training loss: 1.9660024642944336
Validation loss: 2.0352392042836835

Epoch: 6| Step: 7
Training loss: 2.3255209922790527
Validation loss: 2.0269723605084162

Epoch: 6| Step: 8
Training loss: 1.1871042251586914
Validation loss: 2.0269045099135368

Epoch: 6| Step: 9
Training loss: 1.7664413452148438
Validation loss: 2.004327772766031

Epoch: 6| Step: 10
Training loss: 2.5500011444091797
Validation loss: 2.033956155982069

Epoch: 6| Step: 11
Training loss: 1.9869095087051392
Validation loss: 2.0203551092455463

Epoch: 6| Step: 12
Training loss: 2.2637686729431152
Validation loss: 2.0428917254171064

Epoch: 6| Step: 13
Training loss: 2.1131176948547363
Validation loss: 2.0250605165317492

Epoch: 180| Step: 0
Training loss: 2.065462589263916
Validation loss: 2.0240551797292565

Epoch: 6| Step: 1
Training loss: 1.8481552600860596
Validation loss: 2.0246736952053603

Epoch: 6| Step: 2
Training loss: 2.161440849304199
Validation loss: 2.014146858646024

Epoch: 6| Step: 3
Training loss: 1.5977628231048584
Validation loss: 1.9996615020177697

Epoch: 6| Step: 4
Training loss: 2.0472936630249023
Validation loss: 2.014440756972118

Epoch: 6| Step: 5
Training loss: 1.7382841110229492
Validation loss: 2.0022933662578626

Epoch: 6| Step: 6
Training loss: 1.7795073986053467
Validation loss: 1.9802267205330633

Epoch: 6| Step: 7
Training loss: 2.5336904525756836
Validation loss: 1.9741361038659209

Epoch: 6| Step: 8
Training loss: 2.3553223609924316
Validation loss: 2.006930806303537

Epoch: 6| Step: 9
Training loss: 1.3515284061431885
Validation loss: 2.0229733528629428

Epoch: 6| Step: 10
Training loss: 2.460867166519165
Validation loss: 2.0158930940012776

Epoch: 6| Step: 11
Training loss: 2.5248842239379883
Validation loss: 1.9993966907583258

Epoch: 6| Step: 12
Training loss: 1.6618618965148926
Validation loss: 2.0095385146397415

Epoch: 6| Step: 13
Training loss: 2.2536919116973877
Validation loss: 2.018490481120284

Epoch: 181| Step: 0
Training loss: 2.359683036804199
Validation loss: 2.019764672043503

Epoch: 6| Step: 1
Training loss: 2.254757881164551
Validation loss: 2.0285751383791686

Epoch: 6| Step: 2
Training loss: 2.4679970741271973
Validation loss: 2.0074449559693694

Epoch: 6| Step: 3
Training loss: 1.6014312505722046
Validation loss: 2.018877105046344

Epoch: 6| Step: 4
Training loss: 2.4029035568237305
Validation loss: 1.9784190629118232

Epoch: 6| Step: 5
Training loss: 1.333848476409912
Validation loss: 1.9981231138270388

Epoch: 6| Step: 6
Training loss: 1.8059029579162598
Validation loss: 2.0371653572205575

Epoch: 6| Step: 7
Training loss: 1.6572468280792236
Validation loss: 2.013442220226411

Epoch: 6| Step: 8
Training loss: 1.6829721927642822
Validation loss: 2.0024185513937347

Epoch: 6| Step: 9
Training loss: 1.9729118347167969
Validation loss: 2.0196039817666493

Epoch: 6| Step: 10
Training loss: 1.6604300737380981
Validation loss: 2.006092688088776

Epoch: 6| Step: 11
Training loss: 1.6548657417297363
Validation loss: 2.011337335391711

Epoch: 6| Step: 12
Training loss: 2.734058380126953
Validation loss: 2.006612718746226

Epoch: 6| Step: 13
Training loss: 2.9250833988189697
Validation loss: 2.010468344534597

Epoch: 182| Step: 0
Training loss: 2.2910194396972656
Validation loss: 2.0268838867064445

Epoch: 6| Step: 1
Training loss: 2.4689383506774902
Validation loss: 2.0561198085866947

Epoch: 6| Step: 2
Training loss: 2.468656301498413
Validation loss: 2.0511407288171912

Epoch: 6| Step: 3
Training loss: 1.840554118156433
Validation loss: 2.032753808524019

Epoch: 6| Step: 4
Training loss: 2.2811570167541504
Validation loss: 2.085883411028052

Epoch: 6| Step: 5
Training loss: 1.6471552848815918
Validation loss: 2.0493522023641937

Epoch: 6| Step: 6
Training loss: 1.6039756536483765
Validation loss: 2.08377589461624

Epoch: 6| Step: 7
Training loss: 1.8243236541748047
Validation loss: 2.0627957197927658

Epoch: 6| Step: 8
Training loss: 1.619283676147461
Validation loss: 2.0592076804048274

Epoch: 6| Step: 9
Training loss: 1.7765041589736938
Validation loss: 2.059810329509038

Epoch: 6| Step: 10
Training loss: 1.9728567600250244
Validation loss: 2.034057290323319

Epoch: 6| Step: 11
Training loss: 2.2004754543304443
Validation loss: 2.0655358119677474

Epoch: 6| Step: 12
Training loss: 1.9169104099273682
Validation loss: 2.0370892119664017

Epoch: 6| Step: 13
Training loss: 2.3108527660369873
Validation loss: 2.0412437172346216

Epoch: 183| Step: 0
Training loss: 1.7725539207458496
Validation loss: 2.0327356053936865

Epoch: 6| Step: 1
Training loss: 2.0615320205688477
Validation loss: 2.042856019030335

Epoch: 6| Step: 2
Training loss: 2.2678537368774414
Validation loss: 2.0178084501656155

Epoch: 6| Step: 3
Training loss: 1.6999289989471436
Validation loss: 2.0235223898323635

Epoch: 6| Step: 4
Training loss: 2.096280574798584
Validation loss: 2.051074380515724

Epoch: 6| Step: 5
Training loss: 2.051086902618408
Validation loss: 1.9893152752230245

Epoch: 6| Step: 6
Training loss: 1.8357510566711426
Validation loss: 2.0035077038631646

Epoch: 6| Step: 7
Training loss: 2.0980703830718994
Validation loss: 1.9879786096593386

Epoch: 6| Step: 8
Training loss: 1.9055026769638062
Validation loss: 1.9682747381989674

Epoch: 6| Step: 9
Training loss: 1.8587961196899414
Validation loss: 1.996590022117861

Epoch: 6| Step: 10
Training loss: 2.0879838466644287
Validation loss: 2.0118759011709564

Epoch: 6| Step: 11
Training loss: 2.1750264167785645
Validation loss: 1.9931174439768637

Epoch: 6| Step: 12
Training loss: 2.0729639530181885
Validation loss: 1.9777981824772333

Epoch: 6| Step: 13
Training loss: 1.992037057876587
Validation loss: 1.987831779705581

Epoch: 184| Step: 0
Training loss: 1.62923264503479
Validation loss: 1.9654734185946885

Epoch: 6| Step: 1
Training loss: 2.1026368141174316
Validation loss: 2.0030178229014077

Epoch: 6| Step: 2
Training loss: 1.9167147874832153
Validation loss: 2.013278945799797

Epoch: 6| Step: 3
Training loss: 2.7284467220306396
Validation loss: 1.9761378303650887

Epoch: 6| Step: 4
Training loss: 1.8847007751464844
Validation loss: 2.0286672038416707

Epoch: 6| Step: 5
Training loss: 2.275822162628174
Validation loss: 2.039885905481154

Epoch: 6| Step: 6
Training loss: 1.8324694633483887
Validation loss: 2.0098051537749586

Epoch: 6| Step: 7
Training loss: 1.9537259340286255
Validation loss: 2.0369113170972435

Epoch: 6| Step: 8
Training loss: 1.3541065454483032
Validation loss: 2.0129729368353404

Epoch: 6| Step: 9
Training loss: 2.0251846313476562
Validation loss: 2.0298613732860935

Epoch: 6| Step: 10
Training loss: 2.0947885513305664
Validation loss: 2.0643994410832724

Epoch: 6| Step: 11
Training loss: 2.0839977264404297
Validation loss: 2.029136610287492

Epoch: 6| Step: 12
Training loss: 2.02703857421875
Validation loss: 2.0307646733458324

Epoch: 6| Step: 13
Training loss: 2.3500444889068604
Validation loss: 2.046559990093272

Epoch: 185| Step: 0
Training loss: 1.747619390487671
Validation loss: 2.062381831548547

Epoch: 6| Step: 1
Training loss: 2.1476662158966064
Validation loss: 2.0285088451959754

Epoch: 6| Step: 2
Training loss: 2.213599681854248
Validation loss: 2.0438646244746383

Epoch: 6| Step: 3
Training loss: 2.3175899982452393
Validation loss: 2.0261735762319257

Epoch: 6| Step: 4
Training loss: 2.2568864822387695
Validation loss: 2.050997439251151

Epoch: 6| Step: 5
Training loss: 1.627270221710205
Validation loss: 2.0231723182944843

Epoch: 6| Step: 6
Training loss: 2.112088680267334
Validation loss: 2.046927334159933

Epoch: 6| Step: 7
Training loss: 1.3374714851379395
Validation loss: 2.008393749114006

Epoch: 6| Step: 8
Training loss: 2.379847764968872
Validation loss: 2.0333635089217976

Epoch: 6| Step: 9
Training loss: 1.741242527961731
Validation loss: 2.0187282023891324

Epoch: 6| Step: 10
Training loss: 2.1790482997894287
Validation loss: 2.0110094495998916

Epoch: 6| Step: 11
Training loss: 1.7684805393218994
Validation loss: 2.0256820237764748

Epoch: 6| Step: 12
Training loss: 1.8815991878509521
Validation loss: 2.0127876445811284

Epoch: 6| Step: 13
Training loss: 2.3106937408447266
Validation loss: 2.025266399947546

Epoch: 186| Step: 0
Training loss: 1.8690185546875
Validation loss: 1.9976964073796426

Epoch: 6| Step: 1
Training loss: 1.9449223279953003
Validation loss: 2.0220342938617994

Epoch: 6| Step: 2
Training loss: 1.8307087421417236
Validation loss: 2.0125797217892063

Epoch: 6| Step: 3
Training loss: 2.410513401031494
Validation loss: 2.019783486602127

Epoch: 6| Step: 4
Training loss: 1.6230183839797974
Validation loss: 2.0224167095717562

Epoch: 6| Step: 5
Training loss: 1.7001707553863525
Validation loss: 2.01061995567814

Epoch: 6| Step: 6
Training loss: 1.4517390727996826
Validation loss: 2.0399659308054114

Epoch: 6| Step: 7
Training loss: 2.2586092948913574
Validation loss: 2.0366493219970376

Epoch: 6| Step: 8
Training loss: 2.3154971599578857
Validation loss: 2.0234660230657107

Epoch: 6| Step: 9
Training loss: 2.3329193592071533
Validation loss: 2.022926661276048

Epoch: 6| Step: 10
Training loss: 2.2214841842651367
Validation loss: 2.0062492406496437

Epoch: 6| Step: 11
Training loss: 1.8916866779327393
Validation loss: 2.0575119885065223

Epoch: 6| Step: 12
Training loss: 2.074099063873291
Validation loss: 2.023877118223457

Epoch: 6| Step: 13
Training loss: 2.055776357650757
Validation loss: 2.0555860150244927

Epoch: 187| Step: 0
Training loss: 1.7446563243865967
Validation loss: 2.01253996100477

Epoch: 6| Step: 1
Training loss: 2.413956642150879
Validation loss: 2.0457064515800885

Epoch: 6| Step: 2
Training loss: 1.6483569145202637
Validation loss: 2.04642209699077

Epoch: 6| Step: 3
Training loss: 1.6587334871292114
Validation loss: 2.0136395526188675

Epoch: 6| Step: 4
Training loss: 1.9480386972427368
Validation loss: 2.025171977217479

Epoch: 6| Step: 5
Training loss: 1.8361296653747559
Validation loss: 2.041323243930776

Epoch: 6| Step: 6
Training loss: 2.3408751487731934
Validation loss: 2.036994464935795

Epoch: 6| Step: 7
Training loss: 2.0817298889160156
Validation loss: 2.022865549210579

Epoch: 6| Step: 8
Training loss: 2.244497537612915
Validation loss: 2.0337486831090783

Epoch: 6| Step: 9
Training loss: 2.1346969604492188
Validation loss: 2.0394542935074016

Epoch: 6| Step: 10
Training loss: 1.467451810836792
Validation loss: 2.0245555498266734

Epoch: 6| Step: 11
Training loss: 2.104508399963379
Validation loss: 2.0015324161898707

Epoch: 6| Step: 12
Training loss: 2.147573471069336
Validation loss: 2.0294872765899985

Epoch: 6| Step: 13
Training loss: 1.8805198669433594
Validation loss: 2.0124811626249746

Epoch: 188| Step: 0
Training loss: 1.8634891510009766
Validation loss: 2.014862673256987

Epoch: 6| Step: 1
Training loss: 2.0031847953796387
Validation loss: 1.9941021191176547

Epoch: 6| Step: 2
Training loss: 1.9620723724365234
Validation loss: 2.0085861477800595

Epoch: 6| Step: 3
Training loss: 1.8079917430877686
Validation loss: 2.004806358327148

Epoch: 6| Step: 4
Training loss: 2.449309825897217
Validation loss: 2.0260606837529007

Epoch: 6| Step: 5
Training loss: 2.191458225250244
Validation loss: 2.016604128704276

Epoch: 6| Step: 6
Training loss: 1.8066157102584839
Validation loss: 2.0251158514330463

Epoch: 6| Step: 7
Training loss: 1.5313242673873901
Validation loss: 2.003313828540105

Epoch: 6| Step: 8
Training loss: 2.2874720096588135
Validation loss: 2.0232500312148884

Epoch: 6| Step: 9
Training loss: 1.7303749322891235
Validation loss: 2.0198093665543424

Epoch: 6| Step: 10
Training loss: 1.968823790550232
Validation loss: 2.0012178651748167

Epoch: 6| Step: 11
Training loss: 2.0635006427764893
Validation loss: 2.0274301780167447

Epoch: 6| Step: 12
Training loss: 1.9587821960449219
Validation loss: 2.051532298006037

Epoch: 6| Step: 13
Training loss: 2.002906084060669
Validation loss: 2.0155348290679274

Epoch: 189| Step: 0
Training loss: 1.5694773197174072
Validation loss: 2.0352355023866058

Epoch: 6| Step: 1
Training loss: 2.3364064693450928
Validation loss: 1.9988408088684082

Epoch: 6| Step: 2
Training loss: 1.2399663925170898
Validation loss: 2.0007273843211513

Epoch: 6| Step: 3
Training loss: 2.004762887954712
Validation loss: 1.9957615919010614

Epoch: 6| Step: 4
Training loss: 2.023176670074463
Validation loss: 2.00861495284624

Epoch: 6| Step: 5
Training loss: 2.158693790435791
Validation loss: 1.9963916501691263

Epoch: 6| Step: 6
Training loss: 1.9772729873657227
Validation loss: 1.9930132986396871

Epoch: 6| Step: 7
Training loss: 2.2324657440185547
Validation loss: 2.0073207193805325

Epoch: 6| Step: 8
Training loss: 1.7775309085845947
Validation loss: 2.020586311176259

Epoch: 6| Step: 9
Training loss: 2.017777681350708
Validation loss: 1.9875923151611

Epoch: 6| Step: 10
Training loss: 1.8294366598129272
Validation loss: 1.9928722612319454

Epoch: 6| Step: 11
Training loss: 1.816614031791687
Validation loss: 2.023599798961352

Epoch: 6| Step: 12
Training loss: 2.3377866744995117
Validation loss: 2.048130966001941

Epoch: 6| Step: 13
Training loss: 2.478166341781616
Validation loss: 2.0308802127838135

Epoch: 190| Step: 0
Training loss: 2.5869991779327393
Validation loss: 2.0036813905162196

Epoch: 6| Step: 1
Training loss: 1.7646615505218506
Validation loss: 2.014408221808813

Epoch: 6| Step: 2
Training loss: 1.1758575439453125
Validation loss: 2.0192640084092335

Epoch: 6| Step: 3
Training loss: 1.784231424331665
Validation loss: 2.0223265642760904

Epoch: 6| Step: 4
Training loss: 1.8344016075134277
Validation loss: 2.0113106120017266

Epoch: 6| Step: 5
Training loss: 2.7042059898376465
Validation loss: 2.0190966231848604

Epoch: 6| Step: 6
Training loss: 2.121610164642334
Validation loss: 2.0199635451839817

Epoch: 6| Step: 7
Training loss: 1.8124829530715942
Validation loss: 1.9878195024305774

Epoch: 6| Step: 8
Training loss: 1.8481563329696655
Validation loss: 2.0023682502008255

Epoch: 6| Step: 9
Training loss: 2.1553425788879395
Validation loss: 2.024983113811862

Epoch: 6| Step: 10
Training loss: 1.9403918981552124
Validation loss: 2.0022747260268017

Epoch: 6| Step: 11
Training loss: 1.8248440027236938
Validation loss: 1.9970131894593597

Epoch: 6| Step: 12
Training loss: 1.8363335132598877
Validation loss: 2.0179795962508007

Epoch: 6| Step: 13
Training loss: 2.6612958908081055
Validation loss: 2.025901363741967

Epoch: 191| Step: 0
Training loss: 1.5824064016342163
Validation loss: 2.0028413239345757

Epoch: 6| Step: 1
Training loss: 1.6687307357788086
Validation loss: 2.0090729703185377

Epoch: 6| Step: 2
Training loss: 1.8027018308639526
Validation loss: 1.9929137383737872

Epoch: 6| Step: 3
Training loss: 2.4003982543945312
Validation loss: 1.9973124291307183

Epoch: 6| Step: 4
Training loss: 2.399868965148926
Validation loss: 1.9907131707796486

Epoch: 6| Step: 5
Training loss: 2.899616241455078
Validation loss: 2.0018528379419798

Epoch: 6| Step: 6
Training loss: 2.095740556716919
Validation loss: 2.005925058036722

Epoch: 6| Step: 7
Training loss: 2.1890506744384766
Validation loss: 2.00328081141236

Epoch: 6| Step: 8
Training loss: 1.2089849710464478
Validation loss: 2.0294034455412175

Epoch: 6| Step: 9
Training loss: 1.871921181678772
Validation loss: 1.9956875719049925

Epoch: 6| Step: 10
Training loss: 2.1031808853149414
Validation loss: 2.0104295592154227

Epoch: 6| Step: 11
Training loss: 1.4655003547668457
Validation loss: 2.0027251115409275

Epoch: 6| Step: 12
Training loss: 2.081674337387085
Validation loss: 1.9985293521676013

Epoch: 6| Step: 13
Training loss: 2.0129005908966064
Validation loss: 2.0102654926238523

Epoch: 192| Step: 0
Training loss: 1.9417455196380615
Validation loss: 1.999437544935493

Epoch: 6| Step: 1
Training loss: 1.5308074951171875
Validation loss: 2.001753250757853

Epoch: 6| Step: 2
Training loss: 1.6438276767730713
Validation loss: 2.0415059379352036

Epoch: 6| Step: 3
Training loss: 2.1315054893493652
Validation loss: 2.0245187372289677

Epoch: 6| Step: 4
Training loss: 2.044536828994751
Validation loss: 2.0192236797783965

Epoch: 6| Step: 5
Training loss: 2.172271251678467
Validation loss: 2.011430331455764

Epoch: 6| Step: 6
Training loss: 1.4508678913116455
Validation loss: 2.0035816802773425

Epoch: 6| Step: 7
Training loss: 2.4763989448547363
Validation loss: 2.0040334373392086

Epoch: 6| Step: 8
Training loss: 2.211155891418457
Validation loss: 1.9872614593916043

Epoch: 6| Step: 9
Training loss: 2.5912511348724365
Validation loss: 2.0128329569293606

Epoch: 6| Step: 10
Training loss: 1.864466905593872
Validation loss: 2.0050686303005425

Epoch: 6| Step: 11
Training loss: 2.190154790878296
Validation loss: 2.0438827865867206

Epoch: 6| Step: 12
Training loss: 1.3545258045196533
Validation loss: 2.0123559133980864

Epoch: 6| Step: 13
Training loss: 1.9663854837417603
Validation loss: 2.032900784605293

Epoch: 193| Step: 0
Training loss: 1.873811960220337
Validation loss: 2.030227618832742

Epoch: 6| Step: 1
Training loss: 2.0687668323516846
Validation loss: 2.026965278451161

Epoch: 6| Step: 2
Training loss: 2.1615335941314697
Validation loss: 2.0352308545061337

Epoch: 6| Step: 3
Training loss: 2.1090242862701416
Validation loss: 2.0315130244019213

Epoch: 6| Step: 4
Training loss: 1.7683031558990479
Validation loss: 2.0167790612866803

Epoch: 6| Step: 5
Training loss: 2.143312692642212
Validation loss: 2.0456175881047405

Epoch: 6| Step: 6
Training loss: 1.8644338846206665
Validation loss: 2.018578355030347

Epoch: 6| Step: 7
Training loss: 2.1551318168640137
Validation loss: 2.0167980963183987

Epoch: 6| Step: 8
Training loss: 1.539515495300293
Validation loss: 2.044250617745102

Epoch: 6| Step: 9
Training loss: 2.651732921600342
Validation loss: 2.0288375577619

Epoch: 6| Step: 10
Training loss: 1.2712211608886719
Validation loss: 2.0179150501887

Epoch: 6| Step: 11
Training loss: 2.1548309326171875
Validation loss: 2.022241230933897

Epoch: 6| Step: 12
Training loss: 1.489878535270691
Validation loss: 2.0523890397881948

Epoch: 6| Step: 13
Training loss: 2.229376792907715
Validation loss: 2.0351713344614994

Epoch: 194| Step: 0
Training loss: 2.395075798034668
Validation loss: 2.0232429555667344

Epoch: 6| Step: 1
Training loss: 2.247882843017578
Validation loss: 2.025113101928465

Epoch: 6| Step: 2
Training loss: 1.8593440055847168
Validation loss: 2.0262058396493234

Epoch: 6| Step: 3
Training loss: 1.5603210926055908
Validation loss: 2.0363391599347516

Epoch: 6| Step: 4
Training loss: 1.7713623046875
Validation loss: 2.0363465188651957

Epoch: 6| Step: 5
Training loss: 1.9961813688278198
Validation loss: 2.046341888366207

Epoch: 6| Step: 6
Training loss: 2.259068250656128
Validation loss: 2.019350274916618

Epoch: 6| Step: 7
Training loss: 2.3622381687164307
Validation loss: 2.0250734462532947

Epoch: 6| Step: 8
Training loss: 1.943617582321167
Validation loss: 2.0325007066931775

Epoch: 6| Step: 9
Training loss: 2.1399974822998047
Validation loss: 2.0385145089959584

Epoch: 6| Step: 10
Training loss: 1.6081191301345825
Validation loss: 2.0347777579420354

Epoch: 6| Step: 11
Training loss: 1.3733264207839966
Validation loss: 2.01323958622512

Epoch: 6| Step: 12
Training loss: 1.886570692062378
Validation loss: 2.0076641780073925

Epoch: 6| Step: 13
Training loss: 2.2781012058258057
Validation loss: 2.037668867777753

Epoch: 195| Step: 0
Training loss: 1.765676736831665
Validation loss: 2.023513740108859

Epoch: 6| Step: 1
Training loss: 2.158102035522461
Validation loss: 2.0175387410707373

Epoch: 6| Step: 2
Training loss: 2.3052725791931152
Validation loss: 2.0234079207143476

Epoch: 6| Step: 3
Training loss: 1.710532307624817
Validation loss: 2.025503553369994

Epoch: 6| Step: 4
Training loss: 2.0498828887939453
Validation loss: 2.024082212037938

Epoch: 6| Step: 5
Training loss: 1.8972173929214478
Validation loss: 2.0305538651763753

Epoch: 6| Step: 6
Training loss: 1.5172035694122314
Validation loss: 2.0116934596851306

Epoch: 6| Step: 7
Training loss: 1.2336146831512451
Validation loss: 2.020655634582684

Epoch: 6| Step: 8
Training loss: 2.5694069862365723
Validation loss: 2.043893062940208

Epoch: 6| Step: 9
Training loss: 2.291372537612915
Validation loss: 2.0074978836121096

Epoch: 6| Step: 10
Training loss: 2.645638942718506
Validation loss: 2.004849390317035

Epoch: 6| Step: 11
Training loss: 2.13372540473938
Validation loss: 2.010736926909416

Epoch: 6| Step: 12
Training loss: 1.2624565362930298
Validation loss: 2.0106613072015906

Epoch: 6| Step: 13
Training loss: 2.2562453746795654
Validation loss: 1.9818476464158745

Epoch: 196| Step: 0
Training loss: 1.8458815813064575
Validation loss: 2.0013589807735976

Epoch: 6| Step: 1
Training loss: 2.113495349884033
Validation loss: 1.9972748653863066

Epoch: 6| Step: 2
Training loss: 1.412133812904358
Validation loss: 2.011412689762731

Epoch: 6| Step: 3
Training loss: 2.4442195892333984
Validation loss: 2.005350847398081

Epoch: 6| Step: 4
Training loss: 2.0882534980773926
Validation loss: 2.049439143109065

Epoch: 6| Step: 5
Training loss: 1.8414098024368286
Validation loss: 2.027369938870912

Epoch: 6| Step: 6
Training loss: 2.7931056022644043
Validation loss: 2.0495158805642077

Epoch: 6| Step: 7
Training loss: 1.758220911026001
Validation loss: 2.020232913314655

Epoch: 6| Step: 8
Training loss: 2.5237631797790527
Validation loss: 2.0123345582715926

Epoch: 6| Step: 9
Training loss: 1.5733411312103271
Validation loss: 2.0384954919097242

Epoch: 6| Step: 10
Training loss: 1.7297662496566772
Validation loss: 2.000516208269263

Epoch: 6| Step: 11
Training loss: 1.771967887878418
Validation loss: 2.034220089194595

Epoch: 6| Step: 12
Training loss: 1.628725290298462
Validation loss: 2.0290906275472333

Epoch: 6| Step: 13
Training loss: 1.870963215827942
Validation loss: 2.0232258445473126

Epoch: 197| Step: 0
Training loss: 1.958683729171753
Validation loss: 2.0445106542238625

Epoch: 6| Step: 1
Training loss: 2.163079261779785
Validation loss: 2.039804639354829

Epoch: 6| Step: 2
Training loss: 2.0303521156311035
Validation loss: 1.9914701548955773

Epoch: 6| Step: 3
Training loss: 1.7606589794158936
Validation loss: 2.037992605599024

Epoch: 6| Step: 4
Training loss: 2.0892176628112793
Validation loss: 1.9935140250831522

Epoch: 6| Step: 5
Training loss: 1.4476983547210693
Validation loss: 2.0149601813285583

Epoch: 6| Step: 6
Training loss: 2.0715887546539307
Validation loss: 2.0215168793996177

Epoch: 6| Step: 7
Training loss: 2.3936383724212646
Validation loss: 2.0105886613169024

Epoch: 6| Step: 8
Training loss: 1.8299332857131958
Validation loss: 2.0273641514521774

Epoch: 6| Step: 9
Training loss: 1.9432427883148193
Validation loss: 1.9974652721035866

Epoch: 6| Step: 10
Training loss: 1.7007734775543213
Validation loss: 2.0488722542280793

Epoch: 6| Step: 11
Training loss: 1.5602226257324219
Validation loss: 2.0306100460790817

Epoch: 6| Step: 12
Training loss: 2.0760037899017334
Validation loss: 2.0253012641783683

Epoch: 6| Step: 13
Training loss: 2.5465962886810303
Validation loss: 2.0255809112261702

Epoch: 198| Step: 0
Training loss: 2.3551294803619385
Validation loss: 2.023057194166286

Epoch: 6| Step: 1
Training loss: 2.0139224529266357
Validation loss: 2.0335078547077794

Epoch: 6| Step: 2
Training loss: 1.7262654304504395
Validation loss: 2.024141019390475

Epoch: 6| Step: 3
Training loss: 1.7864246368408203
Validation loss: 2.0129459263176046

Epoch: 6| Step: 4
Training loss: 1.7612404823303223
Validation loss: 2.0154040410954464

Epoch: 6| Step: 5
Training loss: 1.7589768171310425
Validation loss: 2.033523316024452

Epoch: 6| Step: 6
Training loss: 1.648127555847168
Validation loss: 2.042908796700098

Epoch: 6| Step: 7
Training loss: 1.8985508680343628
Validation loss: 2.0535826926590293

Epoch: 6| Step: 8
Training loss: 1.5295913219451904
Validation loss: 2.0410764358376943

Epoch: 6| Step: 9
Training loss: 2.335747241973877
Validation loss: 2.049939836225202

Epoch: 6| Step: 10
Training loss: 1.9574919939041138
Validation loss: 2.0446409820228495

Epoch: 6| Step: 11
Training loss: 2.0465238094329834
Validation loss: 2.045452910084878

Epoch: 6| Step: 12
Training loss: 2.4793801307678223
Validation loss: 2.034606469574795

Epoch: 6| Step: 13
Training loss: 2.111238479614258
Validation loss: 2.034472551397098

Epoch: 199| Step: 0
Training loss: 1.7500081062316895
Validation loss: 2.0393208995942147

Epoch: 6| Step: 1
Training loss: 1.7953388690948486
Validation loss: 2.030701119412658

Epoch: 6| Step: 2
Training loss: 1.8855663537979126
Validation loss: 2.0152472014068277

Epoch: 6| Step: 3
Training loss: 1.6691664457321167
Validation loss: 2.0482474527051373

Epoch: 6| Step: 4
Training loss: 1.6729834079742432
Validation loss: 2.0540491816818074

Epoch: 6| Step: 5
Training loss: 1.3307669162750244
Validation loss: 2.0233508643283638

Epoch: 6| Step: 6
Training loss: 2.2901344299316406
Validation loss: 2.0089380023300007

Epoch: 6| Step: 7
Training loss: 1.932420015335083
Validation loss: 2.001901365095569

Epoch: 6| Step: 8
Training loss: 2.7948272228240967
Validation loss: 1.9817780474180817

Epoch: 6| Step: 9
Training loss: 2.378519058227539
Validation loss: 1.998214260224373

Epoch: 6| Step: 10
Training loss: 2.0669479370117188
Validation loss: 2.014735725618178

Epoch: 6| Step: 11
Training loss: 2.336500644683838
Validation loss: 1.9906687480147167

Epoch: 6| Step: 12
Training loss: 1.5039331912994385
Validation loss: 1.9897143033242994

Epoch: 6| Step: 13
Training loss: 2.377638816833496
Validation loss: 2.0205749568118843

Epoch: 200| Step: 0
Training loss: 1.9955554008483887
Validation loss: 2.0155658593741794

Epoch: 6| Step: 1
Training loss: 1.8682454824447632
Validation loss: 1.9829642029218777

Epoch: 6| Step: 2
Training loss: 2.614321231842041
Validation loss: 1.999622380861672

Epoch: 6| Step: 3
Training loss: 2.1499571800231934
Validation loss: 2.039628927425672

Epoch: 6| Step: 4
Training loss: 1.7005877494812012
Validation loss: 2.0062678449897358

Epoch: 6| Step: 5
Training loss: 1.5878667831420898
Validation loss: 2.0481807301121373

Epoch: 6| Step: 6
Training loss: 1.4606462717056274
Validation loss: 2.024903779388756

Epoch: 6| Step: 7
Training loss: 2.259573459625244
Validation loss: 2.0100161567811043

Epoch: 6| Step: 8
Training loss: 1.9679702520370483
Validation loss: 2.0122186753057663

Epoch: 6| Step: 9
Training loss: 1.413973331451416
Validation loss: 2.031457503636678

Epoch: 6| Step: 10
Training loss: 2.042527437210083
Validation loss: 2.027805147632476

Epoch: 6| Step: 11
Training loss: 2.383448600769043
Validation loss: 2.0150927343676166

Epoch: 6| Step: 12
Training loss: 2.0111706256866455
Validation loss: 1.9866481878424203

Epoch: 6| Step: 13
Training loss: 1.6053106784820557
Validation loss: 2.0291768427818053

Epoch: 201| Step: 0
Training loss: 2.148483991622925
Validation loss: 2.0370600492723527

Epoch: 6| Step: 1
Training loss: 2.279841899871826
Validation loss: 2.0408658955686834

Epoch: 6| Step: 2
Training loss: 2.069355010986328
Validation loss: 2.031361737558919

Epoch: 6| Step: 3
Training loss: 2.375575542449951
Validation loss: 2.0354296238191667

Epoch: 6| Step: 4
Training loss: 1.2217832803726196
Validation loss: 2.032270992955854

Epoch: 6| Step: 5
Training loss: 2.028118133544922
Validation loss: 2.0314052797132924

Epoch: 6| Step: 6
Training loss: 1.819374442100525
Validation loss: 2.046877463658651

Epoch: 6| Step: 7
Training loss: 1.2627589702606201
Validation loss: 2.0705982497943345

Epoch: 6| Step: 8
Training loss: 2.3079867362976074
Validation loss: 2.094713305914274

Epoch: 6| Step: 9
Training loss: 2.0757803916931152
Validation loss: 2.060000782371849

Epoch: 6| Step: 10
Training loss: 2.305884599685669
Validation loss: 2.0475053146321285

Epoch: 6| Step: 11
Training loss: 2.2854323387145996
Validation loss: 2.0804036304514897

Epoch: 6| Step: 12
Training loss: 1.78533935546875
Validation loss: 2.0479709204807075

Epoch: 6| Step: 13
Training loss: 1.0207655429840088
Validation loss: 2.0950972931359404

Epoch: 202| Step: 0
Training loss: 2.5675606727600098
Validation loss: 2.0444616925331855

Epoch: 6| Step: 1
Training loss: 1.5758514404296875
Validation loss: 2.045396286954162

Epoch: 6| Step: 2
Training loss: 1.7238364219665527
Validation loss: 2.0541412266351844

Epoch: 6| Step: 3
Training loss: 1.7753992080688477
Validation loss: 2.0241797495913763

Epoch: 6| Step: 4
Training loss: 2.5683846473693848
Validation loss: 2.015544578593264

Epoch: 6| Step: 5
Training loss: 1.7975366115570068
Validation loss: 2.0580940182491014

Epoch: 6| Step: 6
Training loss: 1.9264652729034424
Validation loss: 2.0392390886942544

Epoch: 6| Step: 7
Training loss: 2.0608136653900146
Validation loss: 2.025329356552452

Epoch: 6| Step: 8
Training loss: 2.0610532760620117
Validation loss: 2.0329676520439888

Epoch: 6| Step: 9
Training loss: 1.7007259130477905
Validation loss: 2.017121619434767

Epoch: 6| Step: 10
Training loss: 2.1154866218566895
Validation loss: 2.0452547996274886

Epoch: 6| Step: 11
Training loss: 1.9656624794006348
Validation loss: 2.030957737276631

Epoch: 6| Step: 12
Training loss: 1.9751849174499512
Validation loss: 2.0214272711866643

Epoch: 6| Step: 13
Training loss: 0.99104905128479
Validation loss: 2.0059929355498283

Epoch: 203| Step: 0
Training loss: 1.7403982877731323
Validation loss: 2.0103107677992953

Epoch: 6| Step: 1
Training loss: 1.9300429821014404
Validation loss: 2.0315976104428692

Epoch: 6| Step: 2
Training loss: 1.6989760398864746
Validation loss: 2.033832009120654

Epoch: 6| Step: 3
Training loss: 1.790989637374878
Validation loss: 2.009712585838892

Epoch: 6| Step: 4
Training loss: 1.8052226305007935
Validation loss: 2.0402825083783878

Epoch: 6| Step: 5
Training loss: 1.6232655048370361
Validation loss: 2.012965920150921

Epoch: 6| Step: 6
Training loss: 2.373845100402832
Validation loss: 2.044673206985638

Epoch: 6| Step: 7
Training loss: 1.2992043495178223
Validation loss: 2.0321165848803777

Epoch: 6| Step: 8
Training loss: 1.8825515508651733
Validation loss: 2.03772226713037

Epoch: 6| Step: 9
Training loss: 2.470808506011963
Validation loss: 2.0175090989758893

Epoch: 6| Step: 10
Training loss: 2.743091106414795
Validation loss: 2.0322775763850056

Epoch: 6| Step: 11
Training loss: 1.952902913093567
Validation loss: 2.029057966765537

Epoch: 6| Step: 12
Training loss: 1.6636803150177002
Validation loss: 2.0616459179950017

Epoch: 6| Step: 13
Training loss: 2.563544273376465
Validation loss: 2.0272179854813444

Epoch: 204| Step: 0
Training loss: 1.8965470790863037
Validation loss: 2.0543016067115207

Epoch: 6| Step: 1
Training loss: 1.4817242622375488
Validation loss: 2.049212953095795

Epoch: 6| Step: 2
Training loss: 1.9507315158843994
Validation loss: 2.067614370776761

Epoch: 6| Step: 3
Training loss: 2.1851251125335693
Validation loss: 2.020844018587502

Epoch: 6| Step: 4
Training loss: 2.313729763031006
Validation loss: 2.0070217347914174

Epoch: 6| Step: 5
Training loss: 2.0507822036743164
Validation loss: 2.0284551728156304

Epoch: 6| Step: 6
Training loss: 2.124114513397217
Validation loss: 2.050410875710108

Epoch: 6| Step: 7
Training loss: 1.9034593105316162
Validation loss: 2.0238546068950365

Epoch: 6| Step: 8
Training loss: 1.7396010160446167
Validation loss: 2.033945598909932

Epoch: 6| Step: 9
Training loss: 2.6757712364196777
Validation loss: 2.03379883304719

Epoch: 6| Step: 10
Training loss: 1.6485005617141724
Validation loss: 2.022367315907632

Epoch: 6| Step: 11
Training loss: 1.6414120197296143
Validation loss: 2.038881194206976

Epoch: 6| Step: 12
Training loss: 1.769841194152832
Validation loss: 2.021787074304396

Epoch: 6| Step: 13
Training loss: 1.998647689819336
Validation loss: 2.015383869089106

Epoch: 205| Step: 0
Training loss: 1.3446505069732666
Validation loss: 2.0359914815554054

Epoch: 6| Step: 1
Training loss: 2.332310199737549
Validation loss: 2.0309121352370068

Epoch: 6| Step: 2
Training loss: 2.096074104309082
Validation loss: 2.050012855119603

Epoch: 6| Step: 3
Training loss: 1.662669062614441
Validation loss: 2.036586243619201

Epoch: 6| Step: 4
Training loss: 1.9243505001068115
Validation loss: 2.0329996373063777

Epoch: 6| Step: 5
Training loss: 2.0275766849517822
Validation loss: 2.018887583927442

Epoch: 6| Step: 6
Training loss: 2.0349998474121094
Validation loss: 2.0194992608921503

Epoch: 6| Step: 7
Training loss: 2.2571215629577637
Validation loss: 2.0250118163324173

Epoch: 6| Step: 8
Training loss: 1.7166897058486938
Validation loss: 2.0120393101887037

Epoch: 6| Step: 9
Training loss: 1.545155644416809
Validation loss: 2.0381054429597754

Epoch: 6| Step: 10
Training loss: 1.7795747518539429
Validation loss: 2.028374033589517

Epoch: 6| Step: 11
Training loss: 1.9159108400344849
Validation loss: 2.0122267559010494

Epoch: 6| Step: 12
Training loss: 2.4114151000976562
Validation loss: 2.025318971244238

Epoch: 6| Step: 13
Training loss: 2.307894468307495
Validation loss: 2.0029100474490913

Epoch: 206| Step: 0
Training loss: 1.9886891841888428
Validation loss: 2.03054105594594

Epoch: 6| Step: 1
Training loss: 2.473236083984375
Validation loss: 2.03151031719741

Epoch: 6| Step: 2
Training loss: 2.2702126502990723
Validation loss: 2.0511968123015536

Epoch: 6| Step: 3
Training loss: 1.2009440660476685
Validation loss: 2.0180905929175754

Epoch: 6| Step: 4
Training loss: 2.5055904388427734
Validation loss: 2.019576918694281

Epoch: 6| Step: 5
Training loss: 1.7337491512298584
Validation loss: 2.037952176986202

Epoch: 6| Step: 6
Training loss: 1.9381201267242432
Validation loss: 2.0370995306199595

Epoch: 6| Step: 7
Training loss: 2.0072622299194336
Validation loss: 2.06815432476741

Epoch: 6| Step: 8
Training loss: 1.4241198301315308
Validation loss: 2.032840515977593

Epoch: 6| Step: 9
Training loss: 1.9757312536239624
Validation loss: 2.013635322611819

Epoch: 6| Step: 10
Training loss: 2.044522285461426
Validation loss: 2.027546774956488

Epoch: 6| Step: 11
Training loss: 1.8190031051635742
Validation loss: 2.031999534176242

Epoch: 6| Step: 12
Training loss: 1.8482983112335205
Validation loss: 2.071109608937335

Epoch: 6| Step: 13
Training loss: 1.7802884578704834
Validation loss: 2.0421734548384145

Epoch: 207| Step: 0
Training loss: 1.7689735889434814
Validation loss: 2.075102709954785

Epoch: 6| Step: 1
Training loss: 1.8556835651397705
Validation loss: 2.0527069132815123

Epoch: 6| Step: 2
Training loss: 1.76301908493042
Validation loss: 2.0235654102858676

Epoch: 6| Step: 3
Training loss: 1.5346083641052246
Validation loss: 2.0418575412483624

Epoch: 6| Step: 4
Training loss: 1.9409469366073608
Validation loss: 2.0683914179443033

Epoch: 6| Step: 5
Training loss: 2.3038973808288574
Validation loss: 2.0278519609923005

Epoch: 6| Step: 6
Training loss: 1.6145316362380981
Validation loss: 2.0306208261879544

Epoch: 6| Step: 7
Training loss: 2.09576678276062
Validation loss: 2.0479718151912896

Epoch: 6| Step: 8
Training loss: 2.1960792541503906
Validation loss: 2.0577725095133625

Epoch: 6| Step: 9
Training loss: 2.004786491394043
Validation loss: 2.0433945937823226

Epoch: 6| Step: 10
Training loss: 2.1646382808685303
Validation loss: 2.013954649689377

Epoch: 6| Step: 11
Training loss: 1.4462981224060059
Validation loss: 2.0378215274503155

Epoch: 6| Step: 12
Training loss: 1.9953327178955078
Validation loss: 2.01589532308681

Epoch: 6| Step: 13
Training loss: 2.479151487350464
Validation loss: 2.0142830635911677

Epoch: 208| Step: 0
Training loss: 2.8675503730773926
Validation loss: 1.9980621132799374

Epoch: 6| Step: 1
Training loss: 1.889338731765747
Validation loss: 2.0095250491173036

Epoch: 6| Step: 2
Training loss: 1.6601066589355469
Validation loss: 2.000506724080732

Epoch: 6| Step: 3
Training loss: 1.798947811126709
Validation loss: 1.9981714115347913

Epoch: 6| Step: 4
Training loss: 1.418576955795288
Validation loss: 2.0208428828947005

Epoch: 6| Step: 5
Training loss: 2.1972737312316895
Validation loss: 2.030370702025711

Epoch: 6| Step: 6
Training loss: 1.8862156867980957
Validation loss: 2.05060867340334

Epoch: 6| Step: 7
Training loss: 2.247757911682129
Validation loss: 2.015760285879976

Epoch: 6| Step: 8
Training loss: 2.076925039291382
Validation loss: 2.0589921064274286

Epoch: 6| Step: 9
Training loss: 1.7983206510543823
Validation loss: 2.0240994986667427

Epoch: 6| Step: 10
Training loss: 1.743152379989624
Validation loss: 2.026003550457698

Epoch: 6| Step: 11
Training loss: 2.015676975250244
Validation loss: 2.0346543481273036

Epoch: 6| Step: 12
Training loss: 1.6584243774414062
Validation loss: 2.0376768471092306

Epoch: 6| Step: 13
Training loss: 1.8639708757400513
Validation loss: 2.0457863012949624

Epoch: 209| Step: 0
Training loss: 1.9465562105178833
Validation loss: 2.012811340311522

Epoch: 6| Step: 1
Training loss: 2.417046546936035
Validation loss: 2.0395242257784774

Epoch: 6| Step: 2
Training loss: 1.7256217002868652
Validation loss: 2.025791350231376

Epoch: 6| Step: 3
Training loss: 1.8932918310165405
Validation loss: 2.0407609324301443

Epoch: 6| Step: 4
Training loss: 2.4709856510162354
Validation loss: 2.006544892505933

Epoch: 6| Step: 5
Training loss: 1.5954523086547852
Validation loss: 2.0035683596006004

Epoch: 6| Step: 6
Training loss: 1.917978048324585
Validation loss: 2.008507467085315

Epoch: 6| Step: 7
Training loss: 2.1265082359313965
Validation loss: 2.035657416107834

Epoch: 6| Step: 8
Training loss: 1.5262982845306396
Validation loss: 2.0434706928909465

Epoch: 6| Step: 9
Training loss: 2.059943675994873
Validation loss: 2.051695018686274

Epoch: 6| Step: 10
Training loss: 1.6486679315567017
Validation loss: 2.0188282010375813

Epoch: 6| Step: 11
Training loss: 1.8565514087677002
Validation loss: 2.0179218476818455

Epoch: 6| Step: 12
Training loss: 2.2890844345092773
Validation loss: 2.0314281140604327

Epoch: 6| Step: 13
Training loss: 1.8491899967193604
Validation loss: 2.042422245907527

Epoch: 210| Step: 0
Training loss: 1.6498146057128906
Validation loss: 2.05051363155406

Epoch: 6| Step: 1
Training loss: 1.402290940284729
Validation loss: 2.0360070274722193

Epoch: 6| Step: 2
Training loss: 1.9524874687194824
Validation loss: 2.0401940332945956

Epoch: 6| Step: 3
Training loss: 2.011897087097168
Validation loss: 2.0184947970092937

Epoch: 6| Step: 4
Training loss: 2.3765499591827393
Validation loss: 2.023566366523825

Epoch: 6| Step: 5
Training loss: 1.611215591430664
Validation loss: 2.050857263226663

Epoch: 6| Step: 6
Training loss: 1.068006992340088
Validation loss: 2.021039088567098

Epoch: 6| Step: 7
Training loss: 2.037961959838867
Validation loss: 2.011345091686454

Epoch: 6| Step: 8
Training loss: 2.38417911529541
Validation loss: 2.006341129220942

Epoch: 6| Step: 9
Training loss: 2.195401191711426
Validation loss: 2.034403024181243

Epoch: 6| Step: 10
Training loss: 2.422027826309204
Validation loss: 2.036427164590487

Epoch: 6| Step: 11
Training loss: 1.9848179817199707
Validation loss: 2.00285848750863

Epoch: 6| Step: 12
Training loss: 2.1331470012664795
Validation loss: 2.0396141749556347

Epoch: 6| Step: 13
Training loss: 1.7124958038330078
Validation loss: 2.0277857549728884

Epoch: 211| Step: 0
Training loss: 2.117006540298462
Validation loss: 2.052130486375542

Epoch: 6| Step: 1
Training loss: 1.5325706005096436
Validation loss: 2.0293836106536207

Epoch: 6| Step: 2
Training loss: 1.4752042293548584
Validation loss: 2.0367646191709783

Epoch: 6| Step: 3
Training loss: 2.495394468307495
Validation loss: 2.037129722615724

Epoch: 6| Step: 4
Training loss: 1.6918590068817139
Validation loss: 2.0292375728648198

Epoch: 6| Step: 5
Training loss: 1.5189714431762695
Validation loss: 2.0346579218423493

Epoch: 6| Step: 6
Training loss: 2.6995694637298584
Validation loss: 2.072076939767407

Epoch: 6| Step: 7
Training loss: 1.6349375247955322
Validation loss: 2.03819542033698

Epoch: 6| Step: 8
Training loss: 1.7941163778305054
Validation loss: 2.070605161369488

Epoch: 6| Step: 9
Training loss: 1.8084943294525146
Validation loss: 2.0497479977146273

Epoch: 6| Step: 10
Training loss: 1.9324227571487427
Validation loss: 2.051914647061338

Epoch: 6| Step: 11
Training loss: 2.3722028732299805
Validation loss: 2.064251176772579

Epoch: 6| Step: 12
Training loss: 2.0203139781951904
Validation loss: 2.0443920499535015

Epoch: 6| Step: 13
Training loss: 2.3347156047821045
Validation loss: 2.071907049866133

Epoch: 212| Step: 0
Training loss: 1.4783028364181519
Validation loss: 2.0608803867011942

Epoch: 6| Step: 1
Training loss: 2.6031875610351562
Validation loss: 2.0488533512238534

Epoch: 6| Step: 2
Training loss: 1.9290063381195068
Validation loss: 2.0500432752793833

Epoch: 6| Step: 3
Training loss: 1.4723503589630127
Validation loss: 2.0477053952473465

Epoch: 6| Step: 4
Training loss: 2.0967116355895996
Validation loss: 2.0387639153388237

Epoch: 6| Step: 5
Training loss: 1.950251817703247
Validation loss: 2.0458457880122687

Epoch: 6| Step: 6
Training loss: 2.4113800525665283
Validation loss: 2.047858089529058

Epoch: 6| Step: 7
Training loss: 1.378281593322754
Validation loss: 2.039385537947378

Epoch: 6| Step: 8
Training loss: 1.745247721672058
Validation loss: 2.0226931828324513

Epoch: 6| Step: 9
Training loss: 2.3634655475616455
Validation loss: 2.044945160547892

Epoch: 6| Step: 10
Training loss: 2.227794647216797
Validation loss: 2.04364755974021

Epoch: 6| Step: 11
Training loss: 1.7815006971359253
Validation loss: 2.048276412871576

Epoch: 6| Step: 12
Training loss: 1.7969474792480469
Validation loss: 2.0539900384923464

Epoch: 6| Step: 13
Training loss: 1.570743203163147
Validation loss: 2.0521837819007134

Epoch: 213| Step: 0
Training loss: 1.9544341564178467
Validation loss: 2.0111362113747546

Epoch: 6| Step: 1
Training loss: 2.080751419067383
Validation loss: 2.0425431061816472

Epoch: 6| Step: 2
Training loss: 1.9808850288391113
Validation loss: 2.0225373109181723

Epoch: 6| Step: 3
Training loss: 1.9159870147705078
Validation loss: 2.047221709323186

Epoch: 6| Step: 4
Training loss: 2.051579475402832
Validation loss: 2.0035839465356644

Epoch: 6| Step: 5
Training loss: 2.13368558883667
Validation loss: 2.018939998842055

Epoch: 6| Step: 6
Training loss: 2.0973732471466064
Validation loss: 2.019831484363925

Epoch: 6| Step: 7
Training loss: 2.1166458129882812
Validation loss: 1.971103714358422

Epoch: 6| Step: 8
Training loss: 1.5642266273498535
Validation loss: 2.0184217960603776

Epoch: 6| Step: 9
Training loss: 1.4518016576766968
Validation loss: 2.0217525933378484

Epoch: 6| Step: 10
Training loss: 1.9643810987472534
Validation loss: 2.0047669564524004

Epoch: 6| Step: 11
Training loss: 1.9133527278900146
Validation loss: 2.034507279754967

Epoch: 6| Step: 12
Training loss: 2.2565815448760986
Validation loss: 2.0524121343448596

Epoch: 6| Step: 13
Training loss: 1.4775595664978027
Validation loss: 2.029906416452059

Epoch: 214| Step: 0
Training loss: 1.7372279167175293
Validation loss: 2.057349302435434

Epoch: 6| Step: 1
Training loss: 1.6778607368469238
Validation loss: 2.0235003373956166

Epoch: 6| Step: 2
Training loss: 1.697577714920044
Validation loss: 2.0167859369708645

Epoch: 6| Step: 3
Training loss: 1.8335394859313965
Validation loss: 2.0221428255881033

Epoch: 6| Step: 4
Training loss: 2.736194133758545
Validation loss: 1.9942954586398216

Epoch: 6| Step: 5
Training loss: 1.778160810470581
Validation loss: 1.9852941561770696

Epoch: 6| Step: 6
Training loss: 2.2018589973449707
Validation loss: 2.0040360317435315

Epoch: 6| Step: 7
Training loss: 1.442352056503296
Validation loss: 2.029943889187228

Epoch: 6| Step: 8
Training loss: 2.120577573776245
Validation loss: 2.029730177694751

Epoch: 6| Step: 9
Training loss: 1.6070702075958252
Validation loss: 2.0258756196627052

Epoch: 6| Step: 10
Training loss: 2.0603742599487305
Validation loss: 2.009621840651317

Epoch: 6| Step: 11
Training loss: 1.7905757427215576
Validation loss: 2.0419552454384426

Epoch: 6| Step: 12
Training loss: 2.1837711334228516
Validation loss: 2.0486168271751812

Epoch: 6| Step: 13
Training loss: 2.0223755836486816
Validation loss: 2.0628163737635457

Epoch: 215| Step: 0
Training loss: 1.8419485092163086
Validation loss: 2.064798939612604

Epoch: 6| Step: 1
Training loss: 1.4125607013702393
Validation loss: 2.062583887448875

Epoch: 6| Step: 2
Training loss: 2.345578193664551
Validation loss: 2.0395594232825824

Epoch: 6| Step: 3
Training loss: 1.914766788482666
Validation loss: 2.06294148583566

Epoch: 6| Step: 4
Training loss: 2.3989577293395996
Validation loss: 2.0244596978669525

Epoch: 6| Step: 5
Training loss: 2.345182418823242
Validation loss: 2.0501396656036377

Epoch: 6| Step: 6
Training loss: 1.2273212671279907
Validation loss: 2.068664453362906

Epoch: 6| Step: 7
Training loss: 1.1955878734588623
Validation loss: 2.0564229488372803

Epoch: 6| Step: 8
Training loss: 2.2807531356811523
Validation loss: 2.06501801295947

Epoch: 6| Step: 9
Training loss: 1.8014070987701416
Validation loss: 2.0131277884206464

Epoch: 6| Step: 10
Training loss: 1.9342149496078491
Validation loss: 2.021781898313953

Epoch: 6| Step: 11
Training loss: 1.6163707971572876
Validation loss: 2.025644184440695

Epoch: 6| Step: 12
Training loss: 2.339315891265869
Validation loss: 2.0246220147737892

Epoch: 6| Step: 13
Training loss: 2.555994987487793
Validation loss: 2.062035617008004

Epoch: 216| Step: 0
Training loss: 1.7567683458328247
Validation loss: 2.008075466720007

Epoch: 6| Step: 1
Training loss: 1.844183325767517
Validation loss: 2.04529821231801

Epoch: 6| Step: 2
Training loss: 1.648054599761963
Validation loss: 2.023717370084537

Epoch: 6| Step: 3
Training loss: 2.2715916633605957
Validation loss: 2.0438188506710913

Epoch: 6| Step: 4
Training loss: 2.3367528915405273
Validation loss: 2.0508907430915424

Epoch: 6| Step: 5
Training loss: 1.7097673416137695
Validation loss: 2.0608618477339387

Epoch: 6| Step: 6
Training loss: 1.5771348476409912
Validation loss: 2.0658049711617092

Epoch: 6| Step: 7
Training loss: 1.7389934062957764
Validation loss: 2.071364979590139

Epoch: 6| Step: 8
Training loss: 2.1238760948181152
Validation loss: 2.018793564970775

Epoch: 6| Step: 9
Training loss: 1.9462001323699951
Validation loss: 2.0323956115271455

Epoch: 6| Step: 10
Training loss: 2.001061201095581
Validation loss: 2.0241892440344698

Epoch: 6| Step: 11
Training loss: 2.302778959274292
Validation loss: 2.0450994647959226

Epoch: 6| Step: 12
Training loss: 1.6525129079818726
Validation loss: 2.0115188116668374

Epoch: 6| Step: 13
Training loss: 2.0842409133911133
Validation loss: 2.046689882073351

Epoch: 217| Step: 0
Training loss: 2.0233516693115234
Validation loss: 2.0515961313760407

Epoch: 6| Step: 1
Training loss: 1.9861655235290527
Validation loss: 2.0487722683978338

Epoch: 6| Step: 2
Training loss: 1.6266744136810303
Validation loss: 2.0254624864106536

Epoch: 6| Step: 3
Training loss: 2.6073226928710938
Validation loss: 2.0234207696812128

Epoch: 6| Step: 4
Training loss: 2.058303117752075
Validation loss: 2.029292409138013

Epoch: 6| Step: 5
Training loss: 2.102503776550293
Validation loss: 2.016431434180147

Epoch: 6| Step: 6
Training loss: 1.3922927379608154
Validation loss: 2.04106250116902

Epoch: 6| Step: 7
Training loss: 1.219516634941101
Validation loss: 2.0005028888743412

Epoch: 6| Step: 8
Training loss: 1.276970624923706
Validation loss: 2.0302367338570217

Epoch: 6| Step: 9
Training loss: 1.4848040342330933
Validation loss: 2.0315334784087313

Epoch: 6| Step: 10
Training loss: 2.4506964683532715
Validation loss: 2.038361298140659

Epoch: 6| Step: 11
Training loss: 1.9723819494247437
Validation loss: 2.015810861382433

Epoch: 6| Step: 12
Training loss: 2.0472939014434814
Validation loss: 2.0196823355972127

Epoch: 6| Step: 13
Training loss: 2.798956871032715
Validation loss: 2.0242489012338782

Epoch: 218| Step: 0
Training loss: 1.667121171951294
Validation loss: 2.0478357230463335

Epoch: 6| Step: 1
Training loss: 2.0127782821655273
Validation loss: 2.067518216307445

Epoch: 6| Step: 2
Training loss: 2.1371569633483887
Validation loss: 2.05558358212953

Epoch: 6| Step: 3
Training loss: 1.4715149402618408
Validation loss: 2.038320308090538

Epoch: 6| Step: 4
Training loss: 1.934193730354309
Validation loss: 2.0571900080609065

Epoch: 6| Step: 5
Training loss: 2.556225061416626
Validation loss: 2.0749322983526413

Epoch: 6| Step: 6
Training loss: 2.1325936317443848
Validation loss: 2.094146878488602

Epoch: 6| Step: 7
Training loss: 1.3961466550827026
Validation loss: 2.084589368553572

Epoch: 6| Step: 8
Training loss: 2.444530963897705
Validation loss: 2.1011509574869627

Epoch: 6| Step: 9
Training loss: 2.647556781768799
Validation loss: 2.0826302946254773

Epoch: 6| Step: 10
Training loss: 1.4728233814239502
Validation loss: 2.0861565618104834

Epoch: 6| Step: 11
Training loss: 1.4181348085403442
Validation loss: 2.091566688270979

Epoch: 6| Step: 12
Training loss: 1.8714625835418701
Validation loss: 2.0762684037608485

Epoch: 6| Step: 13
Training loss: 1.9229005575180054
Validation loss: 2.0627156252502115

Epoch: 219| Step: 0
Training loss: 2.0035152435302734
Validation loss: 2.080660976389403

Epoch: 6| Step: 1
Training loss: 2.369584560394287
Validation loss: 2.078601183429841

Epoch: 6| Step: 2
Training loss: 2.006481170654297
Validation loss: 2.028124104263962

Epoch: 6| Step: 3
Training loss: 1.7450109720230103
Validation loss: 2.067023451610278

Epoch: 6| Step: 4
Training loss: 1.8825432062149048
Validation loss: 2.0262647200656194

Epoch: 6| Step: 5
Training loss: 1.7074024677276611
Validation loss: 2.0367971004978305

Epoch: 6| Step: 6
Training loss: 1.6675128936767578
Validation loss: 2.017728852969344

Epoch: 6| Step: 7
Training loss: 1.8884865045547485
Validation loss: 2.040881536340201

Epoch: 6| Step: 8
Training loss: 1.847425103187561
Validation loss: 2.0198820124390306

Epoch: 6| Step: 9
Training loss: 1.3929166793823242
Validation loss: 2.0330079909293883

Epoch: 6| Step: 10
Training loss: 1.8614659309387207
Validation loss: 2.019888074167313

Epoch: 6| Step: 11
Training loss: 1.7788162231445312
Validation loss: 2.013395086411507

Epoch: 6| Step: 12
Training loss: 2.416792631149292
Validation loss: 2.0194334599279586

Epoch: 6| Step: 13
Training loss: 2.219160318374634
Validation loss: 2.017388060528745

Epoch: 220| Step: 0
Training loss: 1.6059260368347168
Validation loss: 2.0544825753858014

Epoch: 6| Step: 1
Training loss: 1.922602653503418
Validation loss: 2.027767550560736

Epoch: 6| Step: 2
Training loss: 2.377115249633789
Validation loss: 2.012884014396257

Epoch: 6| Step: 3
Training loss: 1.7583370208740234
Validation loss: 2.0287807295399327

Epoch: 6| Step: 4
Training loss: 2.212714433670044
Validation loss: 2.0192630329439716

Epoch: 6| Step: 5
Training loss: 1.8073797225952148
Validation loss: 2.042404285041235

Epoch: 6| Step: 6
Training loss: 2.3684706687927246
Validation loss: 2.048489312971792

Epoch: 6| Step: 7
Training loss: 2.211210250854492
Validation loss: 2.0558706278442056

Epoch: 6| Step: 8
Training loss: 1.3151650428771973
Validation loss: 2.0492336083483953

Epoch: 6| Step: 9
Training loss: 1.8526867628097534
Validation loss: 2.0671625393693165

Epoch: 6| Step: 10
Training loss: 2.374380111694336
Validation loss: 2.0576105527980353

Epoch: 6| Step: 11
Training loss: 1.6907026767730713
Validation loss: 2.0681552463962185

Epoch: 6| Step: 12
Training loss: 1.7241225242614746
Validation loss: 2.0822585295605403

Epoch: 6| Step: 13
Training loss: 1.3747849464416504
Validation loss: 2.076898435110687

Epoch: 221| Step: 0
Training loss: 1.5470702648162842
Validation loss: 2.0749462317394953

Epoch: 6| Step: 1
Training loss: 1.5393166542053223
Validation loss: 2.050406893094381

Epoch: 6| Step: 2
Training loss: 2.1658153533935547
Validation loss: 2.018534296302385

Epoch: 6| Step: 3
Training loss: 1.5890029668807983
Validation loss: 2.0346544083728584

Epoch: 6| Step: 4
Training loss: 1.841292381286621
Validation loss: 2.041944226910991

Epoch: 6| Step: 5
Training loss: 2.1318106651306152
Validation loss: 2.014169003373833

Epoch: 6| Step: 6
Training loss: 2.29766583442688
Validation loss: 2.0230074697925198

Epoch: 6| Step: 7
Training loss: 2.185831069946289
Validation loss: 2.015847203552082

Epoch: 6| Step: 8
Training loss: 2.1637253761291504
Validation loss: 2.0289422773545787

Epoch: 6| Step: 9
Training loss: 1.1175293922424316
Validation loss: 2.0394260780785674

Epoch: 6| Step: 10
Training loss: 1.8292179107666016
Validation loss: 2.0014927130873486

Epoch: 6| Step: 11
Training loss: 2.118695020675659
Validation loss: 2.010616913918526

Epoch: 6| Step: 12
Training loss: 2.3556809425354004
Validation loss: 2.0060447723634782

Epoch: 6| Step: 13
Training loss: 1.8084074258804321
Validation loss: 2.045089837043516

Epoch: 222| Step: 0
Training loss: 2.4895243644714355
Validation loss: 2.032032674358737

Epoch: 6| Step: 1
Training loss: 1.6471474170684814
Validation loss: 2.0419605983200895

Epoch: 6| Step: 2
Training loss: 1.834670901298523
Validation loss: 2.0368006280673447

Epoch: 6| Step: 3
Training loss: 1.411689281463623
Validation loss: 2.0641088216535506

Epoch: 6| Step: 4
Training loss: 1.823096513748169
Validation loss: 2.048518773048155

Epoch: 6| Step: 5
Training loss: 1.6577186584472656
Validation loss: 2.0504877105835946

Epoch: 6| Step: 6
Training loss: 2.136950969696045
Validation loss: 2.0586080205055977

Epoch: 6| Step: 7
Training loss: 2.6814374923706055
Validation loss: 2.0641556452679377

Epoch: 6| Step: 8
Training loss: 1.6621787548065186
Validation loss: 2.0517454595975977

Epoch: 6| Step: 9
Training loss: 1.6584694385528564
Validation loss: 2.048474801483975

Epoch: 6| Step: 10
Training loss: 2.070716381072998
Validation loss: 2.059015290711516

Epoch: 6| Step: 11
Training loss: 1.5438721179962158
Validation loss: 2.0448504699173795

Epoch: 6| Step: 12
Training loss: 1.6854227781295776
Validation loss: 2.0509130775287585

Epoch: 6| Step: 13
Training loss: 2.0884737968444824
Validation loss: 2.0419523972336964

Epoch: 223| Step: 0
Training loss: 1.4824702739715576
Validation loss: 2.0282630484591246

Epoch: 6| Step: 1
Training loss: 2.1001956462860107
Validation loss: 2.053552839063829

Epoch: 6| Step: 2
Training loss: 2.950498580932617
Validation loss: 2.0466137650192424

Epoch: 6| Step: 3
Training loss: 2.338569164276123
Validation loss: 2.0844989566392798

Epoch: 6| Step: 4
Training loss: 1.5341713428497314
Validation loss: 2.061060315819197

Epoch: 6| Step: 5
Training loss: 1.8793615102767944
Validation loss: 2.066286757428159

Epoch: 6| Step: 6
Training loss: 1.6034982204437256
Validation loss: 2.0306709094714095

Epoch: 6| Step: 7
Training loss: 1.7600092887878418
Validation loss: 2.0583173754394695

Epoch: 6| Step: 8
Training loss: 2.016371726989746
Validation loss: 2.0376439197089082

Epoch: 6| Step: 9
Training loss: 1.7740097045898438
Validation loss: 2.037777998114145

Epoch: 6| Step: 10
Training loss: 1.8228150606155396
Validation loss: 2.0124297065119587

Epoch: 6| Step: 11
Training loss: 1.9126121997833252
Validation loss: 2.0297968246603526

Epoch: 6| Step: 12
Training loss: 2.250804901123047
Validation loss: 2.0249226247110674

Epoch: 6| Step: 13
Training loss: 1.0104047060012817
Validation loss: 2.046368514337847

Epoch: 224| Step: 0
Training loss: 1.80703866481781
Validation loss: 2.0276001320090344

Epoch: 6| Step: 1
Training loss: 1.618251919746399
Validation loss: 2.070748395817254

Epoch: 6| Step: 2
Training loss: 1.1411914825439453
Validation loss: 2.026323405645227

Epoch: 6| Step: 3
Training loss: 1.7228467464447021
Validation loss: 2.028589617821478

Epoch: 6| Step: 4
Training loss: 2.1052258014678955
Validation loss: 2.0397820498353694

Epoch: 6| Step: 5
Training loss: 2.4878292083740234
Validation loss: 2.051459766203357

Epoch: 6| Step: 6
Training loss: 2.3209192752838135
Validation loss: 2.0109314944154475

Epoch: 6| Step: 7
Training loss: 2.423326253890991
Validation loss: 2.022199039818138

Epoch: 6| Step: 8
Training loss: 1.2848527431488037
Validation loss: 2.024841152211671

Epoch: 6| Step: 9
Training loss: 1.8905205726623535
Validation loss: 2.0217309831291117

Epoch: 6| Step: 10
Training loss: 2.2676992416381836
Validation loss: 2.03695007037091

Epoch: 6| Step: 11
Training loss: 1.5770478248596191
Validation loss: 2.0612611411720194

Epoch: 6| Step: 12
Training loss: 1.4777604341506958
Validation loss: 2.0362715131493023

Epoch: 6| Step: 13
Training loss: 2.784128427505493
Validation loss: 2.006894225715309

Epoch: 225| Step: 0
Training loss: 2.1260030269622803
Validation loss: 2.041393388984024

Epoch: 6| Step: 1
Training loss: 1.3834867477416992
Validation loss: 2.047043517071714

Epoch: 6| Step: 2
Training loss: 1.5785185098648071
Validation loss: 2.061631869244319

Epoch: 6| Step: 3
Training loss: 1.9184610843658447
Validation loss: 2.0380539919740412

Epoch: 6| Step: 4
Training loss: 2.5457282066345215
Validation loss: 2.045392782457413

Epoch: 6| Step: 5
Training loss: 1.581594705581665
Validation loss: 2.0845492860322357

Epoch: 6| Step: 6
Training loss: 1.650327444076538
Validation loss: 2.0528290797305364

Epoch: 6| Step: 7
Training loss: 2.10606050491333
Validation loss: 2.0718660944251606

Epoch: 6| Step: 8
Training loss: 2.0306148529052734
Validation loss: 2.0936457700626825

Epoch: 6| Step: 9
Training loss: 1.7865850925445557
Validation loss: 2.0657140465192896

Epoch: 6| Step: 10
Training loss: 2.528351306915283
Validation loss: 2.0698026918595835

Epoch: 6| Step: 11
Training loss: 1.3391132354736328
Validation loss: 2.0499828079695344

Epoch: 6| Step: 12
Training loss: 1.6368247270584106
Validation loss: 2.0347090703184887

Epoch: 6| Step: 13
Training loss: 2.3958358764648438
Validation loss: 2.0402726960438553

Epoch: 226| Step: 0
Training loss: 1.4790675640106201
Validation loss: 2.0144739099728164

Epoch: 6| Step: 1
Training loss: 2.4363300800323486
Validation loss: 2.0132673555804836

Epoch: 6| Step: 2
Training loss: 1.7280807495117188
Validation loss: 2.0436191366564844

Epoch: 6| Step: 3
Training loss: 1.5977864265441895
Validation loss: 2.0393636483018116

Epoch: 6| Step: 4
Training loss: 1.8400568962097168
Validation loss: 2.041242422596101

Epoch: 6| Step: 5
Training loss: 2.04315185546875
Validation loss: 2.029483543929233

Epoch: 6| Step: 6
Training loss: 2.342905044555664
Validation loss: 2.043724271558946

Epoch: 6| Step: 7
Training loss: 1.3922832012176514
Validation loss: 2.035615077582739

Epoch: 6| Step: 8
Training loss: 1.9487478733062744
Validation loss: 2.016183281457552

Epoch: 6| Step: 9
Training loss: 1.934733510017395
Validation loss: 2.025653662220124

Epoch: 6| Step: 10
Training loss: 2.013838529586792
Validation loss: 2.024994670703847

Epoch: 6| Step: 11
Training loss: 2.2329883575439453
Validation loss: 2.0212521847858222

Epoch: 6| Step: 12
Training loss: 1.8135643005371094
Validation loss: 2.0393967179841894

Epoch: 6| Step: 13
Training loss: 1.6877751350402832
Validation loss: 2.0445872532424105

Epoch: 227| Step: 0
Training loss: 2.379439353942871
Validation loss: 2.029985309928976

Epoch: 6| Step: 1
Training loss: 1.878352165222168
Validation loss: 2.04292074454728

Epoch: 6| Step: 2
Training loss: 2.121480941772461
Validation loss: 2.0603622915924236

Epoch: 6| Step: 3
Training loss: 2.4953079223632812
Validation loss: 2.0456442986765215

Epoch: 6| Step: 4
Training loss: 2.608153820037842
Validation loss: 2.0613307670880388

Epoch: 6| Step: 5
Training loss: 1.5157109498977661
Validation loss: 2.0563780261624243

Epoch: 6| Step: 6
Training loss: 1.4663736820220947
Validation loss: 2.035189582455543

Epoch: 6| Step: 7
Training loss: 1.7468746900558472
Validation loss: 2.074884048072241

Epoch: 6| Step: 8
Training loss: 1.2378138303756714
Validation loss: 2.0644498102126585

Epoch: 6| Step: 9
Training loss: 1.5906301736831665
Validation loss: 2.0815617204994283

Epoch: 6| Step: 10
Training loss: 2.101346015930176
Validation loss: 2.0566051839500346

Epoch: 6| Step: 11
Training loss: 2.4357194900512695
Validation loss: 2.058527649089854

Epoch: 6| Step: 12
Training loss: 1.6595182418823242
Validation loss: 2.083593237784601

Epoch: 6| Step: 13
Training loss: 0.6620540022850037
Validation loss: 2.073749319199593

Epoch: 228| Step: 0
Training loss: 1.908882975578308
Validation loss: 2.054377689156481

Epoch: 6| Step: 1
Training loss: 2.610186815261841
Validation loss: 2.0434675370493243

Epoch: 6| Step: 2
Training loss: 1.2088416814804077
Validation loss: 2.046459996572105

Epoch: 6| Step: 3
Training loss: 1.508105754852295
Validation loss: 2.0517747863646476

Epoch: 6| Step: 4
Training loss: 1.9827053546905518
Validation loss: 2.020845674699353

Epoch: 6| Step: 5
Training loss: 1.9915990829467773
Validation loss: 2.0680070884766115

Epoch: 6| Step: 6
Training loss: 1.4620013236999512
Validation loss: 2.021237361815668

Epoch: 6| Step: 7
Training loss: 1.9924345016479492
Validation loss: 2.062910108156102

Epoch: 6| Step: 8
Training loss: 2.773332357406616
Validation loss: 2.0335347652435303

Epoch: 6| Step: 9
Training loss: 1.86215341091156
Validation loss: 2.036405383899648

Epoch: 6| Step: 10
Training loss: 0.8146002888679504
Validation loss: 2.016535835881387

Epoch: 6| Step: 11
Training loss: 2.0410947799682617
Validation loss: 2.028224857904578

Epoch: 6| Step: 12
Training loss: 1.9868292808532715
Validation loss: 2.015952497400263

Epoch: 6| Step: 13
Training loss: 2.1274077892303467
Validation loss: 2.017275224449814

Epoch: 229| Step: 0
Training loss: 1.7892428636550903
Validation loss: 2.0404655882107314

Epoch: 6| Step: 1
Training loss: 1.9407401084899902
Validation loss: 2.02468039015288

Epoch: 6| Step: 2
Training loss: 1.7369744777679443
Validation loss: 2.035356634406633

Epoch: 6| Step: 3
Training loss: 2.2225418090820312
Validation loss: 2.0419610520844818

Epoch: 6| Step: 4
Training loss: 2.6891379356384277
Validation loss: 2.018054287920716

Epoch: 6| Step: 5
Training loss: 1.1536293029785156
Validation loss: 2.0271842300250964

Epoch: 6| Step: 6
Training loss: 2.201817750930786
Validation loss: 2.0245073918373353

Epoch: 6| Step: 7
Training loss: 1.8325539827346802
Validation loss: 2.0508685214545137

Epoch: 6| Step: 8
Training loss: 1.3953094482421875
Validation loss: 2.047019798268554

Epoch: 6| Step: 9
Training loss: 1.4120713472366333
Validation loss: 2.0344565247976654

Epoch: 6| Step: 10
Training loss: 2.380931854248047
Validation loss: 2.011853212951332

Epoch: 6| Step: 11
Training loss: 1.7100584506988525
Validation loss: 2.048386892964763

Epoch: 6| Step: 12
Training loss: 2.334841251373291
Validation loss: 2.047917232718519

Epoch: 6| Step: 13
Training loss: 1.1060502529144287
Validation loss: 2.0292461777246125

Epoch: 230| Step: 0
Training loss: 1.8381128311157227
Validation loss: 2.0388010266006633

Epoch: 6| Step: 1
Training loss: 1.479414463043213
Validation loss: 2.070048721887732

Epoch: 6| Step: 2
Training loss: 0.8637372255325317
Validation loss: 2.0261177042479157

Epoch: 6| Step: 3
Training loss: 1.6468780040740967
Validation loss: 2.0527745190487114

Epoch: 6| Step: 4
Training loss: 1.6681890487670898
Validation loss: 2.0730882395980177

Epoch: 6| Step: 5
Training loss: 1.8110500574111938
Validation loss: 2.0774901554148686

Epoch: 6| Step: 6
Training loss: 1.7585290670394897
Validation loss: 2.0397190919486423

Epoch: 6| Step: 7
Training loss: 2.0194857120513916
Validation loss: 2.058670646400862

Epoch: 6| Step: 8
Training loss: 2.0297577381134033
Validation loss: 2.0715852117025726

Epoch: 6| Step: 9
Training loss: 1.5933403968811035
Validation loss: 2.0559702150283323

Epoch: 6| Step: 10
Training loss: 2.918771266937256
Validation loss: 2.031820558732556

Epoch: 6| Step: 11
Training loss: 1.762088418006897
Validation loss: 2.047709923918529

Epoch: 6| Step: 12
Training loss: 2.424034595489502
Validation loss: 2.06600696040738

Epoch: 6| Step: 13
Training loss: 2.4846103191375732
Validation loss: 2.039350749343954

Epoch: 231| Step: 0
Training loss: 2.017609119415283
Validation loss: 2.0749568503390075

Epoch: 6| Step: 1
Training loss: 1.6902952194213867
Validation loss: 2.0456781528329335

Epoch: 6| Step: 2
Training loss: 1.526559829711914
Validation loss: 2.004628824931319

Epoch: 6| Step: 3
Training loss: 1.7496709823608398
Validation loss: 2.018316061266007

Epoch: 6| Step: 4
Training loss: 1.9628297090530396
Validation loss: 2.032634347997686

Epoch: 6| Step: 5
Training loss: 2.2885541915893555
Validation loss: 2.0339893012918453

Epoch: 6| Step: 6
Training loss: 1.8882534503936768
Validation loss: 2.03565961827514

Epoch: 6| Step: 7
Training loss: 2.268991470336914
Validation loss: 1.9906244867591447

Epoch: 6| Step: 8
Training loss: 1.6298456192016602
Validation loss: 2.0242004381713046

Epoch: 6| Step: 9
Training loss: 2.375521421432495
Validation loss: 2.040791068025815

Epoch: 6| Step: 10
Training loss: 1.4773519039154053
Validation loss: 2.0486570301876275

Epoch: 6| Step: 11
Training loss: 1.7800297737121582
Validation loss: 2.01064125440454

Epoch: 6| Step: 12
Training loss: 1.6918245553970337
Validation loss: 2.0538874864578247

Epoch: 6| Step: 13
Training loss: 2.471163749694824
Validation loss: 2.0325243806326263

Epoch: 232| Step: 0
Training loss: 1.5069454908370972
Validation loss: 2.0620518422895864

Epoch: 6| Step: 1
Training loss: 2.4764368534088135
Validation loss: 2.060385324621713

Epoch: 6| Step: 2
Training loss: 1.5483592748641968
Validation loss: 2.0372102927136164

Epoch: 6| Step: 3
Training loss: 1.9561653137207031
Validation loss: 2.0369244724191646

Epoch: 6| Step: 4
Training loss: 1.8344247341156006
Validation loss: 2.0717839861428864

Epoch: 6| Step: 5
Training loss: 2.0783565044403076
Validation loss: 2.0171372582835536

Epoch: 6| Step: 6
Training loss: 2.066394329071045
Validation loss: 2.0365378933568157

Epoch: 6| Step: 7
Training loss: 1.0846360921859741
Validation loss: 2.064265144768582

Epoch: 6| Step: 8
Training loss: 2.256838321685791
Validation loss: 2.0735744955719158

Epoch: 6| Step: 9
Training loss: 1.6598591804504395
Validation loss: 2.0424615426730086

Epoch: 6| Step: 10
Training loss: 2.148036003112793
Validation loss: 2.078280588631989

Epoch: 6| Step: 11
Training loss: 1.8120051622390747
Validation loss: 2.072485536657354

Epoch: 6| Step: 12
Training loss: 2.0480380058288574
Validation loss: 2.0755692989595476

Epoch: 6| Step: 13
Training loss: 1.5950919389724731
Validation loss: 2.064449305175453

Epoch: 233| Step: 0
Training loss: 1.3914916515350342
Validation loss: 2.0448892936911633

Epoch: 6| Step: 1
Training loss: 2.1130313873291016
Validation loss: 2.071738623803662

Epoch: 6| Step: 2
Training loss: 1.5921125411987305
Validation loss: 2.0370708434812483

Epoch: 6| Step: 3
Training loss: 2.307891845703125
Validation loss: 2.054878382272618

Epoch: 6| Step: 4
Training loss: 1.7263760566711426
Validation loss: 2.0559238900420485

Epoch: 6| Step: 5
Training loss: 1.6833096742630005
Validation loss: 2.0388974041067143

Epoch: 6| Step: 6
Training loss: 1.9475786685943604
Validation loss: 2.054568398383356

Epoch: 6| Step: 7
Training loss: 2.1121902465820312
Validation loss: 2.0102300708011915

Epoch: 6| Step: 8
Training loss: 1.8008910417556763
Validation loss: 2.013006143672492

Epoch: 6| Step: 9
Training loss: 2.4488677978515625
Validation loss: 2.00667901449306

Epoch: 6| Step: 10
Training loss: 1.3594881296157837
Validation loss: 2.0037104647646666

Epoch: 6| Step: 11
Training loss: 1.3449311256408691
Validation loss: 1.9917172206345426

Epoch: 6| Step: 12
Training loss: 2.2095136642456055
Validation loss: 2.0105152207036174

Epoch: 6| Step: 13
Training loss: 2.1875083446502686
Validation loss: 1.9915643251070412

Epoch: 234| Step: 0
Training loss: 2.1070520877838135
Validation loss: 2.0160446730993127

Epoch: 6| Step: 1
Training loss: 1.6686371564865112
Validation loss: 1.9981406760472122

Epoch: 6| Step: 2
Training loss: 1.8519508838653564
Validation loss: 2.0289574720526256

Epoch: 6| Step: 3
Training loss: 1.7971991300582886
Validation loss: 2.006650727282288

Epoch: 6| Step: 4
Training loss: 2.103809356689453
Validation loss: 2.0316775396306026

Epoch: 6| Step: 5
Training loss: 2.294297695159912
Validation loss: 2.012311497042256

Epoch: 6| Step: 6
Training loss: 1.4439600706100464
Validation loss: 2.033970263696486

Epoch: 6| Step: 7
Training loss: 2.027523994445801
Validation loss: 2.0187283074983986

Epoch: 6| Step: 8
Training loss: 1.5177943706512451
Validation loss: 2.0196194289832987

Epoch: 6| Step: 9
Training loss: 1.8462910652160645
Validation loss: 2.045105202223665

Epoch: 6| Step: 10
Training loss: 1.9797990322113037
Validation loss: 2.0331368036167596

Epoch: 6| Step: 11
Training loss: 1.5912821292877197
Validation loss: 2.0360600730424285

Epoch: 6| Step: 12
Training loss: 1.8494737148284912
Validation loss: 2.0540040821157475

Epoch: 6| Step: 13
Training loss: 2.1135447025299072
Validation loss: 2.0548110046694354

Epoch: 235| Step: 0
Training loss: 1.8268086910247803
Validation loss: 2.0477963903898835

Epoch: 6| Step: 1
Training loss: 2.371338367462158
Validation loss: 2.0264491483729374

Epoch: 6| Step: 2
Training loss: 1.2953979969024658
Validation loss: 2.044751527488873

Epoch: 6| Step: 3
Training loss: 1.6145787239074707
Validation loss: 2.0705846099443335

Epoch: 6| Step: 4
Training loss: 1.7091503143310547
Validation loss: 2.0303264510247017

Epoch: 6| Step: 5
Training loss: 1.535323143005371
Validation loss: 2.036379348847174

Epoch: 6| Step: 6
Training loss: 1.8984203338623047
Validation loss: 2.0480748248356644

Epoch: 6| Step: 7
Training loss: 1.6780970096588135
Validation loss: 2.0238162971312

Epoch: 6| Step: 8
Training loss: 2.176469326019287
Validation loss: 2.04637046270473

Epoch: 6| Step: 9
Training loss: 2.6146888732910156
Validation loss: 2.0723456823697655

Epoch: 6| Step: 10
Training loss: 1.3317065238952637
Validation loss: 2.0662382443745932

Epoch: 6| Step: 11
Training loss: 1.6847703456878662
Validation loss: 2.04234399590441

Epoch: 6| Step: 12
Training loss: 2.3534464836120605
Validation loss: 2.0413377567004134

Epoch: 6| Step: 13
Training loss: 1.951087474822998
Validation loss: 2.0540914202249176

Epoch: 236| Step: 0
Training loss: 1.4256457090377808
Validation loss: 2.040529233153148

Epoch: 6| Step: 1
Training loss: 1.9735488891601562
Validation loss: 2.030302310502657

Epoch: 6| Step: 2
Training loss: 1.747194766998291
Validation loss: 2.0197753149976014

Epoch: 6| Step: 3
Training loss: 1.7258285284042358
Validation loss: 2.078165446558306

Epoch: 6| Step: 4
Training loss: 1.603118658065796
Validation loss: 2.0459066001317834

Epoch: 6| Step: 5
Training loss: 1.6903796195983887
Validation loss: 2.0643560565927976

Epoch: 6| Step: 6
Training loss: 2.3457627296447754
Validation loss: 2.076503446025233

Epoch: 6| Step: 7
Training loss: 2.3315112590789795
Validation loss: 2.0560380733141335

Epoch: 6| Step: 8
Training loss: 0.9919993281364441
Validation loss: 2.0416432888277116

Epoch: 6| Step: 9
Training loss: 2.0961227416992188
Validation loss: 2.068710816803799

Epoch: 6| Step: 10
Training loss: 2.4751248359680176
Validation loss: 2.0398326625106153

Epoch: 6| Step: 11
Training loss: 2.1839599609375
Validation loss: 2.066380177774737

Epoch: 6| Step: 12
Training loss: 1.6379780769348145
Validation loss: 2.0484019863990044

Epoch: 6| Step: 13
Training loss: 1.7869294881820679
Validation loss: 2.0247976626119306

Epoch: 237| Step: 0
Training loss: 1.2800475358963013
Validation loss: 2.025570243917486

Epoch: 6| Step: 1
Training loss: 1.897536277770996
Validation loss: 2.0321646595513947

Epoch: 6| Step: 2
Training loss: 1.733351707458496
Validation loss: 2.0272777439445577

Epoch: 6| Step: 3
Training loss: 2.053689956665039
Validation loss: 2.0510489838097685

Epoch: 6| Step: 4
Training loss: 2.31400203704834
Validation loss: 2.0209540218435307

Epoch: 6| Step: 5
Training loss: 1.4376283884048462
Validation loss: 2.036884646261892

Epoch: 6| Step: 6
Training loss: 1.8945931196212769
Validation loss: 2.0307442295935845

Epoch: 6| Step: 7
Training loss: 1.5417184829711914
Validation loss: 2.0482632703678583

Epoch: 6| Step: 8
Training loss: 2.070708751678467
Validation loss: 2.0035374831127863

Epoch: 6| Step: 9
Training loss: 2.142127513885498
Validation loss: 2.0407605145567205

Epoch: 6| Step: 10
Training loss: 2.3150408267974854
Validation loss: 2.036939472280523

Epoch: 6| Step: 11
Training loss: 2.1725423336029053
Validation loss: 2.0312681377574964

Epoch: 6| Step: 12
Training loss: 1.3159972429275513
Validation loss: 2.0426955787084435

Epoch: 6| Step: 13
Training loss: 1.6013847589492798
Validation loss: 2.0380522230620026

Epoch: 238| Step: 0
Training loss: 2.214999198913574
Validation loss: 2.0332242570897585

Epoch: 6| Step: 1
Training loss: 1.9359643459320068
Validation loss: 2.0356871415210027

Epoch: 6| Step: 2
Training loss: 1.3486416339874268
Validation loss: 2.03925552803983

Epoch: 6| Step: 3
Training loss: 2.4000751972198486
Validation loss: 2.0370750593882736

Epoch: 6| Step: 4
Training loss: 1.8466031551361084
Validation loss: 2.0732081756796887

Epoch: 6| Step: 5
Training loss: 1.3338689804077148
Validation loss: 2.012561709650101

Epoch: 6| Step: 6
Training loss: 2.546686887741089
Validation loss: 2.026382174543155

Epoch: 6| Step: 7
Training loss: 2.065897226333618
Validation loss: 2.0331545363190355

Epoch: 6| Step: 8
Training loss: 1.9483904838562012
Validation loss: 2.038808307340068

Epoch: 6| Step: 9
Training loss: 1.729661464691162
Validation loss: 2.029162327448527

Epoch: 6| Step: 10
Training loss: 2.3383913040161133
Validation loss: 2.0090146321122364

Epoch: 6| Step: 11
Training loss: 1.5330309867858887
Validation loss: 2.037242950931672

Epoch: 6| Step: 12
Training loss: 1.3852673768997192
Validation loss: 2.069393011831468

Epoch: 6| Step: 13
Training loss: 1.141129970550537
Validation loss: 2.0898494310276483

Epoch: 239| Step: 0
Training loss: 1.2785134315490723
Validation loss: 2.075106243933401

Epoch: 6| Step: 1
Training loss: 2.4057374000549316
Validation loss: 2.0780784724861063

Epoch: 6| Step: 2
Training loss: 2.069932460784912
Validation loss: 2.059596848744218

Epoch: 6| Step: 3
Training loss: 1.756519079208374
Validation loss: 2.0576980293438

Epoch: 6| Step: 4
Training loss: 2.156839609146118
Validation loss: 2.0445431560598393

Epoch: 6| Step: 5
Training loss: 1.7826757431030273
Validation loss: 2.0544428543377946

Epoch: 6| Step: 6
Training loss: 1.643026351928711
Validation loss: 2.041405224031018

Epoch: 6| Step: 7
Training loss: 1.5603879690170288
Validation loss: 2.0282011314104964

Epoch: 6| Step: 8
Training loss: 2.5129010677337646
Validation loss: 2.029930335219188

Epoch: 6| Step: 9
Training loss: 2.158134937286377
Validation loss: 2.0441498717954083

Epoch: 6| Step: 10
Training loss: 1.6738224029541016
Validation loss: 2.00744140789073

Epoch: 6| Step: 11
Training loss: 1.588934302330017
Validation loss: 2.0222641793630456

Epoch: 6| Step: 12
Training loss: 1.485133171081543
Validation loss: 2.027307116857139

Epoch: 6| Step: 13
Training loss: 2.217707633972168
Validation loss: 2.042934117778655

Epoch: 240| Step: 0
Training loss: 1.8093315362930298
Validation loss: 2.0415689304310787

Epoch: 6| Step: 1
Training loss: 2.4935050010681152
Validation loss: 2.056095266854891

Epoch: 6| Step: 2
Training loss: 2.0526223182678223
Validation loss: 2.0487636020106654

Epoch: 6| Step: 3
Training loss: 1.9430832862854004
Validation loss: 2.0515347949920164

Epoch: 6| Step: 4
Training loss: 1.5813130140304565
Validation loss: 2.042054932604554

Epoch: 6| Step: 5
Training loss: 2.1920080184936523
Validation loss: 2.0519061588471934

Epoch: 6| Step: 6
Training loss: 1.7757534980773926
Validation loss: 2.0336784060283373

Epoch: 6| Step: 7
Training loss: 1.6478071212768555
Validation loss: 2.0647626666612524

Epoch: 6| Step: 8
Training loss: 1.2528256177902222
Validation loss: 2.068544351926414

Epoch: 6| Step: 9
Training loss: 1.2281253337860107
Validation loss: 2.0339085466118267

Epoch: 6| Step: 10
Training loss: 1.717166543006897
Validation loss: 2.063126664007864

Epoch: 6| Step: 11
Training loss: 1.8750391006469727
Validation loss: 2.0519170786744807

Epoch: 6| Step: 12
Training loss: 2.0159366130828857
Validation loss: 2.0290462586187545

Epoch: 6| Step: 13
Training loss: 2.6187543869018555
Validation loss: 2.047196416444676

Epoch: 241| Step: 0
Training loss: 1.4667367935180664
Validation loss: 2.076782249635266

Epoch: 6| Step: 1
Training loss: 1.49613356590271
Validation loss: 2.0484055524231284

Epoch: 6| Step: 2
Training loss: 1.828156590461731
Validation loss: 2.044052444478517

Epoch: 6| Step: 3
Training loss: 1.7332175970077515
Validation loss: 2.045966922595937

Epoch: 6| Step: 4
Training loss: 1.6096101999282837
Validation loss: 2.085739820234237

Epoch: 6| Step: 5
Training loss: 1.7096538543701172
Validation loss: 2.055516201962707

Epoch: 6| Step: 6
Training loss: 2.377763509750366
Validation loss: 2.071680800889128

Epoch: 6| Step: 7
Training loss: 1.882264494895935
Validation loss: 2.04684615647921

Epoch: 6| Step: 8
Training loss: 1.6876885890960693
Validation loss: 2.0407901720334123

Epoch: 6| Step: 9
Training loss: 2.242894411087036
Validation loss: 2.0601488057003228

Epoch: 6| Step: 10
Training loss: 1.5065398216247559
Validation loss: 2.050531716756923

Epoch: 6| Step: 11
Training loss: 2.4046623706817627
Validation loss: 2.0622890098120576

Epoch: 6| Step: 12
Training loss: 1.7772600650787354
Validation loss: 2.0366267888776717

Epoch: 6| Step: 13
Training loss: 2.319857358932495
Validation loss: 2.0309851374677432

Epoch: 242| Step: 0
Training loss: 1.7019360065460205
Validation loss: 2.07111333903446

Epoch: 6| Step: 1
Training loss: 1.907418966293335
Validation loss: 2.0483195192070416

Epoch: 6| Step: 2
Training loss: 1.874260425567627
Validation loss: 2.056466825546757

Epoch: 6| Step: 3
Training loss: 1.781045913696289
Validation loss: 2.0572951468088294

Epoch: 6| Step: 4
Training loss: 1.3714710474014282
Validation loss: 2.0633047934501403

Epoch: 6| Step: 5
Training loss: 2.386396884918213
Validation loss: 2.0574296623147945

Epoch: 6| Step: 6
Training loss: 1.3462116718292236
Validation loss: 2.0666649623583724

Epoch: 6| Step: 7
Training loss: 2.229377269744873
Validation loss: 2.0520507789427236

Epoch: 6| Step: 8
Training loss: 1.669172763824463
Validation loss: 2.0310156960641184

Epoch: 6| Step: 9
Training loss: 1.9644050598144531
Validation loss: 2.037294195544335

Epoch: 6| Step: 10
Training loss: 2.009481191635132
Validation loss: 2.04181105859818

Epoch: 6| Step: 11
Training loss: 1.710613489151001
Validation loss: 2.034840073636783

Epoch: 6| Step: 12
Training loss: 1.8754452466964722
Validation loss: 2.04276551482498

Epoch: 6| Step: 13
Training loss: 2.4263916015625
Validation loss: 2.066401361137308

Epoch: 243| Step: 0
Training loss: 2.272528886795044
Validation loss: 2.046504485991693

Epoch: 6| Step: 1
Training loss: 1.7226815223693848
Validation loss: 2.0217339018339753

Epoch: 6| Step: 2
Training loss: 2.0761501789093018
Validation loss: 2.0379688355230514

Epoch: 6| Step: 3
Training loss: 1.2956852912902832
Validation loss: 2.0329810188662623

Epoch: 6| Step: 4
Training loss: 1.5088465213775635
Validation loss: 2.035720320158107

Epoch: 6| Step: 5
Training loss: 1.9465677738189697
Validation loss: 2.031830609485667

Epoch: 6| Step: 6
Training loss: 1.2791087627410889
Validation loss: 2.012531940655042

Epoch: 6| Step: 7
Training loss: 2.5818142890930176
Validation loss: 2.03006685421031

Epoch: 6| Step: 8
Training loss: 2.065021276473999
Validation loss: 2.0291302947587866

Epoch: 6| Step: 9
Training loss: 1.886393427848816
Validation loss: 2.0274042262825915

Epoch: 6| Step: 10
Training loss: 1.9478156566619873
Validation loss: 2.0220145128106557

Epoch: 6| Step: 11
Training loss: 1.710505723953247
Validation loss: 2.0487393858612224

Epoch: 6| Step: 12
Training loss: 1.2824680805206299
Validation loss: 2.0342485699602353

Epoch: 6| Step: 13
Training loss: 2.9549052715301514
Validation loss: 2.047433748040148

Epoch: 244| Step: 0
Training loss: 1.522377371788025
Validation loss: 2.0036510857202674

Epoch: 6| Step: 1
Training loss: 1.6928819417953491
Validation loss: 2.0445511892277706

Epoch: 6| Step: 2
Training loss: 1.5806630849838257
Validation loss: 2.020592515186597

Epoch: 6| Step: 3
Training loss: 1.5114696025848389
Validation loss: 2.0901132988673385

Epoch: 6| Step: 4
Training loss: 1.804680347442627
Validation loss: 2.05117146302295

Epoch: 6| Step: 5
Training loss: 1.9356818199157715
Validation loss: 2.06508203219342

Epoch: 6| Step: 6
Training loss: 1.6429595947265625
Validation loss: 2.068456990744478

Epoch: 6| Step: 7
Training loss: 1.7072259187698364
Validation loss: 2.0707446426473637

Epoch: 6| Step: 8
Training loss: 1.8495686054229736
Validation loss: 2.1135401982133106

Epoch: 6| Step: 9
Training loss: 1.7519421577453613
Validation loss: 2.074788342240036

Epoch: 6| Step: 10
Training loss: 2.1543755531311035
Validation loss: 2.065571126117501

Epoch: 6| Step: 11
Training loss: 2.229962110519409
Validation loss: 2.0549436512813775

Epoch: 6| Step: 12
Training loss: 2.228210210800171
Validation loss: 2.052430424638974

Epoch: 6| Step: 13
Training loss: 2.373903751373291
Validation loss: 2.054927154253888

Epoch: 245| Step: 0
Training loss: 2.0252413749694824
Validation loss: 2.064279238382975

Epoch: 6| Step: 1
Training loss: 1.9581325054168701
Validation loss: 2.0173559035024335

Epoch: 6| Step: 2
Training loss: 2.440908908843994
Validation loss: 2.051106160686862

Epoch: 6| Step: 3
Training loss: 2.2438454627990723
Validation loss: 2.0557807619853685

Epoch: 6| Step: 4
Training loss: 2.2082748413085938
Validation loss: 2.070794620821553

Epoch: 6| Step: 5
Training loss: 2.193969249725342
Validation loss: 2.006813583835479

Epoch: 6| Step: 6
Training loss: 1.3765666484832764
Validation loss: 2.0166419988037436

Epoch: 6| Step: 7
Training loss: 0.9432538747787476
Validation loss: 2.043482675347277

Epoch: 6| Step: 8
Training loss: 1.4763747453689575
Validation loss: 2.0601801769707793

Epoch: 6| Step: 9
Training loss: 1.4817301034927368
Validation loss: 2.0569180288622455

Epoch: 6| Step: 10
Training loss: 2.0508785247802734
Validation loss: 2.036212134104903

Epoch: 6| Step: 11
Training loss: 1.7953518629074097
Validation loss: 2.067687875481062

Epoch: 6| Step: 12
Training loss: 1.7751281261444092
Validation loss: 2.0504803529349704

Epoch: 6| Step: 13
Training loss: 1.9021592140197754
Validation loss: 2.0420365641194005

Epoch: 246| Step: 0
Training loss: 1.722187876701355
Validation loss: 2.0711268712115545

Epoch: 6| Step: 1
Training loss: 2.073803186416626
Validation loss: 2.018696511945417

Epoch: 6| Step: 2
Training loss: 1.9701586961746216
Validation loss: 2.0746463601307203

Epoch: 6| Step: 3
Training loss: 2.6214966773986816
Validation loss: 2.0411205650657736

Epoch: 6| Step: 4
Training loss: 2.0613772869110107
Validation loss: 2.0358469742600636

Epoch: 6| Step: 5
Training loss: 2.0641069412231445
Validation loss: 2.0743479587698497

Epoch: 6| Step: 6
Training loss: 1.3716833591461182
Validation loss: 2.0780984304284535

Epoch: 6| Step: 7
Training loss: 1.630539894104004
Validation loss: 2.0732586896547707

Epoch: 6| Step: 8
Training loss: 1.615854263305664
Validation loss: 2.0644132398789927

Epoch: 6| Step: 9
Training loss: 2.170696258544922
Validation loss: 2.047654201907496

Epoch: 6| Step: 10
Training loss: 1.5246261358261108
Validation loss: 2.0575370378391717

Epoch: 6| Step: 11
Training loss: 1.8697984218597412
Validation loss: 2.0892560392297725

Epoch: 6| Step: 12
Training loss: 1.2652729749679565
Validation loss: 2.0267186549402054

Epoch: 6| Step: 13
Training loss: 1.7215495109558105
Validation loss: 2.0377224555579563

Epoch: 247| Step: 0
Training loss: 1.80379056930542
Validation loss: 2.0509229347270024

Epoch: 6| Step: 1
Training loss: 2.435668468475342
Validation loss: 2.0511488478670836

Epoch: 6| Step: 2
Training loss: 2.3948144912719727
Validation loss: 2.0333210088873424

Epoch: 6| Step: 3
Training loss: 1.639948844909668
Validation loss: 2.0813427714891333

Epoch: 6| Step: 4
Training loss: 1.8446896076202393
Validation loss: 2.059187889099121

Epoch: 6| Step: 5
Training loss: 2.1560189723968506
Validation loss: 2.0524298183379637

Epoch: 6| Step: 6
Training loss: 1.6236015558242798
Validation loss: 2.0372582866299536

Epoch: 6| Step: 7
Training loss: 1.969832420349121
Validation loss: 2.0408559832521664

Epoch: 6| Step: 8
Training loss: 1.7893927097320557
Validation loss: 2.0441112672128985

Epoch: 6| Step: 9
Training loss: 1.4550670385360718
Validation loss: 2.0657216092591644

Epoch: 6| Step: 10
Training loss: 2.046894073486328
Validation loss: 2.0381364617296445

Epoch: 6| Step: 11
Training loss: 1.5399632453918457
Validation loss: 2.058327818429598

Epoch: 6| Step: 12
Training loss: 1.32399582862854
Validation loss: 2.0103962254780594

Epoch: 6| Step: 13
Training loss: 2.0571601390838623
Validation loss: 2.0489905175342353

Epoch: 248| Step: 0
Training loss: 2.0287914276123047
Validation loss: 2.05333573074751

Epoch: 6| Step: 1
Training loss: 1.868842363357544
Validation loss: 2.0437319701717747

Epoch: 6| Step: 2
Training loss: 2.531951904296875
Validation loss: 2.028565135053409

Epoch: 6| Step: 3
Training loss: 2.3116278648376465
Validation loss: 2.070143722718762

Epoch: 6| Step: 4
Training loss: 1.6061769723892212
Validation loss: 2.053765744291326

Epoch: 6| Step: 5
Training loss: 1.5525193214416504
Validation loss: 2.021074028425319

Epoch: 6| Step: 6
Training loss: 1.5055955648422241
Validation loss: 2.0289643874732395

Epoch: 6| Step: 7
Training loss: 2.1445250511169434
Validation loss: 2.0358546985092985

Epoch: 6| Step: 8
Training loss: 1.3402897119522095
Validation loss: 2.018235409131614

Epoch: 6| Step: 9
Training loss: 2.8015384674072266
Validation loss: 2.024188292923794

Epoch: 6| Step: 10
Training loss: 1.5197055339813232
Validation loss: 2.059356315161592

Epoch: 6| Step: 11
Training loss: 1.5093541145324707
Validation loss: 2.0561076492391606

Epoch: 6| Step: 12
Training loss: 1.6999733448028564
Validation loss: 2.027132975157871

Epoch: 6| Step: 13
Training loss: 1.1897826194763184
Validation loss: 2.02886051260015

Epoch: 249| Step: 0
Training loss: 2.108590841293335
Validation loss: 2.038231812497621

Epoch: 6| Step: 1
Training loss: 1.5887517929077148
Validation loss: 2.040591803930139

Epoch: 6| Step: 2
Training loss: 1.8520631790161133
Validation loss: 2.0527734436014646

Epoch: 6| Step: 3
Training loss: 3.173178195953369
Validation loss: 2.0765947193227787

Epoch: 6| Step: 4
Training loss: 1.1373132467269897
Validation loss: 2.092713232963316

Epoch: 6| Step: 5
Training loss: 1.6125280857086182
Validation loss: 2.077819287136037

Epoch: 6| Step: 6
Training loss: 1.8736746311187744
Validation loss: 2.07158072276782

Epoch: 6| Step: 7
Training loss: 2.091454029083252
Validation loss: 2.0934092588322137

Epoch: 6| Step: 8
Training loss: 1.7826521396636963
Validation loss: 2.0746599551170104

Epoch: 6| Step: 9
Training loss: 1.2804534435272217
Validation loss: 2.084967627320238

Epoch: 6| Step: 10
Training loss: 2.095033645629883
Validation loss: 2.104222587359849

Epoch: 6| Step: 11
Training loss: 1.8190817832946777
Validation loss: 2.092878317320219

Epoch: 6| Step: 12
Training loss: 1.7521599531173706
Validation loss: 2.075030437079809

Epoch: 6| Step: 13
Training loss: 1.2903437614440918
Validation loss: 2.0774662930478334

Epoch: 250| Step: 0
Training loss: 1.9705510139465332
Validation loss: 2.065394684832583

Epoch: 6| Step: 1
Training loss: 1.7538005113601685
Validation loss: 2.0370236648026334

Epoch: 6| Step: 2
Training loss: 1.4983633756637573
Validation loss: 2.0227586171960317

Epoch: 6| Step: 3
Training loss: 1.2061331272125244
Validation loss: 2.0303770252453384

Epoch: 6| Step: 4
Training loss: 1.8254168033599854
Validation loss: 2.009176508072884

Epoch: 6| Step: 5
Training loss: 2.0141894817352295
Validation loss: 2.017535537801763

Epoch: 6| Step: 6
Training loss: 1.6385219097137451
Validation loss: 2.0181095164309264

Epoch: 6| Step: 7
Training loss: 2.260368824005127
Validation loss: 2.0530905556935135

Epoch: 6| Step: 8
Training loss: 2.6302480697631836
Validation loss: 2.0175584003489506

Epoch: 6| Step: 9
Training loss: 2.1038730144500732
Validation loss: 2.066017682834338

Epoch: 6| Step: 10
Training loss: 1.8316001892089844
Validation loss: 2.049608725373463

Epoch: 6| Step: 11
Training loss: 1.6583753824234009
Validation loss: 2.0601502413390786

Epoch: 6| Step: 12
Training loss: 1.2828233242034912
Validation loss: 2.0616783967582126

Epoch: 6| Step: 13
Training loss: 2.2136082649230957
Validation loss: 2.061156033187784

Epoch: 251| Step: 0
Training loss: 1.2948479652404785
Validation loss: 2.044344109873618

Epoch: 6| Step: 1
Training loss: 1.8862119913101196
Validation loss: 2.060362723565871

Epoch: 6| Step: 2
Training loss: 1.859523057937622
Validation loss: 2.0852779239736576

Epoch: 6| Step: 3
Training loss: 2.132739305496216
Validation loss: 2.053570293611096

Epoch: 6| Step: 4
Training loss: 2.028477191925049
Validation loss: 2.087560769050352

Epoch: 6| Step: 5
Training loss: 1.5468719005584717
Validation loss: 2.0622454535576606

Epoch: 6| Step: 6
Training loss: 1.7044655084609985
Validation loss: 2.0712065389079433

Epoch: 6| Step: 7
Training loss: 1.8062245845794678
Validation loss: 2.0781021553982972

Epoch: 6| Step: 8
Training loss: 2.040391445159912
Validation loss: 2.09036531243273

Epoch: 6| Step: 9
Training loss: 1.982125997543335
Validation loss: 2.0403749135232743

Epoch: 6| Step: 10
Training loss: 1.840383529663086
Validation loss: 2.0727889524993075

Epoch: 6| Step: 11
Training loss: 1.4929031133651733
Validation loss: 2.0717844424709195

Epoch: 6| Step: 12
Training loss: 2.0127854347229004
Validation loss: 2.059809543753183

Epoch: 6| Step: 13
Training loss: 2.2949373722076416
Validation loss: 2.0486904626251548

Epoch: 252| Step: 0
Training loss: 1.6277555227279663
Validation loss: 2.037037944280973

Epoch: 6| Step: 1
Training loss: 2.3339293003082275
Validation loss: 2.0586755429544756

Epoch: 6| Step: 2
Training loss: 1.8088631629943848
Validation loss: 2.0370849588865876

Epoch: 6| Step: 3
Training loss: 1.9055194854736328
Validation loss: 2.035797598541424

Epoch: 6| Step: 4
Training loss: 1.7585828304290771
Validation loss: 2.0166324236059703

Epoch: 6| Step: 5
Training loss: 2.0309529304504395
Validation loss: 2.0332691631009503

Epoch: 6| Step: 6
Training loss: 1.9267927408218384
Validation loss: 2.040658543186803

Epoch: 6| Step: 7
Training loss: 1.8993017673492432
Validation loss: 2.0455581308693014

Epoch: 6| Step: 8
Training loss: 1.5616357326507568
Validation loss: 2.0354042617223596

Epoch: 6| Step: 9
Training loss: 1.1652195453643799
Validation loss: 2.0741342793228807

Epoch: 6| Step: 10
Training loss: 1.403078556060791
Validation loss: 2.039339828234847

Epoch: 6| Step: 11
Training loss: 1.9696931838989258
Validation loss: 2.0832328334931405

Epoch: 6| Step: 12
Training loss: 2.1466944217681885
Validation loss: 2.023372539909937

Epoch: 6| Step: 13
Training loss: 2.072627067565918
Validation loss: 2.0252509732400217

Epoch: 253| Step: 0
Training loss: 2.2358949184417725
Validation loss: 2.0579060713450112

Epoch: 6| Step: 1
Training loss: 1.8728141784667969
Validation loss: 2.0711050687297696

Epoch: 6| Step: 2
Training loss: 2.018806219100952
Validation loss: 2.1021681293364494

Epoch: 6| Step: 3
Training loss: 1.5914908647537231
Validation loss: 2.068478670171512

Epoch: 6| Step: 4
Training loss: 2.2144651412963867
Validation loss: 2.079018303143081

Epoch: 6| Step: 5
Training loss: 1.8874173164367676
Validation loss: 2.096182697562761

Epoch: 6| Step: 6
Training loss: 1.2978893518447876
Validation loss: 2.068122704823812

Epoch: 6| Step: 7
Training loss: 1.5534040927886963
Validation loss: 2.0767410493666127

Epoch: 6| Step: 8
Training loss: 2.0984010696411133
Validation loss: 2.047587207568589

Epoch: 6| Step: 9
Training loss: 1.8936184644699097
Validation loss: 2.0464773831828946

Epoch: 6| Step: 10
Training loss: 1.8943570852279663
Validation loss: 2.0554450301713842

Epoch: 6| Step: 11
Training loss: 1.5398117303848267
Validation loss: 2.024973298913689

Epoch: 6| Step: 12
Training loss: 1.9184651374816895
Validation loss: 2.071378238739506

Epoch: 6| Step: 13
Training loss: 1.4490487575531006
Validation loss: 2.0437525805606636

Epoch: 254| Step: 0
Training loss: 1.7026628255844116
Validation loss: 2.0314116054965603

Epoch: 6| Step: 1
Training loss: 1.412148118019104
Validation loss: 2.046512749887282

Epoch: 6| Step: 2
Training loss: 2.115122079849243
Validation loss: 2.0499034953373734

Epoch: 6| Step: 3
Training loss: 1.8351110219955444
Validation loss: 2.0303354186396443

Epoch: 6| Step: 4
Training loss: 2.0577807426452637
Validation loss: 2.0006301428682063

Epoch: 6| Step: 5
Training loss: 1.5460023880004883
Validation loss: 1.9938048521677654

Epoch: 6| Step: 6
Training loss: 1.8519046306610107
Validation loss: 2.0591612221092306

Epoch: 6| Step: 7
Training loss: 1.9609880447387695
Validation loss: 2.0289878614487185

Epoch: 6| Step: 8
Training loss: 1.8280783891677856
Validation loss: 2.0301105771013486

Epoch: 6| Step: 9
Training loss: 1.7445363998413086
Validation loss: 2.051748198847617

Epoch: 6| Step: 10
Training loss: 1.9758832454681396
Validation loss: 2.026705918773528

Epoch: 6| Step: 11
Training loss: 1.6875792741775513
Validation loss: 2.0476309586596746

Epoch: 6| Step: 12
Training loss: 1.9037339687347412
Validation loss: 2.047080703960952

Epoch: 6| Step: 13
Training loss: 1.7940750122070312
Validation loss: 2.0619429888263827

Epoch: 255| Step: 0
Training loss: 0.9794232249259949
Validation loss: 2.025520616962064

Epoch: 6| Step: 1
Training loss: 1.7782824039459229
Validation loss: 2.0322988635750225

Epoch: 6| Step: 2
Training loss: 2.1246461868286133
Validation loss: 2.066703209313013

Epoch: 6| Step: 3
Training loss: 1.387545108795166
Validation loss: 2.065857918031754

Epoch: 6| Step: 4
Training loss: 1.7971432209014893
Validation loss: 2.061706949305791

Epoch: 6| Step: 5
Training loss: 2.950444221496582
Validation loss: 2.062608339453256

Epoch: 6| Step: 6
Training loss: 1.696777582168579
Validation loss: 2.0587615684796403

Epoch: 6| Step: 7
Training loss: 2.2090048789978027
Validation loss: 2.0801655592456942

Epoch: 6| Step: 8
Training loss: 1.2083475589752197
Validation loss: 2.044854694797147

Epoch: 6| Step: 9
Training loss: 1.7136280536651611
Validation loss: 2.030662913476267

Epoch: 6| Step: 10
Training loss: 1.686246633529663
Validation loss: 2.0287920967225106

Epoch: 6| Step: 11
Training loss: 1.683672547340393
Validation loss: 2.0345791129655737

Epoch: 6| Step: 12
Training loss: 2.564932346343994
Validation loss: 2.0414768726594987

Epoch: 6| Step: 13
Training loss: 1.6460294723510742
Validation loss: 1.9914912818580546

Epoch: 256| Step: 0
Training loss: 2.0261306762695312
Validation loss: 2.0431597489182667

Epoch: 6| Step: 1
Training loss: 1.678216576576233
Validation loss: 2.049107946375365

Epoch: 6| Step: 2
Training loss: 1.5672333240509033
Validation loss: 2.0677797922524075

Epoch: 6| Step: 3
Training loss: 2.368934154510498
Validation loss: 2.046761715283958

Epoch: 6| Step: 4
Training loss: 1.896122694015503
Validation loss: 2.0450790761619486

Epoch: 6| Step: 5
Training loss: 2.458975076675415
Validation loss: 2.067003333440391

Epoch: 6| Step: 6
Training loss: 1.2823355197906494
Validation loss: 2.0527455986187024

Epoch: 6| Step: 7
Training loss: 1.5532950162887573
Validation loss: 2.06453981707173

Epoch: 6| Step: 8
Training loss: 1.9034740924835205
Validation loss: 2.0407308634891304

Epoch: 6| Step: 9
Training loss: 1.3076298236846924
Validation loss: 2.068842749441824

Epoch: 6| Step: 10
Training loss: 1.589494228363037
Validation loss: 2.0655607638820523

Epoch: 6| Step: 11
Training loss: 2.625399589538574
Validation loss: 2.0390841922452374

Epoch: 6| Step: 12
Training loss: 1.4000813961029053
Validation loss: 2.0448642456403343

Epoch: 6| Step: 13
Training loss: 1.6293116807937622
Validation loss: 2.046592399638186

Epoch: 257| Step: 0
Training loss: 1.6301295757293701
Validation loss: 2.0499770205507994

Epoch: 6| Step: 1
Training loss: 1.4391635656356812
Validation loss: 2.0089040430643226

Epoch: 6| Step: 2
Training loss: 1.5511212348937988
Validation loss: 2.0277222612852692

Epoch: 6| Step: 3
Training loss: 1.5763084888458252
Validation loss: 2.0098021120153446

Epoch: 6| Step: 4
Training loss: 3.4016153812408447
Validation loss: 1.9740124594780706

Epoch: 6| Step: 5
Training loss: 2.151305675506592
Validation loss: 2.0311053645226265

Epoch: 6| Step: 6
Training loss: 2.3630359172821045
Validation loss: 2.0454044906041955

Epoch: 6| Step: 7
Training loss: 1.6659393310546875
Validation loss: 2.0044794057005193

Epoch: 6| Step: 8
Training loss: 1.323017954826355
Validation loss: 2.026132692572891

Epoch: 6| Step: 9
Training loss: 1.4574995040893555
Validation loss: 2.0467954912493305

Epoch: 6| Step: 10
Training loss: 1.678217887878418
Validation loss: 2.036372293708145

Epoch: 6| Step: 11
Training loss: 1.7099627256393433
Validation loss: 1.9916462744435957

Epoch: 6| Step: 12
Training loss: 1.7294509410858154
Validation loss: 2.020978994266961

Epoch: 6| Step: 13
Training loss: 1.8167016506195068
Validation loss: 2.034392008217432

Epoch: 258| Step: 0
Training loss: 1.2315720319747925
Validation loss: 2.041299448218397

Epoch: 6| Step: 1
Training loss: 1.621132731437683
Validation loss: 2.0384046928856963

Epoch: 6| Step: 2
Training loss: 1.5970377922058105
Validation loss: 2.00399278056237

Epoch: 6| Step: 3
Training loss: 2.239079475402832
Validation loss: 2.052203814188639

Epoch: 6| Step: 4
Training loss: 1.4117599725723267
Validation loss: 2.0378873989146244

Epoch: 6| Step: 5
Training loss: 1.5746196508407593
Validation loss: 2.027102844689482

Epoch: 6| Step: 6
Training loss: 1.7712715864181519
Validation loss: 2.043768495641729

Epoch: 6| Step: 7
Training loss: 2.337057113647461
Validation loss: 2.0416374232179377

Epoch: 6| Step: 8
Training loss: 1.7124289274215698
Validation loss: 2.0540449465474775

Epoch: 6| Step: 9
Training loss: 1.760223388671875
Validation loss: 2.0851577610097904

Epoch: 6| Step: 10
Training loss: 2.2667224407196045
Validation loss: 2.0856407688510035

Epoch: 6| Step: 11
Training loss: 1.8719732761383057
Validation loss: 2.1295548869717504

Epoch: 6| Step: 12
Training loss: 2.451120376586914
Validation loss: 2.1164294007003948

Epoch: 6| Step: 13
Training loss: 1.6540049314498901
Validation loss: 2.112022619093618

Epoch: 259| Step: 0
Training loss: 1.1489129066467285
Validation loss: 2.0896619776243806

Epoch: 6| Step: 1
Training loss: 3.2616348266601562
Validation loss: 2.084700239601956

Epoch: 6| Step: 2
Training loss: 1.4861760139465332
Validation loss: 2.0705148173916723

Epoch: 6| Step: 3
Training loss: 1.9236925840377808
Validation loss: 2.0497772180905907

Epoch: 6| Step: 4
Training loss: 1.5309234857559204
Validation loss: 2.0547757097469863

Epoch: 6| Step: 5
Training loss: 1.9037401676177979
Validation loss: 2.0418715566717167

Epoch: 6| Step: 6
Training loss: 2.193613052368164
Validation loss: 2.064329739539854

Epoch: 6| Step: 7
Training loss: 2.166484832763672
Validation loss: 2.057895368145358

Epoch: 6| Step: 8
Training loss: 2.5931396484375
Validation loss: 2.0682113350078626

Epoch: 6| Step: 9
Training loss: 0.928338348865509
Validation loss: 2.006462186895391

Epoch: 6| Step: 10
Training loss: 0.7871530055999756
Validation loss: 2.0495355257423977

Epoch: 6| Step: 11
Training loss: 1.9619066715240479
Validation loss: 2.042438655771235

Epoch: 6| Step: 12
Training loss: 1.8551561832427979
Validation loss: 2.0004610938410603

Epoch: 6| Step: 13
Training loss: 1.4634358882904053
Validation loss: 2.0289279196851995

Epoch: 260| Step: 0
Training loss: 1.693958044052124
Validation loss: 2.0306393818188737

Epoch: 6| Step: 1
Training loss: 1.5280587673187256
Validation loss: 1.9935652107320807

Epoch: 6| Step: 2
Training loss: 1.58514404296875
Validation loss: 2.0077755489657

Epoch: 6| Step: 3
Training loss: 1.668243646621704
Validation loss: 2.0424213678606096

Epoch: 6| Step: 4
Training loss: 2.3721940517425537
Validation loss: 2.0501921869093374

Epoch: 6| Step: 5
Training loss: 1.635315179824829
Validation loss: 2.019599065985731

Epoch: 6| Step: 6
Training loss: 1.634403109550476
Validation loss: 2.0139080414208035

Epoch: 6| Step: 7
Training loss: 2.4228007793426514
Validation loss: 2.0169965426127114

Epoch: 6| Step: 8
Training loss: 1.6286810636520386
Validation loss: 2.047108483570878

Epoch: 6| Step: 9
Training loss: 1.3956849575042725
Validation loss: 2.0385998218290267

Epoch: 6| Step: 10
Training loss: 2.160470485687256
Validation loss: 2.0087405917465047

Epoch: 6| Step: 11
Training loss: 2.038515329360962
Validation loss: 2.0414350468625306

Epoch: 6| Step: 12
Training loss: 1.962327480316162
Validation loss: 2.031106161814864

Epoch: 6| Step: 13
Training loss: 1.1118559837341309
Validation loss: 2.0062901204632175

Epoch: 261| Step: 0
Training loss: 1.4290132522583008
Validation loss: 2.0172810785232054

Epoch: 6| Step: 1
Training loss: 1.855015516281128
Validation loss: 2.0434455358853905

Epoch: 6| Step: 2
Training loss: 2.2062809467315674
Validation loss: 2.0624749147763817

Epoch: 6| Step: 3
Training loss: 1.5068252086639404
Validation loss: 2.0268956281805552

Epoch: 6| Step: 4
Training loss: 2.264273166656494
Validation loss: 2.0636104511958298

Epoch: 6| Step: 5
Training loss: 2.0608980655670166
Validation loss: 2.0352423755071496

Epoch: 6| Step: 6
Training loss: 2.1121740341186523
Validation loss: 2.0330532878957768

Epoch: 6| Step: 7
Training loss: 1.8714860677719116
Validation loss: 2.0300599631442817

Epoch: 6| Step: 8
Training loss: 1.6468920707702637
Validation loss: 2.033327446188978

Epoch: 6| Step: 9
Training loss: 1.99088454246521
Validation loss: 2.02934173358384

Epoch: 6| Step: 10
Training loss: 1.123054027557373
Validation loss: 2.014169298192506

Epoch: 6| Step: 11
Training loss: 2.264816999435425
Validation loss: 2.021130363146464

Epoch: 6| Step: 12
Training loss: 0.9099785089492798
Validation loss: 2.0451906419569448

Epoch: 6| Step: 13
Training loss: 2.1476950645446777
Validation loss: 2.0567902147129016

Epoch: 262| Step: 0
Training loss: 2.0101029872894287
Validation loss: 2.0367709962270593

Epoch: 6| Step: 1
Training loss: 1.8856892585754395
Validation loss: 2.0660512716539445

Epoch: 6| Step: 2
Training loss: 2.0965776443481445
Validation loss: 2.039491186859787

Epoch: 6| Step: 3
Training loss: 1.227257251739502
Validation loss: 2.0688304849850234

Epoch: 6| Step: 4
Training loss: 1.9072387218475342
Validation loss: 2.0544714107308337

Epoch: 6| Step: 5
Training loss: 1.677431583404541
Validation loss: 2.0670457681020102

Epoch: 6| Step: 6
Training loss: 2.0651304721832275
Validation loss: 2.047657879449988

Epoch: 6| Step: 7
Training loss: 2.159959316253662
Validation loss: 2.043406614693262

Epoch: 6| Step: 8
Training loss: 1.781097650527954
Validation loss: 2.0554848563286567

Epoch: 6| Step: 9
Training loss: 1.4958993196487427
Validation loss: 2.055535493358489

Epoch: 6| Step: 10
Training loss: 1.3744752407073975
Validation loss: 2.0094212639716362

Epoch: 6| Step: 11
Training loss: 1.5220837593078613
Validation loss: 2.0467615281381915

Epoch: 6| Step: 12
Training loss: 2.031644821166992
Validation loss: 2.0702308929094704

Epoch: 6| Step: 13
Training loss: 2.032623529434204
Validation loss: 2.0310866025186356

Epoch: 263| Step: 0
Training loss: 1.5963308811187744
Validation loss: 2.020926406306605

Epoch: 6| Step: 1
Training loss: 2.6639060974121094
Validation loss: 2.0240793548604494

Epoch: 6| Step: 2
Training loss: 1.0138671398162842
Validation loss: 2.03210864784897

Epoch: 6| Step: 3
Training loss: 1.602473258972168
Validation loss: 2.0220454123712357

Epoch: 6| Step: 4
Training loss: 1.1470767259597778
Validation loss: 2.054251827219481

Epoch: 6| Step: 5
Training loss: 2.1573264598846436
Validation loss: 2.043222309440695

Epoch: 6| Step: 6
Training loss: 1.7618151903152466
Validation loss: 2.032381196175852

Epoch: 6| Step: 7
Training loss: 2.2106096744537354
Validation loss: 1.9849898058881041

Epoch: 6| Step: 8
Training loss: 1.8780078887939453
Validation loss: 2.0168443738773303

Epoch: 6| Step: 9
Training loss: 2.036123752593994
Validation loss: 2.04226351809758

Epoch: 6| Step: 10
Training loss: 1.9305042028427124
Validation loss: 2.0474509013596403

Epoch: 6| Step: 11
Training loss: 1.9083569049835205
Validation loss: 2.029256393832545

Epoch: 6| Step: 12
Training loss: 1.41353440284729
Validation loss: 2.0447664132682224

Epoch: 6| Step: 13
Training loss: 2.153883934020996
Validation loss: 2.045693177048878

Epoch: 264| Step: 0
Training loss: 1.2935302257537842
Validation loss: 2.051103352218546

Epoch: 6| Step: 1
Training loss: 1.8341888189315796
Validation loss: 2.0532790153257308

Epoch: 6| Step: 2
Training loss: 2.0375006198883057
Validation loss: 2.0598427864813034

Epoch: 6| Step: 3
Training loss: 1.723402500152588
Validation loss: 2.0390804211298623

Epoch: 6| Step: 4
Training loss: 1.8932067155838013
Validation loss: 2.0516617810854347

Epoch: 6| Step: 5
Training loss: 1.8218028545379639
Validation loss: 2.0438220731673704

Epoch: 6| Step: 6
Training loss: 2.4781293869018555
Validation loss: 2.0517645676930747

Epoch: 6| Step: 7
Training loss: 1.707369327545166
Validation loss: 2.048106775488905

Epoch: 6| Step: 8
Training loss: 1.4497196674346924
Validation loss: 2.046748779153311

Epoch: 6| Step: 9
Training loss: 1.814587116241455
Validation loss: 2.073280479318352

Epoch: 6| Step: 10
Training loss: 1.6684246063232422
Validation loss: 2.057616110770933

Epoch: 6| Step: 11
Training loss: 1.9110699892044067
Validation loss: 2.036343536069316

Epoch: 6| Step: 12
Training loss: 1.850162386894226
Validation loss: 2.063120654834214

Epoch: 6| Step: 13
Training loss: 1.7328457832336426
Validation loss: 2.0320136995725733

Epoch: 265| Step: 0
Training loss: 1.7049282789230347
Validation loss: 2.0145677110200286

Epoch: 6| Step: 1
Training loss: 2.0744099617004395
Validation loss: 2.0377336214947444

Epoch: 6| Step: 2
Training loss: 1.4022964239120483
Validation loss: 2.0652430647162983

Epoch: 6| Step: 3
Training loss: 2.244858741760254
Validation loss: 2.0455719040286158

Epoch: 6| Step: 4
Training loss: 1.2368894815444946
Validation loss: 2.041149749550768

Epoch: 6| Step: 5
Training loss: 1.1067458391189575
Validation loss: 2.0489077286053727

Epoch: 6| Step: 6
Training loss: 1.3577157258987427
Validation loss: 2.0573326797895533

Epoch: 6| Step: 7
Training loss: 2.1229350566864014
Validation loss: 2.0458540198623494

Epoch: 6| Step: 8
Training loss: 1.8759896755218506
Validation loss: 2.0381416454110095

Epoch: 6| Step: 9
Training loss: 2.0858402252197266
Validation loss: 2.0240602134376444

Epoch: 6| Step: 10
Training loss: 2.114001750946045
Validation loss: 2.0444368188099196

Epoch: 6| Step: 11
Training loss: 2.6019961833953857
Validation loss: 2.039273049241753

Epoch: 6| Step: 12
Training loss: 1.7143580913543701
Validation loss: 2.04461282683957

Epoch: 6| Step: 13
Training loss: 1.4018555879592896
Validation loss: 2.0238401325800086

Epoch: 266| Step: 0
Training loss: 1.7510786056518555
Validation loss: 2.037710464128884

Epoch: 6| Step: 1
Training loss: 1.8893364667892456
Validation loss: 2.0565782413687757

Epoch: 6| Step: 2
Training loss: 2.3278069496154785
Validation loss: 2.0333795803849415

Epoch: 6| Step: 3
Training loss: 2.262838363647461
Validation loss: 2.061678713367831

Epoch: 6| Step: 4
Training loss: 1.0958530902862549
Validation loss: 2.0386663662490023

Epoch: 6| Step: 5
Training loss: 1.9507347345352173
Validation loss: 2.068260000598046

Epoch: 6| Step: 6
Training loss: 1.729367971420288
Validation loss: 2.058181602467773

Epoch: 6| Step: 7
Training loss: 1.4144880771636963
Validation loss: 2.017307307130547

Epoch: 6| Step: 8
Training loss: 1.8583850860595703
Validation loss: 2.029247494154079

Epoch: 6| Step: 9
Training loss: 1.8821741342544556
Validation loss: 2.0776923330881263

Epoch: 6| Step: 10
Training loss: 2.1195991039276123
Validation loss: 2.0399465509640273

Epoch: 6| Step: 11
Training loss: 2.0418851375579834
Validation loss: 2.0608850691908147

Epoch: 6| Step: 12
Training loss: 1.1507759094238281
Validation loss: 2.0579976445885113

Epoch: 6| Step: 13
Training loss: 1.439161777496338
Validation loss: 2.065034011358856

Epoch: 267| Step: 0
Training loss: 1.469069004058838
Validation loss: 2.040266849661386

Epoch: 6| Step: 1
Training loss: 1.135212779045105
Validation loss: 2.078645461349077

Epoch: 6| Step: 2
Training loss: 1.2570977210998535
Validation loss: 2.0411475114924933

Epoch: 6| Step: 3
Training loss: 2.216642379760742
Validation loss: 2.0515079729018675

Epoch: 6| Step: 4
Training loss: 2.110534906387329
Validation loss: 2.054943787154331

Epoch: 6| Step: 5
Training loss: 2.1273751258850098
Validation loss: 2.0798949451856714

Epoch: 6| Step: 6
Training loss: 2.0611727237701416
Validation loss: 2.096869663525653

Epoch: 6| Step: 7
Training loss: 1.3552367687225342
Validation loss: 2.078813301619663

Epoch: 6| Step: 8
Training loss: 1.9262083768844604
Validation loss: 2.064126886347289

Epoch: 6| Step: 9
Training loss: 1.8519725799560547
Validation loss: 2.0848862791574128

Epoch: 6| Step: 10
Training loss: 1.7776730060577393
Validation loss: 2.0385808893429336

Epoch: 6| Step: 11
Training loss: 2.0767617225646973
Validation loss: 2.0412248565304663

Epoch: 6| Step: 12
Training loss: 2.5887670516967773
Validation loss: 2.0310024087147047

Epoch: 6| Step: 13
Training loss: 1.0967522859573364
Validation loss: 2.0396917763576714

Epoch: 268| Step: 0
Training loss: 1.7272827625274658
Validation loss: 2.06177463710949

Epoch: 6| Step: 1
Training loss: 1.6918513774871826
Validation loss: 2.013128020430124

Epoch: 6| Step: 2
Training loss: 1.7064236402511597
Validation loss: 2.044048168325937

Epoch: 6| Step: 3
Training loss: 1.264782190322876
Validation loss: 2.0567840427480717

Epoch: 6| Step: 4
Training loss: 1.7045714855194092
Validation loss: 2.044382467064806

Epoch: 6| Step: 5
Training loss: 2.3584229946136475
Validation loss: 2.080567080487487

Epoch: 6| Step: 6
Training loss: 1.6365811824798584
Validation loss: 2.0505441914322557

Epoch: 6| Step: 7
Training loss: 1.7594259977340698
Validation loss: 2.03416355194584

Epoch: 6| Step: 8
Training loss: 1.044740080833435
Validation loss: 2.022900419850503

Epoch: 6| Step: 9
Training loss: 2.349351644515991
Validation loss: 2.0514664316690094

Epoch: 6| Step: 10
Training loss: 2.291733503341675
Validation loss: 2.070796398706334

Epoch: 6| Step: 11
Training loss: 1.5701687335968018
Validation loss: 2.062066775496288

Epoch: 6| Step: 12
Training loss: 1.581510066986084
Validation loss: 2.0512531547136206

Epoch: 6| Step: 13
Training loss: 2.9456870555877686
Validation loss: 2.041090423061002

Epoch: 269| Step: 0
Training loss: 1.6847240924835205
Validation loss: 2.0562294836967223

Epoch: 6| Step: 1
Training loss: 1.671834945678711
Validation loss: 2.0493831660157893

Epoch: 6| Step: 2
Training loss: 1.2650151252746582
Validation loss: 2.040471182074598

Epoch: 6| Step: 3
Training loss: 1.4660674333572388
Validation loss: 2.0558957233223865

Epoch: 6| Step: 4
Training loss: 1.800410270690918
Validation loss: 2.0251097884229434

Epoch: 6| Step: 5
Training loss: 1.7663121223449707
Validation loss: 2.0569142641559726

Epoch: 6| Step: 6
Training loss: 1.345564842224121
Validation loss: 2.0875564134249123

Epoch: 6| Step: 7
Training loss: 2.039297342300415
Validation loss: 2.0800126419272473

Epoch: 6| Step: 8
Training loss: 2.0747451782226562
Validation loss: 2.069967390388571

Epoch: 6| Step: 9
Training loss: 2.214674234390259
Validation loss: 2.037909410333121

Epoch: 6| Step: 10
Training loss: 2.256486654281616
Validation loss: 2.089060624440511

Epoch: 6| Step: 11
Training loss: 1.7196898460388184
Validation loss: 2.038172815435676

Epoch: 6| Step: 12
Training loss: 1.8685767650604248
Validation loss: 2.042681783758184

Epoch: 6| Step: 13
Training loss: 2.2460851669311523
Validation loss: 2.0134552678754254

Epoch: 270| Step: 0
Training loss: 2.2217907905578613
Validation loss: 2.026014784330963

Epoch: 6| Step: 1
Training loss: 1.1955443620681763
Validation loss: 2.0281171849978867

Epoch: 6| Step: 2
Training loss: 1.4559837579727173
Validation loss: 2.052442551941

Epoch: 6| Step: 3
Training loss: 1.939300537109375
Validation loss: 2.0233738332666378

Epoch: 6| Step: 4
Training loss: 1.1686937808990479
Validation loss: 2.051857861139441

Epoch: 6| Step: 5
Training loss: 1.9356753826141357
Validation loss: 2.0505879040687316

Epoch: 6| Step: 6
Training loss: 1.5930908918380737
Validation loss: 2.0399390651333715

Epoch: 6| Step: 7
Training loss: 2.241964817047119
Validation loss: 2.0572257298295216

Epoch: 6| Step: 8
Training loss: 1.3276472091674805
Validation loss: 2.0621164280881166

Epoch: 6| Step: 9
Training loss: 1.7139683961868286
Validation loss: 2.0618431901419036

Epoch: 6| Step: 10
Training loss: 2.242522954940796
Validation loss: 2.0301571123061644

Epoch: 6| Step: 11
Training loss: 2.1966943740844727
Validation loss: 2.0540884707563665

Epoch: 6| Step: 12
Training loss: 1.925570011138916
Validation loss: 2.054853141948741

Epoch: 6| Step: 13
Training loss: 1.6520507335662842
Validation loss: 2.065440785500311

Epoch: 271| Step: 0
Training loss: 1.8539543151855469
Validation loss: 2.027205628733481

Epoch: 6| Step: 1
Training loss: 2.7376954555511475
Validation loss: 2.0564537509795158

Epoch: 6| Step: 2
Training loss: 1.7102570533752441
Validation loss: 2.048584686812534

Epoch: 6| Step: 3
Training loss: 1.853644609451294
Validation loss: 2.013605220343477

Epoch: 6| Step: 4
Training loss: 1.3625226020812988
Validation loss: 2.044555200043545

Epoch: 6| Step: 5
Training loss: 1.5298224687576294
Validation loss: 2.066746172084603

Epoch: 6| Step: 6
Training loss: 1.3522212505340576
Validation loss: 2.0665410410973335

Epoch: 6| Step: 7
Training loss: 1.6563745737075806
Validation loss: 2.0586397083856727

Epoch: 6| Step: 8
Training loss: 1.6601734161376953
Validation loss: 2.0255359782967517

Epoch: 6| Step: 9
Training loss: 1.760983943939209
Validation loss: 2.095449601450274

Epoch: 6| Step: 10
Training loss: 1.187645673751831
Validation loss: 2.0452406201311337

Epoch: 6| Step: 11
Training loss: 2.549739360809326
Validation loss: 2.055652881181368

Epoch: 6| Step: 12
Training loss: 1.9299874305725098
Validation loss: 2.0381597831685054

Epoch: 6| Step: 13
Training loss: 1.9300202131271362
Validation loss: 2.0361454807302004

Epoch: 272| Step: 0
Training loss: 1.7157154083251953
Validation loss: 2.0286675242967505

Epoch: 6| Step: 1
Training loss: 2.4056529998779297
Validation loss: 2.04524508342948

Epoch: 6| Step: 2
Training loss: 1.623329520225525
Validation loss: 2.0488892063017814

Epoch: 6| Step: 3
Training loss: 1.2227420806884766
Validation loss: 2.0421958072211153

Epoch: 6| Step: 4
Training loss: 2.120269775390625
Validation loss: 2.002975317739671

Epoch: 6| Step: 5
Training loss: 1.3576833009719849
Validation loss: 1.9871934742055914

Epoch: 6| Step: 6
Training loss: 2.1595325469970703
Validation loss: 2.056867448232507

Epoch: 6| Step: 7
Training loss: 2.3407020568847656
Validation loss: 2.0172001495156238

Epoch: 6| Step: 8
Training loss: 1.8250128030776978
Validation loss: 2.0339546101067656

Epoch: 6| Step: 9
Training loss: 1.7358500957489014
Validation loss: 2.01972803120972

Epoch: 6| Step: 10
Training loss: 1.9492688179016113
Validation loss: 2.024451340398481

Epoch: 6| Step: 11
Training loss: 1.2630820274353027
Validation loss: 2.029481719898921

Epoch: 6| Step: 12
Training loss: 1.682274580001831
Validation loss: 2.041102925936381

Epoch: 6| Step: 13
Training loss: 1.9028958082199097
Validation loss: 2.038891183432712

Epoch: 273| Step: 0
Training loss: 1.4610867500305176
Validation loss: 2.0348001833884948

Epoch: 6| Step: 1
Training loss: 1.2373242378234863
Validation loss: 2.0365352489615

Epoch: 6| Step: 2
Training loss: 1.9761700630187988
Validation loss: 2.090039309634957

Epoch: 6| Step: 3
Training loss: 1.9271793365478516
Validation loss: 2.074429117223268

Epoch: 6| Step: 4
Training loss: 1.7745898962020874
Validation loss: 2.105099865185317

Epoch: 6| Step: 5
Training loss: 2.2408478260040283
Validation loss: 2.0986086553142917

Epoch: 6| Step: 6
Training loss: 1.9488581418991089
Validation loss: 2.1159872726727555

Epoch: 6| Step: 7
Training loss: 2.1182196140289307
Validation loss: 2.08844913974885

Epoch: 6| Step: 8
Training loss: 1.88736891746521
Validation loss: 2.067364109459744

Epoch: 6| Step: 9
Training loss: 1.6638057231903076
Validation loss: 2.0841042687816005

Epoch: 6| Step: 10
Training loss: 1.8573068380355835
Validation loss: 2.107260073384931

Epoch: 6| Step: 11
Training loss: 1.7161048650741577
Validation loss: 2.076450570937126

Epoch: 6| Step: 12
Training loss: 1.5895265340805054
Validation loss: 2.0649168004271803

Epoch: 6| Step: 13
Training loss: 1.621207594871521
Validation loss: 2.0561350032847416

Epoch: 274| Step: 0
Training loss: 1.701878547668457
Validation loss: 2.063989522636578

Epoch: 6| Step: 1
Training loss: 2.0789947509765625
Validation loss: 2.0549375600712274

Epoch: 6| Step: 2
Training loss: 2.2788736820220947
Validation loss: 2.0957404951895438

Epoch: 6| Step: 3
Training loss: 2.037252902984619
Validation loss: 2.039865642465571

Epoch: 6| Step: 4
Training loss: 1.8664875030517578
Validation loss: 2.0389728969143284

Epoch: 6| Step: 5
Training loss: 1.0101040601730347
Validation loss: 2.058724416199551

Epoch: 6| Step: 6
Training loss: 1.1960886716842651
Validation loss: 2.0790079716713197

Epoch: 6| Step: 7
Training loss: 1.2084717750549316
Validation loss: 2.0735745660720335

Epoch: 6| Step: 8
Training loss: 2.097008228302002
Validation loss: 2.0496447599062355

Epoch: 6| Step: 9
Training loss: 1.8858413696289062
Validation loss: 2.0398143978529077

Epoch: 6| Step: 10
Training loss: 1.5594909191131592
Validation loss: 2.0727177666079615

Epoch: 6| Step: 11
Training loss: 1.8798679113388062
Validation loss: 2.0672675691625124

Epoch: 6| Step: 12
Training loss: 2.105903387069702
Validation loss: 2.0608051925577144

Epoch: 6| Step: 13
Training loss: 1.826204538345337
Validation loss: 2.0599333906686432

Epoch: 275| Step: 0
Training loss: 1.6918188333511353
Validation loss: 2.040807504807749

Epoch: 6| Step: 1
Training loss: 1.9060767889022827
Validation loss: 2.0773914014139483

Epoch: 6| Step: 2
Training loss: 1.773306131362915
Validation loss: 2.0897612558898104

Epoch: 6| Step: 3
Training loss: 1.2739073038101196
Validation loss: 2.097193958938763

Epoch: 6| Step: 4
Training loss: 1.7486294507980347
Validation loss: 2.080107629940074

Epoch: 6| Step: 5
Training loss: 1.534988522529602
Validation loss: 2.0742718917067333

Epoch: 6| Step: 6
Training loss: 1.952165961265564
Validation loss: 2.1093088529443227

Epoch: 6| Step: 7
Training loss: 1.4890878200531006
Validation loss: 2.0692828752661265

Epoch: 6| Step: 8
Training loss: 2.4094014167785645
Validation loss: 2.0774433202640985

Epoch: 6| Step: 9
Training loss: 2.0737199783325195
Validation loss: 2.0572063615245204

Epoch: 6| Step: 10
Training loss: 1.5239278078079224
Validation loss: 2.062080849883377

Epoch: 6| Step: 11
Training loss: 1.7066411972045898
Validation loss: 2.0639941666715886

Epoch: 6| Step: 12
Training loss: 1.4105695486068726
Validation loss: 2.061838411515759

Epoch: 6| Step: 13
Training loss: 2.5622334480285645
Validation loss: 2.064555614225326

Epoch: 276| Step: 0
Training loss: 1.3291492462158203
Validation loss: 2.052656904343636

Epoch: 6| Step: 1
Training loss: 2.200504779815674
Validation loss: 2.011206570491996

Epoch: 6| Step: 2
Training loss: 1.5699875354766846
Validation loss: 2.029759404479816

Epoch: 6| Step: 3
Training loss: 0.7803694009780884
Validation loss: 2.055723382580665

Epoch: 6| Step: 4
Training loss: 1.3945244550704956
Validation loss: 2.060484287559345

Epoch: 6| Step: 5
Training loss: 1.9165064096450806
Validation loss: 2.023257456799989

Epoch: 6| Step: 6
Training loss: 2.3078701496124268
Validation loss: 2.029042431103286

Epoch: 6| Step: 7
Training loss: 2.2329444885253906
Validation loss: 2.034390026523221

Epoch: 6| Step: 8
Training loss: 2.231984853744507
Validation loss: 2.0554102902771323

Epoch: 6| Step: 9
Training loss: 1.4801266193389893
Validation loss: 2.053989197618218

Epoch: 6| Step: 10
Training loss: 2.6478536128997803
Validation loss: 1.9987861007772467

Epoch: 6| Step: 11
Training loss: 1.540797233581543
Validation loss: 2.0284331870335404

Epoch: 6| Step: 12
Training loss: 1.5457401275634766
Validation loss: 2.048892423670779

Epoch: 6| Step: 13
Training loss: 1.7997546195983887
Validation loss: 2.0620377640570364

Epoch: 277| Step: 0
Training loss: 1.4266765117645264
Validation loss: 2.0478005101603847

Epoch: 6| Step: 1
Training loss: 1.4110443592071533
Validation loss: 2.0799532603192072

Epoch: 6| Step: 2
Training loss: 2.477877616882324
Validation loss: 2.1023138671792965

Epoch: 6| Step: 3
Training loss: 2.174330234527588
Validation loss: 2.149393057310453

Epoch: 6| Step: 4
Training loss: 2.058427333831787
Validation loss: 2.1186583042144775

Epoch: 6| Step: 5
Training loss: 1.465424656867981
Validation loss: 2.125365102162925

Epoch: 6| Step: 6
Training loss: 1.604222297668457
Validation loss: 2.161097954678279

Epoch: 6| Step: 7
Training loss: 1.6364078521728516
Validation loss: 2.1418744107728362

Epoch: 6| Step: 8
Training loss: 1.6961160898208618
Validation loss: 2.1094183127085366

Epoch: 6| Step: 9
Training loss: 2.0490167140960693
Validation loss: 2.109703046019359

Epoch: 6| Step: 10
Training loss: 1.7766704559326172
Validation loss: 2.114360508098397

Epoch: 6| Step: 11
Training loss: 2.1304373741149902
Validation loss: 2.0791941137724024

Epoch: 6| Step: 12
Training loss: 1.5059195756912231
Validation loss: 2.0940491102075063

Epoch: 6| Step: 13
Training loss: 1.6127585172653198
Validation loss: 2.0664144151954242

Epoch: 278| Step: 0
Training loss: 1.697094440460205
Validation loss: 2.0780252602792557

Epoch: 6| Step: 1
Training loss: 1.3762282133102417
Validation loss: 2.048595013157014

Epoch: 6| Step: 2
Training loss: 1.5250811576843262
Validation loss: 2.059197800133818

Epoch: 6| Step: 3
Training loss: 1.8631916046142578
Validation loss: 2.060007591401377

Epoch: 6| Step: 4
Training loss: 2.2032220363616943
Validation loss: 2.0453291580241215

Epoch: 6| Step: 5
Training loss: 1.883209466934204
Validation loss: 2.068388431302963

Epoch: 6| Step: 6
Training loss: 1.5992050170898438
Validation loss: 2.0317706190129763

Epoch: 6| Step: 7
Training loss: 1.8775111436843872
Validation loss: 2.021000231465986

Epoch: 6| Step: 8
Training loss: 2.13320255279541
Validation loss: 2.0291723448743104

Epoch: 6| Step: 9
Training loss: 1.536858081817627
Validation loss: 2.046947899685111

Epoch: 6| Step: 10
Training loss: 1.892174243927002
Validation loss: 2.019813709361579

Epoch: 6| Step: 11
Training loss: 2.030984401702881
Validation loss: 2.023959631560951

Epoch: 6| Step: 12
Training loss: 1.6306798458099365
Validation loss: 2.00636350980369

Epoch: 6| Step: 13
Training loss: 1.193967342376709
Validation loss: 2.0162307998185516

Epoch: 279| Step: 0
Training loss: 1.3507838249206543
Validation loss: 2.0143185277138986

Epoch: 6| Step: 1
Training loss: 1.4027553796768188
Validation loss: 2.019975503285726

Epoch: 6| Step: 2
Training loss: 1.2980955839157104
Validation loss: 2.0495890584043277

Epoch: 6| Step: 3
Training loss: 2.066605806350708
Validation loss: 2.056935005290534

Epoch: 6| Step: 4
Training loss: 1.823547124862671
Validation loss: 2.069143000469413

Epoch: 6| Step: 5
Training loss: 1.2950540781021118
Validation loss: 2.072279648114276

Epoch: 6| Step: 6
Training loss: 1.9608452320098877
Validation loss: 2.050753112762205

Epoch: 6| Step: 7
Training loss: 2.0460357666015625
Validation loss: 2.0582394856278614

Epoch: 6| Step: 8
Training loss: 1.915320873260498
Validation loss: 2.060808975209472

Epoch: 6| Step: 9
Training loss: 2.4135568141937256
Validation loss: 2.0724447183711554

Epoch: 6| Step: 10
Training loss: 1.7088828086853027
Validation loss: 2.0167939842388196

Epoch: 6| Step: 11
Training loss: 1.9175240993499756
Validation loss: 2.0550000359935146

Epoch: 6| Step: 12
Training loss: 1.4017817974090576
Validation loss: 2.038925927172425

Epoch: 6| Step: 13
Training loss: 2.211240530014038
Validation loss: 2.0722155160801385

Epoch: 280| Step: 0
Training loss: 2.0636682510375977
Validation loss: 2.0813039746335757

Epoch: 6| Step: 1
Training loss: 1.2519168853759766
Validation loss: 2.0168827349139797

Epoch: 6| Step: 2
Training loss: 2.165520668029785
Validation loss: 2.0560457706451416

Epoch: 6| Step: 3
Training loss: 1.41416597366333
Validation loss: 2.0722113809277936

Epoch: 6| Step: 4
Training loss: 1.560220718383789
Validation loss: 2.0677530650169618

Epoch: 6| Step: 5
Training loss: 2.5827836990356445
Validation loss: 2.0595011147119666

Epoch: 6| Step: 6
Training loss: 1.1394569873809814
Validation loss: 2.005831303135041

Epoch: 6| Step: 7
Training loss: 2.0287084579467773
Validation loss: 2.0492346543137745

Epoch: 6| Step: 8
Training loss: 1.764109492301941
Validation loss: 2.048228117727464

Epoch: 6| Step: 9
Training loss: 2.1715211868286133
Validation loss: 2.0237016062582693

Epoch: 6| Step: 10
Training loss: 1.8169375658035278
Validation loss: 2.0307063005303823

Epoch: 6| Step: 11
Training loss: 1.7644122838974
Validation loss: 2.0681793382090907

Epoch: 6| Step: 12
Training loss: 1.6469428539276123
Validation loss: 2.0520816387668734

Epoch: 6| Step: 13
Training loss: 1.0519262552261353
Validation loss: 2.056004167884909

Epoch: 281| Step: 0
Training loss: 1.9802954196929932
Validation loss: 2.016934084635909

Epoch: 6| Step: 1
Training loss: 1.9254469871520996
Validation loss: 2.0766430990670317

Epoch: 6| Step: 2
Training loss: 1.9825730323791504
Validation loss: 2.05767628710757

Epoch: 6| Step: 3
Training loss: 1.4289259910583496
Validation loss: 2.0452674409394622

Epoch: 6| Step: 4
Training loss: 2.018071174621582
Validation loss: 2.052709105194256

Epoch: 6| Step: 5
Training loss: 1.757474422454834
Validation loss: 2.0809279975070747

Epoch: 6| Step: 6
Training loss: 1.8991320133209229
Validation loss: 2.0734447151102047

Epoch: 6| Step: 7
Training loss: 1.9275288581848145
Validation loss: 2.081052521223663

Epoch: 6| Step: 8
Training loss: 1.5269132852554321
Validation loss: 2.0800759612873034

Epoch: 6| Step: 9
Training loss: 1.6043989658355713
Validation loss: 2.0362125032691547

Epoch: 6| Step: 10
Training loss: 1.8749942779541016
Validation loss: 2.0675683483000724

Epoch: 6| Step: 11
Training loss: 1.350985050201416
Validation loss: 2.061181626012248

Epoch: 6| Step: 12
Training loss: 1.5970633029937744
Validation loss: 2.042254219772995

Epoch: 6| Step: 13
Training loss: 1.7663568258285522
Validation loss: 2.0656229321674635

Epoch: 282| Step: 0
Training loss: 1.362654447555542
Validation loss: 2.0697092817675684

Epoch: 6| Step: 1
Training loss: 1.6468846797943115
Validation loss: 2.0388027903854207

Epoch: 6| Step: 2
Training loss: 1.722182035446167
Validation loss: 2.0651299004913657

Epoch: 6| Step: 3
Training loss: 2.681889057159424
Validation loss: 2.014246952149176

Epoch: 6| Step: 4
Training loss: 2.0281872749328613
Validation loss: 2.047749739821239

Epoch: 6| Step: 5
Training loss: 2.3171470165252686
Validation loss: 2.041653463917394

Epoch: 6| Step: 6
Training loss: 1.7617290019989014
Validation loss: 2.0657308793837026

Epoch: 6| Step: 7
Training loss: 1.4327974319458008
Validation loss: 2.0624884084988664

Epoch: 6| Step: 8
Training loss: 1.3189700841903687
Validation loss: 2.0680819147376606

Epoch: 6| Step: 9
Training loss: 2.009673595428467
Validation loss: 2.057849942996938

Epoch: 6| Step: 10
Training loss: 1.6106926202774048
Validation loss: 2.0578072455621537

Epoch: 6| Step: 11
Training loss: 1.4740798473358154
Validation loss: 2.0502674553983953

Epoch: 6| Step: 12
Training loss: 1.412585735321045
Validation loss: 2.0753353411151516

Epoch: 6| Step: 13
Training loss: 1.7714622020721436
Validation loss: 2.061299649618005

Epoch: 283| Step: 0
Training loss: 2.0497114658355713
Validation loss: 2.033160819802233

Epoch: 6| Step: 1
Training loss: 1.7556557655334473
Validation loss: 2.0284224120519494

Epoch: 6| Step: 2
Training loss: 2.031829357147217
Validation loss: 2.0570043440788024

Epoch: 6| Step: 3
Training loss: 2.2456650733947754
Validation loss: 2.026973698728828

Epoch: 6| Step: 4
Training loss: 1.5971660614013672
Validation loss: 2.0371985691849903

Epoch: 6| Step: 5
Training loss: 1.5171008110046387
Validation loss: 2.0671424096630466

Epoch: 6| Step: 6
Training loss: 1.484089732170105
Validation loss: 2.0550658100394794

Epoch: 6| Step: 7
Training loss: 1.308758020401001
Validation loss: 2.0544630199350338

Epoch: 6| Step: 8
Training loss: 1.7680165767669678
Validation loss: 2.011769910012522

Epoch: 6| Step: 9
Training loss: 2.2537989616394043
Validation loss: 2.057120812836514

Epoch: 6| Step: 10
Training loss: 1.2761526107788086
Validation loss: 2.022690285918533

Epoch: 6| Step: 11
Training loss: 1.8391838073730469
Validation loss: 2.0552389519188994

Epoch: 6| Step: 12
Training loss: 2.1523070335388184
Validation loss: 2.0456702017015025

Epoch: 6| Step: 13
Training loss: 0.843195915222168
Validation loss: 2.0135436955318657

Epoch: 284| Step: 0
Training loss: 1.1253868341445923
Validation loss: 2.0592929611923876

Epoch: 6| Step: 1
Training loss: 1.410632848739624
Validation loss: 2.060674968586173

Epoch: 6| Step: 2
Training loss: 1.3648139238357544
Validation loss: 2.0441778962330153

Epoch: 6| Step: 3
Training loss: 2.303882122039795
Validation loss: 2.046376984606507

Epoch: 6| Step: 4
Training loss: 1.4631109237670898
Validation loss: 2.048024553124623

Epoch: 6| Step: 5
Training loss: 2.4442248344421387
Validation loss: 2.0329815521035144

Epoch: 6| Step: 6
Training loss: 1.589029312133789
Validation loss: 2.0434783222854778

Epoch: 6| Step: 7
Training loss: 1.5121045112609863
Validation loss: 2.083914872138731

Epoch: 6| Step: 8
Training loss: 1.9714200496673584
Validation loss: 2.0439029534657798

Epoch: 6| Step: 9
Training loss: 1.712054967880249
Validation loss: 2.069223101421069

Epoch: 6| Step: 10
Training loss: 1.723826289176941
Validation loss: 2.066165203689247

Epoch: 6| Step: 11
Training loss: 2.4183812141418457
Validation loss: 2.0465969193366265

Epoch: 6| Step: 12
Training loss: 1.3869664669036865
Validation loss: 2.0738100390280447

Epoch: 6| Step: 13
Training loss: 2.146150827407837
Validation loss: 2.026275352765155

Epoch: 285| Step: 0
Training loss: 1.7672185897827148
Validation loss: 2.0645225124974407

Epoch: 6| Step: 1
Training loss: 1.523871898651123
Validation loss: 2.081617198964601

Epoch: 6| Step: 2
Training loss: 0.825041651725769
Validation loss: 2.0254498271531958

Epoch: 6| Step: 3
Training loss: 2.5029921531677246
Validation loss: 2.0571766309840704

Epoch: 6| Step: 4
Training loss: 1.6690740585327148
Validation loss: 2.021136547929497

Epoch: 6| Step: 5
Training loss: 1.9009056091308594
Validation loss: 2.0369568896550003

Epoch: 6| Step: 6
Training loss: 1.827846884727478
Validation loss: 2.019620026311567

Epoch: 6| Step: 7
Training loss: 1.7676401138305664
Validation loss: 2.077700730293028

Epoch: 6| Step: 8
Training loss: 1.9702508449554443
Validation loss: 2.0211083184006395

Epoch: 6| Step: 9
Training loss: 1.5106925964355469
Validation loss: 2.076761689237369

Epoch: 6| Step: 10
Training loss: 1.5620077848434448
Validation loss: 2.058013872433734

Epoch: 6| Step: 11
Training loss: 2.192903757095337
Validation loss: 2.067175308863322

Epoch: 6| Step: 12
Training loss: 2.011604070663452
Validation loss: 2.082781199486025

Epoch: 6| Step: 13
Training loss: 0.9840210676193237
Validation loss: 2.0819074184663835

Epoch: 286| Step: 0
Training loss: 1.7985049486160278
Validation loss: 2.0647549513847596

Epoch: 6| Step: 1
Training loss: 1.9319751262664795
Validation loss: 2.072500078908859

Epoch: 6| Step: 2
Training loss: 2.126199722290039
Validation loss: 2.0808869766932663

Epoch: 6| Step: 3
Training loss: 1.3022489547729492
Validation loss: 2.062804655362201

Epoch: 6| Step: 4
Training loss: 2.3018391132354736
Validation loss: 2.034155317532119

Epoch: 6| Step: 5
Training loss: 0.9143427014350891
Validation loss: 2.076527308392268

Epoch: 6| Step: 6
Training loss: 2.047532320022583
Validation loss: 2.070480392825219

Epoch: 6| Step: 7
Training loss: 2.0593156814575195
Validation loss: 2.060733925911688

Epoch: 6| Step: 8
Training loss: 1.7220370769500732
Validation loss: 2.064972787775019

Epoch: 6| Step: 9
Training loss: 1.4943134784698486
Validation loss: 2.077560173567905

Epoch: 6| Step: 10
Training loss: 2.24176025390625
Validation loss: 2.051098954293036

Epoch: 6| Step: 11
Training loss: 1.3944724798202515
Validation loss: 2.0549799344872914

Epoch: 6| Step: 12
Training loss: 1.3676190376281738
Validation loss: 2.050447725480603

Epoch: 6| Step: 13
Training loss: 1.6850318908691406
Validation loss: 2.0684943352976153

Epoch: 287| Step: 0
Training loss: 1.8620715141296387
Validation loss: 2.0529293219248452

Epoch: 6| Step: 1
Training loss: 2.4373581409454346
Validation loss: 2.041574280749085

Epoch: 6| Step: 2
Training loss: 1.852952480316162
Validation loss: 2.0259004216040335

Epoch: 6| Step: 3
Training loss: 1.7472443580627441
Validation loss: 2.0086950743070213

Epoch: 6| Step: 4
Training loss: 2.3173248767852783
Validation loss: 2.0098073661968274

Epoch: 6| Step: 5
Training loss: 1.6070358753204346
Validation loss: 2.0109104905077206

Epoch: 6| Step: 6
Training loss: 1.6941590309143066
Validation loss: 2.053538514721778

Epoch: 6| Step: 7
Training loss: 1.6381747722625732
Validation loss: 2.022078223125909

Epoch: 6| Step: 8
Training loss: 2.0639586448669434
Validation loss: 2.017604867617289

Epoch: 6| Step: 9
Training loss: 0.8988896608352661
Validation loss: 2.0299552307333997

Epoch: 6| Step: 10
Training loss: 1.681238055229187
Validation loss: 2.03468237128309

Epoch: 6| Step: 11
Training loss: 1.867275595664978
Validation loss: 2.0223215267222416

Epoch: 6| Step: 12
Training loss: 1.3694772720336914
Validation loss: 2.032077375278678

Epoch: 6| Step: 13
Training loss: 2.1102633476257324
Validation loss: 2.033840507589361

Epoch: 288| Step: 0
Training loss: 1.9977390766143799
Validation loss: 2.058469982557399

Epoch: 6| Step: 1
Training loss: 1.8474451303482056
Validation loss: 2.0615501224353747

Epoch: 6| Step: 2
Training loss: 1.365438461303711
Validation loss: 2.1030527930105887

Epoch: 6| Step: 3
Training loss: 1.4974006414413452
Validation loss: 2.102839926237701

Epoch: 6| Step: 4
Training loss: 1.478346347808838
Validation loss: 2.0846593610702024

Epoch: 6| Step: 5
Training loss: 1.712310552597046
Validation loss: 2.097124053585914

Epoch: 6| Step: 6
Training loss: 1.7067675590515137
Validation loss: 2.105720270064569

Epoch: 6| Step: 7
Training loss: 1.756764531135559
Validation loss: 2.0938611556124944

Epoch: 6| Step: 8
Training loss: 1.5557878017425537
Validation loss: 2.035034533469908

Epoch: 6| Step: 9
Training loss: 1.4645955562591553
Validation loss: 2.0460686478563535

Epoch: 6| Step: 10
Training loss: 1.9894773960113525
Validation loss: 2.0699406593076644

Epoch: 6| Step: 11
Training loss: 2.205289840698242
Validation loss: 2.09463172189651

Epoch: 6| Step: 12
Training loss: 1.7582097053527832
Validation loss: 2.074257012336485

Epoch: 6| Step: 13
Training loss: 2.5032424926757812
Validation loss: 2.0622348823855

Epoch: 289| Step: 0
Training loss: 2.021029233932495
Validation loss: 2.061517641108523

Epoch: 6| Step: 1
Training loss: 1.6500890254974365
Validation loss: 2.080783967048891

Epoch: 6| Step: 2
Training loss: 1.8251235485076904
Validation loss: 2.04544876211433

Epoch: 6| Step: 3
Training loss: 1.7765154838562012
Validation loss: 2.067526363557385

Epoch: 6| Step: 4
Training loss: 1.284095048904419
Validation loss: 2.0620757559294343

Epoch: 6| Step: 5
Training loss: 2.220933437347412
Validation loss: 2.08068173931491

Epoch: 6| Step: 6
Training loss: 2.030360221862793
Validation loss: 2.0300971487517

Epoch: 6| Step: 7
Training loss: 1.460118293762207
Validation loss: 2.0567522279677855

Epoch: 6| Step: 8
Training loss: 1.546824336051941
Validation loss: 2.0503275253439464

Epoch: 6| Step: 9
Training loss: 1.1952793598175049
Validation loss: 2.0753112890387095

Epoch: 6| Step: 10
Training loss: 2.251950263977051
Validation loss: 2.0481938239066833

Epoch: 6| Step: 11
Training loss: 1.871600866317749
Validation loss: 2.062106163271012

Epoch: 6| Step: 12
Training loss: 2.0443873405456543
Validation loss: 2.0988436514331448

Epoch: 6| Step: 13
Training loss: 0.8850929737091064
Validation loss: 2.076895644587855

Epoch: 290| Step: 0
Training loss: 1.3885626792907715
Validation loss: 2.0671445272302114

Epoch: 6| Step: 1
Training loss: 1.3726673126220703
Validation loss: 2.0938114555933143

Epoch: 6| Step: 2
Training loss: 2.0309383869171143
Validation loss: 2.0306751804967083

Epoch: 6| Step: 3
Training loss: 1.6486186981201172
Validation loss: 2.0368050400928785

Epoch: 6| Step: 4
Training loss: 1.293721079826355
Validation loss: 2.025417712426955

Epoch: 6| Step: 5
Training loss: 1.82200288772583
Validation loss: 2.078828957773024

Epoch: 6| Step: 6
Training loss: 1.7052302360534668
Validation loss: 2.0625214448539158

Epoch: 6| Step: 7
Training loss: 1.8220691680908203
Validation loss: 2.0722426804163123

Epoch: 6| Step: 8
Training loss: 2.0941598415374756
Validation loss: 2.023247507310683

Epoch: 6| Step: 9
Training loss: 1.6710261106491089
Validation loss: 2.0222851332797798

Epoch: 6| Step: 10
Training loss: 2.550790786743164
Validation loss: 2.0379375103981263

Epoch: 6| Step: 11
Training loss: 1.6373310089111328
Validation loss: 2.060045983201714

Epoch: 6| Step: 12
Training loss: 1.7976186275482178
Validation loss: 2.0680881187479985

Epoch: 6| Step: 13
Training loss: 1.3825504779815674
Validation loss: 2.054359045079959

Epoch: 291| Step: 0
Training loss: 2.5261483192443848
Validation loss: 2.0668360648616666

Epoch: 6| Step: 1
Training loss: 1.4975683689117432
Validation loss: 2.071505133823682

Epoch: 6| Step: 2
Training loss: 2.006077289581299
Validation loss: 2.109255706110308

Epoch: 6| Step: 3
Training loss: 2.104865550994873
Validation loss: 2.0849943058465117

Epoch: 6| Step: 4
Training loss: 1.9144527912139893
Validation loss: 2.088519392475005

Epoch: 6| Step: 5
Training loss: 1.854624629020691
Validation loss: 2.088869056394023

Epoch: 6| Step: 6
Training loss: 2.00106143951416
Validation loss: 2.0563660975425475

Epoch: 6| Step: 7
Training loss: 1.715036392211914
Validation loss: 2.0568342695954027

Epoch: 6| Step: 8
Training loss: 1.1060168743133545
Validation loss: 2.049144826909547

Epoch: 6| Step: 9
Training loss: 1.1411328315734863
Validation loss: 2.082316114056495

Epoch: 6| Step: 10
Training loss: 1.7537972927093506
Validation loss: 2.048205970436014

Epoch: 6| Step: 11
Training loss: 1.669478416442871
Validation loss: 2.033989432037518

Epoch: 6| Step: 12
Training loss: 1.4972007274627686
Validation loss: 2.0546074592938988

Epoch: 6| Step: 13
Training loss: 1.6994149684906006
Validation loss: 2.0536403527823825

Epoch: 292| Step: 0
Training loss: 1.2775907516479492
Validation loss: 2.031582914372926

Epoch: 6| Step: 1
Training loss: 1.2652266025543213
Validation loss: 2.0645814147046817

Epoch: 6| Step: 2
Training loss: 2.0312089920043945
Validation loss: 2.0704643918621923

Epoch: 6| Step: 3
Training loss: 2.0082287788391113
Validation loss: 2.0675378755856584

Epoch: 6| Step: 4
Training loss: 2.3944525718688965
Validation loss: 2.0600056007344234

Epoch: 6| Step: 5
Training loss: 1.8361300230026245
Validation loss: 2.0591165173438286

Epoch: 6| Step: 6
Training loss: 1.5450515747070312
Validation loss: 2.024740888226417

Epoch: 6| Step: 7
Training loss: 1.9308159351348877
Validation loss: 2.0748734935637443

Epoch: 6| Step: 8
Training loss: 1.9215277433395386
Validation loss: 2.0479601121717885

Epoch: 6| Step: 9
Training loss: 1.2460951805114746
Validation loss: 2.0480876532934045

Epoch: 6| Step: 10
Training loss: 1.4568943977355957
Validation loss: 2.024396886107742

Epoch: 6| Step: 11
Training loss: 1.922526478767395
Validation loss: 2.062465234469342

Epoch: 6| Step: 12
Training loss: 1.968907356262207
Validation loss: 2.0428170773290817

Epoch: 6| Step: 13
Training loss: 1.8410532474517822
Validation loss: 2.079127170706308

Epoch: 293| Step: 0
Training loss: 2.5354106426239014
Validation loss: 2.091926784925563

Epoch: 6| Step: 1
Training loss: 1.3423523902893066
Validation loss: 2.0615385386251632

Epoch: 6| Step: 2
Training loss: 1.9050848484039307
Validation loss: 2.065440349681403

Epoch: 6| Step: 3
Training loss: 1.8748587369918823
Validation loss: 2.048069123298891

Epoch: 6| Step: 4
Training loss: 1.919191837310791
Validation loss: 2.0560539127678

Epoch: 6| Step: 5
Training loss: 1.5393171310424805
Validation loss: 2.0714280387406707

Epoch: 6| Step: 6
Training loss: 1.7148557901382446
Validation loss: 2.0408062678511425

Epoch: 6| Step: 7
Training loss: 1.7802534103393555
Validation loss: 2.0509618995010213

Epoch: 6| Step: 8
Training loss: 1.0961933135986328
Validation loss: 2.044247014548189

Epoch: 6| Step: 9
Training loss: 1.9461140632629395
Validation loss: 2.037493919813505

Epoch: 6| Step: 10
Training loss: 1.395505666732788
Validation loss: 2.069455559535693

Epoch: 6| Step: 11
Training loss: 1.8373095989227295
Validation loss: 2.04979706323275

Epoch: 6| Step: 12
Training loss: 1.8060038089752197
Validation loss: 2.063586947738483

Epoch: 6| Step: 13
Training loss: 1.827767252922058
Validation loss: 2.0321178205551638

Epoch: 294| Step: 0
Training loss: 1.705230951309204
Validation loss: 2.049083376443514

Epoch: 6| Step: 1
Training loss: 1.615154504776001
Validation loss: 2.0595645968632033

Epoch: 6| Step: 2
Training loss: 1.3262182474136353
Validation loss: 2.09094565145431

Epoch: 6| Step: 3
Training loss: 1.1384623050689697
Validation loss: 2.0414755818664387

Epoch: 6| Step: 4
Training loss: 1.8136637210845947
Validation loss: 2.079784967566049

Epoch: 6| Step: 5
Training loss: 1.6473166942596436
Validation loss: 2.059881817909979

Epoch: 6| Step: 6
Training loss: 2.0158352851867676
Validation loss: 2.0706243258650585

Epoch: 6| Step: 7
Training loss: 1.394486427307129
Validation loss: 2.0545079785008586

Epoch: 6| Step: 8
Training loss: 1.893153429031372
Validation loss: 2.055850362264982

Epoch: 6| Step: 9
Training loss: 1.9787557125091553
Validation loss: 2.037767599987727

Epoch: 6| Step: 10
Training loss: 2.0505497455596924
Validation loss: 2.033937831078806

Epoch: 6| Step: 11
Training loss: 1.5968687534332275
Validation loss: 2.0650934147578415

Epoch: 6| Step: 12
Training loss: 2.5886425971984863
Validation loss: 2.048172576453096

Epoch: 6| Step: 13
Training loss: 1.56593656539917
Validation loss: 2.050451030013382

Epoch: 295| Step: 0
Training loss: 1.4010933637619019
Validation loss: 2.058757961437266

Epoch: 6| Step: 1
Training loss: 2.251626968383789
Validation loss: 2.044111969650433

Epoch: 6| Step: 2
Training loss: 1.9209091663360596
Validation loss: 2.054185321254115

Epoch: 6| Step: 3
Training loss: 1.459071159362793
Validation loss: 2.0255144155153664

Epoch: 6| Step: 4
Training loss: 1.2301393747329712
Validation loss: 2.073515853574199

Epoch: 6| Step: 5
Training loss: 2.3453211784362793
Validation loss: 2.0599665090601933

Epoch: 6| Step: 6
Training loss: 1.0532326698303223
Validation loss: 2.0434795579602643

Epoch: 6| Step: 7
Training loss: 2.2853477001190186
Validation loss: 2.0647123859774683

Epoch: 6| Step: 8
Training loss: 1.9070501327514648
Validation loss: 2.0483849215251144

Epoch: 6| Step: 9
Training loss: 1.3339745998382568
Validation loss: 2.077589060670586

Epoch: 6| Step: 10
Training loss: 2.1077094078063965
Validation loss: 2.0288132044576828

Epoch: 6| Step: 11
Training loss: 1.8226540088653564
Validation loss: 2.010312303420036

Epoch: 6| Step: 12
Training loss: 1.2360459566116333
Validation loss: 2.107714614560527

Epoch: 6| Step: 13
Training loss: 1.7160110473632812
Validation loss: 2.0817782725057294

Epoch: 296| Step: 0
Training loss: 0.9666641354560852
Validation loss: 2.0747197315257084

Epoch: 6| Step: 1
Training loss: 2.0798628330230713
Validation loss: 2.0721986498883975

Epoch: 6| Step: 2
Training loss: 1.4450829029083252
Validation loss: 2.0587160997493292

Epoch: 6| Step: 3
Training loss: 1.9175596237182617
Validation loss: 2.0811680670707458

Epoch: 6| Step: 4
Training loss: 2.040909767150879
Validation loss: 2.0291480454065467

Epoch: 6| Step: 5
Training loss: 1.727963924407959
Validation loss: 2.0739224392880677

Epoch: 6| Step: 6
Training loss: 1.9385684728622437
Validation loss: 2.06106613784708

Epoch: 6| Step: 7
Training loss: 1.2947903871536255
Validation loss: 2.04532927466977

Epoch: 6| Step: 8
Training loss: 1.9915039539337158
Validation loss: 2.06935521992304

Epoch: 6| Step: 9
Training loss: 1.765910029411316
Validation loss: 2.046526598673995

Epoch: 6| Step: 10
Training loss: 2.2464263439178467
Validation loss: 2.0935397058404903

Epoch: 6| Step: 11
Training loss: 1.3457947969436646
Validation loss: 2.0922602748358123

Epoch: 6| Step: 12
Training loss: 1.7546374797821045
Validation loss: 2.100985775711716

Epoch: 6| Step: 13
Training loss: 1.6885303258895874
Validation loss: 2.0865710320011264

Epoch: 297| Step: 0
Training loss: 1.458423376083374
Validation loss: 2.0917814790561633

Epoch: 6| Step: 1
Training loss: 1.1957812309265137
Validation loss: 2.0785803923042874

Epoch: 6| Step: 2
Training loss: 2.034898042678833
Validation loss: 2.0663494166507514

Epoch: 6| Step: 3
Training loss: 0.9810951352119446
Validation loss: 2.0472733205364597

Epoch: 6| Step: 4
Training loss: 1.8931784629821777
Validation loss: 2.0877883024113153

Epoch: 6| Step: 5
Training loss: 1.5411022901535034
Validation loss: 2.068986528663225

Epoch: 6| Step: 6
Training loss: 2.142353057861328
Validation loss: 2.0483798852530857

Epoch: 6| Step: 7
Training loss: 2.0384199619293213
Validation loss: 2.0805442307585027

Epoch: 6| Step: 8
Training loss: 1.2956843376159668
Validation loss: 2.030427325156427

Epoch: 6| Step: 9
Training loss: 2.1490912437438965
Validation loss: 2.045016138784347

Epoch: 6| Step: 10
Training loss: 1.5195960998535156
Validation loss: 2.01773900370444

Epoch: 6| Step: 11
Training loss: 1.9256657361984253
Validation loss: 2.051751367507442

Epoch: 6| Step: 12
Training loss: 2.1127381324768066
Validation loss: 2.062651252233854

Epoch: 6| Step: 13
Training loss: 2.3570492267608643
Validation loss: 2.0388172480367843

Epoch: 298| Step: 0
Training loss: 1.6365013122558594
Validation loss: 2.040254874895978

Epoch: 6| Step: 1
Training loss: 2.0219504833221436
Validation loss: 2.0675465932456394

Epoch: 6| Step: 2
Training loss: 1.6391083002090454
Validation loss: 2.024956339149065

Epoch: 6| Step: 3
Training loss: 1.9800745248794556
Validation loss: 2.0604227101931007

Epoch: 6| Step: 4
Training loss: 2.1828274726867676
Validation loss: 2.0710530037521035

Epoch: 6| Step: 5
Training loss: 2.1313772201538086
Validation loss: 2.081305347463136

Epoch: 6| Step: 6
Training loss: 1.4247851371765137
Validation loss: 2.0899031495535247

Epoch: 6| Step: 7
Training loss: 1.8256659507751465
Validation loss: 2.0733134720915105

Epoch: 6| Step: 8
Training loss: 1.586506962776184
Validation loss: 2.0689726132218555

Epoch: 6| Step: 9
Training loss: 1.4376804828643799
Validation loss: 2.098635083885603

Epoch: 6| Step: 10
Training loss: 1.762145757675171
Validation loss: 2.096982494477303

Epoch: 6| Step: 11
Training loss: 1.7834147214889526
Validation loss: 2.124305873788813

Epoch: 6| Step: 12
Training loss: 1.181075096130371
Validation loss: 2.0992996295293174

Epoch: 6| Step: 13
Training loss: 1.6965842247009277
Validation loss: 2.0952356605119604

Epoch: 299| Step: 0
Training loss: 1.4671447277069092
Validation loss: 2.043163425819848

Epoch: 6| Step: 1
Training loss: 1.4050499200820923
Validation loss: 2.031791792120985

Epoch: 6| Step: 2
Training loss: 1.947831153869629
Validation loss: 2.0545162257327827

Epoch: 6| Step: 3
Training loss: 2.0335335731506348
Validation loss: 2.0505145621556107

Epoch: 6| Step: 4
Training loss: 1.0165514945983887
Validation loss: 2.0677232614127536

Epoch: 6| Step: 5
Training loss: 1.5126534700393677
Validation loss: 2.072385372654084

Epoch: 6| Step: 6
Training loss: 1.511121392250061
Validation loss: 2.017777787741794

Epoch: 6| Step: 7
Training loss: 2.2139620780944824
Validation loss: 2.0341053778125393

Epoch: 6| Step: 8
Training loss: 1.5617566108703613
Validation loss: 2.0635558982049265

Epoch: 6| Step: 9
Training loss: 1.2584465742111206
Validation loss: 2.021129787609141

Epoch: 6| Step: 10
Training loss: 1.8861149549484253
Validation loss: 2.0100118037193053

Epoch: 6| Step: 11
Training loss: 2.0700159072875977
Validation loss: 2.0272019063272784

Epoch: 6| Step: 12
Training loss: 2.028244733810425
Validation loss: 2.0202798433201288

Epoch: 6| Step: 13
Training loss: 2.185375690460205
Validation loss: 2.0499102928305186

Epoch: 300| Step: 0
Training loss: 1.8232427835464478
Validation loss: 2.033560450359057

Epoch: 6| Step: 1
Training loss: 1.6935184001922607
Validation loss: 2.0549811970803047

Epoch: 6| Step: 2
Training loss: 1.7637919187545776
Validation loss: 2.038798798796951

Epoch: 6| Step: 3
Training loss: 1.828966498374939
Validation loss: 2.0621732768192085

Epoch: 6| Step: 4
Training loss: 1.7652924060821533
Validation loss: 2.080720806634554

Epoch: 6| Step: 5
Training loss: 1.0183485746383667
Validation loss: 2.0499938508515716

Epoch: 6| Step: 6
Training loss: 1.4966974258422852
Validation loss: 2.046189926003897

Epoch: 6| Step: 7
Training loss: 2.471647262573242
Validation loss: 2.0352118810017905

Epoch: 6| Step: 8
Training loss: 1.117845892906189
Validation loss: 2.0735475888816257

Epoch: 6| Step: 9
Training loss: 1.684557557106018
Validation loss: 2.04928171250128

Epoch: 6| Step: 10
Training loss: 2.2606751918792725
Validation loss: 2.07856523606085

Epoch: 6| Step: 11
Training loss: 1.7607827186584473
Validation loss: 2.088999127828947

Epoch: 6| Step: 12
Training loss: 2.1321630477905273
Validation loss: 2.064493456194478

Epoch: 6| Step: 13
Training loss: 1.2988861799240112
Validation loss: 2.0455348568577922

Epoch: 301| Step: 0
Training loss: 1.5295250415802002
Validation loss: 2.053042560495356

Epoch: 6| Step: 1
Training loss: 2.1334142684936523
Validation loss: 2.1011760196378155

Epoch: 6| Step: 2
Training loss: 1.8122047185897827
Validation loss: 2.038736028055991

Epoch: 6| Step: 3
Training loss: 2.0578813552856445
Validation loss: 2.099938299066277

Epoch: 6| Step: 4
Training loss: 1.9207366704940796
Validation loss: 2.1197275397598103

Epoch: 6| Step: 5
Training loss: 1.7126301527023315
Validation loss: 2.126838573845484

Epoch: 6| Step: 6
Training loss: 2.03141450881958
Validation loss: 2.1418094071008826

Epoch: 6| Step: 7
Training loss: 1.4886298179626465
Validation loss: 2.090568942408408

Epoch: 6| Step: 8
Training loss: 1.2802510261535645
Validation loss: 2.1048921692755913

Epoch: 6| Step: 9
Training loss: 1.7517319917678833
Validation loss: 2.0912181485083794

Epoch: 6| Step: 10
Training loss: 1.7386021614074707
Validation loss: 2.0444453095877044

Epoch: 6| Step: 11
Training loss: 1.3758697509765625
Validation loss: 2.068073535478243

Epoch: 6| Step: 12
Training loss: 1.6647237539291382
Validation loss: 2.0384679584092993

Epoch: 6| Step: 13
Training loss: 1.5870997905731201
Validation loss: 2.0551951803186888

Epoch: 302| Step: 0
Training loss: 1.4399794340133667
Validation loss: 2.026214163790467

Epoch: 6| Step: 1
Training loss: 2.913318157196045
Validation loss: 2.049285501562139

Epoch: 6| Step: 2
Training loss: 1.659982681274414
Validation loss: 2.034587485815889

Epoch: 6| Step: 3
Training loss: 1.7192184925079346
Validation loss: 2.033654382151942

Epoch: 6| Step: 4
Training loss: 1.4864552021026611
Validation loss: 2.0284733182640484

Epoch: 6| Step: 5
Training loss: 2.0161538124084473
Validation loss: 2.0386003781390447

Epoch: 6| Step: 6
Training loss: 1.7537176609039307
Validation loss: 2.0582128083834084

Epoch: 6| Step: 7
Training loss: 1.7406033277511597
Validation loss: 2.0367659112458587

Epoch: 6| Step: 8
Training loss: 1.966292142868042
Validation loss: 2.057469235953464

Epoch: 6| Step: 9
Training loss: 1.1423810720443726
Validation loss: 2.056443818153874

Epoch: 6| Step: 10
Training loss: 1.764284372329712
Validation loss: 2.0846287999101865

Epoch: 6| Step: 11
Training loss: 1.1498863697052002
Validation loss: 2.105658164588354

Epoch: 6| Step: 12
Training loss: 1.3548979759216309
Validation loss: 2.074198449811628

Epoch: 6| Step: 13
Training loss: 2.454383373260498
Validation loss: 2.1093628637252317

Epoch: 303| Step: 0
Training loss: 1.5192404985427856
Validation loss: 2.1127920355848087

Epoch: 6| Step: 1
Training loss: 2.2668538093566895
Validation loss: 2.100474290950324

Epoch: 6| Step: 2
Training loss: 1.4143023490905762
Validation loss: 2.099581403117026

Epoch: 6| Step: 3
Training loss: 1.37949538230896
Validation loss: 2.068874515512938

Epoch: 6| Step: 4
Training loss: 2.2623956203460693
Validation loss: 2.088615009861608

Epoch: 6| Step: 5
Training loss: 1.4277278184890747
Validation loss: 2.101077741192233

Epoch: 6| Step: 6
Training loss: 1.9289863109588623
Validation loss: 2.065248716262079

Epoch: 6| Step: 7
Training loss: 2.1395156383514404
Validation loss: 2.1075083465986353

Epoch: 6| Step: 8
Training loss: 1.2998850345611572
Validation loss: 2.0749347312476045

Epoch: 6| Step: 9
Training loss: 1.6409446001052856
Validation loss: 2.064696906715311

Epoch: 6| Step: 10
Training loss: 1.5177035331726074
Validation loss: 2.044789796234459

Epoch: 6| Step: 11
Training loss: 1.7008562088012695
Validation loss: 2.0476849591860207

Epoch: 6| Step: 12
Training loss: 1.6863844394683838
Validation loss: 2.0645532761850665

Epoch: 6| Step: 13
Training loss: 2.113593578338623
Validation loss: 2.032821237400014

Epoch: 304| Step: 0
Training loss: 1.4051222801208496
Validation loss: 2.0487623599267777

Epoch: 6| Step: 1
Training loss: 1.0946824550628662
Validation loss: 2.0363398290449575

Epoch: 6| Step: 2
Training loss: 1.8370206356048584
Validation loss: 2.042749253652429

Epoch: 6| Step: 3
Training loss: 1.2451252937316895
Validation loss: 2.047762575969901

Epoch: 6| Step: 4
Training loss: 1.689970850944519
Validation loss: 2.0163738009750203

Epoch: 6| Step: 5
Training loss: 1.9993442296981812
Validation loss: 2.0711696109464093

Epoch: 6| Step: 6
Training loss: 1.8150324821472168
Validation loss: 2.0539803940762758

Epoch: 6| Step: 7
Training loss: 1.6607364416122437
Validation loss: 2.051710327466329

Epoch: 6| Step: 8
Training loss: 1.3069472312927246
Validation loss: 2.0803231718719646

Epoch: 6| Step: 9
Training loss: 1.0749690532684326
Validation loss: 2.0744668181224535

Epoch: 6| Step: 10
Training loss: 2.439755916595459
Validation loss: 2.088366707166036

Epoch: 6| Step: 11
Training loss: 2.5443148612976074
Validation loss: 2.0635169372763684

Epoch: 6| Step: 12
Training loss: 1.8484392166137695
Validation loss: 2.0563530127207437

Epoch: 6| Step: 13
Training loss: 2.127211332321167
Validation loss: 2.0980992624836583

Epoch: 305| Step: 0
Training loss: 1.8956072330474854
Validation loss: 2.0749601779445523

Epoch: 6| Step: 1
Training loss: 1.4045032262802124
Validation loss: 2.012668932637861

Epoch: 6| Step: 2
Training loss: 1.1930408477783203
Validation loss: 2.0608987635181797

Epoch: 6| Step: 3
Training loss: 1.3362354040145874
Validation loss: 2.092654476883591

Epoch: 6| Step: 4
Training loss: 1.2813231945037842
Validation loss: 2.113592824628276

Epoch: 6| Step: 5
Training loss: 1.4316425323486328
Validation loss: 2.0913278108002036

Epoch: 6| Step: 6
Training loss: 2.6677634716033936
Validation loss: 2.0781753434929797

Epoch: 6| Step: 7
Training loss: 2.153219223022461
Validation loss: 2.104636828104655

Epoch: 6| Step: 8
Training loss: 2.0946226119995117
Validation loss: 2.0907811939075427

Epoch: 6| Step: 9
Training loss: 1.555638313293457
Validation loss: 2.067236545265362

Epoch: 6| Step: 10
Training loss: 1.9443714618682861
Validation loss: 2.0849194577945176

Epoch: 6| Step: 11
Training loss: 2.244053602218628
Validation loss: 2.064585262729276

Epoch: 6| Step: 12
Training loss: 1.4432857036590576
Validation loss: 2.093428293863932

Epoch: 6| Step: 13
Training loss: 1.0007402896881104
Validation loss: 2.0711492287215365

Epoch: 306| Step: 0
Training loss: 1.5768394470214844
Validation loss: 2.0737109696993263

Epoch: 6| Step: 1
Training loss: 1.0564786195755005
Validation loss: 2.0805368833644415

Epoch: 6| Step: 2
Training loss: 2.0036115646362305
Validation loss: 2.0330410670208674

Epoch: 6| Step: 3
Training loss: 1.7334098815917969
Validation loss: 2.0425202385071786

Epoch: 6| Step: 4
Training loss: 1.603102445602417
Validation loss: 2.05164215641637

Epoch: 6| Step: 5
Training loss: 1.6343680620193481
Validation loss: 2.023390062393681

Epoch: 6| Step: 6
Training loss: 1.5771160125732422
Validation loss: 2.0400014795282835

Epoch: 6| Step: 7
Training loss: 1.3648500442504883
Validation loss: 2.0684640407562256

Epoch: 6| Step: 8
Training loss: 1.8190972805023193
Validation loss: 2.0156640237377537

Epoch: 6| Step: 9
Training loss: 1.9934885501861572
Validation loss: 2.0269317626953125

Epoch: 6| Step: 10
Training loss: 1.5948090553283691
Validation loss: 2.053365474106163

Epoch: 6| Step: 11
Training loss: 1.731795072555542
Validation loss: 2.008119475456976

Epoch: 6| Step: 12
Training loss: 1.7465887069702148
Validation loss: 2.043542710683679

Epoch: 6| Step: 13
Training loss: 3.8140649795532227
Validation loss: 2.0520691179460093

Epoch: 307| Step: 0
Training loss: 1.6275489330291748
Validation loss: 2.051874578640025

Epoch: 6| Step: 1
Training loss: 1.670595407485962
Validation loss: 2.101052548295708

Epoch: 6| Step: 2
Training loss: 2.311182975769043
Validation loss: 2.1303780681343487

Epoch: 6| Step: 3
Training loss: 1.6310369968414307
Validation loss: 2.1623476961607575

Epoch: 6| Step: 4
Training loss: 2.2106666564941406
Validation loss: 2.1833904250975578

Epoch: 6| Step: 5
Training loss: 1.963908076286316
Validation loss: 2.1340033008206274

Epoch: 6| Step: 6
Training loss: 1.835815191268921
Validation loss: 2.1617201797423826

Epoch: 6| Step: 7
Training loss: 1.0692251920700073
Validation loss: 2.1445478431640135

Epoch: 6| Step: 8
Training loss: 1.6845993995666504
Validation loss: 2.1128919816786245

Epoch: 6| Step: 9
Training loss: 1.7904623746871948
Validation loss: 2.092373555706393

Epoch: 6| Step: 10
Training loss: 1.4726134538650513
Validation loss: 2.101738154247243

Epoch: 6| Step: 11
Training loss: 1.8411946296691895
Validation loss: 2.0514389391868346

Epoch: 6| Step: 12
Training loss: 1.5303826332092285
Validation loss: 2.0945132393990793

Epoch: 6| Step: 13
Training loss: 1.798901915550232
Validation loss: 2.060437302435598

Epoch: 308| Step: 0
Training loss: 1.414898157119751
Validation loss: 2.070204852729715

Epoch: 6| Step: 1
Training loss: 1.247675895690918
Validation loss: 2.0634363159056632

Epoch: 6| Step: 2
Training loss: 1.1839768886566162
Validation loss: 2.0593622910079135

Epoch: 6| Step: 3
Training loss: 2.1488687992095947
Validation loss: 2.0715384303882556

Epoch: 6| Step: 4
Training loss: 2.1672346591949463
Validation loss: 2.0606704411968106

Epoch: 6| Step: 5
Training loss: 1.2856955528259277
Validation loss: 2.0545738127923783

Epoch: 6| Step: 6
Training loss: 1.9122816324234009
Validation loss: 2.0342236206095707

Epoch: 6| Step: 7
Training loss: 2.1759238243103027
Validation loss: 2.0005017275451333

Epoch: 6| Step: 8
Training loss: 1.8290178775787354
Validation loss: 2.0473206632880756

Epoch: 6| Step: 9
Training loss: 1.698127031326294
Validation loss: 2.0593235031250985

Epoch: 6| Step: 10
Training loss: 1.279491662979126
Validation loss: 2.0596219621678835

Epoch: 6| Step: 11
Training loss: 1.6914443969726562
Validation loss: 2.0500823323444655

Epoch: 6| Step: 12
Training loss: 1.9614996910095215
Validation loss: 2.064231490576139

Epoch: 6| Step: 13
Training loss: 2.7568740844726562
Validation loss: 2.0830293752813853

Epoch: 309| Step: 0
Training loss: 1.5912983417510986
Validation loss: 2.0688311156406196

Epoch: 6| Step: 1
Training loss: 1.342761516571045
Validation loss: 2.054424003888202

Epoch: 6| Step: 2
Training loss: 1.6991616487503052
Validation loss: 2.0553416116263277

Epoch: 6| Step: 3
Training loss: 1.943868637084961
Validation loss: 2.0624470185208064

Epoch: 6| Step: 4
Training loss: 2.0711545944213867
Validation loss: 2.067482344565853

Epoch: 6| Step: 5
Training loss: 1.5501534938812256
Validation loss: 2.0511139208270657

Epoch: 6| Step: 6
Training loss: 1.8769209384918213
Validation loss: 2.0494194184580157

Epoch: 6| Step: 7
Training loss: 1.4012832641601562
Validation loss: 2.053225250654323

Epoch: 6| Step: 8
Training loss: 2.1007418632507324
Validation loss: 2.0487293940718456

Epoch: 6| Step: 9
Training loss: 1.5287373065948486
Validation loss: 2.02726581276104

Epoch: 6| Step: 10
Training loss: 1.4564485549926758
Validation loss: 2.0001493987216743

Epoch: 6| Step: 11
Training loss: 1.6648852825164795
Validation loss: 2.0733024510004188

Epoch: 6| Step: 12
Training loss: 1.6164357662200928
Validation loss: 2.0210976293010097

Epoch: 6| Step: 13
Training loss: 2.000945806503296
Validation loss: 2.0688351328654955

Epoch: 310| Step: 0
Training loss: 2.1297614574432373
Validation loss: 2.082506292609758

Epoch: 6| Step: 1
Training loss: 2.0166475772857666
Validation loss: 2.076343295394733

Epoch: 6| Step: 2
Training loss: 2.273733615875244
Validation loss: 2.052835920805572

Epoch: 6| Step: 3
Training loss: 1.425450086593628
Validation loss: 2.071500675652617

Epoch: 6| Step: 4
Training loss: 1.3221023082733154
Validation loss: 2.0687618306888047

Epoch: 6| Step: 5
Training loss: 2.104513168334961
Validation loss: 2.062276044199544

Epoch: 6| Step: 6
Training loss: 1.3106160163879395
Validation loss: 2.060792571754866

Epoch: 6| Step: 7
Training loss: 1.0566880702972412
Validation loss: 2.077691799850874

Epoch: 6| Step: 8
Training loss: 2.4219303131103516
Validation loss: 2.090023563754174

Epoch: 6| Step: 9
Training loss: 1.103222370147705
Validation loss: 2.079962243315994

Epoch: 6| Step: 10
Training loss: 1.4667339324951172
Validation loss: 2.081262529537242

Epoch: 6| Step: 11
Training loss: 1.7750930786132812
Validation loss: 2.0517533645834973

Epoch: 6| Step: 12
Training loss: 1.6714231967926025
Validation loss: 2.0748417172380673

Epoch: 6| Step: 13
Training loss: 2.104473114013672
Validation loss: 2.0567847708220124

Epoch: 311| Step: 0
Training loss: 1.7680437564849854
Validation loss: 2.0665799879258677

Epoch: 6| Step: 1
Training loss: 0.8772680759429932
Validation loss: 2.0592330322470715

Epoch: 6| Step: 2
Training loss: 1.8247572183609009
Validation loss: 2.068962739359948

Epoch: 6| Step: 3
Training loss: 1.395439624786377
Validation loss: 2.0192066956591863

Epoch: 6| Step: 4
Training loss: 1.3424608707427979
Validation loss: 2.0392966449901624

Epoch: 6| Step: 5
Training loss: 2.440920829772949
Validation loss: 2.058734611798358

Epoch: 6| Step: 6
Training loss: 1.7326607704162598
Validation loss: 2.058255462236302

Epoch: 6| Step: 7
Training loss: 1.678593397140503
Validation loss: 2.035371047194286

Epoch: 6| Step: 8
Training loss: 1.8700921535491943
Validation loss: 2.0324382064163045

Epoch: 6| Step: 9
Training loss: 1.8211122751235962
Validation loss: 2.0513994924483763

Epoch: 6| Step: 10
Training loss: 1.9991326332092285
Validation loss: 2.091317594692271

Epoch: 6| Step: 11
Training loss: 1.774484634399414
Validation loss: 2.075525212031539

Epoch: 6| Step: 12
Training loss: 1.7558913230895996
Validation loss: 2.0779120614451747

Epoch: 6| Step: 13
Training loss: 1.352335810661316
Validation loss: 2.0664965132231354

Epoch: 312| Step: 0
Training loss: 1.77567720413208
Validation loss: 2.0458934345552997

Epoch: 6| Step: 1
Training loss: 1.3809459209442139
Validation loss: 2.039967308762253

Epoch: 6| Step: 2
Training loss: 1.7416307926177979
Validation loss: 2.035658997874106

Epoch: 6| Step: 3
Training loss: 1.9399487972259521
Validation loss: 2.0437002540916525

Epoch: 6| Step: 4
Training loss: 1.8095595836639404
Validation loss: 2.021571115780902

Epoch: 6| Step: 5
Training loss: 1.985426664352417
Validation loss: 2.0708804233099825

Epoch: 6| Step: 6
Training loss: 1.3285377025604248
Validation loss: 2.0743380900352233

Epoch: 6| Step: 7
Training loss: 1.5504746437072754
Validation loss: 2.0134664914941274

Epoch: 6| Step: 8
Training loss: 1.9266984462738037
Validation loss: 2.0303036679503736

Epoch: 6| Step: 9
Training loss: 1.5278306007385254
Validation loss: 2.054302715486096

Epoch: 6| Step: 10
Training loss: 1.657141923904419
Validation loss: 2.040171839857614

Epoch: 6| Step: 11
Training loss: 2.1347908973693848
Validation loss: 2.0371320721923665

Epoch: 6| Step: 12
Training loss: 1.5410735607147217
Validation loss: 2.0526136787988807

Epoch: 6| Step: 13
Training loss: 1.6015681028366089
Validation loss: 2.094674855150202

Epoch: 313| Step: 0
Training loss: 0.8075685501098633
Validation loss: 2.058237842334214

Epoch: 6| Step: 1
Training loss: 2.020294189453125
Validation loss: 2.0839056250869588

Epoch: 6| Step: 2
Training loss: 1.7937421798706055
Validation loss: 2.1086944995387906

Epoch: 6| Step: 3
Training loss: 1.6787283420562744
Validation loss: 2.09389861552946

Epoch: 6| Step: 4
Training loss: 1.5394039154052734
Validation loss: 2.083539597449764

Epoch: 6| Step: 5
Training loss: 1.7413136959075928
Validation loss: 2.077096193067489

Epoch: 6| Step: 6
Training loss: 1.6552989482879639
Validation loss: 2.062167736791795

Epoch: 6| Step: 7
Training loss: 1.7319705486297607
Validation loss: 2.039133858937089

Epoch: 6| Step: 8
Training loss: 2.571481227874756
Validation loss: 2.09377186400916

Epoch: 6| Step: 9
Training loss: 1.7310798168182373
Validation loss: 2.045316758976188

Epoch: 6| Step: 10
Training loss: 1.485208511352539
Validation loss: 2.025780285558393

Epoch: 6| Step: 11
Training loss: 1.8020881414413452
Validation loss: 2.0606990962900142

Epoch: 6| Step: 12
Training loss: 1.3673502206802368
Validation loss: 2.1034268538157144

Epoch: 6| Step: 13
Training loss: 1.657650351524353
Validation loss: 2.052497722769296

Epoch: 314| Step: 0
Training loss: 1.3861644268035889
Validation loss: 2.0698428051446074

Epoch: 6| Step: 1
Training loss: 1.678350806236267
Validation loss: 2.0379954755947156

Epoch: 6| Step: 2
Training loss: 2.1774487495422363
Validation loss: 2.053052370266248

Epoch: 6| Step: 3
Training loss: 1.4443844556808472
Validation loss: 2.006583741916123

Epoch: 6| Step: 4
Training loss: 2.002239227294922
Validation loss: 2.0311751211843183

Epoch: 6| Step: 5
Training loss: 1.4050863981246948
Validation loss: 2.0761576814036213

Epoch: 6| Step: 6
Training loss: 1.957571029663086
Validation loss: 2.038066376921951

Epoch: 6| Step: 7
Training loss: 1.0113229751586914
Validation loss: 2.0608738878721833

Epoch: 6| Step: 8
Training loss: 1.6653072834014893
Validation loss: 2.088648215416939

Epoch: 6| Step: 9
Training loss: 1.8685922622680664
Validation loss: 2.0819290120114564

Epoch: 6| Step: 10
Training loss: 1.6812806129455566
Validation loss: 2.0801186382129626

Epoch: 6| Step: 11
Training loss: 1.635477066040039
Validation loss: 2.086401429227603

Epoch: 6| Step: 12
Training loss: 2.0364632606506348
Validation loss: 2.054754131583757

Epoch: 6| Step: 13
Training loss: 1.9861836433410645
Validation loss: 2.0853487573644167

Epoch: 315| Step: 0
Training loss: 1.6165218353271484
Validation loss: 2.0603414017667054

Epoch: 6| Step: 1
Training loss: 1.824851155281067
Validation loss: 2.07726449863885

Epoch: 6| Step: 2
Training loss: 1.6061218976974487
Validation loss: 2.049030637228361

Epoch: 6| Step: 3
Training loss: 1.6735327243804932
Validation loss: 2.0840399701108216

Epoch: 6| Step: 4
Training loss: 1.054391622543335
Validation loss: 2.0787810458931872

Epoch: 6| Step: 5
Training loss: 1.4101760387420654
Validation loss: 2.0578812937582693

Epoch: 6| Step: 6
Training loss: 1.143700361251831
Validation loss: 2.073644453479398

Epoch: 6| Step: 7
Training loss: 2.4048309326171875
Validation loss: 2.082680151026736

Epoch: 6| Step: 8
Training loss: 2.127821922302246
Validation loss: 2.0584206991298224

Epoch: 6| Step: 9
Training loss: 1.459038496017456
Validation loss: 2.0234763212101434

Epoch: 6| Step: 10
Training loss: 2.0031559467315674
Validation loss: 2.0784082771629415

Epoch: 6| Step: 11
Training loss: 1.5009551048278809
Validation loss: 2.072902794807188

Epoch: 6| Step: 12
Training loss: 1.7550495862960815
Validation loss: 2.0817213571199806

Epoch: 6| Step: 13
Training loss: 2.6791296005249023
Validation loss: 2.0633856814394713

Epoch: 316| Step: 0
Training loss: 1.9619784355163574
Validation loss: 2.0704702254264586

Epoch: 6| Step: 1
Training loss: 1.4016457796096802
Validation loss: 2.033242469192833

Epoch: 6| Step: 2
Training loss: 1.549079418182373
Validation loss: 2.056333062469318

Epoch: 6| Step: 3
Training loss: 1.4241018295288086
Validation loss: 2.057845864244687

Epoch: 6| Step: 4
Training loss: 2.451251983642578
Validation loss: 2.0342748165130615

Epoch: 6| Step: 5
Training loss: 1.1782642602920532
Validation loss: 2.0513891032947007

Epoch: 6| Step: 6
Training loss: 1.5040669441223145
Validation loss: 2.038219577522688

Epoch: 6| Step: 7
Training loss: 1.4653820991516113
Validation loss: 2.057729128868349

Epoch: 6| Step: 8
Training loss: 1.3414373397827148
Validation loss: 2.015484284329158

Epoch: 6| Step: 9
Training loss: 1.9049220085144043
Validation loss: 2.0151951236109578

Epoch: 6| Step: 10
Training loss: 2.3262710571289062
Validation loss: 2.0404190914605254

Epoch: 6| Step: 11
Training loss: 2.391425132751465
Validation loss: 2.0912601537601923

Epoch: 6| Step: 12
Training loss: 0.9313445091247559
Validation loss: 2.0629562741966656

Epoch: 6| Step: 13
Training loss: 1.7035930156707764
Validation loss: 2.1038188267779607

Epoch: 317| Step: 0
Training loss: 1.4428993463516235
Validation loss: 2.088870885551617

Epoch: 6| Step: 1
Training loss: 1.849472165107727
Validation loss: 2.0827637141750706

Epoch: 6| Step: 2
Training loss: 1.0969188213348389
Validation loss: 2.0826181903962167

Epoch: 6| Step: 3
Training loss: 1.6807525157928467
Validation loss: 2.053727985710226

Epoch: 6| Step: 4
Training loss: 1.4512532949447632
Validation loss: 2.06444663001645

Epoch: 6| Step: 5
Training loss: 1.4703404903411865
Validation loss: 2.0702101735658545

Epoch: 6| Step: 6
Training loss: 2.0830278396606445
Validation loss: 2.0570268554072224

Epoch: 6| Step: 7
Training loss: 1.770837664604187
Validation loss: 2.06283539084978

Epoch: 6| Step: 8
Training loss: 1.9809983968734741
Validation loss: 2.085885719586444

Epoch: 6| Step: 9
Training loss: 1.561774730682373
Validation loss: 2.0685809658419703

Epoch: 6| Step: 10
Training loss: 1.2761971950531006
Validation loss: 2.070136070251465

Epoch: 6| Step: 11
Training loss: 2.0203299522399902
Validation loss: 2.1015419216566187

Epoch: 6| Step: 12
Training loss: 1.8450214862823486
Validation loss: 2.057999913410474

Epoch: 6| Step: 13
Training loss: 2.417667865753174
Validation loss: 2.0724233247900523

Epoch: 318| Step: 0
Training loss: 1.9974191188812256
Validation loss: 2.047870889786751

Epoch: 6| Step: 1
Training loss: 1.5209128856658936
Validation loss: 2.081394136592906

Epoch: 6| Step: 2
Training loss: 2.1627705097198486
Validation loss: 2.082722738224973

Epoch: 6| Step: 3
Training loss: 1.6504619121551514
Validation loss: 2.05822411147497

Epoch: 6| Step: 4
Training loss: 1.5684694051742554
Validation loss: 2.0252777376482562

Epoch: 6| Step: 5
Training loss: 1.3385107517242432
Validation loss: 2.066349720442167

Epoch: 6| Step: 6
Training loss: 1.55817449092865
Validation loss: 2.0628507701299523

Epoch: 6| Step: 7
Training loss: 1.8112417459487915
Validation loss: 2.066043620468468

Epoch: 6| Step: 8
Training loss: 1.8786190748214722
Validation loss: 2.065922893503661

Epoch: 6| Step: 9
Training loss: 1.6186888217926025
Validation loss: 2.043475430498841

Epoch: 6| Step: 10
Training loss: 1.7772066593170166
Validation loss: 2.025557671823809

Epoch: 6| Step: 11
Training loss: 1.4986944198608398
Validation loss: 2.023503908547022

Epoch: 6| Step: 12
Training loss: 1.3842555284500122
Validation loss: 2.0527269224966727

Epoch: 6| Step: 13
Training loss: 2.061567544937134
Validation loss: 2.064936622496574

Epoch: 319| Step: 0
Training loss: 2.0059762001037598
Validation loss: 2.068098227183024

Epoch: 6| Step: 1
Training loss: 1.1353572607040405
Validation loss: 2.0740727083657378

Epoch: 6| Step: 2
Training loss: 1.1888526678085327
Validation loss: 2.0937199643863145

Epoch: 6| Step: 3
Training loss: 1.9562835693359375
Validation loss: 2.086849334419415

Epoch: 6| Step: 4
Training loss: 1.6064804792404175
Validation loss: 2.1097147413479385

Epoch: 6| Step: 5
Training loss: 1.7648879289627075
Validation loss: 2.08629608667025

Epoch: 6| Step: 6
Training loss: 1.856650948524475
Validation loss: 2.1130099578570296

Epoch: 6| Step: 7
Training loss: 1.660200834274292
Validation loss: 2.0265228158684185

Epoch: 6| Step: 8
Training loss: 1.5715231895446777
Validation loss: 2.0601185906317925

Epoch: 6| Step: 9
Training loss: 1.3816272020339966
Validation loss: 2.054880657503682

Epoch: 6| Step: 10
Training loss: 2.3159241676330566
Validation loss: 2.051030079523722

Epoch: 6| Step: 11
Training loss: 1.6971445083618164
Validation loss: 2.0449474101425498

Epoch: 6| Step: 12
Training loss: 1.9633560180664062
Validation loss: 2.084313629775919

Epoch: 6| Step: 13
Training loss: 0.902827799320221
Validation loss: 2.0576501610458537

Epoch: 320| Step: 0
Training loss: 1.3970534801483154
Validation loss: 2.0696112596860496

Epoch: 6| Step: 1
Training loss: 2.2150166034698486
Validation loss: 2.0707121946478404

Epoch: 6| Step: 2
Training loss: 1.6026769876480103
Validation loss: 2.060292966904179

Epoch: 6| Step: 3
Training loss: 1.4379096031188965
Validation loss: 2.040702671133062

Epoch: 6| Step: 4
Training loss: 2.2754292488098145
Validation loss: 2.0491142401131253

Epoch: 6| Step: 5
Training loss: 1.4865679740905762
Validation loss: 2.0358949220308693

Epoch: 6| Step: 6
Training loss: 1.5604304075241089
Validation loss: 2.0380247536525933

Epoch: 6| Step: 7
Training loss: 2.0125410556793213
Validation loss: 2.0776856573679114

Epoch: 6| Step: 8
Training loss: 0.9472827911376953
Validation loss: 2.0424648561785297

Epoch: 6| Step: 9
Training loss: 1.0350909233093262
Validation loss: 2.0463483256678425

Epoch: 6| Step: 10
Training loss: 1.5672407150268555
Validation loss: 2.0653887077044417

Epoch: 6| Step: 11
Training loss: 1.9319722652435303
Validation loss: 2.0439484555234193

Epoch: 6| Step: 12
Training loss: 1.981907606124878
Validation loss: 2.0970178034997757

Epoch: 6| Step: 13
Training loss: 2.1577157974243164
Validation loss: 2.0431357532419185

Epoch: 321| Step: 0
Training loss: 1.802324891090393
Validation loss: 2.0681295523079495

Epoch: 6| Step: 1
Training loss: 2.2861838340759277
Validation loss: 2.093611830024309

Epoch: 6| Step: 2
Training loss: 1.5210092067718506
Validation loss: 2.076428098063315

Epoch: 6| Step: 3
Training loss: 0.8849698901176453
Validation loss: 2.0817633457081293

Epoch: 6| Step: 4
Training loss: 1.2648650407791138
Validation loss: 2.0771549517108547

Epoch: 6| Step: 5
Training loss: 2.1750361919403076
Validation loss: 2.0898731036852767

Epoch: 6| Step: 6
Training loss: 1.718908667564392
Validation loss: 2.0977685143870692

Epoch: 6| Step: 7
Training loss: 1.6164121627807617
Validation loss: 2.0806991079802155

Epoch: 6| Step: 8
Training loss: 1.5229344367980957
Validation loss: 2.1077966049153316

Epoch: 6| Step: 9
Training loss: 1.3011363744735718
Validation loss: 2.0526861542014667

Epoch: 6| Step: 10
Training loss: 2.1557321548461914
Validation loss: 2.04603664336666

Epoch: 6| Step: 11
Training loss: 1.979337453842163
Validation loss: 2.064261894072256

Epoch: 6| Step: 12
Training loss: 1.4435184001922607
Validation loss: 2.036410172780355

Epoch: 6| Step: 13
Training loss: 1.8775473833084106
Validation loss: 2.0597834766552015

Epoch: 322| Step: 0
Training loss: 1.7732715606689453
Validation loss: 2.0536118707349225

Epoch: 6| Step: 1
Training loss: 1.7240862846374512
Validation loss: 2.0224566716019825

Epoch: 6| Step: 2
Training loss: 1.8518424034118652
Validation loss: 2.075260344372001

Epoch: 6| Step: 3
Training loss: 1.5172302722930908
Validation loss: 2.057133590021441

Epoch: 6| Step: 4
Training loss: 1.1462814807891846
Validation loss: 2.0363111393426054

Epoch: 6| Step: 5
Training loss: 2.2530741691589355
Validation loss: 2.064693570137024

Epoch: 6| Step: 6
Training loss: 1.4993305206298828
Validation loss: 2.052129996720181

Epoch: 6| Step: 7
Training loss: 1.656879186630249
Validation loss: 2.0184268131051013

Epoch: 6| Step: 8
Training loss: 1.3796911239624023
Validation loss: 2.0491929054260254

Epoch: 6| Step: 9
Training loss: 2.591308116912842
Validation loss: 2.0734550722183718

Epoch: 6| Step: 10
Training loss: 0.8720419406890869
Validation loss: 2.0396371849121584

Epoch: 6| Step: 11
Training loss: 1.8772237300872803
Validation loss: 2.0535290189968642

Epoch: 6| Step: 12
Training loss: 1.5188937187194824
Validation loss: 2.025270431272445

Epoch: 6| Step: 13
Training loss: 2.183295249938965
Validation loss: 2.090107666548862

Epoch: 323| Step: 0
Training loss: 1.7179383039474487
Validation loss: 2.086854983401555

Epoch: 6| Step: 1
Training loss: 2.357907772064209
Validation loss: 2.1232848603238343

Epoch: 6| Step: 2
Training loss: 1.5561866760253906
Validation loss: 2.115944859802082

Epoch: 6| Step: 3
Training loss: 1.5084400177001953
Validation loss: 2.127249938185497

Epoch: 6| Step: 4
Training loss: 2.06909441947937
Validation loss: 2.1016141496678835

Epoch: 6| Step: 5
Training loss: 1.7192270755767822
Validation loss: 2.1267550427426576

Epoch: 6| Step: 6
Training loss: 1.3471357822418213
Validation loss: 2.1112117203333045

Epoch: 6| Step: 7
Training loss: 1.282065987586975
Validation loss: 2.124718290503307

Epoch: 6| Step: 8
Training loss: 1.7009379863739014
Validation loss: 2.162551156936153

Epoch: 6| Step: 9
Training loss: 1.9306011199951172
Validation loss: 2.1442239899789133

Epoch: 6| Step: 10
Training loss: 1.878311276435852
Validation loss: 2.1269752005095124

Epoch: 6| Step: 11
Training loss: 1.7456825971603394
Validation loss: 2.0715500231712096

Epoch: 6| Step: 12
Training loss: 1.2404073476791382
Validation loss: 2.0582991415454495

Epoch: 6| Step: 13
Training loss: 1.8516439199447632
Validation loss: 2.0875030512450845

Epoch: 324| Step: 0
Training loss: 1.3413382768630981
Validation loss: 2.0845106468405774

Epoch: 6| Step: 1
Training loss: 1.1531810760498047
Validation loss: 2.0781276315771122

Epoch: 6| Step: 2
Training loss: 1.9898135662078857
Validation loss: 2.0790884020507976

Epoch: 6| Step: 3
Training loss: 1.672888159751892
Validation loss: 2.0818880770796087

Epoch: 6| Step: 4
Training loss: 1.4018547534942627
Validation loss: 2.0747700545095626

Epoch: 6| Step: 5
Training loss: 1.6954002380371094
Validation loss: 2.0466976088862263

Epoch: 6| Step: 6
Training loss: 2.184601306915283
Validation loss: 2.0687773407146497

Epoch: 6| Step: 7
Training loss: 2.0853018760681152
Validation loss: 2.056743424425843

Epoch: 6| Step: 8
Training loss: 1.6876205205917358
Validation loss: 2.073080631994432

Epoch: 6| Step: 9
Training loss: 1.7615902423858643
Validation loss: 2.042017070196008

Epoch: 6| Step: 10
Training loss: 1.342094898223877
Validation loss: 2.054241734166299

Epoch: 6| Step: 11
Training loss: 1.809494137763977
Validation loss: 2.051424793017808

Epoch: 6| Step: 12
Training loss: 1.7614328861236572
Validation loss: 2.0627211216957337

Epoch: 6| Step: 13
Training loss: 1.385258674621582
Validation loss: 2.053347323530464

Epoch: 325| Step: 0
Training loss: 0.7914355397224426
Validation loss: 2.109054087310709

Epoch: 6| Step: 1
Training loss: 1.7755107879638672
Validation loss: 2.0666444916878977

Epoch: 6| Step: 2
Training loss: 1.8199443817138672
Validation loss: 2.0789395839937272

Epoch: 6| Step: 3
Training loss: 1.2379498481750488
Validation loss: 2.089236843970514

Epoch: 6| Step: 4
Training loss: 1.5136606693267822
Validation loss: 2.079332406802844

Epoch: 6| Step: 5
Training loss: 1.2782042026519775
Validation loss: 2.1087991729859383

Epoch: 6| Step: 6
Training loss: 1.8867286443710327
Validation loss: 2.063078588055026

Epoch: 6| Step: 7
Training loss: 2.217312812805176
Validation loss: 2.061180237800844

Epoch: 6| Step: 8
Training loss: 2.0522360801696777
Validation loss: 2.0282679603945826

Epoch: 6| Step: 9
Training loss: 1.7718738317489624
Validation loss: 2.0913710427540604

Epoch: 6| Step: 10
Training loss: 2.0565853118896484
Validation loss: 2.0537278985464447

Epoch: 6| Step: 11
Training loss: 1.6949728727340698
Validation loss: 2.0507880205749185

Epoch: 6| Step: 12
Training loss: 1.712106466293335
Validation loss: 2.0375029592103857

Epoch: 6| Step: 13
Training loss: 1.8712267875671387
Validation loss: 2.051471294895295

Epoch: 326| Step: 0
Training loss: 1.5006059408187866
Validation loss: 2.0357804426582913

Epoch: 6| Step: 1
Training loss: 2.279078483581543
Validation loss: 2.0452517488951325

Epoch: 6| Step: 2
Training loss: 1.1362981796264648
Validation loss: 2.0544590873102986

Epoch: 6| Step: 3
Training loss: 2.711726665496826
Validation loss: 2.0529079898711173

Epoch: 6| Step: 4
Training loss: 1.5038299560546875
Validation loss: 2.0645999857174453

Epoch: 6| Step: 5
Training loss: 1.8334765434265137
Validation loss: 2.0306877025993924

Epoch: 6| Step: 6
Training loss: 1.491093635559082
Validation loss: 2.0615801580490603

Epoch: 6| Step: 7
Training loss: 2.0642213821411133
Validation loss: 2.0348884777356218

Epoch: 6| Step: 8
Training loss: 1.937028169631958
Validation loss: 2.023100624802292

Epoch: 6| Step: 9
Training loss: 1.400671362876892
Validation loss: 2.054665452690535

Epoch: 6| Step: 10
Training loss: 1.1743719577789307
Validation loss: 2.061313754768782

Epoch: 6| Step: 11
Training loss: 1.3413760662078857
Validation loss: 2.103695128553657

Epoch: 6| Step: 12
Training loss: 1.3767468929290771
Validation loss: 2.070967787055559

Epoch: 6| Step: 13
Training loss: 1.6227564811706543
Validation loss: 2.0672012695702175

Epoch: 327| Step: 0
Training loss: 1.748661756515503
Validation loss: 2.060800834368634

Epoch: 6| Step: 1
Training loss: 1.1410331726074219
Validation loss: 2.109250350665021

Epoch: 6| Step: 2
Training loss: 2.225539207458496
Validation loss: 2.0582000786258328

Epoch: 6| Step: 3
Training loss: 1.8791190385818481
Validation loss: 2.022186706143041

Epoch: 6| Step: 4
Training loss: 1.9192070960998535
Validation loss: 2.0340471036972536

Epoch: 6| Step: 5
Training loss: 1.5562798976898193
Validation loss: 2.0564270711714223

Epoch: 6| Step: 6
Training loss: 1.6070630550384521
Validation loss: 2.071413560580182

Epoch: 6| Step: 7
Training loss: 1.7348504066467285
Validation loss: 2.0570744237592145

Epoch: 6| Step: 8
Training loss: 1.4730863571166992
Validation loss: 2.049399193897042

Epoch: 6| Step: 9
Training loss: 1.9634406566619873
Validation loss: 2.070155966666437

Epoch: 6| Step: 10
Training loss: 1.4601614475250244
Validation loss: 2.0684615104429183

Epoch: 6| Step: 11
Training loss: 1.2406415939331055
Validation loss: 2.0333420307405534

Epoch: 6| Step: 12
Training loss: 2.3546652793884277
Validation loss: 2.053653840095766

Epoch: 6| Step: 13
Training loss: 0.7796785831451416
Validation loss: 2.0592794059425272

Epoch: 328| Step: 0
Training loss: 1.594664454460144
Validation loss: 2.04197463937985

Epoch: 6| Step: 1
Training loss: 1.9872827529907227
Validation loss: 2.066552677462178

Epoch: 6| Step: 2
Training loss: 1.4998011589050293
Validation loss: 2.045679946099558

Epoch: 6| Step: 3
Training loss: 1.5490188598632812
Validation loss: 2.0747738499795236

Epoch: 6| Step: 4
Training loss: 1.935612678527832
Validation loss: 2.0771799010615193

Epoch: 6| Step: 5
Training loss: 1.789928674697876
Validation loss: 2.0831477795877764

Epoch: 6| Step: 6
Training loss: 1.705873966217041
Validation loss: 2.0484295019539456

Epoch: 6| Step: 7
Training loss: 1.4065163135528564
Validation loss: 2.0712724078086113

Epoch: 6| Step: 8
Training loss: 1.4614744186401367
Validation loss: 2.0970294091009323

Epoch: 6| Step: 9
Training loss: 0.9351138472557068
Validation loss: 2.091157741444085

Epoch: 6| Step: 10
Training loss: 2.1194252967834473
Validation loss: 2.035027475767238

Epoch: 6| Step: 11
Training loss: 2.4955296516418457
Validation loss: 2.0755871534347534

Epoch: 6| Step: 12
Training loss: 1.179722547531128
Validation loss: 2.0564403956936252

Epoch: 6| Step: 13
Training loss: 1.431746006011963
Validation loss: 2.0585369089598298

Epoch: 329| Step: 0
Training loss: 1.9606176614761353
Validation loss: 2.0433248371206303

Epoch: 6| Step: 1
Training loss: 1.6767187118530273
Validation loss: 2.012905119567789

Epoch: 6| Step: 2
Training loss: 2.256237030029297
Validation loss: 2.03761544535237

Epoch: 6| Step: 3
Training loss: 2.0790772438049316
Validation loss: 2.061746874163228

Epoch: 6| Step: 4
Training loss: 1.6817002296447754
Validation loss: 2.0598874104920255

Epoch: 6| Step: 5
Training loss: 1.2449159622192383
Validation loss: 2.0468312412179928

Epoch: 6| Step: 6
Training loss: 1.4158909320831299
Validation loss: 2.0480130718600367

Epoch: 6| Step: 7
Training loss: 1.6965246200561523
Validation loss: 2.031325876071889

Epoch: 6| Step: 8
Training loss: 1.4556739330291748
Validation loss: 2.0427529863131944

Epoch: 6| Step: 9
Training loss: 1.4361438751220703
Validation loss: 2.0222816903104066

Epoch: 6| Step: 10
Training loss: 0.7226089239120483
Validation loss: 2.0477643615456036

Epoch: 6| Step: 11
Training loss: 1.6637260913848877
Validation loss: 2.0272948383003153

Epoch: 6| Step: 12
Training loss: 2.9375317096710205
Validation loss: 2.088954794791437

Epoch: 6| Step: 13
Training loss: 1.3841291666030884
Validation loss: 2.046309563421434

Epoch: 330| Step: 0
Training loss: 1.8506109714508057
Validation loss: 2.0809492321424585

Epoch: 6| Step: 1
Training loss: 1.4270782470703125
Validation loss: 2.0905711599575576

Epoch: 6| Step: 2
Training loss: 1.8808932304382324
Validation loss: 2.0300952490939888

Epoch: 6| Step: 3
Training loss: 1.7005970478057861
Validation loss: 2.040945951656629

Epoch: 6| Step: 4
Training loss: 1.706257939338684
Validation loss: 2.049448137642235

Epoch: 6| Step: 5
Training loss: 1.3610801696777344
Validation loss: 2.061261725682084

Epoch: 6| Step: 6
Training loss: 1.7942008972167969
Validation loss: 2.0864662611356346

Epoch: 6| Step: 7
Training loss: 1.533543348312378
Validation loss: 2.062447735058364

Epoch: 6| Step: 8
Training loss: 1.6993036270141602
Validation loss: 2.028871541382164

Epoch: 6| Step: 9
Training loss: 2.205958843231201
Validation loss: 2.073919186028101

Epoch: 6| Step: 10
Training loss: 1.6868460178375244
Validation loss: 2.0966743884548062

Epoch: 6| Step: 11
Training loss: 1.6142916679382324
Validation loss: 2.119787739169213

Epoch: 6| Step: 12
Training loss: 1.618119239807129
Validation loss: 2.0832134651881393

Epoch: 6| Step: 13
Training loss: 0.7803537249565125
Validation loss: 2.0729666615045197

Epoch: 331| Step: 0
Training loss: 1.9322296380996704
Validation loss: 2.058487812678019

Epoch: 6| Step: 1
Training loss: 1.827877402305603
Validation loss: 2.053974428484517

Epoch: 6| Step: 2
Training loss: 1.9833478927612305
Validation loss: 2.062128864308839

Epoch: 6| Step: 3
Training loss: 2.1239776611328125
Validation loss: 2.0254684596933346

Epoch: 6| Step: 4
Training loss: 1.5050685405731201
Validation loss: 2.0546333046369654

Epoch: 6| Step: 5
Training loss: 1.593582272529602
Validation loss: 2.0030400855566866

Epoch: 6| Step: 6
Training loss: 1.9174139499664307
Validation loss: 2.0031409084155993

Epoch: 6| Step: 7
Training loss: 1.3031344413757324
Validation loss: 2.0314901990275227

Epoch: 6| Step: 8
Training loss: 1.426398754119873
Validation loss: 2.0378068775259037

Epoch: 6| Step: 9
Training loss: 2.172635316848755
Validation loss: 2.0517080496716242

Epoch: 6| Step: 10
Training loss: 1.0632503032684326
Validation loss: 2.040548898840463

Epoch: 6| Step: 11
Training loss: 1.5973248481750488
Validation loss: 2.06946426181383

Epoch: 6| Step: 12
Training loss: 1.8164734840393066
Validation loss: 2.0175754318955126

Epoch: 6| Step: 13
Training loss: 0.8884131908416748
Validation loss: 2.0514864280659664

Epoch: 332| Step: 0
Training loss: 1.6951817274093628
Validation loss: 2.1165024080584125

Epoch: 6| Step: 1
Training loss: 2.186616897583008
Validation loss: 2.103377462715231

Epoch: 6| Step: 2
Training loss: 1.2646808624267578
Validation loss: 2.151154830891599

Epoch: 6| Step: 3
Training loss: 1.9104509353637695
Validation loss: 2.155748031472647

Epoch: 6| Step: 4
Training loss: 1.9717986583709717
Validation loss: 2.162953520333895

Epoch: 6| Step: 5
Training loss: 1.8194526433944702
Validation loss: 2.1584842922866985

Epoch: 6| Step: 6
Training loss: 1.3807120323181152
Validation loss: 2.155544238705789

Epoch: 6| Step: 7
Training loss: 1.8997242450714111
Validation loss: 2.1611491031544183

Epoch: 6| Step: 8
Training loss: 2.141183853149414
Validation loss: 2.1583912013679423

Epoch: 6| Step: 9
Training loss: 1.5473263263702393
Validation loss: 2.1232446470568256

Epoch: 6| Step: 10
Training loss: 1.455485224723816
Validation loss: 2.1088142061746247

Epoch: 6| Step: 11
Training loss: 1.189712405204773
Validation loss: 2.1024429669944187

Epoch: 6| Step: 12
Training loss: 1.4240450859069824
Validation loss: 2.0748232346709057

Epoch: 6| Step: 13
Training loss: 1.7649614810943604
Validation loss: 2.0545996324990385

Epoch: 333| Step: 0
Training loss: 1.8223426342010498
Validation loss: 2.0528446756383425

Epoch: 6| Step: 1
Training loss: 2.2862749099731445
Validation loss: 2.0387486898770897

Epoch: 6| Step: 2
Training loss: 1.1371185779571533
Validation loss: 2.038226125060871

Epoch: 6| Step: 3
Training loss: 1.5719242095947266
Validation loss: 2.0531899018954207

Epoch: 6| Step: 4
Training loss: 1.5840942859649658
Validation loss: 2.03837493670884

Epoch: 6| Step: 5
Training loss: 1.9960534572601318
Validation loss: 2.053692081923126

Epoch: 6| Step: 6
Training loss: 1.6429848670959473
Validation loss: 2.0603989631898942

Epoch: 6| Step: 7
Training loss: 1.7049444913864136
Validation loss: 2.0497279987540296

Epoch: 6| Step: 8
Training loss: 1.6794750690460205
Validation loss: 2.0371069446686776

Epoch: 6| Step: 9
Training loss: 1.7789887189865112
Validation loss: 2.0314563064165014

Epoch: 6| Step: 10
Training loss: 1.132439374923706
Validation loss: 2.036066262952743

Epoch: 6| Step: 11
Training loss: 2.0682897567749023
Validation loss: 2.051156182442942

Epoch: 6| Step: 12
Training loss: 1.604491949081421
Validation loss: 2.0277707833115772

Epoch: 6| Step: 13
Training loss: 0.947391927242279
Validation loss: 2.0661649473251833

Epoch: 334| Step: 0
Training loss: 1.5812528133392334
Validation loss: 2.065637162936631

Epoch: 6| Step: 1
Training loss: 1.0442674160003662
Validation loss: 2.0296077728271484

Epoch: 6| Step: 2
Training loss: 1.131490707397461
Validation loss: 2.0597420430952504

Epoch: 6| Step: 3
Training loss: 1.6678948402404785
Validation loss: 2.0916430706618936

Epoch: 6| Step: 4
Training loss: 1.7239043712615967
Validation loss: 2.1296052227738085

Epoch: 6| Step: 5
Training loss: 2.287529945373535
Validation loss: 2.085509241268199

Epoch: 6| Step: 6
Training loss: 1.493471384048462
Validation loss: 2.1042543226672756

Epoch: 6| Step: 7
Training loss: 1.5555651187896729
Validation loss: 2.1293396065312047

Epoch: 6| Step: 8
Training loss: 2.3342742919921875
Validation loss: 2.1244151105162916

Epoch: 6| Step: 9
Training loss: 1.7174192667007446
Validation loss: 2.1344306443327214

Epoch: 6| Step: 10
Training loss: 1.716285228729248
Validation loss: 2.1001337920465777

Epoch: 6| Step: 11
Training loss: 1.4680919647216797
Validation loss: 2.1004639620422036

Epoch: 6| Step: 12
Training loss: 1.8553193807601929
Validation loss: 2.0955261453505485

Epoch: 6| Step: 13
Training loss: 1.08699369430542
Validation loss: 2.093989265862332

Epoch: 335| Step: 0
Training loss: 1.6194772720336914
Validation loss: 2.085476936832551

Epoch: 6| Step: 1
Training loss: 1.6041724681854248
Validation loss: 2.044443271493399

Epoch: 6| Step: 2
Training loss: 1.827265977859497
Validation loss: 2.0453472150269376

Epoch: 6| Step: 3
Training loss: 1.674118161201477
Validation loss: 2.036909986567754

Epoch: 6| Step: 4
Training loss: 1.3412206172943115
Validation loss: 2.025004489447481

Epoch: 6| Step: 5
Training loss: 1.3168525695800781
Validation loss: 2.0858916057053434

Epoch: 6| Step: 6
Training loss: 1.9966380596160889
Validation loss: 2.1051696269742903

Epoch: 6| Step: 7
Training loss: 1.6360658407211304
Validation loss: 2.017370646999728

Epoch: 6| Step: 8
Training loss: 1.4786133766174316
Validation loss: 2.048649876348434

Epoch: 6| Step: 9
Training loss: 1.8825618028640747
Validation loss: 2.057261154215823

Epoch: 6| Step: 10
Training loss: 1.597137212753296
Validation loss: 2.0274154165739655

Epoch: 6| Step: 11
Training loss: 1.7677295207977295
Validation loss: 2.048309196708023

Epoch: 6| Step: 12
Training loss: 1.6826422214508057
Validation loss: 2.1009678545818535

Epoch: 6| Step: 13
Training loss: 2.041823387145996
Validation loss: 2.0756834860770934

Epoch: 336| Step: 0
Training loss: 1.4572858810424805
Validation loss: 2.0675272146860757

Epoch: 6| Step: 1
Training loss: 1.3564224243164062
Validation loss: 2.065136840266566

Epoch: 6| Step: 2
Training loss: 1.5767759084701538
Validation loss: 2.0809726202359764

Epoch: 6| Step: 3
Training loss: 1.7707079648971558
Validation loss: 2.091651253802802

Epoch: 6| Step: 4
Training loss: 2.503312826156616
Validation loss: 2.07009365225351

Epoch: 6| Step: 5
Training loss: 1.4357655048370361
Validation loss: 2.0555413205136537

Epoch: 6| Step: 6
Training loss: 0.9699015617370605
Validation loss: 2.049862519387276

Epoch: 6| Step: 7
Training loss: 1.544120192527771
Validation loss: 2.073496223777853

Epoch: 6| Step: 8
Training loss: 1.949885368347168
Validation loss: 2.0535182491425545

Epoch: 6| Step: 9
Training loss: 2.4661459922790527
Validation loss: 2.0821521525741904

Epoch: 6| Step: 10
Training loss: 1.3977172374725342
Validation loss: 2.0244467617363058

Epoch: 6| Step: 11
Training loss: 1.9930106401443481
Validation loss: 2.0216444794849684

Epoch: 6| Step: 12
Training loss: 1.2040835618972778
Validation loss: 2.0358876771824335

Epoch: 6| Step: 13
Training loss: 1.2800827026367188
Validation loss: 2.0217439987326182

Epoch: 337| Step: 0
Training loss: 1.9337412118911743
Validation loss: 2.0489087540616273

Epoch: 6| Step: 1
Training loss: 2.4727368354797363
Validation loss: 2.0833686961922595

Epoch: 6| Step: 2
Training loss: 0.8461853861808777
Validation loss: 2.052227061281922

Epoch: 6| Step: 3
Training loss: 2.0692291259765625
Validation loss: 2.047114345335191

Epoch: 6| Step: 4
Training loss: 1.3478692770004272
Validation loss: 2.066905258804239

Epoch: 6| Step: 5
Training loss: 1.63222336769104
Validation loss: 2.100909028002011

Epoch: 6| Step: 6
Training loss: 1.9119793176651
Validation loss: 2.1195999524926625

Epoch: 6| Step: 7
Training loss: 1.1589176654815674
Validation loss: 2.133432944615682

Epoch: 6| Step: 8
Training loss: 1.4790945053100586
Validation loss: 2.114787627291936

Epoch: 6| Step: 9
Training loss: 1.913703203201294
Validation loss: 2.113099657079225

Epoch: 6| Step: 10
Training loss: 0.9967386722564697
Validation loss: 2.1008046519371772

Epoch: 6| Step: 11
Training loss: 2.067350149154663
Validation loss: 2.0966371092745053

Epoch: 6| Step: 12
Training loss: 1.93427312374115
Validation loss: 2.1159249133961175

Epoch: 6| Step: 13
Training loss: 1.6909260749816895
Validation loss: 2.112883255045901

Epoch: 338| Step: 0
Training loss: 2.128598213195801
Validation loss: 2.0584365334562076

Epoch: 6| Step: 1
Training loss: 1.773632287979126
Validation loss: 2.0396373079669092

Epoch: 6| Step: 2
Training loss: 1.6944944858551025
Validation loss: 2.058772774152858

Epoch: 6| Step: 3
Training loss: 1.2415127754211426
Validation loss: 2.043048959906383

Epoch: 6| Step: 4
Training loss: 1.4007869958877563
Validation loss: 2.0436649732692267

Epoch: 6| Step: 5
Training loss: 1.6116524934768677
Validation loss: 2.055860052826584

Epoch: 6| Step: 6
Training loss: 1.608826756477356
Validation loss: 2.053947589730704

Epoch: 6| Step: 7
Training loss: 1.6352641582489014
Validation loss: 2.0500400194557766

Epoch: 6| Step: 8
Training loss: 1.1929258108139038
Validation loss: 2.0255091215974543

Epoch: 6| Step: 9
Training loss: 1.875530481338501
Validation loss: 2.034299473608694

Epoch: 6| Step: 10
Training loss: 1.5608688592910767
Validation loss: 2.080385467057587

Epoch: 6| Step: 11
Training loss: 2.1793689727783203
Validation loss: 2.0518042054227603

Epoch: 6| Step: 12
Training loss: 1.1807425022125244
Validation loss: 2.063635717156113

Epoch: 6| Step: 13
Training loss: 2.107215404510498
Validation loss: 2.0613650096360074

Epoch: 339| Step: 0
Training loss: 1.0503284931182861
Validation loss: 2.056045587344836

Epoch: 6| Step: 1
Training loss: 2.0993590354919434
Validation loss: 2.0744733041332615

Epoch: 6| Step: 2
Training loss: 1.962629795074463
Validation loss: 2.082698018320145

Epoch: 6| Step: 3
Training loss: 1.7515418529510498
Validation loss: 2.048657932589131

Epoch: 6| Step: 4
Training loss: 1.3571001291275024
Validation loss: 2.042844759520664

Epoch: 6| Step: 5
Training loss: 1.7680734395980835
Validation loss: 2.028219780614299

Epoch: 6| Step: 6
Training loss: 1.1700925827026367
Validation loss: 2.060217877869965

Epoch: 6| Step: 7
Training loss: 2.0543274879455566
Validation loss: 2.074443719720328

Epoch: 6| Step: 8
Training loss: 1.9260237216949463
Validation loss: 2.0649806273880826

Epoch: 6| Step: 9
Training loss: 1.5393223762512207
Validation loss: 2.080194201520694

Epoch: 6| Step: 10
Training loss: 1.3003289699554443
Validation loss: 2.0515181031278384

Epoch: 6| Step: 11
Training loss: 1.897946834564209
Validation loss: 2.041672755313176

Epoch: 6| Step: 12
Training loss: 1.5204640626907349
Validation loss: 2.065150462171083

Epoch: 6| Step: 13
Training loss: 1.908933401107788
Validation loss: 2.063610722941737

Epoch: 340| Step: 0
Training loss: 2.270580291748047
Validation loss: 2.074941865859493

Epoch: 6| Step: 1
Training loss: 2.4918065071105957
Validation loss: 2.057053781324817

Epoch: 6| Step: 2
Training loss: 1.4620258808135986
Validation loss: 2.087307758228753

Epoch: 6| Step: 3
Training loss: 1.2706689834594727
Validation loss: 2.067177426430487

Epoch: 6| Step: 4
Training loss: 1.9864888191223145
Validation loss: 2.0690684215996855

Epoch: 6| Step: 5
Training loss: 1.7661373615264893
Validation loss: 2.048896401159225

Epoch: 6| Step: 6
Training loss: 1.6107664108276367
Validation loss: 2.1085291472814416

Epoch: 6| Step: 7
Training loss: 1.6302189826965332
Validation loss: 2.071100611840525

Epoch: 6| Step: 8
Training loss: 1.0378422737121582
Validation loss: 2.07719866178369

Epoch: 6| Step: 9
Training loss: 1.561590552330017
Validation loss: 2.0678223256141908

Epoch: 6| Step: 10
Training loss: 1.3230504989624023
Validation loss: 2.0923537490188435

Epoch: 6| Step: 11
Training loss: 1.4993324279785156
Validation loss: 2.0688130317195768

Epoch: 6| Step: 12
Training loss: 1.6928443908691406
Validation loss: 2.1199963092803955

Epoch: 6| Step: 13
Training loss: 1.5834412574768066
Validation loss: 2.0884605287223734

Epoch: 341| Step: 0
Training loss: 1.8355315923690796
Validation loss: 2.049119039248395

Epoch: 6| Step: 1
Training loss: 1.4684494733810425
Validation loss: 2.089668636680931

Epoch: 6| Step: 2
Training loss: 1.6748723983764648
Validation loss: 2.0798433570451635

Epoch: 6| Step: 3
Training loss: 1.1740765571594238
Validation loss: 2.0492182829046763

Epoch: 6| Step: 4
Training loss: 1.8146429061889648
Validation loss: 2.0451309578393095

Epoch: 6| Step: 5
Training loss: 1.5936346054077148
Validation loss: 2.0289453178323726

Epoch: 6| Step: 6
Training loss: 1.336223840713501
Validation loss: 2.059504014189525

Epoch: 6| Step: 7
Training loss: 1.7738531827926636
Validation loss: 2.0451610985622612

Epoch: 6| Step: 8
Training loss: 1.3342703580856323
Validation loss: 2.003291106993152

Epoch: 6| Step: 9
Training loss: 1.7847869396209717
Validation loss: 2.0429088710456766

Epoch: 6| Step: 10
Training loss: 1.645262598991394
Validation loss: 2.0721313979036067

Epoch: 6| Step: 11
Training loss: 1.667921781539917
Validation loss: 2.0547461996796312

Epoch: 6| Step: 12
Training loss: 2.021998405456543
Validation loss: 2.053726680817143

Epoch: 6| Step: 13
Training loss: 1.9517885446548462
Validation loss: 2.0849560024917766

Epoch: 342| Step: 0
Training loss: 2.4265248775482178
Validation loss: 2.014401007724065

Epoch: 6| Step: 1
Training loss: 1.326202154159546
Validation loss: 2.067208141408941

Epoch: 6| Step: 2
Training loss: 2.376791000366211
Validation loss: 2.060180797371813

Epoch: 6| Step: 3
Training loss: 1.8898690938949585
Validation loss: 2.073432812126734

Epoch: 6| Step: 4
Training loss: 1.3494529724121094
Validation loss: 2.082358960182436

Epoch: 6| Step: 5
Training loss: 1.4000496864318848
Validation loss: 2.1421849317448114

Epoch: 6| Step: 6
Training loss: 1.401780605316162
Validation loss: 2.103935674954486

Epoch: 6| Step: 7
Training loss: 1.9315992593765259
Validation loss: 2.1079421069032405

Epoch: 6| Step: 8
Training loss: 1.4971413612365723
Validation loss: 2.107131535007108

Epoch: 6| Step: 9
Training loss: 1.2525534629821777
Validation loss: 2.0830324542137886

Epoch: 6| Step: 10
Training loss: 1.5232138633728027
Validation loss: 2.090796221968948

Epoch: 6| Step: 11
Training loss: 1.39182710647583
Validation loss: 2.0666418396016604

Epoch: 6| Step: 12
Training loss: 1.1999130249023438
Validation loss: 2.0359552880769134

Epoch: 6| Step: 13
Training loss: 2.7718544006347656
Validation loss: 2.058956359022407

Epoch: 343| Step: 0
Training loss: 1.9049527645111084
Validation loss: 2.0036004602268176

Epoch: 6| Step: 1
Training loss: 1.649245262145996
Validation loss: 2.0641648025922876

Epoch: 6| Step: 2
Training loss: 1.4727771282196045
Validation loss: 2.04215415318807

Epoch: 6| Step: 3
Training loss: 1.8288830518722534
Validation loss: 2.0528141349874516

Epoch: 6| Step: 4
Training loss: 1.5821285247802734
Validation loss: 2.042770670306298

Epoch: 6| Step: 5
Training loss: 1.5164023637771606
Validation loss: 2.030133443493997

Epoch: 6| Step: 6
Training loss: 2.0592546463012695
Validation loss: 2.0379373565796883

Epoch: 6| Step: 7
Training loss: 1.8711857795715332
Validation loss: 2.0621737600654684

Epoch: 6| Step: 8
Training loss: 1.143172264099121
Validation loss: 2.0364104701626684

Epoch: 6| Step: 9
Training loss: 1.7140092849731445
Validation loss: 2.089258952807355

Epoch: 6| Step: 10
Training loss: 2.162266492843628
Validation loss: 2.0956292101131972

Epoch: 6| Step: 11
Training loss: 1.2360671758651733
Validation loss: 2.0389600005201114

Epoch: 6| Step: 12
Training loss: 1.232805609703064
Validation loss: 2.0588260414779826

Epoch: 6| Step: 13
Training loss: 1.6945816278457642
Validation loss: 2.0664072267470823

Epoch: 344| Step: 0
Training loss: 1.369879961013794
Validation loss: 2.0255604674739223

Epoch: 6| Step: 1
Training loss: 1.3630578517913818
Validation loss: 2.0576355354760283

Epoch: 6| Step: 2
Training loss: 1.5605919361114502
Validation loss: 2.073993880261657

Epoch: 6| Step: 3
Training loss: 1.9962530136108398
Validation loss: 2.1069069306055703

Epoch: 6| Step: 4
Training loss: 1.9239401817321777
Validation loss: 2.0755738019943237

Epoch: 6| Step: 5
Training loss: 1.5502618551254272
Validation loss: 2.07146797128903

Epoch: 6| Step: 6
Training loss: 1.8168433904647827
Validation loss: 2.075118295608028

Epoch: 6| Step: 7
Training loss: 1.7854976654052734
Validation loss: 2.071672021701772

Epoch: 6| Step: 8
Training loss: 1.8242114782333374
Validation loss: 2.0214646452216694

Epoch: 6| Step: 9
Training loss: 1.3823723793029785
Validation loss: 2.0269675934186546

Epoch: 6| Step: 10
Training loss: 1.1852405071258545
Validation loss: 2.0490163192954114

Epoch: 6| Step: 11
Training loss: 1.6465234756469727
Validation loss: 2.080561794260497

Epoch: 6| Step: 12
Training loss: 1.4065386056900024
Validation loss: 2.0631768703460693

Epoch: 6| Step: 13
Training loss: 2.4100255966186523
Validation loss: 2.0624187761737454

Epoch: 345| Step: 0
Training loss: 2.2602882385253906
Validation loss: 2.0610291637400144

Epoch: 6| Step: 1
Training loss: 1.554769515991211
Validation loss: 2.0340411034963464

Epoch: 6| Step: 2
Training loss: 1.6803511381149292
Validation loss: 2.0883606454377532

Epoch: 6| Step: 3
Training loss: 1.855822205543518
Validation loss: 2.029491873197658

Epoch: 6| Step: 4
Training loss: 1.4845659732818604
Validation loss: 2.0739783010175152

Epoch: 6| Step: 5
Training loss: 1.3748013973236084
Validation loss: 2.01115313524841

Epoch: 6| Step: 6
Training loss: 1.2890868186950684
Validation loss: 2.059296300334315

Epoch: 6| Step: 7
Training loss: 1.5236687660217285
Validation loss: 2.0615625214833084

Epoch: 6| Step: 8
Training loss: 1.484753131866455
Validation loss: 2.0520346754340717

Epoch: 6| Step: 9
Training loss: 0.9454913139343262
Validation loss: 2.085147196246732

Epoch: 6| Step: 10
Training loss: 2.568188190460205
Validation loss: 2.0564729167569067

Epoch: 6| Step: 11
Training loss: 2.0126609802246094
Validation loss: 2.0864126605372273

Epoch: 6| Step: 12
Training loss: 1.6869392395019531
Validation loss: 2.044271085851936

Epoch: 6| Step: 13
Training loss: 0.7265956401824951
Validation loss: 2.103169415586738

Epoch: 346| Step: 0
Training loss: 1.9255361557006836
Validation loss: 2.106086834784477

Epoch: 6| Step: 1
Training loss: 2.058199167251587
Validation loss: 2.1013371200971704

Epoch: 6| Step: 2
Training loss: 1.3919026851654053
Validation loss: 2.083236227753342

Epoch: 6| Step: 3
Training loss: 2.029191017150879
Validation loss: 2.0716547504548104

Epoch: 6| Step: 4
Training loss: 1.6298890113830566
Validation loss: 2.106080855092695

Epoch: 6| Step: 5
Training loss: 1.420663595199585
Validation loss: 2.0801663116742204

Epoch: 6| Step: 6
Training loss: 1.90122389793396
Validation loss: 2.0793861343014624

Epoch: 6| Step: 7
Training loss: 1.02448308467865
Validation loss: 2.042907440534202

Epoch: 6| Step: 8
Training loss: 2.4105265140533447
Validation loss: 2.0691830804271083

Epoch: 6| Step: 9
Training loss: 1.0885756015777588
Validation loss: 2.058711405723326

Epoch: 6| Step: 10
Training loss: 1.5185227394104004
Validation loss: 2.0396606101784656

Epoch: 6| Step: 11
Training loss: 1.674107313156128
Validation loss: 2.076310009084722

Epoch: 6| Step: 12
Training loss: 1.4089804887771606
Validation loss: 2.048853402496666

Epoch: 6| Step: 13
Training loss: 1.1999032497406006
Validation loss: 2.0422303086967877

Epoch: 347| Step: 0
Training loss: 1.436682105064392
Validation loss: 2.040610441597559

Epoch: 6| Step: 1
Training loss: 1.4563993215560913
Validation loss: 2.056234085431663

Epoch: 6| Step: 2
Training loss: 0.9344727993011475
Validation loss: 2.0520736171353247

Epoch: 6| Step: 3
Training loss: 1.5087521076202393
Validation loss: 2.030659188506424

Epoch: 6| Step: 4
Training loss: 1.689136266708374
Validation loss: 2.0704015698484195

Epoch: 6| Step: 5
Training loss: 2.3480656147003174
Validation loss: 2.071234513354558

Epoch: 6| Step: 6
Training loss: 1.4133169651031494
Validation loss: 2.0526203186281267

Epoch: 6| Step: 7
Training loss: 1.6037003993988037
Validation loss: 2.0367872548359696

Epoch: 6| Step: 8
Training loss: 2.3603663444519043
Validation loss: 2.040745855659567

Epoch: 6| Step: 9
Training loss: 1.8186626434326172
Validation loss: 2.0591085533941946

Epoch: 6| Step: 10
Training loss: 1.1958227157592773
Validation loss: 2.0643338926376833

Epoch: 6| Step: 11
Training loss: 1.8055672645568848
Validation loss: 1.9937089476534116

Epoch: 6| Step: 12
Training loss: 1.852806568145752
Validation loss: 2.017449903231795

Epoch: 6| Step: 13
Training loss: 0.8483272790908813
Validation loss: 2.061250925064087

Epoch: 348| Step: 0
Training loss: 1.7183818817138672
Validation loss: 2.0563505182984056

Epoch: 6| Step: 1
Training loss: 1.5742237567901611
Validation loss: 2.0851912511292325

Epoch: 6| Step: 2
Training loss: 1.6028964519500732
Validation loss: 2.0731705004169094

Epoch: 6| Step: 3
Training loss: 1.8034486770629883
Validation loss: 2.0282914958974367

Epoch: 6| Step: 4
Training loss: 1.54715895652771
Validation loss: 2.073203456017279

Epoch: 6| Step: 5
Training loss: 1.3589050769805908
Validation loss: 2.0557680386368946

Epoch: 6| Step: 6
Training loss: 1.4690797328948975
Validation loss: 2.0659025561424995

Epoch: 6| Step: 7
Training loss: 1.4364370107650757
Validation loss: 2.1153169088466193

Epoch: 6| Step: 8
Training loss: 2.0137999057769775
Validation loss: 2.0980876966189315

Epoch: 6| Step: 9
Training loss: 2.119537830352783
Validation loss: 2.1015559627163793

Epoch: 6| Step: 10
Training loss: 0.9824886322021484
Validation loss: 2.112550494491413

Epoch: 6| Step: 11
Training loss: 1.3942391872406006
Validation loss: 2.0660944266985823

Epoch: 6| Step: 12
Training loss: 1.8065327405929565
Validation loss: 2.061878276127641

Epoch: 6| Step: 13
Training loss: 2.1669862270355225
Validation loss: 2.0570311033597557

Epoch: 349| Step: 0
Training loss: 1.3942527770996094
Validation loss: 2.1091966372664257

Epoch: 6| Step: 1
Training loss: 1.6568677425384521
Validation loss: 2.0639498028703915

Epoch: 6| Step: 2
Training loss: 1.6301051378250122
Validation loss: 2.0486608961577057

Epoch: 6| Step: 3
Training loss: 1.8673843145370483
Validation loss: 2.0607711679192

Epoch: 6| Step: 4
Training loss: 1.6436266899108887
Validation loss: 2.0791122208359423

Epoch: 6| Step: 5
Training loss: 1.5817549228668213
Validation loss: 2.0758262116421937

Epoch: 6| Step: 6
Training loss: 1.7709410190582275
Validation loss: 2.052138443916075

Epoch: 6| Step: 7
Training loss: 2.2242183685302734
Validation loss: 2.0502238042892946

Epoch: 6| Step: 8
Training loss: 1.3570430278778076
Validation loss: 2.0878253239457325

Epoch: 6| Step: 9
Training loss: 1.4442883729934692
Validation loss: 2.056008532483091

Epoch: 6| Step: 10
Training loss: 2.223906993865967
Validation loss: 2.054503107583651

Epoch: 6| Step: 11
Training loss: 1.926783561706543
Validation loss: 2.085491466265853

Epoch: 6| Step: 12
Training loss: 1.0747997760772705
Validation loss: 2.03502582990995

Epoch: 6| Step: 13
Training loss: 0.8274495005607605
Validation loss: 2.053668172128739

Epoch: 350| Step: 0
Training loss: 1.606365442276001
Validation loss: 2.0786040649619153

Epoch: 6| Step: 1
Training loss: 2.4142134189605713
Validation loss: 2.047054458689946

Epoch: 6| Step: 2
Training loss: 1.0727750062942505
Validation loss: 2.045260601146247

Epoch: 6| Step: 3
Training loss: 1.9031165838241577
Validation loss: 2.0569173212974303

Epoch: 6| Step: 4
Training loss: 1.4620003700256348
Validation loss: 2.028859794780772

Epoch: 6| Step: 5
Training loss: 1.708781361579895
Validation loss: 2.058282857300133

Epoch: 6| Step: 6
Training loss: 1.2392961978912354
Validation loss: 2.0495222204474994

Epoch: 6| Step: 7
Training loss: 1.0547916889190674
Validation loss: 2.0640884278922953

Epoch: 6| Step: 8
Training loss: 1.9937024116516113
Validation loss: 2.0199758288680867

Epoch: 6| Step: 9
Training loss: 2.1766061782836914
Validation loss: 2.0877520858600573

Epoch: 6| Step: 10
Training loss: 1.6997156143188477
Validation loss: 2.0675724385887064

Epoch: 6| Step: 11
Training loss: 1.1646099090576172
Validation loss: 2.0740363008232525

Epoch: 6| Step: 12
Training loss: 1.6881885528564453
Validation loss: 2.090048445168362

Epoch: 6| Step: 13
Training loss: 1.5576125383377075
Validation loss: 2.1178993730134863

Epoch: 351| Step: 0
Training loss: 1.464625358581543
Validation loss: 2.1016406269483667

Epoch: 6| Step: 1
Training loss: 1.6872423887252808
Validation loss: 2.118678492884482

Epoch: 6| Step: 2
Training loss: 1.7420227527618408
Validation loss: 2.1252267924688195

Epoch: 6| Step: 3
Training loss: 1.5749125480651855
Validation loss: 2.076535209532707

Epoch: 6| Step: 4
Training loss: 1.1769012212753296
Validation loss: 2.088655610238352

Epoch: 6| Step: 5
Training loss: 1.9881491661071777
Validation loss: 2.103740716493258

Epoch: 6| Step: 6
Training loss: 1.7496970891952515
Validation loss: 2.0660962597016366

Epoch: 6| Step: 7
Training loss: 1.7455987930297852
Validation loss: 2.1081180162327264

Epoch: 6| Step: 8
Training loss: 2.0165719985961914
Validation loss: 2.1045747854376353

Epoch: 6| Step: 9
Training loss: 1.376265048980713
Validation loss: 2.0900770130977837

Epoch: 6| Step: 10
Training loss: 1.2858091592788696
Validation loss: 2.034454454657852

Epoch: 6| Step: 11
Training loss: 1.7626475095748901
Validation loss: 2.0769260416748705

Epoch: 6| Step: 12
Training loss: 1.7326116561889648
Validation loss: 2.0604109841008342

Epoch: 6| Step: 13
Training loss: 1.1169425249099731
Validation loss: 2.101060644272835

Epoch: 352| Step: 0
Training loss: 1.241527795791626
Validation loss: 2.043959984215357

Epoch: 6| Step: 1
Training loss: 1.3128176927566528
Validation loss: 2.0536017007725214

Epoch: 6| Step: 2
Training loss: 1.5054399967193604
Validation loss: 2.073401685683958

Epoch: 6| Step: 3
Training loss: 2.1510863304138184
Validation loss: 2.0534953596771404

Epoch: 6| Step: 4
Training loss: 2.0940256118774414
Validation loss: 2.0409523774218816

Epoch: 6| Step: 5
Training loss: 2.2570502758026123
Validation loss: 2.0630016967814457

Epoch: 6| Step: 6
Training loss: 1.7499232292175293
Validation loss: 2.0127094496962843

Epoch: 6| Step: 7
Training loss: 1.7057499885559082
Validation loss: 2.054369386806283

Epoch: 6| Step: 8
Training loss: 1.3400487899780273
Validation loss: 2.037289205417838

Epoch: 6| Step: 9
Training loss: 1.7666633129119873
Validation loss: 2.0388527429232033

Epoch: 6| Step: 10
Training loss: 1.47872793674469
Validation loss: 2.0311573564365344

Epoch: 6| Step: 11
Training loss: 0.8268173933029175
Validation loss: 2.0640655461178032

Epoch: 6| Step: 12
Training loss: 1.3329768180847168
Validation loss: 2.0780961308428036

Epoch: 6| Step: 13
Training loss: 1.7991023063659668
Validation loss: 2.0808858845823552

Epoch: 353| Step: 0
Training loss: 1.0065491199493408
Validation loss: 2.0450951745433192

Epoch: 6| Step: 1
Training loss: 1.2786316871643066
Validation loss: 2.079182004415861

Epoch: 6| Step: 2
Training loss: 1.5524005889892578
Validation loss: 2.077877644569643

Epoch: 6| Step: 3
Training loss: 2.0808067321777344
Validation loss: 2.092302373660508

Epoch: 6| Step: 4
Training loss: 1.407261848449707
Validation loss: 2.1257947978153022

Epoch: 6| Step: 5
Training loss: 1.231403112411499
Validation loss: 2.0828938561101116

Epoch: 6| Step: 6
Training loss: 2.058403968811035
Validation loss: 2.0675453344980874

Epoch: 6| Step: 7
Training loss: 1.8505862951278687
Validation loss: 2.088039908357846

Epoch: 6| Step: 8
Training loss: 1.6594936847686768
Validation loss: 2.0611238223250195

Epoch: 6| Step: 9
Training loss: 1.4222099781036377
Validation loss: 2.0734029508406118

Epoch: 6| Step: 10
Training loss: 2.4338903427124023
Validation loss: 2.0653595501376736

Epoch: 6| Step: 11
Training loss: 1.8233349323272705
Validation loss: 2.076395551363627

Epoch: 6| Step: 12
Training loss: 0.8213719129562378
Validation loss: 2.0849651418706423

Epoch: 6| Step: 13
Training loss: 1.9305245876312256
Validation loss: 2.067030732349683

Epoch: 354| Step: 0
Training loss: 1.7004132270812988
Validation loss: 2.076626464884768

Epoch: 6| Step: 1
Training loss: 1.4459223747253418
Validation loss: 2.083537910574226

Epoch: 6| Step: 2
Training loss: 1.4718748331069946
Validation loss: 2.0641254699358376

Epoch: 6| Step: 3
Training loss: 1.4266228675842285
Validation loss: 2.0729481481736705

Epoch: 6| Step: 4
Training loss: 2.28220272064209
Validation loss: 2.0673792195576493

Epoch: 6| Step: 5
Training loss: 2.013993740081787
Validation loss: 2.0229640135201077

Epoch: 6| Step: 6
Training loss: 1.3764652013778687
Validation loss: 2.0040269333829164

Epoch: 6| Step: 7
Training loss: 1.5158166885375977
Validation loss: 2.059535734115108

Epoch: 6| Step: 8
Training loss: 1.5082365274429321
Validation loss: 2.055374489035658

Epoch: 6| Step: 9
Training loss: 1.6305468082427979
Validation loss: 2.032050414751935

Epoch: 6| Step: 10
Training loss: 1.4989032745361328
Validation loss: 2.040589863254178

Epoch: 6| Step: 11
Training loss: 1.7394744157791138
Validation loss: 2.042905546003772

Epoch: 6| Step: 12
Training loss: 1.4598174095153809
Validation loss: 2.0576697805876374

Epoch: 6| Step: 13
Training loss: 1.1007083654403687
Validation loss: 2.0631595350080922

Epoch: 355| Step: 0
Training loss: 1.800107479095459
Validation loss: 2.053372875336678

Epoch: 6| Step: 1
Training loss: 1.403183937072754
Validation loss: 2.00789818327914

Epoch: 6| Step: 2
Training loss: 2.3832178115844727
Validation loss: 2.0590975874213764

Epoch: 6| Step: 3
Training loss: 1.1003987789154053
Validation loss: 2.0373083314587994

Epoch: 6| Step: 4
Training loss: 2.1664621829986572
Validation loss: 2.0433024693560857

Epoch: 6| Step: 5
Training loss: 1.2518774271011353
Validation loss: 2.046511184784674

Epoch: 6| Step: 6
Training loss: 2.2179603576660156
Validation loss: 2.002117474873861

Epoch: 6| Step: 7
Training loss: 1.275261402130127
Validation loss: 2.0660121851069952

Epoch: 6| Step: 8
Training loss: 1.0785048007965088
Validation loss: 2.103110126269761

Epoch: 6| Step: 9
Training loss: 1.4689815044403076
Validation loss: 2.082727878324447

Epoch: 6| Step: 10
Training loss: 1.815454363822937
Validation loss: 2.067432704792228

Epoch: 6| Step: 11
Training loss: 1.965396761894226
Validation loss: 2.065517246082265

Epoch: 6| Step: 12
Training loss: 1.014387607574463
Validation loss: 2.0844164061289963

Epoch: 6| Step: 13
Training loss: 0.9423694610595703
Validation loss: 2.0923684002250753

Epoch: 356| Step: 0
Training loss: 1.6296910047531128
Validation loss: 2.0839836520533406

Epoch: 6| Step: 1
Training loss: 2.0647647380828857
Validation loss: 2.1136338287784207

Epoch: 6| Step: 2
Training loss: 1.5837689638137817
Validation loss: 2.1056769330014466

Epoch: 6| Step: 3
Training loss: 2.344576358795166
Validation loss: 2.0922864303793958

Epoch: 6| Step: 4
Training loss: 1.3574888706207275
Validation loss: 2.112678679086829

Epoch: 6| Step: 5
Training loss: 1.7308824062347412
Validation loss: 2.0936198183285293

Epoch: 6| Step: 6
Training loss: 1.407292127609253
Validation loss: 2.0925495009268484

Epoch: 6| Step: 7
Training loss: 1.5263783931732178
Validation loss: 2.0935946049228793

Epoch: 6| Step: 8
Training loss: 1.4025070667266846
Validation loss: 2.07984834588984

Epoch: 6| Step: 9
Training loss: 1.170761227607727
Validation loss: 2.1128316130689395

Epoch: 6| Step: 10
Training loss: 1.2684365510940552
Validation loss: 2.0811446597499232

Epoch: 6| Step: 11
Training loss: 1.6205732822418213
Validation loss: 2.077039726318852

Epoch: 6| Step: 12
Training loss: 2.039999485015869
Validation loss: 2.075581617252801

Epoch: 6| Step: 13
Training loss: 2.0289478302001953
Validation loss: 2.0687391142691336

Epoch: 357| Step: 0
Training loss: 1.2789323329925537
Validation loss: 2.029085395156696

Epoch: 6| Step: 1
Training loss: 1.3442981243133545
Validation loss: 2.056801951059731

Epoch: 6| Step: 2
Training loss: 1.3322625160217285
Validation loss: 2.039946758618919

Epoch: 6| Step: 3
Training loss: 1.6120798587799072
Validation loss: 2.0395912406265095

Epoch: 6| Step: 4
Training loss: 2.21176815032959
Validation loss: 2.0602655218493555

Epoch: 6| Step: 5
Training loss: 1.4933322668075562
Validation loss: 2.02125282185052

Epoch: 6| Step: 6
Training loss: 1.4815361499786377
Validation loss: 2.0509639093952794

Epoch: 6| Step: 7
Training loss: 2.2594470977783203
Validation loss: 2.0236757365606164

Epoch: 6| Step: 8
Training loss: 1.034034013748169
Validation loss: 2.045402316636937

Epoch: 6| Step: 9
Training loss: 1.8586288690567017
Validation loss: 2.0570761747257684

Epoch: 6| Step: 10
Training loss: 1.9372057914733887
Validation loss: 2.0850619680138043

Epoch: 6| Step: 11
Training loss: 1.9547936916351318
Validation loss: 2.0960327938038814

Epoch: 6| Step: 12
Training loss: 1.8171169757843018
Validation loss: 2.078608456478324

Epoch: 6| Step: 13
Training loss: 1.0467771291732788
Validation loss: 2.0858229308999996

Epoch: 358| Step: 0
Training loss: 1.4483203887939453
Validation loss: 2.084608003657351

Epoch: 6| Step: 1
Training loss: 1.99027681350708
Validation loss: 2.0950560159580682

Epoch: 6| Step: 2
Training loss: 1.1101329326629639
Validation loss: 2.0980531220795005

Epoch: 6| Step: 3
Training loss: 1.9067270755767822
Validation loss: 2.0789819725098146

Epoch: 6| Step: 4
Training loss: 2.0186209678649902
Validation loss: 2.0536089789482856

Epoch: 6| Step: 5
Training loss: 1.6692407131195068
Validation loss: 2.065505422571654

Epoch: 6| Step: 6
Training loss: 1.1036423444747925
Validation loss: 2.0341335996504752

Epoch: 6| Step: 7
Training loss: 1.0618984699249268
Validation loss: 2.0352585020885674

Epoch: 6| Step: 8
Training loss: 2.136411666870117
Validation loss: 2.0148454789192445

Epoch: 6| Step: 9
Training loss: 1.652396321296692
Validation loss: 2.0449518670317945

Epoch: 6| Step: 10
Training loss: 1.7158962488174438
Validation loss: 2.030949331098987

Epoch: 6| Step: 11
Training loss: 1.7190881967544556
Validation loss: 2.0194279968097644

Epoch: 6| Step: 12
Training loss: 1.2986811399459839
Validation loss: 2.0245226326809136

Epoch: 6| Step: 13
Training loss: 1.9143880605697632
Validation loss: 2.0271238152698805

Epoch: 359| Step: 0
Training loss: 1.3267085552215576
Validation loss: 2.0569504025161907

Epoch: 6| Step: 1
Training loss: 1.711529016494751
Validation loss: 2.049028586315852

Epoch: 6| Step: 2
Training loss: 2.029693365097046
Validation loss: 2.045179711875095

Epoch: 6| Step: 3
Training loss: 1.223084807395935
Validation loss: 2.055752863166153

Epoch: 6| Step: 4
Training loss: 1.7737300395965576
Validation loss: 2.0806286488809893

Epoch: 6| Step: 5
Training loss: 1.8738367557525635
Validation loss: 2.0879254853853615

Epoch: 6| Step: 6
Training loss: 1.7138711214065552
Validation loss: 2.0830616335715018

Epoch: 6| Step: 7
Training loss: 1.5367681980133057
Validation loss: 2.0819718632646786

Epoch: 6| Step: 8
Training loss: 1.269410490989685
Validation loss: 2.1090416087899158

Epoch: 6| Step: 9
Training loss: 1.9506652355194092
Validation loss: 2.057904592124365

Epoch: 6| Step: 10
Training loss: 0.951206624507904
Validation loss: 2.0826007884035826

Epoch: 6| Step: 11
Training loss: 2.4110260009765625
Validation loss: 2.0325407969054354

Epoch: 6| Step: 12
Training loss: 1.0663554668426514
Validation loss: 2.0646456159571165

Epoch: 6| Step: 13
Training loss: 1.80591881275177
Validation loss: 2.0458353181039133

Epoch: 360| Step: 0
Training loss: 1.61660897731781
Validation loss: 2.0535086201083277

Epoch: 6| Step: 1
Training loss: 1.6757712364196777
Validation loss: 2.038377126057943

Epoch: 6| Step: 2
Training loss: 1.4647035598754883
Validation loss: 2.08488804294217

Epoch: 6| Step: 3
Training loss: 1.5532175302505493
Validation loss: 2.0819023488670267

Epoch: 6| Step: 4
Training loss: 1.9525480270385742
Validation loss: 2.067329873320877

Epoch: 6| Step: 5
Training loss: 2.0543951988220215
Validation loss: 2.0407648778730825

Epoch: 6| Step: 6
Training loss: 1.8810393810272217
Validation loss: 2.036249978567964

Epoch: 6| Step: 7
Training loss: 1.24009370803833
Validation loss: 2.0275113223701395

Epoch: 6| Step: 8
Training loss: 0.9118517637252808
Validation loss: 2.0027333767183366

Epoch: 6| Step: 9
Training loss: 1.905000925064087
Validation loss: 2.0656035766806653

Epoch: 6| Step: 10
Training loss: 1.4445751905441284
Validation loss: 2.0760658940961285

Epoch: 6| Step: 11
Training loss: 1.5012485980987549
Validation loss: 2.0852381465255574

Epoch: 6| Step: 12
Training loss: 1.4271433353424072
Validation loss: 2.037687381108602

Epoch: 6| Step: 13
Training loss: 1.7731359004974365
Validation loss: 2.0467972460613457

Epoch: 361| Step: 0
Training loss: 1.928458571434021
Validation loss: 2.0693884139419882

Epoch: 6| Step: 1
Training loss: 1.1937792301177979
Validation loss: 2.049537056235857

Epoch: 6| Step: 2
Training loss: 2.1991071701049805
Validation loss: 2.058182947097286

Epoch: 6| Step: 3
Training loss: 1.5029157400131226
Validation loss: 2.0813899065858577

Epoch: 6| Step: 4
Training loss: 2.1469554901123047
Validation loss: 2.0699879187409596

Epoch: 6| Step: 5
Training loss: 1.1122281551361084
Validation loss: 2.079787702970607

Epoch: 6| Step: 6
Training loss: 1.2419241666793823
Validation loss: 2.0576065073731127

Epoch: 6| Step: 7
Training loss: 1.7234621047973633
Validation loss: 2.112767242616223

Epoch: 6| Step: 8
Training loss: 1.8394266366958618
Validation loss: 2.1216689950676373

Epoch: 6| Step: 9
Training loss: 1.3203010559082031
Validation loss: 2.1150017579396567

Epoch: 6| Step: 10
Training loss: 1.777703881263733
Validation loss: 2.1028972466786704

Epoch: 6| Step: 11
Training loss: 1.6277756690979004
Validation loss: 2.086807635522658

Epoch: 6| Step: 12
Training loss: 1.488302230834961
Validation loss: 2.0766286003974175

Epoch: 6| Step: 13
Training loss: 1.794628620147705
Validation loss: 2.0598503274302327

Epoch: 362| Step: 0
Training loss: 1.6948347091674805
Validation loss: 2.062019681417814

Epoch: 6| Step: 1
Training loss: 1.8163564205169678
Validation loss: 2.0323221247683287

Epoch: 6| Step: 2
Training loss: 1.6124285459518433
Validation loss: 2.032882398174655

Epoch: 6| Step: 3
Training loss: 1.7310662269592285
Validation loss: 2.0361740435323408

Epoch: 6| Step: 4
Training loss: 1.8770275115966797
Validation loss: 2.034172360615064

Epoch: 6| Step: 5
Training loss: 1.0784151554107666
Validation loss: 2.0515926884066675

Epoch: 6| Step: 6
Training loss: 1.3538703918457031
Validation loss: 2.0433036909308484

Epoch: 6| Step: 7
Training loss: 2.513519287109375
Validation loss: 2.0488013862281718

Epoch: 6| Step: 8
Training loss: 1.1742037534713745
Validation loss: 1.9969880491174676

Epoch: 6| Step: 9
Training loss: 1.5606341361999512
Validation loss: 2.0312706885799283

Epoch: 6| Step: 10
Training loss: 1.2786846160888672
Validation loss: 2.010599003043226

Epoch: 6| Step: 11
Training loss: 1.615118145942688
Validation loss: 2.069473192255984

Epoch: 6| Step: 12
Training loss: 1.7417705059051514
Validation loss: 2.0420955252903763

Epoch: 6| Step: 13
Training loss: 1.8448889255523682
Validation loss: 2.0950651835369807

Epoch: 363| Step: 0
Training loss: 1.7633988857269287
Validation loss: 2.064203934002948

Epoch: 6| Step: 1
Training loss: 2.208550453186035
Validation loss: 2.097193166773806

Epoch: 6| Step: 2
Training loss: 1.4211876392364502
Validation loss: 2.077330699530981

Epoch: 6| Step: 3
Training loss: 1.6510506868362427
Validation loss: 2.099109524039812

Epoch: 6| Step: 4
Training loss: 1.2745507955551147
Validation loss: 2.0842756071398334

Epoch: 6| Step: 5
Training loss: 1.4129588603973389
Validation loss: 2.0993724061596777

Epoch: 6| Step: 6
Training loss: 1.8581773042678833
Validation loss: 2.07925134704959

Epoch: 6| Step: 7
Training loss: 1.6638824939727783
Validation loss: 2.107342799504598

Epoch: 6| Step: 8
Training loss: 1.239749789237976
Validation loss: 2.086921056111654

Epoch: 6| Step: 9
Training loss: 1.3054572343826294
Validation loss: 2.0455225385645384

Epoch: 6| Step: 10
Training loss: 1.5266623497009277
Validation loss: 2.047842965331129

Epoch: 6| Step: 11
Training loss: 1.7342958450317383
Validation loss: 2.040717365921185

Epoch: 6| Step: 12
Training loss: 1.2540032863616943
Validation loss: 2.061828056971232

Epoch: 6| Step: 13
Training loss: 2.144801139831543
Validation loss: 2.0631010634924776

Epoch: 364| Step: 0
Training loss: 1.544998049736023
Validation loss: 2.0215153360879548

Epoch: 6| Step: 1
Training loss: 1.19870924949646
Validation loss: 2.0521541513422483

Epoch: 6| Step: 2
Training loss: 1.5873191356658936
Validation loss: 2.0734264260979107

Epoch: 6| Step: 3
Training loss: 1.5033669471740723
Validation loss: 2.033654284733598

Epoch: 6| Step: 4
Training loss: 2.0989673137664795
Validation loss: 2.073452934142082

Epoch: 6| Step: 5
Training loss: 1.2118723392486572
Validation loss: 2.0670864761516614

Epoch: 6| Step: 6
Training loss: 1.5582809448242188
Validation loss: 2.0676009911362843

Epoch: 6| Step: 7
Training loss: 1.5478944778442383
Validation loss: 2.042027997714217

Epoch: 6| Step: 8
Training loss: 1.9913774728775024
Validation loss: 2.0847982539925525

Epoch: 6| Step: 9
Training loss: 1.2442336082458496
Validation loss: 2.0470255408235776

Epoch: 6| Step: 10
Training loss: 1.8615715503692627
Validation loss: 2.095433881205897

Epoch: 6| Step: 11
Training loss: 1.5048543214797974
Validation loss: 2.0514646448114866

Epoch: 6| Step: 12
Training loss: 1.9978718757629395
Validation loss: 2.0385043390335573

Epoch: 6| Step: 13
Training loss: 1.1839301586151123
Validation loss: 2.038141995347956

Epoch: 365| Step: 0
Training loss: 1.7538514137268066
Validation loss: 2.07693176884805

Epoch: 6| Step: 1
Training loss: 2.1297779083251953
Validation loss: 2.0470918801523026

Epoch: 6| Step: 2
Training loss: 1.690392255783081
Validation loss: 2.0362320382107972

Epoch: 6| Step: 3
Training loss: 1.2331147193908691
Validation loss: 2.065793865470476

Epoch: 6| Step: 4
Training loss: 2.1789159774780273
Validation loss: 2.063356755882181

Epoch: 6| Step: 5
Training loss: 1.5301973819732666
Validation loss: 2.04059890777834

Epoch: 6| Step: 6
Training loss: 0.9349557161331177
Validation loss: 2.062473871374643

Epoch: 6| Step: 7
Training loss: 1.4845497608184814
Validation loss: 2.033336877822876

Epoch: 6| Step: 8
Training loss: 1.3804513216018677
Validation loss: 2.039214702062709

Epoch: 6| Step: 9
Training loss: 1.9396390914916992
Validation loss: 2.044919740769171

Epoch: 6| Step: 10
Training loss: 1.7538306713104248
Validation loss: 2.0406738301759124

Epoch: 6| Step: 11
Training loss: 1.3646128177642822
Validation loss: 2.0683339488121772

Epoch: 6| Step: 12
Training loss: 1.3094757795333862
Validation loss: 2.0739476603846394

Epoch: 6| Step: 13
Training loss: 1.8413827419281006
Validation loss: 2.078881199641894

Epoch: 366| Step: 0
Training loss: 1.5780341625213623
Validation loss: 2.1187354031429497

Epoch: 6| Step: 1
Training loss: 1.6427477598190308
Validation loss: 2.109716446168961

Epoch: 6| Step: 2
Training loss: 1.2109798192977905
Validation loss: 2.0972163600306355

Epoch: 6| Step: 3
Training loss: 1.4087786674499512
Validation loss: 2.1058927735974713

Epoch: 6| Step: 4
Training loss: 2.149261474609375
Validation loss: 2.151042156322028

Epoch: 6| Step: 5
Training loss: 1.9528162479400635
Validation loss: 2.116127739670456

Epoch: 6| Step: 6
Training loss: 1.382749080657959
Validation loss: 2.1232159650453957

Epoch: 6| Step: 7
Training loss: 2.1031718254089355
Validation loss: 2.0761543255980297

Epoch: 6| Step: 8
Training loss: 1.3057303428649902
Validation loss: 2.0816154992708595

Epoch: 6| Step: 9
Training loss: 1.1568840742111206
Validation loss: 2.1019497789362425

Epoch: 6| Step: 10
Training loss: 1.7135953903198242
Validation loss: 2.0906725468174105

Epoch: 6| Step: 11
Training loss: 1.7240328788757324
Validation loss: 2.05241229713604

Epoch: 6| Step: 12
Training loss: 1.3386354446411133
Validation loss: 2.0880714385740218

Epoch: 6| Step: 13
Training loss: 1.6092886924743652
Validation loss: 2.069816017663607

Epoch: 367| Step: 0
Training loss: 1.6558924913406372
Validation loss: 2.0887431213932652

Epoch: 6| Step: 1
Training loss: 1.5431954860687256
Validation loss: 2.0351610055533786

Epoch: 6| Step: 2
Training loss: 2.0650949478149414
Validation loss: 2.076699169733191

Epoch: 6| Step: 3
Training loss: 1.5679101943969727
Validation loss: 2.0445243979013092

Epoch: 6| Step: 4
Training loss: 1.5414156913757324
Validation loss: 2.0423786076166297

Epoch: 6| Step: 5
Training loss: 1.2706358432769775
Validation loss: 2.027132805957589

Epoch: 6| Step: 6
Training loss: 1.4693858623504639
Validation loss: 2.0896549506853987

Epoch: 6| Step: 7
Training loss: 1.3199092149734497
Validation loss: 2.0337553934384416

Epoch: 6| Step: 8
Training loss: 1.393700361251831
Validation loss: 2.06619938470984

Epoch: 6| Step: 9
Training loss: 1.9718754291534424
Validation loss: 2.0698293434676303

Epoch: 6| Step: 10
Training loss: 1.9056035280227661
Validation loss: 2.081757962062795

Epoch: 6| Step: 11
Training loss: 1.3466880321502686
Validation loss: 2.1191766338963665

Epoch: 6| Step: 12
Training loss: 1.7827051877975464
Validation loss: 2.0589358473336823

Epoch: 6| Step: 13
Training loss: 1.180983066558838
Validation loss: 2.070463929125058

Epoch: 368| Step: 0
Training loss: 1.8994964361190796
Validation loss: 2.070522649313814

Epoch: 6| Step: 1
Training loss: 1.5867310762405396
Validation loss: 2.0583019282228205

Epoch: 6| Step: 2
Training loss: 1.4247125387191772
Validation loss: 2.0733959879926456

Epoch: 6| Step: 3
Training loss: 1.3290818929672241
Validation loss: 2.0038743019104004

Epoch: 6| Step: 4
Training loss: 1.5145455598831177
Validation loss: 2.0405595289763583

Epoch: 6| Step: 5
Training loss: 1.58310866355896
Validation loss: 2.029879464898058

Epoch: 6| Step: 6
Training loss: 1.315843105316162
Validation loss: 2.046559609392638

Epoch: 6| Step: 7
Training loss: 1.9679112434387207
Validation loss: 2.0292030534436627

Epoch: 6| Step: 8
Training loss: 1.6112890243530273
Validation loss: 2.0581037357289302

Epoch: 6| Step: 9
Training loss: 2.5864076614379883
Validation loss: 2.009881034974129

Epoch: 6| Step: 10
Training loss: 0.9134974479675293
Validation loss: 2.0401350503326743

Epoch: 6| Step: 11
Training loss: 1.648308515548706
Validation loss: 2.03455840387652

Epoch: 6| Step: 12
Training loss: 1.1892627477645874
Validation loss: 2.095286069377776

Epoch: 6| Step: 13
Training loss: 2.3041906356811523
Validation loss: 2.083541270225279

Epoch: 369| Step: 0
Training loss: 2.67838716506958
Validation loss: 2.067911437762681

Epoch: 6| Step: 1
Training loss: 1.643303632736206
Validation loss: 2.1131777071183726

Epoch: 6| Step: 2
Training loss: 1.4718067646026611
Validation loss: 2.121608772585469

Epoch: 6| Step: 3
Training loss: 2.2905216217041016
Validation loss: 2.0975405734072448

Epoch: 6| Step: 4
Training loss: 1.4639396667480469
Validation loss: 2.174333823624478

Epoch: 6| Step: 5
Training loss: 1.5463100671768188
Validation loss: 2.1684806628893782

Epoch: 6| Step: 6
Training loss: 1.338003396987915
Validation loss: 2.1433622375611336

Epoch: 6| Step: 7
Training loss: 1.2847175598144531
Validation loss: 2.0877037843068442

Epoch: 6| Step: 8
Training loss: 1.2410340309143066
Validation loss: 2.0937529456230903

Epoch: 6| Step: 9
Training loss: 1.5541378259658813
Validation loss: 2.117579342216574

Epoch: 6| Step: 10
Training loss: 1.8766047954559326
Validation loss: 2.061158444291802

Epoch: 6| Step: 11
Training loss: 1.2529666423797607
Validation loss: 2.0674544636921217

Epoch: 6| Step: 12
Training loss: 1.4260063171386719
Validation loss: 2.070173296877133

Epoch: 6| Step: 13
Training loss: 1.8115105628967285
Validation loss: 2.0429698241654264

Epoch: 370| Step: 0
Training loss: 1.2428936958312988
Validation loss: 2.0912597922868628

Epoch: 6| Step: 1
Training loss: 1.9403390884399414
Validation loss: 2.054679598859561

Epoch: 6| Step: 2
Training loss: 1.9605300426483154
Validation loss: 2.0329250584366503

Epoch: 6| Step: 3
Training loss: 1.5240435600280762
Validation loss: 2.0261496933557654

Epoch: 6| Step: 4
Training loss: 1.1258807182312012
Validation loss: 2.03912414017544

Epoch: 6| Step: 5
Training loss: 1.2864985466003418
Validation loss: 2.0771814905187136

Epoch: 6| Step: 6
Training loss: 1.5025200843811035
Validation loss: 2.09414029377763

Epoch: 6| Step: 7
Training loss: 1.5654529333114624
Validation loss: 2.0738482449644353

Epoch: 6| Step: 8
Training loss: 1.7368463277816772
Validation loss: 2.1111542691466627

Epoch: 6| Step: 9
Training loss: 1.6804945468902588
Validation loss: 2.085401068451584

Epoch: 6| Step: 10
Training loss: 1.7060046195983887
Validation loss: 2.1196419013443815

Epoch: 6| Step: 11
Training loss: 1.871087670326233
Validation loss: 2.0994934907523533

Epoch: 6| Step: 12
Training loss: 1.7122485637664795
Validation loss: 2.0730712900879564

Epoch: 6| Step: 13
Training loss: 1.3377113342285156
Validation loss: 2.0614621011159753

Epoch: 371| Step: 0
Training loss: 1.6800909042358398
Validation loss: 2.093073401399838

Epoch: 6| Step: 1
Training loss: 1.674333095550537
Validation loss: 2.0765736359421925

Epoch: 6| Step: 2
Training loss: 2.040945529937744
Validation loss: 2.1001447708375993

Epoch: 6| Step: 3
Training loss: 1.290686845779419
Validation loss: 2.0711513027068107

Epoch: 6| Step: 4
Training loss: 1.153721809387207
Validation loss: 2.06635977632256

Epoch: 6| Step: 5
Training loss: 1.6197081804275513
Validation loss: 2.044959718181241

Epoch: 6| Step: 6
Training loss: 1.5799565315246582
Validation loss: 2.0762967627535582

Epoch: 6| Step: 7
Training loss: 1.7454994916915894
Validation loss: 2.040650201100175

Epoch: 6| Step: 8
Training loss: 1.4602985382080078
Validation loss: 2.045471763098112

Epoch: 6| Step: 9
Training loss: 1.188152551651001
Validation loss: 2.0719435881542903

Epoch: 6| Step: 10
Training loss: 2.542407989501953
Validation loss: 2.049182762381851

Epoch: 6| Step: 11
Training loss: 1.351381540298462
Validation loss: 2.0321429224424463

Epoch: 6| Step: 12
Training loss: 1.3660329580307007
Validation loss: 2.0376739091770624

Epoch: 6| Step: 13
Training loss: 1.311921238899231
Validation loss: 2.049019444373346

Epoch: 372| Step: 0
Training loss: 1.7427507638931274
Validation loss: 2.0783440425831783

Epoch: 6| Step: 1
Training loss: 1.5338218212127686
Validation loss: 2.0649516838853077

Epoch: 6| Step: 2
Training loss: 1.4043956995010376
Validation loss: 2.0484608783516833

Epoch: 6| Step: 3
Training loss: 1.4176712036132812
Validation loss: 2.0863668098244617

Epoch: 6| Step: 4
Training loss: 1.7838342189788818
Validation loss: 2.0471059878667197

Epoch: 6| Step: 5
Training loss: 1.429612636566162
Validation loss: 2.050213434362924

Epoch: 6| Step: 6
Training loss: 1.2115734815597534
Validation loss: 2.080874699418263

Epoch: 6| Step: 7
Training loss: 1.7154539823532104
Validation loss: 2.072568008976598

Epoch: 6| Step: 8
Training loss: 1.7080247402191162
Validation loss: 2.05056062693237

Epoch: 6| Step: 9
Training loss: 1.45254385471344
Validation loss: 2.0081733542103923

Epoch: 6| Step: 10
Training loss: 1.3458359241485596
Validation loss: 2.081215126540071

Epoch: 6| Step: 11
Training loss: 1.4847679138183594
Validation loss: 2.0876410443295716

Epoch: 6| Step: 12
Training loss: 2.4708821773529053
Validation loss: 2.1053611309297624

Epoch: 6| Step: 13
Training loss: 1.4252675771713257
Validation loss: 2.0404884815216064

Epoch: 373| Step: 0
Training loss: 1.363246202468872
Validation loss: 2.064553386421614

Epoch: 6| Step: 1
Training loss: 1.7825937271118164
Validation loss: 2.083645215598486

Epoch: 6| Step: 2
Training loss: 1.8966102600097656
Validation loss: 2.0538665299774497

Epoch: 6| Step: 3
Training loss: 1.2213079929351807
Validation loss: 2.044688682402334

Epoch: 6| Step: 4
Training loss: 1.8184750080108643
Validation loss: 2.08689978173984

Epoch: 6| Step: 5
Training loss: 1.189436435699463
Validation loss: 2.0893393178139963

Epoch: 6| Step: 6
Training loss: 1.188990831375122
Validation loss: 2.064216672733266

Epoch: 6| Step: 7
Training loss: 1.6229147911071777
Validation loss: 2.088660131218613

Epoch: 6| Step: 8
Training loss: 2.0397000312805176
Validation loss: 2.053158765198082

Epoch: 6| Step: 9
Training loss: 1.6977858543395996
Validation loss: 2.090705090953458

Epoch: 6| Step: 10
Training loss: 1.874765396118164
Validation loss: 2.0380315319184334

Epoch: 6| Step: 11
Training loss: 1.4695234298706055
Validation loss: 2.0652878925364506

Epoch: 6| Step: 12
Training loss: 1.0102219581604004
Validation loss: 2.049878889514554

Epoch: 6| Step: 13
Training loss: 2.160828113555908
Validation loss: 2.0225494471929406

Epoch: 374| Step: 0
Training loss: 2.3260507583618164
Validation loss: 2.0005191321014077

Epoch: 6| Step: 1
Training loss: 1.6878622770309448
Validation loss: 2.1009477492301696

Epoch: 6| Step: 2
Training loss: 1.0353035926818848
Validation loss: 2.039507278832056

Epoch: 6| Step: 3
Training loss: 1.5132203102111816
Validation loss: 2.0593435610494306

Epoch: 6| Step: 4
Training loss: 1.2339545488357544
Validation loss: 2.0801119009653726

Epoch: 6| Step: 5
Training loss: 1.1557223796844482
Validation loss: 2.0933888061072237

Epoch: 6| Step: 6
Training loss: 1.2087132930755615
Validation loss: 2.081800676161243

Epoch: 6| Step: 7
Training loss: 1.674776554107666
Validation loss: 2.097545764779532

Epoch: 6| Step: 8
Training loss: 2.369703769683838
Validation loss: 2.1025060492177166

Epoch: 6| Step: 9
Training loss: 1.8702572584152222
Validation loss: 2.1333150914920274

Epoch: 6| Step: 10
Training loss: 1.1092756986618042
Validation loss: 2.0799828626776256

Epoch: 6| Step: 11
Training loss: 1.2182321548461914
Validation loss: 2.1031602069895756

Epoch: 6| Step: 12
Training loss: 1.6634187698364258
Validation loss: 2.0716794998415056

Epoch: 6| Step: 13
Training loss: 2.0554049015045166
Validation loss: 2.06095193534769

Epoch: 375| Step: 0
Training loss: 1.4022846221923828
Validation loss: 2.0390338474704373

Epoch: 6| Step: 1
Training loss: 1.6258223056793213
Validation loss: 2.05438159870845

Epoch: 6| Step: 2
Training loss: 1.2384897470474243
Validation loss: 2.0122634762076923

Epoch: 6| Step: 3
Training loss: 1.003709077835083
Validation loss: 2.046266555786133

Epoch: 6| Step: 4
Training loss: 2.3331875801086426
Validation loss: 2.0254738587205128

Epoch: 6| Step: 5
Training loss: 1.0497808456420898
Validation loss: 2.042316629040626

Epoch: 6| Step: 6
Training loss: 1.3295427560806274
Validation loss: 2.102565052688763

Epoch: 6| Step: 7
Training loss: 1.6118488311767578
Validation loss: 2.03504922697621

Epoch: 6| Step: 8
Training loss: 1.4493905305862427
Validation loss: 2.035261341320571

Epoch: 6| Step: 9
Training loss: 1.8994947671890259
Validation loss: 2.092140190062984

Epoch: 6| Step: 10
Training loss: 1.8499760627746582
Validation loss: 2.0485945683653637

Epoch: 6| Step: 11
Training loss: 1.930321455001831
Validation loss: 2.0256755839111986

Epoch: 6| Step: 12
Training loss: 1.43540358543396
Validation loss: 2.0143217630283807

Epoch: 6| Step: 13
Training loss: 1.97475004196167
Validation loss: 2.0627779883723103

Epoch: 376| Step: 0
Training loss: 2.104433059692383
Validation loss: 2.041403665337511

Epoch: 6| Step: 1
Training loss: 2.1483230590820312
Validation loss: 2.0499464824635494

Epoch: 6| Step: 2
Training loss: 1.5488113164901733
Validation loss: 2.0813925086811023

Epoch: 6| Step: 3
Training loss: 2.1402876377105713
Validation loss: 2.0923607323759343

Epoch: 6| Step: 4
Training loss: 1.6050214767456055
Validation loss: 2.061247148821431

Epoch: 6| Step: 5
Training loss: 1.0817874670028687
Validation loss: 2.059819350960434

Epoch: 6| Step: 6
Training loss: 0.7968936562538147
Validation loss: 2.084379756322471

Epoch: 6| Step: 7
Training loss: 1.8058010339736938
Validation loss: 2.0927468679284535

Epoch: 6| Step: 8
Training loss: 1.9494709968566895
Validation loss: 2.1124938893061813

Epoch: 6| Step: 9
Training loss: 1.4171197414398193
Validation loss: 2.1070401309638895

Epoch: 6| Step: 10
Training loss: 1.1993170976638794
Validation loss: 2.076694050142842

Epoch: 6| Step: 11
Training loss: 1.5624103546142578
Validation loss: 2.109271426354685

Epoch: 6| Step: 12
Training loss: 1.0097960233688354
Validation loss: 2.0892552368102537

Epoch: 6| Step: 13
Training loss: 1.6379246711730957
Validation loss: 2.107067543973205

Epoch: 377| Step: 0
Training loss: 1.1653451919555664
Validation loss: 2.043924664938322

Epoch: 6| Step: 1
Training loss: 2.212130546569824
Validation loss: 2.041032305327795

Epoch: 6| Step: 2
Training loss: 1.57319974899292
Validation loss: 2.051497967012467

Epoch: 6| Step: 3
Training loss: 1.8554470539093018
Validation loss: 2.036030113056142

Epoch: 6| Step: 4
Training loss: 1.515160083770752
Validation loss: 2.065267175756475

Epoch: 6| Step: 5
Training loss: 1.2327648401260376
Validation loss: 2.0372402052725516

Epoch: 6| Step: 6
Training loss: 1.1688201427459717
Validation loss: 2.0562399048959055

Epoch: 6| Step: 7
Training loss: 2.072003126144409
Validation loss: 2.0540410626319145

Epoch: 6| Step: 8
Training loss: 1.602880597114563
Validation loss: 2.0381639670300227

Epoch: 6| Step: 9
Training loss: 1.1524734497070312
Validation loss: 2.0395122702403734

Epoch: 6| Step: 10
Training loss: 2.148564100265503
Validation loss: 2.0500370969054518

Epoch: 6| Step: 11
Training loss: 1.3412439823150635
Validation loss: 2.080500160494158

Epoch: 6| Step: 12
Training loss: 1.7505676746368408
Validation loss: 2.0150138626816454

Epoch: 6| Step: 13
Training loss: 0.9901078343391418
Validation loss: 2.0974345053395917

Epoch: 378| Step: 0
Training loss: 1.322249412536621
Validation loss: 2.0389398913229666

Epoch: 6| Step: 1
Training loss: 1.6551369428634644
Validation loss: 2.0531427808987197

Epoch: 6| Step: 2
Training loss: 2.212430000305176
Validation loss: 2.008604395774103

Epoch: 6| Step: 3
Training loss: 1.5519821643829346
Validation loss: 2.035812108747421

Epoch: 6| Step: 4
Training loss: 0.8753758668899536
Validation loss: 2.0999369570004043

Epoch: 6| Step: 5
Training loss: 1.7120906114578247
Validation loss: 2.0754218639866

Epoch: 6| Step: 6
Training loss: 1.6479142904281616
Validation loss: 2.0912050893229823

Epoch: 6| Step: 7
Training loss: 1.1216039657592773
Validation loss: 2.0895427144983763

Epoch: 6| Step: 8
Training loss: 2.16580867767334
Validation loss: 2.0802995030597975

Epoch: 6| Step: 9
Training loss: 2.1074676513671875
Validation loss: 2.0973793383567565

Epoch: 6| Step: 10
Training loss: 1.272971272468567
Validation loss: 2.073377419543523

Epoch: 6| Step: 11
Training loss: 1.5496680736541748
Validation loss: 2.1037075699016614

Epoch: 6| Step: 12
Training loss: 0.9784072637557983
Validation loss: 2.0473647438069826

Epoch: 6| Step: 13
Training loss: 1.8827584981918335
Validation loss: 2.100231488545736

Epoch: 379| Step: 0
Training loss: 1.7833654880523682
Validation loss: 2.0687277650320404

Epoch: 6| Step: 1
Training loss: 1.1833529472351074
Validation loss: 2.0507125316127652

Epoch: 6| Step: 2
Training loss: 1.3129663467407227
Validation loss: 2.094147051534345

Epoch: 6| Step: 3
Training loss: 1.7264113426208496
Validation loss: 2.0377391563948763

Epoch: 6| Step: 4
Training loss: 1.4522095918655396
Validation loss: 2.011495597900883

Epoch: 6| Step: 5
Training loss: 1.8083046674728394
Validation loss: 2.070940222791446

Epoch: 6| Step: 6
Training loss: 1.299088478088379
Validation loss: 2.0411275279137397

Epoch: 6| Step: 7
Training loss: 2.013446569442749
Validation loss: 2.0174764330669115

Epoch: 6| Step: 8
Training loss: 1.8507919311523438
Validation loss: 2.050725849725867

Epoch: 6| Step: 9
Training loss: 1.8633925914764404
Validation loss: 2.0501863661632744

Epoch: 6| Step: 10
Training loss: 1.3824526071548462
Validation loss: 2.0393093811568392

Epoch: 6| Step: 11
Training loss: 1.8387681245803833
Validation loss: 2.0383809176824426

Epoch: 6| Step: 12
Training loss: 1.2171850204467773
Validation loss: 2.0617684138718473

Epoch: 6| Step: 13
Training loss: 0.6710207462310791
Validation loss: 2.07073647745194

Epoch: 380| Step: 0
Training loss: 1.740281343460083
Validation loss: 2.0790300164171445

Epoch: 6| Step: 1
Training loss: 1.7273114919662476
Validation loss: 2.0524754947231663

Epoch: 6| Step: 2
Training loss: 1.7464420795440674
Validation loss: 2.0837032641133955

Epoch: 6| Step: 3
Training loss: 1.5158874988555908
Validation loss: 2.088611618165047

Epoch: 6| Step: 4
Training loss: 1.1356617212295532
Validation loss: 2.1250305239872267

Epoch: 6| Step: 5
Training loss: 1.983263373374939
Validation loss: 2.0795974423808437

Epoch: 6| Step: 6
Training loss: 1.5020625591278076
Validation loss: 2.1037183743651195

Epoch: 6| Step: 7
Training loss: 1.3478208780288696
Validation loss: 2.0938902901064966

Epoch: 6| Step: 8
Training loss: 2.0281777381896973
Validation loss: 2.1257527797452864

Epoch: 6| Step: 9
Training loss: 1.7938750982284546
Validation loss: 2.059796287167457

Epoch: 6| Step: 10
Training loss: 1.2251945734024048
Validation loss: 2.0385433448258268

Epoch: 6| Step: 11
Training loss: 1.1996079683303833
Validation loss: 2.0587918963483585

Epoch: 6| Step: 12
Training loss: 1.3293678760528564
Validation loss: 2.0275763785967262

Epoch: 6| Step: 13
Training loss: 1.8803719282150269
Validation loss: 2.039946726573411

Epoch: 381| Step: 0
Training loss: 1.552471399307251
Validation loss: 2.0538513404066845

Epoch: 6| Step: 1
Training loss: 1.0241174697875977
Validation loss: 2.116014107581108

Epoch: 6| Step: 2
Training loss: 1.6440479755401611
Validation loss: 2.0206603747542187

Epoch: 6| Step: 3
Training loss: 1.6158385276794434
Validation loss: 2.0340195689150082

Epoch: 6| Step: 4
Training loss: 1.9137067794799805
Validation loss: 2.061971987447431

Epoch: 6| Step: 5
Training loss: 1.5931904315948486
Validation loss: 2.0392952272968907

Epoch: 6| Step: 6
Training loss: 1.6859947443008423
Validation loss: 2.0464492433814594

Epoch: 6| Step: 7
Training loss: 1.3304128646850586
Validation loss: 2.050964988687987

Epoch: 6| Step: 8
Training loss: 1.4667673110961914
Validation loss: 2.109325228198882

Epoch: 6| Step: 9
Training loss: 2.460183620452881
Validation loss: 2.015912755843132

Epoch: 6| Step: 10
Training loss: 1.269181489944458
Validation loss: 2.0761298800027497

Epoch: 6| Step: 11
Training loss: 1.2336152791976929
Validation loss: 2.099684290988471

Epoch: 6| Step: 12
Training loss: 1.3892779350280762
Validation loss: 2.05208614436529

Epoch: 6| Step: 13
Training loss: 1.5282412767410278
Validation loss: 2.107372091662499

Epoch: 382| Step: 0
Training loss: 1.3938930034637451
Validation loss: 2.1056562021214473

Epoch: 6| Step: 1
Training loss: 0.8404873013496399
Validation loss: 2.0898248328957507

Epoch: 6| Step: 2
Training loss: 1.7916864156723022
Validation loss: 2.078403757464501

Epoch: 6| Step: 3
Training loss: 1.5494811534881592
Validation loss: 2.1062193301416214

Epoch: 6| Step: 4
Training loss: 1.5266273021697998
Validation loss: 2.097385004002561

Epoch: 6| Step: 5
Training loss: 1.0311763286590576
Validation loss: 2.1133905072366037

Epoch: 6| Step: 6
Training loss: 1.8897998332977295
Validation loss: 2.0627103005686114

Epoch: 6| Step: 7
Training loss: 2.148477554321289
Validation loss: 2.1091747001935075

Epoch: 6| Step: 8
Training loss: 1.7453738451004028
Validation loss: 2.0614082685080906

Epoch: 6| Step: 9
Training loss: 0.8397772312164307
Validation loss: 2.031023802295808

Epoch: 6| Step: 10
Training loss: 1.4277498722076416
Validation loss: 2.064868224564419

Epoch: 6| Step: 11
Training loss: 1.8158856630325317
Validation loss: 2.0716769156917447

Epoch: 6| Step: 12
Training loss: 1.8356132507324219
Validation loss: 2.04885071580128

Epoch: 6| Step: 13
Training loss: 1.94459068775177
Validation loss: 2.08533618527074

Epoch: 383| Step: 0
Training loss: 1.627569556236267
Validation loss: 2.034091931517406

Epoch: 6| Step: 1
Training loss: 1.2783807516098022
Validation loss: 2.0776353049021896

Epoch: 6| Step: 2
Training loss: 1.5597000122070312
Validation loss: 2.054038364400146

Epoch: 6| Step: 3
Training loss: 1.2942454814910889
Validation loss: 2.051620409052859

Epoch: 6| Step: 4
Training loss: 1.4604393243789673
Validation loss: 2.059848359836045

Epoch: 6| Step: 5
Training loss: 1.7731608152389526
Validation loss: 2.0457642796219035

Epoch: 6| Step: 6
Training loss: 1.90842866897583
Validation loss: 2.044941424041666

Epoch: 6| Step: 7
Training loss: 1.5537571907043457
Validation loss: 2.0470276148088518

Epoch: 6| Step: 8
Training loss: 1.1694209575653076
Validation loss: 2.05716965019062

Epoch: 6| Step: 9
Training loss: 1.8678162097930908
Validation loss: 2.0395129149959934

Epoch: 6| Step: 10
Training loss: 1.3717262744903564
Validation loss: 2.0622395033477456

Epoch: 6| Step: 11
Training loss: 1.4797635078430176
Validation loss: 2.072298034544914

Epoch: 6| Step: 12
Training loss: 1.7771342992782593
Validation loss: 2.106663421917987

Epoch: 6| Step: 13
Training loss: 1.633115530014038
Validation loss: 2.063711509909681

Epoch: 384| Step: 0
Training loss: 2.0132808685302734
Validation loss: 2.0892166014640563

Epoch: 6| Step: 1
Training loss: 1.4877616167068481
Validation loss: 2.066499942092485

Epoch: 6| Step: 2
Training loss: 1.341651439666748
Validation loss: 2.0941802481169343

Epoch: 6| Step: 3
Training loss: 1.6368458271026611
Validation loss: 2.0945704342216573

Epoch: 6| Step: 4
Training loss: 1.313905119895935
Validation loss: 2.0892642505707277

Epoch: 6| Step: 5
Training loss: 1.461613416671753
Validation loss: 2.103783333173362

Epoch: 6| Step: 6
Training loss: 1.895127296447754
Validation loss: 2.061995408868277

Epoch: 6| Step: 7
Training loss: 0.957778811454773
Validation loss: 2.088481959476266

Epoch: 6| Step: 8
Training loss: 1.5196281671524048
Validation loss: 2.0367088343507502

Epoch: 6| Step: 9
Training loss: 1.0549463033676147
Validation loss: 2.048644273511825

Epoch: 6| Step: 10
Training loss: 1.9039126634597778
Validation loss: 2.093964986903693

Epoch: 6| Step: 11
Training loss: 1.8135875463485718
Validation loss: 2.0350348923795964

Epoch: 6| Step: 12
Training loss: 1.5541012287139893
Validation loss: 2.03432830174764

Epoch: 6| Step: 13
Training loss: 1.759995937347412
Validation loss: 2.0252224104378813

Epoch: 385| Step: 0
Training loss: 1.7927005290985107
Validation loss: 2.008588683220648

Epoch: 6| Step: 1
Training loss: 1.9087492227554321
Validation loss: 1.9988518402140627

Epoch: 6| Step: 2
Training loss: 1.6760382652282715
Validation loss: 2.0032839082902476

Epoch: 6| Step: 3
Training loss: 1.3860313892364502
Validation loss: 2.040878306153

Epoch: 6| Step: 4
Training loss: 1.969606637954712
Validation loss: 2.033232004411759

Epoch: 6| Step: 5
Training loss: 1.584608793258667
Validation loss: 2.0726815487748835

Epoch: 6| Step: 6
Training loss: 1.299299955368042
Validation loss: 2.024844588771943

Epoch: 6| Step: 7
Training loss: 0.9913020133972168
Validation loss: 2.0295222549028296

Epoch: 6| Step: 8
Training loss: 1.601224422454834
Validation loss: 2.0684330463409424

Epoch: 6| Step: 9
Training loss: 1.4950618743896484
Validation loss: 2.0848870918314946

Epoch: 6| Step: 10
Training loss: 1.5877866744995117
Validation loss: 2.043787679364604

Epoch: 6| Step: 11
Training loss: 1.4182026386260986
Validation loss: 2.041044786412229

Epoch: 6| Step: 12
Training loss: 1.3480881452560425
Validation loss: 2.0117177822256602

Epoch: 6| Step: 13
Training loss: 1.7596580982208252
Validation loss: 2.0536586366673952

Epoch: 386| Step: 0
Training loss: 1.3979008197784424
Validation loss: 2.0492266711368354

Epoch: 6| Step: 1
Training loss: 1.2510623931884766
Validation loss: 2.054248240686232

Epoch: 6| Step: 2
Training loss: 0.8448207378387451
Validation loss: 2.0199183558905

Epoch: 6| Step: 3
Training loss: 1.9337949752807617
Validation loss: 2.0336287021636963

Epoch: 6| Step: 4
Training loss: 1.5639939308166504
Validation loss: 2.0923575457706245

Epoch: 6| Step: 5
Training loss: 1.7799547910690308
Validation loss: 2.0462588212823354

Epoch: 6| Step: 6
Training loss: 1.503588318824768
Validation loss: 2.038849256371939

Epoch: 6| Step: 7
Training loss: 1.814782977104187
Validation loss: 2.0580779865223873

Epoch: 6| Step: 8
Training loss: 1.8294546604156494
Validation loss: 2.0587284731608566

Epoch: 6| Step: 9
Training loss: 1.2034320831298828
Validation loss: 2.0398421466991468

Epoch: 6| Step: 10
Training loss: 1.753138780593872
Validation loss: 2.069956410315729

Epoch: 6| Step: 11
Training loss: 1.3904707431793213
Validation loss: 2.0610850677695325

Epoch: 6| Step: 12
Training loss: 1.3647491931915283
Validation loss: 2.0575017441985426

Epoch: 6| Step: 13
Training loss: 2.252474784851074
Validation loss: 2.0671454809045278

Epoch: 387| Step: 0
Training loss: 1.3194067478179932
Validation loss: 2.0868884773664576

Epoch: 6| Step: 1
Training loss: 1.5124375820159912
Validation loss: 2.065434294362222

Epoch: 6| Step: 2
Training loss: 1.3004270792007446
Validation loss: 2.071105992922219

Epoch: 6| Step: 3
Training loss: 1.5294928550720215
Validation loss: 2.122487339922177

Epoch: 6| Step: 4
Training loss: 1.8726766109466553
Validation loss: 2.128100848967029

Epoch: 6| Step: 5
Training loss: 1.7987092733383179
Validation loss: 2.139339840540322

Epoch: 6| Step: 6
Training loss: 0.8105226755142212
Validation loss: 2.0992917168524956

Epoch: 6| Step: 7
Training loss: 1.4394742250442505
Validation loss: 2.0941354061967585

Epoch: 6| Step: 8
Training loss: 2.0824713706970215
Validation loss: 2.099776150077902

Epoch: 6| Step: 9
Training loss: 1.2042391300201416
Validation loss: 2.1069149586462204

Epoch: 6| Step: 10
Training loss: 2.0110023021698
Validation loss: 2.113330300136279

Epoch: 6| Step: 11
Training loss: 1.8283287286758423
Validation loss: 2.0599146209737307

Epoch: 6| Step: 12
Training loss: 1.0593246221542358
Validation loss: 2.0874573325598114

Epoch: 6| Step: 13
Training loss: 1.7128262519836426
Validation loss: 2.045794645945231

Epoch: 388| Step: 0
Training loss: 1.5096714496612549
Validation loss: 2.012200654193919

Epoch: 6| Step: 1
Training loss: 2.2231645584106445
Validation loss: 2.0512062913628033

Epoch: 6| Step: 2
Training loss: 1.430133581161499
Validation loss: 2.0549823468731296

Epoch: 6| Step: 3
Training loss: 1.5308754444122314
Validation loss: 2.048699137985065

Epoch: 6| Step: 4
Training loss: 1.217759132385254
Validation loss: 2.0445501676169773

Epoch: 6| Step: 5
Training loss: 2.1470727920532227
Validation loss: 2.0876479943593345

Epoch: 6| Step: 6
Training loss: 1.2027018070220947
Validation loss: 2.036590578735516

Epoch: 6| Step: 7
Training loss: 1.8364733457565308
Validation loss: 2.0843875074899323

Epoch: 6| Step: 8
Training loss: 1.2779288291931152
Validation loss: 2.039707326119946

Epoch: 6| Step: 9
Training loss: 1.0803018808364868
Validation loss: 2.037045507020848

Epoch: 6| Step: 10
Training loss: 1.5829213857650757
Validation loss: 2.06723984595268

Epoch: 6| Step: 11
Training loss: 1.3638551235198975
Validation loss: 2.0987588180008756

Epoch: 6| Step: 12
Training loss: 1.9675366878509521
Validation loss: 2.025444551180768

Epoch: 6| Step: 13
Training loss: 1.1472692489624023
Validation loss: 2.08056313760819

Epoch: 389| Step: 0
Training loss: 1.832029104232788
Validation loss: 2.056809425354004

Epoch: 6| Step: 1
Training loss: 1.6966993808746338
Validation loss: 2.0846545132257606

Epoch: 6| Step: 2
Training loss: 1.4451510906219482
Validation loss: 2.0914559159227597

Epoch: 6| Step: 3
Training loss: 1.182725429534912
Validation loss: 2.0682804353775515

Epoch: 6| Step: 4
Training loss: 1.5604724884033203
Validation loss: 2.1228684353572067

Epoch: 6| Step: 5
Training loss: 1.9415459632873535
Validation loss: 2.081274696575698

Epoch: 6| Step: 6
Training loss: 1.5245060920715332
Validation loss: 2.0697063656263452

Epoch: 6| Step: 7
Training loss: 0.7200839519500732
Validation loss: 2.110239403222197

Epoch: 6| Step: 8
Training loss: 1.7815890312194824
Validation loss: 2.1091538603587816

Epoch: 6| Step: 9
Training loss: 2.1704320907592773
Validation loss: 2.081802693746423

Epoch: 6| Step: 10
Training loss: 1.4533040523529053
Validation loss: 2.0458266222348778

Epoch: 6| Step: 11
Training loss: 1.108525037765503
Validation loss: 1.9923869653414654

Epoch: 6| Step: 12
Training loss: 1.3252294063568115
Validation loss: 2.039587684856948

Epoch: 6| Step: 13
Training loss: 1.8820520639419556
Validation loss: 2.0714779899966334

Epoch: 390| Step: 0
Training loss: 1.208353877067566
Validation loss: 2.0639759596957954

Epoch: 6| Step: 1
Training loss: 2.0171916484832764
Validation loss: 2.0336466630299888

Epoch: 6| Step: 2
Training loss: 1.1416587829589844
Validation loss: 2.0484008045606714

Epoch: 6| Step: 3
Training loss: 1.7332216501235962
Validation loss: 2.017345689958142

Epoch: 6| Step: 4
Training loss: 2.069152355194092
Validation loss: 2.025822829174739

Epoch: 6| Step: 5
Training loss: 1.2584424018859863
Validation loss: 2.0031643490637503

Epoch: 6| Step: 6
Training loss: 1.5155479907989502
Validation loss: 2.072466000433891

Epoch: 6| Step: 7
Training loss: 1.725750207901001
Validation loss: 2.0575699396030878

Epoch: 6| Step: 8
Training loss: 1.6535563468933105
Validation loss: 2.0713112123550905

Epoch: 6| Step: 9
Training loss: 1.4212197065353394
Validation loss: 2.056707041237944

Epoch: 6| Step: 10
Training loss: 1.2279129028320312
Validation loss: 2.064449309020914

Epoch: 6| Step: 11
Training loss: 2.3309221267700195
Validation loss: 2.033433154065122

Epoch: 6| Step: 12
Training loss: 1.504685640335083
Validation loss: 2.062254149426696

Epoch: 6| Step: 13
Training loss: 1.2619423866271973
Validation loss: 2.0531953560408724

Epoch: 391| Step: 0
Training loss: 1.2221333980560303
Validation loss: 2.08701390604819

Epoch: 6| Step: 1
Training loss: 1.4064958095550537
Validation loss: 2.0606825031260008

Epoch: 6| Step: 2
Training loss: 1.2346521615982056
Validation loss: 2.0873812475512104

Epoch: 6| Step: 3
Training loss: 1.7433156967163086
Validation loss: 2.0473806704244306

Epoch: 6| Step: 4
Training loss: 1.5498682260513306
Validation loss: 2.0369555142617997

Epoch: 6| Step: 5
Training loss: 1.831045150756836
Validation loss: 2.0688050344426143

Epoch: 6| Step: 6
Training loss: 1.5355058908462524
Validation loss: 2.0638233179687173

Epoch: 6| Step: 7
Training loss: 1.0608606338500977
Validation loss: 2.066890298679311

Epoch: 6| Step: 8
Training loss: 1.803285002708435
Validation loss: 2.0554903450832573

Epoch: 6| Step: 9
Training loss: 1.249185562133789
Validation loss: 2.079924785962669

Epoch: 6| Step: 10
Training loss: 1.7059016227722168
Validation loss: 2.041896599595265

Epoch: 6| Step: 11
Training loss: 1.7327955961227417
Validation loss: 2.103694967044297

Epoch: 6| Step: 12
Training loss: 1.554783821105957
Validation loss: 2.0263161659240723

Epoch: 6| Step: 13
Training loss: 1.7452622652053833
Validation loss: 2.0627726021633355

Epoch: 392| Step: 0
Training loss: 1.774789810180664
Validation loss: 2.076562655869351

Epoch: 6| Step: 1
Training loss: 1.1192083358764648
Validation loss: 2.0742291019808863

Epoch: 6| Step: 2
Training loss: 1.447198748588562
Validation loss: 2.011078352569252

Epoch: 6| Step: 3
Training loss: 1.6024525165557861
Validation loss: 2.0448198997846214

Epoch: 6| Step: 4
Training loss: 1.230705976486206
Validation loss: 2.04106395218962

Epoch: 6| Step: 5
Training loss: 1.4906139373779297
Validation loss: 2.035482237415929

Epoch: 6| Step: 6
Training loss: 1.719042181968689
Validation loss: 2.0627616272177747

Epoch: 6| Step: 7
Training loss: 1.6756479740142822
Validation loss: 2.0386188722425893

Epoch: 6| Step: 8
Training loss: 1.8128641843795776
Validation loss: 2.0316319645092054

Epoch: 6| Step: 9
Training loss: 2.1433920860290527
Validation loss: 2.0646370431428314

Epoch: 6| Step: 10
Training loss: 1.7026984691619873
Validation loss: 2.0541614332506732

Epoch: 6| Step: 11
Training loss: 1.010801076889038
Validation loss: 2.0818620676635415

Epoch: 6| Step: 12
Training loss: 1.3025504350662231
Validation loss: 2.0368114543217484

Epoch: 6| Step: 13
Training loss: 1.4070171117782593
Validation loss: 2.0470852236593924

Epoch: 393| Step: 0
Training loss: 2.262673854827881
Validation loss: 2.0602824303411666

Epoch: 6| Step: 1
Training loss: 1.7656688690185547
Validation loss: 2.042569868026241

Epoch: 6| Step: 2
Training loss: 1.5910823345184326
Validation loss: 2.0576321078884985

Epoch: 6| Step: 3
Training loss: 1.3091026544570923
Validation loss: 2.0422432294455906

Epoch: 6| Step: 4
Training loss: 2.1969733238220215
Validation loss: 2.092233060508646

Epoch: 6| Step: 5
Training loss: 1.3293001651763916
Validation loss: 2.0628911961791334

Epoch: 6| Step: 6
Training loss: 1.8895550966262817
Validation loss: 2.0540569956584642

Epoch: 6| Step: 7
Training loss: 1.2663663625717163
Validation loss: 2.0669790185907835

Epoch: 6| Step: 8
Training loss: 1.9216617345809937
Validation loss: 2.1064161228877243

Epoch: 6| Step: 9
Training loss: 0.8448220491409302
Validation loss: 2.0617125957242903

Epoch: 6| Step: 10
Training loss: 0.9240193367004395
Validation loss: 2.0597910534950996

Epoch: 6| Step: 11
Training loss: 0.8976923227310181
Validation loss: 2.070826684274981

Epoch: 6| Step: 12
Training loss: 1.7172892093658447
Validation loss: 2.068177189878238

Epoch: 6| Step: 13
Training loss: 1.5911576747894287
Validation loss: 2.0501834166947233

Epoch: 394| Step: 0
Training loss: 1.5073883533477783
Validation loss: 2.071207833546464

Epoch: 6| Step: 1
Training loss: 1.638361930847168
Validation loss: 2.0539571726193993

Epoch: 6| Step: 2
Training loss: 2.2370777130126953
Validation loss: 2.0246609321204563

Epoch: 6| Step: 3
Training loss: 1.9032726287841797
Validation loss: 2.0546449909928026

Epoch: 6| Step: 4
Training loss: 1.8620694875717163
Validation loss: 2.0542576325837003

Epoch: 6| Step: 5
Training loss: 1.4555362462997437
Validation loss: 2.0343910212157876

Epoch: 6| Step: 6
Training loss: 1.267106056213379
Validation loss: 2.065045979715163

Epoch: 6| Step: 7
Training loss: 1.555368423461914
Validation loss: 2.0228828089211577

Epoch: 6| Step: 8
Training loss: 0.969569206237793
Validation loss: 2.0439758044417187

Epoch: 6| Step: 9
Training loss: 1.1527855396270752
Validation loss: 2.067990226130332

Epoch: 6| Step: 10
Training loss: 1.4802250862121582
Validation loss: 2.0774259387805896

Epoch: 6| Step: 11
Training loss: 1.2060844898223877
Validation loss: 2.0434408239139024

Epoch: 6| Step: 12
Training loss: 1.2063100337982178
Validation loss: 2.056825210971217

Epoch: 6| Step: 13
Training loss: 2.0913634300231934
Validation loss: 2.106516340727447

Epoch: 395| Step: 0
Training loss: 1.1608607769012451
Validation loss: 2.1235951172408236

Epoch: 6| Step: 1
Training loss: 2.4033126831054688
Validation loss: 2.106390565954229

Epoch: 6| Step: 2
Training loss: 1.869303822517395
Validation loss: 2.1198258271781345

Epoch: 6| Step: 3
Training loss: 1.5913872718811035
Validation loss: 2.147602399190267

Epoch: 6| Step: 4
Training loss: 1.362852692604065
Validation loss: 2.1079503336260395

Epoch: 6| Step: 5
Training loss: 1.8804354667663574
Validation loss: 2.1044543738006265

Epoch: 6| Step: 6
Training loss: 1.2201356887817383
Validation loss: 2.1162485704627088

Epoch: 6| Step: 7
Training loss: 1.9305534362792969
Validation loss: 2.109902283196808

Epoch: 6| Step: 8
Training loss: 1.4370996952056885
Validation loss: 2.0655547598356843

Epoch: 6| Step: 9
Training loss: 1.0157041549682617
Validation loss: 2.067394359137422

Epoch: 6| Step: 10
Training loss: 1.6049189567565918
Validation loss: 2.0626217908756708

Epoch: 6| Step: 11
Training loss: 1.6262317895889282
Validation loss: 2.0881182685975106

Epoch: 6| Step: 12
Training loss: 1.0817759037017822
Validation loss: 2.090965017195671

Epoch: 6| Step: 13
Training loss: 1.5128871202468872
Validation loss: 1.9977304243272351

Epoch: 396| Step: 0
Training loss: 1.6436452865600586
Validation loss: 2.0548168254154984

Epoch: 6| Step: 1
Training loss: 1.603440523147583
Validation loss: 2.0160720527813

Epoch: 6| Step: 2
Training loss: 1.511329174041748
Validation loss: 2.0639228923346407

Epoch: 6| Step: 3
Training loss: 1.5537787675857544
Validation loss: 2.069327341612949

Epoch: 6| Step: 4
Training loss: 1.53171706199646
Validation loss: 2.0310941306493615

Epoch: 6| Step: 5
Training loss: 2.276296615600586
Validation loss: 2.0354047488140803

Epoch: 6| Step: 6
Training loss: 1.3855925798416138
Validation loss: 2.067059246442651

Epoch: 6| Step: 7
Training loss: 1.0774129629135132
Validation loss: 2.0361982430181196

Epoch: 6| Step: 8
Training loss: 1.8657251596450806
Validation loss: 2.029024085690898

Epoch: 6| Step: 9
Training loss: 1.1222738027572632
Validation loss: 2.0199970071033766

Epoch: 6| Step: 10
Training loss: 1.8179395198822021
Validation loss: 2.065260023199102

Epoch: 6| Step: 11
Training loss: 1.2338173389434814
Validation loss: 2.0768842748416367

Epoch: 6| Step: 12
Training loss: 1.4195170402526855
Validation loss: 2.03108109325491

Epoch: 6| Step: 13
Training loss: 1.6266616582870483
Validation loss: 2.0611167312950216

Epoch: 397| Step: 0
Training loss: 1.650604009628296
Validation loss: 2.0882559412269184

Epoch: 6| Step: 1
Training loss: 1.43277907371521
Validation loss: 2.031233464517901

Epoch: 6| Step: 2
Training loss: 1.0190463066101074
Validation loss: 2.087479788769958

Epoch: 6| Step: 3
Training loss: 1.4448282718658447
Validation loss: 2.0805141951448176

Epoch: 6| Step: 4
Training loss: 2.0656161308288574
Validation loss: 2.0919103853164183

Epoch: 6| Step: 5
Training loss: 1.703855276107788
Validation loss: 2.1169148773275395

Epoch: 6| Step: 6
Training loss: 1.4880621433258057
Validation loss: 2.086749985653867

Epoch: 6| Step: 7
Training loss: 1.454094648361206
Validation loss: 2.0792769719195623

Epoch: 6| Step: 8
Training loss: 1.3278101682662964
Validation loss: 2.1270142883382817

Epoch: 6| Step: 9
Training loss: 1.4165771007537842
Validation loss: 2.1014695577724005

Epoch: 6| Step: 10
Training loss: 1.7983309030532837
Validation loss: 2.0884095904647664

Epoch: 6| Step: 11
Training loss: 1.5283839702606201
Validation loss: 2.0987347069606987

Epoch: 6| Step: 12
Training loss: 1.6290696859359741
Validation loss: 2.07001474724021

Epoch: 6| Step: 13
Training loss: 1.6846991777420044
Validation loss: 2.0810384929821057

Epoch: 398| Step: 0
Training loss: 1.9989993572235107
Validation loss: 2.02390859716682

Epoch: 6| Step: 1
Training loss: 1.4185841083526611
Validation loss: 2.054448909656976

Epoch: 6| Step: 2
Training loss: 0.8752964735031128
Validation loss: 2.037934923684725

Epoch: 6| Step: 3
Training loss: 2.605940103530884
Validation loss: 2.0492965816169657

Epoch: 6| Step: 4
Training loss: 1.9818453788757324
Validation loss: 2.083560143747637

Epoch: 6| Step: 5
Training loss: 1.8629170656204224
Validation loss: 2.0275112403336393

Epoch: 6| Step: 6
Training loss: 1.4636714458465576
Validation loss: 2.0250524846456384

Epoch: 6| Step: 7
Training loss: 1.4226007461547852
Validation loss: 2.0278516866827525

Epoch: 6| Step: 8
Training loss: 1.231813669204712
Validation loss: 1.9912638023335447

Epoch: 6| Step: 9
Training loss: 1.426782250404358
Validation loss: 2.0368316968282065

Epoch: 6| Step: 10
Training loss: 1.3033264875411987
Validation loss: 2.0428550961197063

Epoch: 6| Step: 11
Training loss: 1.4419728517532349
Validation loss: 2.068565144333788

Epoch: 6| Step: 12
Training loss: 1.5110443830490112
Validation loss: 2.050901041235975

Epoch: 6| Step: 13
Training loss: 1.480481505393982
Validation loss: 2.07644292231529

Epoch: 399| Step: 0
Training loss: 1.2787338495254517
Validation loss: 2.1153136504593717

Epoch: 6| Step: 1
Training loss: 0.7381463050842285
Validation loss: 2.1043833583913822

Epoch: 6| Step: 2
Training loss: 1.447158694267273
Validation loss: 2.1221693459377495

Epoch: 6| Step: 3
Training loss: 1.7133103609085083
Validation loss: 2.135342082669658

Epoch: 6| Step: 4
Training loss: 1.461103081703186
Validation loss: 2.1343888185357534

Epoch: 6| Step: 5
Training loss: 1.5165650844573975
Validation loss: 2.1422510788004887

Epoch: 6| Step: 6
Training loss: 1.8549370765686035
Validation loss: 2.1533031694350706

Epoch: 6| Step: 7
Training loss: 1.6988415718078613
Validation loss: 2.1496472448431034

Epoch: 6| Step: 8
Training loss: 1.6196458339691162
Validation loss: 2.124375899632772

Epoch: 6| Step: 9
Training loss: 1.989466667175293
Validation loss: 2.082258214232742

Epoch: 6| Step: 10
Training loss: 2.116877317428589
Validation loss: 2.137629014189525

Epoch: 6| Step: 11
Training loss: 1.357322096824646
Validation loss: 2.083351404436173

Epoch: 6| Step: 12
Training loss: 1.5996992588043213
Validation loss: 2.045888320092232

Epoch: 6| Step: 13
Training loss: 1.0319615602493286
Validation loss: 2.1028310252774145

Epoch: 400| Step: 0
Training loss: 1.9622524976730347
Validation loss: 2.0475054017959105

Epoch: 6| Step: 1
Training loss: 1.9899345636367798
Validation loss: 2.045899288628691

Epoch: 6| Step: 2
Training loss: 1.9633790254592896
Validation loss: 2.0354535887318272

Epoch: 6| Step: 3
Training loss: 1.3148648738861084
Validation loss: 2.036932614541823

Epoch: 6| Step: 4
Training loss: 1.5810432434082031
Validation loss: 2.025507039921258

Epoch: 6| Step: 5
Training loss: 1.3458635807037354
Validation loss: 2.046254701511834

Epoch: 6| Step: 6
Training loss: 1.7845897674560547
Validation loss: 2.006319663857901

Epoch: 6| Step: 7
Training loss: 1.7340576648712158
Validation loss: 2.045751617800805

Epoch: 6| Step: 8
Training loss: 1.409752607345581
Validation loss: 2.031092564264933

Epoch: 6| Step: 9
Training loss: 1.1572625637054443
Validation loss: 2.0558236183658725

Epoch: 6| Step: 10
Training loss: 1.6221423149108887
Validation loss: 2.0182360436326716

Epoch: 6| Step: 11
Training loss: 1.2795779705047607
Validation loss: 2.021278783839236

Epoch: 6| Step: 12
Training loss: 1.3369663953781128
Validation loss: 2.0431256755705802

Epoch: 6| Step: 13
Training loss: 1.181694507598877
Validation loss: 2.0805199889726538

Epoch: 401| Step: 0
Training loss: 1.208770751953125
Validation loss: 2.067227630205052

Epoch: 6| Step: 1
Training loss: 1.2892177104949951
Validation loss: 2.0971745265427457

Epoch: 6| Step: 2
Training loss: 1.719983458518982
Validation loss: 2.0914726295778827

Epoch: 6| Step: 3
Training loss: 1.6464698314666748
Validation loss: 2.1197471349470076

Epoch: 6| Step: 4
Training loss: 1.2957470417022705
Validation loss: 2.081178785652243

Epoch: 6| Step: 5
Training loss: 0.9985851645469666
Validation loss: 2.0835029745614655

Epoch: 6| Step: 6
Training loss: 1.3696285486221313
Validation loss: 2.0864554246266684

Epoch: 6| Step: 7
Training loss: 1.260563611984253
Validation loss: 2.077379477921353

Epoch: 6| Step: 8
Training loss: 1.8296071290969849
Validation loss: 2.0872281430869974

Epoch: 6| Step: 9
Training loss: 1.472781777381897
Validation loss: 2.0643196926322034

Epoch: 6| Step: 10
Training loss: 1.5769058465957642
Validation loss: 2.0405950725719495

Epoch: 6| Step: 11
Training loss: 2.535806894302368
Validation loss: 2.059843986265121

Epoch: 6| Step: 12
Training loss: 1.8757286071777344
Validation loss: 2.068829157019174

Epoch: 6| Step: 13
Training loss: 1.1649196147918701
Validation loss: 2.026629663282825

Epoch: 402| Step: 0
Training loss: 1.945581316947937
Validation loss: 2.0553465325345277

Epoch: 6| Step: 1
Training loss: 1.8132259845733643
Validation loss: 2.048569856151458

Epoch: 6| Step: 2
Training loss: 1.2043750286102295
Validation loss: 2.0659583845446186

Epoch: 6| Step: 3
Training loss: 1.2789573669433594
Validation loss: 2.062512710530271

Epoch: 6| Step: 4
Training loss: 1.4117826223373413
Validation loss: 2.084595589227574

Epoch: 6| Step: 5
Training loss: 1.7541481256484985
Validation loss: 2.068634207530688

Epoch: 6| Step: 6
Training loss: 1.8632478713989258
Validation loss: 2.0114115271517026

Epoch: 6| Step: 7
Training loss: 1.259588599205017
Validation loss: 2.0338260127652075

Epoch: 6| Step: 8
Training loss: 1.3616844415664673
Validation loss: 2.072612647087343

Epoch: 6| Step: 9
Training loss: 1.417198896408081
Validation loss: 2.0663076933994087

Epoch: 6| Step: 10
Training loss: 1.9663589000701904
Validation loss: 2.066521524101175

Epoch: 6| Step: 11
Training loss: 1.1759240627288818
Validation loss: 2.080083902164172

Epoch: 6| Step: 12
Training loss: 0.8780721426010132
Validation loss: 2.094778217295165

Epoch: 6| Step: 13
Training loss: 2.177844762802124
Validation loss: 2.0866482373206847

Epoch: 403| Step: 0
Training loss: 1.2835667133331299
Validation loss: 2.1168030897776284

Epoch: 6| Step: 1
Training loss: 2.4378061294555664
Validation loss: 2.1035256001257125

Epoch: 6| Step: 2
Training loss: 1.6619467735290527
Validation loss: 2.110241772026144

Epoch: 6| Step: 3
Training loss: 1.1302001476287842
Validation loss: 2.1373451909711285

Epoch: 6| Step: 4
Training loss: 1.2785725593566895
Validation loss: 2.1816090768383396

Epoch: 6| Step: 5
Training loss: 1.3432393074035645
Validation loss: 2.092463325428706

Epoch: 6| Step: 6
Training loss: 1.3613336086273193
Validation loss: 2.118377608637656

Epoch: 6| Step: 7
Training loss: 1.4242627620697021
Validation loss: 2.0680637615983204

Epoch: 6| Step: 8
Training loss: 1.423123836517334
Validation loss: 2.0877324688819145

Epoch: 6| Step: 9
Training loss: 1.7687749862670898
Validation loss: 2.080766054891771

Epoch: 6| Step: 10
Training loss: 1.8932337760925293
Validation loss: 2.047615785752573

Epoch: 6| Step: 11
Training loss: 1.8322224617004395
Validation loss: 2.042821334254357

Epoch: 6| Step: 12
Training loss: 1.3564887046813965
Validation loss: 2.0536059384704917

Epoch: 6| Step: 13
Training loss: 0.9775977730751038
Validation loss: 2.01346404065368

Epoch: 404| Step: 0
Training loss: 1.3704309463500977
Validation loss: 2.0381623762910084

Epoch: 6| Step: 1
Training loss: 1.0241832733154297
Validation loss: 2.01863988625106

Epoch: 6| Step: 2
Training loss: 1.6599576473236084
Validation loss: 2.0147067513517154

Epoch: 6| Step: 3
Training loss: 1.6434338092803955
Validation loss: 2.043286608111474

Epoch: 6| Step: 4
Training loss: 1.505832552909851
Validation loss: 1.9952190588879328

Epoch: 6| Step: 5
Training loss: 1.5426695346832275
Validation loss: 2.020216667523948

Epoch: 6| Step: 6
Training loss: 1.588507890701294
Validation loss: 2.0700805828135502

Epoch: 6| Step: 7
Training loss: 1.8922842741012573
Validation loss: 2.0473701261704966

Epoch: 6| Step: 8
Training loss: 1.6916742324829102
Validation loss: 2.0757147817201513

Epoch: 6| Step: 9
Training loss: 1.4840928316116333
Validation loss: 2.0457597676143853

Epoch: 6| Step: 10
Training loss: 2.025843858718872
Validation loss: 2.077708915997577

Epoch: 6| Step: 11
Training loss: 1.6069209575653076
Validation loss: 2.1082822840700866

Epoch: 6| Step: 12
Training loss: 1.3103431463241577
Validation loss: 2.1217551333929903

Epoch: 6| Step: 13
Training loss: 0.8172564506530762
Validation loss: 2.121186940900741

Epoch: 405| Step: 0
Training loss: 1.5302029848098755
Validation loss: 2.1190752060182634

Epoch: 6| Step: 1
Training loss: 1.351649522781372
Validation loss: 2.1278243551972094

Epoch: 6| Step: 2
Training loss: 1.3354160785675049
Validation loss: 2.1269741442895707

Epoch: 6| Step: 3
Training loss: 1.6224656105041504
Validation loss: 2.1164589735769455

Epoch: 6| Step: 4
Training loss: 2.074613094329834
Validation loss: 2.0701514956771687

Epoch: 6| Step: 5
Training loss: 0.9951391220092773
Validation loss: 2.0842392559974425

Epoch: 6| Step: 6
Training loss: 2.2386345863342285
Validation loss: 2.131933932663292

Epoch: 6| Step: 7
Training loss: 1.7186732292175293
Validation loss: 2.029990480792138

Epoch: 6| Step: 8
Training loss: 1.3778570890426636
Validation loss: 2.055688859314047

Epoch: 6| Step: 9
Training loss: 1.2632601261138916
Validation loss: 2.0562754702824417

Epoch: 6| Step: 10
Training loss: 1.557037591934204
Validation loss: 2.0176020219761837

Epoch: 6| Step: 11
Training loss: 1.4809153079986572
Validation loss: 2.036629920364708

Epoch: 6| Step: 12
Training loss: 1.1317286491394043
Validation loss: 2.0264604014735066

Epoch: 6| Step: 13
Training loss: 1.3175946474075317
Validation loss: 2.031881542615993

Epoch: 406| Step: 0
Training loss: 0.8165533542633057
Validation loss: 2.023153725490775

Epoch: 6| Step: 1
Training loss: 1.308454990386963
Validation loss: 2.018336239681449

Epoch: 6| Step: 2
Training loss: 1.9990636110305786
Validation loss: 2.0305614497071955

Epoch: 6| Step: 3
Training loss: 1.3583179712295532
Validation loss: 2.033250234460318

Epoch: 6| Step: 4
Training loss: 1.4064974784851074
Validation loss: 2.068486177793113

Epoch: 6| Step: 5
Training loss: 1.6484360694885254
Validation loss: 2.0843451766557592

Epoch: 6| Step: 6
Training loss: 1.5909888744354248
Validation loss: 2.0446889272300144

Epoch: 6| Step: 7
Training loss: 1.938894271850586
Validation loss: 2.0554357549195648

Epoch: 6| Step: 8
Training loss: 1.3608421087265015
Validation loss: 2.0566023793271793

Epoch: 6| Step: 9
Training loss: 1.2775444984436035
Validation loss: 2.0776773319449475

Epoch: 6| Step: 10
Training loss: 1.6010159254074097
Validation loss: 2.0891218621243715

Epoch: 6| Step: 11
Training loss: 1.4798076152801514
Validation loss: 2.0591815492158294

Epoch: 6| Step: 12
Training loss: 1.4734303951263428
Validation loss: 2.0698632309513707

Epoch: 6| Step: 13
Training loss: 2.667837381362915
Validation loss: 2.0692345198764595

Epoch: 407| Step: 0
Training loss: 0.9880290031433105
Validation loss: 2.0655091552324194

Epoch: 6| Step: 1
Training loss: 2.2996139526367188
Validation loss: 2.039968208600116

Epoch: 6| Step: 2
Training loss: 1.0635857582092285
Validation loss: 2.06175333838309

Epoch: 6| Step: 3
Training loss: 1.940186858177185
Validation loss: 2.035225077341962

Epoch: 6| Step: 4
Training loss: 1.4711495637893677
Validation loss: 2.0349225151923394

Epoch: 6| Step: 5
Training loss: 1.5230481624603271
Validation loss: 2.021647525090043

Epoch: 6| Step: 6
Training loss: 1.859750747680664
Validation loss: 2.042252154760463

Epoch: 6| Step: 7
Training loss: 1.612241506576538
Validation loss: 2.030783974996177

Epoch: 6| Step: 8
Training loss: 1.898106336593628
Validation loss: 2.047473366542529

Epoch: 6| Step: 9
Training loss: 1.5167737007141113
Validation loss: 2.0222282871123283

Epoch: 6| Step: 10
Training loss: 1.2961302995681763
Validation loss: 2.022563918944328

Epoch: 6| Step: 11
Training loss: 1.0291643142700195
Validation loss: 2.0435601921491724

Epoch: 6| Step: 12
Training loss: 1.8284097909927368
Validation loss: 2.0491714810812347

Epoch: 6| Step: 13
Training loss: 0.6562028527259827
Validation loss: 2.0657096998665923

Epoch: 408| Step: 0
Training loss: 1.0062222480773926
Validation loss: 2.0278501895166214

Epoch: 6| Step: 1
Training loss: 0.8957312107086182
Validation loss: 2.035464072740206

Epoch: 6| Step: 2
Training loss: 1.9776729345321655
Validation loss: 2.0711429952293314

Epoch: 6| Step: 3
Training loss: 2.057311534881592
Validation loss: 2.0894407585103023

Epoch: 6| Step: 4
Training loss: 1.1858572959899902
Validation loss: 2.0047223593599055

Epoch: 6| Step: 5
Training loss: 1.979102611541748
Validation loss: 2.052296946125646

Epoch: 6| Step: 6
Training loss: 1.4221100807189941
Validation loss: 2.0947850083792083

Epoch: 6| Step: 7
Training loss: 1.2571941614151
Validation loss: 2.058559786888861

Epoch: 6| Step: 8
Training loss: 2.3633739948272705
Validation loss: 2.0453786144974413

Epoch: 6| Step: 9
Training loss: 1.4064339399337769
Validation loss: 2.0675093025289555

Epoch: 6| Step: 10
Training loss: 1.421739101409912
Validation loss: 2.07164458305605

Epoch: 6| Step: 11
Training loss: 1.590177297592163
Validation loss: 2.06731350703906

Epoch: 6| Step: 12
Training loss: 0.8428264260292053
Validation loss: 2.0568175136402087

Epoch: 6| Step: 13
Training loss: 1.3917126655578613
Validation loss: 2.01317734103049

Epoch: 409| Step: 0
Training loss: 1.251539945602417
Validation loss: 1.9876529888440204

Epoch: 6| Step: 1
Training loss: 2.1771275997161865
Validation loss: 2.0554494716787852

Epoch: 6| Step: 2
Training loss: 1.607818603515625
Validation loss: 2.0458631464230117

Epoch: 6| Step: 3
Training loss: 1.0686912536621094
Validation loss: 2.0190836050177134

Epoch: 6| Step: 4
Training loss: 1.9843381643295288
Validation loss: 2.071870219322943

Epoch: 6| Step: 5
Training loss: 1.0303325653076172
Validation loss: 2.061457662172215

Epoch: 6| Step: 6
Training loss: 1.814426064491272
Validation loss: 2.0686120756210817

Epoch: 6| Step: 7
Training loss: 1.6309351921081543
Validation loss: 2.044519709002587

Epoch: 6| Step: 8
Training loss: 1.719233512878418
Validation loss: 2.1095606562911824

Epoch: 6| Step: 9
Training loss: 1.1360594034194946
Validation loss: 2.077725075906323

Epoch: 6| Step: 10
Training loss: 1.6584850549697876
Validation loss: 2.1573404765898183

Epoch: 6| Step: 11
Training loss: 1.2718992233276367
Validation loss: 2.12642676086836

Epoch: 6| Step: 12
Training loss: 1.7469666004180908
Validation loss: 2.114776498527937

Epoch: 6| Step: 13
Training loss: 1.154355525970459
Validation loss: 2.158265334303661

Epoch: 410| Step: 0
Training loss: 1.351546287536621
Validation loss: 2.129451149253435

Epoch: 6| Step: 1
Training loss: 1.6403907537460327
Validation loss: 2.1375682892337924

Epoch: 6| Step: 2
Training loss: 1.7254629135131836
Validation loss: 2.146222009453722

Epoch: 6| Step: 3
Training loss: 0.9460302591323853
Validation loss: 2.089858865225187

Epoch: 6| Step: 4
Training loss: 1.6207256317138672
Validation loss: 2.119786654749224

Epoch: 6| Step: 5
Training loss: 2.0314557552337646
Validation loss: 2.105783070287397

Epoch: 6| Step: 6
Training loss: 0.7860320806503296
Validation loss: 2.097523504687894

Epoch: 6| Step: 7
Training loss: 1.7556596994400024
Validation loss: 2.0632124946963404

Epoch: 6| Step: 8
Training loss: 1.8194756507873535
Validation loss: 2.073909342929881

Epoch: 6| Step: 9
Training loss: 1.6505300998687744
Validation loss: 2.02590694222399

Epoch: 6| Step: 10
Training loss: 1.2465214729309082
Validation loss: 2.0374221878667034

Epoch: 6| Step: 11
Training loss: 2.0639517307281494
Validation loss: 2.0202119401706162

Epoch: 6| Step: 12
Training loss: 0.7204858064651489
Validation loss: 2.0219882303668606

Epoch: 6| Step: 13
Training loss: 1.7670997381210327
Validation loss: 2.047674520041353

Epoch: 411| Step: 0
Training loss: 1.5977054834365845
Validation loss: 2.0258639217704855

Epoch: 6| Step: 1
Training loss: 1.770781397819519
Validation loss: 2.059329059816176

Epoch: 6| Step: 2
Training loss: 1.259947657585144
Validation loss: 2.029923669753536

Epoch: 6| Step: 3
Training loss: 1.5744961500167847
Validation loss: 2.050662789293515

Epoch: 6| Step: 4
Training loss: 1.5217885971069336
Validation loss: 2.0530244599106493

Epoch: 6| Step: 5
Training loss: 1.7335827350616455
Validation loss: 2.050305889498803

Epoch: 6| Step: 6
Training loss: 1.1619172096252441
Validation loss: 2.052292054699313

Epoch: 6| Step: 7
Training loss: 2.1266250610351562
Validation loss: 2.0622903364960865

Epoch: 6| Step: 8
Training loss: 1.3820706605911255
Validation loss: 2.079466473671698

Epoch: 6| Step: 9
Training loss: 1.383683204650879
Validation loss: 2.104470173517863

Epoch: 6| Step: 10
Training loss: 1.8861806392669678
Validation loss: 2.101501457152828

Epoch: 6| Step: 11
Training loss: 1.132436990737915
Validation loss: 2.086235036132156

Epoch: 6| Step: 12
Training loss: 1.5008474588394165
Validation loss: 2.0954752506748324

Epoch: 6| Step: 13
Training loss: 0.6696253418922424
Validation loss: 2.086487184288681

Epoch: 412| Step: 0
Training loss: 1.161590576171875
Validation loss: 2.091273835910264

Epoch: 6| Step: 1
Training loss: 1.3153340816497803
Validation loss: 2.1000464706010717

Epoch: 6| Step: 2
Training loss: 1.4455854892730713
Validation loss: 2.1022063942365747

Epoch: 6| Step: 3
Training loss: 1.3167201280593872
Validation loss: 2.1251348885156776

Epoch: 6| Step: 4
Training loss: 1.0181230306625366
Validation loss: 2.0909278867065266

Epoch: 6| Step: 5
Training loss: 1.7808125019073486
Validation loss: 2.0413681153328187

Epoch: 6| Step: 6
Training loss: 1.8006346225738525
Validation loss: 2.0707830780295917

Epoch: 6| Step: 7
Training loss: 1.9168319702148438
Validation loss: 2.0368986988580353

Epoch: 6| Step: 8
Training loss: 1.1685543060302734
Validation loss: 2.0516223189651326

Epoch: 6| Step: 9
Training loss: 1.4162263870239258
Validation loss: 2.0605195465908257

Epoch: 6| Step: 10
Training loss: 1.963508129119873
Validation loss: 2.0489562711408063

Epoch: 6| Step: 11
Training loss: 1.6991513967514038
Validation loss: 2.050210219557567

Epoch: 6| Step: 12
Training loss: 1.5832098722457886
Validation loss: 2.0394327025259695

Epoch: 6| Step: 13
Training loss: 1.1341198682785034
Validation loss: 2.0121098487607894

Epoch: 413| Step: 0
Training loss: 1.1230556964874268
Validation loss: 2.060124945896928

Epoch: 6| Step: 1
Training loss: 1.8369174003601074
Validation loss: 2.1104031352586645

Epoch: 6| Step: 2
Training loss: 1.4846107959747314
Validation loss: 2.061311798710977

Epoch: 6| Step: 3
Training loss: 1.565814733505249
Validation loss: 2.0736607736156834

Epoch: 6| Step: 4
Training loss: 1.4630495309829712
Validation loss: 2.092250858583758

Epoch: 6| Step: 5
Training loss: 1.7093737125396729
Validation loss: 2.0958641434228547

Epoch: 6| Step: 6
Training loss: 1.0331255197525024
Validation loss: 2.088379313868861

Epoch: 6| Step: 7
Training loss: 2.2221310138702393
Validation loss: 2.0626585483551025

Epoch: 6| Step: 8
Training loss: 1.943458080291748
Validation loss: 2.060505187639626

Epoch: 6| Step: 9
Training loss: 1.9858968257904053
Validation loss: 2.080845676442628

Epoch: 6| Step: 10
Training loss: 0.859213650226593
Validation loss: 2.103979936210058

Epoch: 6| Step: 11
Training loss: 1.7019051313400269
Validation loss: 2.0779730837832213

Epoch: 6| Step: 12
Training loss: 1.1173269748687744
Validation loss: 2.081885278865855

Epoch: 6| Step: 13
Training loss: 1.0327061414718628
Validation loss: 2.053437558553552

Epoch: 414| Step: 0
Training loss: 2.03520131111145
Validation loss: 2.0671082414606565

Epoch: 6| Step: 1
Training loss: 1.2617213726043701
Validation loss: 2.0497174160454863

Epoch: 6| Step: 2
Training loss: 1.3664705753326416
Validation loss: 2.0749488774166314

Epoch: 6| Step: 3
Training loss: 1.47761869430542
Validation loss: 2.038808091994255

Epoch: 6| Step: 4
Training loss: 2.0662894248962402
Validation loss: 2.0603982197341097

Epoch: 6| Step: 5
Training loss: 1.6254932880401611
Validation loss: 2.0461426127341484

Epoch: 6| Step: 6
Training loss: 2.0360074043273926
Validation loss: 2.043378917119836

Epoch: 6| Step: 7
Training loss: 1.3331869840621948
Validation loss: 2.0453836840967976

Epoch: 6| Step: 8
Training loss: 1.145017147064209
Validation loss: 2.0582394266641266

Epoch: 6| Step: 9
Training loss: 1.2137353420257568
Validation loss: 2.076769418613885

Epoch: 6| Step: 10
Training loss: 1.0453699827194214
Validation loss: 2.0874730053768364

Epoch: 6| Step: 11
Training loss: 1.8240060806274414
Validation loss: 2.070922951544485

Epoch: 6| Step: 12
Training loss: 1.5871753692626953
Validation loss: 2.075791402529645

Epoch: 6| Step: 13
Training loss: 0.9873455762863159
Validation loss: 2.089730529374974

Epoch: 415| Step: 0
Training loss: 1.7916641235351562
Validation loss: 2.062182066261127

Epoch: 6| Step: 1
Training loss: 2.0887937545776367
Validation loss: 2.0946045819149224

Epoch: 6| Step: 2
Training loss: 1.3882718086242676
Validation loss: 2.0621058607614167

Epoch: 6| Step: 3
Training loss: 1.4218297004699707
Validation loss: 2.0865369048169864

Epoch: 6| Step: 4
Training loss: 1.6401309967041016
Validation loss: 2.1192318085701234

Epoch: 6| Step: 5
Training loss: 1.5588024854660034
Validation loss: 2.066947446074537

Epoch: 6| Step: 6
Training loss: 1.5725247859954834
Validation loss: 2.077141688716027

Epoch: 6| Step: 7
Training loss: 1.6788289546966553
Validation loss: 2.0396590079030683

Epoch: 6| Step: 8
Training loss: 0.7762727737426758
Validation loss: 2.088173971381239

Epoch: 6| Step: 9
Training loss: 1.5463922023773193
Validation loss: 2.1312317361113844

Epoch: 6| Step: 10
Training loss: 1.672262191772461
Validation loss: 2.0604101432267057

Epoch: 6| Step: 11
Training loss: 1.528193712234497
Validation loss: 2.078158868256436

Epoch: 6| Step: 12
Training loss: 1.3236846923828125
Validation loss: 2.0442466582021406

Epoch: 6| Step: 13
Training loss: 0.5324453711509705
Validation loss: 2.068983749676776

Epoch: 416| Step: 0
Training loss: 1.3034522533416748
Validation loss: 2.03720925956644

Epoch: 6| Step: 1
Training loss: 1.4177720546722412
Validation loss: 2.053603736303186

Epoch: 6| Step: 2
Training loss: 1.4021282196044922
Validation loss: 2.0216763891199583

Epoch: 6| Step: 3
Training loss: 1.3696411848068237
Validation loss: 2.0357875721428984

Epoch: 6| Step: 4
Training loss: 1.9520677328109741
Validation loss: 2.0213581567169516

Epoch: 6| Step: 5
Training loss: 0.9420743584632874
Validation loss: 2.087906170916814

Epoch: 6| Step: 6
Training loss: 1.5565216541290283
Validation loss: 2.0575085109280002

Epoch: 6| Step: 7
Training loss: 1.4851782321929932
Validation loss: 2.053308120337866

Epoch: 6| Step: 8
Training loss: 1.55584716796875
Validation loss: 2.0557663876523256

Epoch: 6| Step: 9
Training loss: 1.613708734512329
Validation loss: 2.0303394320190593

Epoch: 6| Step: 10
Training loss: 1.843068242073059
Validation loss: 2.0984210865471953

Epoch: 6| Step: 11
Training loss: 1.2253605127334595
Validation loss: 2.095240767284106

Epoch: 6| Step: 12
Training loss: 1.6006288528442383
Validation loss: 2.0287805885396977

Epoch: 6| Step: 13
Training loss: 1.3767666816711426
Validation loss: 2.007679516269315

Epoch: 417| Step: 0
Training loss: 1.2532013654708862
Validation loss: 2.0952095908503376

Epoch: 6| Step: 1
Training loss: 1.5194482803344727
Validation loss: 2.067601180845691

Epoch: 6| Step: 2
Training loss: 1.3660988807678223
Validation loss: 2.120546422978883

Epoch: 6| Step: 3
Training loss: 1.2737842798233032
Validation loss: 2.063197453816732

Epoch: 6| Step: 4
Training loss: 1.918631911277771
Validation loss: 2.0940383749623455

Epoch: 6| Step: 5
Training loss: 1.2582244873046875
Validation loss: 2.070764084016123

Epoch: 6| Step: 6
Training loss: 1.6358859539031982
Validation loss: 2.0768672881587857

Epoch: 6| Step: 7
Training loss: 1.239395022392273
Validation loss: 2.059474960450203

Epoch: 6| Step: 8
Training loss: 1.1581073999404907
Validation loss: 2.0652844764853038

Epoch: 6| Step: 9
Training loss: 1.4225596189498901
Validation loss: 2.1038166605016237

Epoch: 6| Step: 10
Training loss: 1.934804916381836
Validation loss: 2.1061466099113546

Epoch: 6| Step: 11
Training loss: 1.3188438415527344
Validation loss: 2.1139766452133015

Epoch: 6| Step: 12
Training loss: 1.9263042211532593
Validation loss: 2.089666005103819

Epoch: 6| Step: 13
Training loss: 2.2470080852508545
Validation loss: 2.100567199850595

Epoch: 418| Step: 0
Training loss: 1.2893118858337402
Validation loss: 2.079749620088967

Epoch: 6| Step: 1
Training loss: 1.6059348583221436
Validation loss: 2.07896242859543

Epoch: 6| Step: 2
Training loss: 0.9555025100708008
Validation loss: 2.050227934314359

Epoch: 6| Step: 3
Training loss: 1.592270851135254
Validation loss: 2.046476011635155

Epoch: 6| Step: 4
Training loss: 1.4359197616577148
Validation loss: 2.0409932931264243

Epoch: 6| Step: 5
Training loss: 1.6743619441986084
Validation loss: 2.0530222436433196

Epoch: 6| Step: 6
Training loss: 1.8115136623382568
Validation loss: 2.050778781214068

Epoch: 6| Step: 7
Training loss: 1.3733294010162354
Validation loss: 2.069515356453516

Epoch: 6| Step: 8
Training loss: 0.955776572227478
Validation loss: 2.033891752202024

Epoch: 6| Step: 9
Training loss: 2.114957571029663
Validation loss: 2.079325424727573

Epoch: 6| Step: 10
Training loss: 1.650423288345337
Validation loss: 2.0819252934507144

Epoch: 6| Step: 11
Training loss: 1.8644514083862305
Validation loss: 2.0723491509755454

Epoch: 6| Step: 12
Training loss: 1.589617133140564
Validation loss: 2.0312869138615106

Epoch: 6| Step: 13
Training loss: 0.8465331196784973
Validation loss: 2.074430197797796

Epoch: 419| Step: 0
Training loss: 1.3546853065490723
Validation loss: 2.0483896347784225

Epoch: 6| Step: 1
Training loss: 0.9929632544517517
Validation loss: 2.0429809401112218

Epoch: 6| Step: 2
Training loss: 1.2134507894515991
Validation loss: 2.0868248631877284

Epoch: 6| Step: 3
Training loss: 0.9923295378684998
Validation loss: 2.132044853702668

Epoch: 6| Step: 4
Training loss: 1.2576110363006592
Validation loss: 2.058966848158067

Epoch: 6| Step: 5
Training loss: 1.980182409286499
Validation loss: 2.0943193512578167

Epoch: 6| Step: 6
Training loss: 1.863119125366211
Validation loss: 2.099222275518602

Epoch: 6| Step: 7
Training loss: 1.0947446823120117
Validation loss: 2.0629852561540503

Epoch: 6| Step: 8
Training loss: 2.0940563678741455
Validation loss: 2.114456897140831

Epoch: 6| Step: 9
Training loss: 1.2710227966308594
Validation loss: 2.10145475018409

Epoch: 6| Step: 10
Training loss: 1.5781950950622559
Validation loss: 2.052891198024955

Epoch: 6| Step: 11
Training loss: 1.5841782093048096
Validation loss: 2.0714701324380855

Epoch: 6| Step: 12
Training loss: 1.5359570980072021
Validation loss: 2.062201434566129

Epoch: 6| Step: 13
Training loss: 2.6901283264160156
Validation loss: 2.0848493012048865

Epoch: 420| Step: 0
Training loss: 1.7410950660705566
Validation loss: 2.0868588506534533

Epoch: 6| Step: 1
Training loss: 1.085098385810852
Validation loss: 2.0498845679785616

Epoch: 6| Step: 2
Training loss: 2.2545886039733887
Validation loss: 2.0543445925558768

Epoch: 6| Step: 3
Training loss: 1.4559955596923828
Validation loss: 2.0291093908330446

Epoch: 6| Step: 4
Training loss: 1.5208740234375
Validation loss: 2.0556604862213135

Epoch: 6| Step: 5
Training loss: 1.6420824527740479
Validation loss: 2.0685969257867463

Epoch: 6| Step: 6
Training loss: 1.7598786354064941
Validation loss: 2.0434106652454664

Epoch: 6| Step: 7
Training loss: 1.1992723941802979
Validation loss: 2.0647033593987905

Epoch: 6| Step: 8
Training loss: 1.4491698741912842
Validation loss: 2.043413490377447

Epoch: 6| Step: 9
Training loss: 0.6465976238250732
Validation loss: 2.0267692586427093

Epoch: 6| Step: 10
Training loss: 1.5651671886444092
Validation loss: 2.0502104131124352

Epoch: 6| Step: 11
Training loss: 1.7483938932418823
Validation loss: 2.0549206502975954

Epoch: 6| Step: 12
Training loss: 1.2143874168395996
Validation loss: 2.0523600578308105

Epoch: 6| Step: 13
Training loss: 1.9015769958496094
Validation loss: 2.052609233446019

Epoch: 421| Step: 0
Training loss: 1.0285975933074951
Validation loss: 2.0736256337934926

Epoch: 6| Step: 1
Training loss: 1.1779863834381104
Validation loss: 2.086203258524659

Epoch: 6| Step: 2
Training loss: 1.5801563262939453
Validation loss: 2.0982398012632966

Epoch: 6| Step: 3
Training loss: 1.3840512037277222
Validation loss: 2.103649439350251

Epoch: 6| Step: 4
Training loss: 1.4533315896987915
Validation loss: 2.098508378510834

Epoch: 6| Step: 5
Training loss: 1.5373351573944092
Validation loss: 2.094998028970534

Epoch: 6| Step: 6
Training loss: 1.366525411605835
Validation loss: 2.08550863881265

Epoch: 6| Step: 7
Training loss: 1.6153186559677124
Validation loss: 2.0619195635600756

Epoch: 6| Step: 8
Training loss: 1.9881387948989868
Validation loss: 2.0684772024872484

Epoch: 6| Step: 9
Training loss: 1.514847993850708
Validation loss: 2.0562112523663427

Epoch: 6| Step: 10
Training loss: 2.086172580718994
Validation loss: 2.049760728754023

Epoch: 6| Step: 11
Training loss: 1.4237666130065918
Validation loss: 2.0329278912595523

Epoch: 6| Step: 12
Training loss: 1.0939357280731201
Validation loss: 2.0374108129932034

Epoch: 6| Step: 13
Training loss: 1.8379584550857544
Validation loss: 2.041100968596756

Epoch: 422| Step: 0
Training loss: 1.3607122898101807
Validation loss: 2.0303346149383055

Epoch: 6| Step: 1
Training loss: 1.2696235179901123
Validation loss: 1.9940588679364932

Epoch: 6| Step: 2
Training loss: 1.4462699890136719
Validation loss: 2.052365449167067

Epoch: 6| Step: 3
Training loss: 1.1521919965744019
Validation loss: 2.0332102467936854

Epoch: 6| Step: 4
Training loss: 1.3972351551055908
Validation loss: 2.039142034387076

Epoch: 6| Step: 5
Training loss: 1.2424112558364868
Validation loss: 2.0423387430047475

Epoch: 6| Step: 6
Training loss: 1.6253714561462402
Validation loss: 2.0354891823184107

Epoch: 6| Step: 7
Training loss: 1.5171220302581787
Validation loss: 2.0487432428585586

Epoch: 6| Step: 8
Training loss: 1.152085781097412
Validation loss: 2.1094609716887116

Epoch: 6| Step: 9
Training loss: 1.2488995790481567
Validation loss: 2.0792789984774847

Epoch: 6| Step: 10
Training loss: 1.8433527946472168
Validation loss: 2.050150256003103

Epoch: 6| Step: 11
Training loss: 1.679152250289917
Validation loss: 2.0955637911314606

Epoch: 6| Step: 12
Training loss: 2.296013832092285
Validation loss: 2.0781492417858494

Epoch: 6| Step: 13
Training loss: 1.7580636739730835
Validation loss: 2.0264458656311035

Epoch: 423| Step: 0
Training loss: 1.3852779865264893
Validation loss: 2.050723662940405

Epoch: 6| Step: 1
Training loss: 2.1591498851776123
Validation loss: 2.043224360353203

Epoch: 6| Step: 2
Training loss: 1.8853157758712769
Validation loss: 2.0651645109217656

Epoch: 6| Step: 3
Training loss: 1.4381248950958252
Validation loss: 2.057916493826015

Epoch: 6| Step: 4
Training loss: 1.0919523239135742
Validation loss: 2.0777429906270837

Epoch: 6| Step: 5
Training loss: 1.7507648468017578
Validation loss: 2.1083869575172343

Epoch: 6| Step: 6
Training loss: 1.0564286708831787
Validation loss: 2.074810953550441

Epoch: 6| Step: 7
Training loss: 1.6940468549728394
Validation loss: 2.1030921038760932

Epoch: 6| Step: 8
Training loss: 1.5783226490020752
Validation loss: 2.0959132358592045

Epoch: 6| Step: 9
Training loss: 1.138429880142212
Validation loss: 2.058977585966869

Epoch: 6| Step: 10
Training loss: 0.9269629716873169
Validation loss: 2.0370790035493913

Epoch: 6| Step: 11
Training loss: 1.1820834875106812
Validation loss: 2.0959252131882535

Epoch: 6| Step: 12
Training loss: 1.5326555967330933
Validation loss: 2.0614054433761106

Epoch: 6| Step: 13
Training loss: 1.9883791208267212
Validation loss: 2.092724438636534

Epoch: 424| Step: 0
Training loss: 2.019078016281128
Validation loss: 2.0754144358378586

Epoch: 6| Step: 1
Training loss: 1.2060182094573975
Validation loss: 2.0516398311943136

Epoch: 6| Step: 2
Training loss: 1.0915948152542114
Validation loss: 2.0646607952733196

Epoch: 6| Step: 3
Training loss: 1.5218226909637451
Validation loss: 2.089639445786835

Epoch: 6| Step: 4
Training loss: 1.1250295639038086
Validation loss: 2.0721711420243785

Epoch: 6| Step: 5
Training loss: 1.224973201751709
Validation loss: 2.0534198104694323

Epoch: 6| Step: 6
Training loss: 1.1767443418502808
Validation loss: 2.0574457953053136

Epoch: 6| Step: 7
Training loss: 1.0291097164154053
Validation loss: 2.0520115206318517

Epoch: 6| Step: 8
Training loss: 1.5040667057037354
Validation loss: 2.0766342519431986

Epoch: 6| Step: 9
Training loss: 1.4026472568511963
Validation loss: 2.103357413763641

Epoch: 6| Step: 10
Training loss: 2.0712993144989014
Validation loss: 2.1053518890052714

Epoch: 6| Step: 11
Training loss: 2.0867393016815186
Validation loss: 2.0181746944304435

Epoch: 6| Step: 12
Training loss: 1.766106128692627
Validation loss: 2.05351185798645

Epoch: 6| Step: 13
Training loss: 1.16795015335083
Validation loss: 2.028820465969783

Epoch: 425| Step: 0
Training loss: 0.9971266984939575
Validation loss: 2.0460833003444057

Epoch: 6| Step: 1
Training loss: 1.8484528064727783
Validation loss: 2.0789726152214953

Epoch: 6| Step: 2
Training loss: 1.1460635662078857
Validation loss: 2.089798403042619

Epoch: 6| Step: 3
Training loss: 0.8089357614517212
Validation loss: 2.0681611517424225

Epoch: 6| Step: 4
Training loss: 1.6766178607940674
Validation loss: 2.0848354857455016

Epoch: 6| Step: 5
Training loss: 1.7887860536575317
Validation loss: 2.091435568307036

Epoch: 6| Step: 6
Training loss: 2.0922951698303223
Validation loss: 2.088997397371518

Epoch: 6| Step: 7
Training loss: 0.7387063503265381
Validation loss: 2.0814665363680933

Epoch: 6| Step: 8
Training loss: 1.2244768142700195
Validation loss: 2.074465961866481

Epoch: 6| Step: 9
Training loss: 1.932976484298706
Validation loss: 2.0295716088305236

Epoch: 6| Step: 10
Training loss: 1.428730845451355
Validation loss: 2.084498779748076

Epoch: 6| Step: 11
Training loss: 1.6220204830169678
Validation loss: 2.0490247382912585

Epoch: 6| Step: 12
Training loss: 1.5111007690429688
Validation loss: 2.0453897958160727

Epoch: 6| Step: 13
Training loss: 1.8608654737472534
Validation loss: 2.052550078720175

Epoch: 426| Step: 0
Training loss: 1.3544784784317017
Validation loss: 2.0493448613792338

Epoch: 6| Step: 1
Training loss: 1.43837308883667
Validation loss: 2.041904354608187

Epoch: 6| Step: 2
Training loss: 1.5975263118743896
Validation loss: 2.0339365261857227

Epoch: 6| Step: 3
Training loss: 1.265548586845398
Validation loss: 2.042753017076882

Epoch: 6| Step: 4
Training loss: 2.632930040359497
Validation loss: 2.0420527727373186

Epoch: 6| Step: 5
Training loss: 1.7695415019989014
Validation loss: 2.0605378086848924

Epoch: 6| Step: 6
Training loss: 1.4362866878509521
Validation loss: 2.0640651846444733

Epoch: 6| Step: 7
Training loss: 1.56449294090271
Validation loss: 2.023230783400997

Epoch: 6| Step: 8
Training loss: 1.5856777429580688
Validation loss: 2.0135383208592734

Epoch: 6| Step: 9
Training loss: 1.1848907470703125
Validation loss: 2.056558560299617

Epoch: 6| Step: 10
Training loss: 1.5337636470794678
Validation loss: 2.082888598083168

Epoch: 6| Step: 11
Training loss: 1.3700231313705444
Validation loss: 2.048269061632054

Epoch: 6| Step: 12
Training loss: 0.7360988855361938
Validation loss: 2.106227808101203

Epoch: 6| Step: 13
Training loss: 1.0754884481430054
Validation loss: 2.0686952273050943

Epoch: 427| Step: 0
Training loss: 2.052696704864502
Validation loss: 2.068898295843473

Epoch: 6| Step: 1
Training loss: 1.2620832920074463
Validation loss: 2.0468405869699295

Epoch: 6| Step: 2
Training loss: 1.79951810836792
Validation loss: 2.0700353742927633

Epoch: 6| Step: 3
Training loss: 1.2893937826156616
Validation loss: 2.129843898998794

Epoch: 6| Step: 4
Training loss: 1.3385344743728638
Validation loss: 2.101444790440221

Epoch: 6| Step: 5
Training loss: 1.2872194051742554
Validation loss: 2.1145893783979517

Epoch: 6| Step: 6
Training loss: 1.5911476612091064
Validation loss: 2.139838300725465

Epoch: 6| Step: 7
Training loss: 1.4060662984848022
Validation loss: 2.098735793944328

Epoch: 6| Step: 8
Training loss: 1.6512205600738525
Validation loss: 2.0955983438799457

Epoch: 6| Step: 9
Training loss: 2.4110918045043945
Validation loss: 2.0732889841961604

Epoch: 6| Step: 10
Training loss: 0.8394145965576172
Validation loss: 2.059876790610693

Epoch: 6| Step: 11
Training loss: 1.542442798614502
Validation loss: 2.0362454409240396

Epoch: 6| Step: 12
Training loss: 1.0328428745269775
Validation loss: 2.055932834584226

Epoch: 6| Step: 13
Training loss: 1.181954026222229
Validation loss: 1.9983223958681988

Epoch: 428| Step: 0
Training loss: 1.6463501453399658
Validation loss: 2.020417414685731

Epoch: 6| Step: 1
Training loss: 1.72554349899292
Validation loss: 2.033844253068329

Epoch: 6| Step: 2
Training loss: 1.0207184553146362
Validation loss: 2.009100624310073

Epoch: 6| Step: 3
Training loss: 1.5302948951721191
Validation loss: 1.9955760330282233

Epoch: 6| Step: 4
Training loss: 1.568114995956421
Validation loss: 2.054469952019312

Epoch: 6| Step: 5
Training loss: 1.8407435417175293
Validation loss: 2.0313115132752286

Epoch: 6| Step: 6
Training loss: 1.4163599014282227
Validation loss: 2.0259215818938388

Epoch: 6| Step: 7
Training loss: 0.9624494314193726
Validation loss: 2.0464051641443723

Epoch: 6| Step: 8
Training loss: 1.2460651397705078
Validation loss: 2.0464148213786464

Epoch: 6| Step: 9
Training loss: 2.1031241416931152
Validation loss: 2.042078143806868

Epoch: 6| Step: 10
Training loss: 1.5126789808273315
Validation loss: 2.070999385208212

Epoch: 6| Step: 11
Training loss: 1.642266035079956
Validation loss: 2.0745669180347073

Epoch: 6| Step: 12
Training loss: 1.2405701875686646
Validation loss: 2.0631481242436234

Epoch: 6| Step: 13
Training loss: 1.5299601554870605
Validation loss: 2.095015974454982

Epoch: 429| Step: 0
Training loss: 1.2890000343322754
Validation loss: 2.083072289343803

Epoch: 6| Step: 1
Training loss: 1.5756580829620361
Validation loss: 2.081111882322578

Epoch: 6| Step: 2
Training loss: 1.3738948106765747
Validation loss: 2.11505990259109

Epoch: 6| Step: 3
Training loss: 1.773108959197998
Validation loss: 2.102406003141916

Epoch: 6| Step: 4
Training loss: 1.6606179475784302
Validation loss: 2.0847769219388246

Epoch: 6| Step: 5
Training loss: 1.1261942386627197
Validation loss: 2.078084627787272

Epoch: 6| Step: 6
Training loss: 0.9827423095703125
Validation loss: 2.121948480606079

Epoch: 6| Step: 7
Training loss: 1.2501752376556396
Validation loss: 2.1009030329283847

Epoch: 6| Step: 8
Training loss: 1.6223008632659912
Validation loss: 2.1139420283738004

Epoch: 6| Step: 9
Training loss: 1.861215353012085
Validation loss: 2.0947324537461802

Epoch: 6| Step: 10
Training loss: 1.7955777645111084
Validation loss: 2.057512399970844

Epoch: 6| Step: 11
Training loss: 1.482097864151001
Validation loss: 2.0737157303799867

Epoch: 6| Step: 12
Training loss: 1.1705025434494019
Validation loss: 2.048599645655642

Epoch: 6| Step: 13
Training loss: 1.7456307411193848
Validation loss: 2.039439276982379

Epoch: 430| Step: 0
Training loss: 1.0000313520431519
Validation loss: 2.080636742294476

Epoch: 6| Step: 1
Training loss: 1.6508169174194336
Validation loss: 2.0990093754183863

Epoch: 6| Step: 2
Training loss: 1.0341835021972656
Validation loss: 2.0455518948134555

Epoch: 6| Step: 3
Training loss: 1.4938673973083496
Validation loss: 2.0679900325754637

Epoch: 6| Step: 4
Training loss: 1.721307396888733
Validation loss: 2.085708669436875

Epoch: 6| Step: 5
Training loss: 1.262197494506836
Validation loss: 2.0576940864645024

Epoch: 6| Step: 6
Training loss: 1.8918043375015259
Validation loss: 2.1020934069028465

Epoch: 6| Step: 7
Training loss: 1.6560699939727783
Validation loss: 2.081295182628016

Epoch: 6| Step: 8
Training loss: 1.781127691268921
Validation loss: 2.0364159640445503

Epoch: 6| Step: 9
Training loss: 1.1499321460723877
Validation loss: 2.0957063141689507

Epoch: 6| Step: 10
Training loss: 1.1430813074111938
Validation loss: 2.0468312207088677

Epoch: 6| Step: 11
Training loss: 1.498302936553955
Validation loss: 2.0970609329080068

Epoch: 6| Step: 12
Training loss: 1.9756360054016113
Validation loss: 2.064356924385153

Epoch: 6| Step: 13
Training loss: 1.1571540832519531
Validation loss: 2.0874315692532446

Epoch: 431| Step: 0
Training loss: 1.038633108139038
Validation loss: 2.082503890478483

Epoch: 6| Step: 1
Training loss: 0.8146770000457764
Validation loss: 2.0499767859776816

Epoch: 6| Step: 2
Training loss: 1.269059419631958
Validation loss: 2.0673984789079234

Epoch: 6| Step: 3
Training loss: 2.0422298908233643
Validation loss: 2.0471131365786315

Epoch: 6| Step: 4
Training loss: 1.900752067565918
Validation loss: 2.0696425437927246

Epoch: 6| Step: 5
Training loss: 1.3946027755737305
Validation loss: 2.0624903799385153

Epoch: 6| Step: 6
Training loss: 1.7985938787460327
Validation loss: 2.0221588380875124

Epoch: 6| Step: 7
Training loss: 1.1776833534240723
Validation loss: 2.069790221029712

Epoch: 6| Step: 8
Training loss: 1.4325923919677734
Validation loss: 2.0750150436996133

Epoch: 6| Step: 9
Training loss: 1.0025498867034912
Validation loss: 2.0579752306784354

Epoch: 6| Step: 10
Training loss: 1.4107983112335205
Validation loss: 2.065892316961801

Epoch: 6| Step: 11
Training loss: 1.5603327751159668
Validation loss: 2.0503790250388523

Epoch: 6| Step: 12
Training loss: 2.490886926651001
Validation loss: 2.043692675969934

Epoch: 6| Step: 13
Training loss: 0.9344040751457214
Validation loss: 2.087252971946552

Epoch: 432| Step: 0
Training loss: 1.7133457660675049
Validation loss: 2.0718084022562993

Epoch: 6| Step: 1
Training loss: 1.0267868041992188
Validation loss: 2.0904273525361092

Epoch: 6| Step: 2
Training loss: 1.0310485363006592
Validation loss: 2.0745460423090125

Epoch: 6| Step: 3
Training loss: 1.2708338499069214
Validation loss: 2.094174426089051

Epoch: 6| Step: 4
Training loss: 1.5582144260406494
Validation loss: 2.0843938986460366

Epoch: 6| Step: 5
Training loss: 1.8921773433685303
Validation loss: 2.1260760061202513

Epoch: 6| Step: 6
Training loss: 1.1398341655731201
Validation loss: 2.0511927899493965

Epoch: 6| Step: 7
Training loss: 0.747521698474884
Validation loss: 2.0863755479935677

Epoch: 6| Step: 8
Training loss: 1.6117836236953735
Validation loss: 2.052730155247514

Epoch: 6| Step: 9
Training loss: 2.6519856452941895
Validation loss: 2.0908535629190426

Epoch: 6| Step: 10
Training loss: 1.1858978271484375
Validation loss: 2.033229592025921

Epoch: 6| Step: 11
Training loss: 1.3548974990844727
Validation loss: 2.042209391952843

Epoch: 6| Step: 12
Training loss: 1.5917547941207886
Validation loss: 2.073670953832647

Epoch: 6| Step: 13
Training loss: 1.9415345191955566
Validation loss: 2.0460919359678864

Epoch: 433| Step: 0
Training loss: 1.3566622734069824
Validation loss: 2.0314180915073683

Epoch: 6| Step: 1
Training loss: 1.5176167488098145
Validation loss: 2.0360669012992614

Epoch: 6| Step: 2
Training loss: 2.0120561122894287
Validation loss: 2.024308822488272

Epoch: 6| Step: 3
Training loss: 1.4071829319000244
Validation loss: 2.0278406002188243

Epoch: 6| Step: 4
Training loss: 1.536543846130371
Validation loss: 2.0877376807633268

Epoch: 6| Step: 5
Training loss: 1.1698178052902222
Validation loss: 2.0625679108404342

Epoch: 6| Step: 6
Training loss: 1.6537938117980957
Validation loss: 2.0299956798553467

Epoch: 6| Step: 7
Training loss: 1.2940051555633545
Validation loss: 2.083679409437282

Epoch: 6| Step: 8
Training loss: 1.2432537078857422
Validation loss: 2.0499576778822046

Epoch: 6| Step: 9
Training loss: 1.75917649269104
Validation loss: 2.1115579297465663

Epoch: 6| Step: 10
Training loss: 0.8979424238204956
Validation loss: 2.0927343253166444

Epoch: 6| Step: 11
Training loss: 1.8333743810653687
Validation loss: 2.091623221674273

Epoch: 6| Step: 12
Training loss: 1.2681128978729248
Validation loss: 2.1218356573453514

Epoch: 6| Step: 13
Training loss: 1.8331230878829956
Validation loss: 2.0920091367536977

Epoch: 434| Step: 0
Training loss: 1.203201413154602
Validation loss: 2.089412340553858

Epoch: 6| Step: 1
Training loss: 1.3474526405334473
Validation loss: 2.0563389203881703

Epoch: 6| Step: 2
Training loss: 1.6812536716461182
Validation loss: 2.0328071886493313

Epoch: 6| Step: 3
Training loss: 1.198724389076233
Validation loss: 2.0273262326435377

Epoch: 6| Step: 4
Training loss: 1.6781632900238037
Validation loss: 2.0601348953862346

Epoch: 6| Step: 5
Training loss: 1.119478702545166
Validation loss: 2.028839019037062

Epoch: 6| Step: 6
Training loss: 1.9729105234146118
Validation loss: 2.0816743527689288

Epoch: 6| Step: 7
Training loss: 1.9722776412963867
Validation loss: 1.9847569952728927

Epoch: 6| Step: 8
Training loss: 1.4980461597442627
Validation loss: 2.049561760758841

Epoch: 6| Step: 9
Training loss: 1.5018901824951172
Validation loss: 2.073480675297399

Epoch: 6| Step: 10
Training loss: 1.5477336645126343
Validation loss: 2.037305190999021

Epoch: 6| Step: 11
Training loss: 1.4712555408477783
Validation loss: 2.0455198672509964

Epoch: 6| Step: 12
Training loss: 0.8648214340209961
Validation loss: 2.091213454482376

Epoch: 6| Step: 13
Training loss: 1.1027460098266602
Validation loss: 2.03326444343854

Epoch: 435| Step: 0
Training loss: 1.5965421199798584
Validation loss: 2.044855389543759

Epoch: 6| Step: 1
Training loss: 1.3683358430862427
Validation loss: 2.0687110757315033

Epoch: 6| Step: 2
Training loss: 0.9913921356201172
Validation loss: 2.119151953727968

Epoch: 6| Step: 3
Training loss: 1.5551486015319824
Validation loss: 2.0916902224222818

Epoch: 6| Step: 4
Training loss: 1.521809697151184
Validation loss: 2.0883342476301294

Epoch: 6| Step: 5
Training loss: 1.1800850629806519
Validation loss: 2.1288346834080194

Epoch: 6| Step: 6
Training loss: 1.7365261316299438
Validation loss: 2.083567806469497

Epoch: 6| Step: 7
Training loss: 2.1204421520233154
Validation loss: 2.104099086535874

Epoch: 6| Step: 8
Training loss: 1.3797069787979126
Validation loss: 2.0693550084226873

Epoch: 6| Step: 9
Training loss: 1.0374760627746582
Validation loss: 2.129936279789094

Epoch: 6| Step: 10
Training loss: 1.5853825807571411
Validation loss: 2.011679764716856

Epoch: 6| Step: 11
Training loss: 1.4898860454559326
Validation loss: 2.069327249321886

Epoch: 6| Step: 12
Training loss: 1.4334033727645874
Validation loss: 2.0270283017107236

Epoch: 6| Step: 13
Training loss: 1.8903961181640625
Validation loss: 1.9979206541533112

Epoch: 436| Step: 0
Training loss: 1.5219078063964844
Validation loss: 2.015725370376341

Epoch: 6| Step: 1
Training loss: 1.1896729469299316
Validation loss: 2.078579084847563

Epoch: 6| Step: 2
Training loss: 1.6199183464050293
Validation loss: 2.0465273664843653

Epoch: 6| Step: 3
Training loss: 1.7970638275146484
Validation loss: 2.0275636232027443

Epoch: 6| Step: 4
Training loss: 1.5442349910736084
Validation loss: 2.037882407506307

Epoch: 6| Step: 5
Training loss: 1.556496500968933
Validation loss: 2.0376414791230233

Epoch: 6| Step: 6
Training loss: 1.0007630586624146
Validation loss: 2.038100019578011

Epoch: 6| Step: 7
Training loss: 1.5036263465881348
Validation loss: 2.0476714641817155

Epoch: 6| Step: 8
Training loss: 1.650968313217163
Validation loss: 2.0402812944945468

Epoch: 6| Step: 9
Training loss: 1.4022185802459717
Validation loss: 2.0352959914874007

Epoch: 6| Step: 10
Training loss: 1.3920609951019287
Validation loss: 2.023589454671388

Epoch: 6| Step: 11
Training loss: 1.37644624710083
Validation loss: 2.0705269793028473

Epoch: 6| Step: 12
Training loss: 1.7095390558242798
Validation loss: 2.0396972202485606

Epoch: 6| Step: 13
Training loss: 1.0986675024032593
Validation loss: 2.050344326162851

Epoch: 437| Step: 0
Training loss: 1.4654150009155273
Validation loss: 2.1133405623897428

Epoch: 6| Step: 1
Training loss: 1.4696826934814453
Validation loss: 2.0721328502060263

Epoch: 6| Step: 2
Training loss: 2.3230156898498535
Validation loss: 2.0834312797874532

Epoch: 6| Step: 3
Training loss: 1.873754858970642
Validation loss: 2.136896797405776

Epoch: 6| Step: 4
Training loss: 1.4070112705230713
Validation loss: 2.1096895843423824

Epoch: 6| Step: 5
Training loss: 1.060773253440857
Validation loss: 2.099567605603126

Epoch: 6| Step: 6
Training loss: 1.4675019979476929
Validation loss: 2.0916858719241236

Epoch: 6| Step: 7
Training loss: 1.0406208038330078
Validation loss: 2.0759684398610103

Epoch: 6| Step: 8
Training loss: 1.702760934829712
Validation loss: 2.0946376336518155

Epoch: 6| Step: 9
Training loss: 0.469959557056427
Validation loss: 2.062674481381652

Epoch: 6| Step: 10
Training loss: 1.3711175918579102
Validation loss: 2.0315061448722758

Epoch: 6| Step: 11
Training loss: 1.83827805519104
Validation loss: 2.0300552973183255

Epoch: 6| Step: 12
Training loss: 1.3511497974395752
Validation loss: 2.0596380823401996

Epoch: 6| Step: 13
Training loss: 1.685267686843872
Validation loss: 2.1099692672811527

Epoch: 438| Step: 0
Training loss: 1.626230001449585
Validation loss: 2.023396025421799

Epoch: 6| Step: 1
Training loss: 1.4395265579223633
Validation loss: 2.0620414146813015

Epoch: 6| Step: 2
Training loss: 1.5529062747955322
Validation loss: 2.033058824077729

Epoch: 6| Step: 3
Training loss: 1.6003282070159912
Validation loss: 2.0428725955306843

Epoch: 6| Step: 4
Training loss: 1.673486590385437
Validation loss: 2.0512978889608897

Epoch: 6| Step: 5
Training loss: 1.6826283931732178
Validation loss: 2.0418227872540875

Epoch: 6| Step: 6
Training loss: 1.0445406436920166
Validation loss: 2.003957889413321

Epoch: 6| Step: 7
Training loss: 1.118902564048767
Validation loss: 2.013150633022349

Epoch: 6| Step: 8
Training loss: 1.622254490852356
Validation loss: 2.0216642143905803

Epoch: 6| Step: 9
Training loss: 1.9208886623382568
Validation loss: 2.0397401894292524

Epoch: 6| Step: 10
Training loss: 1.6613569259643555
Validation loss: 2.102518061155914

Epoch: 6| Step: 11
Training loss: 1.0116641521453857
Validation loss: 2.0794236429276003

Epoch: 6| Step: 12
Training loss: 1.127744197845459
Validation loss: 2.058426069956954

Epoch: 6| Step: 13
Training loss: 1.1004420518875122
Validation loss: 2.096503870461577

Epoch: 439| Step: 0
Training loss: 1.0642213821411133
Validation loss: 2.056101358065041

Epoch: 6| Step: 1
Training loss: 1.3835411071777344
Validation loss: 2.0487087990648005

Epoch: 6| Step: 2
Training loss: 1.660334587097168
Validation loss: 2.055022701140373

Epoch: 6| Step: 3
Training loss: 1.5101104974746704
Validation loss: 2.0718919333591255

Epoch: 6| Step: 4
Training loss: 1.9331574440002441
Validation loss: 2.0643524405776814

Epoch: 6| Step: 5
Training loss: 1.572594404220581
Validation loss: 2.04044932447454

Epoch: 6| Step: 6
Training loss: 1.3556392192840576
Validation loss: 2.0312610954366703

Epoch: 6| Step: 7
Training loss: 1.2711639404296875
Validation loss: 2.0176184318398915

Epoch: 6| Step: 8
Training loss: 1.1441855430603027
Validation loss: 2.0329571641901487

Epoch: 6| Step: 9
Training loss: 1.5938067436218262
Validation loss: 2.0283872491569928

Epoch: 6| Step: 10
Training loss: 1.9500477313995361
Validation loss: 2.049255600539587

Epoch: 6| Step: 11
Training loss: 0.9720710515975952
Validation loss: 2.0535776615142822

Epoch: 6| Step: 12
Training loss: 1.4779597520828247
Validation loss: 2.062233140391688

Epoch: 6| Step: 13
Training loss: 1.484445571899414
Validation loss: 2.1050090635976484

Epoch: 440| Step: 0
Training loss: 1.2387243509292603
Validation loss: 2.066413374357326

Epoch: 6| Step: 1
Training loss: 1.8966262340545654
Validation loss: 2.0732115443034838

Epoch: 6| Step: 2
Training loss: 1.321087121963501
Validation loss: 2.0355245233863912

Epoch: 6| Step: 3
Training loss: 1.2048753499984741
Validation loss: 2.0465664376494703

Epoch: 6| Step: 4
Training loss: 1.812704086303711
Validation loss: 2.068437360948132

Epoch: 6| Step: 5
Training loss: 1.0629209280014038
Validation loss: 2.0524197906576176

Epoch: 6| Step: 6
Training loss: 0.9095751047134399
Validation loss: 2.067383248318908

Epoch: 6| Step: 7
Training loss: 1.2426908016204834
Validation loss: 2.0474716104486936

Epoch: 6| Step: 8
Training loss: 2.0174479484558105
Validation loss: 2.0295517418974187

Epoch: 6| Step: 9
Training loss: 1.5437707901000977
Validation loss: 2.0612802261947305

Epoch: 6| Step: 10
Training loss: 1.693674087524414
Validation loss: 2.0674483673546904

Epoch: 6| Step: 11
Training loss: 1.3185513019561768
Validation loss: 2.0437735434501403

Epoch: 6| Step: 12
Training loss: 1.334530234336853
Validation loss: 2.0329850591639036

Epoch: 6| Step: 13
Training loss: 1.8322075605392456
Validation loss: 2.059701447845787

Epoch: 441| Step: 0
Training loss: 1.4790229797363281
Validation loss: 2.102104640776111

Epoch: 6| Step: 1
Training loss: 1.6932079792022705
Validation loss: 2.094796165343254

Epoch: 6| Step: 2
Training loss: 1.1097724437713623
Validation loss: 2.1263871295477754

Epoch: 6| Step: 3
Training loss: 1.6748979091644287
Validation loss: 2.105318228403727

Epoch: 6| Step: 4
Training loss: 1.3916890621185303
Validation loss: 2.097527478330879

Epoch: 6| Step: 5
Training loss: 1.9275779724121094
Validation loss: 2.100372956645104

Epoch: 6| Step: 6
Training loss: 1.5281578302383423
Validation loss: 2.1137576051937637

Epoch: 6| Step: 7
Training loss: 1.4964905977249146
Validation loss: 2.107160101654709

Epoch: 6| Step: 8
Training loss: 1.3140366077423096
Validation loss: 2.0759734287056872

Epoch: 6| Step: 9
Training loss: 1.3615505695343018
Validation loss: 2.0770428719059115

Epoch: 6| Step: 10
Training loss: 1.6677062511444092
Validation loss: 2.0728822395365727

Epoch: 6| Step: 11
Training loss: 0.952106773853302
Validation loss: 2.09116538365682

Epoch: 6| Step: 12
Training loss: 0.8811497688293457
Validation loss: 2.0736534031488563

Epoch: 6| Step: 13
Training loss: 2.110062837600708
Validation loss: 2.051652608379241

Epoch: 442| Step: 0
Training loss: 1.4774925708770752
Validation loss: 2.0141274570136942

Epoch: 6| Step: 1
Training loss: 1.6767408847808838
Validation loss: 2.0412197382219377

Epoch: 6| Step: 2
Training loss: 1.2233264446258545
Validation loss: 2.0137464102878364

Epoch: 6| Step: 3
Training loss: 1.4305684566497803
Validation loss: 2.0214824753422893

Epoch: 6| Step: 4
Training loss: 1.3417885303497314
Validation loss: 2.025352895900767

Epoch: 6| Step: 5
Training loss: 1.7899994850158691
Validation loss: 2.0425647253631265

Epoch: 6| Step: 6
Training loss: 1.9662070274353027
Validation loss: 2.0404992770123225

Epoch: 6| Step: 7
Training loss: 1.0919139385223389
Validation loss: 2.0596010223511727

Epoch: 6| Step: 8
Training loss: 1.0895013809204102
Validation loss: 2.0556749066998883

Epoch: 6| Step: 9
Training loss: 1.1674233675003052
Validation loss: 2.050175351481284

Epoch: 6| Step: 10
Training loss: 1.5288138389587402
Validation loss: 2.094758379843927

Epoch: 6| Step: 11
Training loss: 1.7837319374084473
Validation loss: 2.064359123988818

Epoch: 6| Step: 12
Training loss: 1.6986583471298218
Validation loss: 2.074131283708798

Epoch: 6| Step: 13
Training loss: 1.436321496963501
Validation loss: 2.0830735775732223

Epoch: 443| Step: 0
Training loss: 1.413114309310913
Validation loss: 2.085045858096051

Epoch: 6| Step: 1
Training loss: 2.1835122108459473
Validation loss: 2.088465508594308

Epoch: 6| Step: 2
Training loss: 1.1444082260131836
Validation loss: 2.0510736716690885

Epoch: 6| Step: 3
Training loss: 0.9175623655319214
Validation loss: 2.0702857509736092

Epoch: 6| Step: 4
Training loss: 1.7291674613952637
Validation loss: 2.0526841686617945

Epoch: 6| Step: 5
Training loss: 1.7160756587982178
Validation loss: 2.0406172365270634

Epoch: 6| Step: 6
Training loss: 1.215382695198059
Validation loss: 2.06803810468284

Epoch: 6| Step: 7
Training loss: 1.911346435546875
Validation loss: 2.0427586468317176

Epoch: 6| Step: 8
Training loss: 1.2233922481536865
Validation loss: 2.0288081476765294

Epoch: 6| Step: 9
Training loss: 1.3133089542388916
Validation loss: 2.055434557699388

Epoch: 6| Step: 10
Training loss: 1.3895745277404785
Validation loss: 2.052092047147853

Epoch: 6| Step: 11
Training loss: 0.702795147895813
Validation loss: 2.075844087908345

Epoch: 6| Step: 12
Training loss: 1.7549726963043213
Validation loss: 2.0575392579519622

Epoch: 6| Step: 13
Training loss: 2.2210428714752197
Validation loss: 2.0998665927558817

Epoch: 444| Step: 0
Training loss: 1.1818764209747314
Validation loss: 2.0627224368433796

Epoch: 6| Step: 1
Training loss: 1.0830209255218506
Validation loss: 2.11862878389256

Epoch: 6| Step: 2
Training loss: 0.9567854404449463
Validation loss: 2.0878369910742647

Epoch: 6| Step: 3
Training loss: 1.7709906101226807
Validation loss: 2.102990481161302

Epoch: 6| Step: 4
Training loss: 1.397895336151123
Validation loss: 2.099353390355264

Epoch: 6| Step: 5
Training loss: 2.4092307090759277
Validation loss: 2.148772419139903

Epoch: 6| Step: 6
Training loss: 1.339139461517334
Validation loss: 2.113310226830103

Epoch: 6| Step: 7
Training loss: 0.5562857985496521
Validation loss: 2.0962838408767537

Epoch: 6| Step: 8
Training loss: 1.8851062059402466
Validation loss: 2.1067522161750385

Epoch: 6| Step: 9
Training loss: 1.5067789554595947
Validation loss: 2.076336955511442

Epoch: 6| Step: 10
Training loss: 1.7090198993682861
Validation loss: 2.074450046785416

Epoch: 6| Step: 11
Training loss: 0.9235910177230835
Validation loss: 2.004684503360461

Epoch: 6| Step: 12
Training loss: 1.8163443803787231
Validation loss: 2.048373355660387

Epoch: 6| Step: 13
Training loss: 2.7506344318389893
Validation loss: 2.0359990007133892

Epoch: 445| Step: 0
Training loss: 1.2683932781219482
Validation loss: 2.0235468905459166

Epoch: 6| Step: 1
Training loss: 1.6857800483703613
Validation loss: 1.967777616234236

Epoch: 6| Step: 2
Training loss: 1.5825343132019043
Validation loss: 2.0411538898303943

Epoch: 6| Step: 3
Training loss: 1.59515380859375
Validation loss: 2.0200802254420456

Epoch: 6| Step: 4
Training loss: 1.0975340604782104
Validation loss: 2.0364455792211715

Epoch: 6| Step: 5
Training loss: 1.3004324436187744
Validation loss: 2.0353521377809587

Epoch: 6| Step: 6
Training loss: 1.6647751331329346
Validation loss: 2.047881399431536

Epoch: 6| Step: 7
Training loss: 1.5905834436416626
Validation loss: 2.0726595437654884

Epoch: 6| Step: 8
Training loss: 1.7311923503875732
Validation loss: 2.0648057922240226

Epoch: 6| Step: 9
Training loss: 1.4520784616470337
Validation loss: 2.073614042292359

Epoch: 6| Step: 10
Training loss: 0.9070078730583191
Validation loss: 2.0666570971089024

Epoch: 6| Step: 11
Training loss: 0.8395915031433105
Validation loss: 2.0899282219589397

Epoch: 6| Step: 12
Training loss: 1.6729228496551514
Validation loss: 2.0815752834402104

Epoch: 6| Step: 13
Training loss: 2.4008078575134277
Validation loss: 2.1156470160330496

Epoch: 446| Step: 0
Training loss: 1.3576291799545288
Validation loss: 2.0719114401007213

Epoch: 6| Step: 1
Training loss: 1.6087489128112793
Validation loss: 2.1111505313586165

Epoch: 6| Step: 2
Training loss: 1.8276700973510742
Validation loss: 2.0900266631957023

Epoch: 6| Step: 3
Training loss: 1.4966259002685547
Validation loss: 2.0747965663991947

Epoch: 6| Step: 4
Training loss: 1.7541046142578125
Validation loss: 2.030015307088052

Epoch: 6| Step: 5
Training loss: 1.506072759628296
Validation loss: 2.050508254317827

Epoch: 6| Step: 6
Training loss: 1.4384595155715942
Validation loss: 2.091553521412675

Epoch: 6| Step: 7
Training loss: 1.7264378070831299
Validation loss: 2.0555216317535727

Epoch: 6| Step: 8
Training loss: 0.9508354663848877
Validation loss: 2.05939055514592

Epoch: 6| Step: 9
Training loss: 1.016153335571289
Validation loss: 2.0837856364506546

Epoch: 6| Step: 10
Training loss: 1.4252341985702515
Validation loss: 2.0704852073423323

Epoch: 6| Step: 11
Training loss: 1.2215547561645508
Validation loss: 2.0823261481459423

Epoch: 6| Step: 12
Training loss: 1.4652814865112305
Validation loss: 2.0739575073283207

Epoch: 6| Step: 13
Training loss: 1.6125199794769287
Validation loss: 2.0724366044485443

Epoch: 447| Step: 0
Training loss: 1.2934240102767944
Validation loss: 2.0699224010590584

Epoch: 6| Step: 1
Training loss: 1.8002829551696777
Validation loss: 2.075061350740412

Epoch: 6| Step: 2
Training loss: 0.883929967880249
Validation loss: 2.095029524577561

Epoch: 6| Step: 3
Training loss: 1.5249412059783936
Validation loss: 2.0384041981030534

Epoch: 6| Step: 4
Training loss: 1.1256707906723022
Validation loss: 2.042145224027736

Epoch: 6| Step: 5
Training loss: 1.2465146780014038
Validation loss: 2.0526516681076377

Epoch: 6| Step: 6
Training loss: 1.5193644762039185
Validation loss: 2.081969436778817

Epoch: 6| Step: 7
Training loss: 1.5007272958755493
Validation loss: 2.043933863280922

Epoch: 6| Step: 8
Training loss: 1.8762811422348022
Validation loss: 2.0917364589629637

Epoch: 6| Step: 9
Training loss: 2.2139649391174316
Validation loss: 2.063428222492177

Epoch: 6| Step: 10
Training loss: 1.9975368976593018
Validation loss: 2.0666293021171325

Epoch: 6| Step: 11
Training loss: 1.4016671180725098
Validation loss: 2.088796459218507

Epoch: 6| Step: 12
Training loss: 0.8247954249382019
Validation loss: 2.0622202452792915

Epoch: 6| Step: 13
Training loss: 1.102734923362732
Validation loss: 2.0042127652834822

Epoch: 448| Step: 0
Training loss: 1.6394447088241577
Validation loss: 2.0298469297347532

Epoch: 6| Step: 1
Training loss: 1.403655767440796
Validation loss: 2.0579196458221762

Epoch: 6| Step: 2
Training loss: 1.9470601081848145
Validation loss: 2.0045675462292087

Epoch: 6| Step: 3
Training loss: 1.2980337142944336
Validation loss: 2.0347396635240123

Epoch: 6| Step: 4
Training loss: 1.683136224746704
Validation loss: 2.035746612856465

Epoch: 6| Step: 5
Training loss: 0.5299888253211975
Validation loss: 2.069756786028544

Epoch: 6| Step: 6
Training loss: 1.6503760814666748
Validation loss: 2.0427048719057472

Epoch: 6| Step: 7
Training loss: 1.5787649154663086
Validation loss: 2.051078568222702

Epoch: 6| Step: 8
Training loss: 1.6453030109405518
Validation loss: 2.0598296837140153

Epoch: 6| Step: 9
Training loss: 1.8922557830810547
Validation loss: 2.0622561029208604

Epoch: 6| Step: 10
Training loss: 1.0523300170898438
Validation loss: 2.0518773960810837

Epoch: 6| Step: 11
Training loss: 1.3989636898040771
Validation loss: 2.0812386825520504

Epoch: 6| Step: 12
Training loss: 1.148193597793579
Validation loss: 2.0892571403134252

Epoch: 6| Step: 13
Training loss: 1.148460865020752
Validation loss: 2.00134737132698

Epoch: 449| Step: 0
Training loss: 1.8611851930618286
Validation loss: 2.039740723948325

Epoch: 6| Step: 1
Training loss: 1.0059418678283691
Validation loss: 2.0400906352586645

Epoch: 6| Step: 2
Training loss: 1.5976557731628418
Validation loss: 2.012776788844857

Epoch: 6| Step: 3
Training loss: 2.041172742843628
Validation loss: 2.0136830960550616

Epoch: 6| Step: 4
Training loss: 1.9681267738342285
Validation loss: 2.0434691957248154

Epoch: 6| Step: 5
Training loss: 1.2131152153015137
Validation loss: 2.0408540682126115

Epoch: 6| Step: 6
Training loss: 0.9610388875007629
Validation loss: 2.030221485322522

Epoch: 6| Step: 7
Training loss: 1.6458958387374878
Validation loss: 2.0369941880626063

Epoch: 6| Step: 8
Training loss: 0.4928855299949646
Validation loss: 2.051365357573314

Epoch: 6| Step: 9
Training loss: 1.3268890380859375
Validation loss: 2.035764096885599

Epoch: 6| Step: 10
Training loss: 2.108701705932617
Validation loss: 2.047838326423399

Epoch: 6| Step: 11
Training loss: 1.0558443069458008
Validation loss: 2.079505317954607

Epoch: 6| Step: 12
Training loss: 1.4657503366470337
Validation loss: 2.0251693905040784

Epoch: 6| Step: 13
Training loss: 0.7757761478424072
Validation loss: 2.05413955385967

Epoch: 450| Step: 0
Training loss: 1.8181465864181519
Validation loss: 2.1027825263238724

Epoch: 6| Step: 1
Training loss: 1.8603668212890625
Validation loss: 2.1321037007916357

Epoch: 6| Step: 2
Training loss: 0.8178007006645203
Validation loss: 2.0985538562138877

Epoch: 6| Step: 3
Training loss: 1.6520144939422607
Validation loss: 2.103085656319895

Epoch: 6| Step: 4
Training loss: 1.501152515411377
Validation loss: 2.1369632315892044

Epoch: 6| Step: 5
Training loss: 1.1542571783065796
Validation loss: 2.07546813513643

Epoch: 6| Step: 6
Training loss: 1.5048635005950928
Validation loss: 2.0810332426460842

Epoch: 6| Step: 7
Training loss: 0.8305168747901917
Validation loss: 2.085486142866073

Epoch: 6| Step: 8
Training loss: 1.4922797679901123
Validation loss: 2.116762034354671

Epoch: 6| Step: 9
Training loss: 1.4111251831054688
Validation loss: 2.0622047634534937

Epoch: 6| Step: 10
Training loss: 1.4933662414550781
Validation loss: 2.061812416199715

Epoch: 6| Step: 11
Training loss: 1.3236157894134521
Validation loss: 2.055704721840479

Epoch: 6| Step: 12
Training loss: 1.6594356298446655
Validation loss: 2.0715318302954397

Epoch: 6| Step: 13
Training loss: 1.4939525127410889
Validation loss: 2.079357470235517

Epoch: 451| Step: 0
Training loss: 1.447036862373352
Validation loss: 2.0503985304986276

Epoch: 6| Step: 1
Training loss: 1.788786768913269
Validation loss: 2.062054587948707

Epoch: 6| Step: 2
Training loss: 1.294450283050537
Validation loss: 2.057540894836508

Epoch: 6| Step: 3
Training loss: 1.3357582092285156
Validation loss: 2.023748618300243

Epoch: 6| Step: 4
Training loss: 1.563895583152771
Validation loss: 2.0261276191280735

Epoch: 6| Step: 5
Training loss: 1.180454969406128
Validation loss: 2.0153448453513523

Epoch: 6| Step: 6
Training loss: 1.473954200744629
Validation loss: 2.0511692544465423

Epoch: 6| Step: 7
Training loss: 1.5034823417663574
Validation loss: 2.059609918184178

Epoch: 6| Step: 8
Training loss: 1.307133436203003
Validation loss: 2.0593486832034205

Epoch: 6| Step: 9
Training loss: 1.727487325668335
Validation loss: 2.042121592388358

Epoch: 6| Step: 10
Training loss: 2.031606674194336
Validation loss: 2.052347931810605

Epoch: 6| Step: 11
Training loss: 1.7015371322631836
Validation loss: 2.0955084241846555

Epoch: 6| Step: 12
Training loss: 1.3386887311935425
Validation loss: 2.045867927612797

Epoch: 6| Step: 13
Training loss: 0.5822290778160095
Validation loss: 2.0782138839844735

Epoch: 452| Step: 0
Training loss: 1.0396192073822021
Validation loss: 2.099950369968209

Epoch: 6| Step: 1
Training loss: 1.516444444656372
Validation loss: 2.0545796655839488

Epoch: 6| Step: 2
Training loss: 1.431870460510254
Validation loss: 2.0851314067840576

Epoch: 6| Step: 3
Training loss: 1.6990689039230347
Validation loss: 2.045832085353072

Epoch: 6| Step: 4
Training loss: 1.7708261013031006
Validation loss: 2.0786774812206144

Epoch: 6| Step: 5
Training loss: 1.121503472328186
Validation loss: 2.064490314452879

Epoch: 6| Step: 6
Training loss: 1.1685359477996826
Validation loss: 2.0519417716610815

Epoch: 6| Step: 7
Training loss: 1.3928751945495605
Validation loss: 2.045244986011136

Epoch: 6| Step: 8
Training loss: 1.791780948638916
Validation loss: 2.029827804975612

Epoch: 6| Step: 9
Training loss: 1.5371997356414795
Validation loss: 2.0326980877948064

Epoch: 6| Step: 10
Training loss: 1.053433895111084
Validation loss: 2.093378306717001

Epoch: 6| Step: 11
Training loss: 1.1330336332321167
Validation loss: 2.061772205496347

Epoch: 6| Step: 12
Training loss: 1.9320523738861084
Validation loss: 2.0576441018812117

Epoch: 6| Step: 13
Training loss: 1.4017349481582642
Validation loss: 2.0391926611623457

Epoch: 453| Step: 0
Training loss: 1.6325410604476929
Validation loss: 2.049241256970231

Epoch: 6| Step: 1
Training loss: 1.1881332397460938
Validation loss: 2.0596558970789753

Epoch: 6| Step: 2
Training loss: 0.996497631072998
Validation loss: 2.0344823214315597

Epoch: 6| Step: 3
Training loss: 1.6974129676818848
Validation loss: 2.0216391214760403

Epoch: 6| Step: 4
Training loss: 0.7694401741027832
Validation loss: 2.039397193539527

Epoch: 6| Step: 5
Training loss: 1.6995865106582642
Validation loss: 2.0310572706243044

Epoch: 6| Step: 6
Training loss: 1.6885578632354736
Validation loss: 2.0524983047157206

Epoch: 6| Step: 7
Training loss: 1.2581545114517212
Validation loss: 2.0329186377986783

Epoch: 6| Step: 8
Training loss: 1.7506651878356934
Validation loss: 2.027395009994507

Epoch: 6| Step: 9
Training loss: 1.0251878499984741
Validation loss: 2.0554542618413127

Epoch: 6| Step: 10
Training loss: 1.60242760181427
Validation loss: 2.06575487249641

Epoch: 6| Step: 11
Training loss: 1.6221133470535278
Validation loss: 2.104247300855575

Epoch: 6| Step: 12
Training loss: 1.5891305208206177
Validation loss: 2.116101716154365

Epoch: 6| Step: 13
Training loss: 1.2028065919876099
Validation loss: 2.1081509308148454

Epoch: 454| Step: 0
Training loss: 1.407283902168274
Validation loss: 2.13507556018009

Epoch: 6| Step: 1
Training loss: 1.1561074256896973
Validation loss: 2.1170029165924236

Epoch: 6| Step: 2
Training loss: 1.3598382472991943
Validation loss: 2.1483226655631937

Epoch: 6| Step: 3
Training loss: 1.4203652143478394
Validation loss: 2.120480029813705

Epoch: 6| Step: 4
Training loss: 1.545528531074524
Validation loss: 2.066772445555656

Epoch: 6| Step: 5
Training loss: 1.397111415863037
Validation loss: 2.107224202925159

Epoch: 6| Step: 6
Training loss: 1.7395437955856323
Validation loss: 2.0927841868451846

Epoch: 6| Step: 7
Training loss: 1.4151935577392578
Validation loss: 2.0474726948686826

Epoch: 6| Step: 8
Training loss: 1.4338650703430176
Validation loss: 2.0475631708739908

Epoch: 6| Step: 9
Training loss: 1.441243052482605
Validation loss: 2.07560674477649

Epoch: 6| Step: 10
Training loss: 0.8465465307235718
Validation loss: 2.0269054981970016

Epoch: 6| Step: 11
Training loss: 1.7214561700820923
Validation loss: 2.0256133271801855

Epoch: 6| Step: 12
Training loss: 1.6516344547271729
Validation loss: 2.036574955909483

Epoch: 6| Step: 13
Training loss: 1.5475733280181885
Validation loss: 2.0509197173580045

Epoch: 455| Step: 0
Training loss: 1.7802997827529907
Validation loss: 2.047298600596766

Epoch: 6| Step: 1
Training loss: 1.1288753747940063
Validation loss: 2.062825566978865

Epoch: 6| Step: 2
Training loss: 2.209557294845581
Validation loss: 2.079212916794644

Epoch: 6| Step: 3
Training loss: 1.2377500534057617
Validation loss: 2.0040245081788752

Epoch: 6| Step: 4
Training loss: 1.7726695537567139
Validation loss: 2.0936858013112056

Epoch: 6| Step: 5
Training loss: 1.4707509279251099
Validation loss: 2.0330793626846804

Epoch: 6| Step: 6
Training loss: 1.050606369972229
Validation loss: 2.082856837139335

Epoch: 6| Step: 7
Training loss: 1.2977092266082764
Validation loss: 2.030097479461342

Epoch: 6| Step: 8
Training loss: 1.2681188583374023
Validation loss: 2.036733756783188

Epoch: 6| Step: 9
Training loss: 1.3169934749603271
Validation loss: 2.0402595625128797

Epoch: 6| Step: 10
Training loss: 1.8173139095306396
Validation loss: 2.078103606418897

Epoch: 6| Step: 11
Training loss: 2.0142953395843506
Validation loss: 2.0604194723149782

Epoch: 6| Step: 12
Training loss: 0.7571884989738464
Validation loss: 2.0702247158173592

Epoch: 6| Step: 13
Training loss: 0.7247374057769775
Validation loss: 2.055091663073468

Epoch: 456| Step: 0
Training loss: 1.4521574974060059
Validation loss: 2.0247491892947944

Epoch: 6| Step: 1
Training loss: 1.933150291442871
Validation loss: 2.060272712861338

Epoch: 6| Step: 2
Training loss: 2.0694220066070557
Validation loss: 2.0557544180141982

Epoch: 6| Step: 3
Training loss: 1.3559300899505615
Validation loss: 2.012127484044721

Epoch: 6| Step: 4
Training loss: 1.337886929512024
Validation loss: 2.002068124791627

Epoch: 6| Step: 5
Training loss: 1.1428091526031494
Validation loss: 2.059648738112501

Epoch: 6| Step: 6
Training loss: 1.3472723960876465
Validation loss: 2.0598982700737576

Epoch: 6| Step: 7
Training loss: 0.785088062286377
Validation loss: 2.069788311117439

Epoch: 6| Step: 8
Training loss: 1.174431562423706
Validation loss: 2.051497108192854

Epoch: 6| Step: 9
Training loss: 1.6119638681411743
Validation loss: 2.0706392565081195

Epoch: 6| Step: 10
Training loss: 1.342091679573059
Validation loss: 2.052190698603148

Epoch: 6| Step: 11
Training loss: 1.6458015441894531
Validation loss: 2.058603548234509

Epoch: 6| Step: 12
Training loss: 1.631373643875122
Validation loss: 2.0496688837646158

Epoch: 6| Step: 13
Training loss: 1.106765866279602
Validation loss: 2.055620185790523

Epoch: 457| Step: 0
Training loss: 0.9729931950569153
Validation loss: 2.0946968011958624

Epoch: 6| Step: 1
Training loss: 1.648329496383667
Validation loss: 2.0405744967922086

Epoch: 6| Step: 2
Training loss: 1.3095498085021973
Validation loss: 2.0461667571016537

Epoch: 6| Step: 3
Training loss: 1.839863896369934
Validation loss: 2.009271514031195

Epoch: 6| Step: 4
Training loss: 1.1982364654541016
Validation loss: 2.036836358808702

Epoch: 6| Step: 5
Training loss: 1.5149813890457153
Validation loss: 2.0318776792095554

Epoch: 6| Step: 6
Training loss: 1.3387384414672852
Validation loss: 2.055761315489328

Epoch: 6| Step: 7
Training loss: 2.1127963066101074
Validation loss: 2.0367797510598296

Epoch: 6| Step: 8
Training loss: 1.2421197891235352
Validation loss: 2.0241153240203857

Epoch: 6| Step: 9
Training loss: 1.5853514671325684
Validation loss: 2.0344146964370564

Epoch: 6| Step: 10
Training loss: 1.4700044393539429
Validation loss: 2.043903173938874

Epoch: 6| Step: 11
Training loss: 1.6344037055969238
Validation loss: 2.066230297088623

Epoch: 6| Step: 12
Training loss: 1.1077216863632202
Validation loss: 2.035861333211263

Epoch: 6| Step: 13
Training loss: 0.8164236545562744
Validation loss: 2.04673667364223

Epoch: 458| Step: 0
Training loss: 1.1623623371124268
Validation loss: 2.060383681328066

Epoch: 6| Step: 1
Training loss: 0.8681285977363586
Validation loss: 2.108395681586317

Epoch: 6| Step: 2
Training loss: 0.909774661064148
Validation loss: 2.0810894222669702

Epoch: 6| Step: 3
Training loss: 1.6396310329437256
Validation loss: 2.0716024906404558

Epoch: 6| Step: 4
Training loss: 2.0337085723876953
Validation loss: 2.0530751815406223

Epoch: 6| Step: 5
Training loss: 2.037306308746338
Validation loss: 2.048698909821049

Epoch: 6| Step: 6
Training loss: 1.680640459060669
Validation loss: 2.0827475670845277

Epoch: 6| Step: 7
Training loss: 0.9063036441802979
Validation loss: 2.031518732347796

Epoch: 6| Step: 8
Training loss: 1.4419912099838257
Validation loss: 2.06644259729693

Epoch: 6| Step: 9
Training loss: 1.4530448913574219
Validation loss: 2.0727044754130866

Epoch: 6| Step: 10
Training loss: 1.0633554458618164
Validation loss: 2.0703300365837674

Epoch: 6| Step: 11
Training loss: 1.306182622909546
Validation loss: 2.096836014460492

Epoch: 6| Step: 12
Training loss: 2.2105026245117188
Validation loss: 2.0818273662238993

Epoch: 6| Step: 13
Training loss: 1.2272456884384155
Validation loss: 2.0769674265256493

Epoch: 459| Step: 0
Training loss: 1.2789394855499268
Validation loss: 2.0626747813276065

Epoch: 6| Step: 1
Training loss: 1.6156024932861328
Validation loss: 2.0645914436668478

Epoch: 6| Step: 2
Training loss: 1.8636077642440796
Validation loss: 2.0563067133708666

Epoch: 6| Step: 3
Training loss: 1.2261888980865479
Validation loss: 2.05754332388601

Epoch: 6| Step: 4
Training loss: 1.7702093124389648
Validation loss: 2.0508187355533725

Epoch: 6| Step: 5
Training loss: 1.1992675065994263
Validation loss: 2.042298650228849

Epoch: 6| Step: 6
Training loss: 1.1447757482528687
Validation loss: 2.0139066506457586

Epoch: 6| Step: 7
Training loss: 1.2285401821136475
Validation loss: 2.028952613953621

Epoch: 6| Step: 8
Training loss: 1.3450522422790527
Validation loss: 2.036268870035807

Epoch: 6| Step: 9
Training loss: 1.1880053281784058
Validation loss: 2.0788751084317445

Epoch: 6| Step: 10
Training loss: 1.8778460025787354
Validation loss: 2.105876567543194

Epoch: 6| Step: 11
Training loss: 0.7532906532287598
Validation loss: 2.143123707463664

Epoch: 6| Step: 12
Training loss: 2.0199668407440186
Validation loss: 2.119563055294816

Epoch: 6| Step: 13
Training loss: 1.0467023849487305
Validation loss: 2.0820997786778275

Epoch: 460| Step: 0
Training loss: 1.5512394905090332
Validation loss: 2.130898726883755

Epoch: 6| Step: 1
Training loss: 1.029937982559204
Validation loss: 2.139272368082436

Epoch: 6| Step: 2
Training loss: 1.2970539331436157
Validation loss: 2.133586920717711

Epoch: 6| Step: 3
Training loss: 1.4861513376235962
Validation loss: 2.1160341834509246

Epoch: 6| Step: 4
Training loss: 0.9556624293327332
Validation loss: 2.1065556054474204

Epoch: 6| Step: 5
Training loss: 1.4057128429412842
Validation loss: 2.088869201239719

Epoch: 6| Step: 6
Training loss: 1.7999796867370605
Validation loss: 2.0988226731618247

Epoch: 6| Step: 7
Training loss: 1.3307124376296997
Validation loss: 2.0706480574864212

Epoch: 6| Step: 8
Training loss: 1.6922383308410645
Validation loss: 2.0708100052290064

Epoch: 6| Step: 9
Training loss: 1.8478014469146729
Validation loss: 2.0419470622975338

Epoch: 6| Step: 10
Training loss: 1.2812931537628174
Validation loss: 2.0324220336893553

Epoch: 6| Step: 11
Training loss: 1.7304185628890991
Validation loss: 2.053927913788826

Epoch: 6| Step: 12
Training loss: 1.4134187698364258
Validation loss: 2.04542120810478

Epoch: 6| Step: 13
Training loss: 0.71981281042099
Validation loss: 2.0419930053013626

Epoch: 461| Step: 0
Training loss: 0.9695293307304382
Validation loss: 2.0507218786465224

Epoch: 6| Step: 1
Training loss: 1.288756251335144
Validation loss: 2.05615464333565

Epoch: 6| Step: 2
Training loss: 0.9124605059623718
Validation loss: 2.030748822355783

Epoch: 6| Step: 3
Training loss: 1.4066076278686523
Validation loss: 2.0783597025820004

Epoch: 6| Step: 4
Training loss: 2.1573221683502197
Validation loss: 2.082405678687557

Epoch: 6| Step: 5
Training loss: 1.5459489822387695
Validation loss: 2.0780119408843336

Epoch: 6| Step: 6
Training loss: 1.4315547943115234
Validation loss: 2.084078791320965

Epoch: 6| Step: 7
Training loss: 1.2971136569976807
Validation loss: 2.0765784889139156

Epoch: 6| Step: 8
Training loss: 1.0861397981643677
Validation loss: 2.1300479186478483

Epoch: 6| Step: 9
Training loss: 2.190713405609131
Validation loss: 2.102273597512194

Epoch: 6| Step: 10
Training loss: 1.438812017440796
Validation loss: 2.048616043982967

Epoch: 6| Step: 11
Training loss: 1.40931236743927
Validation loss: 2.0786447448115193

Epoch: 6| Step: 12
Training loss: 1.3274487257003784
Validation loss: 2.0621363450122137

Epoch: 6| Step: 13
Training loss: 2.0013928413391113
Validation loss: 2.0477777898952527

Epoch: 462| Step: 0
Training loss: 1.2266498804092407
Validation loss: 2.0585816137252317

Epoch: 6| Step: 1
Training loss: 1.4123401641845703
Validation loss: 2.0618498197165867

Epoch: 6| Step: 2
Training loss: 1.7213424444198608
Validation loss: 2.00781887449244

Epoch: 6| Step: 3
Training loss: 0.9910777807235718
Validation loss: 2.0512820174617152

Epoch: 6| Step: 4
Training loss: 1.092466950416565
Validation loss: 2.037880825740035

Epoch: 6| Step: 5
Training loss: 2.1909804344177246
Validation loss: 2.0083961115088513

Epoch: 6| Step: 6
Training loss: 0.7988681793212891
Validation loss: 2.0010675204697477

Epoch: 6| Step: 7
Training loss: 1.2602027654647827
Validation loss: 2.050400359656221

Epoch: 6| Step: 8
Training loss: 1.549056053161621
Validation loss: 2.0311079179086993

Epoch: 6| Step: 9
Training loss: 1.7536964416503906
Validation loss: 2.0301350444875736

Epoch: 6| Step: 10
Training loss: 1.602310299873352
Validation loss: 2.066429004874281

Epoch: 6| Step: 11
Training loss: 1.662710189819336
Validation loss: 2.0810322146261893

Epoch: 6| Step: 12
Training loss: 1.4476697444915771
Validation loss: 2.0918275438329226

Epoch: 6| Step: 13
Training loss: 1.3498671054840088
Validation loss: 2.063221859675582

Epoch: 463| Step: 0
Training loss: 1.0285773277282715
Validation loss: 2.0770956008665022

Epoch: 6| Step: 1
Training loss: 1.5316369533538818
Validation loss: 2.099517624865296

Epoch: 6| Step: 2
Training loss: 1.5227365493774414
Validation loss: 2.067465300201088

Epoch: 6| Step: 3
Training loss: 1.321993350982666
Validation loss: 2.066173239420819

Epoch: 6| Step: 4
Training loss: 1.2117198705673218
Validation loss: 2.0939544516225017

Epoch: 6| Step: 5
Training loss: 1.0488977432250977
Validation loss: 2.072282079727419

Epoch: 6| Step: 6
Training loss: 2.280712842941284
Validation loss: 2.0412315296870407

Epoch: 6| Step: 7
Training loss: 1.3211033344268799
Validation loss: 2.0447516479799823

Epoch: 6| Step: 8
Training loss: 1.7791653871536255
Validation loss: 2.0398311345807967

Epoch: 6| Step: 9
Training loss: 0.8169410228729248
Validation loss: 2.0199746419024724

Epoch: 6| Step: 10
Training loss: 1.132849931716919
Validation loss: 2.0269545060332104

Epoch: 6| Step: 11
Training loss: 1.6907191276550293
Validation loss: 2.0413612716941425

Epoch: 6| Step: 12
Training loss: 2.0058319568634033
Validation loss: 2.0515787780925794

Epoch: 6| Step: 13
Training loss: 1.0864624977111816
Validation loss: 2.045783632545061

Epoch: 464| Step: 0
Training loss: 0.8277745246887207
Validation loss: 2.059060900442062

Epoch: 6| Step: 1
Training loss: 2.1647024154663086
Validation loss: 2.034516810089029

Epoch: 6| Step: 2
Training loss: 0.8971724510192871
Validation loss: 2.0862396147943314

Epoch: 6| Step: 3
Training loss: 1.2079249620437622
Validation loss: 2.0952168139078284

Epoch: 6| Step: 4
Training loss: 1.4851696491241455
Validation loss: 2.0739707549413047

Epoch: 6| Step: 5
Training loss: 1.4374498128890991
Validation loss: 2.081810361595564

Epoch: 6| Step: 6
Training loss: 1.108007550239563
Validation loss: 2.0710528025063137

Epoch: 6| Step: 7
Training loss: 1.7790499925613403
Validation loss: 2.0696922297118814

Epoch: 6| Step: 8
Training loss: 1.4526939392089844
Validation loss: 2.0742932083786174

Epoch: 6| Step: 9
Training loss: 1.5788280963897705
Validation loss: 2.05957136231084

Epoch: 6| Step: 10
Training loss: 1.1253116130828857
Validation loss: 2.0853815360735823

Epoch: 6| Step: 11
Training loss: 1.4811429977416992
Validation loss: 2.0498462697511077

Epoch: 6| Step: 12
Training loss: 1.7734317779541016
Validation loss: 2.059319491027504

Epoch: 6| Step: 13
Training loss: 1.7380139827728271
Validation loss: 1.992318763527819

Epoch: 465| Step: 0
Training loss: 1.2630479335784912
Validation loss: 2.050493480056845

Epoch: 6| Step: 1
Training loss: 1.8785885572433472
Validation loss: 2.0245481908962293

Epoch: 6| Step: 2
Training loss: 2.026907444000244
Validation loss: 2.0277419179998417

Epoch: 6| Step: 3
Training loss: 1.2288711071014404
Validation loss: 2.054759810047765

Epoch: 6| Step: 4
Training loss: 1.3569968938827515
Validation loss: 2.0222702013548983

Epoch: 6| Step: 5
Training loss: 1.7006758451461792
Validation loss: 2.0142764019709762

Epoch: 6| Step: 6
Training loss: 1.3149514198303223
Validation loss: 2.025894667512627

Epoch: 6| Step: 7
Training loss: 1.2189587354660034
Validation loss: 1.9954141750130603

Epoch: 6| Step: 8
Training loss: 2.0665555000305176
Validation loss: 2.02650656366861

Epoch: 6| Step: 9
Training loss: 1.4008382558822632
Validation loss: 2.046463263932095

Epoch: 6| Step: 10
Training loss: 1.3344626426696777
Validation loss: 2.05359156926473

Epoch: 6| Step: 11
Training loss: 1.1334359645843506
Validation loss: 2.0320172822603615

Epoch: 6| Step: 12
Training loss: 0.5514172315597534
Validation loss: 2.087691516004583

Epoch: 6| Step: 13
Training loss: 1.1553469896316528
Validation loss: 2.0692333367563065

Epoch: 466| Step: 0
Training loss: 1.1189491748809814
Validation loss: 2.09216889514718

Epoch: 6| Step: 1
Training loss: 1.3208578824996948
Validation loss: 2.0887046219200216

Epoch: 6| Step: 2
Training loss: 2.154533863067627
Validation loss: 2.0899712116487565

Epoch: 6| Step: 3
Training loss: 2.2901272773742676
Validation loss: 2.1064781553001812

Epoch: 6| Step: 4
Training loss: 1.2178659439086914
Validation loss: 2.1181964656358123

Epoch: 6| Step: 5
Training loss: 1.235208511352539
Validation loss: 2.117014410675213

Epoch: 6| Step: 6
Training loss: 1.2385609149932861
Validation loss: 2.094686331287507

Epoch: 6| Step: 7
Training loss: 0.8367394208908081
Validation loss: 2.0941128705137517

Epoch: 6| Step: 8
Training loss: 1.2935845851898193
Validation loss: 2.106803350551154

Epoch: 6| Step: 9
Training loss: 1.1817282438278198
Validation loss: 2.0854684973275788

Epoch: 6| Step: 10
Training loss: 1.2135593891143799
Validation loss: 2.0504891898042414

Epoch: 6| Step: 11
Training loss: 2.182858943939209
Validation loss: 2.0453419428999706

Epoch: 6| Step: 12
Training loss: 1.212885856628418
Validation loss: 2.0444956030896915

Epoch: 6| Step: 13
Training loss: 0.9532943367958069
Validation loss: 1.9944221101781374

Epoch: 467| Step: 0
Training loss: 1.5030597448349
Validation loss: 2.0555671543203373

Epoch: 6| Step: 1
Training loss: 1.7904268503189087
Validation loss: 2.0365054966301046

Epoch: 6| Step: 2
Training loss: 1.5855541229248047
Validation loss: 2.043986007731448

Epoch: 6| Step: 3
Training loss: 1.7309082746505737
Validation loss: 2.0657734063363846

Epoch: 6| Step: 4
Training loss: 1.02387535572052
Validation loss: 2.0283168297941967

Epoch: 6| Step: 5
Training loss: 1.3458290100097656
Validation loss: 2.0412810156422276

Epoch: 6| Step: 6
Training loss: 1.4612455368041992
Validation loss: 2.0276909951240785

Epoch: 6| Step: 7
Training loss: 1.384262204170227
Validation loss: 2.030357858186127

Epoch: 6| Step: 8
Training loss: 1.1488046646118164
Validation loss: 2.0636509772269958

Epoch: 6| Step: 9
Training loss: 1.622138500213623
Validation loss: 2.0620055839579594

Epoch: 6| Step: 10
Training loss: 0.877285361289978
Validation loss: 2.069834073384603

Epoch: 6| Step: 11
Training loss: 1.3838858604431152
Validation loss: 2.047790279952429

Epoch: 6| Step: 12
Training loss: 1.2696195840835571
Validation loss: 2.05195253638811

Epoch: 6| Step: 13
Training loss: 1.6693460941314697
Validation loss: 2.0465943749232958

Epoch: 468| Step: 0
Training loss: 1.6654105186462402
Validation loss: 2.0923096518362723

Epoch: 6| Step: 1
Training loss: 1.5944914817810059
Validation loss: 2.0658162973260366

Epoch: 6| Step: 2
Training loss: 1.3103175163269043
Validation loss: 2.0417012476151988

Epoch: 6| Step: 3
Training loss: 1.358947515487671
Validation loss: 2.0291240663938623

Epoch: 6| Step: 4
Training loss: 1.3901646137237549
Validation loss: 2.0224271461527836

Epoch: 6| Step: 5
Training loss: 1.6680333614349365
Validation loss: 2.033612387154692

Epoch: 6| Step: 6
Training loss: 1.4263806343078613
Validation loss: 2.0154502622542845

Epoch: 6| Step: 7
Training loss: 1.5033782720565796
Validation loss: 2.014325095761207

Epoch: 6| Step: 8
Training loss: 1.4875128269195557
Validation loss: 2.0613925239091277

Epoch: 6| Step: 9
Training loss: 0.7226148843765259
Validation loss: 2.026903901048886

Epoch: 6| Step: 10
Training loss: 1.8460538387298584
Validation loss: 2.051682919584295

Epoch: 6| Step: 11
Training loss: 1.1470211744308472
Validation loss: 2.077605708952873

Epoch: 6| Step: 12
Training loss: 1.332633137702942
Validation loss: 2.0588851846674436

Epoch: 6| Step: 13
Training loss: 1.470346212387085
Validation loss: 2.0407245582149875

Epoch: 469| Step: 0
Training loss: 1.700990915298462
Validation loss: 2.049304744248749

Epoch: 6| Step: 1
Training loss: 1.7278430461883545
Validation loss: 2.059358009728052

Epoch: 6| Step: 2
Training loss: 1.5412650108337402
Validation loss: 2.073549965376495

Epoch: 6| Step: 3
Training loss: 1.3896970748901367
Validation loss: 2.019518575360698

Epoch: 6| Step: 4
Training loss: 1.3134486675262451
Validation loss: 2.051312518376176

Epoch: 6| Step: 5
Training loss: 1.6727330684661865
Validation loss: 2.043452911479499

Epoch: 6| Step: 6
Training loss: 1.4907050132751465
Validation loss: 2.0353705652298464

Epoch: 6| Step: 7
Training loss: 1.5228369235992432
Validation loss: 2.0204448546132734

Epoch: 6| Step: 8
Training loss: 0.9609971642494202
Validation loss: 2.0500300827846734

Epoch: 6| Step: 9
Training loss: 1.0342395305633545
Validation loss: 2.0617678703800326

Epoch: 6| Step: 10
Training loss: 1.0693542957305908
Validation loss: 2.0567572475761495

Epoch: 6| Step: 11
Training loss: 1.7144722938537598
Validation loss: 2.051844161043885

Epoch: 6| Step: 12
Training loss: 0.8928713202476501
Validation loss: 2.0670232465190272

Epoch: 6| Step: 13
Training loss: 1.689653992652893
Validation loss: 2.04943258787996

Epoch: 470| Step: 0
Training loss: 0.6552821397781372
Validation loss: 2.041840604556504

Epoch: 6| Step: 1
Training loss: 1.5878002643585205
Validation loss: 2.0559334754943848

Epoch: 6| Step: 2
Training loss: 1.2095290422439575
Validation loss: 2.0389854395261375

Epoch: 6| Step: 3
Training loss: 1.273895263671875
Validation loss: 2.0923529465993247

Epoch: 6| Step: 4
Training loss: 2.407393455505371
Validation loss: 2.086309212510304

Epoch: 6| Step: 5
Training loss: 1.1300159692764282
Validation loss: 2.064615257324711

Epoch: 6| Step: 6
Training loss: 1.7252893447875977
Validation loss: 2.090202195670015

Epoch: 6| Step: 7
Training loss: 1.5209684371948242
Validation loss: 2.04687104686614

Epoch: 6| Step: 8
Training loss: 0.967888355255127
Validation loss: 2.07075192979587

Epoch: 6| Step: 9
Training loss: 1.8168394565582275
Validation loss: 2.0920694220450615

Epoch: 6| Step: 10
Training loss: 1.371201992034912
Validation loss: 2.070565116020941

Epoch: 6| Step: 11
Training loss: 1.608504056930542
Validation loss: 2.0970993785447973

Epoch: 6| Step: 12
Training loss: 1.2012676000595093
Validation loss: 2.097710012107767

Epoch: 6| Step: 13
Training loss: 1.3366271257400513
Validation loss: 2.0654199251564602

Epoch: 471| Step: 0
Training loss: 1.558661699295044
Validation loss: 2.0526456589339883

Epoch: 6| Step: 1
Training loss: 1.1550920009613037
Validation loss: 2.049102396093389

Epoch: 6| Step: 2
Training loss: 1.1953619718551636
Validation loss: 2.0216706145194268

Epoch: 6| Step: 3
Training loss: 2.0381553173065186
Validation loss: 2.074591700748731

Epoch: 6| Step: 4
Training loss: 1.1558971405029297
Validation loss: 2.043774538142707

Epoch: 6| Step: 5
Training loss: 1.3633718490600586
Validation loss: 2.018693512485873

Epoch: 6| Step: 6
Training loss: 0.9674742221832275
Validation loss: 2.0535938791049424

Epoch: 6| Step: 7
Training loss: 1.3229000568389893
Validation loss: 2.0565614674680974

Epoch: 6| Step: 8
Training loss: 1.7649637460708618
Validation loss: 2.0628718676105624

Epoch: 6| Step: 9
Training loss: 1.7801483869552612
Validation loss: 2.022799986664967

Epoch: 6| Step: 10
Training loss: 1.0994699001312256
Validation loss: 2.0217251982740176

Epoch: 6| Step: 11
Training loss: 1.6973578929901123
Validation loss: 2.0105898072642665

Epoch: 6| Step: 12
Training loss: 1.042149305343628
Validation loss: 2.0577892257321264

Epoch: 6| Step: 13
Training loss: 1.1589322090148926
Validation loss: 2.0384834261350733

Epoch: 472| Step: 0
Training loss: 1.3598687648773193
Validation loss: 2.037261883417765

Epoch: 6| Step: 1
Training loss: 1.3441489934921265
Validation loss: 2.050596337164602

Epoch: 6| Step: 2
Training loss: 1.3037939071655273
Validation loss: 2.0581814268583893

Epoch: 6| Step: 3
Training loss: 1.4820970296859741
Validation loss: 2.0787168805317213

Epoch: 6| Step: 4
Training loss: 1.3356359004974365
Validation loss: 2.0514758351028606

Epoch: 6| Step: 5
Training loss: 2.2567691802978516
Validation loss: 2.054396011496103

Epoch: 6| Step: 6
Training loss: 1.4417173862457275
Validation loss: 2.0696682199355094

Epoch: 6| Step: 7
Training loss: 1.3949501514434814
Validation loss: 2.0698573845689014

Epoch: 6| Step: 8
Training loss: 1.4336483478546143
Validation loss: 2.0613456259491625

Epoch: 6| Step: 9
Training loss: 1.2624869346618652
Validation loss: 2.0370402977030766

Epoch: 6| Step: 10
Training loss: 0.9605640172958374
Validation loss: 2.0426071997611754

Epoch: 6| Step: 11
Training loss: 1.6149758100509644
Validation loss: 2.0709275609703472

Epoch: 6| Step: 12
Training loss: 1.1820764541625977
Validation loss: 2.03500190857918

Epoch: 6| Step: 13
Training loss: 1.296396017074585
Validation loss: 2.0367840336215113

Epoch: 473| Step: 0
Training loss: 1.7380790710449219
Validation loss: 2.0462319825285222

Epoch: 6| Step: 1
Training loss: 1.7488130331039429
Validation loss: 2.0825061926277737

Epoch: 6| Step: 2
Training loss: 1.654560923576355
Validation loss: 2.101548602504115

Epoch: 6| Step: 3
Training loss: 1.3965017795562744
Validation loss: 2.059441351121472

Epoch: 6| Step: 4
Training loss: 0.8774266242980957
Validation loss: 2.100265477293281

Epoch: 6| Step: 5
Training loss: 1.6845453977584839
Validation loss: 2.0853152659631546

Epoch: 6| Step: 6
Training loss: 1.4381133317947388
Validation loss: 2.0736472555386123

Epoch: 6| Step: 7
Training loss: 1.1138771772384644
Validation loss: 2.0974184005491194

Epoch: 6| Step: 8
Training loss: 1.3379265069961548
Validation loss: 2.0745625495910645

Epoch: 6| Step: 9
Training loss: 1.5746597051620483
Validation loss: 2.0751224281967326

Epoch: 6| Step: 10
Training loss: 0.94185870885849
Validation loss: 2.1185510825085383

Epoch: 6| Step: 11
Training loss: 0.9493124485015869
Validation loss: 2.045027650812621

Epoch: 6| Step: 12
Training loss: 1.4122059345245361
Validation loss: 2.0209413100314397

Epoch: 6| Step: 13
Training loss: 2.128770112991333
Validation loss: 2.053023998455335

Epoch: 474| Step: 0
Training loss: 1.5763218402862549
Validation loss: 2.01826177489373

Epoch: 6| Step: 1
Training loss: 0.8671455383300781
Validation loss: 2.0399386485417685

Epoch: 6| Step: 2
Training loss: 1.3831307888031006
Validation loss: 1.9956383166774627

Epoch: 6| Step: 3
Training loss: 1.4253547191619873
Validation loss: 2.049053233156922

Epoch: 6| Step: 4
Training loss: 1.9399478435516357
Validation loss: 2.0434985763283184

Epoch: 6| Step: 5
Training loss: 1.1760013103485107
Validation loss: 2.0413327960557837

Epoch: 6| Step: 6
Training loss: 1.582714319229126
Validation loss: 2.0326695544745332

Epoch: 6| Step: 7
Training loss: 1.4387826919555664
Validation loss: 2.058182256196135

Epoch: 6| Step: 8
Training loss: 1.784479022026062
Validation loss: 2.0173572276228215

Epoch: 6| Step: 9
Training loss: 1.180257797241211
Validation loss: 2.086783233509269

Epoch: 6| Step: 10
Training loss: 1.1272506713867188
Validation loss: 2.099280265069777

Epoch: 6| Step: 11
Training loss: 1.2074506282806396
Validation loss: 2.0565861284091906

Epoch: 6| Step: 12
Training loss: 1.5227882862091064
Validation loss: 2.0702997779333465

Epoch: 6| Step: 13
Training loss: 1.7413889169692993
Validation loss: 2.0922025967669744

Epoch: 475| Step: 0
Training loss: 0.9386296272277832
Validation loss: 2.0656920966281684

Epoch: 6| Step: 1
Training loss: 1.5011831521987915
Validation loss: 2.0542185973095637

Epoch: 6| Step: 2
Training loss: 0.9433858394622803
Validation loss: 2.030383312573997

Epoch: 6| Step: 3
Training loss: 1.0592502355575562
Validation loss: 2.048228952192491

Epoch: 6| Step: 4
Training loss: 1.6386384963989258
Validation loss: 2.0794992152080742

Epoch: 6| Step: 5
Training loss: 1.5703144073486328
Validation loss: 2.0388357254766647

Epoch: 6| Step: 6
Training loss: 1.1387982368469238
Validation loss: 2.0611651789757515

Epoch: 6| Step: 7
Training loss: 2.047262668609619
Validation loss: 2.079603556663759

Epoch: 6| Step: 8
Training loss: 1.7011549472808838
Validation loss: 2.0913122623197493

Epoch: 6| Step: 9
Training loss: 1.4214978218078613
Validation loss: 2.0606809892962055

Epoch: 6| Step: 10
Training loss: 1.162039041519165
Validation loss: 2.0922437175627677

Epoch: 6| Step: 11
Training loss: 1.4021357297897339
Validation loss: 2.0923785496783514

Epoch: 6| Step: 12
Training loss: 1.7066006660461426
Validation loss: 2.116256183193576

Epoch: 6| Step: 13
Training loss: 1.5361294746398926
Validation loss: 2.058085149334323

Epoch: 476| Step: 0
Training loss: 1.6000417470932007
Validation loss: 2.090793800610368

Epoch: 6| Step: 1
Training loss: 1.7232898473739624
Validation loss: 2.0425562627853884

Epoch: 6| Step: 2
Training loss: 1.429526686668396
Validation loss: 2.08666556624956

Epoch: 6| Step: 3
Training loss: 1.4618067741394043
Validation loss: 2.0736105800956808

Epoch: 6| Step: 4
Training loss: 1.2408263683319092
Validation loss: 2.023128165993639

Epoch: 6| Step: 5
Training loss: 0.9116721749305725
Validation loss: 2.0534370996618785

Epoch: 6| Step: 6
Training loss: 0.6505235433578491
Validation loss: 2.0074603865223546

Epoch: 6| Step: 7
Training loss: 1.429170846939087
Validation loss: 2.0418545815252487

Epoch: 6| Step: 8
Training loss: 1.6380983591079712
Validation loss: 2.0656984083114134

Epoch: 6| Step: 9
Training loss: 1.8800410032272339
Validation loss: 2.0286345404963337

Epoch: 6| Step: 10
Training loss: 1.4512664079666138
Validation loss: 2.0306737179397256

Epoch: 6| Step: 11
Training loss: 1.2543622255325317
Validation loss: 2.045222746428623

Epoch: 6| Step: 12
Training loss: 1.0083043575286865
Validation loss: 2.0621457035823534

Epoch: 6| Step: 13
Training loss: 1.874126672744751
Validation loss: 2.0391031490859164

Epoch: 477| Step: 0
Training loss: 1.5231140851974487
Validation loss: 2.038762075926668

Epoch: 6| Step: 1
Training loss: 1.1109966039657593
Validation loss: 2.0509261828596874

Epoch: 6| Step: 2
Training loss: 1.6434880495071411
Validation loss: 2.044663361323777

Epoch: 6| Step: 3
Training loss: 1.4436883926391602
Validation loss: 2.0061695062985985

Epoch: 6| Step: 4
Training loss: 0.8591898083686829
Validation loss: 2.074982830273208

Epoch: 6| Step: 5
Training loss: 1.1620409488677979
Validation loss: 2.0498508202132357

Epoch: 6| Step: 6
Training loss: 1.3956769704818726
Validation loss: 2.0569962404107534

Epoch: 6| Step: 7
Training loss: 0.9847936630249023
Validation loss: 2.050797700881958

Epoch: 6| Step: 8
Training loss: 2.190434455871582
Validation loss: 2.0949418852406163

Epoch: 6| Step: 9
Training loss: 1.3850007057189941
Validation loss: 2.128414879563034

Epoch: 6| Step: 10
Training loss: 1.9927085638046265
Validation loss: 2.093979831664793

Epoch: 6| Step: 11
Training loss: 1.2545560598373413
Validation loss: 2.074037613407258

Epoch: 6| Step: 12
Training loss: 1.338912010192871
Validation loss: 2.090369075857183

Epoch: 6| Step: 13
Training loss: 1.5792171955108643
Validation loss: 2.1111399281409478

Epoch: 478| Step: 0
Training loss: 1.77479088306427
Validation loss: 2.0626183555972193

Epoch: 6| Step: 1
Training loss: 1.15235435962677
Validation loss: 2.0354469950481127

Epoch: 6| Step: 2
Training loss: 1.1806259155273438
Validation loss: 2.0596692844103743

Epoch: 6| Step: 3
Training loss: 1.6306952238082886
Validation loss: 2.011257916368464

Epoch: 6| Step: 4
Training loss: 1.0890871286392212
Validation loss: 2.021525042031401

Epoch: 6| Step: 5
Training loss: 1.419076919555664
Validation loss: 2.0214738025460193

Epoch: 6| Step: 6
Training loss: 1.7467080354690552
Validation loss: 2.0066665295631654

Epoch: 6| Step: 7
Training loss: 1.5103070735931396
Validation loss: 2.055788004270164

Epoch: 6| Step: 8
Training loss: 1.0103206634521484
Validation loss: 2.01564307238466

Epoch: 6| Step: 9
Training loss: 1.5798585414886475
Validation loss: 2.0525623290769515

Epoch: 6| Step: 10
Training loss: 1.3150426149368286
Validation loss: 2.0749849670676777

Epoch: 6| Step: 11
Training loss: 1.7260725498199463
Validation loss: 2.079609114636657

Epoch: 6| Step: 12
Training loss: 1.0162749290466309
Validation loss: 2.068900885120515

Epoch: 6| Step: 13
Training loss: 1.1814144849777222
Validation loss: 2.06638846089763

Epoch: 479| Step: 0
Training loss: 1.6017169952392578
Validation loss: 2.053991330567227

Epoch: 6| Step: 1
Training loss: 0.7298238277435303
Validation loss: 2.0859873705012824

Epoch: 6| Step: 2
Training loss: 1.7191665172576904
Validation loss: 2.0674042958085255

Epoch: 6| Step: 3
Training loss: 1.6760718822479248
Validation loss: 2.0505269753035678

Epoch: 6| Step: 4
Training loss: 1.3755719661712646
Validation loss: 2.098204198703971

Epoch: 6| Step: 5
Training loss: 1.6408541202545166
Validation loss: 2.097737871190553

Epoch: 6| Step: 6
Training loss: 1.2028930187225342
Validation loss: 2.074070248552548

Epoch: 6| Step: 7
Training loss: 1.5884417295455933
Validation loss: 2.0692833341578

Epoch: 6| Step: 8
Training loss: 0.7986363172531128
Validation loss: 2.0870879042533135

Epoch: 6| Step: 9
Training loss: 1.2442803382873535
Validation loss: 2.0790821095948577

Epoch: 6| Step: 10
Training loss: 2.036954402923584
Validation loss: 2.0628161943087013

Epoch: 6| Step: 11
Training loss: 1.4676144123077393
Validation loss: 2.0470276622362036

Epoch: 6| Step: 12
Training loss: 1.2821276187896729
Validation loss: 2.0119571967791487

Epoch: 6| Step: 13
Training loss: 1.2486860752105713
Validation loss: 2.0667031785493255

Epoch: 480| Step: 0
Training loss: 1.4912135601043701
Validation loss: 2.022298594956757

Epoch: 6| Step: 1
Training loss: 1.1281532049179077
Validation loss: 2.020133379966982

Epoch: 6| Step: 2
Training loss: 1.2758395671844482
Validation loss: 1.9948459671389671

Epoch: 6| Step: 3
Training loss: 1.847495436668396
Validation loss: 2.0560716582882788

Epoch: 6| Step: 4
Training loss: 1.1493433713912964
Validation loss: 2.0664337040275655

Epoch: 6| Step: 5
Training loss: 1.9172165393829346
Validation loss: 2.03970157459218

Epoch: 6| Step: 6
Training loss: 0.8055054545402527
Validation loss: 2.0826469877714753

Epoch: 6| Step: 7
Training loss: 1.9325751066207886
Validation loss: 2.0714293000518635

Epoch: 6| Step: 8
Training loss: 1.0491245985031128
Validation loss: 2.04194652136936

Epoch: 6| Step: 9
Training loss: 0.6749391555786133
Validation loss: 2.0310262941545054

Epoch: 6| Step: 10
Training loss: 1.2766649723052979
Validation loss: 2.041132870540824

Epoch: 6| Step: 11
Training loss: 1.7696882486343384
Validation loss: 2.005358821602278

Epoch: 6| Step: 12
Training loss: 2.0805017948150635
Validation loss: 2.068826319068991

Epoch: 6| Step: 13
Training loss: 0.7305791974067688
Validation loss: 2.085491071465195

Epoch: 481| Step: 0
Training loss: 1.3707891702651978
Validation loss: 2.077179612651948

Epoch: 6| Step: 1
Training loss: 1.3010327816009521
Validation loss: 2.0856768905475573

Epoch: 6| Step: 2
Training loss: 1.436187505722046
Validation loss: 2.0420843196171585

Epoch: 6| Step: 3
Training loss: 1.3518352508544922
Validation loss: 2.066333504133327

Epoch: 6| Step: 4
Training loss: 1.439474105834961
Validation loss: 2.0417133608172016

Epoch: 6| Step: 5
Training loss: 1.2144511938095093
Validation loss: 2.0882641525678736

Epoch: 6| Step: 6
Training loss: 1.619409441947937
Validation loss: 2.032689304761989

Epoch: 6| Step: 7
Training loss: 1.4729334115982056
Validation loss: 2.014541058130162

Epoch: 6| Step: 8
Training loss: 1.402451992034912
Validation loss: 2.078161895916026

Epoch: 6| Step: 9
Training loss: 1.33214271068573
Validation loss: 2.0987874756577196

Epoch: 6| Step: 10
Training loss: 1.11468505859375
Validation loss: 2.078708658936203

Epoch: 6| Step: 11
Training loss: 1.8385032415390015
Validation loss: 2.0339450246544293

Epoch: 6| Step: 12
Training loss: 1.2028262615203857
Validation loss: 2.085970078745196

Epoch: 6| Step: 13
Training loss: 1.117315411567688
Validation loss: 2.08153203738633

Epoch: 482| Step: 0
Training loss: 1.3117988109588623
Validation loss: 2.0462434304657804

Epoch: 6| Step: 1
Training loss: 1.7283177375793457
Validation loss: 2.093124848540111

Epoch: 6| Step: 2
Training loss: 1.990441083908081
Validation loss: 2.0984747845639466

Epoch: 6| Step: 3
Training loss: 1.775246262550354
Validation loss: 2.1067155509866695

Epoch: 6| Step: 4
Training loss: 1.5203683376312256
Validation loss: 2.1015734941728654

Epoch: 6| Step: 5
Training loss: 1.0372103452682495
Validation loss: 2.106188125507806

Epoch: 6| Step: 6
Training loss: 0.8225525617599487
Validation loss: 2.068445187742992

Epoch: 6| Step: 7
Training loss: 1.0803415775299072
Validation loss: 2.0755752645513064

Epoch: 6| Step: 8
Training loss: 0.9640966057777405
Validation loss: 2.0442848974658596

Epoch: 6| Step: 9
Training loss: 1.3173441886901855
Validation loss: 2.0433039588312947

Epoch: 6| Step: 10
Training loss: 1.4382188320159912
Validation loss: 2.0634549381912395

Epoch: 6| Step: 11
Training loss: 1.5454503297805786
Validation loss: 2.0386111005660026

Epoch: 6| Step: 12
Training loss: 1.5071676969528198
Validation loss: 2.0502993740061277

Epoch: 6| Step: 13
Training loss: 1.3230164051055908
Validation loss: 2.035981667939053

Epoch: 483| Step: 0
Training loss: 1.5497982501983643
Validation loss: 2.0254032534937703

Epoch: 6| Step: 1
Training loss: 1.837146520614624
Validation loss: 2.058732840322679

Epoch: 6| Step: 2
Training loss: 0.9627510905265808
Validation loss: 2.0550444959312357

Epoch: 6| Step: 3
Training loss: 1.4584975242614746
Validation loss: 2.0337373928357194

Epoch: 6| Step: 4
Training loss: 1.201072335243225
Validation loss: 2.0513184737133723

Epoch: 6| Step: 5
Training loss: 0.5175753831863403
Validation loss: 2.065901279449463

Epoch: 6| Step: 6
Training loss: 1.3683276176452637
Validation loss: 2.0225938161214194

Epoch: 6| Step: 7
Training loss: 1.2868469953536987
Validation loss: 2.0546437283997894

Epoch: 6| Step: 8
Training loss: 1.9231090545654297
Validation loss: 2.0602629517996185

Epoch: 6| Step: 9
Training loss: 1.1499297618865967
Validation loss: 2.0407283741940736

Epoch: 6| Step: 10
Training loss: 1.9935355186462402
Validation loss: 2.051729940599011

Epoch: 6| Step: 11
Training loss: 1.2848734855651855
Validation loss: 2.07852917076439

Epoch: 6| Step: 12
Training loss: 1.4801453351974487
Validation loss: 2.056984814264441

Epoch: 6| Step: 13
Training loss: 1.3600648641586304
Validation loss: 2.062289203366926

Epoch: 484| Step: 0
Training loss: 1.0837647914886475
Validation loss: 2.066324646754931

Epoch: 6| Step: 1
Training loss: 1.2679600715637207
Validation loss: 2.0873014388545865

Epoch: 6| Step: 2
Training loss: 1.3719708919525146
Validation loss: 2.0732677316152923

Epoch: 6| Step: 3
Training loss: 1.1171189546585083
Validation loss: 2.0885592827232937

Epoch: 6| Step: 4
Training loss: 1.503517746925354
Validation loss: 2.1314342150124173

Epoch: 6| Step: 5
Training loss: 1.8835113048553467
Validation loss: 2.108094523029943

Epoch: 6| Step: 6
Training loss: 1.4600677490234375
Validation loss: 2.126997552892213

Epoch: 6| Step: 7
Training loss: 1.28789222240448
Validation loss: 2.0997394784804313

Epoch: 6| Step: 8
Training loss: 1.8446507453918457
Validation loss: 2.120178440565704

Epoch: 6| Step: 9
Training loss: 0.6518076658248901
Validation loss: 2.0936928808048205

Epoch: 6| Step: 10
Training loss: 1.2074074745178223
Validation loss: 2.091130083607089

Epoch: 6| Step: 11
Training loss: 1.5842466354370117
Validation loss: 2.0565247048613844

Epoch: 6| Step: 12
Training loss: 1.6850478649139404
Validation loss: 2.0539675246002855

Epoch: 6| Step: 13
Training loss: 1.4063551425933838
Validation loss: 2.06986399363446

Epoch: 485| Step: 0
Training loss: 1.0778625011444092
Validation loss: 2.0880975595084568

Epoch: 6| Step: 1
Training loss: 0.7607032656669617
Validation loss: 2.027145738242775

Epoch: 6| Step: 2
Training loss: 1.4670640230178833
Validation loss: 2.040752549325266

Epoch: 6| Step: 3
Training loss: 1.5152456760406494
Validation loss: 2.045240948277135

Epoch: 6| Step: 4
Training loss: 1.388688087463379
Validation loss: 2.0368934626220376

Epoch: 6| Step: 5
Training loss: 0.9169634580612183
Validation loss: 2.0415995274820635

Epoch: 6| Step: 6
Training loss: 1.6308948993682861
Validation loss: 1.982375229558637

Epoch: 6| Step: 7
Training loss: 1.529372215270996
Validation loss: 2.016380807404877

Epoch: 6| Step: 8
Training loss: 0.7975932359695435
Validation loss: 2.0461963145963606

Epoch: 6| Step: 9
Training loss: 1.6247074604034424
Validation loss: 2.040010042088006

Epoch: 6| Step: 10
Training loss: 1.7936245203018188
Validation loss: 2.0762272675832114

Epoch: 6| Step: 11
Training loss: 2.0275869369506836
Validation loss: 2.084716986584407

Epoch: 6| Step: 12
Training loss: 1.8902413845062256
Validation loss: 2.102754541622695

Epoch: 6| Step: 13
Training loss: 0.7315996289253235
Validation loss: 2.1014671453865628

Epoch: 486| Step: 0
Training loss: 1.5490877628326416
Validation loss: 2.1142125014335877

Epoch: 6| Step: 1
Training loss: 1.571202278137207
Validation loss: 2.096552805234027

Epoch: 6| Step: 2
Training loss: 1.098344087600708
Validation loss: 2.102408832119357

Epoch: 6| Step: 3
Training loss: 0.5453000068664551
Validation loss: 2.040709895472373

Epoch: 6| Step: 4
Training loss: 1.5602481365203857
Validation loss: 2.06591675871162

Epoch: 6| Step: 5
Training loss: 1.3198963403701782
Validation loss: 2.0038859075115574

Epoch: 6| Step: 6
Training loss: 1.9446637630462646
Validation loss: 2.008505763546113

Epoch: 6| Step: 7
Training loss: 0.9794621467590332
Validation loss: 2.0066681767022736

Epoch: 6| Step: 8
Training loss: 1.117300033569336
Validation loss: 2.026587624703684

Epoch: 6| Step: 9
Training loss: 1.5083162784576416
Validation loss: 2.042522950838971

Epoch: 6| Step: 10
Training loss: 1.6976995468139648
Validation loss: 2.038640051759699

Epoch: 6| Step: 11
Training loss: 1.3587899208068848
Validation loss: 2.0403462789391957

Epoch: 6| Step: 12
Training loss: 1.7401440143585205
Validation loss: 2.044046107158866

Epoch: 6| Step: 13
Training loss: 1.4505540132522583
Validation loss: 2.046540824315881

Epoch: 487| Step: 0
Training loss: 1.60942542552948
Validation loss: 2.0609292855826755

Epoch: 6| Step: 1
Training loss: 0.8422380685806274
Validation loss: 2.0609121591814104

Epoch: 6| Step: 2
Training loss: 1.5916407108306885
Validation loss: 2.038068796998711

Epoch: 6| Step: 3
Training loss: 1.5693049430847168
Validation loss: 2.0375250411289993

Epoch: 6| Step: 4
Training loss: 1.8379777669906616
Validation loss: 2.056633690352081

Epoch: 6| Step: 5
Training loss: 1.3487703800201416
Validation loss: 2.0786314548984652

Epoch: 6| Step: 6
Training loss: 1.3326820135116577
Validation loss: 2.023528165714715

Epoch: 6| Step: 7
Training loss: 1.8786321878433228
Validation loss: 2.1072868301022436

Epoch: 6| Step: 8
Training loss: 1.0952479839324951
Validation loss: 2.06207001081077

Epoch: 6| Step: 9
Training loss: 1.5873384475708008
Validation loss: 2.042898649810463

Epoch: 6| Step: 10
Training loss: 1.6838327646255493
Validation loss: 2.056415234842608

Epoch: 6| Step: 11
Training loss: 1.4981443881988525
Validation loss: 2.0689247218511437

Epoch: 6| Step: 12
Training loss: 0.9751496315002441
Validation loss: 2.019947933894332

Epoch: 6| Step: 13
Training loss: 0.9265507459640503
Validation loss: 2.05801954320682

Epoch: 488| Step: 0
Training loss: 0.9950429201126099
Validation loss: 2.021351339996502

Epoch: 6| Step: 1
Training loss: 1.428166389465332
Validation loss: 2.065817548382667

Epoch: 6| Step: 2
Training loss: 0.4740909934043884
Validation loss: 2.047352421668268

Epoch: 6| Step: 3
Training loss: 1.6638103723526
Validation loss: 2.0264151801345167

Epoch: 6| Step: 4
Training loss: 1.53651762008667
Validation loss: 2.0355304197598527

Epoch: 6| Step: 5
Training loss: 1.3409812450408936
Validation loss: 2.0013840518971926

Epoch: 6| Step: 6
Training loss: 1.2334680557250977
Validation loss: 2.026585964746373

Epoch: 6| Step: 7
Training loss: 1.1151429414749146
Validation loss: 2.025705375979024

Epoch: 6| Step: 8
Training loss: 1.5738451480865479
Validation loss: 2.034187073348671

Epoch: 6| Step: 9
Training loss: 1.584123134613037
Validation loss: 2.0457044750131588

Epoch: 6| Step: 10
Training loss: 1.57949960231781
Validation loss: 2.023128281357468

Epoch: 6| Step: 11
Training loss: 1.474517583847046
Validation loss: 2.0163319777416926

Epoch: 6| Step: 12
Training loss: 1.7475481033325195
Validation loss: 2.01316330253437

Epoch: 6| Step: 13
Training loss: 1.6040687561035156
Validation loss: 1.999610629132999

Epoch: 489| Step: 0
Training loss: 1.6624376773834229
Validation loss: 2.0842889278165755

Epoch: 6| Step: 1
Training loss: 1.4003057479858398
Validation loss: 2.0635625880251647

Epoch: 6| Step: 2
Training loss: 0.9285238981246948
Validation loss: 2.097474664770147

Epoch: 6| Step: 3
Training loss: 1.355776071548462
Validation loss: 2.0639488543233564

Epoch: 6| Step: 4
Training loss: 1.721514344215393
Validation loss: 2.078912483748569

Epoch: 6| Step: 5
Training loss: 1.6226420402526855
Validation loss: 2.028026811538204

Epoch: 6| Step: 6
Training loss: 1.3137818574905396
Validation loss: 2.1016555832278345

Epoch: 6| Step: 7
Training loss: 1.3004229068756104
Validation loss: 2.0763922532399497

Epoch: 6| Step: 8
Training loss: 1.7332866191864014
Validation loss: 2.0777550922927035

Epoch: 6| Step: 9
Training loss: 1.139728307723999
Validation loss: 2.0471620995511293

Epoch: 6| Step: 10
Training loss: 0.6840387582778931
Validation loss: 2.030121582810597

Epoch: 6| Step: 11
Training loss: 1.4380136728286743
Validation loss: 2.0860081180449455

Epoch: 6| Step: 12
Training loss: 1.0753726959228516
Validation loss: 2.0522677795861357

Epoch: 6| Step: 13
Training loss: 2.5863490104675293
Validation loss: 2.0408766654229935

Epoch: 490| Step: 0
Training loss: 1.420196771621704
Validation loss: 2.0758926970984346

Epoch: 6| Step: 1
Training loss: 1.0786250829696655
Validation loss: 2.0482721085189493

Epoch: 6| Step: 2
Training loss: 1.0659291744232178
Validation loss: 2.044602153121784

Epoch: 6| Step: 3
Training loss: 1.824296474456787
Validation loss: 2.0585059542809763

Epoch: 6| Step: 4
Training loss: 1.2261672019958496
Validation loss: 2.0351870957241265

Epoch: 6| Step: 5
Training loss: 1.5313670635223389
Validation loss: 2.0230103615791566

Epoch: 6| Step: 6
Training loss: 0.9153228998184204
Validation loss: 2.0414647415120113

Epoch: 6| Step: 7
Training loss: 1.3637681007385254
Validation loss: 2.0226954670362574

Epoch: 6| Step: 8
Training loss: 1.5505154132843018
Validation loss: 2.0253181739520003

Epoch: 6| Step: 9
Training loss: 1.840678334236145
Validation loss: 2.028825854742399

Epoch: 6| Step: 10
Training loss: 1.2845922708511353
Validation loss: 2.0502064561331146

Epoch: 6| Step: 11
Training loss: 0.738047182559967
Validation loss: 2.025792166750918

Epoch: 6| Step: 12
Training loss: 1.444344401359558
Validation loss: 2.048204366878797

Epoch: 6| Step: 13
Training loss: 2.0252299308776855
Validation loss: 2.0567347900841826

Epoch: 491| Step: 0
Training loss: 1.4632697105407715
Validation loss: 2.095360658502066

Epoch: 6| Step: 1
Training loss: 1.2813023328781128
Validation loss: 2.051999940667101

Epoch: 6| Step: 2
Training loss: 1.2454941272735596
Validation loss: 2.052758768040647

Epoch: 6| Step: 3
Training loss: 1.4327678680419922
Validation loss: 2.0284821077059676

Epoch: 6| Step: 4
Training loss: 1.611479640007019
Validation loss: 2.0531725422028573

Epoch: 6| Step: 5
Training loss: 1.1935703754425049
Validation loss: 2.0985040562127226

Epoch: 6| Step: 6
Training loss: 1.6138842105865479
Validation loss: 2.0578415163101687

Epoch: 6| Step: 7
Training loss: 1.5964066982269287
Validation loss: 2.066606786943251

Epoch: 6| Step: 8
Training loss: 1.3372306823730469
Validation loss: 2.0962701330902758

Epoch: 6| Step: 9
Training loss: 0.9144173264503479
Validation loss: 2.071852878857684

Epoch: 6| Step: 10
Training loss: 1.3404440879821777
Validation loss: 2.084243768004961

Epoch: 6| Step: 11
Training loss: 1.6059808731079102
Validation loss: 2.0344460946257397

Epoch: 6| Step: 12
Training loss: 1.8123759031295776
Validation loss: 2.0512146667767595

Epoch: 6| Step: 13
Training loss: 0.766942024230957
Validation loss: 2.0771113672564105

Epoch: 492| Step: 0
Training loss: 1.554499626159668
Validation loss: 2.0209946452930407

Epoch: 6| Step: 1
Training loss: 1.3856759071350098
Validation loss: 2.0354892707640126

Epoch: 6| Step: 2
Training loss: 0.9336069822311401
Validation loss: 2.014082440765955

Epoch: 6| Step: 3
Training loss: 1.1669926643371582
Validation loss: 2.044262445101174

Epoch: 6| Step: 4
Training loss: 1.8253644704818726
Validation loss: 1.9956938579518309

Epoch: 6| Step: 5
Training loss: 1.4843294620513916
Validation loss: 2.0169632921936693

Epoch: 6| Step: 6
Training loss: 1.04204261302948
Validation loss: 2.032048402294036

Epoch: 6| Step: 7
Training loss: 1.2753640413284302
Validation loss: 2.0279730648122807

Epoch: 6| Step: 8
Training loss: 1.7020227909088135
Validation loss: 2.0599848326816352

Epoch: 6| Step: 9
Training loss: 1.509826898574829
Validation loss: 2.0670676333929903

Epoch: 6| Step: 10
Training loss: 0.8541501760482788
Validation loss: 2.0839056686688493

Epoch: 6| Step: 11
Training loss: 1.8446481227874756
Validation loss: 2.067472432249336

Epoch: 6| Step: 12
Training loss: 1.2777059078216553
Validation loss: 2.095909357070923

Epoch: 6| Step: 13
Training loss: 1.5661879777908325
Validation loss: 2.075328278285201

Epoch: 493| Step: 0
Training loss: 1.8524373769760132
Validation loss: 2.102738167649956

Epoch: 6| Step: 1
Training loss: 1.1737768650054932
Validation loss: 2.0937403735294136

Epoch: 6| Step: 2
Training loss: 1.1142010688781738
Validation loss: 2.0828524712593324

Epoch: 6| Step: 3
Training loss: 1.609743356704712
Validation loss: 2.062790709157144

Epoch: 6| Step: 4
Training loss: 1.368845820426941
Validation loss: 2.0605190992355347

Epoch: 6| Step: 5
Training loss: 1.1508150100708008
Validation loss: 2.0276466133773967

Epoch: 6| Step: 6
Training loss: 1.7450196743011475
Validation loss: 2.0720209537013883

Epoch: 6| Step: 7
Training loss: 1.6160783767700195
Validation loss: 2.0210734926244265

Epoch: 6| Step: 8
Training loss: 1.3250737190246582
Validation loss: 2.0091714807735976

Epoch: 6| Step: 9
Training loss: 1.0567703247070312
Validation loss: 2.0107909171811995

Epoch: 6| Step: 10
Training loss: 1.3908681869506836
Validation loss: 2.027080956325736

Epoch: 6| Step: 11
Training loss: 1.1585071086883545
Validation loss: 2.0561014759925103

Epoch: 6| Step: 12
Training loss: 1.6759746074676514
Validation loss: 2.068750346860578

Epoch: 6| Step: 13
Training loss: 1.0749433040618896
Validation loss: 2.0601095461076304

Epoch: 494| Step: 0
Training loss: 1.4340248107910156
Validation loss: 2.00876893279373

Epoch: 6| Step: 1
Training loss: 1.591145634651184
Validation loss: 2.0356400025788175

Epoch: 6| Step: 2
Training loss: 1.529331922531128
Validation loss: 2.0390948146902104

Epoch: 6| Step: 3
Training loss: 1.746537685394287
Validation loss: 2.047044905283118

Epoch: 6| Step: 4
Training loss: 1.5574870109558105
Validation loss: 2.0394217980805265

Epoch: 6| Step: 5
Training loss: 0.7966817617416382
Validation loss: 2.0512398622369252

Epoch: 6| Step: 6
Training loss: 1.5756199359893799
Validation loss: 2.101889071925994

Epoch: 6| Step: 7
Training loss: 1.1732895374298096
Validation loss: 2.0512947164556032

Epoch: 6| Step: 8
Training loss: 1.0792802572250366
Validation loss: 2.0781521797180176

Epoch: 6| Step: 9
Training loss: 1.5780304670333862
Validation loss: 2.089178942864941

Epoch: 6| Step: 10
Training loss: 1.4287617206573486
Validation loss: 2.090665941597313

Epoch: 6| Step: 11
Training loss: 1.6325029134750366
Validation loss: 2.0645933176881526

Epoch: 6| Step: 12
Training loss: 1.0437614917755127
Validation loss: 2.070857842763265

Epoch: 6| Step: 13
Training loss: 0.6549285650253296
Validation loss: 2.0658508731472875

Epoch: 495| Step: 0
Training loss: 1.627808928489685
Validation loss: 2.0554163686690794

Epoch: 6| Step: 1
Training loss: 1.1940643787384033
Validation loss: 2.074949710599838

Epoch: 6| Step: 2
Training loss: 1.1862752437591553
Validation loss: 2.076005599832022

Epoch: 6| Step: 3
Training loss: 1.5323195457458496
Validation loss: 2.059817502575536

Epoch: 6| Step: 4
Training loss: 2.0211567878723145
Validation loss: 2.062990170653148

Epoch: 6| Step: 5
Training loss: 1.7165675163269043
Validation loss: 2.0307142234617666

Epoch: 6| Step: 6
Training loss: 1.7503998279571533
Validation loss: 2.056048777795607

Epoch: 6| Step: 7
Training loss: 1.226330280303955
Validation loss: 2.019478701776074

Epoch: 6| Step: 8
Training loss: 0.911432147026062
Validation loss: 1.993827107132122

Epoch: 6| Step: 9
Training loss: 0.7824119925498962
Validation loss: 2.0500692834136305

Epoch: 6| Step: 10
Training loss: 1.4175641536712646
Validation loss: 2.0800306822663996

Epoch: 6| Step: 11
Training loss: 1.4130803346633911
Validation loss: 2.0811548873942387

Epoch: 6| Step: 12
Training loss: 1.4933197498321533
Validation loss: 2.0526063596048663

Epoch: 6| Step: 13
Training loss: 0.6458669304847717
Validation loss: 2.059105606489284

Epoch: 496| Step: 0
Training loss: 1.24019193649292
Validation loss: 2.0602810177751767

Epoch: 6| Step: 1
Training loss: 0.8487472534179688
Validation loss: 2.0587377996854883

Epoch: 6| Step: 2
Training loss: 1.15153169631958
Validation loss: 2.0255203375252346

Epoch: 6| Step: 3
Training loss: 1.3867254257202148
Validation loss: 2.04695059663506

Epoch: 6| Step: 4
Training loss: 1.3306303024291992
Validation loss: 2.0525878796013455

Epoch: 6| Step: 5
Training loss: 1.5891698598861694
Validation loss: 2.0816912753607637

Epoch: 6| Step: 6
Training loss: 1.0302562713623047
Validation loss: 2.0759287854676605

Epoch: 6| Step: 7
Training loss: 1.8712351322174072
Validation loss: 2.0304865760187947

Epoch: 6| Step: 8
Training loss: 1.7223154306411743
Validation loss: 2.0343583142885597

Epoch: 6| Step: 9
Training loss: 1.4953876733779907
Validation loss: 2.0784406303077616

Epoch: 6| Step: 10
Training loss: 1.7927627563476562
Validation loss: 2.1130300080904396

Epoch: 6| Step: 11
Training loss: 1.4489836692810059
Validation loss: 2.053526084910157

Epoch: 6| Step: 12
Training loss: 1.4684138298034668
Validation loss: 2.075821908571387

Epoch: 6| Step: 13
Training loss: 0.8708045482635498
Validation loss: 2.092620979073227

Epoch: 497| Step: 0
Training loss: 2.2308168411254883
Validation loss: 2.082373197360705

Epoch: 6| Step: 1
Training loss: 1.4900896549224854
Validation loss: 2.076234636768218

Epoch: 6| Step: 2
Training loss: 1.0960479974746704
Validation loss: 2.0992337170467583

Epoch: 6| Step: 3
Training loss: 1.459556221961975
Validation loss: 2.0560832433803107

Epoch: 6| Step: 4
Training loss: 1.213830828666687
Validation loss: 2.0538234646602342

Epoch: 6| Step: 5
Training loss: 1.625303030014038
Validation loss: 1.9777254891651932

Epoch: 6| Step: 6
Training loss: 1.263692855834961
Validation loss: 2.049665492068055

Epoch: 6| Step: 7
Training loss: 0.8915218710899353
Validation loss: 2.0323771597236715

Epoch: 6| Step: 8
Training loss: 1.2801580429077148
Validation loss: 2.0873924224607405

Epoch: 6| Step: 9
Training loss: 1.391633152961731
Validation loss: 2.043760504773868

Epoch: 6| Step: 10
Training loss: 0.8692460060119629
Validation loss: 2.0773347757195912

Epoch: 6| Step: 11
Training loss: 1.4552615880966187
Validation loss: 2.033278073033979

Epoch: 6| Step: 12
Training loss: 1.2745596170425415
Validation loss: 2.03771403784393

Epoch: 6| Step: 13
Training loss: 1.3427581787109375
Validation loss: 2.0601685290695517

Epoch: 498| Step: 0
Training loss: 1.4015387296676636
Validation loss: 2.033232468430714

Epoch: 6| Step: 1
Training loss: 0.8207977414131165
Validation loss: 2.04778794575763

Epoch: 6| Step: 2
Training loss: 1.4644451141357422
Validation loss: 2.0173291442214802

Epoch: 6| Step: 3
Training loss: 1.6277637481689453
Validation loss: 2.034860252052225

Epoch: 6| Step: 4
Training loss: 1.1794793605804443
Validation loss: 2.037935515885712

Epoch: 6| Step: 5
Training loss: 0.8196133971214294
Validation loss: 1.9698583849014775

Epoch: 6| Step: 6
Training loss: 1.6582231521606445
Validation loss: 2.06024960548647

Epoch: 6| Step: 7
Training loss: 1.763585090637207
Validation loss: 2.0606905260393695

Epoch: 6| Step: 8
Training loss: 1.2080060243606567
Validation loss: 2.020574520992976

Epoch: 6| Step: 9
Training loss: 1.3298957347869873
Validation loss: 2.0223567357627292

Epoch: 6| Step: 10
Training loss: 1.210007905960083
Validation loss: 2.0505875015771515

Epoch: 6| Step: 11
Training loss: 1.3506226539611816
Validation loss: 1.9998068117326306

Epoch: 6| Step: 12
Training loss: 1.8650745153427124
Validation loss: 2.054349701891663

Epoch: 6| Step: 13
Training loss: 1.1697890758514404
Validation loss: 2.0619062582651773

Epoch: 499| Step: 0
Training loss: 1.2445815801620483
Validation loss: 2.0487828562336583

Epoch: 6| Step: 1
Training loss: 1.1864967346191406
Validation loss: 2.0292012153133268

Epoch: 6| Step: 2
Training loss: 1.6931750774383545
Validation loss: 2.0622570540315364

Epoch: 6| Step: 3
Training loss: 1.0103092193603516
Validation loss: 2.082824678831203

Epoch: 6| Step: 4
Training loss: 0.8887189030647278
Validation loss: 2.0731343236020816

Epoch: 6| Step: 5
Training loss: 2.0919508934020996
Validation loss: 2.0522881823201335

Epoch: 6| Step: 6
Training loss: 1.4916739463806152
Validation loss: 2.078133035731572

Epoch: 6| Step: 7
Training loss: 1.424451231956482
Validation loss: 2.05555437713541

Epoch: 6| Step: 8
Training loss: 1.194503664970398
Validation loss: 2.0303851353224887

Epoch: 6| Step: 9
Training loss: 1.8434338569641113
Validation loss: 2.071520472085604

Epoch: 6| Step: 10
Training loss: 1.8075172901153564
Validation loss: 2.013017236545522

Epoch: 6| Step: 11
Training loss: 0.7771633863449097
Validation loss: 2.030017368255123

Epoch: 6| Step: 12
Training loss: 1.2203454971313477
Validation loss: 1.9913424996919529

Epoch: 6| Step: 13
Training loss: 1.033606767654419
Validation loss: 2.011708149345972

Epoch: 500| Step: 0
Training loss: 2.0530645847320557
Validation loss: 2.0168491666034987

Epoch: 6| Step: 1
Training loss: 1.2111964225769043
Validation loss: 2.0538805941099763

Epoch: 6| Step: 2
Training loss: 1.0193016529083252
Validation loss: 2.0512170714716755

Epoch: 6| Step: 3
Training loss: 1.355131983757019
Validation loss: 2.0542476331034014

Epoch: 6| Step: 4
Training loss: 1.2813851833343506
Validation loss: 2.070721036644392

Epoch: 6| Step: 5
Training loss: 0.9969794750213623
Validation loss: 2.025733435025779

Epoch: 6| Step: 6
Training loss: 1.775510549545288
Validation loss: 2.0447235914968673

Epoch: 6| Step: 7
Training loss: 1.6320436000823975
Validation loss: 2.0470557430739045

Epoch: 6| Step: 8
Training loss: 1.5115667581558228
Validation loss: 2.031405237413222

Epoch: 6| Step: 9
Training loss: 1.1346819400787354
Validation loss: 2.055716294114308

Epoch: 6| Step: 10
Training loss: 1.3413463830947876
Validation loss: 2.0918397339441444

Epoch: 6| Step: 11
Training loss: 1.4313161373138428
Validation loss: 2.0227565893562893

Epoch: 6| Step: 12
Training loss: 1.0485111474990845
Validation loss: 2.085640218950087

Epoch: 6| Step: 13
Training loss: 0.873952329158783
Validation loss: 2.0923684784161147

Epoch: 501| Step: 0
Training loss: 1.180832862854004
Validation loss: 2.075982603975522

Epoch: 6| Step: 1
Training loss: 1.3049042224884033
Validation loss: 2.065595711431196

Epoch: 6| Step: 2
Training loss: 1.5088460445404053
Validation loss: 2.0883586701526435

Epoch: 6| Step: 3
Training loss: 1.254078984260559
Validation loss: 2.092365691738744

Epoch: 6| Step: 4
Training loss: 0.9668302536010742
Validation loss: 2.044312415584441

Epoch: 6| Step: 5
Training loss: 1.325132966041565
Validation loss: 2.0247275675496748

Epoch: 6| Step: 6
Training loss: 1.3423681259155273
Validation loss: 2.062410062359225

Epoch: 6| Step: 7
Training loss: 2.1229248046875
Validation loss: 2.062380918892481

Epoch: 6| Step: 8
Training loss: 1.512336015701294
Validation loss: 2.1063073540246613

Epoch: 6| Step: 9
Training loss: 1.3279633522033691
Validation loss: 2.081385430469308

Epoch: 6| Step: 10
Training loss: 1.2523828744888306
Validation loss: 2.0596673539889756

Epoch: 6| Step: 11
Training loss: 1.1331121921539307
Validation loss: 2.062826346325618

Epoch: 6| Step: 12
Training loss: 1.2351127862930298
Validation loss: 2.080318522709672

Epoch: 6| Step: 13
Training loss: 1.6638126373291016
Validation loss: 2.0636094334304973

Epoch: 502| Step: 0
Training loss: 0.8160998225212097
Validation loss: 2.0537738133502264

Epoch: 6| Step: 1
Training loss: 1.565260887145996
Validation loss: 2.0397227630820325

Epoch: 6| Step: 2
Training loss: 0.8008288741111755
Validation loss: 2.0335016712065666

Epoch: 6| Step: 3
Training loss: 1.6265217065811157
Validation loss: 2.045730657474969

Epoch: 6| Step: 4
Training loss: 0.8607335090637207
Validation loss: 2.0256461879258514

Epoch: 6| Step: 5
Training loss: 1.3791429996490479
Validation loss: 2.0079011263385897

Epoch: 6| Step: 6
Training loss: 1.154050588607788
Validation loss: 2.028503975560588

Epoch: 6| Step: 7
Training loss: 0.7528292536735535
Validation loss: 1.9887952368746522

Epoch: 6| Step: 8
Training loss: 1.6367161273956299
Validation loss: 2.0509761405247513

Epoch: 6| Step: 9
Training loss: 1.5449082851409912
Validation loss: 2.030072401928645

Epoch: 6| Step: 10
Training loss: 1.5752263069152832
Validation loss: 2.069798061924596

Epoch: 6| Step: 11
Training loss: 2.119468927383423
Validation loss: 2.0807802779700166

Epoch: 6| Step: 12
Training loss: 1.585644006729126
Validation loss: 2.0204327209021455

Epoch: 6| Step: 13
Training loss: 2.106414794921875
Validation loss: 2.0672178370978243

Epoch: 503| Step: 0
Training loss: 1.3852243423461914
Validation loss: 2.0606095303771315

Epoch: 6| Step: 1
Training loss: 0.752031683921814
Validation loss: 2.09144611512461

Epoch: 6| Step: 2
Training loss: 1.352342963218689
Validation loss: 2.0712224104071177

Epoch: 6| Step: 3
Training loss: 1.1994351148605347
Validation loss: 2.067069907342234

Epoch: 6| Step: 4
Training loss: 1.0190935134887695
Validation loss: 2.0832355035248624

Epoch: 6| Step: 5
Training loss: 1.1036479473114014
Validation loss: 2.046926022857748

Epoch: 6| Step: 6
Training loss: 1.4433335065841675
Validation loss: 2.072615687565137

Epoch: 6| Step: 7
Training loss: 1.5768694877624512
Validation loss: 2.0594165299528386

Epoch: 6| Step: 8
Training loss: 1.8384976387023926
Validation loss: 2.0268393665231685

Epoch: 6| Step: 9
Training loss: 0.9161293506622314
Validation loss: 2.0393130317811043

Epoch: 6| Step: 10
Training loss: 1.4662672281265259
Validation loss: 2.0006026529496714

Epoch: 6| Step: 11
Training loss: 1.761305332183838
Validation loss: 2.021495375581967

Epoch: 6| Step: 12
Training loss: 2.17563796043396
Validation loss: 2.0498978630188973

Epoch: 6| Step: 13
Training loss: 0.6859636306762695
Validation loss: 2.0605572474900113

Epoch: 504| Step: 0
Training loss: 1.459686040878296
Validation loss: 2.020902451648507

Epoch: 6| Step: 1
Training loss: 1.4831982851028442
Validation loss: 2.0159691585007535

Epoch: 6| Step: 2
Training loss: 1.996323823928833
Validation loss: 2.0627752580950336

Epoch: 6| Step: 3
Training loss: 0.599277138710022
Validation loss: 2.0288983006631174

Epoch: 6| Step: 4
Training loss: 1.5825080871582031
Validation loss: 2.0038167930418447

Epoch: 6| Step: 5
Training loss: 0.9685450196266174
Validation loss: 2.073377719489477

Epoch: 6| Step: 6
Training loss: 1.2393320798873901
Validation loss: 2.0707482650715816

Epoch: 6| Step: 7
Training loss: 1.4948186874389648
Validation loss: 2.0911432286744476

Epoch: 6| Step: 8
Training loss: 1.3039729595184326
Validation loss: 2.063530804008566

Epoch: 6| Step: 9
Training loss: 1.1544735431671143
Validation loss: 2.1118529048017276

Epoch: 6| Step: 10
Training loss: 2.0423498153686523
Validation loss: 2.071269844167976

Epoch: 6| Step: 11
Training loss: 1.3284218311309814
Validation loss: 2.095614469179543

Epoch: 6| Step: 12
Training loss: 1.0518436431884766
Validation loss: 2.0755266143429663

Epoch: 6| Step: 13
Training loss: 1.2699315547943115
Validation loss: 2.061789516479738

Epoch: 505| Step: 0
Training loss: 1.296326756477356
Validation loss: 2.043037586314704

Epoch: 6| Step: 1
Training loss: 1.367344856262207
Validation loss: 2.0365645052284322

Epoch: 6| Step: 2
Training loss: 2.116166591644287
Validation loss: 2.0249116087472565

Epoch: 6| Step: 3
Training loss: 1.2728149890899658
Validation loss: 2.028150103425467

Epoch: 6| Step: 4
Training loss: 1.365269422531128
Validation loss: 2.0473743895048737

Epoch: 6| Step: 5
Training loss: 1.2387418746948242
Validation loss: 2.0122680535880466

Epoch: 6| Step: 6
Training loss: 1.5468631982803345
Validation loss: 2.0533353256922897

Epoch: 6| Step: 7
Training loss: 1.0603549480438232
Validation loss: 2.016915382877473

Epoch: 6| Step: 8
Training loss: 1.3774540424346924
Validation loss: 2.077638941426431

Epoch: 6| Step: 9
Training loss: 1.6533255577087402
Validation loss: 2.0414511029438307

Epoch: 6| Step: 10
Training loss: 1.0489506721496582
Validation loss: 2.0743166746631747

Epoch: 6| Step: 11
Training loss: 1.484385371208191
Validation loss: 2.077116015136883

Epoch: 6| Step: 12
Training loss: 1.2719664573669434
Validation loss: 2.0365721551320886

Epoch: 6| Step: 13
Training loss: 0.7515414357185364
Validation loss: 2.0785970816048245

Epoch: 506| Step: 0
Training loss: 1.3030118942260742
Validation loss: 2.0326304038365683

Epoch: 6| Step: 1
Training loss: 1.8204631805419922
Validation loss: 2.060359037050637

Epoch: 6| Step: 2
Training loss: 1.5409401655197144
Validation loss: 2.0995280499099405

Epoch: 6| Step: 3
Training loss: 2.2969017028808594
Validation loss: 2.0727524731748845

Epoch: 6| Step: 4
Training loss: 0.903875470161438
Validation loss: 2.0619473047153924

Epoch: 6| Step: 5
Training loss: 1.576953649520874
Validation loss: 2.0598669423851916

Epoch: 6| Step: 6
Training loss: 1.285494089126587
Validation loss: 2.0146413541609243

Epoch: 6| Step: 7
Training loss: 1.9368525743484497
Validation loss: 2.062356100287489

Epoch: 6| Step: 8
Training loss: 1.0111432075500488
Validation loss: 1.9923872114509664

Epoch: 6| Step: 9
Training loss: 0.9061055183410645
Validation loss: 2.0740925099260066

Epoch: 6| Step: 10
Training loss: 0.5339561700820923
Validation loss: 2.0112859305515083

Epoch: 6| Step: 11
Training loss: 0.9120326638221741
Validation loss: 2.049324545809018

Epoch: 6| Step: 12
Training loss: 1.533234715461731
Validation loss: 2.036273019288176

Epoch: 6| Step: 13
Training loss: 1.1477551460266113
Validation loss: 2.042373376507913

Epoch: 507| Step: 0
Training loss: 1.0109111070632935
Validation loss: 2.044470089738087

Epoch: 6| Step: 1
Training loss: 1.5715265274047852
Validation loss: 2.071622674183179

Epoch: 6| Step: 2
Training loss: 1.0224820375442505
Validation loss: 2.054739570104948

Epoch: 6| Step: 3
Training loss: 1.3149796724319458
Validation loss: 2.0169051629240795

Epoch: 6| Step: 4
Training loss: 1.3783982992172241
Validation loss: 2.1125156187242076

Epoch: 6| Step: 5
Training loss: 1.5441546440124512
Validation loss: 2.0564649361436085

Epoch: 6| Step: 6
Training loss: 1.1570565700531006
Validation loss: 2.0278900349011986

Epoch: 6| Step: 7
Training loss: 1.6943690776824951
Validation loss: 2.052112720345938

Epoch: 6| Step: 8
Training loss: 1.2784788608551025
Validation loss: 2.032967150852244

Epoch: 6| Step: 9
Training loss: 1.2639461755752563
Validation loss: 1.9966676645381476

Epoch: 6| Step: 10
Training loss: 1.3116694688796997
Validation loss: 2.0765606293114285

Epoch: 6| Step: 11
Training loss: 1.221917986869812
Validation loss: 1.957822786864414

Epoch: 6| Step: 12
Training loss: 1.4475003480911255
Validation loss: 2.037495900225896

Epoch: 6| Step: 13
Training loss: 2.4856252670288086
Validation loss: 2.033213253944151

Epoch: 508| Step: 0
Training loss: 1.521348237991333
Validation loss: 2.0230912957140195

Epoch: 6| Step: 1
Training loss: 1.8847324848175049
Validation loss: 2.042195368838567

Epoch: 6| Step: 2
Training loss: 1.3230891227722168
Validation loss: 2.071549436097504

Epoch: 6| Step: 3
Training loss: 1.878296971321106
Validation loss: 2.0372406334005375

Epoch: 6| Step: 4
Training loss: 1.003239631652832
Validation loss: 2.028450174998212

Epoch: 6| Step: 5
Training loss: 1.1107158660888672
Validation loss: 2.0117088364016626

Epoch: 6| Step: 6
Training loss: 1.0931332111358643
Validation loss: 2.054317675611024

Epoch: 6| Step: 7
Training loss: 1.1924508810043335
Validation loss: 2.036232872675824

Epoch: 6| Step: 8
Training loss: 0.6303380727767944
Validation loss: 2.03935900298498

Epoch: 6| Step: 9
Training loss: 1.0090874433517456
Validation loss: 2.0193296030003536

Epoch: 6| Step: 10
Training loss: 1.5185972452163696
Validation loss: 2.0255811675902335

Epoch: 6| Step: 11
Training loss: 1.0996977090835571
Validation loss: 2.031332810719808

Epoch: 6| Step: 12
Training loss: 2.37898588180542
Validation loss: 2.069955610459851

Epoch: 6| Step: 13
Training loss: 1.3300814628601074
Validation loss: 2.097603351839127

Epoch: 509| Step: 0
Training loss: 1.0782470703125
Validation loss: 2.0653886641225507

Epoch: 6| Step: 1
Training loss: 2.016728401184082
Validation loss: 2.110474662114215

Epoch: 6| Step: 2
Training loss: 1.499842882156372
Validation loss: 2.1055405165559504

Epoch: 6| Step: 3
Training loss: 0.9472084045410156
Validation loss: 2.0904891029480965

Epoch: 6| Step: 4
Training loss: 0.8126718997955322
Validation loss: 2.069765326797321

Epoch: 6| Step: 5
Training loss: 1.5672709941864014
Validation loss: 2.0677524343613656

Epoch: 6| Step: 6
Training loss: 0.7676296234130859
Validation loss: 2.071898966707209

Epoch: 6| Step: 7
Training loss: 1.5920217037200928
Validation loss: 2.0661684095218615

Epoch: 6| Step: 8
Training loss: 1.8170474767684937
Validation loss: 2.028239493728966

Epoch: 6| Step: 9
Training loss: 1.4518483877182007
Validation loss: 2.0336454722189132

Epoch: 6| Step: 10
Training loss: 1.2157847881317139
Validation loss: 2.039131578578744

Epoch: 6| Step: 11
Training loss: 1.6780915260314941
Validation loss: 2.02973351940032

Epoch: 6| Step: 12
Training loss: 1.983858585357666
Validation loss: 2.0268947385972544

Epoch: 6| Step: 13
Training loss: 0.34810712933540344
Validation loss: 2.032802963769564

Epoch: 510| Step: 0
Training loss: 1.0986757278442383
Validation loss: 2.032992943640678

Epoch: 6| Step: 1
Training loss: 0.8943241834640503
Validation loss: 2.047415187281947

Epoch: 6| Step: 2
Training loss: 1.6140714883804321
Validation loss: 2.0496902799093597

Epoch: 6| Step: 3
Training loss: 1.5720126628875732
Validation loss: 2.0681693361651514

Epoch: 6| Step: 4
Training loss: 1.4924285411834717
Validation loss: 2.0673704301157305

Epoch: 6| Step: 5
Training loss: 1.6890273094177246
Validation loss: 2.0318341998643774

Epoch: 6| Step: 6
Training loss: 1.0819759368896484
Validation loss: 2.058821039815103

Epoch: 6| Step: 7
Training loss: 0.7628305554389954
Validation loss: 2.0636435170327463

Epoch: 6| Step: 8
Training loss: 1.061110019683838
Validation loss: 2.07773095305248

Epoch: 6| Step: 9
Training loss: 1.0496180057525635
Validation loss: 2.0922268718801518

Epoch: 6| Step: 10
Training loss: 1.2867588996887207
Validation loss: 2.019026558886292

Epoch: 6| Step: 11
Training loss: 1.9087321758270264
Validation loss: 2.0239486848154375

Epoch: 6| Step: 12
Training loss: 1.2282383441925049
Validation loss: 2.0175780942363124

Epoch: 6| Step: 13
Training loss: 2.5622875690460205
Validation loss: 2.0090829018623597

Epoch: 511| Step: 0
Training loss: 1.8022589683532715
Validation loss: 2.015345468316027

Epoch: 6| Step: 1
Training loss: 1.346374273300171
Validation loss: 2.0336275126344416

Epoch: 6| Step: 2
Training loss: 1.1454731225967407
Validation loss: 2.029945542735438

Epoch: 6| Step: 3
Training loss: 1.2021665573120117
Validation loss: 2.043433097101027

Epoch: 6| Step: 4
Training loss: 1.5979721546173096
Validation loss: 2.0439695107039584

Epoch: 6| Step: 5
Training loss: 1.7032972574234009
Validation loss: 2.038274318941178

Epoch: 6| Step: 6
Training loss: 1.1371111869812012
Validation loss: 2.0875249883180023

Epoch: 6| Step: 7
Training loss: 0.8690464496612549
Validation loss: 2.0362213196293

Epoch: 6| Step: 8
Training loss: 1.2384865283966064
Validation loss: 2.067508484727593

Epoch: 6| Step: 9
Training loss: 0.9828764200210571
Validation loss: 2.095500530735139

Epoch: 6| Step: 10
Training loss: 1.8925833702087402
Validation loss: 2.1131024758021035

Epoch: 6| Step: 11
Training loss: 1.4779967069625854
Validation loss: 2.0722027171042656

Epoch: 6| Step: 12
Training loss: 1.1009005308151245
Validation loss: 2.0730072695721864

Epoch: 6| Step: 13
Training loss: 1.3032269477844238
Validation loss: 2.0898904672233005

Epoch: 512| Step: 0
Training loss: 1.2368041276931763
Validation loss: 2.0464678400306293

Epoch: 6| Step: 1
Training loss: 1.9735991954803467
Validation loss: 2.0161573566416258

Epoch: 6| Step: 2
Training loss: 1.0934860706329346
Validation loss: 2.082609474018056

Epoch: 6| Step: 3
Training loss: 1.0272502899169922
Validation loss: 2.0130607504998483

Epoch: 6| Step: 4
Training loss: 1.692953109741211
Validation loss: 2.057452997853679

Epoch: 6| Step: 5
Training loss: 0.9354051351547241
Validation loss: 2.0110253403263707

Epoch: 6| Step: 6
Training loss: 1.101776123046875
Validation loss: 2.0035620235627696

Epoch: 6| Step: 7
Training loss: 1.1307424306869507
Validation loss: 2.006818276579662

Epoch: 6| Step: 8
Training loss: 1.3780341148376465
Validation loss: 1.9828523025717786

Epoch: 6| Step: 9
Training loss: 1.1737730503082275
Validation loss: 2.0057403438834736

Epoch: 6| Step: 10
Training loss: 1.3768010139465332
Validation loss: 2.047630338258641

Epoch: 6| Step: 11
Training loss: 1.6311665773391724
Validation loss: 2.010035046967127

Epoch: 6| Step: 12
Training loss: 1.6119685173034668
Validation loss: 2.041887958844503

Epoch: 6| Step: 13
Training loss: 1.6188807487487793
Validation loss: 2.04381509365574

Epoch: 513| Step: 0
Training loss: 1.2403502464294434
Validation loss: 2.03936335861042

Epoch: 6| Step: 1
Training loss: 1.6637519598007202
Validation loss: 2.06198190873669

Epoch: 6| Step: 2
Training loss: 0.9671726822853088
Validation loss: 2.1046795383576424

Epoch: 6| Step: 3
Training loss: 1.3621615171432495
Validation loss: 2.1018011800704466

Epoch: 6| Step: 4
Training loss: 1.7634990215301514
Validation loss: 2.112997769027628

Epoch: 6| Step: 5
Training loss: 0.753585159778595
Validation loss: 2.0975264092927337

Epoch: 6| Step: 6
Training loss: 1.5023536682128906
Validation loss: 2.1332612012022283

Epoch: 6| Step: 7
Training loss: 1.141740322113037
Validation loss: 2.0916301896495204

Epoch: 6| Step: 8
Training loss: 1.8325555324554443
Validation loss: 2.047269526348319

Epoch: 6| Step: 9
Training loss: 1.1083471775054932
Validation loss: 2.055942622564172

Epoch: 6| Step: 10
Training loss: 1.7601944208145142
Validation loss: 2.0683127910860124

Epoch: 6| Step: 11
Training loss: 1.5209850072860718
Validation loss: 2.0362945782241

Epoch: 6| Step: 12
Training loss: 1.1090748310089111
Validation loss: 2.0335805800653275

Epoch: 6| Step: 13
Training loss: 0.9146429896354675
Validation loss: 2.0381015885260796

Epoch: 514| Step: 0
Training loss: 1.1941673755645752
Validation loss: 2.0121559225102907

Epoch: 6| Step: 1
Training loss: 1.6595650911331177
Validation loss: 2.0462532094729844

Epoch: 6| Step: 2
Training loss: 1.04839026927948
Validation loss: 2.03104018780493

Epoch: 6| Step: 3
Training loss: 1.1130874156951904
Validation loss: 2.0593498112053

Epoch: 6| Step: 4
Training loss: 0.9285813570022583
Validation loss: 2.0364610392560243

Epoch: 6| Step: 5
Training loss: 1.4201221466064453
Validation loss: 2.0946599091252973

Epoch: 6| Step: 6
Training loss: 1.0120189189910889
Validation loss: 2.0974363485972085

Epoch: 6| Step: 7
Training loss: 1.8061275482177734
Validation loss: 2.061780983401883

Epoch: 6| Step: 8
Training loss: 0.9251713752746582
Validation loss: 2.0686271370098157

Epoch: 6| Step: 9
Training loss: 1.63338041305542
Validation loss: 2.0700004639164096

Epoch: 6| Step: 10
Training loss: 1.3735895156860352
Validation loss: 2.0561060149182557

Epoch: 6| Step: 11
Training loss: 1.6067390441894531
Validation loss: 2.101629864784979

Epoch: 6| Step: 12
Training loss: 1.422903299331665
Validation loss: 2.0771892968044487

Epoch: 6| Step: 13
Training loss: 1.7874736785888672
Validation loss: 2.066342465339168

Epoch: 515| Step: 0
Training loss: 1.2068930864334106
Validation loss: 2.0530475185763453

Epoch: 6| Step: 1
Training loss: 0.8601258993148804
Validation loss: 2.0147338400604906

Epoch: 6| Step: 2
Training loss: 1.063581943511963
Validation loss: 2.0388113529451433

Epoch: 6| Step: 3
Training loss: 1.7495955228805542
Validation loss: 2.057958061977099

Epoch: 6| Step: 4
Training loss: 1.1971874237060547
Validation loss: 2.0533823223524195

Epoch: 6| Step: 5
Training loss: 1.6830370426177979
Validation loss: 2.0046425814269693

Epoch: 6| Step: 6
Training loss: 0.8169529438018799
Validation loss: 2.029655521915805

Epoch: 6| Step: 7
Training loss: 1.0080691576004028
Validation loss: 2.0329599752221057

Epoch: 6| Step: 8
Training loss: 1.6789281368255615
Validation loss: 1.9991495199100946

Epoch: 6| Step: 9
Training loss: 1.6615904569625854
Validation loss: 2.0490723553524224

Epoch: 6| Step: 10
Training loss: 1.8817640542984009
Validation loss: 2.019722407863986

Epoch: 6| Step: 11
Training loss: 1.0382555723190308
Validation loss: 2.004435611027543

Epoch: 6| Step: 12
Training loss: 1.125131368637085
Validation loss: 2.044698102499849

Epoch: 6| Step: 13
Training loss: 2.16017746925354
Validation loss: 2.0558319091796875

Epoch: 516| Step: 0
Training loss: 1.7555369138717651
Validation loss: 2.083347564102501

Epoch: 6| Step: 1
Training loss: 1.2509212493896484
Validation loss: 2.102646832825035

Epoch: 6| Step: 2
Training loss: 1.2968614101409912
Validation loss: 2.1004140556499524

Epoch: 6| Step: 3
Training loss: 0.8028830289840698
Validation loss: 2.105133142522586

Epoch: 6| Step: 4
Training loss: 1.2613394260406494
Validation loss: 2.1172375807198147

Epoch: 6| Step: 5
Training loss: 1.8652880191802979
Validation loss: 2.1014806224453833

Epoch: 6| Step: 6
Training loss: 1.4126170873641968
Validation loss: 2.0931363515956427

Epoch: 6| Step: 7
Training loss: 1.676863431930542
Validation loss: 2.0371794598076933

Epoch: 6| Step: 8
Training loss: 1.2963910102844238
Validation loss: 2.0338756063933014

Epoch: 6| Step: 9
Training loss: 1.1790411472320557
Validation loss: 2.03461064446357

Epoch: 6| Step: 10
Training loss: 1.1165143251419067
Validation loss: 2.043674261339249

Epoch: 6| Step: 11
Training loss: 1.1277289390563965
Validation loss: 2.063963536293276

Epoch: 6| Step: 12
Training loss: 1.124381422996521
Validation loss: 2.035918540852044

Epoch: 6| Step: 13
Training loss: 1.9680951833724976
Validation loss: 2.0329610801512197

Epoch: 517| Step: 0
Training loss: 0.8069047927856445
Validation loss: 2.0405978900130077

Epoch: 6| Step: 1
Training loss: 1.1003868579864502
Validation loss: 2.0333557116088046

Epoch: 6| Step: 2
Training loss: 1.4790714979171753
Validation loss: 2.021194710526415

Epoch: 6| Step: 3
Training loss: 1.571760654449463
Validation loss: 2.038178587472567

Epoch: 6| Step: 4
Training loss: 1.0765440464019775
Validation loss: 1.9844038089116414

Epoch: 6| Step: 5
Training loss: 1.4563817977905273
Validation loss: 2.0526642286649315

Epoch: 6| Step: 6
Training loss: 1.361770510673523
Validation loss: 2.010452392280743

Epoch: 6| Step: 7
Training loss: 1.394055724143982
Validation loss: 2.0412235465101016

Epoch: 6| Step: 8
Training loss: 1.2905292510986328
Validation loss: 2.04373243547255

Epoch: 6| Step: 9
Training loss: 1.4251916408538818
Validation loss: 2.021527627462982

Epoch: 6| Step: 10
Training loss: 1.9021804332733154
Validation loss: 2.05907916766341

Epoch: 6| Step: 11
Training loss: 1.3798047304153442
Validation loss: 2.07530056148447

Epoch: 6| Step: 12
Training loss: 1.28022301197052
Validation loss: 2.0932811037186654

Epoch: 6| Step: 13
Training loss: 1.0226613283157349
Validation loss: 2.105808832312143

Epoch: 518| Step: 0
Training loss: 1.7575914859771729
Validation loss: 2.132622689329168

Epoch: 6| Step: 1
Training loss: 1.4927055835723877
Validation loss: 2.06035194858428

Epoch: 6| Step: 2
Training loss: 1.8306005001068115
Validation loss: 2.056762795294485

Epoch: 6| Step: 3
Training loss: 0.9270134568214417
Validation loss: 2.0770005590172222

Epoch: 6| Step: 4
Training loss: 0.8570323586463928
Validation loss: 2.0666844844818115

Epoch: 6| Step: 5
Training loss: 1.477616786956787
Validation loss: 2.0326645887026222

Epoch: 6| Step: 6
Training loss: 1.3966281414031982
Validation loss: 2.04403825600942

Epoch: 6| Step: 7
Training loss: 1.307699203491211
Validation loss: 2.0811555975226947

Epoch: 6| Step: 8
Training loss: 1.3662116527557373
Validation loss: 2.029029287317748

Epoch: 6| Step: 9
Training loss: 1.3450677394866943
Validation loss: 2.065708306527907

Epoch: 6| Step: 10
Training loss: 1.3973267078399658
Validation loss: 2.038147880185035

Epoch: 6| Step: 11
Training loss: 1.1614022254943848
Validation loss: 2.0645802482481925

Epoch: 6| Step: 12
Training loss: 1.1619855165481567
Validation loss: 2.027181110074443

Epoch: 6| Step: 13
Training loss: 1.6804918050765991
Validation loss: 2.0337266614360194

Epoch: 519| Step: 0
Training loss: 1.0652189254760742
Validation loss: 2.0234781721586823

Epoch: 6| Step: 1
Training loss: 1.2364579439163208
Validation loss: 2.040479713870633

Epoch: 6| Step: 2
Training loss: 1.3852548599243164
Validation loss: 1.9889350962895218

Epoch: 6| Step: 3
Training loss: 2.0053210258483887
Validation loss: 1.9959252957374818

Epoch: 6| Step: 4
Training loss: 1.8869446516036987
Validation loss: 2.03210384615006

Epoch: 6| Step: 5
Training loss: 1.6428914070129395
Validation loss: 1.985583302795246

Epoch: 6| Step: 6
Training loss: 1.2926197052001953
Validation loss: 2.008979465371819

Epoch: 6| Step: 7
Training loss: 1.3854730129241943
Validation loss: 2.0089409376985286

Epoch: 6| Step: 8
Training loss: 1.2606256008148193
Validation loss: 2.0103184382120767

Epoch: 6| Step: 9
Training loss: 0.6440370082855225
Validation loss: 2.0387751158847602

Epoch: 6| Step: 10
Training loss: 1.5781837701797485
Validation loss: 2.059641102308868

Epoch: 6| Step: 11
Training loss: 0.9698982834815979
Validation loss: 2.0690951552442325

Epoch: 6| Step: 12
Training loss: 1.0183621644973755
Validation loss: 2.061780837274367

Epoch: 6| Step: 13
Training loss: 1.3470630645751953
Validation loss: 2.0379674832026162

Epoch: 520| Step: 0
Training loss: 1.5233083963394165
Validation loss: 2.0765923889734412

Epoch: 6| Step: 1
Training loss: 0.9245611429214478
Validation loss: 2.1196160316467285

Epoch: 6| Step: 2
Training loss: 1.9009140729904175
Validation loss: 2.0809155664136334

Epoch: 6| Step: 3
Training loss: 1.192726969718933
Validation loss: 2.077309403368222

Epoch: 6| Step: 4
Training loss: 1.3071246147155762
Validation loss: 2.0904714907369306

Epoch: 6| Step: 5
Training loss: 1.5906915664672852
Validation loss: 2.0837715441180813

Epoch: 6| Step: 6
Training loss: 1.4277523756027222
Validation loss: 2.047504009739045

Epoch: 6| Step: 7
Training loss: 1.3331434726715088
Validation loss: 2.0346365385158087

Epoch: 6| Step: 8
Training loss: 0.8095172643661499
Validation loss: 2.000111472222113

Epoch: 6| Step: 9
Training loss: 1.6651747226715088
Validation loss: 2.056846070033248

Epoch: 6| Step: 10
Training loss: 1.1917470693588257
Validation loss: 2.060039298508757

Epoch: 6| Step: 11
Training loss: 1.5616357326507568
Validation loss: 2.017888065307371

Epoch: 6| Step: 12
Training loss: 1.0758976936340332
Validation loss: 2.033567927216971

Epoch: 6| Step: 13
Training loss: 1.6835941076278687
Validation loss: 2.059360311877343

Epoch: 521| Step: 0
Training loss: 1.6312716007232666
Validation loss: 2.0234839570137764

Epoch: 6| Step: 1
Training loss: 1.3882315158843994
Validation loss: 2.058595775276102

Epoch: 6| Step: 2
Training loss: 1.4618107080459595
Validation loss: 2.0268277250310427

Epoch: 6| Step: 3
Training loss: 1.372676134109497
Validation loss: 2.036992044859035

Epoch: 6| Step: 4
Training loss: 1.1080842018127441
Validation loss: 2.0369101673044185

Epoch: 6| Step: 5
Training loss: 0.9163108468055725
Validation loss: 2.0625530083974204

Epoch: 6| Step: 6
Training loss: 1.2532024383544922
Validation loss: 2.090184916732132

Epoch: 6| Step: 7
Training loss: 1.1608755588531494
Validation loss: 2.0834489855715024

Epoch: 6| Step: 8
Training loss: 1.477332353591919
Validation loss: 2.1210494349079747

Epoch: 6| Step: 9
Training loss: 1.4781163930892944
Validation loss: 2.084042351732972

Epoch: 6| Step: 10
Training loss: 1.1384459733963013
Validation loss: 2.0962956002963486

Epoch: 6| Step: 11
Training loss: 1.7001073360443115
Validation loss: 2.0922394042373984

Epoch: 6| Step: 12
Training loss: 1.3160145282745361
Validation loss: 2.0812853279934136

Epoch: 6| Step: 13
Training loss: 0.991387128829956
Validation loss: 2.065652434543897

Epoch: 522| Step: 0
Training loss: 1.0056490898132324
Validation loss: 2.107497165280004

Epoch: 6| Step: 1
Training loss: 1.6918914318084717
Validation loss: 2.0698834132122736

Epoch: 6| Step: 2
Training loss: 1.3354918956756592
Validation loss: 2.0375703022044194

Epoch: 6| Step: 3
Training loss: 1.3444745540618896
Validation loss: 2.058350770704208

Epoch: 6| Step: 4
Training loss: 0.9210354089736938
Validation loss: 2.0710887626935075

Epoch: 6| Step: 5
Training loss: 1.2773864269256592
Validation loss: 2.036863434699274

Epoch: 6| Step: 6
Training loss: 1.1076972484588623
Validation loss: 2.0146649281183877

Epoch: 6| Step: 7
Training loss: 1.1788538694381714
Validation loss: 2.022563090888403

Epoch: 6| Step: 8
Training loss: 2.1677184104919434
Validation loss: 2.039684921182612

Epoch: 6| Step: 9
Training loss: 0.6935139298439026
Validation loss: 2.052391367573892

Epoch: 6| Step: 10
Training loss: 1.4097011089324951
Validation loss: 2.0592898502144763

Epoch: 6| Step: 11
Training loss: 1.6854578256607056
Validation loss: 2.0796476615372526

Epoch: 6| Step: 12
Training loss: 1.2938824892044067
Validation loss: 2.056549834948714

Epoch: 6| Step: 13
Training loss: 1.2882018089294434
Validation loss: 2.0956118619570168

Epoch: 523| Step: 0
Training loss: 1.17375910282135
Validation loss: 2.0613760114997945

Epoch: 6| Step: 1
Training loss: 1.454637885093689
Validation loss: 2.0344826098411315

Epoch: 6| Step: 2
Training loss: 1.427842140197754
Validation loss: 2.0622985657825263

Epoch: 6| Step: 3
Training loss: 0.6993619203567505
Validation loss: 2.0609808955141293

Epoch: 6| Step: 4
Training loss: 1.4733725786209106
Validation loss: 2.0590443111235097

Epoch: 6| Step: 5
Training loss: 1.427612066268921
Validation loss: 2.067986462705879

Epoch: 6| Step: 6
Training loss: 0.928963303565979
Validation loss: 2.0705951990619784

Epoch: 6| Step: 7
Training loss: 1.9768551588058472
Validation loss: 2.0133953837938208

Epoch: 6| Step: 8
Training loss: 0.80832439661026
Validation loss: 2.0560612934891895

Epoch: 6| Step: 9
Training loss: 1.2431761026382446
Validation loss: 2.0451963742574057

Epoch: 6| Step: 10
Training loss: 1.2581064701080322
Validation loss: 2.0594638803953766

Epoch: 6| Step: 11
Training loss: 2.0565834045410156
Validation loss: 2.013369407705081

Epoch: 6| Step: 12
Training loss: 1.3913311958312988
Validation loss: 2.056932412168031

Epoch: 6| Step: 13
Training loss: 1.4163870811462402
Validation loss: 2.034947636306927

Epoch: 524| Step: 0
Training loss: 1.592712163925171
Validation loss: 2.0165888981152604

Epoch: 6| Step: 1
Training loss: 1.2342228889465332
Validation loss: 2.0291601714267524

Epoch: 6| Step: 2
Training loss: 1.2642078399658203
Validation loss: 2.0601479058624594

Epoch: 6| Step: 3
Training loss: 1.7331154346466064
Validation loss: 2.0700001101340018

Epoch: 6| Step: 4
Training loss: 1.136075735092163
Validation loss: 2.0473488325713785

Epoch: 6| Step: 5
Training loss: 1.0795063972473145
Validation loss: 2.039130772313764

Epoch: 6| Step: 6
Training loss: 1.654289722442627
Validation loss: 2.039455889373697

Epoch: 6| Step: 7
Training loss: 0.8716163635253906
Validation loss: 2.041201978601435

Epoch: 6| Step: 8
Training loss: 1.5334091186523438
Validation loss: 2.0418579001580515

Epoch: 6| Step: 9
Training loss: 1.464263916015625
Validation loss: 2.097045120372567

Epoch: 6| Step: 10
Training loss: 1.2458515167236328
Validation loss: 2.063337859287057

Epoch: 6| Step: 11
Training loss: 0.9636017084121704
Validation loss: 2.099128520616921

Epoch: 6| Step: 12
Training loss: 1.454832673072815
Validation loss: 2.064477538549772

Epoch: 6| Step: 13
Training loss: 1.4560143947601318
Validation loss: 2.1236330565585884

Epoch: 525| Step: 0
Training loss: 0.811224639415741
Validation loss: 2.0949696033231673

Epoch: 6| Step: 1
Training loss: 1.4612516164779663
Validation loss: 2.149847069094258

Epoch: 6| Step: 2
Training loss: 1.8764435052871704
Validation loss: 2.108997619280251

Epoch: 6| Step: 3
Training loss: 0.9723119735717773
Validation loss: 2.1070343550815376

Epoch: 6| Step: 4
Training loss: 1.1232144832611084
Validation loss: 2.0837292799385647

Epoch: 6| Step: 5
Training loss: 0.9681308269500732
Validation loss: 2.0428057280919885

Epoch: 6| Step: 6
Training loss: 1.7110587358474731
Validation loss: 2.0457047159953783

Epoch: 6| Step: 7
Training loss: 1.2397651672363281
Validation loss: 2.0190447325347574

Epoch: 6| Step: 8
Training loss: 1.7813031673431396
Validation loss: 2.035142481967967

Epoch: 6| Step: 9
Training loss: 1.4628980159759521
Validation loss: 2.025645266297043

Epoch: 6| Step: 10
Training loss: 1.443363904953003
Validation loss: 2.0181403313913653

Epoch: 6| Step: 11
Training loss: 1.2803750038146973
Validation loss: 2.032209955235963

Epoch: 6| Step: 12
Training loss: 1.0867398977279663
Validation loss: 2.0206124051924674

Epoch: 6| Step: 13
Training loss: 1.9037638902664185
Validation loss: 2.020153760910034

Epoch: 526| Step: 0
Training loss: 1.2730387449264526
Validation loss: 2.015648836730629

Epoch: 6| Step: 1
Training loss: 1.1424509286880493
Validation loss: 2.05001369214827

Epoch: 6| Step: 2
Training loss: 1.3896600008010864
Validation loss: 2.02833495729713

Epoch: 6| Step: 3
Training loss: 1.1888633966445923
Validation loss: 2.078083348530595

Epoch: 6| Step: 4
Training loss: 1.5425918102264404
Validation loss: 2.0686420676528767

Epoch: 6| Step: 5
Training loss: 1.5162683725357056
Validation loss: 2.1095883589918896

Epoch: 6| Step: 6
Training loss: 1.1669410467147827
Validation loss: 2.0780660824109147

Epoch: 6| Step: 7
Training loss: 1.2976200580596924
Validation loss: 2.111728237521264

Epoch: 6| Step: 8
Training loss: 1.1427572965621948
Validation loss: 2.132877060162124

Epoch: 6| Step: 9
Training loss: 1.8376976251602173
Validation loss: 2.096235926433276

Epoch: 6| Step: 10
Training loss: 1.2741010189056396
Validation loss: 2.110862652460734

Epoch: 6| Step: 11
Training loss: 1.3252872228622437
Validation loss: 2.1680721570086736

Epoch: 6| Step: 12
Training loss: 0.9586687088012695
Validation loss: 2.094994955165412

Epoch: 6| Step: 13
Training loss: 1.4750852584838867
Validation loss: 2.08064938617009

Epoch: 527| Step: 0
Training loss: 1.1167335510253906
Validation loss: 2.09797086510607

Epoch: 6| Step: 1
Training loss: 1.2314133644104004
Validation loss: 2.089465579678935

Epoch: 6| Step: 2
Training loss: 1.753788709640503
Validation loss: 2.0365734049068984

Epoch: 6| Step: 3
Training loss: 1.0160026550292969
Validation loss: 2.050295945136778

Epoch: 6| Step: 4
Training loss: 1.1720035076141357
Validation loss: 2.067800703869071

Epoch: 6| Step: 5
Training loss: 1.6391843557357788
Validation loss: 2.0289431848833637

Epoch: 6| Step: 6
Training loss: 1.8557429313659668
Validation loss: 2.0069912595133625

Epoch: 6| Step: 7
Training loss: 1.6986064910888672
Validation loss: 2.0279891683209326

Epoch: 6| Step: 8
Training loss: 0.7908810973167419
Validation loss: 1.9852195350072717

Epoch: 6| Step: 9
Training loss: 1.2219291925430298
Validation loss: 2.0582277646628757

Epoch: 6| Step: 10
Training loss: 1.6192436218261719
Validation loss: 2.0192959206078642

Epoch: 6| Step: 11
Training loss: 1.1619168519973755
Validation loss: 2.0441514753526255

Epoch: 6| Step: 12
Training loss: 1.3729757070541382
Validation loss: 2.0144828955332437

Epoch: 6| Step: 13
Training loss: 1.3790452480316162
Validation loss: 2.0744459577786025

Epoch: 528| Step: 0
Training loss: 1.059914231300354
Validation loss: 2.100237613083214

Epoch: 6| Step: 1
Training loss: 1.3072021007537842
Validation loss: 2.0947842803052676

Epoch: 6| Step: 2
Training loss: 1.0786731243133545
Validation loss: 2.0896178086598716

Epoch: 6| Step: 3
Training loss: 1.6043657064437866
Validation loss: 2.0761547485987344

Epoch: 6| Step: 4
Training loss: 1.7039566040039062
Validation loss: 2.1232876662285096

Epoch: 6| Step: 5
Training loss: 0.9593974351882935
Validation loss: 2.105075151689591

Epoch: 6| Step: 6
Training loss: 1.2485922574996948
Validation loss: 2.1199969271177888

Epoch: 6| Step: 7
Training loss: 1.4314954280853271
Validation loss: 2.0607881494747695

Epoch: 6| Step: 8
Training loss: 1.5804169178009033
Validation loss: 2.0681301688635223

Epoch: 6| Step: 9
Training loss: 1.2236491441726685
Validation loss: 2.057995314239174

Epoch: 6| Step: 10
Training loss: 1.2780778408050537
Validation loss: 2.0503344971646547

Epoch: 6| Step: 11
Training loss: 1.5290253162384033
Validation loss: 2.013995225711535

Epoch: 6| Step: 12
Training loss: 1.307650089263916
Validation loss: 2.0036749455236618

Epoch: 6| Step: 13
Training loss: 1.1727958917617798
Validation loss: 2.039161169400779

Epoch: 529| Step: 0
Training loss: 1.2428667545318604
Validation loss: 2.029636042092436

Epoch: 6| Step: 1
Training loss: 1.954546332359314
Validation loss: 2.039601454170801

Epoch: 6| Step: 2
Training loss: 0.9172484278678894
Validation loss: 1.9912301724956882

Epoch: 6| Step: 3
Training loss: 1.8311231136322021
Validation loss: 2.024169497592475

Epoch: 6| Step: 4
Training loss: 1.0509302616119385
Validation loss: 2.0460418860117593

Epoch: 6| Step: 5
Training loss: 0.7603349685668945
Validation loss: 2.052655989123929

Epoch: 6| Step: 6
Training loss: 1.183628797531128
Validation loss: 2.0306502772915747

Epoch: 6| Step: 7
Training loss: 1.477748155593872
Validation loss: 2.051481816076463

Epoch: 6| Step: 8
Training loss: 0.9355793595314026
Validation loss: 2.049174319031418

Epoch: 6| Step: 9
Training loss: 1.1200716495513916
Validation loss: 2.075453988967403

Epoch: 6| Step: 10
Training loss: 1.7118558883666992
Validation loss: 2.0660770682878393

Epoch: 6| Step: 11
Training loss: 1.2832510471343994
Validation loss: 2.0389501497309697

Epoch: 6| Step: 12
Training loss: 1.1115236282348633
Validation loss: 2.086816897956274

Epoch: 6| Step: 13
Training loss: 2.341862678527832
Validation loss: 2.074221070094775

Epoch: 530| Step: 0
Training loss: 1.7278262376785278
Validation loss: 2.0556651417927077

Epoch: 6| Step: 1
Training loss: 0.7896069288253784
Validation loss: 2.0535045490469983

Epoch: 6| Step: 2
Training loss: 1.2986626625061035
Validation loss: 2.0448670617995726

Epoch: 6| Step: 3
Training loss: 0.9827175140380859
Validation loss: 2.05723479999009

Epoch: 6| Step: 4
Training loss: 1.2624616622924805
Validation loss: 2.0256488579575733

Epoch: 6| Step: 5
Training loss: 1.5224308967590332
Validation loss: 2.049953214583858

Epoch: 6| Step: 6
Training loss: 1.095094919204712
Validation loss: 2.031709974811923

Epoch: 6| Step: 7
Training loss: 1.3527626991271973
Validation loss: 2.056429701466714

Epoch: 6| Step: 8
Training loss: 1.4414329528808594
Validation loss: 2.0192310938271145

Epoch: 6| Step: 9
Training loss: 1.1635546684265137
Validation loss: 2.028617997323313

Epoch: 6| Step: 10
Training loss: 1.3858532905578613
Validation loss: 2.028126747377457

Epoch: 6| Step: 11
Training loss: 1.512120246887207
Validation loss: 2.0577575519520748

Epoch: 6| Step: 12
Training loss: 1.119065761566162
Validation loss: 2.040984853621452

Epoch: 6| Step: 13
Training loss: 2.2539188861846924
Validation loss: 2.028532281998665

Epoch: 531| Step: 0
Training loss: 1.0682613849639893
Validation loss: 2.015199681764008

Epoch: 6| Step: 1
Training loss: 1.5814186334609985
Validation loss: 2.0417788964445873

Epoch: 6| Step: 2
Training loss: 1.5754708051681519
Validation loss: 2.054630879432924

Epoch: 6| Step: 3
Training loss: 1.0771827697753906
Validation loss: 2.0682263220510175

Epoch: 6| Step: 4
Training loss: 2.034418821334839
Validation loss: 2.0436681393654115

Epoch: 6| Step: 5
Training loss: 1.1325440406799316
Validation loss: 2.081500662270413

Epoch: 6| Step: 6
Training loss: 0.9696269035339355
Validation loss: 2.049667371216641

Epoch: 6| Step: 7
Training loss: 1.5083868503570557
Validation loss: 2.029090731374679

Epoch: 6| Step: 8
Training loss: 1.1507959365844727
Validation loss: 2.0340785159859607

Epoch: 6| Step: 9
Training loss: 1.290479063987732
Validation loss: 2.0618955396836802

Epoch: 6| Step: 10
Training loss: 0.9936636686325073
Validation loss: 2.0588042402780182

Epoch: 6| Step: 11
Training loss: 0.7790178060531616
Validation loss: 2.0446279433465775

Epoch: 6| Step: 12
Training loss: 1.5244215726852417
Validation loss: 2.005547804217185

Epoch: 6| Step: 13
Training loss: 1.297698974609375
Validation loss: 2.087888735596852

Epoch: 532| Step: 0
Training loss: 0.910378634929657
Validation loss: 2.042708750694029

Epoch: 6| Step: 1
Training loss: 1.2488911151885986
Validation loss: 2.0827189286549888

Epoch: 6| Step: 2
Training loss: 1.1839547157287598
Validation loss: 2.0925654929171325

Epoch: 6| Step: 3
Training loss: 1.504463791847229
Validation loss: 2.059106998546149

Epoch: 6| Step: 4
Training loss: 1.5362887382507324
Validation loss: 2.0744468371073403

Epoch: 6| Step: 5
Training loss: 0.8636252880096436
Validation loss: 2.095682978630066

Epoch: 6| Step: 6
Training loss: 1.4636547565460205
Validation loss: 2.0354342178631852

Epoch: 6| Step: 7
Training loss: 1.1035053730010986
Validation loss: 2.07497468943237

Epoch: 6| Step: 8
Training loss: 1.446782112121582
Validation loss: 2.0270454396483717

Epoch: 6| Step: 9
Training loss: 1.392926573753357
Validation loss: 2.0911811936286187

Epoch: 6| Step: 10
Training loss: 1.527269959449768
Validation loss: 2.028163130565356

Epoch: 6| Step: 11
Training loss: 1.0918751955032349
Validation loss: 2.0244031234454085

Epoch: 6| Step: 12
Training loss: 1.7285082340240479
Validation loss: 2.0527091154488186

Epoch: 6| Step: 13
Training loss: 1.2837281227111816
Validation loss: 2.038112912126767

Epoch: 533| Step: 0
Training loss: 1.477736234664917
Validation loss: 2.0495616146313247

Epoch: 6| Step: 1
Training loss: 1.0615803003311157
Validation loss: 2.0905333334399807

Epoch: 6| Step: 2
Training loss: 1.3430681228637695
Validation loss: 2.0547943166507188

Epoch: 6| Step: 3
Training loss: 1.633392095565796
Validation loss: 2.0672707019313687

Epoch: 6| Step: 4
Training loss: 1.036957859992981
Validation loss: 2.0304369234269664

Epoch: 6| Step: 5
Training loss: 1.515960931777954
Validation loss: 2.0591879172991683

Epoch: 6| Step: 6
Training loss: 1.453094720840454
Validation loss: 2.0365686275625743

Epoch: 6| Step: 7
Training loss: 1.067693829536438
Validation loss: 1.998379502245175

Epoch: 6| Step: 8
Training loss: 1.1684086322784424
Validation loss: 2.0356685076990435

Epoch: 6| Step: 9
Training loss: 1.308478832244873
Validation loss: 2.0989944217025593

Epoch: 6| Step: 10
Training loss: 1.3355133533477783
Validation loss: 2.0345978313876736

Epoch: 6| Step: 11
Training loss: 1.4750945568084717
Validation loss: 2.040291291411205

Epoch: 6| Step: 12
Training loss: 1.0036877393722534
Validation loss: 2.035148718023813

Epoch: 6| Step: 13
Training loss: 1.3581104278564453
Validation loss: 2.0072760581970215

Epoch: 534| Step: 0
Training loss: 1.5946540832519531
Validation loss: 2.06856789640201

Epoch: 6| Step: 1
Training loss: 1.8759276866912842
Validation loss: 2.053114842343074

Epoch: 6| Step: 2
Training loss: 1.7500073909759521
Validation loss: 2.040267289325755

Epoch: 6| Step: 3
Training loss: 0.9526524543762207
Validation loss: 2.036582654522311

Epoch: 6| Step: 4
Training loss: 1.1614704132080078
Validation loss: 2.029998481914561

Epoch: 6| Step: 5
Training loss: 1.2490425109863281
Validation loss: 2.053636714976321

Epoch: 6| Step: 6
Training loss: 1.3112456798553467
Validation loss: 2.0331195451880015

Epoch: 6| Step: 7
Training loss: 0.9533018469810486
Validation loss: 2.027940055375458

Epoch: 6| Step: 8
Training loss: 1.047677993774414
Validation loss: 2.0715436576515116

Epoch: 6| Step: 9
Training loss: 1.5900676250457764
Validation loss: 2.0515688555214995

Epoch: 6| Step: 10
Training loss: 1.1833412647247314
Validation loss: 2.0555803250241023

Epoch: 6| Step: 11
Training loss: 1.2003222703933716
Validation loss: 2.041505954598868

Epoch: 6| Step: 12
Training loss: 1.6168911457061768
Validation loss: 2.0758955247940554

Epoch: 6| Step: 13
Training loss: 0.9375239610671997
Validation loss: 2.0636903457744147

Epoch: 535| Step: 0
Training loss: 0.824346661567688
Validation loss: 2.0610222252466346

Epoch: 6| Step: 1
Training loss: 1.248236894607544
Validation loss: 2.0443355806412233

Epoch: 6| Step: 2
Training loss: 0.48904579877853394
Validation loss: 2.077718263031334

Epoch: 6| Step: 3
Training loss: 1.5667223930358887
Validation loss: 2.0498513508868474

Epoch: 6| Step: 4
Training loss: 1.1740694046020508
Validation loss: 2.0340025578775713

Epoch: 6| Step: 5
Training loss: 1.2081654071807861
Validation loss: 2.0611435815852177

Epoch: 6| Step: 6
Training loss: 0.672756552696228
Validation loss: 2.0836472190836424

Epoch: 6| Step: 7
Training loss: 2.0566859245300293
Validation loss: 2.0353843896619734

Epoch: 6| Step: 8
Training loss: 1.5298576354980469
Validation loss: 2.032903625119117

Epoch: 6| Step: 9
Training loss: 1.7120811939239502
Validation loss: 2.023642854024005

Epoch: 6| Step: 10
Training loss: 1.285675048828125
Validation loss: 2.0872593464389926

Epoch: 6| Step: 11
Training loss: 1.7022144794464111
Validation loss: 2.041791113474036

Epoch: 6| Step: 12
Training loss: 1.5210460424423218
Validation loss: 2.02689714072853

Epoch: 6| Step: 13
Training loss: 1.6599106788635254
Validation loss: 2.0556300173523607

Epoch: 536| Step: 0
Training loss: 0.9129065275192261
Validation loss: 2.054902275403341

Epoch: 6| Step: 1
Training loss: 1.8454961776733398
Validation loss: 2.0229256281288723

Epoch: 6| Step: 2
Training loss: 1.3352065086364746
Validation loss: 2.046457952068698

Epoch: 6| Step: 3
Training loss: 1.2764532566070557
Validation loss: 2.0804013475295036

Epoch: 6| Step: 4
Training loss: 1.45609450340271
Validation loss: 2.0813378287899877

Epoch: 6| Step: 5
Training loss: 0.819875955581665
Validation loss: 2.0805711925670667

Epoch: 6| Step: 6
Training loss: 1.6977027654647827
Validation loss: 2.121270607876521

Epoch: 6| Step: 7
Training loss: 1.266531229019165
Validation loss: 2.095217853464106

Epoch: 6| Step: 8
Training loss: 1.1565709114074707
Validation loss: 2.0829894670876126

Epoch: 6| Step: 9
Training loss: 1.2734864950180054
Validation loss: 2.0625711794822448

Epoch: 6| Step: 10
Training loss: 1.5140955448150635
Validation loss: 2.0726216275204896

Epoch: 6| Step: 11
Training loss: 1.2440611124038696
Validation loss: 2.033525438718898

Epoch: 6| Step: 12
Training loss: 1.5294628143310547
Validation loss: 2.05286838675058

Epoch: 6| Step: 13
Training loss: 0.7669386863708496
Validation loss: 2.083508926053201

Epoch: 537| Step: 0
Training loss: 1.946972131729126
Validation loss: 2.0169764449519496

Epoch: 6| Step: 1
Training loss: 1.402165412902832
Validation loss: 2.06039628418543

Epoch: 6| Step: 2
Training loss: 0.9391878843307495
Validation loss: 2.0165325134031233

Epoch: 6| Step: 3
Training loss: 0.9401842355728149
Validation loss: 2.0753552080482565

Epoch: 6| Step: 4
Training loss: 0.6116956472396851
Validation loss: 1.9992039306189424

Epoch: 6| Step: 5
Training loss: 1.0349832773208618
Validation loss: 2.0356117038316626

Epoch: 6| Step: 6
Training loss: 1.2886621952056885
Validation loss: 2.035910460256761

Epoch: 6| Step: 7
Training loss: 1.4098124504089355
Validation loss: 2.028620840400778

Epoch: 6| Step: 8
Training loss: 1.3923777341842651
Validation loss: 2.00898064080105

Epoch: 6| Step: 9
Training loss: 1.6116153001785278
Validation loss: 2.050807155588622

Epoch: 6| Step: 10
Training loss: 1.7552462816238403
Validation loss: 2.014620780944824

Epoch: 6| Step: 11
Training loss: 1.5007665157318115
Validation loss: 2.0548890713722474

Epoch: 6| Step: 12
Training loss: 1.219254732131958
Validation loss: 2.0137685716793103

Epoch: 6| Step: 13
Training loss: 1.3140097856521606
Validation loss: 2.013240019480387

Epoch: 538| Step: 0
Training loss: 1.51329505443573
Validation loss: 2.013575155247924

Epoch: 6| Step: 1
Training loss: 0.6399784088134766
Validation loss: 2.0255750635618806

Epoch: 6| Step: 2
Training loss: 0.881987988948822
Validation loss: 2.05321946964469

Epoch: 6| Step: 3
Training loss: 1.7658045291900635
Validation loss: 2.0138024514721287

Epoch: 6| Step: 4
Training loss: 1.959824562072754
Validation loss: 2.044567374772923

Epoch: 6| Step: 5
Training loss: 0.9978893399238586
Validation loss: 2.030762226350846

Epoch: 6| Step: 6
Training loss: 1.570230484008789
Validation loss: 2.000028212865194

Epoch: 6| Step: 7
Training loss: 1.1796373128890991
Validation loss: 2.038174166474291

Epoch: 6| Step: 8
Training loss: 1.5629448890686035
Validation loss: 2.034811085270297

Epoch: 6| Step: 9
Training loss: 1.6040502786636353
Validation loss: 2.051369925980927

Epoch: 6| Step: 10
Training loss: 1.5206879377365112
Validation loss: 2.0366785731366885

Epoch: 6| Step: 11
Training loss: 0.5377789735794067
Validation loss: 2.0710531742342058

Epoch: 6| Step: 12
Training loss: 1.3744428157806396
Validation loss: 2.0537462606224963

Epoch: 6| Step: 13
Training loss: 0.8506143093109131
Validation loss: 2.0571261016271447

Epoch: 539| Step: 0
Training loss: 1.4030115604400635
Validation loss: 2.0282476935335385

Epoch: 6| Step: 1
Training loss: 1.0831422805786133
Validation loss: 2.0472381473869405

Epoch: 6| Step: 2
Training loss: 1.5178632736206055
Validation loss: 2.007803511875932

Epoch: 6| Step: 3
Training loss: 0.7693536281585693
Validation loss: 2.0513872292733963

Epoch: 6| Step: 4
Training loss: 1.257143259048462
Validation loss: 2.0438929398854575

Epoch: 6| Step: 5
Training loss: 1.5815205574035645
Validation loss: 2.0482322964617

Epoch: 6| Step: 6
Training loss: 1.2138686180114746
Validation loss: 2.0133540489340342

Epoch: 6| Step: 7
Training loss: 1.8764820098876953
Validation loss: 2.0370082842406405

Epoch: 6| Step: 8
Training loss: 1.199243187904358
Validation loss: 2.014564621833063

Epoch: 6| Step: 9
Training loss: 1.2893128395080566
Validation loss: 2.050100179128749

Epoch: 6| Step: 10
Training loss: 1.5679205656051636
Validation loss: 2.060388402272296

Epoch: 6| Step: 11
Training loss: 1.0579026937484741
Validation loss: 2.1075419020909134

Epoch: 6| Step: 12
Training loss: 1.2375327348709106
Validation loss: 2.039246848834458

Epoch: 6| Step: 13
Training loss: 1.2055237293243408
Validation loss: 2.0257427154048795

Epoch: 540| Step: 0
Training loss: 1.053382158279419
Validation loss: 2.0694936962537867

Epoch: 6| Step: 1
Training loss: 1.382613182067871
Validation loss: 2.0911644428007063

Epoch: 6| Step: 2
Training loss: 1.468631625175476
Validation loss: 2.041633685429891

Epoch: 6| Step: 3
Training loss: 0.965254545211792
Validation loss: 2.0725651146263204

Epoch: 6| Step: 4
Training loss: 1.3431799411773682
Validation loss: 2.0393129574355258

Epoch: 6| Step: 5
Training loss: 1.1392581462860107
Validation loss: 2.081325561769547

Epoch: 6| Step: 6
Training loss: 0.9964724779129028
Validation loss: 2.0300230210827244

Epoch: 6| Step: 7
Training loss: 1.3045637607574463
Validation loss: 2.052726358495733

Epoch: 6| Step: 8
Training loss: 1.1169462203979492
Validation loss: 2.0500900066027077

Epoch: 6| Step: 9
Training loss: 1.2278645038604736
Validation loss: 2.0504139315697456

Epoch: 6| Step: 10
Training loss: 1.3686548471450806
Validation loss: 2.041861876364677

Epoch: 6| Step: 11
Training loss: 1.9946587085723877
Validation loss: 2.0278099762496127

Epoch: 6| Step: 12
Training loss: 1.4797372817993164
Validation loss: 2.030715723191538

Epoch: 6| Step: 13
Training loss: 1.8595004081726074
Validation loss: 2.003323224283034

Epoch: 541| Step: 0
Training loss: 1.2780389785766602
Validation loss: 2.034615461544324

Epoch: 6| Step: 1
Training loss: 1.1806914806365967
Validation loss: 2.017519538120557

Epoch: 6| Step: 2
Training loss: 1.287980079650879
Validation loss: 2.0147127835981307

Epoch: 6| Step: 3
Training loss: 1.688760757446289
Validation loss: 2.0432222876497494

Epoch: 6| Step: 4
Training loss: 1.15975022315979
Validation loss: 1.9998043596103627

Epoch: 6| Step: 5
Training loss: 1.049258828163147
Validation loss: 2.0170504816116823

Epoch: 6| Step: 6
Training loss: 1.3091514110565186
Validation loss: 2.039662135544644

Epoch: 6| Step: 7
Training loss: 1.6196167469024658
Validation loss: 2.0528294886312177

Epoch: 6| Step: 8
Training loss: 1.1653754711151123
Validation loss: 2.0663366445931057

Epoch: 6| Step: 9
Training loss: 1.0333551168441772
Validation loss: 2.0897192262834117

Epoch: 6| Step: 10
Training loss: 1.231788158416748
Validation loss: 2.070940914974418

Epoch: 6| Step: 11
Training loss: 1.535027265548706
Validation loss: 2.0743978715712026

Epoch: 6| Step: 12
Training loss: 1.3877184391021729
Validation loss: 2.0990365833364506

Epoch: 6| Step: 13
Training loss: 2.0517971515655518
Validation loss: 2.115158368182439

Epoch: 542| Step: 0
Training loss: 1.696096420288086
Validation loss: 2.1341242149312007

Epoch: 6| Step: 1
Training loss: 0.8521336317062378
Validation loss: 2.0914954523886404

Epoch: 6| Step: 2
Training loss: 1.3585658073425293
Validation loss: 2.090368898965979

Epoch: 6| Step: 3
Training loss: 1.0576976537704468
Validation loss: 2.1040289837826966

Epoch: 6| Step: 4
Training loss: 1.2713172435760498
Validation loss: 2.080002023327735

Epoch: 6| Step: 5
Training loss: 0.6746764779090881
Validation loss: 2.0559024964609454

Epoch: 6| Step: 6
Training loss: 1.5121060609817505
Validation loss: 2.031975128317392

Epoch: 6| Step: 7
Training loss: 1.5025990009307861
Validation loss: 2.0573910808050506

Epoch: 6| Step: 8
Training loss: 1.7499785423278809
Validation loss: 2.0371128538603425

Epoch: 6| Step: 9
Training loss: 1.7731378078460693
Validation loss: 2.0179406622404694

Epoch: 6| Step: 10
Training loss: 1.4602153301239014
Validation loss: 2.0322227644663986

Epoch: 6| Step: 11
Training loss: 1.4545530080795288
Validation loss: 1.99844180896718

Epoch: 6| Step: 12
Training loss: 1.011497974395752
Validation loss: 2.024251986575383

Epoch: 6| Step: 13
Training loss: 1.0125839710235596
Validation loss: 2.0491536663424585

Epoch: 543| Step: 0
Training loss: 0.9648864269256592
Validation loss: 2.0674041112264

Epoch: 6| Step: 1
Training loss: 0.996983528137207
Validation loss: 2.0910493558452976

Epoch: 6| Step: 2
Training loss: 1.4828131198883057
Validation loss: 2.004676572738155

Epoch: 6| Step: 3
Training loss: 1.2211086750030518
Validation loss: 2.052270212481099

Epoch: 6| Step: 4
Training loss: 1.3560580015182495
Validation loss: 2.095798028412686

Epoch: 6| Step: 5
Training loss: 0.9908086657524109
Validation loss: 2.080054757415607

Epoch: 6| Step: 6
Training loss: 1.2322516441345215
Validation loss: 2.0652861428517166

Epoch: 6| Step: 7
Training loss: 1.7250642776489258
Validation loss: 2.038726233666943

Epoch: 6| Step: 8
Training loss: 0.7867629528045654
Validation loss: 2.0432945784702095

Epoch: 6| Step: 9
Training loss: 1.299102544784546
Validation loss: 2.042898675446869

Epoch: 6| Step: 10
Training loss: 1.317920207977295
Validation loss: 2.026632173087007

Epoch: 6| Step: 11
Training loss: 1.4687201976776123
Validation loss: 2.0583109496742167

Epoch: 6| Step: 12
Training loss: 1.6375410556793213
Validation loss: 2.061593037779613

Epoch: 6| Step: 13
Training loss: 1.3786410093307495
Validation loss: 2.0793440136858212

Epoch: 544| Step: 0
Training loss: 1.0065746307373047
Validation loss: 2.0609527172580844

Epoch: 6| Step: 1
Training loss: 1.886470079421997
Validation loss: 2.046774273277611

Epoch: 6| Step: 2
Training loss: 0.7801147103309631
Validation loss: 2.0339932351984005

Epoch: 6| Step: 3
Training loss: 1.2814542055130005
Validation loss: 2.0463627397373156

Epoch: 6| Step: 4
Training loss: 1.2692835330963135
Validation loss: 2.036805591275615

Epoch: 6| Step: 5
Training loss: 1.2771105766296387
Validation loss: 2.0488847673580213

Epoch: 6| Step: 6
Training loss: 1.33194899559021
Validation loss: 2.052048296056768

Epoch: 6| Step: 7
Training loss: 1.4363341331481934
Validation loss: 2.0649915638790337

Epoch: 6| Step: 8
Training loss: 0.8688585758209229
Validation loss: 2.0477379701470815

Epoch: 6| Step: 9
Training loss: 1.0704281330108643
Validation loss: 2.017763296763102

Epoch: 6| Step: 10
Training loss: 1.7215017080307007
Validation loss: 2.02336294997123

Epoch: 6| Step: 11
Training loss: 1.844343662261963
Validation loss: 2.0064769406472482

Epoch: 6| Step: 12
Training loss: 1.2873117923736572
Validation loss: 2.0616904240782543

Epoch: 6| Step: 13
Training loss: 0.7548478245735168
Validation loss: 2.0579858492779475

Epoch: 545| Step: 0
Training loss: 1.358309268951416
Validation loss: 2.076875258517522

Epoch: 6| Step: 1
Training loss: 1.0484778881072998
Validation loss: 2.077613979257563

Epoch: 6| Step: 2
Training loss: 1.2638132572174072
Validation loss: 2.063865056601904

Epoch: 6| Step: 3
Training loss: 1.3640130758285522
Validation loss: 2.0905235531509563

Epoch: 6| Step: 4
Training loss: 1.1720497608184814
Validation loss: 2.0216288771680606

Epoch: 6| Step: 5
Training loss: 1.0450327396392822
Validation loss: 2.068197102956874

Epoch: 6| Step: 6
Training loss: 1.2512836456298828
Validation loss: 2.039649296832341

Epoch: 6| Step: 7
Training loss: 1.68812894821167
Validation loss: 1.9769236451836043

Epoch: 6| Step: 8
Training loss: 1.7571382522583008
Validation loss: 2.0008906190113356

Epoch: 6| Step: 9
Training loss: 1.0762572288513184
Validation loss: 2.039057920056005

Epoch: 6| Step: 10
Training loss: 1.1683017015457153
Validation loss: 2.020901744083692

Epoch: 6| Step: 11
Training loss: 0.8052656650543213
Validation loss: 2.045409897322296

Epoch: 6| Step: 12
Training loss: 1.8414666652679443
Validation loss: 2.031685188252439

Epoch: 6| Step: 13
Training loss: 1.2122981548309326
Validation loss: 2.0404081318968084

Epoch: 546| Step: 0
Training loss: 0.6921749711036682
Validation loss: 2.030935618185228

Epoch: 6| Step: 1
Training loss: 1.1440004110336304
Validation loss: 2.0575143906377975

Epoch: 6| Step: 2
Training loss: 1.257598638534546
Validation loss: 2.029249491230134

Epoch: 6| Step: 3
Training loss: 0.8645402193069458
Validation loss: 2.092802543793955

Epoch: 6| Step: 4
Training loss: 1.3024673461914062
Validation loss: 2.0494577884674072

Epoch: 6| Step: 5
Training loss: 0.994849443435669
Validation loss: 2.04817376085507

Epoch: 6| Step: 6
Training loss: 1.1876553297042847
Validation loss: 2.0663759400767665

Epoch: 6| Step: 7
Training loss: 2.289788246154785
Validation loss: 2.0752704656252297

Epoch: 6| Step: 8
Training loss: 1.6984100341796875
Validation loss: 2.061666052828553

Epoch: 6| Step: 9
Training loss: 0.806165874004364
Validation loss: 2.0746126533836446

Epoch: 6| Step: 10
Training loss: 1.2750623226165771
Validation loss: 2.0656112086388374

Epoch: 6| Step: 11
Training loss: 1.4838979244232178
Validation loss: 2.064581301904494

Epoch: 6| Step: 12
Training loss: 1.533015489578247
Validation loss: 2.0786743343517347

Epoch: 6| Step: 13
Training loss: 2.1051247119903564
Validation loss: 2.0237372921359156

Epoch: 547| Step: 0
Training loss: 0.6152859330177307
Validation loss: 2.0657198198380007

Epoch: 6| Step: 1
Training loss: 1.3001625537872314
Validation loss: 2.0666617155075073

Epoch: 6| Step: 2
Training loss: 0.5264511108398438
Validation loss: 2.0587952918903802

Epoch: 6| Step: 3
Training loss: 1.2372456789016724
Validation loss: 2.0473035945687243

Epoch: 6| Step: 4
Training loss: 1.575347900390625
Validation loss: 2.0511194852090653

Epoch: 6| Step: 5
Training loss: 1.18898344039917
Validation loss: 2.03463238798162

Epoch: 6| Step: 6
Training loss: 1.605079174041748
Validation loss: 2.07117727751373

Epoch: 6| Step: 7
Training loss: 1.814756155014038
Validation loss: 2.05436812421327

Epoch: 6| Step: 8
Training loss: 1.1317583322525024
Validation loss: 2.0545340853352703

Epoch: 6| Step: 9
Training loss: 1.582054853439331
Validation loss: 2.098784472352715

Epoch: 6| Step: 10
Training loss: 1.9014058113098145
Validation loss: 2.070582133467479

Epoch: 6| Step: 11
Training loss: 1.122025728225708
Validation loss: 2.0822508399204542

Epoch: 6| Step: 12
Training loss: 1.3160157203674316
Validation loss: 2.111451948842695

Epoch: 6| Step: 13
Training loss: 1.2265563011169434
Validation loss: 2.1583805161137737

Epoch: 548| Step: 0
Training loss: 1.7697032690048218
Validation loss: 2.128423583122992

Epoch: 6| Step: 1
Training loss: 1.142319917678833
Validation loss: 2.0945545896407096

Epoch: 6| Step: 2
Training loss: 1.5954694747924805
Validation loss: 2.1176737995557886

Epoch: 6| Step: 3
Training loss: 0.8503745198249817
Validation loss: 2.0967372553322905

Epoch: 6| Step: 4
Training loss: 1.292669415473938
Validation loss: 2.1136617801522695

Epoch: 6| Step: 5
Training loss: 1.0174622535705566
Validation loss: 2.061974980497873

Epoch: 6| Step: 6
Training loss: 1.973206639289856
Validation loss: 2.000467041487335

Epoch: 6| Step: 7
Training loss: 1.3620482683181763
Validation loss: 2.0590313685837613

Epoch: 6| Step: 8
Training loss: 1.9792689085006714
Validation loss: 2.0245256577768633

Epoch: 6| Step: 9
Training loss: 1.3535616397857666
Validation loss: 2.0542887692810385

Epoch: 6| Step: 10
Training loss: 0.6356723308563232
Validation loss: 2.044677326756139

Epoch: 6| Step: 11
Training loss: 0.8751910328865051
Validation loss: 2.008670522320655

Epoch: 6| Step: 12
Training loss: 0.9506402015686035
Validation loss: 1.99719072926429

Epoch: 6| Step: 13
Training loss: 1.6222676038742065
Validation loss: 2.003233923706957

Epoch: 549| Step: 0
Training loss: 1.0825265645980835
Validation loss: 2.004550401882459

Epoch: 6| Step: 1
Training loss: 1.1426939964294434
Validation loss: 2.0317647431486394

Epoch: 6| Step: 2
Training loss: 0.9946582913398743
Validation loss: 2.049318023907241

Epoch: 6| Step: 3
Training loss: 1.1617017984390259
Validation loss: 2.0271642797736713

Epoch: 6| Step: 4
Training loss: 1.4308528900146484
Validation loss: 2.009765963400564

Epoch: 6| Step: 5
Training loss: 1.2675373554229736
Validation loss: 2.0410619217862367

Epoch: 6| Step: 6
Training loss: 1.2146140336990356
Validation loss: 2.061109427482851

Epoch: 6| Step: 7
Training loss: 2.051828145980835
Validation loss: 2.0481806826847855

Epoch: 6| Step: 8
Training loss: 0.9784656763076782
Validation loss: 2.063487870718843

Epoch: 6| Step: 9
Training loss: 1.2406396865844727
Validation loss: 2.076627322422561

Epoch: 6| Step: 10
Training loss: 1.9526455402374268
Validation loss: 2.083525365398776

Epoch: 6| Step: 11
Training loss: 1.2335879802703857
Validation loss: 2.0370425255067888

Epoch: 6| Step: 12
Training loss: 1.2569758892059326
Validation loss: 2.05580428723366

Epoch: 6| Step: 13
Training loss: 0.9555280208587646
Validation loss: 2.069139663891126

Epoch: 550| Step: 0
Training loss: 0.9340912103652954
Validation loss: 2.010277408425526

Epoch: 6| Step: 1
Training loss: 1.1868177652359009
Validation loss: 2.053049748943698

Epoch: 6| Step: 2
Training loss: 1.5685865879058838
Validation loss: 2.0642409234918575

Epoch: 6| Step: 3
Training loss: 1.528756022453308
Validation loss: 2.0446140073960826

Epoch: 6| Step: 4
Training loss: 1.6300413608551025
Validation loss: 2.0974632309329126

Epoch: 6| Step: 5
Training loss: 1.3878333568572998
Validation loss: 2.0555695846516597

Epoch: 6| Step: 6
Training loss: 1.283577561378479
Validation loss: 2.0726768906398485

Epoch: 6| Step: 7
Training loss: 0.9599040746688843
Validation loss: 2.06085543991417

Epoch: 6| Step: 8
Training loss: 1.1550307273864746
Validation loss: 2.0233328188619306

Epoch: 6| Step: 9
Training loss: 1.2219831943511963
Validation loss: 2.073516838012203

Epoch: 6| Step: 10
Training loss: 1.4613418579101562
Validation loss: 2.0786616674033542

Epoch: 6| Step: 11
Training loss: 1.4185400009155273
Validation loss: 2.113041739309988

Epoch: 6| Step: 12
Training loss: 1.131206750869751
Validation loss: 2.034504726368894

Epoch: 6| Step: 13
Training loss: 0.5881505608558655
Validation loss: 2.0202733150092502

Epoch: 551| Step: 0
Training loss: 1.437870740890503
Validation loss: 2.0652699214155956

Epoch: 6| Step: 1
Training loss: 1.1395214796066284
Validation loss: 2.0370832207382366

Epoch: 6| Step: 2
Training loss: 1.2100319862365723
Validation loss: 2.0653717569125596

Epoch: 6| Step: 3
Training loss: 1.2391397953033447
Validation loss: 2.0492663216847244

Epoch: 6| Step: 4
Training loss: 1.9921071529388428
Validation loss: 2.033280057291831

Epoch: 6| Step: 5
Training loss: 0.5889756679534912
Validation loss: 2.065935721961401

Epoch: 6| Step: 6
Training loss: 1.3778249025344849
Validation loss: 2.0674413686157553

Epoch: 6| Step: 7
Training loss: 1.1708908081054688
Validation loss: 2.0470446591736167

Epoch: 6| Step: 8
Training loss: 1.0160069465637207
Validation loss: 2.0638217003114763

Epoch: 6| Step: 9
Training loss: 1.4258198738098145
Validation loss: 2.023308801394637

Epoch: 6| Step: 10
Training loss: 1.3857312202453613
Validation loss: 2.0471113727938746

Epoch: 6| Step: 11
Training loss: 0.9627084732055664
Validation loss: 2.0229156196758313

Epoch: 6| Step: 12
Training loss: 1.630728006362915
Validation loss: 2.0414127175525953

Epoch: 6| Step: 13
Training loss: 1.2531869411468506
Validation loss: 2.0504498276659238

Epoch: 552| Step: 0
Training loss: 1.8762226104736328
Validation loss: 2.0416970804173458

Epoch: 6| Step: 1
Training loss: 1.4548678398132324
Validation loss: 2.059673715663213

Epoch: 6| Step: 2
Training loss: 1.0291469097137451
Validation loss: 2.0137002596291165

Epoch: 6| Step: 3
Training loss: 1.1753325462341309
Validation loss: 2.028111719316052

Epoch: 6| Step: 4
Training loss: 1.3340030908584595
Validation loss: 2.03622373970606

Epoch: 6| Step: 5
Training loss: 1.9690121412277222
Validation loss: 2.0769191890634517

Epoch: 6| Step: 6
Training loss: 1.2838962078094482
Validation loss: 2.0331734611142065

Epoch: 6| Step: 7
Training loss: 0.5293253660202026
Validation loss: 2.0614286597057054

Epoch: 6| Step: 8
Training loss: 1.0085769891738892
Validation loss: 2.038247375078099

Epoch: 6| Step: 9
Training loss: 1.2774639129638672
Validation loss: 2.036170954345375

Epoch: 6| Step: 10
Training loss: 1.28432035446167
Validation loss: 2.0447885759415163

Epoch: 6| Step: 11
Training loss: 1.0696711540222168
Validation loss: 2.0766758803398377

Epoch: 6| Step: 12
Training loss: 1.401843547821045
Validation loss: 2.0412327717709284

Epoch: 6| Step: 13
Training loss: 1.0635030269622803
Validation loss: 2.0603323572425434

Epoch: 553| Step: 0
Training loss: 1.826554536819458
Validation loss: 2.0802766097489225

Epoch: 6| Step: 1
Training loss: 0.7450992465019226
Validation loss: 2.0444151393828855

Epoch: 6| Step: 2
Training loss: 0.9070762991905212
Validation loss: 2.0502038258378223

Epoch: 6| Step: 3
Training loss: 1.3373149633407593
Validation loss: 2.013735386633104

Epoch: 6| Step: 4
Training loss: 2.1111292839050293
Validation loss: 2.046796706414992

Epoch: 6| Step: 5
Training loss: 1.4373571872711182
Validation loss: 2.0421996680639123

Epoch: 6| Step: 6
Training loss: 1.3423206806182861
Validation loss: 2.0320694984928256

Epoch: 6| Step: 7
Training loss: 0.8493924140930176
Validation loss: 2.038643152483048

Epoch: 6| Step: 8
Training loss: 1.2694571018218994
Validation loss: 2.0334570715504308

Epoch: 6| Step: 9
Training loss: 1.1182076930999756
Validation loss: 2.0295472529626664

Epoch: 6| Step: 10
Training loss: 1.4826058149337769
Validation loss: 2.033167815977527

Epoch: 6| Step: 11
Training loss: 0.8639048337936401
Validation loss: 2.0509394753363823

Epoch: 6| Step: 12
Training loss: 1.1690902709960938
Validation loss: 2.0640496130912536

Epoch: 6| Step: 13
Training loss: 1.5684010982513428
Validation loss: 2.0614203817100933

Epoch: 554| Step: 0
Training loss: 1.0593541860580444
Validation loss: 2.0837587823149977

Epoch: 6| Step: 1
Training loss: 0.6788783073425293
Validation loss: 2.004258458332349

Epoch: 6| Step: 2
Training loss: 1.397642731666565
Validation loss: 2.0596397794703

Epoch: 6| Step: 3
Training loss: 1.2048771381378174
Validation loss: 2.0098747053454

Epoch: 6| Step: 4
Training loss: 1.4469562768936157
Validation loss: 2.020112363241052

Epoch: 6| Step: 5
Training loss: 1.057180404663086
Validation loss: 2.056897947865148

Epoch: 6| Step: 6
Training loss: 0.9472965598106384
Validation loss: 2.034278542764725

Epoch: 6| Step: 7
Training loss: 1.5466687679290771
Validation loss: 2.0582608458816365

Epoch: 6| Step: 8
Training loss: 1.4445955753326416
Validation loss: 2.0208406756001134

Epoch: 6| Step: 9
Training loss: 1.2701979875564575
Validation loss: 2.046634743290563

Epoch: 6| Step: 10
Training loss: 1.3770549297332764
Validation loss: 2.042799957336918

Epoch: 6| Step: 11
Training loss: 1.5573804378509521
Validation loss: 2.064026230125017

Epoch: 6| Step: 12
Training loss: 1.6580615043640137
Validation loss: 2.045339589477867

Epoch: 6| Step: 13
Training loss: 0.8577365875244141
Validation loss: 2.0321161759796964

Epoch: 555| Step: 0
Training loss: 1.438844919204712
Validation loss: 2.07726893501897

Epoch: 6| Step: 1
Training loss: 1.6747698783874512
Validation loss: 2.011196285165766

Epoch: 6| Step: 2
Training loss: 1.220905065536499
Validation loss: 2.0679646127967426

Epoch: 6| Step: 3
Training loss: 1.1323347091674805
Validation loss: 2.056575693109984

Epoch: 6| Step: 4
Training loss: 1.069839358329773
Validation loss: 2.0405223241416355

Epoch: 6| Step: 5
Training loss: 1.2511425018310547
Validation loss: 2.0158533242440995

Epoch: 6| Step: 6
Training loss: 1.445670247077942
Validation loss: 2.0361142094417284

Epoch: 6| Step: 7
Training loss: 1.20835542678833
Validation loss: 2.0702221316675984

Epoch: 6| Step: 8
Training loss: 1.172255039215088
Validation loss: 2.047700148756786

Epoch: 6| Step: 9
Training loss: 1.003321647644043
Validation loss: 2.0785682124476277

Epoch: 6| Step: 10
Training loss: 1.1475377082824707
Validation loss: 2.068127966696216

Epoch: 6| Step: 11
Training loss: 1.5042046308517456
Validation loss: 2.0540574160955285

Epoch: 6| Step: 12
Training loss: 1.3985625505447388
Validation loss: 2.056937879131686

Epoch: 6| Step: 13
Training loss: 0.8609600067138672
Validation loss: 2.0675756264758367

Epoch: 556| Step: 0
Training loss: 1.6771295070648193
Validation loss: 2.053405500227405

Epoch: 6| Step: 1
Training loss: 1.2692807912826538
Validation loss: 2.090313987065387

Epoch: 6| Step: 2
Training loss: 1.282677412033081
Validation loss: 2.041792633712933

Epoch: 6| Step: 3
Training loss: 1.5326972007751465
Validation loss: 2.049469304341142

Epoch: 6| Step: 4
Training loss: 0.8488953113555908
Validation loss: 2.0252950191497803

Epoch: 6| Step: 5
Training loss: 1.3650131225585938
Validation loss: 2.0277207077190442

Epoch: 6| Step: 6
Training loss: 1.7228305339813232
Validation loss: 2.0239218178615777

Epoch: 6| Step: 7
Training loss: 1.341768503189087
Validation loss: 2.039134781847718

Epoch: 6| Step: 8
Training loss: 0.6540859937667847
Validation loss: 2.034963056605349

Epoch: 6| Step: 9
Training loss: 1.358741283416748
Validation loss: 2.036550344959382

Epoch: 6| Step: 10
Training loss: 0.6425578594207764
Validation loss: 2.0064101014085995

Epoch: 6| Step: 11
Training loss: 1.1448394060134888
Validation loss: 2.0244824937594834

Epoch: 6| Step: 12
Training loss: 1.4902794361114502
Validation loss: 2.0626051015751337

Epoch: 6| Step: 13
Training loss: 1.4142342805862427
Validation loss: 2.070900709398331

Epoch: 557| Step: 0
Training loss: 1.788148283958435
Validation loss: 2.094085629268359

Epoch: 6| Step: 1
Training loss: 0.9261783361434937
Validation loss: 2.0695623941318964

Epoch: 6| Step: 2
Training loss: 1.1302005052566528
Validation loss: 2.0658466610857236

Epoch: 6| Step: 3
Training loss: 1.7462882995605469
Validation loss: 2.0756622373416858

Epoch: 6| Step: 4
Training loss: 1.2500686645507812
Validation loss: 2.0987328021757063

Epoch: 6| Step: 5
Training loss: 1.2858901023864746
Validation loss: 2.0911299515795965

Epoch: 6| Step: 6
Training loss: 1.2561450004577637
Validation loss: 2.1074308272330993

Epoch: 6| Step: 7
Training loss: 1.014338493347168
Validation loss: 2.0637801103694464

Epoch: 6| Step: 8
Training loss: 1.5196927785873413
Validation loss: 2.0469945835810837

Epoch: 6| Step: 9
Training loss: 1.508847713470459
Validation loss: 2.0606620363009873

Epoch: 6| Step: 10
Training loss: 1.0476446151733398
Validation loss: 2.0250268315756195

Epoch: 6| Step: 11
Training loss: 1.1080222129821777
Validation loss: 2.0437996848937003

Epoch: 6| Step: 12
Training loss: 0.8924828767776489
Validation loss: 2.0346024292771534

Epoch: 6| Step: 13
Training loss: 1.2593786716461182
Validation loss: 2.059430690221889

Epoch: 558| Step: 0
Training loss: 0.7914363145828247
Validation loss: 2.007175801902689

Epoch: 6| Step: 1
Training loss: 1.7326878309249878
Validation loss: 2.0707308810244323

Epoch: 6| Step: 2
Training loss: 1.2503135204315186
Validation loss: 1.990824217437416

Epoch: 6| Step: 3
Training loss: 1.5451390743255615
Validation loss: 2.02793461789367

Epoch: 6| Step: 4
Training loss: 0.9474362134933472
Validation loss: 2.0920617054867487

Epoch: 6| Step: 5
Training loss: 1.527148962020874
Validation loss: 2.0333999920916814

Epoch: 6| Step: 6
Training loss: 1.1749001741409302
Validation loss: 2.053708049558824

Epoch: 6| Step: 7
Training loss: 1.1401615142822266
Validation loss: 2.0514065129782564

Epoch: 6| Step: 8
Training loss: 1.2116329669952393
Validation loss: 2.0637965317695373

Epoch: 6| Step: 9
Training loss: 1.7850531339645386
Validation loss: 2.041436796547264

Epoch: 6| Step: 10
Training loss: 1.1949341297149658
Validation loss: 2.0420950446077573

Epoch: 6| Step: 11
Training loss: 1.1415101289749146
Validation loss: 2.0074144383912444

Epoch: 6| Step: 12
Training loss: 1.2136425971984863
Validation loss: 1.9862537243032967

Epoch: 6| Step: 13
Training loss: 1.0957999229431152
Validation loss: 2.048365021264681

Epoch: 559| Step: 0
Training loss: 0.7401988506317139
Validation loss: 2.0586791730696157

Epoch: 6| Step: 1
Training loss: 1.4893412590026855
Validation loss: 2.028564085242569

Epoch: 6| Step: 2
Training loss: 1.4202208518981934
Validation loss: 2.0572835181349065

Epoch: 6| Step: 3
Training loss: 1.419132947921753
Validation loss: 2.0718562526087605

Epoch: 6| Step: 4
Training loss: 1.6493029594421387
Validation loss: 2.073723776366121

Epoch: 6| Step: 5
Training loss: 1.3376147747039795
Validation loss: 2.075972326340214

Epoch: 6| Step: 6
Training loss: 1.118599772453308
Validation loss: 2.062169098084973

Epoch: 6| Step: 7
Training loss: 0.7840157747268677
Validation loss: 2.0839286491435063

Epoch: 6| Step: 8
Training loss: 1.8117218017578125
Validation loss: 2.041375030753433

Epoch: 6| Step: 9
Training loss: 1.1082602739334106
Validation loss: 2.0502289354160266

Epoch: 6| Step: 10
Training loss: 0.8601856827735901
Validation loss: 2.0717073884061588

Epoch: 6| Step: 11
Training loss: 1.1879031658172607
Validation loss: 2.0809566385002545

Epoch: 6| Step: 12
Training loss: 1.3467602729797363
Validation loss: 2.048157702210129

Epoch: 6| Step: 13
Training loss: 1.7105647325515747
Validation loss: 2.02267010237581

Epoch: 560| Step: 0
Training loss: 1.445754885673523
Validation loss: 2.004906424912073

Epoch: 6| Step: 1
Training loss: 1.2512190341949463
Validation loss: 2.0418374000057096

Epoch: 6| Step: 2
Training loss: 0.4513140618801117
Validation loss: 2.05703144432396

Epoch: 6| Step: 3
Training loss: 1.2542102336883545
Validation loss: 2.0256151665923414

Epoch: 6| Step: 4
Training loss: 1.1469497680664062
Validation loss: 1.9994520013050368

Epoch: 6| Step: 5
Training loss: 1.4749724864959717
Validation loss: 2.0324175447546025

Epoch: 6| Step: 6
Training loss: 1.4071927070617676
Validation loss: 2.024770623894148

Epoch: 6| Step: 7
Training loss: 1.3456679582595825
Validation loss: 2.0590980322130266

Epoch: 6| Step: 8
Training loss: 1.1810847520828247
Validation loss: 2.034428968224474

Epoch: 6| Step: 9
Training loss: 1.142390251159668
Validation loss: 2.0848775191973616

Epoch: 6| Step: 10
Training loss: 1.1633172035217285
Validation loss: 2.0784407918171217

Epoch: 6| Step: 11
Training loss: 1.5209074020385742
Validation loss: 2.1017554344669467

Epoch: 6| Step: 12
Training loss: 2.028545379638672
Validation loss: 2.102733096768779

Epoch: 6| Step: 13
Training loss: 1.210326910018921
Validation loss: 2.0888296686192995

Epoch: 561| Step: 0
Training loss: 1.4890799522399902
Validation loss: 2.081784297061223

Epoch: 6| Step: 1
Training loss: 1.4273396730422974
Validation loss: 2.044217863390523

Epoch: 6| Step: 2
Training loss: 1.4766290187835693
Validation loss: 2.035252228859932

Epoch: 6| Step: 3
Training loss: 1.4067878723144531
Validation loss: 2.0488882949275355

Epoch: 6| Step: 4
Training loss: 0.7993119955062866
Validation loss: 2.0336385901256273

Epoch: 6| Step: 5
Training loss: 1.03519606590271
Validation loss: 2.049845682677402

Epoch: 6| Step: 6
Training loss: 1.5869770050048828
Validation loss: 2.0138758036398117

Epoch: 6| Step: 7
Training loss: 0.9813745021820068
Validation loss: 2.012231711418398

Epoch: 6| Step: 8
Training loss: 1.1856836080551147
Validation loss: 1.962951583247031

Epoch: 6| Step: 9
Training loss: 1.0966182947158813
Validation loss: 2.052645162869525

Epoch: 6| Step: 10
Training loss: 1.0252511501312256
Validation loss: 2.028628296749566

Epoch: 6| Step: 11
Training loss: 2.04893159866333
Validation loss: 2.010174979445755

Epoch: 6| Step: 12
Training loss: 1.2632277011871338
Validation loss: 2.0375517029916086

Epoch: 6| Step: 13
Training loss: 0.8376160860061646
Validation loss: 2.037323595375143

Epoch: 562| Step: 0
Training loss: 1.2043887376785278
Validation loss: 2.043011132106986

Epoch: 6| Step: 1
Training loss: 1.5456898212432861
Validation loss: 2.031707932872157

Epoch: 6| Step: 2
Training loss: 1.4301989078521729
Validation loss: 2.0271660512493503

Epoch: 6| Step: 3
Training loss: 1.57771635055542
Validation loss: 2.0347334723318777

Epoch: 6| Step: 4
Training loss: 0.5643775463104248
Validation loss: 2.048212510283275

Epoch: 6| Step: 5
Training loss: 1.2754576206207275
Validation loss: 2.0393718416972826

Epoch: 6| Step: 6
Training loss: 1.1310780048370361
Validation loss: 2.0553930215938117

Epoch: 6| Step: 7
Training loss: 1.8946270942687988
Validation loss: 2.070375527105024

Epoch: 6| Step: 8
Training loss: 0.9560152888298035
Validation loss: 2.054213382864511

Epoch: 6| Step: 9
Training loss: 1.4969902038574219
Validation loss: 2.0768222142291326

Epoch: 6| Step: 10
Training loss: 0.5703888535499573
Validation loss: 2.080728228374194

Epoch: 6| Step: 11
Training loss: 1.5359184741973877
Validation loss: 2.0650614410318355

Epoch: 6| Step: 12
Training loss: 1.331296682357788
Validation loss: 2.0546704223079066

Epoch: 6| Step: 13
Training loss: 1.0718300342559814
Validation loss: 2.066548148790995

Epoch: 563| Step: 0
Training loss: 1.5039100646972656
Validation loss: 2.1076421686398086

Epoch: 6| Step: 1
Training loss: 0.6398411393165588
Validation loss: 2.05404152921451

Epoch: 6| Step: 2
Training loss: 1.502672553062439
Validation loss: 2.0429309747552358

Epoch: 6| Step: 3
Training loss: 1.4236329793930054
Validation loss: 2.0154239246922154

Epoch: 6| Step: 4
Training loss: 1.0614290237426758
Validation loss: 2.0122480187364804

Epoch: 6| Step: 5
Training loss: 1.3648275136947632
Validation loss: 2.04663654681175

Epoch: 6| Step: 6
Training loss: 1.029062032699585
Validation loss: 2.034870207950633

Epoch: 6| Step: 7
Training loss: 1.2018001079559326
Validation loss: 2.035150472835828

Epoch: 6| Step: 8
Training loss: 1.0820801258087158
Validation loss: 2.0402361244283695

Epoch: 6| Step: 9
Training loss: 1.3426411151885986
Validation loss: 2.016974787558279

Epoch: 6| Step: 10
Training loss: 1.9438550472259521
Validation loss: 2.049383601834697

Epoch: 6| Step: 11
Training loss: 1.202852725982666
Validation loss: 2.0543250755597184

Epoch: 6| Step: 12
Training loss: 1.2534642219543457
Validation loss: 2.0620512680340837

Epoch: 6| Step: 13
Training loss: 1.0628361701965332
Validation loss: 2.043273539953334

Epoch: 564| Step: 0
Training loss: 1.0210963487625122
Validation loss: 2.045909221454333

Epoch: 6| Step: 1
Training loss: 1.1506479978561401
Validation loss: 2.0421566655558925

Epoch: 6| Step: 2
Training loss: 1.2510724067687988
Validation loss: 2.0454174997986003

Epoch: 6| Step: 3
Training loss: 1.2933869361877441
Validation loss: 2.0617618586427424

Epoch: 6| Step: 4
Training loss: 1.1276336908340454
Validation loss: 2.0549384470908874

Epoch: 6| Step: 5
Training loss: 0.5870000123977661
Validation loss: 2.0426639177465953

Epoch: 6| Step: 6
Training loss: 1.6706831455230713
Validation loss: 2.045674503490489

Epoch: 6| Step: 7
Training loss: 1.544880747795105
Validation loss: 2.011450538071253

Epoch: 6| Step: 8
Training loss: 1.2148345708847046
Validation loss: 2.058606727148897

Epoch: 6| Step: 9
Training loss: 1.280922532081604
Validation loss: 2.0823030215437695

Epoch: 6| Step: 10
Training loss: 1.1494396924972534
Validation loss: 2.088132148147911

Epoch: 6| Step: 11
Training loss: 1.754281759262085
Validation loss: 2.0299893143356487

Epoch: 6| Step: 12
Training loss: 1.0837137699127197
Validation loss: 2.0903013918989446

Epoch: 6| Step: 13
Training loss: 1.7146878242492676
Validation loss: 2.0400472815318773

Epoch: 565| Step: 0
Training loss: 1.6893655061721802
Validation loss: 2.1207745203407864

Epoch: 6| Step: 1
Training loss: 1.2364985942840576
Validation loss: 2.0802173101773827

Epoch: 6| Step: 2
Training loss: 0.9462263584136963
Validation loss: 2.057997577933855

Epoch: 6| Step: 3
Training loss: 1.5240727663040161
Validation loss: 2.069817089265393

Epoch: 6| Step: 4
Training loss: 1.1344096660614014
Validation loss: 2.0780272688916934

Epoch: 6| Step: 5
Training loss: 1.0450432300567627
Validation loss: 2.078695353641305

Epoch: 6| Step: 6
Training loss: 1.000273585319519
Validation loss: 2.0687161850672897

Epoch: 6| Step: 7
Training loss: 1.4264869689941406
Validation loss: 2.0058090661161687

Epoch: 6| Step: 8
Training loss: 0.9516651630401611
Validation loss: 2.0824432860138598

Epoch: 6| Step: 9
Training loss: 1.4787012338638306
Validation loss: 2.052608954009189

Epoch: 6| Step: 10
Training loss: 1.5181567668914795
Validation loss: 2.0474104778740996

Epoch: 6| Step: 11
Training loss: 1.5677268505096436
Validation loss: 2.065789717499928

Epoch: 6| Step: 12
Training loss: 1.191540002822876
Validation loss: 2.0548293141908545

Epoch: 6| Step: 13
Training loss: 0.8681552410125732
Validation loss: 2.008549596673699

Epoch: 566| Step: 0
Training loss: 1.0191209316253662
Validation loss: 2.0551136629555815

Epoch: 6| Step: 1
Training loss: 1.0400166511535645
Validation loss: 2.039007552208439

Epoch: 6| Step: 2
Training loss: 0.7089695930480957
Validation loss: 2.071592967997315

Epoch: 6| Step: 3
Training loss: 1.8193039894104004
Validation loss: 1.9919930299123128

Epoch: 6| Step: 4
Training loss: 1.3583569526672363
Validation loss: 2.062189089354648

Epoch: 6| Step: 5
Training loss: 1.339876651763916
Validation loss: 2.054022258327853

Epoch: 6| Step: 6
Training loss: 1.5180363655090332
Validation loss: 2.0421487592881724

Epoch: 6| Step: 7
Training loss: 1.263350009918213
Validation loss: 2.0336079187290643

Epoch: 6| Step: 8
Training loss: 0.7685998678207397
Validation loss: 2.0883590687987623

Epoch: 6| Step: 9
Training loss: 1.6270010471343994
Validation loss: 2.08674289846933

Epoch: 6| Step: 10
Training loss: 1.8897114992141724
Validation loss: 2.0946746205770843

Epoch: 6| Step: 11
Training loss: 0.9023855328559875
Validation loss: 2.0518011751995293

Epoch: 6| Step: 12
Training loss: 1.0095210075378418
Validation loss: 2.107062365419121

Epoch: 6| Step: 13
Training loss: 1.2369306087493896
Validation loss: 2.0908461283611994

Epoch: 567| Step: 0
Training loss: 1.3774724006652832
Validation loss: 2.086403598067581

Epoch: 6| Step: 1
Training loss: 1.1573703289031982
Validation loss: 2.066149070698728

Epoch: 6| Step: 2
Training loss: 1.3376429080963135
Validation loss: 2.049262292923466

Epoch: 6| Step: 3
Training loss: 0.7896031141281128
Validation loss: 2.035991843028735

Epoch: 6| Step: 4
Training loss: 1.2460923194885254
Validation loss: 2.0247507531155824

Epoch: 6| Step: 5
Training loss: 1.5172597169876099
Validation loss: 2.0264067162749586

Epoch: 6| Step: 6
Training loss: 1.2386837005615234
Validation loss: 2.035430339074904

Epoch: 6| Step: 7
Training loss: 0.9372396469116211
Validation loss: 2.0205852677745204

Epoch: 6| Step: 8
Training loss: 1.5134358406066895
Validation loss: 2.0644506921050367

Epoch: 6| Step: 9
Training loss: 1.4487755298614502
Validation loss: 2.0228351905781734

Epoch: 6| Step: 10
Training loss: 0.8865270614624023
Validation loss: 2.057771457138882

Epoch: 6| Step: 11
Training loss: 1.3630211353302002
Validation loss: 2.056319787938108

Epoch: 6| Step: 12
Training loss: 1.774662971496582
Validation loss: 1.99306918216008

Epoch: 6| Step: 13
Training loss: 0.959242582321167
Validation loss: 2.07783769535762

Epoch: 568| Step: 0
Training loss: 1.4289774894714355
Validation loss: 2.050421417400401

Epoch: 6| Step: 1
Training loss: 1.2840083837509155
Validation loss: 2.0390890823897494

Epoch: 6| Step: 2
Training loss: 1.2294580936431885
Validation loss: 2.0814485088471444

Epoch: 6| Step: 3
Training loss: 1.640965461730957
Validation loss: 2.0696441563226844

Epoch: 6| Step: 4
Training loss: 1.2230833768844604
Validation loss: 2.095039398439469

Epoch: 6| Step: 5
Training loss: 1.5251387357711792
Validation loss: 2.1099562619322088

Epoch: 6| Step: 6
Training loss: 0.7009838819503784
Validation loss: 2.0635193419712845

Epoch: 6| Step: 7
Training loss: 1.6164660453796387
Validation loss: 2.1060691328458887

Epoch: 6| Step: 8
Training loss: 1.2197142839431763
Validation loss: 2.075927157555857

Epoch: 6| Step: 9
Training loss: 1.140583872795105
Validation loss: 2.048750028815321

Epoch: 6| Step: 10
Training loss: 1.1053812503814697
Validation loss: 2.0450432505658878

Epoch: 6| Step: 11
Training loss: 1.7031347751617432
Validation loss: 2.0845487399767806

Epoch: 6| Step: 12
Training loss: 1.1232385635375977
Validation loss: 2.0557961669019473

Epoch: 6| Step: 13
Training loss: 0.7018439173698425
Validation loss: 1.9878580929130636

Epoch: 569| Step: 0
Training loss: 1.239876627922058
Validation loss: 2.0332651753579416

Epoch: 6| Step: 1
Training loss: 1.1757539510726929
Validation loss: 2.055789268144997

Epoch: 6| Step: 2
Training loss: 1.1959681510925293
Validation loss: 1.9988398244304042

Epoch: 6| Step: 3
Training loss: 1.1098747253417969
Validation loss: 2.0311930717960482

Epoch: 6| Step: 4
Training loss: 1.2082059383392334
Validation loss: 2.0454544354510564

Epoch: 6| Step: 5
Training loss: 1.3704721927642822
Validation loss: 2.05328098932902

Epoch: 6| Step: 6
Training loss: 1.561384677886963
Validation loss: 2.051745601879653

Epoch: 6| Step: 7
Training loss: 0.9417256712913513
Validation loss: 2.0070540571725495

Epoch: 6| Step: 8
Training loss: 1.8455482721328735
Validation loss: 2.0960926625036422

Epoch: 6| Step: 9
Training loss: 1.3188353776931763
Validation loss: 2.086674295445924

Epoch: 6| Step: 10
Training loss: 1.8726558685302734
Validation loss: 2.107655167579651

Epoch: 6| Step: 11
Training loss: 0.9104517698287964
Validation loss: 2.066136460150442

Epoch: 6| Step: 12
Training loss: 0.6657059192657471
Validation loss: 2.0788710630068215

Epoch: 6| Step: 13
Training loss: 1.9369837045669556
Validation loss: 2.0995538285983506

Epoch: 570| Step: 0
Training loss: 0.7256184816360474
Validation loss: 2.0383384945572063

Epoch: 6| Step: 1
Training loss: 0.8977681994438171
Validation loss: 2.0396516066725536

Epoch: 6| Step: 2
Training loss: 1.7164294719696045
Validation loss: 2.047701381867932

Epoch: 6| Step: 3
Training loss: 1.3601089715957642
Validation loss: 2.0578849443825344

Epoch: 6| Step: 4
Training loss: 0.9329670667648315
Validation loss: 2.036831627609909

Epoch: 6| Step: 5
Training loss: 1.2467849254608154
Validation loss: 2.0418023114563315

Epoch: 6| Step: 6
Training loss: 1.3157130479812622
Validation loss: 2.0554740582743

Epoch: 6| Step: 7
Training loss: 1.8256226778030396
Validation loss: 2.032863824598251

Epoch: 6| Step: 8
Training loss: 1.8889621496200562
Validation loss: 2.058828200063398

Epoch: 6| Step: 9
Training loss: 1.0938830375671387
Validation loss: 1.989098677071192

Epoch: 6| Step: 10
Training loss: 1.241542100906372
Validation loss: 2.007340984959756

Epoch: 6| Step: 11
Training loss: 1.2588481903076172
Validation loss: 2.0368913527457946

Epoch: 6| Step: 12
Training loss: 1.4148601293563843
Validation loss: 2.0181077911007788

Epoch: 6| Step: 13
Training loss: 0.41009923815727234
Validation loss: 2.029756622929727

Epoch: 571| Step: 0
Training loss: 1.7390823364257812
Validation loss: 2.0215198096408638

Epoch: 6| Step: 1
Training loss: 1.1359401941299438
Validation loss: 2.027661326111004

Epoch: 6| Step: 2
Training loss: 1.5758674144744873
Validation loss: 2.0393892975263697

Epoch: 6| Step: 3
Training loss: 1.411557912826538
Validation loss: 2.0487226542606147

Epoch: 6| Step: 4
Training loss: 1.5695440769195557
Validation loss: 2.0425965632161787

Epoch: 6| Step: 5
Training loss: 1.451423168182373
Validation loss: 2.0500632383490123

Epoch: 6| Step: 6
Training loss: 0.7918170094490051
Validation loss: 2.065393394039523

Epoch: 6| Step: 7
Training loss: 1.11729097366333
Validation loss: 2.094570429094376

Epoch: 6| Step: 8
Training loss: 0.8709572553634644
Validation loss: 2.081592511105281

Epoch: 6| Step: 9
Training loss: 1.0776269435882568
Validation loss: 2.0898099714709866

Epoch: 6| Step: 10
Training loss: 1.1005886793136597
Validation loss: 2.070523033859909

Epoch: 6| Step: 11
Training loss: 1.6471467018127441
Validation loss: 2.04738760635417

Epoch: 6| Step: 12
Training loss: 1.2153234481811523
Validation loss: 2.066391375757033

Epoch: 6| Step: 13
Training loss: 0.5385169386863708
Validation loss: 2.0434766661736274

Epoch: 572| Step: 0
Training loss: 0.8071703314781189
Validation loss: 2.0866278320230465

Epoch: 6| Step: 1
Training loss: 1.0217517614364624
Validation loss: 2.0870577417394167

Epoch: 6| Step: 2
Training loss: 1.2534148693084717
Validation loss: 2.0541401857970865

Epoch: 6| Step: 3
Training loss: 1.0457613468170166
Validation loss: 2.0521477986407537

Epoch: 6| Step: 4
Training loss: 1.496683120727539
Validation loss: 2.037781576956472

Epoch: 6| Step: 5
Training loss: 1.3288379907608032
Validation loss: 2.070254343812184

Epoch: 6| Step: 6
Training loss: 1.2700529098510742
Validation loss: 2.046702810513076

Epoch: 6| Step: 7
Training loss: 1.3902411460876465
Validation loss: 2.027710671065956

Epoch: 6| Step: 8
Training loss: 1.2022759914398193
Validation loss: 2.019225501245068

Epoch: 6| Step: 9
Training loss: 1.4504992961883545
Validation loss: 2.029867149168445

Epoch: 6| Step: 10
Training loss: 1.2192240953445435
Validation loss: 2.040980062177104

Epoch: 6| Step: 11
Training loss: 1.2755584716796875
Validation loss: 2.0030417224412322

Epoch: 6| Step: 12
Training loss: 1.411694884300232
Validation loss: 2.019156345757105

Epoch: 6| Step: 13
Training loss: 1.635801911354065
Validation loss: 2.0301389617304646

Epoch: 573| Step: 0
Training loss: 1.4326057434082031
Validation loss: 2.034986993317963

Epoch: 6| Step: 1
Training loss: 0.9717416763305664
Validation loss: 2.0766185470806655

Epoch: 6| Step: 2
Training loss: 1.2748503684997559
Validation loss: 2.0825269760624057

Epoch: 6| Step: 3
Training loss: 0.7520227432250977
Validation loss: 2.136839388519205

Epoch: 6| Step: 4
Training loss: 1.733684778213501
Validation loss: 2.109134417708202

Epoch: 6| Step: 5
Training loss: 1.9857077598571777
Validation loss: 2.128819722001271

Epoch: 6| Step: 6
Training loss: 0.8330142498016357
Validation loss: 2.135422114403017

Epoch: 6| Step: 7
Training loss: 1.1206542253494263
Validation loss: 2.1847106231156217

Epoch: 6| Step: 8
Training loss: 0.8747223615646362
Validation loss: 2.1651044481544086

Epoch: 6| Step: 9
Training loss: 0.837380051612854
Validation loss: 2.077403155706262

Epoch: 6| Step: 10
Training loss: 1.659425139427185
Validation loss: 2.144561611196046

Epoch: 6| Step: 11
Training loss: 1.8100385665893555
Validation loss: 2.1210771734996507

Epoch: 6| Step: 12
Training loss: 1.3470162153244019
Validation loss: 2.064040236575629

Epoch: 6| Step: 13
Training loss: 1.7598419189453125
Validation loss: 2.0216693211627264

Epoch: 574| Step: 0
Training loss: 0.7836790680885315
Validation loss: 2.0539863750498784

Epoch: 6| Step: 1
Training loss: 0.6693747043609619
Validation loss: 2.0538844805891796

Epoch: 6| Step: 2
Training loss: 1.3060855865478516
Validation loss: 2.035640196133685

Epoch: 6| Step: 3
Training loss: 1.1659276485443115
Validation loss: 2.0517956864449287

Epoch: 6| Step: 4
Training loss: 1.7843420505523682
Validation loss: 2.015376975459437

Epoch: 6| Step: 5
Training loss: 1.7016944885253906
Validation loss: 2.0065238321981123

Epoch: 6| Step: 6
Training loss: 1.3856308460235596
Validation loss: 2.020368286358413

Epoch: 6| Step: 7
Training loss: 0.8570417165756226
Validation loss: 2.0144784040348505

Epoch: 6| Step: 8
Training loss: 1.038122296333313
Validation loss: 2.026650281362636

Epoch: 6| Step: 9
Training loss: 1.187780737876892
Validation loss: 2.031164311593579

Epoch: 6| Step: 10
Training loss: 1.4243793487548828
Validation loss: 1.9958329764745568

Epoch: 6| Step: 11
Training loss: 1.7051422595977783
Validation loss: 2.0238462545538463

Epoch: 6| Step: 12
Training loss: 1.680675983428955
Validation loss: 2.086863569034043

Epoch: 6| Step: 13
Training loss: 1.0441153049468994
Validation loss: 2.049296909762967

Epoch: 575| Step: 0
Training loss: 0.8421412706375122
Validation loss: 2.0861959752216133

Epoch: 6| Step: 1
Training loss: 1.297064185142517
Validation loss: 2.1013361279682448

Epoch: 6| Step: 2
Training loss: 1.1410183906555176
Validation loss: 2.1111143942802184

Epoch: 6| Step: 3
Training loss: 1.4904670715332031
Validation loss: 2.0979969116949264

Epoch: 6| Step: 4
Training loss: 1.3877573013305664
Validation loss: 2.054409355245611

Epoch: 6| Step: 5
Training loss: 1.2929238080978394
Validation loss: 2.0756941610766995

Epoch: 6| Step: 6
Training loss: 1.4258265495300293
Validation loss: 2.0812119245529175

Epoch: 6| Step: 7
Training loss: 1.1887893676757812
Validation loss: 2.0728515809582126

Epoch: 6| Step: 8
Training loss: 1.602851390838623
Validation loss: 2.0802508554150982

Epoch: 6| Step: 9
Training loss: 1.1347296237945557
Validation loss: 2.0572406566271217

Epoch: 6| Step: 10
Training loss: 0.8715229034423828
Validation loss: 2.056251766861126

Epoch: 6| Step: 11
Training loss: 1.4271538257598877
Validation loss: 2.0602303602362193

Epoch: 6| Step: 12
Training loss: 1.4790345430374146
Validation loss: 2.0101838278514084

Epoch: 6| Step: 13
Training loss: 1.2150795459747314
Validation loss: 2.0330788935384443

Epoch: 576| Step: 0
Training loss: 2.040339946746826
Validation loss: 1.9931625012428529

Epoch: 6| Step: 1
Training loss: 1.269439935684204
Validation loss: 2.011177457788939

Epoch: 6| Step: 2
Training loss: 0.8605203032493591
Validation loss: 2.0725542755537134

Epoch: 6| Step: 3
Training loss: 1.6789746284484863
Validation loss: 2.0583680919421616

Epoch: 6| Step: 4
Training loss: 1.0395042896270752
Validation loss: 2.0734524162866736

Epoch: 6| Step: 5
Training loss: 1.5848660469055176
Validation loss: 2.02518702578801

Epoch: 6| Step: 6
Training loss: 1.4479694366455078
Validation loss: 2.036507619324551

Epoch: 6| Step: 7
Training loss: 1.0947636365890503
Validation loss: 2.0185061911100983

Epoch: 6| Step: 8
Training loss: 0.5098258852958679
Validation loss: 2.062195772765785

Epoch: 6| Step: 9
Training loss: 1.6486636400222778
Validation loss: 2.0486301734883297

Epoch: 6| Step: 10
Training loss: 0.7686471343040466
Validation loss: 2.0384672303353586

Epoch: 6| Step: 11
Training loss: 1.0243384838104248
Validation loss: 2.064937953026064

Epoch: 6| Step: 12
Training loss: 1.3640363216400146
Validation loss: 2.0358257421883206

Epoch: 6| Step: 13
Training loss: 1.294930100440979
Validation loss: 2.0606158625695015

Epoch: 577| Step: 0
Training loss: 1.035019874572754
Validation loss: 2.0486535256908787

Epoch: 6| Step: 1
Training loss: 1.0657720565795898
Validation loss: 2.0712675433005057

Epoch: 6| Step: 2
Training loss: 1.599870204925537
Validation loss: 2.040954976953486

Epoch: 6| Step: 3
Training loss: 1.8024828433990479
Validation loss: 2.05099130317729

Epoch: 6| Step: 4
Training loss: 1.0605347156524658
Validation loss: 2.053837914620676

Epoch: 6| Step: 5
Training loss: 1.8123159408569336
Validation loss: 2.107923610236055

Epoch: 6| Step: 6
Training loss: 1.0712969303131104
Validation loss: 2.0766340635156118

Epoch: 6| Step: 7
Training loss: 1.501842975616455
Validation loss: 2.0195904636895783

Epoch: 6| Step: 8
Training loss: 0.9186360239982605
Validation loss: 2.0798542012450514

Epoch: 6| Step: 9
Training loss: 1.3492980003356934
Validation loss: 2.071923353338754

Epoch: 6| Step: 10
Training loss: 1.281391978263855
Validation loss: 2.0485212238886024

Epoch: 6| Step: 11
Training loss: 0.7064633369445801
Validation loss: 2.0558208111793763

Epoch: 6| Step: 12
Training loss: 1.6172008514404297
Validation loss: 2.0786790975960354

Epoch: 6| Step: 13
Training loss: 0.574457049369812
Validation loss: 2.039590561261741

Epoch: 578| Step: 0
Training loss: 1.2418608665466309
Validation loss: 2.074319918950399

Epoch: 6| Step: 1
Training loss: 1.3775842189788818
Validation loss: 2.0737546797721618

Epoch: 6| Step: 2
Training loss: 1.6579517126083374
Validation loss: 2.050594855380315

Epoch: 6| Step: 3
Training loss: 0.9316068887710571
Validation loss: 2.0561156247251775

Epoch: 6| Step: 4
Training loss: 1.2240233421325684
Validation loss: 2.0340160721091816

Epoch: 6| Step: 5
Training loss: 1.0771788358688354
Validation loss: 2.03762488595901

Epoch: 6| Step: 6
Training loss: 1.1417958736419678
Validation loss: 2.0386680121062906

Epoch: 6| Step: 7
Training loss: 1.266535758972168
Validation loss: 2.0751535905304777

Epoch: 6| Step: 8
Training loss: 1.243318796157837
Validation loss: 2.0565597652107157

Epoch: 6| Step: 9
Training loss: 0.6858474612236023
Validation loss: 2.0360721593262046

Epoch: 6| Step: 10
Training loss: 0.9209496974945068
Validation loss: 2.038165510341685

Epoch: 6| Step: 11
Training loss: 1.972225308418274
Validation loss: 2.061617494911276

Epoch: 6| Step: 12
Training loss: 1.0752363204956055
Validation loss: 2.0674843993238223

Epoch: 6| Step: 13
Training loss: 1.6518747806549072
Validation loss: 2.027404277555404

Epoch: 579| Step: 0
Training loss: 1.879125714302063
Validation loss: 2.0303377900072324

Epoch: 6| Step: 1
Training loss: 1.1295465230941772
Validation loss: 2.0139761945252777

Epoch: 6| Step: 2
Training loss: 0.8613146543502808
Validation loss: 2.057106484649002

Epoch: 6| Step: 3
Training loss: 1.4169811010360718
Validation loss: 2.0359973189651326

Epoch: 6| Step: 4
Training loss: 0.7183324098587036
Validation loss: 2.0443078856314383

Epoch: 6| Step: 5
Training loss: 1.627434253692627
Validation loss: 2.082138212778235

Epoch: 6| Step: 6
Training loss: 0.9069824814796448
Validation loss: 2.0425816684640865

Epoch: 6| Step: 7
Training loss: 0.9642810821533203
Validation loss: 2.0949770558264946

Epoch: 6| Step: 8
Training loss: 1.9254579544067383
Validation loss: 2.077883433270198

Epoch: 6| Step: 9
Training loss: 1.1838915348052979
Validation loss: 2.0408814735310052

Epoch: 6| Step: 10
Training loss: 1.2009937763214111
Validation loss: 2.0800098462771346

Epoch: 6| Step: 11
Training loss: 1.214939832687378
Validation loss: 2.0541180679875035

Epoch: 6| Step: 12
Training loss: 1.2438786029815674
Validation loss: 2.0400554877455517

Epoch: 6| Step: 13
Training loss: 1.1412582397460938
Validation loss: 2.046406692074191

Epoch: 580| Step: 0
Training loss: 0.9485952258110046
Validation loss: 2.023340916120878

Epoch: 6| Step: 1
Training loss: 1.4574847221374512
Validation loss: 2.0369696386398806

Epoch: 6| Step: 2
Training loss: 1.2084044218063354
Validation loss: 2.0426649547392324

Epoch: 6| Step: 3
Training loss: 0.9665483832359314
Validation loss: 2.0226329026683683

Epoch: 6| Step: 4
Training loss: 2.1773862838745117
Validation loss: 2.027821913842232

Epoch: 6| Step: 5
Training loss: 1.2886906862258911
Validation loss: 2.031243619098458

Epoch: 6| Step: 6
Training loss: 1.2800604104995728
Validation loss: 2.014129202852967

Epoch: 6| Step: 7
Training loss: 1.1414473056793213
Validation loss: 2.036504481428413

Epoch: 6| Step: 8
Training loss: 1.037008285522461
Validation loss: 2.0432293235614734

Epoch: 6| Step: 9
Training loss: 1.1696643829345703
Validation loss: 2.031699944567937

Epoch: 6| Step: 10
Training loss: 1.590088129043579
Validation loss: 2.0587953085540445

Epoch: 6| Step: 11
Training loss: 0.9343435168266296
Validation loss: 2.0265262690923547

Epoch: 6| Step: 12
Training loss: 1.1743898391723633
Validation loss: 2.0258684235234417

Epoch: 6| Step: 13
Training loss: 0.8599682450294495
Validation loss: 2.0893832970690984

Epoch: 581| Step: 0
Training loss: 1.6453789472579956
Validation loss: 2.023264572184573

Epoch: 6| Step: 1
Training loss: 1.3657323122024536
Validation loss: 2.0843200337502266

Epoch: 6| Step: 2
Training loss: 1.0838133096694946
Validation loss: 2.007542191013213

Epoch: 6| Step: 3
Training loss: 0.7258571982383728
Validation loss: 2.059449594507935

Epoch: 6| Step: 4
Training loss: 1.7812471389770508
Validation loss: 2.0903667916533766

Epoch: 6| Step: 5
Training loss: 1.2415289878845215
Validation loss: 2.0425261964080152

Epoch: 6| Step: 6
Training loss: 0.9994862079620361
Validation loss: 2.068047901635529

Epoch: 6| Step: 7
Training loss: 1.0498661994934082
Validation loss: 2.0453459780703307

Epoch: 6| Step: 8
Training loss: 1.3422014713287354
Validation loss: 2.045521789981473

Epoch: 6| Step: 9
Training loss: 1.5383788347244263
Validation loss: 2.0385267849891417

Epoch: 6| Step: 10
Training loss: 1.1273932456970215
Validation loss: 2.085017555503435

Epoch: 6| Step: 11
Training loss: 1.3573516607284546
Validation loss: 2.012322332269402

Epoch: 6| Step: 12
Training loss: 0.8846372961997986
Validation loss: 2.0433903663389144

Epoch: 6| Step: 13
Training loss: 0.7231184244155884
Validation loss: 2.0164120812569895

Epoch: 582| Step: 0
Training loss: 1.4737269878387451
Validation loss: 2.076452197567109

Epoch: 6| Step: 1
Training loss: 1.1726875305175781
Validation loss: 2.055729409699799

Epoch: 6| Step: 2
Training loss: 1.1590434312820435
Validation loss: 2.042436968895697

Epoch: 6| Step: 3
Training loss: 0.7857527732849121
Validation loss: 2.022328192187894

Epoch: 6| Step: 4
Training loss: 0.9335169792175293
Validation loss: 2.02209738762148

Epoch: 6| Step: 5
Training loss: 1.1734709739685059
Validation loss: 2.075085634826332

Epoch: 6| Step: 6
Training loss: 1.377132534980774
Validation loss: 2.038762541227443

Epoch: 6| Step: 7
Training loss: 1.2316241264343262
Validation loss: 2.041294643955846

Epoch: 6| Step: 8
Training loss: 1.3653478622436523
Validation loss: 2.0574461465240805

Epoch: 6| Step: 9
Training loss: 0.830998420715332
Validation loss: 2.0397222759903118

Epoch: 6| Step: 10
Training loss: 1.2642943859100342
Validation loss: 2.025583831212854

Epoch: 6| Step: 11
Training loss: 1.3969537019729614
Validation loss: 2.032332179366901

Epoch: 6| Step: 12
Training loss: 1.950704574584961
Validation loss: 2.1064198145302395

Epoch: 6| Step: 13
Training loss: 0.8902645111083984
Validation loss: 2.046379466210642

Epoch: 583| Step: 0
Training loss: 1.0472339391708374
Validation loss: 2.062974940064133

Epoch: 6| Step: 1
Training loss: 1.5191619396209717
Validation loss: 2.0794151213861283

Epoch: 6| Step: 2
Training loss: 0.6932705640792847
Validation loss: 2.051996969407605

Epoch: 6| Step: 3
Training loss: 1.897027611732483
Validation loss: 2.0679139847396524

Epoch: 6| Step: 4
Training loss: 1.0231724977493286
Validation loss: 2.0443667686113747

Epoch: 6| Step: 5
Training loss: 1.3931125402450562
Validation loss: 2.0329958162000104

Epoch: 6| Step: 6
Training loss: 1.5351508855819702
Validation loss: 2.0380487339470976

Epoch: 6| Step: 7
Training loss: 1.274719476699829
Validation loss: 2.0790717396684872

Epoch: 6| Step: 8
Training loss: 1.2606890201568604
Validation loss: 2.0693108240763345

Epoch: 6| Step: 9
Training loss: 1.5361124277114868
Validation loss: 2.046990986793272

Epoch: 6| Step: 10
Training loss: 1.0580480098724365
Validation loss: 2.0436519217747513

Epoch: 6| Step: 11
Training loss: 1.1600558757781982
Validation loss: 2.075627629474927

Epoch: 6| Step: 12
Training loss: 0.833052933216095
Validation loss: 2.070573978526618

Epoch: 6| Step: 13
Training loss: 1.0472500324249268
Validation loss: 2.043755877402521

Epoch: 584| Step: 0
Training loss: 1.1426664590835571
Validation loss: 1.9917806233129194

Epoch: 6| Step: 1
Training loss: 1.5135369300842285
Validation loss: 1.991283773094095

Epoch: 6| Step: 2
Training loss: 1.1222772598266602
Validation loss: 2.029053585503691

Epoch: 6| Step: 3
Training loss: 1.0307151079177856
Validation loss: 2.069134061054517

Epoch: 6| Step: 4
Training loss: 0.9251803159713745
Validation loss: 2.049378796290326

Epoch: 6| Step: 5
Training loss: 1.2878589630126953
Validation loss: 2.0683119322663996

Epoch: 6| Step: 6
Training loss: 1.1958075761795044
Validation loss: 2.0632714994492067

Epoch: 6| Step: 7
Training loss: 1.6167020797729492
Validation loss: 2.02231442159222

Epoch: 6| Step: 8
Training loss: 0.7009719014167786
Validation loss: 2.0643527841055267

Epoch: 6| Step: 9
Training loss: 0.8655010461807251
Validation loss: 2.023950328109085

Epoch: 6| Step: 10
Training loss: 1.0528863668441772
Validation loss: 2.0735524033987396

Epoch: 6| Step: 11
Training loss: 1.3907476663589478
Validation loss: 2.0726979676113335

Epoch: 6| Step: 12
Training loss: 1.631479024887085
Validation loss: 2.0854548638866794

Epoch: 6| Step: 13
Training loss: 1.8701610565185547
Validation loss: 2.1020320820552048

Epoch: 585| Step: 0
Training loss: 1.1698687076568604
Validation loss: 2.0624523957570395

Epoch: 6| Step: 1
Training loss: 0.941437840461731
Validation loss: 2.04497835072138

Epoch: 6| Step: 2
Training loss: 1.007495641708374
Validation loss: 2.0585880958905785

Epoch: 6| Step: 3
Training loss: 1.2953286170959473
Validation loss: 2.0254573258020545

Epoch: 6| Step: 4
Training loss: 1.587243676185608
Validation loss: 2.0379833572654316

Epoch: 6| Step: 5
Training loss: 1.584227204322815
Validation loss: 2.053646740093026

Epoch: 6| Step: 6
Training loss: 1.161707878112793
Validation loss: 2.072111378433884

Epoch: 6| Step: 7
Training loss: 0.7090555429458618
Validation loss: 2.0249118087112263

Epoch: 6| Step: 8
Training loss: 1.3498566150665283
Validation loss: 2.0771285513395905

Epoch: 6| Step: 9
Training loss: 1.352076530456543
Validation loss: 2.0552735123583066

Epoch: 6| Step: 10
Training loss: 1.4108951091766357
Validation loss: 2.039391989349037

Epoch: 6| Step: 11
Training loss: 0.9663002490997314
Validation loss: 2.0465979178746543

Epoch: 6| Step: 12
Training loss: 1.9499400854110718
Validation loss: 2.075000500166288

Epoch: 6| Step: 13
Training loss: 0.8224648833274841
Validation loss: 2.044692877800234

Epoch: 586| Step: 0
Training loss: 1.595857858657837
Validation loss: 2.0520096158468597

Epoch: 6| Step: 1
Training loss: 1.2076677083969116
Validation loss: 2.054150189122846

Epoch: 6| Step: 2
Training loss: 1.756103754043579
Validation loss: 2.06773203931829

Epoch: 6| Step: 3
Training loss: 1.3893978595733643
Validation loss: 2.0336352061199885

Epoch: 6| Step: 4
Training loss: 1.124036431312561
Validation loss: 2.010066350301107

Epoch: 6| Step: 5
Training loss: 1.659319519996643
Validation loss: 2.04379956183895

Epoch: 6| Step: 6
Training loss: 1.1079493761062622
Validation loss: 2.026676849652362

Epoch: 6| Step: 7
Training loss: 0.9259340763092041
Validation loss: 2.074354492208009

Epoch: 6| Step: 8
Training loss: 1.2764267921447754
Validation loss: 1.9929958492197015

Epoch: 6| Step: 9
Training loss: 0.8705887794494629
Validation loss: 2.0243098505081667

Epoch: 6| Step: 10
Training loss: 1.367806077003479
Validation loss: 2.0300854521413005

Epoch: 6| Step: 11
Training loss: 0.7557141780853271
Validation loss: 2.040631963360694

Epoch: 6| Step: 12
Training loss: 0.9136711359024048
Validation loss: 2.0386876111389487

Epoch: 6| Step: 13
Training loss: 1.161492943763733
Validation loss: 2.046537691547025

Epoch: 587| Step: 0
Training loss: 0.8074925541877747
Validation loss: 2.0736366241208968

Epoch: 6| Step: 1
Training loss: 1.1896352767944336
Validation loss: 2.0225985819293606

Epoch: 6| Step: 2
Training loss: 1.2249841690063477
Validation loss: 2.054223216989989

Epoch: 6| Step: 3
Training loss: 0.7504141330718994
Validation loss: 2.0397854364046486

Epoch: 6| Step: 4
Training loss: 1.5584783554077148
Validation loss: 2.0897768723067416

Epoch: 6| Step: 5
Training loss: 1.8206708431243896
Validation loss: 2.059403743795169

Epoch: 6| Step: 6
Training loss: 1.4408745765686035
Validation loss: 2.048135055008755

Epoch: 6| Step: 7
Training loss: 1.2642802000045776
Validation loss: 2.0132533042661604

Epoch: 6| Step: 8
Training loss: 1.6528122425079346
Validation loss: 2.0563578990197953

Epoch: 6| Step: 9
Training loss: 0.43821966648101807
Validation loss: 2.0615575698114212

Epoch: 6| Step: 10
Training loss: 1.4933805465698242
Validation loss: 2.0713417504423406

Epoch: 6| Step: 11
Training loss: 1.5295650959014893
Validation loss: 2.0758357586399203

Epoch: 6| Step: 12
Training loss: 0.5770450830459595
Validation loss: 2.036848901420511

Epoch: 6| Step: 13
Training loss: 1.776021122932434
Validation loss: 2.0560065469434186

Epoch: 588| Step: 0
Training loss: 1.510352373123169
Validation loss: 2.032167120646405

Epoch: 6| Step: 1
Training loss: 1.3937454223632812
Validation loss: 2.0181898814375683

Epoch: 6| Step: 2
Training loss: 1.2953615188598633
Validation loss: 1.9866617802650697

Epoch: 6| Step: 3
Training loss: 1.2684695720672607
Validation loss: 2.0341730579253166

Epoch: 6| Step: 4
Training loss: 1.2157988548278809
Validation loss: 2.0215391189821306

Epoch: 6| Step: 5
Training loss: 1.2932143211364746
Validation loss: 2.020415384282348

Epoch: 6| Step: 6
Training loss: 1.41928231716156
Validation loss: 2.03130349164368

Epoch: 6| Step: 7
Training loss: 0.9157285690307617
Validation loss: 2.02396729171917

Epoch: 6| Step: 8
Training loss: 1.1217408180236816
Validation loss: 2.0482931649813088

Epoch: 6| Step: 9
Training loss: 0.7131247520446777
Validation loss: 2.0266654299151514

Epoch: 6| Step: 10
Training loss: 1.6793732643127441
Validation loss: 2.093355535179056

Epoch: 6| Step: 11
Training loss: 1.1045734882354736
Validation loss: 2.0204023212514897

Epoch: 6| Step: 12
Training loss: 1.0850303173065186
Validation loss: 2.068933440792945

Epoch: 6| Step: 13
Training loss: 1.1848793029785156
Validation loss: 2.120408465785365

Epoch: 589| Step: 0
Training loss: 1.5926872491836548
Validation loss: 2.0531635822788363

Epoch: 6| Step: 1
Training loss: 1.5824909210205078
Validation loss: 2.047722498575846

Epoch: 6| Step: 2
Training loss: 0.9770849347114563
Validation loss: 2.107770194289505

Epoch: 6| Step: 3
Training loss: 0.9163114428520203
Validation loss: 2.05159608779415

Epoch: 6| Step: 4
Training loss: 1.240640640258789
Validation loss: 2.077109243280144

Epoch: 6| Step: 5
Training loss: 1.458420991897583
Validation loss: 2.045378064596525

Epoch: 6| Step: 6
Training loss: 0.7753688097000122
Validation loss: 2.055968358952512

Epoch: 6| Step: 7
Training loss: 1.1996359825134277
Validation loss: 2.0654179229531238

Epoch: 6| Step: 8
Training loss: 1.1579700708389282
Validation loss: 2.019855007048576

Epoch: 6| Step: 9
Training loss: 1.6386637687683105
Validation loss: 2.0409408923118346

Epoch: 6| Step: 10
Training loss: 1.3127504587173462
Validation loss: 2.036074730657762

Epoch: 6| Step: 11
Training loss: 0.7217101454734802
Validation loss: 2.0062059343502088

Epoch: 6| Step: 12
Training loss: 1.3215246200561523
Validation loss: 2.0377745602720525

Epoch: 6| Step: 13
Training loss: 1.56882643699646
Validation loss: 2.048996158825454

Epoch: 590| Step: 0
Training loss: 1.631105661392212
Validation loss: 2.064634524365907

Epoch: 6| Step: 1
Training loss: 1.1265370845794678
Validation loss: 2.025696277618408

Epoch: 6| Step: 2
Training loss: 0.9211861491203308
Validation loss: 2.0479543593622025

Epoch: 6| Step: 3
Training loss: 1.581658124923706
Validation loss: 2.093266817831224

Epoch: 6| Step: 4
Training loss: 1.3799368143081665
Validation loss: 2.0752561451286398

Epoch: 6| Step: 5
Training loss: 0.939787745475769
Validation loss: 2.0864355858936103

Epoch: 6| Step: 6
Training loss: 1.1768927574157715
Validation loss: 2.097996655330863

Epoch: 6| Step: 7
Training loss: 0.7725083827972412
Validation loss: 2.052113139501182

Epoch: 6| Step: 8
Training loss: 1.2646832466125488
Validation loss: 2.0913043547702093

Epoch: 6| Step: 9
Training loss: 0.8736103773117065
Validation loss: 2.031432626067951

Epoch: 6| Step: 10
Training loss: 1.170072317123413
Validation loss: 2.038063476162572

Epoch: 6| Step: 11
Training loss: 1.332768440246582
Validation loss: 2.0618414955754436

Epoch: 6| Step: 12
Training loss: 2.000936508178711
Validation loss: 2.0549156127437467

Epoch: 6| Step: 13
Training loss: 0.9693080186843872
Validation loss: 2.021077170166918

Epoch: 591| Step: 0
Training loss: 0.9059353470802307
Validation loss: 1.9797045658993464

Epoch: 6| Step: 1
Training loss: 1.4864203929901123
Validation loss: 2.0541085786716913

Epoch: 6| Step: 2
Training loss: 1.5692462921142578
Validation loss: 2.0365492682303152

Epoch: 6| Step: 3
Training loss: 1.3715317249298096
Validation loss: 2.016257301453621

Epoch: 6| Step: 4
Training loss: 1.9004032611846924
Validation loss: 2.0019908438446703

Epoch: 6| Step: 5
Training loss: 0.9804915189743042
Validation loss: 2.023999978137273

Epoch: 6| Step: 6
Training loss: 1.2253992557525635
Validation loss: 2.063203191244474

Epoch: 6| Step: 7
Training loss: 0.3213062882423401
Validation loss: 2.0622420592974593

Epoch: 6| Step: 8
Training loss: 1.4231770038604736
Validation loss: 2.0361737794773553

Epoch: 6| Step: 9
Training loss: 1.856839656829834
Validation loss: 2.0227464091393257

Epoch: 6| Step: 10
Training loss: 0.7645717859268188
Validation loss: 2.059414807186332

Epoch: 6| Step: 11
Training loss: 1.3568907976150513
Validation loss: 2.05358729311215

Epoch: 6| Step: 12
Training loss: 1.4376099109649658
Validation loss: 2.05427598568701

Epoch: 6| Step: 13
Training loss: 1.0981953144073486
Validation loss: 2.04865518436637

Epoch: 592| Step: 0
Training loss: 1.3266725540161133
Validation loss: 2.058267328046983

Epoch: 6| Step: 1
Training loss: 0.9771498441696167
Validation loss: 2.0752184544840167

Epoch: 6| Step: 2
Training loss: 1.0560147762298584
Validation loss: 2.0581643863390853

Epoch: 6| Step: 3
Training loss: 0.7063190937042236
Validation loss: 2.07301414269273

Epoch: 6| Step: 4
Training loss: 1.4820688962936401
Validation loss: 2.078463546691402

Epoch: 6| Step: 5
Training loss: 1.1367753744125366
Validation loss: 2.0901583266514603

Epoch: 6| Step: 6
Training loss: 1.916106939315796
Validation loss: 2.0295848769526326

Epoch: 6| Step: 7
Training loss: 1.500496745109558
Validation loss: 2.0307169755299888

Epoch: 6| Step: 8
Training loss: 0.897240936756134
Validation loss: 2.053515612438161

Epoch: 6| Step: 9
Training loss: 0.9271056056022644
Validation loss: 2.0140940655944166

Epoch: 6| Step: 10
Training loss: 1.2350672483444214
Validation loss: 2.0600132211562125

Epoch: 6| Step: 11
Training loss: 0.9498917460441589
Validation loss: 1.9955809526546027

Epoch: 6| Step: 12
Training loss: 1.871906042098999
Validation loss: 2.02452721775219

Epoch: 6| Step: 13
Training loss: 1.0611199140548706
Validation loss: 2.0321583030044392

Epoch: 593| Step: 0
Training loss: 1.0823509693145752
Validation loss: 2.007780892874605

Epoch: 6| Step: 1
Training loss: 1.0641193389892578
Validation loss: 2.023343034969863

Epoch: 6| Step: 2
Training loss: 1.7510261535644531
Validation loss: 2.0352857189793743

Epoch: 6| Step: 3
Training loss: 1.04165518283844
Validation loss: 2.0436758033690916

Epoch: 6| Step: 4
Training loss: 1.7002582550048828
Validation loss: 2.0296826183155017

Epoch: 6| Step: 5
Training loss: 1.7784249782562256
Validation loss: 2.0194406868309103

Epoch: 6| Step: 6
Training loss: 1.2084399461746216
Validation loss: 2.0561398434382614

Epoch: 6| Step: 7
Training loss: 0.9831104278564453
Validation loss: 2.0588025662206833

Epoch: 6| Step: 8
Training loss: 1.1362695693969727
Validation loss: 2.050588156587334

Epoch: 6| Step: 9
Training loss: 1.5072253942489624
Validation loss: 2.042576928292551

Epoch: 6| Step: 10
Training loss: 1.0202350616455078
Validation loss: 2.0495976914641676

Epoch: 6| Step: 11
Training loss: 0.8984881043434143
Validation loss: 2.0983186306491977

Epoch: 6| Step: 12
Training loss: 1.192397117614746
Validation loss: 2.0621249573205107

Epoch: 6| Step: 13
Training loss: 1.1692389249801636
Validation loss: 2.0933044623303156

Epoch: 594| Step: 0
Training loss: 1.0567302703857422
Validation loss: 2.0637668102018294

Epoch: 6| Step: 1
Training loss: 1.3957428932189941
Validation loss: 2.0495375817821873

Epoch: 6| Step: 2
Training loss: 1.0194839239120483
Validation loss: 2.074326284470097

Epoch: 6| Step: 3
Training loss: 1.4274532794952393
Validation loss: 2.050717951149069

Epoch: 6| Step: 4
Training loss: 0.549501895904541
Validation loss: 2.031833294899233

Epoch: 6| Step: 5
Training loss: 0.6900560855865479
Validation loss: 2.084021040188369

Epoch: 6| Step: 6
Training loss: 1.5813302993774414
Validation loss: 2.067875798030566

Epoch: 6| Step: 7
Training loss: 1.2014169692993164
Validation loss: 2.003544886906942

Epoch: 6| Step: 8
Training loss: 0.9247621297836304
Validation loss: 2.031411527305521

Epoch: 6| Step: 9
Training loss: 1.5976903438568115
Validation loss: 2.019511817603983

Epoch: 6| Step: 10
Training loss: 1.5126935243606567
Validation loss: 2.0500214433157318

Epoch: 6| Step: 11
Training loss: 1.0734999179840088
Validation loss: 2.046680332511984

Epoch: 6| Step: 12
Training loss: 1.6286280155181885
Validation loss: 2.0139350493748984

Epoch: 6| Step: 13
Training loss: 1.6955885887145996
Validation loss: 2.071577318253056

Epoch: 595| Step: 0
Training loss: 1.611313819885254
Validation loss: 2.0489660116934005

Epoch: 6| Step: 1
Training loss: 1.381831169128418
Validation loss: 2.0648932226242556

Epoch: 6| Step: 2
Training loss: 1.122167944908142
Validation loss: 2.0546051635537097

Epoch: 6| Step: 3
Training loss: 1.136610507965088
Validation loss: 2.098777740232406

Epoch: 6| Step: 4
Training loss: 1.4013636112213135
Validation loss: 2.128266470406645

Epoch: 6| Step: 5
Training loss: 0.7019136548042297
Validation loss: 2.178305423387917

Epoch: 6| Step: 6
Training loss: 1.4467345476150513
Validation loss: 2.073003489484069

Epoch: 6| Step: 7
Training loss: 1.3146164417266846
Validation loss: 2.1112450707343315

Epoch: 6| Step: 8
Training loss: 1.0512659549713135
Validation loss: 2.124853495628603

Epoch: 6| Step: 9
Training loss: 1.654416561126709
Validation loss: 2.0726459410882767

Epoch: 6| Step: 10
Training loss: 1.503374695777893
Validation loss: 2.0505789518356323

Epoch: 6| Step: 11
Training loss: 0.750778079032898
Validation loss: 2.012998483514273

Epoch: 6| Step: 12
Training loss: 1.5106149911880493
Validation loss: 2.035731177176199

Epoch: 6| Step: 13
Training loss: 1.3080737590789795
Validation loss: 2.0367555515740507

Epoch: 596| Step: 0
Training loss: 1.4014391899108887
Validation loss: 2.0297828156461

Epoch: 6| Step: 1
Training loss: 1.0818021297454834
Validation loss: 1.9981723395727014

Epoch: 6| Step: 2
Training loss: 1.2924576997756958
Validation loss: 2.087880265328192

Epoch: 6| Step: 3
Training loss: 1.259260892868042
Validation loss: 2.042988015759376

Epoch: 6| Step: 4
Training loss: 1.0776443481445312
Validation loss: 2.0386740879345964

Epoch: 6| Step: 5
Training loss: 1.2415947914123535
Validation loss: 2.02496838056913

Epoch: 6| Step: 6
Training loss: 1.4970510005950928
Validation loss: 2.0219711424202047

Epoch: 6| Step: 7
Training loss: 1.3908038139343262
Validation loss: 2.0055913232987925

Epoch: 6| Step: 8
Training loss: 0.9599658250808716
Validation loss: 1.9750480100672732

Epoch: 6| Step: 9
Training loss: 1.1311386823654175
Validation loss: 2.016639568472421

Epoch: 6| Step: 10
Training loss: 1.2337883710861206
Validation loss: 2.0070503847573393

Epoch: 6| Step: 11
Training loss: 1.8068889379501343
Validation loss: 2.074627378935455

Epoch: 6| Step: 12
Training loss: 0.7451646327972412
Validation loss: 2.114339002998926

Epoch: 6| Step: 13
Training loss: 0.7689121961593628
Validation loss: 2.058480547320458

Epoch: 597| Step: 0
Training loss: 1.1201539039611816
Validation loss: 2.077287199676678

Epoch: 6| Step: 1
Training loss: 1.2521398067474365
Validation loss: 2.0603935923627628

Epoch: 6| Step: 2
Training loss: 0.5865726470947266
Validation loss: 2.098441375199185

Epoch: 6| Step: 3
Training loss: 1.248095989227295
Validation loss: 2.0563139620647637

Epoch: 6| Step: 4
Training loss: 1.929880976676941
Validation loss: 2.0287994953893844

Epoch: 6| Step: 5
Training loss: 1.0923830270767212
Validation loss: 2.0682093879227996

Epoch: 6| Step: 6
Training loss: 1.1202828884124756
Validation loss: 2.0636635134297032

Epoch: 6| Step: 7
Training loss: 0.952609121799469
Validation loss: 2.003988348027711

Epoch: 6| Step: 8
Training loss: 0.7200032472610474
Validation loss: 2.0661331056266703

Epoch: 6| Step: 9
Training loss: 1.5588548183441162
Validation loss: 2.0132670082071775

Epoch: 6| Step: 10
Training loss: 0.9711926579475403
Validation loss: 2.0037774578217538

Epoch: 6| Step: 11
Training loss: 1.5001769065856934
Validation loss: 2.037768263970652

Epoch: 6| Step: 12
Training loss: 1.483893632888794
Validation loss: 2.0353121475506852

Epoch: 6| Step: 13
Training loss: 2.0406389236450195
Validation loss: 2.0519719136658536

Epoch: 598| Step: 0
Training loss: 1.06547212600708
Validation loss: 2.042295261095929

Epoch: 6| Step: 1
Training loss: 0.7603870034217834
Validation loss: 2.055692894484407

Epoch: 6| Step: 2
Training loss: 1.0591987371444702
Validation loss: 2.0295873444567443

Epoch: 6| Step: 3
Training loss: 1.7037758827209473
Validation loss: 2.0702713176768315

Epoch: 6| Step: 4
Training loss: 0.6840892434120178
Validation loss: 2.034656009366435

Epoch: 6| Step: 5
Training loss: 1.160988450050354
Validation loss: 2.0487286749706475

Epoch: 6| Step: 6
Training loss: 1.3759486675262451
Validation loss: 2.0464598209627214

Epoch: 6| Step: 7
Training loss: 1.0483652353286743
Validation loss: 2.046021569159723

Epoch: 6| Step: 8
Training loss: 1.4827812910079956
Validation loss: 2.064790436016616

Epoch: 6| Step: 9
Training loss: 1.1075284481048584
Validation loss: 2.0515221985437537

Epoch: 6| Step: 10
Training loss: 1.4067113399505615
Validation loss: 2.035891902062201

Epoch: 6| Step: 11
Training loss: 1.0647962093353271
Validation loss: 2.0182936409468293

Epoch: 6| Step: 12
Training loss: 1.8132495880126953
Validation loss: 2.02079838578419

Epoch: 6| Step: 13
Training loss: 1.2458422183990479
Validation loss: 2.016052461439563

Epoch: 599| Step: 0
Training loss: 0.6946336627006531
Validation loss: 2.021482067723428

Epoch: 6| Step: 1
Training loss: 1.1407530307769775
Validation loss: 1.993475430755205

Epoch: 6| Step: 2
Training loss: 1.1063326597213745
Validation loss: 2.035912775224255

Epoch: 6| Step: 3
Training loss: 1.31581711769104
Validation loss: 2.012294461650233

Epoch: 6| Step: 4
Training loss: 1.1055850982666016
Validation loss: 2.013624786048807

Epoch: 6| Step: 5
Training loss: 1.0154811143875122
Validation loss: 1.991652714308872

Epoch: 6| Step: 6
Training loss: 1.683124303817749
Validation loss: 2.064092907854306

Epoch: 6| Step: 7
Training loss: 1.1517192125320435
Validation loss: 2.001930547016923

Epoch: 6| Step: 8
Training loss: 1.603556752204895
Validation loss: 2.038526556825125

Epoch: 6| Step: 9
Training loss: 1.0778167247772217
Validation loss: 2.042629300907094

Epoch: 6| Step: 10
Training loss: 1.159196376800537
Validation loss: 2.037901069528313

Epoch: 6| Step: 11
Training loss: 1.3712843656539917
Validation loss: 2.0436665127354283

Epoch: 6| Step: 12
Training loss: 1.2578270435333252
Validation loss: 2.08279372543417

Epoch: 6| Step: 13
Training loss: 0.8791714310646057
Validation loss: 2.035202862114035

Epoch: 600| Step: 0
Training loss: 0.8917633295059204
Validation loss: 2.0633874516333304

Epoch: 6| Step: 1
Training loss: 1.1723430156707764
Validation loss: 2.057866865588773

Epoch: 6| Step: 2
Training loss: 1.1535954475402832
Validation loss: 2.0767841646748204

Epoch: 6| Step: 3
Training loss: 2.0545694828033447
Validation loss: 2.0934218975805465

Epoch: 6| Step: 4
Training loss: 1.4786773920059204
Validation loss: 2.0843116160362

Epoch: 6| Step: 5
Training loss: 0.8231140375137329
Validation loss: 2.076749354280451

Epoch: 6| Step: 6
Training loss: 0.7960608005523682
Validation loss: 2.1240008133713917

Epoch: 6| Step: 7
Training loss: 1.3758327960968018
Validation loss: 2.0675553711511756

Epoch: 6| Step: 8
Training loss: 1.0759992599487305
Validation loss: 2.0600798822218374

Epoch: 6| Step: 9
Training loss: 0.8901785612106323
Validation loss: 2.066243465228747

Epoch: 6| Step: 10
Training loss: 1.2087981700897217
Validation loss: 2.0572542144406225

Epoch: 6| Step: 11
Training loss: 1.5620384216308594
Validation loss: 2.041360952520883

Epoch: 6| Step: 12
Training loss: 1.3311890363693237
Validation loss: 1.9996813484417495

Epoch: 6| Step: 13
Training loss: 0.8100616335868835
Validation loss: 2.0623333402859267

Epoch: 601| Step: 0
Training loss: 1.5249443054199219
Validation loss: 2.042783353918342

Epoch: 6| Step: 1
Training loss: 1.9258644580841064
Validation loss: 2.0491083873215543

Epoch: 6| Step: 2
Training loss: 1.1063860654830933
Validation loss: 2.0438419311277327

Epoch: 6| Step: 3
Training loss: 1.3879458904266357
Validation loss: 2.0046539024640153

Epoch: 6| Step: 4
Training loss: 1.653395652770996
Validation loss: 2.0417086642275573

Epoch: 6| Step: 5
Training loss: 1.642223834991455
Validation loss: 2.05621862283317

Epoch: 6| Step: 6
Training loss: 1.3207610845565796
Validation loss: 2.0527217567607923

Epoch: 6| Step: 7
Training loss: 0.7385120987892151
Validation loss: 2.0631013967657603

Epoch: 6| Step: 8
Training loss: 1.0243370532989502
Validation loss: 2.05059076124622

Epoch: 6| Step: 9
Training loss: 0.8307828307151794
Validation loss: 2.091907047456311

Epoch: 6| Step: 10
Training loss: 1.074493408203125
Validation loss: 2.0559765344024985

Epoch: 6| Step: 11
Training loss: 0.7590785622596741
Validation loss: 2.0352061281922045

Epoch: 6| Step: 12
Training loss: 0.6270738840103149
Validation loss: 2.0361680317950506

Epoch: 6| Step: 13
Training loss: 1.246866226196289
Validation loss: 2.025613841190133

Epoch: 602| Step: 0
Training loss: 1.3197414875030518
Validation loss: 2.0478684658645303

Epoch: 6| Step: 1
Training loss: 1.1476290225982666
Validation loss: 2.0516450276938816

Epoch: 6| Step: 2
Training loss: 0.9644184112548828
Validation loss: 2.0171521427810832

Epoch: 6| Step: 3
Training loss: 1.1308495998382568
Validation loss: 2.0414982457314768

Epoch: 6| Step: 4
Training loss: 0.8079830408096313
Validation loss: 2.033707936604818

Epoch: 6| Step: 5
Training loss: 0.818219006061554
Validation loss: 2.035992755684801

Epoch: 6| Step: 6
Training loss: 1.7346723079681396
Validation loss: 2.0560356276009673

Epoch: 6| Step: 7
Training loss: 1.1990246772766113
Validation loss: 2.049552954653258

Epoch: 6| Step: 8
Training loss: 0.8580936789512634
Validation loss: 2.0486855327442126

Epoch: 6| Step: 9
Training loss: 1.5583608150482178
Validation loss: 2.056724338121312

Epoch: 6| Step: 10
Training loss: 1.056494951248169
Validation loss: 2.0406331708354335

Epoch: 6| Step: 11
Training loss: 1.9067440032958984
Validation loss: 2.022416692908092

Epoch: 6| Step: 12
Training loss: 1.2046817541122437
Validation loss: 2.0369731790275982

Epoch: 6| Step: 13
Training loss: 1.1738638877868652
Validation loss: 2.0106464047585764

Epoch: 603| Step: 0
Training loss: 0.9858808517456055
Validation loss: 2.033739862903472

Epoch: 6| Step: 1
Training loss: 1.3360443115234375
Validation loss: 2.016246206016951

Epoch: 6| Step: 2
Training loss: 1.33902907371521
Validation loss: 2.0487514106176232

Epoch: 6| Step: 3
Training loss: 1.6425199508666992
Validation loss: 2.029653682503649

Epoch: 6| Step: 4
Training loss: 0.931722104549408
Validation loss: 2.0278800995119157

Epoch: 6| Step: 5
Training loss: 1.2047197818756104
Validation loss: 2.057029252411217

Epoch: 6| Step: 6
Training loss: 1.3195323944091797
Validation loss: 2.070530614545268

Epoch: 6| Step: 7
Training loss: 0.7345329523086548
Validation loss: 2.0061076225772982

Epoch: 6| Step: 8
Training loss: 0.9764288067817688
Validation loss: 2.047551547327349

Epoch: 6| Step: 9
Training loss: 0.8564479351043701
Validation loss: 2.0166395851360854

Epoch: 6| Step: 10
Training loss: 0.8090366125106812
Validation loss: 2.021100018614082

Epoch: 6| Step: 11
Training loss: 1.7239539623260498
Validation loss: 2.0606740777210524

Epoch: 6| Step: 12
Training loss: 1.9371167421340942
Validation loss: 2.0725980163902364

Epoch: 6| Step: 13
Training loss: 0.9215549826622009
Validation loss: 2.027635435904226

Epoch: 604| Step: 0
Training loss: 0.9603531360626221
Validation loss: 2.0003226572467434

Epoch: 6| Step: 1
Training loss: 1.1181988716125488
Validation loss: 2.0413244257691088

Epoch: 6| Step: 2
Training loss: 1.2318115234375
Validation loss: 2.0804429131169475

Epoch: 6| Step: 3
Training loss: 1.3087611198425293
Validation loss: 2.0721934815888763

Epoch: 6| Step: 4
Training loss: 1.2027071714401245
Validation loss: 2.033967709028593

Epoch: 6| Step: 5
Training loss: 1.2061619758605957
Validation loss: 2.054142763537745

Epoch: 6| Step: 6
Training loss: 1.0236331224441528
Validation loss: 2.0599980456854707

Epoch: 6| Step: 7
Training loss: 1.0367708206176758
Validation loss: 2.0599704583485923

Epoch: 6| Step: 8
Training loss: 1.3992822170257568
Validation loss: 2.0607417552701888

Epoch: 6| Step: 9
Training loss: 2.0363516807556152
Validation loss: 2.0508864605298607

Epoch: 6| Step: 10
Training loss: 0.5836999416351318
Validation loss: 2.0393892526626587

Epoch: 6| Step: 11
Training loss: 1.1075682640075684
Validation loss: 2.0428055306916595

Epoch: 6| Step: 12
Training loss: 1.733581781387329
Validation loss: 2.065919506934381

Epoch: 6| Step: 13
Training loss: 0.7191541194915771
Validation loss: 2.0185643524251957

Epoch: 605| Step: 0
Training loss: 1.5007083415985107
Validation loss: 2.0684850690185383

Epoch: 6| Step: 1
Training loss: 1.3941974639892578
Validation loss: 2.0349443830469602

Epoch: 6| Step: 2
Training loss: 0.8829206228256226
Validation loss: 2.0478108236866612

Epoch: 6| Step: 3
Training loss: 0.9935770630836487
Validation loss: 2.0240391710753083

Epoch: 6| Step: 4
Training loss: 1.5190446376800537
Validation loss: 2.0881508909245974

Epoch: 6| Step: 5
Training loss: 1.031050205230713
Validation loss: 2.008263408496816

Epoch: 6| Step: 6
Training loss: 1.8089746236801147
Validation loss: 2.030235626364267

Epoch: 6| Step: 7
Training loss: 1.4662690162658691
Validation loss: 2.0387794292101296

Epoch: 6| Step: 8
Training loss: 1.3725920915603638
Validation loss: 2.031215775397516

Epoch: 6| Step: 9
Training loss: 1.2635533809661865
Validation loss: 2.0559439710391465

Epoch: 6| Step: 10
Training loss: 0.9600495100021362
Validation loss: 2.0145838170923214

Epoch: 6| Step: 11
Training loss: 0.9399362802505493
Validation loss: 2.0305091206745436

Epoch: 6| Step: 12
Training loss: 0.8873640894889832
Validation loss: 2.060614014184603

Epoch: 6| Step: 13
Training loss: 0.9865220189094543
Validation loss: 2.0489228412669194

Epoch: 606| Step: 0
Training loss: 1.3327792882919312
Validation loss: 2.066963746983518

Epoch: 6| Step: 1
Training loss: 1.478203535079956
Validation loss: 2.0830966195752545

Epoch: 6| Step: 2
Training loss: 0.6753705739974976
Validation loss: 2.0482942083830475

Epoch: 6| Step: 3
Training loss: 1.48893141746521
Validation loss: 2.0787831044966176

Epoch: 6| Step: 4
Training loss: 1.2703195810317993
Validation loss: 2.058662990088104

Epoch: 6| Step: 5
Training loss: 0.9752991199493408
Validation loss: 2.07089671011894

Epoch: 6| Step: 6
Training loss: 1.095552921295166
Validation loss: 2.0698848129600607

Epoch: 6| Step: 7
Training loss: 1.1121103763580322
Validation loss: 2.0467273714721843

Epoch: 6| Step: 8
Training loss: 1.0692322254180908
Validation loss: 2.0148050297972975

Epoch: 6| Step: 9
Training loss: 2.3571228981018066
Validation loss: 2.0435873052125335

Epoch: 6| Step: 10
Training loss: 0.7445759177207947
Validation loss: 2.053185337333269

Epoch: 6| Step: 11
Training loss: 0.8250386118888855
Validation loss: 2.0811611452410297

Epoch: 6| Step: 12
Training loss: 1.1702795028686523
Validation loss: 2.0267197496147564

Epoch: 6| Step: 13
Training loss: 1.3302512168884277
Validation loss: 2.060784496286864

Epoch: 607| Step: 0
Training loss: 1.0704290866851807
Validation loss: 2.0214866566401657

Epoch: 6| Step: 1
Training loss: 1.3402953147888184
Validation loss: 2.079309895474424

Epoch: 6| Step: 2
Training loss: 0.8793472051620483
Validation loss: 2.0396392947884014

Epoch: 6| Step: 3
Training loss: 1.6713963747024536
Validation loss: 2.0239383161708875

Epoch: 6| Step: 4
Training loss: 1.2686078548431396
Validation loss: 2.0733575961923085

Epoch: 6| Step: 5
Training loss: 0.7376320362091064
Validation loss: 2.035410060677477

Epoch: 6| Step: 6
Training loss: 1.1442883014678955
Validation loss: 2.068386923882269

Epoch: 6| Step: 7
Training loss: 1.316988468170166
Validation loss: 2.0222009074303413

Epoch: 6| Step: 8
Training loss: 1.0337159633636475
Validation loss: 2.036118863731302

Epoch: 6| Step: 9
Training loss: 1.0517561435699463
Validation loss: 2.06055869594697

Epoch: 6| Step: 10
Training loss: 1.5125417709350586
Validation loss: 2.0434348942131124

Epoch: 6| Step: 11
Training loss: 0.962326169013977
Validation loss: 2.0375238618543072

Epoch: 6| Step: 12
Training loss: 1.499467372894287
Validation loss: 2.0265109116031277

Epoch: 6| Step: 13
Training loss: 1.1933820247650146
Validation loss: 2.0451761881510415

Epoch: 608| Step: 0
Training loss: 1.15932297706604
Validation loss: 2.0133711625170965

Epoch: 6| Step: 1
Training loss: 1.0892647504806519
Validation loss: 2.0479560821287093

Epoch: 6| Step: 2
Training loss: 1.83112370967865
Validation loss: 2.0660162279682774

Epoch: 6| Step: 3
Training loss: 1.244974970817566
Validation loss: 2.009121705127019

Epoch: 6| Step: 4
Training loss: 0.924132764339447
Validation loss: 2.0455712977276055

Epoch: 6| Step: 5
Training loss: 0.8566622734069824
Validation loss: 2.0398418006076606

Epoch: 6| Step: 6
Training loss: 1.3271232843399048
Validation loss: 2.0308282452244915

Epoch: 6| Step: 7
Training loss: 1.0208826065063477
Validation loss: 2.0646115682458364

Epoch: 6| Step: 8
Training loss: 1.2345914840698242
Validation loss: 2.0519653507458266

Epoch: 6| Step: 9
Training loss: 1.4214684963226318
Validation loss: 2.0228660183568157

Epoch: 6| Step: 10
Training loss: 1.2955812215805054
Validation loss: 2.0174414124540103

Epoch: 6| Step: 11
Training loss: 1.197037696838379
Validation loss: 2.064308145994781

Epoch: 6| Step: 12
Training loss: 1.152984380722046
Validation loss: 2.0477837285687848

Epoch: 6| Step: 13
Training loss: 0.9113216400146484
Validation loss: 2.056473716612785

Epoch: 609| Step: 0
Training loss: 1.2991955280303955
Validation loss: 2.072138809388684

Epoch: 6| Step: 1
Training loss: 1.8383569717407227
Validation loss: 2.070256197324363

Epoch: 6| Step: 2
Training loss: 1.311502456665039
Validation loss: 2.0617475227643083

Epoch: 6| Step: 3
Training loss: 1.177198886871338
Validation loss: 2.04180746821947

Epoch: 6| Step: 4
Training loss: 1.1624945402145386
Validation loss: 2.0749051647801555

Epoch: 6| Step: 5
Training loss: 0.5758364200592041
Validation loss: 2.0205736506369805

Epoch: 6| Step: 6
Training loss: 1.5004425048828125
Validation loss: 2.0298592762280534

Epoch: 6| Step: 7
Training loss: 1.1435575485229492
Validation loss: 1.9688595956371677

Epoch: 6| Step: 8
Training loss: 1.247554063796997
Validation loss: 2.051848344905402

Epoch: 6| Step: 9
Training loss: 0.8342522382736206
Validation loss: 2.043117659066313

Epoch: 6| Step: 10
Training loss: 1.0721697807312012
Validation loss: 2.0239318737419705

Epoch: 6| Step: 11
Training loss: 1.324938416481018
Validation loss: 1.9891801508524085

Epoch: 6| Step: 12
Training loss: 1.1285791397094727
Validation loss: 2.057979635013047

Epoch: 6| Step: 13
Training loss: 1.7773346900939941
Validation loss: 2.0062643686930337

Epoch: 610| Step: 0
Training loss: 1.0811079740524292
Validation loss: 2.0550881919040473

Epoch: 6| Step: 1
Training loss: 1.365997552871704
Validation loss: 2.063781499862671

Epoch: 6| Step: 2
Training loss: 1.1374053955078125
Validation loss: 2.0709721888265302

Epoch: 6| Step: 3
Training loss: 1.1438589096069336
Validation loss: 2.036317798399156

Epoch: 6| Step: 4
Training loss: 1.2707735300064087
Validation loss: 2.086658790547361

Epoch: 6| Step: 5
Training loss: 0.8625195622444153
Validation loss: 2.023245175679525

Epoch: 6| Step: 6
Training loss: 1.021937608718872
Validation loss: 2.03751076293248

Epoch: 6| Step: 7
Training loss: 1.2061837911605835
Validation loss: 2.036138262799991

Epoch: 6| Step: 8
Training loss: 1.3751633167266846
Validation loss: 2.079838652764597

Epoch: 6| Step: 9
Training loss: 1.0669279098510742
Validation loss: 2.0743841330210366

Epoch: 6| Step: 10
Training loss: 1.2851550579071045
Validation loss: 2.0443562871666363

Epoch: 6| Step: 11
Training loss: 1.5162935256958008
Validation loss: 2.07900405955571

Epoch: 6| Step: 12
Training loss: 1.2287774085998535
Validation loss: 2.0424983091251825

Epoch: 6| Step: 13
Training loss: 1.45034658908844
Validation loss: 2.0430246399294947

Epoch: 611| Step: 0
Training loss: 1.2782652378082275
Validation loss: 2.0600262239415157

Epoch: 6| Step: 1
Training loss: 1.8432087898254395
Validation loss: 2.0318010084090696

Epoch: 6| Step: 2
Training loss: 0.8654632568359375
Validation loss: 2.0080348663432623

Epoch: 6| Step: 3
Training loss: 1.2847888469696045
Validation loss: 2.01869172434653

Epoch: 6| Step: 4
Training loss: 1.1151814460754395
Validation loss: 2.0289743792626167

Epoch: 6| Step: 5
Training loss: 1.1296396255493164
Validation loss: 2.007558358612881

Epoch: 6| Step: 6
Training loss: 1.2095268964767456
Validation loss: 2.0052197947297046

Epoch: 6| Step: 7
Training loss: 1.210938811302185
Validation loss: 2.027395086903726

Epoch: 6| Step: 8
Training loss: 1.856865644454956
Validation loss: 2.061054678373439

Epoch: 6| Step: 9
Training loss: 0.9219176769256592
Validation loss: 2.021775322575723

Epoch: 6| Step: 10
Training loss: 1.1726715564727783
Validation loss: 2.049009023174163

Epoch: 6| Step: 11
Training loss: 1.1969317197799683
Validation loss: 2.070897038264941

Epoch: 6| Step: 12
Training loss: 0.9863160848617554
Validation loss: 2.065172310798399

Epoch: 6| Step: 13
Training loss: 1.0743422508239746
Validation loss: 2.041485536483026

Epoch: 612| Step: 0
Training loss: 0.680073618888855
Validation loss: 2.087591553247103

Epoch: 6| Step: 1
Training loss: 1.060907006263733
Validation loss: 2.0894808153952322

Epoch: 6| Step: 2
Training loss: 1.1933939456939697
Validation loss: 2.0611857201463435

Epoch: 6| Step: 3
Training loss: 1.0076301097869873
Validation loss: 2.082081412756315

Epoch: 6| Step: 4
Training loss: 1.7303789854049683
Validation loss: 2.0552320416255663

Epoch: 6| Step: 5
Training loss: 1.44931960105896
Validation loss: 2.063805108429283

Epoch: 6| Step: 6
Training loss: 0.9945735931396484
Validation loss: 2.0510119943208593

Epoch: 6| Step: 7
Training loss: 1.1252104043960571
Validation loss: 2.0525469869695683

Epoch: 6| Step: 8
Training loss: 0.8150748610496521
Validation loss: 2.0547215297657955

Epoch: 6| Step: 9
Training loss: 1.333875298500061
Validation loss: 2.0574888106315368

Epoch: 6| Step: 10
Training loss: 1.1108256578445435
Validation loss: 2.0249977996272426

Epoch: 6| Step: 11
Training loss: 1.3134112358093262
Validation loss: 1.9988306119877806

Epoch: 6| Step: 12
Training loss: 1.361785888671875
Validation loss: 2.027646872305101

Epoch: 6| Step: 13
Training loss: 1.6800271272659302
Validation loss: 2.0301075148326095

Epoch: 613| Step: 0
Training loss: 1.704650640487671
Validation loss: 1.998751776192778

Epoch: 6| Step: 1
Training loss: 1.1791672706604004
Validation loss: 2.058929522832235

Epoch: 6| Step: 2
Training loss: 1.1320399045944214
Validation loss: 2.0462954954434465

Epoch: 6| Step: 3
Training loss: 1.2186579704284668
Validation loss: 2.011387194356611

Epoch: 6| Step: 4
Training loss: 1.038061499595642
Validation loss: 2.0215291195018317

Epoch: 6| Step: 5
Training loss: 1.236556053161621
Validation loss: 2.0423557899331533

Epoch: 6| Step: 6
Training loss: 1.1833510398864746
Validation loss: 2.042268735106273

Epoch: 6| Step: 7
Training loss: 1.0013197660446167
Validation loss: 2.0366856116120533

Epoch: 6| Step: 8
Training loss: 1.2329766750335693
Validation loss: 2.0225028453334684

Epoch: 6| Step: 9
Training loss: 1.1542389392852783
Validation loss: 2.014980208489203

Epoch: 6| Step: 10
Training loss: 0.8902770280838013
Validation loss: 2.0603011474814465

Epoch: 6| Step: 11
Training loss: 0.7565001249313354
Validation loss: 2.0745954487913396

Epoch: 6| Step: 12
Training loss: 1.211446762084961
Validation loss: 2.1081770466219996

Epoch: 6| Step: 13
Training loss: 1.5899513959884644
Validation loss: 2.0783750728894304

Epoch: 614| Step: 0
Training loss: 1.2421107292175293
Validation loss: 2.1157749186279955

Epoch: 6| Step: 1
Training loss: 1.4729671478271484
Validation loss: 2.1459549332177765

Epoch: 6| Step: 2
Training loss: 1.3566821813583374
Validation loss: 2.1415021983526086

Epoch: 6| Step: 3
Training loss: 1.240635633468628
Validation loss: 2.0685006059626097

Epoch: 6| Step: 4
Training loss: 0.9814677238464355
Validation loss: 2.076110824461906

Epoch: 6| Step: 5
Training loss: 1.5517820119857788
Validation loss: 2.1011243635608303

Epoch: 6| Step: 6
Training loss: 1.4495346546173096
Validation loss: 2.1060868488845004

Epoch: 6| Step: 7
Training loss: 1.1746306419372559
Validation loss: 2.058948793718892

Epoch: 6| Step: 8
Training loss: 1.2606849670410156
Validation loss: 2.0340760177181614

Epoch: 6| Step: 9
Training loss: 0.6073176860809326
Validation loss: 2.0318358226488997

Epoch: 6| Step: 10
Training loss: 1.3878049850463867
Validation loss: 2.0365641655460482

Epoch: 6| Step: 11
Training loss: 1.1910061836242676
Validation loss: 2.033202120052871

Epoch: 6| Step: 12
Training loss: 0.9252365827560425
Validation loss: 2.0080017684608378

Epoch: 6| Step: 13
Training loss: 1.338858962059021
Validation loss: 2.018359232974309

Epoch: 615| Step: 0
Training loss: 1.0865548849105835
Validation loss: 2.100229505569704

Epoch: 6| Step: 1
Training loss: 1.5324026346206665
Validation loss: 2.057611685927196

Epoch: 6| Step: 2
Training loss: 0.618516743183136
Validation loss: 2.039118556566136

Epoch: 6| Step: 3
Training loss: 1.6255624294281006
Validation loss: 2.0730915877126876

Epoch: 6| Step: 4
Training loss: 0.9943712949752808
Validation loss: 2.04522789678266

Epoch: 6| Step: 5
Training loss: 1.2569489479064941
Validation loss: 2.070254556594356

Epoch: 6| Step: 6
Training loss: 1.1930623054504395
Validation loss: 2.083539714095413

Epoch: 6| Step: 7
Training loss: 0.6916177868843079
Validation loss: 2.0535417756726666

Epoch: 6| Step: 8
Training loss: 1.5504670143127441
Validation loss: 2.0181972698498796

Epoch: 6| Step: 9
Training loss: 1.768735408782959
Validation loss: 2.0342580297941804

Epoch: 6| Step: 10
Training loss: 1.1891452074050903
Validation loss: 2.0436659730890745

Epoch: 6| Step: 11
Training loss: 1.0308122634887695
Validation loss: 2.0577610397851593

Epoch: 6| Step: 12
Training loss: 0.4456605613231659
Validation loss: 2.046509542772847

Epoch: 6| Step: 13
Training loss: 1.95307457447052
Validation loss: 2.0438304408904044

Epoch: 616| Step: 0
Training loss: 0.621146559715271
Validation loss: 2.0113546027932117

Epoch: 6| Step: 1
Training loss: 1.130515217781067
Validation loss: 2.0221537877154607

Epoch: 6| Step: 2
Training loss: 0.7813185453414917
Validation loss: 2.0210138136340725

Epoch: 6| Step: 3
Training loss: 1.510618805885315
Validation loss: 2.0291762236625916

Epoch: 6| Step: 4
Training loss: 1.500678539276123
Validation loss: 2.0257619824460757

Epoch: 6| Step: 5
Training loss: 1.8018109798431396
Validation loss: 2.0299624384090467

Epoch: 6| Step: 6
Training loss: 1.2469170093536377
Validation loss: 2.0452497184917493

Epoch: 6| Step: 7
Training loss: 1.0073550939559937
Validation loss: 2.0432216659668954

Epoch: 6| Step: 8
Training loss: 0.6138099431991577
Validation loss: 2.0143855489710325

Epoch: 6| Step: 9
Training loss: 0.9896909594535828
Validation loss: 2.0332093879740727

Epoch: 6| Step: 10
Training loss: 1.3157541751861572
Validation loss: 2.0373265691982803

Epoch: 6| Step: 11
Training loss: 1.5921090841293335
Validation loss: 2.055196423684397

Epoch: 6| Step: 12
Training loss: 1.0418117046356201
Validation loss: 2.085816567943942

Epoch: 6| Step: 13
Training loss: 1.490508794784546
Validation loss: 2.074262252417944

Epoch: 617| Step: 0
Training loss: 0.9700495600700378
Validation loss: 2.0801879949467157

Epoch: 6| Step: 1
Training loss: 1.845196008682251
Validation loss: 2.0977367842069237

Epoch: 6| Step: 2
Training loss: 1.2179471254348755
Validation loss: 2.094280783848096

Epoch: 6| Step: 3
Training loss: 0.7365278601646423
Validation loss: 2.1129998930038942

Epoch: 6| Step: 4
Training loss: 1.0453476905822754
Validation loss: 2.06480210955425

Epoch: 6| Step: 5
Training loss: 1.4088051319122314
Validation loss: 1.9759992809705837

Epoch: 6| Step: 6
Training loss: 0.8975244760513306
Validation loss: 2.0118651825894593

Epoch: 6| Step: 7
Training loss: 0.9294188022613525
Validation loss: 2.0285054765721804

Epoch: 6| Step: 8
Training loss: 1.4606812000274658
Validation loss: 2.045906327104056

Epoch: 6| Step: 9
Training loss: 1.4658911228179932
Validation loss: 1.9953448541702763

Epoch: 6| Step: 10
Training loss: 1.6745762825012207
Validation loss: 2.0961049654150523

Epoch: 6| Step: 11
Training loss: 1.3341302871704102
Validation loss: 2.0411582646831388

Epoch: 6| Step: 12
Training loss: 1.0105998516082764
Validation loss: 2.019075855132072

Epoch: 6| Step: 13
Training loss: 0.7492854595184326
Validation loss: 2.0015986427184074

Epoch: 618| Step: 0
Training loss: 1.0353784561157227
Validation loss: 2.003638526444794

Epoch: 6| Step: 1
Training loss: 0.8967804908752441
Validation loss: 2.0040039785446657

Epoch: 6| Step: 2
Training loss: 1.793104887008667
Validation loss: 1.9993017617092337

Epoch: 6| Step: 3
Training loss: 0.9199739694595337
Validation loss: 2.024946762669471

Epoch: 6| Step: 4
Training loss: 1.36232328414917
Validation loss: 2.0742208291125555

Epoch: 6| Step: 5
Training loss: 1.4919594526290894
Validation loss: 2.1357906223625265

Epoch: 6| Step: 6
Training loss: 1.4329285621643066
Validation loss: 2.0780904575060775

Epoch: 6| Step: 7
Training loss: 1.1721827983856201
Validation loss: 2.083211919312836

Epoch: 6| Step: 8
Training loss: 1.389386534690857
Validation loss: 2.0537882722834104

Epoch: 6| Step: 9
Training loss: 1.3137561082839966
Validation loss: 2.0948921634304907

Epoch: 6| Step: 10
Training loss: 0.841638445854187
Validation loss: 2.076641995419738

Epoch: 6| Step: 11
Training loss: 1.1052199602127075
Validation loss: 2.048651777287965

Epoch: 6| Step: 12
Training loss: 1.1674917936325073
Validation loss: 2.024421307348436

Epoch: 6| Step: 13
Training loss: 0.9328464865684509
Validation loss: 2.017661815048546

Epoch: 619| Step: 0
Training loss: 0.8480528593063354
Validation loss: 2.064259511168285

Epoch: 6| Step: 1
Training loss: 1.1595059633255005
Validation loss: 2.01343374611229

Epoch: 6| Step: 2
Training loss: 0.9421775937080383
Validation loss: 2.050986123341386

Epoch: 6| Step: 3
Training loss: 1.1535992622375488
Validation loss: 2.0180122724143406

Epoch: 6| Step: 4
Training loss: 1.1818931102752686
Validation loss: 2.0507644107264857

Epoch: 6| Step: 5
Training loss: 1.2880651950836182
Validation loss: 2.033266362323556

Epoch: 6| Step: 6
Training loss: 1.520340919494629
Validation loss: 2.038080879437026

Epoch: 6| Step: 7
Training loss: 1.7229492664337158
Validation loss: 2.030129514714723

Epoch: 6| Step: 8
Training loss: 0.6017686128616333
Validation loss: 2.0732867551106278

Epoch: 6| Step: 9
Training loss: 0.9034638404846191
Validation loss: 2.009199975639261

Epoch: 6| Step: 10
Training loss: 1.3168869018554688
Validation loss: 2.088409671219446

Epoch: 6| Step: 11
Training loss: 1.0405452251434326
Validation loss: 2.0508266930939048

Epoch: 6| Step: 12
Training loss: 1.586165428161621
Validation loss: 2.0667862712696032

Epoch: 6| Step: 13
Training loss: 1.7988276481628418
Validation loss: 2.0516694617527786

Epoch: 620| Step: 0
Training loss: 1.952763319015503
Validation loss: 2.067381887025731

Epoch: 6| Step: 1
Training loss: 1.4719746112823486
Validation loss: 2.043921055332307

Epoch: 6| Step: 2
Training loss: 1.380704641342163
Validation loss: 2.0565756469644527

Epoch: 6| Step: 3
Training loss: 0.9803107976913452
Validation loss: 2.031173400981452

Epoch: 6| Step: 4
Training loss: 1.2230331897735596
Validation loss: 2.021388038512199

Epoch: 6| Step: 5
Training loss: 1.8160161972045898
Validation loss: 2.0231288530493297

Epoch: 6| Step: 6
Training loss: 0.8148496150970459
Validation loss: 2.015741821258299

Epoch: 6| Step: 7
Training loss: 0.43422698974609375
Validation loss: 2.0049963433255433

Epoch: 6| Step: 8
Training loss: 1.1943472623825073
Validation loss: 1.9699910020315519

Epoch: 6| Step: 9
Training loss: 0.9828100204467773
Validation loss: 2.0117289250896824

Epoch: 6| Step: 10
Training loss: 1.3546772003173828
Validation loss: 2.0549910414603447

Epoch: 6| Step: 11
Training loss: 1.1264612674713135
Validation loss: 2.054078386675927

Epoch: 6| Step: 12
Training loss: 0.8810576796531677
Validation loss: 2.0496190491543023

Epoch: 6| Step: 13
Training loss: 1.2387619018554688
Validation loss: 2.0303308758684384

Epoch: 621| Step: 0
Training loss: 1.0643084049224854
Validation loss: 2.0577944504317416

Epoch: 6| Step: 1
Training loss: 1.2286458015441895
Validation loss: 2.0210911253447175

Epoch: 6| Step: 2
Training loss: 1.0228562355041504
Validation loss: 2.034838309852026

Epoch: 6| Step: 3
Training loss: 1.504262924194336
Validation loss: 2.064010659853617

Epoch: 6| Step: 4
Training loss: 1.3287453651428223
Validation loss: 2.0480069883408083

Epoch: 6| Step: 5
Training loss: 0.8459005355834961
Validation loss: 2.072000798358712

Epoch: 6| Step: 6
Training loss: 1.9092330932617188
Validation loss: 2.061370148453661

Epoch: 6| Step: 7
Training loss: 0.9876965880393982
Validation loss: 2.0211051074407433

Epoch: 6| Step: 8
Training loss: 1.130481243133545
Validation loss: 2.0350748095461118

Epoch: 6| Step: 9
Training loss: 1.282456636428833
Validation loss: 2.0360260368675314

Epoch: 6| Step: 10
Training loss: 0.6380943655967712
Validation loss: 2.064002707440366

Epoch: 6| Step: 11
Training loss: 0.8519892692565918
Validation loss: 2.0835425097455262

Epoch: 6| Step: 12
Training loss: 1.681046962738037
Validation loss: 2.0742627882188365

Epoch: 6| Step: 13
Training loss: 1.2068244218826294
Validation loss: 2.064630513550133

Epoch: 622| Step: 0
Training loss: 1.3632214069366455
Validation loss: 2.0496764798318186

Epoch: 6| Step: 1
Training loss: 1.105046033859253
Validation loss: 2.0131754875183105

Epoch: 6| Step: 2
Training loss: 0.9954397678375244
Validation loss: 2.0456569822885657

Epoch: 6| Step: 3
Training loss: 1.3529514074325562
Validation loss: 2.015162762775216

Epoch: 6| Step: 4
Training loss: 1.5240325927734375
Validation loss: 2.048717644906813

Epoch: 6| Step: 5
Training loss: 1.1237176656723022
Validation loss: 2.0353347511701685

Epoch: 6| Step: 6
Training loss: 1.012289047241211
Validation loss: 2.0259319441292876

Epoch: 6| Step: 7
Training loss: 1.1201423406600952
Validation loss: 2.029998130695794

Epoch: 6| Step: 8
Training loss: 1.3862988948822021
Validation loss: 2.030525697174893

Epoch: 6| Step: 9
Training loss: 1.568996548652649
Validation loss: 2.056883027476649

Epoch: 6| Step: 10
Training loss: 1.129263162612915
Validation loss: 2.0363370859494774

Epoch: 6| Step: 11
Training loss: 0.7418301105499268
Validation loss: 2.0508067736061673

Epoch: 6| Step: 12
Training loss: 1.1083850860595703
Validation loss: 2.0314343834436066

Epoch: 6| Step: 13
Training loss: 0.8512242436408997
Validation loss: 2.058103822892712

Epoch: 623| Step: 0
Training loss: 1.1332541704177856
Validation loss: 2.0853134278328187

Epoch: 6| Step: 1
Training loss: 1.6536637544631958
Validation loss: 2.110700535517867

Epoch: 6| Step: 2
Training loss: 1.238642930984497
Validation loss: 2.0999124755141554

Epoch: 6| Step: 3
Training loss: 1.2830519676208496
Validation loss: 2.10791838425462

Epoch: 6| Step: 4
Training loss: 1.2282390594482422
Validation loss: 2.1202283431124944

Epoch: 6| Step: 5
Training loss: 1.3793487548828125
Validation loss: 2.0939834079434796

Epoch: 6| Step: 6
Training loss: 0.8051892518997192
Validation loss: 2.1116036779137066

Epoch: 6| Step: 7
Training loss: 1.2126516103744507
Validation loss: 2.0847556667943157

Epoch: 6| Step: 8
Training loss: 0.8904293775558472
Validation loss: 2.0508516091172413

Epoch: 6| Step: 9
Training loss: 0.9278220534324646
Validation loss: 2.025256642731287

Epoch: 6| Step: 10
Training loss: 0.8846275210380554
Validation loss: 2.008147385812575

Epoch: 6| Step: 11
Training loss: 1.2193670272827148
Validation loss: 2.0504593592818066

Epoch: 6| Step: 12
Training loss: 1.3915562629699707
Validation loss: 2.032486904051996

Epoch: 6| Step: 13
Training loss: 1.627101182937622
Validation loss: 2.02860600461242

Epoch: 624| Step: 0
Training loss: 0.7263509631156921
Validation loss: 2.0219005089934154

Epoch: 6| Step: 1
Training loss: 1.012215256690979
Validation loss: 2.017615731044482

Epoch: 6| Step: 2
Training loss: 1.3681089878082275
Validation loss: 2.0268674204426427

Epoch: 6| Step: 3
Training loss: 1.0365073680877686
Validation loss: 2.0319468898157917

Epoch: 6| Step: 4
Training loss: 1.2634481191635132
Validation loss: 2.0181519459652644

Epoch: 6| Step: 5
Training loss: 0.703713059425354
Validation loss: 2.030711640593826

Epoch: 6| Step: 6
Training loss: 1.1193342208862305
Validation loss: 2.077706657430177

Epoch: 6| Step: 7
Training loss: 1.4026315212249756
Validation loss: 2.045357870799239

Epoch: 6| Step: 8
Training loss: 1.2877848148345947
Validation loss: 2.0481649444949244

Epoch: 6| Step: 9
Training loss: 1.2563183307647705
Validation loss: 2.033869248564525

Epoch: 6| Step: 10
Training loss: 1.9888429641723633
Validation loss: 2.0373941160017446

Epoch: 6| Step: 11
Training loss: 1.0722005367279053
Validation loss: 2.0762344726952175

Epoch: 6| Step: 12
Training loss: 1.350982666015625
Validation loss: 2.066489032519761

Epoch: 6| Step: 13
Training loss: 0.3745795786380768
Validation loss: 2.100185368650703

Epoch: 625| Step: 0
Training loss: 1.8690680265426636
Validation loss: 2.095508711312407

Epoch: 6| Step: 1
Training loss: 1.1057648658752441
Validation loss: 2.0732740099712084

Epoch: 6| Step: 2
Training loss: 0.8197513818740845
Validation loss: 2.0714170202132194

Epoch: 6| Step: 3
Training loss: 0.9143306016921997
Validation loss: 2.0616726439486266

Epoch: 6| Step: 4
Training loss: 1.1782721281051636
Validation loss: 2.081186149709968

Epoch: 6| Step: 5
Training loss: 0.6529409885406494
Validation loss: 2.0348194465842298

Epoch: 6| Step: 6
Training loss: 1.2353618144989014
Validation loss: 2.0411037757832515

Epoch: 6| Step: 7
Training loss: 1.277550458908081
Validation loss: 2.0424876315619356

Epoch: 6| Step: 8
Training loss: 0.9480627775192261
Validation loss: 2.01412679431259

Epoch: 6| Step: 9
Training loss: 1.5301907062530518
Validation loss: 2.0206932842090564

Epoch: 6| Step: 10
Training loss: 1.5711427927017212
Validation loss: 2.0732922784743772

Epoch: 6| Step: 11
Training loss: 1.2902079820632935
Validation loss: 2.053461406820564

Epoch: 6| Step: 12
Training loss: 0.8657225966453552
Validation loss: 2.0768532009534937

Epoch: 6| Step: 13
Training loss: 1.5863802433013916
Validation loss: 1.9965235546071043

Epoch: 626| Step: 0
Training loss: 0.9584795236587524
Validation loss: 2.0371321734561714

Epoch: 6| Step: 1
Training loss: 1.119713306427002
Validation loss: 1.9955659604841662

Epoch: 6| Step: 2
Training loss: 2.321511745452881
Validation loss: 2.058389953387681

Epoch: 6| Step: 3
Training loss: 0.9792491793632507
Validation loss: 2.019537273273673

Epoch: 6| Step: 4
Training loss: 1.6415619850158691
Validation loss: 2.0223239955081733

Epoch: 6| Step: 5
Training loss: 1.191215991973877
Validation loss: 2.0317676721080655

Epoch: 6| Step: 6
Training loss: 1.137511134147644
Validation loss: 2.043534973616241

Epoch: 6| Step: 7
Training loss: 1.3694751262664795
Validation loss: 2.099932578302199

Epoch: 6| Step: 8
Training loss: 1.2107254266738892
Validation loss: 2.072261174519857

Epoch: 6| Step: 9
Training loss: 0.9288781881332397
Validation loss: 2.082758488193635

Epoch: 6| Step: 10
Training loss: 1.0082288980484009
Validation loss: 2.0528990094379713

Epoch: 6| Step: 11
Training loss: 0.9063223004341125
Validation loss: 2.097398284942873

Epoch: 6| Step: 12
Training loss: 0.9729516506195068
Validation loss: 2.0471322895378194

Epoch: 6| Step: 13
Training loss: 0.7599905729293823
Validation loss: 2.0067916659898657

Epoch: 627| Step: 0
Training loss: 1.2042534351348877
Validation loss: 2.0324234231825797

Epoch: 6| Step: 1
Training loss: 0.8667223453521729
Validation loss: 2.031717913125151

Epoch: 6| Step: 2
Training loss: 1.235170602798462
Validation loss: 2.0766918813028643

Epoch: 6| Step: 3
Training loss: 1.5812231302261353
Validation loss: 2.05299332064967

Epoch: 6| Step: 4
Training loss: 1.1977393627166748
Validation loss: 2.044336013896491

Epoch: 6| Step: 5
Training loss: 0.9130667448043823
Validation loss: 2.0698168111103836

Epoch: 6| Step: 6
Training loss: 0.5002223253250122
Validation loss: 2.026965865524866

Epoch: 6| Step: 7
Training loss: 1.5533701181411743
Validation loss: 2.018319191471223

Epoch: 6| Step: 8
Training loss: 1.1798094511032104
Validation loss: 2.05508041766382

Epoch: 6| Step: 9
Training loss: 1.050197958946228
Validation loss: 2.037846211464174

Epoch: 6| Step: 10
Training loss: 1.5125389099121094
Validation loss: 2.0208367839936288

Epoch: 6| Step: 11
Training loss: 0.7600400447845459
Validation loss: 2.0413440068562827

Epoch: 6| Step: 12
Training loss: 1.4928414821624756
Validation loss: 2.0510487248820644

Epoch: 6| Step: 13
Training loss: 1.609182357788086
Validation loss: 1.9975430068149362

Epoch: 628| Step: 0
Training loss: 1.0301868915557861
Validation loss: 2.013853109011086

Epoch: 6| Step: 1
Training loss: 1.2426338195800781
Validation loss: 2.0231574094423683

Epoch: 6| Step: 2
Training loss: 1.2513233423233032
Validation loss: 2.0435014399149085

Epoch: 6| Step: 3
Training loss: 1.1569682359695435
Validation loss: 2.052800838665296

Epoch: 6| Step: 4
Training loss: 1.693893551826477
Validation loss: 2.034290850803416

Epoch: 6| Step: 5
Training loss: 0.526583194732666
Validation loss: 1.9980849937726093

Epoch: 6| Step: 6
Training loss: 1.9187183380126953
Validation loss: 1.9919631147897372

Epoch: 6| Step: 7
Training loss: 1.0485938787460327
Validation loss: 2.0666432893404396

Epoch: 6| Step: 8
Training loss: 0.7858660221099854
Validation loss: 2.0821863297493226

Epoch: 6| Step: 9
Training loss: 1.3451323509216309
Validation loss: 2.0239238354467575

Epoch: 6| Step: 10
Training loss: 1.7473974227905273
Validation loss: 2.0591708306343324

Epoch: 6| Step: 11
Training loss: 1.0264191627502441
Validation loss: 2.0100126843298636

Epoch: 6| Step: 12
Training loss: 0.728613018989563
Validation loss: 2.0205333386698077

Epoch: 6| Step: 13
Training loss: 0.9730600714683533
Validation loss: 2.0939602595503612

Epoch: 629| Step: 0
Training loss: 0.8407967686653137
Validation loss: 2.0119300426975375

Epoch: 6| Step: 1
Training loss: 1.3863496780395508
Validation loss: 2.028208041703829

Epoch: 6| Step: 2
Training loss: 1.1728533506393433
Validation loss: 2.0477934370758715

Epoch: 6| Step: 3
Training loss: 1.182579755783081
Validation loss: 2.005116125588776

Epoch: 6| Step: 4
Training loss: 1.3826076984405518
Validation loss: 2.0252091359066706

Epoch: 6| Step: 5
Training loss: 1.2762664556503296
Validation loss: 2.0489684663793093

Epoch: 6| Step: 6
Training loss: 1.0205602645874023
Validation loss: 2.0234736806602887

Epoch: 6| Step: 7
Training loss: 0.8273155689239502
Validation loss: 1.984885464432419

Epoch: 6| Step: 8
Training loss: 1.3529213666915894
Validation loss: 2.053271569231505

Epoch: 6| Step: 9
Training loss: 1.0338417291641235
Validation loss: 2.0375055164419194

Epoch: 6| Step: 10
Training loss: 1.1668944358825684
Validation loss: 2.0056184107257473

Epoch: 6| Step: 11
Training loss: 1.3761544227600098
Validation loss: 2.017229494228158

Epoch: 6| Step: 12
Training loss: 1.4337842464447021
Validation loss: 2.063978902755245

Epoch: 6| Step: 13
Training loss: 0.4667844772338867
Validation loss: 2.026597968993648

Epoch: 630| Step: 0
Training loss: 1.3034913539886475
Validation loss: 2.0397196354404574

Epoch: 6| Step: 1
Training loss: 1.2533378601074219
Validation loss: 2.108177479877267

Epoch: 6| Step: 2
Training loss: 1.0025904178619385
Validation loss: 2.080149307045885

Epoch: 6| Step: 3
Training loss: 1.25529146194458
Validation loss: 2.0866158957122476

Epoch: 6| Step: 4
Training loss: 1.0441871881484985
Validation loss: 2.0675167447777203

Epoch: 6| Step: 5
Training loss: 1.5540523529052734
Validation loss: 2.070335352292625

Epoch: 6| Step: 6
Training loss: 0.9328109622001648
Validation loss: 2.062057315662343

Epoch: 6| Step: 7
Training loss: 1.1093255281448364
Validation loss: 2.047624641849149

Epoch: 6| Step: 8
Training loss: 1.3551926612854004
Validation loss: 2.0912246396464687

Epoch: 6| Step: 9
Training loss: 1.2038965225219727
Validation loss: 2.0338722531513502

Epoch: 6| Step: 10
Training loss: 1.1535366773605347
Validation loss: 1.9873659328747821

Epoch: 6| Step: 11
Training loss: 0.9414721131324768
Validation loss: 2.0041934290239887

Epoch: 6| Step: 12
Training loss: 1.0805296897888184
Validation loss: 2.039751625830127

Epoch: 6| Step: 13
Training loss: 1.9949861764907837
Validation loss: 2.006923642209781

Epoch: 631| Step: 0
Training loss: 1.1002249717712402
Validation loss: 2.0201106943109983

Epoch: 6| Step: 1
Training loss: 1.5347371101379395
Validation loss: 2.0108956316465973

Epoch: 6| Step: 2
Training loss: 1.214991807937622
Validation loss: 2.0085441092009186

Epoch: 6| Step: 3
Training loss: 1.0554678440093994
Validation loss: 1.9948101300065235

Epoch: 6| Step: 4
Training loss: 1.2229199409484863
Validation loss: 2.0301248322251024

Epoch: 6| Step: 5
Training loss: 0.9907971620559692
Validation loss: 2.0234556787757465

Epoch: 6| Step: 6
Training loss: 0.5891942977905273
Validation loss: 2.06791861339282

Epoch: 6| Step: 7
Training loss: 0.8620805740356445
Validation loss: 1.9985419729704499

Epoch: 6| Step: 8
Training loss: 1.4986695051193237
Validation loss: 2.0814154173738215

Epoch: 6| Step: 9
Training loss: 1.3401789665222168
Validation loss: 2.083293531530647

Epoch: 6| Step: 10
Training loss: 1.0719763040542603
Validation loss: 2.0633643083674933

Epoch: 6| Step: 11
Training loss: 1.730849266052246
Validation loss: 2.092675555136896

Epoch: 6| Step: 12
Training loss: 1.04499351978302
Validation loss: 2.0346156294627855

Epoch: 6| Step: 13
Training loss: 0.8439369201660156
Validation loss: 2.0421686275030977

Epoch: 632| Step: 0
Training loss: 0.9048677086830139
Validation loss: 2.0564034536320674

Epoch: 6| Step: 1
Training loss: 1.405733585357666
Validation loss: 2.0217494426235074

Epoch: 6| Step: 2
Training loss: 1.03367018699646
Validation loss: 2.0293953034185592

Epoch: 6| Step: 3
Training loss: 1.4986881017684937
Validation loss: 2.0225034093344085

Epoch: 6| Step: 4
Training loss: 0.8201740980148315
Validation loss: 2.0209030387222127

Epoch: 6| Step: 5
Training loss: 1.4710757732391357
Validation loss: 1.997973713823544

Epoch: 6| Step: 6
Training loss: 1.0784120559692383
Validation loss: 2.042846777105844

Epoch: 6| Step: 7
Training loss: 0.7572314739227295
Validation loss: 2.034680317806941

Epoch: 6| Step: 8
Training loss: 1.0269354581832886
Validation loss: 2.0375198984658844

Epoch: 6| Step: 9
Training loss: 1.359607458114624
Validation loss: 2.010599431171212

Epoch: 6| Step: 10
Training loss: 1.2921867370605469
Validation loss: 2.044489360624744

Epoch: 6| Step: 11
Training loss: 1.3270148038864136
Validation loss: 2.0464676426303003

Epoch: 6| Step: 12
Training loss: 0.8698517084121704
Validation loss: 2.0224911205230223

Epoch: 6| Step: 13
Training loss: 1.796060562133789
Validation loss: 2.0021420409602504

Epoch: 633| Step: 0
Training loss: 1.4725165367126465
Validation loss: 2.053784916477819

Epoch: 6| Step: 1
Training loss: 1.2858037948608398
Validation loss: 2.049371842415102

Epoch: 6| Step: 2
Training loss: 1.596434235572815
Validation loss: 1.9881415110762402

Epoch: 6| Step: 3
Training loss: 1.4873406887054443
Validation loss: 2.0419514897049114

Epoch: 6| Step: 4
Training loss: 0.8642300963401794
Validation loss: 2.0181135182739585

Epoch: 6| Step: 5
Training loss: 0.8637112379074097
Validation loss: 2.049262780015187

Epoch: 6| Step: 6
Training loss: 1.6863977909088135
Validation loss: 1.9785974000089912

Epoch: 6| Step: 7
Training loss: 1.473742127418518
Validation loss: 2.067074352695096

Epoch: 6| Step: 8
Training loss: 0.8809077739715576
Validation loss: 2.0313939304761988

Epoch: 6| Step: 9
Training loss: 1.0544551610946655
Validation loss: 2.048185888157096

Epoch: 6| Step: 10
Training loss: 0.952560544013977
Validation loss: 2.040432655683128

Epoch: 6| Step: 11
Training loss: 0.8736593127250671
Validation loss: 2.0337830141026485

Epoch: 6| Step: 12
Training loss: 0.8338761329650879
Validation loss: 2.0368304355170137

Epoch: 6| Step: 13
Training loss: 1.1145235300064087
Validation loss: 2.085934408249394

Epoch: 634| Step: 0
Training loss: 1.3983924388885498
Validation loss: 2.0340866888723066

Epoch: 6| Step: 1
Training loss: 1.045442819595337
Validation loss: 2.033548452520883

Epoch: 6| Step: 2
Training loss: 0.9409143328666687
Validation loss: 2.050860380613676

Epoch: 6| Step: 3
Training loss: 1.3753912448883057
Validation loss: 2.0412655902165238

Epoch: 6| Step: 4
Training loss: 0.8201088905334473
Validation loss: 2.024661848621984

Epoch: 6| Step: 5
Training loss: 1.5799694061279297
Validation loss: 1.9730661287102649

Epoch: 6| Step: 6
Training loss: 0.8595702648162842
Validation loss: 2.0248220761617026

Epoch: 6| Step: 7
Training loss: 0.9492932558059692
Validation loss: 2.0395707084286596

Epoch: 6| Step: 8
Training loss: 1.040717601776123
Validation loss: 2.0390067638889438

Epoch: 6| Step: 9
Training loss: 0.9028106927871704
Validation loss: 2.0520629869994296

Epoch: 6| Step: 10
Training loss: 1.1929142475128174
Validation loss: 2.0449247206411054

Epoch: 6| Step: 11
Training loss: 1.4088451862335205
Validation loss: 2.0495092971350557

Epoch: 6| Step: 12
Training loss: 1.493011474609375
Validation loss: 2.0956317558083484

Epoch: 6| Step: 13
Training loss: 1.33254075050354
Validation loss: 2.0796235658789195

Epoch: 635| Step: 0
Training loss: 1.4079513549804688
Validation loss: 2.071288929190687

Epoch: 6| Step: 1
Training loss: 1.6606086492538452
Validation loss: 2.033138382819391

Epoch: 6| Step: 2
Training loss: 1.577280044555664
Validation loss: 2.070132424754481

Epoch: 6| Step: 3
Training loss: 1.1329971551895142
Validation loss: 2.044632009280625

Epoch: 6| Step: 4
Training loss: 1.1437249183654785
Validation loss: 2.0812081316465973

Epoch: 6| Step: 5
Training loss: 1.1408149003982544
Validation loss: 2.0632404870884393

Epoch: 6| Step: 6
Training loss: 1.475192904472351
Validation loss: 2.033548108993038

Epoch: 6| Step: 7
Training loss: 1.2046175003051758
Validation loss: 2.0580710211107807

Epoch: 6| Step: 8
Training loss: 1.1145408153533936
Validation loss: 2.0154590683598674

Epoch: 6| Step: 9
Training loss: 1.1323442459106445
Validation loss: 2.0182397109206005

Epoch: 6| Step: 10
Training loss: 0.657640814781189
Validation loss: 2.0256407376258605

Epoch: 6| Step: 11
Training loss: 1.118107795715332
Validation loss: 1.9975809038326304

Epoch: 6| Step: 12
Training loss: 0.9931875467300415
Validation loss: 2.0275882956802205

Epoch: 6| Step: 13
Training loss: 0.4661981761455536
Validation loss: 2.0352776435113724

Epoch: 636| Step: 0
Training loss: 1.129805088043213
Validation loss: 2.047134618605337

Epoch: 6| Step: 1
Training loss: 1.191709041595459
Validation loss: 2.0350556271050566

Epoch: 6| Step: 2
Training loss: 0.5914431810379028
Validation loss: 2.061321686672908

Epoch: 6| Step: 3
Training loss: 1.2592861652374268
Validation loss: 2.0320328871409097

Epoch: 6| Step: 4
Training loss: 1.0109620094299316
Validation loss: 2.0503944786646033

Epoch: 6| Step: 5
Training loss: 1.8541347980499268
Validation loss: 2.045213460922241

Epoch: 6| Step: 6
Training loss: 1.1192879676818848
Validation loss: 2.081400327785041

Epoch: 6| Step: 7
Training loss: 1.4476513862609863
Validation loss: 2.0398879563936623

Epoch: 6| Step: 8
Training loss: 1.0049004554748535
Validation loss: 2.0768807716267084

Epoch: 6| Step: 9
Training loss: 1.3002567291259766
Validation loss: 2.0204015752320648

Epoch: 6| Step: 10
Training loss: 1.0476106405258179
Validation loss: 2.0640690890691613

Epoch: 6| Step: 11
Training loss: 1.1980544328689575
Validation loss: 2.015304729502688

Epoch: 6| Step: 12
Training loss: 1.5123603343963623
Validation loss: 2.034651252531236

Epoch: 6| Step: 13
Training loss: 1.1000245809555054
Validation loss: 2.03635214477457

Epoch: 637| Step: 0
Training loss: 1.214341402053833
Validation loss: 2.026736472242622

Epoch: 6| Step: 1
Training loss: 1.499614953994751
Validation loss: 1.993536627420815

Epoch: 6| Step: 2
Training loss: 1.0833739042282104
Validation loss: 2.037087289235925

Epoch: 6| Step: 3
Training loss: 1.2356138229370117
Validation loss: 2.0076998177395073

Epoch: 6| Step: 4
Training loss: 1.3378372192382812
Validation loss: 2.007997450008187

Epoch: 6| Step: 5
Training loss: 1.2166118621826172
Validation loss: 2.0627881250073834

Epoch: 6| Step: 6
Training loss: 0.9192436933517456
Validation loss: 2.0539248745928527

Epoch: 6| Step: 7
Training loss: 1.5062881708145142
Validation loss: 2.0518978154787453

Epoch: 6| Step: 8
Training loss: 1.2950243949890137
Validation loss: 2.0400572271757227

Epoch: 6| Step: 9
Training loss: 0.8763766288757324
Validation loss: 2.0485459168752036

Epoch: 6| Step: 10
Training loss: 1.202406644821167
Validation loss: 2.0572430882402646

Epoch: 6| Step: 11
Training loss: 0.694661021232605
Validation loss: 2.0266829741898404

Epoch: 6| Step: 12
Training loss: 1.1393511295318604
Validation loss: 2.0587988066416916

Epoch: 6| Step: 13
Training loss: 1.6051377058029175
Validation loss: 2.0348541287965674

Epoch: 638| Step: 0
Training loss: 1.035356879234314
Validation loss: 2.0138341060248752

Epoch: 6| Step: 1
Training loss: 1.5389249324798584
Validation loss: 2.0500547475712274

Epoch: 6| Step: 2
Training loss: 0.8945112228393555
Validation loss: 2.0000718793561383

Epoch: 6| Step: 3
Training loss: 0.5685961246490479
Validation loss: 2.019983891517885

Epoch: 6| Step: 4
Training loss: 0.8645656108856201
Validation loss: 2.032745320309875

Epoch: 6| Step: 5
Training loss: 0.8298980593681335
Validation loss: 2.0117877785877516

Epoch: 6| Step: 6
Training loss: 1.4528275728225708
Validation loss: 2.0363751329401487

Epoch: 6| Step: 7
Training loss: 1.124760627746582
Validation loss: 2.037856255808184

Epoch: 6| Step: 8
Training loss: 1.2751238346099854
Validation loss: 2.0255472198609383

Epoch: 6| Step: 9
Training loss: 1.0445401668548584
Validation loss: 2.037357621295478

Epoch: 6| Step: 10
Training loss: 2.05963134765625
Validation loss: 2.0185414937234696

Epoch: 6| Step: 11
Training loss: 1.2408396005630493
Validation loss: 2.041232639743436

Epoch: 6| Step: 12
Training loss: 1.0769531726837158
Validation loss: 2.016710704372775

Epoch: 6| Step: 13
Training loss: 1.5327445268630981
Validation loss: 2.051253984051366

Epoch: 639| Step: 0
Training loss: 1.115098476409912
Validation loss: 2.0486572891153316

Epoch: 6| Step: 1
Training loss: 1.5719354152679443
Validation loss: 2.024077146284042

Epoch: 6| Step: 2
Training loss: 0.5412319898605347
Validation loss: 2.0323294170441164

Epoch: 6| Step: 3
Training loss: 0.7389428019523621
Validation loss: 2.0554035427749797

Epoch: 6| Step: 4
Training loss: 0.8301844596862793
Validation loss: 2.0781864312387284

Epoch: 6| Step: 5
Training loss: 1.173215389251709
Validation loss: 2.062981882402974

Epoch: 6| Step: 6
Training loss: 1.486189842224121
Validation loss: 2.0509140773486068

Epoch: 6| Step: 7
Training loss: 1.278446912765503
Validation loss: 2.0770165586984284

Epoch: 6| Step: 8
Training loss: 1.4425387382507324
Validation loss: 2.0441837823519142

Epoch: 6| Step: 9
Training loss: 1.2777867317199707
Validation loss: 2.0859792335059053

Epoch: 6| Step: 10
Training loss: 1.042534589767456
Validation loss: 2.027098371136573

Epoch: 6| Step: 11
Training loss: 1.297577142715454
Validation loss: 2.0529936936593827

Epoch: 6| Step: 12
Training loss: 0.9051486253738403
Validation loss: 2.048556694420435

Epoch: 6| Step: 13
Training loss: 1.5673046112060547
Validation loss: 2.0357060483706895

Epoch: 640| Step: 0
Training loss: 1.2990100383758545
Validation loss: 2.0550185916244343

Epoch: 6| Step: 1
Training loss: 1.0797349214553833
Validation loss: 2.0510643361717142

Epoch: 6| Step: 2
Training loss: 1.194238305091858
Validation loss: 2.0454166807154173

Epoch: 6| Step: 3
Training loss: 0.5787810683250427
Validation loss: 1.9872433690614597

Epoch: 6| Step: 4
Training loss: 1.241623878479004
Validation loss: 2.073942261357461

Epoch: 6| Step: 5
Training loss: 1.3843785524368286
Validation loss: 2.015598835483674

Epoch: 6| Step: 6
Training loss: 1.0316205024719238
Validation loss: 2.035142901123211

Epoch: 6| Step: 7
Training loss: 1.1403751373291016
Validation loss: 2.027628949893418

Epoch: 6| Step: 8
Training loss: 1.320607304573059
Validation loss: 2.0436531702677407

Epoch: 6| Step: 9
Training loss: 1.4016289710998535
Validation loss: 2.0140735026328795

Epoch: 6| Step: 10
Training loss: 1.28328537940979
Validation loss: 2.019421651799192

Epoch: 6| Step: 11
Training loss: 1.1420881748199463
Validation loss: 2.0459190504525298

Epoch: 6| Step: 12
Training loss: 1.2625635862350464
Validation loss: 2.014501940819525

Epoch: 6| Step: 13
Training loss: 0.863702654838562
Validation loss: 2.0804496606191

Epoch: 641| Step: 0
Training loss: 1.0705525875091553
Validation loss: 2.0512280143717283

Epoch: 6| Step: 1
Training loss: 1.1482784748077393
Validation loss: 2.0629099146012337

Epoch: 6| Step: 2
Training loss: 1.153198003768921
Validation loss: 2.033813376580515

Epoch: 6| Step: 3
Training loss: 0.9830343723297119
Validation loss: 2.0814508494510444

Epoch: 6| Step: 4
Training loss: 1.0253500938415527
Validation loss: 2.0267064135561705

Epoch: 6| Step: 5
Training loss: 1.3725491762161255
Validation loss: 2.006340604956432

Epoch: 6| Step: 6
Training loss: 1.0672717094421387
Validation loss: 2.1042209491934827

Epoch: 6| Step: 7
Training loss: 1.8321796655654907
Validation loss: 2.04845675089026

Epoch: 6| Step: 8
Training loss: 1.2087143659591675
Validation loss: 2.0378555918252594

Epoch: 6| Step: 9
Training loss: 0.6827858686447144
Validation loss: 2.061221239387348

Epoch: 6| Step: 10
Training loss: 0.9162970185279846
Validation loss: 2.0287996235714165

Epoch: 6| Step: 11
Training loss: 1.453319787979126
Validation loss: 2.0068723232515397

Epoch: 6| Step: 12
Training loss: 0.9442006349563599
Validation loss: 2.026610638505669

Epoch: 6| Step: 13
Training loss: 1.3694757223129272
Validation loss: 2.0616471972516788

Epoch: 642| Step: 0
Training loss: 1.0402594804763794
Validation loss: 2.010752426680698

Epoch: 6| Step: 1
Training loss: 1.0515058040618896
Validation loss: 2.0351182222366333

Epoch: 6| Step: 2
Training loss: 0.6211737394332886
Validation loss: 2.0456425554008892

Epoch: 6| Step: 3
Training loss: 1.3076708316802979
Validation loss: 2.039159672234648

Epoch: 6| Step: 4
Training loss: 2.163079261779785
Validation loss: 2.0700686490663918

Epoch: 6| Step: 5
Training loss: 1.5162864923477173
Validation loss: 2.0191681077403407

Epoch: 6| Step: 6
Training loss: 1.141015648841858
Validation loss: 2.0197749868516

Epoch: 6| Step: 7
Training loss: 0.8840166330337524
Validation loss: 2.04297790732435

Epoch: 6| Step: 8
Training loss: 0.3905186951160431
Validation loss: 2.0849933342267106

Epoch: 6| Step: 9
Training loss: 1.05461847782135
Validation loss: 2.0697266465874127

Epoch: 6| Step: 10
Training loss: 1.0433075428009033
Validation loss: 2.087901341017856

Epoch: 6| Step: 11
Training loss: 1.549208641052246
Validation loss: 2.0815881708616852

Epoch: 6| Step: 12
Training loss: 1.159334659576416
Validation loss: 2.0563834277532433

Epoch: 6| Step: 13
Training loss: 1.5514791011810303
Validation loss: 2.03209113946525

Epoch: 643| Step: 0
Training loss: 1.5387256145477295
Validation loss: 2.083414703287104

Epoch: 6| Step: 1
Training loss: 1.1530040502548218
Validation loss: 2.012424886867564

Epoch: 6| Step: 2
Training loss: 1.22831392288208
Validation loss: 2.024563488139901

Epoch: 6| Step: 3
Training loss: 1.0789061784744263
Validation loss: 1.9929225162793232

Epoch: 6| Step: 4
Training loss: 0.9447805881500244
Validation loss: 2.0181965212668143

Epoch: 6| Step: 5
Training loss: 1.000641107559204
Validation loss: 2.030592159558368

Epoch: 6| Step: 6
Training loss: 1.1638953685760498
Validation loss: 2.0219367627174623

Epoch: 6| Step: 7
Training loss: 1.3326631784439087
Validation loss: 2.047765629265898

Epoch: 6| Step: 8
Training loss: 1.1614818572998047
Validation loss: 2.0501955683513353

Epoch: 6| Step: 9
Training loss: 1.276238203048706
Validation loss: 2.0200895237666305

Epoch: 6| Step: 10
Training loss: 1.571136474609375
Validation loss: 2.054440712416044

Epoch: 6| Step: 11
Training loss: 0.7366698980331421
Validation loss: 2.0330431486970637

Epoch: 6| Step: 12
Training loss: 1.5695972442626953
Validation loss: 1.9851657267539733

Epoch: 6| Step: 13
Training loss: 0.5928627848625183
Validation loss: 2.019865369284025

Epoch: 644| Step: 0
Training loss: 0.8408142328262329
Validation loss: 2.067760967439221

Epoch: 6| Step: 1
Training loss: 0.9670983552932739
Validation loss: 2.0586382381377684

Epoch: 6| Step: 2
Training loss: 1.2471339702606201
Validation loss: 2.092970617355839

Epoch: 6| Step: 3
Training loss: 1.3412094116210938
Validation loss: 2.0593619756801154

Epoch: 6| Step: 4
Training loss: 0.816490650177002
Validation loss: 2.0917906581714587

Epoch: 6| Step: 5
Training loss: 0.746085524559021
Validation loss: 2.059541662534078

Epoch: 6| Step: 6
Training loss: 0.7714913487434387
Validation loss: 2.0438182943610737

Epoch: 6| Step: 7
Training loss: 1.9476685523986816
Validation loss: 2.0667572508576098

Epoch: 6| Step: 8
Training loss: 1.156546711921692
Validation loss: 2.0376076595757597

Epoch: 6| Step: 9
Training loss: 1.063672661781311
Validation loss: 2.0080550486041653

Epoch: 6| Step: 10
Training loss: 1.829970121383667
Validation loss: 1.9730463604773245

Epoch: 6| Step: 11
Training loss: 0.8484312295913696
Validation loss: 2.07898344532136

Epoch: 6| Step: 12
Training loss: 1.1036264896392822
Validation loss: 2.031494394425423

Epoch: 6| Step: 13
Training loss: 2.050041437149048
Validation loss: 2.0429187179893575

Epoch: 645| Step: 0
Training loss: 1.6013253927230835
Validation loss: 2.016283533906424

Epoch: 6| Step: 1
Training loss: 1.019601821899414
Validation loss: 2.042877975330558

Epoch: 6| Step: 2
Training loss: 1.5127553939819336
Validation loss: 2.0345731063555648

Epoch: 6| Step: 3
Training loss: 0.9147013425827026
Validation loss: 2.0256415849090903

Epoch: 6| Step: 4
Training loss: 1.59324049949646
Validation loss: 2.0409188065477597

Epoch: 6| Step: 5
Training loss: 1.4017000198364258
Validation loss: 2.0241696860200618

Epoch: 6| Step: 6
Training loss: 0.6755318641662598
Validation loss: 2.0247748692830405

Epoch: 6| Step: 7
Training loss: 1.5450680255889893
Validation loss: 2.0366958020835795

Epoch: 6| Step: 8
Training loss: 1.103920578956604
Validation loss: 2.0465803761636057

Epoch: 6| Step: 9
Training loss: 1.3558893203735352
Validation loss: 2.0278843115734797

Epoch: 6| Step: 10
Training loss: 0.7409532070159912
Validation loss: 2.028997810938025

Epoch: 6| Step: 11
Training loss: 1.0664706230163574
Validation loss: 2.042073413889895

Epoch: 6| Step: 12
Training loss: 0.9292572140693665
Validation loss: 2.030706892731369

Epoch: 6| Step: 13
Training loss: 0.24840277433395386
Validation loss: 2.037483569114439

Epoch: 646| Step: 0
Training loss: 1.1647987365722656
Validation loss: 2.080835647480462

Epoch: 6| Step: 1
Training loss: 0.6212237477302551
Validation loss: 2.065995790625131

Epoch: 6| Step: 2
Training loss: 0.9264710545539856
Validation loss: 2.0348030380023423

Epoch: 6| Step: 3
Training loss: 1.6218725442886353
Validation loss: 2.0641104841745026

Epoch: 6| Step: 4
Training loss: 1.8997069597244263
Validation loss: 2.001627609293948

Epoch: 6| Step: 5
Training loss: 0.7789376378059387
Validation loss: 2.045906671913721

Epoch: 6| Step: 6
Training loss: 1.32588791847229
Validation loss: 2.0423993013238393

Epoch: 6| Step: 7
Training loss: 0.8433771729469299
Validation loss: 2.051791937120499

Epoch: 6| Step: 8
Training loss: 1.486172080039978
Validation loss: 2.0438162972850185

Epoch: 6| Step: 9
Training loss: 1.5847688913345337
Validation loss: 2.0181438012789656

Epoch: 6| Step: 10
Training loss: 0.6734781265258789
Validation loss: 2.031491511611528

Epoch: 6| Step: 11
Training loss: 1.170290231704712
Validation loss: 2.014638093210036

Epoch: 6| Step: 12
Training loss: 1.100534200668335
Validation loss: 2.0500563216465775

Epoch: 6| Step: 13
Training loss: 0.5207341313362122
Validation loss: 2.0450739078624274

Epoch: 647| Step: 0
Training loss: 0.9310806393623352
Validation loss: 2.052133580689789

Epoch: 6| Step: 1
Training loss: 1.2847578525543213
Validation loss: 2.064098115890257

Epoch: 6| Step: 2
Training loss: 1.3641138076782227
Validation loss: 2.052582859992981

Epoch: 6| Step: 3
Training loss: 1.4268125295639038
Validation loss: 2.080315525813769

Epoch: 6| Step: 4
Training loss: 1.5524870157241821
Validation loss: 2.0771751890900316

Epoch: 6| Step: 5
Training loss: 0.7144477367401123
Validation loss: 2.0519460798591695

Epoch: 6| Step: 6
Training loss: 1.0951483249664307
Validation loss: 2.0651024477456206

Epoch: 6| Step: 7
Training loss: 1.2944512367248535
Validation loss: 2.078344768093478

Epoch: 6| Step: 8
Training loss: 0.5526179075241089
Validation loss: 2.0720800481816775

Epoch: 6| Step: 9
Training loss: 0.9409518241882324
Validation loss: 2.046569070508403

Epoch: 6| Step: 10
Training loss: 1.4073777198791504
Validation loss: 2.0398035844167075

Epoch: 6| Step: 11
Training loss: 1.168066143989563
Validation loss: 2.030193357057469

Epoch: 6| Step: 12
Training loss: 1.1291038990020752
Validation loss: 2.054027088226811

Epoch: 6| Step: 13
Training loss: 1.0048073530197144
Validation loss: 2.02916254151252

Epoch: 648| Step: 0
Training loss: 1.041048288345337
Validation loss: 2.0463677003819454

Epoch: 6| Step: 1
Training loss: 1.2467668056488037
Validation loss: 1.995913464535949

Epoch: 6| Step: 2
Training loss: 0.9069355726242065
Validation loss: 2.0612244990564164

Epoch: 6| Step: 3
Training loss: 1.768962025642395
Validation loss: 2.0246993931390906

Epoch: 6| Step: 4
Training loss: 0.692756175994873
Validation loss: 2.071363534978641

Epoch: 6| Step: 5
Training loss: 1.0462422370910645
Validation loss: 2.0212304540859756

Epoch: 6| Step: 6
Training loss: 1.0236809253692627
Validation loss: 2.0212863414518294

Epoch: 6| Step: 7
Training loss: 1.3741328716278076
Validation loss: 2.032806718221275

Epoch: 6| Step: 8
Training loss: 0.7813769578933716
Validation loss: 2.057199893459197

Epoch: 6| Step: 9
Training loss: 1.9444911479949951
Validation loss: 2.0370915192429737

Epoch: 6| Step: 10
Training loss: 0.6818076372146606
Validation loss: 2.0043806158086306

Epoch: 6| Step: 11
Training loss: 0.6171988248825073
Validation loss: 2.03713724946463

Epoch: 6| Step: 12
Training loss: 1.656647801399231
Validation loss: 2.0232116560782156

Epoch: 6| Step: 13
Training loss: 1.5128304958343506
Validation loss: 2.0895132134037633

Epoch: 649| Step: 0
Training loss: 1.6041407585144043
Validation loss: 2.072823163001768

Epoch: 6| Step: 1
Training loss: 2.142941951751709
Validation loss: 2.017960097200127

Epoch: 6| Step: 2
Training loss: 0.9358018040657043
Validation loss: 2.024533656335646

Epoch: 6| Step: 3
Training loss: 0.8784612417221069
Validation loss: 2.0625270335905013

Epoch: 6| Step: 4
Training loss: 1.162808895111084
Validation loss: 2.0003613143838863

Epoch: 6| Step: 5
Training loss: 1.006809115409851
Validation loss: 2.0018508998296594

Epoch: 6| Step: 6
Training loss: 0.9585086107254028
Validation loss: 1.998368263244629

Epoch: 6| Step: 7
Training loss: 0.756409764289856
Validation loss: 2.067166269466441

Epoch: 6| Step: 8
Training loss: 0.7313552498817444
Validation loss: 2.0252895303951797

Epoch: 6| Step: 9
Training loss: 1.1776227951049805
Validation loss: 2.006192215027348

Epoch: 6| Step: 10
Training loss: 1.1762642860412598
Validation loss: 2.043636998822612

Epoch: 6| Step: 11
Training loss: 1.3349549770355225
Validation loss: 2.0502106810128815

Epoch: 6| Step: 12
Training loss: 1.090908169746399
Validation loss: 1.9976046521176574

Epoch: 6| Step: 13
Training loss: 1.091011881828308
Validation loss: 2.0677900224603634

Epoch: 650| Step: 0
Training loss: 1.1440868377685547
Validation loss: 2.0413529385802565

Epoch: 6| Step: 1
Training loss: 1.3823930025100708
Validation loss: 2.0355041155251126

Epoch: 6| Step: 2
Training loss: 1.2425774335861206
Validation loss: 2.0721496330794467

Epoch: 6| Step: 3
Training loss: 0.675734281539917
Validation loss: 2.0517860279288342

Epoch: 6| Step: 4
Training loss: 1.335193157196045
Validation loss: 2.0365681968709475

Epoch: 6| Step: 5
Training loss: 1.4867663383483887
Validation loss: 2.032245183503756

Epoch: 6| Step: 6
Training loss: 0.542244553565979
Validation loss: 2.0494257339867215

Epoch: 6| Step: 7
Training loss: 1.0898847579956055
Validation loss: 2.00650720186131

Epoch: 6| Step: 8
Training loss: 1.4449275732040405
Validation loss: 2.0435428260475077

Epoch: 6| Step: 9
Training loss: 1.045264482498169
Validation loss: 2.003497144227387

Epoch: 6| Step: 10
Training loss: 0.7888711094856262
Validation loss: 2.0290139900740756

Epoch: 6| Step: 11
Training loss: 1.5761635303497314
Validation loss: 2.042747350149257

Epoch: 6| Step: 12
Training loss: 0.9465752243995667
Validation loss: 2.013912311164282

Epoch: 6| Step: 13
Training loss: 1.1366238594055176
Validation loss: 2.027510899369435

Epoch: 651| Step: 0
Training loss: 0.8680062294006348
Validation loss: 2.029695536500664

Epoch: 6| Step: 1
Training loss: 1.3324531316757202
Validation loss: 2.002816398938497

Epoch: 6| Step: 2
Training loss: 1.3927491903305054
Validation loss: 2.0606556143811954

Epoch: 6| Step: 3
Training loss: 1.0922380685806274
Validation loss: 2.079938245076005

Epoch: 6| Step: 4
Training loss: 1.230103611946106
Validation loss: 2.0562537024098058

Epoch: 6| Step: 5
Training loss: 0.7002586126327515
Validation loss: 2.059341579355219

Epoch: 6| Step: 6
Training loss: 1.3685295581817627
Validation loss: 2.092700437832904

Epoch: 6| Step: 7
Training loss: 1.3091806173324585
Validation loss: 2.04085055217948

Epoch: 6| Step: 8
Training loss: 1.6837689876556396
Validation loss: 2.048362603751562

Epoch: 6| Step: 9
Training loss: 1.3304632902145386
Validation loss: 2.036358428257768

Epoch: 6| Step: 10
Training loss: 1.3317110538482666
Validation loss: 2.037488232376755

Epoch: 6| Step: 11
Training loss: 1.2073369026184082
Validation loss: 2.0389766539296796

Epoch: 6| Step: 12
Training loss: 0.46907079219818115
Validation loss: 2.070556240697061

Epoch: 6| Step: 13
Training loss: 0.43900975584983826
Validation loss: 2.0110422103635726

Epoch: 652| Step: 0
Training loss: 1.722717046737671
Validation loss: 2.035585113750991

Epoch: 6| Step: 1
Training loss: 1.455324411392212
Validation loss: 2.0701532235709568

Epoch: 6| Step: 2
Training loss: 0.7993367910385132
Validation loss: 2.0259709435124553

Epoch: 6| Step: 3
Training loss: 1.0312354564666748
Validation loss: 2.0581739641004995

Epoch: 6| Step: 4
Training loss: 1.2472009658813477
Validation loss: 2.0680551887840353

Epoch: 6| Step: 5
Training loss: 1.043729543685913
Validation loss: 2.0400911197867444

Epoch: 6| Step: 6
Training loss: 0.8337786197662354
Validation loss: 2.03959991598642

Epoch: 6| Step: 7
Training loss: 1.6369024515151978
Validation loss: 2.0748816741410123

Epoch: 6| Step: 8
Training loss: 0.5480639934539795
Validation loss: 2.0819587246064217

Epoch: 6| Step: 9
Training loss: 1.4206902980804443
Validation loss: 2.0395681652971493

Epoch: 6| Step: 10
Training loss: 1.109573483467102
Validation loss: 2.0428405487409202

Epoch: 6| Step: 11
Training loss: 1.1344223022460938
Validation loss: 2.0525096167800245

Epoch: 6| Step: 12
Training loss: 0.8926753997802734
Validation loss: 2.0840844287667224

Epoch: 6| Step: 13
Training loss: 1.2038925886154175
Validation loss: 2.0821843608733146

Epoch: 653| Step: 0
Training loss: 1.117714762687683
Validation loss: 2.087147001297243

Epoch: 6| Step: 1
Training loss: 1.5958232879638672
Validation loss: 2.0718504715991277

Epoch: 6| Step: 2
Training loss: 0.9456093311309814
Validation loss: 2.072883290629233

Epoch: 6| Step: 3
Training loss: 1.198344111442566
Validation loss: 2.071115929593322

Epoch: 6| Step: 4
Training loss: 0.702426016330719
Validation loss: 2.023015526033217

Epoch: 6| Step: 5
Training loss: 1.3940883874893188
Validation loss: 2.0674356042697863

Epoch: 6| Step: 6
Training loss: 1.2163945436477661
Validation loss: 2.0184776911171536

Epoch: 6| Step: 7
Training loss: 0.8461534976959229
Validation loss: 1.997649368419442

Epoch: 6| Step: 8
Training loss: 1.3557050228118896
Validation loss: 2.0121271097531883

Epoch: 6| Step: 9
Training loss: 0.7213340997695923
Validation loss: 2.0660485644494333

Epoch: 6| Step: 10
Training loss: 1.4170465469360352
Validation loss: 2.0264947260579755

Epoch: 6| Step: 11
Training loss: 1.2978615760803223
Validation loss: 2.004541343258273

Epoch: 6| Step: 12
Training loss: 1.2317886352539062
Validation loss: 2.0277450507686985

Epoch: 6| Step: 13
Training loss: 1.2176342010498047
Validation loss: 2.0342658335162747

Epoch: 654| Step: 0
Training loss: 1.0515429973602295
Validation loss: 1.9999877714341687

Epoch: 6| Step: 1
Training loss: 0.6408337950706482
Validation loss: 2.0448414792296705

Epoch: 6| Step: 2
Training loss: 0.7354987859725952
Validation loss: 2.045969238845251

Epoch: 6| Step: 3
Training loss: 0.8117823600769043
Validation loss: 2.068403256836758

Epoch: 6| Step: 4
Training loss: 1.1512479782104492
Validation loss: 2.0304131943692445

Epoch: 6| Step: 5
Training loss: 1.1400765180587769
Validation loss: 2.0278517802556357

Epoch: 6| Step: 6
Training loss: 1.3720568418502808
Validation loss: 2.0420591536388604

Epoch: 6| Step: 7
Training loss: 1.733660340309143
Validation loss: 2.0924866225129817

Epoch: 6| Step: 8
Training loss: 0.9495793581008911
Validation loss: 2.0363591486407864

Epoch: 6| Step: 9
Training loss: 0.6762269735336304
Validation loss: 2.057083117064609

Epoch: 6| Step: 10
Training loss: 1.3481407165527344
Validation loss: 2.0597906702308246

Epoch: 6| Step: 11
Training loss: 1.4424962997436523
Validation loss: 2.0372544052780315

Epoch: 6| Step: 12
Training loss: 1.7159247398376465
Validation loss: 2.083917171724381

Epoch: 6| Step: 13
Training loss: 1.4921114444732666
Validation loss: 2.0493210797668784

Epoch: 655| Step: 0
Training loss: 1.2856502532958984
Validation loss: 2.011718593617921

Epoch: 6| Step: 1
Training loss: 1.0103623867034912
Validation loss: 2.0669401704624133

Epoch: 6| Step: 2
Training loss: 1.2955453395843506
Validation loss: 2.027570850105696

Epoch: 6| Step: 3
Training loss: 1.1943261623382568
Validation loss: 2.0149040401622815

Epoch: 6| Step: 4
Training loss: 1.407869577407837
Validation loss: 2.0641803279999764

Epoch: 6| Step: 5
Training loss: 1.0032200813293457
Validation loss: 2.033878928871565

Epoch: 6| Step: 6
Training loss: 1.2571566104888916
Validation loss: 2.0021623232031382

Epoch: 6| Step: 7
Training loss: 1.3798397779464722
Validation loss: 2.0063044896689792

Epoch: 6| Step: 8
Training loss: 1.419212818145752
Validation loss: 2.0351623424919705

Epoch: 6| Step: 9
Training loss: 0.5681406259536743
Validation loss: 2.0214714401511737

Epoch: 6| Step: 10
Training loss: 1.0903934240341187
Validation loss: 2.007591885905112

Epoch: 6| Step: 11
Training loss: 1.0643786191940308
Validation loss: 2.024390120660105

Epoch: 6| Step: 12
Training loss: 1.073607087135315
Validation loss: 2.1135328918374996

Epoch: 6| Step: 13
Training loss: 1.226967692375183
Validation loss: 2.1272706677836757

Epoch: 656| Step: 0
Training loss: 1.0841330289840698
Validation loss: 2.2068309117388982

Epoch: 6| Step: 1
Training loss: 1.3899962902069092
Validation loss: 2.145922650573074

Epoch: 6| Step: 2
Training loss: 1.327694058418274
Validation loss: 2.1549182886718423

Epoch: 6| Step: 3
Training loss: 1.4318523406982422
Validation loss: 2.1386835523830947

Epoch: 6| Step: 4
Training loss: 0.9434589147567749
Validation loss: 2.1317433054729173

Epoch: 6| Step: 5
Training loss: 0.9215859770774841
Validation loss: 2.11156044467803

Epoch: 6| Step: 6
Training loss: 1.0467745065689087
Validation loss: 2.07818264602333

Epoch: 6| Step: 7
Training loss: 1.7741429805755615
Validation loss: 2.063832381720184

Epoch: 6| Step: 8
Training loss: 1.407727599143982
Validation loss: 2.0043970756633307

Epoch: 6| Step: 9
Training loss: 1.168625831604004
Validation loss: 2.029649821660852

Epoch: 6| Step: 10
Training loss: 1.199449062347412
Validation loss: 2.0065917302203435

Epoch: 6| Step: 11
Training loss: 1.1850286722183228
Validation loss: 2.002167544057292

Epoch: 6| Step: 12
Training loss: 0.9160251617431641
Validation loss: 2.08315102259318

Epoch: 6| Step: 13
Training loss: 0.8491787910461426
Validation loss: 2.041894015445504

Epoch: 657| Step: 0
Training loss: 1.524080514907837
Validation loss: 2.0518005945349254

Epoch: 6| Step: 1
Training loss: 1.50908625125885
Validation loss: 2.013171026783605

Epoch: 6| Step: 2
Training loss: 0.7714579105377197
Validation loss: 2.028149151032971

Epoch: 6| Step: 3
Training loss: 1.390882134437561
Validation loss: 2.0323074145983626

Epoch: 6| Step: 4
Training loss: 0.7197688221931458
Validation loss: 2.0066712569164973

Epoch: 6| Step: 5
Training loss: 1.0987696647644043
Validation loss: 2.0442468620115712

Epoch: 6| Step: 6
Training loss: 1.2026818990707397
Validation loss: 2.0835362262623285

Epoch: 6| Step: 7
Training loss: 0.7861605286598206
Validation loss: 2.0523802285553305

Epoch: 6| Step: 8
Training loss: 1.5214014053344727
Validation loss: 2.056535768252547

Epoch: 6| Step: 9
Training loss: 1.2197619676589966
Validation loss: 2.0535287472509567

Epoch: 6| Step: 10
Training loss: 1.4471936225891113
Validation loss: 2.05791841142921

Epoch: 6| Step: 11
Training loss: 1.1656150817871094
Validation loss: 2.0463264693496046

Epoch: 6| Step: 12
Training loss: 1.1262567043304443
Validation loss: 2.045724174027802

Epoch: 6| Step: 13
Training loss: 0.7425367832183838
Validation loss: 2.0377285211317

Epoch: 658| Step: 0
Training loss: 0.6092050075531006
Validation loss: 2.0210116063394854

Epoch: 6| Step: 1
Training loss: 1.0441274642944336
Validation loss: 2.060901634154781

Epoch: 6| Step: 2
Training loss: 0.7523024678230286
Validation loss: 2.028153839931693

Epoch: 6| Step: 3
Training loss: 0.8275792002677917
Validation loss: 2.050908109193207

Epoch: 6| Step: 4
Training loss: 1.7228047847747803
Validation loss: 2.033328560090834

Epoch: 6| Step: 5
Training loss: 1.149158239364624
Validation loss: 2.0477061989486858

Epoch: 6| Step: 6
Training loss: 1.3397374153137207
Validation loss: 2.0309179547012493

Epoch: 6| Step: 7
Training loss: 1.3944330215454102
Validation loss: 2.0382970776609195

Epoch: 6| Step: 8
Training loss: 1.1713674068450928
Validation loss: 2.0672091976288827

Epoch: 6| Step: 9
Training loss: 0.8983955979347229
Validation loss: 2.071807284508982

Epoch: 6| Step: 10
Training loss: 1.6337342262268066
Validation loss: 2.0275706988508984

Epoch: 6| Step: 11
Training loss: 1.4792537689208984
Validation loss: 2.088651011067052

Epoch: 6| Step: 12
Training loss: 1.11366868019104
Validation loss: 2.040611787508893

Epoch: 6| Step: 13
Training loss: 0.6694999933242798
Validation loss: 2.0423497153866674

Epoch: 659| Step: 0
Training loss: 1.1392918825149536
Validation loss: 2.066065422950252

Epoch: 6| Step: 1
Training loss: 0.5339854955673218
Validation loss: 2.0617547394126974

Epoch: 6| Step: 2
Training loss: 0.5104416608810425
Validation loss: 2.031273936712614

Epoch: 6| Step: 3
Training loss: 0.8803602457046509
Validation loss: 2.052990851863738

Epoch: 6| Step: 4
Training loss: 1.015056848526001
Validation loss: 2.032109014449581

Epoch: 6| Step: 5
Training loss: 1.717893362045288
Validation loss: 2.077264957530524

Epoch: 6| Step: 6
Training loss: 1.5188013315200806
Validation loss: 2.0809411797472226

Epoch: 6| Step: 7
Training loss: 0.8614631295204163
Validation loss: 2.0731172471918087

Epoch: 6| Step: 8
Training loss: 0.9151340126991272
Validation loss: 2.0529952382528656

Epoch: 6| Step: 9
Training loss: 1.4261958599090576
Validation loss: 2.052783663554858

Epoch: 6| Step: 10
Training loss: 0.8280736207962036
Validation loss: 2.0663715229239514

Epoch: 6| Step: 11
Training loss: 2.1604225635528564
Validation loss: 2.0491862912331857

Epoch: 6| Step: 12
Training loss: 1.1644768714904785
Validation loss: 2.0276082408043647

Epoch: 6| Step: 13
Training loss: 0.9977335333824158
Validation loss: 2.040395729003414

Epoch: 660| Step: 0
Training loss: 1.1838265657424927
Validation loss: 2.017795926781111

Epoch: 6| Step: 1
Training loss: 0.7322404384613037
Validation loss: 2.045167043644895

Epoch: 6| Step: 2
Training loss: 1.043439507484436
Validation loss: 2.011250029328049

Epoch: 6| Step: 3
Training loss: 1.6010982990264893
Validation loss: 2.0502962681554977

Epoch: 6| Step: 4
Training loss: 1.26387619972229
Validation loss: 2.0063578685124717

Epoch: 6| Step: 5
Training loss: 0.7122198343276978
Validation loss: 2.0247339228148102

Epoch: 6| Step: 6
Training loss: 0.8312569856643677
Validation loss: 2.0305755010215183

Epoch: 6| Step: 7
Training loss: 1.5306779146194458
Validation loss: 2.0816604911640124

Epoch: 6| Step: 8
Training loss: 1.3510260581970215
Validation loss: 2.015328609815208

Epoch: 6| Step: 9
Training loss: 0.8583017587661743
Validation loss: 2.0253572617807696

Epoch: 6| Step: 10
Training loss: 0.8134130239486694
Validation loss: 2.064406898713881

Epoch: 6| Step: 11
Training loss: 1.081788182258606
Validation loss: 2.0373833051291843

Epoch: 6| Step: 12
Training loss: 1.441619634628296
Validation loss: 2.106505282463566

Epoch: 6| Step: 13
Training loss: 1.6232390403747559
Validation loss: 2.072106297298144

Epoch: 661| Step: 0
Training loss: 0.6611308455467224
Validation loss: 2.035336377800152

Epoch: 6| Step: 1
Training loss: 1.5333209037780762
Validation loss: 2.0533756107412358

Epoch: 6| Step: 2
Training loss: 0.6444337368011475
Validation loss: 2.0353825784498647

Epoch: 6| Step: 3
Training loss: 1.367859125137329
Validation loss: 2.034039813985107

Epoch: 6| Step: 4
Training loss: 0.8035390973091125
Validation loss: 2.035245410857662

Epoch: 6| Step: 5
Training loss: 0.8894609212875366
Validation loss: 2.0387080984730876

Epoch: 6| Step: 6
Training loss: 1.2226026058197021
Validation loss: 2.0603483159054994

Epoch: 6| Step: 7
Training loss: 1.1554765701293945
Validation loss: 2.01252733507464

Epoch: 6| Step: 8
Training loss: 1.2483059167861938
Validation loss: 2.0303523745588077

Epoch: 6| Step: 9
Training loss: 1.4571633338928223
Validation loss: 2.030264127639032

Epoch: 6| Step: 10
Training loss: 1.3571281433105469
Validation loss: 2.019364292903613

Epoch: 6| Step: 11
Training loss: 1.21610689163208
Validation loss: 2.0210804247087046

Epoch: 6| Step: 12
Training loss: 0.9517932534217834
Validation loss: 2.041996919980613

Epoch: 6| Step: 13
Training loss: 1.3588488101959229
Validation loss: 2.051627738501436

Epoch: 662| Step: 0
Training loss: 0.7012425661087036
Validation loss: 2.0482047809067594

Epoch: 6| Step: 1
Training loss: 1.8212478160858154
Validation loss: 2.0318490253981722

Epoch: 6| Step: 2
Training loss: 1.204985499382019
Validation loss: 2.0607262016624532

Epoch: 6| Step: 3
Training loss: 1.1228432655334473
Validation loss: 2.0404443279389413

Epoch: 6| Step: 4
Training loss: 1.30177903175354
Validation loss: 2.0209218455899145

Epoch: 6| Step: 5
Training loss: 0.9605182409286499
Validation loss: 2.0531501898201565

Epoch: 6| Step: 6
Training loss: 0.7033503651618958
Validation loss: 2.0805130004882812

Epoch: 6| Step: 7
Training loss: 0.8783601522445679
Validation loss: 2.0475452792259956

Epoch: 6| Step: 8
Training loss: 1.2488868236541748
Validation loss: 2.073453305869974

Epoch: 6| Step: 9
Training loss: 0.968390166759491
Validation loss: 2.048952987117152

Epoch: 6| Step: 10
Training loss: 0.9297782182693481
Validation loss: 2.0487309796835786

Epoch: 6| Step: 11
Training loss: 1.3027561902999878
Validation loss: 2.0437964008700464

Epoch: 6| Step: 12
Training loss: 1.1860485076904297
Validation loss: 2.007664739444692

Epoch: 6| Step: 13
Training loss: 1.8070693016052246
Validation loss: 2.036407134866202

Epoch: 663| Step: 0
Training loss: 1.121423363685608
Validation loss: 1.998719730684834

Epoch: 6| Step: 1
Training loss: 0.9884940981864929
Validation loss: 2.0546646733437814

Epoch: 6| Step: 2
Training loss: 1.1438634395599365
Validation loss: 1.9835639602394515

Epoch: 6| Step: 3
Training loss: 1.0821119546890259
Validation loss: 2.0496463403906873

Epoch: 6| Step: 4
Training loss: 1.133766531944275
Validation loss: 2.007439476187511

Epoch: 6| Step: 5
Training loss: 1.1734049320220947
Validation loss: 1.9858986767389442

Epoch: 6| Step: 6
Training loss: 0.841506838798523
Validation loss: 2.044506283216579

Epoch: 6| Step: 7
Training loss: 1.3985092639923096
Validation loss: 2.0375778700715754

Epoch: 6| Step: 8
Training loss: 1.1108893156051636
Validation loss: 2.065596377977761

Epoch: 6| Step: 9
Training loss: 1.41670823097229
Validation loss: 2.05534218588183

Epoch: 6| Step: 10
Training loss: 1.2727030515670776
Validation loss: 2.0293986156422603

Epoch: 6| Step: 11
Training loss: 1.467437744140625
Validation loss: 2.0405003409231863

Epoch: 6| Step: 12
Training loss: 0.5026496648788452
Validation loss: 2.0238574884271108

Epoch: 6| Step: 13
Training loss: 1.366678237915039
Validation loss: 2.031728862434305

Epoch: 664| Step: 0
Training loss: 1.2281999588012695
Validation loss: 2.0448781559544225

Epoch: 6| Step: 1
Training loss: 0.9639343023300171
Validation loss: 2.0566895879724973

Epoch: 6| Step: 2
Training loss: 1.0594309568405151
Validation loss: 2.0219226075756933

Epoch: 6| Step: 3
Training loss: 1.1790680885314941
Validation loss: 2.027820764049407

Epoch: 6| Step: 4
Training loss: 1.1335607767105103
Validation loss: 2.034492297839093

Epoch: 6| Step: 5
Training loss: 1.2340986728668213
Validation loss: 2.043509098791307

Epoch: 6| Step: 6
Training loss: 1.6424651145935059
Validation loss: 2.0293156472585534

Epoch: 6| Step: 7
Training loss: 2.2906646728515625
Validation loss: 2.026233111658404

Epoch: 6| Step: 8
Training loss: 0.7540857791900635
Validation loss: 2.0278284549713135

Epoch: 6| Step: 9
Training loss: 0.8563768863677979
Validation loss: 2.031399429485362

Epoch: 6| Step: 10
Training loss: 0.9485731720924377
Validation loss: 2.02313942422149

Epoch: 6| Step: 11
Training loss: 0.5792083740234375
Validation loss: 2.0250797835729455

Epoch: 6| Step: 12
Training loss: 1.1615110635757446
Validation loss: 1.9972786852108535

Epoch: 6| Step: 13
Training loss: 1.1641674041748047
Validation loss: 2.0237174931392876

Epoch: 665| Step: 0
Training loss: 1.853247880935669
Validation loss: 2.0556579277079594

Epoch: 6| Step: 1
Training loss: 0.9300104379653931
Validation loss: 2.028669877718854

Epoch: 6| Step: 2
Training loss: 0.7127877473831177
Validation loss: 2.020453747882638

Epoch: 6| Step: 3
Training loss: 0.7442508339881897
Validation loss: 2.0455090256147486

Epoch: 6| Step: 4
Training loss: 1.466974139213562
Validation loss: 2.0095204332823395

Epoch: 6| Step: 5
Training loss: 0.8807225823402405
Validation loss: 2.0192852917537896

Epoch: 6| Step: 6
Training loss: 1.0388264656066895
Validation loss: 2.0204657559753745

Epoch: 6| Step: 7
Training loss: 1.2159128189086914
Validation loss: 2.0393409472639843

Epoch: 6| Step: 8
Training loss: 1.1315820217132568
Validation loss: 2.0081877041888494

Epoch: 6| Step: 9
Training loss: 0.7882383465766907
Validation loss: 2.036364261822034

Epoch: 6| Step: 10
Training loss: 1.144258975982666
Validation loss: 2.0334916140443537

Epoch: 6| Step: 11
Training loss: 1.560653567314148
Validation loss: 2.046772369774439

Epoch: 6| Step: 12
Training loss: 1.1850566864013672
Validation loss: 2.037474310526284

Epoch: 6| Step: 13
Training loss: 1.141511082649231
Validation loss: 2.056006257252027

Epoch: 666| Step: 0
Training loss: 1.1855506896972656
Validation loss: 2.058951679096427

Epoch: 6| Step: 1
Training loss: 0.6461799144744873
Validation loss: 2.0172475691764586

Epoch: 6| Step: 2
Training loss: 1.3985837697982788
Validation loss: 2.0236119454906834

Epoch: 6| Step: 3
Training loss: 1.7623000144958496
Validation loss: 2.045866950865715

Epoch: 6| Step: 4
Training loss: 1.2577896118164062
Validation loss: 2.047836205010773

Epoch: 6| Step: 5
Training loss: 1.359960913658142
Validation loss: 2.0176057764278945

Epoch: 6| Step: 6
Training loss: 0.9851579070091248
Validation loss: 2.0116812016374324

Epoch: 6| Step: 7
Training loss: 1.0231590270996094
Validation loss: 2.016807762525415

Epoch: 6| Step: 8
Training loss: 0.8604170083999634
Validation loss: 1.9915246604591288

Epoch: 6| Step: 9
Training loss: 1.5692733526229858
Validation loss: 1.9900057136371572

Epoch: 6| Step: 10
Training loss: 0.8735772371292114
Validation loss: 2.027675918353501

Epoch: 6| Step: 11
Training loss: 0.9593024849891663
Validation loss: 2.0405505011158604

Epoch: 6| Step: 12
Training loss: 1.1573158502578735
Validation loss: 2.001104970132151

Epoch: 6| Step: 13
Training loss: 1.0619817972183228
Validation loss: 2.0310398468407254

Epoch: 667| Step: 0
Training loss: 0.9702741503715515
Validation loss: 2.041496325564641

Epoch: 6| Step: 1
Training loss: 1.7677998542785645
Validation loss: 2.026029066372943

Epoch: 6| Step: 2
Training loss: 0.9660397171974182
Validation loss: 2.0691593641875894

Epoch: 6| Step: 3
Training loss: 1.1229991912841797
Validation loss: 2.0332292972072477

Epoch: 6| Step: 4
Training loss: 0.9343980550765991
Validation loss: 2.020577202561081

Epoch: 6| Step: 5
Training loss: 0.8305467367172241
Validation loss: 2.049200124638055

Epoch: 6| Step: 6
Training loss: 0.938490092754364
Validation loss: 2.006389597410797

Epoch: 6| Step: 7
Training loss: 1.3817588090896606
Validation loss: 2.0100005493369153

Epoch: 6| Step: 8
Training loss: 1.0373079776763916
Validation loss: 1.9950782034986763

Epoch: 6| Step: 9
Training loss: 1.5317620038986206
Validation loss: 2.0407889709677747

Epoch: 6| Step: 10
Training loss: 0.9744820594787598
Validation loss: 1.9909243378587949

Epoch: 6| Step: 11
Training loss: 1.3664278984069824
Validation loss: 2.009037458768455

Epoch: 6| Step: 12
Training loss: 0.7071899771690369
Validation loss: 2.015165105942757

Epoch: 6| Step: 13
Training loss: 1.4196170568466187
Validation loss: 2.0048848634125083

Epoch: 668| Step: 0
Training loss: 1.2730703353881836
Validation loss: 2.0280770460764566

Epoch: 6| Step: 1
Training loss: 1.29564368724823
Validation loss: 2.0633337792529853

Epoch: 6| Step: 2
Training loss: 0.802511990070343
Validation loss: 2.0634576812867196

Epoch: 6| Step: 3
Training loss: 0.5009709000587463
Validation loss: 2.094028312672851

Epoch: 6| Step: 4
Training loss: 1.0651850700378418
Validation loss: 2.034222370834761

Epoch: 6| Step: 5
Training loss: 1.031243085861206
Validation loss: 2.0699196220726095

Epoch: 6| Step: 6
Training loss: 1.0563249588012695
Validation loss: 2.050343895471224

Epoch: 6| Step: 7
Training loss: 0.9624586701393127
Validation loss: 2.0078802352310507

Epoch: 6| Step: 8
Training loss: 0.8840655088424683
Validation loss: 2.022278795960129

Epoch: 6| Step: 9
Training loss: 1.0769556760787964
Validation loss: 2.004037482764131

Epoch: 6| Step: 10
Training loss: 1.6361057758331299
Validation loss: 2.0218449036280313

Epoch: 6| Step: 11
Training loss: 1.2806496620178223
Validation loss: 2.0262253079363095

Epoch: 6| Step: 12
Training loss: 1.7771039009094238
Validation loss: 1.9955029103063768

Epoch: 6| Step: 13
Training loss: 1.097732663154602
Validation loss: 2.0194479368066274

Epoch: 669| Step: 0
Training loss: 1.2009916305541992
Validation loss: 2.0103526807600454

Epoch: 6| Step: 1
Training loss: 1.882443904876709
Validation loss: 2.026555258740661

Epoch: 6| Step: 2
Training loss: 1.0526173114776611
Validation loss: 2.0604526817157702

Epoch: 6| Step: 3
Training loss: 0.8654694557189941
Validation loss: 2.08299284596597

Epoch: 6| Step: 4
Training loss: 0.8996734619140625
Validation loss: 2.0458318751345397

Epoch: 6| Step: 5
Training loss: 1.6894700527191162
Validation loss: 2.060714017960333

Epoch: 6| Step: 6
Training loss: 1.299356460571289
Validation loss: 2.1076909239574144

Epoch: 6| Step: 7
Training loss: 0.9208287000656128
Validation loss: 2.0301843920061664

Epoch: 6| Step: 8
Training loss: 1.351897954940796
Validation loss: 2.037511484597319

Epoch: 6| Step: 9
Training loss: 0.9681819677352905
Validation loss: 2.031582481117659

Epoch: 6| Step: 10
Training loss: 1.0072013139724731
Validation loss: 2.0150367982925905

Epoch: 6| Step: 11
Training loss: 1.046783447265625
Validation loss: 2.0111122080074844

Epoch: 6| Step: 12
Training loss: 0.7078238129615784
Validation loss: 1.9960244112117316

Epoch: 6| Step: 13
Training loss: 1.2558103799819946
Validation loss: 2.033412242448458

Epoch: 670| Step: 0
Training loss: 1.108487606048584
Validation loss: 1.9821504341658724

Epoch: 6| Step: 1
Training loss: 0.8593971729278564
Validation loss: 1.9708312044861496

Epoch: 6| Step: 2
Training loss: 1.5358374118804932
Validation loss: 2.0254982299702142

Epoch: 6| Step: 3
Training loss: 1.6541969776153564
Validation loss: 2.0179431681991904

Epoch: 6| Step: 4
Training loss: 0.6976719498634338
Validation loss: 2.025081037193216

Epoch: 6| Step: 5
Training loss: 1.142866611480713
Validation loss: 2.071243164359882

Epoch: 6| Step: 6
Training loss: 0.75657719373703
Validation loss: 1.9718204570072952

Epoch: 6| Step: 7
Training loss: 1.5544865131378174
Validation loss: 1.9942772567913096

Epoch: 6| Step: 8
Training loss: 1.4750670194625854
Validation loss: 2.028524843595361

Epoch: 6| Step: 9
Training loss: 0.9426447749137878
Validation loss: 1.9939844941580167

Epoch: 6| Step: 10
Training loss: 1.071502685546875
Validation loss: 2.008312976488503

Epoch: 6| Step: 11
Training loss: 0.8862999677658081
Validation loss: 2.008092518775694

Epoch: 6| Step: 12
Training loss: 1.028140664100647
Validation loss: 2.0109178122653755

Epoch: 6| Step: 13
Training loss: 1.0994601249694824
Validation loss: 1.9865846480092695

Epoch: 671| Step: 0
Training loss: 1.4892913103103638
Validation loss: 2.012831470017792

Epoch: 6| Step: 1
Training loss: 0.7300682067871094
Validation loss: 2.0691023231834493

Epoch: 6| Step: 2
Training loss: 1.6112635135650635
Validation loss: 2.048042679345736

Epoch: 6| Step: 3
Training loss: 0.8336887359619141
Validation loss: 2.053701105938163

Epoch: 6| Step: 4
Training loss: 1.4092118740081787
Validation loss: 2.024350507285005

Epoch: 6| Step: 5
Training loss: 1.2139182090759277
Validation loss: 2.1071480845892303

Epoch: 6| Step: 6
Training loss: 1.0728623867034912
Validation loss: 2.0160164986887286

Epoch: 6| Step: 7
Training loss: 1.5439400672912598
Validation loss: 2.025042264692245

Epoch: 6| Step: 8
Training loss: 0.8608859777450562
Validation loss: 2.0422056951830463

Epoch: 6| Step: 9
Training loss: 1.2187210321426392
Validation loss: 2.0570480464607157

Epoch: 6| Step: 10
Training loss: 0.8184986710548401
Validation loss: 2.0527557698629235

Epoch: 6| Step: 11
Training loss: 0.6076072454452515
Validation loss: 2.0635324524294947

Epoch: 6| Step: 12
Training loss: 1.4625535011291504
Validation loss: 2.0454352466008996

Epoch: 6| Step: 13
Training loss: 1.5314311981201172
Validation loss: 2.0328143847885953

Epoch: 672| Step: 0
Training loss: 1.517091989517212
Validation loss: 2.0463832783442673

Epoch: 6| Step: 1
Training loss: 1.1632407903671265
Validation loss: 2.0185748120789886

Epoch: 6| Step: 2
Training loss: 1.3508305549621582
Validation loss: 2.0240696143078547

Epoch: 6| Step: 3
Training loss: 1.3372540473937988
Validation loss: 2.0525937336747364

Epoch: 6| Step: 4
Training loss: 0.9143982529640198
Validation loss: 1.9833268632170975

Epoch: 6| Step: 5
Training loss: 0.9757214784622192
Validation loss: 2.010490596935313

Epoch: 6| Step: 6
Training loss: 0.6315566301345825
Validation loss: 1.9910502177412792

Epoch: 6| Step: 7
Training loss: 1.2603912353515625
Validation loss: 2.0025898448882566

Epoch: 6| Step: 8
Training loss: 0.650223433971405
Validation loss: 2.008815457743983

Epoch: 6| Step: 9
Training loss: 1.265305757522583
Validation loss: 2.0107935346582884

Epoch: 6| Step: 10
Training loss: 1.1440314054489136
Validation loss: 2.0396470100648942

Epoch: 6| Step: 11
Training loss: 1.3952187299728394
Validation loss: 2.046943486377757

Epoch: 6| Step: 12
Training loss: 1.5028870105743408
Validation loss: 2.044556289590815

Epoch: 6| Step: 13
Training loss: 0.6187146306037903
Validation loss: 2.045572578266103

Epoch: 673| Step: 0
Training loss: 0.781088650226593
Validation loss: 2.080793465337446

Epoch: 6| Step: 1
Training loss: 0.6660804748535156
Validation loss: 2.0268910982275523

Epoch: 6| Step: 2
Training loss: 1.038920521736145
Validation loss: 2.0515685927483345

Epoch: 6| Step: 3
Training loss: 1.3105194568634033
Validation loss: 2.0801291324759044

Epoch: 6| Step: 4
Training loss: 1.263043999671936
Validation loss: 2.0501608707571544

Epoch: 6| Step: 5
Training loss: 1.0255157947540283
Validation loss: 2.0074920244114374

Epoch: 6| Step: 6
Training loss: 1.5409514904022217
Validation loss: 2.022638670859798

Epoch: 6| Step: 7
Training loss: 0.8082672357559204
Validation loss: 2.036582271258036

Epoch: 6| Step: 8
Training loss: 1.0504302978515625
Validation loss: 2.0560717762157483

Epoch: 6| Step: 9
Training loss: 1.5337212085723877
Validation loss: 2.0217561580801524

Epoch: 6| Step: 10
Training loss: 1.710488200187683
Validation loss: 1.9844074813268517

Epoch: 6| Step: 11
Training loss: 1.1716557741165161
Validation loss: 2.021931955891271

Epoch: 6| Step: 12
Training loss: 0.9531115889549255
Validation loss: 2.0123959074738207

Epoch: 6| Step: 13
Training loss: 0.5978600978851318
Validation loss: 2.006789286931356

Epoch: 674| Step: 0
Training loss: 0.9817020893096924
Validation loss: 2.0341125765154437

Epoch: 6| Step: 1
Training loss: 0.7762263417243958
Validation loss: 2.0802420826368433

Epoch: 6| Step: 2
Training loss: 0.9348235726356506
Validation loss: 2.047837448376481

Epoch: 6| Step: 3
Training loss: 1.507176160812378
Validation loss: 2.0489432222099713

Epoch: 6| Step: 4
Training loss: 1.0372130870819092
Validation loss: 2.045848866944672

Epoch: 6| Step: 5
Training loss: 0.7390366196632385
Validation loss: 2.0415606588445683

Epoch: 6| Step: 6
Training loss: 1.0388983488082886
Validation loss: 2.0484009250517814

Epoch: 6| Step: 7
Training loss: 0.6488019227981567
Validation loss: 2.0168171800592893

Epoch: 6| Step: 8
Training loss: 1.7586166858673096
Validation loss: 2.0201007320034887

Epoch: 6| Step: 9
Training loss: 1.4655687808990479
Validation loss: 2.0419106560368694

Epoch: 6| Step: 10
Training loss: 1.3868114948272705
Validation loss: 1.9963135386026034

Epoch: 6| Step: 11
Training loss: 1.3037128448486328
Validation loss: 2.0017735163370767

Epoch: 6| Step: 12
Training loss: 0.7469394207000732
Validation loss: 2.019790137967756

Epoch: 6| Step: 13
Training loss: 2.109537124633789
Validation loss: 2.01352515656461

Epoch: 675| Step: 0
Training loss: 0.9297754764556885
Validation loss: 2.0190485908139135

Epoch: 6| Step: 1
Training loss: 1.0034739971160889
Validation loss: 2.0368925679114556

Epoch: 6| Step: 2
Training loss: 0.9825602769851685
Validation loss: 2.0649607027730634

Epoch: 6| Step: 3
Training loss: 1.732172966003418
Validation loss: 2.079076314485201

Epoch: 6| Step: 4
Training loss: 0.9455941319465637
Validation loss: 2.0267885820839995

Epoch: 6| Step: 5
Training loss: 1.0703697204589844
Validation loss: 2.0259869995937554

Epoch: 6| Step: 6
Training loss: 1.116613507270813
Validation loss: 2.050616575825599

Epoch: 6| Step: 7
Training loss: 1.5124328136444092
Validation loss: 1.9788477138806415

Epoch: 6| Step: 8
Training loss: 0.7816282510757446
Validation loss: 2.052947143072723

Epoch: 6| Step: 9
Training loss: 0.96395343542099
Validation loss: 1.9989789352622083

Epoch: 6| Step: 10
Training loss: 1.2060163021087646
Validation loss: 1.9840411037527106

Epoch: 6| Step: 11
Training loss: 0.7891678810119629
Validation loss: 1.9975696532957015

Epoch: 6| Step: 12
Training loss: 1.6253278255462646
Validation loss: 2.0071842305121885

Epoch: 6| Step: 13
Training loss: 0.9943734407424927
Validation loss: 2.0042195961039555

Epoch: 676| Step: 0
Training loss: 0.8199758529663086
Validation loss: 2.0390162544865764

Epoch: 6| Step: 1
Training loss: 1.411743402481079
Validation loss: 2.0600080990022227

Epoch: 6| Step: 2
Training loss: 1.2826889753341675
Validation loss: 2.0152765576557448

Epoch: 6| Step: 3
Training loss: 1.1669535636901855
Validation loss: 2.054983890184792

Epoch: 6| Step: 4
Training loss: 1.7753593921661377
Validation loss: 2.023964665269339

Epoch: 6| Step: 5
Training loss: 0.7433650493621826
Validation loss: 2.072362715198148

Epoch: 6| Step: 6
Training loss: 1.0775492191314697
Validation loss: 2.0351610311897854

Epoch: 6| Step: 7
Training loss: 1.1456220149993896
Validation loss: 2.026246428489685

Epoch: 6| Step: 8
Training loss: 1.1256216764450073
Validation loss: 2.0301613269313687

Epoch: 6| Step: 9
Training loss: 0.878040611743927
Validation loss: 2.008072660815331

Epoch: 6| Step: 10
Training loss: 0.8703389167785645
Validation loss: 2.040765303437428

Epoch: 6| Step: 11
Training loss: 1.2177029848098755
Validation loss: 2.003766062439129

Epoch: 6| Step: 12
Training loss: 1.0146348476409912
Validation loss: 2.025613634817062

Epoch: 6| Step: 13
Training loss: 0.7368094325065613
Validation loss: 2.0637319087982178

Epoch: 677| Step: 0
Training loss: 1.1225157976150513
Validation loss: 2.0347284488780524

Epoch: 6| Step: 1
Training loss: 0.9573479890823364
Validation loss: 2.059742940369473

Epoch: 6| Step: 2
Training loss: 1.0976766347885132
Validation loss: 2.0755363164409513

Epoch: 6| Step: 3
Training loss: 0.8475663661956787
Validation loss: 2.0385445279459797

Epoch: 6| Step: 4
Training loss: 1.2655384540557861
Validation loss: 2.0419114994746383

Epoch: 6| Step: 5
Training loss: 1.0139250755310059
Validation loss: 2.0882046248323176

Epoch: 6| Step: 6
Training loss: 1.1413540840148926
Validation loss: 2.0334287587032525

Epoch: 6| Step: 7
Training loss: 1.2491726875305176
Validation loss: 2.0924715675333494

Epoch: 6| Step: 8
Training loss: 0.9927740097045898
Validation loss: 2.040813056371545

Epoch: 6| Step: 9
Training loss: 1.2875170707702637
Validation loss: 2.0593623268988823

Epoch: 6| Step: 10
Training loss: 1.8843857049942017
Validation loss: 2.0202487450774

Epoch: 6| Step: 11
Training loss: 0.6854139566421509
Validation loss: 2.0184913219944125

Epoch: 6| Step: 12
Training loss: 0.6589436531066895
Validation loss: 2.002585050880268

Epoch: 6| Step: 13
Training loss: 1.4537549018859863
Validation loss: 2.000082870965363

Epoch: 678| Step: 0
Training loss: 1.3942233324050903
Validation loss: 2.031429124134843

Epoch: 6| Step: 1
Training loss: 0.9467908143997192
Validation loss: 1.9529119794086744

Epoch: 6| Step: 2
Training loss: 1.2205650806427002
Validation loss: 1.9798641461198048

Epoch: 6| Step: 3
Training loss: 1.6336511373519897
Validation loss: 2.012378708008797

Epoch: 6| Step: 4
Training loss: 0.7197495102882385
Validation loss: 2.0493483466486775

Epoch: 6| Step: 5
Training loss: 0.9728068113327026
Validation loss: 2.029293224375735

Epoch: 6| Step: 6
Training loss: 1.1092569828033447
Validation loss: 2.009765799327563

Epoch: 6| Step: 7
Training loss: 0.9049513936042786
Validation loss: 2.023777041383969

Epoch: 6| Step: 8
Training loss: 0.929996132850647
Validation loss: 1.9806673052490398

Epoch: 6| Step: 9
Training loss: 1.0622884035110474
Validation loss: 2.0185366651063323

Epoch: 6| Step: 10
Training loss: 1.1670316457748413
Validation loss: 2.0494019344288814

Epoch: 6| Step: 11
Training loss: 1.2402727603912354
Validation loss: 2.009209099636283

Epoch: 6| Step: 12
Training loss: 1.441649079322815
Validation loss: 1.9698576414456932

Epoch: 6| Step: 13
Training loss: 0.8056126832962036
Validation loss: 2.037430877326637

Epoch: 679| Step: 0
Training loss: 0.8835926651954651
Validation loss: 2.0563371566034134

Epoch: 6| Step: 1
Training loss: 0.9985123872756958
Validation loss: 2.0537577547052854

Epoch: 6| Step: 2
Training loss: 1.9217880964279175
Validation loss: 1.985622194505507

Epoch: 6| Step: 3
Training loss: 0.9378832578659058
Validation loss: 2.0026321744406097

Epoch: 6| Step: 4
Training loss: 1.2907729148864746
Validation loss: 2.0280845113979873

Epoch: 6| Step: 5
Training loss: 1.8059918880462646
Validation loss: 2.003026972534836

Epoch: 6| Step: 6
Training loss: 1.084082007408142
Validation loss: 2.0120891230080717

Epoch: 6| Step: 7
Training loss: 0.91599440574646
Validation loss: 1.9568926006235101

Epoch: 6| Step: 8
Training loss: 1.0939860343933105
Validation loss: 2.049051438608477

Epoch: 6| Step: 9
Training loss: 0.6480050683021545
Validation loss: 2.071303165087136

Epoch: 6| Step: 10
Training loss: 0.7658450603485107
Validation loss: 2.059982599750642

Epoch: 6| Step: 11
Training loss: 0.6324173808097839
Validation loss: 2.0764503350821872

Epoch: 6| Step: 12
Training loss: 1.4246222972869873
Validation loss: 2.030148729201286

Epoch: 6| Step: 13
Training loss: 1.7771257162094116
Validation loss: 2.02211743785489

Epoch: 680| Step: 0
Training loss: 0.9818676710128784
Validation loss: 2.0286046266555786

Epoch: 6| Step: 1
Training loss: 0.5575146079063416
Validation loss: 2.0258023969588743

Epoch: 6| Step: 2
Training loss: 1.5254571437835693
Validation loss: 2.003286196339515

Epoch: 6| Step: 3
Training loss: 1.1068413257598877
Validation loss: 2.042123991955993

Epoch: 6| Step: 4
Training loss: 1.0881595611572266
Validation loss: 2.0163332005982757

Epoch: 6| Step: 5
Training loss: 0.7787336111068726
Validation loss: 1.9891202654889835

Epoch: 6| Step: 6
Training loss: 1.3387963771820068
Validation loss: 2.034679147504991

Epoch: 6| Step: 7
Training loss: 0.9209271669387817
Validation loss: 2.0147682825724282

Epoch: 6| Step: 8
Training loss: 1.1889845132827759
Validation loss: 2.0156402510981404

Epoch: 6| Step: 9
Training loss: 0.9969165325164795
Validation loss: 1.9993195469661424

Epoch: 6| Step: 10
Training loss: 0.7466555237770081
Validation loss: 1.9873186067868305

Epoch: 6| Step: 11
Training loss: 2.0351765155792236
Validation loss: 2.022864508372481

Epoch: 6| Step: 12
Training loss: 1.1757663488388062
Validation loss: 2.023053571742068

Epoch: 6| Step: 13
Training loss: 1.0401511192321777
Validation loss: 1.9817995281629666

Epoch: 681| Step: 0
Training loss: 1.7040461301803589
Validation loss: 2.0346326494729645

Epoch: 6| Step: 1
Training loss: 0.5151035189628601
Validation loss: 2.068761674306726

Epoch: 6| Step: 2
Training loss: 1.5190786123275757
Validation loss: 2.0289405135698217

Epoch: 6| Step: 3
Training loss: 1.4090828895568848
Validation loss: 2.0089231703871038

Epoch: 6| Step: 4
Training loss: 0.8174523115158081
Validation loss: 2.0281822848063644

Epoch: 6| Step: 5
Training loss: 1.2470710277557373
Validation loss: 2.0749600318170365

Epoch: 6| Step: 6
Training loss: 1.0132193565368652
Validation loss: 2.018607157532887

Epoch: 6| Step: 7
Training loss: 1.0695734024047852
Validation loss: 2.023378146592007

Epoch: 6| Step: 8
Training loss: 0.9983395934104919
Validation loss: 2.0105168716881865

Epoch: 6| Step: 9
Training loss: 1.0794360637664795
Validation loss: 2.020998295917306

Epoch: 6| Step: 10
Training loss: 1.4678981304168701
Validation loss: 1.9713087415182462

Epoch: 6| Step: 11
Training loss: 0.6288909912109375
Validation loss: 1.9734575017806022

Epoch: 6| Step: 12
Training loss: 0.7221542596817017
Validation loss: 2.0282772535918863

Epoch: 6| Step: 13
Training loss: 1.8301957845687866
Validation loss: 1.9825523207264562

Epoch: 682| Step: 0
Training loss: 1.3916442394256592
Validation loss: 2.0378558507529636

Epoch: 6| Step: 1
Training loss: 0.8187018632888794
Validation loss: 2.006650524754678

Epoch: 6| Step: 2
Training loss: 1.1526432037353516
Validation loss: 2.037091306460801

Epoch: 6| Step: 3
Training loss: 1.0402687788009644
Validation loss: 2.0274053260844243

Epoch: 6| Step: 4
Training loss: 1.2545151710510254
Validation loss: 2.040669564277895

Epoch: 6| Step: 5
Training loss: 1.350137710571289
Validation loss: 1.9853617145169167

Epoch: 6| Step: 6
Training loss: 0.6668713092803955
Validation loss: 2.035501212202093

Epoch: 6| Step: 7
Training loss: 1.144869327545166
Validation loss: 2.0554274564148276

Epoch: 6| Step: 8
Training loss: 0.7625669240951538
Validation loss: 2.0696420810555898

Epoch: 6| Step: 9
Training loss: 1.0006604194641113
Validation loss: 2.03535545000466

Epoch: 6| Step: 10
Training loss: 0.8768859505653381
Validation loss: 2.075807059964826

Epoch: 6| Step: 11
Training loss: 1.4095983505249023
Validation loss: 2.045951494606592

Epoch: 6| Step: 12
Training loss: 1.7497460842132568
Validation loss: 2.0123864220034693

Epoch: 6| Step: 13
Training loss: 1.2502663135528564
Validation loss: 1.9606075338138047

Epoch: 683| Step: 0
Training loss: 0.9218000769615173
Validation loss: 2.002961681735131

Epoch: 6| Step: 1
Training loss: 0.8537375330924988
Validation loss: 2.0086864143289547

Epoch: 6| Step: 2
Training loss: 1.5369644165039062
Validation loss: 2.0067062531748125

Epoch: 6| Step: 3
Training loss: 1.824041724205017
Validation loss: 2.0186728918424217

Epoch: 6| Step: 4
Training loss: 1.0127274990081787
Validation loss: 2.009937817050565

Epoch: 6| Step: 5
Training loss: 1.0674482583999634
Validation loss: 2.0400807729331394

Epoch: 6| Step: 6
Training loss: 1.013466238975525
Validation loss: 2.0215510527292886

Epoch: 6| Step: 7
Training loss: 1.0543172359466553
Validation loss: 2.0155323872002224

Epoch: 6| Step: 8
Training loss: 1.158957839012146
Validation loss: 2.0275657561517533

Epoch: 6| Step: 9
Training loss: 1.2511177062988281
Validation loss: 2.014604462090359

Epoch: 6| Step: 10
Training loss: 0.9218964576721191
Validation loss: 2.0441690542364634

Epoch: 6| Step: 11
Training loss: 1.068481206893921
Validation loss: 2.0474732434877785

Epoch: 6| Step: 12
Training loss: 1.2799389362335205
Validation loss: 2.0052560414037397

Epoch: 6| Step: 13
Training loss: 0.5970808863639832
Validation loss: 2.054001497965987

Epoch: 684| Step: 0
Training loss: 1.468353509902954
Validation loss: 2.03986527586496

Epoch: 6| Step: 1
Training loss: 1.2557023763656616
Validation loss: 2.0404660406933037

Epoch: 6| Step: 2
Training loss: 0.8122875690460205
Validation loss: 1.9994660474920785

Epoch: 6| Step: 3
Training loss: 0.8942819833755493
Validation loss: 2.0777652007277294

Epoch: 6| Step: 4
Training loss: 1.3216347694396973
Validation loss: 1.9956674216895975

Epoch: 6| Step: 5
Training loss: 1.248766541481018
Validation loss: 2.0351512701280656

Epoch: 6| Step: 6
Training loss: 1.1014485359191895
Validation loss: 2.0001985655036023

Epoch: 6| Step: 7
Training loss: 0.9148417711257935
Validation loss: 2.009048149149905

Epoch: 6| Step: 8
Training loss: 0.8018460273742676
Validation loss: 2.009062881110817

Epoch: 6| Step: 9
Training loss: 0.8462461829185486
Validation loss: 2.012594143549601

Epoch: 6| Step: 10
Training loss: 1.2872663736343384
Validation loss: 2.0279912807608165

Epoch: 6| Step: 11
Training loss: 1.1781203746795654
Validation loss: 2.009977324034578

Epoch: 6| Step: 12
Training loss: 1.3080297708511353
Validation loss: 2.02429691437752

Epoch: 6| Step: 13
Training loss: 0.8620357513427734
Validation loss: 1.9889452111336492

Epoch: 685| Step: 0
Training loss: 1.0661903619766235
Validation loss: 2.055962683052145

Epoch: 6| Step: 1
Training loss: 1.1990910768508911
Validation loss: 2.047938733972529

Epoch: 6| Step: 2
Training loss: 1.1085107326507568
Validation loss: 2.0524327511428506

Epoch: 6| Step: 3
Training loss: 1.1108596324920654
Validation loss: 2.02171185452451

Epoch: 6| Step: 4
Training loss: 1.0735982656478882
Validation loss: 2.0397863849516837

Epoch: 6| Step: 5
Training loss: 0.9049683809280396
Validation loss: 2.001884247667046

Epoch: 6| Step: 6
Training loss: 1.049344778060913
Validation loss: 2.039652403964791

Epoch: 6| Step: 7
Training loss: 0.8263362050056458
Validation loss: 2.023094715610627

Epoch: 6| Step: 8
Training loss: 1.3092654943466187
Validation loss: 2.053699275498749

Epoch: 6| Step: 9
Training loss: 1.188409686088562
Validation loss: 2.0292536776552916

Epoch: 6| Step: 10
Training loss: 1.8966617584228516
Validation loss: 2.031065588356346

Epoch: 6| Step: 11
Training loss: 0.9812982082366943
Validation loss: 2.0120998121077016

Epoch: 6| Step: 12
Training loss: 1.3538376092910767
Validation loss: 2.002421312434699

Epoch: 6| Step: 13
Training loss: 0.49107858538627625
Validation loss: 2.0240072024765836

Epoch: 686| Step: 0
Training loss: 0.9397310018539429
Validation loss: 1.9997894738310127

Epoch: 6| Step: 1
Training loss: 1.1958248615264893
Validation loss: 2.028458946494646

Epoch: 6| Step: 2
Training loss: 1.7277703285217285
Validation loss: 1.9759183481175413

Epoch: 6| Step: 3
Training loss: 1.2121546268463135
Validation loss: 2.0219584818809264

Epoch: 6| Step: 4
Training loss: 1.2772085666656494
Validation loss: 2.020142137363393

Epoch: 6| Step: 5
Training loss: 0.5605709552764893
Validation loss: 1.9877762589403378

Epoch: 6| Step: 6
Training loss: 1.2517192363739014
Validation loss: 2.0455318215072795

Epoch: 6| Step: 7
Training loss: 0.9790967702865601
Validation loss: 2.004046097878487

Epoch: 6| Step: 8
Training loss: 0.5713284015655518
Validation loss: 2.0083089515727055

Epoch: 6| Step: 9
Training loss: 1.2153997421264648
Validation loss: 2.0146146833255725

Epoch: 6| Step: 10
Training loss: 1.148477554321289
Validation loss: 2.0341242692803823

Epoch: 6| Step: 11
Training loss: 1.0957424640655518
Validation loss: 2.0212339842191307

Epoch: 6| Step: 12
Training loss: 1.0627222061157227
Validation loss: 2.06053461182502

Epoch: 6| Step: 13
Training loss: 1.3485075235366821
Validation loss: 2.053329999728869

Epoch: 687| Step: 0
Training loss: 0.8620654344558716
Validation loss: 2.017401954179169

Epoch: 6| Step: 1
Training loss: 1.093954086303711
Validation loss: 2.033501196933049

Epoch: 6| Step: 2
Training loss: 0.532293438911438
Validation loss: 2.010684214612489

Epoch: 6| Step: 3
Training loss: 1.114302635192871
Validation loss: 2.036151010503051

Epoch: 6| Step: 4
Training loss: 1.1619925498962402
Validation loss: 2.0211685678010345

Epoch: 6| Step: 5
Training loss: 1.530175805091858
Validation loss: 2.007277170817057

Epoch: 6| Step: 6
Training loss: 0.6420483589172363
Validation loss: 2.042555670584402

Epoch: 6| Step: 7
Training loss: 1.3703521490097046
Validation loss: 1.9768194331917712

Epoch: 6| Step: 8
Training loss: 1.147483229637146
Validation loss: 1.97653482678116

Epoch: 6| Step: 9
Training loss: 1.1652519702911377
Validation loss: 2.0176162181362027

Epoch: 6| Step: 10
Training loss: 1.0985515117645264
Validation loss: 2.0006138957956785

Epoch: 6| Step: 11
Training loss: 1.6228349208831787
Validation loss: 2.012506422176156

Epoch: 6| Step: 12
Training loss: 1.17941415309906
Validation loss: 2.0056612235243603

Epoch: 6| Step: 13
Training loss: 0.9081639051437378
Validation loss: 1.9898633495453866

Epoch: 688| Step: 0
Training loss: 1.3658978939056396
Validation loss: 2.0498784588229273

Epoch: 6| Step: 1
Training loss: 0.8688328862190247
Validation loss: 2.018180460058233

Epoch: 6| Step: 2
Training loss: 0.671002984046936
Validation loss: 1.9780955288999824

Epoch: 6| Step: 3
Training loss: 1.245356559753418
Validation loss: 2.014237798670287

Epoch: 6| Step: 4
Training loss: 1.6477470397949219
Validation loss: 2.0003599312997635

Epoch: 6| Step: 5
Training loss: 1.0630168914794922
Validation loss: 2.058169314938207

Epoch: 6| Step: 6
Training loss: 1.5138800144195557
Validation loss: 1.9923327533147668

Epoch: 6| Step: 7
Training loss: 0.7610006332397461
Validation loss: 2.033034598955544

Epoch: 6| Step: 8
Training loss: 1.0333172082901
Validation loss: 2.015066259650774

Epoch: 6| Step: 9
Training loss: 1.2913068532943726
Validation loss: 2.007650454839071

Epoch: 6| Step: 10
Training loss: 0.8997570872306824
Validation loss: 2.036277601795812

Epoch: 6| Step: 11
Training loss: 1.0304473638534546
Validation loss: 2.030712067439992

Epoch: 6| Step: 12
Training loss: 1.2167614698410034
Validation loss: 2.0306240474024126

Epoch: 6| Step: 13
Training loss: 1.0235971212387085
Validation loss: 2.043621365742017

Epoch: 689| Step: 0
Training loss: 1.2625268697738647
Validation loss: 2.084921098524524

Epoch: 6| Step: 1
Training loss: 0.8211724758148193
Validation loss: 2.0908801914543234

Epoch: 6| Step: 2
Training loss: 1.604508876800537
Validation loss: 2.056428042791223

Epoch: 6| Step: 3
Training loss: 0.8752220869064331
Validation loss: 2.0290000797599874

Epoch: 6| Step: 4
Training loss: 0.9802405834197998
Validation loss: 1.9830210836984778

Epoch: 6| Step: 5
Training loss: 0.7238409519195557
Validation loss: 2.058677996358564

Epoch: 6| Step: 6
Training loss: 1.0044846534729004
Validation loss: 2.022589429732292

Epoch: 6| Step: 7
Training loss: 1.116999864578247
Validation loss: 2.0121733206574635

Epoch: 6| Step: 8
Training loss: 1.1773278713226318
Validation loss: 2.0339754294323664

Epoch: 6| Step: 9
Training loss: 1.4732246398925781
Validation loss: 1.9930620219117852

Epoch: 6| Step: 10
Training loss: 1.1983510255813599
Validation loss: 2.011760239960045

Epoch: 6| Step: 11
Training loss: 1.317347764968872
Validation loss: 2.027341445287069

Epoch: 6| Step: 12
Training loss: 1.0972219705581665
Validation loss: 1.9801092468282229

Epoch: 6| Step: 13
Training loss: 0.906611979007721
Validation loss: 2.036074497366464

Epoch: 690| Step: 0
Training loss: 1.5671348571777344
Validation loss: 2.01067953981379

Epoch: 6| Step: 1
Training loss: 1.5097259283065796
Validation loss: 1.9755959600530646

Epoch: 6| Step: 2
Training loss: 1.4410072565078735
Validation loss: 2.0179853875149965

Epoch: 6| Step: 3
Training loss: 0.6128137111663818
Validation loss: 2.025384141552833

Epoch: 6| Step: 4
Training loss: 1.345524787902832
Validation loss: 2.023998623253197

Epoch: 6| Step: 5
Training loss: 1.106020212173462
Validation loss: 2.055007785879156

Epoch: 6| Step: 6
Training loss: 0.44241756200790405
Validation loss: 1.9810057481129963

Epoch: 6| Step: 7
Training loss: 1.3205307722091675
Validation loss: 2.0401545122105587

Epoch: 6| Step: 8
Training loss: 0.718988299369812
Validation loss: 2.049940355362431

Epoch: 6| Step: 9
Training loss: 1.2415523529052734
Validation loss: 2.075171575751356

Epoch: 6| Step: 10
Training loss: 0.9799194931983948
Validation loss: 2.0925180117289224

Epoch: 6| Step: 11
Training loss: 0.9076008796691895
Validation loss: 2.0570348539660053

Epoch: 6| Step: 12
Training loss: 1.32042396068573
Validation loss: 2.0775218394494828

Epoch: 6| Step: 13
Training loss: 1.4647403955459595
Validation loss: 2.043792350317842

Epoch: 691| Step: 0
Training loss: 1.1185252666473389
Validation loss: 2.060598865632088

Epoch: 6| Step: 1
Training loss: 1.2314033508300781
Validation loss: 1.977027388029201

Epoch: 6| Step: 2
Training loss: 0.9829248189926147
Validation loss: 2.02083824270515

Epoch: 6| Step: 3
Training loss: 1.2602927684783936
Validation loss: 2.008110705242362

Epoch: 6| Step: 4
Training loss: 0.9574084281921387
Validation loss: 1.999521832312307

Epoch: 6| Step: 5
Training loss: 1.5811450481414795
Validation loss: 2.0153205971564017

Epoch: 6| Step: 6
Training loss: 1.0088720321655273
Validation loss: 2.0308360643284296

Epoch: 6| Step: 7
Training loss: 1.7877048254013062
Validation loss: 1.976998068953073

Epoch: 6| Step: 8
Training loss: 0.9029212594032288
Validation loss: 1.9640249975265995

Epoch: 6| Step: 9
Training loss: 1.0240188837051392
Validation loss: 2.028965142465407

Epoch: 6| Step: 10
Training loss: 0.9788547158241272
Validation loss: 1.9632754825776624

Epoch: 6| Step: 11
Training loss: 0.8010115027427673
Validation loss: 1.979175672736219

Epoch: 6| Step: 12
Training loss: 1.0885157585144043
Validation loss: 2.0343993543296732

Epoch: 6| Step: 13
Training loss: 1.0663769245147705
Validation loss: 1.9997998617028678

Epoch: 692| Step: 0
Training loss: 1.293102741241455
Validation loss: 1.9697636083890033

Epoch: 6| Step: 1
Training loss: 1.034888505935669
Validation loss: 1.9979603944286224

Epoch: 6| Step: 2
Training loss: 0.6400687098503113
Validation loss: 2.0381644272035166

Epoch: 6| Step: 3
Training loss: 1.0876712799072266
Validation loss: 1.9833132592580651

Epoch: 6| Step: 4
Training loss: 0.9081822633743286
Validation loss: 2.0220343861528622

Epoch: 6| Step: 5
Training loss: 1.3739802837371826
Validation loss: 2.0400351888389996

Epoch: 6| Step: 6
Training loss: 1.2591047286987305
Validation loss: 2.0271416992269535

Epoch: 6| Step: 7
Training loss: 1.1476640701293945
Validation loss: 2.0103790580585437

Epoch: 6| Step: 8
Training loss: 0.9402490258216858
Validation loss: 2.0159817959672663

Epoch: 6| Step: 9
Training loss: 0.6722478866577148
Validation loss: 2.002716673317776

Epoch: 6| Step: 10
Training loss: 1.4847004413604736
Validation loss: 2.0081260050496748

Epoch: 6| Step: 11
Training loss: 1.0965158939361572
Validation loss: 2.026328307326122

Epoch: 6| Step: 12
Training loss: 1.2325091361999512
Validation loss: 2.041644920584976

Epoch: 6| Step: 13
Training loss: 1.2652184963226318
Validation loss: 2.048241578122621

Epoch: 693| Step: 0
Training loss: 0.9450408220291138
Validation loss: 2.007929232812697

Epoch: 6| Step: 1
Training loss: 1.3500473499298096
Validation loss: 2.036834624505812

Epoch: 6| Step: 2
Training loss: 1.0690693855285645
Validation loss: 1.998832659054828

Epoch: 6| Step: 3
Training loss: 0.8167625069618225
Validation loss: 2.002656267535302

Epoch: 6| Step: 4
Training loss: 0.9136210680007935
Validation loss: 2.0364352477494108

Epoch: 6| Step: 5
Training loss: 0.8896675109863281
Validation loss: 1.9896533155954013

Epoch: 6| Step: 6
Training loss: 1.354805588722229
Validation loss: 2.0250611382146038

Epoch: 6| Step: 7
Training loss: 0.791629433631897
Validation loss: 1.9965211973395398

Epoch: 6| Step: 8
Training loss: 1.5294533967971802
Validation loss: 2.0324117316994617

Epoch: 6| Step: 9
Training loss: 1.1421456336975098
Validation loss: 2.0566745983657015

Epoch: 6| Step: 10
Training loss: 1.0043361186981201
Validation loss: 1.985865198155885

Epoch: 6| Step: 11
Training loss: 1.1336424350738525
Validation loss: 1.9971221147045013

Epoch: 6| Step: 12
Training loss: 1.3765915632247925
Validation loss: 2.082327558148292

Epoch: 6| Step: 13
Training loss: 1.3691645860671997
Validation loss: 2.0398026897061254

Epoch: 694| Step: 0
Training loss: 1.0258197784423828
Validation loss: 2.0287433644776702

Epoch: 6| Step: 1
Training loss: 0.8158535957336426
Validation loss: 2.023327055797782

Epoch: 6| Step: 2
Training loss: 1.061856746673584
Validation loss: 2.067838763677946

Epoch: 6| Step: 3
Training loss: 1.0437037944793701
Validation loss: 2.0380999003687212

Epoch: 6| Step: 4
Training loss: 1.201127529144287
Validation loss: 2.0171499841956684

Epoch: 6| Step: 5
Training loss: 0.9855467081069946
Validation loss: 2.0050525306373514

Epoch: 6| Step: 6
Training loss: 1.091782808303833
Validation loss: 2.0132621795900407

Epoch: 6| Step: 7
Training loss: 0.9352988004684448
Validation loss: 2.0359968267461306

Epoch: 6| Step: 8
Training loss: 1.799330472946167
Validation loss: 2.0103149952427035

Epoch: 6| Step: 9
Training loss: 1.379376769065857
Validation loss: 2.0251682586567377

Epoch: 6| Step: 10
Training loss: 1.0402028560638428
Validation loss: 2.058474721447114

Epoch: 6| Step: 11
Training loss: 1.1085596084594727
Validation loss: 2.021025796090403

Epoch: 6| Step: 12
Training loss: 0.7994799017906189
Validation loss: 2.0010255305997786

Epoch: 6| Step: 13
Training loss: 1.0674562454223633
Validation loss: 2.006236058409496

Epoch: 695| Step: 0
Training loss: 0.9210649728775024
Validation loss: 1.993103540071877

Epoch: 6| Step: 1
Training loss: 1.0778651237487793
Validation loss: 2.0402541955312095

Epoch: 6| Step: 2
Training loss: 1.3428692817687988
Validation loss: 1.990651572904279

Epoch: 6| Step: 3
Training loss: 1.0987457036972046
Validation loss: 2.012930472691854

Epoch: 6| Step: 4
Training loss: 1.302917242050171
Validation loss: 2.0342024167378745

Epoch: 6| Step: 5
Training loss: 0.698041558265686
Validation loss: 2.0052752776812484

Epoch: 6| Step: 6
Training loss: 0.7735445499420166
Validation loss: 2.037979684850221

Epoch: 6| Step: 7
Training loss: 1.4866282939910889
Validation loss: 2.0196078336367043

Epoch: 6| Step: 8
Training loss: 1.037963628768921
Validation loss: 2.006064743124029

Epoch: 6| Step: 9
Training loss: 0.6207412481307983
Validation loss: 1.987202872512161

Epoch: 6| Step: 10
Training loss: 1.4714767932891846
Validation loss: 1.973155148567692

Epoch: 6| Step: 11
Training loss: 0.8693551421165466
Validation loss: 1.9975699506780153

Epoch: 6| Step: 12
Training loss: 1.4078428745269775
Validation loss: 2.0272803357852403

Epoch: 6| Step: 13
Training loss: 0.9556195735931396
Validation loss: 2.019160624473326

Epoch: 696| Step: 0
Training loss: 0.6325451135635376
Validation loss: 1.9738322945051296

Epoch: 6| Step: 1
Training loss: 1.6048321723937988
Validation loss: 2.05308642695027

Epoch: 6| Step: 2
Training loss: 0.9359003305435181
Validation loss: 2.0187060397158385

Epoch: 6| Step: 3
Training loss: 0.5844699740409851
Validation loss: 2.0369706141051425

Epoch: 6| Step: 4
Training loss: 1.6364834308624268
Validation loss: 2.0263839050005843

Epoch: 6| Step: 5
Training loss: 1.213529109954834
Validation loss: 2.0240320556907245

Epoch: 6| Step: 6
Training loss: 0.7976763248443604
Validation loss: 2.0014453318811234

Epoch: 6| Step: 7
Training loss: 0.7808526158332825
Validation loss: 2.0071575949268956

Epoch: 6| Step: 8
Training loss: 1.6446845531463623
Validation loss: 2.0250357389450073

Epoch: 6| Step: 9
Training loss: 1.0107195377349854
Validation loss: 2.009818325760544

Epoch: 6| Step: 10
Training loss: 1.4321365356445312
Validation loss: 2.024979583678707

Epoch: 6| Step: 11
Training loss: 0.9690002202987671
Validation loss: 2.050486533872543

Epoch: 6| Step: 12
Training loss: 0.9145887494087219
Validation loss: 1.9909690708242438

Epoch: 6| Step: 13
Training loss: 0.8357440233230591
Validation loss: 2.0431897601773663

Epoch: 697| Step: 0
Training loss: 1.026668667793274
Validation loss: 1.9783568433535996

Epoch: 6| Step: 1
Training loss: 1.296242117881775
Validation loss: 2.0475842722000612

Epoch: 6| Step: 2
Training loss: 0.9501082301139832
Validation loss: 2.011391624327629

Epoch: 6| Step: 3
Training loss: 1.0525383949279785
Validation loss: 2.02946408589681

Epoch: 6| Step: 4
Training loss: 0.8663148880004883
Validation loss: 1.9780995704794442

Epoch: 6| Step: 5
Training loss: 0.7864010334014893
Validation loss: 2.0388583983144453

Epoch: 6| Step: 6
Training loss: 1.5425776243209839
Validation loss: 2.0162752418107885

Epoch: 6| Step: 7
Training loss: 0.48782044649124146
Validation loss: 2.0332802085466284

Epoch: 6| Step: 8
Training loss: 0.8399925231933594
Validation loss: 1.9951151083874445

Epoch: 6| Step: 9
Training loss: 1.464896321296692
Validation loss: 2.0493162473042807

Epoch: 6| Step: 10
Training loss: 1.3496947288513184
Validation loss: 1.9852813610466578

Epoch: 6| Step: 11
Training loss: 1.3602033853530884
Validation loss: 2.002566868259061

Epoch: 6| Step: 12
Training loss: 0.7490050792694092
Validation loss: 2.0168558371964322

Epoch: 6| Step: 13
Training loss: 1.5061672925949097
Validation loss: 2.0189300044890373

Epoch: 698| Step: 0
Training loss: 1.4749304056167603
Validation loss: 2.04297395419049

Epoch: 6| Step: 1
Training loss: 0.802855372428894
Validation loss: 1.9897322859815372

Epoch: 6| Step: 2
Training loss: 1.3265423774719238
Validation loss: 2.009816667085053

Epoch: 6| Step: 3
Training loss: 0.907319188117981
Validation loss: 1.9774432874494983

Epoch: 6| Step: 4
Training loss: 0.7149453163146973
Validation loss: 2.0417350184532905

Epoch: 6| Step: 5
Training loss: 1.2184600830078125
Validation loss: 2.0289675856149323

Epoch: 6| Step: 6
Training loss: 1.126521110534668
Validation loss: 2.0467135162763697

Epoch: 6| Step: 7
Training loss: 1.0272886753082275
Validation loss: 2.042797109132172

Epoch: 6| Step: 8
Training loss: 1.764122724533081
Validation loss: 2.0728313384517545

Epoch: 6| Step: 9
Training loss: 0.963769793510437
Validation loss: 2.0156220197677612

Epoch: 6| Step: 10
Training loss: 0.9835282564163208
Validation loss: 2.0290027869644987

Epoch: 6| Step: 11
Training loss: 1.3612022399902344
Validation loss: 2.0050935078692693

Epoch: 6| Step: 12
Training loss: 0.668860673904419
Validation loss: 2.0168999497608473

Epoch: 6| Step: 13
Training loss: 1.0207048654556274
Validation loss: 2.0007668695142193

Epoch: 699| Step: 0
Training loss: 1.340226411819458
Validation loss: 2.0214603459963234

Epoch: 6| Step: 1
Training loss: 0.8046824932098389
Validation loss: 2.0208862930215816

Epoch: 6| Step: 2
Training loss: 1.5624737739562988
Validation loss: 2.076533616230052

Epoch: 6| Step: 3
Training loss: 1.3078203201293945
Validation loss: 2.0734893147663405

Epoch: 6| Step: 4
Training loss: 1.100372076034546
Validation loss: 2.0628088199964134

Epoch: 6| Step: 5
Training loss: 0.7661863565444946
Validation loss: 2.0859669459763395

Epoch: 6| Step: 6
Training loss: 0.9947477579116821
Validation loss: 2.038381561156242

Epoch: 6| Step: 7
Training loss: 1.214930772781372
Validation loss: 2.0456058773943173

Epoch: 6| Step: 8
Training loss: 0.752403736114502
Validation loss: 2.0686320707362187

Epoch: 6| Step: 9
Training loss: 0.928105354309082
Validation loss: 1.9802979448790192

Epoch: 6| Step: 10
Training loss: 0.9608988165855408
Validation loss: 2.059855473938809

Epoch: 6| Step: 11
Training loss: 0.9919406175613403
Validation loss: 2.024920771198888

Epoch: 6| Step: 12
Training loss: 1.461361289024353
Validation loss: 2.0349845552957184

Epoch: 6| Step: 13
Training loss: 1.2364760637283325
Validation loss: 2.0501025081962667

Epoch: 700| Step: 0
Training loss: 1.4670213460922241
Validation loss: 2.0079410614505893

Epoch: 6| Step: 1
Training loss: 1.4921207427978516
Validation loss: 1.9961135925785187

Epoch: 6| Step: 2
Training loss: 0.9630030989646912
Validation loss: 1.9875620949652888

Epoch: 6| Step: 3
Training loss: 1.0614256858825684
Validation loss: 2.0452883987016577

Epoch: 6| Step: 4
Training loss: 1.3472490310668945
Validation loss: 2.015544617047874

Epoch: 6| Step: 5
Training loss: 1.5108628273010254
Validation loss: 2.0381574066736365

Epoch: 6| Step: 6
Training loss: 0.8140169382095337
Validation loss: 2.021335394151749

Epoch: 6| Step: 7
Training loss: 1.3397703170776367
Validation loss: 1.9969369083322503

Epoch: 6| Step: 8
Training loss: 0.8737958669662476
Validation loss: 1.9902725437636017

Epoch: 6| Step: 9
Training loss: 0.8058120012283325
Validation loss: 1.9747330116969284

Epoch: 6| Step: 10
Training loss: 0.859195351600647
Validation loss: 2.018105149269104

Epoch: 6| Step: 11
Training loss: 0.8482415080070496
Validation loss: 1.9806554522565616

Epoch: 6| Step: 12
Training loss: 0.9066341519355774
Validation loss: 1.9952269164464806

Epoch: 6| Step: 13
Training loss: 1.0056986808776855
Validation loss: 2.0422171674748903

Epoch: 701| Step: 0
Training loss: 0.85281902551651
Validation loss: 2.0146358615608624

Epoch: 6| Step: 1
Training loss: 1.0131089687347412
Validation loss: 2.0756159444009104

Epoch: 6| Step: 2
Training loss: 0.8899738788604736
Validation loss: 1.9720108611609346

Epoch: 6| Step: 3
Training loss: 1.4944161176681519
Validation loss: 2.058583471082872

Epoch: 6| Step: 4
Training loss: 1.0146145820617676
Validation loss: 2.0565987530575005

Epoch: 6| Step: 5
Training loss: 1.0888704061508179
Validation loss: 2.0496156779668664

Epoch: 6| Step: 6
Training loss: 1.1602438688278198
Validation loss: 2.0430887617090696

Epoch: 6| Step: 7
Training loss: 0.909736156463623
Validation loss: 2.0344306474090903

Epoch: 6| Step: 8
Training loss: 0.9958869218826294
Validation loss: 2.011867638557188

Epoch: 6| Step: 9
Training loss: 1.1206958293914795
Validation loss: 2.0170511699491933

Epoch: 6| Step: 10
Training loss: 1.2136974334716797
Validation loss: 2.000842578949467

Epoch: 6| Step: 11
Training loss: 0.8190219402313232
Validation loss: 2.0091173674470637

Epoch: 6| Step: 12
Training loss: 0.8336293697357178
Validation loss: 1.9997629683504823

Epoch: 6| Step: 13
Training loss: 1.8394707441329956
Validation loss: 1.9903530895069081

Epoch: 702| Step: 0
Training loss: 1.317119836807251
Validation loss: 2.0231871412646387

Epoch: 6| Step: 1
Training loss: 1.3120131492614746
Validation loss: 2.020148523392216

Epoch: 6| Step: 2
Training loss: 1.0720183849334717
Validation loss: 1.984523400183647

Epoch: 6| Step: 3
Training loss: 1.0355591773986816
Validation loss: 2.030659362833987

Epoch: 6| Step: 4
Training loss: 1.0607287883758545
Validation loss: 2.0095030184715026

Epoch: 6| Step: 5
Training loss: 1.38142991065979
Validation loss: 2.0283974844922303

Epoch: 6| Step: 6
Training loss: 0.49004095792770386
Validation loss: 2.033279186935835

Epoch: 6| Step: 7
Training loss: 0.9848341941833496
Validation loss: 2.027954896291097

Epoch: 6| Step: 8
Training loss: 1.0157206058502197
Validation loss: 1.9835422820942377

Epoch: 6| Step: 9
Training loss: 0.5532348155975342
Validation loss: 2.0306143658135527

Epoch: 6| Step: 10
Training loss: 1.0473263263702393
Validation loss: 2.0329921617302844

Epoch: 6| Step: 11
Training loss: 1.3880590200424194
Validation loss: 2.010090922796598

Epoch: 6| Step: 12
Training loss: 0.9848872423171997
Validation loss: 2.0622591972351074

Epoch: 6| Step: 13
Training loss: 1.9666908979415894
Validation loss: 2.048478521326537

Epoch: 703| Step: 0
Training loss: 1.4349565505981445
Validation loss: 2.0532241598252328

Epoch: 6| Step: 1
Training loss: 1.4854936599731445
Validation loss: 2.0321383886439826

Epoch: 6| Step: 2
Training loss: 0.6374766826629639
Validation loss: 2.032351827108732

Epoch: 6| Step: 3
Training loss: 1.4391415119171143
Validation loss: 2.0451556136531215

Epoch: 6| Step: 4
Training loss: 0.7879781126976013
Validation loss: 2.0186480719556092

Epoch: 6| Step: 5
Training loss: 0.8972987532615662
Validation loss: 2.0416148683076263

Epoch: 6| Step: 6
Training loss: 0.7805294990539551
Validation loss: 2.0251493659070743

Epoch: 6| Step: 7
Training loss: 0.8582586646080017
Validation loss: 2.0337382516553326

Epoch: 6| Step: 8
Training loss: 0.9805659055709839
Validation loss: 2.0495057618746193

Epoch: 6| Step: 9
Training loss: 1.2477840185165405
Validation loss: 1.9543049463661768

Epoch: 6| Step: 10
Training loss: 1.2005014419555664
Validation loss: 1.9922879024218487

Epoch: 6| Step: 11
Training loss: 0.759217381477356
Validation loss: 1.996208410109243

Epoch: 6| Step: 12
Training loss: 1.4335919618606567
Validation loss: 1.9529412754120365

Epoch: 6| Step: 13
Training loss: 1.193593144416809
Validation loss: 1.9819112516218615

Epoch: 704| Step: 0
Training loss: 1.1308550834655762
Validation loss: 2.0140366118441344

Epoch: 6| Step: 1
Training loss: 0.874969482421875
Validation loss: 2.0031748433266916

Epoch: 6| Step: 2
Training loss: 1.0544154644012451
Validation loss: 2.0128650665283203

Epoch: 6| Step: 3
Training loss: 1.327488660812378
Validation loss: 1.9898295197435605

Epoch: 6| Step: 4
Training loss: 0.8774868249893188
Validation loss: 2.03354380207677

Epoch: 6| Step: 5
Training loss: 1.5447676181793213
Validation loss: 2.0610565780311503

Epoch: 6| Step: 6
Training loss: 0.4312880039215088
Validation loss: 2.029397149239817

Epoch: 6| Step: 7
Training loss: 1.1595364809036255
Validation loss: 2.0425216151821997

Epoch: 6| Step: 8
Training loss: 1.178041696548462
Validation loss: 2.091816658614784

Epoch: 6| Step: 9
Training loss: 1.060735821723938
Validation loss: 2.0216424926634757

Epoch: 6| Step: 10
Training loss: 1.4323532581329346
Validation loss: 2.065634104513353

Epoch: 6| Step: 11
Training loss: 0.8283616304397583
Validation loss: 2.0184548593336538

Epoch: 6| Step: 12
Training loss: 1.3486278057098389
Validation loss: 1.9905644834682505

Epoch: 6| Step: 13
Training loss: 1.003149390220642
Validation loss: 2.0459604699124574

Epoch: 705| Step: 0
Training loss: 1.5359370708465576
Validation loss: 2.0166885160630748

Epoch: 6| Step: 1
Training loss: 1.2294929027557373
Validation loss: 1.999113917350769

Epoch: 6| Step: 2
Training loss: 1.4960373640060425
Validation loss: 1.9819159623115294

Epoch: 6| Step: 3
Training loss: 1.2541205883026123
Validation loss: 2.005315116656724

Epoch: 6| Step: 4
Training loss: 0.7858806848526001
Validation loss: 2.0085192213776293

Epoch: 6| Step: 5
Training loss: 1.0073938369750977
Validation loss: 2.0463339026256273

Epoch: 6| Step: 6
Training loss: 0.9939107894897461
Validation loss: 1.9763484103705293

Epoch: 6| Step: 7
Training loss: 1.46640944480896
Validation loss: 2.0007804209186184

Epoch: 6| Step: 8
Training loss: 0.6340426206588745
Validation loss: 2.0072955303294684

Epoch: 6| Step: 9
Training loss: 1.111607551574707
Validation loss: 2.0081973550140217

Epoch: 6| Step: 10
Training loss: 0.9346605539321899
Validation loss: 2.0199141963835685

Epoch: 6| Step: 11
Training loss: 0.8304502964019775
Validation loss: 2.0034055863657305

Epoch: 6| Step: 12
Training loss: 0.9989594221115112
Validation loss: 2.025600931977713

Epoch: 6| Step: 13
Training loss: 1.4172749519348145
Validation loss: 2.0697878201802573

Epoch: 706| Step: 0
Training loss: 1.094413161277771
Validation loss: 2.0672593757670414

Epoch: 6| Step: 1
Training loss: 0.9968201518058777
Validation loss: 2.033545358206636

Epoch: 6| Step: 2
Training loss: 0.7627350091934204
Validation loss: 2.021084767515941

Epoch: 6| Step: 3
Training loss: 0.9097838997840881
Validation loss: 2.0045400614379556

Epoch: 6| Step: 4
Training loss: 1.5629370212554932
Validation loss: 2.021173423336398

Epoch: 6| Step: 5
Training loss: 1.1056544780731201
Validation loss: 2.015596673052798

Epoch: 6| Step: 6
Training loss: 0.7737622857093811
Validation loss: 1.981773293146523

Epoch: 6| Step: 7
Training loss: 1.4134995937347412
Validation loss: 2.0342387204529135

Epoch: 6| Step: 8
Training loss: 0.8909586668014526
Validation loss: 2.031305636129072

Epoch: 6| Step: 9
Training loss: 1.2910841703414917
Validation loss: 1.9990241002011042

Epoch: 6| Step: 10
Training loss: 0.994821310043335
Validation loss: 2.0027813860165176

Epoch: 6| Step: 11
Training loss: 0.6153951287269592
Validation loss: 2.0161726269670712

Epoch: 6| Step: 12
Training loss: 1.1038926839828491
Validation loss: 2.0175738232110136

Epoch: 6| Step: 13
Training loss: 2.0707123279571533
Validation loss: 1.9708895914016231

Epoch: 707| Step: 0
Training loss: 0.7435480356216431
Validation loss: 2.00552608120826

Epoch: 6| Step: 1
Training loss: 0.9299976825714111
Validation loss: 2.0096379300599456

Epoch: 6| Step: 2
Training loss: 0.68499356508255
Validation loss: 2.0367603378911174

Epoch: 6| Step: 3
Training loss: 1.3390717506408691
Validation loss: 2.0350452597423265

Epoch: 6| Step: 4
Training loss: 0.8826138973236084
Validation loss: 2.0200481786522815

Epoch: 6| Step: 5
Training loss: 1.0260493755340576
Validation loss: 2.0057839232106365

Epoch: 6| Step: 6
Training loss: 1.0378273725509644
Validation loss: 2.0187104773777786

Epoch: 6| Step: 7
Training loss: 0.9987282752990723
Validation loss: 2.0661452765105874

Epoch: 6| Step: 8
Training loss: 1.128998875617981
Validation loss: 2.00874601897373

Epoch: 6| Step: 9
Training loss: 0.865476667881012
Validation loss: 2.017490577954118

Epoch: 6| Step: 10
Training loss: 0.8763214349746704
Validation loss: 1.9905201529943815

Epoch: 6| Step: 11
Training loss: 1.4774208068847656
Validation loss: 2.0325912275621967

Epoch: 6| Step: 12
Training loss: 1.859839916229248
Validation loss: 2.0026702932132188

Epoch: 6| Step: 13
Training loss: 1.4230539798736572
Validation loss: 1.9801403040527015

Epoch: 708| Step: 0
Training loss: 1.7935972213745117
Validation loss: 1.9983352717532907

Epoch: 6| Step: 1
Training loss: 1.6438934803009033
Validation loss: 1.9817396197267758

Epoch: 6| Step: 2
Training loss: 0.8713164329528809
Validation loss: 1.9739175329926193

Epoch: 6| Step: 3
Training loss: 1.0256757736206055
Validation loss: 2.009226611865464

Epoch: 6| Step: 4
Training loss: 0.5824432373046875
Validation loss: 1.9803372224171956

Epoch: 6| Step: 5
Training loss: 0.8275845646858215
Validation loss: 1.9658300517707743

Epoch: 6| Step: 6
Training loss: 0.9575784206390381
Validation loss: 2.0257699374229676

Epoch: 6| Step: 7
Training loss: 1.05191171169281
Validation loss: 2.02644823187141

Epoch: 6| Step: 8
Training loss: 0.645355761051178
Validation loss: 2.024426298756753

Epoch: 6| Step: 9
Training loss: 0.8393642902374268
Validation loss: 1.9919903624442317

Epoch: 6| Step: 10
Training loss: 0.8033276796340942
Validation loss: 2.0081086030570408

Epoch: 6| Step: 11
Training loss: 1.216240644454956
Validation loss: 2.0084597731149323

Epoch: 6| Step: 12
Training loss: 1.3424272537231445
Validation loss: 2.0466760230320755

Epoch: 6| Step: 13
Training loss: 2.07831072807312
Validation loss: 2.0312702578883015

Epoch: 709| Step: 0
Training loss: 1.0266039371490479
Validation loss: 2.0039512072840044

Epoch: 6| Step: 1
Training loss: 0.9746202230453491
Validation loss: 2.0219122709766513

Epoch: 6| Step: 2
Training loss: 1.29986572265625
Validation loss: 1.9863192445488387

Epoch: 6| Step: 3
Training loss: 1.1521403789520264
Validation loss: 2.010515341194727

Epoch: 6| Step: 4
Training loss: 0.331978440284729
Validation loss: 1.992141318577592

Epoch: 6| Step: 5
Training loss: 1.268080472946167
Validation loss: 1.980876394497451

Epoch: 6| Step: 6
Training loss: 1.1439810991287231
Validation loss: 2.0313400299318376

Epoch: 6| Step: 7
Training loss: 1.177075743675232
Validation loss: 2.0237971813448015

Epoch: 6| Step: 8
Training loss: 0.9053033590316772
Validation loss: 1.9859330731053506

Epoch: 6| Step: 9
Training loss: 0.5790319442749023
Validation loss: 1.974988748950343

Epoch: 6| Step: 10
Training loss: 1.3421612977981567
Validation loss: 2.0247491739129506

Epoch: 6| Step: 11
Training loss: 0.7707579135894775
Validation loss: 2.0516962223155524

Epoch: 6| Step: 12
Training loss: 1.7296380996704102
Validation loss: 1.9935367389391827

Epoch: 6| Step: 13
Training loss: 1.0116307735443115
Validation loss: 2.036345907436904

Epoch: 710| Step: 0
Training loss: 1.1740031242370605
Validation loss: 2.013460960439456

Epoch: 6| Step: 1
Training loss: 1.0659010410308838
Validation loss: 1.9811440026888283

Epoch: 6| Step: 2
Training loss: 1.4533294439315796
Validation loss: 1.988629702598818

Epoch: 6| Step: 3
Training loss: 0.6562796235084534
Validation loss: 2.0175717492257395

Epoch: 6| Step: 4
Training loss: 1.1431814432144165
Validation loss: 2.049144083453763

Epoch: 6| Step: 5
Training loss: 1.735572338104248
Validation loss: 2.039536614571848

Epoch: 6| Step: 6
Training loss: 1.283923625946045
Validation loss: 2.0100002442636797

Epoch: 6| Step: 7
Training loss: 0.8965011239051819
Validation loss: 2.0311902825550368

Epoch: 6| Step: 8
Training loss: 0.6345363855361938
Validation loss: 2.022586211081474

Epoch: 6| Step: 9
Training loss: 0.5950490236282349
Validation loss: 2.010943833217826

Epoch: 6| Step: 10
Training loss: 1.1004904508590698
Validation loss: 2.0367174007559337

Epoch: 6| Step: 11
Training loss: 1.479999303817749
Validation loss: 2.0134234043859665

Epoch: 6| Step: 12
Training loss: 0.7163722515106201
Validation loss: 1.9958153950270785

Epoch: 6| Step: 13
Training loss: 1.2581932544708252
Validation loss: 2.022708680040093

Epoch: 711| Step: 0
Training loss: 1.4253664016723633
Validation loss: 2.091971217945058

Epoch: 6| Step: 1
Training loss: 0.8381505608558655
Validation loss: 2.0131925485467397

Epoch: 6| Step: 2
Training loss: 1.2176237106323242
Validation loss: 1.992460209836242

Epoch: 6| Step: 3
Training loss: 1.010496973991394
Validation loss: 2.021478946490954

Epoch: 6| Step: 4
Training loss: 0.39225953817367554
Validation loss: 1.9887357988665182

Epoch: 6| Step: 5
Training loss: 1.3090214729309082
Validation loss: 1.9622975254571566

Epoch: 6| Step: 6
Training loss: 0.824845016002655
Validation loss: 2.0340143096062446

Epoch: 6| Step: 7
Training loss: 1.0248340368270874
Validation loss: 2.0234523793702484

Epoch: 6| Step: 8
Training loss: 1.3029305934906006
Validation loss: 1.9848861437971874

Epoch: 6| Step: 9
Training loss: 1.798275113105774
Validation loss: 2.0029960781015377

Epoch: 6| Step: 10
Training loss: 0.7807844281196594
Validation loss: 2.034616208845569

Epoch: 6| Step: 11
Training loss: 1.421807885169983
Validation loss: 1.9940714759211386

Epoch: 6| Step: 12
Training loss: 0.7665450572967529
Validation loss: 2.035455629389773

Epoch: 6| Step: 13
Training loss: 0.9082715511322021
Validation loss: 1.9554601286047248

Epoch: 712| Step: 0
Training loss: 0.861258864402771
Validation loss: 1.9834937382769842

Epoch: 6| Step: 1
Training loss: 0.8739724159240723
Validation loss: 2.007169491501265

Epoch: 6| Step: 2
Training loss: 1.002898931503296
Validation loss: 1.9730151186707199

Epoch: 6| Step: 3
Training loss: 1.3222699165344238
Validation loss: 1.9611251008126043

Epoch: 6| Step: 4
Training loss: 1.5162849426269531
Validation loss: 1.9708953211384435

Epoch: 6| Step: 5
Training loss: 0.6814051270484924
Validation loss: 2.0200887104516387

Epoch: 6| Step: 6
Training loss: 1.377134919166565
Validation loss: 2.0161416812609603

Epoch: 6| Step: 7
Training loss: 0.8697619438171387
Validation loss: 2.043880005036631

Epoch: 6| Step: 8
Training loss: 1.2864583730697632
Validation loss: 2.0840175049279326

Epoch: 6| Step: 9
Training loss: 1.1488306522369385
Validation loss: 2.0219499859758603

Epoch: 6| Step: 10
Training loss: 0.8262102603912354
Validation loss: 2.0780431096271803

Epoch: 6| Step: 11
Training loss: 1.2676501274108887
Validation loss: 2.089164605704687

Epoch: 6| Step: 12
Training loss: 1.2291487455368042
Validation loss: 2.0617485943660943

Epoch: 6| Step: 13
Training loss: 0.5966982245445251
Validation loss: 2.0678258865110335

Epoch: 713| Step: 0
Training loss: 0.8328410983085632
Validation loss: 2.086413429629418

Epoch: 6| Step: 1
Training loss: 1.8365461826324463
Validation loss: 2.0571832272314254

Epoch: 6| Step: 2
Training loss: 0.784056544303894
Validation loss: 2.038442934713056

Epoch: 6| Step: 3
Training loss: 0.8970842957496643
Validation loss: 1.9821031875507806

Epoch: 6| Step: 4
Training loss: 0.8659831285476685
Validation loss: 2.036626123612927

Epoch: 6| Step: 5
Training loss: 0.6034872531890869
Validation loss: 1.9703803882803967

Epoch: 6| Step: 6
Training loss: 1.423526406288147
Validation loss: 1.995934368461691

Epoch: 6| Step: 7
Training loss: 0.9348007440567017
Validation loss: 1.9963672635375813

Epoch: 6| Step: 8
Training loss: 1.2048379182815552
Validation loss: 2.0125584397264706

Epoch: 6| Step: 9
Training loss: 0.834739625453949
Validation loss: 2.0050091935742285

Epoch: 6| Step: 10
Training loss: 1.3982369899749756
Validation loss: 1.9848505361105806

Epoch: 6| Step: 11
Training loss: 1.781851053237915
Validation loss: 2.0340612332026162

Epoch: 6| Step: 12
Training loss: 1.3111813068389893
Validation loss: 1.9920464754104614

Epoch: 6| Step: 13
Training loss: 0.9178128838539124
Validation loss: 2.047039980529457

Epoch: 714| Step: 0
Training loss: 0.9928231239318848
Validation loss: 2.031311713239198

Epoch: 6| Step: 1
Training loss: 1.4767488241195679
Validation loss: 2.0411141380187003

Epoch: 6| Step: 2
Training loss: 1.3503882884979248
Validation loss: 2.04518715284204

Epoch: 6| Step: 3
Training loss: 1.280561923980713
Validation loss: 2.0502898526448075

Epoch: 6| Step: 4
Training loss: 1.492030143737793
Validation loss: 2.064705917912145

Epoch: 6| Step: 5
Training loss: 1.426804780960083
Validation loss: 2.094649504589778

Epoch: 6| Step: 6
Training loss: 0.9534238576889038
Validation loss: 2.1177269181897564

Epoch: 6| Step: 7
Training loss: 1.0251657962799072
Validation loss: 2.0874262163715978

Epoch: 6| Step: 8
Training loss: 0.664595901966095
Validation loss: 2.0706281815805743

Epoch: 6| Step: 9
Training loss: 0.757487416267395
Validation loss: 2.0758712599354405

Epoch: 6| Step: 10
Training loss: 1.0408824682235718
Validation loss: 2.0946292108105076

Epoch: 6| Step: 11
Training loss: 0.9637220501899719
Validation loss: 2.037665077435073

Epoch: 6| Step: 12
Training loss: 0.7884318828582764
Validation loss: 2.0175744359211256

Epoch: 6| Step: 13
Training loss: 1.354699730873108
Validation loss: 2.062599605129611

Epoch: 715| Step: 0
Training loss: 0.803694486618042
Validation loss: 2.017654508672735

Epoch: 6| Step: 1
Training loss: 0.8978820443153381
Validation loss: 2.010059041361655

Epoch: 6| Step: 2
Training loss: 0.3037675619125366
Validation loss: 2.0118324782258723

Epoch: 6| Step: 3
Training loss: 1.275223970413208
Validation loss: 2.0069215784790697

Epoch: 6| Step: 4
Training loss: 1.4870340824127197
Validation loss: 2.0344068747694775

Epoch: 6| Step: 5
Training loss: 1.4651672840118408
Validation loss: 2.004799099378688

Epoch: 6| Step: 6
Training loss: 1.159852147102356
Validation loss: 1.9992214787390925

Epoch: 6| Step: 7
Training loss: 1.6256814002990723
Validation loss: 2.045343078592772

Epoch: 6| Step: 8
Training loss: 0.7044287919998169
Validation loss: 2.0032879255151235

Epoch: 6| Step: 9
Training loss: 1.454610824584961
Validation loss: 1.979000590180838

Epoch: 6| Step: 10
Training loss: 1.388015866279602
Validation loss: 2.0254316599138322

Epoch: 6| Step: 11
Training loss: 0.7261760234832764
Validation loss: 2.019928173352313

Epoch: 6| Step: 12
Training loss: 0.8238683342933655
Validation loss: 2.0220242059358986

Epoch: 6| Step: 13
Training loss: 0.8333948254585266
Validation loss: 2.0217624479724514

Epoch: 716| Step: 0
Training loss: 1.403700351715088
Validation loss: 2.032106239308593

Epoch: 6| Step: 1
Training loss: 1.0223747491836548
Validation loss: 2.0154611884906726

Epoch: 6| Step: 2
Training loss: 1.228209137916565
Validation loss: 2.0383162908656622

Epoch: 6| Step: 3
Training loss: 1.310889482498169
Validation loss: 2.009045163790385

Epoch: 6| Step: 4
Training loss: 1.2536060810089111
Validation loss: 2.024353534944596

Epoch: 6| Step: 5
Training loss: 0.71410071849823
Validation loss: 2.045380166781846

Epoch: 6| Step: 6
Training loss: 0.8167625665664673
Validation loss: 2.017845787027831

Epoch: 6| Step: 7
Training loss: 1.2931852340698242
Validation loss: 1.9939448423283075

Epoch: 6| Step: 8
Training loss: 1.01593017578125
Validation loss: 1.9964333272749377

Epoch: 6| Step: 9
Training loss: 1.095259428024292
Validation loss: 2.0154220827164187

Epoch: 6| Step: 10
Training loss: 1.1852004528045654
Validation loss: 1.981700917725922

Epoch: 6| Step: 11
Training loss: 0.8708212971687317
Validation loss: 2.0052480877086682

Epoch: 6| Step: 12
Training loss: 0.8673049807548523
Validation loss: 2.0001025033253494

Epoch: 6| Step: 13
Training loss: 0.8301826119422913
Validation loss: 1.9914688346206502

Epoch: 717| Step: 0
Training loss: 0.8723918199539185
Validation loss: 1.9940479929729173

Epoch: 6| Step: 1
Training loss: 1.649904727935791
Validation loss: 1.9792563069251277

Epoch: 6| Step: 2
Training loss: 0.7521497011184692
Validation loss: 2.003014382495675

Epoch: 6| Step: 3
Training loss: 1.127058982849121
Validation loss: 1.9771514246540685

Epoch: 6| Step: 4
Training loss: 1.6598292589187622
Validation loss: 2.0262016686060096

Epoch: 6| Step: 5
Training loss: 1.296828031539917
Validation loss: 1.9956119842426752

Epoch: 6| Step: 6
Training loss: 0.8013482093811035
Validation loss: 1.9966218971437024

Epoch: 6| Step: 7
Training loss: 1.1584913730621338
Validation loss: 2.029798687145274

Epoch: 6| Step: 8
Training loss: 1.2398165464401245
Validation loss: 2.0276945842209684

Epoch: 6| Step: 9
Training loss: 0.634972333908081
Validation loss: 2.014736706210721

Epoch: 6| Step: 10
Training loss: 0.5066519379615784
Validation loss: 1.985606990834718

Epoch: 6| Step: 11
Training loss: 1.3623058795928955
Validation loss: 2.020370867944533

Epoch: 6| Step: 12
Training loss: 1.4060461521148682
Validation loss: 1.9952761550103464

Epoch: 6| Step: 13
Training loss: 0.39914029836654663
Validation loss: 2.0131896695783063

Epoch: 718| Step: 0
Training loss: 1.0199644565582275
Validation loss: 2.028741113601192

Epoch: 6| Step: 1
Training loss: 0.879275381565094
Validation loss: 2.0233402495743125

Epoch: 6| Step: 2
Training loss: 1.225292682647705
Validation loss: 1.971407541664698

Epoch: 6| Step: 3
Training loss: 1.5148836374282837
Validation loss: 2.0269148195943525

Epoch: 6| Step: 4
Training loss: 0.5808888077735901
Validation loss: 1.9694769536295245

Epoch: 6| Step: 5
Training loss: 0.9669548273086548
Validation loss: 1.9917255857939362

Epoch: 6| Step: 6
Training loss: 1.3285561800003052
Validation loss: 1.984196888503208

Epoch: 6| Step: 7
Training loss: 0.9692226052284241
Validation loss: 2.0114364213840936

Epoch: 6| Step: 8
Training loss: 1.360109806060791
Validation loss: 2.002337057103393

Epoch: 6| Step: 9
Training loss: 0.6524900197982788
Validation loss: 1.9612311547802341

Epoch: 6| Step: 10
Training loss: 1.9429906606674194
Validation loss: 2.018185323284518

Epoch: 6| Step: 11
Training loss: 0.8303142786026001
Validation loss: 2.0256447048597437

Epoch: 6| Step: 12
Training loss: 0.8949944972991943
Validation loss: 2.0182394289201304

Epoch: 6| Step: 13
Training loss: 1.0839728116989136
Validation loss: 2.0398665000033636

Epoch: 719| Step: 0
Training loss: 1.0875400304794312
Validation loss: 2.057097165815292

Epoch: 6| Step: 1
Training loss: 0.8742415904998779
Validation loss: 2.0225565177138134

Epoch: 6| Step: 2
Training loss: 0.9895421266555786
Validation loss: 2.008670296720279

Epoch: 6| Step: 3
Training loss: 1.191593885421753
Validation loss: 2.0646215228624243

Epoch: 6| Step: 4
Training loss: 1.4963866472244263
Validation loss: 1.9933163222446237

Epoch: 6| Step: 5
Training loss: 0.9953866004943848
Validation loss: 2.0110391314311693

Epoch: 6| Step: 6
Training loss: 0.9465862512588501
Validation loss: 2.0067681907325663

Epoch: 6| Step: 7
Training loss: 1.6840739250183105
Validation loss: 1.9667274618661532

Epoch: 6| Step: 8
Training loss: 0.9623723030090332
Validation loss: 1.9457678051405056

Epoch: 6| Step: 9
Training loss: 0.6278179883956909
Validation loss: 1.9804333076682141

Epoch: 6| Step: 10
Training loss: 0.8892074823379517
Validation loss: 1.992298464621267

Epoch: 6| Step: 11
Training loss: 1.1812362670898438
Validation loss: 1.9872400273558914

Epoch: 6| Step: 12
Training loss: 0.8096785545349121
Validation loss: 2.0319565034681752

Epoch: 6| Step: 13
Training loss: 1.2773679494857788
Validation loss: 2.011275182488144

Epoch: 720| Step: 0
Training loss: 0.7620189785957336
Validation loss: 1.9757012641558083

Epoch: 6| Step: 1
Training loss: 0.6939637660980225
Validation loss: 2.0186925947025256

Epoch: 6| Step: 2
Training loss: 1.1076222658157349
Validation loss: 2.044252754539572

Epoch: 6| Step: 3
Training loss: 1.2447807788848877
Validation loss: 1.9902630134295392

Epoch: 6| Step: 4
Training loss: 1.2985990047454834
Validation loss: 2.068356857504896

Epoch: 6| Step: 5
Training loss: 1.242727279663086
Validation loss: 1.9871360589099187

Epoch: 6| Step: 6
Training loss: 0.8400812745094299
Validation loss: 2.011191319393855

Epoch: 6| Step: 7
Training loss: 0.8852547407150269
Validation loss: 2.0219562925318235

Epoch: 6| Step: 8
Training loss: 1.814934253692627
Validation loss: 2.038950199721962

Epoch: 6| Step: 9
Training loss: 0.8501572608947754
Validation loss: 2.0094186695673133

Epoch: 6| Step: 10
Training loss: 0.8089420795440674
Validation loss: 2.045628777114294

Epoch: 6| Step: 11
Training loss: 1.131636619567871
Validation loss: 2.0436674215460338

Epoch: 6| Step: 12
Training loss: 1.3342137336730957
Validation loss: 2.0635509285875546

Epoch: 6| Step: 13
Training loss: 0.9994855523109436
Validation loss: 2.030383761211108

Epoch: 721| Step: 0
Training loss: 0.6046962738037109
Validation loss: 2.017440157551919

Epoch: 6| Step: 1
Training loss: 1.4675297737121582
Validation loss: 1.9939473059869581

Epoch: 6| Step: 2
Training loss: 0.6982254981994629
Validation loss: 1.9780431767945648

Epoch: 6| Step: 3
Training loss: 1.510590672492981
Validation loss: 1.9597231649583386

Epoch: 6| Step: 4
Training loss: 0.6600246429443359
Validation loss: 1.9791505247034051

Epoch: 6| Step: 5
Training loss: 1.5445141792297363
Validation loss: 2.0084537459957983

Epoch: 6| Step: 6
Training loss: 1.310113549232483
Validation loss: 2.0158625315594416

Epoch: 6| Step: 7
Training loss: 0.7313507199287415
Validation loss: 2.027780164954483

Epoch: 6| Step: 8
Training loss: 0.7141678929328918
Validation loss: 2.0045971806331346

Epoch: 6| Step: 9
Training loss: 1.118420958518982
Validation loss: 1.9853477093481249

Epoch: 6| Step: 10
Training loss: 1.0277423858642578
Validation loss: 1.98148052923141

Epoch: 6| Step: 11
Training loss: 1.4562901258468628
Validation loss: 1.988945730270878

Epoch: 6| Step: 12
Training loss: 1.0941063165664673
Validation loss: 2.004518921657275

Epoch: 6| Step: 13
Training loss: 1.1210582256317139
Validation loss: 2.028543295398835

Epoch: 722| Step: 0
Training loss: 1.1504391431808472
Validation loss: 2.048574727068665

Epoch: 6| Step: 1
Training loss: 0.6404644846916199
Validation loss: 2.0257074115096882

Epoch: 6| Step: 2
Training loss: 1.2801117897033691
Validation loss: 2.0013252368537326

Epoch: 6| Step: 3
Training loss: 0.9340641498565674
Validation loss: 1.9866516538845596

Epoch: 6| Step: 4
Training loss: 1.2524232864379883
Validation loss: 2.0542728221544655

Epoch: 6| Step: 5
Training loss: 0.7876815795898438
Validation loss: 2.0603965969495874

Epoch: 6| Step: 6
Training loss: 0.9985805153846741
Validation loss: 2.022126782325006

Epoch: 6| Step: 7
Training loss: 1.6381282806396484
Validation loss: 1.991065235548122

Epoch: 6| Step: 8
Training loss: 1.6289308071136475
Validation loss: 1.9921495786277197

Epoch: 6| Step: 9
Training loss: 0.9392004013061523
Validation loss: 2.0164880470563005

Epoch: 6| Step: 10
Training loss: 0.7673978805541992
Validation loss: 1.9974028128449635

Epoch: 6| Step: 11
Training loss: 0.9834922552108765
Validation loss: 2.0087191904744794

Epoch: 6| Step: 12
Training loss: 0.8040947914123535
Validation loss: 2.0280690346994708

Epoch: 6| Step: 13
Training loss: 1.1229239702224731
Validation loss: 1.9884134415657289

Epoch: 723| Step: 0
Training loss: 1.1767091751098633
Validation loss: 1.9803677271771174

Epoch: 6| Step: 1
Training loss: 1.4181817770004272
Validation loss: 1.9906890776849562

Epoch: 6| Step: 2
Training loss: 0.8187177181243896
Validation loss: 2.0076007022652576

Epoch: 6| Step: 3
Training loss: 1.2861686944961548
Validation loss: 1.9827989993556854

Epoch: 6| Step: 4
Training loss: 1.1672775745391846
Validation loss: 1.982111515537385

Epoch: 6| Step: 5
Training loss: 1.4185703992843628
Validation loss: 1.9857374724521433

Epoch: 6| Step: 6
Training loss: 1.0384840965270996
Validation loss: 2.0512883919541554

Epoch: 6| Step: 7
Training loss: 0.44214513897895813
Validation loss: 2.004785185219139

Epoch: 6| Step: 8
Training loss: 0.6832864880561829
Validation loss: 2.031958919699474

Epoch: 6| Step: 9
Training loss: 1.3469181060791016
Validation loss: 2.0150081957540205

Epoch: 6| Step: 10
Training loss: 0.846217930316925
Validation loss: 1.9769627996670303

Epoch: 6| Step: 11
Training loss: 0.7447769641876221
Validation loss: 2.0021764924449306

Epoch: 6| Step: 12
Training loss: 1.243237853050232
Validation loss: 1.9971070161429785

Epoch: 6| Step: 13
Training loss: 1.1168314218521118
Validation loss: 1.9901251177633963

Epoch: 724| Step: 0
Training loss: 1.2325257062911987
Validation loss: 1.9907196196176673

Epoch: 6| Step: 1
Training loss: 1.4185030460357666
Validation loss: 1.9837521481257614

Epoch: 6| Step: 2
Training loss: 1.5606753826141357
Validation loss: 2.0068683496085544

Epoch: 6| Step: 3
Training loss: 1.0755060911178589
Validation loss: 1.9869126555740193

Epoch: 6| Step: 4
Training loss: 1.137582540512085
Validation loss: 1.9394153805189236

Epoch: 6| Step: 5
Training loss: 1.132373332977295
Validation loss: 1.9996702914596887

Epoch: 6| Step: 6
Training loss: 0.7341097593307495
Validation loss: 1.9784916831601052

Epoch: 6| Step: 7
Training loss: 0.524264931678772
Validation loss: 1.9760406119849092

Epoch: 6| Step: 8
Training loss: 1.191694974899292
Validation loss: 1.9946959326344151

Epoch: 6| Step: 9
Training loss: 1.1619840860366821
Validation loss: 1.994331649554673

Epoch: 6| Step: 10
Training loss: 1.0251668691635132
Validation loss: 1.9807553099047752

Epoch: 6| Step: 11
Training loss: 1.1419155597686768
Validation loss: 1.9923069553990518

Epoch: 6| Step: 12
Training loss: 0.8635834455490112
Validation loss: 1.9891085893877092

Epoch: 6| Step: 13
Training loss: 0.8892345428466797
Validation loss: 2.0363238883274857

Epoch: 725| Step: 0
Training loss: 0.7606135606765747
Validation loss: 2.0083122432872815

Epoch: 6| Step: 1
Training loss: 1.5399878025054932
Validation loss: 2.0205358677012946

Epoch: 6| Step: 2
Training loss: 1.2707154750823975
Validation loss: 2.0719151009795485

Epoch: 6| Step: 3
Training loss: 1.5579373836517334
Validation loss: 2.048408718519313

Epoch: 6| Step: 4
Training loss: 0.9979418516159058
Validation loss: 2.0137804310808898

Epoch: 6| Step: 5
Training loss: 0.9308574199676514
Validation loss: 2.010436390035896

Epoch: 6| Step: 6
Training loss: 0.8141290545463562
Validation loss: 2.0095925292661114

Epoch: 6| Step: 7
Training loss: 0.7683185338973999
Validation loss: 1.9770882309124034

Epoch: 6| Step: 8
Training loss: 0.7362279891967773
Validation loss: 2.0009395896747546

Epoch: 6| Step: 9
Training loss: 1.365563154220581
Validation loss: 2.0067133685593963

Epoch: 6| Step: 10
Training loss: 0.7992748022079468
Validation loss: 2.023594831907621

Epoch: 6| Step: 11
Training loss: 0.8904478549957275
Validation loss: 2.0039881608819448

Epoch: 6| Step: 12
Training loss: 1.370339035987854
Validation loss: 2.0014886586896834

Epoch: 6| Step: 13
Training loss: 0.9183964133262634
Validation loss: 2.020978109810942

Epoch: 726| Step: 0
Training loss: 1.2847784757614136
Validation loss: 2.0088538303170154

Epoch: 6| Step: 1
Training loss: 0.979718029499054
Validation loss: 2.015521828846265

Epoch: 6| Step: 2
Training loss: 0.7904917001724243
Validation loss: 2.0268901163531887

Epoch: 6| Step: 3
Training loss: 0.820800244808197
Validation loss: 2.0120480957851616

Epoch: 6| Step: 4
Training loss: 1.1430453062057495
Validation loss: 1.984871756645941

Epoch: 6| Step: 5
Training loss: 1.079866647720337
Validation loss: 1.977612272385628

Epoch: 6| Step: 6
Training loss: 1.5097711086273193
Validation loss: 2.041961755803836

Epoch: 6| Step: 7
Training loss: 1.4425184726715088
Validation loss: 1.9784120000818723

Epoch: 6| Step: 8
Training loss: 0.6593154072761536
Validation loss: 1.9890288281184372

Epoch: 6| Step: 9
Training loss: 1.3596227169036865
Validation loss: 2.007431391746767

Epoch: 6| Step: 10
Training loss: 0.6587401628494263
Validation loss: 2.0246975729542394

Epoch: 6| Step: 11
Training loss: 1.3110542297363281
Validation loss: 1.9881468793397308

Epoch: 6| Step: 12
Training loss: 0.7305847406387329
Validation loss: 2.003007076119864

Epoch: 6| Step: 13
Training loss: 0.9618761539459229
Validation loss: 2.019470319953016

Epoch: 727| Step: 0
Training loss: 0.8391279578208923
Validation loss: 2.029503777462949

Epoch: 6| Step: 1
Training loss: 1.1720516681671143
Validation loss: 2.0286421903999905

Epoch: 6| Step: 2
Training loss: 1.4642620086669922
Validation loss: 1.985410213470459

Epoch: 6| Step: 3
Training loss: 1.1337945461273193
Validation loss: 2.0382393585738314

Epoch: 6| Step: 4
Training loss: 1.1380430459976196
Validation loss: 2.0200106661806823

Epoch: 6| Step: 5
Training loss: 0.8174408078193665
Validation loss: 2.0041214035403345

Epoch: 6| Step: 6
Training loss: 0.7978641390800476
Validation loss: 1.996555297605453

Epoch: 6| Step: 7
Training loss: 0.981715202331543
Validation loss: 1.9512020849412488

Epoch: 6| Step: 8
Training loss: 1.2915492057800293
Validation loss: 2.0164991604384555

Epoch: 6| Step: 9
Training loss: 1.4721827507019043
Validation loss: 1.9911853562119186

Epoch: 6| Step: 10
Training loss: 1.1304876804351807
Validation loss: 2.003495233033293

Epoch: 6| Step: 11
Training loss: 0.8886264562606812
Validation loss: 2.0220654241500364

Epoch: 6| Step: 12
Training loss: 0.7850503921508789
Validation loss: 1.990550829518226

Epoch: 6| Step: 13
Training loss: 0.8627532720565796
Validation loss: 2.023031885905932

Epoch: 728| Step: 0
Training loss: 0.7483474016189575
Validation loss: 1.999965238314803

Epoch: 6| Step: 1
Training loss: 1.2116844654083252
Validation loss: 2.0668369839268346

Epoch: 6| Step: 2
Training loss: 0.9301868677139282
Validation loss: 2.1144584558343373

Epoch: 6| Step: 3
Training loss: 1.1528359651565552
Validation loss: 2.0487645620940835

Epoch: 6| Step: 4
Training loss: 0.7628581523895264
Validation loss: 2.087021884097848

Epoch: 6| Step: 5
Training loss: 0.6517941951751709
Validation loss: 2.073958220020417

Epoch: 6| Step: 6
Training loss: 1.2007360458374023
Validation loss: 2.0395532602904947

Epoch: 6| Step: 7
Training loss: 1.2864172458648682
Validation loss: 2.0500593236697617

Epoch: 6| Step: 8
Training loss: 0.8175588846206665
Validation loss: 2.0222200347531225

Epoch: 6| Step: 9
Training loss: 1.284409999847412
Validation loss: 1.96854704682545

Epoch: 6| Step: 10
Training loss: 1.2713916301727295
Validation loss: 1.9787308785223192

Epoch: 6| Step: 11
Training loss: 0.9654656648635864
Validation loss: 2.0144313432837047

Epoch: 6| Step: 12
Training loss: 1.5599262714385986
Validation loss: 1.9871027123543523

Epoch: 6| Step: 13
Training loss: 1.792317271232605
Validation loss: 1.9658137482981528

Epoch: 729| Step: 0
Training loss: 1.1644275188446045
Validation loss: 2.0246855392250964

Epoch: 6| Step: 1
Training loss: 1.0977318286895752
Validation loss: 1.9792812537121516

Epoch: 6| Step: 2
Training loss: 1.209309458732605
Validation loss: 1.9941511025992773

Epoch: 6| Step: 3
Training loss: 1.2744472026824951
Validation loss: 1.972200547495196

Epoch: 6| Step: 4
Training loss: 1.124380350112915
Validation loss: 2.002666493897797

Epoch: 6| Step: 5
Training loss: 1.1475836038589478
Validation loss: 2.0045266164246427

Epoch: 6| Step: 6
Training loss: 1.1577903032302856
Validation loss: 1.9685666522672098

Epoch: 6| Step: 7
Training loss: 1.0545895099639893
Validation loss: 1.9768955194821922

Epoch: 6| Step: 8
Training loss: 1.3389060497283936
Validation loss: 2.0287721528801868

Epoch: 6| Step: 9
Training loss: 0.7779244780540466
Validation loss: 2.001713211818408

Epoch: 6| Step: 10
Training loss: 0.7390206456184387
Validation loss: 2.030474062888853

Epoch: 6| Step: 11
Training loss: 0.7190722227096558
Validation loss: 2.02544238234079

Epoch: 6| Step: 12
Training loss: 1.1289303302764893
Validation loss: 2.077182046828731

Epoch: 6| Step: 13
Training loss: 0.6496511101722717
Validation loss: 2.045548915863037

Epoch: 730| Step: 0
Training loss: 1.3010377883911133
Validation loss: 2.0660903505099717

Epoch: 6| Step: 1
Training loss: 0.9725772142410278
Validation loss: 2.0231459653505715

Epoch: 6| Step: 2
Training loss: 1.1790869235992432
Validation loss: 1.9925610262860534

Epoch: 6| Step: 3
Training loss: 0.9448789954185486
Validation loss: 2.0033293257477465

Epoch: 6| Step: 4
Training loss: 1.506343126296997
Validation loss: 2.0196492159238426

Epoch: 6| Step: 5
Training loss: 1.0916553735733032
Validation loss: 2.029510997956799

Epoch: 6| Step: 6
Training loss: 0.9654741883277893
Validation loss: 1.964327141802798

Epoch: 6| Step: 7
Training loss: 1.0016844272613525
Validation loss: 2.005044089850559

Epoch: 6| Step: 8
Training loss: 1.138190746307373
Validation loss: 2.0182169560463197

Epoch: 6| Step: 9
Training loss: 0.6380673050880432
Validation loss: 2.008110060486742

Epoch: 6| Step: 10
Training loss: 1.1082701683044434
Validation loss: 1.9871909362013622

Epoch: 6| Step: 11
Training loss: 1.100386142730713
Validation loss: 2.0048329137986705

Epoch: 6| Step: 12
Training loss: 0.7554408311843872
Validation loss: 2.0087865565412786

Epoch: 6| Step: 13
Training loss: 1.0505831241607666
Validation loss: 1.9751034500778362

Epoch: 731| Step: 0
Training loss: 0.8166729211807251
Validation loss: 2.024265294433922

Epoch: 6| Step: 1
Training loss: 1.5627758502960205
Validation loss: 2.0323425428841704

Epoch: 6| Step: 2
Training loss: 1.32391357421875
Validation loss: 2.006771815720425

Epoch: 6| Step: 3
Training loss: 0.6665569543838501
Validation loss: 2.00353394785235

Epoch: 6| Step: 4
Training loss: 0.9649180173873901
Validation loss: 2.019658580903084

Epoch: 6| Step: 5
Training loss: 1.1261037588119507
Validation loss: 1.991058159899968

Epoch: 6| Step: 6
Training loss: 1.2241053581237793
Validation loss: 2.0566914286664737

Epoch: 6| Step: 7
Training loss: 1.313254475593567
Validation loss: 2.0215608189182896

Epoch: 6| Step: 8
Training loss: 0.8992278575897217
Validation loss: 1.960713424990254

Epoch: 6| Step: 9
Training loss: 0.6483038663864136
Validation loss: 1.9915973089074577

Epoch: 6| Step: 10
Training loss: 0.8305662274360657
Validation loss: 1.9323786112569994

Epoch: 6| Step: 11
Training loss: 1.096628189086914
Validation loss: 2.000147792600816

Epoch: 6| Step: 12
Training loss: 0.9061514139175415
Validation loss: 2.0298447224401657

Epoch: 6| Step: 13
Training loss: 1.077078104019165
Validation loss: 1.9813558683600476

Epoch: 732| Step: 0
Training loss: 1.2651968002319336
Validation loss: 2.001257014530961

Epoch: 6| Step: 1
Training loss: 1.3642523288726807
Validation loss: 2.0022058961211995

Epoch: 6| Step: 2
Training loss: 1.0278122425079346
Validation loss: 2.0082584375976236

Epoch: 6| Step: 3
Training loss: 0.7481762170791626
Validation loss: 2.0197307755870204

Epoch: 6| Step: 4
Training loss: 0.7358425259590149
Validation loss: 2.0143507629312496

Epoch: 6| Step: 5
Training loss: 1.1935899257659912
Validation loss: 2.0067264264629734

Epoch: 6| Step: 6
Training loss: 1.2073345184326172
Validation loss: 2.0159307667004165

Epoch: 6| Step: 7
Training loss: 0.9995026588439941
Validation loss: 2.0175383437064385

Epoch: 6| Step: 8
Training loss: 0.6074012517929077
Validation loss: 2.000954315226565

Epoch: 6| Step: 9
Training loss: 1.4643986225128174
Validation loss: 1.9654788201855076

Epoch: 6| Step: 10
Training loss: 0.9453799724578857
Validation loss: 2.018234363166235

Epoch: 6| Step: 11
Training loss: 0.9902352094650269
Validation loss: 2.0031645605641026

Epoch: 6| Step: 12
Training loss: 1.1378440856933594
Validation loss: 1.9794105637458064

Epoch: 6| Step: 13
Training loss: 1.085084080696106
Validation loss: 1.9885266147634035

Epoch: 733| Step: 0
Training loss: 1.1978479623794556
Validation loss: 2.0013179061233357

Epoch: 6| Step: 1
Training loss: 0.7031048536300659
Validation loss: 2.0261653700182514

Epoch: 6| Step: 2
Training loss: 0.993817150592804
Validation loss: 2.0034992617945515

Epoch: 6| Step: 3
Training loss: 1.0273704528808594
Validation loss: 1.9930074548208585

Epoch: 6| Step: 4
Training loss: 0.9109372496604919
Validation loss: 1.9953448592975576

Epoch: 6| Step: 5
Training loss: 0.9232828617095947
Validation loss: 2.014317722730739

Epoch: 6| Step: 6
Training loss: 0.954867959022522
Validation loss: 2.0212107960895827

Epoch: 6| Step: 7
Training loss: 1.7657673358917236
Validation loss: 1.9849156154099332

Epoch: 6| Step: 8
Training loss: 0.7371941804885864
Validation loss: 2.022431032631987

Epoch: 6| Step: 9
Training loss: 0.9746415615081787
Validation loss: 1.9999876150520899

Epoch: 6| Step: 10
Training loss: 0.8680287599563599
Validation loss: 2.028737771895624

Epoch: 6| Step: 11
Training loss: 1.215181827545166
Validation loss: 1.9871958301913353

Epoch: 6| Step: 12
Training loss: 1.2517528533935547
Validation loss: 2.0255454124942904

Epoch: 6| Step: 13
Training loss: 1.0700902938842773
Validation loss: 1.9802049770150134

Epoch: 734| Step: 0
Training loss: 1.0070576667785645
Validation loss: 2.010792624565863

Epoch: 6| Step: 1
Training loss: 0.449357271194458
Validation loss: 1.9513049920399983

Epoch: 6| Step: 2
Training loss: 1.1386140584945679
Validation loss: 1.9902435374516312

Epoch: 6| Step: 3
Training loss: 1.0453479290008545
Validation loss: 1.927111610289543

Epoch: 6| Step: 4
Training loss: 0.9328749179840088
Validation loss: 2.0146568872595347

Epoch: 6| Step: 5
Training loss: 1.5699129104614258
Validation loss: 1.9959412800368441

Epoch: 6| Step: 6
Training loss: 0.8037840127944946
Validation loss: 1.9967226110478884

Epoch: 6| Step: 7
Training loss: 0.8279480934143066
Validation loss: 1.9984021763647757

Epoch: 6| Step: 8
Training loss: 1.3712435960769653
Validation loss: 1.9992424852104598

Epoch: 6| Step: 9
Training loss: 1.3332040309906006
Validation loss: 2.031021902638097

Epoch: 6| Step: 10
Training loss: 1.0153084993362427
Validation loss: 2.0177267700113277

Epoch: 6| Step: 11
Training loss: 0.8949687480926514
Validation loss: 1.9974704916759203

Epoch: 6| Step: 12
Training loss: 1.2607245445251465
Validation loss: 1.987678494504703

Epoch: 6| Step: 13
Training loss: 0.8989567160606384
Validation loss: 1.9687640538779638

Epoch: 735| Step: 0
Training loss: 0.7450718283653259
Validation loss: 1.9974705326941706

Epoch: 6| Step: 1
Training loss: 0.8017650842666626
Validation loss: 1.994054607165757

Epoch: 6| Step: 2
Training loss: 1.1201846599578857
Validation loss: 1.9893851869849748

Epoch: 6| Step: 3
Training loss: 0.7846096754074097
Validation loss: 2.0370563127661265

Epoch: 6| Step: 4
Training loss: 1.1651391983032227
Validation loss: 2.0049932695204213

Epoch: 6| Step: 5
Training loss: 1.0342000722885132
Validation loss: 2.0611144419639342

Epoch: 6| Step: 6
Training loss: 0.814420223236084
Validation loss: 2.0597891410191855

Epoch: 6| Step: 7
Training loss: 0.9666284918785095
Validation loss: 2.0491856003320343

Epoch: 6| Step: 8
Training loss: 0.8564024567604065
Validation loss: 2.044016727837183

Epoch: 6| Step: 9
Training loss: 1.0822327136993408
Validation loss: 2.0357072378999446

Epoch: 6| Step: 10
Training loss: 1.633244276046753
Validation loss: 1.9910213024385515

Epoch: 6| Step: 11
Training loss: 1.6083152294158936
Validation loss: 2.0025563957870647

Epoch: 6| Step: 12
Training loss: 0.9054839015007019
Validation loss: 2.0188558191381474

Epoch: 6| Step: 13
Training loss: 1.1010587215423584
Validation loss: 1.9909370765891126

Epoch: 736| Step: 0
Training loss: 1.139815092086792
Validation loss: 2.001303175444244

Epoch: 6| Step: 1
Training loss: 1.1732056140899658
Validation loss: 1.949404542164136

Epoch: 6| Step: 2
Training loss: 0.762540340423584
Validation loss: 1.967839830665178

Epoch: 6| Step: 3
Training loss: 1.0117039680480957
Validation loss: 1.9911066639807917

Epoch: 6| Step: 4
Training loss: 0.7473999857902527
Validation loss: 1.9845855441144717

Epoch: 6| Step: 5
Training loss: 1.205649495124817
Validation loss: 2.01185114665698

Epoch: 6| Step: 6
Training loss: 0.8032326698303223
Validation loss: 2.0702625474622174

Epoch: 6| Step: 7
Training loss: 1.225611686706543
Validation loss: 1.9978949305831746

Epoch: 6| Step: 8
Training loss: 1.5461070537567139
Validation loss: 2.021905178664833

Epoch: 6| Step: 9
Training loss: 1.2531580924987793
Validation loss: 2.0092707731390513

Epoch: 6| Step: 10
Training loss: 0.6185722351074219
Validation loss: 2.0350728829701743

Epoch: 6| Step: 11
Training loss: 0.9325539469718933
Validation loss: 1.984937083336615

Epoch: 6| Step: 12
Training loss: 1.0848543643951416
Validation loss: 2.0131519045881046

Epoch: 6| Step: 13
Training loss: 0.7054049968719482
Validation loss: 2.043756144021147

Epoch: 737| Step: 0
Training loss: 0.9853987693786621
Validation loss: 2.026614086602324

Epoch: 6| Step: 1
Training loss: 0.9553689360618591
Validation loss: 2.034117316686979

Epoch: 6| Step: 2
Training loss: 1.1395741701126099
Validation loss: 1.9947799303198372

Epoch: 6| Step: 3
Training loss: 0.8251821398735046
Validation loss: 2.018686568865212

Epoch: 6| Step: 4
Training loss: 1.0385453701019287
Validation loss: 1.9917933992160264

Epoch: 6| Step: 5
Training loss: 1.3616939783096313
Validation loss: 2.021423752589892

Epoch: 6| Step: 6
Training loss: 0.7850143909454346
Validation loss: 1.9737173075317054

Epoch: 6| Step: 7
Training loss: 1.2285544872283936
Validation loss: 1.9555869320387482

Epoch: 6| Step: 8
Training loss: 1.4839727878570557
Validation loss: 1.9867940589945803

Epoch: 6| Step: 9
Training loss: 0.7711472511291504
Validation loss: 1.9922223116761895

Epoch: 6| Step: 10
Training loss: 0.4516028165817261
Validation loss: 2.0396600487411662

Epoch: 6| Step: 11
Training loss: 1.4743359088897705
Validation loss: 2.0051569810477634

Epoch: 6| Step: 12
Training loss: 1.407184362411499
Validation loss: 2.053530175198791

Epoch: 6| Step: 13
Training loss: 0.5073671936988831
Validation loss: 1.9627005656560261

Epoch: 738| Step: 0
Training loss: 1.0834705829620361
Validation loss: 1.985892516310497

Epoch: 6| Step: 1
Training loss: 0.98744797706604
Validation loss: 2.0125909774534163

Epoch: 6| Step: 2
Training loss: 1.241849422454834
Validation loss: 1.9614064488359677

Epoch: 6| Step: 3
Training loss: 1.9310424327850342
Validation loss: 1.9852854590262137

Epoch: 6| Step: 4
Training loss: 0.9096190929412842
Validation loss: 2.021764160484396

Epoch: 6| Step: 5
Training loss: 0.9528464078903198
Validation loss: 1.9824489278178061

Epoch: 6| Step: 6
Training loss: 1.085951566696167
Validation loss: 1.9929411847104308

Epoch: 6| Step: 7
Training loss: 0.9610313773155212
Validation loss: 2.0219087395616757

Epoch: 6| Step: 8
Training loss: 0.6088067889213562
Validation loss: 1.9740020639152938

Epoch: 6| Step: 9
Training loss: 1.1184327602386475
Validation loss: 2.0050839685624644

Epoch: 6| Step: 10
Training loss: 0.8294697999954224
Validation loss: 2.0027860492788334

Epoch: 6| Step: 11
Training loss: 0.984923243522644
Validation loss: 1.9770399729410808

Epoch: 6| Step: 12
Training loss: 0.9449513554573059
Validation loss: 2.0209224621454873

Epoch: 6| Step: 13
Training loss: 1.0894875526428223
Validation loss: 2.0543592053074993

Epoch: 739| Step: 0
Training loss: 0.9095594882965088
Validation loss: 2.0107332788487917

Epoch: 6| Step: 1
Training loss: 1.0751149654388428
Validation loss: 1.9932598644687283

Epoch: 6| Step: 2
Training loss: 0.49985361099243164
Validation loss: 1.983460460939715

Epoch: 6| Step: 3
Training loss: 1.0277926921844482
Validation loss: 2.008477128962035

Epoch: 6| Step: 4
Training loss: 0.8345421552658081
Validation loss: 2.0202009934251026

Epoch: 6| Step: 5
Training loss: 1.223362922668457
Validation loss: 1.9841157723498601

Epoch: 6| Step: 6
Training loss: 1.3071237802505493
Validation loss: 2.0006645802528626

Epoch: 6| Step: 7
Training loss: 0.930478572845459
Validation loss: 1.9870338081031718

Epoch: 6| Step: 8
Training loss: 1.2342779636383057
Validation loss: 2.0089347862428233

Epoch: 6| Step: 9
Training loss: 1.3597805500030518
Validation loss: 1.9295176985443279

Epoch: 6| Step: 10
Training loss: 0.9864367842674255
Validation loss: 1.9472573239316222

Epoch: 6| Step: 11
Training loss: 0.9944449663162231
Validation loss: 2.0462610798497356

Epoch: 6| Step: 12
Training loss: 1.2893023490905762
Validation loss: 1.9410214065223612

Epoch: 6| Step: 13
Training loss: 0.7805715203285217
Validation loss: 2.029079511601438

Epoch: 740| Step: 0
Training loss: 1.1483455896377563
Validation loss: 2.0174140981448594

Epoch: 6| Step: 1
Training loss: 1.3514419794082642
Validation loss: 2.033892257239229

Epoch: 6| Step: 2
Training loss: 1.1020160913467407
Validation loss: 1.9947237455716698

Epoch: 6| Step: 3
Training loss: 0.5055326819419861
Validation loss: 2.027599980754237

Epoch: 6| Step: 4
Training loss: 1.0239059925079346
Validation loss: 1.984412549644388

Epoch: 6| Step: 5
Training loss: 0.4976968765258789
Validation loss: 2.0300809875611336

Epoch: 6| Step: 6
Training loss: 1.1852872371673584
Validation loss: 2.023298401986399

Epoch: 6| Step: 7
Training loss: 0.8230569362640381
Validation loss: 2.017798295585058

Epoch: 6| Step: 8
Training loss: 0.8591432571411133
Validation loss: 2.0349085356599543

Epoch: 6| Step: 9
Training loss: 1.1238963603973389
Validation loss: 2.013059969871275

Epoch: 6| Step: 10
Training loss: 1.0263820886611938
Validation loss: 1.958946208800039

Epoch: 6| Step: 11
Training loss: 1.2999681234359741
Validation loss: 1.9841791942555418

Epoch: 6| Step: 12
Training loss: 1.0993225574493408
Validation loss: 2.011797356349166

Epoch: 6| Step: 13
Training loss: 1.1291528940200806
Validation loss: 2.006179372469584

Epoch: 741| Step: 0
Training loss: 0.8445339202880859
Validation loss: 2.0311126273165465

Epoch: 6| Step: 1
Training loss: 1.2184169292449951
Validation loss: 2.003403389325706

Epoch: 6| Step: 2
Training loss: 0.5540543794631958
Validation loss: 1.9660275405453098

Epoch: 6| Step: 3
Training loss: 0.6125972270965576
Validation loss: 1.9830566157576859

Epoch: 6| Step: 4
Training loss: 0.9342325925827026
Validation loss: 1.9931537746101298

Epoch: 6| Step: 5
Training loss: 1.2991623878479004
Validation loss: 2.051422915151042

Epoch: 6| Step: 6
Training loss: 1.516332745552063
Validation loss: 1.9928383417026971

Epoch: 6| Step: 7
Training loss: 1.3050339221954346
Validation loss: 1.983601608584004

Epoch: 6| Step: 8
Training loss: 0.7497518658638
Validation loss: 1.9841412780105427

Epoch: 6| Step: 9
Training loss: 1.630326509475708
Validation loss: 1.9919230745684715

Epoch: 6| Step: 10
Training loss: 0.7959563136100769
Validation loss: 2.0159982327492005

Epoch: 6| Step: 11
Training loss: 0.8416321277618408
Validation loss: 2.030415419609316

Epoch: 6| Step: 12
Training loss: 0.8734689950942993
Validation loss: 1.988019112617739

Epoch: 6| Step: 13
Training loss: 1.4598307609558105
Validation loss: 2.017268278265512

Epoch: 742| Step: 0
Training loss: 0.3505301773548126
Validation loss: 2.033795815642162

Epoch: 6| Step: 1
Training loss: 1.0605591535568237
Validation loss: 2.031145500880416

Epoch: 6| Step: 2
Training loss: 1.4006905555725098
Validation loss: 2.0175794209203413

Epoch: 6| Step: 3
Training loss: 0.6793951392173767
Validation loss: 2.0358321820535967

Epoch: 6| Step: 4
Training loss: 1.1748104095458984
Validation loss: 1.9983233572334371

Epoch: 6| Step: 5
Training loss: 1.0672695636749268
Validation loss: 2.0522598887002594

Epoch: 6| Step: 6
Training loss: 0.7438642978668213
Validation loss: 2.0003196321507937

Epoch: 6| Step: 7
Training loss: 1.070925235748291
Validation loss: 2.040386526815353

Epoch: 6| Step: 8
Training loss: 0.875205397605896
Validation loss: 1.9805425238865677

Epoch: 6| Step: 9
Training loss: 0.9238248467445374
Validation loss: 1.9945587573512908

Epoch: 6| Step: 10
Training loss: 1.4060883522033691
Validation loss: 2.0196041868579004

Epoch: 6| Step: 11
Training loss: 1.5760884284973145
Validation loss: 2.047984996149617

Epoch: 6| Step: 12
Training loss: 1.1979702711105347
Validation loss: 1.9925813995381838

Epoch: 6| Step: 13
Training loss: 0.8542052507400513
Validation loss: 1.9768290724805606

Epoch: 743| Step: 0
Training loss: 1.1024401187896729
Validation loss: 2.007234507991422

Epoch: 6| Step: 1
Training loss: 1.0127012729644775
Validation loss: 2.011724696364454

Epoch: 6| Step: 2
Training loss: 0.9058857560157776
Validation loss: 2.047780734236522

Epoch: 6| Step: 3
Training loss: 1.196460247039795
Validation loss: 2.0096097223220335

Epoch: 6| Step: 4
Training loss: 0.8356731534004211
Validation loss: 2.0481081854912544

Epoch: 6| Step: 5
Training loss: 1.1832890510559082
Validation loss: 2.073841574371502

Epoch: 6| Step: 6
Training loss: 1.1943025588989258
Validation loss: 2.013562020435128

Epoch: 6| Step: 7
Training loss: 1.4235389232635498
Validation loss: 2.002026270794612

Epoch: 6| Step: 8
Training loss: 0.6218606233596802
Validation loss: 2.0369455224724224

Epoch: 6| Step: 9
Training loss: 1.1309704780578613
Validation loss: 2.0212367068054857

Epoch: 6| Step: 10
Training loss: 0.809768795967102
Validation loss: 2.024175009419841

Epoch: 6| Step: 11
Training loss: 0.8069580793380737
Validation loss: 2.014424595781552

Epoch: 6| Step: 12
Training loss: 0.6061152219772339
Validation loss: 1.9962289846071632

Epoch: 6| Step: 13
Training loss: 1.9522974491119385
Validation loss: 1.9263369896078621

Epoch: 744| Step: 0
Training loss: 1.3811551332473755
Validation loss: 1.9663386844819593

Epoch: 6| Step: 1
Training loss: 0.7297607660293579
Validation loss: 2.014368951961558

Epoch: 6| Step: 2
Training loss: 1.0655946731567383
Validation loss: 2.0548464905831123

Epoch: 6| Step: 3
Training loss: 1.3804129362106323
Validation loss: 2.040360014925721

Epoch: 6| Step: 4
Training loss: 0.6104349493980408
Validation loss: 1.995258262080531

Epoch: 6| Step: 5
Training loss: 1.090517520904541
Validation loss: 1.958133033526841

Epoch: 6| Step: 6
Training loss: 0.8957356214523315
Validation loss: 1.9849881946399648

Epoch: 6| Step: 7
Training loss: 1.2792692184448242
Validation loss: 1.9890180557004866

Epoch: 6| Step: 8
Training loss: 1.051771640777588
Validation loss: 2.006685761995213

Epoch: 6| Step: 9
Training loss: 1.2217135429382324
Validation loss: 2.036914017892653

Epoch: 6| Step: 10
Training loss: 1.3043981790542603
Validation loss: 2.0546820112453994

Epoch: 6| Step: 11
Training loss: 0.7942769527435303
Validation loss: 2.0671913572537

Epoch: 6| Step: 12
Training loss: 0.8455507159233093
Validation loss: 2.011781992450837

Epoch: 6| Step: 13
Training loss: 0.7348608374595642
Validation loss: 2.0660260108209427

Epoch: 745| Step: 0
Training loss: 0.8811984062194824
Validation loss: 2.032885730907481

Epoch: 6| Step: 1
Training loss: 0.9585332274436951
Validation loss: 2.039624462845505

Epoch: 6| Step: 2
Training loss: 0.8719132542610168
Validation loss: 2.018681815875474

Epoch: 6| Step: 3
Training loss: 1.1470160484313965
Validation loss: 1.9795590216113674

Epoch: 6| Step: 4
Training loss: 0.7746435403823853
Validation loss: 1.9731394513960807

Epoch: 6| Step: 5
Training loss: 1.9835413694381714
Validation loss: 2.0177649554385932

Epoch: 6| Step: 6
Training loss: 1.0155866146087646
Validation loss: 1.9528359110637377

Epoch: 6| Step: 7
Training loss: 1.2130489349365234
Validation loss: 1.991614798063873

Epoch: 6| Step: 8
Training loss: 0.7720974683761597
Validation loss: 1.9746120104225733

Epoch: 6| Step: 9
Training loss: 0.5372433066368103
Validation loss: 1.974974501517511

Epoch: 6| Step: 10
Training loss: 1.0155162811279297
Validation loss: 1.9796838311738865

Epoch: 6| Step: 11
Training loss: 1.0897411108016968
Validation loss: 1.9893561896457468

Epoch: 6| Step: 12
Training loss: 1.6373330354690552
Validation loss: 1.9984544361791303

Epoch: 6| Step: 13
Training loss: 0.3514840006828308
Validation loss: 1.9670475093267297

Epoch: 746| Step: 0
Training loss: 0.8226969838142395
Validation loss: 1.9941992387976697

Epoch: 6| Step: 1
Training loss: 0.8196349740028381
Validation loss: 1.9870783590501355

Epoch: 6| Step: 2
Training loss: 1.0862786769866943
Validation loss: 2.0013713452123825

Epoch: 6| Step: 3
Training loss: 1.2262821197509766
Validation loss: 2.0015726550932853

Epoch: 6| Step: 4
Training loss: 0.9438213109970093
Validation loss: 1.9901817921669251

Epoch: 6| Step: 5
Training loss: 0.9262682199478149
Validation loss: 2.014754802949967

Epoch: 6| Step: 6
Training loss: 1.12363600730896
Validation loss: 2.019484022612213

Epoch: 6| Step: 7
Training loss: 1.077025294303894
Validation loss: 2.019939976353799

Epoch: 6| Step: 8
Training loss: 0.9729727506637573
Validation loss: 2.0556646329100414

Epoch: 6| Step: 9
Training loss: 0.9509410262107849
Validation loss: 2.011808115948913

Epoch: 6| Step: 10
Training loss: 0.922255277633667
Validation loss: 2.008534323784613

Epoch: 6| Step: 11
Training loss: 1.4803705215454102
Validation loss: 2.0071455560704714

Epoch: 6| Step: 12
Training loss: 0.9613808393478394
Validation loss: 2.0049536535816808

Epoch: 6| Step: 13
Training loss: 0.8578364849090576
Validation loss: 2.00945217891406

Epoch: 747| Step: 0
Training loss: 0.920812726020813
Validation loss: 2.0202459276363416

Epoch: 6| Step: 1
Training loss: 1.1246633529663086
Validation loss: 1.9842885566014115

Epoch: 6| Step: 2
Training loss: 0.9682183265686035
Validation loss: 2.1131558931002052

Epoch: 6| Step: 3
Training loss: 1.0247917175292969
Validation loss: 2.037625453805411

Epoch: 6| Step: 4
Training loss: 1.2825889587402344
Validation loss: 2.0648345588355936

Epoch: 6| Step: 5
Training loss: 0.8375356197357178
Validation loss: 2.0367020701849334

Epoch: 6| Step: 6
Training loss: 0.6116434335708618
Validation loss: 1.975701832002209

Epoch: 6| Step: 7
Training loss: 0.9158000946044922
Validation loss: 1.9449135231715378

Epoch: 6| Step: 8
Training loss: 0.9378131628036499
Validation loss: 1.9572249753500826

Epoch: 6| Step: 9
Training loss: 0.5316822528839111
Validation loss: 1.9973869862095002

Epoch: 6| Step: 10
Training loss: 1.209181308746338
Validation loss: 1.9862794747916601

Epoch: 6| Step: 11
Training loss: 1.7218713760375977
Validation loss: 1.9990166553886988

Epoch: 6| Step: 12
Training loss: 1.4192700386047363
Validation loss: 1.984908632052842

Epoch: 6| Step: 13
Training loss: 1.2528222799301147
Validation loss: 1.9667331146937546

Epoch: 748| Step: 0
Training loss: 0.8996858596801758
Validation loss: 1.9736701967895671

Epoch: 6| Step: 1
Training loss: 0.6899199485778809
Validation loss: 1.9878393809000652

Epoch: 6| Step: 2
Training loss: 1.5630829334259033
Validation loss: 2.016991807568458

Epoch: 6| Step: 3
Training loss: 0.9814621210098267
Validation loss: 1.9658776624228365

Epoch: 6| Step: 4
Training loss: 1.0470579862594604
Validation loss: 1.988584021086334

Epoch: 6| Step: 5
Training loss: 1.0652388334274292
Validation loss: 1.9730843728588474

Epoch: 6| Step: 6
Training loss: 1.2687532901763916
Validation loss: 2.036716209944858

Epoch: 6| Step: 7
Training loss: 0.8998515605926514
Validation loss: 1.998373298234837

Epoch: 6| Step: 8
Training loss: 1.6952441930770874
Validation loss: 2.0105623199093725

Epoch: 6| Step: 9
Training loss: 0.35056212544441223
Validation loss: 2.051774601782522

Epoch: 6| Step: 10
Training loss: 1.1684157848358154
Validation loss: 2.043504625238398

Epoch: 6| Step: 11
Training loss: 1.0100680589675903
Validation loss: 2.0636494518608175

Epoch: 6| Step: 12
Training loss: 1.0554417371749878
Validation loss: 2.036835419234409

Epoch: 6| Step: 13
Training loss: 0.5030604600906372
Validation loss: 2.0394389424272763

Epoch: 749| Step: 0
Training loss: 1.086338996887207
Validation loss: 1.9947850088919363

Epoch: 6| Step: 1
Training loss: 0.9581065773963928
Validation loss: 2.0722434956540345

Epoch: 6| Step: 2
Training loss: 0.9854676127433777
Validation loss: 2.0123042624483825

Epoch: 6| Step: 3
Training loss: 1.5939356088638306
Validation loss: 2.0387862164487123

Epoch: 6| Step: 4
Training loss: 1.7596968412399292
Validation loss: 1.9971520157270535

Epoch: 6| Step: 5
Training loss: 0.9655866622924805
Validation loss: 1.950272257610034

Epoch: 6| Step: 6
Training loss: 1.2494107484817505
Validation loss: 1.9873638012075936

Epoch: 6| Step: 7
Training loss: 1.1331205368041992
Validation loss: 1.9610611187514437

Epoch: 6| Step: 8
Training loss: 0.6709668040275574
Validation loss: 2.038438617542226

Epoch: 6| Step: 9
Training loss: 0.47575801610946655
Validation loss: 1.9721556889113558

Epoch: 6| Step: 10
Training loss: 0.5644403696060181
Validation loss: 2.0186546976848314

Epoch: 6| Step: 11
Training loss: 1.1434433460235596
Validation loss: 1.9436332205290436

Epoch: 6| Step: 12
Training loss: 0.49144673347473145
Validation loss: 1.9649456213879328

Epoch: 6| Step: 13
Training loss: 1.0007424354553223
Validation loss: 1.9262695081772343

Epoch: 750| Step: 0
Training loss: 0.7541396617889404
Validation loss: 2.0102636352662118

Epoch: 6| Step: 1
Training loss: 1.6546134948730469
Validation loss: 1.9995678855526833

Epoch: 6| Step: 2
Training loss: 1.1373234987258911
Validation loss: 1.9792322189577165

Epoch: 6| Step: 3
Training loss: 1.0432829856872559
Validation loss: 1.9972459372653757

Epoch: 6| Step: 4
Training loss: 1.4162876605987549
Validation loss: 2.0068904199907855

Epoch: 6| Step: 5
Training loss: 1.1442118883132935
Validation loss: 2.032237947628062

Epoch: 6| Step: 6
Training loss: 0.7829818725585938
Validation loss: 2.017644028509817

Epoch: 6| Step: 7
Training loss: 0.8851286172866821
Validation loss: 2.0406298816844983

Epoch: 6| Step: 8
Training loss: 0.47702184319496155
Validation loss: 2.012840099232171

Epoch: 6| Step: 9
Training loss: 1.1470024585723877
Validation loss: 2.0144710797135548

Epoch: 6| Step: 10
Training loss: 0.8661699295043945
Validation loss: 1.9989003724949335

Epoch: 6| Step: 11
Training loss: 1.280468463897705
Validation loss: 2.0368412335713706

Epoch: 6| Step: 12
Training loss: 0.8412264585494995
Validation loss: 2.0168080317076815

Epoch: 6| Step: 13
Training loss: 1.3303345441818237
Validation loss: 2.012386983440768

Epoch: 751| Step: 0
Training loss: 0.9570291042327881
Validation loss: 2.0308179675891833

Epoch: 6| Step: 1
Training loss: 1.6570587158203125
Validation loss: 2.0157553226717058

Epoch: 6| Step: 2
Training loss: 1.4557585716247559
Validation loss: 1.9707661924823638

Epoch: 6| Step: 3
Training loss: 0.47880157828330994
Validation loss: 1.9974572158628894

Epoch: 6| Step: 4
Training loss: 0.5908176898956299
Validation loss: 1.989288919715471

Epoch: 6| Step: 5
Training loss: 1.0104119777679443
Validation loss: 1.9888487836366058

Epoch: 6| Step: 6
Training loss: 1.0407378673553467
Validation loss: 1.9917282340347127

Epoch: 6| Step: 7
Training loss: 1.2709916830062866
Validation loss: 1.9927471017324796

Epoch: 6| Step: 8
Training loss: 0.8884851336479187
Validation loss: 1.9785942518582909

Epoch: 6| Step: 9
Training loss: 0.8002405166625977
Validation loss: 2.0000773270924888

Epoch: 6| Step: 10
Training loss: 1.1278038024902344
Validation loss: 1.9279704286206154

Epoch: 6| Step: 11
Training loss: 0.9926570057868958
Validation loss: 1.9905655922428254

Epoch: 6| Step: 12
Training loss: 1.0806161165237427
Validation loss: 2.000028212865194

Epoch: 6| Step: 13
Training loss: 1.326032280921936
Validation loss: 2.0163234203092513

Epoch: 752| Step: 0
Training loss: 0.8098208904266357
Validation loss: 1.935038351243542

Epoch: 6| Step: 1
Training loss: 1.0031474828720093
Validation loss: 1.979073127110799

Epoch: 6| Step: 2
Training loss: 1.0905122756958008
Validation loss: 1.9783355882090907

Epoch: 6| Step: 3
Training loss: 0.9689767360687256
Validation loss: 1.9904687596905617

Epoch: 6| Step: 4
Training loss: 1.113516092300415
Validation loss: 1.990731857156241

Epoch: 6| Step: 5
Training loss: 0.7181963920593262
Validation loss: 1.9645506502479635

Epoch: 6| Step: 6
Training loss: 1.5293197631835938
Validation loss: 1.970922884120736

Epoch: 6| Step: 7
Training loss: 0.8344703912734985
Validation loss: 1.9608642414052

Epoch: 6| Step: 8
Training loss: 1.0156071186065674
Validation loss: 2.000293183070357

Epoch: 6| Step: 9
Training loss: 0.6342833638191223
Validation loss: 2.045956201450799

Epoch: 6| Step: 10
Training loss: 1.3172786235809326
Validation loss: 1.9832320021044823

Epoch: 6| Step: 11
Training loss: 0.7887988090515137
Validation loss: 2.013145823632517

Epoch: 6| Step: 12
Training loss: 1.2532997131347656
Validation loss: 1.9909249159597582

Epoch: 6| Step: 13
Training loss: 1.0831652879714966
Validation loss: 2.003134057086001

Epoch: 753| Step: 0
Training loss: 0.6249867677688599
Validation loss: 2.006461081966277

Epoch: 6| Step: 1
Training loss: 1.2954826354980469
Validation loss: 2.012144434836603

Epoch: 6| Step: 2
Training loss: 1.217729091644287
Validation loss: 2.0059624256626254

Epoch: 6| Step: 3
Training loss: 0.9624812006950378
Validation loss: 2.0361672537301176

Epoch: 6| Step: 4
Training loss: 1.0022536516189575
Validation loss: 2.0317278959417857

Epoch: 6| Step: 5
Training loss: 1.1609196662902832
Validation loss: 2.0107720103315128

Epoch: 6| Step: 6
Training loss: 0.44214892387390137
Validation loss: 2.007225198130454

Epoch: 6| Step: 7
Training loss: 1.4531641006469727
Validation loss: 2.0321658170351418

Epoch: 6| Step: 8
Training loss: 1.1128085851669312
Validation loss: 1.9636554512926327

Epoch: 6| Step: 9
Training loss: 0.9220391511917114
Validation loss: 1.981322875586889

Epoch: 6| Step: 10
Training loss: 1.609039306640625
Validation loss: 1.9856468900557487

Epoch: 6| Step: 11
Training loss: 1.0944241285324097
Validation loss: 1.9920150746581375

Epoch: 6| Step: 12
Training loss: 0.5403302907943726
Validation loss: 2.002639919198969

Epoch: 6| Step: 13
Training loss: 1.1650145053863525
Validation loss: 1.97984343190347

Epoch: 754| Step: 0
Training loss: 1.163682222366333
Validation loss: 2.0210281392579437

Epoch: 6| Step: 1
Training loss: 0.8929403424263
Validation loss: 1.9570210967012631

Epoch: 6| Step: 2
Training loss: 0.9414107799530029
Validation loss: 1.990203885621922

Epoch: 6| Step: 3
Training loss: 0.7292579412460327
Validation loss: 1.9630323353634085

Epoch: 6| Step: 4
Training loss: 0.8523960113525391
Validation loss: 1.9954433594980547

Epoch: 6| Step: 5
Training loss: 0.9513435363769531
Validation loss: 2.0312113736265447

Epoch: 6| Step: 6
Training loss: 1.2964730262756348
Validation loss: 1.9692677477354645

Epoch: 6| Step: 7
Training loss: 0.9221151471138
Validation loss: 2.0076113593193794

Epoch: 6| Step: 8
Training loss: 0.9707877039909363
Validation loss: 1.9686052876134073

Epoch: 6| Step: 9
Training loss: 0.9452690482139587
Validation loss: 2.023081725643527

Epoch: 6| Step: 10
Training loss: 0.9659600853919983
Validation loss: 2.0090999000815937

Epoch: 6| Step: 11
Training loss: 2.0515031814575195
Validation loss: 2.00216349991419

Epoch: 6| Step: 12
Training loss: 0.9763956069946289
Validation loss: 1.9832094395032493

Epoch: 6| Step: 13
Training loss: 0.8912385106086731
Validation loss: 2.026149224209529

Epoch: 755| Step: 0
Training loss: 1.4467105865478516
Validation loss: 1.9897192960144372

Epoch: 6| Step: 1
Training loss: 1.194573163986206
Validation loss: 2.029832882265891

Epoch: 6| Step: 2
Training loss: 1.202696442604065
Validation loss: 2.007071097691854

Epoch: 6| Step: 3
Training loss: 0.6975198984146118
Validation loss: 1.9997005949738205

Epoch: 6| Step: 4
Training loss: 0.925979495048523
Validation loss: 2.0135809862485496

Epoch: 6| Step: 5
Training loss: 0.7241692543029785
Validation loss: 2.0048879038903022

Epoch: 6| Step: 6
Training loss: 0.6065129041671753
Validation loss: 2.0024360738774782

Epoch: 6| Step: 7
Training loss: 0.9615455865859985
Validation loss: 1.9756161551321707

Epoch: 6| Step: 8
Training loss: 1.631596565246582
Validation loss: 2.0120860915030203

Epoch: 6| Step: 9
Training loss: 0.9766175746917725
Validation loss: 1.979315912210813

Epoch: 6| Step: 10
Training loss: 1.0406495332717896
Validation loss: 2.043668916148524

Epoch: 6| Step: 11
Training loss: 0.5818684101104736
Validation loss: 1.9630808407260525

Epoch: 6| Step: 12
Training loss: 0.9431618452072144
Validation loss: 2.0093588700858493

Epoch: 6| Step: 13
Training loss: 1.3451664447784424
Validation loss: 1.9921295412125126

Epoch: 756| Step: 0
Training loss: 0.477502703666687
Validation loss: 1.9984629974570325

Epoch: 6| Step: 1
Training loss: 1.1806632280349731
Validation loss: 1.9849046314916303

Epoch: 6| Step: 2
Training loss: 1.1018650531768799
Validation loss: 1.999432397145097

Epoch: 6| Step: 3
Training loss: 0.9691672325134277
Validation loss: 1.9719849581359534

Epoch: 6| Step: 4
Training loss: 0.6481265425682068
Validation loss: 1.9880781647979573

Epoch: 6| Step: 5
Training loss: 1.2496743202209473
Validation loss: 1.96265152705613

Epoch: 6| Step: 6
Training loss: 0.9363767504692078
Validation loss: 2.018255046618882

Epoch: 6| Step: 7
Training loss: 0.7385425567626953
Validation loss: 2.0076946391854236

Epoch: 6| Step: 8
Training loss: 1.173830509185791
Validation loss: 2.000774009253389

Epoch: 6| Step: 9
Training loss: 1.3408846855163574
Validation loss: 1.9734031384991062

Epoch: 6| Step: 10
Training loss: 1.4538211822509766
Validation loss: 1.9916928301575363

Epoch: 6| Step: 11
Training loss: 0.7758179306983948
Validation loss: 1.9824554715105283

Epoch: 6| Step: 12
Training loss: 1.031720519065857
Validation loss: 1.9899891486731909

Epoch: 6| Step: 13
Training loss: 1.0522209405899048
Validation loss: 2.0019788870247464

Epoch: 757| Step: 0
Training loss: 0.9506632685661316
Validation loss: 1.9368958960297287

Epoch: 6| Step: 1
Training loss: 1.2392590045928955
Validation loss: 1.9631585280100505

Epoch: 6| Step: 2
Training loss: 0.9390252828598022
Validation loss: 1.9391136989798596

Epoch: 6| Step: 3
Training loss: 0.8665339946746826
Validation loss: 1.961266069002049

Epoch: 6| Step: 4
Training loss: 1.4210771322250366
Validation loss: 1.9759235971717424

Epoch: 6| Step: 5
Training loss: 0.7796159982681274
Validation loss: 2.050476936883824

Epoch: 6| Step: 6
Training loss: 0.8741958141326904
Validation loss: 1.972428257747363

Epoch: 6| Step: 7
Training loss: 0.7220426797866821
Validation loss: 1.9829575451471473

Epoch: 6| Step: 8
Training loss: 1.187622308731079
Validation loss: 1.9762056014871086

Epoch: 6| Step: 9
Training loss: 1.2143539190292358
Validation loss: 1.9850150205755746

Epoch: 6| Step: 10
Training loss: 1.1168899536132812
Validation loss: 2.0091628272046327

Epoch: 6| Step: 11
Training loss: 1.0282549858093262
Validation loss: 2.0242390337810723

Epoch: 6| Step: 12
Training loss: 0.49656766653060913
Validation loss: 1.9765443648061445

Epoch: 6| Step: 13
Training loss: 1.4983713626861572
Validation loss: 1.9837979321838708

Epoch: 758| Step: 0
Training loss: 1.4252586364746094
Validation loss: 2.041038099155631

Epoch: 6| Step: 1
Training loss: 0.9996953010559082
Validation loss: 1.9821709150909095

Epoch: 6| Step: 2
Training loss: 0.9678372144699097
Validation loss: 1.9610362232372325

Epoch: 6| Step: 3
Training loss: 1.456535816192627
Validation loss: 2.0115146303689606

Epoch: 6| Step: 4
Training loss: 0.9985324740409851
Validation loss: 2.012673208790441

Epoch: 6| Step: 5
Training loss: 1.213817834854126
Validation loss: 1.9883450256880892

Epoch: 6| Step: 6
Training loss: 0.6491167545318604
Validation loss: 1.983966318509912

Epoch: 6| Step: 7
Training loss: 1.1631580591201782
Validation loss: 1.9546567586160475

Epoch: 6| Step: 8
Training loss: 0.6549646854400635
Validation loss: 1.993434109995442

Epoch: 6| Step: 9
Training loss: 0.7709592580795288
Validation loss: 1.992896588899756

Epoch: 6| Step: 10
Training loss: 0.8641949892044067
Validation loss: 1.9801643920201126

Epoch: 6| Step: 11
Training loss: 1.2835016250610352
Validation loss: 1.986870995131872

Epoch: 6| Step: 12
Training loss: 0.9547157287597656
Validation loss: 1.9820688257935226

Epoch: 6| Step: 13
Training loss: 0.9458500742912292
Validation loss: 1.9722141168450797

Epoch: 759| Step: 0
Training loss: 1.2673043012619019
Validation loss: 2.0127564502018753

Epoch: 6| Step: 1
Training loss: 1.1342401504516602
Validation loss: 1.9740843824160996

Epoch: 6| Step: 2
Training loss: 1.1126353740692139
Validation loss: 2.052115232713761

Epoch: 6| Step: 3
Training loss: 0.5346113443374634
Validation loss: 1.9960339902549662

Epoch: 6| Step: 4
Training loss: 1.3077311515808105
Validation loss: 1.995668649673462

Epoch: 6| Step: 5
Training loss: 0.5729601383209229
Validation loss: 2.00073028379871

Epoch: 6| Step: 6
Training loss: 1.5884284973144531
Validation loss: 2.0096355958651473

Epoch: 6| Step: 7
Training loss: 0.9600616693496704
Validation loss: 1.9851280643093971

Epoch: 6| Step: 8
Training loss: 1.032529354095459
Validation loss: 2.0009132123762563

Epoch: 6| Step: 9
Training loss: 0.8565871715545654
Validation loss: 2.039530602834558

Epoch: 6| Step: 10
Training loss: 0.74663907289505
Validation loss: 2.004743459404156

Epoch: 6| Step: 11
Training loss: 1.302473545074463
Validation loss: 2.0155917893173876

Epoch: 6| Step: 12
Training loss: 0.7668735384941101
Validation loss: 2.042443044724003

Epoch: 6| Step: 13
Training loss: 0.7216074466705322
Validation loss: 2.050382238562389

Epoch: 760| Step: 0
Training loss: 0.9605269432067871
Validation loss: 2.0251074324371996

Epoch: 6| Step: 1
Training loss: 0.8697416186332703
Validation loss: 2.002821204482868

Epoch: 6| Step: 2
Training loss: 1.4255449771881104
Validation loss: 2.031494514916533

Epoch: 6| Step: 3
Training loss: 1.0041437149047852
Validation loss: 2.0085076337219565

Epoch: 6| Step: 4
Training loss: 0.5851504802703857
Validation loss: 2.0303047882613314

Epoch: 6| Step: 5
Training loss: 1.1996817588806152
Validation loss: 2.0102442643975698

Epoch: 6| Step: 6
Training loss: 1.1966360807418823
Validation loss: 1.9924223474276963

Epoch: 6| Step: 7
Training loss: 0.8208400011062622
Validation loss: 1.9614830209362892

Epoch: 6| Step: 8
Training loss: 1.3375405073165894
Validation loss: 1.9712770062108194

Epoch: 6| Step: 9
Training loss: 0.9034274816513062
Validation loss: 1.9977007258322932

Epoch: 6| Step: 10
Training loss: 1.1794888973236084
Validation loss: 1.9610075437894432

Epoch: 6| Step: 11
Training loss: 0.9120092391967773
Validation loss: 1.963726028319328

Epoch: 6| Step: 12
Training loss: 1.0601011514663696
Validation loss: 1.9745021071485294

Epoch: 6| Step: 13
Training loss: 1.3176904916763306
Validation loss: 1.974024890571512

Epoch: 761| Step: 0
Training loss: 1.0255478620529175
Validation loss: 1.9917873208240797

Epoch: 6| Step: 1
Training loss: 0.9168310761451721
Validation loss: 1.9828552071766188

Epoch: 6| Step: 2
Training loss: 1.2507989406585693
Validation loss: 2.0280020877879155

Epoch: 6| Step: 3
Training loss: 0.42211592197418213
Validation loss: 2.0071641206741333

Epoch: 6| Step: 4
Training loss: 1.2039618492126465
Validation loss: 2.0120756049310007

Epoch: 6| Step: 5
Training loss: 1.1845566034317017
Validation loss: 2.0387582548203005

Epoch: 6| Step: 6
Training loss: 1.0538547039031982
Validation loss: 2.0129886545160764

Epoch: 6| Step: 7
Training loss: 1.4265451431274414
Validation loss: 1.98872406764697

Epoch: 6| Step: 8
Training loss: 0.6067742109298706
Validation loss: 2.0113089315352903

Epoch: 6| Step: 9
Training loss: 1.1317143440246582
Validation loss: 1.9691805711356543

Epoch: 6| Step: 10
Training loss: 1.0965027809143066
Validation loss: 1.9965116721327587

Epoch: 6| Step: 11
Training loss: 0.7571504712104797
Validation loss: 1.9572280658188688

Epoch: 6| Step: 12
Training loss: 1.3288211822509766
Validation loss: 1.9793552813991424

Epoch: 6| Step: 13
Training loss: 0.8353497385978699
Validation loss: 1.9743269105111398

Epoch: 762| Step: 0
Training loss: 0.8022340536117554
Validation loss: 2.001975215891356

Epoch: 6| Step: 1
Training loss: 1.2785754203796387
Validation loss: 2.046480562097283

Epoch: 6| Step: 2
Training loss: 1.310861349105835
Validation loss: 2.023984529638803

Epoch: 6| Step: 3
Training loss: 1.3251574039459229
Validation loss: 1.9897055446460683

Epoch: 6| Step: 4
Training loss: 0.9384382963180542
Validation loss: 2.0237665907029183

Epoch: 6| Step: 5
Training loss: 1.2479791641235352
Validation loss: 1.9599544643073954

Epoch: 6| Step: 6
Training loss: 0.9059008359909058
Validation loss: 1.975062580518825

Epoch: 6| Step: 7
Training loss: 0.9162469506263733
Validation loss: 2.001569401833319

Epoch: 6| Step: 8
Training loss: 1.0062836408615112
Validation loss: 2.001586365443404

Epoch: 6| Step: 9
Training loss: 0.8622999787330627
Validation loss: 1.9670125105047738

Epoch: 6| Step: 10
Training loss: 0.6955285668373108
Validation loss: 1.9901884986508278

Epoch: 6| Step: 11
Training loss: 1.3297290802001953
Validation loss: 1.9586322820314797

Epoch: 6| Step: 12
Training loss: 0.604434609413147
Validation loss: 1.9740688672629736

Epoch: 6| Step: 13
Training loss: 1.0221226215362549
Validation loss: 2.009802797789215

Epoch: 763| Step: 0
Training loss: 0.8862777948379517
Validation loss: 1.942142737809048

Epoch: 6| Step: 1
Training loss: 0.8800780773162842
Validation loss: 2.015736977259318

Epoch: 6| Step: 2
Training loss: 1.0086370706558228
Validation loss: 1.9674589275031962

Epoch: 6| Step: 3
Training loss: 1.1511350870132446
Validation loss: 2.0270387203462663

Epoch: 6| Step: 4
Training loss: 0.9556100368499756
Validation loss: 1.9907727779880646

Epoch: 6| Step: 5
Training loss: 0.7013891935348511
Validation loss: 2.010386695143997

Epoch: 6| Step: 6
Training loss: 1.0650392770767212
Validation loss: 2.0322643031356153

Epoch: 6| Step: 7
Training loss: 1.1415438652038574
Validation loss: 2.002097982232289

Epoch: 6| Step: 8
Training loss: 1.2662382125854492
Validation loss: 1.9867992965123986

Epoch: 6| Step: 9
Training loss: 0.6733889579772949
Validation loss: 1.955955381034523

Epoch: 6| Step: 10
Training loss: 0.5398069024085999
Validation loss: 2.0278934560796267

Epoch: 6| Step: 11
Training loss: 1.3126637935638428
Validation loss: 1.9708617015551495

Epoch: 6| Step: 12
Training loss: 1.5977184772491455
Validation loss: 1.9921419953787198

Epoch: 6| Step: 13
Training loss: 1.1201300621032715
Validation loss: 1.9777939165792158

Epoch: 764| Step: 0
Training loss: 0.6371170878410339
Validation loss: 2.0127055439897763

Epoch: 6| Step: 1
Training loss: 0.8611962795257568
Validation loss: 1.9826881641982703

Epoch: 6| Step: 2
Training loss: 0.6404597759246826
Validation loss: 2.0332463582356772

Epoch: 6| Step: 3
Training loss: 1.1566513776779175
Validation loss: 2.0116287764682563

Epoch: 6| Step: 4
Training loss: 1.0247564315795898
Validation loss: 1.989967853792252

Epoch: 6| Step: 5
Training loss: 1.0019872188568115
Validation loss: 2.0187152329311577

Epoch: 6| Step: 6
Training loss: 0.8550179600715637
Validation loss: 1.9820575380838046

Epoch: 6| Step: 7
Training loss: 1.2659586668014526
Validation loss: 1.9613592547755088

Epoch: 6| Step: 8
Training loss: 1.399841547012329
Validation loss: 1.978587656892756

Epoch: 6| Step: 9
Training loss: 0.996175229549408
Validation loss: 1.9868479723571448

Epoch: 6| Step: 10
Training loss: 1.2609699964523315
Validation loss: 1.9869844246936101

Epoch: 6| Step: 11
Training loss: 0.7380130290985107
Validation loss: 1.9753903394104333

Epoch: 6| Step: 12
Training loss: 0.7061023116111755
Validation loss: 1.9807277417952014

Epoch: 6| Step: 13
Training loss: 1.639829397201538
Validation loss: 1.9978989067898

Epoch: 765| Step: 0
Training loss: 1.527341365814209
Validation loss: 1.9759613531892017

Epoch: 6| Step: 1
Training loss: 0.8353148698806763
Validation loss: 1.9669120811646985

Epoch: 6| Step: 2
Training loss: 0.7853789329528809
Validation loss: 2.0039528159685034

Epoch: 6| Step: 3
Training loss: 0.5995253920555115
Validation loss: 1.9833477389427923

Epoch: 6| Step: 4
Training loss: 1.4423068761825562
Validation loss: 1.9890270899700861

Epoch: 6| Step: 5
Training loss: 0.9768149852752686
Validation loss: 2.037883279144123

Epoch: 6| Step: 6
Training loss: 1.063843011856079
Validation loss: 1.9953806425935479

Epoch: 6| Step: 7
Training loss: 0.568940281867981
Validation loss: 2.0287932426698747

Epoch: 6| Step: 8
Training loss: 1.6600315570831299
Validation loss: 1.9688247378154466

Epoch: 6| Step: 9
Training loss: 0.607804000377655
Validation loss: 1.987217987737348

Epoch: 6| Step: 10
Training loss: 1.1066203117370605
Validation loss: 1.9667711488662227

Epoch: 6| Step: 11
Training loss: 0.4013056755065918
Validation loss: 1.9961183237773117

Epoch: 6| Step: 12
Training loss: 1.097733497619629
Validation loss: 2.0077647111749135

Epoch: 6| Step: 13
Training loss: 1.253716230392456
Validation loss: 1.9655619744331605

Epoch: 766| Step: 0
Training loss: 0.8949058055877686
Validation loss: 1.969134303831285

Epoch: 6| Step: 1
Training loss: 0.8062976598739624
Validation loss: 2.0155534539171445

Epoch: 6| Step: 2
Training loss: 0.6980555653572083
Validation loss: 2.0137989418480986

Epoch: 6| Step: 3
Training loss: 0.7791767120361328
Validation loss: 1.9377108735422934

Epoch: 6| Step: 4
Training loss: 0.8257557153701782
Validation loss: 2.0132414948555732

Epoch: 6| Step: 5
Training loss: 0.8457800149917603
Validation loss: 2.046108700895822

Epoch: 6| Step: 6
Training loss: 1.7419342994689941
Validation loss: 1.996660432507915

Epoch: 6| Step: 7
Training loss: 0.5580155849456787
Validation loss: 1.9982072230308288

Epoch: 6| Step: 8
Training loss: 1.3695120811462402
Validation loss: 1.9959794193185785

Epoch: 6| Step: 9
Training loss: 1.0963425636291504
Validation loss: 1.9838782894995906

Epoch: 6| Step: 10
Training loss: 0.8842133283615112
Validation loss: 1.9896574302386212

Epoch: 6| Step: 11
Training loss: 1.0042201280593872
Validation loss: 1.981153880396197

Epoch: 6| Step: 12
Training loss: 1.341281533241272
Validation loss: 1.977404047084111

Epoch: 6| Step: 13
Training loss: 1.0410228967666626
Validation loss: 1.9629673188732517

Epoch: 767| Step: 0
Training loss: 1.1721649169921875
Validation loss: 1.9876834013128792

Epoch: 6| Step: 1
Training loss: 0.7377831935882568
Validation loss: 1.967300183029585

Epoch: 6| Step: 2
Training loss: 1.3697853088378906
Validation loss: 2.0102344071993263

Epoch: 6| Step: 3
Training loss: 1.5014499425888062
Validation loss: 1.9907590163651334

Epoch: 6| Step: 4
Training loss: 1.3381195068359375
Validation loss: 1.981854208054081

Epoch: 6| Step: 5
Training loss: 0.7537723779678345
Validation loss: 2.006578335198023

Epoch: 6| Step: 6
Training loss: 0.8650658130645752
Validation loss: 2.0302511081900647

Epoch: 6| Step: 7
Training loss: 0.8905379772186279
Validation loss: 2.0499811992850354

Epoch: 6| Step: 8
Training loss: 1.3284788131713867
Validation loss: 2.0449222518551733

Epoch: 6| Step: 9
Training loss: 1.2294797897338867
Validation loss: 2.0597869785883094

Epoch: 6| Step: 10
Training loss: 0.9127985239028931
Validation loss: 2.025550700003101

Epoch: 6| Step: 11
Training loss: 0.7994697690010071
Validation loss: 1.9841177155894618

Epoch: 6| Step: 12
Training loss: 0.8294196724891663
Validation loss: 1.9871146063650809

Epoch: 6| Step: 13
Training loss: 0.3835963010787964
Validation loss: 1.9947448315158967

Epoch: 768| Step: 0
Training loss: 1.1578714847564697
Validation loss: 1.9389551916430074

Epoch: 6| Step: 1
Training loss: 1.1659430265426636
Validation loss: 1.9725896363617272

Epoch: 6| Step: 2
Training loss: 0.904390811920166
Validation loss: 1.9933872069081953

Epoch: 6| Step: 3
Training loss: 0.9264693260192871
Validation loss: 1.9457707687090802

Epoch: 6| Step: 4
Training loss: 1.4859334230422974
Validation loss: 1.9836415962506366

Epoch: 6| Step: 5
Training loss: 0.922347903251648
Validation loss: 1.9792135953903198

Epoch: 6| Step: 6
Training loss: 0.7165859341621399
Validation loss: 1.9548598848363405

Epoch: 6| Step: 7
Training loss: 0.972663402557373
Validation loss: 1.9753781108446018

Epoch: 6| Step: 8
Training loss: 0.895408034324646
Validation loss: 1.9616013585880239

Epoch: 6| Step: 9
Training loss: 0.8368180990219116
Validation loss: 1.9628640297920472

Epoch: 6| Step: 10
Training loss: 0.6673374772071838
Validation loss: 1.9503479016724454

Epoch: 6| Step: 11
Training loss: 0.9137592911720276
Validation loss: 1.9620779688640306

Epoch: 6| Step: 12
Training loss: 0.9910320043563843
Validation loss: 1.97992951895601

Epoch: 6| Step: 13
Training loss: 1.583076000213623
Validation loss: 1.963198237521674

Epoch: 769| Step: 0
Training loss: 0.7978315353393555
Validation loss: 1.9554504066385248

Epoch: 6| Step: 1
Training loss: 0.7842727899551392
Validation loss: 1.976952947596068

Epoch: 6| Step: 2
Training loss: 1.0581226348876953
Validation loss: 1.9925392789225425

Epoch: 6| Step: 3
Training loss: 0.5034567713737488
Validation loss: 2.003564234702818

Epoch: 6| Step: 4
Training loss: 1.2156639099121094
Validation loss: 1.9765251913378317

Epoch: 6| Step: 5
Training loss: 1.2090766429901123
Validation loss: 1.9856513174631263

Epoch: 6| Step: 6
Training loss: 1.1519196033477783
Validation loss: 2.0030508220836682

Epoch: 6| Step: 7
Training loss: 0.9745382070541382
Validation loss: 2.046970340513414

Epoch: 6| Step: 8
Training loss: 1.3444020748138428
Validation loss: 1.9491583378084245

Epoch: 6| Step: 9
Training loss: 1.2881914377212524
Validation loss: 2.0236143912038496

Epoch: 6| Step: 10
Training loss: 0.9102944731712341
Validation loss: 1.9684979146526707

Epoch: 6| Step: 11
Training loss: 1.4116833209991455
Validation loss: 1.9684193954672864

Epoch: 6| Step: 12
Training loss: 0.7843787670135498
Validation loss: 1.968615730603536

Epoch: 6| Step: 13
Training loss: 0.653451681137085
Validation loss: 2.004256909893405

Epoch: 770| Step: 0
Training loss: 1.0044254064559937
Validation loss: 1.9926213974593787

Epoch: 6| Step: 1
Training loss: 0.7301961183547974
Validation loss: 1.9882078529686056

Epoch: 6| Step: 2
Training loss: 1.2991323471069336
Validation loss: 1.9959753726118354

Epoch: 6| Step: 3
Training loss: 1.3253151178359985
Validation loss: 2.004089045909143

Epoch: 6| Step: 4
Training loss: 1.1239995956420898
Validation loss: 1.9628539854480374

Epoch: 6| Step: 5
Training loss: 1.2030611038208008
Validation loss: 1.9735376911778604

Epoch: 6| Step: 6
Training loss: 0.5119888782501221
Validation loss: 2.0131014675222416

Epoch: 6| Step: 7
Training loss: 0.704740047454834
Validation loss: 1.9987264217868927

Epoch: 6| Step: 8
Training loss: 1.5493383407592773
Validation loss: 1.9790798848675144

Epoch: 6| Step: 9
Training loss: 0.8109266757965088
Validation loss: 2.0300264255974882

Epoch: 6| Step: 10
Training loss: 1.4043965339660645
Validation loss: 1.9927002153088968

Epoch: 6| Step: 11
Training loss: 0.7872503995895386
Validation loss: 1.9410386623874787

Epoch: 6| Step: 12
Training loss: 0.4073113799095154
Validation loss: 1.966386769407539

Epoch: 6| Step: 13
Training loss: 1.2298407554626465
Validation loss: 1.9634241955254668

Epoch: 771| Step: 0
Training loss: 1.0589983463287354
Validation loss: 1.928121910300306

Epoch: 6| Step: 1
Training loss: 1.271385669708252
Validation loss: 1.9860195190675798

Epoch: 6| Step: 2
Training loss: 0.851643443107605
Validation loss: 1.9619417716098089

Epoch: 6| Step: 3
Training loss: 1.3445128202438354
Validation loss: 1.9523975144150436

Epoch: 6| Step: 4
Training loss: 0.7899660468101501
Validation loss: 1.9535074580100276

Epoch: 6| Step: 5
Training loss: 1.460028886795044
Validation loss: 1.9820266897960375

Epoch: 6| Step: 6
Training loss: 0.8540163040161133
Validation loss: 1.9562475976123606

Epoch: 6| Step: 7
Training loss: 0.6090580224990845
Validation loss: 1.9643044523013535

Epoch: 6| Step: 8
Training loss: 1.1759706735610962
Validation loss: 1.9748216598264632

Epoch: 6| Step: 9
Training loss: 1.1847505569458008
Validation loss: 1.9684277849812661

Epoch: 6| Step: 10
Training loss: 0.7843028903007507
Validation loss: 1.9636456927945536

Epoch: 6| Step: 11
Training loss: 0.8542471528053284
Validation loss: 2.0237667637486614

Epoch: 6| Step: 12
Training loss: 0.8282188773155212
Validation loss: 1.9797261209898098

Epoch: 6| Step: 13
Training loss: 0.7563201785087585
Validation loss: 2.0051508565102854

Epoch: 772| Step: 0
Training loss: 1.0672473907470703
Validation loss: 1.9967630729880383

Epoch: 6| Step: 1
Training loss: 1.1425814628601074
Validation loss: 1.997791072373749

Epoch: 6| Step: 2
Training loss: 0.7583863139152527
Validation loss: 1.961221702637211

Epoch: 6| Step: 3
Training loss: 0.8893938064575195
Validation loss: 1.9730405140948553

Epoch: 6| Step: 4
Training loss: 1.0894333124160767
Validation loss: 1.949573524536625

Epoch: 6| Step: 5
Training loss: 1.0133843421936035
Validation loss: 2.0034170881394417

Epoch: 6| Step: 6
Training loss: 1.3791258335113525
Validation loss: 1.9369743972696283

Epoch: 6| Step: 7
Training loss: 0.8189998865127563
Validation loss: 2.001021054483229

Epoch: 6| Step: 8
Training loss: 0.8803887963294983
Validation loss: 1.9463731217127975

Epoch: 6| Step: 9
Training loss: 1.0063846111297607
Validation loss: 1.9809218734823248

Epoch: 6| Step: 10
Training loss: 0.8107047080993652
Validation loss: 1.9411821737084338

Epoch: 6| Step: 11
Training loss: 1.6364343166351318
Validation loss: 1.9632284307992587

Epoch: 6| Step: 12
Training loss: 0.9324749112129211
Validation loss: 1.9738014654446674

Epoch: 6| Step: 13
Training loss: 0.574340283870697
Validation loss: 2.0050115328963085

Epoch: 773| Step: 0
Training loss: 0.668419599533081
Validation loss: 1.9797190876417263

Epoch: 6| Step: 1
Training loss: 0.8652975559234619
Validation loss: 1.993753728046212

Epoch: 6| Step: 2
Training loss: 0.977329671382904
Validation loss: 1.946829770200996

Epoch: 6| Step: 3
Training loss: 0.6963644027709961
Validation loss: 1.9828073106786257

Epoch: 6| Step: 4
Training loss: 0.7445276975631714
Validation loss: 2.0037967722903014

Epoch: 6| Step: 5
Training loss: 0.7427654266357422
Validation loss: 2.0037788806423062

Epoch: 6| Step: 6
Training loss: 0.9885776042938232
Validation loss: 1.969711765166252

Epoch: 6| Step: 7
Training loss: 0.6010150909423828
Validation loss: 1.9983674556978288

Epoch: 6| Step: 8
Training loss: 1.6463483572006226
Validation loss: 2.0077578534362135

Epoch: 6| Step: 9
Training loss: 1.0376687049865723
Validation loss: 1.9732723312993203

Epoch: 6| Step: 10
Training loss: 1.3460172414779663
Validation loss: 1.995316022185869

Epoch: 6| Step: 11
Training loss: 0.5842406153678894
Validation loss: 1.983820302512056

Epoch: 6| Step: 12
Training loss: 1.860985517501831
Validation loss: 2.0332861203019337

Epoch: 6| Step: 13
Training loss: 0.6522755026817322
Validation loss: 1.9790784902470087

Epoch: 774| Step: 0
Training loss: 1.0496962070465088
Validation loss: 1.9372009949017597

Epoch: 6| Step: 1
Training loss: 1.4422674179077148
Validation loss: 2.0085627096955494

Epoch: 6| Step: 2
Training loss: 0.9066501259803772
Validation loss: 1.9775663422000023

Epoch: 6| Step: 3
Training loss: 0.8282473087310791
Validation loss: 1.9794031625152917

Epoch: 6| Step: 4
Training loss: 1.135250210762024
Validation loss: 1.9870945266498032

Epoch: 6| Step: 5
Training loss: 0.9903079271316528
Validation loss: 1.9798997858519196

Epoch: 6| Step: 6
Training loss: 0.9375083446502686
Validation loss: 2.002253194009104

Epoch: 6| Step: 7
Training loss: 0.8321776390075684
Validation loss: 1.9643235744968537

Epoch: 6| Step: 8
Training loss: 1.0908246040344238
Validation loss: 2.0441315789376535

Epoch: 6| Step: 9
Training loss: 0.9065401554107666
Validation loss: 1.9894405898227487

Epoch: 6| Step: 10
Training loss: 0.6046050190925598
Validation loss: 2.0535808788832797

Epoch: 6| Step: 11
Training loss: 0.9037144184112549
Validation loss: 2.0058303891971545

Epoch: 6| Step: 12
Training loss: 1.242264986038208
Validation loss: 1.982359915651301

Epoch: 6| Step: 13
Training loss: 0.8538337349891663
Validation loss: 2.016840796316824

Epoch: 775| Step: 0
Training loss: 0.9570227265357971
Validation loss: 2.021569836524225

Epoch: 6| Step: 1
Training loss: 0.7615062594413757
Validation loss: 1.997031904035999

Epoch: 6| Step: 2
Training loss: 1.3324370384216309
Validation loss: 1.9850718398247995

Epoch: 6| Step: 3
Training loss: 0.6857050657272339
Validation loss: 1.9904772004773539

Epoch: 6| Step: 4
Training loss: 0.8411606550216675
Validation loss: 2.0032055865051928

Epoch: 6| Step: 5
Training loss: 0.8945682644844055
Validation loss: 1.9748732402760496

Epoch: 6| Step: 6
Training loss: 1.1736159324645996
Validation loss: 1.9777247046911588

Epoch: 6| Step: 7
Training loss: 1.5382016897201538
Validation loss: 1.9909757247535131

Epoch: 6| Step: 8
Training loss: 0.6669367551803589
Validation loss: 1.96245244626076

Epoch: 6| Step: 9
Training loss: 1.503906011581421
Validation loss: 1.9647304883567236

Epoch: 6| Step: 10
Training loss: 0.6991721391677856
Validation loss: 2.012656593835482

Epoch: 6| Step: 11
Training loss: 0.7907193303108215
Validation loss: 1.986898878569244

Epoch: 6| Step: 12
Training loss: 0.946143627166748
Validation loss: 1.971604771511529

Epoch: 6| Step: 13
Training loss: 1.0626351833343506
Validation loss: 1.958236123925896

Epoch: 776| Step: 0
Training loss: 0.4807026982307434
Validation loss: 2.0044974793669996

Epoch: 6| Step: 1
Training loss: 1.1283111572265625
Validation loss: 2.005304096847452

Epoch: 6| Step: 2
Training loss: 1.0909874439239502
Validation loss: 1.9873640742353214

Epoch: 6| Step: 3
Training loss: 0.6002774834632874
Validation loss: 1.993875342030679

Epoch: 6| Step: 4
Training loss: 0.6988518238067627
Validation loss: 1.9637426586561306

Epoch: 6| Step: 5
Training loss: 0.9913320541381836
Validation loss: 1.9960478364780385

Epoch: 6| Step: 6
Training loss: 1.3739873170852661
Validation loss: 1.960035554824337

Epoch: 6| Step: 7
Training loss: 0.7028902769088745
Validation loss: 2.0360027808015064

Epoch: 6| Step: 8
Training loss: 1.1559311151504517
Validation loss: 2.0185695220065374

Epoch: 6| Step: 9
Training loss: 0.8157254457473755
Validation loss: 2.021416511586917

Epoch: 6| Step: 10
Training loss: 1.3470609188079834
Validation loss: 2.004251668530126

Epoch: 6| Step: 11
Training loss: 1.7575148344039917
Validation loss: 2.005686319002541

Epoch: 6| Step: 12
Training loss: 1.0501694679260254
Validation loss: 1.976341765414002

Epoch: 6| Step: 13
Training loss: 0.9244213104248047
Validation loss: 2.000489821998022

Epoch: 777| Step: 0
Training loss: 0.9424153566360474
Validation loss: 1.9879290121857838

Epoch: 6| Step: 1
Training loss: 1.127868413925171
Validation loss: 2.0017711295876452

Epoch: 6| Step: 2
Training loss: 0.5340911149978638
Validation loss: 2.0145260595506236

Epoch: 6| Step: 3
Training loss: 0.6275972723960876
Validation loss: 1.9602323834614088

Epoch: 6| Step: 4
Training loss: 1.4541243314743042
Validation loss: 2.017888352435122

Epoch: 6| Step: 5
Training loss: 1.4784488677978516
Validation loss: 1.9626697340319235

Epoch: 6| Step: 6
Training loss: 0.5946770906448364
Validation loss: 1.993454974184754

Epoch: 6| Step: 7
Training loss: 1.7779392004013062
Validation loss: 1.9662655809874177

Epoch: 6| Step: 8
Training loss: 0.5391011238098145
Validation loss: 1.9953254243378997

Epoch: 6| Step: 9
Training loss: 1.1844456195831299
Validation loss: 1.9804648378843903

Epoch: 6| Step: 10
Training loss: 1.0286868810653687
Validation loss: 1.9934259512091195

Epoch: 6| Step: 11
Training loss: 0.9167629480361938
Validation loss: 1.9992350865435857

Epoch: 6| Step: 12
Training loss: 0.5961660146713257
Validation loss: 2.0398480776817567

Epoch: 6| Step: 13
Training loss: 0.8095957636833191
Validation loss: 1.9933210393433929

Epoch: 778| Step: 0
Training loss: 1.0449048280715942
Validation loss: 1.9862832728252615

Epoch: 6| Step: 1
Training loss: 0.6029406785964966
Validation loss: 1.9765062383426133

Epoch: 6| Step: 2
Training loss: 1.0250883102416992
Validation loss: 1.959695876285594

Epoch: 6| Step: 3
Training loss: 0.9027427434921265
Validation loss: 1.9701853349644651

Epoch: 6| Step: 4
Training loss: 1.1788320541381836
Validation loss: 1.9684060837632866

Epoch: 6| Step: 5
Training loss: 1.2008936405181885
Validation loss: 1.9803684949874878

Epoch: 6| Step: 6
Training loss: 0.9607568979263306
Validation loss: 2.009549617767334

Epoch: 6| Step: 7
Training loss: 0.9920878410339355
Validation loss: 1.9758250508257138

Epoch: 6| Step: 8
Training loss: 1.2533562183380127
Validation loss: 1.9875213907610985

Epoch: 6| Step: 9
Training loss: 0.9615162014961243
Validation loss: 2.001721805141818

Epoch: 6| Step: 10
Training loss: 1.0766620635986328
Validation loss: 1.956896178184017

Epoch: 6| Step: 11
Training loss: 1.0753203630447388
Validation loss: 1.9408374281339749

Epoch: 6| Step: 12
Training loss: 0.5477038621902466
Validation loss: 1.990970637208672

Epoch: 6| Step: 13
Training loss: 1.3351409435272217
Validation loss: 1.9637837897064865

Epoch: 779| Step: 0
Training loss: 1.2629327774047852
Validation loss: 2.029866991504546

Epoch: 6| Step: 1
Training loss: 0.8226805925369263
Validation loss: 1.9544162109333982

Epoch: 6| Step: 2
Training loss: 1.303228497505188
Validation loss: 2.0190619345634215

Epoch: 6| Step: 3
Training loss: 0.8348214626312256
Validation loss: 1.9383966486941102

Epoch: 6| Step: 4
Training loss: 1.0295690298080444
Validation loss: 2.009356032135666

Epoch: 6| Step: 5
Training loss: 1.4477459192276
Validation loss: 1.994382086620536

Epoch: 6| Step: 6
Training loss: 1.0057086944580078
Validation loss: 1.966734517005182

Epoch: 6| Step: 7
Training loss: 0.4930376708507538
Validation loss: 1.9904922362296813

Epoch: 6| Step: 8
Training loss: 0.8711841106414795
Validation loss: 2.018752912039398

Epoch: 6| Step: 9
Training loss: 0.8656938076019287
Validation loss: 2.005908130317606

Epoch: 6| Step: 10
Training loss: 1.0964487791061401
Validation loss: 1.9878848496303763

Epoch: 6| Step: 11
Training loss: 0.9833191633224487
Validation loss: 2.0274083998895462

Epoch: 6| Step: 12
Training loss: 1.1803486347198486
Validation loss: 1.9987391848717966

Epoch: 6| Step: 13
Training loss: 0.4203530550003052
Validation loss: 2.0168886146237774

Epoch: 780| Step: 0
Training loss: 1.2432091236114502
Validation loss: 2.0496076960717478

Epoch: 6| Step: 1
Training loss: 1.27956223487854
Validation loss: 2.028818025383898

Epoch: 6| Step: 2
Training loss: 0.7630013227462769
Validation loss: 2.031825122012887

Epoch: 6| Step: 3
Training loss: 0.8345786929130554
Validation loss: 1.9949738043610767

Epoch: 6| Step: 4
Training loss: 1.4940006732940674
Validation loss: 1.9734676448247765

Epoch: 6| Step: 5
Training loss: 0.6543469429016113
Validation loss: 2.0042666145550307

Epoch: 6| Step: 6
Training loss: 0.656952977180481
Validation loss: 2.00961309607311

Epoch: 6| Step: 7
Training loss: 1.0816363096237183
Validation loss: 1.972564507556218

Epoch: 6| Step: 8
Training loss: 0.7656009197235107
Validation loss: 2.0011363414026078

Epoch: 6| Step: 9
Training loss: 0.7819716930389404
Validation loss: 1.9949581956350675

Epoch: 6| Step: 10
Training loss: 0.8414210081100464
Validation loss: 1.975679902620213

Epoch: 6| Step: 11
Training loss: 1.1761608123779297
Validation loss: 1.9623870695790937

Epoch: 6| Step: 12
Training loss: 1.4526735544204712
Validation loss: 1.99216204561213

Epoch: 6| Step: 13
Training loss: 0.6605170965194702
Validation loss: 1.9926972799403693

Epoch: 781| Step: 0
Training loss: 0.5465666055679321
Validation loss: 2.0029421826844573

Epoch: 6| Step: 1
Training loss: 1.3887159824371338
Validation loss: 2.019994487044632

Epoch: 6| Step: 2
Training loss: 0.9914774894714355
Validation loss: 1.9934134688428653

Epoch: 6| Step: 3
Training loss: 0.8285263776779175
Validation loss: 1.9958386267385175

Epoch: 6| Step: 4
Training loss: 0.5461417436599731
Validation loss: 2.009947608875972

Epoch: 6| Step: 5
Training loss: 1.2480758428573608
Validation loss: 1.9654368956883748

Epoch: 6| Step: 6
Training loss: 0.7877769470214844
Validation loss: 1.9662584515028103

Epoch: 6| Step: 7
Training loss: 0.7474475502967834
Validation loss: 1.9891052258911954

Epoch: 6| Step: 8
Training loss: 0.8324882984161377
Validation loss: 2.0336828308720745

Epoch: 6| Step: 9
Training loss: 1.3273817300796509
Validation loss: 2.011604925637604

Epoch: 6| Step: 10
Training loss: 1.0786468982696533
Validation loss: 1.9790510105830368

Epoch: 6| Step: 11
Training loss: 0.7451159954071045
Validation loss: 1.9537082288854866

Epoch: 6| Step: 12
Training loss: 1.8181207180023193
Validation loss: 1.9525402386983235

Epoch: 6| Step: 13
Training loss: 0.9128833413124084
Validation loss: 1.968846744106662

Epoch: 782| Step: 0
Training loss: 0.9878718852996826
Validation loss: 1.9473184129243255

Epoch: 6| Step: 1
Training loss: 0.9160786867141724
Validation loss: 1.9992430902296496

Epoch: 6| Step: 2
Training loss: 1.073402762413025
Validation loss: 1.9718624571318268

Epoch: 6| Step: 3
Training loss: 1.1070349216461182
Validation loss: 2.0253402417705906

Epoch: 6| Step: 4
Training loss: 1.069847583770752
Validation loss: 1.9805186704922748

Epoch: 6| Step: 5
Training loss: 0.6079527735710144
Validation loss: 1.956791994392231

Epoch: 6| Step: 6
Training loss: 0.5286766290664673
Validation loss: 2.0251002721889044

Epoch: 6| Step: 7
Training loss: 1.2874343395233154
Validation loss: 2.0017758415591334

Epoch: 6| Step: 8
Training loss: 1.036227822303772
Validation loss: 2.0091882303196895

Epoch: 6| Step: 9
Training loss: 0.6432241201400757
Validation loss: 1.9971316578567668

Epoch: 6| Step: 10
Training loss: 1.0550047159194946
Validation loss: 1.9937363388717815

Epoch: 6| Step: 11
Training loss: 1.5243053436279297
Validation loss: 1.9847897329638082

Epoch: 6| Step: 12
Training loss: 0.6281073093414307
Validation loss: 2.054706282513116

Epoch: 6| Step: 13
Training loss: 1.2398762702941895
Validation loss: 1.9501534200483752

Epoch: 783| Step: 0
Training loss: 1.9258826971054077
Validation loss: 1.9817579664209837

Epoch: 6| Step: 1
Training loss: 0.6710147857666016
Validation loss: 1.9633383789370138

Epoch: 6| Step: 2
Training loss: 0.9492769837379456
Validation loss: 1.92752061095289

Epoch: 6| Step: 3
Training loss: 0.49317970871925354
Validation loss: 1.9693843010933167

Epoch: 6| Step: 4
Training loss: 1.271864414215088
Validation loss: 1.9703090485706125

Epoch: 6| Step: 5
Training loss: 1.2050118446350098
Validation loss: 1.982585072517395

Epoch: 6| Step: 6
Training loss: 1.375781774520874
Validation loss: 1.9762272347686112

Epoch: 6| Step: 7
Training loss: 1.0391199588775635
Validation loss: 1.9643229515321794

Epoch: 6| Step: 8
Training loss: 0.8104041218757629
Validation loss: 1.9863372592515842

Epoch: 6| Step: 9
Training loss: 0.6612629890441895
Validation loss: 1.9416957106641544

Epoch: 6| Step: 10
Training loss: 0.627787172794342
Validation loss: 1.948370938659996

Epoch: 6| Step: 11
Training loss: 0.590601921081543
Validation loss: 2.0011829868439706

Epoch: 6| Step: 12
Training loss: 0.43395859003067017
Validation loss: 1.9891275667375135

Epoch: 6| Step: 13
Training loss: 2.376030683517456
Validation loss: 1.979389702120135

Epoch: 784| Step: 0
Training loss: 0.7970349788665771
Validation loss: 2.0187264924408286

Epoch: 6| Step: 1
Training loss: 0.9178010821342468
Validation loss: 2.028624027006088

Epoch: 6| Step: 2
Training loss: 0.9658019542694092
Validation loss: 2.0332156650481688

Epoch: 6| Step: 3
Training loss: 0.8664828538894653
Validation loss: 2.009484293640301

Epoch: 6| Step: 4
Training loss: 0.7980273962020874
Validation loss: 1.9917086888385076

Epoch: 6| Step: 5
Training loss: 0.7043966054916382
Validation loss: 1.9761282397854714

Epoch: 6| Step: 6
Training loss: 1.659995198249817
Validation loss: 2.0195541984291485

Epoch: 6| Step: 7
Training loss: 1.436363697052002
Validation loss: 1.9402886629104614

Epoch: 6| Step: 8
Training loss: 1.199523687362671
Validation loss: 1.9441289978642617

Epoch: 6| Step: 9
Training loss: 1.389235258102417
Validation loss: 1.97997663610725

Epoch: 6| Step: 10
Training loss: 0.7267608642578125
Validation loss: 1.9669740738407258

Epoch: 6| Step: 11
Training loss: 0.8168038725852966
Validation loss: 1.9699697802143712

Epoch: 6| Step: 12
Training loss: 0.6706188321113586
Validation loss: 1.9703003591106785

Epoch: 6| Step: 13
Training loss: 0.7446153163909912
Validation loss: 1.9776946383137857

Epoch: 785| Step: 0
Training loss: 1.3000743389129639
Validation loss: 1.9950861033572946

Epoch: 6| Step: 1
Training loss: 0.9132184982299805
Validation loss: 1.9669489322170135

Epoch: 6| Step: 2
Training loss: 0.7255688309669495
Validation loss: 1.9961742201159078

Epoch: 6| Step: 3
Training loss: 0.47759032249450684
Validation loss: 1.973347649779371

Epoch: 6| Step: 4
Training loss: 0.5462414026260376
Validation loss: 2.001549623345816

Epoch: 6| Step: 5
Training loss: 1.4090594053268433
Validation loss: 2.0088841556220927

Epoch: 6| Step: 6
Training loss: 0.9534552097320557
Validation loss: 1.9913433456933627

Epoch: 6| Step: 7
Training loss: 0.7491122484207153
Validation loss: 2.0177916583194526

Epoch: 6| Step: 8
Training loss: 1.0887819528579712
Validation loss: 1.9809021693404003

Epoch: 6| Step: 9
Training loss: 1.3931736946105957
Validation loss: 1.9586505761710546

Epoch: 6| Step: 10
Training loss: 0.8871595859527588
Validation loss: 1.9476052099658596

Epoch: 6| Step: 11
Training loss: 1.5848033428192139
Validation loss: 1.961471983181533

Epoch: 6| Step: 12
Training loss: 0.6209093332290649
Validation loss: 1.9358194105086788

Epoch: 6| Step: 13
Training loss: 0.7649036049842834
Validation loss: 1.9781274154622068

Epoch: 786| Step: 0
Training loss: 0.42239075899124146
Validation loss: 2.024107584389307

Epoch: 6| Step: 1
Training loss: 0.7419693470001221
Validation loss: 1.9632754505321544

Epoch: 6| Step: 2
Training loss: 0.5537346601486206
Validation loss: 2.00052567707595

Epoch: 6| Step: 3
Training loss: 1.234574556350708
Validation loss: 1.9652118195769608

Epoch: 6| Step: 4
Training loss: 0.9658721089363098
Validation loss: 1.9404292465538107

Epoch: 6| Step: 5
Training loss: 0.9658415913581848
Validation loss: 1.9859329782506472

Epoch: 6| Step: 6
Training loss: 0.7808206081390381
Validation loss: 1.9322991460882208

Epoch: 6| Step: 7
Training loss: 1.3439607620239258
Validation loss: 1.9574563887811476

Epoch: 6| Step: 8
Training loss: 0.6654782295227051
Validation loss: 1.9924647987529795

Epoch: 6| Step: 9
Training loss: 1.5632686614990234
Validation loss: 2.0060693653680945

Epoch: 6| Step: 10
Training loss: 1.5245559215545654
Validation loss: 1.9863535691333074

Epoch: 6| Step: 11
Training loss: 1.453566551208496
Validation loss: 1.9769804093145555

Epoch: 6| Step: 12
Training loss: 0.8409773111343384
Validation loss: 2.00468094887272

Epoch: 6| Step: 13
Training loss: 0.8109591603279114
Validation loss: 1.983636374114662

Epoch: 787| Step: 0
Training loss: 0.8896520137786865
Validation loss: 1.9459674794186828

Epoch: 6| Step: 1
Training loss: 0.6511715650558472
Validation loss: 1.9914823193703928

Epoch: 6| Step: 2
Training loss: 1.5986372232437134
Validation loss: 1.9993978392693303

Epoch: 6| Step: 3
Training loss: 0.45207467675209045
Validation loss: 1.986630170576034

Epoch: 6| Step: 4
Training loss: 0.9564248919487
Validation loss: 1.976729695514966

Epoch: 6| Step: 5
Training loss: 0.9242889881134033
Validation loss: 1.962247460119186

Epoch: 6| Step: 6
Training loss: 0.6835182309150696
Validation loss: 1.9815871484817997

Epoch: 6| Step: 7
Training loss: 1.2878786325454712
Validation loss: 1.9953774482973161

Epoch: 6| Step: 8
Training loss: 0.929678201675415
Validation loss: 2.0129556399519726

Epoch: 6| Step: 9
Training loss: 1.049167513847351
Validation loss: 1.9462151476131972

Epoch: 6| Step: 10
Training loss: 1.2286276817321777
Validation loss: 1.9501144168197468

Epoch: 6| Step: 11
Training loss: 0.7759090662002563
Validation loss: 1.9212931420213433

Epoch: 6| Step: 12
Training loss: 1.1915812492370605
Validation loss: 1.9893988332440775

Epoch: 6| Step: 13
Training loss: 1.6704784631729126
Validation loss: 1.975882790421927

Epoch: 788| Step: 0
Training loss: 0.8652348518371582
Validation loss: 1.9821012545657415

Epoch: 6| Step: 1
Training loss: 1.2251873016357422
Validation loss: 1.9292724619629562

Epoch: 6| Step: 2
Training loss: 0.6440289616584778
Validation loss: 1.9999100508228425

Epoch: 6| Step: 3
Training loss: 0.9689161777496338
Validation loss: 2.017709127036474

Epoch: 6| Step: 4
Training loss: 0.566444993019104
Validation loss: 1.9590846184761292

Epoch: 6| Step: 5
Training loss: 1.3043925762176514
Validation loss: 1.9906195825146091

Epoch: 6| Step: 6
Training loss: 1.0282584428787231
Validation loss: 1.987638650401946

Epoch: 6| Step: 7
Training loss: 1.0269235372543335
Validation loss: 1.9931451197593444

Epoch: 6| Step: 8
Training loss: 0.5743571519851685
Validation loss: 2.0032769556968444

Epoch: 6| Step: 9
Training loss: 1.0394649505615234
Validation loss: 1.9936343341745355

Epoch: 6| Step: 10
Training loss: 0.8545572757720947
Validation loss: 1.9894977731089438

Epoch: 6| Step: 11
Training loss: 0.9666695594787598
Validation loss: 1.9733709558363883

Epoch: 6| Step: 12
Training loss: 1.0922452211380005
Validation loss: 1.9161637085740284

Epoch: 6| Step: 13
Training loss: 1.616025447845459
Validation loss: 2.0124164499262327

Epoch: 789| Step: 0
Training loss: 1.3604650497436523
Validation loss: 1.9542771077925158

Epoch: 6| Step: 1
Training loss: 0.6606459617614746
Validation loss: 1.9627752970623713

Epoch: 6| Step: 2
Training loss: 1.2591413259506226
Validation loss: 1.954956212351399

Epoch: 6| Step: 3
Training loss: 0.45100030303001404
Validation loss: 1.9680356530733005

Epoch: 6| Step: 4
Training loss: 0.8698734045028687
Validation loss: 1.963505401406237

Epoch: 6| Step: 5
Training loss: 0.6582199335098267
Validation loss: 1.9857370879060479

Epoch: 6| Step: 6
Training loss: 1.1329450607299805
Validation loss: 2.05480690925352

Epoch: 6| Step: 7
Training loss: 0.8834373950958252
Validation loss: 1.9764882441489928

Epoch: 6| Step: 8
Training loss: 1.3142478466033936
Validation loss: 2.002172311147054

Epoch: 6| Step: 9
Training loss: 1.1047003269195557
Validation loss: 2.0083403920614593

Epoch: 6| Step: 10
Training loss: 0.6693114042282104
Validation loss: 1.961243740973934

Epoch: 6| Step: 11
Training loss: 1.446120262145996
Validation loss: 2.037885304420225

Epoch: 6| Step: 12
Training loss: 0.4089919328689575
Validation loss: 1.9343716341962096

Epoch: 6| Step: 13
Training loss: 1.2776464223861694
Validation loss: 2.04976043393535

Epoch: 790| Step: 0
Training loss: 1.1215553283691406
Validation loss: 2.000797051255421

Epoch: 6| Step: 1
Training loss: 0.9116381406784058
Validation loss: 2.039603239746504

Epoch: 6| Step: 2
Training loss: 1.4998620748519897
Validation loss: 1.9831251764810214

Epoch: 6| Step: 3
Training loss: 1.2241131067276
Validation loss: 1.9842006468003797

Epoch: 6| Step: 4
Training loss: 0.7100611925125122
Validation loss: 1.960092988065494

Epoch: 6| Step: 5
Training loss: 1.160857915878296
Validation loss: 1.9709038119162283

Epoch: 6| Step: 6
Training loss: 0.8567072153091431
Validation loss: 1.9875330694260136

Epoch: 6| Step: 7
Training loss: 0.7968810796737671
Validation loss: 1.9445727230400167

Epoch: 6| Step: 8
Training loss: 1.0438120365142822
Validation loss: 1.9386053034054336

Epoch: 6| Step: 9
Training loss: 0.8142196536064148
Validation loss: 1.93776987829516

Epoch: 6| Step: 10
Training loss: 0.8993050456047058
Validation loss: 1.9620090505128265

Epoch: 6| Step: 11
Training loss: 1.0425069332122803
Validation loss: 1.9347590861781951

Epoch: 6| Step: 12
Training loss: 0.8297461271286011
Validation loss: 1.9595220499141242

Epoch: 6| Step: 13
Training loss: 0.7770313620567322
Validation loss: 1.9777540340218493

Epoch: 791| Step: 0
Training loss: 0.895939826965332
Validation loss: 1.9852588612546203

Epoch: 6| Step: 1
Training loss: 0.6498754620552063
Validation loss: 1.9933325270170807

Epoch: 6| Step: 2
Training loss: 0.6016830801963806
Validation loss: 1.9705540698061708

Epoch: 6| Step: 3
Training loss: 1.2944780588150024
Validation loss: 1.9888828685206752

Epoch: 6| Step: 4
Training loss: 0.4068526327610016
Validation loss: 2.006412958586088

Epoch: 6| Step: 5
Training loss: 1.6930608749389648
Validation loss: 2.0013627185616443

Epoch: 6| Step: 6
Training loss: 0.9438790082931519
Validation loss: 2.01941131904561

Epoch: 6| Step: 7
Training loss: 0.6746420860290527
Validation loss: 2.0180563849787556

Epoch: 6| Step: 8
Training loss: 1.167783498764038
Validation loss: 1.9588911789719776

Epoch: 6| Step: 9
Training loss: 1.0944185256958008
Validation loss: 1.93934424590039

Epoch: 6| Step: 10
Training loss: 0.8773688673973083
Validation loss: 1.9374733445464924

Epoch: 6| Step: 11
Training loss: 0.655422568321228
Validation loss: 1.962352793703797

Epoch: 6| Step: 12
Training loss: 1.511594295501709
Validation loss: 1.9735514630553543

Epoch: 6| Step: 13
Training loss: 0.9048035740852356
Validation loss: 1.973632981700282

Epoch: 792| Step: 0
Training loss: 1.0465288162231445
Validation loss: 1.9429591522421887

Epoch: 6| Step: 1
Training loss: 1.0738611221313477
Validation loss: 1.9381955515953802

Epoch: 6| Step: 2
Training loss: 1.0881389379501343
Validation loss: 1.9780197246100313

Epoch: 6| Step: 3
Training loss: 0.6617183685302734
Validation loss: 2.0025608437035674

Epoch: 6| Step: 4
Training loss: 0.7666172981262207
Validation loss: 1.9753730514998078

Epoch: 6| Step: 5
Training loss: 1.046467661857605
Validation loss: 2.0546212221986506

Epoch: 6| Step: 6
Training loss: 1.3877705335617065
Validation loss: 1.9829545456876037

Epoch: 6| Step: 7
Training loss: 0.9819548726081848
Validation loss: 1.998350151123539

Epoch: 6| Step: 8
Training loss: 0.8312307596206665
Validation loss: 2.0187829284257788

Epoch: 6| Step: 9
Training loss: 1.13884437084198
Validation loss: 2.0093187824372323

Epoch: 6| Step: 10
Training loss: 1.0026404857635498
Validation loss: 2.0287249203651183

Epoch: 6| Step: 11
Training loss: 0.7076517939567566
Validation loss: 1.964183876591344

Epoch: 6| Step: 12
Training loss: 0.9644796848297119
Validation loss: 1.9729547731338009

Epoch: 6| Step: 13
Training loss: 1.6093608140945435
Validation loss: 1.9887920938512331

Epoch: 793| Step: 0
Training loss: 1.214032769203186
Validation loss: 1.9590283209277737

Epoch: 6| Step: 1
Training loss: 1.1968964338302612
Validation loss: 1.9706593931362193

Epoch: 6| Step: 2
Training loss: 1.6430667638778687
Validation loss: 1.985667597862982

Epoch: 6| Step: 3
Training loss: 0.7296099066734314
Validation loss: 1.9762634910562986

Epoch: 6| Step: 4
Training loss: 1.389446496963501
Validation loss: 1.9749764037388626

Epoch: 6| Step: 5
Training loss: 1.088956594467163
Validation loss: 1.970697449099633

Epoch: 6| Step: 6
Training loss: 0.6614412069320679
Validation loss: 1.9996651308510893

Epoch: 6| Step: 7
Training loss: 0.4852640628814697
Validation loss: 1.9483493681876891

Epoch: 6| Step: 8
Training loss: 0.7655180096626282
Validation loss: 1.9699935246539373

Epoch: 6| Step: 9
Training loss: 0.8431589007377625
Validation loss: 1.9805150788317445

Epoch: 6| Step: 10
Training loss: 1.1119749546051025
Validation loss: 2.0126203452387164

Epoch: 6| Step: 11
Training loss: 0.7649297714233398
Validation loss: 1.9491534771457795

Epoch: 6| Step: 12
Training loss: 0.5742942094802856
Validation loss: 1.9877681245086014

Epoch: 6| Step: 13
Training loss: 1.138549566268921
Validation loss: 1.971133388498778

Epoch: 794| Step: 0
Training loss: 1.0835723876953125
Validation loss: 1.986631654923962

Epoch: 6| Step: 1
Training loss: 1.16679048538208
Validation loss: 1.9696651248521702

Epoch: 6| Step: 2
Training loss: 0.8259347677230835
Validation loss: 1.9862081068818287

Epoch: 6| Step: 3
Training loss: 0.8211377859115601
Validation loss: 1.9520724383733605

Epoch: 6| Step: 4
Training loss: 1.135317325592041
Validation loss: 1.9476669578142063

Epoch: 6| Step: 5
Training loss: 1.3457751274108887
Validation loss: 1.9829584539577525

Epoch: 6| Step: 6
Training loss: 0.8839418888092041
Validation loss: 1.9667836081597112

Epoch: 6| Step: 7
Training loss: 0.4370453953742981
Validation loss: 1.9238504107280443

Epoch: 6| Step: 8
Training loss: 0.3037443161010742
Validation loss: 1.9532421276133547

Epoch: 6| Step: 9
Training loss: 0.7780745625495911
Validation loss: 1.9541981886791926

Epoch: 6| Step: 10
Training loss: 1.022845983505249
Validation loss: 1.9778077038385535

Epoch: 6| Step: 11
Training loss: 1.677924394607544
Validation loss: 2.011363685771983

Epoch: 6| Step: 12
Training loss: 0.8808152675628662
Validation loss: 2.017148211438169

Epoch: 6| Step: 13
Training loss: 1.1831220388412476
Validation loss: 2.004642540408719

Epoch: 795| Step: 0
Training loss: 0.820095956325531
Validation loss: 1.9977505873608332

Epoch: 6| Step: 1
Training loss: 1.120004653930664
Validation loss: 2.0082584017066547

Epoch: 6| Step: 2
Training loss: 1.1515268087387085
Validation loss: 2.0121676473207373

Epoch: 6| Step: 3
Training loss: 0.7242765426635742
Validation loss: 1.9871152870116695

Epoch: 6| Step: 4
Training loss: 0.7208949327468872
Validation loss: 1.985941816401738

Epoch: 6| Step: 5
Training loss: 0.7969566583633423
Validation loss: 1.9948266975341304

Epoch: 6| Step: 6
Training loss: 0.6126918196678162
Validation loss: 1.9661488545838224

Epoch: 6| Step: 7
Training loss: 1.2040495872497559
Validation loss: 1.985162724730789

Epoch: 6| Step: 8
Training loss: 0.9802626371383667
Validation loss: 1.9414662879000428

Epoch: 6| Step: 9
Training loss: 0.8139805197715759
Validation loss: 2.013362830685031

Epoch: 6| Step: 10
Training loss: 1.225364089012146
Validation loss: 1.9670590226368239

Epoch: 6| Step: 11
Training loss: 1.482100486755371
Validation loss: 2.005432282724688

Epoch: 6| Step: 12
Training loss: 0.8716318011283875
Validation loss: 2.0042616167376117

Epoch: 6| Step: 13
Training loss: 1.2606524229049683
Validation loss: 1.991889980531508

Epoch: 796| Step: 0
Training loss: 1.0478546619415283
Validation loss: 2.005416621444046

Epoch: 6| Step: 1
Training loss: 1.4524649381637573
Validation loss: 2.0128448817037765

Epoch: 6| Step: 2
Training loss: 0.8107105493545532
Validation loss: 1.976900436544931

Epoch: 6| Step: 3
Training loss: 1.0911333560943604
Validation loss: 2.0140672422224477

Epoch: 6| Step: 4
Training loss: 0.9829515218734741
Validation loss: 1.9873098634904431

Epoch: 6| Step: 5
Training loss: 0.852664589881897
Validation loss: 2.0168906411817

Epoch: 6| Step: 6
Training loss: 1.1445560455322266
Validation loss: 1.9990377938875588

Epoch: 6| Step: 7
Training loss: 1.3069504499435425
Validation loss: 2.0206549116360244

Epoch: 6| Step: 8
Training loss: 0.7008350491523743
Validation loss: 1.9635094724675661

Epoch: 6| Step: 9
Training loss: 0.7633402943611145
Validation loss: 1.964706036352342

Epoch: 6| Step: 10
Training loss: 1.1444413661956787
Validation loss: 1.976057493558494

Epoch: 6| Step: 11
Training loss: 1.0370293855667114
Validation loss: 1.9699256881590812

Epoch: 6| Step: 12
Training loss: 0.4343126118183136
Validation loss: 1.9850550582331996

Epoch: 6| Step: 13
Training loss: 0.5960002541542053
Validation loss: 1.9385156516105897

Epoch: 797| Step: 0
Training loss: 0.7092852592468262
Validation loss: 1.9630144308972102

Epoch: 6| Step: 1
Training loss: 1.1317310333251953
Validation loss: 1.9662738307829826

Epoch: 6| Step: 2
Training loss: 1.0041402578353882
Validation loss: 1.935763958961733

Epoch: 6| Step: 3
Training loss: 0.7109888792037964
Validation loss: 1.9720850503572853

Epoch: 6| Step: 4
Training loss: 1.1557825803756714
Validation loss: 1.948977114051901

Epoch: 6| Step: 5
Training loss: 1.27736496925354
Validation loss: 1.9272592785537883

Epoch: 6| Step: 6
Training loss: 0.9017136693000793
Validation loss: 1.9566778944384666

Epoch: 6| Step: 7
Training loss: 1.2259831428527832
Validation loss: 1.9738693378304923

Epoch: 6| Step: 8
Training loss: 0.8364659547805786
Validation loss: 2.001332595784177

Epoch: 6| Step: 9
Training loss: 1.3696792125701904
Validation loss: 1.9779471017981087

Epoch: 6| Step: 10
Training loss: 0.5928999781608582
Validation loss: 2.0036766016355125

Epoch: 6| Step: 11
Training loss: 0.335695743560791
Validation loss: 2.0397001120351974

Epoch: 6| Step: 12
Training loss: 0.7891412377357483
Validation loss: 1.969389989811887

Epoch: 6| Step: 13
Training loss: 1.137688159942627
Validation loss: 1.9959793167729531

Epoch: 798| Step: 0
Training loss: 1.0190794467926025
Validation loss: 2.0071596407121226

Epoch: 6| Step: 1
Training loss: 0.9718244075775146
Validation loss: 1.9808313154405164

Epoch: 6| Step: 2
Training loss: 1.2141852378845215
Validation loss: 2.050820025064612

Epoch: 6| Step: 3
Training loss: 0.5195482969284058
Validation loss: 1.997654946901465

Epoch: 6| Step: 4
Training loss: 0.9073115587234497
Validation loss: 1.957283627602362

Epoch: 6| Step: 5
Training loss: 0.6606655120849609
Validation loss: 1.9674141317285516

Epoch: 6| Step: 6
Training loss: 0.950995683670044
Validation loss: 1.9582641586180656

Epoch: 6| Step: 7
Training loss: 1.5742313861846924
Validation loss: 1.9540033442999727

Epoch: 6| Step: 8
Training loss: 1.2282943725585938
Validation loss: 1.9511980036253571

Epoch: 6| Step: 9
Training loss: 0.8625207543373108
Validation loss: 1.9577984899602912

Epoch: 6| Step: 10
Training loss: 0.9118788838386536
Validation loss: 1.9707970952474942

Epoch: 6| Step: 11
Training loss: 0.8001470565795898
Validation loss: 1.9313930016691967

Epoch: 6| Step: 12
Training loss: 0.8291256427764893
Validation loss: 1.9507777742160264

Epoch: 6| Step: 13
Training loss: 1.480003833770752
Validation loss: 1.9991846725504885

Epoch: 799| Step: 0
Training loss: 0.8824760317802429
Validation loss: 1.981312572315175

Epoch: 6| Step: 1
Training loss: 1.0732245445251465
Validation loss: 1.9532147658768522

Epoch: 6| Step: 2
Training loss: 0.5673801302909851
Validation loss: 1.9945874611536663

Epoch: 6| Step: 3
Training loss: 0.90467768907547
Validation loss: 2.0047923390583327

Epoch: 6| Step: 4
Training loss: 1.2501046657562256
Validation loss: 2.0085435208453926

Epoch: 6| Step: 5
Training loss: 1.336977481842041
Validation loss: 2.002553184827169

Epoch: 6| Step: 6
Training loss: 0.7032963037490845
Validation loss: 1.9981050798969884

Epoch: 6| Step: 7
Training loss: 1.137955665588379
Validation loss: 1.9952583723170783

Epoch: 6| Step: 8
Training loss: 0.5592291355133057
Validation loss: 2.020149128411406

Epoch: 6| Step: 9
Training loss: 1.1640965938568115
Validation loss: 1.9892615836153749

Epoch: 6| Step: 10
Training loss: 0.7633198499679565
Validation loss: 2.005317698242844

Epoch: 6| Step: 11
Training loss: 1.0220224857330322
Validation loss: 1.973994226865871

Epoch: 6| Step: 12
Training loss: 1.3600146770477295
Validation loss: 2.025135137701547

Epoch: 6| Step: 13
Training loss: 0.5941070318222046
Validation loss: 1.9800778358213362

Epoch: 800| Step: 0
Training loss: 0.7692962884902954
Validation loss: 1.9112337353408977

Epoch: 6| Step: 1
Training loss: 0.7109631299972534
Validation loss: 1.9728915127374793

Epoch: 6| Step: 2
Training loss: 0.9150036573410034
Validation loss: 1.934981026957112

Epoch: 6| Step: 3
Training loss: 0.7821632623672485
Validation loss: 1.9468424243311728

Epoch: 6| Step: 4
Training loss: 0.6623464822769165
Validation loss: 2.0051391765635502

Epoch: 6| Step: 5
Training loss: 0.4887343645095825
Validation loss: 1.9200536743287118

Epoch: 6| Step: 6
Training loss: 1.957028865814209
Validation loss: 2.000914885151771

Epoch: 6| Step: 7
Training loss: 0.8273119330406189
Validation loss: 1.9632109019064135

Epoch: 6| Step: 8
Training loss: 0.8775869607925415
Validation loss: 2.009665527651387

Epoch: 6| Step: 9
Training loss: 1.4836571216583252
Validation loss: 1.9615656304103073

Epoch: 6| Step: 10
Training loss: 1.2651004791259766
Validation loss: 1.9510855085106307

Epoch: 6| Step: 11
Training loss: 0.9426963329315186
Validation loss: 1.9723832504723662

Epoch: 6| Step: 12
Training loss: 0.8349284529685974
Validation loss: 1.9810886434329453

Epoch: 6| Step: 13
Training loss: 1.1899737119674683
Validation loss: 1.9777837222622288

Testing loss: 2.1365234480963813
