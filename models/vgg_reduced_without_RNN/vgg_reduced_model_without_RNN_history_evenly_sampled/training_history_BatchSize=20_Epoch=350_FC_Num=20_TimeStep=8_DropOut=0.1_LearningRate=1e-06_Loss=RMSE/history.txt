Epoch: 1| Step: 0
Training loss: 5.498660184487026
Validation loss: 5.86476652919719

Epoch: 5| Step: 1
Training loss: 6.098355005807342
Validation loss: 5.859429442231395

Epoch: 5| Step: 2
Training loss: 5.869415875929169
Validation loss: 5.856029861096123

Epoch: 5| Step: 3
Training loss: 5.027627908757371
Validation loss: 5.854448158953657

Epoch: 5| Step: 4
Training loss: 6.75823387640394
Validation loss: 5.8511107240914715

Epoch: 5| Step: 5
Training loss: 5.375934785685769
Validation loss: 5.848761592032498

Epoch: 5| Step: 6
Training loss: 6.2887670980701404
Validation loss: 5.846139667211148

Epoch: 5| Step: 7
Training loss: 6.44847549046463
Validation loss: 5.844448257361189

Epoch: 5| Step: 8
Training loss: 6.023574926488383
Validation loss: 5.842991135033969

Epoch: 5| Step: 9
Training loss: 5.817193546133207
Validation loss: 5.840160819545018

Epoch: 5| Step: 10
Training loss: 5.128366620626556
Validation loss: 5.837971835136146

Epoch: 2| Step: 0
Training loss: 6.5776384404749155
Validation loss: 5.835238646866004

Epoch: 5| Step: 1
Training loss: 6.609912895517469
Validation loss: 5.834158941227249

Epoch: 5| Step: 2
Training loss: 6.005396323612798
Validation loss: 5.831087182162042

Epoch: 5| Step: 3
Training loss: 4.713762287294836
Validation loss: 5.82750582158589

Epoch: 5| Step: 4
Training loss: 6.018619257852759
Validation loss: 5.825662402922259

Epoch: 5| Step: 5
Training loss: 6.490072445222648
Validation loss: 5.8245673604701915

Epoch: 5| Step: 6
Training loss: 6.5524063232898095
Validation loss: 5.819632046627255

Epoch: 5| Step: 7
Training loss: 5.405909003820983
Validation loss: 5.818928639377013

Epoch: 5| Step: 8
Training loss: 5.226976135946752
Validation loss: 5.816206243667025

Epoch: 5| Step: 9
Training loss: 5.226276931602065
Validation loss: 5.814816649582918

Epoch: 5| Step: 10
Training loss: 5.060854232211434
Validation loss: 5.8099527060079295

Epoch: 3| Step: 0
Training loss: 5.274779921727185
Validation loss: 5.809911844365114

Epoch: 5| Step: 1
Training loss: 5.925206357042357
Validation loss: 5.805914740541418

Epoch: 5| Step: 2
Training loss: 6.038292760513515
Validation loss: 5.803564360013775

Epoch: 5| Step: 3
Training loss: 6.483944062770041
Validation loss: 5.801260258860166

Epoch: 5| Step: 4
Training loss: 5.495840580578533
Validation loss: 5.8029759843899384

Epoch: 5| Step: 5
Training loss: 5.594698180920549
Validation loss: 5.797268917487933

Epoch: 5| Step: 6
Training loss: 6.104009667505131
Validation loss: 5.794579118964055

Epoch: 5| Step: 7
Training loss: 5.269715483366703
Validation loss: 5.791643007055567

Epoch: 5| Step: 8
Training loss: 5.902037394845635
Validation loss: 5.789197469615383

Epoch: 5| Step: 9
Training loss: 5.69811758446135
Validation loss: 5.786551366554926

Epoch: 5| Step: 10
Training loss: 6.270395493879011
Validation loss: 5.785146951119208

Epoch: 4| Step: 0
Training loss: 5.272775746962769
Validation loss: 5.782496490507953

Epoch: 5| Step: 1
Training loss: 5.707082383947003
Validation loss: 5.778822604167074

Epoch: 5| Step: 2
Training loss: 6.16306512496981
Validation loss: 5.775664193520308

Epoch: 5| Step: 3
Training loss: 5.85729324998404
Validation loss: 5.774165453338057

Epoch: 5| Step: 4
Training loss: 6.359816177398741
Validation loss: 5.772945071724664

Epoch: 5| Step: 5
Training loss: 6.251908888179173
Validation loss: 5.769654384528798

Epoch: 5| Step: 6
Training loss: 4.961126272860193
Validation loss: 5.764436695555517

Epoch: 5| Step: 7
Training loss: 6.2147878935657745
Validation loss: 5.76351947624434

Epoch: 5| Step: 8
Training loss: 4.643559924583009
Validation loss: 5.760435232698393

Epoch: 5| Step: 9
Training loss: 5.677300330631581
Validation loss: 5.757614837841018

Epoch: 5| Step: 10
Training loss: 6.505764972296175
Validation loss: 5.754911332454171

Epoch: 5| Step: 0
Training loss: 5.761353934425036
Validation loss: 5.752881915571711

Epoch: 5| Step: 1
Training loss: 6.2410507217397395
Validation loss: 5.74736772719532

Epoch: 5| Step: 2
Training loss: 5.1390898015151585
Validation loss: 5.7467571849920756

Epoch: 5| Step: 3
Training loss: 5.903718597632284
Validation loss: 5.743243816880509

Epoch: 5| Step: 4
Training loss: 4.967125969115984
Validation loss: 5.7388212264787395

Epoch: 5| Step: 5
Training loss: 4.783628183951478
Validation loss: 5.7373046437099635

Epoch: 5| Step: 6
Training loss: 5.785493520194867
Validation loss: 5.733519496218123

Epoch: 5| Step: 7
Training loss: 6.284742304967145
Validation loss: 5.7299570216006455

Epoch: 5| Step: 8
Training loss: 6.156590176396157
Validation loss: 5.729448571154103

Epoch: 5| Step: 9
Training loss: 6.043981840781722
Validation loss: 5.725076934960968

Epoch: 5| Step: 10
Training loss: 6.23575035737731
Validation loss: 5.720543346923396

Epoch: 6| Step: 0
Training loss: 5.614979613786004
Validation loss: 5.718469706237685

Epoch: 5| Step: 1
Training loss: 5.635860893335924
Validation loss: 5.714546902718506

Epoch: 5| Step: 2
Training loss: 4.913952848972882
Validation loss: 5.710152398698722

Epoch: 5| Step: 3
Training loss: 5.282481213674796
Validation loss: 5.706065663504248

Epoch: 5| Step: 4
Training loss: 5.375658571572882
Validation loss: 5.703045713980769

Epoch: 5| Step: 5
Training loss: 6.184305001933006
Validation loss: 5.702461520316293

Epoch: 5| Step: 6
Training loss: 5.737294298527828
Validation loss: 5.697091844686904

Epoch: 5| Step: 7
Training loss: 6.175262371466116
Validation loss: 5.694301969138281

Epoch: 5| Step: 8
Training loss: 5.8252446724909985
Validation loss: 5.690862518759906

Epoch: 5| Step: 9
Training loss: 5.972747582485136
Validation loss: 5.687456634078495

Epoch: 5| Step: 10
Training loss: 6.3075765917614905
Validation loss: 5.681905839290478

Epoch: 7| Step: 0
Training loss: 5.8685120815683485
Validation loss: 5.678850796964433

Epoch: 5| Step: 1
Training loss: 5.461311556730465
Validation loss: 5.677268284244828

Epoch: 5| Step: 2
Training loss: 5.521460194057415
Validation loss: 5.673856926770216

Epoch: 5| Step: 3
Training loss: 6.086101407352343
Validation loss: 5.667617950842666

Epoch: 5| Step: 4
Training loss: 6.272737570893651
Validation loss: 5.665678185393627

Epoch: 5| Step: 5
Training loss: 5.16240994649674
Validation loss: 5.662887329351133

Epoch: 5| Step: 6
Training loss: 5.174937468072625
Validation loss: 5.657640877962692

Epoch: 5| Step: 7
Training loss: 5.99228171780557
Validation loss: 5.653083445643443

Epoch: 5| Step: 8
Training loss: 5.756901455442483
Validation loss: 5.649958636319132

Epoch: 5| Step: 9
Training loss: 5.607539054472695
Validation loss: 5.645033637565073

Epoch: 5| Step: 10
Training loss: 5.642655701861578
Validation loss: 5.64166979464364

Epoch: 8| Step: 0
Training loss: 5.292226906903678
Validation loss: 5.637857463062799

Epoch: 5| Step: 1
Training loss: 5.7145734033372
Validation loss: 5.632792263231604

Epoch: 5| Step: 2
Training loss: 6.577419795928719
Validation loss: 5.628387142356359

Epoch: 5| Step: 3
Training loss: 6.553822038550352
Validation loss: 5.625385693233

Epoch: 5| Step: 4
Training loss: 4.840631083810331
Validation loss: 5.6207305802970104

Epoch: 5| Step: 5
Training loss: 5.447017889725644
Validation loss: 5.618873674567226

Epoch: 5| Step: 6
Training loss: 5.568075921461837
Validation loss: 5.610247570154912

Epoch: 5| Step: 7
Training loss: 5.174688305889578
Validation loss: 5.608203171516872

Epoch: 5| Step: 8
Training loss: 5.872875072832194
Validation loss: 5.601986930018088

Epoch: 5| Step: 9
Training loss: 5.96310653320626
Validation loss: 5.597884059752589

Epoch: 5| Step: 10
Training loss: 4.7482475260333095
Validation loss: 5.591625054517908

Epoch: 9| Step: 0
Training loss: 4.759494327644777
Validation loss: 5.592398824892574

Epoch: 5| Step: 1
Training loss: 5.0000005722045575
Validation loss: 5.585102048481715

Epoch: 5| Step: 2
Training loss: 6.1987775274220525
Validation loss: 5.581094690048046

Epoch: 5| Step: 3
Training loss: 5.419307221622438
Validation loss: 5.575202904283911

Epoch: 5| Step: 4
Training loss: 5.3802932579918155
Validation loss: 5.572891653298232

Epoch: 5| Step: 5
Training loss: 6.168572964586995
Validation loss: 5.56583205653326

Epoch: 5| Step: 6
Training loss: 5.730584578328375
Validation loss: 5.5627123690884535

Epoch: 5| Step: 7
Training loss: 6.028465141955574
Validation loss: 5.558575787032873

Epoch: 5| Step: 8
Training loss: 5.3998530473846795
Validation loss: 5.555462856271341

Epoch: 5| Step: 9
Training loss: 6.373933291480862
Validation loss: 5.548784536505881

Epoch: 5| Step: 10
Training loss: 4.842976957592053
Validation loss: 5.541314484499342

Epoch: 10| Step: 0
Training loss: 6.160784450471061
Validation loss: 5.5401147888014695

Epoch: 5| Step: 1
Training loss: 6.5876995367706
Validation loss: 5.53027873789849

Epoch: 5| Step: 2
Training loss: 6.019831942623618
Validation loss: 5.527162475002011

Epoch: 5| Step: 3
Training loss: 4.248539393144149
Validation loss: 5.522776456505332

Epoch: 5| Step: 4
Training loss: 5.6170326604180545
Validation loss: 5.515023470930468

Epoch: 5| Step: 5
Training loss: 5.020901480353407
Validation loss: 5.511532462250712

Epoch: 5| Step: 6
Training loss: 5.273209449640729
Validation loss: 5.506043429818974

Epoch: 5| Step: 7
Training loss: 4.112792476005031
Validation loss: 5.499453982697774

Epoch: 5| Step: 8
Training loss: 4.882869335606719
Validation loss: 5.4934182391537885

Epoch: 5| Step: 9
Training loss: 6.494869848625601
Validation loss: 5.489499501041235

Epoch: 5| Step: 10
Training loss: 6.114122346292204
Validation loss: 5.484455156787896

Epoch: 11| Step: 0
Training loss: 6.28142976266401
Validation loss: 5.475872042905851

Epoch: 5| Step: 1
Training loss: 6.028228477274128
Validation loss: 5.472411187608925

Epoch: 5| Step: 2
Training loss: 4.636888637499532
Validation loss: 5.464367930249528

Epoch: 5| Step: 3
Training loss: 5.360694833954196
Validation loss: 5.4592175967066705

Epoch: 5| Step: 4
Training loss: 3.6724386878248247
Validation loss: 5.45384489728616

Epoch: 5| Step: 5
Training loss: 5.330562626843546
Validation loss: 5.44598027995069

Epoch: 5| Step: 6
Training loss: 5.393069213479634
Validation loss: 5.440440630165632

Epoch: 5| Step: 7
Training loss: 6.259315262660369
Validation loss: 5.4350052314236

Epoch: 5| Step: 8
Training loss: 6.453689513557523
Validation loss: 5.42811550314037

Epoch: 5| Step: 9
Training loss: 5.925453574287386
Validation loss: 5.421200660587104

Epoch: 5| Step: 10
Training loss: 4.129979682484452
Validation loss: 5.416496082330204

Epoch: 12| Step: 0
Training loss: 5.956701450911651
Validation loss: 5.406432193832634

Epoch: 5| Step: 1
Training loss: 6.044869181414115
Validation loss: 5.399362302428155

Epoch: 5| Step: 2
Training loss: 5.732888676159881
Validation loss: 5.391086920371116

Epoch: 5| Step: 3
Training loss: 5.462132400958493
Validation loss: 5.385462985195902

Epoch: 5| Step: 4
Training loss: 4.963351982257582
Validation loss: 5.381974526104155

Epoch: 5| Step: 5
Training loss: 5.353354584179445
Validation loss: 5.375299268453216

Epoch: 5| Step: 6
Training loss: 5.234588709781437
Validation loss: 5.367846644180325

Epoch: 5| Step: 7
Training loss: 5.180866090105352
Validation loss: 5.358316172035486

Epoch: 5| Step: 8
Training loss: 4.513259426471601
Validation loss: 5.347031761044342

Epoch: 5| Step: 9
Training loss: 5.702867475992272
Validation loss: 5.345486013345841

Epoch: 5| Step: 10
Training loss: 5.283599511470133
Validation loss: 5.335008580506668

Epoch: 13| Step: 0
Training loss: 5.616631959228741
Validation loss: 5.327905066429337

Epoch: 5| Step: 1
Training loss: 5.62853214839427
Validation loss: 5.322198855720818

Epoch: 5| Step: 2
Training loss: 4.661474586614763
Validation loss: 5.311939309805363

Epoch: 5| Step: 3
Training loss: 5.754735572235067
Validation loss: 5.3049761794354975

Epoch: 5| Step: 4
Training loss: 5.321119429330746
Validation loss: 5.297851135698474

Epoch: 5| Step: 5
Training loss: 6.112983906007558
Validation loss: 5.289674813107811

Epoch: 5| Step: 6
Training loss: 4.196770952629296
Validation loss: 5.280203984429224

Epoch: 5| Step: 7
Training loss: 5.33998180286293
Validation loss: 5.265785041286202

Epoch: 5| Step: 8
Training loss: 4.992372416860826
Validation loss: 5.263039244548723

Epoch: 5| Step: 9
Training loss: 6.44738070510366
Validation loss: 5.252772769508503

Epoch: 5| Step: 10
Training loss: 3.8989981513810257
Validation loss: 5.2456608569856895

Epoch: 14| Step: 0
Training loss: 5.187029346119028
Validation loss: 5.23061378901179

Epoch: 5| Step: 1
Training loss: 5.551487340184829
Validation loss: 5.226340845183787

Epoch: 5| Step: 2
Training loss: 5.40003760289416
Validation loss: 5.217224006060876

Epoch: 5| Step: 3
Training loss: 5.309835865479738
Validation loss: 5.205122755620002

Epoch: 5| Step: 4
Training loss: 4.64149297438335
Validation loss: 5.200031382100814

Epoch: 5| Step: 5
Training loss: 6.067182482634578
Validation loss: 5.18730013349029

Epoch: 5| Step: 6
Training loss: 4.962461702982146
Validation loss: 5.178593645664956

Epoch: 5| Step: 7
Training loss: 5.861627822123958
Validation loss: 5.167969119071226

Epoch: 5| Step: 8
Training loss: 5.173392358489065
Validation loss: 5.156400726193622

Epoch: 5| Step: 9
Training loss: 3.927417987086183
Validation loss: 5.145644306472232

Epoch: 5| Step: 10
Training loss: 5.280887749341258
Validation loss: 5.135110112574779

Epoch: 15| Step: 0
Training loss: 5.04873046780553
Validation loss: 5.128627136861746

Epoch: 5| Step: 1
Training loss: 5.573778013410064
Validation loss: 5.117800383917594

Epoch: 5| Step: 2
Training loss: 5.606507144674057
Validation loss: 5.1045335120073485

Epoch: 5| Step: 3
Training loss: 5.408853422215985
Validation loss: 5.0911267837089555

Epoch: 5| Step: 4
Training loss: 4.4105329327341405
Validation loss: 5.084164410130736

Epoch: 5| Step: 5
Training loss: 4.513545735675249
Validation loss: 5.072947308133492

Epoch: 5| Step: 6
Training loss: 4.437101749225884
Validation loss: 5.059935093831889

Epoch: 5| Step: 7
Training loss: 5.377268822461239
Validation loss: 5.051902592018856

Epoch: 5| Step: 8
Training loss: 4.543163974336066
Validation loss: 5.038511603817219

Epoch: 5| Step: 9
Training loss: 5.646391818681056
Validation loss: 5.02044056669362

Epoch: 5| Step: 10
Training loss: 5.702829348072953
Validation loss: 5.012403667437615

Epoch: 16| Step: 0
Training loss: 4.817649761221934
Validation loss: 4.999863678089025

Epoch: 5| Step: 1
Training loss: 5.936361424550448
Validation loss: 4.985802364457454

Epoch: 5| Step: 2
Training loss: 4.901552709460855
Validation loss: 4.973983465473851

Epoch: 5| Step: 3
Training loss: 5.517409946275407
Validation loss: 4.956674466690981

Epoch: 5| Step: 4
Training loss: 4.7403186716726955
Validation loss: 4.946937083590115

Epoch: 5| Step: 5
Training loss: 4.32486070177083
Validation loss: 4.9362738319808255

Epoch: 5| Step: 6
Training loss: 5.683232309705805
Validation loss: 4.920947690802643

Epoch: 5| Step: 7
Training loss: 4.604689877615924
Validation loss: 4.907957205468484

Epoch: 5| Step: 8
Training loss: 4.396970243310346
Validation loss: 4.895407891710183

Epoch: 5| Step: 9
Training loss: 4.7839327995913425
Validation loss: 4.883332675585349

Epoch: 5| Step: 10
Training loss: 5.063849751947893
Validation loss: 4.862756548657977

Epoch: 17| Step: 0
Training loss: 4.915209516559269
Validation loss: 4.850922191527509

Epoch: 5| Step: 1
Training loss: 5.052198501794846
Validation loss: 4.836915984336729

Epoch: 5| Step: 2
Training loss: 4.6843611316844616
Validation loss: 4.823146259218205

Epoch: 5| Step: 3
Training loss: 5.300531706140229
Validation loss: 4.8004012370841584

Epoch: 5| Step: 4
Training loss: 4.302352022488982
Validation loss: 4.791254470808684

Epoch: 5| Step: 5
Training loss: 4.227448714276252
Validation loss: 4.7800375655638305

Epoch: 5| Step: 6
Training loss: 5.721767609118174
Validation loss: 4.762048581569365

Epoch: 5| Step: 7
Training loss: 4.537307373666126
Validation loss: 4.7478449584629745

Epoch: 5| Step: 8
Training loss: 4.837187228084211
Validation loss: 4.730212792445893

Epoch: 5| Step: 9
Training loss: 5.029426196759661
Validation loss: 4.710685154952516

Epoch: 5| Step: 10
Training loss: 4.5845025854162715
Validation loss: 4.696278658984225

Epoch: 18| Step: 0
Training loss: 4.518840344635196
Validation loss: 4.68171244475275

Epoch: 5| Step: 1
Training loss: 5.143551442797296
Validation loss: 4.659822126529918

Epoch: 5| Step: 2
Training loss: 5.304579631174987
Validation loss: 4.648334885682503

Epoch: 5| Step: 3
Training loss: 4.880567257227313
Validation loss: 4.630045069514119

Epoch: 5| Step: 4
Training loss: 4.536472441705722
Validation loss: 4.614029371114196

Epoch: 5| Step: 5
Training loss: 4.604723222100155
Validation loss: 4.592588979879384

Epoch: 5| Step: 6
Training loss: 3.739779978109403
Validation loss: 4.577513129212007

Epoch: 5| Step: 7
Training loss: 4.587968159000554
Validation loss: 4.564305367324117

Epoch: 5| Step: 8
Training loss: 4.670092392524147
Validation loss: 4.54467480015121

Epoch: 5| Step: 9
Training loss: 4.27146361127498
Validation loss: 4.521899044080291

Epoch: 5| Step: 10
Training loss: 5.143493964867265
Validation loss: 4.5006240402915525

Epoch: 19| Step: 0
Training loss: 5.581919685674395
Validation loss: 4.4871952792185805

Epoch: 5| Step: 1
Training loss: 4.385841669191536
Validation loss: 4.465251792247301

Epoch: 5| Step: 2
Training loss: 4.474720201322866
Validation loss: 4.450891529559574

Epoch: 5| Step: 3
Training loss: 4.576194382146956
Validation loss: 4.4246790102144535

Epoch: 5| Step: 4
Training loss: 4.508242793181773
Validation loss: 4.41056363447226

Epoch: 5| Step: 5
Training loss: 4.189008981774764
Validation loss: 4.387817560775444

Epoch: 5| Step: 6
Training loss: 4.662976213532378
Validation loss: 4.362636682515449

Epoch: 5| Step: 7
Training loss: 3.876325073105672
Validation loss: 4.338340832726149

Epoch: 5| Step: 8
Training loss: 5.038189763631413
Validation loss: 4.321740436120735

Epoch: 5| Step: 9
Training loss: 3.5691949944385493
Validation loss: 4.304046253760772

Epoch: 5| Step: 10
Training loss: 4.275345120246644
Validation loss: 4.284793683883225

Epoch: 20| Step: 0
Training loss: 3.8178226025364874
Validation loss: 4.262338930293125

Epoch: 5| Step: 1
Training loss: 4.249367386353421
Validation loss: 4.23992640053164

Epoch: 5| Step: 2
Training loss: 4.505968586127729
Validation loss: 4.224417315867072

Epoch: 5| Step: 3
Training loss: 4.416871599925066
Validation loss: 4.2065720204074255

Epoch: 5| Step: 4
Training loss: 4.436772676419941
Validation loss: 4.178413417274209

Epoch: 5| Step: 5
Training loss: 4.727444552253248
Validation loss: 4.159803183197181

Epoch: 5| Step: 6
Training loss: 4.408501232581861
Validation loss: 4.1414178115189335

Epoch: 5| Step: 7
Training loss: 4.234854695643392
Validation loss: 4.112992101139754

Epoch: 5| Step: 8
Training loss: 5.073521049993443
Validation loss: 4.0908752833618784

Epoch: 5| Step: 9
Training loss: 3.7832768580272926
Validation loss: 4.057541358292214

Epoch: 5| Step: 10
Training loss: 3.00673269730808
Validation loss: 4.043942196023083

Epoch: 21| Step: 0
Training loss: 3.7465153080062277
Validation loss: 4.020981720172344

Epoch: 5| Step: 1
Training loss: 4.741603054878096
Validation loss: 3.987943649647017

Epoch: 5| Step: 2
Training loss: 4.507889084190219
Validation loss: 3.977757563546993

Epoch: 5| Step: 3
Training loss: 3.333224835219494
Validation loss: 3.9482461444047345

Epoch: 5| Step: 4
Training loss: 3.4729981398946808
Validation loss: 3.934099084541637

Epoch: 5| Step: 5
Training loss: 4.391966265328236
Validation loss: 3.9164837698733552

Epoch: 5| Step: 6
Training loss: 4.263790868128814
Validation loss: 3.888474936264183

Epoch: 5| Step: 7
Training loss: 3.459037862199387
Validation loss: 3.865300026193435

Epoch: 5| Step: 8
Training loss: 4.24307404698104
Validation loss: 3.845054793842796

Epoch: 5| Step: 9
Training loss: 4.396042491884502
Validation loss: 3.8321791356250254

Epoch: 5| Step: 10
Training loss: 3.7711873740109896
Validation loss: 3.7979498217603123

Epoch: 22| Step: 0
Training loss: 4.384490047367409
Validation loss: 3.76476396899687

Epoch: 5| Step: 1
Training loss: 3.721315284492062
Validation loss: 3.755570032935229

Epoch: 5| Step: 2
Training loss: 4.060267142916903
Validation loss: 3.7278009057312613

Epoch: 5| Step: 3
Training loss: 4.223188086232288
Validation loss: 3.704840396439626

Epoch: 5| Step: 4
Training loss: 4.513594121193125
Validation loss: 3.6760277731860564

Epoch: 5| Step: 5
Training loss: 3.96197520249534
Validation loss: 3.6543205856201455

Epoch: 5| Step: 6
Training loss: 2.9961424504068366
Validation loss: 3.643882471877533

Epoch: 5| Step: 7
Training loss: 3.4984364423115584
Validation loss: 3.6140711817141393

Epoch: 5| Step: 8
Training loss: 3.829446120886601
Validation loss: 3.587094066032644

Epoch: 5| Step: 9
Training loss: 3.283137332726798
Validation loss: 3.5658199871327194

Epoch: 5| Step: 10
Training loss: 3.376961032379406
Validation loss: 3.5347213097742185

Epoch: 23| Step: 0
Training loss: 4.8202448365642
Validation loss: 3.5090208733249817

Epoch: 5| Step: 1
Training loss: 3.9034865713512743
Validation loss: 3.4955295940071935

Epoch: 5| Step: 2
Training loss: 3.3668954815550514
Validation loss: 3.477858593650096

Epoch: 5| Step: 3
Training loss: 3.6568360470327255
Validation loss: 3.4593859549605344

Epoch: 5| Step: 4
Training loss: 2.582642544914225
Validation loss: 3.428236427417755

Epoch: 5| Step: 5
Training loss: 3.233132238787385
Validation loss: 3.4038476599874796

Epoch: 5| Step: 6
Training loss: 2.696930861087938
Validation loss: 3.3843444721640834

Epoch: 5| Step: 7
Training loss: 4.091272900520472
Validation loss: 3.363775551716292

Epoch: 5| Step: 8
Training loss: 3.574095610284862
Validation loss: 3.3496959585040074

Epoch: 5| Step: 9
Training loss: 3.9023441165774977
Validation loss: 3.3311851290903824

Epoch: 5| Step: 10
Training loss: 3.5463490369250485
Validation loss: 3.315021136697557

Epoch: 24| Step: 0
Training loss: 4.106542038657195
Validation loss: 3.2875024084098508

Epoch: 5| Step: 1
Training loss: 3.1780571284215817
Validation loss: 3.276559272180957

Epoch: 5| Step: 2
Training loss: 3.4114505369762216
Validation loss: 3.2451416252494663

Epoch: 5| Step: 3
Training loss: 3.28181336425835
Validation loss: 3.227562037602708

Epoch: 5| Step: 4
Training loss: 3.688026261358204
Validation loss: 3.2145765953595995

Epoch: 5| Step: 5
Training loss: 3.328416838409444
Validation loss: 3.194682492242218

Epoch: 5| Step: 6
Training loss: 3.1838218560439198
Validation loss: 3.1823089944469665

Epoch: 5| Step: 7
Training loss: 3.856483395529232
Validation loss: 3.16226292252143

Epoch: 5| Step: 8
Training loss: 3.7018787202264116
Validation loss: 3.150146225886579

Epoch: 5| Step: 9
Training loss: 3.1479388805306625
Validation loss: 3.1426018941830525

Epoch: 5| Step: 10
Training loss: 2.7771997857103754
Validation loss: 3.1145770705673157

Epoch: 25| Step: 0
Training loss: 2.411715357178432
Validation loss: 3.1034776862166944

Epoch: 5| Step: 1
Training loss: 2.6443502119070557
Validation loss: 3.0823516585576693

Epoch: 5| Step: 2
Training loss: 4.049600397811864
Validation loss: 3.067111240595919

Epoch: 5| Step: 3
Training loss: 3.6286935076650937
Validation loss: 3.059430906450788

Epoch: 5| Step: 4
Training loss: 4.305839813583889
Validation loss: 3.0482420356449516

Epoch: 5| Step: 5
Training loss: 3.1949398504335234
Validation loss: 3.0344836484801143

Epoch: 5| Step: 6
Training loss: 4.191099072067465
Validation loss: 3.010222817542619

Epoch: 5| Step: 7
Training loss: 2.534469723136644
Validation loss: 3.00175718576648

Epoch: 5| Step: 8
Training loss: 3.042723189155194
Validation loss: 2.983190955222894

Epoch: 5| Step: 9
Training loss: 3.3319113241350546
Validation loss: 2.9710780084762187

Epoch: 5| Step: 10
Training loss: 2.2963891585976035
Validation loss: 2.965021809903051

Epoch: 26| Step: 0
Training loss: 3.8565126994223244
Validation loss: 2.967713514994896

Epoch: 5| Step: 1
Training loss: 3.3624218275775313
Validation loss: 2.9455520525066103

Epoch: 5| Step: 2
Training loss: 3.158173683043424
Validation loss: 2.933233763546766

Epoch: 5| Step: 3
Training loss: 3.501334753294301
Validation loss: 2.9222445041293548

Epoch: 5| Step: 4
Training loss: 2.567717938408416
Validation loss: 2.924774270453586

Epoch: 5| Step: 5
Training loss: 3.179008542616059
Validation loss: 2.9180917402193254

Epoch: 5| Step: 6
Training loss: 3.2773367662321298
Validation loss: 2.9087492144575693

Epoch: 5| Step: 7
Training loss: 3.1638625093528288
Validation loss: 2.8977494606860654

Epoch: 5| Step: 8
Training loss: 2.980294358737351
Validation loss: 2.8905399965194847

Epoch: 5| Step: 9
Training loss: 3.282442294076231
Validation loss: 2.8831209327380596

Epoch: 5| Step: 10
Training loss: 3.352140505729706
Validation loss: 2.8799016426110176

Epoch: 27| Step: 0
Training loss: 4.049424005686738
Validation loss: 2.8763446810927498

Epoch: 5| Step: 1
Training loss: 2.8069969593462427
Validation loss: 2.8635898392404115

Epoch: 5| Step: 2
Training loss: 3.513754385148511
Validation loss: 2.87241589628234

Epoch: 5| Step: 3
Training loss: 2.5771117097551057
Validation loss: 2.8625456016853463

Epoch: 5| Step: 4
Training loss: 3.138760293072436
Validation loss: 2.851594041399014

Epoch: 5| Step: 5
Training loss: 2.914359969841316
Validation loss: 2.859501727894679

Epoch: 5| Step: 6
Training loss: 3.5660406888393754
Validation loss: 2.859228528370449

Epoch: 5| Step: 7
Training loss: 3.3403347078381507
Validation loss: 2.84692477308177

Epoch: 5| Step: 8
Training loss: 3.612866715030286
Validation loss: 2.8483495034554527

Epoch: 5| Step: 9
Training loss: 2.8795685336314487
Validation loss: 2.819729695207238

Epoch: 5| Step: 10
Training loss: 2.5598956574096827
Validation loss: 2.8433412719943885

Epoch: 28| Step: 0
Training loss: 3.310781356924582
Validation loss: 2.8322290467865856

Epoch: 5| Step: 1
Training loss: 2.927761736863469
Validation loss: 2.825331496727364

Epoch: 5| Step: 2
Training loss: 3.439946084598043
Validation loss: 2.820688802001889

Epoch: 5| Step: 3
Training loss: 3.720369130760577
Validation loss: 2.8084661088020653

Epoch: 5| Step: 4
Training loss: 3.5030752023633585
Validation loss: 2.8006275361536894

Epoch: 5| Step: 5
Training loss: 2.728444758637022
Validation loss: 2.8112378076293614

Epoch: 5| Step: 6
Training loss: 2.7440367981080973
Validation loss: 2.8192150807946237

Epoch: 5| Step: 7
Training loss: 3.2510198313525644
Validation loss: 2.820586856708208

Epoch: 5| Step: 8
Training loss: 2.7303581160805845
Validation loss: 2.8107056594297606

Epoch: 5| Step: 9
Training loss: 2.873742035684256
Validation loss: 2.797165430796209

Epoch: 5| Step: 10
Training loss: 3.865805639118568
Validation loss: 2.806997528334374

Epoch: 29| Step: 0
Training loss: 2.4807528595904533
Validation loss: 2.8128495102885864

Epoch: 5| Step: 1
Training loss: 3.69827480820542
Validation loss: 2.7953725484591367

Epoch: 5| Step: 2
Training loss: 2.878867988901536
Validation loss: 2.7996268425138298

Epoch: 5| Step: 3
Training loss: 3.426351745497609
Validation loss: 2.8005624390079182

Epoch: 5| Step: 4
Training loss: 3.19506954398009
Validation loss: 2.7962484266869048

Epoch: 5| Step: 5
Training loss: 2.9833348244036424
Validation loss: 2.8114649683185022

Epoch: 5| Step: 6
Training loss: 3.0762202377150656
Validation loss: 2.797102923400392

Epoch: 5| Step: 7
Training loss: 3.0505519492592477
Validation loss: 2.8101763999715312

Epoch: 5| Step: 8
Training loss: 3.3532208516978463
Validation loss: 2.819347014650635

Epoch: 5| Step: 9
Training loss: 3.2457920122434163
Validation loss: 2.8050303568811485

Epoch: 5| Step: 10
Training loss: 3.6059140212503547
Validation loss: 2.798784981597527

Epoch: 30| Step: 0
Training loss: 3.282459871579958
Validation loss: 2.7967394403349615

Epoch: 5| Step: 1
Training loss: 3.370933484702505
Validation loss: 2.799980393354267

Epoch: 5| Step: 2
Training loss: 3.2122851882540364
Validation loss: 2.7799335593582675

Epoch: 5| Step: 3
Training loss: 3.4176819076066796
Validation loss: 2.7780782513145827

Epoch: 5| Step: 4
Training loss: 3.5140788429460312
Validation loss: 2.8039271265178574

Epoch: 5| Step: 5
Training loss: 3.1065969660993735
Validation loss: 2.7913818918171747

Epoch: 5| Step: 6
Training loss: 3.094896970892086
Validation loss: 2.786958281171664

Epoch: 5| Step: 7
Training loss: 3.373252133484049
Validation loss: 2.7843917314919286

Epoch: 5| Step: 8
Training loss: 2.878810844755663
Validation loss: 2.790159286540197

Epoch: 5| Step: 9
Training loss: 2.5937735315197625
Validation loss: 2.780019733450102

Epoch: 5| Step: 10
Training loss: 2.9566735639638635
Validation loss: 2.7800754815353366

Epoch: 31| Step: 0
Training loss: 3.758127179521861
Validation loss: 2.8033999672292103

Epoch: 5| Step: 1
Training loss: 3.0591767633601075
Validation loss: 2.791761962067362

Epoch: 5| Step: 2
Training loss: 3.668634941207444
Validation loss: 2.793800168411577

Epoch: 5| Step: 3
Training loss: 3.0642380745328834
Validation loss: 2.7824610946525894

Epoch: 5| Step: 4
Training loss: 2.778464047111297
Validation loss: 2.7769792172527743

Epoch: 5| Step: 5
Training loss: 3.228075462470828
Validation loss: 2.7966624156415008

Epoch: 5| Step: 6
Training loss: 2.465199875533537
Validation loss: 2.779635788800157

Epoch: 5| Step: 7
Training loss: 3.08209622970949
Validation loss: 2.7852876479731683

Epoch: 5| Step: 8
Training loss: 2.9208355855094146
Validation loss: 2.7886655989329143

Epoch: 5| Step: 9
Training loss: 3.393834155533908
Validation loss: 2.793662086467743

Epoch: 5| Step: 10
Training loss: 3.334512374893863
Validation loss: 2.7872310646096503

Epoch: 32| Step: 0
Training loss: 3.4010071609094163
Validation loss: 2.7843027573707353

Epoch: 5| Step: 1
Training loss: 3.0833211503346636
Validation loss: 2.768729166317175

Epoch: 5| Step: 2
Training loss: 3.1225620678367108
Validation loss: 2.7944364996438846

Epoch: 5| Step: 3
Training loss: 3.4621571615545865
Validation loss: 2.7840989543562564

Epoch: 5| Step: 4
Training loss: 2.5935479510559025
Validation loss: 2.7739226274422446

Epoch: 5| Step: 5
Training loss: 3.467950402280255
Validation loss: 2.774283654837966

Epoch: 5| Step: 6
Training loss: 2.8824479200781563
Validation loss: 2.790953200782658

Epoch: 5| Step: 7
Training loss: 3.4016785349086702
Validation loss: 2.79531189895532

Epoch: 5| Step: 8
Training loss: 2.99566655302686
Validation loss: 2.7918565900098065

Epoch: 5| Step: 9
Training loss: 3.1433054554722117
Validation loss: 2.772159179329179

Epoch: 5| Step: 10
Training loss: 3.351655829848556
Validation loss: 2.7836420737440184

Epoch: 33| Step: 0
Training loss: 2.4499958271847437
Validation loss: 2.784260900781926

Epoch: 5| Step: 1
Training loss: 3.004755383784483
Validation loss: 2.7838638271576768

Epoch: 5| Step: 2
Training loss: 3.7075526812380257
Validation loss: 2.778857074750928

Epoch: 5| Step: 3
Training loss: 3.4347455172827073
Validation loss: 2.797571609373648

Epoch: 5| Step: 4
Training loss: 3.065303531322101
Validation loss: 2.775503817128336

Epoch: 5| Step: 5
Training loss: 2.543727404144929
Validation loss: 2.781995944970667

Epoch: 5| Step: 6
Training loss: 3.767936661797395
Validation loss: 2.789401079244412

Epoch: 5| Step: 7
Training loss: 2.944939465766869
Validation loss: 2.779947454956751

Epoch: 5| Step: 8
Training loss: 3.4183307564990892
Validation loss: 2.7757108428472677

Epoch: 5| Step: 9
Training loss: 2.9727983678864596
Validation loss: 2.780082871618405

Epoch: 5| Step: 10
Training loss: 3.308084532048599
Validation loss: 2.788846170780556

Epoch: 34| Step: 0
Training loss: 4.3478707725882275
Validation loss: 2.7803679465524884

Epoch: 5| Step: 1
Training loss: 3.2682545857245233
Validation loss: 2.776131894884521

Epoch: 5| Step: 2
Training loss: 2.7687086597396067
Validation loss: 2.767547419441796

Epoch: 5| Step: 3
Training loss: 2.6298868014266072
Validation loss: 2.7899480815327213

Epoch: 5| Step: 4
Training loss: 3.2353024834509414
Validation loss: 2.7941048486084332

Epoch: 5| Step: 5
Training loss: 2.3588584688169454
Validation loss: 2.766897909841854

Epoch: 5| Step: 6
Training loss: 2.4471377059981565
Validation loss: 2.776687493999996

Epoch: 5| Step: 7
Training loss: 3.2128366019394323
Validation loss: 2.7949010955530436

Epoch: 5| Step: 8
Training loss: 3.172107857110334
Validation loss: 2.766475734121934

Epoch: 5| Step: 9
Training loss: 3.288486312450282
Validation loss: 2.7781912476613924

Epoch: 5| Step: 10
Training loss: 3.7069229415651668
Validation loss: 2.799290474525212

Epoch: 35| Step: 0
Training loss: 3.3311580394769877
Validation loss: 2.7616112190569067

Epoch: 5| Step: 1
Training loss: 2.7536552585368113
Validation loss: 2.7866878886866338

Epoch: 5| Step: 2
Training loss: 3.0698052295445173
Validation loss: 2.7821006262214847

Epoch: 5| Step: 3
Training loss: 2.7812888324898344
Validation loss: 2.7814816005979557

Epoch: 5| Step: 4
Training loss: 3.254282111066993
Validation loss: 2.7726503296443625

Epoch: 5| Step: 5
Training loss: 3.9366031412484306
Validation loss: 2.7788148667458676

Epoch: 5| Step: 6
Training loss: 2.7905469518257955
Validation loss: 2.78955533083293

Epoch: 5| Step: 7
Training loss: 2.662609878923326
Validation loss: 2.776632567945058

Epoch: 5| Step: 8
Training loss: 3.2766524302993774
Validation loss: 2.7928897919075917

Epoch: 5| Step: 9
Training loss: 2.82868808599354
Validation loss: 2.7560314065090994

Epoch: 5| Step: 10
Training loss: 4.0295283463263605
Validation loss: 2.7789075222135455

Epoch: 36| Step: 0
Training loss: 3.111956420985564
Validation loss: 2.78688423245451

Epoch: 5| Step: 1
Training loss: 3.0118889469885337
Validation loss: 2.790208236906969

Epoch: 5| Step: 2
Training loss: 3.067835616799587
Validation loss: 2.7747374992743703

Epoch: 5| Step: 3
Training loss: 3.393576747904915
Validation loss: 2.7706883250900467

Epoch: 5| Step: 4
Training loss: 3.017896202137748
Validation loss: 2.766916092196307

Epoch: 5| Step: 5
Training loss: 3.1437348867853205
Validation loss: 2.7879481031176483

Epoch: 5| Step: 6
Training loss: 3.2297914618381927
Validation loss: 2.780556657218392

Epoch: 5| Step: 7
Training loss: 3.416809234125784
Validation loss: 2.7823222592393586

Epoch: 5| Step: 8
Training loss: 3.29533646829425
Validation loss: 2.77842723090602

Epoch: 5| Step: 9
Training loss: 3.2391836199861865
Validation loss: 2.7826757280571486

Epoch: 5| Step: 10
Training loss: 2.782459638907792
Validation loss: 2.7797166036126852

Epoch: 37| Step: 0
Training loss: 3.2930753244912934
Validation loss: 2.782527473042172

Epoch: 5| Step: 1
Training loss: 3.224587785266156
Validation loss: 2.765066363074114

Epoch: 5| Step: 2
Training loss: 3.191844149071262
Validation loss: 2.7689958935463714

Epoch: 5| Step: 3
Training loss: 3.437606532440122
Validation loss: 2.7827373959661483

Epoch: 5| Step: 4
Training loss: 2.9128577475158623
Validation loss: 2.775620037836903

Epoch: 5| Step: 5
Training loss: 2.285291045036159
Validation loss: 2.783286157365056

Epoch: 5| Step: 6
Training loss: 2.730278303192647
Validation loss: 2.795793425139751

Epoch: 5| Step: 7
Training loss: 4.05176663897719
Validation loss: 2.7715726377001233

Epoch: 5| Step: 8
Training loss: 2.8640340567433964
Validation loss: 2.7649312976332765

Epoch: 5| Step: 9
Training loss: 3.314246814715606
Validation loss: 2.7780324407627486

Epoch: 5| Step: 10
Training loss: 3.212947912198239
Validation loss: 2.764072862122697

Epoch: 38| Step: 0
Training loss: 3.5016978096851825
Validation loss: 2.7752506636219856

Epoch: 5| Step: 1
Training loss: 3.203345909874634
Validation loss: 2.7636734241269787

Epoch: 5| Step: 2
Training loss: 3.2325242501726263
Validation loss: 2.749702381574444

Epoch: 5| Step: 3
Training loss: 2.816898043758102
Validation loss: 2.7619003261967197

Epoch: 5| Step: 4
Training loss: 3.3133463228253803
Validation loss: 2.76074044264954

Epoch: 5| Step: 5
Training loss: 2.721374647924323
Validation loss: 2.7682768511487006

Epoch: 5| Step: 6
Training loss: 3.042258653558064
Validation loss: 2.7568662099938765

Epoch: 5| Step: 7
Training loss: 3.6878089128833524
Validation loss: 2.7570172392366703

Epoch: 5| Step: 8
Training loss: 3.1963649965678482
Validation loss: 2.7771946947942894

Epoch: 5| Step: 9
Training loss: 2.774568397018514
Validation loss: 2.7614545719433057

Epoch: 5| Step: 10
Training loss: 3.0094889935128846
Validation loss: 2.7620608416732724

Epoch: 39| Step: 0
Training loss: 3.0415590519789033
Validation loss: 2.765024324692967

Epoch: 5| Step: 1
Training loss: 2.943217455727527
Validation loss: 2.7794670814020632

Epoch: 5| Step: 2
Training loss: 3.656716993455612
Validation loss: 2.758217882040793

Epoch: 5| Step: 3
Training loss: 2.811109410998702
Validation loss: 2.748615518608028

Epoch: 5| Step: 4
Training loss: 2.9843684490990765
Validation loss: 2.7588706654538417

Epoch: 5| Step: 5
Training loss: 3.14641026812754
Validation loss: 2.752254764307758

Epoch: 5| Step: 6
Training loss: 3.407285480421735
Validation loss: 2.776169239266533

Epoch: 5| Step: 7
Training loss: 2.8497343709199012
Validation loss: 2.7652765064562055

Epoch: 5| Step: 8
Training loss: 3.211233009421132
Validation loss: 2.7515077177437717

Epoch: 5| Step: 9
Training loss: 3.3986471177271347
Validation loss: 2.7570968964207325

Epoch: 5| Step: 10
Training loss: 2.9501321148787993
Validation loss: 2.75009386866345

Epoch: 40| Step: 0
Training loss: 3.357917504956424
Validation loss: 2.7579611070918317

Epoch: 5| Step: 1
Training loss: 3.0647495337947306
Validation loss: 2.7482059533381564

Epoch: 5| Step: 2
Training loss: 3.5435335661712757
Validation loss: 2.7622712007110484

Epoch: 5| Step: 3
Training loss: 3.4594899889848962
Validation loss: 2.768128124563119

Epoch: 5| Step: 4
Training loss: 2.630442200388783
Validation loss: 2.7584482918581106

Epoch: 5| Step: 5
Training loss: 2.764195908108197
Validation loss: 2.7520998864235264

Epoch: 5| Step: 6
Training loss: 3.3194624945993527
Validation loss: 2.7482125018778674

Epoch: 5| Step: 7
Training loss: 3.0767518674460907
Validation loss: 2.755674225597146

Epoch: 5| Step: 8
Training loss: 2.888183222276498
Validation loss: 2.761184006831189

Epoch: 5| Step: 9
Training loss: 3.360670824524191
Validation loss: 2.7577583488709907

Epoch: 5| Step: 10
Training loss: 2.934815499064601
Validation loss: 2.7517521125125755

Epoch: 41| Step: 0
Training loss: 2.5959627754998733
Validation loss: 2.7417070568406126

Epoch: 5| Step: 1
Training loss: 3.7350090478177256
Validation loss: 2.7680468269377383

Epoch: 5| Step: 2
Training loss: 2.3668710226383642
Validation loss: 2.746975998943857

Epoch: 5| Step: 3
Training loss: 2.879576813282846
Validation loss: 2.7557756176580988

Epoch: 5| Step: 4
Training loss: 3.0478116674235314
Validation loss: 2.761323509543023

Epoch: 5| Step: 5
Training loss: 3.318118530658013
Validation loss: 2.7503019746936976

Epoch: 5| Step: 6
Training loss: 3.113058237777905
Validation loss: 2.751828673571862

Epoch: 5| Step: 7
Training loss: 2.890055007411073
Validation loss: 2.771252123000206

Epoch: 5| Step: 8
Training loss: 3.412129498724287
Validation loss: 2.7639324630501743

Epoch: 5| Step: 9
Training loss: 3.597609330160246
Validation loss: 2.760899941939739

Epoch: 5| Step: 10
Training loss: 3.2792983290832094
Validation loss: 2.755950832028908

Epoch: 42| Step: 0
Training loss: 3.469800085635676
Validation loss: 2.7539115599091835

Epoch: 5| Step: 1
Training loss: 2.952108702800738
Validation loss: 2.758005315754205

Epoch: 5| Step: 2
Training loss: 3.1814520811039024
Validation loss: 2.7440750492011725

Epoch: 5| Step: 3
Training loss: 2.5035038236356852
Validation loss: 2.7500520647178637

Epoch: 5| Step: 4
Training loss: 3.5342719726656604
Validation loss: 2.744730260336106

Epoch: 5| Step: 5
Training loss: 3.4395525266460356
Validation loss: 2.7446351228612467

Epoch: 5| Step: 6
Training loss: 3.6126072270408356
Validation loss: 2.7552185939248295

Epoch: 5| Step: 7
Training loss: 2.9088592301577645
Validation loss: 2.7633619764852786

Epoch: 5| Step: 8
Training loss: 2.470773278246869
Validation loss: 2.750602969294248

Epoch: 5| Step: 9
Training loss: 3.4840119176982696
Validation loss: 2.757251177491737

Epoch: 5| Step: 10
Training loss: 2.311152813251948
Validation loss: 2.7344595947305717

Epoch: 43| Step: 0
Training loss: 3.547133247283899
Validation loss: 2.7484118349452595

Epoch: 5| Step: 1
Training loss: 3.2300421399653825
Validation loss: 2.750155995438784

Epoch: 5| Step: 2
Training loss: 2.863589823125837
Validation loss: 2.756720079882445

Epoch: 5| Step: 3
Training loss: 3.3112136934449317
Validation loss: 2.752343990162252

Epoch: 5| Step: 4
Training loss: 2.725484990348908
Validation loss: 2.7624595365547684

Epoch: 5| Step: 5
Training loss: 3.1248162787791296
Validation loss: 2.74191873805888

Epoch: 5| Step: 6
Training loss: 2.96746814559641
Validation loss: 2.741612166983783

Epoch: 5| Step: 7
Training loss: 3.273378358001682
Validation loss: 2.7368152934220853

Epoch: 5| Step: 8
Training loss: 2.7877550667015503
Validation loss: 2.7302848628067147

Epoch: 5| Step: 9
Training loss: 3.6486319708610053
Validation loss: 2.750324814595003

Epoch: 5| Step: 10
Training loss: 2.859497067706944
Validation loss: 2.7519229279496304

Epoch: 44| Step: 0
Training loss: 2.974515436283442
Validation loss: 2.734822966040079

Epoch: 5| Step: 1
Training loss: 2.7387704453081687
Validation loss: 2.7462609117275387

Epoch: 5| Step: 2
Training loss: 2.6969431491697256
Validation loss: 2.7367432026600595

Epoch: 5| Step: 3
Training loss: 3.118053038854983
Validation loss: 2.750502745500899

Epoch: 5| Step: 4
Training loss: 3.440266692225365
Validation loss: 2.729300803694294

Epoch: 5| Step: 5
Training loss: 2.8508818349658895
Validation loss: 2.7333146826652768

Epoch: 5| Step: 6
Training loss: 3.3259760406420256
Validation loss: 2.7382198911595146

Epoch: 5| Step: 7
Training loss: 3.2179364407689306
Validation loss: 2.7408030961477623

Epoch: 5| Step: 8
Training loss: 3.308939045404308
Validation loss: 2.7631129647408135

Epoch: 5| Step: 9
Training loss: 3.1188787399354574
Validation loss: 2.7369573078719065

Epoch: 5| Step: 10
Training loss: 3.455039895872097
Validation loss: 2.7236714301513403

Epoch: 45| Step: 0
Training loss: 3.2649782261261158
Validation loss: 2.746644378865978

Epoch: 5| Step: 1
Training loss: 3.0206670956526787
Validation loss: 2.733126168975419

Epoch: 5| Step: 2
Training loss: 3.4962680538776527
Validation loss: 2.7471890406933834

Epoch: 5| Step: 3
Training loss: 2.3157743006875378
Validation loss: 2.74054257072987

Epoch: 5| Step: 4
Training loss: 3.2284004204717767
Validation loss: 2.73493216608468

Epoch: 5| Step: 5
Training loss: 3.540345757188743
Validation loss: 2.740307730904706

Epoch: 5| Step: 6
Training loss: 3.8204532901587944
Validation loss: 2.754522657038398

Epoch: 5| Step: 7
Training loss: 3.219545728969808
Validation loss: 2.7399633331126885

Epoch: 5| Step: 8
Training loss: 3.1196765570614384
Validation loss: 2.73863707196312

Epoch: 5| Step: 9
Training loss: 2.233620149310314
Validation loss: 2.7447494114727284

Epoch: 5| Step: 10
Training loss: 2.690076701690906
Validation loss: 2.7433506795236866

Epoch: 46| Step: 0
Training loss: 3.397964199036978
Validation loss: 2.744393042446613

Epoch: 5| Step: 1
Training loss: 2.8917916907583883
Validation loss: 2.7405113480362933

Epoch: 5| Step: 2
Training loss: 2.717949935878671
Validation loss: 2.750616929183199

Epoch: 5| Step: 3
Training loss: 3.212864058828237
Validation loss: 2.7201657256638234

Epoch: 5| Step: 4
Training loss: 3.2818716277797315
Validation loss: 2.728082206719439

Epoch: 5| Step: 5
Training loss: 2.603602254103111
Validation loss: 2.7332939286796907

Epoch: 5| Step: 6
Training loss: 2.601836410628485
Validation loss: 2.729489615867299

Epoch: 5| Step: 7
Training loss: 3.068713832416785
Validation loss: 2.706249869423655

Epoch: 5| Step: 8
Training loss: 3.5825470497891074
Validation loss: 2.7279773579693134

Epoch: 5| Step: 9
Training loss: 3.2937688432476593
Validation loss: 2.7353913455494046

Epoch: 5| Step: 10
Training loss: 3.406333712327847
Validation loss: 2.730554476914455

Epoch: 47| Step: 0
Training loss: 2.6797752254795997
Validation loss: 2.725742038819605

Epoch: 5| Step: 1
Training loss: 3.431646461025914
Validation loss: 2.743668538078209

Epoch: 5| Step: 2
Training loss: 2.896714513256955
Validation loss: 2.7249901991042584

Epoch: 5| Step: 3
Training loss: 2.6050973882061634
Validation loss: 2.71989718081502

Epoch: 5| Step: 4
Training loss: 2.467273608704795
Validation loss: 2.7223889895062023

Epoch: 5| Step: 5
Training loss: 3.046849646829614
Validation loss: 2.738217637620429

Epoch: 5| Step: 6
Training loss: 2.91591554688446
Validation loss: 2.729045712751951

Epoch: 5| Step: 7
Training loss: 4.051810182649921
Validation loss: 2.723480885488348

Epoch: 5| Step: 8
Training loss: 3.29446887399823
Validation loss: 2.7272426919053885

Epoch: 5| Step: 9
Training loss: 2.759298210760439
Validation loss: 2.7403150813556176

Epoch: 5| Step: 10
Training loss: 3.614631029560057
Validation loss: 2.7278062469653337

Epoch: 48| Step: 0
Training loss: 3.5997470078052203
Validation loss: 2.7185029504703904

Epoch: 5| Step: 1
Training loss: 2.971899831128601
Validation loss: 2.727317479168231

Epoch: 5| Step: 2
Training loss: 3.048165541991891
Validation loss: 2.723023703528902

Epoch: 5| Step: 3
Training loss: 3.107622122171778
Validation loss: 2.711769656453509

Epoch: 5| Step: 4
Training loss: 3.2170414510279217
Validation loss: 2.729672917055073

Epoch: 5| Step: 5
Training loss: 2.496750531776458
Validation loss: 2.7185453989271666

Epoch: 5| Step: 6
Training loss: 3.069721970782578
Validation loss: 2.719083803943917

Epoch: 5| Step: 7
Training loss: 3.1539354052269744
Validation loss: 2.736581913199969

Epoch: 5| Step: 8
Training loss: 2.543114723902932
Validation loss: 2.7275447263904433

Epoch: 5| Step: 9
Training loss: 3.0625862576540257
Validation loss: 2.7216679773604526

Epoch: 5| Step: 10
Training loss: 3.7267791237238526
Validation loss: 2.717699498821145

Epoch: 49| Step: 0
Training loss: 3.0195672550004087
Validation loss: 2.7315617409596387

Epoch: 5| Step: 1
Training loss: 3.129520198865932
Validation loss: 2.718172263982559

Epoch: 5| Step: 2
Training loss: 3.2039822059451555
Validation loss: 2.720148108248409

Epoch: 5| Step: 3
Training loss: 2.655547105127542
Validation loss: 2.698452486331164

Epoch: 5| Step: 4
Training loss: 2.9347081004465605
Validation loss: 2.715739777834622

Epoch: 5| Step: 5
Training loss: 3.0459424278945018
Validation loss: 2.7273082654085026

Epoch: 5| Step: 6
Training loss: 3.2737815512250665
Validation loss: 2.7087361404584764

Epoch: 5| Step: 7
Training loss: 3.426459181202481
Validation loss: 2.7251089588895474

Epoch: 5| Step: 8
Training loss: 3.6821164418156127
Validation loss: 2.7042578953158984

Epoch: 5| Step: 9
Training loss: 2.6530356312360204
Validation loss: 2.7234278007173973

Epoch: 5| Step: 10
Training loss: 2.6781458743694033
Validation loss: 2.715362373226472

Epoch: 50| Step: 0
Training loss: 2.689312257311873
Validation loss: 2.708289470901145

Epoch: 5| Step: 1
Training loss: 2.436550053086094
Validation loss: 2.708496160479527

Epoch: 5| Step: 2
Training loss: 3.258195081608733
Validation loss: 2.7220214258082343

Epoch: 5| Step: 3
Training loss: 2.435462589227979
Validation loss: 2.713382654800257

Epoch: 5| Step: 4
Training loss: 3.110221862484172
Validation loss: 2.714876326439816

Epoch: 5| Step: 5
Training loss: 3.171365330530745
Validation loss: 2.7129897908463922

Epoch: 5| Step: 6
Training loss: 3.541399119126121
Validation loss: 2.71062359646388

Epoch: 5| Step: 7
Training loss: 3.574590411431367
Validation loss: 2.710781571316369

Epoch: 5| Step: 8
Training loss: 2.885037026523088
Validation loss: 2.7135587585476526

Epoch: 5| Step: 9
Training loss: 3.323988945769327
Validation loss: 2.717749780699756

Epoch: 5| Step: 10
Training loss: 3.2640363853801397
Validation loss: 2.7158517595840648

Epoch: 51| Step: 0
Training loss: 2.643604831903434
Validation loss: 2.7244412612051097

Epoch: 5| Step: 1
Training loss: 3.216137316405516
Validation loss: 2.7031024166322988

Epoch: 5| Step: 2
Training loss: 3.2796875639720544
Validation loss: 2.705527531595913

Epoch: 5| Step: 3
Training loss: 3.571541806197022
Validation loss: 2.6966365786910527

Epoch: 5| Step: 4
Training loss: 3.1545453897845466
Validation loss: 2.7064449378115643

Epoch: 5| Step: 5
Training loss: 3.3623710579239394
Validation loss: 2.7178084520917487

Epoch: 5| Step: 6
Training loss: 2.7457229993434398
Validation loss: 2.7122312601012464

Epoch: 5| Step: 7
Training loss: 3.061291047300426
Validation loss: 2.7301198639132718

Epoch: 5| Step: 8
Training loss: 2.955739312287562
Validation loss: 2.724520999496806

Epoch: 5| Step: 9
Training loss: 2.820949070489341
Validation loss: 2.7127972702269316

Epoch: 5| Step: 10
Training loss: 3.0896042298124526
Validation loss: 2.703802838095959

Epoch: 52| Step: 0
Training loss: 3.2050101338671175
Validation loss: 2.696999268499195

Epoch: 5| Step: 1
Training loss: 2.6641025931733795
Validation loss: 2.7175103910477896

Epoch: 5| Step: 2
Training loss: 3.1606221651287463
Validation loss: 2.708284205013996

Epoch: 5| Step: 3
Training loss: 3.851614620947098
Validation loss: 2.7173278845920876

Epoch: 5| Step: 4
Training loss: 2.3694636414815955
Validation loss: 2.7094721013171488

Epoch: 5| Step: 5
Training loss: 2.953993089434083
Validation loss: 2.703287622749053

Epoch: 5| Step: 6
Training loss: 2.8780257846825075
Validation loss: 2.715387354650627

Epoch: 5| Step: 7
Training loss: 2.7980386881140697
Validation loss: 2.723619767576878

Epoch: 5| Step: 8
Training loss: 3.143390405918195
Validation loss: 2.7072282241905

Epoch: 5| Step: 9
Training loss: 3.057852819739286
Validation loss: 2.708999086878543

Epoch: 5| Step: 10
Training loss: 3.482200320262258
Validation loss: 2.700310861093837

Epoch: 53| Step: 0
Training loss: 2.6843740336690636
Validation loss: 2.7068855852434606

Epoch: 5| Step: 1
Training loss: 2.833834790752075
Validation loss: 2.69426583346963

Epoch: 5| Step: 2
Training loss: 3.0213767428914506
Validation loss: 2.7013275659440046

Epoch: 5| Step: 3
Training loss: 3.3922251779650505
Validation loss: 2.6849233280717697

Epoch: 5| Step: 4
Training loss: 2.9181878800438574
Validation loss: 2.697726816755837

Epoch: 5| Step: 5
Training loss: 3.084690740284316
Validation loss: 2.7012298995112136

Epoch: 5| Step: 6
Training loss: 2.7517820999575844
Validation loss: 2.71710926807454

Epoch: 5| Step: 7
Training loss: 3.7469700334346845
Validation loss: 2.6823913523836125

Epoch: 5| Step: 8
Training loss: 2.8243918886838344
Validation loss: 2.7119066156907103

Epoch: 5| Step: 9
Training loss: 3.0368019463576097
Validation loss: 2.6934204613386674

Epoch: 5| Step: 10
Training loss: 3.44723201227416
Validation loss: 2.7000669847821155

Epoch: 54| Step: 0
Training loss: 2.7150973633788813
Validation loss: 2.6905056019046323

Epoch: 5| Step: 1
Training loss: 3.6837279860631913
Validation loss: 2.696817635476366

Epoch: 5| Step: 2
Training loss: 3.201240096607552
Validation loss: 2.7068446123035

Epoch: 5| Step: 3
Training loss: 3.072846820274578
Validation loss: 2.7057896367613403

Epoch: 5| Step: 4
Training loss: 2.8524701907767622
Validation loss: 2.7074295511152195

Epoch: 5| Step: 5
Training loss: 3.0922036978676624
Validation loss: 2.6866324231806145

Epoch: 5| Step: 6
Training loss: 3.0224574666781363
Validation loss: 2.6769084647467567

Epoch: 5| Step: 7
Training loss: 2.6226479119698687
Validation loss: 2.691034875026378

Epoch: 5| Step: 8
Training loss: 3.4930888469938988
Validation loss: 2.6795586905100186

Epoch: 5| Step: 9
Training loss: 3.0457982434827233
Validation loss: 2.681124316791585

Epoch: 5| Step: 10
Training loss: 2.7808789637953137
Validation loss: 2.6941336892111667

Epoch: 55| Step: 0
Training loss: 3.464689885693714
Validation loss: 2.6857428256652667

Epoch: 5| Step: 1
Training loss: 2.6485610978084804
Validation loss: 2.7046317025096442

Epoch: 5| Step: 2
Training loss: 3.441648165181256
Validation loss: 2.694876128937778

Epoch: 5| Step: 3
Training loss: 2.993300109061521
Validation loss: 2.6968882682448334

Epoch: 5| Step: 4
Training loss: 3.3625958283677293
Validation loss: 2.701777841207061

Epoch: 5| Step: 5
Training loss: 3.346979595868659
Validation loss: 2.6952043884671206

Epoch: 5| Step: 6
Training loss: 3.2642894003138667
Validation loss: 2.697349292616165

Epoch: 5| Step: 7
Training loss: 2.9250563982881603
Validation loss: 2.6758539565851978

Epoch: 5| Step: 8
Training loss: 2.725987239804983
Validation loss: 2.692087378717347

Epoch: 5| Step: 9
Training loss: 2.410644283993936
Validation loss: 2.7140300356059357

Epoch: 5| Step: 10
Training loss: 2.9809246789424786
Validation loss: 2.6839797222476744

Epoch: 56| Step: 0
Training loss: 2.551511230701187
Validation loss: 2.696141645920865

Epoch: 5| Step: 1
Training loss: 3.046330329922201
Validation loss: 2.688486259298169

Epoch: 5| Step: 2
Training loss: 2.7747798626161724
Validation loss: 2.6977707372068083

Epoch: 5| Step: 3
Training loss: 2.7075897565425024
Validation loss: 2.665808553706266

Epoch: 5| Step: 4
Training loss: 3.1866528750431082
Validation loss: 2.6801728212984988

Epoch: 5| Step: 5
Training loss: 2.1291074885177483
Validation loss: 2.677659069340417

Epoch: 5| Step: 6
Training loss: 3.3263180981144527
Validation loss: 2.7054346305982677

Epoch: 5| Step: 7
Training loss: 3.7479205405932867
Validation loss: 2.6913599491058497

Epoch: 5| Step: 8
Training loss: 2.6091332237937555
Validation loss: 2.692363165088184

Epoch: 5| Step: 9
Training loss: 3.5562302144711992
Validation loss: 2.69778115701932

Epoch: 5| Step: 10
Training loss: 3.6350010995981266
Validation loss: 2.6930804550174368

Epoch: 57| Step: 0
Training loss: 2.6871219635269434
Validation loss: 2.706717887945182

Epoch: 5| Step: 1
Training loss: 2.825664820129984
Validation loss: 2.704937892850823

Epoch: 5| Step: 2
Training loss: 3.2415556142526643
Validation loss: 2.679220412819207

Epoch: 5| Step: 3
Training loss: 3.6539547228416978
Validation loss: 2.693363869573243

Epoch: 5| Step: 4
Training loss: 3.3930572364717255
Validation loss: 2.691927856344507

Epoch: 5| Step: 5
Training loss: 2.6958853734775023
Validation loss: 2.6999742548105186

Epoch: 5| Step: 6
Training loss: 3.0096404627001014
Validation loss: 2.6874766023251224

Epoch: 5| Step: 7
Training loss: 3.333412805245666
Validation loss: 2.6827321792443297

Epoch: 5| Step: 8
Training loss: 3.1544971697727044
Validation loss: 2.701196830115265

Epoch: 5| Step: 9
Training loss: 2.4841989898711527
Validation loss: 2.6931025988650803

Epoch: 5| Step: 10
Training loss: 2.9480489065391504
Validation loss: 2.6949559129668934

Epoch: 58| Step: 0
Training loss: 2.8900632570201013
Validation loss: 2.6682507869104133

Epoch: 5| Step: 1
Training loss: 3.083045241497537
Validation loss: 2.696882999107772

Epoch: 5| Step: 2
Training loss: 3.5406926928898246
Validation loss: 2.6815395302260803

Epoch: 5| Step: 3
Training loss: 2.1961086363611875
Validation loss: 2.6903649903855373

Epoch: 5| Step: 4
Training loss: 2.564637571908386
Validation loss: 2.691473061411162

Epoch: 5| Step: 5
Training loss: 2.82302945370364
Validation loss: 2.695425287603277

Epoch: 5| Step: 6
Training loss: 2.9049781559502046
Validation loss: 2.6814707733538063

Epoch: 5| Step: 7
Training loss: 3.086949744979232
Validation loss: 2.6813739994525956

Epoch: 5| Step: 8
Training loss: 3.495838552356654
Validation loss: 2.687910006231566

Epoch: 5| Step: 9
Training loss: 3.331842057110492
Validation loss: 2.682030187506433

Epoch: 5| Step: 10
Training loss: 3.4285099727935635
Validation loss: 2.6900637170470345

Epoch: 59| Step: 0
Training loss: 3.3734558246321575
Validation loss: 2.6848380013540942

Epoch: 5| Step: 1
Training loss: 3.3843507154725887
Validation loss: 2.688315995258765

Epoch: 5| Step: 2
Training loss: 2.3826353914072187
Validation loss: 2.6709581495663857

Epoch: 5| Step: 3
Training loss: 2.8747453991482996
Validation loss: 2.667183884201551

Epoch: 5| Step: 4
Training loss: 3.7921859609178736
Validation loss: 2.68113901134382

Epoch: 5| Step: 5
Training loss: 2.1183259162602908
Validation loss: 2.697817875490637

Epoch: 5| Step: 6
Training loss: 3.540780902874484
Validation loss: 2.6654519610736025

Epoch: 5| Step: 7
Training loss: 3.3494812521050368
Validation loss: 2.705001222595299

Epoch: 5| Step: 8
Training loss: 2.331826154677318
Validation loss: 2.6770830396617984

Epoch: 5| Step: 9
Training loss: 2.836185833275313
Validation loss: 2.7028781423211865

Epoch: 5| Step: 10
Training loss: 3.0080498143494747
Validation loss: 2.6922977060073965

Epoch: 60| Step: 0
Training loss: 3.442990997914277
Validation loss: 2.6680748231282103

Epoch: 5| Step: 1
Training loss: 2.523802172880615
Validation loss: 2.6788294359008944

Epoch: 5| Step: 2
Training loss: 3.0707550894622004
Validation loss: 2.7021649607332097

Epoch: 5| Step: 3
Training loss: 3.0133028725403883
Validation loss: 2.6660948048533153

Epoch: 5| Step: 4
Training loss: 3.0272579057889373
Validation loss: 2.684469570622939

Epoch: 5| Step: 5
Training loss: 2.1081627647349115
Validation loss: 2.6796968908906855

Epoch: 5| Step: 6
Training loss: 3.368983380614969
Validation loss: 2.6699498894477176

Epoch: 5| Step: 7
Training loss: 2.5324184405344594
Validation loss: 2.690097967781431

Epoch: 5| Step: 8
Training loss: 3.7963030348996227
Validation loss: 2.6647899532919577

Epoch: 5| Step: 9
Training loss: 3.3369189210163634
Validation loss: 2.674912304763797

Epoch: 5| Step: 10
Training loss: 2.781403955206099
Validation loss: 2.6856740637647776

Epoch: 61| Step: 0
Training loss: 2.57734307655957
Validation loss: 2.66262596487533

Epoch: 5| Step: 1
Training loss: 2.4905277094391813
Validation loss: 2.650303228872216

Epoch: 5| Step: 2
Training loss: 2.973947893559737
Validation loss: 2.6770875797562845

Epoch: 5| Step: 3
Training loss: 3.8359609941124337
Validation loss: 2.675091590804558

Epoch: 5| Step: 4
Training loss: 3.0411589385987927
Validation loss: 2.6738420907039386

Epoch: 5| Step: 5
Training loss: 3.5692881109996892
Validation loss: 2.6762621528940516

Epoch: 5| Step: 6
Training loss: 2.754866715268905
Validation loss: 2.6836658914749587

Epoch: 5| Step: 7
Training loss: 2.986196072180517
Validation loss: 2.6846243270086934

Epoch: 5| Step: 8
Training loss: 3.387025249476062
Validation loss: 2.6616924625919736

Epoch: 5| Step: 9
Training loss: 2.4901573977073106
Validation loss: 2.674558786418301

Epoch: 5| Step: 10
Training loss: 2.94453140546232
Validation loss: 2.6717658959433996

Epoch: 62| Step: 0
Training loss: 2.995351687052119
Validation loss: 2.6634278102371423

Epoch: 5| Step: 1
Training loss: 2.919779796397023
Validation loss: 2.6717612134308775

Epoch: 5| Step: 2
Training loss: 2.9824807111910974
Validation loss: 2.6570867215906944

Epoch: 5| Step: 3
Training loss: 2.4545476396467456
Validation loss: 2.6688245309065763

Epoch: 5| Step: 4
Training loss: 3.322262467389005
Validation loss: 2.6643013795791224

Epoch: 5| Step: 5
Training loss: 3.3554028114883243
Validation loss: 2.6823352839245547

Epoch: 5| Step: 6
Training loss: 3.206696691498067
Validation loss: 2.665145973665589

Epoch: 5| Step: 7
Training loss: 3.136760402607164
Validation loss: 2.6507153124721183

Epoch: 5| Step: 8
Training loss: 3.1815496517169635
Validation loss: 2.667183012412227

Epoch: 5| Step: 9
Training loss: 2.5096198963649767
Validation loss: 2.6613837012262893

Epoch: 5| Step: 10
Training loss: 3.096038896419832
Validation loss: 2.677764107591218

Epoch: 63| Step: 0
Training loss: 3.461835275461019
Validation loss: 2.6581466418173485

Epoch: 5| Step: 1
Training loss: 3.173456859294794
Validation loss: 2.6721074333573993

Epoch: 5| Step: 2
Training loss: 3.1556961026778314
Validation loss: 2.6634722914635316

Epoch: 5| Step: 3
Training loss: 2.9172450627438753
Validation loss: 2.6596997476960844

Epoch: 5| Step: 4
Training loss: 2.306852610357208
Validation loss: 2.670498507604287

Epoch: 5| Step: 5
Training loss: 3.1247019816392183
Validation loss: 2.648242200917224

Epoch: 5| Step: 6
Training loss: 3.02287961558993
Validation loss: 2.663946948722447

Epoch: 5| Step: 7
Training loss: 2.6534439524238653
Validation loss: 2.668014875494403

Epoch: 5| Step: 8
Training loss: 3.387417308741214
Validation loss: 2.665082097015606

Epoch: 5| Step: 9
Training loss: 3.082991108503212
Validation loss: 2.656677305342019

Epoch: 5| Step: 10
Training loss: 2.6613392265129714
Validation loss: 2.662766623994354

Epoch: 64| Step: 0
Training loss: 3.1509670952834594
Validation loss: 2.6645045462378456

Epoch: 5| Step: 1
Training loss: 3.0385724533102896
Validation loss: 2.6391841362372994

Epoch: 5| Step: 2
Training loss: 3.5332595373640503
Validation loss: 2.6593070084747223

Epoch: 5| Step: 3
Training loss: 3.196896633697726
Validation loss: 2.6485925333161955

Epoch: 5| Step: 4
Training loss: 2.902031903565418
Validation loss: 2.6380736089187833

Epoch: 5| Step: 5
Training loss: 2.637358140068272
Validation loss: 2.654579325345467

Epoch: 5| Step: 6
Training loss: 3.31314037538914
Validation loss: 2.6647929067601583

Epoch: 5| Step: 7
Training loss: 2.359073240675373
Validation loss: 2.6454066645581342

Epoch: 5| Step: 8
Training loss: 2.646404104669425
Validation loss: 2.647849046582088

Epoch: 5| Step: 9
Training loss: 3.1924793022279423
Validation loss: 2.6678882122428056

Epoch: 5| Step: 10
Training loss: 3.1467694201368333
Validation loss: 2.637867261717598

Epoch: 65| Step: 0
Training loss: 2.9526087395446505
Validation loss: 2.6541150155198507

Epoch: 5| Step: 1
Training loss: 3.002519185610799
Validation loss: 2.6604660596076846

Epoch: 5| Step: 2
Training loss: 3.2721543448776464
Validation loss: 2.6490941500621843

Epoch: 5| Step: 3
Training loss: 2.8714886659733616
Validation loss: 2.647311256569329

Epoch: 5| Step: 4
Training loss: 2.7722763854677037
Validation loss: 2.6473618493521136

Epoch: 5| Step: 5
Training loss: 2.9582168842732632
Validation loss: 2.6463204606329143

Epoch: 5| Step: 6
Training loss: 2.684777588680968
Validation loss: 2.644808102516968

Epoch: 5| Step: 7
Training loss: 2.966855056724596
Validation loss: 2.640319841536703

Epoch: 5| Step: 8
Training loss: 3.05741787616921
Validation loss: 2.6501981682416975

Epoch: 5| Step: 9
Training loss: 3.3813129299322404
Validation loss: 2.6444527254833523

Epoch: 5| Step: 10
Training loss: 3.0955558669628758
Validation loss: 2.6705268299150378

Epoch: 66| Step: 0
Training loss: 2.5684976866869307
Validation loss: 2.6551227626772813

Epoch: 5| Step: 1
Training loss: 3.2750991573319492
Validation loss: 2.657602078744082

Epoch: 5| Step: 2
Training loss: 3.5606395481288495
Validation loss: 2.6411779477279334

Epoch: 5| Step: 3
Training loss: 2.6608115130002807
Validation loss: 2.6579792066759365

Epoch: 5| Step: 4
Training loss: 3.0864452089272474
Validation loss: 2.663921106700359

Epoch: 5| Step: 5
Training loss: 3.0821369186872065
Validation loss: 2.6515962256917667

Epoch: 5| Step: 6
Training loss: 3.053981533571783
Validation loss: 2.6552879352621312

Epoch: 5| Step: 7
Training loss: 3.5051523159741165
Validation loss: 2.646673319324094

Epoch: 5| Step: 8
Training loss: 2.3713053022902644
Validation loss: 2.65777393807021

Epoch: 5| Step: 9
Training loss: 2.6335175699256648
Validation loss: 2.6606254294588285

Epoch: 5| Step: 10
Training loss: 2.9390004972319232
Validation loss: 2.6395538442906448

Epoch: 67| Step: 0
Training loss: 2.4811817496111144
Validation loss: 2.6560906089141203

Epoch: 5| Step: 1
Training loss: 2.770429844745794
Validation loss: 2.6538063501602

Epoch: 5| Step: 2
Training loss: 3.231614856301378
Validation loss: 2.653093262951281

Epoch: 5| Step: 3
Training loss: 3.0178830878463763
Validation loss: 2.6455889055944457

Epoch: 5| Step: 4
Training loss: 2.9529812893893177
Validation loss: 2.6522377775055075

Epoch: 5| Step: 5
Training loss: 2.965076140894407
Validation loss: 2.645387287506232

Epoch: 5| Step: 6
Training loss: 3.2489472664932717
Validation loss: 2.6556184600614476

Epoch: 5| Step: 7
Training loss: 3.4143443395001563
Validation loss: 2.6317923447386695

Epoch: 5| Step: 8
Training loss: 2.7932724580830723
Validation loss: 2.6715288257606327

Epoch: 5| Step: 9
Training loss: 2.960794168591368
Validation loss: 2.6497899351253844

Epoch: 5| Step: 10
Training loss: 3.1153015703470093
Validation loss: 2.658337702442022

Epoch: 68| Step: 0
Training loss: 2.8291327435609093
Validation loss: 2.6534453649434737

Epoch: 5| Step: 1
Training loss: 2.88448758551349
Validation loss: 2.6516622109630723

Epoch: 5| Step: 2
Training loss: 2.9278715074830477
Validation loss: 2.6439670191004114

Epoch: 5| Step: 3
Training loss: 2.993227785312716
Validation loss: 2.6399468108490463

Epoch: 5| Step: 4
Training loss: 3.585404499808368
Validation loss: 2.655005493675935

Epoch: 5| Step: 5
Training loss: 2.0831282196798315
Validation loss: 2.6483239009683035

Epoch: 5| Step: 6
Training loss: 3.346401126200582
Validation loss: 2.6537879917765337

Epoch: 5| Step: 7
Training loss: 2.6449345741761485
Validation loss: 2.6312381699982805

Epoch: 5| Step: 8
Training loss: 2.819064722866903
Validation loss: 2.6433077414328103

Epoch: 5| Step: 9
Training loss: 3.423980622450641
Validation loss: 2.628327080184953

Epoch: 5| Step: 10
Training loss: 3.2727905216752093
Validation loss: 2.6448118857336915

Epoch: 69| Step: 0
Training loss: 3.1892010506825694
Validation loss: 2.6552652419232996

Epoch: 5| Step: 1
Training loss: 2.87511112164243
Validation loss: 2.6404514914702024

Epoch: 5| Step: 2
Training loss: 2.6570802176544346
Validation loss: 2.6505698384066223

Epoch: 5| Step: 3
Training loss: 3.510665175398372
Validation loss: 2.6512913108400142

Epoch: 5| Step: 4
Training loss: 2.4348294226961675
Validation loss: 2.647687660580239

Epoch: 5| Step: 5
Training loss: 2.8987952985756746
Validation loss: 2.65088292547637

Epoch: 5| Step: 6
Training loss: 3.1865955640396733
Validation loss: 2.647969439195196

Epoch: 5| Step: 7
Training loss: 3.1139994980965406
Validation loss: 2.6330969312298507

Epoch: 5| Step: 8
Training loss: 1.7973149300113216
Validation loss: 2.6445501079066602

Epoch: 5| Step: 9
Training loss: 3.1639853385653116
Validation loss: 2.6409830626206214

Epoch: 5| Step: 10
Training loss: 3.7113149993025183
Validation loss: 2.6463614823167716

Epoch: 70| Step: 0
Training loss: 2.756546291765963
Validation loss: 2.6370413643841464

Epoch: 5| Step: 1
Training loss: 3.499132866389956
Validation loss: 2.6488526757238113

Epoch: 5| Step: 2
Training loss: 2.9803428373325693
Validation loss: 2.6384353272380543

Epoch: 5| Step: 3
Training loss: 3.0776061574443463
Validation loss: 2.6370244243459053

Epoch: 5| Step: 4
Training loss: 3.49438598521919
Validation loss: 2.636087167829963

Epoch: 5| Step: 5
Training loss: 3.298699908929632
Validation loss: 2.638287587320542

Epoch: 5| Step: 6
Training loss: 2.0982852610726495
Validation loss: 2.6378338003269537

Epoch: 5| Step: 7
Training loss: 3.12183708343544
Validation loss: 2.6337067650685273

Epoch: 5| Step: 8
Training loss: 2.515902296622407
Validation loss: 2.634025492214942

Epoch: 5| Step: 9
Training loss: 2.577187477501288
Validation loss: 2.6383885068053288

Epoch: 5| Step: 10
Training loss: 3.117123251804997
Validation loss: 2.6198635118785254

Epoch: 71| Step: 0
Training loss: 2.27041130927309
Validation loss: 2.636851385708446

Epoch: 5| Step: 1
Training loss: 2.982209223652441
Validation loss: 2.651849878600848

Epoch: 5| Step: 2
Training loss: 3.0419047188468085
Validation loss: 2.6252847684048723

Epoch: 5| Step: 3
Training loss: 2.9824957398146767
Validation loss: 2.639154755829468

Epoch: 5| Step: 4
Training loss: 2.744559541812173
Validation loss: 2.6342440985487765

Epoch: 5| Step: 5
Training loss: 2.814074774783664
Validation loss: 2.6471092752617436

Epoch: 5| Step: 6
Training loss: 3.4228507266404113
Validation loss: 2.641743408990006

Epoch: 5| Step: 7
Training loss: 3.2144008252558165
Validation loss: 2.643346061326236

Epoch: 5| Step: 8
Training loss: 3.3736165354767844
Validation loss: 2.6433703316301957

Epoch: 5| Step: 9
Training loss: 2.791203379739261
Validation loss: 2.640404928160077

Epoch: 5| Step: 10
Training loss: 2.9939339025791294
Validation loss: 2.6404200726371716

Epoch: 72| Step: 0
Training loss: 2.6705637608815556
Validation loss: 2.628727095682252

Epoch: 5| Step: 1
Training loss: 2.6753673372551496
Validation loss: 2.623411878923058

Epoch: 5| Step: 2
Training loss: 2.9854499518665687
Validation loss: 2.635013426093687

Epoch: 5| Step: 3
Training loss: 3.3033574451088774
Validation loss: 2.614529868030586

Epoch: 5| Step: 4
Training loss: 2.979757041499724
Validation loss: 2.6408361049711555

Epoch: 5| Step: 5
Training loss: 3.4826462909234848
Validation loss: 2.6476830458660117

Epoch: 5| Step: 6
Training loss: 2.5599808754802655
Validation loss: 2.6345789570712457

Epoch: 5| Step: 7
Training loss: 2.770128107792407
Validation loss: 2.6298092443787535

Epoch: 5| Step: 8
Training loss: 3.5153723053715855
Validation loss: 2.6249865362131666

Epoch: 5| Step: 9
Training loss: 2.8007231936429684
Validation loss: 2.6351199969042045

Epoch: 5| Step: 10
Training loss: 2.8724365415942335
Validation loss: 2.6291269606096734

Epoch: 73| Step: 0
Training loss: 2.689016490943876
Validation loss: 2.625934621957659

Epoch: 5| Step: 1
Training loss: 2.6901388298428253
Validation loss: 2.625861166794689

Epoch: 5| Step: 2
Training loss: 2.9595551094586585
Validation loss: 2.632580152641378

Epoch: 5| Step: 3
Training loss: 3.5323114740882615
Validation loss: 2.616849032246205

Epoch: 5| Step: 4
Training loss: 2.4653814004483188
Validation loss: 2.6246217297875263

Epoch: 5| Step: 5
Training loss: 3.0191234791974972
Validation loss: 2.612770055460977

Epoch: 5| Step: 6
Training loss: 2.777049374974918
Validation loss: 2.6314557642837633

Epoch: 5| Step: 7
Training loss: 2.724194216802351
Validation loss: 2.6200027705324063

Epoch: 5| Step: 8
Training loss: 3.425976807461795
Validation loss: 2.6308056803140736

Epoch: 5| Step: 9
Training loss: 2.8902769136913826
Validation loss: 2.640170649568908

Epoch: 5| Step: 10
Training loss: 3.3248005054256873
Validation loss: 2.646672096431557

Epoch: 74| Step: 0
Training loss: 3.164124589475675
Validation loss: 2.633558479529663

Epoch: 5| Step: 1
Training loss: 3.208630700800747
Validation loss: 2.63300707267805

Epoch: 5| Step: 2
Training loss: 2.945394256833206
Validation loss: 2.619614936795877

Epoch: 5| Step: 3
Training loss: 2.392599350192843
Validation loss: 2.6337258552491782

Epoch: 5| Step: 4
Training loss: 2.8791805224676397
Validation loss: 2.6029672951090737

Epoch: 5| Step: 5
Training loss: 2.542128838798407
Validation loss: 2.623582846124456

Epoch: 5| Step: 6
Training loss: 3.164013520791815
Validation loss: 2.6093579383170966

Epoch: 5| Step: 7
Training loss: 3.0675844298093558
Validation loss: 2.625062813815469

Epoch: 5| Step: 8
Training loss: 3.0951459413301214
Validation loss: 2.6153954287056607

Epoch: 5| Step: 9
Training loss: 2.9833552830348604
Validation loss: 2.628604885477842

Epoch: 5| Step: 10
Training loss: 3.0909168873142914
Validation loss: 2.6247674064505815

Epoch: 75| Step: 0
Training loss: 3.0438428610044563
Validation loss: 2.602993152324826

Epoch: 5| Step: 1
Training loss: 3.6245524689229685
Validation loss: 2.6311120961859147

Epoch: 5| Step: 2
Training loss: 2.7469909851792833
Validation loss: 2.6334535199308062

Epoch: 5| Step: 3
Training loss: 3.60543198323954
Validation loss: 2.6121808767357373

Epoch: 5| Step: 4
Training loss: 2.825957083827748
Validation loss: 2.6032878024401005

Epoch: 5| Step: 5
Training loss: 2.591559714740511
Validation loss: 2.6158662328772766

Epoch: 5| Step: 6
Training loss: 2.534595492140088
Validation loss: 2.606615305519067

Epoch: 5| Step: 7
Training loss: 2.998553563148295
Validation loss: 2.614473076239979

Epoch: 5| Step: 8
Training loss: 3.116243836251049
Validation loss: 2.613874207789681

Epoch: 5| Step: 9
Training loss: 2.6301050952756286
Validation loss: 2.613315853723219

Epoch: 5| Step: 10
Training loss: 2.494572183169827
Validation loss: 2.6036840428879953

Epoch: 76| Step: 0
Training loss: 2.8418435214169917
Validation loss: 2.589807576476402

Epoch: 5| Step: 1
Training loss: 2.8392370276376866
Validation loss: 2.5788593657113967

Epoch: 5| Step: 2
Training loss: 2.4176862363669755
Validation loss: 2.5860342041072064

Epoch: 5| Step: 3
Training loss: 2.6443799650343554
Validation loss: 2.596570064922904

Epoch: 5| Step: 4
Training loss: 2.4129761655842126
Validation loss: 2.6150413459775455

Epoch: 5| Step: 5
Training loss: 3.043345279927811
Validation loss: 2.6034520658147215

Epoch: 5| Step: 6
Training loss: 3.0658442085434756
Validation loss: 2.6141845950779814

Epoch: 5| Step: 7
Training loss: 3.143989696427562
Validation loss: 2.605694515490971

Epoch: 5| Step: 8
Training loss: 3.2208624268896084
Validation loss: 2.6007688430746834

Epoch: 5| Step: 9
Training loss: 2.996214067214201
Validation loss: 2.6111287096629483

Epoch: 5| Step: 10
Training loss: 3.7255657150499655
Validation loss: 2.6052125335987646

Epoch: 77| Step: 0
Training loss: 2.804256565491346
Validation loss: 2.595295648768985

Epoch: 5| Step: 1
Training loss: 2.5935119151953505
Validation loss: 2.6152903890941115

Epoch: 5| Step: 2
Training loss: 3.103887728931811
Validation loss: 2.6155050120934584

Epoch: 5| Step: 3
Training loss: 2.7445157592232023
Validation loss: 2.5871149628006265

Epoch: 5| Step: 4
Training loss: 3.2826484243359677
Validation loss: 2.5948338433997264

Epoch: 5| Step: 5
Training loss: 3.4667241134529854
Validation loss: 2.6025280870089484

Epoch: 5| Step: 6
Training loss: 3.7224966457292905
Validation loss: 2.588826781283912

Epoch: 5| Step: 7
Training loss: 2.5808793584628194
Validation loss: 2.603157524895746

Epoch: 5| Step: 8
Training loss: 2.210540196607026
Validation loss: 2.5856542538419194

Epoch: 5| Step: 9
Training loss: 3.1238825516743223
Validation loss: 2.596029173500279

Epoch: 5| Step: 10
Training loss: 2.2531076798322234
Validation loss: 2.5950458599126454

Epoch: 78| Step: 0
Training loss: 3.217872425924298
Validation loss: 2.6007454344852827

Epoch: 5| Step: 1
Training loss: 3.2307804792159454
Validation loss: 2.5985350332639983

Epoch: 5| Step: 2
Training loss: 3.373277860594984
Validation loss: 2.6060833151511087

Epoch: 5| Step: 3
Training loss: 1.9199072836304951
Validation loss: 2.5960253014165096

Epoch: 5| Step: 4
Training loss: 2.3617177283726187
Validation loss: 2.6214511964372997

Epoch: 5| Step: 5
Training loss: 3.2516258281239936
Validation loss: 2.6125581673133897

Epoch: 5| Step: 6
Training loss: 2.819990060396466
Validation loss: 2.5986477130727006

Epoch: 5| Step: 7
Training loss: 2.474110156302916
Validation loss: 2.601308359695389

Epoch: 5| Step: 8
Training loss: 3.1408073410317616
Validation loss: 2.603666527415338

Epoch: 5| Step: 9
Training loss: 2.912412119837082
Validation loss: 2.6129763654501303

Epoch: 5| Step: 10
Training loss: 3.2586706847037576
Validation loss: 2.6178607866230443

Epoch: 79| Step: 0
Training loss: 3.5335959684781204
Validation loss: 2.6079065972059

Epoch: 5| Step: 1
Training loss: 3.33005349605995
Validation loss: 2.6214718232167056

Epoch: 5| Step: 2
Training loss: 3.0554586934621804
Validation loss: 2.59295757487931

Epoch: 5| Step: 3
Training loss: 2.598352508164231
Validation loss: 2.587694641357254

Epoch: 5| Step: 4
Training loss: 2.691459843471527
Validation loss: 2.6185179907345195

Epoch: 5| Step: 5
Training loss: 2.2755604692847293
Validation loss: 2.6022392579402625

Epoch: 5| Step: 6
Training loss: 2.061660827077471
Validation loss: 2.606422842578039

Epoch: 5| Step: 7
Training loss: 3.208189147747846
Validation loss: 2.5890369266260436

Epoch: 5| Step: 8
Training loss: 3.139142649772794
Validation loss: 2.594544861314194

Epoch: 5| Step: 9
Training loss: 3.1542061712964995
Validation loss: 2.5985327350446457

Epoch: 5| Step: 10
Training loss: 2.87242873937596
Validation loss: 2.616248046274734

Epoch: 80| Step: 0
Training loss: 2.975091685957923
Validation loss: 2.603319360199401

Epoch: 5| Step: 1
Training loss: 2.7918373644059593
Validation loss: 2.5874423709360985

Epoch: 5| Step: 2
Training loss: 2.9641435723687115
Validation loss: 2.5914087068300247

Epoch: 5| Step: 3
Training loss: 3.3026862972827553
Validation loss: 2.613590015675042

Epoch: 5| Step: 4
Training loss: 3.164018192687461
Validation loss: 2.604658360157123

Epoch: 5| Step: 5
Training loss: 2.8107959247282164
Validation loss: 2.5935948297426545

Epoch: 5| Step: 6
Training loss: 2.74634326219097
Validation loss: 2.5939840336467

Epoch: 5| Step: 7
Training loss: 2.69857192949886
Validation loss: 2.5841656679417904

Epoch: 5| Step: 8
Training loss: 3.233179286026876
Validation loss: 2.611858772260576

Epoch: 5| Step: 9
Training loss: 2.965073246171766
Validation loss: 2.6043012608027225

Epoch: 5| Step: 10
Training loss: 2.4059078419159627
Validation loss: 2.602972726780605

Epoch: 81| Step: 0
Training loss: 2.7945947142388654
Validation loss: 2.5919629872224217

Epoch: 5| Step: 1
Training loss: 2.4600784982391883
Validation loss: 2.593880258831018

Epoch: 5| Step: 2
Training loss: 2.6044739707192415
Validation loss: 2.592934498172965

Epoch: 5| Step: 3
Training loss: 3.121462689151223
Validation loss: 2.614912618222858

Epoch: 5| Step: 4
Training loss: 2.9095927057648363
Validation loss: 2.587185920088493

Epoch: 5| Step: 5
Training loss: 3.346175410422971
Validation loss: 2.6069861629592195

Epoch: 5| Step: 6
Training loss: 2.818716004160294
Validation loss: 2.610741899629013

Epoch: 5| Step: 7
Training loss: 3.1897367221685378
Validation loss: 2.5923237878139407

Epoch: 5| Step: 8
Training loss: 2.719330999622932
Validation loss: 2.584441830056833

Epoch: 5| Step: 9
Training loss: 3.505137351660261
Validation loss: 2.583606567249807

Epoch: 5| Step: 10
Training loss: 2.329971400564288
Validation loss: 2.598531797307426

Epoch: 82| Step: 0
Training loss: 2.529190827138551
Validation loss: 2.578005216966199

Epoch: 5| Step: 1
Training loss: 3.521327162802087
Validation loss: 2.5892294739562485

Epoch: 5| Step: 2
Training loss: 2.728080348887131
Validation loss: 2.6015321822861748

Epoch: 5| Step: 3
Training loss: 3.030250620533257
Validation loss: 2.5944094856688755

Epoch: 5| Step: 4
Training loss: 3.7017996303466862
Validation loss: 2.5951215505662666

Epoch: 5| Step: 5
Training loss: 2.4947704932814863
Validation loss: 2.598260400651724

Epoch: 5| Step: 6
Training loss: 2.835351468321621
Validation loss: 2.6003983214196675

Epoch: 5| Step: 7
Training loss: 2.514404095380156
Validation loss: 2.6111998862226375

Epoch: 5| Step: 8
Training loss: 2.759015823092132
Validation loss: 2.562541624682066

Epoch: 5| Step: 9
Training loss: 3.003295836417465
Validation loss: 2.5924567250067483

Epoch: 5| Step: 10
Training loss: 2.7444774488848953
Validation loss: 2.5990272128309364

Epoch: 83| Step: 0
Training loss: 2.775381690916303
Validation loss: 2.5742975436700637

Epoch: 5| Step: 1
Training loss: 3.0167678485853533
Validation loss: 2.5976438416104397

Epoch: 5| Step: 2
Training loss: 3.1018415272690074
Validation loss: 2.577670121670613

Epoch: 5| Step: 3
Training loss: 2.9121210007208416
Validation loss: 2.58209072565364

Epoch: 5| Step: 4
Training loss: 2.9434329240769253
Validation loss: 2.5723586872168283

Epoch: 5| Step: 5
Training loss: 3.2633413698787788
Validation loss: 2.5913389108747453

Epoch: 5| Step: 6
Training loss: 2.7239270083861244
Validation loss: 2.5728387866107707

Epoch: 5| Step: 7
Training loss: 2.529179515104217
Validation loss: 2.588569022146121

Epoch: 5| Step: 8
Training loss: 2.7561795422464592
Validation loss: 2.5791052939932158

Epoch: 5| Step: 9
Training loss: 3.359535532819508
Validation loss: 2.5862477637546117

Epoch: 5| Step: 10
Training loss: 2.443072868643894
Validation loss: 2.5744901328538226

Epoch: 84| Step: 0
Training loss: 3.4104579866330074
Validation loss: 2.5630788652000027

Epoch: 5| Step: 1
Training loss: 2.3896503331559193
Validation loss: 2.573121537528911

Epoch: 5| Step: 2
Training loss: 2.648995849807731
Validation loss: 2.582085744497344

Epoch: 5| Step: 3
Training loss: 2.674233538904066
Validation loss: 2.5793078053844734

Epoch: 5| Step: 4
Training loss: 2.78683656401221
Validation loss: 2.5595838820085595

Epoch: 5| Step: 5
Training loss: 3.4923488912475857
Validation loss: 2.577317827389895

Epoch: 5| Step: 6
Training loss: 2.610484909379322
Validation loss: 2.5725322062664993

Epoch: 5| Step: 7
Training loss: 3.522316765009417
Validation loss: 2.589333136161808

Epoch: 5| Step: 8
Training loss: 2.6803139713332684
Validation loss: 2.5832769481712465

Epoch: 5| Step: 9
Training loss: 3.010462636277658
Validation loss: 2.5881489940163185

Epoch: 5| Step: 10
Training loss: 2.588443337203291
Validation loss: 2.5909101267178305

Epoch: 85| Step: 0
Training loss: 3.6514341802743724
Validation loss: 2.594261080533877

Epoch: 5| Step: 1
Training loss: 2.7761895937748013
Validation loss: 2.5794977545119004

Epoch: 5| Step: 2
Training loss: 2.7504912717868306
Validation loss: 2.586811481704048

Epoch: 5| Step: 3
Training loss: 2.6925963053220285
Validation loss: 2.5882154379524396

Epoch: 5| Step: 4
Training loss: 2.6115735323167266
Validation loss: 2.5702681789622055

Epoch: 5| Step: 5
Training loss: 2.8792202699329845
Validation loss: 2.590850086661913

Epoch: 5| Step: 6
Training loss: 3.300525253571451
Validation loss: 2.58741151918886

Epoch: 5| Step: 7
Training loss: 2.2728477316058093
Validation loss: 2.5705183410357852

Epoch: 5| Step: 8
Training loss: 3.049843931113589
Validation loss: 2.5706260488159987

Epoch: 5| Step: 9
Training loss: 2.8391359226304065
Validation loss: 2.5798861815130993

Epoch: 5| Step: 10
Training loss: 2.670391451682413
Validation loss: 2.5799046633289766

Epoch: 86| Step: 0
Training loss: 3.414272555036889
Validation loss: 2.5490629349597604

Epoch: 5| Step: 1
Training loss: 3.0447126491619527
Validation loss: 2.5736348243975358

Epoch: 5| Step: 2
Training loss: 2.359657321232263
Validation loss: 2.5693383431545462

Epoch: 5| Step: 3
Training loss: 2.4196320022234956
Validation loss: 2.5829813780642445

Epoch: 5| Step: 4
Training loss: 3.016774329131245
Validation loss: 2.5679525155966343

Epoch: 5| Step: 5
Training loss: 2.934859367263657
Validation loss: 2.5815413872930915

Epoch: 5| Step: 6
Training loss: 2.9897945387044564
Validation loss: 2.583122664272697

Epoch: 5| Step: 7
Training loss: 2.396711393141477
Validation loss: 2.550082164022187

Epoch: 5| Step: 8
Training loss: 3.1335728357644754
Validation loss: 2.5717337143535635

Epoch: 5| Step: 9
Training loss: 2.8762594035366673
Validation loss: 2.5751034986733004

Epoch: 5| Step: 10
Training loss: 3.0876138890068314
Validation loss: 2.557347620962644

Epoch: 87| Step: 0
Training loss: 3.2435405803251207
Validation loss: 2.564539786069939

Epoch: 5| Step: 1
Training loss: 2.9807743100863737
Validation loss: 2.565509660443021

Epoch: 5| Step: 2
Training loss: 3.4859444543349363
Validation loss: 2.5791980835790342

Epoch: 5| Step: 3
Training loss: 2.852026998234278
Validation loss: 2.5739243667843463

Epoch: 5| Step: 4
Training loss: 2.661612539184909
Validation loss: 2.5951084227393375

Epoch: 5| Step: 5
Training loss: 2.875032839380213
Validation loss: 2.569390503696772

Epoch: 5| Step: 6
Training loss: 2.864629701181313
Validation loss: 2.578003377273697

Epoch: 5| Step: 7
Training loss: 3.383252121901222
Validation loss: 2.576802498907139

Epoch: 5| Step: 8
Training loss: 2.304863150417152
Validation loss: 2.574627751747765

Epoch: 5| Step: 9
Training loss: 2.4522969008409783
Validation loss: 2.559384038984009

Epoch: 5| Step: 10
Training loss: 2.380064433371654
Validation loss: 2.579628773758685

Epoch: 88| Step: 0
Training loss: 2.3956090296912866
Validation loss: 2.555038375368833

Epoch: 5| Step: 1
Training loss: 3.312707714549923
Validation loss: 2.549712033774263

Epoch: 5| Step: 2
Training loss: 2.6057778422472957
Validation loss: 2.5920635631164886

Epoch: 5| Step: 3
Training loss: 3.0059502719869955
Validation loss: 2.5676513644255707

Epoch: 5| Step: 4
Training loss: 2.8787777171951867
Validation loss: 2.569967564487911

Epoch: 5| Step: 5
Training loss: 3.341237202458218
Validation loss: 2.587183722272982

Epoch: 5| Step: 6
Training loss: 2.4199931062647466
Validation loss: 2.570918810382344

Epoch: 5| Step: 7
Training loss: 2.9949828155992586
Validation loss: 2.574946572537709

Epoch: 5| Step: 8
Training loss: 2.7066074936917706
Validation loss: 2.5710338990623023

Epoch: 5| Step: 9
Training loss: 2.807004858498604
Validation loss: 2.558018989072767

Epoch: 5| Step: 10
Training loss: 3.0896309298250717
Validation loss: 2.5618647246369397

Epoch: 89| Step: 0
Training loss: 2.7681226928177654
Validation loss: 2.5373016011524943

Epoch: 5| Step: 1
Training loss: 2.1558053484224557
Validation loss: 2.565246084054088

Epoch: 5| Step: 2
Training loss: 2.7885253559975496
Validation loss: 2.5499971902081016

Epoch: 5| Step: 3
Training loss: 3.3577061966035626
Validation loss: 2.5602196312013987

Epoch: 5| Step: 4
Training loss: 2.9104883606112253
Validation loss: 2.5616916488998602

Epoch: 5| Step: 5
Training loss: 2.822930386405534
Validation loss: 2.5499332079020904

Epoch: 5| Step: 6
Training loss: 3.1468897344704545
Validation loss: 2.554525687788156

Epoch: 5| Step: 7
Training loss: 2.889827308907087
Validation loss: 2.552637068189877

Epoch: 5| Step: 8
Training loss: 3.648144728617205
Validation loss: 2.539416687196612

Epoch: 5| Step: 9
Training loss: 2.627904284413637
Validation loss: 2.5597926388498204

Epoch: 5| Step: 10
Training loss: 2.344662501402579
Validation loss: 2.5595956240625175

Epoch: 90| Step: 0
Training loss: 2.8065582242057503
Validation loss: 2.55451551660464

Epoch: 5| Step: 1
Training loss: 2.8691048928276155
Validation loss: 2.5500748050920343

Epoch: 5| Step: 2
Training loss: 2.8806791190958467
Validation loss: 2.5583594505420204

Epoch: 5| Step: 3
Training loss: 3.45071548008872
Validation loss: 2.5543069587727287

Epoch: 5| Step: 4
Training loss: 2.581723470422088
Validation loss: 2.554731043700131

Epoch: 5| Step: 5
Training loss: 1.9630127522447387
Validation loss: 2.56131328633196

Epoch: 5| Step: 6
Training loss: 2.856999645731166
Validation loss: 2.5593439170527255

Epoch: 5| Step: 7
Training loss: 2.945333384634593
Validation loss: 2.5615561903399056

Epoch: 5| Step: 8
Training loss: 3.1803439725623197
Validation loss: 2.569718505055222

Epoch: 5| Step: 9
Training loss: 2.931208264149339
Validation loss: 2.558226582887119

Epoch: 5| Step: 10
Training loss: 3.067115108900799
Validation loss: 2.575550517933047

Epoch: 91| Step: 0
Training loss: 2.812175138573301
Validation loss: 2.5642213544777537

Epoch: 5| Step: 1
Training loss: 3.1719062690884816
Validation loss: 2.564445433426137

Epoch: 5| Step: 2
Training loss: 2.1360427930952897
Validation loss: 2.575685987006322

Epoch: 5| Step: 3
Training loss: 3.153759417495244
Validation loss: 2.5814637849806803

Epoch: 5| Step: 4
Training loss: 3.1330545003748873
Validation loss: 2.5791180331153134

Epoch: 5| Step: 5
Training loss: 2.565488421839072
Validation loss: 2.5610346182031156

Epoch: 5| Step: 6
Training loss: 3.3013472032373756
Validation loss: 2.5644240900375723

Epoch: 5| Step: 7
Training loss: 2.332396409983874
Validation loss: 2.551312972009679

Epoch: 5| Step: 8
Training loss: 2.7316033839618314
Validation loss: 2.5657599317662765

Epoch: 5| Step: 9
Training loss: 3.1778889286132292
Validation loss: 2.5691815518296153

Epoch: 5| Step: 10
Training loss: 2.889338521527026
Validation loss: 2.5665005505357232

Epoch: 92| Step: 0
Training loss: 2.831219071309837
Validation loss: 2.5432200339095683

Epoch: 5| Step: 1
Training loss: 2.3980666877312133
Validation loss: 2.5788735484779552

Epoch: 5| Step: 2
Training loss: 2.731556164234801
Validation loss: 2.5495221088516047

Epoch: 5| Step: 3
Training loss: 2.8451274847285686
Validation loss: 2.5698228645160976

Epoch: 5| Step: 4
Training loss: 2.728339285808106
Validation loss: 2.553947061199134

Epoch: 5| Step: 5
Training loss: 3.222191313525923
Validation loss: 2.5621159803768765

Epoch: 5| Step: 6
Training loss: 2.4996398666389172
Validation loss: 2.5636110795799625

Epoch: 5| Step: 7
Training loss: 3.1858658435016576
Validation loss: 2.5548868183414912

Epoch: 5| Step: 8
Training loss: 2.556909370722852
Validation loss: 2.5456896550770494

Epoch: 5| Step: 9
Training loss: 3.207044928982703
Validation loss: 2.551852533293901

Epoch: 5| Step: 10
Training loss: 3.133270458510455
Validation loss: 2.5421910349387447

Epoch: 93| Step: 0
Training loss: 3.0371745308023046
Validation loss: 2.5521881028435494

Epoch: 5| Step: 1
Training loss: 2.438759307296097
Validation loss: 2.5584398023101085

Epoch: 5| Step: 2
Training loss: 2.7188708399083623
Validation loss: 2.5544676869116536

Epoch: 5| Step: 3
Training loss: 2.9232771665889286
Validation loss: 2.524231782938348

Epoch: 5| Step: 4
Training loss: 2.6982636590656273
Validation loss: 2.560164020389389

Epoch: 5| Step: 5
Training loss: 2.8813644949119266
Validation loss: 2.5582255807705923

Epoch: 5| Step: 6
Training loss: 3.3014357420187963
Validation loss: 2.538086283953469

Epoch: 5| Step: 7
Training loss: 3.1573295635456486
Validation loss: 2.5562050546746087

Epoch: 5| Step: 8
Training loss: 2.9764952163901355
Validation loss: 2.5415736954211945

Epoch: 5| Step: 9
Training loss: 2.9017326769331024
Validation loss: 2.554589395507465

Epoch: 5| Step: 10
Training loss: 2.0734342251646143
Validation loss: 2.540539849973203

Epoch: 94| Step: 0
Training loss: 2.722081916030553
Validation loss: 2.558572724522184

Epoch: 5| Step: 1
Training loss: 2.662902669052591
Validation loss: 2.551281139239233

Epoch: 5| Step: 2
Training loss: 2.4784724334729056
Validation loss: 2.545810853359981

Epoch: 5| Step: 3
Training loss: 2.800806702480888
Validation loss: 2.5402519172623528

Epoch: 5| Step: 4
Training loss: 2.7018073073093274
Validation loss: 2.5468457133042866

Epoch: 5| Step: 5
Training loss: 3.2975619355256893
Validation loss: 2.552220599811042

Epoch: 5| Step: 6
Training loss: 2.8234503453885558
Validation loss: 2.5476243978629807

Epoch: 5| Step: 7
Training loss: 2.952134708091214
Validation loss: 2.5546857057331605

Epoch: 5| Step: 8
Training loss: 3.2183101316458904
Validation loss: 2.5552237958391615

Epoch: 5| Step: 9
Training loss: 3.0640500875218692
Validation loss: 2.5642467431009757

Epoch: 5| Step: 10
Training loss: 2.4934251157761684
Validation loss: 2.565217554761465

Epoch: 95| Step: 0
Training loss: 2.4192616791375743
Validation loss: 2.5409324430411036

Epoch: 5| Step: 1
Training loss: 3.239021391545622
Validation loss: 2.5602095897821413

Epoch: 5| Step: 2
Training loss: 2.7501939358385075
Validation loss: 2.56388603000562

Epoch: 5| Step: 3
Training loss: 2.35949282320406
Validation loss: 2.5552685232963355

Epoch: 5| Step: 4
Training loss: 2.9622226633559814
Validation loss: 2.5537076316935545

Epoch: 5| Step: 5
Training loss: 3.1211984017674688
Validation loss: 2.5666908781472917

Epoch: 5| Step: 6
Training loss: 2.189144606211083
Validation loss: 2.5620544280313755

Epoch: 5| Step: 7
Training loss: 3.01811850440645
Validation loss: 2.544962158821137

Epoch: 5| Step: 8
Training loss: 3.1669459638065973
Validation loss: 2.5532219548997963

Epoch: 5| Step: 9
Training loss: 3.4175981941989884
Validation loss: 2.5449753619843083

Epoch: 5| Step: 10
Training loss: 2.098699612129064
Validation loss: 2.522045543380471

Epoch: 96| Step: 0
Training loss: 3.062784298526711
Validation loss: 2.570202605644227

Epoch: 5| Step: 1
Training loss: 3.2678369942847243
Validation loss: 2.569068743166275

Epoch: 5| Step: 2
Training loss: 2.951942005063332
Validation loss: 2.5533582341187397

Epoch: 5| Step: 3
Training loss: 2.7707446282512054
Validation loss: 2.5596727050250476

Epoch: 5| Step: 4
Training loss: 2.608433536477629
Validation loss: 2.5548046042948203

Epoch: 5| Step: 5
Training loss: 2.365866818282332
Validation loss: 2.5470842982198154

Epoch: 5| Step: 6
Training loss: 2.877072126590928
Validation loss: 2.54465944540373

Epoch: 5| Step: 7
Training loss: 2.9284930833445344
Validation loss: 2.5550955064347356

Epoch: 5| Step: 8
Training loss: 2.796649774614803
Validation loss: 2.550252592713082

Epoch: 5| Step: 9
Training loss: 2.7462845759066545
Validation loss: 2.5621042093493567

Epoch: 5| Step: 10
Training loss: 2.6157502284545275
Validation loss: 2.562677500830206

Epoch: 97| Step: 0
Training loss: 2.393634373036071
Validation loss: 2.5438578833293293

Epoch: 5| Step: 1
Training loss: 2.90635516889055
Validation loss: 2.559977246296807

Epoch: 5| Step: 2
Training loss: 2.319162514075526
Validation loss: 2.5449474979613873

Epoch: 5| Step: 3
Training loss: 3.1000354764815734
Validation loss: 2.5551003229847393

Epoch: 5| Step: 4
Training loss: 2.4983434911126534
Validation loss: 2.5473622854270155

Epoch: 5| Step: 5
Training loss: 2.4500147060030777
Validation loss: 2.5490403142310876

Epoch: 5| Step: 6
Training loss: 3.18364961727246
Validation loss: 2.530575844660137

Epoch: 5| Step: 7
Training loss: 3.303959037988672
Validation loss: 2.5374979549868297

Epoch: 5| Step: 8
Training loss: 3.205832774359986
Validation loss: 2.563818852555763

Epoch: 5| Step: 9
Training loss: 2.962024821227017
Validation loss: 2.5514827975170125

Epoch: 5| Step: 10
Training loss: 2.5982051412864373
Validation loss: 2.527225977836952

Epoch: 98| Step: 0
Training loss: 2.9614809689957693
Validation loss: 2.566598981839286

Epoch: 5| Step: 1
Training loss: 3.0051709750722178
Validation loss: 2.546445205210768

Epoch: 5| Step: 2
Training loss: 2.674841589114292
Validation loss: 2.544170909738178

Epoch: 5| Step: 3
Training loss: 2.5789855445613488
Validation loss: 2.5536401172150054

Epoch: 5| Step: 4
Training loss: 2.405946192202342
Validation loss: 2.5623648182897814

Epoch: 5| Step: 5
Training loss: 2.5039364341309094
Validation loss: 2.5630683848820297

Epoch: 5| Step: 6
Training loss: 3.1786039788552665
Validation loss: 2.5360620916914

Epoch: 5| Step: 7
Training loss: 3.4857863232273334
Validation loss: 2.54816676239129

Epoch: 5| Step: 8
Training loss: 2.6024401218294186
Validation loss: 2.527633159217246

Epoch: 5| Step: 9
Training loss: 2.3175955641383106
Validation loss: 2.5550493963258103

Epoch: 5| Step: 10
Training loss: 3.2980989471268236
Validation loss: 2.5350732302304086

Epoch: 99| Step: 0
Training loss: 2.908388397074453
Validation loss: 2.5276082776234166

Epoch: 5| Step: 1
Training loss: 3.398239094872939
Validation loss: 2.5503000943396796

Epoch: 5| Step: 2
Training loss: 2.8144543109708637
Validation loss: 2.547328304432672

Epoch: 5| Step: 3
Training loss: 3.0708387860508974
Validation loss: 2.5441505827832884

Epoch: 5| Step: 4
Training loss: 2.931405420798847
Validation loss: 2.551017703159749

Epoch: 5| Step: 5
Training loss: 2.0118482825788524
Validation loss: 2.5560049705428156

Epoch: 5| Step: 6
Training loss: 2.338483054963634
Validation loss: 2.571678458194555

Epoch: 5| Step: 7
Training loss: 2.8341166217636204
Validation loss: 2.5553636100589165

Epoch: 5| Step: 8
Training loss: 2.8299408030974154
Validation loss: 2.5440515041241794

Epoch: 5| Step: 9
Training loss: 3.1754031548644104
Validation loss: 2.566869008018258

Epoch: 5| Step: 10
Training loss: 2.4484595379936125
Validation loss: 2.5458294551655953

Epoch: 100| Step: 0
Training loss: 3.4882640261507865
Validation loss: 2.5442729879451114

Epoch: 5| Step: 1
Training loss: 2.528522670482035
Validation loss: 2.534108668375887

Epoch: 5| Step: 2
Training loss: 2.3468670272183774
Validation loss: 2.5682357525637753

Epoch: 5| Step: 3
Training loss: 2.340632896257229
Validation loss: 2.554455669885433

Epoch: 5| Step: 4
Training loss: 2.7164273041509084
Validation loss: 2.568358702238224

Epoch: 5| Step: 5
Training loss: 3.183307957839354
Validation loss: 2.565211614408549

Epoch: 5| Step: 6
Training loss: 2.813668411000662
Validation loss: 2.5443556188688756

Epoch: 5| Step: 7
Training loss: 2.715837694624795
Validation loss: 2.5452749204989136

Epoch: 5| Step: 8
Training loss: 3.142428207851996
Validation loss: 2.56951344700508

Epoch: 5| Step: 9
Training loss: 3.0427543750706727
Validation loss: 2.5555994727201536

Epoch: 5| Step: 10
Training loss: 2.4913460677286507
Validation loss: 2.559152898785444

Epoch: 101| Step: 0
Training loss: 2.7194874958046134
Validation loss: 2.5593578974460542

Epoch: 5| Step: 1
Training loss: 2.3094153580087937
Validation loss: 2.5502843714736243

Epoch: 5| Step: 2
Training loss: 2.2036619140884572
Validation loss: 2.5411603077927247

Epoch: 5| Step: 3
Training loss: 3.169510133601013
Validation loss: 2.5381501563372533

Epoch: 5| Step: 4
Training loss: 3.1141988629670823
Validation loss: 2.5348445376408986

Epoch: 5| Step: 5
Training loss: 2.9073808992351355
Validation loss: 2.5237950186960356

Epoch: 5| Step: 6
Training loss: 3.560206829663539
Validation loss: 2.528534218648282

Epoch: 5| Step: 7
Training loss: 2.336340827952007
Validation loss: 2.5315902898497837

Epoch: 5| Step: 8
Training loss: 2.688116224745135
Validation loss: 2.5189871719898633

Epoch: 5| Step: 9
Training loss: 3.1271632527188715
Validation loss: 2.5347751675021444

Epoch: 5| Step: 10
Training loss: 2.5684314093985763
Validation loss: 2.5315420958812327

Epoch: 102| Step: 0
Training loss: 2.9597735772007794
Validation loss: 2.542360307629829

Epoch: 5| Step: 1
Training loss: 2.985148065112029
Validation loss: 2.530196594696853

Epoch: 5| Step: 2
Training loss: 3.0301388935950673
Validation loss: 2.51733232273552

Epoch: 5| Step: 3
Training loss: 2.6016812684038144
Validation loss: 2.5350758716633153

Epoch: 5| Step: 4
Training loss: 2.782053456355754
Validation loss: 2.517879673370505

Epoch: 5| Step: 5
Training loss: 3.1676172703544463
Validation loss: 2.533913227537067

Epoch: 5| Step: 6
Training loss: 1.9698891749893221
Validation loss: 2.5380362941682586

Epoch: 5| Step: 7
Training loss: 2.6377804575414348
Validation loss: 2.508938742682804

Epoch: 5| Step: 8
Training loss: 2.4716521962060134
Validation loss: 2.53196535949107

Epoch: 5| Step: 9
Training loss: 3.1578223211785983
Validation loss: 2.5097399646176157

Epoch: 5| Step: 10
Training loss: 2.955887405708243
Validation loss: 2.521281829357636

Epoch: 103| Step: 0
Training loss: 2.0371069172069904
Validation loss: 2.5292883528186025

Epoch: 5| Step: 1
Training loss: 2.9335115017389928
Validation loss: 2.561195297503039

Epoch: 5| Step: 2
Training loss: 2.712515863468878
Validation loss: 2.518615834137619

Epoch: 5| Step: 3
Training loss: 2.9720578687945944
Validation loss: 2.5412167430470776

Epoch: 5| Step: 4
Training loss: 2.7498867705182675
Validation loss: 2.528257673227937

Epoch: 5| Step: 5
Training loss: 3.037140775561148
Validation loss: 2.5352422379626094

Epoch: 5| Step: 6
Training loss: 2.8485327105740685
Validation loss: 2.5476426463044075

Epoch: 5| Step: 7
Training loss: 3.2900858757151124
Validation loss: 2.5535332822358376

Epoch: 5| Step: 8
Training loss: 2.9413196809347504
Validation loss: 2.5500151829003137

Epoch: 5| Step: 9
Training loss: 2.6514743734089223
Validation loss: 2.5572633918201744

Epoch: 5| Step: 10
Training loss: 2.7348619299982158
Validation loss: 2.558179583199486

Epoch: 104| Step: 0
Training loss: 3.161431619865431
Validation loss: 2.562564835027073

Epoch: 5| Step: 1
Training loss: 3.2522163170052534
Validation loss: 2.536529539679227

Epoch: 5| Step: 2
Training loss: 2.607347260168354
Validation loss: 2.5547829204660477

Epoch: 5| Step: 3
Training loss: 2.7846558537320845
Validation loss: 2.530834961549076

Epoch: 5| Step: 4
Training loss: 2.7491148477808385
Validation loss: 2.5552956657922272

Epoch: 5| Step: 5
Training loss: 2.4379198739745664
Validation loss: 2.545202206550834

Epoch: 5| Step: 6
Training loss: 2.8145595215402657
Validation loss: 2.5381313406826815

Epoch: 5| Step: 7
Training loss: 3.261940661893448
Validation loss: 2.525838587549459

Epoch: 5| Step: 8
Training loss: 2.827350826628768
Validation loss: 2.540310897676578

Epoch: 5| Step: 9
Training loss: 2.4773104046779215
Validation loss: 2.5430961531480305

Epoch: 5| Step: 10
Training loss: 2.0982883289571976
Validation loss: 2.5398553526347087

Epoch: 105| Step: 0
Training loss: 2.667446817084205
Validation loss: 2.5445625058305255

Epoch: 5| Step: 1
Training loss: 3.1754340888817123
Validation loss: 2.5339876646122077

Epoch: 5| Step: 2
Training loss: 2.5457343607226126
Validation loss: 2.539142602709262

Epoch: 5| Step: 3
Training loss: 3.306223555172479
Validation loss: 2.548510771715516

Epoch: 5| Step: 4
Training loss: 2.76365513880754
Validation loss: 2.556783909734222

Epoch: 5| Step: 5
Training loss: 2.774604487371188
Validation loss: 2.5571464698018196

Epoch: 5| Step: 6
Training loss: 2.707958860673676
Validation loss: 2.541072587077099

Epoch: 5| Step: 7
Training loss: 2.9335758701394203
Validation loss: 2.531460320695569

Epoch: 5| Step: 8
Training loss: 2.52934155516762
Validation loss: 2.5445685246141116

Epoch: 5| Step: 9
Training loss: 2.7670469777179774
Validation loss: 2.5354868357948765

Epoch: 5| Step: 10
Training loss: 2.7061726583304986
Validation loss: 2.5498305228027434

Epoch: 106| Step: 0
Training loss: 2.447049337634088
Validation loss: 2.523529676864889

Epoch: 5| Step: 1
Training loss: 2.8037003078810607
Validation loss: 2.532898805826824

Epoch: 5| Step: 2
Training loss: 2.591359243118984
Validation loss: 2.5395666841358957

Epoch: 5| Step: 3
Training loss: 2.439755887499481
Validation loss: 2.529938379641642

Epoch: 5| Step: 4
Training loss: 3.4096409429085206
Validation loss: 2.5229005848464743

Epoch: 5| Step: 5
Training loss: 3.171275716458568
Validation loss: 2.5255792564781636

Epoch: 5| Step: 6
Training loss: 3.076042283976685
Validation loss: 2.5242584223062123

Epoch: 5| Step: 7
Training loss: 2.4539636041107644
Validation loss: 2.5438945802444284

Epoch: 5| Step: 8
Training loss: 2.5250536582457537
Validation loss: 2.546451485326488

Epoch: 5| Step: 9
Training loss: 2.9959274305510837
Validation loss: 2.5451830104149233

Epoch: 5| Step: 10
Training loss: 2.7265715066056027
Validation loss: 2.554174128223426

Epoch: 107| Step: 0
Training loss: 3.4177864069665063
Validation loss: 2.534590659382091

Epoch: 5| Step: 1
Training loss: 2.5918697298068554
Validation loss: 2.5367266556484016

Epoch: 5| Step: 2
Training loss: 3.0828744873373117
Validation loss: 2.526796975271465

Epoch: 5| Step: 3
Training loss: 2.434971402605449
Validation loss: 2.5361517294083304

Epoch: 5| Step: 4
Training loss: 3.2244739192097773
Validation loss: 2.5173689266692185

Epoch: 5| Step: 5
Training loss: 2.4538268039088544
Validation loss: 2.5161631793252135

Epoch: 5| Step: 6
Training loss: 2.525336622706644
Validation loss: 2.5321592032148694

Epoch: 5| Step: 7
Training loss: 2.958266852979545
Validation loss: 2.5419770213861654

Epoch: 5| Step: 8
Training loss: 2.7107895692595085
Validation loss: 2.5390687287083056

Epoch: 5| Step: 9
Training loss: 2.8415510457998514
Validation loss: 2.536714669788711

Epoch: 5| Step: 10
Training loss: 2.2742670911750786
Validation loss: 2.550690802715104

Epoch: 108| Step: 0
Training loss: 3.5171218059273257
Validation loss: 2.538246795910609

Epoch: 5| Step: 1
Training loss: 2.866283138996905
Validation loss: 2.5395132306216497

Epoch: 5| Step: 2
Training loss: 3.535736879328861
Validation loss: 2.532720329419029

Epoch: 5| Step: 3
Training loss: 2.2189041943765893
Validation loss: 2.5461440253777745

Epoch: 5| Step: 4
Training loss: 2.5749756969305
Validation loss: 2.529018612155761

Epoch: 5| Step: 5
Training loss: 2.9589816354669662
Validation loss: 2.528552752381669

Epoch: 5| Step: 6
Training loss: 2.8512481098093527
Validation loss: 2.5514031354892213

Epoch: 5| Step: 7
Training loss: 2.444874977238589
Validation loss: 2.538536091167787

Epoch: 5| Step: 8
Training loss: 2.708253438700378
Validation loss: 2.5280158983890866

Epoch: 5| Step: 9
Training loss: 2.6798047632301056
Validation loss: 2.5168188746511158

Epoch: 5| Step: 10
Training loss: 1.8278070809174254
Validation loss: 2.5322641103246606

Epoch: 109| Step: 0
Training loss: 2.598907857543617
Validation loss: 2.5340462232763943

Epoch: 5| Step: 1
Training loss: 3.1387493548892023
Validation loss: 2.524339588888608

Epoch: 5| Step: 2
Training loss: 2.0788166931427514
Validation loss: 2.540610945625302

Epoch: 5| Step: 3
Training loss: 2.2775755252312324
Validation loss: 2.520851920973013

Epoch: 5| Step: 4
Training loss: 2.342658335444936
Validation loss: 2.531367776354571

Epoch: 5| Step: 5
Training loss: 3.014925070064028
Validation loss: 2.52711199120536

Epoch: 5| Step: 6
Training loss: 2.492825800073671
Validation loss: 2.5087626890794805

Epoch: 5| Step: 7
Training loss: 2.718177472044688
Validation loss: 2.5345748279386995

Epoch: 5| Step: 8
Training loss: 3.149871272529768
Validation loss: 2.5181331188418685

Epoch: 5| Step: 9
Training loss: 2.982159496225058
Validation loss: 2.540603208105962

Epoch: 5| Step: 10
Training loss: 3.712352217998518
Validation loss: 2.545911357885606

Epoch: 110| Step: 0
Training loss: 2.726837581541291
Validation loss: 2.5375313270809654

Epoch: 5| Step: 1
Training loss: 2.721355461351491
Validation loss: 2.537178604525486

Epoch: 5| Step: 2
Training loss: 2.4125278372468
Validation loss: 2.562389464436672

Epoch: 5| Step: 3
Training loss: 2.694726941177177
Validation loss: 2.5291109130193683

Epoch: 5| Step: 4
Training loss: 2.747188170963119
Validation loss: 2.53706009654085

Epoch: 5| Step: 5
Training loss: 2.8360715051522285
Validation loss: 2.5346721919747726

Epoch: 5| Step: 6
Training loss: 3.1646932844423845
Validation loss: 2.540695703622001

Epoch: 5| Step: 7
Training loss: 2.659627226042467
Validation loss: 2.530825347504756

Epoch: 5| Step: 8
Training loss: 2.982832584942937
Validation loss: 2.5692652824912656

Epoch: 5| Step: 9
Training loss: 2.93526763501599
Validation loss: 2.520969576006957

Epoch: 5| Step: 10
Training loss: 2.818138743096549
Validation loss: 2.548949140863721

Epoch: 111| Step: 0
Training loss: 2.673915329396527
Validation loss: 2.5403742746385776

Epoch: 5| Step: 1
Training loss: 2.912963660011209
Validation loss: 2.53639122422994

Epoch: 5| Step: 2
Training loss: 2.6243905767826585
Validation loss: 2.533307320977206

Epoch: 5| Step: 3
Training loss: 2.9622464872286765
Validation loss: 2.541217752879778

Epoch: 5| Step: 4
Training loss: 2.581025128117721
Validation loss: 2.5238952196197726

Epoch: 5| Step: 5
Training loss: 2.583822255372296
Validation loss: 2.5264159997291893

Epoch: 5| Step: 6
Training loss: 2.9748329885069644
Validation loss: 2.5574923020312568

Epoch: 5| Step: 7
Training loss: 2.376303666345078
Validation loss: 2.5385900611022474

Epoch: 5| Step: 8
Training loss: 2.7490026225899364
Validation loss: 2.534545923060698

Epoch: 5| Step: 9
Training loss: 3.0152513341702267
Validation loss: 2.5350218259014166

Epoch: 5| Step: 10
Training loss: 3.280702527104537
Validation loss: 2.53789655218768

Epoch: 112| Step: 0
Training loss: 2.154915880654684
Validation loss: 2.537742267720257

Epoch: 5| Step: 1
Training loss: 2.1425858030642395
Validation loss: 2.5344850080131907

Epoch: 5| Step: 2
Training loss: 2.530660395771587
Validation loss: 2.516071090223035

Epoch: 5| Step: 3
Training loss: 2.5614219817045716
Validation loss: 2.540399886955622

Epoch: 5| Step: 4
Training loss: 2.9645503807425735
Validation loss: 2.5388323653233833

Epoch: 5| Step: 5
Training loss: 2.696330179676757
Validation loss: 2.5361011404639164

Epoch: 5| Step: 6
Training loss: 2.9837992647064895
Validation loss: 2.5387874674549606

Epoch: 5| Step: 7
Training loss: 2.749847928090663
Validation loss: 2.5346879348162727

Epoch: 5| Step: 8
Training loss: 3.0685651237908105
Validation loss: 2.526091406006579

Epoch: 5| Step: 9
Training loss: 4.086189101807749
Validation loss: 2.5281352602812346

Epoch: 5| Step: 10
Training loss: 2.154715724702116
Validation loss: 2.5462795094640747

Epoch: 113| Step: 0
Training loss: 2.995705550806245
Validation loss: 2.544594621629072

Epoch: 5| Step: 1
Training loss: 2.5518542336117185
Validation loss: 2.5506957416586533

Epoch: 5| Step: 2
Training loss: 3.147956148746153
Validation loss: 2.549152884866372

Epoch: 5| Step: 3
Training loss: 2.912114287282074
Validation loss: 2.5308149666054423

Epoch: 5| Step: 4
Training loss: 3.2096170276581906
Validation loss: 2.5351598044911743

Epoch: 5| Step: 5
Training loss: 2.606107573425383
Validation loss: 2.533328305179008

Epoch: 5| Step: 6
Training loss: 2.738238324796176
Validation loss: 2.5505293103751403

Epoch: 5| Step: 7
Training loss: 2.1633770129002174
Validation loss: 2.527800612707293

Epoch: 5| Step: 8
Training loss: 2.7971643905528865
Validation loss: 2.5334289947489923

Epoch: 5| Step: 9
Training loss: 2.47162412583244
Validation loss: 2.5401607276958944

Epoch: 5| Step: 10
Training loss: 3.006360939818083
Validation loss: 2.5418121922262236

Epoch: 114| Step: 0
Training loss: 2.6640076393899985
Validation loss: 2.542388693095416

Epoch: 5| Step: 1
Training loss: 2.682938897027494
Validation loss: 2.541605606905705

Epoch: 5| Step: 2
Training loss: 2.488168950443709
Validation loss: 2.516487835247949

Epoch: 5| Step: 3
Training loss: 3.1272483367049424
Validation loss: 2.524342350218782

Epoch: 5| Step: 4
Training loss: 2.6096215959627154
Validation loss: 2.5502352701915436

Epoch: 5| Step: 5
Training loss: 3.0911407256412273
Validation loss: 2.544044118680347

Epoch: 5| Step: 6
Training loss: 2.575636246232471
Validation loss: 2.5333718385452504

Epoch: 5| Step: 7
Training loss: 3.3869012169704074
Validation loss: 2.534459452246635

Epoch: 5| Step: 8
Training loss: 2.0721509148490878
Validation loss: 2.5419972870577148

Epoch: 5| Step: 9
Training loss: 2.860602110324634
Validation loss: 2.5624701655522193

Epoch: 5| Step: 10
Training loss: 2.960164716622393
Validation loss: 2.548168121091908

Epoch: 115| Step: 0
Training loss: 2.6817482011948504
Validation loss: 2.53041474074555

Epoch: 5| Step: 1
Training loss: 2.8681818513769937
Validation loss: 2.538909352166688

Epoch: 5| Step: 2
Training loss: 3.3599066734976817
Validation loss: 2.5262903562792993

Epoch: 5| Step: 3
Training loss: 2.7634632692361736
Validation loss: 2.549324685999365

Epoch: 5| Step: 4
Training loss: 3.2784109276369273
Validation loss: 2.543372926209385

Epoch: 5| Step: 5
Training loss: 1.9690311170631023
Validation loss: 2.5378318319500055

Epoch: 5| Step: 6
Training loss: 2.660000475833248
Validation loss: 2.5278525877988263

Epoch: 5| Step: 7
Training loss: 3.115427232470743
Validation loss: 2.553686564982561

Epoch: 5| Step: 8
Training loss: 2.32258263710921
Validation loss: 2.519144290870032

Epoch: 5| Step: 9
Training loss: 2.4279264587375966
Validation loss: 2.5205277880067216

Epoch: 5| Step: 10
Training loss: 2.877222611805653
Validation loss: 2.549310151795883

Epoch: 116| Step: 0
Training loss: 2.5934259602921643
Validation loss: 2.5490053689743926

Epoch: 5| Step: 1
Training loss: 2.160193996548034
Validation loss: 2.5247035547099803

Epoch: 5| Step: 2
Training loss: 2.622516274488079
Validation loss: 2.522930698215698

Epoch: 5| Step: 3
Training loss: 2.440836066230068
Validation loss: 2.5350825015264355

Epoch: 5| Step: 4
Training loss: 2.874878922276384
Validation loss: 2.519589054925991

Epoch: 5| Step: 5
Training loss: 3.575192378276589
Validation loss: 2.5294499247594944

Epoch: 5| Step: 6
Training loss: 2.9612138362558693
Validation loss: 2.5274535908099947

Epoch: 5| Step: 7
Training loss: 2.561027569027727
Validation loss: 2.5438775772248503

Epoch: 5| Step: 8
Training loss: 2.65588035255403
Validation loss: 2.526768998040774

Epoch: 5| Step: 9
Training loss: 3.0565691759820317
Validation loss: 2.5276349777588285

Epoch: 5| Step: 10
Training loss: 2.7451202273139965
Validation loss: 2.5351661075069405

Epoch: 117| Step: 0
Training loss: 2.990920313940313
Validation loss: 2.53982882739815

Epoch: 5| Step: 1
Training loss: 2.862223556029889
Validation loss: 2.51310376075049

Epoch: 5| Step: 2
Training loss: 3.23144280395226
Validation loss: 2.524666533151923

Epoch: 5| Step: 3
Training loss: 2.81178325421156
Validation loss: 2.549747753595975

Epoch: 5| Step: 4
Training loss: 2.099940698785451
Validation loss: 2.5171573959787694

Epoch: 5| Step: 5
Training loss: 2.4768618814879972
Validation loss: 2.5309165736001327

Epoch: 5| Step: 6
Training loss: 3.1302508680825163
Validation loss: 2.531806266872503

Epoch: 5| Step: 7
Training loss: 3.1358525848676297
Validation loss: 2.5404405966874903

Epoch: 5| Step: 8
Training loss: 2.684791974865692
Validation loss: 2.5295283971271765

Epoch: 5| Step: 9
Training loss: 2.4624618411133214
Validation loss: 2.5037732198654425

Epoch: 5| Step: 10
Training loss: 2.4336459673182507
Validation loss: 2.522236611339668

Epoch: 118| Step: 0
Training loss: 2.6716658303998595
Validation loss: 2.543426276432105

Epoch: 5| Step: 1
Training loss: 2.756845710026294
Validation loss: 2.533254280851161

Epoch: 5| Step: 2
Training loss: 2.7884503715959363
Validation loss: 2.527042213004416

Epoch: 5| Step: 3
Training loss: 2.7157482369469954
Validation loss: 2.5304883041031307

Epoch: 5| Step: 4
Training loss: 2.642791310893342
Validation loss: 2.524090779524915

Epoch: 5| Step: 5
Training loss: 3.2036839439437697
Validation loss: 2.5419022343197843

Epoch: 5| Step: 6
Training loss: 2.69356048696216
Validation loss: 2.5296043618005664

Epoch: 5| Step: 7
Training loss: 3.005569691917596
Validation loss: 2.5323171661282706

Epoch: 5| Step: 8
Training loss: 2.68301283144504
Validation loss: 2.5297159306205854

Epoch: 5| Step: 9
Training loss: 3.058462322816865
Validation loss: 2.514738753891456

Epoch: 5| Step: 10
Training loss: 2.3149845076633744
Validation loss: 2.5437028276275644

Epoch: 119| Step: 0
Training loss: 2.9540184324563703
Validation loss: 2.5252944279162084

Epoch: 5| Step: 1
Training loss: 2.9200659062511902
Validation loss: 2.528555997798795

Epoch: 5| Step: 2
Training loss: 3.262654683037957
Validation loss: 2.5476795573763247

Epoch: 5| Step: 3
Training loss: 2.4131531221677234
Validation loss: 2.5260657764870413

Epoch: 5| Step: 4
Training loss: 2.164780480442167
Validation loss: 2.5449904981424862

Epoch: 5| Step: 5
Training loss: 3.0245163838338027
Validation loss: 2.545594128405796

Epoch: 5| Step: 6
Training loss: 2.616274910856978
Validation loss: 2.5404662860382947

Epoch: 5| Step: 7
Training loss: 2.0570984826146006
Validation loss: 2.541991554151665

Epoch: 5| Step: 8
Training loss: 2.929485670131176
Validation loss: 2.5464365521564414

Epoch: 5| Step: 9
Training loss: 2.6903848467792293
Validation loss: 2.55169331071401

Epoch: 5| Step: 10
Training loss: 3.2925810851566806
Validation loss: 2.5280733237372277

Epoch: 120| Step: 0
Training loss: 2.7477419859628998
Validation loss: 2.5463850761946825

Epoch: 5| Step: 1
Training loss: 3.0614475855336356
Validation loss: 2.535250394300412

Epoch: 5| Step: 2
Training loss: 3.183629996438599
Validation loss: 2.5440754429321415

Epoch: 5| Step: 3
Training loss: 2.0388391598981226
Validation loss: 2.5564791149097537

Epoch: 5| Step: 4
Training loss: 2.6962516585881238
Validation loss: 2.535233329262154

Epoch: 5| Step: 5
Training loss: 3.121498282216235
Validation loss: 2.540312287322307

Epoch: 5| Step: 6
Training loss: 1.806954021593002
Validation loss: 2.5471763178434847

Epoch: 5| Step: 7
Training loss: 2.8455456105600105
Validation loss: 2.5325346684217602

Epoch: 5| Step: 8
Training loss: 3.2637181897989165
Validation loss: 2.5481837166695196

Epoch: 5| Step: 9
Training loss: 2.5729757037062733
Validation loss: 2.5298371741717687

Epoch: 5| Step: 10
Training loss: 2.963458676285162
Validation loss: 2.5358224293040315

Epoch: 121| Step: 0
Training loss: 3.5381378245833033
Validation loss: 2.5386697636757374

Epoch: 5| Step: 1
Training loss: 2.227157566794847
Validation loss: 2.5537900808226137

Epoch: 5| Step: 2
Training loss: 3.0088383498174225
Validation loss: 2.5404749352089624

Epoch: 5| Step: 3
Training loss: 2.6599506405144333
Validation loss: 2.5459147221495178

Epoch: 5| Step: 4
Training loss: 3.1203158558620694
Validation loss: 2.5502648899029268

Epoch: 5| Step: 5
Training loss: 2.8898862152403395
Validation loss: 2.5468698060273205

Epoch: 5| Step: 6
Training loss: 2.8676384927152765
Validation loss: 2.5589460072667753

Epoch: 5| Step: 7
Training loss: 1.976464913714702
Validation loss: 2.5280073140859427

Epoch: 5| Step: 8
Training loss: 2.7277386159043093
Validation loss: 2.5357128337338395

Epoch: 5| Step: 9
Training loss: 2.7143261752303776
Validation loss: 2.5587400297989444

Epoch: 5| Step: 10
Training loss: 2.323842968735423
Validation loss: 2.540382171292624

Epoch: 122| Step: 0
Training loss: 3.5959752366822593
Validation loss: 2.536450235795621

Epoch: 5| Step: 1
Training loss: 2.505768510415379
Validation loss: 2.538199371717217

Epoch: 5| Step: 2
Training loss: 2.6988185911663094
Validation loss: 2.563069831204467

Epoch: 5| Step: 3
Training loss: 2.553476215611065
Validation loss: 2.532423339189768

Epoch: 5| Step: 4
Training loss: 2.903910361700916
Validation loss: 2.54103769265971

Epoch: 5| Step: 5
Training loss: 2.4271539069353762
Validation loss: 2.5315157822818724

Epoch: 5| Step: 6
Training loss: 2.285933194576858
Validation loss: 2.522956237647933

Epoch: 5| Step: 7
Training loss: 2.0260285390969575
Validation loss: 2.549467331596131

Epoch: 5| Step: 8
Training loss: 2.6924811045374146
Validation loss: 2.5571238047870453

Epoch: 5| Step: 9
Training loss: 3.2357527152828673
Validation loss: 2.519040808671887

Epoch: 5| Step: 10
Training loss: 3.1578851373426193
Validation loss: 2.5656274278795705

Epoch: 123| Step: 0
Training loss: 2.8791280218494504
Validation loss: 2.5405618834203616

Epoch: 5| Step: 1
Training loss: 3.056368236165915
Validation loss: 2.5376376426436145

Epoch: 5| Step: 2
Training loss: 2.660216208971162
Validation loss: 2.531315094619619

Epoch: 5| Step: 3
Training loss: 2.218864652868174
Validation loss: 2.5235373519383093

Epoch: 5| Step: 4
Training loss: 2.9848757019233845
Validation loss: 2.5482342790257344

Epoch: 5| Step: 5
Training loss: 2.372723241016679
Validation loss: 2.5771436865284287

Epoch: 5| Step: 6
Training loss: 3.290677288107318
Validation loss: 2.520943994075442

Epoch: 5| Step: 7
Training loss: 2.7019779660267482
Validation loss: 2.5422612373506954

Epoch: 5| Step: 8
Training loss: 2.329761007110009
Validation loss: 2.5344830102928513

Epoch: 5| Step: 9
Training loss: 3.064365052610276
Validation loss: 2.5437418583783002

Epoch: 5| Step: 10
Training loss: 2.6828461206692307
Validation loss: 2.51402247365987

Epoch: 124| Step: 0
Training loss: 2.4363151996435435
Validation loss: 2.5292571707959666

Epoch: 5| Step: 1
Training loss: 2.2702578827496693
Validation loss: 2.5317847668021964

Epoch: 5| Step: 2
Training loss: 1.9868609858639927
Validation loss: 2.524069967366628

Epoch: 5| Step: 3
Training loss: 2.762302277682697
Validation loss: 2.5135046807092403

Epoch: 5| Step: 4
Training loss: 3.2041514171010923
Validation loss: 2.5270453781884927

Epoch: 5| Step: 5
Training loss: 2.6242116925166523
Validation loss: 2.5262353502941437

Epoch: 5| Step: 6
Training loss: 2.6808259286285137
Validation loss: 2.541559953095128

Epoch: 5| Step: 7
Training loss: 3.323767159580153
Validation loss: 2.5487403845411922

Epoch: 5| Step: 8
Training loss: 3.125661551069779
Validation loss: 2.520497366221842

Epoch: 5| Step: 9
Training loss: 3.1585440277707404
Validation loss: 2.563834788398419

Epoch: 5| Step: 10
Training loss: 2.566716144960098
Validation loss: 2.531212786551984

Epoch: 125| Step: 0
Training loss: 2.8485178121606136
Validation loss: 2.53431727291764

Epoch: 5| Step: 1
Training loss: 2.6728620880889755
Validation loss: 2.551848203882798

Epoch: 5| Step: 2
Training loss: 2.9007749771638007
Validation loss: 2.54316860675229

Epoch: 5| Step: 3
Training loss: 2.213673761951618
Validation loss: 2.5399918494086915

Epoch: 5| Step: 4
Training loss: 2.716380522778657
Validation loss: 2.5368329220673194

Epoch: 5| Step: 5
Training loss: 2.8894335791615338
Validation loss: 2.55292926469347

Epoch: 5| Step: 6
Training loss: 2.5661936864977855
Validation loss: 2.5196995827666835

Epoch: 5| Step: 7
Training loss: 2.5681145729044506
Validation loss: 2.54493022092529

Epoch: 5| Step: 8
Training loss: 3.1830133014272795
Validation loss: 2.526643820616679

Epoch: 5| Step: 9
Training loss: 2.6166315655469905
Validation loss: 2.5372570389296065

Epoch: 5| Step: 10
Training loss: 3.057273921016074
Validation loss: 2.5245176615888223

Epoch: 126| Step: 0
Training loss: 2.3592354436362473
Validation loss: 2.5609516264962378

Epoch: 5| Step: 1
Training loss: 2.644483196774228
Validation loss: 2.5318535809653033

Epoch: 5| Step: 2
Training loss: 3.43341223678537
Validation loss: 2.526887903443755

Epoch: 5| Step: 3
Training loss: 2.9015961167992375
Validation loss: 2.5298573197263647

Epoch: 5| Step: 4
Training loss: 3.2734953299355514
Validation loss: 2.526810458004683

Epoch: 5| Step: 5
Training loss: 2.882465620803611
Validation loss: 2.5369237765125234

Epoch: 5| Step: 6
Training loss: 2.1992465029332346
Validation loss: 2.559771954719724

Epoch: 5| Step: 7
Training loss: 2.477129946420627
Validation loss: 2.535652307660088

Epoch: 5| Step: 8
Training loss: 2.511438997864837
Validation loss: 2.524309046994247

Epoch: 5| Step: 9
Training loss: 2.780788854880216
Validation loss: 2.5356661547976334

Epoch: 5| Step: 10
Training loss: 2.5836762744145987
Validation loss: 2.5638973328987777

Epoch: 127| Step: 0
Training loss: 3.100992991243012
Validation loss: 2.5293474773945595

Epoch: 5| Step: 1
Training loss: 2.4582483524785244
Validation loss: 2.523285634946853

Epoch: 5| Step: 2
Training loss: 2.301918357587862
Validation loss: 2.543637045687837

Epoch: 5| Step: 3
Training loss: 3.2559065331955206
Validation loss: 2.5460729140633767

Epoch: 5| Step: 4
Training loss: 3.096331357537721
Validation loss: 2.537507021425649

Epoch: 5| Step: 5
Training loss: 3.257885829182596
Validation loss: 2.535413267818704

Epoch: 5| Step: 6
Training loss: 2.9451700272238632
Validation loss: 2.533560748031414

Epoch: 5| Step: 7
Training loss: 2.5541963717634917
Validation loss: 2.5156157976279134

Epoch: 5| Step: 8
Training loss: 2.28211686895401
Validation loss: 2.556503614231455

Epoch: 5| Step: 9
Training loss: 2.7667020435446075
Validation loss: 2.5713155294013896

Epoch: 5| Step: 10
Training loss: 1.9515910724536558
Validation loss: 2.537264727039933

Epoch: 128| Step: 0
Training loss: 2.5672637575215354
Validation loss: 2.5429741515496405

Epoch: 5| Step: 1
Training loss: 3.5784221675691907
Validation loss: 2.5286792566920746

Epoch: 5| Step: 2
Training loss: 2.684315236040281
Validation loss: 2.523732090862155

Epoch: 5| Step: 3
Training loss: 2.986407641293396
Validation loss: 2.532401602410171

Epoch: 5| Step: 4
Training loss: 3.05929054712582
Validation loss: 2.5382966088427805

Epoch: 5| Step: 5
Training loss: 2.2013193942498415
Validation loss: 2.5494750985244847

Epoch: 5| Step: 6
Training loss: 2.193402528550607
Validation loss: 2.5309506827659356

Epoch: 5| Step: 7
Training loss: 2.8509487379932033
Validation loss: 2.5233212361077135

Epoch: 5| Step: 8
Training loss: 3.148420537330236
Validation loss: 2.5170216816510065

Epoch: 5| Step: 9
Training loss: 2.240020555504081
Validation loss: 2.523624281309216

Epoch: 5| Step: 10
Training loss: 2.687177416936361
Validation loss: 2.553099051472051

Epoch: 129| Step: 0
Training loss: 2.507643078936939
Validation loss: 2.535793699393198

Epoch: 5| Step: 1
Training loss: 2.8032966926922884
Validation loss: 2.5265440813027724

Epoch: 5| Step: 2
Training loss: 2.624244217835632
Validation loss: 2.5477833716157967

Epoch: 5| Step: 3
Training loss: 2.899015219967889
Validation loss: 2.520220091496791

Epoch: 5| Step: 4
Training loss: 2.8512549665609317
Validation loss: 2.5410990569581124

Epoch: 5| Step: 5
Training loss: 2.188064284431601
Validation loss: 2.5384640648355017

Epoch: 5| Step: 6
Training loss: 3.0146118992258524
Validation loss: 2.546165487766754

Epoch: 5| Step: 7
Training loss: 2.755963708104333
Validation loss: 2.554586251906679

Epoch: 5| Step: 8
Training loss: 2.6554890159648394
Validation loss: 2.5627893634153627

Epoch: 5| Step: 9
Training loss: 3.0616628320040404
Validation loss: 2.559375572913205

Epoch: 5| Step: 10
Training loss: 2.9566825953430462
Validation loss: 2.5534259829545825

Epoch: 130| Step: 0
Training loss: 2.8879074932087168
Validation loss: 2.5515062561602146

Epoch: 5| Step: 1
Training loss: 2.616960566916354
Validation loss: 2.547285043298994

Epoch: 5| Step: 2
Training loss: 2.6229292558444177
Validation loss: 2.565489005418381

Epoch: 5| Step: 3
Training loss: 3.0128380740081058
Validation loss: 2.550326936880987

Epoch: 5| Step: 4
Training loss: 2.981051046902465
Validation loss: 2.511812153006772

Epoch: 5| Step: 5
Training loss: 2.4649548875808738
Validation loss: 2.5457591940558544

Epoch: 5| Step: 6
Training loss: 2.807425010406582
Validation loss: 2.540720397516783

Epoch: 5| Step: 7
Training loss: 2.607377252661247
Validation loss: 2.5403704105672253

Epoch: 5| Step: 8
Training loss: 3.5142587677324606
Validation loss: 2.538300870974464

Epoch: 5| Step: 9
Training loss: 2.6071835755455037
Validation loss: 2.5438656195152003

Epoch: 5| Step: 10
Training loss: 1.694284786804449
Validation loss: 2.5492250396148197

Epoch: 131| Step: 0
Training loss: 2.7322826990835303
Validation loss: 2.5557614998171374

Epoch: 5| Step: 1
Training loss: 2.5512600459602384
Validation loss: 2.5305617315967575

Epoch: 5| Step: 2
Training loss: 2.746050165516946
Validation loss: 2.534757959692006

Epoch: 5| Step: 3
Training loss: 2.759417706998264
Validation loss: 2.5254311574312376

Epoch: 5| Step: 4
Training loss: 2.547731033345931
Validation loss: 2.541748128950898

Epoch: 5| Step: 5
Training loss: 3.3713257180474225
Validation loss: 2.554262976264372

Epoch: 5| Step: 6
Training loss: 2.4437701446405358
Validation loss: 2.54130787252728

Epoch: 5| Step: 7
Training loss: 2.956999805036325
Validation loss: 2.5402391850718593

Epoch: 5| Step: 8
Training loss: 2.700861606169396
Validation loss: 2.53880392999793

Epoch: 5| Step: 9
Training loss: 2.5733613364848775
Validation loss: 2.5237629815557

Epoch: 5| Step: 10
Training loss: 2.5581890222892025
Validation loss: 2.5365842395596205

Epoch: 132| Step: 0
Training loss: 2.842292495977574
Validation loss: 2.5208893656742903

Epoch: 5| Step: 1
Training loss: 3.094444736349053
Validation loss: 2.543252549706958

Epoch: 5| Step: 2
Training loss: 2.8233946973789372
Validation loss: 2.5485419797060764

Epoch: 5| Step: 3
Training loss: 2.5706107943360528
Validation loss: 2.545855083090375

Epoch: 5| Step: 4
Training loss: 3.0410813243043524
Validation loss: 2.525716373535098

Epoch: 5| Step: 5
Training loss: 2.413818149483688
Validation loss: 2.548371019127066

Epoch: 5| Step: 6
Training loss: 2.8272358039177754
Validation loss: 2.545118426612844

Epoch: 5| Step: 7
Training loss: 2.482225940094048
Validation loss: 2.5471376039210374

Epoch: 5| Step: 8
Training loss: 2.298766414880356
Validation loss: 2.56310274932247

Epoch: 5| Step: 9
Training loss: 2.787552796278667
Validation loss: 2.5520624735425264

Epoch: 5| Step: 10
Training loss: 2.9508275374583914
Validation loss: 2.556435970523024

Epoch: 133| Step: 0
Training loss: 3.3534694128568265
Validation loss: 2.570187581057575

Epoch: 5| Step: 1
Training loss: 2.521944436933724
Validation loss: 2.557683433293083

Epoch: 5| Step: 2
Training loss: 2.501986858488923
Validation loss: 2.5506647831492635

Epoch: 5| Step: 3
Training loss: 2.618281713600525
Validation loss: 2.5484780966686316

Epoch: 5| Step: 4
Training loss: 2.3046940173040795
Validation loss: 2.5441842076958423

Epoch: 5| Step: 5
Training loss: 2.6311032324517627
Validation loss: 2.5387233202787725

Epoch: 5| Step: 6
Training loss: 3.1374802668585438
Validation loss: 2.542071855007706

Epoch: 5| Step: 7
Training loss: 2.8471828323575537
Validation loss: 2.5295809559449753

Epoch: 5| Step: 8
Training loss: 2.655645144541723
Validation loss: 2.5498453968850026

Epoch: 5| Step: 9
Training loss: 2.318061121690194
Validation loss: 2.5232692113659603

Epoch: 5| Step: 10
Training loss: 3.2916019449430145
Validation loss: 2.5498774129672253

Epoch: 134| Step: 0
Training loss: 2.927981436842561
Validation loss: 2.552248882644203

Epoch: 5| Step: 1
Training loss: 2.441672837007644
Validation loss: 2.5276515301797864

Epoch: 5| Step: 2
Training loss: 2.421284462088273
Validation loss: 2.5441686661984964

Epoch: 5| Step: 3
Training loss: 3.1361481752130413
Validation loss: 2.5144395561848585

Epoch: 5| Step: 4
Training loss: 2.677570006864918
Validation loss: 2.5415711192450585

Epoch: 5| Step: 5
Training loss: 2.2208789765878514
Validation loss: 2.5373327873723466

Epoch: 5| Step: 6
Training loss: 2.7163268943607632
Validation loss: 2.5334900697700165

Epoch: 5| Step: 7
Training loss: 2.3558061905241723
Validation loss: 2.546536101278029

Epoch: 5| Step: 8
Training loss: 3.2736291943050975
Validation loss: 2.530463135505855

Epoch: 5| Step: 9
Training loss: 2.6959568303950565
Validation loss: 2.5329349155816967

Epoch: 5| Step: 10
Training loss: 3.3611705151257185
Validation loss: 2.5359597239191105

Epoch: 135| Step: 0
Training loss: 2.8053026295161394
Validation loss: 2.5244658036758016

Epoch: 5| Step: 1
Training loss: 3.341785317183038
Validation loss: 2.5424696327875855

Epoch: 5| Step: 2
Training loss: 2.5998701026452578
Validation loss: 2.518352245217641

Epoch: 5| Step: 3
Training loss: 2.337610876544242
Validation loss: 2.5466110321193276

Epoch: 5| Step: 4
Training loss: 2.9061927379586465
Validation loss: 2.535635684120112

Epoch: 5| Step: 5
Training loss: 2.4994111321239756
Validation loss: 2.5599572646656

Epoch: 5| Step: 6
Training loss: 2.3521685152084637
Validation loss: 2.55184085908712

Epoch: 5| Step: 7
Training loss: 2.767675297120847
Validation loss: 2.565185112511721

Epoch: 5| Step: 8
Training loss: 3.0235132015716624
Validation loss: 2.5452264759886223

Epoch: 5| Step: 9
Training loss: 2.6916576428650885
Validation loss: 2.561866625953334

Epoch: 5| Step: 10
Training loss: 2.740841875009825
Validation loss: 2.5564671484535744

Epoch: 136| Step: 0
Training loss: 2.5938073577054097
Validation loss: 2.5734398595420056

Epoch: 5| Step: 1
Training loss: 2.7931201813733715
Validation loss: 2.539942821674308

Epoch: 5| Step: 2
Training loss: 2.805357276616098
Validation loss: 2.558209292313523

Epoch: 5| Step: 3
Training loss: 2.7513419258396983
Validation loss: 2.572651788725187

Epoch: 5| Step: 4
Training loss: 2.721367201097049
Validation loss: 2.5425114356623792

Epoch: 5| Step: 5
Training loss: 2.7133295680433136
Validation loss: 2.5573545710136374

Epoch: 5| Step: 6
Training loss: 2.822692036342479
Validation loss: 2.5485598126719604

Epoch: 5| Step: 7
Training loss: 2.588287392196483
Validation loss: 2.571133176833618

Epoch: 5| Step: 8
Training loss: 2.6370673959312443
Validation loss: 2.5322936345025338

Epoch: 5| Step: 9
Training loss: 2.7677812521941756
Validation loss: 2.535980070025471

Epoch: 5| Step: 10
Training loss: 3.0281304106452405
Validation loss: 2.5468402042071707

Epoch: 137| Step: 0
Training loss: 2.41001795243664
Validation loss: 2.538750505865043

Epoch: 5| Step: 1
Training loss: 3.1545716912985178
Validation loss: 2.535104773532692

Epoch: 5| Step: 2
Training loss: 2.507013306474769
Validation loss: 2.5399060767477555

Epoch: 5| Step: 3
Training loss: 2.5392410919763315
Validation loss: 2.540606892209463

Epoch: 5| Step: 4
Training loss: 2.7682511958875256
Validation loss: 2.5367761376499103

Epoch: 5| Step: 5
Training loss: 3.293976725641422
Validation loss: 2.5347933127454016

Epoch: 5| Step: 6
Training loss: 2.6829258338837563
Validation loss: 2.5424412613340586

Epoch: 5| Step: 7
Training loss: 2.6591706319564414
Validation loss: 2.5399567917732218

Epoch: 5| Step: 8
Training loss: 2.488073511000545
Validation loss: 2.5343302321144074

Epoch: 5| Step: 9
Training loss: 2.773870557904474
Validation loss: 2.5354883868277893

Epoch: 5| Step: 10
Training loss: 2.9983527111411883
Validation loss: 2.5413524323158

Epoch: 138| Step: 0
Training loss: 2.606004834250404
Validation loss: 2.533163220917525

Epoch: 5| Step: 1
Training loss: 2.6229475262447304
Validation loss: 2.537761040295522

Epoch: 5| Step: 2
Training loss: 3.0358131905480077
Validation loss: 2.53161991606216

Epoch: 5| Step: 3
Training loss: 2.623876603749052
Validation loss: 2.5413994546955028

Epoch: 5| Step: 4
Training loss: 3.3898697112936214
Validation loss: 2.5184031067147528

Epoch: 5| Step: 5
Training loss: 2.3308703729629925
Validation loss: 2.5325211118976547

Epoch: 5| Step: 6
Training loss: 2.531051627969059
Validation loss: 2.5505263125414523

Epoch: 5| Step: 7
Training loss: 2.7885240734990773
Validation loss: 2.542613568392916

Epoch: 5| Step: 8
Training loss: 2.5051247522656555
Validation loss: 2.535479523480906

Epoch: 5| Step: 9
Training loss: 2.713998435169688
Validation loss: 2.5349602224606858

Epoch: 5| Step: 10
Training loss: 3.025571557896644
Validation loss: 2.5524836802347823

Epoch: 139| Step: 0
Training loss: 2.6816223099451943
Validation loss: 2.571559511370972

Epoch: 5| Step: 1
Training loss: 3.066032396597013
Validation loss: 2.5424601625632888

Epoch: 5| Step: 2
Training loss: 3.504048458347816
Validation loss: 2.5585107943480234

Epoch: 5| Step: 3
Training loss: 2.133916883328311
Validation loss: 2.521825318775308

Epoch: 5| Step: 4
Training loss: 2.5868666901216493
Validation loss: 2.547547494760611

Epoch: 5| Step: 5
Training loss: 2.143642220415228
Validation loss: 2.5247893594940654

Epoch: 5| Step: 6
Training loss: 2.3865399332691624
Validation loss: 2.5500489360723084

Epoch: 5| Step: 7
Training loss: 2.264688127111509
Validation loss: 2.5465594821680138

Epoch: 5| Step: 8
Training loss: 3.2404261205227187
Validation loss: 2.532696595046709

Epoch: 5| Step: 9
Training loss: 3.1587223152303032
Validation loss: 2.5569951565324565

Epoch: 5| Step: 10
Training loss: 2.4867464659042455
Validation loss: 2.5555426348112436

Epoch: 140| Step: 0
Training loss: 3.5655278506070585
Validation loss: 2.528256657711742

Epoch: 5| Step: 1
Training loss: 2.2704884911812315
Validation loss: 2.546521379009216

Epoch: 5| Step: 2
Training loss: 2.457408688033387
Validation loss: 2.5318347605382634

Epoch: 5| Step: 3
Training loss: 2.523701090081319
Validation loss: 2.5421945342142753

Epoch: 5| Step: 4
Training loss: 3.79500606048864
Validation loss: 2.5481780847066267

Epoch: 5| Step: 5
Training loss: 2.333160893562427
Validation loss: 2.5527239777468385

Epoch: 5| Step: 6
Training loss: 2.723186512432474
Validation loss: 2.5668515888948447

Epoch: 5| Step: 7
Training loss: 2.3384664363414034
Validation loss: 2.5533092050010207

Epoch: 5| Step: 8
Training loss: 2.496473495419104
Validation loss: 2.5578360904816466

Epoch: 5| Step: 9
Training loss: 1.9543344643893357
Validation loss: 2.568236890523822

Epoch: 5| Step: 10
Training loss: 3.2703802357824814
Validation loss: 2.5413262929276

Epoch: 141| Step: 0
Training loss: 2.304079447561974
Validation loss: 2.559032734617946

Epoch: 5| Step: 1
Training loss: 2.360579227552166
Validation loss: 2.558483602793558

Epoch: 5| Step: 2
Training loss: 2.9199256310071995
Validation loss: 2.5446960803873138

Epoch: 5| Step: 3
Training loss: 2.8555565858369873
Validation loss: 2.5364630345089587

Epoch: 5| Step: 4
Training loss: 2.756434023156973
Validation loss: 2.5575722690675726

Epoch: 5| Step: 5
Training loss: 2.287581970747318
Validation loss: 2.549648145866666

Epoch: 5| Step: 6
Training loss: 1.9970838028654994
Validation loss: 2.556827818296256

Epoch: 5| Step: 7
Training loss: 2.773902359809698
Validation loss: 2.5592211789027326

Epoch: 5| Step: 8
Training loss: 3.73518471338964
Validation loss: 2.540343769608204

Epoch: 5| Step: 9
Training loss: 3.387044818321476
Validation loss: 2.57069331963373

Epoch: 5| Step: 10
Training loss: 2.148667756659815
Validation loss: 2.548144723270675

Epoch: 142| Step: 0
Training loss: 2.5926031311769595
Validation loss: 2.553711765707747

Epoch: 5| Step: 1
Training loss: 2.4027013000881046
Validation loss: 2.5507745544057268

Epoch: 5| Step: 2
Training loss: 3.234609401888903
Validation loss: 2.5207290614288764

Epoch: 5| Step: 3
Training loss: 2.981103032166301
Validation loss: 2.535984033789696

Epoch: 5| Step: 4
Training loss: 3.0076696584893043
Validation loss: 2.5363428384721436

Epoch: 5| Step: 5
Training loss: 2.8842445682945
Validation loss: 2.544336836509554

Epoch: 5| Step: 6
Training loss: 2.3989795979263953
Validation loss: 2.548983660956132

Epoch: 5| Step: 7
Training loss: 2.4538426412543917
Validation loss: 2.5263613140983345

Epoch: 5| Step: 8
Training loss: 2.868708318935269
Validation loss: 2.537549806214454

Epoch: 5| Step: 9
Training loss: 2.438481060080454
Validation loss: 2.5490929072166253

Epoch: 5| Step: 10
Training loss: 2.802418675735756
Validation loss: 2.542710321136445

Epoch: 143| Step: 0
Training loss: 3.045847714690678
Validation loss: 2.542761206575087

Epoch: 5| Step: 1
Training loss: 2.093541832439659
Validation loss: 2.5495210550478613

Epoch: 5| Step: 2
Training loss: 2.5704695355061276
Validation loss: 2.569545942358479

Epoch: 5| Step: 3
Training loss: 3.069169081528938
Validation loss: 2.5259532771341497

Epoch: 5| Step: 4
Training loss: 2.665515045009065
Validation loss: 2.555807561971517

Epoch: 5| Step: 5
Training loss: 3.0013167352656636
Validation loss: 2.538560609143718

Epoch: 5| Step: 6
Training loss: 2.788873489771356
Validation loss: 2.5471616334950067

Epoch: 5| Step: 7
Training loss: 2.8714526308972634
Validation loss: 2.5357170870652754

Epoch: 5| Step: 8
Training loss: 2.3419518248492115
Validation loss: 2.5252123671614144

Epoch: 5| Step: 9
Training loss: 2.73465679351547
Validation loss: 2.5517262811540142

Epoch: 5| Step: 10
Training loss: 2.9386263372119736
Validation loss: 2.5135900885692584

Epoch: 144| Step: 0
Training loss: 2.418628313024749
Validation loss: 2.526842885666978

Epoch: 5| Step: 1
Training loss: 2.9955559239102723
Validation loss: 2.5334030837658474

Epoch: 5| Step: 2
Training loss: 3.402714565667428
Validation loss: 2.536285585196568

Epoch: 5| Step: 3
Training loss: 2.684934411695187
Validation loss: 2.5449700543350495

Epoch: 5| Step: 4
Training loss: 2.7321230961559597
Validation loss: 2.5441434560927885

Epoch: 5| Step: 5
Training loss: 3.4699964603548934
Validation loss: 2.5342844684850134

Epoch: 5| Step: 6
Training loss: 2.2694590781943784
Validation loss: 2.5475135081861096

Epoch: 5| Step: 7
Training loss: 2.1282492087439016
Validation loss: 2.559820191057328

Epoch: 5| Step: 8
Training loss: 2.3870799389139914
Validation loss: 2.5473941415056487

Epoch: 5| Step: 9
Training loss: 2.353965874495073
Validation loss: 2.5240370866303814

Epoch: 5| Step: 10
Training loss: 2.8440679016162584
Validation loss: 2.530075205740154

Epoch: 145| Step: 0
Training loss: 2.5557761016530782
Validation loss: 2.537632396425889

Epoch: 5| Step: 1
Training loss: 2.4682815686794557
Validation loss: 2.539730592079027

Epoch: 5| Step: 2
Training loss: 2.668890105596698
Validation loss: 2.5295369184998484

Epoch: 5| Step: 3
Training loss: 2.9088710327934453
Validation loss: 2.520937701262873

Epoch: 5| Step: 4
Training loss: 3.2386963213613456
Validation loss: 2.54955276147904

Epoch: 5| Step: 5
Training loss: 2.6641536931961074
Validation loss: 2.541169568986549

Epoch: 5| Step: 6
Training loss: 2.880270894608798
Validation loss: 2.53628410085766

Epoch: 5| Step: 7
Training loss: 2.918350133522545
Validation loss: 2.526063877655476

Epoch: 5| Step: 8
Training loss: 2.731032241066664
Validation loss: 2.542246217045343

Epoch: 5| Step: 9
Training loss: 2.789506721916517
Validation loss: 2.5396799765083227

Epoch: 5| Step: 10
Training loss: 2.3829218604835045
Validation loss: 2.5386863683581247

Epoch: 146| Step: 0
Training loss: 3.1782344712989983
Validation loss: 2.54683078647217

Epoch: 5| Step: 1
Training loss: 2.2756070930428076
Validation loss: 2.5481149290062697

Epoch: 5| Step: 2
Training loss: 2.3881905321056696
Validation loss: 2.553910729565419

Epoch: 5| Step: 3
Training loss: 2.502623040283253
Validation loss: 2.535531865412888

Epoch: 5| Step: 4
Training loss: 2.8322632582767744
Validation loss: 2.5582734634637334

Epoch: 5| Step: 5
Training loss: 2.8569487403594596
Validation loss: 2.56367387953479

Epoch: 5| Step: 6
Training loss: 2.47554789557186
Validation loss: 2.5542866949162

Epoch: 5| Step: 7
Training loss: 3.0624367843642974
Validation loss: 2.5574380132566383

Epoch: 5| Step: 8
Training loss: 2.957202336994591
Validation loss: 2.551070734729712

Epoch: 5| Step: 9
Training loss: 2.8507507004777555
Validation loss: 2.548294054553572

Epoch: 5| Step: 10
Training loss: 2.5082111933004674
Validation loss: 2.570601980284999

Epoch: 147| Step: 0
Training loss: 2.4340610208628073
Validation loss: 2.5484022821459686

Epoch: 5| Step: 1
Training loss: 2.3522309528673926
Validation loss: 2.5397127970502016

Epoch: 5| Step: 2
Training loss: 2.8063971533988163
Validation loss: 2.5580741785001413

Epoch: 5| Step: 3
Training loss: 2.034263136640449
Validation loss: 2.5492312113114295

Epoch: 5| Step: 4
Training loss: 3.099473840914799
Validation loss: 2.5522265613605266

Epoch: 5| Step: 5
Training loss: 2.6256569539836008
Validation loss: 2.5612712888614078

Epoch: 5| Step: 6
Training loss: 2.358725553142287
Validation loss: 2.539683472177656

Epoch: 5| Step: 7
Training loss: 3.4538335979338664
Validation loss: 2.5331710196192287

Epoch: 5| Step: 8
Training loss: 2.866332880444725
Validation loss: 2.5538842348719535

Epoch: 5| Step: 9
Training loss: 2.854862174800979
Validation loss: 2.553665748070408

Epoch: 5| Step: 10
Training loss: 2.9255265047329546
Validation loss: 2.5459179333508826

Epoch: 148| Step: 0
Training loss: 2.7773870150902265
Validation loss: 2.56713948414155

Epoch: 5| Step: 1
Training loss: 2.944032264346086
Validation loss: 2.560742555676233

Epoch: 5| Step: 2
Training loss: 2.932979595645302
Validation loss: 2.5592337961224922

Epoch: 5| Step: 3
Training loss: 3.050450344920194
Validation loss: 2.548640395440118

Epoch: 5| Step: 4
Training loss: 2.6227518172773685
Validation loss: 2.563298715948977

Epoch: 5| Step: 5
Training loss: 2.418025544567238
Validation loss: 2.5490980564313754

Epoch: 5| Step: 6
Training loss: 2.172421393514282
Validation loss: 2.551416013429531

Epoch: 5| Step: 7
Training loss: 2.6273968970543597
Validation loss: 2.5506614522879643

Epoch: 5| Step: 8
Training loss: 2.943600751652954
Validation loss: 2.554596627029018

Epoch: 5| Step: 9
Training loss: 3.0579073977473947
Validation loss: 2.573199682341353

Epoch: 5| Step: 10
Training loss: 2.4002801731606187
Validation loss: 2.5473735901839105

Epoch: 149| Step: 0
Training loss: 2.31132291787112
Validation loss: 2.5572220376150194

Epoch: 5| Step: 1
Training loss: 3.1258311882882897
Validation loss: 2.5479056892872594

Epoch: 5| Step: 2
Training loss: 2.6487016124185105
Validation loss: 2.56567246857788

Epoch: 5| Step: 3
Training loss: 2.910092182862314
Validation loss: 2.552591180823075

Epoch: 5| Step: 4
Training loss: 2.38179149328153
Validation loss: 2.551510147576348

Epoch: 5| Step: 5
Training loss: 2.6534394597949422
Validation loss: 2.546967475601832

Epoch: 5| Step: 6
Training loss: 2.465984775610689
Validation loss: 2.5563191691122453

Epoch: 5| Step: 7
Training loss: 3.6759895808888947
Validation loss: 2.5447796956661985

Epoch: 5| Step: 8
Training loss: 2.606012061804775
Validation loss: 2.5485535246745976

Epoch: 5| Step: 9
Training loss: 2.1826950707930344
Validation loss: 2.524215569145048

Epoch: 5| Step: 10
Training loss: 2.576526863217204
Validation loss: 2.5302133527598287

Epoch: 150| Step: 0
Training loss: 2.845747193968568
Validation loss: 2.5557243157653895

Epoch: 5| Step: 1
Training loss: 2.329027039557242
Validation loss: 2.525147792390067

Epoch: 5| Step: 2
Training loss: 2.7027899914899316
Validation loss: 2.5480122853293623

Epoch: 5| Step: 3
Training loss: 2.7363890287822015
Validation loss: 2.5524032830860173

Epoch: 5| Step: 4
Training loss: 2.8562249514359976
Validation loss: 2.533876968832766

Epoch: 5| Step: 5
Training loss: 2.320115822827699
Validation loss: 2.5541527527029997

Epoch: 5| Step: 6
Training loss: 2.584257657801702
Validation loss: 2.5504492200149085

Epoch: 5| Step: 7
Training loss: 2.7349600029902708
Validation loss: 2.559219561614181

Epoch: 5| Step: 8
Training loss: 2.5401512276693157
Validation loss: 2.561219496471103

Epoch: 5| Step: 9
Training loss: 3.308389956920989
Validation loss: 2.538283961278376

Epoch: 5| Step: 10
Training loss: 3.023372994456827
Validation loss: 2.540421206136547

Epoch: 151| Step: 0
Training loss: 2.785198965721481
Validation loss: 2.5377248456602133

Epoch: 5| Step: 1
Training loss: 2.332653582424039
Validation loss: 2.5401550617967166

Epoch: 5| Step: 2
Training loss: 2.9678139264883674
Validation loss: 2.5370900772134948

Epoch: 5| Step: 3
Training loss: 2.9439558147556153
Validation loss: 2.5414990841068374

Epoch: 5| Step: 4
Training loss: 3.249651963598792
Validation loss: 2.5482584899082026

Epoch: 5| Step: 5
Training loss: 2.5250217436807927
Validation loss: 2.556773181518035

Epoch: 5| Step: 6
Training loss: 2.9539872782645706
Validation loss: 2.5425697697810823

Epoch: 5| Step: 7
Training loss: 2.53048788771852
Validation loss: 2.52727864438614

Epoch: 5| Step: 8
Training loss: 2.765853527562766
Validation loss: 2.5528162279126

Epoch: 5| Step: 9
Training loss: 2.3991579843699467
Validation loss: 2.5251084498635414

Epoch: 5| Step: 10
Training loss: 2.5745303901661205
Validation loss: 2.553369729198112

Epoch: 152| Step: 0
Training loss: 2.326249154166058
Validation loss: 2.539805002999801

Epoch: 5| Step: 1
Training loss: 2.4240156987944013
Validation loss: 2.55443234621571

Epoch: 5| Step: 2
Training loss: 3.0402329257773912
Validation loss: 2.5435483339525193

Epoch: 5| Step: 3
Training loss: 2.1048845885616987
Validation loss: 2.523966783613669

Epoch: 5| Step: 4
Training loss: 3.063292420300502
Validation loss: 2.5466236478916073

Epoch: 5| Step: 5
Training loss: 2.189769439579621
Validation loss: 2.528353350464636

Epoch: 5| Step: 6
Training loss: 2.5127243473230174
Validation loss: 2.5483787521751653

Epoch: 5| Step: 7
Training loss: 2.896341311316431
Validation loss: 2.546720837174414

Epoch: 5| Step: 8
Training loss: 3.0493213711553855
Validation loss: 2.5368221443431658

Epoch: 5| Step: 9
Training loss: 2.9047105875477697
Validation loss: 2.5426962693752335

Epoch: 5| Step: 10
Training loss: 3.2644021697048498
Validation loss: 2.52802467229763

Epoch: 153| Step: 0
Training loss: 2.304447691774221
Validation loss: 2.5191496732853564

Epoch: 5| Step: 1
Training loss: 2.0850911798825664
Validation loss: 2.53682834823517

Epoch: 5| Step: 2
Training loss: 3.0794083296975643
Validation loss: 2.5343697101676446

Epoch: 5| Step: 3
Training loss: 2.504729565548585
Validation loss: 2.550229716143217

Epoch: 5| Step: 4
Training loss: 2.982660250327596
Validation loss: 2.5556471217341215

Epoch: 5| Step: 5
Training loss: 2.8333839711170814
Validation loss: 2.5493972984554167

Epoch: 5| Step: 6
Training loss: 3.6626612865360806
Validation loss: 2.5405041903992815

Epoch: 5| Step: 7
Training loss: 2.3773139924171733
Validation loss: 2.566892696078631

Epoch: 5| Step: 8
Training loss: 2.3511947394959543
Validation loss: 2.537562608474376

Epoch: 5| Step: 9
Training loss: 2.706084995657591
Validation loss: 2.564224133346775

Epoch: 5| Step: 10
Training loss: 2.9457502368679886
Validation loss: 2.5460578165610843

Epoch: 154| Step: 0
Training loss: 2.535926548998228
Validation loss: 2.527859899863754

Epoch: 5| Step: 1
Training loss: 3.0641173159896247
Validation loss: 2.5417073231603613

Epoch: 5| Step: 2
Training loss: 2.7942941361895777
Validation loss: 2.5517175013353395

Epoch: 5| Step: 3
Training loss: 2.270204007732533
Validation loss: 2.5497585360053354

Epoch: 5| Step: 4
Training loss: 2.8289640246383048
Validation loss: 2.5517588935104025

Epoch: 5| Step: 5
Training loss: 2.7766223083134087
Validation loss: 2.5566007217337425

Epoch: 5| Step: 6
Training loss: 2.792453531614592
Validation loss: 2.558335650903501

Epoch: 5| Step: 7
Training loss: 2.8553722276564364
Validation loss: 2.540420544140626

Epoch: 5| Step: 8
Training loss: 2.758302293892863
Validation loss: 2.54793438198486

Epoch: 5| Step: 9
Training loss: 2.6783743885773257
Validation loss: 2.5602910845552787

Epoch: 5| Step: 10
Training loss: 2.562798459419608
Validation loss: 2.557375379952847

Epoch: 155| Step: 0
Training loss: 2.8042359054958044
Validation loss: 2.5539818334432614

Epoch: 5| Step: 1
Training loss: 2.04781977856683
Validation loss: 2.550025814383368

Epoch: 5| Step: 2
Training loss: 2.640442068772288
Validation loss: 2.5458034976917268

Epoch: 5| Step: 3
Training loss: 2.5413198911979173
Validation loss: 2.5456651815933804

Epoch: 5| Step: 4
Training loss: 2.0690626294266075
Validation loss: 2.5432014699718737

Epoch: 5| Step: 5
Training loss: 2.878697878207962
Validation loss: 2.5317149887890755

Epoch: 5| Step: 6
Training loss: 3.1609116678129916
Validation loss: 2.536756324955292

Epoch: 5| Step: 7
Training loss: 2.718734741168118
Validation loss: 2.5351767496882713

Epoch: 5| Step: 8
Training loss: 3.3794100170885795
Validation loss: 2.541954264986033

Epoch: 5| Step: 9
Training loss: 2.5426477091895516
Validation loss: 2.5381808963028356

Epoch: 5| Step: 10
Training loss: 2.8873384504828525
Validation loss: 2.551149335917748

Epoch: 156| Step: 0
Training loss: 2.641141581370495
Validation loss: 2.5452979775742577

Epoch: 5| Step: 1
Training loss: 2.4450862889577576
Validation loss: 2.5455992111804715

Epoch: 5| Step: 2
Training loss: 2.8085518994350216
Validation loss: 2.5398687892636227

Epoch: 5| Step: 3
Training loss: 2.273123912879195
Validation loss: 2.528824795328748

Epoch: 5| Step: 4
Training loss: 3.136866811865901
Validation loss: 2.5423083598945433

Epoch: 5| Step: 5
Training loss: 2.959857028910653
Validation loss: 2.5419260985656815

Epoch: 5| Step: 6
Training loss: 2.125788710587044
Validation loss: 2.5393484247732836

Epoch: 5| Step: 7
Training loss: 3.1933347368602285
Validation loss: 2.553353584465419

Epoch: 5| Step: 8
Training loss: 2.7943210982429076
Validation loss: 2.558297553785423

Epoch: 5| Step: 9
Training loss: 2.903117635038004
Validation loss: 2.5624133439797396

Epoch: 5| Step: 10
Training loss: 2.307284479295086
Validation loss: 2.5331998885726055

Epoch: 157| Step: 0
Training loss: 3.4140636173482153
Validation loss: 2.555724435635536

Epoch: 5| Step: 1
Training loss: 2.106333482485838
Validation loss: 2.5533613064395446

Epoch: 5| Step: 2
Training loss: 2.5489159579873495
Validation loss: 2.5352663843271244

Epoch: 5| Step: 3
Training loss: 2.2626947856535318
Validation loss: 2.546169476956101

Epoch: 5| Step: 4
Training loss: 2.2987673483230764
Validation loss: 2.55867534132557

Epoch: 5| Step: 5
Training loss: 2.655205016185853
Validation loss: 2.5562277554153088

Epoch: 5| Step: 6
Training loss: 2.6707061530990583
Validation loss: 2.5599076148492794

Epoch: 5| Step: 7
Training loss: 3.1722593779279857
Validation loss: 2.5501304097280117

Epoch: 5| Step: 8
Training loss: 3.21775506206817
Validation loss: 2.565906762180526

Epoch: 5| Step: 9
Training loss: 2.66502913224721
Validation loss: 2.5492735599903638

Epoch: 5| Step: 10
Training loss: 2.7365096996546003
Validation loss: 2.558810994471442

Epoch: 158| Step: 0
Training loss: 3.0353120938111022
Validation loss: 2.533870322662637

Epoch: 5| Step: 1
Training loss: 3.230856340582392
Validation loss: 2.538084760769934

Epoch: 5| Step: 2
Training loss: 3.219489003501107
Validation loss: 2.566872655422516

Epoch: 5| Step: 3
Training loss: 3.1148567377398058
Validation loss: 2.5496437931053637

Epoch: 5| Step: 4
Training loss: 2.263099683668984
Validation loss: 2.5542921708905073

Epoch: 5| Step: 5
Training loss: 2.5506548769901567
Validation loss: 2.552368905164811

Epoch: 5| Step: 6
Training loss: 2.593218001993947
Validation loss: 2.5304648689385867

Epoch: 5| Step: 7
Training loss: 2.526685861985995
Validation loss: 2.5753165571667287

Epoch: 5| Step: 8
Training loss: 2.636944163541762
Validation loss: 2.5388628965917075

Epoch: 5| Step: 9
Training loss: 2.325716859786623
Validation loss: 2.5416069085936552

Epoch: 5| Step: 10
Training loss: 2.175159523035742
Validation loss: 2.5442695338479666

Epoch: 159| Step: 0
Training loss: 2.655695419760448
Validation loss: 2.5344943815994467

Epoch: 5| Step: 1
Training loss: 2.828794958521808
Validation loss: 2.5583677250744787

Epoch: 5| Step: 2
Training loss: 3.098314559274983
Validation loss: 2.535381554437386

Epoch: 5| Step: 3
Training loss: 2.3951853221318715
Validation loss: 2.5454152167309356

Epoch: 5| Step: 4
Training loss: 3.399930358622283
Validation loss: 2.548575189078801

Epoch: 5| Step: 5
Training loss: 2.426742879103952
Validation loss: 2.5491442229008854

Epoch: 5| Step: 6
Training loss: 2.1491457239999012
Validation loss: 2.544483351557394

Epoch: 5| Step: 7
Training loss: 3.088391528198022
Validation loss: 2.5485202496339223

Epoch: 5| Step: 8
Training loss: 2.6206825718377234
Validation loss: 2.5221330649243257

Epoch: 5| Step: 9
Training loss: 2.360947444952892
Validation loss: 2.5451694003897343

Epoch: 5| Step: 10
Training loss: 2.5437898262524095
Validation loss: 2.555500141732392

Epoch: 160| Step: 0
Training loss: 2.8504864060111728
Validation loss: 2.5346763651268622

Epoch: 5| Step: 1
Training loss: 3.1210619718344668
Validation loss: 2.548556911604556

Epoch: 5| Step: 2
Training loss: 2.337570589193073
Validation loss: 2.5223981054604847

Epoch: 5| Step: 3
Training loss: 1.9698813684441527
Validation loss: 2.5399519555902446

Epoch: 5| Step: 4
Training loss: 2.692140609146878
Validation loss: 2.540959085395063

Epoch: 5| Step: 5
Training loss: 2.39089824635815
Validation loss: 2.557915312630819

Epoch: 5| Step: 6
Training loss: 2.1932502372947678
Validation loss: 2.5521699074950344

Epoch: 5| Step: 7
Training loss: 2.6331567737283965
Validation loss: 2.5514344522882113

Epoch: 5| Step: 8
Training loss: 3.3906349849993385
Validation loss: 2.5368920759506293

Epoch: 5| Step: 9
Training loss: 3.2445778732936428
Validation loss: 2.5489713294240213

Epoch: 5| Step: 10
Training loss: 2.803103538949862
Validation loss: 2.537079786617424

Epoch: 161| Step: 0
Training loss: 2.4019001869153622
Validation loss: 2.5523993217188696

Epoch: 5| Step: 1
Training loss: 2.876254430018946
Validation loss: 2.5533273510651457

Epoch: 5| Step: 2
Training loss: 2.6743268814982217
Validation loss: 2.5558624781770036

Epoch: 5| Step: 3
Training loss: 2.4608208522701878
Validation loss: 2.5498474278128493

Epoch: 5| Step: 4
Training loss: 2.9568322541818493
Validation loss: 2.5376676296260325

Epoch: 5| Step: 5
Training loss: 2.8974704825845476
Validation loss: 2.5389798836089295

Epoch: 5| Step: 6
Training loss: 2.9314138793683364
Validation loss: 2.528796617501407

Epoch: 5| Step: 7
Training loss: 2.7081036005642694
Validation loss: 2.5458661941505576

Epoch: 5| Step: 8
Training loss: 2.6929826037230686
Validation loss: 2.539632151069374

Epoch: 5| Step: 9
Training loss: 2.431562184979818
Validation loss: 2.52425804044002

Epoch: 5| Step: 10
Training loss: 2.7829895580067068
Validation loss: 2.537713671678311

Epoch: 162| Step: 0
Training loss: 2.855662786776868
Validation loss: 2.5455753884189276

Epoch: 5| Step: 1
Training loss: 2.3706973402801603
Validation loss: 2.5310298409194396

Epoch: 5| Step: 2
Training loss: 3.1545650403616774
Validation loss: 2.517178778593389

Epoch: 5| Step: 3
Training loss: 2.185919708550386
Validation loss: 2.5310075143166344

Epoch: 5| Step: 4
Training loss: 2.1155167071576013
Validation loss: 2.526895275114521

Epoch: 5| Step: 5
Training loss: 2.2376203110385084
Validation loss: 2.526707965512121

Epoch: 5| Step: 6
Training loss: 2.5829978437898373
Validation loss: 2.5419001183767636

Epoch: 5| Step: 7
Training loss: 2.9607363509243876
Validation loss: 2.5767307383253226

Epoch: 5| Step: 8
Training loss: 3.144923215332049
Validation loss: 2.5415161030387936

Epoch: 5| Step: 9
Training loss: 2.7244009286863506
Validation loss: 2.5463766806716714

Epoch: 5| Step: 10
Training loss: 3.316703863909774
Validation loss: 2.5541572583742638

Epoch: 163| Step: 0
Training loss: 2.3403724238735975
Validation loss: 2.587508541729357

Epoch: 5| Step: 1
Training loss: 2.7374438693767367
Validation loss: 2.52565212732776

Epoch: 5| Step: 2
Training loss: 2.7714375766838186
Validation loss: 2.547075003174306

Epoch: 5| Step: 3
Training loss: 2.5919445142399713
Validation loss: 2.5413684116901285

Epoch: 5| Step: 4
Training loss: 2.2594080372527867
Validation loss: 2.5493900260402733

Epoch: 5| Step: 5
Training loss: 2.2793475017138864
Validation loss: 2.55383484643956

Epoch: 5| Step: 6
Training loss: 3.338086617453927
Validation loss: 2.555147599040597

Epoch: 5| Step: 7
Training loss: 2.7572601024481695
Validation loss: 2.532090599849626

Epoch: 5| Step: 8
Training loss: 2.7966312749788265
Validation loss: 2.5305912543618696

Epoch: 5| Step: 9
Training loss: 2.8438915175553103
Validation loss: 2.5416219220861853

Epoch: 5| Step: 10
Training loss: 3.0437739314522974
Validation loss: 2.5410205726600275

Epoch: 164| Step: 0
Training loss: 2.6394950661256336
Validation loss: 2.535865100981629

Epoch: 5| Step: 1
Training loss: 2.6710748199300878
Validation loss: 2.535278995880166

Epoch: 5| Step: 2
Training loss: 2.940487093635909
Validation loss: 2.5522103059351067

Epoch: 5| Step: 3
Training loss: 2.4537645223132425
Validation loss: 2.555070504977948

Epoch: 5| Step: 4
Training loss: 2.423194673376315
Validation loss: 2.551484483009758

Epoch: 5| Step: 5
Training loss: 2.641571958591049
Validation loss: 2.5318838025096895

Epoch: 5| Step: 6
Training loss: 2.8126174902217453
Validation loss: 2.528102818774356

Epoch: 5| Step: 7
Training loss: 2.8447367873893654
Validation loss: 2.550814267404798

Epoch: 5| Step: 8
Training loss: 2.604333633156575
Validation loss: 2.534095011012936

Epoch: 5| Step: 9
Training loss: 2.8321677970853294
Validation loss: 2.5444490328749163

Epoch: 5| Step: 10
Training loss: 3.031783696020474
Validation loss: 2.548420988267444

Epoch: 165| Step: 0
Training loss: 3.091486401370842
Validation loss: 2.570243317114691

Epoch: 5| Step: 1
Training loss: 2.7329832186192426
Validation loss: 2.5510905126273133

Epoch: 5| Step: 2
Training loss: 3.1390147469943726
Validation loss: 2.5399255075674803

Epoch: 5| Step: 3
Training loss: 2.918111243592415
Validation loss: 2.5517930154286654

Epoch: 5| Step: 4
Training loss: 2.3754753841665566
Validation loss: 2.533061435842009

Epoch: 5| Step: 5
Training loss: 2.4848434678328024
Validation loss: 2.5375050826612564

Epoch: 5| Step: 6
Training loss: 1.5333487471897653
Validation loss: 2.5528912355183895

Epoch: 5| Step: 7
Training loss: 3.2651515781799794
Validation loss: 2.5514103343427332

Epoch: 5| Step: 8
Training loss: 2.9241970035968383
Validation loss: 2.5384818171126144

Epoch: 5| Step: 9
Training loss: 2.631110028601043
Validation loss: 2.548292304074176

Epoch: 5| Step: 10
Training loss: 2.3819150141265504
Validation loss: 2.5343164636610966

Epoch: 166| Step: 0
Training loss: 2.800603927468328
Validation loss: 2.5333209087129753

Epoch: 5| Step: 1
Training loss: 2.5186246438459494
Validation loss: 2.5587720287678497

Epoch: 5| Step: 2
Training loss: 2.960383461522816
Validation loss: 2.543314403873728

Epoch: 5| Step: 3
Training loss: 2.6193758341906928
Validation loss: 2.518020876964683

Epoch: 5| Step: 4
Training loss: 2.7344621916902057
Validation loss: 2.553215697461822

Epoch: 5| Step: 5
Training loss: 2.574762544516393
Validation loss: 2.540281121533693

Epoch: 5| Step: 6
Training loss: 2.9901514521487216
Validation loss: 2.5279022546598178

Epoch: 5| Step: 7
Training loss: 2.7889255522116057
Validation loss: 2.552934299725834

Epoch: 5| Step: 8
Training loss: 2.2748382552781643
Validation loss: 2.5320558955178525

Epoch: 5| Step: 9
Training loss: 3.002477258854995
Validation loss: 2.5292487442657694

Epoch: 5| Step: 10
Training loss: 2.458588656943555
Validation loss: 2.5309215045372433

Epoch: 167| Step: 0
Training loss: 2.8098729049883198
Validation loss: 2.536175510291046

Epoch: 5| Step: 1
Training loss: 2.761369955652886
Validation loss: 2.5366899540800185

Epoch: 5| Step: 2
Training loss: 2.5134700288034786
Validation loss: 2.546835382604996

Epoch: 5| Step: 3
Training loss: 2.087307255235508
Validation loss: 2.52006508139453

Epoch: 5| Step: 4
Training loss: 2.8597088394811183
Validation loss: 2.548661596402415

Epoch: 5| Step: 5
Training loss: 3.3354953589003244
Validation loss: 2.540175227455491

Epoch: 5| Step: 6
Training loss: 2.775493708500838
Validation loss: 2.532489517180986

Epoch: 5| Step: 7
Training loss: 2.501786356720016
Validation loss: 2.5814193952065456

Epoch: 5| Step: 8
Training loss: 2.9290396419094353
Validation loss: 2.5489574600249676

Epoch: 5| Step: 9
Training loss: 2.2404257202911437
Validation loss: 2.5481268049005625

Epoch: 5| Step: 10
Training loss: 2.9406826552800527
Validation loss: 2.5574978944373243

Epoch: 168| Step: 0
Training loss: 2.609100875617957
Validation loss: 2.569818649676734

Epoch: 5| Step: 1
Training loss: 2.9527687786352335
Validation loss: 2.549366079817631

Epoch: 5| Step: 2
Training loss: 3.065460953518075
Validation loss: 2.539149427921594

Epoch: 5| Step: 3
Training loss: 2.668927088988279
Validation loss: 2.5573211528542705

Epoch: 5| Step: 4
Training loss: 1.7808829481502166
Validation loss: 2.5589759288856726

Epoch: 5| Step: 5
Training loss: 3.2550171493336335
Validation loss: 2.5534927360587343

Epoch: 5| Step: 6
Training loss: 2.429682201122136
Validation loss: 2.57557696791814

Epoch: 5| Step: 7
Training loss: 2.705114613641539
Validation loss: 2.5588039461834873

Epoch: 5| Step: 8
Training loss: 2.6656633416802613
Validation loss: 2.5352886668522028

Epoch: 5| Step: 9
Training loss: 2.657171291574202
Validation loss: 2.5556777179515313

Epoch: 5| Step: 10
Training loss: 2.8528513046970088
Validation loss: 2.5353815210695716

Epoch: 169| Step: 0
Training loss: 2.8902122409064273
Validation loss: 2.5681144101884095

Epoch: 5| Step: 1
Training loss: 2.993550361236435
Validation loss: 2.558213994771864

Epoch: 5| Step: 2
Training loss: 2.6817837626242533
Validation loss: 2.5439803978048756

Epoch: 5| Step: 3
Training loss: 3.020206272331279
Validation loss: 2.533968658705327

Epoch: 5| Step: 4
Training loss: 2.908368886677488
Validation loss: 2.5746845661261406

Epoch: 5| Step: 5
Training loss: 2.752849403122734
Validation loss: 2.556961026332833

Epoch: 5| Step: 6
Training loss: 2.649418201998701
Validation loss: 2.543656181932818

Epoch: 5| Step: 7
Training loss: 2.241091683067715
Validation loss: 2.571115701846764

Epoch: 5| Step: 8
Training loss: 2.961955758495255
Validation loss: 2.5357092436213393

Epoch: 5| Step: 9
Training loss: 2.202965155680483
Validation loss: 2.5557453521377367

Epoch: 5| Step: 10
Training loss: 2.1219784066758165
Validation loss: 2.53244361703162

Epoch: 170| Step: 0
Training loss: 2.994857194708826
Validation loss: 2.5536288356819954

Epoch: 5| Step: 1
Training loss: 3.0473247489577395
Validation loss: 2.5337269649104757

Epoch: 5| Step: 2
Training loss: 1.7796861576547491
Validation loss: 2.5450021438368795

Epoch: 5| Step: 3
Training loss: 2.8443103280172206
Validation loss: 2.5568865677484376

Epoch: 5| Step: 4
Training loss: 2.3229392240195974
Validation loss: 2.5527334028641477

Epoch: 5| Step: 5
Training loss: 3.1814000721966043
Validation loss: 2.522842886281434

Epoch: 5| Step: 6
Training loss: 2.8708980986695325
Validation loss: 2.5380131862741986

Epoch: 5| Step: 7
Training loss: 2.652758379116887
Validation loss: 2.5414131424084054

Epoch: 5| Step: 8
Training loss: 2.4841906401168354
Validation loss: 2.5426700218041276

Epoch: 5| Step: 9
Training loss: 2.972706778017928
Validation loss: 2.535710805639371

Epoch: 5| Step: 10
Training loss: 2.261950756026039
Validation loss: 2.5502588483742485

Epoch: 171| Step: 0
Training loss: 2.5978354026567723
Validation loss: 2.5376130581655096

Epoch: 5| Step: 1
Training loss: 2.52993344577506
Validation loss: 2.5604354190739627

Epoch: 5| Step: 2
Training loss: 2.6786774714232853
Validation loss: 2.5514241180633555

Epoch: 5| Step: 3
Training loss: 2.92032096457441
Validation loss: 2.5535745470936564

Epoch: 5| Step: 4
Training loss: 2.5359352925044787
Validation loss: 2.543815371930699

Epoch: 5| Step: 5
Training loss: 2.3986782487452163
Validation loss: 2.54825745218151

Epoch: 5| Step: 6
Training loss: 3.0570416757165533
Validation loss: 2.5446184324155867

Epoch: 5| Step: 7
Training loss: 3.112497879701681
Validation loss: 2.5589026875722363

Epoch: 5| Step: 8
Training loss: 2.869392399553387
Validation loss: 2.534274489193037

Epoch: 5| Step: 9
Training loss: 2.427528722496886
Validation loss: 2.5204419739317276

Epoch: 5| Step: 10
Training loss: 2.5740694457128654
Validation loss: 2.5524349697843074

Epoch: 172| Step: 0
Training loss: 2.6502983285214468
Validation loss: 2.5315863561683245

Epoch: 5| Step: 1
Training loss: 2.815674240918015
Validation loss: 2.545641994910689

Epoch: 5| Step: 2
Training loss: 2.1691686660380265
Validation loss: 2.5424786845224507

Epoch: 5| Step: 3
Training loss: 2.28983374612654
Validation loss: 2.5516325196890635

Epoch: 5| Step: 4
Training loss: 2.7817558085803573
Validation loss: 2.5616147442802584

Epoch: 5| Step: 5
Training loss: 3.2407155567785164
Validation loss: 2.571936773281165

Epoch: 5| Step: 6
Training loss: 3.1456500035775314
Validation loss: 2.566238734240337

Epoch: 5| Step: 7
Training loss: 2.5421508786424765
Validation loss: 2.5545250073688552

Epoch: 5| Step: 8
Training loss: 2.5533138396744905
Validation loss: 2.545096453765671

Epoch: 5| Step: 9
Training loss: 2.740307633609564
Validation loss: 2.5524990159298055

Epoch: 5| Step: 10
Training loss: 2.683481450070243
Validation loss: 2.5814811839590557

Epoch: 173| Step: 0
Training loss: 2.9060329233130506
Validation loss: 2.5395652163522047

Epoch: 5| Step: 1
Training loss: 2.969710184721363
Validation loss: 2.5331532700995716

Epoch: 5| Step: 2
Training loss: 2.39677247147686
Validation loss: 2.540026642124558

Epoch: 5| Step: 3
Training loss: 2.175290283475475
Validation loss: 2.5683677984815643

Epoch: 5| Step: 4
Training loss: 2.309022402139651
Validation loss: 2.542267491499337

Epoch: 5| Step: 5
Training loss: 2.111188772791953
Validation loss: 2.540611043504569

Epoch: 5| Step: 6
Training loss: 2.752910374427865
Validation loss: 2.53405008485112

Epoch: 5| Step: 7
Training loss: 3.0504300236462725
Validation loss: 2.555940690281659

Epoch: 5| Step: 8
Training loss: 2.7715359898734966
Validation loss: 2.5650267880061652

Epoch: 5| Step: 9
Training loss: 3.270687577873445
Validation loss: 2.5538930845356838

Epoch: 5| Step: 10
Training loss: 2.7384532923397056
Validation loss: 2.542534624678422

Epoch: 174| Step: 0
Training loss: 3.3399402626771564
Validation loss: 2.542636253355378

Epoch: 5| Step: 1
Training loss: 3.5101936941147045
Validation loss: 2.5514406457695618

Epoch: 5| Step: 2
Training loss: 2.606531661294481
Validation loss: 2.5361564479995784

Epoch: 5| Step: 3
Training loss: 2.928690097145758
Validation loss: 2.5425689177782287

Epoch: 5| Step: 4
Training loss: 2.501646358078018
Validation loss: 2.5444321484210493

Epoch: 5| Step: 5
Training loss: 2.0964954652416514
Validation loss: 2.5397520036870542

Epoch: 5| Step: 6
Training loss: 2.1451856382553247
Validation loss: 2.542048388468328

Epoch: 5| Step: 7
Training loss: 3.1984510606889187
Validation loss: 2.534023697643773

Epoch: 5| Step: 8
Training loss: 2.2199927060119125
Validation loss: 2.5400770267279076

Epoch: 5| Step: 9
Training loss: 2.3484603342658086
Validation loss: 2.518736259825826

Epoch: 5| Step: 10
Training loss: 2.3754279102522604
Validation loss: 2.54143709345894

Epoch: 175| Step: 0
Training loss: 2.20143787905804
Validation loss: 2.5282263410953356

Epoch: 5| Step: 1
Training loss: 2.2676432072042205
Validation loss: 2.530463662323643

Epoch: 5| Step: 2
Training loss: 3.089227009600574
Validation loss: 2.530806867387692

Epoch: 5| Step: 3
Training loss: 2.537286600995887
Validation loss: 2.547420919062525

Epoch: 5| Step: 4
Training loss: 3.059868596814731
Validation loss: 2.5402976077001926

Epoch: 5| Step: 5
Training loss: 2.8790440519937017
Validation loss: 2.5598471350688285

Epoch: 5| Step: 6
Training loss: 2.542355605594755
Validation loss: 2.5533855495314897

Epoch: 5| Step: 7
Training loss: 2.823856905686176
Validation loss: 2.5598550647904257

Epoch: 5| Step: 8
Training loss: 2.9983587543907646
Validation loss: 2.550750822191592

Epoch: 5| Step: 9
Training loss: 2.417599454173311
Validation loss: 2.5340468677156562

Epoch: 5| Step: 10
Training loss: 2.7991409073742495
Validation loss: 2.5727017127569574

Epoch: 176| Step: 0
Training loss: 3.0759762462596667
Validation loss: 2.558809190572443

Epoch: 5| Step: 1
Training loss: 3.2637035795232197
Validation loss: 2.543730333900305

Epoch: 5| Step: 2
Training loss: 2.6558189491127417
Validation loss: 2.5251453659562237

Epoch: 5| Step: 3
Training loss: 2.5447719761110994
Validation loss: 2.534269578942094

Epoch: 5| Step: 4
Training loss: 2.701059070143197
Validation loss: 2.5394040315819386

Epoch: 5| Step: 5
Training loss: 3.0442557790017974
Validation loss: 2.543457895554545

Epoch: 5| Step: 6
Training loss: 3.1697597121375667
Validation loss: 2.561369101394936

Epoch: 5| Step: 7
Training loss: 2.772185136890576
Validation loss: 2.5357497506335496

Epoch: 5| Step: 8
Training loss: 1.8711310842846944
Validation loss: 2.5398787445566446

Epoch: 5| Step: 9
Training loss: 1.9667443246649232
Validation loss: 2.5453939917505677

Epoch: 5| Step: 10
Training loss: 2.2856411411298563
Validation loss: 2.560740068863798

Epoch: 177| Step: 0
Training loss: 3.1413840520074956
Validation loss: 2.5305216399772124

Epoch: 5| Step: 1
Training loss: 2.880277351164104
Validation loss: 2.548580923772791

Epoch: 5| Step: 2
Training loss: 2.649630387639203
Validation loss: 2.5292256315992825

Epoch: 5| Step: 3
Training loss: 2.4621749431020237
Validation loss: 2.5630881092089752

Epoch: 5| Step: 4
Training loss: 1.7459950259160768
Validation loss: 2.536880610294421

Epoch: 5| Step: 5
Training loss: 2.711444554469158
Validation loss: 2.5494396494033325

Epoch: 5| Step: 6
Training loss: 2.8286742630688058
Validation loss: 2.558129620281906

Epoch: 5| Step: 7
Training loss: 2.991122940368211
Validation loss: 2.5453443751254246

Epoch: 5| Step: 8
Training loss: 2.921084210282547
Validation loss: 2.555828310282966

Epoch: 5| Step: 9
Training loss: 2.330480625532829
Validation loss: 2.5379339701660077

Epoch: 5| Step: 10
Training loss: 2.7444645049082292
Validation loss: 2.546357472247192

Epoch: 178| Step: 0
Training loss: 2.958912501705487
Validation loss: 2.5583203732436606

Epoch: 5| Step: 1
Training loss: 2.0971041331051423
Validation loss: 2.53856758235295

Epoch: 5| Step: 2
Training loss: 2.473620089781731
Validation loss: 2.5372892300207184

Epoch: 5| Step: 3
Training loss: 2.9166994002185676
Validation loss: 2.533737302513265

Epoch: 5| Step: 4
Training loss: 2.741519422741662
Validation loss: 2.542640049454712

Epoch: 5| Step: 5
Training loss: 2.451528916818804
Validation loss: 2.5417418957138698

Epoch: 5| Step: 6
Training loss: 3.2559276223538562
Validation loss: 2.554815964424303

Epoch: 5| Step: 7
Training loss: 2.8247495287020308
Validation loss: 2.5501391326825966

Epoch: 5| Step: 8
Training loss: 2.6000302129603967
Validation loss: 2.531058105300736

Epoch: 5| Step: 9
Training loss: 2.5315996093441098
Validation loss: 2.5299618541356907

Epoch: 5| Step: 10
Training loss: 2.4475652780682426
Validation loss: 2.535835618385557

Epoch: 179| Step: 0
Training loss: 2.4386297688843053
Validation loss: 2.5502628140714756

Epoch: 5| Step: 1
Training loss: 2.5599637389595187
Validation loss: 2.5376400672350856

Epoch: 5| Step: 2
Training loss: 2.72635096737756
Validation loss: 2.5382197438064558

Epoch: 5| Step: 3
Training loss: 2.69646714398558
Validation loss: 2.5331168694568826

Epoch: 5| Step: 4
Training loss: 3.1165848916761316
Validation loss: 2.536554488396314

Epoch: 5| Step: 5
Training loss: 2.415504790124267
Validation loss: 2.548055596998133

Epoch: 5| Step: 6
Training loss: 2.5007244014266883
Validation loss: 2.529967878268192

Epoch: 5| Step: 7
Training loss: 3.1771198374834646
Validation loss: 2.5264762752344256

Epoch: 5| Step: 8
Training loss: 2.6329917054355363
Validation loss: 2.5197002471542658

Epoch: 5| Step: 9
Training loss: 2.5962822743789618
Validation loss: 2.5559138936574226

Epoch: 5| Step: 10
Training loss: 2.5859961373402838
Validation loss: 2.5544307936385695

Epoch: 180| Step: 0
Training loss: 2.969567758465723
Validation loss: 2.536401543898842

Epoch: 5| Step: 1
Training loss: 3.0045747843929207
Validation loss: 2.547836970589111

Epoch: 5| Step: 2
Training loss: 2.887721897863334
Validation loss: 2.52982950402383

Epoch: 5| Step: 3
Training loss: 2.518821912169622
Validation loss: 2.562767202961073

Epoch: 5| Step: 4
Training loss: 2.0658996768755618
Validation loss: 2.548431500655118

Epoch: 5| Step: 5
Training loss: 2.300654409438741
Validation loss: 2.5426956936718015

Epoch: 5| Step: 6
Training loss: 2.5026264699100196
Validation loss: 2.5562886337247956

Epoch: 5| Step: 7
Training loss: 2.243952465220289
Validation loss: 2.551566941682346

Epoch: 5| Step: 8
Training loss: 2.4005680127320788
Validation loss: 2.546504921558256

Epoch: 5| Step: 9
Training loss: 3.2347892459098633
Validation loss: 2.550400622491895

Epoch: 5| Step: 10
Training loss: 3.3900425845821998
Validation loss: 2.5396553941352282

Epoch: 181| Step: 0
Training loss: 2.7694993118144784
Validation loss: 2.527754349524674

Epoch: 5| Step: 1
Training loss: 2.0007781660658703
Validation loss: 2.552020381094983

Epoch: 5| Step: 2
Training loss: 2.451524929441937
Validation loss: 2.547619526927387

Epoch: 5| Step: 3
Training loss: 2.571506489602567
Validation loss: 2.5409828656784113

Epoch: 5| Step: 4
Training loss: 3.3370460973110054
Validation loss: 2.558986707475341

Epoch: 5| Step: 5
Training loss: 3.1410496362980305
Validation loss: 2.5383049573622443

Epoch: 5| Step: 6
Training loss: 2.754579805291007
Validation loss: 2.5529582335671783

Epoch: 5| Step: 7
Training loss: 2.4688394264731954
Validation loss: 2.54785550980783

Epoch: 5| Step: 8
Training loss: 2.6942272710507793
Validation loss: 2.5326717378916324

Epoch: 5| Step: 9
Training loss: 2.559139839892164
Validation loss: 2.5330978974986995

Epoch: 5| Step: 10
Training loss: 2.4832599944821148
Validation loss: 2.5450291822724136

Epoch: 182| Step: 0
Training loss: 2.903815777970031
Validation loss: 2.555424479861844

Epoch: 5| Step: 1
Training loss: 3.062943874032966
Validation loss: 2.5405536301079925

Epoch: 5| Step: 2
Training loss: 3.164287643899486
Validation loss: 2.524426919189511

Epoch: 5| Step: 3
Training loss: 2.701647227752931
Validation loss: 2.543966777314868

Epoch: 5| Step: 4
Training loss: 2.432336767351674
Validation loss: 2.562669916969807

Epoch: 5| Step: 5
Training loss: 2.2687162160328427
Validation loss: 2.559229480700749

Epoch: 5| Step: 6
Training loss: 2.476927047517622
Validation loss: 2.538328292873779

Epoch: 5| Step: 7
Training loss: 2.7323237109053418
Validation loss: 2.5232120404179823

Epoch: 5| Step: 8
Training loss: 2.861968318419973
Validation loss: 2.5340004140499675

Epoch: 5| Step: 9
Training loss: 2.103500436995424
Validation loss: 2.5592965978079185

Epoch: 5| Step: 10
Training loss: 2.911576670708093
Validation loss: 2.551859155234277

Epoch: 183| Step: 0
Training loss: 2.440328082243618
Validation loss: 2.5418519590171798

Epoch: 5| Step: 1
Training loss: 3.514622931190444
Validation loss: 2.5301113872042684

Epoch: 5| Step: 2
Training loss: 2.781289261101487
Validation loss: 2.5596513909471184

Epoch: 5| Step: 3
Training loss: 2.614198349856058
Validation loss: 2.5221589244826323

Epoch: 5| Step: 4
Training loss: 2.583775472233988
Validation loss: 2.5395211299531164

Epoch: 5| Step: 5
Training loss: 2.846219510135845
Validation loss: 2.549813297956103

Epoch: 5| Step: 6
Training loss: 2.6201519475075
Validation loss: 2.561222758549781

Epoch: 5| Step: 7
Training loss: 2.5909555847766197
Validation loss: 2.5486071295808315

Epoch: 5| Step: 8
Training loss: 2.5959830725166464
Validation loss: 2.5676013067503947

Epoch: 5| Step: 9
Training loss: 2.0734698709175947
Validation loss: 2.544761398235018

Epoch: 5| Step: 10
Training loss: 2.7383803323840166
Validation loss: 2.5412351832754774

Epoch: 184| Step: 0
Training loss: 3.0460682901402985
Validation loss: 2.5277416020516443

Epoch: 5| Step: 1
Training loss: 2.1452142013623168
Validation loss: 2.550577785334175

Epoch: 5| Step: 2
Training loss: 2.13255884248109
Validation loss: 2.5391338328902724

Epoch: 5| Step: 3
Training loss: 2.472224434364653
Validation loss: 2.5709628669272693

Epoch: 5| Step: 4
Training loss: 2.8592395854632535
Validation loss: 2.538229346003224

Epoch: 5| Step: 5
Training loss: 2.8728669588040936
Validation loss: 2.552134804188822

Epoch: 5| Step: 6
Training loss: 2.46019615027112
Validation loss: 2.5408411482453337

Epoch: 5| Step: 7
Training loss: 2.9795501213230287
Validation loss: 2.5474229126749957

Epoch: 5| Step: 8
Training loss: 3.513717201538521
Validation loss: 2.55413264922238

Epoch: 5| Step: 9
Training loss: 2.8042598812789246
Validation loss: 2.545601599486882

Epoch: 5| Step: 10
Training loss: 1.7174034392464037
Validation loss: 2.563897792852681

Epoch: 185| Step: 0
Training loss: 2.8049351999886296
Validation loss: 2.519495216767619

Epoch: 5| Step: 1
Training loss: 2.2640539575893452
Validation loss: 2.5586111742428477

Epoch: 5| Step: 2
Training loss: 3.043689647287704
Validation loss: 2.542969028243599

Epoch: 5| Step: 3
Training loss: 2.674846758865009
Validation loss: 2.550927447165735

Epoch: 5| Step: 4
Training loss: 3.3133566846222955
Validation loss: 2.537213773298145

Epoch: 5| Step: 5
Training loss: 2.592592739554305
Validation loss: 2.5418372121393555

Epoch: 5| Step: 6
Training loss: 2.628927471647722
Validation loss: 2.550826526711062

Epoch: 5| Step: 7
Training loss: 2.717332492357797
Validation loss: 2.5545949370666134

Epoch: 5| Step: 8
Training loss: 2.7318906124439493
Validation loss: 2.5717780589798407

Epoch: 5| Step: 9
Training loss: 2.341022990352171
Validation loss: 2.5590120563673566

Epoch: 5| Step: 10
Training loss: 2.2238108982884395
Validation loss: 2.5609132429482946

Epoch: 186| Step: 0
Training loss: 2.4752214814317353
Validation loss: 2.545376595876881

Epoch: 5| Step: 1
Training loss: 2.7491817123897135
Validation loss: 2.5212805502222775

Epoch: 5| Step: 2
Training loss: 2.814741555337887
Validation loss: 2.5648107177292094

Epoch: 5| Step: 3
Training loss: 3.12529646420892
Validation loss: 2.5618235597903185

Epoch: 5| Step: 4
Training loss: 2.3012348757634835
Validation loss: 2.553333141352386

Epoch: 5| Step: 5
Training loss: 2.7899780480399703
Validation loss: 2.5514925462308864

Epoch: 5| Step: 6
Training loss: 2.9292161079094075
Validation loss: 2.5444931517726026

Epoch: 5| Step: 7
Training loss: 2.365438891892081
Validation loss: 2.543041666927794

Epoch: 5| Step: 8
Training loss: 2.577347886844494
Validation loss: 2.5670355359023773

Epoch: 5| Step: 9
Training loss: 2.6495789175351208
Validation loss: 2.5532972959801974

Epoch: 5| Step: 10
Training loss: 2.749012683149479
Validation loss: 2.550432032517668

Epoch: 187| Step: 0
Training loss: 2.3788272738070746
Validation loss: 2.5459478066942176

Epoch: 5| Step: 1
Training loss: 2.7172611588534914
Validation loss: 2.5486038423017123

Epoch: 5| Step: 2
Training loss: 2.7324293789545817
Validation loss: 2.5482827921090814

Epoch: 5| Step: 3
Training loss: 2.5214607361764707
Validation loss: 2.540193355318596

Epoch: 5| Step: 4
Training loss: 2.5305892647113564
Validation loss: 2.5383900448438306

Epoch: 5| Step: 5
Training loss: 2.8014060883652574
Validation loss: 2.5540322579272274

Epoch: 5| Step: 6
Training loss: 3.3697633029661858
Validation loss: 2.5428189688661305

Epoch: 5| Step: 7
Training loss: 2.579314079036644
Validation loss: 2.5555578066911213

Epoch: 5| Step: 8
Training loss: 2.6367583547372813
Validation loss: 2.556635641387422

Epoch: 5| Step: 9
Training loss: 2.6303540079295886
Validation loss: 2.542341638593481

Epoch: 5| Step: 10
Training loss: 2.4456419311530087
Validation loss: 2.5525260060873465

Epoch: 188| Step: 0
Training loss: 2.276352210140829
Validation loss: 2.5515652426801814

Epoch: 5| Step: 1
Training loss: 1.8248670843138104
Validation loss: 2.5429365945129545

Epoch: 5| Step: 2
Training loss: 2.9186594195472706
Validation loss: 2.568870948335541

Epoch: 5| Step: 3
Training loss: 3.4918943277824037
Validation loss: 2.5540763267157414

Epoch: 5| Step: 4
Training loss: 2.8326807579551314
Validation loss: 2.532840761128228

Epoch: 5| Step: 5
Training loss: 2.4537699635141013
Validation loss: 2.552224709113113

Epoch: 5| Step: 6
Training loss: 2.6833170785668283
Validation loss: 2.5273999723991194

Epoch: 5| Step: 7
Training loss: 2.5686874122141603
Validation loss: 2.543327069261983

Epoch: 5| Step: 8
Training loss: 2.8165976450060737
Validation loss: 2.534155578327887

Epoch: 5| Step: 9
Training loss: 2.270112427771563
Validation loss: 2.5225836110675255

Epoch: 5| Step: 10
Training loss: 3.059162579059771
Validation loss: 2.5328757877022485

Epoch: 189| Step: 0
Training loss: 2.44046788607435
Validation loss: 2.5454480308025316

Epoch: 5| Step: 1
Training loss: 3.0247274796233743
Validation loss: 2.549736118516748

Epoch: 5| Step: 2
Training loss: 2.097230097213455
Validation loss: 2.5329975626647037

Epoch: 5| Step: 3
Training loss: 1.8212509683097198
Validation loss: 2.528199284186702

Epoch: 5| Step: 4
Training loss: 2.441056908600078
Validation loss: 2.5424795910049847

Epoch: 5| Step: 5
Training loss: 2.805525460622123
Validation loss: 2.547749051098315

Epoch: 5| Step: 6
Training loss: 2.394723508002344
Validation loss: 2.551030996579833

Epoch: 5| Step: 7
Training loss: 3.341692567821653
Validation loss: 2.5560446348740395

Epoch: 5| Step: 8
Training loss: 3.1457264020990117
Validation loss: 2.5160867161212277

Epoch: 5| Step: 9
Training loss: 2.6906700068485536
Validation loss: 2.5346153601607604

Epoch: 5| Step: 10
Training loss: 2.9142617983330927
Validation loss: 2.5328288783394943

Epoch: 190| Step: 0
Training loss: 3.0047826790575485
Validation loss: 2.5387148605403533

Epoch: 5| Step: 1
Training loss: 2.75700016323085
Validation loss: 2.5052772577131255

Epoch: 5| Step: 2
Training loss: 2.2826636128108073
Validation loss: 2.5463487433854164

Epoch: 5| Step: 3
Training loss: 3.21801793930715
Validation loss: 2.518515734143534

Epoch: 5| Step: 4
Training loss: 2.03255983815902
Validation loss: 2.538585004688594

Epoch: 5| Step: 5
Training loss: 3.171584994583726
Validation loss: 2.54066317528258

Epoch: 5| Step: 6
Training loss: 2.5950867299192955
Validation loss: 2.5400509135768448

Epoch: 5| Step: 7
Training loss: 2.318187935459001
Validation loss: 2.52570854065027

Epoch: 5| Step: 8
Training loss: 2.909391120841397
Validation loss: 2.5413850890240974

Epoch: 5| Step: 9
Training loss: 2.4776856195258756
Validation loss: 2.5598026238177036

Epoch: 5| Step: 10
Training loss: 2.29233595582517
Validation loss: 2.5262764374549107

Epoch: 191| Step: 0
Training loss: 2.3315751286230983
Validation loss: 2.5593523391545205

Epoch: 5| Step: 1
Training loss: 3.0057708548734774
Validation loss: 2.540897391825147

Epoch: 5| Step: 2
Training loss: 2.4588682163911537
Validation loss: 2.542516781718318

Epoch: 5| Step: 3
Training loss: 2.866030093049041
Validation loss: 2.562950584880483

Epoch: 5| Step: 4
Training loss: 2.3937208288422243
Validation loss: 2.5484161253932514

Epoch: 5| Step: 5
Training loss: 3.1013121996372988
Validation loss: 2.533785282724712

Epoch: 5| Step: 6
Training loss: 3.0110681130348826
Validation loss: 2.5282294054243395

Epoch: 5| Step: 7
Training loss: 2.629626148616574
Validation loss: 2.5666953598110505

Epoch: 5| Step: 8
Training loss: 3.008783040200075
Validation loss: 2.568540328543403

Epoch: 5| Step: 9
Training loss: 1.9231908372005402
Validation loss: 2.5531861310607873

Epoch: 5| Step: 10
Training loss: 2.310699174106784
Validation loss: 2.539935127539622

Epoch: 192| Step: 0
Training loss: 2.7315091182606124
Validation loss: 2.5543564906293077

Epoch: 5| Step: 1
Training loss: 2.5712549400745757
Validation loss: 2.540397995810703

Epoch: 5| Step: 2
Training loss: 2.063591408230338
Validation loss: 2.555911490412984

Epoch: 5| Step: 3
Training loss: 3.587949234219518
Validation loss: 2.5400323769422193

Epoch: 5| Step: 4
Training loss: 2.183735469252265
Validation loss: 2.562790806894272

Epoch: 5| Step: 5
Training loss: 2.4318067133915857
Validation loss: 2.5322251269082936

Epoch: 5| Step: 6
Training loss: 2.4809058577709213
Validation loss: 2.557251217506772

Epoch: 5| Step: 7
Training loss: 2.5447215706260042
Validation loss: 2.5541367163030726

Epoch: 5| Step: 8
Training loss: 2.9285165303099006
Validation loss: 2.5582073371706007

Epoch: 5| Step: 9
Training loss: 2.176685741081998
Validation loss: 2.5647311003314135

Epoch: 5| Step: 10
Training loss: 3.4216888237737635
Validation loss: 2.545303076048391

Epoch: 193| Step: 0
Training loss: 2.446555312357221
Validation loss: 2.566139976423367

Epoch: 5| Step: 1
Training loss: 3.281758441587849
Validation loss: 2.550846409013723

Epoch: 5| Step: 2
Training loss: 3.076335406119564
Validation loss: 2.564165347052831

Epoch: 5| Step: 3
Training loss: 3.1138044082868155
Validation loss: 2.5453772787416957

Epoch: 5| Step: 4
Training loss: 3.024348631789405
Validation loss: 2.5437398800216884

Epoch: 5| Step: 5
Training loss: 2.502362660727502
Validation loss: 2.546826237641349

Epoch: 5| Step: 6
Training loss: 2.1226006594311904
Validation loss: 2.547614616234002

Epoch: 5| Step: 7
Training loss: 2.4174325869292432
Validation loss: 2.523551113169676

Epoch: 5| Step: 8
Training loss: 2.1854843662517047
Validation loss: 2.5411585967885157

Epoch: 5| Step: 9
Training loss: 2.4247587693560555
Validation loss: 2.547744478751013

Epoch: 5| Step: 10
Training loss: 2.579702645990374
Validation loss: 2.5414547165307644

Epoch: 194| Step: 0
Training loss: 2.8393053806442983
Validation loss: 2.5382751910177364

Epoch: 5| Step: 1
Training loss: 2.6874358590921976
Validation loss: 2.5572476836969447

Epoch: 5| Step: 2
Training loss: 2.6205639367662235
Validation loss: 2.532984192314689

Epoch: 5| Step: 3
Training loss: 2.685256909061696
Validation loss: 2.544883441081572

Epoch: 5| Step: 4
Training loss: 2.096807041573517
Validation loss: 2.5581898440365265

Epoch: 5| Step: 5
Training loss: 2.954612397722647
Validation loss: 2.5339712527276337

Epoch: 5| Step: 6
Training loss: 2.638657237364563
Validation loss: 2.554480047107808

Epoch: 5| Step: 7
Training loss: 2.887683423314213
Validation loss: 2.5453253633713246

Epoch: 5| Step: 8
Training loss: 2.759270733670303
Validation loss: 2.527298482690571

Epoch: 5| Step: 9
Training loss: 3.057995967984582
Validation loss: 2.5429469652463412

Epoch: 5| Step: 10
Training loss: 2.069447232215363
Validation loss: 2.5465019159667217

Epoch: 195| Step: 0
Training loss: 2.168886722355596
Validation loss: 2.558435229028256

Epoch: 5| Step: 1
Training loss: 2.066599845831439
Validation loss: 2.5263621999802823

Epoch: 5| Step: 2
Training loss: 2.8170885590217676
Validation loss: 2.551099497596856

Epoch: 5| Step: 3
Training loss: 2.8252572541710417
Validation loss: 2.5411530097867976

Epoch: 5| Step: 4
Training loss: 3.171866130346666
Validation loss: 2.5316860563227013

Epoch: 5| Step: 5
Training loss: 2.4053806864918994
Validation loss: 2.561089981884142

Epoch: 5| Step: 6
Training loss: 2.484974434949441
Validation loss: 2.5356107445615854

Epoch: 5| Step: 7
Training loss: 3.2239205024894875
Validation loss: 2.5504152479840494

Epoch: 5| Step: 8
Training loss: 2.699324919052118
Validation loss: 2.5545594295338767

Epoch: 5| Step: 9
Training loss: 3.0757099107487567
Validation loss: 2.5306641642488112

Epoch: 5| Step: 10
Training loss: 2.158508665801311
Validation loss: 2.542153736597737

Epoch: 196| Step: 0
Training loss: 2.3373204861012398
Validation loss: 2.5520115379964787

Epoch: 5| Step: 1
Training loss: 3.2060465073285074
Validation loss: 2.5606069267661717

Epoch: 5| Step: 2
Training loss: 2.2071498602669166
Validation loss: 2.556074545824919

Epoch: 5| Step: 3
Training loss: 2.8724948085542117
Validation loss: 2.5429823818842925

Epoch: 5| Step: 4
Training loss: 2.8342397773223853
Validation loss: 2.538529569293803

Epoch: 5| Step: 5
Training loss: 2.364145269161506
Validation loss: 2.5559631536524208

Epoch: 5| Step: 6
Training loss: 2.4359910647098424
Validation loss: 2.5592588731066033

Epoch: 5| Step: 7
Training loss: 2.72489795318754
Validation loss: 2.571115055730629

Epoch: 5| Step: 8
Training loss: 2.557442489081805
Validation loss: 2.5477903226013274

Epoch: 5| Step: 9
Training loss: 2.352712660449716
Validation loss: 2.5378190330685553

Epoch: 5| Step: 10
Training loss: 3.438009328389009
Validation loss: 2.547338845483236

Epoch: 197| Step: 0
Training loss: 3.188119267165192
Validation loss: 2.555349724690714

Epoch: 5| Step: 1
Training loss: 1.9983220810476627
Validation loss: 2.5413391089482817

Epoch: 5| Step: 2
Training loss: 2.6650489032545503
Validation loss: 2.555813177122175

Epoch: 5| Step: 3
Training loss: 2.522578609969438
Validation loss: 2.549317017163379

Epoch: 5| Step: 4
Training loss: 2.4308503241648656
Validation loss: 2.5362752529263743

Epoch: 5| Step: 5
Training loss: 2.276130051864455
Validation loss: 2.5391203317926645

Epoch: 5| Step: 6
Training loss: 3.267618255460011
Validation loss: 2.541258673465089

Epoch: 5| Step: 7
Training loss: 3.006982148726731
Validation loss: 2.542264303922437

Epoch: 5| Step: 8
Training loss: 2.8043814574495243
Validation loss: 2.5511113314599148

Epoch: 5| Step: 9
Training loss: 2.2978972152020423
Validation loss: 2.5360820978307848

Epoch: 5| Step: 10
Training loss: 2.7454915804090394
Validation loss: 2.5341549814631303

Epoch: 198| Step: 0
Training loss: 2.868260154374318
Validation loss: 2.5529492059341528

Epoch: 5| Step: 1
Training loss: 2.642497736010488
Validation loss: 2.5428159795857117

Epoch: 5| Step: 2
Training loss: 2.1333621927137205
Validation loss: 2.52185518880878

Epoch: 5| Step: 3
Training loss: 2.162105625773059
Validation loss: 2.5191489212336893

Epoch: 5| Step: 4
Training loss: 2.5614396669489277
Validation loss: 2.543435842845623

Epoch: 5| Step: 5
Training loss: 3.2046862263260816
Validation loss: 2.5259847229676256

Epoch: 5| Step: 6
Training loss: 2.439225393130707
Validation loss: 2.547690378726586

Epoch: 5| Step: 7
Training loss: 2.6907941457147992
Validation loss: 2.544371004561761

Epoch: 5| Step: 8
Training loss: 3.013852403911153
Validation loss: 2.553540187450887

Epoch: 5| Step: 9
Training loss: 2.769604766687779
Validation loss: 2.560832513290952

Epoch: 5| Step: 10
Training loss: 2.7314708873545728
Validation loss: 2.5621999549431176

Epoch: 199| Step: 0
Training loss: 2.5033323966412713
Validation loss: 2.5388165987017968

Epoch: 5| Step: 1
Training loss: 2.3840288903450815
Validation loss: 2.559535010707865

Epoch: 5| Step: 2
Training loss: 2.3638749819131184
Validation loss: 2.526913827970533

Epoch: 5| Step: 3
Training loss: 2.3624242820917973
Validation loss: 2.5367632303613994

Epoch: 5| Step: 4
Training loss: 2.682789066947749
Validation loss: 2.52069694006322

Epoch: 5| Step: 5
Training loss: 2.4617209504413364
Validation loss: 2.527930088526175

Epoch: 5| Step: 6
Training loss: 2.841342787496709
Validation loss: 2.551833565506274

Epoch: 5| Step: 7
Training loss: 2.518630228910244
Validation loss: 2.5591097188338825

Epoch: 5| Step: 8
Training loss: 3.024309688019779
Validation loss: 2.5532790533128917

Epoch: 5| Step: 9
Training loss: 3.047308631752905
Validation loss: 2.546655679310322

Epoch: 5| Step: 10
Training loss: 3.1827307531901354
Validation loss: 2.552546618368751

Epoch: 200| Step: 0
Training loss: 2.613330424349327
Validation loss: 2.557927654163188

Epoch: 5| Step: 1
Training loss: 2.5391341448726097
Validation loss: 2.5420656850906713

Epoch: 5| Step: 2
Training loss: 2.4963443731769437
Validation loss: 2.5381651922968813

Epoch: 5| Step: 3
Training loss: 2.388298348567452
Validation loss: 2.5310340494506125

Epoch: 5| Step: 4
Training loss: 3.0855732763203796
Validation loss: 2.5459995039588734

Epoch: 5| Step: 5
Training loss: 2.584139933845083
Validation loss: 2.533556218885725

Epoch: 5| Step: 6
Training loss: 2.7955728408583673
Validation loss: 2.5130845652796046

Epoch: 5| Step: 7
Training loss: 2.5438463422446844
Validation loss: 2.554468856094835

Epoch: 5| Step: 8
Training loss: 3.063960291642535
Validation loss: 2.5511723760770355

Epoch: 5| Step: 9
Training loss: 2.5016719949027224
Validation loss: 2.5540611520579373

Epoch: 5| Step: 10
Training loss: 2.617267664350643
Validation loss: 2.570631499956923

Epoch: 201| Step: 0
Training loss: 2.173228000221902
Validation loss: 2.5595462441734482

Epoch: 5| Step: 1
Training loss: 2.0034983556296577
Validation loss: 2.5529367981586297

Epoch: 5| Step: 2
Training loss: 2.626514361301783
Validation loss: 2.5458821743962883

Epoch: 5| Step: 3
Training loss: 2.1754790118429637
Validation loss: 2.542427552939324

Epoch: 5| Step: 4
Training loss: 3.3262468509881367
Validation loss: 2.5665414515815583

Epoch: 5| Step: 5
Training loss: 2.881347780368261
Validation loss: 2.54333021518748

Epoch: 5| Step: 6
Training loss: 2.3745386779873803
Validation loss: 2.5478211228460843

Epoch: 5| Step: 7
Training loss: 2.676205611165944
Validation loss: 2.549972703776763

Epoch: 5| Step: 8
Training loss: 3.281005704959094
Validation loss: 2.5490152996472086

Epoch: 5| Step: 9
Training loss: 3.0017037322195055
Validation loss: 2.539940192368146

Epoch: 5| Step: 10
Training loss: 2.4050600156215345
Validation loss: 2.54095648438154

Epoch: 202| Step: 0
Training loss: 2.18579525597241
Validation loss: 2.54042386925559

Epoch: 5| Step: 1
Training loss: 2.656160061379487
Validation loss: 2.5514624464229794

Epoch: 5| Step: 2
Training loss: 2.548862079964203
Validation loss: 2.5535650302081137

Epoch: 5| Step: 3
Training loss: 2.6252862683377325
Validation loss: 2.569966884166817

Epoch: 5| Step: 4
Training loss: 2.7053780399794185
Validation loss: 2.546023661076975

Epoch: 5| Step: 5
Training loss: 2.2272020994039483
Validation loss: 2.5670687237385765

Epoch: 5| Step: 6
Training loss: 2.04611494789635
Validation loss: 2.5370694909272475

Epoch: 5| Step: 7
Training loss: 2.919025520863954
Validation loss: 2.5312598484120667

Epoch: 5| Step: 8
Training loss: 3.5755283312106534
Validation loss: 2.5762390656871177

Epoch: 5| Step: 9
Training loss: 2.4833592671655254
Validation loss: 2.55544365725131

Epoch: 5| Step: 10
Training loss: 3.2805818876637542
Validation loss: 2.5624841438961403

Epoch: 203| Step: 0
Training loss: 2.5766200441466323
Validation loss: 2.5645106031392237

Epoch: 5| Step: 1
Training loss: 2.386744222801619
Validation loss: 2.5555667358279903

Epoch: 5| Step: 2
Training loss: 2.41234243402174
Validation loss: 2.539598712701114

Epoch: 5| Step: 3
Training loss: 2.83036083549544
Validation loss: 2.5573925348200577

Epoch: 5| Step: 4
Training loss: 1.9773518791619433
Validation loss: 2.5609668023693306

Epoch: 5| Step: 5
Training loss: 2.9138363502436055
Validation loss: 2.575249756037469

Epoch: 5| Step: 6
Training loss: 2.843183859339352
Validation loss: 2.552982136054724

Epoch: 5| Step: 7
Training loss: 2.8855804139828654
Validation loss: 2.5593726270104904

Epoch: 5| Step: 8
Training loss: 2.238630816739282
Validation loss: 2.5459447183785113

Epoch: 5| Step: 9
Training loss: 3.0082763314240357
Validation loss: 2.5434819568688223

Epoch: 5| Step: 10
Training loss: 3.1531458026967236
Validation loss: 2.5441105072965597

Epoch: 204| Step: 0
Training loss: 2.5348331850983086
Validation loss: 2.5438354914408707

Epoch: 5| Step: 1
Training loss: 2.864947782509969
Validation loss: 2.5419128876324573

Epoch: 5| Step: 2
Training loss: 2.715385811020535
Validation loss: 2.566380358800269

Epoch: 5| Step: 3
Training loss: 3.050793441376889
Validation loss: 2.549961211983039

Epoch: 5| Step: 4
Training loss: 3.1532245903809026
Validation loss: 2.533510469608071

Epoch: 5| Step: 5
Training loss: 2.5755920914582013
Validation loss: 2.5423019223188357

Epoch: 5| Step: 6
Training loss: 2.5562302716899934
Validation loss: 2.5419024683038427

Epoch: 5| Step: 7
Training loss: 2.44211249550555
Validation loss: 2.561164944370905

Epoch: 5| Step: 8
Training loss: 2.502307780349991
Validation loss: 2.544843004906386

Epoch: 5| Step: 9
Training loss: 2.381949947141983
Validation loss: 2.552883827445478

Epoch: 5| Step: 10
Training loss: 2.4483495992280764
Validation loss: 2.526787147004542

Epoch: 205| Step: 0
Training loss: 2.587752797037271
Validation loss: 2.570768555552541

Epoch: 5| Step: 1
Training loss: 2.970076094143866
Validation loss: 2.5539728395419585

Epoch: 5| Step: 2
Training loss: 2.753373590995562
Validation loss: 2.5522235288571458

Epoch: 5| Step: 3
Training loss: 2.5814212880788427
Validation loss: 2.551550367571519

Epoch: 5| Step: 4
Training loss: 2.6245463751345555
Validation loss: 2.5362167993012985

Epoch: 5| Step: 5
Training loss: 2.722234750792376
Validation loss: 2.515756339556168

Epoch: 5| Step: 6
Training loss: 2.4030389539694177
Validation loss: 2.549559367773841

Epoch: 5| Step: 7
Training loss: 2.8673085699063843
Validation loss: 2.5546561603593854

Epoch: 5| Step: 8
Training loss: 2.670544477088458
Validation loss: 2.5318043045037615

Epoch: 5| Step: 9
Training loss: 2.4444957014932838
Validation loss: 2.545326795603137

Epoch: 5| Step: 10
Training loss: 2.746487715394516
Validation loss: 2.552422131636656

Epoch: 206| Step: 0
Training loss: 2.509929773328532
Validation loss: 2.5752549062103927

Epoch: 5| Step: 1
Training loss: 1.9546057009333662
Validation loss: 2.5510710683655553

Epoch: 5| Step: 2
Training loss: 2.4889064703993995
Validation loss: 2.553643186184928

Epoch: 5| Step: 3
Training loss: 3.629945735473255
Validation loss: 2.5382174460207345

Epoch: 5| Step: 4
Training loss: 2.3683141664735667
Validation loss: 2.5685575575569946

Epoch: 5| Step: 5
Training loss: 2.730014397579696
Validation loss: 2.5713979034707797

Epoch: 5| Step: 6
Training loss: 2.884567760172207
Validation loss: 2.5570977624545916

Epoch: 5| Step: 7
Training loss: 2.60663081252602
Validation loss: 2.562160023191813

Epoch: 5| Step: 8
Training loss: 2.585195383033366
Validation loss: 2.5834219573661197

Epoch: 5| Step: 9
Training loss: 2.564270617345352
Validation loss: 2.544162756807281

Epoch: 5| Step: 10
Training loss: 2.6258849514224134
Validation loss: 2.552366650751691

Epoch: 207| Step: 0
Training loss: 2.8922164247819215
Validation loss: 2.5521707351983682

Epoch: 5| Step: 1
Training loss: 3.3990507427579337
Validation loss: 2.552130362249181

Epoch: 5| Step: 2
Training loss: 1.9666666179053522
Validation loss: 2.5382142472975433

Epoch: 5| Step: 3
Training loss: 2.7850002764114437
Validation loss: 2.540863621006136

Epoch: 5| Step: 4
Training loss: 2.414539573959708
Validation loss: 2.544608952053812

Epoch: 5| Step: 5
Training loss: 2.7754652750175723
Validation loss: 2.5298669455562006

Epoch: 5| Step: 6
Training loss: 3.1576640672259924
Validation loss: 2.5243173498641243

Epoch: 5| Step: 7
Training loss: 2.4905134456067093
Validation loss: 2.533844052465

Epoch: 5| Step: 8
Training loss: 2.485221958341037
Validation loss: 2.5504270739650043

Epoch: 5| Step: 9
Training loss: 1.9931343371704002
Validation loss: 2.535469088837063

Epoch: 5| Step: 10
Training loss: 2.5059783027239373
Validation loss: 2.5324351277107686

Epoch: 208| Step: 0
Training loss: 2.429776499795555
Validation loss: 2.546715156677349

Epoch: 5| Step: 1
Training loss: 2.4528304002108436
Validation loss: 2.5418750970656983

Epoch: 5| Step: 2
Training loss: 2.213124194701209
Validation loss: 2.533403573036637

Epoch: 5| Step: 3
Training loss: 2.2713380538507706
Validation loss: 2.5476783800460647

Epoch: 5| Step: 4
Training loss: 2.671779519321481
Validation loss: 2.5560514194676367

Epoch: 5| Step: 5
Training loss: 2.934303817454396
Validation loss: 2.5330817561427703

Epoch: 5| Step: 6
Training loss: 2.3946290237353924
Validation loss: 2.5305996485626467

Epoch: 5| Step: 7
Training loss: 2.649067851532902
Validation loss: 2.547398295829372

Epoch: 5| Step: 8
Training loss: 3.0691891233679294
Validation loss: 2.528994709234853

Epoch: 5| Step: 9
Training loss: 3.1787083873357664
Validation loss: 2.536437169175572

Epoch: 5| Step: 10
Training loss: 2.869226380398148
Validation loss: 2.546932720831511

Epoch: 209| Step: 0
Training loss: 3.0188276450713403
Validation loss: 2.5460513854449833

Epoch: 5| Step: 1
Training loss: 2.323850766070207
Validation loss: 2.5671367748377674

Epoch: 5| Step: 2
Training loss: 2.4245091049580356
Validation loss: 2.5596686637669173

Epoch: 5| Step: 3
Training loss: 2.670142431853454
Validation loss: 2.5761319458652148

Epoch: 5| Step: 4
Training loss: 2.295077808033527
Validation loss: 2.5652370996647087

Epoch: 5| Step: 5
Training loss: 2.554002302480928
Validation loss: 2.543902364187257

Epoch: 5| Step: 6
Training loss: 2.026716366752439
Validation loss: 2.5382069256706203

Epoch: 5| Step: 7
Training loss: 2.8214391428799415
Validation loss: 2.554714640641006

Epoch: 5| Step: 8
Training loss: 2.9401072841973526
Validation loss: 2.558357823690135

Epoch: 5| Step: 9
Training loss: 3.242545160995256
Validation loss: 2.5421488173629405

Epoch: 5| Step: 10
Training loss: 2.7869506020823667
Validation loss: 2.554504691048893

Epoch: 210| Step: 0
Training loss: 2.07573028490402
Validation loss: 2.5459615243290403

Epoch: 5| Step: 1
Training loss: 3.737037762792818
Validation loss: 2.566184097029707

Epoch: 5| Step: 2
Training loss: 2.3022300938103886
Validation loss: 2.5671706134673484

Epoch: 5| Step: 3
Training loss: 2.581550772741538
Validation loss: 2.5623549433564197

Epoch: 5| Step: 4
Training loss: 2.7165607100186517
Validation loss: 2.570771858367301

Epoch: 5| Step: 5
Training loss: 2.667354753252688
Validation loss: 2.5452052403691185

Epoch: 5| Step: 6
Training loss: 2.498011847542002
Validation loss: 2.587243898936834

Epoch: 5| Step: 7
Training loss: 2.147778219157305
Validation loss: 2.551129093205525

Epoch: 5| Step: 8
Training loss: 2.6700697483282156
Validation loss: 2.565060838369111

Epoch: 5| Step: 9
Training loss: 2.6887046420688745
Validation loss: 2.558133461536509

Epoch: 5| Step: 10
Training loss: 2.792009436976708
Validation loss: 2.5536948200218292

Epoch: 211| Step: 0
Training loss: 3.255416757650426
Validation loss: 2.5589734794275585

Epoch: 5| Step: 1
Training loss: 2.4491752365116395
Validation loss: 2.56794357312171

Epoch: 5| Step: 2
Training loss: 2.1309686872239477
Validation loss: 2.5470114517323905

Epoch: 5| Step: 3
Training loss: 2.681241755261672
Validation loss: 2.5532746424816413

Epoch: 5| Step: 4
Training loss: 2.1962312018209302
Validation loss: 2.5521055527390133

Epoch: 5| Step: 5
Training loss: 2.8854186313957566
Validation loss: 2.5556507169415728

Epoch: 5| Step: 6
Training loss: 2.7416353457747915
Validation loss: 2.5544121425670197

Epoch: 5| Step: 7
Training loss: 3.1238579761394933
Validation loss: 2.564020837557304

Epoch: 5| Step: 8
Training loss: 2.1168609029403562
Validation loss: 2.5207409178606914

Epoch: 5| Step: 9
Training loss: 2.509457532919732
Validation loss: 2.5347698213006886

Epoch: 5| Step: 10
Training loss: 3.0274736930277526
Validation loss: 2.545640284401085

Epoch: 212| Step: 0
Training loss: 3.315586739192607
Validation loss: 2.5272424741013606

Epoch: 5| Step: 1
Training loss: 2.4278208931247414
Validation loss: 2.555326014401096

Epoch: 5| Step: 2
Training loss: 2.4623504941838146
Validation loss: 2.5629659939818143

Epoch: 5| Step: 3
Training loss: 2.8067815502361153
Validation loss: 2.5632373760340736

Epoch: 5| Step: 4
Training loss: 2.308182887971343
Validation loss: 2.527688683478987

Epoch: 5| Step: 5
Training loss: 2.01849692916731
Validation loss: 2.5416782633736927

Epoch: 5| Step: 6
Training loss: 3.081618596869948
Validation loss: 2.5516788050723846

Epoch: 5| Step: 7
Training loss: 2.066532123964847
Validation loss: 2.5534327107522086

Epoch: 5| Step: 8
Training loss: 3.1285951914572263
Validation loss: 2.5628117917647204

Epoch: 5| Step: 9
Training loss: 2.634514142725181
Validation loss: 2.5536115968009385

Epoch: 5| Step: 10
Training loss: 2.4510039860954853
Validation loss: 2.5477027406089645

Epoch: 213| Step: 0
Training loss: 2.647877591792979
Validation loss: 2.5213274080450643

Epoch: 5| Step: 1
Training loss: 2.760656171281153
Validation loss: 2.5528646368516257

Epoch: 5| Step: 2
Training loss: 2.70740562591498
Validation loss: 2.5513052679519475

Epoch: 5| Step: 3
Training loss: 2.654297054647253
Validation loss: 2.5485652144426214

Epoch: 5| Step: 4
Training loss: 2.933992930148291
Validation loss: 2.5272521555385836

Epoch: 5| Step: 5
Training loss: 2.356769057355742
Validation loss: 2.521570434713178

Epoch: 5| Step: 6
Training loss: 2.7569625452463282
Validation loss: 2.543168688404323

Epoch: 5| Step: 7
Training loss: 2.6243658662234166
Validation loss: 2.55645483196042

Epoch: 5| Step: 8
Training loss: 2.9208365650313306
Validation loss: 2.5425553230005784

Epoch: 5| Step: 9
Training loss: 2.1271222680464312
Validation loss: 2.5320919200972183

Epoch: 5| Step: 10
Training loss: 2.7597092975718462
Validation loss: 2.5657652943275755

Epoch: 214| Step: 0
Training loss: 2.2999400753010035
Validation loss: 2.5251986596529847

Epoch: 5| Step: 1
Training loss: 3.0500564007156306
Validation loss: 2.533686837370894

Epoch: 5| Step: 2
Training loss: 3.010282379287989
Validation loss: 2.54223687002436

Epoch: 5| Step: 3
Training loss: 2.380167108647603
Validation loss: 2.556365805877349

Epoch: 5| Step: 4
Training loss: 2.1797641754336983
Validation loss: 2.5524830073061104

Epoch: 5| Step: 5
Training loss: 2.7446113155597343
Validation loss: 2.537582266364236

Epoch: 5| Step: 6
Training loss: 2.8942811680302
Validation loss: 2.5540902616657184

Epoch: 5| Step: 7
Training loss: 2.535967727828837
Validation loss: 2.5571026198469307

Epoch: 5| Step: 8
Training loss: 1.868335642216277
Validation loss: 2.541810244138241

Epoch: 5| Step: 9
Training loss: 2.345980688947336
Validation loss: 2.5607122452324633

Epoch: 5| Step: 10
Training loss: 3.4756969274477494
Validation loss: 2.5608080749055184

Epoch: 215| Step: 0
Training loss: 2.668985689641522
Validation loss: 2.5572631000944686

Epoch: 5| Step: 1
Training loss: 2.721461555272492
Validation loss: 2.545367529267979

Epoch: 5| Step: 2
Training loss: 2.2431721402771405
Validation loss: 2.561387829921085

Epoch: 5| Step: 3
Training loss: 2.77485315432658
Validation loss: 2.5482839852565182

Epoch: 5| Step: 4
Training loss: 2.149983241880888
Validation loss: 2.592969355631489

Epoch: 5| Step: 5
Training loss: 2.848531203996474
Validation loss: 2.549143947342694

Epoch: 5| Step: 6
Training loss: 2.567727037920088
Validation loss: 2.5332361347040395

Epoch: 5| Step: 7
Training loss: 3.16071132693641
Validation loss: 2.5711456463596356

Epoch: 5| Step: 8
Training loss: 2.301981122493812
Validation loss: 2.53448055132454

Epoch: 5| Step: 9
Training loss: 2.6967800402140014
Validation loss: 2.5599262218761973

Epoch: 5| Step: 10
Training loss: 2.7682939140855662
Validation loss: 2.5498896405835385

Epoch: 216| Step: 0
Training loss: 2.190747493524368
Validation loss: 2.5416417518240495

Epoch: 5| Step: 1
Training loss: 2.2032352717513417
Validation loss: 2.544060731112262

Epoch: 5| Step: 2
Training loss: 3.0354544199784326
Validation loss: 2.5644454794117

Epoch: 5| Step: 3
Training loss: 2.4595226277463853
Validation loss: 2.5601217707454804

Epoch: 5| Step: 4
Training loss: 2.9900471574515644
Validation loss: 2.531442717671695

Epoch: 5| Step: 5
Training loss: 2.5218378908057635
Validation loss: 2.527333531807027

Epoch: 5| Step: 6
Training loss: 2.1437317516562286
Validation loss: 2.560272098678784

Epoch: 5| Step: 7
Training loss: 2.2960058111722024
Validation loss: 2.554507109666885

Epoch: 5| Step: 8
Training loss: 2.6442788030356392
Validation loss: 2.53823960416352

Epoch: 5| Step: 9
Training loss: 2.9698604715369963
Validation loss: 2.559363664073116

Epoch: 5| Step: 10
Training loss: 3.333282200103211
Validation loss: 2.5474664678372054

Epoch: 217| Step: 0
Training loss: 2.5794427451759554
Validation loss: 2.537555692109968

Epoch: 5| Step: 1
Training loss: 3.046759500515177
Validation loss: 2.5508244784723213

Epoch: 5| Step: 2
Training loss: 2.6116893806597723
Validation loss: 2.5458935919608785

Epoch: 5| Step: 3
Training loss: 2.7654546480462106
Validation loss: 2.54373524906884

Epoch: 5| Step: 4
Training loss: 2.3151408401061886
Validation loss: 2.562790724867079

Epoch: 5| Step: 5
Training loss: 2.5863217532205156
Validation loss: 2.561719675053318

Epoch: 5| Step: 6
Training loss: 2.648929516486422
Validation loss: 2.5390835800116203

Epoch: 5| Step: 7
Training loss: 2.929046479350958
Validation loss: 2.572663252404917

Epoch: 5| Step: 8
Training loss: 2.6538060333043076
Validation loss: 2.550479915778619

Epoch: 5| Step: 9
Training loss: 2.567884324382986
Validation loss: 2.5403237051960503

Epoch: 5| Step: 10
Training loss: 2.390732706672969
Validation loss: 2.5576421896222685

Epoch: 218| Step: 0
Training loss: 2.5080234522050033
Validation loss: 2.544452381944107

Epoch: 5| Step: 1
Training loss: 2.390359003564961
Validation loss: 2.53827869771164

Epoch: 5| Step: 2
Training loss: 2.900288856853061
Validation loss: 2.532188921988285

Epoch: 5| Step: 3
Training loss: 3.271187311606033
Validation loss: 2.573266335943583

Epoch: 5| Step: 4
Training loss: 2.442715078858346
Validation loss: 2.5351908805430154

Epoch: 5| Step: 5
Training loss: 2.579829167173539
Validation loss: 2.5390179767601735

Epoch: 5| Step: 6
Training loss: 2.6195080845710432
Validation loss: 2.5593250814145843

Epoch: 5| Step: 7
Training loss: 2.107308173448896
Validation loss: 2.548489232506867

Epoch: 5| Step: 8
Training loss: 2.7224266360427887
Validation loss: 2.5568634988682724

Epoch: 5| Step: 9
Training loss: 2.8227328326249124
Validation loss: 2.5505560324013503

Epoch: 5| Step: 10
Training loss: 2.5637806739255486
Validation loss: 2.548352261332829

Epoch: 219| Step: 0
Training loss: 2.900191524363645
Validation loss: 2.531264356346847

Epoch: 5| Step: 1
Training loss: 2.749787235699113
Validation loss: 2.5235714419856285

Epoch: 5| Step: 2
Training loss: 3.262864986187878
Validation loss: 2.551940884527069

Epoch: 5| Step: 3
Training loss: 2.5413886580047444
Validation loss: 2.542253011740287

Epoch: 5| Step: 4
Training loss: 2.4120475977349645
Validation loss: 2.546440156340874

Epoch: 5| Step: 5
Training loss: 2.2421357152189083
Validation loss: 2.550683596302903

Epoch: 5| Step: 6
Training loss: 2.12034793337828
Validation loss: 2.5425878987208836

Epoch: 5| Step: 7
Training loss: 2.9122465882957163
Validation loss: 2.533253956000749

Epoch: 5| Step: 8
Training loss: 2.6120496735924554
Validation loss: 2.550934750372202

Epoch: 5| Step: 9
Training loss: 2.20117035859808
Validation loss: 2.5151986818388528

Epoch: 5| Step: 10
Training loss: 2.9239372278930156
Validation loss: 2.536125913464173

Epoch: 220| Step: 0
Training loss: 3.294803782338385
Validation loss: 2.5409550315256597

Epoch: 5| Step: 1
Training loss: 2.898430096804477
Validation loss: 2.5733426084286988

Epoch: 5| Step: 2
Training loss: 2.4405302139222
Validation loss: 2.5817741117196547

Epoch: 5| Step: 3
Training loss: 2.600633610035258
Validation loss: 2.545640784411812

Epoch: 5| Step: 4
Training loss: 2.559212413276696
Validation loss: 2.5623460828974967

Epoch: 5| Step: 5
Training loss: 2.7800287715877534
Validation loss: 2.5566508438822506

Epoch: 5| Step: 6
Training loss: 2.764600833549007
Validation loss: 2.5338092608543348

Epoch: 5| Step: 7
Training loss: 2.461148788827748
Validation loss: 2.561684662078666

Epoch: 5| Step: 8
Training loss: 2.525403275719957
Validation loss: 2.5573928084870237

Epoch: 5| Step: 9
Training loss: 2.4785738217470654
Validation loss: 2.537674864918725

Epoch: 5| Step: 10
Training loss: 2.045889347757254
Validation loss: 2.565607564196745

Epoch: 221| Step: 0
Training loss: 2.380928470400686
Validation loss: 2.5593428492628636

Epoch: 5| Step: 1
Training loss: 2.4731596182751816
Validation loss: 2.536424734194554

Epoch: 5| Step: 2
Training loss: 2.6856539396271923
Validation loss: 2.5627052671113604

Epoch: 5| Step: 3
Training loss: 2.7427338927966667
Validation loss: 2.560546784891257

Epoch: 5| Step: 4
Training loss: 2.3879267605743664
Validation loss: 2.561004230132632

Epoch: 5| Step: 5
Training loss: 3.059217601308106
Validation loss: 2.5483921458756487

Epoch: 5| Step: 6
Training loss: 2.775686807955713
Validation loss: 2.5474596910732243

Epoch: 5| Step: 7
Training loss: 2.5875233745901296
Validation loss: 2.565783698009168

Epoch: 5| Step: 8
Training loss: 2.5111269335215463
Validation loss: 2.550825121687805

Epoch: 5| Step: 9
Training loss: 2.7988994240580407
Validation loss: 2.5649348455704417

Epoch: 5| Step: 10
Training loss: 2.401007154855232
Validation loss: 2.5684838159288237

Epoch: 222| Step: 0
Training loss: 2.849812009534148
Validation loss: 2.5757942361088872

Epoch: 5| Step: 1
Training loss: 2.4909869803291693
Validation loss: 2.548276230794222

Epoch: 5| Step: 2
Training loss: 3.226857465141867
Validation loss: 2.53514018343547

Epoch: 5| Step: 3
Training loss: 2.3106459324708624
Validation loss: 2.551518327267493

Epoch: 5| Step: 4
Training loss: 1.886121825255031
Validation loss: 2.5539498296656964

Epoch: 5| Step: 5
Training loss: 2.731116396781015
Validation loss: 2.5671484918320573

Epoch: 5| Step: 6
Training loss: 2.5298987655590195
Validation loss: 2.5696911118525714

Epoch: 5| Step: 7
Training loss: 2.4602747433455763
Validation loss: 2.5406240493047525

Epoch: 5| Step: 8
Training loss: 2.2153724429619404
Validation loss: 2.5843806963622953

Epoch: 5| Step: 9
Training loss: 2.576070440810116
Validation loss: 2.5766047763999604

Epoch: 5| Step: 10
Training loss: 3.537976230875739
Validation loss: 2.524503479114985

Epoch: 223| Step: 0
Training loss: 2.6011722489651894
Validation loss: 2.5537226147024805

Epoch: 5| Step: 1
Training loss: 2.576594042657232
Validation loss: 2.556123868918017

Epoch: 5| Step: 2
Training loss: 2.363857230624325
Validation loss: 2.526223932677821

Epoch: 5| Step: 3
Training loss: 2.2166252170597702
Validation loss: 2.5332072307432494

Epoch: 5| Step: 4
Training loss: 2.4975065194198547
Validation loss: 2.520640371353309

Epoch: 5| Step: 5
Training loss: 2.285618609742058
Validation loss: 2.5497651638867076

Epoch: 5| Step: 6
Training loss: 2.697960125390255
Validation loss: 2.56142647558978

Epoch: 5| Step: 7
Training loss: 2.9736996798208457
Validation loss: 2.527788636246875

Epoch: 5| Step: 8
Training loss: 2.8671670440027266
Validation loss: 2.548024346829762

Epoch: 5| Step: 9
Training loss: 2.6744360890892125
Validation loss: 2.507650297603991

Epoch: 5| Step: 10
Training loss: 3.3693270159039326
Validation loss: 2.5491358002602205

Epoch: 224| Step: 0
Training loss: 2.5762673823747955
Validation loss: 2.53961140974303

Epoch: 5| Step: 1
Training loss: 2.299092785582772
Validation loss: 2.548631915810528

Epoch: 5| Step: 2
Training loss: 2.4258113251079467
Validation loss: 2.5277720755960105

Epoch: 5| Step: 3
Training loss: 2.464227904753321
Validation loss: 2.538815002242596

Epoch: 5| Step: 4
Training loss: 1.8676596966219152
Validation loss: 2.5298767760453216

Epoch: 5| Step: 5
Training loss: 2.260449305238663
Validation loss: 2.552421904643322

Epoch: 5| Step: 6
Training loss: 3.4140025816663515
Validation loss: 2.5393736935876787

Epoch: 5| Step: 7
Training loss: 2.887766151217271
Validation loss: 2.5538606028269872

Epoch: 5| Step: 8
Training loss: 2.7455903157510226
Validation loss: 2.5606903801632335

Epoch: 5| Step: 9
Training loss: 2.7991529171117544
Validation loss: 2.5721200506302573

Epoch: 5| Step: 10
Training loss: 2.9535278368494233
Validation loss: 2.5525346957465196

Epoch: 225| Step: 0
Training loss: 2.4995652774498427
Validation loss: 2.544560862601398

Epoch: 5| Step: 1
Training loss: 2.705583898311868
Validation loss: 2.54439830461755

Epoch: 5| Step: 2
Training loss: 2.517224484532475
Validation loss: 2.5667479645897373

Epoch: 5| Step: 3
Training loss: 2.53460442836883
Validation loss: 2.55034037764739

Epoch: 5| Step: 4
Training loss: 2.1941083001432653
Validation loss: 2.543727334604771

Epoch: 5| Step: 5
Training loss: 2.776955278272085
Validation loss: 2.5541966969614767

Epoch: 5| Step: 6
Training loss: 2.77058999467796
Validation loss: 2.531075833556284

Epoch: 5| Step: 7
Training loss: 2.8911858091967697
Validation loss: 2.5461549237348886

Epoch: 5| Step: 8
Training loss: 2.278308592045507
Validation loss: 2.5662859030036422

Epoch: 5| Step: 9
Training loss: 2.915121831948878
Validation loss: 2.575786631150875

Epoch: 5| Step: 10
Training loss: 2.628143970906374
Validation loss: 2.567622309716036

Epoch: 226| Step: 0
Training loss: 2.1290137587533193
Validation loss: 2.546911436024513

Epoch: 5| Step: 1
Training loss: 2.6682730147981943
Validation loss: 2.550182319765108

Epoch: 5| Step: 2
Training loss: 2.2702113591747195
Validation loss: 2.5310005683910766

Epoch: 5| Step: 3
Training loss: 2.9905298486957026
Validation loss: 2.5456409908613287

Epoch: 5| Step: 4
Training loss: 2.8158564566635302
Validation loss: 2.5540698635952914

Epoch: 5| Step: 5
Training loss: 2.757918574640913
Validation loss: 2.5479975987556673

Epoch: 5| Step: 6
Training loss: 2.594447582151307
Validation loss: 2.5616409468526715

Epoch: 5| Step: 7
Training loss: 2.447498745786445
Validation loss: 2.55002874293446

Epoch: 5| Step: 8
Training loss: 2.898325956516921
Validation loss: 2.5308847289150167

Epoch: 5| Step: 9
Training loss: 2.5363994071951335
Validation loss: 2.557521719914855

Epoch: 5| Step: 10
Training loss: 2.7263361883378985
Validation loss: 2.554447184469996

Epoch: 227| Step: 0
Training loss: 2.1054577659079787
Validation loss: 2.513003806408729

Epoch: 5| Step: 1
Training loss: 2.1279829070258045
Validation loss: 2.5493533866094116

Epoch: 5| Step: 2
Training loss: 2.292793644160361
Validation loss: 2.5543556425579035

Epoch: 5| Step: 3
Training loss: 3.1351930320971855
Validation loss: 2.559980073335027

Epoch: 5| Step: 4
Training loss: 3.004829969118144
Validation loss: 2.5496361785203083

Epoch: 5| Step: 5
Training loss: 2.8319283723232194
Validation loss: 2.52978197979978

Epoch: 5| Step: 6
Training loss: 2.5957238832997085
Validation loss: 2.585398016311677

Epoch: 5| Step: 7
Training loss: 2.4281623199226385
Validation loss: 2.566914295587967

Epoch: 5| Step: 8
Training loss: 3.1908176584390935
Validation loss: 2.5697199386560454

Epoch: 5| Step: 9
Training loss: 2.312800001325314
Validation loss: 2.571404898295739

Epoch: 5| Step: 10
Training loss: 2.6710703569555485
Validation loss: 2.560973709564111

Epoch: 228| Step: 0
Training loss: 3.1159671698861966
Validation loss: 2.557676949217659

Epoch: 5| Step: 1
Training loss: 2.7181851907478953
Validation loss: 2.5415611947895638

Epoch: 5| Step: 2
Training loss: 2.700224626875234
Validation loss: 2.585911718104374

Epoch: 5| Step: 3
Training loss: 2.220614120323613
Validation loss: 2.554598074133704

Epoch: 5| Step: 4
Training loss: 2.853693085151794
Validation loss: 2.5406239423444514

Epoch: 5| Step: 5
Training loss: 2.489227163037086
Validation loss: 2.5509546298214145

Epoch: 5| Step: 6
Training loss: 2.7599034150127384
Validation loss: 2.5410135557372087

Epoch: 5| Step: 7
Training loss: 2.7888452781908244
Validation loss: 2.5269154608628877

Epoch: 5| Step: 8
Training loss: 2.1766805930322555
Validation loss: 2.543978984969631

Epoch: 5| Step: 9
Training loss: 2.784276622742554
Validation loss: 2.525066901544821

Epoch: 5| Step: 10
Training loss: 2.1167591970849218
Validation loss: 2.5551047973865075

Epoch: 229| Step: 0
Training loss: 2.9710507763170426
Validation loss: 2.55101094788904

Epoch: 5| Step: 1
Training loss: 2.9129350132710696
Validation loss: 2.5255477738748424

Epoch: 5| Step: 2
Training loss: 2.6616109268030685
Validation loss: 2.531785887730639

Epoch: 5| Step: 3
Training loss: 2.4107306242696938
Validation loss: 2.54223359770174

Epoch: 5| Step: 4
Training loss: 2.7551019331945743
Validation loss: 2.5648445080841196

Epoch: 5| Step: 5
Training loss: 2.473719171039916
Validation loss: 2.552047844431379

Epoch: 5| Step: 6
Training loss: 2.332589189760176
Validation loss: 2.5267340065356114

Epoch: 5| Step: 7
Training loss: 2.9790613293642965
Validation loss: 2.563832258588761

Epoch: 5| Step: 8
Training loss: 2.728990757832545
Validation loss: 2.5578182309823085

Epoch: 5| Step: 9
Training loss: 2.3284559590682217
Validation loss: 2.53407336545937

Epoch: 5| Step: 10
Training loss: 2.272109020411381
Validation loss: 2.5524932950604406

Epoch: 230| Step: 0
Training loss: 2.7726818505957014
Validation loss: 2.538785067184458

Epoch: 5| Step: 1
Training loss: 2.408020953166453
Validation loss: 2.538704959252958

Epoch: 5| Step: 2
Training loss: 2.415535387990067
Validation loss: 2.541990654554714

Epoch: 5| Step: 3
Training loss: 2.354494111461004
Validation loss: 2.5739488295382826

Epoch: 5| Step: 4
Training loss: 2.3294339180780868
Validation loss: 2.560731876581757

Epoch: 5| Step: 5
Training loss: 3.14001610770012
Validation loss: 2.5344875155293023

Epoch: 5| Step: 6
Training loss: 2.7143851132943397
Validation loss: 2.5343272894691107

Epoch: 5| Step: 7
Training loss: 2.528058524371801
Validation loss: 2.5260972272629703

Epoch: 5| Step: 8
Training loss: 2.741460111387339
Validation loss: 2.5420434130581393

Epoch: 5| Step: 9
Training loss: 2.4839465653573916
Validation loss: 2.5490535133681917

Epoch: 5| Step: 10
Training loss: 2.9684282630449803
Validation loss: 2.533853701596392

Epoch: 231| Step: 0
Training loss: 2.9156254317599157
Validation loss: 2.5760821042335045

Epoch: 5| Step: 1
Training loss: 2.603669009659087
Validation loss: 2.548710878880219

Epoch: 5| Step: 2
Training loss: 2.659396563037993
Validation loss: 2.5703297949316717

Epoch: 5| Step: 3
Training loss: 3.051317311958367
Validation loss: 2.537870807025448

Epoch: 5| Step: 4
Training loss: 2.7921988326377987
Validation loss: 2.516400103097616

Epoch: 5| Step: 5
Training loss: 2.4032841028293666
Validation loss: 2.5532984235291916

Epoch: 5| Step: 6
Training loss: 1.7652384917280222
Validation loss: 2.5416335872499354

Epoch: 5| Step: 7
Training loss: 2.3181970888202637
Validation loss: 2.5518428663251327

Epoch: 5| Step: 8
Training loss: 2.8395283981759807
Validation loss: 2.529621891474019

Epoch: 5| Step: 9
Training loss: 2.8805167301528436
Validation loss: 2.5450793338711684

Epoch: 5| Step: 10
Training loss: 2.477499318358542
Validation loss: 2.5398645272396507

Epoch: 232| Step: 0
Training loss: 3.0209485437631907
Validation loss: 2.5268187135941385

Epoch: 5| Step: 1
Training loss: 2.824511669791882
Validation loss: 2.5601177392086045

Epoch: 5| Step: 2
Training loss: 2.4195880551886355
Validation loss: 2.5464248546299766

Epoch: 5| Step: 3
Training loss: 2.563778256056484
Validation loss: 2.5265964150517166

Epoch: 5| Step: 4
Training loss: 1.9080804884985825
Validation loss: 2.5386374234653366

Epoch: 5| Step: 5
Training loss: 2.9945868292153364
Validation loss: 2.5460969244858616

Epoch: 5| Step: 6
Training loss: 2.8519489183278623
Validation loss: 2.5628501863904725

Epoch: 5| Step: 7
Training loss: 2.5335843660390798
Validation loss: 2.5566635855909814

Epoch: 5| Step: 8
Training loss: 3.124914244428826
Validation loss: 2.5583436754963667

Epoch: 5| Step: 9
Training loss: 2.297608446585715
Validation loss: 2.5473326017728546

Epoch: 5| Step: 10
Training loss: 1.988680156869602
Validation loss: 2.560739710458264

Epoch: 233| Step: 0
Training loss: 2.5941316254925963
Validation loss: 2.5794541985525226

Epoch: 5| Step: 1
Training loss: 2.7838693350130983
Validation loss: 2.554956999020094

Epoch: 5| Step: 2
Training loss: 2.666347832295491
Validation loss: 2.525326562372875

Epoch: 5| Step: 3
Training loss: 2.20242861299728
Validation loss: 2.545281943803683

Epoch: 5| Step: 4
Training loss: 2.720880046714147
Validation loss: 2.5424241568356996

Epoch: 5| Step: 5
Training loss: 2.9624676537659234
Validation loss: 2.5644731865634336

Epoch: 5| Step: 6
Training loss: 2.5629672113018724
Validation loss: 2.5235871982037668

Epoch: 5| Step: 7
Training loss: 2.0380404311447586
Validation loss: 2.5342117993228155

Epoch: 5| Step: 8
Training loss: 2.4598143906080954
Validation loss: 2.547709201769203

Epoch: 5| Step: 9
Training loss: 2.970141757189426
Validation loss: 2.5592780117468372

Epoch: 5| Step: 10
Training loss: 2.837725619450228
Validation loss: 2.5591763086583077

Epoch: 234| Step: 0
Training loss: 3.054222754518129
Validation loss: 2.554270994582408

Epoch: 5| Step: 1
Training loss: 2.7423026992640454
Validation loss: 2.537173610976957

Epoch: 5| Step: 2
Training loss: 2.5046901576741396
Validation loss: 2.552158273413217

Epoch: 5| Step: 3
Training loss: 3.0979402467248836
Validation loss: 2.5306883917764376

Epoch: 5| Step: 4
Training loss: 2.4408489598322864
Validation loss: 2.5558796351744024

Epoch: 5| Step: 5
Training loss: 3.0279770317970267
Validation loss: 2.570763613289195

Epoch: 5| Step: 6
Training loss: 2.220261824349676
Validation loss: 2.546009608470947

Epoch: 5| Step: 7
Training loss: 2.5609888412607846
Validation loss: 2.5453410816181163

Epoch: 5| Step: 8
Training loss: 1.813336541065483
Validation loss: 2.5499357796515847

Epoch: 5| Step: 9
Training loss: 2.68190733492509
Validation loss: 2.5608880119815463

Epoch: 5| Step: 10
Training loss: 2.360451257042038
Validation loss: 2.520647521269779

Epoch: 235| Step: 0
Training loss: 2.4261985333903104
Validation loss: 2.5417810307081394

Epoch: 5| Step: 1
Training loss: 2.8441736932714847
Validation loss: 2.5247205071306467

Epoch: 5| Step: 2
Training loss: 3.016434318769544
Validation loss: 2.5505132376232678

Epoch: 5| Step: 3
Training loss: 2.56545979831016
Validation loss: 2.5392144967170283

Epoch: 5| Step: 4
Training loss: 2.3339102122762316
Validation loss: 2.5543786733674327

Epoch: 5| Step: 5
Training loss: 2.769493543962735
Validation loss: 2.557236481738141

Epoch: 5| Step: 6
Training loss: 2.3210511749687317
Validation loss: 2.5433793449468016

Epoch: 5| Step: 7
Training loss: 2.0031113265548335
Validation loss: 2.564579743744112

Epoch: 5| Step: 8
Training loss: 3.2685729232293066
Validation loss: 2.537497766060247

Epoch: 5| Step: 9
Training loss: 2.554377639130717
Validation loss: 2.548486289109369

Epoch: 5| Step: 10
Training loss: 2.6405306466304603
Validation loss: 2.5415125059933277

Epoch: 236| Step: 0
Training loss: 2.6994085617787724
Validation loss: 2.5526736640039296

Epoch: 5| Step: 1
Training loss: 2.748721866090719
Validation loss: 2.5612342934028347

Epoch: 5| Step: 2
Training loss: 3.028571764542389
Validation loss: 2.5481063289086507

Epoch: 5| Step: 3
Training loss: 2.1670093509910644
Validation loss: 2.55069129269009

Epoch: 5| Step: 4
Training loss: 2.4365353754091315
Validation loss: 2.5459263666371568

Epoch: 5| Step: 5
Training loss: 2.715732522291066
Validation loss: 2.5378364494311705

Epoch: 5| Step: 6
Training loss: 1.943638460448677
Validation loss: 2.5553990773239534

Epoch: 5| Step: 7
Training loss: 2.68443957996068
Validation loss: 2.5803621630765057

Epoch: 5| Step: 8
Training loss: 2.7360151331075913
Validation loss: 2.5515902523600786

Epoch: 5| Step: 9
Training loss: 3.033005982505968
Validation loss: 2.570100670533776

Epoch: 5| Step: 10
Training loss: 2.0839918113225453
Validation loss: 2.554288508532891

Epoch: 237| Step: 0
Training loss: 2.180647006482783
Validation loss: 2.5393333261593503

Epoch: 5| Step: 1
Training loss: 2.592269290969651
Validation loss: 2.5272525105780113

Epoch: 5| Step: 2
Training loss: 3.3912386712441513
Validation loss: 2.5679041654625365

Epoch: 5| Step: 3
Training loss: 2.8082904253963483
Validation loss: 2.555593750766181

Epoch: 5| Step: 4
Training loss: 2.1101469534733086
Validation loss: 2.568010432529825

Epoch: 5| Step: 5
Training loss: 2.909217222137435
Validation loss: 2.5394676865847035

Epoch: 5| Step: 6
Training loss: 2.5474398869992507
Validation loss: 2.5638178146277064

Epoch: 5| Step: 7
Training loss: 2.696748654974258
Validation loss: 2.5415123809136966

Epoch: 5| Step: 8
Training loss: 2.532520587532436
Validation loss: 2.5486926486488373

Epoch: 5| Step: 9
Training loss: 2.11706193502336
Validation loss: 2.542527904342246

Epoch: 5| Step: 10
Training loss: 2.6468609193609756
Validation loss: 2.5525310449282212

Epoch: 238| Step: 0
Training loss: 3.080480303780165
Validation loss: 2.5433132124268756

Epoch: 5| Step: 1
Training loss: 2.6596406725495982
Validation loss: 2.552431393148347

Epoch: 5| Step: 2
Training loss: 2.7245680720435703
Validation loss: 2.539194043761509

Epoch: 5| Step: 3
Training loss: 2.889606688243945
Validation loss: 2.5467500870541335

Epoch: 5| Step: 4
Training loss: 2.3222502249936183
Validation loss: 2.5692136742007867

Epoch: 5| Step: 5
Training loss: 2.5148588162907366
Validation loss: 2.569477726584892

Epoch: 5| Step: 6
Training loss: 2.7977527967133433
Validation loss: 2.56661243328153

Epoch: 5| Step: 7
Training loss: 2.6478728195950048
Validation loss: 2.551483622931334

Epoch: 5| Step: 8
Training loss: 2.186043608723468
Validation loss: 2.563125959587226

Epoch: 5| Step: 9
Training loss: 2.5005497328021775
Validation loss: 2.537885974191603

Epoch: 5| Step: 10
Training loss: 2.469037003071072
Validation loss: 2.5656876225227165

Epoch: 239| Step: 0
Training loss: 2.1495014677253463
Validation loss: 2.566804018035863

Epoch: 5| Step: 1
Training loss: 2.464384347509486
Validation loss: 2.5592758150076396

Epoch: 5| Step: 2
Training loss: 2.6856697415075477
Validation loss: 2.546770829632715

Epoch: 5| Step: 3
Training loss: 2.942259807781981
Validation loss: 2.5736805342929294

Epoch: 5| Step: 4
Training loss: 2.9660204737259526
Validation loss: 2.52503882087618

Epoch: 5| Step: 5
Training loss: 2.440089586364329
Validation loss: 2.569052050456129

Epoch: 5| Step: 6
Training loss: 2.6725827891388185
Validation loss: 2.556748509307652

Epoch: 5| Step: 7
Training loss: 2.162730664426194
Validation loss: 2.558339602076685

Epoch: 5| Step: 8
Training loss: 2.5113162464235326
Validation loss: 2.5330841800346833

Epoch: 5| Step: 9
Training loss: 2.2272034910336354
Validation loss: 2.538149021553761

Epoch: 5| Step: 10
Training loss: 3.3351562442810816
Validation loss: 2.578695120471243

Epoch: 240| Step: 0
Training loss: 2.649730175604588
Validation loss: 2.5589290481545626

Epoch: 5| Step: 1
Training loss: 2.529763998249801
Validation loss: 2.5427073861728613

Epoch: 5| Step: 2
Training loss: 2.2364198091194933
Validation loss: 2.548204235300069

Epoch: 5| Step: 3
Training loss: 2.7739628683739057
Validation loss: 2.5438295948808163

Epoch: 5| Step: 4
Training loss: 2.685737475480604
Validation loss: 2.541110948490394

Epoch: 5| Step: 5
Training loss: 2.6494242312569782
Validation loss: 2.5480383339937145

Epoch: 5| Step: 6
Training loss: 2.632987630662213
Validation loss: 2.529933037405717

Epoch: 5| Step: 7
Training loss: 2.490834792813022
Validation loss: 2.5463684874843815

Epoch: 5| Step: 8
Training loss: 3.1431423745212737
Validation loss: 2.5355231675311165

Epoch: 5| Step: 9
Training loss: 2.449968579149202
Validation loss: 2.5710454317772538

Epoch: 5| Step: 10
Training loss: 2.21959380102318
Validation loss: 2.544696881305742

Epoch: 241| Step: 0
Training loss: 2.2803582316608435
Validation loss: 2.547878182309154

Epoch: 5| Step: 1
Training loss: 2.2350056431846292
Validation loss: 2.540352395985156

Epoch: 5| Step: 2
Training loss: 2.3419904080071525
Validation loss: 2.5398260839144413

Epoch: 5| Step: 3
Training loss: 2.775005058765096
Validation loss: 2.566243576328593

Epoch: 5| Step: 4
Training loss: 2.1910756995714324
Validation loss: 2.5597523130040045

Epoch: 5| Step: 5
Training loss: 2.7385112758346524
Validation loss: 2.5587517421613146

Epoch: 5| Step: 6
Training loss: 1.9956650245540386
Validation loss: 2.555997883424421

Epoch: 5| Step: 7
Training loss: 3.454464889800694
Validation loss: 2.5556000715985365

Epoch: 5| Step: 8
Training loss: 2.584155802904322
Validation loss: 2.549413777960974

Epoch: 5| Step: 9
Training loss: 3.252116907709299
Validation loss: 2.577077794742819

Epoch: 5| Step: 10
Training loss: 2.516830724038296
Validation loss: 2.549280198183325

Epoch: 242| Step: 0
Training loss: 3.1752291078582244
Validation loss: 2.549589213533434

Epoch: 5| Step: 1
Training loss: 2.119578457794171
Validation loss: 2.550997300619912

Epoch: 5| Step: 2
Training loss: 2.613923180715883
Validation loss: 2.5271582174543163

Epoch: 5| Step: 3
Training loss: 2.236669789163804
Validation loss: 2.53854813407006

Epoch: 5| Step: 4
Training loss: 2.516367263752492
Validation loss: 2.5319918516806483

Epoch: 5| Step: 5
Training loss: 1.5634538409400656
Validation loss: 2.54647102828709

Epoch: 5| Step: 6
Training loss: 3.0512552711225625
Validation loss: 2.5366180249039996

Epoch: 5| Step: 7
Training loss: 2.2387833223573317
Validation loss: 2.5567506811455303

Epoch: 5| Step: 8
Training loss: 2.726924139922594
Validation loss: 2.561296618145899

Epoch: 5| Step: 9
Training loss: 2.4904300627769107
Validation loss: 2.5313970243818713

Epoch: 5| Step: 10
Training loss: 3.6464794058783765
Validation loss: 2.522030033688668

Epoch: 243| Step: 0
Training loss: 2.374022935359624
Validation loss: 2.5504734757097567

Epoch: 5| Step: 1
Training loss: 2.299514706870882
Validation loss: 2.5570292406588804

Epoch: 5| Step: 2
Training loss: 3.603108965663518
Validation loss: 2.530200084723714

Epoch: 5| Step: 3
Training loss: 2.445166440263988
Validation loss: 2.5514209449405088

Epoch: 5| Step: 4
Training loss: 2.4798338069912327
Validation loss: 2.5497110805953374

Epoch: 5| Step: 5
Training loss: 2.289309751938305
Validation loss: 2.537942066336815

Epoch: 5| Step: 6
Training loss: 2.286674008519849
Validation loss: 2.5492383393660916

Epoch: 5| Step: 7
Training loss: 2.798345424345007
Validation loss: 2.5395636425721877

Epoch: 5| Step: 8
Training loss: 2.509067399683796
Validation loss: 2.557792654767386

Epoch: 5| Step: 9
Training loss: 2.187023219874453
Validation loss: 2.541490457587135

Epoch: 5| Step: 10
Training loss: 3.149338056253396
Validation loss: 2.563118812642445

Epoch: 244| Step: 0
Training loss: 2.0593128432298733
Validation loss: 2.558293154612993

Epoch: 5| Step: 1
Training loss: 2.8204022760447245
Validation loss: 2.553399703109622

Epoch: 5| Step: 2
Training loss: 2.9706007157931706
Validation loss: 2.565663961306268

Epoch: 5| Step: 3
Training loss: 1.7381502595044764
Validation loss: 2.5459297641108014

Epoch: 5| Step: 4
Training loss: 2.5617719406836783
Validation loss: 2.5793315660657767

Epoch: 5| Step: 5
Training loss: 2.33653420064211
Validation loss: 2.5515923050077194

Epoch: 5| Step: 6
Training loss: 2.6164637233815196
Validation loss: 2.5188562136134776

Epoch: 5| Step: 7
Training loss: 2.6982728484900638
Validation loss: 2.5403365197151673

Epoch: 5| Step: 8
Training loss: 2.792122068316259
Validation loss: 2.559021808956825

Epoch: 5| Step: 9
Training loss: 3.216110035726678
Validation loss: 2.543891257650497

Epoch: 5| Step: 10
Training loss: 2.387662760194768
Validation loss: 2.5736313205546484

Epoch: 245| Step: 0
Training loss: 2.2504383295979222
Validation loss: 2.551541844361431

Epoch: 5| Step: 1
Training loss: 2.7156923134278186
Validation loss: 2.556821132520239

Epoch: 5| Step: 2
Training loss: 2.7312233336519576
Validation loss: 2.564486236292276

Epoch: 5| Step: 3
Training loss: 2.2977236263457854
Validation loss: 2.534419568956387

Epoch: 5| Step: 4
Training loss: 2.5361286761132997
Validation loss: 2.5358290450836853

Epoch: 5| Step: 5
Training loss: 2.9304618117378207
Validation loss: 2.5386094161567967

Epoch: 5| Step: 6
Training loss: 2.798574432141101
Validation loss: 2.555204001274039

Epoch: 5| Step: 7
Training loss: 1.9935711412712234
Validation loss: 2.558386316245493

Epoch: 5| Step: 8
Training loss: 2.627675464117775
Validation loss: 2.541334366185833

Epoch: 5| Step: 9
Training loss: 2.519222648706077
Validation loss: 2.542187858358804

Epoch: 5| Step: 10
Training loss: 3.234533923386503
Validation loss: 2.5404432032748567

Epoch: 246| Step: 0
Training loss: 2.584112993126012
Validation loss: 2.5634338764127165

Epoch: 5| Step: 1
Training loss: 2.9729792936946775
Validation loss: 2.593596847169757

Epoch: 5| Step: 2
Training loss: 2.29643047987819
Validation loss: 2.546978274310695

Epoch: 5| Step: 3
Training loss: 1.910266896419139
Validation loss: 2.547055048152064

Epoch: 5| Step: 4
Training loss: 2.2353519891327682
Validation loss: 2.557382855962491

Epoch: 5| Step: 5
Training loss: 3.4199960505591003
Validation loss: 2.561220363289592

Epoch: 5| Step: 6
Training loss: 2.3760415855005217
Validation loss: 2.567541909327761

Epoch: 5| Step: 7
Training loss: 2.6221601474368708
Validation loss: 2.546420602068953

Epoch: 5| Step: 8
Training loss: 2.10182942677076
Validation loss: 2.5589844052950235

Epoch: 5| Step: 9
Training loss: 2.7592220864528803
Validation loss: 2.5394897303438144

Epoch: 5| Step: 10
Training loss: 2.9258276982815885
Validation loss: 2.5635171187748056

Epoch: 247| Step: 0
Training loss: 2.0405737877768146
Validation loss: 2.557133520466104

Epoch: 5| Step: 1
Training loss: 2.175925012081787
Validation loss: 2.559978552162529

Epoch: 5| Step: 2
Training loss: 2.091364056201136
Validation loss: 2.5685662438823833

Epoch: 5| Step: 3
Training loss: 2.94644119127882
Validation loss: 2.5556635629456257

Epoch: 5| Step: 4
Training loss: 2.7299865384171706
Validation loss: 2.566512174542003

Epoch: 5| Step: 5
Training loss: 3.259654158051516
Validation loss: 2.5545444534401898

Epoch: 5| Step: 6
Training loss: 2.415942796181521
Validation loss: 2.5532582742449836

Epoch: 5| Step: 7
Training loss: 2.1748223374690734
Validation loss: 2.5649883335099837

Epoch: 5| Step: 8
Training loss: 2.724762855500159
Validation loss: 2.533223432020111

Epoch: 5| Step: 9
Training loss: 2.6554183555640356
Validation loss: 2.5650559880514963

Epoch: 5| Step: 10
Training loss: 2.887404508786963
Validation loss: 2.5775855093142

Epoch: 248| Step: 0
Training loss: 2.3102674274957544
Validation loss: 2.5754773527916415

Epoch: 5| Step: 1
Training loss: 3.020262320033067
Validation loss: 2.5336697243639286

Epoch: 5| Step: 2
Training loss: 2.807559697101614
Validation loss: 2.5313588945286956

Epoch: 5| Step: 3
Training loss: 2.3148962441709684
Validation loss: 2.5411707140228743

Epoch: 5| Step: 4
Training loss: 2.8041345587862394
Validation loss: 2.5454402022359837

Epoch: 5| Step: 5
Training loss: 2.0895993669173025
Validation loss: 2.5356379063950563

Epoch: 5| Step: 6
Training loss: 2.4110203805993184
Validation loss: 2.539319151724427

Epoch: 5| Step: 7
Training loss: 2.4869268974416987
Validation loss: 2.5612563179814325

Epoch: 5| Step: 8
Training loss: 3.259080818337671
Validation loss: 2.559113407350224

Epoch: 5| Step: 9
Training loss: 2.0698769165155513
Validation loss: 2.5319001023707126

Epoch: 5| Step: 10
Training loss: 2.6810314489538425
Validation loss: 2.5279914647389607

Epoch: 249| Step: 0
Training loss: 2.896185233783611
Validation loss: 2.566128701390812

Epoch: 5| Step: 1
Training loss: 2.3580955421433765
Validation loss: 2.5590486391555087

Epoch: 5| Step: 2
Training loss: 2.7290715693632492
Validation loss: 2.561575185714293

Epoch: 5| Step: 3
Training loss: 2.191596527814543
Validation loss: 2.5673303525396878

Epoch: 5| Step: 4
Training loss: 2.5989520748779125
Validation loss: 2.53661257545713

Epoch: 5| Step: 5
Training loss: 3.0608132836148827
Validation loss: 2.5756648552076933

Epoch: 5| Step: 6
Training loss: 2.254636120756035
Validation loss: 2.583995293334438

Epoch: 5| Step: 7
Training loss: 2.314085545705214
Validation loss: 2.583375186825911

Epoch: 5| Step: 8
Training loss: 2.8844614662774495
Validation loss: 2.5682682121770677

Epoch: 5| Step: 9
Training loss: 1.7211436856194928
Validation loss: 2.532534941738032

Epoch: 5| Step: 10
Training loss: 3.248086659548512
Validation loss: 2.5472511900977977

Epoch: 250| Step: 0
Training loss: 2.21994652520462
Validation loss: 2.5729279700759102

Epoch: 5| Step: 1
Training loss: 3.1051456691216344
Validation loss: 2.5437514518239213

Epoch: 5| Step: 2
Training loss: 2.1822076263876236
Validation loss: 2.5637319336246502

Epoch: 5| Step: 3
Training loss: 2.969766543168478
Validation loss: 2.5394043617028736

Epoch: 5| Step: 4
Training loss: 1.9889393375020112
Validation loss: 2.5634250846885838

Epoch: 5| Step: 5
Training loss: 2.8589267066615225
Validation loss: 2.5514898770814427

Epoch: 5| Step: 6
Training loss: 2.2249741627768205
Validation loss: 2.5531572762286436

Epoch: 5| Step: 7
Training loss: 3.0830543666801065
Validation loss: 2.5507727955781383

Epoch: 5| Step: 8
Training loss: 2.5294817175761524
Validation loss: 2.558094260024693

Epoch: 5| Step: 9
Training loss: 2.7982797344982617
Validation loss: 2.5241915267959305

Epoch: 5| Step: 10
Training loss: 2.3966535960845996
Validation loss: 2.541439724747022

Epoch: 251| Step: 0
Training loss: 2.7231352068745016
Validation loss: 2.556123141785914

Epoch: 5| Step: 1
Training loss: 2.545558097516541
Validation loss: 2.5460552207563527

Epoch: 5| Step: 2
Training loss: 2.0724407269476792
Validation loss: 2.5448870786940336

Epoch: 5| Step: 3
Training loss: 2.7305961437276625
Validation loss: 2.5730784415450243

Epoch: 5| Step: 4
Training loss: 2.0265087252903644
Validation loss: 2.5489881164252917

Epoch: 5| Step: 5
Training loss: 3.1570750753848427
Validation loss: 2.5794764174014717

Epoch: 5| Step: 6
Training loss: 2.1835782454866592
Validation loss: 2.5405562678610645

Epoch: 5| Step: 7
Training loss: 2.9974417905269912
Validation loss: 2.556075126538718

Epoch: 5| Step: 8
Training loss: 2.661264242023938
Validation loss: 2.5447931619535447

Epoch: 5| Step: 9
Training loss: 2.4991707380142283
Validation loss: 2.553250855188178

Epoch: 5| Step: 10
Training loss: 2.674371724011937
Validation loss: 2.567172996185383

Epoch: 252| Step: 0
Training loss: 2.2107237587855004
Validation loss: 2.5622166582754184

Epoch: 5| Step: 1
Training loss: 2.4962425605460585
Validation loss: 2.5599552167223516

Epoch: 5| Step: 2
Training loss: 2.803159164509698
Validation loss: 2.5731352497813402

Epoch: 5| Step: 3
Training loss: 2.6225980032326834
Validation loss: 2.5671903831694376

Epoch: 5| Step: 4
Training loss: 2.2084085943484926
Validation loss: 2.548053223568337

Epoch: 5| Step: 5
Training loss: 2.285508870363182
Validation loss: 2.525789990503286

Epoch: 5| Step: 6
Training loss: 2.6959608984299157
Validation loss: 2.569778243730971

Epoch: 5| Step: 7
Training loss: 3.070701360950708
Validation loss: 2.5595787358600313

Epoch: 5| Step: 8
Training loss: 2.374605648027179
Validation loss: 2.560228831462013

Epoch: 5| Step: 9
Training loss: 2.8150796715690825
Validation loss: 2.5599910289548893

Epoch: 5| Step: 10
Training loss: 2.916002870137041
Validation loss: 2.5966406374619853

Epoch: 253| Step: 0
Training loss: 1.864669314769346
Validation loss: 2.5621043429294095

Epoch: 5| Step: 1
Training loss: 3.3067848277770957
Validation loss: 2.558647437128477

Epoch: 5| Step: 2
Training loss: 2.256734940676078
Validation loss: 2.5648803280130203

Epoch: 5| Step: 3
Training loss: 2.211424433597652
Validation loss: 2.573523030282203

Epoch: 5| Step: 4
Training loss: 3.0769514761127676
Validation loss: 2.5718079798314544

Epoch: 5| Step: 5
Training loss: 2.9393254553358417
Validation loss: 2.568354662170291

Epoch: 5| Step: 6
Training loss: 2.7406302266087383
Validation loss: 2.542245769308796

Epoch: 5| Step: 7
Training loss: 2.3149101482116348
Validation loss: 2.559036793910926

Epoch: 5| Step: 8
Training loss: 2.554932842081209
Validation loss: 2.5552836667056242

Epoch: 5| Step: 9
Training loss: 2.374227197298799
Validation loss: 2.5561279127716783

Epoch: 5| Step: 10
Training loss: 2.513139148094579
Validation loss: 2.5598753076018226

Epoch: 254| Step: 0
Training loss: 2.4070848280092205
Validation loss: 2.5476012124079763

Epoch: 5| Step: 1
Training loss: 2.842644277381877
Validation loss: 2.535471945223973

Epoch: 5| Step: 2
Training loss: 2.480620420129248
Validation loss: 2.5577425529894713

Epoch: 5| Step: 3
Training loss: 3.4241027547801437
Validation loss: 2.5556258764024635

Epoch: 5| Step: 4
Training loss: 2.568708388833819
Validation loss: 2.5467110868043035

Epoch: 5| Step: 5
Training loss: 2.708783175939058
Validation loss: 2.5463079891721505

Epoch: 5| Step: 6
Training loss: 2.1613503547875195
Validation loss: 2.5641121663859554

Epoch: 5| Step: 7
Training loss: 2.5031448611115636
Validation loss: 2.555912440276561

Epoch: 5| Step: 8
Training loss: 2.2102458397677607
Validation loss: 2.552829340242992

Epoch: 5| Step: 9
Training loss: 2.25990109049993
Validation loss: 2.558516563886369

Epoch: 5| Step: 10
Training loss: 2.57840232513517
Validation loss: 2.543292968832995

Epoch: 255| Step: 0
Training loss: 2.4505786679476937
Validation loss: 2.5502977119411696

Epoch: 5| Step: 1
Training loss: 2.5732852707790386
Validation loss: 2.5405449075416073

Epoch: 5| Step: 2
Training loss: 2.7213632586508307
Validation loss: 2.5401647051213088

Epoch: 5| Step: 3
Training loss: 2.8016247190852233
Validation loss: 2.5624281175097026

Epoch: 5| Step: 4
Training loss: 3.3025967813499584
Validation loss: 2.525611235052211

Epoch: 5| Step: 5
Training loss: 2.63376118125769
Validation loss: 2.5609285576955236

Epoch: 5| Step: 6
Training loss: 2.3420874230073645
Validation loss: 2.5913183707139815

Epoch: 5| Step: 7
Training loss: 2.1115221186750115
Validation loss: 2.5659730687114743

Epoch: 5| Step: 8
Training loss: 2.3273021088582366
Validation loss: 2.5940298232691643

Epoch: 5| Step: 9
Training loss: 2.5799021751132925
Validation loss: 2.5559086583730752

Epoch: 5| Step: 10
Training loss: 2.283188505754095
Validation loss: 2.5384009734620134

Epoch: 256| Step: 0
Training loss: 2.7618958067083264
Validation loss: 2.5543712560593326

Epoch: 5| Step: 1
Training loss: 2.587844468190975
Validation loss: 2.539214825852985

Epoch: 5| Step: 2
Training loss: 2.802994155806928
Validation loss: 2.5526599452800376

Epoch: 5| Step: 3
Training loss: 2.7064689283379173
Validation loss: 2.5365361773657114

Epoch: 5| Step: 4
Training loss: 2.5973329730115218
Validation loss: 2.5273455119456125

Epoch: 5| Step: 5
Training loss: 2.2700253603690754
Validation loss: 2.544822985034571

Epoch: 5| Step: 6
Training loss: 2.505848528510723
Validation loss: 2.5522326534771644

Epoch: 5| Step: 7
Training loss: 2.6976702564095736
Validation loss: 2.5384397963891594

Epoch: 5| Step: 8
Training loss: 2.9320016901654085
Validation loss: 2.526359733107786

Epoch: 5| Step: 9
Training loss: 2.6991728186667294
Validation loss: 2.5635812280620094

Epoch: 5| Step: 10
Training loss: 1.752494668775604
Validation loss: 2.536391503195097

Epoch: 257| Step: 0
Training loss: 2.7724446843427692
Validation loss: 2.548532757374226

Epoch: 5| Step: 1
Training loss: 2.222015020194392
Validation loss: 2.549807463480441

Epoch: 5| Step: 2
Training loss: 2.5602976010612037
Validation loss: 2.5558430732284068

Epoch: 5| Step: 3
Training loss: 2.040187948956034
Validation loss: 2.5729805689855567

Epoch: 5| Step: 4
Training loss: 2.513505789390986
Validation loss: 2.544723656014835

Epoch: 5| Step: 5
Training loss: 3.059380324206137
Validation loss: 2.5637282702524953

Epoch: 5| Step: 6
Training loss: 3.155375444468794
Validation loss: 2.5532516062318558

Epoch: 5| Step: 7
Training loss: 2.867044471270744
Validation loss: 2.5709252680409205

Epoch: 5| Step: 8
Training loss: 2.19948650783139
Validation loss: 2.5492540204128042

Epoch: 5| Step: 9
Training loss: 2.6815227307592626
Validation loss: 2.5925582587266534

Epoch: 5| Step: 10
Training loss: 2.093352550531771
Validation loss: 2.5579063746542494

Epoch: 258| Step: 0
Training loss: 2.3173936151573433
Validation loss: 2.5482579833688566

Epoch: 5| Step: 1
Training loss: 2.82890182701256
Validation loss: 2.548692915203038

Epoch: 5| Step: 2
Training loss: 1.9353698587933852
Validation loss: 2.5662438270739916

Epoch: 5| Step: 3
Training loss: 3.3569092683777746
Validation loss: 2.559967616517967

Epoch: 5| Step: 4
Training loss: 2.534139044110495
Validation loss: 2.547025147534314

Epoch: 5| Step: 5
Training loss: 2.4766954452499257
Validation loss: 2.5589069093712045

Epoch: 5| Step: 6
Training loss: 2.6325451633096884
Validation loss: 2.535496293643145

Epoch: 5| Step: 7
Training loss: 2.357183183597566
Validation loss: 2.5472610053281235

Epoch: 5| Step: 8
Training loss: 2.6376074529517655
Validation loss: 2.5579759473279093

Epoch: 5| Step: 9
Training loss: 2.5472125432357386
Validation loss: 2.5394178734048696

Epoch: 5| Step: 10
Training loss: 2.452855672447855
Validation loss: 2.5545895259680687

Epoch: 259| Step: 0
Training loss: 2.8134373268535002
Validation loss: 2.559051492264413

Epoch: 5| Step: 1
Training loss: 2.7054530355606827
Validation loss: 2.563902812344265

Epoch: 5| Step: 2
Training loss: 2.467348401051548
Validation loss: 2.552878449876035

Epoch: 5| Step: 3
Training loss: 2.739968295784069
Validation loss: 2.558097204393073

Epoch: 5| Step: 4
Training loss: 2.766881107920731
Validation loss: 2.571052572143142

Epoch: 5| Step: 5
Training loss: 2.6704437705732005
Validation loss: 2.5754817713865115

Epoch: 5| Step: 6
Training loss: 2.5777109449408258
Validation loss: 2.5725071530371357

Epoch: 5| Step: 7
Training loss: 2.622044216146906
Validation loss: 2.5602591396182643

Epoch: 5| Step: 8
Training loss: 2.5613315988912406
Validation loss: 2.5347788074841597

Epoch: 5| Step: 9
Training loss: 2.1060529758206203
Validation loss: 2.5558406538685468

Epoch: 5| Step: 10
Training loss: 2.3035410987825933
Validation loss: 2.5681422314868745

Epoch: 260| Step: 0
Training loss: 2.079993189837238
Validation loss: 2.5592146791896466

Epoch: 5| Step: 1
Training loss: 2.9885727684093015
Validation loss: 2.552143803562962

Epoch: 5| Step: 2
Training loss: 3.282305157261546
Validation loss: 2.5535293356731685

Epoch: 5| Step: 3
Training loss: 2.096606455404832
Validation loss: 2.5593537545216667

Epoch: 5| Step: 4
Training loss: 2.3731365924719845
Validation loss: 2.545434314429044

Epoch: 5| Step: 5
Training loss: 2.6816934356712667
Validation loss: 2.5506931927870675

Epoch: 5| Step: 6
Training loss: 2.692081538332969
Validation loss: 2.560021125623934

Epoch: 5| Step: 7
Training loss: 2.4799844584439508
Validation loss: 2.554804273153463

Epoch: 5| Step: 8
Training loss: 2.4329790101249325
Validation loss: 2.5590395528640295

Epoch: 5| Step: 9
Training loss: 2.491631616284215
Validation loss: 2.563654054715215

Epoch: 5| Step: 10
Training loss: 2.476496939287734
Validation loss: 2.5729221606153367

Epoch: 261| Step: 0
Training loss: 3.18555690405955
Validation loss: 2.5593131703361696

Epoch: 5| Step: 1
Training loss: 2.773576587896614
Validation loss: 2.557198930657898

Epoch: 5| Step: 2
Training loss: 2.984693580120397
Validation loss: 2.5526485313660867

Epoch: 5| Step: 3
Training loss: 2.562527354024638
Validation loss: 2.548657178585846

Epoch: 5| Step: 4
Training loss: 2.2989810967251048
Validation loss: 2.561660858306661

Epoch: 5| Step: 5
Training loss: 2.0250047189163043
Validation loss: 2.557541320121841

Epoch: 5| Step: 6
Training loss: 2.9202456903954075
Validation loss: 2.5661651547529036

Epoch: 5| Step: 7
Training loss: 1.8063388551814301
Validation loss: 2.567964540343575

Epoch: 5| Step: 8
Training loss: 2.353829238700407
Validation loss: 2.57889375036066

Epoch: 5| Step: 9
Training loss: 2.207690331277446
Validation loss: 2.528269036537351

Epoch: 5| Step: 10
Training loss: 2.871611713216453
Validation loss: 2.572904546824624

Epoch: 262| Step: 0
Training loss: 2.414797970236961
Validation loss: 2.5854147651114516

Epoch: 5| Step: 1
Training loss: 2.6039956201964785
Validation loss: 2.5622394118129237

Epoch: 5| Step: 2
Training loss: 2.439456741171509
Validation loss: 2.5796407957553456

Epoch: 5| Step: 3
Training loss: 2.5276383430208385
Validation loss: 2.5384880977411703

Epoch: 5| Step: 4
Training loss: 2.2694112775545765
Validation loss: 2.5318059296854125

Epoch: 5| Step: 5
Training loss: 2.5880738621744466
Validation loss: 2.5829656615850967

Epoch: 5| Step: 6
Training loss: 2.632004429903332
Validation loss: 2.5515954387333606

Epoch: 5| Step: 7
Training loss: 2.7652389343112045
Validation loss: 2.5359789549945306

Epoch: 5| Step: 8
Training loss: 2.4671877010024064
Validation loss: 2.546803750051188

Epoch: 5| Step: 9
Training loss: 2.8471923785209206
Validation loss: 2.523898099770588

Epoch: 5| Step: 10
Training loss: 2.9252772794839865
Validation loss: 2.5535577987769864

Epoch: 263| Step: 0
Training loss: 2.8991648951436684
Validation loss: 2.5730668631436924

Epoch: 5| Step: 1
Training loss: 1.9264213318473793
Validation loss: 2.5358918809873257

Epoch: 5| Step: 2
Training loss: 2.3518576199195773
Validation loss: 2.5465432107020374

Epoch: 5| Step: 3
Training loss: 2.339910796005728
Validation loss: 2.584342249115345

Epoch: 5| Step: 4
Training loss: 2.9153509896446885
Validation loss: 2.5653497975069164

Epoch: 5| Step: 5
Training loss: 2.499096134823322
Validation loss: 2.5682366918799553

Epoch: 5| Step: 6
Training loss: 3.0664556997406107
Validation loss: 2.55799514367279

Epoch: 5| Step: 7
Training loss: 1.9795401237566517
Validation loss: 2.541381373768427

Epoch: 5| Step: 8
Training loss: 2.439648781497654
Validation loss: 2.565167239217264

Epoch: 5| Step: 9
Training loss: 2.8101335530428977
Validation loss: 2.5822262854684133

Epoch: 5| Step: 10
Training loss: 2.5601797997395863
Validation loss: 2.5510330768109073

Epoch: 264| Step: 0
Training loss: 2.325264934088671
Validation loss: 2.6003311250065972

Epoch: 5| Step: 1
Training loss: 2.5543991066075407
Validation loss: 2.568384289021196

Epoch: 5| Step: 2
Training loss: 3.695712626370106
Validation loss: 2.5460283311649023

Epoch: 5| Step: 3
Training loss: 2.387688222925313
Validation loss: 2.5729041711820098

Epoch: 5| Step: 4
Training loss: 2.965912115028405
Validation loss: 2.536643425518859

Epoch: 5| Step: 5
Training loss: 2.7352856672712615
Validation loss: 2.5611785414654724

Epoch: 5| Step: 6
Training loss: 1.8105444388594385
Validation loss: 2.548886144575927

Epoch: 5| Step: 7
Training loss: 1.640151691283252
Validation loss: 2.5602816962717303

Epoch: 5| Step: 8
Training loss: 2.454296342654476
Validation loss: 2.5336078603804255

Epoch: 5| Step: 9
Training loss: 2.3960201245897257
Validation loss: 2.5583770923239766

Epoch: 5| Step: 10
Training loss: 2.8261570274316274
Validation loss: 2.5671191188551385

Epoch: 265| Step: 0
Training loss: 2.6231576721468945
Validation loss: 2.5402748766233887

Epoch: 5| Step: 1
Training loss: 2.4106265803938443
Validation loss: 2.5333562383064225

Epoch: 5| Step: 2
Training loss: 2.5868163675399454
Validation loss: 2.5531844130541956

Epoch: 5| Step: 3
Training loss: 2.686464154425876
Validation loss: 2.5332991108204648

Epoch: 5| Step: 4
Training loss: 2.615147766548068
Validation loss: 2.5321239642390823

Epoch: 5| Step: 5
Training loss: 2.519065825774015
Validation loss: 2.546353874993248

Epoch: 5| Step: 6
Training loss: 2.9012641387686977
Validation loss: 2.5655452712336064

Epoch: 5| Step: 7
Training loss: 1.886799117562381
Validation loss: 2.5489173308723654

Epoch: 5| Step: 8
Training loss: 2.5749534750874132
Validation loss: 2.538739039513746

Epoch: 5| Step: 9
Training loss: 2.9810040194520466
Validation loss: 2.5774022058367194

Epoch: 5| Step: 10
Training loss: 2.4400506978943444
Validation loss: 2.554441643593917

Epoch: 266| Step: 0
Training loss: 2.404761907010076
Validation loss: 2.557914578992295

Epoch: 5| Step: 1
Training loss: 2.292510992624932
Validation loss: 2.5770936117899796

Epoch: 5| Step: 2
Training loss: 3.462208947023082
Validation loss: 2.5767115870413932

Epoch: 5| Step: 3
Training loss: 2.697084855880162
Validation loss: 2.577164498822707

Epoch: 5| Step: 4
Training loss: 2.489240955342098
Validation loss: 2.5538141843248052

Epoch: 5| Step: 5
Training loss: 2.11966934288557
Validation loss: 2.5787838230479116

Epoch: 5| Step: 6
Training loss: 2.484985852268403
Validation loss: 2.593277739095996

Epoch: 5| Step: 7
Training loss: 2.590303083971738
Validation loss: 2.5716114693505077

Epoch: 5| Step: 8
Training loss: 2.3303318700897218
Validation loss: 2.561016480701643

Epoch: 5| Step: 9
Training loss: 2.7701504853062904
Validation loss: 2.5655700816808333

Epoch: 5| Step: 10
Training loss: 2.3789301027001013
Validation loss: 2.5564230155826904

Epoch: 267| Step: 0
Training loss: 3.095609780237009
Validation loss: 2.5449967647233516

Epoch: 5| Step: 1
Training loss: 2.6470882613595896
Validation loss: 2.544251546873654

Epoch: 5| Step: 2
Training loss: 2.9557375377026744
Validation loss: 2.534419715628187

Epoch: 5| Step: 3
Training loss: 2.1405011440560076
Validation loss: 2.5416242137680625

Epoch: 5| Step: 4
Training loss: 2.155393347366684
Validation loss: 2.550931782661954

Epoch: 5| Step: 5
Training loss: 2.6475657600974762
Validation loss: 2.557493004716398

Epoch: 5| Step: 6
Training loss: 1.7962644120118028
Validation loss: 2.559262113643265

Epoch: 5| Step: 7
Training loss: 3.07041391297409
Validation loss: 2.5691026167205404

Epoch: 5| Step: 8
Training loss: 2.3489413940991795
Validation loss: 2.55119835931477

Epoch: 5| Step: 9
Training loss: 2.172436648411991
Validation loss: 2.5422316796851057

Epoch: 5| Step: 10
Training loss: 2.643947970866701
Validation loss: 2.5415055781864253

Epoch: 268| Step: 0
Training loss: 2.511277511544719
Validation loss: 2.5499327987141873

Epoch: 5| Step: 1
Training loss: 2.2418666703106926
Validation loss: 2.5418040750990647

Epoch: 5| Step: 2
Training loss: 2.8842696975547244
Validation loss: 2.536932118433888

Epoch: 5| Step: 3
Training loss: 3.334476481558521
Validation loss: 2.5659288385710766

Epoch: 5| Step: 4
Training loss: 2.9140872084973757
Validation loss: 2.5592464318118124

Epoch: 5| Step: 5
Training loss: 2.442867726627327
Validation loss: 2.5654183653762104

Epoch: 5| Step: 6
Training loss: 1.6450573584809318
Validation loss: 2.544344504234817

Epoch: 5| Step: 7
Training loss: 2.0481833433397925
Validation loss: 2.5359720186419072

Epoch: 5| Step: 8
Training loss: 2.5703074910309285
Validation loss: 2.562903172680202

Epoch: 5| Step: 9
Training loss: 2.618478849298274
Validation loss: 2.5424850702262343

Epoch: 5| Step: 10
Training loss: 2.6309905950478933
Validation loss: 2.5308199575056554

Epoch: 269| Step: 0
Training loss: 2.8110133162447353
Validation loss: 2.543553382515202

Epoch: 5| Step: 1
Training loss: 2.5518253637191095
Validation loss: 2.544260422989301

Epoch: 5| Step: 2
Training loss: 2.1555693284585535
Validation loss: 2.5489393401800595

Epoch: 5| Step: 3
Training loss: 2.6449854135381523
Validation loss: 2.5694258511739037

Epoch: 5| Step: 4
Training loss: 2.9083610169004923
Validation loss: 2.5572506400675423

Epoch: 5| Step: 5
Training loss: 1.9446631883771668
Validation loss: 2.5888825869214704

Epoch: 5| Step: 6
Training loss: 2.7953556985006642
Validation loss: 2.5547661554860226

Epoch: 5| Step: 7
Training loss: 1.9399064409171176
Validation loss: 2.563942348996086

Epoch: 5| Step: 8
Training loss: 2.3325369588493543
Validation loss: 2.5591297291214885

Epoch: 5| Step: 9
Training loss: 3.052887603370133
Validation loss: 2.5257852484858034

Epoch: 5| Step: 10
Training loss: 2.897635541745733
Validation loss: 2.5560574804028255

Epoch: 270| Step: 0
Training loss: 1.9076059240526364
Validation loss: 2.53639151330253

Epoch: 5| Step: 1
Training loss: 2.8097216976724906
Validation loss: 2.60166282895168

Epoch: 5| Step: 2
Training loss: 2.401045086927867
Validation loss: 2.5509299556039453

Epoch: 5| Step: 3
Training loss: 2.053599254348554
Validation loss: 2.584164674892157

Epoch: 5| Step: 4
Training loss: 2.4674460915162006
Validation loss: 2.552605276537753

Epoch: 5| Step: 5
Training loss: 3.4135213811553156
Validation loss: 2.597204925660551

Epoch: 5| Step: 6
Training loss: 2.404828927663189
Validation loss: 2.547933439460269

Epoch: 5| Step: 7
Training loss: 2.857729078507097
Validation loss: 2.5726555096435217

Epoch: 5| Step: 8
Training loss: 2.504898993307875
Validation loss: 2.5569701425691327

Epoch: 5| Step: 9
Training loss: 2.9180159762849147
Validation loss: 2.5584659772773892

Epoch: 5| Step: 10
Training loss: 2.1839376598445757
Validation loss: 2.556983379978179

Epoch: 271| Step: 0
Training loss: 2.5569151518957645
Validation loss: 2.5656916572978994

Epoch: 5| Step: 1
Training loss: 2.9131749824012254
Validation loss: 2.5899533771507985

Epoch: 5| Step: 2
Training loss: 2.1436556781449
Validation loss: 2.5779548914559496

Epoch: 5| Step: 3
Training loss: 3.0743561729727897
Validation loss: 2.562394599937882

Epoch: 5| Step: 4
Training loss: 2.6387615061571883
Validation loss: 2.5639379005157656

Epoch: 5| Step: 5
Training loss: 2.148983639746689
Validation loss: 2.5809759516204354

Epoch: 5| Step: 6
Training loss: 2.7992522297038023
Validation loss: 2.579746224586448

Epoch: 5| Step: 7
Training loss: 2.2591173038228094
Validation loss: 2.5457559655348265

Epoch: 5| Step: 8
Training loss: 2.481181941792578
Validation loss: 2.558162847494559

Epoch: 5| Step: 9
Training loss: 2.2806289036373184
Validation loss: 2.560951267119261

Epoch: 5| Step: 10
Training loss: 2.8586431515186725
Validation loss: 2.5929902307299066

Epoch: 272| Step: 0
Training loss: 2.3788070282186493
Validation loss: 2.5533671679354537

Epoch: 5| Step: 1
Training loss: 2.471646119141865
Validation loss: 2.548213317973306

Epoch: 5| Step: 2
Training loss: 2.1429025826858847
Validation loss: 2.5558020842287004

Epoch: 5| Step: 3
Training loss: 1.8980595718778737
Validation loss: 2.5817222222260305

Epoch: 5| Step: 4
Training loss: 2.86558067761738
Validation loss: 2.539160766214544

Epoch: 5| Step: 5
Training loss: 2.1355850029321086
Validation loss: 2.581225447888177

Epoch: 5| Step: 6
Training loss: 2.3151986124679107
Validation loss: 2.5414992919015016

Epoch: 5| Step: 7
Training loss: 3.041804863564218
Validation loss: 2.566840577662737

Epoch: 5| Step: 8
Training loss: 2.583082761199977
Validation loss: 2.5633630107179015

Epoch: 5| Step: 9
Training loss: 3.26603761831415
Validation loss: 2.5693448317254446

Epoch: 5| Step: 10
Training loss: 2.633513495965999
Validation loss: 2.5407355337980744

Epoch: 273| Step: 0
Training loss: 1.9330552709603956
Validation loss: 2.5761125930883573

Epoch: 5| Step: 1
Training loss: 2.5871770832337253
Validation loss: 2.542413011574207

Epoch: 5| Step: 2
Training loss: 2.1882778419650584
Validation loss: 2.5415917790147917

Epoch: 5| Step: 3
Training loss: 2.8120872194647
Validation loss: 2.5604881024004733

Epoch: 5| Step: 4
Training loss: 1.560044610045896
Validation loss: 2.542097335255067

Epoch: 5| Step: 5
Training loss: 2.8548972501152856
Validation loss: 2.547174228423877

Epoch: 5| Step: 6
Training loss: 2.9267421718175672
Validation loss: 2.5745644950694957

Epoch: 5| Step: 7
Training loss: 2.853845471503271
Validation loss: 2.5447453137346128

Epoch: 5| Step: 8
Training loss: 2.69525703704824
Validation loss: 2.542721530629529

Epoch: 5| Step: 9
Training loss: 2.4251906801744636
Validation loss: 2.599198589546789

Epoch: 5| Step: 10
Training loss: 2.862871544059077
Validation loss: 2.5617031486166324

Epoch: 274| Step: 0
Training loss: 2.4316339576966826
Validation loss: 2.569199667611123

Epoch: 5| Step: 1
Training loss: 2.1104261251867134
Validation loss: 2.5577272818100947

Epoch: 5| Step: 2
Training loss: 2.9385935594334827
Validation loss: 2.5420500615593813

Epoch: 5| Step: 3
Training loss: 2.4869102162228267
Validation loss: 2.5566867094191115

Epoch: 5| Step: 4
Training loss: 2.456866866830713
Validation loss: 2.553442344092219

Epoch: 5| Step: 5
Training loss: 2.500359127952981
Validation loss: 2.549445817563712

Epoch: 5| Step: 6
Training loss: 3.1742287908156324
Validation loss: 2.548119596267499

Epoch: 5| Step: 7
Training loss: 2.6387176848528577
Validation loss: 2.5717959795343734

Epoch: 5| Step: 8
Training loss: 2.272336713004494
Validation loss: 2.5624963743842986

Epoch: 5| Step: 9
Training loss: 1.9365407353338953
Validation loss: 2.5732990887573832

Epoch: 5| Step: 10
Training loss: 2.889370042721149
Validation loss: 2.546036142819351

Epoch: 275| Step: 0
Training loss: 2.851168503388882
Validation loss: 2.5714324197961735

Epoch: 5| Step: 1
Training loss: 2.21706799433071
Validation loss: 2.55068884281422

Epoch: 5| Step: 2
Training loss: 2.5639373655777384
Validation loss: 2.560951555421686

Epoch: 5| Step: 3
Training loss: 2.578840769040743
Validation loss: 2.5436073145289813

Epoch: 5| Step: 4
Training loss: 2.019780569716594
Validation loss: 2.5377311564480687

Epoch: 5| Step: 5
Training loss: 2.5125146438399626
Validation loss: 2.570430359063074

Epoch: 5| Step: 6
Training loss: 2.8627372943188796
Validation loss: 2.580002466985832

Epoch: 5| Step: 7
Training loss: 3.3824495116396793
Validation loss: 2.5468954214705057

Epoch: 5| Step: 8
Training loss: 2.0509963149879713
Validation loss: 2.5575984574239916

Epoch: 5| Step: 9
Training loss: 2.470707563916467
Validation loss: 2.5834136861741674

Epoch: 5| Step: 10
Training loss: 2.160040578107797
Validation loss: 2.583031649312552

Epoch: 276| Step: 0
Training loss: 2.6030755669157926
Validation loss: 2.582972170511775

Epoch: 5| Step: 1
Training loss: 2.382637392707794
Validation loss: 2.579808414138006

Epoch: 5| Step: 2
Training loss: 2.1252035155732685
Validation loss: 2.569268372709441

Epoch: 5| Step: 3
Training loss: 2.0677606942748095
Validation loss: 2.540946504052036

Epoch: 5| Step: 4
Training loss: 2.659038022989261
Validation loss: 2.538843318796399

Epoch: 5| Step: 5
Training loss: 2.25199314422648
Validation loss: 2.5861473780275355

Epoch: 5| Step: 6
Training loss: 3.083770377312525
Validation loss: 2.5454075320877987

Epoch: 5| Step: 7
Training loss: 2.545396808799289
Validation loss: 2.5427881312199756

Epoch: 5| Step: 8
Training loss: 2.66563615159344
Validation loss: 2.559429694883231

Epoch: 5| Step: 9
Training loss: 3.1395304276519354
Validation loss: 2.5615706190309835

Epoch: 5| Step: 10
Training loss: 2.3356668066662882
Validation loss: 2.562464783089122

Epoch: 277| Step: 0
Training loss: 2.3774945058668897
Validation loss: 2.5730291176518874

Epoch: 5| Step: 1
Training loss: 2.876564097986808
Validation loss: 2.509524320622385

Epoch: 5| Step: 2
Training loss: 2.268962007395324
Validation loss: 2.5562876609348466

Epoch: 5| Step: 3
Training loss: 2.5089650580541414
Validation loss: 2.5475379095720947

Epoch: 5| Step: 4
Training loss: 2.511794117320362
Validation loss: 2.5878673074592395

Epoch: 5| Step: 5
Training loss: 2.1405037058972165
Validation loss: 2.5738869020458166

Epoch: 5| Step: 6
Training loss: 2.731738667015376
Validation loss: 2.5418018451034534

Epoch: 5| Step: 7
Training loss: 2.32581455359354
Validation loss: 2.5461954750004185

Epoch: 5| Step: 8
Training loss: 2.396581372674082
Validation loss: 2.5387527143056197

Epoch: 5| Step: 9
Training loss: 3.51722918044703
Validation loss: 2.520098800311017

Epoch: 5| Step: 10
Training loss: 2.279116115904451
Validation loss: 2.542879395937399

Epoch: 278| Step: 0
Training loss: 2.558680968217636
Validation loss: 2.537682882108093

Epoch: 5| Step: 1
Training loss: 2.8322583758600475
Validation loss: 2.56771589365964

Epoch: 5| Step: 2
Training loss: 2.243976264957286
Validation loss: 2.547362401161895

Epoch: 5| Step: 3
Training loss: 2.2865340814809487
Validation loss: 2.553482096922767

Epoch: 5| Step: 4
Training loss: 2.028129880925728
Validation loss: 2.5671512061166366

Epoch: 5| Step: 5
Training loss: 2.9020281243989086
Validation loss: 2.5618938061176073

Epoch: 5| Step: 6
Training loss: 2.7417532639514053
Validation loss: 2.5484688559984434

Epoch: 5| Step: 7
Training loss: 2.9118444269773316
Validation loss: 2.5329449102725086

Epoch: 5| Step: 8
Training loss: 2.687325139234399
Validation loss: 2.5332649513038414

Epoch: 5| Step: 9
Training loss: 2.08214587384552
Validation loss: 2.54118680399858

Epoch: 5| Step: 10
Training loss: 2.502188297031962
Validation loss: 2.538352882544233

Epoch: 279| Step: 0
Training loss: 3.224371879976896
Validation loss: 2.5623796196130555

Epoch: 5| Step: 1
Training loss: 2.7425987174420086
Validation loss: 2.5408806280511325

Epoch: 5| Step: 2
Training loss: 2.1538893451656844
Validation loss: 2.532201435477972

Epoch: 5| Step: 3
Training loss: 2.4260495539649343
Validation loss: 2.5402298145183524

Epoch: 5| Step: 4
Training loss: 2.120659940135513
Validation loss: 2.588487447069828

Epoch: 5| Step: 5
Training loss: 2.0412813588599326
Validation loss: 2.538713172123653

Epoch: 5| Step: 6
Training loss: 1.6772473730890318
Validation loss: 2.5537103331591475

Epoch: 5| Step: 7
Training loss: 2.7346304637918695
Validation loss: 2.5495075546571764

Epoch: 5| Step: 8
Training loss: 2.595569569845266
Validation loss: 2.55630882755708

Epoch: 5| Step: 9
Training loss: 3.225150845570571
Validation loss: 2.568790197810164

Epoch: 5| Step: 10
Training loss: 2.578681377139469
Validation loss: 2.5700758050708625

Epoch: 280| Step: 0
Training loss: 2.1937639197970284
Validation loss: 2.5527917434152845

Epoch: 5| Step: 1
Training loss: 2.6209835933272223
Validation loss: 2.568155098860263

Epoch: 5| Step: 2
Training loss: 2.7529878857142034
Validation loss: 2.5654084182546404

Epoch: 5| Step: 3
Training loss: 3.1516206235731548
Validation loss: 2.579065181649239

Epoch: 5| Step: 4
Training loss: 2.5231647166862725
Validation loss: 2.56741198774653

Epoch: 5| Step: 5
Training loss: 2.697064612520228
Validation loss: 2.5721837292181524

Epoch: 5| Step: 6
Training loss: 2.0211248548051004
Validation loss: 2.566348301858602

Epoch: 5| Step: 7
Training loss: 2.4678190383351124
Validation loss: 2.592986475716074

Epoch: 5| Step: 8
Training loss: 2.546786815778261
Validation loss: 2.549532162197857

Epoch: 5| Step: 9
Training loss: 2.2499589916306864
Validation loss: 2.5645205047600017

Epoch: 5| Step: 10
Training loss: 2.574919308629567
Validation loss: 2.5948316451461295

Epoch: 281| Step: 0
Training loss: 2.674144650902908
Validation loss: 2.557460326144645

Epoch: 5| Step: 1
Training loss: 2.658789015870629
Validation loss: 2.5695499810522286

Epoch: 5| Step: 2
Training loss: 2.8320733428983904
Validation loss: 2.6218506295314077

Epoch: 5| Step: 3
Training loss: 2.5928379891328777
Validation loss: 2.5675248252688614

Epoch: 5| Step: 4
Training loss: 2.6285961586073214
Validation loss: 2.566494153663887

Epoch: 5| Step: 5
Training loss: 2.219415484279118
Validation loss: 2.560741955998254

Epoch: 5| Step: 6
Training loss: 2.1851911076263706
Validation loss: 2.582108449040146

Epoch: 5| Step: 7
Training loss: 2.200652012874548
Validation loss: 2.563911570933585

Epoch: 5| Step: 8
Training loss: 2.604220844976789
Validation loss: 2.5761429069340966

Epoch: 5| Step: 9
Training loss: 2.6795999495993015
Validation loss: 2.5640746160175962

Epoch: 5| Step: 10
Training loss: 2.6067980073521717
Validation loss: 2.590499428425719

Epoch: 282| Step: 0
Training loss: 3.0241028203993277
Validation loss: 2.5565322497912017

Epoch: 5| Step: 1
Training loss: 2.1541935056370876
Validation loss: 2.5602742294776957

Epoch: 5| Step: 2
Training loss: 2.6153206159347464
Validation loss: 2.5751771871294356

Epoch: 5| Step: 3
Training loss: 2.603904792334294
Validation loss: 2.571426470870101

Epoch: 5| Step: 4
Training loss: 2.414501952631278
Validation loss: 2.5434544322869845

Epoch: 5| Step: 5
Training loss: 2.542924027994564
Validation loss: 2.5502220942602856

Epoch: 5| Step: 6
Training loss: 2.924293374024864
Validation loss: 2.531594488335338

Epoch: 5| Step: 7
Training loss: 2.6280226788463996
Validation loss: 2.5596985088335913

Epoch: 5| Step: 8
Training loss: 1.978659922994876
Validation loss: 2.5496163843136364

Epoch: 5| Step: 9
Training loss: 2.7346876565111264
Validation loss: 2.5763203708420974

Epoch: 5| Step: 10
Training loss: 2.293902699223718
Validation loss: 2.573508556037074

Epoch: 283| Step: 0
Training loss: 2.45339225722469
Validation loss: 2.5692130844826933

Epoch: 5| Step: 1
Training loss: 2.0642193650176965
Validation loss: 2.56373083216364

Epoch: 5| Step: 2
Training loss: 2.9315446587599023
Validation loss: 2.5554395852281995

Epoch: 5| Step: 3
Training loss: 2.851628383763725
Validation loss: 2.561544811062387

Epoch: 5| Step: 4
Training loss: 3.015785331614609
Validation loss: 2.5254508935093054

Epoch: 5| Step: 5
Training loss: 2.33058507605331
Validation loss: 2.5753870043520375

Epoch: 5| Step: 6
Training loss: 3.1333929651416246
Validation loss: 2.532425361818396

Epoch: 5| Step: 7
Training loss: 2.429014155560609
Validation loss: 2.5662203488069637

Epoch: 5| Step: 8
Training loss: 2.2031991283309753
Validation loss: 2.548580092891774

Epoch: 5| Step: 9
Training loss: 1.6800736094424975
Validation loss: 2.5527135302373

Epoch: 5| Step: 10
Training loss: 2.3632105288682306
Validation loss: 2.5615234765322348

Epoch: 284| Step: 0
Training loss: 2.583767536548589
Validation loss: 2.5533514207823536

Epoch: 5| Step: 1
Training loss: 1.7614779762452664
Validation loss: 2.5737725572549257

Epoch: 5| Step: 2
Training loss: 3.066249809405091
Validation loss: 2.5511450429969633

Epoch: 5| Step: 3
Training loss: 2.243225389106451
Validation loss: 2.547377323872532

Epoch: 5| Step: 4
Training loss: 2.9918292356504854
Validation loss: 2.521332023214898

Epoch: 5| Step: 5
Training loss: 2.944584359337557
Validation loss: 2.539171673342077

Epoch: 5| Step: 6
Training loss: 2.777400921583239
Validation loss: 2.5316427258626377

Epoch: 5| Step: 7
Training loss: 2.877224932000655
Validation loss: 2.5679997537099304

Epoch: 5| Step: 8
Training loss: 1.429911444796396
Validation loss: 2.5490793955069804

Epoch: 5| Step: 9
Training loss: 2.5851597840972933
Validation loss: 2.5494969039186524

Epoch: 5| Step: 10
Training loss: 2.0324393678374633
Validation loss: 2.5395097468320023

Epoch: 285| Step: 0
Training loss: 2.3923889832763914
Validation loss: 2.578322217153048

Epoch: 5| Step: 1
Training loss: 2.9480367755122985
Validation loss: 2.572375959421871

Epoch: 5| Step: 2
Training loss: 2.400180344958265
Validation loss: 2.5619450890481588

Epoch: 5| Step: 3
Training loss: 2.0749629925104895
Validation loss: 2.565943931055703

Epoch: 5| Step: 4
Training loss: 2.2440262010850063
Validation loss: 2.541137469423447

Epoch: 5| Step: 5
Training loss: 3.4570425604511303
Validation loss: 2.539599051377209

Epoch: 5| Step: 6
Training loss: 2.18127318099419
Validation loss: 2.568882895932339

Epoch: 5| Step: 7
Training loss: 1.963994777486038
Validation loss: 2.572031145149566

Epoch: 5| Step: 8
Training loss: 2.5110190738514127
Validation loss: 2.561777078423543

Epoch: 5| Step: 9
Training loss: 2.587552306895064
Validation loss: 2.5747584084566326

Epoch: 5| Step: 10
Training loss: 2.5217781398092254
Validation loss: 2.529531049417632

Epoch: 286| Step: 0
Training loss: 2.6252483068827086
Validation loss: 2.5963510083006245

Epoch: 5| Step: 1
Training loss: 2.495909682577718
Validation loss: 2.582374750342272

Epoch: 5| Step: 2
Training loss: 2.900489594797121
Validation loss: 2.5273449200659193

Epoch: 5| Step: 3
Training loss: 2.0469115741752684
Validation loss: 2.560781242117608

Epoch: 5| Step: 4
Training loss: 2.300642595501067
Validation loss: 2.550811676440415

Epoch: 5| Step: 5
Training loss: 3.0129317674630776
Validation loss: 2.5653793231523423

Epoch: 5| Step: 6
Training loss: 2.5610545664034468
Validation loss: 2.5560142130544756

Epoch: 5| Step: 7
Training loss: 1.8768183474226834
Validation loss: 2.588110260020013

Epoch: 5| Step: 8
Training loss: 2.147222667900764
Validation loss: 2.539397019782952

Epoch: 5| Step: 9
Training loss: 2.3716232990509516
Validation loss: 2.5498124252488914

Epoch: 5| Step: 10
Training loss: 2.9870919048626043
Validation loss: 2.5304064968883297

Epoch: 287| Step: 0
Training loss: 2.163264268537764
Validation loss: 2.581618006153041

Epoch: 5| Step: 1
Training loss: 2.527788974984024
Validation loss: 2.579480874863551

Epoch: 5| Step: 2
Training loss: 2.929767251518675
Validation loss: 2.5735119011589074

Epoch: 5| Step: 3
Training loss: 2.912828117519452
Validation loss: 2.56096927694908

Epoch: 5| Step: 4
Training loss: 2.6220273943182164
Validation loss: 2.5660956522526535

Epoch: 5| Step: 5
Training loss: 2.0447276259071643
Validation loss: 2.564695307806187

Epoch: 5| Step: 6
Training loss: 2.845294574846578
Validation loss: 2.585211396841395

Epoch: 5| Step: 7
Training loss: 2.5958417248373395
Validation loss: 2.5886423322435506

Epoch: 5| Step: 8
Training loss: 2.2508856831573163
Validation loss: 2.5920795330095157

Epoch: 5| Step: 9
Training loss: 2.660655508370524
Validation loss: 2.5767720649758674

Epoch: 5| Step: 10
Training loss: 2.162105294958605
Validation loss: 2.6002069777794903

Epoch: 288| Step: 0
Training loss: 2.298457839429784
Validation loss: 2.5842589325497496

Epoch: 5| Step: 1
Training loss: 2.1657780756939844
Validation loss: 2.573408514164509

Epoch: 5| Step: 2
Training loss: 2.1663130202594467
Validation loss: 2.581684558097822

Epoch: 5| Step: 3
Training loss: 2.9266675515778173
Validation loss: 2.5710222336774753

Epoch: 5| Step: 4
Training loss: 2.500257288091134
Validation loss: 2.5542858739205063

Epoch: 5| Step: 5
Training loss: 2.3416107587373634
Validation loss: 2.5638807370068077

Epoch: 5| Step: 6
Training loss: 2.2890269826796064
Validation loss: 2.568106182533177

Epoch: 5| Step: 7
Training loss: 1.6888916493833859
Validation loss: 2.580511743563409

Epoch: 5| Step: 8
Training loss: 3.159286247236863
Validation loss: 2.559602336144313

Epoch: 5| Step: 9
Training loss: 2.3309134355441525
Validation loss: 2.5387825830990067

Epoch: 5| Step: 10
Training loss: 3.568017000457223
Validation loss: 2.5896178371143193

Epoch: 289| Step: 0
Training loss: 2.104041357054572
Validation loss: 2.553697927073963

Epoch: 5| Step: 1
Training loss: 1.7321035271113536
Validation loss: 2.5493462442951227

Epoch: 5| Step: 2
Training loss: 2.197826100392367
Validation loss: 2.563339398052068

Epoch: 5| Step: 3
Training loss: 3.1848738080331698
Validation loss: 2.5596661508723373

Epoch: 5| Step: 4
Training loss: 2.9570339913399613
Validation loss: 2.53871508371018

Epoch: 5| Step: 5
Training loss: 2.235214609172922
Validation loss: 2.5417564035998685

Epoch: 5| Step: 6
Training loss: 2.7139704994504283
Validation loss: 2.551146389559972

Epoch: 5| Step: 7
Training loss: 2.5003934550615723
Validation loss: 2.563629933727999

Epoch: 5| Step: 8
Training loss: 3.013410951267394
Validation loss: 2.5657175254717473

Epoch: 5| Step: 9
Training loss: 2.481932392979372
Validation loss: 2.560161312716018

Epoch: 5| Step: 10
Training loss: 2.0961714449717816
Validation loss: 2.550364442383139

Epoch: 290| Step: 0
Training loss: 2.2056580178872056
Validation loss: 2.5242201602453864

Epoch: 5| Step: 1
Training loss: 2.5120680404486957
Validation loss: 2.5682454821059006

Epoch: 5| Step: 2
Training loss: 2.1860331385579532
Validation loss: 2.5378429425288713

Epoch: 5| Step: 3
Training loss: 2.458406727444164
Validation loss: 2.5399608482451743

Epoch: 5| Step: 4
Training loss: 2.1940526639378026
Validation loss: 2.5663671309025933

Epoch: 5| Step: 5
Training loss: 3.6724917928605274
Validation loss: 2.563393557843954

Epoch: 5| Step: 6
Training loss: 2.129233910779641
Validation loss: 2.6023600878563937

Epoch: 5| Step: 7
Training loss: 2.886076446641595
Validation loss: 2.5786575637407974

Epoch: 5| Step: 8
Training loss: 2.3912991838437136
Validation loss: 2.566398283581667

Epoch: 5| Step: 9
Training loss: 2.217857503704483
Validation loss: 2.5853201291496495

Epoch: 5| Step: 10
Training loss: 2.4745506032755498
Validation loss: 2.5495624879098635

Epoch: 291| Step: 0
Training loss: 1.5672074929936946
Validation loss: 2.5499686803227464

Epoch: 5| Step: 1
Training loss: 2.4609215145500163
Validation loss: 2.5525529427292803

Epoch: 5| Step: 2
Training loss: 2.425783805415824
Validation loss: 2.5713252183767303

Epoch: 5| Step: 3
Training loss: 2.971962565867868
Validation loss: 2.5471114856557855

Epoch: 5| Step: 4
Training loss: 3.0545267126201976
Validation loss: 2.550196740428546

Epoch: 5| Step: 5
Training loss: 2.5455533208198493
Validation loss: 2.546953115668861

Epoch: 5| Step: 6
Training loss: 3.1268436334086305
Validation loss: 2.5360598182335097

Epoch: 5| Step: 7
Training loss: 2.4654407775672995
Validation loss: 2.562929669165315

Epoch: 5| Step: 8
Training loss: 2.280145456124768
Validation loss: 2.548503410259769

Epoch: 5| Step: 9
Training loss: 2.434394423048618
Validation loss: 2.5567140564526234

Epoch: 5| Step: 10
Training loss: 2.082337433879917
Validation loss: 2.531845283064669

Epoch: 292| Step: 0
Training loss: 2.8841799255730587
Validation loss: 2.5833497574516

Epoch: 5| Step: 1
Training loss: 3.0107128873148548
Validation loss: 2.559132524037817

Epoch: 5| Step: 2
Training loss: 2.7022656965714793
Validation loss: 2.5490308040515366

Epoch: 5| Step: 3
Training loss: 2.123602800482597
Validation loss: 2.556395742653991

Epoch: 5| Step: 4
Training loss: 3.03316916835468
Validation loss: 2.570077484853774

Epoch: 5| Step: 5
Training loss: 1.8619454191835363
Validation loss: 2.5466808690769955

Epoch: 5| Step: 6
Training loss: 2.149690796552488
Validation loss: 2.5537916107005736

Epoch: 5| Step: 7
Training loss: 2.5752795613944395
Validation loss: 2.533855676542525

Epoch: 5| Step: 8
Training loss: 2.0570208278671602
Validation loss: 2.5519046669843326

Epoch: 5| Step: 9
Training loss: 2.48822318447998
Validation loss: 2.5801654615300693

Epoch: 5| Step: 10
Training loss: 2.4757774865798057
Validation loss: 2.556622471367304

Epoch: 293| Step: 0
Training loss: 2.664365063263316
Validation loss: 2.5212061772483314

Epoch: 5| Step: 1
Training loss: 2.7043661454445678
Validation loss: 2.542865998404584

Epoch: 5| Step: 2
Training loss: 3.0837556876202394
Validation loss: 2.5459476365197617

Epoch: 5| Step: 3
Training loss: 2.165226151810167
Validation loss: 2.5574788838154743

Epoch: 5| Step: 4
Training loss: 2.2381872986253915
Validation loss: 2.5530791575920526

Epoch: 5| Step: 5
Training loss: 3.018625772577748
Validation loss: 2.545514569121186

Epoch: 5| Step: 6
Training loss: 1.735020972573114
Validation loss: 2.586791037403399

Epoch: 5| Step: 7
Training loss: 2.561731735061631
Validation loss: 2.5841807640349277

Epoch: 5| Step: 8
Training loss: 2.418779523802371
Validation loss: 2.5654384233887235

Epoch: 5| Step: 9
Training loss: 2.6204930624852736
Validation loss: 2.569073669730313

Epoch: 5| Step: 10
Training loss: 2.315563235057626
Validation loss: 2.5973349411448123

Epoch: 294| Step: 0
Training loss: 2.5716680876883906
Validation loss: 2.5591986514687424

Epoch: 5| Step: 1
Training loss: 2.101159720129488
Validation loss: 2.5974268524928594

Epoch: 5| Step: 2
Training loss: 2.5219250566508764
Validation loss: 2.5756055914867693

Epoch: 5| Step: 3
Training loss: 2.766824235986854
Validation loss: 2.584723810579451

Epoch: 5| Step: 4
Training loss: 3.048582566884856
Validation loss: 2.5631703626170315

Epoch: 5| Step: 5
Training loss: 2.2383381302082226
Validation loss: 2.5729767887550206

Epoch: 5| Step: 6
Training loss: 2.278441699375609
Validation loss: 2.5533515076309206

Epoch: 5| Step: 7
Training loss: 2.4636799381693306
Validation loss: 2.586694134631499

Epoch: 5| Step: 8
Training loss: 2.416295472500167
Validation loss: 2.547294612329929

Epoch: 5| Step: 9
Training loss: 2.8151013529878446
Validation loss: 2.567891536434467

Epoch: 5| Step: 10
Training loss: 2.190372869372876
Validation loss: 2.581573517739261

Epoch: 295| Step: 0
Training loss: 2.461067995517058
Validation loss: 2.5475514344890544

Epoch: 5| Step: 1
Training loss: 2.6853808542432906
Validation loss: 2.5358250406384353

Epoch: 5| Step: 2
Training loss: 1.6557977166814504
Validation loss: 2.5282908220281173

Epoch: 5| Step: 3
Training loss: 2.269609197174251
Validation loss: 2.550161540596728

Epoch: 5| Step: 4
Training loss: 2.698237062574304
Validation loss: 2.566361521861811

Epoch: 5| Step: 5
Training loss: 2.6528857299604947
Validation loss: 2.5601015088538457

Epoch: 5| Step: 6
Training loss: 2.9788233063418303
Validation loss: 2.574507747248024

Epoch: 5| Step: 7
Training loss: 2.5840193442633317
Validation loss: 2.5493973185671552

Epoch: 5| Step: 8
Training loss: 2.9056633798186
Validation loss: 2.5360105416196017

Epoch: 5| Step: 9
Training loss: 2.065250296952527
Validation loss: 2.5246114095348524

Epoch: 5| Step: 10
Training loss: 2.3491396160898077
Validation loss: 2.5423218682632593

Epoch: 296| Step: 0
Training loss: 2.3115339581113563
Validation loss: 2.5284534351284247

Epoch: 5| Step: 1
Training loss: 2.306111144974603
Validation loss: 2.5702620936866842

Epoch: 5| Step: 2
Training loss: 2.4569447900937056
Validation loss: 2.5470292078468284

Epoch: 5| Step: 3
Training loss: 2.702200759144018
Validation loss: 2.5651579317428084

Epoch: 5| Step: 4
Training loss: 1.8554610402800351
Validation loss: 2.5561166246671516

Epoch: 5| Step: 5
Training loss: 2.408070754770143
Validation loss: 2.5629537527312105

Epoch: 5| Step: 6
Training loss: 2.6011997462582688
Validation loss: 2.584711260757463

Epoch: 5| Step: 7
Training loss: 2.860667452523236
Validation loss: 2.522829550013523

Epoch: 5| Step: 8
Training loss: 2.661822050937924
Validation loss: 2.526333319358433

Epoch: 5| Step: 9
Training loss: 2.168890020154352
Validation loss: 2.558626384036962

Epoch: 5| Step: 10
Training loss: 3.214970267530628
Validation loss: 2.561469734586645

Epoch: 297| Step: 0
Training loss: 2.5380851860089306
Validation loss: 2.54295731779103

Epoch: 5| Step: 1
Training loss: 2.667867410056047
Validation loss: 2.565883295816187

Epoch: 5| Step: 2
Training loss: 2.4041530835733758
Validation loss: 2.5689005587536733

Epoch: 5| Step: 3
Training loss: 2.359778464474516
Validation loss: 2.5606842370863783

Epoch: 5| Step: 4
Training loss: 2.344869422611916
Validation loss: 2.5558592202904147

Epoch: 5| Step: 5
Training loss: 2.5450984633009246
Validation loss: 2.575554564132461

Epoch: 5| Step: 6
Training loss: 2.652364604345482
Validation loss: 2.587871806934777

Epoch: 5| Step: 7
Training loss: 2.589860688811499
Validation loss: 2.5397447541235945

Epoch: 5| Step: 8
Training loss: 2.8818092978373087
Validation loss: 2.589934029656953

Epoch: 5| Step: 9
Training loss: 2.046310230410343
Validation loss: 2.567274943688033

Epoch: 5| Step: 10
Training loss: 2.7250873761648733
Validation loss: 2.561764544281606

Epoch: 298| Step: 0
Training loss: 2.0823429296638896
Validation loss: 2.5278683213891626

Epoch: 5| Step: 1
Training loss: 3.0965994611276817
Validation loss: 2.594267729113784

Epoch: 5| Step: 2
Training loss: 2.7743693760700805
Validation loss: 2.5632725463250954

Epoch: 5| Step: 3
Training loss: 2.1866697643227075
Validation loss: 2.564062661013499

Epoch: 5| Step: 4
Training loss: 2.3572096835815444
Validation loss: 2.551483595802687

Epoch: 5| Step: 5
Training loss: 1.72219489530534
Validation loss: 2.556520455059993

Epoch: 5| Step: 6
Training loss: 2.3772432875803746
Validation loss: 2.5812184101525455

Epoch: 5| Step: 7
Training loss: 2.7441592178529377
Validation loss: 2.5531925954142145

Epoch: 5| Step: 8
Training loss: 2.303806356319253
Validation loss: 2.5303194215959834

Epoch: 5| Step: 9
Training loss: 2.7282260312384046
Validation loss: 2.5505135291158707

Epoch: 5| Step: 10
Training loss: 3.0422161772972642
Validation loss: 2.5792827434230663

Epoch: 299| Step: 0
Training loss: 2.1038621990636472
Validation loss: 2.5521851406086684

Epoch: 5| Step: 1
Training loss: 2.3335526454129063
Validation loss: 2.583365371365181

Epoch: 5| Step: 2
Training loss: 2.9303986767023606
Validation loss: 2.53283838356278

Epoch: 5| Step: 3
Training loss: 2.451325357806805
Validation loss: 2.5316693449690417

Epoch: 5| Step: 4
Training loss: 2.1777927271120094
Validation loss: 2.5806022975358753

Epoch: 5| Step: 5
Training loss: 2.2118165118872497
Validation loss: 2.564648985444537

Epoch: 5| Step: 6
Training loss: 2.648936086889515
Validation loss: 2.5520291980445475

Epoch: 5| Step: 7
Training loss: 2.250902736553725
Validation loss: 2.558862554086088

Epoch: 5| Step: 8
Training loss: 2.573428598561089
Validation loss: 2.544466826013918

Epoch: 5| Step: 9
Training loss: 3.490107862232147
Validation loss: 2.5311011267194634

Epoch: 5| Step: 10
Training loss: 2.285803026792755
Validation loss: 2.5440826741088376

Epoch: 300| Step: 0
Training loss: 2.508908801638466
Validation loss: 2.5514555536707313

Epoch: 5| Step: 1
Training loss: 2.286857610669241
Validation loss: 2.5374289463436033

Epoch: 5| Step: 2
Training loss: 2.1726759936091637
Validation loss: 2.5554121392820885

Epoch: 5| Step: 3
Training loss: 2.596504862603935
Validation loss: 2.5757965192838896

Epoch: 5| Step: 4
Training loss: 2.2738458325709536
Validation loss: 2.535262279896195

Epoch: 5| Step: 5
Training loss: 2.729652206288809
Validation loss: 2.586067289887255

Epoch: 5| Step: 6
Training loss: 3.250007629385576
Validation loss: 2.5665168742735163

Epoch: 5| Step: 7
Training loss: 2.7116623494825673
Validation loss: 2.5690736407916415

Epoch: 5| Step: 8
Training loss: 2.6412946766054994
Validation loss: 2.558329975152291

Epoch: 5| Step: 9
Training loss: 2.0120740261983046
Validation loss: 2.5425828623570816

Epoch: 5| Step: 10
Training loss: 2.1410691294799227
Validation loss: 2.5842104668808763

Epoch: 301| Step: 0
Training loss: 2.5577475043761804
Validation loss: 2.54244886217602

Epoch: 5| Step: 1
Training loss: 2.5148390021846687
Validation loss: 2.5783008544052617

Epoch: 5| Step: 2
Training loss: 2.433155589819027
Validation loss: 2.6155158821607825

Epoch: 5| Step: 3
Training loss: 2.457937488906367
Validation loss: 2.5742601827052294

Epoch: 5| Step: 4
Training loss: 2.803706430546491
Validation loss: 2.5668714379571034

Epoch: 5| Step: 5
Training loss: 2.0917707739019917
Validation loss: 2.5627232946254836

Epoch: 5| Step: 6
Training loss: 2.41574729224954
Validation loss: 2.574752458254047

Epoch: 5| Step: 7
Training loss: 2.2412416809234004
Validation loss: 2.5743943852759243

Epoch: 5| Step: 8
Training loss: 2.744860441346383
Validation loss: 2.5825973802802626

Epoch: 5| Step: 9
Training loss: 2.737312003869994
Validation loss: 2.5541506644737355

Epoch: 5| Step: 10
Training loss: 2.7517113995704343
Validation loss: 2.5591234701006598

Epoch: 302| Step: 0
Training loss: 3.115412232873413
Validation loss: 2.5865521574279007

Epoch: 5| Step: 1
Training loss: 2.5401337696504305
Validation loss: 2.5416413186065254

Epoch: 5| Step: 2
Training loss: 2.388220082286804
Validation loss: 2.5514292886977668

Epoch: 5| Step: 3
Training loss: 2.342024816725259
Validation loss: 2.589116731806781

Epoch: 5| Step: 4
Training loss: 2.8139282838457693
Validation loss: 2.576989244344791

Epoch: 5| Step: 5
Training loss: 2.364560725122222
Validation loss: 2.578505756481027

Epoch: 5| Step: 6
Training loss: 2.4907512292978558
Validation loss: 2.523334692709747

Epoch: 5| Step: 7
Training loss: 2.3956223657575135
Validation loss: 2.563913624215764

Epoch: 5| Step: 8
Training loss: 2.317783403073819
Validation loss: 2.5777199564660473

Epoch: 5| Step: 9
Training loss: 2.4126586782817383
Validation loss: 2.5582899238719765

Epoch: 5| Step: 10
Training loss: 2.5053286982837384
Validation loss: 2.562445396123693

Epoch: 303| Step: 0
Training loss: 2.1181469534521105
Validation loss: 2.5794052122516447

Epoch: 5| Step: 1
Training loss: 3.0796964864923906
Validation loss: 2.570942430216833

Epoch: 5| Step: 2
Training loss: 2.577654616475679
Validation loss: 2.578801765997779

Epoch: 5| Step: 3
Training loss: 2.544425675916605
Validation loss: 2.5579879969246995

Epoch: 5| Step: 4
Training loss: 2.662309265468608
Validation loss: 2.5684879810567605

Epoch: 5| Step: 5
Training loss: 2.3024920852972426
Validation loss: 2.5651074501234374

Epoch: 5| Step: 6
Training loss: 2.292835758128179
Validation loss: 2.553756697332247

Epoch: 5| Step: 7
Training loss: 2.563707950866562
Validation loss: 2.6016062504614568

Epoch: 5| Step: 8
Training loss: 2.1799053780555226
Validation loss: 2.574407747191633

Epoch: 5| Step: 9
Training loss: 2.51294703136381
Validation loss: 2.561662569627661

Epoch: 5| Step: 10
Training loss: 2.262180103427448
Validation loss: 2.5299637115358538

Epoch: 304| Step: 0
Training loss: 2.544665542539662
Validation loss: 2.5575850838693253

Epoch: 5| Step: 1
Training loss: 2.7859270866914017
Validation loss: 2.5686760824927872

Epoch: 5| Step: 2
Training loss: 2.289150405601994
Validation loss: 2.57043832545196

Epoch: 5| Step: 3
Training loss: 1.929995678219873
Validation loss: 2.5687668266490786

Epoch: 5| Step: 4
Training loss: 1.6723354097814342
Validation loss: 2.5872706703148105

Epoch: 5| Step: 5
Training loss: 3.0926874050632747
Validation loss: 2.572045404440841

Epoch: 5| Step: 6
Training loss: 2.300969736250856
Validation loss: 2.589817541742107

Epoch: 5| Step: 7
Training loss: 2.3546607812733757
Validation loss: 2.5870895919864285

Epoch: 5| Step: 8
Training loss: 2.6803157503673853
Validation loss: 2.581742618289635

Epoch: 5| Step: 9
Training loss: 3.1964553990193454
Validation loss: 2.5361913923920207

Epoch: 5| Step: 10
Training loss: 2.1399289969670834
Validation loss: 2.572904765036091

Epoch: 305| Step: 0
Training loss: 2.5439841122880895
Validation loss: 2.5447872383976713

Epoch: 5| Step: 1
Training loss: 2.54916381963808
Validation loss: 2.5663358170144464

Epoch: 5| Step: 2
Training loss: 2.522194192910794
Validation loss: 2.555185971376404

Epoch: 5| Step: 3
Training loss: 2.7299110814519723
Validation loss: 2.569158475601487

Epoch: 5| Step: 4
Training loss: 1.9683798790234905
Validation loss: 2.5429021400259244

Epoch: 5| Step: 5
Training loss: 3.33774719465828
Validation loss: 2.5410995079233194

Epoch: 5| Step: 6
Training loss: 2.1807226642092297
Validation loss: 2.5685566672643727

Epoch: 5| Step: 7
Training loss: 2.4060026760070583
Validation loss: 2.5341624473206483

Epoch: 5| Step: 8
Training loss: 2.244330150014838
Validation loss: 2.5548106992950483

Epoch: 5| Step: 9
Training loss: 2.2659651928389084
Validation loss: 2.5766898328647136

Epoch: 5| Step: 10
Training loss: 2.782712401914287
Validation loss: 2.5725849468020234

Epoch: 306| Step: 0
Training loss: 2.1900989896793996
Validation loss: 2.5347605084052383

Epoch: 5| Step: 1
Training loss: 2.127434626111671
Validation loss: 2.5663568488172266

Epoch: 5| Step: 2
Training loss: 2.390428123595166
Validation loss: 2.56550133050244

Epoch: 5| Step: 3
Training loss: 3.113355073328783
Validation loss: 2.5991967451283946

Epoch: 5| Step: 4
Training loss: 2.330097668446697
Validation loss: 2.6004966378653176

Epoch: 5| Step: 5
Training loss: 2.810630346441157
Validation loss: 2.5958834010171046

Epoch: 5| Step: 6
Training loss: 3.304849390704402
Validation loss: 2.5733656062912558

Epoch: 5| Step: 7
Training loss: 2.1313380919566334
Validation loss: 2.5589483134889726

Epoch: 5| Step: 8
Training loss: 2.0710391514796793
Validation loss: 2.5404679611804037

Epoch: 5| Step: 9
Training loss: 2.203118506888703
Validation loss: 2.5633390960165596

Epoch: 5| Step: 10
Training loss: 2.183400918433826
Validation loss: 2.5815662624801434

Epoch: 307| Step: 0
Training loss: 2.393459559417526
Validation loss: 2.5605750087970436

Epoch: 5| Step: 1
Training loss: 2.8989267270531767
Validation loss: 2.564495626177885

Epoch: 5| Step: 2
Training loss: 1.8572829201564205
Validation loss: 2.5441307635310078

Epoch: 5| Step: 3
Training loss: 2.9369222194514975
Validation loss: 2.5784530555227763

Epoch: 5| Step: 4
Training loss: 2.4932453457543997
Validation loss: 2.5563165997732176

Epoch: 5| Step: 5
Training loss: 2.148373800547158
Validation loss: 2.5536530074662425

Epoch: 5| Step: 6
Training loss: 2.4566625855238136
Validation loss: 2.5883755996553943

Epoch: 5| Step: 7
Training loss: 2.638675037441434
Validation loss: 2.5761227506522966

Epoch: 5| Step: 8
Training loss: 2.303238131722045
Validation loss: 2.55505817573221

Epoch: 5| Step: 9
Training loss: 3.0619663629957916
Validation loss: 2.5761649737245866

Epoch: 5| Step: 10
Training loss: 1.9689746304684748
Validation loss: 2.5396089708822163

Epoch: 308| Step: 0
Training loss: 3.059250645355558
Validation loss: 2.577811359856088

Epoch: 5| Step: 1
Training loss: 2.457836510406998
Validation loss: 2.5602843167037395

Epoch: 5| Step: 2
Training loss: 1.6985391595170727
Validation loss: 2.577548314365582

Epoch: 5| Step: 3
Training loss: 2.5604010568820113
Validation loss: 2.57107293120068

Epoch: 5| Step: 4
Training loss: 2.614431541464351
Validation loss: 2.5664779456533435

Epoch: 5| Step: 5
Training loss: 2.0716737122951683
Validation loss: 2.5842628678963706

Epoch: 5| Step: 6
Training loss: 2.3577751141536205
Validation loss: 2.5280589736069308

Epoch: 5| Step: 7
Training loss: 2.613593888220342
Validation loss: 2.583081451134907

Epoch: 5| Step: 8
Training loss: 2.486891713360663
Validation loss: 2.5196352716613615

Epoch: 5| Step: 9
Training loss: 2.634733229565947
Validation loss: 2.545604226973826

Epoch: 5| Step: 10
Training loss: 2.5237119543146815
Validation loss: 2.5602694552039846

Epoch: 309| Step: 0
Training loss: 2.649753929805424
Validation loss: 2.54391122539717

Epoch: 5| Step: 1
Training loss: 2.0219907559448598
Validation loss: 2.554538111931722

Epoch: 5| Step: 2
Training loss: 2.1586155838195222
Validation loss: 2.5712088590263855

Epoch: 5| Step: 3
Training loss: 2.9735728390914393
Validation loss: 2.583239627756874

Epoch: 5| Step: 4
Training loss: 2.6992995695830646
Validation loss: 2.5373648057420124

Epoch: 5| Step: 5
Training loss: 2.4471640112895243
Validation loss: 2.5454258719588756

Epoch: 5| Step: 6
Training loss: 2.404181346705248
Validation loss: 2.5746218709446564

Epoch: 5| Step: 7
Training loss: 2.993578555109719
Validation loss: 2.5473212404752945

Epoch: 5| Step: 8
Training loss: 1.7967737583995629
Validation loss: 2.5875853722733684

Epoch: 5| Step: 9
Training loss: 2.307282722633771
Validation loss: 2.5356853926491434

Epoch: 5| Step: 10
Training loss: 2.6660218850086763
Validation loss: 2.541153790636097

Epoch: 310| Step: 0
Training loss: 2.724260030247176
Validation loss: 2.5351295016620283

Epoch: 5| Step: 1
Training loss: 2.2386128178349756
Validation loss: 2.553573773556259

Epoch: 5| Step: 2
Training loss: 2.0144671285962508
Validation loss: 2.5845618196618436

Epoch: 5| Step: 3
Training loss: 2.3510286352506027
Validation loss: 2.5459440829925852

Epoch: 5| Step: 4
Training loss: 2.2674988462535612
Validation loss: 2.5693880112856715

Epoch: 5| Step: 5
Training loss: 2.7377957119017156
Validation loss: 2.550272069351508

Epoch: 5| Step: 6
Training loss: 2.696243081258599
Validation loss: 2.558024243589682

Epoch: 5| Step: 7
Training loss: 2.0445667093224493
Validation loss: 2.5508196412856856

Epoch: 5| Step: 8
Training loss: 2.792345353559864
Validation loss: 2.539211564780119

Epoch: 5| Step: 9
Training loss: 2.7309425826963354
Validation loss: 2.5855369048155676

Epoch: 5| Step: 10
Training loss: 2.5545836261315014
Validation loss: 2.5506326040730967

Epoch: 311| Step: 0
Training loss: 2.6529110735768437
Validation loss: 2.5577446868979954

Epoch: 5| Step: 1
Training loss: 2.421729495692113
Validation loss: 2.5443135812960853

Epoch: 5| Step: 2
Training loss: 2.762150192552581
Validation loss: 2.573091122828686

Epoch: 5| Step: 3
Training loss: 2.0995675867934502
Validation loss: 2.57319466105929

Epoch: 5| Step: 4
Training loss: 2.6510463232412955
Validation loss: 2.553214740570484

Epoch: 5| Step: 5
Training loss: 2.139114515230833
Validation loss: 2.5469293307351273

Epoch: 5| Step: 6
Training loss: 2.585083235501839
Validation loss: 2.5270581058405934

Epoch: 5| Step: 7
Training loss: 2.396231167698875
Validation loss: 2.5994506263813544

Epoch: 5| Step: 8
Training loss: 2.2835701418219783
Validation loss: 2.6023667856882318

Epoch: 5| Step: 9
Training loss: 2.873072434135971
Validation loss: 2.5636544217132675

Epoch: 5| Step: 10
Training loss: 1.9861921865933192
Validation loss: 2.5722955920053003

Epoch: 312| Step: 0
Training loss: 2.6386532616964713
Validation loss: 2.560160669843443

Epoch: 5| Step: 1
Training loss: 2.443461927522846
Validation loss: 2.5720446987543024

Epoch: 5| Step: 2
Training loss: 1.7668601922736098
Validation loss: 2.5862946885252303

Epoch: 5| Step: 3
Training loss: 2.954391611535533
Validation loss: 2.573953377248271

Epoch: 5| Step: 4
Training loss: 1.7024879313978045
Validation loss: 2.55831670011828

Epoch: 5| Step: 5
Training loss: 3.0117329994191118
Validation loss: 2.5369626826760343

Epoch: 5| Step: 6
Training loss: 2.4359668898751714
Validation loss: 2.5337743306569807

Epoch: 5| Step: 7
Training loss: 2.6963730646662047
Validation loss: 2.5831202585534956

Epoch: 5| Step: 8
Training loss: 2.4713683910114606
Validation loss: 2.562041996309324

Epoch: 5| Step: 9
Training loss: 2.647775122708375
Validation loss: 2.5534103425888945

Epoch: 5| Step: 10
Training loss: 1.8251254913870754
Validation loss: 2.5766905482233637

Epoch: 313| Step: 0
Training loss: 2.9143463896464357
Validation loss: 2.578759328617226

Epoch: 5| Step: 1
Training loss: 2.1556568159109646
Validation loss: 2.554432277970581

Epoch: 5| Step: 2
Training loss: 2.2038994909032077
Validation loss: 2.575858982345029

Epoch: 5| Step: 3
Training loss: 2.21996242010253
Validation loss: 2.550571293245977

Epoch: 5| Step: 4
Training loss: 2.5439475617792358
Validation loss: 2.5373605925558356

Epoch: 5| Step: 5
Training loss: 2.323932533913189
Validation loss: 2.555142268375194

Epoch: 5| Step: 6
Training loss: 2.316099921777178
Validation loss: 2.5977592976433628

Epoch: 5| Step: 7
Training loss: 2.935095594366781
Validation loss: 2.548561265216258

Epoch: 5| Step: 8
Training loss: 2.0951041781577318
Validation loss: 2.5555787355918214

Epoch: 5| Step: 9
Training loss: 2.4136141758875147
Validation loss: 2.5623820558102266

Epoch: 5| Step: 10
Training loss: 2.638596698133383
Validation loss: 2.5592723861674487

Epoch: 314| Step: 0
Training loss: 2.512111698339969
Validation loss: 2.5947261010948175

Epoch: 5| Step: 1
Training loss: 1.8705932967293555
Validation loss: 2.543074753566928

Epoch: 5| Step: 2
Training loss: 2.8062888331795555
Validation loss: 2.545221515352485

Epoch: 5| Step: 3
Training loss: 2.1035897499561567
Validation loss: 2.5720880183789805

Epoch: 5| Step: 4
Training loss: 2.937647714350366
Validation loss: 2.534067544315689

Epoch: 5| Step: 5
Training loss: 2.518180544257898
Validation loss: 2.5934628301592872

Epoch: 5| Step: 6
Training loss: 3.11974992336735
Validation loss: 2.5608221364034716

Epoch: 5| Step: 7
Training loss: 2.1387642897056622
Validation loss: 2.533694352163363

Epoch: 5| Step: 8
Training loss: 1.7753721599227126
Validation loss: 2.589821313724253

Epoch: 5| Step: 9
Training loss: 2.309546362851511
Validation loss: 2.576631080248403

Epoch: 5| Step: 10
Training loss: 2.794930490711083
Validation loss: 2.56131355157274

Epoch: 315| Step: 0
Training loss: 2.046000053413219
Validation loss: 2.5715163463408204

Epoch: 5| Step: 1
Training loss: 2.260284021473198
Validation loss: 2.5773792022164748

Epoch: 5| Step: 2
Training loss: 2.3231794838703537
Validation loss: 2.5877687766918283

Epoch: 5| Step: 3
Training loss: 2.698739877445943
Validation loss: 2.5405548107399665

Epoch: 5| Step: 4
Training loss: 2.4938685568255488
Validation loss: 2.571598211537225

Epoch: 5| Step: 5
Training loss: 2.2280974869280032
Validation loss: 2.5612460043684964

Epoch: 5| Step: 6
Training loss: 2.4219976578692477
Validation loss: 2.5642138876582727

Epoch: 5| Step: 7
Training loss: 2.6591703629794283
Validation loss: 2.534817881082474

Epoch: 5| Step: 8
Training loss: 3.1904972420725213
Validation loss: 2.5302239874027666

Epoch: 5| Step: 9
Training loss: 2.295649610346467
Validation loss: 2.5093014942599825

Epoch: 5| Step: 10
Training loss: 2.4229750565249812
Validation loss: 2.576435087886332

Epoch: 316| Step: 0
Training loss: 2.4146124451017563
Validation loss: 2.5674777002352

Epoch: 5| Step: 1
Training loss: 3.0369663413364734
Validation loss: 2.5643123797426175

Epoch: 5| Step: 2
Training loss: 2.449074675537155
Validation loss: 2.5561265939064177

Epoch: 5| Step: 3
Training loss: 2.772392398407608
Validation loss: 2.5604606364782394

Epoch: 5| Step: 4
Training loss: 2.119946810756872
Validation loss: 2.54072219861891

Epoch: 5| Step: 5
Training loss: 2.6481955088559834
Validation loss: 2.566966812987559

Epoch: 5| Step: 6
Training loss: 2.1303630918763026
Validation loss: 2.5587803585734403

Epoch: 5| Step: 7
Training loss: 2.389162700939402
Validation loss: 2.5533691458609784

Epoch: 5| Step: 8
Training loss: 2.134822247898136
Validation loss: 2.587616368576484

Epoch: 5| Step: 9
Training loss: 2.506837459217497
Validation loss: 2.538027087197172

Epoch: 5| Step: 10
Training loss: 2.013875749333221
Validation loss: 2.562101796902408

Epoch: 317| Step: 0
Training loss: 3.1436491872348515
Validation loss: 2.540523156495094

Epoch: 5| Step: 1
Training loss: 2.1485589010444475
Validation loss: 2.575582189600625

Epoch: 5| Step: 2
Training loss: 1.867445413182356
Validation loss: 2.6169992216633995

Epoch: 5| Step: 3
Training loss: 2.3633084886730886
Validation loss: 2.582766440595709

Epoch: 5| Step: 4
Training loss: 2.3282360076041457
Validation loss: 2.592087066428956

Epoch: 5| Step: 5
Training loss: 2.694263818155169
Validation loss: 2.522987414223577

Epoch: 5| Step: 6
Training loss: 2.7283438298748406
Validation loss: 2.5685012818730013

Epoch: 5| Step: 7
Training loss: 2.18018141315412
Validation loss: 2.5679441207025655

Epoch: 5| Step: 8
Training loss: 2.930851982114493
Validation loss: 2.5764236638750972

Epoch: 5| Step: 9
Training loss: 2.4037042006614175
Validation loss: 2.5485738481986573

Epoch: 5| Step: 10
Training loss: 2.018623900830199
Validation loss: 2.5633145910171247

Epoch: 318| Step: 0
Training loss: 2.5561462343975463
Validation loss: 2.56342241046234

Epoch: 5| Step: 1
Training loss: 2.583773995829248
Validation loss: 2.595052734685776

Epoch: 5| Step: 2
Training loss: 2.253617134261207
Validation loss: 2.5885265151244585

Epoch: 5| Step: 3
Training loss: 2.5267423831126266
Validation loss: 2.563829406300373

Epoch: 5| Step: 4
Training loss: 1.983728378553049
Validation loss: 2.605088155492188

Epoch: 5| Step: 5
Training loss: 2.1185561820083234
Validation loss: 2.5785657618411872

Epoch: 5| Step: 6
Training loss: 2.7301921131322198
Validation loss: 2.548817195828827

Epoch: 5| Step: 7
Training loss: 2.253002177156564
Validation loss: 2.569208006515371

Epoch: 5| Step: 8
Training loss: 2.8768503620054857
Validation loss: 2.5873303287267544

Epoch: 5| Step: 9
Training loss: 2.407972140654804
Validation loss: 2.5754464124611283

Epoch: 5| Step: 10
Training loss: 2.624928155551664
Validation loss: 2.5593981253338867

Epoch: 319| Step: 0
Training loss: 2.56900287877772
Validation loss: 2.5896369830384387

Epoch: 5| Step: 1
Training loss: 2.8877753981010934
Validation loss: 2.5528086539219053

Epoch: 5| Step: 2
Training loss: 2.811366721817603
Validation loss: 2.5702737256169508

Epoch: 5| Step: 3
Training loss: 2.3513642794688283
Validation loss: 2.611901100776853

Epoch: 5| Step: 4
Training loss: 1.9158685999153813
Validation loss: 2.5714699878387264

Epoch: 5| Step: 5
Training loss: 2.589540765913218
Validation loss: 2.578473670329913

Epoch: 5| Step: 6
Training loss: 1.6718152472255159
Validation loss: 2.553366622248624

Epoch: 5| Step: 7
Training loss: 2.595607414231959
Validation loss: 2.6004419997836785

Epoch: 5| Step: 8
Training loss: 2.3924128012078216
Validation loss: 2.5931279434402796

Epoch: 5| Step: 9
Training loss: 2.7013502524085515
Validation loss: 2.5801313134160346

Epoch: 5| Step: 10
Training loss: 2.5268123958436375
Validation loss: 2.551152969620333

Epoch: 320| Step: 0
Training loss: 2.4215994401261307
Validation loss: 2.5482369551064097

Epoch: 5| Step: 1
Training loss: 2.1233651099030553
Validation loss: 2.6022614920827025

Epoch: 5| Step: 2
Training loss: 2.4996974762027064
Validation loss: 2.5745081933569574

Epoch: 5| Step: 3
Training loss: 2.224665961747386
Validation loss: 2.586356504532142

Epoch: 5| Step: 4
Training loss: 2.479642282805625
Validation loss: 2.5657049806040657

Epoch: 5| Step: 5
Training loss: 3.3038503610101317
Validation loss: 2.5434563755878727

Epoch: 5| Step: 6
Training loss: 1.8310014966232542
Validation loss: 2.533252063569172

Epoch: 5| Step: 7
Training loss: 1.8202866974012868
Validation loss: 2.57273918503893

Epoch: 5| Step: 8
Training loss: 2.6585809689959183
Validation loss: 2.536798834389527

Epoch: 5| Step: 9
Training loss: 2.9783601714043773
Validation loss: 2.5617056645168046

Epoch: 5| Step: 10
Training loss: 2.489464207649552
Validation loss: 2.57523090383794

Epoch: 321| Step: 0
Training loss: 2.4163432288500273
Validation loss: 2.5514413601691857

Epoch: 5| Step: 1
Training loss: 3.097794480384423
Validation loss: 2.585403159655435

Epoch: 5| Step: 2
Training loss: 2.3154451328697205
Validation loss: 2.5772774703795553

Epoch: 5| Step: 3
Training loss: 2.4745680422443472
Validation loss: 2.566255630061741

Epoch: 5| Step: 4
Training loss: 2.3448298700429846
Validation loss: 2.563390546551964

Epoch: 5| Step: 5
Training loss: 2.1223100578589955
Validation loss: 2.606447531941399

Epoch: 5| Step: 6
Training loss: 2.334817164775891
Validation loss: 2.6128349254760637

Epoch: 5| Step: 7
Training loss: 2.241091363912638
Validation loss: 2.5669155709590554

Epoch: 5| Step: 8
Training loss: 2.274796017734831
Validation loss: 2.5767053627688488

Epoch: 5| Step: 9
Training loss: 2.588098919241223
Validation loss: 2.5859120373311395

Epoch: 5| Step: 10
Training loss: 2.617719818183143
Validation loss: 2.5928852978959327

Epoch: 322| Step: 0
Training loss: 2.224973734154132
Validation loss: 2.5955230369679825

Epoch: 5| Step: 1
Training loss: 2.715277021125586
Validation loss: 2.5624415473263893

Epoch: 5| Step: 2
Training loss: 2.1185521306278936
Validation loss: 2.5797226903279684

Epoch: 5| Step: 3
Training loss: 2.594849135289393
Validation loss: 2.5778756447105304

Epoch: 5| Step: 4
Training loss: 2.670167433100137
Validation loss: 2.5446999106892645

Epoch: 5| Step: 5
Training loss: 2.31563438176817
Validation loss: 2.5474913778751573

Epoch: 5| Step: 6
Training loss: 1.8340796627685243
Validation loss: 2.571620320814385

Epoch: 5| Step: 7
Training loss: 2.7907233755920573
Validation loss: 2.567948360581737

Epoch: 5| Step: 8
Training loss: 2.8278770548845866
Validation loss: 2.5624601229474417

Epoch: 5| Step: 9
Training loss: 2.314690248599248
Validation loss: 2.551149123884611

Epoch: 5| Step: 10
Training loss: 2.4977704596874206
Validation loss: 2.5474593992311867

Epoch: 323| Step: 0
Training loss: 2.037428862845225
Validation loss: 2.5592430780611286

Epoch: 5| Step: 1
Training loss: 3.3438592340327915
Validation loss: 2.5519839145431074

Epoch: 5| Step: 2
Training loss: 2.480070595813209
Validation loss: 2.546483374947305

Epoch: 5| Step: 3
Training loss: 2.379317525255158
Validation loss: 2.5620358819892552

Epoch: 5| Step: 4
Training loss: 2.2266777142614234
Validation loss: 2.5766954323566025

Epoch: 5| Step: 5
Training loss: 2.2881299094819805
Validation loss: 2.5485051867485766

Epoch: 5| Step: 6
Training loss: 2.926221908571379
Validation loss: 2.572729109776979

Epoch: 5| Step: 7
Training loss: 1.7011829467833592
Validation loss: 2.579090536969589

Epoch: 5| Step: 8
Training loss: 2.0345692437839182
Validation loss: 2.5502257081735897

Epoch: 5| Step: 9
Training loss: 2.944074861455795
Validation loss: 2.547289390529904

Epoch: 5| Step: 10
Training loss: 2.241461872356037
Validation loss: 2.5447713686399775

Epoch: 324| Step: 0
Training loss: 2.3194424317656392
Validation loss: 2.5536301302373023

Epoch: 5| Step: 1
Training loss: 2.122127611182827
Validation loss: 2.5703998860887016

Epoch: 5| Step: 2
Training loss: 1.924201487604321
Validation loss: 2.5751454507487987

Epoch: 5| Step: 3
Training loss: 2.1846041448682163
Validation loss: 2.506844823376283

Epoch: 5| Step: 4
Training loss: 2.9778921606702036
Validation loss: 2.580505900509408

Epoch: 5| Step: 5
Training loss: 2.501061500259895
Validation loss: 2.5746929773774365

Epoch: 5| Step: 6
Training loss: 2.4962410323698734
Validation loss: 2.5533797990218274

Epoch: 5| Step: 7
Training loss: 2.702551455647489
Validation loss: 2.545852129598483

Epoch: 5| Step: 8
Training loss: 2.288363092742512
Validation loss: 2.562820713633701

Epoch: 5| Step: 9
Training loss: 2.135627426043375
Validation loss: 2.6044558177924335

Epoch: 5| Step: 10
Training loss: 2.978073417481044
Validation loss: 2.536495546973091

Epoch: 325| Step: 0
Training loss: 1.7731074895790837
Validation loss: 2.5575644951542387

Epoch: 5| Step: 1
Training loss: 2.903258722385321
Validation loss: 2.5555773853453356

Epoch: 5| Step: 2
Training loss: 2.74642946624883
Validation loss: 2.554440867810091

Epoch: 5| Step: 3
Training loss: 2.360485800673125
Validation loss: 2.5747234836774746

Epoch: 5| Step: 4
Training loss: 2.449088693965207
Validation loss: 2.5733478894375392

Epoch: 5| Step: 5
Training loss: 2.1613181440246
Validation loss: 2.5882310774857347

Epoch: 5| Step: 6
Training loss: 2.2836254763675012
Validation loss: 2.5614709766381183

Epoch: 5| Step: 7
Training loss: 2.221349134063088
Validation loss: 2.5924413161604933

Epoch: 5| Step: 8
Training loss: 2.185640907480604
Validation loss: 2.5888494846373122

Epoch: 5| Step: 9
Training loss: 3.0028564841179115
Validation loss: 2.571324097735638

Epoch: 5| Step: 10
Training loss: 2.8217298164068287
Validation loss: 2.535038270424591

Epoch: 326| Step: 0
Training loss: 2.0457669819044613
Validation loss: 2.5629844597747238

Epoch: 5| Step: 1
Training loss: 2.839773730814503
Validation loss: 2.5697785480024966

Epoch: 5| Step: 2
Training loss: 2.8968613444215294
Validation loss: 2.57807659801045

Epoch: 5| Step: 3
Training loss: 2.578724369544848
Validation loss: 2.546286445425433

Epoch: 5| Step: 4
Training loss: 2.782476433365409
Validation loss: 2.557643753781636

Epoch: 5| Step: 5
Training loss: 1.6778665297376218
Validation loss: 2.587417862365084

Epoch: 5| Step: 6
Training loss: 2.793397158331336
Validation loss: 2.568342124693567

Epoch: 5| Step: 7
Training loss: 2.3629204592884263
Validation loss: 2.542056259752082

Epoch: 5| Step: 8
Training loss: 2.22233796480546
Validation loss: 2.5544353530140054

Epoch: 5| Step: 9
Training loss: 2.2187897584603493
Validation loss: 2.548292684350837

Epoch: 5| Step: 10
Training loss: 2.4787171434465
Validation loss: 2.58675366065358

Epoch: 327| Step: 0
Training loss: 2.1489636695883085
Validation loss: 2.607844103512535

Epoch: 5| Step: 1
Training loss: 2.5887292273335913
Validation loss: 2.5546127097150526

Epoch: 5| Step: 2
Training loss: 3.325998405910346
Validation loss: 2.5479261658854107

Epoch: 5| Step: 3
Training loss: 2.167981286914764
Validation loss: 2.5742561135579125

Epoch: 5| Step: 4
Training loss: 2.2845367374384264
Validation loss: 2.5370381973908396

Epoch: 5| Step: 5
Training loss: 2.0899304523486655
Validation loss: 2.582558878689719

Epoch: 5| Step: 6
Training loss: 2.6561126673482716
Validation loss: 2.5427783345154302

Epoch: 5| Step: 7
Training loss: 2.8590858188169785
Validation loss: 2.5385016163399774

Epoch: 5| Step: 8
Training loss: 2.010217554645366
Validation loss: 2.56633308988006

Epoch: 5| Step: 9
Training loss: 2.0083187667297313
Validation loss: 2.5697650881928706

Epoch: 5| Step: 10
Training loss: 2.551223132427963
Validation loss: 2.584545927305842

Epoch: 328| Step: 0
Training loss: 2.891850392187656
Validation loss: 2.613053499883709

Epoch: 5| Step: 1
Training loss: 2.430716440840331
Validation loss: 2.5711242489109765

Epoch: 5| Step: 2
Training loss: 2.581293921293247
Validation loss: 2.6043976639873265

Epoch: 5| Step: 3
Training loss: 2.49421461170362
Validation loss: 2.5681568867113094

Epoch: 5| Step: 4
Training loss: 1.7617266669592413
Validation loss: 2.587153093369272

Epoch: 5| Step: 5
Training loss: 2.927540717358929
Validation loss: 2.5272916315598324

Epoch: 5| Step: 6
Training loss: 2.1144071107794606
Validation loss: 2.60315675969078

Epoch: 5| Step: 7
Training loss: 2.0756913469663774
Validation loss: 2.5505405000786476

Epoch: 5| Step: 8
Training loss: 1.6611754396812357
Validation loss: 2.571839383591812

Epoch: 5| Step: 9
Training loss: 3.2408603387794472
Validation loss: 2.54338803460932

Epoch: 5| Step: 10
Training loss: 2.083103612314436
Validation loss: 2.5693277007851902

Epoch: 329| Step: 0
Training loss: 2.3935989133001097
Validation loss: 2.5386095878330264

Epoch: 5| Step: 1
Training loss: 2.4033595968955095
Validation loss: 2.5537060184423934

Epoch: 5| Step: 2
Training loss: 2.1156388703515616
Validation loss: 2.5820247228153117

Epoch: 5| Step: 3
Training loss: 2.4324356679064336
Validation loss: 2.5839294671327155

Epoch: 5| Step: 4
Training loss: 2.5373213681640325
Validation loss: 2.55001396341862

Epoch: 5| Step: 5
Training loss: 2.685316218787883
Validation loss: 2.5829297525203803

Epoch: 5| Step: 6
Training loss: 2.127685869034148
Validation loss: 2.589873129541713

Epoch: 5| Step: 7
Training loss: 2.3824836879303906
Validation loss: 2.5737147580352113

Epoch: 5| Step: 8
Training loss: 2.042198604912543
Validation loss: 2.563285937712864

Epoch: 5| Step: 9
Training loss: 2.767004929588126
Validation loss: 2.5916069647336237

Epoch: 5| Step: 10
Training loss: 2.7607019432974944
Validation loss: 2.555546684600476

Epoch: 330| Step: 0
Training loss: 2.979555082454406
Validation loss: 2.5519574340009

Epoch: 5| Step: 1
Training loss: 2.1676007482572097
Validation loss: 2.531620457828949

Epoch: 5| Step: 2
Training loss: 2.4914096108548787
Validation loss: 2.577704225809365

Epoch: 5| Step: 3
Training loss: 1.6571881498291998
Validation loss: 2.5864339461687678

Epoch: 5| Step: 4
Training loss: 2.451495267044593
Validation loss: 2.56825900977163

Epoch: 5| Step: 5
Training loss: 2.067790326879759
Validation loss: 2.5936182124271054

Epoch: 5| Step: 6
Training loss: 2.24282997842085
Validation loss: 2.5653608408705946

Epoch: 5| Step: 7
Training loss: 3.0327651179846185
Validation loss: 2.575515806456847

Epoch: 5| Step: 8
Training loss: 1.925858316175555
Validation loss: 2.5574889219225745

Epoch: 5| Step: 9
Training loss: 2.8812599033011748
Validation loss: 2.57128590790954

Epoch: 5| Step: 10
Training loss: 2.7775300254537956
Validation loss: 2.593229664415135

Epoch: 331| Step: 0
Training loss: 3.11691749569792
Validation loss: 2.589529217558742

Epoch: 5| Step: 1
Training loss: 2.6216547404036366
Validation loss: 2.5367357713317698

Epoch: 5| Step: 2
Training loss: 2.5297899155976027
Validation loss: 2.5770245328583163

Epoch: 5| Step: 3
Training loss: 1.9892093313580128
Validation loss: 2.572454131866006

Epoch: 5| Step: 4
Training loss: 2.0037418171601913
Validation loss: 2.5349658514278812

Epoch: 5| Step: 5
Training loss: 2.2182644594861176
Validation loss: 2.554868608096041

Epoch: 5| Step: 6
Training loss: 2.3184653999489617
Validation loss: 2.543854736040831

Epoch: 5| Step: 7
Training loss: 1.7899819888908348
Validation loss: 2.5942765556504384

Epoch: 5| Step: 8
Training loss: 2.775573423783011
Validation loss: 2.5852210431580507

Epoch: 5| Step: 9
Training loss: 2.557740233652401
Validation loss: 2.6065581544140777

Epoch: 5| Step: 10
Training loss: 2.852004594368464
Validation loss: 2.529963236292843

Epoch: 332| Step: 0
Training loss: 1.8598073248383717
Validation loss: 2.5499528408012773

Epoch: 5| Step: 1
Training loss: 3.1852479346531886
Validation loss: 2.5527729327426987

Epoch: 5| Step: 2
Training loss: 2.3807566294354983
Validation loss: 2.5692466552918107

Epoch: 5| Step: 3
Training loss: 2.5562437024773437
Validation loss: 2.5486647840253247

Epoch: 5| Step: 4
Training loss: 2.2411125344342464
Validation loss: 2.5927959723188816

Epoch: 5| Step: 5
Training loss: 2.233394167436889
Validation loss: 2.586703918630369

Epoch: 5| Step: 6
Training loss: 2.1748073185603753
Validation loss: 2.59139390807996

Epoch: 5| Step: 7
Training loss: 1.9525349450494873
Validation loss: 2.5620359460293414

Epoch: 5| Step: 8
Training loss: 2.781745780732497
Validation loss: 2.56159013971868

Epoch: 5| Step: 9
Training loss: 2.6363365065814035
Validation loss: 2.595940275084257

Epoch: 5| Step: 10
Training loss: 2.20833982310751
Validation loss: 2.546014884752296

Epoch: 333| Step: 0
Training loss: 2.496611014723337
Validation loss: 2.578803351620067

Epoch: 5| Step: 1
Training loss: 2.7143418101917325
Validation loss: 2.613416573122443

Epoch: 5| Step: 2
Training loss: 2.073932060357572
Validation loss: 2.6002233492141893

Epoch: 5| Step: 3
Training loss: 2.7514371584537716
Validation loss: 2.542921099326522

Epoch: 5| Step: 4
Training loss: 2.297594022767519
Validation loss: 2.599536613337999

Epoch: 5| Step: 5
Training loss: 2.8952431569079082
Validation loss: 2.5764091064212966

Epoch: 5| Step: 6
Training loss: 2.1834138035201534
Validation loss: 2.571400607287929

Epoch: 5| Step: 7
Training loss: 2.8042501889657516
Validation loss: 2.597059121446058

Epoch: 5| Step: 8
Training loss: 2.0215855669871803
Validation loss: 2.5805864056312755

Epoch: 5| Step: 9
Training loss: 2.301786089963395
Validation loss: 2.566332783202129

Epoch: 5| Step: 10
Training loss: 2.0723180881082857
Validation loss: 2.560003056048484

Epoch: 334| Step: 0
Training loss: 3.114752791439832
Validation loss: 2.5888996548119034

Epoch: 5| Step: 1
Training loss: 2.3977333053979746
Validation loss: 2.5954467525349805

Epoch: 5| Step: 2
Training loss: 1.911266480119707
Validation loss: 2.600869996119002

Epoch: 5| Step: 3
Training loss: 2.531324785799644
Validation loss: 2.5871375191609856

Epoch: 5| Step: 4
Training loss: 1.8940749415240932
Validation loss: 2.583508791375143

Epoch: 5| Step: 5
Training loss: 1.7485096579926656
Validation loss: 2.5843043260666594

Epoch: 5| Step: 6
Training loss: 2.2314859131973788
Validation loss: 2.570376526571576

Epoch: 5| Step: 7
Training loss: 2.53543865118053
Validation loss: 2.5508531215046104

Epoch: 5| Step: 8
Training loss: 2.520017402528286
Validation loss: 2.565608487488192

Epoch: 5| Step: 9
Training loss: 2.808527366055269
Validation loss: 2.6011705330850434

Epoch: 5| Step: 10
Training loss: 2.659893543866628
Validation loss: 2.563599427419146

Epoch: 335| Step: 0
Training loss: 3.180796736707491
Validation loss: 2.5844170351212403

Epoch: 5| Step: 1
Training loss: 2.903156233538424
Validation loss: 2.559232729288407

Epoch: 5| Step: 2
Training loss: 2.1895460097171315
Validation loss: 2.582480700409953

Epoch: 5| Step: 3
Training loss: 2.1261546420019743
Validation loss: 2.5725087644634073

Epoch: 5| Step: 4
Training loss: 2.170501384384041
Validation loss: 2.5605936229885

Epoch: 5| Step: 5
Training loss: 2.927281401280498
Validation loss: 2.5567441906937947

Epoch: 5| Step: 6
Training loss: 2.045449379230487
Validation loss: 2.581266167257912

Epoch: 5| Step: 7
Training loss: 2.506857146354332
Validation loss: 2.558198864199253

Epoch: 5| Step: 8
Training loss: 2.289345993870494
Validation loss: 2.5552018817982214

Epoch: 5| Step: 9
Training loss: 2.2090661854186395
Validation loss: 2.570522355263319

Epoch: 5| Step: 10
Training loss: 1.8963252117653384
Validation loss: 2.573696715870498

Epoch: 336| Step: 0
Training loss: 2.2373567972229718
Validation loss: 2.5568492100551237

Epoch: 5| Step: 1
Training loss: 1.8796743619210758
Validation loss: 2.5803980278948178

Epoch: 5| Step: 2
Training loss: 1.8498474419040862
Validation loss: 2.587126191954743

Epoch: 5| Step: 3
Training loss: 2.10064541117573
Validation loss: 2.5726153071975633

Epoch: 5| Step: 4
Training loss: 2.892675548821456
Validation loss: 2.572315764821672

Epoch: 5| Step: 5
Training loss: 1.969898373359432
Validation loss: 2.594529418428881

Epoch: 5| Step: 6
Training loss: 3.1468979168903166
Validation loss: 2.5620643011211643

Epoch: 5| Step: 7
Training loss: 2.7033523728546465
Validation loss: 2.610761932490919

Epoch: 5| Step: 8
Training loss: 2.2301933800025124
Validation loss: 2.5609701904007505

Epoch: 5| Step: 9
Training loss: 2.3341314676452893
Validation loss: 2.593297314716261

Epoch: 5| Step: 10
Training loss: 3.016997978465181
Validation loss: 2.5913561515438635

Epoch: 337| Step: 0
Training loss: 2.628748351934173
Validation loss: 2.5608041485643067

Epoch: 5| Step: 1
Training loss: 2.0122427544943817
Validation loss: 2.562526652719995

Epoch: 5| Step: 2
Training loss: 2.5936291218362277
Validation loss: 2.5453444793693936

Epoch: 5| Step: 3
Training loss: 2.690760386889877
Validation loss: 2.5827147010715636

Epoch: 5| Step: 4
Training loss: 2.1295971230622883
Validation loss: 2.5468394854971126

Epoch: 5| Step: 5
Training loss: 2.336344297576632
Validation loss: 2.5697164279787055

Epoch: 5| Step: 6
Training loss: 2.5745118687738215
Validation loss: 2.5462868501652274

Epoch: 5| Step: 7
Training loss: 1.959664528124627
Validation loss: 2.5361872247652966

Epoch: 5| Step: 8
Training loss: 2.6935102103793795
Validation loss: 2.578408032266605

Epoch: 5| Step: 9
Training loss: 2.618052416551385
Validation loss: 2.542932450542774

Epoch: 5| Step: 10
Training loss: 2.38272234636701
Validation loss: 2.5835848066316807

Epoch: 338| Step: 0
Training loss: 2.3084096044432814
Validation loss: 2.564985097209254

Epoch: 5| Step: 1
Training loss: 1.7728267071586867
Validation loss: 2.5709783456703894

Epoch: 5| Step: 2
Training loss: 2.830064645844367
Validation loss: 2.575644154217774

Epoch: 5| Step: 3
Training loss: 2.369850398303521
Validation loss: 2.560492831211175

Epoch: 5| Step: 4
Training loss: 2.6327050976679143
Validation loss: 2.590350470700973

Epoch: 5| Step: 5
Training loss: 2.8031739637846655
Validation loss: 2.5704578117085966

Epoch: 5| Step: 6
Training loss: 2.52596097732086
Validation loss: 2.5856995752726166

Epoch: 5| Step: 7
Training loss: 2.515666416372237
Validation loss: 2.59989578457856

Epoch: 5| Step: 8
Training loss: 2.008964000571145
Validation loss: 2.579696776259355

Epoch: 5| Step: 9
Training loss: 2.3987517011277615
Validation loss: 2.533202110960342

Epoch: 5| Step: 10
Training loss: 2.1215417434501873
Validation loss: 2.519152161465525

Epoch: 339| Step: 0
Training loss: 2.428306653311037
Validation loss: 2.5383869422832683

Epoch: 5| Step: 1
Training loss: 2.445168000360669
Validation loss: 2.5573659939974234

Epoch: 5| Step: 2
Training loss: 2.7086600375584533
Validation loss: 2.5456944617294144

Epoch: 5| Step: 3
Training loss: 2.578516057729143
Validation loss: 2.5745714504227935

Epoch: 5| Step: 4
Training loss: 2.178406916890561
Validation loss: 2.5855185971177765

Epoch: 5| Step: 5
Training loss: 1.8268894682816028
Validation loss: 2.599552982584308

Epoch: 5| Step: 6
Training loss: 2.399160468767152
Validation loss: 2.5985085653886904

Epoch: 5| Step: 7
Training loss: 2.8409378064178177
Validation loss: 2.5892937683985657

Epoch: 5| Step: 8
Training loss: 2.162988719951336
Validation loss: 2.5720175894799207

Epoch: 5| Step: 9
Training loss: 2.633866820639101
Validation loss: 2.5945594998079966

Epoch: 5| Step: 10
Training loss: 2.2337217643161464
Validation loss: 2.6012719168926335

Epoch: 340| Step: 0
Training loss: 2.141961230592327
Validation loss: 2.5861868442415252

Epoch: 5| Step: 1
Training loss: 2.487503097762283
Validation loss: 2.5719290432843738

Epoch: 5| Step: 2
Training loss: 3.0559098317689846
Validation loss: 2.5676972502281394

Epoch: 5| Step: 3
Training loss: 2.340990196432373
Validation loss: 2.578924070781324

Epoch: 5| Step: 4
Training loss: 2.1154648645558183
Validation loss: 2.5886112719682006

Epoch: 5| Step: 5
Training loss: 2.1136682970351233
Validation loss: 2.5644300182190523

Epoch: 5| Step: 6
Training loss: 1.7997772661791305
Validation loss: 2.5901357013252233

Epoch: 5| Step: 7
Training loss: 2.634019162003341
Validation loss: 2.563975125929055

Epoch: 5| Step: 8
Training loss: 2.4777442206641647
Validation loss: 2.614049289157737

Epoch: 5| Step: 9
Training loss: 2.129522895749019
Validation loss: 2.5718810975973825

Epoch: 5| Step: 10
Training loss: 2.9944355540083634
Validation loss: 2.5560075321712072

Epoch: 341| Step: 0
Training loss: 2.669254289281174
Validation loss: 2.576590400557226

Epoch: 5| Step: 1
Training loss: 2.6869442387293816
Validation loss: 2.56312764342472

Epoch: 5| Step: 2
Training loss: 2.1551135841758926
Validation loss: 2.55815931293976

Epoch: 5| Step: 3
Training loss: 3.3667906772951715
Validation loss: 2.5544849119867337

Epoch: 5| Step: 4
Training loss: 1.8448152212846667
Validation loss: 2.570624807198859

Epoch: 5| Step: 5
Training loss: 1.96348193926916
Validation loss: 2.579090745711587

Epoch: 5| Step: 6
Training loss: 2.56042396372621
Validation loss: 2.5185005589873026

Epoch: 5| Step: 7
Training loss: 2.0329735119656633
Validation loss: 2.5583310383545266

Epoch: 5| Step: 8
Training loss: 2.7648888594242376
Validation loss: 2.5655690424627586

Epoch: 5| Step: 9
Training loss: 2.3923602818556997
Validation loss: 2.5619029708459453

Epoch: 5| Step: 10
Training loss: 1.6907669515474895
Validation loss: 2.5561124865187894

Epoch: 342| Step: 0
Training loss: 2.3206315254758714
Validation loss: 2.575035129462406

Epoch: 5| Step: 1
Training loss: 2.506466703487872
Validation loss: 2.548723305216791

Epoch: 5| Step: 2
Training loss: 2.698396549234409
Validation loss: 2.532393067393213

Epoch: 5| Step: 3
Training loss: 1.7905192878236078
Validation loss: 2.592028969421278

Epoch: 5| Step: 4
Training loss: 2.408089665248465
Validation loss: 2.57548725604768

Epoch: 5| Step: 5
Training loss: 2.305560240938668
Validation loss: 2.5731651737811654

Epoch: 5| Step: 6
Training loss: 2.3752367002088537
Validation loss: 2.601300968287134

Epoch: 5| Step: 7
Training loss: 2.944569299158019
Validation loss: 2.557001622284851

Epoch: 5| Step: 8
Training loss: 2.3439276055753564
Validation loss: 2.5510042971156057

Epoch: 5| Step: 9
Training loss: 2.3771029748754304
Validation loss: 2.5977818020408567

Epoch: 5| Step: 10
Training loss: 2.0723503016394402
Validation loss: 2.5575977878457925

Epoch: 343| Step: 0
Training loss: 2.4223008304443496
Validation loss: 2.5815021827411115

Epoch: 5| Step: 1
Training loss: 2.2043037237331027
Validation loss: 2.565293420972891

Epoch: 5| Step: 2
Training loss: 1.826516642129447
Validation loss: 2.5912864244155336

Epoch: 5| Step: 3
Training loss: 2.5515502892019226
Validation loss: 2.5823097569654

Epoch: 5| Step: 4
Training loss: 2.405245286325313
Validation loss: 2.6049998614606595

Epoch: 5| Step: 5
Training loss: 2.4506175839293194
Validation loss: 2.6207481664936085

Epoch: 5| Step: 6
Training loss: 2.485660052686604
Validation loss: 2.6060645664785915

Epoch: 5| Step: 7
Training loss: 2.5410836494365623
Validation loss: 2.5710122514004303

Epoch: 5| Step: 8
Training loss: 2.5084123220923056
Validation loss: 2.5838071571845442

Epoch: 5| Step: 9
Training loss: 2.770729053418482
Validation loss: 2.5711810943412474

Epoch: 5| Step: 10
Training loss: 2.1477009568430177
Validation loss: 2.580487447836463

Epoch: 344| Step: 0
Training loss: 1.9978330316895268
Validation loss: 2.611506355455665

Epoch: 5| Step: 1
Training loss: 2.273987274288647
Validation loss: 2.5700282071078973

Epoch: 5| Step: 2
Training loss: 1.6731729193213831
Validation loss: 2.580053534550518

Epoch: 5| Step: 3
Training loss: 2.138546345131636
Validation loss: 2.583605305079426

Epoch: 5| Step: 4
Training loss: 2.624013988050533
Validation loss: 2.5654831176566617

Epoch: 5| Step: 5
Training loss: 2.56761589167607
Validation loss: 2.5723545722072445

Epoch: 5| Step: 6
Training loss: 2.8872877497093326
Validation loss: 2.592333642041518

Epoch: 5| Step: 7
Training loss: 2.973820261692448
Validation loss: 2.5660362304680215

Epoch: 5| Step: 8
Training loss: 2.2082127472205446
Validation loss: 2.5828644961857576

Epoch: 5| Step: 9
Training loss: 2.344092890770394
Validation loss: 2.5989676414180196

Epoch: 5| Step: 10
Training loss: 2.769931177874926
Validation loss: 2.5944795458483223

Epoch: 345| Step: 0
Training loss: 2.7398178425682467
Validation loss: 2.5707797793215197

Epoch: 5| Step: 1
Training loss: 2.32332100079117
Validation loss: 2.6040180726675284

Epoch: 5| Step: 2
Training loss: 2.326913198218502
Validation loss: 2.5917369919904334

Epoch: 5| Step: 3
Training loss: 2.477288846622866
Validation loss: 2.5867592026822996

Epoch: 5| Step: 4
Training loss: 2.1724389530994532
Validation loss: 2.566368491455251

Epoch: 5| Step: 5
Training loss: 1.9568868800837957
Validation loss: 2.5592902144835565

Epoch: 5| Step: 6
Training loss: 2.4185560557754244
Validation loss: 2.583121273838729

Epoch: 5| Step: 7
Training loss: 1.9016625283229955
Validation loss: 2.556483453024591

Epoch: 5| Step: 8
Training loss: 2.2795430943623716
Validation loss: 2.586405445905981

Epoch: 5| Step: 9
Training loss: 2.6825275996371296
Validation loss: 2.62173254259238

Epoch: 5| Step: 10
Training loss: 2.7964694618864385
Validation loss: 2.5849767811883386

Epoch: 346| Step: 0
Training loss: 2.153592891265337
Validation loss: 2.5876991272631837

Epoch: 5| Step: 1
Training loss: 2.5515034749947247
Validation loss: 2.5819612293461667

Epoch: 5| Step: 2
Training loss: 1.8076652631750092
Validation loss: 2.5925591575874316

Epoch: 5| Step: 3
Training loss: 1.9538087792319474
Validation loss: 2.5713528633610796

Epoch: 5| Step: 4
Training loss: 2.7101374168324446
Validation loss: 2.5879095211875422

Epoch: 5| Step: 5
Training loss: 2.07717759184112
Validation loss: 2.542457943226449

Epoch: 5| Step: 6
Training loss: 2.319056520997927
Validation loss: 2.5914230776324128

Epoch: 5| Step: 7
Training loss: 2.435143138273772
Validation loss: 2.598369009679458

Epoch: 5| Step: 8
Training loss: 2.653812771313984
Validation loss: 2.5964624084869374

Epoch: 5| Step: 9
Training loss: 2.399081563055205
Validation loss: 2.6089359213929155

Epoch: 5| Step: 10
Training loss: 3.515219431901648
Validation loss: 2.5887268149408884

Epoch: 347| Step: 0
Training loss: 2.80287456095405
Validation loss: 2.571348335976861

Epoch: 5| Step: 1
Training loss: 1.7525377945899097
Validation loss: 2.576472001395017

Epoch: 5| Step: 2
Training loss: 2.294195363726324
Validation loss: 2.60047469917156

Epoch: 5| Step: 3
Training loss: 2.0121027015274695
Validation loss: 2.573244802703995

Epoch: 5| Step: 4
Training loss: 2.4751659992691377
Validation loss: 2.545930147761216

Epoch: 5| Step: 5
Training loss: 2.9441064444662417
Validation loss: 2.564367572686423

Epoch: 5| Step: 6
Training loss: 2.431136113419287
Validation loss: 2.572359613068162

Epoch: 5| Step: 7
Training loss: 2.767884274538726
Validation loss: 2.550020272948275

Epoch: 5| Step: 8
Training loss: 2.649449158044829
Validation loss: 2.5404344056533508

Epoch: 5| Step: 9
Training loss: 2.1062166658474744
Validation loss: 2.5840006488077414

Epoch: 5| Step: 10
Training loss: 2.065806195366934
Validation loss: 2.5923260821429404

Epoch: 348| Step: 0
Training loss: 2.2926402595901956
Validation loss: 2.576700924383735

Epoch: 5| Step: 1
Training loss: 2.4883533988325874
Validation loss: 2.5586078376948924

Epoch: 5| Step: 2
Training loss: 2.0675824284756485
Validation loss: 2.5678846583301693

Epoch: 5| Step: 3
Training loss: 2.149020916879145
Validation loss: 2.584792705070951

Epoch: 5| Step: 4
Training loss: 2.7123694252193498
Validation loss: 2.6099049054248846

Epoch: 5| Step: 5
Training loss: 1.9873267020241043
Validation loss: 2.637258604288049

Epoch: 5| Step: 6
Training loss: 2.29112052189526
Validation loss: 2.59996532025806

Epoch: 5| Step: 7
Training loss: 2.2814893205080504
Validation loss: 2.598092764947126

Epoch: 5| Step: 8
Training loss: 3.2455657639764284
Validation loss: 2.608688040061704

Epoch: 5| Step: 9
Training loss: 2.49537880080301
Validation loss: 2.564566450079356

Epoch: 5| Step: 10
Training loss: 2.450748239817187
Validation loss: 2.5784525037110217

Epoch: 349| Step: 0
Training loss: 2.437053541719993
Validation loss: 2.589939335236004

Epoch: 5| Step: 1
Training loss: 2.4750877827191355
Validation loss: 2.581103120054497

Epoch: 5| Step: 2
Training loss: 2.016440293188383
Validation loss: 2.591343045202997

Epoch: 5| Step: 3
Training loss: 2.2469665423806657
Validation loss: 2.5859702886164424

Epoch: 5| Step: 4
Training loss: 2.6752808040224663
Validation loss: 2.5919756799652904

Epoch: 5| Step: 5
Training loss: 3.085721010750804
Validation loss: 2.590431026151263

Epoch: 5| Step: 6
Training loss: 2.194404169778064
Validation loss: 2.601303486295905

Epoch: 5| Step: 7
Training loss: 2.24652392704624
Validation loss: 2.6012398208248935

Epoch: 5| Step: 8
Training loss: 1.9742317781973295
Validation loss: 2.55213858013279

Epoch: 5| Step: 9
Training loss: 2.492185682337944
Validation loss: 2.548752092563178

Epoch: 5| Step: 10
Training loss: 2.367855166709978
Validation loss: 2.57574199125675

Epoch: 350| Step: 0
Training loss: 2.38279508990822
Validation loss: 2.5635021800115276

Epoch: 5| Step: 1
Training loss: 2.7580139259501326
Validation loss: 2.575389406345197

Epoch: 5| Step: 2
Training loss: 2.210447978362116
Validation loss: 2.5395509251017327

Epoch: 5| Step: 3
Training loss: 2.641814646702709
Validation loss: 2.5906469525973947

Epoch: 5| Step: 4
Training loss: 2.593802945619255
Validation loss: 2.5424231726908086

Epoch: 5| Step: 5
Training loss: 2.15893619567109
Validation loss: 2.568298552231306

Epoch: 5| Step: 6
Training loss: 2.2815844147009443
Validation loss: 2.5841418966494207

Epoch: 5| Step: 7
Training loss: 2.6615581655472624
Validation loss: 2.579135753073851

Epoch: 5| Step: 8
Training loss: 2.12104552830631
Validation loss: 2.553235513968232

Epoch: 5| Step: 9
Training loss: 2.3871533486722014
Validation loss: 2.5838354980881237

Epoch: 5| Step: 10
Training loss: 1.9426878722667016
Validation loss: 2.584604645811405

Testing loss: 2.4603151964264125
